Epoch: 1| Step: 0
Training loss: 7.058519440066098
Validation loss: 5.811905259636372

Epoch: 6| Step: 1
Training loss: 6.306854442895221
Validation loss: 5.8003544403166245

Epoch: 6| Step: 2
Training loss: 6.0132474882732545
Validation loss: 5.791665669539478

Epoch: 6| Step: 3
Training loss: 6.2802794356651885
Validation loss: 5.779416070061104

Epoch: 6| Step: 4
Training loss: 5.8035024919712415
Validation loss: 5.768554907930558

Epoch: 6| Step: 5
Training loss: 5.690026361441261
Validation loss: 5.75719598707087

Epoch: 6| Step: 6
Training loss: 6.0867535456584685
Validation loss: 5.7457601976431265

Epoch: 6| Step: 7
Training loss: 5.865870098019213
Validation loss: 5.734334309751468

Epoch: 6| Step: 8
Training loss: 5.744283737272809
Validation loss: 5.720973709877302

Epoch: 6| Step: 9
Training loss: 5.791966419101548
Validation loss: 5.709380933135258

Epoch: 6| Step: 10
Training loss: 4.933533825967234
Validation loss: 5.695500653738586

Epoch: 6| Step: 11
Training loss: 5.572169782079712
Validation loss: 5.681623895733506

Epoch: 6| Step: 12
Training loss: 5.621593206615368
Validation loss: 5.666623657661731

Epoch: 6| Step: 13
Training loss: 4.917021183659537
Validation loss: 5.6506467432178225

Epoch: 2| Step: 0
Training loss: 5.839057547934915
Validation loss: 5.636458840549634

Epoch: 6| Step: 1
Training loss: 6.289891613631388
Validation loss: 5.620849151626774

Epoch: 6| Step: 2
Training loss: 5.498978259809314
Validation loss: 5.604891034172194

Epoch: 6| Step: 3
Training loss: 6.368318235007888
Validation loss: 5.588185730685806

Epoch: 6| Step: 4
Training loss: 6.206454750210159
Validation loss: 5.568715484089745

Epoch: 6| Step: 5
Training loss: 6.057418109058448
Validation loss: 5.548273016037505

Epoch: 6| Step: 6
Training loss: 6.044336540218933
Validation loss: 5.531086087716686

Epoch: 6| Step: 7
Training loss: 5.339933761585906
Validation loss: 5.509121844266541

Epoch: 6| Step: 8
Training loss: 5.959331651118886
Validation loss: 5.485332235209779

Epoch: 6| Step: 9
Training loss: 4.8380295968760905
Validation loss: 5.462133826837373

Epoch: 6| Step: 10
Training loss: 5.505065492661392
Validation loss: 5.440881897837203

Epoch: 6| Step: 11
Training loss: 5.721940948256285
Validation loss: 5.415027732367167

Epoch: 6| Step: 12
Training loss: 4.554737123510228
Validation loss: 5.387571832070304

Epoch: 6| Step: 13
Training loss: 4.0478938525007395
Validation loss: 5.36015956166698

Epoch: 3| Step: 0
Training loss: 5.1710385109982075
Validation loss: 5.331619951083855

Epoch: 6| Step: 1
Training loss: 5.292484770884922
Validation loss: 5.305249880539329

Epoch: 6| Step: 2
Training loss: 6.028882130110816
Validation loss: 5.268723237620933

Epoch: 6| Step: 3
Training loss: 5.319073010328866
Validation loss: 5.233733119799197

Epoch: 6| Step: 4
Training loss: 5.824767262798702
Validation loss: 5.202100223284175

Epoch: 6| Step: 5
Training loss: 5.050771620314196
Validation loss: 5.153128555756209

Epoch: 6| Step: 6
Training loss: 4.933059433902856
Validation loss: 5.1129171709573304

Epoch: 6| Step: 7
Training loss: 4.9274758094569275
Validation loss: 5.067755745655838

Epoch: 6| Step: 8
Training loss: 4.493089880493638
Validation loss: 5.023339586505065

Epoch: 6| Step: 9
Training loss: 5.4293467462769955
Validation loss: 4.971340184086325

Epoch: 6| Step: 10
Training loss: 4.218221899816764
Validation loss: 4.927173293773024

Epoch: 6| Step: 11
Training loss: 5.557237171405234
Validation loss: 4.871983858515033

Epoch: 6| Step: 12
Training loss: 4.821662602471807
Validation loss: 4.809864395884279

Epoch: 6| Step: 13
Training loss: 4.989414262661324
Validation loss: 4.748388318142593

Epoch: 4| Step: 0
Training loss: 5.392060285033137
Validation loss: 4.679390941939354

Epoch: 6| Step: 1
Training loss: 4.3644600473743544
Validation loss: 4.610589715416612

Epoch: 6| Step: 2
Training loss: 3.597278223047763
Validation loss: 4.541423347791389

Epoch: 6| Step: 3
Training loss: 3.91317952260502
Validation loss: 4.455776848269434

Epoch: 6| Step: 4
Training loss: 4.520375429276472
Validation loss: 4.382865937168433

Epoch: 6| Step: 5
Training loss: 3.195186248747414
Validation loss: 4.315278176586399

Epoch: 6| Step: 6
Training loss: 4.0874520115266435
Validation loss: 4.237032161006873

Epoch: 6| Step: 7
Training loss: 4.356038885049857
Validation loss: 4.142672530337594

Epoch: 6| Step: 8
Training loss: 4.8326833002856056
Validation loss: 4.058291480588154

Epoch: 6| Step: 9
Training loss: 4.962327753339896
Validation loss: 3.9458416171660002

Epoch: 6| Step: 10
Training loss: 4.420358997800246
Validation loss: 3.8393866938663845

Epoch: 6| Step: 11
Training loss: 3.796907652412324
Validation loss: 3.75768666311147

Epoch: 6| Step: 12
Training loss: 3.8983356103214977
Validation loss: 3.6354794792862637

Epoch: 6| Step: 13
Training loss: 3.200407634044115
Validation loss: 3.5245170884732135

Epoch: 5| Step: 0
Training loss: 4.605957005368453
Validation loss: 3.4135961381378275

Epoch: 6| Step: 1
Training loss: 3.450177760313052
Validation loss: 3.329125983634577

Epoch: 6| Step: 2
Training loss: 2.720238289212483
Validation loss: 3.183892571090616

Epoch: 6| Step: 3
Training loss: 3.6066141509947074
Validation loss: 3.1124530170780846

Epoch: 6| Step: 4
Training loss: 2.959902459161285
Validation loss: 2.9959793964232673

Epoch: 6| Step: 5
Training loss: 3.1241054017361876
Validation loss: 2.889528702428266

Epoch: 6| Step: 6
Training loss: 2.7462119976430324
Validation loss: 2.83331293678422

Epoch: 6| Step: 7
Training loss: 2.2680785475489076
Validation loss: 2.759824780520626

Epoch: 6| Step: 8
Training loss: 2.5721253839842797
Validation loss: 2.693714925208685

Epoch: 6| Step: 9
Training loss: 2.573573307977296
Validation loss: 2.6672048671330555

Epoch: 6| Step: 10
Training loss: 2.7118539278082516
Validation loss: 2.6242273571118933

Epoch: 6| Step: 11
Training loss: 2.0990935503724772
Validation loss: 2.602886790794198

Epoch: 6| Step: 12
Training loss: 2.569713487944859
Validation loss: 2.6537207660571185

Epoch: 6| Step: 13
Training loss: 2.72429731215808
Validation loss: 2.6620432117101833

Epoch: 6| Step: 0
Training loss: 3.2289750729399382
Validation loss: 2.6545598954967478

Epoch: 6| Step: 1
Training loss: 2.7534019062502533
Validation loss: 2.6912505645089886

Epoch: 6| Step: 2
Training loss: 3.0109818047993926
Validation loss: 2.730422893206407

Epoch: 6| Step: 3
Training loss: 2.1713228690262527
Validation loss: 2.7272680730490997

Epoch: 6| Step: 4
Training loss: 2.42193583750453
Validation loss: 2.7025171820335205

Epoch: 6| Step: 5
Training loss: 2.5430400973154073
Validation loss: 2.7297098817946748

Epoch: 6| Step: 6
Training loss: 2.600576219529815
Validation loss: 2.69511557334175

Epoch: 6| Step: 7
Training loss: 2.8333161484440264
Validation loss: 2.697059794754978

Epoch: 6| Step: 8
Training loss: 2.13584142662814
Validation loss: 2.6988821081962158

Epoch: 6| Step: 9
Training loss: 2.3630572756728414
Validation loss: 2.7039903200209516

Epoch: 6| Step: 10
Training loss: 2.6962024933189364
Validation loss: 2.7135520734727767

Epoch: 6| Step: 11
Training loss: 3.0742938215500324
Validation loss: 2.6831148878076254

Epoch: 6| Step: 12
Training loss: 2.5326022080247417
Validation loss: 2.710833984509388

Epoch: 6| Step: 13
Training loss: 2.199853293989325
Validation loss: 2.6569755759982465

Epoch: 7| Step: 0
Training loss: 2.7865323255940906
Validation loss: 2.6567139463473426

Epoch: 6| Step: 1
Training loss: 2.306309843449952
Validation loss: 2.677485815486147

Epoch: 6| Step: 2
Training loss: 2.4895679255265453
Validation loss: 2.6259628376874584

Epoch: 6| Step: 3
Training loss: 2.279818778281335
Validation loss: 2.632990135893966

Epoch: 6| Step: 4
Training loss: 2.116512176803069
Validation loss: 2.5969537076563736

Epoch: 6| Step: 5
Training loss: 2.9610579574359774
Validation loss: 2.6326887816689015

Epoch: 6| Step: 6
Training loss: 2.524581980331603
Validation loss: 2.602646030234123

Epoch: 6| Step: 7
Training loss: 3.5706421013410377
Validation loss: 2.6016695689792644

Epoch: 6| Step: 8
Training loss: 2.4181685110965865
Validation loss: 2.638613760699059

Epoch: 6| Step: 9
Training loss: 2.6452064272078095
Validation loss: 2.6446514393453264

Epoch: 6| Step: 10
Training loss: 2.9054326374448918
Validation loss: 2.65235525586606

Epoch: 6| Step: 11
Training loss: 1.7884540439382424
Validation loss: 2.6197521492396256

Epoch: 6| Step: 12
Training loss: 2.2723468904356157
Validation loss: 2.6115853090968852

Epoch: 6| Step: 13
Training loss: 2.342585159756821
Validation loss: 2.63328337491205

Epoch: 8| Step: 0
Training loss: 2.2344129865925235
Validation loss: 2.6007059881081176

Epoch: 6| Step: 1
Training loss: 2.1909328228094354
Validation loss: 2.604250827700921

Epoch: 6| Step: 2
Training loss: 2.5091452221401163
Validation loss: 2.615100054701901

Epoch: 6| Step: 3
Training loss: 2.2770433702187534
Validation loss: 2.6142968455248146

Epoch: 6| Step: 4
Training loss: 2.140849637684323
Validation loss: 2.625349021596743

Epoch: 6| Step: 5
Training loss: 3.859930083476722
Validation loss: 2.6260307195773978

Epoch: 6| Step: 6
Training loss: 1.9187183663310947
Validation loss: 2.610583042851473

Epoch: 6| Step: 7
Training loss: 2.3122612082421834
Validation loss: 2.6443072045222786

Epoch: 6| Step: 8
Training loss: 2.9155390785043735
Validation loss: 2.645502044682712

Epoch: 6| Step: 9
Training loss: 2.5356808723535535
Validation loss: 2.630489331837034

Epoch: 6| Step: 10
Training loss: 2.4948446524348395
Validation loss: 2.6010620430079596

Epoch: 6| Step: 11
Training loss: 2.838927487158443
Validation loss: 2.6065046928485964

Epoch: 6| Step: 12
Training loss: 3.2742126566730763
Validation loss: 2.6141603489917915

Epoch: 6| Step: 13
Training loss: 1.9015379654140836
Validation loss: 2.6098127321558553

Epoch: 9| Step: 0
Training loss: 2.533574108761653
Validation loss: 2.5868147776622084

Epoch: 6| Step: 1
Training loss: 3.210717557999092
Validation loss: 2.6082764405047176

Epoch: 6| Step: 2
Training loss: 2.4934903270165885
Validation loss: 2.5999604142672315

Epoch: 6| Step: 3
Training loss: 2.8047417340573775
Validation loss: 2.6229635392521287

Epoch: 6| Step: 4
Training loss: 2.860274710099771
Validation loss: 2.629494951149387

Epoch: 6| Step: 5
Training loss: 3.0777119780605626
Validation loss: 2.6075530096598687

Epoch: 6| Step: 6
Training loss: 2.5483920020199937
Validation loss: 2.626795049021411

Epoch: 6| Step: 7
Training loss: 2.3465890600997823
Validation loss: 2.6149315671798234

Epoch: 6| Step: 8
Training loss: 2.210300313300341
Validation loss: 2.5872206716833404

Epoch: 6| Step: 9
Training loss: 1.326893538472658
Validation loss: 2.605108995970189

Epoch: 6| Step: 10
Training loss: 2.5397414957499858
Validation loss: 2.6045099769636026

Epoch: 6| Step: 11
Training loss: 2.2391909469955737
Validation loss: 2.5996438436613802

Epoch: 6| Step: 12
Training loss: 2.587358527992259
Validation loss: 2.636807603634053

Epoch: 6| Step: 13
Training loss: 2.404670494173136
Validation loss: 2.619990973857445

Epoch: 10| Step: 0
Training loss: 2.6712038859277127
Validation loss: 2.630684918323715

Epoch: 6| Step: 1
Training loss: 3.0959917673992146
Validation loss: 2.6070145763930586

Epoch: 6| Step: 2
Training loss: 2.261475650458069
Validation loss: 2.639276871407379

Epoch: 6| Step: 3
Training loss: 2.395164816646522
Validation loss: 2.632924606698434

Epoch: 6| Step: 4
Training loss: 1.9362652443469786
Validation loss: 2.621718853744122

Epoch: 6| Step: 5
Training loss: 2.5170277540687147
Validation loss: 2.633886961342727

Epoch: 6| Step: 6
Training loss: 2.7035402188548665
Validation loss: 2.628089751537538

Epoch: 6| Step: 7
Training loss: 2.0401269465572107
Validation loss: 2.5904951623668855

Epoch: 6| Step: 8
Training loss: 1.9449650710825948
Validation loss: 2.6076078389081903

Epoch: 6| Step: 9
Training loss: 3.0217884702236946
Validation loss: 2.6158328369891994

Epoch: 6| Step: 10
Training loss: 2.6160595641106594
Validation loss: 2.605998811273116

Epoch: 6| Step: 11
Training loss: 2.955382760652652
Validation loss: 2.609228666850826

Epoch: 6| Step: 12
Training loss: 2.714432543891882
Validation loss: 2.585111042271851

Epoch: 6| Step: 13
Training loss: 2.6858931772459633
Validation loss: 2.6017337166134995

Epoch: 11| Step: 0
Training loss: 2.334927037342785
Validation loss: 2.609541425137502

Epoch: 6| Step: 1
Training loss: 2.773548908413782
Validation loss: 2.620848104579845

Epoch: 6| Step: 2
Training loss: 2.0658146204170778
Validation loss: 2.608973474123299

Epoch: 6| Step: 3
Training loss: 2.4310159761821057
Validation loss: 2.6157187672545135

Epoch: 6| Step: 4
Training loss: 3.219207138635293
Validation loss: 2.607612517170327

Epoch: 6| Step: 5
Training loss: 1.7536990716653644
Validation loss: 2.5727850588190706

Epoch: 6| Step: 6
Training loss: 2.12239543392123
Validation loss: 2.6195887846657655

Epoch: 6| Step: 7
Training loss: 2.7434054981750315
Validation loss: 2.5923405383468014

Epoch: 6| Step: 8
Training loss: 2.6289448841538037
Validation loss: 2.58381413528281

Epoch: 6| Step: 9
Training loss: 2.191825296247961
Validation loss: 2.588814002792649

Epoch: 6| Step: 10
Training loss: 1.9136570092250855
Validation loss: 2.6349881292434056

Epoch: 6| Step: 11
Training loss: 2.809524997190605
Validation loss: 2.622224369649852

Epoch: 6| Step: 12
Training loss: 2.785985879269406
Validation loss: 2.6007064770390627

Epoch: 6| Step: 13
Training loss: 3.2759065261565743
Validation loss: 2.6572071819166445

Epoch: 12| Step: 0
Training loss: 3.680892455478539
Validation loss: 2.5976615121735547

Epoch: 6| Step: 1
Training loss: 2.4988252740831496
Validation loss: 2.6089433629029526

Epoch: 6| Step: 2
Training loss: 3.117039421216544
Validation loss: 2.6180766099464905

Epoch: 6| Step: 3
Training loss: 1.7779484317583065
Validation loss: 2.6296732040261475

Epoch: 6| Step: 4
Training loss: 2.6933594635208924
Validation loss: 2.6209589416128987

Epoch: 6| Step: 5
Training loss: 1.9313699283830768
Validation loss: 2.607365639755234

Epoch: 6| Step: 6
Training loss: 2.308262008868775
Validation loss: 2.600787134107536

Epoch: 6| Step: 7
Training loss: 2.309194728644556
Validation loss: 2.617723089425246

Epoch: 6| Step: 8
Training loss: 2.649612841125138
Validation loss: 2.6047930587190833

Epoch: 6| Step: 9
Training loss: 2.3344209270734146
Validation loss: 2.5861213211539105

Epoch: 6| Step: 10
Training loss: 2.2973109240347624
Validation loss: 2.6120449728518853

Epoch: 6| Step: 11
Training loss: 2.4202678639363713
Validation loss: 2.6174289724823074

Epoch: 6| Step: 12
Training loss: 2.4736056320679025
Validation loss: 2.6162259741134237

Epoch: 6| Step: 13
Training loss: 2.5310240279692073
Validation loss: 2.603617653513326

Epoch: 13| Step: 0
Training loss: 2.487816687892939
Validation loss: 2.6112325608526517

Epoch: 6| Step: 1
Training loss: 2.805025213199659
Validation loss: 2.594332212191621

Epoch: 6| Step: 2
Training loss: 2.31356158247243
Validation loss: 2.612212490463176

Epoch: 6| Step: 3
Training loss: 3.107352207441066
Validation loss: 2.588257531601358

Epoch: 6| Step: 4
Training loss: 2.4744970330779195
Validation loss: 2.6014259921164595

Epoch: 6| Step: 5
Training loss: 2.3072517225081546
Validation loss: 2.5630716601110275

Epoch: 6| Step: 6
Training loss: 2.071070233718399
Validation loss: 2.5875816381478667

Epoch: 6| Step: 7
Training loss: 2.264797506817598
Validation loss: 2.5936860838831923

Epoch: 6| Step: 8
Training loss: 3.1707918168573617
Validation loss: 2.6020925629092972

Epoch: 6| Step: 9
Training loss: 2.7018317508170084
Validation loss: 2.582571491582552

Epoch: 6| Step: 10
Training loss: 2.1016022065109325
Validation loss: 2.617165651752128

Epoch: 6| Step: 11
Training loss: 2.3773855977256693
Validation loss: 2.6126942947148835

Epoch: 6| Step: 12
Training loss: 2.720456256606621
Validation loss: 2.6119222485827565

Epoch: 6| Step: 13
Training loss: 2.2794636041873844
Validation loss: 2.5936904655272963

Epoch: 14| Step: 0
Training loss: 2.5853658084544615
Validation loss: 2.589624241214

Epoch: 6| Step: 1
Training loss: 2.7509643424415753
Validation loss: 2.597142295378215

Epoch: 6| Step: 2
Training loss: 2.478625380037623
Validation loss: 2.62182672128039

Epoch: 6| Step: 3
Training loss: 2.12680291380167
Validation loss: 2.6116282619418882

Epoch: 6| Step: 4
Training loss: 2.0719225111357034
Validation loss: 2.5948754898267574

Epoch: 6| Step: 5
Training loss: 1.9502456803711046
Validation loss: 2.581171320592807

Epoch: 6| Step: 6
Training loss: 3.0997919751172764
Validation loss: 2.589884976787208

Epoch: 6| Step: 7
Training loss: 2.2952607379475594
Validation loss: 2.580897449250861

Epoch: 6| Step: 8
Training loss: 2.99077873831346
Validation loss: 2.5974200989883913

Epoch: 6| Step: 9
Training loss: 2.586011257445105
Validation loss: 2.5669784024247293

Epoch: 6| Step: 10
Training loss: 2.4357087816448693
Validation loss: 2.5857005322877664

Epoch: 6| Step: 11
Training loss: 2.127409186391747
Validation loss: 2.625834332434358

Epoch: 6| Step: 12
Training loss: 2.5681848502966
Validation loss: 2.6044763660653603

Epoch: 6| Step: 13
Training loss: 2.9659881594544384
Validation loss: 2.5807623272461315

Epoch: 15| Step: 0
Training loss: 2.6515927944127453
Validation loss: 2.5797240413524585

Epoch: 6| Step: 1
Training loss: 2.017933196649214
Validation loss: 2.612921552702684

Epoch: 6| Step: 2
Training loss: 2.5911821270162876
Validation loss: 2.577201076604561

Epoch: 6| Step: 3
Training loss: 1.6404990738270524
Validation loss: 2.5831907807262926

Epoch: 6| Step: 4
Training loss: 1.8329237856173497
Validation loss: 2.5775029905951214

Epoch: 6| Step: 5
Training loss: 2.224353430595979
Validation loss: 2.587662090071261

Epoch: 6| Step: 6
Training loss: 2.835119544575017
Validation loss: 2.578452195491792

Epoch: 6| Step: 7
Training loss: 2.4453920589094387
Validation loss: 2.596008328763888

Epoch: 6| Step: 8
Training loss: 2.7813532949403665
Validation loss: 2.581770860216547

Epoch: 6| Step: 9
Training loss: 3.169597691419474
Validation loss: 2.593919939962037

Epoch: 6| Step: 10
Training loss: 3.1417686695434477
Validation loss: 2.5802567887225685

Epoch: 6| Step: 11
Training loss: 2.710976899929825
Validation loss: 2.60834583004242

Epoch: 6| Step: 12
Training loss: 1.8743073137609656
Validation loss: 2.5931997826305815

Epoch: 6| Step: 13
Training loss: 3.0415146846338357
Validation loss: 2.6065071777990343

Epoch: 16| Step: 0
Training loss: 1.8444726465295647
Validation loss: 2.5919930355808507

Epoch: 6| Step: 1
Training loss: 3.075839825828919
Validation loss: 2.599517897083806

Epoch: 6| Step: 2
Training loss: 2.74743879866187
Validation loss: 2.5574611496297335

Epoch: 6| Step: 3
Training loss: 2.810395279773035
Validation loss: 2.5736526229492362

Epoch: 6| Step: 4
Training loss: 2.2221561130650835
Validation loss: 2.5881653684249724

Epoch: 6| Step: 5
Training loss: 3.098222370537629
Validation loss: 2.579590174939545

Epoch: 6| Step: 6
Training loss: 1.824415175912638
Validation loss: 2.585322357802024

Epoch: 6| Step: 7
Training loss: 2.6982908738086326
Validation loss: 2.591319680572076

Epoch: 6| Step: 8
Training loss: 2.6336458511653293
Validation loss: 2.605479227528244

Epoch: 6| Step: 9
Training loss: 3.060570400904714
Validation loss: 2.6005045560183104

Epoch: 6| Step: 10
Training loss: 2.6220768592795367
Validation loss: 2.562270425576698

Epoch: 6| Step: 11
Training loss: 2.080970594191951
Validation loss: 2.5800907539946087

Epoch: 6| Step: 12
Training loss: 2.266073458781348
Validation loss: 2.581270399159268

Epoch: 6| Step: 13
Training loss: 2.1504477234344397
Validation loss: 2.585572646295447

Epoch: 17| Step: 0
Training loss: 2.682244773874588
Validation loss: 2.5817656733928374

Epoch: 6| Step: 1
Training loss: 1.6775518280300399
Validation loss: 2.580970072865784

Epoch: 6| Step: 2
Training loss: 1.9740106446540555
Validation loss: 2.584210713402851

Epoch: 6| Step: 3
Training loss: 2.8983636317132784
Validation loss: 2.5951223764247815

Epoch: 6| Step: 4
Training loss: 2.4019557732632477
Validation loss: 2.587734139947472

Epoch: 6| Step: 5
Training loss: 2.4832290789676192
Validation loss: 2.60781051273015

Epoch: 6| Step: 6
Training loss: 2.3074853498628203
Validation loss: 2.5911115532273614

Epoch: 6| Step: 7
Training loss: 2.6572830883940903
Validation loss: 2.5920823645966786

Epoch: 6| Step: 8
Training loss: 2.591241749788539
Validation loss: 2.6094132076062597

Epoch: 6| Step: 9
Training loss: 2.3988537753320447
Validation loss: 2.5978578417577154

Epoch: 6| Step: 10
Training loss: 2.8917107270005245
Validation loss: 2.60137671493648

Epoch: 6| Step: 11
Training loss: 2.826262139788221
Validation loss: 2.580501971106518

Epoch: 6| Step: 12
Training loss: 1.943529345876486
Validation loss: 2.6024251582523967

Epoch: 6| Step: 13
Training loss: 3.1771118829830636
Validation loss: 2.5711239786997453

Epoch: 18| Step: 0
Training loss: 1.766074874413917
Validation loss: 2.5685803143097887

Epoch: 6| Step: 1
Training loss: 3.111591871520838
Validation loss: 2.5935542940509624

Epoch: 6| Step: 2
Training loss: 3.1251229834198564
Validation loss: 2.5779025665813404

Epoch: 6| Step: 3
Training loss: 2.543752804316444
Validation loss: 2.564281805571575

Epoch: 6| Step: 4
Training loss: 2.8136529042977276
Validation loss: 2.585318784272287

Epoch: 6| Step: 5
Training loss: 2.749171912620082
Validation loss: 2.58389476602486

Epoch: 6| Step: 6
Training loss: 2.4885309354588783
Validation loss: 2.574796126606384

Epoch: 6| Step: 7
Training loss: 2.6262490162037344
Validation loss: 2.5822003915609515

Epoch: 6| Step: 8
Training loss: 2.4560779851032195
Validation loss: 2.5801630460984253

Epoch: 6| Step: 9
Training loss: 2.5089542249910792
Validation loss: 2.5817464266458305

Epoch: 6| Step: 10
Training loss: 2.3265941118151257
Validation loss: 2.579069284460747

Epoch: 6| Step: 11
Training loss: 2.3290272442938673
Validation loss: 2.5954676000529657

Epoch: 6| Step: 12
Training loss: 2.055145560722363
Validation loss: 2.5782805424788626

Epoch: 6| Step: 13
Training loss: 2.3427910432396515
Validation loss: 2.6051329434933903

Epoch: 19| Step: 0
Training loss: 2.624554187519766
Validation loss: 2.5674752264366023

Epoch: 6| Step: 1
Training loss: 2.565582003680382
Validation loss: 2.5916766416923993

Epoch: 6| Step: 2
Training loss: 2.4594735771693976
Validation loss: 2.5620208540382126

Epoch: 6| Step: 3
Training loss: 2.088245272513808
Validation loss: 2.610003336713078

Epoch: 6| Step: 4
Training loss: 2.5175612680656565
Validation loss: 2.6260590006583944

Epoch: 6| Step: 5
Training loss: 2.1486376859860874
Validation loss: 2.628692421759484

Epoch: 6| Step: 6
Training loss: 2.3152630768952314
Validation loss: 2.5700780419549307

Epoch: 6| Step: 7
Training loss: 2.7595479977942268
Validation loss: 2.6072012628195624

Epoch: 6| Step: 8
Training loss: 2.407971843618235
Validation loss: 2.567381744558664

Epoch: 6| Step: 9
Training loss: 1.9162312579747014
Validation loss: 2.605341811474125

Epoch: 6| Step: 10
Training loss: 2.0721028198373226
Validation loss: 2.60330919008705

Epoch: 6| Step: 11
Training loss: 3.086000234231798
Validation loss: 2.6031918697614347

Epoch: 6| Step: 12
Training loss: 2.5183776580255754
Validation loss: 2.584791469267016

Epoch: 6| Step: 13
Training loss: 3.4693839378839675
Validation loss: 2.6007632993562018

Epoch: 20| Step: 0
Training loss: 2.8026624078848315
Validation loss: 2.588374577021941

Epoch: 6| Step: 1
Training loss: 2.932771488770763
Validation loss: 2.5931913011591434

Epoch: 6| Step: 2
Training loss: 1.638381659505495
Validation loss: 2.575285795085908

Epoch: 6| Step: 3
Training loss: 2.4739313920545114
Validation loss: 2.555912435762955

Epoch: 6| Step: 4
Training loss: 2.586120230220128
Validation loss: 2.6032626960913956

Epoch: 6| Step: 5
Training loss: 2.709268633416616
Validation loss: 2.5691352320243226

Epoch: 6| Step: 6
Training loss: 3.1242482616330896
Validation loss: 2.578939551941881

Epoch: 6| Step: 7
Training loss: 2.307177320507234
Validation loss: 2.5990045628739398

Epoch: 6| Step: 8
Training loss: 2.473415746249786
Validation loss: 2.587965708669036

Epoch: 6| Step: 9
Training loss: 2.333089770366094
Validation loss: 2.5827820148580507

Epoch: 6| Step: 10
Training loss: 2.841625887521323
Validation loss: 2.602185813304968

Epoch: 6| Step: 11
Training loss: 2.599426675820795
Validation loss: 2.577302790070882

Epoch: 6| Step: 12
Training loss: 2.0851768221077958
Validation loss: 2.5758744714768205

Epoch: 6| Step: 13
Training loss: 2.014159623579475
Validation loss: 2.554369378770916

Epoch: 21| Step: 0
Training loss: 3.523883529141269
Validation loss: 2.5705693202624307

Epoch: 6| Step: 1
Training loss: 2.480182300758377
Validation loss: 2.561883790273384

Epoch: 6| Step: 2
Training loss: 2.0786581861230404
Validation loss: 2.5931648605493707

Epoch: 6| Step: 3
Training loss: 2.3944509968836387
Validation loss: 2.5786173494867075

Epoch: 6| Step: 4
Training loss: 2.093200839318374
Validation loss: 2.5920401916282225

Epoch: 6| Step: 5
Training loss: 2.984967717135123
Validation loss: 2.590704604621881

Epoch: 6| Step: 6
Training loss: 2.7504108295476013
Validation loss: 2.5865275928464224

Epoch: 6| Step: 7
Training loss: 2.411885190113345
Validation loss: 2.6021585173138324

Epoch: 6| Step: 8
Training loss: 1.7542183307400185
Validation loss: 2.5682742879526064

Epoch: 6| Step: 9
Training loss: 2.974408348940192
Validation loss: 2.612166504814912

Epoch: 6| Step: 10
Training loss: 2.41249067868028
Validation loss: 2.5779375721012023

Epoch: 6| Step: 11
Training loss: 2.5488422495717353
Validation loss: 2.5951247804025876

Epoch: 6| Step: 12
Training loss: 1.9528016089692573
Validation loss: 2.573639560928099

Epoch: 6| Step: 13
Training loss: 2.1996185318802475
Validation loss: 2.577264152686089

Epoch: 22| Step: 0
Training loss: 2.7244474848297617
Validation loss: 2.5873108873043216

Epoch: 6| Step: 1
Training loss: 1.8514808604595268
Validation loss: 2.5879839188175864

Epoch: 6| Step: 2
Training loss: 2.4156559990279347
Validation loss: 2.5714189105697582

Epoch: 6| Step: 3
Training loss: 2.6099151235058002
Validation loss: 2.580736937192015

Epoch: 6| Step: 4
Training loss: 3.2055672615788082
Validation loss: 2.5598992741905415

Epoch: 6| Step: 5
Training loss: 1.6992002990422461
Validation loss: 2.585844408954681

Epoch: 6| Step: 6
Training loss: 2.2152089620150615
Validation loss: 2.611664679254077

Epoch: 6| Step: 7
Training loss: 3.0292427259828356
Validation loss: 2.5897882838228776

Epoch: 6| Step: 8
Training loss: 2.8980363840750605
Validation loss: 2.5966800547668036

Epoch: 6| Step: 9
Training loss: 2.3267927005956954
Validation loss: 2.6089007466314094

Epoch: 6| Step: 10
Training loss: 2.1003600583894966
Validation loss: 2.5889797390080798

Epoch: 6| Step: 11
Training loss: 2.717277917569536
Validation loss: 2.6096038413446165

Epoch: 6| Step: 12
Training loss: 2.224526099839237
Validation loss: 2.5937056480200615

Epoch: 6| Step: 13
Training loss: 2.687412881548097
Validation loss: 2.5818786114289054

Epoch: 23| Step: 0
Training loss: 2.2315967066052496
Validation loss: 2.5780597254649025

Epoch: 6| Step: 1
Training loss: 2.750326657401282
Validation loss: 2.566585408716236

Epoch: 6| Step: 2
Training loss: 2.7088557008576237
Validation loss: 2.575228302596881

Epoch: 6| Step: 3
Training loss: 2.287576863816259
Validation loss: 2.5781242447668955

Epoch: 6| Step: 4
Training loss: 2.765973343975191
Validation loss: 2.575823733598717

Epoch: 6| Step: 5
Training loss: 2.093630886959905
Validation loss: 2.598320316341632

Epoch: 6| Step: 6
Training loss: 2.494169684638855
Validation loss: 2.5789951512913745

Epoch: 6| Step: 7
Training loss: 2.8742717981692296
Validation loss: 2.5570322955353073

Epoch: 6| Step: 8
Training loss: 2.610092247249904
Validation loss: 2.6003480354310415

Epoch: 6| Step: 9
Training loss: 2.0422021072904326
Validation loss: 2.5691366859078326

Epoch: 6| Step: 10
Training loss: 2.589485615497536
Validation loss: 2.549613728282593

Epoch: 6| Step: 11
Training loss: 2.965585728858628
Validation loss: 2.583229690954315

Epoch: 6| Step: 12
Training loss: 2.3065513186564273
Validation loss: 2.5683555071164634

Epoch: 6| Step: 13
Training loss: 2.410394245681959
Validation loss: 2.571794200692532

Epoch: 24| Step: 0
Training loss: 2.429194654910914
Validation loss: 2.5645497040721943

Epoch: 6| Step: 1
Training loss: 2.6569813338640897
Validation loss: 2.585524434792748

Epoch: 6| Step: 2
Training loss: 2.337791396148929
Validation loss: 2.5749331743402215

Epoch: 6| Step: 3
Training loss: 2.6311848756971936
Validation loss: 2.5725729412850797

Epoch: 6| Step: 4
Training loss: 2.234951985161328
Validation loss: 2.579929837497586

Epoch: 6| Step: 5
Training loss: 1.6782935457460202
Validation loss: 2.596784417645579

Epoch: 6| Step: 6
Training loss: 3.0783948441166835
Validation loss: 2.5951630982832232

Epoch: 6| Step: 7
Training loss: 2.920822851694612
Validation loss: 2.5894548786821274

Epoch: 6| Step: 8
Training loss: 2.0445499172969215
Validation loss: 2.607586352319567

Epoch: 6| Step: 9
Training loss: 2.520329785036434
Validation loss: 2.5855773490588727

Epoch: 6| Step: 10
Training loss: 2.5724994666096217
Validation loss: 2.588396315200369

Epoch: 6| Step: 11
Training loss: 2.3401847680007166
Validation loss: 2.577518199063372

Epoch: 6| Step: 12
Training loss: 2.7509273352668653
Validation loss: 2.565505877698045

Epoch: 6| Step: 13
Training loss: 2.679546474827503
Validation loss: 2.585641427200382

Epoch: 25| Step: 0
Training loss: 2.507910040268703
Validation loss: 2.586026177705783

Epoch: 6| Step: 1
Training loss: 2.676549737101521
Validation loss: 2.5760944423264687

Epoch: 6| Step: 2
Training loss: 2.033205470249608
Validation loss: 2.5562901967066343

Epoch: 6| Step: 3
Training loss: 3.159336658097972
Validation loss: 2.558504028300243

Epoch: 6| Step: 4
Training loss: 2.6608717260110746
Validation loss: 2.5984238181305477

Epoch: 6| Step: 5
Training loss: 2.1979455328276676
Validation loss: 2.57633939617245

Epoch: 6| Step: 6
Training loss: 2.0959002712271237
Validation loss: 2.56620229590948

Epoch: 6| Step: 7
Training loss: 2.8780819503430797
Validation loss: 2.57910501368411

Epoch: 6| Step: 8
Training loss: 2.253271056373647
Validation loss: 2.5697668050906834

Epoch: 6| Step: 9
Training loss: 2.8524614981109853
Validation loss: 2.553747192670064

Epoch: 6| Step: 10
Training loss: 2.6555543774061725
Validation loss: 2.5488342830734596

Epoch: 6| Step: 11
Training loss: 2.084775679708632
Validation loss: 2.555546731749334

Epoch: 6| Step: 12
Training loss: 2.528875862342047
Validation loss: 2.537669350308198

Epoch: 6| Step: 13
Training loss: 2.3559057738109312
Validation loss: 2.567553367864884

Epoch: 26| Step: 0
Training loss: 2.5626121124305246
Validation loss: 2.564118564201221

Epoch: 6| Step: 1
Training loss: 2.201031278437376
Validation loss: 2.573719267560544

Epoch: 6| Step: 2
Training loss: 2.3294196913239222
Validation loss: 2.5947059646801542

Epoch: 6| Step: 3
Training loss: 2.3255771289830665
Validation loss: 2.592784073610874

Epoch: 6| Step: 4
Training loss: 3.1706718079525538
Validation loss: 2.575398461829313

Epoch: 6| Step: 5
Training loss: 2.683155451578914
Validation loss: 2.5996022366436007

Epoch: 6| Step: 6
Training loss: 2.425285546706355
Validation loss: 2.5735932180097514

Epoch: 6| Step: 7
Training loss: 1.5927464186425002
Validation loss: 2.594984396616258

Epoch: 6| Step: 8
Training loss: 2.7272924632023035
Validation loss: 2.6024166686745263

Epoch: 6| Step: 9
Training loss: 2.0785517433668845
Validation loss: 2.597861298616296

Epoch: 6| Step: 10
Training loss: 2.81873689635756
Validation loss: 2.5882860104798886

Epoch: 6| Step: 11
Training loss: 2.4447932560420766
Validation loss: 2.6224232394097395

Epoch: 6| Step: 12
Training loss: 2.879469175957702
Validation loss: 2.5994098910654317

Epoch: 6| Step: 13
Training loss: 2.515862874222697
Validation loss: 2.584779270630544

Epoch: 27| Step: 0
Training loss: 2.2829226279930803
Validation loss: 2.564228575831793

Epoch: 6| Step: 1
Training loss: 2.412504415557457
Validation loss: 2.5693457736295

Epoch: 6| Step: 2
Training loss: 2.1762596166092587
Validation loss: 2.575172907384995

Epoch: 6| Step: 3
Training loss: 2.4288489559823523
Validation loss: 2.591843881302963

Epoch: 6| Step: 4
Training loss: 2.4583805424526957
Validation loss: 2.544452060790326

Epoch: 6| Step: 5
Training loss: 2.8458782239047773
Validation loss: 2.5506894930994495

Epoch: 6| Step: 6
Training loss: 2.7552677333224076
Validation loss: 2.5658287819250742

Epoch: 6| Step: 7
Training loss: 2.292788132892519
Validation loss: 2.5658785869311718

Epoch: 6| Step: 8
Training loss: 2.819976448474773
Validation loss: 2.5789994269295575

Epoch: 6| Step: 9
Training loss: 1.6754833748088533
Validation loss: 2.582600756314084

Epoch: 6| Step: 10
Training loss: 2.7076115942559267
Validation loss: 2.5506782452522745

Epoch: 6| Step: 11
Training loss: 2.3045749442854153
Validation loss: 2.5568646438949627

Epoch: 6| Step: 12
Training loss: 2.720246527943842
Validation loss: 2.545139852826912

Epoch: 6| Step: 13
Training loss: 3.026758070866528
Validation loss: 2.570183036658891

Epoch: 28| Step: 0
Training loss: 2.445192961772198
Validation loss: 2.5621923866788343

Epoch: 6| Step: 1
Training loss: 2.4183039764087666
Validation loss: 2.5676781973060128

Epoch: 6| Step: 2
Training loss: 1.9630147562584888
Validation loss: 2.550628361542791

Epoch: 6| Step: 3
Training loss: 2.6062198225510933
Validation loss: 2.566285972931487

Epoch: 6| Step: 4
Training loss: 2.700101009881299
Validation loss: 2.5481080578847486

Epoch: 6| Step: 5
Training loss: 3.1513207346185066
Validation loss: 2.571803702953329

Epoch: 6| Step: 6
Training loss: 2.2387535036401474
Validation loss: 2.5760133514719743

Epoch: 6| Step: 7
Training loss: 2.330949951171351
Validation loss: 2.559512203080401

Epoch: 6| Step: 8
Training loss: 2.0129360034697927
Validation loss: 2.5576609689937495

Epoch: 6| Step: 9
Training loss: 2.62145738879112
Validation loss: 2.549162884356397

Epoch: 6| Step: 10
Training loss: 2.6260564585512123
Validation loss: 2.541171202806946

Epoch: 6| Step: 11
Training loss: 1.9271433503023967
Validation loss: 2.548115574414858

Epoch: 6| Step: 12
Training loss: 2.58620476854171
Validation loss: 2.5733523341039075

Epoch: 6| Step: 13
Training loss: 2.8195452293668843
Validation loss: 2.5903693999130666

Epoch: 29| Step: 0
Training loss: 2.680165506775146
Validation loss: 2.5846502167528613

Epoch: 6| Step: 1
Training loss: 1.9663539414236366
Validation loss: 2.591635221084077

Epoch: 6| Step: 2
Training loss: 2.5370996018383742
Validation loss: 2.583192180550945

Epoch: 6| Step: 3
Training loss: 2.7538380282994854
Validation loss: 2.5868224044581067

Epoch: 6| Step: 4
Training loss: 2.7665075413394127
Validation loss: 2.5924320472731

Epoch: 6| Step: 5
Training loss: 2.6299281408551853
Validation loss: 2.5934580290054217

Epoch: 6| Step: 6
Training loss: 2.4663851070373863
Validation loss: 2.610945999615644

Epoch: 6| Step: 7
Training loss: 2.261188451499742
Validation loss: 2.616440319994837

Epoch: 6| Step: 8
Training loss: 3.303766794208934
Validation loss: 2.626221720661107

Epoch: 6| Step: 9
Training loss: 1.8348447753778643
Validation loss: 2.621757593811218

Epoch: 6| Step: 10
Training loss: 2.470839183815457
Validation loss: 2.6006732142461426

Epoch: 6| Step: 11
Training loss: 2.2754719339013296
Validation loss: 2.587765572843392

Epoch: 6| Step: 12
Training loss: 2.233441778178619
Validation loss: 2.573586053812634

Epoch: 6| Step: 13
Training loss: 2.6646554236742324
Validation loss: 2.5974257441001263

Epoch: 30| Step: 0
Training loss: 2.2946950727356255
Validation loss: 2.5858420424499617

Epoch: 6| Step: 1
Training loss: 2.7693630323450615
Validation loss: 2.5681215976356166

Epoch: 6| Step: 2
Training loss: 2.8269063104704215
Validation loss: 2.559700266035049

Epoch: 6| Step: 3
Training loss: 2.3739019164316564
Validation loss: 2.558316669554808

Epoch: 6| Step: 4
Training loss: 2.944029672867052
Validation loss: 2.536292387268315

Epoch: 6| Step: 5
Training loss: 2.6835029508952246
Validation loss: 2.5561432496704275

Epoch: 6| Step: 6
Training loss: 2.7713146413130367
Validation loss: 2.5720264011716867

Epoch: 6| Step: 7
Training loss: 2.6374986187538036
Validation loss: 2.564397574503657

Epoch: 6| Step: 8
Training loss: 2.273363040084871
Validation loss: 2.5480461938165004

Epoch: 6| Step: 9
Training loss: 1.8334299697838372
Validation loss: 2.566765019361317

Epoch: 6| Step: 10
Training loss: 2.636367887535375
Validation loss: 2.573878202550884

Epoch: 6| Step: 11
Training loss: 2.258361960742241
Validation loss: 2.53144668474286

Epoch: 6| Step: 12
Training loss: 2.0306665609655687
Validation loss: 2.5544709435621886

Epoch: 6| Step: 13
Training loss: 2.3389348731072457
Validation loss: 2.564089158264597

Epoch: 31| Step: 0
Training loss: 2.885866775017838
Validation loss: 2.5572914128714523

Epoch: 6| Step: 1
Training loss: 2.3644409360875525
Validation loss: 2.5603672394250854

Epoch: 6| Step: 2
Training loss: 2.992170129630961
Validation loss: 2.576326957008538

Epoch: 6| Step: 3
Training loss: 2.118357092511275
Validation loss: 2.556196150333001

Epoch: 6| Step: 4
Training loss: 1.79075961846891
Validation loss: 2.549747672405989

Epoch: 6| Step: 5
Training loss: 2.633938602308334
Validation loss: 2.5566497173103935

Epoch: 6| Step: 6
Training loss: 2.921553976609816
Validation loss: 2.54438422011252

Epoch: 6| Step: 7
Training loss: 2.3426614903953884
Validation loss: 2.558820796919527

Epoch: 6| Step: 8
Training loss: 2.8691843339825005
Validation loss: 2.56732870291338

Epoch: 6| Step: 9
Training loss: 2.2527904161547414
Validation loss: 2.523639509463138

Epoch: 6| Step: 10
Training loss: 2.205811506143434
Validation loss: 2.5366453353805363

Epoch: 6| Step: 11
Training loss: 2.6904387264480647
Validation loss: 2.556392540101522

Epoch: 6| Step: 12
Training loss: 2.1444544265967145
Validation loss: 2.5389941710056756

Epoch: 6| Step: 13
Training loss: 2.6815529605458854
Validation loss: 2.5639845649301267

Epoch: 32| Step: 0
Training loss: 2.468564569776584
Validation loss: 2.5475710832276492

Epoch: 6| Step: 1
Training loss: 2.8350746376398575
Validation loss: 2.565911572923562

Epoch: 6| Step: 2
Training loss: 2.0968147735360514
Validation loss: 2.576640940764368

Epoch: 6| Step: 3
Training loss: 2.784603882703846
Validation loss: 2.5645090926513605

Epoch: 6| Step: 4
Training loss: 1.9390025311709758
Validation loss: 2.5731556944815064

Epoch: 6| Step: 5
Training loss: 2.1983836131483243
Validation loss: 2.5546664549167812

Epoch: 6| Step: 6
Training loss: 2.356875276446674
Validation loss: 2.5791754538078764

Epoch: 6| Step: 7
Training loss: 2.523861120232972
Validation loss: 2.5784069947428665

Epoch: 6| Step: 8
Training loss: 2.464314883120695
Validation loss: 2.5569397994379193

Epoch: 6| Step: 9
Training loss: 2.7513523244656044
Validation loss: 2.5855882145612665

Epoch: 6| Step: 10
Training loss: 2.3338745602107824
Validation loss: 2.55732005790494

Epoch: 6| Step: 11
Training loss: 2.481829412728989
Validation loss: 2.5568093869992436

Epoch: 6| Step: 12
Training loss: 2.996312259032007
Validation loss: 2.5834598869171113

Epoch: 6| Step: 13
Training loss: 2.3674731192427325
Validation loss: 2.5626711284282373

Epoch: 33| Step: 0
Training loss: 2.533744712940754
Validation loss: 2.576682324820445

Epoch: 6| Step: 1
Training loss: 2.6317563074977977
Validation loss: 2.569303157862627

Epoch: 6| Step: 2
Training loss: 2.772260389233026
Validation loss: 2.5700532884923826

Epoch: 6| Step: 3
Training loss: 2.42743453294062
Validation loss: 2.5667872656525885

Epoch: 6| Step: 4
Training loss: 2.1616144208199746
Validation loss: 2.544056212094103

Epoch: 6| Step: 5
Training loss: 2.5453474460401733
Validation loss: 2.560061604955633

Epoch: 6| Step: 6
Training loss: 2.8099541904068577
Validation loss: 2.5572618895828088

Epoch: 6| Step: 7
Training loss: 2.618255124185706
Validation loss: 2.5418916404672802

Epoch: 6| Step: 8
Training loss: 1.8662386602222019
Validation loss: 2.5372490769771536

Epoch: 6| Step: 9
Training loss: 2.1247895080433756
Validation loss: 2.554397815452802

Epoch: 6| Step: 10
Training loss: 3.1937132473079473
Validation loss: 2.551286726168132

Epoch: 6| Step: 11
Training loss: 2.4976950510284737
Validation loss: 2.5774685650131763

Epoch: 6| Step: 12
Training loss: 2.201344088136282
Validation loss: 2.600677370208616

Epoch: 6| Step: 13
Training loss: 1.9075380570001241
Validation loss: 2.555840732608114

Epoch: 34| Step: 0
Training loss: 2.854942346314764
Validation loss: 2.5595711974048214

Epoch: 6| Step: 1
Training loss: 2.156713021363425
Validation loss: 2.556546101912524

Epoch: 6| Step: 2
Training loss: 2.67450624704193
Validation loss: 2.5691085361021297

Epoch: 6| Step: 3
Training loss: 3.0696590592127864
Validation loss: 2.5896051679587333

Epoch: 6| Step: 4
Training loss: 1.8993856942772314
Validation loss: 2.5641020287305323

Epoch: 6| Step: 5
Training loss: 2.5820286645457933
Validation loss: 2.5777761589402384

Epoch: 6| Step: 6
Training loss: 2.6099844580585865
Validation loss: 2.563650214232441

Epoch: 6| Step: 7
Training loss: 2.6595358776377016
Validation loss: 2.5492143399271265

Epoch: 6| Step: 8
Training loss: 2.3059583360625253
Validation loss: 2.5411103426662422

Epoch: 6| Step: 9
Training loss: 2.9795219547431406
Validation loss: 2.575310544543748

Epoch: 6| Step: 10
Training loss: 2.0699727481393446
Validation loss: 2.5384702490610445

Epoch: 6| Step: 11
Training loss: 2.388503785352161
Validation loss: 2.56141614864983

Epoch: 6| Step: 12
Training loss: 1.733168723775398
Validation loss: 2.559246059673923

Epoch: 6| Step: 13
Training loss: 2.0437131732574163
Validation loss: 2.5628118557854176

Epoch: 35| Step: 0
Training loss: 2.4291707068835553
Validation loss: 2.544045395691526

Epoch: 6| Step: 1
Training loss: 2.803108812368341
Validation loss: 2.546030883699638

Epoch: 6| Step: 2
Training loss: 2.044786742080249
Validation loss: 2.559415387342273

Epoch: 6| Step: 3
Training loss: 2.1305129401586824
Validation loss: 2.5453010797683486

Epoch: 6| Step: 4
Training loss: 2.7518735918799098
Validation loss: 2.581946698149551

Epoch: 6| Step: 5
Training loss: 2.7654499925317486
Validation loss: 2.574433058759859

Epoch: 6| Step: 6
Training loss: 2.587318627823942
Validation loss: 2.5612092062322014

Epoch: 6| Step: 7
Training loss: 2.8430525375057822
Validation loss: 2.562736841437112

Epoch: 6| Step: 8
Training loss: 2.5251349535843577
Validation loss: 2.588696225091468

Epoch: 6| Step: 9
Training loss: 2.0876612024253505
Validation loss: 2.563049242037533

Epoch: 6| Step: 10
Training loss: 2.5684239832653213
Validation loss: 2.567463255064949

Epoch: 6| Step: 11
Training loss: 2.2024079366574902
Validation loss: 2.5709681114425997

Epoch: 6| Step: 12
Training loss: 2.4944144795389644
Validation loss: 2.5903774227536043

Epoch: 6| Step: 13
Training loss: 2.325964417963614
Validation loss: 2.5741887184903547

Epoch: 36| Step: 0
Training loss: 2.5274479887277357
Validation loss: 2.5470209372430843

Epoch: 6| Step: 1
Training loss: 2.78562155069673
Validation loss: 2.5788823720340255

Epoch: 6| Step: 2
Training loss: 1.9651628542286608
Validation loss: 2.5797930012938517

Epoch: 6| Step: 3
Training loss: 2.410968958809511
Validation loss: 2.5555011180824736

Epoch: 6| Step: 4
Training loss: 3.0674886748983905
Validation loss: 2.578127689552831

Epoch: 6| Step: 5
Training loss: 2.064929687004904
Validation loss: 2.5644769253465247

Epoch: 6| Step: 6
Training loss: 2.152859440830417
Validation loss: 2.553596069008726

Epoch: 6| Step: 7
Training loss: 1.906092840501406
Validation loss: 2.572023573918181

Epoch: 6| Step: 8
Training loss: 2.324049281505496
Validation loss: 2.564499997216389

Epoch: 6| Step: 9
Training loss: 3.471558267479374
Validation loss: 2.548052821624412

Epoch: 6| Step: 10
Training loss: 2.43781141590397
Validation loss: 2.56198178455529

Epoch: 6| Step: 11
Training loss: 2.9931070294321636
Validation loss: 2.5714835578599993

Epoch: 6| Step: 12
Training loss: 1.5766434466296726
Validation loss: 2.5490266569142235

Epoch: 6| Step: 13
Training loss: 2.5659288865282712
Validation loss: 2.541519119065701

Epoch: 37| Step: 0
Training loss: 2.754530815562879
Validation loss: 2.526927805677559

Epoch: 6| Step: 1
Training loss: 2.3442522655181985
Validation loss: 2.5614521241135413

Epoch: 6| Step: 2
Training loss: 2.5427907948846857
Validation loss: 2.5523379970828604

Epoch: 6| Step: 3
Training loss: 2.9896411070519164
Validation loss: 2.5698743483456923

Epoch: 6| Step: 4
Training loss: 2.000375712390714
Validation loss: 2.5622867247364294

Epoch: 6| Step: 5
Training loss: 2.2923970070170574
Validation loss: 2.5929863199985586

Epoch: 6| Step: 6
Training loss: 1.9583833025245425
Validation loss: 2.575441570753022

Epoch: 6| Step: 7
Training loss: 2.084310175446712
Validation loss: 2.593749249316494

Epoch: 6| Step: 8
Training loss: 2.803179577282318
Validation loss: 2.61833535449482

Epoch: 6| Step: 9
Training loss: 2.675901535560518
Validation loss: 2.61036915219583

Epoch: 6| Step: 10
Training loss: 2.5239865677078646
Validation loss: 2.6198980766107707

Epoch: 6| Step: 11
Training loss: 2.61870619707642
Validation loss: 2.593333069103427

Epoch: 6| Step: 12
Training loss: 2.6141248404849806
Validation loss: 2.608725674486401

Epoch: 6| Step: 13
Training loss: 2.697642858644904
Validation loss: 2.588397343767847

Epoch: 38| Step: 0
Training loss: 2.3536160142943707
Validation loss: 2.5650080835513713

Epoch: 6| Step: 1
Training loss: 2.9236422003761526
Validation loss: 2.5896381739617205

Epoch: 6| Step: 2
Training loss: 1.9293792725550651
Validation loss: 2.5647719941107634

Epoch: 6| Step: 3
Training loss: 2.813313260647125
Validation loss: 2.5852127826804145

Epoch: 6| Step: 4
Training loss: 2.444138705274338
Validation loss: 2.5454065188814807

Epoch: 6| Step: 5
Training loss: 2.7628153521718626
Validation loss: 2.5400051929641063

Epoch: 6| Step: 6
Training loss: 3.051500457898649
Validation loss: 2.546452040549183

Epoch: 6| Step: 7
Training loss: 2.4808076401741403
Validation loss: 2.5724796639625067

Epoch: 6| Step: 8
Training loss: 1.8362906907612864
Validation loss: 2.545146597491623

Epoch: 6| Step: 9
Training loss: 2.37127654676604
Validation loss: 2.5579035325455455

Epoch: 6| Step: 10
Training loss: 2.8153763368059126
Validation loss: 2.55783170655189

Epoch: 6| Step: 11
Training loss: 1.7360155748995876
Validation loss: 2.5708988838762465

Epoch: 6| Step: 12
Training loss: 2.2916820756798773
Validation loss: 2.5858066675563274

Epoch: 6| Step: 13
Training loss: 2.4730816274854446
Validation loss: 2.553808747479577

Epoch: 39| Step: 0
Training loss: 2.0237721052370365
Validation loss: 2.5563230888034414

Epoch: 6| Step: 1
Training loss: 2.468986693033147
Validation loss: 2.5668319589062016

Epoch: 6| Step: 2
Training loss: 2.628845123441933
Validation loss: 2.5521160253390116

Epoch: 6| Step: 3
Training loss: 2.806762947490971
Validation loss: 2.5724072177220805

Epoch: 6| Step: 4
Training loss: 2.827699660883713
Validation loss: 2.5813505859727823

Epoch: 6| Step: 5
Training loss: 2.7434320913023167
Validation loss: 2.563004715379219

Epoch: 6| Step: 6
Training loss: 2.9964085379979335
Validation loss: 2.5745648704698603

Epoch: 6| Step: 7
Training loss: 3.2150026006376624
Validation loss: 2.5549174758413984

Epoch: 6| Step: 8
Training loss: 1.89122296169642
Validation loss: 2.5557582217401453

Epoch: 6| Step: 9
Training loss: 2.5512743439697427
Validation loss: 2.5464651015870348

Epoch: 6| Step: 10
Training loss: 1.7341234179335356
Validation loss: 2.5452137152991767

Epoch: 6| Step: 11
Training loss: 2.231592967283877
Validation loss: 2.575874579461509

Epoch: 6| Step: 12
Training loss: 1.8939931832969314
Validation loss: 2.5676669000735033

Epoch: 6| Step: 13
Training loss: 2.1518095430096054
Validation loss: 2.5407635903183134

Epoch: 40| Step: 0
Training loss: 2.26834343243924
Validation loss: 2.5749607357870983

Epoch: 6| Step: 1
Training loss: 1.779287093268598
Validation loss: 2.5559349164332894

Epoch: 6| Step: 2
Training loss: 2.5589019822686447
Validation loss: 2.5530459606149134

Epoch: 6| Step: 3
Training loss: 2.125400729822285
Validation loss: 2.560134842905058

Epoch: 6| Step: 4
Training loss: 2.590001810581355
Validation loss: 2.581579171683212

Epoch: 6| Step: 5
Training loss: 2.482229782103605
Validation loss: 2.5661674554862475

Epoch: 6| Step: 6
Training loss: 3.044249513593323
Validation loss: 2.5266631210758557

Epoch: 6| Step: 7
Training loss: 2.725094812826079
Validation loss: 2.569545094062376

Epoch: 6| Step: 8
Training loss: 2.5310637794094073
Validation loss: 2.5651064696842187

Epoch: 6| Step: 9
Training loss: 2.344498781756709
Validation loss: 2.5367110411747427

Epoch: 6| Step: 10
Training loss: 2.5310883647033195
Validation loss: 2.5609217334670835

Epoch: 6| Step: 11
Training loss: 2.34699817644072
Validation loss: 2.5508391377149224

Epoch: 6| Step: 12
Training loss: 1.9767662214754822
Validation loss: 2.558737823079673

Epoch: 6| Step: 13
Training loss: 2.9775152008411703
Validation loss: 2.5447021295819576

Epoch: 41| Step: 0
Training loss: 2.520907051542819
Validation loss: 2.584700812113829

Epoch: 6| Step: 1
Training loss: 2.554802661598244
Validation loss: 2.5737771874514603

Epoch: 6| Step: 2
Training loss: 1.893563375310459
Validation loss: 2.5587864305778565

Epoch: 6| Step: 3
Training loss: 2.1411640017688285
Validation loss: 2.5772837335560403

Epoch: 6| Step: 4
Training loss: 2.696317004563655
Validation loss: 2.5976699866980937

Epoch: 6| Step: 5
Training loss: 1.8927223615138746
Validation loss: 2.569118775242972

Epoch: 6| Step: 6
Training loss: 2.77618426922272
Validation loss: 2.5823833246699937

Epoch: 6| Step: 7
Training loss: 2.6113551501499837
Validation loss: 2.573626761318254

Epoch: 6| Step: 8
Training loss: 3.036196732852787
Validation loss: 2.589996379422636

Epoch: 6| Step: 9
Training loss: 3.0042887867000405
Validation loss: 2.5726117456631403

Epoch: 6| Step: 10
Training loss: 2.3486038808963876
Validation loss: 2.5711353998356694

Epoch: 6| Step: 11
Training loss: 1.698258121847866
Validation loss: 2.572138314655697

Epoch: 6| Step: 12
Training loss: 2.4346511037850713
Validation loss: 2.565165428294997

Epoch: 6| Step: 13
Training loss: 2.6566435578448835
Validation loss: 2.5798901612905403

Epoch: 42| Step: 0
Training loss: 2.539191046175106
Validation loss: 2.5769025119839766

Epoch: 6| Step: 1
Training loss: 3.4800789525952407
Validation loss: 2.549607244800153

Epoch: 6| Step: 2
Training loss: 1.865455494501365
Validation loss: 2.583932350809474

Epoch: 6| Step: 3
Training loss: 2.281146635039172
Validation loss: 2.541600247333456

Epoch: 6| Step: 4
Training loss: 2.3042471772166584
Validation loss: 2.5600193623838736

Epoch: 6| Step: 5
Training loss: 2.2545179994650986
Validation loss: 2.563799923801756

Epoch: 6| Step: 6
Training loss: 2.8863004760822153
Validation loss: 2.5577260960747754

Epoch: 6| Step: 7
Training loss: 2.648579011360421
Validation loss: 2.5534213755927206

Epoch: 6| Step: 8
Training loss: 2.3384208619676543
Validation loss: 2.5675728602906487

Epoch: 6| Step: 9
Training loss: 2.1194488723106457
Validation loss: 2.5712356996486307

Epoch: 6| Step: 10
Training loss: 2.6868145978003173
Validation loss: 2.5481708483001624

Epoch: 6| Step: 11
Training loss: 2.732351546237966
Validation loss: 2.555215172512908

Epoch: 6| Step: 12
Training loss: 1.885775502096809
Validation loss: 2.545609360586044

Epoch: 6| Step: 13
Training loss: 2.0937459006198207
Validation loss: 2.542839441561842

Epoch: 43| Step: 0
Training loss: 2.1277156755477646
Validation loss: 2.5398609803420165

Epoch: 6| Step: 1
Training loss: 2.4851731271899213
Validation loss: 2.5356006516900234

Epoch: 6| Step: 2
Training loss: 2.0843234443293714
Validation loss: 2.5406702047770655

Epoch: 6| Step: 3
Training loss: 1.8021022891185081
Validation loss: 2.5651635384183544

Epoch: 6| Step: 4
Training loss: 3.6560456308484706
Validation loss: 2.551486125798933

Epoch: 6| Step: 5
Training loss: 2.624386125265271
Validation loss: 2.5502330118817693

Epoch: 6| Step: 6
Training loss: 2.177363862819736
Validation loss: 2.5644437814442074

Epoch: 6| Step: 7
Training loss: 2.5553737267017667
Validation loss: 2.554630803870227

Epoch: 6| Step: 8
Training loss: 2.7233204626606455
Validation loss: 2.589542407824673

Epoch: 6| Step: 9
Training loss: 2.150621670291078
Validation loss: 2.561866619949179

Epoch: 6| Step: 10
Training loss: 1.950806240766538
Validation loss: 2.561732603708283

Epoch: 6| Step: 11
Training loss: 2.1027164056652548
Validation loss: 2.5539907969485975

Epoch: 6| Step: 12
Training loss: 2.0980332247173354
Validation loss: 2.539979911759806

Epoch: 6| Step: 13
Training loss: 3.257775029760534
Validation loss: 2.5714738998883515

Epoch: 44| Step: 0
Training loss: 2.6983531662618754
Validation loss: 2.566093158639397

Epoch: 6| Step: 1
Training loss: 2.2236144777529687
Validation loss: 2.5542671098815886

Epoch: 6| Step: 2
Training loss: 2.555213990628345
Validation loss: 2.564534472927922

Epoch: 6| Step: 3
Training loss: 2.149296703193716
Validation loss: 2.561316930387552

Epoch: 6| Step: 4
Training loss: 1.697954782007443
Validation loss: 2.569471196444892

Epoch: 6| Step: 5
Training loss: 2.342319713319319
Validation loss: 2.5636818184195502

Epoch: 6| Step: 6
Training loss: 2.650619283326831
Validation loss: 2.569086201641241

Epoch: 6| Step: 7
Training loss: 2.627271305370636
Validation loss: 2.5872711553440686

Epoch: 6| Step: 8
Training loss: 2.5435451903125985
Validation loss: 2.600839539234988

Epoch: 6| Step: 9
Training loss: 3.2066324522713794
Validation loss: 2.588374131817226

Epoch: 6| Step: 10
Training loss: 2.7181375624909543
Validation loss: 2.5873456426702983

Epoch: 6| Step: 11
Training loss: 2.527424311348842
Validation loss: 2.584287995146618

Epoch: 6| Step: 12
Training loss: 2.2379322678694478
Validation loss: 2.5995749975960347

Epoch: 6| Step: 13
Training loss: 2.010902135340927
Validation loss: 2.578594049498677

Epoch: 45| Step: 0
Training loss: 2.341281251876977
Validation loss: 2.562996653366732

Epoch: 6| Step: 1
Training loss: 2.2661900309030907
Validation loss: 2.5747513863996594

Epoch: 6| Step: 2
Training loss: 2.2775267434251134
Validation loss: 2.5550247420862946

Epoch: 6| Step: 3
Training loss: 2.2345063497709616
Validation loss: 2.55788850261641

Epoch: 6| Step: 4
Training loss: 2.6589028070367795
Validation loss: 2.5512282567434825

Epoch: 6| Step: 5
Training loss: 2.524533627185433
Validation loss: 2.5670209639079227

Epoch: 6| Step: 6
Training loss: 2.3614198021647197
Validation loss: 2.555257595586291

Epoch: 6| Step: 7
Training loss: 2.3991129666469226
Validation loss: 2.5588613743871083

Epoch: 6| Step: 8
Training loss: 2.8240561537414344
Validation loss: 2.5439723505790828

Epoch: 6| Step: 9
Training loss: 2.44288275664628
Validation loss: 2.555289801195526

Epoch: 6| Step: 10
Training loss: 2.588321750645248
Validation loss: 2.562295099145447

Epoch: 6| Step: 11
Training loss: 2.6717745221078935
Validation loss: 2.549858078092643

Epoch: 6| Step: 12
Training loss: 2.6396284762413496
Validation loss: 2.5497915111032308

Epoch: 6| Step: 13
Training loss: 2.294716579913281
Validation loss: 2.522537905682663

Epoch: 46| Step: 0
Training loss: 1.8593327493435305
Validation loss: 2.5329848102034314

Epoch: 6| Step: 1
Training loss: 2.4624592269387806
Validation loss: 2.5663256581744105

Epoch: 6| Step: 2
Training loss: 2.3371528857346084
Validation loss: 2.5650058527403172

Epoch: 6| Step: 3
Training loss: 1.4857438050471017
Validation loss: 2.5460538886181414

Epoch: 6| Step: 4
Training loss: 2.5479925781153883
Validation loss: 2.5541703286904434

Epoch: 6| Step: 5
Training loss: 2.4540423967885308
Validation loss: 2.53854734232042

Epoch: 6| Step: 6
Training loss: 2.0849953570417123
Validation loss: 2.557098883816263

Epoch: 6| Step: 7
Training loss: 1.8879869830725378
Validation loss: 2.566654017239731

Epoch: 6| Step: 8
Training loss: 2.297733483804781
Validation loss: 2.5381279736773616

Epoch: 6| Step: 9
Training loss: 2.997212227313755
Validation loss: 2.5319736843358687

Epoch: 6| Step: 10
Training loss: 2.810849277538954
Validation loss: 2.557331113388058

Epoch: 6| Step: 11
Training loss: 2.6542726225092346
Validation loss: 2.5397829256388946

Epoch: 6| Step: 12
Training loss: 2.588933309993471
Validation loss: 2.5286176203925956

Epoch: 6| Step: 13
Training loss: 3.2539809860677473
Validation loss: 2.5407333119457514

Epoch: 47| Step: 0
Training loss: 2.5818101843125154
Validation loss: 2.557654397156581

Epoch: 6| Step: 1
Training loss: 1.9064901231959608
Validation loss: 2.5690945616197327

Epoch: 6| Step: 2
Training loss: 1.8660539194721029
Validation loss: 2.5761630212623476

Epoch: 6| Step: 3
Training loss: 2.4299149483446874
Validation loss: 2.5898969289038867

Epoch: 6| Step: 4
Training loss: 3.3095845762177873
Validation loss: 2.60545900448831

Epoch: 6| Step: 5
Training loss: 2.1925657200288224
Validation loss: 2.613087630309974

Epoch: 6| Step: 6
Training loss: 2.985793330905602
Validation loss: 2.6180782263730142

Epoch: 6| Step: 7
Training loss: 2.221090023052404
Validation loss: 2.6292447934480148

Epoch: 6| Step: 8
Training loss: 3.2220169820497824
Validation loss: 2.5935401678427

Epoch: 6| Step: 9
Training loss: 2.1458124943681187
Validation loss: 2.5811470968749677

Epoch: 6| Step: 10
Training loss: 2.4913119987586243
Validation loss: 2.5773483031187285

Epoch: 6| Step: 11
Training loss: 2.0838413636350506
Validation loss: 2.5618852172508846

Epoch: 6| Step: 12
Training loss: 2.242830297328522
Validation loss: 2.549170015870565

Epoch: 6| Step: 13
Training loss: 2.4569717666873148
Validation loss: 2.5355731325499637

Epoch: 48| Step: 0
Training loss: 2.3582484100831422
Validation loss: 2.558221253125864

Epoch: 6| Step: 1
Training loss: 2.2415487728764862
Validation loss: 2.5636280569694776

Epoch: 6| Step: 2
Training loss: 2.4333769332776947
Validation loss: 2.5321724627573747

Epoch: 6| Step: 3
Training loss: 1.651566703740511
Validation loss: 2.5735567406130264

Epoch: 6| Step: 4
Training loss: 1.8264541815757738
Validation loss: 2.5580307358045244

Epoch: 6| Step: 5
Training loss: 2.279282335302008
Validation loss: 2.556136596203681

Epoch: 6| Step: 6
Training loss: 2.4558657746059454
Validation loss: 2.548875596346123

Epoch: 6| Step: 7
Training loss: 3.174635263954438
Validation loss: 2.5316930469480394

Epoch: 6| Step: 8
Training loss: 2.4876610478547256
Validation loss: 2.5520608602559376

Epoch: 6| Step: 9
Training loss: 2.4418007493770255
Validation loss: 2.5660236446979057

Epoch: 6| Step: 10
Training loss: 2.2336190819012645
Validation loss: 2.5743061025768883

Epoch: 6| Step: 11
Training loss: 2.5476133996283785
Validation loss: 2.59790109804613

Epoch: 6| Step: 12
Training loss: 3.0273242186869957
Validation loss: 2.5739441388946944

Epoch: 6| Step: 13
Training loss: 2.943495617543958
Validation loss: 2.571583318721473

Epoch: 49| Step: 0
Training loss: 2.5117776012496904
Validation loss: 2.5542666276182273

Epoch: 6| Step: 1
Training loss: 2.539912530489312
Validation loss: 2.539043187777116

Epoch: 6| Step: 2
Training loss: 2.2992375478387617
Validation loss: 2.544566451943718

Epoch: 6| Step: 3
Training loss: 2.247536264027274
Validation loss: 2.5730673453705513

Epoch: 6| Step: 4
Training loss: 2.4897957449176253
Validation loss: 2.5582581899419834

Epoch: 6| Step: 5
Training loss: 1.8620934369073527
Validation loss: 2.550028325216513

Epoch: 6| Step: 6
Training loss: 2.7129189233697772
Validation loss: 2.5311758477923267

Epoch: 6| Step: 7
Training loss: 2.478687998832576
Validation loss: 2.5524438772031344

Epoch: 6| Step: 8
Training loss: 2.069145132632078
Validation loss: 2.5778412171437273

Epoch: 6| Step: 9
Training loss: 2.160624061961656
Validation loss: 2.5578747542317988

Epoch: 6| Step: 10
Training loss: 2.5184235732823246
Validation loss: 2.5427783166197995

Epoch: 6| Step: 11
Training loss: 3.4322272349182037
Validation loss: 2.5316285372288876

Epoch: 6| Step: 12
Training loss: 2.161428232251496
Validation loss: 2.5435046262749634

Epoch: 6| Step: 13
Training loss: 2.556114055124531
Validation loss: 2.5368993690349697

Epoch: 50| Step: 0
Training loss: 2.1975251582835322
Validation loss: 2.5444633830109282

Epoch: 6| Step: 1
Training loss: 2.3904055825062307
Validation loss: 2.5384741155198705

Epoch: 6| Step: 2
Training loss: 2.9929332152517256
Validation loss: 2.5493104987352146

Epoch: 6| Step: 3
Training loss: 2.5090199828646367
Validation loss: 2.565638024145686

Epoch: 6| Step: 4
Training loss: 2.3096712699261057
Validation loss: 2.5635341015367876

Epoch: 6| Step: 5
Training loss: 2.3221311281621015
Validation loss: 2.574847332277338

Epoch: 6| Step: 6
Training loss: 2.5833258680010163
Validation loss: 2.5721729815113554

Epoch: 6| Step: 7
Training loss: 2.245279658853204
Validation loss: 2.5640127632420544

Epoch: 6| Step: 8
Training loss: 2.3556413223539145
Validation loss: 2.562237408217024

Epoch: 6| Step: 9
Training loss: 2.5619191697745847
Validation loss: 2.548179323679167

Epoch: 6| Step: 10
Training loss: 2.385981419327071
Validation loss: 2.5724414329917975

Epoch: 6| Step: 11
Training loss: 2.6219171859384565
Validation loss: 2.5555253827575917

Epoch: 6| Step: 12
Training loss: 1.8883863704715567
Validation loss: 2.5755403066014027

Epoch: 6| Step: 13
Training loss: 2.797862896055797
Validation loss: 2.551790949882107

Epoch: 51| Step: 0
Training loss: 3.090706763810783
Validation loss: 2.5344307149775083

Epoch: 6| Step: 1
Training loss: 2.588561786494106
Validation loss: 2.5684738385085577

Epoch: 6| Step: 2
Training loss: 2.5378350210535148
Validation loss: 2.5209680211259387

Epoch: 6| Step: 3
Training loss: 2.0686849854732148
Validation loss: 2.551850449712354

Epoch: 6| Step: 4
Training loss: 2.9884883634312946
Validation loss: 2.5365690694105654

Epoch: 6| Step: 5
Training loss: 2.56174941816758
Validation loss: 2.553014131377662

Epoch: 6| Step: 6
Training loss: 2.9213886366182282
Validation loss: 2.565229203070019

Epoch: 6| Step: 7
Training loss: 2.2713908523108
Validation loss: 2.5353510722501804

Epoch: 6| Step: 8
Training loss: 2.117996567980009
Validation loss: 2.5422451319899717

Epoch: 6| Step: 9
Training loss: 1.2131944358799966
Validation loss: 2.5621599886718758

Epoch: 6| Step: 10
Training loss: 2.8796680534645884
Validation loss: 2.5587987919540858

Epoch: 6| Step: 11
Training loss: 1.3957308783815952
Validation loss: 2.5455436581282216

Epoch: 6| Step: 12
Training loss: 2.8945757287194946
Validation loss: 2.5570875243045434

Epoch: 6| Step: 13
Training loss: 2.216340812117799
Validation loss: 2.5531529397420116

Epoch: 52| Step: 0
Training loss: 2.849851162688167
Validation loss: 2.5492736504975797

Epoch: 6| Step: 1
Training loss: 3.09264438794743
Validation loss: 2.5405337096356995

Epoch: 6| Step: 2
Training loss: 2.0965969032038383
Validation loss: 2.5394427518501206

Epoch: 6| Step: 3
Training loss: 2.6589568763096674
Validation loss: 2.5866146833646386

Epoch: 6| Step: 4
Training loss: 2.39856801625365
Validation loss: 2.580837510519945

Epoch: 6| Step: 5
Training loss: 2.515392979886387
Validation loss: 2.5706289419312

Epoch: 6| Step: 6
Training loss: 1.8828674561643766
Validation loss: 2.5778615181117233

Epoch: 6| Step: 7
Training loss: 2.360478932389079
Validation loss: 2.601716656551825

Epoch: 6| Step: 8
Training loss: 1.4004715346794188
Validation loss: 2.5905771880728596

Epoch: 6| Step: 9
Training loss: 2.5456740467376977
Validation loss: 2.634523629927761

Epoch: 6| Step: 10
Training loss: 2.7417935254122314
Validation loss: 2.6254939643883963

Epoch: 6| Step: 11
Training loss: 2.9874424374194275
Validation loss: 2.6096718137739625

Epoch: 6| Step: 12
Training loss: 2.1273085452223257
Validation loss: 2.6009184505032863

Epoch: 6| Step: 13
Training loss: 2.109577536572785
Validation loss: 2.5916379119488107

Epoch: 53| Step: 0
Training loss: 1.9360781959473523
Validation loss: 2.564417362084822

Epoch: 6| Step: 1
Training loss: 2.5328371699812586
Validation loss: 2.564030081919647

Epoch: 6| Step: 2
Training loss: 2.8120745019118853
Validation loss: 2.564106987833217

Epoch: 6| Step: 3
Training loss: 2.7937402473296546
Validation loss: 2.564960337574498

Epoch: 6| Step: 4
Training loss: 2.606022125454689
Validation loss: 2.540005646646786

Epoch: 6| Step: 5
Training loss: 2.8167390878008414
Validation loss: 2.538848578415702

Epoch: 6| Step: 6
Training loss: 2.4148513838253347
Validation loss: 2.5542236669215423

Epoch: 6| Step: 7
Training loss: 2.4512385993781884
Validation loss: 2.5337988496853714

Epoch: 6| Step: 8
Training loss: 2.464422271530545
Validation loss: 2.5415195099384915

Epoch: 6| Step: 9
Training loss: 2.2483107265337847
Validation loss: 2.5313407112476543

Epoch: 6| Step: 10
Training loss: 2.3807796624525044
Validation loss: 2.559698449742726

Epoch: 6| Step: 11
Training loss: 2.0543293804027716
Validation loss: 2.5528041262875925

Epoch: 6| Step: 12
Training loss: 2.4503182068310605
Validation loss: 2.5577826925229203

Epoch: 6| Step: 13
Training loss: 2.081154014046506
Validation loss: 2.5397579238457078

Epoch: 54| Step: 0
Training loss: 2.3891405470819285
Validation loss: 2.5591291105329637

Epoch: 6| Step: 1
Training loss: 2.640366942306856
Validation loss: 2.545148611519981

Epoch: 6| Step: 2
Training loss: 2.1674661139597027
Validation loss: 2.556298575215701

Epoch: 6| Step: 3
Training loss: 2.6506831458185203
Validation loss: 2.5591234275256416

Epoch: 6| Step: 4
Training loss: 2.191329002718838
Validation loss: 2.547936341237556

Epoch: 6| Step: 5
Training loss: 1.9211315174586687
Validation loss: 2.5529794534000123

Epoch: 6| Step: 6
Training loss: 2.5223874012340564
Validation loss: 2.5542004633332693

Epoch: 6| Step: 7
Training loss: 2.4498045979642513
Validation loss: 2.537605814614515

Epoch: 6| Step: 8
Training loss: 2.298063839868113
Validation loss: 2.5700322455425457

Epoch: 6| Step: 9
Training loss: 2.0441790582421495
Validation loss: 2.5701838483373622

Epoch: 6| Step: 10
Training loss: 2.3072509991669174
Validation loss: 2.57259463149471

Epoch: 6| Step: 11
Training loss: 2.9429044314961916
Validation loss: 2.574446873067121

Epoch: 6| Step: 12
Training loss: 3.1804180383914598
Validation loss: 2.567488025759936

Epoch: 6| Step: 13
Training loss: 2.2290550869500643
Validation loss: 2.5571433112988142

Epoch: 55| Step: 0
Training loss: 2.1966020048211345
Validation loss: 2.5912545543973518

Epoch: 6| Step: 1
Training loss: 2.768611437772639
Validation loss: 2.5710196329146418

Epoch: 6| Step: 2
Training loss: 2.170085251887069
Validation loss: 2.5735479705205484

Epoch: 6| Step: 3
Training loss: 3.0148551630306777
Validation loss: 2.551323537543917

Epoch: 6| Step: 4
Training loss: 2.740335213837533
Validation loss: 2.5328938362292073

Epoch: 6| Step: 5
Training loss: 2.12772598447033
Validation loss: 2.5785820449914483

Epoch: 6| Step: 6
Training loss: 2.674034004839749
Validation loss: 2.5691343504137083

Epoch: 6| Step: 7
Training loss: 2.3117495169595252
Validation loss: 2.547177240267347

Epoch: 6| Step: 8
Training loss: 1.6074022961672143
Validation loss: 2.5438167097762387

Epoch: 6| Step: 9
Training loss: 2.4937408294126686
Validation loss: 2.541361701888386

Epoch: 6| Step: 10
Training loss: 2.760376859173958
Validation loss: 2.517258660581196

Epoch: 6| Step: 11
Training loss: 2.3341314676452893
Validation loss: 2.528300352424189

Epoch: 6| Step: 12
Training loss: 2.542141500008781
Validation loss: 2.553474285959583

Epoch: 6| Step: 13
Training loss: 2.3390093861718158
Validation loss: 2.536089904994078

Epoch: 56| Step: 0
Training loss: 2.7268001594913858
Validation loss: 2.5874933362497226

Epoch: 6| Step: 1
Training loss: 4.016955203592145
Validation loss: 2.578720825395169

Epoch: 6| Step: 2
Training loss: 2.0972572671798684
Validation loss: 2.542904573207924

Epoch: 6| Step: 3
Training loss: 2.2090563640112633
Validation loss: 2.532411505058962

Epoch: 6| Step: 4
Training loss: 1.9432602440168847
Validation loss: 2.570989363112344

Epoch: 6| Step: 5
Training loss: 1.9182873245718528
Validation loss: 2.591470444376463

Epoch: 6| Step: 6
Training loss: 1.9768937025653848
Validation loss: 2.58975589348097

Epoch: 6| Step: 7
Training loss: 1.9346739554913113
Validation loss: 2.582523931839857

Epoch: 6| Step: 8
Training loss: 2.7606922707836965
Validation loss: 2.5677380718085003

Epoch: 6| Step: 9
Training loss: 2.872862311373001
Validation loss: 2.5517887853763934

Epoch: 6| Step: 10
Training loss: 2.4776383719503223
Validation loss: 2.5873995793708104

Epoch: 6| Step: 11
Training loss: 2.6208067508030672
Validation loss: 2.561956751234796

Epoch: 6| Step: 12
Training loss: 1.764442655622236
Validation loss: 2.574374960683026

Epoch: 6| Step: 13
Training loss: 1.8137480286601295
Validation loss: 2.5749693236020614

Epoch: 57| Step: 0
Training loss: 2.046008093906476
Validation loss: 2.533057944697128

Epoch: 6| Step: 1
Training loss: 2.4225433411869433
Validation loss: 2.5536603194423733

Epoch: 6| Step: 2
Training loss: 2.2588378267677207
Validation loss: 2.575219738791018

Epoch: 6| Step: 3
Training loss: 2.9394289541676493
Validation loss: 2.5644651491610087

Epoch: 6| Step: 4
Training loss: 2.287959852013105
Validation loss: 2.5663722794218455

Epoch: 6| Step: 5
Training loss: 1.70953213877786
Validation loss: 2.583903254943811

Epoch: 6| Step: 6
Training loss: 2.571688947286483
Validation loss: 2.555847246919697

Epoch: 6| Step: 7
Training loss: 2.487071175729012
Validation loss: 2.571415364077624

Epoch: 6| Step: 8
Training loss: 3.3019090159200424
Validation loss: 2.5424718727849056

Epoch: 6| Step: 9
Training loss: 1.8010638960581955
Validation loss: 2.5593085690650232

Epoch: 6| Step: 10
Training loss: 3.114783256178701
Validation loss: 2.5414178497177944

Epoch: 6| Step: 11
Training loss: 1.9082589741619145
Validation loss: 2.5618887381593614

Epoch: 6| Step: 12
Training loss: 2.0577949262489916
Validation loss: 2.5327195034568906

Epoch: 6| Step: 13
Training loss: 2.4103584390221777
Validation loss: 2.523667316187611

Epoch: 58| Step: 0
Training loss: 2.6748743901218406
Validation loss: 2.543414880046036

Epoch: 6| Step: 1
Training loss: 1.8667128210946666
Validation loss: 2.5658149986524705

Epoch: 6| Step: 2
Training loss: 2.4777524959184833
Validation loss: 2.53698957286171

Epoch: 6| Step: 3
Training loss: 2.2994163104258316
Validation loss: 2.543961463530384

Epoch: 6| Step: 4
Training loss: 3.0482156005059697
Validation loss: 2.541200068643614

Epoch: 6| Step: 5
Training loss: 2.216649525320371
Validation loss: 2.5796156455988064

Epoch: 6| Step: 6
Training loss: 2.264365431459759
Validation loss: 2.54888153604838

Epoch: 6| Step: 7
Training loss: 2.748763413268596
Validation loss: 2.557411942045858

Epoch: 6| Step: 8
Training loss: 1.723037642906292
Validation loss: 2.5513559563461685

Epoch: 6| Step: 9
Training loss: 2.7852285838531716
Validation loss: 2.5367100386435233

Epoch: 6| Step: 10
Training loss: 2.1631434723584184
Validation loss: 2.535026927092709

Epoch: 6| Step: 11
Training loss: 2.4898184395285545
Validation loss: 2.5617814956306857

Epoch: 6| Step: 12
Training loss: 2.211116069147035
Validation loss: 2.5423765493984307

Epoch: 6| Step: 13
Training loss: 2.8165594686239825
Validation loss: 2.5474577239062914

Epoch: 59| Step: 0
Training loss: 2.657293855094731
Validation loss: 2.5385508016787965

Epoch: 6| Step: 1
Training loss: 2.3146241201337383
Validation loss: 2.5536289102231

Epoch: 6| Step: 2
Training loss: 1.9681706862902706
Validation loss: 2.5543401950636326

Epoch: 6| Step: 3
Training loss: 3.107484789294751
Validation loss: 2.556162432699566

Epoch: 6| Step: 4
Training loss: 2.3586575257207048
Validation loss: 2.580088405314315

Epoch: 6| Step: 5
Training loss: 1.7024225308666163
Validation loss: 2.5945228972430248

Epoch: 6| Step: 6
Training loss: 2.596524512627935
Validation loss: 2.575174496734976

Epoch: 6| Step: 7
Training loss: 2.9284059697107403
Validation loss: 2.584555818627652

Epoch: 6| Step: 8
Training loss: 2.317485075638172
Validation loss: 2.599055505642017

Epoch: 6| Step: 9
Training loss: 2.2931395796870913
Validation loss: 2.5777787563671066

Epoch: 6| Step: 10
Training loss: 2.415243902901765
Validation loss: 2.5647315876240935

Epoch: 6| Step: 11
Training loss: 2.62599254190471
Validation loss: 2.5671255186635515

Epoch: 6| Step: 12
Training loss: 2.7741222127383818
Validation loss: 2.557349930129958

Epoch: 6| Step: 13
Training loss: 1.696171204684237
Validation loss: 2.5235553001409876

Epoch: 60| Step: 0
Training loss: 1.8987817648364607
Validation loss: 2.5677504984170825

Epoch: 6| Step: 1
Training loss: 3.0888358496572668
Validation loss: 2.544530183087005

Epoch: 6| Step: 2
Training loss: 2.307515726914132
Validation loss: 2.5669035717594113

Epoch: 6| Step: 3
Training loss: 2.3305735161379344
Validation loss: 2.529034347361775

Epoch: 6| Step: 4
Training loss: 2.040238666036915
Validation loss: 2.5391648179003607

Epoch: 6| Step: 5
Training loss: 2.464330846558812
Validation loss: 2.567743232804547

Epoch: 6| Step: 6
Training loss: 1.6748234783931277
Validation loss: 2.563716708121659

Epoch: 6| Step: 7
Training loss: 3.042722719013319
Validation loss: 2.5709962331600087

Epoch: 6| Step: 8
Training loss: 2.4209274899615667
Validation loss: 2.549001761376865

Epoch: 6| Step: 9
Training loss: 1.781868275201873
Validation loss: 2.582228583308709

Epoch: 6| Step: 10
Training loss: 2.136729015486081
Validation loss: 2.5603544277844716

Epoch: 6| Step: 11
Training loss: 1.8071819422354571
Validation loss: 2.554505383516519

Epoch: 6| Step: 12
Training loss: 2.7893108182579494
Validation loss: 2.5885560606486564

Epoch: 6| Step: 13
Training loss: 3.3904840818030633
Validation loss: 2.5879733474273894

Epoch: 61| Step: 0
Training loss: 2.252693894791383
Validation loss: 2.5636312112330137

Epoch: 6| Step: 1
Training loss: 1.4808006216603298
Validation loss: 2.5563030053995623

Epoch: 6| Step: 2
Training loss: 3.5052718921508546
Validation loss: 2.5302837238620435

Epoch: 6| Step: 3
Training loss: 2.092578503265261
Validation loss: 2.543577294262755

Epoch: 6| Step: 4
Training loss: 2.8385085544346405
Validation loss: 2.5217140225159467

Epoch: 6| Step: 5
Training loss: 2.4040153332378367
Validation loss: 2.5309234377091236

Epoch: 6| Step: 6
Training loss: 2.1077693903694765
Validation loss: 2.5481717917430102

Epoch: 6| Step: 7
Training loss: 2.338429018520383
Validation loss: 2.5725045176504375

Epoch: 6| Step: 8
Training loss: 1.9789471019288682
Validation loss: 2.5511670524299648

Epoch: 6| Step: 9
Training loss: 2.7823847481027153
Validation loss: 2.5396698210720396

Epoch: 6| Step: 10
Training loss: 2.371884963425529
Validation loss: 2.5449576776679037

Epoch: 6| Step: 11
Training loss: 2.4223463030579415
Validation loss: 2.5454018667888474

Epoch: 6| Step: 12
Training loss: 1.8943852633830973
Validation loss: 2.554369347658399

Epoch: 6| Step: 13
Training loss: 2.8417722091390885
Validation loss: 2.5624057163168015

Epoch: 62| Step: 0
Training loss: 2.849137955511908
Validation loss: 2.532119821303661

Epoch: 6| Step: 1
Training loss: 2.203845183707331
Validation loss: 2.525064437975625

Epoch: 6| Step: 2
Training loss: 1.8056025311480601
Validation loss: 2.538937695688212

Epoch: 6| Step: 3
Training loss: 2.323693890974066
Validation loss: 2.5439206171576063

Epoch: 6| Step: 4
Training loss: 2.4168953184502384
Validation loss: 2.5371879034930442

Epoch: 6| Step: 5
Training loss: 2.2822485005765234
Validation loss: 2.548067574283187

Epoch: 6| Step: 6
Training loss: 2.747801508790958
Validation loss: 2.5559792553224514

Epoch: 6| Step: 7
Training loss: 2.1661549721999176
Validation loss: 2.55644621278666

Epoch: 6| Step: 8
Training loss: 2.414904006408631
Validation loss: 2.559663171501603

Epoch: 6| Step: 9
Training loss: 2.2311190911366046
Validation loss: 2.548839911071888

Epoch: 6| Step: 10
Training loss: 2.8649406256523333
Validation loss: 2.52098088318677

Epoch: 6| Step: 11
Training loss: 2.0504916322654134
Validation loss: 2.5530053685399934

Epoch: 6| Step: 12
Training loss: 2.2055988896316983
Validation loss: 2.5190456819479636

Epoch: 6| Step: 13
Training loss: 3.1591793856259516
Validation loss: 2.528589341658483

Epoch: 63| Step: 0
Training loss: 2.265151822894377
Validation loss: 2.559773242662981

Epoch: 6| Step: 1
Training loss: 2.5583613399335334
Validation loss: 2.552053791316314

Epoch: 6| Step: 2
Training loss: 2.1485573475095117
Validation loss: 2.533064831341402

Epoch: 6| Step: 3
Training loss: 2.672839609662258
Validation loss: 2.556960546081485

Epoch: 6| Step: 4
Training loss: 2.206530056649956
Validation loss: 2.5728676800305177

Epoch: 6| Step: 5
Training loss: 2.110507124392864
Validation loss: 2.5683364151579897

Epoch: 6| Step: 6
Training loss: 1.9291690639648482
Validation loss: 2.5587000545714056

Epoch: 6| Step: 7
Training loss: 2.7938166258375214
Validation loss: 2.5727010216993773

Epoch: 6| Step: 8
Training loss: 2.7147924624202258
Validation loss: 2.5482999641731916

Epoch: 6| Step: 9
Training loss: 2.2627187043595574
Validation loss: 2.5276746027248107

Epoch: 6| Step: 10
Training loss: 2.4755284409928127
Validation loss: 2.5457924412399993

Epoch: 6| Step: 11
Training loss: 2.5911761462612626
Validation loss: 2.5460038206596707

Epoch: 6| Step: 12
Training loss: 2.70998794679671
Validation loss: 2.5665774740682368

Epoch: 6| Step: 13
Training loss: 2.3665831143670046
Validation loss: 2.5316748949268355

Epoch: 64| Step: 0
Training loss: 2.8631440216944806
Validation loss: 2.514402704670206

Epoch: 6| Step: 1
Training loss: 2.4774085684494707
Validation loss: 2.5445557782563615

Epoch: 6| Step: 2
Training loss: 1.7063926357693404
Validation loss: 2.5594763323139267

Epoch: 6| Step: 3
Training loss: 2.079525239204733
Validation loss: 2.5500228089203834

Epoch: 6| Step: 4
Training loss: 2.534004408226605
Validation loss: 2.607546312122644

Epoch: 6| Step: 5
Training loss: 2.1773893758744993
Validation loss: 2.593195675977595

Epoch: 6| Step: 6
Training loss: 2.948966514461968
Validation loss: 2.609191263700826

Epoch: 6| Step: 7
Training loss: 2.4516909349884104
Validation loss: 2.5880688261660616

Epoch: 6| Step: 8
Training loss: 2.1364041782051886
Validation loss: 2.569864112215289

Epoch: 6| Step: 9
Training loss: 2.4828136023968503
Validation loss: 2.5902582434314523

Epoch: 6| Step: 10
Training loss: 2.7740843972126887
Validation loss: 2.5966347504842853

Epoch: 6| Step: 11
Training loss: 2.286839678570542
Validation loss: 2.5698866409257546

Epoch: 6| Step: 12
Training loss: 2.323920427939715
Validation loss: 2.571666990623363

Epoch: 6| Step: 13
Training loss: 2.2402464010752294
Validation loss: 2.5492748039614863

Epoch: 65| Step: 0
Training loss: 2.2829189727413226
Validation loss: 2.563087179008326

Epoch: 6| Step: 1
Training loss: 1.9925326179313874
Validation loss: 2.5154492334601213

Epoch: 6| Step: 2
Training loss: 3.0030098757078094
Validation loss: 2.5470050396319603

Epoch: 6| Step: 3
Training loss: 2.080284316181594
Validation loss: 2.5266233161270564

Epoch: 6| Step: 4
Training loss: 2.4769383094198925
Validation loss: 2.5489100183653055

Epoch: 6| Step: 5
Training loss: 2.2695490037023434
Validation loss: 2.533688520536595

Epoch: 6| Step: 6
Training loss: 2.5521457171438398
Validation loss: 2.5622322438850875

Epoch: 6| Step: 7
Training loss: 2.7458798147463135
Validation loss: 2.532410704810567

Epoch: 6| Step: 8
Training loss: 2.513401636448559
Validation loss: 2.5218561924166503

Epoch: 6| Step: 9
Training loss: 2.398497440943527
Validation loss: 2.52239972044095

Epoch: 6| Step: 10
Training loss: 2.467110197898882
Validation loss: 2.5458649580802364

Epoch: 6| Step: 11
Training loss: 2.252047666631313
Validation loss: 2.5371667132556057

Epoch: 6| Step: 12
Training loss: 2.327316451000625
Validation loss: 2.521440548445732

Epoch: 6| Step: 13
Training loss: 2.485665711819332
Validation loss: 2.558953723385189

Epoch: 66| Step: 0
Training loss: 2.057765033843582
Validation loss: 2.572043156061057

Epoch: 6| Step: 1
Training loss: 2.582953261031941
Validation loss: 2.5569906478410447

Epoch: 6| Step: 2
Training loss: 2.232754953655898
Validation loss: 2.56542435921284

Epoch: 6| Step: 3
Training loss: 2.450579057110569
Validation loss: 2.523024636459167

Epoch: 6| Step: 4
Training loss: 2.5000558846903216
Validation loss: 2.5602310959747245

Epoch: 6| Step: 5
Training loss: 2.2131217169232325
Validation loss: 2.53138887942761

Epoch: 6| Step: 6
Training loss: 2.633321560056741
Validation loss: 2.546749821806536

Epoch: 6| Step: 7
Training loss: 2.358670868549446
Validation loss: 2.552118127287265

Epoch: 6| Step: 8
Training loss: 1.8833437601436627
Validation loss: 2.5701353558966114

Epoch: 6| Step: 9
Training loss: 2.199711095740557
Validation loss: 2.5846151022829407

Epoch: 6| Step: 10
Training loss: 2.5486728430907717
Validation loss: 2.5808862560718553

Epoch: 6| Step: 11
Training loss: 2.8579016052670854
Validation loss: 2.566829420065396

Epoch: 6| Step: 12
Training loss: 2.7784992287789017
Validation loss: 2.580104060575707

Epoch: 6| Step: 13
Training loss: 2.379227138982243
Validation loss: 2.581177262950892

Epoch: 67| Step: 0
Training loss: 2.3360660989632946
Validation loss: 2.5577645936028297

Epoch: 6| Step: 1
Training loss: 2.763307710520354
Validation loss: 2.5567653577979965

Epoch: 6| Step: 2
Training loss: 1.6916330374896948
Validation loss: 2.557871103518384

Epoch: 6| Step: 3
Training loss: 2.104363485768753
Validation loss: 2.571016719548608

Epoch: 6| Step: 4
Training loss: 2.431652390784788
Validation loss: 2.553414481602424

Epoch: 6| Step: 5
Training loss: 2.5071837210362253
Validation loss: 2.541666833429383

Epoch: 6| Step: 6
Training loss: 3.0048588506011615
Validation loss: 2.56406908144853

Epoch: 6| Step: 7
Training loss: 2.59866419002336
Validation loss: 2.5284908232760936

Epoch: 6| Step: 8
Training loss: 2.332911237503805
Validation loss: 2.5429563585517587

Epoch: 6| Step: 9
Training loss: 2.341755743357503
Validation loss: 2.539632254033632

Epoch: 6| Step: 10
Training loss: 2.4282539284351405
Validation loss: 2.5452019280477463

Epoch: 6| Step: 11
Training loss: 1.8206875787123236
Validation loss: 2.5598718687988

Epoch: 6| Step: 12
Training loss: 2.5453188770230697
Validation loss: 2.537337749286256

Epoch: 6| Step: 13
Training loss: 2.4535586222923027
Validation loss: 2.5416241913253255

Epoch: 68| Step: 0
Training loss: 1.877469534595041
Validation loss: 2.5581778617819544

Epoch: 6| Step: 1
Training loss: 2.5179159974985232
Validation loss: 2.537527048502361

Epoch: 6| Step: 2
Training loss: 2.724005169341214
Validation loss: 2.582158865109897

Epoch: 6| Step: 3
Training loss: 2.519014243376027
Validation loss: 2.566785609185213

Epoch: 6| Step: 4
Training loss: 2.7144498470702163
Validation loss: 2.543350058317709

Epoch: 6| Step: 5
Training loss: 1.787384712396137
Validation loss: 2.5979263203514713

Epoch: 6| Step: 6
Training loss: 2.655677015549743
Validation loss: 2.576997814954197

Epoch: 6| Step: 7
Training loss: 1.5938593509035377
Validation loss: 2.5849745571967575

Epoch: 6| Step: 8
Training loss: 2.1554488753217917
Validation loss: 2.611332127052803

Epoch: 6| Step: 9
Training loss: 2.2917893347998937
Validation loss: 2.592674660582156

Epoch: 6| Step: 10
Training loss: 2.3554941558733002
Validation loss: 2.602444702499062

Epoch: 6| Step: 11
Training loss: 3.311566491214154
Validation loss: 2.5957396968487787

Epoch: 6| Step: 12
Training loss: 2.566929501126048
Validation loss: 2.563800016795976

Epoch: 6| Step: 13
Training loss: 2.0711311305301443
Validation loss: 2.5642960077302566

Epoch: 69| Step: 0
Training loss: 2.5801884572004443
Validation loss: 2.5481567901806494

Epoch: 6| Step: 1
Training loss: 2.5506046812392777
Validation loss: 2.505894562337184

Epoch: 6| Step: 2
Training loss: 2.013178797384688
Validation loss: 2.5549376167948004

Epoch: 6| Step: 3
Training loss: 2.889667909278768
Validation loss: 2.5400193822426584

Epoch: 6| Step: 4
Training loss: 2.0376373806373653
Validation loss: 2.5764967429408654

Epoch: 6| Step: 5
Training loss: 2.4839672977672134
Validation loss: 2.5487203017383697

Epoch: 6| Step: 6
Training loss: 2.538774585539094
Validation loss: 2.576521511611647

Epoch: 6| Step: 7
Training loss: 2.5556250668714835
Validation loss: 2.568667255315739

Epoch: 6| Step: 8
Training loss: 2.251858050017629
Validation loss: 2.5755932177074836

Epoch: 6| Step: 9
Training loss: 1.9033577662345564
Validation loss: 2.5722406454184075

Epoch: 6| Step: 10
Training loss: 2.5997728945507848
Validation loss: 2.6009880248804476

Epoch: 6| Step: 11
Training loss: 2.3142666641002974
Validation loss: 2.588759389479927

Epoch: 6| Step: 12
Training loss: 2.369921625507342
Validation loss: 2.5692097656944184

Epoch: 6| Step: 13
Training loss: 2.4426512450574003
Validation loss: 2.5452019280477463

Epoch: 70| Step: 0
Training loss: 1.9988291412583528
Validation loss: 2.5471049791969405

Epoch: 6| Step: 1
Training loss: 3.0088152118203997
Validation loss: 2.5389491833562934

Epoch: 6| Step: 2
Training loss: 1.8783781772778823
Validation loss: 2.553571186897706

Epoch: 6| Step: 3
Training loss: 2.6015960416264
Validation loss: 2.5290884828083215

Epoch: 6| Step: 4
Training loss: 2.7535346463602113
Validation loss: 2.5744544053062213

Epoch: 6| Step: 5
Training loss: 2.3011687750626293
Validation loss: 2.5473649659461075

Epoch: 6| Step: 6
Training loss: 2.774437694455628
Validation loss: 2.541899253542539

Epoch: 6| Step: 7
Training loss: 2.057925381819329
Validation loss: 2.5590413485862653

Epoch: 6| Step: 8
Training loss: 2.492281346960741
Validation loss: 2.562945629541874

Epoch: 6| Step: 9
Training loss: 2.054843911139118
Validation loss: 2.567546279673371

Epoch: 6| Step: 10
Training loss: 2.228517657721192
Validation loss: 2.5560281640184113

Epoch: 6| Step: 11
Training loss: 2.0941205052748977
Validation loss: 2.56740054954766

Epoch: 6| Step: 12
Training loss: 2.7956525805771792
Validation loss: 2.5729887382101735

Epoch: 6| Step: 13
Training loss: 2.4715438678852837
Validation loss: 2.5865972316982266

Epoch: 71| Step: 0
Training loss: 2.0166993346077335
Validation loss: 2.540328272734849

Epoch: 6| Step: 1
Training loss: 2.000668175662543
Validation loss: 2.553614290838679

Epoch: 6| Step: 2
Training loss: 2.2045530195741
Validation loss: 2.588826665917313

Epoch: 6| Step: 3
Training loss: 2.4463392545686715
Validation loss: 2.5856136952916033

Epoch: 6| Step: 4
Training loss: 2.7678857388755156
Validation loss: 2.587930147840888

Epoch: 6| Step: 5
Training loss: 2.923551190855354
Validation loss: 2.6312460385109264

Epoch: 6| Step: 6
Training loss: 2.369245886921168
Validation loss: 2.63315069213087

Epoch: 6| Step: 7
Training loss: 2.586929085076945
Validation loss: 2.6572083932072452

Epoch: 6| Step: 8
Training loss: 2.1839097123679134
Validation loss: 2.593849302788537

Epoch: 6| Step: 9
Training loss: 1.8989768812229684
Validation loss: 2.5924412133158774

Epoch: 6| Step: 10
Training loss: 1.8939835533427003
Validation loss: 2.55553071613495

Epoch: 6| Step: 11
Training loss: 2.5515326288533946
Validation loss: 2.553011267505072

Epoch: 6| Step: 12
Training loss: 2.195007628859903
Validation loss: 2.5549824862243833

Epoch: 6| Step: 13
Training loss: 3.2207473927654386
Validation loss: 2.5372103308095135

Epoch: 72| Step: 0
Training loss: 2.441547652155112
Validation loss: 2.553342490424659

Epoch: 6| Step: 1
Training loss: 2.357527053370342
Validation loss: 2.550107351860801

Epoch: 6| Step: 2
Training loss: 2.566623161822449
Validation loss: 2.5173344934452073

Epoch: 6| Step: 3
Training loss: 2.169603655784475
Validation loss: 2.5362510178665616

Epoch: 6| Step: 4
Training loss: 2.451615567724014
Validation loss: 2.523014359875694

Epoch: 6| Step: 5
Training loss: 2.566530546897258
Validation loss: 2.537591815408622

Epoch: 6| Step: 6
Training loss: 2.232616452792723
Validation loss: 2.5159698313171366

Epoch: 6| Step: 7
Training loss: 1.8965447806138556
Validation loss: 2.550080277544371

Epoch: 6| Step: 8
Training loss: 2.2760401768683147
Validation loss: 2.554169029641316

Epoch: 6| Step: 9
Training loss: 2.773008845340283
Validation loss: 2.5458438634784732

Epoch: 6| Step: 10
Training loss: 2.362993913317383
Validation loss: 2.5544461788636017

Epoch: 6| Step: 11
Training loss: 1.6253645561344492
Validation loss: 2.5323302550195677

Epoch: 6| Step: 12
Training loss: 2.3939059811759953
Validation loss: 2.5490248641942346

Epoch: 6| Step: 13
Training loss: 3.1528159618632805
Validation loss: 2.539225255200321

Epoch: 73| Step: 0
Training loss: 1.9046596709699186
Validation loss: 2.5313085776878275

Epoch: 6| Step: 1
Training loss: 2.4547106240954095
Validation loss: 2.524266456209079

Epoch: 6| Step: 2
Training loss: 2.5493807021944916
Validation loss: 2.553311474144629

Epoch: 6| Step: 3
Training loss: 1.8479639809223494
Validation loss: 2.539935504777846

Epoch: 6| Step: 4
Training loss: 3.2885092226896435
Validation loss: 2.5827451979862333

Epoch: 6| Step: 5
Training loss: 2.3570905324569615
Validation loss: 2.5738281586562555

Epoch: 6| Step: 6
Training loss: 2.2108682682264638
Validation loss: 2.589831291310688

Epoch: 6| Step: 7
Training loss: 2.127102877246567
Validation loss: 2.560303296982462

Epoch: 6| Step: 8
Training loss: 2.631220214385211
Validation loss: 2.5730352773366882

Epoch: 6| Step: 9
Training loss: 2.4439101417929523
Validation loss: 2.594231909292868

Epoch: 6| Step: 10
Training loss: 2.4793948755027775
Validation loss: 2.579678539412286

Epoch: 6| Step: 11
Training loss: 2.2183029369141347
Validation loss: 2.5642236402089678

Epoch: 6| Step: 12
Training loss: 2.299965990893156
Validation loss: 2.5727194325658176

Epoch: 6| Step: 13
Training loss: 2.2479263922970314
Validation loss: 2.525603664742003

Epoch: 74| Step: 0
Training loss: 2.863580664661371
Validation loss: 2.5715992227731355

Epoch: 6| Step: 1
Training loss: 1.5941970796504017
Validation loss: 2.5581207847731355

Epoch: 6| Step: 2
Training loss: 2.711021400054816
Validation loss: 2.5360681650184476

Epoch: 6| Step: 3
Training loss: 2.0604064025726108
Validation loss: 2.5472641474015547

Epoch: 6| Step: 4
Training loss: 2.317316657985629
Validation loss: 2.5384800169456714

Epoch: 6| Step: 5
Training loss: 2.328938591651588
Validation loss: 2.5252729104741274

Epoch: 6| Step: 6
Training loss: 2.389291428749147
Validation loss: 2.5584752489753635

Epoch: 6| Step: 7
Training loss: 2.0197322900342467
Validation loss: 2.5255824717114703

Epoch: 6| Step: 8
Training loss: 1.7112476642556478
Validation loss: 2.5481476051887944

Epoch: 6| Step: 9
Training loss: 2.341393264973795
Validation loss: 2.556402519295942

Epoch: 6| Step: 10
Training loss: 3.1093021556813527
Validation loss: 2.5491354960389474

Epoch: 6| Step: 11
Training loss: 2.631598580437756
Validation loss: 2.527112687882029

Epoch: 6| Step: 12
Training loss: 2.7081027201746943
Validation loss: 2.5702506911122827

Epoch: 6| Step: 13
Training loss: 2.2161053221631137
Validation loss: 2.5689484011471206

Epoch: 75| Step: 0
Training loss: 2.930996615066578
Validation loss: 2.586244424697474

Epoch: 6| Step: 1
Training loss: 2.708723675890832
Validation loss: 2.541148888633743

Epoch: 6| Step: 2
Training loss: 2.1149205532438335
Validation loss: 2.54189976941745

Epoch: 6| Step: 3
Training loss: 1.7464287967665022
Validation loss: 2.5362368310066614

Epoch: 6| Step: 4
Training loss: 2.0945230451833656
Validation loss: 2.5408854665023477

Epoch: 6| Step: 5
Training loss: 2.8659858368272744
Validation loss: 2.5161686501363043

Epoch: 6| Step: 6
Training loss: 2.282034438619766
Validation loss: 2.5251304215089334

Epoch: 6| Step: 7
Training loss: 2.5458744634707426
Validation loss: 2.552436015354277

Epoch: 6| Step: 8
Training loss: 2.49703001990126
Validation loss: 2.551413729789062

Epoch: 6| Step: 9
Training loss: 2.080094171739747
Validation loss: 2.562693239694831

Epoch: 6| Step: 10
Training loss: 2.22844619041014
Validation loss: 2.5193654718000422

Epoch: 6| Step: 11
Training loss: 1.6392422616603473
Validation loss: 2.539953801142948

Epoch: 6| Step: 12
Training loss: 2.570797859907528
Validation loss: 2.545076831502266

Epoch: 6| Step: 13
Training loss: 2.306730341317275
Validation loss: 2.557481923118687

Epoch: 76| Step: 0
Training loss: 2.460731521947876
Validation loss: 2.5413633280195183

Epoch: 6| Step: 1
Training loss: 2.5299750991018066
Validation loss: 2.552026854428591

Epoch: 6| Step: 2
Training loss: 2.642968937633935
Validation loss: 2.5579989996613115

Epoch: 6| Step: 3
Training loss: 1.9508567150767402
Validation loss: 2.549483790537947

Epoch: 6| Step: 4
Training loss: 2.848633314674707
Validation loss: 2.5847546656441915

Epoch: 6| Step: 5
Training loss: 1.842243548989309
Validation loss: 2.5859815242281394

Epoch: 6| Step: 6
Training loss: 2.028938504132702
Validation loss: 2.5712913960370076

Epoch: 6| Step: 7
Training loss: 2.6888704576027003
Validation loss: 2.5614145662763064

Epoch: 6| Step: 8
Training loss: 2.6780353936213253
Validation loss: 2.5697204773784867

Epoch: 6| Step: 9
Training loss: 2.456599599405014
Validation loss: 2.537827458416836

Epoch: 6| Step: 10
Training loss: 3.2235098893085046
Validation loss: 2.5373153074352217

Epoch: 6| Step: 11
Training loss: 1.741626871679537
Validation loss: 2.5407625893861447

Epoch: 6| Step: 12
Training loss: 2.1962006967967094
Validation loss: 2.551547532700547

Epoch: 6| Step: 13
Training loss: 1.770285203660988
Validation loss: 2.5464971687255713

Epoch: 77| Step: 0
Training loss: 1.6261162958445143
Validation loss: 2.534434760063712

Epoch: 6| Step: 1
Training loss: 2.03080251606426
Validation loss: 2.5245643989074145

Epoch: 6| Step: 2
Training loss: 2.2290344436743066
Validation loss: 2.5527823652111628

Epoch: 6| Step: 3
Training loss: 2.8899571652521403
Validation loss: 2.5495189368809097

Epoch: 6| Step: 4
Training loss: 2.367551366456246
Validation loss: 2.535992578960917

Epoch: 6| Step: 5
Training loss: 2.083003005224762
Validation loss: 2.542817235789648

Epoch: 6| Step: 6
Training loss: 2.048358292434053
Validation loss: 2.519775410337288

Epoch: 6| Step: 7
Training loss: 2.4326401215172435
Validation loss: 2.542884305693584

Epoch: 6| Step: 8
Training loss: 2.8128303333840665
Validation loss: 2.564845089810878

Epoch: 6| Step: 9
Training loss: 2.415623724814963
Validation loss: 2.549472794542672

Epoch: 6| Step: 10
Training loss: 2.540636155970856
Validation loss: 2.5684072125020565

Epoch: 6| Step: 11
Training loss: 2.436748682286501
Validation loss: 2.550233339093036

Epoch: 6| Step: 12
Training loss: 2.172742601727272
Validation loss: 2.585721209528584

Epoch: 6| Step: 13
Training loss: 2.7501713092505
Validation loss: 2.5572153897120176

Epoch: 78| Step: 0
Training loss: 2.198078408700631
Validation loss: 2.559838005543324

Epoch: 6| Step: 1
Training loss: 2.3756963813171947
Validation loss: 2.5200275730713577

Epoch: 6| Step: 2
Training loss: 1.986569070221599
Validation loss: 2.5660427848349125

Epoch: 6| Step: 3
Training loss: 2.4298450872704467
Validation loss: 2.558062533689207

Epoch: 6| Step: 4
Training loss: 2.6909067606740136
Validation loss: 2.5355118089271893

Epoch: 6| Step: 5
Training loss: 1.9034767615039836
Validation loss: 2.5446571101121727

Epoch: 6| Step: 6
Training loss: 2.8532415593917446
Validation loss: 2.55205729464787

Epoch: 6| Step: 7
Training loss: 1.9711222207715482
Validation loss: 2.5728175624237117

Epoch: 6| Step: 8
Training loss: 2.383559813331318
Validation loss: 2.552310362598361

Epoch: 6| Step: 9
Training loss: 2.435067748394286
Validation loss: 2.5634299970969123

Epoch: 6| Step: 10
Training loss: 2.692439485824456
Validation loss: 2.545382961720898

Epoch: 6| Step: 11
Training loss: 2.6266610475986747
Validation loss: 2.5460978533421166

Epoch: 6| Step: 12
Training loss: 2.4150455781730744
Validation loss: 2.55489800351001

Epoch: 6| Step: 13
Training loss: 1.6479050196619052
Validation loss: 2.5748807126411233

Epoch: 79| Step: 0
Training loss: 2.4707704798748895
Validation loss: 2.5334344707762795

Epoch: 6| Step: 1
Training loss: 2.133450032062303
Validation loss: 2.5528039239322284

Epoch: 6| Step: 2
Training loss: 1.8379189046210334
Validation loss: 2.5556519813820535

Epoch: 6| Step: 3
Training loss: 2.1279957915529786
Validation loss: 2.5376746820667067

Epoch: 6| Step: 4
Training loss: 2.0462672372323842
Validation loss: 2.545659795320848

Epoch: 6| Step: 5
Training loss: 2.4668189113475347
Validation loss: 2.541715032607197

Epoch: 6| Step: 6
Training loss: 2.206528651981796
Validation loss: 2.5463723620860064

Epoch: 6| Step: 7
Training loss: 2.2414925059717223
Validation loss: 2.5735441876369265

Epoch: 6| Step: 8
Training loss: 2.3313548578401893
Validation loss: 2.55187931932116

Epoch: 6| Step: 9
Training loss: 2.6754128752473982
Validation loss: 2.5204946563665067

Epoch: 6| Step: 10
Training loss: 2.7013809663797512
Validation loss: 2.562513692555635

Epoch: 6| Step: 11
Training loss: 2.3188365005028824
Validation loss: 2.5532337995091345

Epoch: 6| Step: 12
Training loss: 2.8720284737474513
Validation loss: 2.5714125825117438

Epoch: 6| Step: 13
Training loss: 2.3984158294394575
Validation loss: 2.546767640142579

Epoch: 80| Step: 0
Training loss: 2.308491092987757
Validation loss: 2.5508567483428193

Epoch: 6| Step: 1
Training loss: 2.789084383667649
Validation loss: 2.5677277497852873

Epoch: 6| Step: 2
Training loss: 2.5302110588485176
Validation loss: 2.5381177817295804

Epoch: 6| Step: 3
Training loss: 2.466673545140479
Validation loss: 2.553111337713124

Epoch: 6| Step: 4
Training loss: 1.9911787882665513
Validation loss: 2.564823709766537

Epoch: 6| Step: 5
Training loss: 2.0331809622576307
Validation loss: 2.5869339850601687

Epoch: 6| Step: 6
Training loss: 1.8930043782759391
Validation loss: 2.5665722023519546

Epoch: 6| Step: 7
Training loss: 1.9095971160908447
Validation loss: 2.5635004106653594

Epoch: 6| Step: 8
Training loss: 2.1976458004439623
Validation loss: 2.535914342511662

Epoch: 6| Step: 9
Training loss: 1.972097245884683
Validation loss: 2.553876913498682

Epoch: 6| Step: 10
Training loss: 2.5021379865595303
Validation loss: 2.5570062347254545

Epoch: 6| Step: 11
Training loss: 2.4774486027533786
Validation loss: 2.5534867508599732

Epoch: 6| Step: 12
Training loss: 2.7250270947150512
Validation loss: 2.5340900422437023

Epoch: 6| Step: 13
Training loss: 2.849711447045279
Validation loss: 2.519294053378749

Epoch: 81| Step: 0
Training loss: 2.2762365774212445
Validation loss: 2.538688217355446

Epoch: 6| Step: 1
Training loss: 2.171116758309062
Validation loss: 2.5441205785004417

Epoch: 6| Step: 2
Training loss: 2.5003514996426275
Validation loss: 2.5386351240379676

Epoch: 6| Step: 3
Training loss: 1.8742063114060399
Validation loss: 2.539593951041662

Epoch: 6| Step: 4
Training loss: 2.2405340498124864
Validation loss: 2.5370160272392988

Epoch: 6| Step: 5
Training loss: 2.064196726775589
Validation loss: 2.5556513283470244

Epoch: 6| Step: 6
Training loss: 3.2950292546040147
Validation loss: 2.5207106873072567

Epoch: 6| Step: 7
Training loss: 2.741262774492062
Validation loss: 2.555447915362649

Epoch: 6| Step: 8
Training loss: 1.9927655148182764
Validation loss: 2.53559370924721

Epoch: 6| Step: 9
Training loss: 2.4000558767171953
Validation loss: 2.538897011083312

Epoch: 6| Step: 10
Training loss: 2.4383136662776286
Validation loss: 2.557976024498426

Epoch: 6| Step: 11
Training loss: 2.650716965331805
Validation loss: 2.558941083245006

Epoch: 6| Step: 12
Training loss: 2.478853243295059
Validation loss: 2.5422524001378126

Epoch: 6| Step: 13
Training loss: 1.4974762029778996
Validation loss: 2.558617977580904

Epoch: 82| Step: 0
Training loss: 2.5931996140740567
Validation loss: 2.582130957297589

Epoch: 6| Step: 1
Training loss: 2.262191802051183
Validation loss: 2.5670169779106233

Epoch: 6| Step: 2
Training loss: 1.971141573597562
Validation loss: 2.566584874579726

Epoch: 6| Step: 3
Training loss: 2.5943933631212177
Validation loss: 2.5880294129205184

Epoch: 6| Step: 4
Training loss: 2.152575914769943
Validation loss: 2.5956479983555134

Epoch: 6| Step: 5
Training loss: 1.8957875913474478
Validation loss: 2.5886949587179813

Epoch: 6| Step: 6
Training loss: 2.3715821820471694
Validation loss: 2.6078135678407417

Epoch: 6| Step: 7
Training loss: 1.9848408189842157
Validation loss: 2.622010057113374

Epoch: 6| Step: 8
Training loss: 3.0670934988222283
Validation loss: 2.5984753992647116

Epoch: 6| Step: 9
Training loss: 1.9164408329589253
Validation loss: 2.588537647287688

Epoch: 6| Step: 10
Training loss: 2.2219606192572976
Validation loss: 2.5931899756872974

Epoch: 6| Step: 11
Training loss: 2.3056095671040295
Validation loss: 2.5697775518872197

Epoch: 6| Step: 12
Training loss: 2.7917371048272943
Validation loss: 2.570857932242533

Epoch: 6| Step: 13
Training loss: 2.3632312107305737
Validation loss: 2.537756262055401

Epoch: 83| Step: 0
Training loss: 2.3189563834171003
Validation loss: 2.5518007913525613

Epoch: 6| Step: 1
Training loss: 2.053541552877202
Validation loss: 2.548126443714827

Epoch: 6| Step: 2
Training loss: 2.7075314630739116
Validation loss: 2.5463388420814757

Epoch: 6| Step: 3
Training loss: 2.80451425001333
Validation loss: 2.546816647725101

Epoch: 6| Step: 4
Training loss: 2.082811391934603
Validation loss: 2.523738343185301

Epoch: 6| Step: 5
Training loss: 2.3810741649998506
Validation loss: 2.547179783095828

Epoch: 6| Step: 6
Training loss: 2.4117590522426195
Validation loss: 2.554773428402148

Epoch: 6| Step: 7
Training loss: 2.9482407318748476
Validation loss: 2.5643509793378754

Epoch: 6| Step: 8
Training loss: 1.751611240331558
Validation loss: 2.540706677314553

Epoch: 6| Step: 9
Training loss: 2.218837467672379
Validation loss: 2.536403308143618

Epoch: 6| Step: 10
Training loss: 2.489110883205407
Validation loss: 2.517655195107629

Epoch: 6| Step: 11
Training loss: 2.1496974510409514
Validation loss: 2.546125851780237

Epoch: 6| Step: 12
Training loss: 1.7757255146025381
Validation loss: 2.5238960408516133

Epoch: 6| Step: 13
Training loss: 2.531674196467734
Validation loss: 2.5291032046840707

Epoch: 84| Step: 0
Training loss: 2.228610519006959
Validation loss: 2.5605370826640637

Epoch: 6| Step: 1
Training loss: 1.8207381246133147
Validation loss: 2.5491213263272234

Epoch: 6| Step: 2
Training loss: 1.7258163842302683
Validation loss: 2.5329979406831113

Epoch: 6| Step: 3
Training loss: 2.556533939475752
Validation loss: 2.5646871986294473

Epoch: 6| Step: 4
Training loss: 2.139904374276707
Validation loss: 2.5485547227248833

Epoch: 6| Step: 5
Training loss: 2.7860575069782643
Validation loss: 2.5451307740428346

Epoch: 6| Step: 6
Training loss: 1.7053927800885202
Validation loss: 2.541581470333183

Epoch: 6| Step: 7
Training loss: 3.082144190044901
Validation loss: 2.5317683062095773

Epoch: 6| Step: 8
Training loss: 2.7567103617786533
Validation loss: 2.546251856547749

Epoch: 6| Step: 9
Training loss: 2.076050375310685
Validation loss: 2.537041001234286

Epoch: 6| Step: 10
Training loss: 2.406499280031066
Validation loss: 2.531060482512754

Epoch: 6| Step: 11
Training loss: 1.9435041364111039
Validation loss: 2.554668461439953

Epoch: 6| Step: 12
Training loss: 2.527945822648277
Validation loss: 2.525262407006571

Epoch: 6| Step: 13
Training loss: 2.5134631991373912
Validation loss: 2.5540647846290896

Epoch: 85| Step: 0
Training loss: 2.6834620814109904
Validation loss: 2.5404568487110266

Epoch: 6| Step: 1
Training loss: 2.637914225516372
Validation loss: 2.529512790414093

Epoch: 6| Step: 2
Training loss: 2.248893465700045
Validation loss: 2.5627744419171656

Epoch: 6| Step: 3
Training loss: 2.3658151205001645
Validation loss: 2.5411287634895783

Epoch: 6| Step: 4
Training loss: 2.606257603769165
Validation loss: 2.5095793935749158

Epoch: 6| Step: 5
Training loss: 2.5763812092143645
Validation loss: 2.576007104115533

Epoch: 6| Step: 6
Training loss: 2.161924883268893
Validation loss: 2.5533025566998533

Epoch: 6| Step: 7
Training loss: 1.5122326512148012
Validation loss: 2.5531863469411364

Epoch: 6| Step: 8
Training loss: 1.983156145285863
Validation loss: 2.5653132371207845

Epoch: 6| Step: 9
Training loss: 2.0248664906135345
Validation loss: 2.5819971310298944

Epoch: 6| Step: 10
Training loss: 2.694222669443174
Validation loss: 2.5681589181318416

Epoch: 6| Step: 11
Training loss: 2.3329321879748166
Validation loss: 2.5537639352272303

Epoch: 6| Step: 12
Training loss: 1.998832063594633
Validation loss: 2.5979344728089573

Epoch: 6| Step: 13
Training loss: 2.532691827496272
Validation loss: 2.5875940615992095

Epoch: 86| Step: 0
Training loss: 2.8414756986675362
Validation loss: 2.5971246237501715

Epoch: 6| Step: 1
Training loss: 2.311929271480714
Validation loss: 2.5716767869339403

Epoch: 6| Step: 2
Training loss: 1.9890166535828655
Validation loss: 2.5725013819901807

Epoch: 6| Step: 3
Training loss: 2.368202218603695
Validation loss: 2.583473299193052

Epoch: 6| Step: 4
Training loss: 1.7834936367014436
Validation loss: 2.56283791957889

Epoch: 6| Step: 5
Training loss: 1.720062171122915
Validation loss: 2.5827749223046688

Epoch: 6| Step: 6
Training loss: 2.3327926849525267
Validation loss: 2.570332334803273

Epoch: 6| Step: 7
Training loss: 2.587621595686073
Validation loss: 2.5587650309687873

Epoch: 6| Step: 8
Training loss: 2.789157555934439
Validation loss: 2.5839915103674476

Epoch: 6| Step: 9
Training loss: 2.619773566383846
Validation loss: 2.5494012765542586

Epoch: 6| Step: 10
Training loss: 1.612286498846906
Validation loss: 2.560846617201085

Epoch: 6| Step: 11
Training loss: 1.7713418417455744
Validation loss: 2.586548432465569

Epoch: 6| Step: 12
Training loss: 2.448862247591363
Validation loss: 2.5788122243765743

Epoch: 6| Step: 13
Training loss: 2.718307108266296
Validation loss: 2.558940213650757

Epoch: 87| Step: 0
Training loss: 1.8175570872286468
Validation loss: 2.5687881943337465

Epoch: 6| Step: 1
Training loss: 2.5783580327921243
Validation loss: 2.5507807670775846

Epoch: 6| Step: 2
Training loss: 2.5619714703605516
Validation loss: 2.554178605251404

Epoch: 6| Step: 3
Training loss: 2.335491431267711
Validation loss: 2.5444626880622874

Epoch: 6| Step: 4
Training loss: 1.695400183031838
Validation loss: 2.518872220692311

Epoch: 6| Step: 5
Training loss: 2.614414761847583
Validation loss: 2.5199906435545545

Epoch: 6| Step: 6
Training loss: 2.482657168542631
Validation loss: 2.5478082674870106

Epoch: 6| Step: 7
Training loss: 2.6536454839334955
Validation loss: 2.5650756885993853

Epoch: 6| Step: 8
Training loss: 2.0447467484854682
Validation loss: 2.5039791388175874

Epoch: 6| Step: 9
Training loss: 2.230186431173804
Validation loss: 2.5413604197457977

Epoch: 6| Step: 10
Training loss: 1.7621486502997339
Validation loss: 2.5550664529289357

Epoch: 6| Step: 11
Training loss: 1.9362018296989572
Validation loss: 2.5556419837084436

Epoch: 6| Step: 12
Training loss: 2.9536054916644887
Validation loss: 2.586788271875409

Epoch: 6| Step: 13
Training loss: 2.3137727276527165
Validation loss: 2.5516310362401464

Epoch: 88| Step: 0
Training loss: 2.838916401523452
Validation loss: 2.571021093460297

Epoch: 6| Step: 1
Training loss: 2.3749419757380514
Validation loss: 2.5891312452884416

Epoch: 6| Step: 2
Training loss: 2.1871812860733364
Validation loss: 2.5594640595991103

Epoch: 6| Step: 3
Training loss: 1.7422705660462956
Validation loss: 2.538529168871604

Epoch: 6| Step: 4
Training loss: 2.31614150903354
Validation loss: 2.5357151444047976

Epoch: 6| Step: 5
Training loss: 2.179532062635107
Validation loss: 2.5503628802931484

Epoch: 6| Step: 6
Training loss: 2.0668054205963475
Validation loss: 2.544529652128966

Epoch: 6| Step: 7
Training loss: 2.274992420896544
Validation loss: 2.548787278667759

Epoch: 6| Step: 8
Training loss: 2.414516862991672
Validation loss: 2.5649283308510085

Epoch: 6| Step: 9
Training loss: 2.8041547093885155
Validation loss: 2.5846338587579267

Epoch: 6| Step: 10
Training loss: 2.4542992569533744
Validation loss: 2.587863370164067

Epoch: 6| Step: 11
Training loss: 2.72857827597296
Validation loss: 2.563853642901172

Epoch: 6| Step: 12
Training loss: 1.9746611727024865
Validation loss: 2.509042598613606

Epoch: 6| Step: 13
Training loss: 1.8673958761865246
Validation loss: 2.5795042567845576

Epoch: 89| Step: 0
Training loss: 2.6464284292691342
Validation loss: 2.540780355873527

Epoch: 6| Step: 1
Training loss: 2.2854961435923467
Validation loss: 2.5436052892014556

Epoch: 6| Step: 2
Training loss: 2.2448588019744142
Validation loss: 2.542950303440019

Epoch: 6| Step: 3
Training loss: 2.574663369850143
Validation loss: 2.550133303978899

Epoch: 6| Step: 4
Training loss: 2.5068857732677814
Validation loss: 2.5611272406834424

Epoch: 6| Step: 5
Training loss: 2.483584104161042
Validation loss: 2.5250553106160925

Epoch: 6| Step: 6
Training loss: 2.3782595301910043
Validation loss: 2.575033133333729

Epoch: 6| Step: 7
Training loss: 2.4844309482632503
Validation loss: 2.556901227328081

Epoch: 6| Step: 8
Training loss: 2.3059745686130384
Validation loss: 2.558657005246429

Epoch: 6| Step: 9
Training loss: 2.339718619489059
Validation loss: 2.558959911440879

Epoch: 6| Step: 10
Training loss: 1.9023406794403799
Validation loss: 2.563401102559994

Epoch: 6| Step: 11
Training loss: 1.8910938028504032
Validation loss: 2.564999764475276

Epoch: 6| Step: 12
Training loss: 1.976546939592592
Validation loss: 2.533927804021304

Epoch: 6| Step: 13
Training loss: 2.1322223000423985
Validation loss: 2.5625017212652614

Epoch: 90| Step: 0
Training loss: 2.124530964867001
Validation loss: 2.5636838566359974

Epoch: 6| Step: 1
Training loss: 2.451510730437498
Validation loss: 2.5532306868718133

Epoch: 6| Step: 2
Training loss: 2.172989922736685
Validation loss: 2.567388043858386

Epoch: 6| Step: 3
Training loss: 2.5632358517938583
Validation loss: 2.5488809124582423

Epoch: 6| Step: 4
Training loss: 2.147261974212946
Validation loss: 2.5649727311646107

Epoch: 6| Step: 5
Training loss: 2.658861738761459
Validation loss: 2.5325259379759157

Epoch: 6| Step: 6
Training loss: 1.8843954562821303
Validation loss: 2.546521683039424

Epoch: 6| Step: 7
Training loss: 2.300074729534693
Validation loss: 2.530541371811628

Epoch: 6| Step: 8
Training loss: 2.229084500613753
Validation loss: 2.5637097488187215

Epoch: 6| Step: 9
Training loss: 2.0556805317778513
Validation loss: 2.5588507370343794

Epoch: 6| Step: 10
Training loss: 2.280806302333328
Validation loss: 2.5217438044056717

Epoch: 6| Step: 11
Training loss: 1.9489874387192443
Validation loss: 2.538500851843221

Epoch: 6| Step: 12
Training loss: 2.763135662563057
Validation loss: 2.5414304362929703

Epoch: 6| Step: 13
Training loss: 2.264747818135285
Validation loss: 2.5596956321584954

Epoch: 91| Step: 0
Training loss: 2.009184016381309
Validation loss: 2.5456839586837554

Epoch: 6| Step: 1
Training loss: 2.2569502401685066
Validation loss: 2.5687723386215517

Epoch: 6| Step: 2
Training loss: 2.3468483345558817
Validation loss: 2.551966113038925

Epoch: 6| Step: 3
Training loss: 2.883217387725527
Validation loss: 2.53414870324668

Epoch: 6| Step: 4
Training loss: 2.049555995588492
Validation loss: 2.535941293854225

Epoch: 6| Step: 5
Training loss: 2.4442945805280765
Validation loss: 2.580360214286883

Epoch: 6| Step: 6
Training loss: 3.041909108014791
Validation loss: 2.5696544635845995

Epoch: 6| Step: 7
Training loss: 2.1322249836473386
Validation loss: 2.531621544653284

Epoch: 6| Step: 8
Training loss: 2.3973769039180506
Validation loss: 2.520673420985886

Epoch: 6| Step: 9
Training loss: 2.1166631182943725
Validation loss: 2.545057697628887

Epoch: 6| Step: 10
Training loss: 1.9588318724522817
Validation loss: 2.548241621138098

Epoch: 6| Step: 11
Training loss: 1.7372190509037004
Validation loss: 2.5492152518083655

Epoch: 6| Step: 12
Training loss: 2.074675256526656
Validation loss: 2.575174442727954

Epoch: 6| Step: 13
Training loss: 2.407463263273953
Validation loss: 2.5597800574343808

Epoch: 92| Step: 0
Training loss: 2.0104173913931325
Validation loss: 2.5857895177812393

Epoch: 6| Step: 1
Training loss: 1.8298979419119856
Validation loss: 2.601505542395101

Epoch: 6| Step: 2
Training loss: 2.6427066881663115
Validation loss: 2.595480490982849

Epoch: 6| Step: 3
Training loss: 1.8215383568703478
Validation loss: 2.575313645924126

Epoch: 6| Step: 4
Training loss: 2.31527327158438
Validation loss: 2.609086414757109

Epoch: 6| Step: 5
Training loss: 2.7518706461646514
Validation loss: 2.619655087338105

Epoch: 6| Step: 6
Training loss: 2.2853955787467037
Validation loss: 2.5927910928071203

Epoch: 6| Step: 7
Training loss: 1.9310938231888501
Validation loss: 2.5552397042697086

Epoch: 6| Step: 8
Training loss: 2.480379742805135
Validation loss: 2.5686125849269503

Epoch: 6| Step: 9
Training loss: 2.481928838694909
Validation loss: 2.5762871404836765

Epoch: 6| Step: 10
Training loss: 2.6123065128498295
Validation loss: 2.551777526802673

Epoch: 6| Step: 11
Training loss: 2.358329692968068
Validation loss: 2.572856505973783

Epoch: 6| Step: 12
Training loss: 2.175222986125256
Validation loss: 2.5656541315454557

Epoch: 6| Step: 13
Training loss: 2.231919760317965
Validation loss: 2.5347952955561794

Epoch: 93| Step: 0
Training loss: 2.5021948716212385
Validation loss: 2.5344066011126123

Epoch: 6| Step: 1
Training loss: 1.8778555424455463
Validation loss: 2.5438495913293453

Epoch: 6| Step: 2
Training loss: 2.4952221036528224
Validation loss: 2.53949679841923

Epoch: 6| Step: 3
Training loss: 2.080473641057842
Validation loss: 2.565649446470856

Epoch: 6| Step: 4
Training loss: 2.1732580597641493
Validation loss: 2.5270043547622603

Epoch: 6| Step: 5
Training loss: 2.2603272685524796
Validation loss: 2.5698847545210612

Epoch: 6| Step: 6
Training loss: 2.4190690059399436
Validation loss: 2.56535544673439

Epoch: 6| Step: 7
Training loss: 2.6789967172053646
Validation loss: 2.569224798992723

Epoch: 6| Step: 8
Training loss: 2.8078958761141113
Validation loss: 2.5806784113189116

Epoch: 6| Step: 9
Training loss: 2.1678018041717766
Validation loss: 2.5597946959366604

Epoch: 6| Step: 10
Training loss: 2.6417955140501355
Validation loss: 2.5717142721563193

Epoch: 6| Step: 11
Training loss: 1.8836804680499533
Validation loss: 2.5647945365634586

Epoch: 6| Step: 12
Training loss: 1.4956185405382885
Validation loss: 2.5510598186835187

Epoch: 6| Step: 13
Training loss: 1.9919682400787473
Validation loss: 2.5569633433688628

Epoch: 94| Step: 0
Training loss: 2.059849278389712
Validation loss: 2.574018456129821

Epoch: 6| Step: 1
Training loss: 2.971217685855946
Validation loss: 2.5441869736864877

Epoch: 6| Step: 2
Training loss: 2.5937175518901734
Validation loss: 2.53528314477618

Epoch: 6| Step: 3
Training loss: 1.780560945782741
Validation loss: 2.5414698217074823

Epoch: 6| Step: 4
Training loss: 1.7327049393976286
Validation loss: 2.5671896162312646

Epoch: 6| Step: 5
Training loss: 1.8738249593632057
Validation loss: 2.56747395733456

Epoch: 6| Step: 6
Training loss: 3.510852337675695
Validation loss: 2.5730445665289587

Epoch: 6| Step: 7
Training loss: 1.7917284696106932
Validation loss: 2.5441746350274084

Epoch: 6| Step: 8
Training loss: 2.1176741487665196
Validation loss: 2.537111692987939

Epoch: 6| Step: 9
Training loss: 2.123715854165957
Validation loss: 2.5345197053826714

Epoch: 6| Step: 10
Training loss: 2.0187727132647364
Validation loss: 2.5518773495335303

Epoch: 6| Step: 11
Training loss: 2.0671557273354875
Validation loss: 2.572734877821942

Epoch: 6| Step: 12
Training loss: 2.4376195242505183
Validation loss: 2.5588346644540354

Epoch: 6| Step: 13
Training loss: 1.8784055300390734
Validation loss: 2.581530023615367

Epoch: 95| Step: 0
Training loss: 1.9282823767340762
Validation loss: 2.6329779719150723

Epoch: 6| Step: 1
Training loss: 2.5032534410381984
Validation loss: 2.6336083119715084

Epoch: 6| Step: 2
Training loss: 2.520825998174751
Validation loss: 2.6303362421843035

Epoch: 6| Step: 3
Training loss: 2.2772920318017866
Validation loss: 2.637336858190483

Epoch: 6| Step: 4
Training loss: 1.7544610520239108
Validation loss: 2.6186121313300985

Epoch: 6| Step: 5
Training loss: 2.6597372164744892
Validation loss: 2.6207283170812845

Epoch: 6| Step: 6
Training loss: 2.2831276260306574
Validation loss: 2.5903034291319695

Epoch: 6| Step: 7
Training loss: 1.514738865999212
Validation loss: 2.6041854069353367

Epoch: 6| Step: 8
Training loss: 2.9306817974200974
Validation loss: 2.5510542423119533

Epoch: 6| Step: 9
Training loss: 2.2721324202873925
Validation loss: 2.5359624943311396

Epoch: 6| Step: 10
Training loss: 2.5227151787645283
Validation loss: 2.5507230338229316

Epoch: 6| Step: 11
Training loss: 2.0648410111523527
Validation loss: 2.548993966856828

Epoch: 6| Step: 12
Training loss: 2.272967837346542
Validation loss: 2.548925342873759

Epoch: 6| Step: 13
Training loss: 1.8148855755469795
Validation loss: 2.542303870534257

Epoch: 96| Step: 0
Training loss: 2.4108056873574077
Validation loss: 2.515978738938557

Epoch: 6| Step: 1
Training loss: 2.5028372876648195
Validation loss: 2.542952998943155

Epoch: 6| Step: 2
Training loss: 1.8787747216136865
Validation loss: 2.5487435318317693

Epoch: 6| Step: 3
Training loss: 2.190052613971941
Validation loss: 2.5463682579378353

Epoch: 6| Step: 4
Training loss: 1.9223865355503897
Validation loss: 2.5348672961751553

Epoch: 6| Step: 5
Training loss: 1.7518047155080514
Validation loss: 2.5663731000473105

Epoch: 6| Step: 6
Training loss: 2.0866816761261093
Validation loss: 2.5595129948553366

Epoch: 6| Step: 7
Training loss: 1.776296185316506
Validation loss: 2.5703068571792085

Epoch: 6| Step: 8
Training loss: 2.465666958412001
Validation loss: 2.5438940861889936

Epoch: 6| Step: 9
Training loss: 1.8344727212328642
Validation loss: 2.5916695734807074

Epoch: 6| Step: 10
Training loss: 3.0430279825148117
Validation loss: 2.5499691412810064

Epoch: 6| Step: 11
Training loss: 2.3170097298316996
Validation loss: 2.566577071529343

Epoch: 6| Step: 12
Training loss: 2.7259937119386937
Validation loss: 2.561351270533751

Epoch: 6| Step: 13
Training loss: 2.40293894271972
Validation loss: 2.561819544441146

Epoch: 97| Step: 0
Training loss: 2.1283671685230043
Validation loss: 2.586552680255285

Epoch: 6| Step: 1
Training loss: 2.8869737814441776
Validation loss: 2.50929570530017

Epoch: 6| Step: 2
Training loss: 2.9996261363723002
Validation loss: 2.5506999775439105

Epoch: 6| Step: 3
Training loss: 2.057947741490965
Validation loss: 2.5732482717057263

Epoch: 6| Step: 4
Training loss: 1.9682576608391251
Validation loss: 2.606319808939833

Epoch: 6| Step: 5
Training loss: 1.8475610817398942
Validation loss: 2.570918466857588

Epoch: 6| Step: 6
Training loss: 2.2084610620183396
Validation loss: 2.564699949892247

Epoch: 6| Step: 7
Training loss: 2.1298968049245217
Validation loss: 2.5503669935936917

Epoch: 6| Step: 8
Training loss: 1.792183964001627
Validation loss: 2.572324295938944

Epoch: 6| Step: 9
Training loss: 2.3826123763297806
Validation loss: 2.568897410461217

Epoch: 6| Step: 10
Training loss: 2.0763907402424406
Validation loss: 2.538590920499692

Epoch: 6| Step: 11
Training loss: 1.8791952882378802
Validation loss: 2.5225316204033708

Epoch: 6| Step: 12
Training loss: 2.304323950073497
Validation loss: 2.5466210642404916

Epoch: 6| Step: 13
Training loss: 2.556852956978484
Validation loss: 2.5272422821257137

Epoch: 98| Step: 0
Training loss: 2.1623122646449526
Validation loss: 2.536275278701509

Epoch: 6| Step: 1
Training loss: 2.5375221627305793
Validation loss: 2.5558920304190007

Epoch: 6| Step: 2
Training loss: 2.4981712328250048
Validation loss: 2.556183776370731

Epoch: 6| Step: 3
Training loss: 2.387877637146709
Validation loss: 2.5317026055476193

Epoch: 6| Step: 4
Training loss: 2.0987651600383894
Validation loss: 2.5605460214698312

Epoch: 6| Step: 5
Training loss: 1.8645683657366874
Validation loss: 2.582583646795219

Epoch: 6| Step: 6
Training loss: 2.052454558228398
Validation loss: 2.560573303256975

Epoch: 6| Step: 7
Training loss: 2.8290356597756463
Validation loss: 2.523766290524869

Epoch: 6| Step: 8
Training loss: 2.1009855364701555
Validation loss: 2.551014490840822

Epoch: 6| Step: 9
Training loss: 2.7224036035207284
Validation loss: 2.565111829613924

Epoch: 6| Step: 10
Training loss: 1.9863716953416457
Validation loss: 2.5811430249280423

Epoch: 6| Step: 11
Training loss: 1.9244811832759823
Validation loss: 2.5647516437607925

Epoch: 6| Step: 12
Training loss: 2.061928062900927
Validation loss: 2.5768521952817016

Epoch: 6| Step: 13
Training loss: 1.7248467252885182
Validation loss: 2.5828493546819797

Epoch: 99| Step: 0
Training loss: 2.543030815714842
Validation loss: 2.580747268772377

Epoch: 6| Step: 1
Training loss: 2.0462689849401587
Validation loss: 2.5596019825873584

Epoch: 6| Step: 2
Training loss: 1.9281990395647928
Validation loss: 2.5784445978761323

Epoch: 6| Step: 3
Training loss: 2.884879345676579
Validation loss: 2.582353426579571

Epoch: 6| Step: 4
Training loss: 2.762152436775417
Validation loss: 2.613225247287207

Epoch: 6| Step: 5
Training loss: 2.1433086419154095
Validation loss: 2.5753185988671343

Epoch: 6| Step: 6
Training loss: 2.178572393412678
Validation loss: 2.548142848940612

Epoch: 6| Step: 7
Training loss: 1.290930948640207
Validation loss: 2.550638347710143

Epoch: 6| Step: 8
Training loss: 1.8202137408664305
Validation loss: 2.5580767160086015

Epoch: 6| Step: 9
Training loss: 2.5194708765174543
Validation loss: 2.538571307280981

Epoch: 6| Step: 10
Training loss: 1.7435426787044788
Validation loss: 2.564779027996994

Epoch: 6| Step: 11
Training loss: 2.650856016562279
Validation loss: 2.56926926425216

Epoch: 6| Step: 12
Training loss: 2.0026575551814134
Validation loss: 2.559480625033301

Epoch: 6| Step: 13
Training loss: 2.1514187190619647
Validation loss: 2.5371355540447342

Epoch: 100| Step: 0
Training loss: 2.2275369218534213
Validation loss: 2.5664370306095856

Epoch: 6| Step: 1
Training loss: 1.6038991118735384
Validation loss: 2.596667812512022

Epoch: 6| Step: 2
Training loss: 1.6385246274352772
Validation loss: 2.586281483678133

Epoch: 6| Step: 3
Training loss: 2.1505587007147065
Validation loss: 2.6176995682686637

Epoch: 6| Step: 4
Training loss: 2.620007171766643
Validation loss: 2.6395268159961307

Epoch: 6| Step: 5
Training loss: 2.409936928932856
Validation loss: 2.634709536005139

Epoch: 6| Step: 6
Training loss: 2.205687851652128
Validation loss: 2.6022063519179133

Epoch: 6| Step: 7
Training loss: 1.7902163320485731
Validation loss: 2.6167956462180917

Epoch: 6| Step: 8
Training loss: 1.6580152641072317
Validation loss: 2.5955408685210517

Epoch: 6| Step: 9
Training loss: 2.926503478115458
Validation loss: 2.5748174701427295

Epoch: 6| Step: 10
Training loss: 2.093269406859132
Validation loss: 2.558238836235203

Epoch: 6| Step: 11
Training loss: 2.4830929309109715
Validation loss: 2.5713741502351692

Epoch: 6| Step: 12
Training loss: 1.7886671270743588
Validation loss: 2.5668715428249427

Epoch: 6| Step: 13
Training loss: 2.998905300048207
Validation loss: 2.5300085689062826

Epoch: 101| Step: 0
Training loss: 2.069131881640662
Validation loss: 2.555608398702015

Epoch: 6| Step: 1
Training loss: 2.4690914642214867
Validation loss: 2.5369777787252468

Epoch: 6| Step: 2
Training loss: 1.6468184054239603
Validation loss: 2.5202123307914865

Epoch: 6| Step: 3
Training loss: 1.962647076580681
Validation loss: 2.5513557928125286

Epoch: 6| Step: 4
Training loss: 2.070013060597667
Validation loss: 2.5537863881311247

Epoch: 6| Step: 5
Training loss: 2.2659785553876195
Validation loss: 2.5455236301707775

Epoch: 6| Step: 6
Training loss: 1.7746373625489484
Validation loss: 2.5558908877149227

Epoch: 6| Step: 7
Training loss: 2.2627973076655836
Validation loss: 2.585008744471583

Epoch: 6| Step: 8
Training loss: 2.2674932735053144
Validation loss: 2.585397777339798

Epoch: 6| Step: 9
Training loss: 2.747163523514164
Validation loss: 2.6135872137652716

Epoch: 6| Step: 10
Training loss: 2.6314833367697346
Validation loss: 2.567756541472125

Epoch: 6| Step: 11
Training loss: 2.2892722596805455
Validation loss: 2.6127216403278486

Epoch: 6| Step: 12
Training loss: 2.390282899401735
Validation loss: 2.5720813697779845

Epoch: 6| Step: 13
Training loss: 1.9387541372819508
Validation loss: 2.5680400383948516

Epoch: 102| Step: 0
Training loss: 2.3571865213982064
Validation loss: 2.5402526882965697

Epoch: 6| Step: 1
Training loss: 2.4636156798220354
Validation loss: 2.5368585342633487

Epoch: 6| Step: 2
Training loss: 2.035092519395617
Validation loss: 2.5560246972217655

Epoch: 6| Step: 3
Training loss: 2.4883366313622046
Validation loss: 2.5380772014025776

Epoch: 6| Step: 4
Training loss: 1.6934351216658712
Validation loss: 2.559745564259172

Epoch: 6| Step: 5
Training loss: 1.6057896351407426
Validation loss: 2.5392423125933075

Epoch: 6| Step: 6
Training loss: 2.131718057823726
Validation loss: 2.5546192467269724

Epoch: 6| Step: 7
Training loss: 1.807083850825632
Validation loss: 2.5377626192342024

Epoch: 6| Step: 8
Training loss: 2.0154906235488372
Validation loss: 2.545228140947173

Epoch: 6| Step: 9
Training loss: 1.9780571755688297
Validation loss: 2.583898379970214

Epoch: 6| Step: 10
Training loss: 2.165868233016336
Validation loss: 2.535123866990708

Epoch: 6| Step: 11
Training loss: 3.0366665925222387
Validation loss: 2.584510555502355

Epoch: 6| Step: 12
Training loss: 2.3029536562657347
Validation loss: 2.5949043707846053

Epoch: 6| Step: 13
Training loss: 2.399230825827942
Validation loss: 2.5551133418216208

Epoch: 103| Step: 0
Training loss: 2.7670312097441623
Validation loss: 2.5975804138586542

Epoch: 6| Step: 1
Training loss: 1.635813387559555
Validation loss: 2.608367085670109

Epoch: 6| Step: 2
Training loss: 1.5745169307492581
Validation loss: 2.6207573149370162

Epoch: 6| Step: 3
Training loss: 2.7172315895579278
Validation loss: 2.5495102945102337

Epoch: 6| Step: 4
Training loss: 2.0352627365750275
Validation loss: 2.5862317028354083

Epoch: 6| Step: 5
Training loss: 2.3091457888117017
Validation loss: 2.527713550082354

Epoch: 6| Step: 6
Training loss: 2.518649823868379
Validation loss: 2.5498036979089944

Epoch: 6| Step: 7
Training loss: 2.1790866912501206
Validation loss: 2.5626934877865013

Epoch: 6| Step: 8
Training loss: 1.9955669984593265
Validation loss: 2.565724553768258

Epoch: 6| Step: 9
Training loss: 2.0940802014867503
Validation loss: 2.5261307900558556

Epoch: 6| Step: 10
Training loss: 1.9140484867750744
Validation loss: 2.5475407765787184

Epoch: 6| Step: 11
Training loss: 2.0928988648324
Validation loss: 2.561614465059592

Epoch: 6| Step: 12
Training loss: 2.2619406372227324
Validation loss: 2.57906461605218

Epoch: 6| Step: 13
Training loss: 1.9491542889594937
Validation loss: 2.538682613808902

Epoch: 104| Step: 0
Training loss: 1.67223183219714
Validation loss: 2.5622907413545404

Epoch: 6| Step: 1
Training loss: 2.240583743429828
Validation loss: 2.5923261755972464

Epoch: 6| Step: 2
Training loss: 2.0906508553906145
Validation loss: 2.5300725231154773

Epoch: 6| Step: 3
Training loss: 2.5918143529812903
Validation loss: 2.6027448180396275

Epoch: 6| Step: 4
Training loss: 2.796795124639587
Validation loss: 2.567006498191107

Epoch: 6| Step: 5
Training loss: 1.738426493888108
Validation loss: 2.5712958158430195

Epoch: 6| Step: 6
Training loss: 2.013724088685633
Validation loss: 2.5882492488713957

Epoch: 6| Step: 7
Training loss: 2.023791897053184
Validation loss: 2.619299284291915

Epoch: 6| Step: 8
Training loss: 2.3065698210648256
Validation loss: 2.6214010302041144

Epoch: 6| Step: 9
Training loss: 2.1898991099071816
Validation loss: 2.648555861747384

Epoch: 6| Step: 10
Training loss: 2.195214103041186
Validation loss: 2.61630835499502

Epoch: 6| Step: 11
Training loss: 2.080385971571249
Validation loss: 2.6402064787430413

Epoch: 6| Step: 12
Training loss: 1.9973250023834064
Validation loss: 2.5922035065030857

Epoch: 6| Step: 13
Training loss: 2.0453009923461125
Validation loss: 2.5896295350531866

Epoch: 105| Step: 0
Training loss: 1.9012550826446795
Validation loss: 2.6143255651294464

Epoch: 6| Step: 1
Training loss: 2.70512765777078
Validation loss: 2.573008150850095

Epoch: 6| Step: 2
Training loss: 2.5154026478184077
Validation loss: 2.5819878971309658

Epoch: 6| Step: 3
Training loss: 1.8841156940856767
Validation loss: 2.5964056613806132

Epoch: 6| Step: 4
Training loss: 2.4253683184106185
Validation loss: 2.568178862403525

Epoch: 6| Step: 5
Training loss: 1.8130214861750191
Validation loss: 2.5844554822475945

Epoch: 6| Step: 6
Training loss: 2.966402109186931
Validation loss: 2.5588316673336826

Epoch: 6| Step: 7
Training loss: 2.1079807901466268
Validation loss: 2.5580013142538385

Epoch: 6| Step: 8
Training loss: 1.517844708175374
Validation loss: 2.5638244431610238

Epoch: 6| Step: 9
Training loss: 1.5619403599820543
Validation loss: 2.5733191500982797

Epoch: 6| Step: 10
Training loss: 2.386377288316922
Validation loss: 2.609230144081493

Epoch: 6| Step: 11
Training loss: 1.9873758289247374
Validation loss: 2.55817508912229

Epoch: 6| Step: 12
Training loss: 2.0934854596537074
Validation loss: 2.5607996625969762

Epoch: 6| Step: 13
Training loss: 2.2220516086356836
Validation loss: 2.571952134524979

Epoch: 106| Step: 0
Training loss: 2.1384792293372037
Validation loss: 2.552754408649033

Epoch: 6| Step: 1
Training loss: 2.1604759710909485
Validation loss: 2.611427961451074

Epoch: 6| Step: 2
Training loss: 2.318422928849299
Validation loss: 2.567504523947153

Epoch: 6| Step: 3
Training loss: 2.301753254927605
Validation loss: 2.5570048050251595

Epoch: 6| Step: 4
Training loss: 1.9184012304178004
Validation loss: 2.595757599874459

Epoch: 6| Step: 5
Training loss: 2.0458238538016147
Validation loss: 2.6151683401137644

Epoch: 6| Step: 6
Training loss: 2.0574093040602284
Validation loss: 2.6017344191740706

Epoch: 6| Step: 7
Training loss: 2.1138535040312343
Validation loss: 2.5607350326607663

Epoch: 6| Step: 8
Training loss: 2.1082612664894125
Validation loss: 2.58548779529373

Epoch: 6| Step: 9
Training loss: 2.031894640233595
Validation loss: 2.571893099740089

Epoch: 6| Step: 10
Training loss: 1.4637998396209242
Validation loss: 2.5804570911439364

Epoch: 6| Step: 11
Training loss: 2.301584618404518
Validation loss: 2.5879053808787256

Epoch: 6| Step: 12
Training loss: 2.1874059384422613
Validation loss: 2.5934967009253302

Epoch: 6| Step: 13
Training loss: 2.7049642490696835
Validation loss: 2.5804438017823803

Epoch: 107| Step: 0
Training loss: 2.1976991759771902
Validation loss: 2.578744871584683

Epoch: 6| Step: 1
Training loss: 2.0892747336111888
Validation loss: 2.5975749985457135

Epoch: 6| Step: 2
Training loss: 2.1246200670666564
Validation loss: 2.607012991212063

Epoch: 6| Step: 3
Training loss: 2.945287243964991
Validation loss: 2.56068388618169

Epoch: 6| Step: 4
Training loss: 2.273558518377483
Validation loss: 2.5217632569897774

Epoch: 6| Step: 5
Training loss: 2.128201037153449
Validation loss: 2.5472267547653993

Epoch: 6| Step: 6
Training loss: 1.9831563857294259
Validation loss: 2.5680163948599333

Epoch: 6| Step: 7
Training loss: 2.0645329253365237
Validation loss: 2.5716005477844166

Epoch: 6| Step: 8
Training loss: 2.031611131697154
Validation loss: 2.5670429370906724

Epoch: 6| Step: 9
Training loss: 2.37837140564986
Validation loss: 2.604169026691639

Epoch: 6| Step: 10
Training loss: 2.4464844646572614
Validation loss: 2.542984063433955

Epoch: 6| Step: 11
Training loss: 1.9998128326575018
Validation loss: 2.5662525581933036

Epoch: 6| Step: 12
Training loss: 1.3746593660292719
Validation loss: 2.559747838463479

Epoch: 6| Step: 13
Training loss: 1.5367630564785197
Validation loss: 2.5968432691145025

Epoch: 108| Step: 0
Training loss: 1.855414267292209
Validation loss: 2.6007409617178863

Epoch: 6| Step: 1
Training loss: 2.3557292737222113
Validation loss: 2.620559433258547

Epoch: 6| Step: 2
Training loss: 1.8762952781057916
Validation loss: 2.5465125701711893

Epoch: 6| Step: 3
Training loss: 2.1213652997216865
Validation loss: 2.567059066633823

Epoch: 6| Step: 4
Training loss: 1.5987000727966487
Validation loss: 2.5505240886642273

Epoch: 6| Step: 5
Training loss: 2.367456905532695
Validation loss: 2.5539549731032207

Epoch: 6| Step: 6
Training loss: 2.7898832764358574
Validation loss: 2.5708443614119343

Epoch: 6| Step: 7
Training loss: 2.0552686442364876
Validation loss: 2.5227117291939383

Epoch: 6| Step: 8
Training loss: 1.895537370768699
Validation loss: 2.5758036633990495

Epoch: 6| Step: 9
Training loss: 2.54432100827666
Validation loss: 2.5879530413316183

Epoch: 6| Step: 10
Training loss: 2.1082527848891073
Validation loss: 2.579794187320945

Epoch: 6| Step: 11
Training loss: 2.0490829556578425
Validation loss: 2.512551034817089

Epoch: 6| Step: 12
Training loss: 1.9666777103997624
Validation loss: 2.5821520786225007

Epoch: 6| Step: 13
Training loss: 2.1078124864265777
Validation loss: 2.615494365460732

Epoch: 109| Step: 0
Training loss: 2.591766426235281
Validation loss: 2.591559285415992

Epoch: 6| Step: 1
Training loss: 2.3512933013027575
Validation loss: 2.5975924758922386

Epoch: 6| Step: 2
Training loss: 1.9765140090241335
Validation loss: 2.5573029268616394

Epoch: 6| Step: 3
Training loss: 1.9978398339776346
Validation loss: 2.5812090220058157

Epoch: 6| Step: 4
Training loss: 2.3110416040707378
Validation loss: 2.568582789539268

Epoch: 6| Step: 5
Training loss: 1.4464919767661613
Validation loss: 2.5440787194356673

Epoch: 6| Step: 6
Training loss: 1.2525623761328277
Validation loss: 2.5757690762621785

Epoch: 6| Step: 7
Training loss: 2.642413194109377
Validation loss: 2.6030160625449206

Epoch: 6| Step: 8
Training loss: 1.9777299049503232
Validation loss: 2.617879656462733

Epoch: 6| Step: 9
Training loss: 1.9455770289716703
Validation loss: 2.5906399998309215

Epoch: 6| Step: 10
Training loss: 2.3194446931738604
Validation loss: 2.6018190305164923

Epoch: 6| Step: 11
Training loss: 2.4030178209867143
Validation loss: 2.565158054670051

Epoch: 6| Step: 12
Training loss: 1.676628698800106
Validation loss: 2.5603717091283498

Epoch: 6| Step: 13
Training loss: 2.147521777503333
Validation loss: 2.605876610444027

Epoch: 110| Step: 0
Training loss: 2.4451557145723584
Validation loss: 2.5648482658167535

Epoch: 6| Step: 1
Training loss: 1.3639337677746586
Validation loss: 2.598802570779484

Epoch: 6| Step: 2
Training loss: 2.1716283205305915
Validation loss: 2.555704285836303

Epoch: 6| Step: 3
Training loss: 1.8526762497800373
Validation loss: 2.5416964440607814

Epoch: 6| Step: 4
Training loss: 1.9052228818254184
Validation loss: 2.529068858744643

Epoch: 6| Step: 5
Training loss: 2.7754645018976456
Validation loss: 2.5678760610482714

Epoch: 6| Step: 6
Training loss: 1.9721984332027465
Validation loss: 2.554692352943594

Epoch: 6| Step: 7
Training loss: 2.1940049591147504
Validation loss: 2.5750177635888765

Epoch: 6| Step: 8
Training loss: 1.6351059863534494
Validation loss: 2.5978436318792157

Epoch: 6| Step: 9
Training loss: 2.2437071219679994
Validation loss: 2.554569268868955

Epoch: 6| Step: 10
Training loss: 2.1080342871032784
Validation loss: 2.594930096923874

Epoch: 6| Step: 11
Training loss: 2.2260338942148565
Validation loss: 2.6281027092519427

Epoch: 6| Step: 12
Training loss: 1.6467098203916994
Validation loss: 2.623723022239855

Epoch: 6| Step: 13
Training loss: 2.637322883625112
Validation loss: 2.5842089912206765

Epoch: 111| Step: 0
Training loss: 2.0394573194821954
Validation loss: 2.603811824783083

Epoch: 6| Step: 1
Training loss: 2.24904569945289
Validation loss: 2.575687435201519

Epoch: 6| Step: 2
Training loss: 2.181080800136958
Validation loss: 2.574621204797978

Epoch: 6| Step: 3
Training loss: 1.992743919308724
Validation loss: 2.55012088501568

Epoch: 6| Step: 4
Training loss: 1.75652968328008
Validation loss: 2.5527534435506642

Epoch: 6| Step: 5
Training loss: 1.749321942439636
Validation loss: 2.57167833208993

Epoch: 6| Step: 6
Training loss: 2.3109055254454214
Validation loss: 2.5693296739073452

Epoch: 6| Step: 7
Training loss: 2.2363330291294483
Validation loss: 2.5842224918680285

Epoch: 6| Step: 8
Training loss: 2.1342534936860895
Validation loss: 2.576799379420845

Epoch: 6| Step: 9
Training loss: 1.4833249845519836
Validation loss: 2.5869561807927

Epoch: 6| Step: 10
Training loss: 1.5736973658721767
Validation loss: 2.5910111486552605

Epoch: 6| Step: 11
Training loss: 1.7804326641715968
Validation loss: 2.6135052792593303

Epoch: 6| Step: 12
Training loss: 2.951923751735395
Validation loss: 2.58461630147148

Epoch: 6| Step: 13
Training loss: 2.31591596126771
Validation loss: 2.5924881619532925

Epoch: 112| Step: 0
Training loss: 1.8623688261192337
Validation loss: 2.611988700223026

Epoch: 6| Step: 1
Training loss: 1.9430692063128479
Validation loss: 2.6083156239778784

Epoch: 6| Step: 2
Training loss: 1.5895587937580278
Validation loss: 2.609076096400344

Epoch: 6| Step: 3
Training loss: 2.0484020564710517
Validation loss: 2.6089651581609132

Epoch: 6| Step: 4
Training loss: 2.0341900016241157
Validation loss: 2.579825485916799

Epoch: 6| Step: 5
Training loss: 1.843222591161699
Validation loss: 2.6010413349494117

Epoch: 6| Step: 6
Training loss: 1.9698046326946
Validation loss: 2.5775674775840343

Epoch: 6| Step: 7
Training loss: 3.1132656274113986
Validation loss: 2.551093307809407

Epoch: 6| Step: 8
Training loss: 2.0250303854840768
Validation loss: 2.6145611087011544

Epoch: 6| Step: 9
Training loss: 2.178104824153328
Validation loss: 2.5907019664710855

Epoch: 6| Step: 10
Training loss: 2.2894560700146878
Validation loss: 2.5752288735162594

Epoch: 6| Step: 11
Training loss: 2.145664936852964
Validation loss: 2.56689648177356

Epoch: 6| Step: 12
Training loss: 2.03328239293727
Validation loss: 2.5682131340059184

Epoch: 6| Step: 13
Training loss: 1.7483740473765317
Validation loss: 2.5884698951232545

Epoch: 113| Step: 0
Training loss: 2.858911362044194
Validation loss: 2.630495132572302

Epoch: 6| Step: 1
Training loss: 3.2520023926448114
Validation loss: 2.572094424263122

Epoch: 6| Step: 2
Training loss: 1.7407301208421648
Validation loss: 2.5976809239948544

Epoch: 6| Step: 3
Training loss: 2.155801698825902
Validation loss: 2.5446654644617577

Epoch: 6| Step: 4
Training loss: 1.6571255654809347
Validation loss: 2.559103769812824

Epoch: 6| Step: 5
Training loss: 2.006587979853446
Validation loss: 2.5821802632033735

Epoch: 6| Step: 6
Training loss: 2.266539395723565
Validation loss: 2.6328928828585134

Epoch: 6| Step: 7
Training loss: 1.6382450825596901
Validation loss: 2.599061674663949

Epoch: 6| Step: 8
Training loss: 1.6807662693401153
Validation loss: 2.617164786320903

Epoch: 6| Step: 9
Training loss: 2.0426423083704766
Validation loss: 2.62123456975579

Epoch: 6| Step: 10
Training loss: 1.7827114334011136
Validation loss: 2.6482541331201297

Epoch: 6| Step: 11
Training loss: 1.7776755893000997
Validation loss: 2.629862218059178

Epoch: 6| Step: 12
Training loss: 1.5575510614882153
Validation loss: 2.6301793024456446

Epoch: 6| Step: 13
Training loss: 1.4246687219599272
Validation loss: 2.562583239684298

Epoch: 114| Step: 0
Training loss: 2.290411541869262
Validation loss: 2.5493285329788824

Epoch: 6| Step: 1
Training loss: 1.8712949385818007
Validation loss: 2.5456608645701158

Epoch: 6| Step: 2
Training loss: 2.365545628777042
Validation loss: 2.5321080515637773

Epoch: 6| Step: 3
Training loss: 1.5256127111556514
Validation loss: 2.597498303346444

Epoch: 6| Step: 4
Training loss: 1.2750857866635643
Validation loss: 2.5188200032971406

Epoch: 6| Step: 5
Training loss: 2.028279288937272
Validation loss: 2.5587238696065002

Epoch: 6| Step: 6
Training loss: 2.1619375655116433
Validation loss: 2.5627619291588637

Epoch: 6| Step: 7
Training loss: 1.629255005895965
Validation loss: 2.6089956803545

Epoch: 6| Step: 8
Training loss: 2.4273542872342295
Validation loss: 2.54363778294037

Epoch: 6| Step: 9
Training loss: 2.240297803837233
Validation loss: 2.5311997962023223

Epoch: 6| Step: 10
Training loss: 2.2104709523899797
Validation loss: 2.534895653793572

Epoch: 6| Step: 11
Training loss: 2.3588299658582454
Validation loss: 2.5521078666493926

Epoch: 6| Step: 12
Training loss: 1.8070732959518103
Validation loss: 2.5551862084081027

Epoch: 6| Step: 13
Training loss: 2.0785102200379595
Validation loss: 2.566139087290046

Epoch: 115| Step: 0
Training loss: 2.0761200834688407
Validation loss: 2.6386724171330864

Epoch: 6| Step: 1
Training loss: 2.0341189737548904
Validation loss: 2.627797316580948

Epoch: 6| Step: 2
Training loss: 1.6941508167286605
Validation loss: 2.624556670521048

Epoch: 6| Step: 3
Training loss: 1.680430687012636
Validation loss: 2.624464177137234

Epoch: 6| Step: 4
Training loss: 3.078910611199652
Validation loss: 2.629620950407929

Epoch: 6| Step: 5
Training loss: 1.9858362419671665
Validation loss: 2.621988362713499

Epoch: 6| Step: 6
Training loss: 2.487319449001643
Validation loss: 2.642602018674507

Epoch: 6| Step: 7
Training loss: 1.7272590854553245
Validation loss: 2.6507044479647295

Epoch: 6| Step: 8
Training loss: 1.9173040850446255
Validation loss: 2.6054976355435127

Epoch: 6| Step: 9
Training loss: 1.3372498697283317
Validation loss: 2.5786527305474314

Epoch: 6| Step: 10
Training loss: 2.2375681008998476
Validation loss: 2.6397366656594548

Epoch: 6| Step: 11
Training loss: 1.497991170431887
Validation loss: 2.561592297944001

Epoch: 6| Step: 12
Training loss: 1.8914191099452131
Validation loss: 2.549771337292271

Epoch: 6| Step: 13
Training loss: 2.3151592738684106
Validation loss: 2.5385597552903514

Epoch: 116| Step: 0
Training loss: 2.2431587481570703
Validation loss: 2.6336599131371523

Epoch: 6| Step: 1
Training loss: 1.9705711902805605
Validation loss: 2.5912795653729046

Epoch: 6| Step: 2
Training loss: 2.253387444352443
Validation loss: 2.531629604556349

Epoch: 6| Step: 3
Training loss: 2.120057697770563
Validation loss: 2.5649168355992056

Epoch: 6| Step: 4
Training loss: 2.240506595478425
Validation loss: 2.5782390376599924

Epoch: 6| Step: 5
Training loss: 1.7952605582775258
Validation loss: 2.5717458390488117

Epoch: 6| Step: 6
Training loss: 1.9673230282832368
Validation loss: 2.608267223466921

Epoch: 6| Step: 7
Training loss: 1.7479504436128663
Validation loss: 2.566906218888846

Epoch: 6| Step: 8
Training loss: 2.5336379102351354
Validation loss: 2.599929189940423

Epoch: 6| Step: 9
Training loss: 2.2538960950811098
Validation loss: 2.5763599711734892

Epoch: 6| Step: 10
Training loss: 1.9816781288416507
Validation loss: 2.6288508068811516

Epoch: 6| Step: 11
Training loss: 1.8127660227267242
Validation loss: 2.5697979474825288

Epoch: 6| Step: 12
Training loss: 1.6297079258751483
Validation loss: 2.607914056889909

Epoch: 6| Step: 13
Training loss: 1.8834076886423086
Validation loss: 2.6135162567164363

Epoch: 117| Step: 0
Training loss: 1.8167118594763283
Validation loss: 2.5883220576892043

Epoch: 6| Step: 1
Training loss: 1.4472355601370734
Validation loss: 2.595097088587017

Epoch: 6| Step: 2
Training loss: 1.7232356405452676
Validation loss: 2.6467501911521056

Epoch: 6| Step: 3
Training loss: 2.0978592360615176
Validation loss: 2.6685933116980456

Epoch: 6| Step: 4
Training loss: 1.8916152378547035
Validation loss: 2.5831984874438167

Epoch: 6| Step: 5
Training loss: 2.0699089376718742
Validation loss: 2.63437830154375

Epoch: 6| Step: 6
Training loss: 3.264716062949378
Validation loss: 2.631714302229396

Epoch: 6| Step: 7
Training loss: 1.9166276831048645
Validation loss: 2.5982131858127957

Epoch: 6| Step: 8
Training loss: 1.3059220554874418
Validation loss: 2.621588442832423

Epoch: 6| Step: 9
Training loss: 1.9599758389015307
Validation loss: 2.578911278014938

Epoch: 6| Step: 10
Training loss: 1.849584110010919
Validation loss: 2.561216979092418

Epoch: 6| Step: 11
Training loss: 2.238973939772081
Validation loss: 2.5646985864552665

Epoch: 6| Step: 12
Training loss: 2.1443440228778936
Validation loss: 2.606519800700873

Epoch: 6| Step: 13
Training loss: 2.2752290463687257
Validation loss: 2.5655908707003188

Epoch: 118| Step: 0
Training loss: 2.5160915344944894
Validation loss: 2.556695209461554

Epoch: 6| Step: 1
Training loss: 2.418541170316745
Validation loss: 2.5939476213659627

Epoch: 6| Step: 2
Training loss: 1.9365350104451218
Validation loss: 2.579369631799353

Epoch: 6| Step: 3
Training loss: 1.718705610222232
Validation loss: 2.596793369398076

Epoch: 6| Step: 4
Training loss: 1.6115508694291008
Validation loss: 2.5872607423057605

Epoch: 6| Step: 5
Training loss: 1.8404543889867724
Validation loss: 2.5848599558168535

Epoch: 6| Step: 6
Training loss: 3.050062185185098
Validation loss: 2.5668648629847155

Epoch: 6| Step: 7
Training loss: 1.9414200043526855
Validation loss: 2.6306044982077417

Epoch: 6| Step: 8
Training loss: 1.8166400717908877
Validation loss: 2.5544690846625575

Epoch: 6| Step: 9
Training loss: 1.3532621248111862
Validation loss: 2.6680844878993795

Epoch: 6| Step: 10
Training loss: 2.0404431576054614
Validation loss: 2.6517481483953387

Epoch: 6| Step: 11
Training loss: 2.044489511509144
Validation loss: 2.6327478040524777

Epoch: 6| Step: 12
Training loss: 1.7332827591242557
Validation loss: 2.59378638490948

Epoch: 6| Step: 13
Training loss: 1.5124692015231351
Validation loss: 2.5719176346438246

Epoch: 119| Step: 0
Training loss: 2.2874675310675947
Validation loss: 2.6344178358813557

Epoch: 6| Step: 1
Training loss: 1.4523087536810748
Validation loss: 2.6289928888684475

Epoch: 6| Step: 2
Training loss: 1.8297960517926597
Validation loss: 2.587500031942714

Epoch: 6| Step: 3
Training loss: 1.6121272284607777
Validation loss: 2.5663105459576117

Epoch: 6| Step: 4
Training loss: 2.7352312763627267
Validation loss: 2.5603724695979198

Epoch: 6| Step: 5
Training loss: 1.8107300370456458
Validation loss: 2.6034608469354166

Epoch: 6| Step: 6
Training loss: 1.8578640865674498
Validation loss: 2.5727654128204365

Epoch: 6| Step: 7
Training loss: 2.0555658239961585
Validation loss: 2.6276047211650546

Epoch: 6| Step: 8
Training loss: 2.0534696849947367
Validation loss: 2.6268361799451676

Epoch: 6| Step: 9
Training loss: 1.6159623522480517
Validation loss: 2.580335220668694

Epoch: 6| Step: 10
Training loss: 2.463900861838847
Validation loss: 2.5838872305480773

Epoch: 6| Step: 11
Training loss: 1.8857235386547122
Validation loss: 2.5560761390264504

Epoch: 6| Step: 12
Training loss: 1.626239597249167
Validation loss: 2.668785063418702

Epoch: 6| Step: 13
Training loss: 2.353034487094236
Validation loss: 2.677859469663021

Epoch: 120| Step: 0
Training loss: 2.1501036685523935
Validation loss: 2.615560179423341

Epoch: 6| Step: 1
Training loss: 1.8291748162553658
Validation loss: 2.5950370414260937

Epoch: 6| Step: 2
Training loss: 1.097955086100406
Validation loss: 2.6284055492814713

Epoch: 6| Step: 3
Training loss: 2.7229480121873784
Validation loss: 2.6554010418329907

Epoch: 6| Step: 4
Training loss: 2.063967442832377
Validation loss: 2.5678115008960676

Epoch: 6| Step: 5
Training loss: 2.120441259130479
Validation loss: 2.6193596778882062

Epoch: 6| Step: 6
Training loss: 1.67590637451267
Validation loss: 2.608643610133989

Epoch: 6| Step: 7
Training loss: 2.1695355226765183
Validation loss: 2.602826564575404

Epoch: 6| Step: 8
Training loss: 2.3999487871428014
Validation loss: 2.5973453345220596

Epoch: 6| Step: 9
Training loss: 1.4164003046987228
Validation loss: 2.5702298043812566

Epoch: 6| Step: 10
Training loss: 2.017333142306833
Validation loss: 2.5888370573078885

Epoch: 6| Step: 11
Training loss: 1.6447944339908498
Validation loss: 2.593063033718102

Epoch: 6| Step: 12
Training loss: 1.8130264832992062
Validation loss: 2.619222064628401

Epoch: 6| Step: 13
Training loss: 2.03129847542067
Validation loss: 2.6101527929830244

Epoch: 121| Step: 0
Training loss: 2.023714378001013
Validation loss: 2.602519335740591

Epoch: 6| Step: 1
Training loss: 2.4107679088623173
Validation loss: 2.61387728597201

Epoch: 6| Step: 2
Training loss: 1.8969848475316102
Validation loss: 2.5711352916519403

Epoch: 6| Step: 3
Training loss: 2.13170441288619
Validation loss: 2.5992076782198668

Epoch: 6| Step: 4
Training loss: 1.4861573611199819
Validation loss: 2.6753165405371253

Epoch: 6| Step: 5
Training loss: 1.6813586770708098
Validation loss: 2.5916861170522347

Epoch: 6| Step: 6
Training loss: 3.008370642461516
Validation loss: 2.611332872681735

Epoch: 6| Step: 7
Training loss: 2.0049517843104527
Validation loss: 2.6318614083250695

Epoch: 6| Step: 8
Training loss: 1.532839514506945
Validation loss: 2.700539059456385

Epoch: 6| Step: 9
Training loss: 1.5380212970047857
Validation loss: 2.5595412191430458

Epoch: 6| Step: 10
Training loss: 2.2204361002677637
Validation loss: 2.5723881249403373

Epoch: 6| Step: 11
Training loss: 1.6850694176838323
Validation loss: 2.6083274154677203

Epoch: 6| Step: 12
Training loss: 1.9141526181551485
Validation loss: 2.585868043149225

Epoch: 6| Step: 13
Training loss: 2.0422469371969285
Validation loss: 2.60934970561729

Epoch: 122| Step: 0
Training loss: 1.8258331800722203
Validation loss: 2.6095199696973674

Epoch: 6| Step: 1
Training loss: 2.46257628114546
Validation loss: 2.5835429588503103

Epoch: 6| Step: 2
Training loss: 1.7774326847169069
Validation loss: 2.5576823623041727

Epoch: 6| Step: 3
Training loss: 1.9023724500931176
Validation loss: 2.598052550562833

Epoch: 6| Step: 4
Training loss: 1.5677079193351258
Validation loss: 2.5664611377004527

Epoch: 6| Step: 5
Training loss: 1.7484140703064956
Validation loss: 2.5874220782600794

Epoch: 6| Step: 6
Training loss: 1.885438978649777
Validation loss: 2.5907877970223714

Epoch: 6| Step: 7
Training loss: 2.0350536240019514
Validation loss: 2.625171368167166

Epoch: 6| Step: 8
Training loss: 1.4454612861550284
Validation loss: 2.6274756459064164

Epoch: 6| Step: 9
Training loss: 2.3593239683985976
Validation loss: 2.647938864249993

Epoch: 6| Step: 10
Training loss: 2.3768378725846007
Validation loss: 2.660056360192627

Epoch: 6| Step: 11
Training loss: 1.6277891577813608
Validation loss: 2.601089465081873

Epoch: 6| Step: 12
Training loss: 1.973186036532193
Validation loss: 2.6495628254238706

Epoch: 6| Step: 13
Training loss: 1.3392243580160554
Validation loss: 2.5684694061110753

Epoch: 123| Step: 0
Training loss: 2.609926725067849
Validation loss: 2.587853297318254

Epoch: 6| Step: 1
Training loss: 2.0689145532721875
Validation loss: 2.599254711021984

Epoch: 6| Step: 2
Training loss: 2.006748615230673
Validation loss: 2.602155096705104

Epoch: 6| Step: 3
Training loss: 1.7270878471557876
Validation loss: 2.5950888429989947

Epoch: 6| Step: 4
Training loss: 1.2917219991009776
Validation loss: 2.5667245668428285

Epoch: 6| Step: 5
Training loss: 2.3506101790074774
Validation loss: 2.606022918346667

Epoch: 6| Step: 6
Training loss: 1.6447770394884214
Validation loss: 2.6023915662355024

Epoch: 6| Step: 7
Training loss: 1.7542858774931536
Validation loss: 2.562402382208576

Epoch: 6| Step: 8
Training loss: 1.7217161766508684
Validation loss: 2.6215327691598382

Epoch: 6| Step: 9
Training loss: 1.9505712674949938
Validation loss: 2.640002581734792

Epoch: 6| Step: 10
Training loss: 1.7277511716608782
Validation loss: 2.6208776166011973

Epoch: 6| Step: 11
Training loss: 2.276673625676628
Validation loss: 2.5392373205791468

Epoch: 6| Step: 12
Training loss: 1.7767830100384663
Validation loss: 2.6088960326015003

Epoch: 6| Step: 13
Training loss: 1.6157554145874544
Validation loss: 2.6170676891934517

Epoch: 124| Step: 0
Training loss: 1.9074044405898005
Validation loss: 2.590455318181181

Epoch: 6| Step: 1
Training loss: 1.893412780952935
Validation loss: 2.5865262562783147

Epoch: 6| Step: 2
Training loss: 1.9617552856786347
Validation loss: 2.5851199422196296

Epoch: 6| Step: 3
Training loss: 1.309258955226513
Validation loss: 2.578455740010709

Epoch: 6| Step: 4
Training loss: 1.9124458180649986
Validation loss: 2.5772351665582454

Epoch: 6| Step: 5
Training loss: 2.0235215099672277
Validation loss: 2.550404854343953

Epoch: 6| Step: 6
Training loss: 1.4732394492902599
Validation loss: 2.570500715760084

Epoch: 6| Step: 7
Training loss: 1.8081412686546672
Validation loss: 2.625228675085562

Epoch: 6| Step: 8
Training loss: 1.9819862225281748
Validation loss: 2.5934652072560094

Epoch: 6| Step: 9
Training loss: 1.9747167118530022
Validation loss: 2.5762144619783984

Epoch: 6| Step: 10
Training loss: 2.1614422410725944
Validation loss: 2.622543638900877

Epoch: 6| Step: 11
Training loss: 1.8000198045276876
Validation loss: 2.5953794899045355

Epoch: 6| Step: 12
Training loss: 1.9425196074449873
Validation loss: 2.6146648186578725

Epoch: 6| Step: 13
Training loss: 2.4412775356695007
Validation loss: 2.5883410022308393

Epoch: 125| Step: 0
Training loss: 1.395970048424619
Validation loss: 2.6011933149729853

Epoch: 6| Step: 1
Training loss: 1.8379366764538034
Validation loss: 2.619967146975682

Epoch: 6| Step: 2
Training loss: 2.5320402254100314
Validation loss: 2.6131237155510005

Epoch: 6| Step: 3
Training loss: 2.7996333495271606
Validation loss: 2.6572572556115266

Epoch: 6| Step: 4
Training loss: 1.8890672051029598
Validation loss: 2.605783286261136

Epoch: 6| Step: 5
Training loss: 2.1661663089000625
Validation loss: 2.6633847027894593

Epoch: 6| Step: 6
Training loss: 2.074085525860784
Validation loss: 2.573383834578864

Epoch: 6| Step: 7
Training loss: 2.131675445065332
Validation loss: 2.619042812173734

Epoch: 6| Step: 8
Training loss: 1.565887745873957
Validation loss: 2.5975490002971457

Epoch: 6| Step: 9
Training loss: 1.3803510580103235
Validation loss: 2.592522050891903

Epoch: 6| Step: 10
Training loss: 1.5342932840562928
Validation loss: 2.5732803756901084

Epoch: 6| Step: 11
Training loss: 1.2102131307494473
Validation loss: 2.5702151634700887

Epoch: 6| Step: 12
Training loss: 1.4620800752223884
Validation loss: 2.586088408554775

Epoch: 6| Step: 13
Training loss: 1.6475480559175253
Validation loss: 2.5691154034458115

Epoch: 126| Step: 0
Training loss: 1.4741303126781953
Validation loss: 2.565924163239827

Epoch: 6| Step: 1
Training loss: 1.9823471882097927
Validation loss: 2.5945858355497275

Epoch: 6| Step: 2
Training loss: 1.8901219605145871
Validation loss: 2.578165936385857

Epoch: 6| Step: 3
Training loss: 1.31772572301113
Validation loss: 2.567915350336838

Epoch: 6| Step: 4
Training loss: 1.7114388763318555
Validation loss: 2.6173404781744756

Epoch: 6| Step: 5
Training loss: 1.8154690857747506
Validation loss: 2.6514108746736498

Epoch: 6| Step: 6
Training loss: 2.317668500122211
Validation loss: 2.6079324781925166

Epoch: 6| Step: 7
Training loss: 1.488562529808999
Validation loss: 2.643236783522482

Epoch: 6| Step: 8
Training loss: 2.8466693020822564
Validation loss: 2.6333637962108405

Epoch: 6| Step: 9
Training loss: 1.9743867743015153
Validation loss: 2.6376356099054847

Epoch: 6| Step: 10
Training loss: 1.393394712316041
Validation loss: 2.573031207995845

Epoch: 6| Step: 11
Training loss: 1.9148770214662554
Validation loss: 2.5788911702107034

Epoch: 6| Step: 12
Training loss: 1.2270279505374548
Validation loss: 2.6304673221600496

Epoch: 6| Step: 13
Training loss: 1.9755601112838603
Validation loss: 2.5598255715699465

Epoch: 127| Step: 0
Training loss: 1.3040385659693272
Validation loss: 2.6617453483205775

Epoch: 6| Step: 1
Training loss: 1.8036065104956094
Validation loss: 2.630422229693487

Epoch: 6| Step: 2
Training loss: 2.0593713091757873
Validation loss: 2.6145008170391106

Epoch: 6| Step: 3
Training loss: 1.594801761421664
Validation loss: 2.5625065283963537

Epoch: 6| Step: 4
Training loss: 1.7810839525427342
Validation loss: 2.624977240388084

Epoch: 6| Step: 5
Training loss: 1.6716130131598583
Validation loss: 2.562559251177798

Epoch: 6| Step: 6
Training loss: 2.311241013389269
Validation loss: 2.6453227404031754

Epoch: 6| Step: 7
Training loss: 1.4701701663908677
Validation loss: 2.5684758419806513

Epoch: 6| Step: 8
Training loss: 1.8861531738749648
Validation loss: 2.578432168868373

Epoch: 6| Step: 9
Training loss: 1.6620790364492088
Validation loss: 2.5629267841135897

Epoch: 6| Step: 10
Training loss: 2.8949216509875435
Validation loss: 2.5441910110701675

Epoch: 6| Step: 11
Training loss: 2.0807604606353554
Validation loss: 2.5918568822434302

Epoch: 6| Step: 12
Training loss: 2.116111341103482
Validation loss: 2.5532288348508065

Epoch: 6| Step: 13
Training loss: 1.6525079451700369
Validation loss: 2.6247479605399917

Epoch: 128| Step: 0
Training loss: 1.640396683564516
Validation loss: 2.6155329394499347

Epoch: 6| Step: 1
Training loss: 1.3881414717684994
Validation loss: 2.652818325547261

Epoch: 6| Step: 2
Training loss: 1.5898938370296622
Validation loss: 2.5933666175710126

Epoch: 6| Step: 3
Training loss: 1.4162398798716505
Validation loss: 2.6659678397827573

Epoch: 6| Step: 4
Training loss: 2.113736087836757
Validation loss: 2.669566594307485

Epoch: 6| Step: 5
Training loss: 2.2864817369750643
Validation loss: 2.667180493641139

Epoch: 6| Step: 6
Training loss: 1.4322361975823972
Validation loss: 2.695664092642128

Epoch: 6| Step: 7
Training loss: 1.8779662511066086
Validation loss: 2.727822611022313

Epoch: 6| Step: 8
Training loss: 2.64324694597751
Validation loss: 2.623776150555391

Epoch: 6| Step: 9
Training loss: 1.8300574107102108
Validation loss: 2.6360154860017033

Epoch: 6| Step: 10
Training loss: 2.053555484970468
Validation loss: 2.6448753204477717

Epoch: 6| Step: 11
Training loss: 1.582464389611285
Validation loss: 2.5631037055229156

Epoch: 6| Step: 12
Training loss: 1.976129899160714
Validation loss: 2.544799629997403

Epoch: 6| Step: 13
Training loss: 1.922493625724553
Validation loss: 2.6680786944216752

Epoch: 129| Step: 0
Training loss: 1.6645085269827593
Validation loss: 2.602285580579981

Epoch: 6| Step: 1
Training loss: 1.4945344692580413
Validation loss: 2.5885512097884456

Epoch: 6| Step: 2
Training loss: 2.2145227270245615
Validation loss: 2.637051543909445

Epoch: 6| Step: 3
Training loss: 1.7952024553933241
Validation loss: 2.59667837911159

Epoch: 6| Step: 4
Training loss: 1.7612006869969532
Validation loss: 2.5919060951184694

Epoch: 6| Step: 5
Training loss: 1.1656688896691063
Validation loss: 2.6115668374826244

Epoch: 6| Step: 6
Training loss: 1.7526810408610154
Validation loss: 2.622995337734813

Epoch: 6| Step: 7
Training loss: 1.8511169154969298
Validation loss: 2.629180259085058

Epoch: 6| Step: 8
Training loss: 2.625265562157586
Validation loss: 2.585647213288485

Epoch: 6| Step: 9
Training loss: 2.349427530889257
Validation loss: 2.6305238037269847

Epoch: 6| Step: 10
Training loss: 1.9333664885780177
Validation loss: 2.7637019395035436

Epoch: 6| Step: 11
Training loss: 2.2761074263255496
Validation loss: 2.7103143098481257

Epoch: 6| Step: 12
Training loss: 1.8570601856254627
Validation loss: 2.7524867374101802

Epoch: 6| Step: 13
Training loss: 1.9715955242995427
Validation loss: 2.7355505750486664

Epoch: 130| Step: 0
Training loss: 1.8786682485736679
Validation loss: 2.646121637651481

Epoch: 6| Step: 1
Training loss: 1.6273988477268009
Validation loss: 2.6308896280846468

Epoch: 6| Step: 2
Training loss: 1.7786173187546828
Validation loss: 2.5445086167316355

Epoch: 6| Step: 3
Training loss: 1.8047511101944016
Validation loss: 2.6085648030772077

Epoch: 6| Step: 4
Training loss: 1.1095284906505316
Validation loss: 2.6306261593148528

Epoch: 6| Step: 5
Training loss: 2.2451081609689685
Validation loss: 2.6160396051354433

Epoch: 6| Step: 6
Training loss: 1.1899683044924836
Validation loss: 2.554420185005258

Epoch: 6| Step: 7
Training loss: 1.8621931757794834
Validation loss: 2.5530529100753045

Epoch: 6| Step: 8
Training loss: 2.1307803802812946
Validation loss: 2.619869850362211

Epoch: 6| Step: 9
Training loss: 1.897737601661711
Validation loss: 2.5405508833706283

Epoch: 6| Step: 10
Training loss: 1.726279118960088
Validation loss: 2.622205503211988

Epoch: 6| Step: 11
Training loss: 2.429540402783231
Validation loss: 2.583627681472831

Epoch: 6| Step: 12
Training loss: 1.8522040305985668
Validation loss: 2.627270125651504

Epoch: 6| Step: 13
Training loss: 2.1713370336154183
Validation loss: 2.6437139708556727

Epoch: 131| Step: 0
Training loss: 2.146428837287656
Validation loss: 2.582748382751

Epoch: 6| Step: 1
Training loss: 1.504844471952376
Validation loss: 2.6038502513664135

Epoch: 6| Step: 2
Training loss: 1.4466462450886033
Validation loss: 2.570452700794332

Epoch: 6| Step: 3
Training loss: 1.68687399096351
Validation loss: 2.630503274728612

Epoch: 6| Step: 4
Training loss: 2.451489140012877
Validation loss: 2.6363488962245705

Epoch: 6| Step: 5
Training loss: 1.7201649476956806
Validation loss: 2.647458498494108

Epoch: 6| Step: 6
Training loss: 1.5674584866613266
Validation loss: 2.640590547114928

Epoch: 6| Step: 7
Training loss: 1.914309800968449
Validation loss: 2.5875063283354547

Epoch: 6| Step: 8
Training loss: 2.129847775065719
Validation loss: 2.655318856187004

Epoch: 6| Step: 9
Training loss: 1.7368044634288575
Validation loss: 2.608859089238559

Epoch: 6| Step: 10
Training loss: 1.8369928451589796
Validation loss: 2.595638568076343

Epoch: 6| Step: 11
Training loss: 1.5375243890580215
Validation loss: 2.5751680004536213

Epoch: 6| Step: 12
Training loss: 2.172805806224689
Validation loss: 2.6215732550869353

Epoch: 6| Step: 13
Training loss: 1.5810613225617416
Validation loss: 2.632831833765599

Epoch: 132| Step: 0
Training loss: 1.962157580394677
Validation loss: 2.656466501425991

Epoch: 6| Step: 1
Training loss: 1.2562571321351395
Validation loss: 2.54771209877063

Epoch: 6| Step: 2
Training loss: 1.2581518438121897
Validation loss: 2.6082634376163396

Epoch: 6| Step: 3
Training loss: 2.8931232276197414
Validation loss: 2.6273431991771674

Epoch: 6| Step: 4
Training loss: 1.4123523972621437
Validation loss: 2.6110466572627526

Epoch: 6| Step: 5
Training loss: 1.8536461803253383
Validation loss: 2.638692099500545

Epoch: 6| Step: 6
Training loss: 1.7449818597632212
Validation loss: 2.600063590959358

Epoch: 6| Step: 7
Training loss: 2.3288921142067225
Validation loss: 2.5488260047484794

Epoch: 6| Step: 8
Training loss: 1.9323064044345806
Validation loss: 2.633852465579179

Epoch: 6| Step: 9
Training loss: 1.656298366776094
Validation loss: 2.581237463193287

Epoch: 6| Step: 10
Training loss: 1.7419739322879875
Validation loss: 2.6459819771971502

Epoch: 6| Step: 11
Training loss: 1.7292178349411942
Validation loss: 2.643737433413436

Epoch: 6| Step: 12
Training loss: 1.5832265600375472
Validation loss: 2.6694654341062254

Epoch: 6| Step: 13
Training loss: 1.7218952184691265
Validation loss: 2.7231069563024977

Epoch: 133| Step: 0
Training loss: 1.619660481561184
Validation loss: 2.68954178777786

Epoch: 6| Step: 1
Training loss: 1.8518315373295475
Validation loss: 2.7468466886378526

Epoch: 6| Step: 2
Training loss: 1.209568357165786
Validation loss: 2.7465181560859557

Epoch: 6| Step: 3
Training loss: 1.8916330723853376
Validation loss: 2.6896023770068616

Epoch: 6| Step: 4
Training loss: 1.5400879827360094
Validation loss: 2.698332151923609

Epoch: 6| Step: 5
Training loss: 2.2998703090757346
Validation loss: 2.6378587758985663

Epoch: 6| Step: 6
Training loss: 1.7550075276531267
Validation loss: 2.5707145384221315

Epoch: 6| Step: 7
Training loss: 1.4692985646541437
Validation loss: 2.607175954968208

Epoch: 6| Step: 8
Training loss: 1.7993348243629936
Validation loss: 2.5844521688973816

Epoch: 6| Step: 9
Training loss: 1.5311403819182046
Validation loss: 2.564897051871362

Epoch: 6| Step: 10
Training loss: 1.7565911691331835
Validation loss: 2.5863453215973347

Epoch: 6| Step: 11
Training loss: 1.744387345415561
Validation loss: 2.6216913594681386

Epoch: 6| Step: 12
Training loss: 1.858044059830521
Validation loss: 2.5795416744735618

Epoch: 6| Step: 13
Training loss: 2.695777919225305
Validation loss: 2.607078165743511

Epoch: 134| Step: 0
Training loss: 1.8276696575436473
Validation loss: 2.5995979566774734

Epoch: 6| Step: 1
Training loss: 1.8048377036468202
Validation loss: 2.5371293910692825

Epoch: 6| Step: 2
Training loss: 1.9221492044488138
Validation loss: 2.5754236422188526

Epoch: 6| Step: 3
Training loss: 1.4266574623280404
Validation loss: 2.5899635160667582

Epoch: 6| Step: 4
Training loss: 2.0491026193549255
Validation loss: 2.5851308711291328

Epoch: 6| Step: 5
Training loss: 1.9635517582182926
Validation loss: 2.627286066939608

Epoch: 6| Step: 6
Training loss: 1.9797416119605542
Validation loss: 2.6692721681669047

Epoch: 6| Step: 7
Training loss: 2.2479651044329607
Validation loss: 2.617255169197672

Epoch: 6| Step: 8
Training loss: 2.41088846172863
Validation loss: 2.6320235582425933

Epoch: 6| Step: 9
Training loss: 2.063171739716177
Validation loss: 2.629083076716044

Epoch: 6| Step: 10
Training loss: 1.5788759767554847
Validation loss: 2.6431368781955156

Epoch: 6| Step: 11
Training loss: 1.2814952336526702
Validation loss: 2.5621340420549403

Epoch: 6| Step: 12
Training loss: 1.3503175856413503
Validation loss: 2.666829422116583

Epoch: 6| Step: 13
Training loss: 1.1064421880127442
Validation loss: 2.614001773023211

Epoch: 135| Step: 0
Training loss: 1.28286827049806
Validation loss: 2.6238135275283967

Epoch: 6| Step: 1
Training loss: 1.7596791846313087
Validation loss: 2.6207776094546036

Epoch: 6| Step: 2
Training loss: 1.5616714569610006
Validation loss: 2.620555680329571

Epoch: 6| Step: 3
Training loss: 1.638061846374803
Validation loss: 2.5693997170160987

Epoch: 6| Step: 4
Training loss: 1.8507434304891257
Validation loss: 2.5825225624263344

Epoch: 6| Step: 5
Training loss: 2.138986559147491
Validation loss: 2.580716073740451

Epoch: 6| Step: 6
Training loss: 2.638560193209258
Validation loss: 2.5491055353455625

Epoch: 6| Step: 7
Training loss: 1.8795237963794489
Validation loss: 2.5581770229944736

Epoch: 6| Step: 8
Training loss: 1.8332531073385383
Validation loss: 2.572088723555276

Epoch: 6| Step: 9
Training loss: 1.6169126710163908
Validation loss: 2.652017010511002

Epoch: 6| Step: 10
Training loss: 1.2946848932967852
Validation loss: 2.6426210853409686

Epoch: 6| Step: 11
Training loss: 1.6979397575196877
Validation loss: 2.658595347471726

Epoch: 6| Step: 12
Training loss: 2.2901613898231643
Validation loss: 2.6581699314142426

Epoch: 6| Step: 13
Training loss: 1.8883080906315721
Validation loss: 2.671065075759377

Epoch: 136| Step: 0
Training loss: 1.8318306949376548
Validation loss: 2.581024535387062

Epoch: 6| Step: 1
Training loss: 1.927718482295019
Validation loss: 2.6522309359349756

Epoch: 6| Step: 2
Training loss: 1.9001109592763934
Validation loss: 2.607871957096941

Epoch: 6| Step: 3
Training loss: 1.304307345439405
Validation loss: 2.5653698675477936

Epoch: 6| Step: 4
Training loss: 1.9632654240278122
Validation loss: 2.660368789046876

Epoch: 6| Step: 5
Training loss: 1.796131411402737
Validation loss: 2.5951131662599023

Epoch: 6| Step: 6
Training loss: 1.1294623988268797
Validation loss: 2.6503303987636095

Epoch: 6| Step: 7
Training loss: 1.4940619553942187
Validation loss: 2.611211134525632

Epoch: 6| Step: 8
Training loss: 1.6401892673788312
Validation loss: 2.587342171762113

Epoch: 6| Step: 9
Training loss: 1.6107389725493106
Validation loss: 2.5722268347107207

Epoch: 6| Step: 10
Training loss: 1.5646802568277545
Validation loss: 2.6248403985081032

Epoch: 6| Step: 11
Training loss: 1.711923532846024
Validation loss: 2.603250774811681

Epoch: 6| Step: 12
Training loss: 2.6003454529075145
Validation loss: 2.569714833257676

Epoch: 6| Step: 13
Training loss: 2.020425211276773
Validation loss: 2.6072893163772295

Epoch: 137| Step: 0
Training loss: 1.854215564154465
Validation loss: 2.6445238272010085

Epoch: 6| Step: 1
Training loss: 1.551766109264321
Validation loss: 2.640059958051624

Epoch: 6| Step: 2
Training loss: 2.0448891127912194
Validation loss: 2.6873712730628507

Epoch: 6| Step: 3
Training loss: 2.2581508079424486
Validation loss: 2.605435746273197

Epoch: 6| Step: 4
Training loss: 1.6421707863869086
Validation loss: 2.695645032631803

Epoch: 6| Step: 5
Training loss: 1.3505951611472145
Validation loss: 2.6307431624624353

Epoch: 6| Step: 6
Training loss: 1.760263251968949
Validation loss: 2.62699260469288

Epoch: 6| Step: 7
Training loss: 1.451153309678939
Validation loss: 2.624911321928395

Epoch: 6| Step: 8
Training loss: 2.0252404152653143
Validation loss: 2.6333488876350177

Epoch: 6| Step: 9
Training loss: 1.627468361847347
Validation loss: 2.652674718478205

Epoch: 6| Step: 10
Training loss: 1.7558802856965374
Validation loss: 2.628613331438039

Epoch: 6| Step: 11
Training loss: 1.865504444003531
Validation loss: 2.584550560519959

Epoch: 6| Step: 12
Training loss: 1.1561602995848723
Validation loss: 2.6544204544667735

Epoch: 6| Step: 13
Training loss: 1.839150915880719
Validation loss: 2.6199379962883755

Epoch: 138| Step: 0
Training loss: 1.8486791122289057
Validation loss: 2.6260515710406094

Epoch: 6| Step: 1
Training loss: 1.7833196428551836
Validation loss: 2.6207955006434656

Epoch: 6| Step: 2
Training loss: 2.009947832483878
Validation loss: 2.612222279232195

Epoch: 6| Step: 3
Training loss: 1.423022299886021
Validation loss: 2.6269205122084966

Epoch: 6| Step: 4
Training loss: 1.58154296875
Validation loss: 2.5486758677484236

Epoch: 6| Step: 5
Training loss: 1.2236250186802866
Validation loss: 2.597741437772384

Epoch: 6| Step: 6
Training loss: 1.7010293368725664
Validation loss: 2.5893640471888273

Epoch: 6| Step: 7
Training loss: 1.3497328529236718
Validation loss: 2.583370882704827

Epoch: 6| Step: 8
Training loss: 1.9717639680244097
Validation loss: 2.5930394114671875

Epoch: 6| Step: 9
Training loss: 1.589385245376789
Validation loss: 2.636547469239093

Epoch: 6| Step: 10
Training loss: 1.7625173040311626
Validation loss: 2.641389815046105

Epoch: 6| Step: 11
Training loss: 1.4698621718999112
Validation loss: 2.6783349096233837

Epoch: 6| Step: 12
Training loss: 2.206230301809583
Validation loss: 2.5700384610386786

Epoch: 6| Step: 13
Training loss: 1.9597335706358652
Validation loss: 2.640086297758469

Epoch: 139| Step: 0
Training loss: 1.4115649343777437
Validation loss: 2.5853361907737935

Epoch: 6| Step: 1
Training loss: 2.0298506391477513
Validation loss: 2.5695252454499444

Epoch: 6| Step: 2
Training loss: 1.5985868024409418
Validation loss: 2.5862366195044952

Epoch: 6| Step: 3
Training loss: 1.4862311553402054
Validation loss: 2.5451780723572845

Epoch: 6| Step: 4
Training loss: 1.8515763423096432
Validation loss: 2.6264980522326216

Epoch: 6| Step: 5
Training loss: 1.6350657416609347
Validation loss: 2.5999481721749786

Epoch: 6| Step: 6
Training loss: 1.8337081684939778
Validation loss: 2.5776782486827754

Epoch: 6| Step: 7
Training loss: 1.3857094543763266
Validation loss: 2.594161648237417

Epoch: 6| Step: 8
Training loss: 2.045062245212109
Validation loss: 2.631274112521466

Epoch: 6| Step: 9
Training loss: 1.4998828524302836
Validation loss: 2.577365431974309

Epoch: 6| Step: 10
Training loss: 1.5830234759789534
Validation loss: 2.5975663936820137

Epoch: 6| Step: 11
Training loss: 1.8383276781541031
Validation loss: 2.5800275082932953

Epoch: 6| Step: 12
Training loss: 1.2772447273532335
Validation loss: 2.6060490760227246

Epoch: 6| Step: 13
Training loss: 2.2920229779301655
Validation loss: 2.647055296178724

Epoch: 140| Step: 0
Training loss: 1.2757854697536708
Validation loss: 2.629299502838277

Epoch: 6| Step: 1
Training loss: 1.093852174618631
Validation loss: 2.635605143164015

Epoch: 6| Step: 2
Training loss: 2.036589895488236
Validation loss: 2.5957168490714637

Epoch: 6| Step: 3
Training loss: 1.4555757426948135
Validation loss: 2.5768061029015126

Epoch: 6| Step: 4
Training loss: 1.58884107759355
Validation loss: 2.6768636477290024

Epoch: 6| Step: 5
Training loss: 1.7710224798575445
Validation loss: 2.629463593955284

Epoch: 6| Step: 6
Training loss: 1.639683189728126
Validation loss: 2.559963583736886

Epoch: 6| Step: 7
Training loss: 2.1598634159208654
Validation loss: 2.5941940831337753

Epoch: 6| Step: 8
Training loss: 1.233956761064783
Validation loss: 2.558736720470761

Epoch: 6| Step: 9
Training loss: 1.848354731792189
Validation loss: 2.680746716242453

Epoch: 6| Step: 10
Training loss: 1.5980615078543574
Validation loss: 2.661557687794837

Epoch: 6| Step: 11
Training loss: 2.4499997197365113
Validation loss: 2.6405750623566986

Epoch: 6| Step: 12
Training loss: 2.0289824520309225
Validation loss: 2.606782702947086

Epoch: 6| Step: 13
Training loss: 1.5188891468747068
Validation loss: 2.664882962398663

Epoch: 141| Step: 0
Training loss: 1.4189890823912052
Validation loss: 2.6199550742017643

Epoch: 6| Step: 1
Training loss: 1.7609238956606257
Validation loss: 2.6728371417811414

Epoch: 6| Step: 2
Training loss: 1.4760480519409909
Validation loss: 2.6083143595126246

Epoch: 6| Step: 3
Training loss: 1.5658795239326937
Validation loss: 2.6681801454825256

Epoch: 6| Step: 4
Training loss: 1.9914059770298826
Validation loss: 2.7237547268942457

Epoch: 6| Step: 5
Training loss: 1.7225905079309813
Validation loss: 2.6818655891641536

Epoch: 6| Step: 6
Training loss: 1.5429235524185207
Validation loss: 2.6354927660141336

Epoch: 6| Step: 7
Training loss: 1.4800179230403772
Validation loss: 2.6371112446586933

Epoch: 6| Step: 8
Training loss: 1.444063296322994
Validation loss: 2.6136187614380937

Epoch: 6| Step: 9
Training loss: 1.3995436231077498
Validation loss: 2.640605783486653

Epoch: 6| Step: 10
Training loss: 1.2998883272770447
Validation loss: 2.5834980932629446

Epoch: 6| Step: 11
Training loss: 1.8230652521521922
Validation loss: 2.5588295398419754

Epoch: 6| Step: 12
Training loss: 1.960909900243083
Validation loss: 2.6423556733935283

Epoch: 6| Step: 13
Training loss: 2.39176016391091
Validation loss: 2.5536286067880845

Epoch: 142| Step: 0
Training loss: 2.4023483152268614
Validation loss: 2.603090282512446

Epoch: 6| Step: 1
Training loss: 1.9246637224034586
Validation loss: 2.5799689432241424

Epoch: 6| Step: 2
Training loss: 1.2342514748876459
Validation loss: 2.6122253139713187

Epoch: 6| Step: 3
Training loss: 1.9271184832142385
Validation loss: 2.646017418612552

Epoch: 6| Step: 4
Training loss: 1.6082500488907439
Validation loss: 2.5843435639972263

Epoch: 6| Step: 5
Training loss: 1.749486030306975
Validation loss: 2.555099360779142

Epoch: 6| Step: 6
Training loss: 1.2666554906418976
Validation loss: 2.5850088059590797

Epoch: 6| Step: 7
Training loss: 1.3771759502220016
Validation loss: 2.572170957746082

Epoch: 6| Step: 8
Training loss: 1.3880365691685659
Validation loss: 2.6115119163717995

Epoch: 6| Step: 9
Training loss: 1.9468058174295628
Validation loss: 2.6310444072705392

Epoch: 6| Step: 10
Training loss: 1.1252817225041163
Validation loss: 2.6192429399525374

Epoch: 6| Step: 11
Training loss: 2.0115982167698574
Validation loss: 2.67081222069579

Epoch: 6| Step: 12
Training loss: 1.3395530452043092
Validation loss: 2.618029042544526

Epoch: 6| Step: 13
Training loss: 1.601559894838773
Validation loss: 2.5919689973176037

Epoch: 143| Step: 0
Training loss: 1.7957380595531833
Validation loss: 2.621955248665883

Epoch: 6| Step: 1
Training loss: 1.6572988535950792
Validation loss: 2.601672532023877

Epoch: 6| Step: 2
Training loss: 1.3269289353091434
Validation loss: 2.5794922025966542

Epoch: 6| Step: 3
Training loss: 1.5341796875
Validation loss: 2.6131449133068543

Epoch: 6| Step: 4
Training loss: 1.8380252736110854
Validation loss: 2.642447089390644

Epoch: 6| Step: 5
Training loss: 2.3312414419717666
Validation loss: 2.629976210722285

Epoch: 6| Step: 6
Training loss: 1.7353942900180905
Validation loss: 2.6232483332708747

Epoch: 6| Step: 7
Training loss: 1.6270096896116912
Validation loss: 2.619930488644689

Epoch: 6| Step: 8
Training loss: 0.9747744250391411
Validation loss: 2.6844776961400147

Epoch: 6| Step: 9
Training loss: 1.6016403551484304
Validation loss: 2.5906390258384837

Epoch: 6| Step: 10
Training loss: 1.5662764117304184
Validation loss: 2.616872375647316

Epoch: 6| Step: 11
Training loss: 1.5978588917751475
Validation loss: 2.6734289368715825

Epoch: 6| Step: 12
Training loss: 1.3684067003852698
Validation loss: 2.6368393406548085

Epoch: 6| Step: 13
Training loss: 1.78679163041487
Validation loss: 2.6379915909246305

Epoch: 144| Step: 0
Training loss: 1.2827222785400256
Validation loss: 2.613817373800305

Epoch: 6| Step: 1
Training loss: 1.4755164583865972
Validation loss: 2.6325576764557175

Epoch: 6| Step: 2
Training loss: 1.8017542397068236
Validation loss: 2.6903878745852863

Epoch: 6| Step: 3
Training loss: 2.2972746001912965
Validation loss: 2.731707261578892

Epoch: 6| Step: 4
Training loss: 1.5385042523910177
Validation loss: 2.680355541121908

Epoch: 6| Step: 5
Training loss: 0.8694621316561718
Validation loss: 2.6381405611474724

Epoch: 6| Step: 6
Training loss: 1.3734145126762571
Validation loss: 2.6398849804704607

Epoch: 6| Step: 7
Training loss: 1.5558598377821855
Validation loss: 2.6004903300415494

Epoch: 6| Step: 8
Training loss: 1.5232964083552911
Validation loss: 2.6159870488101893

Epoch: 6| Step: 9
Training loss: 2.4461372130390906
Validation loss: 2.6050816162073778

Epoch: 6| Step: 10
Training loss: 1.9161001764242755
Validation loss: 2.604294252449143

Epoch: 6| Step: 11
Training loss: 0.9186606538886782
Validation loss: 2.615780428419977

Epoch: 6| Step: 12
Training loss: 1.5224493489977498
Validation loss: 2.633391228976983

Epoch: 6| Step: 13
Training loss: 1.4737117637482111
Validation loss: 2.620631655244802

Epoch: 145| Step: 0
Training loss: 1.1719987422461156
Validation loss: 2.64906524150455

Epoch: 6| Step: 1
Training loss: 1.609481437644799
Validation loss: 2.624488523395562

Epoch: 6| Step: 2
Training loss: 2.1437108428315
Validation loss: 2.6102241611561556

Epoch: 6| Step: 3
Training loss: 1.800885973220876
Validation loss: 2.591756652197953

Epoch: 6| Step: 4
Training loss: 1.8020084196480386
Validation loss: 2.586456845964569

Epoch: 6| Step: 5
Training loss: 1.955769449996734
Validation loss: 2.6870714925358308

Epoch: 6| Step: 6
Training loss: 1.3835539473371685
Validation loss: 2.591961761266135

Epoch: 6| Step: 7
Training loss: 1.7469068848458693
Validation loss: 2.589222077275145

Epoch: 6| Step: 8
Training loss: 1.7375499086964903
Validation loss: 2.630372914116013

Epoch: 6| Step: 9
Training loss: 1.3571130634565398
Validation loss: 2.5953034035042695

Epoch: 6| Step: 10
Training loss: 0.995726274510832
Validation loss: 2.6192210178236093

Epoch: 6| Step: 11
Training loss: 1.5894161464751846
Validation loss: 2.623317527489102

Epoch: 6| Step: 12
Training loss: 1.5264069398864193
Validation loss: 2.6983386903897744

Epoch: 6| Step: 13
Training loss: 1.4234398415773397
Validation loss: 2.7047356454144125

Epoch: 146| Step: 0
Training loss: 1.974255206515328
Validation loss: 2.6955464432034626

Epoch: 6| Step: 1
Training loss: 2.1838681180001753
Validation loss: 2.660640304673151

Epoch: 6| Step: 2
Training loss: 1.1760996644028603
Validation loss: 2.6621153456615607

Epoch: 6| Step: 3
Training loss: 1.3464349935189819
Validation loss: 2.6818042102326345

Epoch: 6| Step: 4
Training loss: 1.6470160118116832
Validation loss: 2.6764785192245126

Epoch: 6| Step: 5
Training loss: 1.2388440125914035
Validation loss: 2.6391386178849574

Epoch: 6| Step: 6
Training loss: 1.5361785202841012
Validation loss: 2.61022492232496

Epoch: 6| Step: 7
Training loss: 1.924463529269464
Validation loss: 2.6308015110418115

Epoch: 6| Step: 8
Training loss: 1.6234208283288873
Validation loss: 2.6923166183176996

Epoch: 6| Step: 9
Training loss: 1.690097575671996
Validation loss: 2.6885347518230924

Epoch: 6| Step: 10
Training loss: 1.6652660047411738
Validation loss: 2.61964295245147

Epoch: 6| Step: 11
Training loss: 2.4322397252376606
Validation loss: 2.646915835110972

Epoch: 6| Step: 12
Training loss: 1.5286176203431756
Validation loss: 2.6240678449137684

Epoch: 6| Step: 13
Training loss: 1.731100203991602
Validation loss: 2.564716481507965

Epoch: 147| Step: 0
Training loss: 1.594951102245673
Validation loss: 2.6509969041763815

Epoch: 6| Step: 1
Training loss: 1.3511928427691307
Validation loss: 2.6816453371055196

Epoch: 6| Step: 2
Training loss: 1.950989616366411
Validation loss: 2.659895000429

Epoch: 6| Step: 3
Training loss: 1.8708832369508555
Validation loss: 2.59086937635628

Epoch: 6| Step: 4
Training loss: 1.9200129598935154
Validation loss: 2.6638182139333257

Epoch: 6| Step: 5
Training loss: 1.0983312845765736
Validation loss: 2.6640549973785865

Epoch: 6| Step: 6
Training loss: 1.495791173073372
Validation loss: 2.613722356756202

Epoch: 6| Step: 7
Training loss: 1.3810706941380775
Validation loss: 2.6735510151922424

Epoch: 6| Step: 8
Training loss: 1.4215479883445736
Validation loss: 2.6237508435586463

Epoch: 6| Step: 9
Training loss: 1.7434360836862273
Validation loss: 2.6005802457687235

Epoch: 6| Step: 10
Training loss: 2.303222190431504
Validation loss: 2.6091501896728944

Epoch: 6| Step: 11
Training loss: 1.6733072866005887
Validation loss: 2.6362281926957745

Epoch: 6| Step: 12
Training loss: 1.04400120755926
Validation loss: 2.674936841652877

Epoch: 6| Step: 13
Training loss: 1.541192763751596
Validation loss: 2.6071895348214293

Epoch: 148| Step: 0
Training loss: 1.7878943215103391
Validation loss: 2.611007332148558

Epoch: 6| Step: 1
Training loss: 2.1721028819016444
Validation loss: 2.64174628293211

Epoch: 6| Step: 2
Training loss: 2.183673345380987
Validation loss: 2.6558615456566774

Epoch: 6| Step: 3
Training loss: 1.002299525890145
Validation loss: 2.6262340596735223

Epoch: 6| Step: 4
Training loss: 1.5885615696728532
Validation loss: 2.6528512790299263

Epoch: 6| Step: 5
Training loss: 1.2504131588012208
Validation loss: 2.620093945658327

Epoch: 6| Step: 6
Training loss: 1.19084699668725
Validation loss: 2.6468943673618415

Epoch: 6| Step: 7
Training loss: 1.228625609503787
Validation loss: 2.696532234225107

Epoch: 6| Step: 8
Training loss: 1.6001875022456398
Validation loss: 2.5767926713435214

Epoch: 6| Step: 9
Training loss: 1.3087619047160886
Validation loss: 2.6557986455670344

Epoch: 6| Step: 10
Training loss: 1.5277071859446556
Validation loss: 2.7328581317445644

Epoch: 6| Step: 11
Training loss: 1.9937440662833859
Validation loss: 2.58915847910444

Epoch: 6| Step: 12
Training loss: 1.2597693628063493
Validation loss: 2.6542758561874735

Epoch: 6| Step: 13
Training loss: 1.8605560911191803
Validation loss: 2.6411627648879756

Epoch: 149| Step: 0
Training loss: 1.3490624209667517
Validation loss: 2.668323967941245

Epoch: 6| Step: 1
Training loss: 1.9579170339188519
Validation loss: 2.564275126733262

Epoch: 6| Step: 2
Training loss: 1.7033782210783925
Validation loss: 2.5948184773210996

Epoch: 6| Step: 3
Training loss: 1.5668647076177795
Validation loss: 2.6126091686358213

Epoch: 6| Step: 4
Training loss: 1.535339965698873
Validation loss: 2.639797555068264

Epoch: 6| Step: 5
Training loss: 1.3998049225453706
Validation loss: 2.6451500488439303

Epoch: 6| Step: 6
Training loss: 1.4881937797253366
Validation loss: 2.704025794671775

Epoch: 6| Step: 7
Training loss: 1.779411839812949
Validation loss: 2.582908015976403

Epoch: 6| Step: 8
Training loss: 1.7870516074594456
Validation loss: 2.6752501171746452

Epoch: 6| Step: 9
Training loss: 1.339926047063692
Validation loss: 2.540989712683941

Epoch: 6| Step: 10
Training loss: 1.5272377543243365
Validation loss: 2.651776537314336

Epoch: 6| Step: 11
Training loss: 1.1111475792834127
Validation loss: 2.633533382864957

Epoch: 6| Step: 12
Training loss: 1.3790507038302622
Validation loss: 2.677754972245576

Epoch: 6| Step: 13
Training loss: 2.045316262820916
Validation loss: 2.7057919732087092

Epoch: 150| Step: 0
Training loss: 1.5657045690604932
Validation loss: 2.6550088039498876

Epoch: 6| Step: 1
Training loss: 1.5192849712304677
Validation loss: 2.6843821604303466

Epoch: 6| Step: 2
Training loss: 1.5810166861554167
Validation loss: 2.587748006093714

Epoch: 6| Step: 3
Training loss: 1.142573847314375
Validation loss: 2.5944012663046223

Epoch: 6| Step: 4
Training loss: 2.0210328413282994
Validation loss: 2.5186516539855095

Epoch: 6| Step: 5
Training loss: 1.5521507845906817
Validation loss: 2.6076770367112836

Epoch: 6| Step: 6
Training loss: 1.6959014432134267
Validation loss: 2.589681130237954

Epoch: 6| Step: 7
Training loss: 1.300654133035508
Validation loss: 2.6131912770960173

Epoch: 6| Step: 8
Training loss: 1.8832502687191464
Validation loss: 2.636523942697482

Epoch: 6| Step: 9
Training loss: 1.9304045298695918
Validation loss: 2.583186119766213

Epoch: 6| Step: 10
Training loss: 1.2597753716616658
Validation loss: 2.5515135823264004

Epoch: 6| Step: 11
Training loss: 1.3694858088682513
Validation loss: 2.65838842145549

Epoch: 6| Step: 12
Training loss: 1.1910782159189914
Validation loss: 2.6657458642806295

Epoch: 6| Step: 13
Training loss: 1.5078590662589593
Validation loss: 2.602154264458104

Epoch: 151| Step: 0
Training loss: 1.6196757905813925
Validation loss: 2.661183178159656

Epoch: 6| Step: 1
Training loss: 1.7355452704738814
Validation loss: 2.6368615985369166

Epoch: 6| Step: 2
Training loss: 1.0876955579996133
Validation loss: 2.6771936554695315

Epoch: 6| Step: 3
Training loss: 1.8172536534529677
Validation loss: 2.568685029902866

Epoch: 6| Step: 4
Training loss: 1.4636529991005802
Validation loss: 2.6035165407561216

Epoch: 6| Step: 5
Training loss: 1.3119315778464065
Validation loss: 2.6030135284650657

Epoch: 6| Step: 6
Training loss: 1.1063572847747227
Validation loss: 2.6117608894176394

Epoch: 6| Step: 7
Training loss: 1.4219308360109086
Validation loss: 2.644842357733164

Epoch: 6| Step: 8
Training loss: 1.2507706650638108
Validation loss: 2.611045241934165

Epoch: 6| Step: 9
Training loss: 1.6506194368013738
Validation loss: 2.619988532029114

Epoch: 6| Step: 10
Training loss: 2.2774531500108592
Validation loss: 2.619704415073609

Epoch: 6| Step: 11
Training loss: 1.209014793592615
Validation loss: 2.688317071183981

Epoch: 6| Step: 12
Training loss: 1.543056360002856
Validation loss: 2.7207348473226927

Epoch: 6| Step: 13
Training loss: 1.7675958621995072
Validation loss: 2.612444079711711

Epoch: 152| Step: 0
Training loss: 1.8698403893146738
Validation loss: 2.6062325383248597

Epoch: 6| Step: 1
Training loss: 1.2513925425064167
Validation loss: 2.643301290395639

Epoch: 6| Step: 2
Training loss: 2.3389454742899973
Validation loss: 2.649040453607099

Epoch: 6| Step: 3
Training loss: 1.219406293568161
Validation loss: 2.631625306825362

Epoch: 6| Step: 4
Training loss: 1.341390800942541
Validation loss: 2.616599993453638

Epoch: 6| Step: 5
Training loss: 1.2749333869138046
Validation loss: 2.6000101003695195

Epoch: 6| Step: 6
Training loss: 1.4581204758568604
Validation loss: 2.582449674728373

Epoch: 6| Step: 7
Training loss: 1.9384006744827564
Validation loss: 2.640262165008926

Epoch: 6| Step: 8
Training loss: 1.1078353728823718
Validation loss: 2.6813110089715577

Epoch: 6| Step: 9
Training loss: 1.4677046444343178
Validation loss: 2.63556286000497

Epoch: 6| Step: 10
Training loss: 1.583436845440877
Validation loss: 2.62973749963588

Epoch: 6| Step: 11
Training loss: 1.4938958260450115
Validation loss: 2.632502597035923

Epoch: 6| Step: 12
Training loss: 1.4341035606838557
Validation loss: 2.6116598865304983

Epoch: 6| Step: 13
Training loss: 1.0258158065658007
Validation loss: 2.6316020684732337

Epoch: 153| Step: 0
Training loss: 1.5467336570822166
Validation loss: 2.6629027287414857

Epoch: 6| Step: 1
Training loss: 1.5615686311080421
Validation loss: 2.644202207664478

Epoch: 6| Step: 2
Training loss: 1.4945975608492355
Validation loss: 2.583073931150061

Epoch: 6| Step: 3
Training loss: 1.4430963795410656
Validation loss: 2.592927511250665

Epoch: 6| Step: 4
Training loss: 1.1995159364939993
Validation loss: 2.6058535999387926

Epoch: 6| Step: 5
Training loss: 1.5716187467311862
Validation loss: 2.5190021442324952

Epoch: 6| Step: 6
Training loss: 1.2933737129285394
Validation loss: 2.663582931117358

Epoch: 6| Step: 7
Training loss: 1.3601625287887729
Validation loss: 2.5966034019983666

Epoch: 6| Step: 8
Training loss: 1.1993232209367908
Validation loss: 2.5622616478701787

Epoch: 6| Step: 9
Training loss: 1.2795712242352633
Validation loss: 2.655873126053141

Epoch: 6| Step: 10
Training loss: 2.3821029857469616
Validation loss: 2.583402907039669

Epoch: 6| Step: 11
Training loss: 1.5729607413813613
Validation loss: 2.6601100773849056

Epoch: 6| Step: 12
Training loss: 1.3333917197715786
Validation loss: 2.63820623190072

Epoch: 6| Step: 13
Training loss: 1.6867869248069558
Validation loss: 2.6100176174110015

Epoch: 154| Step: 0
Training loss: 1.063329821394459
Validation loss: 2.6108301563367395

Epoch: 6| Step: 1
Training loss: 1.0968547895259564
Validation loss: 2.632898640567652

Epoch: 6| Step: 2
Training loss: 1.597700794596969
Validation loss: 2.6470988443565577

Epoch: 6| Step: 3
Training loss: 1.5655594437021982
Validation loss: 2.6228933509555934

Epoch: 6| Step: 4
Training loss: 2.002367049434039
Validation loss: 2.571586223719549

Epoch: 6| Step: 5
Training loss: 1.7055929658592635
Validation loss: 2.602354217511299

Epoch: 6| Step: 6
Training loss: 1.7496992261452442
Validation loss: 2.628082100861697

Epoch: 6| Step: 7
Training loss: 1.0172401496633414
Validation loss: 2.656668177579915

Epoch: 6| Step: 8
Training loss: 2.026254938532596
Validation loss: 2.6124417373025515

Epoch: 6| Step: 9
Training loss: 1.575178738700199
Validation loss: 2.5988039316144205

Epoch: 6| Step: 10
Training loss: 1.8229938454411625
Validation loss: 2.5883408717381178

Epoch: 6| Step: 11
Training loss: 1.6982008417327128
Validation loss: 2.608225677836072

Epoch: 6| Step: 12
Training loss: 1.1949395988075209
Validation loss: 2.6460776979635106

Epoch: 6| Step: 13
Training loss: 1.0815606040464028
Validation loss: 2.659737111894603

Epoch: 155| Step: 0
Training loss: 1.1725248950682234
Validation loss: 2.589074681832189

Epoch: 6| Step: 1
Training loss: 1.105872198560738
Validation loss: 2.675537380419571

Epoch: 6| Step: 2
Training loss: 1.5986541392419071
Validation loss: 2.7071542533022823

Epoch: 6| Step: 3
Training loss: 1.3580523227533445
Validation loss: 2.661089493985155

Epoch: 6| Step: 4
Training loss: 1.1835316053134182
Validation loss: 2.657897408437521

Epoch: 6| Step: 5
Training loss: 1.0824096789132411
Validation loss: 2.6238422414053404

Epoch: 6| Step: 6
Training loss: 1.2304615807702852
Validation loss: 2.5634955356440723

Epoch: 6| Step: 7
Training loss: 1.1262040053278608
Validation loss: 2.599503306482688

Epoch: 6| Step: 8
Training loss: 1.700043015777296
Validation loss: 2.659721394985016

Epoch: 6| Step: 9
Training loss: 1.6066855764001722
Validation loss: 2.5944292948423704

Epoch: 6| Step: 10
Training loss: 2.14298057427727
Validation loss: 2.6405611801711792

Epoch: 6| Step: 11
Training loss: 1.0455964094905892
Validation loss: 2.6282045845987834

Epoch: 6| Step: 12
Training loss: 1.3954479292774005
Validation loss: 2.5408180936075024

Epoch: 6| Step: 13
Training loss: 2.2497352868234985
Validation loss: 2.576414369204074

Epoch: 156| Step: 0
Training loss: 1.5198578079120961
Validation loss: 2.67682764239908

Epoch: 6| Step: 1
Training loss: 1.3524697847217162
Validation loss: 2.6795481357349757

Epoch: 6| Step: 2
Training loss: 1.7518880740605676
Validation loss: 2.691039881248755

Epoch: 6| Step: 3
Training loss: 1.3220144734852766
Validation loss: 2.753039378271975

Epoch: 6| Step: 4
Training loss: 1.4250565868987966
Validation loss: 2.697200847108449

Epoch: 6| Step: 5
Training loss: 1.5040455939402646
Validation loss: 2.722731718297191

Epoch: 6| Step: 6
Training loss: 1.3760500712959844
Validation loss: 2.6124152405539927

Epoch: 6| Step: 7
Training loss: 1.1046261221359923
Validation loss: 2.6382426664140297

Epoch: 6| Step: 8
Training loss: 1.5655059891046752
Validation loss: 2.5571352152673428

Epoch: 6| Step: 9
Training loss: 1.4076532779797304
Validation loss: 2.6328297358853323

Epoch: 6| Step: 10
Training loss: 1.465797053082034
Validation loss: 2.638069631885249

Epoch: 6| Step: 11
Training loss: 0.9680241665128885
Validation loss: 2.5698225642401966

Epoch: 6| Step: 12
Training loss: 2.3318821845024464
Validation loss: 2.637388589805042

Epoch: 6| Step: 13
Training loss: 0.786263212205167
Validation loss: 2.6627150453216726

Epoch: 157| Step: 0
Training loss: 2.292174843595235
Validation loss: 2.606433116112029

Epoch: 6| Step: 1
Training loss: 1.3442792958945655
Validation loss: 2.605560392629674

Epoch: 6| Step: 2
Training loss: 1.04108650581717
Validation loss: 2.6208700358414037

Epoch: 6| Step: 3
Training loss: 1.7402672555816274
Validation loss: 2.6294805948900635

Epoch: 6| Step: 4
Training loss: 1.1670421382157612
Validation loss: 2.6300203665366593

Epoch: 6| Step: 5
Training loss: 1.5146676412185256
Validation loss: 2.681651353177891

Epoch: 6| Step: 6
Training loss: 1.6164026982161015
Validation loss: 2.639226554437645

Epoch: 6| Step: 7
Training loss: 1.49205647637297
Validation loss: 2.6525590722124432

Epoch: 6| Step: 8
Training loss: 1.203239138254788
Validation loss: 2.620925405206136

Epoch: 6| Step: 9
Training loss: 0.9763847494482276
Validation loss: 2.626746172121262

Epoch: 6| Step: 10
Training loss: 1.1019000895603226
Validation loss: 2.6614432934798313

Epoch: 6| Step: 11
Training loss: 1.531304416857338
Validation loss: 2.6203207362755823

Epoch: 6| Step: 12
Training loss: 1.4112410243165372
Validation loss: 2.626493437867216

Epoch: 6| Step: 13
Training loss: 1.5666894823130966
Validation loss: 2.6677969732507076

Epoch: 158| Step: 0
Training loss: 1.356422023147575
Validation loss: 2.7067357608905325

Epoch: 6| Step: 1
Training loss: 1.483470038568835
Validation loss: 2.652613195891673

Epoch: 6| Step: 2
Training loss: 1.500050067066041
Validation loss: 2.62890077829382

Epoch: 6| Step: 3
Training loss: 2.313168300253276
Validation loss: 2.6835662381364354

Epoch: 6| Step: 4
Training loss: 1.7271742621560362
Validation loss: 2.6011069570058556

Epoch: 6| Step: 5
Training loss: 1.382271698628068
Validation loss: 2.63782135691589

Epoch: 6| Step: 6
Training loss: 1.5902105184858473
Validation loss: 2.614759907832907

Epoch: 6| Step: 7
Training loss: 1.4609862946710188
Validation loss: 2.6511036404084027

Epoch: 6| Step: 8
Training loss: 0.9540031640062306
Validation loss: 2.6179873634404482

Epoch: 6| Step: 9
Training loss: 1.6670266557380424
Validation loss: 2.619351918276517

Epoch: 6| Step: 10
Training loss: 1.2465667305293848
Validation loss: 2.5339631504459557

Epoch: 6| Step: 11
Training loss: 1.258757100317286
Validation loss: 2.644720329012698

Epoch: 6| Step: 12
Training loss: 1.204034436807482
Validation loss: 2.6381531381270023

Epoch: 6| Step: 13
Training loss: 1.1976654729220517
Validation loss: 2.651271792593069

Epoch: 159| Step: 0
Training loss: 1.1068458202614861
Validation loss: 2.655977938313855

Epoch: 6| Step: 1
Training loss: 1.4419597607102523
Validation loss: 2.6476501824969896

Epoch: 6| Step: 2
Training loss: 1.4974494548539958
Validation loss: 2.6376507804884253

Epoch: 6| Step: 3
Training loss: 1.6154241853974731
Validation loss: 2.64794843841228

Epoch: 6| Step: 4
Training loss: 0.8578780227401108
Validation loss: 2.6731781189190764

Epoch: 6| Step: 5
Training loss: 1.6814302142246693
Validation loss: 2.698853051622676

Epoch: 6| Step: 6
Training loss: 1.8088685850591568
Validation loss: 2.692085066086633

Epoch: 6| Step: 7
Training loss: 1.3544359477385741
Validation loss: 2.699534918913295

Epoch: 6| Step: 8
Training loss: 1.0235918234450485
Validation loss: 2.684608708053077

Epoch: 6| Step: 9
Training loss: 2.421283182006401
Validation loss: 2.694220973335825

Epoch: 6| Step: 10
Training loss: 1.416528900778061
Validation loss: 2.7110880023027017

Epoch: 6| Step: 11
Training loss: 0.8839848254139857
Validation loss: 2.6433533487448084

Epoch: 6| Step: 12
Training loss: 0.9805900833011243
Validation loss: 2.721673884007481

Epoch: 6| Step: 13
Training loss: 1.3463597349817857
Validation loss: 2.6196241432660954

Epoch: 160| Step: 0
Training loss: 1.0130590449614405
Validation loss: 2.6217243404394375

Epoch: 6| Step: 1
Training loss: 1.620305984469256
Validation loss: 2.6404297434831294

Epoch: 6| Step: 2
Training loss: 1.5933131947036108
Validation loss: 2.635812862806

Epoch: 6| Step: 3
Training loss: 1.1212933193246253
Validation loss: 2.661926412510598

Epoch: 6| Step: 4
Training loss: 1.424077183587267
Validation loss: 2.5745446824160965

Epoch: 6| Step: 5
Training loss: 1.3120024510046697
Validation loss: 2.5879483428852486

Epoch: 6| Step: 6
Training loss: 1.3803207447651271
Validation loss: 2.5906512889134072

Epoch: 6| Step: 7
Training loss: 1.4301893677071025
Validation loss: 2.5817706216536673

Epoch: 6| Step: 8
Training loss: 1.7461815455678678
Validation loss: 2.6391878148363737

Epoch: 6| Step: 9
Training loss: 1.2755694183695814
Validation loss: 2.5819787093687556

Epoch: 6| Step: 10
Training loss: 1.1660288645441563
Validation loss: 2.532553396085711

Epoch: 6| Step: 11
Training loss: 2.085078030230734
Validation loss: 2.643956823052243

Epoch: 6| Step: 12
Training loss: 0.8556668126302173
Validation loss: 2.632686034654497

Epoch: 6| Step: 13
Training loss: 1.2101701335467674
Validation loss: 2.7183713978204005

Epoch: 161| Step: 0
Training loss: 0.9388933318187871
Validation loss: 2.6317313037236114

Epoch: 6| Step: 1
Training loss: 1.3533036147144673
Validation loss: 2.7653083691857296

Epoch: 6| Step: 2
Training loss: 1.3846083364755617
Validation loss: 2.6684697259366574

Epoch: 6| Step: 3
Training loss: 1.3370808399130036
Validation loss: 2.6420145234963264

Epoch: 6| Step: 4
Training loss: 1.0863919302135026
Validation loss: 2.6951164137421286

Epoch: 6| Step: 5
Training loss: 1.3959415261010086
Validation loss: 2.718778427384644

Epoch: 6| Step: 6
Training loss: 1.2740835411611706
Validation loss: 2.6702121966522725

Epoch: 6| Step: 7
Training loss: 1.0608461073780322
Validation loss: 2.6246116138934505

Epoch: 6| Step: 8
Training loss: 1.7877787019295073
Validation loss: 2.6626875117362627

Epoch: 6| Step: 9
Training loss: 1.2793606108884512
Validation loss: 2.5882496710686524

Epoch: 6| Step: 10
Training loss: 1.9626287333063797
Validation loss: 2.663007629906934

Epoch: 6| Step: 11
Training loss: 1.1767400843127773
Validation loss: 2.6148301776814504

Epoch: 6| Step: 12
Training loss: 1.8961444082514811
Validation loss: 2.625916585902891

Epoch: 6| Step: 13
Training loss: 1.251110108488828
Validation loss: 2.684457905399111

Epoch: 162| Step: 0
Training loss: 1.6506114924787065
Validation loss: 2.5920228224817063

Epoch: 6| Step: 1
Training loss: 1.4793741412013228
Validation loss: 2.606417901038028

Epoch: 6| Step: 2
Training loss: 1.817039527018048
Validation loss: 2.57015850065726

Epoch: 6| Step: 3
Training loss: 1.454214118613228
Validation loss: 2.670795482857273

Epoch: 6| Step: 4
Training loss: 2.0362912342821224
Validation loss: 2.6534467827761814

Epoch: 6| Step: 5
Training loss: 1.4603970593901645
Validation loss: 2.607625409015389

Epoch: 6| Step: 6
Training loss: 1.1650623917142438
Validation loss: 2.633039938199179

Epoch: 6| Step: 7
Training loss: 0.873831650134681
Validation loss: 2.6519425715638567

Epoch: 6| Step: 8
Training loss: 1.5565059129729482
Validation loss: 2.6002765337285836

Epoch: 6| Step: 9
Training loss: 1.1538114866526366
Validation loss: 2.6347481453902284

Epoch: 6| Step: 10
Training loss: 0.9773953357868594
Validation loss: 2.686988441809652

Epoch: 6| Step: 11
Training loss: 1.37284634727956
Validation loss: 2.609096474163793

Epoch: 6| Step: 12
Training loss: 1.0875976825558944
Validation loss: 2.6489348868171074

Epoch: 6| Step: 13
Training loss: 1.3306951450047486
Validation loss: 2.674382540781412

Epoch: 163| Step: 0
Training loss: 1.3626019116006263
Validation loss: 2.7029018567250285

Epoch: 6| Step: 1
Training loss: 1.1006469168097406
Validation loss: 2.6657662858448545

Epoch: 6| Step: 2
Training loss: 1.8231816417119653
Validation loss: 2.6745986292727975

Epoch: 6| Step: 3
Training loss: 2.155813974717022
Validation loss: 2.590388728320366

Epoch: 6| Step: 4
Training loss: 1.5105512186386993
Validation loss: 2.6236796767339903

Epoch: 6| Step: 5
Training loss: 1.0993716591095162
Validation loss: 2.68992257159237

Epoch: 6| Step: 6
Training loss: 1.4866818622416944
Validation loss: 2.69392649816559

Epoch: 6| Step: 7
Training loss: 1.8436318052521774
Validation loss: 2.6598574208646246

Epoch: 6| Step: 8
Training loss: 0.9746290369286569
Validation loss: 2.7140176883937257

Epoch: 6| Step: 9
Training loss: 1.3105198591605822
Validation loss: 2.7334260583672045

Epoch: 6| Step: 10
Training loss: 1.0758674315572734
Validation loss: 2.7825028101703246

Epoch: 6| Step: 11
Training loss: 1.080502307781701
Validation loss: 2.7933823712724912

Epoch: 6| Step: 12
Training loss: 1.2136662409724999
Validation loss: 2.7101414635816545

Epoch: 6| Step: 13
Training loss: 1.7197484670843763
Validation loss: 2.7643543636325965

Epoch: 164| Step: 0
Training loss: 1.116187655255327
Validation loss: 2.6517695169105555

Epoch: 6| Step: 1
Training loss: 1.2804470802880106
Validation loss: 2.635844792708859

Epoch: 6| Step: 2
Training loss: 1.2604142759106034
Validation loss: 2.637538693883945

Epoch: 6| Step: 3
Training loss: 1.0889140439750127
Validation loss: 2.6138003470000264

Epoch: 6| Step: 4
Training loss: 1.0164284682429392
Validation loss: 2.6055080672027997

Epoch: 6| Step: 5
Training loss: 1.7633783681319097
Validation loss: 2.6387428784270557

Epoch: 6| Step: 6
Training loss: 1.0131055834049187
Validation loss: 2.6216802343594225

Epoch: 6| Step: 7
Training loss: 1.2367979003871157
Validation loss: 2.6087516298945475

Epoch: 6| Step: 8
Training loss: 1.3151389340881783
Validation loss: 2.6642811257605192

Epoch: 6| Step: 9
Training loss: 1.5097668883403512
Validation loss: 2.6393869797180827

Epoch: 6| Step: 10
Training loss: 1.2953222239903543
Validation loss: 2.57290083124845

Epoch: 6| Step: 11
Training loss: 2.1221053659955733
Validation loss: 2.6873416114679

Epoch: 6| Step: 12
Training loss: 1.3271681087290768
Validation loss: 2.6347004793076887

Epoch: 6| Step: 13
Training loss: 1.206570880093109
Validation loss: 2.5798015653213975

Epoch: 165| Step: 0
Training loss: 1.3721408595075355
Validation loss: 2.588678940958649

Epoch: 6| Step: 1
Training loss: 1.2748690089086774
Validation loss: 2.6528099523016726

Epoch: 6| Step: 2
Training loss: 1.3688750397166027
Validation loss: 2.6316012379890155

Epoch: 6| Step: 3
Training loss: 1.8167472929372024
Validation loss: 2.6384037313589914

Epoch: 6| Step: 4
Training loss: 2.1128215748186223
Validation loss: 2.651692913132524

Epoch: 6| Step: 5
Training loss: 0.8166816283496848
Validation loss: 2.703573200796122

Epoch: 6| Step: 6
Training loss: 1.2909395365720895
Validation loss: 2.5505243379396014

Epoch: 6| Step: 7
Training loss: 1.5587520662368992
Validation loss: 2.657989874588716

Epoch: 6| Step: 8
Training loss: 1.2161791168603042
Validation loss: 2.623173214276398

Epoch: 6| Step: 9
Training loss: 1.4775789183632309
Validation loss: 2.613900089025966

Epoch: 6| Step: 10
Training loss: 0.897679183042855
Validation loss: 2.61397017676744

Epoch: 6| Step: 11
Training loss: 1.1516777570956924
Validation loss: 2.629489707345857

Epoch: 6| Step: 12
Training loss: 1.3841466125438011
Validation loss: 2.6530165195940514

Epoch: 6| Step: 13
Training loss: 1.2105781268024502
Validation loss: 2.6801556473935566

Epoch: 166| Step: 0
Training loss: 1.3767066680894129
Validation loss: 2.641154264420192

Epoch: 6| Step: 1
Training loss: 0.7985445745826387
Validation loss: 2.646170261787224

Epoch: 6| Step: 2
Training loss: 1.13162295268767
Validation loss: 2.6474244797561584

Epoch: 6| Step: 3
Training loss: 1.178686867051764
Validation loss: 2.581168734277243

Epoch: 6| Step: 4
Training loss: 1.1874961852966073
Validation loss: 2.665026433478421

Epoch: 6| Step: 5
Training loss: 1.7644511008530772
Validation loss: 2.5906416640533743

Epoch: 6| Step: 6
Training loss: 1.0967436013488336
Validation loss: 2.6490500162879074

Epoch: 6| Step: 7
Training loss: 1.4241308405912172
Validation loss: 2.579872741148177

Epoch: 6| Step: 8
Training loss: 1.2014795917138208
Validation loss: 2.6465077979821396

Epoch: 6| Step: 9
Training loss: 1.6398687163583765
Validation loss: 2.580135540223513

Epoch: 6| Step: 10
Training loss: 0.9048325865367657
Validation loss: 2.618155775729379

Epoch: 6| Step: 11
Training loss: 1.2038577932103083
Validation loss: 2.6553334618336217

Epoch: 6| Step: 12
Training loss: 1.559355356096523
Validation loss: 2.596011742165121

Epoch: 6| Step: 13
Training loss: 2.0456671026356923
Validation loss: 2.6464849755918753

Epoch: 167| Step: 0
Training loss: 1.3265959970223775
Validation loss: 2.671449608801316

Epoch: 6| Step: 1
Training loss: 0.9185836680352649
Validation loss: 2.5878015965916603

Epoch: 6| Step: 2
Training loss: 1.9315924874721095
Validation loss: 2.6164620376156917

Epoch: 6| Step: 3
Training loss: 1.5142866695020598
Validation loss: 2.641653684429756

Epoch: 6| Step: 4
Training loss: 0.9357971302671674
Validation loss: 2.672845957755625

Epoch: 6| Step: 5
Training loss: 1.064955342659412
Validation loss: 2.627021692224921

Epoch: 6| Step: 6
Training loss: 1.2725119006007017
Validation loss: 2.5947398399670876

Epoch: 6| Step: 7
Training loss: 0.9947077064966525
Validation loss: 2.6479060597261066

Epoch: 6| Step: 8
Training loss: 1.309496121506047
Validation loss: 2.6051022845229204

Epoch: 6| Step: 9
Training loss: 1.3440665382337007
Validation loss: 2.6078635157247696

Epoch: 6| Step: 10
Training loss: 2.068892196885271
Validation loss: 2.7158415280413846

Epoch: 6| Step: 11
Training loss: 1.070846925394404
Validation loss: 2.610532606634715

Epoch: 6| Step: 12
Training loss: 1.5306213022470103
Validation loss: 2.6975645525317247

Epoch: 6| Step: 13
Training loss: 1.2364704357520115
Validation loss: 2.7061202446164243

Epoch: 168| Step: 0
Training loss: 1.6668255571284982
Validation loss: 2.769964732118879

Epoch: 6| Step: 1
Training loss: 1.069800929865466
Validation loss: 2.649643082544668

Epoch: 6| Step: 2
Training loss: 1.891849972194217
Validation loss: 2.6353874556740706

Epoch: 6| Step: 3
Training loss: 1.5370339129099997
Validation loss: 2.63936050506208

Epoch: 6| Step: 4
Training loss: 1.0044022459216968
Validation loss: 2.576310630996752

Epoch: 6| Step: 5
Training loss: 1.2387372931050982
Validation loss: 2.658836840437064

Epoch: 6| Step: 6
Training loss: 1.504442471115218
Validation loss: 2.585931169054593

Epoch: 6| Step: 7
Training loss: 1.0152706408362167
Validation loss: 2.5793130930644366

Epoch: 6| Step: 8
Training loss: 1.3910593790287626
Validation loss: 2.6268381615953316

Epoch: 6| Step: 9
Training loss: 1.3855092106171933
Validation loss: 2.575551731295851

Epoch: 6| Step: 10
Training loss: 1.3491386774154974
Validation loss: 2.7067695993980094

Epoch: 6| Step: 11
Training loss: 1.2818018957427897
Validation loss: 2.6530920666918556

Epoch: 6| Step: 12
Training loss: 1.4456455156360644
Validation loss: 2.6165665150770328

Epoch: 6| Step: 13
Training loss: 0.9655193172262807
Validation loss: 2.5923070915646393

Epoch: 169| Step: 0
Training loss: 1.3360024598150393
Validation loss: 2.6278878630021327

Epoch: 6| Step: 1
Training loss: 1.2529681728336495
Validation loss: 2.7163388606407013

Epoch: 6| Step: 2
Training loss: 1.5824179094425441
Validation loss: 2.733997892987756

Epoch: 6| Step: 3
Training loss: 0.7868760286041154
Validation loss: 2.7293365998300607

Epoch: 6| Step: 4
Training loss: 0.9906794584209154
Validation loss: 2.717637941777698

Epoch: 6| Step: 5
Training loss: 1.535178769167292
Validation loss: 2.6097947656757157

Epoch: 6| Step: 6
Training loss: 0.751293973476774
Validation loss: 2.6633792720774796

Epoch: 6| Step: 7
Training loss: 1.140895341163744
Validation loss: 2.591673391237356

Epoch: 6| Step: 8
Training loss: 1.1967619043207989
Validation loss: 2.6537368554154965

Epoch: 6| Step: 9
Training loss: 1.7263166848132612
Validation loss: 2.604119191054875

Epoch: 6| Step: 10
Training loss: 1.2119428337671876
Validation loss: 2.633398419090919

Epoch: 6| Step: 11
Training loss: 1.1579692533690378
Validation loss: 2.651972224526884

Epoch: 6| Step: 12
Training loss: 1.3879577259749765
Validation loss: 2.640638904422065

Epoch: 6| Step: 13
Training loss: 2.4052494495479633
Validation loss: 2.6680493842953847

Epoch: 170| Step: 0
Training loss: 1.4257038252201313
Validation loss: 2.6308702800461474

Epoch: 6| Step: 1
Training loss: 1.324059625928153
Validation loss: 2.655107424467117

Epoch: 6| Step: 2
Training loss: 1.1012952764515282
Validation loss: 2.6058826794499814

Epoch: 6| Step: 3
Training loss: 1.5885988652505367
Validation loss: 2.6750387456351756

Epoch: 6| Step: 4
Training loss: 0.9422795214402008
Validation loss: 2.7232066783456315

Epoch: 6| Step: 5
Training loss: 1.9523021337890532
Validation loss: 2.7262652361719684

Epoch: 6| Step: 6
Training loss: 1.317936582234931
Validation loss: 2.6721796230199617

Epoch: 6| Step: 7
Training loss: 1.451557092892664
Validation loss: 2.708988716838926

Epoch: 6| Step: 8
Training loss: 1.4972435738372607
Validation loss: 2.5855453055504234

Epoch: 6| Step: 9
Training loss: 0.957840184469719
Validation loss: 2.5544107114148145

Epoch: 6| Step: 10
Training loss: 1.035656214481336
Validation loss: 2.5667711344014457

Epoch: 6| Step: 11
Training loss: 1.3423137529920335
Validation loss: 2.719903094842136

Epoch: 6| Step: 12
Training loss: 1.18025007160092
Validation loss: 2.652741617241462

Epoch: 6| Step: 13
Training loss: 0.8924922776622766
Validation loss: 2.589034777415945

Epoch: 171| Step: 0
Training loss: 1.2334126451267513
Validation loss: 2.59162293199965

Epoch: 6| Step: 1
Training loss: 1.6355513822950343
Validation loss: 2.626165176830179

Epoch: 6| Step: 2
Training loss: 0.9478896455092382
Validation loss: 2.67544326318285

Epoch: 6| Step: 3
Training loss: 1.258232094100493
Validation loss: 2.679670906571597

Epoch: 6| Step: 4
Training loss: 1.273410820242708
Validation loss: 2.648083793554224

Epoch: 6| Step: 5
Training loss: 1.7222810020807213
Validation loss: 2.7317065342601987

Epoch: 6| Step: 6
Training loss: 1.9460179531998223
Validation loss: 2.6712336672145387

Epoch: 6| Step: 7
Training loss: 0.9420855275606171
Validation loss: 2.6442318422364233

Epoch: 6| Step: 8
Training loss: 1.1105866598489393
Validation loss: 2.6808537205932876

Epoch: 6| Step: 9
Training loss: 1.0405263699366336
Validation loss: 2.66715078628441

Epoch: 6| Step: 10
Training loss: 1.2886445263715243
Validation loss: 2.680666315648719

Epoch: 6| Step: 11
Training loss: 0.7127866068162964
Validation loss: 2.714935593915385

Epoch: 6| Step: 12
Training loss: 1.0798775622936556
Validation loss: 2.5989260980496494

Epoch: 6| Step: 13
Training loss: 1.262051281644292
Validation loss: 2.642073826343866

Epoch: 172| Step: 0
Training loss: 1.3426606841864803
Validation loss: 2.6781960536176888

Epoch: 6| Step: 1
Training loss: 0.9373103903715991
Validation loss: 2.641550785876456

Epoch: 6| Step: 2
Training loss: 1.2660198302230037
Validation loss: 2.6780967328105474

Epoch: 6| Step: 3
Training loss: 2.0162898896558543
Validation loss: 2.6033304372308166

Epoch: 6| Step: 4
Training loss: 1.5239884382895703
Validation loss: 2.634191451912981

Epoch: 6| Step: 5
Training loss: 1.0389665831845223
Validation loss: 2.655510055102532

Epoch: 6| Step: 6
Training loss: 0.8209400138337295
Validation loss: 2.6066403783471017

Epoch: 6| Step: 7
Training loss: 1.2275733912606168
Validation loss: 2.618274823447034

Epoch: 6| Step: 8
Training loss: 1.6566071035370764
Validation loss: 2.7077501965234094

Epoch: 6| Step: 9
Training loss: 1.046341489667923
Validation loss: 2.6687304487859738

Epoch: 6| Step: 10
Training loss: 1.0394925253022755
Validation loss: 2.6501619169563995

Epoch: 6| Step: 11
Training loss: 1.6652154644459032
Validation loss: 2.606639166424301

Epoch: 6| Step: 12
Training loss: 1.14843967982494
Validation loss: 2.6722769481380193

Epoch: 6| Step: 13
Training loss: 0.6717517872876382
Validation loss: 2.651525132337999

Epoch: 173| Step: 0
Training loss: 0.9070782001182482
Validation loss: 2.6273161948025052

Epoch: 6| Step: 1
Training loss: 1.5650034875800423
Validation loss: 2.678505202034779

Epoch: 6| Step: 2
Training loss: 1.5716502246960777
Validation loss: 2.6958716360807484

Epoch: 6| Step: 3
Training loss: 1.0859766342466581
Validation loss: 2.6681425411278927

Epoch: 6| Step: 4
Training loss: 0.9687360024210039
Validation loss: 2.6559139562729452

Epoch: 6| Step: 5
Training loss: 0.6865992280410708
Validation loss: 2.592598364523361

Epoch: 6| Step: 6
Training loss: 1.3652355101311895
Validation loss: 2.612565897303666

Epoch: 6| Step: 7
Training loss: 1.85333103108892
Validation loss: 2.6045791273907457

Epoch: 6| Step: 8
Training loss: 1.4535944190706012
Validation loss: 2.5924485246679008

Epoch: 6| Step: 9
Training loss: 1.4091834519640682
Validation loss: 2.682801316122636

Epoch: 6| Step: 10
Training loss: 0.9738855521739787
Validation loss: 2.6495232771079955

Epoch: 6| Step: 11
Training loss: 1.2487990332094467
Validation loss: 2.6642342938083132

Epoch: 6| Step: 12
Training loss: 1.1865987871522297
Validation loss: 2.667846796051328

Epoch: 6| Step: 13
Training loss: 1.2489802015276237
Validation loss: 2.662276249947466

Epoch: 174| Step: 0
Training loss: 1.2156532755017353
Validation loss: 2.6362155914593406

Epoch: 6| Step: 1
Training loss: 0.9462193639575556
Validation loss: 2.603146136909023

Epoch: 6| Step: 2
Training loss: 2.0738530815492497
Validation loss: 2.6354892002020254

Epoch: 6| Step: 3
Training loss: 1.1200991481934768
Validation loss: 2.669465240594221

Epoch: 6| Step: 4
Training loss: 0.8799752748873954
Validation loss: 2.649604712700607

Epoch: 6| Step: 5
Training loss: 1.7052924686742275
Validation loss: 2.6665459893657006

Epoch: 6| Step: 6
Training loss: 0.9948669957638062
Validation loss: 2.61056932082652

Epoch: 6| Step: 7
Training loss: 1.0117728318300359
Validation loss: 2.686731309890045

Epoch: 6| Step: 8
Training loss: 0.9418756731280254
Validation loss: 2.550179894029604

Epoch: 6| Step: 9
Training loss: 1.01493365893109
Validation loss: 2.6402301079236365

Epoch: 6| Step: 10
Training loss: 1.5763924029624337
Validation loss: 2.6908802686724673

Epoch: 6| Step: 11
Training loss: 1.0780437825889309
Validation loss: 2.7216752491068346

Epoch: 6| Step: 12
Training loss: 1.4557014512737418
Validation loss: 2.5924995962625137

Epoch: 6| Step: 13
Training loss: 0.9852513847428459
Validation loss: 2.7816874556529334

Epoch: 175| Step: 0
Training loss: 1.6531334110615714
Validation loss: 2.675488458286181

Epoch: 6| Step: 1
Training loss: 0.8402232532483405
Validation loss: 2.6587143480462965

Epoch: 6| Step: 2
Training loss: 1.0312745062488307
Validation loss: 2.676425516572637

Epoch: 6| Step: 3
Training loss: 1.1224442697976478
Validation loss: 2.5811674257237383

Epoch: 6| Step: 4
Training loss: 1.2030390919321445
Validation loss: 2.6958940846016213

Epoch: 6| Step: 5
Training loss: 1.0751418707625733
Validation loss: 2.6490984366735177

Epoch: 6| Step: 6
Training loss: 0.8778347010672146
Validation loss: 2.6572937205112424

Epoch: 6| Step: 7
Training loss: 1.0498628254250517
Validation loss: 2.6147682053657735

Epoch: 6| Step: 8
Training loss: 1.0371073060095888
Validation loss: 2.6611854030067175

Epoch: 6| Step: 9
Training loss: 0.9020058135333775
Validation loss: 2.6534975788504824

Epoch: 6| Step: 10
Training loss: 1.1567572434732185
Validation loss: 2.587129147378352

Epoch: 6| Step: 11
Training loss: 2.329821077607057
Validation loss: 2.6469941308701426

Epoch: 6| Step: 12
Training loss: 1.1262633329866079
Validation loss: 2.6028064201590224

Epoch: 6| Step: 13
Training loss: 1.0953578574983047
Validation loss: 2.652009219092699

Epoch: 176| Step: 0
Training loss: 0.9799459210869775
Validation loss: 2.650490834106417

Epoch: 6| Step: 1
Training loss: 1.9161618922532637
Validation loss: 2.629733314047079

Epoch: 6| Step: 2
Training loss: 1.1244136553868467
Validation loss: 2.5882855268789062

Epoch: 6| Step: 3
Training loss: 1.0276906983255545
Validation loss: 2.601519671174456

Epoch: 6| Step: 4
Training loss: 1.1167109613505912
Validation loss: 2.654989489494444

Epoch: 6| Step: 5
Training loss: 1.358791094371729
Validation loss: 2.625658255498681

Epoch: 6| Step: 6
Training loss: 0.9404485746172588
Validation loss: 2.6827042098824743

Epoch: 6| Step: 7
Training loss: 1.491902748620141
Validation loss: 2.6547803815010935

Epoch: 6| Step: 8
Training loss: 1.3462056189317062
Validation loss: 2.593647368825004

Epoch: 6| Step: 9
Training loss: 1.4595415922892339
Validation loss: 2.5777411743512184

Epoch: 6| Step: 10
Training loss: 1.0182680218527944
Validation loss: 2.652705531664951

Epoch: 6| Step: 11
Training loss: 1.2273755628516732
Validation loss: 2.6929691613867193

Epoch: 6| Step: 12
Training loss: 0.9297542387785453
Validation loss: 2.613804573305444

Epoch: 6| Step: 13
Training loss: 1.1311225123779112
Validation loss: 2.6184801695566087

Epoch: 177| Step: 0
Training loss: 0.9335166867424356
Validation loss: 2.644693073860469

Epoch: 6| Step: 1
Training loss: 2.141960228815225
Validation loss: 2.640865367656189

Epoch: 6| Step: 2
Training loss: 1.291629616400826
Validation loss: 2.620348760527983

Epoch: 6| Step: 3
Training loss: 1.220243663531457
Validation loss: 2.6907618341272816

Epoch: 6| Step: 4
Training loss: 1.2767612634045837
Validation loss: 2.6489073150037985

Epoch: 6| Step: 5
Training loss: 0.9363246861960834
Validation loss: 2.623908739478175

Epoch: 6| Step: 6
Training loss: 0.9305895748530908
Validation loss: 2.6300177829320117

Epoch: 6| Step: 7
Training loss: 1.5722081523366052
Validation loss: 2.5874221243326896

Epoch: 6| Step: 8
Training loss: 0.8886048008684541
Validation loss: 2.7126061455369164

Epoch: 6| Step: 9
Training loss: 0.945570949817497
Validation loss: 2.6234583490515284

Epoch: 6| Step: 10
Training loss: 1.2314484102359928
Validation loss: 2.6227839440622502

Epoch: 6| Step: 11
Training loss: 1.115250943089223
Validation loss: 2.620377739837412

Epoch: 6| Step: 12
Training loss: 1.040593217244094
Validation loss: 2.6336906621229574

Epoch: 6| Step: 13
Training loss: 1.0182252901723816
Validation loss: 2.6586189626790513

Epoch: 178| Step: 0
Training loss: 1.8251024348108493
Validation loss: 2.622154911696318

Epoch: 6| Step: 1
Training loss: 0.9744442970049099
Validation loss: 2.581811985049339

Epoch: 6| Step: 2
Training loss: 1.0650845675853156
Validation loss: 2.684456188319723

Epoch: 6| Step: 3
Training loss: 0.8512254450389202
Validation loss: 2.6325763177632013

Epoch: 6| Step: 4
Training loss: 1.0078434311016196
Validation loss: 2.670803621179414

Epoch: 6| Step: 5
Training loss: 1.3684796140279218
Validation loss: 2.634282992842742

Epoch: 6| Step: 6
Training loss: 1.1124211787043412
Validation loss: 2.6746114210928154

Epoch: 6| Step: 7
Training loss: 0.6758755303915746
Validation loss: 2.5826123651811788

Epoch: 6| Step: 8
Training loss: 1.3659388480510357
Validation loss: 2.700510175212451

Epoch: 6| Step: 9
Training loss: 1.2111037601652272
Validation loss: 2.6948661840099324

Epoch: 6| Step: 10
Training loss: 1.4983963341174722
Validation loss: 2.6035578410223716

Epoch: 6| Step: 11
Training loss: 1.4534565537097173
Validation loss: 2.6247248126911065

Epoch: 6| Step: 12
Training loss: 1.276296483761622
Validation loss: 2.733127832731833

Epoch: 6| Step: 13
Training loss: 0.6977352195890963
Validation loss: 2.6122299535406075

Epoch: 179| Step: 0
Training loss: 1.050380531112161
Validation loss: 2.5797886884634607

Epoch: 6| Step: 1
Training loss: 1.2451511752407782
Validation loss: 2.6354648349466236

Epoch: 6| Step: 2
Training loss: 1.1781133291946435
Validation loss: 2.6602421399860092

Epoch: 6| Step: 3
Training loss: 0.6645812757055624
Validation loss: 2.637822863326413

Epoch: 6| Step: 4
Training loss: 2.1430303049512514
Validation loss: 2.678201246567229

Epoch: 6| Step: 5
Training loss: 0.8625463749677647
Validation loss: 2.675209002782269

Epoch: 6| Step: 6
Training loss: 1.4646435410056171
Validation loss: 2.596563276608401

Epoch: 6| Step: 7
Training loss: 1.5356492665616577
Validation loss: 2.6454490973348865

Epoch: 6| Step: 8
Training loss: 1.0376687705409453
Validation loss: 2.6164727293012797

Epoch: 6| Step: 9
Training loss: 0.7543539190625831
Validation loss: 2.669226108579514

Epoch: 6| Step: 10
Training loss: 0.9782343477302792
Validation loss: 2.632004943214961

Epoch: 6| Step: 11
Training loss: 0.8967185119851928
Validation loss: 2.672149971240548

Epoch: 6| Step: 12
Training loss: 1.2106569518922774
Validation loss: 2.6193507122350996

Epoch: 6| Step: 13
Training loss: 0.8266944765468683
Validation loss: 2.6219984029313537

Epoch: 180| Step: 0
Training loss: 0.8363580091714972
Validation loss: 2.661429512679092

Epoch: 6| Step: 1
Training loss: 0.6234540894100967
Validation loss: 2.713960609141275

Epoch: 6| Step: 2
Training loss: 1.6127764856626285
Validation loss: 2.6409089727654886

Epoch: 6| Step: 3
Training loss: 0.9375019073466926
Validation loss: 2.6890745651444363

Epoch: 6| Step: 4
Training loss: 0.6934291320956029
Validation loss: 2.642582515798428

Epoch: 6| Step: 5
Training loss: 0.7265963392683655
Validation loss: 2.5936077109531293

Epoch: 6| Step: 6
Training loss: 1.2711280522703268
Validation loss: 2.5848228303366034

Epoch: 6| Step: 7
Training loss: 1.0782269415827688
Validation loss: 2.6207074839139284

Epoch: 6| Step: 8
Training loss: 1.4062093516938794
Validation loss: 2.6169754170133035

Epoch: 6| Step: 9
Training loss: 1.1413213616044833
Validation loss: 2.660157609323984

Epoch: 6| Step: 10
Training loss: 1.8680906146736989
Validation loss: 2.655137086982202

Epoch: 6| Step: 11
Training loss: 1.4340118713153542
Validation loss: 2.6602899533662194

Epoch: 6| Step: 12
Training loss: 1.354592603551817
Validation loss: 2.6822004926179353

Epoch: 6| Step: 13
Training loss: 1.2090378658558645
Validation loss: 2.6147008061457004

Epoch: 181| Step: 0
Training loss: 1.6219321415414198
Validation loss: 2.64031058100506

Epoch: 6| Step: 1
Training loss: 1.2247203429836815
Validation loss: 2.6348780557837412

Epoch: 6| Step: 2
Training loss: 1.3949089073191563
Validation loss: 2.607467974804122

Epoch: 6| Step: 3
Training loss: 0.9656034559790893
Validation loss: 2.6117166911505136

Epoch: 6| Step: 4
Training loss: 1.0996631453327537
Validation loss: 2.6847533155196373

Epoch: 6| Step: 5
Training loss: 1.050149550459835
Validation loss: 2.6011024350874363

Epoch: 6| Step: 6
Training loss: 0.8778423736910206
Validation loss: 2.6797581877435213

Epoch: 6| Step: 7
Training loss: 1.818485374469485
Validation loss: 2.671153158795604

Epoch: 6| Step: 8
Training loss: 0.7700184475559115
Validation loss: 2.6864835901886286

Epoch: 6| Step: 9
Training loss: 0.7935040550969619
Validation loss: 2.6272010809103166

Epoch: 6| Step: 10
Training loss: 1.2453910735840046
Validation loss: 2.7501960019863745

Epoch: 6| Step: 11
Training loss: 1.03228528623537
Validation loss: 2.6094678454908378

Epoch: 6| Step: 12
Training loss: 0.801270870228543
Validation loss: 2.7545487901049572

Epoch: 6| Step: 13
Training loss: 1.4549961963092597
Validation loss: 2.6233673013606977

Epoch: 182| Step: 0
Training loss: 2.0781434710836186
Validation loss: 2.5767496004448196

Epoch: 6| Step: 1
Training loss: 0.9217257621357433
Validation loss: 2.6681266279968456

Epoch: 6| Step: 2
Training loss: 1.106345055154751
Validation loss: 2.692307098619165

Epoch: 6| Step: 3
Training loss: 1.2655796466754523
Validation loss: 2.7088897915926355

Epoch: 6| Step: 4
Training loss: 0.987110847136921
Validation loss: 2.7231495217477133

Epoch: 6| Step: 5
Training loss: 0.8676266975666516
Validation loss: 2.6148946938910305

Epoch: 6| Step: 6
Training loss: 1.5259777311747573
Validation loss: 2.6310581659865995

Epoch: 6| Step: 7
Training loss: 0.9546852161736026
Validation loss: 2.7021100558859317

Epoch: 6| Step: 8
Training loss: 0.6265921340745756
Validation loss: 2.7398530708838265

Epoch: 6| Step: 9
Training loss: 0.9139910286895065
Validation loss: 2.6161230854977218

Epoch: 6| Step: 10
Training loss: 0.943212083015505
Validation loss: 2.6643036465654375

Epoch: 6| Step: 11
Training loss: 1.3683473735155607
Validation loss: 2.689369837538551

Epoch: 6| Step: 12
Training loss: 0.8139543721441369
Validation loss: 2.6528350420014437

Epoch: 6| Step: 13
Training loss: 0.9727750652008416
Validation loss: 2.670403876767774

Epoch: 183| Step: 0
Training loss: 0.7587174193977351
Validation loss: 2.6819636073306703

Epoch: 6| Step: 1
Training loss: 0.9677232099908205
Validation loss: 2.6972782209296993

Epoch: 6| Step: 2
Training loss: 1.011191094266027
Validation loss: 2.6116682015199255

Epoch: 6| Step: 3
Training loss: 1.9590981660542335
Validation loss: 2.787207805104647

Epoch: 6| Step: 4
Training loss: 1.0893422822312326
Validation loss: 2.712273612001987

Epoch: 6| Step: 5
Training loss: 1.1461707860933552
Validation loss: 2.7057069857694485

Epoch: 6| Step: 6
Training loss: 0.946676295112842
Validation loss: 2.5830403489946305

Epoch: 6| Step: 7
Training loss: 1.2244760054343742
Validation loss: 2.6324031447452616

Epoch: 6| Step: 8
Training loss: 1.106717216838554
Validation loss: 2.6625775536359457

Epoch: 6| Step: 9
Training loss: 1.3797297193692475
Validation loss: 2.657220386449816

Epoch: 6| Step: 10
Training loss: 1.635210967845676
Validation loss: 2.7090395569080075

Epoch: 6| Step: 11
Training loss: 0.891780839425818
Validation loss: 2.6724388613248244

Epoch: 6| Step: 12
Training loss: 1.2815451863479062
Validation loss: 2.5625086838489803

Epoch: 6| Step: 13
Training loss: 0.7925992208035663
Validation loss: 2.6219337053664242

Epoch: 184| Step: 0
Training loss: 1.047668782386096
Validation loss: 2.6618896154841547

Epoch: 6| Step: 1
Training loss: 1.4441551729872284
Validation loss: 2.5863113363597128

Epoch: 6| Step: 2
Training loss: 1.2814834196020508
Validation loss: 2.656680412576007

Epoch: 6| Step: 3
Training loss: 0.9070057184402898
Validation loss: 2.7061289007683373

Epoch: 6| Step: 4
Training loss: 1.1725351127458608
Validation loss: 2.7154490868615078

Epoch: 6| Step: 5
Training loss: 1.097005304927048
Validation loss: 2.6781437155426833

Epoch: 6| Step: 6
Training loss: 1.1774011143591798
Validation loss: 2.6369444498550396

Epoch: 6| Step: 7
Training loss: 1.5814209314167427
Validation loss: 2.642363899308576

Epoch: 6| Step: 8
Training loss: 0.989402285962908
Validation loss: 2.610652253119269

Epoch: 6| Step: 9
Training loss: 0.5937958749817354
Validation loss: 2.6009342019141446

Epoch: 6| Step: 10
Training loss: 0.8009644089553212
Validation loss: 2.6531767251132594

Epoch: 6| Step: 11
Training loss: 1.8368788882613847
Validation loss: 2.6465891161622372

Epoch: 6| Step: 12
Training loss: 0.882187883983046
Validation loss: 2.625884527709971

Epoch: 6| Step: 13
Training loss: 1.250891272371832
Validation loss: 2.6651651108715173

Epoch: 185| Step: 0
Training loss: 2.2993812640997295
Validation loss: 2.6718524240354244

Epoch: 6| Step: 1
Training loss: 1.5358310604371868
Validation loss: 2.6685740732280245

Epoch: 6| Step: 2
Training loss: 0.8225499474801201
Validation loss: 2.6570523564869615

Epoch: 6| Step: 3
Training loss: 0.8450202563639917
Validation loss: 2.6262505216868828

Epoch: 6| Step: 4
Training loss: 0.8486219258372835
Validation loss: 2.5814648351791902

Epoch: 6| Step: 5
Training loss: 1.2633940260071526
Validation loss: 2.693737834245038

Epoch: 6| Step: 6
Training loss: 0.7045198169151977
Validation loss: 2.6757005071407693

Epoch: 6| Step: 7
Training loss: 0.5490967442749631
Validation loss: 2.660499031586242

Epoch: 6| Step: 8
Training loss: 1.0609519564243413
Validation loss: 2.7084316431444866

Epoch: 6| Step: 9
Training loss: 0.8918659866829233
Validation loss: 2.6813714285195687

Epoch: 6| Step: 10
Training loss: 0.9705593378734154
Validation loss: 2.6363037687039346

Epoch: 6| Step: 11
Training loss: 0.7161188478876441
Validation loss: 2.6703118702437787

Epoch: 6| Step: 12
Training loss: 1.206073665083485
Validation loss: 2.629009756815728

Epoch: 6| Step: 13
Training loss: 1.2732802217867674
Validation loss: 2.684065228116367

Epoch: 186| Step: 0
Training loss: 1.2463068764888128
Validation loss: 2.6672607048311603

Epoch: 6| Step: 1
Training loss: 0.8944340282397064
Validation loss: 2.6559081362469943

Epoch: 6| Step: 2
Training loss: 1.0180723194709866
Validation loss: 2.659982788584772

Epoch: 6| Step: 3
Training loss: 0.8042347940104897
Validation loss: 2.615703302363687

Epoch: 6| Step: 4
Training loss: 0.9675436199320693
Validation loss: 2.6652692595436256

Epoch: 6| Step: 5
Training loss: 0.774630118364996
Validation loss: 2.673562541261784

Epoch: 6| Step: 6
Training loss: 1.2667247091764635
Validation loss: 2.643287926131956

Epoch: 6| Step: 7
Training loss: 1.3007439043795588
Validation loss: 2.623117968101671

Epoch: 6| Step: 8
Training loss: 1.1080943492904027
Validation loss: 2.6335967242023153

Epoch: 6| Step: 9
Training loss: 0.8023255878238915
Validation loss: 2.6764574816028825

Epoch: 6| Step: 10
Training loss: 0.8596363710530848
Validation loss: 2.7028533710869915

Epoch: 6| Step: 11
Training loss: 1.9485230207603044
Validation loss: 2.71238183380897

Epoch: 6| Step: 12
Training loss: 1.1383968171550358
Validation loss: 2.651328415467163

Epoch: 6| Step: 13
Training loss: 0.5479316312924458
Validation loss: 2.719287300364439

Epoch: 187| Step: 0
Training loss: 0.8131264325773622
Validation loss: 2.6536601437128833

Epoch: 6| Step: 1
Training loss: 1.2217408187049759
Validation loss: 2.6762310977192834

Epoch: 6| Step: 2
Training loss: 1.196024065834504
Validation loss: 2.605038372374655

Epoch: 6| Step: 3
Training loss: 1.0910744230199416
Validation loss: 2.6412651745681797

Epoch: 6| Step: 4
Training loss: 1.1975033696710566
Validation loss: 2.5808420987381187

Epoch: 6| Step: 5
Training loss: 0.7896745026895949
Validation loss: 2.6440591245130074

Epoch: 6| Step: 6
Training loss: 1.2605277188562267
Validation loss: 2.73918916794189

Epoch: 6| Step: 7
Training loss: 0.6540603437903049
Validation loss: 2.623366740917614

Epoch: 6| Step: 8
Training loss: 1.2663131538450805
Validation loss: 2.696918646620219

Epoch: 6| Step: 9
Training loss: 1.1015297634590142
Validation loss: 2.6630480672327965

Epoch: 6| Step: 10
Training loss: 0.805966148384986
Validation loss: 2.624793513820408

Epoch: 6| Step: 11
Training loss: 1.105057171339434
Validation loss: 2.6547103009695756

Epoch: 6| Step: 12
Training loss: 1.8870782924232978
Validation loss: 2.654110978489005

Epoch: 6| Step: 13
Training loss: 1.6266904987611397
Validation loss: 2.7209505697543777

Epoch: 188| Step: 0
Training loss: 1.2625234299553487
Validation loss: 2.7413956095576966

Epoch: 6| Step: 1
Training loss: 1.1189693832538425
Validation loss: 2.7738434257205298

Epoch: 6| Step: 2
Training loss: 1.158201478181797
Validation loss: 2.703784274223367

Epoch: 6| Step: 3
Training loss: 0.9280731867446533
Validation loss: 2.627112628391255

Epoch: 6| Step: 4
Training loss: 1.7696807326615693
Validation loss: 2.6250443379124215

Epoch: 6| Step: 5
Training loss: 1.0741840148858592
Validation loss: 2.5870163156786004

Epoch: 6| Step: 6
Training loss: 0.9851611192478545
Validation loss: 2.681810818629254

Epoch: 6| Step: 7
Training loss: 1.3946397669694968
Validation loss: 2.61267818834951

Epoch: 6| Step: 8
Training loss: 0.9877440911427424
Validation loss: 2.557783205194328

Epoch: 6| Step: 9
Training loss: 0.8613057382316955
Validation loss: 2.566566404225654

Epoch: 6| Step: 10
Training loss: 0.9490962950285595
Validation loss: 2.6187626136591327

Epoch: 6| Step: 11
Training loss: 1.671166671010813
Validation loss: 2.670668390887055

Epoch: 6| Step: 12
Training loss: 1.0916404543828535
Validation loss: 2.6245141109485224

Epoch: 6| Step: 13
Training loss: 0.6982874715565874
Validation loss: 2.656228966723174

Epoch: 189| Step: 0
Training loss: 0.9808513305285567
Validation loss: 2.7156595664683243

Epoch: 6| Step: 1
Training loss: 1.1994637602483236
Validation loss: 2.6543217410582933

Epoch: 6| Step: 2
Training loss: 1.24760756424497
Validation loss: 2.7438608336891135

Epoch: 6| Step: 3
Training loss: 1.0150585061861386
Validation loss: 2.723541889243675

Epoch: 6| Step: 4
Training loss: 1.2656658778241319
Validation loss: 2.5274912080193657

Epoch: 6| Step: 5
Training loss: 0.8585403897866005
Validation loss: 2.590465319551236

Epoch: 6| Step: 6
Training loss: 1.883639585300434
Validation loss: 2.6347017386504965

Epoch: 6| Step: 7
Training loss: 0.9592218668244376
Validation loss: 2.644921653851588

Epoch: 6| Step: 8
Training loss: 0.8589066703174958
Validation loss: 2.659949251207096

Epoch: 6| Step: 9
Training loss: 0.8496953460342331
Validation loss: 2.653545603607828

Epoch: 6| Step: 10
Training loss: 1.1868192327574494
Validation loss: 2.6686700780665507

Epoch: 6| Step: 11
Training loss: 1.222302175324639
Validation loss: 2.6890224461931465

Epoch: 6| Step: 12
Training loss: 0.8301199868810073
Validation loss: 2.7100097211966054

Epoch: 6| Step: 13
Training loss: 0.7473927319470078
Validation loss: 2.5968306450818166

Epoch: 190| Step: 0
Training loss: 0.9273544015248576
Validation loss: 2.67060377877176

Epoch: 6| Step: 1
Training loss: 1.049634343011089
Validation loss: 2.6425469230544683

Epoch: 6| Step: 2
Training loss: 0.5217537059423841
Validation loss: 2.648245880486745

Epoch: 6| Step: 3
Training loss: 0.7663744547525762
Validation loss: 2.5699076850678337

Epoch: 6| Step: 4
Training loss: 0.9361477954731172
Validation loss: 2.587391393719556

Epoch: 6| Step: 5
Training loss: 1.4268990093655776
Validation loss: 2.632468558616086

Epoch: 6| Step: 6
Training loss: 1.3137572488484992
Validation loss: 2.599520885510075

Epoch: 6| Step: 7
Training loss: 1.2964101210958563
Validation loss: 2.6531274131281664

Epoch: 6| Step: 8
Training loss: 1.864975772526441
Validation loss: 2.6262984470436193

Epoch: 6| Step: 9
Training loss: 0.9371000072397426
Validation loss: 2.6766871197474487

Epoch: 6| Step: 10
Training loss: 0.6429865272632231
Validation loss: 2.6181834892587115

Epoch: 6| Step: 11
Training loss: 0.8512515979141273
Validation loss: 2.6400638939730903

Epoch: 6| Step: 12
Training loss: 1.3521358618894657
Validation loss: 2.6323594062843623

Epoch: 6| Step: 13
Training loss: 0.9618592842112047
Validation loss: 2.673715162247922

Epoch: 191| Step: 0
Training loss: 0.7649442020337409
Validation loss: 2.641965544627315

Epoch: 6| Step: 1
Training loss: 0.8026932383297055
Validation loss: 2.672690715045344

Epoch: 6| Step: 2
Training loss: 1.1242507452848856
Validation loss: 2.6537093634420703

Epoch: 6| Step: 3
Training loss: 0.8610125804916869
Validation loss: 2.5949176626550736

Epoch: 6| Step: 4
Training loss: 0.6743610209871385
Validation loss: 2.6024014148490195

Epoch: 6| Step: 5
Training loss: 1.2377081185476444
Validation loss: 2.675070801507999

Epoch: 6| Step: 6
Training loss: 0.8762133904399331
Validation loss: 2.6116442530614985

Epoch: 6| Step: 7
Training loss: 0.8671665704624353
Validation loss: 2.6599889806289734

Epoch: 6| Step: 8
Training loss: 0.9520674920520615
Validation loss: 2.6643342954345224

Epoch: 6| Step: 9
Training loss: 2.116854595742608
Validation loss: 2.6815900730703643

Epoch: 6| Step: 10
Training loss: 0.699188167819605
Validation loss: 2.623590878306019

Epoch: 6| Step: 11
Training loss: 1.1658265744918417
Validation loss: 2.7243249961264624

Epoch: 6| Step: 12
Training loss: 0.9509703875122032
Validation loss: 2.6566774660111947

Epoch: 6| Step: 13
Training loss: 1.0799335845199842
Validation loss: 2.637642223506988

Epoch: 192| Step: 0
Training loss: 0.9396829938510928
Validation loss: 2.5838462310179087

Epoch: 6| Step: 1
Training loss: 1.177790651510964
Validation loss: 2.722908836553903

Epoch: 6| Step: 2
Training loss: 1.2940104457368755
Validation loss: 2.597294916630448

Epoch: 6| Step: 3
Training loss: 1.2294533066665507
Validation loss: 2.576640362446969

Epoch: 6| Step: 4
Training loss: 0.6204300219001678
Validation loss: 2.6738758143279195

Epoch: 6| Step: 5
Training loss: 1.670377827465037
Validation loss: 2.654713848448025

Epoch: 6| Step: 6
Training loss: 0.9772447872906008
Validation loss: 2.6527828401802407

Epoch: 6| Step: 7
Training loss: 1.1298110134619115
Validation loss: 2.7098373394064565

Epoch: 6| Step: 8
Training loss: 0.9743180384205972
Validation loss: 2.6240977447251974

Epoch: 6| Step: 9
Training loss: 1.5742179927398148
Validation loss: 2.6900549136610885

Epoch: 6| Step: 10
Training loss: 0.8707450887392051
Validation loss: 2.667967052096138

Epoch: 6| Step: 11
Training loss: 0.7413703033447715
Validation loss: 2.655333117644103

Epoch: 6| Step: 12
Training loss: 0.6215260758426979
Validation loss: 2.644767806997372

Epoch: 6| Step: 13
Training loss: 0.5463415814148141
Validation loss: 2.652672067059413

Epoch: 193| Step: 0
Training loss: 0.9753582662975117
Validation loss: 2.653282827019628

Epoch: 6| Step: 1
Training loss: 1.1170382633434615
Validation loss: 2.688652811532896

Epoch: 6| Step: 2
Training loss: 0.9546540611891579
Validation loss: 2.631170755191277

Epoch: 6| Step: 3
Training loss: 0.8637842637482833
Validation loss: 2.662349370119184

Epoch: 6| Step: 4
Training loss: 1.0875619497960403
Validation loss: 2.6250055479566288

Epoch: 6| Step: 5
Training loss: 0.7358468909074872
Validation loss: 2.6858611173866467

Epoch: 6| Step: 6
Training loss: 0.7618018471801348
Validation loss: 2.659908363417844

Epoch: 6| Step: 7
Training loss: 0.9992498325885082
Validation loss: 2.674217283111238

Epoch: 6| Step: 8
Training loss: 1.046550757455317
Validation loss: 2.678260297113756

Epoch: 6| Step: 9
Training loss: 1.20524341309098
Validation loss: 2.708101326223948

Epoch: 6| Step: 10
Training loss: 1.0860976505881776
Validation loss: 2.6253482496771987

Epoch: 6| Step: 11
Training loss: 1.3204540199412442
Validation loss: 2.583813781566211

Epoch: 6| Step: 12
Training loss: 1.8065134694483909
Validation loss: 2.6524719596816437

Epoch: 6| Step: 13
Training loss: 0.6073088218747964
Validation loss: 2.713917057676837

Epoch: 194| Step: 0
Training loss: 0.9257214683835601
Validation loss: 2.6065779445342927

Epoch: 6| Step: 1
Training loss: 0.9527620969198063
Validation loss: 2.724675630518156

Epoch: 6| Step: 2
Training loss: 1.3076402521129131
Validation loss: 2.7112571095499

Epoch: 6| Step: 3
Training loss: 0.7368760233347018
Validation loss: 2.7140060779107107

Epoch: 6| Step: 4
Training loss: 0.5805530851358218
Validation loss: 2.6880651811207055

Epoch: 6| Step: 5
Training loss: 0.9973144232424261
Validation loss: 2.6665243965185463

Epoch: 6| Step: 6
Training loss: 1.2688523575407882
Validation loss: 2.6547585732127335

Epoch: 6| Step: 7
Training loss: 1.203709695602784
Validation loss: 2.601270199107163

Epoch: 6| Step: 8
Training loss: 0.7943499708096776
Validation loss: 2.7039429413852902

Epoch: 6| Step: 9
Training loss: 0.7735956203782491
Validation loss: 2.682484996951603

Epoch: 6| Step: 10
Training loss: 1.3502432498067456
Validation loss: 2.6593868956129842

Epoch: 6| Step: 11
Training loss: 0.6336824300961805
Validation loss: 2.557341679370827

Epoch: 6| Step: 12
Training loss: 1.6779759402999752
Validation loss: 2.6534182844348644

Epoch: 6| Step: 13
Training loss: 1.1257444673521277
Validation loss: 2.678777779396406

Epoch: 195| Step: 0
Training loss: 1.0582140702659888
Validation loss: 2.612638720490523

Epoch: 6| Step: 1
Training loss: 1.046144999586973
Validation loss: 2.6591547024931024

Epoch: 6| Step: 2
Training loss: 1.362122838725311
Validation loss: 2.6709153829777423

Epoch: 6| Step: 3
Training loss: 0.9559909694117418
Validation loss: 2.6517642572148614

Epoch: 6| Step: 4
Training loss: 0.8298634689134402
Validation loss: 2.7030324313680487

Epoch: 6| Step: 5
Training loss: 0.8393204233998711
Validation loss: 2.739251792388847

Epoch: 6| Step: 6
Training loss: 0.9364537440871056
Validation loss: 2.6891396643889935

Epoch: 6| Step: 7
Training loss: 0.7252896552410173
Validation loss: 2.660148885738208

Epoch: 6| Step: 8
Training loss: 1.075456274033109
Validation loss: 2.6468803306624995

Epoch: 6| Step: 9
Training loss: 0.8864017541732025
Validation loss: 2.6151331036051944

Epoch: 6| Step: 10
Training loss: 1.7534034195128765
Validation loss: 2.663869677414588

Epoch: 6| Step: 11
Training loss: 1.251787814505296
Validation loss: 2.7008654314170215

Epoch: 6| Step: 12
Training loss: 0.6436679723014542
Validation loss: 2.691888449500733

Epoch: 6| Step: 13
Training loss: 0.8899200393353748
Validation loss: 2.701173750627795

Epoch: 196| Step: 0
Training loss: 1.283081141789328
Validation loss: 2.665220782574102

Epoch: 6| Step: 1
Training loss: 1.0505991497864942
Validation loss: 2.69689760636999

Epoch: 6| Step: 2
Training loss: 1.0201957554061647
Validation loss: 2.7006424545716325

Epoch: 6| Step: 3
Training loss: 1.1463632860850774
Validation loss: 2.7922056636208845

Epoch: 6| Step: 4
Training loss: 1.2490979754745402
Validation loss: 2.705942989316924

Epoch: 6| Step: 5
Training loss: 0.9520452981498079
Validation loss: 2.716365148236832

Epoch: 6| Step: 6
Training loss: 0.9568733552187307
Validation loss: 2.6621368697853347

Epoch: 6| Step: 7
Training loss: 0.9141905279241757
Validation loss: 2.7508871352619884

Epoch: 6| Step: 8
Training loss: 1.1958369681450411
Validation loss: 2.7249225468375298

Epoch: 6| Step: 9
Training loss: 0.5971370261683998
Validation loss: 2.6978574375637363

Epoch: 6| Step: 10
Training loss: 0.5184458817809848
Validation loss: 2.602020964067194

Epoch: 6| Step: 11
Training loss: 1.7211283787218983
Validation loss: 2.619685560824343

Epoch: 6| Step: 12
Training loss: 0.8831327414527665
Validation loss: 2.624097351009965

Epoch: 6| Step: 13
Training loss: 1.0441523775694443
Validation loss: 2.6191638828869244

Epoch: 197| Step: 0
Training loss: 0.7968021808338769
Validation loss: 2.6967184481779114

Epoch: 6| Step: 1
Training loss: 0.8891895505098969
Validation loss: 2.695307767559817

Epoch: 6| Step: 2
Training loss: 1.138617695849371
Validation loss: 2.710783324680879

Epoch: 6| Step: 3
Training loss: 1.4236218966357213
Validation loss: 2.644845663037572

Epoch: 6| Step: 4
Training loss: 0.8344989055971497
Validation loss: 2.64469920404047

Epoch: 6| Step: 5
Training loss: 0.9801804319999011
Validation loss: 2.650044451646637

Epoch: 6| Step: 6
Training loss: 0.825045636388693
Validation loss: 2.623228671358357

Epoch: 6| Step: 7
Training loss: 1.807210108724272
Validation loss: 2.7112653316042628

Epoch: 6| Step: 8
Training loss: 1.100861996246979
Validation loss: 2.751934093863474

Epoch: 6| Step: 9
Training loss: 0.8777490754672673
Validation loss: 2.6371801504813304

Epoch: 6| Step: 10
Training loss: 0.6778621717994597
Validation loss: 2.6382185223922052

Epoch: 6| Step: 11
Training loss: 0.8699678406307266
Validation loss: 2.6513735270556116

Epoch: 6| Step: 12
Training loss: 0.9906779542842968
Validation loss: 2.7341323890230993

Epoch: 6| Step: 13
Training loss: 0.8135138568366231
Validation loss: 2.6698749633924317

Epoch: 198| Step: 0
Training loss: 1.8190050136419473
Validation loss: 2.6390259394833833

Epoch: 6| Step: 1
Training loss: 0.8719455676763416
Validation loss: 2.68208349710199

Epoch: 6| Step: 2
Training loss: 0.6953279300649221
Validation loss: 2.665338652459327

Epoch: 6| Step: 3
Training loss: 0.8924295982140859
Validation loss: 2.644028901884326

Epoch: 6| Step: 4
Training loss: 0.8986611792720409
Validation loss: 2.6343425527002067

Epoch: 6| Step: 5
Training loss: 0.7044131876385247
Validation loss: 2.650612117439499

Epoch: 6| Step: 6
Training loss: 0.5521807644600029
Validation loss: 2.582102256641131

Epoch: 6| Step: 7
Training loss: 0.9400788125012094
Validation loss: 2.682043302327252

Epoch: 6| Step: 8
Training loss: 1.0866076370795181
Validation loss: 2.7212540141145993

Epoch: 6| Step: 9
Training loss: 1.1044935366405608
Validation loss: 2.6766420636485373

Epoch: 6| Step: 10
Training loss: 1.4401886715736254
Validation loss: 2.6584025169705416

Epoch: 6| Step: 11
Training loss: 1.0641177707831195
Validation loss: 2.6165567577467166

Epoch: 6| Step: 12
Training loss: 1.1910890751126046
Validation loss: 2.662465620938273

Epoch: 6| Step: 13
Training loss: 1.1556583643584701
Validation loss: 2.705163323154404

Epoch: 199| Step: 0
Training loss: 1.3583334078330427
Validation loss: 2.629615555744487

Epoch: 6| Step: 1
Training loss: 0.9165080359502558
Validation loss: 2.7044063316924087

Epoch: 6| Step: 2
Training loss: 0.7057600448628664
Validation loss: 2.688336264444524

Epoch: 6| Step: 3
Training loss: 0.81383309673978
Validation loss: 2.6930433958881994

Epoch: 6| Step: 4
Training loss: 0.7513966272237308
Validation loss: 2.644755783578838

Epoch: 6| Step: 5
Training loss: 1.1093899363197302
Validation loss: 2.7069354239893566

Epoch: 6| Step: 6
Training loss: 0.8464085409842209
Validation loss: 2.6513331514706486

Epoch: 6| Step: 7
Training loss: 0.766047302867194
Validation loss: 2.662704584085089

Epoch: 6| Step: 8
Training loss: 0.8837655585941446
Validation loss: 2.676010485851421

Epoch: 6| Step: 9
Training loss: 1.145678573329728
Validation loss: 2.6375623770956538

Epoch: 6| Step: 10
Training loss: 0.8861322017446444
Validation loss: 2.6243512926380728

Epoch: 6| Step: 11
Training loss: 0.7816205481105507
Validation loss: 2.6531178277004486

Epoch: 6| Step: 12
Training loss: 1.8777190520278555
Validation loss: 2.721797988450328

Epoch: 6| Step: 13
Training loss: 0.994042832036997
Validation loss: 2.7082095093420078

Epoch: 200| Step: 0
Training loss: 1.0576805314162048
Validation loss: 2.6826616248139667

Epoch: 6| Step: 1
Training loss: 0.8039414363830848
Validation loss: 2.683172186362461

Epoch: 6| Step: 2
Training loss: 0.5628821875994117
Validation loss: 2.6769643762087556

Epoch: 6| Step: 3
Training loss: 1.0341257400058168
Validation loss: 2.7007600585765257

Epoch: 6| Step: 4
Training loss: 0.7083203277141897
Validation loss: 2.7281612529290378

Epoch: 6| Step: 5
Training loss: 1.4362498942907176
Validation loss: 2.666355663780554

Epoch: 6| Step: 6
Training loss: 0.9190483076082178
Validation loss: 2.729364465626638

Epoch: 6| Step: 7
Training loss: 1.0434702264132647
Validation loss: 2.722204491066656

Epoch: 6| Step: 8
Training loss: 0.7413764135629919
Validation loss: 2.6669238358907363

Epoch: 6| Step: 9
Training loss: 0.7569554388392999
Validation loss: 2.6341851916853996

Epoch: 6| Step: 10
Training loss: 0.9187019828652911
Validation loss: 2.636548765378141

Epoch: 6| Step: 11
Training loss: 1.6555180641739535
Validation loss: 2.6763896167012664

Epoch: 6| Step: 12
Training loss: 1.2646928344945851
Validation loss: 2.6186756514963565

Epoch: 6| Step: 13
Training loss: 0.9586301565057717
Validation loss: 2.6893746543043044

Epoch: 201| Step: 0
Training loss: 0.7580662332072216
Validation loss: 2.6641200591699756

Epoch: 6| Step: 1
Training loss: 1.1111438243076903
Validation loss: 2.578981677206841

Epoch: 6| Step: 2
Training loss: 0.9397432826909011
Validation loss: 2.686389841658876

Epoch: 6| Step: 3
Training loss: 1.1211972072595116
Validation loss: 2.6035519573770096

Epoch: 6| Step: 4
Training loss: 0.881513602149125
Validation loss: 2.6409029090200966

Epoch: 6| Step: 5
Training loss: 1.2583696541165348
Validation loss: 2.7241831602210085

Epoch: 6| Step: 6
Training loss: 0.6146812738084829
Validation loss: 2.6660320425867168

Epoch: 6| Step: 7
Training loss: 1.6956410595041604
Validation loss: 2.7411172486373845

Epoch: 6| Step: 8
Training loss: 1.0723761274031922
Validation loss: 2.7184434622935165

Epoch: 6| Step: 9
Training loss: 0.7216381840521595
Validation loss: 2.708499702821194

Epoch: 6| Step: 10
Training loss: 0.9875442410469796
Validation loss: 2.637593901651541

Epoch: 6| Step: 11
Training loss: 1.1621251722271884
Validation loss: 2.6515719339970563

Epoch: 6| Step: 12
Training loss: 0.6836174225114333
Validation loss: 2.6648885093351433

Epoch: 6| Step: 13
Training loss: 0.9033846775527324
Validation loss: 2.6182088728336343

Epoch: 202| Step: 0
Training loss: 0.6170528844507078
Validation loss: 2.692512037745597

Epoch: 6| Step: 1
Training loss: 1.282003506785103
Validation loss: 2.637825032556055

Epoch: 6| Step: 2
Training loss: 1.088515152068334
Validation loss: 2.6217874517665227

Epoch: 6| Step: 3
Training loss: 0.6753609513426616
Validation loss: 2.6961484930213517

Epoch: 6| Step: 4
Training loss: 0.8622755173169897
Validation loss: 2.612909477790535

Epoch: 6| Step: 5
Training loss: 1.2571345332492483
Validation loss: 2.690652654123948

Epoch: 6| Step: 6
Training loss: 0.8367914490590187
Validation loss: 2.7713285782771475

Epoch: 6| Step: 7
Training loss: 1.9740416845540971
Validation loss: 2.706001544615499

Epoch: 6| Step: 8
Training loss: 0.7579218991941156
Validation loss: 2.774207052286563

Epoch: 6| Step: 9
Training loss: 0.802369231921666
Validation loss: 2.6461269160714003

Epoch: 6| Step: 10
Training loss: 0.7687122227140304
Validation loss: 2.7055943406223504

Epoch: 6| Step: 11
Training loss: 0.7021070104694801
Validation loss: 2.6747130032058264

Epoch: 6| Step: 12
Training loss: 1.1222910053956288
Validation loss: 2.6528921557584733

Epoch: 6| Step: 13
Training loss: 0.788631283611539
Validation loss: 2.6148904617494093

Epoch: 203| Step: 0
Training loss: 0.7476391988661465
Validation loss: 2.5979053655122133

Epoch: 6| Step: 1
Training loss: 0.86117625032864
Validation loss: 2.6602899683030987

Epoch: 6| Step: 2
Training loss: 0.9815046150168979
Validation loss: 2.6592774435663458

Epoch: 6| Step: 3
Training loss: 0.9058275224580588
Validation loss: 2.638474870015222

Epoch: 6| Step: 4
Training loss: 0.563922038249698
Validation loss: 2.644661731590678

Epoch: 6| Step: 5
Training loss: 0.7446895387071756
Validation loss: 2.6001238200463743

Epoch: 6| Step: 6
Training loss: 1.023241330048314
Validation loss: 2.6603420825641195

Epoch: 6| Step: 7
Training loss: 1.0226095796547836
Validation loss: 2.6568570210104205

Epoch: 6| Step: 8
Training loss: 1.6335517633443364
Validation loss: 2.6454759091030353

Epoch: 6| Step: 9
Training loss: 0.8577393311248697
Validation loss: 2.7119081135621492

Epoch: 6| Step: 10
Training loss: 1.0292866252121005
Validation loss: 2.7019445381213774

Epoch: 6| Step: 11
Training loss: 0.6960749785250201
Validation loss: 2.7085706875793654

Epoch: 6| Step: 12
Training loss: 1.0212043684776695
Validation loss: 2.6722473866587952

Epoch: 6| Step: 13
Training loss: 1.087304770824442
Validation loss: 2.703254917087738

Epoch: 204| Step: 0
Training loss: 0.9678524535532573
Validation loss: 2.6280961321236767

Epoch: 6| Step: 1
Training loss: 0.6047103562089134
Validation loss: 2.616243683791734

Epoch: 6| Step: 2
Training loss: 0.8408034408241231
Validation loss: 2.6283614570485385

Epoch: 6| Step: 3
Training loss: 0.8206522646672456
Validation loss: 2.633741341341134

Epoch: 6| Step: 4
Training loss: 0.639972540594156
Validation loss: 2.6755902818534594

Epoch: 6| Step: 5
Training loss: 1.0127802990647004
Validation loss: 2.6491060116537852

Epoch: 6| Step: 6
Training loss: 1.079655431776331
Validation loss: 2.5859608874843243

Epoch: 6| Step: 7
Training loss: 0.622802327633332
Validation loss: 2.648409232829884

Epoch: 6| Step: 8
Training loss: 1.6449243795991382
Validation loss: 2.64037454233694

Epoch: 6| Step: 9
Training loss: 1.2127305077170007
Validation loss: 2.6467578854523706

Epoch: 6| Step: 10
Training loss: 1.0580852455561927
Validation loss: 2.7112126132936956

Epoch: 6| Step: 11
Training loss: 0.8374454765221799
Validation loss: 2.690628965628165

Epoch: 6| Step: 12
Training loss: 0.9016857307613977
Validation loss: 2.6321106681795268

Epoch: 6| Step: 13
Training loss: 0.6995056671856457
Validation loss: 2.722717517982555

Epoch: 205| Step: 0
Training loss: 0.7373617188078391
Validation loss: 2.6639425897693663

Epoch: 6| Step: 1
Training loss: 0.5550394419238517
Validation loss: 2.602268508866321

Epoch: 6| Step: 2
Training loss: 1.2392014895747265
Validation loss: 2.6782439619043923

Epoch: 6| Step: 3
Training loss: 0.7823968480526442
Validation loss: 2.6644373207758862

Epoch: 6| Step: 4
Training loss: 1.1446710182230162
Validation loss: 2.6671016358236885

Epoch: 6| Step: 5
Training loss: 0.8539256632029936
Validation loss: 2.653095226922068

Epoch: 6| Step: 6
Training loss: 0.7893286529973601
Validation loss: 2.6570751927955816

Epoch: 6| Step: 7
Training loss: 1.0964262780812999
Validation loss: 2.689061635246485

Epoch: 6| Step: 8
Training loss: 0.6452191005847544
Validation loss: 2.6661772328489106

Epoch: 6| Step: 9
Training loss: 0.9199027608193695
Validation loss: 2.6028445104550477

Epoch: 6| Step: 10
Training loss: 0.6925863550582522
Validation loss: 2.65775123509135

Epoch: 6| Step: 11
Training loss: 1.7930483997746203
Validation loss: 2.7021857965513325

Epoch: 6| Step: 12
Training loss: 1.0850968434583281
Validation loss: 2.686796939174674

Epoch: 6| Step: 13
Training loss: 0.8752144823143613
Validation loss: 2.733942459046019

Epoch: 206| Step: 0
Training loss: 0.6159149039201162
Validation loss: 2.6477662982959513

Epoch: 6| Step: 1
Training loss: 0.7561700069271596
Validation loss: 2.6403479195613966

Epoch: 6| Step: 2
Training loss: 0.6685146086857721
Validation loss: 2.6971770687974828

Epoch: 6| Step: 3
Training loss: 0.5132945310131488
Validation loss: 2.6656412348489513

Epoch: 6| Step: 4
Training loss: 0.7975490935231447
Validation loss: 2.6773831883584926

Epoch: 6| Step: 5
Training loss: 0.5749878695493816
Validation loss: 2.7048577725008034

Epoch: 6| Step: 6
Training loss: 0.6776506003895691
Validation loss: 2.598436648517224

Epoch: 6| Step: 7
Training loss: 1.2936022264055662
Validation loss: 2.7073215844523233

Epoch: 6| Step: 8
Training loss: 0.6718527989822547
Validation loss: 2.6572561564976973

Epoch: 6| Step: 9
Training loss: 1.0037045999903298
Validation loss: 2.7183503628198715

Epoch: 6| Step: 10
Training loss: 1.8931725732739357
Validation loss: 2.680433104709922

Epoch: 6| Step: 11
Training loss: 0.7999426195308831
Validation loss: 2.6644835973649816

Epoch: 6| Step: 12
Training loss: 1.0101105858910029
Validation loss: 2.675658568008552

Epoch: 6| Step: 13
Training loss: 0.7042399996506885
Validation loss: 2.671148502561894

Epoch: 207| Step: 0
Training loss: 0.8407682077033942
Validation loss: 2.6388014566984266

Epoch: 6| Step: 1
Training loss: 0.7491213897358381
Validation loss: 2.6817967572456074

Epoch: 6| Step: 2
Training loss: 1.0658300610796039
Validation loss: 2.7171304490204027

Epoch: 6| Step: 3
Training loss: 0.734337582548052
Validation loss: 2.6983160413109846

Epoch: 6| Step: 4
Training loss: 0.7726906918215471
Validation loss: 2.659792777692407

Epoch: 6| Step: 5
Training loss: 0.9378555259508031
Validation loss: 2.6392478737735376

Epoch: 6| Step: 6
Training loss: 0.896826485574447
Validation loss: 2.6737966486859412

Epoch: 6| Step: 7
Training loss: 1.7725845503985889
Validation loss: 2.6749197879541984

Epoch: 6| Step: 8
Training loss: 0.997304801007072
Validation loss: 2.7080047456999328

Epoch: 6| Step: 9
Training loss: 0.5934648833101421
Validation loss: 2.7281903614838625

Epoch: 6| Step: 10
Training loss: 0.7725593128087682
Validation loss: 2.6002456035519996

Epoch: 6| Step: 11
Training loss: 0.5958969551300546
Validation loss: 2.658745718950903

Epoch: 6| Step: 12
Training loss: 0.8461270932489945
Validation loss: 2.659011796294605

Epoch: 6| Step: 13
Training loss: 1.1252276931921332
Validation loss: 2.6402253670540423

Epoch: 208| Step: 0
Training loss: 0.8903944821436098
Validation loss: 2.7036270087055927

Epoch: 6| Step: 1
Training loss: 0.9887966576140125
Validation loss: 2.7293914576160136

Epoch: 6| Step: 2
Training loss: 0.9418893421399958
Validation loss: 2.674627949341094

Epoch: 6| Step: 3
Training loss: 0.9960011158672655
Validation loss: 2.7336329007168376

Epoch: 6| Step: 4
Training loss: 0.9070875966841165
Validation loss: 2.714978214291255

Epoch: 6| Step: 5
Training loss: 1.1773247204048278
Validation loss: 2.5652683005450188

Epoch: 6| Step: 6
Training loss: 0.952298791213762
Validation loss: 2.693091984367418

Epoch: 6| Step: 7
Training loss: 0.5313643725078837
Validation loss: 2.688859270548342

Epoch: 6| Step: 8
Training loss: 1.562319020280548
Validation loss: 2.711857444493602

Epoch: 6| Step: 9
Training loss: 0.8477999657654536
Validation loss: 2.7505742542752154

Epoch: 6| Step: 10
Training loss: 0.9086898319942033
Validation loss: 2.7098176092329047

Epoch: 6| Step: 11
Training loss: 0.7287980010515053
Validation loss: 2.5663807643668144

Epoch: 6| Step: 12
Training loss: 0.8819467130683564
Validation loss: 2.69103224711315

Epoch: 6| Step: 13
Training loss: 0.9475903141389808
Validation loss: 2.69381634010236

Epoch: 209| Step: 0
Training loss: 0.9593657378206258
Validation loss: 2.6590727673573435

Epoch: 6| Step: 1
Training loss: 1.898014539532298
Validation loss: 2.63700602155665

Epoch: 6| Step: 2
Training loss: 1.0231638535268632
Validation loss: 2.7126866395086444

Epoch: 6| Step: 3
Training loss: 0.6321816302039726
Validation loss: 2.664032481929622

Epoch: 6| Step: 4
Training loss: 0.6478129677004858
Validation loss: 2.6655645526861176

Epoch: 6| Step: 5
Training loss: 0.6376750761738182
Validation loss: 2.703546509559207

Epoch: 6| Step: 6
Training loss: 0.5304531965939152
Validation loss: 2.660202959558978

Epoch: 6| Step: 7
Training loss: 0.977761531975435
Validation loss: 2.6763793276915324

Epoch: 6| Step: 8
Training loss: 0.5922019755423593
Validation loss: 2.725967298539643

Epoch: 6| Step: 9
Training loss: 0.8331147066068537
Validation loss: 2.610827302614275

Epoch: 6| Step: 10
Training loss: 1.1018143494478136
Validation loss: 2.6880572576678294

Epoch: 6| Step: 11
Training loss: 0.7380174437996707
Validation loss: 2.6348620850231015

Epoch: 6| Step: 12
Training loss: 1.0019314114781408
Validation loss: 2.6354627090070952

Epoch: 6| Step: 13
Training loss: 0.6086313160184484
Validation loss: 2.696702239513553

Epoch: 210| Step: 0
Training loss: 1.5313561850340027
Validation loss: 2.70342813015951

Epoch: 6| Step: 1
Training loss: 0.8416861264336654
Validation loss: 2.6740230826392333

Epoch: 6| Step: 2
Training loss: 0.7855728714187192
Validation loss: 2.7098778697619705

Epoch: 6| Step: 3
Training loss: 0.8408201707226216
Validation loss: 2.7673278853398733

Epoch: 6| Step: 4
Training loss: 0.7554744558503502
Validation loss: 2.818000007429951

Epoch: 6| Step: 5
Training loss: 1.0537135395516413
Validation loss: 2.6132278474940325

Epoch: 6| Step: 6
Training loss: 0.5684240507576374
Validation loss: 2.6463980535151403

Epoch: 6| Step: 7
Training loss: 1.056011358084429
Validation loss: 2.629331262477262

Epoch: 6| Step: 8
Training loss: 1.0994272301407675
Validation loss: 2.6728684509955425

Epoch: 6| Step: 9
Training loss: 0.9588660577012207
Validation loss: 2.6636655927603483

Epoch: 6| Step: 10
Training loss: 0.7735208023371152
Validation loss: 2.68657737981919

Epoch: 6| Step: 11
Training loss: 0.7409726288768634
Validation loss: 2.6843900355198116

Epoch: 6| Step: 12
Training loss: 1.0679305922996505
Validation loss: 2.6679446068970374

Epoch: 6| Step: 13
Training loss: 1.0002781361972946
Validation loss: 2.703176861745088

Epoch: 211| Step: 0
Training loss: 0.912821979414716
Validation loss: 2.6866119529187116

Epoch: 6| Step: 1
Training loss: 0.5577031217988734
Validation loss: 2.7072243889941046

Epoch: 6| Step: 2
Training loss: 0.7994335091110796
Validation loss: 2.6852482078240123

Epoch: 6| Step: 3
Training loss: 0.8551428884044017
Validation loss: 2.624886828208195

Epoch: 6| Step: 4
Training loss: 0.6810184689018557
Validation loss: 2.6388311519218255

Epoch: 6| Step: 5
Training loss: 0.991240973557772
Validation loss: 2.66935710984647

Epoch: 6| Step: 6
Training loss: 1.2818685759667507
Validation loss: 2.751376544446071

Epoch: 6| Step: 7
Training loss: 1.6173492203351751
Validation loss: 2.6745337481007065

Epoch: 6| Step: 8
Training loss: 0.8699382422440133
Validation loss: 2.6175796746361004

Epoch: 6| Step: 9
Training loss: 0.7342957798860065
Validation loss: 2.585366377135202

Epoch: 6| Step: 10
Training loss: 0.7557654901595999
Validation loss: 2.6399949655821993

Epoch: 6| Step: 11
Training loss: 0.6509015708233927
Validation loss: 2.6602935158095393

Epoch: 6| Step: 12
Training loss: 1.1627598584876122
Validation loss: 2.6633829721242064

Epoch: 6| Step: 13
Training loss: 0.7531471185878916
Validation loss: 2.6613424814668396

Epoch: 212| Step: 0
Training loss: 0.7808618344167552
Validation loss: 2.602255666832592

Epoch: 6| Step: 1
Training loss: 0.9117266160221941
Validation loss: 2.6909213060600488

Epoch: 6| Step: 2
Training loss: 0.8814443603889163
Validation loss: 2.6675244878844384

Epoch: 6| Step: 3
Training loss: 0.6680370095159914
Validation loss: 2.5717437454171805

Epoch: 6| Step: 4
Training loss: 0.6701861602590514
Validation loss: 2.6261928209691985

Epoch: 6| Step: 5
Training loss: 0.5014835343039628
Validation loss: 2.70789477881301

Epoch: 6| Step: 6
Training loss: 0.7529037213826713
Validation loss: 2.6115120913543164

Epoch: 6| Step: 7
Training loss: 0.6703269556794298
Validation loss: 2.6518719065721057

Epoch: 6| Step: 8
Training loss: 0.5215177203886432
Validation loss: 2.62879128131508

Epoch: 6| Step: 9
Training loss: 0.8612994753685512
Validation loss: 2.6866634234897107

Epoch: 6| Step: 10
Training loss: 1.2976457534540058
Validation loss: 2.743441897090846

Epoch: 6| Step: 11
Training loss: 0.7109795023489179
Validation loss: 2.6541888449164968

Epoch: 6| Step: 12
Training loss: 1.7616140668601885
Validation loss: 2.676532500678464

Epoch: 6| Step: 13
Training loss: 1.0662365453481635
Validation loss: 2.6232775683536893

Epoch: 213| Step: 0
Training loss: 1.020391985147059
Validation loss: 2.6474451927393234

Epoch: 6| Step: 1
Training loss: 0.9922343866278494
Validation loss: 2.68485098405756

Epoch: 6| Step: 2
Training loss: 0.9177593885256913
Validation loss: 2.6818796427785903

Epoch: 6| Step: 3
Training loss: 0.46364721603833015
Validation loss: 2.681525131372422

Epoch: 6| Step: 4
Training loss: 0.8740811973538648
Validation loss: 2.6468538934255683

Epoch: 6| Step: 5
Training loss: 0.6294647485408608
Validation loss: 2.6351453669127554

Epoch: 6| Step: 6
Training loss: 1.0379890690964821
Validation loss: 2.6264552896144666

Epoch: 6| Step: 7
Training loss: 0.7869748741317275
Validation loss: 2.6367563956128173

Epoch: 6| Step: 8
Training loss: 0.46649623111498495
Validation loss: 2.7663649666453005

Epoch: 6| Step: 9
Training loss: 0.6582292500639887
Validation loss: 2.6172718698747377

Epoch: 6| Step: 10
Training loss: 1.472672925293107
Validation loss: 2.7090402023037905

Epoch: 6| Step: 11
Training loss: 0.9555567690714688
Validation loss: 2.713780490862677

Epoch: 6| Step: 12
Training loss: 0.6305570320802039
Validation loss: 2.7681512447860612

Epoch: 6| Step: 13
Training loss: 0.6703054147625981
Validation loss: 2.6342963952479526

Epoch: 214| Step: 0
Training loss: 0.6553768525476664
Validation loss: 2.67806279908825

Epoch: 6| Step: 1
Training loss: 0.6587948954663555
Validation loss: 2.5486265061341116

Epoch: 6| Step: 2
Training loss: 0.6946254293053622
Validation loss: 2.622648980133735

Epoch: 6| Step: 3
Training loss: 0.4432344134506191
Validation loss: 2.698227917208577

Epoch: 6| Step: 4
Training loss: 0.642460449945925
Validation loss: 2.6366776526745093

Epoch: 6| Step: 5
Training loss: 0.9631141882802621
Validation loss: 2.6621879776871644

Epoch: 6| Step: 6
Training loss: 1.103014266640332
Validation loss: 2.739356888573309

Epoch: 6| Step: 7
Training loss: 2.0172145992382373
Validation loss: 2.7655227843395345

Epoch: 6| Step: 8
Training loss: 0.7226557551201853
Validation loss: 2.7591742160624326

Epoch: 6| Step: 9
Training loss: 0.8083494619025462
Validation loss: 2.6798698874815856

Epoch: 6| Step: 10
Training loss: 0.6859523954055885
Validation loss: 2.6313884290947165

Epoch: 6| Step: 11
Training loss: 0.7520854486733344
Validation loss: 2.7215575852486427

Epoch: 6| Step: 12
Training loss: 0.7781330491228001
Validation loss: 2.6891721801732813

Epoch: 6| Step: 13
Training loss: 0.8164728675931476
Validation loss: 2.6172693495975716

Epoch: 215| Step: 0
Training loss: 0.6600130365991531
Validation loss: 2.527453302743783

Epoch: 6| Step: 1
Training loss: 0.9667194990540842
Validation loss: 2.7195943054878713

Epoch: 6| Step: 2
Training loss: 0.6509659430653145
Validation loss: 2.6459916110017505

Epoch: 6| Step: 3
Training loss: 1.6355686562570353
Validation loss: 2.669851492396158

Epoch: 6| Step: 4
Training loss: 0.8551596862735081
Validation loss: 2.6708218318872086

Epoch: 6| Step: 5
Training loss: 0.8378052212243517
Validation loss: 2.7251029639667146

Epoch: 6| Step: 6
Training loss: 0.8085196640793989
Validation loss: 2.711707014202988

Epoch: 6| Step: 7
Training loss: 0.8392567202015196
Validation loss: 2.6037895132977487

Epoch: 6| Step: 8
Training loss: 0.9520257332793961
Validation loss: 2.749969771247951

Epoch: 6| Step: 9
Training loss: 0.8222197023738304
Validation loss: 2.6942885218291055

Epoch: 6| Step: 10
Training loss: 0.821912639901871
Validation loss: 2.645218474866487

Epoch: 6| Step: 11
Training loss: 0.42873187872068425
Validation loss: 2.6996611229432634

Epoch: 6| Step: 12
Training loss: 0.5967738300482849
Validation loss: 2.786692405685243

Epoch: 6| Step: 13
Training loss: 0.9981171644807372
Validation loss: 2.600132576912408

Epoch: 216| Step: 0
Training loss: 0.5487239915336842
Validation loss: 2.6489143654947944

Epoch: 6| Step: 1
Training loss: 0.6749811452422172
Validation loss: 2.6326861403089503

Epoch: 6| Step: 2
Training loss: 0.6376712438180142
Validation loss: 2.7184989199402056

Epoch: 6| Step: 3
Training loss: 0.7169248794058057
Validation loss: 2.7023878617595467

Epoch: 6| Step: 4
Training loss: 1.8820274267478485
Validation loss: 2.6320451321853344

Epoch: 6| Step: 5
Training loss: 0.8344721205404403
Validation loss: 2.729553957145241

Epoch: 6| Step: 6
Training loss: 0.588882952173866
Validation loss: 2.6996546318372197

Epoch: 6| Step: 7
Training loss: 0.912817604497306
Validation loss: 2.649800582795961

Epoch: 6| Step: 8
Training loss: 1.2667468714836339
Validation loss: 2.660171852308798

Epoch: 6| Step: 9
Training loss: 0.7923002384781012
Validation loss: 2.751296431389254

Epoch: 6| Step: 10
Training loss: 0.5140707113891395
Validation loss: 2.639191187447656

Epoch: 6| Step: 11
Training loss: 0.9011431546837089
Validation loss: 2.6058000680865727

Epoch: 6| Step: 12
Training loss: 1.0023354438562462
Validation loss: 2.640043747712838

Epoch: 6| Step: 13
Training loss: 0.42708759964773657
Validation loss: 2.7724824649037276

Epoch: 217| Step: 0
Training loss: 1.6073732982910982
Validation loss: 2.7025741280438584

Epoch: 6| Step: 1
Training loss: 0.7029879966351388
Validation loss: 2.7117920773592226

Epoch: 6| Step: 2
Training loss: 0.4602119101262604
Validation loss: 2.688028128429956

Epoch: 6| Step: 3
Training loss: 0.8002188591801529
Validation loss: 2.690833943960483

Epoch: 6| Step: 4
Training loss: 1.056684623549638
Validation loss: 2.650284062461526

Epoch: 6| Step: 5
Training loss: 0.8488702123734738
Validation loss: 2.6570719999115817

Epoch: 6| Step: 6
Training loss: 0.6164487691122083
Validation loss: 2.6860268421711297

Epoch: 6| Step: 7
Training loss: 1.0691736106815544
Validation loss: 2.6829618684559238

Epoch: 6| Step: 8
Training loss: 1.0200920462682779
Validation loss: 2.61991436609675

Epoch: 6| Step: 9
Training loss: 0.8976297479208323
Validation loss: 2.647305226856519

Epoch: 6| Step: 10
Training loss: 1.071265137786917
Validation loss: 2.659145654336112

Epoch: 6| Step: 11
Training loss: 0.7772751591004047
Validation loss: 2.733030864409627

Epoch: 6| Step: 12
Training loss: 0.5870911494488998
Validation loss: 2.675202095858842

Epoch: 6| Step: 13
Training loss: 0.7591133357583597
Validation loss: 2.6736418773207546

Epoch: 218| Step: 0
Training loss: 0.8174726831031001
Validation loss: 2.6427109283887615

Epoch: 6| Step: 1
Training loss: 0.7496616474510531
Validation loss: 2.6939036202346442

Epoch: 6| Step: 2
Training loss: 1.1478328021108137
Validation loss: 2.6075649874651186

Epoch: 6| Step: 3
Training loss: 1.1665469800773565
Validation loss: 2.6579100713325605

Epoch: 6| Step: 4
Training loss: 0.6250011682499458
Validation loss: 2.6386944411955464

Epoch: 6| Step: 5
Training loss: 0.7206338575204241
Validation loss: 2.6831133772062703

Epoch: 6| Step: 6
Training loss: 0.4945764692703804
Validation loss: 2.750810503729619

Epoch: 6| Step: 7
Training loss: 0.7523281202742723
Validation loss: 2.5667248300262187

Epoch: 6| Step: 8
Training loss: 0.522113377842449
Validation loss: 2.679124363337339

Epoch: 6| Step: 9
Training loss: 0.8484215863107096
Validation loss: 2.673771934021017

Epoch: 6| Step: 10
Training loss: 0.5206504182689866
Validation loss: 2.6562563428616057

Epoch: 6| Step: 11
Training loss: 0.7131722507987724
Validation loss: 2.6343131990676554

Epoch: 6| Step: 12
Training loss: 1.5004509406962967
Validation loss: 2.635030067243349

Epoch: 6| Step: 13
Training loss: 0.7933687225497338
Validation loss: 2.726620809228506

Epoch: 219| Step: 0
Training loss: 0.7905454015053646
Validation loss: 2.726059219562332

Epoch: 6| Step: 1
Training loss: 0.5643743440237701
Validation loss: 2.693130627296714

Epoch: 6| Step: 2
Training loss: 1.1610228516122938
Validation loss: 2.6629869782829805

Epoch: 6| Step: 3
Training loss: 1.077712768028383
Validation loss: 2.6951947983551823

Epoch: 6| Step: 4
Training loss: 0.6502169586272833
Validation loss: 2.6891873555490386

Epoch: 6| Step: 5
Training loss: 0.3962323181527377
Validation loss: 2.6890119099739236

Epoch: 6| Step: 6
Training loss: 0.7430171946747507
Validation loss: 2.684639258324446

Epoch: 6| Step: 7
Training loss: 0.7789600380525779
Validation loss: 2.6908411947092015

Epoch: 6| Step: 8
Training loss: 0.9102521199173144
Validation loss: 2.6826873536822755

Epoch: 6| Step: 9
Training loss: 1.4595199480304237
Validation loss: 2.7038364980790766

Epoch: 6| Step: 10
Training loss: 0.8150509622940608
Validation loss: 2.6785429131034526

Epoch: 6| Step: 11
Training loss: 0.6722481600650052
Validation loss: 2.7132072511133196

Epoch: 6| Step: 12
Training loss: 0.9353462274844916
Validation loss: 2.7248170762100243

Epoch: 6| Step: 13
Training loss: 0.7664635406452734
Validation loss: 2.673965053057032

Epoch: 220| Step: 0
Training loss: 1.0190998787153036
Validation loss: 2.692616346154296

Epoch: 6| Step: 1
Training loss: 0.3874258647266335
Validation loss: 2.6631061705662447

Epoch: 6| Step: 2
Training loss: 0.6527580727202574
Validation loss: 2.687149734737425

Epoch: 6| Step: 3
Training loss: 0.6828820147362664
Validation loss: 2.7039139832837313

Epoch: 6| Step: 4
Training loss: 0.7680236067248212
Validation loss: 2.6666839320895437

Epoch: 6| Step: 5
Training loss: 0.6901394289232594
Validation loss: 2.7445534609388047

Epoch: 6| Step: 6
Training loss: 0.7357614294441774
Validation loss: 2.6560535582663376

Epoch: 6| Step: 7
Training loss: 1.0857599785697771
Validation loss: 2.6675006461388504

Epoch: 6| Step: 8
Training loss: 0.5151811481136553
Validation loss: 2.6746093559831556

Epoch: 6| Step: 9
Training loss: 0.7059262951708474
Validation loss: 2.703314846185703

Epoch: 6| Step: 10
Training loss: 0.6240099695032842
Validation loss: 2.6617568434040333

Epoch: 6| Step: 11
Training loss: 1.0065271623739205
Validation loss: 2.6938333700544654

Epoch: 6| Step: 12
Training loss: 1.6053090259706744
Validation loss: 2.6849425811595182

Epoch: 6| Step: 13
Training loss: 0.7003337558310516
Validation loss: 2.678975921849209

Epoch: 221| Step: 0
Training loss: 0.43015317825013205
Validation loss: 2.7303442756102285

Epoch: 6| Step: 1
Training loss: 0.9364278384552176
Validation loss: 2.6364854798915767

Epoch: 6| Step: 2
Training loss: 0.6699610662535269
Validation loss: 2.6558793201979642

Epoch: 6| Step: 3
Training loss: 0.9062217839551103
Validation loss: 2.670855232740137

Epoch: 6| Step: 4
Training loss: 0.7918613763252984
Validation loss: 2.6528026575205566

Epoch: 6| Step: 5
Training loss: 0.6064248196737592
Validation loss: 2.6744179624235938

Epoch: 6| Step: 6
Training loss: 0.7257451618202826
Validation loss: 2.7438484226378748

Epoch: 6| Step: 7
Training loss: 0.8360764575154502
Validation loss: 2.6485825670510432

Epoch: 6| Step: 8
Training loss: 0.574648300709208
Validation loss: 2.6378616455691635

Epoch: 6| Step: 9
Training loss: 0.6796387841316184
Validation loss: 2.7006429695509144

Epoch: 6| Step: 10
Training loss: 0.8045611976832874
Validation loss: 2.730170456032762

Epoch: 6| Step: 11
Training loss: 1.048361733167637
Validation loss: 2.6978004361796164

Epoch: 6| Step: 12
Training loss: 0.8600741230270971
Validation loss: 2.6403433895994333

Epoch: 6| Step: 13
Training loss: 1.48336034528733
Validation loss: 2.7035667337805296

Epoch: 222| Step: 0
Training loss: 0.582595551639262
Validation loss: 2.7441364401426793

Epoch: 6| Step: 1
Training loss: 0.8454712159926815
Validation loss: 2.7628624691223616

Epoch: 6| Step: 2
Training loss: 0.7487705007558217
Validation loss: 2.6587148562011067

Epoch: 6| Step: 3
Training loss: 0.5987150997590373
Validation loss: 2.6613617050237535

Epoch: 6| Step: 4
Training loss: 0.9987307182140865
Validation loss: 2.6659997066260117

Epoch: 6| Step: 5
Training loss: 0.6486562107257268
Validation loss: 2.7392040227004846

Epoch: 6| Step: 6
Training loss: 0.829771205034629
Validation loss: 2.7154095469505304

Epoch: 6| Step: 7
Training loss: 1.7097963333422552
Validation loss: 2.677790067331473

Epoch: 6| Step: 8
Training loss: 0.5964730961800616
Validation loss: 2.727483074789567

Epoch: 6| Step: 9
Training loss: 0.6313430302119286
Validation loss: 2.6706322722749247

Epoch: 6| Step: 10
Training loss: 0.7942997703075497
Validation loss: 2.7362566912972817

Epoch: 6| Step: 11
Training loss: 0.9868946223757293
Validation loss: 2.7458113067932084

Epoch: 6| Step: 12
Training loss: 0.377020103552253
Validation loss: 2.715289079838283

Epoch: 6| Step: 13
Training loss: 0.7973513208112459
Validation loss: 2.7662643440749206

Epoch: 223| Step: 0
Training loss: 0.5968252151258131
Validation loss: 2.626488036780033

Epoch: 6| Step: 1
Training loss: 0.7570671269878418
Validation loss: 2.580405180630549

Epoch: 6| Step: 2
Training loss: 0.8110719014478539
Validation loss: 2.7139385516454384

Epoch: 6| Step: 3
Training loss: 0.5149626957706301
Validation loss: 2.6223323982291733

Epoch: 6| Step: 4
Training loss: 0.8524890024141429
Validation loss: 2.643781126423784

Epoch: 6| Step: 5
Training loss: 1.5880359615991166
Validation loss: 2.7390643499715956

Epoch: 6| Step: 6
Training loss: 1.0982423893946829
Validation loss: 2.646284175118151

Epoch: 6| Step: 7
Training loss: 0.904789240622527
Validation loss: 2.6295650690160013

Epoch: 6| Step: 8
Training loss: 0.5783006298216111
Validation loss: 2.6988306424376773

Epoch: 6| Step: 9
Training loss: 0.6855044012144051
Validation loss: 2.6697796493261796

Epoch: 6| Step: 10
Training loss: 1.1639040128614946
Validation loss: 2.7226703046876524

Epoch: 6| Step: 11
Training loss: 0.8324077631856462
Validation loss: 2.685747654663111

Epoch: 6| Step: 12
Training loss: 0.49000060446371047
Validation loss: 2.7166357333132547

Epoch: 6| Step: 13
Training loss: 0.5385532738217504
Validation loss: 2.723338117918234

Epoch: 224| Step: 0
Training loss: 0.7806076842587353
Validation loss: 2.723849122366626

Epoch: 6| Step: 1
Training loss: 0.6040927633488911
Validation loss: 2.681448577427632

Epoch: 6| Step: 2
Training loss: 0.9347961216760834
Validation loss: 2.709417659155294

Epoch: 6| Step: 3
Training loss: 0.7820521623404857
Validation loss: 2.7190845839020077

Epoch: 6| Step: 4
Training loss: 0.7197354237232236
Validation loss: 2.726003084843831

Epoch: 6| Step: 5
Training loss: 0.5859408060616366
Validation loss: 2.6944713809664953

Epoch: 6| Step: 6
Training loss: 1.0061127278777016
Validation loss: 2.7248181116138346

Epoch: 6| Step: 7
Training loss: 1.5276369559766965
Validation loss: 2.6362786121121053

Epoch: 6| Step: 8
Training loss: 0.6154473798866665
Validation loss: 2.7379266397722897

Epoch: 6| Step: 9
Training loss: 0.8729430271317017
Validation loss: 2.715199047962442

Epoch: 6| Step: 10
Training loss: 0.5138396072670768
Validation loss: 2.645958819880325

Epoch: 6| Step: 11
Training loss: 0.9107767699414987
Validation loss: 2.650908421213744

Epoch: 6| Step: 12
Training loss: 0.7713423586157746
Validation loss: 2.6881048275994015

Epoch: 6| Step: 13
Training loss: 0.8379423396728405
Validation loss: 2.679298454195588

Epoch: 225| Step: 0
Training loss: 0.9470209493928142
Validation loss: 2.730426415082028

Epoch: 6| Step: 1
Training loss: 0.7678083312403127
Validation loss: 2.60914951956845

Epoch: 6| Step: 2
Training loss: 0.6173913112153178
Validation loss: 2.7513389362274765

Epoch: 6| Step: 3
Training loss: 0.874566379459729
Validation loss: 2.7420694193544737

Epoch: 6| Step: 4
Training loss: 1.6147077779085386
Validation loss: 2.6969495583988006

Epoch: 6| Step: 5
Training loss: 0.8318630281270453
Validation loss: 2.6760166036863366

Epoch: 6| Step: 6
Training loss: 0.7041287780665778
Validation loss: 2.666907289695587

Epoch: 6| Step: 7
Training loss: 0.8101061254609037
Validation loss: 2.6887992557144385

Epoch: 6| Step: 8
Training loss: 0.8525662587165963
Validation loss: 2.6676735740302724

Epoch: 6| Step: 9
Training loss: 0.7674233860582342
Validation loss: 2.6489930597014935

Epoch: 6| Step: 10
Training loss: 0.61476560626828
Validation loss: 2.7583665876506465

Epoch: 6| Step: 11
Training loss: 0.792838062359949
Validation loss: 2.675203076197447

Epoch: 6| Step: 12
Training loss: 0.9125919739866236
Validation loss: 2.764692778003257

Epoch: 6| Step: 13
Training loss: 0.5915706693203098
Validation loss: 2.684357113939589

Epoch: 226| Step: 0
Training loss: 1.229420581820098
Validation loss: 2.716460495323875

Epoch: 6| Step: 1
Training loss: 0.8425808683234888
Validation loss: 2.7364725478235967

Epoch: 6| Step: 2
Training loss: 1.0008650852558887
Validation loss: 2.7071119097371312

Epoch: 6| Step: 3
Training loss: 0.6168477052565366
Validation loss: 2.664076729565874

Epoch: 6| Step: 4
Training loss: 0.8153879120684642
Validation loss: 2.637751368134498

Epoch: 6| Step: 5
Training loss: 0.7059798458210659
Validation loss: 2.64384438757297

Epoch: 6| Step: 6
Training loss: 0.5764072777854502
Validation loss: 2.671735585165225

Epoch: 6| Step: 7
Training loss: 0.9270362556305659
Validation loss: 2.710205265062685

Epoch: 6| Step: 8
Training loss: 0.783209099116574
Validation loss: 2.690111503086383

Epoch: 6| Step: 9
Training loss: 0.5151068945472724
Validation loss: 2.6414425579359864

Epoch: 6| Step: 10
Training loss: 1.5441346990354368
Validation loss: 2.669216246007989

Epoch: 6| Step: 11
Training loss: 0.8978839661794318
Validation loss: 2.6394390023586523

Epoch: 6| Step: 12
Training loss: 0.5196620805112637
Validation loss: 2.6506645868774226

Epoch: 6| Step: 13
Training loss: 0.7496085734956958
Validation loss: 2.7020129523796275

Epoch: 227| Step: 0
Training loss: 1.1053063371058882
Validation loss: 2.7185427195724103

Epoch: 6| Step: 1
Training loss: 0.8032106346459803
Validation loss: 2.7430004135791646

Epoch: 6| Step: 2
Training loss: 0.3987769756340662
Validation loss: 2.742617306259396

Epoch: 6| Step: 3
Training loss: 0.7020871662257886
Validation loss: 2.630427894618677

Epoch: 6| Step: 4
Training loss: 0.6210576172880795
Validation loss: 2.7179564271512113

Epoch: 6| Step: 5
Training loss: 1.1335337480351304
Validation loss: 2.7007398280508603

Epoch: 6| Step: 6
Training loss: 0.6896473122120041
Validation loss: 2.604162373857139

Epoch: 6| Step: 7
Training loss: 0.5311818920682845
Validation loss: 2.7081632903099515

Epoch: 6| Step: 8
Training loss: 1.4318192228778617
Validation loss: 2.7376782909378603

Epoch: 6| Step: 9
Training loss: 0.6486214526203137
Validation loss: 2.6394919648849973

Epoch: 6| Step: 10
Training loss: 0.9418687752642668
Validation loss: 2.695895374317267

Epoch: 6| Step: 11
Training loss: 0.935329021660983
Validation loss: 2.8420216964110057

Epoch: 6| Step: 12
Training loss: 0.889906308836114
Validation loss: 2.7151383859856377

Epoch: 6| Step: 13
Training loss: 0.7807401901053902
Validation loss: 2.697958902939117

Epoch: 228| Step: 0
Training loss: 0.8538692623409718
Validation loss: 2.646397768224646

Epoch: 6| Step: 1
Training loss: 1.0446140299302415
Validation loss: 2.6060487024523993

Epoch: 6| Step: 2
Training loss: 0.8868117766799789
Validation loss: 2.723308395736924

Epoch: 6| Step: 3
Training loss: 0.7549567537995633
Validation loss: 2.7342187891344905

Epoch: 6| Step: 4
Training loss: 0.729644800280531
Validation loss: 2.676189233718691

Epoch: 6| Step: 5
Training loss: 0.7156616701284227
Validation loss: 2.704912098404157

Epoch: 6| Step: 6
Training loss: 0.5607319170875943
Validation loss: 2.7466686907624993

Epoch: 6| Step: 7
Training loss: 1.0018875070839495
Validation loss: 2.7551870844021016

Epoch: 6| Step: 8
Training loss: 0.6537785540995097
Validation loss: 2.736653161830624

Epoch: 6| Step: 9
Training loss: 0.44945261299612055
Validation loss: 2.771070661395736

Epoch: 6| Step: 10
Training loss: 1.034783753365527
Validation loss: 2.680794215791955

Epoch: 6| Step: 11
Training loss: 0.7848363575785624
Validation loss: 2.689465816618376

Epoch: 6| Step: 12
Training loss: 0.5785921632156227
Validation loss: 2.75183873404724

Epoch: 6| Step: 13
Training loss: 1.3822973552587763
Validation loss: 2.68541151410761

Epoch: 229| Step: 0
Training loss: 0.5226339748864662
Validation loss: 2.672668867054477

Epoch: 6| Step: 1
Training loss: 0.6001767633254976
Validation loss: 2.5791617880812576

Epoch: 6| Step: 2
Training loss: 0.8006705975260021
Validation loss: 2.6881950647665525

Epoch: 6| Step: 3
Training loss: 0.6177044405715362
Validation loss: 2.701237881604005

Epoch: 6| Step: 4
Training loss: 0.5582660434038768
Validation loss: 2.702239286519778

Epoch: 6| Step: 5
Training loss: 1.033410612159697
Validation loss: 2.6393226105373504

Epoch: 6| Step: 6
Training loss: 0.7958842832090708
Validation loss: 2.7625828334995886

Epoch: 6| Step: 7
Training loss: 0.9348309989415367
Validation loss: 2.741224752096209

Epoch: 6| Step: 8
Training loss: 0.8106893758866062
Validation loss: 2.6741060010860744

Epoch: 6| Step: 9
Training loss: 0.5649360518008059
Validation loss: 2.745340546964247

Epoch: 6| Step: 10
Training loss: 1.5695993502678727
Validation loss: 2.6695905590083626

Epoch: 6| Step: 11
Training loss: 0.5297947755283111
Validation loss: 2.6854458950593734

Epoch: 6| Step: 12
Training loss: 0.7636130620061047
Validation loss: 2.6842188063252035

Epoch: 6| Step: 13
Training loss: 0.8054040477676546
Validation loss: 2.746595572883284

Epoch: 230| Step: 0
Training loss: 1.160706155350265
Validation loss: 2.687849761322596

Epoch: 6| Step: 1
Training loss: 0.551979007100619
Validation loss: 2.648224663598502

Epoch: 6| Step: 2
Training loss: 0.6276302068433944
Validation loss: 2.6296634122183886

Epoch: 6| Step: 3
Training loss: 0.6972613294453097
Validation loss: 2.698894711304899

Epoch: 6| Step: 4
Training loss: 0.7454627199554745
Validation loss: 2.6345284263065243

Epoch: 6| Step: 5
Training loss: 1.3859909081731947
Validation loss: 2.699506156404233

Epoch: 6| Step: 6
Training loss: 0.7516366664273528
Validation loss: 2.656896564854081

Epoch: 6| Step: 7
Training loss: 0.8929755663674183
Validation loss: 2.648559177420512

Epoch: 6| Step: 8
Training loss: 0.6190444919791906
Validation loss: 2.653173392745268

Epoch: 6| Step: 9
Training loss: 0.810957691918805
Validation loss: 2.72194341580132

Epoch: 6| Step: 10
Training loss: 0.778894994839969
Validation loss: 2.6101437652572472

Epoch: 6| Step: 11
Training loss: 0.8777021849518251
Validation loss: 2.64866454164964

Epoch: 6| Step: 12
Training loss: 0.7641525121921987
Validation loss: 2.6374338946261666

Epoch: 6| Step: 13
Training loss: 0.7678360445032542
Validation loss: 2.587745303506256

Epoch: 231| Step: 0
Training loss: 0.6235602246101788
Validation loss: 2.59914372049884

Epoch: 6| Step: 1
Training loss: 0.6133732088963455
Validation loss: 2.7699780590230447

Epoch: 6| Step: 2
Training loss: 0.5545967188948218
Validation loss: 2.6057262912947623

Epoch: 6| Step: 3
Training loss: 0.5165993126169403
Validation loss: 2.6595258670722006

Epoch: 6| Step: 4
Training loss: 0.9813969690363529
Validation loss: 2.576360248796068

Epoch: 6| Step: 5
Training loss: 0.5050205360146195
Validation loss: 2.699082639347525

Epoch: 6| Step: 6
Training loss: 0.6570816447087734
Validation loss: 2.593783029859189

Epoch: 6| Step: 7
Training loss: 1.12687421023256
Validation loss: 2.6848140720136944

Epoch: 6| Step: 8
Training loss: 1.538262406171284
Validation loss: 2.679192455596758

Epoch: 6| Step: 9
Training loss: 0.3424697138976992
Validation loss: 2.625829474776119

Epoch: 6| Step: 10
Training loss: 0.5597847466087819
Validation loss: 2.702294165024105

Epoch: 6| Step: 11
Training loss: 0.7894260588719804
Validation loss: 2.6193717382361115

Epoch: 6| Step: 12
Training loss: 0.678772145537032
Validation loss: 2.76138109357905

Epoch: 6| Step: 13
Training loss: 0.8167653366414417
Validation loss: 2.582548027244389

Epoch: 232| Step: 0
Training loss: 1.4281440282843647
Validation loss: 2.6153237382408263

Epoch: 6| Step: 1
Training loss: 0.8066123606461393
Validation loss: 2.6611695303994

Epoch: 6| Step: 2
Training loss: 0.7230992789215177
Validation loss: 2.705569365662202

Epoch: 6| Step: 3
Training loss: 0.9376904929858993
Validation loss: 2.7238593195953364

Epoch: 6| Step: 4
Training loss: 0.4956095878542649
Validation loss: 2.6211491297989036

Epoch: 6| Step: 5
Training loss: 0.7124894777156785
Validation loss: 2.6488746574847712

Epoch: 6| Step: 6
Training loss: 0.4423795114692996
Validation loss: 2.6541159565591164

Epoch: 6| Step: 7
Training loss: 0.653744091131228
Validation loss: 2.6255250890014117

Epoch: 6| Step: 8
Training loss: 0.6401669329998824
Validation loss: 2.699926950502612

Epoch: 6| Step: 9
Training loss: 0.44928114084610066
Validation loss: 2.6148682295967225

Epoch: 6| Step: 10
Training loss: 0.6572636994841853
Validation loss: 2.672814365806896

Epoch: 6| Step: 11
Training loss: 0.814745880130583
Validation loss: 2.702497391065761

Epoch: 6| Step: 12
Training loss: 0.5331456918491032
Validation loss: 2.6235509990642374

Epoch: 6| Step: 13
Training loss: 0.8002573299793251
Validation loss: 2.728267104040807

Epoch: 233| Step: 0
Training loss: 0.8124542223432163
Validation loss: 2.6983691146658466

Epoch: 6| Step: 1
Training loss: 0.7118055472852092
Validation loss: 2.6560996218730746

Epoch: 6| Step: 2
Training loss: 0.787271714803528
Validation loss: 2.668740216370516

Epoch: 6| Step: 3
Training loss: 1.4902821304448914
Validation loss: 2.638942897533955

Epoch: 6| Step: 4
Training loss: 0.6384354600019534
Validation loss: 2.662520737186679

Epoch: 6| Step: 5
Training loss: 0.5589741831876007
Validation loss: 2.6965760296261028

Epoch: 6| Step: 6
Training loss: 0.649684809412667
Validation loss: 2.6722919666717075

Epoch: 6| Step: 7
Training loss: 0.5083435509650182
Validation loss: 2.5763368667007103

Epoch: 6| Step: 8
Training loss: 0.5704147299498437
Validation loss: 2.5962699843329187

Epoch: 6| Step: 9
Training loss: 0.5640959087844258
Validation loss: 2.617375077694798

Epoch: 6| Step: 10
Training loss: 0.7206584223914707
Validation loss: 2.6460143850862514

Epoch: 6| Step: 11
Training loss: 0.5641781094074794
Validation loss: 2.6572991935676216

Epoch: 6| Step: 12
Training loss: 0.5915081465507581
Validation loss: 2.684084555412088

Epoch: 6| Step: 13
Training loss: 0.7041076575238967
Validation loss: 2.64618040546819

Epoch: 234| Step: 0
Training loss: 0.8298378989477212
Validation loss: 2.67165207258186

Epoch: 6| Step: 1
Training loss: 0.6948814556167121
Validation loss: 2.7098957005802036

Epoch: 6| Step: 2
Training loss: 0.5119419921335144
Validation loss: 2.665613254463105

Epoch: 6| Step: 3
Training loss: 0.45464310707909056
Validation loss: 2.6997971087624446

Epoch: 6| Step: 4
Training loss: 0.3742447041727394
Validation loss: 2.6856566472593597

Epoch: 6| Step: 5
Training loss: 0.542516890847378
Validation loss: 2.70287909886861

Epoch: 6| Step: 6
Training loss: 0.8899912670864317
Validation loss: 2.7102318613987615

Epoch: 6| Step: 7
Training loss: 0.4705240534239477
Validation loss: 2.6379121693370102

Epoch: 6| Step: 8
Training loss: 0.7051549431120758
Validation loss: 2.6943848271236073

Epoch: 6| Step: 9
Training loss: 0.6128318257569642
Validation loss: 2.7055088622963765

Epoch: 6| Step: 10
Training loss: 0.9269006456259902
Validation loss: 2.675999913249373

Epoch: 6| Step: 11
Training loss: 1.0334681151278746
Validation loss: 2.7130042854009955

Epoch: 6| Step: 12
Training loss: 1.089130345862386
Validation loss: 2.6967538416681793

Epoch: 6| Step: 13
Training loss: 1.2571151411419634
Validation loss: 2.617009171061322

Epoch: 235| Step: 0
Training loss: 0.8412541102270693
Validation loss: 2.759658195850605

Epoch: 6| Step: 1
Training loss: 0.5349341996897052
Validation loss: 2.7559975044929415

Epoch: 6| Step: 2
Training loss: 0.6204466417687624
Validation loss: 2.635331847342508

Epoch: 6| Step: 3
Training loss: 1.3959543355998714
Validation loss: 2.670373699334399

Epoch: 6| Step: 4
Training loss: 0.5570694994534329
Validation loss: 2.683914246871561

Epoch: 6| Step: 5
Training loss: 0.8904298936726908
Validation loss: 2.613259262653906

Epoch: 6| Step: 6
Training loss: 0.5857082427066992
Validation loss: 2.699912571374563

Epoch: 6| Step: 7
Training loss: 0.7742716981891626
Validation loss: 2.7057029177016934

Epoch: 6| Step: 8
Training loss: 0.5666718485071703
Validation loss: 2.6991763371522737

Epoch: 6| Step: 9
Training loss: 0.8773689218852163
Validation loss: 2.6867158766074204

Epoch: 6| Step: 10
Training loss: 0.6953838183227707
Validation loss: 2.6919502406148164

Epoch: 6| Step: 11
Training loss: 0.7506180441960512
Validation loss: 2.6174835493122797

Epoch: 6| Step: 12
Training loss: 0.9955223688652157
Validation loss: 2.609164398892527

Epoch: 6| Step: 13
Training loss: 0.9194367702953956
Validation loss: 2.6462389767693044

Epoch: 236| Step: 0
Training loss: 0.6294335944318089
Validation loss: 2.571662339680514

Epoch: 6| Step: 1
Training loss: 0.7973676168647436
Validation loss: 2.6958345506558232

Epoch: 6| Step: 2
Training loss: 0.5484967028623952
Validation loss: 2.656544515700464

Epoch: 6| Step: 3
Training loss: 1.074275899580643
Validation loss: 2.6865990777265827

Epoch: 6| Step: 4
Training loss: 0.6959990637159079
Validation loss: 2.6912430712393207

Epoch: 6| Step: 5
Training loss: 1.3048544223016867
Validation loss: 2.6877150634353346

Epoch: 6| Step: 6
Training loss: 0.46957640914697435
Validation loss: 2.7156206295562098

Epoch: 6| Step: 7
Training loss: 0.6644497359434395
Validation loss: 2.643214218523324

Epoch: 6| Step: 8
Training loss: 0.861307226087516
Validation loss: 2.5966665959348005

Epoch: 6| Step: 9
Training loss: 0.6034220156863428
Validation loss: 2.7651057932356657

Epoch: 6| Step: 10
Training loss: 0.510057709130943
Validation loss: 2.770927575786511

Epoch: 6| Step: 11
Training loss: 0.788644736712497
Validation loss: 2.7134667579625495

Epoch: 6| Step: 12
Training loss: 0.431386933493551
Validation loss: 2.589771820189529

Epoch: 6| Step: 13
Training loss: 0.7886385392450591
Validation loss: 2.7233008739454485

Epoch: 237| Step: 0
Training loss: 0.8157562150312191
Validation loss: 2.6915227959825154

Epoch: 6| Step: 1
Training loss: 0.6133476027050268
Validation loss: 2.6973727253564093

Epoch: 6| Step: 2
Training loss: 0.6512650119420486
Validation loss: 2.7319501460996922

Epoch: 6| Step: 3
Training loss: 0.6935787230064978
Validation loss: 2.669944467288513

Epoch: 6| Step: 4
Training loss: 0.7187087005691553
Validation loss: 2.6138372433278914

Epoch: 6| Step: 5
Training loss: 0.5529882973317384
Validation loss: 2.604466586326259

Epoch: 6| Step: 6
Training loss: 0.6460322847846577
Validation loss: 2.7044624151212506

Epoch: 6| Step: 7
Training loss: 0.534085225290864
Validation loss: 2.736846649610811

Epoch: 6| Step: 8
Training loss: 0.91287251798524
Validation loss: 2.699351902284612

Epoch: 6| Step: 9
Training loss: 0.7777429830246255
Validation loss: 2.6812384059035854

Epoch: 6| Step: 10
Training loss: 0.8187725690104344
Validation loss: 2.6806976964771065

Epoch: 6| Step: 11
Training loss: 0.7117449608005708
Validation loss: 2.7065544497508913

Epoch: 6| Step: 12
Training loss: 0.8029113722901985
Validation loss: 2.6946735011616063

Epoch: 6| Step: 13
Training loss: 1.3017783252791175
Validation loss: 2.6677906578277697

Epoch: 238| Step: 0
Training loss: 0.9415008054234508
Validation loss: 2.773042835218861

Epoch: 6| Step: 1
Training loss: 0.8451510206396804
Validation loss: 2.787670924558592

Epoch: 6| Step: 2
Training loss: 1.3662842737001564
Validation loss: 2.70648099693112

Epoch: 6| Step: 3
Training loss: 0.8818318819985649
Validation loss: 2.73899928395565

Epoch: 6| Step: 4
Training loss: 0.6395150314872978
Validation loss: 2.66161574901622

Epoch: 6| Step: 5
Training loss: 0.5372740891790975
Validation loss: 2.623717282257677

Epoch: 6| Step: 6
Training loss: 0.6324788379521531
Validation loss: 2.674543331061234

Epoch: 6| Step: 7
Training loss: 0.9388519076363168
Validation loss: 2.7149496300265197

Epoch: 6| Step: 8
Training loss: 0.9517936789026793
Validation loss: 2.620907135870901

Epoch: 6| Step: 9
Training loss: 0.5208037431576543
Validation loss: 2.70606931299052

Epoch: 6| Step: 10
Training loss: 0.6735574150859841
Validation loss: 2.6885119462516696

Epoch: 6| Step: 11
Training loss: 0.6105058642846963
Validation loss: 2.6687899768941103

Epoch: 6| Step: 12
Training loss: 0.5687372059483463
Validation loss: 2.7860181490495712

Epoch: 6| Step: 13
Training loss: 0.7883224794098979
Validation loss: 2.73541158737172

Epoch: 239| Step: 0
Training loss: 0.8647560881560006
Validation loss: 2.7399420606097964

Epoch: 6| Step: 1
Training loss: 0.8945585688121702
Validation loss: 2.6343306966475026

Epoch: 6| Step: 2
Training loss: 0.49687687195719166
Validation loss: 2.639639013877848

Epoch: 6| Step: 3
Training loss: 0.4115749346824974
Validation loss: 2.736499193803959

Epoch: 6| Step: 4
Training loss: 0.759417731256268
Validation loss: 2.745266105478394

Epoch: 6| Step: 5
Training loss: 0.8310432478120734
Validation loss: 2.7642349801771133

Epoch: 6| Step: 6
Training loss: 0.6590676671671633
Validation loss: 2.6885876709407515

Epoch: 6| Step: 7
Training loss: 0.4768956380155495
Validation loss: 2.700933416933511

Epoch: 6| Step: 8
Training loss: 0.7002114862039805
Validation loss: 2.7108282237606245

Epoch: 6| Step: 9
Training loss: 1.3888126521909794
Validation loss: 2.7042927066562017

Epoch: 6| Step: 10
Training loss: 0.6465305185129011
Validation loss: 2.6898657122847456

Epoch: 6| Step: 11
Training loss: 0.5576542776836597
Validation loss: 2.731687471168184

Epoch: 6| Step: 12
Training loss: 0.5778962275496627
Validation loss: 2.6752444580418078

Epoch: 6| Step: 13
Training loss: 0.5509763331583514
Validation loss: 2.623474131743627

Epoch: 240| Step: 0
Training loss: 0.39306390417973064
Validation loss: 2.7974161658113066

Epoch: 6| Step: 1
Training loss: 0.6170802687191725
Validation loss: 2.683759466734087

Epoch: 6| Step: 2
Training loss: 0.5340368439040256
Validation loss: 2.6912419933879774

Epoch: 6| Step: 3
Training loss: 0.7054179632719877
Validation loss: 2.6696076988472535

Epoch: 6| Step: 4
Training loss: 0.5210957025265466
Validation loss: 2.7184521011315326

Epoch: 6| Step: 5
Training loss: 1.3206384922246457
Validation loss: 2.6959314639957404

Epoch: 6| Step: 6
Training loss: 1.1203412444658138
Validation loss: 2.7244612969160253

Epoch: 6| Step: 7
Training loss: 0.5722266434552189
Validation loss: 2.7172076940562997

Epoch: 6| Step: 8
Training loss: 0.5878743267651645
Validation loss: 2.6552592804786106

Epoch: 6| Step: 9
Training loss: 0.3921625395351105
Validation loss: 2.6983152902654535

Epoch: 6| Step: 10
Training loss: 0.6867442745807449
Validation loss: 2.718539160376179

Epoch: 6| Step: 11
Training loss: 0.4686569439391368
Validation loss: 2.6554743064260338

Epoch: 6| Step: 12
Training loss: 0.6780468882562817
Validation loss: 2.6894501847911565

Epoch: 6| Step: 13
Training loss: 0.662625946812798
Validation loss: 2.6564941443645553

Epoch: 241| Step: 0
Training loss: 0.7967481325173733
Validation loss: 2.663276235647154

Epoch: 6| Step: 1
Training loss: 0.578959867437178
Validation loss: 2.6260522217004403

Epoch: 6| Step: 2
Training loss: 0.49315413663336494
Validation loss: 2.5886915126439627

Epoch: 6| Step: 3
Training loss: 0.6668015706143363
Validation loss: 2.687984792468596

Epoch: 6| Step: 4
Training loss: 0.6433814688283792
Validation loss: 2.6851278082124037

Epoch: 6| Step: 5
Training loss: 0.9783667414959886
Validation loss: 2.659163145419421

Epoch: 6| Step: 6
Training loss: 0.542671396630096
Validation loss: 2.6193655184409814

Epoch: 6| Step: 7
Training loss: 0.7014646423670944
Validation loss: 2.6831670918907324

Epoch: 6| Step: 8
Training loss: 0.7632577851514115
Validation loss: 2.724807597142767

Epoch: 6| Step: 9
Training loss: 1.3694466807949195
Validation loss: 2.797213244452702

Epoch: 6| Step: 10
Training loss: 0.4059413874779933
Validation loss: 2.7337092288441793

Epoch: 6| Step: 11
Training loss: 0.6042153459427906
Validation loss: 2.7864888887720625

Epoch: 6| Step: 12
Training loss: 0.9514674798536817
Validation loss: 2.7201774766699915

Epoch: 6| Step: 13
Training loss: 0.6632665464031834
Validation loss: 2.7395918426574912

Epoch: 242| Step: 0
Training loss: 0.46747866523224246
Validation loss: 2.7035041499076926

Epoch: 6| Step: 1
Training loss: 0.5652844072724337
Validation loss: 2.6241613895302227

Epoch: 6| Step: 2
Training loss: 0.5837208079731636
Validation loss: 2.6145550598399048

Epoch: 6| Step: 3
Training loss: 0.6940561581269938
Validation loss: 2.678780671984099

Epoch: 6| Step: 4
Training loss: 0.6872434137277849
Validation loss: 2.712800660002244

Epoch: 6| Step: 5
Training loss: 0.7001842886297691
Validation loss: 2.6782216325060713

Epoch: 6| Step: 6
Training loss: 0.6735186100946614
Validation loss: 2.7092458410397464

Epoch: 6| Step: 7
Training loss: 0.5204303963007915
Validation loss: 2.7254271233766345

Epoch: 6| Step: 8
Training loss: 0.6226161077523413
Validation loss: 2.6546352938914257

Epoch: 6| Step: 9
Training loss: 1.4270710167272114
Validation loss: 2.7362534673699903

Epoch: 6| Step: 10
Training loss: 0.492071955606107
Validation loss: 2.830842203914866

Epoch: 6| Step: 11
Training loss: 0.7737254367805813
Validation loss: 2.745465716430755

Epoch: 6| Step: 12
Training loss: 0.9693202832026523
Validation loss: 2.693221603458673

Epoch: 6| Step: 13
Training loss: 0.6589755271946272
Validation loss: 2.686006426708139

Epoch: 243| Step: 0
Training loss: 0.7231083460994413
Validation loss: 2.703396307646456

Epoch: 6| Step: 1
Training loss: 0.8611172441722175
Validation loss: 2.6865375333079027

Epoch: 6| Step: 2
Training loss: 0.6628962879017701
Validation loss: 2.688759870713526

Epoch: 6| Step: 3
Training loss: 0.5901738941806173
Validation loss: 2.630792569277733

Epoch: 6| Step: 4
Training loss: 0.6293043452268803
Validation loss: 2.721738269231567

Epoch: 6| Step: 5
Training loss: 0.8627588408908948
Validation loss: 2.7480071968010287

Epoch: 6| Step: 6
Training loss: 1.4467838530534043
Validation loss: 2.6349659912597776

Epoch: 6| Step: 7
Training loss: 0.7919303973420353
Validation loss: 2.7240150304744675

Epoch: 6| Step: 8
Training loss: 0.5418883628033538
Validation loss: 2.669387149912649

Epoch: 6| Step: 9
Training loss: 0.626896460518556
Validation loss: 2.6907362563066286

Epoch: 6| Step: 10
Training loss: 0.49323485215752777
Validation loss: 2.645228659752094

Epoch: 6| Step: 11
Training loss: 0.7491888587247494
Validation loss: 2.6066826657156277

Epoch: 6| Step: 12
Training loss: 0.47627261991674563
Validation loss: 2.699205883416859

Epoch: 6| Step: 13
Training loss: 0.49066210320974923
Validation loss: 2.744046920316828

Epoch: 244| Step: 0
Training loss: 0.7569050418930269
Validation loss: 2.7491425275557084

Epoch: 6| Step: 1
Training loss: 0.6236319112129043
Validation loss: 2.7184541914046263

Epoch: 6| Step: 2
Training loss: 0.5401176961039916
Validation loss: 2.689364813908637

Epoch: 6| Step: 3
Training loss: 0.48245007513612803
Validation loss: 2.665691455699885

Epoch: 6| Step: 4
Training loss: 0.6260292876083395
Validation loss: 2.711305591464151

Epoch: 6| Step: 5
Training loss: 0.7043656318264967
Validation loss: 2.7007220692027034

Epoch: 6| Step: 6
Training loss: 0.570347797921405
Validation loss: 2.6638406193160664

Epoch: 6| Step: 7
Training loss: 0.7481045215197243
Validation loss: 2.7119605765900014

Epoch: 6| Step: 8
Training loss: 1.34962125516264
Validation loss: 2.713495262662015

Epoch: 6| Step: 9
Training loss: 0.5479653796115991
Validation loss: 2.671304831542301

Epoch: 6| Step: 10
Training loss: 0.6352571902237849
Validation loss: 2.6850611095945056

Epoch: 6| Step: 11
Training loss: 0.7325822578306277
Validation loss: 2.700071620579941

Epoch: 6| Step: 12
Training loss: 0.9514039557409417
Validation loss: 2.6823950491429

Epoch: 6| Step: 13
Training loss: 0.8043882313479664
Validation loss: 2.7069326348849345

Epoch: 245| Step: 0
Training loss: 0.567836560341582
Validation loss: 2.726056770707529

Epoch: 6| Step: 1
Training loss: 0.5235257714840543
Validation loss: 2.6715881015159084

Epoch: 6| Step: 2
Training loss: 0.35698172561771707
Validation loss: 2.6950703977497708

Epoch: 6| Step: 3
Training loss: 0.7824883755073347
Validation loss: 2.707561358446077

Epoch: 6| Step: 4
Training loss: 0.6661475713695751
Validation loss: 2.66223499489623

Epoch: 6| Step: 5
Training loss: 0.48660659477532997
Validation loss: 2.6023266102602314

Epoch: 6| Step: 6
Training loss: 0.8725889229479927
Validation loss: 2.785730303670549

Epoch: 6| Step: 7
Training loss: 0.48801004125766617
Validation loss: 2.650971414850571

Epoch: 6| Step: 8
Training loss: 0.6598152769839173
Validation loss: 2.699258424032137

Epoch: 6| Step: 9
Training loss: 1.2640660421465648
Validation loss: 2.759692004590366

Epoch: 6| Step: 10
Training loss: 0.6443647227314095
Validation loss: 2.5924543798657638

Epoch: 6| Step: 11
Training loss: 0.7376375571162898
Validation loss: 2.6663937329649468

Epoch: 6| Step: 12
Training loss: 0.6247345599128502
Validation loss: 2.656843351027418

Epoch: 6| Step: 13
Training loss: 0.7851731028100382
Validation loss: 2.749140742471585

Epoch: 246| Step: 0
Training loss: 0.8450102754114857
Validation loss: 2.7824963552308866

Epoch: 6| Step: 1
Training loss: 0.5245440728623287
Validation loss: 2.7470838372613726

Epoch: 6| Step: 2
Training loss: 1.332404031357268
Validation loss: 2.6601719643403636

Epoch: 6| Step: 3
Training loss: 0.7596920340625154
Validation loss: 2.7024441635240364

Epoch: 6| Step: 4
Training loss: 0.7191222512272047
Validation loss: 2.6515245328877604

Epoch: 6| Step: 5
Training loss: 0.5736285179946365
Validation loss: 2.658613477393268

Epoch: 6| Step: 6
Training loss: 0.7990340361525132
Validation loss: 2.701566301898035

Epoch: 6| Step: 7
Training loss: 0.6613308090272662
Validation loss: 2.6664216157455747

Epoch: 6| Step: 8
Training loss: 0.8442453766894753
Validation loss: 2.614792991428943

Epoch: 6| Step: 9
Training loss: 0.655468020705862
Validation loss: 2.659926155733669

Epoch: 6| Step: 10
Training loss: 0.6215732091381009
Validation loss: 2.6891674517037454

Epoch: 6| Step: 11
Training loss: 0.5671146041223342
Validation loss: 2.7212747857351234

Epoch: 6| Step: 12
Training loss: 0.5973827758621427
Validation loss: 2.652214785002859

Epoch: 6| Step: 13
Training loss: 0.5797866705613988
Validation loss: 2.6662750304248863

Epoch: 247| Step: 0
Training loss: 0.6041258655670552
Validation loss: 2.75361633217636

Epoch: 6| Step: 1
Training loss: 0.6708326015902807
Validation loss: 2.754951123717343

Epoch: 6| Step: 2
Training loss: 1.223415200138627
Validation loss: 2.711109958406978

Epoch: 6| Step: 3
Training loss: 0.6160711017947387
Validation loss: 2.731170324040702

Epoch: 6| Step: 4
Training loss: 0.8185963071465349
Validation loss: 2.653193244610533

Epoch: 6| Step: 5
Training loss: 0.5879926624651225
Validation loss: 2.6694245283336784

Epoch: 6| Step: 6
Training loss: 0.9430434683310872
Validation loss: 2.616451095298485

Epoch: 6| Step: 7
Training loss: 0.5253379256468109
Validation loss: 2.67576654806066

Epoch: 6| Step: 8
Training loss: 0.6185441859720673
Validation loss: 2.6835513419289896

Epoch: 6| Step: 9
Training loss: 0.5953716919474911
Validation loss: 2.6707485196418568

Epoch: 6| Step: 10
Training loss: 0.645199192620001
Validation loss: 2.7590832254675015

Epoch: 6| Step: 11
Training loss: 0.7185730509007023
Validation loss: 2.669644590432834

Epoch: 6| Step: 12
Training loss: 0.5044474098575402
Validation loss: 2.731400694134334

Epoch: 6| Step: 13
Training loss: 0.6515831996639336
Validation loss: 2.7019440380967765

Epoch: 248| Step: 0
Training loss: 0.6212217570894658
Validation loss: 2.6624353535285605

Epoch: 6| Step: 1
Training loss: 0.41794397155899143
Validation loss: 2.614791547734589

Epoch: 6| Step: 2
Training loss: 0.5087931041593611
Validation loss: 2.6605200609763853

Epoch: 6| Step: 3
Training loss: 0.7056684690792411
Validation loss: 2.701842531186646

Epoch: 6| Step: 4
Training loss: 0.47475868984603925
Validation loss: 2.652615375496365

Epoch: 6| Step: 5
Training loss: 0.9379507888378228
Validation loss: 2.7354369508253176

Epoch: 6| Step: 6
Training loss: 0.6776631122687601
Validation loss: 2.799457799549029

Epoch: 6| Step: 7
Training loss: 0.9825013206317752
Validation loss: 2.7108786042454898

Epoch: 6| Step: 8
Training loss: 0.5452233577762485
Validation loss: 2.6821402398978864

Epoch: 6| Step: 9
Training loss: 0.4921610083338183
Validation loss: 2.691467136825651

Epoch: 6| Step: 10
Training loss: 1.2643119688440736
Validation loss: 2.7023489100743427

Epoch: 6| Step: 11
Training loss: 0.6924982875844117
Validation loss: 2.6547428867009972

Epoch: 6| Step: 12
Training loss: 0.7358142061076842
Validation loss: 2.7622548131174347

Epoch: 6| Step: 13
Training loss: 0.7750284420454915
Validation loss: 2.7190704595310975

Epoch: 249| Step: 0
Training loss: 0.5068770963387936
Validation loss: 2.6763067096164046

Epoch: 6| Step: 1
Training loss: 0.6036906559529222
Validation loss: 2.661206800266371

Epoch: 6| Step: 2
Training loss: 0.6269018324550926
Validation loss: 2.6375676199152984

Epoch: 6| Step: 3
Training loss: 0.7446618044730619
Validation loss: 2.664064483790997

Epoch: 6| Step: 4
Training loss: 0.4340312228595913
Validation loss: 2.679413561818226

Epoch: 6| Step: 5
Training loss: 0.5428319250923437
Validation loss: 2.6164291118094956

Epoch: 6| Step: 6
Training loss: 0.4493186839526225
Validation loss: 2.7889257516826875

Epoch: 6| Step: 7
Training loss: 0.6986918248780561
Validation loss: 2.6602918802229474

Epoch: 6| Step: 8
Training loss: 0.7572547984079824
Validation loss: 2.6731316658146804

Epoch: 6| Step: 9
Training loss: 0.7503216371690887
Validation loss: 2.6883870220873614

Epoch: 6| Step: 10
Training loss: 1.3224230719043892
Validation loss: 2.6652540150742072

Epoch: 6| Step: 11
Training loss: 0.8590909314992735
Validation loss: 2.777856320754238

Epoch: 6| Step: 12
Training loss: 0.6650728057501636
Validation loss: 2.6599409302866746

Epoch: 6| Step: 13
Training loss: 0.6804071978859967
Validation loss: 2.7254587907154835

Epoch: 250| Step: 0
Training loss: 0.591075444897279
Validation loss: 2.746299667198658

Epoch: 6| Step: 1
Training loss: 0.8145118161650482
Validation loss: 2.7654378579826795

Epoch: 6| Step: 2
Training loss: 0.7807425567584855
Validation loss: 2.7768267200802508

Epoch: 6| Step: 3
Training loss: 0.49884250891969073
Validation loss: 2.6878622904997442

Epoch: 6| Step: 4
Training loss: 0.7202171196335863
Validation loss: 2.630424299280904

Epoch: 6| Step: 5
Training loss: 0.7261073009391324
Validation loss: 2.689507739903001

Epoch: 6| Step: 6
Training loss: 0.490293993117399
Validation loss: 2.681070510262884

Epoch: 6| Step: 7
Training loss: 0.6340017094243107
Validation loss: 2.715137346890513

Epoch: 6| Step: 8
Training loss: 0.8752229270332786
Validation loss: 2.6910679221141716

Epoch: 6| Step: 9
Training loss: 0.5722955168640951
Validation loss: 2.689498284135526

Epoch: 6| Step: 10
Training loss: 0.6057574660517687
Validation loss: 2.6611280640725985

Epoch: 6| Step: 11
Training loss: 0.6539384002256426
Validation loss: 2.6426935163680745

Epoch: 6| Step: 12
Training loss: 1.3891062640578828
Validation loss: 2.6504610671200575

Epoch: 6| Step: 13
Training loss: 0.504964176314254
Validation loss: 2.623522388023206

Epoch: 251| Step: 0
Training loss: 0.5016386182311501
Validation loss: 2.693425853370796

Epoch: 6| Step: 1
Training loss: 0.5005470501890631
Validation loss: 2.7428556028690063

Epoch: 6| Step: 2
Training loss: 1.2474034520860948
Validation loss: 2.7043791050237327

Epoch: 6| Step: 3
Training loss: 0.6978241209095201
Validation loss: 2.6474787834501265

Epoch: 6| Step: 4
Training loss: 0.5314880847366867
Validation loss: 2.704621747718244

Epoch: 6| Step: 5
Training loss: 0.7032409148566803
Validation loss: 2.7531006268199283

Epoch: 6| Step: 6
Training loss: 0.6813915420620879
Validation loss: 2.7105223881136364

Epoch: 6| Step: 7
Training loss: 0.6638177757358826
Validation loss: 2.6664741317464205

Epoch: 6| Step: 8
Training loss: 0.8448874612502466
Validation loss: 2.6966977158052927

Epoch: 6| Step: 9
Training loss: 0.7912326844597211
Validation loss: 2.596741877271771

Epoch: 6| Step: 10
Training loss: 0.831692622231402
Validation loss: 2.62885366371165

Epoch: 6| Step: 11
Training loss: 0.8661837568179493
Validation loss: 2.6480855042068665

Epoch: 6| Step: 12
Training loss: 0.7080344990929628
Validation loss: 2.686672245860716

Epoch: 6| Step: 13
Training loss: 0.5585502394156215
Validation loss: 2.6738545333119195

Epoch: 252| Step: 0
Training loss: 0.368015168131372
Validation loss: 2.7204846953746946

Epoch: 6| Step: 1
Training loss: 0.9829518763655779
Validation loss: 2.6563161654739926

Epoch: 6| Step: 2
Training loss: 0.47669186946736386
Validation loss: 2.670707283874163

Epoch: 6| Step: 3
Training loss: 0.7646177634058426
Validation loss: 2.6570678349494026

Epoch: 6| Step: 4
Training loss: 0.5840831405152038
Validation loss: 2.7153029897310126

Epoch: 6| Step: 5
Training loss: 0.6314495149066103
Validation loss: 2.6299223388693225

Epoch: 6| Step: 6
Training loss: 0.510161527457404
Validation loss: 2.6870701468269313

Epoch: 6| Step: 7
Training loss: 0.47883324494489965
Validation loss: 2.7198968346633015

Epoch: 6| Step: 8
Training loss: 0.47247370828413315
Validation loss: 2.693091069560541

Epoch: 6| Step: 9
Training loss: 0.5941309961345053
Validation loss: 2.618702297337653

Epoch: 6| Step: 10
Training loss: 0.6031690670379214
Validation loss: 2.6864973164264625

Epoch: 6| Step: 11
Training loss: 0.7102883697586612
Validation loss: 2.6568411823693836

Epoch: 6| Step: 12
Training loss: 0.6924978787427563
Validation loss: 2.6865192072641024

Epoch: 6| Step: 13
Training loss: 1.346570669606662
Validation loss: 2.735513940395282

Epoch: 253| Step: 0
Training loss: 0.8724348069021041
Validation loss: 2.6980242075652985

Epoch: 6| Step: 1
Training loss: 0.42914540167163556
Validation loss: 2.6952938797901886

Epoch: 6| Step: 2
Training loss: 0.44287129563029437
Validation loss: 2.6772380640657523

Epoch: 6| Step: 3
Training loss: 0.5416339687112833
Validation loss: 2.6826238235189734

Epoch: 6| Step: 4
Training loss: 0.5981765427100518
Validation loss: 2.7743436667241363

Epoch: 6| Step: 5
Training loss: 0.7083567634148153
Validation loss: 2.726449463112495

Epoch: 6| Step: 6
Training loss: 0.5778325088444848
Validation loss: 2.764340506503826

Epoch: 6| Step: 7
Training loss: 0.7510490233704297
Validation loss: 2.7270601505219907

Epoch: 6| Step: 8
Training loss: 0.7858222300519405
Validation loss: 2.6518529663561123

Epoch: 6| Step: 9
Training loss: 0.8021397302460102
Validation loss: 2.722669224683075

Epoch: 6| Step: 10
Training loss: 0.555983841901403
Validation loss: 2.7117958139224774

Epoch: 6| Step: 11
Training loss: 1.2755672688856485
Validation loss: 2.628398300154945

Epoch: 6| Step: 12
Training loss: 0.6387068945940066
Validation loss: 2.669674597495442

Epoch: 6| Step: 13
Training loss: 0.41715773215513885
Validation loss: 2.708889234174429

Epoch: 254| Step: 0
Training loss: 0.4709883652665381
Validation loss: 2.6772681492837336

Epoch: 6| Step: 1
Training loss: 1.3303179419677056
Validation loss: 2.5935541714811565

Epoch: 6| Step: 2
Training loss: 0.36416168580842667
Validation loss: 2.7359729566297215

Epoch: 6| Step: 3
Training loss: 0.828003136647314
Validation loss: 2.7697313933158547

Epoch: 6| Step: 4
Training loss: 0.4130906990804914
Validation loss: 2.7696506203706037

Epoch: 6| Step: 5
Training loss: 0.6477662484292781
Validation loss: 2.7167749794818845

Epoch: 6| Step: 6
Training loss: 0.6905843299869885
Validation loss: 2.709415847898654

Epoch: 6| Step: 7
Training loss: 0.511821183297177
Validation loss: 2.7697962395174907

Epoch: 6| Step: 8
Training loss: 0.7161462309865136
Validation loss: 2.7863605137467653

Epoch: 6| Step: 9
Training loss: 0.6117737337348195
Validation loss: 2.7234225259771567

Epoch: 6| Step: 10
Training loss: 0.7925019793079581
Validation loss: 2.7342834602655492

Epoch: 6| Step: 11
Training loss: 0.6287974387866558
Validation loss: 2.7001477053942518

Epoch: 6| Step: 12
Training loss: 0.5687800158450657
Validation loss: 2.676164689632301

Epoch: 6| Step: 13
Training loss: 0.3179141248415572
Validation loss: 2.716776412861214

Epoch: 255| Step: 0
Training loss: 0.5303712196188398
Validation loss: 2.693955969256439

Epoch: 6| Step: 1
Training loss: 0.493413367378884
Validation loss: 2.722676142542817

Epoch: 6| Step: 2
Training loss: 0.7496523051171823
Validation loss: 2.688089025251245

Epoch: 6| Step: 3
Training loss: 0.6175060415937649
Validation loss: 2.67121539981124

Epoch: 6| Step: 4
Training loss: 0.5676282657074878
Validation loss: 2.6958258982992653

Epoch: 6| Step: 5
Training loss: 0.6328866703223976
Validation loss: 2.6723506422328867

Epoch: 6| Step: 6
Training loss: 0.5655953752547147
Validation loss: 2.6358279534268014

Epoch: 6| Step: 7
Training loss: 0.6434634293032454
Validation loss: 2.7331981924035307

Epoch: 6| Step: 8
Training loss: 0.5229767151913548
Validation loss: 2.666415788849725

Epoch: 6| Step: 9
Training loss: 0.9346728931281735
Validation loss: 2.770187508219175

Epoch: 6| Step: 10
Training loss: 1.360775368774474
Validation loss: 2.7435466155123107

Epoch: 6| Step: 11
Training loss: 0.650019038361721
Validation loss: 2.7247672742804783

Epoch: 6| Step: 12
Training loss: 0.9502369008073434
Validation loss: 2.709170099743401

Epoch: 6| Step: 13
Training loss: 0.7700407403844336
Validation loss: 2.638260785581598

Epoch: 256| Step: 0
Training loss: 0.8422968678420379
Validation loss: 2.6346033874437045

Epoch: 6| Step: 1
Training loss: 0.513093630148931
Validation loss: 2.709236718168501

Epoch: 6| Step: 2
Training loss: 0.5848500141824422
Validation loss: 2.704596984159648

Epoch: 6| Step: 3
Training loss: 0.8780505613766743
Validation loss: 2.7222796069690363

Epoch: 6| Step: 4
Training loss: 0.5631990856925901
Validation loss: 2.704717383907367

Epoch: 6| Step: 5
Training loss: 0.966316674166411
Validation loss: 2.673022271139287

Epoch: 6| Step: 6
Training loss: 0.44356417862057307
Validation loss: 2.67447461527456

Epoch: 6| Step: 7
Training loss: 0.647382061096503
Validation loss: 2.770512430830145

Epoch: 6| Step: 8
Training loss: 0.5175943911893411
Validation loss: 2.7775008831829653

Epoch: 6| Step: 9
Training loss: 0.6408723958250662
Validation loss: 2.7688871064119978

Epoch: 6| Step: 10
Training loss: 0.6796447915876637
Validation loss: 2.653941523905486

Epoch: 6| Step: 11
Training loss: 0.8235690914740527
Validation loss: 2.7340324259920803

Epoch: 6| Step: 12
Training loss: 0.3878974099540634
Validation loss: 2.703487717358999

Epoch: 6| Step: 13
Training loss: 1.2515826696325578
Validation loss: 2.7017483154782975

Epoch: 257| Step: 0
Training loss: 0.45678410817092635
Validation loss: 2.708784393505294

Epoch: 6| Step: 1
Training loss: 0.6523042084365311
Validation loss: 2.6786417055750302

Epoch: 6| Step: 2
Training loss: 0.4396712715391244
Validation loss: 2.708839256765363

Epoch: 6| Step: 3
Training loss: 0.4326625137178773
Validation loss: 2.6449855036779972

Epoch: 6| Step: 4
Training loss: 0.5509292187341521
Validation loss: 2.647445177729974

Epoch: 6| Step: 5
Training loss: 0.4770470953870211
Validation loss: 2.692773524269351

Epoch: 6| Step: 6
Training loss: 0.4109040845041774
Validation loss: 2.69725121695215

Epoch: 6| Step: 7
Training loss: 0.5764435725590715
Validation loss: 2.7391388584540106

Epoch: 6| Step: 8
Training loss: 1.2574491746160374
Validation loss: 2.702604666373093

Epoch: 6| Step: 9
Training loss: 0.746478316174187
Validation loss: 2.7513025623519103

Epoch: 6| Step: 10
Training loss: 0.6885539126401288
Validation loss: 2.712455200083182

Epoch: 6| Step: 11
Training loss: 0.8935538203334249
Validation loss: 2.7000883388196413

Epoch: 6| Step: 12
Training loss: 0.8325250798820777
Validation loss: 2.753560275807465

Epoch: 6| Step: 13
Training loss: 0.5411271073372373
Validation loss: 2.7420354730355205

Epoch: 258| Step: 0
Training loss: 0.5161518526415957
Validation loss: 2.7473612176001074

Epoch: 6| Step: 1
Training loss: 1.3221841671531325
Validation loss: 2.6611732783142754

Epoch: 6| Step: 2
Training loss: 0.6273773279384389
Validation loss: 2.715646558294848

Epoch: 6| Step: 3
Training loss: 0.8277670248522279
Validation loss: 2.797051536060721

Epoch: 6| Step: 4
Training loss: 0.5092783678287732
Validation loss: 2.758916992102062

Epoch: 6| Step: 5
Training loss: 0.5614630359837253
Validation loss: 2.7389906591469915

Epoch: 6| Step: 6
Training loss: 0.5141184790837915
Validation loss: 2.789416222176202

Epoch: 6| Step: 7
Training loss: 0.6665263077880281
Validation loss: 2.7900568937382304

Epoch: 6| Step: 8
Training loss: 0.6491592480950136
Validation loss: 2.737513762487367

Epoch: 6| Step: 9
Training loss: 0.4464631523635301
Validation loss: 2.748739358194131

Epoch: 6| Step: 10
Training loss: 0.5403870053216281
Validation loss: 2.743049203621207

Epoch: 6| Step: 11
Training loss: 0.7917462777380597
Validation loss: 2.6621231672079437

Epoch: 6| Step: 12
Training loss: 0.7926653953549537
Validation loss: 2.702873776913302

Epoch: 6| Step: 13
Training loss: 0.5349404951230791
Validation loss: 2.7983158314445173

Epoch: 259| Step: 0
Training loss: 0.6528161445687592
Validation loss: 2.755990093545591

Epoch: 6| Step: 1
Training loss: 0.4703142768091242
Validation loss: 2.67271270409842

Epoch: 6| Step: 2
Training loss: 0.7186033679826962
Validation loss: 2.7433645216589246

Epoch: 6| Step: 3
Training loss: 0.5741052839837685
Validation loss: 2.7185190183072385

Epoch: 6| Step: 4
Training loss: 0.5074611622179491
Validation loss: 2.6775792598895407

Epoch: 6| Step: 5
Training loss: 0.5398203732940049
Validation loss: 2.702361908736127

Epoch: 6| Step: 6
Training loss: 0.5991910786313455
Validation loss: 2.690657409520036

Epoch: 6| Step: 7
Training loss: 0.8109411912073349
Validation loss: 2.723135046360716

Epoch: 6| Step: 8
Training loss: 0.7650850688783205
Validation loss: 2.644937593917324

Epoch: 6| Step: 9
Training loss: 0.4786158709717719
Validation loss: 2.7114061725497516

Epoch: 6| Step: 10
Training loss: 0.33951028270205963
Validation loss: 2.625157760239144

Epoch: 6| Step: 11
Training loss: 0.5975352395411629
Validation loss: 2.6871287954487926

Epoch: 6| Step: 12
Training loss: 0.5251615230405666
Validation loss: 2.6404266960126535

Epoch: 6| Step: 13
Training loss: 1.210694910176525
Validation loss: 2.7403501058851787

Epoch: 260| Step: 0
Training loss: 0.6051183363357089
Validation loss: 2.7701869344466945

Epoch: 6| Step: 1
Training loss: 0.40895688129399815
Validation loss: 2.770811487173899

Epoch: 6| Step: 2
Training loss: 1.327817185578369
Validation loss: 2.7227075791776887

Epoch: 6| Step: 3
Training loss: 0.640029351187244
Validation loss: 2.6899692222129685

Epoch: 6| Step: 4
Training loss: 0.7158662331125731
Validation loss: 2.690953453299311

Epoch: 6| Step: 5
Training loss: 0.5623692519501904
Validation loss: 2.7179653745555177

Epoch: 6| Step: 6
Training loss: 0.8329481347230149
Validation loss: 2.6756473999701607

Epoch: 6| Step: 7
Training loss: 0.448137757347186
Validation loss: 2.6505576905436268

Epoch: 6| Step: 8
Training loss: 0.7988384964323284
Validation loss: 2.6959156633056267

Epoch: 6| Step: 9
Training loss: 0.6955968939560483
Validation loss: 2.7125112782374243

Epoch: 6| Step: 10
Training loss: 0.5981987130673849
Validation loss: 2.7075895510793084

Epoch: 6| Step: 11
Training loss: 0.6132018408419854
Validation loss: 2.748842371414503

Epoch: 6| Step: 12
Training loss: 0.5721024941469877
Validation loss: 2.74629033462614

Epoch: 6| Step: 13
Training loss: 0.5959729693478798
Validation loss: 2.677225062159967

Epoch: 261| Step: 0
Training loss: 0.3620203758585609
Validation loss: 2.7763941089614343

Epoch: 6| Step: 1
Training loss: 0.7089935386212639
Validation loss: 2.689428450785885

Epoch: 6| Step: 2
Training loss: 0.7345563380589002
Validation loss: 2.693618050136726

Epoch: 6| Step: 3
Training loss: 0.5723323327461047
Validation loss: 2.661103306411345

Epoch: 6| Step: 4
Training loss: 0.588616262339063
Validation loss: 2.6787684192579

Epoch: 6| Step: 5
Training loss: 1.1702442775750208
Validation loss: 2.7135767919179252

Epoch: 6| Step: 6
Training loss: 0.656344520483031
Validation loss: 2.634492362754082

Epoch: 6| Step: 7
Training loss: 0.5811323354434105
Validation loss: 2.6965104467796857

Epoch: 6| Step: 8
Training loss: 0.4384139766078854
Validation loss: 2.692087117790613

Epoch: 6| Step: 9
Training loss: 0.4131099252071314
Validation loss: 2.7325040610848346

Epoch: 6| Step: 10
Training loss: 0.6795301364829035
Validation loss: 2.7111331748151457

Epoch: 6| Step: 11
Training loss: 0.5762442333239062
Validation loss: 2.636760931737245

Epoch: 6| Step: 12
Training loss: 0.5719131321518749
Validation loss: 2.7352261263127966

Epoch: 6| Step: 13
Training loss: 0.4612782721913403
Validation loss: 2.6691404928003313

Epoch: 262| Step: 0
Training loss: 0.6187379893668877
Validation loss: 2.757026221671689

Epoch: 6| Step: 1
Training loss: 0.6342243880204338
Validation loss: 2.8025087768639576

Epoch: 6| Step: 2
Training loss: 0.58823007307821
Validation loss: 2.662994230244319

Epoch: 6| Step: 3
Training loss: 0.6752296357373067
Validation loss: 2.7164179420896124

Epoch: 6| Step: 4
Training loss: 0.39307664182616436
Validation loss: 2.7878889077710314

Epoch: 6| Step: 5
Training loss: 0.5228255096203229
Validation loss: 2.6823228902141407

Epoch: 6| Step: 6
Training loss: 1.2152543432004688
Validation loss: 2.693590168588671

Epoch: 6| Step: 7
Training loss: 0.6017519169623567
Validation loss: 2.7402055176465936

Epoch: 6| Step: 8
Training loss: 0.6868204095822226
Validation loss: 2.6300388294152954

Epoch: 6| Step: 9
Training loss: 0.49456042524577726
Validation loss: 2.6454938285254332

Epoch: 6| Step: 10
Training loss: 0.5885547422683861
Validation loss: 2.6985773041128525

Epoch: 6| Step: 11
Training loss: 0.9689970624345752
Validation loss: 2.739497648767849

Epoch: 6| Step: 12
Training loss: 0.6011221128296446
Validation loss: 2.6476231225970026

Epoch: 6| Step: 13
Training loss: 0.5644599887734173
Validation loss: 2.7692164146630023

Epoch: 263| Step: 0
Training loss: 0.419655116316687
Validation loss: 2.766489716313609

Epoch: 6| Step: 1
Training loss: 0.6095517709070026
Validation loss: 2.699366107751441

Epoch: 6| Step: 2
Training loss: 0.6181427287537974
Validation loss: 2.7537562985549493

Epoch: 6| Step: 3
Training loss: 0.40542845920898957
Validation loss: 2.7343896629303654

Epoch: 6| Step: 4
Training loss: 0.7409016764398001
Validation loss: 2.735791404450077

Epoch: 6| Step: 5
Training loss: 0.48493340821622644
Validation loss: 2.7397867182863713

Epoch: 6| Step: 6
Training loss: 0.5964613794517036
Validation loss: 2.6844350651929103

Epoch: 6| Step: 7
Training loss: 0.5113796828863753
Validation loss: 2.7469707768870144

Epoch: 6| Step: 8
Training loss: 0.609015480994158
Validation loss: 2.702132364346358

Epoch: 6| Step: 9
Training loss: 1.2405571464989242
Validation loss: 2.6539165195299708

Epoch: 6| Step: 10
Training loss: 0.9940896011778732
Validation loss: 2.742710943881216

Epoch: 6| Step: 11
Training loss: 0.5873013708479575
Validation loss: 2.6333661350991857

Epoch: 6| Step: 12
Training loss: 0.44284871811368437
Validation loss: 2.6707476641344714

Epoch: 6| Step: 13
Training loss: 0.565927184509599
Validation loss: 2.6949410592630434

Epoch: 264| Step: 0
Training loss: 0.8200287100952955
Validation loss: 2.709368248813406

Epoch: 6| Step: 1
Training loss: 0.6084005928307529
Validation loss: 2.6277952600461685

Epoch: 6| Step: 2
Training loss: 0.4911500502479836
Validation loss: 2.634668150942239

Epoch: 6| Step: 3
Training loss: 0.6699807277441295
Validation loss: 2.691764789206098

Epoch: 6| Step: 4
Training loss: 0.8239917532938709
Validation loss: 2.6943799603230074

Epoch: 6| Step: 5
Training loss: 0.4415608363245071
Validation loss: 2.7555774136243762

Epoch: 6| Step: 6
Training loss: 0.44500696843831145
Validation loss: 2.7181686276703165

Epoch: 6| Step: 7
Training loss: 0.7408884022702273
Validation loss: 2.769972851639706

Epoch: 6| Step: 8
Training loss: 0.4767293481639589
Validation loss: 2.693394074966826

Epoch: 6| Step: 9
Training loss: 1.2314203367188696
Validation loss: 2.6055301809623

Epoch: 6| Step: 10
Training loss: 0.5417054663724754
Validation loss: 2.7226541629529675

Epoch: 6| Step: 11
Training loss: 0.5603831513982216
Validation loss: 2.7824060130690316

Epoch: 6| Step: 12
Training loss: 0.45924616713318334
Validation loss: 2.726334213420712

Epoch: 6| Step: 13
Training loss: 0.6047810001683226
Validation loss: 2.5907790545837757

Epoch: 265| Step: 0
Training loss: 0.38560205159462646
Validation loss: 2.6871936904463873

Epoch: 6| Step: 1
Training loss: 0.7961262195617946
Validation loss: 2.6536697421558224

Epoch: 6| Step: 2
Training loss: 0.7474431323105512
Validation loss: 2.6579418852820127

Epoch: 6| Step: 3
Training loss: 0.49376226723799393
Validation loss: 2.658250578924584

Epoch: 6| Step: 4
Training loss: 0.48497141758767487
Validation loss: 2.6972576622795925

Epoch: 6| Step: 5
Training loss: 0.5912813011819811
Validation loss: 2.707516860157985

Epoch: 6| Step: 6
Training loss: 0.4624640837461737
Validation loss: 2.7388101557629922

Epoch: 6| Step: 7
Training loss: 0.40911048904918224
Validation loss: 2.651016105323775

Epoch: 6| Step: 8
Training loss: 0.6099001993163672
Validation loss: 2.737492352014829

Epoch: 6| Step: 9
Training loss: 1.2850763359848187
Validation loss: 2.6895573156523125

Epoch: 6| Step: 10
Training loss: 0.6200361784639193
Validation loss: 2.644050798671655

Epoch: 6| Step: 11
Training loss: 0.4612076824180308
Validation loss: 2.6526976973300607

Epoch: 6| Step: 12
Training loss: 0.8004335718654986
Validation loss: 2.607341529856067

Epoch: 6| Step: 13
Training loss: 0.5930638615217408
Validation loss: 2.741237943303582

Epoch: 266| Step: 0
Training loss: 0.7875737413061682
Validation loss: 2.633108075281659

Epoch: 6| Step: 1
Training loss: 0.395456739354052
Validation loss: 2.5592441809527435

Epoch: 6| Step: 2
Training loss: 0.36490718445295217
Validation loss: 2.721315036230739

Epoch: 6| Step: 3
Training loss: 0.5751502338354894
Validation loss: 2.7363148084702664

Epoch: 6| Step: 4
Training loss: 0.6905044018841979
Validation loss: 2.6598256597057053

Epoch: 6| Step: 5
Training loss: 0.4993548850876981
Validation loss: 2.7044799143235227

Epoch: 6| Step: 6
Training loss: 0.7813873170337431
Validation loss: 2.700531775888598

Epoch: 6| Step: 7
Training loss: 0.6135256335026131
Validation loss: 2.718089231675461

Epoch: 6| Step: 8
Training loss: 0.5512113042039066
Validation loss: 2.7342595539245242

Epoch: 6| Step: 9
Training loss: 0.497223326508961
Validation loss: 2.719763672790654

Epoch: 6| Step: 10
Training loss: 0.4591125633929545
Validation loss: 2.7253517734593644

Epoch: 6| Step: 11
Training loss: 0.6653395546661776
Validation loss: 2.642000521031958

Epoch: 6| Step: 12
Training loss: 0.6178577019494422
Validation loss: 2.642821667959661

Epoch: 6| Step: 13
Training loss: 1.133314665939827
Validation loss: 2.73497528753094

Epoch: 267| Step: 0
Training loss: 0.8426812078372178
Validation loss: 2.698963504689625

Epoch: 6| Step: 1
Training loss: 0.45429360215507963
Validation loss: 2.737528829553418

Epoch: 6| Step: 2
Training loss: 0.6993601991588969
Validation loss: 2.692614132520357

Epoch: 6| Step: 3
Training loss: 0.6185022185524058
Validation loss: 2.6965346730523096

Epoch: 6| Step: 4
Training loss: 0.43692714789230896
Validation loss: 2.7964252699955634

Epoch: 6| Step: 5
Training loss: 0.471808453471651
Validation loss: 2.654281642365787

Epoch: 6| Step: 6
Training loss: 0.41026208511186973
Validation loss: 2.7614260909189863

Epoch: 6| Step: 7
Training loss: 0.5475645894660702
Validation loss: 2.723364994545167

Epoch: 6| Step: 8
Training loss: 0.44661034970366825
Validation loss: 2.7633324296702098

Epoch: 6| Step: 9
Training loss: 0.6251672520964866
Validation loss: 2.629933935273604

Epoch: 6| Step: 10
Training loss: 0.6054464766804756
Validation loss: 2.7579344379386352

Epoch: 6| Step: 11
Training loss: 0.5906564028026128
Validation loss: 2.6746466837084535

Epoch: 6| Step: 12
Training loss: 0.6552431466254691
Validation loss: 2.7016051913246084

Epoch: 6| Step: 13
Training loss: 1.2095834360222286
Validation loss: 2.7995369815031435

Epoch: 268| Step: 0
Training loss: 1.3955038830092508
Validation loss: 2.750112213388471

Epoch: 6| Step: 1
Training loss: 0.636317448441572
Validation loss: 2.6978303215516095

Epoch: 6| Step: 2
Training loss: 0.5853763181780307
Validation loss: 2.7046802434708224

Epoch: 6| Step: 3
Training loss: 0.5417560784809105
Validation loss: 2.6980490388148644

Epoch: 6| Step: 4
Training loss: 0.5189607686134063
Validation loss: 2.687777615779735

Epoch: 6| Step: 5
Training loss: 0.5802968958090453
Validation loss: 2.629592745413569

Epoch: 6| Step: 6
Training loss: 0.6918828582317408
Validation loss: 2.651880147921321

Epoch: 6| Step: 7
Training loss: 0.9087379767502751
Validation loss: 2.7198786676450126

Epoch: 6| Step: 8
Training loss: 0.6308284314954921
Validation loss: 2.7102752961438914

Epoch: 6| Step: 9
Training loss: 0.40310493241862244
Validation loss: 2.664385435755211

Epoch: 6| Step: 10
Training loss: 0.4727070363400878
Validation loss: 2.639009933595607

Epoch: 6| Step: 11
Training loss: 0.5186354579629651
Validation loss: 2.6524041102961284

Epoch: 6| Step: 12
Training loss: 0.426151114988765
Validation loss: 2.654059595276898

Epoch: 6| Step: 13
Training loss: 0.5288974620365117
Validation loss: 2.645652304235924

Epoch: 269| Step: 0
Training loss: 0.4175962053458137
Validation loss: 2.6905336926452637

Epoch: 6| Step: 1
Training loss: 0.6447397992827373
Validation loss: 2.715226912503083

Epoch: 6| Step: 2
Training loss: 0.6163578976618223
Validation loss: 2.7368375751857488

Epoch: 6| Step: 3
Training loss: 0.4037593087283608
Validation loss: 2.7408570687586646

Epoch: 6| Step: 4
Training loss: 0.6248679975348888
Validation loss: 2.6895419650709385

Epoch: 6| Step: 5
Training loss: 0.5260530854550098
Validation loss: 2.6364733169674484

Epoch: 6| Step: 6
Training loss: 0.6731923739223471
Validation loss: 2.757419532969069

Epoch: 6| Step: 7
Training loss: 0.45014678627349136
Validation loss: 2.626840657564785

Epoch: 6| Step: 8
Training loss: 0.8570473793758401
Validation loss: 2.7103258481791643

Epoch: 6| Step: 9
Training loss: 1.1249640247102994
Validation loss: 2.78424633797773

Epoch: 6| Step: 10
Training loss: 0.7209394527519642
Validation loss: 2.704444284006346

Epoch: 6| Step: 11
Training loss: 0.5188146826621538
Validation loss: 2.7414838752181927

Epoch: 6| Step: 12
Training loss: 0.33149226704089213
Validation loss: 2.619612941118542

Epoch: 6| Step: 13
Training loss: 0.6236941523959316
Validation loss: 2.6838824520820457

Epoch: 270| Step: 0
Training loss: 0.5538032360621583
Validation loss: 2.6572341591715802

Epoch: 6| Step: 1
Training loss: 0.46246360042748463
Validation loss: 2.6473302786665447

Epoch: 6| Step: 2
Training loss: 0.6098017543179458
Validation loss: 2.7409965341595486

Epoch: 6| Step: 3
Training loss: 0.39764491891361936
Validation loss: 2.604073924638468

Epoch: 6| Step: 4
Training loss: 0.5266408686516355
Validation loss: 2.736117652351663

Epoch: 6| Step: 5
Training loss: 0.8671590783212851
Validation loss: 2.6724747250547987

Epoch: 6| Step: 6
Training loss: 0.4812880253322025
Validation loss: 2.768362324987919

Epoch: 6| Step: 7
Training loss: 0.632174794573352
Validation loss: 2.71018136625802

Epoch: 6| Step: 8
Training loss: 0.5311847534503661
Validation loss: 2.7033119798499747

Epoch: 6| Step: 9
Training loss: 1.2313657851408293
Validation loss: 2.690116865061024

Epoch: 6| Step: 10
Training loss: 0.6574698192138623
Validation loss: 2.6184929016689154

Epoch: 6| Step: 11
Training loss: 0.479502334021217
Validation loss: 2.7369072805171952

Epoch: 6| Step: 12
Training loss: 0.6292928135537778
Validation loss: 2.6604591678897815

Epoch: 6| Step: 13
Training loss: 0.42334871381819045
Validation loss: 2.668880837335528

Epoch: 271| Step: 0
Training loss: 0.6345087323846669
Validation loss: 2.6941107978144987

Epoch: 6| Step: 1
Training loss: 0.6533866358279767
Validation loss: 2.696033517715012

Epoch: 6| Step: 2
Training loss: 0.7513091661636163
Validation loss: 2.697871871831662

Epoch: 6| Step: 3
Training loss: 0.6389496925233262
Validation loss: 2.6995409245571675

Epoch: 6| Step: 4
Training loss: 0.5621066837630752
Validation loss: 2.642328604388089

Epoch: 6| Step: 5
Training loss: 0.5022488327886254
Validation loss: 2.6500905447312255

Epoch: 6| Step: 6
Training loss: 0.44664751678429016
Validation loss: 2.6887367419169146

Epoch: 6| Step: 7
Training loss: 0.372869519320347
Validation loss: 2.6558399706748497

Epoch: 6| Step: 8
Training loss: 0.49952329322031175
Validation loss: 2.6895056640693955

Epoch: 6| Step: 9
Training loss: 1.206539461261216
Validation loss: 2.6478163179180743

Epoch: 6| Step: 10
Training loss: 0.33749636762924895
Validation loss: 2.662111225906516

Epoch: 6| Step: 11
Training loss: 0.5896393124814726
Validation loss: 2.777137644971901

Epoch: 6| Step: 12
Training loss: 0.5912827376643367
Validation loss: 2.727936464999874

Epoch: 6| Step: 13
Training loss: 0.6197031155541012
Validation loss: 2.70686029332001

Epoch: 272| Step: 0
Training loss: 0.6836480473343943
Validation loss: 2.7431920920298354

Epoch: 6| Step: 1
Training loss: 0.43924277463473105
Validation loss: 2.7320478872800376

Epoch: 6| Step: 2
Training loss: 1.2843958683592551
Validation loss: 2.7095059619478254

Epoch: 6| Step: 3
Training loss: 0.38286395602935325
Validation loss: 2.669334743323924

Epoch: 6| Step: 4
Training loss: 0.3635498612508665
Validation loss: 2.7348371932548243

Epoch: 6| Step: 5
Training loss: 0.5618083463263409
Validation loss: 2.6582491812545532

Epoch: 6| Step: 6
Training loss: 0.7148433330930735
Validation loss: 2.6991802972832373

Epoch: 6| Step: 7
Training loss: 0.5102766552102141
Validation loss: 2.6832726595122134

Epoch: 6| Step: 8
Training loss: 0.5538166355658412
Validation loss: 2.7360984965473065

Epoch: 6| Step: 9
Training loss: 0.582227379440968
Validation loss: 2.676983654576036

Epoch: 6| Step: 10
Training loss: 0.43250264530806176
Validation loss: 2.6445458851742223

Epoch: 6| Step: 11
Training loss: 0.35600809952812373
Validation loss: 2.6530233494756423

Epoch: 6| Step: 12
Training loss: 0.5775391213265764
Validation loss: 2.7447202312479977

Epoch: 6| Step: 13
Training loss: 0.3933893807870268
Validation loss: 2.6748436391890476

Epoch: 273| Step: 0
Training loss: 0.8612135899658162
Validation loss: 2.6815720169911486

Epoch: 6| Step: 1
Training loss: 0.39693429158577426
Validation loss: 2.6583361044682934

Epoch: 6| Step: 2
Training loss: 0.5386453202903644
Validation loss: 2.6764544231910516

Epoch: 6| Step: 3
Training loss: 0.35299397544339645
Validation loss: 2.6066377639468974

Epoch: 6| Step: 4
Training loss: 0.48167324280567053
Validation loss: 2.720448967937667

Epoch: 6| Step: 5
Training loss: 0.5246007434308146
Validation loss: 2.624674807190554

Epoch: 6| Step: 6
Training loss: 0.4929791698775274
Validation loss: 2.686541748724022

Epoch: 6| Step: 7
Training loss: 0.4949945602696081
Validation loss: 2.664659837743455

Epoch: 6| Step: 8
Training loss: 0.5396829986826319
Validation loss: 2.595150152185438

Epoch: 6| Step: 9
Training loss: 1.2212120033061593
Validation loss: 2.7714239987156315

Epoch: 6| Step: 10
Training loss: 0.565786035280974
Validation loss: 2.730466719859928

Epoch: 6| Step: 11
Training loss: 0.7275134190898127
Validation loss: 2.7153719820384157

Epoch: 6| Step: 12
Training loss: 0.5634251774409954
Validation loss: 2.673822254799566

Epoch: 6| Step: 13
Training loss: 0.7314946523407028
Validation loss: 2.737059360034669

Epoch: 274| Step: 0
Training loss: 0.5824344441767316
Validation loss: 2.70635568355154

Epoch: 6| Step: 1
Training loss: 0.5803010043565288
Validation loss: 2.721606409286115

Epoch: 6| Step: 2
Training loss: 0.7151301492933396
Validation loss: 2.6915624358208436

Epoch: 6| Step: 3
Training loss: 0.7541434749880187
Validation loss: 2.702299370483525

Epoch: 6| Step: 4
Training loss: 1.161091129206078
Validation loss: 2.7155447880378323

Epoch: 6| Step: 5
Training loss: 0.6155432516127669
Validation loss: 2.692595287043064

Epoch: 6| Step: 6
Training loss: 0.5499246036262955
Validation loss: 2.7489890494491043

Epoch: 6| Step: 7
Training loss: 0.6390581974919992
Validation loss: 2.7109891683178473

Epoch: 6| Step: 8
Training loss: 0.44267664029239806
Validation loss: 2.7494960091887903

Epoch: 6| Step: 9
Training loss: 0.45553559324804777
Validation loss: 2.720008427312362

Epoch: 6| Step: 10
Training loss: 0.5040796558182707
Validation loss: 2.673366970348483

Epoch: 6| Step: 11
Training loss: 0.5673070124879467
Validation loss: 2.6624154735633634

Epoch: 6| Step: 12
Training loss: 0.3805527063751919
Validation loss: 2.7632000883286105

Epoch: 6| Step: 13
Training loss: 0.4435917585596287
Validation loss: 2.722132000649895

Epoch: 275| Step: 0
Training loss: 0.6711273025100893
Validation loss: 2.7303556201439547

Epoch: 6| Step: 1
Training loss: 0.610521753615609
Validation loss: 2.6781180097918273

Epoch: 6| Step: 2
Training loss: 1.2517671015420524
Validation loss: 2.6195897630633147

Epoch: 6| Step: 3
Training loss: 0.3801959005265258
Validation loss: 2.706837921064781

Epoch: 6| Step: 4
Training loss: 0.5217631876969134
Validation loss: 2.6928270462597697

Epoch: 6| Step: 5
Training loss: 0.7683782702218611
Validation loss: 2.708456863129293

Epoch: 6| Step: 6
Training loss: 0.36324295744530766
Validation loss: 2.7193366108461783

Epoch: 6| Step: 7
Training loss: 0.6966027065702588
Validation loss: 2.7960972192868354

Epoch: 6| Step: 8
Training loss: 0.7652644651454684
Validation loss: 2.7478623173457777

Epoch: 6| Step: 9
Training loss: 0.59351715742473
Validation loss: 2.704375725547623

Epoch: 6| Step: 10
Training loss: 0.5624416109085969
Validation loss: 2.6478987064147645

Epoch: 6| Step: 11
Training loss: 0.5652446542897916
Validation loss: 2.6629323193464076

Epoch: 6| Step: 12
Training loss: 0.5417510174828425
Validation loss: 2.7160655906189097

Epoch: 6| Step: 13
Training loss: 0.424679722437542
Validation loss: 2.651339191361554

Epoch: 276| Step: 0
Training loss: 0.6935611484992589
Validation loss: 2.645606869795333

Epoch: 6| Step: 1
Training loss: 1.0921715381858483
Validation loss: 2.6917458196837667

Epoch: 6| Step: 2
Training loss: 0.8998380276841991
Validation loss: 2.659912501523749

Epoch: 6| Step: 3
Training loss: 0.5733524456923104
Validation loss: 2.741107659228417

Epoch: 6| Step: 4
Training loss: 0.35036676297966013
Validation loss: 2.7176486302040894

Epoch: 6| Step: 5
Training loss: 0.5304039782164908
Validation loss: 2.7707283363430437

Epoch: 6| Step: 6
Training loss: 0.5333896911418032
Validation loss: 2.708418453541748

Epoch: 6| Step: 7
Training loss: 0.595959717566937
Validation loss: 2.746701444163407

Epoch: 6| Step: 8
Training loss: 0.5957650574555355
Validation loss: 2.76276118682142

Epoch: 6| Step: 9
Training loss: 0.6176622230941569
Validation loss: 2.7887163419358063

Epoch: 6| Step: 10
Training loss: 0.5522485491818616
Validation loss: 2.663383792698389

Epoch: 6| Step: 11
Training loss: 0.5586783338409982
Validation loss: 2.7020830854907447

Epoch: 6| Step: 12
Training loss: 0.6252175429353451
Validation loss: 2.689264989481271

Epoch: 6| Step: 13
Training loss: 0.5574524163351434
Validation loss: 2.621698619561313

Epoch: 277| Step: 0
Training loss: 0.5820563394144096
Validation loss: 2.692665591660081

Epoch: 6| Step: 1
Training loss: 1.1913740310064642
Validation loss: 2.7135304153609385

Epoch: 6| Step: 2
Training loss: 0.4372013639551824
Validation loss: 2.652720690962365

Epoch: 6| Step: 3
Training loss: 0.4019216897755913
Validation loss: 2.6481101284790447

Epoch: 6| Step: 4
Training loss: 0.7955197047509085
Validation loss: 2.642829982637646

Epoch: 6| Step: 5
Training loss: 0.5080337922560076
Validation loss: 2.5831772439212872

Epoch: 6| Step: 6
Training loss: 0.35032564451618015
Validation loss: 2.6692578620905616

Epoch: 6| Step: 7
Training loss: 0.7768042527728637
Validation loss: 2.6413980514909112

Epoch: 6| Step: 8
Training loss: 0.4557779522169387
Validation loss: 2.6999729278761366

Epoch: 6| Step: 9
Training loss: 0.46594105561177074
Validation loss: 2.6744455683949324

Epoch: 6| Step: 10
Training loss: 0.6241615393325728
Validation loss: 2.718624360554068

Epoch: 6| Step: 11
Training loss: 0.4655290888887044
Validation loss: 2.793825671645409

Epoch: 6| Step: 12
Training loss: 0.5427452011423382
Validation loss: 2.629544260525257

Epoch: 6| Step: 13
Training loss: 0.664461330248782
Validation loss: 2.719175458919781

Epoch: 278| Step: 0
Training loss: 0.4179677161088082
Validation loss: 2.7791457484733924

Epoch: 6| Step: 1
Training loss: 0.46368629542409107
Validation loss: 2.6260156634469607

Epoch: 6| Step: 2
Training loss: 0.520300790007734
Validation loss: 2.6631771865168403

Epoch: 6| Step: 3
Training loss: 0.4728544781109287
Validation loss: 2.6462550065046235

Epoch: 6| Step: 4
Training loss: 0.41939977080957846
Validation loss: 2.7304976957039364

Epoch: 6| Step: 5
Training loss: 0.4413329544654
Validation loss: 2.7234460897304746

Epoch: 6| Step: 6
Training loss: 0.3273646195525833
Validation loss: 2.594509197487135

Epoch: 6| Step: 7
Training loss: 0.5321578795186156
Validation loss: 2.618859329308572

Epoch: 6| Step: 8
Training loss: 1.1212157073459559
Validation loss: 2.745238111599402

Epoch: 6| Step: 9
Training loss: 0.6272917216425626
Validation loss: 2.6968350740131686

Epoch: 6| Step: 10
Training loss: 0.40332193813042544
Validation loss: 2.6228449619017087

Epoch: 6| Step: 11
Training loss: 0.7807025135487956
Validation loss: 2.6819961286275538

Epoch: 6| Step: 12
Training loss: 0.48819989861862745
Validation loss: 2.7181453544022416

Epoch: 6| Step: 13
Training loss: 0.7123400508636466
Validation loss: 2.672873654295729

Epoch: 279| Step: 0
Training loss: 1.1725094921321595
Validation loss: 2.6694698104508863

Epoch: 6| Step: 1
Training loss: 0.5743995952632668
Validation loss: 2.700533644603823

Epoch: 6| Step: 2
Training loss: 0.6606462454650247
Validation loss: 2.7137950747164266

Epoch: 6| Step: 3
Training loss: 0.5321105270586101
Validation loss: 2.7277822453250113

Epoch: 6| Step: 4
Training loss: 0.7109670947276403
Validation loss: 2.645667278655798

Epoch: 6| Step: 5
Training loss: 0.8391329574128105
Validation loss: 2.7140294013149124

Epoch: 6| Step: 6
Training loss: 0.5119382664075481
Validation loss: 2.714525484965207

Epoch: 6| Step: 7
Training loss: 0.6435461434475865
Validation loss: 2.700241542831997

Epoch: 6| Step: 8
Training loss: 0.43552798927314373
Validation loss: 2.6694751692304957

Epoch: 6| Step: 9
Training loss: 0.50998119020369
Validation loss: 2.6325684235252145

Epoch: 6| Step: 10
Training loss: 0.6417802767891337
Validation loss: 2.6485458246844225

Epoch: 6| Step: 11
Training loss: 0.42690402042607284
Validation loss: 2.6669034976895336

Epoch: 6| Step: 12
Training loss: 0.43644930489548445
Validation loss: 2.649199984607853

Epoch: 6| Step: 13
Training loss: 0.6788621034305057
Validation loss: 2.6493025035737805

Epoch: 280| Step: 0
Training loss: 0.7252452764294824
Validation loss: 2.7438504211540016

Epoch: 6| Step: 1
Training loss: 0.49054829550639345
Validation loss: 2.686870175866269

Epoch: 6| Step: 2
Training loss: 0.5679605402084206
Validation loss: 2.7134363418805667

Epoch: 6| Step: 3
Training loss: 0.54094555122118
Validation loss: 2.6183388829632794

Epoch: 6| Step: 4
Training loss: 0.5264165002374636
Validation loss: 2.6715531480659487

Epoch: 6| Step: 5
Training loss: 0.5104671634944833
Validation loss: 2.6647201874767608

Epoch: 6| Step: 6
Training loss: 0.8295781683142327
Validation loss: 2.6851121511307463

Epoch: 6| Step: 7
Training loss: 0.5751318904710184
Validation loss: 2.5449686072960898

Epoch: 6| Step: 8
Training loss: 0.8524911349218781
Validation loss: 2.6631797006511992

Epoch: 6| Step: 9
Training loss: 1.1842343450682835
Validation loss: 2.5845002389657914

Epoch: 6| Step: 10
Training loss: 0.43388899640076417
Validation loss: 2.6876980316774484

Epoch: 6| Step: 11
Training loss: 0.5067239685448593
Validation loss: 2.6980435895092065

Epoch: 6| Step: 12
Training loss: 0.38224719600509793
Validation loss: 2.6432931500788412

Epoch: 6| Step: 13
Training loss: 0.43913165732271847
Validation loss: 2.69099420900831

Epoch: 281| Step: 0
Training loss: 0.5053787894284983
Validation loss: 2.6972302382254356

Epoch: 6| Step: 1
Training loss: 0.5764204103463081
Validation loss: 2.783255521939167

Epoch: 6| Step: 2
Training loss: 0.5326315362757976
Validation loss: 2.6879510870591234

Epoch: 6| Step: 3
Training loss: 1.1662541693380881
Validation loss: 2.6969849562229515

Epoch: 6| Step: 4
Training loss: 0.44609556448278503
Validation loss: 2.6662891885697513

Epoch: 6| Step: 5
Training loss: 0.8309507921410318
Validation loss: 2.596205847102552

Epoch: 6| Step: 6
Training loss: 0.45058571526530605
Validation loss: 2.5675209059540465

Epoch: 6| Step: 7
Training loss: 0.5067694883207825
Validation loss: 2.5952699642841126

Epoch: 6| Step: 8
Training loss: 0.7415809562177189
Validation loss: 2.6853674034490993

Epoch: 6| Step: 9
Training loss: 0.5069996710819479
Validation loss: 2.6510278417880073

Epoch: 6| Step: 10
Training loss: 0.6362708452928211
Validation loss: 2.6576757008225047

Epoch: 6| Step: 11
Training loss: 0.4400778843482707
Validation loss: 2.6074373432895968

Epoch: 6| Step: 12
Training loss: 0.6015437730128415
Validation loss: 2.6004161122712732

Epoch: 6| Step: 13
Training loss: 0.5764540676303316
Validation loss: 2.6842726025130252

Epoch: 282| Step: 0
Training loss: 0.4871017553349919
Validation loss: 2.6347533787281807

Epoch: 6| Step: 1
Training loss: 0.4704382376656818
Validation loss: 2.6733125236427453

Epoch: 6| Step: 2
Training loss: 0.43046319476799144
Validation loss: 2.607064326199095

Epoch: 6| Step: 3
Training loss: 0.5028464535474627
Validation loss: 2.6595895306383883

Epoch: 6| Step: 4
Training loss: 0.5306131809567335
Validation loss: 2.691248091363178

Epoch: 6| Step: 5
Training loss: 0.587291526329815
Validation loss: 2.6561112760334415

Epoch: 6| Step: 6
Training loss: 1.1175945580776654
Validation loss: 2.7123983662985576

Epoch: 6| Step: 7
Training loss: 0.6840006679857907
Validation loss: 2.654430806137933

Epoch: 6| Step: 8
Training loss: 0.7305923602120624
Validation loss: 2.723061500867192

Epoch: 6| Step: 9
Training loss: 0.5364628732976808
Validation loss: 2.628882655075169

Epoch: 6| Step: 10
Training loss: 0.6768756450111084
Validation loss: 2.6889420566040103

Epoch: 6| Step: 11
Training loss: 0.46210549966407677
Validation loss: 2.651673192396432

Epoch: 6| Step: 12
Training loss: 0.4638656134327734
Validation loss: 2.7373734083473695

Epoch: 6| Step: 13
Training loss: 0.40862378434904467
Validation loss: 2.694366613445947

Epoch: 283| Step: 0
Training loss: 0.663147913602538
Validation loss: 2.696744160813788

Epoch: 6| Step: 1
Training loss: 0.539155371585476
Validation loss: 2.72473115090579

Epoch: 6| Step: 2
Training loss: 0.4518134604425495
Validation loss: 2.631057501461901

Epoch: 6| Step: 3
Training loss: 0.5328419338833202
Validation loss: 2.760516821046007

Epoch: 6| Step: 4
Training loss: 0.4540077850970384
Validation loss: 2.7352842581187424

Epoch: 6| Step: 5
Training loss: 1.1196273091667088
Validation loss: 2.701347258954464

Epoch: 6| Step: 6
Training loss: 0.407293355390295
Validation loss: 2.6521266423295367

Epoch: 6| Step: 7
Training loss: 0.656760357907576
Validation loss: 2.6321390198040437

Epoch: 6| Step: 8
Training loss: 0.6055646512775554
Validation loss: 2.648128870382835

Epoch: 6| Step: 9
Training loss: 0.5807785532070026
Validation loss: 2.661543571664937

Epoch: 6| Step: 10
Training loss: 0.47133239850383646
Validation loss: 2.6804200590035014

Epoch: 6| Step: 11
Training loss: 0.4033169134333917
Validation loss: 2.6778287084923407

Epoch: 6| Step: 12
Training loss: 0.7508864330083688
Validation loss: 2.6980394067914517

Epoch: 6| Step: 13
Training loss: 0.5927521703383518
Validation loss: 2.8294411296235427

Epoch: 284| Step: 0
Training loss: 0.3477843295134195
Validation loss: 2.6140781360317438

Epoch: 6| Step: 1
Training loss: 0.8094314437685596
Validation loss: 2.66117231520518

Epoch: 6| Step: 2
Training loss: 0.4341438000631388
Validation loss: 2.7350611525166633

Epoch: 6| Step: 3
Training loss: 0.5564914436539401
Validation loss: 2.735496683298958

Epoch: 6| Step: 4
Training loss: 0.5920499002635541
Validation loss: 2.7312755784292615

Epoch: 6| Step: 5
Training loss: 0.4599475575179553
Validation loss: 2.752957155709267

Epoch: 6| Step: 6
Training loss: 0.785894170518489
Validation loss: 2.7054740239634576

Epoch: 6| Step: 7
Training loss: 0.4604277297311924
Validation loss: 2.6922393970944896

Epoch: 6| Step: 8
Training loss: 0.5744705426654487
Validation loss: 2.7167714399092806

Epoch: 6| Step: 9
Training loss: 0.651888431472875
Validation loss: 2.72499173306019

Epoch: 6| Step: 10
Training loss: 0.6062543878691458
Validation loss: 2.661276649997451

Epoch: 6| Step: 11
Training loss: 0.39311572411150947
Validation loss: 2.670424046947915

Epoch: 6| Step: 12
Training loss: 0.4765303084960618
Validation loss: 2.712855734988701

Epoch: 6| Step: 13
Training loss: 1.2114724239055823
Validation loss: 2.6600727622757234

Epoch: 285| Step: 0
Training loss: 0.34977039699438994
Validation loss: 2.7016250182449357

Epoch: 6| Step: 1
Training loss: 0.8095325419745695
Validation loss: 2.678927893155788

Epoch: 6| Step: 2
Training loss: 0.5010120758497217
Validation loss: 2.815411212466662

Epoch: 6| Step: 3
Training loss: 1.0119479004563008
Validation loss: 2.7143378282625568

Epoch: 6| Step: 4
Training loss: 0.5373868191012269
Validation loss: 2.8130604362183864

Epoch: 6| Step: 5
Training loss: 0.6764720847523031
Validation loss: 2.639357177833187

Epoch: 6| Step: 6
Training loss: 0.3936465892025724
Validation loss: 2.7403203507102605

Epoch: 6| Step: 7
Training loss: 0.5404132560655691
Validation loss: 2.671214351068089

Epoch: 6| Step: 8
Training loss: 0.5767266140724352
Validation loss: 2.668264764511942

Epoch: 6| Step: 9
Training loss: 0.25959580111884367
Validation loss: 2.7030081751280295

Epoch: 6| Step: 10
Training loss: 0.5745958141228211
Validation loss: 2.6910541453589865

Epoch: 6| Step: 11
Training loss: 0.5165182814506261
Validation loss: 2.7076011597253156

Epoch: 6| Step: 12
Training loss: 0.4154725985655442
Validation loss: 2.6722499145646745

Epoch: 6| Step: 13
Training loss: 0.6701669939655882
Validation loss: 2.6802407630552736

Epoch: 286| Step: 0
Training loss: 0.4910788083450868
Validation loss: 2.7088118252742257

Epoch: 6| Step: 1
Training loss: 0.47578264746750426
Validation loss: 2.6906890134916797

Epoch: 6| Step: 2
Training loss: 0.48228092682856716
Validation loss: 2.7237683017787506

Epoch: 6| Step: 3
Training loss: 1.125364562411083
Validation loss: 2.6844520584432496

Epoch: 6| Step: 4
Training loss: 0.4866715716034263
Validation loss: 2.691733581687523

Epoch: 6| Step: 5
Training loss: 0.7788800341327592
Validation loss: 2.74254421076787

Epoch: 6| Step: 6
Training loss: 0.41962415210000725
Validation loss: 2.6428618427981068

Epoch: 6| Step: 7
Training loss: 0.6233686136607413
Validation loss: 2.717583592453085

Epoch: 6| Step: 8
Training loss: 0.4839969821177731
Validation loss: 2.6725713852239075

Epoch: 6| Step: 9
Training loss: 0.5488215001476828
Validation loss: 2.6883217198530374

Epoch: 6| Step: 10
Training loss: 0.8044167961400553
Validation loss: 2.71504237777112

Epoch: 6| Step: 11
Training loss: 0.7037871104360126
Validation loss: 2.626139756675411

Epoch: 6| Step: 12
Training loss: 0.5127806383610861
Validation loss: 2.616865922140577

Epoch: 6| Step: 13
Training loss: 0.4387095794371402
Validation loss: 2.6574928068994907

Epoch: 287| Step: 0
Training loss: 0.5667542013644467
Validation loss: 2.6104891562741694

Epoch: 6| Step: 1
Training loss: 0.4834759736733643
Validation loss: 2.6903581133193475

Epoch: 6| Step: 2
Training loss: 0.4496452794458305
Validation loss: 2.760288614625855

Epoch: 6| Step: 3
Training loss: 0.5755213799337378
Validation loss: 2.69929063391208

Epoch: 6| Step: 4
Training loss: 0.5663250568994578
Validation loss: 2.7353165522255947

Epoch: 6| Step: 5
Training loss: 0.4828387324296106
Validation loss: 2.6927570336154107

Epoch: 6| Step: 6
Training loss: 0.4747258738011563
Validation loss: 2.698251347544094

Epoch: 6| Step: 7
Training loss: 0.8006460680486343
Validation loss: 2.5819144864596146

Epoch: 6| Step: 8
Training loss: 0.37302542420074186
Validation loss: 2.6957863358926657

Epoch: 6| Step: 9
Training loss: 0.6548832557465111
Validation loss: 2.674642367832919

Epoch: 6| Step: 10
Training loss: 1.0394975712221661
Validation loss: 2.5853573089679456

Epoch: 6| Step: 11
Training loss: 0.35185521973054
Validation loss: 2.669740861897244

Epoch: 6| Step: 12
Training loss: 0.5687748547247872
Validation loss: 2.6824480819773697

Epoch: 6| Step: 13
Training loss: 0.3956058710303859
Validation loss: 2.7237357175655936

Epoch: 288| Step: 0
Training loss: 0.7360545897426822
Validation loss: 2.6569931935328586

Epoch: 6| Step: 1
Training loss: 0.5503447405909261
Validation loss: 2.7291571032135726

Epoch: 6| Step: 2
Training loss: 0.5466675501133983
Validation loss: 2.648096548393822

Epoch: 6| Step: 3
Training loss: 1.0312483816423144
Validation loss: 2.7613646456955285

Epoch: 6| Step: 4
Training loss: 0.4239967467817523
Validation loss: 2.654635084329667

Epoch: 6| Step: 5
Training loss: 0.5664553916923051
Validation loss: 2.6327225908422283

Epoch: 6| Step: 6
Training loss: 0.3994032618174552
Validation loss: 2.632999900238348

Epoch: 6| Step: 7
Training loss: 0.43435878105895537
Validation loss: 2.6776610665149017

Epoch: 6| Step: 8
Training loss: 0.5629342839862911
Validation loss: 2.6052702332934103

Epoch: 6| Step: 9
Training loss: 0.45375663208646627
Validation loss: 2.721258358280334

Epoch: 6| Step: 10
Training loss: 0.532903454308348
Validation loss: 2.6484041014959474

Epoch: 6| Step: 11
Training loss: 0.4757268802539711
Validation loss: 2.7012209498208355

Epoch: 6| Step: 12
Training loss: 0.5769670591950985
Validation loss: 2.641481790982763

Epoch: 6| Step: 13
Training loss: 0.6258197415404444
Validation loss: 2.717318592854046

Epoch: 289| Step: 0
Training loss: 0.6532383569423634
Validation loss: 2.7656071980221326

Epoch: 6| Step: 1
Training loss: 0.4399605936318163
Validation loss: 2.6425920341822984

Epoch: 6| Step: 2
Training loss: 0.47185252559269314
Validation loss: 2.6469397646904578

Epoch: 6| Step: 3
Training loss: 1.1044587282868534
Validation loss: 2.7520454775689864

Epoch: 6| Step: 4
Training loss: 0.48530085584693555
Validation loss: 2.7865681754355296

Epoch: 6| Step: 5
Training loss: 0.5867443886753919
Validation loss: 2.6680755519387893

Epoch: 6| Step: 6
Training loss: 0.5145383134317123
Validation loss: 2.738640312274478

Epoch: 6| Step: 7
Training loss: 0.4551915694524548
Validation loss: 2.7023188099919264

Epoch: 6| Step: 8
Training loss: 0.4247153352621626
Validation loss: 2.6959668088609283

Epoch: 6| Step: 9
Training loss: 0.21507435473522982
Validation loss: 2.6899589556005408

Epoch: 6| Step: 10
Training loss: 0.47559195324737397
Validation loss: 2.6927821126504696

Epoch: 6| Step: 11
Training loss: 0.8894660503133519
Validation loss: 2.770680033714254

Epoch: 6| Step: 12
Training loss: 0.4856061824014996
Validation loss: 2.669434993006919

Epoch: 6| Step: 13
Training loss: 0.46401030892397177
Validation loss: 2.7414594736238675

Epoch: 290| Step: 0
Training loss: 0.49886597241095454
Validation loss: 2.812869478610721

Epoch: 6| Step: 1
Training loss: 0.6228312056316849
Validation loss: 2.6790368241981573

Epoch: 6| Step: 2
Training loss: 0.44119878974257454
Validation loss: 2.733337307167266

Epoch: 6| Step: 3
Training loss: 0.5100102623206204
Validation loss: 2.6691843803485726

Epoch: 6| Step: 4
Training loss: 0.40278852748045474
Validation loss: 2.6873447905677685

Epoch: 6| Step: 5
Training loss: 0.5640635218307243
Validation loss: 2.734663753703572

Epoch: 6| Step: 6
Training loss: 0.3803025699344079
Validation loss: 2.673563626240626

Epoch: 6| Step: 7
Training loss: 0.5480336585323929
Validation loss: 2.6998534792715527

Epoch: 6| Step: 8
Training loss: 0.663808212960338
Validation loss: 2.6877075677010205

Epoch: 6| Step: 9
Training loss: 0.4386455150915021
Validation loss: 2.6545939051231437

Epoch: 6| Step: 10
Training loss: 0.5820029847111151
Validation loss: 2.6563868618281865

Epoch: 6| Step: 11
Training loss: 1.0859708163413082
Validation loss: 2.6833702708796006

Epoch: 6| Step: 12
Training loss: 0.5382243288281826
Validation loss: 2.7187284563752963

Epoch: 6| Step: 13
Training loss: 0.8395549898750945
Validation loss: 2.689677103320271

Epoch: 291| Step: 0
Training loss: 0.4139196401340401
Validation loss: 2.690952050465005

Epoch: 6| Step: 1
Training loss: 0.6275236202065096
Validation loss: 2.685990419693121

Epoch: 6| Step: 2
Training loss: 0.3881099799070962
Validation loss: 2.769892085735632

Epoch: 6| Step: 3
Training loss: 0.5924666740606062
Validation loss: 2.738868973186511

Epoch: 6| Step: 4
Training loss: 0.5056766489288804
Validation loss: 2.6594472081160485

Epoch: 6| Step: 5
Training loss: 0.5042933670028308
Validation loss: 2.6429964511196573

Epoch: 6| Step: 6
Training loss: 0.6110461379922792
Validation loss: 2.721623885859382

Epoch: 6| Step: 7
Training loss: 0.3881639583587891
Validation loss: 2.723674669442212

Epoch: 6| Step: 8
Training loss: 0.5884231993912225
Validation loss: 2.6883379790456527

Epoch: 6| Step: 9
Training loss: 0.5609508746579559
Validation loss: 2.734619289566543

Epoch: 6| Step: 10
Training loss: 0.5837423275886509
Validation loss: 2.7998564331396425

Epoch: 6| Step: 11
Training loss: 1.1617015988713502
Validation loss: 2.676699040558768

Epoch: 6| Step: 12
Training loss: 0.49056585283381476
Validation loss: 2.731361399691273

Epoch: 6| Step: 13
Training loss: 0.46195225628300696
Validation loss: 2.6202597885577443

Epoch: 292| Step: 0
Training loss: 0.435379937172692
Validation loss: 2.665084866430313

Epoch: 6| Step: 1
Training loss: 0.5419515783544399
Validation loss: 2.6800239359204285

Epoch: 6| Step: 2
Training loss: 0.5761880904679936
Validation loss: 2.6468721413024574

Epoch: 6| Step: 3
Training loss: 0.48150560106008516
Validation loss: 2.7180718420202736

Epoch: 6| Step: 4
Training loss: 0.4314849365606458
Validation loss: 2.6625106035239297

Epoch: 6| Step: 5
Training loss: 1.049922549706444
Validation loss: 2.611675504690998

Epoch: 6| Step: 6
Training loss: 0.7625825337002224
Validation loss: 2.6202545490199323

Epoch: 6| Step: 7
Training loss: 0.347642201772023
Validation loss: 2.79916386211134

Epoch: 6| Step: 8
Training loss: 0.7327188525521751
Validation loss: 2.692238998584726

Epoch: 6| Step: 9
Training loss: 0.5708185328585907
Validation loss: 2.6542213621946527

Epoch: 6| Step: 10
Training loss: 0.3905523423332814
Validation loss: 2.6836116666163345

Epoch: 6| Step: 11
Training loss: 0.3736883510025474
Validation loss: 2.6731675797095487

Epoch: 6| Step: 12
Training loss: 0.6337685603747687
Validation loss: 2.76637889263563

Epoch: 6| Step: 13
Training loss: 0.5492789700785203
Validation loss: 2.8168934450518286

Epoch: 293| Step: 0
Training loss: 0.3697827924639646
Validation loss: 2.6596308864872538

Epoch: 6| Step: 1
Training loss: 0.5879743649480473
Validation loss: 2.688103511972464

Epoch: 6| Step: 2
Training loss: 0.3685989037994709
Validation loss: 2.62215210060699

Epoch: 6| Step: 3
Training loss: 0.7501523340016139
Validation loss: 2.698105843489035

Epoch: 6| Step: 4
Training loss: 0.5696987873744128
Validation loss: 2.665074205755103

Epoch: 6| Step: 5
Training loss: 0.47589962618861836
Validation loss: 2.6478258024803214

Epoch: 6| Step: 6
Training loss: 0.5239981879465061
Validation loss: 2.611327265242609

Epoch: 6| Step: 7
Training loss: 0.44345629468771414
Validation loss: 2.652646241802162

Epoch: 6| Step: 8
Training loss: 0.3919024369948828
Validation loss: 2.6532774205602614

Epoch: 6| Step: 9
Training loss: 0.4598717410673824
Validation loss: 2.6727077680995484

Epoch: 6| Step: 10
Training loss: 1.0088389883768862
Validation loss: 2.718873821376671

Epoch: 6| Step: 11
Training loss: 0.41631005841936447
Validation loss: 2.7040759345195218

Epoch: 6| Step: 12
Training loss: 0.30467537097753383
Validation loss: 2.6206049835316456

Epoch: 6| Step: 13
Training loss: 0.3788001905051581
Validation loss: 2.6417881738133144

Epoch: 294| Step: 0
Training loss: 0.5991052751388171
Validation loss: 2.576661204924065

Epoch: 6| Step: 1
Training loss: 0.8016798978204056
Validation loss: 2.729336396003959

Epoch: 6| Step: 2
Training loss: 0.4842200800584151
Validation loss: 2.705250295950832

Epoch: 6| Step: 3
Training loss: 0.5066919434614797
Validation loss: 2.6878570496887977

Epoch: 6| Step: 4
Training loss: 1.1073361318182755
Validation loss: 2.6569489999206843

Epoch: 6| Step: 5
Training loss: 0.5281364134960326
Validation loss: 2.734094834279838

Epoch: 6| Step: 6
Training loss: 0.4660312007273999
Validation loss: 2.7294872959482106

Epoch: 6| Step: 7
Training loss: 0.45014496561065853
Validation loss: 2.681514047041863

Epoch: 6| Step: 8
Training loss: 0.4158409719141449
Validation loss: 2.6955583248358317

Epoch: 6| Step: 9
Training loss: 0.43309820915253555
Validation loss: 2.725420620737579

Epoch: 6| Step: 10
Training loss: 0.7100263352949938
Validation loss: 2.8307218905404823

Epoch: 6| Step: 11
Training loss: 0.8768594602593193
Validation loss: 2.70623738298419

Epoch: 6| Step: 12
Training loss: 0.557413200840227
Validation loss: 2.750688235541188

Epoch: 6| Step: 13
Training loss: 0.5977303951371751
Validation loss: 2.7682586170734083

Epoch: 295| Step: 0
Training loss: 0.5881090740516359
Validation loss: 2.757590842412173

Epoch: 6| Step: 1
Training loss: 0.3637645337062334
Validation loss: 2.6928294072825456

Epoch: 6| Step: 2
Training loss: 0.6433387590914135
Validation loss: 2.6547860692887815

Epoch: 6| Step: 3
Training loss: 0.4475042048315342
Validation loss: 2.677438917677276

Epoch: 6| Step: 4
Training loss: 0.5159466058400034
Validation loss: 2.7214034056277683

Epoch: 6| Step: 5
Training loss: 0.5730367419095198
Validation loss: 2.710238994274719

Epoch: 6| Step: 6
Training loss: 0.4882225001277247
Validation loss: 2.705551087751971

Epoch: 6| Step: 7
Training loss: 0.6220045788587217
Validation loss: 2.78266829142533

Epoch: 6| Step: 8
Training loss: 0.8085403056150869
Validation loss: 2.747451453828587

Epoch: 6| Step: 9
Training loss: 0.4258134812220975
Validation loss: 2.6904054210235415

Epoch: 6| Step: 10
Training loss: 0.39515572405712623
Validation loss: 2.6619958253947638

Epoch: 6| Step: 11
Training loss: 0.4050847361070214
Validation loss: 2.7082128546889535

Epoch: 6| Step: 12
Training loss: 1.053612450777809
Validation loss: 2.699655676891628

Epoch: 6| Step: 13
Training loss: 0.40804338752064034
Validation loss: 2.75156137183717

Epoch: 296| Step: 0
Training loss: 0.49125706056078156
Validation loss: 2.669898032337991

Epoch: 6| Step: 1
Training loss: 0.4320952149096869
Validation loss: 2.6999479818631404

Epoch: 6| Step: 2
Training loss: 0.4460790962444636
Validation loss: 2.736427016720997

Epoch: 6| Step: 3
Training loss: 0.5741892177746681
Validation loss: 2.759848069464384

Epoch: 6| Step: 4
Training loss: 0.5001663288982657
Validation loss: 2.6436025471671245

Epoch: 6| Step: 5
Training loss: 1.144548539691827
Validation loss: 2.7714575635613654

Epoch: 6| Step: 6
Training loss: 0.6096541425611924
Validation loss: 2.7072586984206093

Epoch: 6| Step: 7
Training loss: 0.6714659931891268
Validation loss: 2.7731946525455413

Epoch: 6| Step: 8
Training loss: 0.5524311649370566
Validation loss: 2.6445146989327935

Epoch: 6| Step: 9
Training loss: 0.4060964294086875
Validation loss: 2.7412386825891493

Epoch: 6| Step: 10
Training loss: 0.3722566753644603
Validation loss: 2.6601889632085927

Epoch: 6| Step: 11
Training loss: 0.45343789445687716
Validation loss: 2.6780561517674055

Epoch: 6| Step: 12
Training loss: 0.27640324279891676
Validation loss: 2.6761927378772112

Epoch: 6| Step: 13
Training loss: 0.8218466808241159
Validation loss: 2.746922707459834

Epoch: 297| Step: 0
Training loss: 0.45104835107385866
Validation loss: 2.756906362335145

Epoch: 6| Step: 1
Training loss: 0.8035409406903163
Validation loss: 2.771286810190408

Epoch: 6| Step: 2
Training loss: 0.5606536763489733
Validation loss: 2.6982711107487396

Epoch: 6| Step: 3
Training loss: 0.5286470485228555
Validation loss: 2.8074907198079133

Epoch: 6| Step: 4
Training loss: 1.0468994820991684
Validation loss: 2.7369732238143634

Epoch: 6| Step: 5
Training loss: 0.5576467155481583
Validation loss: 2.7332522457779658

Epoch: 6| Step: 6
Training loss: 0.6028491540723644
Validation loss: 2.7215325742705625

Epoch: 6| Step: 7
Training loss: 0.5016582825373047
Validation loss: 2.6442190988100824

Epoch: 6| Step: 8
Training loss: 0.42069634278904167
Validation loss: 2.662452755838714

Epoch: 6| Step: 9
Training loss: 0.4562929825589485
Validation loss: 2.6770446616223342

Epoch: 6| Step: 10
Training loss: 0.4615302396540199
Validation loss: 2.714054173976709

Epoch: 6| Step: 11
Training loss: 0.5089956731706041
Validation loss: 2.77897834158821

Epoch: 6| Step: 12
Training loss: 0.6259336174146017
Validation loss: 2.6724808212462814

Epoch: 6| Step: 13
Training loss: 0.3833394219426352
Validation loss: 2.6567101397920094

Epoch: 298| Step: 0
Training loss: 0.39708196770205373
Validation loss: 2.698077654852842

Epoch: 6| Step: 1
Training loss: 0.726443660410314
Validation loss: 2.7290690067280234

Epoch: 6| Step: 2
Training loss: 0.4326081630204689
Validation loss: 2.669316142868432

Epoch: 6| Step: 3
Training loss: 0.47615430891824656
Validation loss: 2.715925408279621

Epoch: 6| Step: 4
Training loss: 0.5486173937903237
Validation loss: 2.7342403996354188

Epoch: 6| Step: 5
Training loss: 0.40671278197005595
Validation loss: 2.729448847463569

Epoch: 6| Step: 6
Training loss: 0.5271376878307353
Validation loss: 2.6992478320795037

Epoch: 6| Step: 7
Training loss: 0.6189051038755048
Validation loss: 2.7572669623439996

Epoch: 6| Step: 8
Training loss: 0.9846061556239148
Validation loss: 2.767635412168431

Epoch: 6| Step: 9
Training loss: 0.5066264460100893
Validation loss: 2.7568100502275237

Epoch: 6| Step: 10
Training loss: 0.34290453585578057
Validation loss: 2.6856552712499107

Epoch: 6| Step: 11
Training loss: 0.5949679231011298
Validation loss: 2.6660596534158225

Epoch: 6| Step: 12
Training loss: 0.4704957560652897
Validation loss: 2.708607737994066

Epoch: 6| Step: 13
Training loss: 0.42717148483606265
Validation loss: 2.717355984624125

Epoch: 299| Step: 0
Training loss: 0.4794587164421183
Validation loss: 2.7028770406550926

Epoch: 6| Step: 1
Training loss: 0.45569300553497943
Validation loss: 2.701873173380321

Epoch: 6| Step: 2
Training loss: 0.3999600584234902
Validation loss: 2.663606740797864

Epoch: 6| Step: 3
Training loss: 0.4204940269184331
Validation loss: 2.694798266610782

Epoch: 6| Step: 4
Training loss: 0.9914192168798388
Validation loss: 2.7336814945511723

Epoch: 6| Step: 5
Training loss: 0.6497995250830495
Validation loss: 2.7178319352918474

Epoch: 6| Step: 6
Training loss: 0.3200665902351469
Validation loss: 2.699079525600788

Epoch: 6| Step: 7
Training loss: 0.43504288941541475
Validation loss: 2.7150519202029235

Epoch: 6| Step: 8
Training loss: 0.3283154071393756
Validation loss: 2.781067802947835

Epoch: 6| Step: 9
Training loss: 0.5034546417879314
Validation loss: 2.750324114570645

Epoch: 6| Step: 10
Training loss: 0.8173618838093131
Validation loss: 2.7429342819854314

Epoch: 6| Step: 11
Training loss: 0.47894426726994194
Validation loss: 2.7197250284022827

Epoch: 6| Step: 12
Training loss: 0.4460009890981578
Validation loss: 2.7150008268220414

Epoch: 6| Step: 13
Training loss: 0.6343088707492588
Validation loss: 2.7322209474983703

Epoch: 300| Step: 0
Training loss: 0.323556637590577
Validation loss: 2.7674811792006495

Epoch: 6| Step: 1
Training loss: 0.5406180618370131
Validation loss: 2.6683443772204383

Epoch: 6| Step: 2
Training loss: 0.5158256371601359
Validation loss: 2.7304483175536474

Epoch: 6| Step: 3
Training loss: 0.6263205643833121
Validation loss: 2.663428580745742

Epoch: 6| Step: 4
Training loss: 0.4378377087869015
Validation loss: 2.7127946104741425

Epoch: 6| Step: 5
Training loss: 1.083597860074104
Validation loss: 2.702508756921574

Epoch: 6| Step: 6
Training loss: 0.39785761802832814
Validation loss: 2.730726194455886

Epoch: 6| Step: 7
Training loss: 0.3796417334331938
Validation loss: 2.7131430735261066

Epoch: 6| Step: 8
Training loss: 0.46105683931648317
Validation loss: 2.75009403645965

Epoch: 6| Step: 9
Training loss: 0.4852699809905897
Validation loss: 2.749897593701137

Epoch: 6| Step: 10
Training loss: 0.557128665532855
Validation loss: 2.8025754522442847

Epoch: 6| Step: 11
Training loss: 0.5327980263273954
Validation loss: 2.771894586344104

Epoch: 6| Step: 12
Training loss: 0.30337690033099396
Validation loss: 2.7132614830667108

Epoch: 6| Step: 13
Training loss: 0.4009565680080891
Validation loss: 2.746425444031721

Epoch: 301| Step: 0
Training loss: 0.5722997349282704
Validation loss: 2.7409758467567467

Epoch: 6| Step: 1
Training loss: 0.5634685760408076
Validation loss: 2.7358401632867624

Epoch: 6| Step: 2
Training loss: 0.41474600824041274
Validation loss: 2.744946301113948

Epoch: 6| Step: 3
Training loss: 0.5291092599933367
Validation loss: 2.680572111663904

Epoch: 6| Step: 4
Training loss: 0.5247318150503004
Validation loss: 2.666451316323744

Epoch: 6| Step: 5
Training loss: 0.38888325526304646
Validation loss: 2.741377679228961

Epoch: 6| Step: 6
Training loss: 0.3245592741972142
Validation loss: 2.7575171927604636

Epoch: 6| Step: 7
Training loss: 0.5487799029360086
Validation loss: 2.7824131680010096

Epoch: 6| Step: 8
Training loss: 0.4530350497183078
Validation loss: 2.6897672951268103

Epoch: 6| Step: 9
Training loss: 0.6870498050199432
Validation loss: 2.7718310651196654

Epoch: 6| Step: 10
Training loss: 0.668609913744046
Validation loss: 2.7081172539026284

Epoch: 6| Step: 11
Training loss: 0.5923585649678869
Validation loss: 2.762257193917452

Epoch: 6| Step: 12
Training loss: 0.3185027799994024
Validation loss: 2.706552291561346

Epoch: 6| Step: 13
Training loss: 0.9063772572584116
Validation loss: 2.6702240868446703

Epoch: 302| Step: 0
Training loss: 0.40573066748691217
Validation loss: 2.76456807661027

Epoch: 6| Step: 1
Training loss: 0.6393001860535529
Validation loss: 2.7034083605592123

Epoch: 6| Step: 2
Training loss: 0.4956269658880703
Validation loss: 2.677450686729936

Epoch: 6| Step: 3
Training loss: 0.8984576015711503
Validation loss: 2.6883472615224315

Epoch: 6| Step: 4
Training loss: 0.6345556293267006
Validation loss: 2.7586311371649295

Epoch: 6| Step: 5
Training loss: 0.46435729787568575
Validation loss: 2.733439214524241

Epoch: 6| Step: 6
Training loss: 0.38636351173572264
Validation loss: 2.761016252765764

Epoch: 6| Step: 7
Training loss: 0.6808293058547852
Validation loss: 2.746205934898241

Epoch: 6| Step: 8
Training loss: 0.5429249478243119
Validation loss: 2.6541637530428126

Epoch: 6| Step: 9
Training loss: 0.6026883921756567
Validation loss: 2.698750581822252

Epoch: 6| Step: 10
Training loss: 0.4725183490692186
Validation loss: 2.6238183889188997

Epoch: 6| Step: 11
Training loss: 0.5595466915024963
Validation loss: 2.7611372720880656

Epoch: 6| Step: 12
Training loss: 0.42894347538288463
Validation loss: 2.678232953014998

Epoch: 6| Step: 13
Training loss: 0.5486085934587914
Validation loss: 2.604974984923254

Epoch: 303| Step: 0
Training loss: 0.5303264612485521
Validation loss: 2.7177403062250973

Epoch: 6| Step: 1
Training loss: 0.4397172939180729
Validation loss: 2.81199286798393

Epoch: 6| Step: 2
Training loss: 0.4000836940467912
Validation loss: 2.6446145071337264

Epoch: 6| Step: 3
Training loss: 0.37830493838651286
Validation loss: 2.6221021975870156

Epoch: 6| Step: 4
Training loss: 0.5059793396320404
Validation loss: 2.7762285542994474

Epoch: 6| Step: 5
Training loss: 0.5386141695645416
Validation loss: 2.6940377210828523

Epoch: 6| Step: 6
Training loss: 0.8291101533873787
Validation loss: 2.682623201392892

Epoch: 6| Step: 7
Training loss: 0.5374559983273905
Validation loss: 2.6900541750807143

Epoch: 6| Step: 8
Training loss: 0.415633119776293
Validation loss: 2.6721232040557936

Epoch: 6| Step: 9
Training loss: 0.3417670863658381
Validation loss: 2.7237471917464573

Epoch: 6| Step: 10
Training loss: 0.5454779901216346
Validation loss: 2.7263106964924604

Epoch: 6| Step: 11
Training loss: 1.0457421051500717
Validation loss: 2.7479059453894386

Epoch: 6| Step: 12
Training loss: 0.3528370852389543
Validation loss: 2.7446990362434023

Epoch: 6| Step: 13
Training loss: 0.3545200977950342
Validation loss: 2.7266968090129216

Epoch: 304| Step: 0
Training loss: 0.5523812611750114
Validation loss: 2.712672635633505

Epoch: 6| Step: 1
Training loss: 0.4267647085789273
Validation loss: 2.7613219210328848

Epoch: 6| Step: 2
Training loss: 0.48558210888030606
Validation loss: 2.6872026737366017

Epoch: 6| Step: 3
Training loss: 0.5538277746654968
Validation loss: 2.6946539991259724

Epoch: 6| Step: 4
Training loss: 0.4168400185304544
Validation loss: 2.698407092987956

Epoch: 6| Step: 5
Training loss: 0.9401859906516741
Validation loss: 2.6513427583378104

Epoch: 6| Step: 6
Training loss: 0.5198950963393119
Validation loss: 2.722235903954238

Epoch: 6| Step: 7
Training loss: 0.5810023949437507
Validation loss: 2.686525848435661

Epoch: 6| Step: 8
Training loss: 0.4719079138790439
Validation loss: 2.711330007964547

Epoch: 6| Step: 9
Training loss: 0.6706418319893571
Validation loss: 2.644803129464052

Epoch: 6| Step: 10
Training loss: 0.37269875625892074
Validation loss: 2.6738090579474854

Epoch: 6| Step: 11
Training loss: 0.26500111127566406
Validation loss: 2.750207170716851

Epoch: 6| Step: 12
Training loss: 0.5402772181714235
Validation loss: 2.6697251294601725

Epoch: 6| Step: 13
Training loss: 0.6085461824409109
Validation loss: 2.683931154587598

Epoch: 305| Step: 0
Training loss: 0.37890853094613874
Validation loss: 2.741884002844676

Epoch: 6| Step: 1
Training loss: 0.38274464687089776
Validation loss: 2.8069050699029234

Epoch: 6| Step: 2
Training loss: 0.5189592467975987
Validation loss: 2.7365473374228437

Epoch: 6| Step: 3
Training loss: 0.4543928299229883
Validation loss: 2.7439887786520867

Epoch: 6| Step: 4
Training loss: 0.6137121351258423
Validation loss: 2.7301218870338593

Epoch: 6| Step: 5
Training loss: 0.5280143994423333
Validation loss: 2.808199795190225

Epoch: 6| Step: 6
Training loss: 0.5452904224025455
Validation loss: 2.7270787214022096

Epoch: 6| Step: 7
Training loss: 0.599871823408361
Validation loss: 2.7466897258978826

Epoch: 6| Step: 8
Training loss: 0.3529799602361308
Validation loss: 2.7430027024425807

Epoch: 6| Step: 9
Training loss: 0.4397770514319314
Validation loss: 2.7327246926481488

Epoch: 6| Step: 10
Training loss: 0.7953896235935647
Validation loss: 2.700347862970076

Epoch: 6| Step: 11
Training loss: 0.9206973166721554
Validation loss: 2.6678835109128163

Epoch: 6| Step: 12
Training loss: 0.3809973246825899
Validation loss: 2.698990896409615

Epoch: 6| Step: 13
Training loss: 0.46057026992147215
Validation loss: 2.7850021169849617

Epoch: 306| Step: 0
Training loss: 0.6171583096325313
Validation loss: 2.6431292936251563

Epoch: 6| Step: 1
Training loss: 0.5596003765664596
Validation loss: 2.784195786519572

Epoch: 6| Step: 2
Training loss: 0.34677140003332596
Validation loss: 2.7115424632736453

Epoch: 6| Step: 3
Training loss: 0.40946269661208406
Validation loss: 2.7185165918940872

Epoch: 6| Step: 4
Training loss: 0.688110470666041
Validation loss: 2.676856232941844

Epoch: 6| Step: 5
Training loss: 0.4460625939921638
Validation loss: 2.6350441369082587

Epoch: 6| Step: 6
Training loss: 0.38949337122887173
Validation loss: 2.6569252577019835

Epoch: 6| Step: 7
Training loss: 0.4481394864112396
Validation loss: 2.7612997022202

Epoch: 6| Step: 8
Training loss: 0.49810590207237715
Validation loss: 2.782713572853317

Epoch: 6| Step: 9
Training loss: 1.09396768855929
Validation loss: 2.734916197488425

Epoch: 6| Step: 10
Training loss: 0.4153967180248234
Validation loss: 2.6782037540164016

Epoch: 6| Step: 11
Training loss: 0.3829561859149234
Validation loss: 2.548260395843329

Epoch: 6| Step: 12
Training loss: 0.538040851566502
Validation loss: 2.7032963398927743

Epoch: 6| Step: 13
Training loss: 0.36818591794172856
Validation loss: 2.67218261197245

Epoch: 307| Step: 0
Training loss: 0.6068116830546649
Validation loss: 2.7543452929706813

Epoch: 6| Step: 1
Training loss: 0.45738794801998733
Validation loss: 2.699154975899557

Epoch: 6| Step: 2
Training loss: 0.39613313573160724
Validation loss: 2.649460796464741

Epoch: 6| Step: 3
Training loss: 0.4428141766599196
Validation loss: 2.747495825998354

Epoch: 6| Step: 4
Training loss: 0.3597703500576147
Validation loss: 2.6842336544176213

Epoch: 6| Step: 5
Training loss: 0.4912923059131233
Validation loss: 2.6455064756893

Epoch: 6| Step: 6
Training loss: 0.5029237617217645
Validation loss: 2.656570893894288

Epoch: 6| Step: 7
Training loss: 1.134080374632821
Validation loss: 2.734699353553581

Epoch: 6| Step: 8
Training loss: 0.4978099034846923
Validation loss: 2.7385043979767563

Epoch: 6| Step: 9
Training loss: 0.47718901178686346
Validation loss: 2.756304032076544

Epoch: 6| Step: 10
Training loss: 0.5233549366073904
Validation loss: 2.633774578774599

Epoch: 6| Step: 11
Training loss: 0.6006135763616186
Validation loss: 2.710490223743865

Epoch: 6| Step: 12
Training loss: 0.5665919032517803
Validation loss: 2.7399516903546854

Epoch: 6| Step: 13
Training loss: 0.5743246434981061
Validation loss: 2.728066467729266

Epoch: 308| Step: 0
Training loss: 0.5343343172704847
Validation loss: 2.728092380137858

Epoch: 6| Step: 1
Training loss: 0.707331009015475
Validation loss: 2.8335601608323144

Epoch: 6| Step: 2
Training loss: 0.45285025850541144
Validation loss: 2.7013049163014062

Epoch: 6| Step: 3
Training loss: 0.48697865498017817
Validation loss: 2.7567361490871405

Epoch: 6| Step: 4
Training loss: 0.5673452814659854
Validation loss: 2.743809769891093

Epoch: 6| Step: 5
Training loss: 0.28096364596591794
Validation loss: 2.701564595692522

Epoch: 6| Step: 6
Training loss: 0.604134547815819
Validation loss: 2.7228784894613978

Epoch: 6| Step: 7
Training loss: 0.36505544838987375
Validation loss: 2.709616977983926

Epoch: 6| Step: 8
Training loss: 1.0721710663672634
Validation loss: 2.6159647955970624

Epoch: 6| Step: 9
Training loss: 0.46516537158596255
Validation loss: 2.706177753544263

Epoch: 6| Step: 10
Training loss: 0.40439029664671533
Validation loss: 2.728263084176805

Epoch: 6| Step: 11
Training loss: 0.4141289279842422
Validation loss: 2.6983537111304177

Epoch: 6| Step: 12
Training loss: 0.6969128525721681
Validation loss: 2.747431646659013

Epoch: 6| Step: 13
Training loss: 0.5576869566873197
Validation loss: 2.782020119331716

Epoch: 309| Step: 0
Training loss: 0.6881478031964041
Validation loss: 2.7289163508657386

Epoch: 6| Step: 1
Training loss: 0.42562382088720535
Validation loss: 2.6788540833308256

Epoch: 6| Step: 2
Training loss: 0.47490991880135963
Validation loss: 2.717939906539715

Epoch: 6| Step: 3
Training loss: 0.34612098052837864
Validation loss: 2.6622653242870142

Epoch: 6| Step: 4
Training loss: 0.412071660200796
Validation loss: 2.6404364178074164

Epoch: 6| Step: 5
Training loss: 0.5525713029653638
Validation loss: 2.719798693336771

Epoch: 6| Step: 6
Training loss: 0.3773209748591974
Validation loss: 2.6864330776211243

Epoch: 6| Step: 7
Training loss: 0.3960484330176046
Validation loss: 2.7024851355907

Epoch: 6| Step: 8
Training loss: 0.3820206373491977
Validation loss: 2.7650943972688706

Epoch: 6| Step: 9
Training loss: 0.2789531273008268
Validation loss: 2.6928318273287433

Epoch: 6| Step: 10
Training loss: 0.9285831142832549
Validation loss: 2.7102007565619823

Epoch: 6| Step: 11
Training loss: 0.36857937728589535
Validation loss: 2.6617248959064956

Epoch: 6| Step: 12
Training loss: 0.478824126777257
Validation loss: 2.7011468665049527

Epoch: 6| Step: 13
Training loss: 0.7850183773926813
Validation loss: 2.691982405088758

Epoch: 310| Step: 0
Training loss: 0.3603489986835032
Validation loss: 2.718021236686651

Epoch: 6| Step: 1
Training loss: 0.6094221439220628
Validation loss: 2.7380165773943634

Epoch: 6| Step: 2
Training loss: 0.4781153347559364
Validation loss: 2.689548894266257

Epoch: 6| Step: 3
Training loss: 0.44667373873440275
Validation loss: 2.74219186172066

Epoch: 6| Step: 4
Training loss: 0.6731580858236991
Validation loss: 2.713727660342702

Epoch: 6| Step: 5
Training loss: 0.43398337857658204
Validation loss: 2.7269805033981998

Epoch: 6| Step: 6
Training loss: 0.4004374406938671
Validation loss: 2.691328412071392

Epoch: 6| Step: 7
Training loss: 1.1733654970308687
Validation loss: 2.7189247835181387

Epoch: 6| Step: 8
Training loss: 0.38234655088483016
Validation loss: 2.6833233722557166

Epoch: 6| Step: 9
Training loss: 0.44787652552922713
Validation loss: 2.7197885831544877

Epoch: 6| Step: 10
Training loss: 0.5459115124059623
Validation loss: 2.6930698666108435

Epoch: 6| Step: 11
Training loss: 0.6507739979132663
Validation loss: 2.7388201957283393

Epoch: 6| Step: 12
Training loss: 0.37905275324455706
Validation loss: 2.6289546484079604

Epoch: 6| Step: 13
Training loss: 0.25540983588173877
Validation loss: 2.685750998397784

Epoch: 311| Step: 0
Training loss: 0.6511425677628365
Validation loss: 2.705167803327917

Epoch: 6| Step: 1
Training loss: 0.9591114402855526
Validation loss: 2.7433463869290287

Epoch: 6| Step: 2
Training loss: 0.4294398894828549
Validation loss: 2.7037218497038484

Epoch: 6| Step: 3
Training loss: 0.7138812145937199
Validation loss: 2.7229056624929817

Epoch: 6| Step: 4
Training loss: 0.44163682704866813
Validation loss: 2.6449083428465583

Epoch: 6| Step: 5
Training loss: 0.47584589251274345
Validation loss: 2.6626772145498703

Epoch: 6| Step: 6
Training loss: 0.2518366611021216
Validation loss: 2.7250677418235987

Epoch: 6| Step: 7
Training loss: 0.4669381570291881
Validation loss: 2.716059263074395

Epoch: 6| Step: 8
Training loss: 0.4498730579778416
Validation loss: 2.7433535206130393

Epoch: 6| Step: 9
Training loss: 0.538088928325116
Validation loss: 2.7447854077571225

Epoch: 6| Step: 10
Training loss: 0.28453338215849716
Validation loss: 2.6876408000406093

Epoch: 6| Step: 11
Training loss: 0.4044946748739009
Validation loss: 2.7491018822760847

Epoch: 6| Step: 12
Training loss: 0.38620407843824167
Validation loss: 2.7528659451870174

Epoch: 6| Step: 13
Training loss: 0.4760181570056194
Validation loss: 2.6994971036575754

Epoch: 312| Step: 0
Training loss: 0.4191426699287181
Validation loss: 2.715356938367304

Epoch: 6| Step: 1
Training loss: 0.491709810387219
Validation loss: 2.7141628957629886

Epoch: 6| Step: 2
Training loss: 0.648052422957905
Validation loss: 2.6443375441860977

Epoch: 6| Step: 3
Training loss: 0.6758094737603334
Validation loss: 2.7353770499884535

Epoch: 6| Step: 4
Training loss: 0.4344764179419294
Validation loss: 2.710758624739452

Epoch: 6| Step: 5
Training loss: 0.9055053677202327
Validation loss: 2.7250849556001815

Epoch: 6| Step: 6
Training loss: 0.4297885775890399
Validation loss: 2.774505416796542

Epoch: 6| Step: 7
Training loss: 0.4041597806534017
Validation loss: 2.6881778512758654

Epoch: 6| Step: 8
Training loss: 0.44250094287039093
Validation loss: 2.6807156769184757

Epoch: 6| Step: 9
Training loss: 0.44189925217609444
Validation loss: 2.6922849153770887

Epoch: 6| Step: 10
Training loss: 0.4805172376279707
Validation loss: 2.718946106367587

Epoch: 6| Step: 11
Training loss: 0.46789974347075125
Validation loss: 2.7824963266691745

Epoch: 6| Step: 12
Training loss: 0.4933954734613552
Validation loss: 2.7017478595404065

Epoch: 6| Step: 13
Training loss: 0.4403384636506223
Validation loss: 2.6744330580815485

Epoch: 313| Step: 0
Training loss: 0.5111415898724977
Validation loss: 2.7647292559781125

Epoch: 6| Step: 1
Training loss: 0.712664257323234
Validation loss: 2.7224689931887385

Epoch: 6| Step: 2
Training loss: 0.47508793318111436
Validation loss: 2.7158457418671182

Epoch: 6| Step: 3
Training loss: 0.41279967288837854
Validation loss: 2.6739528971489124

Epoch: 6| Step: 4
Training loss: 0.49809957487248624
Validation loss: 2.759743206475756

Epoch: 6| Step: 5
Training loss: 0.4876118152716378
Validation loss: 2.608885149937726

Epoch: 6| Step: 6
Training loss: 0.4686259582430367
Validation loss: 2.7183703745788317

Epoch: 6| Step: 7
Training loss: 0.38119001463839186
Validation loss: 2.6375846590071705

Epoch: 6| Step: 8
Training loss: 0.40980289315207297
Validation loss: 2.6804018542070556

Epoch: 6| Step: 9
Training loss: 0.9263473582613632
Validation loss: 2.7674825145257502

Epoch: 6| Step: 10
Training loss: 0.5542798223150728
Validation loss: 2.876406339474463

Epoch: 6| Step: 11
Training loss: 0.34108156831651093
Validation loss: 2.8148548863953224

Epoch: 6| Step: 12
Training loss: 0.6747081814556115
Validation loss: 2.6946606571146856

Epoch: 6| Step: 13
Training loss: 0.4470805822336973
Validation loss: 2.7813836112057464

Epoch: 314| Step: 0
Training loss: 0.45991660064373774
Validation loss: 2.749696368014471

Epoch: 6| Step: 1
Training loss: 0.5765993504520242
Validation loss: 2.7387192285626436

Epoch: 6| Step: 2
Training loss: 0.4750880743238602
Validation loss: 2.7600494908304625

Epoch: 6| Step: 3
Training loss: 0.40263041681709844
Validation loss: 2.764844866994298

Epoch: 6| Step: 4
Training loss: 0.3632087840334601
Validation loss: 2.7141346982065477

Epoch: 6| Step: 5
Training loss: 0.4632334505996387
Validation loss: 2.7180779894478726

Epoch: 6| Step: 6
Training loss: 0.9714171701952308
Validation loss: 2.802893784937473

Epoch: 6| Step: 7
Training loss: 0.4219820805039943
Validation loss: 2.7330469593973903

Epoch: 6| Step: 8
Training loss: 0.4181410354196577
Validation loss: 2.7740139214483333

Epoch: 6| Step: 9
Training loss: 0.7397425081776758
Validation loss: 2.7316848018882913

Epoch: 6| Step: 10
Training loss: 0.4500077160862498
Validation loss: 2.749046897449298

Epoch: 6| Step: 11
Training loss: 0.4852244097365506
Validation loss: 2.7806311215263078

Epoch: 6| Step: 12
Training loss: 0.4768915291267649
Validation loss: 2.7691854486126024

Epoch: 6| Step: 13
Training loss: 0.6176570603017705
Validation loss: 2.747342928456885

Epoch: 315| Step: 0
Training loss: 0.34442270087032484
Validation loss: 2.7130690521233998

Epoch: 6| Step: 1
Training loss: 0.6172516704952337
Validation loss: 2.7141850173168995

Epoch: 6| Step: 2
Training loss: 0.5028535359329904
Validation loss: 2.731092797359269

Epoch: 6| Step: 3
Training loss: 0.4636513619517169
Validation loss: 2.8283718556388475

Epoch: 6| Step: 4
Training loss: 0.46215246391460874
Validation loss: 2.6487732695991135

Epoch: 6| Step: 5
Training loss: 0.5075889388733987
Validation loss: 2.707886062271472

Epoch: 6| Step: 6
Training loss: 0.5324820648898151
Validation loss: 2.7186963890899287

Epoch: 6| Step: 7
Training loss: 0.518203041402165
Validation loss: 2.692875727179453

Epoch: 6| Step: 8
Training loss: 0.4093087295589231
Validation loss: 2.7308386614408677

Epoch: 6| Step: 9
Training loss: 0.4542093784768291
Validation loss: 2.7374692575479087

Epoch: 6| Step: 10
Training loss: 0.49309571047440975
Validation loss: 2.8156804857280338

Epoch: 6| Step: 11
Training loss: 0.8655132249078502
Validation loss: 2.723307768313793

Epoch: 6| Step: 12
Training loss: 0.5324718784912233
Validation loss: 2.7561478818630176

Epoch: 6| Step: 13
Training loss: 0.3908531857628984
Validation loss: 2.7294837437443933

Epoch: 316| Step: 0
Training loss: 0.43016722515833083
Validation loss: 2.840733517741176

Epoch: 6| Step: 1
Training loss: 0.5863787197823697
Validation loss: 2.7627749368091448

Epoch: 6| Step: 2
Training loss: 0.5499672251386023
Validation loss: 2.6529609362854525

Epoch: 6| Step: 3
Training loss: 0.4207260593124202
Validation loss: 2.798402933645265

Epoch: 6| Step: 4
Training loss: 0.5050350232773821
Validation loss: 2.7919405238257355

Epoch: 6| Step: 5
Training loss: 0.36481351625040526
Validation loss: 2.7549967453205246

Epoch: 6| Step: 6
Training loss: 0.44063338413784126
Validation loss: 2.7667198887458926

Epoch: 6| Step: 7
Training loss: 0.5083299201579755
Validation loss: 2.8818389709863457

Epoch: 6| Step: 8
Training loss: 0.46080865513956554
Validation loss: 2.73525950340352

Epoch: 6| Step: 9
Training loss: 0.5174884070604437
Validation loss: 2.751167641908667

Epoch: 6| Step: 10
Training loss: 0.7249467994638762
Validation loss: 2.782072774221361

Epoch: 6| Step: 11
Training loss: 0.5480007029828206
Validation loss: 2.7671815331838254

Epoch: 6| Step: 12
Training loss: 0.4619715616516995
Validation loss: 2.692139398813373

Epoch: 6| Step: 13
Training loss: 0.8977546418849985
Validation loss: 2.7795485674979297

Epoch: 317| Step: 0
Training loss: 0.44570552480922493
Validation loss: 2.775539937344031

Epoch: 6| Step: 1
Training loss: 0.580367661475133
Validation loss: 2.718021426741667

Epoch: 6| Step: 2
Training loss: 0.5643913472829633
Validation loss: 2.6755677743667414

Epoch: 6| Step: 3
Training loss: 0.6561041851626528
Validation loss: 2.7035902207314115

Epoch: 6| Step: 4
Training loss: 0.34487647020179374
Validation loss: 2.8074894388962095

Epoch: 6| Step: 5
Training loss: 0.3871356181498263
Validation loss: 2.691283999740782

Epoch: 6| Step: 6
Training loss: 0.7246507494031416
Validation loss: 2.805494158821051

Epoch: 6| Step: 7
Training loss: 0.5242333695807745
Validation loss: 2.7633792070723247

Epoch: 6| Step: 8
Training loss: 0.43591438491956763
Validation loss: 2.7842975164693313

Epoch: 6| Step: 9
Training loss: 0.4908232476677588
Validation loss: 2.7800429507352105

Epoch: 6| Step: 10
Training loss: 0.5857214465766888
Validation loss: 2.75751435394563

Epoch: 6| Step: 11
Training loss: 0.9910356939837626
Validation loss: 2.726910777469669

Epoch: 6| Step: 12
Training loss: 0.48253631778771144
Validation loss: 2.796476609255271

Epoch: 6| Step: 13
Training loss: 0.40738085927082596
Validation loss: 2.711355098400952

Epoch: 318| Step: 0
Training loss: 0.4963308353551221
Validation loss: 2.7743109388833673

Epoch: 6| Step: 1
Training loss: 0.5713053904751325
Validation loss: 2.7493019518521216

Epoch: 6| Step: 2
Training loss: 0.43271565231698816
Validation loss: 2.6969917410598065

Epoch: 6| Step: 3
Training loss: 0.36428959684814005
Validation loss: 2.7616120011608154

Epoch: 6| Step: 4
Training loss: 0.5028528543688465
Validation loss: 2.693161361235221

Epoch: 6| Step: 5
Training loss: 0.30295901424037813
Validation loss: 2.727635082462767

Epoch: 6| Step: 6
Training loss: 0.5917140537636676
Validation loss: 2.8132447846053372

Epoch: 6| Step: 7
Training loss: 0.7368646988864556
Validation loss: 2.747215971400143

Epoch: 6| Step: 8
Training loss: 0.5163630780570826
Validation loss: 2.727664247620441

Epoch: 6| Step: 9
Training loss: 0.3424795145848723
Validation loss: 2.735198196747602

Epoch: 6| Step: 10
Training loss: 0.3812876714011391
Validation loss: 2.713713793625064

Epoch: 6| Step: 11
Training loss: 0.4491598671178496
Validation loss: 2.8192451408695933

Epoch: 6| Step: 12
Training loss: 0.37731811167809315
Validation loss: 2.7155209215922578

Epoch: 6| Step: 13
Training loss: 0.9672748963737644
Validation loss: 2.686190189874988

Epoch: 319| Step: 0
Training loss: 0.32587192929177927
Validation loss: 2.6918348498007614

Epoch: 6| Step: 1
Training loss: 0.47234274184876224
Validation loss: 2.720395156799464

Epoch: 6| Step: 2
Training loss: 0.5401924839727751
Validation loss: 2.7518619894978866

Epoch: 6| Step: 3
Training loss: 0.4974085138778326
Validation loss: 2.685996322475935

Epoch: 6| Step: 4
Training loss: 0.7788263492294212
Validation loss: 2.7339746745293967

Epoch: 6| Step: 5
Training loss: 0.27826497381077264
Validation loss: 2.7972941022457802

Epoch: 6| Step: 6
Training loss: 0.48810537604083465
Validation loss: 2.630174048675581

Epoch: 6| Step: 7
Training loss: 0.5133680598270761
Validation loss: 2.7377340120948266

Epoch: 6| Step: 8
Training loss: 0.5980166177800946
Validation loss: 2.7418913069953796

Epoch: 6| Step: 9
Training loss: 0.4236757558299858
Validation loss: 2.7338387681049316

Epoch: 6| Step: 10
Training loss: 0.43444527530970123
Validation loss: 2.6788079363238624

Epoch: 6| Step: 11
Training loss: 0.46653828181823287
Validation loss: 2.7993324040230196

Epoch: 6| Step: 12
Training loss: 0.5783089010187882
Validation loss: 2.728104396769943

Epoch: 6| Step: 13
Training loss: 0.4806714444482955
Validation loss: 2.744579941596084

Epoch: 320| Step: 0
Training loss: 0.39555718384580535
Validation loss: 2.653041592362636

Epoch: 6| Step: 1
Training loss: 0.6202309091175408
Validation loss: 2.755316969539188

Epoch: 6| Step: 2
Training loss: 0.44801008743611903
Validation loss: 2.7671663260156887

Epoch: 6| Step: 3
Training loss: 0.3187096897516467
Validation loss: 2.6815502043147537

Epoch: 6| Step: 4
Training loss: 0.4918094878817703
Validation loss: 2.6931631096508477

Epoch: 6| Step: 5
Training loss: 0.4567135578843102
Validation loss: 2.7401423349328264

Epoch: 6| Step: 6
Training loss: 0.3459754453177804
Validation loss: 2.667129838972375

Epoch: 6| Step: 7
Training loss: 0.6025893130129929
Validation loss: 2.6926043334789305

Epoch: 6| Step: 8
Training loss: 0.4787979227487858
Validation loss: 2.6275763811067043

Epoch: 6| Step: 9
Training loss: 0.4168999813435771
Validation loss: 2.7050736006091824

Epoch: 6| Step: 10
Training loss: 0.4131770292809658
Validation loss: 2.712754152992685

Epoch: 6| Step: 11
Training loss: 0.38619477966776833
Validation loss: 2.665907890928384

Epoch: 6| Step: 12
Training loss: 1.0182238852647691
Validation loss: 2.7089126456403507

Epoch: 6| Step: 13
Training loss: 0.5030870210043673
Validation loss: 2.7086755145150088

Epoch: 321| Step: 0
Training loss: 0.6343798360029527
Validation loss: 2.768744051476971

Epoch: 6| Step: 1
Training loss: 0.7282770497451195
Validation loss: 2.582841739231339

Epoch: 6| Step: 2
Training loss: 0.4218521111954908
Validation loss: 2.6742921124313073

Epoch: 6| Step: 3
Training loss: 0.3228241213602005
Validation loss: 2.727661494279725

Epoch: 6| Step: 4
Training loss: 0.49029242791154865
Validation loss: 2.6507599736551652

Epoch: 6| Step: 5
Training loss: 0.6346290558840743
Validation loss: 2.676983869810152

Epoch: 6| Step: 6
Training loss: 0.4938517242378753
Validation loss: 2.6765747972670964

Epoch: 6| Step: 7
Training loss: 0.5036700382616325
Validation loss: 2.6164480730543005

Epoch: 6| Step: 8
Training loss: 0.3700833066062571
Validation loss: 2.6662440014697326

Epoch: 6| Step: 9
Training loss: 0.35865176028760043
Validation loss: 2.6832883347317966

Epoch: 6| Step: 10
Training loss: 0.48808012825697994
Validation loss: 2.7551256154172186

Epoch: 6| Step: 11
Training loss: 0.47214300490051986
Validation loss: 2.797101386372029

Epoch: 6| Step: 12
Training loss: 0.9726661467144443
Validation loss: 2.7592576286724526

Epoch: 6| Step: 13
Training loss: 0.4547257266410916
Validation loss: 2.7439549502075122

Epoch: 322| Step: 0
Training loss: 0.4490910555919504
Validation loss: 2.6659484333146075

Epoch: 6| Step: 1
Training loss: 0.374838357101897
Validation loss: 2.7382250901148577

Epoch: 6| Step: 2
Training loss: 0.8473649117600388
Validation loss: 2.7282287257497124

Epoch: 6| Step: 3
Training loss: 0.5761781853799033
Validation loss: 2.775922165541698

Epoch: 6| Step: 4
Training loss: 0.38634623300911086
Validation loss: 2.7690547215712273

Epoch: 6| Step: 5
Training loss: 0.44091425119989414
Validation loss: 2.6795314821250638

Epoch: 6| Step: 6
Training loss: 0.3708787395596048
Validation loss: 2.616972805345918

Epoch: 6| Step: 7
Training loss: 0.5484649162286727
Validation loss: 2.757417111965277

Epoch: 6| Step: 8
Training loss: 0.5119252261531326
Validation loss: 2.7070414885620435

Epoch: 6| Step: 9
Training loss: 0.4147646187349559
Validation loss: 2.6623203103526403

Epoch: 6| Step: 10
Training loss: 0.5174362276008407
Validation loss: 2.6881035267547926

Epoch: 6| Step: 11
Training loss: 0.7523697924835391
Validation loss: 2.736691247742161

Epoch: 6| Step: 12
Training loss: 0.6107013646051987
Validation loss: 2.7351505451275466

Epoch: 6| Step: 13
Training loss: 0.5873973716214648
Validation loss: 2.679376204104576

Epoch: 323| Step: 0
Training loss: 0.3403128313425516
Validation loss: 2.713180976857901

Epoch: 6| Step: 1
Training loss: 0.5351923631052664
Validation loss: 2.6942760520327513

Epoch: 6| Step: 2
Training loss: 0.6635426000791139
Validation loss: 2.7100872058491383

Epoch: 6| Step: 3
Training loss: 0.5395020061558147
Validation loss: 2.75747646197236

Epoch: 6| Step: 4
Training loss: 0.4419039730517545
Validation loss: 2.70447152471171

Epoch: 6| Step: 5
Training loss: 0.9609163793708368
Validation loss: 2.730148958862934

Epoch: 6| Step: 6
Training loss: 0.6263643155866253
Validation loss: 2.704150290260826

Epoch: 6| Step: 7
Training loss: 0.6641990969919684
Validation loss: 2.714924133720782

Epoch: 6| Step: 8
Training loss: 0.42761911729269325
Validation loss: 2.6813284814311094

Epoch: 6| Step: 9
Training loss: 0.3336989091850768
Validation loss: 2.671231867256081

Epoch: 6| Step: 10
Training loss: 0.33073238561470497
Validation loss: 2.686734393577959

Epoch: 6| Step: 11
Training loss: 0.5255878177695661
Validation loss: 2.721842136469341

Epoch: 6| Step: 12
Training loss: 0.3661467839315057
Validation loss: 2.650003186110015

Epoch: 6| Step: 13
Training loss: 0.4734436286554771
Validation loss: 2.696556696077824

Epoch: 324| Step: 0
Training loss: 0.4282122168143844
Validation loss: 2.6700916696735035

Epoch: 6| Step: 1
Training loss: 0.43911450373340033
Validation loss: 2.733624600576799

Epoch: 6| Step: 2
Training loss: 0.47258986645322304
Validation loss: 2.720057622460471

Epoch: 6| Step: 3
Training loss: 0.3827696795745759
Validation loss: 2.7176058616244445

Epoch: 6| Step: 4
Training loss: 0.5926343575579446
Validation loss: 2.6576388823211814

Epoch: 6| Step: 5
Training loss: 0.4042668538764721
Validation loss: 2.7041322011372553

Epoch: 6| Step: 6
Training loss: 1.015212341985389
Validation loss: 2.774856619810872

Epoch: 6| Step: 7
Training loss: 0.5829810770572383
Validation loss: 2.7535479950604236

Epoch: 6| Step: 8
Training loss: 0.44625799292130014
Validation loss: 2.7113905939371836

Epoch: 6| Step: 9
Training loss: 0.3846931001889294
Validation loss: 2.7130659837213056

Epoch: 6| Step: 10
Training loss: 0.4126122827589603
Validation loss: 2.725370071666787

Epoch: 6| Step: 11
Training loss: 0.44210318175954655
Validation loss: 2.7260568727431895

Epoch: 6| Step: 12
Training loss: 0.508849508315609
Validation loss: 2.691105442372778

Epoch: 6| Step: 13
Training loss: 0.4249725010334172
Validation loss: 2.727875576437177

Epoch: 325| Step: 0
Training loss: 1.1208982928618787
Validation loss: 2.667742412865334

Epoch: 6| Step: 1
Training loss: 0.31099172435648104
Validation loss: 2.7079791546586987

Epoch: 6| Step: 2
Training loss: 0.4603392549600492
Validation loss: 2.72454009156002

Epoch: 6| Step: 3
Training loss: 0.47579215276844583
Validation loss: 2.646857091129252

Epoch: 6| Step: 4
Training loss: 0.38110054401067595
Validation loss: 2.7450693099855332

Epoch: 6| Step: 5
Training loss: 0.42418947066117274
Validation loss: 2.661933070254954

Epoch: 6| Step: 6
Training loss: 0.46041685538769933
Validation loss: 2.6108452772087887

Epoch: 6| Step: 7
Training loss: 0.44552846323037965
Validation loss: 2.749869415766299

Epoch: 6| Step: 8
Training loss: 0.3604781179281485
Validation loss: 2.7573500003175697

Epoch: 6| Step: 9
Training loss: 0.3691173727795744
Validation loss: 2.69678795277313

Epoch: 6| Step: 10
Training loss: 0.45320516732157984
Validation loss: 2.712252910628275

Epoch: 6| Step: 11
Training loss: 0.43062264379512816
Validation loss: 2.750450386388125

Epoch: 6| Step: 12
Training loss: 0.4831698561173081
Validation loss: 2.6759443247310593

Epoch: 6| Step: 13
Training loss: 0.46701193288734616
Validation loss: 2.6682937372007074

Epoch: 326| Step: 0
Training loss: 0.5159527286197506
Validation loss: 2.723201600401827

Epoch: 6| Step: 1
Training loss: 0.2962098198615179
Validation loss: 2.718851957199816

Epoch: 6| Step: 2
Training loss: 0.4005190015469031
Validation loss: 2.6998537736314354

Epoch: 6| Step: 3
Training loss: 1.085544542527687
Validation loss: 2.7031160034735584

Epoch: 6| Step: 4
Training loss: 0.47859838898814433
Validation loss: 2.693791735356038

Epoch: 6| Step: 5
Training loss: 0.3698416617898204
Validation loss: 2.731497756696396

Epoch: 6| Step: 6
Training loss: 0.348334272771615
Validation loss: 2.7127375567549876

Epoch: 6| Step: 7
Training loss: 0.5371488244568036
Validation loss: 2.715055608373101

Epoch: 6| Step: 8
Training loss: 0.521933258825097
Validation loss: 2.7114716955366904

Epoch: 6| Step: 9
Training loss: 0.5221396626008898
Validation loss: 2.6911063578546437

Epoch: 6| Step: 10
Training loss: 0.4554371543119712
Validation loss: 2.6437449711480494

Epoch: 6| Step: 11
Training loss: 0.4482767594578915
Validation loss: 2.7008159528920666

Epoch: 6| Step: 12
Training loss: 0.5646665493024113
Validation loss: 2.7173625211849877

Epoch: 6| Step: 13
Training loss: 0.4470614671144589
Validation loss: 2.68444490885713

Epoch: 327| Step: 0
Training loss: 0.6427380672936261
Validation loss: 2.746568561888269

Epoch: 6| Step: 1
Training loss: 0.46463527332080345
Validation loss: 2.7425301565055666

Epoch: 6| Step: 2
Training loss: 0.46492430045139904
Validation loss: 2.7300239604555223

Epoch: 6| Step: 3
Training loss: 0.44811948538756197
Validation loss: 2.7397182030108826

Epoch: 6| Step: 4
Training loss: 0.38136760351784876
Validation loss: 2.6512146139533685

Epoch: 6| Step: 5
Training loss: 0.4723583417550992
Validation loss: 2.707850506121977

Epoch: 6| Step: 6
Training loss: 0.5246871436130933
Validation loss: 2.6860054503125426

Epoch: 6| Step: 7
Training loss: 0.522216340323842
Validation loss: 2.7562064013849765

Epoch: 6| Step: 8
Training loss: 0.8768122842429367
Validation loss: 2.7962790339074854

Epoch: 6| Step: 9
Training loss: 0.3473077162817672
Validation loss: 2.665642293238176

Epoch: 6| Step: 10
Training loss: 0.4697030551286388
Validation loss: 2.682732278627572

Epoch: 6| Step: 11
Training loss: 0.26138566300339205
Validation loss: 2.680012526601487

Epoch: 6| Step: 12
Training loss: 0.46551569289297645
Validation loss: 2.7246687323190084

Epoch: 6| Step: 13
Training loss: 0.6427787073476311
Validation loss: 2.798971530517388

Epoch: 328| Step: 0
Training loss: 0.4512953486071214
Validation loss: 2.7324374209605486

Epoch: 6| Step: 1
Training loss: 0.27224521916240296
Validation loss: 2.6985980956694693

Epoch: 6| Step: 2
Training loss: 0.48816960393521874
Validation loss: 2.785675128899113

Epoch: 6| Step: 3
Training loss: 0.32077948326817224
Validation loss: 2.7490468685400566

Epoch: 6| Step: 4
Training loss: 0.2924783034714169
Validation loss: 2.7573964901146693

Epoch: 6| Step: 5
Training loss: 0.48649309416688885
Validation loss: 2.710557586697134

Epoch: 6| Step: 6
Training loss: 0.31445433338004186
Validation loss: 2.792538981061734

Epoch: 6| Step: 7
Training loss: 0.5051548002005721
Validation loss: 2.6565493396312947

Epoch: 6| Step: 8
Training loss: 0.26103662446904596
Validation loss: 2.729565647071633

Epoch: 6| Step: 9
Training loss: 0.2653943069826958
Validation loss: 2.696103614767711

Epoch: 6| Step: 10
Training loss: 0.6053041542041124
Validation loss: 2.8072095916772253

Epoch: 6| Step: 11
Training loss: 0.5500580388570806
Validation loss: 2.7265911228313464

Epoch: 6| Step: 12
Training loss: 0.9158200053065837
Validation loss: 2.713961860988467

Epoch: 6| Step: 13
Training loss: 0.6086564840907907
Validation loss: 2.672093626004796

Epoch: 329| Step: 0
Training loss: 0.37362699688594453
Validation loss: 2.694022418155675

Epoch: 6| Step: 1
Training loss: 0.4656036000806542
Validation loss: 2.6449262360669397

Epoch: 6| Step: 2
Training loss: 0.678092927657728
Validation loss: 2.74130841371683

Epoch: 6| Step: 3
Training loss: 0.4065978321787907
Validation loss: 2.8153383555766838

Epoch: 6| Step: 4
Training loss: 0.40864739585549864
Validation loss: 2.6902531929995654

Epoch: 6| Step: 5
Training loss: 0.35107143862582507
Validation loss: 2.7456868188076884

Epoch: 6| Step: 6
Training loss: 0.4807715663486383
Validation loss: 2.7299314596959863

Epoch: 6| Step: 7
Training loss: 0.9687532609453999
Validation loss: 2.636972176888324

Epoch: 6| Step: 8
Training loss: 0.44231963390716905
Validation loss: 2.645847731022947

Epoch: 6| Step: 9
Training loss: 0.4012480695921669
Validation loss: 2.768624240151836

Epoch: 6| Step: 10
Training loss: 0.5777129173807696
Validation loss: 2.7327471001696657

Epoch: 6| Step: 11
Training loss: 0.44124053274918396
Validation loss: 2.696929387693077

Epoch: 6| Step: 12
Training loss: 0.43130507739426366
Validation loss: 2.664887830879823

Epoch: 6| Step: 13
Training loss: 0.4246503878581904
Validation loss: 2.75735482802981

Epoch: 330| Step: 0
Training loss: 0.31754646190347463
Validation loss: 2.6785028654739143

Epoch: 6| Step: 1
Training loss: 0.34144209841585926
Validation loss: 2.720259601765971

Epoch: 6| Step: 2
Training loss: 0.49988041878291306
Validation loss: 2.7323732733068145

Epoch: 6| Step: 3
Training loss: 0.4568778375571413
Validation loss: 2.7093664008579386

Epoch: 6| Step: 4
Training loss: 0.5508696032061314
Validation loss: 2.7116071623322737

Epoch: 6| Step: 5
Training loss: 0.3142570215835244
Validation loss: 2.7452840827827374

Epoch: 6| Step: 6
Training loss: 0.5782098450132964
Validation loss: 2.699944685145655

Epoch: 6| Step: 7
Training loss: 0.36757473107938926
Validation loss: 2.6724679300152205

Epoch: 6| Step: 8
Training loss: 0.40411844785212314
Validation loss: 2.745273661171373

Epoch: 6| Step: 9
Training loss: 0.3171038531423887
Validation loss: 2.7949477718138955

Epoch: 6| Step: 10
Training loss: 0.5368799447841102
Validation loss: 2.799167978896477

Epoch: 6| Step: 11
Training loss: 0.4249742191573446
Validation loss: 2.7663422568603595

Epoch: 6| Step: 12
Training loss: 0.47407394787639906
Validation loss: 2.690204353842614

Epoch: 6| Step: 13
Training loss: 0.9033439344462091
Validation loss: 2.770834131647057

Epoch: 331| Step: 0
Training loss: 0.49671425648469014
Validation loss: 2.7448426349885398

Epoch: 6| Step: 1
Training loss: 0.37882479549179143
Validation loss: 2.7359475690974824

Epoch: 6| Step: 2
Training loss: 0.34554614797296185
Validation loss: 2.7140723726616067

Epoch: 6| Step: 3
Training loss: 0.5563071339443476
Validation loss: 2.695629864128212

Epoch: 6| Step: 4
Training loss: 0.5279441806103627
Validation loss: 2.6988057226754067

Epoch: 6| Step: 5
Training loss: 0.5908324437432885
Validation loss: 2.7542077731375105

Epoch: 6| Step: 6
Training loss: 0.27665654862432026
Validation loss: 2.7736886783816455

Epoch: 6| Step: 7
Training loss: 0.3386933158238609
Validation loss: 2.7290640852968076

Epoch: 6| Step: 8
Training loss: 0.38278013209306544
Validation loss: 2.732489308053912

Epoch: 6| Step: 9
Training loss: 0.4261932129942034
Validation loss: 2.7668605422452286

Epoch: 6| Step: 10
Training loss: 0.8127526110651463
Validation loss: 2.7295055009202183

Epoch: 6| Step: 11
Training loss: 0.38734208550197496
Validation loss: 2.6288863280978845

Epoch: 6| Step: 12
Training loss: 0.5291640055081394
Validation loss: 2.6994273670507987

Epoch: 6| Step: 13
Training loss: 0.4025560393031911
Validation loss: 2.740142102907323

Epoch: 332| Step: 0
Training loss: 0.37542013633866184
Validation loss: 2.7417260168390176

Epoch: 6| Step: 1
Training loss: 0.3854976216773502
Validation loss: 2.6583047137817535

Epoch: 6| Step: 2
Training loss: 0.8568756866452327
Validation loss: 2.694247181762343

Epoch: 6| Step: 3
Training loss: 0.2307038320549278
Validation loss: 2.7658749483599596

Epoch: 6| Step: 4
Training loss: 0.6304999588399899
Validation loss: 2.754700991979236

Epoch: 6| Step: 5
Training loss: 0.2815643514134106
Validation loss: 2.7148635387842934

Epoch: 6| Step: 6
Training loss: 0.6162495064491632
Validation loss: 2.7149036428308015

Epoch: 6| Step: 7
Training loss: 0.3402987645882907
Validation loss: 2.7844902622671173

Epoch: 6| Step: 8
Training loss: 0.5851824664162513
Validation loss: 2.672698386703071

Epoch: 6| Step: 9
Training loss: 0.6321334963637322
Validation loss: 2.7293267288056664

Epoch: 6| Step: 10
Training loss: 0.4732900893606577
Validation loss: 2.7498705428892363

Epoch: 6| Step: 11
Training loss: 0.3404499107039983
Validation loss: 2.6913427041814857

Epoch: 6| Step: 12
Training loss: 0.4777648173728759
Validation loss: 2.7114663904465797

Epoch: 6| Step: 13
Training loss: 0.3554502209875064
Validation loss: 2.733407421581118

Epoch: 333| Step: 0
Training loss: 0.682129823742784
Validation loss: 2.661213101450308

Epoch: 6| Step: 1
Training loss: 0.4358817553684553
Validation loss: 2.7567431904651114

Epoch: 6| Step: 2
Training loss: 0.8677621947596316
Validation loss: 2.6662267431337865

Epoch: 6| Step: 3
Training loss: 0.45064599902235924
Validation loss: 2.7662760009669856

Epoch: 6| Step: 4
Training loss: 0.6045823284231081
Validation loss: 2.655995914050104

Epoch: 6| Step: 5
Training loss: 0.4444071115354386
Validation loss: 2.7021202763306755

Epoch: 6| Step: 6
Training loss: 0.5127502702594195
Validation loss: 2.761780633372451

Epoch: 6| Step: 7
Training loss: 0.4681610858489994
Validation loss: 2.7264856730278884

Epoch: 6| Step: 8
Training loss: 0.45550067259741994
Validation loss: 2.8212739357125196

Epoch: 6| Step: 9
Training loss: 0.5723085354805881
Validation loss: 2.681514684243925

Epoch: 6| Step: 10
Training loss: 0.34376090205851
Validation loss: 2.775071084770254

Epoch: 6| Step: 11
Training loss: 0.4238824414022178
Validation loss: 2.7591147801589835

Epoch: 6| Step: 12
Training loss: 0.3653934560702376
Validation loss: 2.7285190182671353

Epoch: 6| Step: 13
Training loss: 0.3324812588393527
Validation loss: 2.757660426628879

Epoch: 334| Step: 0
Training loss: 0.6568210025011606
Validation loss: 2.7269293275093567

Epoch: 6| Step: 1
Training loss: 0.4845095109291472
Validation loss: 2.7264425256779568

Epoch: 6| Step: 2
Training loss: 0.39518451428194235
Validation loss: 2.7316190582286644

Epoch: 6| Step: 3
Training loss: 0.4354076419546057
Validation loss: 2.74550353536087

Epoch: 6| Step: 4
Training loss: 0.3262946303303696
Validation loss: 2.7618438102467127

Epoch: 6| Step: 5
Training loss: 0.4363606808776362
Validation loss: 2.6804872585374016

Epoch: 6| Step: 6
Training loss: 0.4681039649861871
Validation loss: 2.6856251764153165

Epoch: 6| Step: 7
Training loss: 0.3234869039278484
Validation loss: 2.703536000547262

Epoch: 6| Step: 8
Training loss: 0.38097790560900685
Validation loss: 2.7208402571266332

Epoch: 6| Step: 9
Training loss: 0.4590892266166272
Validation loss: 2.755364099340796

Epoch: 6| Step: 10
Training loss: 0.8065750797418422
Validation loss: 2.7296720915200994

Epoch: 6| Step: 11
Training loss: 0.3599920159024102
Validation loss: 2.7398686254405638

Epoch: 6| Step: 12
Training loss: 0.5952659378465479
Validation loss: 2.6959468961102186

Epoch: 6| Step: 13
Training loss: 0.5598849864766604
Validation loss: 2.7813415798011363

Epoch: 335| Step: 0
Training loss: 0.37161477304341056
Validation loss: 2.702722184995936

Epoch: 6| Step: 1
Training loss: 0.39511682469817555
Validation loss: 2.765400778666516

Epoch: 6| Step: 2
Training loss: 0.4489767998646605
Validation loss: 2.6774960854030074

Epoch: 6| Step: 3
Training loss: 0.41651508633812406
Validation loss: 2.763456913616258

Epoch: 6| Step: 4
Training loss: 0.2933045814838507
Validation loss: 2.6533400958740216

Epoch: 6| Step: 5
Training loss: 0.3508234308790391
Validation loss: 2.8262120445927583

Epoch: 6| Step: 6
Training loss: 0.6820313609888919
Validation loss: 2.746971297646591

Epoch: 6| Step: 7
Training loss: 0.40115594061506527
Validation loss: 2.6433961611958243

Epoch: 6| Step: 8
Training loss: 0.44294220039152704
Validation loss: 2.79035288703996

Epoch: 6| Step: 9
Training loss: 0.9929410821044835
Validation loss: 2.674173136396498

Epoch: 6| Step: 10
Training loss: 0.5859585567505495
Validation loss: 2.7177514913652714

Epoch: 6| Step: 11
Training loss: 0.4873690056257324
Validation loss: 2.8189416796238125

Epoch: 6| Step: 12
Training loss: 0.4252311582792312
Validation loss: 2.754834116645422

Epoch: 6| Step: 13
Training loss: 0.5523750026553539
Validation loss: 2.7845481861511976

Epoch: 336| Step: 0
Training loss: 0.33386685718731146
Validation loss: 2.5989257922584827

Epoch: 6| Step: 1
Training loss: 1.0175458496598437
Validation loss: 2.7139405136204697

Epoch: 6| Step: 2
Training loss: 0.4037365370534237
Validation loss: 2.7259433192664355

Epoch: 6| Step: 3
Training loss: 0.37945677886077056
Validation loss: 2.7085553347248563

Epoch: 6| Step: 4
Training loss: 0.34880469864017694
Validation loss: 2.741327250456586

Epoch: 6| Step: 5
Training loss: 0.5189346674185172
Validation loss: 2.7144034415123834

Epoch: 6| Step: 6
Training loss: 0.5032043595840051
Validation loss: 2.695586466111025

Epoch: 6| Step: 7
Training loss: 0.32864175704306214
Validation loss: 2.710588533512274

Epoch: 6| Step: 8
Training loss: 0.5543561939976247
Validation loss: 2.7560627459224265

Epoch: 6| Step: 9
Training loss: 0.3673573973411295
Validation loss: 2.717567303528012

Epoch: 6| Step: 10
Training loss: 0.436345706404483
Validation loss: 2.744822157534215

Epoch: 6| Step: 11
Training loss: 0.4165780469907857
Validation loss: 2.7191826779354664

Epoch: 6| Step: 12
Training loss: 0.3856001193955541
Validation loss: 2.751770128961771

Epoch: 6| Step: 13
Training loss: 0.48100594983416123
Validation loss: 2.7058099190658673

Epoch: 337| Step: 0
Training loss: 0.4012892153106609
Validation loss: 2.741838539866026

Epoch: 6| Step: 1
Training loss: 0.6298147238665339
Validation loss: 2.759076096447976

Epoch: 6| Step: 2
Training loss: 0.3817811424178407
Validation loss: 2.7527433641089454

Epoch: 6| Step: 3
Training loss: 0.3963808948796691
Validation loss: 2.750156773809041

Epoch: 6| Step: 4
Training loss: 0.37194677990487296
Validation loss: 2.7204257433913157

Epoch: 6| Step: 5
Training loss: 0.9732124546078795
Validation loss: 2.7134380552654553

Epoch: 6| Step: 6
Training loss: 0.4342335628523752
Validation loss: 2.677981041830476

Epoch: 6| Step: 7
Training loss: 0.37980392146815506
Validation loss: 2.766249146229365

Epoch: 6| Step: 8
Training loss: 0.4149716311260745
Validation loss: 2.7537745378889893

Epoch: 6| Step: 9
Training loss: 0.6863611498873213
Validation loss: 2.675398557449488

Epoch: 6| Step: 10
Training loss: 0.5342798226350771
Validation loss: 2.7747427577706625

Epoch: 6| Step: 11
Training loss: 0.4730515836549077
Validation loss: 2.689432587795664

Epoch: 6| Step: 12
Training loss: 0.3404756787432345
Validation loss: 2.717494521253971

Epoch: 6| Step: 13
Training loss: 0.46703495354713853
Validation loss: 2.6794217110398724

Epoch: 338| Step: 0
Training loss: 0.6175214129762314
Validation loss: 2.789214414133348

Epoch: 6| Step: 1
Training loss: 0.4867806531504885
Validation loss: 2.7795100680998837

Epoch: 6| Step: 2
Training loss: 0.5026092990224481
Validation loss: 2.7362431420637763

Epoch: 6| Step: 3
Training loss: 0.3361830700945746
Validation loss: 2.7506778849659437

Epoch: 6| Step: 4
Training loss: 0.758539067820688
Validation loss: 2.7927069908137914

Epoch: 6| Step: 5
Training loss: 0.5772349233099902
Validation loss: 2.7355660160739954

Epoch: 6| Step: 6
Training loss: 0.3291775873139162
Validation loss: 2.713181511425834

Epoch: 6| Step: 7
Training loss: 0.37143779667202664
Validation loss: 2.734180857714475

Epoch: 6| Step: 8
Training loss: 0.4020405339734311
Validation loss: 2.7343344549170343

Epoch: 6| Step: 9
Training loss: 0.5605370656926307
Validation loss: 2.6848920248000288

Epoch: 6| Step: 10
Training loss: 0.501826080987994
Validation loss: 2.736400791159065

Epoch: 6| Step: 11
Training loss: 0.49053514228710876
Validation loss: 2.6664472628774765

Epoch: 6| Step: 12
Training loss: 0.3631230081447789
Validation loss: 2.6903426491469693

Epoch: 6| Step: 13
Training loss: 0.5284278182051353
Validation loss: 2.7342010806040826

Epoch: 339| Step: 0
Training loss: 0.4353864571101312
Validation loss: 2.7402097447603238

Epoch: 6| Step: 1
Training loss: 0.3866088788173846
Validation loss: 2.73045908681081

Epoch: 6| Step: 2
Training loss: 0.5048481912751094
Validation loss: 2.7890898545577327

Epoch: 6| Step: 3
Training loss: 0.3653043180190652
Validation loss: 2.6818172195718897

Epoch: 6| Step: 4
Training loss: 0.45514837222184856
Validation loss: 2.784614784998842

Epoch: 6| Step: 5
Training loss: 0.5270273177596511
Validation loss: 2.7073380230854633

Epoch: 6| Step: 6
Training loss: 0.3965090100381904
Validation loss: 2.752838750327148

Epoch: 6| Step: 7
Training loss: 0.6826243911821479
Validation loss: 2.8225952519128223

Epoch: 6| Step: 8
Training loss: 0.8623368288575606
Validation loss: 2.7853050103035684

Epoch: 6| Step: 9
Training loss: 0.5011150622259083
Validation loss: 2.682795939526761

Epoch: 6| Step: 10
Training loss: 0.47380253218730584
Validation loss: 2.7804778809632853

Epoch: 6| Step: 11
Training loss: 0.35399479295246966
Validation loss: 2.7372995776426916

Epoch: 6| Step: 12
Training loss: 0.3612411806818574
Validation loss: 2.7354780606200197

Epoch: 6| Step: 13
Training loss: 0.366475287076532
Validation loss: 2.7175390828073267

Epoch: 340| Step: 0
Training loss: 0.3855071885110372
Validation loss: 2.6958056897058422

Epoch: 6| Step: 1
Training loss: 0.5665336728639424
Validation loss: 2.7534858689378208

Epoch: 6| Step: 2
Training loss: 0.4443937829899544
Validation loss: 2.688321572041745

Epoch: 6| Step: 3
Training loss: 0.5217975718914369
Validation loss: 2.7315803560823215

Epoch: 6| Step: 4
Training loss: 0.5885454250879602
Validation loss: 2.6989723604682605

Epoch: 6| Step: 5
Training loss: 0.25575580393450564
Validation loss: 2.744527428857185

Epoch: 6| Step: 6
Training loss: 0.5047611997664567
Validation loss: 2.707541707082502

Epoch: 6| Step: 7
Training loss: 0.5215982891349438
Validation loss: 2.725439348587654

Epoch: 6| Step: 8
Training loss: 0.4270233096610371
Validation loss: 2.7375760768962083

Epoch: 6| Step: 9
Training loss: 0.9178702768305327
Validation loss: 2.816281792531359

Epoch: 6| Step: 10
Training loss: 0.5352941739073677
Validation loss: 2.707690989296988

Epoch: 6| Step: 11
Training loss: 0.33110151831752005
Validation loss: 2.805118637454665

Epoch: 6| Step: 12
Training loss: 0.6190921030375505
Validation loss: 2.740225195784363

Epoch: 6| Step: 13
Training loss: 0.39875472287218217
Validation loss: 2.727405829384659

Epoch: 341| Step: 0
Training loss: 0.5857599879629082
Validation loss: 2.8002601468624664

Epoch: 6| Step: 1
Training loss: 0.43233013747898524
Validation loss: 2.715555294475276

Epoch: 6| Step: 2
Training loss: 0.5021240002900196
Validation loss: 2.747535034317311

Epoch: 6| Step: 3
Training loss: 0.37471072642771347
Validation loss: 2.706770744468086

Epoch: 6| Step: 4
Training loss: 0.5159323383260254
Validation loss: 2.6758608247011404

Epoch: 6| Step: 5
Training loss: 0.38450613808662126
Validation loss: 2.8022709090024844

Epoch: 6| Step: 6
Training loss: 0.6315859929641283
Validation loss: 2.840992873025683

Epoch: 6| Step: 7
Training loss: 0.9194719708699413
Validation loss: 2.675891705017603

Epoch: 6| Step: 8
Training loss: 0.3873089611685269
Validation loss: 2.7764470637591216

Epoch: 6| Step: 9
Training loss: 0.6164546188503859
Validation loss: 2.7140296941372943

Epoch: 6| Step: 10
Training loss: 0.5647998787500911
Validation loss: 2.7695823560697406

Epoch: 6| Step: 11
Training loss: 0.4297783495488177
Validation loss: 2.725029041415508

Epoch: 6| Step: 12
Training loss: 0.37617820187771034
Validation loss: 2.7762193652756753

Epoch: 6| Step: 13
Training loss: 0.42667215216483034
Validation loss: 2.7356350130056692

Epoch: 342| Step: 0
Training loss: 0.5738126655298328
Validation loss: 2.6780260160501044

Epoch: 6| Step: 1
Training loss: 0.30331510403024464
Validation loss: 2.724846300695983

Epoch: 6| Step: 2
Training loss: 0.4608181944505223
Validation loss: 2.7549144874220346

Epoch: 6| Step: 3
Training loss: 0.48502825708758057
Validation loss: 2.773381686656434

Epoch: 6| Step: 4
Training loss: 0.5035157575821684
Validation loss: 2.787882978419847

Epoch: 6| Step: 5
Training loss: 0.5534706738188541
Validation loss: 2.6646010226531693

Epoch: 6| Step: 6
Training loss: 0.45143096882556905
Validation loss: 2.7803683079963992

Epoch: 6| Step: 7
Training loss: 0.398282712901539
Validation loss: 2.6817225225861745

Epoch: 6| Step: 8
Training loss: 0.4110034730119453
Validation loss: 2.743463840493595

Epoch: 6| Step: 9
Training loss: 0.5130498622936855
Validation loss: 2.79739608030733

Epoch: 6| Step: 10
Training loss: 0.5548024125681363
Validation loss: 2.848018977223438

Epoch: 6| Step: 11
Training loss: 0.4182755957168916
Validation loss: 2.720422763623848

Epoch: 6| Step: 12
Training loss: 0.43751009861326395
Validation loss: 2.71962569008029

Epoch: 6| Step: 13
Training loss: 0.8069811233950458
Validation loss: 2.73997579357379

Epoch: 343| Step: 0
Training loss: 0.47599298811203805
Validation loss: 2.6896034850634467

Epoch: 6| Step: 1
Training loss: 0.48320763415466145
Validation loss: 2.7134547497282564

Epoch: 6| Step: 2
Training loss: 0.5705179340910388
Validation loss: 2.7739422979021495

Epoch: 6| Step: 3
Training loss: 0.48430383836318835
Validation loss: 2.714452255160319

Epoch: 6| Step: 4
Training loss: 0.42026266419449565
Validation loss: 2.7588954452663437

Epoch: 6| Step: 5
Training loss: 0.3925935163375012
Validation loss: 2.848430938071433

Epoch: 6| Step: 6
Training loss: 0.4960515312192339
Validation loss: 2.7179527429173476

Epoch: 6| Step: 7
Training loss: 0.3727987572758247
Validation loss: 2.728836736076742

Epoch: 6| Step: 8
Training loss: 0.7688401502768335
Validation loss: 2.6996970960462194

Epoch: 6| Step: 9
Training loss: 0.5061068132203834
Validation loss: 2.6903541845122474

Epoch: 6| Step: 10
Training loss: 0.3938732892734442
Validation loss: 2.646713325760218

Epoch: 6| Step: 11
Training loss: 0.39935764949641783
Validation loss: 2.703634328027088

Epoch: 6| Step: 12
Training loss: 0.3922640554779994
Validation loss: 2.663761080846081

Epoch: 6| Step: 13
Training loss: 0.4786868509172899
Validation loss: 2.761116174321827

Epoch: 344| Step: 0
Training loss: 0.3553778563608402
Validation loss: 2.7702261013178306

Epoch: 6| Step: 1
Training loss: 0.5347750900467497
Validation loss: 2.723975352324692

Epoch: 6| Step: 2
Training loss: 0.5663804673213251
Validation loss: 2.7174879338319156

Epoch: 6| Step: 3
Training loss: 0.4423229185405215
Validation loss: 2.7810622877003772

Epoch: 6| Step: 4
Training loss: 0.25652265116113765
Validation loss: 2.6941196769190143

Epoch: 6| Step: 5
Training loss: 0.4841891824484524
Validation loss: 2.668511383443112

Epoch: 6| Step: 6
Training loss: 0.35023666027105527
Validation loss: 2.760253517559786

Epoch: 6| Step: 7
Training loss: 0.48518403998009385
Validation loss: 2.781476143776214

Epoch: 6| Step: 8
Training loss: 0.5056494789186484
Validation loss: 2.7024136674932113

Epoch: 6| Step: 9
Training loss: 0.4679883968706085
Validation loss: 2.731591280893329

Epoch: 6| Step: 10
Training loss: 0.42407071953877634
Validation loss: 2.70731732800426

Epoch: 6| Step: 11
Training loss: 0.4678325257382128
Validation loss: 2.752316655085095

Epoch: 6| Step: 12
Training loss: 0.33147309456034557
Validation loss: 2.7353609687110487

Epoch: 6| Step: 13
Training loss: 0.8273537120993787
Validation loss: 2.764535189920651

Epoch: 345| Step: 0
Training loss: 0.4403440472555345
Validation loss: 2.7392637020417228

Epoch: 6| Step: 1
Training loss: 0.35369598677248226
Validation loss: 2.7817698717904276

Epoch: 6| Step: 2
Training loss: 0.35177458617754215
Validation loss: 2.6636872087820382

Epoch: 6| Step: 3
Training loss: 0.8107267984369312
Validation loss: 2.741182307868581

Epoch: 6| Step: 4
Training loss: 0.32631016843277344
Validation loss: 2.740802483953845

Epoch: 6| Step: 5
Training loss: 0.42341563812350663
Validation loss: 2.776013735021716

Epoch: 6| Step: 6
Training loss: 0.547272837208092
Validation loss: 2.7691381666025743

Epoch: 6| Step: 7
Training loss: 0.3392558658348547
Validation loss: 2.739408659110632

Epoch: 6| Step: 8
Training loss: 0.26280109587158557
Validation loss: 2.7646797130796

Epoch: 6| Step: 9
Training loss: 0.3959770527317595
Validation loss: 2.758131071859546

Epoch: 6| Step: 10
Training loss: 0.31921918875523614
Validation loss: 2.8000149567522485

Epoch: 6| Step: 11
Training loss: 0.47932558603264347
Validation loss: 2.718929913293631

Epoch: 6| Step: 12
Training loss: 0.4202944677235678
Validation loss: 2.757996442242016

Epoch: 6| Step: 13
Training loss: 0.5779653792787033
Validation loss: 2.793335648204175

Epoch: 346| Step: 0
Training loss: 0.35755094688699834
Validation loss: 2.693795452634282

Epoch: 6| Step: 1
Training loss: 0.7811425707387305
Validation loss: 2.748947577957173

Epoch: 6| Step: 2
Training loss: 0.5500652989724925
Validation loss: 2.7909021516890067

Epoch: 6| Step: 3
Training loss: 0.5127938893327529
Validation loss: 2.729947209063218

Epoch: 6| Step: 4
Training loss: 0.39996419388728627
Validation loss: 2.6910614693448003

Epoch: 6| Step: 5
Training loss: 0.38013044195221785
Validation loss: 2.782362297605968

Epoch: 6| Step: 6
Training loss: 0.372825217177996
Validation loss: 2.774561393717121

Epoch: 6| Step: 7
Training loss: 0.3337830723224456
Validation loss: 2.7642172842496437

Epoch: 6| Step: 8
Training loss: 0.3462004882309907
Validation loss: 2.6353022634731946

Epoch: 6| Step: 9
Training loss: 0.3513006294659655
Validation loss: 2.6712482453457858

Epoch: 6| Step: 10
Training loss: 0.3289323366018303
Validation loss: 2.7682533633926156

Epoch: 6| Step: 11
Training loss: 0.2978693722262519
Validation loss: 2.70431440936288

Epoch: 6| Step: 12
Training loss: 0.5072585385554776
Validation loss: 2.728208822715578

Epoch: 6| Step: 13
Training loss: 0.3739137413973751
Validation loss: 2.7583998792137154

Epoch: 347| Step: 0
Training loss: 0.40671604274298645
Validation loss: 2.696461205178241

Epoch: 6| Step: 1
Training loss: 0.47017789162712964
Validation loss: 2.807734584841777

Epoch: 6| Step: 2
Training loss: 0.6712637049947054
Validation loss: 2.7422583010265003

Epoch: 6| Step: 3
Training loss: 0.7272947989441613
Validation loss: 2.793745709102331

Epoch: 6| Step: 4
Training loss: 0.5304494042443451
Validation loss: 2.801962808524647

Epoch: 6| Step: 5
Training loss: 0.38649737639850645
Validation loss: 2.786703264161161

Epoch: 6| Step: 6
Training loss: 0.2962416241866131
Validation loss: 2.7283682832322236

Epoch: 6| Step: 7
Training loss: 0.3299968777494402
Validation loss: 2.7321366221893717

Epoch: 6| Step: 8
Training loss: 0.2841301052190353
Validation loss: 2.7353114531814398

Epoch: 6| Step: 9
Training loss: 0.34972475588061436
Validation loss: 2.7085984515983794

Epoch: 6| Step: 10
Training loss: 0.2589690967731034
Validation loss: 2.784108646609977

Epoch: 6| Step: 11
Training loss: 0.3740006083799708
Validation loss: 2.714736153279431

Epoch: 6| Step: 12
Training loss: 0.46259411034766185
Validation loss: 2.747542764552453

Epoch: 6| Step: 13
Training loss: 0.5813839788766717
Validation loss: 2.683596341253563

Epoch: 348| Step: 0
Training loss: 0.3310067246163113
Validation loss: 2.6739132934708185

Epoch: 6| Step: 1
Training loss: 0.8358154207733541
Validation loss: 2.7414331077723304

Epoch: 6| Step: 2
Training loss: 0.39587035340646753
Validation loss: 2.7224764224065727

Epoch: 6| Step: 3
Training loss: 0.3440916790832777
Validation loss: 2.6699386331980626

Epoch: 6| Step: 4
Training loss: 0.4088334687778722
Validation loss: 2.699212478652492

Epoch: 6| Step: 5
Training loss: 0.2779222016924806
Validation loss: 2.6695369432742337

Epoch: 6| Step: 6
Training loss: 0.5736693264461628
Validation loss: 2.676667019031291

Epoch: 6| Step: 7
Training loss: 0.4377782141407106
Validation loss: 2.744901931159684

Epoch: 6| Step: 8
Training loss: 0.34890026230891047
Validation loss: 2.689856006639816

Epoch: 6| Step: 9
Training loss: 0.5948522776259731
Validation loss: 2.68375119002419

Epoch: 6| Step: 10
Training loss: 0.31346321671737826
Validation loss: 2.7003581563030523

Epoch: 6| Step: 11
Training loss: 0.42709021640286304
Validation loss: 2.6132727652784067

Epoch: 6| Step: 12
Training loss: 0.3589510282650269
Validation loss: 2.7124099763384586

Epoch: 6| Step: 13
Training loss: 0.44475862289483803
Validation loss: 2.684685800935402

Epoch: 349| Step: 0
Training loss: 0.5517577044731642
Validation loss: 2.719390618277895

Epoch: 6| Step: 1
Training loss: 0.3109772536968844
Validation loss: 2.718132592029309

Epoch: 6| Step: 2
Training loss: 0.4914148563425841
Validation loss: 2.7504861719805214

Epoch: 6| Step: 3
Training loss: 0.4689132406189691
Validation loss: 2.6637645715189344

Epoch: 6| Step: 4
Training loss: 0.4585013587332491
Validation loss: 2.7083706388594067

Epoch: 6| Step: 5
Training loss: 0.5912012810827424
Validation loss: 2.7184896600243755

Epoch: 6| Step: 6
Training loss: 0.5328598314668171
Validation loss: 2.768487687956936

Epoch: 6| Step: 7
Training loss: 0.3520956870550798
Validation loss: 2.6493985768179753

Epoch: 6| Step: 8
Training loss: 0.5027451852675089
Validation loss: 2.779115493585433

Epoch: 6| Step: 9
Training loss: 0.29501723964474175
Validation loss: 2.7449135557227486

Epoch: 6| Step: 10
Training loss: 0.5958251077800015
Validation loss: 2.6559480158863265

Epoch: 6| Step: 11
Training loss: 0.31027797837328214
Validation loss: 2.73088708673523

Epoch: 6| Step: 12
Training loss: 0.4379870564625434
Validation loss: 2.622462203932593

Epoch: 6| Step: 13
Training loss: 0.8514037728024193
Validation loss: 2.715634954775938

Epoch: 350| Step: 0
Training loss: 0.571055359600258
Validation loss: 2.703366447058558

Epoch: 6| Step: 1
Training loss: 0.352137635584235
Validation loss: 2.762155256437421

Epoch: 6| Step: 2
Training loss: 0.8807916720945964
Validation loss: 2.7674674813124116

Epoch: 6| Step: 3
Training loss: 0.4459005121023245
Validation loss: 2.7536284105906446

Epoch: 6| Step: 4
Training loss: 0.5699271899283369
Validation loss: 2.766581712896862

Epoch: 6| Step: 5
Training loss: 0.3227908853419909
Validation loss: 2.771349526606786

Epoch: 6| Step: 6
Training loss: 0.4222646609144471
Validation loss: 2.7486772679514537

Epoch: 6| Step: 7
Training loss: 0.5688458225728225
Validation loss: 2.770027385225127

Epoch: 6| Step: 8
Training loss: 0.5855680445330103
Validation loss: 2.7376771297659754

Epoch: 6| Step: 9
Training loss: 0.4502600501261054
Validation loss: 2.7379529523111636

Epoch: 6| Step: 10
Training loss: 0.3002049262766564
Validation loss: 2.781397526289485

Epoch: 6| Step: 11
Training loss: 0.3893825034617161
Validation loss: 2.689477680789541

Epoch: 6| Step: 12
Training loss: 0.39324082953060485
Validation loss: 2.700312582807021

Epoch: 6| Step: 13
Training loss: 0.6184838599224628
Validation loss: 2.6982746156834825

Epoch: 351| Step: 0
Training loss: 0.5387739155411012
Validation loss: 2.6729077133619445

Epoch: 6| Step: 1
Training loss: 0.36816309111692147
Validation loss: 2.6984100528890176

Epoch: 6| Step: 2
Training loss: 0.4367199824389161
Validation loss: 2.7928004074048305

Epoch: 6| Step: 3
Training loss: 0.3481778721406951
Validation loss: 2.7580076442185644

Epoch: 6| Step: 4
Training loss: 0.42783229177432647
Validation loss: 2.7040528338610867

Epoch: 6| Step: 5
Training loss: 0.4042007958694071
Validation loss: 2.7921410532373723

Epoch: 6| Step: 6
Training loss: 0.42964376747221544
Validation loss: 2.7636836219061673

Epoch: 6| Step: 7
Training loss: 0.6169843218556529
Validation loss: 2.7516128116638616

Epoch: 6| Step: 8
Training loss: 0.7842933125913264
Validation loss: 2.785627342213436

Epoch: 6| Step: 9
Training loss: 0.37551113897429783
Validation loss: 2.731683521796736

Epoch: 6| Step: 10
Training loss: 0.5399460393382935
Validation loss: 2.6493462622900914

Epoch: 6| Step: 11
Training loss: 0.42241588110645967
Validation loss: 2.683832253301819

Epoch: 6| Step: 12
Training loss: 0.4539127408481117
Validation loss: 2.754658062987295

Epoch: 6| Step: 13
Training loss: 0.5810352995386748
Validation loss: 2.700741049243253

Epoch: 352| Step: 0
Training loss: 0.3869521660025574
Validation loss: 2.694279569538809

Epoch: 6| Step: 1
Training loss: 0.5081371150150245
Validation loss: 2.6212203198500315

Epoch: 6| Step: 2
Training loss: 0.31595311861079234
Validation loss: 2.6474945130019685

Epoch: 6| Step: 3
Training loss: 0.43114969980675566
Validation loss: 2.6825991901784123

Epoch: 6| Step: 4
Training loss: 0.36702566435726297
Validation loss: 2.736594674313074

Epoch: 6| Step: 5
Training loss: 0.4171159547185724
Validation loss: 2.725880389070288

Epoch: 6| Step: 6
Training loss: 0.5464504774049832
Validation loss: 2.671959635860833

Epoch: 6| Step: 7
Training loss: 0.42266446879464276
Validation loss: 2.7646760336180107

Epoch: 6| Step: 8
Training loss: 0.9009042462349116
Validation loss: 2.636950326804921

Epoch: 6| Step: 9
Training loss: 0.3987721926094986
Validation loss: 2.7000558294010757

Epoch: 6| Step: 10
Training loss: 0.43258486039255845
Validation loss: 2.6694855890489415

Epoch: 6| Step: 11
Training loss: 0.6568987682191029
Validation loss: 2.6602640526914847

Epoch: 6| Step: 12
Training loss: 0.48053061854550533
Validation loss: 2.7424537840953613

Epoch: 6| Step: 13
Training loss: 0.3482312045074334
Validation loss: 2.6472849405706143

Epoch: 353| Step: 0
Training loss: 0.3885171476848625
Validation loss: 2.763288815104855

Epoch: 6| Step: 1
Training loss: 0.772074567810576
Validation loss: 2.6541124307389947

Epoch: 6| Step: 2
Training loss: 0.4396348535107571
Validation loss: 2.6688497270090807

Epoch: 6| Step: 3
Training loss: 0.6115234599178947
Validation loss: 2.7728027047102826

Epoch: 6| Step: 4
Training loss: 0.44839722522286257
Validation loss: 2.6760621454789977

Epoch: 6| Step: 5
Training loss: 0.38850514271792325
Validation loss: 2.692674283686108

Epoch: 6| Step: 6
Training loss: 0.44986678111885736
Validation loss: 2.7434490667367912

Epoch: 6| Step: 7
Training loss: 0.38884991732480345
Validation loss: 2.716631425636769

Epoch: 6| Step: 8
Training loss: 0.2714760044920665
Validation loss: 2.7047701553593706

Epoch: 6| Step: 9
Training loss: 0.5613763500461556
Validation loss: 2.6612890728443848

Epoch: 6| Step: 10
Training loss: 0.2991181007606648
Validation loss: 2.795282802207246

Epoch: 6| Step: 11
Training loss: 0.5017917239978815
Validation loss: 2.682977974997824

Epoch: 6| Step: 12
Training loss: 0.5575590888386085
Validation loss: 2.6608943652727857

Epoch: 6| Step: 13
Training loss: 0.6372750783080935
Validation loss: 2.687315039960519

Epoch: 354| Step: 0
Training loss: 0.47860309035016446
Validation loss: 2.7425065104089392

Epoch: 6| Step: 1
Training loss: 0.7271408732325887
Validation loss: 2.7022531532995977

Epoch: 6| Step: 2
Training loss: 0.45265867638851154
Validation loss: 2.7416874573642986

Epoch: 6| Step: 3
Training loss: 0.40990814697822453
Validation loss: 2.768149321233849

Epoch: 6| Step: 4
Training loss: 0.43927310223257665
Validation loss: 2.7199768279995946

Epoch: 6| Step: 5
Training loss: 0.4425207769236054
Validation loss: 2.7352610433160485

Epoch: 6| Step: 6
Training loss: 0.35952935842905875
Validation loss: 2.677858267713637

Epoch: 6| Step: 7
Training loss: 0.5587674917773008
Validation loss: 2.7343835885049272

Epoch: 6| Step: 8
Training loss: 0.5221931127569601
Validation loss: 2.7454272890852773

Epoch: 6| Step: 9
Training loss: 0.5098187941377444
Validation loss: 2.690819678682958

Epoch: 6| Step: 10
Training loss: 0.6791872397819225
Validation loss: 2.646302119099045

Epoch: 6| Step: 11
Training loss: 0.7401130194316863
Validation loss: 2.710797191730358

Epoch: 6| Step: 12
Training loss: 0.5128011539745291
Validation loss: 2.6116672049397893

Epoch: 6| Step: 13
Training loss: 0.31549409380038046
Validation loss: 2.7097855024858375

Epoch: 355| Step: 0
Training loss: 0.44311740338764083
Validation loss: 2.7515839003467772

Epoch: 6| Step: 1
Training loss: 0.5351880753235742
Validation loss: 2.6741211728031904

Epoch: 6| Step: 2
Training loss: 0.45834660149645245
Validation loss: 2.783263131548846

Epoch: 6| Step: 3
Training loss: 0.4758785843530072
Validation loss: 2.8220306967488034

Epoch: 6| Step: 4
Training loss: 0.35143182233185705
Validation loss: 2.6335379848952916

Epoch: 6| Step: 5
Training loss: 0.33065595216938676
Validation loss: 2.6642947575817333

Epoch: 6| Step: 6
Training loss: 0.4304766257893129
Validation loss: 2.7249741687191955

Epoch: 6| Step: 7
Training loss: 0.4307250587362818
Validation loss: 2.6686804191339193

Epoch: 6| Step: 8
Training loss: 0.4254510631660522
Validation loss: 2.669207753002101

Epoch: 6| Step: 9
Training loss: 0.8641493562223295
Validation loss: 2.7543323304469465

Epoch: 6| Step: 10
Training loss: 0.5692543507871691
Validation loss: 2.7483710174876377

Epoch: 6| Step: 11
Training loss: 0.44028458668564496
Validation loss: 2.7844531726531225

Epoch: 6| Step: 12
Training loss: 0.30208715348733095
Validation loss: 2.70466647728548

Epoch: 6| Step: 13
Training loss: 0.3393498481998579
Validation loss: 2.6804228460461155

Epoch: 356| Step: 0
Training loss: 0.3937864544054335
Validation loss: 2.7379037086165856

Epoch: 6| Step: 1
Training loss: 0.3631611287040662
Validation loss: 2.6958194716587034

Epoch: 6| Step: 2
Training loss: 0.3557074238102455
Validation loss: 2.7186416224367127

Epoch: 6| Step: 3
Training loss: 0.6576232166654026
Validation loss: 2.639950351946643

Epoch: 6| Step: 4
Training loss: 0.4519745428471997
Validation loss: 2.7330357641584846

Epoch: 6| Step: 5
Training loss: 0.3563652889356266
Validation loss: 2.6357102488160584

Epoch: 6| Step: 6
Training loss: 0.7879119264960027
Validation loss: 2.748421345934908

Epoch: 6| Step: 7
Training loss: 0.5430562065550969
Validation loss: 2.684095592116386

Epoch: 6| Step: 8
Training loss: 0.30687019841619495
Validation loss: 2.7421548231012824

Epoch: 6| Step: 9
Training loss: 0.3416637597406207
Validation loss: 2.6641848956468754

Epoch: 6| Step: 10
Training loss: 0.2939201166754259
Validation loss: 2.658647793872478

Epoch: 6| Step: 11
Training loss: 0.46801627272860136
Validation loss: 2.6764017392716473

Epoch: 6| Step: 12
Training loss: 0.4227486148114467
Validation loss: 2.6751444780543654

Epoch: 6| Step: 13
Training loss: 0.21262177281058298
Validation loss: 2.7201740218690795

Epoch: 357| Step: 0
Training loss: 0.6207316560711859
Validation loss: 2.810220069786275

Epoch: 6| Step: 1
Training loss: 0.33717406924052734
Validation loss: 2.6873687741674304

Epoch: 6| Step: 2
Training loss: 0.43775173165781106
Validation loss: 2.715098139052899

Epoch: 6| Step: 3
Training loss: 0.7869713901326586
Validation loss: 2.6800165669441585

Epoch: 6| Step: 4
Training loss: 0.6089352708439205
Validation loss: 2.6326519457784743

Epoch: 6| Step: 5
Training loss: 0.3381498588195646
Validation loss: 2.6994429484626643

Epoch: 6| Step: 6
Training loss: 0.3878748787779254
Validation loss: 2.7447390952435264

Epoch: 6| Step: 7
Training loss: 0.36778780381904813
Validation loss: 2.698700652243353

Epoch: 6| Step: 8
Training loss: 0.5534582621181796
Validation loss: 2.771605223981864

Epoch: 6| Step: 9
Training loss: 0.7806002012640078
Validation loss: 2.6838916093161544

Epoch: 6| Step: 10
Training loss: 0.5006495071870448
Validation loss: 2.6649769530811698

Epoch: 6| Step: 11
Training loss: 0.4285840691819693
Validation loss: 2.6960267230972432

Epoch: 6| Step: 12
Training loss: 0.3450918018825309
Validation loss: 2.71154564330875

Epoch: 6| Step: 13
Training loss: 0.29476899485579017
Validation loss: 2.706674835830099

Epoch: 358| Step: 0
Training loss: 0.3464659448343052
Validation loss: 2.7300590386021204

Epoch: 6| Step: 1
Training loss: 0.40080225184925405
Validation loss: 2.7802656910766834

Epoch: 6| Step: 2
Training loss: 0.4040932257609573
Validation loss: 2.7155754146285074

Epoch: 6| Step: 3
Training loss: 0.4683273317194583
Validation loss: 2.6869575781095736

Epoch: 6| Step: 4
Training loss: 0.4733212734362828
Validation loss: 2.62005740284826

Epoch: 6| Step: 5
Training loss: 0.899334070415586
Validation loss: 2.6941603994802996

Epoch: 6| Step: 6
Training loss: 0.3763147393796567
Validation loss: 2.7232726032048964

Epoch: 6| Step: 7
Training loss: 0.4754731594837721
Validation loss: 2.8152725752790957

Epoch: 6| Step: 8
Training loss: 0.27089407435329704
Validation loss: 2.809539925582529

Epoch: 6| Step: 9
Training loss: 0.6082022214281332
Validation loss: 2.7663869580430456

Epoch: 6| Step: 10
Training loss: 0.47763360146687084
Validation loss: 2.7693558867424937

Epoch: 6| Step: 11
Training loss: 0.41021125061382396
Validation loss: 2.7677086346422364

Epoch: 6| Step: 12
Training loss: 0.47917501988247957
Validation loss: 2.7458852125330946

Epoch: 6| Step: 13
Training loss: 0.5036884103140324
Validation loss: 2.737846945923414

Epoch: 359| Step: 0
Training loss: 0.5112329171458204
Validation loss: 2.706533117366422

Epoch: 6| Step: 1
Training loss: 0.31121562231709826
Validation loss: 2.791674775258904

Epoch: 6| Step: 2
Training loss: 0.3769458710758184
Validation loss: 2.7806089426818716

Epoch: 6| Step: 3
Training loss: 0.5055062375914826
Validation loss: 2.7868076759083373

Epoch: 6| Step: 4
Training loss: 0.4126873031828343
Validation loss: 2.781011685508823

Epoch: 6| Step: 5
Training loss: 0.3569263713225978
Validation loss: 2.7989295218806416

Epoch: 6| Step: 6
Training loss: 0.3941003315710044
Validation loss: 2.8125200624103597

Epoch: 6| Step: 7
Training loss: 0.30003923070222727
Validation loss: 2.737082675727219

Epoch: 6| Step: 8
Training loss: 0.3698447440117523
Validation loss: 2.794748176030634

Epoch: 6| Step: 9
Training loss: 0.5200983551890529
Validation loss: 2.750207633069528

Epoch: 6| Step: 10
Training loss: 0.9081063824062507
Validation loss: 2.7442303010490057

Epoch: 6| Step: 11
Training loss: 0.44932760495393437
Validation loss: 2.7310098158374663

Epoch: 6| Step: 12
Training loss: 0.328753131282239
Validation loss: 2.7242839222347097

Epoch: 6| Step: 13
Training loss: 0.4198622550336054
Validation loss: 2.6939598928107817

Epoch: 360| Step: 0
Training loss: 0.5331250367606218
Validation loss: 2.7276054799458724

Epoch: 6| Step: 1
Training loss: 0.38553065040716766
Validation loss: 2.780636837694655

Epoch: 6| Step: 2
Training loss: 0.353223627377568
Validation loss: 2.733223212939161

Epoch: 6| Step: 3
Training loss: 0.4031532440345518
Validation loss: 2.7363821455900674

Epoch: 6| Step: 4
Training loss: 0.41429187611227997
Validation loss: 2.796921585803213

Epoch: 6| Step: 5
Training loss: 0.5959399143564159
Validation loss: 2.732173607549595

Epoch: 6| Step: 6
Training loss: 0.42066223172471223
Validation loss: 2.72583862430903

Epoch: 6| Step: 7
Training loss: 0.4318038493725618
Validation loss: 2.7236389400814005

Epoch: 6| Step: 8
Training loss: 0.5346029163657808
Validation loss: 2.7320737619267756

Epoch: 6| Step: 9
Training loss: 0.8106757004175952
Validation loss: 2.72974638326772

Epoch: 6| Step: 10
Training loss: 0.3849777953445175
Validation loss: 2.721156637272082

Epoch: 6| Step: 11
Training loss: 0.3527138189702995
Validation loss: 2.7312398466595114

Epoch: 6| Step: 12
Training loss: 0.3626310210387222
Validation loss: 2.7524820743985337

Epoch: 6| Step: 13
Training loss: 0.5553369346914412
Validation loss: 2.701160415253657

Epoch: 361| Step: 0
Training loss: 0.31762328208074436
Validation loss: 2.7345418388693967

Epoch: 6| Step: 1
Training loss: 0.3637407739524517
Validation loss: 2.6945440403948195

Epoch: 6| Step: 2
Training loss: 0.26339865763560427
Validation loss: 2.7958487931424347

Epoch: 6| Step: 3
Training loss: 0.5062445275281716
Validation loss: 2.7509580157233335

Epoch: 6| Step: 4
Training loss: 0.32038225019290684
Validation loss: 2.7293231181565574

Epoch: 6| Step: 5
Training loss: 0.532449909907869
Validation loss: 2.7571140589987775

Epoch: 6| Step: 6
Training loss: 0.24723991031329112
Validation loss: 2.746773257232001

Epoch: 6| Step: 7
Training loss: 0.3377102938451384
Validation loss: 2.7331875793238827

Epoch: 6| Step: 8
Training loss: 0.48478121797749285
Validation loss: 2.7437344903297567

Epoch: 6| Step: 9
Training loss: 0.3231103749350357
Validation loss: 2.7684011373038313

Epoch: 6| Step: 10
Training loss: 0.7655516608787699
Validation loss: 2.7783861023991463

Epoch: 6| Step: 11
Training loss: 0.4130809053155094
Validation loss: 2.7125022981929856

Epoch: 6| Step: 12
Training loss: 0.5776657909774453
Validation loss: 2.715394927866524

Epoch: 6| Step: 13
Training loss: 0.39909101633753574
Validation loss: 2.8370589603925853

Epoch: 362| Step: 0
Training loss: 0.4271871471612864
Validation loss: 2.7380298130835596

Epoch: 6| Step: 1
Training loss: 0.5638532255615785
Validation loss: 2.814839922665646

Epoch: 6| Step: 2
Training loss: 0.7689143772699589
Validation loss: 2.774337378998257

Epoch: 6| Step: 3
Training loss: 0.48437539992777406
Validation loss: 2.796659138055185

Epoch: 6| Step: 4
Training loss: 0.5288894042089144
Validation loss: 2.7557180806866266

Epoch: 6| Step: 5
Training loss: 0.3873555883373536
Validation loss: 2.703442924193339

Epoch: 6| Step: 6
Training loss: 0.3699044091553584
Validation loss: 2.7403608652304916

Epoch: 6| Step: 7
Training loss: 0.5606130634002484
Validation loss: 2.779161747971452

Epoch: 6| Step: 8
Training loss: 0.5494441040808576
Validation loss: 2.817962865327141

Epoch: 6| Step: 9
Training loss: 0.41944107208868164
Validation loss: 2.7320180707727633

Epoch: 6| Step: 10
Training loss: 0.39307724837046076
Validation loss: 2.7698999902824264

Epoch: 6| Step: 11
Training loss: 0.423459925884683
Validation loss: 2.7322596914728177

Epoch: 6| Step: 12
Training loss: 0.3347944062545594
Validation loss: 2.7543035703058396

Epoch: 6| Step: 13
Training loss: 0.29359184126464416
Validation loss: 2.746634360033915

Epoch: 363| Step: 0
Training loss: 0.49601767549918585
Validation loss: 2.800143159885014

Epoch: 6| Step: 1
Training loss: 0.7692977628511969
Validation loss: 2.8372090329116655

Epoch: 6| Step: 2
Training loss: 0.41415195578399217
Validation loss: 2.7226950279185305

Epoch: 6| Step: 3
Training loss: 0.40031806474401804
Validation loss: 2.7543825788215486

Epoch: 6| Step: 4
Training loss: 0.549777855226826
Validation loss: 2.7688486596893425

Epoch: 6| Step: 5
Training loss: 0.4160242572300755
Validation loss: 2.7706409306279376

Epoch: 6| Step: 6
Training loss: 0.489866673543085
Validation loss: 2.7617545046868157

Epoch: 6| Step: 7
Training loss: 0.37110125885443856
Validation loss: 2.7019522002514864

Epoch: 6| Step: 8
Training loss: 0.5680830241056928
Validation loss: 2.8067570296968793

Epoch: 6| Step: 9
Training loss: 0.5282231662865559
Validation loss: 2.717697963107525

Epoch: 6| Step: 10
Training loss: 0.4135113232560206
Validation loss: 2.739218848365557

Epoch: 6| Step: 11
Training loss: 0.5926826570935111
Validation loss: 2.739238221704213

Epoch: 6| Step: 12
Training loss: 0.44016696173458086
Validation loss: 2.807796784337323

Epoch: 6| Step: 13
Training loss: 0.35426539793315565
Validation loss: 2.7619305016444935

Epoch: 364| Step: 0
Training loss: 0.3631665038323938
Validation loss: 2.8010881398579026

Epoch: 6| Step: 1
Training loss: 0.7920819665561571
Validation loss: 2.6955295198947278

Epoch: 6| Step: 2
Training loss: 0.3771538471799973
Validation loss: 2.692403430511559

Epoch: 6| Step: 3
Training loss: 0.3762144252840007
Validation loss: 2.809847782114227

Epoch: 6| Step: 4
Training loss: 0.4004921016962031
Validation loss: 2.768975658133417

Epoch: 6| Step: 5
Training loss: 0.44154819805527906
Validation loss: 2.8085443583439886

Epoch: 6| Step: 6
Training loss: 0.357115776023004
Validation loss: 2.709033352299798

Epoch: 6| Step: 7
Training loss: 0.4834488197042
Validation loss: 2.7280985122682386

Epoch: 6| Step: 8
Training loss: 0.46155469597254206
Validation loss: 2.755238485381642

Epoch: 6| Step: 9
Training loss: 0.38454055012256916
Validation loss: 2.861306099486829

Epoch: 6| Step: 10
Training loss: 0.3135325064012769
Validation loss: 2.755587731375636

Epoch: 6| Step: 11
Training loss: 0.4108170408934928
Validation loss: 2.7192058108060153

Epoch: 6| Step: 12
Training loss: 0.40374873500661235
Validation loss: 2.7542959095404025

Epoch: 6| Step: 13
Training loss: 0.3742101616560805
Validation loss: 2.71095177667763

Epoch: 365| Step: 0
Training loss: 0.42109841820105653
Validation loss: 2.681520819158358

Epoch: 6| Step: 1
Training loss: 0.5224059459231063
Validation loss: 2.8756723447043284

Epoch: 6| Step: 2
Training loss: 0.3680223349007837
Validation loss: 2.798191833220538

Epoch: 6| Step: 3
Training loss: 0.3173032103263098
Validation loss: 2.721152650712416

Epoch: 6| Step: 4
Training loss: 0.3348572684588399
Validation loss: 2.7445331333500333

Epoch: 6| Step: 5
Training loss: 0.2245806136582932
Validation loss: 2.690843424568932

Epoch: 6| Step: 6
Training loss: 0.41724391727230736
Validation loss: 2.7721777978861413

Epoch: 6| Step: 7
Training loss: 0.47846928586214155
Validation loss: 2.701360144757802

Epoch: 6| Step: 8
Training loss: 0.4573143954121108
Validation loss: 2.755764129384197

Epoch: 6| Step: 9
Training loss: 0.4331386342730685
Validation loss: 2.706389101020103

Epoch: 6| Step: 10
Training loss: 0.37838516585395765
Validation loss: 2.7255437308487496

Epoch: 6| Step: 11
Training loss: 0.6960105606530281
Validation loss: 2.7893868621931794

Epoch: 6| Step: 12
Training loss: 0.33494603426952085
Validation loss: 2.7550019377409116

Epoch: 6| Step: 13
Training loss: 0.8401015839573481
Validation loss: 2.6872592492906886

Epoch: 366| Step: 0
Training loss: 0.3859003442956002
Validation loss: 2.698640105315937

Epoch: 6| Step: 1
Training loss: 0.36408429960546246
Validation loss: 2.688608192429739

Epoch: 6| Step: 2
Training loss: 0.4959029183592852
Validation loss: 2.7838749731634596

Epoch: 6| Step: 3
Training loss: 0.4606359432892583
Validation loss: 2.6753536875885486

Epoch: 6| Step: 4
Training loss: 0.46646347269949967
Validation loss: 2.771235147659221

Epoch: 6| Step: 5
Training loss: 0.43451553170897506
Validation loss: 2.6776519399132153

Epoch: 6| Step: 6
Training loss: 0.5045531504471349
Validation loss: 2.725989236838871

Epoch: 6| Step: 7
Training loss: 0.3718587519197555
Validation loss: 2.751599078104063

Epoch: 6| Step: 8
Training loss: 0.28190685762509693
Validation loss: 2.7255333503908576

Epoch: 6| Step: 9
Training loss: 0.5424069578835713
Validation loss: 2.725496187444304

Epoch: 6| Step: 10
Training loss: 0.7940764184037473
Validation loss: 2.7342552231485904

Epoch: 6| Step: 11
Training loss: 0.41195538432476375
Validation loss: 2.7523717478370218

Epoch: 6| Step: 12
Training loss: 0.3404954493305378
Validation loss: 2.7478686945740396

Epoch: 6| Step: 13
Training loss: 0.5315194848903902
Validation loss: 2.713766507274688

Epoch: 367| Step: 0
Training loss: 0.40319343769607596
Validation loss: 2.7758819410072095

Epoch: 6| Step: 1
Training loss: 0.8745214652365515
Validation loss: 2.7229809341687794

Epoch: 6| Step: 2
Training loss: 0.3024812193628647
Validation loss: 2.763129248665787

Epoch: 6| Step: 3
Training loss: 0.3497560715451703
Validation loss: 2.802878473810921

Epoch: 6| Step: 4
Training loss: 0.3535685631331773
Validation loss: 2.711964569335787

Epoch: 6| Step: 5
Training loss: 0.4972163437413542
Validation loss: 2.807036341637696

Epoch: 6| Step: 6
Training loss: 0.4385560437320198
Validation loss: 2.780826150551279

Epoch: 6| Step: 7
Training loss: 0.2913894172899938
Validation loss: 2.7243325515547427

Epoch: 6| Step: 8
Training loss: 0.5445827946834143
Validation loss: 2.7343297318844035

Epoch: 6| Step: 9
Training loss: 0.33181577310260907
Validation loss: 2.760327166180016

Epoch: 6| Step: 10
Training loss: 0.4821955655820839
Validation loss: 2.6812714102363735

Epoch: 6| Step: 11
Training loss: 0.444720728337113
Validation loss: 2.741278792156297

Epoch: 6| Step: 12
Training loss: 0.5665335939569174
Validation loss: 2.6951526244288386

Epoch: 6| Step: 13
Training loss: 0.3275639755974214
Validation loss: 2.7000942181407783

Epoch: 368| Step: 0
Training loss: 0.3709137329354642
Validation loss: 2.784990445730736

Epoch: 6| Step: 1
Training loss: 0.37743086510233903
Validation loss: 2.7124415905548327

Epoch: 6| Step: 2
Training loss: 0.372010293760468
Validation loss: 2.7100349484896347

Epoch: 6| Step: 3
Training loss: 0.4338290976264942
Validation loss: 2.747086361393956

Epoch: 6| Step: 4
Training loss: 0.40175463314031623
Validation loss: 2.775635542276541

Epoch: 6| Step: 5
Training loss: 0.42279045244857544
Validation loss: 2.7162910683493

Epoch: 6| Step: 6
Training loss: 0.3532911399324197
Validation loss: 2.722395816499136

Epoch: 6| Step: 7
Training loss: 0.31873282077720233
Validation loss: 2.7642703716922026

Epoch: 6| Step: 8
Training loss: 0.5364400959309862
Validation loss: 2.706961318484797

Epoch: 6| Step: 9
Training loss: 0.36402861310560697
Validation loss: 2.6407898921007704

Epoch: 6| Step: 10
Training loss: 0.7185419859700661
Validation loss: 2.6458152009437783

Epoch: 6| Step: 11
Training loss: 0.4563396143760812
Validation loss: 2.727922502993805

Epoch: 6| Step: 12
Training loss: 0.6303421120219749
Validation loss: 2.6007587157251337

Epoch: 6| Step: 13
Training loss: 0.3111471456613484
Validation loss: 2.780088460736065

Epoch: 369| Step: 0
Training loss: 0.4729145699789255
Validation loss: 2.6918214386375725

Epoch: 6| Step: 1
Training loss: 0.2798612800615514
Validation loss: 2.7790178063677695

Epoch: 6| Step: 2
Training loss: 0.3978640974314573
Validation loss: 2.6741778616603025

Epoch: 6| Step: 3
Training loss: 0.5988334083199642
Validation loss: 2.698284372042983

Epoch: 6| Step: 4
Training loss: 0.24825303829077938
Validation loss: 2.7139439690357334

Epoch: 6| Step: 5
Training loss: 0.39212896738547326
Validation loss: 2.700505356236946

Epoch: 6| Step: 6
Training loss: 0.43062795543902205
Validation loss: 2.73336632425666

Epoch: 6| Step: 7
Training loss: 0.5128564199995843
Validation loss: 2.6859479163150777

Epoch: 6| Step: 8
Training loss: 0.4221939364831381
Validation loss: 2.8444042501200837

Epoch: 6| Step: 9
Training loss: 0.3201429569655257
Validation loss: 2.7826809148933944

Epoch: 6| Step: 10
Training loss: 0.42410014691713466
Validation loss: 2.753271728716225

Epoch: 6| Step: 11
Training loss: 0.637248164343781
Validation loss: 2.6778363505913694

Epoch: 6| Step: 12
Training loss: 0.7179866136854419
Validation loss: 2.755103937970395

Epoch: 6| Step: 13
Training loss: 0.3232115878001597
Validation loss: 2.7257962612133455

Epoch: 370| Step: 0
Training loss: 0.5213931571818708
Validation loss: 2.6817497421998993

Epoch: 6| Step: 1
Training loss: 0.43247013735898376
Validation loss: 2.7651356697024396

Epoch: 6| Step: 2
Training loss: 0.4744500728806118
Validation loss: 2.8344614971159174

Epoch: 6| Step: 3
Training loss: 0.34880117416927897
Validation loss: 2.7763863731827905

Epoch: 6| Step: 4
Training loss: 0.5383148260399605
Validation loss: 2.782745002386362

Epoch: 6| Step: 5
Training loss: 0.37126107709908723
Validation loss: 2.7437983144389073

Epoch: 6| Step: 6
Training loss: 0.6147149693955224
Validation loss: 2.783703625387948

Epoch: 6| Step: 7
Training loss: 0.4035882313964296
Validation loss: 2.6751824295963997

Epoch: 6| Step: 8
Training loss: 0.4443507936111082
Validation loss: 2.7400270593425464

Epoch: 6| Step: 9
Training loss: 0.3486855517762194
Validation loss: 2.739694619668277

Epoch: 6| Step: 10
Training loss: 0.4462912327820076
Validation loss: 2.7172076501843163

Epoch: 6| Step: 11
Training loss: 0.47055649748971506
Validation loss: 2.738179000418364

Epoch: 6| Step: 12
Training loss: 0.5231183345830356
Validation loss: 2.7283283406932206

Epoch: 6| Step: 13
Training loss: 0.7078990773857389
Validation loss: 2.751402439514337

Epoch: 371| Step: 0
Training loss: 0.4359202815658121
Validation loss: 2.7983584456900767

Epoch: 6| Step: 1
Training loss: 0.5525127815908502
Validation loss: 2.7937720364036487

Epoch: 6| Step: 2
Training loss: 0.4086911510252526
Validation loss: 2.761530580634375

Epoch: 6| Step: 3
Training loss: 0.3451770939885914
Validation loss: 2.704790855238547

Epoch: 6| Step: 4
Training loss: 0.3844796100401339
Validation loss: 2.6858796254554913

Epoch: 6| Step: 5
Training loss: 0.3063524678137892
Validation loss: 2.712700980222175

Epoch: 6| Step: 6
Training loss: 0.3513251032920951
Validation loss: 2.7673175611038086

Epoch: 6| Step: 7
Training loss: 0.35986779467626284
Validation loss: 2.793263012160976

Epoch: 6| Step: 8
Training loss: 0.3259978144022455
Validation loss: 2.725729960043499

Epoch: 6| Step: 9
Training loss: 0.6967794181723347
Validation loss: 2.694543022851912

Epoch: 6| Step: 10
Training loss: 0.4274209847124604
Validation loss: 2.8432620401899253

Epoch: 6| Step: 11
Training loss: 0.2824815172715223
Validation loss: 2.6997616521395065

Epoch: 6| Step: 12
Training loss: 0.34629635101238787
Validation loss: 2.7740584703612194

Epoch: 6| Step: 13
Training loss: 0.31119656529259515
Validation loss: 2.755162696003704

Epoch: 372| Step: 0
Training loss: 0.36570495236662875
Validation loss: 2.7931518067878676

Epoch: 6| Step: 1
Training loss: 0.3338731837200033
Validation loss: 2.733694736693678

Epoch: 6| Step: 2
Training loss: 0.38490405230937313
Validation loss: 2.7970361006103537

Epoch: 6| Step: 3
Training loss: 0.3078196752263804
Validation loss: 2.7735996252679693

Epoch: 6| Step: 4
Training loss: 0.629184992841214
Validation loss: 2.6943206436407108

Epoch: 6| Step: 5
Training loss: 0.2857631600037049
Validation loss: 2.733115700066864

Epoch: 6| Step: 6
Training loss: 0.4883098899071402
Validation loss: 2.7452670680343068

Epoch: 6| Step: 7
Training loss: 0.4237275597586105
Validation loss: 2.7018273386478624

Epoch: 6| Step: 8
Training loss: 0.5698078221803478
Validation loss: 2.714305723745166

Epoch: 6| Step: 9
Training loss: 0.4668392337749411
Validation loss: 2.7966174783196447

Epoch: 6| Step: 10
Training loss: 0.40951779037416014
Validation loss: 2.7697209632651414

Epoch: 6| Step: 11
Training loss: 0.5045376451830682
Validation loss: 2.7518802630469255

Epoch: 6| Step: 12
Training loss: 0.44758428025037483
Validation loss: 2.784094698690455

Epoch: 6| Step: 13
Training loss: 0.35091134273642743
Validation loss: 2.748060843209214

Epoch: 373| Step: 0
Training loss: 0.3652046313898826
Validation loss: 2.698282906750487

Epoch: 6| Step: 1
Training loss: 0.385854120552787
Validation loss: 2.730863179763634

Epoch: 6| Step: 2
Training loss: 0.4731327523890195
Validation loss: 2.7485325539326375

Epoch: 6| Step: 3
Training loss: 0.417913789789954
Validation loss: 2.816014234796764

Epoch: 6| Step: 4
Training loss: 0.3909186213361871
Validation loss: 2.8054763548806454

Epoch: 6| Step: 5
Training loss: 0.34721425709595527
Validation loss: 2.8366938091313845

Epoch: 6| Step: 6
Training loss: 0.3098123488719234
Validation loss: 2.7152833285414557

Epoch: 6| Step: 7
Training loss: 0.5580752440484297
Validation loss: 2.7444036717438527

Epoch: 6| Step: 8
Training loss: 0.5527935737746994
Validation loss: 2.771656134106169

Epoch: 6| Step: 9
Training loss: 0.3632473468342323
Validation loss: 2.691171001899629

Epoch: 6| Step: 10
Training loss: 0.40843192446229676
Validation loss: 2.7366895779553957

Epoch: 6| Step: 11
Training loss: 0.2804477694429001
Validation loss: 2.7027245814816827

Epoch: 6| Step: 12
Training loss: 0.4947772542627952
Validation loss: 2.663443313491434

Epoch: 6| Step: 13
Training loss: 0.7306143875591355
Validation loss: 2.7538046166534333

Epoch: 374| Step: 0
Training loss: 0.3262478403041871
Validation loss: 2.751743991865926

Epoch: 6| Step: 1
Training loss: 0.4848452715491793
Validation loss: 2.743109950935998

Epoch: 6| Step: 2
Training loss: 0.7728407898818016
Validation loss: 2.6854134377360754

Epoch: 6| Step: 3
Training loss: 0.3608318322806085
Validation loss: 2.7448215856978435

Epoch: 6| Step: 4
Training loss: 0.42039931014155907
Validation loss: 2.755997864947071

Epoch: 6| Step: 5
Training loss: 0.5089044714601738
Validation loss: 2.706828936878755

Epoch: 6| Step: 6
Training loss: 0.48743842053904246
Validation loss: 2.735430704406683

Epoch: 6| Step: 7
Training loss: 0.39876251428273524
Validation loss: 2.7097818218068106

Epoch: 6| Step: 8
Training loss: 0.45126173437400224
Validation loss: 2.7842643490321355

Epoch: 6| Step: 9
Training loss: 0.455841341291217
Validation loss: 2.7114094406763076

Epoch: 6| Step: 10
Training loss: 0.3754962181175153
Validation loss: 2.72020856237682

Epoch: 6| Step: 11
Training loss: 0.37970170359476735
Validation loss: 2.7807750510682365

Epoch: 6| Step: 12
Training loss: 0.4438654997777674
Validation loss: 2.7903347871192015

Epoch: 6| Step: 13
Training loss: 0.37075075058658524
Validation loss: 2.802439051364354

Epoch: 375| Step: 0
Training loss: 0.409598343471627
Validation loss: 2.8015168526159777

Epoch: 6| Step: 1
Training loss: 0.5098694443490036
Validation loss: 2.8210811254471877

Epoch: 6| Step: 2
Training loss: 0.3144649716627633
Validation loss: 2.8226420256024607

Epoch: 6| Step: 3
Training loss: 0.36764157403332753
Validation loss: 2.8021786376930966

Epoch: 6| Step: 4
Training loss: 0.38474682214947714
Validation loss: 2.7357773154971903

Epoch: 6| Step: 5
Training loss: 0.5312621732326858
Validation loss: 2.7877946923096997

Epoch: 6| Step: 6
Training loss: 0.29588228439708175
Validation loss: 2.7778038219714456

Epoch: 6| Step: 7
Training loss: 0.3534349697268684
Validation loss: 2.655722621848064

Epoch: 6| Step: 8
Training loss: 0.3917949703090386
Validation loss: 2.690821111121074

Epoch: 6| Step: 9
Training loss: 0.48564663979958383
Validation loss: 2.7106164454479886

Epoch: 6| Step: 10
Training loss: 0.3838552946835856
Validation loss: 2.751478707956419

Epoch: 6| Step: 11
Training loss: 0.39574393300161104
Validation loss: 2.7242377717112802

Epoch: 6| Step: 12
Training loss: 0.744575833790017
Validation loss: 2.7776791941845014

Epoch: 6| Step: 13
Training loss: 0.6331739923740042
Validation loss: 2.775270685391279

Epoch: 376| Step: 0
Training loss: 0.3996658837122774
Validation loss: 2.7727767515434305

Epoch: 6| Step: 1
Training loss: 0.5223739123729036
Validation loss: 2.711715381429359

Epoch: 6| Step: 2
Training loss: 0.3441699345693702
Validation loss: 2.7101553925635384

Epoch: 6| Step: 3
Training loss: 0.4780056474104661
Validation loss: 2.7366174131538683

Epoch: 6| Step: 4
Training loss: 0.36057762353780154
Validation loss: 2.7413776647339025

Epoch: 6| Step: 5
Training loss: 0.45345846599584044
Validation loss: 2.7131394926004986

Epoch: 6| Step: 6
Training loss: 0.4469325728776326
Validation loss: 2.7885783511686535

Epoch: 6| Step: 7
Training loss: 0.6906742811960006
Validation loss: 2.6557288612315175

Epoch: 6| Step: 8
Training loss: 0.30231012950927627
Validation loss: 2.665611316545911

Epoch: 6| Step: 9
Training loss: 0.33816693424936844
Validation loss: 2.7674053804969483

Epoch: 6| Step: 10
Training loss: 0.7334836054492906
Validation loss: 2.6657890922243666

Epoch: 6| Step: 11
Training loss: 0.3662656209172763
Validation loss: 2.7759296950517163

Epoch: 6| Step: 12
Training loss: 0.549243701785843
Validation loss: 2.728783549045602

Epoch: 6| Step: 13
Training loss: 0.6692182220877294
Validation loss: 2.7012834983300853

Epoch: 377| Step: 0
Training loss: 0.5585083262609225
Validation loss: 2.7206119431704434

Epoch: 6| Step: 1
Training loss: 0.5964792167675367
Validation loss: 2.7068143888933736

Epoch: 6| Step: 2
Training loss: 0.7799750797252247
Validation loss: 2.7238631563109905

Epoch: 6| Step: 3
Training loss: 0.39467089608273903
Validation loss: 2.76711876538103

Epoch: 6| Step: 4
Training loss: 0.3801512174512321
Validation loss: 2.7263060032851008

Epoch: 6| Step: 5
Training loss: 0.3787597294303716
Validation loss: 2.825871379337063

Epoch: 6| Step: 6
Training loss: 0.5079156330725042
Validation loss: 2.7741760130297304

Epoch: 6| Step: 7
Training loss: 0.2624309727192493
Validation loss: 2.749928719145843

Epoch: 6| Step: 8
Training loss: 0.43954141365719246
Validation loss: 2.758525320403732

Epoch: 6| Step: 9
Training loss: 0.4639001131920616
Validation loss: 2.7768978399401654

Epoch: 6| Step: 10
Training loss: 0.5425847843384923
Validation loss: 2.804368095664337

Epoch: 6| Step: 11
Training loss: 0.37521669961320336
Validation loss: 2.7044129436321027

Epoch: 6| Step: 12
Training loss: 0.41113708928799153
Validation loss: 2.7185507368823747

Epoch: 6| Step: 13
Training loss: 0.38155549816983625
Validation loss: 2.7126578553144864

Epoch: 378| Step: 0
Training loss: 0.32199494525099154
Validation loss: 2.753949695722422

Epoch: 6| Step: 1
Training loss: 0.3555018650601552
Validation loss: 2.747932494963629

Epoch: 6| Step: 2
Training loss: 0.5728581716557456
Validation loss: 2.7754866359496386

Epoch: 6| Step: 3
Training loss: 0.38374464248744555
Validation loss: 2.714548957609003

Epoch: 6| Step: 4
Training loss: 0.4597144306626405
Validation loss: 2.784621898580615

Epoch: 6| Step: 5
Training loss: 0.5925376460835333
Validation loss: 2.667111163545152

Epoch: 6| Step: 6
Training loss: 0.2932616867385527
Validation loss: 2.7480459423375394

Epoch: 6| Step: 7
Training loss: 0.42570057375866766
Validation loss: 2.7243831636324463

Epoch: 6| Step: 8
Training loss: 0.46410599835429306
Validation loss: 2.6999522352114487

Epoch: 6| Step: 9
Training loss: 0.24550979449580565
Validation loss: 2.7251249238056743

Epoch: 6| Step: 10
Training loss: 0.4729090873458202
Validation loss: 2.7160245600710273

Epoch: 6| Step: 11
Training loss: 0.353980901562604
Validation loss: 2.719431663793141

Epoch: 6| Step: 12
Training loss: 0.4463300957378332
Validation loss: 2.75376478332347

Epoch: 6| Step: 13
Training loss: 0.47296517105185104
Validation loss: 2.691934918440228

Epoch: 379| Step: 0
Training loss: 0.35859932323770655
Validation loss: 2.7396104663815484

Epoch: 6| Step: 1
Training loss: 0.7724002471886886
Validation loss: 2.7816426717897698

Epoch: 6| Step: 2
Training loss: 0.3667394461072113
Validation loss: 2.847061618420838

Epoch: 6| Step: 3
Training loss: 0.2553188642551394
Validation loss: 2.7715253802279864

Epoch: 6| Step: 4
Training loss: 0.3914719745329304
Validation loss: 2.71287082182447

Epoch: 6| Step: 5
Training loss: 0.27254561335599636
Validation loss: 2.7475758473991396

Epoch: 6| Step: 6
Training loss: 0.43181185540899175
Validation loss: 2.7933284501220457

Epoch: 6| Step: 7
Training loss: 0.44290251867474334
Validation loss: 2.796108503108235

Epoch: 6| Step: 8
Training loss: 0.41451465462753634
Validation loss: 2.764969110391078

Epoch: 6| Step: 9
Training loss: 0.4050475812559354
Validation loss: 2.7911463057986285

Epoch: 6| Step: 10
Training loss: 0.2673816516480419
Validation loss: 2.6686382803362165

Epoch: 6| Step: 11
Training loss: 0.35010871178104574
Validation loss: 2.6692122488648504

Epoch: 6| Step: 12
Training loss: 0.5146942697345008
Validation loss: 2.7545866862872765

Epoch: 6| Step: 13
Training loss: 0.44359867847011875
Validation loss: 2.732310345772872

Epoch: 380| Step: 0
Training loss: 0.43298434485134973
Validation loss: 2.7977186383354837

Epoch: 6| Step: 1
Training loss: 0.44570943642376026
Validation loss: 2.7944956911501677

Epoch: 6| Step: 2
Training loss: 0.3688317474982439
Validation loss: 2.7813811110549866

Epoch: 6| Step: 3
Training loss: 0.5569721506234665
Validation loss: 2.7635576815428107

Epoch: 6| Step: 4
Training loss: 0.4467990390533745
Validation loss: 2.7664930917302115

Epoch: 6| Step: 5
Training loss: 0.6327259334175839
Validation loss: 2.8331615919533766

Epoch: 6| Step: 6
Training loss: 0.47107806646199973
Validation loss: 2.7182900781501456

Epoch: 6| Step: 7
Training loss: 0.313172772526579
Validation loss: 2.73520489405815

Epoch: 6| Step: 8
Training loss: 0.3558931018578858
Validation loss: 2.7517628365925964

Epoch: 6| Step: 9
Training loss: 0.31990172633626157
Validation loss: 2.7765127978637616

Epoch: 6| Step: 10
Training loss: 0.41107702896173304
Validation loss: 2.782916573390587

Epoch: 6| Step: 11
Training loss: 0.3560247160684415
Validation loss: 2.8712844058720997

Epoch: 6| Step: 12
Training loss: 0.49253614883595725
Validation loss: 2.861225238291268

Epoch: 6| Step: 13
Training loss: 0.7577936229124377
Validation loss: 2.750228149891327

Epoch: 381| Step: 0
Training loss: 0.3833182944409202
Validation loss: 2.7704925662188074

Epoch: 6| Step: 1
Training loss: 0.3990221035674098
Validation loss: 2.868618551718079

Epoch: 6| Step: 2
Training loss: 0.3691664792649516
Validation loss: 2.790177023750966

Epoch: 6| Step: 3
Training loss: 0.4034794823560006
Validation loss: 2.8095710762349064

Epoch: 6| Step: 4
Training loss: 0.36005354138754203
Validation loss: 2.779395467403885

Epoch: 6| Step: 5
Training loss: 0.3511297741732084
Validation loss: 2.7312721594894325

Epoch: 6| Step: 6
Training loss: 0.3525949153879197
Validation loss: 2.8281244941837427

Epoch: 6| Step: 7
Training loss: 0.3532354076763735
Validation loss: 2.793862537276533

Epoch: 6| Step: 8
Training loss: 0.37748352842205607
Validation loss: 2.7842329651939797

Epoch: 6| Step: 9
Training loss: 0.28543590523742246
Validation loss: 2.810438728858613

Epoch: 6| Step: 10
Training loss: 0.44932539959276746
Validation loss: 2.7004721528941045

Epoch: 6| Step: 11
Training loss: 0.7701375286715938
Validation loss: 2.7926262065266223

Epoch: 6| Step: 12
Training loss: 0.5285379240148842
Validation loss: 2.805526126312742

Epoch: 6| Step: 13
Training loss: 0.3757484834149301
Validation loss: 2.825515048582188

Epoch: 382| Step: 0
Training loss: 0.37536537728565966
Validation loss: 2.7511095929573868

Epoch: 6| Step: 1
Training loss: 0.4109659467939036
Validation loss: 2.7110319973089103

Epoch: 6| Step: 2
Training loss: 0.43856735818712766
Validation loss: 2.7450351112496554

Epoch: 6| Step: 3
Training loss: 0.39374142137900753
Validation loss: 2.7148597918066217

Epoch: 6| Step: 4
Training loss: 0.32924607044516646
Validation loss: 2.7743199193840176

Epoch: 6| Step: 5
Training loss: 0.6194353334852599
Validation loss: 2.794683652864709

Epoch: 6| Step: 6
Training loss: 0.3258157487711315
Validation loss: 2.7693885870499577

Epoch: 6| Step: 7
Training loss: 0.3789592784466456
Validation loss: 2.7545055557954794

Epoch: 6| Step: 8
Training loss: 0.37045357346872615
Validation loss: 2.661752947024164

Epoch: 6| Step: 9
Training loss: 0.45083519730150284
Validation loss: 2.804054153323961

Epoch: 6| Step: 10
Training loss: 0.32824745617975415
Validation loss: 2.798921642529112

Epoch: 6| Step: 11
Training loss: 0.7513594228106805
Validation loss: 2.6869927896143326

Epoch: 6| Step: 12
Training loss: 0.30120846517421634
Validation loss: 2.7279109881087384

Epoch: 6| Step: 13
Training loss: 0.4269133574593134
Validation loss: 2.6963176235301414

Epoch: 383| Step: 0
Training loss: 0.45716894960870663
Validation loss: 2.741419062308645

Epoch: 6| Step: 1
Training loss: 0.4787613218477703
Validation loss: 2.6910518418431986

Epoch: 6| Step: 2
Training loss: 0.3786287569745606
Validation loss: 2.656595933116934

Epoch: 6| Step: 3
Training loss: 0.3491010113255372
Validation loss: 2.6970154326038265

Epoch: 6| Step: 4
Training loss: 0.4105562167279918
Validation loss: 2.73055954447037

Epoch: 6| Step: 5
Training loss: 0.3118089545387289
Validation loss: 2.772073731005622

Epoch: 6| Step: 6
Training loss: 0.29614519462467376
Validation loss: 2.786028767686659

Epoch: 6| Step: 7
Training loss: 0.4067565620774612
Validation loss: 2.8027054522680137

Epoch: 6| Step: 8
Training loss: 0.3480157707692579
Validation loss: 2.7267671524673727

Epoch: 6| Step: 9
Training loss: 0.41896675961956986
Validation loss: 2.766484387456037

Epoch: 6| Step: 10
Training loss: 0.3547848210856889
Validation loss: 2.765906985862385

Epoch: 6| Step: 11
Training loss: 0.7452863148821836
Validation loss: 2.820656442848033

Epoch: 6| Step: 12
Training loss: 0.3952789774918432
Validation loss: 2.763375439601074

Epoch: 6| Step: 13
Training loss: 0.47025692633598476
Validation loss: 2.7312231881624607

Epoch: 384| Step: 0
Training loss: 0.3773392987038098
Validation loss: 2.768154632531483

Epoch: 6| Step: 1
Training loss: 0.5019360550527255
Validation loss: 2.8224916079463713

Epoch: 6| Step: 2
Training loss: 0.4300726118436017
Validation loss: 2.787250218511763

Epoch: 6| Step: 3
Training loss: 0.5604923766755181
Validation loss: 2.7590228370485494

Epoch: 6| Step: 4
Training loss: 0.41919075060884126
Validation loss: 2.753960769871176

Epoch: 6| Step: 5
Training loss: 0.39847508421512334
Validation loss: 2.7513577981709525

Epoch: 6| Step: 6
Training loss: 0.3900550690004078
Validation loss: 2.773306027730376

Epoch: 6| Step: 7
Training loss: 0.4718033369859568
Validation loss: 2.7576145176699307

Epoch: 6| Step: 8
Training loss: 0.39033871650458596
Validation loss: 2.7444656921659027

Epoch: 6| Step: 9
Training loss: 0.7622334233173994
Validation loss: 2.727199432683811

Epoch: 6| Step: 10
Training loss: 0.43550364532105673
Validation loss: 2.690174959820077

Epoch: 6| Step: 11
Training loss: 0.4383641971968088
Validation loss: 2.771911043422333

Epoch: 6| Step: 12
Training loss: 0.25634319483189894
Validation loss: 2.790422323569703

Epoch: 6| Step: 13
Training loss: 0.32671808433373684
Validation loss: 2.7569351818036947

Epoch: 385| Step: 0
Training loss: 0.379499384114365
Validation loss: 2.8224498367469635

Epoch: 6| Step: 1
Training loss: 0.3831846413543845
Validation loss: 2.72625064614889

Epoch: 6| Step: 2
Training loss: 0.549868402126278
Validation loss: 2.6822241370332898

Epoch: 6| Step: 3
Training loss: 0.406595816511632
Validation loss: 2.7634194985619813

Epoch: 6| Step: 4
Training loss: 0.30999083491974644
Validation loss: 2.810946537078925

Epoch: 6| Step: 5
Training loss: 0.29775800642704303
Validation loss: 2.6901785860849476

Epoch: 6| Step: 6
Training loss: 0.435299294073574
Validation loss: 2.756316848370972

Epoch: 6| Step: 7
Training loss: 0.4041985654860215
Validation loss: 2.7771624842642026

Epoch: 6| Step: 8
Training loss: 0.4771454169622402
Validation loss: 2.822054901528027

Epoch: 6| Step: 9
Training loss: 0.35714921817904915
Validation loss: 2.7613059404865017

Epoch: 6| Step: 10
Training loss: 0.41450466083671716
Validation loss: 2.6854825246788385

Epoch: 6| Step: 11
Training loss: 0.39426137172914516
Validation loss: 2.76185353627799

Epoch: 6| Step: 12
Training loss: 0.4430548676705011
Validation loss: 2.7434351909202044

Epoch: 6| Step: 13
Training loss: 0.3695232285643125
Validation loss: 2.733065700415465

Epoch: 386| Step: 0
Training loss: 0.380243928976206
Validation loss: 2.792516640659385

Epoch: 6| Step: 1
Training loss: 0.5052259743615736
Validation loss: 2.8187426621256275

Epoch: 6| Step: 2
Training loss: 0.2796496983774265
Validation loss: 2.761723613240134

Epoch: 6| Step: 3
Training loss: 0.4860429655478212
Validation loss: 2.772799329809173

Epoch: 6| Step: 4
Training loss: 0.4070056892613638
Validation loss: 2.7885544970538674

Epoch: 6| Step: 5
Training loss: 0.3904027688162753
Validation loss: 2.726967316081341

Epoch: 6| Step: 6
Training loss: 0.5341944718625073
Validation loss: 2.7714196543252796

Epoch: 6| Step: 7
Training loss: 0.4258261140757616
Validation loss: 2.7059084429320523

Epoch: 6| Step: 8
Training loss: 0.5524235043281154
Validation loss: 2.6845592407427503

Epoch: 6| Step: 9
Training loss: 0.49736293131338316
Validation loss: 2.7465469615816622

Epoch: 6| Step: 10
Training loss: 0.37923161802711736
Validation loss: 2.7963105099138788

Epoch: 6| Step: 11
Training loss: 0.3363000111454268
Validation loss: 2.737359429151277

Epoch: 6| Step: 12
Training loss: 0.6621438526640481
Validation loss: 2.7211984446870514

Epoch: 6| Step: 13
Training loss: 0.5231958657123239
Validation loss: 2.740786738971482

Epoch: 387| Step: 0
Training loss: 0.43996983985595195
Validation loss: 2.6914056446681935

Epoch: 6| Step: 1
Training loss: 0.4157287611545594
Validation loss: 2.8176263643330315

Epoch: 6| Step: 2
Training loss: 0.3883778403969907
Validation loss: 2.7164013536080165

Epoch: 6| Step: 3
Training loss: 0.5375615384115776
Validation loss: 2.7145508239938585

Epoch: 6| Step: 4
Training loss: 0.5675950826906381
Validation loss: 2.6945526010123264

Epoch: 6| Step: 5
Training loss: 0.42726740320742074
Validation loss: 2.7850378866489387

Epoch: 6| Step: 6
Training loss: 0.34976491185452796
Validation loss: 2.795225058123136

Epoch: 6| Step: 7
Training loss: 0.3664017447253607
Validation loss: 2.7742600774770763

Epoch: 6| Step: 8
Training loss: 0.5451455152990319
Validation loss: 2.6898509839178826

Epoch: 6| Step: 9
Training loss: 0.28077649948355554
Validation loss: 2.752130420136649

Epoch: 6| Step: 10
Training loss: 0.6927360419178786
Validation loss: 2.7757662313827858

Epoch: 6| Step: 11
Training loss: 0.4357635745857527
Validation loss: 2.7587923897242104

Epoch: 6| Step: 12
Training loss: 0.2902959334755865
Validation loss: 2.7221689613694005

Epoch: 6| Step: 13
Training loss: 0.3254653679959982
Validation loss: 2.729765183337479

Epoch: 388| Step: 0
Training loss: 0.5105614424409816
Validation loss: 2.7605976021446144

Epoch: 6| Step: 1
Training loss: 0.544627694738558
Validation loss: 2.7587721382454697

Epoch: 6| Step: 2
Training loss: 0.546200636197966
Validation loss: 2.7257443924935147

Epoch: 6| Step: 3
Training loss: 0.4187692303298617
Validation loss: 2.6848954584002427

Epoch: 6| Step: 4
Training loss: 0.7195148130645608
Validation loss: 2.700133091978275

Epoch: 6| Step: 5
Training loss: 0.47600718490904065
Validation loss: 2.6914878061429235

Epoch: 6| Step: 6
Training loss: 0.47505123464433746
Validation loss: 2.778513501539795

Epoch: 6| Step: 7
Training loss: 0.3885798896554061
Validation loss: 2.6838214450062687

Epoch: 6| Step: 8
Training loss: 0.39689107997488704
Validation loss: 2.685623223346551

Epoch: 6| Step: 9
Training loss: 0.3226539584025363
Validation loss: 2.7243329599556745

Epoch: 6| Step: 10
Training loss: 0.5106586803782068
Validation loss: 2.7269536769771485

Epoch: 6| Step: 11
Training loss: 0.3343586302698654
Validation loss: 2.726321161441269

Epoch: 6| Step: 12
Training loss: 0.3904652077955734
Validation loss: 2.7966018060279296

Epoch: 6| Step: 13
Training loss: 0.40497074083318274
Validation loss: 2.762173584170288

Epoch: 389| Step: 0
Training loss: 0.4554772325514319
Validation loss: 2.8082816242773925

Epoch: 6| Step: 1
Training loss: 0.5512796946721442
Validation loss: 2.761709901183114

Epoch: 6| Step: 2
Training loss: 0.37780692696700885
Validation loss: 2.7929288421127207

Epoch: 6| Step: 3
Training loss: 0.6145600998791944
Validation loss: 2.754419734329865

Epoch: 6| Step: 4
Training loss: 0.2826798965912572
Validation loss: 2.7923003564024036

Epoch: 6| Step: 5
Training loss: 0.533814635014929
Validation loss: 2.7598788379252204

Epoch: 6| Step: 6
Training loss: 0.40807519395586783
Validation loss: 2.7516794134022304

Epoch: 6| Step: 7
Training loss: 0.28278933583019344
Validation loss: 2.773409948077825

Epoch: 6| Step: 8
Training loss: 0.4791163507940324
Validation loss: 2.7670750094495684

Epoch: 6| Step: 9
Training loss: 0.4336998955647996
Validation loss: 2.7672011200081243

Epoch: 6| Step: 10
Training loss: 0.4636834674212003
Validation loss: 2.845078978713275

Epoch: 6| Step: 11
Training loss: 0.46082614911476844
Validation loss: 2.8039626492730374

Epoch: 6| Step: 12
Training loss: 0.4554042220822102
Validation loss: 2.7674328629719143

Epoch: 6| Step: 13
Training loss: 0.4176817291742438
Validation loss: 2.7749513031865187

Epoch: 390| Step: 0
Training loss: 0.5001913538980595
Validation loss: 2.758731807688511

Epoch: 6| Step: 1
Training loss: 0.2514742655053824
Validation loss: 2.7097170351718427

Epoch: 6| Step: 2
Training loss: 0.34737642149138503
Validation loss: 2.734075518965259

Epoch: 6| Step: 3
Training loss: 0.32175373691220516
Validation loss: 2.862632688420482

Epoch: 6| Step: 4
Training loss: 0.4931726436057276
Validation loss: 2.6878326417153287

Epoch: 6| Step: 5
Training loss: 0.3200666833480145
Validation loss: 2.7574416965835518

Epoch: 6| Step: 6
Training loss: 0.29606495317115583
Validation loss: 2.761299097819948

Epoch: 6| Step: 7
Training loss: 0.45552051308939984
Validation loss: 2.7568478000163585

Epoch: 6| Step: 8
Training loss: 0.5114098992758018
Validation loss: 2.7399540470265555

Epoch: 6| Step: 9
Training loss: 0.44562696764111653
Validation loss: 2.7245327481850947

Epoch: 6| Step: 10
Training loss: 0.46349623453900785
Validation loss: 2.7404132258079597

Epoch: 6| Step: 11
Training loss: 0.5149960583471175
Validation loss: 2.736093137545431

Epoch: 6| Step: 12
Training loss: 0.5801416741185749
Validation loss: 2.762766120140787

Epoch: 6| Step: 13
Training loss: 0.29442660954480754
Validation loss: 2.7065983766090183

Epoch: 391| Step: 0
Training loss: 0.42948433668065855
Validation loss: 2.721939758861831

Epoch: 6| Step: 1
Training loss: 0.276479179417584
Validation loss: 2.685259335932484

Epoch: 6| Step: 2
Training loss: 0.29551684762236585
Validation loss: 2.7063461545053284

Epoch: 6| Step: 3
Training loss: 0.43457408431912997
Validation loss: 2.8970884626491187

Epoch: 6| Step: 4
Training loss: 0.34528875571386025
Validation loss: 2.86294678612014

Epoch: 6| Step: 5
Training loss: 0.3697513997178476
Validation loss: 2.7364391564862696

Epoch: 6| Step: 6
Training loss: 0.290569013925041
Validation loss: 2.820068292444692

Epoch: 6| Step: 7
Training loss: 0.5777536694630094
Validation loss: 2.7735301544042987

Epoch: 6| Step: 8
Training loss: 0.7239323252298908
Validation loss: 2.744253888852846

Epoch: 6| Step: 9
Training loss: 0.28378173650643795
Validation loss: 2.762349029374283

Epoch: 6| Step: 10
Training loss: 0.35466043562288463
Validation loss: 2.7607216048803096

Epoch: 6| Step: 11
Training loss: 0.4171692161982547
Validation loss: 2.8342943011105644

Epoch: 6| Step: 12
Training loss: 0.3809633162077088
Validation loss: 2.7677398899984733

Epoch: 6| Step: 13
Training loss: 0.3602852695759347
Validation loss: 2.819395470989903

Epoch: 392| Step: 0
Training loss: 0.438898236373692
Validation loss: 2.7509709002574554

Epoch: 6| Step: 1
Training loss: 0.3958808928913216
Validation loss: 2.7489424030111715

Epoch: 6| Step: 2
Training loss: 0.44523551342362294
Validation loss: 2.7972922271442333

Epoch: 6| Step: 3
Training loss: 0.7118418045945121
Validation loss: 2.68080845289352

Epoch: 6| Step: 4
Training loss: 0.48498306254670775
Validation loss: 2.725980694771257

Epoch: 6| Step: 5
Training loss: 0.3878646596033663
Validation loss: 2.7359318833190907

Epoch: 6| Step: 6
Training loss: 0.5023769266851401
Validation loss: 2.7443606395920543

Epoch: 6| Step: 7
Training loss: 0.2585845715141423
Validation loss: 2.7172759580042354

Epoch: 6| Step: 8
Training loss: 0.5383163484998057
Validation loss: 2.7563798909854857

Epoch: 6| Step: 9
Training loss: 0.25281522068026197
Validation loss: 2.727026403506566

Epoch: 6| Step: 10
Training loss: 0.27781950749762596
Validation loss: 2.805640495281864

Epoch: 6| Step: 11
Training loss: 0.3787951355658059
Validation loss: 2.7394913680930486

Epoch: 6| Step: 12
Training loss: 0.3739903288447607
Validation loss: 2.7100757031582634

Epoch: 6| Step: 13
Training loss: 0.2565626714057675
Validation loss: 2.772570407341493

Epoch: 393| Step: 0
Training loss: 0.33481292123431594
Validation loss: 2.7801826514931083

Epoch: 6| Step: 1
Training loss: 0.2847031560124968
Validation loss: 2.806258708087916

Epoch: 6| Step: 2
Training loss: 0.40731243444831183
Validation loss: 2.7437185014844325

Epoch: 6| Step: 3
Training loss: 0.3995537548567099
Validation loss: 2.764380870228968

Epoch: 6| Step: 4
Training loss: 0.3876106112029073
Validation loss: 2.7168358828104777

Epoch: 6| Step: 5
Training loss: 0.25685492325728404
Validation loss: 2.7107321655020744

Epoch: 6| Step: 6
Training loss: 0.4016511381413582
Validation loss: 2.754434059732686

Epoch: 6| Step: 7
Training loss: 0.46865966244273183
Validation loss: 2.752289274327897

Epoch: 6| Step: 8
Training loss: 0.4770858736123277
Validation loss: 2.7789295960922864

Epoch: 6| Step: 9
Training loss: 0.32848918096226287
Validation loss: 2.796036919706151

Epoch: 6| Step: 10
Training loss: 0.3758957020393363
Validation loss: 2.7284022029821395

Epoch: 6| Step: 11
Training loss: 0.7064360542312943
Validation loss: 2.6800732497149755

Epoch: 6| Step: 12
Training loss: 0.4010678402505184
Validation loss: 2.7531304747995766

Epoch: 6| Step: 13
Training loss: 0.4459751619556064
Validation loss: 2.764793615864849

Epoch: 394| Step: 0
Training loss: 0.3788058747727246
Validation loss: 2.7217650959587503

Epoch: 6| Step: 1
Training loss: 0.3692497213307067
Validation loss: 2.7420944241543532

Epoch: 6| Step: 2
Training loss: 0.4816130371112933
Validation loss: 2.7125552990692423

Epoch: 6| Step: 3
Training loss: 0.4750365701200205
Validation loss: 2.7035251754873517

Epoch: 6| Step: 4
Training loss: 0.3037580226694276
Validation loss: 2.7424837044828996

Epoch: 6| Step: 5
Training loss: 0.3513156129943089
Validation loss: 2.7625289225035194

Epoch: 6| Step: 6
Training loss: 0.36665028983447645
Validation loss: 2.68917726326876

Epoch: 6| Step: 7
Training loss: 0.7034702089382767
Validation loss: 2.753693571062317

Epoch: 6| Step: 8
Training loss: 0.5123971998808241
Validation loss: 2.8182414191665934

Epoch: 6| Step: 9
Training loss: 0.40466468776195974
Validation loss: 2.7554458318697663

Epoch: 6| Step: 10
Training loss: 0.5625401588515613
Validation loss: 2.7302604017322394

Epoch: 6| Step: 11
Training loss: 0.3431246010199557
Validation loss: 2.682939844917535

Epoch: 6| Step: 12
Training loss: 0.26640676011738645
Validation loss: 2.702275092958578

Epoch: 6| Step: 13
Training loss: 0.3965573549049589
Validation loss: 2.761494456116932

Epoch: 395| Step: 0
Training loss: 0.6412333182159783
Validation loss: 2.7581758484920855

Epoch: 6| Step: 1
Training loss: 0.3022231677208475
Validation loss: 2.7602273240320163

Epoch: 6| Step: 2
Training loss: 0.3645090254489082
Validation loss: 2.72725477056179

Epoch: 6| Step: 3
Training loss: 0.33667850829220125
Validation loss: 2.7441279545646466

Epoch: 6| Step: 4
Training loss: 0.2711157182482683
Validation loss: 2.7848500943546384

Epoch: 6| Step: 5
Training loss: 0.3417701165760403
Validation loss: 2.796876974833269

Epoch: 6| Step: 6
Training loss: 0.5567976612970273
Validation loss: 2.733210550047082

Epoch: 6| Step: 7
Training loss: 0.5622128972523925
Validation loss: 2.7958157343151826

Epoch: 6| Step: 8
Training loss: 0.361610158187835
Validation loss: 2.764464499461985

Epoch: 6| Step: 9
Training loss: 0.43221703616683627
Validation loss: 2.8066127477512177

Epoch: 6| Step: 10
Training loss: 0.4189914597924648
Validation loss: 2.751654170782165

Epoch: 6| Step: 11
Training loss: 0.4516186999291485
Validation loss: 2.7208425573296826

Epoch: 6| Step: 12
Training loss: 0.5362311656907777
Validation loss: 2.6980211294170178

Epoch: 6| Step: 13
Training loss: 0.5058415236692453
Validation loss: 2.720409047887386

Epoch: 396| Step: 0
Training loss: 0.4744560873264828
Validation loss: 2.736424330282409

Epoch: 6| Step: 1
Training loss: 0.3450554745585459
Validation loss: 2.7629370405534868

Epoch: 6| Step: 2
Training loss: 0.2996512651067641
Validation loss: 2.7454291996100744

Epoch: 6| Step: 3
Training loss: 0.27439494762162336
Validation loss: 2.8184071706630283

Epoch: 6| Step: 4
Training loss: 0.45448900327398994
Validation loss: 2.707221343323466

Epoch: 6| Step: 5
Training loss: 0.5252003662047813
Validation loss: 2.728890926806959

Epoch: 6| Step: 6
Training loss: 0.48114353959282236
Validation loss: 2.723778543076182

Epoch: 6| Step: 7
Training loss: 0.6494283115286527
Validation loss: 2.7558941675590245

Epoch: 6| Step: 8
Training loss: 0.4066497962936141
Validation loss: 2.7424957594814106

Epoch: 6| Step: 9
Training loss: 0.42043528553717074
Validation loss: 2.71339023384758

Epoch: 6| Step: 10
Training loss: 0.3577363970254309
Validation loss: 2.7243454307403625

Epoch: 6| Step: 11
Training loss: 0.4445572522005294
Validation loss: 2.671297155882444

Epoch: 6| Step: 12
Training loss: 0.39926741689720974
Validation loss: 2.7334289367362548

Epoch: 6| Step: 13
Training loss: 0.5113951555325467
Validation loss: 2.708107312870497

Epoch: 397| Step: 0
Training loss: 0.523737693223235
Validation loss: 2.731061148061247

Epoch: 6| Step: 1
Training loss: 0.4167874657838928
Validation loss: 2.6633529986139712

Epoch: 6| Step: 2
Training loss: 0.4594308021284482
Validation loss: 2.787770560666473

Epoch: 6| Step: 3
Training loss: 0.40483282565502143
Validation loss: 2.777469408614758

Epoch: 6| Step: 4
Training loss: 0.395453913277337
Validation loss: 2.73721979295159

Epoch: 6| Step: 5
Training loss: 0.4088629176991191
Validation loss: 2.6535094840397377

Epoch: 6| Step: 6
Training loss: 0.4342849137178505
Validation loss: 2.729266104209197

Epoch: 6| Step: 7
Training loss: 0.6234407764243552
Validation loss: 2.6734505779957938

Epoch: 6| Step: 8
Training loss: 0.2073734262784968
Validation loss: 2.6881062171372654

Epoch: 6| Step: 9
Training loss: 0.3828256565869339
Validation loss: 2.699808191621288

Epoch: 6| Step: 10
Training loss: 0.3880605058635703
Validation loss: 2.71485371759355

Epoch: 6| Step: 11
Training loss: 0.32397976075642637
Validation loss: 2.701962936021038

Epoch: 6| Step: 12
Training loss: 0.29114515506936073
Validation loss: 2.751192715672556

Epoch: 6| Step: 13
Training loss: 0.5335732876385423
Validation loss: 2.68649324885252

Epoch: 398| Step: 0
Training loss: 0.6526776218910608
Validation loss: 2.6950850386169245

Epoch: 6| Step: 1
Training loss: 0.33180606161953374
Validation loss: 2.713179263310666

Epoch: 6| Step: 2
Training loss: 0.3960945392728688
Validation loss: 2.7516966845351694

Epoch: 6| Step: 3
Training loss: 0.31967774742665983
Validation loss: 2.77265512239432

Epoch: 6| Step: 4
Training loss: 0.3713691492611691
Validation loss: 2.795891800300838

Epoch: 6| Step: 5
Training loss: 0.23825748512702632
Validation loss: 2.7831232570320346

Epoch: 6| Step: 6
Training loss: 0.2991403681230177
Validation loss: 2.7233897552419686

Epoch: 6| Step: 7
Training loss: 0.6014721046996754
Validation loss: 2.7296394977159246

Epoch: 6| Step: 8
Training loss: 0.3996253911870498
Validation loss: 2.758589709795818

Epoch: 6| Step: 9
Training loss: 0.4600162837266506
Validation loss: 2.69628135480174

Epoch: 6| Step: 10
Training loss: 0.35355134646521175
Validation loss: 2.681402282421451

Epoch: 6| Step: 11
Training loss: 0.4466799437034683
Validation loss: 2.7181564209245357

Epoch: 6| Step: 12
Training loss: 0.5269019077258525
Validation loss: 2.6991052451883517

Epoch: 6| Step: 13
Training loss: 0.5296902197933981
Validation loss: 2.7288919461036785

Epoch: 399| Step: 0
Training loss: 0.355774611627687
Validation loss: 2.7470973474912803

Epoch: 6| Step: 1
Training loss: 0.34264908406931077
Validation loss: 2.748624775665004

Epoch: 6| Step: 2
Training loss: 0.6391307337365894
Validation loss: 2.634936101670721

Epoch: 6| Step: 3
Training loss: 0.3760008568779333
Validation loss: 2.797125679020236

Epoch: 6| Step: 4
Training loss: 0.34181605693942496
Validation loss: 2.7871597738149014

Epoch: 6| Step: 5
Training loss: 0.40069825054735947
Validation loss: 2.6428872675019566

Epoch: 6| Step: 6
Training loss: 0.41022603485806364
Validation loss: 2.7299397273973227

Epoch: 6| Step: 7
Training loss: 0.36936453431692484
Validation loss: 2.7980099440700834

Epoch: 6| Step: 8
Training loss: 0.42287397435374285
Validation loss: 2.7683577461322213

Epoch: 6| Step: 9
Training loss: 0.32335300217159846
Validation loss: 2.7688202871294916

Epoch: 6| Step: 10
Training loss: 0.41637691516143743
Validation loss: 2.7590646899784206

Epoch: 6| Step: 11
Training loss: 0.30540206454465435
Validation loss: 2.6875665050232587

Epoch: 6| Step: 12
Training loss: 0.32586442996969583
Validation loss: 2.694822449293902

Epoch: 6| Step: 13
Training loss: 0.48628059982276933
Validation loss: 2.6596193672746002

Epoch: 400| Step: 0
Training loss: 0.40766191881419284
Validation loss: 2.732798457922973

Epoch: 6| Step: 1
Training loss: 0.433527039215904
Validation loss: 2.705669932348839

Epoch: 6| Step: 2
Training loss: 0.4374675738715807
Validation loss: 2.707435860242504

Epoch: 6| Step: 3
Training loss: 0.48195231516302084
Validation loss: 2.7248338832443624

Epoch: 6| Step: 4
Training loss: 0.4516251834010626
Validation loss: 2.8451159902883356

Epoch: 6| Step: 5
Training loss: 0.6642566621451328
Validation loss: 2.720369601978734

Epoch: 6| Step: 6
Training loss: 0.3629662984041865
Validation loss: 2.777501298072619

Epoch: 6| Step: 7
Training loss: 0.64782081142307
Validation loss: 2.726736637008938

Epoch: 6| Step: 8
Training loss: 0.38286533769576386
Validation loss: 2.7042490656151874

Epoch: 6| Step: 9
Training loss: 0.3669170844847996
Validation loss: 2.689321300015678

Epoch: 6| Step: 10
Training loss: 0.4026617441627794
Validation loss: 2.641314023504613

Epoch: 6| Step: 11
Training loss: 0.39462488781743454
Validation loss: 2.704432154898494

Epoch: 6| Step: 12
Training loss: 0.4087821103237067
Validation loss: 2.7716431880269226

Epoch: 6| Step: 13
Training loss: 0.4020266347976788
Validation loss: 2.751589503562831

Epoch: 401| Step: 0
Training loss: 0.5744405305193327
Validation loss: 2.757570120991165

Epoch: 6| Step: 1
Training loss: 0.4153319817387605
Validation loss: 2.7197919580894574

Epoch: 6| Step: 2
Training loss: 0.5373669925509266
Validation loss: 2.739750582638584

Epoch: 6| Step: 3
Training loss: 0.411647447351061
Validation loss: 2.7775003538409035

Epoch: 6| Step: 4
Training loss: 0.3035209773118282
Validation loss: 2.746648740509324

Epoch: 6| Step: 5
Training loss: 0.42743501682399665
Validation loss: 2.69674787402232

Epoch: 6| Step: 6
Training loss: 0.33779137316831775
Validation loss: 2.769568783353744

Epoch: 6| Step: 7
Training loss: 0.4418522767155392
Validation loss: 2.7172119350113393

Epoch: 6| Step: 8
Training loss: 0.4338446226440262
Validation loss: 2.74550570635138

Epoch: 6| Step: 9
Training loss: 0.41003372542142336
Validation loss: 2.7705914575846995

Epoch: 6| Step: 10
Training loss: 0.32853611667874344
Validation loss: 2.7368429182108676

Epoch: 6| Step: 11
Training loss: 0.4284412517703317
Validation loss: 2.7573700965148213

Epoch: 6| Step: 12
Training loss: 0.3631876548053843
Validation loss: 2.6983740037237176

Epoch: 6| Step: 13
Training loss: 0.25177723267366137
Validation loss: 2.706193464949938

Epoch: 402| Step: 0
Training loss: 0.449086775259642
Validation loss: 2.777970341259774

Epoch: 6| Step: 1
Training loss: 0.704379023089424
Validation loss: 2.74389876162964

Epoch: 6| Step: 2
Training loss: 0.46355021036682525
Validation loss: 2.7523393723164924

Epoch: 6| Step: 3
Training loss: 0.38337784496628646
Validation loss: 2.7474201990767635

Epoch: 6| Step: 4
Training loss: 0.4917285686927218
Validation loss: 2.7265108061720373

Epoch: 6| Step: 5
Training loss: 0.40651567648352754
Validation loss: 2.7039499071548705

Epoch: 6| Step: 6
Training loss: 0.47100108359752824
Validation loss: 2.7719664921618388

Epoch: 6| Step: 7
Training loss: 0.5122522965059051
Validation loss: 2.764307818354329

Epoch: 6| Step: 8
Training loss: 0.3413293092741605
Validation loss: 2.7484668156873218

Epoch: 6| Step: 9
Training loss: 0.2313763237997236
Validation loss: 2.6733085400564494

Epoch: 6| Step: 10
Training loss: 0.37371769851624687
Validation loss: 2.6923326467573223

Epoch: 6| Step: 11
Training loss: 0.36495883768337667
Validation loss: 2.7156801321317716

Epoch: 6| Step: 12
Training loss: 0.4718869308832832
Validation loss: 2.734801108446985

Epoch: 6| Step: 13
Training loss: 0.35591141940948184
Validation loss: 2.7876016546966746

Epoch: 403| Step: 0
Training loss: 0.4542486137280807
Validation loss: 2.877081794563414

Epoch: 6| Step: 1
Training loss: 0.5240296956704147
Validation loss: 2.8146399233701214

Epoch: 6| Step: 2
Training loss: 0.6110023873839742
Validation loss: 2.750426172699374

Epoch: 6| Step: 3
Training loss: 0.4793465387283259
Validation loss: 2.7714680300896637

Epoch: 6| Step: 4
Training loss: 0.3605197420997421
Validation loss: 2.676340309269224

Epoch: 6| Step: 5
Training loss: 0.3678712768392206
Validation loss: 2.6685614386000847

Epoch: 6| Step: 6
Training loss: 0.34926716343041664
Validation loss: 2.818018719306177

Epoch: 6| Step: 7
Training loss: 0.576857905191417
Validation loss: 2.7663535040447043

Epoch: 6| Step: 8
Training loss: 0.5858003582995964
Validation loss: 2.6987826063534266

Epoch: 6| Step: 9
Training loss: 0.4341800609043041
Validation loss: 2.709251355815183

Epoch: 6| Step: 10
Training loss: 0.4322400138820047
Validation loss: 2.7977055785045106

Epoch: 6| Step: 11
Training loss: 0.676768777601578
Validation loss: 2.725703325412372

Epoch: 6| Step: 12
Training loss: 0.4363115893229997
Validation loss: 2.701277011122572

Epoch: 6| Step: 13
Training loss: 0.3311679162582784
Validation loss: 2.6847498077336622

Epoch: 404| Step: 0
Training loss: 0.4351518490361603
Validation loss: 2.715209906971844

Epoch: 6| Step: 1
Training loss: 0.360644089971996
Validation loss: 2.761972677381588

Epoch: 6| Step: 2
Training loss: 0.35438859755383195
Validation loss: 2.733395297425849

Epoch: 6| Step: 3
Training loss: 0.38437053321165826
Validation loss: 2.7280059753531516

Epoch: 6| Step: 4
Training loss: 0.5760029173287052
Validation loss: 2.724276293741314

Epoch: 6| Step: 5
Training loss: 0.5046441936513789
Validation loss: 2.7818472574565196

Epoch: 6| Step: 6
Training loss: 0.3372811349532632
Validation loss: 2.702974333634326

Epoch: 6| Step: 7
Training loss: 0.5463491636567807
Validation loss: 2.732429626177541

Epoch: 6| Step: 8
Training loss: 0.3211537455919267
Validation loss: 2.6062671023508286

Epoch: 6| Step: 9
Training loss: 0.28818118573652834
Validation loss: 2.7331207159744304

Epoch: 6| Step: 10
Training loss: 0.33143845541519784
Validation loss: 2.690150956925269

Epoch: 6| Step: 11
Training loss: 0.3773810176729688
Validation loss: 2.713017291596864

Epoch: 6| Step: 12
Training loss: 0.6461925942991006
Validation loss: 2.64990580769248

Epoch: 6| Step: 13
Training loss: 0.3071266016547702
Validation loss: 2.7601633111579265

Epoch: 405| Step: 0
Training loss: 0.39992674961536034
Validation loss: 2.7149242800837254

Epoch: 6| Step: 1
Training loss: 0.3831851857814988
Validation loss: 2.763033944451483

Epoch: 6| Step: 2
Training loss: 0.31655152835642686
Validation loss: 2.7727300395302725

Epoch: 6| Step: 3
Training loss: 0.4516064091225952
Validation loss: 2.676683230255805

Epoch: 6| Step: 4
Training loss: 0.3601145805035285
Validation loss: 2.6444646093479474

Epoch: 6| Step: 5
Training loss: 0.47901432753181683
Validation loss: 2.6851863956692283

Epoch: 6| Step: 6
Training loss: 0.5000504229870023
Validation loss: 2.718253517858004

Epoch: 6| Step: 7
Training loss: 0.3296619138687634
Validation loss: 2.7056820779373805

Epoch: 6| Step: 8
Training loss: 0.36208777090601046
Validation loss: 2.6826517968247576

Epoch: 6| Step: 9
Training loss: 0.26357010184115454
Validation loss: 2.6879295109402683

Epoch: 6| Step: 10
Training loss: 0.29999582118859175
Validation loss: 2.7596732428068003

Epoch: 6| Step: 11
Training loss: 0.40863769615849865
Validation loss: 2.797622935844123

Epoch: 6| Step: 12
Training loss: 0.40018791091352124
Validation loss: 2.737473481629013

Epoch: 6| Step: 13
Training loss: 0.7541809767389365
Validation loss: 2.6649591646650372

Epoch: 406| Step: 0
Training loss: 0.364756592953078
Validation loss: 2.795614075531691

Epoch: 6| Step: 1
Training loss: 0.4210911639245621
Validation loss: 2.8203645033898375

Epoch: 6| Step: 2
Training loss: 0.5197795762036441
Validation loss: 2.777360532471161

Epoch: 6| Step: 3
Training loss: 0.36191498807242173
Validation loss: 2.716938438356454

Epoch: 6| Step: 4
Training loss: 0.42921675124395614
Validation loss: 2.7683182801012105

Epoch: 6| Step: 5
Training loss: 0.3305375327456032
Validation loss: 2.7525750011004506

Epoch: 6| Step: 6
Training loss: 0.5664567069895122
Validation loss: 2.718618112047092

Epoch: 6| Step: 7
Training loss: 0.34619914316589767
Validation loss: 2.8009924248144986

Epoch: 6| Step: 8
Training loss: 0.6409918269842961
Validation loss: 2.8076983966969054

Epoch: 6| Step: 9
Training loss: 0.3782005423757294
Validation loss: 2.7511970486731125

Epoch: 6| Step: 10
Training loss: 0.31115573001230806
Validation loss: 2.7761498740878214

Epoch: 6| Step: 11
Training loss: 0.2894391106676243
Validation loss: 2.790475923515566

Epoch: 6| Step: 12
Training loss: 0.4402750424655432
Validation loss: 2.7967333624581814

Epoch: 6| Step: 13
Training loss: 0.43233580727789717
Validation loss: 2.7770087947319277

Epoch: 407| Step: 0
Training loss: 0.35691875212950247
Validation loss: 2.761167119539298

Epoch: 6| Step: 1
Training loss: 0.273784798365644
Validation loss: 2.808496508022458

Epoch: 6| Step: 2
Training loss: 0.388354550509893
Validation loss: 2.739228306575714

Epoch: 6| Step: 3
Training loss: 0.44990949184137125
Validation loss: 2.8071545418186794

Epoch: 6| Step: 4
Training loss: 0.39935701517792715
Validation loss: 2.8092043181591007

Epoch: 6| Step: 5
Training loss: 0.4138539706861082
Validation loss: 2.837849318502794

Epoch: 6| Step: 6
Training loss: 0.47395963109715566
Validation loss: 2.718029189746738

Epoch: 6| Step: 7
Training loss: 0.40374172261259555
Validation loss: 2.7680098888481504

Epoch: 6| Step: 8
Training loss: 0.3723468103575191
Validation loss: 2.8183604606332007

Epoch: 6| Step: 9
Training loss: 0.3480783429032755
Validation loss: 2.786583989717788

Epoch: 6| Step: 10
Training loss: 0.40571432376231525
Validation loss: 2.7329856321885604

Epoch: 6| Step: 11
Training loss: 0.4578274695126566
Validation loss: 2.7466911436659998

Epoch: 6| Step: 12
Training loss: 0.3217015502763675
Validation loss: 2.7691673610072987

Epoch: 6| Step: 13
Training loss: 0.6307364659998718
Validation loss: 2.7980502268332517

Epoch: 408| Step: 0
Training loss: 0.40485951070903603
Validation loss: 2.7883737035893033

Epoch: 6| Step: 1
Training loss: 0.3654055474777861
Validation loss: 2.7620323682928327

Epoch: 6| Step: 2
Training loss: 0.3797604086619096
Validation loss: 2.838834489656609

Epoch: 6| Step: 3
Training loss: 0.649535914870729
Validation loss: 2.779016533780362

Epoch: 6| Step: 4
Training loss: 0.48505231201577187
Validation loss: 2.793546596407722

Epoch: 6| Step: 5
Training loss: 0.3944124666181514
Validation loss: 2.8086616320446836

Epoch: 6| Step: 6
Training loss: 0.45809158177288467
Validation loss: 2.8131976216097208

Epoch: 6| Step: 7
Training loss: 0.43935389776006223
Validation loss: 2.7763821295873856

Epoch: 6| Step: 8
Training loss: 0.40028536273535936
Validation loss: 2.8204871746155518

Epoch: 6| Step: 9
Training loss: 0.3486548237837673
Validation loss: 2.7035616115992465

Epoch: 6| Step: 10
Training loss: 0.5402134756816178
Validation loss: 2.7414324047761167

Epoch: 6| Step: 11
Training loss: 0.2949214707933902
Validation loss: 2.742176878239274

Epoch: 6| Step: 12
Training loss: 0.4435424258755836
Validation loss: 2.7556234718826684

Epoch: 6| Step: 13
Training loss: 0.24761403984624378
Validation loss: 2.7257074656786298

Epoch: 409| Step: 0
Training loss: 0.3029591003148211
Validation loss: 2.7257868292851564

Epoch: 6| Step: 1
Training loss: 0.3739744707130447
Validation loss: 2.7681994192846324

Epoch: 6| Step: 2
Training loss: 0.3695411325951866
Validation loss: 2.7681473259058884

Epoch: 6| Step: 3
Training loss: 0.5901027388750419
Validation loss: 2.768660106591765

Epoch: 6| Step: 4
Training loss: 0.36004393971696913
Validation loss: 2.734642567940217

Epoch: 6| Step: 5
Training loss: 0.40040350172224615
Validation loss: 2.801295532510168

Epoch: 6| Step: 6
Training loss: 0.4135085304814885
Validation loss: 2.6922718385433004

Epoch: 6| Step: 7
Training loss: 0.32548075111301555
Validation loss: 2.759728476671865

Epoch: 6| Step: 8
Training loss: 0.5409168469978157
Validation loss: 2.7185940021762014

Epoch: 6| Step: 9
Training loss: 0.4494186288401863
Validation loss: 2.7467024496171937

Epoch: 6| Step: 10
Training loss: 0.42201145932155215
Validation loss: 2.7888312720324566

Epoch: 6| Step: 11
Training loss: 0.34827650653112663
Validation loss: 2.714824780734088

Epoch: 6| Step: 12
Training loss: 0.5243986898261114
Validation loss: 2.7449302324694664

Epoch: 6| Step: 13
Training loss: 0.5543657094785511
Validation loss: 2.764075223966402

Epoch: 410| Step: 0
Training loss: 0.4316770615884875
Validation loss: 2.777287063699741

Epoch: 6| Step: 1
Training loss: 0.281477954991394
Validation loss: 2.825244905326842

Epoch: 6| Step: 2
Training loss: 0.36204293144521155
Validation loss: 2.7743229988153466

Epoch: 6| Step: 3
Training loss: 0.4299948720016327
Validation loss: 2.7499688175629857

Epoch: 6| Step: 4
Training loss: 0.4074595308686403
Validation loss: 2.8259679039227903

Epoch: 6| Step: 5
Training loss: 0.5971395964600289
Validation loss: 2.7219428829541554

Epoch: 6| Step: 6
Training loss: 0.26834943383695364
Validation loss: 2.640284958413322

Epoch: 6| Step: 7
Training loss: 0.4789981666711035
Validation loss: 2.668037261008771

Epoch: 6| Step: 8
Training loss: 0.3311431339010294
Validation loss: 2.729835651513715

Epoch: 6| Step: 9
Training loss: 0.36779074119179744
Validation loss: 2.7356070222497024

Epoch: 6| Step: 10
Training loss: 0.2659574279759786
Validation loss: 2.784857350022833

Epoch: 6| Step: 11
Training loss: 0.31001000211330854
Validation loss: 2.6968913590932186

Epoch: 6| Step: 12
Training loss: 0.3974486403003987
Validation loss: 2.766439414936514

Epoch: 6| Step: 13
Training loss: 0.28487594100341446
Validation loss: 2.7069034665523017

Epoch: 411| Step: 0
Training loss: 0.3732103518847778
Validation loss: 2.7388567861576085

Epoch: 6| Step: 1
Training loss: 0.2955787618902154
Validation loss: 2.7406045342394942

Epoch: 6| Step: 2
Training loss: 0.42684390947604395
Validation loss: 2.7701954119230034

Epoch: 6| Step: 3
Training loss: 0.35074502422299997
Validation loss: 2.7918413354309854

Epoch: 6| Step: 4
Training loss: 0.6779999226482876
Validation loss: 2.753227103249174

Epoch: 6| Step: 5
Training loss: 0.4099442797107615
Validation loss: 2.8345799695492695

Epoch: 6| Step: 6
Training loss: 0.4440972997356974
Validation loss: 2.742754987084935

Epoch: 6| Step: 7
Training loss: 0.32226589087273005
Validation loss: 2.877248078605498

Epoch: 6| Step: 8
Training loss: 0.3596177317998966
Validation loss: 2.7893467178637503

Epoch: 6| Step: 9
Training loss: 0.374344013568452
Validation loss: 2.7970263193351736

Epoch: 6| Step: 10
Training loss: 0.3740652673502627
Validation loss: 2.7608018474431923

Epoch: 6| Step: 11
Training loss: 0.3470536699743193
Validation loss: 2.7264731172996566

Epoch: 6| Step: 12
Training loss: 0.34136597856315615
Validation loss: 2.6793651776214937

Epoch: 6| Step: 13
Training loss: 0.46591120059155294
Validation loss: 2.7907834055426846

Epoch: 412| Step: 0
Training loss: 0.4660707196573212
Validation loss: 2.7083254055983104

Epoch: 6| Step: 1
Training loss: 0.3370646706795395
Validation loss: 2.758485043858819

Epoch: 6| Step: 2
Training loss: 0.3814132966074721
Validation loss: 2.6965107194001443

Epoch: 6| Step: 3
Training loss: 0.5988753606850515
Validation loss: 2.7802784683759074

Epoch: 6| Step: 4
Training loss: 0.6522520537660256
Validation loss: 2.666690607758181

Epoch: 6| Step: 5
Training loss: 0.41541705701931464
Validation loss: 2.729353648373663

Epoch: 6| Step: 6
Training loss: 0.4731279021845589
Validation loss: 2.7724500590746204

Epoch: 6| Step: 7
Training loss: 0.3484973590906748
Validation loss: 2.736554902667944

Epoch: 6| Step: 8
Training loss: 0.49125552875620526
Validation loss: 2.764210980677035

Epoch: 6| Step: 9
Training loss: 0.3580155158996083
Validation loss: 2.7314320012608033

Epoch: 6| Step: 10
Training loss: 0.3663841346622347
Validation loss: 2.7474886813753545

Epoch: 6| Step: 11
Training loss: 0.23723611508097917
Validation loss: 2.812131250014397

Epoch: 6| Step: 12
Training loss: 0.3797195789929934
Validation loss: 2.745969824710131

Epoch: 6| Step: 13
Training loss: 0.30535231710347793
Validation loss: 2.7385226663419093

Epoch: 413| Step: 0
Training loss: 0.27920540065266025
Validation loss: 2.7371418206217397

Epoch: 6| Step: 1
Training loss: 0.5019564498613133
Validation loss: 2.8001492903283247

Epoch: 6| Step: 2
Training loss: 0.3639603696670441
Validation loss: 2.6792925144102044

Epoch: 6| Step: 3
Training loss: 0.35117689814385555
Validation loss: 2.691886117175767

Epoch: 6| Step: 4
Training loss: 0.28741957327358386
Validation loss: 2.836098462345497

Epoch: 6| Step: 5
Training loss: 0.47748105061463975
Validation loss: 2.7483641498458087

Epoch: 6| Step: 6
Training loss: 0.4103563274849495
Validation loss: 2.696701885868881

Epoch: 6| Step: 7
Training loss: 0.3534422951195106
Validation loss: 2.8340912160576375

Epoch: 6| Step: 8
Training loss: 0.4747082014761985
Validation loss: 2.775300230504471

Epoch: 6| Step: 9
Training loss: 0.2961645660665792
Validation loss: 2.7895212802343066

Epoch: 6| Step: 10
Training loss: 0.25636634395239133
Validation loss: 2.762139273519304

Epoch: 6| Step: 11
Training loss: 0.6647419763075803
Validation loss: 2.73275396343606

Epoch: 6| Step: 12
Training loss: 0.2814957154652595
Validation loss: 2.7038749874511727

Epoch: 6| Step: 13
Training loss: 0.5119066257511523
Validation loss: 2.769374453792003

Epoch: 414| Step: 0
Training loss: 0.5813326130885874
Validation loss: 2.7112920274609142

Epoch: 6| Step: 1
Training loss: 0.6176715835609587
Validation loss: 2.733168606524017

Epoch: 6| Step: 2
Training loss: 0.33794619814355026
Validation loss: 2.7076552324654335

Epoch: 6| Step: 3
Training loss: 0.3683194103385678
Validation loss: 2.7633158711716472

Epoch: 6| Step: 4
Training loss: 0.3760698078999358
Validation loss: 2.7836486673946768

Epoch: 6| Step: 5
Training loss: 0.28741552936405995
Validation loss: 2.8034596000006955

Epoch: 6| Step: 6
Training loss: 0.43955956759397447
Validation loss: 2.741292345491394

Epoch: 6| Step: 7
Training loss: 0.3492733176693201
Validation loss: 2.708861392455954

Epoch: 6| Step: 8
Training loss: 0.3566616290321982
Validation loss: 2.7784471139872724

Epoch: 6| Step: 9
Training loss: 0.23285500055292183
Validation loss: 2.7967107145624275

Epoch: 6| Step: 10
Training loss: 0.4805741233337849
Validation loss: 2.757693841991278

Epoch: 6| Step: 11
Training loss: 0.3414203095323611
Validation loss: 2.7808004580314822

Epoch: 6| Step: 12
Training loss: 0.3191110244713576
Validation loss: 2.683668058755678

Epoch: 6| Step: 13
Training loss: 0.2877336578815938
Validation loss: 2.7940500295998096

Epoch: 415| Step: 0
Training loss: 0.34314992937437183
Validation loss: 2.7535316014043962

Epoch: 6| Step: 1
Training loss: 0.2980552727152417
Validation loss: 2.7124371516949735

Epoch: 6| Step: 2
Training loss: 0.32016923072902914
Validation loss: 2.7565164086960414

Epoch: 6| Step: 3
Training loss: 0.34822567372686536
Validation loss: 2.723262637242908

Epoch: 6| Step: 4
Training loss: 0.3109972824440986
Validation loss: 2.7735808429478945

Epoch: 6| Step: 5
Training loss: 0.2954276213724373
Validation loss: 2.787534535626014

Epoch: 6| Step: 6
Training loss: 0.28359332334207854
Validation loss: 2.7577830773243823

Epoch: 6| Step: 7
Training loss: 0.3266287020149762
Validation loss: 2.7593739153527577

Epoch: 6| Step: 8
Training loss: 0.49343518650993534
Validation loss: 2.7447000496694787

Epoch: 6| Step: 9
Training loss: 0.36055503827707586
Validation loss: 2.729093657431887

Epoch: 6| Step: 10
Training loss: 0.2796714511720858
Validation loss: 2.7928263452323385

Epoch: 6| Step: 11
Training loss: 0.6242905882174059
Validation loss: 2.7818632414172275

Epoch: 6| Step: 12
Training loss: 0.3723917496286131
Validation loss: 2.756206185128868

Epoch: 6| Step: 13
Training loss: 0.5365839104443677
Validation loss: 2.8059129083458383

Epoch: 416| Step: 0
Training loss: 0.6378217633110639
Validation loss: 2.739199279050977

Epoch: 6| Step: 1
Training loss: 0.580667960073335
Validation loss: 2.816461006157827

Epoch: 6| Step: 2
Training loss: 0.3840927397988036
Validation loss: 2.7569552305786207

Epoch: 6| Step: 3
Training loss: 0.3658312851400252
Validation loss: 2.840066403454412

Epoch: 6| Step: 4
Training loss: 0.5017636308818998
Validation loss: 2.761551970212542

Epoch: 6| Step: 5
Training loss: 0.48360326261516273
Validation loss: 2.734379388714856

Epoch: 6| Step: 6
Training loss: 0.27806502563536806
Validation loss: 2.7727542805765766

Epoch: 6| Step: 7
Training loss: 0.3619440345273088
Validation loss: 2.7793329325463927

Epoch: 6| Step: 8
Training loss: 0.3330799818843013
Validation loss: 2.7445737087470365

Epoch: 6| Step: 9
Training loss: 0.3512296160284702
Validation loss: 2.7765706305670133

Epoch: 6| Step: 10
Training loss: 0.3059033928543953
Validation loss: 2.7791529403949973

Epoch: 6| Step: 11
Training loss: 0.3237453819740883
Validation loss: 2.7352286032773727

Epoch: 6| Step: 12
Training loss: 0.4005425885876831
Validation loss: 2.7779933421945677

Epoch: 6| Step: 13
Training loss: 0.4720121361235036
Validation loss: 2.83061763165852

Epoch: 417| Step: 0
Training loss: 0.44507868802405126
Validation loss: 2.805643554499245

Epoch: 6| Step: 1
Training loss: 0.3596829877581965
Validation loss: 2.7686414342854606

Epoch: 6| Step: 2
Training loss: 0.556123352634822
Validation loss: 2.763546538010172

Epoch: 6| Step: 3
Training loss: 0.3549209607813903
Validation loss: 2.764953689854203

Epoch: 6| Step: 4
Training loss: 0.45913838176818655
Validation loss: 2.82442957934061

Epoch: 6| Step: 5
Training loss: 0.2792312705077817
Validation loss: 2.761183352733151

Epoch: 6| Step: 6
Training loss: 0.3937069430348746
Validation loss: 2.748619318202315

Epoch: 6| Step: 7
Training loss: 0.5156668443751424
Validation loss: 2.7583906740142687

Epoch: 6| Step: 8
Training loss: 0.34305237291552587
Validation loss: 2.7156967469670517

Epoch: 6| Step: 9
Training loss: 0.4908256916035247
Validation loss: 2.7645665817692286

Epoch: 6| Step: 10
Training loss: 0.4409923807511006
Validation loss: 2.8183520575393355

Epoch: 6| Step: 11
Training loss: 0.3454367478833363
Validation loss: 2.786068260959547

Epoch: 6| Step: 12
Training loss: 0.47683732910153187
Validation loss: 2.7118419417380886

Epoch: 6| Step: 13
Training loss: 0.4664747012209731
Validation loss: 2.778700027485516

Epoch: 418| Step: 0
Training loss: 0.43549165247330734
Validation loss: 2.704113803301753

Epoch: 6| Step: 1
Training loss: 0.46583400362315713
Validation loss: 2.804545831954276

Epoch: 6| Step: 2
Training loss: 0.45563579329381654
Validation loss: 2.8431250895155444

Epoch: 6| Step: 3
Training loss: 0.230684413868082
Validation loss: 2.7310814049637067

Epoch: 6| Step: 4
Training loss: 0.4774475634078974
Validation loss: 2.699077037545258

Epoch: 6| Step: 5
Training loss: 0.32484757672982967
Validation loss: 2.706102058531074

Epoch: 6| Step: 6
Training loss: 0.5414460050620976
Validation loss: 2.7814839011144783

Epoch: 6| Step: 7
Training loss: 0.4725659181642512
Validation loss: 2.6880230801183727

Epoch: 6| Step: 8
Training loss: 0.6253306944495903
Validation loss: 2.768126482537898

Epoch: 6| Step: 9
Training loss: 0.25762045093982594
Validation loss: 2.777282563942595

Epoch: 6| Step: 10
Training loss: 0.3736726395656796
Validation loss: 2.838588711876604

Epoch: 6| Step: 11
Training loss: 0.442987563391375
Validation loss: 2.7773101990609663

Epoch: 6| Step: 12
Training loss: 0.3696566411325164
Validation loss: 2.738589093095222

Epoch: 6| Step: 13
Training loss: 0.4152156499047997
Validation loss: 2.871553276119985

Epoch: 419| Step: 0
Training loss: 0.5004350438529959
Validation loss: 2.818822592218526

Epoch: 6| Step: 1
Training loss: 0.37263362024081625
Validation loss: 2.791000989052918

Epoch: 6| Step: 2
Training loss: 0.4752705681818399
Validation loss: 2.7506154989921985

Epoch: 6| Step: 3
Training loss: 0.46137866228707325
Validation loss: 2.7697283374728774

Epoch: 6| Step: 4
Training loss: 0.5940298123825668
Validation loss: 2.761568229922309

Epoch: 6| Step: 5
Training loss: 0.48155791414764465
Validation loss: 2.748543353533588

Epoch: 6| Step: 6
Training loss: 0.2736537895357752
Validation loss: 2.749453287977777

Epoch: 6| Step: 7
Training loss: 0.5546800854684356
Validation loss: 2.740433598456833

Epoch: 6| Step: 8
Training loss: 0.3507955556726354
Validation loss: 2.7795806904271623

Epoch: 6| Step: 9
Training loss: 0.575068020943681
Validation loss: 2.7747040341607807

Epoch: 6| Step: 10
Training loss: 0.3974009288129526
Validation loss: 2.722667371160707

Epoch: 6| Step: 11
Training loss: 0.26810271637357536
Validation loss: 2.7800481821362713

Epoch: 6| Step: 12
Training loss: 0.3542817386981507
Validation loss: 2.789781436813575

Epoch: 6| Step: 13
Training loss: 0.3056648790634997
Validation loss: 2.7619568516645487

Epoch: 420| Step: 0
Training loss: 0.3867167655816845
Validation loss: 2.7993682886684668

Epoch: 6| Step: 1
Training loss: 0.4981115560978964
Validation loss: 2.704482294558913

Epoch: 6| Step: 2
Training loss: 0.43582045511775236
Validation loss: 2.770331385089659

Epoch: 6| Step: 3
Training loss: 0.5302131576418533
Validation loss: 2.6922228072307455

Epoch: 6| Step: 4
Training loss: 0.5175787008030406
Validation loss: 2.7408688554542837

Epoch: 6| Step: 5
Training loss: 0.44773463683020026
Validation loss: 2.7734316973558357

Epoch: 6| Step: 6
Training loss: 0.2957513903353814
Validation loss: 2.769862461416741

Epoch: 6| Step: 7
Training loss: 0.27031667959697464
Validation loss: 2.7766069238730036

Epoch: 6| Step: 8
Training loss: 0.46088790626757314
Validation loss: 2.76486210618901

Epoch: 6| Step: 9
Training loss: 0.45275615610121783
Validation loss: 2.7650502931413885

Epoch: 6| Step: 10
Training loss: 0.5246255402052096
Validation loss: 2.7383082701855037

Epoch: 6| Step: 11
Training loss: 0.45353619235614356
Validation loss: 2.784545203650005

Epoch: 6| Step: 12
Training loss: 0.42545684215008
Validation loss: 2.789088080793764

Epoch: 6| Step: 13
Training loss: 0.330803857714601
Validation loss: 2.7136070453482612

Epoch: 421| Step: 0
Training loss: 0.3569314228623278
Validation loss: 2.6887082924852708

Epoch: 6| Step: 1
Training loss: 0.547294809787158
Validation loss: 2.787271417845102

Epoch: 6| Step: 2
Training loss: 0.3801480032029869
Validation loss: 2.750656497505992

Epoch: 6| Step: 3
Training loss: 0.3025289022809503
Validation loss: 2.7430069180024814

Epoch: 6| Step: 4
Training loss: 0.5362764871275866
Validation loss: 2.792037303480433

Epoch: 6| Step: 5
Training loss: 0.2820392369753504
Validation loss: 2.838883732241306

Epoch: 6| Step: 6
Training loss: 0.29515427786156617
Validation loss: 2.679820273384394

Epoch: 6| Step: 7
Training loss: 0.28282793118861316
Validation loss: 2.684222151964362

Epoch: 6| Step: 8
Training loss: 0.31092470804096334
Validation loss: 2.6962817821890273

Epoch: 6| Step: 9
Training loss: 0.5205110760956844
Validation loss: 2.8554619033668773

Epoch: 6| Step: 10
Training loss: 0.3247267982374676
Validation loss: 2.790326427792798

Epoch: 6| Step: 11
Training loss: 0.3154321440137511
Validation loss: 2.7678331371151184

Epoch: 6| Step: 12
Training loss: 0.42125622971113696
Validation loss: 2.7154452382574195

Epoch: 6| Step: 13
Training loss: 0.39524640522141896
Validation loss: 2.7347787758752076

Epoch: 422| Step: 0
Training loss: 0.4378406016270836
Validation loss: 2.7357515049282757

Epoch: 6| Step: 1
Training loss: 0.34493502184652786
Validation loss: 2.70822679359008

Epoch: 6| Step: 2
Training loss: 0.4155638843432424
Validation loss: 2.7782641753216653

Epoch: 6| Step: 3
Training loss: 0.32400409072777825
Validation loss: 2.8157876473324106

Epoch: 6| Step: 4
Training loss: 0.40610219027124195
Validation loss: 2.747627246144294

Epoch: 6| Step: 5
Training loss: 0.35742525192916774
Validation loss: 2.737608372997728

Epoch: 6| Step: 6
Training loss: 0.5009864969737148
Validation loss: 2.7091835790329406

Epoch: 6| Step: 7
Training loss: 0.4293406213437725
Validation loss: 2.6927298367279326

Epoch: 6| Step: 8
Training loss: 0.37185013631838953
Validation loss: 2.7366104288940094

Epoch: 6| Step: 9
Training loss: 0.369394689251407
Validation loss: 2.729285875779362

Epoch: 6| Step: 10
Training loss: 0.30752196276161664
Validation loss: 2.7353854392352117

Epoch: 6| Step: 11
Training loss: 0.559258365725418
Validation loss: 2.8150605166871423

Epoch: 6| Step: 12
Training loss: 0.4244059829188628
Validation loss: 2.7605111351882594

Epoch: 6| Step: 13
Training loss: 0.5698247679092389
Validation loss: 2.6614920557402675

Epoch: 423| Step: 0
Training loss: 0.42819222458479744
Validation loss: 2.7359178531855584

Epoch: 6| Step: 1
Training loss: 0.29932560369850786
Validation loss: 2.7400788317197176

Epoch: 6| Step: 2
Training loss: 0.4737340130788388
Validation loss: 2.7800211245376847

Epoch: 6| Step: 3
Training loss: 0.5035040381306582
Validation loss: 2.7890129761702314

Epoch: 6| Step: 4
Training loss: 0.21957538066146084
Validation loss: 2.736640834252764

Epoch: 6| Step: 5
Training loss: 0.44291092967890094
Validation loss: 2.746662238412207

Epoch: 6| Step: 6
Training loss: 0.29364784371746855
Validation loss: 2.7798005802797174

Epoch: 6| Step: 7
Training loss: 0.5052497755009578
Validation loss: 2.735505413543954

Epoch: 6| Step: 8
Training loss: 0.30851645648503256
Validation loss: 2.724043432089263

Epoch: 6| Step: 9
Training loss: 0.394477217345168
Validation loss: 2.863193817677289

Epoch: 6| Step: 10
Training loss: 0.3774362936327511
Validation loss: 2.688408010698623

Epoch: 6| Step: 11
Training loss: 0.4602622565813691
Validation loss: 2.7209851077063734

Epoch: 6| Step: 12
Training loss: 0.2897984569562121
Validation loss: 2.8465191699356955

Epoch: 6| Step: 13
Training loss: 0.4222796583358092
Validation loss: 2.746486066031827

Epoch: 424| Step: 0
Training loss: 0.37751676490642855
Validation loss: 2.7684353416415224

Epoch: 6| Step: 1
Training loss: 0.39184326931681857
Validation loss: 2.7835125381966677

Epoch: 6| Step: 2
Training loss: 0.32847925771840747
Validation loss: 2.7446908709110738

Epoch: 6| Step: 3
Training loss: 0.4928455495063158
Validation loss: 2.7863181723641484

Epoch: 6| Step: 4
Training loss: 0.42732693152658713
Validation loss: 2.690297038921237

Epoch: 6| Step: 5
Training loss: 0.35858120532730114
Validation loss: 2.7733694865165823

Epoch: 6| Step: 6
Training loss: 0.30070078380344284
Validation loss: 2.755762117878956

Epoch: 6| Step: 7
Training loss: 0.3203545286936448
Validation loss: 2.7881115201276323

Epoch: 6| Step: 8
Training loss: 0.5917232203207693
Validation loss: 2.7657353438439296

Epoch: 6| Step: 9
Training loss: 0.5068338206693511
Validation loss: 2.7164139193189882

Epoch: 6| Step: 10
Training loss: 0.6504106948092891
Validation loss: 2.7687745919150863

Epoch: 6| Step: 11
Training loss: 0.3970819864653848
Validation loss: 2.7757006084403493

Epoch: 6| Step: 12
Training loss: 0.27294236722204873
Validation loss: 2.7834900396931848

Epoch: 6| Step: 13
Training loss: 0.47718356265159284
Validation loss: 2.7640819806924997

Epoch: 425| Step: 0
Training loss: 0.45777613915314236
Validation loss: 2.7492970015993974

Epoch: 6| Step: 1
Training loss: 0.4501600934400473
Validation loss: 2.752350164198983

Epoch: 6| Step: 2
Training loss: 0.3717395984756798
Validation loss: 2.747426389310359

Epoch: 6| Step: 3
Training loss: 0.38762452754927124
Validation loss: 2.6999718093577756

Epoch: 6| Step: 4
Training loss: 0.391256660916602
Validation loss: 2.7409782750339096

Epoch: 6| Step: 5
Training loss: 0.39510530311561165
Validation loss: 2.742485964799157

Epoch: 6| Step: 6
Training loss: 0.34272428850332026
Validation loss: 2.6696356745788994

Epoch: 6| Step: 7
Training loss: 0.5492987193333134
Validation loss: 2.7226124289738363

Epoch: 6| Step: 8
Training loss: 0.3507210941176877
Validation loss: 2.703131967877354

Epoch: 6| Step: 9
Training loss: 0.282674770117518
Validation loss: 2.7354892603898655

Epoch: 6| Step: 10
Training loss: 0.4545574893767044
Validation loss: 2.723385188318359

Epoch: 6| Step: 11
Training loss: 0.38669940630381616
Validation loss: 2.679202911780419

Epoch: 6| Step: 12
Training loss: 0.40627571171310967
Validation loss: 2.797624768113121

Epoch: 6| Step: 13
Training loss: 0.5052573255661906
Validation loss: 2.6812125075178344

Epoch: 426| Step: 0
Training loss: 0.2886722094955881
Validation loss: 2.677190464315432

Epoch: 6| Step: 1
Training loss: 0.29714145748986465
Validation loss: 2.815458183131137

Epoch: 6| Step: 2
Training loss: 0.4163493219506835
Validation loss: 2.7571216038417257

Epoch: 6| Step: 3
Training loss: 0.39021140136911137
Validation loss: 2.6957161716273896

Epoch: 6| Step: 4
Training loss: 0.47467713990750016
Validation loss: 2.754468560132691

Epoch: 6| Step: 5
Training loss: 0.45365458814696685
Validation loss: 2.704897804539146

Epoch: 6| Step: 6
Training loss: 0.25917475048155103
Validation loss: 2.7109280456905793

Epoch: 6| Step: 7
Training loss: 0.2816869731971786
Validation loss: 2.6713240577834063

Epoch: 6| Step: 8
Training loss: 0.3725475344635062
Validation loss: 2.705113798381373

Epoch: 6| Step: 9
Training loss: 0.3083838702790533
Validation loss: 2.747519949810803

Epoch: 6| Step: 10
Training loss: 0.5353526847796974
Validation loss: 2.6862899140756

Epoch: 6| Step: 11
Training loss: 0.4288273785724145
Validation loss: 2.698674649035795

Epoch: 6| Step: 12
Training loss: 0.3669527805157012
Validation loss: 2.699756206290662

Epoch: 6| Step: 13
Training loss: 0.21256496298971742
Validation loss: 2.7252511384128346

Epoch: 427| Step: 0
Training loss: 0.48919808333443304
Validation loss: 2.762904623441912

Epoch: 6| Step: 1
Training loss: 0.4370124859510113
Validation loss: 2.753141140899511

Epoch: 6| Step: 2
Training loss: 0.5034558256994449
Validation loss: 2.7240754728980954

Epoch: 6| Step: 3
Training loss: 0.3722767094726129
Validation loss: 2.692839485875243

Epoch: 6| Step: 4
Training loss: 0.285998876165136
Validation loss: 2.7622338605502397

Epoch: 6| Step: 5
Training loss: 0.39546011177916834
Validation loss: 2.7597535230511188

Epoch: 6| Step: 6
Training loss: 0.5491293355508808
Validation loss: 2.774271894135895

Epoch: 6| Step: 7
Training loss: 0.37396570462299966
Validation loss: 2.7256427222741957

Epoch: 6| Step: 8
Training loss: 0.5886955453914415
Validation loss: 2.7532992295938685

Epoch: 6| Step: 9
Training loss: 0.23375725398308178
Validation loss: 2.789678197552991

Epoch: 6| Step: 10
Training loss: 0.41946910134986887
Validation loss: 2.7728095118231644

Epoch: 6| Step: 11
Training loss: 0.3126544094079176
Validation loss: 2.737867773077406

Epoch: 6| Step: 12
Training loss: 0.4736221154961499
Validation loss: 2.7211818123344917

Epoch: 6| Step: 13
Training loss: 0.49161337109683784
Validation loss: 2.7449870513536494

Epoch: 428| Step: 0
Training loss: 0.39643184896474176
Validation loss: 2.7576256995834467

Epoch: 6| Step: 1
Training loss: 0.27249038701206446
Validation loss: 2.774795858646994

Epoch: 6| Step: 2
Training loss: 0.5996753519645692
Validation loss: 2.7922862821900525

Epoch: 6| Step: 3
Training loss: 0.3783713822760534
Validation loss: 2.8018599968340543

Epoch: 6| Step: 4
Training loss: 0.34958673116141314
Validation loss: 2.7795495253298497

Epoch: 6| Step: 5
Training loss: 0.3459542865350327
Validation loss: 2.7749886629944127

Epoch: 6| Step: 6
Training loss: 0.24586476162808898
Validation loss: 2.737022092260591

Epoch: 6| Step: 7
Training loss: 0.3908399753304406
Validation loss: 2.674001683912981

Epoch: 6| Step: 8
Training loss: 0.4695331865419894
Validation loss: 2.751087941641537

Epoch: 6| Step: 9
Training loss: 0.3721467187480811
Validation loss: 2.734128523117463

Epoch: 6| Step: 10
Training loss: 0.3439670224462188
Validation loss: 2.712686536970072

Epoch: 6| Step: 11
Training loss: 0.3926976339904717
Validation loss: 2.7639013260306484

Epoch: 6| Step: 12
Training loss: 0.4287542612347837
Validation loss: 2.7362435559481084

Epoch: 6| Step: 13
Training loss: 0.47054878648689213
Validation loss: 2.7821285988853717

Epoch: 429| Step: 0
Training loss: 0.4652887186105221
Validation loss: 2.7451351223539215

Epoch: 6| Step: 1
Training loss: 0.35233201474695197
Validation loss: 2.8002143403166637

Epoch: 6| Step: 2
Training loss: 0.44947721260621454
Validation loss: 2.781367803071838

Epoch: 6| Step: 3
Training loss: 0.33499202083579144
Validation loss: 2.7032535647356393

Epoch: 6| Step: 4
Training loss: 0.4429262877603883
Validation loss: 2.739400144382282

Epoch: 6| Step: 5
Training loss: 0.5437452129723307
Validation loss: 2.79884849837298

Epoch: 6| Step: 6
Training loss: 0.3296626257891446
Validation loss: 2.739879205389302

Epoch: 6| Step: 7
Training loss: 0.3735294715598378
Validation loss: 2.755670509922954

Epoch: 6| Step: 8
Training loss: 0.3338836384151676
Validation loss: 2.819726236686028

Epoch: 6| Step: 9
Training loss: 0.3095747649537483
Validation loss: 2.726190630922097

Epoch: 6| Step: 10
Training loss: 0.5636011577613261
Validation loss: 2.7653564710695955

Epoch: 6| Step: 11
Training loss: 0.349176863904206
Validation loss: 2.7123410185649197

Epoch: 6| Step: 12
Training loss: 0.2696984643132891
Validation loss: 2.676523993772427

Epoch: 6| Step: 13
Training loss: 0.440235052641353
Validation loss: 2.765518215150952

Epoch: 430| Step: 0
Training loss: 0.3703717284983441
Validation loss: 2.7827194561005015

Epoch: 6| Step: 1
Training loss: 0.2919392872737075
Validation loss: 2.7723689210139586

Epoch: 6| Step: 2
Training loss: 0.2804879885905019
Validation loss: 2.784328371535936

Epoch: 6| Step: 3
Training loss: 0.3910818480243896
Validation loss: 2.725693492254805

Epoch: 6| Step: 4
Training loss: 0.34608658036153106
Validation loss: 2.74352026971868

Epoch: 6| Step: 5
Training loss: 0.4342533970503947
Validation loss: 2.7392487315561747

Epoch: 6| Step: 6
Training loss: 0.624248935509119
Validation loss: 2.7513162757277603

Epoch: 6| Step: 7
Training loss: 0.4037344332844481
Validation loss: 2.7619728787992206

Epoch: 6| Step: 8
Training loss: 0.4327196124827151
Validation loss: 2.8201364689467745

Epoch: 6| Step: 9
Training loss: 0.39527518884139073
Validation loss: 2.7413307148371087

Epoch: 6| Step: 10
Training loss: 0.31941159253345136
Validation loss: 2.756902081548177

Epoch: 6| Step: 11
Training loss: 0.2755673700318897
Validation loss: 2.6729579612136756

Epoch: 6| Step: 12
Training loss: 0.3710338744998662
Validation loss: 2.794971237262093

Epoch: 6| Step: 13
Training loss: 0.512464024281272
Validation loss: 2.796643196033235

Epoch: 431| Step: 0
Training loss: 0.23715981036610195
Validation loss: 2.738797489684841

Epoch: 6| Step: 1
Training loss: 0.2742525487431869
Validation loss: 2.7738136573696774

Epoch: 6| Step: 2
Training loss: 0.6021736310501049
Validation loss: 2.7795625132121837

Epoch: 6| Step: 3
Training loss: 0.25901758432714417
Validation loss: 2.6902398625751713

Epoch: 6| Step: 4
Training loss: 0.22034891787982377
Validation loss: 2.7422376811045015

Epoch: 6| Step: 5
Training loss: 0.3432952191649438
Validation loss: 2.7282419360990784

Epoch: 6| Step: 6
Training loss: 0.4279161180358361
Validation loss: 2.681951383962224

Epoch: 6| Step: 7
Training loss: 0.5560721991903179
Validation loss: 2.7778604190507084

Epoch: 6| Step: 8
Training loss: 0.29109640088514976
Validation loss: 2.7059777408463455

Epoch: 6| Step: 9
Training loss: 0.3513809265029109
Validation loss: 2.7881092967999486

Epoch: 6| Step: 10
Training loss: 0.31148348226196854
Validation loss: 2.7596082883253

Epoch: 6| Step: 11
Training loss: 0.34253005818223264
Validation loss: 2.658723808677282

Epoch: 6| Step: 12
Training loss: 0.3261595626608733
Validation loss: 2.77712566880516

Epoch: 6| Step: 13
Training loss: 0.45174965461460204
Validation loss: 2.7406401801622278

Epoch: 432| Step: 0
Training loss: 0.5636213040682251
Validation loss: 2.7616419298134254

Epoch: 6| Step: 1
Training loss: 0.5723711769224585
Validation loss: 2.7504228498018257

Epoch: 6| Step: 2
Training loss: 0.3879528007347721
Validation loss: 2.7385189227154516

Epoch: 6| Step: 3
Training loss: 0.40565603190422733
Validation loss: 2.759250428097688

Epoch: 6| Step: 4
Training loss: 0.33997951733376114
Validation loss: 2.7946232232513037

Epoch: 6| Step: 5
Training loss: 0.39679870923499544
Validation loss: 2.75676549645162

Epoch: 6| Step: 6
Training loss: 0.41654080834541496
Validation loss: 2.7366375091368593

Epoch: 6| Step: 7
Training loss: 0.4531176993998689
Validation loss: 2.683795097752751

Epoch: 6| Step: 8
Training loss: 0.34420738352096675
Validation loss: 2.707101737495073

Epoch: 6| Step: 9
Training loss: 0.4041118106123346
Validation loss: 2.7174315050717412

Epoch: 6| Step: 10
Training loss: 0.3731061279214371
Validation loss: 2.773394474179353

Epoch: 6| Step: 11
Training loss: 0.4955855793086072
Validation loss: 2.7528404680571374

Epoch: 6| Step: 12
Training loss: 0.4611505565598178
Validation loss: 2.740702706210053

Epoch: 6| Step: 13
Training loss: 0.3547993529818655
Validation loss: 2.7182677561110054

Epoch: 433| Step: 0
Training loss: 0.20127391079316656
Validation loss: 2.748064053284528

Epoch: 6| Step: 1
Training loss: 0.386725377498055
Validation loss: 2.786229223416612

Epoch: 6| Step: 2
Training loss: 0.4907367913027585
Validation loss: 2.7915044969930976

Epoch: 6| Step: 3
Training loss: 0.3320836867271148
Validation loss: 2.711625069703819

Epoch: 6| Step: 4
Training loss: 0.36605050196629507
Validation loss: 2.7409349788917594

Epoch: 6| Step: 5
Training loss: 0.3312092535581453
Validation loss: 2.7390668307188726

Epoch: 6| Step: 6
Training loss: 0.47013879717618245
Validation loss: 2.78572535396189

Epoch: 6| Step: 7
Training loss: 0.37091590233573135
Validation loss: 2.731481448914072

Epoch: 6| Step: 8
Training loss: 0.3087597895240165
Validation loss: 2.775535699612822

Epoch: 6| Step: 9
Training loss: 0.33647414525594715
Validation loss: 2.7356056132627184

Epoch: 6| Step: 10
Training loss: 0.6372351863092568
Validation loss: 2.683209431988352

Epoch: 6| Step: 11
Training loss: 0.3645769209524908
Validation loss: 2.7346079699861403

Epoch: 6| Step: 12
Training loss: 0.3307032337184036
Validation loss: 2.848033655010636

Epoch: 6| Step: 13
Training loss: 0.3281220367842797
Validation loss: 2.7340376872953582

Epoch: 434| Step: 0
Training loss: 0.32993351855497954
Validation loss: 2.7128611252464534

Epoch: 6| Step: 1
Training loss: 0.4333907674666861
Validation loss: 2.7218839625529645

Epoch: 6| Step: 2
Training loss: 0.2971164574733126
Validation loss: 2.810363749427007

Epoch: 6| Step: 3
Training loss: 0.2506032757844871
Validation loss: 2.778798812663993

Epoch: 6| Step: 4
Training loss: 0.3455876734135802
Validation loss: 2.7922869510369366

Epoch: 6| Step: 5
Training loss: 0.37614686750116466
Validation loss: 2.798751869059057

Epoch: 6| Step: 6
Training loss: 0.376533314060579
Validation loss: 2.7234000417351467

Epoch: 6| Step: 7
Training loss: 0.44494401175043075
Validation loss: 2.7647009130070397

Epoch: 6| Step: 8
Training loss: 0.3249498649588083
Validation loss: 2.8264931454645406

Epoch: 6| Step: 9
Training loss: 0.25197799323319814
Validation loss: 2.800023414877218

Epoch: 6| Step: 10
Training loss: 0.21715790526379125
Validation loss: 2.798261614848527

Epoch: 6| Step: 11
Training loss: 0.6147422881307816
Validation loss: 2.7834718094906816

Epoch: 6| Step: 12
Training loss: 0.3375905749853104
Validation loss: 2.733230627464122

Epoch: 6| Step: 13
Training loss: 0.4107128181786708
Validation loss: 2.7905136165909816

Epoch: 435| Step: 0
Training loss: 0.3939930105388157
Validation loss: 2.751951450034237

Epoch: 6| Step: 1
Training loss: 0.26175104482873973
Validation loss: 2.7931236099668775

Epoch: 6| Step: 2
Training loss: 0.34230842456825855
Validation loss: 2.7994066852974595

Epoch: 6| Step: 3
Training loss: 0.3293778705652799
Validation loss: 2.756355527557406

Epoch: 6| Step: 4
Training loss: 0.28174251242490034
Validation loss: 2.79579791138027

Epoch: 6| Step: 5
Training loss: 0.37096619672573833
Validation loss: 2.727959567338104

Epoch: 6| Step: 6
Training loss: 0.3190518203128645
Validation loss: 2.7968215653129653

Epoch: 6| Step: 7
Training loss: 0.3359521374729411
Validation loss: 2.7435642130290283

Epoch: 6| Step: 8
Training loss: 0.2846841562160588
Validation loss: 2.791040169937413

Epoch: 6| Step: 9
Training loss: 0.3336884598661923
Validation loss: 2.7530271168518894

Epoch: 6| Step: 10
Training loss: 0.5531725275773755
Validation loss: 2.799772526946947

Epoch: 6| Step: 11
Training loss: 0.37931561723283996
Validation loss: 2.750882238419244

Epoch: 6| Step: 12
Training loss: 0.28444017355124873
Validation loss: 2.719512094548754

Epoch: 6| Step: 13
Training loss: 0.5311997333755744
Validation loss: 2.8250241219495025

Epoch: 436| Step: 0
Training loss: 0.2567972364385398
Validation loss: 2.7824120112168464

Epoch: 6| Step: 1
Training loss: 0.21694714261503312
Validation loss: 2.813664371922336

Epoch: 6| Step: 2
Training loss: 0.18490265891859306
Validation loss: 2.670113888477301

Epoch: 6| Step: 3
Training loss: 0.36686609283370386
Validation loss: 2.802051562917385

Epoch: 6| Step: 4
Training loss: 0.40731975120375374
Validation loss: 2.785703486699935

Epoch: 6| Step: 5
Training loss: 0.3498658353096552
Validation loss: 2.7309924175157656

Epoch: 6| Step: 6
Training loss: 0.27050833581536415
Validation loss: 2.8203243068683923

Epoch: 6| Step: 7
Training loss: 0.359979825447952
Validation loss: 2.7426773749513202

Epoch: 6| Step: 8
Training loss: 0.5745444639095743
Validation loss: 2.7704822250903955

Epoch: 6| Step: 9
Training loss: 0.3546932900582156
Validation loss: 2.810330946180346

Epoch: 6| Step: 10
Training loss: 0.39605012612068125
Validation loss: 2.767023842709205

Epoch: 6| Step: 11
Training loss: 0.49584825704325375
Validation loss: 2.741142573793505

Epoch: 6| Step: 12
Training loss: 0.44920893119364375
Validation loss: 2.708867245401559

Epoch: 6| Step: 13
Training loss: 0.4338987497760514
Validation loss: 2.7619549237982772

Epoch: 437| Step: 0
Training loss: 0.4948665428392894
Validation loss: 2.734657229435913

Epoch: 6| Step: 1
Training loss: 0.45023431836534467
Validation loss: 2.783993628600565

Epoch: 6| Step: 2
Training loss: 0.34343416703527274
Validation loss: 2.7135534206924135

Epoch: 6| Step: 3
Training loss: 0.39145530195349953
Validation loss: 2.8096844532074345

Epoch: 6| Step: 4
Training loss: 0.3225730816517782
Validation loss: 2.76850934672694

Epoch: 6| Step: 5
Training loss: 0.523184273801551
Validation loss: 2.783592987417323

Epoch: 6| Step: 6
Training loss: 0.33201757290663825
Validation loss: 2.7639916835904543

Epoch: 6| Step: 7
Training loss: 0.3712459252194872
Validation loss: 2.737201791717212

Epoch: 6| Step: 8
Training loss: 0.3192655386597214
Validation loss: 2.7715162186230367

Epoch: 6| Step: 9
Training loss: 0.43036352211091444
Validation loss: 2.792042982064801

Epoch: 6| Step: 10
Training loss: 0.43570511342607754
Validation loss: 2.8091127131043203

Epoch: 6| Step: 11
Training loss: 0.37589726788496325
Validation loss: 2.8192214898546433

Epoch: 6| Step: 12
Training loss: 0.6104168422121526
Validation loss: 2.7392539973467565

Epoch: 6| Step: 13
Training loss: 0.33972081339510124
Validation loss: 2.717924277656406

Epoch: 438| Step: 0
Training loss: 0.5403026744507339
Validation loss: 2.7633216159681036

Epoch: 6| Step: 1
Training loss: 0.573258979720377
Validation loss: 2.7130824973957144

Epoch: 6| Step: 2
Training loss: 0.5467095260954046
Validation loss: 2.7507028115120202

Epoch: 6| Step: 3
Training loss: 0.6899921590248969
Validation loss: 2.7323641840252706

Epoch: 6| Step: 4
Training loss: 0.350529955801454
Validation loss: 2.694723313659979

Epoch: 6| Step: 5
Training loss: 0.3489322178116448
Validation loss: 2.737089716853108

Epoch: 6| Step: 6
Training loss: 0.3482782500331641
Validation loss: 2.7491224507128207

Epoch: 6| Step: 7
Training loss: 0.4943553473114616
Validation loss: 2.828437296167342

Epoch: 6| Step: 8
Training loss: 0.5603470396256232
Validation loss: 2.794583154142469

Epoch: 6| Step: 9
Training loss: 0.5329434108162531
Validation loss: 2.7312213549941338

Epoch: 6| Step: 10
Training loss: 0.461030692038712
Validation loss: 2.7779798034211187

Epoch: 6| Step: 11
Training loss: 0.4258728453780686
Validation loss: 2.7638063647433144

Epoch: 6| Step: 12
Training loss: 0.3601636525880757
Validation loss: 2.741280241714053

Epoch: 6| Step: 13
Training loss: 0.313975095210747
Validation loss: 2.7214582408126384

Epoch: 439| Step: 0
Training loss: 0.5214886611590887
Validation loss: 2.7405287896453485

Epoch: 6| Step: 1
Training loss: 0.5129779726768589
Validation loss: 2.695296902081603

Epoch: 6| Step: 2
Training loss: 0.46500717624131066
Validation loss: 2.7609056483534355

Epoch: 6| Step: 3
Training loss: 0.572393982328616
Validation loss: 2.7619241065293716

Epoch: 6| Step: 4
Training loss: 0.31337468996477713
Validation loss: 2.750773646163507

Epoch: 6| Step: 5
Training loss: 0.27653770443383235
Validation loss: 2.7610488071827604

Epoch: 6| Step: 6
Training loss: 0.465715056549541
Validation loss: 2.748771465310799

Epoch: 6| Step: 7
Training loss: 0.5479175167536456
Validation loss: 2.7415258364659256

Epoch: 6| Step: 8
Training loss: 0.3788388772430997
Validation loss: 2.7252781419804872

Epoch: 6| Step: 9
Training loss: 0.43569406665170446
Validation loss: 2.7773982318554538

Epoch: 6| Step: 10
Training loss: 0.4030805341460268
Validation loss: 2.7997180830857022

Epoch: 6| Step: 11
Training loss: 0.3056912394864057
Validation loss: 2.7308439434482925

Epoch: 6| Step: 12
Training loss: 0.36936501842896197
Validation loss: 2.782664435829776

Epoch: 6| Step: 13
Training loss: 0.5342200227394798
Validation loss: 2.7017435281266033

Epoch: 440| Step: 0
Training loss: 0.40729842249477943
Validation loss: 2.72258145098693

Epoch: 6| Step: 1
Training loss: 0.43450128242777514
Validation loss: 2.7648986178592514

Epoch: 6| Step: 2
Training loss: 0.24056112351919431
Validation loss: 2.762233112498215

Epoch: 6| Step: 3
Training loss: 0.41727371896486914
Validation loss: 2.776241042448888

Epoch: 6| Step: 4
Training loss: 0.36486324282735266
Validation loss: 2.7823388614934004

Epoch: 6| Step: 5
Training loss: 0.35623024500901485
Validation loss: 2.8541576125472385

Epoch: 6| Step: 6
Training loss: 0.39079132353844903
Validation loss: 2.781370196084775

Epoch: 6| Step: 7
Training loss: 0.3360073216646757
Validation loss: 2.6527440588795934

Epoch: 6| Step: 8
Training loss: 0.3071639097125898
Validation loss: 2.750769233045374

Epoch: 6| Step: 9
Training loss: 0.5665217840815914
Validation loss: 2.8173162759893984

Epoch: 6| Step: 10
Training loss: 0.3843598137933703
Validation loss: 2.742377061803656

Epoch: 6| Step: 11
Training loss: 0.48493343894448826
Validation loss: 2.7480809711870644

Epoch: 6| Step: 12
Training loss: 0.4937027208411285
Validation loss: 2.7567772295442996

Epoch: 6| Step: 13
Training loss: 0.3184836092576027
Validation loss: 2.7241779746980734

Epoch: 441| Step: 0
Training loss: 0.26777822433188664
Validation loss: 2.7128321231899415

Epoch: 6| Step: 1
Training loss: 0.537805501481159
Validation loss: 2.8292042761106755

Epoch: 6| Step: 2
Training loss: 0.36754428492900304
Validation loss: 2.758469572669141

Epoch: 6| Step: 3
Training loss: 0.5200851470670332
Validation loss: 2.7334610492440112

Epoch: 6| Step: 4
Training loss: 0.29167162800156826
Validation loss: 2.7996539867138353

Epoch: 6| Step: 5
Training loss: 0.4325588006086144
Validation loss: 2.7140211583518967

Epoch: 6| Step: 6
Training loss: 0.26709400013369317
Validation loss: 2.7787853850644093

Epoch: 6| Step: 7
Training loss: 0.33400881270743216
Validation loss: 2.7523204521314204

Epoch: 6| Step: 8
Training loss: 0.49700315730053385
Validation loss: 2.786362866819214

Epoch: 6| Step: 9
Training loss: 0.4179493730278164
Validation loss: 2.7693416815741965

Epoch: 6| Step: 10
Training loss: 0.2445530269298203
Validation loss: 2.7592034654881457

Epoch: 6| Step: 11
Training loss: 0.4675530091490037
Validation loss: 2.7577348793640484

Epoch: 6| Step: 12
Training loss: 0.39727160093900926
Validation loss: 2.791956236515435

Epoch: 6| Step: 13
Training loss: 0.3340301036202995
Validation loss: 2.7446586509096766

Epoch: 442| Step: 0
Training loss: 0.3057670907127693
Validation loss: 2.743389884007418

Epoch: 6| Step: 1
Training loss: 0.24145443012702167
Validation loss: 2.7380985737813845

Epoch: 6| Step: 2
Training loss: 0.3916757185207873
Validation loss: 2.7319037832679673

Epoch: 6| Step: 3
Training loss: 0.2733980831618669
Validation loss: 2.7928338291685066

Epoch: 6| Step: 4
Training loss: 0.33360947654514966
Validation loss: 2.7812653587574445

Epoch: 6| Step: 5
Training loss: 0.30287587950291855
Validation loss: 2.752954232804601

Epoch: 6| Step: 6
Training loss: 0.3395101510315491
Validation loss: 2.723372165978154

Epoch: 6| Step: 7
Training loss: 0.4656372030310431
Validation loss: 2.8372803548422163

Epoch: 6| Step: 8
Training loss: 0.32165450904943566
Validation loss: 2.8140790462625227

Epoch: 6| Step: 9
Training loss: 0.3816566534200304
Validation loss: 2.7359704585534748

Epoch: 6| Step: 10
Training loss: 0.37951658193073484
Validation loss: 2.834515708226199

Epoch: 6| Step: 11
Training loss: 0.3835619771505357
Validation loss: 2.826473168176977

Epoch: 6| Step: 12
Training loss: 0.4885700134913747
Validation loss: 2.7677385117265376

Epoch: 6| Step: 13
Training loss: 0.40804577947999393
Validation loss: 2.764054378643508

Epoch: 443| Step: 0
Training loss: 0.32142181900288735
Validation loss: 2.7464854583716396

Epoch: 6| Step: 1
Training loss: 0.36413965021709666
Validation loss: 2.8444760971079783

Epoch: 6| Step: 2
Training loss: 0.3195669988953042
Validation loss: 2.795190939935268

Epoch: 6| Step: 3
Training loss: 0.30531298185406147
Validation loss: 2.729290258118306

Epoch: 6| Step: 4
Training loss: 0.48723263867266453
Validation loss: 2.8547627924034447

Epoch: 6| Step: 5
Training loss: 0.3240343741605613
Validation loss: 2.7179111268098515

Epoch: 6| Step: 6
Training loss: 0.3578605253148401
Validation loss: 2.7850522115071965

Epoch: 6| Step: 7
Training loss: 0.34624444208263444
Validation loss: 2.8024660910268633

Epoch: 6| Step: 8
Training loss: 0.4563879718927381
Validation loss: 2.7628868686559342

Epoch: 6| Step: 9
Training loss: 0.32348343757921416
Validation loss: 2.7993258033557895

Epoch: 6| Step: 10
Training loss: 0.33036011156935446
Validation loss: 2.8424308288219025

Epoch: 6| Step: 11
Training loss: 0.26332967239311844
Validation loss: 2.820072533709495

Epoch: 6| Step: 12
Training loss: 0.37505554741491026
Validation loss: 2.8154790289351936

Epoch: 6| Step: 13
Training loss: 0.33237896831735897
Validation loss: 2.7666930814041253

Epoch: 444| Step: 0
Training loss: 0.3653141689343995
Validation loss: 2.755188786245617

Epoch: 6| Step: 1
Training loss: 0.4820183985649298
Validation loss: 2.8280118143324087

Epoch: 6| Step: 2
Training loss: 0.34363248290167236
Validation loss: 2.8071348020268614

Epoch: 6| Step: 3
Training loss: 0.6982321144924646
Validation loss: 2.749721057789821

Epoch: 6| Step: 4
Training loss: 0.33525958524494903
Validation loss: 2.7232831746722974

Epoch: 6| Step: 5
Training loss: 0.3523420697529519
Validation loss: 2.7266923642132865

Epoch: 6| Step: 6
Training loss: 0.3908325406915778
Validation loss: 2.8109961339077394

Epoch: 6| Step: 7
Training loss: 0.3051528800000879
Validation loss: 2.782602717013735

Epoch: 6| Step: 8
Training loss: 0.3115591190196776
Validation loss: 2.7339146689805163

Epoch: 6| Step: 9
Training loss: 0.3658396555383972
Validation loss: 2.7307951245056676

Epoch: 6| Step: 10
Training loss: 0.32372374836892354
Validation loss: 2.8316439519431054

Epoch: 6| Step: 11
Training loss: 0.44807407659090587
Validation loss: 2.694294494922232

Epoch: 6| Step: 12
Training loss: 0.27196472539929706
Validation loss: 2.8505794276334897

Epoch: 6| Step: 13
Training loss: 0.36111613060242165
Validation loss: 2.7175480754522083

Epoch: 445| Step: 0
Training loss: 0.43302553766059876
Validation loss: 2.755102639914275

Epoch: 6| Step: 1
Training loss: 0.29276969505193196
Validation loss: 2.71972808198641

Epoch: 6| Step: 2
Training loss: 0.33108864669143245
Validation loss: 2.8002715274308096

Epoch: 6| Step: 3
Training loss: 0.3559264286318846
Validation loss: 2.809543620541756

Epoch: 6| Step: 4
Training loss: 0.36317458689087057
Validation loss: 2.8402702504508817

Epoch: 6| Step: 5
Training loss: 0.33105591405230583
Validation loss: 2.7654743333139398

Epoch: 6| Step: 6
Training loss: 0.49577606722638135
Validation loss: 2.7645488879643465

Epoch: 6| Step: 7
Training loss: 0.46751154375358683
Validation loss: 2.814835207662644

Epoch: 6| Step: 8
Training loss: 0.346031054981514
Validation loss: 2.757486657334871

Epoch: 6| Step: 9
Training loss: 0.26552443844719953
Validation loss: 2.765853620946883

Epoch: 6| Step: 10
Training loss: 0.284505742274059
Validation loss: 2.7171238972768004

Epoch: 6| Step: 11
Training loss: 0.3527111996359418
Validation loss: 2.781632857813395

Epoch: 6| Step: 12
Training loss: 0.35790601366255614
Validation loss: 2.7371518667065966

Epoch: 6| Step: 13
Training loss: 0.3543503322459273
Validation loss: 2.8301899293131036

Epoch: 446| Step: 0
Training loss: 0.4759673482811518
Validation loss: 2.766396488552042

Epoch: 6| Step: 1
Training loss: 0.3383623920060427
Validation loss: 2.8244041709127883

Epoch: 6| Step: 2
Training loss: 0.4314737472040343
Validation loss: 2.728628641826668

Epoch: 6| Step: 3
Training loss: 0.47063929967952317
Validation loss: 2.8213750470277077

Epoch: 6| Step: 4
Training loss: 0.38541150948794306
Validation loss: 2.7166231978825626

Epoch: 6| Step: 5
Training loss: 0.4008589076305424
Validation loss: 2.761155275579664

Epoch: 6| Step: 6
Training loss: 0.5914594235823919
Validation loss: 2.743663799811648

Epoch: 6| Step: 7
Training loss: 0.3926812980547031
Validation loss: 2.724289202364856

Epoch: 6| Step: 8
Training loss: 0.37034227678036347
Validation loss: 2.6931210219468285

Epoch: 6| Step: 9
Training loss: 0.40098077964144485
Validation loss: 2.711701592343744

Epoch: 6| Step: 10
Training loss: 0.2449029921290285
Validation loss: 2.7844293117399515

Epoch: 6| Step: 11
Training loss: 0.2524798601918837
Validation loss: 2.6976924690166824

Epoch: 6| Step: 12
Training loss: 0.3522637155819072
Validation loss: 2.791920598186263

Epoch: 6| Step: 13
Training loss: 0.3981421254665212
Validation loss: 2.7463788408636822

Epoch: 447| Step: 0
Training loss: 0.39565065418248624
Validation loss: 2.758296689907053

Epoch: 6| Step: 1
Training loss: 0.44341617170016007
Validation loss: 2.7409793913158236

Epoch: 6| Step: 2
Training loss: 0.389897775824387
Validation loss: 2.8038100461274147

Epoch: 6| Step: 3
Training loss: 0.2785228728304993
Validation loss: 2.7496584188844984

Epoch: 6| Step: 4
Training loss: 0.4221480157263583
Validation loss: 2.68441869354511

Epoch: 6| Step: 5
Training loss: 0.39061256388895327
Validation loss: 2.685174475541322

Epoch: 6| Step: 6
Training loss: 0.33028071579902146
Validation loss: 2.7265855411113433

Epoch: 6| Step: 7
Training loss: 0.4445834466093301
Validation loss: 2.717443671205668

Epoch: 6| Step: 8
Training loss: 0.49871362673032227
Validation loss: 2.7762420228914806

Epoch: 6| Step: 9
Training loss: 0.4559361959416524
Validation loss: 2.714867476032603

Epoch: 6| Step: 10
Training loss: 0.30909010649101326
Validation loss: 2.7699712592973915

Epoch: 6| Step: 11
Training loss: 0.3866931637092865
Validation loss: 2.7857814263717064

Epoch: 6| Step: 12
Training loss: 0.3522407876110271
Validation loss: 2.7558012374271623

Epoch: 6| Step: 13
Training loss: 0.48682058441603615
Validation loss: 2.7839325530123538

Epoch: 448| Step: 0
Training loss: 0.4093869578820884
Validation loss: 2.7214119839648476

Epoch: 6| Step: 1
Training loss: 0.3461455192338726
Validation loss: 2.713105037849815

Epoch: 6| Step: 2
Training loss: 0.508436377300765
Validation loss: 2.7693027246023703

Epoch: 6| Step: 3
Training loss: 0.4076323100174169
Validation loss: 2.7663129680009706

Epoch: 6| Step: 4
Training loss: 0.45410691124832114
Validation loss: 2.763353280439117

Epoch: 6| Step: 5
Training loss: 0.4228888620748231
Validation loss: 2.793127280406714

Epoch: 6| Step: 6
Training loss: 0.4302712376798481
Validation loss: 2.7880344579857717

Epoch: 6| Step: 7
Training loss: 0.3236643751059523
Validation loss: 2.745358292196474

Epoch: 6| Step: 8
Training loss: 0.2741278109051939
Validation loss: 2.809962067104806

Epoch: 6| Step: 9
Training loss: 0.41012037211129204
Validation loss: 2.812307612585417

Epoch: 6| Step: 10
Training loss: 0.3281617598151449
Validation loss: 2.777156331695219

Epoch: 6| Step: 11
Training loss: 0.5156752244012793
Validation loss: 2.7571208039596407

Epoch: 6| Step: 12
Training loss: 0.3231010013426669
Validation loss: 2.827414449718018

Epoch: 6| Step: 13
Training loss: 0.35850107661821135
Validation loss: 2.828955252720847

Epoch: 449| Step: 0
Training loss: 0.43295411020815466
Validation loss: 2.764548787349373

Epoch: 6| Step: 1
Training loss: 0.24005538971810927
Validation loss: 2.775050422279099

Epoch: 6| Step: 2
Training loss: 0.5196894641410151
Validation loss: 2.781042198390473

Epoch: 6| Step: 3
Training loss: 0.38327352827826056
Validation loss: 2.758239669784609

Epoch: 6| Step: 4
Training loss: 0.3998552418078887
Validation loss: 2.7946970751709013

Epoch: 6| Step: 5
Training loss: 0.4454226775814997
Validation loss: 2.7374680527400757

Epoch: 6| Step: 6
Training loss: 0.3924702358501722
Validation loss: 2.762670889699622

Epoch: 6| Step: 7
Training loss: 0.3898252119652485
Validation loss: 2.745723563756021

Epoch: 6| Step: 8
Training loss: 0.36133604298756866
Validation loss: 2.750274593920065

Epoch: 6| Step: 9
Training loss: 0.22045486125279898
Validation loss: 2.75431020673325

Epoch: 6| Step: 10
Training loss: 0.29929217291802473
Validation loss: 2.7564734935615096

Epoch: 6| Step: 11
Training loss: 0.49961775831596233
Validation loss: 2.7268971235106565

Epoch: 6| Step: 12
Training loss: 0.3077248521131792
Validation loss: 2.8449571583477073

Epoch: 6| Step: 13
Training loss: 0.38903756885236856
Validation loss: 2.7376346160212113

Epoch: 450| Step: 0
Training loss: 0.3991126903137424
Validation loss: 2.784469783837981

Epoch: 6| Step: 1
Training loss: 0.3012977722879446
Validation loss: 2.784849059867466

Epoch: 6| Step: 2
Training loss: 0.3081880147539372
Validation loss: 2.7444052572022373

Epoch: 6| Step: 3
Training loss: 0.30314025742191136
Validation loss: 2.7322393814961683

Epoch: 6| Step: 4
Training loss: 0.2982960995134589
Validation loss: 2.7573172148839684

Epoch: 6| Step: 5
Training loss: 0.38111100320834596
Validation loss: 2.7932339771311603

Epoch: 6| Step: 6
Training loss: 0.26983505210708014
Validation loss: 2.8058899380131375

Epoch: 6| Step: 7
Training loss: 0.6101599796977327
Validation loss: 2.744867809959862

Epoch: 6| Step: 8
Training loss: 0.32657887997226753
Validation loss: 2.6895652051374315

Epoch: 6| Step: 9
Training loss: 0.21214301402830218
Validation loss: 2.746791239138771

Epoch: 6| Step: 10
Training loss: 0.31207807190555187
Validation loss: 2.7110227192173344

Epoch: 6| Step: 11
Training loss: 0.49601678927139675
Validation loss: 2.7505171246254716

Epoch: 6| Step: 12
Training loss: 0.3798923834450656
Validation loss: 2.7482572292928094

Epoch: 6| Step: 13
Training loss: 0.37022046180755025
Validation loss: 2.761793122106244

Testing loss: 2.601844402285451
