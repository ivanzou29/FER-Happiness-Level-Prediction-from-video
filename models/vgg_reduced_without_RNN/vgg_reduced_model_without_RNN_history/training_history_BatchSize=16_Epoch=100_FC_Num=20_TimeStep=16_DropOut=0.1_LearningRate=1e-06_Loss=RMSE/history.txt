Epoch: 1| Step: 0
Training loss: 6.494757665704739
Validation loss: 6.241240457466805
Epoch: 9| Step: 1
Training loss: 6.143548711077406
Validation loss: 6.227039749629994
Epoch: 9| Step: 2
Training loss: 6.4688372767361075
Validation loss: 6.202589000403345
Epoch: 9| Step: 3
Training loss: 6.962833373274444
Validation loss: 6.20655116653499
Epoch: 9| Step: 4
Training loss: 7.057609552822942
Validation loss: 6.21633519058218
Epoch: 9| Step: 5
Training loss: 6.616421021226427
Validation loss: 6.224937933287393
Epoch: 9| Step: 6
Training loss: 7.42305628962593
Validation loss: 6.21867000761544
Epoch: 9| Step: 7
Training loss: 5.740323092309488
Validation loss: 6.2159428178235325
Epoch: 9| Step: 8
Training loss: 7.804863455223768
Validation loss: 6.204288168577027
Epoch: 9| Step: 9
Training loss: 6.324383719956899
Validation loss: 6.182268988376873
Epoch: 9| Step: 10
Training loss: 6.904219246823143
Validation loss: 6.200024962850454
Epoch: 9| Step: 11
Training loss: 5.879587857600577
Validation loss: 6.206459549060265
Epoch: 9| Step: 12
Training loss: 6.011765388768894
Validation loss: 6.196925026688884
Epoch: 9| Step: 13
Training loss: 6.54846259558094
Validation loss: 6.197270281905543
Epoch: 9| Step: 14
Training loss: 6.236611636700753
Validation loss: 6.179936956059234
Epoch: 9| Step: 15
Training loss: 7.443872622769914
Validation loss: 6.170728745786817
Epoch: 9| Step: 16
Training loss: 7.121248294829448
Validation loss: 6.1792033084978835
Epoch: 9| Step: 17
Training loss: 6.496993910310019
Validation loss: 6.167577272602171
Epoch: 9| Step: 18
Training loss: 5.1917363529008504
Validation loss: 6.17042551859254
Epoch: 9| Step: 19
Training loss: 5.566673855957749
Validation loss: 6.166712693665781
Epoch: 2| Step: 0
Training loss: 6.745548051720216
Validation loss: 6.167711813421828
Epoch: 9| Step: 1
Training loss: 6.154621974018096
Validation loss: 6.167636877649893
Epoch: 9| Step: 2
Training loss: 6.949935627371621
Validation loss: 6.160606675799772
Epoch: 9| Step: 3
Training loss: 6.428862471274413
Validation loss: 6.157491033584757
Epoch: 9| Step: 4
Training loss: 6.742809845987104
Validation loss: 6.167571946682844
Epoch: 9| Step: 5
Training loss: 6.227928557410637
Validation loss: 6.162643547768948
Epoch: 9| Step: 6
Training loss: 6.356189576708564
Validation loss: 6.139664110412584
Epoch: 9| Step: 7
Training loss: 7.196319741525221
Validation loss: 6.152090574650741
Epoch: 9| Step: 8
Training loss: 6.736864660877816
Validation loss: 6.145968565150739
Epoch: 9| Step: 9
Training loss: 6.9003013434466105
Validation loss: 6.154615756676554
Epoch: 9| Step: 10
Training loss: 6.2545006378415025
Validation loss: 6.1531949539514335
Epoch: 9| Step: 11
Training loss: 5.797433008857239
Validation loss: 6.125191502644184
Epoch: 9| Step: 12
Training loss: 6.512185339181134
Validation loss: 6.13320112036
Epoch: 9| Step: 13
Training loss: 5.959887890881421
Validation loss: 6.137440038796097
Epoch: 9| Step: 14
Training loss: 6.375439796985026
Validation loss: 6.127588180810795
Epoch: 9| Step: 15
Training loss: 5.766672923060792
Validation loss: 6.125789279060805
Epoch: 9| Step: 16
Training loss: 6.821567485481938
Validation loss: 6.098542804606979
Epoch: 9| Step: 17
Training loss: 5.486291968775485
Validation loss: 6.108784217665372
Epoch: 9| Step: 18
Training loss: 6.870113231275513
Validation loss: 6.091534918086285
Epoch: 9| Step: 19
Training loss: 7.2090423176518605
Validation loss: 6.094559140086649
Epoch: 3| Step: 0
Training loss: 5.958715182075222
Validation loss: 6.091469278241965
Epoch: 9| Step: 1
Training loss: 6.137521206883232
Validation loss: 6.091503040505977
Epoch: 9| Step: 2
Training loss: 5.829547780002831
Validation loss: 6.076442586809857
Epoch: 9| Step: 3
Training loss: 6.719815617711185
Validation loss: 6.06748032822572
Epoch: 9| Step: 4
Training loss: 6.636241659941312
Validation loss: 6.0800422746211495
Epoch: 9| Step: 5
Training loss: 6.6897316889992515
Validation loss: 6.064361636357172
Epoch: 9| Step: 6
Training loss: 5.9288060836182215
Validation loss: 6.075916732843362
Epoch: 9| Step: 7
Training loss: 6.839550105686292
Validation loss: 6.072765152191284
Epoch: 9| Step: 8
Training loss: 7.098137796680483
Validation loss: 6.067969308871998
Epoch: 9| Step: 9
Training loss: 7.40735988107199
Validation loss: 6.065483820004149
Epoch: 9| Step: 10
Training loss: 6.598294540616277
Validation loss: 6.068292235055821
Epoch: 9| Step: 11
Training loss: 6.585073828489712
Validation loss: 6.039939923768095
Epoch: 9| Step: 12
Training loss: 6.078487748253184
Validation loss: 6.051495015436319
Epoch: 9| Step: 13
Training loss: 6.641611829249711
Validation loss: 6.053421344889353
Epoch: 9| Step: 14
Training loss: 5.841524567374534
Validation loss: 6.03739715722133
Epoch: 9| Step: 15
Training loss: 6.153930846878608
Validation loss: 6.042910707960179
Epoch: 9| Step: 16
Training loss: 5.940249157955729
Validation loss: 6.042243032568773
Epoch: 9| Step: 17
Training loss: 6.055054172364888
Validation loss: 6.010945773921722
Epoch: 9| Step: 18
Training loss: 6.044791875621532
Validation loss: 6.030330658842053
Epoch: 9| Step: 19
Training loss: 6.847512521666171
Validation loss: 6.020478302905878
Epoch: 4| Step: 0
Training loss: 6.257335782793889
Validation loss: 6.004681172674042
Epoch: 9| Step: 1
Training loss: 7.1004985688004405
Validation loss: 6.016584245086186
Epoch: 9| Step: 2
Training loss: 5.696680728782647
Validation loss: 6.004276384469585
Epoch: 9| Step: 3
Training loss: 5.532167347846158
Validation loss: 5.999530787440349
Epoch: 9| Step: 4
Training loss: 6.12634760765055
Validation loss: 5.9880991829851045
Epoch: 9| Step: 5
Training loss: 7.023903497124235
Validation loss: 5.99100114460047
Epoch: 9| Step: 6
Training loss: 6.993883185188086
Validation loss: 5.996739638793524
Epoch: 9| Step: 7
Training loss: 5.354306863614196
Validation loss: 5.97332904551417
Epoch: 9| Step: 8
Training loss: 6.096133035144306
Validation loss: 5.986517570657503
Epoch: 9| Step: 9
Training loss: 5.94657702037713
Validation loss: 5.976785394932146
Epoch: 9| Step: 10
Training loss: 5.819050369131232
Validation loss: 5.965714457092416
Epoch: 9| Step: 11
Training loss: 6.205781382283561
Validation loss: 5.95619240835932
Epoch: 9| Step: 12
Training loss: 6.969974427361008
Validation loss: 5.966184929189017
Epoch: 9| Step: 13
Training loss: 6.6561196184597025
Validation loss: 5.957197603321204
Epoch: 9| Step: 14
Training loss: 6.667190372242028
Validation loss: 5.952790379274817
Epoch: 9| Step: 15
Training loss: 5.183394312525442
Validation loss: 5.948052057773654
Epoch: 9| Step: 16
Training loss: 6.2198834943746135
Validation loss: 5.939369329411102
Epoch: 9| Step: 17
Training loss: 7.114168734964808
Validation loss: 5.926140330333439
Epoch: 9| Step: 18
Training loss: 6.831827447467672
Validation loss: 5.926740045382847
Epoch: 9| Step: 19
Training loss: 6.2111794862450695
Validation loss: 5.911115914455655
Epoch: 5| Step: 0
Training loss: 6.621605921377936
Validation loss: 5.917845033191831
Epoch: 9| Step: 1
Training loss: 5.603610591409457
Validation loss: 5.8927473927227965
Epoch: 9| Step: 2
Training loss: 6.602714627643812
Validation loss: 5.902355230646946
Epoch: 9| Step: 3
Training loss: 5.747811605892798
Validation loss: 5.875919155773606
Epoch: 9| Step: 4
Training loss: 6.002869873344632
Validation loss: 5.8885570876078
Epoch: 9| Step: 5
Training loss: 5.822068736712064
Validation loss: 5.860668833222959
Epoch: 9| Step: 6
Training loss: 7.310508261152363
Validation loss: 5.859342623788215
Epoch: 9| Step: 7
Training loss: 6.62075007174045
Validation loss: 5.8716849096780335
Epoch: 9| Step: 8
Training loss: 5.0685106552567465
Validation loss: 5.860534395103488
Epoch: 9| Step: 9
Training loss: 5.936937164935353
Validation loss: 5.819952634798271
Epoch: 9| Step: 10
Training loss: 6.655111152758187
Validation loss: 5.858872727371786
Epoch: 9| Step: 11
Training loss: 6.540488685758516
Validation loss: 5.843068117650694
Epoch: 9| Step: 12
Training loss: 5.506146551019923
Validation loss: 5.837196010140391
Epoch: 9| Step: 13
Training loss: 5.533675357098903
Validation loss: 5.815166960955947
Epoch: 9| Step: 14
Training loss: 5.573740713450123
Validation loss: 5.810009978872496
Epoch: 9| Step: 15
Training loss: 6.589708870692869
Validation loss: 5.810406530606728
Epoch: 9| Step: 16
Training loss: 7.375618342970446
Validation loss: 5.808829764307477
Epoch: 9| Step: 17
Training loss: 6.220905792911298
Validation loss: 5.797227989011792
Epoch: 9| Step: 18
Training loss: 6.5616890542473065
Validation loss: 5.783088132671922
Epoch: 9| Step: 19
Training loss: 5.832760846338222
Validation loss: 5.7958410617760965
Epoch: 6| Step: 0
Training loss: 5.523133610805781
Validation loss: 5.7791457457820785
Epoch: 9| Step: 1
Training loss: 6.5086204879004566
Validation loss: 5.772112282072545
Epoch: 9| Step: 2
Training loss: 6.481175380119051
Validation loss: 5.765644239453391
Epoch: 9| Step: 3
Training loss: 6.1621941852325355
Validation loss: 5.7695265533171005
Epoch: 9| Step: 4
Training loss: 6.750061600015507
Validation loss: 5.747169994702272
Epoch: 9| Step: 5
Training loss: 6.716699757585188
Validation loss: 5.736510662252678
Epoch: 9| Step: 6
Training loss: 6.017224067095459
Validation loss: 5.739941419078772
Epoch: 9| Step: 7
Training loss: 6.540393033131268
Validation loss: 5.735973691113674
Epoch: 9| Step: 8
Training loss: 5.574286499894866
Validation loss: 5.719467809213716
Epoch: 9| Step: 9
Training loss: 6.423742018273615
Validation loss: 5.710670342342331
Epoch: 9| Step: 10
Training loss: 6.3152737708109665
Validation loss: 5.703907943449448
Epoch: 9| Step: 11
Training loss: 6.357532881135323
Validation loss: 5.678291823701883
Epoch: 9| Step: 12
Training loss: 5.638869754819347
Validation loss: 5.67216011332638
Epoch: 9| Step: 13
Training loss: 6.637989768944166
Validation loss: 5.6856030983437345
Epoch: 9| Step: 14
Training loss: 6.138278192415237
Validation loss: 5.651408993168571
Epoch: 9| Step: 15
Training loss: 4.777220779795115
Validation loss: 5.647086040209
Epoch: 9| Step: 16
Training loss: 6.074881897080515
Validation loss: 5.636285378022734
Epoch: 9| Step: 17
Training loss: 6.028358833836303
Validation loss: 5.640004222864
Epoch: 9| Step: 18
Training loss: 5.965059907265444
Validation loss: 5.623623370081513
Epoch: 9| Step: 19
Training loss: 4.338753880153142
Validation loss: 5.6173835895696
Epoch: 7| Step: 0
Training loss: 6.064552510256482
Validation loss: 5.57483372439085
Epoch: 9| Step: 1
Training loss: 6.001262214138105
Validation loss: 5.615377032411971
Epoch: 9| Step: 2
Training loss: 6.768807664733017
Validation loss: 5.603954533251991
Epoch: 9| Step: 3
Training loss: 5.245720163366383
Validation loss: 5.566131493775161
Epoch: 9| Step: 4
Training loss: 5.709006759385641
Validation loss: 5.578786894456524
Epoch: 9| Step: 5
Training loss: 5.4016654801752395
Validation loss: 5.562972902148219
Epoch: 9| Step: 6
Training loss: 5.503086611144319
Validation loss: 5.568199135431043
Epoch: 9| Step: 7
Training loss: 6.1279790990288765
Validation loss: 5.5398785623190445
Epoch: 9| Step: 8
Training loss: 7.004484647408491
Validation loss: 5.526074750113231
Epoch: 9| Step: 9
Training loss: 6.119113818565606
Validation loss: 5.541230685332921
Epoch: 9| Step: 10
Training loss: 5.600966928655147
Validation loss: 5.532354308686088
Epoch: 9| Step: 11
Training loss: 5.959281721420284
Validation loss: 5.520401501594242
Epoch: 9| Step: 12
Training loss: 6.50550227930218
Validation loss: 5.5038828642893485
Epoch: 9| Step: 13
Training loss: 5.998097117992108
Validation loss: 5.489703158965501
Epoch: 9| Step: 14
Training loss: 6.104890782584497
Validation loss: 5.483914883744365
Epoch: 9| Step: 15
Training loss: 5.306832555417613
Validation loss: 5.449066850457455
Epoch: 9| Step: 16
Training loss: 5.215249172267132
Validation loss: 5.449342083935527
Epoch: 9| Step: 17
Training loss: 5.832647701115015
Validation loss: 5.425778807518172
Epoch: 9| Step: 18
Training loss: 6.620211616199419
Validation loss: 5.44066351142383
Epoch: 9| Step: 19
Training loss: 4.410157114979986
Validation loss: 5.42220476754424
Epoch: 8| Step: 0
Training loss: 6.626644290346453
Validation loss: 5.388885760185838
Epoch: 9| Step: 1
Training loss: 6.528199866245851
Validation loss: 5.37322314689578
Epoch: 9| Step: 2
Training loss: 5.055415341362334
Validation loss: 5.404228229577942
Epoch: 9| Step: 3
Training loss: 5.685348942363657
Validation loss: 5.374546659761854
Epoch: 9| Step: 4
Training loss: 6.0717724550455285
Validation loss: 5.342812462434225
Epoch: 9| Step: 5
Training loss: 5.686347928582332
Validation loss: 5.34377982016856
Epoch: 9| Step: 6
Training loss: 5.424008172425721
Validation loss: 5.330936109334392
Epoch: 9| Step: 7
Training loss: 5.493672632707679
Validation loss: 5.325190206362521
Epoch: 9| Step: 8
Training loss: 6.269178643219198
Validation loss: 5.303370026776618
Epoch: 9| Step: 9
Training loss: 5.040986112370021
Validation loss: 5.3071166539064984
Epoch: 9| Step: 10
Training loss: 5.558675758684396
Validation loss: 5.28541422054038
Epoch: 9| Step: 11
Training loss: 5.238830310057592
Validation loss: 5.252341888871697
Epoch: 9| Step: 12
Training loss: 5.0909247491026015
Validation loss: 5.232120745475917
Epoch: 9| Step: 13
Training loss: 6.004922754710427
Validation loss: 5.2477298231292036
Epoch: 9| Step: 14
Training loss: 6.158439750250928
Validation loss: 5.225994832667232
Epoch: 9| Step: 15
Training loss: 5.226435684011279
Validation loss: 5.2091203758092615
Epoch: 9| Step: 16
Training loss: 6.834260955124144
Validation loss: 5.190623158430033
Epoch: 9| Step: 17
Training loss: 5.187226069927656
Validation loss: 5.171469378464732
Epoch: 9| Step: 18
Training loss: 5.013346597234617
Validation loss: 5.171827986026217
Epoch: 9| Step: 19
Training loss: 5.033586611069942
Validation loss: 5.1581292696862935
Epoch: 9| Step: 0
Training loss: 5.652694005863556
Validation loss: 5.141245130957836
Epoch: 9| Step: 1
Training loss: 5.825476159538511
Validation loss: 5.119595814467651
Epoch: 9| Step: 2
Training loss: 6.407073475084918
Validation loss: 5.101624120973316
Epoch: 9| Step: 3
Training loss: 5.347107128319353
Validation loss: 5.097014650710355
Epoch: 9| Step: 4
Training loss: 6.159606947806397
Validation loss: 5.082268155337108
Epoch: 9| Step: 5
Training loss: 6.092737984374532
Validation loss: 5.051112078491225
Epoch: 9| Step: 6
Training loss: 5.112430323939748
Validation loss: 5.0438710331033665
Epoch: 9| Step: 7
Training loss: 4.976490637052274
Validation loss: 5.032075248069729
Epoch: 9| Step: 8
Training loss: 4.857401848948466
Validation loss: 5.017743505394289
Epoch: 9| Step: 9
Training loss: 5.197291497786503
Validation loss: 5.0003917165448675
Epoch: 9| Step: 10
Training loss: 5.320740893981652
Validation loss: 4.9778261671117905
Epoch: 9| Step: 11
Training loss: 5.607006539934405
Validation loss: 4.9437030821424806
Epoch: 9| Step: 12
Training loss: 4.9039130020763615
Validation loss: 4.946498945396204
Epoch: 9| Step: 13
Training loss: 5.253988295130766
Validation loss: 4.931765092097004
Epoch: 9| Step: 14
Training loss: 5.559506414445947
Validation loss: 4.895942575042084
Epoch: 9| Step: 15
Training loss: 6.179045478659608
Validation loss: 4.901793864642204
Epoch: 9| Step: 16
Training loss: 4.704771647085616
Validation loss: 4.875397180586315
Epoch: 9| Step: 17
Training loss: 5.31816570869383
Validation loss: 4.865457592223013
Epoch: 9| Step: 18
Training loss: 4.213262309027052
Validation loss: 4.8234244819163665
Epoch: 9| Step: 19
Training loss: 4.913259370851866
Validation loss: 4.792869416141883
Epoch: 10| Step: 0
Training loss: 3.828052255367502
Validation loss: 4.8058204095212265
Epoch: 9| Step: 1
Training loss: 3.998940804434725
Validation loss: 4.780209090637057
Epoch: 9| Step: 2
Training loss: 5.858315008287633
Validation loss: 4.754991995264453
Epoch: 9| Step: 3
Training loss: 4.920944464987411
Validation loss: 4.735567414528031
Epoch: 9| Step: 4
Training loss: 5.298929091889608
Validation loss: 4.716748607477033
Epoch: 9| Step: 5
Training loss: 5.183333596641477
Validation loss: 4.697520101281095
Epoch: 9| Step: 6
Training loss: 5.733225028915029
Validation loss: 4.678082722983697
Epoch: 9| Step: 7
Training loss: 4.348631387021157
Validation loss: 4.66920460040625
Epoch: 9| Step: 8
Training loss: 4.911554081436246
Validation loss: 4.646610998686575
Epoch: 9| Step: 9
Training loss: 4.892151420701458
Validation loss: 4.623240424873339
Epoch: 9| Step: 10
Training loss: 4.809441920081955
Validation loss: 4.607075914854074
Epoch: 9| Step: 11
Training loss: 4.875572562217513
Validation loss: 4.58580643149792
Epoch: 9| Step: 12
Training loss: 6.256302974145104
Validation loss: 4.570166664331874
Epoch: 9| Step: 13
Training loss: 5.279428021054192
Validation loss: 4.524854498959001
Epoch: 9| Step: 14
Training loss: 4.253432290372012
Validation loss: 4.517242581260422
Epoch: 9| Step: 15
Training loss: 4.992265058938795
Validation loss: 4.471426352801757
Epoch: 9| Step: 16
Training loss: 5.192489614315602
Validation loss: 4.463848431358757
Epoch: 9| Step: 17
Training loss: 4.928001248409063
Validation loss: 4.4566456741195015
Epoch: 9| Step: 18
Training loss: 5.258668917644501
Validation loss: 4.403067152827342
Epoch: 9| Step: 19
Training loss: 5.500501263057528
Validation loss: 4.390905091688165
Epoch: 11| Step: 0
Training loss: 4.224052205514523
Validation loss: 4.3766601088268455
Epoch: 9| Step: 1
Training loss: 5.203331745610961
Validation loss: 4.345539045609136
Epoch: 9| Step: 2
Training loss: 4.797983047792509
Validation loss: 4.289917860901662
Epoch: 9| Step: 3
Training loss: 4.140690641062835
Validation loss: 4.283419254411387
Epoch: 9| Step: 4
Training loss: 4.023470684025776
Validation loss: 4.255596595543026
Epoch: 9| Step: 5
Training loss: 4.746680454991348
Validation loss: 4.231477979353783
Epoch: 9| Step: 6
Training loss: 4.0780447882587
Validation loss: 4.2286670630563545
Epoch: 9| Step: 7
Training loss: 5.371348360442517
Validation loss: 4.162435090767309
Epoch: 9| Step: 8
Training loss: 5.283056909367643
Validation loss: 4.168686481348984
Epoch: 9| Step: 9
Training loss: 4.751413636916099
Validation loss: 4.136338014124849
Epoch: 9| Step: 10
Training loss: 4.921073727249809
Validation loss: 4.09693031761807
Epoch: 9| Step: 11
Training loss: 4.185347729892606
Validation loss: 4.094236828551159
Epoch: 9| Step: 12
Training loss: 4.7221871293702495
Validation loss: 4.05222581587092
Epoch: 9| Step: 13
Training loss: 5.039201601459438
Validation loss: 4.033147992734838
Epoch: 9| Step: 14
Training loss: 4.523465540243942
Validation loss: 3.9936821894619174
Epoch: 9| Step: 15
Training loss: 4.5801197692669655
Validation loss: 3.9638990938508756
Epoch: 9| Step: 16
Training loss: 5.401882811194981
Validation loss: 3.930213756451255
Epoch: 9| Step: 17
Training loss: 4.271735317845948
Validation loss: 3.9128992130380427
Epoch: 9| Step: 18
Training loss: 3.7389202468663005
Validation loss: 3.8884341494956
Epoch: 9| Step: 19
Training loss: 3.3159396468998534
Validation loss: 3.814904050307476
Epoch: 12| Step: 0
Training loss: 3.5942095918758037
Validation loss: 3.814726665302864
Epoch: 9| Step: 1
Training loss: 4.760846252869024
Validation loss: 3.804515910098738
Epoch: 9| Step: 2
Training loss: 3.8775349600794295
Validation loss: 3.7657312890835124
Epoch: 9| Step: 3
Training loss: 3.8596633618075415
Validation loss: 3.7193450030207837
Epoch: 9| Step: 4
Training loss: 4.435570095712006
Validation loss: 3.683484546468606
Epoch: 9| Step: 5
Training loss: 3.796036992784177
Validation loss: 3.668465695941739
Epoch: 9| Step: 6
Training loss: 3.384750832835176
Validation loss: 3.6191969737932688
Epoch: 9| Step: 7
Training loss: 4.430100625232187
Validation loss: 3.61908076068472
Epoch: 9| Step: 8
Training loss: 4.301896923296963
Validation loss: 3.55981772182678
Epoch: 9| Step: 9
Training loss: 4.076898500011318
Validation loss: 3.554580310169768
Epoch: 9| Step: 10
Training loss: 3.776021700400697
Validation loss: 3.5137471179171045
Epoch: 9| Step: 11
Training loss: 4.450451928668005
Validation loss: 3.4776862299251152
Epoch: 9| Step: 12
Training loss: 3.9966890221724296
Validation loss: 3.4588307616978464
Epoch: 9| Step: 13
Training loss: 4.045096341601989
Validation loss: 3.4059754317318682
Epoch: 9| Step: 14
Training loss: 3.7755944699721886
Validation loss: 3.364086751476705
Epoch: 9| Step: 15
Training loss: 4.362305889893779
Validation loss: 3.3814896183285357
Epoch: 9| Step: 16
Training loss: 4.259811967810156
Validation loss: 3.332465211316104
Epoch: 9| Step: 17
Training loss: 4.205544608429592
Validation loss: 3.2941922765036353
Epoch: 9| Step: 18
Training loss: 3.7024754465591054
Validation loss: 3.274726997885061
Epoch: 9| Step: 19
Training loss: 3.58752206935142
Validation loss: 3.2367610183537323
Epoch: 13| Step: 0
Training loss: 3.004896300902047
Validation loss: 3.2247914118402625
Epoch: 9| Step: 1
Training loss: 3.4555982475328424
Validation loss: 3.1367604739696495
Epoch: 9| Step: 2
Training loss: 3.1395659677640766
Validation loss: 3.1456357241150643
Epoch: 9| Step: 3
Training loss: 2.2856152717397906
Validation loss: 3.085396400447721
Epoch: 9| Step: 4
Training loss: 3.3618427527675854
Validation loss: 3.096006911190121
Epoch: 9| Step: 5
Training loss: 3.9301133882506285
Validation loss: 3.0632930196573716
Epoch: 9| Step: 6
Training loss: 3.9229340966003408
Validation loss: 3.020870382023836
Epoch: 9| Step: 7
Training loss: 3.893166443522575
Validation loss: 2.9704443638420748
Epoch: 9| Step: 8
Training loss: 3.843589469224643
Validation loss: 2.9720960004645396
Epoch: 9| Step: 9
Training loss: 3.944532018832553
Validation loss: 2.9274421491947686
Epoch: 9| Step: 10
Training loss: 3.108581441704868
Validation loss: 2.8958557157751694
Epoch: 9| Step: 11
Training loss: 3.8661459396768616
Validation loss: 2.8785433621768104
Epoch: 9| Step: 12
Training loss: 2.7966200216841783
Validation loss: 2.796802387239332
Epoch: 9| Step: 13
Training loss: 4.1545530598018585
Validation loss: 2.8071327524119525
Epoch: 9| Step: 14
Training loss: 3.585684973108959
Validation loss: 2.8031614370485722
Epoch: 9| Step: 15
Training loss: 3.0256974795461513
Validation loss: 2.772260821699235
Epoch: 9| Step: 16
Training loss: 3.4983748341340637
Validation loss: 2.7088945707301533
Epoch: 9| Step: 17
Training loss: 3.408186056099808
Validation loss: 2.691679051150152
Epoch: 9| Step: 18
Training loss: 3.2013976859419837
Validation loss: 2.675465646781065
Epoch: 9| Step: 19
Training loss: 3.462382202348077
Validation loss: 2.6476188687618833
Epoch: 14| Step: 0
Training loss: 3.1547651669604493
Validation loss: 2.5910998567553225
Epoch: 9| Step: 1
Training loss: 3.123450848931111
Validation loss: 2.6003687917340295
Epoch: 9| Step: 2
Training loss: 3.033534339560776
Validation loss: 2.523865556015972
Epoch: 9| Step: 3
Training loss: 2.9783949130252303
Validation loss: 2.544619858448042
Epoch: 9| Step: 4
Training loss: 3.1560220163928743
Validation loss: 2.524384991951076
Epoch: 9| Step: 5
Training loss: 3.120709029108666
Validation loss: 2.492146584546707
Epoch: 9| Step: 6
Training loss: 4.200069862874586
Validation loss: 2.4363274790962017
Epoch: 9| Step: 7
Training loss: 2.697537418844846
Validation loss: 2.443883286382049
Epoch: 9| Step: 8
Training loss: 2.1876368888530617
Validation loss: 2.4052542363961296
Epoch: 9| Step: 9
Training loss: 3.1585977717054843
Validation loss: 2.4086112039844205
Epoch: 9| Step: 10
Training loss: 2.166767839368228
Validation loss: 2.4137068266886077
Epoch: 9| Step: 11
Training loss: 2.4826028129132074
Validation loss: 2.379733211584373
Epoch: 9| Step: 12
Training loss: 2.630313400335476
Validation loss: 2.3352840810252458
Epoch: 9| Step: 13
Training loss: 3.1636926505483727
Validation loss: 2.364266666334022
Epoch: 9| Step: 14
Training loss: 2.841527384666144
Validation loss: 2.340022325699557
Epoch: 9| Step: 15
Training loss: 3.321463208230362
Validation loss: 2.326550881408089
Epoch: 9| Step: 16
Training loss: 3.088181078458977
Validation loss: 2.3043908634293433
Epoch: 9| Step: 17
Training loss: 2.6762776826213437
Validation loss: 2.308519662829873
Epoch: 9| Step: 18
Training loss: 3.6560199371729167
Validation loss: 2.286733790256995
Epoch: 9| Step: 19
Training loss: 2.5313289300362714
Validation loss: 2.2877489122141297
Epoch: 15| Step: 0
Training loss: 3.0728550446791907
Validation loss: 2.2427550767569198
Epoch: 9| Step: 1
Training loss: 2.712065184589081
Validation loss: 2.255585846526706
Epoch: 9| Step: 2
Training loss: 3.3071277167265873
Validation loss: 2.226797521588756
Epoch: 9| Step: 3
Training loss: 2.944323791175195
Validation loss: 2.2495958882061715
Epoch: 9| Step: 4
Training loss: 3.265113754043381
Validation loss: 2.2447684381613997
Epoch: 9| Step: 5
Training loss: 2.9495943146115153
Validation loss: 2.251069305744594
Epoch: 9| Step: 6
Training loss: 2.6459811812616083
Validation loss: 2.224161127976593
Epoch: 9| Step: 7
Training loss: 2.505898764487282
Validation loss: 2.23996845440766
Epoch: 9| Step: 8
Training loss: 2.726275759596689
Validation loss: 2.225333323438512
Epoch: 9| Step: 9
Training loss: 2.1593746820165287
Validation loss: 2.2363194462065796
Epoch: 9| Step: 10
Training loss: 1.9752332718622083
Validation loss: 2.228852539187641
Epoch: 9| Step: 11
Training loss: 3.499187920228666
Validation loss: 2.194721590484612
Epoch: 9| Step: 12
Training loss: 2.074499423762729
Validation loss: 2.1512517427670783
Epoch: 9| Step: 13
Training loss: 2.9869054482012216
Validation loss: 2.2104343272944442
Epoch: 9| Step: 14
Training loss: 2.967014166664114
Validation loss: 2.1636748249358373
Epoch: 9| Step: 15
Training loss: 3.2699562079154165
Validation loss: 2.2144732458859493
Epoch: 9| Step: 16
Training loss: 2.6153368427694854
Validation loss: 2.157950187920611
Epoch: 9| Step: 17
Training loss: 2.0303305085322814
Validation loss: 2.1782548571974067
Epoch: 9| Step: 18
Training loss: 2.6823944565913407
Validation loss: 2.1919582701587896
Epoch: 9| Step: 19
Training loss: 2.4504084032612683
Validation loss: 2.1783633768607555
Epoch: 16| Step: 0
Training loss: 2.479112918388669
Validation loss: 2.1737170149263614
Epoch: 9| Step: 1
Training loss: 2.8139948792834617
Validation loss: 2.1602798057151484
Epoch: 9| Step: 2
Training loss: 2.7337269042216406
Validation loss: 2.190063115821331
Epoch: 9| Step: 3
Training loss: 2.793823538202792
Validation loss: 2.215845746062034
Epoch: 9| Step: 4
Training loss: 2.757713251246154
Validation loss: 2.201800431289632
Epoch: 9| Step: 5
Training loss: 2.3747336589645767
Validation loss: 2.2000978200446033
Epoch: 9| Step: 6
Training loss: 2.7826867839297464
Validation loss: 2.2101889699656567
Epoch: 9| Step: 7
Training loss: 2.598562899813493
Validation loss: 2.186671101201718
Epoch: 9| Step: 8
Training loss: 3.2375113350806033
Validation loss: 2.2119507187956335
Epoch: 9| Step: 9
Training loss: 2.8119738616488226
Validation loss: 2.1980077981668797
Epoch: 9| Step: 10
Training loss: 2.029327421720285
Validation loss: 2.1976848772309863
Epoch: 9| Step: 11
Training loss: 2.720764378544814
Validation loss: 2.1852673298430862
Epoch: 9| Step: 12
Training loss: 2.643683112991514
Validation loss: 2.206688567488762
Epoch: 9| Step: 13
Training loss: 2.3191733084430597
Validation loss: 2.2050881793850112
Epoch: 9| Step: 14
Training loss: 2.689645664744686
Validation loss: 2.1994182849176585
Epoch: 9| Step: 15
Training loss: 3.099595375726499
Validation loss: 2.186713866467229
Epoch: 9| Step: 16
Training loss: 3.213083705492052
Validation loss: 2.223749500739215
Epoch: 9| Step: 17
Training loss: 2.349790596255854
Validation loss: 2.2363885991941745
Epoch: 9| Step: 18
Training loss: 2.5252276705087073
Validation loss: 2.2084322680348416
Epoch: 9| Step: 19
Training loss: 2.6558237070324706
Validation loss: 2.217607934228143
Epoch: 17| Step: 0
Training loss: 2.5210234725325464
Validation loss: 2.1688478704854557
Epoch: 9| Step: 1
Training loss: 3.4337273442618366
Validation loss: 2.219281937733779
Epoch: 9| Step: 2
Training loss: 2.500123974587193
Validation loss: 2.175191315396134
Epoch: 9| Step: 3
Training loss: 3.4463871601138285
Validation loss: 2.204986530618925
Epoch: 9| Step: 4
Training loss: 2.071173722699187
Validation loss: 2.1948092156581027
Epoch: 9| Step: 5
Training loss: 2.3882055069053187
Validation loss: 2.1609188285952623
Epoch: 9| Step: 6
Training loss: 3.231983719831953
Validation loss: 2.230272866826371
Epoch: 9| Step: 7
Training loss: 2.6237952783029908
Validation loss: 2.216124814739866
Epoch: 9| Step: 8
Training loss: 2.302243556550166
Validation loss: 2.2092569448153756
Epoch: 9| Step: 9
Training loss: 3.1193223875206613
Validation loss: 2.206485286487014
Epoch: 9| Step: 10
Training loss: 2.413072302736166
Validation loss: 2.217531120288945
Epoch: 9| Step: 11
Training loss: 2.4273324819449997
Validation loss: 2.240638854501487
Epoch: 9| Step: 12
Training loss: 2.76779408712681
Validation loss: 2.227712556465789
Epoch: 9| Step: 13
Training loss: 1.9058950124928233
Validation loss: 2.176174646500782
Epoch: 9| Step: 14
Training loss: 1.9990253457794995
Validation loss: 2.215818026971701
Epoch: 9| Step: 15
Training loss: 2.3754033197968005
Validation loss: 2.2303788564231013
Epoch: 9| Step: 16
Training loss: 2.6324335838699384
Validation loss: 2.2407981399319064
Epoch: 9| Step: 17
Training loss: 2.9294065620507737
Validation loss: 2.2110659912263726
Epoch: 9| Step: 18
Training loss: 3.159653141444985
Validation loss: 2.2210592671589753
Epoch: 9| Step: 19
Training loss: 3.038332343953178
Validation loss: 2.1923907251784995
Epoch: 18| Step: 0
Training loss: 2.6756848394469754
Validation loss: 2.2270599986854647
Epoch: 9| Step: 1
Training loss: 2.610484909379322
Validation loss: 2.2045157908475055
Epoch: 9| Step: 2
Training loss: 1.8099102065432726
Validation loss: 2.196401094362684
Epoch: 9| Step: 3
Training loss: 2.7418139602687503
Validation loss: 2.219056147019265
Epoch: 9| Step: 4
Training loss: 2.9102057331153786
Validation loss: 2.225559383297785
Epoch: 9| Step: 5
Training loss: 3.044351638143577
Validation loss: 2.20010144456737
Epoch: 9| Step: 6
Training loss: 2.6228072681190744
Validation loss: 2.217644194752977
Epoch: 9| Step: 7
Training loss: 2.8348063585462238
Validation loss: 2.246784607701663
Epoch: 9| Step: 8
Training loss: 2.0879261381378154
Validation loss: 2.198505624947669
Epoch: 9| Step: 9
Training loss: 3.0363586479212485
Validation loss: 2.213054946193268
Epoch: 9| Step: 10
Training loss: 2.5992627675875792
Validation loss: 2.1909494858464753
Epoch: 9| Step: 11
Training loss: 2.603888128007559
Validation loss: 2.2241591138298515
Epoch: 9| Step: 12
Training loss: 2.7642386027250634
Validation loss: 2.2050137938388903
Epoch: 9| Step: 13
Training loss: 2.8307957973318043
Validation loss: 2.202411207432186
Epoch: 9| Step: 14
Training loss: 2.665354843134275
Validation loss: 2.1640988605996885
Epoch: 9| Step: 15
Training loss: 2.3835458096134587
Validation loss: 2.2277155304629663
Epoch: 9| Step: 16
Training loss: 3.5614305195926863
Validation loss: 2.2314022073212234
Epoch: 9| Step: 17
Training loss: 2.046966783635158
Validation loss: 2.206046464040435
Epoch: 9| Step: 18
Training loss: 2.962225238919024
Validation loss: 2.2025328189092646
Epoch: 9| Step: 19
Training loss: 2.1522890281297977
Validation loss: 2.1865230150605734
Epoch: 19| Step: 0
Training loss: 2.8974787110804714
Validation loss: 2.213316969183625
Epoch: 9| Step: 1
Training loss: 2.4097605276834564
Validation loss: 2.2040417523935933
Epoch: 9| Step: 2
Training loss: 2.396051568305857
Validation loss: 2.222943876953649
Epoch: 9| Step: 3
Training loss: 2.1692818728773218
Validation loss: 2.237893519534772
Epoch: 9| Step: 4
Training loss: 2.706606348552628
Validation loss: 2.239594459465348
Epoch: 9| Step: 5
Training loss: 1.9354053372426898
Validation loss: 2.225708084829376
Epoch: 9| Step: 6
Training loss: 2.6236139907224256
Validation loss: 2.1957352948528652
Epoch: 9| Step: 7
Training loss: 2.4937102350492046
Validation loss: 2.212738522925622
Epoch: 9| Step: 8
Training loss: 2.912458945054577
Validation loss: 2.206685690312888
Epoch: 9| Step: 9
Training loss: 3.4215815170056447
Validation loss: 2.2247218883813633
Epoch: 9| Step: 10
Training loss: 2.53530963263249
Validation loss: 2.2156006779374824
Epoch: 9| Step: 11
Training loss: 2.913157795637778
Validation loss: 2.18867710341591
Epoch: 9| Step: 12
Training loss: 2.6891494834436815
Validation loss: 2.2323120344040346
Epoch: 9| Step: 13
Training loss: 3.191327956697222
Validation loss: 2.2176826876748703
Epoch: 9| Step: 14
Training loss: 2.2809119823286412
Validation loss: 2.2540730657819923
Epoch: 9| Step: 15
Training loss: 2.2908543158391645
Validation loss: 2.2109878307510393
Epoch: 9| Step: 16
Training loss: 2.848628125531797
Validation loss: 2.226307963500468
Epoch: 9| Step: 17
Training loss: 2.1870543979739656
Validation loss: 2.221602877844954
Epoch: 9| Step: 18
Training loss: 3.0137145953509674
Validation loss: 2.233926600639864
Epoch: 9| Step: 19
Training loss: 3.282183995605039
Validation loss: 2.193876490472641
Epoch: 20| Step: 0
Training loss: 3.0292653931310616
Validation loss: 2.2595197011430757
Epoch: 9| Step: 1
Training loss: 2.2607793092254655
Validation loss: 2.2017261165078374
Epoch: 9| Step: 2
Training loss: 2.646881186377852
Validation loss: 2.256577685559925
Epoch: 9| Step: 3
Training loss: 2.2231964902882364
Validation loss: 2.222288812684483
Epoch: 9| Step: 4
Training loss: 2.6774948536087
Validation loss: 2.19554456192583
Epoch: 9| Step: 5
Training loss: 2.1277190371584367
Validation loss: 2.1890614957736187
Epoch: 9| Step: 6
Training loss: 3.012442851810604
Validation loss: 2.2017068440342795
Epoch: 9| Step: 7
Training loss: 2.3658913063111773
Validation loss: 2.2303798215476314
Epoch: 9| Step: 8
Training loss: 2.580241681097632
Validation loss: 2.2208511189861713
Epoch: 9| Step: 9
Training loss: 2.359908087928782
Validation loss: 2.2258532310800243
Epoch: 9| Step: 10
Training loss: 2.3764688065799353
Validation loss: 2.2096842232168585
Epoch: 9| Step: 11
Training loss: 3.207268839688089
Validation loss: 2.213234277314103
Epoch: 9| Step: 12
Training loss: 3.170511789013323
Validation loss: 2.1747090564344234
Epoch: 9| Step: 13
Training loss: 3.455689871515982
Validation loss: 2.246114183033213
Epoch: 9| Step: 14
Training loss: 2.097582142691178
Validation loss: 2.1871288195634047
Epoch: 9| Step: 15
Training loss: 2.861615413265294
Validation loss: 2.233201038060936
Epoch: 9| Step: 16
Training loss: 3.1487612877280373
Validation loss: 2.174163752531628
Epoch: 9| Step: 17
Training loss: 2.5885558917897513
Validation loss: 2.234865885988969
Epoch: 9| Step: 18
Training loss: 1.8505753730734076
Validation loss: 2.1930373116916178
Epoch: 9| Step: 19
Training loss: 2.602731894386434
Validation loss: 2.2031362229394316
Epoch: 21| Step: 0
Training loss: 2.5972294277515067
Validation loss: 2.230120663887111
Epoch: 9| Step: 1
Training loss: 2.7299557096081464
Validation loss: 2.242061318700753
Epoch: 9| Step: 2
Training loss: 2.170648461766177
Validation loss: 2.211055654814934
Epoch: 9| Step: 3
Training loss: 3.1733315416806502
Validation loss: 2.245228782606197
Epoch: 9| Step: 4
Training loss: 2.4277341785875826
Validation loss: 2.227699311391691
Epoch: 9| Step: 5
Training loss: 2.6194390021014002
Validation loss: 2.2326678079565982
Epoch: 9| Step: 6
Training loss: 3.4696112585946284
Validation loss: 2.2328733192155794
Epoch: 9| Step: 7
Training loss: 2.915320240050959
Validation loss: 2.182414360249598
Epoch: 9| Step: 8
Training loss: 2.1188955701484735
Validation loss: 2.2221453594165657
Epoch: 9| Step: 9
Training loss: 2.355964671700694
Validation loss: 2.2154554513242575
Epoch: 9| Step: 10
Training loss: 2.989476661684181
Validation loss: 2.209611119791972
Epoch: 9| Step: 11
Training loss: 2.5947943733494223
Validation loss: 2.2292294680962184
Epoch: 9| Step: 12
Training loss: 2.546163447860851
Validation loss: 2.2215127924646128
Epoch: 9| Step: 13
Training loss: 2.9095891003035086
Validation loss: 2.2145769989927073
Epoch: 9| Step: 14
Training loss: 2.5066569390344915
Validation loss: 2.1644614586228794
Epoch: 9| Step: 15
Training loss: 2.250373173602812
Validation loss: 2.188570850021263
Epoch: 9| Step: 16
Training loss: 2.9863998174949855
Validation loss: 2.169690090917695
Epoch: 9| Step: 17
Training loss: 2.280335961736488
Validation loss: 2.2289408386319884
Epoch: 9| Step: 18
Training loss: 2.6366287781235247
Validation loss: 2.180177461531221
Epoch: 9| Step: 19
Training loss: 2.771657281042721
Validation loss: 2.1989564540071984
Epoch: 22| Step: 0
Training loss: 3.3880480277250182
Validation loss: 2.206987549955642
Epoch: 9| Step: 1
Training loss: 2.480097513127575
Validation loss: 2.174795531625527
Epoch: 9| Step: 2
Training loss: 2.3941570443866116
Validation loss: 2.1542120303703554
Epoch: 9| Step: 3
Training loss: 2.2678906917772412
Validation loss: 2.170183946200692
Epoch: 9| Step: 4
Training loss: 2.8298361643892314
Validation loss: 2.2145477874380264
Epoch: 9| Step: 5
Training loss: 1.886249870972727
Validation loss: 2.146546357775303
Epoch: 9| Step: 6
Training loss: 3.0536907940753126
Validation loss: 2.209791273770959
Epoch: 9| Step: 7
Training loss: 2.782679501182058
Validation loss: 2.1884860328471847
Epoch: 9| Step: 8
Training loss: 2.9541585415475984
Validation loss: 2.200161841106733
Epoch: 9| Step: 9
Training loss: 2.392521224610386
Validation loss: 2.188699996952271
Epoch: 9| Step: 10
Training loss: 2.3102887897056505
Validation loss: 2.206034309578602
Epoch: 9| Step: 11
Training loss: 3.0416004400141605
Validation loss: 2.187434009527834
Epoch: 9| Step: 12
Training loss: 3.0137414930390487
Validation loss: 2.1930381387479105
Epoch: 9| Step: 13
Training loss: 2.946792352190964
Validation loss: 2.2263033152038605
Epoch: 9| Step: 14
Training loss: 2.7646875031735245
Validation loss: 2.226137077640013
Epoch: 9| Step: 15
Training loss: 2.4326165014363244
Validation loss: 2.2119899869083794
Epoch: 9| Step: 16
Training loss: 2.7838330221964087
Validation loss: 2.237561365814085
Epoch: 9| Step: 17
Training loss: 2.3586938139950915
Validation loss: 2.2109456782048618
Epoch: 9| Step: 18
Training loss: 2.404890394667451
Validation loss: 2.2109735411582374
Epoch: 9| Step: 19
Training loss: 2.5021861054983643
Validation loss: 2.206950359205929
Epoch: 23| Step: 0
Training loss: 2.631028201796994
Validation loss: 2.1730828009205765
Epoch: 9| Step: 1
Training loss: 2.1060745981232736
Validation loss: 2.2108302089570957
Epoch: 9| Step: 2
Training loss: 3.2647344661769284
Validation loss: 2.1948351703812765
Epoch: 9| Step: 3
Training loss: 2.1069025313650283
Validation loss: 2.196104826380929
Epoch: 9| Step: 4
Training loss: 2.475186997872782
Validation loss: 2.2285042932915258
Epoch: 9| Step: 5
Training loss: 2.3546222032227733
Validation loss: 2.2067589219553914
Epoch: 9| Step: 6
Training loss: 3.263245514209855
Validation loss: 2.201165225165945
Epoch: 9| Step: 7
Training loss: 2.587596349719096
Validation loss: 2.187487951933166
Epoch: 9| Step: 8
Training loss: 2.0988869351216994
Validation loss: 2.1660496318293005
Epoch: 9| Step: 9
Training loss: 2.408734710755694
Validation loss: 2.2189524518824593
Epoch: 9| Step: 10
Training loss: 3.3992286199778423
Validation loss: 2.229980574426066
Epoch: 9| Step: 11
Training loss: 3.341225071852228
Validation loss: 2.1732342536720326
Epoch: 9| Step: 12
Training loss: 2.9129567848192686
Validation loss: 2.2030240096350884
Epoch: 9| Step: 13
Training loss: 3.00489027080038
Validation loss: 2.219756679010203
Epoch: 9| Step: 14
Training loss: 2.574782175276594
Validation loss: 2.1814450091761426
Epoch: 9| Step: 15
Training loss: 2.583107682083968
Validation loss: 2.2329310814718464
Epoch: 9| Step: 16
Training loss: 2.7263232456811513
Validation loss: 2.2085424033142456
Epoch: 9| Step: 17
Training loss: 2.0459394573751757
Validation loss: 2.2116255875843107
Epoch: 9| Step: 18
Training loss: 1.9187914915289435
Validation loss: 2.1942459657834035
Epoch: 9| Step: 19
Training loss: 2.599541322890733
Validation loss: 2.1737865091191706
Epoch: 24| Step: 0
Training loss: 1.9524735241607831
Validation loss: 2.219353564954464
Epoch: 9| Step: 1
Training loss: 2.644401332982872
Validation loss: 2.212066612679085
Epoch: 9| Step: 2
Training loss: 2.583266985461679
Validation loss: 2.227190483753442
Epoch: 9| Step: 3
Training loss: 2.8455878386908173
Validation loss: 2.2116396562049006
Epoch: 9| Step: 4
Training loss: 3.138969022765103
Validation loss: 2.2005766084674416
Epoch: 9| Step: 5
Training loss: 2.922227154893987
Validation loss: 2.2696086185752185
Epoch: 9| Step: 6
Training loss: 2.29649692459947
Validation loss: 2.24762366900232
Epoch: 9| Step: 7
Training loss: 3.244576256685797
Validation loss: 2.2050710604930903
Epoch: 9| Step: 8
Training loss: 2.897191851919899
Validation loss: 2.2256634042678685
Epoch: 9| Step: 9
Training loss: 2.5432365967871626
Validation loss: 2.1908161467370695
Epoch: 9| Step: 10
Training loss: 2.9969928292668233
Validation loss: 2.214682202563767
Epoch: 9| Step: 11
Training loss: 2.0493902229937313
Validation loss: 2.195006128696718
Epoch: 9| Step: 12
Training loss: 2.261540381162778
Validation loss: 2.2239266920851906
Epoch: 9| Step: 13
Training loss: 1.9270141245468344
Validation loss: 2.1882649979742754
Epoch: 9| Step: 14
Training loss: 2.7451767672407614
Validation loss: 2.209362708169786
Epoch: 9| Step: 15
Training loss: 2.4983198241957987
Validation loss: 2.1833122096675965
Epoch: 9| Step: 16
Training loss: 2.4541144835575586
Validation loss: 2.228566787161384
Epoch: 9| Step: 17
Training loss: 3.288919549948018
Validation loss: 2.241561053421522
Epoch: 9| Step: 18
Training loss: 2.9807475948258446
Validation loss: 2.220694231418505
Epoch: 9| Step: 19
Training loss: 2.227036382205836
Validation loss: 2.2064632828055304
Epoch: 25| Step: 0
Training loss: 2.0918360830242384
Validation loss: 2.188706625305514
Epoch: 9| Step: 1
Training loss: 2.1136512643954464
Validation loss: 2.216478223754453
Epoch: 9| Step: 2
Training loss: 2.7464843298595056
Validation loss: 2.198014986478136
Epoch: 9| Step: 3
Training loss: 2.233978876599721
Validation loss: 2.217854582852153
Epoch: 9| Step: 4
Training loss: 2.7518244673338694
Validation loss: 2.201051876078478
Epoch: 9| Step: 5
Training loss: 3.151646949495247
Validation loss: 2.2232537753886725
Epoch: 9| Step: 6
Training loss: 3.028543109195874
Validation loss: 2.243025978679482
Epoch: 9| Step: 7
Training loss: 3.087664852297332
Validation loss: 2.194798210492611
Epoch: 9| Step: 8
Training loss: 3.020466293311071
Validation loss: 2.187362995120973
Epoch: 9| Step: 9
Training loss: 2.1547824454187854
Validation loss: 2.191340514439192
Epoch: 9| Step: 10
Training loss: 2.8543810984306432
Validation loss: 2.1776629426398286
Epoch: 9| Step: 11
Training loss: 2.387367672273881
Validation loss: 2.2079426089152707
Epoch: 9| Step: 12
Training loss: 2.75530641281461
Validation loss: 2.202970623193321
Epoch: 9| Step: 13
Training loss: 2.340714383424015
Validation loss: 2.191444397993471
Epoch: 9| Step: 14
Training loss: 2.8703515994462
Validation loss: 2.1917965545937603
Epoch: 9| Step: 15
Training loss: 2.4280265208811653
Validation loss: 2.2017288015291303
Epoch: 9| Step: 16
Training loss: 3.25950728501853
Validation loss: 2.1719951111177314
Epoch: 9| Step: 17
Training loss: 3.2047997539171647
Validation loss: 2.192545415086161
Epoch: 9| Step: 18
Training loss: 1.7725953106347834
Validation loss: 2.179803195961369
Epoch: 9| Step: 19
Training loss: 2.452725517644562
Validation loss: 2.1832236088209642
Epoch: 26| Step: 0
Training loss: 2.852595228499601
Validation loss: 2.167919935574819
Epoch: 9| Step: 1
Training loss: 2.328490260612724
Validation loss: 2.177294208732001
Epoch: 9| Step: 2
Training loss: 3.0909603912767785
Validation loss: 2.1916331667848414
Epoch: 9| Step: 3
Training loss: 2.7227948672063964
Validation loss: 2.2062901844177447
Epoch: 9| Step: 4
Training loss: 2.202479491122103
Validation loss: 2.233163621098829
Epoch: 9| Step: 5
Training loss: 2.1732101178882126
Validation loss: 2.210046797676241
Epoch: 9| Step: 6
Training loss: 2.7559483092710617
Validation loss: 2.2206450469464842
Epoch: 9| Step: 7
Training loss: 2.712845803996646
Validation loss: 2.209396465119926
Epoch: 9| Step: 8
Training loss: 3.086032527957351
Validation loss: 2.2058142676835883
Epoch: 9| Step: 9
Training loss: 2.8423790613916533
Validation loss: 2.195230021907711
Epoch: 9| Step: 10
Training loss: 2.820590525948348
Validation loss: 2.218226221038406
Epoch: 9| Step: 11
Training loss: 2.319659928028602
Validation loss: 2.203097839387978
Epoch: 9| Step: 12
Training loss: 2.4268473127044703
Validation loss: 2.1827436869104684
Epoch: 9| Step: 13
Training loss: 2.407652409087707
Validation loss: 2.2000978326764744
Epoch: 9| Step: 14
Training loss: 2.1831560873444174
Validation loss: 2.1790621826794685
Epoch: 9| Step: 15
Training loss: 2.2001933619748346
Validation loss: 2.184385522789597
Epoch: 9| Step: 16
Training loss: 2.625996809115654
Validation loss: 2.2071030321797873
Epoch: 9| Step: 17
Training loss: 3.0891800853711193
Validation loss: 2.2274467654070405
Epoch: 9| Step: 18
Training loss: 3.2778718543336343
Validation loss: 2.187087478439053
Epoch: 9| Step: 19
Training loss: 2.493259880833529
Validation loss: 2.221820798667051
Epoch: 27| Step: 0
Training loss: 2.5438576827817636
Validation loss: 2.1377142274189955
Epoch: 9| Step: 1
Training loss: 1.770441490652295
Validation loss: 2.196505416397444
Epoch: 9| Step: 2
Training loss: 2.5400115601584425
Validation loss: 2.1655607889106725
Epoch: 9| Step: 3
Training loss: 3.1158046475484578
Validation loss: 2.1908631313210023
Epoch: 9| Step: 4
Training loss: 2.305487232140633
Validation loss: 2.195832227594247
Epoch: 9| Step: 5
Training loss: 1.8539229529295898
Validation loss: 2.181134205865827
Epoch: 9| Step: 6
Training loss: 3.137466740526917
Validation loss: 2.1758274198638636
Epoch: 9| Step: 7
Training loss: 2.4716582732552204
Validation loss: 2.242465651333776
Epoch: 9| Step: 8
Training loss: 2.7069821043631386
Validation loss: 2.2147141249110547
Epoch: 9| Step: 9
Training loss: 3.228050350718288
Validation loss: 2.23246594024813
Epoch: 9| Step: 10
Training loss: 1.9530425397631854
Validation loss: 2.163444694511678
Epoch: 9| Step: 11
Training loss: 2.4593869122964365
Validation loss: 2.2082236597564147
Epoch: 9| Step: 12
Training loss: 2.3915210116845333
Validation loss: 2.204782203105747
Epoch: 9| Step: 13
Training loss: 2.7629676595611397
Validation loss: 2.169693070639325
Epoch: 9| Step: 14
Training loss: 2.4998966195665986
Validation loss: 2.2236711143185337
Epoch: 9| Step: 15
Training loss: 2.917456565344023
Validation loss: 2.197820878581004
Epoch: 9| Step: 16
Training loss: 2.530644662318554
Validation loss: 2.205595116947122
Epoch: 9| Step: 17
Training loss: 2.7520210468906843
Validation loss: 2.207283277001678
Epoch: 9| Step: 18
Training loss: 3.2579042709927246
Validation loss: 2.207739820496752
Epoch: 9| Step: 19
Training loss: 3.101406756509654
Validation loss: 2.1880419130833184
Epoch: 28| Step: 0
Training loss: 2.70586393214685
Validation loss: 2.2219463739198217
Epoch: 9| Step: 1
Training loss: 2.6931878160439893
Validation loss: 2.2199899569335413
Epoch: 9| Step: 2
Training loss: 3.6003924473793805
Validation loss: 2.173573526395421
Epoch: 9| Step: 3
Training loss: 1.8431070790886166
Validation loss: 2.206548752219184
Epoch: 9| Step: 4
Training loss: 2.6870432620837295
Validation loss: 2.2441145896040546
Epoch: 9| Step: 5
Training loss: 2.398917979470954
Validation loss: 2.190041953305261
Epoch: 9| Step: 6
Training loss: 2.2446950255890115
Validation loss: 2.1724477810142613
Epoch: 9| Step: 7
Training loss: 2.850121539017312
Validation loss: 2.168709916800019
Epoch: 9| Step: 8
Training loss: 3.2599929355474586
Validation loss: 2.2412818860662838
Epoch: 9| Step: 9
Training loss: 2.681584968183808
Validation loss: 2.2206236480543837
Epoch: 9| Step: 10
Training loss: 2.992511940839076
Validation loss: 2.242456390708318
Epoch: 9| Step: 11
Training loss: 2.4003938033949663
Validation loss: 2.193316790136189
Epoch: 9| Step: 12
Training loss: 2.7277316234781788
Validation loss: 2.2255053167940138
Epoch: 9| Step: 13
Training loss: 2.5875474234395366
Validation loss: 2.1807610181395156
Epoch: 9| Step: 14
Training loss: 2.4320957232886147
Validation loss: 2.1945521649876834
Epoch: 9| Step: 15
Training loss: 2.728281610457299
Validation loss: 2.2291934687166743
Epoch: 9| Step: 16
Training loss: 2.685667433373519
Validation loss: 2.216505108638954
Epoch: 9| Step: 17
Training loss: 2.5673611749932164
Validation loss: 2.149534049726303
Epoch: 9| Step: 18
Training loss: 2.581135696946882
Validation loss: 2.195821334079517
Epoch: 9| Step: 19
Training loss: 1.994889465271937
Validation loss: 2.205759727265132
Epoch: 29| Step: 0
Training loss: 2.9092786861092748
Validation loss: 2.203952902420553
Epoch: 9| Step: 1
Training loss: 2.894651011513234
Validation loss: 2.164429014263098
Epoch: 9| Step: 2
Training loss: 1.950985033714027
Validation loss: 2.138506357909329
Epoch: 9| Step: 3
Training loss: 2.7187567524442455
Validation loss: 2.1896876907300036
Epoch: 9| Step: 4
Training loss: 2.236909615823584
Validation loss: 2.164929321481285
Epoch: 9| Step: 5
Training loss: 2.3765027160950045
Validation loss: 2.157474028504693
Epoch: 9| Step: 6
Training loss: 3.3036087475881755
Validation loss: 2.1954425367466848
Epoch: 9| Step: 7
Training loss: 2.0645099440797328
Validation loss: 2.201716600387658
Epoch: 9| Step: 8
Training loss: 2.7453935362612976
Validation loss: 2.2329099837154063
Epoch: 9| Step: 9
Training loss: 2.8033941575602284
Validation loss: 2.212272249039057
Epoch: 9| Step: 10
Training loss: 2.984462876548982
Validation loss: 2.2023701497541133
Epoch: 9| Step: 11
Training loss: 2.676452552510248
Validation loss: 2.216676377552775
Epoch: 9| Step: 12
Training loss: 2.7674438185533012
Validation loss: 2.1927501378296355
Epoch: 9| Step: 13
Training loss: 2.955165259166461
Validation loss: 2.1739832544918025
Epoch: 9| Step: 14
Training loss: 2.731863906966993
Validation loss: 2.1981667596886205
Epoch: 9| Step: 15
Training loss: 2.5748242142313122
Validation loss: 2.1800408411498946
Epoch: 9| Step: 16
Training loss: 2.81354588029629
Validation loss: 2.1754837913543077
Epoch: 9| Step: 17
Training loss: 3.088635310811381
Validation loss: 2.2103286043855626
Epoch: 9| Step: 18
Training loss: 2.297004228965842
Validation loss: 2.2064812473602426
Epoch: 9| Step: 19
Training loss: 2.3252163324923996
Validation loss: 2.1478836155238334
Epoch: 30| Step: 0
Training loss: 2.4154862338103977
Validation loss: 2.180949889337276
Epoch: 9| Step: 1
Training loss: 3.203806883641468
Validation loss: 2.196586293795129
Epoch: 9| Step: 2
Training loss: 2.7411542287953226
Validation loss: 2.1782100817526517
Epoch: 9| Step: 3
Training loss: 2.6832097429834496
Validation loss: 2.1913676083185147
Epoch: 9| Step: 4
Training loss: 2.776459586705502
Validation loss: 2.203308180442474
Epoch: 9| Step: 5
Training loss: 2.755108163859973
Validation loss: 2.1665741472249818
Epoch: 9| Step: 6
Training loss: 3.1986046132912347
Validation loss: 2.155595205041195
Epoch: 9| Step: 7
Training loss: 2.5811344037715767
Validation loss: 2.174549372759164
Epoch: 9| Step: 8
Training loss: 2.3138483601359043
Validation loss: 2.1960940420672497
Epoch: 9| Step: 9
Training loss: 2.4823346666674233
Validation loss: 2.1660380141925972
Epoch: 9| Step: 10
Training loss: 3.0138834139241437
Validation loss: 2.2200196790341047
Epoch: 9| Step: 11
Training loss: 3.007117570137131
Validation loss: 2.2117058698829326
Epoch: 9| Step: 12
Training loss: 3.107812690255383
Validation loss: 2.2233399484228964
Epoch: 9| Step: 13
Training loss: 1.671433934295118
Validation loss: 2.195412446147853
Epoch: 9| Step: 14
Training loss: 2.501961796646516
Validation loss: 2.2346772154453785
Epoch: 9| Step: 15
Training loss: 2.46004060417098
Validation loss: 2.2049087368226226
Epoch: 9| Step: 16
Training loss: 2.6327424988086015
Validation loss: 2.1843712822284207
Epoch: 9| Step: 17
Training loss: 2.060453382061443
Validation loss: 2.202501912815545
Epoch: 9| Step: 18
Training loss: 2.671104096858159
Validation loss: 2.1838460073922263
Epoch: 9| Step: 19
Training loss: 2.2096748116255305
Validation loss: 2.2328593005879105
Epoch: 31| Step: 0
Training loss: 3.2862419303020127
Validation loss: 2.198062911465647
Epoch: 9| Step: 1
Training loss: 3.08639530697313
Validation loss: 2.1794925754858734
Epoch: 9| Step: 2
Training loss: 2.3723551428802128
Validation loss: 2.1997119922567276
Epoch: 9| Step: 3
Training loss: 2.6539840008584723
Validation loss: 2.204291589539316
Epoch: 9| Step: 4
Training loss: 2.439262730885725
Validation loss: 2.169284207916219
Epoch: 9| Step: 5
Training loss: 2.1984082315607343
Validation loss: 2.200351785320472
Epoch: 9| Step: 6
Training loss: 2.3983311334440396
Validation loss: 2.206392833461143
Epoch: 9| Step: 7
Training loss: 2.7575194119334756
Validation loss: 2.1553494871956325
Epoch: 9| Step: 8
Training loss: 2.364000245741365
Validation loss: 2.1873354814254204
Epoch: 9| Step: 9
Training loss: 2.330591111738553
Validation loss: 2.1898447139043564
Epoch: 9| Step: 10
Training loss: 3.1848133208512985
Validation loss: 2.197532585966386
Epoch: 9| Step: 11
Training loss: 2.5177206468156097
Validation loss: 2.2361127638596416
Epoch: 9| Step: 12
Training loss: 2.8188308670387117
Validation loss: 2.171662187387783
Epoch: 9| Step: 13
Training loss: 2.8218508088858743
Validation loss: 2.2185944080805906
Epoch: 9| Step: 14
Training loss: 2.703553799702936
Validation loss: 2.1786048910590936
Epoch: 9| Step: 15
Training loss: 2.5833470949196102
Validation loss: 2.196736333250926
Epoch: 9| Step: 16
Training loss: 2.492967728602942
Validation loss: 2.200944216486775
Epoch: 9| Step: 17
Training loss: 1.8412564760134384
Validation loss: 2.198999688732927
Epoch: 9| Step: 18
Training loss: 2.2090379082814784
Validation loss: 2.1832971151554896
Epoch: 9| Step: 19
Training loss: 2.960770010929114
Validation loss: 2.1780661243654094
Epoch: 32| Step: 0
Training loss: 2.719655467119459
Validation loss: 2.1928372673380974
Epoch: 9| Step: 1
Training loss: 2.5201349998825573
Validation loss: 2.1895295571953515
Epoch: 9| Step: 2
Training loss: 3.288930568631439
Validation loss: 2.2210438005788955
Epoch: 9| Step: 3
Training loss: 2.6246409397694044
Validation loss: 2.176521349798166
Epoch: 9| Step: 4
Training loss: 2.190265324514923
Validation loss: 2.1993338552502903
Epoch: 9| Step: 5
Training loss: 2.1342699150701474
Validation loss: 2.184278424238723
Epoch: 9| Step: 6
Training loss: 2.346472011461831
Validation loss: 2.218599032556223
Epoch: 9| Step: 7
Training loss: 2.966415772562162
Validation loss: 2.1895802546420584
Epoch: 9| Step: 8
Training loss: 2.9505400470445857
Validation loss: 2.16635909483993
Epoch: 9| Step: 9
Training loss: 2.702166084036163
Validation loss: 2.2310223516637753
Epoch: 9| Step: 10
Training loss: 2.5203072705720118
Validation loss: 2.1508211340545937
Epoch: 9| Step: 11
Training loss: 2.5088101598105723
Validation loss: 2.170756707767355
Epoch: 9| Step: 12
Training loss: 2.181555053890577
Validation loss: 2.1864900247131565
Epoch: 9| Step: 13
Training loss: 3.487404366005774
Validation loss: 2.189655399771819
Epoch: 9| Step: 14
Training loss: 2.693027578253042
Validation loss: 2.1497342804452506
Epoch: 9| Step: 15
Training loss: 2.674200105950383
Validation loss: 2.151549102120119
Epoch: 9| Step: 16
Training loss: 2.614789997661869
Validation loss: 2.1419191730865768
Epoch: 9| Step: 17
Training loss: 2.368485500897704
Validation loss: 2.170611557287131
Epoch: 9| Step: 18
Training loss: 1.7526807007840182
Validation loss: 2.1864819504457382
Epoch: 9| Step: 19
Training loss: 3.1839848003216344
Validation loss: 2.1868394234241557
Epoch: 33| Step: 0
Training loss: 2.411497957523374
Validation loss: 2.196320249426494
Epoch: 9| Step: 1
Training loss: 3.4415094747660926
Validation loss: 2.20218638897763
Epoch: 9| Step: 2
Training loss: 2.848278422472745
Validation loss: 2.2047100962807673
Epoch: 9| Step: 3
Training loss: 3.0746328615423937
Validation loss: 2.205295920065219
Epoch: 9| Step: 4
Training loss: 2.429604777310887
Validation loss: 2.214242830952628
Epoch: 9| Step: 5
Training loss: 2.5743145150647666
Validation loss: 2.1612705080197894
Epoch: 9| Step: 6
Training loss: 2.4651526788005165
Validation loss: 2.1869324005042188
Epoch: 9| Step: 7
Training loss: 2.140731808858764
Validation loss: 2.20032310761359
Epoch: 9| Step: 8
Training loss: 2.9723444009389235
Validation loss: 2.2141011874401855
Epoch: 9| Step: 9
Training loss: 3.101464411724304
Validation loss: 2.168111349598018
Epoch: 9| Step: 10
Training loss: 2.669697102571061
Validation loss: 2.18989331569674
Epoch: 9| Step: 11
Training loss: 2.028018670020606
Validation loss: 2.177411657447244
Epoch: 9| Step: 12
Training loss: 1.8184841944941397
Validation loss: 2.120612471777571
Epoch: 9| Step: 13
Training loss: 2.8873001359739714
Validation loss: 2.1874925906109333
Epoch: 9| Step: 14
Training loss: 2.477369110930382
Validation loss: 2.235098339508443
Epoch: 9| Step: 15
Training loss: 2.5939498272869375
Validation loss: 2.180608002973716
Epoch: 9| Step: 16
Training loss: 2.249655273308416
Validation loss: 2.1866854183563618
Epoch: 9| Step: 17
Training loss: 3.678379223123473
Validation loss: 2.2167123561268616
Epoch: 9| Step: 18
Training loss: 2.1402712341688255
Validation loss: 2.1925922684985806
Epoch: 9| Step: 19
Training loss: 2.2814803333793345
Validation loss: 2.199696575739064
Epoch: 34| Step: 0
Training loss: 2.788214119070736
Validation loss: 2.1844448386381745
Epoch: 9| Step: 1
Training loss: 2.7748040069925084
Validation loss: 2.230393266573853
Epoch: 9| Step: 2
Training loss: 2.658815379269275
Validation loss: 2.1669714326184617
Epoch: 9| Step: 3
Training loss: 2.3943370846161294
Validation loss: 2.174501485083459
Epoch: 9| Step: 4
Training loss: 2.36777340527819
Validation loss: 2.2191773328760434
Epoch: 9| Step: 5
Training loss: 2.0503733783388296
Validation loss: 2.170953513981038
Epoch: 9| Step: 6
Training loss: 2.010918852653684
Validation loss: 2.1886999863571206
Epoch: 9| Step: 7
Training loss: 2.7039786517863647
Validation loss: 2.204254819708167
Epoch: 9| Step: 8
Training loss: 3.0915769401204574
Validation loss: 2.1796726618831666
Epoch: 9| Step: 9
Training loss: 1.833422687549356
Validation loss: 2.201013217522645
Epoch: 9| Step: 10
Training loss: 2.8130575687011206
Validation loss: 2.184879143047159
Epoch: 9| Step: 11
Training loss: 2.1047817376214812
Validation loss: 2.213409424407864
Epoch: 9| Step: 12
Training loss: 3.447928959727582
Validation loss: 2.2167584759508245
Epoch: 9| Step: 13
Training loss: 2.157704180872188
Validation loss: 2.202663761860867
Epoch: 9| Step: 14
Training loss: 2.8232193018626646
Validation loss: 2.234041863603939
Epoch: 9| Step: 15
Training loss: 3.0261108250465427
Validation loss: 2.205598696928993
Epoch: 9| Step: 16
Training loss: 2.443663019451888
Validation loss: 2.2153359283674177
Epoch: 9| Step: 17
Training loss: 3.2325931376929984
Validation loss: 2.2147927169628514
Epoch: 9| Step: 18
Training loss: 2.8705011080520637
Validation loss: 2.185949626862465
Epoch: 9| Step: 19
Training loss: 2.1047636135869485
Validation loss: 2.2031673698385146
Epoch: 35| Step: 0
Training loss: 3.11199258245452
Validation loss: 2.23055068242562
Epoch: 9| Step: 1
Training loss: 2.5910986712331434
Validation loss: 2.2028700095876044
Epoch: 9| Step: 2
Training loss: 2.1344646161368623
Validation loss: 2.1787719729620827
Epoch: 9| Step: 3
Training loss: 2.365843539303861
Validation loss: 2.185221200437784
Epoch: 9| Step: 4
Training loss: 2.6447166028563114
Validation loss: 2.2134407277677637
Epoch: 9| Step: 5
Training loss: 3.50078560323004
Validation loss: 2.199990160781054
Epoch: 9| Step: 6
Training loss: 2.960257661018159
Validation loss: 2.182420461892853
Epoch: 9| Step: 7
Training loss: 2.2665605389302406
Validation loss: 2.1826290382593645
Epoch: 9| Step: 8
Training loss: 2.714350945183652
Validation loss: 2.203157621212505
Epoch: 9| Step: 9
Training loss: 2.9042967108166566
Validation loss: 2.1476390747548333
Epoch: 9| Step: 10
Training loss: 3.164061746479463
Validation loss: 2.187395321074249
Epoch: 9| Step: 11
Training loss: 2.1574692527021053
Validation loss: 2.1780324911919813
Epoch: 9| Step: 12
Training loss: 2.1967054407443882
Validation loss: 2.184453850669118
Epoch: 9| Step: 13
Training loss: 2.385450360144879
Validation loss: 2.183230820356491
Epoch: 9| Step: 14
Training loss: 2.550058259485461
Validation loss: 2.176144941986423
Epoch: 9| Step: 15
Training loss: 2.554520441128445
Validation loss: 2.1981870977037197
Epoch: 9| Step: 16
Training loss: 2.5374418280186473
Validation loss: 2.19701978717907
Epoch: 9| Step: 17
Training loss: 2.243568447067855
Validation loss: 2.188923711636949
Epoch: 9| Step: 18
Training loss: 3.3421104903798775
Validation loss: 2.1798525302153124
Epoch: 9| Step: 19
Training loss: 1.843367197416651
Validation loss: 2.1853566576711194
Epoch: 36| Step: 0
Training loss: 2.166590236880781
Validation loss: 2.207644844692552
Epoch: 9| Step: 1
Training loss: 2.683547728919893
Validation loss: 2.1712936596411647
Epoch: 9| Step: 2
Training loss: 2.8957181033986346
Validation loss: 2.171666952464182
Epoch: 9| Step: 3
Training loss: 2.8590114341525874
Validation loss: 2.141665679096818
Epoch: 9| Step: 4
Training loss: 2.4534701936667047
Validation loss: 2.182012718553024
Epoch: 9| Step: 5
Training loss: 3.020956909458278
Validation loss: 2.1891440238738076
Epoch: 9| Step: 6
Training loss: 4.019692820868967
Validation loss: 2.178537039518598
Epoch: 9| Step: 7
Training loss: 2.31450823625709
Validation loss: 2.1771030936717404
Epoch: 9| Step: 8
Training loss: 2.999428217758159
Validation loss: 2.1634862237499606
Epoch: 9| Step: 9
Training loss: 2.8933439097526135
Validation loss: 2.1877698147372584
Epoch: 9| Step: 10
Training loss: 2.2684578909813418
Validation loss: 2.150047251794539
Epoch: 9| Step: 11
Training loss: 3.131905364934385
Validation loss: 2.161857873077784
Epoch: 9| Step: 12
Training loss: 1.511445880876279
Validation loss: 2.196221354133545
Epoch: 9| Step: 13
Training loss: 2.335287252397121
Validation loss: 2.19047551544155
Epoch: 9| Step: 14
Training loss: 2.544888898001999
Validation loss: 2.163046202495181
Epoch: 9| Step: 15
Training loss: 2.5412214754364166
Validation loss: 2.1275427985468363
Epoch: 9| Step: 16
Training loss: 2.511089145185483
Validation loss: 2.1842216108322132
Epoch: 9| Step: 17
Training loss: 2.180321713953395
Validation loss: 2.1902290625080285
Epoch: 9| Step: 18
Training loss: 2.1431840511006257
Validation loss: 2.1916507997566033
Epoch: 9| Step: 19
Training loss: 2.848685038195409
Validation loss: 2.17726235379115
Epoch: 37| Step: 0
Training loss: 2.5965281855131215
Validation loss: 2.1671035617066563
Epoch: 9| Step: 1
Training loss: 3.0050372114114947
Validation loss: 2.185022264154584
Epoch: 9| Step: 2
Training loss: 2.1898582825465986
Validation loss: 2.2243627194097355
Epoch: 9| Step: 3
Training loss: 2.0355880191431663
Validation loss: 2.180044472374969
Epoch: 9| Step: 4
Training loss: 1.8016031173004907
Validation loss: 2.169801413453541
Epoch: 9| Step: 5
Training loss: 2.4621007682822955
Validation loss: 2.1585028865513944
Epoch: 9| Step: 6
Training loss: 1.9202532865428872
Validation loss: 2.197763841619092
Epoch: 9| Step: 7
Training loss: 2.684187333427042
Validation loss: 2.209531880576384
Epoch: 9| Step: 8
Training loss: 3.107912879577067
Validation loss: 2.2070260538933
Epoch: 9| Step: 9
Training loss: 3.162607871164702
Validation loss: 2.179903862274839
Epoch: 9| Step: 10
Training loss: 2.990085271684706
Validation loss: 2.2387030574493383
Epoch: 9| Step: 11
Training loss: 2.6694208664326418
Validation loss: 2.1938671003167736
Epoch: 9| Step: 12
Training loss: 3.04165672056758
Validation loss: 2.222172133004755
Epoch: 9| Step: 13
Training loss: 2.6898706315708574
Validation loss: 2.210816168339026
Epoch: 9| Step: 14
Training loss: 3.1669875199915496
Validation loss: 2.207913154412145
Epoch: 9| Step: 15
Training loss: 2.502988554894452
Validation loss: 2.1489777697898975
Epoch: 9| Step: 16
Training loss: 2.6807342353349437
Validation loss: 2.159008159643525
Epoch: 9| Step: 17
Training loss: 2.5256487249078043
Validation loss: 2.2107266199351985
Epoch: 9| Step: 18
Training loss: 2.405428659539254
Validation loss: 2.2131887698921027
Epoch: 9| Step: 19
Training loss: 2.32988923067374
Validation loss: 2.199640070656281
Epoch: 38| Step: 0
Training loss: 2.593372915042696
Validation loss: 2.163504497368441
Epoch: 9| Step: 1
Training loss: 2.120906252503674
Validation loss: 2.2295459722117794
Epoch: 9| Step: 2
Training loss: 2.6525534545516987
Validation loss: 2.1847415555283587
Epoch: 9| Step: 3
Training loss: 2.5369317607069934
Validation loss: 2.196019612053683
Epoch: 9| Step: 4
Training loss: 2.517464291149798
Validation loss: 2.170641153137175
Epoch: 9| Step: 5
Training loss: 2.9820502848488633
Validation loss: 2.1786757021745795
Epoch: 9| Step: 6
Training loss: 2.7121086998594865
Validation loss: 2.1588808690990597
Epoch: 9| Step: 7
Training loss: 2.1759370648735517
Validation loss: 2.185111062439687
Epoch: 9| Step: 8
Training loss: 2.8699525394569423
Validation loss: 2.2214260282895566
Epoch: 9| Step: 9
Training loss: 3.138325774807842
Validation loss: 2.1911411286097637
Epoch: 9| Step: 10
Training loss: 2.8980531669041416
Validation loss: 2.1951410611413467
Epoch: 9| Step: 11
Training loss: 2.8577596134988195
Validation loss: 2.185340860498022
Epoch: 9| Step: 12
Training loss: 2.778499657820879
Validation loss: 2.1971262626010635
Epoch: 9| Step: 13
Training loss: 2.304706638062753
Validation loss: 2.1216959535845525
Epoch: 9| Step: 14
Training loss: 1.9162179449278152
Validation loss: 2.1790016832918115
Epoch: 9| Step: 15
Training loss: 2.5574946947685993
Validation loss: 2.2041397485677594
Epoch: 9| Step: 16
Training loss: 2.387169828103566
Validation loss: 2.19097599404561
Epoch: 9| Step: 17
Training loss: 2.6280755690417728
Validation loss: 2.193726176666399
Epoch: 9| Step: 18
Training loss: 3.3621871178707723
Validation loss: 2.1612755832225488
Epoch: 9| Step: 19
Training loss: 2.4446302930908512
Validation loss: 2.168754271757969
Epoch: 39| Step: 0
Training loss: 3.064171315565638
Validation loss: 2.1712357020192545
Epoch: 9| Step: 1
Training loss: 2.4077847032966213
Validation loss: 2.1594256356764046
Epoch: 9| Step: 2
Training loss: 2.6346509723305283
Validation loss: 2.171044833429621
Epoch: 9| Step: 3
Training loss: 2.529236169035008
Validation loss: 2.1883230471177466
Epoch: 9| Step: 4
Training loss: 2.297461194861522
Validation loss: 2.149392046512919
Epoch: 9| Step: 5
Training loss: 3.015397928019889
Validation loss: 2.1443238262811675
Epoch: 9| Step: 6
Training loss: 2.444391046528437
Validation loss: 2.179034051626148
Epoch: 9| Step: 7
Training loss: 1.8844072861064378
Validation loss: 2.1741714929008022
Epoch: 9| Step: 8
Training loss: 3.2221177639600107
Validation loss: 2.174377965055541
Epoch: 9| Step: 9
Training loss: 2.8647841689481184
Validation loss: 2.1519590777274047
Epoch: 9| Step: 10
Training loss: 2.573310749798177
Validation loss: 2.2134251259880027
Epoch: 9| Step: 11
Training loss: 3.0203710969706234
Validation loss: 2.150006088931948
Epoch: 9| Step: 12
Training loss: 2.9939883716589324
Validation loss: 2.188445876683886
Epoch: 9| Step: 13
Training loss: 2.2648310881698603
Validation loss: 2.132199198496573
Epoch: 9| Step: 14
Training loss: 2.1334683594092945
Validation loss: 2.2093936703473545
Epoch: 9| Step: 15
Training loss: 2.170892836425804
Validation loss: 2.2044643833665907
Epoch: 9| Step: 16
Training loss: 2.2805522740049162
Validation loss: 2.170219913107501
Epoch: 9| Step: 17
Training loss: 2.863775150849665
Validation loss: 2.1712508453974806
Epoch: 9| Step: 18
Training loss: 2.427163926343212
Validation loss: 2.153865726988842
Epoch: 9| Step: 19
Training loss: 2.7516137503378966
Validation loss: 2.1630854099051287
Epoch: 40| Step: 0
Training loss: 2.327688905976349
Validation loss: 2.1645165804079327
Epoch: 9| Step: 1
Training loss: 2.6329264177529286
Validation loss: 2.1817578262332216
Epoch: 9| Step: 2
Training loss: 3.28556975348896
Validation loss: 2.162903174721983
Epoch: 9| Step: 3
Training loss: 2.3408551458218647
Validation loss: 2.1743360696664724
Epoch: 9| Step: 4
Training loss: 2.55102631354135
Validation loss: 2.1628948921133886
Epoch: 9| Step: 5
Training loss: 2.977757812151551
Validation loss: 2.1728477911695334
Epoch: 9| Step: 6
Training loss: 2.108085068370596
Validation loss: 2.1771710646795865
Epoch: 9| Step: 7
Training loss: 2.8453743456048057
Validation loss: 2.1788110834212384
Epoch: 9| Step: 8
Training loss: 2.7491312388665556
Validation loss: 2.20450916015586
Epoch: 9| Step: 9
Training loss: 2.5791041508885155
Validation loss: 2.189558692911137
Epoch: 9| Step: 10
Training loss: 2.8171245278055377
Validation loss: 2.1825251020184626
Epoch: 9| Step: 11
Training loss: 3.0200548593957306
Validation loss: 2.1856336688063824
Epoch: 9| Step: 12
Training loss: 3.302972731964802
Validation loss: 2.1403272800839344
Epoch: 9| Step: 13
Training loss: 2.0146614551354762
Validation loss: 2.155317854579304
Epoch: 9| Step: 14
Training loss: 3.054566832205455
Validation loss: 2.1874742833867216
Epoch: 9| Step: 15
Training loss: 2.2537763482117716
Validation loss: 2.168006134922107
Epoch: 9| Step: 16
Training loss: 2.9057984360208557
Validation loss: 2.2241549837790964
Epoch: 9| Step: 17
Training loss: 1.8687474585678527
Validation loss: 2.183379842367292
Epoch: 9| Step: 18
Training loss: 2.2613079112973637
Validation loss: 2.160009118115133
Epoch: 9| Step: 19
Training loss: 2.152061374647062
Validation loss: 2.215014126100968
Epoch: 41| Step: 0
Training loss: 2.045232448657846
Validation loss: 2.199835018763637
Epoch: 9| Step: 1
Training loss: 2.4469448893225683
Validation loss: 2.2046542176278727
Epoch: 9| Step: 2
Training loss: 2.5212340758865244
Validation loss: 2.179958880283345
Epoch: 9| Step: 3
Training loss: 2.120417646978922
Validation loss: 2.1534329272994626
Epoch: 9| Step: 4
Training loss: 2.916180452056264
Validation loss: 2.2200343193915013
Epoch: 9| Step: 5
Training loss: 2.214603794562004
Validation loss: 2.160424819698796
Epoch: 9| Step: 6
Training loss: 3.1100941502097563
Validation loss: 2.1841572440238872
Epoch: 9| Step: 7
Training loss: 2.3150376495199962
Validation loss: 2.1641755794356
Epoch: 9| Step: 8
Training loss: 2.3789328086635795
Validation loss: 2.1824114260330787
Epoch: 9| Step: 9
Training loss: 2.726932533316467
Validation loss: 2.1597147454966676
Epoch: 9| Step: 10
Training loss: 2.7460008499688753
Validation loss: 2.1680054671816227
Epoch: 9| Step: 11
Training loss: 2.1735836415963803
Validation loss: 2.163364155050523
Epoch: 9| Step: 12
Training loss: 2.6598909444610284
Validation loss: 2.1856566791572503
Epoch: 9| Step: 13
Training loss: 2.7923614908837044
Validation loss: 2.1729611009428975
Epoch: 9| Step: 14
Training loss: 3.0788653882327206
Validation loss: 2.1763253578329063
Epoch: 9| Step: 15
Training loss: 2.98336934826244
Validation loss: 2.2130939526564783
Epoch: 9| Step: 16
Training loss: 2.75759722596182
Validation loss: 2.207825145788417
Epoch: 9| Step: 17
Training loss: 3.0013243613033445
Validation loss: 2.1708084450581606
Epoch: 9| Step: 18
Training loss: 3.4488031605698297
Validation loss: 2.182488246254094
Epoch: 9| Step: 19
Training loss: 1.6330940697387413
Validation loss: 2.160155843157
Epoch: 42| Step: 0
Training loss: 2.75090003457298
Validation loss: 2.1970315572080605
Epoch: 9| Step: 1
Training loss: 1.8195393111303024
Validation loss: 2.140300881599406
Epoch: 9| Step: 2
Training loss: 1.9611444250104355
Validation loss: 2.1975610342443077
Epoch: 9| Step: 3
Training loss: 2.7920085830447245
Validation loss: 2.1575692389753915
Epoch: 9| Step: 4
Training loss: 2.7884378882500536
Validation loss: 2.157452344473236
Epoch: 9| Step: 5
Training loss: 2.6963786352436463
Validation loss: 2.164191314860837
Epoch: 9| Step: 6
Training loss: 1.969112120734014
Validation loss: 2.156874458866404
Epoch: 9| Step: 7
Training loss: 2.3488871922402144
Validation loss: 2.1619358144516845
Epoch: 9| Step: 8
Training loss: 2.706289478745268
Validation loss: 2.18344620090372
Epoch: 9| Step: 9
Training loss: 2.4644953123246585
Validation loss: 2.157223818443788
Epoch: 9| Step: 10
Training loss: 2.449654231681966
Validation loss: 2.1652972726212254
Epoch: 9| Step: 11
Training loss: 2.986331318466245
Validation loss: 2.1618426708430905
Epoch: 9| Step: 12
Training loss: 2.8437557010803087
Validation loss: 2.1941762226174655
Epoch: 9| Step: 13
Training loss: 2.7323620171360874
Validation loss: 2.191708353361681
Epoch: 9| Step: 14
Training loss: 2.905621204238352
Validation loss: 2.16870363760334
Epoch: 9| Step: 15
Training loss: 2.709407319576823
Validation loss: 2.185773975605373
Epoch: 9| Step: 16
Training loss: 3.151416060639385
Validation loss: 2.1896096938742824
Epoch: 9| Step: 17
Training loss: 2.5574340987827426
Validation loss: 2.1589973400429248
Epoch: 9| Step: 18
Training loss: 2.525174420064009
Validation loss: 2.1877794333436764
Epoch: 9| Step: 19
Training loss: 2.5743775846945764
Validation loss: 2.1718062715278994
Epoch: 43| Step: 0
Training loss: 2.421309078915711
Validation loss: 2.2136112347810672
Epoch: 9| Step: 1
Training loss: 2.2706575471460098
Validation loss: 2.1925859487670256
Epoch: 9| Step: 2
Training loss: 2.58473772411787
Validation loss: 2.1569107847526765
Epoch: 9| Step: 3
Training loss: 2.641016462755007
Validation loss: 2.1713113689582815
Epoch: 9| Step: 4
Training loss: 3.162313246207382
Validation loss: 2.1312296199573533
Epoch: 9| Step: 5
Training loss: 2.6999829503686676
Validation loss: 2.1919550310741402
Epoch: 9| Step: 6
Training loss: 2.6920487698562723
Validation loss: 2.142446320072995
Epoch: 9| Step: 7
Training loss: 3.119492828033171
Validation loss: 2.2097350704741934
Epoch: 9| Step: 8
Training loss: 3.0309671486307965
Validation loss: 2.1459524355526605
Epoch: 9| Step: 9
Training loss: 2.7175396384512878
Validation loss: 2.1809692269663765
Epoch: 9| Step: 10
Training loss: 2.6166911551267105
Validation loss: 2.153739376219641
Epoch: 9| Step: 11
Training loss: 2.5916828052799197
Validation loss: 2.173299890093123
Epoch: 9| Step: 12
Training loss: 2.60445300753245
Validation loss: 2.152017297384755
Epoch: 9| Step: 13
Training loss: 1.8409356442858011
Validation loss: 2.1326089311444396
Epoch: 9| Step: 14
Training loss: 2.570558484026342
Validation loss: 2.1722465141041187
Epoch: 9| Step: 15
Training loss: 2.99556372379481
Validation loss: 2.194577983679025
Epoch: 9| Step: 16
Training loss: 1.9726356429732756
Validation loss: 2.2066331457043145
Epoch: 9| Step: 17
Training loss: 2.681937204785033
Validation loss: 2.1894664859652955
Epoch: 9| Step: 18
Training loss: 2.0526563228500594
Validation loss: 2.176434552741605
Epoch: 9| Step: 19
Training loss: 2.59954526665998
Validation loss: 2.1835868160517835
Epoch: 44| Step: 0
Training loss: 2.9223306066077477
Validation loss: 2.1654743315107927
Epoch: 9| Step: 1
Training loss: 2.757095546302382
Validation loss: 2.163898975834303
Epoch: 9| Step: 2
Training loss: 2.288035295734392
Validation loss: 2.17355476238093
Epoch: 9| Step: 3
Training loss: 2.271712654956219
Validation loss: 2.1922784708208027
Epoch: 9| Step: 4
Training loss: 2.38399138758211
Validation loss: 2.1391097067184166
Epoch: 9| Step: 5
Training loss: 3.0633000477119463
Validation loss: 2.1778251531066877
Epoch: 9| Step: 6
Training loss: 2.3656744323161534
Validation loss: 2.1728508628954235
Epoch: 9| Step: 7
Training loss: 2.001398432109787
Validation loss: 2.2023435136140503
Epoch: 9| Step: 8
Training loss: 1.7210327248440487
Validation loss: 2.194060005371608
Epoch: 9| Step: 9
Training loss: 2.529216184765024
Validation loss: 2.1530234505828902
Epoch: 9| Step: 10
Training loss: 3.067369443420404
Validation loss: 2.1838839336914035
Epoch: 9| Step: 11
Training loss: 2.1918139834867394
Validation loss: 2.162756386534079
Epoch: 9| Step: 12
Training loss: 3.5249428927077084
Validation loss: 2.202353860792978
Epoch: 9| Step: 13
Training loss: 2.644746982897635
Validation loss: 2.1411638776931206
Epoch: 9| Step: 14
Training loss: 2.680502987106244
Validation loss: 2.1608268468911453
Epoch: 9| Step: 15
Training loss: 2.4061703359124027
Validation loss: 2.2093815388913387
Epoch: 9| Step: 16
Training loss: 2.83224978952056
Validation loss: 2.195502114385587
Epoch: 9| Step: 17
Training loss: 2.229646387503109
Validation loss: 2.197464404683573
Epoch: 9| Step: 18
Training loss: 2.5080159422688695
Validation loss: 2.217258345662614
Epoch: 9| Step: 19
Training loss: 2.97595256653793
Validation loss: 2.2208269846750572
Epoch: 45| Step: 0
Training loss: 2.613706545584853
Validation loss: 2.1730688222161834
Epoch: 9| Step: 1
Training loss: 1.6775693090592076
Validation loss: 2.190652102910072
Epoch: 9| Step: 2
Training loss: 2.9509445294732046
Validation loss: 2.1868185703664773
Epoch: 9| Step: 3
Training loss: 3.3153380705769355
Validation loss: 2.1979222409966073
Epoch: 9| Step: 4
Training loss: 2.1850596303244747
Validation loss: 2.1703779952321085
Epoch: 9| Step: 5
Training loss: 2.830908991001306
Validation loss: 2.165926237999458
Epoch: 9| Step: 6
Training loss: 2.198284269088547
Validation loss: 2.136708143849479
Epoch: 9| Step: 7
Training loss: 2.5700696465224584
Validation loss: 2.1978116621542023
Epoch: 9| Step: 8
Training loss: 2.648154094465091
Validation loss: 2.1728265124515826
Epoch: 9| Step: 9
Training loss: 1.8654152348097992
Validation loss: 2.1537013685027815
Epoch: 9| Step: 10
Training loss: 2.9252637499714402
Validation loss: 2.1796791034769516
Epoch: 9| Step: 11
Training loss: 2.219188700542823
Validation loss: 2.166150706776574
Epoch: 9| Step: 12
Training loss: 2.7193774672163666
Validation loss: 2.1963004462825406
Epoch: 9| Step: 13
Training loss: 3.29218280141936
Validation loss: 2.1710743688085135
Epoch: 9| Step: 14
Training loss: 2.90091223345241
Validation loss: 2.1909631211471154
Epoch: 9| Step: 15
Training loss: 2.0245139303936415
Validation loss: 2.152027281946209
Epoch: 9| Step: 16
Training loss: 2.3971721280982217
Validation loss: 2.1593284263693
Epoch: 9| Step: 17
Training loss: 3.330913682747432
Validation loss: 2.157556981309085
Epoch: 9| Step: 18
Training loss: 2.597864220117085
Validation loss: 2.1513685077378066
Epoch: 9| Step: 19
Training loss: 2.181721275157105
Validation loss: 2.141717005328874
Epoch: 46| Step: 0
Training loss: 2.959344359806238
Validation loss: 2.144888875193269
Epoch: 9| Step: 1
Training loss: 2.1767884804647606
Validation loss: 2.1968986875723426
Epoch: 9| Step: 2
Training loss: 3.009418009513043
Validation loss: 2.1237748821640365
Epoch: 9| Step: 3
Training loss: 3.8529865967086496
Validation loss: 2.215498546817278
Epoch: 9| Step: 4
Training loss: 2.3719539181895266
Validation loss: 2.1592951517915706
Epoch: 9| Step: 5
Training loss: 2.2889251146978533
Validation loss: 2.1704037431232597
Epoch: 9| Step: 6
Training loss: 2.202219675607724
Validation loss: 2.195796806908057
Epoch: 9| Step: 7
Training loss: 2.206598344054405
Validation loss: 2.2182805303288875
Epoch: 9| Step: 8
Training loss: 2.9941342547225123
Validation loss: 2.1711714456232505
Epoch: 9| Step: 9
Training loss: 2.681808121931255
Validation loss: 2.1684869411241046
Epoch: 9| Step: 10
Training loss: 2.5996223065336235
Validation loss: 2.1626031335129188
Epoch: 9| Step: 11
Training loss: 2.8698392242165
Validation loss: 2.189945651782763
Epoch: 9| Step: 12
Training loss: 2.06710370990368
Validation loss: 2.1833769610843863
Epoch: 9| Step: 13
Training loss: 2.514808854106584
Validation loss: 2.168348652552606
Epoch: 9| Step: 14
Training loss: 1.4972364080948786
Validation loss: 2.2039858972989395
Epoch: 9| Step: 15
Training loss: 2.9995962507038056
Validation loss: 2.1760084148588823
Epoch: 9| Step: 16
Training loss: 2.3771525215513147
Validation loss: 2.1662203978790613
Epoch: 9| Step: 17
Training loss: 2.8749414520936436
Validation loss: 2.1736138673575227
Epoch: 9| Step: 18
Training loss: 2.384674445431359
Validation loss: 2.164178517944527
Epoch: 9| Step: 19
Training loss: 2.3703325485759636
Validation loss: 2.2045646709855937
Epoch: 47| Step: 0
Training loss: 2.8152191580907258
Validation loss: 2.20204439839929
Epoch: 9| Step: 1
Training loss: 2.6491992496367884
Validation loss: 2.2017885403228385
Epoch: 9| Step: 2
Training loss: 3.67038076312105
Validation loss: 2.1669107911232923
Epoch: 9| Step: 3
Training loss: 2.773545298026091
Validation loss: 2.180052484284064
Epoch: 9| Step: 4
Training loss: 1.726919007929651
Validation loss: 2.187484311502767
Epoch: 9| Step: 5
Training loss: 2.589147413722628
Validation loss: 2.1434974038196066
Epoch: 9| Step: 6
Training loss: 2.579896537864968
Validation loss: 2.1574081497247133
Epoch: 9| Step: 7
Training loss: 2.758684490551285
Validation loss: 2.139120543969449
Epoch: 9| Step: 8
Training loss: 2.395269133989574
Validation loss: 2.149554274095305
Epoch: 9| Step: 9
Training loss: 1.6049523184280243
Validation loss: 2.1670065184663527
Epoch: 9| Step: 10
Training loss: 2.165471248480761
Validation loss: 2.2040932699052838
Epoch: 9| Step: 11
Training loss: 2.9860260076495275
Validation loss: 2.1476374151079023
Epoch: 9| Step: 12
Training loss: 2.78712605589678
Validation loss: 2.1737696296608644
Epoch: 9| Step: 13
Training loss: 2.1203607518574707
Validation loss: 2.19430770628767
Epoch: 9| Step: 14
Training loss: 2.823434723523901
Validation loss: 2.1614843865720954
Epoch: 9| Step: 15
Training loss: 2.612473800746837
Validation loss: 2.2008570209944462
Epoch: 9| Step: 16
Training loss: 3.1156932337414456
Validation loss: 2.1953096351108266
Epoch: 9| Step: 17
Training loss: 2.760950998857245
Validation loss: 2.1985302343403945
Epoch: 9| Step: 18
Training loss: 1.7151535553766368
Validation loss: 2.124670974812254
Epoch: 9| Step: 19
Training loss: 2.42476142417607
Validation loss: 2.1999630508295183
Epoch: 48| Step: 0
Training loss: 2.1680072402973964
Validation loss: 2.1662302315257125
Epoch: 9| Step: 1
Training loss: 3.0894304425888484
Validation loss: 2.154797407953306
Epoch: 9| Step: 2
Training loss: 2.924233367092525
Validation loss: 2.188620080759907
Epoch: 9| Step: 3
Training loss: 2.125707396402343
Validation loss: 2.1357484313561046
Epoch: 9| Step: 4
Training loss: 2.4525205997453505
Validation loss: 2.1442214915108986
Epoch: 9| Step: 5
Training loss: 2.301173644614782
Validation loss: 2.1582107425293238
Epoch: 9| Step: 6
Training loss: 3.058045085936378
Validation loss: 2.1730891925772813
Epoch: 9| Step: 7
Training loss: 2.4191525816718182
Validation loss: 2.1594917210552187
Epoch: 9| Step: 8
Training loss: 2.281187814361384
Validation loss: 2.149421191342162
Epoch: 9| Step: 9
Training loss: 3.3020046156556964
Validation loss: 2.1671665918957674
Epoch: 9| Step: 10
Training loss: 3.0032836110031496
Validation loss: 2.1831110900011224
Epoch: 9| Step: 11
Training loss: 2.4250729028813858
Validation loss: 2.1605509377885403
Epoch: 9| Step: 12
Training loss: 2.3175621300921274
Validation loss: 2.171799893305912
Epoch: 9| Step: 13
Training loss: 3.255193229131625
Validation loss: 2.1500204035680697
Epoch: 9| Step: 14
Training loss: 2.684073104135714
Validation loss: 2.1573004235074573
Epoch: 9| Step: 15
Training loss: 2.3050580260281808
Validation loss: 2.1728873223287777
Epoch: 9| Step: 16
Training loss: 2.463621776695026
Validation loss: 2.192788949273294
Epoch: 9| Step: 17
Training loss: 2.2791738599516096
Validation loss: 2.1897389486551093
Epoch: 9| Step: 18
Training loss: 2.7218586479948415
Validation loss: 2.144741952304578
Epoch: 9| Step: 19
Training loss: 2.307239219006279
Validation loss: 2.135715338182426
Epoch: 49| Step: 0
Training loss: 2.5938485368142823
Validation loss: 2.178610768547828
Epoch: 9| Step: 1
Training loss: 2.7941906370307943
Validation loss: 2.1927317743272337
Epoch: 9| Step: 2
Training loss: 2.303023018513647
Validation loss: 2.1765847822659783
Epoch: 9| Step: 3
Training loss: 2.9417178127031822
Validation loss: 2.1765102712588296
Epoch: 9| Step: 4
Training loss: 2.1755313969535948
Validation loss: 2.1602720749238635
Epoch: 9| Step: 5
Training loss: 3.246708303363409
Validation loss: 2.183827324380118
Epoch: 9| Step: 6
Training loss: 2.227426461698107
Validation loss: 2.20373456298831
Epoch: 9| Step: 7
Training loss: 2.223895272307116
Validation loss: 2.206028858022703
Epoch: 9| Step: 8
Training loss: 2.7699122415680915
Validation loss: 2.181290880750813
Epoch: 9| Step: 9
Training loss: 1.897144269606217
Validation loss: 2.2000632071920907
Epoch: 9| Step: 10
Training loss: 2.4998281419811477
Validation loss: 2.20609949940329
Epoch: 9| Step: 11
Training loss: 3.12352992765947
Validation loss: 2.160768506279982
Epoch: 9| Step: 12
Training loss: 2.8012627649250468
Validation loss: 2.1670350913428433
Epoch: 9| Step: 13
Training loss: 2.4255878168650624
Validation loss: 2.1873250651669984
Epoch: 9| Step: 14
Training loss: 2.500450856562469
Validation loss: 2.159752730252143
Epoch: 9| Step: 15
Training loss: 2.5445837468139185
Validation loss: 2.140591388367733
Epoch: 9| Step: 16
Training loss: 2.342602461586213
Validation loss: 2.134015808357569
Epoch: 9| Step: 17
Training loss: 2.9149436947863014
Validation loss: 2.178084256853229
Epoch: 9| Step: 18
Training loss: 2.5149209121190803
Validation loss: 2.1628791049005693
Epoch: 9| Step: 19
Training loss: 2.9092718022090027
Validation loss: 2.162204088813137
Epoch: 50| Step: 0
Training loss: 2.2980240004492174
Validation loss: 2.1610158646712563
Epoch: 9| Step: 1
Training loss: 2.572705485419867
Validation loss: 2.149668067267113
Epoch: 9| Step: 2
Training loss: 3.064934055185246
Validation loss: 2.127742387721695
Epoch: 9| Step: 3
Training loss: 2.918568581409745
Validation loss: 2.1602322517595516
Epoch: 9| Step: 4
Training loss: 2.6318401046465154
Validation loss: 2.1387262555235713
Epoch: 9| Step: 5
Training loss: 2.6575438994462783
Validation loss: 2.12345209285033
Epoch: 9| Step: 6
Training loss: 2.5535211262812183
Validation loss: 2.185992751760552
Epoch: 9| Step: 7
Training loss: 2.290527499883415
Validation loss: 2.152639807532066
Epoch: 9| Step: 8
Training loss: 2.7434758042814917
Validation loss: 2.1695048344220296
Epoch: 9| Step: 9
Training loss: 2.167776508227733
Validation loss: 2.096609295641379
Epoch: 9| Step: 10
Training loss: 1.831546027827524
Validation loss: 2.163965863737639
Epoch: 9| Step: 11
Training loss: 2.3138726774118212
Validation loss: 2.203725526765555
Epoch: 9| Step: 12
Training loss: 3.494801611774846
Validation loss: 2.1765190892170625
Epoch: 9| Step: 13
Training loss: 2.750632300077917
Validation loss: 2.1825745557630305
Epoch: 9| Step: 14
Training loss: 2.8190086499826066
Validation loss: 2.1823246449842744
Epoch: 9| Step: 15
Training loss: 2.292358733206158
Validation loss: 2.155629869205618
Epoch: 9| Step: 16
Training loss: 3.1078502808082504
Validation loss: 2.1886013674808154
Epoch: 9| Step: 17
Training loss: 1.9269322791480896
Validation loss: 2.169035175687037
Epoch: 9| Step: 18
Training loss: 2.9155168355849193
Validation loss: 2.185378352336835
Epoch: 9| Step: 19
Training loss: 2.1592854681375866
Validation loss: 2.1979263589627007
Epoch: 51| Step: 0
Training loss: 3.254014396931054
Validation loss: 2.200708547872641
Epoch: 9| Step: 1
Training loss: 2.3465227129341137
Validation loss: 2.203909745193803
Epoch: 9| Step: 2
Training loss: 2.6265250725833895
Validation loss: 2.1802710104632763
Epoch: 9| Step: 3
Training loss: 2.4295604218739606
Validation loss: 2.1625485704991014
Epoch: 9| Step: 4
Training loss: 2.3613828490221067
Validation loss: 2.188546513601729
Epoch: 9| Step: 5
Training loss: 2.366946368636077
Validation loss: 2.1721312998944238
Epoch: 9| Step: 6
Training loss: 2.491049288384199
Validation loss: 2.1159844547273083
Epoch: 9| Step: 7
Training loss: 3.018363065385346
Validation loss: 2.175912756506522
Epoch: 9| Step: 8
Training loss: 1.940759685468111
Validation loss: 2.167008298225815
Epoch: 9| Step: 9
Training loss: 3.0216890548098294
Validation loss: 2.195650036264595
Epoch: 9| Step: 10
Training loss: 2.3580520659854898
Validation loss: 2.1846221736726696
Epoch: 9| Step: 11
Training loss: 2.961340723286419
Validation loss: 2.182556464798315
Epoch: 9| Step: 12
Training loss: 2.6289897752391065
Validation loss: 2.190932853576997
Epoch: 9| Step: 13
Training loss: 2.446740851494608
Validation loss: 2.1793842987741243
Epoch: 9| Step: 14
Training loss: 2.611622282363923
Validation loss: 2.1544299271182834
Epoch: 9| Step: 15
Training loss: 2.9383845519306035
Validation loss: 2.1787749351243884
Epoch: 9| Step: 16
Training loss: 2.2801435739921243
Validation loss: 2.1785982670262904
Epoch: 9| Step: 17
Training loss: 2.7795334565835126
Validation loss: 2.198493627410994
Epoch: 9| Step: 18
Training loss: 2.4946443412035957
Validation loss: 2.132246434251419
Epoch: 9| Step: 19
Training loss: 2.5692524216757335
Validation loss: 2.1524027636206307
Epoch: 52| Step: 0
Training loss: 3.1622119154158606
Validation loss: 2.147202141068467
Epoch: 9| Step: 1
Training loss: 1.9707573239573768
Validation loss: 2.174574757630591
Epoch: 9| Step: 2
Training loss: 2.222169417177758
Validation loss: 2.15362645752525
Epoch: 9| Step: 3
Training loss: 2.869387746494692
Validation loss: 2.158844563393995
Epoch: 9| Step: 4
Training loss: 1.9758193839342446
Validation loss: 2.146648390825478
Epoch: 9| Step: 5
Training loss: 2.727863689898919
Validation loss: 2.1693688449980217
Epoch: 9| Step: 6
Training loss: 2.9209856117884083
Validation loss: 2.1521116785810444
Epoch: 9| Step: 7
Training loss: 3.202328466605546
Validation loss: 2.1855660963775727
Epoch: 9| Step: 8
Training loss: 2.6436315270971504
Validation loss: 2.1584196189276503
Epoch: 9| Step: 9
Training loss: 2.3510258971702203
Validation loss: 2.1632434178810103
Epoch: 9| Step: 10
Training loss: 2.364229677167628
Validation loss: 2.1529501922734138
Epoch: 9| Step: 11
Training loss: 2.431266639476017
Validation loss: 2.201741322455862
Epoch: 9| Step: 12
Training loss: 2.6459730717160252
Validation loss: 2.183727676012565
Epoch: 9| Step: 13
Training loss: 3.04995493621054
Validation loss: 2.1570915161302864
Epoch: 9| Step: 14
Training loss: 1.6752578878440452
Validation loss: 2.13688629269856
Epoch: 9| Step: 15
Training loss: 3.4068422415093886
Validation loss: 2.1380848983363325
Epoch: 9| Step: 16
Training loss: 2.5832847057400863
Validation loss: 2.173232378495243
Epoch: 9| Step: 17
Training loss: 2.1702077490160154
Validation loss: 2.173490777891098
Epoch: 9| Step: 18
Training loss: 2.803418395679266
Validation loss: 2.1859093312864135
Epoch: 9| Step: 19
Training loss: 2.184978885155795
Validation loss: 2.172485923603832
Epoch: 53| Step: 0
Training loss: 2.8403225879404004
Validation loss: 2.166851355179612
Epoch: 9| Step: 1
Training loss: 2.93629788089719
Validation loss: 2.157738786187474
Epoch: 9| Step: 2
Training loss: 2.9026315785105083
Validation loss: 2.154824411513052
Epoch: 9| Step: 3
Training loss: 2.360278430290302
Validation loss: 2.1561540087532136
Epoch: 9| Step: 4
Training loss: 2.0540155392572506
Validation loss: 2.162269985873658
Epoch: 9| Step: 5
Training loss: 3.108355024192201
Validation loss: 2.1900543011322817
Epoch: 9| Step: 6
Training loss: 2.9027125662049964
Validation loss: 2.176153211709284
Epoch: 9| Step: 7
Training loss: 3.0608201382673963
Validation loss: 2.169170589976975
Epoch: 9| Step: 8
Training loss: 1.8105958604821555
Validation loss: 2.1593009811667274
Epoch: 9| Step: 9
Training loss: 2.726346682338804
Validation loss: 2.1547990307027884
Epoch: 9| Step: 10
Training loss: 2.1267170420373485
Validation loss: 2.138112685747662
Epoch: 9| Step: 11
Training loss: 2.6031676143533224
Validation loss: 2.173499529078987
Epoch: 9| Step: 12
Training loss: 2.1080940030327295
Validation loss: 2.153189623590679
Epoch: 9| Step: 13
Training loss: 2.795239700384384
Validation loss: 2.1448075826705955
Epoch: 9| Step: 14
Training loss: 2.8228035278920984
Validation loss: 2.1456640631683603
Epoch: 9| Step: 15
Training loss: 2.406756657355922
Validation loss: 2.1678184477626665
Epoch: 9| Step: 16
Training loss: 2.431075800364756
Validation loss: 2.1195409111182957
Epoch: 9| Step: 17
Training loss: 2.5655863713691414
Validation loss: 2.129512171109708
Epoch: 9| Step: 18
Training loss: 2.6239467506006657
Validation loss: 2.1791372564653275
Epoch: 9| Step: 19
Training loss: 2.498690262080891
Validation loss: 2.130818879401304
Epoch: 54| Step: 0
Training loss: 2.352020725963385
Validation loss: 2.1213301090065357
Epoch: 9| Step: 1
Training loss: 2.390662099512989
Validation loss: 2.1598471209144394
Epoch: 9| Step: 2
Training loss: 2.153550711348892
Validation loss: 2.182207668017288
Epoch: 9| Step: 3
Training loss: 3.088996703586073
Validation loss: 2.153379903668431
Epoch: 9| Step: 4
Training loss: 2.5965785035170335
Validation loss: 2.1335621289591375
Epoch: 9| Step: 5
Training loss: 3.030189092545954
Validation loss: 2.128255567081709
Epoch: 9| Step: 6
Training loss: 2.293123464222537
Validation loss: 2.151488683925144
Epoch: 9| Step: 7
Training loss: 2.339077271521233
Validation loss: 2.1477484164150913
Epoch: 9| Step: 8
Training loss: 2.2026077637305166
Validation loss: 2.147412379716819
Epoch: 9| Step: 9
Training loss: 2.2786717934719123
Validation loss: 2.147808801510479
Epoch: 9| Step: 10
Training loss: 2.6386627490763264
Validation loss: 2.154255248718655
Epoch: 9| Step: 11
Training loss: 2.4292400966252803
Validation loss: 2.1641433012363622
Epoch: 9| Step: 12
Training loss: 3.054939435243018
Validation loss: 2.108472181006804
Epoch: 9| Step: 13
Training loss: 2.2991321916842598
Validation loss: 2.1170791779592606
Epoch: 9| Step: 14
Training loss: 2.8080835210545754
Validation loss: 2.1705322165697947
Epoch: 9| Step: 15
Training loss: 2.6272997999641383
Validation loss: 2.162948698832988
Epoch: 9| Step: 16
Training loss: 3.0628730391026835
Validation loss: 2.155024244894824
Epoch: 9| Step: 17
Training loss: 2.9894452389890107
Validation loss: 2.159635321009874
Epoch: 9| Step: 18
Training loss: 2.259109388596483
Validation loss: 2.1735779972722478
Epoch: 9| Step: 19
Training loss: 2.6234575008427385
Validation loss: 2.1772112122903224
Epoch: 55| Step: 0
Training loss: 2.463808062762905
Validation loss: 2.190010097405344
Epoch: 9| Step: 1
Training loss: 2.823971728315753
Validation loss: 2.1669919578362795
Epoch: 9| Step: 2
Training loss: 2.358164697915028
Validation loss: 2.1877737925191294
Epoch: 9| Step: 3
Training loss: 2.530451330706195
Validation loss: 2.1529190935807883
Epoch: 9| Step: 4
Training loss: 2.938819751114555
Validation loss: 2.184359426162818
Epoch: 9| Step: 5
Training loss: 2.1692302161204062
Validation loss: 2.1725126805234867
Epoch: 9| Step: 6
Training loss: 1.9946092434197598
Validation loss: 2.181891966611532
Epoch: 9| Step: 7
Training loss: 2.49059586836986
Validation loss: 2.177521969171326
Epoch: 9| Step: 8
Training loss: 2.543352933069038
Validation loss: 2.181224665654015
Epoch: 9| Step: 9
Training loss: 3.12351557761421
Validation loss: 2.1435371335519093
Epoch: 9| Step: 10
Training loss: 3.0359551790972317
Validation loss: 2.1825779216240653
Epoch: 9| Step: 11
Training loss: 2.446574997323666
Validation loss: 2.187325821011673
Epoch: 9| Step: 12
Training loss: 2.414099041807271
Validation loss: 2.115248279078912
Epoch: 9| Step: 13
Training loss: 3.0426421669662655
Validation loss: 2.1533914751225356
Epoch: 9| Step: 14
Training loss: 2.203876123827573
Validation loss: 2.1430985050872224
Epoch: 9| Step: 15
Training loss: 2.4289285633611923
Validation loss: 2.1883872980036654
Epoch: 9| Step: 16
Training loss: 2.1042696735613107
Validation loss: 2.155642962546477
Epoch: 9| Step: 17
Training loss: 2.705236062627625
Validation loss: 2.155085417144451
Epoch: 9| Step: 18
Training loss: 3.3239898064889695
Validation loss: 2.1397100514921616
Epoch: 9| Step: 19
Training loss: 2.1621212842659814
Validation loss: 2.1332951532496875
Epoch: 56| Step: 0
Training loss: 2.4517843871787295
Validation loss: 2.1282684424203104
Epoch: 9| Step: 1
Training loss: 2.2501800253161495
Validation loss: 2.1232999775393417
Epoch: 9| Step: 2
Training loss: 2.5245957683637466
Validation loss: 2.1516728128021074
Epoch: 9| Step: 3
Training loss: 3.379136270620764
Validation loss: 2.1663758605669523
Epoch: 9| Step: 4
Training loss: 2.9003240404288873
Validation loss: 2.134541006949296
Epoch: 9| Step: 5
Training loss: 3.038635380794641
Validation loss: 2.15649697341366
Epoch: 9| Step: 6
Training loss: 3.233948610368129
Validation loss: 2.139669558891279
Epoch: 9| Step: 7
Training loss: 2.393112185292717
Validation loss: 2.159956454653675
Epoch: 9| Step: 8
Training loss: 2.4251379858656046
Validation loss: 2.1611565830521644
Epoch: 9| Step: 9
Training loss: 2.6474973196965266
Validation loss: 2.1960894541282827
Epoch: 9| Step: 10
Training loss: 2.9193660959880976
Validation loss: 2.1266194008087393
Epoch: 9| Step: 11
Training loss: 3.3466222672981165
Validation loss: 2.1344087084799392
Epoch: 9| Step: 12
Training loss: 2.363030235894571
Validation loss: 2.1481250113420667
Epoch: 9| Step: 13
Training loss: 2.169334407636536
Validation loss: 2.1354062101049505
Epoch: 9| Step: 14
Training loss: 2.078340676954195
Validation loss: 2.127895093270753
Epoch: 9| Step: 15
Training loss: 2.62820248302496
Validation loss: 2.1348935877055055
Epoch: 9| Step: 16
Training loss: 1.9765456127304781
Validation loss: 2.1409217020794644
Epoch: 9| Step: 17
Training loss: 2.578077743559561
Validation loss: 2.116998848635307
Epoch: 9| Step: 18
Training loss: 2.1648412742311494
Validation loss: 2.0885071184645
Epoch: 9| Step: 19
Training loss: 2.1687086337758954
Validation loss: 2.159515059595574
Epoch: 57| Step: 0
Training loss: 3.325047605933797
Validation loss: 2.146275692991019
Epoch: 9| Step: 1
Training loss: 2.2597730104000964
Validation loss: 2.1607579410832076
Epoch: 9| Step: 2
Training loss: 2.7412392914124086
Validation loss: 2.1359391206104825
Epoch: 9| Step: 3
Training loss: 2.5847278543208567
Validation loss: 2.1483266683597995
Epoch: 9| Step: 4
Training loss: 2.264328052645813
Validation loss: 2.149444718135804
Epoch: 9| Step: 5
Training loss: 2.536344229281183
Validation loss: 2.1344452217427654
Epoch: 9| Step: 6
Training loss: 2.17042591960319
Validation loss: 2.1622922870603403
Epoch: 9| Step: 7
Training loss: 2.45694042335106
Validation loss: 2.160365607228809
Epoch: 9| Step: 8
Training loss: 2.567386527075099
Validation loss: 2.1779986144213415
Epoch: 9| Step: 9
Training loss: 2.198423523034927
Validation loss: 2.1381447044062316
Epoch: 9| Step: 10
Training loss: 2.7778064970015346
Validation loss: 2.164201164040592
Epoch: 9| Step: 11
Training loss: 2.8375646373764005
Validation loss: 2.1382587157794277
Epoch: 9| Step: 12
Training loss: 2.7757769966039216
Validation loss: 2.16457991789356
Epoch: 9| Step: 13
Training loss: 2.071103732942274
Validation loss: 2.1525113443863013
Epoch: 9| Step: 14
Training loss: 1.5876095230889535
Validation loss: 2.1830805962239324
Epoch: 9| Step: 15
Training loss: 2.7301673122459813
Validation loss: 2.1794989849680646
Epoch: 9| Step: 16
Training loss: 2.812404291855705
Validation loss: 2.1857438339537345
Epoch: 9| Step: 17
Training loss: 3.0292321794046626
Validation loss: 2.1866676995985332
Epoch: 9| Step: 18
Training loss: 2.2404059267085206
Validation loss: 2.1618534849993845
Epoch: 9| Step: 19
Training loss: 3.0432492323999574
Validation loss: 2.2164834075442315
Epoch: 58| Step: 0
Training loss: 2.158550527928942
Validation loss: 2.1415737290771895
Epoch: 9| Step: 1
Training loss: 2.8104533059965195
Validation loss: 2.1265904803414464
Epoch: 9| Step: 2
Training loss: 2.409138122868042
Validation loss: 2.1829565714479373
Epoch: 9| Step: 3
Training loss: 2.778941535886548
Validation loss: 2.154107252730729
Epoch: 9| Step: 4
Training loss: 3.19591980924491
Validation loss: 2.136712873704095
Epoch: 9| Step: 5
Training loss: 2.621418371436862
Validation loss: 2.1762859861942574
Epoch: 9| Step: 6
Training loss: 1.8067799777337177
Validation loss: 2.169497656570748
Epoch: 9| Step: 7
Training loss: 2.335391896298275
Validation loss: 2.150944815346315
Epoch: 9| Step: 8
Training loss: 2.4175352530685257
Validation loss: 2.1451642824685773
Epoch: 9| Step: 9
Training loss: 2.08614345491036
Validation loss: 2.18828676966598
Epoch: 9| Step: 10
Training loss: 2.3253805894985975
Validation loss: 2.176765408300007
Epoch: 9| Step: 11
Training loss: 2.8747366079669887
Validation loss: 2.1518620240828037
Epoch: 9| Step: 12
Training loss: 2.6857267340339717
Validation loss: 2.2099485994405392
Epoch: 9| Step: 13
Training loss: 3.589296982130029
Validation loss: 2.1898688217208666
Epoch: 9| Step: 14
Training loss: 2.439293812664722
Validation loss: 2.18303165640202
Epoch: 9| Step: 15
Training loss: 2.189471092456662
Validation loss: 2.2035230776733465
Epoch: 9| Step: 16
Training loss: 2.3150752394377623
Validation loss: 2.1354517753460045
Epoch: 9| Step: 17
Training loss: 2.459868474406092
Validation loss: 2.222702974473878
Epoch: 9| Step: 18
Training loss: 2.6984264132786056
Validation loss: 2.1811574259258086
Epoch: 9| Step: 19
Training loss: 3.1493379048446997
Validation loss: 2.1984939102041685
Epoch: 59| Step: 0
Training loss: 2.700034430955414
Validation loss: 2.198243690664242
Epoch: 9| Step: 1
Training loss: 2.1597354748132913
Validation loss: 2.1967067576785935
Epoch: 9| Step: 2
Training loss: 2.865344544043369
Validation loss: 2.1561603981680797
Epoch: 9| Step: 3
Training loss: 2.7011453071440634
Validation loss: 2.144140438706117
Epoch: 9| Step: 4
Training loss: 1.8389821231879626
Validation loss: 2.1890785697872053
Epoch: 9| Step: 5
Training loss: 2.345419632347384
Validation loss: 2.1874642864934972
Epoch: 9| Step: 6
Training loss: 2.9354994434375006
Validation loss: 2.164521312373849
Epoch: 9| Step: 7
Training loss: 3.231622086431097
Validation loss: 2.1724354203658147
Epoch: 9| Step: 8
Training loss: 2.2878741932806936
Validation loss: 2.1748001143240523
Epoch: 9| Step: 9
Training loss: 2.1518108725984972
Validation loss: 2.1766282261474177
Epoch: 9| Step: 10
Training loss: 2.4493869559465153
Validation loss: 2.1764236619497384
Epoch: 9| Step: 11
Training loss: 2.768975076934527
Validation loss: 2.126073282803703
Epoch: 9| Step: 12
Training loss: 2.3859200647462786
Validation loss: 2.179377232476774
Epoch: 9| Step: 13
Training loss: 2.3573819262162474
Validation loss: 2.1471426752898353
Epoch: 9| Step: 14
Training loss: 2.4467162956519277
Validation loss: 2.169605246986351
Epoch: 9| Step: 15
Training loss: 3.2345788863783476
Validation loss: 2.160531064336252
Epoch: 9| Step: 16
Training loss: 2.7873950750335497
Validation loss: 2.1302741455516525
Epoch: 9| Step: 17
Training loss: 2.7753554898319215
Validation loss: 2.1393464467298324
Epoch: 9| Step: 18
Training loss: 2.5623552234968976
Validation loss: 2.1681505290401386
Epoch: 9| Step: 19
Training loss: 2.529014825007442
Validation loss: 2.14913906629577
Epoch: 60| Step: 0
Training loss: 3.2282219930370535
Validation loss: 2.172049553153025
Epoch: 9| Step: 1
Training loss: 1.9604654541863535
Validation loss: 2.1305420417701737
Epoch: 9| Step: 2
Training loss: 2.711069153329011
Validation loss: 2.1964041650577357
Epoch: 9| Step: 3
Training loss: 2.22771694304288
Validation loss: 2.1698416829934795
Epoch: 9| Step: 4
Training loss: 3.47589434085834
Validation loss: 2.0987146117648505
Epoch: 9| Step: 5
Training loss: 2.3397915791345736
Validation loss: 2.136526990992875
Epoch: 9| Step: 6
Training loss: 2.9062493437079233
Validation loss: 2.147137321766833
Epoch: 9| Step: 7
Training loss: 2.1149711691692716
Validation loss: 2.1514135448081504
Epoch: 9| Step: 8
Training loss: 2.232493642219128
Validation loss: 2.1423834082288127
Epoch: 9| Step: 9
Training loss: 2.660381201196767
Validation loss: 2.1371897482918962
Epoch: 9| Step: 10
Training loss: 2.9399188208239133
Validation loss: 2.112131316452179
Epoch: 9| Step: 11
Training loss: 2.5027530770089044
Validation loss: 2.1667152529750537
Epoch: 9| Step: 12
Training loss: 2.5720435345704367
Validation loss: 2.1645432686210886
Epoch: 9| Step: 13
Training loss: 2.437036225630009
Validation loss: 2.1718736717209763
Epoch: 9| Step: 14
Training loss: 2.621207995135023
Validation loss: 2.114655120038135
Epoch: 9| Step: 15
Training loss: 3.275169624420327
Validation loss: 2.140924131627545
Epoch: 9| Step: 16
Training loss: 2.47667850258807
Validation loss: 2.121864473899029
Epoch: 9| Step: 17
Training loss: 2.1158086925192086
Validation loss: 2.1284495954810345
Epoch: 9| Step: 18
Training loss: 2.294640109032453
Validation loss: 2.1119962113681985
Epoch: 9| Step: 19
Training loss: 2.3611651570236836
Validation loss: 2.184321322474734
Epoch: 61| Step: 0
Training loss: 2.8381162738812913
Validation loss: 2.1365381621674224
Epoch: 9| Step: 1
Training loss: 2.0458295642121422
Validation loss: 2.154197262135536
Epoch: 9| Step: 2
Training loss: 3.1434142219704726
Validation loss: 2.1815055355044857
Epoch: 9| Step: 3
Training loss: 2.9160864298273372
Validation loss: 2.1383639574750513
Epoch: 9| Step: 4
Training loss: 2.7380954390973953
Validation loss: 2.137857496135663
Epoch: 9| Step: 5
Training loss: 2.641878722030079
Validation loss: 2.099927668443429
Epoch: 9| Step: 6
Training loss: 2.61893061194859
Validation loss: 2.142693522955393
Epoch: 9| Step: 7
Training loss: 2.1572561818926292
Validation loss: 2.135588631895641
Epoch: 9| Step: 8
Training loss: 2.073615667166804
Validation loss: 2.1511481279979283
Epoch: 9| Step: 9
Training loss: 2.6523575929890044
Validation loss: 2.1227585828773385
Epoch: 9| Step: 10
Training loss: 1.494254552948174
Validation loss: 2.1702001047676123
Epoch: 9| Step: 11
Training loss: 2.8099884687302494
Validation loss: 2.160226920007351
Epoch: 9| Step: 12
Training loss: 2.1495364066370803
Validation loss: 2.1160774904150794
Epoch: 9| Step: 13
Training loss: 2.9085867726715935
Validation loss: 2.1639908805948505
Epoch: 9| Step: 14
Training loss: 2.5566306467349684
Validation loss: 2.1540277230167684
Epoch: 9| Step: 15
Training loss: 2.3701997733924864
Validation loss: 2.1332039486448107
Epoch: 9| Step: 16
Training loss: 2.4070843327657605
Validation loss: 2.137838651527207
Epoch: 9| Step: 17
Training loss: 2.3456522025267312
Validation loss: 2.1419298139907674
Epoch: 9| Step: 18
Training loss: 3.1453174058522504
Validation loss: 2.1290861120172453
Epoch: 9| Step: 19
Training loss: 3.0078944603788598
Validation loss: 2.1540970616755684
Epoch: 62| Step: 0
Training loss: 2.5069326598318105
Validation loss: 2.1559644944481473
Epoch: 9| Step: 1
Training loss: 2.8672335670366818
Validation loss: 2.1604994650713882
Epoch: 9| Step: 2
Training loss: 3.024524266689709
Validation loss: 2.130554585824057
Epoch: 9| Step: 3
Training loss: 3.598271585499785
Validation loss: 2.1342393525622705
Epoch: 9| Step: 4
Training loss: 2.3489521531209117
Validation loss: 2.12865522542593
Epoch: 9| Step: 5
Training loss: 2.5289242267411627
Validation loss: 2.159971594667713
Epoch: 9| Step: 6
Training loss: 2.45055765306065
Validation loss: 2.1494804031019576
Epoch: 9| Step: 7
Training loss: 3.2784443804252636
Validation loss: 2.160049568569639
Epoch: 9| Step: 8
Training loss: 2.8141117987585114
Validation loss: 2.125399614041467
Epoch: 9| Step: 9
Training loss: 1.7691019981784846
Validation loss: 2.1457625529507216
Epoch: 9| Step: 10
Training loss: 2.127013542781413
Validation loss: 2.137179403041777
Epoch: 9| Step: 11
Training loss: 2.7827547267633435
Validation loss: 2.1439930824426447
Epoch: 9| Step: 12
Training loss: 2.474598102498743
Validation loss: 2.1976192201277103
Epoch: 9| Step: 13
Training loss: 2.2381841029310525
Validation loss: 2.1505643213188637
Epoch: 9| Step: 14
Training loss: 2.2101538249892805
Validation loss: 2.1564489760332437
Epoch: 9| Step: 15
Training loss: 2.314190942263546
Validation loss: 2.1709906076742334
Epoch: 9| Step: 16
Training loss: 1.8415369232643948
Validation loss: 2.1788495167557045
Epoch: 9| Step: 17
Training loss: 2.536691162786453
Validation loss: 2.160484882051647
Epoch: 9| Step: 18
Training loss: 2.9873287902039256
Validation loss: 2.14905440708643
Epoch: 9| Step: 19
Training loss: 2.478624610518782
Validation loss: 2.161140486140629
Epoch: 63| Step: 0
Training loss: 2.08488980960349
Validation loss: 2.1919422325299647
Epoch: 9| Step: 1
Training loss: 2.7450839230297346
Validation loss: 2.151873408585644
Epoch: 9| Step: 2
Training loss: 2.012132442862758
Validation loss: 2.154193671548201
Epoch: 9| Step: 3
Training loss: 2.5205918083398626
Validation loss: 2.158201134789554
Epoch: 9| Step: 4
Training loss: 2.6233088177218495
Validation loss: 2.156717815114587
Epoch: 9| Step: 5
Training loss: 2.427417148233003
Validation loss: 2.1905526393323274
Epoch: 9| Step: 6
Training loss: 2.834168441967818
Validation loss: 2.1416338283692866
Epoch: 9| Step: 7
Training loss: 3.1208349318727304
Validation loss: 2.158845055288619
Epoch: 9| Step: 8
Training loss: 2.2540602606610602
Validation loss: 2.157176575738782
Epoch: 9| Step: 9
Training loss: 2.661244263721195
Validation loss: 2.122326490711221
Epoch: 9| Step: 10
Training loss: 2.769875229321845
Validation loss: 2.176488635679378
Epoch: 9| Step: 11
Training loss: 2.7457494831933933
Validation loss: 2.152373472899152
Epoch: 9| Step: 12
Training loss: 2.3748662810577934
Validation loss: 2.127809070937644
Epoch: 9| Step: 13
Training loss: 1.918425340553346
Validation loss: 2.1037837429792297
Epoch: 9| Step: 14
Training loss: 3.000696419309106
Validation loss: 2.1184568690260233
Epoch: 9| Step: 15
Training loss: 2.8965360671592704
Validation loss: 2.146294832338721
Epoch: 9| Step: 16
Training loss: 2.852882894750015
Validation loss: 2.136712593860698
Epoch: 9| Step: 17
Training loss: 2.280060131217011
Validation loss: 2.122986982597461
Epoch: 9| Step: 18
Training loss: 2.6884774493165082
Validation loss: 2.148993956179359
Epoch: 9| Step: 19
Training loss: 2.5916468354802387
Validation loss: 2.17777052850533
Epoch: 64| Step: 0
Training loss: 2.7455288345303885
Validation loss: 2.1258545238844273
Epoch: 9| Step: 1
Training loss: 2.0949099160357543
Validation loss: 2.142648222099909
Epoch: 9| Step: 2
Training loss: 2.682962534935437
Validation loss: 2.1489432378516504
Epoch: 9| Step: 3
Training loss: 2.7657027583855966
Validation loss: 2.1448755296290263
Epoch: 9| Step: 4
Training loss: 3.104683408460911
Validation loss: 2.11585116293048
Epoch: 9| Step: 5
Training loss: 2.8399135995536358
Validation loss: 2.147277354390688
Epoch: 9| Step: 6
Training loss: 2.3092118676656903
Validation loss: 2.1563206955055967
Epoch: 9| Step: 7
Training loss: 2.5273093172584393
Validation loss: 2.163486682786726
Epoch: 9| Step: 8
Training loss: 2.690368186400061
Validation loss: 2.177466030380053
Epoch: 9| Step: 9
Training loss: 2.209949501807023
Validation loss: 2.1355392584026025
Epoch: 9| Step: 10
Training loss: 2.4154099342770468
Validation loss: 2.139083536083081
Epoch: 9| Step: 11
Training loss: 1.9597738392418045
Validation loss: 2.1092533904214656
Epoch: 9| Step: 12
Training loss: 3.348647479417063
Validation loss: 2.121675708432734
Epoch: 9| Step: 13
Training loss: 2.6999772989237094
Validation loss: 2.184479989510929
Epoch: 9| Step: 14
Training loss: 2.8869513184394124
Validation loss: 2.162128166928264
Epoch: 9| Step: 15
Training loss: 2.7268096024870037
Validation loss: 2.133891988398037
Epoch: 9| Step: 16
Training loss: 2.320550257770844
Validation loss: 2.1802621996266005
Epoch: 9| Step: 17
Training loss: 2.1495432834353583
Validation loss: 2.1532595079570602
Epoch: 9| Step: 18
Training loss: 2.5663664885856328
Validation loss: 2.165944336368714
Epoch: 9| Step: 19
Training loss: 2.196191794894831
Validation loss: 2.1788313491242266
Epoch: 65| Step: 0
Training loss: 2.3901794616805048
Validation loss: 2.187340331883453
Epoch: 9| Step: 1
Training loss: 2.7641152609215087
Validation loss: 2.1107738942741774
Epoch: 9| Step: 2
Training loss: 2.21033526194893
Validation loss: 2.1662148579187472
Epoch: 9| Step: 3
Training loss: 3.169891188044626
Validation loss: 2.1393797103527836
Epoch: 9| Step: 4
Training loss: 2.903918736153628
Validation loss: 2.1538863265639523
Epoch: 9| Step: 5
Training loss: 3.0008370503285433
Validation loss: 2.1382921405358672
Epoch: 9| Step: 6
Training loss: 2.364216869934113
Validation loss: 2.147981023984925
Epoch: 9| Step: 7
Training loss: 2.6591131599165183
Validation loss: 2.15209024965326
Epoch: 9| Step: 8
Training loss: 2.8152227150336966
Validation loss: 2.140980536772111
Epoch: 9| Step: 9
Training loss: 2.2197304292201254
Validation loss: 2.149871659101001
Epoch: 9| Step: 10
Training loss: 2.773395978589938
Validation loss: 2.1692675924935223
Epoch: 9| Step: 11
Training loss: 2.8927436281568726
Validation loss: 2.1649561686113556
Epoch: 9| Step: 12
Training loss: 2.1338806831016477
Validation loss: 2.1510612406169463
Epoch: 9| Step: 13
Training loss: 2.8569716061632207
Validation loss: 2.1484025743463273
Epoch: 9| Step: 14
Training loss: 2.3751999620282795
Validation loss: 2.1178562593115466
Epoch: 9| Step: 15
Training loss: 2.74527898777768
Validation loss: 2.160613422261789
Epoch: 9| Step: 16
Training loss: 2.3642110209382494
Validation loss: 2.131446848151233
Epoch: 9| Step: 17
Training loss: 2.304900389068437
Validation loss: 2.179222915825854
Epoch: 9| Step: 18
Training loss: 2.5621156171608384
Validation loss: 2.149594006177798
Epoch: 9| Step: 19
Training loss: 2.001889766527893
Validation loss: 2.120053977472808
Epoch: 66| Step: 0
Training loss: 2.407351155180853
Validation loss: 2.158499113874913
Epoch: 9| Step: 1
Training loss: 1.8690850101117429
Validation loss: 2.1472063857841035
Epoch: 9| Step: 2
Training loss: 2.9836963461121884
Validation loss: 2.154035456994761
Epoch: 9| Step: 3
Training loss: 3.044727057390187
Validation loss: 2.133166305583588
Epoch: 9| Step: 4
Training loss: 2.307006910217016
Validation loss: 2.1030819157784815
Epoch: 9| Step: 5
Training loss: 1.964767363563171
Validation loss: 2.137714207151612
Epoch: 9| Step: 6
Training loss: 2.8482558217075784
Validation loss: 2.116796118082409
Epoch: 9| Step: 7
Training loss: 2.8444652286737115
Validation loss: 2.151592228767381
Epoch: 9| Step: 8
Training loss: 1.8362995196599383
Validation loss: 2.159864390802421
Epoch: 9| Step: 9
Training loss: 2.3052238228253525
Validation loss: 2.1583414545969393
Epoch: 9| Step: 10
Training loss: 2.6165100131755374
Validation loss: 2.1689914381479585
Epoch: 9| Step: 11
Training loss: 2.5980048153710027
Validation loss: 2.1508361707780437
Epoch: 9| Step: 12
Training loss: 3.082730792858071
Validation loss: 2.146694351118879
Epoch: 9| Step: 13
Training loss: 2.9353090597283016
Validation loss: 2.1057362801306008
Epoch: 9| Step: 14
Training loss: 2.5304432277917535
Validation loss: 2.139070862074656
Epoch: 9| Step: 15
Training loss: 3.0102473720655967
Validation loss: 2.1569617893059454
Epoch: 9| Step: 16
Training loss: 1.971961898218965
Validation loss: 2.1626014511141762
Epoch: 9| Step: 17
Training loss: 2.449349577845553
Validation loss: 2.1621169484990586
Epoch: 9| Step: 18
Training loss: 2.314300866893162
Validation loss: 2.1449177688982624
Epoch: 9| Step: 19
Training loss: 3.205949087318149
Validation loss: 2.1460517352450377
Epoch: 67| Step: 0
Training loss: 2.3979573219580304
Validation loss: 2.119678356669073
Epoch: 9| Step: 1
Training loss: 2.9692854548983494
Validation loss: 2.134926941507835
Epoch: 9| Step: 2
Training loss: 2.7390639727817545
Validation loss: 2.148248882884763
Epoch: 9| Step: 3
Training loss: 2.5882984459026854
Validation loss: 2.156628997188482
Epoch: 9| Step: 4
Training loss: 2.693861507223205
Validation loss: 2.1310002383448405
Epoch: 9| Step: 5
Training loss: 2.8443559273549948
Validation loss: 2.1420014967741876
Epoch: 9| Step: 6
Training loss: 2.222295265851662
Validation loss: 2.138391072574905
Epoch: 9| Step: 7
Training loss: 2.6197551828401022
Validation loss: 2.1001332204030505
Epoch: 9| Step: 8
Training loss: 2.2499670450128373
Validation loss: 2.1698013662324063
Epoch: 9| Step: 9
Training loss: 2.4054395623711304
Validation loss: 2.1270093039407962
Epoch: 9| Step: 10
Training loss: 2.659962651270191
Validation loss: 2.1437406450088177
Epoch: 9| Step: 11
Training loss: 1.6717586298577634
Validation loss: 2.1592317782033517
Epoch: 9| Step: 12
Training loss: 2.477446581806426
Validation loss: 2.189639127694521
Epoch: 9| Step: 13
Training loss: 2.637211325517819
Validation loss: 2.1450400894237953
Epoch: 9| Step: 14
Training loss: 2.6657149484178277
Validation loss: 2.157093275710652
Epoch: 9| Step: 15
Training loss: 2.725330500727536
Validation loss: 2.1688861063042695
Epoch: 9| Step: 16
Training loss: 2.4924266544979328
Validation loss: 2.1362670017357805
Epoch: 9| Step: 17
Training loss: 2.527326769528544
Validation loss: 2.1627831055543147
Epoch: 9| Step: 18
Training loss: 2.6976037942540647
Validation loss: 2.132628758764556
Epoch: 9| Step: 19
Training loss: 3.1075737878289806
Validation loss: 2.145817094862621
Epoch: 68| Step: 0
Training loss: 1.9249004338264522
Validation loss: 2.1720089639227225
Epoch: 9| Step: 1
Training loss: 2.8780508025605003
Validation loss: 2.1889358589263073
Epoch: 9| Step: 2
Training loss: 2.731654792311413
Validation loss: 2.1335707518146796
Epoch: 9| Step: 3
Training loss: 2.4278097961937095
Validation loss: 2.1246443634561603
Epoch: 9| Step: 4
Training loss: 2.0760083425718054
Validation loss: 2.145870189123123
Epoch: 9| Step: 5
Training loss: 2.360266308710665
Validation loss: 2.107861960560197
Epoch: 9| Step: 6
Training loss: 2.297485166715571
Validation loss: 2.1272775170612643
Epoch: 9| Step: 7
Training loss: 2.2701560127320666
Validation loss: 2.1632272021768695
Epoch: 9| Step: 8
Training loss: 2.1158660480884346
Validation loss: 2.1441154022661966
Epoch: 9| Step: 9
Training loss: 2.0798152847067346
Validation loss: 2.149303388848076
Epoch: 9| Step: 10
Training loss: 2.6919150349102368
Validation loss: 2.177827045338015
Epoch: 9| Step: 11
Training loss: 3.686947538726353
Validation loss: 2.1312610666866116
Epoch: 9| Step: 12
Training loss: 2.5795071682668644
Validation loss: 2.1506574661304527
Epoch: 9| Step: 13
Training loss: 2.601261889069869
Validation loss: 2.1557691774923717
Epoch: 9| Step: 14
Training loss: 2.6074738115145806
Validation loss: 2.1786257053652336
Epoch: 9| Step: 15
Training loss: 2.330517250244358
Validation loss: 2.1490137385125156
Epoch: 9| Step: 16
Training loss: 2.97092944003571
Validation loss: 2.1435392461589258
Epoch: 9| Step: 17
Training loss: 2.3518587350396962
Validation loss: 2.1607874667007065
Epoch: 9| Step: 18
Training loss: 2.839651319026239
Validation loss: 2.1490781342182337
Epoch: 9| Step: 19
Training loss: 3.256644865318998
Validation loss: 2.1634947634261437
Epoch: 69| Step: 0
Training loss: 2.01851972559829
Validation loss: 2.1333307168039966
Epoch: 9| Step: 1
Training loss: 2.522448272023468
Validation loss: 2.153215586811819
Epoch: 9| Step: 2
Training loss: 3.289184278104836
Validation loss: 2.148232460301495
Epoch: 9| Step: 3
Training loss: 2.327060123101318
Validation loss: 2.137049229002417
Epoch: 9| Step: 4
Training loss: 2.1366679797513184
Validation loss: 2.16676843857844
Epoch: 9| Step: 5
Training loss: 3.182988583203022
Validation loss: 2.16340541660711
Epoch: 9| Step: 6
Training loss: 2.516667215292494
Validation loss: 2.1443970288717726
Epoch: 9| Step: 7
Training loss: 2.138516689575229
Validation loss: 2.1428795776322787
Epoch: 9| Step: 8
Training loss: 2.5552567247384927
Validation loss: 2.155040434979732
Epoch: 9| Step: 9
Training loss: 2.6136406849459783
Validation loss: 2.128920563439874
Epoch: 9| Step: 10
Training loss: 2.906399630724681
Validation loss: 2.152230347438119
Epoch: 9| Step: 11
Training loss: 3.0033477541809814
Validation loss: 2.1766173234648454
Epoch: 9| Step: 12
Training loss: 2.4784928268935227
Validation loss: 2.142017990628028
Epoch: 9| Step: 13
Training loss: 2.3054692381157356
Validation loss: 2.148614663797593
Epoch: 9| Step: 14
Training loss: 1.647888887784539
Validation loss: 2.177850204594503
Epoch: 9| Step: 15
Training loss: 2.409403728308888
Validation loss: 2.148817607665723
Epoch: 9| Step: 16
Training loss: 2.3761276780319633
Validation loss: 2.149401636883831
Epoch: 9| Step: 17
Training loss: 3.019285836061049
Validation loss: 2.149279068440872
Epoch: 9| Step: 18
Training loss: 2.9555240957677986
Validation loss: 2.134307512248512
Epoch: 9| Step: 19
Training loss: 2.32758350603573
Validation loss: 2.1058640081783433
Epoch: 70| Step: 0
Training loss: 2.3192789877876616
Validation loss: 2.1443037903516493
Epoch: 9| Step: 1
Training loss: 2.106904907738526
Validation loss: 2.1333433788863085
Epoch: 9| Step: 2
Training loss: 3.0552256858862683
Validation loss: 2.1687387401205345
Epoch: 9| Step: 3
Training loss: 2.6682328949355623
Validation loss: 2.152247541299917
Epoch: 9| Step: 4
Training loss: 2.0500675376373607
Validation loss: 2.134117631438463
Epoch: 9| Step: 5
Training loss: 2.7651248630523475
Validation loss: 2.1423022595282797
Epoch: 9| Step: 6
Training loss: 1.584749048986479
Validation loss: 2.0991265759952498
Epoch: 9| Step: 7
Training loss: 2.6865204201296216
Validation loss: 2.1226081235761725
Epoch: 9| Step: 8
Training loss: 2.5076992686725474
Validation loss: 2.1528353615310243
Epoch: 9| Step: 9
Training loss: 2.2398478033949196
Validation loss: 2.1309030479401008
Epoch: 9| Step: 10
Training loss: 3.4600743580143303
Validation loss: 2.1633087958485175
Epoch: 9| Step: 11
Training loss: 2.2419803536989504
Validation loss: 2.1455480015082284
Epoch: 9| Step: 12
Training loss: 2.4665531089349724
Validation loss: 2.1442080325304813
Epoch: 9| Step: 13
Training loss: 2.5843290645479318
Validation loss: 2.1477898847090118
Epoch: 9| Step: 14
Training loss: 2.156502529228597
Validation loss: 2.169744264310334
Epoch: 9| Step: 15
Training loss: 2.3199324890705797
Validation loss: 2.1390771300483737
Epoch: 9| Step: 16
Training loss: 2.6307856967863747
Validation loss: 2.1298738523075484
Epoch: 9| Step: 17
Training loss: 2.7122982248946377
Validation loss: 2.1502649167464423
Epoch: 9| Step: 18
Training loss: 2.6293719985832347
Validation loss: 2.144108995019068
Epoch: 9| Step: 19
Training loss: 3.461646564947495
Validation loss: 2.122497486211067
Epoch: 71| Step: 0
Training loss: 2.7951229297716766
Validation loss: 2.1591451353825684
Epoch: 9| Step: 1
Training loss: 3.174204304629634
Validation loss: 2.13404518282616
Epoch: 9| Step: 2
Training loss: 1.6813620093943247
Validation loss: 2.1519830460134823
Epoch: 9| Step: 3
Training loss: 2.6510054929972076
Validation loss: 2.1406168667175205
Epoch: 9| Step: 4
Training loss: 2.1168337593307447
Validation loss: 2.115480057325397
Epoch: 9| Step: 5
Training loss: 2.79006862925137
Validation loss: 2.157065430963448
Epoch: 9| Step: 6
Training loss: 2.885826623394581
Validation loss: 2.1506811789934988
Epoch: 9| Step: 7
Training loss: 2.7152083556874453
Validation loss: 2.127449979613531
Epoch: 9| Step: 8
Training loss: 2.5542736593201556
Validation loss: 2.145125079582246
Epoch: 9| Step: 9
Training loss: 2.267705659130262
Validation loss: 2.1375268467582274
Epoch: 9| Step: 10
Training loss: 2.3403016217152497
Validation loss: 2.1285799967525882
Epoch: 9| Step: 11
Training loss: 2.2723537103381806
Validation loss: 2.1350325701620947
Epoch: 9| Step: 12
Training loss: 2.9812241143276417
Validation loss: 2.1463284487298013
Epoch: 9| Step: 13
Training loss: 2.373971013471465
Validation loss: 2.1282209191363552
Epoch: 9| Step: 14
Training loss: 2.42973038123459
Validation loss: 2.121044264409733
Epoch: 9| Step: 15
Training loss: 1.6696698628828657
Validation loss: 2.124972210403114
Epoch: 9| Step: 16
Training loss: 2.5243828954193037
Validation loss: 2.1953864790587243
Epoch: 9| Step: 17
Training loss: 2.7846108179383253
Validation loss: 2.1421724180470947
Epoch: 9| Step: 18
Training loss: 2.1930834765673812
Validation loss: 2.1151132601572598
Epoch: 9| Step: 19
Training loss: 3.2703536991999953
Validation loss: 2.1287156089814143
Epoch: 72| Step: 0
Training loss: 3.002197414527549
Validation loss: 2.1332246977879694
Epoch: 9| Step: 1
Training loss: 1.6805954009797937
Validation loss: 2.125043694290967
Epoch: 9| Step: 2
Training loss: 3.3614696980463457
Validation loss: 2.1581358205116166
Epoch: 9| Step: 3
Training loss: 3.18566647322049
Validation loss: 2.105422074884345
Epoch: 9| Step: 4
Training loss: 3.389364685121682
Validation loss: 2.130117603714013
Epoch: 9| Step: 5
Training loss: 2.143895011423676
Validation loss: 2.1408718076377293
Epoch: 9| Step: 6
Training loss: 1.8461469812907452
Validation loss: 2.150656896489947
Epoch: 9| Step: 7
Training loss: 2.28673489808955
Validation loss: 2.168957391319386
Epoch: 9| Step: 8
Training loss: 2.361912455487649
Validation loss: 2.1578615715901375
Epoch: 9| Step: 9
Training loss: 1.7424592631543618
Validation loss: 2.1458253100353257
Epoch: 9| Step: 10
Training loss: 2.309068556754537
Validation loss: 2.1841354948339338
Epoch: 9| Step: 11
Training loss: 2.307947161858068
Validation loss: 2.164105435440948
Epoch: 9| Step: 12
Training loss: 3.0009166588655924
Validation loss: 2.096915850479601
Epoch: 9| Step: 13
Training loss: 2.5243385997243615
Validation loss: 2.1391437798298036
Epoch: 9| Step: 14
Training loss: 3.2846750458082115
Validation loss: 2.1394209589567095
Epoch: 9| Step: 15
Training loss: 2.086675049193164
Validation loss: 2.1069033990893318
Epoch: 9| Step: 16
Training loss: 2.2928929486978307
Validation loss: 2.161282220128473
Epoch: 9| Step: 17
Training loss: 2.246215923137879
Validation loss: 2.1451723113633676
Epoch: 9| Step: 18
Training loss: 2.341789544661171
Validation loss: 2.1435591614913005
Epoch: 9| Step: 19
Training loss: 2.8335197798774128
Validation loss: 2.124337924303352
Epoch: 73| Step: 0
Training loss: 2.1029164090379053
Validation loss: 2.122494487185517
Epoch: 9| Step: 1
Training loss: 2.9954382864539375
Validation loss: 2.1109651936297102
Epoch: 9| Step: 2
Training loss: 2.043130725982101
Validation loss: 2.158814083405214
Epoch: 9| Step: 3
Training loss: 2.9848306517749696
Validation loss: 2.1185331258101714
Epoch: 9| Step: 4
Training loss: 2.6709768112929853
Validation loss: 2.156775149623235
Epoch: 9| Step: 5
Training loss: 1.6464243523821753
Validation loss: 2.141724481219738
Epoch: 9| Step: 6
Training loss: 2.9700903828030287
Validation loss: 2.1472978830642515
Epoch: 9| Step: 7
Training loss: 2.565394186029101
Validation loss: 2.1705012749939594
Epoch: 9| Step: 8
Training loss: 2.034253174493232
Validation loss: 2.1613566221054232
Epoch: 9| Step: 9
Training loss: 2.7194644383894855
Validation loss: 2.1333888460473305
Epoch: 9| Step: 10
Training loss: 2.7873422997175425
Validation loss: 2.113896372925256
Epoch: 9| Step: 11
Training loss: 2.4285712422442964
Validation loss: 2.1386463702367506
Epoch: 9| Step: 12
Training loss: 1.807046248806241
Validation loss: 2.157414196545893
Epoch: 9| Step: 13
Training loss: 2.8896380414965916
Validation loss: 2.1292243860515914
Epoch: 9| Step: 14
Training loss: 2.276125861966811
Validation loss: 2.1261854410571144
Epoch: 9| Step: 15
Training loss: 2.336530425180766
Validation loss: 2.112901505610699
Epoch: 9| Step: 16
Training loss: 3.1295846496533217
Validation loss: 2.1218670755890714
Epoch: 9| Step: 17
Training loss: 2.7912819630509236
Validation loss: 2.1348671668726085
Epoch: 9| Step: 18
Training loss: 2.5704431935392305
Validation loss: 2.1316162874759312
Epoch: 9| Step: 19
Training loss: 2.8589005206888234
Validation loss: 2.1463677012436593
Epoch: 74| Step: 0
Training loss: 2.3310853710800004
Validation loss: 2.1093694058993657
Epoch: 9| Step: 1
Training loss: 2.349980427274968
Validation loss: 2.113583021284852
Epoch: 9| Step: 2
Training loss: 1.8655969716687104
Validation loss: 2.1373505678877502
Epoch: 9| Step: 3
Training loss: 2.2938410644748353
Validation loss: 2.130142618536337
Epoch: 9| Step: 4
Training loss: 3.2742023166325107
Validation loss: 2.1333172855481704
Epoch: 9| Step: 5
Training loss: 2.848764714014302
Validation loss: 2.1537232198670835
Epoch: 9| Step: 6
Training loss: 2.256707472138808
Validation loss: 2.116445626176937
Epoch: 9| Step: 7
Training loss: 2.258037727500295
Validation loss: 2.1400594200443805
Epoch: 9| Step: 8
Training loss: 2.7934935176808975
Validation loss: 2.1622572364783768
Epoch: 9| Step: 9
Training loss: 2.683568873838487
Validation loss: 2.112494312525061
Epoch: 9| Step: 10
Training loss: 2.593435980850034
Validation loss: 2.141571517136351
Epoch: 9| Step: 11
Training loss: 2.517384168731208
Validation loss: 2.1430614439916162
Epoch: 9| Step: 12
Training loss: 2.9949914130340924
Validation loss: 2.1510089903243714
Epoch: 9| Step: 13
Training loss: 2.8595164112914815
Validation loss: 2.1446030045037645
Epoch: 9| Step: 14
Training loss: 2.5295160264915477
Validation loss: 2.1533643169675294
Epoch: 9| Step: 15
Training loss: 2.5167290770347894
Validation loss: 2.1475941308083657
Epoch: 9| Step: 16
Training loss: 2.75206496997591
Validation loss: 2.1205903961862673
Epoch: 9| Step: 17
Training loss: 2.506369677799345
Validation loss: 2.134058118845608
Epoch: 9| Step: 18
Training loss: 2.463615389494374
Validation loss: 2.1223966280140276
Epoch: 9| Step: 19
Training loss: 2.5505565409971296
Validation loss: 2.130078630625852
Epoch: 75| Step: 0
Training loss: 2.3327076504466633
Validation loss: 2.169040711611382
Epoch: 9| Step: 1
Training loss: 2.177353022418418
Validation loss: 2.1397739148691834
Epoch: 9| Step: 2
Training loss: 2.3638893038785067
Validation loss: 2.1382788177241183
Epoch: 9| Step: 3
Training loss: 2.731411270513198
Validation loss: 2.141718973927511
Epoch: 9| Step: 4
Training loss: 2.9487894516295166
Validation loss: 2.1493250738341656
Epoch: 9| Step: 5
Training loss: 1.8333493434322539
Validation loss: 2.144761522579665
Epoch: 9| Step: 6
Training loss: 2.530955450557417
Validation loss: 2.116563792730669
Epoch: 9| Step: 7
Training loss: 3.1680203773440425
Validation loss: 2.1248174756132983
Epoch: 9| Step: 8
Training loss: 1.833031485012963
Validation loss: 2.147012093545282
Epoch: 9| Step: 9
Training loss: 2.945431977537719
Validation loss: 2.1258116869399606
Epoch: 9| Step: 10
Training loss: 2.4410493879811175
Validation loss: 2.1303598585374757
Epoch: 9| Step: 11
Training loss: 2.96160687854407
Validation loss: 2.1112398717926757
Epoch: 9| Step: 12
Training loss: 1.862194071996736
Validation loss: 2.116318856384784
Epoch: 9| Step: 13
Training loss: 2.685251226623954
Validation loss: 2.1122097126725063
Epoch: 9| Step: 14
Training loss: 3.2153935385275907
Validation loss: 2.1085146141493936
Epoch: 9| Step: 15
Training loss: 2.328354996962947
Validation loss: 2.092252326775259
Epoch: 9| Step: 16
Training loss: 2.7958715759330053
Validation loss: 2.1049157023046727
Epoch: 9| Step: 17
Training loss: 2.651424197994346
Validation loss: 2.147388984572486
Epoch: 9| Step: 18
Training loss: 2.984443384155984
Validation loss: 2.0954716080793916
Epoch: 9| Step: 19
Training loss: 1.9235085468821262
Validation loss: 2.1015993242109694
Epoch: 76| Step: 0
Training loss: 2.388979476374294
Validation loss: 2.106112406565331
Epoch: 9| Step: 1
Training loss: 2.406939915425752
Validation loss: 2.1488182332222947
Epoch: 9| Step: 2
Training loss: 2.7550418757806
Validation loss: 2.1492926673164003
Epoch: 9| Step: 3
Training loss: 2.927321472979104
Validation loss: 2.135682937813201
Epoch: 9| Step: 4
Training loss: 2.4459705381451595
Validation loss: 2.161807768160179
Epoch: 9| Step: 5
Training loss: 2.617186042443624
Validation loss: 2.1636982197823795
Epoch: 9| Step: 6
Training loss: 2.084006569484087
Validation loss: 2.1388310789549174
Epoch: 9| Step: 7
Training loss: 1.817523571632886
Validation loss: 2.1253579273035643
Epoch: 9| Step: 8
Training loss: 2.4822274768985846
Validation loss: 2.0986788734920516
Epoch: 9| Step: 9
Training loss: 2.1698972630242377
Validation loss: 2.1407497980967043
Epoch: 9| Step: 10
Training loss: 3.046955440144085
Validation loss: 2.187395769542668
Epoch: 9| Step: 11
Training loss: 2.5613200564691523
Validation loss: 2.1762130989605004
Epoch: 9| Step: 12
Training loss: 2.057107522827534
Validation loss: 2.140734728023493
Epoch: 9| Step: 13
Training loss: 3.3060426931884246
Validation loss: 2.1564986421614063
Epoch: 9| Step: 14
Training loss: 2.2476074425599393
Validation loss: 2.1692498116302583
Epoch: 9| Step: 15
Training loss: 3.1179553164252707
Validation loss: 2.124495936712228
Epoch: 9| Step: 16
Training loss: 2.8660367480608744
Validation loss: 2.1547609668084577
Epoch: 9| Step: 17
Training loss: 2.6730788346470056
Validation loss: 2.1636537211383198
Epoch: 9| Step: 18
Training loss: 2.880261458078855
Validation loss: 2.13499124828552
Epoch: 9| Step: 19
Training loss: 2.012531834700051
Validation loss: 2.1079073299992794
Epoch: 77| Step: 0
Training loss: 1.8445754708753792
Validation loss: 2.1497687644838743
Epoch: 9| Step: 1
Training loss: 2.681591903121669
Validation loss: 2.163857641664899
Epoch: 9| Step: 2
Training loss: 2.0189584772035603
Validation loss: 2.137723080024797
Epoch: 9| Step: 3
Training loss: 2.6419788027771403
Validation loss: 2.1363937845270407
Epoch: 9| Step: 4
Training loss: 3.19865276467643
Validation loss: 2.1253344347274106
Epoch: 9| Step: 5
Training loss: 2.1649380782084293
Validation loss: 2.161037878236432
Epoch: 9| Step: 6
Training loss: 2.584118159861026
Validation loss: 2.0970339041846313
Epoch: 9| Step: 7
Training loss: 2.158155953422554
Validation loss: 2.126477640711901
Epoch: 9| Step: 8
Training loss: 2.1014748026761967
Validation loss: 2.15794276539729
Epoch: 9| Step: 9
Training loss: 2.799101726312062
Validation loss: 2.1231228234927526
Epoch: 9| Step: 10
Training loss: 2.3999587214416884
Validation loss: 2.115238726574861
Epoch: 9| Step: 11
Training loss: 2.296480936514053
Validation loss: 2.129648751110397
Epoch: 9| Step: 12
Training loss: 2.5360074017774705
Validation loss: 2.132053372727581
Epoch: 9| Step: 13
Training loss: 3.069780065753833
Validation loss: 2.103780907898175
Epoch: 9| Step: 14
Training loss: 3.2576851579765926
Validation loss: 2.1314487489536176
Epoch: 9| Step: 15
Training loss: 2.0829802277460314
Validation loss: 2.135720212245415
Epoch: 9| Step: 16
Training loss: 2.6849375196465033
Validation loss: 2.123748282024007
Epoch: 9| Step: 17
Training loss: 2.8332811425581963
Validation loss: 2.146249377748089
Epoch: 9| Step: 18
Training loss: 3.0240742803866274
Validation loss: 2.092707500836473
Epoch: 9| Step: 19
Training loss: 2.441451757388375
Validation loss: 2.1358589107835204
Epoch: 78| Step: 0
Training loss: 1.7302895618948637
Validation loss: 2.122741723842913
Epoch: 9| Step: 1
Training loss: 2.6571528078587283
Validation loss: 2.0786940691197073
Epoch: 9| Step: 2
Training loss: 2.0701617491916333
Validation loss: 2.151827124458144
Epoch: 9| Step: 3
Training loss: 2.4879825718198756
Validation loss: 2.159448835599862
Epoch: 9| Step: 4
Training loss: 2.746956441494347
Validation loss: 2.1347536690335254
Epoch: 9| Step: 5
Training loss: 2.217254779593314
Validation loss: 2.12531497052507
Epoch: 9| Step: 6
Training loss: 2.461050460887122
Validation loss: 2.1699709446871074
Epoch: 9| Step: 7
Training loss: 2.3506090632950483
Validation loss: 2.1517018998857917
Epoch: 9| Step: 8
Training loss: 2.489341713474241
Validation loss: 2.148593165735232
Epoch: 9| Step: 9
Training loss: 3.2117952932016274
Validation loss: 2.1666124171292647
Epoch: 9| Step: 10
Training loss: 2.745634862724459
Validation loss: 2.162610100937108
Epoch: 9| Step: 11
Training loss: 3.1209614406991726
Validation loss: 2.171293323682081
Epoch: 9| Step: 12
Training loss: 2.010983942143214
Validation loss: 2.1782085965420395
Epoch: 9| Step: 13
Training loss: 2.7559430321230107
Validation loss: 2.1671275978464313
Epoch: 9| Step: 14
Training loss: 3.2111430229997784
Validation loss: 2.1566331361365325
Epoch: 9| Step: 15
Training loss: 2.608187833715191
Validation loss: 2.2008244385319276
Epoch: 9| Step: 16
Training loss: 2.38359602256324
Validation loss: 2.148049572739513
Epoch: 9| Step: 17
Training loss: 2.942748555046377
Validation loss: 2.143365063116579
Epoch: 9| Step: 18
Training loss: 2.4035773358791688
Validation loss: 2.145436214991318
Epoch: 9| Step: 19
Training loss: 2.396590724037223
Validation loss: 2.160505088759028
Epoch: 79| Step: 0
Training loss: 2.5865440924923795
Validation loss: 2.1319262909577943
Epoch: 9| Step: 1
Training loss: 2.8506888109327795
Validation loss: 2.113252412445879
Epoch: 9| Step: 2
Training loss: 2.2079975544667176
Validation loss: 2.160637598134654
Epoch: 9| Step: 3
Training loss: 2.3198874755405536
Validation loss: 2.1252892479675713
Epoch: 9| Step: 4
Training loss: 2.322138109869039
Validation loss: 2.1619179485574307
Epoch: 9| Step: 5
Training loss: 2.6021163396724654
Validation loss: 2.132686531093781
Epoch: 9| Step: 6
Training loss: 2.9301702076293643
Validation loss: 2.1371657081525464
Epoch: 9| Step: 7
Training loss: 1.8869188411909976
Validation loss: 2.1314437730359903
Epoch: 9| Step: 8
Training loss: 2.8125033908399697
Validation loss: 2.1156431374052334
Epoch: 9| Step: 9
Training loss: 3.06748991848782
Validation loss: 2.1392871632726544
Epoch: 9| Step: 10
Training loss: 2.3700036146240997
Validation loss: 2.1384938331016383
Epoch: 9| Step: 11
Training loss: 2.682045658027313
Validation loss: 2.120430455124761
Epoch: 9| Step: 12
Training loss: 2.3433601563800996
Validation loss: 2.1497413115515087
Epoch: 9| Step: 13
Training loss: 2.9610270383477033
Validation loss: 2.106923455969519
Epoch: 9| Step: 14
Training loss: 1.8627587311524323
Validation loss: 2.1111027279868897
Epoch: 9| Step: 15
Training loss: 2.5571798596669493
Validation loss: 2.1553340964190646
Epoch: 9| Step: 16
Training loss: 2.9005888900038
Validation loss: 2.1423569883790363
Epoch: 9| Step: 17
Training loss: 2.9499404125337856
Validation loss: 2.1177065509262913
Epoch: 9| Step: 18
Training loss: 2.435417850995544
Validation loss: 2.1016263545424025
Epoch: 9| Step: 19
Training loss: 2.36027812725157
Validation loss: 2.124456375592819
Epoch: 80| Step: 0
Training loss: 2.312329054004144
Validation loss: 2.1279206827458883
Epoch: 9| Step: 1
Training loss: 2.1461393514648024
Validation loss: 2.152930643612971
Epoch: 9| Step: 2
Training loss: 3.1888451823194175
Validation loss: 2.1097148361439495
Epoch: 9| Step: 3
Training loss: 2.9725125211639667
Validation loss: 2.1089555935976363
Epoch: 9| Step: 4
Training loss: 1.8586034376061102
Validation loss: 2.1402690280400627
Epoch: 9| Step: 5
Training loss: 2.3699143821606663
Validation loss: 2.090559926494426
Epoch: 9| Step: 6
Training loss: 2.8423433283135062
Validation loss: 2.096808285885068
Epoch: 9| Step: 7
Training loss: 3.123716930200618
Validation loss: 2.134726778413528
Epoch: 9| Step: 8
Training loss: 2.5179602168048376
Validation loss: 2.151101555698307
Epoch: 9| Step: 9
Training loss: 3.3362806800297755
Validation loss: 2.116252307825173
Epoch: 9| Step: 10
Training loss: 2.7199180111028314
Validation loss: 2.1092862396478376
Epoch: 9| Step: 11
Training loss: 2.6198727624878995
Validation loss: 2.090049115848534
Epoch: 9| Step: 12
Training loss: 2.627599972638708
Validation loss: 2.121652184889104
Epoch: 9| Step: 13
Training loss: 2.47535786979522
Validation loss: 2.118761315576767
Epoch: 9| Step: 14
Training loss: 1.9333515670618087
Validation loss: 2.1260779227250968
Epoch: 9| Step: 15
Training loss: 2.040298963967223
Validation loss: 2.127351950088207
Epoch: 9| Step: 16
Training loss: 2.3005017562557715
Validation loss: 2.1356054654939918
Epoch: 9| Step: 17
Training loss: 2.3155346110176276
Validation loss: 2.1308857682329987
Epoch: 9| Step: 18
Training loss: 2.1977707752664366
Validation loss: 2.135874802188154
Epoch: 9| Step: 19
Training loss: 2.647291087264113
Validation loss: 2.088646354729069
Epoch: 81| Step: 0
Training loss: 2.538247315052859
Validation loss: 2.1156721808905887
Epoch: 9| Step: 1
Training loss: 2.251866520112117
Validation loss: 2.1417623196171833
Epoch: 9| Step: 2
Training loss: 2.407590319403957
Validation loss: 2.144412961673252
Epoch: 9| Step: 3
Training loss: 2.9095112540261274
Validation loss: 2.115281003649218
Epoch: 9| Step: 4
Training loss: 3.142033806622005
Validation loss: 2.1495541050773572
Epoch: 9| Step: 5
Training loss: 2.5803383314094717
Validation loss: 2.1299412976757655
Epoch: 9| Step: 6
Training loss: 1.868529408171153
Validation loss: 2.1164020810757114
Epoch: 9| Step: 7
Training loss: 1.9601058108125946
Validation loss: 2.1575859796809462
Epoch: 9| Step: 8
Training loss: 3.1211903047486595
Validation loss: 2.1394568610794606
Epoch: 9| Step: 9
Training loss: 2.264096500833807
Validation loss: 2.1368330503361834
Epoch: 9| Step: 10
Training loss: 2.548693048983061
Validation loss: 2.1265159207552027
Epoch: 9| Step: 11
Training loss: 2.8536145495344063
Validation loss: 2.1510184157536067
Epoch: 9| Step: 12
Training loss: 2.7061561832508803
Validation loss: 2.1522651788882055
Epoch: 9| Step: 13
Training loss: 3.1020848677515898
Validation loss: 2.1295303640898258
Epoch: 9| Step: 14
Training loss: 3.056035751602995
Validation loss: 2.1262144057616634
Epoch: 9| Step: 15
Training loss: 2.1437573313240166
Validation loss: 2.127424421247975
Epoch: 9| Step: 16
Training loss: 2.5771240140705154
Validation loss: 2.157215749505165
Epoch: 9| Step: 17
Training loss: 2.205189920840175
Validation loss: 2.1443016710762377
Epoch: 9| Step: 18
Training loss: 2.1221872675792626
Validation loss: 2.1212831203921936
Epoch: 9| Step: 19
Training loss: 2.0204289874063517
Validation loss: 2.134418838750908
Epoch: 82| Step: 0
Training loss: 1.9557957204033656
Validation loss: 2.1193458486513914
Epoch: 9| Step: 1
Training loss: 2.3566197355670186
Validation loss: 2.11322058353311
Epoch: 9| Step: 2
Training loss: 2.4689097292448072
Validation loss: 2.1453413071592866
Epoch: 9| Step: 3
Training loss: 2.4702262810289435
Validation loss: 2.1409056136697595
Epoch: 9| Step: 4
Training loss: 1.7935278858008832
Validation loss: 2.1517577700759345
Epoch: 9| Step: 5
Training loss: 2.715826194342561
Validation loss: 2.160947955402082
Epoch: 9| Step: 6
Training loss: 2.6284361556442826
Validation loss: 2.1513506776192934
Epoch: 9| Step: 7
Training loss: 2.941694957247706
Validation loss: 2.1329601252152304
Epoch: 9| Step: 8
Training loss: 2.794088072664567
Validation loss: 2.135800944128837
Epoch: 9| Step: 9
Training loss: 1.7200103300361043
Validation loss: 2.136088284790299
Epoch: 9| Step: 10
Training loss: 2.891930197837603
Validation loss: 2.15777368699036
Epoch: 9| Step: 11
Training loss: 2.467652668505601
Validation loss: 2.1095683929970646
Epoch: 9| Step: 12
Training loss: 2.4411147286888886
Validation loss: 2.09911067521307
Epoch: 9| Step: 13
Training loss: 3.137321898736096
Validation loss: 2.15398666332573
Epoch: 9| Step: 14
Training loss: 2.245720926938486
Validation loss: 2.1551692611388757
Epoch: 9| Step: 15
Training loss: 2.5276065554169653
Validation loss: 2.1600806558479033
Epoch: 9| Step: 16
Training loss: 2.6606850791637515
Validation loss: 2.137431799176777
Epoch: 9| Step: 17
Training loss: 2.546514942016746
Validation loss: 2.103564207920198
Epoch: 9| Step: 18
Training loss: 3.4506824537129326
Validation loss: 2.109096802680999
Epoch: 9| Step: 19
Training loss: 2.677310434250469
Validation loss: 2.1276086885252163
Epoch: 83| Step: 0
Training loss: 2.7668662868627103
Validation loss: 2.130679083763657
Epoch: 9| Step: 1
Training loss: 2.8963793415927537
Validation loss: 2.1620843041782667
Epoch: 9| Step: 2
Training loss: 2.871479366642177
Validation loss: 2.129411550269009
Epoch: 9| Step: 3
Training loss: 2.226862301636367
Validation loss: 2.1572994591643995
Epoch: 9| Step: 4
Training loss: 2.263783620819549
Validation loss: 2.1597595027618244
Epoch: 9| Step: 5
Training loss: 2.5601436667064696
Validation loss: 2.1221941381324143
Epoch: 9| Step: 6
Training loss: 2.5769987478434517
Validation loss: 2.0732896257351268
Epoch: 9| Step: 7
Training loss: 2.159668134343906
Validation loss: 2.0673740119010646
Epoch: 9| Step: 8
Training loss: 2.523670575506149
Validation loss: 2.151681384792667
Epoch: 9| Step: 9
Training loss: 3.3246651158160603
Validation loss: 2.141020830665459
Epoch: 9| Step: 10
Training loss: 2.47126738245499
Validation loss: 2.146415645764476
Epoch: 9| Step: 11
Training loss: 2.784535214388293
Validation loss: 2.114651917775046
Epoch: 9| Step: 12
Training loss: 3.2381588828753647
Validation loss: 2.1024270516973727
Epoch: 9| Step: 13
Training loss: 2.06745638781749
Validation loss: 2.126893166776896
Epoch: 9| Step: 14
Training loss: 1.639340942703857
Validation loss: 2.1141725735627803
Epoch: 9| Step: 15
Training loss: 2.0141719341511704
Validation loss: 2.131008732918337
Epoch: 9| Step: 16
Training loss: 2.3557134852258876
Validation loss: 2.1198120708455765
Epoch: 9| Step: 17
Training loss: 3.0875765153925046
Validation loss: 2.073045089401007
Epoch: 9| Step: 18
Training loss: 2.668927803638142
Validation loss: 2.1455595649078565
Epoch: 9| Step: 19
Training loss: 1.9445647368990344
Validation loss: 2.121839404209628
Epoch: 84| Step: 0
Training loss: 2.9293593566229417
Validation loss: 2.142830493881551
Epoch: 9| Step: 1
Training loss: 2.6928788407215176
Validation loss: 2.0454608957143816
Epoch: 9| Step: 2
Training loss: 2.5207319843526554
Validation loss: 2.127538811288843
Epoch: 9| Step: 3
Training loss: 2.2229906846236087
Validation loss: 2.0909787373102064
Epoch: 9| Step: 4
Training loss: 2.8700449163132054
Validation loss: 2.093890713704656
Epoch: 9| Step: 5
Training loss: 2.4882429230760974
Validation loss: 2.134142317943701
Epoch: 9| Step: 6
Training loss: 2.6896571883253912
Validation loss: 2.1041002209350887
Epoch: 9| Step: 7
Training loss: 2.846695768072077
Validation loss: 2.123066968326688
Epoch: 9| Step: 8
Training loss: 2.1351607254601146
Validation loss: 2.152092267336111
Epoch: 9| Step: 9
Training loss: 2.3669973366274757
Validation loss: 2.139770906980575
Epoch: 9| Step: 10
Training loss: 2.6939209815191667
Validation loss: 2.121824417847864
Epoch: 9| Step: 11
Training loss: 2.0762892337332723
Validation loss: 2.0982641100540453
Epoch: 9| Step: 12
Training loss: 1.925899973956664
Validation loss: 2.133323609366059
Epoch: 9| Step: 13
Training loss: 1.7806807829881584
Validation loss: 2.111730138788349
Epoch: 9| Step: 14
Training loss: 2.069878529103614
Validation loss: 2.1104100288666516
Epoch: 9| Step: 15
Training loss: 2.979853695343833
Validation loss: 2.123791574561028
Epoch: 9| Step: 16
Training loss: 2.756513857159865
Validation loss: 2.128084638894074
Epoch: 9| Step: 17
Training loss: 2.7310348600595256
Validation loss: 2.120997621458682
Epoch: 9| Step: 18
Training loss: 2.553596566959693
Validation loss: 2.1327057489323535
Epoch: 9| Step: 19
Training loss: 3.2284258249005453
Validation loss: 2.1238276377174894
Epoch: 85| Step: 0
Training loss: 2.8246669809309592
Validation loss: 2.130381783721486
Epoch: 9| Step: 1
Training loss: 1.9068584409161675
Validation loss: 2.1382794785477612
Epoch: 9| Step: 2
Training loss: 2.900479895248664
Validation loss: 2.1200089025348836
Epoch: 9| Step: 3
Training loss: 2.5909759210183947
Validation loss: 2.1295069550567525
Epoch: 9| Step: 4
Training loss: 2.56327082507738
Validation loss: 2.0997146225563146
Epoch: 9| Step: 5
Training loss: 1.7947996676977542
Validation loss: 2.116514460062051
Epoch: 9| Step: 6
Training loss: 2.3169570448132535
Validation loss: 2.1339944879522688
Epoch: 9| Step: 7
Training loss: 2.2939432338219614
Validation loss: 2.094126537037852
Epoch: 9| Step: 8
Training loss: 2.3975443714797255
Validation loss: 2.1449668381419578
Epoch: 9| Step: 9
Training loss: 2.5098568198412265
Validation loss: 2.116463952438441
Epoch: 9| Step: 10
Training loss: 3.1172872350507816
Validation loss: 2.136552560844551
Epoch: 9| Step: 11
Training loss: 2.8729081214370136
Validation loss: 2.175712456705136
Epoch: 9| Step: 12
Training loss: 2.154262788006616
Validation loss: 2.108648173374164
Epoch: 9| Step: 13
Training loss: 2.958966165115172
Validation loss: 2.0910015700695137
Epoch: 9| Step: 14
Training loss: 2.479219665815675
Validation loss: 2.149639360017609
Epoch: 9| Step: 15
Training loss: 2.371792182934057
Validation loss: 2.1317918255916677
Epoch: 9| Step: 16
Training loss: 2.4307070245927
Validation loss: 2.103986029337659
Epoch: 9| Step: 17
Training loss: 2.4682354934159445
Validation loss: 2.1250125080130022
Epoch: 9| Step: 18
Training loss: 2.8919087626520836
Validation loss: 2.1399273298242374
Epoch: 9| Step: 19
Training loss: 2.6568008749202585
Validation loss: 2.094558463842956
Epoch: 86| Step: 0
Training loss: 1.9553836427548927
Validation loss: 2.1232652673646286
Epoch: 9| Step: 1
Training loss: 2.4803800311705344
Validation loss: 2.1329161669233074
Epoch: 9| Step: 2
Training loss: 2.6061156240533645
Validation loss: 2.1387827911448163
Epoch: 9| Step: 3
Training loss: 2.2810266463794147
Validation loss: 2.106221273318118
Epoch: 9| Step: 4
Training loss: 2.5760240722088303
Validation loss: 2.1118896089253036
Epoch: 9| Step: 5
Training loss: 2.4845208659026126
Validation loss: 2.1716809177970946
Epoch: 9| Step: 6
Training loss: 2.6597091590376842
Validation loss: 2.152236087950535
Epoch: 9| Step: 7
Training loss: 2.543675384551869
Validation loss: 2.1383515977174663
Epoch: 9| Step: 8
Training loss: 2.3109699032918836
Validation loss: 2.129413418029729
Epoch: 9| Step: 9
Training loss: 2.677571787722182
Validation loss: 2.118449581034047
Epoch: 9| Step: 10
Training loss: 2.316033010020241
Validation loss: 2.123285512301166
Epoch: 9| Step: 11
Training loss: 2.7360787451605333
Validation loss: 2.145722630927147
Epoch: 9| Step: 12
Training loss: 1.8669737370283006
Validation loss: 2.1306529275959103
Epoch: 9| Step: 13
Training loss: 2.4302363619037632
Validation loss: 2.124579245381022
Epoch: 9| Step: 14
Training loss: 3.0603876419370306
Validation loss: 2.1517216958643473
Epoch: 9| Step: 15
Training loss: 2.3477281505472627
Validation loss: 2.1399516777053615
Epoch: 9| Step: 16
Training loss: 2.7856843723186184
Validation loss: 2.1076907318390905
Epoch: 9| Step: 17
Training loss: 2.3838436709614594
Validation loss: 2.125624727674907
Epoch: 9| Step: 18
Training loss: 3.040365140970684
Validation loss: 2.1018516371382083
Epoch: 9| Step: 19
Training loss: 2.9048363313512993
Validation loss: 2.1098924909147785
Epoch: 87| Step: 0
Training loss: 2.214305455695543
Validation loss: 2.1551050425416025
Epoch: 9| Step: 1
Training loss: 2.3166969978853484
Validation loss: 2.1130722956744474
Epoch: 9| Step: 2
Training loss: 2.5360555361614456
Validation loss: 2.127887211343508
Epoch: 9| Step: 3
Training loss: 2.865541905786471
Validation loss: 2.0969000089117875
Epoch: 9| Step: 4
Training loss: 2.271889805384777
Validation loss: 2.1202857302684093
Epoch: 9| Step: 5
Training loss: 3.2331332711792973
Validation loss: 2.1177731225778613
Epoch: 9| Step: 6
Training loss: 2.774201365840483
Validation loss: 2.112379271578109
Epoch: 9| Step: 7
Training loss: 2.6269425062227296
Validation loss: 2.0513286755736373
Epoch: 9| Step: 8
Training loss: 1.7407844949789115
Validation loss: 2.1015493030929857
Epoch: 9| Step: 9
Training loss: 2.681974008262133
Validation loss: 2.1022797038104404
Epoch: 9| Step: 10
Training loss: 2.292826711489217
Validation loss: 2.094873583970153
Epoch: 9| Step: 11
Training loss: 2.6035723096968266
Validation loss: 2.1001960110431632
Epoch: 9| Step: 12
Training loss: 2.6160605666122474
Validation loss: 2.1224877858979703
Epoch: 9| Step: 13
Training loss: 1.9818374148064737
Validation loss: 2.0937002719397837
Epoch: 9| Step: 14
Training loss: 1.772266421403006
Validation loss: 2.135841146385816
Epoch: 9| Step: 15
Training loss: 3.1104026131505154
Validation loss: 2.099067414298526
Epoch: 9| Step: 16
Training loss: 2.6338162192704506
Validation loss: 2.1076531834103625
Epoch: 9| Step: 17
Training loss: 2.6854596931871666
Validation loss: 2.0789527594826196
Epoch: 9| Step: 18
Training loss: 3.20520844970412
Validation loss: 2.0958569204292083
Epoch: 9| Step: 19
Training loss: 2.2477227448779793
Validation loss: 2.0680924525102
Epoch: 88| Step: 0
Training loss: 2.642626844409544
Validation loss: 2.1005364535765163
Epoch: 9| Step: 1
Training loss: 2.461838039751207
Validation loss: 2.115897551525148
Epoch: 9| Step: 2
Training loss: 2.387512474626636
Validation loss: 2.1232134995168015
Epoch: 9| Step: 3
Training loss: 2.95568833287919
Validation loss: 2.092662095672829
Epoch: 9| Step: 4
Training loss: 2.5297423217186434
Validation loss: 2.140417153973043
Epoch: 9| Step: 5
Training loss: 2.5441200006001314
Validation loss: 2.1371168135194654
Epoch: 9| Step: 6
Training loss: 2.1607447783064893
Validation loss: 2.085510558860595
Epoch: 9| Step: 7
Training loss: 2.209413144485133
Validation loss: 2.099310354701804
Epoch: 9| Step: 8
Training loss: 2.2849978661057673
Validation loss: 2.092837238965338
Epoch: 9| Step: 9
Training loss: 3.016149919907077
Validation loss: 2.1105333396803023
Epoch: 9| Step: 10
Training loss: 2.634184618458998
Validation loss: 2.095431697370256
Epoch: 9| Step: 11
Training loss: 3.4504330183646794
Validation loss: 2.13892209918762
Epoch: 9| Step: 12
Training loss: 1.6548565454918522
Validation loss: 2.0881745203267292
Epoch: 9| Step: 13
Training loss: 2.2803090911626462
Validation loss: 2.1196627130775187
Epoch: 9| Step: 14
Training loss: 2.4760270848618524
Validation loss: 2.1325814303559603
Epoch: 9| Step: 15
Training loss: 2.4101585252154476
Validation loss: 2.099223315024654
Epoch: 9| Step: 16
Training loss: 3.31282070694702
Validation loss: 2.118704372267922
Epoch: 9| Step: 17
Training loss: 2.6897624051981315
Validation loss: 2.144813545738199
Epoch: 9| Step: 18
Training loss: 1.9834950215551481
Validation loss: 2.1541834311248342
Epoch: 9| Step: 19
Training loss: 2.4432350572265533
Validation loss: 2.1566064182387223
Epoch: 89| Step: 0
Training loss: 2.9927628962403277
Validation loss: 2.1242121575606534
Epoch: 9| Step: 1
Training loss: 3.4972681555754277
Validation loss: 2.137489148762733
Epoch: 9| Step: 2
Training loss: 1.6435901549621192
Validation loss: 2.131201795472902
Epoch: 9| Step: 3
Training loss: 2.0437652027369624
Validation loss: 2.1196409359007955
Epoch: 9| Step: 4
Training loss: 2.838861308634694
Validation loss: 2.089821146273989
Epoch: 9| Step: 5
Training loss: 3.202888591695088
Validation loss: 2.125276420836147
Epoch: 9| Step: 6
Training loss: 2.0893509613580443
Validation loss: 2.1034897966814676
Epoch: 9| Step: 7
Training loss: 2.230779569384348
Validation loss: 2.131443526532179
Epoch: 9| Step: 8
Training loss: 2.479010013364671
Validation loss: 2.111783481599317
Epoch: 9| Step: 9
Training loss: 2.3529290065731145
Validation loss: 2.082232376044031
Epoch: 9| Step: 10
Training loss: 2.301619941942461
Validation loss: 2.153460419324499
Epoch: 9| Step: 11
Training loss: 2.866497237351392
Validation loss: 2.0987522150875404
Epoch: 9| Step: 12
Training loss: 2.23023068949722
Validation loss: 2.1372719267119695
Epoch: 9| Step: 13
Training loss: 2.38881500139732
Validation loss: 2.0882963883171635
Epoch: 9| Step: 14
Training loss: 2.4011419996590906
Validation loss: 2.120938035613613
Epoch: 9| Step: 15
Training loss: 2.371451688643955
Validation loss: 2.106062446383569
Epoch: 9| Step: 16
Training loss: 2.601426496186943
Validation loss: 2.1317760841689717
Epoch: 9| Step: 17
Training loss: 2.4400953511852723
Validation loss: 2.146082706327011
Epoch: 9| Step: 18
Training loss: 2.1950544429622605
Validation loss: 2.1535287658631046
Epoch: 9| Step: 19
Training loss: 3.2137771264633614
Validation loss: 2.139796218899699
Epoch: 90| Step: 0
Training loss: 2.3721121246057617
Validation loss: 2.112811331143396
Epoch: 9| Step: 1
Training loss: 2.8202500270359607
Validation loss: 2.1136693197528498
Epoch: 9| Step: 2
Training loss: 2.0353723802957893
Validation loss: 2.150979448813529
Epoch: 9| Step: 3
Training loss: 2.6103145712341105
Validation loss: 2.1454470224536544
Epoch: 9| Step: 4
Training loss: 2.3488926733839204
Validation loss: 2.1090035348226936
Epoch: 9| Step: 5
Training loss: 2.8230319028937414
Validation loss: 2.068155962273354
Epoch: 9| Step: 6
Training loss: 2.568754332601416
Validation loss: 2.11591282918376
Epoch: 9| Step: 7
Training loss: 2.5612827294093683
Validation loss: 2.1421220208889844
Epoch: 9| Step: 8
Training loss: 2.6207660862513493
Validation loss: 2.163316452789454
Epoch: 9| Step: 9
Training loss: 2.2509416093408796
Validation loss: 2.1657714591425736
Epoch: 9| Step: 10
Training loss: 2.184257283674847
Validation loss: 2.0894871883981834
Epoch: 9| Step: 11
Training loss: 2.767238426493771
Validation loss: 2.1129307488763454
Epoch: 9| Step: 12
Training loss: 3.0329679359881836
Validation loss: 2.142227672664753
Epoch: 9| Step: 13
Training loss: 3.2075655790598776
Validation loss: 2.163955444102122
Epoch: 9| Step: 14
Training loss: 2.80188077362303
Validation loss: 2.100332261858446
Epoch: 9| Step: 15
Training loss: 2.175008146774995
Validation loss: 2.1373400016669724
Epoch: 9| Step: 16
Training loss: 2.069439628419101
Validation loss: 2.131679268111032
Epoch: 9| Step: 17
Training loss: 2.209338792992528
Validation loss: 2.12991480410355
Epoch: 9| Step: 18
Training loss: 3.094851827448659
Validation loss: 2.1869485710911656
Epoch: 9| Step: 19
Training loss: 2.132533463889694
Validation loss: 2.087588229302959
Epoch: 91| Step: 0
Training loss: 2.1161001869165164
Validation loss: 2.125920272296382
Epoch: 9| Step: 1
Training loss: 2.3008154460133845
Validation loss: 2.12968048743079
Epoch: 9| Step: 2
Training loss: 2.4742151923435602
Validation loss: 2.1452742592261598
Epoch: 9| Step: 3
Training loss: 1.7381713832467274
Validation loss: 2.1193146152166635
Epoch: 9| Step: 4
Training loss: 2.505513976889994
Validation loss: 2.0973031841090877
Epoch: 9| Step: 5
Training loss: 3.4796485491021296
Validation loss: 2.1221260799291826
Epoch: 9| Step: 6
Training loss: 2.118356079571704
Validation loss: 2.1422213345591583
Epoch: 9| Step: 7
Training loss: 2.543149223896644
Validation loss: 2.1169510227694976
Epoch: 9| Step: 8
Training loss: 3.2928450845143553
Validation loss: 2.1164949745198642
Epoch: 9| Step: 9
Training loss: 3.3597407651987643
Validation loss: 2.1355264049825076
Epoch: 9| Step: 10
Training loss: 1.985907796161888
Validation loss: 2.0907200112931212
Epoch: 9| Step: 11
Training loss: 2.4956090513236124
Validation loss: 2.140634502663062
Epoch: 9| Step: 12
Training loss: 1.5173694756823144
Validation loss: 2.0948677846042174
Epoch: 9| Step: 13
Training loss: 2.3837488554705235
Validation loss: 2.1255032431836116
Epoch: 9| Step: 14
Training loss: 2.8468976050273995
Validation loss: 2.119688096252649
Epoch: 9| Step: 15
Training loss: 2.691752861304156
Validation loss: 2.154098974976273
Epoch: 9| Step: 16
Training loss: 2.682855540637384
Validation loss: 2.1491219665061165
Epoch: 9| Step: 17
Training loss: 2.2887633456930163
Validation loss: 2.1540813207764877
Epoch: 9| Step: 18
Training loss: 2.940128205806194
Validation loss: 2.148972295647597
Epoch: 9| Step: 19
Training loss: 2.3992272484000616
Validation loss: 2.1082682089301947
Epoch: 92| Step: 0
Training loss: 2.251883354330328
Validation loss: 2.13897322291986
Epoch: 9| Step: 1
Training loss: 2.7060083435561517
Validation loss: 2.136777304317197
Epoch: 9| Step: 2
Training loss: 2.8899576602461043
Validation loss: 2.1073701256552617
Epoch: 9| Step: 3
Training loss: 1.723916697695649
Validation loss: 2.158271755020317
Epoch: 9| Step: 4
Training loss: 2.9827547318553154
Validation loss: 2.1032755077735827
Epoch: 9| Step: 5
Training loss: 2.7360522548414794
Validation loss: 2.1036583935152726
Epoch: 9| Step: 6
Training loss: 2.4513362510248116
Validation loss: 2.13955914586087
Epoch: 9| Step: 7
Training loss: 2.4587665973485193
Validation loss: 2.1205008098246556
Epoch: 9| Step: 8
Training loss: 2.849605024306994
Validation loss: 2.137393249823181
Epoch: 9| Step: 9
Training loss: 2.2624755015021623
Validation loss: 2.124849026549562
Epoch: 9| Step: 10
Training loss: 2.5184492286591733
Validation loss: 2.152122337005492
Epoch: 9| Step: 11
Training loss: 1.925057110620459
Validation loss: 2.12368523889774
Epoch: 9| Step: 12
Training loss: 2.8401046696031744
Validation loss: 2.1525635011558237
Epoch: 9| Step: 13
Training loss: 2.5489836780538844
Validation loss: 2.1432669630854284
Epoch: 9| Step: 14
Training loss: 2.399439698619153
Validation loss: 2.1401159310939386
Epoch: 9| Step: 15
Training loss: 2.120123709901874
Validation loss: 2.1802713015619912
Epoch: 9| Step: 16
Training loss: 2.61564312818072
Validation loss: 2.150948755262379
Epoch: 9| Step: 17
Training loss: 2.522616509732659
Validation loss: 2.1554382846212055
Epoch: 9| Step: 18
Training loss: 2.9857066114617763
Validation loss: 2.103035345693443
Epoch: 9| Step: 19
Training loss: 2.3667473210663834
Validation loss: 2.11078319878698
Epoch: 93| Step: 0
Training loss: 2.610369098916965
Validation loss: 2.1093012697398836
Epoch: 9| Step: 1
Training loss: 2.524590952004912
Validation loss: 2.1492830332579076
Epoch: 9| Step: 2
Training loss: 2.5608649270909796
Validation loss: 2.1216336629531427
Epoch: 9| Step: 3
Training loss: 2.9618759077352084
Validation loss: 2.1386173272848876
Epoch: 9| Step: 4
Training loss: 2.4926704727998077
Validation loss: 2.128062841029948
Epoch: 9| Step: 5
Training loss: 2.3558706570144694
Validation loss: 2.1410373498067377
Epoch: 9| Step: 6
Training loss: 2.5092845173599785
Validation loss: 2.1593173635161675
Epoch: 9| Step: 7
Training loss: 2.1190038118278633
Validation loss: 2.142339812480441
Epoch: 9| Step: 8
Training loss: 2.4307038858353835
Validation loss: 2.1221945574610985
Epoch: 9| Step: 9
Training loss: 1.7561151744636356
Validation loss: 2.1016750879215413
Epoch: 9| Step: 10
Training loss: 2.4337137599886027
Validation loss: 2.13666737009442
Epoch: 9| Step: 11
Training loss: 2.678831269512886
Validation loss: 2.1381400350886106
Epoch: 9| Step: 12
Training loss: 2.1621322010355053
Validation loss: 2.0872591551583537
Epoch: 9| Step: 13
Training loss: 2.888581414447345
Validation loss: 2.1295008953760735
Epoch: 9| Step: 14
Training loss: 2.5872257400600547
Validation loss: 2.1188016045849634
Epoch: 9| Step: 15
Training loss: 2.1137997031839757
Validation loss: 2.137016959553484
Epoch: 9| Step: 16
Training loss: 2.2305369458570947
Validation loss: 2.1682420949563594
Epoch: 9| Step: 17
Training loss: 3.1662761715162375
Validation loss: 2.1490395016642547
Epoch: 9| Step: 18
Training loss: 3.061567982132082
Validation loss: 2.1692682241549686
Epoch: 9| Step: 19
Training loss: 2.8086887391306092
Validation loss: 2.1402803029394186
Epoch: 94| Step: 0
Training loss: 3.1934361253200327
Validation loss: 2.105752030519799
Epoch: 9| Step: 1
Training loss: 2.2676658120561894
Validation loss: 2.1391378600600395
Epoch: 9| Step: 2
Training loss: 2.6151790370884003
Validation loss: 2.1232905270247286
Epoch: 9| Step: 3
Training loss: 2.379714502793797
Validation loss: 2.126386990004983
Epoch: 9| Step: 4
Training loss: 1.5774877791377204
Validation loss: 2.137086697458993
Epoch: 9| Step: 5
Training loss: 3.2511025539287606
Validation loss: 2.1034538078106935
Epoch: 9| Step: 6
Training loss: 2.3562059150436987
Validation loss: 2.1240317248936273
Epoch: 9| Step: 7
Training loss: 2.676466092646546
Validation loss: 2.109583673526678
Epoch: 9| Step: 8
Training loss: 2.0677677277330964
Validation loss: 2.0797529004073128
Epoch: 9| Step: 9
Training loss: 2.6582747876487804
Validation loss: 2.1145443548455907
Epoch: 9| Step: 10
Training loss: 2.359453414725488
Validation loss: 2.1015857653679397
Epoch: 9| Step: 11
Training loss: 1.9209823396140024
Validation loss: 2.1038791629332954
Epoch: 9| Step: 12
Training loss: 2.4468715195125608
Validation loss: 2.1105960314874093
Epoch: 9| Step: 13
Training loss: 2.9144403043985703
Validation loss: 2.1130841396539233
Epoch: 9| Step: 14
Training loss: 2.9531991131883117
Validation loss: 2.088263183992145
Epoch: 9| Step: 15
Training loss: 2.423653620140956
Validation loss: 2.112720140133387
Epoch: 9| Step: 16
Training loss: 3.141401356254737
Validation loss: 2.056518115555064
Epoch: 9| Step: 17
Training loss: 2.17105021012702
Validation loss: 2.1144996005162002
Epoch: 9| Step: 18
Training loss: 2.336552669702932
Validation loss: 2.132832428418466
Epoch: 9| Step: 19
Training loss: 2.5538380928548703
Validation loss: 2.1449777726016843
Epoch: 95| Step: 0
Training loss: 2.3495851231668707
Validation loss: 2.1354350722671698
Epoch: 9| Step: 1
Training loss: 2.429257468287173
Validation loss: 2.096763577114985
Epoch: 9| Step: 2
Training loss: 2.4941947291875457
Validation loss: 2.1032104333064705
Epoch: 9| Step: 3
Training loss: 2.9474427793738602
Validation loss: 2.0902857702335775
Epoch: 9| Step: 4
Training loss: 1.8110784019969792
Validation loss: 2.1207078868727454
Epoch: 9| Step: 5
Training loss: 2.9258822944417524
Validation loss: 2.0943625882736105
Epoch: 9| Step: 6
Training loss: 2.6863723873271095
Validation loss: 2.097268940049084
Epoch: 9| Step: 7
Training loss: 2.1057247650253963
Validation loss: 2.0815886501097998
Epoch: 9| Step: 8
Training loss: 2.9569867431838843
Validation loss: 2.127705079754312
Epoch: 9| Step: 9
Training loss: 1.987182673427277
Validation loss: 2.12435192079242
Epoch: 9| Step: 10
Training loss: 2.7137211735976536
Validation loss: 2.0694167550217015
Epoch: 9| Step: 11
Training loss: 3.2172305770739484
Validation loss: 2.131883320451128
Epoch: 9| Step: 12
Training loss: 2.523481244632204
Validation loss: 2.101898386892232
Epoch: 9| Step: 13
Training loss: 2.474794159623649
Validation loss: 2.0730869800559057
Epoch: 9| Step: 14
Training loss: 2.620631715896484
Validation loss: 2.126398382247949
Epoch: 9| Step: 15
Training loss: 2.3895528545836004
Validation loss: 2.107323561268147
Epoch: 9| Step: 16
Training loss: 1.8274943902468392
Validation loss: 2.0948778504426486
Epoch: 9| Step: 17
Training loss: 3.073748735611428
Validation loss: 2.1124949480717667
Epoch: 9| Step: 18
Training loss: 2.785682831750831
Validation loss: 2.162344858705546
Epoch: 9| Step: 19
Training loss: 2.465979651411243
Validation loss: 2.1090273714228096
Epoch: 96| Step: 0
Training loss: 2.5099939858413927
Validation loss: 2.0797419572043245
Epoch: 9| Step: 1
Training loss: 3.5652241246634175
Validation loss: 2.1347114041307282
Epoch: 9| Step: 2
Training loss: 2.4558018942965987
Validation loss: 2.1331922872751634
Epoch: 9| Step: 3
Training loss: 2.693575888403621
Validation loss: 2.075171386464012
Epoch: 9| Step: 4
Training loss: 2.139729779019229
Validation loss: 2.0659189184046802
Epoch: 9| Step: 5
Training loss: 2.621812610997876
Validation loss: 2.1230846405038712
Epoch: 9| Step: 6
Training loss: 2.5337290927380067
Validation loss: 2.1202406704712513
Epoch: 9| Step: 7
Training loss: 2.1047189824865593
Validation loss: 2.140942992482084
Epoch: 9| Step: 8
Training loss: 2.6022739296819886
Validation loss: 2.133039948951382
Epoch: 9| Step: 9
Training loss: 2.4082130252483034
Validation loss: 2.098617996916837
Epoch: 9| Step: 10
Training loss: 2.1907548939372607
Validation loss: 2.0737016973644904
Epoch: 9| Step: 11
Training loss: 2.291952762662895
Validation loss: 2.122713342230055
Epoch: 9| Step: 12
Training loss: 2.4029327910982357
Validation loss: 2.1239778597746457
Epoch: 9| Step: 13
Training loss: 2.4397286228228827
Validation loss: 2.1044591654412206
Epoch: 9| Step: 14
Training loss: 2.778405781857587
Validation loss: 2.145679878089167
Epoch: 9| Step: 15
Training loss: 2.2342337183534626
Validation loss: 2.142489394933852
Epoch: 9| Step: 16
Training loss: 2.8714212451399423
Validation loss: 2.12650496782021
Epoch: 9| Step: 17
Training loss: 1.9451611318258109
Validation loss: 2.0762553226684024
Epoch: 9| Step: 18
Training loss: 2.395015400018736
Validation loss: 2.078831531183902
Epoch: 9| Step: 19
Training loss: 2.948045024615989
Validation loss: 2.1050787327718297
Epoch: 97| Step: 0
Training loss: 2.208520329553483
Validation loss: 2.072203059859507
Epoch: 9| Step: 1
Training loss: 3.101054190773875
Validation loss: 2.1122611532976134
Epoch: 9| Step: 2
Training loss: 2.756296059705851
Validation loss: 2.1595665741693866
Epoch: 9| Step: 3
Training loss: 2.6720664864794257
Validation loss: 2.108116744193423
Epoch: 9| Step: 4
Training loss: 2.8435304997168265
Validation loss: 2.0985240637299354
Epoch: 9| Step: 5
Training loss: 2.905794169456781
Validation loss: 2.122159116942215
Epoch: 9| Step: 6
Training loss: 2.354395987445239
Validation loss: 2.1191879843453565
Epoch: 9| Step: 7
Training loss: 2.9898442986305676
Validation loss: 2.1123571616940104
Epoch: 9| Step: 8
Training loss: 2.370026450351601
Validation loss: 2.1278549762729213
Epoch: 9| Step: 9
Training loss: 2.1585647763307274
Validation loss: 2.116695165992343
Epoch: 9| Step: 10
Training loss: 2.485952488286398
Validation loss: 2.1151196334085838
Epoch: 9| Step: 11
Training loss: 2.6957179552374266
Validation loss: 2.1200755903246713
Epoch: 9| Step: 12
Training loss: 2.2944689754234875
Validation loss: 2.1427699480405518
Epoch: 9| Step: 13
Training loss: 1.837065978919628
Validation loss: 2.1254251445750425
Epoch: 9| Step: 14
Training loss: 2.4191445987372497
Validation loss: 2.1058008669376935
Epoch: 9| Step: 15
Training loss: 2.2746155298678103
Validation loss: 2.140743491785629
Epoch: 9| Step: 16
Training loss: 2.1209672921773413
Validation loss: 2.1057169153863424
Epoch: 9| Step: 17
Training loss: 2.2192560612770977
Validation loss: 2.122209183399843
Epoch: 9| Step: 18
Training loss: 3.199320399121562
Validation loss: 2.1365462739540964
Epoch: 9| Step: 19
Training loss: 2.3870235067487795
Validation loss: 2.105340640472003
Epoch: 98| Step: 0
Training loss: 2.9126938784006224
Validation loss: 2.1021328824845122
Epoch: 9| Step: 1
Training loss: 2.3124626775255703
Validation loss: 2.1126201323522165
Epoch: 9| Step: 2
Training loss: 1.6359097249789303
Validation loss: 2.130786835898252
Epoch: 9| Step: 3
Training loss: 2.7030196858436133
Validation loss: 2.1306078116380585
Epoch: 9| Step: 4
Training loss: 3.0488816133800976
Validation loss: 2.1412076064954912
Epoch: 9| Step: 5
Training loss: 3.120765563745124
Validation loss: 2.1860129612366204
Epoch: 9| Step: 6
Training loss: 2.6545720803337587
Validation loss: 2.1131309044607187
Epoch: 9| Step: 7
Training loss: 3.0056983552652516
Validation loss: 2.1534904983525576
Epoch: 9| Step: 8
Training loss: 2.005487067596273
Validation loss: 2.1217515360822667
Epoch: 9| Step: 9
Training loss: 2.214675816219445
Validation loss: 2.1161723798475855
Epoch: 9| Step: 10
Training loss: 2.6713068843313152
Validation loss: 2.1311262135517577
Epoch: 9| Step: 11
Training loss: 2.4095854987628864
Validation loss: 2.1249247659181596
Epoch: 9| Step: 12
Training loss: 2.647269202268361
Validation loss: 2.1120343667052666
Epoch: 9| Step: 13
Training loss: 2.1011204591450463
Validation loss: 2.1287290147960554
Epoch: 9| Step: 14
Training loss: 2.5216657246825114
Validation loss: 2.11789191421324
Epoch: 9| Step: 15
Training loss: 1.8751588118371723
Validation loss: 2.138598849092884
Epoch: 9| Step: 16
Training loss: 2.222595750357414
Validation loss: 2.1076444222544137
Epoch: 9| Step: 17
Training loss: 2.3509218477526477
Validation loss: 2.1431978298557297
Epoch: 9| Step: 18
Training loss: 2.8075113770822533
Validation loss: 2.116979442276212
Epoch: 9| Step: 19
Training loss: 2.99988476214014
Validation loss: 2.1057331374390893
Epoch: 99| Step: 0
Training loss: 2.6565336188198185
Validation loss: 2.15193834646429
Epoch: 9| Step: 1
Training loss: 2.2959993730471084
Validation loss: 2.1154705716908295
Epoch: 9| Step: 2
Training loss: 1.9892450481112016
Validation loss: 2.116991475807474
Epoch: 9| Step: 3
Training loss: 2.7721942532830903
Validation loss: 2.0941979581577144
Epoch: 9| Step: 4
Training loss: 2.825602549881611
Validation loss: 2.112460033625179
Epoch: 9| Step: 5
Training loss: 3.032161457634401
Validation loss: 2.123258121188185
Epoch: 9| Step: 6
Training loss: 2.59179227551165
Validation loss: 2.08221894120151
Epoch: 9| Step: 7
Training loss: 2.556719890207933
Validation loss: 2.1189945073942877
Epoch: 9| Step: 8
Training loss: 2.189400964093486
Validation loss: 2.1177141082859756
Epoch: 9| Step: 9
Training loss: 2.727450338273422
Validation loss: 2.1262355425449186
Epoch: 9| Step: 10
Training loss: 2.8331523912285106
Validation loss: 2.118566569279565
Epoch: 9| Step: 11
Training loss: 1.9036054559087991
Validation loss: 2.1212742159016886
Epoch: 9| Step: 12
Training loss: 2.0289041912081633
Validation loss: 2.1087283067064777
Epoch: 9| Step: 13
Training loss: 2.154005126011947
Validation loss: 2.1277487416418444
Epoch: 9| Step: 14
Training loss: 2.987560868540975
Validation loss: 2.125385094137164
Epoch: 9| Step: 15
Training loss: 2.696098588946324
Validation loss: 2.0919079472193878
Epoch: 9| Step: 16
Training loss: 2.2577009866492923
Validation loss: 2.079965077063524
Epoch: 9| Step: 17
Training loss: 1.9669646993668437
Validation loss: 2.0992346079432083
Epoch: 9| Step: 18
Training loss: 2.8244332513038004
Validation loss: 2.113552961348448
Epoch: 9| Step: 19
Training loss: 2.7349557314398694
Validation loss: 2.1279158569087233
Epoch: 100| Step: 0
Training loss: 2.978897260386711
Validation loss: 2.1192186321112554
Epoch: 9| Step: 1
Training loss: 3.464531335002733
Validation loss: 2.156726763279357
Epoch: 9| Step: 2
Training loss: 2.3476414227771167
Validation loss: 2.0881275834115156
Epoch: 9| Step: 3
Training loss: 2.356062629191104
Validation loss: 2.1258145318309234
Epoch: 9| Step: 4
Training loss: 2.1238141958717636
Validation loss: 2.1068638258152927
Epoch: 9| Step: 5
Training loss: 2.8221262333116153
Validation loss: 2.090022507235019
Epoch: 9| Step: 6
Training loss: 2.497213336427594
Validation loss: 2.1157998365027626
Epoch: 9| Step: 7
Training loss: 2.168984444998175
Validation loss: 2.12243227913042
Epoch: 9| Step: 8
Training loss: 2.69230984383801
Validation loss: 2.1309954532899793
Epoch: 9| Step: 9
Training loss: 1.5962816961452908
Validation loss: 2.1219129646143196
Epoch: 9| Step: 10
Training loss: 2.153627653095184
Validation loss: 2.0785288947423104
Epoch: 9| Step: 11
Training loss: 2.580971181372374
Validation loss: 2.1434933634107294
Epoch: 9| Step: 12
Training loss: 2.5341190985049846
Validation loss: 2.1083144710861
Epoch: 9| Step: 13
Training loss: 2.7186815976713055
Validation loss: 2.137821603550802
Epoch: 9| Step: 14
Training loss: 2.565494183679655
Validation loss: 2.1497474629580022
Epoch: 9| Step: 15
Training loss: 2.6760456038154414
Validation loss: 2.1100262969743255
Epoch: 9| Step: 16
Training loss: 2.6023301833390926
Validation loss: 2.131580416588066
Epoch: 9| Step: 17
Training loss: 1.911153458925746
Validation loss: 2.094368518886125
Epoch: 9| Step: 18
Training loss: 2.454429911132047
Validation loss: 2.114542558868388
Epoch: 9| Step: 19
Training loss: 2.9428875803861443
Validation loss: 2.1120097971500553
