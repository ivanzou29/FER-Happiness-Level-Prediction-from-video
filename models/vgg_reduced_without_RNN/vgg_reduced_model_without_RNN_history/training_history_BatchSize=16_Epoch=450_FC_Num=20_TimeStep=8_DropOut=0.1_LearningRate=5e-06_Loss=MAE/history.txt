Epoch: 1| Step: 0
Training loss: 5.50595760345459
Validation loss: 6.1597630977630615

Epoch: 6| Step: 1
Training loss: 6.8618574142456055
Validation loss: 6.136544068654378

Epoch: 6| Step: 2
Training loss: 5.679757118225098
Validation loss: 6.119610230127971

Epoch: 6| Step: 3
Training loss: 5.778144359588623
Validation loss: 6.099551359812419

Epoch: 6| Step: 4
Training loss: 6.405488014221191
Validation loss: 6.080830494562785

Epoch: 6| Step: 5
Training loss: 6.516933441162109
Validation loss: 6.055979569753011

Epoch: 6| Step: 6
Training loss: 6.611722946166992
Validation loss: 6.037595113118489

Epoch: 6| Step: 7
Training loss: 6.177349090576172
Validation loss: 6.017532666524251

Epoch: 6| Step: 8
Training loss: 5.755618095397949
Validation loss: 5.994667609532674

Epoch: 6| Step: 9
Training loss: 6.535499572753906
Validation loss: 5.975549141565959

Epoch: 6| Step: 10
Training loss: 5.32961893081665
Validation loss: 5.95348318417867

Epoch: 6| Step: 11
Training loss: 6.45162296295166
Validation loss: 5.934419870376587

Epoch: 6| Step: 12
Training loss: 5.787181854248047
Validation loss: 5.910855849583943

Epoch: 6| Step: 13
Training loss: 5.925329208374023
Validation loss: 5.885592222213745

Epoch: 2| Step: 0
Training loss: 5.420839786529541
Validation loss: 5.862388928731282

Epoch: 6| Step: 1
Training loss: 6.380685806274414
Validation loss: 5.839916467666626

Epoch: 6| Step: 2
Training loss: 5.502564430236816
Validation loss: 5.812386512756348

Epoch: 6| Step: 3
Training loss: 6.04998254776001
Validation loss: 5.783968448638916

Epoch: 6| Step: 4
Training loss: 6.4169511795043945
Validation loss: 5.757153590520223

Epoch: 6| Step: 5
Training loss: 5.6228928565979
Validation loss: 5.730569998423259

Epoch: 6| Step: 6
Training loss: 6.380558013916016
Validation loss: 5.698245922724406

Epoch: 6| Step: 7
Training loss: 5.79988956451416
Validation loss: 5.667616844177246

Epoch: 6| Step: 8
Training loss: 5.639308929443359
Validation loss: 5.63385287920634

Epoch: 6| Step: 9
Training loss: 4.632289886474609
Validation loss: 5.601156393686931

Epoch: 6| Step: 10
Training loss: 6.082487106323242
Validation loss: 5.562883297602336

Epoch: 6| Step: 11
Training loss: 5.7255024909973145
Validation loss: 5.528850714365642

Epoch: 6| Step: 12
Training loss: 5.031002998352051
Validation loss: 5.491207440694173

Epoch: 6| Step: 13
Training loss: 5.629203796386719
Validation loss: 5.451522588729858

Epoch: 3| Step: 0
Training loss: 6.4321184158325195
Validation loss: 5.407354354858398

Epoch: 6| Step: 1
Training loss: 4.995243072509766
Validation loss: 5.3632283210754395

Epoch: 6| Step: 2
Training loss: 5.507071018218994
Validation loss: 5.311904589335124

Epoch: 6| Step: 3
Training loss: 4.154618740081787
Validation loss: 5.265610138575236

Epoch: 6| Step: 4
Training loss: 4.469742298126221
Validation loss: 5.211451689402263

Epoch: 6| Step: 5
Training loss: 5.264805793762207
Validation loss: 5.164191166559855

Epoch: 6| Step: 6
Training loss: 5.834283828735352
Validation loss: 5.1059393882751465

Epoch: 6| Step: 7
Training loss: 6.837862968444824
Validation loss: 5.051868756612142

Epoch: 6| Step: 8
Training loss: 5.300675868988037
Validation loss: 4.990346074104309

Epoch: 6| Step: 9
Training loss: 4.614002704620361
Validation loss: 4.926774342854817

Epoch: 6| Step: 10
Training loss: 5.277203559875488
Validation loss: 4.857629934946696

Epoch: 6| Step: 11
Training loss: 4.4313249588012695
Validation loss: 4.783293803532918

Epoch: 6| Step: 12
Training loss: 5.208650588989258
Validation loss: 4.710290352503459

Epoch: 6| Step: 13
Training loss: 3.4433226585388184
Validation loss: 4.646276315053304

Epoch: 4| Step: 0
Training loss: 5.294139862060547
Validation loss: 4.559818585713704

Epoch: 6| Step: 1
Training loss: 5.47646427154541
Validation loss: 4.475497364997864

Epoch: 6| Step: 2
Training loss: 4.878821849822998
Validation loss: 4.3946770032246905

Epoch: 6| Step: 3
Training loss: 4.510308265686035
Validation loss: 4.308655182520549

Epoch: 6| Step: 4
Training loss: 4.548898220062256
Validation loss: 4.208959937095642

Epoch: 6| Step: 5
Training loss: 3.27486515045166
Validation loss: 4.124472697575887

Epoch: 6| Step: 6
Training loss: 3.8045310974121094
Validation loss: 4.037860592206319

Epoch: 6| Step: 7
Training loss: 3.7177083492279053
Validation loss: 3.9422099590301514

Epoch: 6| Step: 8
Training loss: 4.014642238616943
Validation loss: 3.8587761322657266

Epoch: 6| Step: 9
Training loss: 3.3877549171447754
Validation loss: 3.7479074398676553

Epoch: 6| Step: 10
Training loss: 4.277775287628174
Validation loss: 3.666869600613912

Epoch: 6| Step: 11
Training loss: 2.991478443145752
Validation loss: 3.5556090275446572

Epoch: 6| Step: 12
Training loss: 3.3265292644500732
Validation loss: 3.453992009162903

Epoch: 6| Step: 13
Training loss: 3.2070045471191406
Validation loss: 3.3617449601491294

Epoch: 5| Step: 0
Training loss: 2.4432568550109863
Validation loss: 3.2476271390914917

Epoch: 6| Step: 1
Training loss: 3.700826644897461
Validation loss: 3.1485678354899087

Epoch: 6| Step: 2
Training loss: 3.43981671333313
Validation loss: 3.0670445362726846

Epoch: 6| Step: 3
Training loss: 3.574852466583252
Validation loss: 2.968401392300924

Epoch: 6| Step: 4
Training loss: 3.122389793395996
Validation loss: 2.860858956972758

Epoch: 6| Step: 5
Training loss: 2.793060779571533
Validation loss: 2.752995491027832

Epoch: 6| Step: 6
Training loss: 2.8420848846435547
Validation loss: 2.664457400639852

Epoch: 6| Step: 7
Training loss: 2.6218364238739014
Validation loss: 2.578209479649862

Epoch: 6| Step: 8
Training loss: 2.5296895503997803
Validation loss: 2.5005924701690674

Epoch: 6| Step: 9
Training loss: 1.782447099685669
Validation loss: 2.4350075324376426

Epoch: 6| Step: 10
Training loss: 1.907358169555664
Validation loss: 2.3631472984949746

Epoch: 6| Step: 11
Training loss: 2.3566203117370605
Validation loss: 2.346108357111613

Epoch: 6| Step: 12
Training loss: 2.2045109272003174
Validation loss: 2.3028492530186973

Epoch: 6| Step: 13
Training loss: 1.4864898920059204
Validation loss: 2.288101394971212

Epoch: 6| Step: 0
Training loss: 2.5365467071533203
Validation loss: 2.3155049284299216

Epoch: 6| Step: 1
Training loss: 2.5623278617858887
Validation loss: 2.289555033047994

Epoch: 6| Step: 2
Training loss: 1.3646043539047241
Validation loss: 2.3274953762690225

Epoch: 6| Step: 3
Training loss: 2.7846803665161133
Validation loss: 2.3760379552841187

Epoch: 6| Step: 4
Training loss: 1.9538254737854004
Validation loss: 2.3993693192799888

Epoch: 6| Step: 5
Training loss: 2.3006980419158936
Validation loss: 2.406651576360067

Epoch: 6| Step: 6
Training loss: 2.409341335296631
Validation loss: 2.4360990126927695

Epoch: 6| Step: 7
Training loss: 2.3425464630126953
Validation loss: 2.4613450368245444

Epoch: 6| Step: 8
Training loss: 2.6509366035461426
Validation loss: 2.4389822681744895

Epoch: 6| Step: 9
Training loss: 2.4016385078430176
Validation loss: 2.414130906263987

Epoch: 6| Step: 10
Training loss: 3.13002347946167
Validation loss: 2.4222415486971536

Epoch: 6| Step: 11
Training loss: 1.5682563781738281
Validation loss: 2.378009796142578

Epoch: 6| Step: 12
Training loss: 1.782485842704773
Validation loss: 2.31031197309494

Epoch: 6| Step: 13
Training loss: 2.774860382080078
Validation loss: 2.290951430797577

Epoch: 7| Step: 0
Training loss: 2.500598192214966
Validation loss: 2.3329896132151284

Epoch: 6| Step: 1
Training loss: 1.8329344987869263
Validation loss: 2.2628591855367026

Epoch: 6| Step: 2
Training loss: 1.592280387878418
Validation loss: 2.314990242322286

Epoch: 6| Step: 3
Training loss: 2.290182113647461
Validation loss: 2.289108951886495

Epoch: 6| Step: 4
Training loss: 2.71740984916687
Validation loss: 2.2820972402890525

Epoch: 6| Step: 5
Training loss: 2.672752618789673
Validation loss: 2.3009225328763327

Epoch: 6| Step: 6
Training loss: 2.005127429962158
Validation loss: 2.3102736473083496

Epoch: 6| Step: 7
Training loss: 2.1590447425842285
Validation loss: 2.33441952864329

Epoch: 6| Step: 8
Training loss: 2.184828281402588
Validation loss: 2.3285094102223716

Epoch: 6| Step: 9
Training loss: 2.3681893348693848
Validation loss: 2.2956124544143677

Epoch: 6| Step: 10
Training loss: 2.064765453338623
Validation loss: 2.3135510285695395

Epoch: 6| Step: 11
Training loss: 2.465420961380005
Validation loss: 2.3219067653020224

Epoch: 6| Step: 12
Training loss: 2.49564528465271
Validation loss: 2.307029883066813

Epoch: 6| Step: 13
Training loss: 2.926677703857422
Validation loss: 2.302346626917521

Epoch: 8| Step: 0
Training loss: 2.1795949935913086
Validation loss: 2.266518851121267

Epoch: 6| Step: 1
Training loss: 1.7800346612930298
Validation loss: 2.2771650751431785

Epoch: 6| Step: 2
Training loss: 2.6654164791107178
Validation loss: 2.302023708820343

Epoch: 6| Step: 3
Training loss: 2.4190080165863037
Validation loss: 2.253739515940348

Epoch: 6| Step: 4
Training loss: 2.4203882217407227
Validation loss: 2.2764413754145303

Epoch: 6| Step: 5
Training loss: 2.682866096496582
Validation loss: 2.307662049929301

Epoch: 6| Step: 6
Training loss: 1.6737232208251953
Validation loss: 2.2538556655248008

Epoch: 6| Step: 7
Training loss: 1.9496302604675293
Validation loss: 2.2849756876627603

Epoch: 6| Step: 8
Training loss: 2.5456314086914062
Validation loss: 2.254183014233907

Epoch: 6| Step: 9
Training loss: 2.530987501144409
Validation loss: 2.2718902826309204

Epoch: 6| Step: 10
Training loss: 1.7811108827590942
Validation loss: 2.2962187925974527

Epoch: 6| Step: 11
Training loss: 2.5381851196289062
Validation loss: 2.2729647159576416

Epoch: 6| Step: 12
Training loss: 1.9886691570281982
Validation loss: 2.261088490486145

Epoch: 6| Step: 13
Training loss: 1.8892221450805664
Validation loss: 2.26618500550588

Epoch: 9| Step: 0
Training loss: 2.3357088565826416
Validation loss: 2.277354081471761

Epoch: 6| Step: 1
Training loss: 2.5116019248962402
Validation loss: 2.263825297355652

Epoch: 6| Step: 2
Training loss: 1.947236180305481
Validation loss: 2.277092218399048

Epoch: 6| Step: 3
Training loss: 2.0789527893066406
Validation loss: 2.212891081968943

Epoch: 6| Step: 4
Training loss: 1.9656996726989746
Validation loss: 2.2492905060450235

Epoch: 6| Step: 5
Training loss: 2.0324718952178955
Validation loss: 2.27313764890035

Epoch: 6| Step: 6
Training loss: 2.2828593254089355
Validation loss: 2.2874473333358765

Epoch: 6| Step: 7
Training loss: 2.5291967391967773
Validation loss: 2.246443510055542

Epoch: 6| Step: 8
Training loss: 2.0745301246643066
Validation loss: 2.250457684199015

Epoch: 6| Step: 9
Training loss: 2.413053512573242
Validation loss: 2.2820911010106406

Epoch: 6| Step: 10
Training loss: 1.7355839014053345
Validation loss: 2.2546284596125283

Epoch: 6| Step: 11
Training loss: 2.671372413635254
Validation loss: 2.2712666591008506

Epoch: 6| Step: 12
Training loss: 2.62105655670166
Validation loss: 2.2347353100776672

Epoch: 6| Step: 13
Training loss: 1.8098642826080322
Validation loss: 2.2396023869514465

Epoch: 10| Step: 0
Training loss: 1.9409538507461548
Validation loss: 2.273960073788961

Epoch: 6| Step: 1
Training loss: 1.8412925004959106
Validation loss: 2.248078485329946

Epoch: 6| Step: 2
Training loss: 2.662198543548584
Validation loss: 2.215595861275991

Epoch: 6| Step: 3
Training loss: 1.967495083808899
Validation loss: 2.2666700879732766

Epoch: 6| Step: 4
Training loss: 2.3213772773742676
Validation loss: 2.2899343570073447

Epoch: 6| Step: 5
Training loss: 2.79823637008667
Validation loss: 2.2332706451416016

Epoch: 6| Step: 6
Training loss: 2.311514139175415
Validation loss: 2.2288285891215005

Epoch: 6| Step: 7
Training loss: 2.0150809288024902
Validation loss: 2.2311080495516458

Epoch: 6| Step: 8
Training loss: 2.071021795272827
Validation loss: 2.2275319695472717

Epoch: 6| Step: 9
Training loss: 2.3111581802368164
Validation loss: 2.250809053579966

Epoch: 6| Step: 10
Training loss: 2.2377119064331055
Validation loss: 2.2434675892194114

Epoch: 6| Step: 11
Training loss: 1.8884321451187134
Validation loss: 2.2461538116137185

Epoch: 6| Step: 12
Training loss: 2.349954128265381
Validation loss: 2.232739965120951

Epoch: 6| Step: 13
Training loss: 1.895301342010498
Validation loss: 2.236465275287628

Epoch: 11| Step: 0
Training loss: 2.048741340637207
Validation loss: 2.242841343084971

Epoch: 6| Step: 1
Training loss: 2.142543315887451
Validation loss: 2.207042614618937

Epoch: 6| Step: 2
Training loss: 3.1706604957580566
Validation loss: 2.2175633907318115

Epoch: 6| Step: 3
Training loss: 2.08746600151062
Validation loss: 2.2287460366884866

Epoch: 6| Step: 4
Training loss: 2.1927173137664795
Validation loss: 2.260180572668711

Epoch: 6| Step: 5
Training loss: 2.1367430686950684
Validation loss: 2.236546496550242

Epoch: 6| Step: 6
Training loss: 1.7719154357910156
Validation loss: 2.2052663564682007

Epoch: 6| Step: 7
Training loss: 2.026137351989746
Validation loss: 2.2265875538190207

Epoch: 6| Step: 8
Training loss: 2.4536945819854736
Validation loss: 2.212710738182068

Epoch: 6| Step: 9
Training loss: 2.520678997039795
Validation loss: 2.2309130430221558

Epoch: 6| Step: 10
Training loss: 1.9676377773284912
Validation loss: 2.2038617531458535

Epoch: 6| Step: 11
Training loss: 1.8908679485321045
Validation loss: 2.2358556191126504

Epoch: 6| Step: 12
Training loss: 1.885523796081543
Validation loss: 2.216155449549357

Epoch: 6| Step: 13
Training loss: 2.380098819732666
Validation loss: 2.1913941701253257

Epoch: 12| Step: 0
Training loss: 1.7438812255859375
Validation loss: 2.1769720713297525

Epoch: 6| Step: 1
Training loss: 1.5784012079238892
Validation loss: 2.205838123957316

Epoch: 6| Step: 2
Training loss: 1.85076904296875
Validation loss: 2.215333104133606

Epoch: 6| Step: 3
Training loss: 2.3506057262420654
Validation loss: 2.229004919528961

Epoch: 6| Step: 4
Training loss: 2.8346691131591797
Validation loss: 2.2138814330101013

Epoch: 6| Step: 5
Training loss: 1.7404358386993408
Validation loss: 2.185258388519287

Epoch: 6| Step: 6
Training loss: 2.133589744567871
Validation loss: 2.237937410672506

Epoch: 6| Step: 7
Training loss: 2.2870779037475586
Validation loss: 2.203931709130605

Epoch: 6| Step: 8
Training loss: 1.7029293775558472
Validation loss: 2.213106691837311

Epoch: 6| Step: 9
Training loss: 1.7511889934539795
Validation loss: 2.1952978571256003

Epoch: 6| Step: 10
Training loss: 1.9688663482666016
Validation loss: 2.2274872859319053

Epoch: 6| Step: 11
Training loss: 2.3126983642578125
Validation loss: 2.214394728342692

Epoch: 6| Step: 12
Training loss: 2.258800506591797
Validation loss: 2.204585631688436

Epoch: 6| Step: 13
Training loss: 3.3594019412994385
Validation loss: 2.2446494897206626

Epoch: 13| Step: 0
Training loss: 2.8614768981933594
Validation loss: 2.186312814553579

Epoch: 6| Step: 1
Training loss: 1.683255910873413
Validation loss: 2.186045209566752

Epoch: 6| Step: 2
Training loss: 2.0204925537109375
Validation loss: 2.214457094669342

Epoch: 6| Step: 3
Training loss: 1.860984206199646
Validation loss: 2.2308599750200906

Epoch: 6| Step: 4
Training loss: 1.8488246202468872
Validation loss: 2.229652206103007

Epoch: 6| Step: 5
Training loss: 2.875885486602783
Validation loss: 2.216277281443278

Epoch: 6| Step: 6
Training loss: 2.267293930053711
Validation loss: 2.1854803562164307

Epoch: 6| Step: 7
Training loss: 1.8727004528045654
Validation loss: 2.1968931953112283

Epoch: 6| Step: 8
Training loss: 2.172559976577759
Validation loss: 2.1585657795270285

Epoch: 6| Step: 9
Training loss: 1.4090425968170166
Validation loss: 2.1882039308547974

Epoch: 6| Step: 10
Training loss: 2.2351927757263184
Validation loss: 2.178810477256775

Epoch: 6| Step: 11
Training loss: 2.129284381866455
Validation loss: 2.184048056602478

Epoch: 6| Step: 12
Training loss: 2.8635826110839844
Validation loss: 2.2034222880999246

Epoch: 6| Step: 13
Training loss: 1.865654468536377
Validation loss: 2.167326827843984

Epoch: 14| Step: 0
Training loss: 2.6543936729431152
Validation loss: 2.163051108519236

Epoch: 6| Step: 1
Training loss: 1.8602932691574097
Validation loss: 2.152867575486501

Epoch: 6| Step: 2
Training loss: 1.5040063858032227
Validation loss: 2.1826738516489663

Epoch: 6| Step: 3
Training loss: 2.1409430503845215
Validation loss: 2.215201755364736

Epoch: 6| Step: 4
Training loss: 2.8569138050079346
Validation loss: 2.20326566696167

Epoch: 6| Step: 5
Training loss: 1.9489998817443848
Validation loss: 2.1880083084106445

Epoch: 6| Step: 6
Training loss: 2.1552658081054688
Validation loss: 2.152589817841848

Epoch: 6| Step: 7
Training loss: 2.819821357727051
Validation loss: 2.1788087089856467

Epoch: 6| Step: 8
Training loss: 1.5005217790603638
Validation loss: 2.1664235989252725

Epoch: 6| Step: 9
Training loss: 2.0404930114746094
Validation loss: 2.121402084827423

Epoch: 6| Step: 10
Training loss: 2.114105224609375
Validation loss: 2.166127026081085

Epoch: 6| Step: 11
Training loss: 2.2385683059692383
Validation loss: 2.1917645732561746

Epoch: 6| Step: 12
Training loss: 1.7464220523834229
Validation loss: 2.1697839895884194

Epoch: 6| Step: 13
Training loss: 1.9293830394744873
Validation loss: 2.1777873635292053

Epoch: 15| Step: 0
Training loss: 2.0642809867858887
Validation loss: 2.178026497364044

Epoch: 6| Step: 1
Training loss: 1.6936296224594116
Validation loss: 2.167773644129435

Epoch: 6| Step: 2
Training loss: 1.675152063369751
Validation loss: 2.14377494653066

Epoch: 6| Step: 3
Training loss: 2.51132869720459
Validation loss: 2.1707783142725625

Epoch: 6| Step: 4
Training loss: 2.5457825660705566
Validation loss: 2.1874512831370034

Epoch: 6| Step: 5
Training loss: 1.81669020652771
Validation loss: 2.185665567715963

Epoch: 6| Step: 6
Training loss: 2.1349024772644043
Validation loss: 2.1536311705907187

Epoch: 6| Step: 7
Training loss: 2.342799186706543
Validation loss: 2.1980449755986533

Epoch: 6| Step: 8
Training loss: 2.8794758319854736
Validation loss: 2.175046463807424

Epoch: 6| Step: 9
Training loss: 1.6012520790100098
Validation loss: 2.1913470029830933

Epoch: 6| Step: 10
Training loss: 1.9194998741149902
Validation loss: 2.1998725732167563

Epoch: 6| Step: 11
Training loss: 2.0574049949645996
Validation loss: 2.1468576391537986

Epoch: 6| Step: 12
Training loss: 2.1214659214019775
Validation loss: 2.139202296733856

Epoch: 6| Step: 13
Training loss: 2.2885398864746094
Validation loss: 2.164102633794149

Epoch: 16| Step: 0
Training loss: 1.7670958042144775
Validation loss: 2.1649532516797385

Epoch: 6| Step: 1
Training loss: 1.858142614364624
Validation loss: 2.1658314069112143

Epoch: 6| Step: 2
Training loss: 2.1290440559387207
Validation loss: 2.1527703205744424

Epoch: 6| Step: 3
Training loss: 2.3070216178894043
Validation loss: 2.178213616212209

Epoch: 6| Step: 4
Training loss: 2.625049114227295
Validation loss: 2.1795137325922647

Epoch: 6| Step: 5
Training loss: 1.7346147298812866
Validation loss: 2.167837977409363

Epoch: 6| Step: 6
Training loss: 1.9486228227615356
Validation loss: 2.161813656489054

Epoch: 6| Step: 7
Training loss: 1.8632919788360596
Validation loss: 2.173220078150431

Epoch: 6| Step: 8
Training loss: 2.4343762397766113
Validation loss: 2.1479248801867166

Epoch: 6| Step: 9
Training loss: 2.2826406955718994
Validation loss: 2.1543282667795816

Epoch: 6| Step: 10
Training loss: 1.8922637701034546
Validation loss: 2.1475452184677124

Epoch: 6| Step: 11
Training loss: 2.186326503753662
Validation loss: 2.152050793170929

Epoch: 6| Step: 12
Training loss: 2.207326889038086
Validation loss: 2.1388357083002725

Epoch: 6| Step: 13
Training loss: 2.135061740875244
Validation loss: 2.1703540881474814

Epoch: 17| Step: 0
Training loss: 2.2992725372314453
Validation loss: 2.1523163517316184

Epoch: 6| Step: 1
Training loss: 1.6110386848449707
Validation loss: 2.1281197468439736

Epoch: 6| Step: 2
Training loss: 2.369706153869629
Validation loss: 2.1480542421340942

Epoch: 6| Step: 3
Training loss: 1.7657158374786377
Validation loss: 2.157253543535868

Epoch: 6| Step: 4
Training loss: 2.1668009757995605
Validation loss: 2.140430748462677

Epoch: 6| Step: 5
Training loss: 1.9821445941925049
Validation loss: 2.1055503487586975

Epoch: 6| Step: 6
Training loss: 2.2746164798736572
Validation loss: 2.161633094151815

Epoch: 6| Step: 7
Training loss: 2.044710874557495
Validation loss: 2.1594793796539307

Epoch: 6| Step: 8
Training loss: 1.7690021991729736
Validation loss: 2.127167363961538

Epoch: 6| Step: 9
Training loss: 1.838260293006897
Validation loss: 2.143416166305542

Epoch: 6| Step: 10
Training loss: 2.289358615875244
Validation loss: 2.121513545513153

Epoch: 6| Step: 11
Training loss: 2.3622806072235107
Validation loss: 2.1260898113250732

Epoch: 6| Step: 12
Training loss: 2.289057970046997
Validation loss: 2.151048243045807

Epoch: 6| Step: 13
Training loss: 2.117947816848755
Validation loss: 2.115813136100769

Epoch: 18| Step: 0
Training loss: 2.212345600128174
Validation loss: 2.1216501196225486

Epoch: 6| Step: 1
Training loss: 1.6767138242721558
Validation loss: 2.117357691129049

Epoch: 6| Step: 2
Training loss: 2.2969532012939453
Validation loss: 2.1345449686050415

Epoch: 6| Step: 3
Training loss: 1.9391356706619263
Validation loss: 2.1332571109135947

Epoch: 6| Step: 4
Training loss: 2.7154288291931152
Validation loss: 2.104245940844218

Epoch: 6| Step: 5
Training loss: 1.8953661918640137
Validation loss: 2.143079161643982

Epoch: 6| Step: 6
Training loss: 2.241209030151367
Validation loss: 2.1457608143488565

Epoch: 6| Step: 7
Training loss: 1.5788962841033936
Validation loss: 2.140641371409098

Epoch: 6| Step: 8
Training loss: 2.4457848072052
Validation loss: 2.1206522981325784

Epoch: 6| Step: 9
Training loss: 1.9263107776641846
Validation loss: 2.1322198112805686

Epoch: 6| Step: 10
Training loss: 1.6787468194961548
Validation loss: 2.1436789631843567

Epoch: 6| Step: 11
Training loss: 1.9446144104003906
Validation loss: 2.164505958557129

Epoch: 6| Step: 12
Training loss: 2.8840694427490234
Validation loss: 2.1204803784688315

Epoch: 6| Step: 13
Training loss: 1.8751425743103027
Validation loss: 2.1389745473861694

Epoch: 19| Step: 0
Training loss: 2.2524704933166504
Validation loss: 2.1109984715779624

Epoch: 6| Step: 1
Training loss: 2.084339141845703
Validation loss: 2.158574938774109

Epoch: 6| Step: 2
Training loss: 2.4025869369506836
Validation loss: 2.174748877684275

Epoch: 6| Step: 3
Training loss: 1.8811211585998535
Validation loss: 2.1017908255259194

Epoch: 6| Step: 4
Training loss: 1.7198797464370728
Validation loss: 2.111445983250936

Epoch: 6| Step: 5
Training loss: 1.4278125762939453
Validation loss: 2.1108821630477905

Epoch: 6| Step: 6
Training loss: 2.0025672912597656
Validation loss: 2.1022755106290183

Epoch: 6| Step: 7
Training loss: 1.8632657527923584
Validation loss: 2.1134440104166665

Epoch: 6| Step: 8
Training loss: 1.918581247329712
Validation loss: 2.0935616890589395

Epoch: 6| Step: 9
Training loss: 2.128917694091797
Validation loss: 2.109150250752767

Epoch: 6| Step: 10
Training loss: 1.9143414497375488
Validation loss: 2.1157544453938804

Epoch: 6| Step: 11
Training loss: 3.1334967613220215
Validation loss: 2.097027142842611

Epoch: 6| Step: 12
Training loss: 2.043626308441162
Validation loss: 2.1252222657203674

Epoch: 6| Step: 13
Training loss: 2.304969549179077
Validation loss: 2.1292392015457153

Epoch: 20| Step: 0
Training loss: 1.519808053970337
Validation loss: 2.1180997689565024

Epoch: 6| Step: 1
Training loss: 2.3225815296173096
Validation loss: 2.0983774264653525

Epoch: 6| Step: 2
Training loss: 2.1102662086486816
Validation loss: 2.11934902270635

Epoch: 6| Step: 3
Training loss: 2.687594175338745
Validation loss: 2.133585969607035

Epoch: 6| Step: 4
Training loss: 1.4837058782577515
Validation loss: 2.10588538646698

Epoch: 6| Step: 5
Training loss: 1.7216655015945435
Validation loss: 2.0697845617930093

Epoch: 6| Step: 6
Training loss: 2.273164749145508
Validation loss: 2.149118443330129

Epoch: 6| Step: 7
Training loss: 2.3553295135498047
Validation loss: 2.075253446896871

Epoch: 6| Step: 8
Training loss: 1.4403666257858276
Validation loss: 2.126343290011088

Epoch: 6| Step: 9
Training loss: 2.3471341133117676
Validation loss: 2.115902086098989

Epoch: 6| Step: 10
Training loss: 1.8849797248840332
Validation loss: 2.0872640212376914

Epoch: 6| Step: 11
Training loss: 2.121751070022583
Validation loss: 2.0956159432729087

Epoch: 6| Step: 12
Training loss: 2.094357490539551
Validation loss: 2.127193252245585

Epoch: 6| Step: 13
Training loss: 2.4825992584228516
Validation loss: 2.133991519610087

Epoch: 21| Step: 0
Training loss: 2.457047939300537
Validation loss: 2.1204885840415955

Epoch: 6| Step: 1
Training loss: 2.0116286277770996
Validation loss: 2.0830535292625427

Epoch: 6| Step: 2
Training loss: 1.6723414659500122
Validation loss: 2.1037281155586243

Epoch: 6| Step: 3
Training loss: 2.3840811252593994
Validation loss: 2.1174092292785645

Epoch: 6| Step: 4
Training loss: 2.2620763778686523
Validation loss: 2.1098398168881736

Epoch: 6| Step: 5
Training loss: 2.6086618900299072
Validation loss: 2.0965137481689453

Epoch: 6| Step: 6
Training loss: 1.8910036087036133
Validation loss: 2.137923757235209

Epoch: 6| Step: 7
Training loss: 1.9008359909057617
Validation loss: 2.0810715158780417

Epoch: 6| Step: 8
Training loss: 1.5584683418273926
Validation loss: 2.128003458182017

Epoch: 6| Step: 9
Training loss: 1.8437280654907227
Validation loss: 2.1130500634511313

Epoch: 6| Step: 10
Training loss: 1.584876537322998
Validation loss: 2.0949520270029702

Epoch: 6| Step: 11
Training loss: 2.204728364944458
Validation loss: 2.1272724866867065

Epoch: 6| Step: 12
Training loss: 2.057687759399414
Validation loss: 2.131166378657023

Epoch: 6| Step: 13
Training loss: 2.2105891704559326
Validation loss: 2.0885000228881836

Epoch: 22| Step: 0
Training loss: 2.3578219413757324
Validation loss: 2.062175214290619

Epoch: 6| Step: 1
Training loss: 1.8554881811141968
Validation loss: 2.111658751964569

Epoch: 6| Step: 2
Training loss: 1.923018217086792
Validation loss: 2.1287508805592856

Epoch: 6| Step: 3
Training loss: 2.1301817893981934
Validation loss: 2.0995142459869385

Epoch: 6| Step: 4
Training loss: 1.802203893661499
Validation loss: 2.1337575117746987

Epoch: 6| Step: 5
Training loss: 2.3447041511535645
Validation loss: 2.134676436583201

Epoch: 6| Step: 6
Training loss: 2.16347599029541
Validation loss: 2.114306886990865

Epoch: 6| Step: 7
Training loss: 1.884644627571106
Validation loss: 2.1118260423342385

Epoch: 6| Step: 8
Training loss: 2.6340179443359375
Validation loss: 2.1207282741864524

Epoch: 6| Step: 9
Training loss: 2.601588726043701
Validation loss: 2.126068393389384

Epoch: 6| Step: 10
Training loss: 1.768911600112915
Validation loss: 2.1162507931391397

Epoch: 6| Step: 11
Training loss: 1.6886998414993286
Validation loss: 2.1201122204462686

Epoch: 6| Step: 12
Training loss: 2.091893434524536
Validation loss: 2.1097253561019897

Epoch: 6| Step: 13
Training loss: 1.8562697172164917
Validation loss: 2.0820796291033425

Epoch: 23| Step: 0
Training loss: 1.957607626914978
Validation loss: 2.1308687925338745

Epoch: 6| Step: 1
Training loss: 2.218621253967285
Validation loss: 2.1093080242474875

Epoch: 6| Step: 2
Training loss: 1.858558177947998
Validation loss: 2.1233875155448914

Epoch: 6| Step: 3
Training loss: 2.3524978160858154
Validation loss: 2.1280300617218018

Epoch: 6| Step: 4
Training loss: 2.304232358932495
Validation loss: 2.1101935307184854

Epoch: 6| Step: 5
Training loss: 1.744764804840088
Validation loss: 2.0740973949432373

Epoch: 6| Step: 6
Training loss: 1.8333860635757446
Validation loss: 2.105094313621521

Epoch: 6| Step: 7
Training loss: 2.223930835723877
Validation loss: 2.0874279737472534

Epoch: 6| Step: 8
Training loss: 2.030277729034424
Validation loss: 2.0948597192764282

Epoch: 6| Step: 9
Training loss: 2.367828130722046
Validation loss: 2.120091736316681

Epoch: 6| Step: 10
Training loss: 1.5268338918685913
Validation loss: 2.1045148968696594

Epoch: 6| Step: 11
Training loss: 2.193600654602051
Validation loss: 2.0728718638420105

Epoch: 6| Step: 12
Training loss: 2.1049599647521973
Validation loss: 2.1039186914761863

Epoch: 6| Step: 13
Training loss: 1.7993230819702148
Validation loss: 2.0871676802635193

Epoch: 24| Step: 0
Training loss: 1.4995638132095337
Validation loss: 2.079393982887268

Epoch: 6| Step: 1
Training loss: 1.7386806011199951
Validation loss: 2.102595269680023

Epoch: 6| Step: 2
Training loss: 2.2217252254486084
Validation loss: 2.101921041806539

Epoch: 6| Step: 3
Training loss: 1.8051061630249023
Validation loss: 2.0911762515703836

Epoch: 6| Step: 4
Training loss: 2.4335999488830566
Validation loss: 2.077800909678141

Epoch: 6| Step: 5
Training loss: 1.8120465278625488
Validation loss: 2.1283751130104065

Epoch: 6| Step: 6
Training loss: 2.3836960792541504
Validation loss: 2.1035393476486206

Epoch: 6| Step: 7
Training loss: 2.6798949241638184
Validation loss: 2.0950413942337036

Epoch: 6| Step: 8
Training loss: 2.006563663482666
Validation loss: 2.0876912275950112

Epoch: 6| Step: 9
Training loss: 2.2183098793029785
Validation loss: 2.0618909796079

Epoch: 6| Step: 10
Training loss: 2.2399260997772217
Validation loss: 2.0910407503445945

Epoch: 6| Step: 11
Training loss: 2.143026351928711
Validation loss: 2.092220942179362

Epoch: 6| Step: 12
Training loss: 1.9462546110153198
Validation loss: 2.102455496788025

Epoch: 6| Step: 13
Training loss: 1.3281259536743164
Validation loss: 2.095535139242808

Epoch: 25| Step: 0
Training loss: 1.9243332147598267
Validation loss: 2.092101494471232

Epoch: 6| Step: 1
Training loss: 1.7784838676452637
Validation loss: 2.097561836242676

Epoch: 6| Step: 2
Training loss: 2.4648423194885254
Validation loss: 2.090533435344696

Epoch: 6| Step: 3
Training loss: 1.9582431316375732
Validation loss: 2.1155850887298584

Epoch: 6| Step: 4
Training loss: 2.0700173377990723
Validation loss: 2.0868881940841675

Epoch: 6| Step: 5
Training loss: 2.2742791175842285
Validation loss: 2.1190414428710938

Epoch: 6| Step: 6
Training loss: 2.6282405853271484
Validation loss: 2.107407033443451

Epoch: 6| Step: 7
Training loss: 1.744437575340271
Validation loss: 2.1211992700894675

Epoch: 6| Step: 8
Training loss: 2.3352088928222656
Validation loss: 2.0820906360944114

Epoch: 6| Step: 9
Training loss: 1.6465563774108887
Validation loss: 2.078259269396464

Epoch: 6| Step: 10
Training loss: 2.003593921661377
Validation loss: 2.0978277722994485

Epoch: 6| Step: 11
Training loss: 2.332808017730713
Validation loss: 2.096016804377238

Epoch: 6| Step: 12
Training loss: 1.4879604578018188
Validation loss: 2.101819713910421

Epoch: 6| Step: 13
Training loss: 2.226252555847168
Validation loss: 2.074146548906962

Epoch: 26| Step: 0
Training loss: 2.6688785552978516
Validation loss: 2.085736890633901

Epoch: 6| Step: 1
Training loss: 1.4713935852050781
Validation loss: 2.0765918294588723

Epoch: 6| Step: 2
Training loss: 2.001526355743408
Validation loss: 2.0735016465187073

Epoch: 6| Step: 3
Training loss: 1.6149991750717163
Validation loss: 2.04868753751119

Epoch: 6| Step: 4
Training loss: 2.180881977081299
Validation loss: 2.0948248505592346

Epoch: 6| Step: 5
Training loss: 2.8741307258605957
Validation loss: 2.0694567362467446

Epoch: 6| Step: 6
Training loss: 1.6741749048233032
Validation loss: 2.1094806591669717

Epoch: 6| Step: 7
Training loss: 1.305323839187622
Validation loss: 2.0848627289136252

Epoch: 6| Step: 8
Training loss: 1.9750580787658691
Validation loss: 2.08144348859787

Epoch: 6| Step: 9
Training loss: 1.792184829711914
Validation loss: 2.122736136118571

Epoch: 6| Step: 10
Training loss: 1.8870854377746582
Validation loss: 2.0666154424349465

Epoch: 6| Step: 11
Training loss: 2.2500505447387695
Validation loss: 2.0954886078834534

Epoch: 6| Step: 12
Training loss: 2.51285982131958
Validation loss: 2.0663567185401917

Epoch: 6| Step: 13
Training loss: 2.3217921257019043
Validation loss: 2.0849681297938027

Epoch: 27| Step: 0
Training loss: 2.283447265625
Validation loss: 2.134536345799764

Epoch: 6| Step: 1
Training loss: 2.1026203632354736
Validation loss: 2.0871909459431968

Epoch: 6| Step: 2
Training loss: 1.3106169700622559
Validation loss: 2.1053778926531472

Epoch: 6| Step: 3
Training loss: 2.22062349319458
Validation loss: 2.0842717488606772

Epoch: 6| Step: 4
Training loss: 1.806623935699463
Validation loss: 2.0746061205863953

Epoch: 6| Step: 5
Training loss: 2.0302579402923584
Validation loss: 2.089835524559021

Epoch: 6| Step: 6
Training loss: 2.2525787353515625
Validation loss: 2.0936408241589866

Epoch: 6| Step: 7
Training loss: 1.5402896404266357
Validation loss: 2.1147351463635764

Epoch: 6| Step: 8
Training loss: 2.974461793899536
Validation loss: 2.075284421443939

Epoch: 6| Step: 9
Training loss: 2.2645678520202637
Validation loss: 2.1209162871042886

Epoch: 6| Step: 10
Training loss: 1.8166899681091309
Validation loss: 2.0534600814183555

Epoch: 6| Step: 11
Training loss: 1.7140189409255981
Validation loss: 2.0704318284988403

Epoch: 6| Step: 12
Training loss: 1.9896371364593506
Validation loss: 2.091005265712738

Epoch: 6| Step: 13
Training loss: 2.181436538696289
Validation loss: 2.0920871694882712

Epoch: 28| Step: 0
Training loss: 1.6540396213531494
Validation loss: 2.0852383176485696

Epoch: 6| Step: 1
Training loss: 2.5101540088653564
Validation loss: 2.0807709097862244

Epoch: 6| Step: 2
Training loss: 2.146082878112793
Validation loss: 2.056450386842092

Epoch: 6| Step: 3
Training loss: 1.9850986003875732
Validation loss: 2.094268580277761

Epoch: 6| Step: 4
Training loss: 1.9361767768859863
Validation loss: 2.0647024512290955

Epoch: 6| Step: 5
Training loss: 2.3186802864074707
Validation loss: 2.060850977897644

Epoch: 6| Step: 6
Training loss: 1.9467039108276367
Validation loss: 2.070449948310852

Epoch: 6| Step: 7
Training loss: 1.4941961765289307
Validation loss: 2.059220234553019

Epoch: 6| Step: 8
Training loss: 2.3956458568573
Validation loss: 2.0846076011657715

Epoch: 6| Step: 9
Training loss: 2.7526607513427734
Validation loss: 2.1005985538164773

Epoch: 6| Step: 10
Training loss: 1.473867416381836
Validation loss: 2.073998828728994

Epoch: 6| Step: 11
Training loss: 1.6629751920700073
Validation loss: 2.0755540132522583

Epoch: 6| Step: 12
Training loss: 2.5066401958465576
Validation loss: 2.093502660592397

Epoch: 6| Step: 13
Training loss: 2.1658129692077637
Validation loss: 2.0754539171854653

Epoch: 29| Step: 0
Training loss: 1.6603655815124512
Validation loss: 2.09253998597463

Epoch: 6| Step: 1
Training loss: 1.8637714385986328
Validation loss: 2.0608131090799966

Epoch: 6| Step: 2
Training loss: 1.6117995977401733
Validation loss: 2.0873692631721497

Epoch: 6| Step: 3
Training loss: 2.361361503601074
Validation loss: 2.0605792005856833

Epoch: 6| Step: 4
Training loss: 2.013995409011841
Validation loss: 2.0643802881240845

Epoch: 6| Step: 5
Training loss: 1.6568467617034912
Validation loss: 2.0710840622584024

Epoch: 6| Step: 6
Training loss: 2.089449405670166
Validation loss: 2.0798678199450173

Epoch: 6| Step: 7
Training loss: 2.026007890701294
Validation loss: 2.096110184987386

Epoch: 6| Step: 8
Training loss: 2.5276541709899902
Validation loss: 2.0625418424606323

Epoch: 6| Step: 9
Training loss: 2.2426533699035645
Validation loss: 2.064218978087107

Epoch: 6| Step: 10
Training loss: 2.1663331985473633
Validation loss: 2.0779710610707602

Epoch: 6| Step: 11
Training loss: 1.894234538078308
Validation loss: 2.057986537615458

Epoch: 6| Step: 12
Training loss: 2.186434268951416
Validation loss: 2.0702412128448486

Epoch: 6| Step: 13
Training loss: 2.460069179534912
Validation loss: 2.0889342228571572

Epoch: 30| Step: 0
Training loss: 2.3534047603607178
Validation loss: 2.09848552942276

Epoch: 6| Step: 1
Training loss: 2.6296844482421875
Validation loss: 2.0620198845863342

Epoch: 6| Step: 2
Training loss: 2.1021950244903564
Validation loss: 2.0888675451278687

Epoch: 6| Step: 3
Training loss: 1.2607741355895996
Validation loss: 2.06230092048645

Epoch: 6| Step: 4
Training loss: 2.289712905883789
Validation loss: 2.1016584833463035

Epoch: 6| Step: 5
Training loss: 1.4049761295318604
Validation loss: 2.09200253089269

Epoch: 6| Step: 6
Training loss: 2.049302816390991
Validation loss: 2.0690036018689475

Epoch: 6| Step: 7
Training loss: 2.1395955085754395
Validation loss: 2.0649783611297607

Epoch: 6| Step: 8
Training loss: 2.297065019607544
Validation loss: 2.0995503067970276

Epoch: 6| Step: 9
Training loss: 1.9476149082183838
Validation loss: 2.1185386975606284

Epoch: 6| Step: 10
Training loss: 1.7228913307189941
Validation loss: 2.088036040465037

Epoch: 6| Step: 11
Training loss: 1.892102599143982
Validation loss: 2.064449926217397

Epoch: 6| Step: 12
Training loss: 2.247011661529541
Validation loss: 2.068219562371572

Epoch: 6| Step: 13
Training loss: 1.9076958894729614
Validation loss: 2.09190034866333

Epoch: 31| Step: 0
Training loss: 2.3850111961364746
Validation loss: 2.0750158627827964

Epoch: 6| Step: 1
Training loss: 2.0473735332489014
Validation loss: 2.0591441988945007

Epoch: 6| Step: 2
Training loss: 1.9347925186157227
Validation loss: 2.065896908442179

Epoch: 6| Step: 3
Training loss: 1.4944937229156494
Validation loss: 2.0599995056788125

Epoch: 6| Step: 4
Training loss: 1.7442415952682495
Validation loss: 2.0729666352272034

Epoch: 6| Step: 5
Training loss: 2.187662124633789
Validation loss: 2.112341503302256

Epoch: 6| Step: 6
Training loss: 1.852576494216919
Validation loss: 2.0556756059328714

Epoch: 6| Step: 7
Training loss: 2.2408018112182617
Validation loss: 2.066638429959615

Epoch: 6| Step: 8
Training loss: 2.1945552825927734
Validation loss: 2.085942010084788

Epoch: 6| Step: 9
Training loss: 1.9000754356384277
Validation loss: 2.1040186683336892

Epoch: 6| Step: 10
Training loss: 2.0042147636413574
Validation loss: 2.0521830717722573

Epoch: 6| Step: 11
Training loss: 1.8295906782150269
Validation loss: 2.1367031137148538

Epoch: 6| Step: 12
Training loss: 2.0375280380249023
Validation loss: 2.0672370990117392

Epoch: 6| Step: 13
Training loss: 2.317755937576294
Validation loss: 2.0793123841285706

Epoch: 32| Step: 0
Training loss: 1.539586067199707
Validation loss: 2.054041584332784

Epoch: 6| Step: 1
Training loss: 2.1830637454986572
Validation loss: 2.102872848510742

Epoch: 6| Step: 2
Training loss: 1.963637113571167
Validation loss: 2.0835242867469788

Epoch: 6| Step: 3
Training loss: 2.3264055252075195
Validation loss: 2.0861517190933228

Epoch: 6| Step: 4
Training loss: 1.73721444606781
Validation loss: 2.088801125685374

Epoch: 6| Step: 5
Training loss: 2.0023186206817627
Validation loss: 2.05182812611262

Epoch: 6| Step: 6
Training loss: 2.2080373764038086
Validation loss: 2.0508273442586265

Epoch: 6| Step: 7
Training loss: 2.0285942554473877
Validation loss: 2.060705920060476

Epoch: 6| Step: 8
Training loss: 2.440948486328125
Validation loss: 2.081071615219116

Epoch: 6| Step: 9
Training loss: 1.8897860050201416
Validation loss: 2.101408143838247

Epoch: 6| Step: 10
Training loss: 2.3791894912719727
Validation loss: 2.0755640467007956

Epoch: 6| Step: 11
Training loss: 2.038902759552002
Validation loss: 2.0625370740890503

Epoch: 6| Step: 12
Training loss: 1.8361895084381104
Validation loss: 2.056169271469116

Epoch: 6| Step: 13
Training loss: 1.6383399963378906
Validation loss: 2.0545048316319785

Epoch: 33| Step: 0
Training loss: 2.697714328765869
Validation loss: 2.061877409617106

Epoch: 6| Step: 1
Training loss: 1.5567985773086548
Validation loss: 2.0648473699887595

Epoch: 6| Step: 2
Training loss: 1.9269278049468994
Validation loss: 2.1001574198404946

Epoch: 6| Step: 3
Training loss: 1.4364848136901855
Validation loss: 2.087195018927256

Epoch: 6| Step: 4
Training loss: 1.7551655769348145
Validation loss: 2.058710833390554

Epoch: 6| Step: 5
Training loss: 2.129739284515381
Validation loss: 2.0497506658236184

Epoch: 6| Step: 6
Training loss: 1.7018189430236816
Validation loss: 2.0698668162027993

Epoch: 6| Step: 7
Training loss: 2.335420608520508
Validation loss: 2.086558222770691

Epoch: 6| Step: 8
Training loss: 2.0257420539855957
Validation loss: 2.061742067337036

Epoch: 6| Step: 9
Training loss: 1.512897253036499
Validation loss: 2.0919657150904336

Epoch: 6| Step: 10
Training loss: 2.7430644035339355
Validation loss: 2.10558021068573

Epoch: 6| Step: 11
Training loss: 2.3103513717651367
Validation loss: 2.097358524799347

Epoch: 6| Step: 12
Training loss: 1.9551587104797363
Validation loss: 2.1306183338165283

Epoch: 6| Step: 13
Training loss: 1.9733916521072388
Validation loss: 2.093100607395172

Epoch: 34| Step: 0
Training loss: 1.692259669303894
Validation loss: 2.0944871306419373

Epoch: 6| Step: 1
Training loss: 1.9310336112976074
Validation loss: 2.0845255255699158

Epoch: 6| Step: 2
Training loss: 2.437239170074463
Validation loss: 2.09420382976532

Epoch: 6| Step: 3
Training loss: 2.2525978088378906
Validation loss: 2.102381408214569

Epoch: 6| Step: 4
Training loss: 2.308892250061035
Validation loss: 2.063524683316549

Epoch: 6| Step: 5
Training loss: 1.258420467376709
Validation loss: 2.059452931086222

Epoch: 6| Step: 6
Training loss: 1.4999775886535645
Validation loss: 2.081382135550181

Epoch: 6| Step: 7
Training loss: 2.2152204513549805
Validation loss: 2.0977056423823037

Epoch: 6| Step: 8
Training loss: 1.9086395502090454
Validation loss: 2.06206351518631

Epoch: 6| Step: 9
Training loss: 1.400944471359253
Validation loss: 2.105299969514211

Epoch: 6| Step: 10
Training loss: 2.451239585876465
Validation loss: 2.071943779786428

Epoch: 6| Step: 11
Training loss: 2.4896857738494873
Validation loss: 2.0952505270640054

Epoch: 6| Step: 12
Training loss: 2.0337657928466797
Validation loss: 2.073771675427755

Epoch: 6| Step: 13
Training loss: 2.0963120460510254
Validation loss: 2.078459640343984

Epoch: 35| Step: 0
Training loss: 1.8141151666641235
Validation loss: 2.1008901993433633

Epoch: 6| Step: 1
Training loss: 2.3560264110565186
Validation loss: 2.0732761224110923

Epoch: 6| Step: 2
Training loss: 2.0925650596618652
Validation loss: 2.087481995423635

Epoch: 6| Step: 3
Training loss: 2.360947847366333
Validation loss: 2.075889507929484

Epoch: 6| Step: 4
Training loss: 2.3116745948791504
Validation loss: 2.0695157249768577

Epoch: 6| Step: 5
Training loss: 2.076535701751709
Validation loss: 2.0687928795814514

Epoch: 6| Step: 6
Training loss: 2.1656978130340576
Validation loss: 2.0746726592381797

Epoch: 6| Step: 7
Training loss: 1.7926323413848877
Validation loss: 2.074081758658091

Epoch: 6| Step: 8
Training loss: 1.6876399517059326
Validation loss: 2.0643167893091836

Epoch: 6| Step: 9
Training loss: 1.6434307098388672
Validation loss: 2.0935679276784263

Epoch: 6| Step: 10
Training loss: 1.7069215774536133
Validation loss: 2.123734474182129

Epoch: 6| Step: 11
Training loss: 1.7153613567352295
Validation loss: 2.0858417550722756

Epoch: 6| Step: 12
Training loss: 2.3458032608032227
Validation loss: 2.09051251411438

Epoch: 6| Step: 13
Training loss: 2.2122764587402344
Validation loss: 2.0934927066167197

Epoch: 36| Step: 0
Training loss: 1.9283668994903564
Validation loss: 2.09324316183726

Epoch: 6| Step: 1
Training loss: 2.284175395965576
Validation loss: 2.056287467479706

Epoch: 6| Step: 2
Training loss: 2.437528610229492
Validation loss: 2.06924174229304

Epoch: 6| Step: 3
Training loss: 2.2838261127471924
Validation loss: 2.0614142417907715

Epoch: 6| Step: 4
Training loss: 1.9112472534179688
Validation loss: 2.0809076031049094

Epoch: 6| Step: 5
Training loss: 1.9074926376342773
Validation loss: 2.078272898991903

Epoch: 6| Step: 6
Training loss: 1.5619657039642334
Validation loss: 2.102534313996633

Epoch: 6| Step: 7
Training loss: 2.3020403385162354
Validation loss: 2.1006985306739807

Epoch: 6| Step: 8
Training loss: 1.2865655422210693
Validation loss: 2.1006919940312705

Epoch: 6| Step: 9
Training loss: 2.1090307235717773
Validation loss: 2.083624084790548

Epoch: 6| Step: 10
Training loss: 2.1812102794647217
Validation loss: 2.0783615112304688

Epoch: 6| Step: 11
Training loss: 2.102504253387451
Validation loss: 2.0705735882123313

Epoch: 6| Step: 12
Training loss: 2.0076048374176025
Validation loss: 2.078286031881968

Epoch: 6| Step: 13
Training loss: 1.963356614112854
Validation loss: 2.107180198033651

Epoch: 37| Step: 0
Training loss: 2.2285499572753906
Validation loss: 2.056463976701101

Epoch: 6| Step: 1
Training loss: 1.7899452447891235
Validation loss: 2.0856354435284934

Epoch: 6| Step: 2
Training loss: 2.7910571098327637
Validation loss: 2.083251138528188

Epoch: 6| Step: 3
Training loss: 2.5990939140319824
Validation loss: 2.1250535448392234

Epoch: 6| Step: 4
Training loss: 2.5227813720703125
Validation loss: 2.137626131375631

Epoch: 6| Step: 5
Training loss: 1.956412434577942
Validation loss: 2.13851668437322

Epoch: 6| Step: 6
Training loss: 1.7837727069854736
Validation loss: 2.0898110071818032

Epoch: 6| Step: 7
Training loss: 2.059248924255371
Validation loss: 2.094779630502065

Epoch: 6| Step: 8
Training loss: 1.2996360063552856
Validation loss: 2.100023706754049

Epoch: 6| Step: 9
Training loss: 1.292327642440796
Validation loss: 2.0693179965019226

Epoch: 6| Step: 10
Training loss: 2.1324145793914795
Validation loss: 2.075142780939738

Epoch: 6| Step: 11
Training loss: 2.0165905952453613
Validation loss: 2.080143372217814

Epoch: 6| Step: 12
Training loss: 1.6386168003082275
Validation loss: 2.0696433186531067

Epoch: 6| Step: 13
Training loss: 1.9209935665130615
Validation loss: 2.093086898326874

Epoch: 38| Step: 0
Training loss: 1.816562294960022
Validation loss: 2.0422372221946716

Epoch: 6| Step: 1
Training loss: 1.5502315759658813
Validation loss: 2.0528506437937417

Epoch: 6| Step: 2
Training loss: 2.4658656120300293
Validation loss: 2.064051330089569

Epoch: 6| Step: 3
Training loss: 1.7293109893798828
Validation loss: 2.073448677857717

Epoch: 6| Step: 4
Training loss: 1.162138819694519
Validation loss: 2.0856376687685647

Epoch: 6| Step: 5
Training loss: 2.157135009765625
Validation loss: 2.067939579486847

Epoch: 6| Step: 6
Training loss: 2.195941925048828
Validation loss: 2.050130625565847

Epoch: 6| Step: 7
Training loss: 2.16037917137146
Validation loss: 2.067927837371826

Epoch: 6| Step: 8
Training loss: 2.6298987865448
Validation loss: 2.0938678979873657

Epoch: 6| Step: 9
Training loss: 1.8566169738769531
Validation loss: 2.056244909763336

Epoch: 6| Step: 10
Training loss: 2.2852189540863037
Validation loss: 2.0454923113187156

Epoch: 6| Step: 11
Training loss: 1.898829460144043
Validation loss: 2.085576812426249

Epoch: 6| Step: 12
Training loss: 1.5344337224960327
Validation loss: 2.085357983907064

Epoch: 6| Step: 13
Training loss: 2.5641160011291504
Validation loss: 2.078431804974874

Epoch: 39| Step: 0
Training loss: 2.161787509918213
Validation loss: 2.0842820008595786

Epoch: 6| Step: 1
Training loss: 2.8742787837982178
Validation loss: 2.070366462071737

Epoch: 6| Step: 2
Training loss: 1.7272725105285645
Validation loss: 2.0788921316464744

Epoch: 6| Step: 3
Training loss: 2.4356675148010254
Validation loss: 2.095227003097534

Epoch: 6| Step: 4
Training loss: 1.4290943145751953
Validation loss: 2.0721325476964316

Epoch: 6| Step: 5
Training loss: 2.4157674312591553
Validation loss: 2.0694937109947205

Epoch: 6| Step: 6
Training loss: 1.6944419145584106
Validation loss: 2.0918222069740295

Epoch: 6| Step: 7
Training loss: 2.3591272830963135
Validation loss: 2.042606254418691

Epoch: 6| Step: 8
Training loss: 1.7534022331237793
Validation loss: 2.0527907609939575

Epoch: 6| Step: 9
Training loss: 1.3859198093414307
Validation loss: 2.049019475777944

Epoch: 6| Step: 10
Training loss: 1.948388934135437
Validation loss: 2.0635239084561667

Epoch: 6| Step: 11
Training loss: 1.9823710918426514
Validation loss: 2.046889305114746

Epoch: 6| Step: 12
Training loss: 2.130965232849121
Validation loss: 2.065514008204142

Epoch: 6| Step: 13
Training loss: 1.6219185590744019
Validation loss: 2.0851954023043313

Epoch: 40| Step: 0
Training loss: 1.7657212018966675
Validation loss: 2.0764085054397583

Epoch: 6| Step: 1
Training loss: 2.274022102355957
Validation loss: 2.0546526114145913

Epoch: 6| Step: 2
Training loss: 1.6152334213256836
Validation loss: 2.0671068032582602

Epoch: 6| Step: 3
Training loss: 1.9247525930404663
Validation loss: 2.0821948448816934

Epoch: 6| Step: 4
Training loss: 2.2241649627685547
Validation loss: 2.0895172556241355

Epoch: 6| Step: 5
Training loss: 1.480175256729126
Validation loss: 2.0783424973487854

Epoch: 6| Step: 6
Training loss: 2.9800851345062256
Validation loss: 2.0888542532920837

Epoch: 6| Step: 7
Training loss: 1.9881459474563599
Validation loss: 2.074190338452657

Epoch: 6| Step: 8
Training loss: 2.307847499847412
Validation loss: 2.0619378089904785

Epoch: 6| Step: 9
Training loss: 1.936915636062622
Validation loss: 2.055363953113556

Epoch: 6| Step: 10
Training loss: 2.1986308097839355
Validation loss: 2.049673875172933

Epoch: 6| Step: 11
Training loss: 1.628265380859375
Validation loss: 2.051449259122213

Epoch: 6| Step: 12
Training loss: 1.3746047019958496
Validation loss: 2.089024802049001

Epoch: 6| Step: 13
Training loss: 2.0633890628814697
Validation loss: 2.0687734882036843

Epoch: 41| Step: 0
Training loss: 1.7357473373413086
Validation loss: 2.0639355778694153

Epoch: 6| Step: 1
Training loss: 2.373629570007324
Validation loss: 2.063896338144938

Epoch: 6| Step: 2
Training loss: 2.958191156387329
Validation loss: 2.071934759616852

Epoch: 6| Step: 3
Training loss: 2.10870361328125
Validation loss: 2.0570587515830994

Epoch: 6| Step: 4
Training loss: 1.8522015810012817
Validation loss: 2.0591824849446616

Epoch: 6| Step: 5
Training loss: 1.5295908451080322
Validation loss: 2.065590977668762

Epoch: 6| Step: 6
Training loss: 1.8653602600097656
Validation loss: 2.057572841644287

Epoch: 6| Step: 7
Training loss: 2.4888556003570557
Validation loss: 2.0685311555862427

Epoch: 6| Step: 8
Training loss: 1.331894040107727
Validation loss: 2.0698841214179993

Epoch: 6| Step: 9
Training loss: 2.0774388313293457
Validation loss: 2.0650333364804587

Epoch: 6| Step: 10
Training loss: 1.9354653358459473
Validation loss: 2.0681161284446716

Epoch: 6| Step: 11
Training loss: 2.2402663230895996
Validation loss: 2.0817437767982483

Epoch: 6| Step: 12
Training loss: 1.8024635314941406
Validation loss: 2.085574448108673

Epoch: 6| Step: 13
Training loss: 1.7992236614227295
Validation loss: 2.0981616576512656

Epoch: 42| Step: 0
Training loss: 1.981138825416565
Validation loss: 2.1070645848910012

Epoch: 6| Step: 1
Training loss: 2.0497474670410156
Validation loss: 2.0908198952674866

Epoch: 6| Step: 2
Training loss: 1.7720913887023926
Validation loss: 2.073408544063568

Epoch: 6| Step: 3
Training loss: 1.5850112438201904
Validation loss: 2.049889922142029

Epoch: 6| Step: 4
Training loss: 2.397783041000366
Validation loss: 2.0557541052500405

Epoch: 6| Step: 5
Training loss: 1.964571475982666
Validation loss: 2.0768973429997764

Epoch: 6| Step: 6
Training loss: 2.145022392272949
Validation loss: 2.0555068850517273

Epoch: 6| Step: 7
Training loss: 1.6288092136383057
Validation loss: 2.0857845544815063

Epoch: 6| Step: 8
Training loss: 1.8224928379058838
Validation loss: 2.0720371206601462

Epoch: 6| Step: 9
Training loss: 2.2845299243927
Validation loss: 2.102280000845591

Epoch: 6| Step: 10
Training loss: 2.7640891075134277
Validation loss: 2.0829067627588906

Epoch: 6| Step: 11
Training loss: 1.9471856355667114
Validation loss: 2.1252315441767373

Epoch: 6| Step: 12
Training loss: 1.6072429418563843
Validation loss: 2.0657988588015237

Epoch: 6| Step: 13
Training loss: 2.751819610595703
Validation loss: 2.0556331078211465

Epoch: 43| Step: 0
Training loss: 2.2676939964294434
Validation loss: 2.064633766810099

Epoch: 6| Step: 1
Training loss: 1.9934343099594116
Validation loss: 2.075090706348419

Epoch: 6| Step: 2
Training loss: 1.8741047382354736
Validation loss: 2.0945595304171243

Epoch: 6| Step: 3
Training loss: 1.812057614326477
Validation loss: 2.0498363773028054

Epoch: 6| Step: 4
Training loss: 2.115687847137451
Validation loss: 2.066510319709778

Epoch: 6| Step: 5
Training loss: 1.9772906303405762
Validation loss: 2.0582032203674316

Epoch: 6| Step: 6
Training loss: 1.9360449314117432
Validation loss: 2.0758344729741416

Epoch: 6| Step: 7
Training loss: 2.2971460819244385
Validation loss: 2.0518048206965127

Epoch: 6| Step: 8
Training loss: 1.8958897590637207
Validation loss: 2.1037848790486655

Epoch: 6| Step: 9
Training loss: 1.4840887784957886
Validation loss: 2.079418400923411

Epoch: 6| Step: 10
Training loss: 1.5315250158309937
Validation loss: 2.059471368789673

Epoch: 6| Step: 11
Training loss: 2.2784924507141113
Validation loss: 2.1137032906214395

Epoch: 6| Step: 12
Training loss: 2.5566983222961426
Validation loss: 2.0857343475023904

Epoch: 6| Step: 13
Training loss: 1.5489239692687988
Validation loss: 2.0963566501935325

Epoch: 44| Step: 0
Training loss: 2.1060569286346436
Validation loss: 2.0967746575673423

Epoch: 6| Step: 1
Training loss: 2.1637911796569824
Validation loss: 2.1256832480430603

Epoch: 6| Step: 2
Training loss: 1.9238474369049072
Validation loss: 2.134788393974304

Epoch: 6| Step: 3
Training loss: 1.829537034034729
Validation loss: 2.1074260075887046

Epoch: 6| Step: 4
Training loss: 2.543929100036621
Validation loss: 2.089508314927419

Epoch: 6| Step: 5
Training loss: 1.9948023557662964
Validation loss: 2.0952523152033486

Epoch: 6| Step: 6
Training loss: 1.679345726966858
Validation loss: 2.0891148845354715

Epoch: 6| Step: 7
Training loss: 1.7645444869995117
Validation loss: 2.109342892964681

Epoch: 6| Step: 8
Training loss: 1.7225027084350586
Validation loss: 2.090887665748596

Epoch: 6| Step: 9
Training loss: 1.9050889015197754
Validation loss: 2.1213538646698

Epoch: 6| Step: 10
Training loss: 2.6574723720550537
Validation loss: 2.054368734359741

Epoch: 6| Step: 11
Training loss: 1.653063178062439
Validation loss: 2.066602090994517

Epoch: 6| Step: 12
Training loss: 1.9041004180908203
Validation loss: 2.077430228392283

Epoch: 6| Step: 13
Training loss: 2.0434296131134033
Validation loss: 2.0844270984331765

Epoch: 45| Step: 0
Training loss: 2.357897996902466
Validation loss: 2.058920999368032

Epoch: 6| Step: 1
Training loss: 2.5970163345336914
Validation loss: 2.071836451689402

Epoch: 6| Step: 2
Training loss: 1.9868725538253784
Validation loss: 2.128005107243856

Epoch: 6| Step: 3
Training loss: 1.6960312128067017
Validation loss: 2.1118677258491516

Epoch: 6| Step: 4
Training loss: 2.076828718185425
Validation loss: 2.0862995386123657

Epoch: 6| Step: 5
Training loss: 2.4047727584838867
Validation loss: 2.091188291708628

Epoch: 6| Step: 6
Training loss: 2.2335352897644043
Validation loss: 2.101650913556417

Epoch: 6| Step: 7
Training loss: 2.171475887298584
Validation loss: 2.102812568346659

Epoch: 6| Step: 8
Training loss: 1.5163700580596924
Validation loss: 2.085713346799215

Epoch: 6| Step: 9
Training loss: 1.3663959503173828
Validation loss: 2.095302244027456

Epoch: 6| Step: 10
Training loss: 1.696771264076233
Validation loss: 2.0431299805641174

Epoch: 6| Step: 11
Training loss: 1.879259705543518
Validation loss: 2.0528473456700644

Epoch: 6| Step: 12
Training loss: 2.6881778240203857
Validation loss: 2.032723128795624

Epoch: 6| Step: 13
Training loss: 1.4656107425689697
Validation loss: 2.058073957761129

Epoch: 46| Step: 0
Training loss: 2.2434511184692383
Validation loss: 2.046871066093445

Epoch: 6| Step: 1
Training loss: 2.733410358428955
Validation loss: 2.0613661209742227

Epoch: 6| Step: 2
Training loss: 2.2254581451416016
Validation loss: 2.050519665082296

Epoch: 6| Step: 3
Training loss: 1.2842929363250732
Validation loss: 2.106739640235901

Epoch: 6| Step: 4
Training loss: 2.1349446773529053
Validation loss: 2.074078698952993

Epoch: 6| Step: 5
Training loss: 2.4881131649017334
Validation loss: 2.091811418533325

Epoch: 6| Step: 6
Training loss: 1.6441525220870972
Validation loss: 2.1040401260058084

Epoch: 6| Step: 7
Training loss: 1.7098513841629028
Validation loss: 2.0894733468691506

Epoch: 6| Step: 8
Training loss: 1.350975751876831
Validation loss: 2.0967912077903748

Epoch: 6| Step: 9
Training loss: 2.351140022277832
Validation loss: 2.09883846839269

Epoch: 6| Step: 10
Training loss: 1.5531744956970215
Validation loss: 2.1054110129674277

Epoch: 6| Step: 11
Training loss: 2.425708055496216
Validation loss: 2.0563167532285056

Epoch: 6| Step: 12
Training loss: 1.587378740310669
Validation loss: 2.104127844174703

Epoch: 6| Step: 13
Training loss: 1.8933453559875488
Validation loss: 2.10713396469752

Epoch: 47| Step: 0
Training loss: 1.859513759613037
Validation loss: 2.096854110558828

Epoch: 6| Step: 1
Training loss: 1.745272159576416
Validation loss: 2.087642550468445

Epoch: 6| Step: 2
Training loss: 1.8517709970474243
Validation loss: 2.070570170879364

Epoch: 6| Step: 3
Training loss: 1.658102035522461
Validation loss: 2.0454183419545493

Epoch: 6| Step: 4
Training loss: 1.8238520622253418
Validation loss: 2.0685494343439736

Epoch: 6| Step: 5
Training loss: 2.6456711292266846
Validation loss: 2.0767650802930198

Epoch: 6| Step: 6
Training loss: 1.78364896774292
Validation loss: 2.0601889292399087

Epoch: 6| Step: 7
Training loss: 2.1402602195739746
Validation loss: 2.038209239641825

Epoch: 6| Step: 8
Training loss: 1.9525983333587646
Validation loss: 2.0576115449269614

Epoch: 6| Step: 9
Training loss: 1.5645736455917358
Validation loss: 2.069449722766876

Epoch: 6| Step: 10
Training loss: 2.223862648010254
Validation loss: 2.0596717397371926

Epoch: 6| Step: 11
Training loss: 2.5997276306152344
Validation loss: 2.033903956413269

Epoch: 6| Step: 12
Training loss: 2.092411994934082
Validation loss: 2.082461416721344

Epoch: 6| Step: 13
Training loss: 1.8111481666564941
Validation loss: 2.077681521574656

Epoch: 48| Step: 0
Training loss: 2.927964925765991
Validation loss: 2.0539750258127847

Epoch: 6| Step: 1
Training loss: 1.936523675918579
Validation loss: 2.0483200748761496

Epoch: 6| Step: 2
Training loss: 1.4471571445465088
Validation loss: 2.0667930444081626

Epoch: 6| Step: 3
Training loss: 1.4824442863464355
Validation loss: 2.0367270906766257

Epoch: 6| Step: 4
Training loss: 2.2453372478485107
Validation loss: 2.0678911209106445

Epoch: 6| Step: 5
Training loss: 1.8905067443847656
Validation loss: 2.028337220350901

Epoch: 6| Step: 6
Training loss: 1.7119331359863281
Validation loss: 2.0778331756591797

Epoch: 6| Step: 7
Training loss: 1.8273528814315796
Validation loss: 2.0776858727137246

Epoch: 6| Step: 8
Training loss: 1.9805927276611328
Validation loss: 2.0754253466924033

Epoch: 6| Step: 9
Training loss: 2.227141857147217
Validation loss: 2.092792352040609

Epoch: 6| Step: 10
Training loss: 1.6808431148529053
Validation loss: 2.0676904122034707

Epoch: 6| Step: 11
Training loss: 2.515683889389038
Validation loss: 2.093859076499939

Epoch: 6| Step: 12
Training loss: 1.8761358261108398
Validation loss: 2.0839773416519165

Epoch: 6| Step: 13
Training loss: 1.830100178718567
Validation loss: 2.096845587094625

Epoch: 49| Step: 0
Training loss: 2.1548967361450195
Validation loss: 2.1173494458198547

Epoch: 6| Step: 1
Training loss: 2.883448600769043
Validation loss: 2.0640382965405784

Epoch: 6| Step: 2
Training loss: 1.8196556568145752
Validation loss: 2.0671767393747964

Epoch: 6| Step: 3
Training loss: 1.9354846477508545
Validation loss: 2.077259083588918

Epoch: 6| Step: 4
Training loss: 1.9098553657531738
Validation loss: 2.0892801682154336

Epoch: 6| Step: 5
Training loss: 1.5232267379760742
Validation loss: 2.07287190357844

Epoch: 6| Step: 6
Training loss: 1.5760397911071777
Validation loss: 2.0540312925974527

Epoch: 6| Step: 7
Training loss: 1.7492074966430664
Validation loss: 2.08161453406016

Epoch: 6| Step: 8
Training loss: 2.3204307556152344
Validation loss: 2.0906373262405396

Epoch: 6| Step: 9
Training loss: 2.1227245330810547
Validation loss: 2.059804856777191

Epoch: 6| Step: 10
Training loss: 1.710032343864441
Validation loss: 2.0396836002667746

Epoch: 6| Step: 11
Training loss: 2.042128801345825
Validation loss: 2.010863721370697

Epoch: 6| Step: 12
Training loss: 1.5104573965072632
Validation loss: 2.065271516640981

Epoch: 6| Step: 13
Training loss: 2.0354833602905273
Validation loss: 2.0700340469678244

Epoch: 50| Step: 0
Training loss: 2.2828426361083984
Validation loss: 2.0786264737447104

Epoch: 6| Step: 1
Training loss: 2.057798385620117
Validation loss: 2.067704955736796

Epoch: 6| Step: 2
Training loss: 2.1157946586608887
Validation loss: 2.0707616607348123

Epoch: 6| Step: 3
Training loss: 2.219576835632324
Validation loss: 2.07158625125885

Epoch: 6| Step: 4
Training loss: 1.9791340827941895
Validation loss: 2.068688233693441

Epoch: 6| Step: 5
Training loss: 2.282733201980591
Validation loss: 2.052690049012502

Epoch: 6| Step: 6
Training loss: 1.8726823329925537
Validation loss: 2.0629970033963523

Epoch: 6| Step: 7
Training loss: 1.4369546175003052
Validation loss: 2.085756023724874

Epoch: 6| Step: 8
Training loss: 0.9065622687339783
Validation loss: 2.098821520805359

Epoch: 6| Step: 9
Training loss: 2.0460381507873535
Validation loss: 2.054639995098114

Epoch: 6| Step: 10
Training loss: 2.223294496536255
Validation loss: 2.0898913741111755

Epoch: 6| Step: 11
Training loss: 1.7055366039276123
Validation loss: 2.0631564060846963

Epoch: 6| Step: 12
Training loss: 2.3152966499328613
Validation loss: 2.1122249364852905

Epoch: 6| Step: 13
Training loss: 2.2392377853393555
Validation loss: 2.0809208949406943

Epoch: 51| Step: 0
Training loss: 1.7637912034988403
Validation loss: 2.0732290148735046

Epoch: 6| Step: 1
Training loss: 1.6051923036575317
Validation loss: 2.0967588822046914

Epoch: 6| Step: 2
Training loss: 2.4631590843200684
Validation loss: 2.082748591899872

Epoch: 6| Step: 3
Training loss: 1.4546897411346436
Validation loss: 2.095105508963267

Epoch: 6| Step: 4
Training loss: 1.7600250244140625
Validation loss: 2.132098118464152

Epoch: 6| Step: 5
Training loss: 2.1992087364196777
Validation loss: 2.139385382334391

Epoch: 6| Step: 6
Training loss: 1.5656664371490479
Validation loss: 2.0677268306414285

Epoch: 6| Step: 7
Training loss: 1.6522035598754883
Validation loss: 2.1053035259246826

Epoch: 6| Step: 8
Training loss: 2.1837830543518066
Validation loss: 2.0957306623458862

Epoch: 6| Step: 9
Training loss: 1.76082181930542
Validation loss: 2.0596946279207864

Epoch: 6| Step: 10
Training loss: 2.2158706188201904
Validation loss: 2.0470874309539795

Epoch: 6| Step: 11
Training loss: 2.44118070602417
Validation loss: 2.0676674048105874

Epoch: 6| Step: 12
Training loss: 2.311440944671631
Validation loss: 2.044964333375295

Epoch: 6| Step: 13
Training loss: 1.9874454736709595
Validation loss: 2.0718643267949424

Epoch: 52| Step: 0
Training loss: 2.0670928955078125
Validation loss: 2.067148427168528

Epoch: 6| Step: 1
Training loss: 2.2733798027038574
Validation loss: 2.0739843249320984

Epoch: 6| Step: 2
Training loss: 1.6543917655944824
Validation loss: 2.0763156612714133

Epoch: 6| Step: 3
Training loss: 1.6351398229599
Validation loss: 2.0399913787841797

Epoch: 6| Step: 4
Training loss: 1.6457017660140991
Validation loss: 2.060044308503469

Epoch: 6| Step: 5
Training loss: 2.1966090202331543
Validation loss: 2.0159998734792075

Epoch: 6| Step: 6
Training loss: 2.5407204627990723
Validation loss: 2.043926457564036

Epoch: 6| Step: 7
Training loss: 1.2714433670043945
Validation loss: 2.091817259788513

Epoch: 6| Step: 8
Training loss: 1.9029624462127686
Validation loss: 2.0797340869903564

Epoch: 6| Step: 9
Training loss: 1.5919305086135864
Validation loss: 2.105506956577301

Epoch: 6| Step: 10
Training loss: 2.2733399868011475
Validation loss: 2.062809328238169

Epoch: 6| Step: 11
Training loss: 1.69087815284729
Validation loss: 2.070901016394297

Epoch: 6| Step: 12
Training loss: 1.9507865905761719
Validation loss: 2.0767848889033

Epoch: 6| Step: 13
Training loss: 2.563964366912842
Validation loss: 2.067290723323822

Epoch: 53| Step: 0
Training loss: 2.1222574710845947
Validation loss: 2.0510172049204507

Epoch: 6| Step: 1
Training loss: 1.7559564113616943
Validation loss: 2.083163022994995

Epoch: 6| Step: 2
Training loss: 1.8395496606826782
Validation loss: 2.054899791876475

Epoch: 6| Step: 3
Training loss: 1.8771628141403198
Validation loss: 2.063001533349355

Epoch: 6| Step: 4
Training loss: 1.3209311962127686
Validation loss: 2.0788330833117166

Epoch: 6| Step: 5
Training loss: 1.6462855339050293
Validation loss: 2.07245280345281

Epoch: 6| Step: 6
Training loss: 2.1579930782318115
Validation loss: 2.0668561259905496

Epoch: 6| Step: 7
Training loss: 2.131549835205078
Validation loss: 2.052007774511973

Epoch: 6| Step: 8
Training loss: 1.7259119749069214
Validation loss: 2.0586275855700173

Epoch: 6| Step: 9
Training loss: 2.8259778022766113
Validation loss: 2.077070395151774

Epoch: 6| Step: 10
Training loss: 2.1818180084228516
Validation loss: 2.07184761762619

Epoch: 6| Step: 11
Training loss: 1.7091528177261353
Validation loss: 2.0603974064191184

Epoch: 6| Step: 12
Training loss: 1.4355947971343994
Validation loss: 2.0490981340408325

Epoch: 6| Step: 13
Training loss: 2.550888776779175
Validation loss: 2.084647019704183

Epoch: 54| Step: 0
Training loss: 1.649223804473877
Validation loss: 2.069985330104828

Epoch: 6| Step: 1
Training loss: 1.6885125637054443
Validation loss: 2.1286887327829995

Epoch: 6| Step: 2
Training loss: 2.304436206817627
Validation loss: 2.097443679968516

Epoch: 6| Step: 3
Training loss: 2.474444627761841
Validation loss: 2.0814942518870034

Epoch: 6| Step: 4
Training loss: 0.9290363192558289
Validation loss: 2.1073909203211465

Epoch: 6| Step: 5
Training loss: 1.724377155303955
Validation loss: 2.078600068887075

Epoch: 6| Step: 6
Training loss: 1.3011168241500854
Validation loss: 2.082451283931732

Epoch: 6| Step: 7
Training loss: 1.9177178144454956
Validation loss: 2.075792153676351

Epoch: 6| Step: 8
Training loss: 2.739469051361084
Validation loss: 2.07418700059255

Epoch: 6| Step: 9
Training loss: 2.414978504180908
Validation loss: 2.0790263613065085

Epoch: 6| Step: 10
Training loss: 2.0692882537841797
Validation loss: 2.0762112140655518

Epoch: 6| Step: 11
Training loss: 1.84685218334198
Validation loss: 2.0987628698349

Epoch: 6| Step: 12
Training loss: 2.452192783355713
Validation loss: 2.0261589090029397

Epoch: 6| Step: 13
Training loss: 1.9409399032592773
Validation loss: 2.0814086198806763

Epoch: 55| Step: 0
Training loss: 2.6281611919403076
Validation loss: 2.035360058148702

Epoch: 6| Step: 1
Training loss: 1.4613654613494873
Validation loss: 2.052514433860779

Epoch: 6| Step: 2
Training loss: 1.949486255645752
Validation loss: 2.067944268385569

Epoch: 6| Step: 3
Training loss: 1.733928918838501
Validation loss: 2.0694530606269836

Epoch: 6| Step: 4
Training loss: 1.5530604124069214
Validation loss: 2.0922072927157083

Epoch: 6| Step: 5
Training loss: 1.6168179512023926
Validation loss: 2.0893953839937844

Epoch: 6| Step: 6
Training loss: 1.4441046714782715
Validation loss: 2.0934603214263916

Epoch: 6| Step: 7
Training loss: 2.5790815353393555
Validation loss: 2.056244969367981

Epoch: 6| Step: 8
Training loss: 2.0986361503601074
Validation loss: 2.0749868750572205

Epoch: 6| Step: 9
Training loss: 2.046969413757324
Validation loss: 2.0849789579709372

Epoch: 6| Step: 10
Training loss: 2.580349922180176
Validation loss: 2.0633826851844788

Epoch: 6| Step: 11
Training loss: 1.9350390434265137
Validation loss: 2.0696950952212014

Epoch: 6| Step: 12
Training loss: 1.6964111328125
Validation loss: 2.131613532702128

Epoch: 6| Step: 13
Training loss: 2.2607579231262207
Validation loss: 2.1598409612973533

Epoch: 56| Step: 0
Training loss: 2.5665676593780518
Validation loss: 2.1307627161343894

Epoch: 6| Step: 1
Training loss: 1.758101224899292
Validation loss: 2.168886721134186

Epoch: 6| Step: 2
Training loss: 2.554624319076538
Validation loss: 2.14090359210968

Epoch: 6| Step: 3
Training loss: 2.6798033714294434
Validation loss: 2.0930360754330954

Epoch: 6| Step: 4
Training loss: 2.255237579345703
Validation loss: 2.109695096810659

Epoch: 6| Step: 5
Training loss: 1.4466993808746338
Validation loss: 2.1022825638453164

Epoch: 6| Step: 6
Training loss: 1.6513813734054565
Validation loss: 2.087760249773661

Epoch: 6| Step: 7
Training loss: 1.4818944931030273
Validation loss: 2.090562661488851

Epoch: 6| Step: 8
Training loss: 1.3428950309753418
Validation loss: 2.064164638519287

Epoch: 6| Step: 9
Training loss: 2.4065043926239014
Validation loss: 2.075478454430898

Epoch: 6| Step: 10
Training loss: 1.64163076877594
Validation loss: 2.0788800517717996

Epoch: 6| Step: 11
Training loss: 1.74131178855896
Validation loss: 2.0423728624979653

Epoch: 6| Step: 12
Training loss: 2.1494927406311035
Validation loss: 2.082434515158335

Epoch: 6| Step: 13
Training loss: 2.0124433040618896
Validation loss: 2.0625852942466736

Epoch: 57| Step: 0
Training loss: 2.1195735931396484
Validation loss: 2.079808314641317

Epoch: 6| Step: 1
Training loss: 2.4410624504089355
Validation loss: 2.0528151392936707

Epoch: 6| Step: 2
Training loss: 1.3186166286468506
Validation loss: 2.0685946941375732

Epoch: 6| Step: 3
Training loss: 1.4485788345336914
Validation loss: 2.0593971014022827

Epoch: 6| Step: 4
Training loss: 2.3360595703125
Validation loss: 2.0256853302319846

Epoch: 6| Step: 5
Training loss: 1.9519867897033691
Validation loss: 2.0511085589726767

Epoch: 6| Step: 6
Training loss: 1.715219497680664
Validation loss: 2.0451719164848328

Epoch: 6| Step: 7
Training loss: 2.069827079772949
Validation loss: 2.0695369442303977

Epoch: 6| Step: 8
Training loss: 2.145857810974121
Validation loss: 2.0871912042299905

Epoch: 6| Step: 9
Training loss: 1.7979283332824707
Validation loss: 2.065506120522817

Epoch: 6| Step: 10
Training loss: 1.522288203239441
Validation loss: 2.0772131085395813

Epoch: 6| Step: 11
Training loss: 2.395585536956787
Validation loss: 2.0901546478271484

Epoch: 6| Step: 12
Training loss: 2.067905902862549
Validation loss: 2.1287230451901755

Epoch: 6| Step: 13
Training loss: 1.951882004737854
Validation loss: 2.1201480428377786

Epoch: 58| Step: 0
Training loss: 2.4164605140686035
Validation loss: 2.116606513659159

Epoch: 6| Step: 1
Training loss: 1.377253770828247
Validation loss: 2.0999395648638406

Epoch: 6| Step: 2
Training loss: 1.9452576637268066
Validation loss: 2.080333729585012

Epoch: 6| Step: 3
Training loss: 1.2896692752838135
Validation loss: 2.0758760571479797

Epoch: 6| Step: 4
Training loss: 2.0454261302948
Validation loss: 2.1105191707611084

Epoch: 6| Step: 5
Training loss: 1.8766833543777466
Validation loss: 2.0724686980247498

Epoch: 6| Step: 6
Training loss: 1.7810028791427612
Validation loss: 2.057682752609253

Epoch: 6| Step: 7
Training loss: 2.990302562713623
Validation loss: 2.041680693626404

Epoch: 6| Step: 8
Training loss: 1.7545406818389893
Validation loss: 2.088838259379069

Epoch: 6| Step: 9
Training loss: 1.6742069721221924
Validation loss: 2.0795952876408896

Epoch: 6| Step: 10
Training loss: 2.3050756454467773
Validation loss: 2.093495726585388

Epoch: 6| Step: 11
Training loss: 2.0902037620544434
Validation loss: 2.0623849034309387

Epoch: 6| Step: 12
Training loss: 2.2176642417907715
Validation loss: 2.0466298262278237

Epoch: 6| Step: 13
Training loss: 2.2633464336395264
Validation loss: 2.0388547579447427

Epoch: 59| Step: 0
Training loss: 1.8448456525802612
Validation loss: 2.0731654167175293

Epoch: 6| Step: 1
Training loss: 2.214759111404419
Validation loss: 2.0605161786079407

Epoch: 6| Step: 2
Training loss: 1.614472508430481
Validation loss: 2.0618971586227417

Epoch: 6| Step: 3
Training loss: 2.2929084300994873
Validation loss: 2.0463302532831826

Epoch: 6| Step: 4
Training loss: 1.8313841819763184
Validation loss: 2.0874730348587036

Epoch: 6| Step: 5
Training loss: 1.7526774406433105
Validation loss: 2.0959099531173706

Epoch: 6| Step: 6
Training loss: 2.430957794189453
Validation loss: 2.1041274070739746

Epoch: 6| Step: 7
Training loss: 2.2818520069122314
Validation loss: 2.094291925430298

Epoch: 6| Step: 8
Training loss: 2.9074478149414062
Validation loss: 2.10527894894282

Epoch: 6| Step: 9
Training loss: 1.7426578998565674
Validation loss: 2.1103574633598328

Epoch: 6| Step: 10
Training loss: 1.3551422357559204
Validation loss: 2.0729812383651733

Epoch: 6| Step: 11
Training loss: 1.5203564167022705
Validation loss: 2.1048636436462402

Epoch: 6| Step: 12
Training loss: 1.7490240335464478
Validation loss: 2.0832738876342773

Epoch: 6| Step: 13
Training loss: 1.9954636096954346
Validation loss: 2.108742892742157

Epoch: 60| Step: 0
Training loss: 1.872398018836975
Validation loss: 2.1041321953137717

Epoch: 6| Step: 1
Training loss: 1.7838308811187744
Validation loss: 2.08451916774114

Epoch: 6| Step: 2
Training loss: 1.8956258296966553
Validation loss: 2.0973301331202188

Epoch: 6| Step: 3
Training loss: 1.7653274536132812
Validation loss: 2.0773966709772744

Epoch: 6| Step: 4
Training loss: 1.7194777727127075
Validation loss: 2.077968418598175

Epoch: 6| Step: 5
Training loss: 2.581665515899658
Validation loss: 2.0153536796569824

Epoch: 6| Step: 6
Training loss: 1.9235002994537354
Validation loss: 2.072309732437134

Epoch: 6| Step: 7
Training loss: 2.0655739307403564
Validation loss: 2.0251034100850425

Epoch: 6| Step: 8
Training loss: 1.5380970239639282
Validation loss: 2.033759375413259

Epoch: 6| Step: 9
Training loss: 2.2509970664978027
Validation loss: 2.0690972805023193

Epoch: 6| Step: 10
Training loss: 1.6275794506072998
Validation loss: 2.040104866027832

Epoch: 6| Step: 11
Training loss: 2.480666160583496
Validation loss: 2.0445542534192405

Epoch: 6| Step: 12
Training loss: 1.7272231578826904
Validation loss: 2.0731999476750693

Epoch: 6| Step: 13
Training loss: 1.9763314723968506
Validation loss: 2.057598888874054

Epoch: 61| Step: 0
Training loss: 1.8166682720184326
Validation loss: 2.0892807443936667

Epoch: 6| Step: 1
Training loss: 1.8946665525436401
Validation loss: 2.080794552961985

Epoch: 6| Step: 2
Training loss: 1.9821510314941406
Validation loss: 2.0842658082644143

Epoch: 6| Step: 3
Training loss: 1.5713777542114258
Validation loss: 2.0959189335505166

Epoch: 6| Step: 4
Training loss: 1.356260061264038
Validation loss: 2.1182518204053244

Epoch: 6| Step: 5
Training loss: 1.8188316822052002
Validation loss: 2.0807939767837524

Epoch: 6| Step: 6
Training loss: 1.7381751537322998
Validation loss: 2.0923693577448526

Epoch: 6| Step: 7
Training loss: 3.118947982788086
Validation loss: 2.072490374247233

Epoch: 6| Step: 8
Training loss: 2.3001084327697754
Validation loss: 2.0730743209520974

Epoch: 6| Step: 9
Training loss: 1.9491820335388184
Validation loss: 2.1084561347961426

Epoch: 6| Step: 10
Training loss: 1.8560998439788818
Validation loss: 2.0471686323483786

Epoch: 6| Step: 11
Training loss: 1.3927947282791138
Validation loss: 2.0989254117012024

Epoch: 6| Step: 12
Training loss: 2.26684308052063
Validation loss: 2.120300054550171

Epoch: 6| Step: 13
Training loss: 1.8377259969711304
Validation loss: 2.1031728386878967

Epoch: 62| Step: 0
Training loss: 1.8919410705566406
Validation loss: 2.1103935837745667

Epoch: 6| Step: 1
Training loss: 1.9362152814865112
Validation loss: 2.0769999623298645

Epoch: 6| Step: 2
Training loss: 1.113584041595459
Validation loss: 2.1439086397488913

Epoch: 6| Step: 3
Training loss: 1.5563206672668457
Validation loss: 2.054141640663147

Epoch: 6| Step: 4
Training loss: 2.117788314819336
Validation loss: 2.0815940300623574

Epoch: 6| Step: 5
Training loss: 1.9170187711715698
Validation loss: 2.091029783089956

Epoch: 6| Step: 6
Training loss: 1.6705856323242188
Validation loss: 2.087604542573293

Epoch: 6| Step: 7
Training loss: 2.2338147163391113
Validation loss: 2.0643493930498757

Epoch: 6| Step: 8
Training loss: 2.336644172668457
Validation loss: 2.044620672861735

Epoch: 6| Step: 9
Training loss: 1.6531074047088623
Validation loss: 2.0667449037233987

Epoch: 6| Step: 10
Training loss: 1.5342555046081543
Validation loss: 2.0593758622805276

Epoch: 6| Step: 11
Training loss: 1.8879902362823486
Validation loss: 2.0560456911722818

Epoch: 6| Step: 12
Training loss: 2.379457950592041
Validation loss: 2.071968654791514

Epoch: 6| Step: 13
Training loss: 2.646033763885498
Validation loss: 2.0755744775136313

Epoch: 63| Step: 0
Training loss: 2.4235591888427734
Validation loss: 2.0792124271392822

Epoch: 6| Step: 1
Training loss: 1.6666202545166016
Validation loss: 2.085239509741465

Epoch: 6| Step: 2
Training loss: 1.5529543161392212
Validation loss: 2.068246066570282

Epoch: 6| Step: 3
Training loss: 1.9425753355026245
Validation loss: 2.0324748754501343

Epoch: 6| Step: 4
Training loss: 1.9563829898834229
Validation loss: 2.043776293595632

Epoch: 6| Step: 5
Training loss: 1.81779944896698
Validation loss: 2.0270639459292092

Epoch: 6| Step: 6
Training loss: 1.7628421783447266
Validation loss: 2.0451706449190774

Epoch: 6| Step: 7
Training loss: 2.173233985900879
Validation loss: 2.0852907299995422

Epoch: 6| Step: 8
Training loss: 2.189438819885254
Validation loss: 2.0543526808420816

Epoch: 6| Step: 9
Training loss: 1.8676406145095825
Validation loss: 2.096031665802002

Epoch: 6| Step: 10
Training loss: 2.382443904876709
Validation loss: 2.0805328488349915

Epoch: 6| Step: 11
Training loss: 1.891493320465088
Validation loss: 2.078189273675283

Epoch: 6| Step: 12
Training loss: 1.5990328788757324
Validation loss: 2.097010552883148

Epoch: 6| Step: 13
Training loss: 1.5571720600128174
Validation loss: 2.058826764424642

Epoch: 64| Step: 0
Training loss: 2.1238040924072266
Validation loss: 2.0823859175046286

Epoch: 6| Step: 1
Training loss: 1.7099337577819824
Validation loss: 2.085374673207601

Epoch: 6| Step: 2
Training loss: 2.208517551422119
Validation loss: 2.1377711097399392

Epoch: 6| Step: 3
Training loss: 2.0033130645751953
Validation loss: 2.125503977139791

Epoch: 6| Step: 4
Training loss: 2.1776628494262695
Validation loss: 2.100614527861277

Epoch: 6| Step: 5
Training loss: 1.9242384433746338
Validation loss: 2.131547292073568

Epoch: 6| Step: 6
Training loss: 2.5049214363098145
Validation loss: 2.0724979241689048

Epoch: 6| Step: 7
Training loss: 1.5722233057022095
Validation loss: 2.069247523943583

Epoch: 6| Step: 8
Training loss: 1.7884037494659424
Validation loss: 2.0569567680358887

Epoch: 6| Step: 9
Training loss: 1.5736840963363647
Validation loss: 2.0573357542355857

Epoch: 6| Step: 10
Training loss: 2.0264453887939453
Validation loss: 2.04690420627594

Epoch: 6| Step: 11
Training loss: 1.6763380765914917
Validation loss: 2.0480673710505166

Epoch: 6| Step: 12
Training loss: 1.4502301216125488
Validation loss: 2.0810694098472595

Epoch: 6| Step: 13
Training loss: 2.1206557750701904
Validation loss: 2.099384307861328

Epoch: 65| Step: 0
Training loss: 1.0255420207977295
Validation loss: 2.0669435262680054

Epoch: 6| Step: 1
Training loss: 1.392920732498169
Validation loss: 2.0434622367223105

Epoch: 6| Step: 2
Training loss: 2.1226260662078857
Validation loss: 2.078363080819448

Epoch: 6| Step: 3
Training loss: 1.8302078247070312
Validation loss: 2.057246963183085

Epoch: 6| Step: 4
Training loss: 2.300421714782715
Validation loss: 2.0558330019315085

Epoch: 6| Step: 5
Training loss: 1.7597407102584839
Validation loss: 2.086981256802877

Epoch: 6| Step: 6
Training loss: 2.053196430206299
Validation loss: 2.061577538649241

Epoch: 6| Step: 7
Training loss: 2.1004478931427
Validation loss: 2.031404435634613

Epoch: 6| Step: 8
Training loss: 2.2821412086486816
Validation loss: 2.0694236954053244

Epoch: 6| Step: 9
Training loss: 1.9032583236694336
Validation loss: 2.1288229624430337

Epoch: 6| Step: 10
Training loss: 2.545919895172119
Validation loss: 2.0955116947491965

Epoch: 6| Step: 11
Training loss: 2.0922508239746094
Validation loss: 2.111776908238729

Epoch: 6| Step: 12
Training loss: 1.636436939239502
Validation loss: 2.1078279415766397

Epoch: 6| Step: 13
Training loss: 2.027160167694092
Validation loss: 2.0770411292711892

Epoch: 66| Step: 0
Training loss: 2.185767412185669
Validation loss: 2.06191623210907

Epoch: 6| Step: 1
Training loss: 1.2893569469451904
Validation loss: 2.0822293361028037

Epoch: 6| Step: 2
Training loss: 1.875677466392517
Validation loss: 2.0576382875442505

Epoch: 6| Step: 3
Training loss: 1.4573779106140137
Validation loss: 2.0797484318415322

Epoch: 6| Step: 4
Training loss: 2.2758822441101074
Validation loss: 2.087280829747518

Epoch: 6| Step: 5
Training loss: 2.2271225452423096
Validation loss: 2.0854422648747764

Epoch: 6| Step: 6
Training loss: 2.191439628601074
Validation loss: 2.059491594632467

Epoch: 6| Step: 7
Training loss: 1.8714977502822876
Validation loss: 2.0874385635058084

Epoch: 6| Step: 8
Training loss: 2.0362443923950195
Validation loss: 2.075233062108358

Epoch: 6| Step: 9
Training loss: 1.7925119400024414
Validation loss: 2.0287190079689026

Epoch: 6| Step: 10
Training loss: 1.6723872423171997
Validation loss: 2.0660616755485535

Epoch: 6| Step: 11
Training loss: 2.368227005004883
Validation loss: 2.0523639718691506

Epoch: 6| Step: 12
Training loss: 0.9857913851737976
Validation loss: 2.073420266310374

Epoch: 6| Step: 13
Training loss: 2.13565731048584
Validation loss: 2.0611069401105246

Epoch: 67| Step: 0
Training loss: 1.4612255096435547
Validation loss: 2.081187148888906

Epoch: 6| Step: 1
Training loss: 2.296713352203369
Validation loss: 2.101754367351532

Epoch: 6| Step: 2
Training loss: 1.7293845415115356
Validation loss: 2.090528428554535

Epoch: 6| Step: 3
Training loss: 1.2977936267852783
Validation loss: 2.1032981673876443

Epoch: 6| Step: 4
Training loss: 1.2854243516921997
Validation loss: 2.1114890774091086

Epoch: 6| Step: 5
Training loss: 1.595555305480957
Validation loss: 2.0792852441469827

Epoch: 6| Step: 6
Training loss: 1.8573591709136963
Validation loss: 2.1144795219103494

Epoch: 6| Step: 7
Training loss: 1.9211876392364502
Validation loss: 2.140520672003428

Epoch: 6| Step: 8
Training loss: 2.421351194381714
Validation loss: 2.07826958100001

Epoch: 6| Step: 9
Training loss: 1.628716230392456
Validation loss: 2.124066650867462

Epoch: 6| Step: 10
Training loss: 2.618870973587036
Validation loss: 2.10095206896464

Epoch: 6| Step: 11
Training loss: 1.834740400314331
Validation loss: 2.107577304045359

Epoch: 6| Step: 12
Training loss: 3.123436450958252
Validation loss: 2.086646576722463

Epoch: 6| Step: 13
Training loss: 1.6780192852020264
Validation loss: 2.0879915356636047

Epoch: 68| Step: 0
Training loss: 1.8963476419448853
Validation loss: 2.073070148626963

Epoch: 6| Step: 1
Training loss: 2.6423850059509277
Validation loss: 2.039292554060618

Epoch: 6| Step: 2
Training loss: 1.1692955493927002
Validation loss: 2.076914687951406

Epoch: 6| Step: 3
Training loss: 1.533450722694397
Validation loss: 2.05443799495697

Epoch: 6| Step: 4
Training loss: 1.8884965181350708
Validation loss: 2.0333993236223855

Epoch: 6| Step: 5
Training loss: 1.7865709066390991
Validation loss: 2.088464538256327

Epoch: 6| Step: 6
Training loss: 1.3251581192016602
Validation loss: 2.052700857321421

Epoch: 6| Step: 7
Training loss: 2.0169529914855957
Validation loss: 2.022033711274465

Epoch: 6| Step: 8
Training loss: 1.7883260250091553
Validation loss: 2.013480464617411

Epoch: 6| Step: 9
Training loss: 2.463270664215088
Validation loss: 2.036217431227366

Epoch: 6| Step: 10
Training loss: 1.9299328327178955
Validation loss: 2.038511484861374

Epoch: 6| Step: 11
Training loss: 2.2077345848083496
Validation loss: 2.0817025899887085

Epoch: 6| Step: 12
Training loss: 2.1571056842803955
Validation loss: 2.1019568840662637

Epoch: 6| Step: 13
Training loss: 2.0262856483459473
Validation loss: 2.086487352848053

Epoch: 69| Step: 0
Training loss: 1.5810015201568604
Validation loss: 2.1008227467536926

Epoch: 6| Step: 1
Training loss: 1.46174955368042
Validation loss: 2.115665376186371

Epoch: 6| Step: 2
Training loss: 1.9057121276855469
Validation loss: 2.0856021642684937

Epoch: 6| Step: 3
Training loss: 1.9902167320251465
Validation loss: 2.0968856612841287

Epoch: 6| Step: 4
Training loss: 2.4250872135162354
Validation loss: 2.107390344142914

Epoch: 6| Step: 5
Training loss: 1.9300628900527954
Validation loss: 2.057477275530497

Epoch: 6| Step: 6
Training loss: 1.676320195198059
Validation loss: 2.0388631025950112

Epoch: 6| Step: 7
Training loss: 2.502305507659912
Validation loss: 2.0609386960665383

Epoch: 6| Step: 8
Training loss: 1.2219855785369873
Validation loss: 2.087967832883199

Epoch: 6| Step: 9
Training loss: 1.5886857509613037
Validation loss: 2.0830141504605613

Epoch: 6| Step: 10
Training loss: 2.5030765533447266
Validation loss: 2.0558858712514243

Epoch: 6| Step: 11
Training loss: 2.070201873779297
Validation loss: 2.0668508807818093

Epoch: 6| Step: 12
Training loss: 2.1158816814422607
Validation loss: 2.0393285155296326

Epoch: 6| Step: 13
Training loss: 1.6861003637313843
Validation loss: 2.0448383887608848

Epoch: 70| Step: 0
Training loss: 1.772444725036621
Validation loss: 2.097221334775289

Epoch: 6| Step: 1
Training loss: 2.157935380935669
Validation loss: 2.0444390575091043

Epoch: 6| Step: 2
Training loss: 1.485479712486267
Validation loss: 2.044384717941284

Epoch: 6| Step: 3
Training loss: 1.9141772985458374
Validation loss: 2.0542234579722085

Epoch: 6| Step: 4
Training loss: 1.8434110879898071
Validation loss: 2.048452397187551

Epoch: 6| Step: 5
Training loss: 2.179716110229492
Validation loss: 2.061525364716848

Epoch: 6| Step: 6
Training loss: 1.754575490951538
Validation loss: 2.0455060601234436

Epoch: 6| Step: 7
Training loss: 1.4975664615631104
Validation loss: 2.049203415711721

Epoch: 6| Step: 8
Training loss: 2.714539051055908
Validation loss: 2.079476992289225

Epoch: 6| Step: 9
Training loss: 1.923807144165039
Validation loss: 2.0193596283594766

Epoch: 6| Step: 10
Training loss: 2.163766622543335
Validation loss: 2.081294039885203

Epoch: 6| Step: 11
Training loss: 1.7643210887908936
Validation loss: 2.0769410928090415

Epoch: 6| Step: 12
Training loss: 1.6749470233917236
Validation loss: 2.1081254283587136

Epoch: 6| Step: 13
Training loss: 1.7083632946014404
Validation loss: 2.111634830633799

Epoch: 71| Step: 0
Training loss: 1.510854721069336
Validation loss: 2.0813326040903726

Epoch: 6| Step: 1
Training loss: 1.5914971828460693
Validation loss: 2.0905211170514426

Epoch: 6| Step: 2
Training loss: 1.951862096786499
Validation loss: 2.0987203319867453

Epoch: 6| Step: 3
Training loss: 1.5957080125808716
Validation loss: 2.1099774638811746

Epoch: 6| Step: 4
Training loss: 1.6433145999908447
Validation loss: 2.0879194339116416

Epoch: 6| Step: 5
Training loss: 2.423208713531494
Validation loss: 2.130269010861715

Epoch: 6| Step: 6
Training loss: 1.7518298625946045
Validation loss: 2.110941211382548

Epoch: 6| Step: 7
Training loss: 2.9997262954711914
Validation loss: 2.1355928977330527

Epoch: 6| Step: 8
Training loss: 1.524648666381836
Validation loss: 2.098076343536377

Epoch: 6| Step: 9
Training loss: 2.053093910217285
Validation loss: 2.0913541515668235

Epoch: 6| Step: 10
Training loss: 1.6628785133361816
Validation loss: 2.0995503862698874

Epoch: 6| Step: 11
Training loss: 2.1737751960754395
Validation loss: 2.1038080056508384

Epoch: 6| Step: 12
Training loss: 1.5255393981933594
Validation loss: 2.053288141886393

Epoch: 6| Step: 13
Training loss: 1.7504312992095947
Validation loss: 2.0930590430895486

Epoch: 72| Step: 0
Training loss: 1.5929548740386963
Validation loss: 2.0545687278111777

Epoch: 6| Step: 1
Training loss: 1.3881765604019165
Validation loss: 2.0271681745847068

Epoch: 6| Step: 2
Training loss: 1.952531099319458
Validation loss: 2.063302477200826

Epoch: 6| Step: 3
Training loss: 2.4500479698181152
Validation loss: 2.0452649195988974

Epoch: 6| Step: 4
Training loss: 1.8217897415161133
Validation loss: 2.076816419760386

Epoch: 6| Step: 5
Training loss: 2.148895502090454
Validation loss: 2.04621152083079

Epoch: 6| Step: 6
Training loss: 1.2438607215881348
Validation loss: 2.087973952293396

Epoch: 6| Step: 7
Training loss: 2.0045881271362305
Validation loss: 2.044022719065348

Epoch: 6| Step: 8
Training loss: 1.757203221321106
Validation loss: 2.060537338256836

Epoch: 6| Step: 9
Training loss: 2.019049644470215
Validation loss: 2.0661686658859253

Epoch: 6| Step: 10
Training loss: 1.5135412216186523
Validation loss: 2.050304194291433

Epoch: 6| Step: 11
Training loss: 2.0356359481811523
Validation loss: 2.11349626382192

Epoch: 6| Step: 12
Training loss: 2.218449592590332
Validation loss: 2.073855936527252

Epoch: 6| Step: 13
Training loss: 2.1059255599975586
Validation loss: 2.072017788887024

Epoch: 73| Step: 0
Training loss: 1.8566190004348755
Validation loss: 2.113156775633494

Epoch: 6| Step: 1
Training loss: 2.130047559738159
Validation loss: 2.0936579505602517

Epoch: 6| Step: 2
Training loss: 1.6228164434432983
Validation loss: 2.075486501057943

Epoch: 6| Step: 3
Training loss: 1.8147157430648804
Validation loss: 2.062461038430532

Epoch: 6| Step: 4
Training loss: 1.5265206098556519
Validation loss: 2.0553579529126487

Epoch: 6| Step: 5
Training loss: 2.2231054306030273
Validation loss: 2.083071490128835

Epoch: 6| Step: 6
Training loss: 1.3248975276947021
Validation loss: 2.078068276246389

Epoch: 6| Step: 7
Training loss: 2.131887674331665
Validation loss: 2.0638811190923056

Epoch: 6| Step: 8
Training loss: 2.048802375793457
Validation loss: 2.0790979067484536

Epoch: 6| Step: 9
Training loss: 1.3422105312347412
Validation loss: 2.0826743443806968

Epoch: 6| Step: 10
Training loss: 2.281005859375
Validation loss: 2.1091055671374

Epoch: 6| Step: 11
Training loss: 1.8236503601074219
Validation loss: 2.105901916821798

Epoch: 6| Step: 12
Training loss: 2.0138769149780273
Validation loss: 2.1050144831339517

Epoch: 6| Step: 13
Training loss: 2.119994640350342
Validation loss: 2.0692454179128013

Epoch: 74| Step: 0
Training loss: 1.2490934133529663
Validation loss: 2.145680586496989

Epoch: 6| Step: 1
Training loss: 1.97230863571167
Validation loss: 2.133994162082672

Epoch: 6| Step: 2
Training loss: 2.3785793781280518
Validation loss: 2.11747944355011

Epoch: 6| Step: 3
Training loss: 0.9924850463867188
Validation loss: 2.113726496696472

Epoch: 6| Step: 4
Training loss: 2.5537595748901367
Validation loss: 2.0659277637799582

Epoch: 6| Step: 5
Training loss: 2.185023784637451
Validation loss: 2.050102432568868

Epoch: 6| Step: 6
Training loss: 1.4724699258804321
Validation loss: 2.0325080355008445

Epoch: 6| Step: 7
Training loss: 2.6073999404907227
Validation loss: 2.0712342063585916

Epoch: 6| Step: 8
Training loss: 2.053269386291504
Validation loss: 2.072360396385193

Epoch: 6| Step: 9
Training loss: 2.0926852226257324
Validation loss: 2.0497670769691467

Epoch: 6| Step: 10
Training loss: 1.511843204498291
Validation loss: 2.080508311589559

Epoch: 6| Step: 11
Training loss: 1.5480667352676392
Validation loss: 2.0458754499753318

Epoch: 6| Step: 12
Training loss: 2.127440929412842
Validation loss: 2.0808520118395486

Epoch: 6| Step: 13
Training loss: 1.5677428245544434
Validation loss: 2.050044894218445

Epoch: 75| Step: 0
Training loss: 2.3271324634552
Validation loss: 2.0403342843055725

Epoch: 6| Step: 1
Training loss: 2.176286220550537
Validation loss: 2.0484296083450317

Epoch: 6| Step: 2
Training loss: 1.45725679397583
Validation loss: 2.05389396349589

Epoch: 6| Step: 3
Training loss: 2.1135499477386475
Validation loss: 2.0854275226593018

Epoch: 6| Step: 4
Training loss: 1.8696739673614502
Validation loss: 2.074670155843099

Epoch: 6| Step: 5
Training loss: 1.6668500900268555
Validation loss: 2.100802560647329

Epoch: 6| Step: 6
Training loss: 1.2343939542770386
Validation loss: 2.108670473098755

Epoch: 6| Step: 7
Training loss: 1.8439314365386963
Validation loss: 2.1091601053873696

Epoch: 6| Step: 8
Training loss: 2.282254457473755
Validation loss: 2.113155464331309

Epoch: 6| Step: 9
Training loss: 1.5166072845458984
Validation loss: 2.0819538036982217

Epoch: 6| Step: 10
Training loss: 2.1940839290618896
Validation loss: 2.076172431310018

Epoch: 6| Step: 11
Training loss: 1.7299432754516602
Validation loss: 2.065873086452484

Epoch: 6| Step: 12
Training loss: 1.478240728378296
Validation loss: 2.0428123275438943

Epoch: 6| Step: 13
Training loss: 2.1999731063842773
Validation loss: 2.071317195892334

Epoch: 76| Step: 0
Training loss: 1.660555124282837
Validation loss: 2.039162000020345

Epoch: 6| Step: 1
Training loss: 2.147965908050537
Validation loss: 2.0502877036730447

Epoch: 6| Step: 2
Training loss: 1.9899049997329712
Validation loss: 2.058643937110901

Epoch: 6| Step: 3
Training loss: 2.453015089035034
Validation loss: 2.0679324865341187

Epoch: 6| Step: 4
Training loss: 1.4543001651763916
Validation loss: 2.0392563144365945

Epoch: 6| Step: 5
Training loss: 2.232654333114624
Validation loss: 2.0518477956453958

Epoch: 6| Step: 6
Training loss: 2.3744688034057617
Validation loss: 2.075615962346395

Epoch: 6| Step: 7
Training loss: 1.8459441661834717
Validation loss: 2.054576555887858

Epoch: 6| Step: 8
Training loss: 1.4736398458480835
Validation loss: 2.0604143341382346

Epoch: 6| Step: 9
Training loss: 2.0343809127807617
Validation loss: 2.059426248073578

Epoch: 6| Step: 10
Training loss: 1.8901264667510986
Validation loss: 2.084216078122457

Epoch: 6| Step: 11
Training loss: 1.6945279836654663
Validation loss: 2.052486260732015

Epoch: 6| Step: 12
Training loss: 1.8152074813842773
Validation loss: 2.0778205394744873

Epoch: 6| Step: 13
Training loss: 1.4572248458862305
Validation loss: 2.061769743760427

Epoch: 77| Step: 0
Training loss: 2.468949317932129
Validation loss: 2.059328079223633

Epoch: 6| Step: 1
Training loss: 2.4112114906311035
Validation loss: 2.040138761202494

Epoch: 6| Step: 2
Training loss: 1.9865062236785889
Validation loss: 2.0313764611879983

Epoch: 6| Step: 3
Training loss: 1.8273919820785522
Validation loss: 2.067479888598124

Epoch: 6| Step: 4
Training loss: 1.3574035167694092
Validation loss: 2.020115613937378

Epoch: 6| Step: 5
Training loss: 1.8997910022735596
Validation loss: 2.0648602644602456

Epoch: 6| Step: 6
Training loss: 1.8734201192855835
Validation loss: 2.047108848889669

Epoch: 6| Step: 7
Training loss: 1.8873276710510254
Validation loss: 2.0618484020233154

Epoch: 6| Step: 8
Training loss: 1.4087908267974854
Validation loss: 2.08988889058431

Epoch: 6| Step: 9
Training loss: 1.5593054294586182
Validation loss: 2.059658388296763

Epoch: 6| Step: 10
Training loss: 1.907024621963501
Validation loss: 2.0520979364713035

Epoch: 6| Step: 11
Training loss: 1.9589543342590332
Validation loss: 2.0882135033607483

Epoch: 6| Step: 12
Training loss: 1.726588249206543
Validation loss: 2.0500568946202598

Epoch: 6| Step: 13
Training loss: 1.4767935276031494
Validation loss: 2.088780085245768

Epoch: 78| Step: 0
Training loss: 1.9372848272323608
Validation loss: 2.0537062088648477

Epoch: 6| Step: 1
Training loss: 2.2793936729431152
Validation loss: 2.1035688519477844

Epoch: 6| Step: 2
Training loss: 1.1343133449554443
Validation loss: 2.0944197177886963

Epoch: 6| Step: 3
Training loss: 1.6374413967132568
Validation loss: 2.0934898853302

Epoch: 6| Step: 4
Training loss: 1.4470553398132324
Validation loss: 2.1051867604255676

Epoch: 6| Step: 5
Training loss: 2.1461338996887207
Validation loss: 2.107805152734121

Epoch: 6| Step: 6
Training loss: 1.6487082242965698
Validation loss: 2.096550007661184

Epoch: 6| Step: 7
Training loss: 2.2791733741760254
Validation loss: 2.109897553920746

Epoch: 6| Step: 8
Training loss: 2.209456205368042
Validation loss: 2.039717455705007

Epoch: 6| Step: 9
Training loss: 1.6772116422653198
Validation loss: 2.091818352540334

Epoch: 6| Step: 10
Training loss: 2.1769771575927734
Validation loss: 2.0390599568684897

Epoch: 6| Step: 11
Training loss: 1.4177151918411255
Validation loss: 2.056645452976227

Epoch: 6| Step: 12
Training loss: 1.6432536840438843
Validation loss: 2.040237784385681

Epoch: 6| Step: 13
Training loss: 2.2047576904296875
Validation loss: 2.054102063179016

Epoch: 79| Step: 0
Training loss: 1.1664198637008667
Validation loss: 2.0662575165430703

Epoch: 6| Step: 1
Training loss: 1.66745126247406
Validation loss: 2.0732490022977195

Epoch: 6| Step: 2
Training loss: 1.8009066581726074
Validation loss: 2.0436391830444336

Epoch: 6| Step: 3
Training loss: 2.0529465675354004
Validation loss: 2.047003368536631

Epoch: 6| Step: 4
Training loss: 1.4671356678009033
Validation loss: 2.083805779616038

Epoch: 6| Step: 5
Training loss: 2.0074057579040527
Validation loss: 2.1046398083368936

Epoch: 6| Step: 6
Training loss: 2.3263514041900635
Validation loss: 2.071333964665731

Epoch: 6| Step: 7
Training loss: 2.237776756286621
Validation loss: 2.070801575978597

Epoch: 6| Step: 8
Training loss: 1.752859115600586
Validation loss: 2.101178685824076

Epoch: 6| Step: 9
Training loss: 2.0083932876586914
Validation loss: 2.0661184787750244

Epoch: 6| Step: 10
Training loss: 1.8867084980010986
Validation loss: 2.095059851805369

Epoch: 6| Step: 11
Training loss: 1.8064016103744507
Validation loss: 2.0394192139307656

Epoch: 6| Step: 12
Training loss: 2.094860553741455
Validation loss: 2.0357235868771872

Epoch: 6| Step: 13
Training loss: 1.6025192737579346
Validation loss: 2.0401191314061484

Epoch: 80| Step: 0
Training loss: 2.003894567489624
Validation loss: 2.0832875768343606

Epoch: 6| Step: 1
Training loss: 1.8181321620941162
Validation loss: 2.0593164761861167

Epoch: 6| Step: 2
Training loss: 2.4044461250305176
Validation loss: 2.0542765259742737

Epoch: 6| Step: 3
Training loss: 1.8727552890777588
Validation loss: 2.072433888912201

Epoch: 6| Step: 4
Training loss: 1.9684488773345947
Validation loss: 2.1128900051116943

Epoch: 6| Step: 5
Training loss: 2.2091193199157715
Validation loss: 2.0730415185292563

Epoch: 6| Step: 6
Training loss: 1.6991314888000488
Validation loss: 2.0858824451764426

Epoch: 6| Step: 7
Training loss: 1.1842926740646362
Validation loss: 2.0816115140914917

Epoch: 6| Step: 8
Training loss: 1.5557513236999512
Validation loss: 2.0940478642781577

Epoch: 6| Step: 9
Training loss: 1.5219355821609497
Validation loss: 2.071054776509603

Epoch: 6| Step: 10
Training loss: 2.3807716369628906
Validation loss: 2.1103882789611816

Epoch: 6| Step: 11
Training loss: 1.9643193483352661
Validation loss: 2.0976224144299827

Epoch: 6| Step: 12
Training loss: 1.6123607158660889
Validation loss: 2.1319814125696817

Epoch: 6| Step: 13
Training loss: 1.683379054069519
Validation loss: 2.1199311216672263

Epoch: 81| Step: 0
Training loss: 1.5068140029907227
Validation loss: 2.1173513929049173

Epoch: 6| Step: 1
Training loss: 1.9475237131118774
Validation loss: 2.1148025393486023

Epoch: 6| Step: 2
Training loss: 2.1533751487731934
Validation loss: 2.0773310462633767

Epoch: 6| Step: 3
Training loss: 1.426872968673706
Validation loss: 2.0915061434110007

Epoch: 6| Step: 4
Training loss: 1.9831092357635498
Validation loss: 2.099717656771342

Epoch: 6| Step: 5
Training loss: 2.5413966178894043
Validation loss: 2.141840616861979

Epoch: 6| Step: 6
Training loss: 1.1380120515823364
Validation loss: 2.089997629324595

Epoch: 6| Step: 7
Training loss: 2.2633919715881348
Validation loss: 2.112359563509623

Epoch: 6| Step: 8
Training loss: 1.4207103252410889
Validation loss: 2.0624093214670816

Epoch: 6| Step: 9
Training loss: 1.58394455909729
Validation loss: 2.093648354212443

Epoch: 6| Step: 10
Training loss: 1.4984443187713623
Validation loss: 2.0750073393185935

Epoch: 6| Step: 11
Training loss: 2.4148776531219482
Validation loss: 2.065408726533254

Epoch: 6| Step: 12
Training loss: 1.688904881477356
Validation loss: 2.0644090374310813

Epoch: 6| Step: 13
Training loss: 2.194337844848633
Validation loss: 2.0410598317782083

Epoch: 82| Step: 0
Training loss: 1.7707914113998413
Validation loss: 2.032973607381185

Epoch: 6| Step: 1
Training loss: 2.0935020446777344
Validation loss: 2.031800846258799

Epoch: 6| Step: 2
Training loss: 1.7770676612854004
Validation loss: 2.0927947759628296

Epoch: 6| Step: 3
Training loss: 1.4422789812088013
Validation loss: 2.051149070262909

Epoch: 6| Step: 4
Training loss: 1.7945795059204102
Validation loss: 2.0253843863805137

Epoch: 6| Step: 5
Training loss: 1.4824106693267822
Validation loss: 2.0652677416801453

Epoch: 6| Step: 6
Training loss: 2.2079977989196777
Validation loss: 2.062039236227671

Epoch: 6| Step: 7
Training loss: 1.821972370147705
Validation loss: 2.0623456637064614

Epoch: 6| Step: 8
Training loss: 2.1860222816467285
Validation loss: 2.0872698227564492

Epoch: 6| Step: 9
Training loss: 1.0571225881576538
Validation loss: 2.0350754062334695

Epoch: 6| Step: 10
Training loss: 1.7669572830200195
Validation loss: 2.0553762118021646

Epoch: 6| Step: 11
Training loss: 1.8676674365997314
Validation loss: 2.074229061603546

Epoch: 6| Step: 12
Training loss: 2.8321797847747803
Validation loss: 2.0976518789927163

Epoch: 6| Step: 13
Training loss: 1.8006658554077148
Validation loss: 2.1007579366366067

Epoch: 83| Step: 0
Training loss: 1.251203179359436
Validation loss: 2.0810526609420776

Epoch: 6| Step: 1
Training loss: 1.622005581855774
Validation loss: 2.0519684751828513

Epoch: 6| Step: 2
Training loss: 2.4861550331115723
Validation loss: 2.0519548654556274

Epoch: 6| Step: 3
Training loss: 2.4963107109069824
Validation loss: 2.113478640715281

Epoch: 6| Step: 4
Training loss: 1.4365322589874268
Validation loss: 2.083645761013031

Epoch: 6| Step: 5
Training loss: 2.0752882957458496
Validation loss: 2.1422912081082663

Epoch: 6| Step: 6
Training loss: 1.4229276180267334
Validation loss: 2.136201103528341

Epoch: 6| Step: 7
Training loss: 2.0314767360687256
Validation loss: 2.1651591459910073

Epoch: 6| Step: 8
Training loss: 1.8150529861450195
Validation loss: 2.1248735785484314

Epoch: 6| Step: 9
Training loss: 2.4035768508911133
Validation loss: 2.1193395256996155

Epoch: 6| Step: 10
Training loss: 1.4280835390090942
Validation loss: 2.0743507941563926

Epoch: 6| Step: 11
Training loss: 1.4868032932281494
Validation loss: 2.0963053703308105

Epoch: 6| Step: 12
Training loss: 2.073479175567627
Validation loss: 2.05624920129776

Epoch: 6| Step: 13
Training loss: 1.7820037603378296
Validation loss: 2.0451748371124268

Epoch: 84| Step: 0
Training loss: 1.5210964679718018
Validation loss: 2.042068898677826

Epoch: 6| Step: 1
Training loss: 2.616802215576172
Validation loss: 2.062730630238851

Epoch: 6| Step: 2
Training loss: 1.6431009769439697
Validation loss: 2.0941640039285025

Epoch: 6| Step: 3
Training loss: 1.6594637632369995
Validation loss: 2.0882044434547424

Epoch: 6| Step: 4
Training loss: 1.836276650428772
Validation loss: 2.080956300099691

Epoch: 6| Step: 5
Training loss: 1.8566005229949951
Validation loss: 2.076922277609507

Epoch: 6| Step: 6
Training loss: 1.8024338483810425
Validation loss: 2.0400867462158203

Epoch: 6| Step: 7
Training loss: 1.3653686046600342
Validation loss: 2.0778124729792276

Epoch: 6| Step: 8
Training loss: 2.941092014312744
Validation loss: 2.076228121916453

Epoch: 6| Step: 9
Training loss: 2.29103684425354
Validation loss: 2.0929190516471863

Epoch: 6| Step: 10
Training loss: 1.6049917936325073
Validation loss: 2.0927675565083823

Epoch: 6| Step: 11
Training loss: 1.596267580986023
Validation loss: 2.1094476779301963

Epoch: 6| Step: 12
Training loss: 1.4898664951324463
Validation loss: 2.1152544816335044

Epoch: 6| Step: 13
Training loss: 1.5695133209228516
Validation loss: 2.0973296960194907

Epoch: 85| Step: 0
Training loss: 1.7710165977478027
Validation loss: 2.1012386083602905

Epoch: 6| Step: 1
Training loss: 1.577270746231079
Validation loss: 2.138552109400431

Epoch: 6| Step: 2
Training loss: 1.624328374862671
Validation loss: 2.1009514530499778

Epoch: 6| Step: 3
Training loss: 1.768397331237793
Validation loss: 2.1056755979855857

Epoch: 6| Step: 4
Training loss: 1.7000102996826172
Validation loss: 2.052946945031484

Epoch: 6| Step: 5
Training loss: 1.8934204578399658
Validation loss: 2.0599572459856668

Epoch: 6| Step: 6
Training loss: 2.160480499267578
Validation loss: 2.0886120994885764

Epoch: 6| Step: 7
Training loss: 1.8439302444458008
Validation loss: 2.0549166997273765

Epoch: 6| Step: 8
Training loss: 2.3009161949157715
Validation loss: 2.026765008767446

Epoch: 6| Step: 9
Training loss: 1.3527780771255493
Validation loss: 2.059923609097799

Epoch: 6| Step: 10
Training loss: 1.9220664501190186
Validation loss: 2.059902290503184

Epoch: 6| Step: 11
Training loss: 1.942482829093933
Validation loss: 2.082520624001821

Epoch: 6| Step: 12
Training loss: 1.9104148149490356
Validation loss: 2.037627557913462

Epoch: 6| Step: 13
Training loss: 1.7861624956130981
Validation loss: 2.059643586476644

Epoch: 86| Step: 0
Training loss: 2.252531051635742
Validation loss: 2.0775509079297385

Epoch: 6| Step: 1
Training loss: 2.689126491546631
Validation loss: 2.1078811089197793

Epoch: 6| Step: 2
Training loss: 1.6682240962982178
Validation loss: 2.063375393549601

Epoch: 6| Step: 3
Training loss: 1.3568699359893799
Validation loss: 2.105852961540222

Epoch: 6| Step: 4
Training loss: 2.352961540222168
Validation loss: 2.1496976812680564

Epoch: 6| Step: 5
Training loss: 1.5473344326019287
Validation loss: 2.1064840952555337

Epoch: 6| Step: 6
Training loss: 1.9324413537979126
Validation loss: 2.1048438946406045

Epoch: 6| Step: 7
Training loss: 1.4230350255966187
Validation loss: 2.1236491401990256

Epoch: 6| Step: 8
Training loss: 1.1558325290679932
Validation loss: 2.1215325196584067

Epoch: 6| Step: 9
Training loss: 1.6986732482910156
Validation loss: 2.0603906313578286

Epoch: 6| Step: 10
Training loss: 2.2410988807678223
Validation loss: 2.056139369805654

Epoch: 6| Step: 11
Training loss: 1.3682836294174194
Validation loss: 2.0759554306666055

Epoch: 6| Step: 12
Training loss: 2.002129316329956
Validation loss: 2.055572231610616

Epoch: 6| Step: 13
Training loss: 1.8607019186019897
Validation loss: 2.0647037823994956

Epoch: 87| Step: 0
Training loss: 1.6985657215118408
Validation loss: 2.0619133909543357

Epoch: 6| Step: 1
Training loss: 1.6159470081329346
Validation loss: 2.074323038260142

Epoch: 6| Step: 2
Training loss: 2.4439446926116943
Validation loss: 2.0628333687782288

Epoch: 6| Step: 3
Training loss: 2.285489559173584
Validation loss: 2.0650661389033

Epoch: 6| Step: 4
Training loss: 2.153374195098877
Validation loss: 2.104878604412079

Epoch: 6| Step: 5
Training loss: 1.8716771602630615
Validation loss: 2.1032931407292685

Epoch: 6| Step: 6
Training loss: 1.519604206085205
Validation loss: 2.058956801891327

Epoch: 6| Step: 7
Training loss: 2.026723623275757
Validation loss: 2.0750431219736734

Epoch: 6| Step: 8
Training loss: 1.8475643396377563
Validation loss: 2.0444297989209494

Epoch: 6| Step: 9
Training loss: 1.3846385478973389
Validation loss: 2.0903805096944175

Epoch: 6| Step: 10
Training loss: 1.6736328601837158
Validation loss: 2.0655025839805603

Epoch: 6| Step: 11
Training loss: 1.4233453273773193
Validation loss: 2.0838659008344016

Epoch: 6| Step: 12
Training loss: 2.0313992500305176
Validation loss: 2.0892105301221213

Epoch: 6| Step: 13
Training loss: 1.8624529838562012
Validation loss: 2.0982877214749656

Epoch: 88| Step: 0
Training loss: 1.5006235837936401
Validation loss: 2.076468586921692

Epoch: 6| Step: 1
Training loss: 1.9351451396942139
Validation loss: 2.0817851424217224

Epoch: 6| Step: 2
Training loss: 1.9319231510162354
Validation loss: 2.0487749179204306

Epoch: 6| Step: 3
Training loss: 1.3668999671936035
Validation loss: 2.0641752084096274

Epoch: 6| Step: 4
Training loss: 1.8345175981521606
Validation loss: 2.0577256083488464

Epoch: 6| Step: 5
Training loss: 1.3047540187835693
Validation loss: 2.063174565633138

Epoch: 6| Step: 6
Training loss: 1.4657559394836426
Validation loss: 2.0606581568717957

Epoch: 6| Step: 7
Training loss: 2.315199375152588
Validation loss: 2.0781440337498984

Epoch: 6| Step: 8
Training loss: 2.3223459720611572
Validation loss: 2.0504630406697593

Epoch: 6| Step: 9
Training loss: 1.5156097412109375
Validation loss: 2.0657514731089273

Epoch: 6| Step: 10
Training loss: 1.641732931137085
Validation loss: 2.0471036036809287

Epoch: 6| Step: 11
Training loss: 1.5980689525604248
Validation loss: 2.064360499382019

Epoch: 6| Step: 12
Training loss: 2.254180908203125
Validation loss: 2.0358259280522666

Epoch: 6| Step: 13
Training loss: 2.0591444969177246
Validation loss: 2.0267817775408425

Epoch: 89| Step: 0
Training loss: 1.454947829246521
Validation loss: 2.0361141165097556

Epoch: 6| Step: 1
Training loss: 1.5819166898727417
Validation loss: 2.06689715385437

Epoch: 6| Step: 2
Training loss: 1.8178486824035645
Validation loss: 2.058172802130381

Epoch: 6| Step: 3
Training loss: 2.493347406387329
Validation loss: 2.0579683780670166

Epoch: 6| Step: 4
Training loss: 1.5919075012207031
Validation loss: 2.0465312600135803

Epoch: 6| Step: 5
Training loss: 1.2979793548583984
Validation loss: 2.0810922384262085

Epoch: 6| Step: 6
Training loss: 1.4993646144866943
Validation loss: 2.0841773748397827

Epoch: 6| Step: 7
Training loss: 1.9742348194122314
Validation loss: 2.0465232332547507

Epoch: 6| Step: 8
Training loss: 1.83158278465271
Validation loss: 2.0559711257616677

Epoch: 6| Step: 9
Training loss: 2.0146501064300537
Validation loss: 2.1102718909581504

Epoch: 6| Step: 10
Training loss: 2.019307851791382
Validation loss: 2.135243813196818

Epoch: 6| Step: 11
Training loss: 1.6718316078186035
Validation loss: 2.1279930075009665

Epoch: 6| Step: 12
Training loss: 1.9124497175216675
Validation loss: 2.151016573111216

Epoch: 6| Step: 13
Training loss: 1.5577293634414673
Validation loss: 2.05580864350001

Epoch: 90| Step: 0
Training loss: 1.6245869398117065
Validation loss: 2.0493650237719216

Epoch: 6| Step: 1
Training loss: 1.4501012563705444
Validation loss: 2.0299649238586426

Epoch: 6| Step: 2
Training loss: 1.636351227760315
Validation loss: 2.0924775997797647

Epoch: 6| Step: 3
Training loss: 2.035008430480957
Validation loss: 2.06196000178655

Epoch: 6| Step: 4
Training loss: 1.9996525049209595
Validation loss: 2.0785215695699057

Epoch: 6| Step: 5
Training loss: 1.8292558193206787
Validation loss: 2.052942395210266

Epoch: 6| Step: 6
Training loss: 2.166938304901123
Validation loss: 2.045151730378469

Epoch: 6| Step: 7
Training loss: 2.581676483154297
Validation loss: 2.0736180941263833

Epoch: 6| Step: 8
Training loss: 1.4782600402832031
Validation loss: 2.03482723236084

Epoch: 6| Step: 9
Training loss: 2.030005931854248
Validation loss: 2.051920553048452

Epoch: 6| Step: 10
Training loss: 0.9024901390075684
Validation loss: 2.0260915954907737

Epoch: 6| Step: 11
Training loss: 1.8498419523239136
Validation loss: 2.0552729964256287

Epoch: 6| Step: 12
Training loss: 1.8338844776153564
Validation loss: 2.0409106413523355

Epoch: 6| Step: 13
Training loss: 1.8222553730010986
Validation loss: 2.0541463096936545

Epoch: 91| Step: 0
Training loss: 1.9837170839309692
Validation loss: 2.0678316752115884

Epoch: 6| Step: 1
Training loss: 1.846933126449585
Validation loss: 2.0831799308458963

Epoch: 6| Step: 2
Training loss: 1.8810269832611084
Validation loss: 2.12752374013265

Epoch: 6| Step: 3
Training loss: 1.3750678300857544
Validation loss: 2.177858134110769

Epoch: 6| Step: 4
Training loss: 2.251142978668213
Validation loss: 2.158657451470693

Epoch: 6| Step: 5
Training loss: 1.9765746593475342
Validation loss: 2.1748845179875693

Epoch: 6| Step: 6
Training loss: 1.7244949340820312
Validation loss: 2.2006442149480185

Epoch: 6| Step: 7
Training loss: 2.3775672912597656
Validation loss: 2.1394549012184143

Epoch: 6| Step: 8
Training loss: 1.266808032989502
Validation loss: 2.1252729098002114

Epoch: 6| Step: 9
Training loss: 1.740577220916748
Validation loss: 2.1252192656199136

Epoch: 6| Step: 10
Training loss: 1.5838786363601685
Validation loss: 2.0973146160443625

Epoch: 6| Step: 11
Training loss: 1.560115933418274
Validation loss: 2.0739189187685647

Epoch: 6| Step: 12
Training loss: 1.5377693176269531
Validation loss: 2.058219234148661

Epoch: 6| Step: 13
Training loss: 2.0187766551971436
Validation loss: 2.058241883913676

Epoch: 92| Step: 0
Training loss: 1.8807936906814575
Validation loss: 2.0313852429389954

Epoch: 6| Step: 1
Training loss: 2.3845179080963135
Validation loss: 2.0359941323598227

Epoch: 6| Step: 2
Training loss: 1.809631586074829
Validation loss: 2.0949267148971558

Epoch: 6| Step: 3
Training loss: 1.6245250701904297
Validation loss: 2.0913624366124473

Epoch: 6| Step: 4
Training loss: 2.0933077335357666
Validation loss: 2.0556049942970276

Epoch: 6| Step: 5
Training loss: 1.4776942729949951
Validation loss: 2.0565492113431296

Epoch: 6| Step: 6
Training loss: 2.346614122390747
Validation loss: 2.0622013211250305

Epoch: 6| Step: 7
Training loss: 1.7060699462890625
Validation loss: 2.0412737925847373

Epoch: 6| Step: 8
Training loss: 1.861067533493042
Validation loss: 2.028265376885732

Epoch: 6| Step: 9
Training loss: 1.296056866645813
Validation loss: 2.0306261777877808

Epoch: 6| Step: 10
Training loss: 1.45212721824646
Validation loss: 2.0458902716636658

Epoch: 6| Step: 11
Training loss: 1.2313010692596436
Validation loss: 2.0612857143084207

Epoch: 6| Step: 12
Training loss: 1.8832595348358154
Validation loss: 2.14453254143397

Epoch: 6| Step: 13
Training loss: 1.9511222839355469
Validation loss: 2.190483013788859

Epoch: 93| Step: 0
Training loss: 1.0904498100280762
Validation loss: 2.1490556995073953

Epoch: 6| Step: 1
Training loss: 1.5632765293121338
Validation loss: 2.1895787119865417

Epoch: 6| Step: 2
Training loss: 1.7259106636047363
Validation loss: 2.205031434694926

Epoch: 6| Step: 3
Training loss: 2.6360573768615723
Validation loss: 2.204074263572693

Epoch: 6| Step: 4
Training loss: 1.960840106010437
Validation loss: 2.160639444986979

Epoch: 6| Step: 5
Training loss: 1.8887606859207153
Validation loss: 2.110415796438853

Epoch: 6| Step: 6
Training loss: 1.605433702468872
Validation loss: 2.0696308414141336

Epoch: 6| Step: 7
Training loss: 2.015092372894287
Validation loss: 2.13930873076121

Epoch: 6| Step: 8
Training loss: 1.837058424949646
Validation loss: 2.08430023988088

Epoch: 6| Step: 9
Training loss: 1.714021921157837
Validation loss: 2.079316516717275

Epoch: 6| Step: 10
Training loss: 2.03456449508667
Validation loss: 2.0745745499928794

Epoch: 6| Step: 11
Training loss: 1.2130885124206543
Validation loss: 2.0870835979779563

Epoch: 6| Step: 12
Training loss: 1.9321670532226562
Validation loss: 2.0625638365745544

Epoch: 6| Step: 13
Training loss: 1.6468948125839233
Validation loss: 2.0698200861612954

Epoch: 94| Step: 0
Training loss: 1.6602413654327393
Validation loss: 2.0735758344332376

Epoch: 6| Step: 1
Training loss: 1.933377742767334
Validation loss: 2.0707539319992065

Epoch: 6| Step: 2
Training loss: 1.7154992818832397
Validation loss: 2.0395970741907754

Epoch: 6| Step: 3
Training loss: 2.3038973808288574
Validation loss: 2.05191578467687

Epoch: 6| Step: 4
Training loss: 2.706763744354248
Validation loss: 2.0421769420305886

Epoch: 6| Step: 5
Training loss: 2.174588203430176
Validation loss: 2.0302823384602866

Epoch: 6| Step: 6
Training loss: 1.079138994216919
Validation loss: 2.050886889298757

Epoch: 6| Step: 7
Training loss: 1.2845896482467651
Validation loss: 2.059008300304413

Epoch: 6| Step: 8
Training loss: 1.4467343091964722
Validation loss: 2.053341527779897

Epoch: 6| Step: 9
Training loss: 1.3552672863006592
Validation loss: 2.074641207853953

Epoch: 6| Step: 10
Training loss: 1.5797193050384521
Validation loss: 2.064314603805542

Epoch: 6| Step: 11
Training loss: 1.7780160903930664
Validation loss: 2.065664052963257

Epoch: 6| Step: 12
Training loss: 1.6998001337051392
Validation loss: 2.1430070996284485

Epoch: 6| Step: 13
Training loss: 1.3627256155014038
Validation loss: 2.1441950599352517

Epoch: 95| Step: 0
Training loss: 2.3648486137390137
Validation loss: 2.138439893722534

Epoch: 6| Step: 1
Training loss: 1.41855788230896
Validation loss: 2.158843676249186

Epoch: 6| Step: 2
Training loss: 1.2649388313293457
Validation loss: 2.1363957722981772

Epoch: 6| Step: 3
Training loss: 1.8041794300079346
Validation loss: 2.1582621137301126

Epoch: 6| Step: 4
Training loss: 2.3004848957061768
Validation loss: 2.0887680649757385

Epoch: 6| Step: 5
Training loss: 0.6750439405441284
Validation loss: 2.029574533303579

Epoch: 6| Step: 6
Training loss: 1.9684094190597534
Validation loss: 2.0824762980143228

Epoch: 6| Step: 7
Training loss: 2.1636769771575928
Validation loss: 2.065817872683207

Epoch: 6| Step: 8
Training loss: 1.5474176406860352
Validation loss: 2.0543256998062134

Epoch: 6| Step: 9
Training loss: 2.4984824657440186
Validation loss: 2.077780783176422

Epoch: 6| Step: 10
Training loss: 1.7855541706085205
Validation loss: 2.1226749420166016

Epoch: 6| Step: 11
Training loss: 1.7568943500518799
Validation loss: 2.112886985143026

Epoch: 6| Step: 12
Training loss: 1.55706787109375
Validation loss: 2.066323677698771

Epoch: 6| Step: 13
Training loss: 2.0913360118865967
Validation loss: 2.048972249031067

Epoch: 96| Step: 0
Training loss: 1.9231102466583252
Validation loss: 2.060323119163513

Epoch: 6| Step: 1
Training loss: 2.062530517578125
Validation loss: 2.078679859638214

Epoch: 6| Step: 2
Training loss: 1.8482367992401123
Validation loss: 2.030013104279836

Epoch: 6| Step: 3
Training loss: 2.493736743927002
Validation loss: 2.0395260055859885

Epoch: 6| Step: 4
Training loss: 1.1362841129302979
Validation loss: 2.0222378770510354

Epoch: 6| Step: 5
Training loss: 2.242640495300293
Validation loss: 2.0367099046707153

Epoch: 6| Step: 6
Training loss: 1.2682380676269531
Validation loss: 2.0814905563990274

Epoch: 6| Step: 7
Training loss: 1.8220586776733398
Validation loss: 2.1184237798055015

Epoch: 6| Step: 8
Training loss: 1.635812520980835
Validation loss: 2.115272045135498

Epoch: 6| Step: 9
Training loss: 1.1628069877624512
Validation loss: 2.07966681321462

Epoch: 6| Step: 10
Training loss: 1.199944257736206
Validation loss: 2.071808954079946

Epoch: 6| Step: 11
Training loss: 1.826337218284607
Validation loss: 2.037445326646169

Epoch: 6| Step: 12
Training loss: 1.738446593284607
Validation loss: 2.0395681063334146

Epoch: 6| Step: 13
Training loss: 2.1358399391174316
Validation loss: 2.0900395711263022

Epoch: 97| Step: 0
Training loss: 2.115297555923462
Validation loss: 2.0603841741879783

Epoch: 6| Step: 1
Training loss: 2.020421266555786
Validation loss: 2.0670191645622253

Epoch: 6| Step: 2
Training loss: 1.5610737800598145
Validation loss: 2.0496191581090293

Epoch: 6| Step: 3
Training loss: 1.7244634628295898
Validation loss: 2.041604777177175

Epoch: 6| Step: 4
Training loss: 2.022871732711792
Validation loss: 2.053692102432251

Epoch: 6| Step: 5
Training loss: 1.139493703842163
Validation loss: 2.0605588555336

Epoch: 6| Step: 6
Training loss: 1.6980060338974
Validation loss: 2.0416613022486367

Epoch: 6| Step: 7
Training loss: 2.3208422660827637
Validation loss: 2.04306169350942

Epoch: 6| Step: 8
Training loss: 1.9582138061523438
Validation loss: 2.0472542444864907

Epoch: 6| Step: 9
Training loss: 1.540212869644165
Validation loss: 2.0179194609324136

Epoch: 6| Step: 10
Training loss: 1.2111232280731201
Validation loss: 2.061552802721659

Epoch: 6| Step: 11
Training loss: 1.4312756061553955
Validation loss: 2.0414481361707053

Epoch: 6| Step: 12
Training loss: 1.8203476667404175
Validation loss: 2.0674540797869363

Epoch: 6| Step: 13
Training loss: 1.8158103227615356
Validation loss: 2.1028692523638406

Epoch: 98| Step: 0
Training loss: 1.5642468929290771
Validation loss: 2.1281999548276267

Epoch: 6| Step: 1
Training loss: 2.1747496128082275
Validation loss: 2.14899605512619

Epoch: 6| Step: 2
Training loss: 1.402721881866455
Validation loss: 2.125442544619242

Epoch: 6| Step: 3
Training loss: 1.9270892143249512
Validation loss: 2.110123256842295

Epoch: 6| Step: 4
Training loss: 1.1859042644500732
Validation loss: 2.1119627157847085

Epoch: 6| Step: 5
Training loss: 1.0503268241882324
Validation loss: 2.0719250043233237

Epoch: 6| Step: 6
Training loss: 1.7701606750488281
Validation loss: 2.084185302257538

Epoch: 6| Step: 7
Training loss: 1.6547491550445557
Validation loss: 2.088320016860962

Epoch: 6| Step: 8
Training loss: 1.986954927444458
Validation loss: 2.0613662004470825

Epoch: 6| Step: 9
Training loss: 1.676152229309082
Validation loss: 2.062667508920034

Epoch: 6| Step: 10
Training loss: 2.105714797973633
Validation loss: 2.023465653260549

Epoch: 6| Step: 11
Training loss: 1.5025583505630493
Validation loss: 2.0960415403048196

Epoch: 6| Step: 12
Training loss: 1.6709203720092773
Validation loss: 2.0576521952946982

Epoch: 6| Step: 13
Training loss: 2.615999221801758
Validation loss: 2.0823845664660134

Epoch: 99| Step: 0
Training loss: 1.6828422546386719
Validation loss: 2.0569955706596375

Epoch: 6| Step: 1
Training loss: 1.8845100402832031
Validation loss: 2.0452506939570108

Epoch: 6| Step: 2
Training loss: 1.5250134468078613
Validation loss: 2.0528574188550315

Epoch: 6| Step: 3
Training loss: 2.4127914905548096
Validation loss: 2.0539179046948752

Epoch: 6| Step: 4
Training loss: 2.088101387023926
Validation loss: 2.0600147247314453

Epoch: 6| Step: 5
Training loss: 1.3233041763305664
Validation loss: 2.0275702277819314

Epoch: 6| Step: 6
Training loss: 1.2822368144989014
Validation loss: 2.0908720890680947

Epoch: 6| Step: 7
Training loss: 1.72471022605896
Validation loss: 2.08537087837855

Epoch: 6| Step: 8
Training loss: 1.2939480543136597
Validation loss: 2.105255663394928

Epoch: 6| Step: 9
Training loss: 1.677259087562561
Validation loss: 2.0997904936472573

Epoch: 6| Step: 10
Training loss: 1.53634512424469
Validation loss: 2.113493025302887

Epoch: 6| Step: 11
Training loss: 2.35567569732666
Validation loss: 2.1040356357892356

Epoch: 6| Step: 12
Training loss: 1.6734259128570557
Validation loss: 2.1002304355303445

Epoch: 6| Step: 13
Training loss: 1.5782207250595093
Validation loss: 2.10905385017395

Epoch: 100| Step: 0
Training loss: 1.4453048706054688
Validation loss: 2.1024340192476907

Epoch: 6| Step: 1
Training loss: 2.646620273590088
Validation loss: 2.106609582901001

Epoch: 6| Step: 2
Training loss: 1.561185359954834
Validation loss: 2.058408518632253

Epoch: 6| Step: 3
Training loss: 1.4825184345245361
Validation loss: 2.039970795313517

Epoch: 6| Step: 4
Training loss: 1.6062395572662354
Validation loss: 2.0409299731254578

Epoch: 6| Step: 5
Training loss: 1.3313418626785278
Validation loss: 2.0528691609700522

Epoch: 6| Step: 6
Training loss: 1.5211422443389893
Validation loss: 2.015257199605306

Epoch: 6| Step: 7
Training loss: 2.1030311584472656
Validation loss: 2.0488449732462564

Epoch: 6| Step: 8
Training loss: 1.2069411277770996
Validation loss: 2.0376586318016052

Epoch: 6| Step: 9
Training loss: 2.5463874340057373
Validation loss: 2.0685309966405234

Epoch: 6| Step: 10
Training loss: 1.6625951528549194
Validation loss: 2.0735227266947427

Epoch: 6| Step: 11
Training loss: 1.4157664775848389
Validation loss: 2.051000475883484

Epoch: 6| Step: 12
Training loss: 1.8156325817108154
Validation loss: 2.086840053399404

Epoch: 6| Step: 13
Training loss: 1.9592825174331665
Validation loss: 2.068049669265747

Epoch: 101| Step: 0
Training loss: 1.8886088132858276
Validation loss: 2.0884217421213784

Epoch: 6| Step: 1
Training loss: 2.0368027687072754
Validation loss: 2.10853777329127

Epoch: 6| Step: 2
Training loss: 1.3439527750015259
Validation loss: 2.10285077492396

Epoch: 6| Step: 3
Training loss: 1.1154427528381348
Validation loss: 2.14783775806427

Epoch: 6| Step: 4
Training loss: 1.5251739025115967
Validation loss: 2.1203004121780396

Epoch: 6| Step: 5
Training loss: 1.7524666786193848
Validation loss: 2.0841652750968933

Epoch: 6| Step: 6
Training loss: 1.423861026763916
Validation loss: 2.099022130171458

Epoch: 6| Step: 7
Training loss: 1.2766244411468506
Validation loss: 2.036888837814331

Epoch: 6| Step: 8
Training loss: 2.136565685272217
Validation loss: 2.07199635108312

Epoch: 6| Step: 9
Training loss: 1.3117973804473877
Validation loss: 2.0748349825541177

Epoch: 6| Step: 10
Training loss: 1.7216724157333374
Validation loss: 2.074584980805715

Epoch: 6| Step: 11
Training loss: 1.8424862623214722
Validation loss: 2.0462563931941986

Epoch: 6| Step: 12
Training loss: 2.019681215286255
Validation loss: 2.0470674435297647

Epoch: 6| Step: 13
Training loss: 2.160839557647705
Validation loss: 2.085797925790151

Epoch: 102| Step: 0
Training loss: 1.599366545677185
Validation loss: 2.054739832878113

Epoch: 6| Step: 1
Training loss: 2.0001907348632812
Validation loss: 2.0887346069018045

Epoch: 6| Step: 2
Training loss: 1.4416496753692627
Validation loss: 2.077026089032491

Epoch: 6| Step: 3
Training loss: 1.7493499517440796
Validation loss: 2.052739679813385

Epoch: 6| Step: 4
Training loss: 2.07808256149292
Validation loss: 2.08223686615626

Epoch: 6| Step: 5
Training loss: 1.8691953420639038
Validation loss: 2.083272933959961

Epoch: 6| Step: 6
Training loss: 1.4720778465270996
Validation loss: 2.0794294476509094

Epoch: 6| Step: 7
Training loss: 1.9947254657745361
Validation loss: 2.1059321959813437

Epoch: 6| Step: 8
Training loss: 1.7472909688949585
Validation loss: 2.1019570032755532

Epoch: 6| Step: 9
Training loss: 2.1061205863952637
Validation loss: 2.0773670077323914

Epoch: 6| Step: 10
Training loss: 1.6569328308105469
Validation loss: 2.048283795515696

Epoch: 6| Step: 11
Training loss: 1.769790530204773
Validation loss: 2.081217666467031

Epoch: 6| Step: 12
Training loss: 1.357743263244629
Validation loss: 2.078208943208059

Epoch: 6| Step: 13
Training loss: 1.1776657104492188
Validation loss: 2.0630309780438743

Epoch: 103| Step: 0
Training loss: 2.2254884243011475
Validation loss: 2.0306307872136435

Epoch: 6| Step: 1
Training loss: 1.6638413667678833
Validation loss: 2.034972687562307

Epoch: 6| Step: 2
Training loss: 1.1601333618164062
Validation loss: 2.081872602303823

Epoch: 6| Step: 3
Training loss: 1.4829437732696533
Validation loss: 2.094278554121653

Epoch: 6| Step: 4
Training loss: 2.353205680847168
Validation loss: 2.0921860535939536

Epoch: 6| Step: 5
Training loss: 1.5686835050582886
Validation loss: 2.1355608701705933

Epoch: 6| Step: 6
Training loss: 2.2147011756896973
Validation loss: 2.0900208254655204

Epoch: 6| Step: 7
Training loss: 1.738990306854248
Validation loss: 2.130248030026754

Epoch: 6| Step: 8
Training loss: 1.4340670108795166
Validation loss: 2.103918472925822

Epoch: 6| Step: 9
Training loss: 1.9436756372451782
Validation loss: 2.088278869787852

Epoch: 6| Step: 10
Training loss: 1.7196626663208008
Validation loss: 2.0546101331710815

Epoch: 6| Step: 11
Training loss: 1.3455278873443604
Validation loss: 2.0917406479517617

Epoch: 6| Step: 12
Training loss: 1.2139616012573242
Validation loss: 2.0916197896003723

Epoch: 6| Step: 13
Training loss: 1.737438678741455
Validation loss: 2.0818704962730408

Epoch: 104| Step: 0
Training loss: 1.239766240119934
Validation loss: 2.0402924617131553

Epoch: 6| Step: 1
Training loss: 1.7824690341949463
Validation loss: 2.09147717555364

Epoch: 6| Step: 2
Training loss: 0.7787351012229919
Validation loss: 2.062846223513285

Epoch: 6| Step: 3
Training loss: 1.6652233600616455
Validation loss: 2.111606021722158

Epoch: 6| Step: 4
Training loss: 1.6550840139389038
Validation loss: 2.0997844537099204

Epoch: 6| Step: 5
Training loss: 1.3650680780410767
Validation loss: 2.1257063349088035

Epoch: 6| Step: 6
Training loss: 2.031068801879883
Validation loss: 2.137552181879679

Epoch: 6| Step: 7
Training loss: 1.7289942502975464
Validation loss: 2.1520176331202188

Epoch: 6| Step: 8
Training loss: 2.337472438812256
Validation loss: 2.1345799962679544

Epoch: 6| Step: 9
Training loss: 1.7895640134811401
Validation loss: 2.135372738043467

Epoch: 6| Step: 10
Training loss: 1.4394649267196655
Validation loss: 2.108028988043467

Epoch: 6| Step: 11
Training loss: 1.554875373840332
Validation loss: 2.0937737822532654

Epoch: 6| Step: 12
Training loss: 2.277390241622925
Validation loss: 2.090362012386322

Epoch: 6| Step: 13
Training loss: 1.8045068979263306
Validation loss: 2.0907259384791055

Epoch: 105| Step: 0
Training loss: 2.174367904663086
Validation loss: 2.1021768450737

Epoch: 6| Step: 1
Training loss: 1.2496306896209717
Validation loss: 2.061876674493154

Epoch: 6| Step: 2
Training loss: 1.3020057678222656
Validation loss: 2.0625943342844644

Epoch: 6| Step: 3
Training loss: 1.796478271484375
Validation loss: 2.085194726785024

Epoch: 6| Step: 4
Training loss: 1.753290057182312
Validation loss: 2.0462095538775125

Epoch: 6| Step: 5
Training loss: 1.678529977798462
Validation loss: 2.0788022677103677

Epoch: 6| Step: 6
Training loss: 1.5105159282684326
Validation loss: 2.027873396873474

Epoch: 6| Step: 7
Training loss: 1.5412510633468628
Validation loss: 2.048011541366577

Epoch: 6| Step: 8
Training loss: 2.0557656288146973
Validation loss: 2.0669973293940225

Epoch: 6| Step: 9
Training loss: 2.3134682178497314
Validation loss: 2.0851659973462424

Epoch: 6| Step: 10
Training loss: 1.3526381254196167
Validation loss: 2.099314033985138

Epoch: 6| Step: 11
Training loss: 1.5671770572662354
Validation loss: 2.0370299021402993

Epoch: 6| Step: 12
Training loss: 1.8820511102676392
Validation loss: 2.07540762424469

Epoch: 6| Step: 13
Training loss: 1.2398064136505127
Validation loss: 2.0774493416150412

Epoch: 106| Step: 0
Training loss: 2.2815604209899902
Validation loss: 2.070444564024607

Epoch: 6| Step: 1
Training loss: 2.119910955429077
Validation loss: 2.1129608750343323

Epoch: 6| Step: 2
Training loss: 1.592028021812439
Validation loss: 2.108969231446584

Epoch: 6| Step: 3
Training loss: 1.332482099533081
Validation loss: 2.066331426302592

Epoch: 6| Step: 4
Training loss: 1.7839152812957764
Validation loss: 2.0640884240468345

Epoch: 6| Step: 5
Training loss: 1.3961496353149414
Validation loss: 2.086690584818522

Epoch: 6| Step: 6
Training loss: 1.8490676879882812
Validation loss: 2.005840798219045

Epoch: 6| Step: 7
Training loss: 2.1041736602783203
Validation loss: 2.0396145582199097

Epoch: 6| Step: 8
Training loss: 1.4184646606445312
Validation loss: 2.094311853249868

Epoch: 6| Step: 9
Training loss: 1.3094260692596436
Validation loss: 2.041550358136495

Epoch: 6| Step: 10
Training loss: 1.2155358791351318
Validation loss: 2.066125830014547

Epoch: 6| Step: 11
Training loss: 1.8217511177062988
Validation loss: 2.0781479279200235

Epoch: 6| Step: 12
Training loss: 1.7641985416412354
Validation loss: 2.069200058778127

Epoch: 6| Step: 13
Training loss: 1.271360993385315
Validation loss: 2.060818155606588

Epoch: 107| Step: 0
Training loss: 1.9593695402145386
Validation loss: 2.100502868493398

Epoch: 6| Step: 1
Training loss: 1.8395663499832153
Validation loss: 2.1092318296432495

Epoch: 6| Step: 2
Training loss: 1.7315906286239624
Validation loss: 2.1612098813056946

Epoch: 6| Step: 3
Training loss: 2.211808204650879
Validation loss: 2.069467822710673

Epoch: 6| Step: 4
Training loss: 1.016396403312683
Validation loss: 2.0580477515856423

Epoch: 6| Step: 5
Training loss: 1.294132113456726
Validation loss: 2.104932208855947

Epoch: 6| Step: 6
Training loss: 2.0409767627716064
Validation loss: 2.1055545806884766

Epoch: 6| Step: 7
Training loss: 1.601330041885376
Validation loss: 2.064814249674479

Epoch: 6| Step: 8
Training loss: 1.5062379837036133
Validation loss: 2.0836757818857827

Epoch: 6| Step: 9
Training loss: 1.826355218887329
Validation loss: 2.079051375389099

Epoch: 6| Step: 10
Training loss: 1.8134589195251465
Validation loss: 2.089242955048879

Epoch: 6| Step: 11
Training loss: 1.1453442573547363
Validation loss: 2.0877090891202292

Epoch: 6| Step: 12
Training loss: 1.662700891494751
Validation loss: 2.103801687558492

Epoch: 6| Step: 13
Training loss: 1.5278918743133545
Validation loss: 2.0964752038319907

Epoch: 108| Step: 0
Training loss: 2.0945372581481934
Validation loss: 2.0946157773335776

Epoch: 6| Step: 1
Training loss: 1.356812596321106
Validation loss: 2.041728933652242

Epoch: 6| Step: 2
Training loss: 1.6278401613235474
Validation loss: 2.1125278075536094

Epoch: 6| Step: 3
Training loss: 1.4749215841293335
Validation loss: 2.075797140598297

Epoch: 6| Step: 4
Training loss: 0.9932273626327515
Validation loss: 2.0792243282000222

Epoch: 6| Step: 5
Training loss: 1.7963042259216309
Validation loss: 2.101556042830149

Epoch: 6| Step: 6
Training loss: 1.901705026626587
Validation loss: 2.0492210388183594

Epoch: 6| Step: 7
Training loss: 2.0475974082946777
Validation loss: 2.044117351373037

Epoch: 6| Step: 8
Training loss: 1.462266445159912
Validation loss: 2.0806519389152527

Epoch: 6| Step: 9
Training loss: 1.513725996017456
Validation loss: 2.007507880528768

Epoch: 6| Step: 10
Training loss: 1.760853886604309
Validation loss: 2.0677738785743713

Epoch: 6| Step: 11
Training loss: 1.5806481838226318
Validation loss: 2.0621082385381064

Epoch: 6| Step: 12
Training loss: 1.6625112295150757
Validation loss: 2.059824764728546

Epoch: 6| Step: 13
Training loss: 1.549583911895752
Validation loss: 2.061281740665436

Epoch: 109| Step: 0
Training loss: 2.5705933570861816
Validation loss: 2.0371344288190207

Epoch: 6| Step: 1
Training loss: 1.3760417699813843
Validation loss: 2.0659729639689126

Epoch: 6| Step: 2
Training loss: 1.2649073600769043
Validation loss: 2.165702740351359

Epoch: 6| Step: 3
Training loss: 1.6554840803146362
Validation loss: 2.167779008547465

Epoch: 6| Step: 4
Training loss: 1.0431411266326904
Validation loss: 2.202284594376882

Epoch: 6| Step: 5
Training loss: 1.7070105075836182
Validation loss: 2.1865057349205017

Epoch: 6| Step: 6
Training loss: 1.9142885208129883
Validation loss: 2.16006330649058

Epoch: 6| Step: 7
Training loss: 1.3738402128219604
Validation loss: 2.135527789592743

Epoch: 6| Step: 8
Training loss: 1.5447893142700195
Validation loss: 2.1471454898516336

Epoch: 6| Step: 9
Training loss: 1.7504165172576904
Validation loss: 2.065489172935486

Epoch: 6| Step: 10
Training loss: 1.5614054203033447
Validation loss: 2.0616438388824463

Epoch: 6| Step: 11
Training loss: 1.7232069969177246
Validation loss: 2.0585686763127646

Epoch: 6| Step: 12
Training loss: 1.334751844406128
Validation loss: 2.0802599589029946

Epoch: 6| Step: 13
Training loss: 2.3874430656433105
Validation loss: 2.077399810155233

Epoch: 110| Step: 0
Training loss: 1.4478263854980469
Validation loss: 2.0774081548055015

Epoch: 6| Step: 1
Training loss: 1.653696060180664
Validation loss: 2.0858717560768127

Epoch: 6| Step: 2
Training loss: 1.3911173343658447
Validation loss: 2.0416441559791565

Epoch: 6| Step: 3
Training loss: 1.828421950340271
Validation loss: 2.052961786588033

Epoch: 6| Step: 4
Training loss: 1.2867422103881836
Validation loss: 2.07347971200943

Epoch: 6| Step: 5
Training loss: 1.3374828100204468
Validation loss: 2.0449676513671875

Epoch: 6| Step: 6
Training loss: 2.0994904041290283
Validation loss: 2.0907179911931357

Epoch: 6| Step: 7
Training loss: 1.9437562227249146
Validation loss: 2.123272875944773

Epoch: 6| Step: 8
Training loss: 1.7633476257324219
Validation loss: 2.1473435163497925

Epoch: 6| Step: 9
Training loss: 1.9785068035125732
Validation loss: 2.0970304210980735

Epoch: 6| Step: 10
Training loss: 1.8798844814300537
Validation loss: 2.154408792654673

Epoch: 6| Step: 11
Training loss: 1.8303240537643433
Validation loss: 2.1667065421740213

Epoch: 6| Step: 12
Training loss: 1.6179087162017822
Validation loss: 2.147193511327108

Epoch: 6| Step: 13
Training loss: 1.2657215595245361
Validation loss: 2.144081433614095

Epoch: 111| Step: 0
Training loss: 1.4321033954620361
Validation loss: 2.0789926250775657

Epoch: 6| Step: 1
Training loss: 1.444400429725647
Validation loss: 2.0878999829292297

Epoch: 6| Step: 2
Training loss: 1.936018466949463
Validation loss: 2.087060809135437

Epoch: 6| Step: 3
Training loss: 1.1040284633636475
Validation loss: 2.117474675178528

Epoch: 6| Step: 4
Training loss: 1.1370092630386353
Validation loss: 2.120548685391744

Epoch: 6| Step: 5
Training loss: 1.1991980075836182
Validation loss: 2.0994447271029153

Epoch: 6| Step: 6
Training loss: 1.608149766921997
Validation loss: 2.073486944039663

Epoch: 6| Step: 7
Training loss: 2.350831985473633
Validation loss: 2.033075133959452

Epoch: 6| Step: 8
Training loss: 1.6987600326538086
Validation loss: 2.051871438821157

Epoch: 6| Step: 9
Training loss: 1.9172403812408447
Validation loss: 2.033920089403788

Epoch: 6| Step: 10
Training loss: 1.5184414386749268
Validation loss: 2.0382627646128335

Epoch: 6| Step: 11
Training loss: 1.7883596420288086
Validation loss: 2.039303104082743

Epoch: 6| Step: 12
Training loss: 1.4740009307861328
Validation loss: 2.027063767115275

Epoch: 6| Step: 13
Training loss: 1.509291648864746
Validation loss: 2.043789486090342

Epoch: 112| Step: 0
Training loss: 1.1846871376037598
Validation loss: 2.1202476421991983

Epoch: 6| Step: 1
Training loss: 1.5858162641525269
Validation loss: 2.061838706334432

Epoch: 6| Step: 2
Training loss: 1.4861756563186646
Validation loss: 2.0172996322313943

Epoch: 6| Step: 3
Training loss: 1.3558273315429688
Validation loss: 2.072494308153788

Epoch: 6| Step: 4
Training loss: 2.159799575805664
Validation loss: 2.0616154869397483

Epoch: 6| Step: 5
Training loss: 2.001595973968506
Validation loss: 2.093481878439585

Epoch: 6| Step: 6
Training loss: 2.2359890937805176
Validation loss: 2.071438213189443

Epoch: 6| Step: 7
Training loss: 1.1054890155792236
Validation loss: 2.0692944725354514

Epoch: 6| Step: 8
Training loss: 1.7846053838729858
Validation loss: 2.0953380465507507

Epoch: 6| Step: 9
Training loss: 1.3004921674728394
Validation loss: 2.1232176621754966

Epoch: 6| Step: 10
Training loss: 1.4224520921707153
Validation loss: 2.092537581920624

Epoch: 6| Step: 11
Training loss: 1.6154472827911377
Validation loss: 2.116806427637736

Epoch: 6| Step: 12
Training loss: 1.9132131338119507
Validation loss: 2.0882458885510764

Epoch: 6| Step: 13
Training loss: 1.384390115737915
Validation loss: 2.109927237033844

Epoch: 113| Step: 0
Training loss: 2.2843048572540283
Validation loss: 2.084318478902181

Epoch: 6| Step: 1
Training loss: 1.3817474842071533
Validation loss: 2.098574082056681

Epoch: 6| Step: 2
Training loss: 1.8197031021118164
Validation loss: 2.0602818528811135

Epoch: 6| Step: 3
Training loss: 1.3368380069732666
Validation loss: 2.0651877721150718

Epoch: 6| Step: 4
Training loss: 1.6799731254577637
Validation loss: 2.0634588400522866

Epoch: 6| Step: 5
Training loss: 1.4876859188079834
Validation loss: 2.1011265317598977

Epoch: 6| Step: 6
Training loss: 1.335680603981018
Validation loss: 2.0750150283177695

Epoch: 6| Step: 7
Training loss: 1.3205314874649048
Validation loss: 2.1228537559509277

Epoch: 6| Step: 8
Training loss: 1.340169072151184
Validation loss: 2.0532674193382263

Epoch: 6| Step: 9
Training loss: 1.6718202829360962
Validation loss: 2.085749924182892

Epoch: 6| Step: 10
Training loss: 2.2079877853393555
Validation loss: 2.0591143369674683

Epoch: 6| Step: 11
Training loss: 1.4167979955673218
Validation loss: 2.043972154458364

Epoch: 6| Step: 12
Training loss: 1.622665286064148
Validation loss: 2.0725518663724265

Epoch: 6| Step: 13
Training loss: 1.352531909942627
Validation loss: 2.077990452448527

Epoch: 114| Step: 0
Training loss: 2.221125602722168
Validation loss: 2.0541528860727944

Epoch: 6| Step: 1
Training loss: 1.6530725955963135
Validation loss: 2.071348170439402

Epoch: 6| Step: 2
Training loss: 1.2891950607299805
Validation loss: 2.084594945112864

Epoch: 6| Step: 3
Training loss: 1.7662304639816284
Validation loss: 2.095077157020569

Epoch: 6| Step: 4
Training loss: 1.14493989944458
Validation loss: 2.071117420991262

Epoch: 6| Step: 5
Training loss: 2.452770233154297
Validation loss: 2.053794244925181

Epoch: 6| Step: 6
Training loss: 1.7884770631790161
Validation loss: 2.091244697570801

Epoch: 6| Step: 7
Training loss: 1.1156624555587769
Validation loss: 2.0552215576171875

Epoch: 6| Step: 8
Training loss: 1.1255804300308228
Validation loss: 2.0892862478892007

Epoch: 6| Step: 9
Training loss: 1.5383549928665161
Validation loss: 2.1024306615193686

Epoch: 6| Step: 10
Training loss: 1.9004985094070435
Validation loss: 2.1092047691345215

Epoch: 6| Step: 11
Training loss: 1.537949562072754
Validation loss: 2.1046140591303506

Epoch: 6| Step: 12
Training loss: 1.5026416778564453
Validation loss: 2.0630061626434326

Epoch: 6| Step: 13
Training loss: 1.1057395935058594
Validation loss: 2.099043329556783

Epoch: 115| Step: 0
Training loss: 1.0419633388519287
Validation loss: 2.093615710735321

Epoch: 6| Step: 1
Training loss: 1.66459321975708
Validation loss: 2.0370516975720725

Epoch: 6| Step: 2
Training loss: 1.666795015335083
Validation loss: 2.085529307524363

Epoch: 6| Step: 3
Training loss: 1.4198437929153442
Validation loss: 2.0726449688275657

Epoch: 6| Step: 4
Training loss: 1.2822675704956055
Validation loss: 2.07945587237676

Epoch: 6| Step: 5
Training loss: 1.0370543003082275
Validation loss: 2.0681181947390237

Epoch: 6| Step: 6
Training loss: 2.4666404724121094
Validation loss: 2.083690563837687

Epoch: 6| Step: 7
Training loss: 2.0618855953216553
Validation loss: 2.089774270852407

Epoch: 6| Step: 8
Training loss: 1.9100279808044434
Validation loss: 2.0796929796536765

Epoch: 6| Step: 9
Training loss: 1.5104657411575317
Validation loss: 2.04252290725708

Epoch: 6| Step: 10
Training loss: 1.7300410270690918
Validation loss: 2.0216548840204873

Epoch: 6| Step: 11
Training loss: 1.1867432594299316
Validation loss: 2.0754425724347434

Epoch: 6| Step: 12
Training loss: 1.4082815647125244
Validation loss: 2.0757036407788596

Epoch: 6| Step: 13
Training loss: 1.687746524810791
Validation loss: 2.105583926041921

Epoch: 116| Step: 0
Training loss: 1.854061484336853
Validation loss: 2.078223089377085

Epoch: 6| Step: 1
Training loss: 0.918332576751709
Validation loss: 2.108166674772898

Epoch: 6| Step: 2
Training loss: 1.6943840980529785
Validation loss: 2.084609647591909

Epoch: 6| Step: 3
Training loss: 1.166755199432373
Validation loss: 2.1028796434402466

Epoch: 6| Step: 4
Training loss: 1.8210856914520264
Validation loss: 2.0757506688435874

Epoch: 6| Step: 5
Training loss: 0.9376838207244873
Validation loss: 2.048721194267273

Epoch: 6| Step: 6
Training loss: 1.5783019065856934
Validation loss: 2.085314412911733

Epoch: 6| Step: 7
Training loss: 1.3644776344299316
Validation loss: 2.0776370763778687

Epoch: 6| Step: 8
Training loss: 1.775066614151001
Validation loss: 2.060223082701365

Epoch: 6| Step: 9
Training loss: 1.3928184509277344
Validation loss: 2.0755717555681863

Epoch: 6| Step: 10
Training loss: 1.922440767288208
Validation loss: 2.0597912470499673

Epoch: 6| Step: 11
Training loss: 1.656294822692871
Validation loss: 2.099575678507487

Epoch: 6| Step: 12
Training loss: 2.596338987350464
Validation loss: 2.070539871851603

Epoch: 6| Step: 13
Training loss: 1.0982530117034912
Validation loss: 2.039595067501068

Epoch: 117| Step: 0
Training loss: 1.7998651266098022
Validation loss: 2.0800140102704368

Epoch: 6| Step: 1
Training loss: 1.170691967010498
Validation loss: 2.076430638631185

Epoch: 6| Step: 2
Training loss: 0.9871872067451477
Validation loss: 2.133094628651937

Epoch: 6| Step: 3
Training loss: 1.7825137376785278
Validation loss: 2.1168631315231323

Epoch: 6| Step: 4
Training loss: 1.1968282461166382
Validation loss: 2.096143623193105

Epoch: 6| Step: 5
Training loss: 1.874243974685669
Validation loss: 2.12228133281072

Epoch: 6| Step: 6
Training loss: 0.8478845357894897
Validation loss: 2.086682299772898

Epoch: 6| Step: 7
Training loss: 1.7803287506103516
Validation loss: 2.0678696433703103

Epoch: 6| Step: 8
Training loss: 2.213015079498291
Validation loss: 2.073568284511566

Epoch: 6| Step: 9
Training loss: 1.6511893272399902
Validation loss: 2.0209426283836365

Epoch: 6| Step: 10
Training loss: 1.49431312084198
Validation loss: 2.0359732508659363

Epoch: 6| Step: 11
Training loss: 1.2996920347213745
Validation loss: 2.049019912878672

Epoch: 6| Step: 12
Training loss: 2.5734715461730957
Validation loss: 2.077112098534902

Epoch: 6| Step: 13
Training loss: 1.49459969997406
Validation loss: 2.037412444750468

Epoch: 118| Step: 0
Training loss: 1.7652311325073242
Validation loss: 2.0762924353281655

Epoch: 6| Step: 1
Training loss: 1.6039750576019287
Validation loss: 2.063511828581492

Epoch: 6| Step: 2
Training loss: 1.8317739963531494
Validation loss: 2.0214502016703286

Epoch: 6| Step: 3
Training loss: 1.501052737236023
Validation loss: 2.060228188832601

Epoch: 6| Step: 4
Training loss: 1.5652275085449219
Validation loss: 2.057924230893453

Epoch: 6| Step: 5
Training loss: 1.7039134502410889
Validation loss: 2.0702734192212424

Epoch: 6| Step: 6
Training loss: 1.3189359903335571
Validation loss: 2.0417221983273826

Epoch: 6| Step: 7
Training loss: 1.326192021369934
Validation loss: 2.0836886366208396

Epoch: 6| Step: 8
Training loss: 1.6471871137619019
Validation loss: 2.1176515420277915

Epoch: 6| Step: 9
Training loss: 1.4552223682403564
Validation loss: 2.0969693064689636

Epoch: 6| Step: 10
Training loss: 1.0112919807434082
Validation loss: 2.100119113922119

Epoch: 6| Step: 11
Training loss: 2.1021316051483154
Validation loss: 2.135968645413717

Epoch: 6| Step: 12
Training loss: 1.1913471221923828
Validation loss: 2.0912835200627646

Epoch: 6| Step: 13
Training loss: 1.407214641571045
Validation loss: 2.101104497909546

Epoch: 119| Step: 0
Training loss: 1.0917613506317139
Validation loss: 2.028786321481069

Epoch: 6| Step: 1
Training loss: 1.3846741914749146
Validation loss: 2.0836873849232993

Epoch: 6| Step: 2
Training loss: 1.892665147781372
Validation loss: 2.106331249078115

Epoch: 6| Step: 3
Training loss: 1.7294234037399292
Validation loss: 2.081131100654602

Epoch: 6| Step: 4
Training loss: 1.306972861289978
Validation loss: 2.114323635896047

Epoch: 6| Step: 5
Training loss: 1.4245305061340332
Validation loss: 2.1030762990315757

Epoch: 6| Step: 6
Training loss: 1.9141825437545776
Validation loss: 2.0993139346440635

Epoch: 6| Step: 7
Training loss: 1.7896054983139038
Validation loss: 2.121756454308828

Epoch: 6| Step: 8
Training loss: 1.563315510749817
Validation loss: 2.079361697038015

Epoch: 6| Step: 9
Training loss: 1.3839447498321533
Validation loss: 2.062093814214071

Epoch: 6| Step: 10
Training loss: 0.9596654772758484
Validation loss: 2.1176711122194924

Epoch: 6| Step: 11
Training loss: 1.3820257186889648
Validation loss: 2.103220740954081

Epoch: 6| Step: 12
Training loss: 1.8481751680374146
Validation loss: 2.047112981478373

Epoch: 6| Step: 13
Training loss: 1.8147085905075073
Validation loss: 2.0937293569246926

Epoch: 120| Step: 0
Training loss: 1.5581748485565186
Validation loss: 2.078280250231425

Epoch: 6| Step: 1
Training loss: 1.0029475688934326
Validation loss: 2.0568426052729287

Epoch: 6| Step: 2
Training loss: 1.1875486373901367
Validation loss: 2.059320608774821

Epoch: 6| Step: 3
Training loss: 1.5617601871490479
Validation loss: 2.057738741238912

Epoch: 6| Step: 4
Training loss: 1.0405373573303223
Validation loss: 2.077159821987152

Epoch: 6| Step: 5
Training loss: 2.2121543884277344
Validation loss: 2.117635667324066

Epoch: 6| Step: 6
Training loss: 1.6616744995117188
Validation loss: 2.1930173436800637

Epoch: 6| Step: 7
Training loss: 1.8716505765914917
Validation loss: 2.2048011223475137

Epoch: 6| Step: 8
Training loss: 2.169332981109619
Validation loss: 2.1997599601745605

Epoch: 6| Step: 9
Training loss: 1.780158519744873
Validation loss: 2.1669140259424844

Epoch: 6| Step: 10
Training loss: 1.6964476108551025
Validation loss: 2.122557520866394

Epoch: 6| Step: 11
Training loss: 1.4300100803375244
Validation loss: 2.060242513815562

Epoch: 6| Step: 12
Training loss: 2.1085567474365234
Validation loss: 2.0595296223958335

Epoch: 6| Step: 13
Training loss: 1.6129684448242188
Validation loss: 2.0015490452448526

Epoch: 121| Step: 0
Training loss: 1.7556618452072144
Validation loss: 2.059063971042633

Epoch: 6| Step: 1
Training loss: 1.5882902145385742
Validation loss: 2.059836745262146

Epoch: 6| Step: 2
Training loss: 1.4656553268432617
Validation loss: 2.0174671014149985

Epoch: 6| Step: 3
Training loss: 1.1351745128631592
Validation loss: 2.056792438030243

Epoch: 6| Step: 4
Training loss: 1.3921141624450684
Validation loss: 2.052179455757141

Epoch: 6| Step: 5
Training loss: 1.5148268938064575
Validation loss: 2.0806320707003274

Epoch: 6| Step: 6
Training loss: 1.2797013521194458
Validation loss: 2.1105347077051797

Epoch: 6| Step: 7
Training loss: 2.2513298988342285
Validation loss: 2.0951780478159585

Epoch: 6| Step: 8
Training loss: 1.3401339054107666
Validation loss: 2.1298877596855164

Epoch: 6| Step: 9
Training loss: 1.5524287223815918
Validation loss: 2.140926480293274

Epoch: 6| Step: 10
Training loss: 1.4416736364364624
Validation loss: 2.1675894459088645

Epoch: 6| Step: 11
Training loss: 1.2605253458023071
Validation loss: 2.1838985681533813

Epoch: 6| Step: 12
Training loss: 3.016451597213745
Validation loss: 2.219977617263794

Epoch: 6| Step: 13
Training loss: 1.8548482656478882
Validation loss: 2.0998520056406655

Epoch: 122| Step: 0
Training loss: 1.4485902786254883
Validation loss: 2.0798083345095315

Epoch: 6| Step: 1
Training loss: 1.333551287651062
Validation loss: 2.079443951447805

Epoch: 6| Step: 2
Training loss: 1.6344457864761353
Validation loss: 2.0886016885439553

Epoch: 6| Step: 3
Training loss: 1.5411417484283447
Validation loss: 2.0850978891054788

Epoch: 6| Step: 4
Training loss: 2.15702486038208
Validation loss: 2.0781699419021606

Epoch: 6| Step: 5
Training loss: 1.1676695346832275
Validation loss: 2.0625254114468894

Epoch: 6| Step: 6
Training loss: 1.1753829717636108
Validation loss: 2.0698193510373435

Epoch: 6| Step: 7
Training loss: 1.578894853591919
Validation loss: 2.0687394936879477

Epoch: 6| Step: 8
Training loss: 1.5784833431243896
Validation loss: 2.0728168288866677

Epoch: 6| Step: 9
Training loss: 1.5076013803482056
Validation loss: 2.0578620632489524

Epoch: 6| Step: 10
Training loss: 1.2527530193328857
Validation loss: 2.0352267622947693

Epoch: 6| Step: 11
Training loss: 1.9349961280822754
Validation loss: 2.0589259465535483

Epoch: 6| Step: 12
Training loss: 1.5499441623687744
Validation loss: 2.117552022139231

Epoch: 6| Step: 13
Training loss: 1.4232988357543945
Validation loss: 2.031244774659475

Epoch: 123| Step: 0
Training loss: 1.8185490369796753
Validation loss: 2.083330273628235

Epoch: 6| Step: 1
Training loss: 1.5297307968139648
Validation loss: 2.0671798388163247

Epoch: 6| Step: 2
Training loss: 1.416440725326538
Validation loss: 2.047061006228129

Epoch: 6| Step: 3
Training loss: 1.9358538389205933
Validation loss: 2.0085071325302124

Epoch: 6| Step: 4
Training loss: 1.0230075120925903
Validation loss: 2.0568665067354837

Epoch: 6| Step: 5
Training loss: 1.0889467000961304
Validation loss: 2.101602335770925

Epoch: 6| Step: 6
Training loss: 1.4456285238265991
Validation loss: 2.0924691359202066

Epoch: 6| Step: 7
Training loss: 1.0662978887557983
Validation loss: 2.127895712852478

Epoch: 6| Step: 8
Training loss: 1.8910953998565674
Validation loss: 2.093003749847412

Epoch: 6| Step: 9
Training loss: 1.52286696434021
Validation loss: 2.0969388683636985

Epoch: 6| Step: 10
Training loss: 1.5308196544647217
Validation loss: 2.0656740268071494

Epoch: 6| Step: 11
Training loss: 1.3802132606506348
Validation loss: 2.1963139375050864

Epoch: 6| Step: 12
Training loss: 1.2133777141571045
Validation loss: 2.1344815492630005

Epoch: 6| Step: 13
Training loss: 1.891871452331543
Validation loss: 2.1470019022623696

Epoch: 124| Step: 0
Training loss: 1.2620185613632202
Validation loss: 2.0978787342707315

Epoch: 6| Step: 1
Training loss: 1.1681663990020752
Validation loss: 2.096316615740458

Epoch: 6| Step: 2
Training loss: 1.9306191205978394
Validation loss: 2.0656080842018127

Epoch: 6| Step: 3
Training loss: 2.0149471759796143
Validation loss: 2.0571256081263223

Epoch: 6| Step: 4
Training loss: 0.9764111042022705
Validation loss: 2.0983758568763733

Epoch: 6| Step: 5
Training loss: 1.0104670524597168
Validation loss: 2.1009804606437683

Epoch: 6| Step: 6
Training loss: 1.4983043670654297
Validation loss: 2.050641139348348

Epoch: 6| Step: 7
Training loss: 1.193424940109253
Validation loss: 2.094356199105581

Epoch: 6| Step: 8
Training loss: 1.3347924947738647
Validation loss: 2.0783747831980386

Epoch: 6| Step: 9
Training loss: 1.6928799152374268
Validation loss: 2.092278083165487

Epoch: 6| Step: 10
Training loss: 1.9850637912750244
Validation loss: 2.129257599512736

Epoch: 6| Step: 11
Training loss: 1.8112287521362305
Validation loss: 2.170814832051595

Epoch: 6| Step: 12
Training loss: 1.444690227508545
Validation loss: 2.1060185035069785

Epoch: 6| Step: 13
Training loss: 1.384664535522461
Validation loss: 2.05949874718984

Epoch: 125| Step: 0
Training loss: 1.194410800933838
Validation loss: 2.1132335662841797

Epoch: 6| Step: 1
Training loss: 1.6528863906860352
Validation loss: 2.0628323753674827

Epoch: 6| Step: 2
Training loss: 1.6228177547454834
Validation loss: 2.0407575567563376

Epoch: 6| Step: 3
Training loss: 0.9714740514755249
Validation loss: 2.0687285463015237

Epoch: 6| Step: 4
Training loss: 1.3642635345458984
Validation loss: 2.101689656575521

Epoch: 6| Step: 5
Training loss: 1.3769584894180298
Validation loss: 2.0509862899780273

Epoch: 6| Step: 6
Training loss: 1.5451894998550415
Validation loss: 2.0826267202695212

Epoch: 6| Step: 7
Training loss: 1.2667784690856934
Validation loss: 2.0953025420506797

Epoch: 6| Step: 8
Training loss: 1.559891700744629
Validation loss: 2.07553893327713

Epoch: 6| Step: 9
Training loss: 0.6899893283843994
Validation loss: 2.042809307575226

Epoch: 6| Step: 10
Training loss: 1.943790078163147
Validation loss: 2.0540219148000083

Epoch: 6| Step: 11
Training loss: 2.2140254974365234
Validation loss: 2.0724995930989585

Epoch: 6| Step: 12
Training loss: 1.3712856769561768
Validation loss: 2.091585020224253

Epoch: 6| Step: 13
Training loss: 1.452257513999939
Validation loss: 2.089885115623474

Epoch: 126| Step: 0
Training loss: 1.3140233755111694
Validation loss: 2.085145672162374

Epoch: 6| Step: 1
Training loss: 1.3591196537017822
Validation loss: 2.0371419390042624

Epoch: 6| Step: 2
Training loss: 1.7218765020370483
Validation loss: 2.0251965721448264

Epoch: 6| Step: 3
Training loss: 1.5977418422698975
Validation loss: 2.041185279687246

Epoch: 6| Step: 4
Training loss: 1.293381929397583
Validation loss: 2.1070324182510376

Epoch: 6| Step: 5
Training loss: 1.1584110260009766
Validation loss: 2.083851436773936

Epoch: 6| Step: 6
Training loss: 0.9258421659469604
Validation loss: 2.101191222667694

Epoch: 6| Step: 7
Training loss: 1.675363540649414
Validation loss: 2.081255932648977

Epoch: 6| Step: 8
Training loss: 1.4858187437057495
Validation loss: 2.096269905567169

Epoch: 6| Step: 9
Training loss: 1.9780685901641846
Validation loss: 2.117136299610138

Epoch: 6| Step: 10
Training loss: 2.3669636249542236
Validation loss: 2.127825657526652

Epoch: 6| Step: 11
Training loss: 1.0011885166168213
Validation loss: 2.0896968841552734

Epoch: 6| Step: 12
Training loss: 0.9700828194618225
Validation loss: 2.050721049308777

Epoch: 6| Step: 13
Training loss: 1.7371771335601807
Validation loss: 2.1066993474960327

Epoch: 127| Step: 0
Training loss: 1.2818076610565186
Validation loss: 2.061961273352305

Epoch: 6| Step: 1
Training loss: 1.3398181200027466
Validation loss: 2.09259823958079

Epoch: 6| Step: 2
Training loss: 1.0478317737579346
Validation loss: 2.0949211915334067

Epoch: 6| Step: 3
Training loss: 1.9447641372680664
Validation loss: 2.0461327036221824

Epoch: 6| Step: 4
Training loss: 1.4855413436889648
Validation loss: 2.004705826441447

Epoch: 6| Step: 5
Training loss: 1.7850617170333862
Validation loss: 2.023900787035624

Epoch: 6| Step: 6
Training loss: 2.025350570678711
Validation loss: 2.0544311801592507

Epoch: 6| Step: 7
Training loss: 1.4084709882736206
Validation loss: 2.0827415585517883

Epoch: 6| Step: 8
Training loss: 1.364275336265564
Validation loss: 2.1253378788630166

Epoch: 6| Step: 9
Training loss: 1.4411602020263672
Validation loss: 2.1901970307032266

Epoch: 6| Step: 10
Training loss: 1.3367184400558472
Validation loss: 2.1518683433532715

Epoch: 6| Step: 11
Training loss: 1.8889904022216797
Validation loss: 2.1248315374056497

Epoch: 6| Step: 12
Training loss: 0.7905808687210083
Validation loss: 2.1359938780466714

Epoch: 6| Step: 13
Training loss: 1.6864540576934814
Validation loss: 2.112090587615967

Epoch: 128| Step: 0
Training loss: 1.6245670318603516
Validation loss: 2.076878249645233

Epoch: 6| Step: 1
Training loss: 1.8021903038024902
Validation loss: 2.0510158141454062

Epoch: 6| Step: 2
Training loss: 1.3663091659545898
Validation loss: 2.0523334741592407

Epoch: 6| Step: 3
Training loss: 1.331763505935669
Validation loss: 2.0627047618230185

Epoch: 6| Step: 4
Training loss: 1.2715034484863281
Validation loss: 2.0803911089897156

Epoch: 6| Step: 5
Training loss: 1.4179677963256836
Validation loss: 2.0692457954088845

Epoch: 6| Step: 6
Training loss: 1.4302330017089844
Validation loss: 2.0573920607566833

Epoch: 6| Step: 7
Training loss: 1.27200448513031
Validation loss: 2.086598555246989

Epoch: 6| Step: 8
Training loss: 1.7842237949371338
Validation loss: 2.055765469868978

Epoch: 6| Step: 9
Training loss: 1.5966635942459106
Validation loss: 2.087122321128845

Epoch: 6| Step: 10
Training loss: 1.5689060688018799
Validation loss: 2.096036752065023

Epoch: 6| Step: 11
Training loss: 1.6781173944473267
Validation loss: 2.1275131901105246

Epoch: 6| Step: 12
Training loss: 1.2787096500396729
Validation loss: 2.141749103864034

Epoch: 6| Step: 13
Training loss: 1.3614366054534912
Validation loss: 2.0948010087013245

Epoch: 129| Step: 0
Training loss: 1.1957173347473145
Validation loss: 2.1404609084129333

Epoch: 6| Step: 1
Training loss: 1.394805669784546
Validation loss: 2.1861295898755393

Epoch: 6| Step: 2
Training loss: 1.6142216920852661
Validation loss: 2.153354525566101

Epoch: 6| Step: 3
Training loss: 1.6788384914398193
Validation loss: 2.097156524658203

Epoch: 6| Step: 4
Training loss: 1.8209425210952759
Validation loss: 2.0954607129096985

Epoch: 6| Step: 5
Training loss: 1.9252378940582275
Validation loss: 2.105333924293518

Epoch: 6| Step: 6
Training loss: 1.4598065614700317
Validation loss: 2.037982404232025

Epoch: 6| Step: 7
Training loss: 1.0430412292480469
Validation loss: 2.069757262865702

Epoch: 6| Step: 8
Training loss: 1.6798291206359863
Validation loss: 2.062305967013041

Epoch: 6| Step: 9
Training loss: 0.9836596250534058
Validation loss: 2.049813171227773

Epoch: 6| Step: 10
Training loss: 1.4632244110107422
Validation loss: 2.030433197816213

Epoch: 6| Step: 11
Training loss: 1.3640782833099365
Validation loss: 2.0404162804285684

Epoch: 6| Step: 12
Training loss: 1.6086112260818481
Validation loss: 2.0416004260381064

Epoch: 6| Step: 13
Training loss: 1.016374111175537
Validation loss: 2.083918491999308

Epoch: 130| Step: 0
Training loss: 1.5542935132980347
Validation loss: 2.0693339705467224

Epoch: 6| Step: 1
Training loss: 1.5325223207473755
Validation loss: 2.129832943280538

Epoch: 6| Step: 2
Training loss: 1.195002555847168
Validation loss: 2.091157933076223

Epoch: 6| Step: 3
Training loss: 0.8755279779434204
Validation loss: 2.13373068968455

Epoch: 6| Step: 4
Training loss: 1.3270082473754883
Validation loss: 2.046996812025706

Epoch: 6| Step: 5
Training loss: 1.4281589984893799
Validation loss: 2.092140038808187

Epoch: 6| Step: 6
Training loss: 1.4162416458129883
Validation loss: 2.0296923716863

Epoch: 6| Step: 7
Training loss: 1.7072070837020874
Validation loss: 2.069034536679586

Epoch: 6| Step: 8
Training loss: 1.8375163078308105
Validation loss: 2.1000076731046042

Epoch: 6| Step: 9
Training loss: 1.3257765769958496
Validation loss: 2.1000266075134277

Epoch: 6| Step: 10
Training loss: 1.554532527923584
Validation loss: 2.0548526644706726

Epoch: 6| Step: 11
Training loss: 0.9689173102378845
Validation loss: 2.050939679145813

Epoch: 6| Step: 12
Training loss: 1.6416397094726562
Validation loss: 2.0250651439030967

Epoch: 6| Step: 13
Training loss: 1.6843297481536865
Validation loss: 2.067940413951874

Epoch: 131| Step: 0
Training loss: 1.429246425628662
Validation loss: 2.0553995172182717

Epoch: 6| Step: 1
Training loss: 1.04966402053833
Validation loss: 2.1114831964174905

Epoch: 6| Step: 2
Training loss: 1.3515851497650146
Validation loss: 2.0764936010042825

Epoch: 6| Step: 3
Training loss: 1.4972989559173584
Validation loss: 2.0848644971847534

Epoch: 6| Step: 4
Training loss: 1.8577682971954346
Validation loss: 2.1403717398643494

Epoch: 6| Step: 5
Training loss: 1.4012978076934814
Validation loss: 2.1070335110028586

Epoch: 6| Step: 6
Training loss: 2.0208821296691895
Validation loss: 2.0933164159456887

Epoch: 6| Step: 7
Training loss: 0.9446315765380859
Validation loss: 2.158685823281606

Epoch: 6| Step: 8
Training loss: 0.9410504102706909
Validation loss: 2.083772857983907

Epoch: 6| Step: 9
Training loss: 1.9799940586090088
Validation loss: 2.0616499185562134

Epoch: 6| Step: 10
Training loss: 1.606842041015625
Validation loss: 2.092716097831726

Epoch: 6| Step: 11
Training loss: 0.9130799770355225
Validation loss: 2.072565257549286

Epoch: 6| Step: 12
Training loss: 1.1910197734832764
Validation loss: 2.104820470015208

Epoch: 6| Step: 13
Training loss: 1.2637746334075928
Validation loss: 2.075460433959961

Epoch: 132| Step: 0
Training loss: 1.6567699909210205
Validation loss: 2.044359306494395

Epoch: 6| Step: 1
Training loss: 1.7370954751968384
Validation loss: 2.09730859597524

Epoch: 6| Step: 2
Training loss: 1.1130039691925049
Validation loss: 2.0530080795288086

Epoch: 6| Step: 3
Training loss: 1.1934773921966553
Validation loss: 2.0540056824684143

Epoch: 6| Step: 4
Training loss: 1.1674587726593018
Validation loss: 2.0865206122398376

Epoch: 6| Step: 5
Training loss: 1.177436351776123
Validation loss: 2.051513950030009

Epoch: 6| Step: 6
Training loss: 1.7419102191925049
Validation loss: 2.0834035873413086

Epoch: 6| Step: 7
Training loss: 1.4440195560455322
Validation loss: 2.1240556836128235

Epoch: 6| Step: 8
Training loss: 0.932951807975769
Validation loss: 2.0965539813041687

Epoch: 6| Step: 9
Training loss: 1.0582181215286255
Validation loss: 2.0877560575803122

Epoch: 6| Step: 10
Training loss: 1.7180756330490112
Validation loss: 2.071951409180959

Epoch: 6| Step: 11
Training loss: 1.23249351978302
Validation loss: 2.0800221959749856

Epoch: 6| Step: 12
Training loss: 1.8105409145355225
Validation loss: 2.1760016679763794

Epoch: 6| Step: 13
Training loss: 1.3774445056915283
Validation loss: 2.1322649717330933

Epoch: 133| Step: 0
Training loss: 1.1412290334701538
Validation loss: 2.0827730298042297

Epoch: 6| Step: 1
Training loss: 1.3032296895980835
Validation loss: 2.1171929041544595

Epoch: 6| Step: 2
Training loss: 1.2837278842926025
Validation loss: 2.0799474914868674

Epoch: 6| Step: 3
Training loss: 1.4512040615081787
Validation loss: 2.0601527293523154

Epoch: 6| Step: 4
Training loss: 1.4745992422103882
Validation loss: 2.040949821472168

Epoch: 6| Step: 5
Training loss: 1.290732741355896
Validation loss: 2.0678564508756003

Epoch: 6| Step: 6
Training loss: 0.9834542274475098
Validation loss: 2.1075170834859214

Epoch: 6| Step: 7
Training loss: 1.6650934219360352
Validation loss: 2.0384074648221335

Epoch: 6| Step: 8
Training loss: 1.0949596166610718
Validation loss: 2.052068551381429

Epoch: 6| Step: 9
Training loss: 1.5720469951629639
Validation loss: 2.050034542878469

Epoch: 6| Step: 10
Training loss: 0.9826706647872925
Validation loss: 2.078180432319641

Epoch: 6| Step: 11
Training loss: 1.8490068912506104
Validation loss: 2.116682847340902

Epoch: 6| Step: 12
Training loss: 1.9302359819412231
Validation loss: 2.063453276952108

Epoch: 6| Step: 13
Training loss: 1.542280673980713
Validation loss: 2.013328750928243

Epoch: 134| Step: 0
Training loss: 1.582841396331787
Validation loss: 2.0168707569440207

Epoch: 6| Step: 1
Training loss: 1.7832691669464111
Validation loss: 2.0265550216039023

Epoch: 6| Step: 2
Training loss: 1.7510590553283691
Validation loss: 2.021501143773397

Epoch: 6| Step: 3
Training loss: 1.3126287460327148
Validation loss: 2.051351547241211

Epoch: 6| Step: 4
Training loss: 1.4330445528030396
Validation loss: 2.0819444060325623

Epoch: 6| Step: 5
Training loss: 1.2801401615142822
Validation loss: 2.030720313390096

Epoch: 6| Step: 6
Training loss: 1.4404661655426025
Validation loss: 2.0241573055585227

Epoch: 6| Step: 7
Training loss: 1.6525485515594482
Validation loss: 2.088571925957998

Epoch: 6| Step: 8
Training loss: 1.1714028120040894
Validation loss: 2.111108402411143

Epoch: 6| Step: 9
Training loss: 0.9518048167228699
Validation loss: 2.1118092139561973

Epoch: 6| Step: 10
Training loss: 1.256422996520996
Validation loss: 2.12827996412913

Epoch: 6| Step: 11
Training loss: 0.9240697622299194
Validation loss: 2.1092140078544617

Epoch: 6| Step: 12
Training loss: 1.692370057106018
Validation loss: 2.064397692680359

Epoch: 6| Step: 13
Training loss: 1.5037822723388672
Validation loss: 2.121435801188151

Epoch: 135| Step: 0
Training loss: 1.5746619701385498
Validation loss: 2.0353391567866006

Epoch: 6| Step: 1
Training loss: 1.3081355094909668
Validation loss: 2.0486286878585815

Epoch: 6| Step: 2
Training loss: 1.171130895614624
Validation loss: 2.0359319845835366

Epoch: 6| Step: 3
Training loss: 1.2699660062789917
Validation loss: 2.0765912532806396

Epoch: 6| Step: 4
Training loss: 1.7369751930236816
Validation loss: 2.0710705121358237

Epoch: 6| Step: 5
Training loss: 0.9044077396392822
Validation loss: 2.0769646962483725

Epoch: 6| Step: 6
Training loss: 1.168121337890625
Validation loss: 2.0838362773259482

Epoch: 6| Step: 7
Training loss: 1.002934217453003
Validation loss: 2.054719944794973

Epoch: 6| Step: 8
Training loss: 1.4006242752075195
Validation loss: 2.1548381646474204

Epoch: 6| Step: 9
Training loss: 1.6241557598114014
Validation loss: 2.141397019227346

Epoch: 6| Step: 10
Training loss: 1.3709096908569336
Validation loss: 2.120309273401896

Epoch: 6| Step: 11
Training loss: 1.9313340187072754
Validation loss: 2.1285177866617837

Epoch: 6| Step: 12
Training loss: 1.2175319194793701
Validation loss: 2.07652755578359

Epoch: 6| Step: 13
Training loss: 1.3902418613433838
Validation loss: 2.0683491627375283

Epoch: 136| Step: 0
Training loss: 1.871410608291626
Validation loss: 1.9977801442146301

Epoch: 6| Step: 1
Training loss: 1.3429970741271973
Validation loss: 2.05754425128301

Epoch: 6| Step: 2
Training loss: 1.1043922901153564
Validation loss: 2.0412975748380027

Epoch: 6| Step: 3
Training loss: 1.1957370042800903
Validation loss: 2.052580257256826

Epoch: 6| Step: 4
Training loss: 0.9925839900970459
Validation loss: 2.104571839173635

Epoch: 6| Step: 5
Training loss: 0.887617290019989
Validation loss: 2.066457211971283

Epoch: 6| Step: 6
Training loss: 0.8301206827163696
Validation loss: 2.0975802143414817

Epoch: 6| Step: 7
Training loss: 1.7256909608840942
Validation loss: 2.122463266054789

Epoch: 6| Step: 8
Training loss: 1.7275714874267578
Validation loss: 2.1064468224843345

Epoch: 6| Step: 9
Training loss: 1.7241591215133667
Validation loss: 2.1295590003331504

Epoch: 6| Step: 10
Training loss: 1.6265637874603271
Validation loss: 2.125094453493754

Epoch: 6| Step: 11
Training loss: 1.3482775688171387
Validation loss: 2.100445111592611

Epoch: 6| Step: 12
Training loss: 1.6561872959136963
Validation loss: 2.0837859908739724

Epoch: 6| Step: 13
Training loss: 1.1481165885925293
Validation loss: 2.075896163781484

Epoch: 137| Step: 0
Training loss: 1.3474048376083374
Validation loss: 2.0758944352467856

Epoch: 6| Step: 1
Training loss: 0.7360407114028931
Validation loss: 2.040389577547709

Epoch: 6| Step: 2
Training loss: 1.1504803895950317
Validation loss: 2.0608973304430642

Epoch: 6| Step: 3
Training loss: 1.1075079441070557
Validation loss: 2.1051003535588584

Epoch: 6| Step: 4
Training loss: 1.6981232166290283
Validation loss: 2.0931140383084617

Epoch: 6| Step: 5
Training loss: 1.463584542274475
Validation loss: 2.117176651954651

Epoch: 6| Step: 6
Training loss: 0.9407695531845093
Validation loss: 2.03158837556839

Epoch: 6| Step: 7
Training loss: 1.938551902770996
Validation loss: 2.0700873136520386

Epoch: 6| Step: 8
Training loss: 1.0602943897247314
Validation loss: 2.0824861923853555

Epoch: 6| Step: 9
Training loss: 1.9482545852661133
Validation loss: 2.053349475065867

Epoch: 6| Step: 10
Training loss: 1.5083441734313965
Validation loss: 2.094933032989502

Epoch: 6| Step: 11
Training loss: 1.176805019378662
Validation loss: 2.096792995929718

Epoch: 6| Step: 12
Training loss: 1.073493242263794
Validation loss: 2.1128324270248413

Epoch: 6| Step: 13
Training loss: 1.6075072288513184
Validation loss: 2.0792791843414307

Epoch: 138| Step: 0
Training loss: 1.2891651391983032
Validation loss: 2.113167961438497

Epoch: 6| Step: 1
Training loss: 1.1211533546447754
Validation loss: 2.131359418233236

Epoch: 6| Step: 2
Training loss: 1.3683288097381592
Validation loss: 2.1008418202400208

Epoch: 6| Step: 3
Training loss: 2.016974449157715
Validation loss: 2.1070650815963745

Epoch: 6| Step: 4
Training loss: 0.936577320098877
Validation loss: 2.115658223628998

Epoch: 6| Step: 5
Training loss: 0.9791989326477051
Validation loss: 2.1093409260114035

Epoch: 6| Step: 6
Training loss: 0.9152655005455017
Validation loss: 2.070881446202596

Epoch: 6| Step: 7
Training loss: 1.6259804964065552
Validation loss: 2.093387941519419

Epoch: 6| Step: 8
Training loss: 1.6590750217437744
Validation loss: 2.0825497110684714

Epoch: 6| Step: 9
Training loss: 1.7564542293548584
Validation loss: 2.114041010538737

Epoch: 6| Step: 10
Training loss: 1.2127487659454346
Validation loss: 2.0693708459536233

Epoch: 6| Step: 11
Training loss: 1.0849170684814453
Validation loss: 2.0939897100130715

Epoch: 6| Step: 12
Training loss: 1.4308674335479736
Validation loss: 2.0339267253875732

Epoch: 6| Step: 13
Training loss: 1.3973078727722168
Validation loss: 2.053072929382324

Epoch: 139| Step: 0
Training loss: 1.304291844367981
Validation loss: 2.046255429585775

Epoch: 6| Step: 1
Training loss: 1.4051697254180908
Validation loss: 2.066703279813131

Epoch: 6| Step: 2
Training loss: 1.4493378400802612
Validation loss: 2.091358244419098

Epoch: 6| Step: 3
Training loss: 1.0578744411468506
Validation loss: 2.1566122571627298

Epoch: 6| Step: 4
Training loss: 1.2057652473449707
Validation loss: 2.1691023310025535

Epoch: 6| Step: 5
Training loss: 1.0157243013381958
Validation loss: 2.117597818374634

Epoch: 6| Step: 6
Training loss: 1.668910026550293
Validation loss: 2.1267057259877524

Epoch: 6| Step: 7
Training loss: 1.6222562789916992
Validation loss: 2.0862823327382407

Epoch: 6| Step: 8
Training loss: 1.167895793914795
Validation loss: 2.0926658113797507

Epoch: 6| Step: 9
Training loss: 0.6687669157981873
Validation loss: 2.0331406792004905

Epoch: 6| Step: 10
Training loss: 0.8149010539054871
Validation loss: 2.032384475072225

Epoch: 6| Step: 11
Training loss: 1.4231919050216675
Validation loss: 2.0294516483942666

Epoch: 6| Step: 12
Training loss: 1.857426643371582
Validation loss: 2.041345258553823

Epoch: 6| Step: 13
Training loss: 1.6576822996139526
Validation loss: 2.0291207830111184

Epoch: 140| Step: 0
Training loss: 1.1684836149215698
Validation loss: 2.0646363894144693

Epoch: 6| Step: 1
Training loss: 1.4074645042419434
Validation loss: 2.058046877384186

Epoch: 6| Step: 2
Training loss: 1.1760449409484863
Validation loss: 2.1382452845573425

Epoch: 6| Step: 3
Training loss: 1.2653124332427979
Validation loss: 2.080784877141317

Epoch: 6| Step: 4
Training loss: 1.5607372522354126
Validation loss: 2.09825332959493

Epoch: 6| Step: 5
Training loss: 1.0045955181121826
Validation loss: 2.1890653371810913

Epoch: 6| Step: 6
Training loss: 1.3292322158813477
Validation loss: 2.070291578769684

Epoch: 6| Step: 7
Training loss: 1.7763712406158447
Validation loss: 2.0850097934405007

Epoch: 6| Step: 8
Training loss: 1.0622663497924805
Validation loss: 2.0391522645950317

Epoch: 6| Step: 9
Training loss: 1.179194450378418
Validation loss: 2.0656654834747314

Epoch: 6| Step: 10
Training loss: 1.3729639053344727
Validation loss: 2.0534281134605408

Epoch: 6| Step: 11
Training loss: 1.627432942390442
Validation loss: 2.043331285317739

Epoch: 6| Step: 12
Training loss: 1.2298063039779663
Validation loss: 2.000256141026815

Epoch: 6| Step: 13
Training loss: 1.3842589855194092
Validation loss: 2.09913831949234

Epoch: 141| Step: 0
Training loss: 0.8691253662109375
Validation loss: 2.039323647816976

Epoch: 6| Step: 1
Training loss: 1.9640071392059326
Validation loss: 2.0498965978622437

Epoch: 6| Step: 2
Training loss: 0.9066148996353149
Validation loss: 2.076410432656606

Epoch: 6| Step: 3
Training loss: 0.906238853931427
Validation loss: 2.073276937007904

Epoch: 6| Step: 4
Training loss: 1.3419289588928223
Validation loss: 2.100726366043091

Epoch: 6| Step: 5
Training loss: 1.7013531923294067
Validation loss: 2.1502304673194885

Epoch: 6| Step: 6
Training loss: 0.6487842798233032
Validation loss: 2.1347320874532065

Epoch: 6| Step: 7
Training loss: 1.644863247871399
Validation loss: 2.0698562264442444

Epoch: 6| Step: 8
Training loss: 1.6008448600769043
Validation loss: 2.0878301858901978

Epoch: 6| Step: 9
Training loss: 1.9760138988494873
Validation loss: 2.0284396608670554

Epoch: 6| Step: 10
Training loss: 1.256723165512085
Validation loss: 2.030649781227112

Epoch: 6| Step: 11
Training loss: 1.1068682670593262
Validation loss: 2.0575071573257446

Epoch: 6| Step: 12
Training loss: 1.554815649986267
Validation loss: 2.071441888809204

Epoch: 6| Step: 13
Training loss: 1.6856651306152344
Validation loss: 2.068894644578298

Epoch: 142| Step: 0
Training loss: 1.343692421913147
Validation loss: 2.0583450396855674

Epoch: 6| Step: 1
Training loss: 1.4484143257141113
Validation loss: 2.0618204275767007

Epoch: 6| Step: 2
Training loss: 1.6370714902877808
Validation loss: 2.067033509413401

Epoch: 6| Step: 3
Training loss: 0.8033843040466309
Validation loss: 2.0721099575360618

Epoch: 6| Step: 4
Training loss: 1.3371672630310059
Validation loss: 2.076712489128113

Epoch: 6| Step: 5
Training loss: 1.1148567199707031
Validation loss: 2.0873888731002808

Epoch: 6| Step: 6
Training loss: 1.9572097063064575
Validation loss: 2.175681471824646

Epoch: 6| Step: 7
Training loss: 1.1443243026733398
Validation loss: 2.0958916346232095

Epoch: 6| Step: 8
Training loss: 1.252752423286438
Validation loss: 2.1334232091903687

Epoch: 6| Step: 9
Training loss: 1.0972594022750854
Validation loss: 2.057397643725077

Epoch: 6| Step: 10
Training loss: 1.485651969909668
Validation loss: 2.0593820015589395

Epoch: 6| Step: 11
Training loss: 1.124922752380371
Validation loss: 2.0362785259882608

Epoch: 6| Step: 12
Training loss: 0.9658700823783875
Validation loss: 2.0585073232650757

Epoch: 6| Step: 13
Training loss: 1.6595392227172852
Validation loss: 2.047420084476471

Epoch: 143| Step: 0
Training loss: 1.1846932172775269
Validation loss: 2.0759848157564798

Epoch: 6| Step: 1
Training loss: 0.966869592666626
Validation loss: 2.0469280083974204

Epoch: 6| Step: 2
Training loss: 1.1809804439544678
Validation loss: 2.138867139816284

Epoch: 6| Step: 3
Training loss: 1.3347039222717285
Validation loss: 2.0319629907608032

Epoch: 6| Step: 4
Training loss: 1.6353650093078613
Validation loss: 2.1086698373158774

Epoch: 6| Step: 5
Training loss: 1.4993095397949219
Validation loss: 2.171526392300924

Epoch: 6| Step: 6
Training loss: 0.7885249853134155
Validation loss: 2.1165040334065757

Epoch: 6| Step: 7
Training loss: 1.346402883529663
Validation loss: 2.091411828994751

Epoch: 6| Step: 8
Training loss: 1.8282233476638794
Validation loss: 2.0054622093836465

Epoch: 6| Step: 9
Training loss: 0.9919172525405884
Validation loss: 2.040169914563497

Epoch: 6| Step: 10
Training loss: 1.1481781005859375
Validation loss: 2.093026340007782

Epoch: 6| Step: 11
Training loss: 1.4685275554656982
Validation loss: 2.0173668464024863

Epoch: 6| Step: 12
Training loss: 0.9579049944877625
Validation loss: 2.0316189726193747

Epoch: 6| Step: 13
Training loss: 1.5684069395065308
Validation loss: 2.0792466004689536

Epoch: 144| Step: 0
Training loss: 1.3419363498687744
Validation loss: 2.0314014554023743

Epoch: 6| Step: 1
Training loss: 0.65553879737854
Validation loss: 2.026131053765615

Epoch: 6| Step: 2
Training loss: 1.32218599319458
Validation loss: 2.114886999130249

Epoch: 6| Step: 3
Training loss: 0.9910541772842407
Validation loss: 2.063794950644175

Epoch: 6| Step: 4
Training loss: 1.1217620372772217
Validation loss: 2.047909756501516

Epoch: 6| Step: 5
Training loss: 1.0886929035186768
Validation loss: 2.0848336617151895

Epoch: 6| Step: 6
Training loss: 1.5814664363861084
Validation loss: 2.0662710865338645

Epoch: 6| Step: 7
Training loss: 0.9667121767997742
Validation loss: 2.0630090634028115

Epoch: 6| Step: 8
Training loss: 1.5368967056274414
Validation loss: 2.062090833981832

Epoch: 6| Step: 9
Training loss: 1.1951978206634521
Validation loss: 2.041833519935608

Epoch: 6| Step: 10
Training loss: 1.3403820991516113
Validation loss: 2.062940458456675

Epoch: 6| Step: 11
Training loss: 1.4874401092529297
Validation loss: 2.083538214365641

Epoch: 6| Step: 12
Training loss: 1.3754758834838867
Validation loss: 2.02501251300176

Epoch: 6| Step: 13
Training loss: 1.702296257019043
Validation loss: 2.101924697558085

Epoch: 145| Step: 0
Training loss: 1.2781782150268555
Validation loss: 2.0971246361732483

Epoch: 6| Step: 1
Training loss: 1.436540126800537
Validation loss: 2.0291011532147727

Epoch: 6| Step: 2
Training loss: 1.1106364727020264
Validation loss: 2.0733766754468284

Epoch: 6| Step: 3
Training loss: 1.781115174293518
Validation loss: 2.0771185755729675

Epoch: 6| Step: 4
Training loss: 0.9537349343299866
Validation loss: 2.0433056553204856

Epoch: 6| Step: 5
Training loss: 0.9377471208572388
Validation loss: 2.0453587969144187

Epoch: 6| Step: 6
Training loss: 0.9845945239067078
Validation loss: 2.068573792775472

Epoch: 6| Step: 7
Training loss: 1.2013109922409058
Validation loss: 2.067131201426188

Epoch: 6| Step: 8
Training loss: 1.3093239068984985
Validation loss: 2.059621572494507

Epoch: 6| Step: 9
Training loss: 1.2799105644226074
Validation loss: 2.0165863633155823

Epoch: 6| Step: 10
Training loss: 1.5480347871780396
Validation loss: 2.11788276831309

Epoch: 6| Step: 11
Training loss: 0.7133733034133911
Validation loss: 2.0634953578313193

Epoch: 6| Step: 12
Training loss: 1.6186872720718384
Validation loss: 2.0626224478085837

Epoch: 6| Step: 13
Training loss: 1.1892762184143066
Validation loss: 2.1455138127009072

Epoch: 146| Step: 0
Training loss: 1.3169139623641968
Validation loss: 2.0737240513165793

Epoch: 6| Step: 1
Training loss: 1.3650310039520264
Validation loss: 2.0407116413116455

Epoch: 6| Step: 2
Training loss: 1.6701494455337524
Validation loss: 2.0293950835863748

Epoch: 6| Step: 3
Training loss: 0.9460164904594421
Validation loss: 2.0451125303904214

Epoch: 6| Step: 4
Training loss: 0.8862199783325195
Validation loss: 2.01719864209493

Epoch: 6| Step: 5
Training loss: 1.240760087966919
Validation loss: 2.0980236331621804

Epoch: 6| Step: 6
Training loss: 1.3290876150131226
Validation loss: 2.0662026604016623

Epoch: 6| Step: 7
Training loss: 1.1883089542388916
Validation loss: 2.09513129790624

Epoch: 6| Step: 8
Training loss: 0.7963228225708008
Validation loss: 2.125759025414785

Epoch: 6| Step: 9
Training loss: 1.7251628637313843
Validation loss: 2.060074726740519

Epoch: 6| Step: 10
Training loss: 0.9630674123764038
Validation loss: 2.132118582725525

Epoch: 6| Step: 11
Training loss: 1.149843692779541
Validation loss: 2.124239126841227

Epoch: 6| Step: 12
Training loss: 1.2569900751113892
Validation loss: 2.074233074982961

Epoch: 6| Step: 13
Training loss: 1.0380011796951294
Validation loss: 2.030750056107839

Epoch: 147| Step: 0
Training loss: 1.4375884532928467
Validation loss: 1.9929498036702473

Epoch: 6| Step: 1
Training loss: 0.657597005367279
Validation loss: 2.0943283240000405

Epoch: 6| Step: 2
Training loss: 1.0678629875183105
Validation loss: 2.087988535563151

Epoch: 6| Step: 3
Training loss: 1.0488078594207764
Validation loss: 2.02957554658254

Epoch: 6| Step: 4
Training loss: 1.1500476598739624
Validation loss: 2.0515108903249106

Epoch: 6| Step: 5
Training loss: 0.9672170877456665
Validation loss: 2.10954741636912

Epoch: 6| Step: 6
Training loss: 1.088568925857544
Validation loss: 2.0980772376060486

Epoch: 6| Step: 7
Training loss: 1.3817780017852783
Validation loss: 2.1079158584276834

Epoch: 6| Step: 8
Training loss: 1.1555663347244263
Validation loss: 2.123305102189382

Epoch: 6| Step: 9
Training loss: 0.9359937906265259
Validation loss: 2.0919941663742065

Epoch: 6| Step: 10
Training loss: 1.6038949489593506
Validation loss: 2.1011882424354553

Epoch: 6| Step: 11
Training loss: 1.6507771015167236
Validation loss: 1.9974886377652485

Epoch: 6| Step: 12
Training loss: 1.2542455196380615
Validation loss: 1.9892287055651348

Epoch: 6| Step: 13
Training loss: 1.8108789920806885
Validation loss: 2.0348757902781167

Epoch: 148| Step: 0
Training loss: 0.9387331008911133
Validation loss: 2.072454571723938

Epoch: 6| Step: 1
Training loss: 1.3767175674438477
Validation loss: 2.090777317682902

Epoch: 6| Step: 2
Training loss: 1.6659345626831055
Validation loss: 2.044672667980194

Epoch: 6| Step: 3
Training loss: 1.0976073741912842
Validation loss: 2.0636866887410483

Epoch: 6| Step: 4
Training loss: 1.0185906887054443
Validation loss: 2.0046048561731973

Epoch: 6| Step: 5
Training loss: 1.2860206365585327
Validation loss: 2.0925294359525046

Epoch: 6| Step: 6
Training loss: 1.9732078313827515
Validation loss: 2.0809408823649087

Epoch: 6| Step: 7
Training loss: 1.2030372619628906
Validation loss: 2.104639987150828

Epoch: 6| Step: 8
Training loss: 1.3791804313659668
Validation loss: 2.1440330147743225

Epoch: 6| Step: 9
Training loss: 1.2560020685195923
Validation loss: 2.1379725337028503

Epoch: 6| Step: 10
Training loss: 1.2363650798797607
Validation loss: 2.083608945210775

Epoch: 6| Step: 11
Training loss: 1.1803923845291138
Validation loss: 2.07877649863561

Epoch: 6| Step: 12
Training loss: 1.3314220905303955
Validation loss: 2.1053677598635354

Epoch: 6| Step: 13
Training loss: 0.7762078046798706
Validation loss: 2.1006851394971213

Epoch: 149| Step: 0
Training loss: 1.4321178197860718
Validation loss: 2.0717094341913858

Epoch: 6| Step: 1
Training loss: 0.6815457344055176
Validation loss: 2.1131216287612915

Epoch: 6| Step: 2
Training loss: 0.9728301167488098
Validation loss: 2.1136765281359353

Epoch: 6| Step: 3
Training loss: 0.981052041053772
Validation loss: 2.0663405060768127

Epoch: 6| Step: 4
Training loss: 1.13340163230896
Validation loss: 2.080712894598643

Epoch: 6| Step: 5
Training loss: 1.0398285388946533
Validation loss: 2.084911823272705

Epoch: 6| Step: 6
Training loss: 1.4364798069000244
Validation loss: 2.056020438671112

Epoch: 6| Step: 7
Training loss: 1.1364823579788208
Validation loss: 2.04432213306427

Epoch: 6| Step: 8
Training loss: 1.0188544988632202
Validation loss: 2.074237644672394

Epoch: 6| Step: 9
Training loss: 1.0851504802703857
Validation loss: 2.1364503502845764

Epoch: 6| Step: 10
Training loss: 1.5292680263519287
Validation loss: 2.121941347916921

Epoch: 6| Step: 11
Training loss: 1.8511509895324707
Validation loss: 2.0661147832870483

Epoch: 6| Step: 12
Training loss: 1.2035644054412842
Validation loss: 2.0717081427574158

Epoch: 6| Step: 13
Training loss: 1.2971467971801758
Validation loss: 2.043922265370687

Epoch: 150| Step: 0
Training loss: 1.5125482082366943
Validation loss: 2.0970951517422995

Epoch: 6| Step: 1
Training loss: 0.789726972579956
Validation loss: 2.069853643576304

Epoch: 6| Step: 2
Training loss: 1.2737798690795898
Validation loss: 2.11759082476298

Epoch: 6| Step: 3
Training loss: 1.2652720212936401
Validation loss: 2.065542380015055

Epoch: 6| Step: 4
Training loss: 1.0781841278076172
Validation loss: 2.0979207952817283

Epoch: 6| Step: 5
Training loss: 1.1904187202453613
Validation loss: 2.0885247588157654

Epoch: 6| Step: 6
Training loss: 1.4147088527679443
Validation loss: 2.087144136428833

Epoch: 6| Step: 7
Training loss: 2.0931453704833984
Validation loss: 2.049295485019684

Epoch: 6| Step: 8
Training loss: 0.8903514742851257
Validation loss: 2.027855396270752

Epoch: 6| Step: 9
Training loss: 1.2626304626464844
Validation loss: 2.0464407006899514

Epoch: 6| Step: 10
Training loss: 1.1204752922058105
Validation loss: 2.007659614086151

Epoch: 6| Step: 11
Training loss: 1.4839198589324951
Validation loss: 2.0280598203341165

Epoch: 6| Step: 12
Training loss: 0.8195886611938477
Validation loss: 2.0830224752426147

Epoch: 6| Step: 13
Training loss: 1.0937553644180298
Validation loss: 2.018790324529012

Epoch: 151| Step: 0
Training loss: 1.093078851699829
Validation loss: 2.0853866736094155

Epoch: 6| Step: 1
Training loss: 1.1489505767822266
Validation loss: 2.1098464926083884

Epoch: 6| Step: 2
Training loss: 0.5362988710403442
Validation loss: 2.089857816696167

Epoch: 6| Step: 3
Training loss: 0.8552250862121582
Validation loss: 2.0583132108052573

Epoch: 6| Step: 4
Training loss: 1.9700467586517334
Validation loss: 2.0892154574394226

Epoch: 6| Step: 5
Training loss: 0.7844305038452148
Validation loss: 2.007562776406606

Epoch: 6| Step: 6
Training loss: 1.0039777755737305
Validation loss: 2.053796192010244

Epoch: 6| Step: 7
Training loss: 1.2410839796066284
Validation loss: 2.0677040815353394

Epoch: 6| Step: 8
Training loss: 1.3758466243743896
Validation loss: 2.0789014299710593

Epoch: 6| Step: 9
Training loss: 0.8590995073318481
Validation loss: 2.0361801783243814

Epoch: 6| Step: 10
Training loss: 1.0856316089630127
Validation loss: 2.016139050324758

Epoch: 6| Step: 11
Training loss: 1.3391129970550537
Validation loss: 2.030138929684957

Epoch: 6| Step: 12
Training loss: 1.7230205535888672
Validation loss: 2.0760735074679055

Epoch: 6| Step: 13
Training loss: 1.5404987335205078
Validation loss: 2.0819995403289795

Epoch: 152| Step: 0
Training loss: 1.1970105171203613
Validation loss: 2.0603211919466653

Epoch: 6| Step: 1
Training loss: 0.9836848974227905
Validation loss: 2.0646380186080933

Epoch: 6| Step: 2
Training loss: 0.9518814086914062
Validation loss: 2.0484536488850913

Epoch: 6| Step: 3
Training loss: 1.0012375116348267
Validation loss: 2.0819804271062217

Epoch: 6| Step: 4
Training loss: 1.4450392723083496
Validation loss: 2.0291571021080017

Epoch: 6| Step: 5
Training loss: 1.2292425632476807
Validation loss: 2.0320586562156677

Epoch: 6| Step: 6
Training loss: 1.3897323608398438
Validation loss: 2.072005331516266

Epoch: 6| Step: 7
Training loss: 1.8309648036956787
Validation loss: 2.0970643162727356

Epoch: 6| Step: 8
Training loss: 1.0326746702194214
Validation loss: 2.0701526403427124

Epoch: 6| Step: 9
Training loss: 1.3850501775741577
Validation loss: 2.0844615499178567

Epoch: 6| Step: 10
Training loss: 0.9036341905593872
Validation loss: 2.0868962605794272

Epoch: 6| Step: 11
Training loss: 1.2464303970336914
Validation loss: 2.160311241944631

Epoch: 6| Step: 12
Training loss: 1.1634697914123535
Validation loss: 2.2357905904452005

Epoch: 6| Step: 13
Training loss: 1.2519009113311768
Validation loss: 2.1311850945154824

Epoch: 153| Step: 0
Training loss: 1.071871042251587
Validation loss: 2.172035356362661

Epoch: 6| Step: 1
Training loss: 1.901627540588379
Validation loss: 2.1553374926249185

Epoch: 6| Step: 2
Training loss: 1.0591413974761963
Validation loss: 2.1061878403027854

Epoch: 6| Step: 3
Training loss: 0.8010388612747192
Validation loss: 2.0651687383651733

Epoch: 6| Step: 4
Training loss: 0.997272253036499
Validation loss: 2.0119276444117227

Epoch: 6| Step: 5
Training loss: 1.8413376808166504
Validation loss: 2.013067106405894

Epoch: 6| Step: 6
Training loss: 0.9143487811088562
Validation loss: 2.0914038817087808

Epoch: 6| Step: 7
Training loss: 1.4324429035186768
Validation loss: 2.0585694313049316

Epoch: 6| Step: 8
Training loss: 0.782943606376648
Validation loss: 1.9958719611167908

Epoch: 6| Step: 9
Training loss: 1.2440403699874878
Validation loss: 2.0746156175931296

Epoch: 6| Step: 10
Training loss: 0.9437390565872192
Validation loss: 2.0437031388282776

Epoch: 6| Step: 11
Training loss: 1.1881930828094482
Validation loss: 2.074836790561676

Epoch: 6| Step: 12
Training loss: 1.257359504699707
Validation loss: 2.0758496522903442

Epoch: 6| Step: 13
Training loss: 1.2939682006835938
Validation loss: 2.042147139708201

Epoch: 154| Step: 0
Training loss: 1.0571608543395996
Validation loss: 2.104204555352529

Epoch: 6| Step: 1
Training loss: 1.0783023834228516
Validation loss: 2.034602463245392

Epoch: 6| Step: 2
Training loss: 1.043173909187317
Validation loss: 2.050739904244741

Epoch: 6| Step: 3
Training loss: 1.1191630363464355
Validation loss: 2.0368530551592507

Epoch: 6| Step: 4
Training loss: 1.245079517364502
Validation loss: 2.0534289876619973

Epoch: 6| Step: 5
Training loss: 1.2480404376983643
Validation loss: 2.092037578423818

Epoch: 6| Step: 6
Training loss: 0.9522010087966919
Validation loss: 2.111302932103475

Epoch: 6| Step: 7
Training loss: 1.1946923732757568
Validation loss: 2.091416815916697

Epoch: 6| Step: 8
Training loss: 1.1183497905731201
Validation loss: 2.060202419757843

Epoch: 6| Step: 9
Training loss: 0.9984261393547058
Validation loss: 2.0424174865086875

Epoch: 6| Step: 10
Training loss: 0.8305717706680298
Validation loss: 2.0234527786572776

Epoch: 6| Step: 11
Training loss: 1.8669819831848145
Validation loss: 2.0865750511487327

Epoch: 6| Step: 12
Training loss: 1.3070114850997925
Validation loss: 2.037468453248342

Epoch: 6| Step: 13
Training loss: 1.6279627084732056
Validation loss: 2.0792389512062073

Epoch: 155| Step: 0
Training loss: 1.2882673740386963
Validation loss: 2.0842347542444863

Epoch: 6| Step: 1
Training loss: 0.7614816427230835
Validation loss: 2.051400899887085

Epoch: 6| Step: 2
Training loss: 0.8074786067008972
Validation loss: 1.9775571425755818

Epoch: 6| Step: 3
Training loss: 1.4325463771820068
Validation loss: 2.0250924229621887

Epoch: 6| Step: 4
Training loss: 1.7497743368148804
Validation loss: 2.0709309180577598

Epoch: 6| Step: 5
Training loss: 1.2431235313415527
Validation loss: 2.1201252341270447

Epoch: 6| Step: 6
Training loss: 0.9431143403053284
Validation loss: 2.1542610128720603

Epoch: 6| Step: 7
Training loss: 1.7202163934707642
Validation loss: 2.0965904792149863

Epoch: 6| Step: 8
Training loss: 0.9064301252365112
Validation loss: 2.1501389741897583

Epoch: 6| Step: 9
Training loss: 1.0399436950683594
Validation loss: 2.1330859661102295

Epoch: 6| Step: 10
Training loss: 1.2676337957382202
Validation loss: 2.0826674699783325

Epoch: 6| Step: 11
Training loss: 1.4524598121643066
Validation loss: 2.1000232299168906

Epoch: 6| Step: 12
Training loss: 1.0325692892074585
Validation loss: 2.0280974904696145

Epoch: 6| Step: 13
Training loss: 0.943845272064209
Validation loss: 2.044605294863383

Epoch: 156| Step: 0
Training loss: 0.9038478136062622
Validation loss: 2.0934635003407798

Epoch: 6| Step: 1
Training loss: 1.1273306608200073
Validation loss: 2.018114229043325

Epoch: 6| Step: 2
Training loss: 1.5814889669418335
Validation loss: 2.0626404682795205

Epoch: 6| Step: 3
Training loss: 0.9560267925262451
Validation loss: 2.030016283194224

Epoch: 6| Step: 4
Training loss: 1.0290215015411377
Validation loss: 1.996537188688914

Epoch: 6| Step: 5
Training loss: 1.17847740650177
Validation loss: 2.0968998869260154

Epoch: 6| Step: 6
Training loss: 1.31769859790802
Validation loss: 2.039208789666494

Epoch: 6| Step: 7
Training loss: 0.8937211036682129
Validation loss: 2.0442553957303367

Epoch: 6| Step: 8
Training loss: 1.3208009004592896
Validation loss: 2.0833762486775718

Epoch: 6| Step: 9
Training loss: 0.7860478758811951
Validation loss: 2.0525079369544983

Epoch: 6| Step: 10
Training loss: 1.5810892581939697
Validation loss: 2.0476608077685037

Epoch: 6| Step: 11
Training loss: 1.6375176906585693
Validation loss: 2.1353003780047097

Epoch: 6| Step: 12
Training loss: 0.9155983328819275
Validation loss: 2.108846068382263

Epoch: 6| Step: 13
Training loss: 0.8195014595985413
Validation loss: 2.077090561389923

Epoch: 157| Step: 0
Training loss: 0.774186372756958
Validation loss: 2.0854577819506326

Epoch: 6| Step: 1
Training loss: 0.664238452911377
Validation loss: 2.1106231013933816

Epoch: 6| Step: 2
Training loss: 1.197793960571289
Validation loss: 2.1021297375361123

Epoch: 6| Step: 3
Training loss: 1.154962420463562
Validation loss: 2.0456907749176025

Epoch: 6| Step: 4
Training loss: 0.7932614088058472
Validation loss: 2.074380338191986

Epoch: 6| Step: 5
Training loss: 1.0459821224212646
Validation loss: 2.024476408958435

Epoch: 6| Step: 6
Training loss: 1.1716347932815552
Validation loss: 2.0313795804977417

Epoch: 6| Step: 7
Training loss: 1.1048088073730469
Validation loss: 2.114845037460327

Epoch: 6| Step: 8
Training loss: 1.8267838954925537
Validation loss: 2.0125258962313333

Epoch: 6| Step: 9
Training loss: 1.9003729820251465
Validation loss: 2.044108768304189

Epoch: 6| Step: 10
Training loss: 0.860345184803009
Validation loss: 2.1465859413146973

Epoch: 6| Step: 11
Training loss: 1.0501519441604614
Validation loss: 2.11298135916392

Epoch: 6| Step: 12
Training loss: 1.0106816291809082
Validation loss: 2.0488134622573853

Epoch: 6| Step: 13
Training loss: 1.4354579448699951
Validation loss: 2.088979880015055

Epoch: 158| Step: 0
Training loss: 1.2848963737487793
Validation loss: 2.112558881441752

Epoch: 6| Step: 1
Training loss: 1.2595624923706055
Validation loss: 2.0779236952463784

Epoch: 6| Step: 2
Training loss: 1.0305687189102173
Validation loss: 2.0629018346468606

Epoch: 6| Step: 3
Training loss: 0.6150282621383667
Validation loss: 2.057217518488566

Epoch: 6| Step: 4
Training loss: 1.2039910554885864
Validation loss: 2.013514757156372

Epoch: 6| Step: 5
Training loss: 0.9493318200111389
Validation loss: 2.088638166586558

Epoch: 6| Step: 6
Training loss: 1.3901910781860352
Validation loss: 2.004554828008016

Epoch: 6| Step: 7
Training loss: 1.17580246925354
Validation loss: 2.0394320289293923

Epoch: 6| Step: 8
Training loss: 1.0415980815887451
Validation loss: 2.046518623828888

Epoch: 6| Step: 9
Training loss: 0.8501562476158142
Validation loss: 2.0713568925857544

Epoch: 6| Step: 10
Training loss: 1.4581087827682495
Validation loss: 2.083359122276306

Epoch: 6| Step: 11
Training loss: 1.7863895893096924
Validation loss: 2.0587607622146606

Epoch: 6| Step: 12
Training loss: 0.9715224504470825
Validation loss: 2.071733593940735

Epoch: 6| Step: 13
Training loss: 1.1973607540130615
Validation loss: 2.0923747618993125

Epoch: 159| Step: 0
Training loss: 0.8161353468894958
Validation loss: 2.0983715454737344

Epoch: 6| Step: 1
Training loss: 1.1096910238265991
Validation loss: 2.096213459968567

Epoch: 6| Step: 2
Training loss: 0.8941422700881958
Validation loss: 2.045279880364736

Epoch: 6| Step: 3
Training loss: 1.8950660228729248
Validation loss: 2.0838516553243003

Epoch: 6| Step: 4
Training loss: 1.1502971649169922
Validation loss: 2.006274402141571

Epoch: 6| Step: 5
Training loss: 0.8241300582885742
Validation loss: 2.0421248277028403

Epoch: 6| Step: 6
Training loss: 0.9933695793151855
Validation loss: 2.033996820449829

Epoch: 6| Step: 7
Training loss: 1.215498447418213
Validation loss: 2.030043085416158

Epoch: 6| Step: 8
Training loss: 1.1416596174240112
Validation loss: 2.0475566188494363

Epoch: 6| Step: 9
Training loss: 0.9885928630828857
Validation loss: 2.046265423297882

Epoch: 6| Step: 10
Training loss: 0.812832236289978
Validation loss: 2.0491274992624917

Epoch: 6| Step: 11
Training loss: 1.7578372955322266
Validation loss: 2.079590678215027

Epoch: 6| Step: 12
Training loss: 1.2744122743606567
Validation loss: 2.1575659910837808

Epoch: 6| Step: 13
Training loss: 1.1488736867904663
Validation loss: 2.0793385108311973

Epoch: 160| Step: 0
Training loss: 1.1496660709381104
Validation loss: 2.0328274766604104

Epoch: 6| Step: 1
Training loss: 1.0400322675704956
Validation loss: 2.0353590647379556

Epoch: 6| Step: 2
Training loss: 1.3601843118667603
Validation loss: 2.067317306995392

Epoch: 6| Step: 3
Training loss: 1.315953254699707
Validation loss: 2.04039732615153

Epoch: 6| Step: 4
Training loss: 1.068260669708252
Validation loss: 2.0386076172192893

Epoch: 6| Step: 5
Training loss: 0.9185620546340942
Validation loss: 2.1262388229370117

Epoch: 6| Step: 6
Training loss: 0.7929965257644653
Validation loss: 2.067725678284963

Epoch: 6| Step: 7
Training loss: 1.1058449745178223
Validation loss: 2.0583644906679788

Epoch: 6| Step: 8
Training loss: 1.3444089889526367
Validation loss: 2.090565244356791

Epoch: 6| Step: 9
Training loss: 0.9892120361328125
Validation loss: 2.0930875539779663

Epoch: 6| Step: 10
Training loss: 1.02729070186615
Validation loss: 2.1215103467305503

Epoch: 6| Step: 11
Training loss: 0.5560542941093445
Validation loss: 2.1382214029630027

Epoch: 6| Step: 12
Training loss: 1.5172882080078125
Validation loss: 2.129188517729441

Epoch: 6| Step: 13
Training loss: 1.8500728607177734
Validation loss: 2.071139375368754

Epoch: 161| Step: 0
Training loss: 0.8721640110015869
Validation loss: 2.1261342565218606

Epoch: 6| Step: 1
Training loss: 1.9934651851654053
Validation loss: 2.1028157273928323

Epoch: 6| Step: 2
Training loss: 1.3590104579925537
Validation loss: 2.078405221303304

Epoch: 6| Step: 3
Training loss: 1.518467903137207
Validation loss: 2.0697084069252014

Epoch: 6| Step: 4
Training loss: 1.0564589500427246
Validation loss: 2.052102347215017

Epoch: 6| Step: 5
Training loss: 1.2502517700195312
Validation loss: 2.0757585962613425

Epoch: 6| Step: 6
Training loss: 0.9952489137649536
Validation loss: 2.0531479120254517

Epoch: 6| Step: 7
Training loss: 0.9410813450813293
Validation loss: 2.006870130697886

Epoch: 6| Step: 8
Training loss: 1.0239684581756592
Validation loss: 2.041775405406952

Epoch: 6| Step: 9
Training loss: 1.4537097215652466
Validation loss: 2.037960429986318

Epoch: 6| Step: 10
Training loss: 0.4339272677898407
Validation loss: 2.0378214716911316

Epoch: 6| Step: 11
Training loss: 0.9259109497070312
Validation loss: 2.06415456533432

Epoch: 6| Step: 12
Training loss: 1.236591100692749
Validation loss: 2.1194045543670654

Epoch: 6| Step: 13
Training loss: 0.5863665342330933
Validation loss: 2.0462045073509216

Epoch: 162| Step: 0
Training loss: 0.9474136829376221
Validation loss: 2.081735630830129

Epoch: 6| Step: 1
Training loss: 1.00089693069458
Validation loss: 2.0273335576057434

Epoch: 6| Step: 2
Training loss: 0.9284868836402893
Validation loss: 2.032641351222992

Epoch: 6| Step: 3
Training loss: 0.7556871771812439
Validation loss: 2.0271590749422708

Epoch: 6| Step: 4
Training loss: 1.043771743774414
Validation loss: 2.045344074567159

Epoch: 6| Step: 5
Training loss: 0.953311562538147
Validation loss: 2.062991480032603

Epoch: 6| Step: 6
Training loss: 1.1452926397323608
Validation loss: 2.065869688987732

Epoch: 6| Step: 7
Training loss: 0.9415388703346252
Validation loss: 2.0734025835990906

Epoch: 6| Step: 8
Training loss: 1.8975039720535278
Validation loss: 2.0541522900263467

Epoch: 6| Step: 9
Training loss: 1.1780226230621338
Validation loss: 2.0504390597343445

Epoch: 6| Step: 10
Training loss: 0.7719022035598755
Validation loss: 2.0826565424601235

Epoch: 6| Step: 11
Training loss: 0.9347670674324036
Validation loss: 2.0648252765337625

Epoch: 6| Step: 12
Training loss: 1.2550404071807861
Validation loss: 2.1047650376955667

Epoch: 6| Step: 13
Training loss: 1.2111153602600098
Validation loss: 2.0875123937924704

Epoch: 163| Step: 0
Training loss: 1.412142276763916
Validation loss: 2.1005183458328247

Epoch: 6| Step: 1
Training loss: 0.81390380859375
Validation loss: 2.0275957783063254

Epoch: 6| Step: 2
Training loss: 1.110026240348816
Validation loss: 2.0148271719614663

Epoch: 6| Step: 3
Training loss: 0.6522774696350098
Validation loss: 2.002998431523641

Epoch: 6| Step: 4
Training loss: 1.207903265953064
Validation loss: 2.01133131980896

Epoch: 6| Step: 5
Training loss: 1.4456744194030762
Validation loss: 2.0450026790301004

Epoch: 6| Step: 6
Training loss: 0.6614413261413574
Validation loss: 2.0722981293996177

Epoch: 6| Step: 7
Training loss: 0.8818049430847168
Validation loss: 2.0947025616963706

Epoch: 6| Step: 8
Training loss: 0.7854633331298828
Validation loss: 2.0521854162216187

Epoch: 6| Step: 9
Training loss: 0.7574487924575806
Validation loss: 2.0426579117774963

Epoch: 6| Step: 10
Training loss: 1.1887856721878052
Validation loss: 2.0659834345181785

Epoch: 6| Step: 11
Training loss: 1.0133780241012573
Validation loss: 2.0560430685679116

Epoch: 6| Step: 12
Training loss: 1.748785376548767
Validation loss: 2.037310302257538

Epoch: 6| Step: 13
Training loss: 1.1959950923919678
Validation loss: 1.992044468720754

Epoch: 164| Step: 0
Training loss: 0.8324927091598511
Validation loss: 2.082020401954651

Epoch: 6| Step: 1
Training loss: 0.6246767044067383
Validation loss: 2.053950786590576

Epoch: 6| Step: 2
Training loss: 1.1421589851379395
Validation loss: 2.011511445045471

Epoch: 6| Step: 3
Training loss: 0.8278793692588806
Validation loss: 2.0242787996927896

Epoch: 6| Step: 4
Training loss: 1.0123851299285889
Validation loss: 1.986814280351003

Epoch: 6| Step: 5
Training loss: 2.089975118637085
Validation loss: 2.0620808601379395

Epoch: 6| Step: 6
Training loss: 1.0285556316375732
Validation loss: 2.099770983060201

Epoch: 6| Step: 7
Training loss: 1.032088041305542
Validation loss: 2.0714869697888694

Epoch: 6| Step: 8
Training loss: 1.1372175216674805
Validation loss: 2.0648003816604614

Epoch: 6| Step: 9
Training loss: 0.7125141620635986
Validation loss: 2.052590032418569

Epoch: 6| Step: 10
Training loss: 1.2001779079437256
Validation loss: 2.0703747073809304

Epoch: 6| Step: 11
Training loss: 0.5261628031730652
Validation loss: 2.0210158626238504

Epoch: 6| Step: 12
Training loss: 1.1294636726379395
Validation loss: 2.0847209692001343

Epoch: 6| Step: 13
Training loss: 1.451009750366211
Validation loss: 2.087868332862854

Epoch: 165| Step: 0
Training loss: 0.9089593887329102
Validation loss: 2.0230050484339395

Epoch: 6| Step: 1
Training loss: 0.9099502563476562
Validation loss: 2.07145357131958

Epoch: 6| Step: 2
Training loss: 0.4929121136665344
Validation loss: 2.0281384189923606

Epoch: 6| Step: 3
Training loss: 1.6471807956695557
Validation loss: 2.0447575449943542

Epoch: 6| Step: 4
Training loss: 0.5031623840332031
Validation loss: 2.0451274116834006

Epoch: 6| Step: 5
Training loss: 1.2274904251098633
Validation loss: 2.057799498240153

Epoch: 6| Step: 6
Training loss: 1.2367483377456665
Validation loss: 2.060297886530558

Epoch: 6| Step: 7
Training loss: 1.5066567659378052
Validation loss: 2.069970746835073

Epoch: 6| Step: 8
Training loss: 1.0715261697769165
Validation loss: 2.0468019247055054

Epoch: 6| Step: 9
Training loss: 0.9539288282394409
Validation loss: 2.0610394875208535

Epoch: 6| Step: 10
Training loss: 0.7024837732315063
Validation loss: 2.0165204803148904

Epoch: 6| Step: 11
Training loss: 1.186004638671875
Validation loss: 2.0628000100453696

Epoch: 6| Step: 12
Training loss: 0.6949641704559326
Validation loss: 2.092011292775472

Epoch: 6| Step: 13
Training loss: 1.653435468673706
Validation loss: 2.0164580742518106

Epoch: 166| Step: 0
Training loss: 1.233725905418396
Validation loss: 2.077974796295166

Epoch: 6| Step: 1
Training loss: 1.2412856817245483
Validation loss: 2.0378353794415793

Epoch: 6| Step: 2
Training loss: 1.1750292778015137
Validation loss: 2.084376871585846

Epoch: 6| Step: 3
Training loss: 1.1716957092285156
Validation loss: 2.0796852310498557

Epoch: 6| Step: 4
Training loss: 1.469921588897705
Validation loss: 2.0944181283315024

Epoch: 6| Step: 5
Training loss: 1.0235109329223633
Validation loss: 2.0907936096191406

Epoch: 6| Step: 6
Training loss: 0.8512593507766724
Validation loss: 2.0674723982810974

Epoch: 6| Step: 7
Training loss: 0.9316731095314026
Validation loss: 2.052142838637034

Epoch: 6| Step: 8
Training loss: 0.8346120119094849
Validation loss: 2.0733792781829834

Epoch: 6| Step: 9
Training loss: 1.6386975049972534
Validation loss: 2.0571767687797546

Epoch: 6| Step: 10
Training loss: 1.0989718437194824
Validation loss: 2.0731337467829385

Epoch: 6| Step: 11
Training loss: 0.809028148651123
Validation loss: 2.148215432961782

Epoch: 6| Step: 12
Training loss: 1.0312308073043823
Validation loss: 2.0745049715042114

Epoch: 6| Step: 13
Training loss: 0.6960050463676453
Validation loss: 2.0905218720436096

Epoch: 167| Step: 0
Training loss: 1.17400062084198
Validation loss: 2.0884231527646384

Epoch: 6| Step: 1
Training loss: 1.431638479232788
Validation loss: 2.0538384318351746

Epoch: 6| Step: 2
Training loss: 0.9070114493370056
Validation loss: 2.018372197945913

Epoch: 6| Step: 3
Training loss: 1.434214472770691
Validation loss: 2.027957042058309

Epoch: 6| Step: 4
Training loss: 1.0584466457366943
Validation loss: 2.047605295976003

Epoch: 6| Step: 5
Training loss: 1.219422698020935
Validation loss: 2.001735349496206

Epoch: 6| Step: 6
Training loss: 0.9352587461471558
Validation loss: 2.0471436977386475

Epoch: 6| Step: 7
Training loss: 1.0691570043563843
Validation loss: 2.045588751633962

Epoch: 6| Step: 8
Training loss: 1.0604875087738037
Validation loss: 2.0889045794804892

Epoch: 6| Step: 9
Training loss: 1.305556297302246
Validation loss: 2.032649795214335

Epoch: 6| Step: 10
Training loss: 0.5634026527404785
Validation loss: 2.1179468830426535

Epoch: 6| Step: 11
Training loss: 0.6280044317245483
Validation loss: 2.040988544623057

Epoch: 6| Step: 12
Training loss: 1.0466300249099731
Validation loss: 2.00339812040329

Epoch: 6| Step: 13
Training loss: 0.9415469169616699
Validation loss: 2.1575294733047485

Epoch: 168| Step: 0
Training loss: 1.422845482826233
Validation loss: 2.034076730410258

Epoch: 6| Step: 1
Training loss: 0.5894355773925781
Validation loss: 2.0787166158358255

Epoch: 6| Step: 2
Training loss: 0.7461676597595215
Validation loss: 2.0629030068715415

Epoch: 6| Step: 3
Training loss: 1.3930237293243408
Validation loss: 2.0627185304959617

Epoch: 6| Step: 4
Training loss: 1.3007526397705078
Validation loss: 2.094246784845988

Epoch: 6| Step: 5
Training loss: 0.8459678292274475
Validation loss: 2.0845763087272644

Epoch: 6| Step: 6
Training loss: 0.8849173188209534
Validation loss: 2.0690597693125405

Epoch: 6| Step: 7
Training loss: 0.5802096128463745
Validation loss: 2.0759925842285156

Epoch: 6| Step: 8
Training loss: 0.9624033570289612
Validation loss: 2.0176873207092285

Epoch: 6| Step: 9
Training loss: 1.0673575401306152
Validation loss: 2.0220356583595276

Epoch: 6| Step: 10
Training loss: 0.711309552192688
Validation loss: 2.1025837659835815

Epoch: 6| Step: 11
Training loss: 1.2028089761734009
Validation loss: 2.09434312582016

Epoch: 6| Step: 12
Training loss: 0.994060218334198
Validation loss: 2.046566983064016

Epoch: 6| Step: 13
Training loss: 1.465775728225708
Validation loss: 2.0741536219914756

Epoch: 169| Step: 0
Training loss: 0.8467158675193787
Validation loss: 2.0598119695981345

Epoch: 6| Step: 1
Training loss: 1.6480106115341187
Validation loss: 2.0591715574264526

Epoch: 6| Step: 2
Training loss: 1.5818140506744385
Validation loss: 2.055664896965027

Epoch: 6| Step: 3
Training loss: 0.4302655756473541
Validation loss: 2.0608019828796387

Epoch: 6| Step: 4
Training loss: 0.8633146286010742
Validation loss: 2.049207329750061

Epoch: 6| Step: 5
Training loss: 0.5594130754470825
Validation loss: 2.0639442801475525

Epoch: 6| Step: 6
Training loss: 1.237687349319458
Validation loss: 2.125498096148173

Epoch: 6| Step: 7
Training loss: 1.1228156089782715
Validation loss: 2.1599857211112976

Epoch: 6| Step: 8
Training loss: 1.002993106842041
Validation loss: 2.069594919681549

Epoch: 6| Step: 9
Training loss: 0.8878779411315918
Validation loss: 2.0502023100852966

Epoch: 6| Step: 10
Training loss: 0.7927153706550598
Validation loss: 2.0180147091547647

Epoch: 6| Step: 11
Training loss: 0.9946960806846619
Validation loss: 2.070573369661967

Epoch: 6| Step: 12
Training loss: 1.0184509754180908
Validation loss: 2.0492398341496787

Epoch: 6| Step: 13
Training loss: 1.321070909500122
Validation loss: 2.0803392926851907

Epoch: 170| Step: 0
Training loss: 0.8601282835006714
Validation loss: 2.06083736817042

Epoch: 6| Step: 1
Training loss: 0.8832147717475891
Validation loss: 2.0268781979878745

Epoch: 6| Step: 2
Training loss: 1.3579708337783813
Validation loss: 2.0899789532025657

Epoch: 6| Step: 3
Training loss: 0.9082702398300171
Validation loss: 2.044807195663452

Epoch: 6| Step: 4
Training loss: 0.9111086130142212
Validation loss: 2.0996941725413003

Epoch: 6| Step: 5
Training loss: 0.9628439545631409
Validation loss: 2.0358663201332092

Epoch: 6| Step: 6
Training loss: 1.234797477722168
Validation loss: 2.131137510140737

Epoch: 6| Step: 7
Training loss: 0.38668787479400635
Validation loss: 2.0599064032236734

Epoch: 6| Step: 8
Training loss: 1.3351469039916992
Validation loss: 2.0085391799608865

Epoch: 6| Step: 9
Training loss: 1.1172746419906616
Validation loss: 2.01810089747111

Epoch: 6| Step: 10
Training loss: 1.1052366495132446
Validation loss: 2.0242390235265098

Epoch: 6| Step: 11
Training loss: 0.47809022665023804
Validation loss: 2.0341867208480835

Epoch: 6| Step: 12
Training loss: 0.8535169363021851
Validation loss: 2.0329716404279075

Epoch: 6| Step: 13
Training loss: 1.7982168197631836
Validation loss: 2.0705440441767373

Epoch: 171| Step: 0
Training loss: 1.0857394933700562
Validation loss: 2.0865238110224404

Epoch: 6| Step: 1
Training loss: 0.9451231360435486
Validation loss: 2.020934065183004

Epoch: 6| Step: 2
Training loss: 0.821377158164978
Validation loss: 2.064811627070109

Epoch: 6| Step: 3
Training loss: 0.6033886671066284
Validation loss: 2.093803564707438

Epoch: 6| Step: 4
Training loss: 1.2740399837493896
Validation loss: 2.083485960960388

Epoch: 6| Step: 5
Training loss: 0.76408451795578
Validation loss: 2.0600365002950034

Epoch: 6| Step: 6
Training loss: 1.1921309232711792
Validation loss: 2.0834690928459167

Epoch: 6| Step: 7
Training loss: 1.109541654586792
Validation loss: 2.0372870365778604

Epoch: 6| Step: 8
Training loss: 1.2033032178878784
Validation loss: 2.0832884510358176

Epoch: 6| Step: 9
Training loss: 0.9727113246917725
Validation loss: 2.0852139393488565

Epoch: 6| Step: 10
Training loss: 0.7937053442001343
Validation loss: 2.10263329744339

Epoch: 6| Step: 11
Training loss: 1.0637913942337036
Validation loss: 1.9950262506802876

Epoch: 6| Step: 12
Training loss: 1.0193321704864502
Validation loss: 2.060887575149536

Epoch: 6| Step: 13
Training loss: 1.162246823310852
Validation loss: 2.040235777695974

Epoch: 172| Step: 0
Training loss: 0.9716290235519409
Validation loss: 2.033701777458191

Epoch: 6| Step: 1
Training loss: 1.052727222442627
Validation loss: 2.048160215218862

Epoch: 6| Step: 2
Training loss: 1.5949602127075195
Validation loss: 2.075512250264486

Epoch: 6| Step: 3
Training loss: 1.464077115058899
Validation loss: 2.09955757856369

Epoch: 6| Step: 4
Training loss: 0.6400468945503235
Validation loss: 2.107339918613434

Epoch: 6| Step: 5
Training loss: 1.1868445873260498
Validation loss: 2.09935333331426

Epoch: 6| Step: 6
Training loss: 0.8468140363693237
Validation loss: 2.084127426147461

Epoch: 6| Step: 7
Training loss: 0.8831720948219299
Validation loss: 2.052897870540619

Epoch: 6| Step: 8
Training loss: 0.9593256711959839
Validation loss: 2.0523855884869895

Epoch: 6| Step: 9
Training loss: 0.8653837442398071
Validation loss: 2.0771720012029014

Epoch: 6| Step: 10
Training loss: 1.2350244522094727
Validation loss: 2.0397422115008035

Epoch: 6| Step: 11
Training loss: 0.9132829904556274
Validation loss: 2.020765781402588

Epoch: 6| Step: 12
Training loss: 1.2068053483963013
Validation loss: 2.101410388946533

Epoch: 6| Step: 13
Training loss: 0.9341233968734741
Validation loss: 2.022433261076609

Epoch: 173| Step: 0
Training loss: 0.7908935546875
Validation loss: 2.0787842671076455

Epoch: 6| Step: 1
Training loss: 1.0723354816436768
Validation loss: 2.0723724166552224

Epoch: 6| Step: 2
Training loss: 1.3046660423278809
Validation loss: 2.122983396053314

Epoch: 6| Step: 3
Training loss: 0.6833585500717163
Validation loss: 2.0619243582089744

Epoch: 6| Step: 4
Training loss: 1.2205984592437744
Validation loss: 2.04740842183431

Epoch: 6| Step: 5
Training loss: 0.6885294914245605
Validation loss: 2.0475275913874307

Epoch: 6| Step: 6
Training loss: 0.8072788715362549
Validation loss: 2.0235762000083923

Epoch: 6| Step: 7
Training loss: 0.6063182353973389
Validation loss: 2.053829570611318

Epoch: 6| Step: 8
Training loss: 1.0481655597686768
Validation loss: 2.0502635836601257

Epoch: 6| Step: 9
Training loss: 1.1137135028839111
Validation loss: 2.1116201281547546

Epoch: 6| Step: 10
Training loss: 1.3664450645446777
Validation loss: 2.0540433724721274

Epoch: 6| Step: 11
Training loss: 1.0004758834838867
Validation loss: 2.0701002875963845

Epoch: 6| Step: 12
Training loss: 1.5148704051971436
Validation loss: 2.0307400623957315

Epoch: 6| Step: 13
Training loss: 0.5631871819496155
Validation loss: 2.0525124073028564

Epoch: 174| Step: 0
Training loss: 1.3246674537658691
Validation loss: 2.048527975877126

Epoch: 6| Step: 1
Training loss: 0.9144539833068848
Validation loss: 2.0704050858815513

Epoch: 6| Step: 2
Training loss: 1.1559028625488281
Validation loss: 2.040968338648478

Epoch: 6| Step: 3
Training loss: 1.1981350183486938
Validation loss: 2.05251814921697

Epoch: 6| Step: 4
Training loss: 0.8729730844497681
Validation loss: 2.0096128980318704

Epoch: 6| Step: 5
Training loss: 0.8210395574569702
Validation loss: 2.0317214926083884

Epoch: 6| Step: 6
Training loss: 1.0534254312515259
Validation loss: 2.0329233209292092

Epoch: 6| Step: 7
Training loss: 0.6314987540245056
Validation loss: 2.0575268864631653

Epoch: 6| Step: 8
Training loss: 0.8589887619018555
Validation loss: 2.0214192469914756

Epoch: 6| Step: 9
Training loss: 0.7519091367721558
Validation loss: 2.038031021753947

Epoch: 6| Step: 10
Training loss: 1.1607780456542969
Validation loss: 2.0932666261990867

Epoch: 6| Step: 11
Training loss: 1.058868169784546
Validation loss: 2.098922689755758

Epoch: 6| Step: 12
Training loss: 0.9614666700363159
Validation loss: 2.102939327557882

Epoch: 6| Step: 13
Training loss: 0.9342100024223328
Validation loss: 2.125077505906423

Epoch: 175| Step: 0
Training loss: 0.9714532494544983
Validation loss: 2.1063119967778525

Epoch: 6| Step: 1
Training loss: 1.2289435863494873
Validation loss: 2.088162104288737

Epoch: 6| Step: 2
Training loss: 0.667216420173645
Validation loss: 2.114808360735575

Epoch: 6| Step: 3
Training loss: 1.3389151096343994
Validation loss: 2.1140896479288735

Epoch: 6| Step: 4
Training loss: 0.7260414361953735
Validation loss: 2.0347761710484824

Epoch: 6| Step: 5
Training loss: 1.1222350597381592
Validation loss: 2.069949527581533

Epoch: 6| Step: 6
Training loss: 0.6434150338172913
Validation loss: 2.0703188379605613

Epoch: 6| Step: 7
Training loss: 0.9560890197753906
Validation loss: 2.075939893722534

Epoch: 6| Step: 8
Training loss: 1.2344491481781006
Validation loss: 2.119404455025991

Epoch: 6| Step: 9
Training loss: 0.9726064205169678
Validation loss: 2.0391769806543985

Epoch: 6| Step: 10
Training loss: 1.3920278549194336
Validation loss: 2.07257749636968

Epoch: 6| Step: 11
Training loss: 0.5763634443283081
Validation loss: 2.0647731026013694

Epoch: 6| Step: 12
Training loss: 0.7622369527816772
Validation loss: 2.06801438331604

Epoch: 6| Step: 13
Training loss: 0.8005838394165039
Validation loss: 2.080399831136068

Epoch: 176| Step: 0
Training loss: 1.0234425067901611
Validation loss: 2.068270484606425

Epoch: 6| Step: 1
Training loss: 0.4288979768753052
Validation loss: 2.0939849813779197

Epoch: 6| Step: 2
Training loss: 1.0607900619506836
Validation loss: 2.125448743502299

Epoch: 6| Step: 3
Training loss: 1.4076071977615356
Validation loss: 2.049095571041107

Epoch: 6| Step: 4
Training loss: 0.9546074867248535
Validation loss: 2.0511696139971414

Epoch: 6| Step: 5
Training loss: 0.7262483835220337
Validation loss: 2.025801102320353

Epoch: 6| Step: 6
Training loss: 0.7604701519012451
Validation loss: 2.02683695157369

Epoch: 6| Step: 7
Training loss: 1.1689444780349731
Validation loss: 1.9987958073616028

Epoch: 6| Step: 8
Training loss: 1.76979398727417
Validation loss: 2.0490029056866965

Epoch: 6| Step: 9
Training loss: 1.055040955543518
Validation loss: 2.0350452065467834

Epoch: 6| Step: 10
Training loss: 1.1062579154968262
Validation loss: 2.0710656444231668

Epoch: 6| Step: 11
Training loss: 0.7401149272918701
Validation loss: 2.0191660126050315

Epoch: 6| Step: 12
Training loss: 1.2578232288360596
Validation loss: 2.00876118739446

Epoch: 6| Step: 13
Training loss: 0.6621556282043457
Validation loss: 2.0300099849700928

Epoch: 177| Step: 0
Training loss: 0.6904387474060059
Validation loss: 2.048852105935415

Epoch: 6| Step: 1
Training loss: 0.7829591631889343
Validation loss: 2.0371759136517844

Epoch: 6| Step: 2
Training loss: 0.8292734622955322
Validation loss: 2.019893229007721

Epoch: 6| Step: 3
Training loss: 0.9299370646476746
Validation loss: 2.077772001425425

Epoch: 6| Step: 4
Training loss: 1.3662408590316772
Validation loss: 2.0444470643997192

Epoch: 6| Step: 5
Training loss: 0.7513973116874695
Validation loss: 2.089847981929779

Epoch: 6| Step: 6
Training loss: 1.2126729488372803
Validation loss: 2.032144824663798

Epoch: 6| Step: 7
Training loss: 0.8718550205230713
Validation loss: 1.9750169316927593

Epoch: 6| Step: 8
Training loss: 0.8105220794677734
Validation loss: 2.072304666042328

Epoch: 6| Step: 9
Training loss: 1.0581377744674683
Validation loss: 2.05332487821579

Epoch: 6| Step: 10
Training loss: 0.8690783977508545
Validation loss: 2.026226202646891

Epoch: 6| Step: 11
Training loss: 1.1446468830108643
Validation loss: 2.0643174052238464

Epoch: 6| Step: 12
Training loss: 1.2186341285705566
Validation loss: 2.04280153910319

Epoch: 6| Step: 13
Training loss: 0.8538726568222046
Validation loss: 2.079931159814199

Epoch: 178| Step: 0
Training loss: 0.9431754350662231
Validation loss: 2.0914629101753235

Epoch: 6| Step: 1
Training loss: 1.06488037109375
Validation loss: 2.036773681640625

Epoch: 6| Step: 2
Training loss: 1.0463066101074219
Validation loss: 2.0491925477981567

Epoch: 6| Step: 3
Training loss: 0.9339067935943604
Validation loss: 2.0430474281311035

Epoch: 6| Step: 4
Training loss: 0.9678381681442261
Validation loss: 2.0468616684277854

Epoch: 6| Step: 5
Training loss: 1.019760251045227
Validation loss: 2.02657284339269

Epoch: 6| Step: 6
Training loss: 0.6790139675140381
Validation loss: 2.038434147834778

Epoch: 6| Step: 7
Training loss: 1.028049111366272
Validation loss: 2.0844014088312783

Epoch: 6| Step: 8
Training loss: 0.6871533393859863
Validation loss: 2.0698908964792886

Epoch: 6| Step: 9
Training loss: 1.010799527168274
Validation loss: 2.1059516270955405

Epoch: 6| Step: 10
Training loss: 1.2314598560333252
Validation loss: 2.027310768763224

Epoch: 6| Step: 11
Training loss: 0.9468271732330322
Validation loss: 2.08222766717275

Epoch: 6| Step: 12
Training loss: 0.8108004331588745
Validation loss: 2.030592660109202

Epoch: 6| Step: 13
Training loss: 0.8121211528778076
Validation loss: 2.0695444544156394

Epoch: 179| Step: 0
Training loss: 0.8623735308647156
Validation loss: 2.091573158899943

Epoch: 6| Step: 1
Training loss: 0.5798366665840149
Validation loss: 2.003637969493866

Epoch: 6| Step: 2
Training loss: 1.2256262302398682
Validation loss: 2.024861137072245

Epoch: 6| Step: 3
Training loss: 1.023379921913147
Validation loss: 2.0415233771006265

Epoch: 6| Step: 4
Training loss: 0.8024184703826904
Validation loss: 2.065582791964213

Epoch: 6| Step: 5
Training loss: 1.338921070098877
Validation loss: 2.061932067076365

Epoch: 6| Step: 6
Training loss: 0.5536125898361206
Validation loss: 2.039277136325836

Epoch: 6| Step: 7
Training loss: 0.9798745512962341
Validation loss: 2.055650214354197

Epoch: 6| Step: 8
Training loss: 1.2502521276474
Validation loss: 2.0706340869267783

Epoch: 6| Step: 9
Training loss: 0.992246687412262
Validation loss: 2.035220185915629

Epoch: 6| Step: 10
Training loss: 0.9365113973617554
Validation loss: 2.0287245313326516

Epoch: 6| Step: 11
Training loss: 1.4718542098999023
Validation loss: 2.023941218852997

Epoch: 6| Step: 12
Training loss: 0.6122777462005615
Validation loss: 2.0240317583084106

Epoch: 6| Step: 13
Training loss: 0.6755188703536987
Validation loss: 2.0629840095837912

Epoch: 180| Step: 0
Training loss: 1.2011696100234985
Validation loss: 2.005380094051361

Epoch: 6| Step: 1
Training loss: 1.2599351406097412
Validation loss: 2.036259174346924

Epoch: 6| Step: 2
Training loss: 0.7175275087356567
Validation loss: 2.032587210337321

Epoch: 6| Step: 3
Training loss: 0.6110008358955383
Validation loss: 2.0728121598561606

Epoch: 6| Step: 4
Training loss: 1.039194941520691
Validation loss: 2.018265187740326

Epoch: 6| Step: 5
Training loss: 0.5057052373886108
Validation loss: 2.0489551027615867

Epoch: 6| Step: 6
Training loss: 0.7406120300292969
Validation loss: 2.0504313111305237

Epoch: 6| Step: 7
Training loss: 0.9726855158805847
Validation loss: 2.1463862458864846

Epoch: 6| Step: 8
Training loss: 0.8735386729240417
Validation loss: 2.1688170234362283

Epoch: 6| Step: 9
Training loss: 0.9383827447891235
Validation loss: 2.0545096596082053

Epoch: 6| Step: 10
Training loss: 1.2907606363296509
Validation loss: 2.026553531487783

Epoch: 6| Step: 11
Training loss: 1.0687354803085327
Validation loss: 2.0292537808418274

Epoch: 6| Step: 12
Training loss: 0.9697944521903992
Validation loss: 2.0063612858454385

Epoch: 6| Step: 13
Training loss: 1.1334911584854126
Validation loss: 2.0658350785573325

Epoch: 181| Step: 0
Training loss: 1.2600404024124146
Validation loss: 2.034115493297577

Epoch: 6| Step: 1
Training loss: 1.1126536130905151
Validation loss: 2.0476110776265464

Epoch: 6| Step: 2
Training loss: 1.3458783626556396
Validation loss: 1.9979474544525146

Epoch: 6| Step: 3
Training loss: 0.5018914341926575
Validation loss: 2.0116708278656006

Epoch: 6| Step: 4
Training loss: 0.5826623439788818
Validation loss: 2.047173579533895

Epoch: 6| Step: 5
Training loss: 0.7419582605361938
Validation loss: 2.044028878211975

Epoch: 6| Step: 6
Training loss: 0.7628123164176941
Validation loss: 2.067768653233846

Epoch: 6| Step: 7
Training loss: 0.7125555276870728
Validation loss: 2.104848086833954

Epoch: 6| Step: 8
Training loss: 0.7560266256332397
Validation loss: 2.1036028464635215

Epoch: 6| Step: 9
Training loss: 1.1200816631317139
Validation loss: 2.0092934171358743

Epoch: 6| Step: 10
Training loss: 1.0461418628692627
Validation loss: 2.0011116663614907

Epoch: 6| Step: 11
Training loss: 1.140525221824646
Validation loss: 2.044933279355367

Epoch: 6| Step: 12
Training loss: 0.6358269453048706
Validation loss: 2.09997965892156

Epoch: 6| Step: 13
Training loss: 1.0338499546051025
Validation loss: 2.0424175461133323

Epoch: 182| Step: 0
Training loss: 0.8154253959655762
Validation loss: 2.063392718633016

Epoch: 6| Step: 1
Training loss: 0.9506447315216064
Validation loss: 2.0022602677345276

Epoch: 6| Step: 2
Training loss: 0.9145560264587402
Validation loss: 2.024354894955953

Epoch: 6| Step: 3
Training loss: 0.7406591176986694
Validation loss: 2.0640048583348594

Epoch: 6| Step: 4
Training loss: 1.0364539623260498
Validation loss: 2.0438076059023538

Epoch: 6| Step: 5
Training loss: 1.0611658096313477
Validation loss: 2.056773841381073

Epoch: 6| Step: 6
Training loss: 1.2736872434616089
Validation loss: 2.0298808415730796

Epoch: 6| Step: 7
Training loss: 0.5128289461135864
Validation loss: 2.111564556757609

Epoch: 6| Step: 8
Training loss: 0.903266191482544
Validation loss: 2.0818288326263428

Epoch: 6| Step: 9
Training loss: 0.8709604740142822
Validation loss: 2.1055252949396768

Epoch: 6| Step: 10
Training loss: 1.0456689596176147
Validation loss: 2.135820766290029

Epoch: 6| Step: 11
Training loss: 1.0846447944641113
Validation loss: 2.0894025365511575

Epoch: 6| Step: 12
Training loss: 1.178053617477417
Validation loss: 2.0889617800712585

Epoch: 6| Step: 13
Training loss: 0.9464109539985657
Validation loss: 2.0435234904289246

Epoch: 183| Step: 0
Training loss: 0.7758449912071228
Validation loss: 2.0772025187810264

Epoch: 6| Step: 1
Training loss: 1.258084774017334
Validation loss: 2.081997891267141

Epoch: 6| Step: 2
Training loss: 0.9274232387542725
Validation loss: 2.037219484647115

Epoch: 6| Step: 3
Training loss: 0.8032554984092712
Validation loss: 1.9858397245407104

Epoch: 6| Step: 4
Training loss: 1.6302192211151123
Validation loss: 2.0569798946380615

Epoch: 6| Step: 5
Training loss: 0.7747384309768677
Validation loss: 2.0620745023091636

Epoch: 6| Step: 6
Training loss: 0.8226408958435059
Validation loss: 2.0365586479504905

Epoch: 6| Step: 7
Training loss: 0.9632296562194824
Validation loss: 2.1277196407318115

Epoch: 6| Step: 8
Training loss: 0.9902013540267944
Validation loss: 2.0926319360733032

Epoch: 6| Step: 9
Training loss: 0.7660760879516602
Validation loss: 2.0623921354611716

Epoch: 6| Step: 10
Training loss: 0.8020059466362
Validation loss: 2.049753566582998

Epoch: 6| Step: 11
Training loss: 1.2157013416290283
Validation loss: 2.0479023853937783

Epoch: 6| Step: 12
Training loss: 0.6230427622795105
Validation loss: 1.9859087665875752

Epoch: 6| Step: 13
Training loss: 0.7202444076538086
Validation loss: 2.084633708000183

Epoch: 184| Step: 0
Training loss: 0.9267431497573853
Validation loss: 2.0688753525416055

Epoch: 6| Step: 1
Training loss: 1.010515809059143
Validation loss: 2.049960454305013

Epoch: 6| Step: 2
Training loss: 0.6873879432678223
Validation loss: 2.0773937702178955

Epoch: 6| Step: 3
Training loss: 0.9775175452232361
Validation loss: 2.073880056540171

Epoch: 6| Step: 4
Training loss: 0.6336945295333862
Validation loss: 2.0743378400802612

Epoch: 6| Step: 5
Training loss: 0.5062011480331421
Validation loss: 2.0674463510513306

Epoch: 6| Step: 6
Training loss: 1.022939682006836
Validation loss: 2.1106364130973816

Epoch: 6| Step: 7
Training loss: 0.5271324515342712
Validation loss: 2.1187148491541543

Epoch: 6| Step: 8
Training loss: 1.0386857986450195
Validation loss: 2.0418214400609336

Epoch: 6| Step: 9
Training loss: 1.2382112741470337
Validation loss: 2.0706769625345864

Epoch: 6| Step: 10
Training loss: 0.8883754014968872
Validation loss: 2.0662638743718467

Epoch: 6| Step: 11
Training loss: 0.8740850687026978
Validation loss: 2.048099378744761

Epoch: 6| Step: 12
Training loss: 1.4825944900512695
Validation loss: 2.0983786384264627

Epoch: 6| Step: 13
Training loss: 0.8559212684631348
Validation loss: 2.0261728763580322

Epoch: 185| Step: 0
Training loss: 0.9704715013504028
Validation loss: 2.120083769162496

Epoch: 6| Step: 1
Training loss: 0.7011282444000244
Validation loss: 2.033740520477295

Epoch: 6| Step: 2
Training loss: 0.5204951763153076
Validation loss: 2.0008078813552856

Epoch: 6| Step: 3
Training loss: 0.7498496174812317
Validation loss: 2.0326914191246033

Epoch: 6| Step: 4
Training loss: 0.9627781510353088
Validation loss: 2.010033349196116

Epoch: 6| Step: 5
Training loss: 1.4845144748687744
Validation loss: 2.0803890228271484

Epoch: 6| Step: 6
Training loss: 0.9991629123687744
Validation loss: 2.115160048007965

Epoch: 6| Step: 7
Training loss: 1.264786958694458
Validation loss: 2.0286325414975486

Epoch: 6| Step: 8
Training loss: 0.7814947366714478
Validation loss: 1.9983602960904439

Epoch: 6| Step: 9
Training loss: 1.1576473712921143
Validation loss: 2.0174901485443115

Epoch: 6| Step: 10
Training loss: 0.9220235347747803
Validation loss: 2.0422730644543967

Epoch: 6| Step: 11
Training loss: 0.6868256330490112
Validation loss: 1.980319360891978

Epoch: 6| Step: 12
Training loss: 0.9266719818115234
Validation loss: 2.0387927095095315

Epoch: 6| Step: 13
Training loss: 0.6854692697525024
Validation loss: 2.0271008809407554

Epoch: 186| Step: 0
Training loss: 1.1485403776168823
Validation loss: 2.0920298099517822

Epoch: 6| Step: 1
Training loss: 0.8250113725662231
Validation loss: 2.041066567103068

Epoch: 6| Step: 2
Training loss: 1.002389907836914
Validation loss: 2.020703077316284

Epoch: 6| Step: 3
Training loss: 0.974577784538269
Validation loss: 2.050225853919983

Epoch: 6| Step: 4
Training loss: 0.702111542224884
Validation loss: 2.059250752131144

Epoch: 6| Step: 5
Training loss: 0.9415794014930725
Validation loss: 1.9985126455624898

Epoch: 6| Step: 6
Training loss: 0.950171709060669
Validation loss: 2.0868667364120483

Epoch: 6| Step: 7
Training loss: 1.3697441816329956
Validation loss: 1.971549888451894

Epoch: 6| Step: 8
Training loss: 0.8968418836593628
Validation loss: 2.059002180894216

Epoch: 6| Step: 9
Training loss: 0.8794076442718506
Validation loss: 2.0904422402381897

Epoch: 6| Step: 10
Training loss: 0.6864919662475586
Validation loss: 2.0268412431081138

Epoch: 6| Step: 11
Training loss: 0.9008709788322449
Validation loss: 2.088196039199829

Epoch: 6| Step: 12
Training loss: 0.614852249622345
Validation loss: 2.1087066332499185

Epoch: 6| Step: 13
Training loss: 0.9923185110092163
Validation loss: 2.0290271639823914

Epoch: 187| Step: 0
Training loss: 0.7615436315536499
Validation loss: 2.0751139322916665

Epoch: 6| Step: 1
Training loss: 0.6087560653686523
Validation loss: 2.0654118855794272

Epoch: 6| Step: 2
Training loss: 1.6300957202911377
Validation loss: 2.0720346768697104

Epoch: 6| Step: 3
Training loss: 0.5332052707672119
Validation loss: 2.044534961382548

Epoch: 6| Step: 4
Training loss: 1.0100094079971313
Validation loss: 1.9737994869550068

Epoch: 6| Step: 5
Training loss: 0.6069316864013672
Validation loss: 2.007349888483683

Epoch: 6| Step: 6
Training loss: 0.9953951239585876
Validation loss: 2.0295339226722717

Epoch: 6| Step: 7
Training loss: 0.666275680065155
Validation loss: 2.0994668205579123

Epoch: 6| Step: 8
Training loss: 0.9143937230110168
Validation loss: 2.038187265396118

Epoch: 6| Step: 9
Training loss: 0.4401213526725769
Validation loss: 2.0314184427261353

Epoch: 6| Step: 10
Training loss: 1.4511899948120117
Validation loss: 2.035412053267161

Epoch: 6| Step: 11
Training loss: 1.5057255029678345
Validation loss: 2.024305244286855

Epoch: 6| Step: 12
Training loss: 0.5287907719612122
Validation loss: 2.021927078564962

Epoch: 6| Step: 13
Training loss: 0.8957278728485107
Validation loss: 2.009482502937317

Epoch: 188| Step: 0
Training loss: 0.8726440072059631
Validation loss: 2.0066750049591064

Epoch: 6| Step: 1
Training loss: 1.0529558658599854
Validation loss: 2.099540094534556

Epoch: 6| Step: 2
Training loss: 0.758467435836792
Validation loss: 2.0009064078330994

Epoch: 6| Step: 3
Training loss: 0.7920902967453003
Validation loss: 2.0156259139378867

Epoch: 6| Step: 4
Training loss: 0.8028289079666138
Validation loss: 2.055599808692932

Epoch: 6| Step: 5
Training loss: 1.0166651010513306
Validation loss: 1.997402588526408

Epoch: 6| Step: 6
Training loss: 0.4746251404285431
Validation loss: 2.0355624159177146

Epoch: 6| Step: 7
Training loss: 1.3996890783309937
Validation loss: 2.0303789575894675

Epoch: 6| Step: 8
Training loss: 0.8052467107772827
Validation loss: 2.054529130458832

Epoch: 6| Step: 9
Training loss: 0.6294246912002563
Validation loss: 2.0075125296910605

Epoch: 6| Step: 10
Training loss: 0.9618332386016846
Validation loss: 2.0208914478619895

Epoch: 6| Step: 11
Training loss: 0.851044237613678
Validation loss: 1.9971747994422913

Epoch: 6| Step: 12
Training loss: 0.9648950099945068
Validation loss: 2.0531120697657266

Epoch: 6| Step: 13
Training loss: 0.8407701253890991
Validation loss: 2.1062339742978415

Epoch: 189| Step: 0
Training loss: 0.9415379762649536
Validation loss: 2.1056659817695618

Epoch: 6| Step: 1
Training loss: 1.3831617832183838
Validation loss: 2.024141709009806

Epoch: 6| Step: 2
Training loss: 0.8751522302627563
Validation loss: 2.0681156118710837

Epoch: 6| Step: 3
Training loss: 1.1640132665634155
Validation loss: 2.055826981862386

Epoch: 6| Step: 4
Training loss: 0.4272708296775818
Validation loss: 2.0373757084210715

Epoch: 6| Step: 5
Training loss: 0.8652628660202026
Validation loss: 2.056692143281301

Epoch: 6| Step: 6
Training loss: 0.8166894912719727
Validation loss: 2.07767516374588

Epoch: 6| Step: 7
Training loss: 0.8570899963378906
Validation loss: 2.0356955925623574

Epoch: 6| Step: 8
Training loss: 0.6846615076065063
Validation loss: 2.0395862460136414

Epoch: 6| Step: 9
Training loss: 1.1049631834030151
Validation loss: 2.031882385412852

Epoch: 6| Step: 10
Training loss: 0.6989864110946655
Validation loss: 2.0096416076024375

Epoch: 6| Step: 11
Training loss: 1.3084955215454102
Validation loss: 2.0575762192408242

Epoch: 6| Step: 12
Training loss: 0.8733288645744324
Validation loss: 2.0654696027437844

Epoch: 6| Step: 13
Training loss: 0.9251562356948853
Validation loss: 2.0108627478281655

Epoch: 190| Step: 0
Training loss: 1.3676295280456543
Validation loss: 2.139775196711222

Epoch: 6| Step: 1
Training loss: 0.9819989800453186
Validation loss: 2.0830087463061013

Epoch: 6| Step: 2
Training loss: 1.1213352680206299
Validation loss: 2.02417383591334

Epoch: 6| Step: 3
Training loss: 0.6971853971481323
Validation loss: 2.0504868626594543

Epoch: 6| Step: 4
Training loss: 0.7593468427658081
Validation loss: 2.0336772203445435

Epoch: 6| Step: 5
Training loss: 1.067996859550476
Validation loss: 2.063904285430908

Epoch: 6| Step: 6
Training loss: 1.3597017526626587
Validation loss: 2.0381067792574563

Epoch: 6| Step: 7
Training loss: 1.3069267272949219
Validation loss: 2.080587943394979

Epoch: 6| Step: 8
Training loss: 0.9536401033401489
Validation loss: 2.173807919025421

Epoch: 6| Step: 9
Training loss: 0.9544246792793274
Validation loss: 2.1016096274058023

Epoch: 6| Step: 10
Training loss: 0.9305031895637512
Validation loss: 2.0937638680140176

Epoch: 6| Step: 11
Training loss: 0.557047963142395
Validation loss: 2.0285602807998657

Epoch: 6| Step: 12
Training loss: 0.6717414855957031
Validation loss: 2.0247287352879844

Epoch: 6| Step: 13
Training loss: 0.6359331011772156
Validation loss: 2.088834504286448

Epoch: 191| Step: 0
Training loss: 0.6420762538909912
Validation loss: 1.9699360529581706

Epoch: 6| Step: 1
Training loss: 0.8246499300003052
Validation loss: 2.062666734059652

Epoch: 6| Step: 2
Training loss: 1.2209841012954712
Validation loss: 2.0004684925079346

Epoch: 6| Step: 3
Training loss: 0.7303721904754639
Validation loss: 2.026498774687449

Epoch: 6| Step: 4
Training loss: 1.0177860260009766
Validation loss: 2.0382109880447388

Epoch: 6| Step: 5
Training loss: 0.6762690544128418
Validation loss: 2.0129751563072205

Epoch: 6| Step: 6
Training loss: 0.9967087507247925
Validation loss: 2.018784840901693

Epoch: 6| Step: 7
Training loss: 1.2061400413513184
Validation loss: 2.0700308680534363

Epoch: 6| Step: 8
Training loss: 0.7336297035217285
Validation loss: 2.062474807103475

Epoch: 6| Step: 9
Training loss: 1.1964821815490723
Validation loss: 2.006567577521006

Epoch: 6| Step: 10
Training loss: 0.9316979646682739
Validation loss: 2.0408387382825217

Epoch: 6| Step: 11
Training loss: 1.115311622619629
Validation loss: 2.0644218921661377

Epoch: 6| Step: 12
Training loss: 0.6440282464027405
Validation loss: 2.0382836063702903

Epoch: 6| Step: 13
Training loss: 0.8029495477676392
Validation loss: 2.0619155963261924

Epoch: 192| Step: 0
Training loss: 0.633269190788269
Validation loss: 2.039088507493337

Epoch: 6| Step: 1
Training loss: 1.1365184783935547
Validation loss: 2.06096480290095

Epoch: 6| Step: 2
Training loss: 0.716134250164032
Validation loss: 2.063371181488037

Epoch: 6| Step: 3
Training loss: 0.8829151391983032
Validation loss: 1.9870410958925884

Epoch: 6| Step: 4
Training loss: 0.8156927227973938
Validation loss: 2.021116038163503

Epoch: 6| Step: 5
Training loss: 1.0875049829483032
Validation loss: 2.0007739067077637

Epoch: 6| Step: 6
Training loss: 0.9209859371185303
Validation loss: 2.054040849208832

Epoch: 6| Step: 7
Training loss: 0.5502011775970459
Validation loss: 2.0319584210713706

Epoch: 6| Step: 8
Training loss: 1.1880528926849365
Validation loss: 2.100879708925883

Epoch: 6| Step: 9
Training loss: 0.8175513744354248
Validation loss: 2.052687406539917

Epoch: 6| Step: 10
Training loss: 0.8135831952095032
Validation loss: 2.0611781676610312

Epoch: 6| Step: 11
Training loss: 1.4501533508300781
Validation loss: 2.110227187474569

Epoch: 6| Step: 12
Training loss: 0.6780628561973572
Validation loss: 2.0595222115516663

Epoch: 6| Step: 13
Training loss: 0.8866101503372192
Validation loss: 1.9881670673688252

Epoch: 193| Step: 0
Training loss: 0.6723546981811523
Validation loss: 2.095515708128611

Epoch: 6| Step: 1
Training loss: 0.7267409563064575
Validation loss: 2.092872122923533

Epoch: 6| Step: 2
Training loss: 0.7773400545120239
Validation loss: 2.030439337094625

Epoch: 6| Step: 3
Training loss: 0.7367119789123535
Validation loss: 2.006621460119883

Epoch: 6| Step: 4
Training loss: 0.7999711036682129
Validation loss: 2.010085860888163

Epoch: 6| Step: 5
Training loss: 0.7000551819801331
Validation loss: 2.025246282418569

Epoch: 6| Step: 6
Training loss: 1.3005441427230835
Validation loss: 1.9901891350746155

Epoch: 6| Step: 7
Training loss: 1.1751937866210938
Validation loss: 2.023445983727773

Epoch: 6| Step: 8
Training loss: 0.6848168969154358
Validation loss: 2.1014689207077026

Epoch: 6| Step: 9
Training loss: 0.7796002626419067
Validation loss: 2.0008593996365867

Epoch: 6| Step: 10
Training loss: 1.0323776006698608
Validation loss: 2.0704265038172402

Epoch: 6| Step: 11
Training loss: 0.8961414098739624
Validation loss: 2.0770154198010764

Epoch: 6| Step: 12
Training loss: 1.2003898620605469
Validation loss: 2.0508724451065063

Epoch: 6| Step: 13
Training loss: 1.031803846359253
Validation loss: 1.9951369563738506

Epoch: 194| Step: 0
Training loss: 1.209245204925537
Validation loss: 2.0744346976280212

Epoch: 6| Step: 1
Training loss: 0.7474418878555298
Validation loss: 2.0199634234110513

Epoch: 6| Step: 2
Training loss: 1.5690722465515137
Validation loss: 2.0753987431526184

Epoch: 6| Step: 3
Training loss: 0.3912152051925659
Validation loss: 2.01298056046168

Epoch: 6| Step: 4
Training loss: 0.7916803359985352
Validation loss: 2.01931369304657

Epoch: 6| Step: 5
Training loss: 0.6944271326065063
Validation loss: 2.006018658479055

Epoch: 6| Step: 6
Training loss: 0.950859785079956
Validation loss: 1.9890560507774353

Epoch: 6| Step: 7
Training loss: 0.8476256132125854
Validation loss: 2.001953740914663

Epoch: 6| Step: 8
Training loss: 1.2036757469177246
Validation loss: 2.1080657839775085

Epoch: 6| Step: 9
Training loss: 0.8202713131904602
Validation loss: 2.027762770652771

Epoch: 6| Step: 10
Training loss: 0.6399499177932739
Validation loss: 2.0255122582117715

Epoch: 6| Step: 11
Training loss: 0.544282853603363
Validation loss: 2.0078077713648477

Epoch: 6| Step: 12
Training loss: 0.8242843747138977
Validation loss: 1.9966084559758503

Epoch: 6| Step: 13
Training loss: 0.5607653856277466
Validation loss: 2.009120603402456

Epoch: 195| Step: 0
Training loss: 0.5873301029205322
Validation loss: 1.998977780342102

Epoch: 6| Step: 1
Training loss: 0.6417880058288574
Validation loss: 2.0285059809684753

Epoch: 6| Step: 2
Training loss: 0.6024857759475708
Validation loss: 1.9810468951861064

Epoch: 6| Step: 3
Training loss: 0.6564056873321533
Validation loss: 2.008741478125254

Epoch: 6| Step: 4
Training loss: 0.9535560011863708
Validation loss: 2.0842427015304565

Epoch: 6| Step: 5
Training loss: 0.7993044257164001
Validation loss: 2.012186805407206

Epoch: 6| Step: 6
Training loss: 0.7852057218551636
Validation loss: 2.064003884792328

Epoch: 6| Step: 7
Training loss: 1.5877853631973267
Validation loss: 2.007123072942098

Epoch: 6| Step: 8
Training loss: 0.5840533375740051
Validation loss: 2.000114917755127

Epoch: 6| Step: 9
Training loss: 0.5302746295928955
Validation loss: 1.9791490038235982

Epoch: 6| Step: 10
Training loss: 0.7739227414131165
Validation loss: 2.000873625278473

Epoch: 6| Step: 11
Training loss: 1.3154494762420654
Validation loss: 1.9982865452766418

Epoch: 6| Step: 12
Training loss: 1.377153992652893
Validation loss: 1.9679617881774902

Epoch: 6| Step: 13
Training loss: 0.7028613090515137
Validation loss: 2.070360024770101

Epoch: 196| Step: 0
Training loss: 0.6887917518615723
Validation loss: 2.0500554045041404

Epoch: 6| Step: 1
Training loss: 0.8533468246459961
Validation loss: 2.0137459437052407

Epoch: 6| Step: 2
Training loss: 0.6308832764625549
Validation loss: 1.9871617754300435

Epoch: 6| Step: 3
Training loss: 0.9816243648529053
Validation loss: 2.0377500851949057

Epoch: 6| Step: 4
Training loss: 1.2778010368347168
Validation loss: 2.0635417103767395

Epoch: 6| Step: 5
Training loss: 0.9503859281539917
Validation loss: 1.9999756614367168

Epoch: 6| Step: 6
Training loss: 0.6767596006393433
Validation loss: 2.099987546602885

Epoch: 6| Step: 7
Training loss: 0.8030112981796265
Validation loss: 2.026240090529124

Epoch: 6| Step: 8
Training loss: 0.805427610874176
Validation loss: 2.0493968725204468

Epoch: 6| Step: 9
Training loss: 1.4503037929534912
Validation loss: 2.0191158056259155

Epoch: 6| Step: 10
Training loss: 0.6465439796447754
Validation loss: 2.0667814215024314

Epoch: 6| Step: 11
Training loss: 0.9611810445785522
Validation loss: 2.0424068172772727

Epoch: 6| Step: 12
Training loss: 0.7549258470535278
Validation loss: 1.9933217962582905

Epoch: 6| Step: 13
Training loss: 0.6457216739654541
Validation loss: 1.9670539299647014

Epoch: 197| Step: 0
Training loss: 1.2462577819824219
Validation loss: 2.0877405802408853

Epoch: 6| Step: 1
Training loss: 0.5873801708221436
Validation loss: 2.0162458022435508

Epoch: 6| Step: 2
Training loss: 0.9034465551376343
Validation loss: 2.0508561531702676

Epoch: 6| Step: 3
Training loss: 1.3503026962280273
Validation loss: 2.0059910217920938

Epoch: 6| Step: 4
Training loss: 0.755434513092041
Validation loss: 2.0395814577738443

Epoch: 6| Step: 5
Training loss: 0.675979495048523
Validation loss: 2.037892242272695

Epoch: 6| Step: 6
Training loss: 0.4657427966594696
Validation loss: 2.024188816547394

Epoch: 6| Step: 7
Training loss: 0.787219762802124
Validation loss: 2.018935283025106

Epoch: 6| Step: 8
Training loss: 0.8411234021186829
Validation loss: 2.0409552653630576

Epoch: 6| Step: 9
Training loss: 0.47244346141815186
Validation loss: 2.0389700333277383

Epoch: 6| Step: 10
Training loss: 1.250624418258667
Validation loss: 2.029431382815043

Epoch: 6| Step: 11
Training loss: 0.7148211002349854
Validation loss: 2.009243289629618

Epoch: 6| Step: 12
Training loss: 0.6505500674247742
Validation loss: 2.0208539764086404

Epoch: 6| Step: 13
Training loss: 0.5366636514663696
Validation loss: 2.0820795694986978

Epoch: 198| Step: 0
Training loss: 0.7423720359802246
Validation loss: 2.053337514400482

Epoch: 6| Step: 1
Training loss: 1.0924146175384521
Validation loss: 2.0590684612592063

Epoch: 6| Step: 2
Training loss: 0.7010037899017334
Validation loss: 2.0362055699030557

Epoch: 6| Step: 3
Training loss: 1.1700708866119385
Validation loss: 1.997241735458374

Epoch: 6| Step: 4
Training loss: 0.9465662240982056
Validation loss: 2.0826789140701294

Epoch: 6| Step: 5
Training loss: 0.41693735122680664
Validation loss: 2.0122138261795044

Epoch: 6| Step: 6
Training loss: 0.4870395362377167
Validation loss: 2.064748446146647

Epoch: 6| Step: 7
Training loss: 0.7329025268554688
Validation loss: 2.0952909191449485

Epoch: 6| Step: 8
Training loss: 0.9488670825958252
Validation loss: 2.012483239173889

Epoch: 6| Step: 9
Training loss: 0.6504299640655518
Validation loss: 2.0676804979642234

Epoch: 6| Step: 10
Training loss: 0.8896507620811462
Validation loss: 2.045972228050232

Epoch: 6| Step: 11
Training loss: 0.7350795865058899
Validation loss: 1.9722533424695332

Epoch: 6| Step: 12
Training loss: 1.0595049858093262
Validation loss: 2.021902779738108

Epoch: 6| Step: 13
Training loss: 0.7883908152580261
Validation loss: 2.063489536444346

Epoch: 199| Step: 0
Training loss: 0.8088535666465759
Validation loss: 2.023822824160258

Epoch: 6| Step: 1
Training loss: 1.0045037269592285
Validation loss: 2.0077757040659585

Epoch: 6| Step: 2
Training loss: 0.892390251159668
Validation loss: 2.1032652854919434

Epoch: 6| Step: 3
Training loss: 0.5279942750930786
Validation loss: 2.0054021080334983

Epoch: 6| Step: 4
Training loss: 0.6457970142364502
Validation loss: 1.9794716835021973

Epoch: 6| Step: 5
Training loss: 0.801348090171814
Validation loss: 2.072805086771647

Epoch: 6| Step: 6
Training loss: 0.8797897696495056
Validation loss: 1.974927544593811

Epoch: 6| Step: 7
Training loss: 1.1644630432128906
Validation loss: 2.051718513170878

Epoch: 6| Step: 8
Training loss: 1.1705435514450073
Validation loss: 2.029917577902476

Epoch: 6| Step: 9
Training loss: 1.0296645164489746
Validation loss: 2.0514551599820456

Epoch: 6| Step: 10
Training loss: 0.6074108481407166
Validation loss: 2.077303727467855

Epoch: 6| Step: 11
Training loss: 0.8053598999977112
Validation loss: 2.0699609915415444

Epoch: 6| Step: 12
Training loss: 0.7550585865974426
Validation loss: 2.0439805587132773

Epoch: 6| Step: 13
Training loss: 0.6098114252090454
Validation loss: 2.0493451356887817

Epoch: 200| Step: 0
Training loss: 1.1803735494613647
Validation loss: 2.009219308694204

Epoch: 6| Step: 1
Training loss: 0.793821394443512
Validation loss: 2.024244785308838

Epoch: 6| Step: 2
Training loss: 0.5753401517868042
Validation loss: 2.004228432973226

Epoch: 6| Step: 3
Training loss: 1.1287662982940674
Validation loss: 2.011327842871348

Epoch: 6| Step: 4
Training loss: 0.5819942951202393
Validation loss: 2.0342629750569663

Epoch: 6| Step: 5
Training loss: 0.8205995559692383
Validation loss: 2.0378457506497702

Epoch: 6| Step: 6
Training loss: 0.6604768633842468
Validation loss: 2.022054155667623

Epoch: 6| Step: 7
Training loss: 0.7869360446929932
Validation loss: 2.0230772892634072

Epoch: 6| Step: 8
Training loss: 0.2099805474281311
Validation loss: 2.077626566092173

Epoch: 6| Step: 9
Training loss: 0.5200716853141785
Validation loss: 2.0198343793551126

Epoch: 6| Step: 10
Training loss: 1.2750751972198486
Validation loss: 2.0075884461402893

Epoch: 6| Step: 11
Training loss: 0.6459716558456421
Validation loss: 2.1094752152760825

Epoch: 6| Step: 12
Training loss: 0.8684432506561279
Validation loss: 2.067771792411804

Epoch: 6| Step: 13
Training loss: 1.1290183067321777
Validation loss: 2.0106743375460305

Epoch: 201| Step: 0
Training loss: 0.5723323822021484
Validation loss: 2.017778297265371

Epoch: 6| Step: 1
Training loss: 1.0929409265518188
Validation loss: 2.0793826977411904

Epoch: 6| Step: 2
Training loss: 1.321250081062317
Validation loss: 2.077393651008606

Epoch: 6| Step: 3
Training loss: 0.6338655948638916
Validation loss: 2.0265989700953164

Epoch: 6| Step: 4
Training loss: 0.5322270393371582
Validation loss: 2.056993544101715

Epoch: 6| Step: 5
Training loss: 0.5720574855804443
Validation loss: 2.0547125140825906

Epoch: 6| Step: 6
Training loss: 1.3344675302505493
Validation loss: 2.02440877755483

Epoch: 6| Step: 7
Training loss: 0.9373860359191895
Validation loss: 2.0360036293665567

Epoch: 6| Step: 8
Training loss: 0.6631227731704712
Validation loss: 2.0583781798680625

Epoch: 6| Step: 9
Training loss: 0.7505828142166138
Validation loss: 1.9794997771581013

Epoch: 6| Step: 10
Training loss: 0.4504822790622711
Validation loss: 2.0498467485109964

Epoch: 6| Step: 11
Training loss: 0.89272540807724
Validation loss: 2.0689164201418557

Epoch: 6| Step: 12
Training loss: 0.9951366186141968
Validation loss: 2.0332178870836892

Epoch: 6| Step: 13
Training loss: 0.5107901096343994
Validation loss: 2.078475594520569

Epoch: 202| Step: 0
Training loss: 1.1522588729858398
Validation loss: 2.070424179236094

Epoch: 6| Step: 1
Training loss: 0.6786223649978638
Validation loss: 2.0406360427538552

Epoch: 6| Step: 2
Training loss: 0.5233719944953918
Validation loss: 2.065389851729075

Epoch: 6| Step: 3
Training loss: 0.9304660558700562
Validation loss: 2.0023405154546103

Epoch: 6| Step: 4
Training loss: 0.5498043298721313
Validation loss: 2.043620467185974

Epoch: 6| Step: 5
Training loss: 0.96209716796875
Validation loss: 2.070177674293518

Epoch: 6| Step: 6
Training loss: 0.9225505590438843
Validation loss: 2.047476609547933

Epoch: 6| Step: 7
Training loss: 0.6944295167922974
Validation loss: 2.0932833154996238

Epoch: 6| Step: 8
Training loss: 0.5380713939666748
Validation loss: 2.1005398432413735

Epoch: 6| Step: 9
Training loss: 0.5023554563522339
Validation loss: 2.0358290672302246

Epoch: 6| Step: 10
Training loss: 0.9639861583709717
Validation loss: 2.065591891606649

Epoch: 6| Step: 11
Training loss: 1.0456949472427368
Validation loss: 2.1030784447987876

Epoch: 6| Step: 12
Training loss: 1.1557310819625854
Validation loss: 2.0949833591779075

Epoch: 6| Step: 13
Training loss: 0.513826847076416
Validation loss: 2.0194414059321084

Epoch: 203| Step: 0
Training loss: 0.50537109375
Validation loss: 2.1080440481503806

Epoch: 6| Step: 1
Training loss: 0.8479568958282471
Validation loss: 2.052128255367279

Epoch: 6| Step: 2
Training loss: 0.8310208916664124
Validation loss: 1.9982412060101826

Epoch: 6| Step: 3
Training loss: 0.9627031087875366
Validation loss: 2.0780574878056846

Epoch: 6| Step: 4
Training loss: 0.7862478494644165
Validation loss: 2.0777491331100464

Epoch: 6| Step: 5
Training loss: 0.7441365122795105
Validation loss: 2.0845108032226562

Epoch: 6| Step: 6
Training loss: 1.0563946962356567
Validation loss: 2.114151199658712

Epoch: 6| Step: 7
Training loss: 0.6613966226577759
Validation loss: 2.051283518473307

Epoch: 6| Step: 8
Training loss: 1.0526987314224243
Validation loss: 2.117653489112854

Epoch: 6| Step: 9
Training loss: 0.691366970539093
Validation loss: 2.013565023740133

Epoch: 6| Step: 10
Training loss: 1.1241835355758667
Validation loss: 2.0649207830429077

Epoch: 6| Step: 11
Training loss: 0.8161664605140686
Validation loss: 2.090866764386495

Epoch: 6| Step: 12
Training loss: 0.5466721653938293
Validation loss: 2.063881516456604

Epoch: 6| Step: 13
Training loss: 0.8329839706420898
Validation loss: 2.0916674931844077

Epoch: 204| Step: 0
Training loss: 0.6642014980316162
Validation loss: 2.0470487674077353

Epoch: 6| Step: 1
Training loss: 0.6075724959373474
Validation loss: 2.0526512265205383

Epoch: 6| Step: 2
Training loss: 0.44619667530059814
Validation loss: 2.0351144671440125

Epoch: 6| Step: 3
Training loss: 0.9894628524780273
Validation loss: 2.0884607235590615

Epoch: 6| Step: 4
Training loss: 1.1535286903381348
Validation loss: 2.1092642347017923

Epoch: 6| Step: 5
Training loss: 0.6839044094085693
Validation loss: 2.0917476812998452

Epoch: 6| Step: 6
Training loss: 1.2110005617141724
Validation loss: 2.0725587805112204

Epoch: 6| Step: 7
Training loss: 0.7311277389526367
Validation loss: 2.1256806453069053

Epoch: 6| Step: 8
Training loss: 1.0946688652038574
Validation loss: 2.1236296693483987

Epoch: 6| Step: 9
Training loss: 1.1733429431915283
Validation loss: 2.160974899927775

Epoch: 6| Step: 10
Training loss: 1.2547359466552734
Validation loss: 2.1927470763524375

Epoch: 6| Step: 11
Training loss: 1.1032283306121826
Validation loss: 2.0834744771321616

Epoch: 6| Step: 12
Training loss: 0.8385992050170898
Validation loss: 2.0972793896993003

Epoch: 6| Step: 13
Training loss: 0.6540001034736633
Validation loss: 2.043193439642588

Epoch: 205| Step: 0
Training loss: 0.9067253470420837
Validation loss: 2.049314538637797

Epoch: 6| Step: 1
Training loss: 0.4762426018714905
Validation loss: 2.072783589363098

Epoch: 6| Step: 2
Training loss: 0.6870867609977722
Validation loss: 2.0798821250597634

Epoch: 6| Step: 3
Training loss: 0.691219687461853
Validation loss: 2.105517784754435

Epoch: 6| Step: 4
Training loss: 1.1375503540039062
Validation loss: 2.0553200046221414

Epoch: 6| Step: 5
Training loss: 1.3350616693496704
Validation loss: 2.092983861764272

Epoch: 6| Step: 6
Training loss: 0.9037870764732361
Validation loss: 2.087563087542852

Epoch: 6| Step: 7
Training loss: 0.6261361837387085
Validation loss: 2.061360796292623

Epoch: 6| Step: 8
Training loss: 0.8642427921295166
Validation loss: 2.1091131567955017

Epoch: 6| Step: 9
Training loss: 1.2054033279418945
Validation loss: 2.0485933224360147

Epoch: 6| Step: 10
Training loss: 0.7364590764045715
Validation loss: 2.1325223048528037

Epoch: 6| Step: 11
Training loss: 0.8483474850654602
Validation loss: 2.107702990372976

Epoch: 6| Step: 12
Training loss: 0.4856485426425934
Validation loss: 2.0931918819745383

Epoch: 6| Step: 13
Training loss: 0.7499911785125732
Validation loss: 2.0386995871861777

Epoch: 206| Step: 0
Training loss: 0.5955986380577087
Validation loss: 2.07093354066213

Epoch: 6| Step: 1
Training loss: 1.074596881866455
Validation loss: 2.0686950087547302

Epoch: 6| Step: 2
Training loss: 0.94633549451828
Validation loss: 2.070559859275818

Epoch: 6| Step: 3
Training loss: 0.9375061392784119
Validation loss: 2.053990642229716

Epoch: 6| Step: 4
Training loss: 0.5585293769836426
Validation loss: 2.0114495754241943

Epoch: 6| Step: 5
Training loss: 0.43486684560775757
Validation loss: 2.09210334221522

Epoch: 6| Step: 6
Training loss: 1.176466703414917
Validation loss: 2.0360335310300193

Epoch: 6| Step: 7
Training loss: 0.5380412936210632
Validation loss: 2.0363131562868753

Epoch: 6| Step: 8
Training loss: 0.8530855178833008
Validation loss: 2.0324963331222534

Epoch: 6| Step: 9
Training loss: 1.0353562831878662
Validation loss: 2.1126599510510764

Epoch: 6| Step: 10
Training loss: 0.8386756181716919
Validation loss: 1.984987775484721

Epoch: 6| Step: 11
Training loss: 0.646944522857666
Validation loss: 2.0745020310084024

Epoch: 6| Step: 12
Training loss: 0.6229062080383301
Validation loss: 2.0365054408709207

Epoch: 6| Step: 13
Training loss: 0.7438451051712036
Validation loss: 2.095782538255056

Epoch: 207| Step: 0
Training loss: 1.1986360549926758
Validation loss: 2.1056336561838784

Epoch: 6| Step: 1
Training loss: 0.8032333254814148
Validation loss: 2.070146640141805

Epoch: 6| Step: 2
Training loss: 0.6896982789039612
Validation loss: 2.078264137109121

Epoch: 6| Step: 3
Training loss: 0.6792101860046387
Validation loss: 2.094150404135386

Epoch: 6| Step: 4
Training loss: 0.4782807528972626
Validation loss: 2.0007352431615195

Epoch: 6| Step: 5
Training loss: 1.3880407810211182
Validation loss: 2.0918879906336465

Epoch: 6| Step: 6
Training loss: 0.8258453607559204
Validation loss: 2.0542569756507874

Epoch: 6| Step: 7
Training loss: 0.8872935771942139
Validation loss: 2.116694966952006

Epoch: 6| Step: 8
Training loss: 0.5699105262756348
Validation loss: 2.0772663354873657

Epoch: 6| Step: 9
Training loss: 0.7962648868560791
Validation loss: 2.0943458676338196

Epoch: 6| Step: 10
Training loss: 0.8807342648506165
Validation loss: 1.9957852760950725

Epoch: 6| Step: 11
Training loss: 0.6389544010162354
Validation loss: 2.0750749508539834

Epoch: 6| Step: 12
Training loss: 0.511070728302002
Validation loss: 2.0660589138666787

Epoch: 6| Step: 13
Training loss: 0.6382492184638977
Validation loss: 2.008305609226227

Epoch: 208| Step: 0
Training loss: 0.7784909009933472
Validation loss: 2.1348776618639627

Epoch: 6| Step: 1
Training loss: 0.9501031637191772
Validation loss: 2.0108518600463867

Epoch: 6| Step: 2
Training loss: 0.6368780732154846
Validation loss: 2.0340946118036904

Epoch: 6| Step: 3
Training loss: 0.6409856081008911
Validation loss: 1.9927364985148113

Epoch: 6| Step: 4
Training loss: 1.045243740081787
Validation loss: 2.0718502203623452

Epoch: 6| Step: 5
Training loss: 0.6933631300926208
Validation loss: 2.0556065440177917

Epoch: 6| Step: 6
Training loss: 0.5917352437973022
Validation loss: 2.1215656201044717

Epoch: 6| Step: 7
Training loss: 0.9192441701889038
Validation loss: 2.0470632314682007

Epoch: 6| Step: 8
Training loss: 1.2660177946090698
Validation loss: 2.0423840085665383

Epoch: 6| Step: 9
Training loss: 0.9086688756942749
Validation loss: 1.9967382351557414

Epoch: 6| Step: 10
Training loss: 0.5232928395271301
Validation loss: 2.0306284030278525

Epoch: 6| Step: 11
Training loss: 0.35095834732055664
Validation loss: 2.0483506321907043

Epoch: 6| Step: 12
Training loss: 0.6286224126815796
Validation loss: 2.052852670351664

Epoch: 6| Step: 13
Training loss: 1.0338062047958374
Validation loss: 2.0086215337117515

Epoch: 209| Step: 0
Training loss: 0.6379787921905518
Validation loss: 2.046678284804026

Epoch: 6| Step: 1
Training loss: 0.5377830862998962
Validation loss: 2.0587444504102073

Epoch: 6| Step: 2
Training loss: 1.146177887916565
Validation loss: 1.9829336106777191

Epoch: 6| Step: 3
Training loss: 0.6011245250701904
Validation loss: 1.9522536993026733

Epoch: 6| Step: 4
Training loss: 1.1746609210968018
Validation loss: 1.9819045861562092

Epoch: 6| Step: 5
Training loss: 1.1874289512634277
Validation loss: 2.0357825756073

Epoch: 6| Step: 6
Training loss: 0.450801819562912
Validation loss: 2.0518810153007507

Epoch: 6| Step: 7
Training loss: 1.2134740352630615
Validation loss: 2.015976866086324

Epoch: 6| Step: 8
Training loss: 0.5472307801246643
Validation loss: 2.067050258318583

Epoch: 6| Step: 9
Training loss: 0.4530039131641388
Validation loss: 2.0054059425989785

Epoch: 6| Step: 10
Training loss: 1.1923418045043945
Validation loss: 2.049438238143921

Epoch: 6| Step: 11
Training loss: 0.7318650484085083
Validation loss: 2.001469870408376

Epoch: 6| Step: 12
Training loss: 0.3363189697265625
Validation loss: 2.0366612474123635

Epoch: 6| Step: 13
Training loss: 0.7751861810684204
Validation loss: 2.032141168912252

Epoch: 210| Step: 0
Training loss: 0.9594444036483765
Validation loss: 2.084104855855306

Epoch: 6| Step: 1
Training loss: 0.9439066648483276
Validation loss: 2.038309395313263

Epoch: 6| Step: 2
Training loss: 1.1269804239273071
Validation loss: 1.9907755851745605

Epoch: 6| Step: 3
Training loss: 0.9128350019454956
Validation loss: 2.046883304913839

Epoch: 6| Step: 4
Training loss: 0.7159767746925354
Validation loss: 2.0784425735473633

Epoch: 6| Step: 5
Training loss: 0.7541669011116028
Validation loss: 2.0362107952435813

Epoch: 6| Step: 6
Training loss: 0.7142993807792664
Validation loss: 2.0265012383461

Epoch: 6| Step: 7
Training loss: 0.3634287416934967
Validation loss: 2.0188756783803306

Epoch: 6| Step: 8
Training loss: 0.5795713663101196
Validation loss: 2.0914732615152993

Epoch: 6| Step: 9
Training loss: 0.6692870259284973
Validation loss: 2.020760973294576

Epoch: 6| Step: 10
Training loss: 0.7293404340744019
Validation loss: 2.0527037183443704

Epoch: 6| Step: 11
Training loss: 0.8109148740768433
Validation loss: 1.9708062211672466

Epoch: 6| Step: 12
Training loss: 1.0326917171478271
Validation loss: 1.9623854358990986

Epoch: 6| Step: 13
Training loss: 0.5962364673614502
Validation loss: 2.012491246064504

Epoch: 211| Step: 0
Training loss: 0.7777483463287354
Validation loss: 2.013618230819702

Epoch: 6| Step: 1
Training loss: 0.7753537893295288
Validation loss: 2.028956194718679

Epoch: 6| Step: 2
Training loss: 1.0598866939544678
Validation loss: 1.9998265107472737

Epoch: 6| Step: 3
Training loss: 0.7488598227500916
Validation loss: 2.0197649598121643

Epoch: 6| Step: 4
Training loss: 0.7081020474433899
Validation loss: 2.025991678237915

Epoch: 6| Step: 5
Training loss: 0.627238392829895
Validation loss: 2.0628828207651773

Epoch: 6| Step: 6
Training loss: 1.0771772861480713
Validation loss: 1.993210772673289

Epoch: 6| Step: 7
Training loss: 0.8515928387641907
Validation loss: 2.0035996635754905

Epoch: 6| Step: 8
Training loss: 0.8107937574386597
Validation loss: 2.054937481880188

Epoch: 6| Step: 9
Training loss: 0.7313169240951538
Validation loss: 1.9891869227091472

Epoch: 6| Step: 10
Training loss: 0.4030020833015442
Validation loss: 2.024166226387024

Epoch: 6| Step: 11
Training loss: 0.6866724491119385
Validation loss: 1.995261828104655

Epoch: 6| Step: 12
Training loss: 0.5765982866287231
Validation loss: 2.098788062731425

Epoch: 6| Step: 13
Training loss: 0.9895461797714233
Validation loss: 2.0591344436009726

Epoch: 212| Step: 0
Training loss: 1.048919916152954
Validation loss: 2.057608445485433

Epoch: 6| Step: 1
Training loss: 0.7700536847114563
Validation loss: 2.045299251874288

Epoch: 6| Step: 2
Training loss: 0.5563673377037048
Validation loss: 2.008603274822235

Epoch: 6| Step: 3
Training loss: 0.6579916477203369
Validation loss: 2.0642396211624146

Epoch: 6| Step: 4
Training loss: 0.45927929878234863
Validation loss: 2.05008735259374

Epoch: 6| Step: 5
Training loss: 0.7663884162902832
Validation loss: 2.009316325187683

Epoch: 6| Step: 6
Training loss: 0.8802496790885925
Validation loss: 2.0413397351900735

Epoch: 6| Step: 7
Training loss: 0.4460199475288391
Validation loss: 2.1079075733820596

Epoch: 6| Step: 8
Training loss: 1.3764015436172485
Validation loss: 2.040695587793986

Epoch: 6| Step: 9
Training loss: 0.8553927540779114
Validation loss: 2.047169586022695

Epoch: 6| Step: 10
Training loss: 0.8319541215896606
Validation loss: 2.0459916591644287

Epoch: 6| Step: 11
Training loss: 0.6847426891326904
Validation loss: 2.0616178711255393

Epoch: 6| Step: 12
Training loss: 0.5174976587295532
Validation loss: 2.0827521284421286

Epoch: 6| Step: 13
Training loss: 0.6085699200630188
Validation loss: 2.063598116238912

Epoch: 213| Step: 0
Training loss: 1.059667944908142
Validation loss: 2.0833791693051658

Epoch: 6| Step: 1
Training loss: 0.4970923364162445
Validation loss: 2.0588394602139792

Epoch: 6| Step: 2
Training loss: 0.9135342240333557
Validation loss: 2.0689613620440164

Epoch: 6| Step: 3
Training loss: 0.42614269256591797
Validation loss: 2.060968359311422

Epoch: 6| Step: 4
Training loss: 0.7056525349617004
Validation loss: 2.096238831679026

Epoch: 6| Step: 5
Training loss: 0.7598557472229004
Validation loss: 1.9912070433298747

Epoch: 6| Step: 6
Training loss: 0.6044156551361084
Validation loss: 2.0602816541989646

Epoch: 6| Step: 7
Training loss: 1.1457324028015137
Validation loss: 2.0577887892723083

Epoch: 6| Step: 8
Training loss: 0.43806809186935425
Validation loss: 2.0998467803001404

Epoch: 6| Step: 9
Training loss: 0.6461968421936035
Validation loss: 2.017387092113495

Epoch: 6| Step: 10
Training loss: 1.3709499835968018
Validation loss: 2.0377848148345947

Epoch: 6| Step: 11
Training loss: 0.7537693381309509
Validation loss: 2.0711427132288613

Epoch: 6| Step: 12
Training loss: 0.6512782573699951
Validation loss: 2.0652456879615784

Epoch: 6| Step: 13
Training loss: 0.6333527565002441
Validation loss: 2.068963646888733

Epoch: 214| Step: 0
Training loss: 0.7179721593856812
Validation loss: 2.0152347087860107

Epoch: 6| Step: 1
Training loss: 0.7068045735359192
Validation loss: 2.0333935817082724

Epoch: 6| Step: 2
Training loss: 0.5693359375
Validation loss: 2.0734922885894775

Epoch: 6| Step: 3
Training loss: 0.9488241076469421
Validation loss: 1.9940757155418396

Epoch: 6| Step: 4
Training loss: 0.8236780762672424
Validation loss: 2.0229066809018454

Epoch: 6| Step: 5
Training loss: 0.7211544513702393
Validation loss: 2.0961064100265503

Epoch: 6| Step: 6
Training loss: 0.8400554656982422
Validation loss: 2.0682034889856973

Epoch: 6| Step: 7
Training loss: 0.32878151535987854
Validation loss: 2.053972522417704

Epoch: 6| Step: 8
Training loss: 0.5583382248878479
Validation loss: 2.0563353300094604

Epoch: 6| Step: 9
Training loss: 0.5663474202156067
Validation loss: 2.0969973603884378

Epoch: 6| Step: 10
Training loss: 1.3140108585357666
Validation loss: 2.049416104952494

Epoch: 6| Step: 11
Training loss: 0.7414443492889404
Validation loss: 2.1044190923372903

Epoch: 6| Step: 12
Training loss: 0.8762052655220032
Validation loss: 2.103174865245819

Epoch: 6| Step: 13
Training loss: 0.6318736672401428
Validation loss: 2.159633378187815

Epoch: 215| Step: 0
Training loss: 0.9787792563438416
Validation loss: 2.0729450384775796

Epoch: 6| Step: 1
Training loss: 0.8398473262786865
Validation loss: 2.0833506981531777

Epoch: 6| Step: 2
Training loss: 0.5849114656448364
Validation loss: 2.103002587954203

Epoch: 6| Step: 3
Training loss: 1.305098295211792
Validation loss: 2.090653717517853

Epoch: 6| Step: 4
Training loss: 0.7284877300262451
Validation loss: 2.015299399693807

Epoch: 6| Step: 5
Training loss: 0.33471572399139404
Validation loss: 2.010602056980133

Epoch: 6| Step: 6
Training loss: 0.7616602182388306
Validation loss: 2.0137768387794495

Epoch: 6| Step: 7
Training loss: 0.7782866358757019
Validation loss: 2.074830114841461

Epoch: 6| Step: 8
Training loss: 0.5975111126899719
Validation loss: 2.033722480138143

Epoch: 6| Step: 9
Training loss: 0.6698839664459229
Validation loss: 2.039469043413798

Epoch: 6| Step: 10
Training loss: 0.834669828414917
Validation loss: 2.067064046859741

Epoch: 6| Step: 11
Training loss: 0.7785330414772034
Validation loss: 2.039223233858744

Epoch: 6| Step: 12
Training loss: 0.5522392392158508
Validation loss: 2.004998823006948

Epoch: 6| Step: 13
Training loss: 0.7096183896064758
Validation loss: 2.020638942718506

Epoch: 216| Step: 0
Training loss: 0.5458723902702332
Validation loss: 2.055367926756541

Epoch: 6| Step: 1
Training loss: 0.8590924739837646
Validation loss: 1.9886884093284607

Epoch: 6| Step: 2
Training loss: 0.5260492563247681
Validation loss: 2.0551960865656533

Epoch: 6| Step: 3
Training loss: 0.9265095591545105
Validation loss: 2.0184102058410645

Epoch: 6| Step: 4
Training loss: 1.031245470046997
Validation loss: 2.0377843578656516

Epoch: 6| Step: 5
Training loss: 0.6999654769897461
Validation loss: 2.043582499027252

Epoch: 6| Step: 6
Training loss: 0.6737268567085266
Validation loss: 2.0631285905838013

Epoch: 6| Step: 7
Training loss: 0.41452378034591675
Validation loss: 2.0255190332730613

Epoch: 6| Step: 8
Training loss: 0.9082944393157959
Validation loss: 2.0401808818181357

Epoch: 6| Step: 9
Training loss: 0.9471021890640259
Validation loss: 2.0036522150039673

Epoch: 6| Step: 10
Training loss: 0.6570939421653748
Validation loss: 2.0660001238187156

Epoch: 6| Step: 11
Training loss: 0.6666107177734375
Validation loss: 2.055003265539805

Epoch: 6| Step: 12
Training loss: 0.628740668296814
Validation loss: 2.052179296811422

Epoch: 6| Step: 13
Training loss: 0.42885857820510864
Validation loss: 2.045863687992096

Epoch: 217| Step: 0
Training loss: 0.45174872875213623
Validation loss: 2.0522438883781433

Epoch: 6| Step: 1
Training loss: 0.969028890132904
Validation loss: 2.032434821128845

Epoch: 6| Step: 2
Training loss: 0.4901666045188904
Validation loss: 2.096338450908661

Epoch: 6| Step: 3
Training loss: 0.659044623374939
Validation loss: 2.1003912885983786

Epoch: 6| Step: 4
Training loss: 0.9846433997154236
Validation loss: 2.0789067149162292

Epoch: 6| Step: 5
Training loss: 0.6894778609275818
Validation loss: 2.011252741018931

Epoch: 6| Step: 6
Training loss: 0.424699068069458
Validation loss: 2.002276619275411

Epoch: 6| Step: 7
Training loss: 0.8625166416168213
Validation loss: 2.029003659884135

Epoch: 6| Step: 8
Training loss: 0.20186978578567505
Validation loss: 2.0095179080963135

Epoch: 6| Step: 9
Training loss: 0.6222380995750427
Validation loss: 2.058672030766805

Epoch: 6| Step: 10
Training loss: 0.5014389157295227
Validation loss: 2.0248934626579285

Epoch: 6| Step: 11
Training loss: 0.9515049457550049
Validation loss: 2.0287839770317078

Epoch: 6| Step: 12
Training loss: 0.6189444065093994
Validation loss: 2.0329225858052573

Epoch: 6| Step: 13
Training loss: 1.4104903936386108
Validation loss: 2.079748292764028

Epoch: 218| Step: 0
Training loss: 0.8949478268623352
Validation loss: 2.0264282623926797

Epoch: 6| Step: 1
Training loss: 0.5074124336242676
Validation loss: 2.0251786510149636

Epoch: 6| Step: 2
Training loss: 0.9057893753051758
Validation loss: 2.0449323654174805

Epoch: 6| Step: 3
Training loss: 0.8057469129562378
Validation loss: 2.026665210723877

Epoch: 6| Step: 4
Training loss: 0.3588232398033142
Validation loss: 2.0430111487706504

Epoch: 6| Step: 5
Training loss: 0.7587460279464722
Validation loss: 2.019940892855326

Epoch: 6| Step: 6
Training loss: 0.7248104810714722
Validation loss: 2.1214035948117576

Epoch: 6| Step: 7
Training loss: 0.4903702139854431
Validation loss: 2.0654387871424356

Epoch: 6| Step: 8
Training loss: 0.49978089332580566
Validation loss: 2.0107081135114035

Epoch: 6| Step: 9
Training loss: 1.3540689945220947
Validation loss: 2.0376715858777366

Epoch: 6| Step: 10
Training loss: 0.624535083770752
Validation loss: 2.0087889432907104

Epoch: 6| Step: 11
Training loss: 0.606892466545105
Validation loss: 2.0439930160840354

Epoch: 6| Step: 12
Training loss: 0.9357764720916748
Validation loss: 2.0020371278127036

Epoch: 6| Step: 13
Training loss: 0.36275166273117065
Validation loss: 1.9902353088061016

Epoch: 219| Step: 0
Training loss: 0.553048849105835
Validation loss: 2.1077187061309814

Epoch: 6| Step: 1
Training loss: 0.7499852776527405
Validation loss: 2.0515414476394653

Epoch: 6| Step: 2
Training loss: 0.8672907948493958
Validation loss: 1.998652994632721

Epoch: 6| Step: 3
Training loss: 0.5149665474891663
Validation loss: 2.0353817343711853

Epoch: 6| Step: 4
Training loss: 0.7659339904785156
Validation loss: 2.0692198872566223

Epoch: 6| Step: 5
Training loss: 0.7778827548027039
Validation loss: 2.013911008834839

Epoch: 6| Step: 6
Training loss: 0.38929441571235657
Validation loss: 2.0127180020014444

Epoch: 6| Step: 7
Training loss: 0.8355416655540466
Validation loss: 2.0272674361864724

Epoch: 6| Step: 8
Training loss: 1.1187777519226074
Validation loss: 2.059480686982473

Epoch: 6| Step: 9
Training loss: 0.7452114820480347
Validation loss: 1.9854701956113179

Epoch: 6| Step: 10
Training loss: 0.5116453170776367
Validation loss: 2.0688007275263467

Epoch: 6| Step: 11
Training loss: 0.8484031558036804
Validation loss: 2.037723203500112

Epoch: 6| Step: 12
Training loss: 0.8972777128219604
Validation loss: 2.04630047082901

Epoch: 6| Step: 13
Training loss: 0.6142083406448364
Validation loss: 2.055160125096639

Epoch: 220| Step: 0
Training loss: 0.8673614859580994
Validation loss: 2.0468932588895163

Epoch: 6| Step: 1
Training loss: 0.8412696719169617
Validation loss: 2.0549447735150657

Epoch: 6| Step: 2
Training loss: 1.0134483575820923
Validation loss: 2.032740374406179

Epoch: 6| Step: 3
Training loss: 0.3989042043685913
Validation loss: 2.0622230172157288

Epoch: 6| Step: 4
Training loss: 0.8960336446762085
Validation loss: 2.025769531726837

Epoch: 6| Step: 5
Training loss: 0.9653701782226562
Validation loss: 2.068588654200236

Epoch: 6| Step: 6
Training loss: 1.0537171363830566
Validation loss: 2.091509699821472

Epoch: 6| Step: 7
Training loss: 0.534819483757019
Validation loss: 2.1174803177515664

Epoch: 6| Step: 8
Training loss: 0.5959595441818237
Validation loss: 2.0644084215164185

Epoch: 6| Step: 9
Training loss: 0.6652631759643555
Validation loss: 2.0493088364601135

Epoch: 6| Step: 10
Training loss: 0.36698901653289795
Validation loss: 2.101173182328542

Epoch: 6| Step: 11
Training loss: 0.48468437790870667
Validation loss: 2.0743497808774314

Epoch: 6| Step: 12
Training loss: 0.6121112108230591
Validation loss: 2.034157117207845

Epoch: 6| Step: 13
Training loss: 0.7042104005813599
Validation loss: 2.0566323002179465

Epoch: 221| Step: 0
Training loss: 0.5703526735305786
Validation loss: 2.084914247194926

Epoch: 6| Step: 1
Training loss: 0.6761712431907654
Validation loss: 2.0648103753725686

Epoch: 6| Step: 2
Training loss: 0.5971240401268005
Validation loss: 2.0945801734924316

Epoch: 6| Step: 3
Training loss: 0.9218431711196899
Validation loss: 2.1184682051340737

Epoch: 6| Step: 4
Training loss: 1.0012191534042358
Validation loss: 2.0636218388875327

Epoch: 6| Step: 5
Training loss: 0.34599268436431885
Validation loss: 2.0979093114535012

Epoch: 6| Step: 6
Training loss: 0.9874691963195801
Validation loss: 2.108774940172831

Epoch: 6| Step: 7
Training loss: 0.7276721596717834
Validation loss: 2.098919411500295

Epoch: 6| Step: 8
Training loss: 0.7412265539169312
Validation loss: 2.0709866086641946

Epoch: 6| Step: 9
Training loss: 0.3885940611362457
Validation loss: 2.052094062169393

Epoch: 6| Step: 10
Training loss: 0.8580230474472046
Validation loss: 2.0428547461827598

Epoch: 6| Step: 11
Training loss: 0.5665246844291687
Validation loss: 2.0392098228136697

Epoch: 6| Step: 12
Training loss: 0.6515981554985046
Validation loss: 1.9990052779515584

Epoch: 6| Step: 13
Training loss: 0.504085898399353
Validation loss: 2.0719916621843972

Epoch: 222| Step: 0
Training loss: 0.720894455909729
Validation loss: 2.010537644227346

Epoch: 6| Step: 1
Training loss: 0.592271625995636
Validation loss: 2.0130346417427063

Epoch: 6| Step: 2
Training loss: 0.7598145604133606
Validation loss: 2.0845622221628823

Epoch: 6| Step: 3
Training loss: 0.8700023889541626
Validation loss: 2.046728710333506

Epoch: 6| Step: 4
Training loss: 0.5722672939300537
Validation loss: 2.023412585258484

Epoch: 6| Step: 5
Training loss: 0.7270401120185852
Validation loss: 2.0078906416893005

Epoch: 6| Step: 6
Training loss: 0.9029381275177002
Validation loss: 2.0195216735204062

Epoch: 6| Step: 7
Training loss: 0.9073699712753296
Validation loss: 2.021419962247213

Epoch: 6| Step: 8
Training loss: 0.6777607798576355
Validation loss: 1.9878202676773071

Epoch: 6| Step: 9
Training loss: 0.6035680770874023
Validation loss: 1.9952319065729778

Epoch: 6| Step: 10
Training loss: 0.7292596101760864
Validation loss: 2.0163961251576743

Epoch: 6| Step: 11
Training loss: 0.5625180006027222
Validation loss: 2.0181068579355874

Epoch: 6| Step: 12
Training loss: 0.6087512373924255
Validation loss: 2.059636652469635

Epoch: 6| Step: 13
Training loss: 0.39414769411087036
Validation loss: 2.0406752030054727

Epoch: 223| Step: 0
Training loss: 0.36336252093315125
Validation loss: 2.085307856400808

Epoch: 6| Step: 1
Training loss: 0.45585960149765015
Validation loss: 2.1026257077852883

Epoch: 6| Step: 2
Training loss: 0.6040035486221313
Validation loss: 2.0450491110483804

Epoch: 6| Step: 3
Training loss: 0.5404950380325317
Validation loss: 2.0588685075441995

Epoch: 6| Step: 4
Training loss: 0.7600094079971313
Validation loss: 2.052100737889608

Epoch: 6| Step: 5
Training loss: 0.6743228435516357
Validation loss: 2.089937667051951

Epoch: 6| Step: 6
Training loss: 0.4332101047039032
Validation loss: 2.0272927482922873

Epoch: 6| Step: 7
Training loss: 0.7977665662765503
Validation loss: 2.034842848777771

Epoch: 6| Step: 8
Training loss: 1.2482759952545166
Validation loss: 2.038787623246511

Epoch: 6| Step: 9
Training loss: 0.4580441117286682
Validation loss: 2.0398120085398355

Epoch: 6| Step: 10
Training loss: 1.0062185525894165
Validation loss: 2.1147323648134866

Epoch: 6| Step: 11
Training loss: 0.6494569182395935
Validation loss: 2.031286875406901

Epoch: 6| Step: 12
Training loss: 1.021178960800171
Validation loss: 2.118898610273997

Epoch: 6| Step: 13
Training loss: 0.4998723864555359
Validation loss: 2.104260245958964

Epoch: 224| Step: 0
Training loss: 0.7061805725097656
Validation loss: 2.1343881289164224

Epoch: 6| Step: 1
Training loss: 0.7022393345832825
Validation loss: 2.152169088522593

Epoch: 6| Step: 2
Training loss: 0.654121994972229
Validation loss: 2.1052634716033936

Epoch: 6| Step: 3
Training loss: 1.2679612636566162
Validation loss: 2.045950929323832

Epoch: 6| Step: 4
Training loss: 0.37785768508911133
Validation loss: 2.072485307852427

Epoch: 6| Step: 5
Training loss: 0.651946485042572
Validation loss: 2.056726555029551

Epoch: 6| Step: 6
Training loss: 0.3769615888595581
Validation loss: 2.0247315963109336

Epoch: 6| Step: 7
Training loss: 0.8462263345718384
Validation loss: 2.103575110435486

Epoch: 6| Step: 8
Training loss: 0.9582365155220032
Validation loss: 2.063906669616699

Epoch: 6| Step: 9
Training loss: 0.8365392684936523
Validation loss: 2.043099045753479

Epoch: 6| Step: 10
Training loss: 0.5199403166770935
Validation loss: 2.071042080720266

Epoch: 6| Step: 11
Training loss: 0.7872487902641296
Validation loss: 2.121641437212626

Epoch: 6| Step: 12
Training loss: 0.3963176906108856
Validation loss: 2.0494179924329123

Epoch: 6| Step: 13
Training loss: 0.9148444533348083
Validation loss: 2.076461215813955

Epoch: 225| Step: 0
Training loss: 0.5406935811042786
Validation loss: 2.0508611599604287

Epoch: 6| Step: 1
Training loss: 0.5063104629516602
Validation loss: 2.0569571256637573

Epoch: 6| Step: 2
Training loss: 0.5114295482635498
Validation loss: 2.043127179145813

Epoch: 6| Step: 3
Training loss: 0.4950949251651764
Validation loss: 2.073872526486715

Epoch: 6| Step: 4
Training loss: 0.8928313255310059
Validation loss: 2.014989495277405

Epoch: 6| Step: 5
Training loss: 0.48656970262527466
Validation loss: 1.9806101322174072

Epoch: 6| Step: 6
Training loss: 0.7453886270523071
Validation loss: 2.006416161855062

Epoch: 6| Step: 7
Training loss: 1.057124376296997
Validation loss: 2.103945255279541

Epoch: 6| Step: 8
Training loss: 0.7563138008117676
Validation loss: 2.002973655859629

Epoch: 6| Step: 9
Training loss: 0.5418170690536499
Validation loss: 2.050727645556132

Epoch: 6| Step: 10
Training loss: 0.7029774785041809
Validation loss: 2.089034120241801

Epoch: 6| Step: 11
Training loss: 0.763422966003418
Validation loss: 2.0799763202667236

Epoch: 6| Step: 12
Training loss: 0.7741038799285889
Validation loss: 2.0308340191841125

Epoch: 6| Step: 13
Training loss: 0.38174206018447876
Validation loss: 2.009808917840322

Epoch: 226| Step: 0
Training loss: 0.658720076084137
Validation loss: 2.0327343543370566

Epoch: 6| Step: 1
Training loss: 0.625073254108429
Validation loss: 2.0446296532948813

Epoch: 6| Step: 2
Training loss: 0.51434326171875
Validation loss: 1.9948147734006245

Epoch: 6| Step: 3
Training loss: 0.6123105883598328
Validation loss: 2.0253969033559165

Epoch: 6| Step: 4
Training loss: 0.34263119101524353
Validation loss: 2.0952922900517783

Epoch: 6| Step: 5
Training loss: 0.45082172751426697
Validation loss: 2.0398506124814353

Epoch: 6| Step: 6
Training loss: 0.6784864068031311
Validation loss: 2.07616259654363

Epoch: 6| Step: 7
Training loss: 0.7746636271476746
Validation loss: 2.112072169780731

Epoch: 6| Step: 8
Training loss: 0.6210936307907104
Validation loss: 2.08997635046641

Epoch: 6| Step: 9
Training loss: 0.7031067609786987
Validation loss: 2.0571799675623574

Epoch: 6| Step: 10
Training loss: 0.9737334847450256
Validation loss: 2.0746548771858215

Epoch: 6| Step: 11
Training loss: 0.7433539628982544
Validation loss: 2.0843399365743003

Epoch: 6| Step: 12
Training loss: 0.5261579155921936
Validation loss: 2.1228278080622354

Epoch: 6| Step: 13
Training loss: 1.2805019617080688
Validation loss: 2.0430097579956055

Epoch: 227| Step: 0
Training loss: 0.8530788421630859
Validation loss: 2.036623020966848

Epoch: 6| Step: 1
Training loss: 0.5670040845870972
Validation loss: 2.051999827226003

Epoch: 6| Step: 2
Training loss: 0.5439980030059814
Validation loss: 2.046765089035034

Epoch: 6| Step: 3
Training loss: 0.5398797988891602
Validation loss: 2.0684204697608948

Epoch: 6| Step: 4
Training loss: 0.7322564125061035
Validation loss: 2.0696826378504434

Epoch: 6| Step: 5
Training loss: 0.8903771042823792
Validation loss: 2.05593732992808

Epoch: 6| Step: 6
Training loss: 0.41525304317474365
Validation loss: 2.1037698785463967

Epoch: 6| Step: 7
Training loss: 0.98017418384552
Validation loss: 2.0677135785420737

Epoch: 6| Step: 8
Training loss: 0.6701791882514954
Validation loss: 2.0634761651357016

Epoch: 6| Step: 9
Training loss: 0.607683002948761
Validation loss: 2.1021984616915383

Epoch: 6| Step: 10
Training loss: 0.8528477549552917
Validation loss: 2.023777743180593

Epoch: 6| Step: 11
Training loss: 0.9395542740821838
Validation loss: 2.003046194712321

Epoch: 6| Step: 12
Training loss: 0.3196313977241516
Validation loss: 2.0390914479891458

Epoch: 6| Step: 13
Training loss: 0.4920743703842163
Validation loss: 2.012088894844055

Epoch: 228| Step: 0
Training loss: 0.954835832118988
Validation loss: 2.0900184512138367

Epoch: 6| Step: 1
Training loss: 0.6552039384841919
Validation loss: 2.0489750305811563

Epoch: 6| Step: 2
Training loss: 0.5633891224861145
Validation loss: 2.0397395690282187

Epoch: 6| Step: 3
Training loss: 0.6521943211555481
Validation loss: 2.041698455810547

Epoch: 6| Step: 4
Training loss: 0.482623815536499
Validation loss: 2.08479380607605

Epoch: 6| Step: 5
Training loss: 0.8030068278312683
Validation loss: 2.0418879191080728

Epoch: 6| Step: 6
Training loss: 0.3919752240180969
Validation loss: 2.056613862514496

Epoch: 6| Step: 7
Training loss: 0.42401421070098877
Validation loss: 2.068708817164103

Epoch: 6| Step: 8
Training loss: 0.3942864239215851
Validation loss: 2.084498643875122

Epoch: 6| Step: 9
Training loss: 0.9228332042694092
Validation loss: 2.096291740735372

Epoch: 6| Step: 10
Training loss: 0.8210117816925049
Validation loss: 2.0489212473233542

Epoch: 6| Step: 11
Training loss: 1.4016263484954834
Validation loss: 2.0709932247797647

Epoch: 6| Step: 12
Training loss: 0.47727060317993164
Validation loss: 2.0651094714800515

Epoch: 6| Step: 13
Training loss: 0.7299492359161377
Validation loss: 2.0780415336290994

Epoch: 229| Step: 0
Training loss: 0.3144288957118988
Validation loss: 2.0411607225735984

Epoch: 6| Step: 1
Training loss: 0.8103858232498169
Validation loss: 2.089113732179006

Epoch: 6| Step: 2
Training loss: 0.9596788883209229
Validation loss: 2.050446112950643

Epoch: 6| Step: 3
Training loss: 0.782305896282196
Validation loss: 2.0499334732691445

Epoch: 6| Step: 4
Training loss: 0.6259376406669617
Validation loss: 2.1066123843193054

Epoch: 6| Step: 5
Training loss: 0.6419870853424072
Validation loss: 2.0723720590273538

Epoch: 6| Step: 6
Training loss: 0.8169299364089966
Validation loss: 2.0693233609199524

Epoch: 6| Step: 7
Training loss: 0.6130194664001465
Validation loss: 2.0906982421875

Epoch: 6| Step: 8
Training loss: 0.8498594760894775
Validation loss: 2.066238363583883

Epoch: 6| Step: 9
Training loss: 0.5197936296463013
Validation loss: 2.0372299949328103

Epoch: 6| Step: 10
Training loss: 0.2821536958217621
Validation loss: 2.0660711924235025

Epoch: 6| Step: 11
Training loss: 0.42015182971954346
Validation loss: 2.1281783183415732

Epoch: 6| Step: 12
Training loss: 0.9426361322402954
Validation loss: 2.0695679585138955

Epoch: 6| Step: 13
Training loss: 0.7862133383750916
Validation loss: 2.1010877887407937

Epoch: 230| Step: 0
Training loss: 0.7701563835144043
Validation loss: 2.060462991396586

Epoch: 6| Step: 1
Training loss: 0.3305498957633972
Validation loss: 2.0272273222605386

Epoch: 6| Step: 2
Training loss: 0.5389658808708191
Validation loss: 2.0450163880983987

Epoch: 6| Step: 3
Training loss: 0.8406823873519897
Validation loss: 2.0626824696858725

Epoch: 6| Step: 4
Training loss: 0.8074417114257812
Validation loss: 2.01123700539271

Epoch: 6| Step: 5
Training loss: 1.367266297340393
Validation loss: 2.1269028981526694

Epoch: 6| Step: 6
Training loss: 0.5551494359970093
Validation loss: 2.1188291907310486

Epoch: 6| Step: 7
Training loss: 0.4905009865760803
Validation loss: 2.1151719093322754

Epoch: 6| Step: 8
Training loss: 0.6602880358695984
Validation loss: 2.110492010911306

Epoch: 6| Step: 9
Training loss: 0.5766337513923645
Validation loss: 2.0604740579922995

Epoch: 6| Step: 10
Training loss: 0.5611792206764221
Validation loss: 2.0773872335751853

Epoch: 6| Step: 11
Training loss: 0.78278648853302
Validation loss: 2.063238342603048

Epoch: 6| Step: 12
Training loss: 0.8853315711021423
Validation loss: 2.0380462408065796

Epoch: 6| Step: 13
Training loss: 0.5327122807502747
Validation loss: 2.078529159228007

Epoch: 231| Step: 0
Training loss: 0.51680588722229
Validation loss: 2.049191931883494

Epoch: 6| Step: 1
Training loss: 0.9897013306617737
Validation loss: 2.0437216560045877

Epoch: 6| Step: 2
Training loss: 0.6288105249404907
Validation loss: 2.0522901813189187

Epoch: 6| Step: 3
Training loss: 0.5942299962043762
Validation loss: 2.0376731554667153

Epoch: 6| Step: 4
Training loss: 0.9459560513496399
Validation loss: 2.029521564642588

Epoch: 6| Step: 5
Training loss: 0.8982248306274414
Validation loss: 2.111011524995168

Epoch: 6| Step: 6
Training loss: 0.44402599334716797
Validation loss: 2.045871138572693

Epoch: 6| Step: 7
Training loss: 0.328357070684433
Validation loss: 2.0682366490364075

Epoch: 6| Step: 8
Training loss: 0.5700094699859619
Validation loss: 2.0206714471181235

Epoch: 6| Step: 9
Training loss: 0.5113222002983093
Validation loss: 2.070624748865763

Epoch: 6| Step: 10
Training loss: 0.6737680435180664
Validation loss: 2.0447251200675964

Epoch: 6| Step: 11
Training loss: 1.3690067529678345
Validation loss: 2.039581855138143

Epoch: 6| Step: 12
Training loss: 0.42783957719802856
Validation loss: 2.010925034681956

Epoch: 6| Step: 13
Training loss: 0.4029119908809662
Validation loss: 2.0262500047683716

Epoch: 232| Step: 0
Training loss: 0.7999389171600342
Validation loss: 2.0298271775245667

Epoch: 6| Step: 1
Training loss: 0.8324916362762451
Validation loss: 2.0409074425697327

Epoch: 6| Step: 2
Training loss: 0.7307130098342896
Validation loss: 2.062031904856364

Epoch: 6| Step: 3
Training loss: 0.6391848921775818
Validation loss: 2.090932091077169

Epoch: 6| Step: 4
Training loss: 0.6555185914039612
Validation loss: 2.069960117340088

Epoch: 6| Step: 5
Training loss: 0.49568530917167664
Validation loss: 2.0347365538279214

Epoch: 6| Step: 6
Training loss: 0.7156120538711548
Validation loss: 2.1039219299952188

Epoch: 6| Step: 7
Training loss: 1.0039645433425903
Validation loss: 2.059962014357249

Epoch: 6| Step: 8
Training loss: 0.536882758140564
Validation loss: 2.066997547944387

Epoch: 6| Step: 9
Training loss: 0.9053689241409302
Validation loss: 2.028986871242523

Epoch: 6| Step: 10
Training loss: 0.6993643045425415
Validation loss: 2.0184486905733743

Epoch: 6| Step: 11
Training loss: 0.4038147032260895
Validation loss: 2.0132245222727456

Epoch: 6| Step: 12
Training loss: 0.5414117574691772
Validation loss: 2.04827352364858

Epoch: 6| Step: 13
Training loss: 0.9627574682235718
Validation loss: 2.040176749229431

Epoch: 233| Step: 0
Training loss: 0.7399773001670837
Validation loss: 2.1014065543810525

Epoch: 6| Step: 1
Training loss: 0.5956348776817322
Validation loss: 2.084404190381368

Epoch: 6| Step: 2
Training loss: 0.917253851890564
Validation loss: 2.0352713664372764

Epoch: 6| Step: 3
Training loss: 0.5366654396057129
Validation loss: 2.049048145612081

Epoch: 6| Step: 4
Training loss: 0.5504953861236572
Validation loss: 2.0808735688527427

Epoch: 6| Step: 5
Training loss: 0.6601748466491699
Validation loss: 2.1508735815684

Epoch: 6| Step: 6
Training loss: 0.7447130680084229
Validation loss: 2.0438686410586038

Epoch: 6| Step: 7
Training loss: 0.6958784461021423
Validation loss: 2.056499103705088

Epoch: 6| Step: 8
Training loss: 0.7640581130981445
Validation loss: 2.0716712276140847

Epoch: 6| Step: 9
Training loss: 0.5245624780654907
Validation loss: 2.0792922973632812

Epoch: 6| Step: 10
Training loss: 0.4457886219024658
Validation loss: 2.0628846685091653

Epoch: 6| Step: 11
Training loss: 0.4894445240497589
Validation loss: 2.063146948814392

Epoch: 6| Step: 12
Training loss: 1.027437448501587
Validation loss: 2.0731669664382935

Epoch: 6| Step: 13
Training loss: 1.0396902561187744
Validation loss: 2.1385497649510703

Epoch: 234| Step: 0
Training loss: 0.6770731210708618
Validation loss: 2.0969117085138955

Epoch: 6| Step: 1
Training loss: 0.8157885670661926
Validation loss: 2.0995258490244546

Epoch: 6| Step: 2
Training loss: 0.6466599702835083
Validation loss: 2.0991999904314675

Epoch: 6| Step: 3
Training loss: 0.4381440281867981
Validation loss: 2.075396478176117

Epoch: 6| Step: 4
Training loss: 0.5515382289886475
Validation loss: 2.0616820255915322

Epoch: 6| Step: 5
Training loss: 0.46155285835266113
Validation loss: 2.077014068762461

Epoch: 6| Step: 6
Training loss: 1.5128318071365356
Validation loss: 2.0895702838897705

Epoch: 6| Step: 7
Training loss: 0.792442798614502
Validation loss: 2.0128660202026367

Epoch: 6| Step: 8
Training loss: 0.5438756942749023
Validation loss: 2.0348007678985596

Epoch: 6| Step: 9
Training loss: 0.5666707754135132
Validation loss: 2.0785412589708963

Epoch: 6| Step: 10
Training loss: 0.5260640382766724
Validation loss: 2.0833692153294883

Epoch: 6| Step: 11
Training loss: 0.7046711444854736
Validation loss: 2.1067294677098594

Epoch: 6| Step: 12
Training loss: 0.40720123052597046
Validation loss: 1.9923529426256816

Epoch: 6| Step: 13
Training loss: 0.7556408643722534
Validation loss: 2.109653890132904

Epoch: 235| Step: 0
Training loss: 0.6969308853149414
Validation loss: 2.102456748485565

Epoch: 6| Step: 1
Training loss: 0.6567034721374512
Validation loss: 2.083024740219116

Epoch: 6| Step: 2
Training loss: 0.8026251792907715
Validation loss: 2.096349855264028

Epoch: 6| Step: 3
Training loss: 0.34331297874450684
Validation loss: 2.0794924100240073

Epoch: 6| Step: 4
Training loss: 0.5718974471092224
Validation loss: 2.0609840949376426

Epoch: 6| Step: 5
Training loss: 0.4764542579650879
Validation loss: 2.0319166779518127

Epoch: 6| Step: 6
Training loss: 0.9387993812561035
Validation loss: 1.996380607287089

Epoch: 6| Step: 7
Training loss: 0.8210552334785461
Validation loss: 2.053927779197693

Epoch: 6| Step: 8
Training loss: 0.7855947017669678
Validation loss: 2.0350410540898642

Epoch: 6| Step: 9
Training loss: 0.3359040319919586
Validation loss: 2.056851029396057

Epoch: 6| Step: 10
Training loss: 0.42842942476272583
Validation loss: 2.0485387245814004

Epoch: 6| Step: 11
Training loss: 0.7160506844520569
Validation loss: 2.0845882296562195

Epoch: 6| Step: 12
Training loss: 0.9211494326591492
Validation loss: 2.1178537209828696

Epoch: 6| Step: 13
Training loss: 0.48753097653388977
Validation loss: 2.0808401107788086

Epoch: 236| Step: 0
Training loss: 0.7664079666137695
Validation loss: 2.1316663026809692

Epoch: 6| Step: 1
Training loss: 0.7897883653640747
Validation loss: 2.1750622391700745

Epoch: 6| Step: 2
Training loss: 0.6264622211456299
Validation loss: 2.044713020324707

Epoch: 6| Step: 3
Training loss: 0.3374301791191101
Validation loss: 2.1226921478907266

Epoch: 6| Step: 4
Training loss: 0.4980809688568115
Validation loss: 2.0602418979008994

Epoch: 6| Step: 5
Training loss: 0.646788477897644
Validation loss: 2.059187392393748

Epoch: 6| Step: 6
Training loss: 0.6228957176208496
Validation loss: 2.0410212874412537

Epoch: 6| Step: 7
Training loss: 0.873540461063385
Validation loss: 2.0584809382756553

Epoch: 6| Step: 8
Training loss: 0.8358777165412903
Validation loss: 2.0812944173812866

Epoch: 6| Step: 9
Training loss: 1.1061122417449951
Validation loss: 2.004786252975464

Epoch: 6| Step: 10
Training loss: 0.3587116301059723
Validation loss: 2.0227301120758057

Epoch: 6| Step: 11
Training loss: 0.6835519075393677
Validation loss: 2.0631853143374124

Epoch: 6| Step: 12
Training loss: 0.7732465267181396
Validation loss: 2.06415061155955

Epoch: 6| Step: 13
Training loss: 0.4539799690246582
Validation loss: 2.1309135357538858

Epoch: 237| Step: 0
Training loss: 0.5858519673347473
Validation loss: 2.09713081518809

Epoch: 6| Step: 1
Training loss: 0.8283275365829468
Validation loss: 2.093663493792216

Epoch: 6| Step: 2
Training loss: 0.6468386650085449
Validation loss: 2.114947517712911

Epoch: 6| Step: 3
Training loss: 0.4483240842819214
Validation loss: 2.1529878775278726

Epoch: 6| Step: 4
Training loss: 1.2146615982055664
Validation loss: 2.140696903069814

Epoch: 6| Step: 5
Training loss: 0.4577712118625641
Validation loss: 2.142560362815857

Epoch: 6| Step: 6
Training loss: 0.7734886407852173
Validation loss: 2.0602824489275613

Epoch: 6| Step: 7
Training loss: 0.49749478697776794
Validation loss: 2.081855138142904

Epoch: 6| Step: 8
Training loss: 0.630840539932251
Validation loss: 2.0857375860214233

Epoch: 6| Step: 9
Training loss: 0.4789618253707886
Validation loss: 2.043575644493103

Epoch: 6| Step: 10
Training loss: 0.5719605684280396
Validation loss: 2.143891533215841

Epoch: 6| Step: 11
Training loss: 0.509665846824646
Validation loss: 2.134960889816284

Epoch: 6| Step: 12
Training loss: 0.5633946061134338
Validation loss: 2.1034427483876548

Epoch: 6| Step: 13
Training loss: 0.930010199546814
Validation loss: 2.143756409486135

Epoch: 238| Step: 0
Training loss: 0.4642474055290222
Validation loss: 2.091847817103068

Epoch: 6| Step: 1
Training loss: 0.8697068095207214
Validation loss: 2.0189960400263467

Epoch: 6| Step: 2
Training loss: 0.976030707359314
Validation loss: 2.0194833477338157

Epoch: 6| Step: 3
Training loss: 1.05683171749115
Validation loss: 2.091885487238566

Epoch: 6| Step: 4
Training loss: 0.6609634160995483
Validation loss: 2.097567697366079

Epoch: 6| Step: 5
Training loss: 0.5899209380149841
Validation loss: 2.1136733492215476

Epoch: 6| Step: 6
Training loss: 0.5301904678344727
Validation loss: 2.0587668220202127

Epoch: 6| Step: 7
Training loss: 0.5789476633071899
Validation loss: 2.0338520606358848

Epoch: 6| Step: 8
Training loss: 0.49282485246658325
Validation loss: 2.0593590339024863

Epoch: 6| Step: 9
Training loss: 0.396481990814209
Validation loss: 2.037684698899587

Epoch: 6| Step: 10
Training loss: 0.7437925934791565
Validation loss: 2.033095439275106

Epoch: 6| Step: 11
Training loss: 0.7843450903892517
Validation loss: 2.116447687149048

Epoch: 6| Step: 12
Training loss: 0.6159387826919556
Validation loss: 2.0641492009162903

Epoch: 6| Step: 13
Training loss: 0.7659623026847839
Validation loss: 2.0910507440567017

Epoch: 239| Step: 0
Training loss: 0.7902770638465881
Validation loss: 2.0898428360621133

Epoch: 6| Step: 1
Training loss: 1.2821903228759766
Validation loss: 2.0932586789131165

Epoch: 6| Step: 2
Training loss: 0.2960819602012634
Validation loss: 2.066131273905436

Epoch: 6| Step: 3
Training loss: 0.6449377536773682
Validation loss: 2.136053681373596

Epoch: 6| Step: 4
Training loss: 0.6079256534576416
Validation loss: 2.107430656750997

Epoch: 6| Step: 5
Training loss: 0.6304634809494019
Validation loss: 2.0589540004730225

Epoch: 6| Step: 6
Training loss: 0.5678099393844604
Validation loss: 2.0508580406506858

Epoch: 6| Step: 7
Training loss: 0.6018993854522705
Validation loss: 2.1180222630500793

Epoch: 6| Step: 8
Training loss: 0.33200782537460327
Validation loss: 2.058901568253835

Epoch: 6| Step: 9
Training loss: 0.6207139492034912
Validation loss: 2.0284268657366433

Epoch: 6| Step: 10
Training loss: 0.6793549060821533
Validation loss: 2.1048288345336914

Epoch: 6| Step: 11
Training loss: 0.6514224410057068
Validation loss: 2.151459733645121

Epoch: 6| Step: 12
Training loss: 0.6383419036865234
Validation loss: 2.0652092893918357

Epoch: 6| Step: 13
Training loss: 0.5055123567581177
Validation loss: 2.081044773260752

Epoch: 240| Step: 0
Training loss: 0.2810657322406769
Validation loss: 2.069092035293579

Epoch: 6| Step: 1
Training loss: 0.7220368385314941
Validation loss: 2.108969728151957

Epoch: 6| Step: 2
Training loss: 0.9151920080184937
Validation loss: 2.0732784271240234

Epoch: 6| Step: 3
Training loss: 0.6092957258224487
Validation loss: 2.084631085395813

Epoch: 6| Step: 4
Training loss: 0.39625483751296997
Validation loss: 2.09304408232371

Epoch: 6| Step: 5
Training loss: 0.42179518938064575
Validation loss: 2.039803465207418

Epoch: 6| Step: 6
Training loss: 0.4374365508556366
Validation loss: 2.102306842803955

Epoch: 6| Step: 7
Training loss: 1.3605425357818604
Validation loss: 2.082989494005839

Epoch: 6| Step: 8
Training loss: 0.8849046230316162
Validation loss: 2.042013247807821

Epoch: 6| Step: 9
Training loss: 0.39561545848846436
Validation loss: 2.0528738300005593

Epoch: 6| Step: 10
Training loss: 0.5967046618461609
Validation loss: 2.112101217110952

Epoch: 6| Step: 11
Training loss: 0.8376070261001587
Validation loss: 2.0661958853403726

Epoch: 6| Step: 12
Training loss: 0.7693290710449219
Validation loss: 2.0707058111826577

Epoch: 6| Step: 13
Training loss: 0.3218444883823395
Validation loss: 2.0574511686960855

Epoch: 241| Step: 0
Training loss: 0.48863494396209717
Validation loss: 2.0765623450279236

Epoch: 6| Step: 1
Training loss: 0.44079071283340454
Validation loss: 2.01923398176829

Epoch: 6| Step: 2
Training loss: 0.45181703567504883
Validation loss: 2.0810873905817666

Epoch: 6| Step: 3
Training loss: 0.8136171102523804
Validation loss: 2.0490402976671853

Epoch: 6| Step: 4
Training loss: 0.3838730752468109
Validation loss: 2.04692405462265

Epoch: 6| Step: 5
Training loss: 0.589369535446167
Validation loss: 2.100095351537069

Epoch: 6| Step: 6
Training loss: 0.99696946144104
Validation loss: 2.0947909553845725

Epoch: 6| Step: 7
Training loss: 0.3925870656967163
Validation loss: 2.0589905977249146

Epoch: 6| Step: 8
Training loss: 0.6291458010673523
Validation loss: 2.071151296297709

Epoch: 6| Step: 9
Training loss: 0.6247174739837646
Validation loss: 2.1039398511250815

Epoch: 6| Step: 10
Training loss: 0.5061747431755066
Validation loss: 2.0669277707735696

Epoch: 6| Step: 11
Training loss: 0.7048890590667725
Validation loss: 2.074412683645884

Epoch: 6| Step: 12
Training loss: 1.2021753787994385
Validation loss: 2.0401676495869956

Epoch: 6| Step: 13
Training loss: 0.6494814157485962
Validation loss: 2.042532980442047

Epoch: 242| Step: 0
Training loss: 0.9361646175384521
Validation loss: 2.0486992398897805

Epoch: 6| Step: 1
Training loss: 0.5556882619857788
Validation loss: 2.0623658100763955

Epoch: 6| Step: 2
Training loss: 0.30772238969802856
Validation loss: 2.07860674460729

Epoch: 6| Step: 3
Training loss: 0.9589077234268188
Validation loss: 2.0953294237454734

Epoch: 6| Step: 4
Training loss: 0.4418947696685791
Validation loss: 2.1038687229156494

Epoch: 6| Step: 5
Training loss: 0.44306114315986633
Validation loss: 2.0939747293790183

Epoch: 6| Step: 6
Training loss: 0.6766860485076904
Validation loss: 2.1051745216051736

Epoch: 6| Step: 7
Training loss: 0.6331468820571899
Validation loss: 2.0993252992630005

Epoch: 6| Step: 8
Training loss: 0.3921664357185364
Validation loss: 2.0498627424240112

Epoch: 6| Step: 9
Training loss: 0.28671202063560486
Validation loss: 2.118682940800985

Epoch: 6| Step: 10
Training loss: 0.6358177661895752
Validation loss: 2.1111827294031777

Epoch: 6| Step: 11
Training loss: 0.9038532972335815
Validation loss: 2.019994000593821

Epoch: 6| Step: 12
Training loss: 0.6695957183837891
Validation loss: 2.057478904724121

Epoch: 6| Step: 13
Training loss: 0.5929120779037476
Validation loss: 1.999090572198232

Epoch: 243| Step: 0
Training loss: 0.6805843114852905
Validation loss: 2.013885259628296

Epoch: 6| Step: 1
Training loss: 0.4187439978122711
Validation loss: 1.9960094889005024

Epoch: 6| Step: 2
Training loss: 0.7244691848754883
Validation loss: 2.0513980786005654

Epoch: 6| Step: 3
Training loss: 0.53408282995224
Validation loss: 2.1248606244723

Epoch: 6| Step: 4
Training loss: 0.6251114010810852
Validation loss: 2.148408134778341

Epoch: 6| Step: 5
Training loss: 0.7871052026748657
Validation loss: 2.149543603261312

Epoch: 6| Step: 6
Training loss: 0.7094215154647827
Validation loss: 2.1341129342714944

Epoch: 6| Step: 7
Training loss: 0.8384195566177368
Validation loss: 2.0495381951332092

Epoch: 6| Step: 8
Training loss: 0.6396321058273315
Validation loss: 2.0978506604830423

Epoch: 6| Step: 9
Training loss: 0.5601526498794556
Validation loss: 2.0963187217712402

Epoch: 6| Step: 10
Training loss: 0.5887234210968018
Validation loss: 2.116844058036804

Epoch: 6| Step: 11
Training loss: 0.8718188405036926
Validation loss: 2.1372763315836587

Epoch: 6| Step: 12
Training loss: 0.9636783003807068
Validation loss: 2.0980758666992188

Epoch: 6| Step: 13
Training loss: 1.087401032447815
Validation loss: 2.1134389638900757

Epoch: 244| Step: 0
Training loss: 0.6939303874969482
Validation loss: 2.134230852127075

Epoch: 6| Step: 1
Training loss: 0.3382081985473633
Validation loss: 2.1150619188944497

Epoch: 6| Step: 2
Training loss: 0.6435370445251465
Validation loss: 2.0645592411359153

Epoch: 6| Step: 3
Training loss: 0.7555172443389893
Validation loss: 2.0717038909594216

Epoch: 6| Step: 4
Training loss: 0.38149601221084595
Validation loss: 2.126223345597585

Epoch: 6| Step: 5
Training loss: 0.508319079875946
Validation loss: 2.1784411867459617

Epoch: 6| Step: 6
Training loss: 0.4982488453388214
Validation loss: 2.0946260690689087

Epoch: 6| Step: 7
Training loss: 0.43672603368759155
Validation loss: 2.0953078071276345

Epoch: 6| Step: 8
Training loss: 0.3432273864746094
Validation loss: 2.076059718926748

Epoch: 6| Step: 9
Training loss: 0.6916433572769165
Validation loss: 2.050994336605072

Epoch: 6| Step: 10
Training loss: 1.7562073469161987
Validation loss: 2.1177826126416526

Epoch: 6| Step: 11
Training loss: 0.6760550737380981
Validation loss: 2.07156370083491

Epoch: 6| Step: 12
Training loss: 0.6297293305397034
Validation loss: 2.111335794130961

Epoch: 6| Step: 13
Training loss: 0.6390389204025269
Validation loss: 2.0267409284909568

Epoch: 245| Step: 0
Training loss: 0.5561105608940125
Validation loss: 2.0457670291264853

Epoch: 6| Step: 1
Training loss: 0.4107438921928406
Validation loss: 2.141543447971344

Epoch: 6| Step: 2
Training loss: 0.39208984375
Validation loss: 2.0857128500938416

Epoch: 6| Step: 3
Training loss: 0.8821463584899902
Validation loss: 2.111804703871409

Epoch: 6| Step: 4
Training loss: 1.2121573686599731
Validation loss: 2.1093406875928244

Epoch: 6| Step: 5
Training loss: 0.780712366104126
Validation loss: 2.1312750379244485

Epoch: 6| Step: 6
Training loss: 1.0492756366729736
Validation loss: 2.1038561264673867

Epoch: 6| Step: 7
Training loss: 0.685836136341095
Validation loss: 2.1113969683647156

Epoch: 6| Step: 8
Training loss: 0.688878059387207
Validation loss: 2.092667023340861

Epoch: 6| Step: 9
Training loss: 0.34376004338264465
Validation loss: 2.0557703773180642

Epoch: 6| Step: 10
Training loss: 0.32474249601364136
Validation loss: 2.0680125753084817

Epoch: 6| Step: 11
Training loss: 0.3601033687591553
Validation loss: 2.0203099052111306

Epoch: 6| Step: 12
Training loss: 0.6445693969726562
Validation loss: 2.0341038902600608

Epoch: 6| Step: 13
Training loss: 0.5039793252944946
Validation loss: 2.030968348185221

Epoch: 246| Step: 0
Training loss: 0.5761725902557373
Validation loss: 2.0643285314242044

Epoch: 6| Step: 1
Training loss: 0.9346331357955933
Validation loss: 2.042651613553365

Epoch: 6| Step: 2
Training loss: 0.7611110806465149
Validation loss: 2.026326616605123

Epoch: 6| Step: 3
Training loss: 0.5460878014564514
Validation loss: 2.010960261027018

Epoch: 6| Step: 4
Training loss: 0.4110596477985382
Validation loss: 2.0958293080329895

Epoch: 6| Step: 5
Training loss: 0.32110515236854553
Validation loss: 2.0401261250178018

Epoch: 6| Step: 6
Training loss: 0.8035744428634644
Validation loss: 2.0640615224838257

Epoch: 6| Step: 7
Training loss: 0.34565702080726624
Validation loss: 2.054753084977468

Epoch: 6| Step: 8
Training loss: 0.7697741985321045
Validation loss: 2.0796268582344055

Epoch: 6| Step: 9
Training loss: 0.5412846207618713
Validation loss: 2.037763257821401

Epoch: 6| Step: 10
Training loss: 0.4655502438545227
Validation loss: 2.029725710550944

Epoch: 6| Step: 11
Training loss: 0.8449432849884033
Validation loss: 2.0799665451049805

Epoch: 6| Step: 12
Training loss: 0.40707728266716003
Validation loss: 2.099756379922231

Epoch: 6| Step: 13
Training loss: 0.8418991565704346
Validation loss: 2.1087242563565574

Epoch: 247| Step: 0
Training loss: 0.9426440000534058
Validation loss: 2.065321425596873

Epoch: 6| Step: 1
Training loss: 0.4447759985923767
Validation loss: 2.0790895024935403

Epoch: 6| Step: 2
Training loss: 1.111241340637207
Validation loss: 2.0873398979504905

Epoch: 6| Step: 3
Training loss: 0.40017861127853394
Validation loss: 2.027939041455587

Epoch: 6| Step: 4
Training loss: 0.532335102558136
Validation loss: 2.027700404326121

Epoch: 6| Step: 5
Training loss: 1.0160387754440308
Validation loss: 2.024065295855204

Epoch: 6| Step: 6
Training loss: 0.45758625864982605
Validation loss: 2.091640591621399

Epoch: 6| Step: 7
Training loss: 0.4178786873817444
Validation loss: 2.006467640399933

Epoch: 6| Step: 8
Training loss: 0.4815753102302551
Validation loss: 2.0126078128814697

Epoch: 6| Step: 9
Training loss: 0.7577155828475952
Validation loss: 2.032631834348043

Epoch: 6| Step: 10
Training loss: 0.376459002494812
Validation loss: 2.0321658651034036

Epoch: 6| Step: 11
Training loss: 0.4719984233379364
Validation loss: 2.0803566575050354

Epoch: 6| Step: 12
Training loss: 0.43614813685417175
Validation loss: 2.07592119773229

Epoch: 6| Step: 13
Training loss: 0.6613747477531433
Validation loss: 2.040009379386902

Epoch: 248| Step: 0
Training loss: 0.4151768684387207
Validation loss: 2.061756193637848

Epoch: 6| Step: 1
Training loss: 0.5023045539855957
Validation loss: 2.103224257628123

Epoch: 6| Step: 2
Training loss: 0.7995638847351074
Validation loss: 2.0835907061894736

Epoch: 6| Step: 3
Training loss: 0.30486807227134705
Validation loss: 2.025836408138275

Epoch: 6| Step: 4
Training loss: 0.6270307302474976
Validation loss: 2.090288499991099

Epoch: 6| Step: 5
Training loss: 0.5654855370521545
Validation loss: 2.0706836183865867

Epoch: 6| Step: 6
Training loss: 1.0060371160507202
Validation loss: 2.062647223472595

Epoch: 6| Step: 7
Training loss: 0.7897363305091858
Validation loss: 2.052457789580027

Epoch: 6| Step: 8
Training loss: 0.5648317337036133
Validation loss: 2.066515644391378

Epoch: 6| Step: 9
Training loss: 0.6246621608734131
Validation loss: 2.06397944688797

Epoch: 6| Step: 10
Training loss: 0.7355283498764038
Validation loss: 2.012558122475942

Epoch: 6| Step: 11
Training loss: 0.38007017970085144
Validation loss: 2.0790473421414695

Epoch: 6| Step: 12
Training loss: 0.5774931311607361
Validation loss: 2.031305213769277

Epoch: 6| Step: 13
Training loss: 0.3820890188217163
Validation loss: 2.0284119049708047

Epoch: 249| Step: 0
Training loss: 0.7009927034378052
Validation loss: 2.015407065550486

Epoch: 6| Step: 1
Training loss: 0.3823047876358032
Validation loss: 2.085400720437368

Epoch: 6| Step: 2
Training loss: 0.5869115591049194
Validation loss: 2.070616066455841

Epoch: 6| Step: 3
Training loss: 0.33478492498397827
Validation loss: 2.073864698410034

Epoch: 6| Step: 4
Training loss: 0.5787007808685303
Validation loss: 2.0959720611572266

Epoch: 6| Step: 5
Training loss: 0.8359126448631287
Validation loss: 2.0995270808537803

Epoch: 6| Step: 6
Training loss: 0.7458162903785706
Validation loss: 2.1184951861699424

Epoch: 6| Step: 7
Training loss: 0.3417268395423889
Validation loss: 2.0304028193155923

Epoch: 6| Step: 8
Training loss: 0.4090438187122345
Validation loss: 2.114399015903473

Epoch: 6| Step: 9
Training loss: 0.6589068174362183
Validation loss: 2.1011618971824646

Epoch: 6| Step: 10
Training loss: 0.6490936875343323
Validation loss: 2.1163395245869956

Epoch: 6| Step: 11
Training loss: 0.693842887878418
Validation loss: 2.1021495262781777

Epoch: 6| Step: 12
Training loss: 0.4872690737247467
Validation loss: 2.085301399230957

Epoch: 6| Step: 13
Training loss: 0.8846371173858643
Validation loss: 2.1171783606211343

Epoch: 250| Step: 0
Training loss: 0.48979899287223816
Validation loss: 2.1099042892456055

Epoch: 6| Step: 1
Training loss: 0.37448352575302124
Validation loss: 2.02471395333608

Epoch: 6| Step: 2
Training loss: 0.761162519454956
Validation loss: 2.1183637777964273

Epoch: 6| Step: 3
Training loss: 0.48258182406425476
Validation loss: 2.1081030567487082

Epoch: 6| Step: 4
Training loss: 0.89610755443573
Validation loss: 2.0482728282610574

Epoch: 6| Step: 5
Training loss: 0.4705924987792969
Validation loss: 2.077659328778585

Epoch: 6| Step: 6
Training loss: 0.594310998916626
Validation loss: 2.10795263449351

Epoch: 6| Step: 7
Training loss: 0.6691337823867798
Validation loss: 2.0100335280100503

Epoch: 6| Step: 8
Training loss: 0.4798537492752075
Validation loss: 2.04349817832311

Epoch: 6| Step: 9
Training loss: 0.5727500915527344
Validation loss: 2.0757494966189065

Epoch: 6| Step: 10
Training loss: 0.534034013748169
Validation loss: 2.0576166907946267

Epoch: 6| Step: 11
Training loss: 0.6310958862304688
Validation loss: 2.139975368976593

Epoch: 6| Step: 12
Training loss: 0.5873977541923523
Validation loss: 2.108399530251821

Epoch: 6| Step: 13
Training loss: 0.6583567261695862
Validation loss: 2.0920236309369407

Epoch: 251| Step: 0
Training loss: 0.9465516805648804
Validation loss: 2.115757425626119

Epoch: 6| Step: 1
Training loss: 0.48719072341918945
Validation loss: 2.093042731285095

Epoch: 6| Step: 2
Training loss: 0.6338253021240234
Validation loss: 2.088995118935903

Epoch: 6| Step: 3
Training loss: 0.507754385471344
Validation loss: 2.0826555689175925

Epoch: 6| Step: 4
Training loss: 0.8976486921310425
Validation loss: 2.095126966635386

Epoch: 6| Step: 5
Training loss: 0.5611497163772583
Validation loss: 2.0503551363945007

Epoch: 6| Step: 6
Training loss: 0.3057366609573364
Validation loss: 2.0711052815119424

Epoch: 6| Step: 7
Training loss: 0.7650041580200195
Validation loss: 2.024013181527456

Epoch: 6| Step: 8
Training loss: 0.7142773270606995
Validation loss: 2.0543351769447327

Epoch: 6| Step: 9
Training loss: 0.568035900592804
Validation loss: 2.0449311931928

Epoch: 6| Step: 10
Training loss: 0.6547237634658813
Validation loss: 2.0756694873174033

Epoch: 6| Step: 11
Training loss: 0.34533193707466125
Validation loss: 2.1191018422444663

Epoch: 6| Step: 12
Training loss: 0.6742556095123291
Validation loss: 2.04240216811498

Epoch: 6| Step: 13
Training loss: 0.5207807421684265
Validation loss: 2.085792620976766

Epoch: 252| Step: 0
Training loss: 0.796205997467041
Validation loss: 2.0837042729059854

Epoch: 6| Step: 1
Training loss: 1.079652190208435
Validation loss: 2.0381179650624595

Epoch: 6| Step: 2
Training loss: 0.35994160175323486
Validation loss: 2.074385344982147

Epoch: 6| Step: 3
Training loss: 0.6174108386039734
Validation loss: 2.0613108476003013

Epoch: 6| Step: 4
Training loss: 0.7695292234420776
Validation loss: 2.0761320988337197

Epoch: 6| Step: 5
Training loss: 0.44818317890167236
Validation loss: 2.04643976688385

Epoch: 6| Step: 6
Training loss: 0.5811778903007507
Validation loss: 2.080005725224813

Epoch: 6| Step: 7
Training loss: 0.25079700350761414
Validation loss: 2.0256657203038535

Epoch: 6| Step: 8
Training loss: 0.8050858378410339
Validation loss: 2.034514009952545

Epoch: 6| Step: 9
Training loss: 0.8143792748451233
Validation loss: 2.0666621128718057

Epoch: 6| Step: 10
Training loss: 0.4255889058113098
Validation loss: 2.016235570112864

Epoch: 6| Step: 11
Training loss: 0.6336195468902588
Validation loss: 2.0357153614362082

Epoch: 6| Step: 12
Training loss: 0.6507572531700134
Validation loss: 2.1013817191123962

Epoch: 6| Step: 13
Training loss: 0.3726985454559326
Validation loss: 2.0325293938318887

Epoch: 253| Step: 0
Training loss: 0.9318705797195435
Validation loss: 2.0818052093187966

Epoch: 6| Step: 1
Training loss: 0.7729194164276123
Validation loss: 2.0247724652290344

Epoch: 6| Step: 2
Training loss: 0.497142493724823
Validation loss: 2.0290178755919137

Epoch: 6| Step: 3
Training loss: 0.43900206685066223
Validation loss: 2.055545190970103

Epoch: 6| Step: 4
Training loss: 0.6494992971420288
Validation loss: 2.0153106848398843

Epoch: 6| Step: 5
Training loss: 0.6277704238891602
Validation loss: 2.049179216225942

Epoch: 6| Step: 6
Training loss: 0.38498497009277344
Validation loss: 2.0218153397242227

Epoch: 6| Step: 7
Training loss: 0.5040937662124634
Validation loss: 2.0367260177930198

Epoch: 6| Step: 8
Training loss: 0.5668497085571289
Validation loss: 2.1014719804128013

Epoch: 6| Step: 9
Training loss: 0.9704717993736267
Validation loss: 2.1092418233553567

Epoch: 6| Step: 10
Training loss: 0.41256600618362427
Validation loss: 2.0532031456629434

Epoch: 6| Step: 11
Training loss: 0.2798490524291992
Validation loss: 2.0555723309516907

Epoch: 6| Step: 12
Training loss: 0.7418002486228943
Validation loss: 2.0667446851730347

Epoch: 6| Step: 13
Training loss: 0.5838395357131958
Validation loss: 2.0196670095125833

Epoch: 254| Step: 0
Training loss: 0.6904376149177551
Validation loss: 2.0755077799161277

Epoch: 6| Step: 1
Training loss: 0.449049174785614
Validation loss: 2.0550615191459656

Epoch: 6| Step: 2
Training loss: 0.446669340133667
Validation loss: 2.1218897700309753

Epoch: 6| Step: 3
Training loss: 0.49383294582366943
Validation loss: 2.0767969886461892

Epoch: 6| Step: 4
Training loss: 0.5971686244010925
Validation loss: 2.0430226723353067

Epoch: 6| Step: 5
Training loss: 0.7844758033752441
Validation loss: 2.012596905231476

Epoch: 6| Step: 6
Training loss: 0.5891515612602234
Validation loss: 2.0748252073923745

Epoch: 6| Step: 7
Training loss: 0.5995550155639648
Validation loss: 2.0423129002253213

Epoch: 6| Step: 8
Training loss: 0.5348121523857117
Validation loss: 2.0961399475733438

Epoch: 6| Step: 9
Training loss: 0.5047799348831177
Validation loss: 2.044785976409912

Epoch: 6| Step: 10
Training loss: 0.5432611703872681
Validation loss: 2.1228120923042297

Epoch: 6| Step: 11
Training loss: 0.7255330681800842
Validation loss: 2.043208281199137

Epoch: 6| Step: 12
Training loss: 0.7716593742370605
Validation loss: 2.1056564450263977

Epoch: 6| Step: 13
Training loss: 0.7024685144424438
Validation loss: 2.0781535704930625

Epoch: 255| Step: 0
Training loss: 0.4789547920227051
Validation loss: 2.101851542790731

Epoch: 6| Step: 1
Training loss: 0.6079877614974976
Validation loss: 2.0602117776870728

Epoch: 6| Step: 2
Training loss: 0.573488175868988
Validation loss: 2.109148303667704

Epoch: 6| Step: 3
Training loss: 0.6511622667312622
Validation loss: 2.1227346658706665

Epoch: 6| Step: 4
Training loss: 0.34222471714019775
Validation loss: 2.1229569911956787

Epoch: 6| Step: 5
Training loss: 0.5003604888916016
Validation loss: 2.0557925502459207

Epoch: 6| Step: 6
Training loss: 0.2695811688899994
Validation loss: 2.0989614923795066

Epoch: 6| Step: 7
Training loss: 0.3015296459197998
Validation loss: 2.0660833517710366

Epoch: 6| Step: 8
Training loss: 1.2319576740264893
Validation loss: 2.0962515672047934

Epoch: 6| Step: 9
Training loss: 0.6346527338027954
Validation loss: 2.0474554300308228

Epoch: 6| Step: 10
Training loss: 0.788836658000946
Validation loss: 2.04936013619105

Epoch: 6| Step: 11
Training loss: 0.46796900033950806
Validation loss: 2.0400538245836892

Epoch: 6| Step: 12
Training loss: 0.6727747917175293
Validation loss: 2.035387098789215

Epoch: 6| Step: 13
Training loss: 0.7174427509307861
Validation loss: 2.1166066924730935

Epoch: 256| Step: 0
Training loss: 0.4792972505092621
Validation loss: 2.080141544342041

Epoch: 6| Step: 1
Training loss: 0.5256527662277222
Validation loss: 2.1447528998057046

Epoch: 6| Step: 2
Training loss: 0.3335110545158386
Validation loss: 2.1080023050308228

Epoch: 6| Step: 3
Training loss: 0.43622690439224243
Validation loss: 2.0226365327835083

Epoch: 6| Step: 4
Training loss: 0.6740490198135376
Validation loss: 2.0546398162841797

Epoch: 6| Step: 5
Training loss: 0.4515504837036133
Validation loss: 2.0684659282366433

Epoch: 6| Step: 6
Training loss: 0.4053466022014618
Validation loss: 2.1494086186091104

Epoch: 6| Step: 7
Training loss: 0.555777907371521
Validation loss: 2.0764460961023965

Epoch: 6| Step: 8
Training loss: 0.49393367767333984
Validation loss: 2.1108541091283164

Epoch: 6| Step: 9
Training loss: 0.7795695066452026
Validation loss: 2.0930055578549704

Epoch: 6| Step: 10
Training loss: 0.3874429166316986
Validation loss: 2.1904537876447043

Epoch: 6| Step: 11
Training loss: 0.7367169857025146
Validation loss: 2.051040212313334

Epoch: 6| Step: 12
Training loss: 0.6443687677383423
Validation loss: 2.1330332358678183

Epoch: 6| Step: 13
Training loss: 0.8977305293083191
Validation loss: 2.0433523654937744

Epoch: 257| Step: 0
Training loss: 0.4638802111148834
Validation loss: 2.1422094106674194

Epoch: 6| Step: 1
Training loss: 0.38013678789138794
Validation loss: 2.0643713076909385

Epoch: 6| Step: 2
Training loss: 0.45556873083114624
Validation loss: 2.1110361417134604

Epoch: 6| Step: 3
Training loss: 0.6994155645370483
Validation loss: 2.1166582703590393

Epoch: 6| Step: 4
Training loss: 0.6843665838241577
Validation loss: 2.0912171403566995

Epoch: 6| Step: 5
Training loss: 0.6982377171516418
Validation loss: 2.109498679637909

Epoch: 6| Step: 6
Training loss: 0.6100311279296875
Validation loss: 2.0879581769307456

Epoch: 6| Step: 7
Training loss: 0.6993967890739441
Validation loss: 2.0915729999542236

Epoch: 6| Step: 8
Training loss: 0.7768048644065857
Validation loss: 2.043032983938853

Epoch: 6| Step: 9
Training loss: 0.6905850768089294
Validation loss: 2.0631227095921836

Epoch: 6| Step: 10
Training loss: 0.7624417543411255
Validation loss: 2.0721232493718467

Epoch: 6| Step: 11
Training loss: 0.5174822807312012
Validation loss: 2.058214286963145

Epoch: 6| Step: 12
Training loss: 0.36839109659194946
Validation loss: 2.036401093006134

Epoch: 6| Step: 13
Training loss: 0.2947325110435486
Validation loss: 2.067808290322622

Epoch: 258| Step: 0
Training loss: 0.43622520565986633
Validation loss: 2.052040954430898

Epoch: 6| Step: 1
Training loss: 0.8574588894844055
Validation loss: 2.0590497056643167

Epoch: 6| Step: 2
Training loss: 0.9071320295333862
Validation loss: 2.100709935029348

Epoch: 6| Step: 3
Training loss: 0.5115395784378052
Validation loss: 2.0371570189793906

Epoch: 6| Step: 4
Training loss: 0.5880584716796875
Validation loss: 2.0372567772865295

Epoch: 6| Step: 5
Training loss: 0.30921003222465515
Validation loss: 2.0906306505203247

Epoch: 6| Step: 6
Training loss: 0.46047770977020264
Validation loss: 2.0868303179740906

Epoch: 6| Step: 7
Training loss: 0.4351813793182373
Validation loss: 2.0838983058929443

Epoch: 6| Step: 8
Training loss: 0.5592259764671326
Validation loss: 1.9970361789067586

Epoch: 6| Step: 9
Training loss: 0.6937453150749207
Validation loss: 2.0991443196932473

Epoch: 6| Step: 10
Training loss: 0.5941163897514343
Validation loss: 2.0940410693486533

Epoch: 6| Step: 11
Training loss: 0.6344510316848755
Validation loss: 2.064830780029297

Epoch: 6| Step: 12
Training loss: 0.7262497544288635
Validation loss: 2.0511489311854043

Epoch: 6| Step: 13
Training loss: 0.6400486826896667
Validation loss: 2.1064590414365134

Epoch: 259| Step: 0
Training loss: 0.7738118171691895
Validation loss: 2.0881360173225403

Epoch: 6| Step: 1
Training loss: 0.7832527160644531
Validation loss: 2.1018455028533936

Epoch: 6| Step: 2
Training loss: 0.6349631547927856
Validation loss: 2.0556541879971824

Epoch: 6| Step: 3
Training loss: 0.6235394477844238
Validation loss: 1.997331400712331

Epoch: 6| Step: 4
Training loss: 0.6194151639938354
Validation loss: 2.069446047147115

Epoch: 6| Step: 5
Training loss: 0.6607081890106201
Validation loss: 2.067828198273977

Epoch: 6| Step: 6
Training loss: 0.2354389727115631
Validation loss: 2.096170802911123

Epoch: 6| Step: 7
Training loss: 0.6599065065383911
Validation loss: 2.033136308193207

Epoch: 6| Step: 8
Training loss: 0.5247772932052612
Validation loss: 2.0306293964385986

Epoch: 6| Step: 9
Training loss: 0.48052242398262024
Validation loss: 2.036154866218567

Epoch: 6| Step: 10
Training loss: 0.25547486543655396
Validation loss: 2.0461620092391968

Epoch: 6| Step: 11
Training loss: 0.561756432056427
Validation loss: 2.0931021173795066

Epoch: 6| Step: 12
Training loss: 0.8675003051757812
Validation loss: 2.0921286940574646

Epoch: 6| Step: 13
Training loss: 0.552521288394928
Validation loss: 2.0669028560320535

Epoch: 260| Step: 0
Training loss: 0.4741555154323578
Validation loss: 2.0517053405443826

Epoch: 6| Step: 1
Training loss: 0.3162381649017334
Validation loss: 2.0978979070981345

Epoch: 6| Step: 2
Training loss: 0.9449559450149536
Validation loss: 2.0404505332310996

Epoch: 6| Step: 3
Training loss: 0.3659266233444214
Validation loss: 2.041097084681193

Epoch: 6| Step: 4
Training loss: 0.7152220010757446
Validation loss: 2.0889817078908286

Epoch: 6| Step: 5
Training loss: 0.3738919198513031
Validation loss: 2.072710394859314

Epoch: 6| Step: 6
Training loss: 0.4240162670612335
Validation loss: 2.0707746148109436

Epoch: 6| Step: 7
Training loss: 0.3162330985069275
Validation loss: 2.0694334705670676

Epoch: 6| Step: 8
Training loss: 0.4980437755584717
Validation loss: 2.0605472524960837

Epoch: 6| Step: 9
Training loss: 0.42605674266815186
Validation loss: 2.092856446901957

Epoch: 6| Step: 10
Training loss: 1.0348206758499146
Validation loss: 2.1134416659673056

Epoch: 6| Step: 11
Training loss: 0.5237895250320435
Validation loss: 2.0382577975591025

Epoch: 6| Step: 12
Training loss: 0.9216198921203613
Validation loss: 2.070229729016622

Epoch: 6| Step: 13
Training loss: 0.6177569031715393
Validation loss: 2.1491761008898416

Epoch: 261| Step: 0
Training loss: 0.6252112984657288
Validation loss: 2.0553052028020224

Epoch: 6| Step: 1
Training loss: 0.3870258927345276
Validation loss: 2.0758553544680276

Epoch: 6| Step: 2
Training loss: 0.6092772483825684
Validation loss: 2.0967761476834617

Epoch: 6| Step: 3
Training loss: 0.3861461877822876
Validation loss: 2.0641202131907144

Epoch: 6| Step: 4
Training loss: 0.9006180763244629
Validation loss: 2.0542994340260825

Epoch: 6| Step: 5
Training loss: 0.791096031665802
Validation loss: 2.1046855052312217

Epoch: 6| Step: 6
Training loss: 0.7568786144256592
Validation loss: 2.1183444062868753

Epoch: 6| Step: 7
Training loss: 0.36064907908439636
Validation loss: 2.0872050325075784

Epoch: 6| Step: 8
Training loss: 0.7637264728546143
Validation loss: 2.082148015499115

Epoch: 6| Step: 9
Training loss: 0.7296976447105408
Validation loss: 2.0897016525268555

Epoch: 6| Step: 10
Training loss: 0.524451732635498
Validation loss: 1.9940534432729085

Epoch: 6| Step: 11
Training loss: 0.4867246150970459
Validation loss: 2.0688592990239463

Epoch: 6| Step: 12
Training loss: 1.023848295211792
Validation loss: 2.0719417730967202

Epoch: 6| Step: 13
Training loss: 0.46002197265625
Validation loss: 2.101091424624125

Epoch: 262| Step: 0
Training loss: 0.5301839113235474
Validation loss: 2.021174430847168

Epoch: 6| Step: 1
Training loss: 0.905840277671814
Validation loss: 2.0728185176849365

Epoch: 6| Step: 2
Training loss: 0.6124011874198914
Validation loss: 2.0214192867279053

Epoch: 6| Step: 3
Training loss: 0.737969696521759
Validation loss: 2.0477410356203714

Epoch: 6| Step: 4
Training loss: 0.8076436519622803
Validation loss: 2.099092980225881

Epoch: 6| Step: 5
Training loss: 0.3911822438240051
Validation loss: 2.074154774347941

Epoch: 6| Step: 6
Training loss: 0.565480649471283
Validation loss: 2.1005853414535522

Epoch: 6| Step: 7
Training loss: 0.6615880727767944
Validation loss: 2.086214244365692

Epoch: 6| Step: 8
Training loss: 0.48037880659103394
Validation loss: 2.0607560873031616

Epoch: 6| Step: 9
Training loss: 1.0303348302841187
Validation loss: 1.9947101473808289

Epoch: 6| Step: 10
Training loss: 0.3856624364852905
Validation loss: 2.0656376481056213

Epoch: 6| Step: 11
Training loss: 0.711738646030426
Validation loss: 2.05874365568161

Epoch: 6| Step: 12
Training loss: 0.272737979888916
Validation loss: 2.0917049646377563

Epoch: 6| Step: 13
Training loss: 0.38954678177833557
Validation loss: 2.1050928433736167

Epoch: 263| Step: 0
Training loss: 1.084514856338501
Validation loss: 2.0720260739326477

Epoch: 6| Step: 1
Training loss: 0.331706702709198
Validation loss: 2.0094454685846963

Epoch: 6| Step: 2
Training loss: 0.41632968187332153
Validation loss: 2.044897754987081

Epoch: 6| Step: 3
Training loss: 0.3425025939941406
Validation loss: 2.085581203301748

Epoch: 6| Step: 4
Training loss: 0.45841333270072937
Validation loss: 1.9932296673456829

Epoch: 6| Step: 5
Training loss: 0.7261455059051514
Validation loss: 2.0882840355237327

Epoch: 6| Step: 6
Training loss: 0.5979554057121277
Validation loss: 2.1005934476852417

Epoch: 6| Step: 7
Training loss: 0.7681634426116943
Validation loss: 2.0925222039222717

Epoch: 6| Step: 8
Training loss: 0.5493483543395996
Validation loss: 2.0862879355748496

Epoch: 6| Step: 9
Training loss: 0.4713165760040283
Validation loss: 2.0588752230008445

Epoch: 6| Step: 10
Training loss: 0.8596737384796143
Validation loss: 2.0354324181874595

Epoch: 6| Step: 11
Training loss: 0.7717846035957336
Validation loss: 2.058567464351654

Epoch: 6| Step: 12
Training loss: 0.4656562805175781
Validation loss: 2.0853399435679116

Epoch: 6| Step: 13
Training loss: 0.5431541800498962
Validation loss: 2.074970265229543

Epoch: 264| Step: 0
Training loss: 0.37906962633132935
Validation loss: 2.083414892355601

Epoch: 6| Step: 1
Training loss: 0.33402955532073975
Validation loss: 2.0715007185935974

Epoch: 6| Step: 2
Training loss: 0.9174548387527466
Validation loss: 2.057480494181315

Epoch: 6| Step: 3
Training loss: 0.5698845386505127
Validation loss: 2.0588708917299905

Epoch: 6| Step: 4
Training loss: 0.5403537750244141
Validation loss: 2.016980528831482

Epoch: 6| Step: 5
Training loss: 0.8276117444038391
Validation loss: 2.0589995781580606

Epoch: 6| Step: 6
Training loss: 0.5301921367645264
Validation loss: 2.104288955529531

Epoch: 6| Step: 7
Training loss: 0.5675097703933716
Validation loss: 2.116880019505819

Epoch: 6| Step: 8
Training loss: 0.444417268037796
Validation loss: 2.068348248799642

Epoch: 6| Step: 9
Training loss: 0.3686177134513855
Validation loss: 2.042617082595825

Epoch: 6| Step: 10
Training loss: 0.6241937875747681
Validation loss: 2.047871689001719

Epoch: 6| Step: 11
Training loss: 0.40152692794799805
Validation loss: 2.0547295411427817

Epoch: 6| Step: 12
Training loss: 0.5964143872261047
Validation loss: 2.1252814531326294

Epoch: 6| Step: 13
Training loss: 0.6780134439468384
Validation loss: 2.084448754787445

Epoch: 265| Step: 0
Training loss: 0.8827722072601318
Validation loss: 2.095631460348765

Epoch: 6| Step: 1
Training loss: 0.6710154414176941
Validation loss: 2.062960982322693

Epoch: 6| Step: 2
Training loss: 0.30307793617248535
Validation loss: 2.022061765193939

Epoch: 6| Step: 3
Training loss: 0.7459883689880371
Validation loss: 2.110385080178579

Epoch: 6| Step: 4
Training loss: 1.0257210731506348
Validation loss: 2.1158876617749534

Epoch: 6| Step: 5
Training loss: 0.7218754887580872
Validation loss: 2.0977758169174194

Epoch: 6| Step: 6
Training loss: 0.659700870513916
Validation loss: 2.0588227113087973

Epoch: 6| Step: 7
Training loss: 0.30379772186279297
Validation loss: 2.0418912768363953

Epoch: 6| Step: 8
Training loss: 0.5393841862678528
Validation loss: 2.085857351620992

Epoch: 6| Step: 9
Training loss: 0.501682460308075
Validation loss: 2.1246599356333413

Epoch: 6| Step: 10
Training loss: 0.3522813320159912
Validation loss: 2.1214410265286765

Epoch: 6| Step: 11
Training loss: 0.469947874546051
Validation loss: 2.149947782357534

Epoch: 6| Step: 12
Training loss: 0.8130307793617249
Validation loss: 2.0939677953720093

Epoch: 6| Step: 13
Training loss: 0.5514463186264038
Validation loss: 2.107929607232412

Epoch: 266| Step: 0
Training loss: 1.0095003843307495
Validation loss: 2.059578080972036

Epoch: 6| Step: 1
Training loss: 0.456864595413208
Validation loss: 2.038143833478292

Epoch: 6| Step: 2
Training loss: 1.0671367645263672
Validation loss: 2.1366326014200845

Epoch: 6| Step: 3
Training loss: 0.42023950815200806
Validation loss: 2.0772623221079507

Epoch: 6| Step: 4
Training loss: 0.6035811901092529
Validation loss: 2.021533489227295

Epoch: 6| Step: 5
Training loss: 0.7829787731170654
Validation loss: 2.0278199513753257

Epoch: 6| Step: 6
Training loss: 0.5461596250534058
Validation loss: 2.0977268616358438

Epoch: 6| Step: 7
Training loss: 0.4420967102050781
Validation loss: 2.085461695988973

Epoch: 6| Step: 8
Training loss: 0.8632121086120605
Validation loss: 2.0494335095087686

Epoch: 6| Step: 9
Training loss: 0.40836286544799805
Validation loss: 2.030723591645559

Epoch: 6| Step: 10
Training loss: 0.3361099064350128
Validation loss: 2.0659937461217246

Epoch: 6| Step: 11
Training loss: 0.30477556586265564
Validation loss: 2.0237152775128684

Epoch: 6| Step: 12
Training loss: 0.29291409254074097
Validation loss: 2.0436600049336753

Epoch: 6| Step: 13
Training loss: 0.6789569854736328
Validation loss: 2.0287762681643167

Epoch: 267| Step: 0
Training loss: 0.7274208068847656
Validation loss: 2.07302725315094

Epoch: 6| Step: 1
Training loss: 0.6578717231750488
Validation loss: 2.0826411843299866

Epoch: 6| Step: 2
Training loss: 0.8052501678466797
Validation loss: 2.030241906642914

Epoch: 6| Step: 3
Training loss: 0.6991258263587952
Validation loss: 2.073812743028005

Epoch: 6| Step: 4
Training loss: 0.43050211668014526
Validation loss: 2.0570950508117676

Epoch: 6| Step: 5
Training loss: 0.4670938551425934
Validation loss: 1.9626376231511433

Epoch: 6| Step: 6
Training loss: 0.4069555997848511
Validation loss: 2.062780221303304

Epoch: 6| Step: 7
Training loss: 0.4544135630130768
Validation loss: 2.055367887020111

Epoch: 6| Step: 8
Training loss: 0.7804919481277466
Validation loss: 2.1233432491620383

Epoch: 6| Step: 9
Training loss: 0.393397718667984
Validation loss: 2.0848292311032615

Epoch: 6| Step: 10
Training loss: 0.6387324333190918
Validation loss: 2.06582502524058

Epoch: 6| Step: 11
Training loss: 0.567602276802063
Validation loss: 2.0714953541755676

Epoch: 6| Step: 12
Training loss: 0.32926562428474426
Validation loss: 2.0710421403249106

Epoch: 6| Step: 13
Training loss: 0.4941992163658142
Validation loss: 2.052826543649038

Epoch: 268| Step: 0
Training loss: 0.32702624797821045
Validation loss: 2.072386085987091

Epoch: 6| Step: 1
Training loss: 0.546520471572876
Validation loss: 2.047444502512614

Epoch: 6| Step: 2
Training loss: 0.6355926990509033
Validation loss: 2.09667706489563

Epoch: 6| Step: 3
Training loss: 0.29550495743751526
Validation loss: 2.0809582471847534

Epoch: 6| Step: 4
Training loss: 0.7731773257255554
Validation loss: 2.0695766607920327

Epoch: 6| Step: 5
Training loss: 0.3969166874885559
Validation loss: 2.106125513712565

Epoch: 6| Step: 6
Training loss: 0.3213632106781006
Validation loss: 2.090043048063914

Epoch: 6| Step: 7
Training loss: 0.4859246611595154
Validation loss: 2.1215678254763284

Epoch: 6| Step: 8
Training loss: 0.46670785546302795
Validation loss: 2.0614542961120605

Epoch: 6| Step: 9
Training loss: 0.7986836433410645
Validation loss: 2.060604214668274

Epoch: 6| Step: 10
Training loss: 0.40852710604667664
Validation loss: 2.0308172702789307

Epoch: 6| Step: 11
Training loss: 1.035308837890625
Validation loss: 2.0950859586397805

Epoch: 6| Step: 12
Training loss: 0.28060802817344666
Validation loss: 2.085595687230428

Epoch: 6| Step: 13
Training loss: 0.48749566078186035
Validation loss: 2.042254467805227

Epoch: 269| Step: 0
Training loss: 0.417729914188385
Validation loss: 2.047065774599711

Epoch: 6| Step: 1
Training loss: 0.7843111753463745
Validation loss: 2.072129170099894

Epoch: 6| Step: 2
Training loss: 0.2832146883010864
Validation loss: 2.069596548875173

Epoch: 6| Step: 3
Training loss: 0.3568417429924011
Validation loss: 2.0513458251953125

Epoch: 6| Step: 4
Training loss: 0.529674232006073
Validation loss: 2.019180337587992

Epoch: 6| Step: 5
Training loss: 0.903427004814148
Validation loss: 2.109866221745809

Epoch: 6| Step: 6
Training loss: 0.456720769405365
Validation loss: 2.0880648295084634

Epoch: 6| Step: 7
Training loss: 0.36373370885849
Validation loss: 2.016596794128418

Epoch: 6| Step: 8
Training loss: 0.416310578584671
Validation loss: 2.1351933081944785

Epoch: 6| Step: 9
Training loss: 1.3089792728424072
Validation loss: 1.9889949361483257

Epoch: 6| Step: 10
Training loss: 0.35849469900131226
Validation loss: 2.055115759372711

Epoch: 6| Step: 11
Training loss: 0.4985317885875702
Validation loss: 2.058531165122986

Epoch: 6| Step: 12
Training loss: 0.369430273771286
Validation loss: 2.0647246837615967

Epoch: 6| Step: 13
Training loss: 0.19707214832305908
Validation loss: 2.0695472955703735

Epoch: 270| Step: 0
Training loss: 0.6946578025817871
Validation loss: 2.1074856917063394

Epoch: 6| Step: 1
Training loss: 0.4480475187301636
Validation loss: 2.027837117513021

Epoch: 6| Step: 2
Training loss: 0.9756169319152832
Validation loss: 2.0473175843556723

Epoch: 6| Step: 3
Training loss: 0.6906906366348267
Validation loss: 1.9927305777867634

Epoch: 6| Step: 4
Training loss: 0.6115198135375977
Validation loss: 2.0815325578053794

Epoch: 6| Step: 5
Training loss: 0.4371216297149658
Validation loss: 2.0347374280293784

Epoch: 6| Step: 6
Training loss: 0.3036445081233978
Validation loss: 2.0641173720359802

Epoch: 6| Step: 7
Training loss: 0.4625099003314972
Validation loss: 2.006883720556895

Epoch: 6| Step: 8
Training loss: 0.3953131139278412
Validation loss: 2.1082417170206704

Epoch: 6| Step: 9
Training loss: 0.265977144241333
Validation loss: 2.0906538168589273

Epoch: 6| Step: 10
Training loss: 0.8559436798095703
Validation loss: 2.102995534737905

Epoch: 6| Step: 11
Training loss: 0.5217386484146118
Validation loss: 2.0273879567782083

Epoch: 6| Step: 12
Training loss: 0.5673370361328125
Validation loss: 2.0831260879834494

Epoch: 6| Step: 13
Training loss: 0.33577385544776917
Validation loss: 2.026633342107137

Epoch: 271| Step: 0
Training loss: 0.44222357869148254
Validation loss: 2.072251876195272

Epoch: 6| Step: 1
Training loss: 0.648175060749054
Validation loss: 2.0780839721361795

Epoch: 6| Step: 2
Training loss: 0.5330546498298645
Validation loss: 2.1447389125823975

Epoch: 6| Step: 3
Training loss: 0.5573116540908813
Validation loss: 2.072796642780304

Epoch: 6| Step: 4
Training loss: 0.35694849491119385
Validation loss: 2.1320142348607383

Epoch: 6| Step: 5
Training loss: 1.0113621950149536
Validation loss: 2.0525241096814475

Epoch: 6| Step: 6
Training loss: 0.4013531804084778
Validation loss: 2.067318598429362

Epoch: 6| Step: 7
Training loss: 0.2276485562324524
Validation loss: 2.1344255606333413

Epoch: 6| Step: 8
Training loss: 0.4553198516368866
Validation loss: 2.10622368256251

Epoch: 6| Step: 9
Training loss: 0.4055904746055603
Validation loss: 2.073288321495056

Epoch: 6| Step: 10
Training loss: 0.4263535737991333
Validation loss: 2.008777936299642

Epoch: 6| Step: 11
Training loss: 0.5492217540740967
Validation loss: 2.055229981740316

Epoch: 6| Step: 12
Training loss: 0.29887691140174866
Validation loss: 2.023605982462565

Epoch: 6| Step: 13
Training loss: 0.9946988821029663
Validation loss: 2.053927024205526

Epoch: 272| Step: 0
Training loss: 1.016068696975708
Validation loss: 2.0770539045333862

Epoch: 6| Step: 1
Training loss: 0.8688207864761353
Validation loss: 2.0872008005777993

Epoch: 6| Step: 2
Training loss: 0.38503265380859375
Validation loss: 2.0811685919761658

Epoch: 6| Step: 3
Training loss: 0.47844767570495605
Validation loss: 2.041632135709127

Epoch: 6| Step: 4
Training loss: 0.27529820799827576
Validation loss: 2.053826153278351

Epoch: 6| Step: 5
Training loss: 0.46460968255996704
Validation loss: 2.097468316555023

Epoch: 6| Step: 6
Training loss: 1.0096282958984375
Validation loss: 2.066633323828379

Epoch: 6| Step: 7
Training loss: 0.518190324306488
Validation loss: 2.077528933684031

Epoch: 6| Step: 8
Training loss: 0.2718276381492615
Validation loss: 2.06358003616333

Epoch: 6| Step: 9
Training loss: 0.3882787823677063
Validation loss: 2.0886203050613403

Epoch: 6| Step: 10
Training loss: 0.35497361421585083
Validation loss: 2.0302071372667947

Epoch: 6| Step: 11
Training loss: 0.6262400150299072
Validation loss: 2.064982215563456

Epoch: 6| Step: 12
Training loss: 0.4900459051132202
Validation loss: 2.0846360524495444

Epoch: 6| Step: 13
Training loss: 0.3178565502166748
Validation loss: 2.109474758307139

Epoch: 273| Step: 0
Training loss: 0.3765099346637726
Validation loss: 2.074652632077535

Epoch: 6| Step: 1
Training loss: 0.9091943502426147
Validation loss: 2.065505544344584

Epoch: 6| Step: 2
Training loss: 0.46003106236457825
Validation loss: 2.049121697743734

Epoch: 6| Step: 3
Training loss: 0.5911142230033875
Validation loss: 2.0728065570195517

Epoch: 6| Step: 4
Training loss: 0.2939654588699341
Validation loss: 2.0402859250704446

Epoch: 6| Step: 5
Training loss: 0.546947717666626
Validation loss: 2.0543261965115867

Epoch: 6| Step: 6
Training loss: 0.4954383969306946
Validation loss: 2.011283059914907

Epoch: 6| Step: 7
Training loss: 0.5541296601295471
Validation loss: 2.022819141546885

Epoch: 6| Step: 8
Training loss: 0.448361337184906
Validation loss: 2.131810247898102

Epoch: 6| Step: 9
Training loss: 0.3359904885292053
Validation loss: 2.078767955303192

Epoch: 6| Step: 10
Training loss: 0.5273444056510925
Validation loss: 2.0348923603693643

Epoch: 6| Step: 11
Training loss: 0.3457685112953186
Validation loss: 2.0400640964508057

Epoch: 6| Step: 12
Training loss: 0.6914607286453247
Validation loss: 2.001225749651591

Epoch: 6| Step: 13
Training loss: 0.5769298076629639
Validation loss: 2.0919823249181113

Epoch: 274| Step: 0
Training loss: 0.28620603680610657
Validation loss: 2.022355874379476

Epoch: 6| Step: 1
Training loss: 0.47739753127098083
Validation loss: 2.0238766372203827

Epoch: 6| Step: 2
Training loss: 1.0546352863311768
Validation loss: 2.094361404577891

Epoch: 6| Step: 3
Training loss: 0.7109147906303406
Validation loss: 2.0522817770640054

Epoch: 6| Step: 4
Training loss: 0.3578343987464905
Validation loss: 2.002802610397339

Epoch: 6| Step: 5
Training loss: 0.5015382170677185
Validation loss: 2.05490909020106

Epoch: 6| Step: 6
Training loss: 0.6719965934753418
Validation loss: 2.1663244565327964

Epoch: 6| Step: 7
Training loss: 0.5534909963607788
Validation loss: 2.06756462653478

Epoch: 6| Step: 8
Training loss: 0.7484176158905029
Validation loss: 2.1048317551612854

Epoch: 6| Step: 9
Training loss: 0.4147889316082001
Validation loss: 2.059827367464701

Epoch: 6| Step: 10
Training loss: 0.594487726688385
Validation loss: 2.0833372473716736

Epoch: 6| Step: 11
Training loss: 0.597940981388092
Validation loss: 2.0566835006078086

Epoch: 6| Step: 12
Training loss: 0.3999835252761841
Validation loss: 2.0563369194666543

Epoch: 6| Step: 13
Training loss: 0.4041076898574829
Validation loss: 2.0842336614926658

Epoch: 275| Step: 0
Training loss: 0.46541380882263184
Validation loss: 2.0981208086013794

Epoch: 6| Step: 1
Training loss: 0.4644221067428589
Validation loss: 2.0726952155431113

Epoch: 6| Step: 2
Training loss: 0.7913510203361511
Validation loss: 2.0852744777997336

Epoch: 6| Step: 3
Training loss: 0.3584930896759033
Validation loss: 2.0617975195248923

Epoch: 6| Step: 4
Training loss: 0.695152223110199
Validation loss: 2.0781946579615274

Epoch: 6| Step: 5
Training loss: 0.698521614074707
Validation loss: 2.1081769267717996

Epoch: 6| Step: 6
Training loss: 0.4195685088634491
Validation loss: 2.0935367941856384

Epoch: 6| Step: 7
Training loss: 0.42138099670410156
Validation loss: 2.0823824803034463

Epoch: 6| Step: 8
Training loss: 0.6874641180038452
Validation loss: 2.0504619479179382

Epoch: 6| Step: 9
Training loss: 0.5576817989349365
Validation loss: 2.0932790239652

Epoch: 6| Step: 10
Training loss: 0.2978367209434509
Validation loss: 2.0501566330591836

Epoch: 6| Step: 11
Training loss: 0.35030612349510193
Validation loss: 2.0636741320292153

Epoch: 6| Step: 12
Training loss: 0.8685069680213928
Validation loss: 2.0504987835884094

Epoch: 6| Step: 13
Training loss: 0.5499967336654663
Validation loss: 2.0625238021214805

Epoch: 276| Step: 0
Training loss: 0.6162313222885132
Validation loss: 2.1117023229599

Epoch: 6| Step: 1
Training loss: 0.5166219472885132
Validation loss: 2.0348520477612815

Epoch: 6| Step: 2
Training loss: 0.4231884181499481
Validation loss: 2.0709657669067383

Epoch: 6| Step: 3
Training loss: 0.4351622462272644
Validation loss: 2.1066851218541465

Epoch: 6| Step: 4
Training loss: 0.4800834655761719
Validation loss: 2.0542021989822388

Epoch: 6| Step: 5
Training loss: 0.48617810010910034
Validation loss: 2.0714956521987915

Epoch: 6| Step: 6
Training loss: 0.5590166449546814
Validation loss: 2.0707241892814636

Epoch: 6| Step: 7
Training loss: 1.0642039775848389
Validation loss: 2.1384038726488748

Epoch: 6| Step: 8
Training loss: 0.31918731331825256
Validation loss: 2.069332003593445

Epoch: 6| Step: 9
Training loss: 0.9988721013069153
Validation loss: 2.1136420369148254

Epoch: 6| Step: 10
Training loss: 0.7605272531509399
Validation loss: 2.0466390252113342

Epoch: 6| Step: 11
Training loss: 0.5827566385269165
Validation loss: 2.0484923919041953

Epoch: 6| Step: 12
Training loss: 0.5471329689025879
Validation loss: 2.1115854581197104

Epoch: 6| Step: 13
Training loss: 0.4480476379394531
Validation loss: 2.0122182369232178

Epoch: 277| Step: 0
Training loss: 0.6977906227111816
Validation loss: 2.075785299142202

Epoch: 6| Step: 1
Training loss: 0.4539446234703064
Validation loss: 2.11774210135142

Epoch: 6| Step: 2
Training loss: 0.711768388748169
Validation loss: 2.0554314653078714

Epoch: 6| Step: 3
Training loss: 0.5923057198524475
Validation loss: 2.0785022377967834

Epoch: 6| Step: 4
Training loss: 0.5631542205810547
Validation loss: 2.0356080134709678

Epoch: 6| Step: 5
Training loss: 0.2840486168861389
Validation loss: 2.0852153301239014

Epoch: 6| Step: 6
Training loss: 0.3472863435745239
Validation loss: 2.051633973916372

Epoch: 6| Step: 7
Training loss: 0.42980122566223145
Validation loss: 2.0753041903177896

Epoch: 6| Step: 8
Training loss: 0.35057076811790466
Validation loss: 2.08659956852595

Epoch: 6| Step: 9
Training loss: 0.5041042566299438
Validation loss: 2.1019581158955893

Epoch: 6| Step: 10
Training loss: 0.4884858727455139
Validation loss: 2.061907470226288

Epoch: 6| Step: 11
Training loss: 0.6589236259460449
Validation loss: 2.0532712936401367

Epoch: 6| Step: 12
Training loss: 0.5978819727897644
Validation loss: 2.0548263589541116

Epoch: 6| Step: 13
Training loss: 0.7867699861526489
Validation loss: 2.049916684627533

Epoch: 278| Step: 0
Training loss: 0.6470201015472412
Validation loss: 2.0928222139676413

Epoch: 6| Step: 1
Training loss: 0.4233868420124054
Validation loss: 2.0854222575823465

Epoch: 6| Step: 2
Training loss: 0.3537869155406952
Validation loss: 2.05074679851532

Epoch: 6| Step: 3
Training loss: 0.5360997319221497
Validation loss: 2.0762027303377786

Epoch: 6| Step: 4
Training loss: 0.613890528678894
Validation loss: 2.0990371108055115

Epoch: 6| Step: 5
Training loss: 0.6912757158279419
Validation loss: 2.016176958878835

Epoch: 6| Step: 6
Training loss: 0.45008566975593567
Validation loss: 2.071661333243052

Epoch: 6| Step: 7
Training loss: 0.37061989307403564
Validation loss: 2.091413676738739

Epoch: 6| Step: 8
Training loss: 0.9602696299552917
Validation loss: 2.0766689578692117

Epoch: 6| Step: 9
Training loss: 0.4152473509311676
Validation loss: 1.9875409205754597

Epoch: 6| Step: 10
Training loss: 0.40718549489974976
Validation loss: 2.064883768558502

Epoch: 6| Step: 11
Training loss: 0.265874445438385
Validation loss: 2.077053666114807

Epoch: 6| Step: 12
Training loss: 0.31351712346076965
Validation loss: 2.048199554284414

Epoch: 6| Step: 13
Training loss: 0.6644542217254639
Validation loss: 2.0999406774838767

Epoch: 279| Step: 0
Training loss: 0.31501150131225586
Validation loss: 2.044220268726349

Epoch: 6| Step: 1
Training loss: 0.7332994937896729
Validation loss: 2.0021756887435913

Epoch: 6| Step: 2
Training loss: 0.6337057948112488
Validation loss: 2.0833815336227417

Epoch: 6| Step: 3
Training loss: 0.7331380844116211
Validation loss: 2.0741315682729087

Epoch: 6| Step: 4
Training loss: 0.6129372119903564
Validation loss: 2.0875173211097717

Epoch: 6| Step: 5
Training loss: 0.3670884072780609
Validation loss: 2.0399946173032126

Epoch: 6| Step: 6
Training loss: 0.32042112946510315
Validation loss: 2.0399415294329324

Epoch: 6| Step: 7
Training loss: 1.1782442331314087
Validation loss: 2.06037700176239

Epoch: 6| Step: 8
Training loss: 0.8325347900390625
Validation loss: 2.072100599606832

Epoch: 6| Step: 9
Training loss: 0.27071815729141235
Validation loss: 2.059601386388143

Epoch: 6| Step: 10
Training loss: 0.3136221170425415
Validation loss: 2.100471019744873

Epoch: 6| Step: 11
Training loss: 0.4322023391723633
Validation loss: 2.0539246996243796

Epoch: 6| Step: 12
Training loss: 0.2978576421737671
Validation loss: 2.0311262806256614

Epoch: 6| Step: 13
Training loss: 0.4248608946800232
Validation loss: 2.0421064297358194

Epoch: 280| Step: 0
Training loss: 0.7162103056907654
Validation loss: 2.0654380321502686

Epoch: 6| Step: 1
Training loss: 0.5321825742721558
Validation loss: 2.058154741923014

Epoch: 6| Step: 2
Training loss: 0.6639339327812195
Validation loss: 2.0608169635136924

Epoch: 6| Step: 3
Training loss: 0.4938824772834778
Validation loss: 2.1154945691426597

Epoch: 6| Step: 4
Training loss: 0.31402096152305603
Validation loss: 2.041774034500122

Epoch: 6| Step: 5
Training loss: 0.4878200888633728
Validation loss: 2.1451416611671448

Epoch: 6| Step: 6
Training loss: 0.45182621479034424
Validation loss: 2.0375072956085205

Epoch: 6| Step: 7
Training loss: 0.7347750663757324
Validation loss: 2.090877672036489

Epoch: 6| Step: 8
Training loss: 0.44202926754951477
Validation loss: 2.1251834630966187

Epoch: 6| Step: 9
Training loss: 0.4229664206504822
Validation loss: 2.0998158057530723

Epoch: 6| Step: 10
Training loss: 0.4625529646873474
Validation loss: 2.085303485393524

Epoch: 6| Step: 11
Training loss: 0.5308306217193604
Validation loss: 2.049522042274475

Epoch: 6| Step: 12
Training loss: 0.6830531358718872
Validation loss: 2.004159132639567

Epoch: 6| Step: 13
Training loss: 0.439054399728775
Validation loss: 2.040835996468862

Epoch: 281| Step: 0
Training loss: 0.5114762783050537
Validation loss: 2.110524376233419

Epoch: 6| Step: 1
Training loss: 0.73663330078125
Validation loss: 2.042589783668518

Epoch: 6| Step: 2
Training loss: 0.8875065445899963
Validation loss: 2.023358941078186

Epoch: 6| Step: 3
Training loss: 0.22152459621429443
Validation loss: 2.069192866484324

Epoch: 6| Step: 4
Training loss: 0.2867957353591919
Validation loss: 2.0564096172650657

Epoch: 6| Step: 5
Training loss: 0.5776300430297852
Validation loss: 2.0384267767270408

Epoch: 6| Step: 6
Training loss: 1.0856425762176514
Validation loss: 2.0311414003372192

Epoch: 6| Step: 7
Training loss: 0.7603253126144409
Validation loss: 2.0454729000727334

Epoch: 6| Step: 8
Training loss: 0.3985688090324402
Validation loss: 2.0464500784873962

Epoch: 6| Step: 9
Training loss: 0.3593558073043823
Validation loss: 2.017935276031494

Epoch: 6| Step: 10
Training loss: 0.2730221748352051
Validation loss: 2.0099374055862427

Epoch: 6| Step: 11
Training loss: 0.37508341670036316
Validation loss: 2.050335943698883

Epoch: 6| Step: 12
Training loss: 0.8089974522590637
Validation loss: 2.0371150175730386

Epoch: 6| Step: 13
Training loss: 0.3358043432235718
Validation loss: 2.05333803097407

Epoch: 282| Step: 0
Training loss: 0.31594225764274597
Validation loss: 2.0631805857022605

Epoch: 6| Step: 1
Training loss: 0.3992699384689331
Validation loss: 2.0507914423942566

Epoch: 6| Step: 2
Training loss: 0.6042434573173523
Validation loss: 2.084285239378611

Epoch: 6| Step: 3
Training loss: 0.2367866039276123
Validation loss: 2.1133787631988525

Epoch: 6| Step: 4
Training loss: 0.5868794918060303
Validation loss: 2.1156232357025146

Epoch: 6| Step: 5
Training loss: 0.4422977864742279
Validation loss: 2.083963950475057

Epoch: 6| Step: 6
Training loss: 1.242678165435791
Validation loss: 2.0133471488952637

Epoch: 6| Step: 7
Training loss: 0.616532027721405
Validation loss: 2.0597560008366904

Epoch: 6| Step: 8
Training loss: 0.321458101272583
Validation loss: 2.058408776919047

Epoch: 6| Step: 9
Training loss: 0.6277526617050171
Validation loss: 2.0724370082219443

Epoch: 6| Step: 10
Training loss: 0.4190053939819336
Validation loss: 2.014953831831614

Epoch: 6| Step: 11
Training loss: 0.34066057205200195
Validation loss: 2.056709130605062

Epoch: 6| Step: 12
Training loss: 0.8292827606201172
Validation loss: 2.0942721168200173

Epoch: 6| Step: 13
Training loss: 0.4445914626121521
Validation loss: 2.0722383658091226

Epoch: 283| Step: 0
Training loss: 0.511480450630188
Validation loss: 2.044055759906769

Epoch: 6| Step: 1
Training loss: 0.5424324870109558
Validation loss: 2.053462187449137

Epoch: 6| Step: 2
Training loss: 1.014513611793518
Validation loss: 2.037960489590963

Epoch: 6| Step: 3
Training loss: 0.8240764737129211
Validation loss: 2.0607954462369285

Epoch: 6| Step: 4
Training loss: 0.4248368740081787
Validation loss: 2.0251611471176147

Epoch: 6| Step: 5
Training loss: 0.3475340008735657
Validation loss: 2.081387380758921

Epoch: 6| Step: 6
Training loss: 0.36743849515914917
Validation loss: 2.074000279108683

Epoch: 6| Step: 7
Training loss: 0.444586843252182
Validation loss: 2.079647739728292

Epoch: 6| Step: 8
Training loss: 0.6148783564567566
Validation loss: 2.0367159843444824

Epoch: 6| Step: 9
Training loss: 0.34462082386016846
Validation loss: 2.024118185043335

Epoch: 6| Step: 10
Training loss: 0.3959922194480896
Validation loss: 2.102053244908651

Epoch: 6| Step: 11
Training loss: 0.45676738023757935
Validation loss: 2.0796117583910623

Epoch: 6| Step: 12
Training loss: 0.4818403124809265
Validation loss: 2.0571091969807944

Epoch: 6| Step: 13
Training loss: 0.2509576678276062
Validation loss: 2.0729307730992637

Epoch: 284| Step: 0
Training loss: 0.2263084352016449
Validation loss: 2.1106141805648804

Epoch: 6| Step: 1
Training loss: 0.5295063853263855
Validation loss: 2.130719244480133

Epoch: 6| Step: 2
Training loss: 0.3652991056442261
Validation loss: 2.1076505978902182

Epoch: 6| Step: 3
Training loss: 0.5645870566368103
Validation loss: 2.003423273563385

Epoch: 6| Step: 4
Training loss: 0.4660123288631439
Validation loss: 2.0272864500681558

Epoch: 6| Step: 5
Training loss: 0.514036238193512
Validation loss: 2.077264428138733

Epoch: 6| Step: 6
Training loss: 0.7919301986694336
Validation loss: 2.09704997142156

Epoch: 6| Step: 7
Training loss: 0.46932747960090637
Validation loss: 2.090424120426178

Epoch: 6| Step: 8
Training loss: 0.615510106086731
Validation loss: 2.1055901249249778

Epoch: 6| Step: 9
Training loss: 0.3795219361782074
Validation loss: 2.067243774731954

Epoch: 6| Step: 10
Training loss: 0.4886277914047241
Validation loss: 2.1051012674967446

Epoch: 6| Step: 11
Training loss: 0.4226650595664978
Validation loss: 2.0659978787104287

Epoch: 6| Step: 12
Training loss: 0.6756346225738525
Validation loss: 2.032707611719767

Epoch: 6| Step: 13
Training loss: 0.4289768934249878
Validation loss: 2.0575051506360373

Epoch: 285| Step: 0
Training loss: 0.5381025075912476
Validation loss: 2.113223393758138

Epoch: 6| Step: 1
Training loss: 0.6491968631744385
Validation loss: 2.076525390148163

Epoch: 6| Step: 2
Training loss: 0.40801316499710083
Validation loss: 2.041921555995941

Epoch: 6| Step: 3
Training loss: 0.7277927994728088
Validation loss: 2.085012753804525

Epoch: 6| Step: 4
Training loss: 0.49274393916130066
Validation loss: 2.0511703491210938

Epoch: 6| Step: 5
Training loss: 0.7271477580070496
Validation loss: 2.107534170150757

Epoch: 6| Step: 6
Training loss: 0.3696745038032532
Validation loss: 2.0761959155400596

Epoch: 6| Step: 7
Training loss: 0.50375896692276
Validation loss: 2.035947541395823

Epoch: 6| Step: 8
Training loss: 0.5593656301498413
Validation loss: 2.102524975935618

Epoch: 6| Step: 9
Training loss: 0.3811900317668915
Validation loss: 2.062165915966034

Epoch: 6| Step: 10
Training loss: 0.45374634861946106
Validation loss: 2.065678060054779

Epoch: 6| Step: 11
Training loss: 0.32351893186569214
Validation loss: 2.082665721575419

Epoch: 6| Step: 12
Training loss: 0.47102421522140503
Validation loss: 2.0985620617866516

Epoch: 6| Step: 13
Training loss: 0.5408809781074524
Validation loss: 2.1109856963157654

Epoch: 286| Step: 0
Training loss: 0.5599168539047241
Validation loss: 2.0567625562349954

Epoch: 6| Step: 1
Training loss: 0.32204145193099976
Validation loss: 2.0938865741093955

Epoch: 6| Step: 2
Training loss: 0.5694919228553772
Validation loss: 2.1235808531443277

Epoch: 6| Step: 3
Training loss: 0.3915303349494934
Validation loss: 2.083586633205414

Epoch: 6| Step: 4
Training loss: 0.18831685185432434
Validation loss: 2.0592374205589294

Epoch: 6| Step: 5
Training loss: 1.0560712814331055
Validation loss: 2.0540771484375

Epoch: 6| Step: 6
Training loss: 0.38108211755752563
Validation loss: 2.0389873385429382

Epoch: 6| Step: 7
Training loss: 0.6646866202354431
Validation loss: 2.0832286874453225

Epoch: 6| Step: 8
Training loss: 0.2167224884033203
Validation loss: 2.113900105158488

Epoch: 6| Step: 9
Training loss: 0.6657075881958008
Validation loss: 2.0626418590545654

Epoch: 6| Step: 10
Training loss: 0.716706395149231
Validation loss: 2.048720121383667

Epoch: 6| Step: 11
Training loss: 0.30223724246025085
Validation loss: 2.081379850705465

Epoch: 6| Step: 12
Training loss: 0.38408753275871277
Validation loss: 2.0702039996782937

Epoch: 6| Step: 13
Training loss: 0.627342700958252
Validation loss: 2.111294666926066

Epoch: 287| Step: 0
Training loss: 0.2922491431236267
Validation loss: 2.0826724966367087

Epoch: 6| Step: 1
Training loss: 0.20457926392555237
Validation loss: 2.058435082435608

Epoch: 6| Step: 2
Training loss: 0.5764793753623962
Validation loss: 2.04151181379954

Epoch: 6| Step: 3
Training loss: 0.5810797810554504
Validation loss: 2.0652395288149514

Epoch: 6| Step: 4
Training loss: 0.505704402923584
Validation loss: 2.0418850580851235

Epoch: 6| Step: 5
Training loss: 0.45836392045021057
Validation loss: 2.0777039726575217

Epoch: 6| Step: 6
Training loss: 0.4033907353878021
Validation loss: 2.0177749395370483

Epoch: 6| Step: 7
Training loss: 0.587882936000824
Validation loss: 2.0287224849065146

Epoch: 6| Step: 8
Training loss: 0.5121580362319946
Validation loss: 1.9864020943641663

Epoch: 6| Step: 9
Training loss: 0.4707777500152588
Validation loss: 2.1254993279774985

Epoch: 6| Step: 10
Training loss: 0.4979696273803711
Validation loss: 2.1143884857495627

Epoch: 6| Step: 11
Training loss: 1.166776418685913
Validation loss: 2.0434739192326865

Epoch: 6| Step: 12
Training loss: 0.40588217973709106
Validation loss: 2.0887603163719177

Epoch: 6| Step: 13
Training loss: 0.5054526329040527
Validation loss: 2.1110863288243613

Epoch: 288| Step: 0
Training loss: 0.7819473743438721
Validation loss: 2.127817670504252

Epoch: 6| Step: 1
Training loss: 0.6821644306182861
Validation loss: 2.1251450777053833

Epoch: 6| Step: 2
Training loss: 0.3558003306388855
Validation loss: 2.107511500517527

Epoch: 6| Step: 3
Training loss: 0.6644406318664551
Validation loss: 2.0824997425079346

Epoch: 6| Step: 4
Training loss: 0.38038766384124756
Validation loss: 2.0576035181681314

Epoch: 6| Step: 5
Training loss: 0.4105198383331299
Validation loss: 2.054994265238444

Epoch: 6| Step: 6
Training loss: 0.5859754085540771
Validation loss: 2.0639362136522927

Epoch: 6| Step: 7
Training loss: 0.6826220750808716
Validation loss: 2.084192434946696

Epoch: 6| Step: 8
Training loss: 0.701951801776886
Validation loss: 2.108873426914215

Epoch: 6| Step: 9
Training loss: 0.5374935865402222
Validation loss: 2.076202392578125

Epoch: 6| Step: 10
Training loss: 0.29445981979370117
Validation loss: 2.072876254717509

Epoch: 6| Step: 11
Training loss: 0.5268933773040771
Validation loss: 2.046345909436544

Epoch: 6| Step: 12
Training loss: 0.6060817241668701
Validation loss: 2.0383274952570596

Epoch: 6| Step: 13
Training loss: 0.7283965349197388
Validation loss: 2.0714844266573587

Epoch: 289| Step: 0
Training loss: 0.32466059923171997
Validation loss: 2.083654205004374

Epoch: 6| Step: 1
Training loss: 0.814670979976654
Validation loss: 2.0952831506729126

Epoch: 6| Step: 2
Training loss: 0.34868568181991577
Validation loss: 2.068656086921692

Epoch: 6| Step: 3
Training loss: 0.5352281332015991
Validation loss: 2.067080855369568

Epoch: 6| Step: 4
Training loss: 0.9250589609146118
Validation loss: 2.0755863785743713

Epoch: 6| Step: 5
Training loss: 0.6947508454322815
Validation loss: 2.146481156349182

Epoch: 6| Step: 6
Training loss: 0.42462456226348877
Validation loss: 2.1234344442685447

Epoch: 6| Step: 7
Training loss: 0.36396324634552
Validation loss: 2.0493078231811523

Epoch: 6| Step: 8
Training loss: 0.5934708714485168
Validation loss: 2.056071122487386

Epoch: 6| Step: 9
Training loss: 0.303246408700943
Validation loss: 2.0573806365331015

Epoch: 6| Step: 10
Training loss: 0.36561787128448486
Validation loss: 2.052631457646688

Epoch: 6| Step: 11
Training loss: 0.2805166244506836
Validation loss: 2.091367463270823

Epoch: 6| Step: 12
Training loss: 0.302706241607666
Validation loss: 2.057613750298818

Epoch: 6| Step: 13
Training loss: 0.3024662733078003
Validation loss: 2.0946361223856607

Epoch: 290| Step: 0
Training loss: 0.6333068609237671
Validation loss: 2.0520220200220742

Epoch: 6| Step: 1
Training loss: 0.3880466818809509
Validation loss: 2.0788047115008035

Epoch: 6| Step: 2
Training loss: 0.7101171016693115
Validation loss: 2.0667786598205566

Epoch: 6| Step: 3
Training loss: 0.4696272313594818
Validation loss: 2.0711787939071655

Epoch: 6| Step: 4
Training loss: 0.5309597253799438
Validation loss: 2.001148005326589

Epoch: 6| Step: 5
Training loss: 0.26197758316993713
Validation loss: 2.0259160002072654

Epoch: 6| Step: 6
Training loss: 0.7136977910995483
Validation loss: 2.0744228959083557

Epoch: 6| Step: 7
Training loss: 0.47931522130966187
Validation loss: 2.0691133538881936

Epoch: 6| Step: 8
Training loss: 0.44393685460090637
Validation loss: 2.1033931175867715

Epoch: 6| Step: 9
Training loss: 0.7792329788208008
Validation loss: 2.0632150173187256

Epoch: 6| Step: 10
Training loss: 0.3602779805660248
Validation loss: 2.0079452196756997

Epoch: 6| Step: 11
Training loss: 0.4336020350456238
Validation loss: 2.03393026192983

Epoch: 6| Step: 12
Training loss: 0.4043860137462616
Validation loss: 2.072523375352224

Epoch: 6| Step: 13
Training loss: 0.4798797369003296
Validation loss: 2.0164979298909507

Epoch: 291| Step: 0
Training loss: 0.5669744610786438
Validation loss: 2.032345175743103

Epoch: 6| Step: 1
Training loss: 0.41285762190818787
Validation loss: 2.0452616810798645

Epoch: 6| Step: 2
Training loss: 0.526104211807251
Validation loss: 2.115996539592743

Epoch: 6| Step: 3
Training loss: 0.2959938943386078
Validation loss: 2.070397516091665

Epoch: 6| Step: 4
Training loss: 0.5640863180160522
Validation loss: 2.065801521142324

Epoch: 6| Step: 5
Training loss: 0.4038947820663452
Validation loss: 2.0441030462582908

Epoch: 6| Step: 6
Training loss: 0.3804129362106323
Validation loss: 2.0731013814608255

Epoch: 6| Step: 7
Training loss: 0.8504157066345215
Validation loss: 2.0702465971310935

Epoch: 6| Step: 8
Training loss: 0.40700000524520874
Validation loss: 2.0415039658546448

Epoch: 6| Step: 9
Training loss: 0.37933290004730225
Validation loss: 2.0314467748006186

Epoch: 6| Step: 10
Training loss: 0.9686648845672607
Validation loss: 2.0034525791803994

Epoch: 6| Step: 11
Training loss: 0.642810046672821
Validation loss: 2.037671148777008

Epoch: 6| Step: 12
Training loss: 0.48974984884262085
Validation loss: 2.0965068141619363

Epoch: 6| Step: 13
Training loss: 0.48229628801345825
Validation loss: 2.0062712828318277

Epoch: 292| Step: 0
Training loss: 0.3032481372356415
Validation loss: 2.0159831047058105

Epoch: 6| Step: 1
Training loss: 0.3680688738822937
Validation loss: 2.018992861111959

Epoch: 6| Step: 2
Training loss: 0.4460280239582062
Validation loss: 2.0769291520118713

Epoch: 6| Step: 3
Training loss: 0.5347313284873962
Validation loss: 2.1139424045880637

Epoch: 6| Step: 4
Training loss: 0.9435255527496338
Validation loss: 2.1027119954427085

Epoch: 6| Step: 5
Training loss: 0.47894197702407837
Validation loss: 2.078910768032074

Epoch: 6| Step: 6
Training loss: 0.31933820247650146
Validation loss: 2.0937981406847634

Epoch: 6| Step: 7
Training loss: 0.4569275379180908
Validation loss: 2.034321745236715

Epoch: 6| Step: 8
Training loss: 0.445097953081131
Validation loss: 2.0985375245412192

Epoch: 6| Step: 9
Training loss: 0.2619621157646179
Validation loss: 2.0084684093793235

Epoch: 6| Step: 10
Training loss: 0.7964521050453186
Validation loss: 2.094731648763021

Epoch: 6| Step: 11
Training loss: 0.3868844211101532
Validation loss: 2.0604730248451233

Epoch: 6| Step: 12
Training loss: 0.43346506357192993
Validation loss: 2.075885832309723

Epoch: 6| Step: 13
Training loss: 1.3321788311004639
Validation loss: 2.0302467942237854

Epoch: 293| Step: 0
Training loss: 0.5661771297454834
Validation loss: 2.0851951241493225

Epoch: 6| Step: 1
Training loss: 0.22557619214057922
Validation loss: 2.048592189947764

Epoch: 6| Step: 2
Training loss: 0.3826311230659485
Validation loss: 2.086110691229502

Epoch: 6| Step: 3
Training loss: 0.4159286916255951
Validation loss: 2.04093861579895

Epoch: 6| Step: 4
Training loss: 0.40095049142837524
Validation loss: 2.0380293329556785

Epoch: 6| Step: 5
Training loss: 0.4928593635559082
Validation loss: 2.04978613058726

Epoch: 6| Step: 6
Training loss: 0.5266321301460266
Validation loss: 2.1105507413546243

Epoch: 6| Step: 7
Training loss: 0.5744830369949341
Validation loss: 2.060710589090983

Epoch: 6| Step: 8
Training loss: 0.5559139251708984
Validation loss: 2.0400792757670083

Epoch: 6| Step: 9
Training loss: 1.005730152130127
Validation loss: 2.083487590154012

Epoch: 6| Step: 10
Training loss: 0.437997430562973
Validation loss: 2.075679361820221

Epoch: 6| Step: 11
Training loss: 0.38631176948547363
Validation loss: 2.030686835447947

Epoch: 6| Step: 12
Training loss: 0.47122734785079956
Validation loss: 2.0724642872810364

Epoch: 6| Step: 13
Training loss: 0.34141403436660767
Validation loss: 2.1039276123046875

Epoch: 294| Step: 0
Training loss: 0.4366582930088043
Validation loss: 2.0469781955083213

Epoch: 6| Step: 1
Training loss: 0.33320003747940063
Validation loss: 2.0377718210220337

Epoch: 6| Step: 2
Training loss: 0.2623346149921417
Validation loss: 2.00579043229421

Epoch: 6| Step: 3
Training loss: 0.4467953145503998
Validation loss: 2.092930813630422

Epoch: 6| Step: 4
Training loss: 0.2559804618358612
Validation loss: 2.1120638052622476

Epoch: 6| Step: 5
Training loss: 1.0711555480957031
Validation loss: 2.022351066271464

Epoch: 6| Step: 6
Training loss: 0.44571858644485474
Validation loss: 2.0723965962727866

Epoch: 6| Step: 7
Training loss: 0.5034788250923157
Validation loss: 2.0627682209014893

Epoch: 6| Step: 8
Training loss: 1.240883469581604
Validation loss: 2.0592308839162192

Epoch: 6| Step: 9
Training loss: 0.6913831830024719
Validation loss: 2.0768636067708335

Epoch: 6| Step: 10
Training loss: 0.40002983808517456
Validation loss: 2.092024346192678

Epoch: 6| Step: 11
Training loss: 0.3313921093940735
Validation loss: 2.1111515760421753

Epoch: 6| Step: 12
Training loss: 0.5191042423248291
Validation loss: 2.061724384625753

Epoch: 6| Step: 13
Training loss: 0.3363564610481262
Validation loss: 2.143072565396627

Epoch: 295| Step: 0
Training loss: 0.7881590127944946
Validation loss: 2.0893155535062156

Epoch: 6| Step: 1
Training loss: 0.4130308926105499
Validation loss: 2.065308451652527

Epoch: 6| Step: 2
Training loss: 0.4033312201499939
Validation loss: 2.110339045524597

Epoch: 6| Step: 3
Training loss: 0.32626861333847046
Validation loss: 2.123464067776998

Epoch: 6| Step: 4
Training loss: 0.23339134454727173
Validation loss: 2.04105281829834

Epoch: 6| Step: 5
Training loss: 0.41529718041419983
Validation loss: 2.0327135920524597

Epoch: 6| Step: 6
Training loss: 1.3249380588531494
Validation loss: 2.064518908659617

Epoch: 6| Step: 7
Training loss: 0.301225483417511
Validation loss: 2.0882619818051658

Epoch: 6| Step: 8
Training loss: 0.39957496523857117
Validation loss: 2.0787238081296286

Epoch: 6| Step: 9
Training loss: 0.39492398500442505
Validation loss: 2.0799614787101746

Epoch: 6| Step: 10
Training loss: 0.6631219387054443
Validation loss: 2.1008266607920327

Epoch: 6| Step: 11
Training loss: 0.540407657623291
Validation loss: 2.069701353708903

Epoch: 6| Step: 12
Training loss: 0.6057475805282593
Validation loss: 2.0615379214286804

Epoch: 6| Step: 13
Training loss: 0.4525708556175232
Validation loss: 2.054610292116801

Epoch: 296| Step: 0
Training loss: 0.5595941543579102
Validation loss: 2.1157576044400535

Epoch: 6| Step: 1
Training loss: 0.3256092965602875
Validation loss: 2.0209589203198752

Epoch: 6| Step: 2
Training loss: 0.6718220114707947
Validation loss: 2.058728814125061

Epoch: 6| Step: 3
Training loss: 0.514755129814148
Validation loss: 2.093287467956543

Epoch: 6| Step: 4
Training loss: 0.5392903089523315
Validation loss: 2.0963643193244934

Epoch: 6| Step: 5
Training loss: 0.5535955429077148
Validation loss: 2.064886669317881

Epoch: 6| Step: 6
Training loss: 0.27311161160469055
Validation loss: 2.0564396381378174

Epoch: 6| Step: 7
Training loss: 0.7071902751922607
Validation loss: 2.0571311314900718

Epoch: 6| Step: 8
Training loss: 0.38198617100715637
Validation loss: 2.079637626806895

Epoch: 6| Step: 9
Training loss: 0.5497324466705322
Validation loss: 2.082547883192698

Epoch: 6| Step: 10
Training loss: 0.5885623097419739
Validation loss: 2.0797268748283386

Epoch: 6| Step: 11
Training loss: 0.2746385931968689
Validation loss: 2.0944072008132935

Epoch: 6| Step: 12
Training loss: 0.5264409184455872
Validation loss: 2.096702297528585

Epoch: 6| Step: 13
Training loss: 0.5867047309875488
Validation loss: 2.0799561937650046

Epoch: 297| Step: 0
Training loss: 0.6569588780403137
Validation loss: 2.082640528678894

Epoch: 6| Step: 1
Training loss: 0.6105281114578247
Validation loss: 2.0933456222216287

Epoch: 6| Step: 2
Training loss: 0.4103812575340271
Validation loss: 2.087343454360962

Epoch: 6| Step: 3
Training loss: 0.7998473644256592
Validation loss: 2.022383987903595

Epoch: 6| Step: 4
Training loss: 0.8965363502502441
Validation loss: 2.0725640058517456

Epoch: 6| Step: 5
Training loss: 0.3837616443634033
Validation loss: 2.0630879998207092

Epoch: 6| Step: 6
Training loss: 0.5807033777236938
Validation loss: 2.028849979241689

Epoch: 6| Step: 7
Training loss: 0.5192179083824158
Validation loss: 2.1572025616963706

Epoch: 6| Step: 8
Training loss: 0.43130409717559814
Validation loss: 2.057880699634552

Epoch: 6| Step: 9
Training loss: 0.33490657806396484
Validation loss: 2.0772440830866494

Epoch: 6| Step: 10
Training loss: 0.4621644914150238
Validation loss: 2.0605423847834268

Epoch: 6| Step: 11
Training loss: 0.31488457322120667
Validation loss: 2.0775375763575235

Epoch: 6| Step: 12
Training loss: 0.3762246072292328
Validation loss: 2.067359983921051

Epoch: 6| Step: 13
Training loss: 0.4142425060272217
Validation loss: 2.095723032951355

Epoch: 298| Step: 0
Training loss: 0.41488975286483765
Validation loss: 2.057473619778951

Epoch: 6| Step: 1
Training loss: 0.5560704469680786
Validation loss: 2.0626068313916526

Epoch: 6| Step: 2
Training loss: 0.268513560295105
Validation loss: 2.0632156133651733

Epoch: 6| Step: 3
Training loss: 0.5067499876022339
Validation loss: 2.090467115243276

Epoch: 6| Step: 4
Training loss: 0.9048073887825012
Validation loss: 2.05005419254303

Epoch: 6| Step: 5
Training loss: 0.39987850189208984
Validation loss: 2.065030654271444

Epoch: 6| Step: 6
Training loss: 0.35302066802978516
Validation loss: 2.0634003281593323

Epoch: 6| Step: 7
Training loss: 0.2914152145385742
Validation loss: 2.0498841603597007

Epoch: 6| Step: 8
Training loss: 0.3349234461784363
Validation loss: 2.038406511147817

Epoch: 6| Step: 9
Training loss: 0.41925907135009766
Validation loss: 2.1176724235216775

Epoch: 6| Step: 10
Training loss: 0.7549325823783875
Validation loss: 2.074536899725596

Epoch: 6| Step: 11
Training loss: 0.5529746413230896
Validation loss: 2.122624635696411

Epoch: 6| Step: 12
Training loss: 0.5167223215103149
Validation loss: 2.096501032511393

Epoch: 6| Step: 13
Training loss: 0.5552048683166504
Validation loss: 2.059001386165619

Epoch: 299| Step: 0
Training loss: 0.9843714833259583
Validation loss: 2.14623228708903

Epoch: 6| Step: 1
Training loss: 0.45513030886650085
Validation loss: 2.128777722517649

Epoch: 6| Step: 2
Training loss: 0.38148850202560425
Validation loss: 2.1178341110547385

Epoch: 6| Step: 3
Training loss: 0.3721124827861786
Validation loss: 2.0529741048812866

Epoch: 6| Step: 4
Training loss: 1.0058828592300415
Validation loss: 2.075381020704905

Epoch: 6| Step: 5
Training loss: 0.5130759477615356
Validation loss: 2.0677693486213684

Epoch: 6| Step: 6
Training loss: 0.766447901725769
Validation loss: 2.094250440597534

Epoch: 6| Step: 7
Training loss: 0.24362224340438843
Validation loss: 2.048537492752075

Epoch: 6| Step: 8
Training loss: 0.41598421335220337
Validation loss: 2.08040318886439

Epoch: 6| Step: 9
Training loss: 0.2858307957649231
Validation loss: 2.0323915680249534

Epoch: 6| Step: 10
Training loss: 0.3324645757675171
Validation loss: 2.0927260319391885

Epoch: 6| Step: 11
Training loss: 0.4731476902961731
Validation loss: 2.1247840325037637

Epoch: 6| Step: 12
Training loss: 0.382562518119812
Validation loss: 2.030495822429657

Epoch: 6| Step: 13
Training loss: 0.4388197958469391
Validation loss: 2.0452327728271484

Epoch: 300| Step: 0
Training loss: 0.3603902757167816
Validation loss: 2.061219334602356

Epoch: 6| Step: 1
Training loss: 0.3679758906364441
Validation loss: 2.0576976537704468

Epoch: 6| Step: 2
Training loss: 0.33382079005241394
Validation loss: 2.10476823647817

Epoch: 6| Step: 3
Training loss: 0.25990718603134155
Validation loss: 2.0466204484303794

Epoch: 6| Step: 4
Training loss: 0.30393004417419434
Validation loss: 2.0356138547261557

Epoch: 6| Step: 5
Training loss: 0.7647342681884766
Validation loss: 2.108604113260905

Epoch: 6| Step: 6
Training loss: 0.7081155776977539
Validation loss: 2.0536024371782937

Epoch: 6| Step: 7
Training loss: 0.7998927235603333
Validation loss: 2.0101533929506936

Epoch: 6| Step: 8
Training loss: 0.556647777557373
Validation loss: 2.070407291253408

Epoch: 6| Step: 9
Training loss: 0.2215513288974762
Validation loss: 2.0584742426872253

Epoch: 6| Step: 10
Training loss: 0.29236626625061035
Validation loss: 2.0414550503094993

Epoch: 6| Step: 11
Training loss: 0.8025326132774353
Validation loss: 2.128620743751526

Epoch: 6| Step: 12
Training loss: 0.38088977336883545
Validation loss: 2.039462089538574

Epoch: 6| Step: 13
Training loss: 0.2822182774543762
Validation loss: 2.0414090951283774

Epoch: 301| Step: 0
Training loss: 0.630838930606842
Validation loss: 2.0671987334887185

Epoch: 6| Step: 1
Training loss: 0.3801214098930359
Validation loss: 2.081232786178589

Epoch: 6| Step: 2
Training loss: 0.5326963663101196
Validation loss: 2.070357064406077

Epoch: 6| Step: 3
Training loss: 0.9014889001846313
Validation loss: 2.082299808661143

Epoch: 6| Step: 4
Training loss: 0.8503121137619019
Validation loss: 2.1028509736061096

Epoch: 6| Step: 5
Training loss: 0.24495568871498108
Validation loss: 2.0403852065404258

Epoch: 6| Step: 6
Training loss: 0.3080788850784302
Validation loss: 2.1175204714139304

Epoch: 6| Step: 7
Training loss: 0.42022353410720825
Validation loss: 2.102717320124308

Epoch: 6| Step: 8
Training loss: 0.3173162341117859
Validation loss: 2.1219804286956787

Epoch: 6| Step: 9
Training loss: 0.5627101063728333
Validation loss: 2.09096493323644

Epoch: 6| Step: 10
Training loss: 0.2651320993900299
Validation loss: 2.092987140019735

Epoch: 6| Step: 11
Training loss: 0.3971273899078369
Validation loss: 2.106921831766764

Epoch: 6| Step: 12
Training loss: 0.3177492320537567
Validation loss: 2.1101494630177817

Epoch: 6| Step: 13
Training loss: 0.6363666653633118
Validation loss: 2.0712100068728128

Epoch: 302| Step: 0
Training loss: 0.29278725385665894
Validation loss: 2.0839134454727173

Epoch: 6| Step: 1
Training loss: 0.30573737621307373
Validation loss: 2.052504380544027

Epoch: 6| Step: 2
Training loss: 0.8621567487716675
Validation loss: 2.048904458681742

Epoch: 6| Step: 3
Training loss: 0.2787841558456421
Validation loss: 2.1191615660985312

Epoch: 6| Step: 4
Training loss: 0.6955901384353638
Validation loss: 2.0712735454241433

Epoch: 6| Step: 5
Training loss: 0.49598225951194763
Validation loss: 2.1151798566182456

Epoch: 6| Step: 6
Training loss: 0.3282812237739563
Validation loss: 2.0455913146336875

Epoch: 6| Step: 7
Training loss: 0.22305050492286682
Validation loss: 2.090668002764384

Epoch: 6| Step: 8
Training loss: 0.5466700792312622
Validation loss: 2.1047923962275186

Epoch: 6| Step: 9
Training loss: 0.6602447032928467
Validation loss: 2.0384684602419534

Epoch: 6| Step: 10
Training loss: 0.5552192330360413
Validation loss: 2.0209822257359824

Epoch: 6| Step: 11
Training loss: 0.48065435886383057
Validation loss: 2.091640134652456

Epoch: 6| Step: 12
Training loss: 0.7442415952682495
Validation loss: 2.157559593518575

Epoch: 6| Step: 13
Training loss: 0.3852671682834625
Validation loss: 2.1190345287323

Epoch: 303| Step: 0
Training loss: 0.42670774459838867
Validation loss: 2.110659956932068

Epoch: 6| Step: 1
Training loss: 0.41362839937210083
Validation loss: 2.0818925301233926

Epoch: 6| Step: 2
Training loss: 0.4536055326461792
Validation loss: 2.125901997089386

Epoch: 6| Step: 3
Training loss: 0.4482124149799347
Validation loss: 2.0768389304478965

Epoch: 6| Step: 4
Training loss: 0.45021992921829224
Validation loss: 2.10348912080129

Epoch: 6| Step: 5
Training loss: 0.4643248915672302
Validation loss: 2.1358637611071267

Epoch: 6| Step: 6
Training loss: 0.5023228526115417
Validation loss: 2.0754177967707315

Epoch: 6| Step: 7
Training loss: 0.2674849331378937
Validation loss: 2.138175288836161

Epoch: 6| Step: 8
Training loss: 0.58912193775177
Validation loss: 2.1087698340415955

Epoch: 6| Step: 9
Training loss: 0.4747530221939087
Validation loss: 2.04348091284434

Epoch: 6| Step: 10
Training loss: 0.25697389245033264
Validation loss: 2.027458349863688

Epoch: 6| Step: 11
Training loss: 0.7087157964706421
Validation loss: 2.1536009510358176

Epoch: 6| Step: 12
Training loss: 0.3951515257358551
Validation loss: 2.0817178885142007

Epoch: 6| Step: 13
Training loss: 0.4978308081626892
Validation loss: 2.1136431097984314

Epoch: 304| Step: 0
Training loss: 0.2887178957462311
Validation loss: 2.0966679453849792

Epoch: 6| Step: 1
Training loss: 0.41582903265953064
Validation loss: 2.11361833413442

Epoch: 6| Step: 2
Training loss: 1.0769076347351074
Validation loss: 2.0910112460454306

Epoch: 6| Step: 3
Training loss: 0.39257460832595825
Validation loss: 2.0613260666529336

Epoch: 6| Step: 4
Training loss: 0.22122830152511597
Validation loss: 2.08286323149999

Epoch: 6| Step: 5
Training loss: 0.2900978922843933
Validation loss: 2.058285435040792

Epoch: 6| Step: 6
Training loss: 0.5576441287994385
Validation loss: 2.0302823781967163

Epoch: 6| Step: 7
Training loss: 0.5723211169242859
Validation loss: 2.087638000647227

Epoch: 6| Step: 8
Training loss: 0.37718552350997925
Validation loss: 2.0715242624282837

Epoch: 6| Step: 9
Training loss: 0.45751190185546875
Validation loss: 2.0985625187555947

Epoch: 6| Step: 10
Training loss: 0.39765262603759766
Validation loss: 2.0906073649724326

Epoch: 6| Step: 11
Training loss: 0.3085789978504181
Validation loss: 2.0885952512423196

Epoch: 6| Step: 12
Training loss: 0.3430633544921875
Validation loss: 2.0586222410202026

Epoch: 6| Step: 13
Training loss: 0.8244956731796265
Validation loss: 2.0872589151064553

Epoch: 305| Step: 0
Training loss: 0.37663257122039795
Validation loss: 2.0625675320625305

Epoch: 6| Step: 1
Training loss: 0.3383695185184479
Validation loss: 2.07697860399882

Epoch: 6| Step: 2
Training loss: 0.3096381723880768
Validation loss: 2.0582178433736167

Epoch: 6| Step: 3
Training loss: 0.5152839422225952
Validation loss: 2.071431895097097

Epoch: 6| Step: 4
Training loss: 0.4227190613746643
Validation loss: 2.1146512428919473

Epoch: 6| Step: 5
Training loss: 0.32778728008270264
Validation loss: 2.050402065118154

Epoch: 6| Step: 6
Training loss: 0.6526521444320679
Validation loss: 2.041873574256897

Epoch: 6| Step: 7
Training loss: 0.42527833580970764
Validation loss: 2.0767993132273355

Epoch: 6| Step: 8
Training loss: 0.5520404577255249
Validation loss: 2.0214153130849204

Epoch: 6| Step: 9
Training loss: 1.0705866813659668
Validation loss: 2.0463003317515054

Epoch: 6| Step: 10
Training loss: 0.3958643078804016
Validation loss: 2.0321454405784607

Epoch: 6| Step: 11
Training loss: 0.5883312225341797
Validation loss: 2.1468072732289634

Epoch: 6| Step: 12
Training loss: 0.33991241455078125
Validation loss: 2.0827463666598

Epoch: 6| Step: 13
Training loss: 0.35107773542404175
Validation loss: 2.0289339621861777

Epoch: 306| Step: 0
Training loss: 0.4195653796195984
Validation loss: 2.097862422466278

Epoch: 6| Step: 1
Training loss: 0.3344356119632721
Validation loss: 2.0768216451009116

Epoch: 6| Step: 2
Training loss: 0.33300915360450745
Validation loss: 2.13417911529541

Epoch: 6| Step: 3
Training loss: 0.27940624952316284
Validation loss: 2.043525993824005

Epoch: 6| Step: 4
Training loss: 0.2463499754667282
Validation loss: 2.0368723471959433

Epoch: 6| Step: 5
Training loss: 0.30207329988479614
Validation loss: 2.0950530966122947

Epoch: 6| Step: 6
Training loss: 0.5019444227218628
Validation loss: 2.0779667099316916

Epoch: 6| Step: 7
Training loss: 0.3412732779979706
Validation loss: 2.0664535959561667

Epoch: 6| Step: 8
Training loss: 0.3840453028678894
Validation loss: 2.0579402248064675

Epoch: 6| Step: 9
Training loss: 0.37113988399505615
Validation loss: 2.0956305662790933

Epoch: 6| Step: 10
Training loss: 0.4407096803188324
Validation loss: 2.0852033495903015

Epoch: 6| Step: 11
Training loss: 1.046506643295288
Validation loss: 2.069573958714803

Epoch: 6| Step: 12
Training loss: 0.7969316244125366
Validation loss: 2.1129478414853415

Epoch: 6| Step: 13
Training loss: 0.7598876953125
Validation loss: 2.1357345978418985

Epoch: 307| Step: 0
Training loss: 0.6572716236114502
Validation loss: 2.1146008570988974

Epoch: 6| Step: 1
Training loss: 0.48620525002479553
Validation loss: 2.1001798709233603

Epoch: 6| Step: 2
Training loss: 0.20666053891181946
Validation loss: 2.0882686773935952

Epoch: 6| Step: 3
Training loss: 0.37034711241722107
Validation loss: 2.138330817222595

Epoch: 6| Step: 4
Training loss: 0.39162856340408325
Validation loss: 2.005689561367035

Epoch: 6| Step: 5
Training loss: 0.17127519845962524
Validation loss: 2.067246933778127

Epoch: 6| Step: 6
Training loss: 0.517022967338562
Validation loss: 2.0988479455312095

Epoch: 6| Step: 7
Training loss: 0.37352126836776733
Validation loss: 2.0870757897694907

Epoch: 6| Step: 8
Training loss: 0.4191398024559021
Validation loss: 2.0776100754737854

Epoch: 6| Step: 9
Training loss: 0.5169463157653809
Validation loss: 2.0570671757062278

Epoch: 6| Step: 10
Training loss: 0.662617564201355
Validation loss: 2.12416406472524

Epoch: 6| Step: 11
Training loss: 1.0340577363967896
Validation loss: 2.098913093407949

Epoch: 6| Step: 12
Training loss: 0.3528290092945099
Validation loss: 2.0750941832860312

Epoch: 6| Step: 13
Training loss: 0.5004261136054993
Validation loss: 2.0513165990511575

Epoch: 308| Step: 0
Training loss: 0.6188839077949524
Validation loss: 2.077269275983175

Epoch: 6| Step: 1
Training loss: 0.3226083815097809
Validation loss: 2.084837019443512

Epoch: 6| Step: 2
Training loss: 0.6611087918281555
Validation loss: 2.058347841103872

Epoch: 6| Step: 3
Training loss: 0.46079549193382263
Validation loss: 2.0547193686167398

Epoch: 6| Step: 4
Training loss: 0.2695867419242859
Validation loss: 2.0281479358673096

Epoch: 6| Step: 5
Training loss: 0.5403558015823364
Validation loss: 2.0948739051818848

Epoch: 6| Step: 6
Training loss: 0.5021121501922607
Validation loss: 2.054704030354818

Epoch: 6| Step: 7
Training loss: 0.42459923028945923
Validation loss: 2.0676714976628623

Epoch: 6| Step: 8
Training loss: 0.2745001018047333
Validation loss: 2.0939838687578836

Epoch: 6| Step: 9
Training loss: 0.3584858477115631
Validation loss: 2.124184707800547

Epoch: 6| Step: 10
Training loss: 0.7014132738113403
Validation loss: 2.0890161792437234

Epoch: 6| Step: 11
Training loss: 0.6458104848861694
Validation loss: 2.0289431611696878

Epoch: 6| Step: 12
Training loss: 0.4448685646057129
Validation loss: 2.0607872207959494

Epoch: 6| Step: 13
Training loss: 0.3061709702014923
Validation loss: 2.058211088180542

Epoch: 309| Step: 0
Training loss: 0.4672498106956482
Validation loss: 2.017390032609304

Epoch: 6| Step: 1
Training loss: 0.5146900415420532
Validation loss: 2.042836308479309

Epoch: 6| Step: 2
Training loss: 0.1506921648979187
Validation loss: 2.087948203086853

Epoch: 6| Step: 3
Training loss: 0.6076570749282837
Validation loss: 2.09406715631485

Epoch: 6| Step: 4
Training loss: 0.43892091512680054
Validation loss: 2.0793138345082602

Epoch: 6| Step: 5
Training loss: 0.4923924207687378
Validation loss: 2.033842126528422

Epoch: 6| Step: 6
Training loss: 0.4794849157333374
Validation loss: 2.0720964868863425

Epoch: 6| Step: 7
Training loss: 0.5160394906997681
Validation loss: 2.0562779108683267

Epoch: 6| Step: 8
Training loss: 0.6041921377182007
Validation loss: 2.0886860489845276

Epoch: 6| Step: 9
Training loss: 0.7362509965896606
Validation loss: 2.0211467345555625

Epoch: 6| Step: 10
Training loss: 0.26848548650741577
Validation loss: 2.066475967566172

Epoch: 6| Step: 11
Training loss: 0.28068938851356506
Validation loss: 2.071148673693339

Epoch: 6| Step: 12
Training loss: 0.6484214663505554
Validation loss: 2.0780574480692544

Epoch: 6| Step: 13
Training loss: 0.4372433125972748
Validation loss: 2.0452653765678406

Epoch: 310| Step: 0
Training loss: 0.6611877679824829
Validation loss: 2.0165738463401794

Epoch: 6| Step: 1
Training loss: 0.4414207339286804
Validation loss: 2.0235732992490134

Epoch: 6| Step: 2
Training loss: 0.27657756209373474
Validation loss: 2.060224711894989

Epoch: 6| Step: 3
Training loss: 0.2654726505279541
Validation loss: 2.058314939339956

Epoch: 6| Step: 4
Training loss: 0.2760266363620758
Validation loss: 2.047845482826233

Epoch: 6| Step: 5
Training loss: 0.5025669932365417
Validation loss: 2.0908396442731223

Epoch: 6| Step: 6
Training loss: 0.4073566794395447
Validation loss: 2.0715784430503845

Epoch: 6| Step: 7
Training loss: 0.8212184906005859
Validation loss: 2.0403055349985757

Epoch: 6| Step: 8
Training loss: 0.3720657527446747
Validation loss: 2.024351398150126

Epoch: 6| Step: 9
Training loss: 0.5366514325141907
Validation loss: 2.1003819902737937

Epoch: 6| Step: 10
Training loss: 0.6874020099639893
Validation loss: 2.0704365372657776

Epoch: 6| Step: 11
Training loss: 0.5686871409416199
Validation loss: 2.0798442165056863

Epoch: 6| Step: 12
Training loss: 0.7264740467071533
Validation loss: 2.050149977207184

Epoch: 6| Step: 13
Training loss: 0.376995325088501
Validation loss: 2.0502131382624307

Epoch: 311| Step: 0
Training loss: 0.8474197387695312
Validation loss: 2.0752535859743753

Epoch: 6| Step: 1
Training loss: 0.4321820139884949
Validation loss: 2.1190832257270813

Epoch: 6| Step: 2
Training loss: 0.619044303894043
Validation loss: 2.085292855898539

Epoch: 6| Step: 3
Training loss: 0.2211066633462906
Validation loss: 2.049052655696869

Epoch: 6| Step: 4
Training loss: 0.3962864875793457
Validation loss: 2.0751078128814697

Epoch: 6| Step: 5
Training loss: 0.348216712474823
Validation loss: 2.0602145989735923

Epoch: 6| Step: 6
Training loss: 0.5564701557159424
Validation loss: 2.083285629749298

Epoch: 6| Step: 7
Training loss: 0.6976272463798523
Validation loss: 2.0364009539286294

Epoch: 6| Step: 8
Training loss: 0.4075891077518463
Validation loss: 2.051967144012451

Epoch: 6| Step: 9
Training loss: 0.3899056911468506
Validation loss: 2.032505134741465

Epoch: 6| Step: 10
Training loss: 0.5872572064399719
Validation loss: 2.0489455461502075

Epoch: 6| Step: 11
Training loss: 0.39825430512428284
Validation loss: 2.0277209083239236

Epoch: 6| Step: 12
Training loss: 0.398779958486557
Validation loss: 2.0619160731633506

Epoch: 6| Step: 13
Training loss: 0.3190423250198364
Validation loss: 2.040172298749288

Epoch: 312| Step: 0
Training loss: 0.35791677236557007
Validation loss: 2.0678149859110513

Epoch: 6| Step: 1
Training loss: 0.4405099153518677
Validation loss: 2.0446637868881226

Epoch: 6| Step: 2
Training loss: 0.20882275700569153
Validation loss: 2.0578004519144693

Epoch: 6| Step: 3
Training loss: 0.47005823254585266
Validation loss: 2.081837554772695

Epoch: 6| Step: 4
Training loss: 0.4120780825614929
Validation loss: 2.059792697429657

Epoch: 6| Step: 5
Training loss: 0.3713417649269104
Validation loss: 2.0734457770983377

Epoch: 6| Step: 6
Training loss: 0.3707074820995331
Validation loss: 2.09352578719457

Epoch: 6| Step: 7
Training loss: 0.6458850502967834
Validation loss: 2.0788110494613647

Epoch: 6| Step: 8
Training loss: 0.5907171964645386
Validation loss: 2.046274205048879

Epoch: 6| Step: 9
Training loss: 0.6605693101882935
Validation loss: 2.0803194443384805

Epoch: 6| Step: 10
Training loss: 0.33643919229507446
Validation loss: 2.1089386145273843

Epoch: 6| Step: 11
Training loss: 0.40338000655174255
Validation loss: 2.084902028242747

Epoch: 6| Step: 12
Training loss: 0.3247188627719879
Validation loss: 2.0753095944722495

Epoch: 6| Step: 13
Training loss: 0.7611510157585144
Validation loss: 2.072259326775869

Epoch: 313| Step: 0
Training loss: 0.2738206386566162
Validation loss: 2.0589628418286643

Epoch: 6| Step: 1
Training loss: 0.3610682785511017
Validation loss: 2.0392942428588867

Epoch: 6| Step: 2
Training loss: 0.4628797173500061
Validation loss: 2.099844515323639

Epoch: 6| Step: 3
Training loss: 0.5629568099975586
Validation loss: 2.08724973599116

Epoch: 6| Step: 4
Training loss: 0.5029569864273071
Validation loss: 2.096585214138031

Epoch: 6| Step: 5
Training loss: 0.3930536210536957
Validation loss: 2.1194254557291665

Epoch: 6| Step: 6
Training loss: 0.4599626660346985
Validation loss: 2.065310537815094

Epoch: 6| Step: 7
Training loss: 0.3881487250328064
Validation loss: 2.058217247327169

Epoch: 6| Step: 8
Training loss: 0.24345020949840546
Validation loss: 2.0722763538360596

Epoch: 6| Step: 9
Training loss: 1.0051782131195068
Validation loss: 2.1059558391571045

Epoch: 6| Step: 10
Training loss: 0.39912649989128113
Validation loss: 2.0412381092707315

Epoch: 6| Step: 11
Training loss: 0.45181673765182495
Validation loss: 2.0897770325342813

Epoch: 6| Step: 12
Training loss: 0.25243398547172546
Validation loss: 2.1031426986058555

Epoch: 6| Step: 13
Training loss: 0.5945373773574829
Validation loss: 2.144826591014862

Epoch: 314| Step: 0
Training loss: 0.757077157497406
Validation loss: 2.0700814525286355

Epoch: 6| Step: 1
Training loss: 0.4210730493068695
Validation loss: 2.16277684768041

Epoch: 6| Step: 2
Training loss: 0.5465346574783325
Validation loss: 2.13009375333786

Epoch: 6| Step: 3
Training loss: 0.1720905750989914
Validation loss: 2.1019500295321145

Epoch: 6| Step: 4
Training loss: 0.6340752243995667
Validation loss: 2.0705503622690835

Epoch: 6| Step: 5
Training loss: 0.5499423742294312
Validation loss: 2.074608941872915

Epoch: 6| Step: 6
Training loss: 0.4303995370864868
Validation loss: 2.13372395435969

Epoch: 6| Step: 7
Training loss: 0.4118565320968628
Validation loss: 2.1067011952400208

Epoch: 6| Step: 8
Training loss: 0.424426794052124
Validation loss: 2.1243650913238525

Epoch: 6| Step: 9
Training loss: 0.31948238611221313
Validation loss: 2.078144371509552

Epoch: 6| Step: 10
Training loss: 0.5298932790756226
Validation loss: 2.0820459524790444

Epoch: 6| Step: 11
Training loss: 0.30051425099372864
Validation loss: 2.1154879530270896

Epoch: 6| Step: 12
Training loss: 1.0480825901031494
Validation loss: 2.1363219221433005

Epoch: 6| Step: 13
Training loss: 0.2701641917228699
Validation loss: 2.0980711579322815

Epoch: 315| Step: 0
Training loss: 0.3269151449203491
Validation loss: 2.158199369907379

Epoch: 6| Step: 1
Training loss: 0.5189701318740845
Validation loss: 2.1176182428995767

Epoch: 6| Step: 2
Training loss: 0.39774295687675476
Validation loss: 2.0588811238606772

Epoch: 6| Step: 3
Training loss: 0.5263589024543762
Validation loss: 2.0931376417477927

Epoch: 6| Step: 4
Training loss: 0.57423996925354
Validation loss: 2.061623473962148

Epoch: 6| Step: 5
Training loss: 0.3513846695423126
Validation loss: 2.0667662819226584

Epoch: 6| Step: 6
Training loss: 0.564955472946167
Validation loss: 2.0696051915486655

Epoch: 6| Step: 7
Training loss: 0.886458158493042
Validation loss: 2.062674065430959

Epoch: 6| Step: 8
Training loss: 0.3287949562072754
Validation loss: 2.1228196024894714

Epoch: 6| Step: 9
Training loss: 0.6989875435829163
Validation loss: 2.0807554125785828

Epoch: 6| Step: 10
Training loss: 0.531721830368042
Validation loss: 2.0576942364374795

Epoch: 6| Step: 11
Training loss: 0.49285387992858887
Validation loss: 2.0308476289113364

Epoch: 6| Step: 12
Training loss: 0.26394712924957275
Validation loss: 2.0676828225453696

Epoch: 6| Step: 13
Training loss: 0.3790324926376343
Validation loss: 2.046011527379354

Epoch: 316| Step: 0
Training loss: 0.3324054479598999
Validation loss: 2.0853310227394104

Epoch: 6| Step: 1
Training loss: 0.38750797510147095
Validation loss: 2.002400974432627

Epoch: 6| Step: 2
Training loss: 0.38874125480651855
Validation loss: 1.9723946650822957

Epoch: 6| Step: 3
Training loss: 0.26439520716667175
Validation loss: 2.0605209271113076

Epoch: 6| Step: 4
Training loss: 0.7473270893096924
Validation loss: 2.0439817309379578

Epoch: 6| Step: 5
Training loss: 0.2797177731990814
Validation loss: 2.0439175168673196

Epoch: 6| Step: 6
Training loss: 0.3800698518753052
Validation loss: 2.050761063893636

Epoch: 6| Step: 7
Training loss: 0.6136640906333923
Validation loss: 2.0576454599698386

Epoch: 6| Step: 8
Training loss: 0.741545557975769
Validation loss: 2.035835941632589

Epoch: 6| Step: 9
Training loss: 0.6396704912185669
Validation loss: 2.1202840010325112

Epoch: 6| Step: 10
Training loss: 0.3736079931259155
Validation loss: 2.0691184202829995

Epoch: 6| Step: 11
Training loss: 0.4876900911331177
Validation loss: 2.0928955078125

Epoch: 6| Step: 12
Training loss: 0.4114696979522705
Validation loss: 2.1007731556892395

Epoch: 6| Step: 13
Training loss: 0.4495205581188202
Validation loss: 2.0851130882898965

Epoch: 317| Step: 0
Training loss: 0.2993888854980469
Validation loss: 2.0652872920036316

Epoch: 6| Step: 1
Training loss: 0.3135530352592468
Validation loss: 2.0540791352589927

Epoch: 6| Step: 2
Training loss: 0.3145918846130371
Validation loss: 2.0595969756444297

Epoch: 6| Step: 3
Training loss: 0.25419342517852783
Validation loss: 2.1044694979985556

Epoch: 6| Step: 4
Training loss: 0.6233290433883667
Validation loss: 2.0679149826367698

Epoch: 6| Step: 5
Training loss: 0.3894585072994232
Validation loss: 2.067140976587931

Epoch: 6| Step: 6
Training loss: 0.6146366596221924
Validation loss: 2.0715196331342063

Epoch: 6| Step: 7
Training loss: 1.017026424407959
Validation loss: 2.105581521987915

Epoch: 6| Step: 8
Training loss: 0.6003473401069641
Validation loss: 2.098251978556315

Epoch: 6| Step: 9
Training loss: 0.22668254375457764
Validation loss: 2.1153568824132285

Epoch: 6| Step: 10
Training loss: 0.40230658650398254
Validation loss: 2.117679496606191

Epoch: 6| Step: 11
Training loss: 0.7623928189277649
Validation loss: 2.1261175076166787

Epoch: 6| Step: 12
Training loss: 0.3363306224346161
Validation loss: 2.075643221537272

Epoch: 6| Step: 13
Training loss: 0.44837167859077454
Validation loss: 2.0582973957061768

Epoch: 318| Step: 0
Training loss: 0.41694825887680054
Validation loss: 2.0845995942751565

Epoch: 6| Step: 1
Training loss: 0.35162872076034546
Validation loss: 2.0610424677530923

Epoch: 6| Step: 2
Training loss: 0.4691506624221802
Validation loss: 2.0682798624038696

Epoch: 6| Step: 3
Training loss: 0.43840456008911133
Validation loss: 2.146394928296407

Epoch: 6| Step: 4
Training loss: 0.3380477726459503
Validation loss: 2.1255462169647217

Epoch: 6| Step: 5
Training loss: 0.5509052276611328
Validation loss: 2.0910675525665283

Epoch: 6| Step: 6
Training loss: 0.5677512884140015
Validation loss: 2.1386555830637612

Epoch: 6| Step: 7
Training loss: 0.24912294745445251
Validation loss: 2.0665833552678428

Epoch: 6| Step: 8
Training loss: 0.6429673433303833
Validation loss: 2.1461086670557656

Epoch: 6| Step: 9
Training loss: 0.38962322473526
Validation loss: 2.0172544717788696

Epoch: 6| Step: 10
Training loss: 0.1902332752943039
Validation loss: 2.0254180232683816

Epoch: 6| Step: 11
Training loss: 0.9998639822006226
Validation loss: 2.059333105882009

Epoch: 6| Step: 12
Training loss: 0.36121290922164917
Validation loss: 2.0606250564257302

Epoch: 6| Step: 13
Training loss: 0.35420286655426025
Validation loss: 2.04660701751709

Epoch: 319| Step: 0
Training loss: 0.5559178590774536
Validation loss: 2.0988155404726663

Epoch: 6| Step: 1
Training loss: 0.5784188508987427
Validation loss: 2.056847890218099

Epoch: 6| Step: 2
Training loss: 0.3462081551551819
Validation loss: 2.052876035372416

Epoch: 6| Step: 3
Training loss: 0.5021353960037231
Validation loss: 2.068391740322113

Epoch: 6| Step: 4
Training loss: 0.3788753151893616
Validation loss: 2.153300325075785

Epoch: 6| Step: 5
Training loss: 0.6035047173500061
Validation loss: 2.1312419970830283

Epoch: 6| Step: 6
Training loss: 0.4453612267971039
Validation loss: 2.1107208331425986

Epoch: 6| Step: 7
Training loss: 0.6520328521728516
Validation loss: 2.0637911558151245

Epoch: 6| Step: 8
Training loss: 0.3393608331680298
Validation loss: 2.075554052988688

Epoch: 6| Step: 9
Training loss: 0.24528217315673828
Validation loss: 2.1221737265586853

Epoch: 6| Step: 10
Training loss: 0.4668518304824829
Validation loss: 2.1602256496747336

Epoch: 6| Step: 11
Training loss: 0.42656809091567993
Validation loss: 2.0798897544542947

Epoch: 6| Step: 12
Training loss: 0.46736544370651245
Validation loss: 2.081344564755758

Epoch: 6| Step: 13
Training loss: 0.5563309788703918
Validation loss: 2.063651164372762

Epoch: 320| Step: 0
Training loss: 0.2776004374027252
Validation loss: 2.0880114436149597

Epoch: 6| Step: 1
Training loss: 0.5482746362686157
Validation loss: 2.1203385392824807

Epoch: 6| Step: 2
Training loss: 0.3733562231063843
Validation loss: 2.157393674055735

Epoch: 6| Step: 3
Training loss: 0.3290308713912964
Validation loss: 2.0570159753163657

Epoch: 6| Step: 4
Training loss: 0.2975628972053528
Validation loss: 2.0913145542144775

Epoch: 6| Step: 5
Training loss: 0.6315266489982605
Validation loss: 2.0776718060175576

Epoch: 6| Step: 6
Training loss: 0.4432753920555115
Validation loss: 2.1151846249898276

Epoch: 6| Step: 7
Training loss: 0.634949803352356
Validation loss: 2.070443630218506

Epoch: 6| Step: 8
Training loss: 0.38692641258239746
Validation loss: 2.0437009731928506

Epoch: 6| Step: 9
Training loss: 0.32915735244750977
Validation loss: 2.1103203495343528

Epoch: 6| Step: 10
Training loss: 0.7213078737258911
Validation loss: 2.0814966758092246

Epoch: 6| Step: 11
Training loss: 0.4016452431678772
Validation loss: 2.0976556539535522

Epoch: 6| Step: 12
Training loss: 0.32161837816238403
Validation loss: 2.083349883556366

Epoch: 6| Step: 13
Training loss: 0.5697163343429565
Validation loss: 2.093731860319773

Epoch: 321| Step: 0
Training loss: 0.34327781200408936
Validation loss: 2.108353018760681

Epoch: 6| Step: 1
Training loss: 0.4807593524456024
Validation loss: 2.0526326497395835

Epoch: 6| Step: 2
Training loss: 0.7025425434112549
Validation loss: 2.1005656520525613

Epoch: 6| Step: 3
Training loss: 0.3341781795024872
Validation loss: 2.121401766935984

Epoch: 6| Step: 4
Training loss: 0.3518539071083069
Validation loss: 2.118574579556783

Epoch: 6| Step: 5
Training loss: 0.34897616505622864
Validation loss: 2.1468699177106223

Epoch: 6| Step: 6
Training loss: 0.3454507291316986
Validation loss: 2.1151174108187356

Epoch: 6| Step: 7
Training loss: 0.3593288064002991
Validation loss: 2.0863144795099893

Epoch: 6| Step: 8
Training loss: 0.9639543294906616
Validation loss: 2.1499447027842202

Epoch: 6| Step: 9
Training loss: 0.500660240650177
Validation loss: 2.1052523652712503

Epoch: 6| Step: 10
Training loss: 0.34504586458206177
Validation loss: 2.1038635969161987

Epoch: 6| Step: 11
Training loss: 0.22163699567317963
Validation loss: 2.0179333686828613

Epoch: 6| Step: 12
Training loss: 0.42008453607559204
Validation loss: 2.053386310736338

Epoch: 6| Step: 13
Training loss: 0.47574061155319214
Validation loss: 2.040550092856089

Epoch: 322| Step: 0
Training loss: 0.4688844680786133
Validation loss: 2.0543185273806253

Epoch: 6| Step: 1
Training loss: 0.7957339882850647
Validation loss: 2.113121489683787

Epoch: 6| Step: 2
Training loss: 0.3402881622314453
Validation loss: 2.056685149669647

Epoch: 6| Step: 3
Training loss: 0.9204806089401245
Validation loss: 2.0205931862195334

Epoch: 6| Step: 4
Training loss: 0.46845805644989014
Validation loss: 2.1179571946461997

Epoch: 6| Step: 5
Training loss: 0.30901622772216797
Validation loss: 2.0771320859591165

Epoch: 6| Step: 6
Training loss: 0.2997007668018341
Validation loss: 2.083354413509369

Epoch: 6| Step: 7
Training loss: 0.46296414732933044
Validation loss: 2.1147592266400657

Epoch: 6| Step: 8
Training loss: 0.46181559562683105
Validation loss: 2.0930899580319724

Epoch: 6| Step: 9
Training loss: 0.25060537457466125
Validation loss: 2.082931856314341

Epoch: 6| Step: 10
Training loss: 0.44043993949890137
Validation loss: 2.0859997272491455

Epoch: 6| Step: 11
Training loss: 0.32991310954093933
Validation loss: 2.0372289617856345

Epoch: 6| Step: 12
Training loss: 0.35229068994522095
Validation loss: 2.071461300055186

Epoch: 6| Step: 13
Training loss: 0.2931983470916748
Validation loss: 2.05984636147817

Epoch: 323| Step: 0
Training loss: 0.4696740508079529
Validation loss: 1.9988762935002644

Epoch: 6| Step: 1
Training loss: 0.29286110401153564
Validation loss: 2.110051910082499

Epoch: 6| Step: 2
Training loss: 0.40883949398994446
Validation loss: 2.0489600896835327

Epoch: 6| Step: 3
Training loss: 0.9401440024375916
Validation loss: 2.0770943760871887

Epoch: 6| Step: 4
Training loss: 0.746317982673645
Validation loss: 2.0659226973851523

Epoch: 6| Step: 5
Training loss: 0.30027151107788086
Validation loss: 2.114630122979482

Epoch: 6| Step: 6
Training loss: 0.4562678039073944
Validation loss: 2.0461502075195312

Epoch: 6| Step: 7
Training loss: 0.40579596161842346
Validation loss: 2.059014320373535

Epoch: 6| Step: 8
Training loss: 0.20374098420143127
Validation loss: 2.0833226442337036

Epoch: 6| Step: 9
Training loss: 0.46796703338623047
Validation loss: 2.0774824619293213

Epoch: 6| Step: 10
Training loss: 0.3190697133541107
Validation loss: 2.139372626940409

Epoch: 6| Step: 11
Training loss: 0.3505668640136719
Validation loss: 2.0847365458806357

Epoch: 6| Step: 12
Training loss: 0.41331470012664795
Validation loss: 2.0977439284324646

Epoch: 6| Step: 13
Training loss: 0.55397629737854
Validation loss: 2.0706173181533813

Epoch: 324| Step: 0
Training loss: 0.2998782992362976
Validation loss: 2.1006620724995932

Epoch: 6| Step: 1
Training loss: 0.5098334550857544
Validation loss: 2.076281030972799

Epoch: 6| Step: 2
Training loss: 0.304279625415802
Validation loss: 2.1233944495519004

Epoch: 6| Step: 3
Training loss: 0.38858890533447266
Validation loss: 2.0560782750447593

Epoch: 6| Step: 4
Training loss: 0.5377061367034912
Validation loss: 2.102225124835968

Epoch: 6| Step: 5
Training loss: 0.4263799786567688
Validation loss: 2.117433170477549

Epoch: 6| Step: 6
Training loss: 0.29151323437690735
Validation loss: 2.081825315952301

Epoch: 6| Step: 7
Training loss: 0.42910924553871155
Validation loss: 2.109101633230845

Epoch: 6| Step: 8
Training loss: 0.4891469478607178
Validation loss: 2.062364141146342

Epoch: 6| Step: 9
Training loss: 0.7694960832595825
Validation loss: 2.0738669633865356

Epoch: 6| Step: 10
Training loss: 0.21490971744060516
Validation loss: 2.1063774824142456

Epoch: 6| Step: 11
Training loss: 0.28428715467453003
Validation loss: 2.045604328314463

Epoch: 6| Step: 12
Training loss: 0.9358790516853333
Validation loss: 2.0971771279970803

Epoch: 6| Step: 13
Training loss: 0.2620697617530823
Validation loss: 2.1094674468040466

Epoch: 325| Step: 0
Training loss: 0.2192009538412094
Validation loss: 2.046832720438639

Epoch: 6| Step: 1
Training loss: 0.427301287651062
Validation loss: 2.0708377162615457

Epoch: 6| Step: 2
Training loss: 0.5461466908454895
Validation loss: 2.084040959676107

Epoch: 6| Step: 3
Training loss: 0.2650667726993561
Validation loss: 2.1268258094787598

Epoch: 6| Step: 4
Training loss: 0.4552169442176819
Validation loss: 2.107447365919749

Epoch: 6| Step: 5
Training loss: 0.4194347858428955
Validation loss: 2.104480187098185

Epoch: 6| Step: 6
Training loss: 0.4094276428222656
Validation loss: 2.1047181487083435

Epoch: 6| Step: 7
Training loss: 0.7700695395469666
Validation loss: 2.0839489102363586

Epoch: 6| Step: 8
Training loss: 0.2704189717769623
Validation loss: 2.094313303629557

Epoch: 6| Step: 9
Training loss: 0.4682857096195221
Validation loss: 2.069042762120565

Epoch: 6| Step: 10
Training loss: 0.546686589717865
Validation loss: 2.0615529219309487

Epoch: 6| Step: 11
Training loss: 0.19250518083572388
Validation loss: 2.1136083205540976

Epoch: 6| Step: 12
Training loss: 0.5379087924957275
Validation loss: 2.056744118531545

Epoch: 6| Step: 13
Training loss: 0.33086729049682617
Validation loss: 2.049442927042643

Epoch: 326| Step: 0
Training loss: 0.41258329153060913
Validation loss: 2.1051134864489236

Epoch: 6| Step: 1
Training loss: 0.7413921356201172
Validation loss: 2.1433258851369223

Epoch: 6| Step: 2
Training loss: 0.18609535694122314
Validation loss: 2.045533855756124

Epoch: 6| Step: 3
Training loss: 0.3105698823928833
Validation loss: 2.094500164190928

Epoch: 6| Step: 4
Training loss: 0.8056284785270691
Validation loss: 2.1489636500676474

Epoch: 6| Step: 5
Training loss: 0.5461711287498474
Validation loss: 2.117291569709778

Epoch: 6| Step: 6
Training loss: 0.29366424679756165
Validation loss: 2.0677269299825034

Epoch: 6| Step: 7
Training loss: 0.31046298146247864
Validation loss: 2.0528069933255515

Epoch: 6| Step: 8
Training loss: 0.26776179671287537
Validation loss: 2.083047866821289

Epoch: 6| Step: 9
Training loss: 0.2326340675354004
Validation loss: 2.04842476050059

Epoch: 6| Step: 10
Training loss: 0.3379812240600586
Validation loss: 2.0600563089052835

Epoch: 6| Step: 11
Training loss: 0.612183690071106
Validation loss: 2.083639979362488

Epoch: 6| Step: 12
Training loss: 0.3427439033985138
Validation loss: 2.0672993659973145

Epoch: 6| Step: 13
Training loss: 0.616884708404541
Validation loss: 2.064467966556549

Epoch: 327| Step: 0
Training loss: 0.4994578957557678
Validation loss: 2.024382253487905

Epoch: 6| Step: 1
Training loss: 0.32833802700042725
Validation loss: 2.1445685227711997

Epoch: 6| Step: 2
Training loss: 0.19942893087863922
Validation loss: 2.0775558153788247

Epoch: 6| Step: 3
Training loss: 0.6002359390258789
Validation loss: 2.113830884297689

Epoch: 6| Step: 4
Training loss: 0.43945348262786865
Validation loss: 2.064913809299469

Epoch: 6| Step: 5
Training loss: 0.3469988703727722
Validation loss: 2.100907822450002

Epoch: 6| Step: 6
Training loss: 0.44545555114746094
Validation loss: 2.081085423628489

Epoch: 6| Step: 7
Training loss: 0.7743747234344482
Validation loss: 2.1077920794487

Epoch: 6| Step: 8
Training loss: 0.4505883753299713
Validation loss: 2.0576278368631997

Epoch: 6| Step: 9
Training loss: 0.23663228750228882
Validation loss: 2.0850502053896585

Epoch: 6| Step: 10
Training loss: 0.36985182762145996
Validation loss: 2.09364906946818

Epoch: 6| Step: 11
Training loss: 0.4827001690864563
Validation loss: 2.1117155949274697

Epoch: 6| Step: 12
Training loss: 0.3994543254375458
Validation loss: 2.1074724197387695

Epoch: 6| Step: 13
Training loss: 0.5029785633087158
Validation loss: 2.1173434456189475

Epoch: 328| Step: 0
Training loss: 0.4807615578174591
Validation loss: 2.0735483368237815

Epoch: 6| Step: 1
Training loss: 0.33941537141799927
Validation loss: 2.1504074732462564

Epoch: 6| Step: 2
Training loss: 0.5708180665969849
Validation loss: 2.088377912839254

Epoch: 6| Step: 3
Training loss: 0.353101909160614
Validation loss: 2.1248232324918113

Epoch: 6| Step: 4
Training loss: 0.36073946952819824
Validation loss: 2.1726330121358237

Epoch: 6| Step: 5
Training loss: 0.4133550822734833
Validation loss: 2.100649118423462

Epoch: 6| Step: 6
Training loss: 0.1804589182138443
Validation loss: 2.096426486968994

Epoch: 6| Step: 7
Training loss: 0.5809648633003235
Validation loss: 2.100526730219523

Epoch: 6| Step: 8
Training loss: 0.4303627610206604
Validation loss: 2.0791332523028054

Epoch: 6| Step: 9
Training loss: 0.26474830508232117
Validation loss: 2.0724061528841653

Epoch: 6| Step: 10
Training loss: 0.4091925621032715
Validation loss: 2.0416194001833596

Epoch: 6| Step: 11
Training loss: 0.8474400043487549
Validation loss: 2.0592602690060935

Epoch: 6| Step: 12
Training loss: 0.3834611773490906
Validation loss: 2.1109771132469177

Epoch: 6| Step: 13
Training loss: 0.6064700484275818
Validation loss: 2.0908855199813843

Epoch: 329| Step: 0
Training loss: 0.4634060263633728
Validation loss: 2.04162460565567

Epoch: 6| Step: 1
Training loss: 0.38973939418792725
Validation loss: 2.050140122572581

Epoch: 6| Step: 2
Training loss: 0.4798242151737213
Validation loss: 2.108161211013794

Epoch: 6| Step: 3
Training loss: 0.27473682165145874
Validation loss: 2.1457152565320334

Epoch: 6| Step: 4
Training loss: 0.5455910563468933
Validation loss: 2.0822160045305886

Epoch: 6| Step: 5
Training loss: 0.19698598980903625
Validation loss: 2.0634605089823403

Epoch: 6| Step: 6
Training loss: 0.22113697230815887
Validation loss: 2.06959460179011

Epoch: 6| Step: 7
Training loss: 0.3027648627758026
Validation loss: 2.0569607615470886

Epoch: 6| Step: 8
Training loss: 0.3024924397468567
Validation loss: 2.076100707054138

Epoch: 6| Step: 9
Training loss: 0.2602100670337677
Validation loss: 2.1135995388031006

Epoch: 6| Step: 10
Training loss: 0.328502893447876
Validation loss: 2.0647665659586587

Epoch: 6| Step: 11
Training loss: 0.9011716842651367
Validation loss: 2.069138288497925

Epoch: 6| Step: 12
Training loss: 0.6445677280426025
Validation loss: 2.0962687134742737

Epoch: 6| Step: 13
Training loss: 0.8017849922180176
Validation loss: 2.0601710081100464

Epoch: 330| Step: 0
Training loss: 0.3028371036052704
Validation loss: 2.054977377255758

Epoch: 6| Step: 1
Training loss: 0.38025277853012085
Validation loss: 2.100627839565277

Epoch: 6| Step: 2
Training loss: 0.458444744348526
Validation loss: 2.125695288181305

Epoch: 6| Step: 3
Training loss: 0.4555695652961731
Validation loss: 2.0259339213371277

Epoch: 6| Step: 4
Training loss: 0.24009032547473907
Validation loss: 2.053477088610331

Epoch: 6| Step: 5
Training loss: 0.30862119793891907
Validation loss: 2.114252765973409

Epoch: 6| Step: 6
Training loss: 0.6335378885269165
Validation loss: 2.142982562383016

Epoch: 6| Step: 7
Training loss: 0.4150375425815582
Validation loss: 2.0953731139500937

Epoch: 6| Step: 8
Training loss: 0.4788179397583008
Validation loss: 2.1442626118659973

Epoch: 6| Step: 9
Training loss: 0.6786225438117981
Validation loss: 2.0960935950279236

Epoch: 6| Step: 10
Training loss: 0.47654294967651367
Validation loss: 2.077467401822408

Epoch: 6| Step: 11
Training loss: 0.34078502655029297
Validation loss: 2.0778071880340576

Epoch: 6| Step: 12
Training loss: 0.5028560757637024
Validation loss: 2.183952530225118

Epoch: 6| Step: 13
Training loss: 0.4750254154205322
Validation loss: 2.069662113984426

Epoch: 331| Step: 0
Training loss: 0.48215144872665405
Validation loss: 2.0973740021387735

Epoch: 6| Step: 1
Training loss: 0.4406193196773529
Validation loss: 2.0462305148442588

Epoch: 6| Step: 2
Training loss: 0.5836009383201599
Validation loss: 2.119115650653839

Epoch: 6| Step: 3
Training loss: 0.5258034467697144
Validation loss: 2.065519372622172

Epoch: 6| Step: 4
Training loss: 0.29920703172683716
Validation loss: 2.1317753195762634

Epoch: 6| Step: 5
Training loss: 0.3917178809642792
Validation loss: 2.1506073276201882

Epoch: 6| Step: 6
Training loss: 0.395699679851532
Validation loss: 2.073042372862498

Epoch: 6| Step: 7
Training loss: 0.4340704083442688
Validation loss: 2.075382649898529

Epoch: 6| Step: 8
Training loss: 0.8885124325752258
Validation loss: 2.1437676350275674

Epoch: 6| Step: 9
Training loss: 0.5522814393043518
Validation loss: 2.060979167620341

Epoch: 6| Step: 10
Training loss: 0.23771058022975922
Validation loss: 2.080391824245453

Epoch: 6| Step: 11
Training loss: 0.24597662687301636
Validation loss: 2.064364194869995

Epoch: 6| Step: 12
Training loss: 0.5600677132606506
Validation loss: 2.1313233772913613

Epoch: 6| Step: 13
Training loss: 0.35017311573028564
Validation loss: 2.1541447838147483

Epoch: 332| Step: 0
Training loss: 0.25674453377723694
Validation loss: 2.086038291454315

Epoch: 6| Step: 1
Training loss: 0.5055021047592163
Validation loss: 2.1380395889282227

Epoch: 6| Step: 2
Training loss: 0.5094277858734131
Validation loss: 2.066376248995463

Epoch: 6| Step: 3
Training loss: 0.648247241973877
Validation loss: 2.0691428581873574

Epoch: 6| Step: 4
Training loss: 0.33298441767692566
Validation loss: 2.0663865407307944

Epoch: 6| Step: 5
Training loss: 0.289050430059433
Validation loss: 2.1102987925211587

Epoch: 6| Step: 6
Training loss: 0.32319650053977966
Validation loss: 2.084034522374471

Epoch: 6| Step: 7
Training loss: 0.4661670923233032
Validation loss: 2.0288320581118264

Epoch: 6| Step: 8
Training loss: 0.4894736111164093
Validation loss: 2.1117945114771524

Epoch: 6| Step: 9
Training loss: 0.7422220706939697
Validation loss: 2.164027750492096

Epoch: 6| Step: 10
Training loss: 0.3665393590927124
Validation loss: 2.137350638707479

Epoch: 6| Step: 11
Training loss: 0.26889580488204956
Validation loss: 2.134643276532491

Epoch: 6| Step: 12
Training loss: 0.4595680832862854
Validation loss: 2.0987090468406677

Epoch: 6| Step: 13
Training loss: 0.38091176748275757
Validation loss: 2.0523919264475503

Epoch: 333| Step: 0
Training loss: 0.4461476504802704
Validation loss: 2.1377579967180886

Epoch: 6| Step: 1
Training loss: 0.5337677001953125
Validation loss: 2.0160412192344666

Epoch: 6| Step: 2
Training loss: 0.4595622420310974
Validation loss: 2.141958753267924

Epoch: 6| Step: 3
Training loss: 0.5344661474227905
Validation loss: 2.093312362829844

Epoch: 6| Step: 4
Training loss: 0.2847115397453308
Validation loss: 2.162399709224701

Epoch: 6| Step: 5
Training loss: 0.2418941855430603
Validation loss: 2.1178332368532815

Epoch: 6| Step: 6
Training loss: 0.2701985836029053
Validation loss: 2.1610660354296365

Epoch: 6| Step: 7
Training loss: 0.6022030115127563
Validation loss: 2.1160839398701987

Epoch: 6| Step: 8
Training loss: 0.3732529580593109
Validation loss: 2.0679778258005777

Epoch: 6| Step: 9
Training loss: 0.5249179601669312
Validation loss: 2.1091983318328857

Epoch: 6| Step: 10
Training loss: 1.0886679887771606
Validation loss: 2.0557544430096946

Epoch: 6| Step: 11
Training loss: 0.32125604152679443
Validation loss: 2.099947730700175

Epoch: 6| Step: 12
Training loss: 0.6108040809631348
Validation loss: 2.0498016277949014

Epoch: 6| Step: 13
Training loss: 0.2914898991584778
Validation loss: 2.1239416003227234

Epoch: 334| Step: 0
Training loss: 0.48388588428497314
Validation loss: 2.079748968283335

Epoch: 6| Step: 1
Training loss: 0.5511457324028015
Validation loss: 2.117244243621826

Epoch: 6| Step: 2
Training loss: 0.38135725259780884
Validation loss: 2.103372077147166

Epoch: 6| Step: 3
Training loss: 0.2356337308883667
Validation loss: 2.0693395336469016

Epoch: 6| Step: 4
Training loss: 0.2953829765319824
Validation loss: 2.0576746066411338

Epoch: 6| Step: 5
Training loss: 0.18483003973960876
Validation loss: 2.0953951676686606

Epoch: 6| Step: 6
Training loss: 0.6015617847442627
Validation loss: 2.1158133347829184

Epoch: 6| Step: 7
Training loss: 1.0861302614212036
Validation loss: 2.1051358381907144

Epoch: 6| Step: 8
Training loss: 0.4056849479675293
Validation loss: 2.0943098862965903

Epoch: 6| Step: 9
Training loss: 0.5127734541893005
Validation loss: 2.132376571496328

Epoch: 6| Step: 10
Training loss: 0.4393550157546997
Validation loss: 2.0506123304367065

Epoch: 6| Step: 11
Training loss: 0.24542731046676636
Validation loss: 2.0487911303838096

Epoch: 6| Step: 12
Training loss: 0.2557774782180786
Validation loss: 2.085413654645284

Epoch: 6| Step: 13
Training loss: 0.3690353035926819
Validation loss: 2.1070233980814614

Epoch: 335| Step: 0
Training loss: 0.39817899465560913
Validation loss: 2.1487776041030884

Epoch: 6| Step: 1
Training loss: 0.2214675098657608
Validation loss: 2.066701829433441

Epoch: 6| Step: 2
Training loss: 0.6168332099914551
Validation loss: 2.058701972166697

Epoch: 6| Step: 3
Training loss: 0.47861120104789734
Validation loss: 2.1022333900133767

Epoch: 6| Step: 4
Training loss: 0.9270426630973816
Validation loss: 2.1432448625564575

Epoch: 6| Step: 5
Training loss: 0.585090696811676
Validation loss: 2.1187280217806497

Epoch: 6| Step: 6
Training loss: 0.4882592558860779
Validation loss: 2.090804119904836

Epoch: 6| Step: 7
Training loss: 0.3293958902359009
Validation loss: 2.0825934608777366

Epoch: 6| Step: 8
Training loss: 0.536657989025116
Validation loss: 2.0811252196629844

Epoch: 6| Step: 9
Training loss: 0.3253106474876404
Validation loss: 2.0587892532348633

Epoch: 6| Step: 10
Training loss: 0.3249562680721283
Validation loss: 2.0483731031417847

Epoch: 6| Step: 11
Training loss: 0.39126983284950256
Validation loss: 2.059875806172689

Epoch: 6| Step: 12
Training loss: 0.19969287514686584
Validation loss: 2.1090996861457825

Epoch: 6| Step: 13
Training loss: 0.4465806484222412
Validation loss: 2.1229858795801797

Epoch: 336| Step: 0
Training loss: 0.3880085349082947
Validation loss: 2.0779338081677756

Epoch: 6| Step: 1
Training loss: 0.4544847309589386
Validation loss: 2.1532906691233316

Epoch: 6| Step: 2
Training loss: 0.88731449842453
Validation loss: 2.1282173792521157

Epoch: 6| Step: 3
Training loss: 0.5331233143806458
Validation loss: 2.105805218219757

Epoch: 6| Step: 4
Training loss: 0.3616105914115906
Validation loss: 2.0880860487620034

Epoch: 6| Step: 5
Training loss: 0.4922332167625427
Validation loss: 2.0603177547454834

Epoch: 6| Step: 6
Training loss: 0.4268939197063446
Validation loss: 2.0658499002456665

Epoch: 6| Step: 7
Training loss: 0.4253694713115692
Validation loss: 2.06184321641922

Epoch: 6| Step: 8
Training loss: 0.29349637031555176
Validation loss: 2.0707777539889016

Epoch: 6| Step: 9
Training loss: 0.37906330823898315
Validation loss: 2.078160504500071

Epoch: 6| Step: 10
Training loss: 0.8104403018951416
Validation loss: 2.089441438515981

Epoch: 6| Step: 11
Training loss: 0.6131268739700317
Validation loss: 2.05937526623408

Epoch: 6| Step: 12
Training loss: 0.38446828722953796
Validation loss: 2.077255288759867

Epoch: 6| Step: 13
Training loss: 0.47787922620773315
Validation loss: 2.1565574407577515

Epoch: 337| Step: 0
Training loss: 0.36477965116500854
Validation loss: 2.112103203932444

Epoch: 6| Step: 1
Training loss: 1.0214805603027344
Validation loss: 2.068570872147878

Epoch: 6| Step: 2
Training loss: 0.28612422943115234
Validation loss: 2.10080357392629

Epoch: 6| Step: 3
Training loss: 0.3136584162712097
Validation loss: 2.1531986196835837

Epoch: 6| Step: 4
Training loss: 0.4431256651878357
Validation loss: 2.1325729290644326

Epoch: 6| Step: 5
Training loss: 0.4369468688964844
Validation loss: 2.086168865362803

Epoch: 6| Step: 6
Training loss: 0.47036704421043396
Validation loss: 2.096816122531891

Epoch: 6| Step: 7
Training loss: 0.350168913602829
Validation loss: 2.119207799434662

Epoch: 6| Step: 8
Training loss: 0.2756197452545166
Validation loss: 2.113772749900818

Epoch: 6| Step: 9
Training loss: 0.4205866754055023
Validation loss: 2.1065171162287393

Epoch: 6| Step: 10
Training loss: 0.5713545083999634
Validation loss: 2.098400294780731

Epoch: 6| Step: 11
Training loss: 0.5891280174255371
Validation loss: 2.0248467524846396

Epoch: 6| Step: 12
Training loss: 0.3677304685115814
Validation loss: 2.118675251801809

Epoch: 6| Step: 13
Training loss: 0.4509700536727905
Validation loss: 2.0568488438924155

Epoch: 338| Step: 0
Training loss: 0.8266851902008057
Validation loss: 2.0636096199353537

Epoch: 6| Step: 1
Training loss: 0.5713781118392944
Validation loss: 2.068485160668691

Epoch: 6| Step: 2
Training loss: 0.3748767077922821
Validation loss: 2.0746009349823

Epoch: 6| Step: 3
Training loss: 0.3714151978492737
Validation loss: 2.01177450021108

Epoch: 6| Step: 4
Training loss: 0.24582818150520325
Validation loss: 2.0839730501174927

Epoch: 6| Step: 5
Training loss: 0.4573536515235901
Validation loss: 2.068733016649882

Epoch: 6| Step: 6
Training loss: 0.5076330304145813
Validation loss: 2.106280565261841

Epoch: 6| Step: 7
Training loss: 0.29191017150878906
Validation loss: 2.029644330342611

Epoch: 6| Step: 8
Training loss: 0.4900919198989868
Validation loss: 2.0936352411905923

Epoch: 6| Step: 9
Training loss: 0.6242550611495972
Validation loss: 2.0629020730654397

Epoch: 6| Step: 10
Training loss: 0.357879102230072
Validation loss: 2.0807530283927917

Epoch: 6| Step: 11
Training loss: 0.38132244348526
Validation loss: 2.119844079017639

Epoch: 6| Step: 12
Training loss: 0.2591532766819
Validation loss: 2.07522181669871

Epoch: 6| Step: 13
Training loss: 0.33416634798049927
Validation loss: 2.108542879422506

Epoch: 339| Step: 0
Training loss: 0.6549025177955627
Validation loss: 2.083073159058889

Epoch: 6| Step: 1
Training loss: 0.42147892713546753
Validation loss: 2.1028404434521994

Epoch: 6| Step: 2
Training loss: 0.34251588582992554
Validation loss: 2.0855919122695923

Epoch: 6| Step: 3
Training loss: 0.2949882447719574
Validation loss: 2.099539319674174

Epoch: 6| Step: 4
Training loss: 0.5900002121925354
Validation loss: 2.0656061371167502

Epoch: 6| Step: 5
Training loss: 0.41578054428100586
Validation loss: 2.094339966773987

Epoch: 6| Step: 6
Training loss: 0.38425230979919434
Validation loss: 2.1034983197848

Epoch: 6| Step: 7
Training loss: 0.36634206771850586
Validation loss: 2.0761035084724426

Epoch: 6| Step: 8
Training loss: 0.31347984075546265
Validation loss: 2.09270171324412

Epoch: 6| Step: 9
Training loss: 0.46851134300231934
Validation loss: 2.038582464059194

Epoch: 6| Step: 10
Training loss: 0.8604114651679993
Validation loss: 2.0410579244295755

Epoch: 6| Step: 11
Training loss: 0.5612541437149048
Validation loss: 2.049654563268026

Epoch: 6| Step: 12
Training loss: 0.3327120542526245
Validation loss: 2.055199940999349

Epoch: 6| Step: 13
Training loss: 0.3273065984249115
Validation loss: 2.0706546306610107

Epoch: 340| Step: 0
Training loss: 0.3904339075088501
Validation loss: 2.093648155530294

Epoch: 6| Step: 1
Training loss: 0.25792402029037476
Validation loss: 2.039958337942759

Epoch: 6| Step: 2
Training loss: 0.2857729196548462
Validation loss: 2.0394529700279236

Epoch: 6| Step: 3
Training loss: 0.23941966891288757
Validation loss: 2.0454790194829306

Epoch: 6| Step: 4
Training loss: 1.1909434795379639
Validation loss: 2.097567399342855

Epoch: 6| Step: 5
Training loss: 0.2841719090938568
Validation loss: 2.065444270769755

Epoch: 6| Step: 6
Training loss: 0.39909034967422485
Validation loss: 2.09308922290802

Epoch: 6| Step: 7
Training loss: 0.3745800256729126
Validation loss: 2.0039620399475098

Epoch: 6| Step: 8
Training loss: 0.4992123544216156
Validation loss: 2.0350545048713684

Epoch: 6| Step: 9
Training loss: 0.39795351028442383
Validation loss: 2.0700100461641946

Epoch: 6| Step: 10
Training loss: 0.5673348307609558
Validation loss: 2.103547434012095

Epoch: 6| Step: 11
Training loss: 0.4745696187019348
Validation loss: 2.0260918736457825

Epoch: 6| Step: 12
Training loss: 0.47806504368782043
Validation loss: 2.0915474692980447

Epoch: 6| Step: 13
Training loss: 0.5101003050804138
Validation loss: 2.0675784746805825

Epoch: 341| Step: 0
Training loss: 0.3537103533744812
Validation loss: 2.1099532643953958

Epoch: 6| Step: 1
Training loss: 0.26820218563079834
Validation loss: 2.1454136768976846

Epoch: 6| Step: 2
Training loss: 0.3492583930492401
Validation loss: 2.1303786039352417

Epoch: 6| Step: 3
Training loss: 0.30753135681152344
Validation loss: 2.039554715156555

Epoch: 6| Step: 4
Training loss: 0.9732210636138916
Validation loss: 2.093952794869741

Epoch: 6| Step: 5
Training loss: 0.20477493107318878
Validation loss: 2.0658891995747886

Epoch: 6| Step: 6
Training loss: 0.4767429530620575
Validation loss: 2.078813135623932

Epoch: 6| Step: 7
Training loss: 0.8185483813285828
Validation loss: 2.125383277734121

Epoch: 6| Step: 8
Training loss: 0.39451292157173157
Validation loss: 2.0757382114728293

Epoch: 6| Step: 9
Training loss: 0.3133400082588196
Validation loss: 2.0781220197677612

Epoch: 6| Step: 10
Training loss: 0.640099048614502
Validation loss: 2.140395144621531

Epoch: 6| Step: 11
Training loss: 0.29294073581695557
Validation loss: 2.1076215505599976

Epoch: 6| Step: 12
Training loss: 0.363766610622406
Validation loss: 2.1188486218452454

Epoch: 6| Step: 13
Training loss: 0.23098933696746826
Validation loss: 2.1013119419415793

Epoch: 342| Step: 0
Training loss: 0.21696189045906067
Validation loss: 2.1446736256281533

Epoch: 6| Step: 1
Training loss: 0.5989751815795898
Validation loss: 2.1169007221857705

Epoch: 6| Step: 2
Training loss: 0.15936553478240967
Validation loss: 2.1294761896133423

Epoch: 6| Step: 3
Training loss: 0.5166045427322388
Validation loss: 2.1344767014185586

Epoch: 6| Step: 4
Training loss: 0.2207947075366974
Validation loss: 2.112472097078959

Epoch: 6| Step: 5
Training loss: 0.618003249168396
Validation loss: 2.0869742035865784

Epoch: 6| Step: 6
Training loss: 0.5290336608886719
Validation loss: 2.11648162206014

Epoch: 6| Step: 7
Training loss: 0.5166075229644775
Validation loss: 2.0783166885375977

Epoch: 6| Step: 8
Training loss: 0.7463444471359253
Validation loss: 2.1624267299969993

Epoch: 6| Step: 9
Training loss: 0.33835914731025696
Validation loss: 2.0837390422821045

Epoch: 6| Step: 10
Training loss: 0.4221718907356262
Validation loss: 2.0613792339960733

Epoch: 6| Step: 11
Training loss: 0.45096254348754883
Validation loss: 2.065871218840281

Epoch: 6| Step: 12
Training loss: 0.6139892339706421
Validation loss: 2.116218070189158

Epoch: 6| Step: 13
Training loss: 0.8901014924049377
Validation loss: 2.1167973279953003

Epoch: 343| Step: 0
Training loss: 0.40710562467575073
Validation loss: 2.116914947827657

Epoch: 6| Step: 1
Training loss: 0.3871247470378876
Validation loss: 2.0988025466601052

Epoch: 6| Step: 2
Training loss: 0.6311836242675781
Validation loss: 2.048021694024404

Epoch: 6| Step: 3
Training loss: 0.29093635082244873
Validation loss: 2.035474340120951

Epoch: 6| Step: 4
Training loss: 0.8396167755126953
Validation loss: 2.080837845802307

Epoch: 6| Step: 5
Training loss: 0.34057146310806274
Validation loss: 2.042503595352173

Epoch: 6| Step: 6
Training loss: 0.520986795425415
Validation loss: 2.0775665044784546

Epoch: 6| Step: 7
Training loss: 0.34797218441963196
Validation loss: 2.0387468338012695

Epoch: 6| Step: 8
Training loss: 0.4428941011428833
Validation loss: 2.103657364845276

Epoch: 6| Step: 9
Training loss: 0.6772748827934265
Validation loss: 2.0355855027834573

Epoch: 6| Step: 10
Training loss: 0.2629268169403076
Validation loss: 2.059576471646627

Epoch: 6| Step: 11
Training loss: 0.2382107824087143
Validation loss: 2.031641403834025

Epoch: 6| Step: 12
Training loss: 0.3868703842163086
Validation loss: 2.096881151199341

Epoch: 6| Step: 13
Training loss: 0.34779149293899536
Validation loss: 2.0274179776509604

Epoch: 344| Step: 0
Training loss: 0.4608810842037201
Validation loss: 2.072280685106913

Epoch: 6| Step: 1
Training loss: 0.4618898034095764
Validation loss: 2.01431397596995

Epoch: 6| Step: 2
Training loss: 0.4503152370452881
Validation loss: 2.1080135901769004

Epoch: 6| Step: 3
Training loss: 0.36296725273132324
Validation loss: 2.1186230381329856

Epoch: 6| Step: 4
Training loss: 0.38652095198631287
Validation loss: 2.0824036598205566

Epoch: 6| Step: 5
Training loss: 0.3210217356681824
Validation loss: 2.034149706363678

Epoch: 6| Step: 6
Training loss: 0.3791404366493225
Validation loss: 2.096022625764211

Epoch: 6| Step: 7
Training loss: 0.3577324450016022
Validation loss: 2.0301228960355124

Epoch: 6| Step: 8
Training loss: 0.37094032764434814
Validation loss: 2.019805113474528

Epoch: 6| Step: 9
Training loss: 0.3333965241909027
Validation loss: 2.047165592511495

Epoch: 6| Step: 10
Training loss: 0.17252007126808167
Validation loss: 2.143624504407247

Epoch: 6| Step: 11
Training loss: 0.8143165111541748
Validation loss: 2.0878305236498513

Epoch: 6| Step: 12
Training loss: 0.29462432861328125
Validation loss: 2.0400097767512

Epoch: 6| Step: 13
Training loss: 0.287562757730484
Validation loss: 2.1072213649749756

Epoch: 345| Step: 0
Training loss: 0.44343361258506775
Validation loss: 2.0800843636194863

Epoch: 6| Step: 1
Training loss: 0.5045046806335449
Validation loss: 2.1294630567232766

Epoch: 6| Step: 2
Training loss: 0.3179071545600891
Validation loss: 2.0790324608484902

Epoch: 6| Step: 3
Training loss: 0.5343029499053955
Validation loss: 2.0597310264905295

Epoch: 6| Step: 4
Training loss: 0.22020766139030457
Validation loss: 2.0435529351234436

Epoch: 6| Step: 5
Training loss: 0.7679397463798523
Validation loss: 2.0845356384913125

Epoch: 6| Step: 6
Training loss: 0.7173015475273132
Validation loss: 2.084575434525808

Epoch: 6| Step: 7
Training loss: 0.437890887260437
Validation loss: 2.0920910835266113

Epoch: 6| Step: 8
Training loss: 0.36389070749282837
Validation loss: 2.13097349802653

Epoch: 6| Step: 9
Training loss: 0.3020319938659668
Validation loss: 2.0360082387924194

Epoch: 6| Step: 10
Training loss: 0.6784002184867859
Validation loss: 2.0504573782285056

Epoch: 6| Step: 11
Training loss: 0.49704432487487793
Validation loss: 2.0859647591908774

Epoch: 6| Step: 12
Training loss: 0.27230632305145264
Validation loss: 2.116846740245819

Epoch: 6| Step: 13
Training loss: 0.28901344537734985
Validation loss: 2.0770153403282166

Epoch: 346| Step: 0
Training loss: 0.35085180401802063
Validation loss: 2.0649685064951577

Epoch: 6| Step: 1
Training loss: 0.48212820291519165
Validation loss: 2.070346931616465

Epoch: 6| Step: 2
Training loss: 0.4621116816997528
Validation loss: 2.0561893781026206

Epoch: 6| Step: 3
Training loss: 0.9117496609687805
Validation loss: 2.061998267968496

Epoch: 6| Step: 4
Training loss: 0.2608579993247986
Validation loss: 2.057539621988932

Epoch: 6| Step: 5
Training loss: 0.325035959482193
Validation loss: 2.05381049712499

Epoch: 6| Step: 6
Training loss: 0.5116467475891113
Validation loss: 2.0813977320988974

Epoch: 6| Step: 7
Training loss: 0.47701889276504517
Validation loss: 2.058131913344065

Epoch: 6| Step: 8
Training loss: 0.5877792835235596
Validation loss: 2.0934088230133057

Epoch: 6| Step: 9
Training loss: 0.39249902963638306
Validation loss: 2.1176238854726157

Epoch: 6| Step: 10
Training loss: 0.6700277328491211
Validation loss: 2.0699519713719687

Epoch: 6| Step: 11
Training loss: 0.26121777296066284
Validation loss: 2.058421274026235

Epoch: 6| Step: 12
Training loss: 0.41109412908554077
Validation loss: 2.055459717909495

Epoch: 6| Step: 13
Training loss: 0.38754817843437195
Validation loss: 2.045092205206553

Epoch: 347| Step: 0
Training loss: 0.30720922350883484
Validation loss: 2.0595524509747825

Epoch: 6| Step: 1
Training loss: 0.6792125701904297
Validation loss: 2.0319555401802063

Epoch: 6| Step: 2
Training loss: 0.9215564727783203
Validation loss: 2.109757125377655

Epoch: 6| Step: 3
Training loss: 0.2599899172782898
Validation loss: 2.0528202255566916

Epoch: 6| Step: 4
Training loss: 0.2707539200782776
Validation loss: 2.072169244289398

Epoch: 6| Step: 5
Training loss: 0.226586252450943
Validation loss: 2.062663714090983

Epoch: 6| Step: 6
Training loss: 0.17109228670597076
Validation loss: 2.0492558081944785

Epoch: 6| Step: 7
Training loss: 0.28096121549606323
Validation loss: 2.050036629041036

Epoch: 6| Step: 8
Training loss: 0.691306471824646
Validation loss: 2.061856726805369

Epoch: 6| Step: 9
Training loss: 0.32843297719955444
Validation loss: 2.0826059579849243

Epoch: 6| Step: 10
Training loss: 0.4804237484931946
Validation loss: 2.1110565066337585

Epoch: 6| Step: 11
Training loss: 0.56208336353302
Validation loss: 2.0451731085777283

Epoch: 6| Step: 12
Training loss: 0.30507892370224
Validation loss: 2.065728267033895

Epoch: 6| Step: 13
Training loss: 0.4795437455177307
Validation loss: 2.057848334312439

Epoch: 348| Step: 0
Training loss: 0.2577049732208252
Validation loss: 2.050721605618795

Epoch: 6| Step: 1
Training loss: 0.26793256402015686
Validation loss: 2.0831193327903748

Epoch: 6| Step: 2
Training loss: 0.249006986618042
Validation loss: 2.0724143981933594

Epoch: 6| Step: 3
Training loss: 0.5986036062240601
Validation loss: 2.0464118917783103

Epoch: 6| Step: 4
Training loss: 0.4476509988307953
Validation loss: 2.0824678540229797

Epoch: 6| Step: 5
Training loss: 0.652108371257782
Validation loss: 2.037663380304972

Epoch: 6| Step: 6
Training loss: 0.3431962728500366
Validation loss: 2.024602949619293

Epoch: 6| Step: 7
Training loss: 0.39241763949394226
Validation loss: 2.0861303408940635

Epoch: 6| Step: 8
Training loss: 0.3134327530860901
Validation loss: 2.0247766375541687

Epoch: 6| Step: 9
Training loss: 0.4151473045349121
Validation loss: 2.056727727254232

Epoch: 6| Step: 10
Training loss: 0.20085395872592926
Validation loss: 2.0467442671457925

Epoch: 6| Step: 11
Training loss: 0.2735447585582733
Validation loss: 2.0944151679674783

Epoch: 6| Step: 12
Training loss: 0.8146133422851562
Validation loss: 2.0429608623186746

Epoch: 6| Step: 13
Training loss: 0.5211548805236816
Validation loss: 2.085249145825704

Epoch: 349| Step: 0
Training loss: 0.2452729344367981
Validation loss: 2.0525818268458047

Epoch: 6| Step: 1
Training loss: 0.3486675024032593
Validation loss: 2.0485328833262124

Epoch: 6| Step: 2
Training loss: 0.2561037540435791
Validation loss: 2.061186750729879

Epoch: 6| Step: 3
Training loss: 0.2918633222579956
Validation loss: 2.121573328971863

Epoch: 6| Step: 4
Training loss: 0.49707910418510437
Validation loss: 2.047068476676941

Epoch: 6| Step: 5
Training loss: 0.51128089427948
Validation loss: 2.0828839937845864

Epoch: 6| Step: 6
Training loss: 0.6015937328338623
Validation loss: 2.043084681034088

Epoch: 6| Step: 7
Training loss: 0.8057401776313782
Validation loss: 2.011943221092224

Epoch: 6| Step: 8
Training loss: 0.2811773419380188
Validation loss: 2.1131572922070823

Epoch: 6| Step: 9
Training loss: 0.2867347002029419
Validation loss: 2.069760719935099

Epoch: 6| Step: 10
Training loss: 0.4162387251853943
Validation loss: 2.0759342312812805

Epoch: 6| Step: 11
Training loss: 0.31050366163253784
Validation loss: 2.0339031418164573

Epoch: 6| Step: 12
Training loss: 0.5185583233833313
Validation loss: 2.0864983201026917

Epoch: 6| Step: 13
Training loss: 0.17100785672664642
Validation loss: 2.039145588874817

Epoch: 350| Step: 0
Training loss: 0.26776444911956787
Validation loss: 2.0988585154215493

Epoch: 6| Step: 1
Training loss: 0.7294643521308899
Validation loss: 2.1127100189526877

Epoch: 6| Step: 2
Training loss: 0.349442720413208
Validation loss: 2.1426015893618264

Epoch: 6| Step: 3
Training loss: 0.6377481818199158
Validation loss: 2.1059993704160056

Epoch: 6| Step: 4
Training loss: 0.42305779457092285
Validation loss: 2.0641713539759317

Epoch: 6| Step: 5
Training loss: 0.29530781507492065
Validation loss: 2.065313438574473

Epoch: 6| Step: 6
Training loss: 0.27189356088638306
Validation loss: 2.0668652852376304

Epoch: 6| Step: 7
Training loss: 0.3729286789894104
Validation loss: 2.0832174817721048

Epoch: 6| Step: 8
Training loss: 0.3328314423561096
Validation loss: 2.0554696520169577

Epoch: 6| Step: 9
Training loss: 0.669293999671936
Validation loss: 2.0057589610417685

Epoch: 6| Step: 10
Training loss: 0.18883121013641357
Validation loss: 2.037196854750315

Epoch: 6| Step: 11
Training loss: 0.2843295931816101
Validation loss: 2.0431320667266846

Epoch: 6| Step: 12
Training loss: 0.49439841508865356
Validation loss: 2.0812334219614663

Epoch: 6| Step: 13
Training loss: 0.3763996958732605
Validation loss: 2.1341196497281394

Epoch: 351| Step: 0
Training loss: 0.24009905755519867
Validation loss: 2.0660215616226196

Epoch: 6| Step: 1
Training loss: 0.2858116030693054
Validation loss: 2.0900317231814065

Epoch: 6| Step: 2
Training loss: 0.9875515103340149
Validation loss: 2.14047118028005

Epoch: 6| Step: 3
Training loss: 0.40484103560447693
Validation loss: 2.1048768758773804

Epoch: 6| Step: 4
Training loss: 0.3188084363937378
Validation loss: 2.1226792335510254

Epoch: 6| Step: 5
Training loss: 0.45145195722579956
Validation loss: 2.1025394797325134

Epoch: 6| Step: 6
Training loss: 0.2087303102016449
Validation loss: 2.099195917447408

Epoch: 6| Step: 7
Training loss: 0.32231849431991577
Validation loss: 2.0859254002571106

Epoch: 6| Step: 8
Training loss: 0.9386945366859436
Validation loss: 2.0464901526769004

Epoch: 6| Step: 9
Training loss: 0.5036798119544983
Validation loss: 2.086613575617472

Epoch: 6| Step: 10
Training loss: 0.44500964879989624
Validation loss: 2.0701733231544495

Epoch: 6| Step: 11
Training loss: 0.29102396965026855
Validation loss: 2.0604295134544373

Epoch: 6| Step: 12
Training loss: 0.2193702757358551
Validation loss: 2.0662668744723

Epoch: 6| Step: 13
Training loss: 0.2507171034812927
Validation loss: 2.1187690893809

Epoch: 352| Step: 0
Training loss: 0.26349377632141113
Validation loss: 2.1208402514457703

Epoch: 6| Step: 1
Training loss: 0.23782393336296082
Validation loss: 2.11783496538798

Epoch: 6| Step: 2
Training loss: 0.18660962581634521
Validation loss: 2.076626400152842

Epoch: 6| Step: 3
Training loss: 0.2517522871494293
Validation loss: 2.08329043785731

Epoch: 6| Step: 4
Training loss: 0.7643833160400391
Validation loss: 2.1214982867240906

Epoch: 6| Step: 5
Training loss: 0.39107251167297363
Validation loss: 2.1151487827301025

Epoch: 6| Step: 6
Training loss: 0.4394734799861908
Validation loss: 2.068724493185679

Epoch: 6| Step: 7
Training loss: 0.2551049590110779
Validation loss: 2.0977593262990317

Epoch: 6| Step: 8
Training loss: 0.4431658685207367
Validation loss: 2.090131163597107

Epoch: 6| Step: 9
Training loss: 0.4184584617614746
Validation loss: 2.0735285878181458

Epoch: 6| Step: 10
Training loss: 0.45022255182266235
Validation loss: 2.078099568684896

Epoch: 6| Step: 11
Training loss: 0.5523042678833008
Validation loss: 2.0527684092521667

Epoch: 6| Step: 12
Training loss: 0.3752604126930237
Validation loss: 2.1004239519437156

Epoch: 6| Step: 13
Training loss: 0.4152805805206299
Validation loss: 2.0944428046544394

Epoch: 353| Step: 0
Training loss: 0.3298620879650116
Validation loss: 2.083712935447693

Epoch: 6| Step: 1
Training loss: 0.22285889089107513
Validation loss: 2.1213208039601645

Epoch: 6| Step: 2
Training loss: 0.44118139147758484
Validation loss: 2.126655697822571

Epoch: 6| Step: 3
Training loss: 0.4645775556564331
Validation loss: 2.15559059381485

Epoch: 6| Step: 4
Training loss: 0.2974964678287506
Validation loss: 2.1120068629582724

Epoch: 6| Step: 5
Training loss: 0.2721647620201111
Validation loss: 2.1129773259162903

Epoch: 6| Step: 6
Training loss: 0.3656490445137024
Validation loss: 2.0809661547342935

Epoch: 6| Step: 7
Training loss: 0.40487658977508545
Validation loss: 2.1053502360979715

Epoch: 6| Step: 8
Training loss: 0.47904282808303833
Validation loss: 2.0610130429267883

Epoch: 6| Step: 9
Training loss: 1.2346347570419312
Validation loss: 2.067196309566498

Epoch: 6| Step: 10
Training loss: 0.2642952799797058
Validation loss: 2.0895445545514426

Epoch: 6| Step: 11
Training loss: 0.3138711154460907
Validation loss: 2.092092971007029

Epoch: 6| Step: 12
Training loss: 0.45869773626327515
Validation loss: 2.1553936998049417

Epoch: 6| Step: 13
Training loss: 0.5001233220100403
Validation loss: 2.0773218472798667

Epoch: 354| Step: 0
Training loss: 0.2651190459728241
Validation loss: 2.0417638619740806

Epoch: 6| Step: 1
Training loss: 0.2675192654132843
Validation loss: 2.0632922053337097

Epoch: 6| Step: 2
Training loss: 0.2377394437789917
Validation loss: 2.111397405465444

Epoch: 6| Step: 3
Training loss: 0.30824652314186096
Validation loss: 2.128436247507731

Epoch: 6| Step: 4
Training loss: 0.6395065784454346
Validation loss: 2.112323760986328

Epoch: 6| Step: 5
Training loss: 0.3508526086807251
Validation loss: 2.1153293450673423

Epoch: 6| Step: 6
Training loss: 0.4800795912742615
Validation loss: 2.1078965067863464

Epoch: 6| Step: 7
Training loss: 0.3925977349281311
Validation loss: 2.115276257197062

Epoch: 6| Step: 8
Training loss: 0.6991898417472839
Validation loss: 2.138416886329651

Epoch: 6| Step: 9
Training loss: 0.29079949855804443
Validation loss: 2.1058640082677207

Epoch: 6| Step: 10
Training loss: 0.3125822842121124
Validation loss: 2.086749851703644

Epoch: 6| Step: 11
Training loss: 0.3992459177970886
Validation loss: 2.0852007071177163

Epoch: 6| Step: 12
Training loss: 0.5222968459129333
Validation loss: 2.070130447546641

Epoch: 6| Step: 13
Training loss: 0.4314234256744385
Validation loss: 2.1355496644973755

Epoch: 355| Step: 0
Training loss: 0.5210326313972473
Validation loss: 2.104982554912567

Epoch: 6| Step: 1
Training loss: 0.280992329120636
Validation loss: 2.017412841320038

Epoch: 6| Step: 2
Training loss: 0.22488489747047424
Validation loss: 2.1020992596944175

Epoch: 6| Step: 3
Training loss: 0.23395892977714539
Validation loss: 2.13978640238444

Epoch: 6| Step: 4
Training loss: 0.20127147436141968
Validation loss: 2.1024701793988547

Epoch: 6| Step: 5
Training loss: 1.0153111219406128
Validation loss: 2.0767460068066916

Epoch: 6| Step: 6
Training loss: 0.3810042142868042
Validation loss: 2.0403146743774414

Epoch: 6| Step: 7
Training loss: 0.23812031745910645
Validation loss: 2.1042245825131736

Epoch: 6| Step: 8
Training loss: 0.5481023788452148
Validation loss: 2.0990049839019775

Epoch: 6| Step: 9
Training loss: 0.6080321073532104
Validation loss: 2.1220136880874634

Epoch: 6| Step: 10
Training loss: 0.24541506171226501
Validation loss: 2.1042794585227966

Epoch: 6| Step: 11
Training loss: 0.39879921078681946
Validation loss: 2.144479672114054

Epoch: 6| Step: 12
Training loss: 0.4804215431213379
Validation loss: 2.0947617292404175

Epoch: 6| Step: 13
Training loss: 0.5845208168029785
Validation loss: 2.161121149857839

Epoch: 356| Step: 0
Training loss: 0.3575659990310669
Validation loss: 2.0032613277435303

Epoch: 6| Step: 1
Training loss: 0.5136156678199768
Validation loss: 2.1532607078552246

Epoch: 6| Step: 2
Training loss: 0.2825949788093567
Validation loss: 2.112134059270223

Epoch: 6| Step: 3
Training loss: 0.4876038730144501
Validation loss: 2.10002338886261

Epoch: 6| Step: 4
Training loss: 0.5557378530502319
Validation loss: 2.1053964495658875

Epoch: 6| Step: 5
Training loss: 0.4703482389450073
Validation loss: 2.1512170235315957

Epoch: 6| Step: 6
Training loss: 0.3318024277687073
Validation loss: 2.0930548707644143

Epoch: 6| Step: 7
Training loss: 0.41411110758781433
Validation loss: 2.134620110193888

Epoch: 6| Step: 8
Training loss: 0.7516450881958008
Validation loss: 2.095958709716797

Epoch: 6| Step: 9
Training loss: 0.5379398465156555
Validation loss: 2.0959816376368203

Epoch: 6| Step: 10
Training loss: 0.2497946321964264
Validation loss: 2.0626226464907327

Epoch: 6| Step: 11
Training loss: 0.46077805757522583
Validation loss: 2.034259617328644

Epoch: 6| Step: 12
Training loss: 0.2882366180419922
Validation loss: 2.0620614886283875

Epoch: 6| Step: 13
Training loss: 0.2643643021583557
Validation loss: 2.0680052439371743

Epoch: 357| Step: 0
Training loss: 0.39661315083503723
Validation loss: 2.0460458993911743

Epoch: 6| Step: 1
Training loss: 0.2025371491909027
Validation loss: 2.0962997873624167

Epoch: 6| Step: 2
Training loss: 0.29469674825668335
Validation loss: 2.042573114236196

Epoch: 6| Step: 3
Training loss: 0.21305371820926666
Validation loss: 2.102834721406301

Epoch: 6| Step: 4
Training loss: 0.8542908430099487
Validation loss: 2.0936988592147827

Epoch: 6| Step: 5
Training loss: 0.47026750445365906
Validation loss: 2.031424880027771

Epoch: 6| Step: 6
Training loss: 0.4408870339393616
Validation loss: 2.0439046820004783

Epoch: 6| Step: 7
Training loss: 0.3173125386238098
Validation loss: 2.025882124900818

Epoch: 6| Step: 8
Training loss: 0.7431056499481201
Validation loss: 2.0774885614713035

Epoch: 6| Step: 9
Training loss: 0.18393678963184357
Validation loss: 2.075500945250193

Epoch: 6| Step: 10
Training loss: 0.5592667460441589
Validation loss: 2.0746071537335715

Epoch: 6| Step: 11
Training loss: 0.2974849343299866
Validation loss: 2.0596882502237954

Epoch: 6| Step: 12
Training loss: 0.21719519793987274
Validation loss: 2.1007637778917947

Epoch: 6| Step: 13
Training loss: 0.27514445781707764
Validation loss: 2.061036467552185

Epoch: 358| Step: 0
Training loss: 0.34286078810691833
Validation loss: 2.0662184953689575

Epoch: 6| Step: 1
Training loss: 0.486952543258667
Validation loss: 2.0645936131477356

Epoch: 6| Step: 2
Training loss: 0.2889319956302643
Validation loss: 2.072809934616089

Epoch: 6| Step: 3
Training loss: 0.4194915294647217
Validation loss: 2.045229136943817

Epoch: 6| Step: 4
Training loss: 0.21829311549663544
Validation loss: 2.15636416276296

Epoch: 6| Step: 5
Training loss: 0.298917680978775
Validation loss: 2.087803860505422

Epoch: 6| Step: 6
Training loss: 0.4037190079689026
Validation loss: 2.1110422213872275

Epoch: 6| Step: 7
Training loss: 0.3272424638271332
Validation loss: 2.0565383632977805

Epoch: 6| Step: 8
Training loss: 0.3748578131198883
Validation loss: 2.113715489705404

Epoch: 6| Step: 9
Training loss: 0.722193717956543
Validation loss: 2.1248380541801453

Epoch: 6| Step: 10
Training loss: 0.49646899104118347
Validation loss: 2.1010727087656655

Epoch: 6| Step: 11
Training loss: 0.5248241424560547
Validation loss: 2.1150197784105935

Epoch: 6| Step: 12
Training loss: 0.37247395515441895
Validation loss: 2.076860189437866

Epoch: 6| Step: 13
Training loss: 0.4467620253562927
Validation loss: 2.048012057940165

Epoch: 359| Step: 0
Training loss: 0.3883844017982483
Validation loss: 2.0879680713017783

Epoch: 6| Step: 1
Training loss: 0.2045057713985443
Validation loss: 2.1197398900985718

Epoch: 6| Step: 2
Training loss: 0.3954363763332367
Validation loss: 2.036013344923655

Epoch: 6| Step: 3
Training loss: 0.4749414920806885
Validation loss: 2.024158557256063

Epoch: 6| Step: 4
Training loss: 0.36539363861083984
Validation loss: 2.032767375310262

Epoch: 6| Step: 5
Training loss: 0.21818652749061584
Validation loss: 2.1382948557535806

Epoch: 6| Step: 6
Training loss: 0.31572225689888
Validation loss: 2.103155533472697

Epoch: 6| Step: 7
Training loss: 0.5940828919410706
Validation loss: 2.0812031626701355

Epoch: 6| Step: 8
Training loss: 0.2885124683380127
Validation loss: 2.0790419379870095

Epoch: 6| Step: 9
Training loss: 0.9917570352554321
Validation loss: 2.0803290804227195

Epoch: 6| Step: 10
Training loss: 0.3067014515399933
Validation loss: 2.07367205619812

Epoch: 6| Step: 11
Training loss: 0.29303795099258423
Validation loss: 2.0979351798693338

Epoch: 6| Step: 12
Training loss: 0.45481055974960327
Validation loss: 2.1080132325490317

Epoch: 6| Step: 13
Training loss: 0.32727712392807007
Validation loss: 2.041726529598236

Epoch: 360| Step: 0
Training loss: 0.2641924023628235
Validation loss: 2.060510516166687

Epoch: 6| Step: 1
Training loss: 0.33205264806747437
Validation loss: 2.0206732749938965

Epoch: 6| Step: 2
Training loss: 0.32356369495391846
Validation loss: 2.071032007535299

Epoch: 6| Step: 3
Training loss: 0.5115058422088623
Validation loss: 2.05613766113917

Epoch: 6| Step: 4
Training loss: 0.3651903569698334
Validation loss: 2.0970184405644736

Epoch: 6| Step: 5
Training loss: 0.9487892389297485
Validation loss: 2.0915485620498657

Epoch: 6| Step: 6
Training loss: 0.6630306243896484
Validation loss: 2.097565253575643

Epoch: 6| Step: 7
Training loss: 0.3774468004703522
Validation loss: 2.107776939868927

Epoch: 6| Step: 8
Training loss: 0.47376808524131775
Validation loss: 2.1097184816996255

Epoch: 6| Step: 9
Training loss: 0.3234451413154602
Validation loss: 2.0894080797831216

Epoch: 6| Step: 10
Training loss: 0.2807950973510742
Validation loss: 2.093980610370636

Epoch: 6| Step: 11
Training loss: 0.3016914129257202
Validation loss: 2.0617753863334656

Epoch: 6| Step: 12
Training loss: 0.2907235622406006
Validation loss: 2.080057064692179

Epoch: 6| Step: 13
Training loss: 0.46213316917419434
Validation loss: 2.0889816880226135

Epoch: 361| Step: 0
Training loss: 0.5666256546974182
Validation loss: 2.0713771184285483

Epoch: 6| Step: 1
Training loss: 0.3725878596305847
Validation loss: 2.0395382841428122

Epoch: 6| Step: 2
Training loss: 0.9879419207572937
Validation loss: 2.08540803194046

Epoch: 6| Step: 3
Training loss: 0.32836639881134033
Validation loss: 2.091849664847056

Epoch: 6| Step: 4
Training loss: 0.32870277762413025
Validation loss: 2.1147480408350625

Epoch: 6| Step: 5
Training loss: 0.27610963582992554
Validation loss: 2.0871055523554483

Epoch: 6| Step: 6
Training loss: 0.4219043254852295
Validation loss: 2.1421448787053428

Epoch: 6| Step: 7
Training loss: 0.35145047307014465
Validation loss: 2.088341216246287

Epoch: 6| Step: 8
Training loss: 0.2072163075208664
Validation loss: 2.1359100341796875

Epoch: 6| Step: 9
Training loss: 0.46364814043045044
Validation loss: 2.071016252040863

Epoch: 6| Step: 10
Training loss: 0.5218326449394226
Validation loss: 2.094784994920095

Epoch: 6| Step: 11
Training loss: 0.3071874976158142
Validation loss: 2.091887593269348

Epoch: 6| Step: 12
Training loss: 0.39795374870300293
Validation loss: 2.11000790198644

Epoch: 6| Step: 13
Training loss: 0.426058828830719
Validation loss: 2.0648950338363647

Epoch: 362| Step: 0
Training loss: 0.3306625485420227
Validation loss: 2.0140186746915183

Epoch: 6| Step: 1
Training loss: 0.24065817892551422
Validation loss: 2.0166176160176597

Epoch: 6| Step: 2
Training loss: 0.29073384404182434
Validation loss: 2.0610093673070273

Epoch: 6| Step: 3
Training loss: 0.6208531856536865
Validation loss: 2.0735632181167603

Epoch: 6| Step: 4
Training loss: 0.39087533950805664
Validation loss: 2.1170528332392373

Epoch: 6| Step: 5
Training loss: 0.6731973886489868
Validation loss: 2.163443366686503

Epoch: 6| Step: 6
Training loss: 0.4720810055732727
Validation loss: 2.0758872429529824

Epoch: 6| Step: 7
Training loss: 0.2466319352388382
Validation loss: 2.061832149823507

Epoch: 6| Step: 8
Training loss: 0.39325714111328125
Validation loss: 2.11281810204188

Epoch: 6| Step: 9
Training loss: 0.2510632276535034
Validation loss: 2.08760658899943

Epoch: 6| Step: 10
Training loss: 0.8710077404975891
Validation loss: 2.075453281402588

Epoch: 6| Step: 11
Training loss: 0.39446261525154114
Validation loss: 2.0809898376464844

Epoch: 6| Step: 12
Training loss: 0.2478792667388916
Validation loss: 2.05680646498998

Epoch: 6| Step: 13
Training loss: 0.28798264265060425
Validation loss: 2.0483764012654624

Epoch: 363| Step: 0
Training loss: 0.2925933301448822
Validation loss: 2.121641159057617

Epoch: 6| Step: 1
Training loss: 0.6510782241821289
Validation loss: 2.1260122855504355

Epoch: 6| Step: 2
Training loss: 0.44390547275543213
Validation loss: 2.0875558455785117

Epoch: 6| Step: 3
Training loss: 0.36266231536865234
Validation loss: 2.039443016052246

Epoch: 6| Step: 4
Training loss: 0.26907414197921753
Validation loss: 2.081331968307495

Epoch: 6| Step: 5
Training loss: 0.34299376606941223
Validation loss: 2.0872815251350403

Epoch: 6| Step: 6
Training loss: 0.3258548974990845
Validation loss: 2.1044224898020425

Epoch: 6| Step: 7
Training loss: 0.4294186234474182
Validation loss: 2.0764092803001404

Epoch: 6| Step: 8
Training loss: 0.9853299856185913
Validation loss: 2.0858254631360373

Epoch: 6| Step: 9
Training loss: 0.2349238097667694
Validation loss: 2.129914700984955

Epoch: 6| Step: 10
Training loss: 0.39954912662506104
Validation loss: 2.0772927006085715

Epoch: 6| Step: 11
Training loss: 0.2671823501586914
Validation loss: 2.1074939370155334

Epoch: 6| Step: 12
Training loss: 0.31030744314193726
Validation loss: 2.0809451142946878

Epoch: 6| Step: 13
Training loss: 0.23505625128746033
Validation loss: 2.127605219682058

Epoch: 364| Step: 0
Training loss: 0.6993837952613831
Validation loss: 2.0798121293385825

Epoch: 6| Step: 1
Training loss: 0.5715937614440918
Validation loss: 2.1281944513320923

Epoch: 6| Step: 2
Training loss: 0.2557612657546997
Validation loss: 2.1180402040481567

Epoch: 6| Step: 3
Training loss: 0.313836932182312
Validation loss: 2.075299541155497

Epoch: 6| Step: 4
Training loss: 0.4431416392326355
Validation loss: 2.1210220058759055

Epoch: 6| Step: 5
Training loss: 0.8219236135482788
Validation loss: 2.102346102396647

Epoch: 6| Step: 6
Training loss: 0.3593185245990753
Validation loss: 2.0938655932744346

Epoch: 6| Step: 7
Training loss: 0.2704143226146698
Validation loss: 2.071820378303528

Epoch: 6| Step: 8
Training loss: 0.3270132541656494
Validation loss: 2.044690489768982

Epoch: 6| Step: 9
Training loss: 0.4349817633628845
Validation loss: 2.0766379833221436

Epoch: 6| Step: 10
Training loss: 0.3417026698589325
Validation loss: 2.1004440983136496

Epoch: 6| Step: 11
Training loss: 0.36014753580093384
Validation loss: 2.1111398537953696

Epoch: 6| Step: 12
Training loss: 0.26339828968048096
Validation loss: 2.072496255238851

Epoch: 6| Step: 13
Training loss: 0.42617857456207275
Validation loss: 2.149314522743225

Epoch: 365| Step: 0
Training loss: 0.4203629493713379
Validation loss: 2.097040275732676

Epoch: 6| Step: 1
Training loss: 0.41628628969192505
Validation loss: 2.075759549935659

Epoch: 6| Step: 2
Training loss: 0.3801019489765167
Validation loss: 2.125361979007721

Epoch: 6| Step: 3
Training loss: 0.33546018600463867
Validation loss: 2.0802372892697654

Epoch: 6| Step: 4
Training loss: 0.3133280873298645
Validation loss: 2.0574323336283364

Epoch: 6| Step: 5
Training loss: 0.2743198871612549
Validation loss: 2.0077924132347107

Epoch: 6| Step: 6
Training loss: 0.2667390704154968
Validation loss: 2.036450465520223

Epoch: 6| Step: 7
Training loss: 0.35256361961364746
Validation loss: 2.0682626565297446

Epoch: 6| Step: 8
Training loss: 0.3823568820953369
Validation loss: 2.051660140355428

Epoch: 6| Step: 9
Training loss: 0.5400558114051819
Validation loss: 1.994732101758321

Epoch: 6| Step: 10
Training loss: 0.6136345267295837
Validation loss: 2.071567396322886

Epoch: 6| Step: 11
Training loss: 0.8927326202392578
Validation loss: 2.0336314042409263

Epoch: 6| Step: 12
Training loss: 0.3621615469455719
Validation loss: 2.047747532526652

Epoch: 6| Step: 13
Training loss: 0.26922833919525146
Validation loss: 2.111146092414856

Epoch: 366| Step: 0
Training loss: 0.41395145654678345
Validation loss: 2.0655383666356406

Epoch: 6| Step: 1
Training loss: 0.6666482090950012
Validation loss: 2.029075105985006

Epoch: 6| Step: 2
Training loss: 0.3651065528392792
Validation loss: 2.0691001415252686

Epoch: 6| Step: 3
Training loss: 0.23880138993263245
Validation loss: 2.075911303361257

Epoch: 6| Step: 4
Training loss: 1.1619960069656372
Validation loss: 2.0511310497919717

Epoch: 6| Step: 5
Training loss: 0.3222753405570984
Validation loss: 2.0696273843447366

Epoch: 6| Step: 6
Training loss: 0.2344713807106018
Validation loss: 2.039910395940145

Epoch: 6| Step: 7
Training loss: 0.3342711329460144
Validation loss: 2.0649439295132956

Epoch: 6| Step: 8
Training loss: 0.2856738865375519
Validation loss: 2.057126760482788

Epoch: 6| Step: 9
Training loss: 0.3783787488937378
Validation loss: 2.0868984858194985

Epoch: 6| Step: 10
Training loss: 0.4049715995788574
Validation loss: 2.086601456006368

Epoch: 6| Step: 11
Training loss: 0.3406129479408264
Validation loss: 2.0692720810572305

Epoch: 6| Step: 12
Training loss: 0.2676859498023987
Validation loss: 2.087049146493276

Epoch: 6| Step: 13
Training loss: 0.2952057421207428
Validation loss: 2.1023936669031777

Epoch: 367| Step: 0
Training loss: 0.30840733647346497
Validation loss: 2.0740168690681458

Epoch: 6| Step: 1
Training loss: 0.3129134476184845
Validation loss: 2.0601308345794678

Epoch: 6| Step: 2
Training loss: 0.2506831884384155
Validation loss: 2.0849698781967163

Epoch: 6| Step: 3
Training loss: 0.3070690333843231
Validation loss: 2.112489918867747

Epoch: 6| Step: 4
Training loss: 0.19525012373924255
Validation loss: 2.089493711789449

Epoch: 6| Step: 5
Training loss: 0.6546032428741455
Validation loss: 2.0579975644747415

Epoch: 6| Step: 6
Training loss: 0.608189046382904
Validation loss: 2.063010315100352

Epoch: 6| Step: 7
Training loss: 0.21745139360427856
Validation loss: 2.0267793933550515

Epoch: 6| Step: 8
Training loss: 0.418169230222702
Validation loss: 2.069649577140808

Epoch: 6| Step: 9
Training loss: 0.45450466871261597
Validation loss: 2.04314523935318

Epoch: 6| Step: 10
Training loss: 0.5231024026870728
Validation loss: 2.099055310090383

Epoch: 6| Step: 11
Training loss: 0.22558413445949554
Validation loss: 2.0971813003222146

Epoch: 6| Step: 12
Training loss: 0.6059274673461914
Validation loss: 2.0932440559069314

Epoch: 6| Step: 13
Training loss: 0.6053186655044556
Validation loss: 2.079863210519155

Epoch: 368| Step: 0
Training loss: 0.7837243676185608
Validation loss: 2.06448886791865

Epoch: 6| Step: 1
Training loss: 0.2573736011981964
Validation loss: 2.0881049036979675

Epoch: 6| Step: 2
Training loss: 0.35412779450416565
Validation loss: 2.0905111829439798

Epoch: 6| Step: 3
Training loss: 0.4340023696422577
Validation loss: 2.0884406765302024

Epoch: 6| Step: 4
Training loss: 0.4796604812145233
Validation loss: 2.06714274485906

Epoch: 6| Step: 5
Training loss: 0.3062247037887573
Validation loss: 2.066418687502543

Epoch: 6| Step: 6
Training loss: 0.55513596534729
Validation loss: 2.040097693602244

Epoch: 6| Step: 7
Training loss: 0.20825965702533722
Validation loss: 2.0768478314081826

Epoch: 6| Step: 8
Training loss: 0.3843456506729126
Validation loss: 2.0980116724967957

Epoch: 6| Step: 9
Training loss: 0.7713382244110107
Validation loss: 2.0636023680369058

Epoch: 6| Step: 10
Training loss: 0.31469905376434326
Validation loss: 2.1058836579322815

Epoch: 6| Step: 11
Training loss: 0.182503804564476
Validation loss: 2.082529366016388

Epoch: 6| Step: 12
Training loss: 0.4116760492324829
Validation loss: 2.027332901954651

Epoch: 6| Step: 13
Training loss: 0.2765747308731079
Validation loss: 2.0728273391723633

Epoch: 369| Step: 0
Training loss: 0.8687322735786438
Validation loss: 2.1000723441441855

Epoch: 6| Step: 1
Training loss: 0.31044381856918335
Validation loss: 2.089591145515442

Epoch: 6| Step: 2
Training loss: 0.3018714487552643
Validation loss: 2.0656419595082602

Epoch: 6| Step: 3
Training loss: 0.5427426099777222
Validation loss: 2.102684438228607

Epoch: 6| Step: 4
Training loss: 0.334904283285141
Validation loss: 2.08567221959432

Epoch: 6| Step: 5
Training loss: 0.4093526303768158
Validation loss: 2.0669127901395163

Epoch: 6| Step: 6
Training loss: 0.6079495549201965
Validation loss: 2.08114222685496

Epoch: 6| Step: 7
Training loss: 0.2454611361026764
Validation loss: 2.0471975604693093

Epoch: 6| Step: 8
Training loss: 0.5397260785102844
Validation loss: 2.0602647066116333

Epoch: 6| Step: 9
Training loss: 0.298366904258728
Validation loss: 2.092561443646749

Epoch: 6| Step: 10
Training loss: 0.3567452132701874
Validation loss: 2.107286830743154

Epoch: 6| Step: 11
Training loss: 0.4155430197715759
Validation loss: 2.097275416056315

Epoch: 6| Step: 12
Training loss: 0.2959787845611572
Validation loss: 2.0539546410242715

Epoch: 6| Step: 13
Training loss: 0.3801942467689514
Validation loss: 2.054054061571757

Epoch: 370| Step: 0
Training loss: 0.9436869621276855
Validation loss: 2.0748804608980813

Epoch: 6| Step: 1
Training loss: 0.3981587290763855
Validation loss: 2.0753464897473655

Epoch: 6| Step: 2
Training loss: 0.23807933926582336
Validation loss: 2.0705316265424094

Epoch: 6| Step: 3
Training loss: 0.2599033713340759
Validation loss: 2.1100117762883506

Epoch: 6| Step: 4
Training loss: 0.5168492794036865
Validation loss: 2.1042024294535318

Epoch: 6| Step: 5
Training loss: 0.5932036638259888
Validation loss: 2.074456830819448

Epoch: 6| Step: 6
Training loss: 0.3257664442062378
Validation loss: 2.055834094683329

Epoch: 6| Step: 7
Training loss: 0.33420082926750183
Validation loss: 2.113934894402822

Epoch: 6| Step: 8
Training loss: 0.311069130897522
Validation loss: 2.051185588041941

Epoch: 6| Step: 9
Training loss: 0.5907827615737915
Validation loss: 2.0580715934435525

Epoch: 6| Step: 10
Training loss: 0.3972444534301758
Validation loss: 2.078039308389028

Epoch: 6| Step: 11
Training loss: 0.29088300466537476
Validation loss: 2.066899319489797

Epoch: 6| Step: 12
Training loss: 0.24331197142601013
Validation loss: 2.1361915866533914

Epoch: 6| Step: 13
Training loss: 0.3341161608695984
Validation loss: 2.1235350171724954

Epoch: 371| Step: 0
Training loss: 0.41570281982421875
Validation loss: 2.114823122819265

Epoch: 6| Step: 1
Training loss: 0.31781715154647827
Validation loss: 2.082999289035797

Epoch: 6| Step: 2
Training loss: 0.5114048719406128
Validation loss: 2.0834603706995645

Epoch: 6| Step: 3
Training loss: 0.4267268180847168
Validation loss: 2.087397277355194

Epoch: 6| Step: 4
Training loss: 0.3887484073638916
Validation loss: 2.0944950779279075

Epoch: 6| Step: 5
Training loss: 0.7893206477165222
Validation loss: 2.094905157883962

Epoch: 6| Step: 6
Training loss: 0.2975950241088867
Validation loss: 2.0853455861409507

Epoch: 6| Step: 7
Training loss: 0.3517563045024872
Validation loss: 2.1167829235394797

Epoch: 6| Step: 8
Training loss: 0.617828369140625
Validation loss: 2.1145774126052856

Epoch: 6| Step: 9
Training loss: 0.3778633177280426
Validation loss: 2.0486197074254355

Epoch: 6| Step: 10
Training loss: 0.30239883065223694
Validation loss: 2.0750734011332193

Epoch: 6| Step: 11
Training loss: 0.20415011048316956
Validation loss: 2.043487787246704

Epoch: 6| Step: 12
Training loss: 0.2744981646537781
Validation loss: 2.1151837905248008

Epoch: 6| Step: 13
Training loss: 0.5031863451004028
Validation loss: 2.136017858982086

Epoch: 372| Step: 0
Training loss: 0.6223593354225159
Validation loss: 2.1105202436447144

Epoch: 6| Step: 1
Training loss: 0.6544695496559143
Validation loss: 2.0985329945882163

Epoch: 6| Step: 2
Training loss: 0.44477781653404236
Validation loss: 2.0825050274531045

Epoch: 6| Step: 3
Training loss: 0.3998669981956482
Validation loss: 2.065832495689392

Epoch: 6| Step: 4
Training loss: 0.18510845303535461
Validation loss: 2.1152052084604898

Epoch: 6| Step: 5
Training loss: 0.6556898951530457
Validation loss: 2.149233877658844

Epoch: 6| Step: 6
Training loss: 0.29925447702407837
Validation loss: 2.1216193238894143

Epoch: 6| Step: 7
Training loss: 0.2914721667766571
Validation loss: 2.125321944554647

Epoch: 6| Step: 8
Training loss: 0.24960121512413025
Validation loss: 2.027537484963735

Epoch: 6| Step: 9
Training loss: 0.24686510860919952
Validation loss: 2.115036904811859

Epoch: 6| Step: 10
Training loss: 0.2233019769191742
Validation loss: 2.065472503503164

Epoch: 6| Step: 11
Training loss: 0.6722402572631836
Validation loss: 2.086370329062144

Epoch: 6| Step: 12
Training loss: 0.28656628727912903
Validation loss: 2.1026188333829245

Epoch: 6| Step: 13
Training loss: 0.26798099279403687
Validation loss: 2.0943022767702737

Epoch: 373| Step: 0
Training loss: 0.26279738545417786
Validation loss: 2.0394640366236367

Epoch: 6| Step: 1
Training loss: 0.6561001539230347
Validation loss: 2.0488940874735513

Epoch: 6| Step: 2
Training loss: 0.3803378641605377
Validation loss: 2.074798901875814

Epoch: 6| Step: 3
Training loss: 0.578302264213562
Validation loss: 2.0632659594217935

Epoch: 6| Step: 4
Training loss: 0.4054734706878662
Validation loss: 2.0614213943481445

Epoch: 6| Step: 5
Training loss: 0.3614944517612457
Validation loss: 2.048995554447174

Epoch: 6| Step: 6
Training loss: 0.26797065138816833
Validation loss: 2.1034792264302573

Epoch: 6| Step: 7
Training loss: 0.5120121836662292
Validation loss: 2.1543545921643577

Epoch: 6| Step: 8
Training loss: 0.5342360734939575
Validation loss: 2.1250627040863037

Epoch: 6| Step: 9
Training loss: 0.496633380651474
Validation loss: 2.095648189385732

Epoch: 6| Step: 10
Training loss: 0.309407114982605
Validation loss: 2.109583000342051

Epoch: 6| Step: 11
Training loss: 0.2926657795906067
Validation loss: 2.101732631524404

Epoch: 6| Step: 12
Training loss: 0.7260861396789551
Validation loss: 2.046380420525869

Epoch: 6| Step: 13
Training loss: 0.6449694037437439
Validation loss: 2.046794275442759

Epoch: 374| Step: 0
Training loss: 0.3938829302787781
Validation loss: 2.0539159576098123

Epoch: 6| Step: 1
Training loss: 0.2818557620048523
Validation loss: 2.014462113380432

Epoch: 6| Step: 2
Training loss: 0.2219422161579132
Validation loss: 2.0805798371632895

Epoch: 6| Step: 3
Training loss: 0.3611503541469574
Validation loss: 2.0508354902267456

Epoch: 6| Step: 4
Training loss: 0.37915897369384766
Validation loss: 2.039521555105845

Epoch: 6| Step: 5
Training loss: 0.2984725832939148
Validation loss: 2.081189672152201

Epoch: 6| Step: 6
Training loss: 0.6977514624595642
Validation loss: 2.040731052557627

Epoch: 6| Step: 7
Training loss: 0.6057161092758179
Validation loss: 2.1046635707219443

Epoch: 6| Step: 8
Training loss: 0.4378200173377991
Validation loss: 2.0230720043182373

Epoch: 6| Step: 9
Training loss: 0.2143859565258026
Validation loss: 2.0603877107302346

Epoch: 6| Step: 10
Training loss: 0.5040733814239502
Validation loss: 2.026045481363932

Epoch: 6| Step: 11
Training loss: 0.33122718334198
Validation loss: 2.0690848231315613

Epoch: 6| Step: 12
Training loss: 0.2909942865371704
Validation loss: 2.029103855292002

Epoch: 6| Step: 13
Training loss: 0.4512678384780884
Validation loss: 2.0692957441012063

Epoch: 375| Step: 0
Training loss: 0.20262889564037323
Validation loss: 2.0285696983337402

Epoch: 6| Step: 1
Training loss: 0.7416434288024902
Validation loss: 2.075534721215566

Epoch: 6| Step: 2
Training loss: 0.2796333432197571
Validation loss: 2.1002750595410666

Epoch: 6| Step: 3
Training loss: 0.31744688749313354
Validation loss: 2.095219135284424

Epoch: 6| Step: 4
Training loss: 0.4491652846336365
Validation loss: 2.0732609629631042

Epoch: 6| Step: 5
Training loss: 0.6121389269828796
Validation loss: 2.082270622253418

Epoch: 6| Step: 6
Training loss: 0.4859415292739868
Validation loss: 2.077745815118154

Epoch: 6| Step: 7
Training loss: 0.3941900134086609
Validation loss: 2.0679237047831216

Epoch: 6| Step: 8
Training loss: 0.43235111236572266
Validation loss: 2.081964353720347

Epoch: 6| Step: 9
Training loss: 0.3550277054309845
Validation loss: 2.0992775360743203

Epoch: 6| Step: 10
Training loss: 0.33535176515579224
Validation loss: 2.097686489423116

Epoch: 6| Step: 11
Training loss: 0.33640027046203613
Validation loss: 2.1088803807894387

Epoch: 6| Step: 12
Training loss: 0.4613046646118164
Validation loss: 2.080654819806417

Epoch: 6| Step: 13
Training loss: 0.2569211721420288
Validation loss: 2.046510557333628

Epoch: 376| Step: 0
Training loss: 0.1766749620437622
Validation loss: 2.0526604056358337

Epoch: 6| Step: 1
Training loss: 0.24413052201271057
Validation loss: 2.086769938468933

Epoch: 6| Step: 2
Training loss: 0.5355600714683533
Validation loss: 2.0590511560440063

Epoch: 6| Step: 3
Training loss: 0.36273112893104553
Validation loss: 2.0734326243400574

Epoch: 6| Step: 4
Training loss: 0.44238483905792236
Validation loss: 2.1101035873095193

Epoch: 6| Step: 5
Training loss: 0.39523711800575256
Validation loss: 2.097401976585388

Epoch: 6| Step: 6
Training loss: 0.47934383153915405
Validation loss: 2.055102586746216

Epoch: 6| Step: 7
Training loss: 0.19269835948944092
Validation loss: 2.0962181886037192

Epoch: 6| Step: 8
Training loss: 0.3400893211364746
Validation loss: 2.0689360896746316

Epoch: 6| Step: 9
Training loss: 0.24769140779972076
Validation loss: 2.072163720925649

Epoch: 6| Step: 10
Training loss: 0.20667701959609985
Validation loss: 2.0841686129570007

Epoch: 6| Step: 11
Training loss: 0.35360801219940186
Validation loss: 2.09128201007843

Epoch: 6| Step: 12
Training loss: 0.8418852686882019
Validation loss: 2.0697397589683533

Epoch: 6| Step: 13
Training loss: 0.30859071016311646
Validation loss: 2.1008039911588035

Epoch: 377| Step: 0
Training loss: 0.3393159508705139
Validation loss: 2.081453005472819

Epoch: 6| Step: 1
Training loss: 0.30832910537719727
Validation loss: 2.1031763156255088

Epoch: 6| Step: 2
Training loss: 0.8058372139930725
Validation loss: 2.078673303127289

Epoch: 6| Step: 3
Training loss: 0.8215211033821106
Validation loss: 2.0565823117891946

Epoch: 6| Step: 4
Training loss: 0.33925122022628784
Validation loss: 2.0478037198384604

Epoch: 6| Step: 5
Training loss: 0.15913531184196472
Validation loss: 2.0177714228630066

Epoch: 6| Step: 6
Training loss: 0.1588643193244934
Validation loss: 2.0942495465278625

Epoch: 6| Step: 7
Training loss: 0.4606870412826538
Validation loss: 2.096070567766825

Epoch: 6| Step: 8
Training loss: 0.2937169075012207
Validation loss: 2.0421996315320334

Epoch: 6| Step: 9
Training loss: 0.41366294026374817
Validation loss: 2.120540499687195

Epoch: 6| Step: 10
Training loss: 0.2834692597389221
Validation loss: 2.09096759557724

Epoch: 6| Step: 11
Training loss: 0.3747531771659851
Validation loss: 2.071026007334391

Epoch: 6| Step: 12
Training loss: 0.2428549975156784
Validation loss: 2.0959953467051187

Epoch: 6| Step: 13
Training loss: 0.2527400851249695
Validation loss: 2.0750723083813987

Epoch: 378| Step: 0
Training loss: 0.4877445697784424
Validation loss: 2.0632332960764566

Epoch: 6| Step: 1
Training loss: 0.3958888053894043
Validation loss: 2.138669570287069

Epoch: 6| Step: 2
Training loss: 0.4141300320625305
Validation loss: 2.0333933234214783

Epoch: 6| Step: 3
Training loss: 0.5287665128707886
Validation loss: 2.094848930835724

Epoch: 6| Step: 4
Training loss: 0.26122212409973145
Validation loss: 2.1123735308647156

Epoch: 6| Step: 5
Training loss: 0.616636335849762
Validation loss: 2.094020346800486

Epoch: 6| Step: 6
Training loss: 0.4026830792427063
Validation loss: 2.121795654296875

Epoch: 6| Step: 7
Training loss: 0.2678598463535309
Validation loss: 2.1263362566630044

Epoch: 6| Step: 8
Training loss: 0.4187524914741516
Validation loss: 2.12192839384079

Epoch: 6| Step: 9
Training loss: 0.6851263642311096
Validation loss: 2.112777372201284

Epoch: 6| Step: 10
Training loss: 0.25074684619903564
Validation loss: 2.087477127710978

Epoch: 6| Step: 11
Training loss: 0.26512712240219116
Validation loss: 2.0943839947382608

Epoch: 6| Step: 12
Training loss: 0.422183632850647
Validation loss: 2.1065635879834494

Epoch: 6| Step: 13
Training loss: 0.30218306183815
Validation loss: 2.131482720375061

Epoch: 379| Step: 0
Training loss: 0.35521984100341797
Validation loss: 2.089372913042704

Epoch: 6| Step: 1
Training loss: 0.24199166893959045
Validation loss: 2.0771822929382324

Epoch: 6| Step: 2
Training loss: 0.19816984236240387
Validation loss: 2.0806065599123635

Epoch: 6| Step: 3
Training loss: 0.2617782950401306
Validation loss: 2.0707370241483054

Epoch: 6| Step: 4
Training loss: 0.5524919033050537
Validation loss: 2.1028957962989807

Epoch: 6| Step: 5
Training loss: 0.3586350679397583
Validation loss: 2.05056103070577

Epoch: 6| Step: 6
Training loss: 0.4756067991256714
Validation loss: 2.125259300072988

Epoch: 6| Step: 7
Training loss: 0.6242574453353882
Validation loss: 2.1284563541412354

Epoch: 6| Step: 8
Training loss: 0.4680948853492737
Validation loss: 2.1071316798528037

Epoch: 6| Step: 9
Training loss: 0.5620202422142029
Validation loss: 2.059942881266276

Epoch: 6| Step: 10
Training loss: 0.301646888256073
Validation loss: 2.078806698322296

Epoch: 6| Step: 11
Training loss: 0.44561830163002014
Validation loss: 2.02939240137736

Epoch: 6| Step: 12
Training loss: 0.23587018251419067
Validation loss: 2.0677353541056314

Epoch: 6| Step: 13
Training loss: 0.40059441328048706
Validation loss: 2.0446337858835855

Epoch: 380| Step: 0
Training loss: 0.7708326578140259
Validation loss: 2.1077446937561035

Epoch: 6| Step: 1
Training loss: 0.2133491039276123
Validation loss: 2.1069501837094626

Epoch: 6| Step: 2
Training loss: 0.17612123489379883
Validation loss: 2.10468727350235

Epoch: 6| Step: 3
Training loss: 0.2949577569961548
Validation loss: 2.121015787124634

Epoch: 6| Step: 4
Training loss: 0.40394556522369385
Validation loss: 2.0480940341949463

Epoch: 6| Step: 5
Training loss: 0.6993730068206787
Validation loss: 2.0438241759936013

Epoch: 6| Step: 6
Training loss: 0.5124856233596802
Validation loss: 2.0451538960138955

Epoch: 6| Step: 7
Training loss: 0.4330407679080963
Validation loss: 2.0505043864250183

Epoch: 6| Step: 8
Training loss: 0.3342474400997162
Validation loss: 2.0535203218460083

Epoch: 6| Step: 9
Training loss: 0.2992442846298218
Validation loss: 2.104884366194407

Epoch: 6| Step: 10
Training loss: 0.406484454870224
Validation loss: 2.0922334790229797

Epoch: 6| Step: 11
Training loss: 0.2499554604291916
Validation loss: 2.0725902716318765

Epoch: 6| Step: 12
Training loss: 0.31723225116729736
Validation loss: 2.1024006803830466

Epoch: 6| Step: 13
Training loss: 0.4669661223888397
Validation loss: 2.127397576967875

Epoch: 381| Step: 0
Training loss: 0.39184874296188354
Validation loss: 2.0953526894251504

Epoch: 6| Step: 1
Training loss: 0.3372915983200073
Validation loss: 2.136126617590586

Epoch: 6| Step: 2
Training loss: 0.35494884848594666
Validation loss: 2.08307554324468

Epoch: 6| Step: 3
Training loss: 1.0047262907028198
Validation loss: 2.0792196393013

Epoch: 6| Step: 4
Training loss: 0.23644933104515076
Validation loss: 2.110752741495768

Epoch: 6| Step: 5
Training loss: 0.4679403305053711
Validation loss: 2.091445883115133

Epoch: 6| Step: 6
Training loss: 0.49202761054039
Validation loss: 2.0905471444129944

Epoch: 6| Step: 7
Training loss: 0.4421197772026062
Validation loss: 2.069119314352671

Epoch: 6| Step: 8
Training loss: 0.2366851270198822
Validation loss: 2.123944660027822

Epoch: 6| Step: 9
Training loss: 0.418718159198761
Validation loss: 2.0805781483650208

Epoch: 6| Step: 10
Training loss: 0.34246331453323364
Validation loss: 2.068818231423696

Epoch: 6| Step: 11
Training loss: 0.2131926566362381
Validation loss: 2.0938875873883567

Epoch: 6| Step: 12
Training loss: 0.28856781125068665
Validation loss: 2.14083065589269

Epoch: 6| Step: 13
Training loss: 0.2591146230697632
Validation loss: 2.1088207562764487

Epoch: 382| Step: 0
Training loss: 0.3822455406188965
Validation loss: 2.113903284072876

Epoch: 6| Step: 1
Training loss: 1.097862958908081
Validation loss: 2.1291744112968445

Epoch: 6| Step: 2
Training loss: 0.24398314952850342
Validation loss: 2.125064432621002

Epoch: 6| Step: 3
Training loss: 0.30771228671073914
Validation loss: 2.093612333138784

Epoch: 6| Step: 4
Training loss: 0.1393866240978241
Validation loss: 2.068552792072296

Epoch: 6| Step: 5
Training loss: 0.516924262046814
Validation loss: 2.076981782913208

Epoch: 6| Step: 6
Training loss: 0.35106581449508667
Validation loss: 2.060323397318522

Epoch: 6| Step: 7
Training loss: 0.28207525610923767
Validation loss: 2.058566947778066

Epoch: 6| Step: 8
Training loss: 0.2135695368051529
Validation loss: 2.061632255713145

Epoch: 6| Step: 9
Training loss: 0.30558812618255615
Validation loss: 2.065819501876831

Epoch: 6| Step: 10
Training loss: 0.33538365364074707
Validation loss: 2.0740734338760376

Epoch: 6| Step: 11
Training loss: 0.21476426720619202
Validation loss: 2.0685999393463135

Epoch: 6| Step: 12
Training loss: 0.43478256464004517
Validation loss: 2.08034219344457

Epoch: 6| Step: 13
Training loss: 0.5012060403823853
Validation loss: 2.0632070899009705

Epoch: 383| Step: 0
Training loss: 0.3450479507446289
Validation loss: 2.134877343972524

Epoch: 6| Step: 1
Training loss: 0.3533848226070404
Validation loss: 2.137875239054362

Epoch: 6| Step: 2
Training loss: 0.2900780141353607
Validation loss: 2.0840452114741006

Epoch: 6| Step: 3
Training loss: 0.4382745027542114
Validation loss: 2.0882153709729514

Epoch: 6| Step: 4
Training loss: 0.5564607381820679
Validation loss: 2.082258383433024

Epoch: 6| Step: 5
Training loss: 0.6233837604522705
Validation loss: 2.0881540973981223

Epoch: 6| Step: 6
Training loss: 0.3599454164505005
Validation loss: 2.0474448800086975

Epoch: 6| Step: 7
Training loss: 0.34648358821868896
Validation loss: 2.0829803148905435

Epoch: 6| Step: 8
Training loss: 0.3377286493778229
Validation loss: 2.1120195984840393

Epoch: 6| Step: 9
Training loss: 0.6847125291824341
Validation loss: 2.117586096127828

Epoch: 6| Step: 10
Training loss: 0.4383239150047302
Validation loss: 2.1311086813608804

Epoch: 6| Step: 11
Training loss: 0.37093493342399597
Validation loss: 2.0731840332349143

Epoch: 6| Step: 12
Training loss: 0.34818413853645325
Validation loss: 2.1128226121266684

Epoch: 6| Step: 13
Training loss: 0.679621696472168
Validation loss: 2.0592497189839682

Epoch: 384| Step: 0
Training loss: 0.48413312435150146
Validation loss: 2.0585397680600486

Epoch: 6| Step: 1
Training loss: 0.6862610578536987
Validation loss: 2.082811415195465

Epoch: 6| Step: 2
Training loss: 0.24253882467746735
Validation loss: 2.030885179837545

Epoch: 6| Step: 3
Training loss: 0.2222740799188614
Validation loss: 2.0743767420450845

Epoch: 6| Step: 4
Training loss: 0.39197778701782227
Validation loss: 2.0702309211095176

Epoch: 6| Step: 5
Training loss: 0.6677230596542358
Validation loss: 2.0803305904070535

Epoch: 6| Step: 6
Training loss: 0.2767033278942108
Validation loss: 2.0674785574277244

Epoch: 6| Step: 7
Training loss: 0.472293496131897
Validation loss: 2.1186492641766868

Epoch: 6| Step: 8
Training loss: 0.24279436469078064
Validation loss: 2.1458335717519126

Epoch: 6| Step: 9
Training loss: 0.54654461145401
Validation loss: 2.1186197996139526

Epoch: 6| Step: 10
Training loss: 0.4692392349243164
Validation loss: 2.1181428829828897

Epoch: 6| Step: 11
Training loss: 0.34022045135498047
Validation loss: 2.118816872437795

Epoch: 6| Step: 12
Training loss: 0.21925170719623566
Validation loss: 2.1144027709960938

Epoch: 6| Step: 13
Training loss: 0.3390185832977295
Validation loss: 2.1350735823313394

Epoch: 385| Step: 0
Training loss: 0.27916333079338074
Validation loss: 2.0566099087397256

Epoch: 6| Step: 1
Training loss: 0.29727256298065186
Validation loss: 2.101860821247101

Epoch: 6| Step: 2
Training loss: 0.598818302154541
Validation loss: 2.1044870217641196

Epoch: 6| Step: 3
Training loss: 0.2572721838951111
Validation loss: 2.0891769329706826

Epoch: 6| Step: 4
Training loss: 0.3170066475868225
Validation loss: 2.162168502807617

Epoch: 6| Step: 5
Training loss: 0.21920882165431976
Validation loss: 2.104563295841217

Epoch: 6| Step: 6
Training loss: 0.42536860704421997
Validation loss: 2.057058314482371

Epoch: 6| Step: 7
Training loss: 0.46521371603012085
Validation loss: 2.1773259242375693

Epoch: 6| Step: 8
Training loss: 0.24460795521736145
Validation loss: 2.0986221631368003

Epoch: 6| Step: 9
Training loss: 0.3852344751358032
Validation loss: 2.07104100783666

Epoch: 6| Step: 10
Training loss: 0.32959046959877014
Validation loss: 2.096696933110555

Epoch: 6| Step: 11
Training loss: 0.463961124420166
Validation loss: 2.0986918608347573

Epoch: 6| Step: 12
Training loss: 0.5160117149353027
Validation loss: 2.075979252656301

Epoch: 6| Step: 13
Training loss: 0.4630591869354248
Validation loss: 2.062549591064453

Epoch: 386| Step: 0
Training loss: 0.2783832550048828
Validation loss: 2.046758313973745

Epoch: 6| Step: 1
Training loss: 0.29036444425582886
Validation loss: 2.0537116328875222

Epoch: 6| Step: 2
Training loss: 0.18332304060459137
Validation loss: 2.0721001029014587

Epoch: 6| Step: 3
Training loss: 0.49272146821022034
Validation loss: 2.1167859633763633

Epoch: 6| Step: 4
Training loss: 0.46756279468536377
Validation loss: 2.1152717073758445

Epoch: 6| Step: 5
Training loss: 0.29217952489852905
Validation loss: 2.068179170290629

Epoch: 6| Step: 6
Training loss: 0.36298882961273193
Validation loss: 2.0911192496617637

Epoch: 6| Step: 7
Training loss: 0.33978092670440674
Validation loss: 2.1087854703267417

Epoch: 6| Step: 8
Training loss: 0.6239984035491943
Validation loss: 2.0517513354619346

Epoch: 6| Step: 9
Training loss: 0.7665728330612183
Validation loss: 2.0771536827087402

Epoch: 6| Step: 10
Training loss: 0.19279637932777405
Validation loss: 2.0256727735201516

Epoch: 6| Step: 11
Training loss: 0.27961599826812744
Validation loss: 2.0919887026151023

Epoch: 6| Step: 12
Training loss: 0.3991967439651489
Validation loss: 2.088794449965159

Epoch: 6| Step: 13
Training loss: 0.46349480748176575
Validation loss: 2.0881970524787903

Epoch: 387| Step: 0
Training loss: 0.3613935112953186
Validation loss: 2.1169081131617227

Epoch: 6| Step: 1
Training loss: 0.38758379220962524
Validation loss: 2.0801021258036294

Epoch: 6| Step: 2
Training loss: 0.6675809621810913
Validation loss: 2.1073246002197266

Epoch: 6| Step: 3
Training loss: 0.3779595196247101
Validation loss: 2.084435065587362

Epoch: 6| Step: 4
Training loss: 0.2869877815246582
Validation loss: 2.129772365093231

Epoch: 6| Step: 5
Training loss: 0.3641807436943054
Validation loss: 2.0413827101389566

Epoch: 6| Step: 6
Training loss: 0.3819763660430908
Validation loss: 2.0492723186810813

Epoch: 6| Step: 7
Training loss: 0.44731006026268005
Validation loss: 2.05266010761261

Epoch: 6| Step: 8
Training loss: 0.50266432762146
Validation loss: 1.9940295219421387

Epoch: 6| Step: 9
Training loss: 0.18100300431251526
Validation loss: 2.089341163635254

Epoch: 6| Step: 10
Training loss: 0.30336058139801025
Validation loss: 2.0706292390823364

Epoch: 6| Step: 11
Training loss: 0.5725252628326416
Validation loss: 2.097880760828654

Epoch: 6| Step: 12
Training loss: 0.22848078608512878
Validation loss: 2.0443581144014993

Epoch: 6| Step: 13
Training loss: 0.3342907130718231
Validation loss: 2.1333021322886148

Epoch: 388| Step: 0
Training loss: 0.5564832091331482
Validation loss: 2.16830575466156

Epoch: 6| Step: 1
Training loss: 0.20926682651042938
Validation loss: 2.1039071083068848

Epoch: 6| Step: 2
Training loss: 0.3093930184841156
Validation loss: 2.046721359093984

Epoch: 6| Step: 3
Training loss: 0.26265496015548706
Validation loss: 2.1129926840464273

Epoch: 6| Step: 4
Training loss: 0.2392382025718689
Validation loss: 2.102384110291799

Epoch: 6| Step: 5
Training loss: 0.47704485058784485
Validation loss: 2.069137136141459

Epoch: 6| Step: 6
Training loss: 0.608315110206604
Validation loss: 2.0923954844474792

Epoch: 6| Step: 7
Training loss: 0.41094210743904114
Validation loss: 2.1065468986829123

Epoch: 6| Step: 8
Training loss: 0.7530872225761414
Validation loss: 2.0829425056775412

Epoch: 6| Step: 9
Training loss: 0.2557135820388794
Validation loss: 2.047465999921163

Epoch: 6| Step: 10
Training loss: 0.2190445065498352
Validation loss: 2.1024513045946756

Epoch: 6| Step: 11
Training loss: 0.2508167326450348
Validation loss: 2.042032321294149

Epoch: 6| Step: 12
Training loss: 0.2082081139087677
Validation loss: 2.0551856756210327

Epoch: 6| Step: 13
Training loss: 0.22563913464546204
Validation loss: 2.0504108468691506

Epoch: 389| Step: 0
Training loss: 0.2649114727973938
Validation loss: 2.057475467522939

Epoch: 6| Step: 1
Training loss: 0.3734493851661682
Validation loss: 2.065571387608846

Epoch: 6| Step: 2
Training loss: 0.6191773414611816
Validation loss: 2.0795185367266336

Epoch: 6| Step: 3
Training loss: 0.30434146523475647
Validation loss: 2.0507485270500183

Epoch: 6| Step: 4
Training loss: 0.39349156618118286
Validation loss: 2.113716185092926

Epoch: 6| Step: 5
Training loss: 0.30871516466140747
Validation loss: 2.042659322420756

Epoch: 6| Step: 6
Training loss: 0.6608511209487915
Validation loss: 2.077334483464559

Epoch: 6| Step: 7
Training loss: 0.3494883179664612
Validation loss: 2.0440812508265176

Epoch: 6| Step: 8
Training loss: 0.5001459121704102
Validation loss: 2.0825424194335938

Epoch: 6| Step: 9
Training loss: 0.23502027988433838
Validation loss: 2.106266419092814

Epoch: 6| Step: 10
Training loss: 0.37619495391845703
Validation loss: 2.0970716079076133

Epoch: 6| Step: 11
Training loss: 0.25653427839279175
Validation loss: 2.0802767475446067

Epoch: 6| Step: 12
Training loss: 0.32510942220687866
Validation loss: 2.063256243864695

Epoch: 6| Step: 13
Training loss: 0.3228651285171509
Validation loss: 2.0681087573369346

Epoch: 390| Step: 0
Training loss: 0.27395984530448914
Validation loss: 2.0734736124674478

Epoch: 6| Step: 1
Training loss: 0.1564522087574005
Validation loss: 2.06014891465505

Epoch: 6| Step: 2
Training loss: 0.4484497308731079
Validation loss: 2.0507126847902932

Epoch: 6| Step: 3
Training loss: 0.389096736907959
Validation loss: 2.088156839211782

Epoch: 6| Step: 4
Training loss: 0.37909549474716187
Validation loss: 2.1040688951810202

Epoch: 6| Step: 5
Training loss: 0.17508357763290405
Validation loss: 2.0953218142191568

Epoch: 6| Step: 6
Training loss: 0.24653497338294983
Validation loss: 2.058291514714559

Epoch: 6| Step: 7
Training loss: 0.41914522647857666
Validation loss: 2.0788386265436807

Epoch: 6| Step: 8
Training loss: 0.3052632212638855
Validation loss: 2.076139450073242

Epoch: 6| Step: 9
Training loss: 0.4105556011199951
Validation loss: 2.0543053150177

Epoch: 6| Step: 10
Training loss: 0.37234216928482056
Validation loss: 2.1189996202786765

Epoch: 6| Step: 11
Training loss: 0.28843677043914795
Validation loss: 2.077821413675944

Epoch: 6| Step: 12
Training loss: 0.6105003356933594
Validation loss: 2.0670889218648276

Epoch: 6| Step: 13
Training loss: 0.7639314532279968
Validation loss: 2.0492921074231467

Epoch: 391| Step: 0
Training loss: 0.3619079291820526
Validation loss: 2.084492047627767

Epoch: 6| Step: 1
Training loss: 0.913550853729248
Validation loss: 2.0696459809939065

Epoch: 6| Step: 2
Training loss: 0.26730602979660034
Validation loss: 2.0565892855326333

Epoch: 6| Step: 3
Training loss: 0.29516303539276123
Validation loss: 2.1531668305397034

Epoch: 6| Step: 4
Training loss: 0.4449830651283264
Validation loss: 2.1226659019788108

Epoch: 6| Step: 5
Training loss: 0.19480837881565094
Validation loss: 2.124734659989675

Epoch: 6| Step: 6
Training loss: 0.2969657778739929
Validation loss: 2.0768890579541526

Epoch: 6| Step: 7
Training loss: 0.3270842432975769
Validation loss: 2.1223228375116983

Epoch: 6| Step: 8
Training loss: 0.3242986798286438
Validation loss: 2.1190121372540793

Epoch: 6| Step: 9
Training loss: 0.5796841382980347
Validation loss: 2.0745966037114463

Epoch: 6| Step: 10
Training loss: 0.4064735174179077
Validation loss: 2.0859989126523337

Epoch: 6| Step: 11
Training loss: 0.4559618830680847
Validation loss: 2.1029890378316245

Epoch: 6| Step: 12
Training loss: 0.2275916337966919
Validation loss: 2.058554232120514

Epoch: 6| Step: 13
Training loss: 0.2960880994796753
Validation loss: 2.082653224468231

Epoch: 392| Step: 0
Training loss: 0.33473092317581177
Validation loss: 2.0791012048721313

Epoch: 6| Step: 1
Training loss: 0.36826902627944946
Validation loss: 2.043996294339498

Epoch: 6| Step: 2
Training loss: 0.6036055088043213
Validation loss: 2.1094716986020408

Epoch: 6| Step: 3
Training loss: 0.30233192443847656
Validation loss: 2.050392131010691

Epoch: 6| Step: 4
Training loss: 0.556228756904602
Validation loss: 2.096805155277252

Epoch: 6| Step: 5
Training loss: 0.8249342441558838
Validation loss: 2.069249411424001

Epoch: 6| Step: 6
Training loss: 0.4414103627204895
Validation loss: 2.130135099093119

Epoch: 6| Step: 7
Training loss: 0.33185675740242004
Validation loss: 2.077664295832316

Epoch: 6| Step: 8
Training loss: 0.5639820694923401
Validation loss: 2.1084304451942444

Epoch: 6| Step: 9
Training loss: 0.41193532943725586
Validation loss: 2.074177086353302

Epoch: 6| Step: 10
Training loss: 0.2062395066022873
Validation loss: 2.124451239903768

Epoch: 6| Step: 11
Training loss: 0.3042536675930023
Validation loss: 2.1195470293362937

Epoch: 6| Step: 12
Training loss: 0.2724439203739166
Validation loss: 2.0646711786588035

Epoch: 6| Step: 13
Training loss: 0.3045485317707062
Validation loss: 2.0937235752741494

Epoch: 393| Step: 0
Training loss: 0.24383515119552612
Validation loss: 2.069031000137329

Epoch: 6| Step: 1
Training loss: 0.35901743173599243
Validation loss: 2.077996810277303

Epoch: 6| Step: 2
Training loss: 0.5639029741287231
Validation loss: 2.1074189941088357

Epoch: 6| Step: 3
Training loss: 0.1409161388874054
Validation loss: 2.1064652800559998

Epoch: 6| Step: 4
Training loss: 0.3934483230113983
Validation loss: 2.072491387526194

Epoch: 6| Step: 5
Training loss: 0.37286949157714844
Validation loss: 2.0356345574061074

Epoch: 6| Step: 6
Training loss: 0.6863268613815308
Validation loss: 2.0524453123410544

Epoch: 6| Step: 7
Training loss: 0.2370302975177765
Validation loss: 2.0943601528803506

Epoch: 6| Step: 8
Training loss: 0.4620926082134247
Validation loss: 2.1128085056940713

Epoch: 6| Step: 9
Training loss: 0.4083259105682373
Validation loss: 2.15125439564387

Epoch: 6| Step: 10
Training loss: 0.26929378509521484
Validation loss: 2.0882652600606284

Epoch: 6| Step: 11
Training loss: 0.39586141705513
Validation loss: 2.09110563993454

Epoch: 6| Step: 12
Training loss: 0.25564730167388916
Validation loss: 2.153155346711477

Epoch: 6| Step: 13
Training loss: 0.7189689874649048
Validation loss: 2.074671904246012

Epoch: 394| Step: 0
Training loss: 0.3124619424343109
Validation loss: 2.1139145493507385

Epoch: 6| Step: 1
Training loss: 0.18336501717567444
Validation loss: 2.132728020350138

Epoch: 6| Step: 2
Training loss: 0.3144373595714569
Validation loss: 2.092710852622986

Epoch: 6| Step: 3
Training loss: 1.0483031272888184
Validation loss: 2.111202597618103

Epoch: 6| Step: 4
Training loss: 0.2877374589443207
Validation loss: 2.1070289611816406

Epoch: 6| Step: 5
Training loss: 0.49373793601989746
Validation loss: 2.0907904307047525

Epoch: 6| Step: 6
Training loss: 0.5339775681495667
Validation loss: 2.0477819442749023

Epoch: 6| Step: 7
Training loss: 0.2999817728996277
Validation loss: 2.09974068403244

Epoch: 6| Step: 8
Training loss: 0.19341132044792175
Validation loss: 2.0760302742322287

Epoch: 6| Step: 9
Training loss: 0.362329363822937
Validation loss: 2.076256732145945

Epoch: 6| Step: 10
Training loss: 0.37773221731185913
Validation loss: 2.0799877444903054

Epoch: 6| Step: 11
Training loss: 0.3900047838687897
Validation loss: 2.1292685667673745

Epoch: 6| Step: 12
Training loss: 0.3680984675884247
Validation loss: 2.1138113538424173

Epoch: 6| Step: 13
Training loss: 0.3980649709701538
Validation loss: 2.099385996659597

Epoch: 395| Step: 0
Training loss: 0.23824766278266907
Validation loss: 2.0974278847376504

Epoch: 6| Step: 1
Training loss: 0.32917341589927673
Validation loss: 2.0703569849332175

Epoch: 6| Step: 2
Training loss: 0.3289279043674469
Validation loss: 2.044019103050232

Epoch: 6| Step: 3
Training loss: 0.5278304815292358
Validation loss: 2.0665703217188516

Epoch: 6| Step: 4
Training loss: 0.5330446362495422
Validation loss: 2.118199427922567

Epoch: 6| Step: 5
Training loss: 0.32632899284362793
Validation loss: 2.0986586213111877

Epoch: 6| Step: 6
Training loss: 0.514958381652832
Validation loss: 2.0296178658803306

Epoch: 6| Step: 7
Training loss: 0.8684350848197937
Validation loss: 2.09418777624766

Epoch: 6| Step: 8
Training loss: 0.29830825328826904
Validation loss: 2.0714709758758545

Epoch: 6| Step: 9
Training loss: 0.13986755907535553
Validation loss: 2.100178897380829

Epoch: 6| Step: 10
Training loss: 0.2954346537590027
Validation loss: 2.10648113489151

Epoch: 6| Step: 11
Training loss: 0.27833735942840576
Validation loss: 2.136016607284546

Epoch: 6| Step: 12
Training loss: 0.4689527750015259
Validation loss: 2.1639334559440613

Epoch: 6| Step: 13
Training loss: 0.3350749611854553
Validation loss: 2.1429333686828613

Epoch: 396| Step: 0
Training loss: 0.6405904293060303
Validation loss: 2.105267643928528

Epoch: 6| Step: 1
Training loss: 0.37185969948768616
Validation loss: 2.1406613985697427

Epoch: 6| Step: 2
Training loss: 0.3752264380455017
Validation loss: 2.0789476235707602

Epoch: 6| Step: 3
Training loss: 0.24935516715049744
Validation loss: 2.078706463177999

Epoch: 6| Step: 4
Training loss: 0.47210392355918884
Validation loss: 2.109072188536326

Epoch: 6| Step: 5
Training loss: 0.3108097314834595
Validation loss: 2.1244298418362937

Epoch: 6| Step: 6
Training loss: 0.259931355714798
Validation loss: 2.0472200314203897

Epoch: 6| Step: 7
Training loss: 0.20621387660503387
Validation loss: 2.1211965680122375

Epoch: 6| Step: 8
Training loss: 0.38930565118789673
Validation loss: 2.0725088715553284

Epoch: 6| Step: 9
Training loss: 0.19227051734924316
Validation loss: 2.112196962038676

Epoch: 6| Step: 10
Training loss: 0.8948431015014648
Validation loss: 2.0791444778442383

Epoch: 6| Step: 11
Training loss: 0.22318021953105927
Validation loss: 2.085322896639506

Epoch: 6| Step: 12
Training loss: 0.5560359954833984
Validation loss: 2.1512888073921204

Epoch: 6| Step: 13
Training loss: 0.3642563819885254
Validation loss: 2.1237069765726724

Epoch: 397| Step: 0
Training loss: 0.27482473850250244
Validation loss: 2.1101985971132913

Epoch: 6| Step: 1
Training loss: 0.49216794967651367
Validation loss: 2.0842540860176086

Epoch: 6| Step: 2
Training loss: 0.2652333974838257
Validation loss: 2.0917590459187827

Epoch: 6| Step: 3
Training loss: 0.9372939467430115
Validation loss: 2.074524740378062

Epoch: 6| Step: 4
Training loss: 0.297687292098999
Validation loss: 2.1293031374613443

Epoch: 6| Step: 5
Training loss: 0.23968328535556793
Validation loss: 2.0765485167503357

Epoch: 6| Step: 6
Training loss: 0.2676783800125122
Validation loss: 2.106796145439148

Epoch: 6| Step: 7
Training loss: 0.283174604177475
Validation loss: 2.0624476869901023

Epoch: 6| Step: 8
Training loss: 0.3055565059185028
Validation loss: 2.0895244677861533

Epoch: 6| Step: 9
Training loss: 0.19773432612419128
Validation loss: 2.1152144273122153

Epoch: 6| Step: 10
Training loss: 0.4397585391998291
Validation loss: 2.130204677581787

Epoch: 6| Step: 11
Training loss: 0.5081344246864319
Validation loss: 2.1157463590304055

Epoch: 6| Step: 12
Training loss: 0.2707768678665161
Validation loss: 2.0881813963254294

Epoch: 6| Step: 13
Training loss: 0.4279266595840454
Validation loss: 2.1048845450083413

Epoch: 398| Step: 0
Training loss: 0.21801285445690155
Validation loss: 2.0957661668459573

Epoch: 6| Step: 1
Training loss: 0.21879452466964722
Validation loss: 2.107899864514669

Epoch: 6| Step: 2
Training loss: 0.2468760460615158
Validation loss: 2.1036019921302795

Epoch: 6| Step: 3
Training loss: 0.309950590133667
Validation loss: 2.0072126388549805

Epoch: 6| Step: 4
Training loss: 0.32783734798431396
Validation loss: 2.1041091084480286

Epoch: 6| Step: 5
Training loss: 1.0143821239471436
Validation loss: 2.0942184726397195

Epoch: 6| Step: 6
Training loss: 0.3005540370941162
Validation loss: 2.0861235658327737

Epoch: 6| Step: 7
Training loss: 0.32272377610206604
Validation loss: 2.145291050275167

Epoch: 6| Step: 8
Training loss: 0.3273877799510956
Validation loss: 2.1082122524579368

Epoch: 6| Step: 9
Training loss: 0.44604915380477905
Validation loss: 2.1228801608085632

Epoch: 6| Step: 10
Training loss: 0.3197605609893799
Validation loss: 2.094513396422068

Epoch: 6| Step: 11
Training loss: 0.5489389896392822
Validation loss: 2.0923811197280884

Epoch: 6| Step: 12
Training loss: 0.48373883962631226
Validation loss: 2.0910894870758057

Epoch: 6| Step: 13
Training loss: 0.290038526058197
Validation loss: 2.0955700675646463

Epoch: 399| Step: 0
Training loss: 0.33503228425979614
Validation loss: 2.085778594017029

Epoch: 6| Step: 1
Training loss: 0.2812763452529907
Validation loss: 2.066934068997701

Epoch: 6| Step: 2
Training loss: 0.3139181137084961
Validation loss: 2.0609131256739297

Epoch: 6| Step: 3
Training loss: 0.22937247157096863
Validation loss: 2.078627586364746

Epoch: 6| Step: 4
Training loss: 0.3229018449783325
Validation loss: 2.0868264635403952

Epoch: 6| Step: 5
Training loss: 0.5468546152114868
Validation loss: 2.094154477119446

Epoch: 6| Step: 6
Training loss: 0.868728756904602
Validation loss: 2.0641912817955017

Epoch: 6| Step: 7
Training loss: 0.2829495072364807
Validation loss: 2.059904158115387

Epoch: 6| Step: 8
Training loss: 0.31749624013900757
Validation loss: 2.0363906820615134

Epoch: 6| Step: 9
Training loss: 0.5009581446647644
Validation loss: 2.07582026720047

Epoch: 6| Step: 10
Training loss: 0.5827062129974365
Validation loss: 2.057991365591685

Epoch: 6| Step: 11
Training loss: 0.3737891912460327
Validation loss: 2.0469088355700173

Epoch: 6| Step: 12
Training loss: 0.2330261468887329
Validation loss: 2.062901039918264

Epoch: 6| Step: 13
Training loss: 0.374100923538208
Validation loss: 2.0671518643697104

Epoch: 400| Step: 0
Training loss: 0.6080405712127686
Validation loss: 2.1241368850072226

Epoch: 6| Step: 1
Training loss: 0.3253059685230255
Validation loss: 2.0994312365849814

Epoch: 6| Step: 2
Training loss: 0.7877288460731506
Validation loss: 2.1184303959210715

Epoch: 6| Step: 3
Training loss: 0.3405071496963501
Validation loss: 2.0420629382133484

Epoch: 6| Step: 4
Training loss: 0.3882678151130676
Validation loss: 2.076055884361267

Epoch: 6| Step: 5
Training loss: 0.478034645318985
Validation loss: 2.0543630917867026

Epoch: 6| Step: 6
Training loss: 0.4658621549606323
Validation loss: 2.088908771673838

Epoch: 6| Step: 7
Training loss: 0.502670168876648
Validation loss: 2.1205061872800193

Epoch: 6| Step: 8
Training loss: 0.28446751832962036
Validation loss: 2.117586135864258

Epoch: 6| Step: 9
Training loss: 0.3061244487762451
Validation loss: 2.075452208518982

Epoch: 6| Step: 10
Training loss: 0.24408726394176483
Validation loss: 2.075090845425924

Epoch: 6| Step: 11
Training loss: 0.2785143256187439
Validation loss: 2.114572823047638

Epoch: 6| Step: 12
Training loss: 0.2925640344619751
Validation loss: 2.114466587702433

Epoch: 6| Step: 13
Training loss: 0.33904528617858887
Validation loss: 2.1444836258888245

Epoch: 401| Step: 0
Training loss: 0.2628852128982544
Validation loss: 2.1223666866620383

Epoch: 6| Step: 1
Training loss: 0.3433009386062622
Validation loss: 2.1645562648773193

Epoch: 6| Step: 2
Training loss: 0.19697946310043335
Validation loss: 2.100458343823751

Epoch: 6| Step: 3
Training loss: 0.5773354768753052
Validation loss: 2.062113960584005

Epoch: 6| Step: 4
Training loss: 0.42850178480148315
Validation loss: 2.1054159800211587

Epoch: 6| Step: 5
Training loss: 0.22111649811267853
Validation loss: 2.122272809346517

Epoch: 6| Step: 6
Training loss: 0.5518014430999756
Validation loss: 2.0885682900746665

Epoch: 6| Step: 7
Training loss: 0.26395636796951294
Validation loss: 2.084188679854075

Epoch: 6| Step: 8
Training loss: 0.32304129004478455
Validation loss: 2.0867601235707602

Epoch: 6| Step: 9
Training loss: 0.21526572108268738
Validation loss: 2.085247278213501

Epoch: 6| Step: 10
Training loss: 0.28517380356788635
Validation loss: 2.1118149161338806

Epoch: 6| Step: 11
Training loss: 0.8245588541030884
Validation loss: 2.124270776907603

Epoch: 6| Step: 12
Training loss: 0.21605150401592255
Validation loss: 2.085037350654602

Epoch: 6| Step: 13
Training loss: 0.36250099539756775
Validation loss: 2.1248276829719543

Epoch: 402| Step: 0
Training loss: 0.33345937728881836
Validation loss: 2.103058636188507

Epoch: 6| Step: 1
Training loss: 0.18155483901500702
Validation loss: 2.143941362698873

Epoch: 6| Step: 2
Training loss: 0.5318570137023926
Validation loss: 2.0785154898961387

Epoch: 6| Step: 3
Training loss: 0.254630982875824
Validation loss: 2.086520791053772

Epoch: 6| Step: 4
Training loss: 0.30040478706359863
Validation loss: 2.1081053018569946

Epoch: 6| Step: 5
Training loss: 0.33135509490966797
Validation loss: 2.085606098175049

Epoch: 6| Step: 6
Training loss: 0.2259143888950348
Validation loss: 2.0680492321650186

Epoch: 6| Step: 7
Training loss: 0.49158596992492676
Validation loss: 2.0602449576059976

Epoch: 6| Step: 8
Training loss: 0.8186652660369873
Validation loss: 2.0710336168607077

Epoch: 6| Step: 9
Training loss: 0.41648709774017334
Validation loss: 2.0617907842000327

Epoch: 6| Step: 10
Training loss: 0.2783048450946808
Validation loss: 2.0874541997909546

Epoch: 6| Step: 11
Training loss: 0.2442011684179306
Validation loss: 2.125006377696991

Epoch: 6| Step: 12
Training loss: 0.3602055311203003
Validation loss: 2.095163345336914

Epoch: 6| Step: 13
Training loss: 0.4035257399082184
Validation loss: 2.122076670328776

Epoch: 403| Step: 0
Training loss: 0.47134849429130554
Validation loss: 2.0472682317097983

Epoch: 6| Step: 1
Training loss: 0.2517359256744385
Validation loss: 2.0928656657536826

Epoch: 6| Step: 2
Training loss: 0.842756986618042
Validation loss: 2.1030154824256897

Epoch: 6| Step: 3
Training loss: 0.46967554092407227
Validation loss: 2.0541181763013205

Epoch: 6| Step: 4
Training loss: 0.28957703709602356
Validation loss: 2.0651777386665344

Epoch: 6| Step: 5
Training loss: 0.27730226516723633
Validation loss: 2.087790568669637

Epoch: 6| Step: 6
Training loss: 0.2916870713233948
Validation loss: 2.054874281088511

Epoch: 6| Step: 7
Training loss: 0.2840174436569214
Validation loss: 2.073912183443705

Epoch: 6| Step: 8
Training loss: 0.3782801926136017
Validation loss: 2.047991712888082

Epoch: 6| Step: 9
Training loss: 0.5895081162452698
Validation loss: 2.0963173111279807

Epoch: 6| Step: 10
Training loss: 0.26163896918296814
Validation loss: 2.125162581602732

Epoch: 6| Step: 11
Training loss: 0.3539896011352539
Validation loss: 2.0970296462376914

Epoch: 6| Step: 12
Training loss: 0.19562332332134247
Validation loss: 2.0926349560419717

Epoch: 6| Step: 13
Training loss: 0.30542686581611633
Validation loss: 2.0995526115099588

Epoch: 404| Step: 0
Training loss: 0.2573668658733368
Validation loss: 2.0394524733225503

Epoch: 6| Step: 1
Training loss: 0.2378019094467163
Validation loss: 2.079707125822703

Epoch: 6| Step: 2
Training loss: 0.5588381290435791
Validation loss: 2.098256746927897

Epoch: 6| Step: 3
Training loss: 0.7275435924530029
Validation loss: 2.081095496813456

Epoch: 6| Step: 4
Training loss: 0.4075503945350647
Validation loss: 2.0411370595296225

Epoch: 6| Step: 5
Training loss: 0.22112853825092316
Validation loss: 2.069329102834066

Epoch: 6| Step: 6
Training loss: 0.2374575436115265
Validation loss: 2.069646676381429

Epoch: 6| Step: 7
Training loss: 0.34177055954933167
Validation loss: 2.108658730983734

Epoch: 6| Step: 8
Training loss: 0.6192641258239746
Validation loss: 2.0964983900388083

Epoch: 6| Step: 9
Training loss: 0.3167886734008789
Validation loss: 2.13208270072937

Epoch: 6| Step: 10
Training loss: 0.26916706562042236
Validation loss: 2.1156720717748008

Epoch: 6| Step: 11
Training loss: 0.3495844602584839
Validation loss: 2.1358514428138733

Epoch: 6| Step: 12
Training loss: 0.31055107712745667
Validation loss: 2.124919136365255

Epoch: 6| Step: 13
Training loss: 0.5668929815292358
Validation loss: 2.107379674911499

Epoch: 405| Step: 0
Training loss: 0.5755313634872437
Validation loss: 2.0773701270421348

Epoch: 6| Step: 1
Training loss: 0.39753612875938416
Validation loss: 2.156707843144735

Epoch: 6| Step: 2
Training loss: 0.3295961618423462
Validation loss: 2.1371471683184304

Epoch: 6| Step: 3
Training loss: 0.3105947971343994
Validation loss: 2.055931011835734

Epoch: 6| Step: 4
Training loss: 0.39948657155036926
Validation loss: 2.1049030224482217

Epoch: 6| Step: 5
Training loss: 0.6861367225646973
Validation loss: 2.1128360430399575

Epoch: 6| Step: 6
Training loss: 0.44897526502609253
Validation loss: 2.0949244300524392

Epoch: 6| Step: 7
Training loss: 0.2572527527809143
Validation loss: 2.077334443728129

Epoch: 6| Step: 8
Training loss: 0.28091442584991455
Validation loss: 2.1320276260375977

Epoch: 6| Step: 9
Training loss: 0.384169340133667
Validation loss: 2.163681427637736

Epoch: 6| Step: 10
Training loss: 0.49421191215515137
Validation loss: 2.1347514192263284

Epoch: 6| Step: 11
Training loss: 0.3155127763748169
Validation loss: 2.086675524711609

Epoch: 6| Step: 12
Training loss: 0.34720951318740845
Validation loss: 2.0924270351727805

Epoch: 6| Step: 13
Training loss: 0.30773264169692993
Validation loss: 2.0969533721605935

Epoch: 406| Step: 0
Training loss: 0.49990755319595337
Validation loss: 2.049325863520304

Epoch: 6| Step: 1
Training loss: 0.837529182434082
Validation loss: 2.077334145704905

Epoch: 6| Step: 2
Training loss: 0.46331506967544556
Validation loss: 2.051839550336202

Epoch: 6| Step: 3
Training loss: 0.1736375093460083
Validation loss: 2.0861772696177163

Epoch: 6| Step: 4
Training loss: 0.23356512188911438
Validation loss: 2.100401838620504

Epoch: 6| Step: 5
Training loss: 0.2835974097251892
Validation loss: 2.0915968815485635

Epoch: 6| Step: 6
Training loss: 0.4608081579208374
Validation loss: 2.0814812978108725

Epoch: 6| Step: 7
Training loss: 0.4573945999145508
Validation loss: 2.0595963994661965

Epoch: 6| Step: 8
Training loss: 0.23855534195899963
Validation loss: 2.0753344098726907

Epoch: 6| Step: 9
Training loss: 0.16267608106136322
Validation loss: 2.1251431504885354

Epoch: 6| Step: 10
Training loss: 0.3062717020511627
Validation loss: 2.099885642528534

Epoch: 6| Step: 11
Training loss: 0.24298229813575745
Validation loss: 2.079123934110006

Epoch: 6| Step: 12
Training loss: 0.24759216606616974
Validation loss: 2.1274242599805198

Epoch: 6| Step: 13
Training loss: 0.2894197702407837
Validation loss: 2.1487574179967246

Epoch: 407| Step: 0
Training loss: 0.38736966252326965
Validation loss: 2.062859137852987

Epoch: 6| Step: 1
Training loss: 0.219326451420784
Validation loss: 2.1732728083928428

Epoch: 6| Step: 2
Training loss: 0.4994180500507355
Validation loss: 2.0966869592666626

Epoch: 6| Step: 3
Training loss: 0.2940024733543396
Validation loss: 2.067094008127848

Epoch: 6| Step: 4
Training loss: 0.8603514432907104
Validation loss: 2.1025611956914267

Epoch: 6| Step: 5
Training loss: 0.27753350138664246
Validation loss: 2.103928784529368

Epoch: 6| Step: 6
Training loss: 0.3210921287536621
Validation loss: 2.0834343433380127

Epoch: 6| Step: 7
Training loss: 0.4661928415298462
Validation loss: 2.095862885316213

Epoch: 6| Step: 8
Training loss: 0.1800205111503601
Validation loss: 2.0411945978800454

Epoch: 6| Step: 9
Training loss: 0.26506516337394714
Validation loss: 2.1070441802342734

Epoch: 6| Step: 10
Training loss: 0.38089752197265625
Validation loss: 2.1508268316586814

Epoch: 6| Step: 11
Training loss: 0.36762934923171997
Validation loss: 2.096090575059255

Epoch: 6| Step: 12
Training loss: 0.40535449981689453
Validation loss: 2.0996216535568237

Epoch: 6| Step: 13
Training loss: 0.23597192764282227
Validation loss: 2.097575565179189

Epoch: 408| Step: 0
Training loss: 0.3788302540779114
Validation loss: 2.0942960182825723

Epoch: 6| Step: 1
Training loss: 0.2929137349128723
Validation loss: 2.068395256996155

Epoch: 6| Step: 2
Training loss: 0.6603453159332275
Validation loss: 2.06127937634786

Epoch: 6| Step: 3
Training loss: 0.3754584491252899
Validation loss: 2.1321163376172385

Epoch: 6| Step: 4
Training loss: 0.3790273666381836
Validation loss: 2.1141494313875833

Epoch: 6| Step: 5
Training loss: 0.9318250417709351
Validation loss: 2.093412538369497

Epoch: 6| Step: 6
Training loss: 0.2753743529319763
Validation loss: 2.064137061436971

Epoch: 6| Step: 7
Training loss: 0.20167939364910126
Validation loss: 2.1297936836878457

Epoch: 6| Step: 8
Training loss: 0.3715071678161621
Validation loss: 2.062788208325704

Epoch: 6| Step: 9
Training loss: 0.28707295656204224
Validation loss: 2.0923798282941184

Epoch: 6| Step: 10
Training loss: 0.39121243357658386
Validation loss: 2.1247284412384033

Epoch: 6| Step: 11
Training loss: 0.3204302489757538
Validation loss: 2.050377905368805

Epoch: 6| Step: 12
Training loss: 0.2286083698272705
Validation loss: 2.0753751595815024

Epoch: 6| Step: 13
Training loss: 0.517578661441803
Validation loss: 2.0902733405431113

Epoch: 409| Step: 0
Training loss: 0.2685047686100006
Validation loss: 2.0925646821657815

Epoch: 6| Step: 1
Training loss: 0.2990531027317047
Validation loss: 2.1095555623372397

Epoch: 6| Step: 2
Training loss: 0.8094326853752136
Validation loss: 2.05164368947347

Epoch: 6| Step: 3
Training loss: 0.3095513582229614
Validation loss: 2.084963858127594

Epoch: 6| Step: 4
Training loss: 0.6293227672576904
Validation loss: 2.0855252544085183

Epoch: 6| Step: 5
Training loss: 0.4142567217350006
Validation loss: 2.053121328353882

Epoch: 6| Step: 6
Training loss: 0.26596570014953613
Validation loss: 2.034567356109619

Epoch: 6| Step: 7
Training loss: 0.44484883546829224
Validation loss: 2.0865927934646606

Epoch: 6| Step: 8
Training loss: 0.27268221974372864
Validation loss: 2.078823228677114

Epoch: 6| Step: 9
Training loss: 0.2115282118320465
Validation loss: 2.1024831533432007

Epoch: 6| Step: 10
Training loss: 0.44896793365478516
Validation loss: 2.054458578427633

Epoch: 6| Step: 11
Training loss: 0.32691437005996704
Validation loss: 2.0656001766522727

Epoch: 6| Step: 12
Training loss: 0.32123124599456787
Validation loss: 2.034589727719625

Epoch: 6| Step: 13
Training loss: 0.3796643018722534
Validation loss: 2.0878988107045493

Epoch: 410| Step: 0
Training loss: 0.470842182636261
Validation loss: 2.131301522254944

Epoch: 6| Step: 1
Training loss: 0.35130321979522705
Validation loss: 2.0843566258748374

Epoch: 6| Step: 2
Training loss: 0.3193013668060303
Validation loss: 2.079797069231669

Epoch: 6| Step: 3
Training loss: 0.32672736048698425
Validation loss: 2.0935633381207785

Epoch: 6| Step: 4
Training loss: 0.268475204706192
Validation loss: 2.0423460801442466

Epoch: 6| Step: 5
Training loss: 0.28839293122291565
Validation loss: 2.0959025422732034

Epoch: 6| Step: 6
Training loss: 0.39548543095588684
Validation loss: 2.082932492097219

Epoch: 6| Step: 7
Training loss: 0.47006210684776306
Validation loss: 2.0631136496861777

Epoch: 6| Step: 8
Training loss: 0.627677321434021
Validation loss: 2.0965668161710105

Epoch: 6| Step: 9
Training loss: 0.31932419538497925
Validation loss: 2.0710649887720742

Epoch: 6| Step: 10
Training loss: 0.2199472188949585
Validation loss: 2.125816524028778

Epoch: 6| Step: 11
Training loss: 0.30577701330184937
Validation loss: 2.1199610829353333

Epoch: 6| Step: 12
Training loss: 0.20732460916042328
Validation loss: 2.1502477327982583

Epoch: 6| Step: 13
Training loss: 0.719550609588623
Validation loss: 2.089917004108429

Epoch: 411| Step: 0
Training loss: 0.312183678150177
Validation loss: 2.1080315510431924

Epoch: 6| Step: 1
Training loss: 0.8627328276634216
Validation loss: 2.1350021362304688

Epoch: 6| Step: 2
Training loss: 0.3907843232154846
Validation loss: 2.1362606287002563

Epoch: 6| Step: 3
Training loss: 0.2524746060371399
Validation loss: 2.137576460838318

Epoch: 6| Step: 4
Training loss: 0.34492889046669006
Validation loss: 2.1016894578933716

Epoch: 6| Step: 5
Training loss: 0.3686336874961853
Validation loss: 2.055710772673289

Epoch: 6| Step: 6
Training loss: 0.5097648501396179
Validation loss: 2.047245502471924

Epoch: 6| Step: 7
Training loss: 0.3672361373901367
Validation loss: 2.0095527370770774

Epoch: 6| Step: 8
Training loss: 0.2688712477684021
Validation loss: 2.0988614757855735

Epoch: 6| Step: 9
Training loss: 0.47721052169799805
Validation loss: 2.086628576119741

Epoch: 6| Step: 10
Training loss: 0.4522426426410675
Validation loss: 2.070238928000132

Epoch: 6| Step: 11
Training loss: 0.22533175349235535
Validation loss: 2.063784639040629

Epoch: 6| Step: 12
Training loss: 0.49644848704338074
Validation loss: 2.090032637119293

Epoch: 6| Step: 13
Training loss: 0.2343159019947052
Validation loss: 2.054600934187571

Epoch: 412| Step: 0
Training loss: 0.42397788166999817
Validation loss: 2.118640045324961

Epoch: 6| Step: 1
Training loss: 0.40801382064819336
Validation loss: 2.07316001256307

Epoch: 6| Step: 2
Training loss: 0.8777430057525635
Validation loss: 2.1206530133883157

Epoch: 6| Step: 3
Training loss: 0.37573111057281494
Validation loss: 2.06460702419281

Epoch: 6| Step: 4
Training loss: 0.3357418179512024
Validation loss: 2.1157690485318503

Epoch: 6| Step: 5
Training loss: 0.33962422609329224
Validation loss: 2.0986334482828775

Epoch: 6| Step: 6
Training loss: 0.35504892468452454
Validation loss: 2.1147680083910623

Epoch: 6| Step: 7
Training loss: 0.15947800874710083
Validation loss: 2.0153333147366843

Epoch: 6| Step: 8
Training loss: 0.2086845338344574
Validation loss: 2.077301025390625

Epoch: 6| Step: 9
Training loss: 0.38637682795524597
Validation loss: 2.1066326101620994

Epoch: 6| Step: 10
Training loss: 0.2744891345500946
Validation loss: 2.069445470968882

Epoch: 6| Step: 11
Training loss: 0.2623435854911804
Validation loss: 2.1054513851801553

Epoch: 6| Step: 12
Training loss: 0.27112144231796265
Validation loss: 2.1306795676549277

Epoch: 6| Step: 13
Training loss: 0.5246438980102539
Validation loss: 2.0978789726893106

Epoch: 413| Step: 0
Training loss: 0.7945918440818787
Validation loss: 2.08385968208313

Epoch: 6| Step: 1
Training loss: 0.5554876327514648
Validation loss: 2.1167392333348594

Epoch: 6| Step: 2
Training loss: 0.32692950963974
Validation loss: 2.117900530497233

Epoch: 6| Step: 3
Training loss: 0.4709615111351013
Validation loss: 2.1216688553492227

Epoch: 6| Step: 4
Training loss: 0.21353617310523987
Validation loss: 2.0808664560317993

Epoch: 6| Step: 5
Training loss: 0.249067485332489
Validation loss: 2.0805986523628235

Epoch: 6| Step: 6
Training loss: 0.48777103424072266
Validation loss: 2.060651262601217

Epoch: 6| Step: 7
Training loss: 0.35138970613479614
Validation loss: 2.086690604686737

Epoch: 6| Step: 8
Training loss: 0.2834419906139374
Validation loss: 2.120153228441874

Epoch: 6| Step: 9
Training loss: 0.34760087728500366
Validation loss: 2.0838899413744607

Epoch: 6| Step: 10
Training loss: 0.40076547861099243
Validation loss: 2.086606423060099

Epoch: 6| Step: 11
Training loss: 0.41317275166511536
Validation loss: 2.098682085673014

Epoch: 6| Step: 12
Training loss: 0.36076706647872925
Validation loss: 2.1351260940233865

Epoch: 6| Step: 13
Training loss: 0.3199186325073242
Validation loss: 2.117335319519043

Epoch: 414| Step: 0
Training loss: 0.28194108605384827
Validation loss: 2.1183104316393533

Epoch: 6| Step: 1
Training loss: 0.2649475038051605
Validation loss: 2.129358649253845

Epoch: 6| Step: 2
Training loss: 0.31620025634765625
Validation loss: 2.096895615259806

Epoch: 6| Step: 3
Training loss: 0.5638777613639832
Validation loss: 2.094707747300466

Epoch: 6| Step: 4
Training loss: 0.32507577538490295
Validation loss: 2.088123361269633

Epoch: 6| Step: 5
Training loss: 0.3786124587059021
Validation loss: 2.1009130676587424

Epoch: 6| Step: 6
Training loss: 0.3718261122703552
Validation loss: 2.094612638155619

Epoch: 6| Step: 7
Training loss: 0.38326287269592285
Validation loss: 2.036642551422119

Epoch: 6| Step: 8
Training loss: 0.33355802297592163
Validation loss: 2.1181172132492065

Epoch: 6| Step: 9
Training loss: 0.2929561734199524
Validation loss: 2.0702098409334817

Epoch: 6| Step: 10
Training loss: 0.12245537340641022
Validation loss: 2.1135865648587546

Epoch: 6| Step: 11
Training loss: 0.5535317659378052
Validation loss: 2.107228676478068

Epoch: 6| Step: 12
Training loss: 0.7225229144096375
Validation loss: 2.0449982484181723

Epoch: 6| Step: 13
Training loss: 0.25710177421569824
Validation loss: 2.1206130584081015

Epoch: 415| Step: 0
Training loss: 0.47987914085388184
Validation loss: 2.1446431279182434

Epoch: 6| Step: 1
Training loss: 0.3683900833129883
Validation loss: 2.090378999710083

Epoch: 6| Step: 2
Training loss: 0.712064266204834
Validation loss: 2.0745537678400674

Epoch: 6| Step: 3
Training loss: 0.22926148772239685
Validation loss: 2.124318857987722

Epoch: 6| Step: 4
Training loss: 0.3056319057941437
Validation loss: 2.059695820013682

Epoch: 6| Step: 5
Training loss: 0.3177027702331543
Validation loss: 2.108547568321228

Epoch: 6| Step: 6
Training loss: 0.41117388010025024
Validation loss: 2.0700455705324807

Epoch: 6| Step: 7
Training loss: 0.37963446974754333
Validation loss: 2.1007933020591736

Epoch: 6| Step: 8
Training loss: 0.3351059854030609
Validation loss: 2.1407472292582193

Epoch: 6| Step: 9
Training loss: 0.41598573327064514
Validation loss: 2.0751288334528604

Epoch: 6| Step: 10
Training loss: 0.3090478181838989
Validation loss: 2.078245977560679

Epoch: 6| Step: 11
Training loss: 0.19568488001823425
Validation loss: 2.1252301136652627

Epoch: 6| Step: 12
Training loss: 0.3084883987903595
Validation loss: 2.0650654435157776

Epoch: 6| Step: 13
Training loss: 0.2792041599750519
Validation loss: 2.120443125565847

Epoch: 416| Step: 0
Training loss: 0.24345868825912476
Validation loss: 2.089575787385305

Epoch: 6| Step: 1
Training loss: 0.32330384850502014
Validation loss: 2.137854437033335

Epoch: 6| Step: 2
Training loss: 0.20308658480644226
Validation loss: 2.0896527568499246

Epoch: 6| Step: 3
Training loss: 0.27065032720565796
Validation loss: 2.110593875249227

Epoch: 6| Step: 4
Training loss: 0.3141835331916809
Validation loss: 2.033427973588308

Epoch: 6| Step: 5
Training loss: 0.2819681167602539
Validation loss: 2.086221675078074

Epoch: 6| Step: 6
Training loss: 1.062347412109375
Validation loss: 2.119082033634186

Epoch: 6| Step: 7
Training loss: 0.27744948863983154
Validation loss: 2.070240577061971

Epoch: 6| Step: 8
Training loss: 0.1927080750465393
Validation loss: 2.0889986952145896

Epoch: 6| Step: 9
Training loss: 0.4329502284526825
Validation loss: 2.078446706136068

Epoch: 6| Step: 10
Training loss: 0.3486912250518799
Validation loss: 2.1103856563568115

Epoch: 6| Step: 11
Training loss: 0.32408779859542847
Validation loss: 2.0642473697662354

Epoch: 6| Step: 12
Training loss: 0.2780790328979492
Validation loss: 2.086656947930654

Epoch: 6| Step: 13
Training loss: 0.2319907695055008
Validation loss: 2.127733826637268

Epoch: 417| Step: 0
Training loss: 0.25031107664108276
Validation loss: 2.1448543866475425

Epoch: 6| Step: 1
Training loss: 0.19739438593387604
Validation loss: 2.0844447215398154

Epoch: 6| Step: 2
Training loss: 0.19251400232315063
Validation loss: 2.0848942001660666

Epoch: 6| Step: 3
Training loss: 0.35747528076171875
Validation loss: 2.1318837801615396

Epoch: 6| Step: 4
Training loss: 0.3353610038757324
Validation loss: 2.1063202818234763

Epoch: 6| Step: 5
Training loss: 0.43378207087516785
Validation loss: 2.1499557296435037

Epoch: 6| Step: 6
Training loss: 0.2563885450363159
Validation loss: 2.124533951282501

Epoch: 6| Step: 7
Training loss: 0.590401291847229
Validation loss: 2.083059251308441

Epoch: 6| Step: 8
Training loss: 0.8797774314880371
Validation loss: 2.135817527770996

Epoch: 6| Step: 9
Training loss: 0.30624258518218994
Validation loss: 2.0649619698524475

Epoch: 6| Step: 10
Training loss: 0.30800580978393555
Validation loss: 2.1177246371905007

Epoch: 6| Step: 11
Training loss: 0.20964346826076508
Validation loss: 2.1205648382504783

Epoch: 6| Step: 12
Training loss: 0.6786882281303406
Validation loss: 2.0986680388450623

Epoch: 6| Step: 13
Training loss: 0.3041827082633972
Validation loss: 2.10900084177653

Epoch: 418| Step: 0
Training loss: 0.2815883755683899
Validation loss: 2.1040314038594565

Epoch: 6| Step: 1
Training loss: 0.23486563563346863
Validation loss: 2.0750340620676675

Epoch: 6| Step: 2
Training loss: 0.25115013122558594
Validation loss: 2.0853270490964255

Epoch: 6| Step: 3
Training loss: 0.21483898162841797
Validation loss: 2.1027019023895264

Epoch: 6| Step: 4
Training loss: 0.2313404381275177
Validation loss: 2.0919129451115928

Epoch: 6| Step: 5
Training loss: 0.34850621223449707
Validation loss: 2.090723176797231

Epoch: 6| Step: 6
Training loss: 0.41261762380599976
Validation loss: 2.0627456108729043

Epoch: 6| Step: 7
Training loss: 0.45698389410972595
Validation loss: 2.076573630174001

Epoch: 6| Step: 8
Training loss: 0.3258870840072632
Validation loss: 2.0847947796185813

Epoch: 6| Step: 9
Training loss: 0.3307842016220093
Validation loss: 2.1236268480618796

Epoch: 6| Step: 10
Training loss: 0.2085489183664322
Validation loss: 2.0619472662607827

Epoch: 6| Step: 11
Training loss: 0.7929548621177673
Validation loss: 2.0770886540412903

Epoch: 6| Step: 12
Training loss: 0.4446120262145996
Validation loss: 2.130930244922638

Epoch: 6| Step: 13
Training loss: 0.2940424680709839
Validation loss: 2.0694671670595803

Epoch: 419| Step: 0
Training loss: 0.28175580501556396
Validation loss: 2.098764657974243

Epoch: 6| Step: 1
Training loss: 0.18975982069969177
Validation loss: 2.0990118185679116

Epoch: 6| Step: 2
Training loss: 0.15835273265838623
Validation loss: 2.1083911061286926

Epoch: 6| Step: 3
Training loss: 0.18111643195152283
Validation loss: 2.1098742683728537

Epoch: 6| Step: 4
Training loss: 0.38506102561950684
Validation loss: 2.1357012391090393

Epoch: 6| Step: 5
Training loss: 0.22859925031661987
Validation loss: 2.0966426531473794

Epoch: 6| Step: 6
Training loss: 0.3273595869541168
Validation loss: 2.0831284523010254

Epoch: 6| Step: 7
Training loss: 0.34988564252853394
Validation loss: 2.0657305121421814

Epoch: 6| Step: 8
Training loss: 0.32376837730407715
Validation loss: 2.0392191211382547

Epoch: 6| Step: 9
Training loss: 0.3084647059440613
Validation loss: 2.0762741367022195

Epoch: 6| Step: 10
Training loss: 0.4640595316886902
Validation loss: 2.1311519344647727

Epoch: 6| Step: 11
Training loss: 0.7059047818183899
Validation loss: 2.069745500882467

Epoch: 6| Step: 12
Training loss: 0.3702600598335266
Validation loss: 2.0453496972719827

Epoch: 6| Step: 13
Training loss: 0.6340099573135376
Validation loss: 2.164187490940094

Epoch: 420| Step: 0
Training loss: 0.3884662985801697
Validation loss: 2.151896854241689

Epoch: 6| Step: 1
Training loss: 0.323405385017395
Validation loss: 2.131782114505768

Epoch: 6| Step: 2
Training loss: 0.2541857063770294
Validation loss: 2.110663811365763

Epoch: 6| Step: 3
Training loss: 0.5948551893234253
Validation loss: 2.1274996598561606

Epoch: 6| Step: 4
Training loss: 0.2504367530345917
Validation loss: 2.0619011720021567

Epoch: 6| Step: 5
Training loss: 0.20973369479179382
Validation loss: 2.1347818771998086

Epoch: 6| Step: 6
Training loss: 0.6244773864746094
Validation loss: 2.1163302262624106

Epoch: 6| Step: 7
Training loss: 0.32057705521583557
Validation loss: 2.077339251836141

Epoch: 6| Step: 8
Training loss: 0.23578664660453796
Validation loss: 2.0874342918395996

Epoch: 6| Step: 9
Training loss: 0.19991658627986908
Validation loss: 2.100320796171824

Epoch: 6| Step: 10
Training loss: 0.6369954943656921
Validation loss: 2.1156083742777505

Epoch: 6| Step: 11
Training loss: 0.17321506142616272
Validation loss: 2.0975099007288613

Epoch: 6| Step: 12
Training loss: 0.18763884902000427
Validation loss: 2.093594233194987

Epoch: 6| Step: 13
Training loss: 0.46806085109710693
Validation loss: 2.1311671137809753

Epoch: 421| Step: 0
Training loss: 0.3071463704109192
Validation loss: 2.094093918800354

Epoch: 6| Step: 1
Training loss: 0.2823752760887146
Validation loss: 2.0738590955734253

Epoch: 6| Step: 2
Training loss: 0.4080764055252075
Validation loss: 2.1001984675725303

Epoch: 6| Step: 3
Training loss: 0.3812353312969208
Validation loss: 2.1542898217837014

Epoch: 6| Step: 4
Training loss: 0.2020847648382187
Validation loss: 2.1075449188550315

Epoch: 6| Step: 5
Training loss: 0.520498514175415
Validation loss: 2.1129063765207925

Epoch: 6| Step: 6
Training loss: 0.32853391766548157
Validation loss: 2.184349477291107

Epoch: 6| Step: 7
Training loss: 0.20509062707424164
Validation loss: 2.0666611393292746

Epoch: 6| Step: 8
Training loss: 0.33242762088775635
Validation loss: 2.1559765736262

Epoch: 6| Step: 9
Training loss: 0.5247690081596375
Validation loss: 2.1263108253479004

Epoch: 6| Step: 10
Training loss: 0.37474673986434937
Validation loss: 2.1021127700805664

Epoch: 6| Step: 11
Training loss: 0.2723124325275421
Validation loss: 2.082786758740743

Epoch: 6| Step: 12
Training loss: 0.6746968626976013
Validation loss: 2.093372364838918

Epoch: 6| Step: 13
Training loss: 0.2668939232826233
Validation loss: 2.1043004393577576

Epoch: 422| Step: 0
Training loss: 0.27808308601379395
Validation loss: 2.1218781073888144

Epoch: 6| Step: 1
Training loss: 0.26911360025405884
Validation loss: 2.139900883038839

Epoch: 6| Step: 2
Training loss: 0.4948520362377167
Validation loss: 2.114599585533142

Epoch: 6| Step: 3
Training loss: 0.21264639496803284
Validation loss: 2.1396443843841553

Epoch: 6| Step: 4
Training loss: 0.25596457719802856
Validation loss: 2.087247888247172

Epoch: 6| Step: 5
Training loss: 0.23008230328559875
Validation loss: 2.1051310499509177

Epoch: 6| Step: 6
Training loss: 0.4618533253669739
Validation loss: 2.0736940503120422

Epoch: 6| Step: 7
Training loss: 0.24457217752933502
Validation loss: 2.1145583391189575

Epoch: 6| Step: 8
Training loss: 0.7659608125686646
Validation loss: 2.0833482146263123

Epoch: 6| Step: 9
Training loss: 0.16706299781799316
Validation loss: 2.135443607966105

Epoch: 6| Step: 10
Training loss: 0.24760064482688904
Validation loss: 2.070810159047445

Epoch: 6| Step: 11
Training loss: 0.3377414047718048
Validation loss: 2.1206143895785012

Epoch: 6| Step: 12
Training loss: 0.6672520041465759
Validation loss: 2.119851807753245

Epoch: 6| Step: 13
Training loss: 0.2605213522911072
Validation loss: 2.0877413749694824

Epoch: 423| Step: 0
Training loss: 0.9289422035217285
Validation loss: 2.092694660027822

Epoch: 6| Step: 1
Training loss: 0.2127760350704193
Validation loss: 2.091487685839335

Epoch: 6| Step: 2
Training loss: 0.2297137826681137
Validation loss: 2.068230628967285

Epoch: 6| Step: 3
Training loss: 0.44204235076904297
Validation loss: 2.084955414136251

Epoch: 6| Step: 4
Training loss: 0.15289591252803802
Validation loss: 2.1105943520863852

Epoch: 6| Step: 5
Training loss: 0.4121582508087158
Validation loss: 2.08280340830485

Epoch: 6| Step: 6
Training loss: 0.2466401755809784
Validation loss: 2.123926877975464

Epoch: 6| Step: 7
Training loss: 0.5659381151199341
Validation loss: 2.0994806488355002

Epoch: 6| Step: 8
Training loss: 0.2668132483959198
Validation loss: 2.0884874065717063

Epoch: 6| Step: 9
Training loss: 0.31679320335388184
Validation loss: 2.0801130135854087

Epoch: 6| Step: 10
Training loss: 0.24007846415042877
Validation loss: 2.119769891103109

Epoch: 6| Step: 11
Training loss: 0.20559096336364746
Validation loss: 2.1133578221003213

Epoch: 6| Step: 12
Training loss: 0.29845401644706726
Validation loss: 2.0497554540634155

Epoch: 6| Step: 13
Training loss: 0.5033077001571655
Validation loss: 2.0588582952817283

Epoch: 424| Step: 0
Training loss: 0.3074119985103607
Validation loss: 2.067771832148234

Epoch: 6| Step: 1
Training loss: 0.21761378645896912
Validation loss: 2.0902322928110757

Epoch: 6| Step: 2
Training loss: 0.34620988368988037
Validation loss: 2.0857557455698648

Epoch: 6| Step: 3
Training loss: 0.4731445610523224
Validation loss: 2.109555641810099

Epoch: 6| Step: 4
Training loss: 0.2732623815536499
Validation loss: 2.08842009305954

Epoch: 6| Step: 5
Training loss: 0.3598335385322571
Validation loss: 2.098718841870626

Epoch: 6| Step: 6
Training loss: 0.2926692068576813
Validation loss: 2.0541176001230874

Epoch: 6| Step: 7
Training loss: 0.30927056074142456
Validation loss: 2.0761576493581138

Epoch: 6| Step: 8
Training loss: 0.32097750902175903
Validation loss: 2.095744033654531

Epoch: 6| Step: 9
Training loss: 0.8480217456817627
Validation loss: 2.089585065841675

Epoch: 6| Step: 10
Training loss: 0.2726442217826843
Validation loss: 2.088004012902578

Epoch: 6| Step: 11
Training loss: 0.5998857617378235
Validation loss: 2.086579998334249

Epoch: 6| Step: 12
Training loss: 0.2907467484474182
Validation loss: 2.0934444864590964

Epoch: 6| Step: 13
Training loss: 0.32969409227371216
Validation loss: 2.1130804220835366

Epoch: 425| Step: 0
Training loss: 0.18416976928710938
Validation loss: 2.0577334562937417

Epoch: 6| Step: 1
Training loss: 0.2773721218109131
Validation loss: 2.0689600308736167

Epoch: 6| Step: 2
Training loss: 0.2631705105304718
Validation loss: 2.0820043285687766

Epoch: 6| Step: 3
Training loss: 0.9489898085594177
Validation loss: 2.0564246773719788

Epoch: 6| Step: 4
Training loss: 0.49080607295036316
Validation loss: 2.094081779321035

Epoch: 6| Step: 5
Training loss: 0.28273776173591614
Validation loss: 2.047375818093618

Epoch: 6| Step: 6
Training loss: 0.4065095782279968
Validation loss: 2.1444259881973267

Epoch: 6| Step: 7
Training loss: 0.20329535007476807
Validation loss: 2.0674198071161904

Epoch: 6| Step: 8
Training loss: 0.36871272325515747
Validation loss: 2.0931778947512307

Epoch: 6| Step: 9
Training loss: 0.4677760601043701
Validation loss: 2.063164472579956

Epoch: 6| Step: 10
Training loss: 0.3650951385498047
Validation loss: 2.070150891939799

Epoch: 6| Step: 11
Training loss: 0.29054197669029236
Validation loss: 2.139614542325338

Epoch: 6| Step: 12
Training loss: 0.4547147750854492
Validation loss: 2.1624045968055725

Epoch: 6| Step: 13
Training loss: 0.3258233666419983
Validation loss: 2.1051621437072754

Epoch: 426| Step: 0
Training loss: 0.4443875551223755
Validation loss: 2.1215232809384665

Epoch: 6| Step: 1
Training loss: 0.45465609431266785
Validation loss: 2.1368179519971213

Epoch: 6| Step: 2
Training loss: 0.24108825623989105
Validation loss: 2.131562332312266

Epoch: 6| Step: 3
Training loss: 0.25983965396881104
Validation loss: 2.10890261332194

Epoch: 6| Step: 4
Training loss: 0.3320053815841675
Validation loss: 2.078971266746521

Epoch: 6| Step: 5
Training loss: 0.7734725475311279
Validation loss: 2.118217964967092

Epoch: 6| Step: 6
Training loss: 0.3510829508304596
Validation loss: 2.069403807322184

Epoch: 6| Step: 7
Training loss: 0.2995298504829407
Validation loss: 2.0584115187327066

Epoch: 6| Step: 8
Training loss: 0.5670161247253418
Validation loss: 2.0951984524726868

Epoch: 6| Step: 9
Training loss: 0.2909452021121979
Validation loss: 2.1342032750447593

Epoch: 6| Step: 10
Training loss: 0.2232995331287384
Validation loss: 2.1136038303375244

Epoch: 6| Step: 11
Training loss: 0.3861684203147888
Validation loss: 2.144750416278839

Epoch: 6| Step: 12
Training loss: 0.3128814995288849
Validation loss: 2.1297942797342935

Epoch: 6| Step: 13
Training loss: 0.5696654319763184
Validation loss: 2.1249159574508667

Epoch: 427| Step: 0
Training loss: 0.24598591029644012
Validation loss: 2.098752717177073

Epoch: 6| Step: 1
Training loss: 0.6396929025650024
Validation loss: 2.115744133790334

Epoch: 6| Step: 2
Training loss: 0.346274733543396
Validation loss: 2.0844852725664773

Epoch: 6| Step: 3
Training loss: 0.31596362590789795
Validation loss: 2.1181538899739585

Epoch: 6| Step: 4
Training loss: 0.2670086622238159
Validation loss: 2.0870314836502075

Epoch: 6| Step: 5
Training loss: 0.3741738200187683
Validation loss: 2.112380802631378

Epoch: 6| Step: 6
Training loss: 0.4136087894439697
Validation loss: 2.067768414815267

Epoch: 6| Step: 7
Training loss: 0.19121429324150085
Validation loss: 2.1348448991775513

Epoch: 6| Step: 8
Training loss: 0.24009352922439575
Validation loss: 2.082947393258413

Epoch: 6| Step: 9
Training loss: 0.16355493664741516
Validation loss: 2.0595110654830933

Epoch: 6| Step: 10
Training loss: 0.17739075422286987
Validation loss: 2.104801873366038

Epoch: 6| Step: 11
Training loss: 0.2584949731826782
Validation loss: 2.092161774635315

Epoch: 6| Step: 12
Training loss: 0.7695706486701965
Validation loss: 2.111667970816294

Epoch: 6| Step: 13
Training loss: 0.4096266031265259
Validation loss: 2.110156238079071

Epoch: 428| Step: 0
Training loss: 0.513804018497467
Validation loss: 2.1299636363983154

Epoch: 6| Step: 1
Training loss: 0.25625312328338623
Validation loss: 2.126879016558329

Epoch: 6| Step: 2
Training loss: 0.2762877941131592
Validation loss: 2.1073572238286338

Epoch: 6| Step: 3
Training loss: 0.4646908640861511
Validation loss: 2.09378719329834

Epoch: 6| Step: 4
Training loss: 0.3611021935939789
Validation loss: 2.1132163405418396

Epoch: 6| Step: 5
Training loss: 0.34101828932762146
Validation loss: 2.0925779342651367

Epoch: 6| Step: 6
Training loss: 0.8995280265808105
Validation loss: 2.1208475828170776

Epoch: 6| Step: 7
Training loss: 0.2708542048931122
Validation loss: 2.074621061484019

Epoch: 6| Step: 8
Training loss: 0.2876186668872833
Validation loss: 2.103218376636505

Epoch: 6| Step: 9
Training loss: 0.30563366413116455
Validation loss: 2.0916782220204673

Epoch: 6| Step: 10
Training loss: 0.4373481273651123
Validation loss: 2.1740185419718423

Epoch: 6| Step: 11
Training loss: 0.36855533719062805
Validation loss: 2.1316299438476562

Epoch: 6| Step: 12
Training loss: 0.4074493944644928
Validation loss: 2.1447710196177163

Epoch: 6| Step: 13
Training loss: 0.6159269213676453
Validation loss: 2.0807400941848755

Epoch: 429| Step: 0
Training loss: 0.2653149366378784
Validation loss: 2.109001358350118

Epoch: 6| Step: 1
Training loss: 0.3477059304714203
Validation loss: 2.070836305618286

Epoch: 6| Step: 2
Training loss: 0.19852158427238464
Validation loss: 2.095531682173411

Epoch: 6| Step: 3
Training loss: 0.28922536969184875
Validation loss: 2.107363224029541

Epoch: 6| Step: 4
Training loss: 0.39614880084991455
Validation loss: 2.1139103770256042

Epoch: 6| Step: 5
Training loss: 0.317502498626709
Validation loss: 2.1002440055211387

Epoch: 6| Step: 6
Training loss: 0.30351024866104126
Validation loss: 2.092221200466156

Epoch: 6| Step: 7
Training loss: 0.39861738681793213
Validation loss: 2.1014766494433084

Epoch: 6| Step: 8
Training loss: 0.24479031562805176
Validation loss: 2.0779292384783425

Epoch: 6| Step: 9
Training loss: 0.7448326349258423
Validation loss: 2.1384563644727073

Epoch: 6| Step: 10
Training loss: 0.29469233751296997
Validation loss: 2.126943369706472

Epoch: 6| Step: 11
Training loss: 0.4118225872516632
Validation loss: 2.092028776804606

Epoch: 6| Step: 12
Training loss: 0.15914800763130188
Validation loss: 2.09685871998469

Epoch: 6| Step: 13
Training loss: 0.4967573285102844
Validation loss: 2.1211868127187095

Epoch: 430| Step: 0
Training loss: 0.2214067578315735
Validation loss: 2.0658947428067527

Epoch: 6| Step: 1
Training loss: 0.2696281671524048
Validation loss: 2.1002158721288047

Epoch: 6| Step: 2
Training loss: 0.37787550687789917
Validation loss: 2.1397511760393777

Epoch: 6| Step: 3
Training loss: 0.6560310125350952
Validation loss: 2.1070211927096048

Epoch: 6| Step: 4
Training loss: 0.41349342465400696
Validation loss: 2.04848704735438

Epoch: 6| Step: 5
Training loss: 0.6950872540473938
Validation loss: 2.0755733251571655

Epoch: 6| Step: 6
Training loss: 0.3059437572956085
Validation loss: 2.0978618264198303

Epoch: 6| Step: 7
Training loss: 0.3230295479297638
Validation loss: 2.0936912099520364

Epoch: 6| Step: 8
Training loss: 0.3119572699069977
Validation loss: 2.1068871219952903

Epoch: 6| Step: 9
Training loss: 0.3686482012271881
Validation loss: 2.1332082748413086

Epoch: 6| Step: 10
Training loss: 0.3988809585571289
Validation loss: 2.146695832411448

Epoch: 6| Step: 11
Training loss: 0.3469507694244385
Validation loss: 2.0924793084462485

Epoch: 6| Step: 12
Training loss: 0.278953492641449
Validation loss: 2.0912972887357077

Epoch: 6| Step: 13
Training loss: 0.21895435452461243
Validation loss: 2.0849631627400718

Epoch: 431| Step: 0
Training loss: 0.5624233484268188
Validation loss: 2.1584043900171914

Epoch: 6| Step: 1
Training loss: 0.3583979606628418
Validation loss: 2.076746960481008

Epoch: 6| Step: 2
Training loss: 0.7586855888366699
Validation loss: 2.139193375905355

Epoch: 6| Step: 3
Training loss: 0.2615683972835541
Validation loss: 2.1040831208229065

Epoch: 6| Step: 4
Training loss: 0.4614298939704895
Validation loss: 2.104519248008728

Epoch: 6| Step: 5
Training loss: 0.2667176425457001
Validation loss: 2.0679285724957785

Epoch: 6| Step: 6
Training loss: 0.47576606273651123
Validation loss: 2.1044835646947226

Epoch: 6| Step: 7
Training loss: 0.2993110418319702
Validation loss: 2.1123462120691934

Epoch: 6| Step: 8
Training loss: 0.3635101318359375
Validation loss: 2.1583377718925476

Epoch: 6| Step: 9
Training loss: 0.6311773061752319
Validation loss: 2.159591535727183

Epoch: 6| Step: 10
Training loss: 0.38903167843818665
Validation loss: 2.1444815198580423

Epoch: 6| Step: 11
Training loss: 0.3643673062324524
Validation loss: 2.1169233123461404

Epoch: 6| Step: 12
Training loss: 0.26141881942749023
Validation loss: 2.0844740668932595

Epoch: 6| Step: 13
Training loss: 0.2704499363899231
Validation loss: 2.1426760951677957

Epoch: 432| Step: 0
Training loss: 0.3691330850124359
Validation loss: 2.0571794907251992

Epoch: 6| Step: 1
Training loss: 0.3206942081451416
Validation loss: 2.101745307445526

Epoch: 6| Step: 2
Training loss: 0.16702568531036377
Validation loss: 2.0802369912465415

Epoch: 6| Step: 3
Training loss: 0.2473750114440918
Validation loss: 2.0482371846834817

Epoch: 6| Step: 4
Training loss: 0.32210299372673035
Validation loss: 2.0974207719167075

Epoch: 6| Step: 5
Training loss: 0.6123208999633789
Validation loss: 2.1277127861976624

Epoch: 6| Step: 6
Training loss: 0.40700680017471313
Validation loss: 2.1384835640589395

Epoch: 6| Step: 7
Training loss: 0.47809290885925293
Validation loss: 2.1019405921300254

Epoch: 6| Step: 8
Training loss: 0.2457352876663208
Validation loss: 2.082653065522512

Epoch: 6| Step: 9
Training loss: 0.3685087561607361
Validation loss: 2.088511884212494

Epoch: 6| Step: 10
Training loss: 0.2581337094306946
Validation loss: 2.108046571413676

Epoch: 6| Step: 11
Training loss: 0.1876922994852066
Validation loss: 2.110748906930288

Epoch: 6| Step: 12
Training loss: 0.7655661702156067
Validation loss: 2.1017969846725464

Epoch: 6| Step: 13
Training loss: 0.1897868812084198
Validation loss: 2.0802595814069114

Epoch: 433| Step: 0
Training loss: 0.31799882650375366
Validation loss: 2.065039793650309

Epoch: 6| Step: 1
Training loss: 0.3495945930480957
Validation loss: 2.10414981842041

Epoch: 6| Step: 2
Training loss: 0.3384281098842621
Validation loss: 2.1051789919535318

Epoch: 6| Step: 3
Training loss: 0.31021538376808167
Validation loss: 2.16739430030187

Epoch: 6| Step: 4
Training loss: 0.7255621552467346
Validation loss: 2.098518947760264

Epoch: 6| Step: 5
Training loss: 0.27842408418655396
Validation loss: 2.1452009677886963

Epoch: 6| Step: 6
Training loss: 0.33558574318885803
Validation loss: 2.1396391789118447

Epoch: 6| Step: 7
Training loss: 0.39754897356033325
Validation loss: 2.1096888184547424

Epoch: 6| Step: 8
Training loss: 0.3773842453956604
Validation loss: 2.119170367717743

Epoch: 6| Step: 9
Training loss: 0.26852306723594666
Validation loss: 2.091494599978129

Epoch: 6| Step: 10
Training loss: 0.36885830760002136
Validation loss: 2.0968544085820517

Epoch: 6| Step: 11
Training loss: 0.19373714923858643
Validation loss: 2.119275530179342

Epoch: 6| Step: 12
Training loss: 0.2613239288330078
Validation loss: 2.1228819489479065

Epoch: 6| Step: 13
Training loss: 0.36122405529022217
Validation loss: 2.111716310183207

Epoch: 434| Step: 0
Training loss: 0.24931971728801727
Validation loss: 2.1071568926175437

Epoch: 6| Step: 1
Training loss: 0.38188642263412476
Validation loss: 2.1195958455403647

Epoch: 6| Step: 2
Training loss: 0.2915549576282501
Validation loss: 2.0869699716567993

Epoch: 6| Step: 3
Training loss: 0.15100416541099548
Validation loss: 2.115927775700887

Epoch: 6| Step: 4
Training loss: 0.24739299714565277
Validation loss: 2.167986353238424

Epoch: 6| Step: 5
Training loss: 0.7301678657531738
Validation loss: 2.130498766899109

Epoch: 6| Step: 6
Training loss: 0.22117725014686584
Validation loss: 2.089591125647227

Epoch: 6| Step: 7
Training loss: 0.5313920974731445
Validation loss: 2.0817602475484214

Epoch: 6| Step: 8
Training loss: 0.19235137104988098
Validation loss: 2.0867907206217446

Epoch: 6| Step: 9
Training loss: 0.19933651387691498
Validation loss: 2.078612665335337

Epoch: 6| Step: 10
Training loss: 0.44795989990234375
Validation loss: 2.04671972990036

Epoch: 6| Step: 11
Training loss: 0.34663668274879456
Validation loss: 2.1286384065945945

Epoch: 6| Step: 12
Training loss: 0.3532082736492157
Validation loss: 2.056693971157074

Epoch: 6| Step: 13
Training loss: 0.22383087873458862
Validation loss: 2.1531996925671897

Epoch: 435| Step: 0
Training loss: 0.281984806060791
Validation loss: 2.086859325567881

Epoch: 6| Step: 1
Training loss: 0.39744532108306885
Validation loss: 2.110829512278239

Epoch: 6| Step: 2
Training loss: 0.3419339656829834
Validation loss: 2.0821361939112344

Epoch: 6| Step: 3
Training loss: 0.5143017768859863
Validation loss: 2.0956859985987344

Epoch: 6| Step: 4
Training loss: 0.1985882818698883
Validation loss: 2.077021837234497

Epoch: 6| Step: 5
Training loss: 0.2686752378940582
Validation loss: 2.1260669231414795

Epoch: 6| Step: 6
Training loss: 0.5025798678398132
Validation loss: 2.081943412621816

Epoch: 6| Step: 7
Training loss: 0.46086108684539795
Validation loss: 2.1621172428131104

Epoch: 6| Step: 8
Training loss: 0.6083148717880249
Validation loss: 2.1080953081448874

Epoch: 6| Step: 9
Training loss: 0.2669559419155121
Validation loss: 2.0654970606168113

Epoch: 6| Step: 10
Training loss: 0.29790744185447693
Validation loss: 2.089429577191671

Epoch: 6| Step: 11
Training loss: 0.2775149941444397
Validation loss: 2.1037445863087973

Epoch: 6| Step: 12
Training loss: 0.3240143656730652
Validation loss: 2.124723434448242

Epoch: 6| Step: 13
Training loss: 0.24322623014450073
Validation loss: 2.1111066341400146

Epoch: 436| Step: 0
Training loss: 0.3471713364124298
Validation loss: 2.1113839149475098

Epoch: 6| Step: 1
Training loss: 0.1799907386302948
Validation loss: 2.0677504340807595

Epoch: 6| Step: 2
Training loss: 0.39358699321746826
Validation loss: 2.1206648349761963

Epoch: 6| Step: 3
Training loss: 0.3683457374572754
Validation loss: 2.116109927495321

Epoch: 6| Step: 4
Training loss: 0.4183736741542816
Validation loss: 2.1097750266393027

Epoch: 6| Step: 5
Training loss: 0.313496470451355
Validation loss: 2.0621559421221414

Epoch: 6| Step: 6
Training loss: 0.24500510096549988
Validation loss: 2.103261172771454

Epoch: 6| Step: 7
Training loss: 0.6925085186958313
Validation loss: 2.076850334803263

Epoch: 6| Step: 8
Training loss: 0.18504445254802704
Validation loss: 2.046292006969452

Epoch: 6| Step: 9
Training loss: 0.39997780323028564
Validation loss: 2.0700972278912864

Epoch: 6| Step: 10
Training loss: 0.2580563724040985
Validation loss: 2.1002465883890786

Epoch: 6| Step: 11
Training loss: 0.16850298643112183
Validation loss: 2.11174742380778

Epoch: 6| Step: 12
Training loss: 0.4207480549812317
Validation loss: 2.0886120001475015

Epoch: 6| Step: 13
Training loss: 0.21428385376930237
Validation loss: 2.1205365459124246

Epoch: 437| Step: 0
Training loss: 0.23870369791984558
Validation loss: 2.132955272992452

Epoch: 6| Step: 1
Training loss: 0.1831217110157013
Validation loss: 2.0794429183006287

Epoch: 6| Step: 2
Training loss: 0.2509872019290924
Validation loss: 2.086180408795675

Epoch: 6| Step: 3
Training loss: 0.6805869936943054
Validation loss: 2.1079660654067993

Epoch: 6| Step: 4
Training loss: 0.39453282952308655
Validation loss: 2.097473919391632

Epoch: 6| Step: 5
Training loss: 0.4622471034526825
Validation loss: 2.141683260599772

Epoch: 6| Step: 6
Training loss: 0.2531796991825104
Validation loss: 2.1292787392934165

Epoch: 6| Step: 7
Training loss: 0.17808914184570312
Validation loss: 2.0762500166893005

Epoch: 6| Step: 8
Training loss: 0.4207887053489685
Validation loss: 2.074779768784841

Epoch: 6| Step: 9
Training loss: 0.41309496760368347
Validation loss: 2.1157132983207703

Epoch: 6| Step: 10
Training loss: 0.42272916436195374
Validation loss: 2.125497261683146

Epoch: 6| Step: 11
Training loss: 0.48229867219924927
Validation loss: 2.135154962539673

Epoch: 6| Step: 12
Training loss: 0.3991560935974121
Validation loss: 2.173514187335968

Epoch: 6| Step: 13
Training loss: 0.30404117703437805
Validation loss: 2.0784109433492026

Epoch: 438| Step: 0
Training loss: 0.29346564412117004
Validation loss: 2.1203616857528687

Epoch: 6| Step: 1
Training loss: 0.447665810585022
Validation loss: 2.04077539841334

Epoch: 6| Step: 2
Training loss: 0.215060293674469
Validation loss: 2.106187343597412

Epoch: 6| Step: 3
Training loss: 0.5164363384246826
Validation loss: 2.0740755001703897

Epoch: 6| Step: 4
Training loss: 0.29474154114723206
Validation loss: 2.0486724774042764

Epoch: 6| Step: 5
Training loss: 0.14899563789367676
Validation loss: 2.098099668820699

Epoch: 6| Step: 6
Training loss: 0.6836945414543152
Validation loss: 2.1218663851420083

Epoch: 6| Step: 7
Training loss: 0.2475930154323578
Validation loss: 2.0784220496813455

Epoch: 6| Step: 8
Training loss: 0.228862464427948
Validation loss: 2.074130892753601

Epoch: 6| Step: 9
Training loss: 0.2984834313392639
Validation loss: 2.120306591192881

Epoch: 6| Step: 10
Training loss: 0.2926594913005829
Validation loss: 2.09574302037557

Epoch: 6| Step: 11
Training loss: 0.412345826625824
Validation loss: 2.1283016204833984

Epoch: 6| Step: 12
Training loss: 0.41655150055885315
Validation loss: 2.118237574895223

Epoch: 6| Step: 13
Training loss: 0.3248788118362427
Validation loss: 2.1412652134895325

Epoch: 439| Step: 0
Training loss: 0.3490979075431824
Validation loss: 2.147893170515696

Epoch: 6| Step: 1
Training loss: 0.6740991473197937
Validation loss: 2.1417885621388755

Epoch: 6| Step: 2
Training loss: 0.4141555428504944
Validation loss: 2.086432079474131

Epoch: 6| Step: 3
Training loss: 0.29020196199417114
Validation loss: 2.106760303179423

Epoch: 6| Step: 4
Training loss: 0.5630966424942017
Validation loss: 2.1053627729415894

Epoch: 6| Step: 5
Training loss: 0.42217817902565
Validation loss: 2.084685722986857

Epoch: 6| Step: 6
Training loss: 0.29133141040802
Validation loss: 2.1167428692181907

Epoch: 6| Step: 7
Training loss: 0.3369053602218628
Validation loss: 2.0946507851282754

Epoch: 6| Step: 8
Training loss: 0.2745428681373596
Validation loss: 2.168357570966085

Epoch: 6| Step: 9
Training loss: 0.2401033639907837
Validation loss: 2.1516217390696206

Epoch: 6| Step: 10
Training loss: 0.244468092918396
Validation loss: 2.127888321876526

Epoch: 6| Step: 11
Training loss: 0.520886242389679
Validation loss: 2.0849010149637857

Epoch: 6| Step: 12
Training loss: 0.297269344329834
Validation loss: 2.108472923437754

Epoch: 6| Step: 13
Training loss: 0.2536650002002716
Validation loss: 2.0299662152926126

Epoch: 440| Step: 0
Training loss: 0.28975874185562134
Validation loss: 2.0602591832478843

Epoch: 6| Step: 1
Training loss: 0.3270418643951416
Validation loss: 2.1073612769444785

Epoch: 6| Step: 2
Training loss: 0.4599539041519165
Validation loss: 2.0832918683687844

Epoch: 6| Step: 3
Training loss: 0.47152167558670044
Validation loss: 2.0955492854118347

Epoch: 6| Step: 4
Training loss: 0.42664197087287903
Validation loss: 2.12034805615743

Epoch: 6| Step: 5
Training loss: 0.3189890384674072
Validation loss: 2.115386188030243

Epoch: 6| Step: 6
Training loss: 0.7670190334320068
Validation loss: 2.1363643407821655

Epoch: 6| Step: 7
Training loss: 0.21383129060268402
Validation loss: 2.1196460326512656

Epoch: 6| Step: 8
Training loss: 0.17896562814712524
Validation loss: 2.1205313205718994

Epoch: 6| Step: 9
Training loss: 0.4317203164100647
Validation loss: 2.078902324040731

Epoch: 6| Step: 10
Training loss: 0.24271821975708008
Validation loss: 2.1165226300557456

Epoch: 6| Step: 11
Training loss: 0.3444558382034302
Validation loss: 2.1296260754267373

Epoch: 6| Step: 12
Training loss: 0.295772910118103
Validation loss: 2.1110220750172934

Epoch: 6| Step: 13
Training loss: 0.22303031384944916
Validation loss: 2.076654771963755

Epoch: 441| Step: 0
Training loss: 0.2996152341365814
Validation loss: 2.0957847436269126

Epoch: 6| Step: 1
Training loss: 0.6886300444602966
Validation loss: 2.156883259614309

Epoch: 6| Step: 2
Training loss: 0.46546897292137146
Validation loss: 2.1224859158198037

Epoch: 6| Step: 3
Training loss: 0.3202073574066162
Validation loss: 2.0966743628184

Epoch: 6| Step: 4
Training loss: 0.25650936365127563
Validation loss: 2.1335155963897705

Epoch: 6| Step: 5
Training loss: 0.5107322335243225
Validation loss: 2.094875693321228

Epoch: 6| Step: 6
Training loss: 0.2851918935775757
Validation loss: 2.211738129456838

Epoch: 6| Step: 7
Training loss: 0.40771469473838806
Validation loss: 2.1343912482261658

Epoch: 6| Step: 8
Training loss: 0.19080707430839539
Validation loss: 2.139382481575012

Epoch: 6| Step: 9
Training loss: 0.3184511661529541
Validation loss: 2.1494100093841553

Epoch: 6| Step: 10
Training loss: 0.22582396864891052
Validation loss: 2.1387976805369058

Epoch: 6| Step: 11
Training loss: 0.33410388231277466
Validation loss: 2.122918645540873

Epoch: 6| Step: 12
Training loss: 0.21793732047080994
Validation loss: 2.121332307656606

Epoch: 6| Step: 13
Training loss: 0.21483442187309265
Validation loss: 2.1005789637565613

Epoch: 442| Step: 0
Training loss: 0.24636584520339966
Validation loss: 2.114957630634308

Epoch: 6| Step: 1
Training loss: 0.40116217732429504
Validation loss: 2.067244311173757

Epoch: 6| Step: 2
Training loss: 0.30785632133483887
Validation loss: 2.117883821328481

Epoch: 6| Step: 3
Training loss: 0.22426874935626984
Validation loss: 2.104232132434845

Epoch: 6| Step: 4
Training loss: 0.37720024585723877
Validation loss: 2.0863355795542398

Epoch: 6| Step: 5
Training loss: 0.3308327794075012
Validation loss: 2.12075408299764

Epoch: 6| Step: 6
Training loss: 0.4688678979873657
Validation loss: 2.099747439225515

Epoch: 6| Step: 7
Training loss: 0.3177715837955475
Validation loss: 2.123489022254944

Epoch: 6| Step: 8
Training loss: 0.411886602640152
Validation loss: 2.0650439262390137

Epoch: 6| Step: 9
Training loss: 0.30900317430496216
Validation loss: 2.1292810241381326

Epoch: 6| Step: 10
Training loss: 0.7336248159408569
Validation loss: 2.134869853655497

Epoch: 6| Step: 11
Training loss: 0.1723732054233551
Validation loss: 2.07570610443751

Epoch: 6| Step: 12
Training loss: 0.3383902609348297
Validation loss: 2.121606190999349

Epoch: 6| Step: 13
Training loss: 0.18398374319076538
Validation loss: 2.128076950709025

Epoch: 443| Step: 0
Training loss: 0.28464508056640625
Validation loss: 2.109343409538269

Epoch: 6| Step: 1
Training loss: 0.6270723938941956
Validation loss: 2.114904761314392

Epoch: 6| Step: 2
Training loss: 0.38227999210357666
Validation loss: 2.0951757431030273

Epoch: 6| Step: 3
Training loss: 0.3160225749015808
Validation loss: 2.1037253737449646

Epoch: 6| Step: 4
Training loss: 0.18882903456687927
Validation loss: 2.0939324498176575

Epoch: 6| Step: 5
Training loss: 0.23653219640254974
Validation loss: 2.10857230424881

Epoch: 6| Step: 6
Training loss: 0.18849310278892517
Validation loss: 2.0810161232948303

Epoch: 6| Step: 7
Training loss: 0.2329992651939392
Validation loss: 2.1302401622136435

Epoch: 6| Step: 8
Training loss: 0.31002771854400635
Validation loss: 2.114510178565979

Epoch: 6| Step: 9
Training loss: 0.26483848690986633
Validation loss: 2.129277209440867

Epoch: 6| Step: 10
Training loss: 0.6341875791549683
Validation loss: 2.105243722597758

Epoch: 6| Step: 11
Training loss: 0.31880494952201843
Validation loss: 2.106188337008158

Epoch: 6| Step: 12
Training loss: 0.17675277590751648
Validation loss: 2.0438759326934814

Epoch: 6| Step: 13
Training loss: 0.2061023712158203
Validation loss: 2.039484659830729

Epoch: 444| Step: 0
Training loss: 0.27760952711105347
Validation loss: 2.111477494239807

Epoch: 6| Step: 1
Training loss: 0.36174464225769043
Validation loss: 2.0955201586087546

Epoch: 6| Step: 2
Training loss: 0.21806713938713074
Validation loss: 2.063584585984548

Epoch: 6| Step: 3
Training loss: 0.16013236343860626
Validation loss: 2.098497986793518

Epoch: 6| Step: 4
Training loss: 0.290811151266098
Validation loss: 2.0787501136461892

Epoch: 6| Step: 5
Training loss: 0.1959472894668579
Validation loss: 2.102519452571869

Epoch: 6| Step: 6
Training loss: 0.39029502868652344
Validation loss: 2.115083654721578

Epoch: 6| Step: 7
Training loss: 0.7710128426551819
Validation loss: 2.0864078203837075

Epoch: 6| Step: 8
Training loss: 0.2244769185781479
Validation loss: 2.0988954106966653

Epoch: 6| Step: 9
Training loss: 0.3594250977039337
Validation loss: 2.120967706044515

Epoch: 6| Step: 10
Training loss: 0.42167794704437256
Validation loss: 2.0857598781585693

Epoch: 6| Step: 11
Training loss: 0.2550409138202667
Validation loss: 2.110745350519816

Epoch: 6| Step: 12
Training loss: 0.2867276668548584
Validation loss: 2.1383315920829773

Epoch: 6| Step: 13
Training loss: 0.2899235486984253
Validation loss: 2.0944509307543435

Epoch: 445| Step: 0
Training loss: 0.35784828662872314
Validation loss: 2.149572749932607

Epoch: 6| Step: 1
Training loss: 0.29342591762542725
Validation loss: 2.109216789404551

Epoch: 6| Step: 2
Training loss: 0.2857432961463928
Validation loss: 2.119151989618937

Epoch: 6| Step: 3
Training loss: 0.2751898765563965
Validation loss: 2.085869828859965

Epoch: 6| Step: 4
Training loss: 0.5950253009796143
Validation loss: 2.0678467750549316

Epoch: 6| Step: 5
Training loss: 0.24549753963947296
Validation loss: 2.0970116456349692

Epoch: 6| Step: 6
Training loss: 0.2927910387516022
Validation loss: 2.130564530690511

Epoch: 6| Step: 7
Training loss: 0.3065827488899231
Validation loss: 2.100636382897695

Epoch: 6| Step: 8
Training loss: 0.32786619663238525
Validation loss: 2.0821893215179443

Epoch: 6| Step: 9
Training loss: 0.40554630756378174
Validation loss: 2.0874942541122437

Epoch: 6| Step: 10
Training loss: 0.428752601146698
Validation loss: 2.0767482916514077

Epoch: 6| Step: 11
Training loss: 0.4883292317390442
Validation loss: 2.083241800467173

Epoch: 6| Step: 12
Training loss: 0.3172866702079773
Validation loss: 2.0923458536465964

Epoch: 6| Step: 13
Training loss: 0.23792895674705505
Validation loss: 2.0988306999206543

Epoch: 446| Step: 0
Training loss: 0.36764416098594666
Validation loss: 2.0453049341837564

Epoch: 6| Step: 1
Training loss: 0.45508646965026855
Validation loss: 2.110520303249359

Epoch: 6| Step: 2
Training loss: 0.23362034559249878
Validation loss: 2.1288109024365744

Epoch: 6| Step: 3
Training loss: 0.3156464695930481
Validation loss: 2.127245088418325

Epoch: 6| Step: 4
Training loss: 0.19248266518115997
Validation loss: 2.090800921122233

Epoch: 6| Step: 5
Training loss: 0.6671626567840576
Validation loss: 2.0700753331184387

Epoch: 6| Step: 6
Training loss: 0.20627394318580627
Validation loss: 2.089252452055613

Epoch: 6| Step: 7
Training loss: 0.16428741812705994
Validation loss: 2.081442713737488

Epoch: 6| Step: 8
Training loss: 0.1580338478088379
Validation loss: 2.072687288125356

Epoch: 6| Step: 9
Training loss: 0.3031991720199585
Validation loss: 2.1089533964792886

Epoch: 6| Step: 10
Training loss: 0.41574305295944214
Validation loss: 2.0807296435038247

Epoch: 6| Step: 11
Training loss: 0.4218008816242218
Validation loss: 2.1031333406766257

Epoch: 6| Step: 12
Training loss: 0.3446093797683716
Validation loss: 2.0987767775853476

Epoch: 6| Step: 13
Training loss: 0.3520413637161255
Validation loss: 2.108217477798462

Epoch: 447| Step: 0
Training loss: 0.23853664100170135
Validation loss: 2.1005919178326926

Epoch: 6| Step: 1
Training loss: 0.1839759796857834
Validation loss: 2.0544550816218057

Epoch: 6| Step: 2
Training loss: 0.21122072637081146
Validation loss: 2.1129512786865234

Epoch: 6| Step: 3
Training loss: 0.6021804809570312
Validation loss: 2.0922345320383706

Epoch: 6| Step: 4
Training loss: 0.26942771673202515
Validation loss: 2.1176934838294983

Epoch: 6| Step: 5
Training loss: 0.3037075698375702
Validation loss: 2.0562381545702615

Epoch: 6| Step: 6
Training loss: 0.3826562464237213
Validation loss: 2.1248152256011963

Epoch: 6| Step: 7
Training loss: 0.39224904775619507
Validation loss: 2.107231338818868

Epoch: 6| Step: 8
Training loss: 0.5745471715927124
Validation loss: 2.19188791513443

Epoch: 6| Step: 9
Training loss: 0.19063207507133484
Validation loss: 2.097023824850718

Epoch: 6| Step: 10
Training loss: 0.44071316719055176
Validation loss: 2.1342679858207703

Epoch: 6| Step: 11
Training loss: 0.2375529706478119
Validation loss: 2.067751963933309

Epoch: 6| Step: 12
Training loss: 0.2092842161655426
Validation loss: 2.1171618700027466

Epoch: 6| Step: 13
Training loss: 0.30100947618484497
Validation loss: 2.1104840636253357

Epoch: 448| Step: 0
Training loss: 0.49815618991851807
Validation loss: 2.1031487186749778

Epoch: 6| Step: 1
Training loss: 0.3240729868412018
Validation loss: 2.061650574207306

Epoch: 6| Step: 2
Training loss: 0.18352770805358887
Validation loss: 2.1024630864461265

Epoch: 6| Step: 3
Training loss: 0.22821485996246338
Validation loss: 2.089436630407969

Epoch: 6| Step: 4
Training loss: 0.25371432304382324
Validation loss: 2.1086714466412864

Epoch: 6| Step: 5
Training loss: 0.349199503660202
Validation loss: 2.0976155201594033

Epoch: 6| Step: 6
Training loss: 0.36274707317352295
Validation loss: 2.0949644645055137

Epoch: 6| Step: 7
Training loss: 0.3307473659515381
Validation loss: 2.10662309328715

Epoch: 6| Step: 8
Training loss: 0.6469948887825012
Validation loss: 2.105355978012085

Epoch: 6| Step: 9
Training loss: 0.22956418991088867
Validation loss: 2.108652412891388

Epoch: 6| Step: 10
Training loss: 0.31634896993637085
Validation loss: 2.123209814230601

Epoch: 6| Step: 11
Training loss: 0.5098199844360352
Validation loss: 2.102795958518982

Epoch: 6| Step: 12
Training loss: 0.2582876980304718
Validation loss: 2.080442190170288

Epoch: 6| Step: 13
Training loss: 0.3755642771720886
Validation loss: 2.120591461658478

Epoch: 449| Step: 0
Training loss: 0.17638520896434784
Validation loss: 2.0567878683408103

Epoch: 6| Step: 1
Training loss: 0.4275857210159302
Validation loss: 2.0826395948727927

Epoch: 6| Step: 2
Training loss: 0.34445255994796753
Validation loss: 2.1108288566271463

Epoch: 6| Step: 3
Training loss: 0.5593260526657104
Validation loss: 2.0308587153752646

Epoch: 6| Step: 4
Training loss: 0.5632040500640869
Validation loss: 2.1022379199663797

Epoch: 6| Step: 5
Training loss: 0.4318074882030487
Validation loss: 2.12277219692866

Epoch: 6| Step: 6
Training loss: 0.22752724587917328
Validation loss: 2.1087751984596252

Epoch: 6| Step: 7
Training loss: 0.25848594307899475
Validation loss: 2.093036731084188

Epoch: 6| Step: 8
Training loss: 0.24433287978172302
Validation loss: 2.0516625245412192

Epoch: 6| Step: 9
Training loss: 0.2701415717601776
Validation loss: 2.076237459977468

Epoch: 6| Step: 10
Training loss: 0.2158707082271576
Validation loss: 2.075273950894674

Epoch: 6| Step: 11
Training loss: 0.2998747229576111
Validation loss: 2.1298860708872476

Epoch: 6| Step: 12
Training loss: 0.2656342089176178
Validation loss: 2.085331161816915

Epoch: 6| Step: 13
Training loss: 0.25962841510772705
Validation loss: 2.0524922211964927

Epoch: 450| Step: 0
Training loss: 0.2072688639163971
Validation loss: 2.093421439329783

Epoch: 6| Step: 1
Training loss: 0.34397202730178833
Validation loss: 2.0722023049990335

Epoch: 6| Step: 2
Training loss: 0.21029846370220184
Validation loss: 2.1012351910273233

Epoch: 6| Step: 3
Training loss: 0.4054955840110779
Validation loss: 2.0701438585917153

Epoch: 6| Step: 4
Training loss: 0.3781774044036865
Validation loss: 2.143376628557841

Epoch: 6| Step: 5
Training loss: 0.2848430275917053
Validation loss: 2.050762335459391

Epoch: 6| Step: 6
Training loss: 0.2767525613307953
Validation loss: 2.1173813541730246

Epoch: 6| Step: 7
Training loss: 0.35597461462020874
Validation loss: 2.1195432345072427

Epoch: 6| Step: 8
Training loss: 0.5084624290466309
Validation loss: 2.1107104818026223

Epoch: 6| Step: 9
Training loss: 0.2596467137336731
Validation loss: 2.063829183578491

Epoch: 6| Step: 10
Training loss: 0.27126994729042053
Validation loss: 2.129382093747457

Epoch: 6| Step: 11
Training loss: 0.2594240605831146
Validation loss: 2.132957379023234

Epoch: 6| Step: 12
Training loss: 0.6161249876022339
Validation loss: 2.1606003046035767

Epoch: 6| Step: 13
Training loss: 0.3038165271282196
Validation loss: 2.1598209738731384

Testing loss: 2.1549545637995218
