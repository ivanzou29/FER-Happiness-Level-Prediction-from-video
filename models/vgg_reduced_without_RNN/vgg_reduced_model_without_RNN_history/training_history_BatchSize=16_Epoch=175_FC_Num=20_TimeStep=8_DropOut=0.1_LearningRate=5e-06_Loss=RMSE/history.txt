Epoch: 1| Step: 0
Training loss: 8.371762689091284
Validation loss: 7.902360203025486

Epoch: 6| Step: 1
Training loss: 8.30865710924361
Validation loss: 7.889608447371781

Epoch: 6| Step: 2
Training loss: 7.086962977925614
Validation loss: 7.873508776401221

Epoch: 6| Step: 3
Training loss: 7.652883856242604
Validation loss: 7.863531086909059

Epoch: 6| Step: 4
Training loss: 7.7373179375793715
Validation loss: 7.84978983085474

Epoch: 6| Step: 5
Training loss: 8.509897192077386
Validation loss: 7.839366929386347

Epoch: 6| Step: 6
Training loss: 7.277464312272939
Validation loss: 7.828211415233274

Epoch: 6| Step: 7
Training loss: 7.797361064430183
Validation loss: 7.813790827605693

Epoch: 6| Step: 8
Training loss: 7.968771541790736
Validation loss: 7.803968974995692

Epoch: 6| Step: 9
Training loss: 8.038461735023043
Validation loss: 7.791739709957141

Epoch: 6| Step: 10
Training loss: 7.852562805527001
Validation loss: 7.781904445840955

Epoch: 6| Step: 11
Training loss: 7.581721319657253
Validation loss: 7.769426383795091

Epoch: 6| Step: 12
Training loss: 8.833490142390103
Validation loss: 7.759759643869874

Epoch: 6| Step: 13
Training loss: 7.784810304970507
Validation loss: 7.747776368783835

Epoch: 2| Step: 0
Training loss: 7.7481807911605785
Validation loss: 7.737047261687746

Epoch: 6| Step: 1
Training loss: 7.833873351401018
Validation loss: 7.724608593091511

Epoch: 6| Step: 2
Training loss: 8.421054665665633
Validation loss: 7.712994281545272

Epoch: 6| Step: 3
Training loss: 6.864565056722003
Validation loss: 7.700370208295699

Epoch: 6| Step: 4
Training loss: 7.369159519505992
Validation loss: 7.690042752336006

Epoch: 6| Step: 5
Training loss: 8.345601880017169
Validation loss: 7.677995880287485

Epoch: 6| Step: 6
Training loss: 7.50681758008439
Validation loss: 7.666095242420951

Epoch: 6| Step: 7
Training loss: 8.185353237911881
Validation loss: 7.6520930416780555

Epoch: 6| Step: 8
Training loss: 8.053460783465722
Validation loss: 7.638378642602134

Epoch: 6| Step: 9
Training loss: 7.568307711517215
Validation loss: 7.624635239511713

Epoch: 6| Step: 10
Training loss: 7.90381835212937
Validation loss: 7.61179592674607

Epoch: 6| Step: 11
Training loss: 6.871777698336258
Validation loss: 7.595115758580015

Epoch: 6| Step: 12
Training loss: 7.673864165017813
Validation loss: 7.582172039388157

Epoch: 6| Step: 13
Training loss: 8.055356194963347
Validation loss: 7.568477569641597

Epoch: 3| Step: 0
Training loss: 8.345292423854806
Validation loss: 7.550247439272863

Epoch: 6| Step: 1
Training loss: 8.154820576371531
Validation loss: 7.533818778992099

Epoch: 6| Step: 2
Training loss: 7.03035937284695
Validation loss: 7.5196553696466175

Epoch: 6| Step: 3
Training loss: 7.0651815269350955
Validation loss: 7.501929607121103

Epoch: 6| Step: 4
Training loss: 6.105454691982376
Validation loss: 7.48649576677679

Epoch: 6| Step: 5
Training loss: 8.119363091205857
Validation loss: 7.468720461309483

Epoch: 6| Step: 6
Training loss: 7.705589782203667
Validation loss: 7.451529384717297

Epoch: 6| Step: 7
Training loss: 8.057334013722617
Validation loss: 7.4328443985097445

Epoch: 6| Step: 8
Training loss: 8.081008839088216
Validation loss: 7.414983351198533

Epoch: 6| Step: 9
Training loss: 7.252831793910687
Validation loss: 7.397847362534945

Epoch: 6| Step: 10
Training loss: 6.789252415712485
Validation loss: 7.373711295601017

Epoch: 6| Step: 11
Training loss: 7.558385817553387
Validation loss: 7.3581488816963985

Epoch: 6| Step: 12
Training loss: 7.410706543384913
Validation loss: 7.3345030660870565

Epoch: 6| Step: 13
Training loss: 7.516654786680635
Validation loss: 7.318769848126374

Epoch: 4| Step: 0
Training loss: 7.21025424419064
Validation loss: 7.299787769106649

Epoch: 6| Step: 1
Training loss: 7.807454425386816
Validation loss: 7.27317552268869

Epoch: 6| Step: 2
Training loss: 7.041888652966706
Validation loss: 7.256957782284913

Epoch: 6| Step: 3
Training loss: 7.371935450171423
Validation loss: 7.241362457850848

Epoch: 6| Step: 4
Training loss: 8.057940946202105
Validation loss: 7.2132879733612025

Epoch: 6| Step: 5
Training loss: 7.096601946410058
Validation loss: 7.1996101415131255

Epoch: 6| Step: 6
Training loss: 7.046321195845357
Validation loss: 7.177981057977577

Epoch: 6| Step: 7
Training loss: 6.955076205331805
Validation loss: 7.1647530447901975

Epoch: 6| Step: 8
Training loss: 6.076960670332624
Validation loss: 7.144355717541955

Epoch: 6| Step: 9
Training loss: 7.071052436678423
Validation loss: 7.1270283717452525

Epoch: 6| Step: 10
Training loss: 7.721544261906049
Validation loss: 7.114238933607129

Epoch: 6| Step: 11
Training loss: 6.8934943005615805
Validation loss: 7.100351855017271

Epoch: 6| Step: 12
Training loss: 6.924107176587541
Validation loss: 7.088417188535734

Epoch: 6| Step: 13
Training loss: 8.376934226706942
Validation loss: 7.075911983666422

Epoch: 5| Step: 0
Training loss: 7.565327769841616
Validation loss: 7.059599649390616

Epoch: 6| Step: 1
Training loss: 7.266759771514694
Validation loss: 7.0391878207923675

Epoch: 6| Step: 2
Training loss: 7.249128618162065
Validation loss: 7.042216518385478

Epoch: 6| Step: 3
Training loss: 7.170570138478519
Validation loss: 7.024014560640923

Epoch: 6| Step: 4
Training loss: 6.611920094435888
Validation loss: 7.011999154748918

Epoch: 6| Step: 5
Training loss: 7.306487652100887
Validation loss: 6.981090071851859

Epoch: 6| Step: 6
Training loss: 6.7182793030979
Validation loss: 6.981238290201474

Epoch: 6| Step: 7
Training loss: 7.360089763425687
Validation loss: 6.955768119981912

Epoch: 6| Step: 8
Training loss: 7.3652522436636865
Validation loss: 6.909491191262596

Epoch: 6| Step: 9
Training loss: 6.621897420804716
Validation loss: 6.881306616665434

Epoch: 6| Step: 10
Training loss: 7.647145365747472
Validation loss: 6.851646153147035

Epoch: 6| Step: 11
Training loss: 7.236757219902741
Validation loss: 6.7820886893158585

Epoch: 6| Step: 12
Training loss: 5.287782680449261
Validation loss: 6.740965884659716

Epoch: 6| Step: 13
Training loss: 6.856066903214091
Validation loss: 6.687159283000875

Epoch: 6| Step: 0
Training loss: 6.575513742776705
Validation loss: 6.6376855186115895

Epoch: 6| Step: 1
Training loss: 6.943760976430765
Validation loss: 6.592917584129061

Epoch: 6| Step: 2
Training loss: 6.4821320480742965
Validation loss: 6.5150679998979495

Epoch: 6| Step: 3
Training loss: 6.808004593431871
Validation loss: 6.454836565308131

Epoch: 6| Step: 4
Training loss: 7.007680221891204
Validation loss: 6.3787005785154385

Epoch: 6| Step: 5
Training loss: 6.492990382156992
Validation loss: 6.317791801167523

Epoch: 6| Step: 6
Training loss: 6.493264449822757
Validation loss: 6.237441683020729

Epoch: 6| Step: 7
Training loss: 6.561309415810231
Validation loss: 6.177753208456116

Epoch: 6| Step: 8
Training loss: 5.708096613001516
Validation loss: 6.093572865055369

Epoch: 6| Step: 9
Training loss: 6.321698125306206
Validation loss: 6.006011812089858

Epoch: 6| Step: 10
Training loss: 5.676237588115765
Validation loss: 5.93916985303439

Epoch: 6| Step: 11
Training loss: 4.882072600190943
Validation loss: 5.828808782724093

Epoch: 6| Step: 12
Training loss: 5.902685633918775
Validation loss: 5.7620909903590345

Epoch: 6| Step: 13
Training loss: 6.109373751198722
Validation loss: 5.672146176808059

Epoch: 7| Step: 0
Training loss: 6.193100369564505
Validation loss: 5.59099543712259

Epoch: 6| Step: 1
Training loss: 5.07516101901176
Validation loss: 5.488436362539679

Epoch: 6| Step: 2
Training loss: 5.892270938400867
Validation loss: 5.4096157644056255

Epoch: 6| Step: 3
Training loss: 6.16527658552125
Validation loss: 5.299720682425337

Epoch: 6| Step: 4
Training loss: 5.337408575128155
Validation loss: 5.22233431044245

Epoch: 6| Step: 5
Training loss: 4.6395831752869
Validation loss: 5.086402383507411

Epoch: 6| Step: 6
Training loss: 4.773508224337973
Validation loss: 4.991424263411012

Epoch: 6| Step: 7
Training loss: 5.616302887467813
Validation loss: 4.911639774189776

Epoch: 6| Step: 8
Training loss: 4.210920740777179
Validation loss: 4.823040240402603

Epoch: 6| Step: 9
Training loss: 4.509475692079519
Validation loss: 4.691576528727895

Epoch: 6| Step: 10
Training loss: 4.569104157170448
Validation loss: 4.600511967461043

Epoch: 6| Step: 11
Training loss: 4.649600407648561
Validation loss: 4.4818603873148755

Epoch: 6| Step: 12
Training loss: 4.326769234294329
Validation loss: 4.372570562213171

Epoch: 6| Step: 13
Training loss: 4.200651327220099
Validation loss: 4.265495643005066

Epoch: 8| Step: 0
Training loss: 4.02198092566415
Validation loss: 4.163631109110934

Epoch: 6| Step: 1
Training loss: 4.199107465821932
Validation loss: 4.04070018079796

Epoch: 6| Step: 2
Training loss: 4.374473322092972
Validation loss: 3.8897238917290697

Epoch: 6| Step: 3
Training loss: 2.5565858839453304
Validation loss: 3.8135588587804348

Epoch: 6| Step: 4
Training loss: 3.6807645934300846
Validation loss: 3.6590171841001293

Epoch: 6| Step: 5
Training loss: 3.8144606254726567
Validation loss: 3.5226089394272324

Epoch: 6| Step: 6
Training loss: 3.755450420362682
Validation loss: 3.465300898622393

Epoch: 6| Step: 7
Training loss: 3.8515600239279566
Validation loss: 3.3442681644898187

Epoch: 6| Step: 8
Training loss: 3.0713522511882134
Validation loss: 3.244379477652454

Epoch: 6| Step: 9
Training loss: 2.1887563095132547
Validation loss: 3.149956083748481

Epoch: 6| Step: 10
Training loss: 3.418383763866759
Validation loss: 3.0381126978942374

Epoch: 6| Step: 11
Training loss: 2.2216441660965267
Validation loss: 3.058726743467585

Epoch: 6| Step: 12
Training loss: 2.713998259474239
Validation loss: 2.9581959025379914

Epoch: 6| Step: 13
Training loss: 2.9320820292490315
Validation loss: 2.952773555989047

Epoch: 9| Step: 0
Training loss: 2.464294469118856
Validation loss: 2.8857722126473986

Epoch: 6| Step: 1
Training loss: 3.208084361006422
Validation loss: 2.8835232762155267

Epoch: 6| Step: 2
Training loss: 1.7818563667321277
Validation loss: 2.9519870859921564

Epoch: 6| Step: 3
Training loss: 2.4310146031507958
Validation loss: 2.9634614787234

Epoch: 6| Step: 4
Training loss: 2.3469578470573897
Validation loss: 3.0231719249495455

Epoch: 6| Step: 5
Training loss: 2.4851767727706906
Validation loss: 3.0096953604762584

Epoch: 6| Step: 6
Training loss: 3.5669621413531543
Validation loss: 3.080976414479702

Epoch: 6| Step: 7
Training loss: 4.29648768673445
Validation loss: 3.021775044073781

Epoch: 6| Step: 8
Training loss: 2.558521904555458
Validation loss: 3.1090144550612804

Epoch: 6| Step: 9
Training loss: 2.5624585032010647
Validation loss: 3.039749028738202

Epoch: 6| Step: 10
Training loss: 3.812621067813884
Validation loss: 2.9855990071769325

Epoch: 6| Step: 11
Training loss: 2.54931879107399
Validation loss: 3.0372744859828376

Epoch: 6| Step: 12
Training loss: 2.52833228846985
Validation loss: 2.9848281755946164

Epoch: 6| Step: 13
Training loss: 2.730333404024378
Validation loss: 2.932915322546026

Epoch: 10| Step: 0
Training loss: 3.222082838427341
Validation loss: 2.8702105973895558

Epoch: 6| Step: 1
Training loss: 2.8722884618358937
Validation loss: 2.851554529187633

Epoch: 6| Step: 2
Training loss: 1.6384509986904898
Validation loss: 2.8621363829500375

Epoch: 6| Step: 3
Training loss: 2.043739071504731
Validation loss: 2.826194209476527

Epoch: 6| Step: 4
Training loss: 2.160202494948876
Validation loss: 2.8556612839609286

Epoch: 6| Step: 5
Training loss: 2.9331925647366166
Validation loss: 2.825369769627278

Epoch: 6| Step: 6
Training loss: 3.071624242690054
Validation loss: 2.8955789815680975

Epoch: 6| Step: 7
Training loss: 2.436973612752446
Validation loss: 2.8711221222113577

Epoch: 6| Step: 8
Training loss: 3.1833939378438503
Validation loss: 2.886857101297952

Epoch: 6| Step: 9
Training loss: 3.2414635275089707
Validation loss: 2.8397427785379548

Epoch: 6| Step: 10
Training loss: 2.3398027878170553
Validation loss: 2.8334498848971714

Epoch: 6| Step: 11
Training loss: 2.8564858771158153
Validation loss: 2.8514641592408876

Epoch: 6| Step: 12
Training loss: 2.466566254745713
Validation loss: 2.8521030000872853

Epoch: 6| Step: 13
Training loss: 3.703183201843519
Validation loss: 2.869834724190952

Epoch: 11| Step: 0
Training loss: 2.383738253503992
Validation loss: 2.833750039667018

Epoch: 6| Step: 1
Training loss: 3.00213038778038
Validation loss: 2.8036230789462135

Epoch: 6| Step: 2
Training loss: 3.0041108576387305
Validation loss: 2.8527563931477617

Epoch: 6| Step: 3
Training loss: 2.907593775357899
Validation loss: 2.927556733825816

Epoch: 6| Step: 4
Training loss: 2.51805537563332
Validation loss: 2.8246871820058503

Epoch: 6| Step: 5
Training loss: 2.408498827870032
Validation loss: 2.8527672996398725

Epoch: 6| Step: 6
Training loss: 2.6546000124394826
Validation loss: 2.8512238741264055

Epoch: 6| Step: 7
Training loss: 2.8712769326660323
Validation loss: 2.894084654009513

Epoch: 6| Step: 8
Training loss: 2.233880902058684
Validation loss: 2.8019838043650633

Epoch: 6| Step: 9
Training loss: 2.2805565603142757
Validation loss: 2.863478733137638

Epoch: 6| Step: 10
Training loss: 3.175544307639286
Validation loss: 2.865463944529947

Epoch: 6| Step: 11
Training loss: 3.046301372033859
Validation loss: 2.819813072105494

Epoch: 6| Step: 12
Training loss: 2.596367491927367
Validation loss: 2.884288826781763

Epoch: 6| Step: 13
Training loss: 2.9811524573149364
Validation loss: 2.8173668325974823

Epoch: 12| Step: 0
Training loss: 3.369591511948809
Validation loss: 2.88822361630043

Epoch: 6| Step: 1
Training loss: 3.4219236326898685
Validation loss: 2.80276010747388

Epoch: 6| Step: 2
Training loss: 2.6495555217027342
Validation loss: 2.885728679179995

Epoch: 6| Step: 3
Training loss: 2.8334652552092514
Validation loss: 2.8235087506934544

Epoch: 6| Step: 4
Training loss: 2.9661976332770212
Validation loss: 2.770655107622141

Epoch: 6| Step: 5
Training loss: 2.6157443038731114
Validation loss: 2.80837819453177

Epoch: 6| Step: 6
Training loss: 3.3303530403383688
Validation loss: 2.831883148179392

Epoch: 6| Step: 7
Training loss: 2.137648469107591
Validation loss: 2.80658158550138

Epoch: 6| Step: 8
Training loss: 2.3718053513504906
Validation loss: 2.8122098419842696

Epoch: 6| Step: 9
Training loss: 1.6061719111003692
Validation loss: 2.7835877840911603

Epoch: 6| Step: 10
Training loss: 2.8483206100879097
Validation loss: 2.8219762035540796

Epoch: 6| Step: 11
Training loss: 2.1201226978063468
Validation loss: 2.784788673688267

Epoch: 6| Step: 12
Training loss: 2.72352032516344
Validation loss: 2.8218603703375544

Epoch: 6| Step: 13
Training loss: 2.388013822378158
Validation loss: 2.8560009976509053

Epoch: 13| Step: 0
Training loss: 2.959542220002536
Validation loss: 2.8213380620303243

Epoch: 6| Step: 1
Training loss: 2.8377449434067477
Validation loss: 2.8096246927351163

Epoch: 6| Step: 2
Training loss: 2.314945165425523
Validation loss: 2.8277685457123463

Epoch: 6| Step: 3
Training loss: 3.318521460873697
Validation loss: 2.7917123098105727

Epoch: 6| Step: 4
Training loss: 2.2246340247070475
Validation loss: 2.8119397629724814

Epoch: 6| Step: 5
Training loss: 2.918131669282594
Validation loss: 2.814423913250373

Epoch: 6| Step: 6
Training loss: 2.360249338394588
Validation loss: 2.7604442715014303

Epoch: 6| Step: 7
Training loss: 3.0902732039476093
Validation loss: 2.8069521404372466

Epoch: 6| Step: 8
Training loss: 3.408210400242951
Validation loss: 2.7513537542735933

Epoch: 6| Step: 9
Training loss: 2.0059379406245257
Validation loss: 2.795966428799843

Epoch: 6| Step: 10
Training loss: 2.1540892458591347
Validation loss: 2.850376777951611

Epoch: 6| Step: 11
Training loss: 2.5241803944683427
Validation loss: 2.779451438768267

Epoch: 6| Step: 12
Training loss: 3.176879092462828
Validation loss: 2.818640173487394

Epoch: 6| Step: 13
Training loss: 2.132838210625137
Validation loss: 2.79828169413987

Epoch: 14| Step: 0
Training loss: 3.3716623262184804
Validation loss: 2.8021942504334114

Epoch: 6| Step: 1
Training loss: 3.0314117073893585
Validation loss: 2.7902059196948406

Epoch: 6| Step: 2
Training loss: 2.3100548266225096
Validation loss: 2.824752328081424

Epoch: 6| Step: 3
Training loss: 3.2911098025285948
Validation loss: 2.7616071089463734

Epoch: 6| Step: 4
Training loss: 2.6051420495957176
Validation loss: 2.763603175447294

Epoch: 6| Step: 5
Training loss: 2.8182629352652744
Validation loss: 2.8109014277310926

Epoch: 6| Step: 6
Training loss: 2.1877989428475715
Validation loss: 2.785324626610738

Epoch: 6| Step: 7
Training loss: 3.2188145899541887
Validation loss: 2.722753930768265

Epoch: 6| Step: 8
Training loss: 2.1022659882758474
Validation loss: 2.790274904168498

Epoch: 6| Step: 9
Training loss: 2.0738906744575645
Validation loss: 2.764739747977894

Epoch: 6| Step: 10
Training loss: 3.225384439428034
Validation loss: 2.833620061577815

Epoch: 6| Step: 11
Training loss: 2.1716889226226312
Validation loss: 2.7357210896853346

Epoch: 6| Step: 12
Training loss: 2.2878045801724642
Validation loss: 2.8099245783502527

Epoch: 6| Step: 13
Training loss: 2.9139518819068306
Validation loss: 2.7916944962627928

Epoch: 15| Step: 0
Training loss: 1.8748390764479745
Validation loss: 2.8502944983751863

Epoch: 6| Step: 1
Training loss: 1.9802315172995109
Validation loss: 2.827471002373265

Epoch: 6| Step: 2
Training loss: 1.8850144296189952
Validation loss: 2.8253562961375516

Epoch: 6| Step: 3
Training loss: 2.5333794949324586
Validation loss: 2.7987070387961404

Epoch: 6| Step: 4
Training loss: 2.421539283372361
Validation loss: 2.834862973996174

Epoch: 6| Step: 5
Training loss: 2.7658290464485447
Validation loss: 2.788158964947723

Epoch: 6| Step: 6
Training loss: 2.466006722533135
Validation loss: 2.76626499048427

Epoch: 6| Step: 7
Training loss: 3.4841156593596905
Validation loss: 2.821863918909316

Epoch: 6| Step: 8
Training loss: 3.0650372018469945
Validation loss: 2.809871971634786

Epoch: 6| Step: 9
Training loss: 3.2982816904223022
Validation loss: 2.8171196614675384

Epoch: 6| Step: 10
Training loss: 3.403584128270211
Validation loss: 2.7955112222450693

Epoch: 6| Step: 11
Training loss: 2.4110764488779663
Validation loss: 2.749822495251546

Epoch: 6| Step: 12
Training loss: 2.6332715819961185
Validation loss: 2.7830689015286203

Epoch: 6| Step: 13
Training loss: 2.8455642111234223
Validation loss: 2.818525697590192

Epoch: 16| Step: 0
Training loss: 2.135959078743241
Validation loss: 2.7504777926748356

Epoch: 6| Step: 1
Training loss: 2.4143741739791573
Validation loss: 2.766702589315045

Epoch: 6| Step: 2
Training loss: 3.312028671416974
Validation loss: 2.7622651418905644

Epoch: 6| Step: 3
Training loss: 2.721910065207183
Validation loss: 2.7553938939585856

Epoch: 6| Step: 4
Training loss: 3.2156333278181157
Validation loss: 2.7443745903652497

Epoch: 6| Step: 5
Training loss: 2.7658059443533034
Validation loss: 2.7403721900483218

Epoch: 6| Step: 6
Training loss: 2.688874891032765
Validation loss: 2.7725794938033466

Epoch: 6| Step: 7
Training loss: 2.9749052785972827
Validation loss: 2.779559060743055

Epoch: 6| Step: 8
Training loss: 2.1984172329378526
Validation loss: 2.7573030053397862

Epoch: 6| Step: 9
Training loss: 2.4674159441296504
Validation loss: 2.74803474313335

Epoch: 6| Step: 10
Training loss: 2.432715978649353
Validation loss: 2.816078777207462

Epoch: 6| Step: 11
Training loss: 2.242287450815564
Validation loss: 2.788060725198869

Epoch: 6| Step: 12
Training loss: 2.4990189534751193
Validation loss: 2.7776322713465227

Epoch: 6| Step: 13
Training loss: 3.4881617748821547
Validation loss: 2.722661460313231

Epoch: 17| Step: 0
Training loss: 1.951709203650173
Validation loss: 2.7382220716698096

Epoch: 6| Step: 1
Training loss: 2.692393173181235
Validation loss: 2.7636644558756425

Epoch: 6| Step: 2
Training loss: 2.2957545032110187
Validation loss: 2.799557456171216

Epoch: 6| Step: 3
Training loss: 2.2881104243714794
Validation loss: 2.79167864687802

Epoch: 6| Step: 4
Training loss: 3.289500590164171
Validation loss: 2.8581854703228564

Epoch: 6| Step: 5
Training loss: 3.297204457675892
Validation loss: 2.748561627460502

Epoch: 6| Step: 6
Training loss: 2.7409861832291007
Validation loss: 2.7325014798555034

Epoch: 6| Step: 7
Training loss: 2.8367412678658215
Validation loss: 2.8018913817807864

Epoch: 6| Step: 8
Training loss: 2.5741663277690545
Validation loss: 2.727620907675621

Epoch: 6| Step: 9
Training loss: 2.4516859754073885
Validation loss: 2.832000914663322

Epoch: 6| Step: 10
Training loss: 3.2752287340730946
Validation loss: 2.813990318195829

Epoch: 6| Step: 11
Training loss: 2.474768340703615
Validation loss: 2.757159702461101

Epoch: 6| Step: 12
Training loss: 2.031474174453657
Validation loss: 2.7331890331728457

Epoch: 6| Step: 13
Training loss: 2.4733158816658434
Validation loss: 2.790385768499633

Epoch: 18| Step: 0
Training loss: 2.122818107176403
Validation loss: 2.7513387773591034

Epoch: 6| Step: 1
Training loss: 2.17424222527077
Validation loss: 2.717772911145745

Epoch: 6| Step: 2
Training loss: 2.48360666353865
Validation loss: 2.7394518415759093

Epoch: 6| Step: 3
Training loss: 2.986150562903045
Validation loss: 2.7204011309984413

Epoch: 6| Step: 4
Training loss: 2.5023238825299643
Validation loss: 2.748062961570146

Epoch: 6| Step: 5
Training loss: 2.093177375491278
Validation loss: 2.771930439139096

Epoch: 6| Step: 6
Training loss: 3.3297146864541527
Validation loss: 2.676304987307325

Epoch: 6| Step: 7
Training loss: 2.92352803027418
Validation loss: 2.719857162179832

Epoch: 6| Step: 8
Training loss: 2.833983028945235
Validation loss: 2.6895007293410838

Epoch: 6| Step: 9
Training loss: 3.45109311906107
Validation loss: 2.673975693146413

Epoch: 6| Step: 10
Training loss: 2.4531690265568056
Validation loss: 2.768317756180303

Epoch: 6| Step: 11
Training loss: 2.335404657428864
Validation loss: 2.796786585712089

Epoch: 6| Step: 12
Training loss: 2.9240897041890714
Validation loss: 2.7121775609819703

Epoch: 6| Step: 13
Training loss: 2.3462019238350367
Validation loss: 2.7046638033758246

Epoch: 19| Step: 0
Training loss: 2.8718629390558763
Validation loss: 2.811377916084627

Epoch: 6| Step: 1
Training loss: 2.347678998433879
Validation loss: 2.749727640247369

Epoch: 6| Step: 2
Training loss: 2.39745069451096
Validation loss: 2.8176068741917266

Epoch: 6| Step: 3
Training loss: 2.1769017291337853
Validation loss: 2.716245893840141

Epoch: 6| Step: 4
Training loss: 2.47573858087713
Validation loss: 2.6340942281457305

Epoch: 6| Step: 5
Training loss: 2.852682651352262
Validation loss: 2.7214924072976427

Epoch: 6| Step: 6
Training loss: 2.4604449066772345
Validation loss: 2.720083282471949

Epoch: 6| Step: 7
Training loss: 3.3034330832480996
Validation loss: 2.7732258890579637

Epoch: 6| Step: 8
Training loss: 2.4111268795492014
Validation loss: 2.7795342857559704

Epoch: 6| Step: 9
Training loss: 2.82458172967819
Validation loss: 2.739660839729813

Epoch: 6| Step: 10
Training loss: 3.7752726576402886
Validation loss: 2.718775913509653

Epoch: 6| Step: 11
Training loss: 2.1543756714397344
Validation loss: 2.778854681649558

Epoch: 6| Step: 12
Training loss: 2.381291138301145
Validation loss: 2.7437151849459718

Epoch: 6| Step: 13
Training loss: 2.1249094551094005
Validation loss: 2.743519864173975

Epoch: 20| Step: 0
Training loss: 1.8465946688313657
Validation loss: 2.7589605173491525

Epoch: 6| Step: 1
Training loss: 2.285972410340913
Validation loss: 2.779702831366839

Epoch: 6| Step: 2
Training loss: 2.73985604402271
Validation loss: 2.7387056189660774

Epoch: 6| Step: 3
Training loss: 2.934943689849168
Validation loss: 2.689713549742836

Epoch: 6| Step: 4
Training loss: 2.037059516333162
Validation loss: 2.6804681943801874

Epoch: 6| Step: 5
Training loss: 2.171625356254445
Validation loss: 2.7106809027432925

Epoch: 6| Step: 6
Training loss: 2.122225801798857
Validation loss: 2.72937819459526

Epoch: 6| Step: 7
Training loss: 2.790017955407779
Validation loss: 2.8229941935761613

Epoch: 6| Step: 8
Training loss: 3.0944048255957735
Validation loss: 2.7299764368533173

Epoch: 6| Step: 9
Training loss: 3.010338611756837
Validation loss: 2.7357410324783085

Epoch: 6| Step: 10
Training loss: 3.122426308341862
Validation loss: 2.722106980351924

Epoch: 6| Step: 11
Training loss: 2.1966085171950236
Validation loss: 2.740893907450786

Epoch: 6| Step: 12
Training loss: 3.1402511753772195
Validation loss: 2.6959632272297167

Epoch: 6| Step: 13
Training loss: 2.9444596652071393
Validation loss: 2.735875834974307

Epoch: 21| Step: 0
Training loss: 1.6694998581558629
Validation loss: 2.675350152625453

Epoch: 6| Step: 1
Training loss: 2.102089741309247
Validation loss: 2.722264878810299

Epoch: 6| Step: 2
Training loss: 2.4164347921043072
Validation loss: 2.7330298321172046

Epoch: 6| Step: 3
Training loss: 2.887504253962302
Validation loss: 2.712415199008972

Epoch: 6| Step: 4
Training loss: 2.555921997068071
Validation loss: 2.7430103223158864

Epoch: 6| Step: 5
Training loss: 2.550476897281066
Validation loss: 2.7066692130385324

Epoch: 6| Step: 6
Training loss: 3.074279551892377
Validation loss: 2.741716103460734

Epoch: 6| Step: 7
Training loss: 2.6783467044112794
Validation loss: 2.7261457297773193

Epoch: 6| Step: 8
Training loss: 2.698909758397299
Validation loss: 2.740965495748175

Epoch: 6| Step: 9
Training loss: 2.5725827843457267
Validation loss: 2.772921747957232

Epoch: 6| Step: 10
Training loss: 3.9283905012405294
Validation loss: 2.6633234276028337

Epoch: 6| Step: 11
Training loss: 3.2248177232906836
Validation loss: 2.711541657273372

Epoch: 6| Step: 12
Training loss: 1.6687678761185554
Validation loss: 2.673230962989163

Epoch: 6| Step: 13
Training loss: 1.8620796087601494
Validation loss: 2.7483362453561706

Epoch: 22| Step: 0
Training loss: 3.296525981923927
Validation loss: 2.716284646241769

Epoch: 6| Step: 1
Training loss: 2.705488461657545
Validation loss: 2.7425556714583537

Epoch: 6| Step: 2
Training loss: 2.999202622302952
Validation loss: 2.8144655494318638

Epoch: 6| Step: 3
Training loss: 3.0971668525464056
Validation loss: 2.762884833571922

Epoch: 6| Step: 4
Training loss: 1.676201543143149
Validation loss: 2.7199463386244482

Epoch: 6| Step: 5
Training loss: 2.6767590594784583
Validation loss: 2.7106214003729234

Epoch: 6| Step: 6
Training loss: 2.6348036303087343
Validation loss: 2.7318774924655616

Epoch: 6| Step: 7
Training loss: 2.955594922124641
Validation loss: 2.6956507963459693

Epoch: 6| Step: 8
Training loss: 1.593603314399911
Validation loss: 2.6780805523988676

Epoch: 6| Step: 9
Training loss: 2.17276981500016
Validation loss: 2.7552991009611727

Epoch: 6| Step: 10
Training loss: 2.2864270972085703
Validation loss: 2.7122491893454743

Epoch: 6| Step: 11
Training loss: 3.0202016937406717
Validation loss: 2.7555131845737373

Epoch: 6| Step: 12
Training loss: 2.095191573167352
Validation loss: 2.760764151720713

Epoch: 6| Step: 13
Training loss: 2.5262601672708334
Validation loss: 2.7303286886242844

Epoch: 23| Step: 0
Training loss: 2.8646916224501093
Validation loss: 2.733008662766891

Epoch: 6| Step: 1
Training loss: 1.7272465244158308
Validation loss: 2.7267208690976448

Epoch: 6| Step: 2
Training loss: 2.5334144098291405
Validation loss: 2.7021559961137656

Epoch: 6| Step: 3
Training loss: 2.5529264860824066
Validation loss: 2.803140466846562

Epoch: 6| Step: 4
Training loss: 2.1090042353551817
Validation loss: 2.7233121456814606

Epoch: 6| Step: 5
Training loss: 2.256598017262098
Validation loss: 2.6562929785748257

Epoch: 6| Step: 6
Training loss: 2.7724504460549118
Validation loss: 2.662009185301317

Epoch: 6| Step: 7
Training loss: 1.908018198882187
Validation loss: 2.6410818363160136

Epoch: 6| Step: 8
Training loss: 2.8537594210000914
Validation loss: 2.694897930309642

Epoch: 6| Step: 9
Training loss: 2.8740856541112287
Validation loss: 2.7429150289173

Epoch: 6| Step: 10
Training loss: 2.842439286549017
Validation loss: 2.673845527467831

Epoch: 6| Step: 11
Training loss: 2.7974909098923226
Validation loss: 2.6855274916440637

Epoch: 6| Step: 12
Training loss: 3.464652588397367
Validation loss: 2.6534219384694597

Epoch: 6| Step: 13
Training loss: 2.423781598157141
Validation loss: 2.7176258788656815

Epoch: 24| Step: 0
Training loss: 2.7250431057381648
Validation loss: 2.7195020636651055

Epoch: 6| Step: 1
Training loss: 2.8398217537512127
Validation loss: 2.8024833327520047

Epoch: 6| Step: 2
Training loss: 2.8094707706069437
Validation loss: 2.769387582658372

Epoch: 6| Step: 3
Training loss: 1.9431658317764147
Validation loss: 2.8270510325675

Epoch: 6| Step: 4
Training loss: 2.0356112097933936
Validation loss: 2.9026307981921167

Epoch: 6| Step: 5
Training loss: 3.1227468378681498
Validation loss: 2.908665900539892

Epoch: 6| Step: 6
Training loss: 2.7656541380990634
Validation loss: 2.8702850656127588

Epoch: 6| Step: 7
Training loss: 1.7009484618473423
Validation loss: 2.8840405296078266

Epoch: 6| Step: 8
Training loss: 2.7023572768672093
Validation loss: 2.8763618146439898

Epoch: 6| Step: 9
Training loss: 3.352170520041391
Validation loss: 2.8388825844704866

Epoch: 6| Step: 10
Training loss: 3.2425383963918137
Validation loss: 2.7821062463016126

Epoch: 6| Step: 11
Training loss: 3.291334223960842
Validation loss: 2.7480583416614373

Epoch: 6| Step: 12
Training loss: 1.8567890810147858
Validation loss: 2.7530498354376

Epoch: 6| Step: 13
Training loss: 2.381504187446291
Validation loss: 2.685542406483025

Epoch: 25| Step: 0
Training loss: 3.535941998743962
Validation loss: 2.6534321667444605

Epoch: 6| Step: 1
Training loss: 2.1460295899156323
Validation loss: 2.700714521289043

Epoch: 6| Step: 2
Training loss: 2.8044156338574915
Validation loss: 2.7029611615048483

Epoch: 6| Step: 3
Training loss: 2.2835301539478863
Validation loss: 2.66123224381806

Epoch: 6| Step: 4
Training loss: 2.332941283486587
Validation loss: 2.776116337347473

Epoch: 6| Step: 5
Training loss: 3.0016135009372524
Validation loss: 2.7520254363429575

Epoch: 6| Step: 6
Training loss: 2.818858609359133
Validation loss: 2.7431353953099284

Epoch: 6| Step: 7
Training loss: 2.4695931455536213
Validation loss: 2.7764291164894854

Epoch: 6| Step: 8
Training loss: 2.36042832868029
Validation loss: 2.7214868297212673

Epoch: 6| Step: 9
Training loss: 2.4416560419087996
Validation loss: 2.677026626837339

Epoch: 6| Step: 10
Training loss: 2.96035156894298
Validation loss: 2.6720524779151824

Epoch: 6| Step: 11
Training loss: 2.256490670257357
Validation loss: 2.6575289545667906

Epoch: 6| Step: 12
Training loss: 2.642537795475932
Validation loss: 2.6633859112705642

Epoch: 6| Step: 13
Training loss: 2.2945364121095535
Validation loss: 2.6645949979103762

Epoch: 26| Step: 0
Training loss: 2.7308973595388353
Validation loss: 2.6608072717546998

Epoch: 6| Step: 1
Training loss: 2.84316608177051
Validation loss: 2.8142282191819654

Epoch: 6| Step: 2
Training loss: 3.038392922351904
Validation loss: 2.658175544679775

Epoch: 6| Step: 3
Training loss: 2.230031947775221
Validation loss: 2.765725229174849

Epoch: 6| Step: 4
Training loss: 2.7563566087791944
Validation loss: 2.781433785184754

Epoch: 6| Step: 5
Training loss: 3.077392490966505
Validation loss: 2.7662391052629127

Epoch: 6| Step: 6
Training loss: 2.513862229188889
Validation loss: 2.740209708507232

Epoch: 6| Step: 7
Training loss: 2.8021008988483374
Validation loss: 2.787345215073742

Epoch: 6| Step: 8
Training loss: 2.3746178972154404
Validation loss: 2.7423880232974356

Epoch: 6| Step: 9
Training loss: 2.13058724488265
Validation loss: 2.8090997062457257

Epoch: 6| Step: 10
Training loss: 2.125979478279466
Validation loss: 2.745027019295955

Epoch: 6| Step: 11
Training loss: 2.656213468412622
Validation loss: 2.669975996457237

Epoch: 6| Step: 12
Training loss: 3.240320021754609
Validation loss: 2.728178738490462

Epoch: 6| Step: 13
Training loss: 2.157993220137445
Validation loss: 2.7391748716113304

Epoch: 27| Step: 0
Training loss: 2.9188644484763424
Validation loss: 2.7117943925637285

Epoch: 6| Step: 1
Training loss: 1.6919909869465757
Validation loss: 2.7385517735885436

Epoch: 6| Step: 2
Training loss: 2.6679607072879326
Validation loss: 2.663738734464484

Epoch: 6| Step: 3
Training loss: 2.0551556536159494
Validation loss: 2.6947652952370795

Epoch: 6| Step: 4
Training loss: 2.460955810478756
Validation loss: 2.747033484309583

Epoch: 6| Step: 5
Training loss: 1.7467436466409971
Validation loss: 2.808673162491599

Epoch: 6| Step: 6
Training loss: 2.4611217611449363
Validation loss: 2.6579162756806003

Epoch: 6| Step: 7
Training loss: 2.782993413151832
Validation loss: 2.670513884612496

Epoch: 6| Step: 8
Training loss: 2.651415475647982
Validation loss: 2.8063202747928178

Epoch: 6| Step: 9
Training loss: 2.7503626324237254
Validation loss: 2.7272602634915777

Epoch: 6| Step: 10
Training loss: 2.7352417362368278
Validation loss: 2.657375927322795

Epoch: 6| Step: 11
Training loss: 2.9995053201365294
Validation loss: 2.697454690349411

Epoch: 6| Step: 12
Training loss: 3.423199123090581
Validation loss: 2.7036768913995948

Epoch: 6| Step: 13
Training loss: 2.3244747758146223
Validation loss: 2.6673270738937105

Epoch: 28| Step: 0
Training loss: 2.8288922191272974
Validation loss: 2.6719789689268074

Epoch: 6| Step: 1
Training loss: 2.272506260962931
Validation loss: 2.6850652237351467

Epoch: 6| Step: 2
Training loss: 3.1733721126730035
Validation loss: 2.6857748112904742

Epoch: 6| Step: 3
Training loss: 2.023133715356551
Validation loss: 2.678501040729726

Epoch: 6| Step: 4
Training loss: 3.2146706517133006
Validation loss: 2.67334126325828

Epoch: 6| Step: 5
Training loss: 2.342877747033064
Validation loss: 2.675819994420873

Epoch: 6| Step: 6
Training loss: 2.5463516540161226
Validation loss: 2.6618295598531105

Epoch: 6| Step: 7
Training loss: 2.373015126459432
Validation loss: 2.673714240811297

Epoch: 6| Step: 8
Training loss: 1.7454981801600764
Validation loss: 2.687541946556922

Epoch: 6| Step: 9
Training loss: 3.0662991061595832
Validation loss: 2.6777846509951666

Epoch: 6| Step: 10
Training loss: 2.0574802231794145
Validation loss: 2.7079717590375183

Epoch: 6| Step: 11
Training loss: 2.5835263169921108
Validation loss: 2.6869453478821437

Epoch: 6| Step: 12
Training loss: 2.7850194525595784
Validation loss: 2.7433851620802305

Epoch: 6| Step: 13
Training loss: 2.886201680581454
Validation loss: 2.65844399591584

Epoch: 29| Step: 0
Training loss: 2.240899224306192
Validation loss: 2.6651592961381323

Epoch: 6| Step: 1
Training loss: 1.9639687381478343
Validation loss: 2.7448016799271193

Epoch: 6| Step: 2
Training loss: 2.9183319968745733
Validation loss: 2.690160528566841

Epoch: 6| Step: 3
Training loss: 3.003581293633215
Validation loss: 2.694894996041239

Epoch: 6| Step: 4
Training loss: 2.4847899276391696
Validation loss: 2.711175825652955

Epoch: 6| Step: 5
Training loss: 2.408791030193847
Validation loss: 2.701363711878571

Epoch: 6| Step: 6
Training loss: 2.7464950073019025
Validation loss: 2.689309804547102

Epoch: 6| Step: 7
Training loss: 1.3998247650013846
Validation loss: 2.7181601048823314

Epoch: 6| Step: 8
Training loss: 2.5568987407901584
Validation loss: 2.720627819515222

Epoch: 6| Step: 9
Training loss: 2.144212153585209
Validation loss: 2.7470772990962744

Epoch: 6| Step: 10
Training loss: 2.9042377683965306
Validation loss: 2.7513189765109454

Epoch: 6| Step: 11
Training loss: 2.897930584199249
Validation loss: 2.7004926650007666

Epoch: 6| Step: 12
Training loss: 2.695544246717301
Validation loss: 2.7531204004209604

Epoch: 6| Step: 13
Training loss: 2.958225588560227
Validation loss: 2.6703789967783482

Epoch: 30| Step: 0
Training loss: 2.3892898321676275
Validation loss: 2.719719951263191

Epoch: 6| Step: 1
Training loss: 2.3561583564401096
Validation loss: 2.724934599321986

Epoch: 6| Step: 2
Training loss: 1.881187655914512
Validation loss: 2.6531998269200923

Epoch: 6| Step: 3
Training loss: 2.960714125448351
Validation loss: 2.6811642891701055

Epoch: 6| Step: 4
Training loss: 2.6387479532541986
Validation loss: 2.739997344166566

Epoch: 6| Step: 5
Training loss: 2.2600646089078933
Validation loss: 2.6402182783093395

Epoch: 6| Step: 6
Training loss: 2.6764089920018317
Validation loss: 2.611578492569107

Epoch: 6| Step: 7
Training loss: 2.439370635740035
Validation loss: 2.7083531427881624

Epoch: 6| Step: 8
Training loss: 2.63490045087995
Validation loss: 2.6328858498336754

Epoch: 6| Step: 9
Training loss: 2.324685134896748
Validation loss: 2.6032789980859143

Epoch: 6| Step: 10
Training loss: 3.309174073543311
Validation loss: 2.650110007347947

Epoch: 6| Step: 11
Training loss: 2.416709066435592
Validation loss: 2.648495743822823

Epoch: 6| Step: 12
Training loss: 2.1004896864570886
Validation loss: 2.716222252994432

Epoch: 6| Step: 13
Training loss: 3.1207191137404906
Validation loss: 2.630603214245305

Epoch: 31| Step: 0
Training loss: 3.04288303318177
Validation loss: 2.691305541584427

Epoch: 6| Step: 1
Training loss: 1.976320757048615
Validation loss: 2.6925726929571128

Epoch: 6| Step: 2
Training loss: 2.6429925721865546
Validation loss: 2.6476788329715353

Epoch: 6| Step: 3
Training loss: 3.2492020434358007
Validation loss: 2.6750960834870696

Epoch: 6| Step: 4
Training loss: 2.313889575707297
Validation loss: 2.6475014922102105

Epoch: 6| Step: 5
Training loss: 1.8560197192862786
Validation loss: 2.635914530613499

Epoch: 6| Step: 6
Training loss: 2.1955414242017257
Validation loss: 2.700098677291952

Epoch: 6| Step: 7
Training loss: 2.947884082052458
Validation loss: 2.6780837053982665

Epoch: 6| Step: 8
Training loss: 2.192829506275239
Validation loss: 2.6344289373666063

Epoch: 6| Step: 9
Training loss: 2.8416404864614515
Validation loss: 2.6608654240187275

Epoch: 6| Step: 10
Training loss: 2.8761085363395407
Validation loss: 2.7434942712850883

Epoch: 6| Step: 11
Training loss: 2.8887587012601874
Validation loss: 2.674352571685047

Epoch: 6| Step: 12
Training loss: 2.108838726680275
Validation loss: 2.6941358421238615

Epoch: 6| Step: 13
Training loss: 2.190410748288051
Validation loss: 2.717079292352467

Epoch: 32| Step: 0
Training loss: 2.655029016253577
Validation loss: 2.6965786968196723

Epoch: 6| Step: 1
Training loss: 2.1726101516173224
Validation loss: 2.7034875409804746

Epoch: 6| Step: 2
Training loss: 2.732254339485028
Validation loss: 2.753016565780414

Epoch: 6| Step: 3
Training loss: 2.431944360109109
Validation loss: 2.7548297460926823

Epoch: 6| Step: 4
Training loss: 2.283957768652752
Validation loss: 2.6118207726923757

Epoch: 6| Step: 5
Training loss: 2.4859788623871766
Validation loss: 2.688862159679784

Epoch: 6| Step: 6
Training loss: 1.982617719024686
Validation loss: 2.6403701478667667

Epoch: 6| Step: 7
Training loss: 2.7128248872749885
Validation loss: 2.6342815372031807

Epoch: 6| Step: 8
Training loss: 2.9807847081769365
Validation loss: 2.635725814921129

Epoch: 6| Step: 9
Training loss: 2.723971384477926
Validation loss: 2.6402875093961558

Epoch: 6| Step: 10
Training loss: 2.692920364108984
Validation loss: 2.65758077159588

Epoch: 6| Step: 11
Training loss: 2.8987757236117426
Validation loss: 2.6919790395720846

Epoch: 6| Step: 12
Training loss: 2.148416415024376
Validation loss: 2.637890605718446

Epoch: 6| Step: 13
Training loss: 2.6212449236280833
Validation loss: 2.625332871781724

Epoch: 33| Step: 0
Training loss: 3.070661141594198
Validation loss: 2.6155352487057577

Epoch: 6| Step: 1
Training loss: 2.5684345654987077
Validation loss: 2.513772815731691

Epoch: 6| Step: 2
Training loss: 2.4234893340735306
Validation loss: 2.573273226063992

Epoch: 6| Step: 3
Training loss: 2.75421314017541
Validation loss: 2.7304369806816338

Epoch: 6| Step: 4
Training loss: 1.6425459016050037
Validation loss: 2.674962659676211

Epoch: 6| Step: 5
Training loss: 2.012113958259862
Validation loss: 2.653291385976404

Epoch: 6| Step: 6
Training loss: 2.13976677167354
Validation loss: 2.7013176257865212

Epoch: 6| Step: 7
Training loss: 1.7359795923220112
Validation loss: 2.7203596326852058

Epoch: 6| Step: 8
Training loss: 3.0413309373602266
Validation loss: 2.6618151689910876

Epoch: 6| Step: 9
Training loss: 3.259732419365402
Validation loss: 2.634799241628461

Epoch: 6| Step: 10
Training loss: 3.0740167922266792
Validation loss: 2.7065610858059226

Epoch: 6| Step: 11
Training loss: 2.2064177884281766
Validation loss: 2.686070010008752

Epoch: 6| Step: 12
Training loss: 2.28271771599084
Validation loss: 2.632923686078589

Epoch: 6| Step: 13
Training loss: 2.86228353023356
Validation loss: 2.660800364782198

Epoch: 34| Step: 0
Training loss: 3.0645436844291214
Validation loss: 2.6658566754738136

Epoch: 6| Step: 1
Training loss: 1.7018067043692873
Validation loss: 2.6087051262718046

Epoch: 6| Step: 2
Training loss: 2.6527906443054734
Validation loss: 2.699828068533705

Epoch: 6| Step: 3
Training loss: 2.030721625051284
Validation loss: 2.6514672697788937

Epoch: 6| Step: 4
Training loss: 2.408969481861191
Validation loss: 2.7239807643416607

Epoch: 6| Step: 5
Training loss: 3.321422723392899
Validation loss: 2.739577381625558

Epoch: 6| Step: 6
Training loss: 2.409893497630523
Validation loss: 2.651053652833074

Epoch: 6| Step: 7
Training loss: 2.8104552571498815
Validation loss: 2.7161168614735387

Epoch: 6| Step: 8
Training loss: 2.6460454260054522
Validation loss: 2.65893182943106

Epoch: 6| Step: 9
Training loss: 2.1674690839241157
Validation loss: 2.6333141056598195

Epoch: 6| Step: 10
Training loss: 2.2553308701794457
Validation loss: 2.6332524325421938

Epoch: 6| Step: 11
Training loss: 3.0518323428399063
Validation loss: 2.678074327996215

Epoch: 6| Step: 12
Training loss: 2.527188940480599
Validation loss: 2.607314508825494

Epoch: 6| Step: 13
Training loss: 1.9989641606608883
Validation loss: 2.6679977035626963

Epoch: 35| Step: 0
Training loss: 2.4918349444191263
Validation loss: 2.630927538348637

Epoch: 6| Step: 1
Training loss: 1.7991080299329278
Validation loss: 2.7083664280752293

Epoch: 6| Step: 2
Training loss: 2.1191244239012037
Validation loss: 2.665727067359522

Epoch: 6| Step: 3
Training loss: 1.614099401327289
Validation loss: 2.632775794130875

Epoch: 6| Step: 4
Training loss: 3.2547868542242
Validation loss: 2.714880326937166

Epoch: 6| Step: 5
Training loss: 2.479997340785416
Validation loss: 2.7337052315184645

Epoch: 6| Step: 6
Training loss: 2.3086845263918416
Validation loss: 2.6663163645455894

Epoch: 6| Step: 7
Training loss: 3.2122225452348014
Validation loss: 2.7654598064620326

Epoch: 6| Step: 8
Training loss: 2.1405849035364253
Validation loss: 2.6662120630278068

Epoch: 6| Step: 9
Training loss: 2.791625055790609
Validation loss: 2.7213221108527437

Epoch: 6| Step: 10
Training loss: 2.7810582298429316
Validation loss: 2.693158218510608

Epoch: 6| Step: 11
Training loss: 2.125881461038964
Validation loss: 2.6670768442200634

Epoch: 6| Step: 12
Training loss: 2.5454353991320984
Validation loss: 2.6247397702518525

Epoch: 6| Step: 13
Training loss: 3.1100309820563825
Validation loss: 2.7448127113611647

Epoch: 36| Step: 0
Training loss: 2.3381863489084185
Validation loss: 2.654010067626248

Epoch: 6| Step: 1
Training loss: 2.6858568713128985
Validation loss: 2.718022245440046

Epoch: 6| Step: 2
Training loss: 3.1320356894709276
Validation loss: 2.596941382534788

Epoch: 6| Step: 3
Training loss: 2.150199472799477
Validation loss: 2.646094562120053

Epoch: 6| Step: 4
Training loss: 2.3132149905552004
Validation loss: 2.626856858617944

Epoch: 6| Step: 5
Training loss: 3.1009713097124374
Validation loss: 2.6607600351718035

Epoch: 6| Step: 6
Training loss: 2.417696590852525
Validation loss: 2.6422445984755494

Epoch: 6| Step: 7
Training loss: 2.3395731009998118
Validation loss: 2.697776545318847

Epoch: 6| Step: 8
Training loss: 2.5007987653696304
Validation loss: 2.6477356827595266

Epoch: 6| Step: 9
Training loss: 2.7389787555607445
Validation loss: 2.6342071250440138

Epoch: 6| Step: 10
Training loss: 2.7542369454593767
Validation loss: 2.6720576530621196

Epoch: 6| Step: 11
Training loss: 2.394479872384174
Validation loss: 2.688444090034058

Epoch: 6| Step: 12
Training loss: 3.029963269404504
Validation loss: 2.628192247278069

Epoch: 6| Step: 13
Training loss: 1.911783286043214
Validation loss: 2.68104599604172

Epoch: 37| Step: 0
Training loss: 2.438902622532779
Validation loss: 2.6621925152571935

Epoch: 6| Step: 1
Training loss: 2.3425770176752425
Validation loss: 2.7121259739096013

Epoch: 6| Step: 2
Training loss: 2.625013805534753
Validation loss: 2.6882309178447548

Epoch: 6| Step: 3
Training loss: 2.7900778581153793
Validation loss: 2.669739105584363

Epoch: 6| Step: 4
Training loss: 2.7209051075027264
Validation loss: 2.723350082573187

Epoch: 6| Step: 5
Training loss: 2.4096246810163273
Validation loss: 2.7084887582246227

Epoch: 6| Step: 6
Training loss: 2.6267792257729137
Validation loss: 2.7389838006275333

Epoch: 6| Step: 7
Training loss: 1.9355530955256057
Validation loss: 2.6959332327239447

Epoch: 6| Step: 8
Training loss: 2.3837370532783946
Validation loss: 2.703181242311772

Epoch: 6| Step: 9
Training loss: 2.8216501376604315
Validation loss: 2.7118815336656428

Epoch: 6| Step: 10
Training loss: 2.2487213952289857
Validation loss: 2.706018828282119

Epoch: 6| Step: 11
Training loss: 2.3397218803039075
Validation loss: 2.7366063486840555

Epoch: 6| Step: 12
Training loss: 2.2342900613499292
Validation loss: 2.674614377613941

Epoch: 6| Step: 13
Training loss: 3.0994107640074766
Validation loss: 2.661090285401781

Epoch: 38| Step: 0
Training loss: 3.0430483532190706
Validation loss: 2.6709176369115886

Epoch: 6| Step: 1
Training loss: 2.0791050027126308
Validation loss: 2.558446686767297

Epoch: 6| Step: 2
Training loss: 2.901099779150808
Validation loss: 2.684936269066525

Epoch: 6| Step: 3
Training loss: 2.290242070226284
Validation loss: 2.6011723558996698

Epoch: 6| Step: 4
Training loss: 2.1324565436708274
Validation loss: 2.622256980232799

Epoch: 6| Step: 5
Training loss: 2.2197246291374113
Validation loss: 2.5723349393650348

Epoch: 6| Step: 6
Training loss: 2.1449470047528547
Validation loss: 2.6344682296118256

Epoch: 6| Step: 7
Training loss: 2.436235344315706
Validation loss: 2.674502116658596

Epoch: 6| Step: 8
Training loss: 2.1568580544092644
Validation loss: 2.683930399516737

Epoch: 6| Step: 9
Training loss: 2.9419043779010527
Validation loss: 2.697588224314679

Epoch: 6| Step: 10
Training loss: 3.345788922298184
Validation loss: 2.7156726038440127

Epoch: 6| Step: 11
Training loss: 2.4435952100975658
Validation loss: 2.6606862440670596

Epoch: 6| Step: 12
Training loss: 2.473426734963545
Validation loss: 2.6602181806931515

Epoch: 6| Step: 13
Training loss: 2.7825122497782497
Validation loss: 2.6660118093684537

Epoch: 39| Step: 0
Training loss: 2.389865330688766
Validation loss: 2.7042687555996747

Epoch: 6| Step: 1
Training loss: 2.221821552819497
Validation loss: 2.6618113025532804

Epoch: 6| Step: 2
Training loss: 2.4193695891351092
Validation loss: 2.575899924885378

Epoch: 6| Step: 3
Training loss: 2.09266771271092
Validation loss: 2.7173114639384255

Epoch: 6| Step: 4
Training loss: 2.96399444357162
Validation loss: 2.7219601821855375

Epoch: 6| Step: 5
Training loss: 1.9430232538509398
Validation loss: 2.658134913637935

Epoch: 6| Step: 6
Training loss: 2.1685933081228383
Validation loss: 2.6400374261052764

Epoch: 6| Step: 7
Training loss: 2.8601963552014427
Validation loss: 2.6553996501453

Epoch: 6| Step: 8
Training loss: 2.606230891681394
Validation loss: 2.673876170991549

Epoch: 6| Step: 9
Training loss: 2.588545668130055
Validation loss: 2.6662849560374804

Epoch: 6| Step: 10
Training loss: 2.5803314939347053
Validation loss: 2.6596135852385476

Epoch: 6| Step: 11
Training loss: 2.1416319546193345
Validation loss: 2.6443968850978328

Epoch: 6| Step: 12
Training loss: 3.413893217520836
Validation loss: 2.629376736353144

Epoch: 6| Step: 13
Training loss: 2.3014490165624313
Validation loss: 2.6590336743073535

Epoch: 40| Step: 0
Training loss: 2.1368709419348075
Validation loss: 2.574950512160512

Epoch: 6| Step: 1
Training loss: 2.1593119676943684
Validation loss: 2.6513313829640075

Epoch: 6| Step: 2
Training loss: 2.2549291236717846
Validation loss: 2.6731152843994175

Epoch: 6| Step: 3
Training loss: 2.3122155298069678
Validation loss: 2.5821291567832114

Epoch: 6| Step: 4
Training loss: 2.4208568771014076
Validation loss: 2.6943222216996396

Epoch: 6| Step: 5
Training loss: 2.5100677902064485
Validation loss: 2.6634995284245093

Epoch: 6| Step: 6
Training loss: 2.0139393226476305
Validation loss: 2.6643035272504165

Epoch: 6| Step: 7
Training loss: 2.8550036425993173
Validation loss: 2.6877815040007804

Epoch: 6| Step: 8
Training loss: 2.575042453897368
Validation loss: 2.6621987991818634

Epoch: 6| Step: 9
Training loss: 2.551614108384234
Validation loss: 2.6823766651697993

Epoch: 6| Step: 10
Training loss: 3.524035214900926
Validation loss: 2.601059476470369

Epoch: 6| Step: 11
Training loss: 2.572861911535969
Validation loss: 2.648782375690501

Epoch: 6| Step: 12
Training loss: 2.7008456283457405
Validation loss: 2.6863199275024234

Epoch: 6| Step: 13
Training loss: 2.9007710319768525
Validation loss: 2.6958879529165114

Epoch: 41| Step: 0
Training loss: 3.0185646395116597
Validation loss: 2.6644910540395674

Epoch: 6| Step: 1
Training loss: 2.2601886640137003
Validation loss: 2.650932494627999

Epoch: 6| Step: 2
Training loss: 2.6050212424321897
Validation loss: 2.5784116489309015

Epoch: 6| Step: 3
Training loss: 2.8741550033065764
Validation loss: 2.5877446585701955

Epoch: 6| Step: 4
Training loss: 2.635412183514025
Validation loss: 2.653600021630725

Epoch: 6| Step: 5
Training loss: 2.3512613604289903
Validation loss: 2.5860982116976645

Epoch: 6| Step: 6
Training loss: 2.4814640481324877
Validation loss: 2.680183179440547

Epoch: 6| Step: 7
Training loss: 2.0351895203314587
Validation loss: 2.5897583945023808

Epoch: 6| Step: 8
Training loss: 2.503122287324919
Validation loss: 2.631500732363788

Epoch: 6| Step: 9
Training loss: 3.154818370687347
Validation loss: 2.711240753303449

Epoch: 6| Step: 10
Training loss: 2.455597621486448
Validation loss: 2.585704597057566

Epoch: 6| Step: 11
Training loss: 2.1227426319706524
Validation loss: 2.5849862399494405

Epoch: 6| Step: 12
Training loss: 2.159922471597763
Validation loss: 2.626732330308339

Epoch: 6| Step: 13
Training loss: 2.1716177808636883
Validation loss: 2.660712469191158

Epoch: 42| Step: 0
Training loss: 2.216688245892954
Validation loss: 2.6278162789655015

Epoch: 6| Step: 1
Training loss: 2.735947249573264
Validation loss: 2.6360437353313912

Epoch: 6| Step: 2
Training loss: 3.102711654439662
Validation loss: 2.6906684709523367

Epoch: 6| Step: 3
Training loss: 2.6308270220901853
Validation loss: 2.751465320333255

Epoch: 6| Step: 4
Training loss: 2.6459394618899217
Validation loss: 2.76419540496905

Epoch: 6| Step: 5
Training loss: 2.4660840669582162
Validation loss: 2.6922419136084854

Epoch: 6| Step: 6
Training loss: 2.3014781265694526
Validation loss: 2.7164103353910507

Epoch: 6| Step: 7
Training loss: 2.5813354847494465
Validation loss: 2.6914738396073576

Epoch: 6| Step: 8
Training loss: 2.997859509108547
Validation loss: 2.6731465234633958

Epoch: 6| Step: 9
Training loss: 2.7601301704338614
Validation loss: 2.591670631413836

Epoch: 6| Step: 10
Training loss: 2.36339201864635
Validation loss: 2.6458885357321997

Epoch: 6| Step: 11
Training loss: 2.1816504605446374
Validation loss: 2.631069402469723

Epoch: 6| Step: 12
Training loss: 2.693647052541322
Validation loss: 2.650066568630151

Epoch: 6| Step: 13
Training loss: 2.3192972858621466
Validation loss: 2.5726749960468043

Epoch: 43| Step: 0
Training loss: 2.4785623748915473
Validation loss: 2.6149703546135883

Epoch: 6| Step: 1
Training loss: 2.441595500477436
Validation loss: 2.6015991956778586

Epoch: 6| Step: 2
Training loss: 3.079926249376618
Validation loss: 2.6403838730370284

Epoch: 6| Step: 3
Training loss: 2.1494131751190806
Validation loss: 2.6251898954218422

Epoch: 6| Step: 4
Training loss: 2.068040399927826
Validation loss: 2.6598398671195347

Epoch: 6| Step: 5
Training loss: 2.8785342179266196
Validation loss: 2.621123751958005

Epoch: 6| Step: 6
Training loss: 2.6439951320839996
Validation loss: 2.645839245606873

Epoch: 6| Step: 7
Training loss: 1.8478287662672048
Validation loss: 2.694966154835534

Epoch: 6| Step: 8
Training loss: 2.39605674254872
Validation loss: 2.6086155439138388

Epoch: 6| Step: 9
Training loss: 2.7623060753880946
Validation loss: 2.6522781446355572

Epoch: 6| Step: 10
Training loss: 2.673090786415043
Validation loss: 2.628541147349365

Epoch: 6| Step: 11
Training loss: 2.819599938659191
Validation loss: 2.663440143160635

Epoch: 6| Step: 12
Training loss: 2.8253877154282163
Validation loss: 2.7682426693940783

Epoch: 6| Step: 13
Training loss: 1.8659294710639809
Validation loss: 2.717762047755995

Epoch: 44| Step: 0
Training loss: 2.4851408923483147
Validation loss: 2.717653528442903

Epoch: 6| Step: 1
Training loss: 2.4878973792031296
Validation loss: 2.7161864329175147

Epoch: 6| Step: 2
Training loss: 2.280948880323103
Validation loss: 2.6953762323335746

Epoch: 6| Step: 3
Training loss: 3.0037530629320597
Validation loss: 2.73665970312

Epoch: 6| Step: 4
Training loss: 1.5864939347712357
Validation loss: 2.7215235363883226

Epoch: 6| Step: 5
Training loss: 2.2659823431823685
Validation loss: 2.725259916059749

Epoch: 6| Step: 6
Training loss: 2.164041897782403
Validation loss: 2.631512797469557

Epoch: 6| Step: 7
Training loss: 2.746078729927584
Validation loss: 2.7031984558121005

Epoch: 6| Step: 8
Training loss: 2.088098442504764
Validation loss: 2.655533802492259

Epoch: 6| Step: 9
Training loss: 2.2034994037195434
Validation loss: 2.61463036564526

Epoch: 6| Step: 10
Training loss: 2.3363216428757676
Validation loss: 2.590542506740181

Epoch: 6| Step: 11
Training loss: 3.141409552970161
Validation loss: 2.632444874861653

Epoch: 6| Step: 12
Training loss: 2.933797247643948
Validation loss: 2.628304369623139

Epoch: 6| Step: 13
Training loss: 3.2460535003333457
Validation loss: 2.599593309849128

Epoch: 45| Step: 0
Training loss: 2.617055041249271
Validation loss: 2.555842520547314

Epoch: 6| Step: 1
Training loss: 2.071686486691315
Validation loss: 2.59864853189142

Epoch: 6| Step: 2
Training loss: 2.2816991494511183
Validation loss: 2.5774041603442184

Epoch: 6| Step: 3
Training loss: 2.006801127853518
Validation loss: 2.639687110127403

Epoch: 6| Step: 4
Training loss: 3.126043526940119
Validation loss: 2.624256482865215

Epoch: 6| Step: 5
Training loss: 3.0191664382832
Validation loss: 2.6355317936253706

Epoch: 6| Step: 6
Training loss: 2.4382225335118215
Validation loss: 2.5861887276767628

Epoch: 6| Step: 7
Training loss: 2.655278645349343
Validation loss: 2.613495229220082

Epoch: 6| Step: 8
Training loss: 2.310368148069536
Validation loss: 2.6526241762874734

Epoch: 6| Step: 9
Training loss: 1.9865990138002385
Validation loss: 2.684980216613477

Epoch: 6| Step: 10
Training loss: 2.013825433834871
Validation loss: 2.653965704559535

Epoch: 6| Step: 11
Training loss: 2.6895888439056024
Validation loss: 2.7207856285582688

Epoch: 6| Step: 12
Training loss: 3.2549178255786324
Validation loss: 2.66059267681125

Epoch: 6| Step: 13
Training loss: 2.9173287503045513
Validation loss: 2.708575316158181

Epoch: 46| Step: 0
Training loss: 2.1855726197936325
Validation loss: 2.676676505281728

Epoch: 6| Step: 1
Training loss: 2.531696233151909
Validation loss: 2.6699881779126815

Epoch: 6| Step: 2
Training loss: 3.3252515253141386
Validation loss: 2.63378114172254

Epoch: 6| Step: 3
Training loss: 2.3643417122917976
Validation loss: 2.596339239436596

Epoch: 6| Step: 4
Training loss: 3.147269588457074
Validation loss: 2.6433306193808837

Epoch: 6| Step: 5
Training loss: 2.0608931553301755
Validation loss: 2.6506899367394543

Epoch: 6| Step: 6
Training loss: 2.764712511813794
Validation loss: 2.6410419202696467

Epoch: 6| Step: 7
Training loss: 2.2941255267253897
Validation loss: 2.680688179986948

Epoch: 6| Step: 8
Training loss: 2.2026411025608947
Validation loss: 2.550440073685432

Epoch: 6| Step: 9
Training loss: 1.8470423124017734
Validation loss: 2.624216129187725

Epoch: 6| Step: 10
Training loss: 2.694463800795551
Validation loss: 2.5777268844089467

Epoch: 6| Step: 11
Training loss: 2.812542046126683
Validation loss: 2.578409383482808

Epoch: 6| Step: 12
Training loss: 2.4004870675486893
Validation loss: 2.6085675907260972

Epoch: 6| Step: 13
Training loss: 1.8877800588436215
Validation loss: 2.6512271588876497

Epoch: 47| Step: 0
Training loss: 2.3523125450372864
Validation loss: 2.646939524495001

Epoch: 6| Step: 1
Training loss: 2.274376115036052
Validation loss: 2.618624377215438

Epoch: 6| Step: 2
Training loss: 2.67251891469373
Validation loss: 2.6554028151114113

Epoch: 6| Step: 3
Training loss: 2.5573322010647703
Validation loss: 2.61410764847898

Epoch: 6| Step: 4
Training loss: 2.1522353018632003
Validation loss: 2.5957336883238153

Epoch: 6| Step: 5
Training loss: 2.5518312498402267
Validation loss: 2.6330390628940683

Epoch: 6| Step: 6
Training loss: 2.891668677718666
Validation loss: 2.576141133581705

Epoch: 6| Step: 7
Training loss: 2.439654156454699
Validation loss: 2.667097404580725

Epoch: 6| Step: 8
Training loss: 2.541433782278864
Validation loss: 2.628905327972961

Epoch: 6| Step: 9
Training loss: 2.2485087008996074
Validation loss: 2.641605608943489

Epoch: 6| Step: 10
Training loss: 1.8230062044951487
Validation loss: 2.6524276383045695

Epoch: 6| Step: 11
Training loss: 2.768729670947254
Validation loss: 2.5860907133722755

Epoch: 6| Step: 12
Training loss: 2.588573207445595
Validation loss: 2.596830583874236

Epoch: 6| Step: 13
Training loss: 2.8867714429286737
Validation loss: 2.6410444479527433

Epoch: 48| Step: 0
Training loss: 2.657990547329848
Validation loss: 2.631612623149831

Epoch: 6| Step: 1
Training loss: 2.388531235479266
Validation loss: 2.572146085386341

Epoch: 6| Step: 2
Training loss: 2.501477949058609
Validation loss: 2.65900882242515

Epoch: 6| Step: 3
Training loss: 2.7214852966158105
Validation loss: 2.5740480805367087

Epoch: 6| Step: 4
Training loss: 3.2791788012915433
Validation loss: 2.626080094000445

Epoch: 6| Step: 5
Training loss: 2.32974371225045
Validation loss: 2.620568895164714

Epoch: 6| Step: 6
Training loss: 2.2372509780491185
Validation loss: 2.5852924475900285

Epoch: 6| Step: 7
Training loss: 2.7805799041335755
Validation loss: 2.6285477082468613

Epoch: 6| Step: 8
Training loss: 2.4671181222680914
Validation loss: 2.6234800843082153

Epoch: 6| Step: 9
Training loss: 2.70595847447147
Validation loss: 2.635590450804303

Epoch: 6| Step: 10
Training loss: 2.314305296735987
Validation loss: 2.6933210746876446

Epoch: 6| Step: 11
Training loss: 1.942307445354693
Validation loss: 2.717475285351904

Epoch: 6| Step: 12
Training loss: 2.3307467042629004
Validation loss: 2.7299711677230443

Epoch: 6| Step: 13
Training loss: 3.1199891161117472
Validation loss: 2.676854429341862

Epoch: 49| Step: 0
Training loss: 2.407419391205568
Validation loss: 2.6581412221038496

Epoch: 6| Step: 1
Training loss: 1.703717959712149
Validation loss: 2.672967564689653

Epoch: 6| Step: 2
Training loss: 3.2846570446455963
Validation loss: 2.6755014092233673

Epoch: 6| Step: 3
Training loss: 2.4585480246035925
Validation loss: 2.571097349792019

Epoch: 6| Step: 4
Training loss: 2.1253770605915365
Validation loss: 2.5868825885360023

Epoch: 6| Step: 5
Training loss: 3.0371241333041743
Validation loss: 2.498812297981426

Epoch: 6| Step: 6
Training loss: 2.6226802748692477
Validation loss: 2.6152974682111303

Epoch: 6| Step: 7
Training loss: 2.27584302604266
Validation loss: 2.6165990519038784

Epoch: 6| Step: 8
Training loss: 2.336634605267571
Validation loss: 2.6212413839120687

Epoch: 6| Step: 9
Training loss: 3.1607154002584075
Validation loss: 2.6644940068769354

Epoch: 6| Step: 10
Training loss: 2.3359647513238486
Validation loss: 2.6574776823004456

Epoch: 6| Step: 11
Training loss: 2.3189639915575717
Validation loss: 2.6440017598358394

Epoch: 6| Step: 12
Training loss: 2.604094135545923
Validation loss: 2.558935927789069

Epoch: 6| Step: 13
Training loss: 2.451844774264599
Validation loss: 2.583655403938824

Epoch: 50| Step: 0
Training loss: 1.9513109251159977
Validation loss: 2.628945246913121

Epoch: 6| Step: 1
Training loss: 2.3816513484233535
Validation loss: 2.668258219365984

Epoch: 6| Step: 2
Training loss: 2.823035196628804
Validation loss: 2.652393001647819

Epoch: 6| Step: 3
Training loss: 2.178083807447644
Validation loss: 2.654787700783527

Epoch: 6| Step: 4
Training loss: 2.3569217078598945
Validation loss: 2.664231415257008

Epoch: 6| Step: 5
Training loss: 2.32752665568985
Validation loss: 2.793736663035533

Epoch: 6| Step: 6
Training loss: 2.472193380847196
Validation loss: 2.767214689977385

Epoch: 6| Step: 7
Training loss: 3.1332231285789263
Validation loss: 2.812700617664053

Epoch: 6| Step: 8
Training loss: 2.945002612904554
Validation loss: 2.6817669302731133

Epoch: 6| Step: 9
Training loss: 3.146099727711139
Validation loss: 2.6217359655266574

Epoch: 6| Step: 10
Training loss: 2.154605182848477
Validation loss: 2.598078589656149

Epoch: 6| Step: 11
Training loss: 2.5759520650218404
Validation loss: 2.7372748847034907

Epoch: 6| Step: 12
Training loss: 2.749517051598118
Validation loss: 2.630504045135418

Epoch: 6| Step: 13
Training loss: 1.7728318175808793
Validation loss: 2.6307059896794116

Epoch: 51| Step: 0
Training loss: 2.3406190431567433
Validation loss: 2.5570461028394478

Epoch: 6| Step: 1
Training loss: 3.2623344525542235
Validation loss: 2.5710541989392715

Epoch: 6| Step: 2
Training loss: 2.912636415618572
Validation loss: 2.6178775921369044

Epoch: 6| Step: 3
Training loss: 2.306419006605956
Validation loss: 2.6331132967882223

Epoch: 6| Step: 4
Training loss: 2.8648256141623256
Validation loss: 2.590932641132734

Epoch: 6| Step: 5
Training loss: 2.3245041103051816
Validation loss: 2.6135768599641107

Epoch: 6| Step: 6
Training loss: 2.409004715347584
Validation loss: 2.6621067180513003

Epoch: 6| Step: 7
Training loss: 2.21576844949497
Validation loss: 2.688956967281039

Epoch: 6| Step: 8
Training loss: 2.1379228229492306
Validation loss: 2.5985304659271717

Epoch: 6| Step: 9
Training loss: 2.8136473964318545
Validation loss: 2.5617283845646437

Epoch: 6| Step: 10
Training loss: 1.9821654506264674
Validation loss: 2.6264093490934215

Epoch: 6| Step: 11
Training loss: 2.1042454267309147
Validation loss: 2.6507995185106368

Epoch: 6| Step: 12
Training loss: 2.6537382928964677
Validation loss: 2.5914130042786123

Epoch: 6| Step: 13
Training loss: 2.7675269532032645
Validation loss: 2.611438019446139

Epoch: 52| Step: 0
Training loss: 2.4003598340808923
Validation loss: 2.6339358113384113

Epoch: 6| Step: 1
Training loss: 2.6291399507530504
Validation loss: 2.572319059171771

Epoch: 6| Step: 2
Training loss: 1.6275730303011362
Validation loss: 2.6115640758585577

Epoch: 6| Step: 3
Training loss: 3.236286575151958
Validation loss: 2.6336472845242627

Epoch: 6| Step: 4
Training loss: 1.8786530829715333
Validation loss: 2.6521669009563023

Epoch: 6| Step: 5
Training loss: 1.7269231497271316
Validation loss: 2.63038334531771

Epoch: 6| Step: 6
Training loss: 2.5231335341729957
Validation loss: 2.6571260092338376

Epoch: 6| Step: 7
Training loss: 1.6818014637305951
Validation loss: 2.620361013461919

Epoch: 6| Step: 8
Training loss: 3.47293443284337
Validation loss: 2.644729696967359

Epoch: 6| Step: 9
Training loss: 2.450952819519532
Validation loss: 2.727187499487119

Epoch: 6| Step: 10
Training loss: 2.5220397290360883
Validation loss: 2.673110185626268

Epoch: 6| Step: 11
Training loss: 2.870707749349929
Validation loss: 2.556466139630524

Epoch: 6| Step: 12
Training loss: 2.3511333897830498
Validation loss: 2.611429741764671

Epoch: 6| Step: 13
Training loss: 2.3793223350714636
Validation loss: 2.586463513614313

Epoch: 53| Step: 0
Training loss: 2.1901780220729963
Validation loss: 2.633941800605366

Epoch: 6| Step: 1
Training loss: 3.0962903930838306
Validation loss: 2.615628012257022

Epoch: 6| Step: 2
Training loss: 3.3632499170560664
Validation loss: 2.6338382613099296

Epoch: 6| Step: 3
Training loss: 2.1123274873798406
Validation loss: 2.607145967780271

Epoch: 6| Step: 4
Training loss: 2.30318357892637
Validation loss: 2.604497191752473

Epoch: 6| Step: 5
Training loss: 2.3878658553613694
Validation loss: 2.6569028912162125

Epoch: 6| Step: 6
Training loss: 2.629020064952454
Validation loss: 2.6595647287731543

Epoch: 6| Step: 7
Training loss: 2.067573203436484
Validation loss: 2.6352723173834574

Epoch: 6| Step: 8
Training loss: 2.0804343334965445
Validation loss: 2.7018964618033725

Epoch: 6| Step: 9
Training loss: 2.30848417328649
Validation loss: 2.574070155824057

Epoch: 6| Step: 10
Training loss: 2.412358049555026
Validation loss: 2.6438411411360168

Epoch: 6| Step: 11
Training loss: 2.123037890965352
Validation loss: 2.6969618169278475

Epoch: 6| Step: 12
Training loss: 1.7364410603958425
Validation loss: 2.7047315097741795

Epoch: 6| Step: 13
Training loss: 3.4098547663482517
Validation loss: 2.699558853091016

Epoch: 54| Step: 0
Training loss: 1.8830870115624594
Validation loss: 2.7132601503473888

Epoch: 6| Step: 1
Training loss: 1.6662264798930404
Validation loss: 2.5947467773017605

Epoch: 6| Step: 2
Training loss: 2.7294688652011208
Validation loss: 2.5990935285999535

Epoch: 6| Step: 3
Training loss: 2.7480807109124297
Validation loss: 2.6286430510542806

Epoch: 6| Step: 4
Training loss: 2.1457780503741026
Validation loss: 2.6852805783572533

Epoch: 6| Step: 5
Training loss: 2.2762551167580893
Validation loss: 2.5932477288553244

Epoch: 6| Step: 6
Training loss: 3.2647578352052666
Validation loss: 2.6301727418411387

Epoch: 6| Step: 7
Training loss: 2.457534035090943
Validation loss: 2.5873525230409027

Epoch: 6| Step: 8
Training loss: 2.4220300440228173
Validation loss: 2.5797177567720664

Epoch: 6| Step: 9
Training loss: 2.8346013055564625
Validation loss: 2.5839884347804465

Epoch: 6| Step: 10
Training loss: 2.5494637467746357
Validation loss: 2.592709849811712

Epoch: 6| Step: 11
Training loss: 2.494137757254127
Validation loss: 2.6217653690373997

Epoch: 6| Step: 12
Training loss: 2.1358860771502326
Validation loss: 2.6174871927875287

Epoch: 6| Step: 13
Training loss: 2.3041290123767526
Validation loss: 2.6416325048490084

Epoch: 55| Step: 0
Training loss: 2.0652437166941056
Validation loss: 2.6139255978065883

Epoch: 6| Step: 1
Training loss: 2.2721954833273315
Validation loss: 2.572376740261128

Epoch: 6| Step: 2
Training loss: 2.062601953934286
Validation loss: 2.57867242415054

Epoch: 6| Step: 3
Training loss: 2.5151209355849424
Validation loss: 2.582252389091829

Epoch: 6| Step: 4
Training loss: 1.768706544268138
Validation loss: 2.596676795272106

Epoch: 6| Step: 5
Training loss: 2.063366678961683
Validation loss: 2.6276344975566204

Epoch: 6| Step: 6
Training loss: 2.136389558808239
Validation loss: 2.694232256116816

Epoch: 6| Step: 7
Training loss: 3.226459640082614
Validation loss: 2.618342768067137

Epoch: 6| Step: 8
Training loss: 3.4915473231736294
Validation loss: 2.64891074274485

Epoch: 6| Step: 9
Training loss: 2.73825704479539
Validation loss: 2.640969835145937

Epoch: 6| Step: 10
Training loss: 2.48754555741961
Validation loss: 2.6793333659264205

Epoch: 6| Step: 11
Training loss: 2.8758265095086957
Validation loss: 2.621210011359278

Epoch: 6| Step: 12
Training loss: 2.2832634806099814
Validation loss: 2.5837284883152067

Epoch: 6| Step: 13
Training loss: 1.790295371827465
Validation loss: 2.6310811674994166

Epoch: 56| Step: 0
Training loss: 2.034866868896661
Validation loss: 2.601689852021265

Epoch: 6| Step: 1
Training loss: 2.2651264562947895
Validation loss: 2.581441437747519

Epoch: 6| Step: 2
Training loss: 2.1256654482825987
Validation loss: 2.5770751819363467

Epoch: 6| Step: 3
Training loss: 2.094693099601599
Validation loss: 2.623809540727126

Epoch: 6| Step: 4
Training loss: 2.5616001316911614
Validation loss: 2.6757431584452256

Epoch: 6| Step: 5
Training loss: 3.0001969272829454
Validation loss: 2.72188417423657

Epoch: 6| Step: 6
Training loss: 2.941318708234149
Validation loss: 2.6036205990789365

Epoch: 6| Step: 7
Training loss: 1.8436474529132583
Validation loss: 2.6579237059289538

Epoch: 6| Step: 8
Training loss: 2.086179797783892
Validation loss: 2.6327051882282184

Epoch: 6| Step: 9
Training loss: 2.4169657511180493
Validation loss: 2.6078724142101777

Epoch: 6| Step: 10
Training loss: 2.9324901958539087
Validation loss: 2.660478031901521

Epoch: 6| Step: 11
Training loss: 2.383803864917171
Validation loss: 2.615069755708181

Epoch: 6| Step: 12
Training loss: 2.2197327922124415
Validation loss: 2.6469444635097017

Epoch: 6| Step: 13
Training loss: 2.3490347726455956
Validation loss: 2.6145501204327766

Epoch: 57| Step: 0
Training loss: 3.0028425101675147
Validation loss: 2.592116427467594

Epoch: 6| Step: 1
Training loss: 2.5302651455624456
Validation loss: 2.6209520281753695

Epoch: 6| Step: 2
Training loss: 2.033676341574606
Validation loss: 2.6247491413927357

Epoch: 6| Step: 3
Training loss: 2.518993231527663
Validation loss: 2.62891702711174

Epoch: 6| Step: 4
Training loss: 2.107126803948904
Validation loss: 2.540793508624385

Epoch: 6| Step: 5
Training loss: 1.5354121725291816
Validation loss: 2.6069008676956846

Epoch: 6| Step: 6
Training loss: 2.8382985608816993
Validation loss: 2.668833222532174

Epoch: 6| Step: 7
Training loss: 2.40605915848578
Validation loss: 2.645414940100514

Epoch: 6| Step: 8
Training loss: 2.560600600271848
Validation loss: 2.6188676821320716

Epoch: 6| Step: 9
Training loss: 2.52913266388997
Validation loss: 2.6315471049523875

Epoch: 6| Step: 10
Training loss: 2.7088534124796664
Validation loss: 2.670085404324346

Epoch: 6| Step: 11
Training loss: 3.569798271826867
Validation loss: 2.6167362868002937

Epoch: 6| Step: 12
Training loss: 2.4497264475791476
Validation loss: 2.6622374278276273

Epoch: 6| Step: 13
Training loss: 1.6835784557382458
Validation loss: 2.6389586177336

Epoch: 58| Step: 0
Training loss: 2.2364464607746863
Validation loss: 2.695596121640634

Epoch: 6| Step: 1
Training loss: 3.0377721719504835
Validation loss: 2.7074186736831742

Epoch: 6| Step: 2
Training loss: 3.053128129846224
Validation loss: 2.6991379721626654

Epoch: 6| Step: 3
Training loss: 2.6864708105248423
Validation loss: 2.6461647506962893

Epoch: 6| Step: 4
Training loss: 2.0528785081489773
Validation loss: 2.66018400397179

Epoch: 6| Step: 5
Training loss: 1.9346011225304038
Validation loss: 2.6206195855321672

Epoch: 6| Step: 6
Training loss: 2.3562526632035885
Validation loss: 2.613528161579714

Epoch: 6| Step: 7
Training loss: 3.0473917205075183
Validation loss: 2.550022769963447

Epoch: 6| Step: 8
Training loss: 2.11799003902755
Validation loss: 2.5573812392656667

Epoch: 6| Step: 9
Training loss: 2.6011137704221414
Validation loss: 2.599504743381562

Epoch: 6| Step: 10
Training loss: 1.9047119314302592
Validation loss: 2.622078996072097

Epoch: 6| Step: 11
Training loss: 2.2381086832201142
Validation loss: 2.58822730219554

Epoch: 6| Step: 12
Training loss: 3.0107413956068534
Validation loss: 2.633832249177142

Epoch: 6| Step: 13
Training loss: 2.2814383233081457
Validation loss: 2.5849326372008554

Epoch: 59| Step: 0
Training loss: 2.8143799326881185
Validation loss: 2.528224502698952

Epoch: 6| Step: 1
Training loss: 1.6148997171168227
Validation loss: 2.6297953265654046

Epoch: 6| Step: 2
Training loss: 2.295456221036531
Validation loss: 2.6010013009390387

Epoch: 6| Step: 3
Training loss: 2.442990306421224
Validation loss: 2.649596036854662

Epoch: 6| Step: 4
Training loss: 2.3953501559667516
Validation loss: 2.593940865721308

Epoch: 6| Step: 5
Training loss: 2.6870409551295373
Validation loss: 2.6382289752896626

Epoch: 6| Step: 6
Training loss: 2.46663903873883
Validation loss: 2.5912357691711274

Epoch: 6| Step: 7
Training loss: 2.44476936329075
Validation loss: 2.605854270890794

Epoch: 6| Step: 8
Training loss: 2.6359679558966875
Validation loss: 2.6861841247963896

Epoch: 6| Step: 9
Training loss: 2.5836687075408733
Validation loss: 2.6206598126371867

Epoch: 6| Step: 10
Training loss: 2.683372344055297
Validation loss: 2.597576780705032

Epoch: 6| Step: 11
Training loss: 1.8473372395718612
Validation loss: 2.646137675605998

Epoch: 6| Step: 12
Training loss: 2.238785345755894
Validation loss: 2.617183279157433

Epoch: 6| Step: 13
Training loss: 2.386755510662075
Validation loss: 2.6623806683419273

Epoch: 60| Step: 0
Training loss: 2.537529773255615
Validation loss: 2.660814828335429

Epoch: 6| Step: 1
Training loss: 2.0507670665432145
Validation loss: 2.5836273969411248

Epoch: 6| Step: 2
Training loss: 2.0497259422032177
Validation loss: 2.7072401677148408

Epoch: 6| Step: 3
Training loss: 2.8310594035619565
Validation loss: 2.7317469874317957

Epoch: 6| Step: 4
Training loss: 2.492364954834006
Validation loss: 2.668917359309133

Epoch: 6| Step: 5
Training loss: 2.568620582903122
Validation loss: 2.769019706914026

Epoch: 6| Step: 6
Training loss: 2.5640614102190993
Validation loss: 2.6602702515495107

Epoch: 6| Step: 7
Training loss: 2.8295196972134593
Validation loss: 2.635272860215907

Epoch: 6| Step: 8
Training loss: 2.1711001763621045
Validation loss: 2.6514131227077087

Epoch: 6| Step: 9
Training loss: 2.339386603988824
Validation loss: 2.652870691435391

Epoch: 6| Step: 10
Training loss: 2.2005347859017412
Validation loss: 2.5980693899710556

Epoch: 6| Step: 11
Training loss: 2.2218114658720194
Validation loss: 2.5230099184887327

Epoch: 6| Step: 12
Training loss: 2.494374048456992
Validation loss: 2.6320333412700316

Epoch: 6| Step: 13
Training loss: 3.2153696624245303
Validation loss: 2.6486144330273325

Epoch: 61| Step: 0
Training loss: 1.8985704917007393
Validation loss: 2.5794113726123813

Epoch: 6| Step: 1
Training loss: 2.970012035152827
Validation loss: 2.6370747643766164

Epoch: 6| Step: 2
Training loss: 2.5552104449713764
Validation loss: 2.6518751057170697

Epoch: 6| Step: 3
Training loss: 2.3454919064068456
Validation loss: 2.5750735324866385

Epoch: 6| Step: 4
Training loss: 2.534568212931145
Validation loss: 2.618271848837721

Epoch: 6| Step: 5
Training loss: 2.650048230290115
Validation loss: 2.629509292218602

Epoch: 6| Step: 6
Training loss: 2.5545982788557984
Validation loss: 2.57534182048225

Epoch: 6| Step: 7
Training loss: 2.5870300935131065
Validation loss: 2.617059808908877

Epoch: 6| Step: 8
Training loss: 2.8172145746996096
Validation loss: 2.646936371927607

Epoch: 6| Step: 9
Training loss: 2.226183300186454
Validation loss: 2.677618801925564

Epoch: 6| Step: 10
Training loss: 2.2303314968442316
Validation loss: 2.7156138839464905

Epoch: 6| Step: 11
Training loss: 2.720011451360495
Validation loss: 2.7078949549044693

Epoch: 6| Step: 12
Training loss: 2.4367414419004927
Validation loss: 2.679191980988872

Epoch: 6| Step: 13
Training loss: 2.1570355739639973
Validation loss: 2.715193808694396

Epoch: 62| Step: 0
Training loss: 2.2549012102026635
Validation loss: 2.63959227161254

Epoch: 6| Step: 1
Training loss: 1.8170666878344668
Validation loss: 2.6384060959010878

Epoch: 6| Step: 2
Training loss: 2.0830634387351052
Validation loss: 2.722236969533752

Epoch: 6| Step: 3
Training loss: 2.428253339323915
Validation loss: 2.7142730039762655

Epoch: 6| Step: 4
Training loss: 2.9622036685093867
Validation loss: 2.6379353746967835

Epoch: 6| Step: 5
Training loss: 2.7740505346908435
Validation loss: 2.7197738415063224

Epoch: 6| Step: 6
Training loss: 1.934850788918468
Validation loss: 2.707687768046271

Epoch: 6| Step: 7
Training loss: 2.1549572593893647
Validation loss: 2.665562979963153

Epoch: 6| Step: 8
Training loss: 2.5111593095079154
Validation loss: 2.7338677362672237

Epoch: 6| Step: 9
Training loss: 2.2987416266516503
Validation loss: 2.5816381388943905

Epoch: 6| Step: 10
Training loss: 2.9427038322121732
Validation loss: 2.6342872466242078

Epoch: 6| Step: 11
Training loss: 2.5065095077446946
Validation loss: 2.5599878449201108

Epoch: 6| Step: 12
Training loss: 2.213631972920441
Validation loss: 2.593487109607526

Epoch: 6| Step: 13
Training loss: 2.558593563633104
Validation loss: 2.5947312486726126

Epoch: 63| Step: 0
Training loss: 1.9538817503688493
Validation loss: 2.5401071600198595

Epoch: 6| Step: 1
Training loss: 2.9188156022535057
Validation loss: 2.544813745699298

Epoch: 6| Step: 2
Training loss: 2.5813449980686336
Validation loss: 2.587853757967546

Epoch: 6| Step: 3
Training loss: 3.1268521732806307
Validation loss: 2.61092692992656

Epoch: 6| Step: 4
Training loss: 3.223182810911623
Validation loss: 2.5968930148568274

Epoch: 6| Step: 5
Training loss: 2.6800169450309594
Validation loss: 2.6438319879659216

Epoch: 6| Step: 6
Training loss: 1.6092801112376836
Validation loss: 2.603275594213469

Epoch: 6| Step: 7
Training loss: 2.453361742781195
Validation loss: 2.644264797534156

Epoch: 6| Step: 8
Training loss: 2.086426409742036
Validation loss: 2.633331413710977

Epoch: 6| Step: 9
Training loss: 2.277934342976251
Validation loss: 2.5925935672071936

Epoch: 6| Step: 10
Training loss: 2.032695549335675
Validation loss: 2.6248770336837977

Epoch: 6| Step: 11
Training loss: 1.8412551811440596
Validation loss: 2.671607139798401

Epoch: 6| Step: 12
Training loss: 2.0441837235537537
Validation loss: 2.6631515974178726

Epoch: 6| Step: 13
Training loss: 2.8331093045095925
Validation loss: 2.613798051414004

Epoch: 64| Step: 0
Training loss: 2.473331594218065
Validation loss: 2.5523335366637805

Epoch: 6| Step: 1
Training loss: 2.637714655670004
Validation loss: 2.6716510017000816

Epoch: 6| Step: 2
Training loss: 2.15944302530419
Validation loss: 2.6583152521249955

Epoch: 6| Step: 3
Training loss: 2.102971848782394
Validation loss: 2.6551343033293873

Epoch: 6| Step: 4
Training loss: 2.0071415949178975
Validation loss: 2.6141129991419496

Epoch: 6| Step: 5
Training loss: 2.0039032755749733
Validation loss: 2.592876930829368

Epoch: 6| Step: 6
Training loss: 2.4117673561924473
Validation loss: 2.58719489960208

Epoch: 6| Step: 7
Training loss: 2.693664754771126
Validation loss: 2.6178059165203615

Epoch: 6| Step: 8
Training loss: 2.1382437499566125
Validation loss: 2.6494660007416395

Epoch: 6| Step: 9
Training loss: 2.6158772847093665
Validation loss: 2.6144925946502657

Epoch: 6| Step: 10
Training loss: 2.582370845375318
Validation loss: 2.685520892393249

Epoch: 6| Step: 11
Training loss: 2.9540758973575194
Validation loss: 2.6215326478981664

Epoch: 6| Step: 12
Training loss: 2.050190577138596
Validation loss: 2.6021333513016076

Epoch: 6| Step: 13
Training loss: 2.3454108901863937
Validation loss: 2.5846593642706837

Epoch: 65| Step: 0
Training loss: 2.777183045192359
Validation loss: 2.629502794167426

Epoch: 6| Step: 1
Training loss: 2.826856465655268
Validation loss: 2.642572636491706

Epoch: 6| Step: 2
Training loss: 2.526372000472561
Validation loss: 2.6607519856040844

Epoch: 6| Step: 3
Training loss: 2.534649673422341
Validation loss: 2.6360165864348337

Epoch: 6| Step: 4
Training loss: 2.232704445084284
Validation loss: 2.5771930050366145

Epoch: 6| Step: 5
Training loss: 2.3083225355572865
Validation loss: 2.554371525533659

Epoch: 6| Step: 6
Training loss: 1.9502151786239335
Validation loss: 2.5766143226077207

Epoch: 6| Step: 7
Training loss: 2.3569186731549427
Validation loss: 2.617888346345889

Epoch: 6| Step: 8
Training loss: 2.398349921898361
Validation loss: 2.6442967155431623

Epoch: 6| Step: 9
Training loss: 1.874064339195877
Validation loss: 2.58376681372332

Epoch: 6| Step: 10
Training loss: 2.8282272573288556
Validation loss: 2.5644718894843366

Epoch: 6| Step: 11
Training loss: 2.9436036674915207
Validation loss: 2.591186436218403

Epoch: 6| Step: 12
Training loss: 2.06701489662889
Validation loss: 2.641574395510719

Epoch: 6| Step: 13
Training loss: 2.141458390890888
Validation loss: 2.576482291869158

Epoch: 66| Step: 0
Training loss: 2.3593760105156156
Validation loss: 2.6049679146594946

Epoch: 6| Step: 1
Training loss: 2.3557436452102003
Validation loss: 2.653086360295065

Epoch: 6| Step: 2
Training loss: 1.6981759916700896
Validation loss: 2.631272995003371

Epoch: 6| Step: 3
Training loss: 2.666722555369586
Validation loss: 2.679443763495366

Epoch: 6| Step: 4
Training loss: 3.2172204985369053
Validation loss: 2.6861971868876755

Epoch: 6| Step: 5
Training loss: 2.1085103841430475
Validation loss: 2.683848939447971

Epoch: 6| Step: 6
Training loss: 2.5185942570927042
Validation loss: 2.6765485494101253

Epoch: 6| Step: 7
Training loss: 1.9599011482885105
Validation loss: 2.658829300652381

Epoch: 6| Step: 8
Training loss: 2.343866981130101
Validation loss: 2.6290812403427637

Epoch: 6| Step: 9
Training loss: 2.120791587593607
Validation loss: 2.5811932425920823

Epoch: 6| Step: 10
Training loss: 2.650737472698857
Validation loss: 2.616765776860995

Epoch: 6| Step: 11
Training loss: 2.630155496098051
Validation loss: 2.5910759435585993

Epoch: 6| Step: 12
Training loss: 2.2844533507638993
Validation loss: 2.6129806033900107

Epoch: 6| Step: 13
Training loss: 2.4083714236862868
Validation loss: 2.6710526686264457

Epoch: 67| Step: 0
Training loss: 2.547921930922661
Validation loss: 2.686270365968437

Epoch: 6| Step: 1
Training loss: 1.9962509302413005
Validation loss: 2.612365349276199

Epoch: 6| Step: 2
Training loss: 1.967828807572413
Validation loss: 2.596404987986942

Epoch: 6| Step: 3
Training loss: 2.2365044536789287
Validation loss: 2.6179616817392986

Epoch: 6| Step: 4
Training loss: 1.9976875526502926
Validation loss: 2.6047723193013157

Epoch: 6| Step: 5
Training loss: 2.8743608842417276
Validation loss: 2.642883613937445

Epoch: 6| Step: 6
Training loss: 2.542160069669929
Validation loss: 2.599736688956124

Epoch: 6| Step: 7
Training loss: 2.7182504479990204
Validation loss: 2.5996505386299646

Epoch: 6| Step: 8
Training loss: 1.9757977842074272
Validation loss: 2.550109042535198

Epoch: 6| Step: 9
Training loss: 2.6691480853382497
Validation loss: 2.659052892139989

Epoch: 6| Step: 10
Training loss: 2.5781385941580517
Validation loss: 2.647602501056583

Epoch: 6| Step: 11
Training loss: 2.980386355399852
Validation loss: 2.6019216753484007

Epoch: 6| Step: 12
Training loss: 2.651172587241598
Validation loss: 2.6059973779549512

Epoch: 6| Step: 13
Training loss: 2.589318407726125
Validation loss: 2.6326381274698827

Epoch: 68| Step: 0
Training loss: 2.485419383744329
Validation loss: 2.6425342316517018

Epoch: 6| Step: 1
Training loss: 3.018840755259415
Validation loss: 2.6911891929087046

Epoch: 6| Step: 2
Training loss: 1.6697259799207955
Validation loss: 2.6894472593540413

Epoch: 6| Step: 3
Training loss: 2.2302283376277336
Validation loss: 2.6977383813655855

Epoch: 6| Step: 4
Training loss: 2.6351296390441763
Validation loss: 2.6936731337860023

Epoch: 6| Step: 5
Training loss: 2.452227385726322
Validation loss: 2.707664808268999

Epoch: 6| Step: 6
Training loss: 1.9706128707497945
Validation loss: 2.7269511123516468

Epoch: 6| Step: 7
Training loss: 2.274889819652556
Validation loss: 2.6453646497548746

Epoch: 6| Step: 8
Training loss: 2.220774412059409
Validation loss: 2.5685325341783365

Epoch: 6| Step: 9
Training loss: 2.632652209918019
Validation loss: 2.7019984961147157

Epoch: 6| Step: 10
Training loss: 2.180908954705212
Validation loss: 2.6297451757164416

Epoch: 6| Step: 11
Training loss: 2.737343185322841
Validation loss: 2.723304426918405

Epoch: 6| Step: 12
Training loss: 2.006504449127915
Validation loss: 2.6435476527773965

Epoch: 6| Step: 13
Training loss: 2.444177723792482
Validation loss: 2.6120187154852017

Epoch: 69| Step: 0
Training loss: 2.5917341372752474
Validation loss: 2.580028008843712

Epoch: 6| Step: 1
Training loss: 1.8682456110909496
Validation loss: 2.5726599983553315

Epoch: 6| Step: 2
Training loss: 2.3073676608439215
Validation loss: 2.6288113173055447

Epoch: 6| Step: 3
Training loss: 3.1658788671496647
Validation loss: 2.5906878937317734

Epoch: 6| Step: 4
Training loss: 2.232906258965684
Validation loss: 2.666271766589249

Epoch: 6| Step: 5
Training loss: 2.1680087798950787
Validation loss: 2.6450348397588272

Epoch: 6| Step: 6
Training loss: 1.673032199707081
Validation loss: 2.6150215713797724

Epoch: 6| Step: 7
Training loss: 2.461269973821077
Validation loss: 2.590330251776407

Epoch: 6| Step: 8
Training loss: 2.6427731776799446
Validation loss: 2.5720669093478716

Epoch: 6| Step: 9
Training loss: 2.761118088382303
Validation loss: 2.5619107165843933

Epoch: 6| Step: 10
Training loss: 2.02685105762815
Validation loss: 2.637820151786852

Epoch: 6| Step: 11
Training loss: 1.9994181144146388
Validation loss: 2.6002125793753272

Epoch: 6| Step: 12
Training loss: 2.9280982017308594
Validation loss: 2.6762446760955836

Epoch: 6| Step: 13
Training loss: 2.36980542748337
Validation loss: 2.607232270508514

Epoch: 70| Step: 0
Training loss: 2.4647968366363044
Validation loss: 2.6614278852558755

Epoch: 6| Step: 1
Training loss: 3.3036983804354176
Validation loss: 2.63165230473116

Epoch: 6| Step: 2
Training loss: 2.615962319630589
Validation loss: 2.6118458149351897

Epoch: 6| Step: 3
Training loss: 1.6165918552484695
Validation loss: 2.6484618209277295

Epoch: 6| Step: 4
Training loss: 2.3450299646215917
Validation loss: 2.620521509474449

Epoch: 6| Step: 5
Training loss: 2.497305371525946
Validation loss: 2.709337596055805

Epoch: 6| Step: 6
Training loss: 2.4276758433963854
Validation loss: 2.57033493202261

Epoch: 6| Step: 7
Training loss: 2.41637588812435
Validation loss: 2.606624409885127

Epoch: 6| Step: 8
Training loss: 1.9907354111645286
Validation loss: 2.6456859777872928

Epoch: 6| Step: 9
Training loss: 2.001648104621566
Validation loss: 2.6005655541685377

Epoch: 6| Step: 10
Training loss: 2.640222462326561
Validation loss: 2.5715724790321324

Epoch: 6| Step: 11
Training loss: 2.4670589788010364
Validation loss: 2.6264432390994212

Epoch: 6| Step: 12
Training loss: 2.2693543356981847
Validation loss: 2.638601411809953

Epoch: 6| Step: 13
Training loss: 2.486752506066541
Validation loss: 2.588152364294306

Epoch: 71| Step: 0
Training loss: 2.19811572097065
Validation loss: 2.6457235709023217

Epoch: 6| Step: 1
Training loss: 2.230836854612953
Validation loss: 2.6083220986397526

Epoch: 6| Step: 2
Training loss: 3.146252046386635
Validation loss: 2.662573986786566

Epoch: 6| Step: 3
Training loss: 2.6071524834501814
Validation loss: 2.6082886282732822

Epoch: 6| Step: 4
Training loss: 1.989874540524346
Validation loss: 2.6948558623270493

Epoch: 6| Step: 5
Training loss: 2.6959977757702265
Validation loss: 2.603034900145546

Epoch: 6| Step: 6
Training loss: 2.3666007444665684
Validation loss: 2.5265680662592005

Epoch: 6| Step: 7
Training loss: 1.7465231280036377
Validation loss: 2.5498628467251674

Epoch: 6| Step: 8
Training loss: 2.3088549161244756
Validation loss: 2.575012995245774

Epoch: 6| Step: 9
Training loss: 3.024789433992905
Validation loss: 2.592504209823403

Epoch: 6| Step: 10
Training loss: 2.1307159291629127
Validation loss: 2.5950960856431693

Epoch: 6| Step: 11
Training loss: 2.489815183774295
Validation loss: 2.5702337544755274

Epoch: 6| Step: 12
Training loss: 2.539599458696984
Validation loss: 2.660587927419853

Epoch: 6| Step: 13
Training loss: 2.4152539717169055
Validation loss: 2.621080818277021

Epoch: 72| Step: 0
Training loss: 2.5110287586237923
Validation loss: 2.6064797974781744

Epoch: 6| Step: 1
Training loss: 2.565397531738426
Validation loss: 2.6920069230459673

Epoch: 6| Step: 2
Training loss: 2.6091959086651433
Validation loss: 2.569214189081448

Epoch: 6| Step: 3
Training loss: 2.2508122779325563
Validation loss: 2.7085631321960006

Epoch: 6| Step: 4
Training loss: 2.134700177333326
Validation loss: 2.6758191034094474

Epoch: 6| Step: 5
Training loss: 1.5939559803416297
Validation loss: 2.658394004364611

Epoch: 6| Step: 6
Training loss: 2.6608538056145656
Validation loss: 2.650112016577589

Epoch: 6| Step: 7
Training loss: 1.8005867478591977
Validation loss: 2.708746912751597

Epoch: 6| Step: 8
Training loss: 3.0425772849730834
Validation loss: 2.6489147105183406

Epoch: 6| Step: 9
Training loss: 2.1279747281115546
Validation loss: 2.638260152994303

Epoch: 6| Step: 10
Training loss: 2.3436885571373267
Validation loss: 2.5933512798691876

Epoch: 6| Step: 11
Training loss: 2.1985838059881013
Validation loss: 2.6874176278908735

Epoch: 6| Step: 12
Training loss: 2.5355425571186854
Validation loss: 2.604918353631121

Epoch: 6| Step: 13
Training loss: 2.6681627507419825
Validation loss: 2.664548469734925

Epoch: 73| Step: 0
Training loss: 1.8883385191484552
Validation loss: 2.5854632662114447

Epoch: 6| Step: 1
Training loss: 2.9690577297334984
Validation loss: 2.6496654503252017

Epoch: 6| Step: 2
Training loss: 2.5699373568607613
Validation loss: 2.609347390887301

Epoch: 6| Step: 3
Training loss: 1.9517005914312624
Validation loss: 2.548021460244648

Epoch: 6| Step: 4
Training loss: 2.1029538225227595
Validation loss: 2.6030247638846795

Epoch: 6| Step: 5
Training loss: 2.583142478619763
Validation loss: 2.619518930687034

Epoch: 6| Step: 6
Training loss: 2.3831818841507535
Validation loss: 2.5490906328091816

Epoch: 6| Step: 7
Training loss: 2.5782426287086007
Validation loss: 2.530226316004664

Epoch: 6| Step: 8
Training loss: 2.24214783743094
Validation loss: 2.586216983501451

Epoch: 6| Step: 9
Training loss: 2.8545235923477703
Validation loss: 2.6167838473312943

Epoch: 6| Step: 10
Training loss: 2.2591414714755844
Validation loss: 2.644383917065977

Epoch: 6| Step: 11
Training loss: 2.378898432676503
Validation loss: 2.62679166049438

Epoch: 6| Step: 12
Training loss: 2.083363062328575
Validation loss: 2.57169373724438

Epoch: 6| Step: 13
Training loss: 2.5010026828365586
Validation loss: 2.649490087261807

Epoch: 74| Step: 0
Training loss: 2.600321155667096
Validation loss: 2.6691740933387504

Epoch: 6| Step: 1
Training loss: 2.473303735698176
Validation loss: 2.620038444974681

Epoch: 6| Step: 2
Training loss: 2.0362017795948764
Validation loss: 2.6360527045056203

Epoch: 6| Step: 3
Training loss: 2.465587763632055
Validation loss: 2.561957154499642

Epoch: 6| Step: 4
Training loss: 3.1638554258049636
Validation loss: 2.5699302597825247

Epoch: 6| Step: 5
Training loss: 2.9370944778058496
Validation loss: 2.6429035881986245

Epoch: 6| Step: 6
Training loss: 2.100340874572076
Validation loss: 2.6578434521672323

Epoch: 6| Step: 7
Training loss: 2.014159860321948
Validation loss: 2.597977590165214

Epoch: 6| Step: 8
Training loss: 2.57367965772565
Validation loss: 2.620893543706094

Epoch: 6| Step: 9
Training loss: 2.2227960150407866
Validation loss: 2.5703649158022417

Epoch: 6| Step: 10
Training loss: 1.9977112429452408
Validation loss: 2.6804808840675745

Epoch: 6| Step: 11
Training loss: 2.1387485716841192
Validation loss: 2.59421988524459

Epoch: 6| Step: 12
Training loss: 2.228919886063649
Validation loss: 2.5778809403004828

Epoch: 6| Step: 13
Training loss: 2.5000532144605
Validation loss: 2.570783964164289

Epoch: 75| Step: 0
Training loss: 2.3166115783984327
Validation loss: 2.594823056131581

Epoch: 6| Step: 1
Training loss: 2.379996314646969
Validation loss: 2.612431226856378

Epoch: 6| Step: 2
Training loss: 1.9730998229824175
Validation loss: 2.5927601039852544

Epoch: 6| Step: 3
Training loss: 2.341703004204398
Validation loss: 2.654254642587548

Epoch: 6| Step: 4
Training loss: 2.2501785419409663
Validation loss: 2.635532049937693

Epoch: 6| Step: 5
Training loss: 2.4864464527150467
Validation loss: 2.6598405842109654

Epoch: 6| Step: 6
Training loss: 2.4294645446338197
Validation loss: 2.6740854946127226

Epoch: 6| Step: 7
Training loss: 2.213385530836794
Validation loss: 2.728997936323016

Epoch: 6| Step: 8
Training loss: 2.6963677593436564
Validation loss: 2.682930765894478

Epoch: 6| Step: 9
Training loss: 2.082958136787529
Validation loss: 2.73368980905429

Epoch: 6| Step: 10
Training loss: 1.9440370231250443
Validation loss: 2.6352114289673434

Epoch: 6| Step: 11
Training loss: 3.119332935230773
Validation loss: 2.674620008366242

Epoch: 6| Step: 12
Training loss: 2.430551847424782
Validation loss: 2.6817455044338847

Epoch: 6| Step: 13
Training loss: 2.1166312412491424
Validation loss: 2.6097815648017373

Epoch: 76| Step: 0
Training loss: 2.1051652509108587
Validation loss: 2.6413901008774965

Epoch: 6| Step: 1
Training loss: 2.769874454641639
Validation loss: 2.598641176818361

Epoch: 6| Step: 2
Training loss: 1.8399103561623265
Validation loss: 2.552875167594889

Epoch: 6| Step: 3
Training loss: 2.4636433575686714
Validation loss: 2.5590800902979107

Epoch: 6| Step: 4
Training loss: 2.1219725641172205
Validation loss: 2.666855489979671

Epoch: 6| Step: 5
Training loss: 3.086987898515881
Validation loss: 2.6023641731516687

Epoch: 6| Step: 6
Training loss: 2.4482967216951828
Validation loss: 2.616940888130451

Epoch: 6| Step: 7
Training loss: 2.8275179553958516
Validation loss: 2.6537676113488824

Epoch: 6| Step: 8
Training loss: 2.4169221501847575
Validation loss: 2.707023822431113

Epoch: 6| Step: 9
Training loss: 2.0016840758613443
Validation loss: 2.580057102207241

Epoch: 6| Step: 10
Training loss: 2.336878762335247
Validation loss: 2.6264979085066082

Epoch: 6| Step: 11
Training loss: 2.7950644999860077
Validation loss: 2.5954544258239114

Epoch: 6| Step: 12
Training loss: 2.429733324998678
Validation loss: 2.573969287198043

Epoch: 6| Step: 13
Training loss: 2.400843503860528
Validation loss: 2.6239942107272443

Epoch: 77| Step: 0
Training loss: 2.363036592288177
Validation loss: 2.642495179642606

Epoch: 6| Step: 1
Training loss: 1.7380422363548573
Validation loss: 2.698107875887159

Epoch: 6| Step: 2
Training loss: 2.96144329169648
Validation loss: 2.6377628397333375

Epoch: 6| Step: 3
Training loss: 1.9858905681644106
Validation loss: 2.735340231422889

Epoch: 6| Step: 4
Training loss: 1.9289804622793854
Validation loss: 2.691738482797644

Epoch: 6| Step: 5
Training loss: 2.027402549875866
Validation loss: 2.697453556055755

Epoch: 6| Step: 6
Training loss: 2.2919300852725826
Validation loss: 2.5935268689125475

Epoch: 6| Step: 7
Training loss: 2.6967699616134477
Validation loss: 2.6595288104811914

Epoch: 6| Step: 8
Training loss: 2.385078828256687
Validation loss: 2.624673020721501

Epoch: 6| Step: 9
Training loss: 2.262346197137906
Validation loss: 2.6625470487112053

Epoch: 6| Step: 10
Training loss: 2.9552946647984415
Validation loss: 2.686205737123679

Epoch: 6| Step: 11
Training loss: 1.9607596145738515
Validation loss: 2.6814195468177893

Epoch: 6| Step: 12
Training loss: 2.3326923193766174
Validation loss: 2.626529066609418

Epoch: 6| Step: 13
Training loss: 2.7940483940919547
Validation loss: 2.623325086028898

Epoch: 78| Step: 0
Training loss: 1.6307263348616854
Validation loss: 2.5896263894399025

Epoch: 6| Step: 1
Training loss: 2.342200822645982
Validation loss: 2.567793387551233

Epoch: 6| Step: 2
Training loss: 2.7422168871399872
Validation loss: 2.6189964002497366

Epoch: 6| Step: 3
Training loss: 2.3680243193305506
Validation loss: 2.613507210200418

Epoch: 6| Step: 4
Training loss: 1.756177896668938
Validation loss: 2.602423753504014

Epoch: 6| Step: 5
Training loss: 2.0918422377054946
Validation loss: 2.6138405498336996

Epoch: 6| Step: 6
Training loss: 2.6234730411959792
Validation loss: 2.6431748007208546

Epoch: 6| Step: 7
Training loss: 2.768403204216637
Validation loss: 2.670632086286987

Epoch: 6| Step: 8
Training loss: 2.442881097492884
Validation loss: 2.5241490041073478

Epoch: 6| Step: 9
Training loss: 1.8268963850442155
Validation loss: 2.6307351418860763

Epoch: 6| Step: 10
Training loss: 2.6820335683748717
Validation loss: 2.544312949533204

Epoch: 6| Step: 11
Training loss: 2.8600351374141635
Validation loss: 2.6397599076662774

Epoch: 6| Step: 12
Training loss: 2.299695728741892
Validation loss: 2.6631644666018763

Epoch: 6| Step: 13
Training loss: 2.6753000536757114
Validation loss: 2.7260108761378032

Epoch: 79| Step: 0
Training loss: 3.2672318151342865
Validation loss: 2.665571104446209

Epoch: 6| Step: 1
Training loss: 1.8143875553696687
Validation loss: 2.6801388344697132

Epoch: 6| Step: 2
Training loss: 2.635487722612507
Validation loss: 2.6837429132887682

Epoch: 6| Step: 3
Training loss: 2.60299670577601
Validation loss: 2.642855512895904

Epoch: 6| Step: 4
Training loss: 1.7592753786980768
Validation loss: 2.6580654298284427

Epoch: 6| Step: 5
Training loss: 1.8596376506038963
Validation loss: 2.5783059258988303

Epoch: 6| Step: 6
Training loss: 2.1242646459662917
Validation loss: 2.683559811750919

Epoch: 6| Step: 7
Training loss: 1.9695382735094238
Validation loss: 2.620783045053289

Epoch: 6| Step: 8
Training loss: 2.6037575565691813
Validation loss: 2.5544550767603265

Epoch: 6| Step: 9
Training loss: 2.049984266639439
Validation loss: 2.598217620997285

Epoch: 6| Step: 10
Training loss: 2.714921030824521
Validation loss: 2.6042302594367603

Epoch: 6| Step: 11
Training loss: 2.538654001093506
Validation loss: 2.569601809061664

Epoch: 6| Step: 12
Training loss: 2.6790996829885145
Validation loss: 2.6100307105195415

Epoch: 6| Step: 13
Training loss: 2.344814719910558
Validation loss: 2.61837403080241

Epoch: 80| Step: 0
Training loss: 2.7258086378362183
Validation loss: 2.633294262374881

Epoch: 6| Step: 1
Training loss: 1.8464441174403183
Validation loss: 2.5444972634790823

Epoch: 6| Step: 2
Training loss: 2.2387394461071506
Validation loss: 2.568946374841586

Epoch: 6| Step: 3
Training loss: 2.559453036617232
Validation loss: 2.6459474814314454

Epoch: 6| Step: 4
Training loss: 2.1224888943043525
Validation loss: 2.5983536245480727

Epoch: 6| Step: 5
Training loss: 2.9117918602577655
Validation loss: 2.626737836786916

Epoch: 6| Step: 6
Training loss: 1.6916841978971842
Validation loss: 2.6156878829561645

Epoch: 6| Step: 7
Training loss: 1.5743804924275846
Validation loss: 2.624137267376782

Epoch: 6| Step: 8
Training loss: 2.549381637396265
Validation loss: 2.594949912002503

Epoch: 6| Step: 9
Training loss: 2.528144061154628
Validation loss: 2.6612276747474723

Epoch: 6| Step: 10
Training loss: 2.462435989709777
Validation loss: 2.499005676262067

Epoch: 6| Step: 11
Training loss: 2.4143465239217923
Validation loss: 2.622554230033839

Epoch: 6| Step: 12
Training loss: 2.5362417662568206
Validation loss: 2.6043694429923425

Epoch: 6| Step: 13
Training loss: 2.441856599088631
Validation loss: 2.641699149255976

Epoch: 81| Step: 0
Training loss: 2.0311758174554995
Validation loss: 2.6414074312282847

Epoch: 6| Step: 1
Training loss: 1.5513748839195969
Validation loss: 2.611673526750849

Epoch: 6| Step: 2
Training loss: 2.3718039440422998
Validation loss: 2.6188289979416375

Epoch: 6| Step: 3
Training loss: 1.7405745219884896
Validation loss: 2.674725400787855

Epoch: 6| Step: 4
Training loss: 3.0722175104504816
Validation loss: 2.606844331592488

Epoch: 6| Step: 5
Training loss: 2.6744916272391586
Validation loss: 2.5923214084343935

Epoch: 6| Step: 6
Training loss: 2.4815093973855396
Validation loss: 2.5421914095732285

Epoch: 6| Step: 7
Training loss: 2.0103850156305327
Validation loss: 2.585992357300265

Epoch: 6| Step: 8
Training loss: 2.795023811661999
Validation loss: 2.5432780634856256

Epoch: 6| Step: 9
Training loss: 2.635434076505509
Validation loss: 2.5879615015844553

Epoch: 6| Step: 10
Training loss: 2.2057906453385896
Validation loss: 2.6201053277409714

Epoch: 6| Step: 11
Training loss: 2.777762294302279
Validation loss: 2.5745546375541353

Epoch: 6| Step: 12
Training loss: 2.182261051761376
Validation loss: 2.572009066814422

Epoch: 6| Step: 13
Training loss: 2.225661781562006
Validation loss: 2.6321217793957055

Epoch: 82| Step: 0
Training loss: 2.3672461171965886
Validation loss: 2.5757462441778225

Epoch: 6| Step: 1
Training loss: 2.378341532610434
Validation loss: 2.6751137747886093

Epoch: 6| Step: 2
Training loss: 1.9021522378575086
Validation loss: 2.611194927705524

Epoch: 6| Step: 3
Training loss: 2.3581703597012527
Validation loss: 2.6534939923081557

Epoch: 6| Step: 4
Training loss: 1.5633001186255873
Validation loss: 2.6124763256503076

Epoch: 6| Step: 5
Training loss: 2.2183121799957464
Validation loss: 2.6601273604666753

Epoch: 6| Step: 6
Training loss: 2.3204962147125165
Validation loss: 2.5682307105961337

Epoch: 6| Step: 7
Training loss: 2.2034029954332968
Validation loss: 2.62683956841477

Epoch: 6| Step: 8
Training loss: 2.471099508099717
Validation loss: 2.5869512808515176

Epoch: 6| Step: 9
Training loss: 2.4461520280356033
Validation loss: 2.6011153439215717

Epoch: 6| Step: 10
Training loss: 2.7037878381459692
Validation loss: 2.5276147145878465

Epoch: 6| Step: 11
Training loss: 2.637969357640104
Validation loss: 2.6071401379565486

Epoch: 6| Step: 12
Training loss: 2.4508213962894176
Validation loss: 2.6129793715968725

Epoch: 6| Step: 13
Training loss: 2.282348159469259
Validation loss: 2.5974218124111363

Epoch: 83| Step: 0
Training loss: 2.9559025695395227
Validation loss: 2.6094042077780717

Epoch: 6| Step: 1
Training loss: 2.6427769667198926
Validation loss: 2.681372125033278

Epoch: 6| Step: 2
Training loss: 1.749640972910767
Validation loss: 2.6633473589611

Epoch: 6| Step: 3
Training loss: 2.1902186257612715
Validation loss: 2.735898245735554

Epoch: 6| Step: 4
Training loss: 2.084146023230782
Validation loss: 2.7203424109184495

Epoch: 6| Step: 5
Training loss: 2.3208850706441533
Validation loss: 2.6921665278654956

Epoch: 6| Step: 6
Training loss: 2.464223937924769
Validation loss: 2.697533220611583

Epoch: 6| Step: 7
Training loss: 2.227691899349031
Validation loss: 2.8066652031877317

Epoch: 6| Step: 8
Training loss: 2.52741808538768
Validation loss: 2.6323819133795108

Epoch: 6| Step: 9
Training loss: 1.8421084968638899
Validation loss: 2.633768015810304

Epoch: 6| Step: 10
Training loss: 2.331292167875376
Validation loss: 2.617298222567278

Epoch: 6| Step: 11
Training loss: 2.8893810998124865
Validation loss: 2.602242565144286

Epoch: 6| Step: 12
Training loss: 2.1836457220726917
Validation loss: 2.534153391677757

Epoch: 6| Step: 13
Training loss: 2.130703508671259
Validation loss: 2.5842449261590716

Epoch: 84| Step: 0
Training loss: 2.678626559462172
Validation loss: 2.6660354035963145

Epoch: 6| Step: 1
Training loss: 1.9324650716647755
Validation loss: 2.567293506305802

Epoch: 6| Step: 2
Training loss: 2.149274850138811
Validation loss: 2.527989748624647

Epoch: 6| Step: 3
Training loss: 1.7351903974736085
Validation loss: 2.610068878078587

Epoch: 6| Step: 4
Training loss: 2.9273760412800653
Validation loss: 2.549814832733671

Epoch: 6| Step: 5
Training loss: 2.170348804409165
Validation loss: 2.61977525001878

Epoch: 6| Step: 6
Training loss: 2.395313328135049
Validation loss: 2.6859350305427174

Epoch: 6| Step: 7
Training loss: 1.7505116395974667
Validation loss: 2.6051931316466566

Epoch: 6| Step: 8
Training loss: 2.699209475466836
Validation loss: 2.614359588978884

Epoch: 6| Step: 9
Training loss: 2.4066886997359096
Validation loss: 2.6161458385988254

Epoch: 6| Step: 10
Training loss: 2.450742597338991
Validation loss: 2.6214981335668415

Epoch: 6| Step: 11
Training loss: 1.9736050882709166
Validation loss: 2.606358564449935

Epoch: 6| Step: 12
Training loss: 2.6734031189001444
Validation loss: 2.6515214157443343

Epoch: 6| Step: 13
Training loss: 2.5664209281234553
Validation loss: 2.5856769349818567

Epoch: 85| Step: 0
Training loss: 2.197790627383597
Validation loss: 2.6695197806531996

Epoch: 6| Step: 1
Training loss: 2.1724587074631185
Validation loss: 2.6028983168191555

Epoch: 6| Step: 2
Training loss: 2.5484296114464433
Validation loss: 2.661063974405903

Epoch: 6| Step: 3
Training loss: 2.224787061124321
Validation loss: 2.6236728916284187

Epoch: 6| Step: 4
Training loss: 2.8265018758182183
Validation loss: 2.5782677813208745

Epoch: 6| Step: 5
Training loss: 1.9305625506791955
Validation loss: 2.617382949439307

Epoch: 6| Step: 6
Training loss: 2.3653225744483706
Validation loss: 2.6048468095786887

Epoch: 6| Step: 7
Training loss: 2.0615863510355026
Validation loss: 2.5980224045376463

Epoch: 6| Step: 8
Training loss: 1.957312283924192
Validation loss: 2.5821241476532735

Epoch: 6| Step: 9
Training loss: 2.2228193977428057
Validation loss: 2.614953813989863

Epoch: 6| Step: 10
Training loss: 2.0846624585092832
Validation loss: 2.5873824401539136

Epoch: 6| Step: 11
Training loss: 2.423581611091848
Validation loss: 2.585705426915265

Epoch: 6| Step: 12
Training loss: 3.09372395205851
Validation loss: 2.5714453893444555

Epoch: 6| Step: 13
Training loss: 2.3912700705276717
Validation loss: 2.607914392100879

Epoch: 86| Step: 0
Training loss: 2.594028228176764
Validation loss: 2.659616902066968

Epoch: 6| Step: 1
Training loss: 2.125864974857741
Validation loss: 2.561368048711982

Epoch: 6| Step: 2
Training loss: 1.7281144705756868
Validation loss: 2.6097348892038044

Epoch: 6| Step: 3
Training loss: 2.150211004504349
Validation loss: 2.689443078041933

Epoch: 6| Step: 4
Training loss: 2.5017803528546314
Validation loss: 2.6020329902447785

Epoch: 6| Step: 5
Training loss: 2.4447453727830513
Validation loss: 2.7597477852257573

Epoch: 6| Step: 6
Training loss: 2.967175196521194
Validation loss: 2.6875290979983624

Epoch: 6| Step: 7
Training loss: 2.1496474309648113
Validation loss: 2.6653644590963244

Epoch: 6| Step: 8
Training loss: 2.1466051090291636
Validation loss: 2.647746533306317

Epoch: 6| Step: 9
Training loss: 1.7856897270693708
Validation loss: 2.6224548929200266

Epoch: 6| Step: 10
Training loss: 2.1175997287005
Validation loss: 2.5595583429678874

Epoch: 6| Step: 11
Training loss: 3.124257113847664
Validation loss: 2.589104041881102

Epoch: 6| Step: 12
Training loss: 2.09016384632401
Validation loss: 2.5379800063764333

Epoch: 6| Step: 13
Training loss: 2.18883844028091
Validation loss: 2.515212386512529

Epoch: 87| Step: 0
Training loss: 2.2048946334680135
Validation loss: 2.615224544325289

Epoch: 6| Step: 1
Training loss: 2.5680500496951493
Validation loss: 2.538900219548617

Epoch: 6| Step: 2
Training loss: 2.4142679170289516
Validation loss: 2.5892173734581494

Epoch: 6| Step: 3
Training loss: 2.0803457455115293
Validation loss: 2.5985167337778825

Epoch: 6| Step: 4
Training loss: 2.7268132747542464
Validation loss: 2.5151488680858685

Epoch: 6| Step: 5
Training loss: 1.9144637952256973
Validation loss: 2.503175070297968

Epoch: 6| Step: 6
Training loss: 2.214616175133204
Validation loss: 2.514747142644626

Epoch: 6| Step: 7
Training loss: 1.6045411486129495
Validation loss: 2.693701811062197

Epoch: 6| Step: 8
Training loss: 2.5634010405542
Validation loss: 2.6109879280910913

Epoch: 6| Step: 9
Training loss: 1.9273715310632384
Validation loss: 2.703824939403505

Epoch: 6| Step: 10
Training loss: 2.045667452279911
Validation loss: 2.712573683597839

Epoch: 6| Step: 11
Training loss: 2.2243084122031407
Validation loss: 2.6295961983316203

Epoch: 6| Step: 12
Training loss: 2.2966543078632142
Validation loss: 2.6731980600600886

Epoch: 6| Step: 13
Training loss: 2.9176644571299515
Validation loss: 2.6240938075702145

Epoch: 88| Step: 0
Training loss: 1.9520441345165804
Validation loss: 2.637230687305183

Epoch: 6| Step: 1
Training loss: 2.6972970926160436
Validation loss: 2.615753145166603

Epoch: 6| Step: 2
Training loss: 1.949267369583236
Validation loss: 2.622569972711808

Epoch: 6| Step: 3
Training loss: 2.8696056012565028
Validation loss: 2.6605277527927678

Epoch: 6| Step: 4
Training loss: 2.014753522919783
Validation loss: 2.635989512631553

Epoch: 6| Step: 5
Training loss: 1.9755109922682055
Validation loss: 2.6448419220336383

Epoch: 6| Step: 6
Training loss: 2.1502558001557666
Validation loss: 2.645842594721247

Epoch: 6| Step: 7
Training loss: 2.39471305418362
Validation loss: 2.5932390713251965

Epoch: 6| Step: 8
Training loss: 2.4762836864939555
Validation loss: 2.713914553940542

Epoch: 6| Step: 9
Training loss: 2.4353364977491894
Validation loss: 2.6926879119590574

Epoch: 6| Step: 10
Training loss: 1.8673587225772665
Validation loss: 2.602839693857219

Epoch: 6| Step: 11
Training loss: 1.8670588492919447
Validation loss: 2.6039663288622314

Epoch: 6| Step: 12
Training loss: 3.163039958227488
Validation loss: 2.6345048214022495

Epoch: 6| Step: 13
Training loss: 1.7650381817888834
Validation loss: 2.6323671577436185

Epoch: 89| Step: 0
Training loss: 2.92578450955259
Validation loss: 2.589168086457229

Epoch: 6| Step: 1
Training loss: 2.2466134971001983
Validation loss: 2.57956450377267

Epoch: 6| Step: 2
Training loss: 2.185634689680464
Validation loss: 2.596144386828543

Epoch: 6| Step: 3
Training loss: 1.8414908323740777
Validation loss: 2.5132495888014295

Epoch: 6| Step: 4
Training loss: 2.102830809015893
Validation loss: 2.6581962187352883

Epoch: 6| Step: 5
Training loss: 2.4973702905095836
Validation loss: 2.5360976373296698

Epoch: 6| Step: 6
Training loss: 2.094040352346014
Validation loss: 2.60234522380957

Epoch: 6| Step: 7
Training loss: 2.4285654500679352
Validation loss: 2.56303704069383

Epoch: 6| Step: 8
Training loss: 1.696355402236159
Validation loss: 2.55064412751769

Epoch: 6| Step: 9
Training loss: 2.887643462080996
Validation loss: 2.589054699005241

Epoch: 6| Step: 10
Training loss: 1.142734197406751
Validation loss: 2.6169208903237346

Epoch: 6| Step: 11
Training loss: 2.3094148418205624
Validation loss: 2.6115599752598584

Epoch: 6| Step: 12
Training loss: 3.01481657112328
Validation loss: 2.6377473459074654

Epoch: 6| Step: 13
Training loss: 2.2997846792853105
Validation loss: 2.5931041173798217

Epoch: 90| Step: 0
Training loss: 1.9337978062703165
Validation loss: 2.6330808357514823

Epoch: 6| Step: 1
Training loss: 2.7101837781408125
Validation loss: 2.650932974295302

Epoch: 6| Step: 2
Training loss: 2.355464600010596
Validation loss: 2.6372391401498767

Epoch: 6| Step: 3
Training loss: 2.022121634910242
Validation loss: 2.5998726703569717

Epoch: 6| Step: 4
Training loss: 2.7374243599531374
Validation loss: 2.646722093629548

Epoch: 6| Step: 5
Training loss: 1.9540778315455274
Validation loss: 2.6239932566872066

Epoch: 6| Step: 6
Training loss: 2.7633524895507535
Validation loss: 2.701605985580891

Epoch: 6| Step: 7
Training loss: 2.4708341661765982
Validation loss: 2.663103425085444

Epoch: 6| Step: 8
Training loss: 2.17680403333891
Validation loss: 2.5710643994211155

Epoch: 6| Step: 9
Training loss: 2.4757196093102585
Validation loss: 2.6615827398219984

Epoch: 6| Step: 10
Training loss: 1.8509332416516997
Validation loss: 2.5941431904175865

Epoch: 6| Step: 11
Training loss: 1.8920009429719604
Validation loss: 2.5815311318815146

Epoch: 6| Step: 12
Training loss: 2.132876999546981
Validation loss: 2.530382235254206

Epoch: 6| Step: 13
Training loss: 2.5320153668737313
Validation loss: 2.593484750076623

Epoch: 91| Step: 0
Training loss: 2.2670962062255917
Validation loss: 2.616562718454775

Epoch: 6| Step: 1
Training loss: 2.3574160091450427
Validation loss: 2.5509690453652474

Epoch: 6| Step: 2
Training loss: 2.0460171831216742
Validation loss: 2.633479364989674

Epoch: 6| Step: 3
Training loss: 1.949033556379685
Validation loss: 2.6223954949225643

Epoch: 6| Step: 4
Training loss: 1.639707690333298
Validation loss: 2.6318763253268957

Epoch: 6| Step: 5
Training loss: 2.263167633691702
Validation loss: 2.6882370965582276

Epoch: 6| Step: 6
Training loss: 2.843122140510213
Validation loss: 2.794220415829569

Epoch: 6| Step: 7
Training loss: 2.614011015444883
Validation loss: 2.7254939859356915

Epoch: 6| Step: 8
Training loss: 2.1090714978054264
Validation loss: 2.6931064884413916

Epoch: 6| Step: 9
Training loss: 2.8569891309254354
Validation loss: 2.6799293016009558

Epoch: 6| Step: 10
Training loss: 2.47594976215824
Validation loss: 2.608846066407062

Epoch: 6| Step: 11
Training loss: 2.5178078605057053
Validation loss: 2.5882536166905923

Epoch: 6| Step: 12
Training loss: 2.067755505642706
Validation loss: 2.6220520056778676

Epoch: 6| Step: 13
Training loss: 2.5025793121299826
Validation loss: 2.5674538682942862

Epoch: 92| Step: 0
Training loss: 2.267107248496216
Validation loss: 2.6083453768207354

Epoch: 6| Step: 1
Training loss: 2.5954023865826295
Validation loss: 2.600234203305188

Epoch: 6| Step: 2
Training loss: 3.190319086218055
Validation loss: 2.557146846506052

Epoch: 6| Step: 3
Training loss: 2.1547576605181202
Validation loss: 2.5811164070146586

Epoch: 6| Step: 4
Training loss: 1.997857137939478
Validation loss: 2.6776897371978445

Epoch: 6| Step: 5
Training loss: 2.863883544525511
Validation loss: 2.5886524619345503

Epoch: 6| Step: 6
Training loss: 1.380542983265017
Validation loss: 2.7048224850531333

Epoch: 6| Step: 7
Training loss: 2.0029765867101843
Validation loss: 2.6436112351670427

Epoch: 6| Step: 8
Training loss: 2.2860938080691247
Validation loss: 2.5214364825131943

Epoch: 6| Step: 9
Training loss: 1.4341923350124954
Validation loss: 2.655741564391373

Epoch: 6| Step: 10
Training loss: 2.1764754278617384
Validation loss: 2.630718692830942

Epoch: 6| Step: 11
Training loss: 2.671491182655778
Validation loss: 2.654110723970884

Epoch: 6| Step: 12
Training loss: 2.3107123811444
Validation loss: 2.7489173520873584

Epoch: 6| Step: 13
Training loss: 2.361737211901666
Validation loss: 2.7133827284957106

Epoch: 93| Step: 0
Training loss: 2.0436981241251093
Validation loss: 2.766849713608845

Epoch: 6| Step: 1
Training loss: 1.8015111408042679
Validation loss: 2.675654276041866

Epoch: 6| Step: 2
Training loss: 1.962223193820143
Validation loss: 2.6863755971576477

Epoch: 6| Step: 3
Training loss: 2.5434354245488713
Validation loss: 2.582646376014938

Epoch: 6| Step: 4
Training loss: 2.773901672204793
Validation loss: 2.6652828639475965

Epoch: 6| Step: 5
Training loss: 2.6608236990767273
Validation loss: 2.6249944141873467

Epoch: 6| Step: 6
Training loss: 2.1459495982057804
Validation loss: 2.559655168823033

Epoch: 6| Step: 7
Training loss: 2.46222103494523
Validation loss: 2.583039933637707

Epoch: 6| Step: 8
Training loss: 1.4663350156575101
Validation loss: 2.689761873362452

Epoch: 6| Step: 9
Training loss: 1.892770983747829
Validation loss: 2.6212446355999783

Epoch: 6| Step: 10
Training loss: 2.5411719377483504
Validation loss: 2.524187384044233

Epoch: 6| Step: 11
Training loss: 1.9268590916939865
Validation loss: 2.5689388883248334

Epoch: 6| Step: 12
Training loss: 2.191669958230606
Validation loss: 2.5779476528628904

Epoch: 6| Step: 13
Training loss: 2.3212405830812664
Validation loss: 2.582239709115725

Epoch: 94| Step: 0
Training loss: 2.188338418776953
Validation loss: 2.583736178049422

Epoch: 6| Step: 1
Training loss: 2.4941659566120125
Validation loss: 2.632273119755568

Epoch: 6| Step: 2
Training loss: 1.8678594042699983
Validation loss: 2.5980293484019534

Epoch: 6| Step: 3
Training loss: 1.7620875613249884
Validation loss: 2.6591888775003016

Epoch: 6| Step: 4
Training loss: 2.709312985600385
Validation loss: 2.6134504825096703

Epoch: 6| Step: 5
Training loss: 2.6404897440743853
Validation loss: 2.6287375438985814

Epoch: 6| Step: 6
Training loss: 1.887725308846482
Validation loss: 2.6448993135600922

Epoch: 6| Step: 7
Training loss: 2.7153347970927517
Validation loss: 2.625821862913514

Epoch: 6| Step: 8
Training loss: 2.3781336138816154
Validation loss: 2.6231881049437256

Epoch: 6| Step: 9
Training loss: 2.3559385625085687
Validation loss: 2.6080372897282813

Epoch: 6| Step: 10
Training loss: 2.1785980017513245
Validation loss: 2.593635954896598

Epoch: 6| Step: 11
Training loss: 1.5846803690652667
Validation loss: 2.610447996113386

Epoch: 6| Step: 12
Training loss: 2.669384604409744
Validation loss: 2.631387115312904

Epoch: 6| Step: 13
Training loss: 2.0793221832804853
Validation loss: 2.5790364205336704

Epoch: 95| Step: 0
Training loss: 1.7529088776184696
Validation loss: 2.6747356590192934

Epoch: 6| Step: 1
Training loss: 2.0234127558664414
Validation loss: 2.627887560581069

Epoch: 6| Step: 2
Training loss: 2.0970107920036525
Validation loss: 2.657556264980876

Epoch: 6| Step: 3
Training loss: 3.299024125505005
Validation loss: 2.6120172550445435

Epoch: 6| Step: 4
Training loss: 2.6800122300623355
Validation loss: 2.6365645149238026

Epoch: 6| Step: 5
Training loss: 2.3937646531734726
Validation loss: 2.621336408848412

Epoch: 6| Step: 6
Training loss: 1.6504653101167204
Validation loss: 2.633977041960787

Epoch: 6| Step: 7
Training loss: 2.2312787350639507
Validation loss: 2.6064935486552265

Epoch: 6| Step: 8
Training loss: 2.3387136643898727
Validation loss: 2.5979446901116727

Epoch: 6| Step: 9
Training loss: 1.9002497308141444
Validation loss: 2.6488437622310816

Epoch: 6| Step: 10
Training loss: 2.288959175355758
Validation loss: 2.623965059347241

Epoch: 6| Step: 11
Training loss: 2.4973061352885053
Validation loss: 2.6151020756353334

Epoch: 6| Step: 12
Training loss: 2.3635314304561104
Validation loss: 2.674879188423913

Epoch: 6| Step: 13
Training loss: 1.8800273255127657
Validation loss: 2.6326213129583267

Epoch: 96| Step: 0
Training loss: 2.7936710355040475
Validation loss: 2.5908106345868136

Epoch: 6| Step: 1
Training loss: 2.535828394020561
Validation loss: 2.6112280108163755

Epoch: 6| Step: 2
Training loss: 2.049139968224474
Validation loss: 2.5720379109967753

Epoch: 6| Step: 3
Training loss: 2.3951204206738352
Validation loss: 2.637729825798322

Epoch: 6| Step: 4
Training loss: 2.2521074809551
Validation loss: 2.6580300145115805

Epoch: 6| Step: 5
Training loss: 3.0224688257166856
Validation loss: 2.5230752470377413

Epoch: 6| Step: 6
Training loss: 2.4501277812410476
Validation loss: 2.5583213292274127

Epoch: 6| Step: 7
Training loss: 1.8663567007520665
Validation loss: 2.613682859054957

Epoch: 6| Step: 8
Training loss: 2.1918156151385957
Validation loss: 2.6158878572616215

Epoch: 6| Step: 9
Training loss: 1.8392747780822611
Validation loss: 2.619433829186151

Epoch: 6| Step: 10
Training loss: 1.805833328920701
Validation loss: 2.569927801312944

Epoch: 6| Step: 11
Training loss: 1.6474006610147962
Validation loss: 2.644139638855395

Epoch: 6| Step: 12
Training loss: 2.2274667075052847
Validation loss: 2.707145009625314

Epoch: 6| Step: 13
Training loss: 2.2011316899961533
Validation loss: 2.642554155923801

Epoch: 97| Step: 0
Training loss: 2.287482331421369
Validation loss: 2.5363706433897657

Epoch: 6| Step: 1
Training loss: 1.491444187870752
Validation loss: 2.6047615643341078

Epoch: 6| Step: 2
Training loss: 2.058610659100977
Validation loss: 2.55803516298851

Epoch: 6| Step: 3
Training loss: 2.1194738451294906
Validation loss: 2.5256140487900436

Epoch: 6| Step: 4
Training loss: 2.0563235423378066
Validation loss: 2.6056999778802896

Epoch: 6| Step: 5
Training loss: 2.273609797185343
Validation loss: 2.602596295212334

Epoch: 6| Step: 6
Training loss: 2.2712593262333463
Validation loss: 2.661022073383951

Epoch: 6| Step: 7
Training loss: 1.890077874330239
Validation loss: 2.565932820014308

Epoch: 6| Step: 8
Training loss: 2.806848060412377
Validation loss: 2.5134543932673843

Epoch: 6| Step: 9
Training loss: 2.0079680505011765
Validation loss: 2.5273828989855724

Epoch: 6| Step: 10
Training loss: 2.1095769714866317
Validation loss: 2.688842438155602

Epoch: 6| Step: 11
Training loss: 3.19984275312309
Validation loss: 2.6098982691761394

Epoch: 6| Step: 12
Training loss: 2.4314535413724316
Validation loss: 2.5983356094187258

Epoch: 6| Step: 13
Training loss: 1.8457412312121209
Validation loss: 2.6095897258802268

Epoch: 98| Step: 0
Training loss: 1.7797980162858438
Validation loss: 2.592231144919938

Epoch: 6| Step: 1
Training loss: 2.292600429918438
Validation loss: 2.5988071731509486

Epoch: 6| Step: 2
Training loss: 2.032787621336339
Validation loss: 2.6790989117239503

Epoch: 6| Step: 3
Training loss: 2.491827768414464
Validation loss: 2.6565330204997517

Epoch: 6| Step: 4
Training loss: 2.4920445703160876
Validation loss: 2.5794216247737047

Epoch: 6| Step: 5
Training loss: 2.117446827226505
Validation loss: 2.5763574879924276

Epoch: 6| Step: 6
Training loss: 2.289917040992198
Validation loss: 2.679234191098976

Epoch: 6| Step: 7
Training loss: 1.996148394230484
Validation loss: 2.5988696025208697

Epoch: 6| Step: 8
Training loss: 3.1265520437848333
Validation loss: 2.6674905537393636

Epoch: 6| Step: 9
Training loss: 2.1034524920525355
Validation loss: 2.5843364372897377

Epoch: 6| Step: 10
Training loss: 2.0504027971112437
Validation loss: 2.659045360439861

Epoch: 6| Step: 11
Training loss: 2.3305207285389895
Validation loss: 2.5949991351268897

Epoch: 6| Step: 12
Training loss: 1.770474685552611
Validation loss: 2.627683796477852

Epoch: 6| Step: 13
Training loss: 1.9526398323188792
Validation loss: 2.639739992410027

Epoch: 99| Step: 0
Training loss: 2.362266133353742
Validation loss: 2.560801121212969

Epoch: 6| Step: 1
Training loss: 1.793592689341705
Validation loss: 2.5258891947765525

Epoch: 6| Step: 2
Training loss: 2.0335668408917646
Validation loss: 2.692979283723075

Epoch: 6| Step: 3
Training loss: 1.809157215774898
Validation loss: 2.5769621567439924

Epoch: 6| Step: 4
Training loss: 2.2271503943923374
Validation loss: 2.6770455225390735

Epoch: 6| Step: 5
Training loss: 1.733781867803592
Validation loss: 2.602988050139553

Epoch: 6| Step: 6
Training loss: 1.978554426831388
Validation loss: 2.5845157983166307

Epoch: 6| Step: 7
Training loss: 2.4666112979482633
Validation loss: 2.643380196802537

Epoch: 6| Step: 8
Training loss: 2.0745155136547044
Validation loss: 2.6255159173813616

Epoch: 6| Step: 9
Training loss: 2.18825692296423
Validation loss: 2.621184558309214

Epoch: 6| Step: 10
Training loss: 2.738279334488007
Validation loss: 2.6867197811549572

Epoch: 6| Step: 11
Training loss: 1.865587642429836
Validation loss: 2.56609066552324

Epoch: 6| Step: 12
Training loss: 2.8562418129968483
Validation loss: 2.697444518517186

Epoch: 6| Step: 13
Training loss: 2.9239251599107794
Validation loss: 2.585788150097146

Epoch: 100| Step: 0
Training loss: 2.06623825226829
Validation loss: 2.646165756809115

Epoch: 6| Step: 1
Training loss: 2.4285152833523265
Validation loss: 2.6220278944281934

Epoch: 6| Step: 2
Training loss: 1.607651908424485
Validation loss: 2.565586402345631

Epoch: 6| Step: 3
Training loss: 1.8872990633890512
Validation loss: 2.704199737166358

Epoch: 6| Step: 4
Training loss: 2.203779515649188
Validation loss: 2.5393662178124914

Epoch: 6| Step: 5
Training loss: 2.468955115959791
Validation loss: 2.6283098879268167

Epoch: 6| Step: 6
Training loss: 2.60557187632655
Validation loss: 2.6222663753998474

Epoch: 6| Step: 7
Training loss: 2.8912700861172524
Validation loss: 2.6029563736231602

Epoch: 6| Step: 8
Training loss: 1.7121607618477335
Validation loss: 2.622183363387697

Epoch: 6| Step: 9
Training loss: 2.619021373881501
Validation loss: 2.6299577776223546

Epoch: 6| Step: 10
Training loss: 2.129819901423592
Validation loss: 2.6470290858649053

Epoch: 6| Step: 11
Training loss: 2.359619330077107
Validation loss: 2.6197298066639045

Epoch: 6| Step: 12
Training loss: 1.9579905825496582
Validation loss: 2.656303450102738

Epoch: 6| Step: 13
Training loss: 1.995579125044037
Validation loss: 2.5536482599661716

Epoch: 101| Step: 0
Training loss: 2.384208595398752
Validation loss: 2.615459786639465

Epoch: 6| Step: 1
Training loss: 2.5277824669632603
Validation loss: 2.5955088752987256

Epoch: 6| Step: 2
Training loss: 1.7509587250294028
Validation loss: 2.5868611602154927

Epoch: 6| Step: 3
Training loss: 1.8501111229179656
Validation loss: 2.7080263232792894

Epoch: 6| Step: 4
Training loss: 1.2999140967817222
Validation loss: 2.545667006891153

Epoch: 6| Step: 5
Training loss: 2.0833257547876483
Validation loss: 2.636582283915481

Epoch: 6| Step: 6
Training loss: 2.047964257598953
Validation loss: 2.652350319436149

Epoch: 6| Step: 7
Training loss: 2.7659511050621415
Validation loss: 2.6757776413496424

Epoch: 6| Step: 8
Training loss: 2.432519176442851
Validation loss: 2.658504412018135

Epoch: 6| Step: 9
Training loss: 2.379286261212166
Validation loss: 2.6136469031612704

Epoch: 6| Step: 10
Training loss: 2.165365549814846
Validation loss: 2.6416038339244317

Epoch: 6| Step: 11
Training loss: 1.8884279710982803
Validation loss: 2.6078928166160433

Epoch: 6| Step: 12
Training loss: 2.742154721664627
Validation loss: 2.686578992007838

Epoch: 6| Step: 13
Training loss: 2.072942481207693
Validation loss: 2.5616584264274835

Epoch: 102| Step: 0
Training loss: 1.786124469785567
Validation loss: 2.6200837161494577

Epoch: 6| Step: 1
Training loss: 1.9553817528496684
Validation loss: 2.6739616945842744

Epoch: 6| Step: 2
Training loss: 1.8712564608679614
Validation loss: 2.6676032140343984

Epoch: 6| Step: 3
Training loss: 1.923875031649768
Validation loss: 2.6589742565527583

Epoch: 6| Step: 4
Training loss: 3.156556369528932
Validation loss: 2.6543650801997005

Epoch: 6| Step: 5
Training loss: 2.446692714015474
Validation loss: 2.6940411946508442

Epoch: 6| Step: 6
Training loss: 2.1662984926460904
Validation loss: 2.6546134320202674

Epoch: 6| Step: 7
Training loss: 2.136514880620663
Validation loss: 2.6816577841368803

Epoch: 6| Step: 8
Training loss: 2.1706355009036415
Validation loss: 2.6502040496576442

Epoch: 6| Step: 9
Training loss: 1.929425797110419
Validation loss: 2.61143634565237

Epoch: 6| Step: 10
Training loss: 2.8374080155709316
Validation loss: 2.6447634799252078

Epoch: 6| Step: 11
Training loss: 1.7394756200035313
Validation loss: 2.6544709624556497

Epoch: 6| Step: 12
Training loss: 2.5646894452113336
Validation loss: 2.5853264154814144

Epoch: 6| Step: 13
Training loss: 1.8590206161143845
Validation loss: 2.6421449940197115

Epoch: 103| Step: 0
Training loss: 2.4721483429098274
Validation loss: 2.6060604279607453

Epoch: 6| Step: 1
Training loss: 1.9571914455003117
Validation loss: 2.7063192997400334

Epoch: 6| Step: 2
Training loss: 1.9522609172588576
Validation loss: 2.6063313502751257

Epoch: 6| Step: 3
Training loss: 3.0808476059569014
Validation loss: 2.6461760882142045

Epoch: 6| Step: 4
Training loss: 1.9208393562978234
Validation loss: 2.5596524288119147

Epoch: 6| Step: 5
Training loss: 2.119694987973745
Validation loss: 2.679774810288015

Epoch: 6| Step: 6
Training loss: 2.3079031542288155
Validation loss: 2.671746754682375

Epoch: 6| Step: 7
Training loss: 1.5610824258023424
Validation loss: 2.6817402887126742

Epoch: 6| Step: 8
Training loss: 2.3306385782776684
Validation loss: 2.6942373444143533

Epoch: 6| Step: 9
Training loss: 2.957415980276618
Validation loss: 2.6149042294812497

Epoch: 6| Step: 10
Training loss: 2.0305988148286325
Validation loss: 2.5873601252148255

Epoch: 6| Step: 11
Training loss: 2.2115487375945624
Validation loss: 2.580582620647381

Epoch: 6| Step: 12
Training loss: 1.9550774542838822
Validation loss: 2.631252200019261

Epoch: 6| Step: 13
Training loss: 1.5841183305911657
Validation loss: 2.6929339542470485

Epoch: 104| Step: 0
Training loss: 2.339236886067113
Validation loss: 2.573450609678296

Epoch: 6| Step: 1
Training loss: 2.2985605296408558
Validation loss: 2.704220397329208

Epoch: 6| Step: 2
Training loss: 2.255188998403031
Validation loss: 2.5926421530341153

Epoch: 6| Step: 3
Training loss: 2.7242676442000167
Validation loss: 2.57405635493233

Epoch: 6| Step: 4
Training loss: 2.2674279766988414
Validation loss: 2.570923065049814

Epoch: 6| Step: 5
Training loss: 1.9276272667654493
Validation loss: 2.5561022559562563

Epoch: 6| Step: 6
Training loss: 1.6583604142679118
Validation loss: 2.6171574832846076

Epoch: 6| Step: 7
Training loss: 2.1811592848312715
Validation loss: 2.577531580591227

Epoch: 6| Step: 8
Training loss: 2.2227039834848594
Validation loss: 2.567143907600611

Epoch: 6| Step: 9
Training loss: 2.2865255312650574
Validation loss: 2.6261549180116175

Epoch: 6| Step: 10
Training loss: 2.938819751114555
Validation loss: 2.552201830130604

Epoch: 6| Step: 11
Training loss: 2.313124701173439
Validation loss: 2.5987928461405474

Epoch: 6| Step: 12
Training loss: 2.2700123367310434
Validation loss: 2.6041096312316987

Epoch: 6| Step: 13
Training loss: 1.676940161554723
Validation loss: 2.755777647526485

Epoch: 105| Step: 0
Training loss: 2.448217451946743
Validation loss: 2.647843593446511

Epoch: 6| Step: 1
Training loss: 2.0102775670554665
Validation loss: 2.6629512702923157

Epoch: 6| Step: 2
Training loss: 1.957495598136464
Validation loss: 2.763082035596113

Epoch: 6| Step: 3
Training loss: 1.9825865728806586
Validation loss: 2.7288351998197453

Epoch: 6| Step: 4
Training loss: 2.049403368959164
Validation loss: 2.823756305405533

Epoch: 6| Step: 5
Training loss: 2.5911740299907935
Validation loss: 2.7641396997114076

Epoch: 6| Step: 6
Training loss: 2.276268942605918
Validation loss: 2.784315341662839

Epoch: 6| Step: 7
Training loss: 2.5528529868556
Validation loss: 2.7152117509502594

Epoch: 6| Step: 8
Training loss: 1.8850280895214564
Validation loss: 2.6507271140998028

Epoch: 6| Step: 9
Training loss: 2.501154442314893
Validation loss: 2.571325147090412

Epoch: 6| Step: 10
Training loss: 2.535808085619794
Validation loss: 2.5313152257733638

Epoch: 6| Step: 11
Training loss: 1.7604628863465117
Validation loss: 2.560021931261257

Epoch: 6| Step: 12
Training loss: 1.979780991897565
Validation loss: 2.6211593778896214

Epoch: 6| Step: 13
Training loss: 2.3043873736983334
Validation loss: 2.6128138498151388

Epoch: 106| Step: 0
Training loss: 2.2022998969186776
Validation loss: 2.5958736259390807

Epoch: 6| Step: 1
Training loss: 1.6037172290667903
Validation loss: 2.690667230420137

Epoch: 6| Step: 2
Training loss: 2.310920175689901
Validation loss: 2.6169402503895434

Epoch: 6| Step: 3
Training loss: 2.178487577321073
Validation loss: 2.554003889446837

Epoch: 6| Step: 4
Training loss: 1.788890580491766
Validation loss: 2.632761365203384

Epoch: 6| Step: 5
Training loss: 3.227789176910576
Validation loss: 2.6318377795003602

Epoch: 6| Step: 6
Training loss: 2.1140614759805008
Validation loss: 2.5795226576055823

Epoch: 6| Step: 7
Training loss: 2.2027545373991337
Validation loss: 2.645868906898347

Epoch: 6| Step: 8
Training loss: 2.6696211025264778
Validation loss: 2.5848929609202935

Epoch: 6| Step: 9
Training loss: 2.098482164715698
Validation loss: 2.6118138350662314

Epoch: 6| Step: 10
Training loss: 1.8108179903792114
Validation loss: 2.615353722825

Epoch: 6| Step: 11
Training loss: 1.5908941974190465
Validation loss: 2.653825423752598

Epoch: 6| Step: 12
Training loss: 2.2749793208932565
Validation loss: 2.6299252398638537

Epoch: 6| Step: 13
Training loss: 2.3877916687165444
Validation loss: 2.7326330103818384

Epoch: 107| Step: 0
Training loss: 2.395343288116763
Validation loss: 2.684486962360476

Epoch: 6| Step: 1
Training loss: 2.67672574714012
Validation loss: 2.5302937275053266

Epoch: 6| Step: 2
Training loss: 1.8050535417049631
Validation loss: 2.578379562602968

Epoch: 6| Step: 3
Training loss: 1.9624297402798063
Validation loss: 2.624598260443325

Epoch: 6| Step: 4
Training loss: 2.0656087161993484
Validation loss: 2.5453209689729075

Epoch: 6| Step: 5
Training loss: 1.9522208600638673
Validation loss: 2.4846076776400583

Epoch: 6| Step: 6
Training loss: 1.8986694445420065
Validation loss: 2.5719221924244713

Epoch: 6| Step: 7
Training loss: 3.0241980569457216
Validation loss: 2.680302140726354

Epoch: 6| Step: 8
Training loss: 2.322686724265584
Validation loss: 2.614037648029841

Epoch: 6| Step: 9
Training loss: 2.3258206016586604
Validation loss: 2.524063638927194

Epoch: 6| Step: 10
Training loss: 2.4333227505736827
Validation loss: 2.595989731005679

Epoch: 6| Step: 11
Training loss: 2.0147686699157115
Validation loss: 2.6127664299376745

Epoch: 6| Step: 12
Training loss: 2.1329454094133196
Validation loss: 2.568751873006393

Epoch: 6| Step: 13
Training loss: 1.743718795770624
Validation loss: 2.572422108757699

Epoch: 108| Step: 0
Training loss: 1.862065460410662
Validation loss: 2.609091417812821

Epoch: 6| Step: 1
Training loss: 1.739005291624173
Validation loss: 2.7280222165153027

Epoch: 6| Step: 2
Training loss: 3.181471265731132
Validation loss: 2.8347415416490525

Epoch: 6| Step: 3
Training loss: 2.212979401628323
Validation loss: 2.764863047550862

Epoch: 6| Step: 4
Training loss: 1.8143443227941254
Validation loss: 2.7487822567450926

Epoch: 6| Step: 5
Training loss: 2.678810799211776
Validation loss: 2.7667706374276557

Epoch: 6| Step: 6
Training loss: 1.9050665762173657
Validation loss: 2.6841254820373703

Epoch: 6| Step: 7
Training loss: 2.391140651565706
Validation loss: 2.5913419307454566

Epoch: 6| Step: 8
Training loss: 1.5459137829653318
Validation loss: 2.6053807798039443

Epoch: 6| Step: 9
Training loss: 2.545068392630922
Validation loss: 2.569508621055866

Epoch: 6| Step: 10
Training loss: 1.9362739252197034
Validation loss: 2.6118466669149263

Epoch: 6| Step: 11
Training loss: 2.205751949644519
Validation loss: 2.6055187885868794

Epoch: 6| Step: 12
Training loss: 2.238478300731155
Validation loss: 2.514864836335104

Epoch: 6| Step: 13
Training loss: 2.7625030310428613
Validation loss: 2.593371459424079

Epoch: 109| Step: 0
Training loss: 1.727431963010009
Validation loss: 2.636150745388224

Epoch: 6| Step: 1
Training loss: 1.6574792438893315
Validation loss: 2.573116176350114

Epoch: 6| Step: 2
Training loss: 2.039903021732585
Validation loss: 2.570255715652155

Epoch: 6| Step: 3
Training loss: 1.9259734454399087
Validation loss: 2.6395980824512835

Epoch: 6| Step: 4
Training loss: 2.7131762316475223
Validation loss: 2.6164474731611955

Epoch: 6| Step: 5
Training loss: 2.1184090894253433
Validation loss: 2.718681670751635

Epoch: 6| Step: 6
Training loss: 2.438142740653982
Validation loss: 2.603986204888191

Epoch: 6| Step: 7
Training loss: 2.3154167133098125
Validation loss: 2.682121380088734

Epoch: 6| Step: 8
Training loss: 2.064831889331713
Validation loss: 2.655651788107344

Epoch: 6| Step: 9
Training loss: 1.6435815238914955
Validation loss: 2.584570332179337

Epoch: 6| Step: 10
Training loss: 1.6099787940530195
Validation loss: 2.6229514954193474

Epoch: 6| Step: 11
Training loss: 2.2497662316847507
Validation loss: 2.601347860010602

Epoch: 6| Step: 12
Training loss: 2.8588935154834876
Validation loss: 2.6271278597400864

Epoch: 6| Step: 13
Training loss: 2.5158679915883173
Validation loss: 2.5554292556632565

Epoch: 110| Step: 0
Training loss: 2.1558679435713146
Validation loss: 2.5979870731344423

Epoch: 6| Step: 1
Training loss: 2.0615566292552385
Validation loss: 2.5738255263652334

Epoch: 6| Step: 2
Training loss: 2.4748667979761274
Validation loss: 2.5578944679942026

Epoch: 6| Step: 3
Training loss: 2.535962651022844
Validation loss: 2.607628395769454

Epoch: 6| Step: 4
Training loss: 2.2694471018648663
Validation loss: 2.689572503629275

Epoch: 6| Step: 5
Training loss: 2.462641631570049
Validation loss: 2.539595672185233

Epoch: 6| Step: 6
Training loss: 1.7777822100398655
Validation loss: 2.715747285876363

Epoch: 6| Step: 7
Training loss: 1.8433152672271502
Validation loss: 2.642425134200385

Epoch: 6| Step: 8
Training loss: 2.4826078067662634
Validation loss: 2.575811453925561

Epoch: 6| Step: 9
Training loss: 1.6824579855447115
Validation loss: 2.6551682906325937

Epoch: 6| Step: 10
Training loss: 1.9347133901296651
Validation loss: 2.576582645717661

Epoch: 6| Step: 11
Training loss: 1.8220633407788156
Validation loss: 2.649000019961038

Epoch: 6| Step: 12
Training loss: 2.022259107656221
Validation loss: 2.5603165434424353

Epoch: 6| Step: 13
Training loss: 2.496692758720086
Validation loss: 2.5951002505372194

Epoch: 111| Step: 0
Training loss: 1.8896761948865726
Validation loss: 2.62494848594376

Epoch: 6| Step: 1
Training loss: 1.6416548630085137
Validation loss: 2.567694059774616

Epoch: 6| Step: 2
Training loss: 1.748758693234457
Validation loss: 2.5497865007819187

Epoch: 6| Step: 3
Training loss: 2.1463283103737565
Validation loss: 2.6244740640467383

Epoch: 6| Step: 4
Training loss: 2.0502231383418215
Validation loss: 2.6069150282046354

Epoch: 6| Step: 5
Training loss: 2.6011075375218398
Validation loss: 2.6313851823913432

Epoch: 6| Step: 6
Training loss: 2.104995589444213
Validation loss: 2.5783814582040447

Epoch: 6| Step: 7
Training loss: 2.343173757286458
Validation loss: 2.669583027268411

Epoch: 6| Step: 8
Training loss: 1.7177918971524482
Validation loss: 2.5785709496334

Epoch: 6| Step: 9
Training loss: 2.7008468642028767
Validation loss: 2.7110848657018614

Epoch: 6| Step: 10
Training loss: 2.7901211820967404
Validation loss: 2.71507800072734

Epoch: 6| Step: 11
Training loss: 2.2348110600430133
Validation loss: 2.7673168575035647

Epoch: 6| Step: 12
Training loss: 1.982188183770685
Validation loss: 2.7304656938745864

Epoch: 6| Step: 13
Training loss: 2.316455551060249
Validation loss: 2.6363518052199395

Epoch: 112| Step: 0
Training loss: 2.1605745155498925
Validation loss: 2.702002246221385

Epoch: 6| Step: 1
Training loss: 1.9969543274120352
Validation loss: 2.6638492935198346

Epoch: 6| Step: 2
Training loss: 1.8128346101424886
Validation loss: 2.6429760039663455

Epoch: 6| Step: 3
Training loss: 1.801922417955221
Validation loss: 2.6614256008894985

Epoch: 6| Step: 4
Training loss: 2.3122857484284363
Validation loss: 2.5852565579529316

Epoch: 6| Step: 5
Training loss: 1.877777077538675
Validation loss: 2.6584578818758144

Epoch: 6| Step: 6
Training loss: 2.012742102614481
Validation loss: 2.57261583111341

Epoch: 6| Step: 7
Training loss: 2.2809266161655706
Validation loss: 2.671879164188702

Epoch: 6| Step: 8
Training loss: 2.0780444595676824
Validation loss: 2.6432350997983494

Epoch: 6| Step: 9
Training loss: 2.4629876210702744
Validation loss: 2.6123537281222364

Epoch: 6| Step: 10
Training loss: 1.9984245651816728
Validation loss: 2.6135364174109106

Epoch: 6| Step: 11
Training loss: 1.9231065975247226
Validation loss: 2.601710547281409

Epoch: 6| Step: 12
Training loss: 2.2578763853756394
Validation loss: 2.6615960570133907

Epoch: 6| Step: 13
Training loss: 2.120311838823186
Validation loss: 2.5811241815058823

Epoch: 113| Step: 0
Training loss: 2.1487670645665884
Validation loss: 2.6091172020543634

Epoch: 6| Step: 1
Training loss: 1.8028202057116829
Validation loss: 2.60192535588687

Epoch: 6| Step: 2
Training loss: 2.4206822565400206
Validation loss: 2.665160488904989

Epoch: 6| Step: 3
Training loss: 2.5675403057675106
Validation loss: 2.6469240768788946

Epoch: 6| Step: 4
Training loss: 2.3236571587150197
Validation loss: 2.668978714504194

Epoch: 6| Step: 5
Training loss: 1.7876138610855574
Validation loss: 2.6808279741269434

Epoch: 6| Step: 6
Training loss: 2.0797271289102084
Validation loss: 2.707537869252878

Epoch: 6| Step: 7
Training loss: 1.9220191467315908
Validation loss: 2.6342679612514406

Epoch: 6| Step: 8
Training loss: 2.5655345162014096
Validation loss: 2.658868165061833

Epoch: 6| Step: 9
Training loss: 1.6274044148258082
Validation loss: 2.6141362637580103

Epoch: 6| Step: 10
Training loss: 2.428510767315342
Validation loss: 2.5755739942617843

Epoch: 6| Step: 11
Training loss: 1.6150601903133397
Validation loss: 2.6623450268460402

Epoch: 6| Step: 12
Training loss: 1.8735310204256215
Validation loss: 2.6305025647456692

Epoch: 6| Step: 13
Training loss: 1.6823502127869676
Validation loss: 2.553859720460696

Epoch: 114| Step: 0
Training loss: 1.6099182989584562
Validation loss: 2.696854567643757

Epoch: 6| Step: 1
Training loss: 2.3683675210602835
Validation loss: 2.6472820661046543

Epoch: 6| Step: 2
Training loss: 1.7997573953956945
Validation loss: 2.628242095140967

Epoch: 6| Step: 3
Training loss: 2.4782342412857985
Validation loss: 2.6649077445899505

Epoch: 6| Step: 4
Training loss: 1.893608639417214
Validation loss: 2.6446577949993757

Epoch: 6| Step: 5
Training loss: 2.66213033196309
Validation loss: 2.596935124319065

Epoch: 6| Step: 6
Training loss: 2.0381095676487098
Validation loss: 2.5906584365950907

Epoch: 6| Step: 7
Training loss: 2.7486597609962518
Validation loss: 2.623912616335008

Epoch: 6| Step: 8
Training loss: 1.8727125201565897
Validation loss: 2.636014958396615

Epoch: 6| Step: 9
Training loss: 1.8766570080948448
Validation loss: 2.6780883124801256

Epoch: 6| Step: 10
Training loss: 2.0405430588912377
Validation loss: 2.5843457166126678

Epoch: 6| Step: 11
Training loss: 2.0526474953367675
Validation loss: 2.6949032975058906

Epoch: 6| Step: 12
Training loss: 1.6269217644974237
Validation loss: 2.6872623027988696

Epoch: 6| Step: 13
Training loss: 1.8788289710507757
Validation loss: 2.5969639976727312

Epoch: 115| Step: 0
Training loss: 1.7508582326772884
Validation loss: 2.575375626459261

Epoch: 6| Step: 1
Training loss: 2.168718527969536
Validation loss: 2.6449394718640775

Epoch: 6| Step: 2
Training loss: 2.0928618411974385
Validation loss: 2.682687087063144

Epoch: 6| Step: 3
Training loss: 1.9745103639556223
Validation loss: 2.5460026501064688

Epoch: 6| Step: 4
Training loss: 1.7742753927309278
Validation loss: 2.6693082381938398

Epoch: 6| Step: 5
Training loss: 2.4090692427562233
Validation loss: 2.6198363910191826

Epoch: 6| Step: 6
Training loss: 2.0274011386988184
Validation loss: 2.65683919318494

Epoch: 6| Step: 7
Training loss: 1.8483142931031717
Validation loss: 2.5605843524532523

Epoch: 6| Step: 8
Training loss: 1.8360480092655205
Validation loss: 2.6491631608067636

Epoch: 6| Step: 9
Training loss: 2.1458156054113218
Validation loss: 2.6664231209007454

Epoch: 6| Step: 10
Training loss: 2.4064006015168107
Validation loss: 2.567029191296369

Epoch: 6| Step: 11
Training loss: 2.7249551751885956
Validation loss: 2.666835367310417

Epoch: 6| Step: 12
Training loss: 2.2462288724641253
Validation loss: 2.660953307090844

Epoch: 6| Step: 13
Training loss: 1.269526085476274
Validation loss: 2.5591923836008337

Epoch: 116| Step: 0
Training loss: 2.1508189925856587
Validation loss: 2.659811295350534

Epoch: 6| Step: 1
Training loss: 1.487162652750971
Validation loss: 2.595017586858564

Epoch: 6| Step: 2
Training loss: 1.5003501165593054
Validation loss: 2.606697078935559

Epoch: 6| Step: 3
Training loss: 2.274721183040086
Validation loss: 2.582129356840426

Epoch: 6| Step: 4
Training loss: 2.3197742184578183
Validation loss: 2.655565629946204

Epoch: 6| Step: 5
Training loss: 2.224204223285237
Validation loss: 2.629510395374533

Epoch: 6| Step: 6
Training loss: 2.265677194980668
Validation loss: 2.6097075199076007

Epoch: 6| Step: 7
Training loss: 2.6926248169766946
Validation loss: 2.6680777561451823

Epoch: 6| Step: 8
Training loss: 1.4963133329597336
Validation loss: 2.6533259285371416

Epoch: 6| Step: 9
Training loss: 2.4294639558161517
Validation loss: 2.681022333825443

Epoch: 6| Step: 10
Training loss: 2.1917432774061782
Validation loss: 2.579561122522829

Epoch: 6| Step: 11
Training loss: 2.405939255503321
Validation loss: 2.560791066056056

Epoch: 6| Step: 12
Training loss: 1.329222057746923
Validation loss: 2.560555674103517

Epoch: 6| Step: 13
Training loss: 1.776604467213331
Validation loss: 2.540708319504824

Epoch: 117| Step: 0
Training loss: 1.5648677433667473
Validation loss: 2.6135827514492425

Epoch: 6| Step: 1
Training loss: 2.0748232662816637
Validation loss: 2.5471585823807232

Epoch: 6| Step: 2
Training loss: 2.4813676782178806
Validation loss: 2.7665253087971724

Epoch: 6| Step: 3
Training loss: 2.4396411588109936
Validation loss: 2.6803712111637856

Epoch: 6| Step: 4
Training loss: 2.20053413582718
Validation loss: 2.6138840052925816

Epoch: 6| Step: 5
Training loss: 2.533284817615873
Validation loss: 2.6540585771845566

Epoch: 6| Step: 6
Training loss: 2.0063890688222714
Validation loss: 2.67265695056908

Epoch: 6| Step: 7
Training loss: 2.9336519400645225
Validation loss: 2.622482076146659

Epoch: 6| Step: 8
Training loss: 2.1275825514954136
Validation loss: 2.6388203400079746

Epoch: 6| Step: 9
Training loss: 1.9142791002683923
Validation loss: 2.5365189865557713

Epoch: 6| Step: 10
Training loss: 2.2806781417831563
Validation loss: 2.560063840075049

Epoch: 6| Step: 11
Training loss: 1.5022433512720368
Validation loss: 2.6669946160917095

Epoch: 6| Step: 12
Training loss: 1.6961888452242957
Validation loss: 2.6062936768504508

Epoch: 6| Step: 13
Training loss: 1.7971053266104469
Validation loss: 2.627002784609423

Epoch: 118| Step: 0
Training loss: 2.345703328281111
Validation loss: 2.6332714612750165

Epoch: 6| Step: 1
Training loss: 1.7345125985764305
Validation loss: 2.623365468559897

Epoch: 6| Step: 2
Training loss: 1.5360087194840975
Validation loss: 2.568147839633179

Epoch: 6| Step: 3
Training loss: 1.864355517345378
Validation loss: 2.683126395007681

Epoch: 6| Step: 4
Training loss: 2.1300001221419467
Validation loss: 2.7352903886532767

Epoch: 6| Step: 5
Training loss: 2.170441737765871
Validation loss: 2.65878689363556

Epoch: 6| Step: 6
Training loss: 1.6211518426620477
Validation loss: 2.62255230575392

Epoch: 6| Step: 7
Training loss: 2.2811998335665518
Validation loss: 2.7046092814876297

Epoch: 6| Step: 8
Training loss: 2.0274580553939545
Validation loss: 2.773253578929036

Epoch: 6| Step: 9
Training loss: 2.186121479006068
Validation loss: 2.7185421714418774

Epoch: 6| Step: 10
Training loss: 1.925891122527301
Validation loss: 2.737825581598047

Epoch: 6| Step: 11
Training loss: 3.1215297504249557
Validation loss: 2.677843577177572

Epoch: 6| Step: 12
Training loss: 1.5648231783051278
Validation loss: 2.5765473904541607

Epoch: 6| Step: 13
Training loss: 2.0010997609554346
Validation loss: 2.54867059798174

Epoch: 119| Step: 0
Training loss: 1.8311270819022047
Validation loss: 2.652761524765351

Epoch: 6| Step: 1
Training loss: 2.09203427745826
Validation loss: 2.6222711638913925

Epoch: 6| Step: 2
Training loss: 1.4209324993232637
Validation loss: 2.609022607821632

Epoch: 6| Step: 3
Training loss: 2.2970145046920414
Validation loss: 2.5818630823571214

Epoch: 6| Step: 4
Training loss: 1.6136287287288478
Validation loss: 2.633133911074272

Epoch: 6| Step: 5
Training loss: 2.3837651584025257
Validation loss: 2.5867436315533623

Epoch: 6| Step: 6
Training loss: 2.2317040758746196
Validation loss: 2.555596566101552

Epoch: 6| Step: 7
Training loss: 1.852322708068289
Validation loss: 2.632874168330303

Epoch: 6| Step: 8
Training loss: 2.1581220378573693
Validation loss: 2.567467580861147

Epoch: 6| Step: 9
Training loss: 2.7526372055241124
Validation loss: 2.6981873812167696

Epoch: 6| Step: 10
Training loss: 2.3170259878572277
Validation loss: 2.547379862978945

Epoch: 6| Step: 11
Training loss: 1.9882522910656626
Validation loss: 2.697716007110297

Epoch: 6| Step: 12
Training loss: 2.247493301228861
Validation loss: 2.5173875308934126

Epoch: 6| Step: 13
Training loss: 1.8016392449130971
Validation loss: 2.609603156129662

Epoch: 120| Step: 0
Training loss: 2.0945550310377747
Validation loss: 2.56630653563104

Epoch: 6| Step: 1
Training loss: 1.960765815909403
Validation loss: 2.617201164551548

Epoch: 6| Step: 2
Training loss: 1.8460924171962763
Validation loss: 2.676320027779364

Epoch: 6| Step: 3
Training loss: 1.9683244638891864
Validation loss: 2.6091478443065865

Epoch: 6| Step: 4
Training loss: 1.8669977450814343
Validation loss: 2.5517133379687227

Epoch: 6| Step: 5
Training loss: 2.2565873461841117
Validation loss: 2.680006669947167

Epoch: 6| Step: 6
Training loss: 2.6090814116918035
Validation loss: 2.621835155585931

Epoch: 6| Step: 7
Training loss: 1.8836892014015494
Validation loss: 2.6415134718445095

Epoch: 6| Step: 8
Training loss: 2.7022866067968137
Validation loss: 2.6102486250104406

Epoch: 6| Step: 9
Training loss: 2.295519162632537
Validation loss: 2.5980275742005032

Epoch: 6| Step: 10
Training loss: 1.5818485860981828
Validation loss: 2.639271345922282

Epoch: 6| Step: 11
Training loss: 1.6570661441306953
Validation loss: 2.681997550962289

Epoch: 6| Step: 12
Training loss: 2.0343493950751617
Validation loss: 2.7469143606815294

Epoch: 6| Step: 13
Training loss: 1.9347462927909338
Validation loss: 2.7890113519560877

Epoch: 121| Step: 0
Training loss: 2.127295880684455
Validation loss: 2.809636714231511

Epoch: 6| Step: 1
Training loss: 1.5509396719547446
Validation loss: 2.809711189791012

Epoch: 6| Step: 2
Training loss: 2.2261520275081974
Validation loss: 2.739015488947415

Epoch: 6| Step: 3
Training loss: 2.26441639200358
Validation loss: 2.774782569202623

Epoch: 6| Step: 4
Training loss: 2.089700797352299
Validation loss: 2.7051264312140093

Epoch: 6| Step: 5
Training loss: 2.1470624372680893
Validation loss: 2.7048934047165725

Epoch: 6| Step: 6
Training loss: 2.0417738386817468
Validation loss: 2.642225544131306

Epoch: 6| Step: 7
Training loss: 2.0638208494727106
Validation loss: 2.695291653612394

Epoch: 6| Step: 8
Training loss: 2.0420335193539403
Validation loss: 2.59747110342793

Epoch: 6| Step: 9
Training loss: 2.615522623736197
Validation loss: 2.535712441207706

Epoch: 6| Step: 10
Training loss: 1.6771823387855536
Validation loss: 2.5827721068171234

Epoch: 6| Step: 11
Training loss: 1.6350517432748222
Validation loss: 2.5874793612383447

Epoch: 6| Step: 12
Training loss: 1.9275321506535186
Validation loss: 2.6412958350163556

Epoch: 6| Step: 13
Training loss: 2.427134260917599
Validation loss: 2.6729306669356685

Epoch: 122| Step: 0
Training loss: 1.5836339297135067
Validation loss: 2.635772866966495

Epoch: 6| Step: 1
Training loss: 1.6419916183127656
Validation loss: 2.6251011026682267

Epoch: 6| Step: 2
Training loss: 1.7897077837634354
Validation loss: 2.573797026432011

Epoch: 6| Step: 3
Training loss: 1.9856307494380756
Validation loss: 2.6301435607387713

Epoch: 6| Step: 4
Training loss: 2.3001834630357307
Validation loss: 2.6544222358852214

Epoch: 6| Step: 5
Training loss: 2.1777733495671585
Validation loss: 2.5993199119224633

Epoch: 6| Step: 6
Training loss: 3.0091419799208987
Validation loss: 2.63227964115956

Epoch: 6| Step: 7
Training loss: 1.3547287825791736
Validation loss: 2.610078088754153

Epoch: 6| Step: 8
Training loss: 1.9240370583722513
Validation loss: 2.70076744451977

Epoch: 6| Step: 9
Training loss: 2.0636431675967977
Validation loss: 2.7118117125752383

Epoch: 6| Step: 10
Training loss: 2.6109162307503015
Validation loss: 2.770692396284344

Epoch: 6| Step: 11
Training loss: 1.6342695388174473
Validation loss: 2.7584241525579123

Epoch: 6| Step: 12
Training loss: 1.7839226999599431
Validation loss: 2.7508736869797437

Epoch: 6| Step: 13
Training loss: 1.7366669777975456
Validation loss: 2.6121059449077646

Epoch: 123| Step: 0
Training loss: 1.9556938672763795
Validation loss: 2.6378461824515798

Epoch: 6| Step: 1
Training loss: 1.9593286487505606
Validation loss: 2.6102333408371283

Epoch: 6| Step: 2
Training loss: 2.334643359506729
Validation loss: 2.6480293672129838

Epoch: 6| Step: 3
Training loss: 1.8692825247575315
Validation loss: 2.6073317456235308

Epoch: 6| Step: 4
Training loss: 1.8082747703362976
Validation loss: 2.594946053127339

Epoch: 6| Step: 5
Training loss: 1.6342663293016568
Validation loss: 2.65455169240544

Epoch: 6| Step: 6
Training loss: 1.5776543245835564
Validation loss: 2.6219499367396866

Epoch: 6| Step: 7
Training loss: 1.7915747715057142
Validation loss: 2.6128542883444057

Epoch: 6| Step: 8
Training loss: 1.7886958516986708
Validation loss: 2.5918574801624725

Epoch: 6| Step: 9
Training loss: 1.853426739216531
Validation loss: 2.6509761889652372

Epoch: 6| Step: 10
Training loss: 2.523348874640971
Validation loss: 2.522030842821625

Epoch: 6| Step: 11
Training loss: 2.7308908990266296
Validation loss: 2.5576648219779017

Epoch: 6| Step: 12
Training loss: 2.0001857194501915
Validation loss: 2.593816840601293

Epoch: 6| Step: 13
Training loss: 2.2304871352952866
Validation loss: 2.659967760306572

Epoch: 124| Step: 0
Training loss: 2.2524134090262233
Validation loss: 2.6005746304243176

Epoch: 6| Step: 1
Training loss: 2.4867131968108747
Validation loss: 2.6878510179388684

Epoch: 6| Step: 2
Training loss: 2.259992873256553
Validation loss: 2.612996571026282

Epoch: 6| Step: 3
Training loss: 2.23955974714294
Validation loss: 2.675565271873018

Epoch: 6| Step: 4
Training loss: 1.6613509602864258
Validation loss: 2.6040041504058733

Epoch: 6| Step: 5
Training loss: 1.890773168385327
Validation loss: 2.628310553146204

Epoch: 6| Step: 6
Training loss: 1.4535489848162586
Validation loss: 2.596538745029093

Epoch: 6| Step: 7
Training loss: 1.7488365392970322
Validation loss: 2.678712391247403

Epoch: 6| Step: 8
Training loss: 2.2197006767834577
Validation loss: 2.51189473011766

Epoch: 6| Step: 9
Training loss: 1.3202046457513748
Validation loss: 2.5684329874491265

Epoch: 6| Step: 10
Training loss: 1.8674376252365619
Validation loss: 2.5338941272330264

Epoch: 6| Step: 11
Training loss: 2.0278145715635607
Validation loss: 2.5742653826598216

Epoch: 6| Step: 12
Training loss: 1.6211583871479347
Validation loss: 2.5710677763899006

Epoch: 6| Step: 13
Training loss: 2.3615631668071706
Validation loss: 2.5651889896729756

Epoch: 125| Step: 0
Training loss: 2.018527521209913
Validation loss: 2.576790335078009

Epoch: 6| Step: 1
Training loss: 1.823950084040919
Validation loss: 2.6342812053474165

Epoch: 6| Step: 2
Training loss: 2.572380185020126
Validation loss: 2.660934177649726

Epoch: 6| Step: 3
Training loss: 2.304538321112088
Validation loss: 2.527851051856841

Epoch: 6| Step: 4
Training loss: 1.6984380221958288
Validation loss: 2.654751613082992

Epoch: 6| Step: 5
Training loss: 2.079100645109004
Validation loss: 2.5956725842793933

Epoch: 6| Step: 6
Training loss: 1.9437186824324058
Validation loss: 2.710207119777057

Epoch: 6| Step: 7
Training loss: 2.1637840780464836
Validation loss: 2.6790771234082746

Epoch: 6| Step: 8
Training loss: 1.6363072572253103
Validation loss: 2.666064124778248

Epoch: 6| Step: 9
Training loss: 1.3012114492197047
Validation loss: 2.5823499335737017

Epoch: 6| Step: 10
Training loss: 1.9804503310210426
Validation loss: 2.6947851429906877

Epoch: 6| Step: 11
Training loss: 2.0995939316292507
Validation loss: 2.6307860215308763

Epoch: 6| Step: 12
Training loss: 2.384696640778965
Validation loss: 2.631027295616589

Epoch: 6| Step: 13
Training loss: 2.0588608049175834
Validation loss: 2.642355177130924

Epoch: 126| Step: 0
Training loss: 1.5637401237145419
Validation loss: 2.5645631067845494

Epoch: 6| Step: 1
Training loss: 2.3596353955604434
Validation loss: 2.644815374275395

Epoch: 6| Step: 2
Training loss: 1.7550087503068366
Validation loss: 2.6198173860433878

Epoch: 6| Step: 3
Training loss: 1.810374427656776
Validation loss: 2.6263518258589706

Epoch: 6| Step: 4
Training loss: 1.7884215160337484
Validation loss: 2.5657070529345054

Epoch: 6| Step: 5
Training loss: 1.9357148221748666
Validation loss: 2.6406440057014127

Epoch: 6| Step: 6
Training loss: 2.0433890674368427
Validation loss: 2.6111598430193848

Epoch: 6| Step: 7
Training loss: 2.2321080799118387
Validation loss: 2.673435201816697

Epoch: 6| Step: 8
Training loss: 2.0725302280112845
Validation loss: 2.632409718659909

Epoch: 6| Step: 9
Training loss: 1.9933584923044232
Validation loss: 2.631036078001869

Epoch: 6| Step: 10
Training loss: 1.3727602924134064
Validation loss: 2.65630611285611

Epoch: 6| Step: 11
Training loss: 2.0469696954851626
Validation loss: 2.629621343296151

Epoch: 6| Step: 12
Training loss: 2.840526052835273
Validation loss: 2.8395244378642976

Epoch: 6| Step: 13
Training loss: 2.3399348424333306
Validation loss: 2.8573605610580715

Epoch: 127| Step: 0
Training loss: 2.00439792126312
Validation loss: 2.871421314332906

Epoch: 6| Step: 1
Training loss: 2.011355350596834
Validation loss: 2.751549529854314

Epoch: 6| Step: 2
Training loss: 2.4997161704115904
Validation loss: 2.7106449874505745

Epoch: 6| Step: 3
Training loss: 2.0685975079070453
Validation loss: 2.5650367121210187

Epoch: 6| Step: 4
Training loss: 1.867286966778939
Validation loss: 2.606172450411362

Epoch: 6| Step: 5
Training loss: 1.4442564534258897
Validation loss: 2.6419546026554794

Epoch: 6| Step: 6
Training loss: 2.2598004416748503
Validation loss: 2.5694305545557468

Epoch: 6| Step: 7
Training loss: 2.329432587522028
Validation loss: 2.6840617638449

Epoch: 6| Step: 8
Training loss: 2.66557559898904
Validation loss: 2.6259421368422227

Epoch: 6| Step: 9
Training loss: 1.6585176886189408
Validation loss: 2.5661717602397074

Epoch: 6| Step: 10
Training loss: 1.5047053604412801
Validation loss: 2.668338584307004

Epoch: 6| Step: 11
Training loss: 2.1042284311224955
Validation loss: 2.6855704751567195

Epoch: 6| Step: 12
Training loss: 1.8262696591885081
Validation loss: 2.6815436693683306

Epoch: 6| Step: 13
Training loss: 1.6454735455213554
Validation loss: 2.66554059651156

Epoch: 128| Step: 0
Training loss: 2.0680953911892233
Validation loss: 2.7371607513636356

Epoch: 6| Step: 1
Training loss: 1.9393238589262018
Validation loss: 2.6802758700691403

Epoch: 6| Step: 2
Training loss: 2.107857278245005
Validation loss: 2.5923721912972812

Epoch: 6| Step: 3
Training loss: 1.243718050062329
Validation loss: 2.581035751059696

Epoch: 6| Step: 4
Training loss: 2.6759623890843813
Validation loss: 2.691030814787422

Epoch: 6| Step: 5
Training loss: 2.026239995066883
Validation loss: 2.6853549440174738

Epoch: 6| Step: 6
Training loss: 1.2009148547588344
Validation loss: 2.598651712457106

Epoch: 6| Step: 7
Training loss: 1.8676194206161092
Validation loss: 2.6387915933530324

Epoch: 6| Step: 8
Training loss: 2.4039416449727065
Validation loss: 2.5606683682372577

Epoch: 6| Step: 9
Training loss: 2.27171559358311
Validation loss: 2.67399663141096

Epoch: 6| Step: 10
Training loss: 1.9612870227827655
Validation loss: 2.66294176499221

Epoch: 6| Step: 11
Training loss: 1.7116423248125174
Validation loss: 2.5473977081056907

Epoch: 6| Step: 12
Training loss: 2.0452105328442904
Validation loss: 2.7142570904606376

Epoch: 6| Step: 13
Training loss: 2.163409523623934
Validation loss: 2.7268029064155517

Epoch: 129| Step: 0
Training loss: 2.891581938837077
Validation loss: 2.7375354485851195

Epoch: 6| Step: 1
Training loss: 1.8913251352859723
Validation loss: 2.7712611009246104

Epoch: 6| Step: 2
Training loss: 1.7858281780434926
Validation loss: 2.7406259203988665

Epoch: 6| Step: 3
Training loss: 1.1822720944749332
Validation loss: 2.7759422775903664

Epoch: 6| Step: 4
Training loss: 2.1826414375750156
Validation loss: 2.7085064808199513

Epoch: 6| Step: 5
Training loss: 2.4252361969114116
Validation loss: 2.6990182068775903

Epoch: 6| Step: 6
Training loss: 2.2950004142145852
Validation loss: 2.682790711036141

Epoch: 6| Step: 7
Training loss: 2.018742715450407
Validation loss: 2.700796370150852

Epoch: 6| Step: 8
Training loss: 1.896108823888436
Validation loss: 2.581677234136315

Epoch: 6| Step: 9
Training loss: 2.096370708013318
Validation loss: 2.628235261337614

Epoch: 6| Step: 10
Training loss: 2.085632530521176
Validation loss: 2.683544041868709

Epoch: 6| Step: 11
Training loss: 1.7608178112442927
Validation loss: 2.59721542862963

Epoch: 6| Step: 12
Training loss: 1.9128559903200684
Validation loss: 2.704343914185099

Epoch: 6| Step: 13
Training loss: 1.8595121317070502
Validation loss: 2.506203187551296

Epoch: 130| Step: 0
Training loss: 1.8894056691599632
Validation loss: 2.752382792241859

Epoch: 6| Step: 1
Training loss: 1.515439759565261
Validation loss: 2.6189853699003502

Epoch: 6| Step: 2
Training loss: 1.987448047462757
Validation loss: 2.665517236425241

Epoch: 6| Step: 3
Training loss: 1.8534777429405647
Validation loss: 2.6665598480367594

Epoch: 6| Step: 4
Training loss: 1.632346638928626
Validation loss: 2.655254312034606

Epoch: 6| Step: 5
Training loss: 2.0774176978599743
Validation loss: 2.758990186713698

Epoch: 6| Step: 6
Training loss: 1.4365752189426684
Validation loss: 2.8006977545912064

Epoch: 6| Step: 7
Training loss: 1.8873012109625953
Validation loss: 2.7177556729875536

Epoch: 6| Step: 8
Training loss: 2.227446370619139
Validation loss: 2.7776785361257903

Epoch: 6| Step: 9
Training loss: 1.9341508775576384
Validation loss: 2.789409227661951

Epoch: 6| Step: 10
Training loss: 2.621882085597361
Validation loss: 2.7670907053719764

Epoch: 6| Step: 11
Training loss: 2.4165890999107846
Validation loss: 2.7443564478305706

Epoch: 6| Step: 12
Training loss: 1.8310796873293356
Validation loss: 2.6878629779396324

Epoch: 6| Step: 13
Training loss: 1.878653019516874
Validation loss: 2.6147802109070106

Epoch: 131| Step: 0
Training loss: 1.712619877538558
Validation loss: 2.4729309250876628

Epoch: 6| Step: 1
Training loss: 1.7985008513613254
Validation loss: 2.6876696082126714

Epoch: 6| Step: 2
Training loss: 2.1806579398425017
Validation loss: 2.7122132069145595

Epoch: 6| Step: 3
Training loss: 1.9694196984954786
Validation loss: 2.712430881609924

Epoch: 6| Step: 4
Training loss: 1.7332700354071373
Validation loss: 2.7446520707730135

Epoch: 6| Step: 5
Training loss: 2.4103116521706482
Validation loss: 2.690892362879442

Epoch: 6| Step: 6
Training loss: 1.9516147725638637
Validation loss: 2.6671850525141405

Epoch: 6| Step: 7
Training loss: 2.785086824854615
Validation loss: 2.6322932726532224

Epoch: 6| Step: 8
Training loss: 1.7868625491263213
Validation loss: 2.6008696831637397

Epoch: 6| Step: 9
Training loss: 1.9631445876986986
Validation loss: 2.6302222273557194

Epoch: 6| Step: 10
Training loss: 2.2283427299276664
Validation loss: 2.673209468733949

Epoch: 6| Step: 11
Training loss: 2.141457054874343
Validation loss: 2.73297147788267

Epoch: 6| Step: 12
Training loss: 2.303481999010017
Validation loss: 2.7724835828335768

Epoch: 6| Step: 13
Training loss: 2.0066808933036784
Validation loss: 2.719498016233259

Epoch: 132| Step: 0
Training loss: 2.4727765817876675
Validation loss: 2.721558067069081

Epoch: 6| Step: 1
Training loss: 2.1098973510505705
Validation loss: 2.6672488461221793

Epoch: 6| Step: 2
Training loss: 1.7424931963619472
Validation loss: 2.572326613089158

Epoch: 6| Step: 3
Training loss: 1.6097505742318043
Validation loss: 2.5704810059261254

Epoch: 6| Step: 4
Training loss: 1.6920229732315573
Validation loss: 2.5638895221689677

Epoch: 6| Step: 5
Training loss: 1.5936382478915414
Validation loss: 2.596155713199332

Epoch: 6| Step: 6
Training loss: 1.7641560343027198
Validation loss: 2.6005037461635054

Epoch: 6| Step: 7
Training loss: 1.816320601874387
Validation loss: 2.6292977875197088

Epoch: 6| Step: 8
Training loss: 2.2554792868378315
Validation loss: 2.638834690630525

Epoch: 6| Step: 9
Training loss: 2.654223128775703
Validation loss: 2.6296696832105804

Epoch: 6| Step: 10
Training loss: 1.6888888965921791
Validation loss: 2.628055913004255

Epoch: 6| Step: 11
Training loss: 1.6428504745276984
Validation loss: 2.635531115151456

Epoch: 6| Step: 12
Training loss: 2.6156932607697017
Validation loss: 2.697362162828021

Epoch: 6| Step: 13
Training loss: 1.6897064195508167
Validation loss: 2.6664406760141506

Epoch: 133| Step: 0
Training loss: 1.4747529421005998
Validation loss: 2.636765422643443

Epoch: 6| Step: 1
Training loss: 2.1558415122725507
Validation loss: 2.624531794981353

Epoch: 6| Step: 2
Training loss: 1.38423669610736
Validation loss: 2.679236267475144

Epoch: 6| Step: 3
Training loss: 2.3147285651633758
Validation loss: 2.7381830492609454

Epoch: 6| Step: 4
Training loss: 2.2005385779995223
Validation loss: 2.67226781801787

Epoch: 6| Step: 5
Training loss: 1.6200982035788762
Validation loss: 2.664950091483337

Epoch: 6| Step: 6
Training loss: 1.8174013098954553
Validation loss: 2.6268869006425644

Epoch: 6| Step: 7
Training loss: 2.4592040723564663
Validation loss: 2.624047409268023

Epoch: 6| Step: 8
Training loss: 1.9983673584464392
Validation loss: 2.608468711151092

Epoch: 6| Step: 9
Training loss: 1.8388933776513845
Validation loss: 2.549315315153313

Epoch: 6| Step: 10
Training loss: 2.5387653822552596
Validation loss: 2.619581579401242

Epoch: 6| Step: 11
Training loss: 1.9979369132322424
Validation loss: 2.644308181287557

Epoch: 6| Step: 12
Training loss: 1.364205689141066
Validation loss: 2.6053945520331694

Epoch: 6| Step: 13
Training loss: 1.7784676488165205
Validation loss: 2.5980020928632626

Epoch: 134| Step: 0
Training loss: 1.5650546742599287
Validation loss: 2.5282217443413635

Epoch: 6| Step: 1
Training loss: 1.6013544459230946
Validation loss: 2.5323907691292242

Epoch: 6| Step: 2
Training loss: 1.7463325490807184
Validation loss: 2.659213189754452

Epoch: 6| Step: 3
Training loss: 2.321652523179343
Validation loss: 2.6595946254507434

Epoch: 6| Step: 4
Training loss: 1.6979931149112863
Validation loss: 2.6363282769322263

Epoch: 6| Step: 5
Training loss: 1.7680464487706131
Validation loss: 2.723029119790938

Epoch: 6| Step: 6
Training loss: 2.105370797053269
Validation loss: 2.647601855692828

Epoch: 6| Step: 7
Training loss: 2.102341518167015
Validation loss: 2.6779810566686804

Epoch: 6| Step: 8
Training loss: 2.954822193870165
Validation loss: 2.6626083492267445

Epoch: 6| Step: 9
Training loss: 1.8438437486510881
Validation loss: 2.685705916810548

Epoch: 6| Step: 10
Training loss: 1.5773497839741881
Validation loss: 2.574066173023973

Epoch: 6| Step: 11
Training loss: 1.88788526026356
Validation loss: 2.590711928543875

Epoch: 6| Step: 12
Training loss: 1.9431246668489255
Validation loss: 2.542418045753604

Epoch: 6| Step: 13
Training loss: 1.6147125028398686
Validation loss: 2.5452362904654184

Epoch: 135| Step: 0
Training loss: 2.0799942214592115
Validation loss: 2.58177132195109

Epoch: 6| Step: 1
Training loss: 1.705257445668809
Validation loss: 2.6099940420377505

Epoch: 6| Step: 2
Training loss: 1.9042084815221978
Validation loss: 2.6138711747197494

Epoch: 6| Step: 3
Training loss: 1.9165379923322303
Validation loss: 2.668603407372182

Epoch: 6| Step: 4
Training loss: 2.2987622662414564
Validation loss: 2.6675230280398488

Epoch: 6| Step: 5
Training loss: 1.5394991337624144
Validation loss: 2.6863743694349

Epoch: 6| Step: 6
Training loss: 1.5018438292025715
Validation loss: 2.5625400074882787

Epoch: 6| Step: 7
Training loss: 2.1399325622200362
Validation loss: 2.661309297174868

Epoch: 6| Step: 8
Training loss: 2.007895620087606
Validation loss: 2.5687132926353926

Epoch: 6| Step: 9
Training loss: 2.2054220358819667
Validation loss: 2.5990239646641426

Epoch: 6| Step: 10
Training loss: 1.4418918029573324
Validation loss: 2.6489310915845388

Epoch: 6| Step: 11
Training loss: 1.861270035020381
Validation loss: 2.6612585307531487

Epoch: 6| Step: 12
Training loss: 1.8544007771458284
Validation loss: 2.58999445396674

Epoch: 6| Step: 13
Training loss: 1.9465851814490638
Validation loss: 2.5774596001030097

Epoch: 136| Step: 0
Training loss: 1.4617211183317766
Validation loss: 2.6102535268877083

Epoch: 6| Step: 1
Training loss: 2.300670886671554
Validation loss: 2.6550065514770442

Epoch: 6| Step: 2
Training loss: 1.4459689737212473
Validation loss: 2.7046045653146913

Epoch: 6| Step: 3
Training loss: 1.8463379106402311
Validation loss: 2.5679614939798436

Epoch: 6| Step: 4
Training loss: 1.824784577079328
Validation loss: 2.6465740568724185

Epoch: 6| Step: 5
Training loss: 1.8191975465682504
Validation loss: 2.715153928459618

Epoch: 6| Step: 6
Training loss: 1.6799309132766647
Validation loss: 2.7064272677866654

Epoch: 6| Step: 7
Training loss: 2.217904480489729
Validation loss: 2.7059791212063526

Epoch: 6| Step: 8
Training loss: 1.9569760617452368
Validation loss: 2.627921507128162

Epoch: 6| Step: 9
Training loss: 1.9974400110510961
Validation loss: 2.6774757533039657

Epoch: 6| Step: 10
Training loss: 1.839992120352749
Validation loss: 2.627118844970312

Epoch: 6| Step: 11
Training loss: 1.5780752948449421
Validation loss: 2.6839450567366643

Epoch: 6| Step: 12
Training loss: 1.7537224552223685
Validation loss: 2.633715375718844

Epoch: 6| Step: 13
Training loss: 2.2270440902559265
Validation loss: 2.565399638293911

Epoch: 137| Step: 0
Training loss: 1.7106854675555176
Validation loss: 2.6732249576959752

Epoch: 6| Step: 1
Training loss: 1.6149525702158039
Validation loss: 2.5168118253953895

Epoch: 6| Step: 2
Training loss: 1.2659551872650667
Validation loss: 2.6002829290773963

Epoch: 6| Step: 3
Training loss: 1.9628986415414658
Validation loss: 2.7084109124052036

Epoch: 6| Step: 4
Training loss: 2.0885720064491546
Validation loss: 2.6490861816595737

Epoch: 6| Step: 5
Training loss: 2.0431171895762117
Validation loss: 2.5927265170174802

Epoch: 6| Step: 6
Training loss: 1.2449469954915982
Validation loss: 2.6986326988256817

Epoch: 6| Step: 7
Training loss: 1.885674987575457
Validation loss: 2.6977145415090873

Epoch: 6| Step: 8
Training loss: 1.728414379538373
Validation loss: 2.663035682434387

Epoch: 6| Step: 9
Training loss: 2.319081194891843
Validation loss: 2.6626346225761943

Epoch: 6| Step: 10
Training loss: 2.521105748949793
Validation loss: 2.748672352715174

Epoch: 6| Step: 11
Training loss: 1.7508038309556944
Validation loss: 2.607228353607723

Epoch: 6| Step: 12
Training loss: 1.9514875948895531
Validation loss: 2.60066435224516

Epoch: 6| Step: 13
Training loss: 1.9807647544063842
Validation loss: 2.594566844714017

Epoch: 138| Step: 0
Training loss: 2.300299550328225
Validation loss: 2.631954064487221

Epoch: 6| Step: 1
Training loss: 1.9007557344742751
Validation loss: 2.543468654735631

Epoch: 6| Step: 2
Training loss: 1.7614711409843278
Validation loss: 2.6570025107386583

Epoch: 6| Step: 3
Training loss: 1.5157470653970488
Validation loss: 2.633883370726695

Epoch: 6| Step: 4
Training loss: 2.028152216418646
Validation loss: 2.5745634350859437

Epoch: 6| Step: 5
Training loss: 2.229443423004808
Validation loss: 2.6251830385364556

Epoch: 6| Step: 6
Training loss: 1.7448977613693692
Validation loss: 2.682929551406193

Epoch: 6| Step: 7
Training loss: 1.5270410418237967
Validation loss: 2.7055995544191096

Epoch: 6| Step: 8
Training loss: 2.1425162543767446
Validation loss: 2.6321339775246724

Epoch: 6| Step: 9
Training loss: 1.6154364352246178
Validation loss: 2.570206613881491

Epoch: 6| Step: 10
Training loss: 2.1629347083139607
Validation loss: 2.683668332680731

Epoch: 6| Step: 11
Training loss: 1.7042855324674848
Validation loss: 2.5843543578080377

Epoch: 6| Step: 12
Training loss: 1.5450703275902062
Validation loss: 2.484461992768034

Epoch: 6| Step: 13
Training loss: 1.8593864120004966
Validation loss: 2.618230522665858

Epoch: 139| Step: 0
Training loss: 1.4299604645178932
Validation loss: 2.6528378280668994

Epoch: 6| Step: 1
Training loss: 2.610523633498124
Validation loss: 2.588754232008057

Epoch: 6| Step: 2
Training loss: 1.8943604067822737
Validation loss: 2.570475935450282

Epoch: 6| Step: 3
Training loss: 1.6863453058070523
Validation loss: 2.6311947977613666

Epoch: 6| Step: 4
Training loss: 2.431813674345676
Validation loss: 2.639576028293376

Epoch: 6| Step: 5
Training loss: 1.7394863109219945
Validation loss: 2.6185769259875977

Epoch: 6| Step: 6
Training loss: 1.4051062277008302
Validation loss: 2.5831458167243304

Epoch: 6| Step: 7
Training loss: 2.004609755973136
Validation loss: 2.6963666098557284

Epoch: 6| Step: 8
Training loss: 1.9295902613800537
Validation loss: 2.6147122345010496

Epoch: 6| Step: 9
Training loss: 1.8842924640856475
Validation loss: 2.6973742574351953

Epoch: 6| Step: 10
Training loss: 1.4975067716773378
Validation loss: 2.6230543207028343

Epoch: 6| Step: 11
Training loss: 1.889422451966698
Validation loss: 2.6397117826364704

Epoch: 6| Step: 12
Training loss: 1.6419775337698836
Validation loss: 2.6115701392552246

Epoch: 6| Step: 13
Training loss: 1.4490071679484933
Validation loss: 2.6029392986759907

Epoch: 140| Step: 0
Training loss: 1.8033522252816683
Validation loss: 2.6442732128658313

Epoch: 6| Step: 1
Training loss: 1.5934857916149152
Validation loss: 2.725187375687217

Epoch: 6| Step: 2
Training loss: 2.1142433782705896
Validation loss: 2.6389441172079677

Epoch: 6| Step: 3
Training loss: 1.611024326237883
Validation loss: 2.67132992603601

Epoch: 6| Step: 4
Training loss: 2.0369166048008274
Validation loss: 2.5601014642923277

Epoch: 6| Step: 5
Training loss: 2.2845995624343116
Validation loss: 2.680140272616354

Epoch: 6| Step: 6
Training loss: 2.051675772172858
Validation loss: 2.608860916999181

Epoch: 6| Step: 7
Training loss: 2.223103510098837
Validation loss: 2.6239666039999174

Epoch: 6| Step: 8
Training loss: 1.5616530602567047
Validation loss: 2.657850120139143

Epoch: 6| Step: 9
Training loss: 1.511923763755047
Validation loss: 2.604799732825393

Epoch: 6| Step: 10
Training loss: 1.7817367424073582
Validation loss: 2.5534364551589825

Epoch: 6| Step: 11
Training loss: 1.190803049946891
Validation loss: 2.649065721509957

Epoch: 6| Step: 12
Training loss: 1.7666728193547816
Validation loss: 2.6249521039195947

Epoch: 6| Step: 13
Training loss: 2.25755049825397
Validation loss: 2.6300911578273767

Epoch: 141| Step: 0
Training loss: 2.104592786893707
Validation loss: 2.7451493948819516

Epoch: 6| Step: 1
Training loss: 1.9796523719567396
Validation loss: 2.663142532998769

Epoch: 6| Step: 2
Training loss: 1.4591758837246298
Validation loss: 2.7426418786570728

Epoch: 6| Step: 3
Training loss: 1.8728752813409675
Validation loss: 2.6384362775134176

Epoch: 6| Step: 4
Training loss: 1.7062893090942537
Validation loss: 2.643355193993785

Epoch: 6| Step: 5
Training loss: 1.6659546602818296
Validation loss: 2.586602408833381

Epoch: 6| Step: 6
Training loss: 1.8990675897045142
Validation loss: 2.684558781885515

Epoch: 6| Step: 7
Training loss: 1.8797932075844512
Validation loss: 2.622136400882876

Epoch: 6| Step: 8
Training loss: 1.4186260286859032
Validation loss: 2.6024696670069067

Epoch: 6| Step: 9
Training loss: 1.9748394961265652
Validation loss: 2.6476229124802244

Epoch: 6| Step: 10
Training loss: 2.266704012993212
Validation loss: 2.708806955055318

Epoch: 6| Step: 11
Training loss: 1.935611173329718
Validation loss: 2.611499462151245

Epoch: 6| Step: 12
Training loss: 1.8040657458663543
Validation loss: 2.7128166699473564

Epoch: 6| Step: 13
Training loss: 1.1117559859687471
Validation loss: 2.648750789270768

Epoch: 142| Step: 0
Training loss: 2.095588218759826
Validation loss: 2.6297596363034077

Epoch: 6| Step: 1
Training loss: 1.6140560478679729
Validation loss: 2.6301197502906084

Epoch: 6| Step: 2
Training loss: 2.0336637973628644
Validation loss: 2.716283358892647

Epoch: 6| Step: 3
Training loss: 1.7201787385554226
Validation loss: 2.6226241395295364

Epoch: 6| Step: 4
Training loss: 1.8274915853116165
Validation loss: 2.7017692738305565

Epoch: 6| Step: 5
Training loss: 1.9768747075599553
Validation loss: 2.660733153403399

Epoch: 6| Step: 6
Training loss: 1.5399411399541592
Validation loss: 2.759502667432628

Epoch: 6| Step: 7
Training loss: 1.483904954874165
Validation loss: 2.734067685251002

Epoch: 6| Step: 8
Training loss: 1.5571277578929208
Validation loss: 2.693437847629148

Epoch: 6| Step: 9
Training loss: 2.3109806327586027
Validation loss: 2.5797741788168564

Epoch: 6| Step: 10
Training loss: 1.4629735783076931
Validation loss: 2.6829473095399052

Epoch: 6| Step: 11
Training loss: 2.515838613977373
Validation loss: 2.6229095612405207

Epoch: 6| Step: 12
Training loss: 1.7722376995480433
Validation loss: 2.6365245907728685

Epoch: 6| Step: 13
Training loss: 1.7077776152319009
Validation loss: 2.6868900375732188

Epoch: 143| Step: 0
Training loss: 1.798248031803933
Validation loss: 2.613741071586374

Epoch: 6| Step: 1
Training loss: 1.8616134889134457
Validation loss: 2.573911518292306

Epoch: 6| Step: 2
Training loss: 1.4103126333495706
Validation loss: 2.6618761206256782

Epoch: 6| Step: 3
Training loss: 1.8880727896721412
Validation loss: 2.705223063087438

Epoch: 6| Step: 4
Training loss: 1.4336093828975638
Validation loss: 2.6895343414580224

Epoch: 6| Step: 5
Training loss: 2.276162313817979
Validation loss: 2.691264104019205

Epoch: 6| Step: 6
Training loss: 1.8101796391951315
Validation loss: 2.653325074900262

Epoch: 6| Step: 7
Training loss: 1.7780361964571658
Validation loss: 2.6319631532816605

Epoch: 6| Step: 8
Training loss: 1.9451485070653536
Validation loss: 2.596409043650729

Epoch: 6| Step: 9
Training loss: 1.8135131109167082
Validation loss: 2.652264061518633

Epoch: 6| Step: 10
Training loss: 1.639204882027769
Validation loss: 2.645885186675977

Epoch: 6| Step: 11
Training loss: 1.8372076307979208
Validation loss: 2.664921686335138

Epoch: 6| Step: 12
Training loss: 1.5181261641653787
Validation loss: 2.5888948154881883

Epoch: 6| Step: 13
Training loss: 2.4446999267043834
Validation loss: 2.6576182712135843

Epoch: 144| Step: 0
Training loss: 1.6535939926872518
Validation loss: 2.666180511704151

Epoch: 6| Step: 1
Training loss: 1.8275601419136394
Validation loss: 2.6267354012305075

Epoch: 6| Step: 2
Training loss: 2.2176487298436265
Validation loss: 2.668569114683472

Epoch: 6| Step: 3
Training loss: 1.8552803666703954
Validation loss: 2.6705802918618575

Epoch: 6| Step: 4
Training loss: 1.5758646272039694
Validation loss: 2.582180971084054

Epoch: 6| Step: 5
Training loss: 1.1132659911063665
Validation loss: 2.6040044250812033

Epoch: 6| Step: 6
Training loss: 1.6990805383355825
Validation loss: 2.6198701006231393

Epoch: 6| Step: 7
Training loss: 2.620922736829844
Validation loss: 2.592810203928546

Epoch: 6| Step: 8
Training loss: 1.7535500621409617
Validation loss: 2.6935107267222937

Epoch: 6| Step: 9
Training loss: 1.577626895667345
Validation loss: 2.657279918190588

Epoch: 6| Step: 10
Training loss: 1.6946041191757852
Validation loss: 2.708995427606685

Epoch: 6| Step: 11
Training loss: 1.5518312526870974
Validation loss: 2.6991541073129963

Epoch: 6| Step: 12
Training loss: 2.0690861362616153
Validation loss: 2.69219297769011

Epoch: 6| Step: 13
Training loss: 1.117434067626611
Validation loss: 2.704641354183907

Epoch: 145| Step: 0
Training loss: 1.782587252135968
Validation loss: 2.7553557348693634

Epoch: 6| Step: 1
Training loss: 1.8321074447566361
Validation loss: 2.592682185845174

Epoch: 6| Step: 2
Training loss: 1.8167488677416457
Validation loss: 2.6348124378099764

Epoch: 6| Step: 3
Training loss: 2.5800770161097164
Validation loss: 2.6534821244873994

Epoch: 6| Step: 4
Training loss: 1.767081546052465
Validation loss: 2.7171241312679157

Epoch: 6| Step: 5
Training loss: 1.768159178602038
Validation loss: 2.640961108364175

Epoch: 6| Step: 6
Training loss: 1.7473879120860845
Validation loss: 2.7370776090089293

Epoch: 6| Step: 7
Training loss: 1.373535763780749
Validation loss: 2.5823955730929318

Epoch: 6| Step: 8
Training loss: 1.3153019016787797
Validation loss: 2.693790215990834

Epoch: 6| Step: 9
Training loss: 1.6090440872866576
Validation loss: 2.570793671098509

Epoch: 6| Step: 10
Training loss: 1.704364570499036
Validation loss: 2.7264706250936754

Epoch: 6| Step: 11
Training loss: 1.5387049225712892
Validation loss: 2.724316638456485

Epoch: 6| Step: 12
Training loss: 1.9227673079599863
Validation loss: 2.7251786415503148

Epoch: 6| Step: 13
Training loss: 1.7882058037291118
Validation loss: 2.778865999736965

Epoch: 146| Step: 0
Training loss: 1.0616990043370305
Validation loss: 2.6884795924551956

Epoch: 6| Step: 1
Training loss: 1.8904284540584815
Validation loss: 2.763157765946987

Epoch: 6| Step: 2
Training loss: 2.160636089761052
Validation loss: 2.710911145114223

Epoch: 6| Step: 3
Training loss: 1.7107076969583006
Validation loss: 2.7197919873096557

Epoch: 6| Step: 4
Training loss: 1.995196295620218
Validation loss: 2.6273196431503205

Epoch: 6| Step: 5
Training loss: 1.6742018434896495
Validation loss: 2.6963715614925428

Epoch: 6| Step: 6
Training loss: 2.013969983919912
Validation loss: 2.6433898551216726

Epoch: 6| Step: 7
Training loss: 2.4416423713942215
Validation loss: 2.661337091380519

Epoch: 6| Step: 8
Training loss: 1.41346863136528
Validation loss: 2.5419263290176444

Epoch: 6| Step: 9
Training loss: 1.6071943305113516
Validation loss: 2.711919015054069

Epoch: 6| Step: 10
Training loss: 1.7172921673824393
Validation loss: 2.646731462005776

Epoch: 6| Step: 11
Training loss: 1.7558906730603578
Validation loss: 2.513327850931126

Epoch: 6| Step: 12
Training loss: 1.7437323319828697
Validation loss: 2.699469238671229

Epoch: 6| Step: 13
Training loss: 1.6326965582901916
Validation loss: 2.7414078142899645

Epoch: 147| Step: 0
Training loss: 1.4150244038772317
Validation loss: 2.679123443761112

Epoch: 6| Step: 1
Training loss: 1.5540377538702532
Validation loss: 2.720674498645465

Epoch: 6| Step: 2
Training loss: 1.960230179232929
Validation loss: 2.6479624244303905

Epoch: 6| Step: 3
Training loss: 1.7585702576798827
Validation loss: 2.6827522302166296

Epoch: 6| Step: 4
Training loss: 1.9286090756329468
Validation loss: 2.708923837892486

Epoch: 6| Step: 5
Training loss: 1.781276903451229
Validation loss: 2.6795277302289366

Epoch: 6| Step: 6
Training loss: 1.8629066202633247
Validation loss: 2.644873427431525

Epoch: 6| Step: 7
Training loss: 2.0394151170802357
Validation loss: 2.649720592883743

Epoch: 6| Step: 8
Training loss: 2.0654849791284193
Validation loss: 2.659616573372444

Epoch: 6| Step: 9
Training loss: 2.0330225326557825
Validation loss: 2.7190486700058973

Epoch: 6| Step: 10
Training loss: 1.4022897268956382
Validation loss: 2.6150446987525853

Epoch: 6| Step: 11
Training loss: 1.3676086213177365
Validation loss: 2.7224556234647093

Epoch: 6| Step: 12
Training loss: 1.3369528498014294
Validation loss: 2.774955556129844

Epoch: 6| Step: 13
Training loss: 1.584309385848383
Validation loss: 2.714649542945011

Epoch: 148| Step: 0
Training loss: 1.324867427239585
Validation loss: 2.6526936678065463

Epoch: 6| Step: 1
Training loss: 1.6715479022758102
Validation loss: 2.7296617995480514

Epoch: 6| Step: 2
Training loss: 1.402201568281292
Validation loss: 2.660525975462414

Epoch: 6| Step: 3
Training loss: 1.7696733901848858
Validation loss: 2.630801586563338

Epoch: 6| Step: 4
Training loss: 1.7652401800159376
Validation loss: 2.6669732056701987

Epoch: 6| Step: 5
Training loss: 1.4920132520307015
Validation loss: 2.625356937542893

Epoch: 6| Step: 6
Training loss: 1.9538552101787199
Validation loss: 2.643003938346524

Epoch: 6| Step: 7
Training loss: 2.0053584319245084
Validation loss: 2.7332781090236136

Epoch: 6| Step: 8
Training loss: 1.4979758911026262
Validation loss: 2.6497902355304697

Epoch: 6| Step: 9
Training loss: 1.7707978488134395
Validation loss: 2.6943553607236423

Epoch: 6| Step: 10
Training loss: 2.1026774005232918
Validation loss: 2.6658482835578403

Epoch: 6| Step: 11
Training loss: 1.610948108597465
Validation loss: 2.610655662594607

Epoch: 6| Step: 12
Training loss: 1.6951318460009352
Validation loss: 2.680731656137786

Epoch: 6| Step: 13
Training loss: 1.295840896674323
Validation loss: 2.7276679041691585

Epoch: 149| Step: 0
Training loss: 1.8126750729950385
Validation loss: 2.7508082646989314

Epoch: 6| Step: 1
Training loss: 2.091270116879144
Validation loss: 2.6917860762462973

Epoch: 6| Step: 2
Training loss: 1.7124347145277614
Validation loss: 2.61932931438907

Epoch: 6| Step: 3
Training loss: 1.2750426864958186
Validation loss: 2.573823226003133

Epoch: 6| Step: 4
Training loss: 1.5345140817542375
Validation loss: 2.671345872147812

Epoch: 6| Step: 5
Training loss: 2.3213009767784274
Validation loss: 2.6033105943576507

Epoch: 6| Step: 6
Training loss: 1.6022986976245415
Validation loss: 2.586706894110329

Epoch: 6| Step: 7
Training loss: 1.9208700142072896
Validation loss: 2.7162754153499056

Epoch: 6| Step: 8
Training loss: 1.330687440739337
Validation loss: 2.6342110923376567

Epoch: 6| Step: 9
Training loss: 1.6861531569580157
Validation loss: 2.6952910933819307

Epoch: 6| Step: 10
Training loss: 1.9894858797449018
Validation loss: 2.6612659591356347

Epoch: 6| Step: 11
Training loss: 1.4113728355422877
Validation loss: 2.639534192630193

Epoch: 6| Step: 12
Training loss: 1.9796612840947445
Validation loss: 2.6746867742194653

Epoch: 6| Step: 13
Training loss: 1.4987531884344831
Validation loss: 2.668391613567038

Epoch: 150| Step: 0
Training loss: 1.353417110848838
Validation loss: 2.6309907913897463

Epoch: 6| Step: 1
Training loss: 1.6172940868690613
Validation loss: 2.7218738747151705

Epoch: 6| Step: 2
Training loss: 1.9687194821853449
Validation loss: 2.5870551069303596

Epoch: 6| Step: 3
Training loss: 1.3685439002536188
Validation loss: 2.6794248698761742

Epoch: 6| Step: 4
Training loss: 1.4624210923255607
Validation loss: 2.639614822412634

Epoch: 6| Step: 5
Training loss: 1.627614046193974
Validation loss: 2.6453409612889187

Epoch: 6| Step: 6
Training loss: 1.6883827302540708
Validation loss: 2.5631865380332113

Epoch: 6| Step: 7
Training loss: 1.5911673769660426
Validation loss: 2.6540207877160698

Epoch: 6| Step: 8
Training loss: 2.074986777206022
Validation loss: 2.6897553879133467

Epoch: 6| Step: 9
Training loss: 1.3205210955464757
Validation loss: 2.727892590411615

Epoch: 6| Step: 10
Training loss: 2.421507776783899
Validation loss: 2.625202625265324

Epoch: 6| Step: 11
Training loss: 1.379729848969939
Validation loss: 2.6259034736423508

Epoch: 6| Step: 12
Training loss: 1.1584421975735426
Validation loss: 2.660944257583146

Epoch: 6| Step: 13
Training loss: 1.5648842740156224
Validation loss: 2.679681375717119

Epoch: 151| Step: 0
Training loss: 1.7308463552196647
Validation loss: 2.6797699910952737

Epoch: 6| Step: 1
Training loss: 1.8469345909354693
Validation loss: 2.6129254002385354

Epoch: 6| Step: 2
Training loss: 2.1794432363064615
Validation loss: 2.6596063389999065

Epoch: 6| Step: 3
Training loss: 1.59629872294772
Validation loss: 2.686230174672378

Epoch: 6| Step: 4
Training loss: 1.660520554008418
Validation loss: 2.7292673126376976

Epoch: 6| Step: 5
Training loss: 1.3176619429834568
Validation loss: 2.6063002022742108

Epoch: 6| Step: 6
Training loss: 1.6536830947963206
Validation loss: 2.5369446514749625

Epoch: 6| Step: 7
Training loss: 2.309111922666142
Validation loss: 2.7887929007825227

Epoch: 6| Step: 8
Training loss: 1.5567487537923652
Validation loss: 2.5932623316680847

Epoch: 6| Step: 9
Training loss: 1.3686297847264544
Validation loss: 2.6034339229950056

Epoch: 6| Step: 10
Training loss: 1.4022927447635896
Validation loss: 2.692409407786749

Epoch: 6| Step: 11
Training loss: 1.7964625673075698
Validation loss: 2.670969119813327

Epoch: 6| Step: 12
Training loss: 1.1743018896906807
Validation loss: 2.7414392680407187

Epoch: 6| Step: 13
Training loss: 1.632766284927417
Validation loss: 2.856425016064822

Epoch: 152| Step: 0
Training loss: 2.1058922166621543
Validation loss: 2.75654065537959

Epoch: 6| Step: 1
Training loss: 2.4918386759333844
Validation loss: 2.8620653194457226

Epoch: 6| Step: 2
Training loss: 1.5197629776413257
Validation loss: 2.7574081917008177

Epoch: 6| Step: 3
Training loss: 1.2368489836066896
Validation loss: 2.727119804198678

Epoch: 6| Step: 4
Training loss: 1.6508876435873119
Validation loss: 2.6916110067448917

Epoch: 6| Step: 5
Training loss: 1.6607128691191133
Validation loss: 2.655047694350771

Epoch: 6| Step: 6
Training loss: 1.976593198273993
Validation loss: 2.65915207247872

Epoch: 6| Step: 7
Training loss: 1.5326568213372416
Validation loss: 2.6957164811796295

Epoch: 6| Step: 8
Training loss: 1.4447747957234256
Validation loss: 2.7307552101881574

Epoch: 6| Step: 9
Training loss: 1.9606865954125094
Validation loss: 2.62822959168639

Epoch: 6| Step: 10
Training loss: 1.3673740804606205
Validation loss: 2.6541572704378424

Epoch: 6| Step: 11
Training loss: 1.7106304851272611
Validation loss: 2.6387618525082415

Epoch: 6| Step: 12
Training loss: 2.1443496932979977
Validation loss: 2.6882922756830347

Epoch: 6| Step: 13
Training loss: 1.8014890392773626
Validation loss: 2.666263919954347

Epoch: 153| Step: 0
Training loss: 1.9152536850667123
Validation loss: 2.6959250302371087

Epoch: 6| Step: 1
Training loss: 1.8950975338639053
Validation loss: 2.6886913113563753

Epoch: 6| Step: 2
Training loss: 1.540102999079028
Validation loss: 2.7624361508385706

Epoch: 6| Step: 3
Training loss: 1.294136234809114
Validation loss: 2.717567054952995

Epoch: 6| Step: 4
Training loss: 2.290030733593596
Validation loss: 2.626161325995166

Epoch: 6| Step: 5
Training loss: 1.7494093715702361
Validation loss: 2.721835114295954

Epoch: 6| Step: 6
Training loss: 1.4793744635248602
Validation loss: 2.686706070843701

Epoch: 6| Step: 7
Training loss: 1.6183231070706443
Validation loss: 2.670771142133362

Epoch: 6| Step: 8
Training loss: 1.382349658814163
Validation loss: 2.6400602891809983

Epoch: 6| Step: 9
Training loss: 1.81026505105018
Validation loss: 2.677885571122136

Epoch: 6| Step: 10
Training loss: 1.4803713160034713
Validation loss: 2.720427072600261

Epoch: 6| Step: 11
Training loss: 1.6233523158321945
Validation loss: 2.6481112839084955

Epoch: 6| Step: 12
Training loss: 1.5060886154142685
Validation loss: 2.6739202631662673

Epoch: 6| Step: 13
Training loss: 1.3342383660932693
Validation loss: 2.5941224347869625

Epoch: 154| Step: 0
Training loss: 1.7550355126246677
Validation loss: 2.6930902137731803

Epoch: 6| Step: 1
Training loss: 1.3083770572540125
Validation loss: 2.644229843566306

Epoch: 6| Step: 2
Training loss: 1.7656155476274913
Validation loss: 2.7425485574323507

Epoch: 6| Step: 3
Training loss: 1.4265786645313996
Validation loss: 2.7239716470561994

Epoch: 6| Step: 4
Training loss: 1.5552638533489858
Validation loss: 2.8269699716762244

Epoch: 6| Step: 5
Training loss: 1.7739499733847905
Validation loss: 2.7505805096433567

Epoch: 6| Step: 6
Training loss: 1.2830250237597192
Validation loss: 2.6893465514572954

Epoch: 6| Step: 7
Training loss: 1.8190814263572077
Validation loss: 2.6813076448801842

Epoch: 6| Step: 8
Training loss: 1.8738497066626743
Validation loss: 2.627003034190834

Epoch: 6| Step: 9
Training loss: 2.115797649421688
Validation loss: 2.673006929660943

Epoch: 6| Step: 10
Training loss: 1.1323399051239358
Validation loss: 2.6306587261667236

Epoch: 6| Step: 11
Training loss: 1.4736600738086845
Validation loss: 2.6605802507126866

Epoch: 6| Step: 12
Training loss: 1.9624609026081887
Validation loss: 2.72851467837966

Epoch: 6| Step: 13
Training loss: 1.3511557435536485
Validation loss: 2.7145684630971596

Epoch: 155| Step: 0
Training loss: 1.819399821807628
Validation loss: 2.722953951599089

Epoch: 6| Step: 1
Training loss: 1.8030661694004944
Validation loss: 2.581214240737033

Epoch: 6| Step: 2
Training loss: 1.428977581598444
Validation loss: 2.6515243980114382

Epoch: 6| Step: 3
Training loss: 1.0874165952422634
Validation loss: 2.6417291503480103

Epoch: 6| Step: 4
Training loss: 2.3130866672624557
Validation loss: 2.7419931717835597

Epoch: 6| Step: 5
Training loss: 1.6439845972940674
Validation loss: 2.6794715994561074

Epoch: 6| Step: 6
Training loss: 1.4149758776977623
Validation loss: 2.707135329234257

Epoch: 6| Step: 7
Training loss: 1.8370566345729629
Validation loss: 2.606960313880007

Epoch: 6| Step: 8
Training loss: 1.8330920306263871
Validation loss: 2.672985307243754

Epoch: 6| Step: 9
Training loss: 1.7635864372301209
Validation loss: 2.693227121537661

Epoch: 6| Step: 10
Training loss: 1.660724425980744
Validation loss: 2.732048265438528

Epoch: 6| Step: 11
Training loss: 1.731617359062734
Validation loss: 2.6576984719692556

Epoch: 6| Step: 12
Training loss: 1.2617287650168507
Validation loss: 2.7008845722862582

Epoch: 6| Step: 13
Training loss: 1.1585372777283036
Validation loss: 2.6457831811031465

Epoch: 156| Step: 0
Training loss: 1.811713014949721
Validation loss: 2.809819420502341

Epoch: 6| Step: 1
Training loss: 1.4469623119136132
Validation loss: 2.664725824224164

Epoch: 6| Step: 2
Training loss: 1.6844664256915975
Validation loss: 2.6626290560205343

Epoch: 6| Step: 3
Training loss: 1.331070718647729
Validation loss: 2.7291076207264906

Epoch: 6| Step: 4
Training loss: 1.8614262397901238
Validation loss: 2.731774072248189

Epoch: 6| Step: 5
Training loss: 1.4994154426873452
Validation loss: 2.6583267470928944

Epoch: 6| Step: 6
Training loss: 1.3207133660854464
Validation loss: 2.6891195902581657

Epoch: 6| Step: 7
Training loss: 1.3476430256512615
Validation loss: 2.6843824120782998

Epoch: 6| Step: 8
Training loss: 2.3018907032000366
Validation loss: 2.7243424260886866

Epoch: 6| Step: 9
Training loss: 1.9186250453359703
Validation loss: 2.569339355404614

Epoch: 6| Step: 10
Training loss: 1.9854894797498646
Validation loss: 2.6646504131003086

Epoch: 6| Step: 11
Training loss: 1.2383753021815902
Validation loss: 2.6995503893070336

Epoch: 6| Step: 12
Training loss: 1.676059086315734
Validation loss: 2.6403214470158707

Epoch: 6| Step: 13
Training loss: 1.460701336871549
Validation loss: 2.6957904778856943

Epoch: 157| Step: 0
Training loss: 1.268747786346158
Validation loss: 2.6141891080967037

Epoch: 6| Step: 1
Training loss: 2.0779946652032777
Validation loss: 2.6823684582628053

Epoch: 6| Step: 2
Training loss: 1.311914040691994
Validation loss: 2.647602125845117

Epoch: 6| Step: 3
Training loss: 1.44559026574983
Validation loss: 2.6180622669632005

Epoch: 6| Step: 4
Training loss: 1.7983190953230508
Validation loss: 2.722185266550983

Epoch: 6| Step: 5
Training loss: 1.806302491583587
Validation loss: 2.7035015630372414

Epoch: 6| Step: 6
Training loss: 1.809543302677202
Validation loss: 2.651948939711716

Epoch: 6| Step: 7
Training loss: 2.024430197151393
Validation loss: 2.686488811492104

Epoch: 6| Step: 8
Training loss: 1.8224574209924813
Validation loss: 2.6451179308161303

Epoch: 6| Step: 9
Training loss: 1.6048160906326363
Validation loss: 2.6356009216631966

Epoch: 6| Step: 10
Training loss: 1.8128828762409142
Validation loss: 2.6859862921756266

Epoch: 6| Step: 11
Training loss: 1.3461783888958494
Validation loss: 2.6592018256338203

Epoch: 6| Step: 12
Training loss: 1.4896394234436203
Validation loss: 2.6993854947808753

Epoch: 6| Step: 13
Training loss: 1.4687339294853026
Validation loss: 2.785781240939497

Epoch: 158| Step: 0
Training loss: 1.473885748955295
Validation loss: 2.7752091028285792

Epoch: 6| Step: 1
Training loss: 1.7339446762569515
Validation loss: 2.724776024319373

Epoch: 6| Step: 2
Training loss: 1.6975214757670394
Validation loss: 2.7512231115274846

Epoch: 6| Step: 3
Training loss: 1.391870690807152
Validation loss: 2.6561033619814602

Epoch: 6| Step: 4
Training loss: 2.023748543298773
Validation loss: 2.712226231554815

Epoch: 6| Step: 5
Training loss: 1.4748288427068923
Validation loss: 2.6577270290738557

Epoch: 6| Step: 6
Training loss: 1.791184412200693
Validation loss: 2.7630434074282664

Epoch: 6| Step: 7
Training loss: 1.4041079419286022
Validation loss: 2.6573264689592104

Epoch: 6| Step: 8
Training loss: 1.2605550968456447
Validation loss: 2.562123488080885

Epoch: 6| Step: 9
Training loss: 1.967052090857373
Validation loss: 2.6652585772424127

Epoch: 6| Step: 10
Training loss: 1.150113083628326
Validation loss: 2.64537223542678

Epoch: 6| Step: 11
Training loss: 1.6138694005122565
Validation loss: 2.7271652429886997

Epoch: 6| Step: 12
Training loss: 1.7205004708051939
Validation loss: 2.71293559173309

Epoch: 6| Step: 13
Training loss: 1.2001696864000375
Validation loss: 2.739974539109434

Epoch: 159| Step: 0
Training loss: 1.1712349733347494
Validation loss: 2.7420468199201626

Epoch: 6| Step: 1
Training loss: 1.2753385150539607
Validation loss: 2.781162403456004

Epoch: 6| Step: 2
Training loss: 1.6953479393977264
Validation loss: 2.8289185775239614

Epoch: 6| Step: 3
Training loss: 2.0346485756777675
Validation loss: 2.6675320850219557

Epoch: 6| Step: 4
Training loss: 1.3314572437138468
Validation loss: 2.664500464333109

Epoch: 6| Step: 5
Training loss: 1.4740458036782822
Validation loss: 2.6754366390582063

Epoch: 6| Step: 6
Training loss: 1.7895487162121442
Validation loss: 2.6243932567741792

Epoch: 6| Step: 7
Training loss: 1.7351615428199751
Validation loss: 2.658665011730017

Epoch: 6| Step: 8
Training loss: 1.7454286541788562
Validation loss: 2.7000707670050663

Epoch: 6| Step: 9
Training loss: 1.6920076847082268
Validation loss: 2.7372149079509

Epoch: 6| Step: 10
Training loss: 2.2536267614707386
Validation loss: 2.7228944401513684

Epoch: 6| Step: 11
Training loss: 1.7330341826786104
Validation loss: 2.6640886322261212

Epoch: 6| Step: 12
Training loss: 1.3778617728601272
Validation loss: 2.783842228910557

Epoch: 6| Step: 13
Training loss: 1.2481166002261206
Validation loss: 2.632182980824555

Epoch: 160| Step: 0
Training loss: 1.53623400413684
Validation loss: 2.5988324325329346

Epoch: 6| Step: 1
Training loss: 1.45625198429611
Validation loss: 2.6878800677865673

Epoch: 6| Step: 2
Training loss: 1.442774095195591
Validation loss: 2.6841815450975055

Epoch: 6| Step: 3
Training loss: 1.4547623464503259
Validation loss: 2.787389044841361

Epoch: 6| Step: 4
Training loss: 1.2540129143811936
Validation loss: 2.8267059137960566

Epoch: 6| Step: 5
Training loss: 1.5415854131920106
Validation loss: 2.7553555185464895

Epoch: 6| Step: 6
Training loss: 1.1607834889668516
Validation loss: 2.7949868191776197

Epoch: 6| Step: 7
Training loss: 1.8570168551993234
Validation loss: 2.8280170623807734

Epoch: 6| Step: 8
Training loss: 1.3443846423709107
Validation loss: 2.764991795525959

Epoch: 6| Step: 9
Training loss: 1.5699388049888798
Validation loss: 2.753954197531587

Epoch: 6| Step: 10
Training loss: 1.2326010016169109
Validation loss: 2.7414081911573174

Epoch: 6| Step: 11
Training loss: 2.4754328031409396
Validation loss: 2.675708986963317

Epoch: 6| Step: 12
Training loss: 1.461174359219796
Validation loss: 2.7291962473967315

Epoch: 6| Step: 13
Training loss: 1.5157828494587398
Validation loss: 2.764228439453513

Epoch: 161| Step: 0
Training loss: 1.4358421385338818
Validation loss: 2.762395348731473

Epoch: 6| Step: 1
Training loss: 2.4752222520085705
Validation loss: 2.7799464968008425

Epoch: 6| Step: 2
Training loss: 1.2946241217699836
Validation loss: 2.766262476669286

Epoch: 6| Step: 3
Training loss: 1.5119003462825298
Validation loss: 2.7825846666431477

Epoch: 6| Step: 4
Training loss: 1.3450843041528364
Validation loss: 2.6896110937063344

Epoch: 6| Step: 5
Training loss: 1.818540045820931
Validation loss: 2.670467757162226

Epoch: 6| Step: 6
Training loss: 1.9691496549375442
Validation loss: 2.684476452746976

Epoch: 6| Step: 7
Training loss: 1.2236217550035355
Validation loss: 2.714405212843192

Epoch: 6| Step: 8
Training loss: 1.3369391183337338
Validation loss: 2.778654108628044

Epoch: 6| Step: 9
Training loss: 2.2777121296651557
Validation loss: 2.8742780470030316

Epoch: 6| Step: 10
Training loss: 1.4129483802556373
Validation loss: 2.7111451200487053

Epoch: 6| Step: 11
Training loss: 1.332879833743215
Validation loss: 2.7294716531143766

Epoch: 6| Step: 12
Training loss: 1.4649890878420693
Validation loss: 2.6310075257030707

Epoch: 6| Step: 13
Training loss: 1.5285267650842689
Validation loss: 2.701842928279931

Epoch: 162| Step: 0
Training loss: 1.162173280641777
Validation loss: 2.7014470267121125

Epoch: 6| Step: 1
Training loss: 1.264934021506999
Validation loss: 2.658051197980699

Epoch: 6| Step: 2
Training loss: 1.4533085860907273
Validation loss: 2.8095609072290366

Epoch: 6| Step: 3
Training loss: 1.5216771053918536
Validation loss: 2.755945440003293

Epoch: 6| Step: 4
Training loss: 1.6948899828109811
Validation loss: 2.7779679953825878

Epoch: 6| Step: 5
Training loss: 1.5327020105637088
Validation loss: 2.6589556807599646

Epoch: 6| Step: 6
Training loss: 1.8941717376954381
Validation loss: 2.6883907616195333

Epoch: 6| Step: 7
Training loss: 1.4936218557896945
Validation loss: 2.7369807733639333

Epoch: 6| Step: 8
Training loss: 1.4343499208472703
Validation loss: 2.606022689627852

Epoch: 6| Step: 9
Training loss: 1.572492613903948
Validation loss: 2.7671411815911795

Epoch: 6| Step: 10
Training loss: 1.0630505762171054
Validation loss: 2.7775873791821386

Epoch: 6| Step: 11
Training loss: 2.2650678278385996
Validation loss: 2.7250287279020453

Epoch: 6| Step: 12
Training loss: 1.699526844374921
Validation loss: 2.6745765665823202

Epoch: 6| Step: 13
Training loss: 1.5527518793235047
Validation loss: 2.801378371795227

Epoch: 163| Step: 0
Training loss: 1.522801975814303
Validation loss: 2.790682652452117

Epoch: 6| Step: 1
Training loss: 1.3920681783488145
Validation loss: 2.6637768335898797

Epoch: 6| Step: 2
Training loss: 1.0147379596124642
Validation loss: 2.8124164427601634

Epoch: 6| Step: 3
Training loss: 1.1290390834074666
Validation loss: 2.7198392505688522

Epoch: 6| Step: 4
Training loss: 1.6688560252136329
Validation loss: 2.783974545299422

Epoch: 6| Step: 5
Training loss: 1.6021965446536812
Validation loss: 2.6316457666731243

Epoch: 6| Step: 6
Training loss: 1.7266858087065304
Validation loss: 2.7452441330576565

Epoch: 6| Step: 7
Training loss: 1.1924308998352726
Validation loss: 2.737023950580006

Epoch: 6| Step: 8
Training loss: 1.6221676865574524
Validation loss: 2.6020740010012995

Epoch: 6| Step: 9
Training loss: 1.1570511697088621
Validation loss: 2.7456226912547455

Epoch: 6| Step: 10
Training loss: 1.0136597031761096
Validation loss: 2.8045949256516467

Epoch: 6| Step: 11
Training loss: 2.268992479886017
Validation loss: 2.627207947653676

Epoch: 6| Step: 12
Training loss: 1.4268932447967189
Validation loss: 2.6706570234342037

Epoch: 6| Step: 13
Training loss: 1.9962189218948054
Validation loss: 2.6467069825489733

Epoch: 164| Step: 0
Training loss: 1.3905606201356684
Validation loss: 2.6810770537731363

Epoch: 6| Step: 1
Training loss: 1.5276500658158059
Validation loss: 2.690985511555552

Epoch: 6| Step: 2
Training loss: 1.1668267424074494
Validation loss: 2.6563177212328846

Epoch: 6| Step: 3
Training loss: 2.2925304403332873
Validation loss: 2.7656088719014456

Epoch: 6| Step: 4
Training loss: 1.6411040560353252
Validation loss: 2.7859204685263252

Epoch: 6| Step: 5
Training loss: 1.1610065773375942
Validation loss: 2.6389112159275263

Epoch: 6| Step: 6
Training loss: 1.4911503407895095
Validation loss: 2.6702106192260238

Epoch: 6| Step: 7
Training loss: 1.6286063158270951
Validation loss: 2.7507630503344127

Epoch: 6| Step: 8
Training loss: 1.5303838187345857
Validation loss: 2.757155789576276

Epoch: 6| Step: 9
Training loss: 1.7424942225575275
Validation loss: 2.774258645151375

Epoch: 6| Step: 10
Training loss: 1.4054033061679023
Validation loss: 2.745959318876091

Epoch: 6| Step: 11
Training loss: 1.9524371957874247
Validation loss: 2.76828572504659

Epoch: 6| Step: 12
Training loss: 1.5430273117347992
Validation loss: 2.657591073577063

Epoch: 6| Step: 13
Training loss: 1.4802562389992868
Validation loss: 2.7311986585224557

Epoch: 165| Step: 0
Training loss: 1.5616863421025424
Validation loss: 2.7671818347415553

Epoch: 6| Step: 1
Training loss: 1.5888236707508738
Validation loss: 2.7312369368856912

Epoch: 6| Step: 2
Training loss: 1.2747785375901624
Validation loss: 2.685129243686966

Epoch: 6| Step: 3
Training loss: 1.3835767369056309
Validation loss: 2.7806578159317934

Epoch: 6| Step: 4
Training loss: 1.5292931333766488
Validation loss: 2.7882014208925807

Epoch: 6| Step: 5
Training loss: 2.3512039671655125
Validation loss: 2.667481526409463

Epoch: 6| Step: 6
Training loss: 1.388961139495122
Validation loss: 2.7025419425944412

Epoch: 6| Step: 7
Training loss: 1.231725529273759
Validation loss: 2.6199492197963927

Epoch: 6| Step: 8
Training loss: 1.4421434455664708
Validation loss: 2.860430288224503

Epoch: 6| Step: 9
Training loss: 1.5321994873922387
Validation loss: 2.825214131434687

Epoch: 6| Step: 10
Training loss: 1.7784254199100193
Validation loss: 2.7894840723278036

Epoch: 6| Step: 11
Training loss: 1.2114764091125012
Validation loss: 2.7546582505145882

Epoch: 6| Step: 12
Training loss: 2.135819212645688
Validation loss: 2.7067784076169

Epoch: 6| Step: 13
Training loss: 1.3993738971278218
Validation loss: 2.7254882561731506

Epoch: 166| Step: 0
Training loss: 1.7017847789955685
Validation loss: 2.652573161253255

Epoch: 6| Step: 1
Training loss: 1.3530061101331425
Validation loss: 2.779761283857327

Epoch: 6| Step: 2
Training loss: 0.8504990052604801
Validation loss: 2.7372931177242035

Epoch: 6| Step: 3
Training loss: 1.7669305616291606
Validation loss: 2.7821100026908625

Epoch: 6| Step: 4
Training loss: 1.4041601971364992
Validation loss: 2.711881914636231

Epoch: 6| Step: 5
Training loss: 1.7604733821001817
Validation loss: 2.7079252277909447

Epoch: 6| Step: 6
Training loss: 1.2575842608818597
Validation loss: 2.7415443963224524

Epoch: 6| Step: 7
Training loss: 1.504628669325476
Validation loss: 2.720493451884664

Epoch: 6| Step: 8
Training loss: 1.9259796968857594
Validation loss: 2.801387386093615

Epoch: 6| Step: 9
Training loss: 1.387009625083129
Validation loss: 2.7897984720638545

Epoch: 6| Step: 10
Training loss: 1.7883493926271408
Validation loss: 2.8250894431074225

Epoch: 6| Step: 11
Training loss: 2.5544911347028374
Validation loss: 2.9430300556410525

Epoch: 6| Step: 12
Training loss: 1.6733436194834481
Validation loss: 2.941963281527241

Epoch: 6| Step: 13
Training loss: 1.166253913799232
Validation loss: 2.8871932407606558

Epoch: 167| Step: 0
Training loss: 2.1992091014372606
Validation loss: 2.7105301945861147

Epoch: 6| Step: 1
Training loss: 1.3800184827064417
Validation loss: 2.79551177660543

Epoch: 6| Step: 2
Training loss: 1.659539033932394
Validation loss: 2.6590927619749785

Epoch: 6| Step: 3
Training loss: 1.8723711021887524
Validation loss: 2.6507247005853807

Epoch: 6| Step: 4
Training loss: 1.9053772976721368
Validation loss: 2.8127844207495696

Epoch: 6| Step: 5
Training loss: 1.1947127688941352
Validation loss: 2.793857431301861

Epoch: 6| Step: 6
Training loss: 1.4302837191739213
Validation loss: 2.819991124265424

Epoch: 6| Step: 7
Training loss: 1.7424354547835952
Validation loss: 2.663469951580687

Epoch: 6| Step: 8
Training loss: 1.4628701711531122
Validation loss: 2.667519363528482

Epoch: 6| Step: 9
Training loss: 1.5045217864467582
Validation loss: 2.6282776775002836

Epoch: 6| Step: 10
Training loss: 1.3524854298228117
Validation loss: 2.6277523748806697

Epoch: 6| Step: 11
Training loss: 1.914287071288549
Validation loss: 2.808607204866611

Epoch: 6| Step: 12
Training loss: 1.509377413603628
Validation loss: 2.684996866026647

Epoch: 6| Step: 13
Training loss: 1.535087525671275
Validation loss: 2.811543888478322

Epoch: 168| Step: 0
Training loss: 1.4790780573707163
Validation loss: 2.739145306766123

Epoch: 6| Step: 1
Training loss: 1.7592419047178207
Validation loss: 2.7948705213988494

Epoch: 6| Step: 2
Training loss: 1.4345205361992786
Validation loss: 2.7821859577929793

Epoch: 6| Step: 3
Training loss: 1.0810138312168653
Validation loss: 2.8078873992479956

Epoch: 6| Step: 4
Training loss: 0.9823114776771052
Validation loss: 2.628703350911491

Epoch: 6| Step: 5
Training loss: 1.4156000198282337
Validation loss: 2.7146829461425863

Epoch: 6| Step: 6
Training loss: 1.5916793686258408
Validation loss: 2.745731711545226

Epoch: 6| Step: 7
Training loss: 1.2753616493286792
Validation loss: 2.708705573299297

Epoch: 6| Step: 8
Training loss: 1.3344754254968065
Validation loss: 2.7148192333697034

Epoch: 6| Step: 9
Training loss: 1.2736952351185924
Validation loss: 2.711613815330271

Epoch: 6| Step: 10
Training loss: 1.5468319973603666
Validation loss: 2.7267669921673847

Epoch: 6| Step: 11
Training loss: 2.5908482877541656
Validation loss: 2.7519879091878807

Epoch: 6| Step: 12
Training loss: 1.5639207865321187
Validation loss: 2.784047623500142

Epoch: 6| Step: 13
Training loss: 1.4663146098569557
Validation loss: 2.60738462881091

Epoch: 169| Step: 0
Training loss: 1.1141792824676937
Validation loss: 2.7277590103781413

Epoch: 6| Step: 1
Training loss: 1.7747358367350479
Validation loss: 2.693122659727803

Epoch: 6| Step: 2
Training loss: 1.497865827579296
Validation loss: 2.672711068678117

Epoch: 6| Step: 3
Training loss: 1.2772550872922432
Validation loss: 2.7092368941727383

Epoch: 6| Step: 4
Training loss: 0.914746020771055
Validation loss: 2.715668565337023

Epoch: 6| Step: 5
Training loss: 1.9399765552991803
Validation loss: 2.6596043369428632

Epoch: 6| Step: 6
Training loss: 1.2735069583602374
Validation loss: 2.6963846037067056

Epoch: 6| Step: 7
Training loss: 1.578034804382195
Validation loss: 2.727382926328089

Epoch: 6| Step: 8
Training loss: 1.4307798787912678
Validation loss: 2.7082962669379227

Epoch: 6| Step: 9
Training loss: 1.5646567146711847
Validation loss: 2.7718833759787707

Epoch: 6| Step: 10
Training loss: 1.6378574097766057
Validation loss: 2.715642095408827

Epoch: 6| Step: 11
Training loss: 1.2881185138507627
Validation loss: 2.6956836389628642

Epoch: 6| Step: 12
Training loss: 1.405197512634708
Validation loss: 2.7601388371603335

Epoch: 6| Step: 13
Training loss: 1.0528725726233132
Validation loss: 2.6295793643688348

Epoch: 170| Step: 0
Training loss: 1.0698096214701873
Validation loss: 2.714556737863671

Epoch: 6| Step: 1
Training loss: 1.599710798949
Validation loss: 2.7004667820513415

Epoch: 6| Step: 2
Training loss: 1.8747278651797559
Validation loss: 2.702204273686942

Epoch: 6| Step: 3
Training loss: 1.3161100059899329
Validation loss: 2.7972095438600335

Epoch: 6| Step: 4
Training loss: 1.6514688254130125
Validation loss: 2.694620782668522

Epoch: 6| Step: 5
Training loss: 1.1242045663412072
Validation loss: 2.6443904987633253

Epoch: 6| Step: 6
Training loss: 1.956794039118461
Validation loss: 2.6693991330954674

Epoch: 6| Step: 7
Training loss: 1.519270690701748
Validation loss: 2.721601839370001

Epoch: 6| Step: 8
Training loss: 1.2405352850696378
Validation loss: 2.7851231498588276

Epoch: 6| Step: 9
Training loss: 1.1954792380131525
Validation loss: 2.6928608086886165

Epoch: 6| Step: 10
Training loss: 1.5971729694825796
Validation loss: 2.7100025657228755

Epoch: 6| Step: 11
Training loss: 0.9908396058222251
Validation loss: 2.69912705585434

Epoch: 6| Step: 12
Training loss: 1.1231771111644964
Validation loss: 2.697201274350038

Epoch: 6| Step: 13
Training loss: 1.4430565626091738
Validation loss: 2.6636405454047103

Epoch: 171| Step: 0
Training loss: 1.7073633495067093
Validation loss: 2.7094900864295823

Epoch: 6| Step: 1
Training loss: 1.2981701094715228
Validation loss: 2.7104124060872685

Epoch: 6| Step: 2
Training loss: 1.1717266751835387
Validation loss: 2.8043581770127424

Epoch: 6| Step: 3
Training loss: 1.3704023655792503
Validation loss: 2.7094556512675396

Epoch: 6| Step: 4
Training loss: 2.3174750964360586
Validation loss: 2.779027965598034

Epoch: 6| Step: 5
Training loss: 1.3956274004043048
Validation loss: 2.7092730554675244

Epoch: 6| Step: 6
Training loss: 1.0231495808961661
Validation loss: 2.692422572504072

Epoch: 6| Step: 7
Training loss: 1.474125541485713
Validation loss: 2.7853907789131993

Epoch: 6| Step: 8
Training loss: 1.1743014836304972
Validation loss: 2.706828687317606

Epoch: 6| Step: 9
Training loss: 1.2340074305782072
Validation loss: 2.7005926188262617

Epoch: 6| Step: 10
Training loss: 1.4620998878589062
Validation loss: 2.7772402773153617

Epoch: 6| Step: 11
Training loss: 1.6802954704580955
Validation loss: 2.743595931724702

Epoch: 6| Step: 12
Training loss: 1.568189941983296
Validation loss: 2.8658448279541195

Epoch: 6| Step: 13
Training loss: 1.0763749002074086
Validation loss: 2.736215310014077

Epoch: 172| Step: 0
Training loss: 1.5764958498942796
Validation loss: 2.742158344399997

Epoch: 6| Step: 1
Training loss: 1.520882444590331
Validation loss: 2.756319126176343

Epoch: 6| Step: 2
Training loss: 1.230600113895584
Validation loss: 2.785414488931136

Epoch: 6| Step: 3
Training loss: 1.1329541348014582
Validation loss: 2.72893045339873

Epoch: 6| Step: 4
Training loss: 1.5032723812566855
Validation loss: 2.85205930797711

Epoch: 6| Step: 5
Training loss: 1.508107289962395
Validation loss: 2.7034327307966866

Epoch: 6| Step: 6
Training loss: 1.2553929342226937
Validation loss: 2.7214619933065323

Epoch: 6| Step: 7
Training loss: 1.396805476905686
Validation loss: 2.7139105713844835

Epoch: 6| Step: 8
Training loss: 1.1849203701063806
Validation loss: 2.7370428240650884

Epoch: 6| Step: 9
Training loss: 1.2063532533085772
Validation loss: 2.8294329068995427

Epoch: 6| Step: 10
Training loss: 1.5055561477797603
Validation loss: 2.7257498593106866

Epoch: 6| Step: 11
Training loss: 1.665878308127831
Validation loss: 2.790848915882031

Epoch: 6| Step: 12
Training loss: 2.0064285198895138
Validation loss: 2.7769421565655357

Epoch: 6| Step: 13
Training loss: 1.317617883203972
Validation loss: 2.8357029897586776

Epoch: 173| Step: 0
Training loss: 1.764615065444335
Validation loss: 2.6688408308332616

Epoch: 6| Step: 1
Training loss: 1.445533034536661
Validation loss: 2.7227677806338706

Epoch: 6| Step: 2
Training loss: 1.0882091774937521
Validation loss: 2.7637710679296665

Epoch: 6| Step: 3
Training loss: 1.5353403539167179
Validation loss: 2.7820442580051363

Epoch: 6| Step: 4
Training loss: 1.4823630903045286
Validation loss: 2.817608608847974

Epoch: 6| Step: 5
Training loss: 1.6189019886671714
Validation loss: 2.64554326026762

Epoch: 6| Step: 6
Training loss: 1.2373878312571356
Validation loss: 2.7812225397590273

Epoch: 6| Step: 7
Training loss: 1.3220534724964852
Validation loss: 2.810664149973006

Epoch: 6| Step: 8
Training loss: 2.0641393215486756
Validation loss: 2.8483209937356433

Epoch: 6| Step: 9
Training loss: 1.0926663070951208
Validation loss: 2.645211692431974

Epoch: 6| Step: 10
Training loss: 1.4149693905650262
Validation loss: 2.8900035018195704

Epoch: 6| Step: 11
Training loss: 1.1588553896551073
Validation loss: 2.953485362622669

Epoch: 6| Step: 12
Training loss: 1.5428735631240524
Validation loss: 2.9826165123069175

Epoch: 6| Step: 13
Training loss: 1.3746041681831178
Validation loss: 2.854021337851314

Epoch: 174| Step: 0
Training loss: 1.516127906028497
Validation loss: 2.944271102537265

Epoch: 6| Step: 1
Training loss: 1.372043465456873
Validation loss: 2.8378350221140445

Epoch: 6| Step: 2
Training loss: 1.127902419516174
Validation loss: 2.6340832685619637

Epoch: 6| Step: 3
Training loss: 1.9222033460544083
Validation loss: 2.753731551164105

Epoch: 6| Step: 4
Training loss: 1.351909791284445
Validation loss: 2.770064589095133

Epoch: 6| Step: 5
Training loss: 1.5276099555964466
Validation loss: 2.582984967482269

Epoch: 6| Step: 6
Training loss: 1.2022086778386254
Validation loss: 2.802686595620254

Epoch: 6| Step: 7
Training loss: 1.5079593883378362
Validation loss: 2.7441313285262905

Epoch: 6| Step: 8
Training loss: 1.8480526779106274
Validation loss: 2.778644255494966

Epoch: 6| Step: 9
Training loss: 1.4667189332289972
Validation loss: 2.7377823154257386

Epoch: 6| Step: 10
Training loss: 1.4614025334613079
Validation loss: 2.723738861481369

Epoch: 6| Step: 11
Training loss: 2.033683961852371
Validation loss: 2.755156032784571

Epoch: 6| Step: 12
Training loss: 1.3863766960262305
Validation loss: 2.667237091646296

Epoch: 6| Step: 13
Training loss: 1.2205000807696873
Validation loss: 2.85245528506761

Epoch: 175| Step: 0
Training loss: 2.262306993376782
Validation loss: 2.8690327484922826

Epoch: 6| Step: 1
Training loss: 1.2702966818112045
Validation loss: 2.8756891889620593

Epoch: 6| Step: 2
Training loss: 1.3450424277693602
Validation loss: 2.8823488270935154

Epoch: 6| Step: 3
Training loss: 1.066391661827159
Validation loss: 2.6760994158183857

Epoch: 6| Step: 4
Training loss: 2.0742527730848983
Validation loss: 2.830541263486423

Epoch: 6| Step: 5
Training loss: 1.436150041360386
Validation loss: 2.7648292876712666

Epoch: 6| Step: 6
Training loss: 0.7120042280703817
Validation loss: 2.714641975204666

Epoch: 6| Step: 7
Training loss: 1.281927069429958
Validation loss: 2.742779790051525

Epoch: 6| Step: 8
Training loss: 1.4041800629441803
Validation loss: 2.7883929847938402

Epoch: 6| Step: 9
Training loss: 1.5817398368035045
Validation loss: 2.7756143399693647

Epoch: 6| Step: 10
Training loss: 1.6673984669395885
Validation loss: 2.8005070820383833

Epoch: 6| Step: 11
Training loss: 1.1777287067131423
Validation loss: 2.702379627399508

Epoch: 6| Step: 12
Training loss: 1.1384711113113888
Validation loss: 2.7588793642462006

Epoch: 6| Step: 13
Training loss: 1.2568450429448723
Validation loss: 2.6868330327492433

Testing loss: 2.4139173525825814
