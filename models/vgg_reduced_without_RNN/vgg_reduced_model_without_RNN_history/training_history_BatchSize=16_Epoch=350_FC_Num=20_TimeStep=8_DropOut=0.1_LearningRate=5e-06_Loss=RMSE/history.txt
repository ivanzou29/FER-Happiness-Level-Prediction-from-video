Epoch: 1| Step: 0
Training loss: 7.554494861249333
Validation loss: 6.827648201480174

Epoch: 6| Step: 1
Training loss: 8.555347434590983
Validation loss: 6.810668069052695

Epoch: 6| Step: 2
Training loss: 6.204554011249771
Validation loss: 6.8005271950350865

Epoch: 6| Step: 3
Training loss: 7.308771731698441
Validation loss: 6.783493866141726

Epoch: 6| Step: 4
Training loss: 5.989116334262679
Validation loss: 6.76813519833247

Epoch: 6| Step: 5
Training loss: 6.736873154505905
Validation loss: 6.7530197641392355

Epoch: 6| Step: 6
Training loss: 6.125805860172475
Validation loss: 6.740867464895048

Epoch: 6| Step: 7
Training loss: 6.585631665496769
Validation loss: 6.727231986666824

Epoch: 6| Step: 8
Training loss: 6.927792467422771
Validation loss: 6.709645073946229

Epoch: 6| Step: 9
Training loss: 7.100419593555089
Validation loss: 6.691887815375369

Epoch: 6| Step: 10
Training loss: 6.506715679817913
Validation loss: 6.677205704050223

Epoch: 6| Step: 11
Training loss: 6.624266097966621
Validation loss: 6.6606419361031985

Epoch: 6| Step: 12
Training loss: 5.762483066360186
Validation loss: 6.640664014514682

Epoch: 6| Step: 13
Training loss: 7.31977260882617
Validation loss: 6.622161833098765

Epoch: 2| Step: 0
Training loss: 6.769578021152623
Validation loss: 6.602926753604063

Epoch: 6| Step: 1
Training loss: 6.56347125904134
Validation loss: 6.5819733901079545

Epoch: 6| Step: 2
Training loss: 7.177839869547878
Validation loss: 6.563649249490478

Epoch: 6| Step: 3
Training loss: 6.856326735839954
Validation loss: 6.541779907931038

Epoch: 6| Step: 4
Training loss: 6.478856249995478
Validation loss: 6.5201102963969095

Epoch: 6| Step: 5
Training loss: 6.185309744921834
Validation loss: 6.4995826440483055

Epoch: 6| Step: 6
Training loss: 7.334316996868003
Validation loss: 6.474611314377223

Epoch: 6| Step: 7
Training loss: 5.42028539039956
Validation loss: 6.453749163894358

Epoch: 6| Step: 8
Training loss: 6.748292495077632
Validation loss: 6.4253578116087935

Epoch: 6| Step: 9
Training loss: 6.330111570896677
Validation loss: 6.398681288202019

Epoch: 6| Step: 10
Training loss: 5.628343054970405
Validation loss: 6.371978966458926

Epoch: 6| Step: 11
Training loss: 6.579216873270507
Validation loss: 6.345885971094818

Epoch: 6| Step: 12
Training loss: 6.553341824023832
Validation loss: 6.313102945167692

Epoch: 6| Step: 13
Training loss: 6.959514159861204
Validation loss: 6.289864978968465

Epoch: 3| Step: 0
Training loss: 5.564560926309667
Validation loss: 6.251783879333095

Epoch: 6| Step: 1
Training loss: 6.5751592696593075
Validation loss: 6.217968915643844

Epoch: 6| Step: 2
Training loss: 7.049593585048394
Validation loss: 6.184682750578328

Epoch: 6| Step: 3
Training loss: 4.27194606272619
Validation loss: 6.152542986191978

Epoch: 6| Step: 4
Training loss: 6.01088490196639
Validation loss: 6.110718718367331

Epoch: 6| Step: 5
Training loss: 5.7746494863908255
Validation loss: 6.068732502391876

Epoch: 6| Step: 6
Training loss: 5.746221544827203
Validation loss: 6.033719784213346

Epoch: 6| Step: 7
Training loss: 7.133390605851086
Validation loss: 5.99515369514153

Epoch: 6| Step: 8
Training loss: 6.669221229671628
Validation loss: 5.945633253417083

Epoch: 6| Step: 9
Training loss: 5.91410894136323
Validation loss: 5.90079883189145

Epoch: 6| Step: 10
Training loss: 5.3820594737021255
Validation loss: 5.845097894645556

Epoch: 6| Step: 11
Training loss: 6.482254453717038
Validation loss: 5.801484365268435

Epoch: 6| Step: 12
Training loss: 5.9247408653281255
Validation loss: 5.754232811277154

Epoch: 6| Step: 13
Training loss: 6.17242259240079
Validation loss: 5.694879125529754

Epoch: 4| Step: 0
Training loss: 5.233994199651201
Validation loss: 5.642938394864044

Epoch: 6| Step: 1
Training loss: 5.8624874545941195
Validation loss: 5.576560206121983

Epoch: 6| Step: 2
Training loss: 5.618206414564206
Validation loss: 5.517057756850062

Epoch: 6| Step: 3
Training loss: 5.680808689951297
Validation loss: 5.458973572822124

Epoch: 6| Step: 4
Training loss: 4.290016721323855
Validation loss: 5.396398723344588

Epoch: 6| Step: 5
Training loss: 4.834793177286767
Validation loss: 5.319444283977049

Epoch: 6| Step: 6
Training loss: 5.630954727069439
Validation loss: 5.247030750634093

Epoch: 6| Step: 7
Training loss: 5.351831404341243
Validation loss: 5.18954369300007

Epoch: 6| Step: 8
Training loss: 5.965841972997386
Validation loss: 5.102349135470446

Epoch: 6| Step: 9
Training loss: 5.485567403427728
Validation loss: 5.027007626488959

Epoch: 6| Step: 10
Training loss: 5.642612603736819
Validation loss: 4.937436485686803

Epoch: 6| Step: 11
Training loss: 5.167495209904385
Validation loss: 4.844746722965217

Epoch: 6| Step: 12
Training loss: 4.6650876143917355
Validation loss: 4.764022240781929

Epoch: 6| Step: 13
Training loss: 3.707658399103585
Validation loss: 4.657621979466694

Epoch: 5| Step: 0
Training loss: 5.1710130601377555
Validation loss: 4.578744648909369

Epoch: 6| Step: 1
Training loss: 3.8178625695825836
Validation loss: 4.45855731342071

Epoch: 6| Step: 2
Training loss: 4.098605937746952
Validation loss: 4.378377137784853

Epoch: 6| Step: 3
Training loss: 4.1223177425517115
Validation loss: 4.263052885680353

Epoch: 6| Step: 4
Training loss: 4.737105686818264
Validation loss: 4.149824524811978

Epoch: 6| Step: 5
Training loss: 4.680561270680446
Validation loss: 4.066630918835553

Epoch: 6| Step: 6
Training loss: 4.79442859606274
Validation loss: 3.931008129027689

Epoch: 6| Step: 7
Training loss: 3.73831645506542
Validation loss: 3.826417004773707

Epoch: 6| Step: 8
Training loss: 3.4551120754232203
Validation loss: 3.7229735168203657

Epoch: 6| Step: 9
Training loss: 3.7006664243008656
Validation loss: 3.596321335996489

Epoch: 6| Step: 10
Training loss: 3.6795726847301053
Validation loss: 3.4855196773236465

Epoch: 6| Step: 11
Training loss: 2.736368379153857
Validation loss: 3.3964070301634433

Epoch: 6| Step: 12
Training loss: 3.345133842675811
Validation loss: 3.272467810246874

Epoch: 6| Step: 13
Training loss: 2.8145951838117984
Validation loss: 3.2173810350091334

Epoch: 6| Step: 0
Training loss: 2.6758525309848684
Validation loss: 3.128794350212593

Epoch: 6| Step: 1
Training loss: 3.388627830900729
Validation loss: 3.0215799833959656

Epoch: 6| Step: 2
Training loss: 3.715964805009309
Validation loss: 2.9707537397411237

Epoch: 6| Step: 3
Training loss: 3.781538014437865
Validation loss: 2.94335186878674

Epoch: 6| Step: 4
Training loss: 2.5482595226042926
Validation loss: 2.880337887564109

Epoch: 6| Step: 5
Training loss: 2.4348883698428954
Validation loss: 2.8635053143645965

Epoch: 6| Step: 6
Training loss: 3.0178274699773353
Validation loss: 2.8465764877082314

Epoch: 6| Step: 7
Training loss: 2.2045781098282693
Validation loss: 2.8199569604849337

Epoch: 6| Step: 8
Training loss: 2.7080617817433583
Validation loss: 2.8263772724193035

Epoch: 6| Step: 9
Training loss: 1.8834914886549643
Validation loss: 2.8728065554453837

Epoch: 6| Step: 10
Training loss: 2.549286432095501
Validation loss: 2.9159638693445773

Epoch: 6| Step: 11
Training loss: 3.1918547559118218
Validation loss: 2.8969133590578258

Epoch: 6| Step: 12
Training loss: 3.2519858235499464
Validation loss: 2.9211975373048937

Epoch: 6| Step: 13
Training loss: 2.7908056459128927
Validation loss: 2.948021449910341

Epoch: 7| Step: 0
Training loss: 1.9742421639808514
Validation loss: 2.9112482467128507

Epoch: 6| Step: 1
Training loss: 2.5802936103002785
Validation loss: 2.9362477413215897

Epoch: 6| Step: 2
Training loss: 3.210154342743638
Validation loss: 2.9376573182313686

Epoch: 6| Step: 3
Training loss: 3.6059490640251353
Validation loss: 2.9347262983709568

Epoch: 6| Step: 4
Training loss: 2.310254424314759
Validation loss: 2.9038568850510242

Epoch: 6| Step: 5
Training loss: 3.0287007102466457
Validation loss: 2.91875636762405

Epoch: 6| Step: 6
Training loss: 2.2987800016203397
Validation loss: 2.8746865972448457

Epoch: 6| Step: 7
Training loss: 3.5608939850689727
Validation loss: 2.8718960495247594

Epoch: 6| Step: 8
Training loss: 3.4301579528562485
Validation loss: 2.9004668939668736

Epoch: 6| Step: 9
Training loss: 3.234623848745182
Validation loss: 2.8315735054595126

Epoch: 6| Step: 10
Training loss: 2.146190230926471
Validation loss: 2.8603656352122306

Epoch: 6| Step: 11
Training loss: 2.307649835782587
Validation loss: 2.805125890276528

Epoch: 6| Step: 12
Training loss: 3.0644739756899004
Validation loss: 2.81988684206256

Epoch: 6| Step: 13
Training loss: 2.180843798571344
Validation loss: 2.795934977344293

Epoch: 8| Step: 0
Training loss: 2.8723224942945507
Validation loss: 2.8160485099078487

Epoch: 6| Step: 1
Training loss: 2.0911240693349713
Validation loss: 2.838271526582868

Epoch: 6| Step: 2
Training loss: 3.3106442417466355
Validation loss: 2.7726561614310907

Epoch: 6| Step: 3
Training loss: 1.9262884683004515
Validation loss: 2.818024500644468

Epoch: 6| Step: 4
Training loss: 2.3440795666727223
Validation loss: 2.834285734958729

Epoch: 6| Step: 5
Training loss: 2.278462522853535
Validation loss: 2.7554364076956404

Epoch: 6| Step: 6
Training loss: 3.104296346596941
Validation loss: 2.834329890320139

Epoch: 6| Step: 7
Training loss: 2.3185913689736917
Validation loss: 2.809534727880462

Epoch: 6| Step: 8
Training loss: 3.380770236404335
Validation loss: 2.818746764413086

Epoch: 6| Step: 9
Training loss: 3.1786680344646934
Validation loss: 2.818980993714932

Epoch: 6| Step: 10
Training loss: 3.0901989835106782
Validation loss: 2.818714227893465

Epoch: 6| Step: 11
Training loss: 2.951242644233375
Validation loss: 2.793559263177127

Epoch: 6| Step: 12
Training loss: 2.622726364039421
Validation loss: 2.8218889418462116

Epoch: 6| Step: 13
Training loss: 2.8481533626561393
Validation loss: 2.8119205937671055

Epoch: 9| Step: 0
Training loss: 2.489661775467822
Validation loss: 2.8229016002145046

Epoch: 6| Step: 1
Training loss: 3.677405036203242
Validation loss: 2.785014002209477

Epoch: 6| Step: 2
Training loss: 2.8852115562792453
Validation loss: 2.8460167035908133

Epoch: 6| Step: 3
Training loss: 1.9647934529899034
Validation loss: 2.778039500834284

Epoch: 6| Step: 4
Training loss: 2.5806576397809464
Validation loss: 2.7913583234104595

Epoch: 6| Step: 5
Training loss: 2.8669267166825394
Validation loss: 2.793509221635451

Epoch: 6| Step: 6
Training loss: 2.8908859547539323
Validation loss: 2.748006531636834

Epoch: 6| Step: 7
Training loss: 3.181894197422936
Validation loss: 2.759482838765261

Epoch: 6| Step: 8
Training loss: 2.8271228005098394
Validation loss: 2.7864586850935575

Epoch: 6| Step: 9
Training loss: 2.005068198587656
Validation loss: 2.7913083278257855

Epoch: 6| Step: 10
Training loss: 2.559318707677307
Validation loss: 2.7896246107683225

Epoch: 6| Step: 11
Training loss: 2.620784553676309
Validation loss: 2.8117740965894584

Epoch: 6| Step: 12
Training loss: 3.277943861968847
Validation loss: 2.7746025396498526

Epoch: 6| Step: 13
Training loss: 2.5783221545117843
Validation loss: 2.7878148469892596

Epoch: 10| Step: 0
Training loss: 3.0227706134267756
Validation loss: 2.801797495352979

Epoch: 6| Step: 1
Training loss: 2.6352635415766734
Validation loss: 2.7728699009307656

Epoch: 6| Step: 2
Training loss: 1.9775299599520444
Validation loss: 2.8068678942403333

Epoch: 6| Step: 3
Training loss: 2.6947310995445424
Validation loss: 2.7905315729544724

Epoch: 6| Step: 4
Training loss: 2.3894707380228435
Validation loss: 2.783626127166271

Epoch: 6| Step: 5
Training loss: 3.3980628497691807
Validation loss: 2.8489018399194985

Epoch: 6| Step: 6
Training loss: 2.7081661955294845
Validation loss: 2.830325877295014

Epoch: 6| Step: 7
Training loss: 2.4539814808464637
Validation loss: 2.7834841295231505

Epoch: 6| Step: 8
Training loss: 2.544861354386387
Validation loss: 2.75919270761134

Epoch: 6| Step: 9
Training loss: 3.2109375
Validation loss: 2.7777046580757516

Epoch: 6| Step: 10
Training loss: 3.3202786073637824
Validation loss: 2.7617990211428913

Epoch: 6| Step: 11
Training loss: 2.9237506578435726
Validation loss: 2.7229846553783412

Epoch: 6| Step: 12
Training loss: 1.8952550390327751
Validation loss: 2.8151905330051075

Epoch: 6| Step: 13
Training loss: 2.943681908081163
Validation loss: 2.7703030779184017

Epoch: 11| Step: 0
Training loss: 2.383356251195168
Validation loss: 2.7434192003305418

Epoch: 6| Step: 1
Training loss: 2.6506386221311002
Validation loss: 2.7522137141525076

Epoch: 6| Step: 2
Training loss: 2.7254931257431014
Validation loss: 2.7865338799523895

Epoch: 6| Step: 3
Training loss: 1.908509338236133
Validation loss: 2.7473098861966894

Epoch: 6| Step: 4
Training loss: 2.746871382327947
Validation loss: 2.8220261908914726

Epoch: 6| Step: 5
Training loss: 2.9672859195659913
Validation loss: 2.7597618813926896

Epoch: 6| Step: 6
Training loss: 3.592239991443769
Validation loss: 2.7688057921839775

Epoch: 6| Step: 7
Training loss: 2.5354251101835694
Validation loss: 2.7696823559543664

Epoch: 6| Step: 8
Training loss: 3.097513549134653
Validation loss: 2.8030824877046676

Epoch: 6| Step: 9
Training loss: 3.261544192091803
Validation loss: 2.776246230918528

Epoch: 6| Step: 10
Training loss: 3.046696740829092
Validation loss: 2.726927724604388

Epoch: 6| Step: 11
Training loss: 2.3212557843639012
Validation loss: 2.74248570399353

Epoch: 6| Step: 12
Training loss: 2.4008973272026948
Validation loss: 2.772164366884351

Epoch: 6| Step: 13
Training loss: 2.647992121964229
Validation loss: 2.7717658579432842

Epoch: 12| Step: 0
Training loss: 2.688092188684786
Validation loss: 2.7953254200448603

Epoch: 6| Step: 1
Training loss: 2.358163484673354
Validation loss: 2.7711825234413423

Epoch: 6| Step: 2
Training loss: 2.5982812115341605
Validation loss: 2.7658674489448054

Epoch: 6| Step: 3
Training loss: 2.827731953490899
Validation loss: 2.7665395140632882

Epoch: 6| Step: 4
Training loss: 2.3718710918168147
Validation loss: 2.751307003500072

Epoch: 6| Step: 5
Training loss: 3.17835404462489
Validation loss: 2.756761979396912

Epoch: 6| Step: 6
Training loss: 2.7108140197247272
Validation loss: 2.806222394709756

Epoch: 6| Step: 7
Training loss: 2.6483871770258243
Validation loss: 2.758371874567855

Epoch: 6| Step: 8
Training loss: 2.4785323627168294
Validation loss: 2.7840484370552523

Epoch: 6| Step: 9
Training loss: 2.9350410071242576
Validation loss: 2.7387979829810774

Epoch: 6| Step: 10
Training loss: 2.1189342767479236
Validation loss: 2.7894303393602997

Epoch: 6| Step: 11
Training loss: 2.682208507446241
Validation loss: 2.752926295453044

Epoch: 6| Step: 12
Training loss: 3.253699764372436
Validation loss: 2.761207781495269

Epoch: 6| Step: 13
Training loss: 3.0098972774479487
Validation loss: 2.747825774530191

Epoch: 13| Step: 0
Training loss: 2.561210493953189
Validation loss: 2.7805202969900567

Epoch: 6| Step: 1
Training loss: 2.410218174662845
Validation loss: 2.7210152495607747

Epoch: 6| Step: 2
Training loss: 2.9400476000299545
Validation loss: 2.8048225023228004

Epoch: 6| Step: 3
Training loss: 2.3153522531600625
Validation loss: 2.7427266488415696

Epoch: 6| Step: 4
Training loss: 2.5307359526682522
Validation loss: 2.778191059415638

Epoch: 6| Step: 5
Training loss: 3.1276209711941
Validation loss: 2.768757800456498

Epoch: 6| Step: 6
Training loss: 2.826034447651037
Validation loss: 2.7448700683128817

Epoch: 6| Step: 7
Training loss: 3.016930806378979
Validation loss: 2.7187424582891984

Epoch: 6| Step: 8
Training loss: 3.108397056874104
Validation loss: 2.7399033382517817

Epoch: 6| Step: 9
Training loss: 2.5947649704886944
Validation loss: 2.7530542376831595

Epoch: 6| Step: 10
Training loss: 2.835669807011129
Validation loss: 2.7678677504492972

Epoch: 6| Step: 11
Training loss: 2.820846211241078
Validation loss: 2.783006020866933

Epoch: 6| Step: 12
Training loss: 2.644087468245687
Validation loss: 2.7532628960485943

Epoch: 6| Step: 13
Training loss: 2.1682322299070313
Validation loss: 2.7583340303894577

Epoch: 14| Step: 0
Training loss: 2.2552947159243444
Validation loss: 2.7784667072041715

Epoch: 6| Step: 1
Training loss: 2.5317177046084023
Validation loss: 2.7731437133496977

Epoch: 6| Step: 2
Training loss: 2.7949745924994174
Validation loss: 2.7183466791199176

Epoch: 6| Step: 3
Training loss: 2.916349684429588
Validation loss: 2.700274852020374

Epoch: 6| Step: 4
Training loss: 2.4144318430798433
Validation loss: 2.744352726641436

Epoch: 6| Step: 5
Training loss: 3.533009858589227
Validation loss: 2.7529176493229612

Epoch: 6| Step: 6
Training loss: 3.311306432500168
Validation loss: 2.7038203908710896

Epoch: 6| Step: 7
Training loss: 2.747481753676608
Validation loss: 2.7502417458135655

Epoch: 6| Step: 8
Training loss: 2.179049053142443
Validation loss: 2.7771578913012043

Epoch: 6| Step: 9
Training loss: 2.4037868228339483
Validation loss: 2.7366463664235487

Epoch: 6| Step: 10
Training loss: 2.6325739630790133
Validation loss: 2.7118977688263373

Epoch: 6| Step: 11
Training loss: 2.74241963243568
Validation loss: 2.740845137033613

Epoch: 6| Step: 12
Training loss: 2.041649007396491
Validation loss: 2.7173365941967114

Epoch: 6| Step: 13
Training loss: 2.9911804895099854
Validation loss: 2.7385493359047834

Epoch: 15| Step: 0
Training loss: 2.6407441783849164
Validation loss: 2.7309121429957495

Epoch: 6| Step: 1
Training loss: 3.4862909224205536
Validation loss: 2.742140187202202

Epoch: 6| Step: 2
Training loss: 2.743978323158524
Validation loss: 2.7057896088111266

Epoch: 6| Step: 3
Training loss: 2.593015084078248
Validation loss: 2.739629539612579

Epoch: 6| Step: 4
Training loss: 2.1534942487503037
Validation loss: 2.6991703454189153

Epoch: 6| Step: 5
Training loss: 2.8026556023882323
Validation loss: 2.721844165742683

Epoch: 6| Step: 6
Training loss: 2.185449565667702
Validation loss: 2.7537097328717857

Epoch: 6| Step: 7
Training loss: 2.627840775623365
Validation loss: 2.6911328623962154

Epoch: 6| Step: 8
Training loss: 2.7192083388968062
Validation loss: 2.7367616537369917

Epoch: 6| Step: 9
Training loss: 2.548221255728347
Validation loss: 2.7244866602162636

Epoch: 6| Step: 10
Training loss: 2.071717674300549
Validation loss: 2.6894430632669675

Epoch: 6| Step: 11
Training loss: 2.4858759538571285
Validation loss: 2.68435088928787

Epoch: 6| Step: 12
Training loss: 2.953353792238808
Validation loss: 2.727497614513628

Epoch: 6| Step: 13
Training loss: 2.801433237288263
Validation loss: 2.7079827644188446

Epoch: 16| Step: 0
Training loss: 2.5421564120201277
Validation loss: 2.7368396078595776

Epoch: 6| Step: 1
Training loss: 1.7615521472723463
Validation loss: 2.6992211495962484

Epoch: 6| Step: 2
Training loss: 2.2571822081958945
Validation loss: 2.7131230964410844

Epoch: 6| Step: 3
Training loss: 2.2620375018261676
Validation loss: 2.712179172604324

Epoch: 6| Step: 4
Training loss: 2.6307562430486326
Validation loss: 2.700474875098001

Epoch: 6| Step: 5
Training loss: 2.5482563415167006
Validation loss: 2.714455629410638

Epoch: 6| Step: 6
Training loss: 2.4649942536509544
Validation loss: 2.727093357993503

Epoch: 6| Step: 7
Training loss: 2.1184669373061333
Validation loss: 2.757415195335767

Epoch: 6| Step: 8
Training loss: 3.073063285476394
Validation loss: 2.7200822452658184

Epoch: 6| Step: 9
Training loss: 3.2566634605753753
Validation loss: 2.7625715997315234

Epoch: 6| Step: 10
Training loss: 3.978377671769104
Validation loss: 2.666148602309779

Epoch: 6| Step: 11
Training loss: 3.09113702341617
Validation loss: 2.7413487469395066

Epoch: 6| Step: 12
Training loss: 2.6362255398088994
Validation loss: 2.699830636846773

Epoch: 6| Step: 13
Training loss: 2.4047502079471936
Validation loss: 2.7036958653942658

Epoch: 17| Step: 0
Training loss: 2.7630202101342123
Validation loss: 2.716459968715218

Epoch: 6| Step: 1
Training loss: 1.9698835470180098
Validation loss: 2.719794734006857

Epoch: 6| Step: 2
Training loss: 2.648725105805944
Validation loss: 2.6993117732770346

Epoch: 6| Step: 3
Training loss: 2.2666007209983356
Validation loss: 2.675273124916899

Epoch: 6| Step: 4
Training loss: 2.5376956958193544
Validation loss: 2.696907669759452

Epoch: 6| Step: 5
Training loss: 2.304608359836921
Validation loss: 2.6730403626726043

Epoch: 6| Step: 6
Training loss: 2.5289546779253453
Validation loss: 2.725048530216464

Epoch: 6| Step: 7
Training loss: 3.1703374734781384
Validation loss: 2.7206072401323995

Epoch: 6| Step: 8
Training loss: 3.2263694871711492
Validation loss: 2.7384980569827593

Epoch: 6| Step: 9
Training loss: 1.8837367278443429
Validation loss: 2.691103537578865

Epoch: 6| Step: 10
Training loss: 2.240398264629589
Validation loss: 2.6903051625607852

Epoch: 6| Step: 11
Training loss: 3.692637598447982
Validation loss: 2.648708228393521

Epoch: 6| Step: 12
Training loss: 2.1748337386151837
Validation loss: 2.7064133710055245

Epoch: 6| Step: 13
Training loss: 3.3234650130538705
Validation loss: 2.6731856553946267

Epoch: 18| Step: 0
Training loss: 2.2606603488156995
Validation loss: 2.68288236366741

Epoch: 6| Step: 1
Training loss: 2.661829395642468
Validation loss: 2.6350162387856635

Epoch: 6| Step: 2
Training loss: 2.3430782118282747
Validation loss: 2.6978164173093213

Epoch: 6| Step: 3
Training loss: 2.7630391073866027
Validation loss: 2.6922986267971236

Epoch: 6| Step: 4
Training loss: 2.707969601977536
Validation loss: 2.7208982143484612

Epoch: 6| Step: 5
Training loss: 2.0139406248733196
Validation loss: 2.695802609024391

Epoch: 6| Step: 6
Training loss: 3.0794307824314906
Validation loss: 2.689442058569091

Epoch: 6| Step: 7
Training loss: 3.051177288534597
Validation loss: 2.7311558547914507

Epoch: 6| Step: 8
Training loss: 3.0029844697746952
Validation loss: 2.699101152448399

Epoch: 6| Step: 9
Training loss: 2.807937821365492
Validation loss: 2.6920562904045457

Epoch: 6| Step: 10
Training loss: 3.104062396523503
Validation loss: 2.67997716407631

Epoch: 6| Step: 11
Training loss: 2.459723860586166
Validation loss: 2.6727057758564574

Epoch: 6| Step: 12
Training loss: 2.5011849456212047
Validation loss: 2.6840484989008497

Epoch: 6| Step: 13
Training loss: 2.181434396201926
Validation loss: 2.6882332976858363

Epoch: 19| Step: 0
Training loss: 3.138997429590549
Validation loss: 2.6733663312043974

Epoch: 6| Step: 1
Training loss: 2.3152167368333325
Validation loss: 2.7051156712759825

Epoch: 6| Step: 2
Training loss: 2.854486006717992
Validation loss: 2.6591807036316766

Epoch: 6| Step: 3
Training loss: 2.5244618512763872
Validation loss: 2.6875520449781334

Epoch: 6| Step: 4
Training loss: 2.3358791178166216
Validation loss: 2.68528524708082

Epoch: 6| Step: 5
Training loss: 3.071534202508208
Validation loss: 2.7002881255475506

Epoch: 6| Step: 6
Training loss: 3.046422210696941
Validation loss: 2.6985538913325535

Epoch: 6| Step: 7
Training loss: 1.516229882417389
Validation loss: 2.663216338108417

Epoch: 6| Step: 8
Training loss: 2.7569097927252915
Validation loss: 2.6874329314623644

Epoch: 6| Step: 9
Training loss: 2.379723118936893
Validation loss: 2.6912042830842884

Epoch: 6| Step: 10
Training loss: 2.5512300479151726
Validation loss: 2.670005650055964

Epoch: 6| Step: 11
Training loss: 2.7567801556026303
Validation loss: 2.702674048997871

Epoch: 6| Step: 12
Training loss: 2.405828067398078
Validation loss: 2.7308382103598703

Epoch: 6| Step: 13
Training loss: 2.4566118279611877
Validation loss: 2.6867856066831335

Epoch: 20| Step: 0
Training loss: 2.209014055911063
Validation loss: 2.640372947084914

Epoch: 6| Step: 1
Training loss: 2.9456822494619006
Validation loss: 2.7024907744394575

Epoch: 6| Step: 2
Training loss: 2.895868442972067
Validation loss: 2.6854257193314877

Epoch: 6| Step: 3
Training loss: 2.557321852579026
Validation loss: 2.644137707742141

Epoch: 6| Step: 4
Training loss: 2.0648443596586783
Validation loss: 2.6685192011332455

Epoch: 6| Step: 5
Training loss: 2.9467389525383374
Validation loss: 2.6685463469537205

Epoch: 6| Step: 6
Training loss: 2.3300473258324383
Validation loss: 2.645035050081197

Epoch: 6| Step: 7
Training loss: 3.198965656483718
Validation loss: 2.6826252751459356

Epoch: 6| Step: 8
Training loss: 2.2587485303594286
Validation loss: 2.7082283195285832

Epoch: 6| Step: 9
Training loss: 2.7118867207221347
Validation loss: 2.6533845742308206

Epoch: 6| Step: 10
Training loss: 2.7691407352059505
Validation loss: 2.7041037740775273

Epoch: 6| Step: 11
Training loss: 2.465645105161514
Validation loss: 2.6767278551524263

Epoch: 6| Step: 12
Training loss: 2.9271644409092454
Validation loss: 2.6395298268696665

Epoch: 6| Step: 13
Training loss: 2.264962355951408
Validation loss: 2.693009886590219

Epoch: 21| Step: 0
Training loss: 3.129673476813862
Validation loss: 2.6595224604831085

Epoch: 6| Step: 1
Training loss: 3.4360265174704
Validation loss: 2.662737310755432

Epoch: 6| Step: 2
Training loss: 2.787513708927674
Validation loss: 2.668862144383152

Epoch: 6| Step: 3
Training loss: 2.0892677725556035
Validation loss: 2.678020526001081

Epoch: 6| Step: 4
Training loss: 2.422042840863831
Validation loss: 2.593279937678227

Epoch: 6| Step: 5
Training loss: 2.848929749693552
Validation loss: 2.668892368685299

Epoch: 6| Step: 6
Training loss: 2.2845664803843855
Validation loss: 2.6427143265763107

Epoch: 6| Step: 7
Training loss: 2.19658756899018
Validation loss: 2.6000391153303175

Epoch: 6| Step: 8
Training loss: 2.3194882762470392
Validation loss: 2.654034786650855

Epoch: 6| Step: 9
Training loss: 2.850868621432331
Validation loss: 2.642008266765243

Epoch: 6| Step: 10
Training loss: 2.646814349672005
Validation loss: 2.656002422089411

Epoch: 6| Step: 11
Training loss: 2.2384813894964206
Validation loss: 2.6532429597390332

Epoch: 6| Step: 12
Training loss: 2.4469421611352824
Validation loss: 2.6475720187037446

Epoch: 6| Step: 13
Training loss: 2.2798387525659387
Validation loss: 2.6558058722705864

Epoch: 22| Step: 0
Training loss: 3.3262497181051853
Validation loss: 2.659622176114451

Epoch: 6| Step: 1
Training loss: 2.3191921213635314
Validation loss: 2.6421832541249857

Epoch: 6| Step: 2
Training loss: 2.284735538195217
Validation loss: 2.6372470204067127

Epoch: 6| Step: 3
Training loss: 2.1564884883185083
Validation loss: 2.636837999449411

Epoch: 6| Step: 4
Training loss: 3.401493776579545
Validation loss: 2.6386128044151986

Epoch: 6| Step: 5
Training loss: 2.326402474991585
Validation loss: 2.615800617236631

Epoch: 6| Step: 6
Training loss: 2.39880437871811
Validation loss: 2.630514649535582

Epoch: 6| Step: 7
Training loss: 2.393241995748366
Validation loss: 2.6490295108578445

Epoch: 6| Step: 8
Training loss: 2.653584927255204
Validation loss: 2.6758959223546364

Epoch: 6| Step: 9
Training loss: 2.5572787800533465
Validation loss: 2.6590776240608025

Epoch: 6| Step: 10
Training loss: 2.6554891057481425
Validation loss: 2.6438854486444363

Epoch: 6| Step: 11
Training loss: 2.0240025265342414
Validation loss: 2.6106131351594946

Epoch: 6| Step: 12
Training loss: 2.6610761891911654
Validation loss: 2.6571794716240693

Epoch: 6| Step: 13
Training loss: 3.034221961958075
Validation loss: 2.6153288357203572

Epoch: 23| Step: 0
Training loss: 2.4928194877007237
Validation loss: 2.6343104235787926

Epoch: 6| Step: 1
Training loss: 2.4684509868859466
Validation loss: 2.6986630608892037

Epoch: 6| Step: 2
Training loss: 3.1007197313652886
Validation loss: 2.680298879146343

Epoch: 6| Step: 3
Training loss: 2.368353427512685
Validation loss: 2.6184929471948313

Epoch: 6| Step: 4
Training loss: 1.9451600286946689
Validation loss: 2.649574763290224

Epoch: 6| Step: 5
Training loss: 2.691350086440031
Validation loss: 2.6254152847461567

Epoch: 6| Step: 6
Training loss: 2.481790794033438
Validation loss: 2.663171255537657

Epoch: 6| Step: 7
Training loss: 1.7514904351088971
Validation loss: 2.633035833317522

Epoch: 6| Step: 8
Training loss: 2.1710963328463855
Validation loss: 2.686420889380611

Epoch: 6| Step: 9
Training loss: 2.4150754908102265
Validation loss: 2.7268081233779675

Epoch: 6| Step: 10
Training loss: 2.7816928125260842
Validation loss: 2.7354930517412535

Epoch: 6| Step: 11
Training loss: 2.908559230422341
Validation loss: 2.6909837248088055

Epoch: 6| Step: 12
Training loss: 3.4380087736061085
Validation loss: 2.6724866943932164

Epoch: 6| Step: 13
Training loss: 3.0222471589885975
Validation loss: 2.651217716469522

Epoch: 24| Step: 0
Training loss: 2.44719343391004
Validation loss: 2.6848234924772902

Epoch: 6| Step: 1
Training loss: 2.8792850240034737
Validation loss: 2.5945121380780627

Epoch: 6| Step: 2
Training loss: 2.9341180690939805
Validation loss: 2.6473686139312678

Epoch: 6| Step: 3
Training loss: 2.9043366070962464
Validation loss: 2.655461916232465

Epoch: 6| Step: 4
Training loss: 2.7785770559096328
Validation loss: 2.6473186008600926

Epoch: 6| Step: 5
Training loss: 2.370734852207525
Validation loss: 2.6279391077487775

Epoch: 6| Step: 6
Training loss: 2.2700290363824176
Validation loss: 2.5948963772536824

Epoch: 6| Step: 7
Training loss: 2.8583135250135507
Validation loss: 2.6602263812484748

Epoch: 6| Step: 8
Training loss: 2.251804687689735
Validation loss: 2.6342014833309775

Epoch: 6| Step: 9
Training loss: 2.471396850174461
Validation loss: 2.612234045481764

Epoch: 6| Step: 10
Training loss: 2.829999271028782
Validation loss: 2.6519003615948593

Epoch: 6| Step: 11
Training loss: 2.212184486952927
Validation loss: 2.689982354556497

Epoch: 6| Step: 12
Training loss: 2.0515088924891147
Validation loss: 2.603991500049553

Epoch: 6| Step: 13
Training loss: 2.4890691207539066
Validation loss: 2.6389058553139106

Epoch: 25| Step: 0
Training loss: 2.5056765007193813
Validation loss: 2.6300675584240985

Epoch: 6| Step: 1
Training loss: 2.7354483105547427
Validation loss: 2.6621461988417865

Epoch: 6| Step: 2
Training loss: 2.9617934788861064
Validation loss: 2.5978555473800116

Epoch: 6| Step: 3
Training loss: 2.367822945793142
Validation loss: 2.613084330454806

Epoch: 6| Step: 4
Training loss: 1.8640105861395955
Validation loss: 2.6079539009829333

Epoch: 6| Step: 5
Training loss: 2.685750347405519
Validation loss: 2.656225952338775

Epoch: 6| Step: 6
Training loss: 3.127714732701452
Validation loss: 2.627939206033699

Epoch: 6| Step: 7
Training loss: 2.573035933681383
Validation loss: 2.644973184537377

Epoch: 6| Step: 8
Training loss: 2.4282736635786115
Validation loss: 2.6205350201697817

Epoch: 6| Step: 9
Training loss: 2.6387716256126965
Validation loss: 2.6520337619828407

Epoch: 6| Step: 10
Training loss: 2.914629270033889
Validation loss: 2.654015412704379

Epoch: 6| Step: 11
Training loss: 2.1660686792561297
Validation loss: 2.627837184306636

Epoch: 6| Step: 12
Training loss: 2.4184510669754085
Validation loss: 2.6135640734952053

Epoch: 6| Step: 13
Training loss: 2.2376618651761864
Validation loss: 2.63639061663862

Epoch: 26| Step: 0
Training loss: 2.6098573889813044
Validation loss: 2.6332006272143467

Epoch: 6| Step: 1
Training loss: 2.587001155367882
Validation loss: 2.618004651394086

Epoch: 6| Step: 2
Training loss: 1.989989201022804
Validation loss: 2.631103187144042

Epoch: 6| Step: 3
Training loss: 3.412638701250608
Validation loss: 2.616993759348018

Epoch: 6| Step: 4
Training loss: 2.4058179591336986
Validation loss: 2.6112464087403593

Epoch: 6| Step: 5
Training loss: 2.79138873030991
Validation loss: 2.6144530477903287

Epoch: 6| Step: 6
Training loss: 2.2974317226289016
Validation loss: 2.663285993394836

Epoch: 6| Step: 7
Training loss: 2.3715234709576927
Validation loss: 2.576882095518358

Epoch: 6| Step: 8
Training loss: 2.2570461569795883
Validation loss: 2.6195782042968334

Epoch: 6| Step: 9
Training loss: 2.3070540352434756
Validation loss: 2.682488448446098

Epoch: 6| Step: 10
Training loss: 1.79100677255088
Validation loss: 2.6056109174672817

Epoch: 6| Step: 11
Training loss: 3.526318643003929
Validation loss: 2.6182591611804567

Epoch: 6| Step: 12
Training loss: 2.8002151066033325
Validation loss: 2.613461703469268

Epoch: 6| Step: 13
Training loss: 2.2916786424728515
Validation loss: 2.6019299985503768

Epoch: 27| Step: 0
Training loss: 2.7635762875474827
Validation loss: 2.6146218701039143

Epoch: 6| Step: 1
Training loss: 2.960588661117399
Validation loss: 2.6103679115591176

Epoch: 6| Step: 2
Training loss: 2.8878353370050007
Validation loss: 2.605657941439662

Epoch: 6| Step: 3
Training loss: 3.2650794344669327
Validation loss: 2.621235130654751

Epoch: 6| Step: 4
Training loss: 2.0103023542672656
Validation loss: 2.6326583983226364

Epoch: 6| Step: 5
Training loss: 2.397899455503932
Validation loss: 2.6303612818799618

Epoch: 6| Step: 6
Training loss: 2.5827172272747965
Validation loss: 2.6660506212408492

Epoch: 6| Step: 7
Training loss: 1.8028511513758794
Validation loss: 2.652508273146249

Epoch: 6| Step: 8
Training loss: 1.9624010680707784
Validation loss: 2.635318103399675

Epoch: 6| Step: 9
Training loss: 2.3221597735613573
Validation loss: 2.636768918914114

Epoch: 6| Step: 10
Training loss: 2.7862977929378214
Validation loss: 2.681276967728873

Epoch: 6| Step: 11
Training loss: 2.611197925594385
Validation loss: 2.6287084829111746

Epoch: 6| Step: 12
Training loss: 2.6482929201525605
Validation loss: 2.6435101489723714

Epoch: 6| Step: 13
Training loss: 2.996162980733308
Validation loss: 2.6447745530089506

Epoch: 28| Step: 0
Training loss: 2.33661205541741
Validation loss: 2.6457643925453374

Epoch: 6| Step: 1
Training loss: 2.3984758703287627
Validation loss: 2.620143272714604

Epoch: 6| Step: 2
Training loss: 2.764666116294809
Validation loss: 2.6075573375246024

Epoch: 6| Step: 3
Training loss: 2.15256350965214
Validation loss: 2.608909123723316

Epoch: 6| Step: 4
Training loss: 2.7627382029025296
Validation loss: 2.592542911298251

Epoch: 6| Step: 5
Training loss: 2.2595187277341706
Validation loss: 2.6294812144776105

Epoch: 6| Step: 6
Training loss: 2.7714080692510468
Validation loss: 2.635770213621337

Epoch: 6| Step: 7
Training loss: 2.5875957968849463
Validation loss: 2.615405623375335

Epoch: 6| Step: 8
Training loss: 2.6422495161884956
Validation loss: 2.67743851696461

Epoch: 6| Step: 9
Training loss: 2.853138443746993
Validation loss: 2.581122842139757

Epoch: 6| Step: 10
Training loss: 2.5623801598787472
Validation loss: 2.6343407878713143

Epoch: 6| Step: 11
Training loss: 2.694972716212836
Validation loss: 2.5508643736057244

Epoch: 6| Step: 12
Training loss: 2.2747080814747447
Validation loss: 2.6106062399875323

Epoch: 6| Step: 13
Training loss: 2.524120132186942
Validation loss: 2.5446830787762384

Epoch: 29| Step: 0
Training loss: 2.3472942765090674
Validation loss: 2.5975403035610367

Epoch: 6| Step: 1
Training loss: 1.5878408501625552
Validation loss: 2.624135313972354

Epoch: 6| Step: 2
Training loss: 1.840312274473581
Validation loss: 2.618754495694255

Epoch: 6| Step: 3
Training loss: 2.147920969512606
Validation loss: 2.593233876793246

Epoch: 6| Step: 4
Training loss: 3.1945208849030915
Validation loss: 2.586505162991318

Epoch: 6| Step: 5
Training loss: 3.4120427143155703
Validation loss: 2.6562820432637566

Epoch: 6| Step: 6
Training loss: 1.8950736930830885
Validation loss: 2.6071358322613776

Epoch: 6| Step: 7
Training loss: 2.924448766689076
Validation loss: 2.5864576755809114

Epoch: 6| Step: 8
Training loss: 3.070110285266034
Validation loss: 2.662895625753596

Epoch: 6| Step: 9
Training loss: 1.8839875033180797
Validation loss: 2.6317675334507853

Epoch: 6| Step: 10
Training loss: 2.7537521427404212
Validation loss: 2.634587324522431

Epoch: 6| Step: 11
Training loss: 2.639767479338039
Validation loss: 2.5968743010212814

Epoch: 6| Step: 12
Training loss: 2.6124213247909793
Validation loss: 2.609503813284282

Epoch: 6| Step: 13
Training loss: 2.6044614294443638
Validation loss: 2.574010845427252

Epoch: 30| Step: 0
Training loss: 2.647935847931506
Validation loss: 2.634099070562574

Epoch: 6| Step: 1
Training loss: 2.93721623774875
Validation loss: 2.60885246359557

Epoch: 6| Step: 2
Training loss: 2.469051680662482
Validation loss: 2.662831354789654

Epoch: 6| Step: 3
Training loss: 2.494262883498997
Validation loss: 2.607883171585217

Epoch: 6| Step: 4
Training loss: 2.535779973259593
Validation loss: 2.654724430982156

Epoch: 6| Step: 5
Training loss: 2.6395626301142956
Validation loss: 2.5528643496443637

Epoch: 6| Step: 6
Training loss: 2.16349371861709
Validation loss: 2.563841840604632

Epoch: 6| Step: 7
Training loss: 1.9922828801079775
Validation loss: 2.5686480573859085

Epoch: 6| Step: 8
Training loss: 3.2456133655712005
Validation loss: 2.577044898455555

Epoch: 6| Step: 9
Training loss: 2.644471836972235
Validation loss: 2.6120884962137882

Epoch: 6| Step: 10
Training loss: 2.8173091039155813
Validation loss: 2.583436968990887

Epoch: 6| Step: 11
Training loss: 1.7701550998729465
Validation loss: 2.617377461234207

Epoch: 6| Step: 12
Training loss: 2.2559105276938536
Validation loss: 2.6065643233828846

Epoch: 6| Step: 13
Training loss: 2.195556735642477
Validation loss: 2.5281580655230815

Epoch: 31| Step: 0
Training loss: 1.905192472691856
Validation loss: 2.547643705413389

Epoch: 6| Step: 1
Training loss: 2.6289787112448186
Validation loss: 2.5999747654105976

Epoch: 6| Step: 2
Training loss: 1.8715972541490546
Validation loss: 2.597703609178248

Epoch: 6| Step: 3
Training loss: 2.770736797821387
Validation loss: 2.609755322727652

Epoch: 6| Step: 4
Training loss: 2.5150911700672007
Validation loss: 2.5775933844653713

Epoch: 6| Step: 5
Training loss: 3.1190267313954956
Validation loss: 2.582645252841422

Epoch: 6| Step: 6
Training loss: 1.807017881852776
Validation loss: 2.600296002435645

Epoch: 6| Step: 7
Training loss: 2.4955763780618363
Validation loss: 2.604304444800938

Epoch: 6| Step: 8
Training loss: 2.8579952058531672
Validation loss: 2.653848272855771

Epoch: 6| Step: 9
Training loss: 1.974197963639891
Validation loss: 2.5787330912141844

Epoch: 6| Step: 10
Training loss: 2.6613103796836097
Validation loss: 2.593785925313806

Epoch: 6| Step: 11
Training loss: 3.111108344697479
Validation loss: 2.6126536635939734

Epoch: 6| Step: 12
Training loss: 2.940568335997631
Validation loss: 2.5906242548531573

Epoch: 6| Step: 13
Training loss: 2.5760042658053792
Validation loss: 2.5482248734853057

Epoch: 32| Step: 0
Training loss: 3.3927535306555043
Validation loss: 2.6128956691324277

Epoch: 6| Step: 1
Training loss: 1.727227130543589
Validation loss: 2.6404431824097445

Epoch: 6| Step: 2
Training loss: 1.922833087574717
Validation loss: 2.5776215495208605

Epoch: 6| Step: 3
Training loss: 2.3674445185862294
Validation loss: 2.6098790167395722

Epoch: 6| Step: 4
Training loss: 2.1535751780152186
Validation loss: 2.623630348010735

Epoch: 6| Step: 5
Training loss: 2.6455970318219584
Validation loss: 2.581442203554972

Epoch: 6| Step: 6
Training loss: 2.4752502815778885
Validation loss: 2.563406125024347

Epoch: 6| Step: 7
Training loss: 2.8408109127766457
Validation loss: 2.600860592659424

Epoch: 6| Step: 8
Training loss: 3.15741942241724
Validation loss: 2.6146725845808136

Epoch: 6| Step: 9
Training loss: 3.0497745117883563
Validation loss: 2.6190244538451077

Epoch: 6| Step: 10
Training loss: 2.575718351735263
Validation loss: 2.6319919896144

Epoch: 6| Step: 11
Training loss: 2.483169263075075
Validation loss: 2.6109322414501235

Epoch: 6| Step: 12
Training loss: 1.941233145597039
Validation loss: 2.628704076496738

Epoch: 6| Step: 13
Training loss: 2.037045939583382
Validation loss: 2.5662865922923137

Epoch: 33| Step: 0
Training loss: 2.105927992297038
Validation loss: 2.555709276782086

Epoch: 6| Step: 1
Training loss: 2.6393387951943326
Validation loss: 2.5483412939046697

Epoch: 6| Step: 2
Training loss: 2.680453621919748
Validation loss: 2.5870517661901298

Epoch: 6| Step: 3
Training loss: 2.4633982148184055
Validation loss: 2.6137211405156475

Epoch: 6| Step: 4
Training loss: 2.3820309217033024
Validation loss: 2.584907042149634

Epoch: 6| Step: 5
Training loss: 1.914508253859319
Validation loss: 2.5917877680051475

Epoch: 6| Step: 6
Training loss: 2.3676540808805253
Validation loss: 2.63582264684472

Epoch: 6| Step: 7
Training loss: 2.5384126271690906
Validation loss: 2.584700304781488

Epoch: 6| Step: 8
Training loss: 2.4167833519312647
Validation loss: 2.590738777634756

Epoch: 6| Step: 9
Training loss: 1.768306687406262
Validation loss: 2.577508502037217

Epoch: 6| Step: 10
Training loss: 2.32188049151463
Validation loss: 2.559659298239348

Epoch: 6| Step: 11
Training loss: 3.500646531471817
Validation loss: 2.5510940398923654

Epoch: 6| Step: 12
Training loss: 2.62794365909283
Validation loss: 2.557905404484023

Epoch: 6| Step: 13
Training loss: 2.885502746252863
Validation loss: 2.5684617634950087

Epoch: 34| Step: 0
Training loss: 3.383689995618717
Validation loss: 2.5886336040992104

Epoch: 6| Step: 1
Training loss: 2.765034068278848
Validation loss: 2.5613952829596274

Epoch: 6| Step: 2
Training loss: 1.9910112087177576
Validation loss: 2.6004562698948304

Epoch: 6| Step: 3
Training loss: 2.9895517877028692
Validation loss: 2.649152376060984

Epoch: 6| Step: 4
Training loss: 2.32358718112871
Validation loss: 2.5695588959872677

Epoch: 6| Step: 5
Training loss: 2.902047348803473
Validation loss: 2.611591912591204

Epoch: 6| Step: 6
Training loss: 2.509061793333052
Validation loss: 2.5879755430864226

Epoch: 6| Step: 7
Training loss: 2.0915584196777304
Validation loss: 2.5958318513362895

Epoch: 6| Step: 8
Training loss: 2.3069974024195408
Validation loss: 2.559217785550692

Epoch: 6| Step: 9
Training loss: 1.7313815566113595
Validation loss: 2.6383658908667407

Epoch: 6| Step: 10
Training loss: 1.8158600016586575
Validation loss: 2.626814169913444

Epoch: 6| Step: 11
Training loss: 2.4185001608970955
Validation loss: 2.6222812106031457

Epoch: 6| Step: 12
Training loss: 2.4287943777760606
Validation loss: 2.629379705955768

Epoch: 6| Step: 13
Training loss: 3.0145258506315677
Validation loss: 2.62499235545665

Epoch: 35| Step: 0
Training loss: 2.0378126501309417
Validation loss: 2.6226534573264844

Epoch: 6| Step: 1
Training loss: 3.617631987910209
Validation loss: 2.5981863298443097

Epoch: 6| Step: 2
Training loss: 2.2475734977882715
Validation loss: 2.6504815689709735

Epoch: 6| Step: 3
Training loss: 1.4812310905698187
Validation loss: 2.619434587678762

Epoch: 6| Step: 4
Training loss: 2.8237420783875335
Validation loss: 2.6309243061801006

Epoch: 6| Step: 5
Training loss: 2.465299391912949
Validation loss: 2.6618456524469187

Epoch: 6| Step: 6
Training loss: 2.9037867125589116
Validation loss: 2.6064565178811447

Epoch: 6| Step: 7
Training loss: 2.4451335804963596
Validation loss: 2.635201303379842

Epoch: 6| Step: 8
Training loss: 1.7581560265454197
Validation loss: 2.631556081902566

Epoch: 6| Step: 9
Training loss: 2.11244735200725
Validation loss: 2.5656052824463806

Epoch: 6| Step: 10
Training loss: 2.5306007588724193
Validation loss: 2.5599331909641134

Epoch: 6| Step: 11
Training loss: 2.4304612083894366
Validation loss: 2.597416044903289

Epoch: 6| Step: 12
Training loss: 2.855603675420351
Validation loss: 2.6047863388301966

Epoch: 6| Step: 13
Training loss: 2.6555966639651056
Validation loss: 2.6126799526021176

Epoch: 36| Step: 0
Training loss: 2.6550406900797214
Validation loss: 2.570945901328019

Epoch: 6| Step: 1
Training loss: 2.7539368106959006
Validation loss: 2.5249766408513348

Epoch: 6| Step: 2
Training loss: 2.4542262041504888
Validation loss: 2.5494743765349908

Epoch: 6| Step: 3
Training loss: 2.0711290584563353
Validation loss: 2.52777099142689

Epoch: 6| Step: 4
Training loss: 2.4687293329460287
Validation loss: 2.5836559576161133

Epoch: 6| Step: 5
Training loss: 3.4890223417520727
Validation loss: 2.5983988606295805

Epoch: 6| Step: 6
Training loss: 2.535336245596403
Validation loss: 2.571141659029371

Epoch: 6| Step: 7
Training loss: 2.758556233261419
Validation loss: 2.5493429041690145

Epoch: 6| Step: 8
Training loss: 1.9966014358275375
Validation loss: 2.5584449317109432

Epoch: 6| Step: 9
Training loss: 2.06190863714564
Validation loss: 2.566270558540755

Epoch: 6| Step: 10
Training loss: 1.8797609284757135
Validation loss: 2.60095404763935

Epoch: 6| Step: 11
Training loss: 3.125304550589518
Validation loss: 2.5644622670863164

Epoch: 6| Step: 12
Training loss: 2.3551152661536796
Validation loss: 2.605951480860759

Epoch: 6| Step: 13
Training loss: 1.661511682433144
Validation loss: 2.5916531371308302

Epoch: 37| Step: 0
Training loss: 2.3397459286730657
Validation loss: 2.57568135675752

Epoch: 6| Step: 1
Training loss: 2.465178405000629
Validation loss: 2.5856044589400793

Epoch: 6| Step: 2
Training loss: 3.1063060855215543
Validation loss: 2.582804646281021

Epoch: 6| Step: 3
Training loss: 1.7255986487930235
Validation loss: 2.562001187536921

Epoch: 6| Step: 4
Training loss: 2.0422439018697354
Validation loss: 2.580868873445917

Epoch: 6| Step: 5
Training loss: 2.369539005658003
Validation loss: 2.568512043446539

Epoch: 6| Step: 6
Training loss: 2.3745932983717695
Validation loss: 2.543017869856803

Epoch: 6| Step: 7
Training loss: 2.790768739900699
Validation loss: 2.6008309222545

Epoch: 6| Step: 8
Training loss: 2.5322427568899823
Validation loss: 2.5491364469188724

Epoch: 6| Step: 9
Training loss: 2.3436099201303007
Validation loss: 2.5736473888848965

Epoch: 6| Step: 10
Training loss: 2.0465474339814684
Validation loss: 2.5441294187969317

Epoch: 6| Step: 11
Training loss: 3.2972906492467953
Validation loss: 2.6306275187926147

Epoch: 6| Step: 12
Training loss: 2.551513566752731
Validation loss: 2.5994716792201658

Epoch: 6| Step: 13
Training loss: 2.552718590802148
Validation loss: 2.573530862578082

Epoch: 38| Step: 0
Training loss: 2.3155587046575987
Validation loss: 2.583989926440599

Epoch: 6| Step: 1
Training loss: 2.5431856921311593
Validation loss: 2.5757724856303805

Epoch: 6| Step: 2
Training loss: 2.7213247099868583
Validation loss: 2.580372164323158

Epoch: 6| Step: 3
Training loss: 2.39226082079626
Validation loss: 2.6126752529955493

Epoch: 6| Step: 4
Training loss: 2.0893812006368555
Validation loss: 2.560118374831985

Epoch: 6| Step: 5
Training loss: 2.4741860910614433
Validation loss: 2.658966829240076

Epoch: 6| Step: 6
Training loss: 2.2677156470733815
Validation loss: 2.6128649795846934

Epoch: 6| Step: 7
Training loss: 2.538669497078966
Validation loss: 2.6139035702747

Epoch: 6| Step: 8
Training loss: 2.5780123599328046
Validation loss: 2.5895075898718165

Epoch: 6| Step: 9
Training loss: 2.4590479787246773
Validation loss: 2.638135515276556

Epoch: 6| Step: 10
Training loss: 3.0043884604628452
Validation loss: 2.6422532759017

Epoch: 6| Step: 11
Training loss: 2.557436709100956
Validation loss: 2.639503722481916

Epoch: 6| Step: 12
Training loss: 2.144227386793013
Validation loss: 2.5861476954904417

Epoch: 6| Step: 13
Training loss: 2.7481329388619837
Validation loss: 2.5473874752510977

Epoch: 39| Step: 0
Training loss: 2.779093817385678
Validation loss: 2.5876831355376932

Epoch: 6| Step: 1
Training loss: 2.9596978564318333
Validation loss: 2.5806607655308524

Epoch: 6| Step: 2
Training loss: 2.6013902945129144
Validation loss: 2.6090611556520273

Epoch: 6| Step: 3
Training loss: 2.162418222810522
Validation loss: 2.516598578241464

Epoch: 6| Step: 4
Training loss: 2.1576766670891465
Validation loss: 2.5491497046421867

Epoch: 6| Step: 5
Training loss: 2.008296566807364
Validation loss: 2.611820894404951

Epoch: 6| Step: 6
Training loss: 2.8079716148571996
Validation loss: 2.587571379925531

Epoch: 6| Step: 7
Training loss: 2.6222998037373895
Validation loss: 2.640490376127533

Epoch: 6| Step: 8
Training loss: 1.9202771251080233
Validation loss: 2.583059993762464

Epoch: 6| Step: 9
Training loss: 2.4298422417627727
Validation loss: 2.57972219294805

Epoch: 6| Step: 10
Training loss: 2.290918424581805
Validation loss: 2.610527515011376

Epoch: 6| Step: 11
Training loss: 2.5460095953809225
Validation loss: 2.571286790776508

Epoch: 6| Step: 12
Training loss: 2.07881784003807
Validation loss: 2.5834336927875086

Epoch: 6| Step: 13
Training loss: 2.607701844461313
Validation loss: 2.581065079389906

Epoch: 40| Step: 0
Training loss: 2.371145634342753
Validation loss: 2.546886436265104

Epoch: 6| Step: 1
Training loss: 3.0109637510207485
Validation loss: 2.6449642606362627

Epoch: 6| Step: 2
Training loss: 2.3505317735632234
Validation loss: 2.588053748789686

Epoch: 6| Step: 3
Training loss: 2.0254477159037254
Validation loss: 2.590182397794841

Epoch: 6| Step: 4
Training loss: 2.2367420596374803
Validation loss: 2.569708903051634

Epoch: 6| Step: 5
Training loss: 2.286240644816451
Validation loss: 2.666052186223853

Epoch: 6| Step: 6
Training loss: 2.3876813330367863
Validation loss: 2.557746696519003

Epoch: 6| Step: 7
Training loss: 2.822686123788859
Validation loss: 2.6037592963438687

Epoch: 6| Step: 8
Training loss: 3.1982751369963016
Validation loss: 2.6109245633273375

Epoch: 6| Step: 9
Training loss: 2.3935678357962002
Validation loss: 2.618552281966221

Epoch: 6| Step: 10
Training loss: 2.7514878496293083
Validation loss: 2.548210495989795

Epoch: 6| Step: 11
Training loss: 2.8997850601519706
Validation loss: 2.57527919107566

Epoch: 6| Step: 12
Training loss: 2.4704157364353954
Validation loss: 2.552993391575561

Epoch: 6| Step: 13
Training loss: 1.5624705502595775
Validation loss: 2.582125709641071

Epoch: 41| Step: 0
Training loss: 2.0610810224810887
Validation loss: 2.6219638037997153

Epoch: 6| Step: 1
Training loss: 2.8643252354726463
Validation loss: 2.5190711969079493

Epoch: 6| Step: 2
Training loss: 2.2724943006924545
Validation loss: 2.5583406978422483

Epoch: 6| Step: 3
Training loss: 2.4646583160920676
Validation loss: 2.533743834698978

Epoch: 6| Step: 4
Training loss: 2.043153364253609
Validation loss: 2.585669527642462

Epoch: 6| Step: 5
Training loss: 2.7155930178112127
Validation loss: 2.5747312461080396

Epoch: 6| Step: 6
Training loss: 2.7896422737244184
Validation loss: 2.58262035826742

Epoch: 6| Step: 7
Training loss: 3.114867300571711
Validation loss: 2.5724171811320113

Epoch: 6| Step: 8
Training loss: 2.512918663253923
Validation loss: 2.6019624511478305

Epoch: 6| Step: 9
Training loss: 2.2867870282821983
Validation loss: 2.583240035638592

Epoch: 6| Step: 10
Training loss: 2.1664626930276834
Validation loss: 2.608324977954811

Epoch: 6| Step: 11
Training loss: 2.2523340199207755
Validation loss: 2.558968296737134

Epoch: 6| Step: 12
Training loss: 2.3792301452327758
Validation loss: 2.6567684340838515

Epoch: 6| Step: 13
Training loss: 2.668784780521358
Validation loss: 2.5438858620792524

Epoch: 42| Step: 0
Training loss: 2.050427680644569
Validation loss: 2.6352820280359417

Epoch: 6| Step: 1
Training loss: 2.5549292027169748
Validation loss: 2.593250647892153

Epoch: 6| Step: 2
Training loss: 2.259029284945571
Validation loss: 2.543566905437586

Epoch: 6| Step: 3
Training loss: 2.644791245181899
Validation loss: 2.586039346185658

Epoch: 6| Step: 4
Training loss: 2.9451321412574636
Validation loss: 2.5374971230025496

Epoch: 6| Step: 5
Training loss: 2.734560017457051
Validation loss: 2.581730581255421

Epoch: 6| Step: 6
Training loss: 2.1096091811557884
Validation loss: 2.551569740361447

Epoch: 6| Step: 7
Training loss: 2.4136729497084515
Validation loss: 2.597832136963689

Epoch: 6| Step: 8
Training loss: 1.5511238238640455
Validation loss: 2.575254765348547

Epoch: 6| Step: 9
Training loss: 3.2451850730185003
Validation loss: 2.5548040769772746

Epoch: 6| Step: 10
Training loss: 2.851242590948544
Validation loss: 2.5435849491594125

Epoch: 6| Step: 11
Training loss: 2.7470066946008496
Validation loss: 2.5651986093449635

Epoch: 6| Step: 12
Training loss: 1.8791171330297631
Validation loss: 2.578743168866048

Epoch: 6| Step: 13
Training loss: 2.2337005237464482
Validation loss: 2.54056413115423

Epoch: 43| Step: 0
Training loss: 2.4781032065819866
Validation loss: 2.5694836378688177

Epoch: 6| Step: 1
Training loss: 2.7125294872737946
Validation loss: 2.5653822746489077

Epoch: 6| Step: 2
Training loss: 2.237957729639257
Validation loss: 2.532169630237195

Epoch: 6| Step: 3
Training loss: 1.8362746558147351
Validation loss: 2.6326062190503774

Epoch: 6| Step: 4
Training loss: 2.697510461654387
Validation loss: 2.624203273420548

Epoch: 6| Step: 5
Training loss: 3.020833947192601
Validation loss: 2.6283781173928733

Epoch: 6| Step: 6
Training loss: 2.410185926554531
Validation loss: 2.6858265568143422

Epoch: 6| Step: 7
Training loss: 2.7162327129236985
Validation loss: 2.5165206704728647

Epoch: 6| Step: 8
Training loss: 2.753603828003487
Validation loss: 2.624734380695253

Epoch: 6| Step: 9
Training loss: 2.1874716620653323
Validation loss: 2.6117986817660954

Epoch: 6| Step: 10
Training loss: 1.9965398181791796
Validation loss: 2.5966036315468686

Epoch: 6| Step: 11
Training loss: 2.147742696599362
Validation loss: 2.610346569470845

Epoch: 6| Step: 12
Training loss: 2.9025045891987533
Validation loss: 2.588355379418069

Epoch: 6| Step: 13
Training loss: 2.4666112979482633
Validation loss: 2.5815778633377504

Epoch: 44| Step: 0
Training loss: 3.2516943109752505
Validation loss: 2.5977258352649226

Epoch: 6| Step: 1
Training loss: 2.2953496526174386
Validation loss: 2.500729430596394

Epoch: 6| Step: 2
Training loss: 2.683680992429692
Validation loss: 2.5902143839378833

Epoch: 6| Step: 3
Training loss: 3.0210156265152643
Validation loss: 2.6258191541141427

Epoch: 6| Step: 4
Training loss: 2.208002737478964
Validation loss: 2.549488980693586

Epoch: 6| Step: 5
Training loss: 2.680454066655216
Validation loss: 2.5543808437075537

Epoch: 6| Step: 6
Training loss: 2.8008862931944924
Validation loss: 2.5629222180881035

Epoch: 6| Step: 7
Training loss: 2.1323031421595466
Validation loss: 2.542603348801109

Epoch: 6| Step: 8
Training loss: 2.5378033611695328
Validation loss: 2.5743276199681793

Epoch: 6| Step: 9
Training loss: 1.6536678843392183
Validation loss: 2.5619155403348732

Epoch: 6| Step: 10
Training loss: 2.6393697791259063
Validation loss: 2.57209790029829

Epoch: 6| Step: 11
Training loss: 2.010572740363604
Validation loss: 2.6061987971727567

Epoch: 6| Step: 12
Training loss: 2.2388659607265677
Validation loss: 2.553492936602558

Epoch: 6| Step: 13
Training loss: 2.147700068754282
Validation loss: 2.5666913435934573

Epoch: 45| Step: 0
Training loss: 2.1158376522052684
Validation loss: 2.572394968081479

Epoch: 6| Step: 1
Training loss: 2.283885113206693
Validation loss: 2.535053480325304

Epoch: 6| Step: 2
Training loss: 2.7734015663935363
Validation loss: 2.5862068120547166

Epoch: 6| Step: 3
Training loss: 2.147270967928988
Validation loss: 2.570335766842554

Epoch: 6| Step: 4
Training loss: 2.5126492925670596
Validation loss: 2.5681931590553364

Epoch: 6| Step: 5
Training loss: 2.030255118063094
Validation loss: 2.586131093441633

Epoch: 6| Step: 6
Training loss: 2.526452309700969
Validation loss: 2.5838347276570137

Epoch: 6| Step: 7
Training loss: 2.3738501927673146
Validation loss: 2.569157751659558

Epoch: 6| Step: 8
Training loss: 2.2477650668759668
Validation loss: 2.638312536733198

Epoch: 6| Step: 9
Training loss: 2.597350964497459
Validation loss: 2.572274237260857

Epoch: 6| Step: 10
Training loss: 3.1207884829005765
Validation loss: 2.5784667433992627

Epoch: 6| Step: 11
Training loss: 2.562756037132558
Validation loss: 2.6164511028920594

Epoch: 6| Step: 12
Training loss: 2.648420665766235
Validation loss: 2.5462178199568575

Epoch: 6| Step: 13
Training loss: 2.4730486565973484
Validation loss: 2.583483527544763

Epoch: 46| Step: 0
Training loss: 2.738213074361944
Validation loss: 2.5497462464278864

Epoch: 6| Step: 1
Training loss: 1.8096049635359523
Validation loss: 2.589222967392897

Epoch: 6| Step: 2
Training loss: 2.281258988036125
Validation loss: 2.557625468443265

Epoch: 6| Step: 3
Training loss: 2.2152557797138606
Validation loss: 2.543488917593649

Epoch: 6| Step: 4
Training loss: 2.829817797453516
Validation loss: 2.535460866722019

Epoch: 6| Step: 5
Training loss: 2.741960130269503
Validation loss: 2.592048439249273

Epoch: 6| Step: 6
Training loss: 3.189590367052598
Validation loss: 2.550512364904268

Epoch: 6| Step: 7
Training loss: 2.310262473911624
Validation loss: 2.574527133497629

Epoch: 6| Step: 8
Training loss: 2.74925499274562
Validation loss: 2.589875955127306

Epoch: 6| Step: 9
Training loss: 3.0903190314769433
Validation loss: 2.5517166704709706

Epoch: 6| Step: 10
Training loss: 1.9532159402656588
Validation loss: 2.634483162019672

Epoch: 6| Step: 11
Training loss: 2.559092232869978
Validation loss: 2.5679655326696995

Epoch: 6| Step: 12
Training loss: 1.9204883690451804
Validation loss: 2.6031185609540186

Epoch: 6| Step: 13
Training loss: 1.8959041065238593
Validation loss: 2.5484726152431234

Epoch: 47| Step: 0
Training loss: 1.7555175720135054
Validation loss: 2.550072112341589

Epoch: 6| Step: 1
Training loss: 2.701385291020063
Validation loss: 2.6200901162323302

Epoch: 6| Step: 2
Training loss: 2.3784051877960586
Validation loss: 2.571668149494857

Epoch: 6| Step: 3
Training loss: 2.098484550624618
Validation loss: 2.5791070782295398

Epoch: 6| Step: 4
Training loss: 2.9481844471511325
Validation loss: 2.641669253118394

Epoch: 6| Step: 5
Training loss: 1.9584277380515416
Validation loss: 2.5769527968639263

Epoch: 6| Step: 6
Training loss: 2.081545431344573
Validation loss: 2.6561525962772716

Epoch: 6| Step: 7
Training loss: 2.910607793198884
Validation loss: 2.6098421253551836

Epoch: 6| Step: 8
Training loss: 2.6398027031318843
Validation loss: 2.619081015291361

Epoch: 6| Step: 9
Training loss: 2.352449978368577
Validation loss: 2.601154528333403

Epoch: 6| Step: 10
Training loss: 2.725672273214977
Validation loss: 2.6284425353895204

Epoch: 6| Step: 11
Training loss: 2.488949001907078
Validation loss: 2.5826796940427537

Epoch: 6| Step: 12
Training loss: 2.9807466349916694
Validation loss: 2.567966847950465

Epoch: 6| Step: 13
Training loss: 2.0338840718498705
Validation loss: 2.586978337934369

Epoch: 48| Step: 0
Training loss: 2.3388230480894996
Validation loss: 2.561122058597685

Epoch: 6| Step: 1
Training loss: 2.4025583062852185
Validation loss: 2.6317314396143305

Epoch: 6| Step: 2
Training loss: 2.8119653829448845
Validation loss: 2.5809531526852627

Epoch: 6| Step: 3
Training loss: 2.2169859414831405
Validation loss: 2.565008703220764

Epoch: 6| Step: 4
Training loss: 1.6014797282345752
Validation loss: 2.6072360959584704

Epoch: 6| Step: 5
Training loss: 3.194334146189501
Validation loss: 2.597929578278451

Epoch: 6| Step: 6
Training loss: 2.355099271070993
Validation loss: 2.610106908062952

Epoch: 6| Step: 7
Training loss: 2.859432032282147
Validation loss: 2.542326596578706

Epoch: 6| Step: 8
Training loss: 2.018042246048367
Validation loss: 2.5987543065492766

Epoch: 6| Step: 9
Training loss: 1.638232857749385
Validation loss: 2.5901907740604027

Epoch: 6| Step: 10
Training loss: 2.3173347657853687
Validation loss: 2.5932716786509293

Epoch: 6| Step: 11
Training loss: 2.5608775887687805
Validation loss: 2.5393137020167798

Epoch: 6| Step: 12
Training loss: 3.169039055094595
Validation loss: 2.61093309372797

Epoch: 6| Step: 13
Training loss: 2.146579452227791
Validation loss: 2.585330196495114

Epoch: 49| Step: 0
Training loss: 2.4578083792504595
Validation loss: 2.551006873815017

Epoch: 6| Step: 1
Training loss: 2.9724560543626524
Validation loss: 2.4984340054581224

Epoch: 6| Step: 2
Training loss: 1.9331337738084668
Validation loss: 2.5514202320423536

Epoch: 6| Step: 3
Training loss: 2.5759604875602578
Validation loss: 2.5942134060209465

Epoch: 6| Step: 4
Training loss: 2.5640538784442386
Validation loss: 2.4881068337722847

Epoch: 6| Step: 5
Training loss: 2.632535925581092
Validation loss: 2.520205558814641

Epoch: 6| Step: 6
Training loss: 1.7023512456272851
Validation loss: 2.576723307258028

Epoch: 6| Step: 7
Training loss: 2.5643374670463053
Validation loss: 2.5519300038475494

Epoch: 6| Step: 8
Training loss: 2.9574672523678305
Validation loss: 2.5559283867983806

Epoch: 6| Step: 9
Training loss: 2.448162721212316
Validation loss: 2.5405884368254967

Epoch: 6| Step: 10
Training loss: 2.488434168549784
Validation loss: 2.571004841945228

Epoch: 6| Step: 11
Training loss: 2.548466097673024
Validation loss: 2.5618312862550945

Epoch: 6| Step: 12
Training loss: 2.438191731431302
Validation loss: 2.592739061413867

Epoch: 6| Step: 13
Training loss: 2.6427518867830204
Validation loss: 2.5672395960544083

Epoch: 50| Step: 0
Training loss: 2.1318731789649648
Validation loss: 2.565321400281879

Epoch: 6| Step: 1
Training loss: 2.524374206346395
Validation loss: 2.510618887600981

Epoch: 6| Step: 2
Training loss: 2.2604153423627733
Validation loss: 2.556010487970237

Epoch: 6| Step: 3
Training loss: 2.178472912010392
Validation loss: 2.567883303073394

Epoch: 6| Step: 4
Training loss: 2.956597441243131
Validation loss: 2.6018586548643015

Epoch: 6| Step: 5
Training loss: 2.734040158069647
Validation loss: 2.6668781827447683

Epoch: 6| Step: 6
Training loss: 2.110081307168937
Validation loss: 2.5629714284061644

Epoch: 6| Step: 7
Training loss: 2.408639390323086
Validation loss: 2.5343405455078973

Epoch: 6| Step: 8
Training loss: 1.7843154496445779
Validation loss: 2.56869827181298

Epoch: 6| Step: 9
Training loss: 2.5017286999572312
Validation loss: 2.577566144077889

Epoch: 6| Step: 10
Training loss: 3.144630117816857
Validation loss: 2.582160719464461

Epoch: 6| Step: 11
Training loss: 2.977574294129869
Validation loss: 2.522090839917011

Epoch: 6| Step: 12
Training loss: 1.7882327358586285
Validation loss: 2.543884331282862

Epoch: 6| Step: 13
Training loss: 2.5117449484685395
Validation loss: 2.5986524770155848

Epoch: 51| Step: 0
Training loss: 2.984976982398561
Validation loss: 2.5494862531356333

Epoch: 6| Step: 1
Training loss: 1.4723063490881187
Validation loss: 2.5204930719503507

Epoch: 6| Step: 2
Training loss: 2.2113786129291517
Validation loss: 2.5752256177310806

Epoch: 6| Step: 3
Training loss: 1.484679742952227
Validation loss: 2.5889836221242977

Epoch: 6| Step: 4
Training loss: 3.092324130609138
Validation loss: 2.595268540351712

Epoch: 6| Step: 5
Training loss: 1.9391082733678142
Validation loss: 2.529629726429562

Epoch: 6| Step: 6
Training loss: 2.8466031360311717
Validation loss: 2.6166655518191284

Epoch: 6| Step: 7
Training loss: 2.3931759457210275
Validation loss: 2.571252583323312

Epoch: 6| Step: 8
Training loss: 2.6879539993414476
Validation loss: 2.5823386082005904

Epoch: 6| Step: 9
Training loss: 2.1542924481482166
Validation loss: 2.57901572821659

Epoch: 6| Step: 10
Training loss: 2.4720168891626075
Validation loss: 2.5612347278105516

Epoch: 6| Step: 11
Training loss: 2.594038246408122
Validation loss: 2.5612450449721695

Epoch: 6| Step: 12
Training loss: 2.725049317639836
Validation loss: 2.5848822615943132

Epoch: 6| Step: 13
Training loss: 2.685160572358183
Validation loss: 2.573287633389607

Epoch: 52| Step: 0
Training loss: 3.1138057865151536
Validation loss: 2.5022879621400875

Epoch: 6| Step: 1
Training loss: 2.3198372196771824
Validation loss: 2.5647526120909627

Epoch: 6| Step: 2
Training loss: 2.539197618850668
Validation loss: 2.6073185170389186

Epoch: 6| Step: 3
Training loss: 3.0151641968003986
Validation loss: 2.6297035009781697

Epoch: 6| Step: 4
Training loss: 1.998689937679174
Validation loss: 2.560245576692603

Epoch: 6| Step: 5
Training loss: 2.090596115300507
Validation loss: 2.5318718448576254

Epoch: 6| Step: 6
Training loss: 2.0923146124494476
Validation loss: 2.6204087508313494

Epoch: 6| Step: 7
Training loss: 2.135626309656507
Validation loss: 2.5739193454220106

Epoch: 6| Step: 8
Training loss: 2.1670518190448935
Validation loss: 2.538794071973843

Epoch: 6| Step: 9
Training loss: 2.026773537946727
Validation loss: 2.6287479286832656

Epoch: 6| Step: 10
Training loss: 2.8471351010606094
Validation loss: 2.594710130200406

Epoch: 6| Step: 11
Training loss: 2.3660852868838753
Validation loss: 2.5408455168433104

Epoch: 6| Step: 12
Training loss: 2.1796600449449772
Validation loss: 2.5916855497582034

Epoch: 6| Step: 13
Training loss: 3.0826361271732527
Validation loss: 2.5948282168547805

Epoch: 53| Step: 0
Training loss: 2.0481218806299197
Validation loss: 2.649957361418101

Epoch: 6| Step: 1
Training loss: 2.854930487753561
Validation loss: 2.587932282118537

Epoch: 6| Step: 2
Training loss: 2.644430454423729
Validation loss: 2.691202732727683

Epoch: 6| Step: 3
Training loss: 1.667252898430661
Validation loss: 2.6217152919330053

Epoch: 6| Step: 4
Training loss: 2.7084222827878697
Validation loss: 2.6569928719914655

Epoch: 6| Step: 5
Training loss: 2.221101616071632
Validation loss: 2.622113123898834

Epoch: 6| Step: 6
Training loss: 2.93198867958038
Validation loss: 2.6894522015679203

Epoch: 6| Step: 7
Training loss: 2.6396400375317235
Validation loss: 2.6928863073053555

Epoch: 6| Step: 8
Training loss: 2.0751838234976083
Validation loss: 2.6339395678323756

Epoch: 6| Step: 9
Training loss: 2.6258221201736442
Validation loss: 2.6133316255664436

Epoch: 6| Step: 10
Training loss: 2.3254863968563892
Validation loss: 2.6668409548865255

Epoch: 6| Step: 11
Training loss: 2.5495987819605284
Validation loss: 2.5306320535026514

Epoch: 6| Step: 12
Training loss: 1.9612559633668838
Validation loss: 2.6130530424504603

Epoch: 6| Step: 13
Training loss: 2.334564519948578
Validation loss: 2.5912939799272694

Epoch: 54| Step: 0
Training loss: 2.282514143499904
Validation loss: 2.6032455697287684

Epoch: 6| Step: 1
Training loss: 2.0981956086878304
Validation loss: 2.5472331819075507

Epoch: 6| Step: 2
Training loss: 2.6465317612801016
Validation loss: 2.581566334476724

Epoch: 6| Step: 3
Training loss: 2.461158669841997
Validation loss: 2.6007433910599422

Epoch: 6| Step: 4
Training loss: 2.3548677351431673
Validation loss: 2.5463961363655145

Epoch: 6| Step: 5
Training loss: 2.4008683302752876
Validation loss: 2.5875442906518926

Epoch: 6| Step: 6
Training loss: 2.224666390429373
Validation loss: 2.5967980900961534

Epoch: 6| Step: 7
Training loss: 2.273254596916576
Validation loss: 2.5697408734267864

Epoch: 6| Step: 8
Training loss: 2.2778342816340706
Validation loss: 2.6526904621589327

Epoch: 6| Step: 9
Training loss: 1.9840385572316963
Validation loss: 2.5703820911946518

Epoch: 6| Step: 10
Training loss: 2.904456456821192
Validation loss: 2.5833886253428426

Epoch: 6| Step: 11
Training loss: 2.951240543801113
Validation loss: 2.5705794608357118

Epoch: 6| Step: 12
Training loss: 2.2389346462251054
Validation loss: 2.5204244917890355

Epoch: 6| Step: 13
Training loss: 2.179332635903716
Validation loss: 2.634725658508573

Epoch: 55| Step: 0
Training loss: 2.502312734877942
Validation loss: 2.5265894947957213

Epoch: 6| Step: 1
Training loss: 2.2460557486595087
Validation loss: 2.530729986079313

Epoch: 6| Step: 2
Training loss: 2.173040063803814
Validation loss: 2.4843509440986815

Epoch: 6| Step: 3
Training loss: 2.7507605801352604
Validation loss: 2.6012335980821057

Epoch: 6| Step: 4
Training loss: 3.045835973179235
Validation loss: 2.5482013579732614

Epoch: 6| Step: 5
Training loss: 2.5768855034139717
Validation loss: 2.600109026530303

Epoch: 6| Step: 6
Training loss: 2.364639875321339
Validation loss: 2.592315062422653

Epoch: 6| Step: 7
Training loss: 2.681593592398688
Validation loss: 2.624108874727523

Epoch: 6| Step: 8
Training loss: 2.1723619093647333
Validation loss: 2.5738531768655712

Epoch: 6| Step: 9
Training loss: 2.4714703601230577
Validation loss: 2.5855584764794233

Epoch: 6| Step: 10
Training loss: 2.09111950874782
Validation loss: 2.535504709521121

Epoch: 6| Step: 11
Training loss: 2.4856063382429205
Validation loss: 2.5537318815365655

Epoch: 6| Step: 12
Training loss: 2.0941384937209357
Validation loss: 2.5669973961252603

Epoch: 6| Step: 13
Training loss: 1.992127720553009
Validation loss: 2.6400042073139227

Epoch: 56| Step: 0
Training loss: 2.7025992703621653
Validation loss: 2.608242889568892

Epoch: 6| Step: 1
Training loss: 2.0408345557391283
Validation loss: 2.589224839708549

Epoch: 6| Step: 2
Training loss: 2.8882611481160767
Validation loss: 2.615496370896797

Epoch: 6| Step: 3
Training loss: 2.5961252390271676
Validation loss: 2.5453708708337994

Epoch: 6| Step: 4
Training loss: 2.944518774122051
Validation loss: 2.6467921304472104

Epoch: 6| Step: 5
Training loss: 2.3605717535379167
Validation loss: 2.574223303706416

Epoch: 6| Step: 6
Training loss: 2.984421974331717
Validation loss: 2.613153291999377

Epoch: 6| Step: 7
Training loss: 1.9611765803154637
Validation loss: 2.5633765791513636

Epoch: 6| Step: 8
Training loss: 1.8940478150516433
Validation loss: 2.5782969099586066

Epoch: 6| Step: 9
Training loss: 1.5025906443744974
Validation loss: 2.5793214275988805

Epoch: 6| Step: 10
Training loss: 2.1761720809703613
Validation loss: 2.6039161307300707

Epoch: 6| Step: 11
Training loss: 2.56560207640133
Validation loss: 2.542005279268915

Epoch: 6| Step: 12
Training loss: 2.344907144363298
Validation loss: 2.58674321679108

Epoch: 6| Step: 13
Training loss: 2.546086569603589
Validation loss: 2.611864086796816

Epoch: 57| Step: 0
Training loss: 2.4565347676300444
Validation loss: 2.593090938805047

Epoch: 6| Step: 1
Training loss: 2.3128140210539816
Validation loss: 2.5731961539950694

Epoch: 6| Step: 2
Training loss: 2.123734939099683
Validation loss: 2.5319276538384448

Epoch: 6| Step: 3
Training loss: 2.7217907617718704
Validation loss: 2.5990380916448457

Epoch: 6| Step: 4
Training loss: 2.011891300245594
Validation loss: 2.581223669833791

Epoch: 6| Step: 5
Training loss: 2.025730321606621
Validation loss: 2.548763705982713

Epoch: 6| Step: 6
Training loss: 2.21909985000385
Validation loss: 2.6299432350240664

Epoch: 6| Step: 7
Training loss: 2.831282902204309
Validation loss: 2.589025783489505

Epoch: 6| Step: 8
Training loss: 2.0199573886267195
Validation loss: 2.5694996824999827

Epoch: 6| Step: 9
Training loss: 2.4689366716719987
Validation loss: 2.5432659547795873

Epoch: 6| Step: 10
Training loss: 1.956354507726016
Validation loss: 2.601292379444361

Epoch: 6| Step: 11
Training loss: 3.066740253505455
Validation loss: 2.596097534923873

Epoch: 6| Step: 12
Training loss: 2.410048026401754
Validation loss: 2.5427722298296733

Epoch: 6| Step: 13
Training loss: 2.797981767803612
Validation loss: 2.5252651528611088

Epoch: 58| Step: 0
Training loss: 2.7006378197536756
Validation loss: 2.5801831362904037

Epoch: 6| Step: 1
Training loss: 2.9864429279662303
Validation loss: 2.5973216517745144

Epoch: 6| Step: 2
Training loss: 2.2396458698383404
Validation loss: 2.622827675551762

Epoch: 6| Step: 3
Training loss: 1.7964089494114057
Validation loss: 2.5406701813168597

Epoch: 6| Step: 4
Training loss: 1.4861026547786533
Validation loss: 2.61405655821653

Epoch: 6| Step: 5
Training loss: 2.258554514884266
Validation loss: 2.612853664814106

Epoch: 6| Step: 6
Training loss: 2.5570271362308894
Validation loss: 2.6397254359636646

Epoch: 6| Step: 7
Training loss: 3.3450565815745996
Validation loss: 2.661584844898166

Epoch: 6| Step: 8
Training loss: 2.6027198943391263
Validation loss: 2.709120134849523

Epoch: 6| Step: 9
Training loss: 1.9732720046672954
Validation loss: 2.5941091388418527

Epoch: 6| Step: 10
Training loss: 2.242111789608094
Validation loss: 2.5851847771839904

Epoch: 6| Step: 11
Training loss: 2.6396748114202224
Validation loss: 2.617920145759738

Epoch: 6| Step: 12
Training loss: 2.186072946732629
Validation loss: 2.5716406531964116

Epoch: 6| Step: 13
Training loss: 2.711162195045781
Validation loss: 2.5850696394349324

Epoch: 59| Step: 0
Training loss: 2.2026409943187555
Validation loss: 2.5924362471027433

Epoch: 6| Step: 1
Training loss: 1.3642013636429138
Validation loss: 2.626112475128426

Epoch: 6| Step: 2
Training loss: 2.2607449294664796
Validation loss: 2.585339741224611

Epoch: 6| Step: 3
Training loss: 1.6694315229449352
Validation loss: 2.561159651754396

Epoch: 6| Step: 4
Training loss: 2.105138522775459
Validation loss: 2.5789756989741193

Epoch: 6| Step: 5
Training loss: 3.238579564912155
Validation loss: 2.4993846294894535

Epoch: 6| Step: 6
Training loss: 2.4157005110729264
Validation loss: 2.5355252711017715

Epoch: 6| Step: 7
Training loss: 2.605607836898529
Validation loss: 2.541354259198

Epoch: 6| Step: 8
Training loss: 2.1668293476164417
Validation loss: 2.53239359355643

Epoch: 6| Step: 9
Training loss: 3.037202633716894
Validation loss: 2.486209000507849

Epoch: 6| Step: 10
Training loss: 2.558570454032781
Validation loss: 2.547576168095855

Epoch: 6| Step: 11
Training loss: 2.2228156436558457
Validation loss: 2.567420917594346

Epoch: 6| Step: 12
Training loss: 2.6314699275875
Validation loss: 2.5849167805968896

Epoch: 6| Step: 13
Training loss: 2.060707700699487
Validation loss: 2.6072669279657466

Epoch: 60| Step: 0
Training loss: 2.7898845583095095
Validation loss: 2.535750371892401

Epoch: 6| Step: 1
Training loss: 2.71801897064505
Validation loss: 2.63460393041398

Epoch: 6| Step: 2
Training loss: 2.02500966387668
Validation loss: 2.6157914950705243

Epoch: 6| Step: 3
Training loss: 2.3363067437185188
Validation loss: 2.6293152504683452

Epoch: 6| Step: 4
Training loss: 1.834710543095837
Validation loss: 2.6982363115067893

Epoch: 6| Step: 5
Training loss: 1.9112193887677975
Validation loss: 2.6844379812896824

Epoch: 6| Step: 6
Training loss: 3.246278539509372
Validation loss: 2.6925842040108763

Epoch: 6| Step: 7
Training loss: 1.9359668695594299
Validation loss: 2.701708236773012

Epoch: 6| Step: 8
Training loss: 2.250607938227751
Validation loss: 2.73035717009904

Epoch: 6| Step: 9
Training loss: 2.0206128291793894
Validation loss: 2.7108203521833616

Epoch: 6| Step: 10
Training loss: 2.5522281112606646
Validation loss: 2.617815069615004

Epoch: 6| Step: 11
Training loss: 2.033035549913157
Validation loss: 2.636997432345357

Epoch: 6| Step: 12
Training loss: 2.8138327090132322
Validation loss: 2.6059833649411535

Epoch: 6| Step: 13
Training loss: 2.6447742975923445
Validation loss: 2.561709987776246

Epoch: 61| Step: 0
Training loss: 2.577755248402475
Validation loss: 2.5316052599607115

Epoch: 6| Step: 1
Training loss: 2.466683887301295
Validation loss: 2.59607220301266

Epoch: 6| Step: 2
Training loss: 2.813274276966287
Validation loss: 2.6050045242319095

Epoch: 6| Step: 3
Training loss: 2.215503950807238
Validation loss: 2.5567324713909336

Epoch: 6| Step: 4
Training loss: 2.247234127965111
Validation loss: 2.5582768756050336

Epoch: 6| Step: 5
Training loss: 2.871035786776723
Validation loss: 2.5577189456932583

Epoch: 6| Step: 6
Training loss: 2.025897794843705
Validation loss: 2.574036425326114

Epoch: 6| Step: 7
Training loss: 2.473846390182551
Validation loss: 2.572819145506347

Epoch: 6| Step: 8
Training loss: 2.398801297607885
Validation loss: 2.5680967170034923

Epoch: 6| Step: 9
Training loss: 1.747923709217141
Validation loss: 2.563407272129022

Epoch: 6| Step: 10
Training loss: 2.5296607974494503
Validation loss: 2.614799905954007

Epoch: 6| Step: 11
Training loss: 2.6085114106478393
Validation loss: 2.591861205654938

Epoch: 6| Step: 12
Training loss: 2.078266798645578
Validation loss: 2.5415318458528695

Epoch: 6| Step: 13
Training loss: 2.4234718226862064
Validation loss: 2.550883970193162

Epoch: 62| Step: 0
Training loss: 2.216078533461142
Validation loss: 2.623127345036454

Epoch: 6| Step: 1
Training loss: 2.6675281523887655
Validation loss: 2.546283684484158

Epoch: 6| Step: 2
Training loss: 2.246009254524819
Validation loss: 2.52829287128431

Epoch: 6| Step: 3
Training loss: 1.9790085444947805
Validation loss: 2.6065691635875363

Epoch: 6| Step: 4
Training loss: 2.223746784758964
Validation loss: 2.5672684473891865

Epoch: 6| Step: 5
Training loss: 1.9346645896465808
Validation loss: 2.604972979014342

Epoch: 6| Step: 6
Training loss: 2.1849363290688726
Validation loss: 2.61513740373064

Epoch: 6| Step: 7
Training loss: 2.437399250784953
Validation loss: 2.592125655945117

Epoch: 6| Step: 8
Training loss: 2.645174339909032
Validation loss: 2.5215069577490943

Epoch: 6| Step: 9
Training loss: 2.4409943011825654
Validation loss: 2.594867297131727

Epoch: 6| Step: 10
Training loss: 2.979416967872208
Validation loss: 2.5771836382856748

Epoch: 6| Step: 11
Training loss: 1.976934104033484
Validation loss: 2.558003372530669

Epoch: 6| Step: 12
Training loss: 1.6972092244881367
Validation loss: 2.59179133261553

Epoch: 6| Step: 13
Training loss: 2.714576675121918
Validation loss: 2.5441324019995926

Epoch: 63| Step: 0
Training loss: 2.1622551487245985
Validation loss: 2.6173492381664776

Epoch: 6| Step: 1
Training loss: 2.331775849380761
Validation loss: 2.608751218631291

Epoch: 6| Step: 2
Training loss: 2.0901836938760927
Validation loss: 2.5705657339525483

Epoch: 6| Step: 3
Training loss: 2.6606193061034675
Validation loss: 2.5954608713295726

Epoch: 6| Step: 4
Training loss: 2.2509472230666567
Validation loss: 2.540146722385606

Epoch: 6| Step: 5
Training loss: 1.7435404224310025
Validation loss: 2.5570196614370464

Epoch: 6| Step: 6
Training loss: 2.677201700129497
Validation loss: 2.645858003596435

Epoch: 6| Step: 7
Training loss: 2.3462378966680317
Validation loss: 2.545425782825579

Epoch: 6| Step: 8
Training loss: 1.890432174559592
Validation loss: 2.5850827359302673

Epoch: 6| Step: 9
Training loss: 2.5427139084215837
Validation loss: 2.5780887793876888

Epoch: 6| Step: 10
Training loss: 2.8598038815567053
Validation loss: 2.604891627809893

Epoch: 6| Step: 11
Training loss: 2.8129372998520905
Validation loss: 2.5828484008287864

Epoch: 6| Step: 12
Training loss: 1.9997426105815317
Validation loss: 2.6220501113388104

Epoch: 6| Step: 13
Training loss: 2.196600485264449
Validation loss: 2.5504142337515954

Epoch: 64| Step: 0
Training loss: 2.263106636788266
Validation loss: 2.4975313873151603

Epoch: 6| Step: 1
Training loss: 1.9721915424748557
Validation loss: 2.6230638266304673

Epoch: 6| Step: 2
Training loss: 2.461600659345725
Validation loss: 2.571767972725455

Epoch: 6| Step: 3
Training loss: 3.0435265555015234
Validation loss: 2.617695143322718

Epoch: 6| Step: 4
Training loss: 3.040962468676797
Validation loss: 2.571413695138457

Epoch: 6| Step: 5
Training loss: 2.1895969694120083
Validation loss: 2.5810587057023917

Epoch: 6| Step: 6
Training loss: 2.40922511088487
Validation loss: 2.5298577392548207

Epoch: 6| Step: 7
Training loss: 2.140078732477189
Validation loss: 2.561011370465688

Epoch: 6| Step: 8
Training loss: 2.184942548856372
Validation loss: 2.576521002668753

Epoch: 6| Step: 9
Training loss: 2.277988349154639
Validation loss: 2.542927153247619

Epoch: 6| Step: 10
Training loss: 2.123386668199645
Validation loss: 2.5866878223864944

Epoch: 6| Step: 11
Training loss: 2.1833099562968363
Validation loss: 2.6304922850775516

Epoch: 6| Step: 12
Training loss: 2.419156622406435
Validation loss: 2.5375533641722354

Epoch: 6| Step: 13
Training loss: 2.5634518227972873
Validation loss: 2.590959158200196

Epoch: 65| Step: 0
Training loss: 3.3006768023877773
Validation loss: 2.57500399863911

Epoch: 6| Step: 1
Training loss: 1.9066310564241433
Validation loss: 2.582600079320887

Epoch: 6| Step: 2
Training loss: 2.5589616117948406
Validation loss: 2.55651365566654

Epoch: 6| Step: 3
Training loss: 2.3440441709919897
Validation loss: 2.625555600298921

Epoch: 6| Step: 4
Training loss: 2.020975389763936
Validation loss: 2.599279889617489

Epoch: 6| Step: 5
Training loss: 2.9837709784279665
Validation loss: 2.5500447337895467

Epoch: 6| Step: 6
Training loss: 2.0579528389986796
Validation loss: 2.619108825232632

Epoch: 6| Step: 7
Training loss: 2.1295745080764887
Validation loss: 2.585843440839376

Epoch: 6| Step: 8
Training loss: 2.090500544790887
Validation loss: 2.6158296165508768

Epoch: 6| Step: 9
Training loss: 2.2517157476663376
Validation loss: 2.6135507092117374

Epoch: 6| Step: 10
Training loss: 1.9603494317108825
Validation loss: 2.571129248810718

Epoch: 6| Step: 11
Training loss: 2.3793848617986626
Validation loss: 2.6126178836539733

Epoch: 6| Step: 12
Training loss: 2.010152558947131
Validation loss: 2.593125126341348

Epoch: 6| Step: 13
Training loss: 2.574683834776623
Validation loss: 2.56111101172119

Epoch: 66| Step: 0
Training loss: 1.9828939843475297
Validation loss: 2.5753949593904304

Epoch: 6| Step: 1
Training loss: 2.4509128388089856
Validation loss: 2.6032880801453238

Epoch: 6| Step: 2
Training loss: 2.106665446345463
Validation loss: 2.5473438135697073

Epoch: 6| Step: 3
Training loss: 2.266037791564084
Validation loss: 2.5753069956959473

Epoch: 6| Step: 4
Training loss: 2.3954337629963454
Validation loss: 2.527410098526157

Epoch: 6| Step: 5
Training loss: 2.5213892510257097
Validation loss: 2.6377955971628086

Epoch: 6| Step: 6
Training loss: 2.3459269268366243
Validation loss: 2.5708556214968254

Epoch: 6| Step: 7
Training loss: 2.967514423441362
Validation loss: 2.58047373739714

Epoch: 6| Step: 8
Training loss: 2.188727007472272
Validation loss: 2.537269217233164

Epoch: 6| Step: 9
Training loss: 2.358074613023243
Validation loss: 2.493688914380236

Epoch: 6| Step: 10
Training loss: 2.2389577538958765
Validation loss: 2.5860996406793397

Epoch: 6| Step: 11
Training loss: 2.2771749810159605
Validation loss: 2.542202898169184

Epoch: 6| Step: 12
Training loss: 2.667903156507455
Validation loss: 2.553346318800387

Epoch: 6| Step: 13
Training loss: 2.0791548851561075
Validation loss: 2.6176607377845653

Epoch: 67| Step: 0
Training loss: 2.2605858899130173
Validation loss: 2.522416300864197

Epoch: 6| Step: 1
Training loss: 2.3975799717458326
Validation loss: 2.581654669789399

Epoch: 6| Step: 2
Training loss: 2.2604468793358796
Validation loss: 2.579392277757009

Epoch: 6| Step: 3
Training loss: 2.4350003850729007
Validation loss: 2.6021425595248497

Epoch: 6| Step: 4
Training loss: 2.4088339864899355
Validation loss: 2.631993491812605

Epoch: 6| Step: 5
Training loss: 2.2137069341260496
Validation loss: 2.6168954562941122

Epoch: 6| Step: 6
Training loss: 2.4531662081033314
Validation loss: 2.529352630825493

Epoch: 6| Step: 7
Training loss: 2.647541265841478
Validation loss: 2.62859438992032

Epoch: 6| Step: 8
Training loss: 2.0483825024424163
Validation loss: 2.630400778399536

Epoch: 6| Step: 9
Training loss: 2.7096628495965853
Validation loss: 2.6578723366243855

Epoch: 6| Step: 10
Training loss: 3.170672710292094
Validation loss: 2.5200723387412127

Epoch: 6| Step: 11
Training loss: 1.743471912373302
Validation loss: 2.5486230604519324

Epoch: 6| Step: 12
Training loss: 1.723410789303509
Validation loss: 2.5065381069222648

Epoch: 6| Step: 13
Training loss: 2.53985817986399
Validation loss: 2.5610344580403006

Epoch: 68| Step: 0
Training loss: 2.559427978563494
Validation loss: 2.547619022525147

Epoch: 6| Step: 1
Training loss: 3.009717778760674
Validation loss: 2.5409619156841963

Epoch: 6| Step: 2
Training loss: 2.054506011025721
Validation loss: 2.6106195736811095

Epoch: 6| Step: 3
Training loss: 2.6716871585960402
Validation loss: 2.5645477517637407

Epoch: 6| Step: 4
Training loss: 2.6384987481370725
Validation loss: 2.5395227885572282

Epoch: 6| Step: 5
Training loss: 2.559590991248498
Validation loss: 2.5715235801078986

Epoch: 6| Step: 6
Training loss: 2.4065783388126563
Validation loss: 2.588301370521221

Epoch: 6| Step: 7
Training loss: 2.144077941011606
Validation loss: 2.5831999026469314

Epoch: 6| Step: 8
Training loss: 1.9866105350569516
Validation loss: 2.478645804262866

Epoch: 6| Step: 9
Training loss: 1.8882055012507546
Validation loss: 2.591406625374464

Epoch: 6| Step: 10
Training loss: 2.0957473792872334
Validation loss: 2.565518067300209

Epoch: 6| Step: 11
Training loss: 2.1633298439307302
Validation loss: 2.5741405947933185

Epoch: 6| Step: 12
Training loss: 1.8150253461218715
Validation loss: 2.567422898672331

Epoch: 6| Step: 13
Training loss: 2.300233422749374
Validation loss: 2.583280429503473

Epoch: 69| Step: 0
Training loss: 2.370402755477442
Validation loss: 2.6061312373215957

Epoch: 6| Step: 1
Training loss: 2.9336834727457766
Validation loss: 2.5753788049080337

Epoch: 6| Step: 2
Training loss: 1.9528420205158135
Validation loss: 2.512998042555063

Epoch: 6| Step: 3
Training loss: 2.196750807744958
Validation loss: 2.6142474689547393

Epoch: 6| Step: 4
Training loss: 1.8599334647470949
Validation loss: 2.6822609439806375

Epoch: 6| Step: 5
Training loss: 2.2609498293210284
Validation loss: 2.6073922182984934

Epoch: 6| Step: 6
Training loss: 2.549035776383342
Validation loss: 2.558686031007205

Epoch: 6| Step: 7
Training loss: 2.5325605037650556
Validation loss: 2.619576236115963

Epoch: 6| Step: 8
Training loss: 1.8643571798180758
Validation loss: 2.6681105807330194

Epoch: 6| Step: 9
Training loss: 3.0782057078668164
Validation loss: 2.5779872356559483

Epoch: 6| Step: 10
Training loss: 1.6800752414021405
Validation loss: 2.5781182106005733

Epoch: 6| Step: 11
Training loss: 3.3302804477119636
Validation loss: 2.6151908128266435

Epoch: 6| Step: 12
Training loss: 2.329120807048377
Validation loss: 2.554742911668204

Epoch: 6| Step: 13
Training loss: 1.2482533172221069
Validation loss: 2.56311998388058

Epoch: 70| Step: 0
Training loss: 2.5424976762218976
Validation loss: 2.5465597882070883

Epoch: 6| Step: 1
Training loss: 2.066953878544234
Validation loss: 2.5819385567713624

Epoch: 6| Step: 2
Training loss: 2.1048524198650176
Validation loss: 2.5308282759884606

Epoch: 6| Step: 3
Training loss: 2.2006688055062535
Validation loss: 2.6009156699339466

Epoch: 6| Step: 4
Training loss: 2.447900931666239
Validation loss: 2.5635274517518263

Epoch: 6| Step: 5
Training loss: 2.574098899725659
Validation loss: 2.4767117781229415

Epoch: 6| Step: 6
Training loss: 1.5713862453680694
Validation loss: 2.5364966001241567

Epoch: 6| Step: 7
Training loss: 1.8326604937831865
Validation loss: 2.568965353991871

Epoch: 6| Step: 8
Training loss: 2.13012369325055
Validation loss: 2.5355542952443115

Epoch: 6| Step: 9
Training loss: 2.535835915609201
Validation loss: 2.593748406712299

Epoch: 6| Step: 10
Training loss: 3.162752911854689
Validation loss: 2.5402342454774445

Epoch: 6| Step: 11
Training loss: 2.543910823302677
Validation loss: 2.553331830079887

Epoch: 6| Step: 12
Training loss: 2.5565173394047704
Validation loss: 2.4957069809719106

Epoch: 6| Step: 13
Training loss: 1.9568437497894633
Validation loss: 2.54338446137853

Epoch: 71| Step: 0
Training loss: 2.360637402854133
Validation loss: 2.5678953730698786

Epoch: 6| Step: 1
Training loss: 2.928803414782878
Validation loss: 2.599379286888252

Epoch: 6| Step: 2
Training loss: 1.979903702946968
Validation loss: 2.594872672155123

Epoch: 6| Step: 3
Training loss: 1.9433687602827707
Validation loss: 2.5880589844262643

Epoch: 6| Step: 4
Training loss: 1.599585079991403
Validation loss: 2.6072279421041857

Epoch: 6| Step: 5
Training loss: 1.9973434448003218
Validation loss: 2.5291844562698818

Epoch: 6| Step: 6
Training loss: 2.2888766789445025
Validation loss: 2.584615609632006

Epoch: 6| Step: 7
Training loss: 2.4994006392128996
Validation loss: 2.643315842182966

Epoch: 6| Step: 8
Training loss: 2.970968441523704
Validation loss: 2.6282542205624746

Epoch: 6| Step: 9
Training loss: 2.5250662162332107
Validation loss: 2.547382826776135

Epoch: 6| Step: 10
Training loss: 2.1438365151433794
Validation loss: 2.6300858774415112

Epoch: 6| Step: 11
Training loss: 1.9485578926536797
Validation loss: 2.5775063899614987

Epoch: 6| Step: 12
Training loss: 2.307052175063311
Validation loss: 2.596520135766303

Epoch: 6| Step: 13
Training loss: 2.9757166984929766
Validation loss: 2.5731245155139435

Epoch: 72| Step: 0
Training loss: 2.1996464965484415
Validation loss: 2.5924137457462524

Epoch: 6| Step: 1
Training loss: 2.036648662547913
Validation loss: 2.5126368148523657

Epoch: 6| Step: 2
Training loss: 2.429308306674341
Validation loss: 2.584386785096709

Epoch: 6| Step: 3
Training loss: 2.3063049847424137
Validation loss: 2.5958201867796804

Epoch: 6| Step: 4
Training loss: 2.202806382102442
Validation loss: 2.536150188384073

Epoch: 6| Step: 5
Training loss: 2.0301201832715745
Validation loss: 2.5339623977322017

Epoch: 6| Step: 6
Training loss: 2.1844835464511
Validation loss: 2.467943792246128

Epoch: 6| Step: 7
Training loss: 2.0460703192640497
Validation loss: 2.550947837199577

Epoch: 6| Step: 8
Training loss: 2.2684136427715105
Validation loss: 2.5973058937543727

Epoch: 6| Step: 9
Training loss: 2.488735570707696
Validation loss: 2.5529873602694066

Epoch: 6| Step: 10
Training loss: 2.235761945591694
Validation loss: 2.514554848518842

Epoch: 6| Step: 11
Training loss: 2.916104743960097
Validation loss: 2.4947219525646567

Epoch: 6| Step: 12
Training loss: 2.301264506495814
Validation loss: 2.565432599466213

Epoch: 6| Step: 13
Training loss: 2.9395238519315026
Validation loss: 2.575915651880892

Epoch: 73| Step: 0
Training loss: 2.2141280052170265
Validation loss: 2.628679346019993

Epoch: 6| Step: 1
Training loss: 2.493203843812077
Validation loss: 2.5285405386869084

Epoch: 6| Step: 2
Training loss: 3.1178910840521223
Validation loss: 2.54603368519167

Epoch: 6| Step: 3
Training loss: 2.127339701906094
Validation loss: 2.5596858288040703

Epoch: 6| Step: 4
Training loss: 2.006828571686604
Validation loss: 2.486730886052821

Epoch: 6| Step: 5
Training loss: 2.136305634838305
Validation loss: 2.56037633402143

Epoch: 6| Step: 6
Training loss: 2.085863090645275
Validation loss: 2.591442736511703

Epoch: 6| Step: 7
Training loss: 2.9389307311968818
Validation loss: 2.5987977390451897

Epoch: 6| Step: 8
Training loss: 2.098328324671255
Validation loss: 2.540706911913228

Epoch: 6| Step: 9
Training loss: 2.329159602755604
Validation loss: 2.5518654918470163

Epoch: 6| Step: 10
Training loss: 1.8518373953290321
Validation loss: 2.58332106884742

Epoch: 6| Step: 11
Training loss: 2.3765767535322078
Validation loss: 2.607117786367801

Epoch: 6| Step: 12
Training loss: 2.820134461085335
Validation loss: 2.5413358712812455

Epoch: 6| Step: 13
Training loss: 2.203645577036633
Validation loss: 2.589194974577771

Epoch: 74| Step: 0
Training loss: 2.22832625284071
Validation loss: 2.6215639180659958

Epoch: 6| Step: 1
Training loss: 2.7888763109137136
Validation loss: 2.659799216682947

Epoch: 6| Step: 2
Training loss: 2.30472091391959
Validation loss: 2.644027654498394

Epoch: 6| Step: 3
Training loss: 2.0163277280787075
Validation loss: 2.616685088410699

Epoch: 6| Step: 4
Training loss: 2.013054324747841
Validation loss: 2.6205957946921

Epoch: 6| Step: 5
Training loss: 2.5696589325972248
Validation loss: 2.610056934600465

Epoch: 6| Step: 6
Training loss: 2.6211665181776653
Validation loss: 2.6385238835613634

Epoch: 6| Step: 7
Training loss: 1.991869972205901
Validation loss: 2.647220050430163

Epoch: 6| Step: 8
Training loss: 2.0252630180691096
Validation loss: 2.640152341536447

Epoch: 6| Step: 9
Training loss: 1.2973550574430028
Validation loss: 2.6359342034241466

Epoch: 6| Step: 10
Training loss: 2.43552152105012
Validation loss: 2.5801926923597835

Epoch: 6| Step: 11
Training loss: 2.5016635128596905
Validation loss: 2.6105144548379435

Epoch: 6| Step: 12
Training loss: 2.2860504226797316
Validation loss: 2.6168922827172487

Epoch: 6| Step: 13
Training loss: 2.731333408784326
Validation loss: 2.5951270925065297

Epoch: 75| Step: 0
Training loss: 2.5373520004633514
Validation loss: 2.5451106803849304

Epoch: 6| Step: 1
Training loss: 2.235122768947345
Validation loss: 2.549499758415463

Epoch: 6| Step: 2
Training loss: 2.5599631801579976
Validation loss: 2.5587457975680117

Epoch: 6| Step: 3
Training loss: 1.7361093733037092
Validation loss: 2.613118910296927

Epoch: 6| Step: 4
Training loss: 2.479194469990553
Validation loss: 2.4733884188420623

Epoch: 6| Step: 5
Training loss: 2.322857318570498
Validation loss: 2.5275711829842678

Epoch: 6| Step: 6
Training loss: 2.128549640430625
Validation loss: 2.5564607149434857

Epoch: 6| Step: 7
Training loss: 2.493724002559213
Validation loss: 2.5024400962267914

Epoch: 6| Step: 8
Training loss: 2.4516614690950727
Validation loss: 2.57772420214558

Epoch: 6| Step: 9
Training loss: 1.6401185480163443
Validation loss: 2.5402543151376316

Epoch: 6| Step: 10
Training loss: 2.28672488895657
Validation loss: 2.5723164639557696

Epoch: 6| Step: 11
Training loss: 2.138942976538824
Validation loss: 2.533927380613939

Epoch: 6| Step: 12
Training loss: 2.492129429825269
Validation loss: 2.5400941757955753

Epoch: 6| Step: 13
Training loss: 2.872065165702206
Validation loss: 2.6503227223314347

Epoch: 76| Step: 0
Training loss: 2.7001046301737084
Validation loss: 2.57784832327144

Epoch: 6| Step: 1
Training loss: 2.154346233781219
Validation loss: 2.5557002588667137

Epoch: 6| Step: 2
Training loss: 2.451227316666325
Validation loss: 2.590276774956512

Epoch: 6| Step: 3
Training loss: 2.2961800490571265
Validation loss: 2.5824586377027328

Epoch: 6| Step: 4
Training loss: 1.3169558139186786
Validation loss: 2.5772308494474823

Epoch: 6| Step: 5
Training loss: 2.7951866467004627
Validation loss: 2.5516553143581593

Epoch: 6| Step: 6
Training loss: 2.5657593072824456
Validation loss: 2.634595031720353

Epoch: 6| Step: 7
Training loss: 2.771543559974114
Validation loss: 2.60164371092609

Epoch: 6| Step: 8
Training loss: 2.49695716694067
Validation loss: 2.5786373669670195

Epoch: 6| Step: 9
Training loss: 1.9296951602675638
Validation loss: 2.6536969350599486

Epoch: 6| Step: 10
Training loss: 2.5096295865368448
Validation loss: 2.564422165624955

Epoch: 6| Step: 11
Training loss: 2.0582443027572705
Validation loss: 2.556789882451924

Epoch: 6| Step: 12
Training loss: 2.253219420508799
Validation loss: 2.582439750025191

Epoch: 6| Step: 13
Training loss: 2.017697001202031
Validation loss: 2.602653534299943

Epoch: 77| Step: 0
Training loss: 2.7140799566310365
Validation loss: 2.5998532214059935

Epoch: 6| Step: 1
Training loss: 2.3658335625286826
Validation loss: 2.638366937606064

Epoch: 6| Step: 2
Training loss: 1.8622941895515595
Validation loss: 2.613490105357663

Epoch: 6| Step: 3
Training loss: 2.1439119149944967
Validation loss: 2.5990471426570596

Epoch: 6| Step: 4
Training loss: 2.6565281441861806
Validation loss: 2.569839495855613

Epoch: 6| Step: 5
Training loss: 2.2487523540423013
Validation loss: 2.6021583951493126

Epoch: 6| Step: 6
Training loss: 2.0874122235694554
Validation loss: 2.550483300652994

Epoch: 6| Step: 7
Training loss: 2.3573110281002645
Validation loss: 2.5227851615000025

Epoch: 6| Step: 8
Training loss: 2.1867750874056413
Validation loss: 2.5372839699475565

Epoch: 6| Step: 9
Training loss: 1.9193091904125557
Validation loss: 2.5147557148688815

Epoch: 6| Step: 10
Training loss: 2.552741846775599
Validation loss: 2.6001880210969652

Epoch: 6| Step: 11
Training loss: 2.8771606287608287
Validation loss: 2.542115567906513

Epoch: 6| Step: 12
Training loss: 2.0470098785922355
Validation loss: 2.513135487736092

Epoch: 6| Step: 13
Training loss: 2.075995939305915
Validation loss: 2.5522561825716514

Epoch: 78| Step: 0
Training loss: 2.392131256100119
Validation loss: 2.592897037450398

Epoch: 6| Step: 1
Training loss: 1.547317133438354
Validation loss: 2.5956361186475765

Epoch: 6| Step: 2
Training loss: 2.2920308835144185
Validation loss: 2.476054672016615

Epoch: 6| Step: 3
Training loss: 2.2510278261516197
Validation loss: 2.5313837463459876

Epoch: 6| Step: 4
Training loss: 2.256773607358116
Validation loss: 2.570456751028913

Epoch: 6| Step: 5
Training loss: 2.3380019847381757
Validation loss: 2.5983300580421473

Epoch: 6| Step: 6
Training loss: 2.1654980026373307
Validation loss: 2.611758546395747

Epoch: 6| Step: 7
Training loss: 2.4633069454151104
Validation loss: 2.6150427537514482

Epoch: 6| Step: 8
Training loss: 2.9636232781639924
Validation loss: 2.60680020239892

Epoch: 6| Step: 9
Training loss: 2.0687146048384664
Validation loss: 2.616880651297373

Epoch: 6| Step: 10
Training loss: 2.1032987888399255
Validation loss: 2.583504676263858

Epoch: 6| Step: 11
Training loss: 2.2025308010619202
Validation loss: 2.601108973534508

Epoch: 6| Step: 12
Training loss: 2.4034146534904353
Validation loss: 2.5498982683470874

Epoch: 6| Step: 13
Training loss: 2.4395242746329533
Validation loss: 2.557187738009501

Epoch: 79| Step: 0
Training loss: 2.3089893602379674
Validation loss: 2.5221528522215055

Epoch: 6| Step: 1
Training loss: 2.5184168517197225
Validation loss: 2.56838456251512

Epoch: 6| Step: 2
Training loss: 2.4493611612242923
Validation loss: 2.5724353623247818

Epoch: 6| Step: 3
Training loss: 3.2016587786070128
Validation loss: 2.564062169594349

Epoch: 6| Step: 4
Training loss: 1.8768305425875826
Validation loss: 2.6372599481957986

Epoch: 6| Step: 5
Training loss: 2.2491837186427257
Validation loss: 2.615811038190124

Epoch: 6| Step: 6
Training loss: 1.8290956316850258
Validation loss: 2.5774336841684233

Epoch: 6| Step: 7
Training loss: 2.354138354465976
Validation loss: 2.593512068410103

Epoch: 6| Step: 8
Training loss: 2.102303186519327
Validation loss: 2.6233794796078795

Epoch: 6| Step: 9
Training loss: 1.5681464595854326
Validation loss: 2.633539901148174

Epoch: 6| Step: 10
Training loss: 2.132249806832917
Validation loss: 2.541366095567226

Epoch: 6| Step: 11
Training loss: 2.409244705021791
Validation loss: 2.614446345131032

Epoch: 6| Step: 12
Training loss: 2.181344335751351
Validation loss: 2.6306249131262875

Epoch: 6| Step: 13
Training loss: 2.0277927026533265
Validation loss: 2.5622903691585326

Epoch: 80| Step: 0
Training loss: 2.432665897526423
Validation loss: 2.4943043518894266

Epoch: 6| Step: 1
Training loss: 1.9057515227396673
Validation loss: 2.592012612496604

Epoch: 6| Step: 2
Training loss: 3.081903297852951
Validation loss: 2.5892550114281776

Epoch: 6| Step: 3
Training loss: 2.1092989307391994
Validation loss: 2.6180070343603057

Epoch: 6| Step: 4
Training loss: 2.366516018044177
Validation loss: 2.5727867345910984

Epoch: 6| Step: 5
Training loss: 2.3241365818918305
Validation loss: 2.569235316062698

Epoch: 6| Step: 6
Training loss: 2.348743053870616
Validation loss: 2.634538863679191

Epoch: 6| Step: 7
Training loss: 2.340640332078821
Validation loss: 2.523450499069069

Epoch: 6| Step: 8
Training loss: 2.044821604663219
Validation loss: 2.5630645052630934

Epoch: 6| Step: 9
Training loss: 2.0628496509449166
Validation loss: 2.5802790264927373

Epoch: 6| Step: 10
Training loss: 2.4525170028361556
Validation loss: 2.5718432876034667

Epoch: 6| Step: 11
Training loss: 1.7245207576945782
Validation loss: 2.6080619264556155

Epoch: 6| Step: 12
Training loss: 2.24065205705339
Validation loss: 2.5488936180771877

Epoch: 6| Step: 13
Training loss: 1.7334040767954042
Validation loss: 2.5425919948552584

Epoch: 81| Step: 0
Training loss: 1.8814530272569694
Validation loss: 2.57918263329251

Epoch: 6| Step: 1
Training loss: 2.9325251556904544
Validation loss: 2.6580792131209536

Epoch: 6| Step: 2
Training loss: 2.315483231007863
Validation loss: 2.56395841205531

Epoch: 6| Step: 3
Training loss: 1.900175076499557
Validation loss: 2.627188905252966

Epoch: 6| Step: 4
Training loss: 2.4696148673277025
Validation loss: 2.6731262177417077

Epoch: 6| Step: 5
Training loss: 1.5269342444251146
Validation loss: 2.6777092960072695

Epoch: 6| Step: 6
Training loss: 1.2275956777355463
Validation loss: 2.522869609159752

Epoch: 6| Step: 7
Training loss: 3.089831867026376
Validation loss: 2.677648407984214

Epoch: 6| Step: 8
Training loss: 1.91257690075619
Validation loss: 2.6941134526993147

Epoch: 6| Step: 9
Training loss: 1.797768014337229
Validation loss: 2.63060581238041

Epoch: 6| Step: 10
Training loss: 2.0944748947376475
Validation loss: 2.593783397536145

Epoch: 6| Step: 11
Training loss: 2.1626121536013563
Validation loss: 2.5873807661562136

Epoch: 6| Step: 12
Training loss: 2.4928532491459148
Validation loss: 2.6108405438601703

Epoch: 6| Step: 13
Training loss: 2.7879798989248616
Validation loss: 2.5636820509158045

Epoch: 82| Step: 0
Training loss: 2.516729645435785
Validation loss: 2.610538946414917

Epoch: 6| Step: 1
Training loss: 2.932474097928569
Validation loss: 2.5669388975542557

Epoch: 6| Step: 2
Training loss: 2.5598033579166137
Validation loss: 2.5952023495995107

Epoch: 6| Step: 3
Training loss: 2.2409306103620796
Validation loss: 2.569504275498845

Epoch: 6| Step: 4
Training loss: 2.538112803159564
Validation loss: 2.535427304331505

Epoch: 6| Step: 5
Training loss: 1.778786813297379
Validation loss: 2.582435672422907

Epoch: 6| Step: 6
Training loss: 1.760178122826883
Validation loss: 2.582167613650665

Epoch: 6| Step: 7
Training loss: 2.6523089624294975
Validation loss: 2.530605783625883

Epoch: 6| Step: 8
Training loss: 2.1267349789847825
Validation loss: 2.5623857736327382

Epoch: 6| Step: 9
Training loss: 2.386917031101122
Validation loss: 2.5848452286715182

Epoch: 6| Step: 10
Training loss: 1.9984120979514024
Validation loss: 2.543883800190021

Epoch: 6| Step: 11
Training loss: 2.322984691587496
Validation loss: 2.5378523852830965

Epoch: 6| Step: 12
Training loss: 2.297750500792373
Validation loss: 2.540597211209544

Epoch: 6| Step: 13
Training loss: 1.5873732809118595
Validation loss: 2.5068543248579

Epoch: 83| Step: 0
Training loss: 2.5113327655283575
Validation loss: 2.5295128375414637

Epoch: 6| Step: 1
Training loss: 1.964857340286002
Validation loss: 2.604202214316301

Epoch: 6| Step: 2
Training loss: 2.142939520569435
Validation loss: 2.623661078233098

Epoch: 6| Step: 3
Training loss: 1.8483280307474717
Validation loss: 2.634668739145573

Epoch: 6| Step: 4
Training loss: 2.4282940858467694
Validation loss: 2.6100411240613006

Epoch: 6| Step: 5
Training loss: 1.6778921068716683
Validation loss: 2.6580642189283967

Epoch: 6| Step: 6
Training loss: 2.079867328117248
Validation loss: 2.6217959468231427

Epoch: 6| Step: 7
Training loss: 3.3619854387992585
Validation loss: 2.708910445323221

Epoch: 6| Step: 8
Training loss: 2.314526056999634
Validation loss: 2.619512870520069

Epoch: 6| Step: 9
Training loss: 2.20095187748908
Validation loss: 2.533381769277756

Epoch: 6| Step: 10
Training loss: 2.101600277926307
Validation loss: 2.713954803783882

Epoch: 6| Step: 11
Training loss: 2.1614813991066595
Validation loss: 2.614140854334043

Epoch: 6| Step: 12
Training loss: 1.698860358666807
Validation loss: 2.5703552922761284

Epoch: 6| Step: 13
Training loss: 1.9257189758012425
Validation loss: 2.5589545774464626

Epoch: 84| Step: 0
Training loss: 2.312210064832158
Validation loss: 2.506834843764979

Epoch: 6| Step: 1
Training loss: 2.1499476448604207
Validation loss: 2.5732540470552134

Epoch: 6| Step: 2
Training loss: 2.11585083605556
Validation loss: 2.534589001596302

Epoch: 6| Step: 3
Training loss: 1.243863348851778
Validation loss: 2.5501223809040394

Epoch: 6| Step: 4
Training loss: 2.271492666949343
Validation loss: 2.600758685167566

Epoch: 6| Step: 5
Training loss: 1.9164231670891048
Validation loss: 2.576062018631195

Epoch: 6| Step: 6
Training loss: 2.38522386951725
Validation loss: 2.5232724351307905

Epoch: 6| Step: 7
Training loss: 2.191841177525771
Validation loss: 2.6012955415018233

Epoch: 6| Step: 8
Training loss: 2.5411711871698928
Validation loss: 2.516168571174128

Epoch: 6| Step: 9
Training loss: 1.9292709580553862
Validation loss: 2.5968144097204755

Epoch: 6| Step: 10
Training loss: 2.5406208596659163
Validation loss: 2.6147508960137196

Epoch: 6| Step: 11
Training loss: 2.7987874913909687
Validation loss: 2.5603589052700353

Epoch: 6| Step: 12
Training loss: 2.0033570963020932
Validation loss: 2.587584893742861

Epoch: 6| Step: 13
Training loss: 2.6296474551202134
Validation loss: 2.6166051112262423

Epoch: 85| Step: 0
Training loss: 2.47689047004591
Validation loss: 2.639506643054848

Epoch: 6| Step: 1
Training loss: 1.6424707112248442
Validation loss: 2.614070679962864

Epoch: 6| Step: 2
Training loss: 2.9502211730288286
Validation loss: 2.5292661844205604

Epoch: 6| Step: 3
Training loss: 2.5226360737267535
Validation loss: 2.6133964752659273

Epoch: 6| Step: 4
Training loss: 2.1901085695153673
Validation loss: 2.546431746653159

Epoch: 6| Step: 5
Training loss: 2.3297788135176636
Validation loss: 2.5939285645816597

Epoch: 6| Step: 6
Training loss: 2.1833646650711267
Validation loss: 2.5746851311918264

Epoch: 6| Step: 7
Training loss: 1.9070647327776455
Validation loss: 2.489275188342998

Epoch: 6| Step: 8
Training loss: 1.6562014878563796
Validation loss: 2.4723660829622642

Epoch: 6| Step: 9
Training loss: 1.8473174286530185
Validation loss: 2.4935675201320864

Epoch: 6| Step: 10
Training loss: 1.8949945571539424
Validation loss: 2.52891061943713

Epoch: 6| Step: 11
Training loss: 2.461616156113016
Validation loss: 2.603761097162058

Epoch: 6| Step: 12
Training loss: 2.1981573711286164
Validation loss: 2.5591428288879823

Epoch: 6| Step: 13
Training loss: 2.7880822604233635
Validation loss: 2.607995877562036

Epoch: 86| Step: 0
Training loss: 2.3546742480031044
Validation loss: 2.6099801494433015

Epoch: 6| Step: 1
Training loss: 1.7276845194734267
Validation loss: 2.582275456024618

Epoch: 6| Step: 2
Training loss: 2.548785096020895
Validation loss: 2.5595947637048675

Epoch: 6| Step: 3
Training loss: 2.563486514117588
Validation loss: 2.463691595299092

Epoch: 6| Step: 4
Training loss: 2.0851004417614725
Validation loss: 2.506622998900542

Epoch: 6| Step: 5
Training loss: 2.2131119135136026
Validation loss: 2.537854467730063

Epoch: 6| Step: 6
Training loss: 1.5214613397345609
Validation loss: 2.634082914052987

Epoch: 6| Step: 7
Training loss: 2.1043604267409957
Validation loss: 2.5717442630310634

Epoch: 6| Step: 8
Training loss: 2.260870950875448
Validation loss: 2.593416307424576

Epoch: 6| Step: 9
Training loss: 3.036541439814456
Validation loss: 2.6155126194300355

Epoch: 6| Step: 10
Training loss: 2.3502724996803894
Validation loss: 2.674263851087464

Epoch: 6| Step: 11
Training loss: 1.9040887806974316
Validation loss: 2.6402082998530156

Epoch: 6| Step: 12
Training loss: 2.5204593811939393
Validation loss: 2.6158471466247413

Epoch: 6| Step: 13
Training loss: 2.1490100444489735
Validation loss: 2.5472522448405885

Epoch: 87| Step: 0
Training loss: 1.440365133617045
Validation loss: 2.573174688912518

Epoch: 6| Step: 1
Training loss: 2.262556958403645
Validation loss: 2.5849396930893325

Epoch: 6| Step: 2
Training loss: 1.5522845690369609
Validation loss: 2.6417493664846137

Epoch: 6| Step: 3
Training loss: 1.9747835982347983
Validation loss: 2.5746495721382208

Epoch: 6| Step: 4
Training loss: 2.161433968157726
Validation loss: 2.6625815905873242

Epoch: 6| Step: 5
Training loss: 1.9415434207466944
Validation loss: 2.6600945718106264

Epoch: 6| Step: 6
Training loss: 2.76731881035278
Validation loss: 2.5703152982161264

Epoch: 6| Step: 7
Training loss: 2.478689441643308
Validation loss: 2.5948138678749615

Epoch: 6| Step: 8
Training loss: 2.168489960573128
Validation loss: 2.5909969625726363

Epoch: 6| Step: 9
Training loss: 2.0496243946883923
Validation loss: 2.6192417717883574

Epoch: 6| Step: 10
Training loss: 2.984193327002667
Validation loss: 2.5657902350362387

Epoch: 6| Step: 11
Training loss: 2.6089402253455845
Validation loss: 2.553890582270274

Epoch: 6| Step: 12
Training loss: 2.188955422286913
Validation loss: 2.6086627345956863

Epoch: 6| Step: 13
Training loss: 1.887615867241522
Validation loss: 2.5354741646091026

Epoch: 88| Step: 0
Training loss: 2.1354810627477474
Validation loss: 2.5621140352193095

Epoch: 6| Step: 1
Training loss: 2.7269661940635923
Validation loss: 2.6070654083687623

Epoch: 6| Step: 2
Training loss: 2.0450039531044655
Validation loss: 2.5449245293799314

Epoch: 6| Step: 3
Training loss: 3.073384929259737
Validation loss: 2.6384631605450597

Epoch: 6| Step: 4
Training loss: 1.7949216757557356
Validation loss: 2.609253992864976

Epoch: 6| Step: 5
Training loss: 2.192482206474663
Validation loss: 2.5923033973702094

Epoch: 6| Step: 6
Training loss: 1.5171555332073006
Validation loss: 2.564073157264123

Epoch: 6| Step: 7
Training loss: 2.715340240965493
Validation loss: 2.5264359838248405

Epoch: 6| Step: 8
Training loss: 2.553402265343655
Validation loss: 2.5929480005997005

Epoch: 6| Step: 9
Training loss: 2.23882922110654
Validation loss: 2.6652177709048934

Epoch: 6| Step: 10
Training loss: 1.6876304717311787
Validation loss: 2.5804512010239975

Epoch: 6| Step: 11
Training loss: 1.9855913054069168
Validation loss: 2.6107450531873675

Epoch: 6| Step: 12
Training loss: 2.248097357029844
Validation loss: 2.6447892920077885

Epoch: 6| Step: 13
Training loss: 1.5660317751022432
Validation loss: 2.6490552213718157

Epoch: 89| Step: 0
Training loss: 2.5260514930979676
Validation loss: 2.580068668614783

Epoch: 6| Step: 1
Training loss: 2.206538160487265
Validation loss: 2.576506505465313

Epoch: 6| Step: 2
Training loss: 2.077056495342621
Validation loss: 2.585629493833034

Epoch: 6| Step: 3
Training loss: 1.972575512735161
Validation loss: 2.5619360295403535

Epoch: 6| Step: 4
Training loss: 1.6748518066895763
Validation loss: 2.5118322272644313

Epoch: 6| Step: 5
Training loss: 2.0785547256734977
Validation loss: 2.600373822322633

Epoch: 6| Step: 6
Training loss: 1.9163076506799328
Validation loss: 2.531302337733334

Epoch: 6| Step: 7
Training loss: 1.880591130761451
Validation loss: 2.5452655941688724

Epoch: 6| Step: 8
Training loss: 1.8629180746201863
Validation loss: 2.595451463335537

Epoch: 6| Step: 9
Training loss: 2.24826873294369
Validation loss: 2.562834399974431

Epoch: 6| Step: 10
Training loss: 2.2218576079169425
Validation loss: 2.5832483421208874

Epoch: 6| Step: 11
Training loss: 2.0594369511410386
Validation loss: 2.5401476922737465

Epoch: 6| Step: 12
Training loss: 2.3285932646019276
Validation loss: 2.6181531804167033

Epoch: 6| Step: 13
Training loss: 3.3294911334287356
Validation loss: 2.595460794779718

Epoch: 90| Step: 0
Training loss: 2.126817599095653
Validation loss: 2.5936955978632503

Epoch: 6| Step: 1
Training loss: 2.0801162931137283
Validation loss: 2.5996132040246382

Epoch: 6| Step: 2
Training loss: 1.8890819715785279
Validation loss: 2.6685458555617285

Epoch: 6| Step: 3
Training loss: 2.3940570604476408
Validation loss: 2.6184539994841716

Epoch: 6| Step: 4
Training loss: 2.0395003393144413
Validation loss: 2.563565490149007

Epoch: 6| Step: 5
Training loss: 1.640192319944533
Validation loss: 2.6864293797384624

Epoch: 6| Step: 6
Training loss: 2.011588972035125
Validation loss: 2.632346665764252

Epoch: 6| Step: 7
Training loss: 1.7846626250347495
Validation loss: 2.567518979119737

Epoch: 6| Step: 8
Training loss: 1.634070828727176
Validation loss: 2.6597493477133405

Epoch: 6| Step: 9
Training loss: 2.7926172848953437
Validation loss: 2.6608000586348934

Epoch: 6| Step: 10
Training loss: 2.7014124743149237
Validation loss: 2.698896492814346

Epoch: 6| Step: 11
Training loss: 2.889232238107594
Validation loss: 2.609240058257422

Epoch: 6| Step: 12
Training loss: 2.102079760343945
Validation loss: 2.5114487443063442

Epoch: 6| Step: 13
Training loss: 2.240571293526388
Validation loss: 2.596299362496985

Epoch: 91| Step: 0
Training loss: 2.187016896988874
Validation loss: 2.5025665936674604

Epoch: 6| Step: 1
Training loss: 2.4127547292681775
Validation loss: 2.434866403548054

Epoch: 6| Step: 2
Training loss: 2.403988059917129
Validation loss: 2.5026475556601993

Epoch: 6| Step: 3
Training loss: 2.960940559808363
Validation loss: 2.514662327403993

Epoch: 6| Step: 4
Training loss: 2.4775406984437347
Validation loss: 2.5762789812205464

Epoch: 6| Step: 5
Training loss: 1.8778660803629177
Validation loss: 2.5434308157204684

Epoch: 6| Step: 6
Training loss: 1.6681937215634084
Validation loss: 2.539510544590978

Epoch: 6| Step: 7
Training loss: 1.9555395231649388
Validation loss: 2.584830639798681

Epoch: 6| Step: 8
Training loss: 2.010206643105589
Validation loss: 2.54295002998302

Epoch: 6| Step: 9
Training loss: 1.5667255485237268
Validation loss: 2.552978169309659

Epoch: 6| Step: 10
Training loss: 1.8731978338704363
Validation loss: 2.5385533061887067

Epoch: 6| Step: 11
Training loss: 2.3368585614230466
Validation loss: 2.521481979609306

Epoch: 6| Step: 12
Training loss: 2.171834492477183
Validation loss: 2.6425332542307145

Epoch: 6| Step: 13
Training loss: 2.7053376772196893
Validation loss: 2.61204549008589

Epoch: 92| Step: 0
Training loss: 1.6806555508936123
Validation loss: 2.5623834785082833

Epoch: 6| Step: 1
Training loss: 3.171453137836529
Validation loss: 2.6365290971531286

Epoch: 6| Step: 2
Training loss: 2.7800626470518974
Validation loss: 2.6173135451904654

Epoch: 6| Step: 3
Training loss: 2.3915273920460827
Validation loss: 2.576343066986777

Epoch: 6| Step: 4
Training loss: 1.8132458171809387
Validation loss: 2.6427918371456047

Epoch: 6| Step: 5
Training loss: 1.4273751324824688
Validation loss: 2.5657433786468773

Epoch: 6| Step: 6
Training loss: 2.2033219486159825
Validation loss: 2.6388962332863133

Epoch: 6| Step: 7
Training loss: 2.336812241500452
Validation loss: 2.618777225932497

Epoch: 6| Step: 8
Training loss: 2.0787741428792286
Validation loss: 2.62134418532388

Epoch: 6| Step: 9
Training loss: 1.5848017040844324
Validation loss: 2.5994887693015434

Epoch: 6| Step: 10
Training loss: 1.3845986506376038
Validation loss: 2.5563123165328987

Epoch: 6| Step: 11
Training loss: 2.344737137496977
Validation loss: 2.5015596293254823

Epoch: 6| Step: 12
Training loss: 1.694665389777562
Validation loss: 2.581798933526657

Epoch: 6| Step: 13
Training loss: 2.135533200937679
Validation loss: 2.5514967315601065

Epoch: 93| Step: 0
Training loss: 2.6354898937641664
Validation loss: 2.576033096103831

Epoch: 6| Step: 1
Training loss: 1.7255578894243562
Validation loss: 2.654574999297466

Epoch: 6| Step: 2
Training loss: 1.8552578776143092
Validation loss: 2.5528318955177336

Epoch: 6| Step: 3
Training loss: 1.9088693351888868
Validation loss: 2.590229203283211

Epoch: 6| Step: 4
Training loss: 2.1963574512056994
Validation loss: 2.601313780540853

Epoch: 6| Step: 5
Training loss: 1.7072414382270769
Validation loss: 2.5595883210291066

Epoch: 6| Step: 6
Training loss: 1.8012456398566352
Validation loss: 2.51559850232561

Epoch: 6| Step: 7
Training loss: 2.2306431904203663
Validation loss: 2.61665839165596

Epoch: 6| Step: 8
Training loss: 2.4035377574579266
Validation loss: 2.6385338533278024

Epoch: 6| Step: 9
Training loss: 2.5558970909594922
Validation loss: 2.6015833795605054

Epoch: 6| Step: 10
Training loss: 2.279705308474661
Validation loss: 2.550469060529067

Epoch: 6| Step: 11
Training loss: 2.065237367302069
Validation loss: 2.519619126475431

Epoch: 6| Step: 12
Training loss: 2.3914163314472243
Validation loss: 2.544308373529919

Epoch: 6| Step: 13
Training loss: 2.0629314780456407
Validation loss: 2.6264097500268524

Epoch: 94| Step: 0
Training loss: 1.905449746175158
Validation loss: 2.5682501282562114

Epoch: 6| Step: 1
Training loss: 1.6984862403929921
Validation loss: 2.5684094094163923

Epoch: 6| Step: 2
Training loss: 2.1072363290075136
Validation loss: 2.5373155266866454

Epoch: 6| Step: 3
Training loss: 2.2081218354293988
Validation loss: 2.6270602784643873

Epoch: 6| Step: 4
Training loss: 2.5022722408523195
Validation loss: 2.570540552351305

Epoch: 6| Step: 5
Training loss: 2.0984187667135474
Validation loss: 2.5878606062773506

Epoch: 6| Step: 6
Training loss: 2.398118982692762
Validation loss: 2.604165929158424

Epoch: 6| Step: 7
Training loss: 2.2167682662663872
Validation loss: 2.5787705663198994

Epoch: 6| Step: 8
Training loss: 1.699546203631666
Validation loss: 2.7021474816426676

Epoch: 6| Step: 9
Training loss: 2.5953876886379605
Validation loss: 2.7052464622147987

Epoch: 6| Step: 10
Training loss: 1.9101936945141254
Validation loss: 2.6124958555441173

Epoch: 6| Step: 11
Training loss: 2.2697804194383693
Validation loss: 2.649143241241968

Epoch: 6| Step: 12
Training loss: 1.5007579001378104
Validation loss: 2.569826940184369

Epoch: 6| Step: 13
Training loss: 2.133980455696966
Validation loss: 2.588414798649151

Epoch: 95| Step: 0
Training loss: 1.8372725157801744
Validation loss: 2.6079694422996975

Epoch: 6| Step: 1
Training loss: 2.113730222495579
Validation loss: 2.6159812310942483

Epoch: 6| Step: 2
Training loss: 1.8973638693286186
Validation loss: 2.6715223886516877

Epoch: 6| Step: 3
Training loss: 2.2632414809378156
Validation loss: 2.5745461332448114

Epoch: 6| Step: 4
Training loss: 2.591031223746483
Validation loss: 2.6177783052499337

Epoch: 6| Step: 5
Training loss: 1.9423655666930164
Validation loss: 2.528420377685999

Epoch: 6| Step: 6
Training loss: 2.788703446557521
Validation loss: 2.5375853168695723

Epoch: 6| Step: 7
Training loss: 2.150491294617939
Validation loss: 2.576977807867822

Epoch: 6| Step: 8
Training loss: 1.9562806538383064
Validation loss: 2.6120048260529796

Epoch: 6| Step: 9
Training loss: 1.6025479890062173
Validation loss: 2.6318524550637363

Epoch: 6| Step: 10
Training loss: 2.657673712262672
Validation loss: 2.5535427876942274

Epoch: 6| Step: 11
Training loss: 2.419410288185558
Validation loss: 2.5885787797463777

Epoch: 6| Step: 12
Training loss: 1.7789710340066234
Validation loss: 2.597653251780068

Epoch: 6| Step: 13
Training loss: 1.7985151020611194
Validation loss: 2.5568109178279355

Epoch: 96| Step: 0
Training loss: 1.747057143322187
Validation loss: 2.5638948226489

Epoch: 6| Step: 1
Training loss: 1.2846579469748778
Validation loss: 2.6636494365716152

Epoch: 6| Step: 2
Training loss: 2.5666769456864
Validation loss: 2.67920061290666

Epoch: 6| Step: 3
Training loss: 2.4468227025237135
Validation loss: 2.66679010006223

Epoch: 6| Step: 4
Training loss: 1.6805988057493766
Validation loss: 2.6569177124926227

Epoch: 6| Step: 5
Training loss: 1.9817480285642426
Validation loss: 2.6454143843283227

Epoch: 6| Step: 6
Training loss: 2.4888093349064686
Validation loss: 2.575532684967472

Epoch: 6| Step: 7
Training loss: 1.9638218431060825
Validation loss: 2.6358142648353495

Epoch: 6| Step: 8
Training loss: 2.129601825157891
Validation loss: 2.5342833314647786

Epoch: 6| Step: 9
Training loss: 1.9897883311276228
Validation loss: 2.621792423007279

Epoch: 6| Step: 10
Training loss: 2.415688766289269
Validation loss: 2.529133857962546

Epoch: 6| Step: 11
Training loss: 2.0716389563321758
Validation loss: 2.5960004840467343

Epoch: 6| Step: 12
Training loss: 2.4373773397247325
Validation loss: 2.5395898515859123

Epoch: 6| Step: 13
Training loss: 2.1501955919233513
Validation loss: 2.569265753457918

Epoch: 97| Step: 0
Training loss: 2.3384816276019436
Validation loss: 2.609667733041868

Epoch: 6| Step: 1
Training loss: 2.3886328481135726
Validation loss: 2.631303394346723

Epoch: 6| Step: 2
Training loss: 1.8675434619181746
Validation loss: 2.6189532192771923

Epoch: 6| Step: 3
Training loss: 2.634866790299751
Validation loss: 2.6088475743171946

Epoch: 6| Step: 4
Training loss: 1.3536988942088455
Validation loss: 2.5822387396489708

Epoch: 6| Step: 5
Training loss: 1.7064642411874373
Validation loss: 2.638070791712263

Epoch: 6| Step: 6
Training loss: 1.7884596429440887
Validation loss: 2.642921307053678

Epoch: 6| Step: 7
Training loss: 2.1093670880204627
Validation loss: 2.640726979109198

Epoch: 6| Step: 8
Training loss: 1.7313889926242796
Validation loss: 2.631652697316114

Epoch: 6| Step: 9
Training loss: 1.7784555835169809
Validation loss: 2.642651865386829

Epoch: 6| Step: 10
Training loss: 2.0422553426948418
Validation loss: 2.582838539196895

Epoch: 6| Step: 11
Training loss: 3.132719804338964
Validation loss: 2.503578073277559

Epoch: 6| Step: 12
Training loss: 2.950876176967104
Validation loss: 2.5752162361090623

Epoch: 6| Step: 13
Training loss: 1.7632297709483842
Validation loss: 2.6186849532929433

Epoch: 98| Step: 0
Training loss: 2.780669162405548
Validation loss: 2.5062624854128024

Epoch: 6| Step: 1
Training loss: 1.8452579344870996
Validation loss: 2.532501146969625

Epoch: 6| Step: 2
Training loss: 1.7867908298112796
Validation loss: 2.5600047174052643

Epoch: 6| Step: 3
Training loss: 1.848596378054027
Validation loss: 2.5543319345827427

Epoch: 6| Step: 4
Training loss: 2.0643027547678865
Validation loss: 2.631526855739541

Epoch: 6| Step: 5
Training loss: 1.8729767373550308
Validation loss: 2.5793897050629866

Epoch: 6| Step: 6
Training loss: 1.8583760503241358
Validation loss: 2.5467907944315327

Epoch: 6| Step: 7
Training loss: 2.017238473876066
Validation loss: 2.5603374722439085

Epoch: 6| Step: 8
Training loss: 2.1793158976683107
Validation loss: 2.575631957297373

Epoch: 6| Step: 9
Training loss: 2.0905402333134013
Validation loss: 2.478543713517947

Epoch: 6| Step: 10
Training loss: 1.9733737962457778
Validation loss: 2.6098690821526973

Epoch: 6| Step: 11
Training loss: 2.3900632509935797
Validation loss: 2.6341435871925416

Epoch: 6| Step: 12
Training loss: 2.0525532941137
Validation loss: 2.6254377302898804

Epoch: 6| Step: 13
Training loss: 2.2889966727416327
Validation loss: 2.540023840819883

Epoch: 99| Step: 0
Training loss: 2.169778594223203
Validation loss: 2.5710836874943546

Epoch: 6| Step: 1
Training loss: 1.613466709366855
Validation loss: 2.616920191840252

Epoch: 6| Step: 2
Training loss: 1.437628864648983
Validation loss: 2.748830069589625

Epoch: 6| Step: 3
Training loss: 2.0606077356977677
Validation loss: 2.6586334306264985

Epoch: 6| Step: 4
Training loss: 3.064494981838505
Validation loss: 2.677675483514184

Epoch: 6| Step: 5
Training loss: 2.779317977728652
Validation loss: 2.6548841143555113

Epoch: 6| Step: 6
Training loss: 2.2864752720326322
Validation loss: 2.6695098149696204

Epoch: 6| Step: 7
Training loss: 1.4819903845172666
Validation loss: 2.6196237943847684

Epoch: 6| Step: 8
Training loss: 1.884450113244997
Validation loss: 2.6112043626740653

Epoch: 6| Step: 9
Training loss: 1.7273862090773646
Validation loss: 2.5686277145397884

Epoch: 6| Step: 10
Training loss: 2.2370433746348235
Validation loss: 2.5753862727042764

Epoch: 6| Step: 11
Training loss: 2.2689576991825855
Validation loss: 2.5920581048758593

Epoch: 6| Step: 12
Training loss: 1.994267951868273
Validation loss: 2.5830419950380774

Epoch: 6| Step: 13
Training loss: 1.9011428457708366
Validation loss: 2.56916480447176

Epoch: 100| Step: 0
Training loss: 1.7074578142889194
Validation loss: 2.5294272527881523

Epoch: 6| Step: 1
Training loss: 1.8950247524929682
Validation loss: 2.5098824202973438

Epoch: 6| Step: 2
Training loss: 1.8310527343739584
Validation loss: 2.6163869667804414

Epoch: 6| Step: 3
Training loss: 1.7261177284120155
Validation loss: 2.547245583750088

Epoch: 6| Step: 4
Training loss: 2.3670718728206444
Validation loss: 2.588451366013612

Epoch: 6| Step: 5
Training loss: 2.171087547642049
Validation loss: 2.579003694856819

Epoch: 6| Step: 6
Training loss: 2.598295159033991
Validation loss: 2.605284341656381

Epoch: 6| Step: 7
Training loss: 1.6298684770377658
Validation loss: 2.6484187302726063

Epoch: 6| Step: 8
Training loss: 2.5051783337188054
Validation loss: 2.6365056910205933

Epoch: 6| Step: 9
Training loss: 2.0320469393302303
Validation loss: 2.6122797105016997

Epoch: 6| Step: 10
Training loss: 1.9157455829548036
Validation loss: 2.5980140841119197

Epoch: 6| Step: 11
Training loss: 1.8937476985904822
Validation loss: 2.5262299195500897

Epoch: 6| Step: 12
Training loss: 2.0770228625505345
Validation loss: 2.5649942881227465

Epoch: 6| Step: 13
Training loss: 2.767771776702363
Validation loss: 2.5521574567553347

Epoch: 101| Step: 0
Training loss: 1.7380350345728328
Validation loss: 2.616347949750183

Epoch: 6| Step: 1
Training loss: 2.084018925073839
Validation loss: 2.6125325117263265

Epoch: 6| Step: 2
Training loss: 1.5283672678988898
Validation loss: 2.561600395401045

Epoch: 6| Step: 3
Training loss: 1.9051362207724403
Validation loss: 2.625563561025562

Epoch: 6| Step: 4
Training loss: 2.143441345416061
Validation loss: 2.5756499769478824

Epoch: 6| Step: 5
Training loss: 1.8238506721807195
Validation loss: 2.6180278131267003

Epoch: 6| Step: 6
Training loss: 2.235944929983615
Validation loss: 2.600211876403564

Epoch: 6| Step: 7
Training loss: 1.9371804619907578
Validation loss: 2.569930043313599

Epoch: 6| Step: 8
Training loss: 2.3306301898647885
Validation loss: 2.6257349832127113

Epoch: 6| Step: 9
Training loss: 2.1349280069617493
Validation loss: 2.5948388445432196

Epoch: 6| Step: 10
Training loss: 1.983899757967702
Validation loss: 2.6571308919275376

Epoch: 6| Step: 11
Training loss: 2.3051820386055457
Validation loss: 2.5808901667616473

Epoch: 6| Step: 12
Training loss: 1.616061274580154
Validation loss: 2.6678055824588385

Epoch: 6| Step: 13
Training loss: 2.2999993697455827
Validation loss: 2.5623757557095486

Epoch: 102| Step: 0
Training loss: 1.6698120794954316
Validation loss: 2.695394778262776

Epoch: 6| Step: 1
Training loss: 1.7235243636208422
Validation loss: 2.549802645981126

Epoch: 6| Step: 2
Training loss: 2.5952833308372667
Validation loss: 2.6329752704778904

Epoch: 6| Step: 3
Training loss: 1.9420073593699498
Validation loss: 2.563707950866562

Epoch: 6| Step: 4
Training loss: 2.035509778030437
Validation loss: 2.623144856637507

Epoch: 6| Step: 5
Training loss: 2.251494441171892
Validation loss: 2.5506330508399735

Epoch: 6| Step: 6
Training loss: 2.4921554515535846
Validation loss: 2.6674198388374744

Epoch: 6| Step: 7
Training loss: 1.8590483819371288
Validation loss: 2.628261160148866

Epoch: 6| Step: 8
Training loss: 2.391143842256072
Validation loss: 2.5358472449599794

Epoch: 6| Step: 9
Training loss: 1.2724970990280928
Validation loss: 2.5927954299865688

Epoch: 6| Step: 10
Training loss: 1.316973193417921
Validation loss: 2.5587165938921985

Epoch: 6| Step: 11
Training loss: 2.0383225775637914
Validation loss: 2.5692190145858853

Epoch: 6| Step: 12
Training loss: 2.8556354020067647
Validation loss: 2.5608617926953863

Epoch: 6| Step: 13
Training loss: 1.5767861909839382
Validation loss: 2.628065559601038

Epoch: 103| Step: 0
Training loss: 2.419494049209999
Validation loss: 2.566150128006301

Epoch: 6| Step: 1
Training loss: 1.2973851498909617
Validation loss: 2.642229048215973

Epoch: 6| Step: 2
Training loss: 2.1134691983341343
Validation loss: 2.66435460850531

Epoch: 6| Step: 3
Training loss: 1.656375448406361
Validation loss: 2.6289886718647173

Epoch: 6| Step: 4
Training loss: 1.7094004794772524
Validation loss: 2.580500331142212

Epoch: 6| Step: 5
Training loss: 2.249832359002715
Validation loss: 2.6255136623081583

Epoch: 6| Step: 6
Training loss: 1.7360260124542974
Validation loss: 2.5663726510258624

Epoch: 6| Step: 7
Training loss: 2.301456786173281
Validation loss: 2.5794425911255074

Epoch: 6| Step: 8
Training loss: 2.452787145200962
Validation loss: 2.6752388286038276

Epoch: 6| Step: 9
Training loss: 1.9822850072056946
Validation loss: 2.634605152096691

Epoch: 6| Step: 10
Training loss: 1.914108587216197
Validation loss: 2.6724332557149144

Epoch: 6| Step: 11
Training loss: 1.7034104834153028
Validation loss: 2.5820344972036993

Epoch: 6| Step: 12
Training loss: 1.8319984546971362
Validation loss: 2.634028409615921

Epoch: 6| Step: 13
Training loss: 2.955862562667602
Validation loss: 2.574072239844901

Epoch: 104| Step: 0
Training loss: 1.61209587533344
Validation loss: 2.6562621471650867

Epoch: 6| Step: 1
Training loss: 1.3474926835464835
Validation loss: 2.6206539446433728

Epoch: 6| Step: 2
Training loss: 1.9923190802709525
Validation loss: 2.5503793334555174

Epoch: 6| Step: 3
Training loss: 1.8483146155842551
Validation loss: 2.570898652032638

Epoch: 6| Step: 4
Training loss: 2.804826143286118
Validation loss: 2.639241444867644

Epoch: 6| Step: 5
Training loss: 2.1920137974172578
Validation loss: 2.625204865469205

Epoch: 6| Step: 6
Training loss: 2.0629922683948156
Validation loss: 2.5625763238224626

Epoch: 6| Step: 7
Training loss: 2.2794131892451373
Validation loss: 2.5630361724892694

Epoch: 6| Step: 8
Training loss: 1.7579566726900353
Validation loss: 2.5378241859645794

Epoch: 6| Step: 9
Training loss: 1.8709982447450315
Validation loss: 2.595232635561465

Epoch: 6| Step: 10
Training loss: 2.2860442693967773
Validation loss: 2.5835119052408646

Epoch: 6| Step: 11
Training loss: 2.25708333949281
Validation loss: 2.6144988260379

Epoch: 6| Step: 12
Training loss: 1.7006557658369643
Validation loss: 2.549925928972338

Epoch: 6| Step: 13
Training loss: 2.264726658005274
Validation loss: 2.5763919669787265

Epoch: 105| Step: 0
Training loss: 2.06481687865307
Validation loss: 2.5196008953552544

Epoch: 6| Step: 1
Training loss: 1.511589103876288
Validation loss: 2.700466576046201

Epoch: 6| Step: 2
Training loss: 1.6642121440243107
Validation loss: 2.564218379150002

Epoch: 6| Step: 3
Training loss: 1.7653915115855936
Validation loss: 2.685801967643252

Epoch: 6| Step: 4
Training loss: 1.9179257390002942
Validation loss: 2.5397945815847662

Epoch: 6| Step: 5
Training loss: 2.4117824811704542
Validation loss: 2.720152365353253

Epoch: 6| Step: 6
Training loss: 2.5423533549070783
Validation loss: 2.524964664702985

Epoch: 6| Step: 7
Training loss: 2.1005223759851166
Validation loss: 2.6242126616195063

Epoch: 6| Step: 8
Training loss: 1.920138062639233
Validation loss: 2.6283711932335514

Epoch: 6| Step: 9
Training loss: 2.389937956575295
Validation loss: 2.62612698598099

Epoch: 6| Step: 10
Training loss: 2.4256831593115527
Validation loss: 2.627985890955915

Epoch: 6| Step: 11
Training loss: 1.6203382087220344
Validation loss: 2.5928934360472704

Epoch: 6| Step: 12
Training loss: 2.0373577138447234
Validation loss: 2.5605884493341375

Epoch: 6| Step: 13
Training loss: 1.7290139035073513
Validation loss: 2.5773405480728697

Epoch: 106| Step: 0
Training loss: 1.8617604445103915
Validation loss: 2.559403836278437

Epoch: 6| Step: 1
Training loss: 2.300971601348261
Validation loss: 2.5381190968219163

Epoch: 6| Step: 2
Training loss: 2.304674361886546
Validation loss: 2.591126060729888

Epoch: 6| Step: 3
Training loss: 1.553845661683306
Validation loss: 2.5556212341350504

Epoch: 6| Step: 4
Training loss: 2.1556061598921405
Validation loss: 2.5969469292292704

Epoch: 6| Step: 5
Training loss: 1.9102182826791523
Validation loss: 2.651917503388528

Epoch: 6| Step: 6
Training loss: 1.9984381060565808
Validation loss: 2.5711909283973897

Epoch: 6| Step: 7
Training loss: 2.178814456793829
Validation loss: 2.5020138258944615

Epoch: 6| Step: 8
Training loss: 2.107460113546159
Validation loss: 2.6042132615053535

Epoch: 6| Step: 9
Training loss: 2.701531795152922
Validation loss: 2.5639383264663396

Epoch: 6| Step: 10
Training loss: 1.557274204866457
Validation loss: 2.553755921842282

Epoch: 6| Step: 11
Training loss: 1.9174253855565373
Validation loss: 2.5898273174058

Epoch: 6| Step: 12
Training loss: 1.6241677427149666
Validation loss: 2.6911507140545337

Epoch: 6| Step: 13
Training loss: 1.6589578768790096
Validation loss: 2.6062913136672554

Epoch: 107| Step: 0
Training loss: 1.2962809661433068
Validation loss: 2.717826613375345

Epoch: 6| Step: 1
Training loss: 2.251154921079118
Validation loss: 2.6392421223877385

Epoch: 6| Step: 2
Training loss: 2.016085313384512
Validation loss: 2.651762474010819

Epoch: 6| Step: 3
Training loss: 1.8739628784509077
Validation loss: 2.6102590376828374

Epoch: 6| Step: 4
Training loss: 1.9138829983991392
Validation loss: 2.655614574947889

Epoch: 6| Step: 5
Training loss: 2.5761346705875874
Validation loss: 2.6485576321073085

Epoch: 6| Step: 6
Training loss: 1.5507741779002786
Validation loss: 2.6033430755358054

Epoch: 6| Step: 7
Training loss: 2.562447151941702
Validation loss: 2.6379422586883026

Epoch: 6| Step: 8
Training loss: 1.6240912610799942
Validation loss: 2.6404661473152804

Epoch: 6| Step: 9
Training loss: 1.2747134503759887
Validation loss: 2.596007333825464

Epoch: 6| Step: 10
Training loss: 2.1498248805209084
Validation loss: 2.6656371652639343

Epoch: 6| Step: 11
Training loss: 1.2574137653943747
Validation loss: 2.675942669011522

Epoch: 6| Step: 12
Training loss: 2.4124875162226593
Validation loss: 2.603793526937462

Epoch: 6| Step: 13
Training loss: 1.9250472025843248
Validation loss: 2.638461767453511

Epoch: 108| Step: 0
Training loss: 1.4064997133430328
Validation loss: 2.5643734790048436

Epoch: 6| Step: 1
Training loss: 2.4823248699452556
Validation loss: 2.540028831288266

Epoch: 6| Step: 2
Training loss: 1.809300327901421
Validation loss: 2.7032067832261637

Epoch: 6| Step: 3
Training loss: 1.5863595786096178
Validation loss: 2.626124519595647

Epoch: 6| Step: 4
Training loss: 2.6256337082102563
Validation loss: 2.7096917389285258

Epoch: 6| Step: 5
Training loss: 2.3137542828438318
Validation loss: 2.5634620070271295

Epoch: 6| Step: 6
Training loss: 2.1247487761151396
Validation loss: 2.72002790095474

Epoch: 6| Step: 7
Training loss: 2.091379560343742
Validation loss: 2.7105630841439163

Epoch: 6| Step: 8
Training loss: 1.700612726303947
Validation loss: 2.656431543466785

Epoch: 6| Step: 9
Training loss: 1.906854877497034
Validation loss: 2.612887396068824

Epoch: 6| Step: 10
Training loss: 2.2878318837697744
Validation loss: 2.662579859400052

Epoch: 6| Step: 11
Training loss: 1.0969211383908015
Validation loss: 2.641437172372577

Epoch: 6| Step: 12
Training loss: 2.1948855381972323
Validation loss: 2.515806266619694

Epoch: 6| Step: 13
Training loss: 1.8099239063601444
Validation loss: 2.4845345563854355

Epoch: 109| Step: 0
Training loss: 1.6400622901484616
Validation loss: 2.6009045629047884

Epoch: 6| Step: 1
Training loss: 1.9185674474898262
Validation loss: 2.613633721743569

Epoch: 6| Step: 2
Training loss: 2.254870018606786
Validation loss: 2.6142630564566147

Epoch: 6| Step: 3
Training loss: 2.004962486620113
Validation loss: 2.5979313831376487

Epoch: 6| Step: 4
Training loss: 1.5910970261034427
Validation loss: 2.532509102084795

Epoch: 6| Step: 5
Training loss: 2.595575907899951
Validation loss: 2.767414383406737

Epoch: 6| Step: 6
Training loss: 1.7857272447388317
Validation loss: 2.7029884759608134

Epoch: 6| Step: 7
Training loss: 1.760869601818418
Validation loss: 2.582128941336962

Epoch: 6| Step: 8
Training loss: 1.949458472546066
Validation loss: 2.5986161143652726

Epoch: 6| Step: 9
Training loss: 1.167405876351788
Validation loss: 2.6058372835528476

Epoch: 6| Step: 10
Training loss: 2.192926488128689
Validation loss: 2.633768875785867

Epoch: 6| Step: 11
Training loss: 2.224722975726548
Validation loss: 2.76905101922267

Epoch: 6| Step: 12
Training loss: 2.347705301035774
Validation loss: 2.6901430396157635

Epoch: 6| Step: 13
Training loss: 1.4026519521719865
Validation loss: 2.7152684892613164

Epoch: 110| Step: 0
Training loss: 1.801667696552294
Validation loss: 2.5604895326588766

Epoch: 6| Step: 1
Training loss: 1.9356338989526238
Validation loss: 2.6797940276596517

Epoch: 6| Step: 2
Training loss: 2.1746248908334787
Validation loss: 2.7374343469373503

Epoch: 6| Step: 3
Training loss: 2.4552210703214468
Validation loss: 2.65259842546492

Epoch: 6| Step: 4
Training loss: 1.8316235444486106
Validation loss: 2.61391606624725

Epoch: 6| Step: 5
Training loss: 1.4134619686379568
Validation loss: 2.7924584409375557

Epoch: 6| Step: 6
Training loss: 2.532418628827647
Validation loss: 2.5597735220844884

Epoch: 6| Step: 7
Training loss: 2.005830848141842
Validation loss: 2.5641134501495113

Epoch: 6| Step: 8
Training loss: 2.238967763596283
Validation loss: 2.628382607503907

Epoch: 6| Step: 9
Training loss: 1.7811483387630422
Validation loss: 2.6347586120557382

Epoch: 6| Step: 10
Training loss: 1.628355376772142
Validation loss: 2.5738324274391986

Epoch: 6| Step: 11
Training loss: 1.8325838016224174
Validation loss: 2.6143752290094993

Epoch: 6| Step: 12
Training loss: 1.8169807427980893
Validation loss: 2.5315746993922392

Epoch: 6| Step: 13
Training loss: 1.7398344837039599
Validation loss: 2.5762516960867714

Epoch: 111| Step: 0
Training loss: 1.8731023086125496
Validation loss: 2.5679637995928384

Epoch: 6| Step: 1
Training loss: 1.6798010499409781
Validation loss: 2.586900460694804

Epoch: 6| Step: 2
Training loss: 2.1346596345128432
Validation loss: 2.5877836154909932

Epoch: 6| Step: 3
Training loss: 1.6962944035069916
Validation loss: 2.5923775255094776

Epoch: 6| Step: 4
Training loss: 1.6990265836246952
Validation loss: 2.6344454688394627

Epoch: 6| Step: 5
Training loss: 1.5921919443594437
Validation loss: 2.616331167236292

Epoch: 6| Step: 6
Training loss: 2.037265731355694
Validation loss: 2.6080599914829787

Epoch: 6| Step: 7
Training loss: 2.308781288649568
Validation loss: 2.620507740927631

Epoch: 6| Step: 8
Training loss: 1.416935652085471
Validation loss: 2.6547850365071857

Epoch: 6| Step: 9
Training loss: 2.107335779165514
Validation loss: 2.676890256180487

Epoch: 6| Step: 10
Training loss: 1.6333655192000116
Validation loss: 2.6697062117144004

Epoch: 6| Step: 11
Training loss: 2.105488453279212
Validation loss: 2.7329982525042573

Epoch: 6| Step: 12
Training loss: 2.0637811092109164
Validation loss: 2.7080220165813325

Epoch: 6| Step: 13
Training loss: 2.479733912436828
Validation loss: 2.6351969229014127

Epoch: 112| Step: 0
Training loss: 1.6151291283633769
Validation loss: 2.7036105475085512

Epoch: 6| Step: 1
Training loss: 1.6941451171365103
Validation loss: 2.6288661037363044

Epoch: 6| Step: 2
Training loss: 1.8778107873785341
Validation loss: 2.6652575037917727

Epoch: 6| Step: 3
Training loss: 1.5646644859076637
Validation loss: 2.619974957848765

Epoch: 6| Step: 4
Training loss: 1.5692402229484612
Validation loss: 2.527143813434469

Epoch: 6| Step: 5
Training loss: 1.7842773009909825
Validation loss: 2.5461273344091238

Epoch: 6| Step: 6
Training loss: 2.2245866541585544
Validation loss: 2.646273153399273

Epoch: 6| Step: 7
Training loss: 2.669939198748205
Validation loss: 2.5456532393301146

Epoch: 6| Step: 8
Training loss: 1.8975345049549184
Validation loss: 2.6508185262145583

Epoch: 6| Step: 9
Training loss: 2.0623145742583118
Validation loss: 2.599711694382807

Epoch: 6| Step: 10
Training loss: 2.060459167638696
Validation loss: 2.604945491042313

Epoch: 6| Step: 11
Training loss: 1.40664709630493
Validation loss: 2.6429492269770876

Epoch: 6| Step: 12
Training loss: 1.8145910894298967
Validation loss: 2.6250253403666677

Epoch: 6| Step: 13
Training loss: 2.3157510329323183
Validation loss: 2.676003254314928

Epoch: 113| Step: 0
Training loss: 2.1091557141515382
Validation loss: 2.76505938994472

Epoch: 6| Step: 1
Training loss: 1.6518171476812376
Validation loss: 2.6786088468572022

Epoch: 6| Step: 2
Training loss: 1.498881717903837
Validation loss: 2.707819410617211

Epoch: 6| Step: 3
Training loss: 2.594856302034941
Validation loss: 2.7183373236690245

Epoch: 6| Step: 4
Training loss: 1.2928726759882965
Validation loss: 2.5609442787786687

Epoch: 6| Step: 5
Training loss: 1.8597038042433565
Validation loss: 2.7151473573115124

Epoch: 6| Step: 6
Training loss: 2.2910091728516346
Validation loss: 2.711914707211693

Epoch: 6| Step: 7
Training loss: 1.454392731299875
Validation loss: 2.584458065274048

Epoch: 6| Step: 8
Training loss: 1.6367386336473082
Validation loss: 2.643850850375407

Epoch: 6| Step: 9
Training loss: 2.2224520034670814
Validation loss: 2.542444193579842

Epoch: 6| Step: 10
Training loss: 1.448797200629628
Validation loss: 2.5824005740026807

Epoch: 6| Step: 11
Training loss: 1.7944050938425542
Validation loss: 2.6419925496710808

Epoch: 6| Step: 12
Training loss: 1.5076864713663654
Validation loss: 2.4976990760629336

Epoch: 6| Step: 13
Training loss: 2.6665566143532877
Validation loss: 2.5972487051073183

Epoch: 114| Step: 0
Training loss: 2.238671393619899
Validation loss: 2.6286093254620333

Epoch: 6| Step: 1
Training loss: 2.466930733112277
Validation loss: 2.590172349308657

Epoch: 6| Step: 2
Training loss: 1.7752729823853302
Validation loss: 2.662417846630074

Epoch: 6| Step: 3
Training loss: 2.051333863417084
Validation loss: 2.569235671786371

Epoch: 6| Step: 4
Training loss: 2.2304787977964358
Validation loss: 2.6237623082187724

Epoch: 6| Step: 5
Training loss: 1.8502236205345253
Validation loss: 2.6146596286984694

Epoch: 6| Step: 6
Training loss: 1.8430241594640489
Validation loss: 2.5941049264026312

Epoch: 6| Step: 7
Training loss: 1.7825303411910962
Validation loss: 2.5549152828785857

Epoch: 6| Step: 8
Training loss: 1.7601671512298356
Validation loss: 2.6370936148456074

Epoch: 6| Step: 9
Training loss: 2.003707072749465
Validation loss: 2.575553088987433

Epoch: 6| Step: 10
Training loss: 1.5316957097556732
Validation loss: 2.6191614402875016

Epoch: 6| Step: 11
Training loss: 1.7464649736030256
Validation loss: 2.5796310187567775

Epoch: 6| Step: 12
Training loss: 1.6772717514185618
Validation loss: 2.6640810551001857

Epoch: 6| Step: 13
Training loss: 1.4833967498910332
Validation loss: 2.6280392506173187

Epoch: 115| Step: 0
Training loss: 1.3472617636227373
Validation loss: 2.571367072575967

Epoch: 6| Step: 1
Training loss: 1.9344237732785554
Validation loss: 2.676965040470496

Epoch: 6| Step: 2
Training loss: 1.715102052460437
Validation loss: 2.7482374640778366

Epoch: 6| Step: 3
Training loss: 1.5917097009296926
Validation loss: 2.6809332707206432

Epoch: 6| Step: 4
Training loss: 1.7087478910041078
Validation loss: 2.5859540495098026

Epoch: 6| Step: 5
Training loss: 1.9980452044378403
Validation loss: 2.609910837613862

Epoch: 6| Step: 6
Training loss: 2.165171865641079
Validation loss: 2.5835097211690927

Epoch: 6| Step: 7
Training loss: 2.863096056852043
Validation loss: 2.639876776935808

Epoch: 6| Step: 8
Training loss: 1.9080133880649355
Validation loss: 2.6152203886889316

Epoch: 6| Step: 9
Training loss: 1.9189079766366293
Validation loss: 2.6465968184378665

Epoch: 6| Step: 10
Training loss: 1.8267482561954347
Validation loss: 2.6733432030039777

Epoch: 6| Step: 11
Training loss: 1.7577646884773808
Validation loss: 2.6200512301796834

Epoch: 6| Step: 12
Training loss: 1.3823027452467138
Validation loss: 2.647339494791052

Epoch: 6| Step: 13
Training loss: 1.9815463232593211
Validation loss: 2.6403111002268154

Epoch: 116| Step: 0
Training loss: 2.3074229413326
Validation loss: 2.612644652114336

Epoch: 6| Step: 1
Training loss: 1.776852047155094
Validation loss: 2.682814231757951

Epoch: 6| Step: 2
Training loss: 2.0834372176654647
Validation loss: 2.567074801354413

Epoch: 6| Step: 3
Training loss: 2.1398545709554346
Validation loss: 2.6456862631545404

Epoch: 6| Step: 4
Training loss: 2.2050455798846644
Validation loss: 2.741363503025087

Epoch: 6| Step: 5
Training loss: 1.7689310365370172
Validation loss: 2.7728799178862262

Epoch: 6| Step: 6
Training loss: 1.2175010737545597
Validation loss: 2.744759334443753

Epoch: 6| Step: 7
Training loss: 1.5711034045119587
Validation loss: 2.734373677571295

Epoch: 6| Step: 8
Training loss: 1.7065954284900007
Validation loss: 2.6740174060493738

Epoch: 6| Step: 9
Training loss: 1.8699979818812613
Validation loss: 2.672672710351287

Epoch: 6| Step: 10
Training loss: 2.056967974601247
Validation loss: 2.6387785074226207

Epoch: 6| Step: 11
Training loss: 1.9161807425587691
Validation loss: 2.6874614905030563

Epoch: 6| Step: 12
Training loss: 2.1077551379362314
Validation loss: 2.6374250958791006

Epoch: 6| Step: 13
Training loss: 1.3308296041291088
Validation loss: 2.610092597405277

Epoch: 117| Step: 0
Training loss: 2.501401508399958
Validation loss: 2.61471338949163

Epoch: 6| Step: 1
Training loss: 1.8764471191712657
Validation loss: 2.707670414317592

Epoch: 6| Step: 2
Training loss: 2.0911117557268346
Validation loss: 2.7098973722133977

Epoch: 6| Step: 3
Training loss: 1.8962786923414818
Validation loss: 2.5978945209341386

Epoch: 6| Step: 4
Training loss: 1.986008219806606
Validation loss: 2.670788564520047

Epoch: 6| Step: 5
Training loss: 1.8176839293086864
Validation loss: 2.6985005271043607

Epoch: 6| Step: 6
Training loss: 2.074491608627313
Validation loss: 2.6287635435734096

Epoch: 6| Step: 7
Training loss: 1.2828921517514684
Validation loss: 2.6403847158083162

Epoch: 6| Step: 8
Training loss: 1.8380982365843765
Validation loss: 2.727754916928125

Epoch: 6| Step: 9
Training loss: 1.7693485393048027
Validation loss: 2.638434093725709

Epoch: 6| Step: 10
Training loss: 1.6893964636677936
Validation loss: 2.7519327076753983

Epoch: 6| Step: 11
Training loss: 2.1173802812369567
Validation loss: 2.68516899270867

Epoch: 6| Step: 12
Training loss: 1.7753583277753657
Validation loss: 2.708571061680324

Epoch: 6| Step: 13
Training loss: 1.8096143178843904
Validation loss: 2.640613322636594

Epoch: 118| Step: 0
Training loss: 1.8960762566952873
Validation loss: 2.6295347855805766

Epoch: 6| Step: 1
Training loss: 1.5299036763605904
Validation loss: 2.624455895118522

Epoch: 6| Step: 2
Training loss: 1.6144119992153332
Validation loss: 2.627707129969924

Epoch: 6| Step: 3
Training loss: 1.1786102530042037
Validation loss: 2.5980207832803117

Epoch: 6| Step: 4
Training loss: 1.5525565567403468
Validation loss: 2.641988293255328

Epoch: 6| Step: 5
Training loss: 2.3736933074978963
Validation loss: 2.6061749433021038

Epoch: 6| Step: 6
Training loss: 2.049981940585349
Validation loss: 2.6620390097446474

Epoch: 6| Step: 7
Training loss: 1.6709809096208679
Validation loss: 2.6263575298235495

Epoch: 6| Step: 8
Training loss: 1.4567309522664986
Validation loss: 2.5781680170959427

Epoch: 6| Step: 9
Training loss: 1.8762018166797065
Validation loss: 2.7076017174087004

Epoch: 6| Step: 10
Training loss: 2.4443376932050227
Validation loss: 2.684094637232294

Epoch: 6| Step: 11
Training loss: 1.6238717050143812
Validation loss: 2.6640712704332357

Epoch: 6| Step: 12
Training loss: 2.1919601746721207
Validation loss: 2.7184989784083977

Epoch: 6| Step: 13
Training loss: 2.3294673864305033
Validation loss: 2.719564396277141

Epoch: 119| Step: 0
Training loss: 3.0845840769733415
Validation loss: 2.723362090948414

Epoch: 6| Step: 1
Training loss: 1.7596862300867544
Validation loss: 2.7316214075425784

Epoch: 6| Step: 2
Training loss: 1.7749277315068757
Validation loss: 2.6967678103283346

Epoch: 6| Step: 3
Training loss: 1.4015177469752818
Validation loss: 2.6899275203191086

Epoch: 6| Step: 4
Training loss: 2.208155738839037
Validation loss: 2.6156946887748282

Epoch: 6| Step: 5
Training loss: 1.99372618849356
Validation loss: 2.683971557971515

Epoch: 6| Step: 6
Training loss: 1.618232426324448
Validation loss: 2.5794445167554456

Epoch: 6| Step: 7
Training loss: 1.914293360898214
Validation loss: 2.6354317243746483

Epoch: 6| Step: 8
Training loss: 1.7077111607645636
Validation loss: 2.6356886822590044

Epoch: 6| Step: 9
Training loss: 1.8488310291002308
Validation loss: 2.665336162724344

Epoch: 6| Step: 10
Training loss: 1.8274044344816192
Validation loss: 2.6134956017260085

Epoch: 6| Step: 11
Training loss: 2.0075989843456785
Validation loss: 2.6658326473952667

Epoch: 6| Step: 12
Training loss: 1.1290634732172256
Validation loss: 2.7279411262692443

Epoch: 6| Step: 13
Training loss: 1.7844047049540113
Validation loss: 2.631871403329566

Epoch: 120| Step: 0
Training loss: 1.80267724042722
Validation loss: 2.606665508468384

Epoch: 6| Step: 1
Training loss: 1.7813398773540476
Validation loss: 2.6517809952985503

Epoch: 6| Step: 2
Training loss: 1.6027540287055848
Validation loss: 2.5547006122590914

Epoch: 6| Step: 3
Training loss: 1.5829074270057908
Validation loss: 2.667228331622977

Epoch: 6| Step: 4
Training loss: 2.0902959316587637
Validation loss: 2.6197005547415846

Epoch: 6| Step: 5
Training loss: 1.9036344500895834
Validation loss: 2.5635613670248345

Epoch: 6| Step: 6
Training loss: 1.5446046293711635
Validation loss: 2.675161352074559

Epoch: 6| Step: 7
Training loss: 2.3108190664774266
Validation loss: 2.583844616244402

Epoch: 6| Step: 8
Training loss: 1.6706608436698136
Validation loss: 2.6606944730489768

Epoch: 6| Step: 9
Training loss: 2.258832760399301
Validation loss: 2.636886086511072

Epoch: 6| Step: 10
Training loss: 1.6140714100446836
Validation loss: 2.6101325909294837

Epoch: 6| Step: 11
Training loss: 1.688253870101689
Validation loss: 2.600020966689839

Epoch: 6| Step: 12
Training loss: 1.3956894966525628
Validation loss: 2.6010888998386994

Epoch: 6| Step: 13
Training loss: 1.8089213064357437
Validation loss: 2.628991498315994

Epoch: 121| Step: 0
Training loss: 2.0316960945324305
Validation loss: 2.685281666000394

Epoch: 6| Step: 1
Training loss: 1.4041135453421123
Validation loss: 2.6225206988753906

Epoch: 6| Step: 2
Training loss: 1.8741891379201503
Validation loss: 2.6815796336040187

Epoch: 6| Step: 3
Training loss: 1.80177971224411
Validation loss: 2.6659660660791684

Epoch: 6| Step: 4
Training loss: 1.1729271806389103
Validation loss: 2.7553390851691857

Epoch: 6| Step: 5
Training loss: 1.8665196329632932
Validation loss: 2.7122052514511035

Epoch: 6| Step: 6
Training loss: 2.679548877211194
Validation loss: 2.7847474214127685

Epoch: 6| Step: 7
Training loss: 1.7856572823281742
Validation loss: 2.7515428723269375

Epoch: 6| Step: 8
Training loss: 1.8477759937413611
Validation loss: 2.8511062047973477

Epoch: 6| Step: 9
Training loss: 1.5434807422895978
Validation loss: 2.6348161478102488

Epoch: 6| Step: 10
Training loss: 1.8026162023031376
Validation loss: 2.7516574921927726

Epoch: 6| Step: 11
Training loss: 1.3750465125106452
Validation loss: 2.7393141107786056

Epoch: 6| Step: 12
Training loss: 1.781011264262061
Validation loss: 2.6366909600194472

Epoch: 6| Step: 13
Training loss: 1.2978580379970368
Validation loss: 2.6006016298060084

Epoch: 122| Step: 0
Training loss: 1.671615009948641
Validation loss: 2.585842226853005

Epoch: 6| Step: 1
Training loss: 1.3863129357790047
Validation loss: 2.6536710449059324

Epoch: 6| Step: 2
Training loss: 1.5077634022679514
Validation loss: 2.669259201892849

Epoch: 6| Step: 3
Training loss: 2.500245368360485
Validation loss: 2.769734635661994

Epoch: 6| Step: 4
Training loss: 1.5488561408839132
Validation loss: 2.58740974612862

Epoch: 6| Step: 5
Training loss: 2.1577316943043945
Validation loss: 2.6681419230716963

Epoch: 6| Step: 6
Training loss: 2.1333105602638365
Validation loss: 2.654175168677047

Epoch: 6| Step: 7
Training loss: 1.4888828293280076
Validation loss: 2.795115615452979

Epoch: 6| Step: 8
Training loss: 1.973149908257181
Validation loss: 2.609746544858656

Epoch: 6| Step: 9
Training loss: 1.7011393599791618
Validation loss: 2.661060958032206

Epoch: 6| Step: 10
Training loss: 1.4659479887454354
Validation loss: 2.7454750083860837

Epoch: 6| Step: 11
Training loss: 1.543411770729934
Validation loss: 2.673116310098963

Epoch: 6| Step: 12
Training loss: 1.6623386534218225
Validation loss: 2.6710509280528276

Epoch: 6| Step: 13
Training loss: 1.6625801612056763
Validation loss: 2.7380138054381944

Epoch: 123| Step: 0
Training loss: 1.4738460358704948
Validation loss: 2.6427551646300174

Epoch: 6| Step: 1
Training loss: 1.1255500296578094
Validation loss: 2.6900910595368055

Epoch: 6| Step: 2
Training loss: 1.6628890937437892
Validation loss: 2.6681457282105834

Epoch: 6| Step: 3
Training loss: 1.6454447114431217
Validation loss: 2.6304373059207546

Epoch: 6| Step: 4
Training loss: 1.730557476033791
Validation loss: 2.63788103271078

Epoch: 6| Step: 5
Training loss: 1.983994695310269
Validation loss: 2.6700121090646536

Epoch: 6| Step: 6
Training loss: 2.540493042769475
Validation loss: 2.6463697195143516

Epoch: 6| Step: 7
Training loss: 1.5014029935177604
Validation loss: 2.7129366536420454

Epoch: 6| Step: 8
Training loss: 2.3407307823734316
Validation loss: 2.587273405353477

Epoch: 6| Step: 9
Training loss: 1.1329409296305097
Validation loss: 2.7351010621092917

Epoch: 6| Step: 10
Training loss: 1.5474470217607612
Validation loss: 2.727625496643552

Epoch: 6| Step: 11
Training loss: 2.217276070178614
Validation loss: 2.692868998374827

Epoch: 6| Step: 12
Training loss: 2.011600231642301
Validation loss: 2.651731155357799

Epoch: 6| Step: 13
Training loss: 1.5550322030710138
Validation loss: 2.71440348542969

Epoch: 124| Step: 0
Training loss: 1.9270915744364714
Validation loss: 2.7616557141510625

Epoch: 6| Step: 1
Training loss: 1.52555012082784
Validation loss: 2.6253116967565875

Epoch: 6| Step: 2
Training loss: 1.6800736094424975
Validation loss: 2.7360217848481203

Epoch: 6| Step: 3
Training loss: 1.8516723342703474
Validation loss: 2.686485246807261

Epoch: 6| Step: 4
Training loss: 1.7621353232067878
Validation loss: 2.707839045290842

Epoch: 6| Step: 5
Training loss: 2.356666880188986
Validation loss: 2.6680769519079255

Epoch: 6| Step: 6
Training loss: 1.8662532879442097
Validation loss: 2.6515775087793862

Epoch: 6| Step: 7
Training loss: 2.7002149143162835
Validation loss: 2.796300477419383

Epoch: 6| Step: 8
Training loss: 1.6693956047794538
Validation loss: 2.6202357821378914

Epoch: 6| Step: 9
Training loss: 1.1889284476911333
Validation loss: 2.628490579513843

Epoch: 6| Step: 10
Training loss: 1.488851282884764
Validation loss: 2.700964076796977

Epoch: 6| Step: 11
Training loss: 1.4826253115617725
Validation loss: 2.702448162977963

Epoch: 6| Step: 12
Training loss: 1.052435668012188
Validation loss: 2.6934785657461453

Epoch: 6| Step: 13
Training loss: 1.6134716595837397
Validation loss: 2.676346263030258

Epoch: 125| Step: 0
Training loss: 2.5641905627678105
Validation loss: 2.7637416367998804

Epoch: 6| Step: 1
Training loss: 1.0147040079299512
Validation loss: 2.723536374224519

Epoch: 6| Step: 2
Training loss: 0.9277738221465536
Validation loss: 2.6995249536365087

Epoch: 6| Step: 3
Training loss: 1.5762928061908419
Validation loss: 2.6849973988061637

Epoch: 6| Step: 4
Training loss: 1.5156202807795407
Validation loss: 2.6809891633892917

Epoch: 6| Step: 5
Training loss: 1.2434206425860799
Validation loss: 2.7615814966234256

Epoch: 6| Step: 6
Training loss: 2.4231272751603403
Validation loss: 2.6778048768745415

Epoch: 6| Step: 7
Training loss: 1.560788781582018
Validation loss: 2.6223969344307574

Epoch: 6| Step: 8
Training loss: 1.941218960053915
Validation loss: 2.670005188697602

Epoch: 6| Step: 9
Training loss: 1.8244155679591798
Validation loss: 2.7453963731355464

Epoch: 6| Step: 10
Training loss: 1.7072959013865632
Validation loss: 2.5873886446864027

Epoch: 6| Step: 11
Training loss: 1.8669949994952473
Validation loss: 2.7024477659736097

Epoch: 6| Step: 12
Training loss: 2.322389745322888
Validation loss: 2.7691885050546663

Epoch: 6| Step: 13
Training loss: 1.5539073424337853
Validation loss: 2.687189098975347

Epoch: 126| Step: 0
Training loss: 1.4161833986007215
Validation loss: 2.7624233269731477

Epoch: 6| Step: 1
Training loss: 2.4320040634209166
Validation loss: 2.6345752885792084

Epoch: 6| Step: 2
Training loss: 1.8686860268145995
Validation loss: 2.730645009883792

Epoch: 6| Step: 3
Training loss: 1.629951928137809
Validation loss: 2.6107249165986306

Epoch: 6| Step: 4
Training loss: 1.986519803351496
Validation loss: 2.5635964133689257

Epoch: 6| Step: 5
Training loss: 1.684304638244044
Validation loss: 2.6921142621298895

Epoch: 6| Step: 6
Training loss: 2.0698561831285405
Validation loss: 2.6421062821700705

Epoch: 6| Step: 7
Training loss: 1.620136612677398
Validation loss: 2.6061270138197896

Epoch: 6| Step: 8
Training loss: 1.8032101616012082
Validation loss: 2.6408789548326834

Epoch: 6| Step: 9
Training loss: 1.2773397369788357
Validation loss: 2.6276184222789603

Epoch: 6| Step: 10
Training loss: 1.7079800341240974
Validation loss: 2.533294338838052

Epoch: 6| Step: 11
Training loss: 2.0950508062352062
Validation loss: 2.6787218850885934

Epoch: 6| Step: 12
Training loss: 1.2126879438267635
Validation loss: 2.728918564174654

Epoch: 6| Step: 13
Training loss: 1.5656474646747838
Validation loss: 2.6618675220960983

Epoch: 127| Step: 0
Training loss: 2.699114255083213
Validation loss: 2.7239380951829197

Epoch: 6| Step: 1
Training loss: 1.3883734488368245
Validation loss: 2.6273624597587104

Epoch: 6| Step: 2
Training loss: 1.9241949206172686
Validation loss: 2.795165095130746

Epoch: 6| Step: 3
Training loss: 1.2205824647398003
Validation loss: 2.7760572784920026

Epoch: 6| Step: 4
Training loss: 1.5257099125168256
Validation loss: 2.7803689654184938

Epoch: 6| Step: 5
Training loss: 1.70898674665014
Validation loss: 2.7280786155669756

Epoch: 6| Step: 6
Training loss: 1.508740075559931
Validation loss: 2.8336053792460505

Epoch: 6| Step: 7
Training loss: 1.6763977481776855
Validation loss: 2.6506568214660935

Epoch: 6| Step: 8
Training loss: 1.9074835616337122
Validation loss: 2.617010233934756

Epoch: 6| Step: 9
Training loss: 1.5147200566864405
Validation loss: 2.630995095803612

Epoch: 6| Step: 10
Training loss: 1.9497866367107142
Validation loss: 2.6817207148502753

Epoch: 6| Step: 11
Training loss: 1.6664576240414366
Validation loss: 2.614495619154899

Epoch: 6| Step: 12
Training loss: 1.3309661096891203
Validation loss: 2.587049446869088

Epoch: 6| Step: 13
Training loss: 1.7391434149413223
Validation loss: 2.6195882234142935

Epoch: 128| Step: 0
Training loss: 1.7692512475936866
Validation loss: 2.604212208667533

Epoch: 6| Step: 1
Training loss: 1.413868464018647
Validation loss: 2.6938145257312596

Epoch: 6| Step: 2
Training loss: 1.2256308254821309
Validation loss: 2.6920153810251577

Epoch: 6| Step: 3
Training loss: 2.463920795282349
Validation loss: 2.725024280381595

Epoch: 6| Step: 4
Training loss: 1.9376987232308582
Validation loss: 2.8223239985042397

Epoch: 6| Step: 5
Training loss: 1.741907619010757
Validation loss: 2.706391288704665

Epoch: 6| Step: 6
Training loss: 1.1653026656709982
Validation loss: 2.8097565020975224

Epoch: 6| Step: 7
Training loss: 2.158731332067586
Validation loss: 2.753626657275729

Epoch: 6| Step: 8
Training loss: 1.5829431990109961
Validation loss: 2.8501875815649065

Epoch: 6| Step: 9
Training loss: 2.20822613533916
Validation loss: 2.796270422351458

Epoch: 6| Step: 10
Training loss: 1.589953144630675
Validation loss: 2.7512854909449183

Epoch: 6| Step: 11
Training loss: 1.3554006773815401
Validation loss: 2.806995416319262

Epoch: 6| Step: 12
Training loss: 1.7257098686131056
Validation loss: 2.6512588731760247

Epoch: 6| Step: 13
Training loss: 1.8371443008454469
Validation loss: 2.6562069758502442

Epoch: 129| Step: 0
Training loss: 1.6706529232935405
Validation loss: 2.6629203219849513

Epoch: 6| Step: 1
Training loss: 2.5265083642183597
Validation loss: 2.5992686074354543

Epoch: 6| Step: 2
Training loss: 1.0997870455861163
Validation loss: 2.83455648854101

Epoch: 6| Step: 3
Training loss: 2.1327169208279813
Validation loss: 2.6889301309584126

Epoch: 6| Step: 4
Training loss: 1.535313411365303
Validation loss: 2.616344608443783

Epoch: 6| Step: 5
Training loss: 1.4753230306923828
Validation loss: 2.6155654815379967

Epoch: 6| Step: 6
Training loss: 1.9968461561433122
Validation loss: 2.6915339424392575

Epoch: 6| Step: 7
Training loss: 2.2348693087469242
Validation loss: 2.7258835669561163

Epoch: 6| Step: 8
Training loss: 1.7034753561563438
Validation loss: 2.680803605913761

Epoch: 6| Step: 9
Training loss: 1.5186242385097461
Validation loss: 2.6341227394439093

Epoch: 6| Step: 10
Training loss: 1.1326142236230405
Validation loss: 2.7515728960593595

Epoch: 6| Step: 11
Training loss: 1.4609334201041795
Validation loss: 2.689916795604274

Epoch: 6| Step: 12
Training loss: 1.162947664921791
Validation loss: 2.6950808807956683

Epoch: 6| Step: 13
Training loss: 1.8087707828363795
Validation loss: 2.572389237145103

Epoch: 130| Step: 0
Training loss: 1.4469230956947008
Validation loss: 2.6837833195065897

Epoch: 6| Step: 1
Training loss: 1.6370732690520082
Validation loss: 2.726094159233223

Epoch: 6| Step: 2
Training loss: 1.9229392849744684
Validation loss: 2.7426203560884095

Epoch: 6| Step: 3
Training loss: 1.847192879573634
Validation loss: 2.73342653809559

Epoch: 6| Step: 4
Training loss: 2.323900935138038
Validation loss: 2.687989892592425

Epoch: 6| Step: 5
Training loss: 1.7815731491629754
Validation loss: 2.7543797728425967

Epoch: 6| Step: 6
Training loss: 1.3931782032805013
Validation loss: 2.785256589532881

Epoch: 6| Step: 7
Training loss: 0.9480937994875827
Validation loss: 2.794791939463243

Epoch: 6| Step: 8
Training loss: 1.5950254684615206
Validation loss: 2.7144976425015446

Epoch: 6| Step: 9
Training loss: 1.4641219738714288
Validation loss: 2.5862167223016574

Epoch: 6| Step: 10
Training loss: 2.1641428137243115
Validation loss: 2.720871999756968

Epoch: 6| Step: 11
Training loss: 1.7243488326650316
Validation loss: 2.689223298831106

Epoch: 6| Step: 12
Training loss: 1.5297538298739566
Validation loss: 2.8156153696723205

Epoch: 6| Step: 13
Training loss: 1.6908963956897007
Validation loss: 2.79001855358668

Epoch: 131| Step: 0
Training loss: 1.674811235865478
Validation loss: 2.71863655058248

Epoch: 6| Step: 1
Training loss: 1.6593395423333641
Validation loss: 2.6595688225909435

Epoch: 6| Step: 2
Training loss: 2.171927032945165
Validation loss: 2.642680720414453

Epoch: 6| Step: 3
Training loss: 1.7279973346813273
Validation loss: 2.730314556928933

Epoch: 6| Step: 4
Training loss: 2.030892443364767
Validation loss: 2.6698396451947577

Epoch: 6| Step: 5
Training loss: 1.7278258245778493
Validation loss: 2.6904088918963396

Epoch: 6| Step: 6
Training loss: 1.4521024654374066
Validation loss: 2.6418816399774734

Epoch: 6| Step: 7
Training loss: 1.8329025181406866
Validation loss: 2.659423458316812

Epoch: 6| Step: 8
Training loss: 1.616158863162215
Validation loss: 2.5803112431993167

Epoch: 6| Step: 9
Training loss: 1.7507217145173986
Validation loss: 2.6764884960768947

Epoch: 6| Step: 10
Training loss: 1.1535641689401106
Validation loss: 2.659999788661939

Epoch: 6| Step: 11
Training loss: 1.1641421194817674
Validation loss: 2.818308758650135

Epoch: 6| Step: 12
Training loss: 1.4151041820171844
Validation loss: 2.6320754320288646

Epoch: 6| Step: 13
Training loss: 1.1961152616095054
Validation loss: 2.698625572084258

Epoch: 132| Step: 0
Training loss: 2.1395352227863547
Validation loss: 2.759698858441118

Epoch: 6| Step: 1
Training loss: 1.5281641481217705
Validation loss: 2.7545512713326925

Epoch: 6| Step: 2
Training loss: 1.8867340403188004
Validation loss: 2.744890234164843

Epoch: 6| Step: 3
Training loss: 1.4752378627560319
Validation loss: 2.7970364486725297

Epoch: 6| Step: 4
Training loss: 1.448997048748162
Validation loss: 2.7546009386944785

Epoch: 6| Step: 5
Training loss: 1.497445076395351
Validation loss: 2.6595636829062848

Epoch: 6| Step: 6
Training loss: 1.3309450615164031
Validation loss: 2.775542585922751

Epoch: 6| Step: 7
Training loss: 2.1356036468769095
Validation loss: 2.7505758867398664

Epoch: 6| Step: 8
Training loss: 1.6569506045100237
Validation loss: 2.7652981236278436

Epoch: 6| Step: 9
Training loss: 1.4227272246419216
Validation loss: 2.697069518675996

Epoch: 6| Step: 10
Training loss: 1.7446616356825357
Validation loss: 2.7063021354557577

Epoch: 6| Step: 11
Training loss: 1.5577085653545266
Validation loss: 2.6320109066809683

Epoch: 6| Step: 12
Training loss: 2.1268264550636227
Validation loss: 2.667969941510837

Epoch: 6| Step: 13
Training loss: 1.557351059137237
Validation loss: 2.798731331705494

Epoch: 133| Step: 0
Training loss: 1.5955480269062887
Validation loss: 2.8307182126972372

Epoch: 6| Step: 1
Training loss: 1.5025808066982485
Validation loss: 2.7684439393082845

Epoch: 6| Step: 2
Training loss: 1.4819298129842629
Validation loss: 2.744607652628155

Epoch: 6| Step: 3
Training loss: 1.6670957330905067
Validation loss: 2.782810973263921

Epoch: 6| Step: 4
Training loss: 1.58428312558178
Validation loss: 2.9665599843106327

Epoch: 6| Step: 5
Training loss: 1.714606057901381
Validation loss: 2.8637851689728278

Epoch: 6| Step: 6
Training loss: 2.3101631935900255
Validation loss: 2.8484352138312716

Epoch: 6| Step: 7
Training loss: 1.3964699057516359
Validation loss: 2.821135128861867

Epoch: 6| Step: 8
Training loss: 2.0345810793144725
Validation loss: 2.784945657908765

Epoch: 6| Step: 9
Training loss: 1.534484327970232
Validation loss: 2.744723343888578

Epoch: 6| Step: 10
Training loss: 1.5906864716468554
Validation loss: 2.7976484312622727

Epoch: 6| Step: 11
Training loss: 1.9223894500695347
Validation loss: 2.8394156600769294

Epoch: 6| Step: 12
Training loss: 1.88409165107218
Validation loss: 2.656531016126545

Epoch: 6| Step: 13
Training loss: 1.445282476989691
Validation loss: 2.705445060218687

Epoch: 134| Step: 0
Training loss: 2.018575711595278
Validation loss: 2.718423144106042

Epoch: 6| Step: 1
Training loss: 1.6849557275361018
Validation loss: 2.784620336020078

Epoch: 6| Step: 2
Training loss: 1.332760071701551
Validation loss: 2.6416291955241773

Epoch: 6| Step: 3
Training loss: 1.6742986776593114
Validation loss: 2.7286896228037447

Epoch: 6| Step: 4
Training loss: 1.2554538956186514
Validation loss: 2.748503292150008

Epoch: 6| Step: 5
Training loss: 1.4880020800904121
Validation loss: 2.5573973287493317

Epoch: 6| Step: 6
Training loss: 1.5893873454704648
Validation loss: 2.732896634045071

Epoch: 6| Step: 7
Training loss: 1.519414352980681
Validation loss: 2.6746032200723855

Epoch: 6| Step: 8
Training loss: 1.5303243836745197
Validation loss: 2.636426066413807

Epoch: 6| Step: 9
Training loss: 1.9014245540387706
Validation loss: 2.6788813024237914

Epoch: 6| Step: 10
Training loss: 1.5574289046665406
Validation loss: 2.830482413665814

Epoch: 6| Step: 11
Training loss: 1.3427022353281188
Validation loss: 2.8958908230863325

Epoch: 6| Step: 12
Training loss: 2.398837276777344
Validation loss: 2.8786122255185016

Epoch: 6| Step: 13
Training loss: 1.8495075395177252
Validation loss: 2.8489016167517875

Epoch: 135| Step: 0
Training loss: 1.5910576911982768
Validation loss: 2.8521748760533754

Epoch: 6| Step: 1
Training loss: 1.0964506322807839
Validation loss: 2.8752201521243848

Epoch: 6| Step: 2
Training loss: 2.548650017723461
Validation loss: 2.8504506769833924

Epoch: 6| Step: 3
Training loss: 1.2399656470216271
Validation loss: 2.836994573136828

Epoch: 6| Step: 4
Training loss: 1.9993114478268204
Validation loss: 2.759837530071831

Epoch: 6| Step: 5
Training loss: 1.3491893948452314
Validation loss: 2.7940614496844978

Epoch: 6| Step: 6
Training loss: 1.6515005859780492
Validation loss: 2.715610342860495

Epoch: 6| Step: 7
Training loss: 1.1919141343507766
Validation loss: 2.712631941954267

Epoch: 6| Step: 8
Training loss: 1.7264967685805106
Validation loss: 2.621023814845501

Epoch: 6| Step: 9
Training loss: 1.6261515571888223
Validation loss: 2.7311072742173788

Epoch: 6| Step: 10
Training loss: 1.497123662566605
Validation loss: 2.685450104790596

Epoch: 6| Step: 11
Training loss: 1.071020963882161
Validation loss: 2.692924540021899

Epoch: 6| Step: 12
Training loss: 2.0649510471554615
Validation loss: 2.769385502131786

Epoch: 6| Step: 13
Training loss: 1.9885039738765735
Validation loss: 2.6611143712329297

Epoch: 136| Step: 0
Training loss: 1.5036325180826016
Validation loss: 2.6750343635467195

Epoch: 6| Step: 1
Training loss: 1.3843385713145815
Validation loss: 2.7660008263125855

Epoch: 6| Step: 2
Training loss: 1.3518050753374427
Validation loss: 2.6379154306024324

Epoch: 6| Step: 3
Training loss: 1.6044045143994066
Validation loss: 2.6225173957376247

Epoch: 6| Step: 4
Training loss: 1.9894179297059842
Validation loss: 2.694373515485654

Epoch: 6| Step: 5
Training loss: 1.8628002641567496
Validation loss: 2.7821907852566503

Epoch: 6| Step: 6
Training loss: 1.179676687431046
Validation loss: 2.7454902633348914

Epoch: 6| Step: 7
Training loss: 1.6364030556313858
Validation loss: 2.8132162524293323

Epoch: 6| Step: 8
Training loss: 2.396668915922182
Validation loss: 2.7683664301624504

Epoch: 6| Step: 9
Training loss: 1.1746868730864561
Validation loss: 2.765619310276192

Epoch: 6| Step: 10
Training loss: 1.5836521463490605
Validation loss: 2.68499714721585

Epoch: 6| Step: 11
Training loss: 2.0690770331562143
Validation loss: 2.776213947745072

Epoch: 6| Step: 12
Training loss: 1.7606509878497314
Validation loss: 2.794089693927595

Epoch: 6| Step: 13
Training loss: 1.1707062551604852
Validation loss: 2.709619060407721

Epoch: 137| Step: 0
Training loss: 1.8278351252344653
Validation loss: 2.698944806607702

Epoch: 6| Step: 1
Training loss: 1.4295906909622464
Validation loss: 2.703187945447049

Epoch: 6| Step: 2
Training loss: 1.3928910127301495
Validation loss: 2.73856988202855

Epoch: 6| Step: 3
Training loss: 1.530009253604805
Validation loss: 2.749173011121071

Epoch: 6| Step: 4
Training loss: 2.363709062678718
Validation loss: 2.7062583212544675

Epoch: 6| Step: 5
Training loss: 1.2594635357274733
Validation loss: 2.7217755199871227

Epoch: 6| Step: 6
Training loss: 1.9028231978119636
Validation loss: 2.679842500494889

Epoch: 6| Step: 7
Training loss: 1.3627746427719136
Validation loss: 2.6891310717631884

Epoch: 6| Step: 8
Training loss: 1.3732000186865716
Validation loss: 2.791482653650113

Epoch: 6| Step: 9
Training loss: 2.0327651022004183
Validation loss: 2.696896921233032

Epoch: 6| Step: 10
Training loss: 1.42597638192755
Validation loss: 2.6069033827540222

Epoch: 6| Step: 11
Training loss: 1.1879699178798062
Validation loss: 2.792224647973616

Epoch: 6| Step: 12
Training loss: 1.5946501639404251
Validation loss: 2.6516239049002275

Epoch: 6| Step: 13
Training loss: 1.4795228860521803
Validation loss: 2.746460211418818

Epoch: 138| Step: 0
Training loss: 2.006367679365132
Validation loss: 2.6145368675773892

Epoch: 6| Step: 1
Training loss: 1.7162489293283345
Validation loss: 2.664665034704096

Epoch: 6| Step: 2
Training loss: 1.7247770580022193
Validation loss: 2.591641239111028

Epoch: 6| Step: 3
Training loss: 1.8296372769154916
Validation loss: 2.7091831903492523

Epoch: 6| Step: 4
Training loss: 1.9952479173548796
Validation loss: 2.677460452184549

Epoch: 6| Step: 5
Training loss: 0.9863311767530913
Validation loss: 2.698523763644693

Epoch: 6| Step: 6
Training loss: 1.823215249449498
Validation loss: 2.695362772449718

Epoch: 6| Step: 7
Training loss: 1.0115049865418717
Validation loss: 2.7925099811927687

Epoch: 6| Step: 8
Training loss: 2.276906620950575
Validation loss: 2.80412455428434

Epoch: 6| Step: 9
Training loss: 1.891377575108237
Validation loss: 2.7992646293347576

Epoch: 6| Step: 10
Training loss: 1.087268041668472
Validation loss: 2.851949336320205

Epoch: 6| Step: 11
Training loss: 1.2699085789914057
Validation loss: 2.704614658796274

Epoch: 6| Step: 12
Training loss: 1.4410792034018445
Validation loss: 2.7359209758405507

Epoch: 6| Step: 13
Training loss: 1.064580339301889
Validation loss: 2.842736353490907

Epoch: 139| Step: 0
Training loss: 1.4991125024436658
Validation loss: 2.827351149877594

Epoch: 6| Step: 1
Training loss: 1.821054332016887
Validation loss: 2.6868190346226877

Epoch: 6| Step: 2
Training loss: 1.6778537410243872
Validation loss: 2.8552367624516455

Epoch: 6| Step: 3
Training loss: 1.3032924023141816
Validation loss: 2.779274485344417

Epoch: 6| Step: 4
Training loss: 1.47118233096479
Validation loss: 2.6946215642369307

Epoch: 6| Step: 5
Training loss: 1.7440549823029594
Validation loss: 2.691921648008524

Epoch: 6| Step: 6
Training loss: 1.3300127413863603
Validation loss: 2.706689758926534

Epoch: 6| Step: 7
Training loss: 1.877101991527546
Validation loss: 2.597668258142084

Epoch: 6| Step: 8
Training loss: 0.9981381846723372
Validation loss: 2.7832952401605824

Epoch: 6| Step: 9
Training loss: 1.4052338213502498
Validation loss: 2.658273786119024

Epoch: 6| Step: 10
Training loss: 1.5533405392333663
Validation loss: 2.6963197309625886

Epoch: 6| Step: 11
Training loss: 1.5117938986539952
Validation loss: 2.7151597824757157

Epoch: 6| Step: 12
Training loss: 1.4466176506534154
Validation loss: 2.6617258961377

Epoch: 6| Step: 13
Training loss: 2.3872145716828395
Validation loss: 2.700135203791011

Epoch: 140| Step: 0
Training loss: 1.4917658664530205
Validation loss: 2.792120388984189

Epoch: 6| Step: 1
Training loss: 1.6454098635536345
Validation loss: 2.58839705976045

Epoch: 6| Step: 2
Training loss: 1.5457033286047535
Validation loss: 2.780883507745098

Epoch: 6| Step: 3
Training loss: 1.293086804304762
Validation loss: 2.7461451909550045

Epoch: 6| Step: 4
Training loss: 2.085312653296745
Validation loss: 2.791860763482764

Epoch: 6| Step: 5
Training loss: 2.2409413559954534
Validation loss: 2.9187740387563115

Epoch: 6| Step: 6
Training loss: 1.354080808803191
Validation loss: 2.6469901527117856

Epoch: 6| Step: 7
Training loss: 1.6884313768173083
Validation loss: 2.8229640848791933

Epoch: 6| Step: 8
Training loss: 1.2020052368253096
Validation loss: 2.770384290826057

Epoch: 6| Step: 9
Training loss: 1.4325088428803572
Validation loss: 2.82704782784603

Epoch: 6| Step: 10
Training loss: 1.2714139154134447
Validation loss: 2.776523646059746

Epoch: 6| Step: 11
Training loss: 1.3694607391746385
Validation loss: 2.77602787742029

Epoch: 6| Step: 12
Training loss: 1.6416488359260748
Validation loss: 2.6759218499214823

Epoch: 6| Step: 13
Training loss: 1.7654224380832184
Validation loss: 2.7518505459057825

Epoch: 141| Step: 0
Training loss: 2.301989511732772
Validation loss: 2.7236416828990846

Epoch: 6| Step: 1
Training loss: 1.2980559154451676
Validation loss: 2.725662126504778

Epoch: 6| Step: 2
Training loss: 1.657606325263397
Validation loss: 2.8297132384521473

Epoch: 6| Step: 3
Training loss: 1.2693385520822433
Validation loss: 2.7051983417556107

Epoch: 6| Step: 4
Training loss: 0.862094875225857
Validation loss: 2.7565931699089057

Epoch: 6| Step: 5
Training loss: 1.7153678214891663
Validation loss: 2.8175357241595504

Epoch: 6| Step: 6
Training loss: 1.2229914099203696
Validation loss: 2.808600413774801

Epoch: 6| Step: 7
Training loss: 1.4287379712710648
Validation loss: 2.807967397768635

Epoch: 6| Step: 8
Training loss: 1.2635482421016235
Validation loss: 2.61032562300056

Epoch: 6| Step: 9
Training loss: 1.5722255914934329
Validation loss: 2.6986751643905866

Epoch: 6| Step: 10
Training loss: 0.8657282330483448
Validation loss: 2.7151770517496687

Epoch: 6| Step: 11
Training loss: 1.3948866874724113
Validation loss: 2.7471355200408984

Epoch: 6| Step: 12
Training loss: 1.5572343983746708
Validation loss: 2.650840621749546

Epoch: 6| Step: 13
Training loss: 1.886623846158993
Validation loss: 2.8056018298857874

Epoch: 142| Step: 0
Training loss: 1.5892614099471927
Validation loss: 2.788476891395268

Epoch: 6| Step: 1
Training loss: 1.5432652442088994
Validation loss: 2.747207032476573

Epoch: 6| Step: 2
Training loss: 1.2672168469587937
Validation loss: 2.8655074183844444

Epoch: 6| Step: 3
Training loss: 1.3978648798181474
Validation loss: 2.8144253180756253

Epoch: 6| Step: 4
Training loss: 1.278388712942143
Validation loss: 2.782979848728655

Epoch: 6| Step: 5
Training loss: 1.5330718743582252
Validation loss: 2.7462358867529755

Epoch: 6| Step: 6
Training loss: 1.2434271139328068
Validation loss: 2.6738386170223447

Epoch: 6| Step: 7
Training loss: 1.6424571388493379
Validation loss: 2.6874248730708477

Epoch: 6| Step: 8
Training loss: 1.0482726943991314
Validation loss: 2.646398061022784

Epoch: 6| Step: 9
Training loss: 1.6129910482831051
Validation loss: 2.698938203356481

Epoch: 6| Step: 10
Training loss: 2.1084566731116188
Validation loss: 2.6870537616579164

Epoch: 6| Step: 11
Training loss: 1.8756816896377395
Validation loss: 2.6820752152201597

Epoch: 6| Step: 12
Training loss: 1.5567755550935296
Validation loss: 2.7497095041297435

Epoch: 6| Step: 13
Training loss: 1.6653215543443896
Validation loss: 2.788155893671854

Epoch: 143| Step: 0
Training loss: 1.4605694475493118
Validation loss: 2.777298216484515

Epoch: 6| Step: 1
Training loss: 1.6344327781486214
Validation loss: 2.8302564509942507

Epoch: 6| Step: 2
Training loss: 1.706432106444622
Validation loss: 2.7950275222569725

Epoch: 6| Step: 3
Training loss: 1.353834194548594
Validation loss: 2.738989244646764

Epoch: 6| Step: 4
Training loss: 1.9234044261973866
Validation loss: 2.707305762173656

Epoch: 6| Step: 5
Training loss: 1.414832142824938
Validation loss: 2.7552438359896705

Epoch: 6| Step: 6
Training loss: 1.3184601469732786
Validation loss: 2.7182537371335127

Epoch: 6| Step: 7
Training loss: 1.430111681438453
Validation loss: 2.7458246568611226

Epoch: 6| Step: 8
Training loss: 0.8983961344608596
Validation loss: 2.7320519452087972

Epoch: 6| Step: 9
Training loss: 1.3833253415960773
Validation loss: 2.658177936480395

Epoch: 6| Step: 10
Training loss: 2.2696554179539143
Validation loss: 2.715445808963313

Epoch: 6| Step: 11
Training loss: 0.82245595727127
Validation loss: 2.733753562428392

Epoch: 6| Step: 12
Training loss: 1.712585491635997
Validation loss: 2.716848285626493

Epoch: 6| Step: 13
Training loss: 1.200850578694312
Validation loss: 2.7315448683288333

Epoch: 144| Step: 0
Training loss: 1.1637930846305642
Validation loss: 2.8017172922949634

Epoch: 6| Step: 1
Training loss: 1.5435597507143248
Validation loss: 2.741359603831412

Epoch: 6| Step: 2
Training loss: 0.7370270667443632
Validation loss: 2.8900313859003073

Epoch: 6| Step: 3
Training loss: 1.1531324887743255
Validation loss: 2.6805036838456133

Epoch: 6| Step: 4
Training loss: 1.0386327557551391
Validation loss: 2.762469278282694

Epoch: 6| Step: 5
Training loss: 2.3649103775947147
Validation loss: 2.9307756090232773

Epoch: 6| Step: 6
Training loss: 1.603021171434774
Validation loss: 2.989318042818393

Epoch: 6| Step: 7
Training loss: 2.110512885724251
Validation loss: 2.8802260294273467

Epoch: 6| Step: 8
Training loss: 2.0178652593205895
Validation loss: 2.7979128597306526

Epoch: 6| Step: 9
Training loss: 1.3625250962772133
Validation loss: 2.8376545957779604

Epoch: 6| Step: 10
Training loss: 1.2188150437433494
Validation loss: 2.716201976709134

Epoch: 6| Step: 11
Training loss: 1.4831136865903722
Validation loss: 2.79998609107968

Epoch: 6| Step: 12
Training loss: 1.8233175073154182
Validation loss: 2.7313864370526217

Epoch: 6| Step: 13
Training loss: 1.0734949621287564
Validation loss: 2.720482781938405

Epoch: 145| Step: 0
Training loss: 1.5067902098841708
Validation loss: 2.7385079094591065

Epoch: 6| Step: 1
Training loss: 1.2705061705078022
Validation loss: 2.722329571179479

Epoch: 6| Step: 2
Training loss: 2.281225648514881
Validation loss: 2.753243542016041

Epoch: 6| Step: 3
Training loss: 2.09759748721085
Validation loss: 2.7177549273141213

Epoch: 6| Step: 4
Training loss: 0.670577104178875
Validation loss: 2.7693610522401726

Epoch: 6| Step: 5
Training loss: 1.1276372621303197
Validation loss: 2.789831459761124

Epoch: 6| Step: 6
Training loss: 1.3803991605687027
Validation loss: 2.825606459391056

Epoch: 6| Step: 7
Training loss: 1.4516737058682734
Validation loss: 2.8504770381626954

Epoch: 6| Step: 8
Training loss: 1.512113219058946
Validation loss: 2.838318678936971

Epoch: 6| Step: 9
Training loss: 1.6974256854862344
Validation loss: 2.7486691433502717

Epoch: 6| Step: 10
Training loss: 1.528874559420024
Validation loss: 2.74301348759924

Epoch: 6| Step: 11
Training loss: 1.6978134482746365
Validation loss: 2.832213605951022

Epoch: 6| Step: 12
Training loss: 1.5009266851870682
Validation loss: 2.928040701983656

Epoch: 6| Step: 13
Training loss: 1.2556174417498946
Validation loss: 2.859742535315237

Epoch: 146| Step: 0
Training loss: 1.3701594720733619
Validation loss: 2.687838584803783

Epoch: 6| Step: 1
Training loss: 1.2418533931517026
Validation loss: 2.669003272564224

Epoch: 6| Step: 2
Training loss: 1.459034460553667
Validation loss: 2.7835391906935882

Epoch: 6| Step: 3
Training loss: 1.7343958947924913
Validation loss: 2.602548620458137

Epoch: 6| Step: 4
Training loss: 1.4549674382449764
Validation loss: 2.768411328317296

Epoch: 6| Step: 5
Training loss: 1.4818352102587349
Validation loss: 2.7688124656089124

Epoch: 6| Step: 6
Training loss: 2.3033059327317074
Validation loss: 2.644888316117969

Epoch: 6| Step: 7
Training loss: 1.3273017126727171
Validation loss: 2.741905509454937

Epoch: 6| Step: 8
Training loss: 1.5166925819334784
Validation loss: 2.7185369386168263

Epoch: 6| Step: 9
Training loss: 1.2672769573728675
Validation loss: 2.686243635938989

Epoch: 6| Step: 10
Training loss: 1.4639914512697365
Validation loss: 2.7936237696406923

Epoch: 6| Step: 11
Training loss: 1.2899942440821257
Validation loss: 2.7356016985991958

Epoch: 6| Step: 12
Training loss: 1.9082429817277549
Validation loss: 2.734505365079647

Epoch: 6| Step: 13
Training loss: 1.3644744111286506
Validation loss: 2.8161256873513913

Epoch: 147| Step: 0
Training loss: 1.2739392561691525
Validation loss: 2.780593008673479

Epoch: 6| Step: 1
Training loss: 0.9929325580379095
Validation loss: 2.7666468339998183

Epoch: 6| Step: 2
Training loss: 0.5929365106596303
Validation loss: 2.7666701301491745

Epoch: 6| Step: 3
Training loss: 1.115276489531545
Validation loss: 2.7776530433835553

Epoch: 6| Step: 4
Training loss: 1.5449501932010772
Validation loss: 2.66456087732782

Epoch: 6| Step: 5
Training loss: 0.8291807103205772
Validation loss: 2.767540205698202

Epoch: 6| Step: 6
Training loss: 1.2872611666884224
Validation loss: 2.6810342427715455

Epoch: 6| Step: 7
Training loss: 1.322982796445423
Validation loss: 2.7771078546981536

Epoch: 6| Step: 8
Training loss: 2.000183693079411
Validation loss: 2.768125520753356

Epoch: 6| Step: 9
Training loss: 1.332764454520115
Validation loss: 2.7659256909949104

Epoch: 6| Step: 10
Training loss: 1.4440250745693815
Validation loss: 2.7447126885089737

Epoch: 6| Step: 11
Training loss: 1.4768070240496383
Validation loss: 2.714402738835379

Epoch: 6| Step: 12
Training loss: 2.605573614889793
Validation loss: 2.621406835891838

Epoch: 6| Step: 13
Training loss: 1.469342700598386
Validation loss: 2.7274630861846765

Epoch: 148| Step: 0
Training loss: 1.2836004887390633
Validation loss: 2.8052468339837415

Epoch: 6| Step: 1
Training loss: 1.4256314133596428
Validation loss: 2.750286809819124

Epoch: 6| Step: 2
Training loss: 1.2960899458743713
Validation loss: 2.783160764137608

Epoch: 6| Step: 3
Training loss: 1.4619806818540317
Validation loss: 2.8221728176534344

Epoch: 6| Step: 4
Training loss: 1.7669383877697367
Validation loss: 2.7998927794090855

Epoch: 6| Step: 5
Training loss: 1.6116499146015264
Validation loss: 2.854447613182238

Epoch: 6| Step: 6
Training loss: 1.5465930720337029
Validation loss: 2.9932496631655794

Epoch: 6| Step: 7
Training loss: 1.5644282078276712
Validation loss: 2.8684440305570185

Epoch: 6| Step: 8
Training loss: 1.1096539213900647
Validation loss: 2.869402668107112

Epoch: 6| Step: 9
Training loss: 1.2413715585767124
Validation loss: 2.8005218882337335

Epoch: 6| Step: 10
Training loss: 1.2714778589412767
Validation loss: 2.8013147034975043

Epoch: 6| Step: 11
Training loss: 2.2030619077914646
Validation loss: 2.673117306067711

Epoch: 6| Step: 12
Training loss: 1.6940774242177907
Validation loss: 2.780206434511975

Epoch: 6| Step: 13
Training loss: 1.3907221642313794
Validation loss: 2.849551518606567

Epoch: 149| Step: 0
Training loss: 1.5407335533293018
Validation loss: 2.6988011730455206

Epoch: 6| Step: 1
Training loss: 1.4207091529850464
Validation loss: 2.770430848759518

Epoch: 6| Step: 2
Training loss: 1.1169789259620775
Validation loss: 2.663827596769672

Epoch: 6| Step: 3
Training loss: 1.829959763777687
Validation loss: 2.7244395796760217

Epoch: 6| Step: 4
Training loss: 0.9565476110247388
Validation loss: 2.7811321419307515

Epoch: 6| Step: 5
Training loss: 2.4330879775767293
Validation loss: 2.649621966826655

Epoch: 6| Step: 6
Training loss: 1.563812620035884
Validation loss: 2.761849982539763

Epoch: 6| Step: 7
Training loss: 1.7820628135391092
Validation loss: 2.7522863795891612

Epoch: 6| Step: 8
Training loss: 1.1257214881764763
Validation loss: 2.782215422329838

Epoch: 6| Step: 9
Training loss: 1.3590834732524955
Validation loss: 2.7504879489679293

Epoch: 6| Step: 10
Training loss: 1.118780534210364
Validation loss: 2.751364022872772

Epoch: 6| Step: 11
Training loss: 1.0197149235518381
Validation loss: 2.8460336675173847

Epoch: 6| Step: 12
Training loss: 1.2417527403642843
Validation loss: 2.805005833828821

Epoch: 6| Step: 13
Training loss: 1.177793384294655
Validation loss: 2.783027580926885

Epoch: 150| Step: 0
Training loss: 1.0816370387102259
Validation loss: 2.8030502655261977

Epoch: 6| Step: 1
Training loss: 1.214011591134833
Validation loss: 2.778029788559486

Epoch: 6| Step: 2
Training loss: 1.4908027015184593
Validation loss: 2.781169261546271

Epoch: 6| Step: 3
Training loss: 1.1159740340107298
Validation loss: 2.822448949788605

Epoch: 6| Step: 4
Training loss: 1.5025644633195157
Validation loss: 2.8332940313941903

Epoch: 6| Step: 5
Training loss: 1.5126923178734883
Validation loss: 2.696596880820445

Epoch: 6| Step: 6
Training loss: 1.2714575136221533
Validation loss: 2.8368314344724257

Epoch: 6| Step: 7
Training loss: 2.2247564118165712
Validation loss: 2.8078500667684843

Epoch: 6| Step: 8
Training loss: 1.100935304256765
Validation loss: 2.7830342488056496

Epoch: 6| Step: 9
Training loss: 1.5783753149349944
Validation loss: 2.8142589578885

Epoch: 6| Step: 10
Training loss: 1.873568306143233
Validation loss: 2.944035544183468

Epoch: 6| Step: 11
Training loss: 1.2292510289266834
Validation loss: 2.8302491362130415

Epoch: 6| Step: 12
Training loss: 1.5397239851378999
Validation loss: 2.844790858563467

Epoch: 6| Step: 13
Training loss: 1.324433525920157
Validation loss: 2.7990516135020487

Epoch: 151| Step: 0
Training loss: 1.0836815763386742
Validation loss: 2.728477206513782

Epoch: 6| Step: 1
Training loss: 1.3989500672793747
Validation loss: 2.7821910423402794

Epoch: 6| Step: 2
Training loss: 1.069916923542132
Validation loss: 2.700834387904872

Epoch: 6| Step: 3
Training loss: 1.4459472911825568
Validation loss: 2.7142472524355856

Epoch: 6| Step: 4
Training loss: 0.7951011361863544
Validation loss: 2.734449970489165

Epoch: 6| Step: 5
Training loss: 1.2457586812561448
Validation loss: 2.7258986254197843

Epoch: 6| Step: 6
Training loss: 1.547948753602818
Validation loss: 2.7196901091821313

Epoch: 6| Step: 7
Training loss: 1.3501854204069048
Validation loss: 2.741229434257302

Epoch: 6| Step: 8
Training loss: 1.6094438852919242
Validation loss: 2.790993172742347

Epoch: 6| Step: 9
Training loss: 1.389584698693073
Validation loss: 2.793168408920164

Epoch: 6| Step: 10
Training loss: 1.3964684118678978
Validation loss: 2.774964720699364

Epoch: 6| Step: 11
Training loss: 2.2662587298957853
Validation loss: 2.7188513068255524

Epoch: 6| Step: 12
Training loss: 1.053684464087622
Validation loss: 2.7760918894811786

Epoch: 6| Step: 13
Training loss: 1.6576613404933576
Validation loss: 2.769142485872808

Epoch: 152| Step: 0
Training loss: 1.234336128105676
Validation loss: 2.8139819867782805

Epoch: 6| Step: 1
Training loss: 2.2846550807601598
Validation loss: 2.828623873440954

Epoch: 6| Step: 2
Training loss: 0.9564285872003686
Validation loss: 2.752863606786057

Epoch: 6| Step: 3
Training loss: 0.9842108937876665
Validation loss: 2.766771657131263

Epoch: 6| Step: 4
Training loss: 1.1912163755108545
Validation loss: 2.8265474531688044

Epoch: 6| Step: 5
Training loss: 1.816068228166742
Validation loss: 2.7095620644775043

Epoch: 6| Step: 6
Training loss: 1.0955323546910267
Validation loss: 2.728369608571717

Epoch: 6| Step: 7
Training loss: 1.0851174970371176
Validation loss: 2.7836745762981194

Epoch: 6| Step: 8
Training loss: 1.3619628477364947
Validation loss: 2.8006518062258445

Epoch: 6| Step: 9
Training loss: 1.5707580541622495
Validation loss: 2.8507854221543805

Epoch: 6| Step: 10
Training loss: 1.3304421351084106
Validation loss: 2.80524278277976

Epoch: 6| Step: 11
Training loss: 1.4943762898808508
Validation loss: 2.7476124947738865

Epoch: 6| Step: 12
Training loss: 1.379019886553958
Validation loss: 2.7950487763363276

Epoch: 6| Step: 13
Training loss: 1.5842655934136307
Validation loss: 2.8500975028865745

Epoch: 153| Step: 0
Training loss: 1.2482406155405188
Validation loss: 2.770767889946999

Epoch: 6| Step: 1
Training loss: 1.3997453083246536
Validation loss: 2.786965986456039

Epoch: 6| Step: 2
Training loss: 1.3489691047778454
Validation loss: 2.8172260419311117

Epoch: 6| Step: 3
Training loss: 0.9134235594263486
Validation loss: 2.901893324061883

Epoch: 6| Step: 4
Training loss: 0.9206949213412626
Validation loss: 2.8361463093314434

Epoch: 6| Step: 5
Training loss: 1.2566726922380664
Validation loss: 2.782310797881337

Epoch: 6| Step: 6
Training loss: 1.0009990112764733
Validation loss: 2.7110406011348083

Epoch: 6| Step: 7
Training loss: 1.2599907252560725
Validation loss: 2.7837324029588695

Epoch: 6| Step: 8
Training loss: 1.1280728336012886
Validation loss: 2.644333081166749

Epoch: 6| Step: 9
Training loss: 1.8364663518974724
Validation loss: 2.7807948993850085

Epoch: 6| Step: 10
Training loss: 1.6343833996062764
Validation loss: 2.7528290501847397

Epoch: 6| Step: 11
Training loss: 1.3687800695870103
Validation loss: 2.786489901259863

Epoch: 6| Step: 12
Training loss: 1.6051137861280915
Validation loss: 2.9006029181916317

Epoch: 6| Step: 13
Training loss: 2.1558012564501423
Validation loss: 2.8267492808634045

Epoch: 154| Step: 0
Training loss: 2.173369408095506
Validation loss: 2.718953201768071

Epoch: 6| Step: 1
Training loss: 1.1232365986992277
Validation loss: 2.7414351950177585

Epoch: 6| Step: 2
Training loss: 1.9578429954205743
Validation loss: 2.7306303268454

Epoch: 6| Step: 3
Training loss: 1.4048986087474766
Validation loss: 2.757644749079115

Epoch: 6| Step: 4
Training loss: 1.5155759980450403
Validation loss: 2.854254899900312

Epoch: 6| Step: 5
Training loss: 1.3336197227626045
Validation loss: 2.890587883788315

Epoch: 6| Step: 6
Training loss: 0.8702595912116604
Validation loss: 2.9058976592184447

Epoch: 6| Step: 7
Training loss: 1.2953261352852143
Validation loss: 2.7818487001591565

Epoch: 6| Step: 8
Training loss: 1.3032431459727782
Validation loss: 3.0069074317664795

Epoch: 6| Step: 9
Training loss: 1.1358561700515561
Validation loss: 2.8094641230403203

Epoch: 6| Step: 10
Training loss: 1.3737608788209668
Validation loss: 2.8231385532087883

Epoch: 6| Step: 11
Training loss: 1.4256003905249766
Validation loss: 2.778017015221496

Epoch: 6| Step: 12
Training loss: 1.3608828545689975
Validation loss: 2.844881957297567

Epoch: 6| Step: 13
Training loss: 0.7853223330834286
Validation loss: 2.8351815777668077

Epoch: 155| Step: 0
Training loss: 0.9049019488545211
Validation loss: 2.7347706826340388

Epoch: 6| Step: 1
Training loss: 1.0310717920010783
Validation loss: 2.7807377547118204

Epoch: 6| Step: 2
Training loss: 1.1740399517039535
Validation loss: 2.8840785498624926

Epoch: 6| Step: 3
Training loss: 1.0360726960168285
Validation loss: 2.6965604537524044

Epoch: 6| Step: 4
Training loss: 1.270791610699928
Validation loss: 2.7306982697965294

Epoch: 6| Step: 5
Training loss: 1.115410946097588
Validation loss: 2.807950557653841

Epoch: 6| Step: 6
Training loss: 2.1167685456676018
Validation loss: 2.7896918718467494

Epoch: 6| Step: 7
Training loss: 1.3885345176442152
Validation loss: 2.664846370221925

Epoch: 6| Step: 8
Training loss: 1.0586639043217836
Validation loss: 2.7714869270913343

Epoch: 6| Step: 9
Training loss: 1.360772258830899
Validation loss: 2.7654307381603047

Epoch: 6| Step: 10
Training loss: 1.3785189768274018
Validation loss: 2.7859768080064407

Epoch: 6| Step: 11
Training loss: 1.408920845902933
Validation loss: 2.781808704165336

Epoch: 6| Step: 12
Training loss: 1.5101827856930476
Validation loss: 2.8386311274905323

Epoch: 6| Step: 13
Training loss: 1.6717560627780175
Validation loss: 2.756157087344427

Epoch: 156| Step: 0
Training loss: 1.2150139398128377
Validation loss: 2.701757184190359

Epoch: 6| Step: 1
Training loss: 1.2071279838835618
Validation loss: 2.880695134023199

Epoch: 6| Step: 2
Training loss: 0.9564722413752651
Validation loss: 2.8921501466388504

Epoch: 6| Step: 3
Training loss: 1.5612929450207316
Validation loss: 2.7206720595492913

Epoch: 6| Step: 4
Training loss: 1.0801423590048456
Validation loss: 2.705570063289917

Epoch: 6| Step: 5
Training loss: 2.21195803971183
Validation loss: 2.809200159501452

Epoch: 6| Step: 6
Training loss: 1.3855927529925183
Validation loss: 2.877284068720259

Epoch: 6| Step: 7
Training loss: 1.546814117774825
Validation loss: 2.817110309611783

Epoch: 6| Step: 8
Training loss: 1.1159130910544979
Validation loss: 2.7315427807995643

Epoch: 6| Step: 9
Training loss: 1.6101096245068804
Validation loss: 2.952030416340563

Epoch: 6| Step: 10
Training loss: 1.493301854284335
Validation loss: 2.8307097620622113

Epoch: 6| Step: 11
Training loss: 1.238833812568976
Validation loss: 2.6313993621501055

Epoch: 6| Step: 12
Training loss: 1.1537051160519236
Validation loss: 2.867430701755691

Epoch: 6| Step: 13
Training loss: 1.2966269750003598
Validation loss: 2.8311494283097636

Epoch: 157| Step: 0
Training loss: 1.7652911655502959
Validation loss: 2.7700341346051394

Epoch: 6| Step: 1
Training loss: 1.1160704356597844
Validation loss: 2.763587013981659

Epoch: 6| Step: 2
Training loss: 1.7858464682566682
Validation loss: 2.8566048549862697

Epoch: 6| Step: 3
Training loss: 1.2913154565518732
Validation loss: 2.752069445990601

Epoch: 6| Step: 4
Training loss: 1.1661631428551429
Validation loss: 2.8255039103245854

Epoch: 6| Step: 5
Training loss: 1.4546325410977032
Validation loss: 2.788449908459102

Epoch: 6| Step: 6
Training loss: 1.2247583034068052
Validation loss: 2.643985678867254

Epoch: 6| Step: 7
Training loss: 1.017973605164128
Validation loss: 2.736967474528031

Epoch: 6| Step: 8
Training loss: 1.1153953422718634
Validation loss: 2.7303941213498866

Epoch: 6| Step: 9
Training loss: 1.389297966582605
Validation loss: 2.733190763252104

Epoch: 6| Step: 10
Training loss: 1.1710587774326386
Validation loss: 2.7380457263028046

Epoch: 6| Step: 11
Training loss: 1.3983473508963538
Validation loss: 2.878042145736596

Epoch: 6| Step: 12
Training loss: 1.0635155144345823
Validation loss: 2.854776669957255

Epoch: 6| Step: 13
Training loss: 1.9576908911027837
Validation loss: 2.8116913092015166

Epoch: 158| Step: 0
Training loss: 2.094185399574968
Validation loss: 2.8670132867340907

Epoch: 6| Step: 1
Training loss: 1.5960860989275671
Validation loss: 2.8462467621237737

Epoch: 6| Step: 2
Training loss: 1.1898883092380157
Validation loss: 2.763335506966

Epoch: 6| Step: 3
Training loss: 1.2805605638414825
Validation loss: 2.903963221607837

Epoch: 6| Step: 4
Training loss: 0.7813447513342763
Validation loss: 2.8478888411000893

Epoch: 6| Step: 5
Training loss: 1.610225859964644
Validation loss: 2.802779332242328

Epoch: 6| Step: 6
Training loss: 1.3372104224344004
Validation loss: 2.8235233447942347

Epoch: 6| Step: 7
Training loss: 0.8123622924308546
Validation loss: 2.811913097039003

Epoch: 6| Step: 8
Training loss: 1.188996927506028
Validation loss: 2.872679285132238

Epoch: 6| Step: 9
Training loss: 1.0575277443891924
Validation loss: 2.7949498830725257

Epoch: 6| Step: 10
Training loss: 1.1114664913451313
Validation loss: 2.7083113645004926

Epoch: 6| Step: 11
Training loss: 2.1564397313775028
Validation loss: 2.87113034318021

Epoch: 6| Step: 12
Training loss: 1.3268830719682971
Validation loss: 2.7703428240595787

Epoch: 6| Step: 13
Training loss: 1.18151844748658
Validation loss: 2.8779049723323014

Epoch: 159| Step: 0
Training loss: 1.0366662294585194
Validation loss: 2.846555757960254

Epoch: 6| Step: 1
Training loss: 1.4780725094788068
Validation loss: 2.8024544216082896

Epoch: 6| Step: 2
Training loss: 1.4243963334886667
Validation loss: 2.7980417556428283

Epoch: 6| Step: 3
Training loss: 0.8076021315290975
Validation loss: 2.7957076863586616

Epoch: 6| Step: 4
Training loss: 0.705934358634562
Validation loss: 2.881744131661695

Epoch: 6| Step: 5
Training loss: 1.5241062359364619
Validation loss: 2.8357702649061194

Epoch: 6| Step: 6
Training loss: 1.0601590116460669
Validation loss: 2.916656444168342

Epoch: 6| Step: 7
Training loss: 1.0169530548543466
Validation loss: 2.819737031367656

Epoch: 6| Step: 8
Training loss: 1.2753467873579687
Validation loss: 2.756733511268449

Epoch: 6| Step: 9
Training loss: 2.3387002077006414
Validation loss: 2.832184815902025

Epoch: 6| Step: 10
Training loss: 1.3069052207367888
Validation loss: 2.7994043999675533

Epoch: 6| Step: 11
Training loss: 1.4243196703821441
Validation loss: 2.785152012633194

Epoch: 6| Step: 12
Training loss: 0.9922311127456465
Validation loss: 2.8133785147300703

Epoch: 6| Step: 13
Training loss: 1.5219385842703284
Validation loss: 2.838778387342383

Epoch: 160| Step: 0
Training loss: 0.8303506560885289
Validation loss: 2.7902855991726283

Epoch: 6| Step: 1
Training loss: 0.8211295645440743
Validation loss: 2.804929122505316

Epoch: 6| Step: 2
Training loss: 1.7971967989489135
Validation loss: 2.823181369847325

Epoch: 6| Step: 3
Training loss: 0.8370243031062351
Validation loss: 2.7900813331735455

Epoch: 6| Step: 4
Training loss: 1.1440716233940804
Validation loss: 2.728428199585314

Epoch: 6| Step: 5
Training loss: 1.0327104572897385
Validation loss: 2.8150687743346174

Epoch: 6| Step: 6
Training loss: 1.069069021696277
Validation loss: 2.8053470498421738

Epoch: 6| Step: 7
Training loss: 1.4435518004871517
Validation loss: 2.829545242269637

Epoch: 6| Step: 8
Training loss: 1.3649995571876339
Validation loss: 2.808859524732662

Epoch: 6| Step: 9
Training loss: 2.1818091345368273
Validation loss: 2.8633658486393765

Epoch: 6| Step: 10
Training loss: 1.352195018432676
Validation loss: 2.822283449743668

Epoch: 6| Step: 11
Training loss: 1.3171979295129892
Validation loss: 2.841096681239028

Epoch: 6| Step: 12
Training loss: 1.1292168740984962
Validation loss: 2.8882030616463137

Epoch: 6| Step: 13
Training loss: 0.9718344407035769
Validation loss: 2.85052030844358

Epoch: 161| Step: 0
Training loss: 1.126202523419482
Validation loss: 2.951206855894808

Epoch: 6| Step: 1
Training loss: 2.074529994450786
Validation loss: 2.9209704299365096

Epoch: 6| Step: 2
Training loss: 1.6463563627208082
Validation loss: 2.981008738226306

Epoch: 6| Step: 3
Training loss: 1.2413427491508724
Validation loss: 2.893661512500872

Epoch: 6| Step: 4
Training loss: 0.8697654278541752
Validation loss: 2.8494809291478314

Epoch: 6| Step: 5
Training loss: 1.4633468100000355
Validation loss: 2.8267693756857346

Epoch: 6| Step: 6
Training loss: 1.3228781336581708
Validation loss: 2.876676312622336

Epoch: 6| Step: 7
Training loss: 1.1105125934517104
Validation loss: 2.887848615312859

Epoch: 6| Step: 8
Training loss: 1.1581008119728347
Validation loss: 2.757165373612123

Epoch: 6| Step: 9
Training loss: 1.1335311714634857
Validation loss: 2.813790540952485

Epoch: 6| Step: 10
Training loss: 1.0847778715239798
Validation loss: 2.768832327922572

Epoch: 6| Step: 11
Training loss: 1.1039054789611327
Validation loss: 2.8297835908242943

Epoch: 6| Step: 12
Training loss: 1.628057610989715
Validation loss: 2.8237312145826947

Epoch: 6| Step: 13
Training loss: 1.7108078302166325
Validation loss: 2.794036319747821

Epoch: 162| Step: 0
Training loss: 1.7674083649272787
Validation loss: 2.7370550482067513

Epoch: 6| Step: 1
Training loss: 1.0480935136482052
Validation loss: 2.8733141144008707

Epoch: 6| Step: 2
Training loss: 1.1482117100067846
Validation loss: 2.8365520445470684

Epoch: 6| Step: 3
Training loss: 1.465768506928263
Validation loss: 2.8268022341727885

Epoch: 6| Step: 4
Training loss: 0.9587054497664683
Validation loss: 2.8690641049784067

Epoch: 6| Step: 5
Training loss: 1.0094749283116904
Validation loss: 2.8304362538853893

Epoch: 6| Step: 6
Training loss: 0.9767454662583919
Validation loss: 2.866179230930001

Epoch: 6| Step: 7
Training loss: 1.1423691778597078
Validation loss: 2.975926235276063

Epoch: 6| Step: 8
Training loss: 1.3855523160145229
Validation loss: 2.857010452574508

Epoch: 6| Step: 9
Training loss: 1.5508641910233187
Validation loss: 2.8309445736416974

Epoch: 6| Step: 10
Training loss: 1.8643245055636875
Validation loss: 2.775865636305683

Epoch: 6| Step: 11
Training loss: 1.1787319734556208
Validation loss: 2.7941608436934127

Epoch: 6| Step: 12
Training loss: 0.96941764959076
Validation loss: 2.815833708563745

Epoch: 6| Step: 13
Training loss: 1.2127598002424498
Validation loss: 2.775760691285956

Epoch: 163| Step: 0
Training loss: 0.9588544644934285
Validation loss: 2.883202806359145

Epoch: 6| Step: 1
Training loss: 1.307214949992427
Validation loss: 2.6896375982088156

Epoch: 6| Step: 2
Training loss: 1.4003900291196867
Validation loss: 2.750890342039239

Epoch: 6| Step: 3
Training loss: 1.6273679353305874
Validation loss: 2.8168542993187082

Epoch: 6| Step: 4
Training loss: 0.9131274861557136
Validation loss: 2.869357155215573

Epoch: 6| Step: 5
Training loss: 1.1960575050927051
Validation loss: 2.8597750774717645

Epoch: 6| Step: 6
Training loss: 1.39874805433259
Validation loss: 2.83029176104456

Epoch: 6| Step: 7
Training loss: 1.4382190564502153
Validation loss: 2.6908694886863667

Epoch: 6| Step: 8
Training loss: 2.1871016003347368
Validation loss: 2.8681348851778177

Epoch: 6| Step: 9
Training loss: 1.2424810770386048
Validation loss: 2.9531279468017084

Epoch: 6| Step: 10
Training loss: 1.3151011350489759
Validation loss: 2.868793034559716

Epoch: 6| Step: 11
Training loss: 1.3052107623971478
Validation loss: 2.78320380316832

Epoch: 6| Step: 12
Training loss: 1.0102841136282574
Validation loss: 2.822588424085923

Epoch: 6| Step: 13
Training loss: 1.0734582046666454
Validation loss: 2.8634242446671982

Epoch: 164| Step: 0
Training loss: 1.050078657019723
Validation loss: 2.850894922994135

Epoch: 6| Step: 1
Training loss: 1.3075882877862721
Validation loss: 2.932810144113561

Epoch: 6| Step: 2
Training loss: 1.3353634766664686
Validation loss: 2.7833733757549837

Epoch: 6| Step: 3
Training loss: 1.3669068838690883
Validation loss: 2.7429779594380506

Epoch: 6| Step: 4
Training loss: 2.0300588783407316
Validation loss: 2.8488939592991125

Epoch: 6| Step: 5
Training loss: 1.0837304170064597
Validation loss: 2.809547428642975

Epoch: 6| Step: 6
Training loss: 1.318143835462239
Validation loss: 2.8232041713425073

Epoch: 6| Step: 7
Training loss: 0.9022386828267961
Validation loss: 2.788184717925955

Epoch: 6| Step: 8
Training loss: 1.038341587629824
Validation loss: 2.8588232261932585

Epoch: 6| Step: 9
Training loss: 1.2246669043940641
Validation loss: 2.7145095875682514

Epoch: 6| Step: 10
Training loss: 1.3034984172523176
Validation loss: 2.7432116473461576

Epoch: 6| Step: 11
Training loss: 1.3887720085343518
Validation loss: 2.7773331196184055

Epoch: 6| Step: 12
Training loss: 0.833736695579514
Validation loss: 2.7603453908871223

Epoch: 6| Step: 13
Training loss: 1.139719407618433
Validation loss: 2.7974622028332607

Epoch: 165| Step: 0
Training loss: 1.259945500269957
Validation loss: 2.7070148095039483

Epoch: 6| Step: 1
Training loss: 1.0934089128802595
Validation loss: 2.802431323672964

Epoch: 6| Step: 2
Training loss: 1.1906094247194732
Validation loss: 2.8477016283142813

Epoch: 6| Step: 3
Training loss: 0.8744736518860159
Validation loss: 2.8552509995429176

Epoch: 6| Step: 4
Training loss: 1.25979869710404
Validation loss: 2.7436475353761183

Epoch: 6| Step: 5
Training loss: 1.0861364497984918
Validation loss: 2.8011649138116277

Epoch: 6| Step: 6
Training loss: 1.2050340047763117
Validation loss: 2.8600140050398437

Epoch: 6| Step: 7
Training loss: 0.8198036068568253
Validation loss: 2.752984508172901

Epoch: 6| Step: 8
Training loss: 1.602420335238583
Validation loss: 2.7712719983558554

Epoch: 6| Step: 9
Training loss: 2.290159203604947
Validation loss: 2.8657147386894017

Epoch: 6| Step: 10
Training loss: 1.430234460483223
Validation loss: 2.718272740943763

Epoch: 6| Step: 11
Training loss: 0.8163831789690209
Validation loss: 2.7942491561935245

Epoch: 6| Step: 12
Training loss: 1.0404265205875047
Validation loss: 2.827655928967044

Epoch: 6| Step: 13
Training loss: 1.0742780079536223
Validation loss: 2.78645797206603

Epoch: 166| Step: 0
Training loss: 0.7192203806962864
Validation loss: 2.9100123017827775

Epoch: 6| Step: 1
Training loss: 1.1973829103059817
Validation loss: 2.8388797990247405

Epoch: 6| Step: 2
Training loss: 1.2638822259599238
Validation loss: 2.8658466582022246

Epoch: 6| Step: 3
Training loss: 1.1938678263889169
Validation loss: 2.806029909674636

Epoch: 6| Step: 4
Training loss: 0.6793819924760625
Validation loss: 2.8193474242915966

Epoch: 6| Step: 5
Training loss: 1.686043287180836
Validation loss: 2.903665603547582

Epoch: 6| Step: 6
Training loss: 0.7738946661726287
Validation loss: 2.857101565017228

Epoch: 6| Step: 7
Training loss: 1.156312270678547
Validation loss: 2.7645771821870384

Epoch: 6| Step: 8
Training loss: 1.195498034470433
Validation loss: 2.874263240562844

Epoch: 6| Step: 9
Training loss: 1.2555863007904335
Validation loss: 2.803767713155476

Epoch: 6| Step: 10
Training loss: 1.3784855965521488
Validation loss: 2.8308541774197593

Epoch: 6| Step: 11
Training loss: 2.0047039504056383
Validation loss: 2.7893987429804477

Epoch: 6| Step: 12
Training loss: 1.006854762910511
Validation loss: 2.902916284893944

Epoch: 6| Step: 13
Training loss: 1.1251651854571485
Validation loss: 2.8588370006395945

Epoch: 167| Step: 0
Training loss: 1.0167221012532175
Validation loss: 2.8736919523429885

Epoch: 6| Step: 1
Training loss: 1.1160862436673646
Validation loss: 2.8575509512189377

Epoch: 6| Step: 2
Training loss: 1.358829564254052
Validation loss: 2.849236376559425

Epoch: 6| Step: 3
Training loss: 0.8801578680315116
Validation loss: 2.877802298558789

Epoch: 6| Step: 4
Training loss: 0.9277663054743621
Validation loss: 2.955571273193856

Epoch: 6| Step: 5
Training loss: 2.0835420376825917
Validation loss: 2.844353524466961

Epoch: 6| Step: 6
Training loss: 0.9651191719866358
Validation loss: 2.873518451478987

Epoch: 6| Step: 7
Training loss: 1.3541095525972706
Validation loss: 2.835023296536324

Epoch: 6| Step: 8
Training loss: 0.8999471503211309
Validation loss: 3.0165531397018652

Epoch: 6| Step: 9
Training loss: 1.1703649837607575
Validation loss: 2.793448524793318

Epoch: 6| Step: 10
Training loss: 1.1440862630352355
Validation loss: 2.7873358844975633

Epoch: 6| Step: 11
Training loss: 1.177112927810291
Validation loss: 2.9579277342582864

Epoch: 6| Step: 12
Training loss: 1.0353881576164434
Validation loss: 2.806321570397787

Epoch: 6| Step: 13
Training loss: 1.328612025105066
Validation loss: 2.7831831368068802

Epoch: 168| Step: 0
Training loss: 1.290541430485571
Validation loss: 2.7365779177283778

Epoch: 6| Step: 1
Training loss: 1.1089967969499017
Validation loss: 2.827215902152726

Epoch: 6| Step: 2
Training loss: 2.134975468407519
Validation loss: 2.832098079199821

Epoch: 6| Step: 3
Training loss: 0.9772465865689649
Validation loss: 2.91437607237995

Epoch: 6| Step: 4
Training loss: 0.9305882938439884
Validation loss: 2.8372621971560843

Epoch: 6| Step: 5
Training loss: 1.3078681414399835
Validation loss: 2.7555556532088983

Epoch: 6| Step: 6
Training loss: 1.5547144901865724
Validation loss: 2.857198223644767

Epoch: 6| Step: 7
Training loss: 1.3493778013524513
Validation loss: 2.8678100353589384

Epoch: 6| Step: 8
Training loss: 1.119356304376793
Validation loss: 2.813657056374104

Epoch: 6| Step: 9
Training loss: 1.149620951504478
Validation loss: 2.860882429491881

Epoch: 6| Step: 10
Training loss: 1.1342565343280564
Validation loss: 2.9001365541776827

Epoch: 6| Step: 11
Training loss: 1.1362691822677993
Validation loss: 2.89676358126317

Epoch: 6| Step: 12
Training loss: 1.3492254878827352
Validation loss: 2.8601869219049094

Epoch: 6| Step: 13
Training loss: 1.0207605660382413
Validation loss: 2.817526077515388

Epoch: 169| Step: 0
Training loss: 0.6899335662331562
Validation loss: 2.793874071909198

Epoch: 6| Step: 1
Training loss: 1.2877844746203149
Validation loss: 2.732651208938386

Epoch: 6| Step: 2
Training loss: 1.1885208961662304
Validation loss: 2.7346034072665404

Epoch: 6| Step: 3
Training loss: 1.031216302956946
Validation loss: 2.711416533816356

Epoch: 6| Step: 4
Training loss: 1.0577596496271706
Validation loss: 2.8688111727417898

Epoch: 6| Step: 5
Training loss: 2.363928234979708
Validation loss: 2.757568377387441

Epoch: 6| Step: 6
Training loss: 1.4232049109229992
Validation loss: 2.783887890907944

Epoch: 6| Step: 7
Training loss: 1.1030369083146907
Validation loss: 2.8707346304511105

Epoch: 6| Step: 8
Training loss: 0.985469905525378
Validation loss: 2.823893154118635

Epoch: 6| Step: 9
Training loss: 1.1122239831276832
Validation loss: 2.827466280326048

Epoch: 6| Step: 10
Training loss: 1.4671431334656198
Validation loss: 2.839144390172949

Epoch: 6| Step: 11
Training loss: 1.3849974789235
Validation loss: 2.847332789954322

Epoch: 6| Step: 12
Training loss: 0.7395718712433397
Validation loss: 2.837082602768384

Epoch: 6| Step: 13
Training loss: 0.8885928276034418
Validation loss: 2.9283321246291396

Epoch: 170| Step: 0
Training loss: 1.2437936248029509
Validation loss: 2.858367158635873

Epoch: 6| Step: 1
Training loss: 0.7928173503193577
Validation loss: 2.889177719577728

Epoch: 6| Step: 2
Training loss: 0.9671909646509879
Validation loss: 2.7152977287121045

Epoch: 6| Step: 3
Training loss: 1.7373547774626277
Validation loss: 2.793413929705938

Epoch: 6| Step: 4
Training loss: 0.7213358595598774
Validation loss: 2.8499742936207535

Epoch: 6| Step: 5
Training loss: 2.2539876992567813
Validation loss: 2.828094004536713

Epoch: 6| Step: 6
Training loss: 0.9782636550273952
Validation loss: 2.6431663217574597

Epoch: 6| Step: 7
Training loss: 1.1658279037803607
Validation loss: 2.7636313858930426

Epoch: 6| Step: 8
Training loss: 1.2594326791735877
Validation loss: 2.7391205071564886

Epoch: 6| Step: 9
Training loss: 1.3048599494674913
Validation loss: 2.823572108527934

Epoch: 6| Step: 10
Training loss: 1.3261876955057823
Validation loss: 2.933693760074262

Epoch: 6| Step: 11
Training loss: 1.2561974433798815
Validation loss: 2.8039517938630363

Epoch: 6| Step: 12
Training loss: 1.0717459776161975
Validation loss: 3.0115375258119523

Epoch: 6| Step: 13
Training loss: 1.0869434006562455
Validation loss: 3.0958765857767583

Epoch: 171| Step: 0
Training loss: 2.0150363269494127
Validation loss: 2.819291061045971

Epoch: 6| Step: 1
Training loss: 1.6095997181268373
Validation loss: 2.962190991796115

Epoch: 6| Step: 2
Training loss: 1.2326165240531857
Validation loss: 2.838489431664716

Epoch: 6| Step: 3
Training loss: 1.199698833581959
Validation loss: 2.950561864331365

Epoch: 6| Step: 4
Training loss: 1.1958042703922658
Validation loss: 2.8558127721783406

Epoch: 6| Step: 5
Training loss: 1.1466285835824757
Validation loss: 2.8948871155265175

Epoch: 6| Step: 6
Training loss: 1.39160023471702
Validation loss: 2.8462460361520683

Epoch: 6| Step: 7
Training loss: 0.9887982248923037
Validation loss: 2.817543170669299

Epoch: 6| Step: 8
Training loss: 1.6405970979770217
Validation loss: 2.8327280454535884

Epoch: 6| Step: 9
Training loss: 1.169455204327985
Validation loss: 2.7379078449468435

Epoch: 6| Step: 10
Training loss: 0.6923804451238839
Validation loss: 2.7917766454488673

Epoch: 6| Step: 11
Training loss: 0.7788545122630947
Validation loss: 2.914299131165758

Epoch: 6| Step: 12
Training loss: 0.9357154391707005
Validation loss: 2.849650399477299

Epoch: 6| Step: 13
Training loss: 1.199334850344954
Validation loss: 2.8449658041062666

Epoch: 172| Step: 0
Training loss: 1.4250033830301383
Validation loss: 2.8840337852486697

Epoch: 6| Step: 1
Training loss: 1.1155669189208306
Validation loss: 2.7995645672687313

Epoch: 6| Step: 2
Training loss: 1.1753493621571285
Validation loss: 2.89139523940836

Epoch: 6| Step: 3
Training loss: 2.0232387135779013
Validation loss: 2.866461707890714

Epoch: 6| Step: 4
Training loss: 0.7570372086202869
Validation loss: 2.8130423128950945

Epoch: 6| Step: 5
Training loss: 1.0378073087824895
Validation loss: 2.918479891687452

Epoch: 6| Step: 6
Training loss: 0.9207476819164834
Validation loss: 2.7820506568609593

Epoch: 6| Step: 7
Training loss: 1.1392268142132242
Validation loss: 2.8285970697827922

Epoch: 6| Step: 8
Training loss: 0.8021432598235776
Validation loss: 2.6866216037258854

Epoch: 6| Step: 9
Training loss: 0.9837338918120844
Validation loss: 2.9026838182962718

Epoch: 6| Step: 10
Training loss: 0.7775187079825265
Validation loss: 2.890820814493945

Epoch: 6| Step: 11
Training loss: 1.2877875756876676
Validation loss: 2.816604332168304

Epoch: 6| Step: 12
Training loss: 1.5977759281466664
Validation loss: 2.8561149175686533

Epoch: 6| Step: 13
Training loss: 1.2623569067510079
Validation loss: 2.8606871979641264

Epoch: 173| Step: 0
Training loss: 1.0792166670086991
Validation loss: 2.8757048585931355

Epoch: 6| Step: 1
Training loss: 0.9659254057419251
Validation loss: 2.915352011899548

Epoch: 6| Step: 2
Training loss: 1.282015827465103
Validation loss: 2.8040510923725446

Epoch: 6| Step: 3
Training loss: 1.9615222925207314
Validation loss: 2.9274653437751432

Epoch: 6| Step: 4
Training loss: 1.1318995513022705
Validation loss: 2.8192417722329783

Epoch: 6| Step: 5
Training loss: 1.047452966367034
Validation loss: 2.888403057446209

Epoch: 6| Step: 6
Training loss: 0.7314005737475595
Validation loss: 2.8019605040070825

Epoch: 6| Step: 7
Training loss: 1.4751224660949434
Validation loss: 2.9025680708590205

Epoch: 6| Step: 8
Training loss: 0.7628471819202812
Validation loss: 2.815543371916198

Epoch: 6| Step: 9
Training loss: 1.0085194791577892
Validation loss: 2.819544933409557

Epoch: 6| Step: 10
Training loss: 1.3469356213444539
Validation loss: 2.88596716540087

Epoch: 6| Step: 11
Training loss: 1.1137831242662957
Validation loss: 2.7739834243684403

Epoch: 6| Step: 12
Training loss: 1.425376437475424
Validation loss: 2.7843446694950926

Epoch: 6| Step: 13
Training loss: 0.9084986052221614
Validation loss: 2.900273580362285

Epoch: 174| Step: 0
Training loss: 0.875355614196533
Validation loss: 2.8447841538495697

Epoch: 6| Step: 1
Training loss: 1.1896198826044775
Validation loss: 2.7988263361113876

Epoch: 6| Step: 2
Training loss: 1.0876797757689067
Validation loss: 2.896230318224572

Epoch: 6| Step: 3
Training loss: 1.1994246514217437
Validation loss: 2.7969420867205144

Epoch: 6| Step: 4
Training loss: 1.9942210869617394
Validation loss: 2.7934085028472286

Epoch: 6| Step: 5
Training loss: 1.1076232081266286
Validation loss: 2.7301381447182496

Epoch: 6| Step: 6
Training loss: 0.9600315941141665
Validation loss: 2.849693989080328

Epoch: 6| Step: 7
Training loss: 1.1210932183347497
Validation loss: 2.8042324196379282

Epoch: 6| Step: 8
Training loss: 1.0617062464771476
Validation loss: 2.8515530660116135

Epoch: 6| Step: 9
Training loss: 1.4614892417519583
Validation loss: 2.9080572627585006

Epoch: 6| Step: 10
Training loss: 0.6325006540770033
Validation loss: 2.8483899169563416

Epoch: 6| Step: 11
Training loss: 1.3052425460208041
Validation loss: 2.899283725151266

Epoch: 6| Step: 12
Training loss: 1.1239980898599922
Validation loss: 2.8405534993354147

Epoch: 6| Step: 13
Training loss: 0.9090591170430633
Validation loss: 2.9731163307156034

Epoch: 175| Step: 0
Training loss: 0.6263070744073044
Validation loss: 2.876013369883311

Epoch: 6| Step: 1
Training loss: 0.9076964575027341
Validation loss: 2.8471340961825997

Epoch: 6| Step: 2
Training loss: 1.0150280885615175
Validation loss: 2.8114111735367375

Epoch: 6| Step: 3
Training loss: 1.142700345276019
Validation loss: 2.829023355516375

Epoch: 6| Step: 4
Training loss: 2.094665441088173
Validation loss: 2.8896817154604877

Epoch: 6| Step: 5
Training loss: 1.3354550209825964
Validation loss: 2.8690786751018087

Epoch: 6| Step: 6
Training loss: 0.9137868873258187
Validation loss: 2.8638860142772846

Epoch: 6| Step: 7
Training loss: 0.9862592918625493
Validation loss: 2.8820053941851365

Epoch: 6| Step: 8
Training loss: 1.0006111780721432
Validation loss: 2.789358940719336

Epoch: 6| Step: 9
Training loss: 1.2523385583837776
Validation loss: 2.8397090133054137

Epoch: 6| Step: 10
Training loss: 1.1840456864589601
Validation loss: 2.794138352713027

Epoch: 6| Step: 11
Training loss: 0.9978038394885457
Validation loss: 2.7688626305926385

Epoch: 6| Step: 12
Training loss: 1.0092843714793727
Validation loss: 2.803925207851119

Epoch: 6| Step: 13
Training loss: 1.2520111594236003
Validation loss: 2.847802457121632

Epoch: 176| Step: 0
Training loss: 1.1570997466444681
Validation loss: 2.7995456752713106

Epoch: 6| Step: 1
Training loss: 1.2895842449984103
Validation loss: 2.846261197753466

Epoch: 6| Step: 2
Training loss: 1.1988424400352462
Validation loss: 2.8515375284294726

Epoch: 6| Step: 3
Training loss: 1.0141706176864742
Validation loss: 2.8810034695381197

Epoch: 6| Step: 4
Training loss: 0.9381436999119966
Validation loss: 2.9308412984075085

Epoch: 6| Step: 5
Training loss: 1.9836607721521389
Validation loss: 2.803245322410432

Epoch: 6| Step: 6
Training loss: 1.1443941209946753
Validation loss: 2.8319148598793267

Epoch: 6| Step: 7
Training loss: 0.8519693155337541
Validation loss: 2.9193104115416966

Epoch: 6| Step: 8
Training loss: 1.0853186291566332
Validation loss: 2.8826737202473653

Epoch: 6| Step: 9
Training loss: 1.0600447054198745
Validation loss: 2.894756347854427

Epoch: 6| Step: 10
Training loss: 0.7542219538647282
Validation loss: 2.7388494303889206

Epoch: 6| Step: 11
Training loss: 0.7866602674186259
Validation loss: 2.8692903490430544

Epoch: 6| Step: 12
Training loss: 0.9628069920616008
Validation loss: 2.850335150526468

Epoch: 6| Step: 13
Training loss: 1.2662164695344698
Validation loss: 2.8458929546211666

Epoch: 177| Step: 0
Training loss: 1.0752360572682598
Validation loss: 2.845247957076094

Epoch: 6| Step: 1
Training loss: 1.263562110720811
Validation loss: 2.7995274218754713

Epoch: 6| Step: 2
Training loss: 1.2370205788623696
Validation loss: 2.850022911515079

Epoch: 6| Step: 3
Training loss: 1.3983368224660078
Validation loss: 2.8538113718650573

Epoch: 6| Step: 4
Training loss: 1.0422350985568263
Validation loss: 2.789528701813256

Epoch: 6| Step: 5
Training loss: 1.1965837886308301
Validation loss: 2.8502067931480832

Epoch: 6| Step: 6
Training loss: 0.7188895546148337
Validation loss: 2.8553263589169817

Epoch: 6| Step: 7
Training loss: 0.8728117828967149
Validation loss: 2.8547246253027305

Epoch: 6| Step: 8
Training loss: 0.807876489934502
Validation loss: 2.6975463308622216

Epoch: 6| Step: 9
Training loss: 1.246264311498809
Validation loss: 2.8186600089245677

Epoch: 6| Step: 10
Training loss: 1.0621225023037137
Validation loss: 2.943143070932621

Epoch: 6| Step: 11
Training loss: 1.0268448463140838
Validation loss: 2.882680047359989

Epoch: 6| Step: 12
Training loss: 0.9342628858278368
Validation loss: 2.9212889058007914

Epoch: 6| Step: 13
Training loss: 1.9198602179467306
Validation loss: 2.844635682291821

Epoch: 178| Step: 0
Training loss: 1.257826337086642
Validation loss: 2.7398240354749817

Epoch: 6| Step: 1
Training loss: 0.9740598731056016
Validation loss: 2.7932826294845525

Epoch: 6| Step: 2
Training loss: 1.183120632979711
Validation loss: 2.8074095824512892

Epoch: 6| Step: 3
Training loss: 0.9210129926512689
Validation loss: 2.7686028406260292

Epoch: 6| Step: 4
Training loss: 0.9773595990085896
Validation loss: 2.8379867057874244

Epoch: 6| Step: 5
Training loss: 0.824687950767287
Validation loss: 2.9181240164740885

Epoch: 6| Step: 6
Training loss: 1.4044828543779297
Validation loss: 2.8396598130186828

Epoch: 6| Step: 7
Training loss: 1.0595158013591741
Validation loss: 2.745143373215889

Epoch: 6| Step: 8
Training loss: 0.9868406871316994
Validation loss: 2.8126032492441397

Epoch: 6| Step: 9
Training loss: 0.8963271857188325
Validation loss: 2.8517623761642192

Epoch: 6| Step: 10
Training loss: 1.0935172787083056
Validation loss: 2.7923775142717155

Epoch: 6| Step: 11
Training loss: 2.14590915681768
Validation loss: 2.9080664587861538

Epoch: 6| Step: 12
Training loss: 0.8164867744706199
Validation loss: 2.9561763117116837

Epoch: 6| Step: 13
Training loss: 1.138397236022221
Validation loss: 2.770690388446086

Epoch: 179| Step: 0
Training loss: 0.8052027265806695
Validation loss: 2.8644284616855877

Epoch: 6| Step: 1
Training loss: 1.036191832562986
Validation loss: 2.873596111246372

Epoch: 6| Step: 2
Training loss: 1.2166584358633672
Validation loss: 2.9428688388138795

Epoch: 6| Step: 3
Training loss: 1.0759932963506342
Validation loss: 2.88841440713999

Epoch: 6| Step: 4
Training loss: 1.377906458474362
Validation loss: 2.965315294189723

Epoch: 6| Step: 5
Training loss: 0.8593435455114495
Validation loss: 2.8276654848420586

Epoch: 6| Step: 6
Training loss: 1.2573494384606607
Validation loss: 2.7907462998954324

Epoch: 6| Step: 7
Training loss: 1.0243552366518258
Validation loss: 2.8803341627084094

Epoch: 6| Step: 8
Training loss: 1.5335972759188803
Validation loss: 2.8461071627357812

Epoch: 6| Step: 9
Training loss: 0.6495020527135467
Validation loss: 2.7711465462551303

Epoch: 6| Step: 10
Training loss: 1.2957594796300773
Validation loss: 2.806290227917446

Epoch: 6| Step: 11
Training loss: 2.055654088084471
Validation loss: 2.7704483185400695

Epoch: 6| Step: 12
Training loss: 0.7735905736628017
Validation loss: 2.8591237887179792

Epoch: 6| Step: 13
Training loss: 0.6158500860187074
Validation loss: 2.7806386668660443

Epoch: 180| Step: 0
Training loss: 2.008533986410648
Validation loss: 2.970451964679959

Epoch: 6| Step: 1
Training loss: 1.348637143735125
Validation loss: 2.86543139764319

Epoch: 6| Step: 2
Training loss: 0.7080091594814774
Validation loss: 2.910297269199325

Epoch: 6| Step: 3
Training loss: 1.1367153416743092
Validation loss: 2.921813284210283

Epoch: 6| Step: 4
Training loss: 0.8999382090549523
Validation loss: 2.8369269488376285

Epoch: 6| Step: 5
Training loss: 1.003623002166603
Validation loss: 2.8317218620290068

Epoch: 6| Step: 6
Training loss: 0.7109374580802486
Validation loss: 2.844530969494187

Epoch: 6| Step: 7
Training loss: 0.8671375294627414
Validation loss: 2.8728756173907795

Epoch: 6| Step: 8
Training loss: 1.2839387268734983
Validation loss: 2.936394158661549

Epoch: 6| Step: 9
Training loss: 1.3655066484717564
Validation loss: 2.930605921581168

Epoch: 6| Step: 10
Training loss: 1.3356919983271374
Validation loss: 2.8891190738753916

Epoch: 6| Step: 11
Training loss: 1.1755289713259975
Validation loss: 2.901684131171708

Epoch: 6| Step: 12
Training loss: 0.961608714324926
Validation loss: 2.956015032193613

Epoch: 6| Step: 13
Training loss: 0.7711368598984429
Validation loss: 2.7542288661133383

Epoch: 181| Step: 0
Training loss: 1.2584229877356028
Validation loss: 2.8270002485494885

Epoch: 6| Step: 1
Training loss: 0.8366642582492689
Validation loss: 2.721989831498563

Epoch: 6| Step: 2
Training loss: 1.096097660941381
Validation loss: 2.8870088657753494

Epoch: 6| Step: 3
Training loss: 0.8261603677006858
Validation loss: 2.8977977118541083

Epoch: 6| Step: 4
Training loss: 1.9133852636398812
Validation loss: 2.9321110174568794

Epoch: 6| Step: 5
Training loss: 0.9623441867297817
Validation loss: 2.9192305785281176

Epoch: 6| Step: 6
Training loss: 0.8658894971402424
Validation loss: 2.943024330839632

Epoch: 6| Step: 7
Training loss: 1.1836380651254281
Validation loss: 2.8420225632792206

Epoch: 6| Step: 8
Training loss: 1.302817094684495
Validation loss: 2.8998519037513253

Epoch: 6| Step: 9
Training loss: 1.0994992243342072
Validation loss: 2.785135063101502

Epoch: 6| Step: 10
Training loss: 1.474002617304431
Validation loss: 2.926451283337754

Epoch: 6| Step: 11
Training loss: 1.1994838359486244
Validation loss: 2.82354358219778

Epoch: 6| Step: 12
Training loss: 1.2095688499418435
Validation loss: 2.757487305801883

Epoch: 6| Step: 13
Training loss: 0.8848772125949348
Validation loss: 2.8455088140422324

Epoch: 182| Step: 0
Training loss: 0.9266250563502761
Validation loss: 2.853323921101932

Epoch: 6| Step: 1
Training loss: 0.7261741995197128
Validation loss: 2.781216624770487

Epoch: 6| Step: 2
Training loss: 1.181488884885263
Validation loss: 2.8272951991717603

Epoch: 6| Step: 3
Training loss: 0.5719537243047272
Validation loss: 2.8064241974026323

Epoch: 6| Step: 4
Training loss: 0.6948212592034432
Validation loss: 2.799593167608261

Epoch: 6| Step: 5
Training loss: 1.030032855685737
Validation loss: 2.8158343718173944

Epoch: 6| Step: 6
Training loss: 2.0328528315936234
Validation loss: 2.86768518991181

Epoch: 6| Step: 7
Training loss: 1.1223769337537297
Validation loss: 3.0035537757655018

Epoch: 6| Step: 8
Training loss: 0.789008299221876
Validation loss: 2.8607999936998465

Epoch: 6| Step: 9
Training loss: 1.2772682937593256
Validation loss: 3.0339230945708473

Epoch: 6| Step: 10
Training loss: 1.5944880104463481
Validation loss: 3.0261538425123478

Epoch: 6| Step: 11
Training loss: 1.1428537932840717
Validation loss: 2.9890586224198636

Epoch: 6| Step: 12
Training loss: 1.0286513445098935
Validation loss: 2.856985208726086

Epoch: 6| Step: 13
Training loss: 1.0120807132762941
Validation loss: 2.9392054727009835

Epoch: 183| Step: 0
Training loss: 0.9995023562053866
Validation loss: 2.8446244373055287

Epoch: 6| Step: 1
Training loss: 1.065011254372031
Validation loss: 2.8123509685449783

Epoch: 6| Step: 2
Training loss: 1.150668772828866
Validation loss: 2.7111279423465686

Epoch: 6| Step: 3
Training loss: 1.1967186728593378
Validation loss: 2.881962527686891

Epoch: 6| Step: 4
Training loss: 1.2456866230055557
Validation loss: 2.8659063624729137

Epoch: 6| Step: 5
Training loss: 1.0840829065578959
Validation loss: 2.8763366162961477

Epoch: 6| Step: 6
Training loss: 1.0052239938942444
Validation loss: 2.927330337003655

Epoch: 6| Step: 7
Training loss: 1.1007163944455818
Validation loss: 2.714526721913461

Epoch: 6| Step: 8
Training loss: 1.375489754586316
Validation loss: 2.8758794296433257

Epoch: 6| Step: 9
Training loss: 0.6214435719846871
Validation loss: 2.967719946736225

Epoch: 6| Step: 10
Training loss: 1.9967984562443
Validation loss: 2.8342135034639444

Epoch: 6| Step: 11
Training loss: 0.7703639139036632
Validation loss: 2.9837545711981464

Epoch: 6| Step: 12
Training loss: 0.7481887722640294
Validation loss: 2.950984926191073

Epoch: 6| Step: 13
Training loss: 0.9664697883707196
Validation loss: 2.82136714585612

Epoch: 184| Step: 0
Training loss: 1.1310836754023632
Validation loss: 2.865891290936248

Epoch: 6| Step: 1
Training loss: 1.2186673454231303
Validation loss: 2.8518988424019707

Epoch: 6| Step: 2
Training loss: 1.3155591372859656
Validation loss: 2.7744830958903877

Epoch: 6| Step: 3
Training loss: 1.1799220174140088
Validation loss: 2.7516374192588735

Epoch: 6| Step: 4
Training loss: 0.8465692608726336
Validation loss: 2.75606800842346

Epoch: 6| Step: 5
Training loss: 0.8257961997246138
Validation loss: 2.8571302430691876

Epoch: 6| Step: 6
Training loss: 1.1197748700442065
Validation loss: 2.8250236859074134

Epoch: 6| Step: 7
Training loss: 0.7674098716153603
Validation loss: 2.88485887738756

Epoch: 6| Step: 8
Training loss: 0.9617559157750579
Validation loss: 2.8150310006927537

Epoch: 6| Step: 9
Training loss: 1.059694288181982
Validation loss: 2.8409082515599713

Epoch: 6| Step: 10
Training loss: 0.8467272048868776
Validation loss: 2.757294387345268

Epoch: 6| Step: 11
Training loss: 0.7948183934295528
Validation loss: 2.9347239830163057

Epoch: 6| Step: 12
Training loss: 1.7857937331918612
Validation loss: 2.8795051107121146

Epoch: 6| Step: 13
Training loss: 0.8701123238544275
Validation loss: 2.865205625508138

Epoch: 185| Step: 0
Training loss: 1.179270841267562
Validation loss: 2.894037037201826

Epoch: 6| Step: 1
Training loss: 1.2622280451133974
Validation loss: 2.8082356938746225

Epoch: 6| Step: 2
Training loss: 1.8722874411528225
Validation loss: 2.8904858117486985

Epoch: 6| Step: 3
Training loss: 0.8712991378259788
Validation loss: 2.8904991741116555

Epoch: 6| Step: 4
Training loss: 0.7374186648761606
Validation loss: 2.821007020487451

Epoch: 6| Step: 5
Training loss: 1.265678498821059
Validation loss: 2.8535715489757214

Epoch: 6| Step: 6
Training loss: 0.9190940290670279
Validation loss: 2.809001371314299

Epoch: 6| Step: 7
Training loss: 0.6232577119649286
Validation loss: 2.8590338387058436

Epoch: 6| Step: 8
Training loss: 1.1059691034799177
Validation loss: 2.825688459401951

Epoch: 6| Step: 9
Training loss: 1.1729149844946354
Validation loss: 2.898940324653142

Epoch: 6| Step: 10
Training loss: 0.8484025473797876
Validation loss: 2.7827761745348836

Epoch: 6| Step: 11
Training loss: 0.983493531373108
Validation loss: 2.7691198419160608

Epoch: 6| Step: 12
Training loss: 1.1285089763948588
Validation loss: 2.8620351011290563

Epoch: 6| Step: 13
Training loss: 0.6322422990793785
Validation loss: 2.8112144357827

Epoch: 186| Step: 0
Training loss: 1.1986914851731394
Validation loss: 2.862394312610808

Epoch: 6| Step: 1
Training loss: 1.1903923848717415
Validation loss: 2.876730646775271

Epoch: 6| Step: 2
Training loss: 0.6733490941198573
Validation loss: 2.7945182290225765

Epoch: 6| Step: 3
Training loss: 1.3334249325918366
Validation loss: 2.9025561741429184

Epoch: 6| Step: 4
Training loss: 0.8567898447696689
Validation loss: 2.8895217852281974

Epoch: 6| Step: 5
Training loss: 0.724640714476636
Validation loss: 2.8060047453126233

Epoch: 6| Step: 6
Training loss: 0.7666849856330366
Validation loss: 2.841708592882114

Epoch: 6| Step: 7
Training loss: 1.9679742526060364
Validation loss: 2.8206103758457846

Epoch: 6| Step: 8
Training loss: 1.2087902104219284
Validation loss: 2.7984210949787345

Epoch: 6| Step: 9
Training loss: 1.1179857403352498
Validation loss: 2.941094127371887

Epoch: 6| Step: 10
Training loss: 1.1114153836123175
Validation loss: 2.9858376744975423

Epoch: 6| Step: 11
Training loss: 0.9341818262163868
Validation loss: 2.9270653548768912

Epoch: 6| Step: 12
Training loss: 1.0319404024946606
Validation loss: 2.947914640248459

Epoch: 6| Step: 13
Training loss: 0.8878567824687956
Validation loss: 2.964394650561382

Epoch: 187| Step: 0
Training loss: 0.9728046595094796
Validation loss: 2.919826176838974

Epoch: 6| Step: 1
Training loss: 0.7552281782677966
Validation loss: 2.810405997182295

Epoch: 6| Step: 2
Training loss: 1.0899362832441088
Validation loss: 2.8605175688622526

Epoch: 6| Step: 3
Training loss: 1.0411717510702765
Validation loss: 2.8254470792130353

Epoch: 6| Step: 4
Training loss: 0.859320968316519
Validation loss: 2.8577375604819695

Epoch: 6| Step: 5
Training loss: 1.092991047891461
Validation loss: 2.8287897048930435

Epoch: 6| Step: 6
Training loss: 1.173038058100138
Validation loss: 2.8470988135743

Epoch: 6| Step: 7
Training loss: 0.7614115560195259
Validation loss: 2.8165214045911204

Epoch: 6| Step: 8
Training loss: 1.3339886644330743
Validation loss: 2.8767128416962158

Epoch: 6| Step: 9
Training loss: 0.9013430508474418
Validation loss: 2.946495445945764

Epoch: 6| Step: 10
Training loss: 0.7561090732132487
Validation loss: 3.0386546432491026

Epoch: 6| Step: 11
Training loss: 0.8387987599647025
Validation loss: 2.9077752325671775

Epoch: 6| Step: 12
Training loss: 1.808619192121602
Validation loss: 2.934162259201933

Epoch: 6| Step: 13
Training loss: 0.9105801884314768
Validation loss: 2.8628966388456187

Epoch: 188| Step: 0
Training loss: 0.9686117996574628
Validation loss: 2.7995452636486102

Epoch: 6| Step: 1
Training loss: 1.2427177497057225
Validation loss: 2.852765391354991

Epoch: 6| Step: 2
Training loss: 2.226101476222543
Validation loss: 2.8382424899750944

Epoch: 6| Step: 3
Training loss: 1.0001407762619816
Validation loss: 2.852098771623096

Epoch: 6| Step: 4
Training loss: 0.8994450103041175
Validation loss: 2.8149394229155162

Epoch: 6| Step: 5
Training loss: 0.8527348698795016
Validation loss: 2.9083574099122522

Epoch: 6| Step: 6
Training loss: 0.9639845508983677
Validation loss: 2.815889562440713

Epoch: 6| Step: 7
Training loss: 0.7331748245622508
Validation loss: 2.8582605159889383

Epoch: 6| Step: 8
Training loss: 0.97237361493682
Validation loss: 2.786629735125466

Epoch: 6| Step: 9
Training loss: 1.0962120682907948
Validation loss: 2.8167828340294623

Epoch: 6| Step: 10
Training loss: 0.6082377213847031
Validation loss: 2.975109369741254

Epoch: 6| Step: 11
Training loss: 0.6987862981195365
Validation loss: 2.8783358971238844

Epoch: 6| Step: 12
Training loss: 1.0185209215662445
Validation loss: 2.9022934619625187

Epoch: 6| Step: 13
Training loss: 1.051775720527092
Validation loss: 2.8622416039548435

Epoch: 189| Step: 0
Training loss: 0.7200686755806631
Validation loss: 2.9258686183350777

Epoch: 6| Step: 1
Training loss: 1.0206268387151298
Validation loss: 2.8294140738925324

Epoch: 6| Step: 2
Training loss: 0.9473286401297734
Validation loss: 2.8687077579421714

Epoch: 6| Step: 3
Training loss: 0.8117433105512675
Validation loss: 2.8913829600163976

Epoch: 6| Step: 4
Training loss: 1.902310349564813
Validation loss: 2.8847631455748486

Epoch: 6| Step: 5
Training loss: 0.7351330841662971
Validation loss: 2.8519934202352832

Epoch: 6| Step: 6
Training loss: 0.9627857576721789
Validation loss: 2.8448961344678

Epoch: 6| Step: 7
Training loss: 0.8191548489493986
Validation loss: 2.8205590109555287

Epoch: 6| Step: 8
Training loss: 0.5820440508567684
Validation loss: 2.9121795106864123

Epoch: 6| Step: 9
Training loss: 1.0109076470473277
Validation loss: 2.862106491649007

Epoch: 6| Step: 10
Training loss: 1.3415930980549193
Validation loss: 2.867675393263283

Epoch: 6| Step: 11
Training loss: 1.2869545086554663
Validation loss: 2.9054749662027297

Epoch: 6| Step: 12
Training loss: 1.1195463872978946
Validation loss: 2.7415989663559133

Epoch: 6| Step: 13
Training loss: 0.8203691008886245
Validation loss: 2.817181315232786

Epoch: 190| Step: 0
Training loss: 0.9209059455055817
Validation loss: 2.7846865193231105

Epoch: 6| Step: 1
Training loss: 0.696320371204794
Validation loss: 2.8880210764099146

Epoch: 6| Step: 2
Training loss: 1.1195935569403344
Validation loss: 2.8444955009317137

Epoch: 6| Step: 3
Training loss: 0.6919526349682175
Validation loss: 2.8657283413500716

Epoch: 6| Step: 4
Training loss: 0.9400127433359465
Validation loss: 2.9057074556544165

Epoch: 6| Step: 5
Training loss: 0.8188931492887747
Validation loss: 2.8224638309419494

Epoch: 6| Step: 6
Training loss: 0.7326430736942509
Validation loss: 2.82764732865192

Epoch: 6| Step: 7
Training loss: 1.0785844901763773
Validation loss: 2.9017995578309894

Epoch: 6| Step: 8
Training loss: 1.1219667232495016
Validation loss: 2.914898354495925

Epoch: 6| Step: 9
Training loss: 0.6440102523348966
Validation loss: 2.8723550046000175

Epoch: 6| Step: 10
Training loss: 0.9397916758785418
Validation loss: 2.8344232529160753

Epoch: 6| Step: 11
Training loss: 0.9199499300102648
Validation loss: 2.8565452345192175

Epoch: 6| Step: 12
Training loss: 2.009125988660683
Validation loss: 2.9305750744266543

Epoch: 6| Step: 13
Training loss: 0.9649695187038748
Validation loss: 2.8791005980386486

Epoch: 191| Step: 0
Training loss: 1.186040483308076
Validation loss: 2.838580368664748

Epoch: 6| Step: 1
Training loss: 2.0174781501276975
Validation loss: 2.938011273740082

Epoch: 6| Step: 2
Training loss: 0.7815513029825525
Validation loss: 2.8548743676971973

Epoch: 6| Step: 3
Training loss: 0.6852626156861663
Validation loss: 2.8234012980727163

Epoch: 6| Step: 4
Training loss: 1.1246776118881237
Validation loss: 2.914983022759249

Epoch: 6| Step: 5
Training loss: 0.9788540922915013
Validation loss: 2.8187384329570486

Epoch: 6| Step: 6
Training loss: 1.0930409994506622
Validation loss: 2.8379669494236746

Epoch: 6| Step: 7
Training loss: 0.7514485833959992
Validation loss: 2.928724383248805

Epoch: 6| Step: 8
Training loss: 0.7515890453829462
Validation loss: 2.8889216860311455

Epoch: 6| Step: 9
Training loss: 1.0708873346766512
Validation loss: 2.9234948385580295

Epoch: 6| Step: 10
Training loss: 0.930935831007625
Validation loss: 2.809694162131129

Epoch: 6| Step: 11
Training loss: 0.7286707735917324
Validation loss: 2.8475019276215834

Epoch: 6| Step: 12
Training loss: 1.4980802967466358
Validation loss: 2.9216547320293156

Epoch: 6| Step: 13
Training loss: 1.1830021856034663
Validation loss: 2.8828233479172525

Epoch: 192| Step: 0
Training loss: 0.6264103711916367
Validation loss: 2.75664575551169

Epoch: 6| Step: 1
Training loss: 0.6910655157301676
Validation loss: 2.8656757884099116

Epoch: 6| Step: 2
Training loss: 0.8706076595773051
Validation loss: 2.891559456661806

Epoch: 6| Step: 3
Training loss: 0.8110496340566978
Validation loss: 2.9040015625691127

Epoch: 6| Step: 4
Training loss: 0.961713617033783
Validation loss: 2.871209396143848

Epoch: 6| Step: 5
Training loss: 0.6108724339952117
Validation loss: 2.841534684398623

Epoch: 6| Step: 6
Training loss: 0.772059822349009
Validation loss: 2.8366039743529696

Epoch: 6| Step: 7
Training loss: 1.2407786699341958
Validation loss: 2.8808375401935606

Epoch: 6| Step: 8
Training loss: 0.954650876955123
Validation loss: 2.8616493365948505

Epoch: 6| Step: 9
Training loss: 1.2296081439808946
Validation loss: 2.930428929076584

Epoch: 6| Step: 10
Training loss: 0.8448127834880917
Validation loss: 2.833169530359661

Epoch: 6| Step: 11
Training loss: 1.1120060627861232
Validation loss: 2.778548010427279

Epoch: 6| Step: 12
Training loss: 0.8335555892832913
Validation loss: 2.8503275875415364

Epoch: 6| Step: 13
Training loss: 1.9317012889196008
Validation loss: 2.861412802214675

Epoch: 193| Step: 0
Training loss: 1.065190387149142
Validation loss: 2.845394706900155

Epoch: 6| Step: 1
Training loss: 1.1787260065640424
Validation loss: 2.9426799986608874

Epoch: 6| Step: 2
Training loss: 0.8390207205658746
Validation loss: 2.810360129777204

Epoch: 6| Step: 3
Training loss: 0.7208652055636235
Validation loss: 2.8949004713001667

Epoch: 6| Step: 4
Training loss: 1.0228294721268099
Validation loss: 2.7544587142545294

Epoch: 6| Step: 5
Training loss: 1.911880682107214
Validation loss: 2.835710696844644

Epoch: 6| Step: 6
Training loss: 0.9267846315641665
Validation loss: 2.838890030975344

Epoch: 6| Step: 7
Training loss: 1.0425351273727088
Validation loss: 2.815026864758728

Epoch: 6| Step: 8
Training loss: 0.8342421622383965
Validation loss: 2.8583326958821496

Epoch: 6| Step: 9
Training loss: 0.7425787446622957
Validation loss: 2.9291650060338776

Epoch: 6| Step: 10
Training loss: 1.13825627851357
Validation loss: 2.9066803726331027

Epoch: 6| Step: 11
Training loss: 1.4643335700106905
Validation loss: 2.8151444047892253

Epoch: 6| Step: 12
Training loss: 0.8355884001312481
Validation loss: 2.892061210085686

Epoch: 6| Step: 13
Training loss: 0.9023363517689137
Validation loss: 2.833863255554517

Epoch: 194| Step: 0
Training loss: 0.7365144448349683
Validation loss: 2.914026664124911

Epoch: 6| Step: 1
Training loss: 0.8845120502403663
Validation loss: 2.968617004627915

Epoch: 6| Step: 2
Training loss: 1.1404517055188481
Validation loss: 2.862152335030775

Epoch: 6| Step: 3
Training loss: 0.881675731009008
Validation loss: 2.916824926896476

Epoch: 6| Step: 4
Training loss: 0.7923720421363517
Validation loss: 2.890560293762161

Epoch: 6| Step: 5
Training loss: 1.976269183804696
Validation loss: 2.819689596466308

Epoch: 6| Step: 6
Training loss: 0.8505683485417717
Validation loss: 2.9417286595268326

Epoch: 6| Step: 7
Training loss: 0.8868284115641901
Validation loss: 2.855154121902083

Epoch: 6| Step: 8
Training loss: 0.7712121797188488
Validation loss: 2.8265116324134487

Epoch: 6| Step: 9
Training loss: 0.9264496591440855
Validation loss: 2.8474149457840037

Epoch: 6| Step: 10
Training loss: 0.8261961155575017
Validation loss: 2.977286370100768

Epoch: 6| Step: 11
Training loss: 1.0536429424815072
Validation loss: 2.915280698540844

Epoch: 6| Step: 12
Training loss: 1.3121605388708721
Validation loss: 2.82461034399941

Epoch: 6| Step: 13
Training loss: 0.6697765448501141
Validation loss: 2.8321822974603292

Epoch: 195| Step: 0
Training loss: 0.7357363966715715
Validation loss: 2.819233075775912

Epoch: 6| Step: 1
Training loss: 1.0364596240676178
Validation loss: 2.907625378807947

Epoch: 6| Step: 2
Training loss: 1.1098760628457258
Validation loss: 2.905965374097302

Epoch: 6| Step: 3
Training loss: 0.584228515625
Validation loss: 2.9170057008879597

Epoch: 6| Step: 4
Training loss: 0.9311699147959517
Validation loss: 2.8554959137159868

Epoch: 6| Step: 5
Training loss: 0.5537973703139427
Validation loss: 2.97282651797089

Epoch: 6| Step: 6
Training loss: 0.65062484876794
Validation loss: 2.8782091474295344

Epoch: 6| Step: 7
Training loss: 0.8247045016659326
Validation loss: 2.9123123817972405

Epoch: 6| Step: 8
Training loss: 1.308770694441531
Validation loss: 2.8228906346395894

Epoch: 6| Step: 9
Training loss: 0.9096980107865522
Validation loss: 2.9857933442141023

Epoch: 6| Step: 10
Training loss: 1.2153590051056946
Validation loss: 2.9328850145271823

Epoch: 6| Step: 11
Training loss: 1.060054545348672
Validation loss: 2.953470146018415

Epoch: 6| Step: 12
Training loss: 1.86468350729204
Validation loss: 2.846412062456058

Epoch: 6| Step: 13
Training loss: 0.761800634433365
Validation loss: 2.9543874756719313

Epoch: 196| Step: 0
Training loss: 0.7104716189284378
Validation loss: 3.0265086213690773

Epoch: 6| Step: 1
Training loss: 0.6783929313101904
Validation loss: 2.8627052022575694

Epoch: 6| Step: 2
Training loss: 0.9825425121340996
Validation loss: 2.8865520066078854

Epoch: 6| Step: 3
Training loss: 1.1498624304710494
Validation loss: 2.963610902501539

Epoch: 6| Step: 4
Training loss: 1.3664044562841107
Validation loss: 2.8184513985530524

Epoch: 6| Step: 5
Training loss: 0.9149305346442905
Validation loss: 2.8320842167954563

Epoch: 6| Step: 6
Training loss: 1.9103905781746802
Validation loss: 2.876046197692625

Epoch: 6| Step: 7
Training loss: 0.8996518759847898
Validation loss: 2.8849563001852343

Epoch: 6| Step: 8
Training loss: 0.8461861937682071
Validation loss: 2.850464812516516

Epoch: 6| Step: 9
Training loss: 0.5591364271862631
Validation loss: 2.852797650948251

Epoch: 6| Step: 10
Training loss: 0.5731162561646103
Validation loss: 2.804511671301684

Epoch: 6| Step: 11
Training loss: 0.7228550817841495
Validation loss: 2.9144230432904643

Epoch: 6| Step: 12
Training loss: 0.9269687746111821
Validation loss: 2.835039807645108

Epoch: 6| Step: 13
Training loss: 0.6556388643324359
Validation loss: 2.7742761337975783

Epoch: 197| Step: 0
Training loss: 1.0962735627446571
Validation loss: 2.906397935390465

Epoch: 6| Step: 1
Training loss: 0.8852325958700012
Validation loss: 2.8577811866353144

Epoch: 6| Step: 2
Training loss: 1.3213060692300969
Validation loss: 2.8216075794442284

Epoch: 6| Step: 3
Training loss: 1.7894980887322613
Validation loss: 2.8921162101028486

Epoch: 6| Step: 4
Training loss: 0.827264662754754
Validation loss: 2.9390322970147005

Epoch: 6| Step: 5
Training loss: 1.2304050974049534
Validation loss: 2.8506852703641243

Epoch: 6| Step: 6
Training loss: 0.8519579817726612
Validation loss: 2.9150301474685705

Epoch: 6| Step: 7
Training loss: 0.7712890377706377
Validation loss: 2.9416548787241936

Epoch: 6| Step: 8
Training loss: 0.7277264859257708
Validation loss: 2.8845730361927338

Epoch: 6| Step: 9
Training loss: 0.6468103745101491
Validation loss: 2.8857208302799995

Epoch: 6| Step: 10
Training loss: 0.7196046889080785
Validation loss: 2.9025930414831405

Epoch: 6| Step: 11
Training loss: 0.9339760033692179
Validation loss: 2.884809868606075

Epoch: 6| Step: 12
Training loss: 0.9320808825903301
Validation loss: 2.8560353772352483

Epoch: 6| Step: 13
Training loss: 0.9265613729589083
Validation loss: 2.7873280579091935

Epoch: 198| Step: 0
Training loss: 1.0127362175886228
Validation loss: 2.9322090656759023

Epoch: 6| Step: 1
Training loss: 0.6173581478956996
Validation loss: 2.9304803614639328

Epoch: 6| Step: 2
Training loss: 0.5328977499858697
Validation loss: 2.7884931508573474

Epoch: 6| Step: 3
Training loss: 1.1417228431988509
Validation loss: 2.792710498172007

Epoch: 6| Step: 4
Training loss: 1.277987863136771
Validation loss: 2.8350253849586218

Epoch: 6| Step: 5
Training loss: 0.7742815517664051
Validation loss: 2.894835833175622

Epoch: 6| Step: 6
Training loss: 1.304996476735003
Validation loss: 2.8873911321024126

Epoch: 6| Step: 7
Training loss: 0.5526290092193401
Validation loss: 2.888801989613674

Epoch: 6| Step: 8
Training loss: 1.9555842671429982
Validation loss: 3.022540554955669

Epoch: 6| Step: 9
Training loss: 0.7166017687785033
Validation loss: 2.788161416265247

Epoch: 6| Step: 10
Training loss: 0.6275904853142115
Validation loss: 2.9431007236168876

Epoch: 6| Step: 11
Training loss: 0.68162070958466
Validation loss: 2.8495398049493614

Epoch: 6| Step: 12
Training loss: 1.0737207541518528
Validation loss: 2.761303199104776

Epoch: 6| Step: 13
Training loss: 0.6724749259812263
Validation loss: 2.843388635780303

Epoch: 199| Step: 0
Training loss: 1.864538380455705
Validation loss: 2.8966131235302086

Epoch: 6| Step: 1
Training loss: 0.7173168988147396
Validation loss: 2.8598550001036127

Epoch: 6| Step: 2
Training loss: 0.8874499629247268
Validation loss: 2.872479577917373

Epoch: 6| Step: 3
Training loss: 0.996337651330068
Validation loss: 2.8534548677055094

Epoch: 6| Step: 4
Training loss: 0.8330748554543849
Validation loss: 2.8815261189957573

Epoch: 6| Step: 5
Training loss: 0.5446778985215183
Validation loss: 2.8903328000408646

Epoch: 6| Step: 6
Training loss: 0.7290024754177393
Validation loss: 2.905755455571444

Epoch: 6| Step: 7
Training loss: 1.1582478969726968
Validation loss: 2.898776313055864

Epoch: 6| Step: 8
Training loss: 1.128554873577883
Validation loss: 2.922506090848007

Epoch: 6| Step: 9
Training loss: 0.849094664659766
Validation loss: 2.8450644672511274

Epoch: 6| Step: 10
Training loss: 1.0941737852617957
Validation loss: 2.7444466670237957

Epoch: 6| Step: 11
Training loss: 0.8798005703881963
Validation loss: 2.865941316486092

Epoch: 6| Step: 12
Training loss: 0.8760442292988264
Validation loss: 2.992557618944341

Epoch: 6| Step: 13
Training loss: 0.4721591005804188
Validation loss: 2.989473857049263

Epoch: 200| Step: 0
Training loss: 0.9046524041044118
Validation loss: 2.8978227304408093

Epoch: 6| Step: 1
Training loss: 0.6682895314004736
Validation loss: 2.9081950908111827

Epoch: 6| Step: 2
Training loss: 0.9102206227864159
Validation loss: 2.8298084173516744

Epoch: 6| Step: 3
Training loss: 0.8898553031995282
Validation loss: 2.8966981067714452

Epoch: 6| Step: 4
Training loss: 0.6331815702992659
Validation loss: 2.818893103621667

Epoch: 6| Step: 5
Training loss: 1.2012134575818152
Validation loss: 2.8339794955484354

Epoch: 6| Step: 6
Training loss: 1.0882469155399104
Validation loss: 2.88579378291703

Epoch: 6| Step: 7
Training loss: 0.742728708602109
Validation loss: 2.8990270763877164

Epoch: 6| Step: 8
Training loss: 1.8908487613138791
Validation loss: 2.7805580106968497

Epoch: 6| Step: 9
Training loss: 0.9794224479394528
Validation loss: 2.881816026719453

Epoch: 6| Step: 10
Training loss: 0.63244330857014
Validation loss: 2.928923606464999

Epoch: 6| Step: 11
Training loss: 0.8927105360920161
Validation loss: 2.944834892208487

Epoch: 6| Step: 12
Training loss: 1.0569661145043336
Validation loss: 2.815458860586911

Epoch: 6| Step: 13
Training loss: 0.6434475197366234
Validation loss: 2.9502445685307004

Epoch: 201| Step: 0
Training loss: 1.0405274583162185
Validation loss: 2.935847121751428

Epoch: 6| Step: 1
Training loss: 0.5158573840742848
Validation loss: 2.8353524493462454

Epoch: 6| Step: 2
Training loss: 1.1229069630917825
Validation loss: 2.891433437810192

Epoch: 6| Step: 3
Training loss: 0.6812464495225131
Validation loss: 2.82981535413657

Epoch: 6| Step: 4
Training loss: 1.7948531344163359
Validation loss: 2.898006959043738

Epoch: 6| Step: 5
Training loss: 0.5960448238747411
Validation loss: 2.9108519812713842

Epoch: 6| Step: 6
Training loss: 0.902518119313112
Validation loss: 2.8754457874497477

Epoch: 6| Step: 7
Training loss: 0.6828643395061192
Validation loss: 2.986564858041058

Epoch: 6| Step: 8
Training loss: 1.1712748198591862
Validation loss: 2.9055574747358426

Epoch: 6| Step: 9
Training loss: 1.0042085303817405
Validation loss: 2.9243784904418386

Epoch: 6| Step: 10
Training loss: 0.7549761360388546
Validation loss: 2.9417483268908744

Epoch: 6| Step: 11
Training loss: 0.49954954360240056
Validation loss: 2.8480792784479267

Epoch: 6| Step: 12
Training loss: 0.8321743336179266
Validation loss: 2.9288514839072612

Epoch: 6| Step: 13
Training loss: 0.9133437827886192
Validation loss: 2.867674506436305

Epoch: 202| Step: 0
Training loss: 1.955437412841475
Validation loss: 2.80675586878844

Epoch: 6| Step: 1
Training loss: 0.7014669153564487
Validation loss: 3.0206083981308804

Epoch: 6| Step: 2
Training loss: 0.8769446969423792
Validation loss: 2.8807990012874

Epoch: 6| Step: 3
Training loss: 0.9797416513860648
Validation loss: 2.8289550630954294

Epoch: 6| Step: 4
Training loss: 0.874777220567139
Validation loss: 2.8868038455738954

Epoch: 6| Step: 5
Training loss: 0.6717248349602948
Validation loss: 2.8878825332003304

Epoch: 6| Step: 6
Training loss: 0.47990440161725945
Validation loss: 2.863982804669452

Epoch: 6| Step: 7
Training loss: 0.7291141945260446
Validation loss: 2.960738753305827

Epoch: 6| Step: 8
Training loss: 1.0166131714259719
Validation loss: 3.0127400119295054

Epoch: 6| Step: 9
Training loss: 1.2665513969139903
Validation loss: 2.9523555957603316

Epoch: 6| Step: 10
Training loss: 0.8960945428713389
Validation loss: 2.9373892634736873

Epoch: 6| Step: 11
Training loss: 1.0119886590601124
Validation loss: 2.952537424343999

Epoch: 6| Step: 12
Training loss: 0.8849070185507671
Validation loss: 2.8419193481761376

Epoch: 6| Step: 13
Training loss: 1.2418499373972485
Validation loss: 2.9151082553031746

Epoch: 203| Step: 0
Training loss: 1.9613560689589087
Validation loss: 2.9084929079985025

Epoch: 6| Step: 1
Training loss: 0.9466383282579348
Validation loss: 2.839698042666861

Epoch: 6| Step: 2
Training loss: 1.1891656036390024
Validation loss: 2.861837803013732

Epoch: 6| Step: 3
Training loss: 0.7653774717703141
Validation loss: 2.8979349720365546

Epoch: 6| Step: 4
Training loss: 1.03434888916251
Validation loss: 2.823628836648744

Epoch: 6| Step: 5
Training loss: 0.8441733605049452
Validation loss: 2.9058120014650073

Epoch: 6| Step: 6
Training loss: 0.8010679522609533
Validation loss: 2.8182915291448314

Epoch: 6| Step: 7
Training loss: 0.7374836483451942
Validation loss: 2.9056218743480127

Epoch: 6| Step: 8
Training loss: 0.9612596173543216
Validation loss: 2.844491938684576

Epoch: 6| Step: 9
Training loss: 0.7771014885575575
Validation loss: 2.8207416436879837

Epoch: 6| Step: 10
Training loss: 0.885206369595509
Validation loss: 2.9071583165897725

Epoch: 6| Step: 11
Training loss: 0.6783497679576082
Validation loss: 2.891965737299917

Epoch: 6| Step: 12
Training loss: 1.1857517323104299
Validation loss: 2.87110061471685

Epoch: 6| Step: 13
Training loss: 0.9540968770875551
Validation loss: 2.9154732215247767

Epoch: 204| Step: 0
Training loss: 0.9623424524941719
Validation loss: 2.9042358118379306

Epoch: 6| Step: 1
Training loss: 0.5773216800833268
Validation loss: 2.8964406938575236

Epoch: 6| Step: 2
Training loss: 0.8219357370191325
Validation loss: 2.9010321767070795

Epoch: 6| Step: 3
Training loss: 0.8564825452238547
Validation loss: 2.822316972910018

Epoch: 6| Step: 4
Training loss: 0.9427457910897463
Validation loss: 2.817700501793621

Epoch: 6| Step: 5
Training loss: 0.8177016717594874
Validation loss: 2.957038533358421

Epoch: 6| Step: 6
Training loss: 0.6785959269826648
Validation loss: 2.856614467035617

Epoch: 6| Step: 7
Training loss: 1.9086191432542485
Validation loss: 3.0044422771004315

Epoch: 6| Step: 8
Training loss: 1.1195608152437435
Validation loss: 2.9696676074264987

Epoch: 6| Step: 9
Training loss: 0.8065481063581224
Validation loss: 2.853759950121146

Epoch: 6| Step: 10
Training loss: 1.084378667379988
Validation loss: 2.9085927291951665

Epoch: 6| Step: 11
Training loss: 0.9858232168956045
Validation loss: 2.8176500992506956

Epoch: 6| Step: 12
Training loss: 0.735387955736426
Validation loss: 2.9340498934080954

Epoch: 6| Step: 13
Training loss: 0.7914243042704423
Validation loss: 2.8244052260846058

Epoch: 205| Step: 0
Training loss: 1.3103153120829973
Validation loss: 2.8672962635833743

Epoch: 6| Step: 1
Training loss: 0.862982098284332
Validation loss: 2.888980707111422

Epoch: 6| Step: 2
Training loss: 1.1319593702917128
Validation loss: 2.8583241461633078

Epoch: 6| Step: 3
Training loss: 0.7299231056971415
Validation loss: 2.949132841429513

Epoch: 6| Step: 4
Training loss: 0.9253918436411944
Validation loss: 2.911739429058928

Epoch: 6| Step: 5
Training loss: 0.7618202337494784
Validation loss: 2.8517108826374336

Epoch: 6| Step: 6
Training loss: 0.5834308156803906
Validation loss: 2.843038295235228

Epoch: 6| Step: 7
Training loss: 1.1711592459352398
Validation loss: 2.925137743192684

Epoch: 6| Step: 8
Training loss: 0.5854747979793707
Validation loss: 2.8270826298022445

Epoch: 6| Step: 9
Training loss: 0.6054347859362456
Validation loss: 2.9842522880530726

Epoch: 6| Step: 10
Training loss: 0.7333098458372361
Validation loss: 2.9185152916541695

Epoch: 6| Step: 11
Training loss: 0.9613811740242998
Validation loss: 2.893738672881069

Epoch: 6| Step: 12
Training loss: 1.9099332527161603
Validation loss: 2.8010894875341408

Epoch: 6| Step: 13
Training loss: 0.8350655830348658
Validation loss: 2.890461795083034

Epoch: 206| Step: 0
Training loss: 0.7602092555855819
Validation loss: 2.79024214957326

Epoch: 6| Step: 1
Training loss: 0.6168604599959993
Validation loss: 2.8866152540485723

Epoch: 6| Step: 2
Training loss: 0.9583476763495051
Validation loss: 2.828513861630484

Epoch: 6| Step: 3
Training loss: 1.0063031152958466
Validation loss: 2.9983826357096115

Epoch: 6| Step: 4
Training loss: 0.7649049681808504
Validation loss: 2.7902530227174003

Epoch: 6| Step: 5
Training loss: 0.9048146028456692
Validation loss: 2.9217520023235832

Epoch: 6| Step: 6
Training loss: 0.8612877107511275
Validation loss: 2.809887782036127

Epoch: 6| Step: 7
Training loss: 0.9201885249987127
Validation loss: 2.9397233976054817

Epoch: 6| Step: 8
Training loss: 0.75166105072337
Validation loss: 2.842085718111869

Epoch: 6| Step: 9
Training loss: 0.7357114440635584
Validation loss: 2.893730529873452

Epoch: 6| Step: 10
Training loss: 0.9583879780047978
Validation loss: 2.9115125802342785

Epoch: 6| Step: 11
Training loss: 0.696238212280205
Validation loss: 2.910772530588415

Epoch: 6| Step: 12
Training loss: 1.72946668419755
Validation loss: 2.8801657390146715

Epoch: 6| Step: 13
Training loss: 0.769365631715833
Validation loss: 2.9396852522028687

Epoch: 207| Step: 0
Training loss: 0.9837756678760128
Validation loss: 2.9075385077854725

Epoch: 6| Step: 1
Training loss: 0.8914226172747463
Validation loss: 2.8854105062223883

Epoch: 6| Step: 2
Training loss: 0.6899750330803175
Validation loss: 2.8552776225739303

Epoch: 6| Step: 3
Training loss: 0.6490244679151512
Validation loss: 2.823835755861763

Epoch: 6| Step: 4
Training loss: 0.8879670418624384
Validation loss: 2.9335880677379396

Epoch: 6| Step: 5
Training loss: 0.9280865773683227
Validation loss: 2.8871828634428067

Epoch: 6| Step: 6
Training loss: 0.5514473911156241
Validation loss: 2.818212133884981

Epoch: 6| Step: 7
Training loss: 0.8405894318043593
Validation loss: 2.889416347446838

Epoch: 6| Step: 8
Training loss: 0.8961385753963929
Validation loss: 2.952527357443592

Epoch: 6| Step: 9
Training loss: 0.8868873200693287
Validation loss: 2.862266482138687

Epoch: 6| Step: 10
Training loss: 1.0916606565606075
Validation loss: 2.8948814053311067

Epoch: 6| Step: 11
Training loss: 0.8098544184817225
Validation loss: 2.9236452108726763

Epoch: 6| Step: 12
Training loss: 2.0989313494617727
Validation loss: 2.8975827446818907

Epoch: 6| Step: 13
Training loss: 0.6838183224870077
Validation loss: 3.0028644238334845

Epoch: 208| Step: 0
Training loss: 0.6946996066419466
Validation loss: 2.8888274231101985

Epoch: 6| Step: 1
Training loss: 0.7199132048425795
Validation loss: 2.905132762591246

Epoch: 6| Step: 2
Training loss: 0.5621308864058813
Validation loss: 2.8969747960288323

Epoch: 6| Step: 3
Training loss: 0.7283859751188565
Validation loss: 2.922741127498182

Epoch: 6| Step: 4
Training loss: 1.8812560933670266
Validation loss: 2.883541466435246

Epoch: 6| Step: 5
Training loss: 0.9840558458080859
Validation loss: 2.9251875569998775

Epoch: 6| Step: 6
Training loss: 0.604975936663311
Validation loss: 2.863911849418168

Epoch: 6| Step: 7
Training loss: 0.8334115627445181
Validation loss: 2.9338662824759236

Epoch: 6| Step: 8
Training loss: 0.3926848081562966
Validation loss: 2.8763453058829223

Epoch: 6| Step: 9
Training loss: 0.9922964081352939
Validation loss: 2.9187186765657733

Epoch: 6| Step: 10
Training loss: 0.7595741010960334
Validation loss: 2.931090809743181

Epoch: 6| Step: 11
Training loss: 1.0502488159376415
Validation loss: 2.8938628818034746

Epoch: 6| Step: 12
Training loss: 0.9904711438384933
Validation loss: 2.858668811636566

Epoch: 6| Step: 13
Training loss: 0.9709399297147908
Validation loss: 2.851531160086592

Epoch: 209| Step: 0
Training loss: 0.810901426420699
Validation loss: 2.8619470059384415

Epoch: 6| Step: 1
Training loss: 0.8845850947705876
Validation loss: 2.849774626693873

Epoch: 6| Step: 2
Training loss: 0.7170784628431356
Validation loss: 2.904927243247935

Epoch: 6| Step: 3
Training loss: 1.9789058981984364
Validation loss: 2.9471077005601556

Epoch: 6| Step: 4
Training loss: 0.8913037909048895
Validation loss: 2.9241715651875433

Epoch: 6| Step: 5
Training loss: 1.1153785091329127
Validation loss: 2.9562198226065908

Epoch: 6| Step: 6
Training loss: 0.46312878111661293
Validation loss: 2.964891757501024

Epoch: 6| Step: 7
Training loss: 1.053972468123343
Validation loss: 2.8843648671323177

Epoch: 6| Step: 8
Training loss: 0.870086258361019
Validation loss: 2.908219056676126

Epoch: 6| Step: 9
Training loss: 0.6805095305633798
Validation loss: 2.9929115475152286

Epoch: 6| Step: 10
Training loss: 1.0913040058628394
Validation loss: 2.8126841873327897

Epoch: 6| Step: 11
Training loss: 0.7719867857014577
Validation loss: 2.76801835863644

Epoch: 6| Step: 12
Training loss: 0.8780248673117396
Validation loss: 2.912564449115673

Epoch: 6| Step: 13
Training loss: 0.6493631213866808
Validation loss: 2.8776046453737347

Epoch: 210| Step: 0
Training loss: 0.7986510810432528
Validation loss: 2.9052548088951085

Epoch: 6| Step: 1
Training loss: 0.8744946110179307
Validation loss: 2.796374753972279

Epoch: 6| Step: 2
Training loss: 0.9450563130932728
Validation loss: 2.919084709193801

Epoch: 6| Step: 3
Training loss: 0.4032691017872164
Validation loss: 2.848139229602829

Epoch: 6| Step: 4
Training loss: 1.887047527723456
Validation loss: 2.786861053076008

Epoch: 6| Step: 5
Training loss: 0.5736837944362417
Validation loss: 2.950132101409426

Epoch: 6| Step: 6
Training loss: 0.7475306868872573
Validation loss: 2.9117052431904678

Epoch: 6| Step: 7
Training loss: 1.026051626140971
Validation loss: 2.8921334394708915

Epoch: 6| Step: 8
Training loss: 0.6030157296610582
Validation loss: 2.810879756326616

Epoch: 6| Step: 9
Training loss: 1.042986866082862
Validation loss: 2.9341943687280403

Epoch: 6| Step: 10
Training loss: 0.6841100432428372
Validation loss: 2.9379392390199386

Epoch: 6| Step: 11
Training loss: 0.7754207576402598
Validation loss: 3.0321812460968958

Epoch: 6| Step: 12
Training loss: 0.8638738609088977
Validation loss: 2.9081052375546643

Epoch: 6| Step: 13
Training loss: 0.8215296117468863
Validation loss: 2.903845253612439

Epoch: 211| Step: 0
Training loss: 0.5259648698200485
Validation loss: 2.87267050146061

Epoch: 6| Step: 1
Training loss: 1.1661737740517109
Validation loss: 2.90861169162476

Epoch: 6| Step: 2
Training loss: 0.7218420855131676
Validation loss: 2.8783940860791795

Epoch: 6| Step: 3
Training loss: 0.6986907371884834
Validation loss: 2.8762867715455935

Epoch: 6| Step: 4
Training loss: 0.5840052980483127
Validation loss: 2.851944334341157

Epoch: 6| Step: 5
Training loss: 0.4325365460671509
Validation loss: 2.9269789318503348

Epoch: 6| Step: 6
Training loss: 1.1583284307051354
Validation loss: 2.8996504501714906

Epoch: 6| Step: 7
Training loss: 1.0777288068272874
Validation loss: 2.9129620230622186

Epoch: 6| Step: 8
Training loss: 0.7189376834795198
Validation loss: 2.948281233028718

Epoch: 6| Step: 9
Training loss: 0.6274943882284721
Validation loss: 2.8601360454747002

Epoch: 6| Step: 10
Training loss: 0.5687519566009738
Validation loss: 2.774575142512959

Epoch: 6| Step: 11
Training loss: 0.8106097093609148
Validation loss: 2.90328568532965

Epoch: 6| Step: 12
Training loss: 1.9014163410120561
Validation loss: 2.9439518194540697

Epoch: 6| Step: 13
Training loss: 0.9616080944817081
Validation loss: 2.8852374759123833

Epoch: 212| Step: 0
Training loss: 0.6098302461153828
Validation loss: 2.858644013346522

Epoch: 6| Step: 1
Training loss: 1.0714206945038938
Validation loss: 2.925508222416383

Epoch: 6| Step: 2
Training loss: 0.5421142165818141
Validation loss: 2.9417934829853776

Epoch: 6| Step: 3
Training loss: 0.8837725390159444
Validation loss: 2.8664500356112756

Epoch: 6| Step: 4
Training loss: 0.8319202761004496
Validation loss: 2.964579118487502

Epoch: 6| Step: 5
Training loss: 1.8600031969596706
Validation loss: 2.8930169321543295

Epoch: 6| Step: 6
Training loss: 0.9578003576109547
Validation loss: 2.9598700109712803

Epoch: 6| Step: 7
Training loss: 0.6523336306946352
Validation loss: 2.931272954247672

Epoch: 6| Step: 8
Training loss: 0.8552183019790427
Validation loss: 2.913018660962578

Epoch: 6| Step: 9
Training loss: 0.715756526670768
Validation loss: 2.8633335970906977

Epoch: 6| Step: 10
Training loss: 0.6244610369937644
Validation loss: 2.8794166116017195

Epoch: 6| Step: 11
Training loss: 0.8697308882685626
Validation loss: 2.881269571013053

Epoch: 6| Step: 12
Training loss: 0.7184771973741877
Validation loss: 2.865899734888817

Epoch: 6| Step: 13
Training loss: 0.5099900727147325
Validation loss: 2.9103847200628703

Epoch: 213| Step: 0
Training loss: 1.347786275147266
Validation loss: 2.728328508183666

Epoch: 6| Step: 1
Training loss: 0.4988517092489382
Validation loss: 2.8916582065278957

Epoch: 6| Step: 2
Training loss: 0.8902960052515444
Validation loss: 2.841172471986545

Epoch: 6| Step: 3
Training loss: 0.8400183917484467
Validation loss: 2.864874063245971

Epoch: 6| Step: 4
Training loss: 0.48722011466780546
Validation loss: 2.9247979080724504

Epoch: 6| Step: 5
Training loss: 0.7511678186744516
Validation loss: 2.942134569434453

Epoch: 6| Step: 6
Training loss: 0.954404128953519
Validation loss: 2.882121926068086

Epoch: 6| Step: 7
Training loss: 0.6937467111045615
Validation loss: 2.9475987176431024

Epoch: 6| Step: 8
Training loss: 0.8804593753400242
Validation loss: 2.9394934768695222

Epoch: 6| Step: 9
Training loss: 0.7405906363454426
Validation loss: 2.896814500272296

Epoch: 6| Step: 10
Training loss: 0.9059236201854403
Validation loss: 2.8265292195050846

Epoch: 6| Step: 11
Training loss: 1.881520758119738
Validation loss: 2.68147296941732

Epoch: 6| Step: 12
Training loss: 0.575220363311072
Validation loss: 2.804775622726992

Epoch: 6| Step: 13
Training loss: 0.8686398896069157
Validation loss: 2.859389619494588

Epoch: 214| Step: 0
Training loss: 0.9369046228063294
Validation loss: 2.869499099320078

Epoch: 6| Step: 1
Training loss: 1.2136740987442414
Validation loss: 2.8762484756016966

Epoch: 6| Step: 2
Training loss: 0.7231145282010214
Validation loss: 2.8713933325622594

Epoch: 6| Step: 3
Training loss: 1.867916076759905
Validation loss: 2.9049700991634126

Epoch: 6| Step: 4
Training loss: 0.8237865092011715
Validation loss: 2.9040798301977406

Epoch: 6| Step: 5
Training loss: 0.8949690168228426
Validation loss: 2.8323488815905646

Epoch: 6| Step: 6
Training loss: 0.6945641809129246
Validation loss: 2.9174688643859175

Epoch: 6| Step: 7
Training loss: 0.7249769733323829
Validation loss: 2.9215805938962327

Epoch: 6| Step: 8
Training loss: 0.9799571431286814
Validation loss: 2.8950998671836516

Epoch: 6| Step: 9
Training loss: 0.9920932995390274
Validation loss: 2.9744159905300513

Epoch: 6| Step: 10
Training loss: 0.876578949962625
Validation loss: 2.8968843615619675

Epoch: 6| Step: 11
Training loss: 0.973647443686298
Validation loss: 2.911789676780558

Epoch: 6| Step: 12
Training loss: 0.5120781371761159
Validation loss: 2.8688830525578313

Epoch: 6| Step: 13
Training loss: 0.6613118818060453
Validation loss: 2.898932237378591

Epoch: 215| Step: 0
Training loss: 0.6673769197323846
Validation loss: 2.8716724046180095

Epoch: 6| Step: 1
Training loss: 0.9971052232808458
Validation loss: 2.9415321407590658

Epoch: 6| Step: 2
Training loss: 0.6472401652511675
Validation loss: 2.8852451195429474

Epoch: 6| Step: 3
Training loss: 0.7711802208987655
Validation loss: 2.9496953515975726

Epoch: 6| Step: 4
Training loss: 0.7990656268819856
Validation loss: 2.8992596306022076

Epoch: 6| Step: 5
Training loss: 1.9959333919006854
Validation loss: 2.8708110228964845

Epoch: 6| Step: 6
Training loss: 0.8379542897897466
Validation loss: 2.8882073954710985

Epoch: 6| Step: 7
Training loss: 0.8563192659749319
Validation loss: 2.9326874424660323

Epoch: 6| Step: 8
Training loss: 0.7241394904919293
Validation loss: 3.024017895987873

Epoch: 6| Step: 9
Training loss: 1.1108809981215855
Validation loss: 3.0063677996675744

Epoch: 6| Step: 10
Training loss: 0.8106302609122215
Validation loss: 2.9834669772285833

Epoch: 6| Step: 11
Training loss: 0.8394830328298543
Validation loss: 2.9439663293915412

Epoch: 6| Step: 12
Training loss: 0.8528626342440554
Validation loss: 3.026569935335405

Epoch: 6| Step: 13
Training loss: 0.9643741345108114
Validation loss: 2.8551805509941093

Epoch: 216| Step: 0
Training loss: 0.7067850854083715
Validation loss: 2.861890495854275

Epoch: 6| Step: 1
Training loss: 0.7597145122212016
Validation loss: 2.9842784925904438

Epoch: 6| Step: 2
Training loss: 0.9402757560267485
Validation loss: 2.8616962426074886

Epoch: 6| Step: 3
Training loss: 1.1420099916304964
Validation loss: 2.794665524117889

Epoch: 6| Step: 4
Training loss: 1.2123568184855353
Validation loss: 2.8917865240961356

Epoch: 6| Step: 5
Training loss: 2.0595449606147715
Validation loss: 2.92804503112831

Epoch: 6| Step: 6
Training loss: 0.6466421067434149
Validation loss: 2.859177518323872

Epoch: 6| Step: 7
Training loss: 1.0271382289450985
Validation loss: 2.9151547509628295

Epoch: 6| Step: 8
Training loss: 0.8986828013036684
Validation loss: 2.872104693426095

Epoch: 6| Step: 9
Training loss: 0.48897262454294305
Validation loss: 2.964966742536505

Epoch: 6| Step: 10
Training loss: 0.8088679194381437
Validation loss: 2.9650066667710178

Epoch: 6| Step: 11
Training loss: 1.1078439812968937
Validation loss: 3.0538127196204594

Epoch: 6| Step: 12
Training loss: 0.7277868066677392
Validation loss: 2.793065451346235

Epoch: 6| Step: 13
Training loss: 0.8778773749426789
Validation loss: 2.8835156693623447

Epoch: 217| Step: 0
Training loss: 0.5846751538700602
Validation loss: 2.896646952508961

Epoch: 6| Step: 1
Training loss: 0.852141996818787
Validation loss: 2.877201108480808

Epoch: 6| Step: 2
Training loss: 0.886506849336709
Validation loss: 2.8568416413973337

Epoch: 6| Step: 3
Training loss: 0.8024816556123257
Validation loss: 2.848025576656129

Epoch: 6| Step: 4
Training loss: 0.9530782531781222
Validation loss: 2.863873263120239

Epoch: 6| Step: 5
Training loss: 0.9552042435142851
Validation loss: 2.8410422600254166

Epoch: 6| Step: 6
Training loss: 0.8475460912611072
Validation loss: 2.8828145675858523

Epoch: 6| Step: 7
Training loss: 0.7176949594374625
Validation loss: 2.8408003100751777

Epoch: 6| Step: 8
Training loss: 0.712064583228141
Validation loss: 2.894807583569646

Epoch: 6| Step: 9
Training loss: 1.779908126538858
Validation loss: 2.9302753587731014

Epoch: 6| Step: 10
Training loss: 0.9757250742933204
Validation loss: 2.9163135223948253

Epoch: 6| Step: 11
Training loss: 0.6448154863098156
Validation loss: 2.915841644404638

Epoch: 6| Step: 12
Training loss: 0.6051473933762861
Validation loss: 2.9736783262714885

Epoch: 6| Step: 13
Training loss: 0.6112262531262523
Validation loss: 2.974258198404258

Epoch: 218| Step: 0
Training loss: 0.5962568367460146
Validation loss: 2.9481589326731377

Epoch: 6| Step: 1
Training loss: 0.6381739971020158
Validation loss: 3.0397083344792466

Epoch: 6| Step: 2
Training loss: 0.9297334675684521
Validation loss: 2.834284718515099

Epoch: 6| Step: 3
Training loss: 0.8585175484745002
Validation loss: 2.9082409864992265

Epoch: 6| Step: 4
Training loss: 1.1355946019355094
Validation loss: 2.989052839541075

Epoch: 6| Step: 5
Training loss: 0.8280223926819524
Validation loss: 2.9063338947834474

Epoch: 6| Step: 6
Training loss: 0.8465233892824787
Validation loss: 2.8701685515475215

Epoch: 6| Step: 7
Training loss: 0.9258059083897987
Validation loss: 2.847575482625898

Epoch: 6| Step: 8
Training loss: 0.7165364720125432
Validation loss: 2.8086896021389642

Epoch: 6| Step: 9
Training loss: 0.7326042253470826
Validation loss: 2.8617208894788786

Epoch: 6| Step: 10
Training loss: 0.6513765440215948
Validation loss: 2.88752367139309

Epoch: 6| Step: 11
Training loss: 1.837087976881414
Validation loss: 2.86544117422876

Epoch: 6| Step: 12
Training loss: 0.9675478090011583
Validation loss: 2.9374000315869155

Epoch: 6| Step: 13
Training loss: 0.615527080358503
Validation loss: 2.900190866700579

Epoch: 219| Step: 0
Training loss: 0.7851240996046025
Validation loss: 2.951458630703964

Epoch: 6| Step: 1
Training loss: 1.117146097763206
Validation loss: 2.916366443622953

Epoch: 6| Step: 2
Training loss: 0.7467820752167196
Validation loss: 2.9627979308489922

Epoch: 6| Step: 3
Training loss: 0.6128369319389256
Validation loss: 2.931655114544924

Epoch: 6| Step: 4
Training loss: 0.9302571258620557
Validation loss: 2.8866952250773434

Epoch: 6| Step: 5
Training loss: 0.7451027085083649
Validation loss: 2.8326815154591034

Epoch: 6| Step: 6
Training loss: 0.9563443268272261
Validation loss: 2.871242237360127

Epoch: 6| Step: 7
Training loss: 1.952314284866689
Validation loss: 2.859635346447426

Epoch: 6| Step: 8
Training loss: 0.5602587979777893
Validation loss: 2.875486705881297

Epoch: 6| Step: 9
Training loss: 0.5511442300526495
Validation loss: 2.882602232559043

Epoch: 6| Step: 10
Training loss: 0.8952142365275567
Validation loss: 2.861366079033156

Epoch: 6| Step: 11
Training loss: 0.7029402808101064
Validation loss: 2.9715904166437097

Epoch: 6| Step: 12
Training loss: 1.0854310425863745
Validation loss: 2.9200538903101547

Epoch: 6| Step: 13
Training loss: 0.6361948678163126
Validation loss: 2.9843305814143712

Epoch: 220| Step: 0
Training loss: 0.6611876697404844
Validation loss: 2.950134391201958

Epoch: 6| Step: 1
Training loss: 0.9675979224140528
Validation loss: 2.9849850628562713

Epoch: 6| Step: 2
Training loss: 0.5125131337878757
Validation loss: 3.055734557389833

Epoch: 6| Step: 3
Training loss: 0.5408009402689434
Validation loss: 2.9325351015522974

Epoch: 6| Step: 4
Training loss: 0.7332692038788045
Validation loss: 2.9768336215157825

Epoch: 6| Step: 5
Training loss: 0.8405010401431698
Validation loss: 2.928468292859273

Epoch: 6| Step: 6
Training loss: 0.593243860046597
Validation loss: 2.957325969809276

Epoch: 6| Step: 7
Training loss: 0.841793334670267
Validation loss: 3.0041236220056793

Epoch: 6| Step: 8
Training loss: 1.2131836762896917
Validation loss: 2.866980064434546

Epoch: 6| Step: 9
Training loss: 0.7207458814224771
Validation loss: 2.9200030091239717

Epoch: 6| Step: 10
Training loss: 0.9571396435447785
Validation loss: 2.885975137550166

Epoch: 6| Step: 11
Training loss: 1.6938367476542293
Validation loss: 2.9606217188270367

Epoch: 6| Step: 12
Training loss: 0.7881590704091715
Validation loss: 2.912883734902736

Epoch: 6| Step: 13
Training loss: 1.0952571294396207
Validation loss: 2.9616127955171114

Epoch: 221| Step: 0
Training loss: 0.9628913678210878
Validation loss: 2.923481681377061

Epoch: 6| Step: 1
Training loss: 0.5695093587637232
Validation loss: 2.892041548321886

Epoch: 6| Step: 2
Training loss: 0.7666910495888903
Validation loss: 2.9648531853714597

Epoch: 6| Step: 3
Training loss: 0.7954202350425177
Validation loss: 2.9291334789742

Epoch: 6| Step: 4
Training loss: 0.754966109443587
Validation loss: 2.842445451587139

Epoch: 6| Step: 5
Training loss: 0.5972328182014838
Validation loss: 2.9350608682250794

Epoch: 6| Step: 6
Training loss: 0.8569501826319007
Validation loss: 2.791197799101108

Epoch: 6| Step: 7
Training loss: 0.8655253108492571
Validation loss: 2.868982056628218

Epoch: 6| Step: 8
Training loss: 0.7612063909983993
Validation loss: 2.9181044213800433

Epoch: 6| Step: 9
Training loss: 1.2382058683248622
Validation loss: 2.8939396454836555

Epoch: 6| Step: 10
Training loss: 1.785011001788089
Validation loss: 3.056848722449064

Epoch: 6| Step: 11
Training loss: 0.85883373207657
Validation loss: 2.9117548228039656

Epoch: 6| Step: 12
Training loss: 0.9427267603188513
Validation loss: 2.819492830342576

Epoch: 6| Step: 13
Training loss: 0.7609708586788878
Validation loss: 2.925914331863421

Epoch: 222| Step: 0
Training loss: 0.7663829710494057
Validation loss: 2.866582947070378

Epoch: 6| Step: 1
Training loss: 0.798692910985411
Validation loss: 2.9744441653831686

Epoch: 6| Step: 2
Training loss: 0.7507769216359119
Validation loss: 2.941840110687004

Epoch: 6| Step: 3
Training loss: 0.7867708827211949
Validation loss: 2.915627871311269

Epoch: 6| Step: 4
Training loss: 0.6240810313980995
Validation loss: 2.891537675170029

Epoch: 6| Step: 5
Training loss: 0.41672716496270407
Validation loss: 2.7786943573842615

Epoch: 6| Step: 6
Training loss: 0.9080912203193474
Validation loss: 2.8942359845791743

Epoch: 6| Step: 7
Training loss: 0.7525336860644872
Validation loss: 2.860282059234563

Epoch: 6| Step: 8
Training loss: 0.8809460853139368
Validation loss: 2.9478766817182644

Epoch: 6| Step: 9
Training loss: 0.5961422411792474
Validation loss: 2.9361061008530522

Epoch: 6| Step: 10
Training loss: 0.7671644343309771
Validation loss: 2.935173303620413

Epoch: 6| Step: 11
Training loss: 1.0448720759708998
Validation loss: 2.8660355002473326

Epoch: 6| Step: 12
Training loss: 1.9293840918838017
Validation loss: 2.9187386555420596

Epoch: 6| Step: 13
Training loss: 0.5733430374048764
Validation loss: 2.8290906771388

Epoch: 223| Step: 0
Training loss: 0.6321448112100444
Validation loss: 2.9366074958004305

Epoch: 6| Step: 1
Training loss: 0.6654196391062154
Validation loss: 2.91241956935386

Epoch: 6| Step: 2
Training loss: 0.7367746228807776
Validation loss: 2.974031054425487

Epoch: 6| Step: 3
Training loss: 0.5756860268681354
Validation loss: 2.9251368058644833

Epoch: 6| Step: 4
Training loss: 0.7951454017035572
Validation loss: 2.924488686976077

Epoch: 6| Step: 5
Training loss: 0.8741696709568217
Validation loss: 2.9161336184640594

Epoch: 6| Step: 6
Training loss: 0.7786464797477634
Validation loss: 2.9369816153598913

Epoch: 6| Step: 7
Training loss: 0.5263432371674591
Validation loss: 2.9738254728998172

Epoch: 6| Step: 8
Training loss: 0.99393171652312
Validation loss: 2.96331541318449

Epoch: 6| Step: 9
Training loss: 1.1036169495102628
Validation loss: 2.895438837491768

Epoch: 6| Step: 10
Training loss: 0.5181804103695303
Validation loss: 3.0112697466177356

Epoch: 6| Step: 11
Training loss: 0.8640489228821946
Validation loss: 2.979724542807287

Epoch: 6| Step: 12
Training loss: 0.7714674549420274
Validation loss: 2.8845628974084496

Epoch: 6| Step: 13
Training loss: 1.8415565374366223
Validation loss: 2.930131598827456

Epoch: 224| Step: 0
Training loss: 0.6255578650810599
Validation loss: 2.9109541036119

Epoch: 6| Step: 1
Training loss: 0.7427021049534399
Validation loss: 2.9320878567285105

Epoch: 6| Step: 2
Training loss: 0.8455386100900149
Validation loss: 3.0276664840783303

Epoch: 6| Step: 3
Training loss: 0.6443780890463815
Validation loss: 2.8599856337828937

Epoch: 6| Step: 4
Training loss: 0.7143545092082798
Validation loss: 2.9300488600926284

Epoch: 6| Step: 5
Training loss: 0.6454517149680006
Validation loss: 2.9056009504428366

Epoch: 6| Step: 6
Training loss: 0.5381939289815205
Validation loss: 2.8418540782786157

Epoch: 6| Step: 7
Training loss: 0.9270477002328845
Validation loss: 2.8191367786915618

Epoch: 6| Step: 8
Training loss: 1.1750412954013307
Validation loss: 2.828911434865191

Epoch: 6| Step: 9
Training loss: 1.7579256148501254
Validation loss: 2.9654633314834675

Epoch: 6| Step: 10
Training loss: 0.5615497616112263
Validation loss: 2.846212641253453

Epoch: 6| Step: 11
Training loss: 1.0029052018219633
Validation loss: 2.9464113325795456

Epoch: 6| Step: 12
Training loss: 0.8375907663722654
Validation loss: 2.9433726998314222

Epoch: 6| Step: 13
Training loss: 0.8311664940901626
Validation loss: 2.9117368361328717

Epoch: 225| Step: 0
Training loss: 1.928719096106162
Validation loss: 2.9363049450276946

Epoch: 6| Step: 1
Training loss: 0.7608960917836335
Validation loss: 2.8301081580127665

Epoch: 6| Step: 2
Training loss: 0.5649827894188936
Validation loss: 2.796118237854592

Epoch: 6| Step: 3
Training loss: 0.7837902731640133
Validation loss: 2.902450963432178

Epoch: 6| Step: 4
Training loss: 0.8131111487485068
Validation loss: 2.900214199946881

Epoch: 6| Step: 5
Training loss: 0.6135820756524849
Validation loss: 2.9351559749058573

Epoch: 6| Step: 6
Training loss: 0.6273398231772994
Validation loss: 2.8379642610914

Epoch: 6| Step: 7
Training loss: 0.6717882100316267
Validation loss: 2.953228270862786

Epoch: 6| Step: 8
Training loss: 0.6709361725124664
Validation loss: 2.976355371085247

Epoch: 6| Step: 9
Training loss: 0.5699429817291662
Validation loss: 2.9642843557235397

Epoch: 6| Step: 10
Training loss: 0.5648879649900236
Validation loss: 2.974242794152439

Epoch: 6| Step: 11
Training loss: 0.8414804169137913
Validation loss: 2.876789020140539

Epoch: 6| Step: 12
Training loss: 0.977559427664676
Validation loss: 2.985615630528761

Epoch: 6| Step: 13
Training loss: 0.8279536447840691
Validation loss: 2.9640129175029086

Epoch: 226| Step: 0
Training loss: 0.9509666581812327
Validation loss: 2.932224392613272

Epoch: 6| Step: 1
Training loss: 0.49151932305453605
Validation loss: 2.9582578935988795

Epoch: 6| Step: 2
Training loss: 0.6902978925079001
Validation loss: 2.9255708925268795

Epoch: 6| Step: 3
Training loss: 0.8266931066463534
Validation loss: 2.880902947565083

Epoch: 6| Step: 4
Training loss: 0.7715497339304191
Validation loss: 2.9212178325936002

Epoch: 6| Step: 5
Training loss: 0.4383465886499014
Validation loss: 2.9414791994813503

Epoch: 6| Step: 6
Training loss: 0.7243038469048357
Validation loss: 3.0009877247824663

Epoch: 6| Step: 7
Training loss: 0.6721374753092578
Validation loss: 2.9652479563833256

Epoch: 6| Step: 8
Training loss: 1.05165557222716
Validation loss: 2.896278694723025

Epoch: 6| Step: 9
Training loss: 0.7461332140965852
Validation loss: 3.0150496307851413

Epoch: 6| Step: 10
Training loss: 0.8698391282767569
Validation loss: 2.937107790472042

Epoch: 6| Step: 11
Training loss: 1.8454359719024667
Validation loss: 2.8476798462555117

Epoch: 6| Step: 12
Training loss: 0.550544877430992
Validation loss: 2.999040927171405

Epoch: 6| Step: 13
Training loss: 0.7892209639864666
Validation loss: 2.8594073795785206

Epoch: 227| Step: 0
Training loss: 0.8023128841595653
Validation loss: 2.884742180572543

Epoch: 6| Step: 1
Training loss: 0.7335166378747608
Validation loss: 2.995049816560044

Epoch: 6| Step: 2
Training loss: 0.6985818530259695
Validation loss: 2.910774318935205

Epoch: 6| Step: 3
Training loss: 0.7617925754864336
Validation loss: 2.930282139088774

Epoch: 6| Step: 4
Training loss: 0.5324226228256739
Validation loss: 2.915169785900198

Epoch: 6| Step: 5
Training loss: 0.87568215618609
Validation loss: 2.957849010706347

Epoch: 6| Step: 6
Training loss: 0.6739028225835245
Validation loss: 2.878132343869637

Epoch: 6| Step: 7
Training loss: 0.9396738598020367
Validation loss: 2.8172964663526847

Epoch: 6| Step: 8
Training loss: 0.9020718251493456
Validation loss: 2.97832238743042

Epoch: 6| Step: 9
Training loss: 0.5968558742794321
Validation loss: 2.8791488621147883

Epoch: 6| Step: 10
Training loss: 1.8319960470823262
Validation loss: 3.031199608872255

Epoch: 6| Step: 11
Training loss: 0.45244539202707423
Validation loss: 2.937508116365948

Epoch: 6| Step: 12
Training loss: 0.7388848960341539
Validation loss: 2.918973478247523

Epoch: 6| Step: 13
Training loss: 0.48771005408846996
Validation loss: 2.9929688896697617

Epoch: 228| Step: 0
Training loss: 0.6742069230086609
Validation loss: 2.982972006698519

Epoch: 6| Step: 1
Training loss: 0.8156049894019379
Validation loss: 2.931185611432484

Epoch: 6| Step: 2
Training loss: 0.7146075332666245
Validation loss: 3.02311982187066

Epoch: 6| Step: 3
Training loss: 0.651687749080989
Validation loss: 3.0083203039829383

Epoch: 6| Step: 4
Training loss: 0.431942519169667
Validation loss: 2.920097286267198

Epoch: 6| Step: 5
Training loss: 0.518726729824751
Validation loss: 2.919312099377241

Epoch: 6| Step: 6
Training loss: 0.7468631631719252
Validation loss: 2.9046054001522945

Epoch: 6| Step: 7
Training loss: 1.0007719398321577
Validation loss: 2.8786289283380757

Epoch: 6| Step: 8
Training loss: 0.6931667436390411
Validation loss: 2.804580884800259

Epoch: 6| Step: 9
Training loss: 0.8074045327976642
Validation loss: 2.9290732727427886

Epoch: 6| Step: 10
Training loss: 0.7312775076884545
Validation loss: 2.8978947408044595

Epoch: 6| Step: 11
Training loss: 1.778458063613014
Validation loss: 2.930785425239484

Epoch: 6| Step: 12
Training loss: 1.1396003196515017
Validation loss: 2.919171420380336

Epoch: 6| Step: 13
Training loss: 0.620100486710703
Validation loss: 2.8942669925020077

Epoch: 229| Step: 0
Training loss: 0.8310484476897432
Validation loss: 2.9880863566620346

Epoch: 6| Step: 1
Training loss: 0.6901205144901222
Validation loss: 2.938082373495894

Epoch: 6| Step: 2
Training loss: 0.8185195219896181
Validation loss: 2.979979775358008

Epoch: 6| Step: 3
Training loss: 0.6167945093516619
Validation loss: 2.9119654687486403

Epoch: 6| Step: 4
Training loss: 0.8461301927828441
Validation loss: 2.966172675641218

Epoch: 6| Step: 5
Training loss: 0.8371375908237271
Validation loss: 2.893965624252061

Epoch: 6| Step: 6
Training loss: 0.887094594478726
Validation loss: 2.8960074960126865

Epoch: 6| Step: 7
Training loss: 0.6862636199322244
Validation loss: 2.919210786681154

Epoch: 6| Step: 8
Training loss: 0.6454915377921323
Validation loss: 2.8391047814509376

Epoch: 6| Step: 9
Training loss: 0.8782851673819985
Validation loss: 2.84638285062576

Epoch: 6| Step: 10
Training loss: 1.8056640625
Validation loss: 2.925967228830887

Epoch: 6| Step: 11
Training loss: 0.48051759425053636
Validation loss: 2.8549440861230035

Epoch: 6| Step: 12
Training loss: 0.7249118142920652
Validation loss: 2.886794925935534

Epoch: 6| Step: 13
Training loss: 0.46195940113755646
Validation loss: 2.9078797996914405

Epoch: 230| Step: 0
Training loss: 0.8276474853535498
Validation loss: 2.8986029153596387

Epoch: 6| Step: 1
Training loss: 0.7586001992074276
Validation loss: 2.9641194285983863

Epoch: 6| Step: 2
Training loss: 1.7282618104610328
Validation loss: 3.0147697013255317

Epoch: 6| Step: 3
Training loss: 0.37298827185358374
Validation loss: 2.8905408142477755

Epoch: 6| Step: 4
Training loss: 0.7037159873237014
Validation loss: 2.901896836385373

Epoch: 6| Step: 5
Training loss: 0.772699987024105
Validation loss: 2.9821086486733974

Epoch: 6| Step: 6
Training loss: 0.5550296426709741
Validation loss: 2.9353645354371407

Epoch: 6| Step: 7
Training loss: 0.749906653317213
Validation loss: 2.817920928287024

Epoch: 6| Step: 8
Training loss: 0.6967245615246048
Validation loss: 2.9606854441375927

Epoch: 6| Step: 9
Training loss: 0.7476868721840478
Validation loss: 2.8132625393826602

Epoch: 6| Step: 10
Training loss: 0.6537013745869292
Validation loss: 2.8858677801781933

Epoch: 6| Step: 11
Training loss: 0.5184044629332412
Validation loss: 2.8187499362807396

Epoch: 6| Step: 12
Training loss: 0.7573945770931795
Validation loss: 2.909577846865175

Epoch: 6| Step: 13
Training loss: 1.1439533532309287
Validation loss: 2.8611468608149435

Epoch: 231| Step: 0
Training loss: 0.40041942958030735
Validation loss: 2.9980726276165597

Epoch: 6| Step: 1
Training loss: 0.8828503760930773
Validation loss: 2.9306206196276112

Epoch: 6| Step: 2
Training loss: 0.9195774024653436
Validation loss: 2.9850209121354965

Epoch: 6| Step: 3
Training loss: 0.39659838611026255
Validation loss: 2.985945004025087

Epoch: 6| Step: 4
Training loss: 0.9702392636486288
Validation loss: 3.018220486215655

Epoch: 6| Step: 5
Training loss: 0.7638907350652715
Validation loss: 2.954677664748643

Epoch: 6| Step: 6
Training loss: 0.6965193401124374
Validation loss: 2.8941558168842936

Epoch: 6| Step: 7
Training loss: 1.8926945228331737
Validation loss: 2.880093030133455

Epoch: 6| Step: 8
Training loss: 0.6829573802747794
Validation loss: 2.8463506579341127

Epoch: 6| Step: 9
Training loss: 0.45399007761821225
Validation loss: 2.9122703980194244

Epoch: 6| Step: 10
Training loss: 0.5365820498229225
Validation loss: 2.9358694948742574

Epoch: 6| Step: 11
Training loss: 0.6607992437965647
Validation loss: 2.967133627441487

Epoch: 6| Step: 12
Training loss: 0.9112567715072732
Validation loss: 2.9062580122204884

Epoch: 6| Step: 13
Training loss: 0.6900127182355059
Validation loss: 2.961660171126708

Epoch: 232| Step: 0
Training loss: 0.8513116729622527
Validation loss: 2.92381774180201

Epoch: 6| Step: 1
Training loss: 0.9835235000987163
Validation loss: 2.950726768173159

Epoch: 6| Step: 2
Training loss: 0.9613398198203436
Validation loss: 2.889200536615381

Epoch: 6| Step: 3
Training loss: 0.7263771559053567
Validation loss: 2.891480836384701

Epoch: 6| Step: 4
Training loss: 0.6344926922244306
Validation loss: 2.8674845528623045

Epoch: 6| Step: 5
Training loss: 0.5248726202067538
Validation loss: 2.941442792512639

Epoch: 6| Step: 6
Training loss: 0.6866297849762389
Validation loss: 2.792955461661643

Epoch: 6| Step: 7
Training loss: 0.8004025936395429
Validation loss: 2.9862697904156428

Epoch: 6| Step: 8
Training loss: 0.6060455528109329
Validation loss: 2.933045885964656

Epoch: 6| Step: 9
Training loss: 1.0934755253401067
Validation loss: 2.8516183647362054

Epoch: 6| Step: 10
Training loss: 0.4466231616858106
Validation loss: 2.878070628936279

Epoch: 6| Step: 11
Training loss: 1.7220963932886306
Validation loss: 2.8661133905000646

Epoch: 6| Step: 12
Training loss: 0.5173926830970254
Validation loss: 2.8633193585547354

Epoch: 6| Step: 13
Training loss: 0.8634347908565669
Validation loss: 2.8632119705124763

Epoch: 233| Step: 0
Training loss: 0.6854450987123961
Validation loss: 2.8981032954293036

Epoch: 6| Step: 1
Training loss: 0.979645524045919
Validation loss: 2.863648242338644

Epoch: 6| Step: 2
Training loss: 0.8296174330499191
Validation loss: 2.8779001949625576

Epoch: 6| Step: 3
Training loss: 0.4495427663134775
Validation loss: 2.9509511276415754

Epoch: 6| Step: 4
Training loss: 0.5200993006599769
Validation loss: 2.910365591691015

Epoch: 6| Step: 5
Training loss: 0.7903610346723365
Validation loss: 2.9341568827517883

Epoch: 6| Step: 6
Training loss: 1.6391767376563027
Validation loss: 2.940199240855581

Epoch: 6| Step: 7
Training loss: 0.8381485619813749
Validation loss: 2.8795434047436856

Epoch: 6| Step: 8
Training loss: 0.8608056038350596
Validation loss: 2.9480076473651042

Epoch: 6| Step: 9
Training loss: 0.5935758034005677
Validation loss: 2.892155848487405

Epoch: 6| Step: 10
Training loss: 0.6204753172005039
Validation loss: 2.9634727353804355

Epoch: 6| Step: 11
Training loss: 1.0027853797866313
Validation loss: 2.8438386868351935

Epoch: 6| Step: 12
Training loss: 0.5857262548484746
Validation loss: 2.9613429373202256

Epoch: 6| Step: 13
Training loss: 0.7875956885921639
Validation loss: 2.8420223116078307

Epoch: 234| Step: 0
Training loss: 0.9325407466218876
Validation loss: 2.9962279394571287

Epoch: 6| Step: 1
Training loss: 0.5021737055613834
Validation loss: 3.015043647348959

Epoch: 6| Step: 2
Training loss: 0.5622900465039372
Validation loss: 2.908262506258337

Epoch: 6| Step: 3
Training loss: 1.0205402277858702
Validation loss: 2.920584572190412

Epoch: 6| Step: 4
Training loss: 0.7439316583824064
Validation loss: 2.904128650615318

Epoch: 6| Step: 5
Training loss: 0.4857568257775511
Validation loss: 2.856666755461126

Epoch: 6| Step: 6
Training loss: 0.8632716873122619
Validation loss: 2.8912599983047955

Epoch: 6| Step: 7
Training loss: 0.6599488468648814
Validation loss: 2.848129449433074

Epoch: 6| Step: 8
Training loss: 0.5375820507587552
Validation loss: 2.9659338192388884

Epoch: 6| Step: 9
Training loss: 0.6810141365093643
Validation loss: 2.919526024632469

Epoch: 6| Step: 10
Training loss: 0.6899936275602558
Validation loss: 2.8789279890339547

Epoch: 6| Step: 11
Training loss: 0.7095538077835511
Validation loss: 2.897048356823349

Epoch: 6| Step: 12
Training loss: 1.7601664739685174
Validation loss: 2.9676516994233286

Epoch: 6| Step: 13
Training loss: 0.7603422590108402
Validation loss: 2.789927586193413

Epoch: 235| Step: 0
Training loss: 0.7033717252398495
Validation loss: 2.9545985183752386

Epoch: 6| Step: 1
Training loss: 0.6150884303815629
Validation loss: 2.8996478875468594

Epoch: 6| Step: 2
Training loss: 0.6623534256358213
Validation loss: 2.896045050440112

Epoch: 6| Step: 3
Training loss: 0.6304104273408113
Validation loss: 2.9714616805653744

Epoch: 6| Step: 4
Training loss: 1.12762653190628
Validation loss: 2.8260643830296233

Epoch: 6| Step: 5
Training loss: 1.748064264818355
Validation loss: 2.8429576203010556

Epoch: 6| Step: 6
Training loss: 0.8459390571052868
Validation loss: 2.9720503281019646

Epoch: 6| Step: 7
Training loss: 0.6018672022804601
Validation loss: 2.8260228474308287

Epoch: 6| Step: 8
Training loss: 0.8962203823500244
Validation loss: 2.81394076708007

Epoch: 6| Step: 9
Training loss: 0.7463893604344116
Validation loss: 2.952334868475018

Epoch: 6| Step: 10
Training loss: 0.7550888668584895
Validation loss: 2.8607814505280444

Epoch: 6| Step: 11
Training loss: 0.7294228966422676
Validation loss: 2.8889239555659625

Epoch: 6| Step: 12
Training loss: 0.7142303002524508
Validation loss: 2.928254695206269

Epoch: 6| Step: 13
Training loss: 0.5762530253531587
Validation loss: 2.932800849535074

Epoch: 236| Step: 0
Training loss: 0.770914374206827
Validation loss: 3.083089836059788

Epoch: 6| Step: 1
Training loss: 0.9136527683695224
Validation loss: 3.117671486003469

Epoch: 6| Step: 2
Training loss: 0.8016943215287912
Validation loss: 3.056667664949621

Epoch: 6| Step: 3
Training loss: 1.6911183876541618
Validation loss: 3.000733921558718

Epoch: 6| Step: 4
Training loss: 0.4316856395327324
Validation loss: 2.9402452721648706

Epoch: 6| Step: 5
Training loss: 1.0665482087718874
Validation loss: 3.008440066176307

Epoch: 6| Step: 6
Training loss: 0.6389886379694404
Validation loss: 2.9699772891279816

Epoch: 6| Step: 7
Training loss: 0.7351471108852597
Validation loss: 2.9681480198937633

Epoch: 6| Step: 8
Training loss: 1.048368498895168
Validation loss: 2.901439322173342

Epoch: 6| Step: 9
Training loss: 0.6072947378282663
Validation loss: 2.847946842892294

Epoch: 6| Step: 10
Training loss: 0.6325047062333115
Validation loss: 2.951926188211212

Epoch: 6| Step: 11
Training loss: 0.6814430628198481
Validation loss: 2.813876768736508

Epoch: 6| Step: 12
Training loss: 0.6204565366236049
Validation loss: 2.917291912545684

Epoch: 6| Step: 13
Training loss: 0.7338758760972366
Validation loss: 2.878780077546484

Epoch: 237| Step: 0
Training loss: 0.9192528042993003
Validation loss: 2.9733128735204724

Epoch: 6| Step: 1
Training loss: 0.6551228107094828
Validation loss: 2.8744159671954863

Epoch: 6| Step: 2
Training loss: 0.5838834235160087
Validation loss: 2.8507992633150465

Epoch: 6| Step: 3
Training loss: 0.7227279215145089
Validation loss: 2.881073659050337

Epoch: 6| Step: 4
Training loss: 0.8746995750757661
Validation loss: 2.9701149462923913

Epoch: 6| Step: 5
Training loss: 0.686837527404448
Validation loss: 2.9974527406082268

Epoch: 6| Step: 6
Training loss: 0.8489018793974802
Validation loss: 2.9757963380959382

Epoch: 6| Step: 7
Training loss: 0.6642144870733431
Validation loss: 2.8427176785108683

Epoch: 6| Step: 8
Training loss: 0.9908234839649002
Validation loss: 2.971915514937569

Epoch: 6| Step: 9
Training loss: 0.6736424065777972
Validation loss: 2.933235725671767

Epoch: 6| Step: 10
Training loss: 1.7646927524526987
Validation loss: 2.8643681023398346

Epoch: 6| Step: 11
Training loss: 0.7732179888942118
Validation loss: 2.835428842092847

Epoch: 6| Step: 12
Training loss: 0.5836513935100907
Validation loss: 2.989248879539903

Epoch: 6| Step: 13
Training loss: 0.8381706427905072
Validation loss: 2.8706770337155763

Epoch: 238| Step: 0
Training loss: 0.8703962878125283
Validation loss: 2.8756904325866923

Epoch: 6| Step: 1
Training loss: 0.7225012535691524
Validation loss: 2.928322069504304

Epoch: 6| Step: 2
Training loss: 0.43206571127670595
Validation loss: 2.923583457697195

Epoch: 6| Step: 3
Training loss: 0.5914130650156639
Validation loss: 2.941042123979936

Epoch: 6| Step: 4
Training loss: 0.669033117170275
Validation loss: 2.9848428196421257

Epoch: 6| Step: 5
Training loss: 0.8067461365050775
Validation loss: 3.016697365163772

Epoch: 6| Step: 6
Training loss: 1.9449739582897487
Validation loss: 3.0186782428224066

Epoch: 6| Step: 7
Training loss: 0.6698749848351724
Validation loss: 3.0033986787606026

Epoch: 6| Step: 8
Training loss: 0.8624107148769915
Validation loss: 3.1264790023236073

Epoch: 6| Step: 9
Training loss: 0.7487227372187876
Validation loss: 2.837786027381368

Epoch: 6| Step: 10
Training loss: 0.645491560877115
Validation loss: 2.9538044089096616

Epoch: 6| Step: 11
Training loss: 0.8499276102319435
Validation loss: 2.9357411685552943

Epoch: 6| Step: 12
Training loss: 0.7810126897877505
Validation loss: 2.9528435063296063

Epoch: 6| Step: 13
Training loss: 0.7495947776275625
Validation loss: 2.930387015013478

Epoch: 239| Step: 0
Training loss: 0.5110458725721067
Validation loss: 2.9036561540953363

Epoch: 6| Step: 1
Training loss: 0.8399774844126603
Validation loss: 2.8547492627674824

Epoch: 6| Step: 2
Training loss: 1.7188562533740812
Validation loss: 2.8610637659848854

Epoch: 6| Step: 3
Training loss: 0.7977509639450844
Validation loss: 2.969448455831231

Epoch: 6| Step: 4
Training loss: 0.6893824900464928
Validation loss: 2.9730708150234335

Epoch: 6| Step: 5
Training loss: 0.7337897383214881
Validation loss: 2.8927084348021723

Epoch: 6| Step: 6
Training loss: 0.837428821556618
Validation loss: 2.8841467632395745

Epoch: 6| Step: 7
Training loss: 0.7539579146476174
Validation loss: 3.087242166149915

Epoch: 6| Step: 8
Training loss: 0.7323407344377572
Validation loss: 2.892635615342237

Epoch: 6| Step: 9
Training loss: 0.6573820794539094
Validation loss: 3.016463655592296

Epoch: 6| Step: 10
Training loss: 0.6833850651054407
Validation loss: 3.0161175366796176

Epoch: 6| Step: 11
Training loss: 0.7344979933963838
Validation loss: 3.0094062975203086

Epoch: 6| Step: 12
Training loss: 0.5784923314383338
Validation loss: 2.920636586098874

Epoch: 6| Step: 13
Training loss: 0.7096790032023014
Validation loss: 2.9306424157185216

Epoch: 240| Step: 0
Training loss: 0.5554944468374315
Validation loss: 2.8854583755581813

Epoch: 6| Step: 1
Training loss: 0.7249294920869663
Validation loss: 2.922328607772581

Epoch: 6| Step: 2
Training loss: 0.8515096525540031
Validation loss: 2.927768251555176

Epoch: 6| Step: 3
Training loss: 0.5986923262866237
Validation loss: 3.017008106832346

Epoch: 6| Step: 4
Training loss: 0.5578364861297335
Validation loss: 2.9708551672676644

Epoch: 6| Step: 5
Training loss: 0.5641991330932886
Validation loss: 2.9532715560904417

Epoch: 6| Step: 6
Training loss: 0.6962177512954788
Validation loss: 2.8770294351982413

Epoch: 6| Step: 7
Training loss: 0.6454742469082585
Validation loss: 2.9350701827236825

Epoch: 6| Step: 8
Training loss: 0.9889352617183618
Validation loss: 2.9538134759665504

Epoch: 6| Step: 9
Training loss: 0.5853858130753747
Validation loss: 2.9278676395230097

Epoch: 6| Step: 10
Training loss: 0.60192104900236
Validation loss: 2.996978907529059

Epoch: 6| Step: 11
Training loss: 1.712311911173382
Validation loss: 2.9764052355348016

Epoch: 6| Step: 12
Training loss: 0.6864482246970584
Validation loss: 2.9301897220357285

Epoch: 6| Step: 13
Training loss: 0.568254126802724
Validation loss: 2.9968746117680114

Epoch: 241| Step: 0
Training loss: 0.4580923949917125
Validation loss: 2.8306108793351608

Epoch: 6| Step: 1
Training loss: 0.5321659158573336
Validation loss: 2.979894726939795

Epoch: 6| Step: 2
Training loss: 0.5462450486401775
Validation loss: 2.858757730642301

Epoch: 6| Step: 3
Training loss: 0.8676077365759816
Validation loss: 2.9598397910089562

Epoch: 6| Step: 4
Training loss: 0.6592187940512075
Validation loss: 2.9125287994576268

Epoch: 6| Step: 5
Training loss: 0.835509431275534
Validation loss: 2.9750009013155903

Epoch: 6| Step: 6
Training loss: 0.5775021471256123
Validation loss: 2.832416937862385

Epoch: 6| Step: 7
Training loss: 0.6495389201665961
Validation loss: 3.0059781512711963

Epoch: 6| Step: 8
Training loss: 1.7923149961503462
Validation loss: 2.98313938146194

Epoch: 6| Step: 9
Training loss: 0.5956510927583355
Validation loss: 2.9284233247986973

Epoch: 6| Step: 10
Training loss: 0.6840132379896062
Validation loss: 2.985544158775927

Epoch: 6| Step: 11
Training loss: 0.807311880207289
Validation loss: 2.966646794634781

Epoch: 6| Step: 12
Training loss: 0.9038564709513156
Validation loss: 2.9367241206775

Epoch: 6| Step: 13
Training loss: 0.6220627908536388
Validation loss: 2.9682446769170334

Epoch: 242| Step: 0
Training loss: 0.7070819562570009
Validation loss: 2.891722379765203

Epoch: 6| Step: 1
Training loss: 0.6581699351650342
Validation loss: 2.9220973047560417

Epoch: 6| Step: 2
Training loss: 1.72148919742152
Validation loss: 2.886882992392229

Epoch: 6| Step: 3
Training loss: 0.49559715527105985
Validation loss: 2.9145795620795485

Epoch: 6| Step: 4
Training loss: 0.554121669099255
Validation loss: 2.922575514758401

Epoch: 6| Step: 5
Training loss: 0.8619328665999856
Validation loss: 2.9330004732608685

Epoch: 6| Step: 6
Training loss: 0.7129256566467589
Validation loss: 3.018913965925642

Epoch: 6| Step: 7
Training loss: 0.6829259826144218
Validation loss: 2.8421145896234976

Epoch: 6| Step: 8
Training loss: 0.4547556770310088
Validation loss: 2.971408042229835

Epoch: 6| Step: 9
Training loss: 0.5434655311379036
Validation loss: 2.9998241346521892

Epoch: 6| Step: 10
Training loss: 0.9304298834766681
Validation loss: 2.9022883550697913

Epoch: 6| Step: 11
Training loss: 0.7352716369558222
Validation loss: 2.991758669409914

Epoch: 6| Step: 12
Training loss: 0.5563839504676444
Validation loss: 2.780483954726489

Epoch: 6| Step: 13
Training loss: 0.45095294743526443
Validation loss: 2.9896095000040126

Epoch: 243| Step: 0
Training loss: 0.7313199718938992
Validation loss: 3.097539141871795

Epoch: 6| Step: 1
Training loss: 0.8191607427787087
Validation loss: 2.925993344233972

Epoch: 6| Step: 2
Training loss: 0.6103490966747065
Validation loss: 2.9081755244625747

Epoch: 6| Step: 3
Training loss: 0.654973764585734
Validation loss: 2.918586362598657

Epoch: 6| Step: 4
Training loss: 0.6835938589913417
Validation loss: 2.9264503600086447

Epoch: 6| Step: 5
Training loss: 0.5331811585984344
Validation loss: 2.8728848707077685

Epoch: 6| Step: 6
Training loss: 0.6690651445189537
Validation loss: 2.975830388583568

Epoch: 6| Step: 7
Training loss: 0.5829232057046039
Validation loss: 2.908757826605107

Epoch: 6| Step: 8
Training loss: 1.7177916889619853
Validation loss: 2.9248669379418137

Epoch: 6| Step: 9
Training loss: 0.7140531910763226
Validation loss: 2.9968639115018036

Epoch: 6| Step: 10
Training loss: 0.6079271183941309
Validation loss: 2.974599563138279

Epoch: 6| Step: 11
Training loss: 0.6085618780798357
Validation loss: 3.021006761154628

Epoch: 6| Step: 12
Training loss: 0.7414040295132507
Validation loss: 3.0034578978405793

Epoch: 6| Step: 13
Training loss: 0.6153696547234827
Validation loss: 3.0285069747323017

Epoch: 244| Step: 0
Training loss: 0.81098958989246
Validation loss: 2.961151866819246

Epoch: 6| Step: 1
Training loss: 0.5044048415364593
Validation loss: 3.0838402425929154

Epoch: 6| Step: 2
Training loss: 0.5377984637701324
Validation loss: 3.036336059900206

Epoch: 6| Step: 3
Training loss: 0.6342754408034748
Validation loss: 2.969438198698791

Epoch: 6| Step: 4
Training loss: 0.5032579850436483
Validation loss: 2.904261794281379

Epoch: 6| Step: 5
Training loss: 1.6343069583886838
Validation loss: 2.933507275481473

Epoch: 6| Step: 6
Training loss: 0.6736620269837718
Validation loss: 2.976094139810617

Epoch: 6| Step: 7
Training loss: 0.5336178574485053
Validation loss: 2.8790570534037965

Epoch: 6| Step: 8
Training loss: 0.9600327737498805
Validation loss: 3.070486748096995

Epoch: 6| Step: 9
Training loss: 0.6225749413830983
Validation loss: 2.955715247750244

Epoch: 6| Step: 10
Training loss: 0.6247503497293324
Validation loss: 2.9569488473595342

Epoch: 6| Step: 11
Training loss: 0.49952936374378576
Validation loss: 2.8863473669661737

Epoch: 6| Step: 12
Training loss: 0.7476838428663293
Validation loss: 2.998517743140695

Epoch: 6| Step: 13
Training loss: 0.8361938653873722
Validation loss: 3.0264476344037488

Epoch: 245| Step: 0
Training loss: 0.4931409622674216
Validation loss: 3.0517881639115694

Epoch: 6| Step: 1
Training loss: 0.9737059050187504
Validation loss: 2.8967668323150164

Epoch: 6| Step: 2
Training loss: 0.5465123472764652
Validation loss: 2.9563636311688857

Epoch: 6| Step: 3
Training loss: 0.669553249358254
Validation loss: 2.9475500510131702

Epoch: 6| Step: 4
Training loss: 0.5447341978591864
Validation loss: 2.8379532837081816

Epoch: 6| Step: 5
Training loss: 0.5737073008952605
Validation loss: 2.8609670435076078

Epoch: 6| Step: 6
Training loss: 0.5946128498477569
Validation loss: 2.884330797666106

Epoch: 6| Step: 7
Training loss: 0.7228249017993181
Validation loss: 2.9458783429999937

Epoch: 6| Step: 8
Training loss: 0.5797284032163846
Validation loss: 2.9314739561980616

Epoch: 6| Step: 9
Training loss: 1.8028163705282705
Validation loss: 2.8173242801996814

Epoch: 6| Step: 10
Training loss: 0.6746050350224106
Validation loss: 2.9846614014507606

Epoch: 6| Step: 11
Training loss: 0.7779929359233011
Validation loss: 2.9583027305273815

Epoch: 6| Step: 12
Training loss: 0.6795007076315883
Validation loss: 2.812619362170285

Epoch: 6| Step: 13
Training loss: 0.699678088998479
Validation loss: 2.926802195196687

Epoch: 246| Step: 0
Training loss: 0.6215379913622737
Validation loss: 3.0074910177856156

Epoch: 6| Step: 1
Training loss: 1.6872086450050525
Validation loss: 2.9891671257631964

Epoch: 6| Step: 2
Training loss: 0.8496491521534438
Validation loss: 2.9410687135142397

Epoch: 6| Step: 3
Training loss: 0.6379038541301544
Validation loss: 2.9223284174072557

Epoch: 6| Step: 4
Training loss: 0.5985927350566627
Validation loss: 2.9310645092889236

Epoch: 6| Step: 5
Training loss: 0.8074449127114485
Validation loss: 2.992251867758999

Epoch: 6| Step: 6
Training loss: 0.6731328500840712
Validation loss: 2.8569191007757784

Epoch: 6| Step: 7
Training loss: 0.5460970385974975
Validation loss: 2.8977430527926624

Epoch: 6| Step: 8
Training loss: 0.689003016700563
Validation loss: 2.908801063228185

Epoch: 6| Step: 9
Training loss: 0.5497096574144221
Validation loss: 2.937805903854461

Epoch: 6| Step: 10
Training loss: 0.7151105205775014
Validation loss: 2.946407475471663

Epoch: 6| Step: 11
Training loss: 0.7532355136434234
Validation loss: 2.9443411739001255

Epoch: 6| Step: 12
Training loss: 0.5075535040402154
Validation loss: 3.083721166567924

Epoch: 6| Step: 13
Training loss: 0.8908930592607288
Validation loss: 2.995871365287646

Epoch: 247| Step: 0
Training loss: 0.8056319166764025
Validation loss: 2.9802641058810573

Epoch: 6| Step: 1
Training loss: 0.792298320114067
Validation loss: 2.8428264417722637

Epoch: 6| Step: 2
Training loss: 1.733993557061146
Validation loss: 2.8282455924441585

Epoch: 6| Step: 3
Training loss: 0.5214983477488574
Validation loss: 2.9103394862440437

Epoch: 6| Step: 4
Training loss: 0.6769082038533848
Validation loss: 2.9331101155602792

Epoch: 6| Step: 5
Training loss: 0.6319645982074085
Validation loss: 2.999089526722819

Epoch: 6| Step: 6
Training loss: 0.8781400265205548
Validation loss: 2.9543201107174144

Epoch: 6| Step: 7
Training loss: 0.6626620166530346
Validation loss: 2.8998018054541452

Epoch: 6| Step: 8
Training loss: 0.5500928215249163
Validation loss: 3.0394002274042777

Epoch: 6| Step: 9
Training loss: 0.5973042966449574
Validation loss: 2.957511738517126

Epoch: 6| Step: 10
Training loss: 0.4995575526772944
Validation loss: 2.8339519573367

Epoch: 6| Step: 11
Training loss: 0.900725726412256
Validation loss: 2.861577906897425

Epoch: 6| Step: 12
Training loss: 0.7721820236129189
Validation loss: 2.9306771874358994

Epoch: 6| Step: 13
Training loss: 0.951373257164417
Validation loss: 2.953657381486636

Epoch: 248| Step: 0
Training loss: 0.60428523401984
Validation loss: 2.96211576209993

Epoch: 6| Step: 1
Training loss: 1.6648965097746729
Validation loss: 2.9259121589251813

Epoch: 6| Step: 2
Training loss: 0.581131489270091
Validation loss: 2.9429196757265608

Epoch: 6| Step: 3
Training loss: 0.47021855147851865
Validation loss: 2.870213158607972

Epoch: 6| Step: 4
Training loss: 0.7108303450431784
Validation loss: 2.970700690548326

Epoch: 6| Step: 5
Training loss: 0.5749989094931172
Validation loss: 2.854584173773027

Epoch: 6| Step: 6
Training loss: 0.4060674587367966
Validation loss: 2.9471642889891854

Epoch: 6| Step: 7
Training loss: 0.8008777839346712
Validation loss: 2.9708061860829558

Epoch: 6| Step: 8
Training loss: 0.4693325714104918
Validation loss: 2.995775347605206

Epoch: 6| Step: 9
Training loss: 0.5212167917737753
Validation loss: 2.8298524108836185

Epoch: 6| Step: 10
Training loss: 0.3977995234048826
Validation loss: 2.897875845370446

Epoch: 6| Step: 11
Training loss: 0.6683773330425168
Validation loss: 2.960708421419445

Epoch: 6| Step: 12
Training loss: 1.174344220694507
Validation loss: 2.979794780611601

Epoch: 6| Step: 13
Training loss: 0.7381613094046143
Validation loss: 2.963172820367239

Epoch: 249| Step: 0
Training loss: 0.6835865783315211
Validation loss: 2.968502128024177

Epoch: 6| Step: 1
Training loss: 0.4996421844947671
Validation loss: 2.9139328996817437

Epoch: 6| Step: 2
Training loss: 0.9066860531097056
Validation loss: 2.863544502317029

Epoch: 6| Step: 3
Training loss: 0.7582700468910439
Validation loss: 2.85694481810466

Epoch: 6| Step: 4
Training loss: 0.6264220272902399
Validation loss: 2.8861400005162174

Epoch: 6| Step: 5
Training loss: 0.5141154357647514
Validation loss: 2.92779713318049

Epoch: 6| Step: 6
Training loss: 0.5665488754123942
Validation loss: 2.859413994417269

Epoch: 6| Step: 7
Training loss: 0.43843600079150286
Validation loss: 2.8657982116954894

Epoch: 6| Step: 8
Training loss: 0.5447646156825775
Validation loss: 2.907947892021695

Epoch: 6| Step: 9
Training loss: 0.497854741753431
Validation loss: 3.0657198451539474

Epoch: 6| Step: 10
Training loss: 0.9994997919262759
Validation loss: 2.9506385737083143

Epoch: 6| Step: 11
Training loss: 1.8077067430797038
Validation loss: 2.999066260514574

Epoch: 6| Step: 12
Training loss: 0.5507549252543088
Validation loss: 3.0316106313008073

Epoch: 6| Step: 13
Training loss: 0.5848475682314612
Validation loss: 3.025532643001862

Epoch: 250| Step: 0
Training loss: 0.8540431297721365
Validation loss: 2.9200619122830704

Epoch: 6| Step: 1
Training loss: 1.814782119998543
Validation loss: 2.859697000685559

Epoch: 6| Step: 2
Training loss: 0.6726904732995449
Validation loss: 3.0004199184475504

Epoch: 6| Step: 3
Training loss: 0.6602586068701344
Validation loss: 2.8604337055970377

Epoch: 6| Step: 4
Training loss: 0.5085835984677461
Validation loss: 2.994594366236314

Epoch: 6| Step: 5
Training loss: 0.49931353891445807
Validation loss: 3.007822011957362

Epoch: 6| Step: 6
Training loss: 0.675957629168178
Validation loss: 2.9293084335929973

Epoch: 6| Step: 7
Training loss: 0.5783872009781119
Validation loss: 3.097814644880427

Epoch: 6| Step: 8
Training loss: 0.6956568733103896
Validation loss: 3.0059838487128188

Epoch: 6| Step: 9
Training loss: 0.459168466214267
Validation loss: 2.953645071694272

Epoch: 6| Step: 10
Training loss: 0.7073282703334708
Validation loss: 2.988706630773436

Epoch: 6| Step: 11
Training loss: 0.6097730656914597
Validation loss: 2.8760943195995057

Epoch: 6| Step: 12
Training loss: 0.5298154760729162
Validation loss: 2.9764905438607503

Epoch: 6| Step: 13
Training loss: 0.5539880560334511
Validation loss: 2.874951984170414

Epoch: 251| Step: 0
Training loss: 0.7399282099078351
Validation loss: 2.8862686942029154

Epoch: 6| Step: 1
Training loss: 0.8177671634058938
Validation loss: 2.920221510262751

Epoch: 6| Step: 2
Training loss: 0.5522400495635199
Validation loss: 2.9303208137094043

Epoch: 6| Step: 3
Training loss: 0.5387032735524367
Validation loss: 2.8618668918032397

Epoch: 6| Step: 4
Training loss: 0.6433989317545088
Validation loss: 2.9471228286668936

Epoch: 6| Step: 5
Training loss: 0.6680356934670841
Validation loss: 2.890185265988085

Epoch: 6| Step: 6
Training loss: 0.6564767990574024
Validation loss: 2.9684324128116417

Epoch: 6| Step: 7
Training loss: 0.5193067366706852
Validation loss: 2.9183789177309483

Epoch: 6| Step: 8
Training loss: 0.7921545800586435
Validation loss: 2.944949167306182

Epoch: 6| Step: 9
Training loss: 0.6960833273641442
Validation loss: 2.909712489214763

Epoch: 6| Step: 10
Training loss: 0.6199897214591269
Validation loss: 2.9992737155841676

Epoch: 6| Step: 11
Training loss: 1.7453796838245246
Validation loss: 2.851861396348577

Epoch: 6| Step: 12
Training loss: 0.42157395536045256
Validation loss: 3.009075715317295

Epoch: 6| Step: 13
Training loss: 0.931719154870884
Validation loss: 2.929542748160116

Epoch: 252| Step: 0
Training loss: 0.6387850693184999
Validation loss: 2.9649512699083282

Epoch: 6| Step: 1
Training loss: 0.7236153501393371
Validation loss: 2.958529416601925

Epoch: 6| Step: 2
Training loss: 0.8960568940117074
Validation loss: 3.036063184376365

Epoch: 6| Step: 3
Training loss: 0.5343580488672992
Validation loss: 2.9203665200222884

Epoch: 6| Step: 4
Training loss: 0.5652157868108175
Validation loss: 2.9131607624077565

Epoch: 6| Step: 5
Training loss: 0.5356023001562332
Validation loss: 2.9138804660970754

Epoch: 6| Step: 6
Training loss: 1.7690595457062128
Validation loss: 3.0011241846326717

Epoch: 6| Step: 7
Training loss: 0.6568022402565441
Validation loss: 2.876352848809777

Epoch: 6| Step: 8
Training loss: 0.6688934974372593
Validation loss: 2.889152674267465

Epoch: 6| Step: 9
Training loss: 0.6024985276595998
Validation loss: 2.825826817599402

Epoch: 6| Step: 10
Training loss: 0.3990356219387751
Validation loss: 2.9488530822821626

Epoch: 6| Step: 11
Training loss: 0.4728785851000078
Validation loss: 2.95837100546764

Epoch: 6| Step: 12
Training loss: 0.5387106590333897
Validation loss: 2.9944485055883736

Epoch: 6| Step: 13
Training loss: 0.7150702195932419
Validation loss: 2.957216822228128

Epoch: 253| Step: 0
Training loss: 0.4625964135122488
Validation loss: 2.9679889841269436

Epoch: 6| Step: 1
Training loss: 0.5980016670108129
Validation loss: 3.030840593723862

Epoch: 6| Step: 2
Training loss: 0.44151598486254706
Validation loss: 2.8553561820313145

Epoch: 6| Step: 3
Training loss: 0.6492144055456417
Validation loss: 2.96106527114879

Epoch: 6| Step: 4
Training loss: 0.7175244788403654
Validation loss: 2.825490423410964

Epoch: 6| Step: 5
Training loss: 0.7001327848514148
Validation loss: 2.870322901209061

Epoch: 6| Step: 6
Training loss: 0.5387845082748428
Validation loss: 2.9768390944186494

Epoch: 6| Step: 7
Training loss: 0.7101603861437581
Validation loss: 2.966037514941283

Epoch: 6| Step: 8
Training loss: 0.7570117770781845
Validation loss: 2.9684322387892856

Epoch: 6| Step: 9
Training loss: 0.7003611390884991
Validation loss: 2.948415913896193

Epoch: 6| Step: 10
Training loss: 0.6463763328233093
Validation loss: 2.9621002544571375

Epoch: 6| Step: 11
Training loss: 0.5966487195958246
Validation loss: 2.9433095177248205

Epoch: 6| Step: 12
Training loss: 0.5988869804230225
Validation loss: 2.8877941532224387

Epoch: 6| Step: 13
Training loss: 1.8723697015020253
Validation loss: 2.9201425186197163

Epoch: 254| Step: 0
Training loss: 0.6269201347251431
Validation loss: 2.9426387317269502

Epoch: 6| Step: 1
Training loss: 0.7622292006480244
Validation loss: 3.015621429072293

Epoch: 6| Step: 2
Training loss: 0.7042153699009576
Validation loss: 2.8528160788682544

Epoch: 6| Step: 3
Training loss: 1.759938493000681
Validation loss: 2.944898351934705

Epoch: 6| Step: 4
Training loss: 0.664144353870693
Validation loss: 2.820081650293643

Epoch: 6| Step: 5
Training loss: 0.41736973414907924
Validation loss: 2.979857082438797

Epoch: 6| Step: 6
Training loss: 0.5806952639093491
Validation loss: 2.8733669286860066

Epoch: 6| Step: 7
Training loss: 0.7531430428270793
Validation loss: 2.961083562061569

Epoch: 6| Step: 8
Training loss: 0.7286106896440641
Validation loss: 2.9268986563385346

Epoch: 6| Step: 9
Training loss: 0.551679595534537
Validation loss: 2.968207259509255

Epoch: 6| Step: 10
Training loss: 0.3812328561461542
Validation loss: 2.8875663590065286

Epoch: 6| Step: 11
Training loss: 0.570989885813496
Validation loss: 2.915023795151253

Epoch: 6| Step: 12
Training loss: 0.6425077173682403
Validation loss: 2.8443747731913294

Epoch: 6| Step: 13
Training loss: 0.4745475666003045
Validation loss: 2.919422337425859

Epoch: 255| Step: 0
Training loss: 0.872192203422939
Validation loss: 3.0935787577390803

Epoch: 6| Step: 1
Training loss: 0.4891064042198355
Validation loss: 2.8662168711785543

Epoch: 6| Step: 2
Training loss: 0.6907353351884999
Validation loss: 2.91867796259658

Epoch: 6| Step: 3
Training loss: 0.574521121386317
Validation loss: 3.0628755948969704

Epoch: 6| Step: 4
Training loss: 0.5605403886479573
Validation loss: 2.879515777893522

Epoch: 6| Step: 5
Training loss: 0.5321674839092749
Validation loss: 2.9282973725599177

Epoch: 6| Step: 6
Training loss: 0.5541056146429837
Validation loss: 2.9826000054671615

Epoch: 6| Step: 7
Training loss: 0.957479068537277
Validation loss: 3.0414835252016204

Epoch: 6| Step: 8
Training loss: 0.7039607696927567
Validation loss: 2.957711333492554

Epoch: 6| Step: 9
Training loss: 0.6411243446482111
Validation loss: 2.9259912799984265

Epoch: 6| Step: 10
Training loss: 0.48805121534532503
Validation loss: 2.9570065240737486

Epoch: 6| Step: 11
Training loss: 0.5881542995909615
Validation loss: 2.9134714244730646

Epoch: 6| Step: 12
Training loss: 1.8041786037810754
Validation loss: 2.8999320647076257

Epoch: 6| Step: 13
Training loss: 0.5066197399108227
Validation loss: 2.9139102217607826

Epoch: 256| Step: 0
Training loss: 0.5807864812328511
Validation loss: 2.964050709605961

Epoch: 6| Step: 1
Training loss: 1.7971672152212055
Validation loss: 2.8687275727059554

Epoch: 6| Step: 2
Training loss: 0.9043427490726583
Validation loss: 2.938240864171979

Epoch: 6| Step: 3
Training loss: 0.5659091741423251
Validation loss: 2.992291135794335

Epoch: 6| Step: 4
Training loss: 0.7441585668768788
Validation loss: 2.975484711298518

Epoch: 6| Step: 5
Training loss: 0.459439915981383
Validation loss: 3.0174274756758512

Epoch: 6| Step: 6
Training loss: 0.4815826529631017
Validation loss: 2.8941125811498756

Epoch: 6| Step: 7
Training loss: 1.1233181567728037
Validation loss: 2.9470049837853636

Epoch: 6| Step: 8
Training loss: 0.4870481255269182
Validation loss: 3.027806439881368

Epoch: 6| Step: 9
Training loss: 0.8239829281987474
Validation loss: 2.9712699100317854

Epoch: 6| Step: 10
Training loss: 0.5545910764889754
Validation loss: 2.8701454170727723

Epoch: 6| Step: 11
Training loss: 0.7968984114255903
Validation loss: 2.886483024088666

Epoch: 6| Step: 12
Training loss: 0.8995987726299857
Validation loss: 2.953683588392837

Epoch: 6| Step: 13
Training loss: 0.47679732743800735
Validation loss: 2.81583049107574

Epoch: 257| Step: 0
Training loss: 0.5319732903322234
Validation loss: 2.8569104772821405

Epoch: 6| Step: 1
Training loss: 0.8365742050110122
Validation loss: 3.026284204284745

Epoch: 6| Step: 2
Training loss: 0.5091114743293086
Validation loss: 2.961031265585856

Epoch: 6| Step: 3
Training loss: 1.6129969607310979
Validation loss: 2.9294225140578716

Epoch: 6| Step: 4
Training loss: 0.46776289320750536
Validation loss: 2.860212887707952

Epoch: 6| Step: 5
Training loss: 0.6704288488395151
Validation loss: 2.917448365953956

Epoch: 6| Step: 6
Training loss: 0.3477709827338603
Validation loss: 2.9678619662778973

Epoch: 6| Step: 7
Training loss: 0.6053171275626144
Validation loss: 3.022051892104971

Epoch: 6| Step: 8
Training loss: 0.8045481588957898
Validation loss: 2.9471047612220294

Epoch: 6| Step: 9
Training loss: 0.6829386160370023
Validation loss: 2.964960698236624

Epoch: 6| Step: 10
Training loss: 0.5469048083219713
Validation loss: 2.91062833980636

Epoch: 6| Step: 11
Training loss: 0.7564684954182787
Validation loss: 3.0040206986589144

Epoch: 6| Step: 12
Training loss: 0.6201465509626478
Validation loss: 2.9353873183491435

Epoch: 6| Step: 13
Training loss: 0.651134306356529
Validation loss: 2.8508139128489525

Epoch: 258| Step: 0
Training loss: 0.5619067136239554
Validation loss: 2.889723986168469

Epoch: 6| Step: 1
Training loss: 0.4685157508461907
Validation loss: 2.870114986163136

Epoch: 6| Step: 2
Training loss: 0.6028228536599661
Validation loss: 2.9895405827211468

Epoch: 6| Step: 3
Training loss: 0.7176886476014059
Validation loss: 2.9325469986015844

Epoch: 6| Step: 4
Training loss: 0.6556427734845988
Validation loss: 2.9598851812491964

Epoch: 6| Step: 5
Training loss: 0.5649435163638207
Validation loss: 2.92735925009779

Epoch: 6| Step: 6
Training loss: 0.4465352387379278
Validation loss: 2.957079438086074

Epoch: 6| Step: 7
Training loss: 1.6362345486837375
Validation loss: 3.024249734131009

Epoch: 6| Step: 8
Training loss: 0.4055134992951288
Validation loss: 3.050456897199526

Epoch: 6| Step: 9
Training loss: 0.7082142496050602
Validation loss: 2.86728679821116

Epoch: 6| Step: 10
Training loss: 1.0093418316661829
Validation loss: 2.9340050108939844

Epoch: 6| Step: 11
Training loss: 0.5525761839612634
Validation loss: 2.9831797950987564

Epoch: 6| Step: 12
Training loss: 0.4299368914879786
Validation loss: 2.9866619834125223

Epoch: 6| Step: 13
Training loss: 1.021385465249703
Validation loss: 2.9788201448455265

Epoch: 259| Step: 0
Training loss: 0.8274490188614023
Validation loss: 2.9025234544996343

Epoch: 6| Step: 1
Training loss: 0.6294926817652661
Validation loss: 3.0293476125902234

Epoch: 6| Step: 2
Training loss: 0.7698843286379256
Validation loss: 2.963164747478884

Epoch: 6| Step: 3
Training loss: 0.5906811763145218
Validation loss: 2.943329080022012

Epoch: 6| Step: 4
Training loss: 0.8664144558599655
Validation loss: 2.911387629779296

Epoch: 6| Step: 5
Training loss: 0.7439909055984624
Validation loss: 2.8436187182854025

Epoch: 6| Step: 6
Training loss: 1.806897482268663
Validation loss: 2.875712499925467

Epoch: 6| Step: 7
Training loss: 0.6786741836805433
Validation loss: 2.8754383665168066

Epoch: 6| Step: 8
Training loss: 0.4091537940816143
Validation loss: 2.9559531352462467

Epoch: 6| Step: 9
Training loss: 0.487848471537748
Validation loss: 3.01507007190596

Epoch: 6| Step: 10
Training loss: 0.9422894841760031
Validation loss: 3.1929289019233784

Epoch: 6| Step: 11
Training loss: 0.6898536275327136
Validation loss: 2.9678781534231296

Epoch: 6| Step: 12
Training loss: 0.8745172735790743
Validation loss: 3.072736267139437

Epoch: 6| Step: 13
Training loss: 0.6868806563501134
Validation loss: 3.039587163541462

Epoch: 260| Step: 0
Training loss: 1.6970409248960658
Validation loss: 3.0237182171441592

Epoch: 6| Step: 1
Training loss: 0.6237346237519642
Validation loss: 2.8912393003123653

Epoch: 6| Step: 2
Training loss: 0.6130495544896173
Validation loss: 2.8702556329671953

Epoch: 6| Step: 3
Training loss: 0.5423476144910686
Validation loss: 2.895632391528472

Epoch: 6| Step: 4
Training loss: 0.37671644063753584
Validation loss: 3.024928327504758

Epoch: 6| Step: 5
Training loss: 0.6773746426235226
Validation loss: 2.8684791198807447

Epoch: 6| Step: 6
Training loss: 0.7492435136984597
Validation loss: 2.944752080808941

Epoch: 6| Step: 7
Training loss: 0.5891603717395724
Validation loss: 2.8547520188096382

Epoch: 6| Step: 8
Training loss: 0.8575431720553676
Validation loss: 2.9426918952055168

Epoch: 6| Step: 9
Training loss: 0.6977925166451778
Validation loss: 2.9437315430707116

Epoch: 6| Step: 10
Training loss: 0.7492933520585362
Validation loss: 2.8930762130635475

Epoch: 6| Step: 11
Training loss: 0.46222545620100747
Validation loss: 2.985830008905682

Epoch: 6| Step: 12
Training loss: 0.7328772998131549
Validation loss: 3.0416636053270234

Epoch: 6| Step: 13
Training loss: 0.5138245562359437
Validation loss: 3.0287467084744217

Epoch: 261| Step: 0
Training loss: 0.4422334667347842
Validation loss: 2.888991201761259

Epoch: 6| Step: 1
Training loss: 0.8009944724941149
Validation loss: 2.9543623173915377

Epoch: 6| Step: 2
Training loss: 0.513793988815817
Validation loss: 2.924803736479047

Epoch: 6| Step: 3
Training loss: 0.5830137677423677
Validation loss: 2.866408211863441

Epoch: 6| Step: 4
Training loss: 0.7661642394371441
Validation loss: 2.8629569181779915

Epoch: 6| Step: 5
Training loss: 0.7040849067315833
Validation loss: 2.9544905611865375

Epoch: 6| Step: 6
Training loss: 1.7663401952824889
Validation loss: 2.867443326230934

Epoch: 6| Step: 7
Training loss: 0.6021009735198388
Validation loss: 2.9173295675540496

Epoch: 6| Step: 8
Training loss: 0.5261270969881089
Validation loss: 2.9101228784614843

Epoch: 6| Step: 9
Training loss: 0.6700024792639566
Validation loss: 2.8847563133700707

Epoch: 6| Step: 10
Training loss: 0.753310447432449
Validation loss: 2.8462186445458872

Epoch: 6| Step: 11
Training loss: 0.7420639738384561
Validation loss: 2.911217876916088

Epoch: 6| Step: 12
Training loss: 0.36393172981159694
Validation loss: 2.9430335526251206

Epoch: 6| Step: 13
Training loss: 0.9445290589918498
Validation loss: 2.883398339378498

Epoch: 262| Step: 0
Training loss: 0.7320770672736433
Validation loss: 2.9106749752888357

Epoch: 6| Step: 1
Training loss: 0.4307967692981031
Validation loss: 2.917770167908434

Epoch: 6| Step: 2
Training loss: 0.7778917231048683
Validation loss: 2.876608799263579

Epoch: 6| Step: 3
Training loss: 0.7649028252610165
Validation loss: 3.0179609037411352

Epoch: 6| Step: 4
Training loss: 0.3586678804388272
Validation loss: 2.9089927993200972

Epoch: 6| Step: 5
Training loss: 0.7677294943458242
Validation loss: 2.898315152913203

Epoch: 6| Step: 6
Training loss: 0.9536478140848792
Validation loss: 2.844606123946992

Epoch: 6| Step: 7
Training loss: 0.5121546628525807
Validation loss: 2.946461663328674

Epoch: 6| Step: 8
Training loss: 1.6807631486125607
Validation loss: 2.90827220717704

Epoch: 6| Step: 9
Training loss: 0.5275585161087382
Validation loss: 2.934818261155737

Epoch: 6| Step: 10
Training loss: 0.4808975570233127
Validation loss: 2.94117733899272

Epoch: 6| Step: 11
Training loss: 0.8434993936867787
Validation loss: 3.0112626802022557

Epoch: 6| Step: 12
Training loss: 0.3922177458874807
Validation loss: 2.9605738165690254

Epoch: 6| Step: 13
Training loss: 0.7494072558640956
Validation loss: 2.941924368257236

Epoch: 263| Step: 0
Training loss: 0.685019265620939
Validation loss: 2.874471712641317

Epoch: 6| Step: 1
Training loss: 0.8039750584107126
Validation loss: 2.968117429030538

Epoch: 6| Step: 2
Training loss: 0.882306451834988
Validation loss: 2.897154737543838

Epoch: 6| Step: 3
Training loss: 0.6851453556251638
Validation loss: 2.8926988053202125

Epoch: 6| Step: 4
Training loss: 0.5551175344438027
Validation loss: 2.904976815433748

Epoch: 6| Step: 5
Training loss: 0.3338133725531851
Validation loss: 2.905818674765101

Epoch: 6| Step: 6
Training loss: 0.4618831567727995
Validation loss: 2.8072908268197714

Epoch: 6| Step: 7
Training loss: 0.7262947245366725
Validation loss: 3.0266611818720435

Epoch: 6| Step: 8
Training loss: 0.6033518300417618
Validation loss: 2.8950852084097

Epoch: 6| Step: 9
Training loss: 0.5719595862196779
Validation loss: 2.9846123273130734

Epoch: 6| Step: 10
Training loss: 0.8796121432888218
Validation loss: 2.924664000968278

Epoch: 6| Step: 11
Training loss: 0.4772879597578069
Validation loss: 2.9023087825867853

Epoch: 6| Step: 12
Training loss: 1.664848607600844
Validation loss: 2.9370221770690423

Epoch: 6| Step: 13
Training loss: 0.7769999294845569
Validation loss: 3.0597421594001846

Epoch: 264| Step: 0
Training loss: 0.5515082140783788
Validation loss: 2.8563906272587682

Epoch: 6| Step: 1
Training loss: 0.5702863190794757
Validation loss: 2.9246464469444917

Epoch: 6| Step: 2
Training loss: 0.7321034464048048
Validation loss: 2.8355503431019495

Epoch: 6| Step: 3
Training loss: 0.7572987181393372
Validation loss: 2.9047253071864034

Epoch: 6| Step: 4
Training loss: 0.6311820182452711
Validation loss: 2.8703460480970966

Epoch: 6| Step: 5
Training loss: 0.8694127374791405
Validation loss: 2.9564882533257633

Epoch: 6| Step: 6
Training loss: 0.4668137774739194
Validation loss: 2.851788349004231

Epoch: 6| Step: 7
Training loss: 0.5778915346269203
Validation loss: 2.860827460986262

Epoch: 6| Step: 8
Training loss: 0.8005850947111095
Validation loss: 2.8853218439452792

Epoch: 6| Step: 9
Training loss: 0.6954529866797782
Validation loss: 2.855053719740589

Epoch: 6| Step: 10
Training loss: 1.7369789302736167
Validation loss: 2.8655414481758923

Epoch: 6| Step: 11
Training loss: 0.47951024287583516
Validation loss: 2.892763669770569

Epoch: 6| Step: 12
Training loss: 0.5366966187468865
Validation loss: 2.8815273738913163

Epoch: 6| Step: 13
Training loss: 0.5588833251722117
Validation loss: 2.9867330558953777

Epoch: 265| Step: 0
Training loss: 0.4595228567073534
Validation loss: 2.894977104522527

Epoch: 6| Step: 1
Training loss: 0.4912824483885598
Validation loss: 2.9695276814510985

Epoch: 6| Step: 2
Training loss: 0.6635444640056227
Validation loss: 2.94632325169973

Epoch: 6| Step: 3
Training loss: 0.920282216375304
Validation loss: 2.8725185189398563

Epoch: 6| Step: 4
Training loss: 0.6121052929925314
Validation loss: 2.9401513031975712

Epoch: 6| Step: 5
Training loss: 0.8238476826429549
Validation loss: 2.936006382730841

Epoch: 6| Step: 6
Training loss: 0.4741962031577255
Validation loss: 2.915211387154148

Epoch: 6| Step: 7
Training loss: 0.8651570098250809
Validation loss: 2.8943402857556553

Epoch: 6| Step: 8
Training loss: 0.731261695051002
Validation loss: 2.899510859202086

Epoch: 6| Step: 9
Training loss: 0.602368990793551
Validation loss: 2.9282698664321742

Epoch: 6| Step: 10
Training loss: 0.5512217390294157
Validation loss: 2.9360163844705562

Epoch: 6| Step: 11
Training loss: 1.6427643406169037
Validation loss: 2.877506849389606

Epoch: 6| Step: 12
Training loss: 0.6109534142023936
Validation loss: 2.922691747848704

Epoch: 6| Step: 13
Training loss: 0.3649047343157356
Validation loss: 2.972191097912579

Epoch: 266| Step: 0
Training loss: 0.637664467034914
Validation loss: 2.9590369225128215

Epoch: 6| Step: 1
Training loss: 0.4346980903591441
Validation loss: 2.9844620909973547

Epoch: 6| Step: 2
Training loss: 1.65987058089069
Validation loss: 3.020187313237106

Epoch: 6| Step: 3
Training loss: 0.7364911776659756
Validation loss: 2.969421605219692

Epoch: 6| Step: 4
Training loss: 0.7386080709787524
Validation loss: 3.0323962374528115

Epoch: 6| Step: 5
Training loss: 0.647336507724963
Validation loss: 2.847132253905327

Epoch: 6| Step: 6
Training loss: 0.6758220858721802
Validation loss: 2.885445857445499

Epoch: 6| Step: 7
Training loss: 0.8255713334065468
Validation loss: 2.9419197893971036

Epoch: 6| Step: 8
Training loss: 0.6850780612085491
Validation loss: 2.894262207816529

Epoch: 6| Step: 9
Training loss: 0.8135397200778886
Validation loss: 2.973675446604006

Epoch: 6| Step: 10
Training loss: 0.29530183682036765
Validation loss: 3.0043946238327157

Epoch: 6| Step: 11
Training loss: 0.5804187532356841
Validation loss: 3.0071112802066744

Epoch: 6| Step: 12
Training loss: 0.9115799014444808
Validation loss: 2.93574296876289

Epoch: 6| Step: 13
Training loss: 0.5561476281077515
Validation loss: 2.881138330089833

Epoch: 267| Step: 0
Training loss: 0.6412606690915359
Validation loss: 3.022742442064515

Epoch: 6| Step: 1
Training loss: 0.519189019168474
Validation loss: 3.014238292365829

Epoch: 6| Step: 2
Training loss: 0.5604423398893389
Validation loss: 2.925043913791456

Epoch: 6| Step: 3
Training loss: 0.5847469951182216
Validation loss: 2.940357563372034

Epoch: 6| Step: 4
Training loss: 0.6326619192798814
Validation loss: 2.925755417917296

Epoch: 6| Step: 5
Training loss: 0.4413930502749323
Validation loss: 2.970096202602369

Epoch: 6| Step: 6
Training loss: 0.4066048136396161
Validation loss: 2.922936877241748

Epoch: 6| Step: 7
Training loss: 0.6098032204806626
Validation loss: 2.8764446056877664

Epoch: 6| Step: 8
Training loss: 1.8028563089349368
Validation loss: 2.9265147750936005

Epoch: 6| Step: 9
Training loss: 0.5746425180841459
Validation loss: 2.903262130405815

Epoch: 6| Step: 10
Training loss: 0.7465057034641902
Validation loss: 2.949158482219991

Epoch: 6| Step: 11
Training loss: 0.42377564768973214
Validation loss: 2.997881459198846

Epoch: 6| Step: 12
Training loss: 0.7671559655570744
Validation loss: 2.9645644145548675

Epoch: 6| Step: 13
Training loss: 0.7032147668121271
Validation loss: 2.950718041765517

Epoch: 268| Step: 0
Training loss: 0.6840016701089536
Validation loss: 2.8897958339525167

Epoch: 6| Step: 1
Training loss: 0.6453887783532529
Validation loss: 3.0313798804494816

Epoch: 6| Step: 2
Training loss: 0.4103910954572739
Validation loss: 2.9723872874722916

Epoch: 6| Step: 3
Training loss: 0.624462802811492
Validation loss: 2.9780982753839487

Epoch: 6| Step: 4
Training loss: 0.8226272621372933
Validation loss: 2.907730381793602

Epoch: 6| Step: 5
Training loss: 0.42721006405000256
Validation loss: 2.9794821983360835

Epoch: 6| Step: 6
Training loss: 1.64087602420652
Validation loss: 2.9481182411390794

Epoch: 6| Step: 7
Training loss: 0.8073836038393564
Validation loss: 2.9177145483370013

Epoch: 6| Step: 8
Training loss: 0.38747163176524424
Validation loss: 2.887570212144968

Epoch: 6| Step: 9
Training loss: 0.4573133853050339
Validation loss: 2.921998754046325

Epoch: 6| Step: 10
Training loss: 0.8233329750039663
Validation loss: 3.0503607609539514

Epoch: 6| Step: 11
Training loss: 0.6756948515065417
Validation loss: 3.0710091225262826

Epoch: 6| Step: 12
Training loss: 0.8111399491581963
Validation loss: 3.012866944669604

Epoch: 6| Step: 13
Training loss: 0.5034668063460745
Validation loss: 2.9425486068362496

Epoch: 269| Step: 0
Training loss: 0.7919970793284884
Validation loss: 2.9342015462627957

Epoch: 6| Step: 1
Training loss: 0.44283980119169586
Validation loss: 3.0096013814219593

Epoch: 6| Step: 2
Training loss: 0.6640569125669693
Validation loss: 2.98037238275633

Epoch: 6| Step: 3
Training loss: 0.5565292514677533
Validation loss: 2.8823090262672055

Epoch: 6| Step: 4
Training loss: 0.7653528625137689
Validation loss: 2.8732883914595515

Epoch: 6| Step: 5
Training loss: 1.7115207183234704
Validation loss: 2.9129877776197155

Epoch: 6| Step: 6
Training loss: 0.8225348749854451
Validation loss: 2.880404934143013

Epoch: 6| Step: 7
Training loss: 0.6784414071805629
Validation loss: 2.992107181118481

Epoch: 6| Step: 8
Training loss: 0.5748394316925575
Validation loss: 2.9008181683908223

Epoch: 6| Step: 9
Training loss: 0.5914925274219723
Validation loss: 2.916358922435892

Epoch: 6| Step: 10
Training loss: 0.4824593409765966
Validation loss: 3.0141743413946815

Epoch: 6| Step: 11
Training loss: 0.6027086659138361
Validation loss: 2.914336190823934

Epoch: 6| Step: 12
Training loss: 0.7070023968115057
Validation loss: 2.882781665227025

Epoch: 6| Step: 13
Training loss: 0.5817516090360979
Validation loss: 2.9539070237683434

Epoch: 270| Step: 0
Training loss: 0.40509157811396085
Validation loss: 2.911690190363427

Epoch: 6| Step: 1
Training loss: 0.5399557535711519
Validation loss: 2.9444909067106906

Epoch: 6| Step: 2
Training loss: 0.6003787295789356
Validation loss: 2.980206665941714

Epoch: 6| Step: 3
Training loss: 0.6653058697400139
Validation loss: 2.8837847358144963

Epoch: 6| Step: 4
Training loss: 0.6047599088701504
Validation loss: 2.9336843125290457

Epoch: 6| Step: 5
Training loss: 0.6166780034732907
Validation loss: 3.0351606489269924

Epoch: 6| Step: 6
Training loss: 0.536166858808044
Validation loss: 2.9804528045561067

Epoch: 6| Step: 7
Training loss: 1.6951733369446937
Validation loss: 2.9554794855853044

Epoch: 6| Step: 8
Training loss: 0.809122032783592
Validation loss: 2.887747038144804

Epoch: 6| Step: 9
Training loss: 0.48748896598555386
Validation loss: 2.9339691477277876

Epoch: 6| Step: 10
Training loss: 0.5062309285091919
Validation loss: 2.938737256990489

Epoch: 6| Step: 11
Training loss: 0.5681389450023644
Validation loss: 2.9394235873507273

Epoch: 6| Step: 12
Training loss: 0.4664042429665173
Validation loss: 2.9268407393052387

Epoch: 6| Step: 13
Training loss: 0.7009827722767031
Validation loss: 2.8633183871120798

Epoch: 271| Step: 0
Training loss: 0.4617114116518001
Validation loss: 2.9558551823084818

Epoch: 6| Step: 1
Training loss: 0.58283605553527
Validation loss: 3.0769694009986193

Epoch: 6| Step: 2
Training loss: 0.44700064993390787
Validation loss: 2.937320135575525

Epoch: 6| Step: 3
Training loss: 0.4968887477148471
Validation loss: 2.932245519533544

Epoch: 6| Step: 4
Training loss: 0.6438269263664747
Validation loss: 2.923684292680522

Epoch: 6| Step: 5
Training loss: 0.5907306949965899
Validation loss: 3.100877277774015

Epoch: 6| Step: 6
Training loss: 0.6151028447106024
Validation loss: 2.961147800784455

Epoch: 6| Step: 7
Training loss: 0.400862401885056
Validation loss: 2.892581037321992

Epoch: 6| Step: 8
Training loss: 0.5495302860532478
Validation loss: 2.957764951522242

Epoch: 6| Step: 9
Training loss: 0.7023914325215501
Validation loss: 2.9174931762929317

Epoch: 6| Step: 10
Training loss: 0.6380414505306776
Validation loss: 3.0246682959881435

Epoch: 6| Step: 11
Training loss: 0.5551266610752706
Validation loss: 2.911042858816877

Epoch: 6| Step: 12
Training loss: 0.7894012932464545
Validation loss: 2.8964508733786167

Epoch: 6| Step: 13
Training loss: 1.6058353645907062
Validation loss: 2.9369912078893807

Epoch: 272| Step: 0
Training loss: 0.6866074967777617
Validation loss: 2.982382743493795

Epoch: 6| Step: 1
Training loss: 0.6871034171934268
Validation loss: 3.010461784913467

Epoch: 6| Step: 2
Training loss: 0.598790208744632
Validation loss: 2.9288643998908865

Epoch: 6| Step: 3
Training loss: 0.4722535648494118
Validation loss: 3.0595414539497736

Epoch: 6| Step: 4
Training loss: 1.5899053088368202
Validation loss: 2.95909125509581

Epoch: 6| Step: 5
Training loss: 0.6059273244506054
Validation loss: 2.855356947436122

Epoch: 6| Step: 6
Training loss: 0.447088064738702
Validation loss: 2.859250904996675

Epoch: 6| Step: 7
Training loss: 0.6115271880998246
Validation loss: 2.837965535249202

Epoch: 6| Step: 8
Training loss: 0.7732922966800693
Validation loss: 2.90868357832955

Epoch: 6| Step: 9
Training loss: 0.5869492252118244
Validation loss: 2.950484789330478

Epoch: 6| Step: 10
Training loss: 0.6945857203678456
Validation loss: 2.8945357528150426

Epoch: 6| Step: 11
Training loss: 0.5986093637874127
Validation loss: 3.010445476952907

Epoch: 6| Step: 12
Training loss: 0.901101913349024
Validation loss: 2.895496147522526

Epoch: 6| Step: 13
Training loss: 0.5411894481168787
Validation loss: 2.8808548232220397

Epoch: 273| Step: 0
Training loss: 0.6376797964828486
Validation loss: 2.866471418581035

Epoch: 6| Step: 1
Training loss: 0.5809260634701703
Validation loss: 2.8376274433168316

Epoch: 6| Step: 2
Training loss: 0.5583461399412596
Validation loss: 2.972695215465267

Epoch: 6| Step: 3
Training loss: 0.6999309258781149
Validation loss: 2.9812510519072504

Epoch: 6| Step: 4
Training loss: 0.9509095881913514
Validation loss: 2.978256624561385

Epoch: 6| Step: 5
Training loss: 0.6759053595913284
Validation loss: 2.9557072754888094

Epoch: 6| Step: 6
Training loss: 0.47034203065949903
Validation loss: 2.9667413039587505

Epoch: 6| Step: 7
Training loss: 0.6045565470758624
Validation loss: 2.9521146118904773

Epoch: 6| Step: 8
Training loss: 0.7637153086298917
Validation loss: 2.887468638944757

Epoch: 6| Step: 9
Training loss: 0.5795029122671919
Validation loss: 2.8436759547839565

Epoch: 6| Step: 10
Training loss: 1.7100601385372214
Validation loss: 2.9397676791742398

Epoch: 6| Step: 11
Training loss: 0.458221743466391
Validation loss: 2.965436069592458

Epoch: 6| Step: 12
Training loss: 0.7427557125379046
Validation loss: 2.955341294616169

Epoch: 6| Step: 13
Training loss: 0.5801621193233176
Validation loss: 2.9641351133577354

Epoch: 274| Step: 0
Training loss: 0.5846647299120428
Validation loss: 3.0204101441465063

Epoch: 6| Step: 1
Training loss: 1.602314246922973
Validation loss: 2.975734311794634

Epoch: 6| Step: 2
Training loss: 0.7552309010959393
Validation loss: 3.0203322466346036

Epoch: 6| Step: 3
Training loss: 0.35338477352742553
Validation loss: 2.9947295649627126

Epoch: 6| Step: 4
Training loss: 0.5100136807420634
Validation loss: 3.0115431995412663

Epoch: 6| Step: 5
Training loss: 0.5619992835610462
Validation loss: 3.0108632655116003

Epoch: 6| Step: 6
Training loss: 0.4771491957544086
Validation loss: 2.992577031927951

Epoch: 6| Step: 7
Training loss: 0.7052549103569652
Validation loss: 2.8996890674171194

Epoch: 6| Step: 8
Training loss: 0.44559225697758514
Validation loss: 2.9189098905215936

Epoch: 6| Step: 9
Training loss: 0.4278334411444613
Validation loss: 3.032357357724059

Epoch: 6| Step: 10
Training loss: 0.5852780000261463
Validation loss: 3.0041148787508543

Epoch: 6| Step: 11
Training loss: 0.4395685849570655
Validation loss: 2.9575141838251695

Epoch: 6| Step: 12
Training loss: 0.7306828312628837
Validation loss: 2.9933412749376984

Epoch: 6| Step: 13
Training loss: 0.7024649382899824
Validation loss: 2.957508487060442

Epoch: 275| Step: 0
Training loss: 0.4728819883406463
Validation loss: 2.9857844940486795

Epoch: 6| Step: 1
Training loss: 0.5408758540648172
Validation loss: 3.046475245669195

Epoch: 6| Step: 2
Training loss: 0.5617311043899429
Validation loss: 2.90343238946995

Epoch: 6| Step: 3
Training loss: 0.7098961633992611
Validation loss: 3.0266982836339316

Epoch: 6| Step: 4
Training loss: 0.6445161066299263
Validation loss: 2.956034483523931

Epoch: 6| Step: 5
Training loss: 0.5870183512468946
Validation loss: 2.922069849055424

Epoch: 6| Step: 6
Training loss: 0.46862433656476127
Validation loss: 3.0392939749906374

Epoch: 6| Step: 7
Training loss: 0.6352097586113977
Validation loss: 2.973595850421965

Epoch: 6| Step: 8
Training loss: 0.5514159637399803
Validation loss: 2.9732780056953323

Epoch: 6| Step: 9
Training loss: 1.5712658469676364
Validation loss: 2.9581730803663144

Epoch: 6| Step: 10
Training loss: 0.7133249292443077
Validation loss: 2.9721598534462546

Epoch: 6| Step: 11
Training loss: 0.6214390160907451
Validation loss: 2.9107968438197833

Epoch: 6| Step: 12
Training loss: 0.5421885366732226
Validation loss: 2.8919175840745934

Epoch: 6| Step: 13
Training loss: 0.5796399243514552
Validation loss: 2.983063014977133

Epoch: 276| Step: 0
Training loss: 0.4105648004191865
Validation loss: 2.993789363594332

Epoch: 6| Step: 1
Training loss: 0.9167922251859344
Validation loss: 2.9175725801576684

Epoch: 6| Step: 2
Training loss: 0.4182066195987074
Validation loss: 2.976421750029123

Epoch: 6| Step: 3
Training loss: 0.43733157594451744
Validation loss: 2.9493123222816164

Epoch: 6| Step: 4
Training loss: 0.5360663256389164
Validation loss: 2.8811988621915807

Epoch: 6| Step: 5
Training loss: 0.5459295001259948
Validation loss: 2.99253337245552

Epoch: 6| Step: 6
Training loss: 0.6258870267586766
Validation loss: 3.0932243234511163

Epoch: 6| Step: 7
Training loss: 0.46043533514618645
Validation loss: 2.9244127048040967

Epoch: 6| Step: 8
Training loss: 0.6732107015118983
Validation loss: 2.8913829462733447

Epoch: 6| Step: 9
Training loss: 0.6363389924621854
Validation loss: 3.033514704015417

Epoch: 6| Step: 10
Training loss: 0.5950136040086034
Validation loss: 2.9679610827063194

Epoch: 6| Step: 11
Training loss: 0.5976201464151331
Validation loss: 2.8810172896558783

Epoch: 6| Step: 12
Training loss: 1.6823158459259342
Validation loss: 2.956214479551579

Epoch: 6| Step: 13
Training loss: 0.6887284704052328
Validation loss: 2.9861268632064255

Epoch: 277| Step: 0
Training loss: 0.9672514184096903
Validation loss: 3.000884766710385

Epoch: 6| Step: 1
Training loss: 0.8367667318881757
Validation loss: 2.920182946823173

Epoch: 6| Step: 2
Training loss: 0.28526061251604984
Validation loss: 2.9757362213426823

Epoch: 6| Step: 3
Training loss: 0.5849243305450781
Validation loss: 3.053213585069851

Epoch: 6| Step: 4
Training loss: 0.4536448653510446
Validation loss: 3.0524636618606746

Epoch: 6| Step: 5
Training loss: 0.5378368375725312
Validation loss: 2.9494684581010953

Epoch: 6| Step: 6
Training loss: 1.5812305826193618
Validation loss: 3.021918007808578

Epoch: 6| Step: 7
Training loss: 0.37933213593537574
Validation loss: 3.0063216572956457

Epoch: 6| Step: 8
Training loss: 0.36467105854566906
Validation loss: 2.9672552662483787

Epoch: 6| Step: 9
Training loss: 0.5158541488093866
Validation loss: 3.0634686371937185

Epoch: 6| Step: 10
Training loss: 0.808983602850383
Validation loss: 2.918434796954126

Epoch: 6| Step: 11
Training loss: 0.6374523406819761
Validation loss: 2.96963901259009

Epoch: 6| Step: 12
Training loss: 0.7243512045874434
Validation loss: 2.936915116215749

Epoch: 6| Step: 13
Training loss: 0.40691354554355796
Validation loss: 3.0146895491195433

Epoch: 278| Step: 0
Training loss: 1.7446401122208683
Validation loss: 2.9287546529175303

Epoch: 6| Step: 1
Training loss: 0.3222564464764773
Validation loss: 2.9593058496470706

Epoch: 6| Step: 2
Training loss: 0.6892997419792078
Validation loss: 2.9983830465408468

Epoch: 6| Step: 3
Training loss: 0.47995454518347463
Validation loss: 2.9288761761792563

Epoch: 6| Step: 4
Training loss: 0.544002235488646
Validation loss: 3.002397804193874

Epoch: 6| Step: 5
Training loss: 0.6589721352933511
Validation loss: 2.986632659866098

Epoch: 6| Step: 6
Training loss: 0.6836468267271315
Validation loss: 3.0408424715249964

Epoch: 6| Step: 7
Training loss: 0.6417773048170771
Validation loss: 3.095398473339982

Epoch: 6| Step: 8
Training loss: 0.4651091002586733
Validation loss: 2.910855353099478

Epoch: 6| Step: 9
Training loss: 0.5390910265464953
Validation loss: 2.9934105826040875

Epoch: 6| Step: 10
Training loss: 0.6258465755431435
Validation loss: 2.97495656983547

Epoch: 6| Step: 11
Training loss: 0.5066269166102134
Validation loss: 2.9530620669163357

Epoch: 6| Step: 12
Training loss: 0.6167595985556343
Validation loss: 3.009570670575008

Epoch: 6| Step: 13
Training loss: 0.7920023474176857
Validation loss: 2.8967543630710058

Epoch: 279| Step: 0
Training loss: 0.8932619709778977
Validation loss: 2.950896389328911

Epoch: 6| Step: 1
Training loss: 0.4652344800563024
Validation loss: 2.9135263885617553

Epoch: 6| Step: 2
Training loss: 1.6058027750673307
Validation loss: 3.021256046754707

Epoch: 6| Step: 3
Training loss: 0.5671683610361539
Validation loss: 3.0015162768719326

Epoch: 6| Step: 4
Training loss: 0.5109646897853691
Validation loss: 2.975897633813852

Epoch: 6| Step: 5
Training loss: 0.6015423362622339
Validation loss: 2.9446267325477486

Epoch: 6| Step: 6
Training loss: 0.31736855108057715
Validation loss: 2.8919788248905833

Epoch: 6| Step: 7
Training loss: 0.4964491704889491
Validation loss: 2.950520249737342

Epoch: 6| Step: 8
Training loss: 0.48265879137945267
Validation loss: 2.936571407317461

Epoch: 6| Step: 9
Training loss: 0.4659296863036336
Validation loss: 3.00080219775609

Epoch: 6| Step: 10
Training loss: 0.6274743216226516
Validation loss: 2.975257433911365

Epoch: 6| Step: 11
Training loss: 0.7084165879483507
Validation loss: 2.946691889921032

Epoch: 6| Step: 12
Training loss: 0.6286850060302465
Validation loss: 2.9275245922173068

Epoch: 6| Step: 13
Training loss: 0.6570323186586741
Validation loss: 3.0187950009821662

Epoch: 280| Step: 0
Training loss: 0.4619451274466625
Validation loss: 2.985431410936539

Epoch: 6| Step: 1
Training loss: 0.46796669680952185
Validation loss: 2.8601113015860995

Epoch: 6| Step: 2
Training loss: 0.5950887544936406
Validation loss: 2.896625620818579

Epoch: 6| Step: 3
Training loss: 0.593171113556073
Validation loss: 2.901288394720491

Epoch: 6| Step: 4
Training loss: 1.6752264353727613
Validation loss: 2.9783380507602772

Epoch: 6| Step: 5
Training loss: 0.4911797212119938
Validation loss: 2.9530126425815553

Epoch: 6| Step: 6
Training loss: 0.3819886119428261
Validation loss: 2.9634565845113525

Epoch: 6| Step: 7
Training loss: 0.6670988787861653
Validation loss: 3.004233962075548

Epoch: 6| Step: 8
Training loss: 0.5814670926423726
Validation loss: 3.006215623644505

Epoch: 6| Step: 9
Training loss: 0.6885833873795694
Validation loss: 2.848088598375188

Epoch: 6| Step: 10
Training loss: 0.7253704752303521
Validation loss: 3.0151959181519685

Epoch: 6| Step: 11
Training loss: 0.5643907664347335
Validation loss: 2.8766988765803694

Epoch: 6| Step: 12
Training loss: 0.7312935237484565
Validation loss: 2.9880036268735677

Epoch: 6| Step: 13
Training loss: 0.7183079396721046
Validation loss: 2.950162151427679

Epoch: 281| Step: 0
Training loss: 0.4514413004386054
Validation loss: 2.9297433737619043

Epoch: 6| Step: 1
Training loss: 0.5718663876828262
Validation loss: 2.9396785206098492

Epoch: 6| Step: 2
Training loss: 0.8772611353252545
Validation loss: 2.8900990875487325

Epoch: 6| Step: 3
Training loss: 0.7744166793875237
Validation loss: 2.998926593223443

Epoch: 6| Step: 4
Training loss: 1.654698346816579
Validation loss: 2.966272357567594

Epoch: 6| Step: 5
Training loss: 0.38739888271654155
Validation loss: 2.9023776764767195

Epoch: 6| Step: 6
Training loss: 0.422944567453743
Validation loss: 2.9795447334183045

Epoch: 6| Step: 7
Training loss: 0.6265146974512541
Validation loss: 2.9841811298558536

Epoch: 6| Step: 8
Training loss: 0.4946615466299946
Validation loss: 2.9571977952277204

Epoch: 6| Step: 9
Training loss: 0.5866238960566234
Validation loss: 2.983586232070261

Epoch: 6| Step: 10
Training loss: 0.6071771208327092
Validation loss: 2.9393952120021747

Epoch: 6| Step: 11
Training loss: 0.7558542492912041
Validation loss: 2.953129749866144

Epoch: 6| Step: 12
Training loss: 0.49327584689941834
Validation loss: 3.023580661114727

Epoch: 6| Step: 13
Training loss: 0.7387124875996292
Validation loss: 3.068158456176114

Epoch: 282| Step: 0
Training loss: 1.575232016413086
Validation loss: 2.986475074134815

Epoch: 6| Step: 1
Training loss: 0.5868661261101938
Validation loss: 2.9550161479158037

Epoch: 6| Step: 2
Training loss: 0.5736973270015541
Validation loss: 2.874204691473798

Epoch: 6| Step: 3
Training loss: 0.5393292416714822
Validation loss: 2.983071433635439

Epoch: 6| Step: 4
Training loss: 0.4286529571324409
Validation loss: 2.9855828362534758

Epoch: 6| Step: 5
Training loss: 0.6797454195446986
Validation loss: 2.9332304288052504

Epoch: 6| Step: 6
Training loss: 0.7707722527987818
Validation loss: 2.925774676557897

Epoch: 6| Step: 7
Training loss: 0.35608217736956826
Validation loss: 2.983683920529305

Epoch: 6| Step: 8
Training loss: 0.5373035981400546
Validation loss: 2.9161741022446614

Epoch: 6| Step: 9
Training loss: 0.5758238695124198
Validation loss: 2.907704239021734

Epoch: 6| Step: 10
Training loss: 0.5110158387769664
Validation loss: 2.927578790257556

Epoch: 6| Step: 11
Training loss: 0.4749444163577242
Validation loss: 2.945564468358633

Epoch: 6| Step: 12
Training loss: 0.5067842490239277
Validation loss: 2.894516245141994

Epoch: 6| Step: 13
Training loss: 0.6837009672823987
Validation loss: 2.9858732873016316

Epoch: 283| Step: 0
Training loss: 0.6296341042798532
Validation loss: 2.9941511890136265

Epoch: 6| Step: 1
Training loss: 0.4141402981203981
Validation loss: 3.030021838160882

Epoch: 6| Step: 2
Training loss: 0.6188834104342094
Validation loss: 2.9530644149889786

Epoch: 6| Step: 3
Training loss: 0.49348466479853953
Validation loss: 2.914010505110133

Epoch: 6| Step: 4
Training loss: 1.6076048217342342
Validation loss: 2.9940904985127457

Epoch: 6| Step: 5
Training loss: 0.47902281993112866
Validation loss: 2.995499294547716

Epoch: 6| Step: 6
Training loss: 0.5130231118191954
Validation loss: 2.9732307884754405

Epoch: 6| Step: 7
Training loss: 0.6153177356255052
Validation loss: 3.1115660240217493

Epoch: 6| Step: 8
Training loss: 0.45856084559343513
Validation loss: 2.9159090329664887

Epoch: 6| Step: 9
Training loss: 0.6237403334898707
Validation loss: 2.986381934450221

Epoch: 6| Step: 10
Training loss: 0.7721157146511255
Validation loss: 2.9526437572481363

Epoch: 6| Step: 11
Training loss: 0.5624825951744563
Validation loss: 3.030037004740057

Epoch: 6| Step: 12
Training loss: 0.40032013063208344
Validation loss: 2.9891453775527443

Epoch: 6| Step: 13
Training loss: 0.4334578086204229
Validation loss: 2.898225486932278

Epoch: 284| Step: 0
Training loss: 0.7810694676665596
Validation loss: 2.901069535966804

Epoch: 6| Step: 1
Training loss: 0.6807543832845849
Validation loss: 3.0230197404306725

Epoch: 6| Step: 2
Training loss: 0.6862657478485098
Validation loss: 2.9905812705738297

Epoch: 6| Step: 3
Training loss: 0.5245344425180396
Validation loss: 2.9523933890332743

Epoch: 6| Step: 4
Training loss: 0.5478275178198889
Validation loss: 2.9665363156331006

Epoch: 6| Step: 5
Training loss: 0.6397764121592711
Validation loss: 2.925446311613212

Epoch: 6| Step: 6
Training loss: 0.5521506202527768
Validation loss: 2.9618480292242895

Epoch: 6| Step: 7
Training loss: 0.5056650090273194
Validation loss: 2.949287545115463

Epoch: 6| Step: 8
Training loss: 1.635178890882581
Validation loss: 2.9536935033680773

Epoch: 6| Step: 9
Training loss: 0.6408856024671459
Validation loss: 2.953031467793261

Epoch: 6| Step: 10
Training loss: 0.7442338539655582
Validation loss: 3.0265492305225115

Epoch: 6| Step: 11
Training loss: 0.48986787508460045
Validation loss: 2.876573740039134

Epoch: 6| Step: 12
Training loss: 0.5386663169657089
Validation loss: 2.9201806335449048

Epoch: 6| Step: 13
Training loss: 0.46685458668480767
Validation loss: 3.035837889807611

Epoch: 285| Step: 0
Training loss: 0.60665838211904
Validation loss: 2.920233552728633

Epoch: 6| Step: 1
Training loss: 0.841749574965349
Validation loss: 2.9132977829676565

Epoch: 6| Step: 2
Training loss: 0.5241461838640532
Validation loss: 2.9002958305786017

Epoch: 6| Step: 3
Training loss: 0.5528331708736294
Validation loss: 2.930098698898983

Epoch: 6| Step: 4
Training loss: 1.7046212439593922
Validation loss: 2.9744785118914985

Epoch: 6| Step: 5
Training loss: 0.5417368244317005
Validation loss: 2.9096988053898216

Epoch: 6| Step: 6
Training loss: 0.6209463268434016
Validation loss: 2.938493006178373

Epoch: 6| Step: 7
Training loss: 0.5472291344750958
Validation loss: 2.970020169704464

Epoch: 6| Step: 8
Training loss: 0.703200251473077
Validation loss: 2.9845844614709445

Epoch: 6| Step: 9
Training loss: 0.6847749368890751
Validation loss: 3.0385757749515605

Epoch: 6| Step: 10
Training loss: 0.5719724561688655
Validation loss: 2.953994797808131

Epoch: 6| Step: 11
Training loss: 0.578928131843125
Validation loss: 2.9441889838495685

Epoch: 6| Step: 12
Training loss: 0.44501910666905287
Validation loss: 2.9725078691100864

Epoch: 6| Step: 13
Training loss: 0.4093428766590904
Validation loss: 2.912447961934489

Epoch: 286| Step: 0
Training loss: 0.663873712968306
Validation loss: 2.901596281135391

Epoch: 6| Step: 1
Training loss: 0.5181694827064091
Validation loss: 2.9423771944782633

Epoch: 6| Step: 2
Training loss: 1.6494595220432082
Validation loss: 2.98109532774083

Epoch: 6| Step: 3
Training loss: 0.726749273104939
Validation loss: 2.871802902008495

Epoch: 6| Step: 4
Training loss: 0.7763759780482093
Validation loss: 2.9695238543689904

Epoch: 6| Step: 5
Training loss: 0.4083827595412885
Validation loss: 2.989612357677677

Epoch: 6| Step: 6
Training loss: 0.5901802063377858
Validation loss: 2.8943050568988293

Epoch: 6| Step: 7
Training loss: 0.6698416614611139
Validation loss: 2.978782353366219

Epoch: 6| Step: 8
Training loss: 0.46878563427583464
Validation loss: 3.0463006285168848

Epoch: 6| Step: 9
Training loss: 0.4447810699606184
Validation loss: 3.0040712546877057

Epoch: 6| Step: 10
Training loss: 0.4248570026324315
Validation loss: 3.080250917634202

Epoch: 6| Step: 11
Training loss: 0.5913239657406582
Validation loss: 2.977692810806714

Epoch: 6| Step: 12
Training loss: 0.7348910202924941
Validation loss: 2.977995693499148

Epoch: 6| Step: 13
Training loss: 0.43687283317563386
Validation loss: 2.990203119733779

Epoch: 287| Step: 0
Training loss: 0.5752455943592504
Validation loss: 2.897879698513217

Epoch: 6| Step: 1
Training loss: 0.47047089352304705
Validation loss: 2.936371647445118

Epoch: 6| Step: 2
Training loss: 0.45552072571983554
Validation loss: 3.0184484911737384

Epoch: 6| Step: 3
Training loss: 0.6455133527324654
Validation loss: 2.864341938367085

Epoch: 6| Step: 4
Training loss: 0.705452267611606
Validation loss: 2.8969900899148513

Epoch: 6| Step: 5
Training loss: 0.4430167937421587
Validation loss: 2.954937978826242

Epoch: 6| Step: 6
Training loss: 0.603749671169847
Validation loss: 2.991431888693946

Epoch: 6| Step: 7
Training loss: 0.45978839334977173
Validation loss: 2.9465653430411063

Epoch: 6| Step: 8
Training loss: 0.38635304045682317
Validation loss: 2.993122535736945

Epoch: 6| Step: 9
Training loss: 0.409291800569263
Validation loss: 3.0161205536833564

Epoch: 6| Step: 10
Training loss: 1.5846370382517467
Validation loss: 3.002135642498466

Epoch: 6| Step: 11
Training loss: 0.5911043351405678
Validation loss: 2.9267398773007005

Epoch: 6| Step: 12
Training loss: 0.5332453784339962
Validation loss: 2.975444393465922

Epoch: 6| Step: 13
Training loss: 0.6201815354009376
Validation loss: 3.002669696252705

Epoch: 288| Step: 0
Training loss: 0.5071503063015567
Validation loss: 2.9030806443268693

Epoch: 6| Step: 1
Training loss: 0.37304985085144254
Validation loss: 2.9436650074259485

Epoch: 6| Step: 2
Training loss: 0.6622363618589094
Validation loss: 2.9587506595380377

Epoch: 6| Step: 3
Training loss: 0.8327978837840175
Validation loss: 2.993338221699632

Epoch: 6| Step: 4
Training loss: 0.7076370425996247
Validation loss: 3.0771134420035446

Epoch: 6| Step: 5
Training loss: 0.681138605232194
Validation loss: 2.923141857634476

Epoch: 6| Step: 6
Training loss: 0.4789528386914096
Validation loss: 2.917462217734057

Epoch: 6| Step: 7
Training loss: 0.3669217954227066
Validation loss: 2.953022815477123

Epoch: 6| Step: 8
Training loss: 1.5834881890846875
Validation loss: 2.905776474088909

Epoch: 6| Step: 9
Training loss: 0.5306890274706952
Validation loss: 2.952451894972804

Epoch: 6| Step: 10
Training loss: 0.4028420186972129
Validation loss: 2.953211505571522

Epoch: 6| Step: 11
Training loss: 0.699208136962817
Validation loss: 2.8982712251554035

Epoch: 6| Step: 12
Training loss: 0.6047689516079252
Validation loss: 2.9024417633032122

Epoch: 6| Step: 13
Training loss: 0.5178800170290799
Validation loss: 2.99497242699924

Epoch: 289| Step: 0
Training loss: 1.6133468651532457
Validation loss: 2.953085359176115

Epoch: 6| Step: 1
Training loss: 0.523705655772197
Validation loss: 2.95813080716767

Epoch: 6| Step: 2
Training loss: 0.5472899633709507
Validation loss: 2.987234240513204

Epoch: 6| Step: 3
Training loss: 0.42268237810586623
Validation loss: 2.939298241675839

Epoch: 6| Step: 4
Training loss: 0.5035761557833515
Validation loss: 3.015552289280551

Epoch: 6| Step: 5
Training loss: 0.6751604260432686
Validation loss: 2.9697742100825546

Epoch: 6| Step: 6
Training loss: 0.6649038258539871
Validation loss: 2.9700039273374133

Epoch: 6| Step: 7
Training loss: 0.5153042055460675
Validation loss: 2.960878826220965

Epoch: 6| Step: 8
Training loss: 0.4807649490275818
Validation loss: 2.9690605268868993

Epoch: 6| Step: 9
Training loss: 0.6043369420484402
Validation loss: 2.838283496746949

Epoch: 6| Step: 10
Training loss: 0.6468379042304282
Validation loss: 2.9766404349469524

Epoch: 6| Step: 11
Training loss: 0.8299098304234342
Validation loss: 2.907060503314829

Epoch: 6| Step: 12
Training loss: 0.6648076532877036
Validation loss: 2.9188452327311967

Epoch: 6| Step: 13
Training loss: 0.5038807588975435
Validation loss: 3.0350791630064853

Epoch: 290| Step: 0
Training loss: 0.4775091368614941
Validation loss: 3.0049519729796255

Epoch: 6| Step: 1
Training loss: 0.5093298617062832
Validation loss: 2.94712323316066

Epoch: 6| Step: 2
Training loss: 0.5995878781121456
Validation loss: 3.102683914352474

Epoch: 6| Step: 3
Training loss: 0.739900297201308
Validation loss: 3.083536944668696

Epoch: 6| Step: 4
Training loss: 0.390835285805473
Validation loss: 2.991837151503629

Epoch: 6| Step: 5
Training loss: 1.6122308964886294
Validation loss: 2.9459418476914743

Epoch: 6| Step: 6
Training loss: 0.4508255789660456
Validation loss: 2.887256164493994

Epoch: 6| Step: 7
Training loss: 0.6852073154536622
Validation loss: 2.982899778889947

Epoch: 6| Step: 8
Training loss: 0.5148324944940174
Validation loss: 2.9496946376150133

Epoch: 6| Step: 9
Training loss: 0.6953669323135194
Validation loss: 2.9263083403761674

Epoch: 6| Step: 10
Training loss: 0.8899603923813854
Validation loss: 2.8662470939300975

Epoch: 6| Step: 11
Training loss: 0.7009060921777467
Validation loss: 2.871313122177408

Epoch: 6| Step: 12
Training loss: 0.4735794194594696
Validation loss: 2.876377563499292

Epoch: 6| Step: 13
Training loss: 0.40974716494046687
Validation loss: 3.0099101756983546

Epoch: 291| Step: 0
Training loss: 0.49967651035422017
Validation loss: 2.9628414182656906

Epoch: 6| Step: 1
Training loss: 0.737055694776386
Validation loss: 3.0661835348641886

Epoch: 6| Step: 2
Training loss: 0.3916418953765957
Validation loss: 3.0827067400061186

Epoch: 6| Step: 3
Training loss: 0.6199601102117653
Validation loss: 3.020784342576825

Epoch: 6| Step: 4
Training loss: 0.658422914478339
Validation loss: 3.0046599806254215

Epoch: 6| Step: 5
Training loss: 0.5162254363213012
Validation loss: 3.031165393815305

Epoch: 6| Step: 6
Training loss: 0.5274682922234734
Validation loss: 2.977105679349187

Epoch: 6| Step: 7
Training loss: 0.49873419813110387
Validation loss: 2.8996817633430303

Epoch: 6| Step: 8
Training loss: 0.4964958123571196
Validation loss: 2.9112164983245377

Epoch: 6| Step: 9
Training loss: 0.6324189457581078
Validation loss: 2.972683385523802

Epoch: 6| Step: 10
Training loss: 0.9679151136856878
Validation loss: 2.9098210698597695

Epoch: 6| Step: 11
Training loss: 1.627095412023487
Validation loss: 2.9008939261401574

Epoch: 6| Step: 12
Training loss: 0.46251684299936346
Validation loss: 2.927626825197565

Epoch: 6| Step: 13
Training loss: 0.5267132415981365
Validation loss: 3.0025031587540156

Epoch: 292| Step: 0
Training loss: 0.4758090332137454
Validation loss: 3.089332637960756

Epoch: 6| Step: 1
Training loss: 0.4013718096613132
Validation loss: 2.9953343217665416

Epoch: 6| Step: 2
Training loss: 0.5359287394705681
Validation loss: 3.0046245640435143

Epoch: 6| Step: 3
Training loss: 0.43281597108516356
Validation loss: 2.9920257312149303

Epoch: 6| Step: 4
Training loss: 0.5033005615432854
Validation loss: 3.008461688113417

Epoch: 6| Step: 5
Training loss: 0.4162358162442326
Validation loss: 3.048684898203776

Epoch: 6| Step: 6
Training loss: 0.6564747107749036
Validation loss: 2.8802335345986267

Epoch: 6| Step: 7
Training loss: 1.5952633423288376
Validation loss: 2.9331900720580633

Epoch: 6| Step: 8
Training loss: 0.670886754540858
Validation loss: 2.90839461359501

Epoch: 6| Step: 9
Training loss: 0.6949476506393927
Validation loss: 2.9763329685250977

Epoch: 6| Step: 10
Training loss: 0.40104075427591485
Validation loss: 2.8967994386543023

Epoch: 6| Step: 11
Training loss: 0.4620484364331526
Validation loss: 2.9699629597864106

Epoch: 6| Step: 12
Training loss: 0.7650761875535897
Validation loss: 2.9406420224460885

Epoch: 6| Step: 13
Training loss: 0.6315676135611641
Validation loss: 2.985979404551328

Epoch: 293| Step: 0
Training loss: 0.38936357913098735
Validation loss: 2.927670122476031

Epoch: 6| Step: 1
Training loss: 0.448341624547853
Validation loss: 2.950276206712235

Epoch: 6| Step: 2
Training loss: 0.5705983216482644
Validation loss: 2.944462728643528

Epoch: 6| Step: 3
Training loss: 0.5953238358507182
Validation loss: 2.935439665582217

Epoch: 6| Step: 4
Training loss: 1.6840816773203817
Validation loss: 3.0006075879580822

Epoch: 6| Step: 5
Training loss: 0.45737649642019795
Validation loss: 2.976019141397138

Epoch: 6| Step: 6
Training loss: 0.5356534611141037
Validation loss: 2.9429597640299083

Epoch: 6| Step: 7
Training loss: 0.6361940714568584
Validation loss: 2.934204579781641

Epoch: 6| Step: 8
Training loss: 0.5113558756595831
Validation loss: 2.83315849232227

Epoch: 6| Step: 9
Training loss: 0.800622431194821
Validation loss: 3.060114184225093

Epoch: 6| Step: 10
Training loss: 0.448692726980504
Validation loss: 2.8914507399603453

Epoch: 6| Step: 11
Training loss: 0.624435408212157
Validation loss: 2.9498573538134156

Epoch: 6| Step: 12
Training loss: 0.6940190790052094
Validation loss: 2.935862619183755

Epoch: 6| Step: 13
Training loss: 0.44767827151259837
Validation loss: 2.998567702855921

Epoch: 294| Step: 0
Training loss: 0.5394471772437123
Validation loss: 2.9837993446108513

Epoch: 6| Step: 1
Training loss: 0.4557950671550055
Validation loss: 2.952102268744245

Epoch: 6| Step: 2
Training loss: 0.7692379852561677
Validation loss: 2.881486789464579

Epoch: 6| Step: 3
Training loss: 0.47325931255167647
Validation loss: 2.939387208995842

Epoch: 6| Step: 4
Training loss: 0.5253275439884153
Validation loss: 2.902960963657024

Epoch: 6| Step: 5
Training loss: 0.306176459961182
Validation loss: 2.9744634828380563

Epoch: 6| Step: 6
Training loss: 0.31744025077461663
Validation loss: 2.914705875339215

Epoch: 6| Step: 7
Training loss: 0.5821666688002616
Validation loss: 2.897200355516351

Epoch: 6| Step: 8
Training loss: 1.5476375203200419
Validation loss: 3.026344918809918

Epoch: 6| Step: 9
Training loss: 0.5820583362805215
Validation loss: 2.9345187622214084

Epoch: 6| Step: 10
Training loss: 0.4699697360734775
Validation loss: 2.9885610611504445

Epoch: 6| Step: 11
Training loss: 0.7919430793937171
Validation loss: 2.8950882417388644

Epoch: 6| Step: 12
Training loss: 0.5278122128022283
Validation loss: 2.987016889915397

Epoch: 6| Step: 13
Training loss: 0.380694622694015
Validation loss: 2.964010464150014

Epoch: 295| Step: 0
Training loss: 0.5286408754564136
Validation loss: 2.852195551029747

Epoch: 6| Step: 1
Training loss: 0.49961746006464136
Validation loss: 2.972526169820262

Epoch: 6| Step: 2
Training loss: 0.44182237910715744
Validation loss: 2.9393480858776138

Epoch: 6| Step: 3
Training loss: 0.6065340084752397
Validation loss: 2.87553041513306

Epoch: 6| Step: 4
Training loss: 0.5771013424630514
Validation loss: 2.897356433224511

Epoch: 6| Step: 5
Training loss: 0.3477414487531926
Validation loss: 2.9906197367495277

Epoch: 6| Step: 6
Training loss: 0.6182679003242446
Validation loss: 3.052082704060113

Epoch: 6| Step: 7
Training loss: 0.5086977065764123
Validation loss: 2.9608700223697215

Epoch: 6| Step: 8
Training loss: 0.6610615183312729
Validation loss: 2.956597427803212

Epoch: 6| Step: 9
Training loss: 0.6575532869132833
Validation loss: 2.896549593670745

Epoch: 6| Step: 10
Training loss: 0.40201490351939756
Validation loss: 2.9631811547297344

Epoch: 6| Step: 11
Training loss: 1.5545767739896372
Validation loss: 2.9147760848758857

Epoch: 6| Step: 12
Training loss: 0.5318118938568567
Validation loss: 3.025251161641557

Epoch: 6| Step: 13
Training loss: 0.5505240901921661
Validation loss: 2.9506414421909266

Epoch: 296| Step: 0
Training loss: 1.5091725278783032
Validation loss: 3.0089513430960677

Epoch: 6| Step: 1
Training loss: 0.520450896681549
Validation loss: 2.9247687115205343

Epoch: 6| Step: 2
Training loss: 0.6055679240067005
Validation loss: 3.0307307503217507

Epoch: 6| Step: 3
Training loss: 0.6260364283650924
Validation loss: 3.0818331178929115

Epoch: 6| Step: 4
Training loss: 0.4936321039323792
Validation loss: 3.083003971619862

Epoch: 6| Step: 5
Training loss: 0.6745198776350355
Validation loss: 2.9976912595102854

Epoch: 6| Step: 6
Training loss: 0.6287054843197998
Validation loss: 2.9935992490313503

Epoch: 6| Step: 7
Training loss: 0.5208696034835978
Validation loss: 3.014307686401296

Epoch: 6| Step: 8
Training loss: 0.5272447846409302
Validation loss: 2.958839780592005

Epoch: 6| Step: 9
Training loss: 0.4686661963254722
Validation loss: 3.04512706731582

Epoch: 6| Step: 10
Training loss: 0.702157138563634
Validation loss: 2.8989509340265616

Epoch: 6| Step: 11
Training loss: 0.35401710222576444
Validation loss: 2.931594024836785

Epoch: 6| Step: 12
Training loss: 0.7942568084645912
Validation loss: 2.9005926847448977

Epoch: 6| Step: 13
Training loss: 0.6800461184766496
Validation loss: 3.0417941515260325

Epoch: 297| Step: 0
Training loss: 0.5172100269678446
Validation loss: 2.9909062045078945

Epoch: 6| Step: 1
Training loss: 0.6185027967681191
Validation loss: 2.969264832411232

Epoch: 6| Step: 2
Training loss: 0.706033793413289
Validation loss: 3.0414510589546757

Epoch: 6| Step: 3
Training loss: 0.5415600953045973
Validation loss: 2.9313764662800557

Epoch: 6| Step: 4
Training loss: 0.8443498598389705
Validation loss: 3.054480712343499

Epoch: 6| Step: 5
Training loss: 0.3858490035491194
Validation loss: 2.917845873647799

Epoch: 6| Step: 6
Training loss: 0.6145283356536113
Validation loss: 3.0335902589065147

Epoch: 6| Step: 7
Training loss: 0.501036642238409
Validation loss: 2.9925852910387434

Epoch: 6| Step: 8
Training loss: 0.3805678596889746
Validation loss: 2.9611848108886534

Epoch: 6| Step: 9
Training loss: 0.4565496270821285
Validation loss: 2.9596107751525658

Epoch: 6| Step: 10
Training loss: 1.5894203465781023
Validation loss: 2.995618561185224

Epoch: 6| Step: 11
Training loss: 0.8116030510549411
Validation loss: 2.8581432197746945

Epoch: 6| Step: 12
Training loss: 0.3988517963434965
Validation loss: 2.944946981426678

Epoch: 6| Step: 13
Training loss: 0.5288116652240122
Validation loss: 3.101274862972641

Epoch: 298| Step: 0
Training loss: 0.5054073302320473
Validation loss: 2.9749663337704626

Epoch: 6| Step: 1
Training loss: 0.25836518319484575
Validation loss: 3.041891290043533

Epoch: 6| Step: 2
Training loss: 1.5303139452998522
Validation loss: 2.977773571861517

Epoch: 6| Step: 3
Training loss: 0.6862602543368735
Validation loss: 2.942682159217402

Epoch: 6| Step: 4
Training loss: 0.46809459006897985
Validation loss: 2.856106639466859

Epoch: 6| Step: 5
Training loss: 0.747705725425012
Validation loss: 3.021702310387325

Epoch: 6| Step: 6
Training loss: 0.38275529472954556
Validation loss: 3.013090527958504

Epoch: 6| Step: 7
Training loss: 0.5431544583214635
Validation loss: 2.940435376811618

Epoch: 6| Step: 8
Training loss: 0.6522705585285391
Validation loss: 2.9325863886014187

Epoch: 6| Step: 9
Training loss: 0.43643754288980335
Validation loss: 2.975975586172342

Epoch: 6| Step: 10
Training loss: 0.3533773415227821
Validation loss: 3.0385156186809135

Epoch: 6| Step: 11
Training loss: 0.36953595099977277
Validation loss: 2.9748820102492095

Epoch: 6| Step: 12
Training loss: 0.7076675333954218
Validation loss: 3.0038288108126894

Epoch: 6| Step: 13
Training loss: 0.47262746549869755
Validation loss: 3.0675625510083337

Epoch: 299| Step: 0
Training loss: 0.46783230277775695
Validation loss: 2.941298281447214

Epoch: 6| Step: 1
Training loss: 0.4539596171694291
Validation loss: 2.985969477012678

Epoch: 6| Step: 2
Training loss: 1.6155027745422887
Validation loss: 2.9958340409180324

Epoch: 6| Step: 3
Training loss: 0.3970868649013795
Validation loss: 2.986897665617491

Epoch: 6| Step: 4
Training loss: 0.42009000739045305
Validation loss: 2.910269811407216

Epoch: 6| Step: 5
Training loss: 0.5514711428620784
Validation loss: 2.9124330493834028

Epoch: 6| Step: 6
Training loss: 0.43845912839218154
Validation loss: 2.963486070340499

Epoch: 6| Step: 7
Training loss: 0.4479077489837537
Validation loss: 2.9172497348177777

Epoch: 6| Step: 8
Training loss: 0.7382305874673369
Validation loss: 2.975222615586874

Epoch: 6| Step: 9
Training loss: 0.5287561223282116
Validation loss: 2.934594848327129

Epoch: 6| Step: 10
Training loss: 0.6353502134583789
Validation loss: 2.938321857599477

Epoch: 6| Step: 11
Training loss: 0.5119725246005064
Validation loss: 3.054318535026991

Epoch: 6| Step: 12
Training loss: 0.7263708374555379
Validation loss: 2.9541938098975105

Epoch: 6| Step: 13
Training loss: 0.6094207746479519
Validation loss: 3.010204213091371

Epoch: 300| Step: 0
Training loss: 0.4060622111362477
Validation loss: 2.9640990248812473

Epoch: 6| Step: 1
Training loss: 0.5297722458914406
Validation loss: 2.961259379878606

Epoch: 6| Step: 2
Training loss: 0.34555204506201165
Validation loss: 2.947600753265794

Epoch: 6| Step: 3
Training loss: 0.4524166391050272
Validation loss: 2.9292504963787716

Epoch: 6| Step: 4
Training loss: 0.2897245455020161
Validation loss: 2.8845675948659246

Epoch: 6| Step: 5
Training loss: 0.6012655491315243
Validation loss: 2.9140970400211232

Epoch: 6| Step: 6
Training loss: 0.41442831542230757
Validation loss: 2.995789354520597

Epoch: 6| Step: 7
Training loss: 0.5625832019307186
Validation loss: 2.9611472975619395

Epoch: 6| Step: 8
Training loss: 1.6347759068757082
Validation loss: 2.9931615401107505

Epoch: 6| Step: 9
Training loss: 0.7168595704976581
Validation loss: 2.968649357210769

Epoch: 6| Step: 10
Training loss: 0.5079394548617203
Validation loss: 2.8817442143958187

Epoch: 6| Step: 11
Training loss: 0.4833329744036208
Validation loss: 3.0106686989287734

Epoch: 6| Step: 12
Training loss: 0.7067493277088769
Validation loss: 2.9169918878072187

Epoch: 6| Step: 13
Training loss: 0.35157259820634323
Validation loss: 2.937434473050865

Epoch: 301| Step: 0
Training loss: 0.4180254318449524
Validation loss: 3.004581304463169

Epoch: 6| Step: 1
Training loss: 0.655704135028157
Validation loss: 2.9712211630383027

Epoch: 6| Step: 2
Training loss: 0.4885955714383041
Validation loss: 3.013703677985547

Epoch: 6| Step: 3
Training loss: 0.516725723547145
Validation loss: 2.9054432231113014

Epoch: 6| Step: 4
Training loss: 0.36509216314256804
Validation loss: 2.944086239476807

Epoch: 6| Step: 5
Training loss: 1.4822218688416016
Validation loss: 2.940493904459019

Epoch: 6| Step: 6
Training loss: 0.4110343978414429
Validation loss: 3.025315325041875

Epoch: 6| Step: 7
Training loss: 0.8363042722006081
Validation loss: 2.8874023619158393

Epoch: 6| Step: 8
Training loss: 0.5675353536222746
Validation loss: 2.9610922310827466

Epoch: 6| Step: 9
Training loss: 0.48169910481175543
Validation loss: 2.9826864954966164

Epoch: 6| Step: 10
Training loss: 0.4265267730954184
Validation loss: 2.93456513990982

Epoch: 6| Step: 11
Training loss: 0.4574228386091056
Validation loss: 3.00233759141989

Epoch: 6| Step: 12
Training loss: 0.6555668135752124
Validation loss: 3.0426280623028337

Epoch: 6| Step: 13
Training loss: 0.4835078722451982
Validation loss: 3.095729066437213

Epoch: 302| Step: 0
Training loss: 0.6290176008700271
Validation loss: 2.9371367831937794

Epoch: 6| Step: 1
Training loss: 0.698847965408751
Validation loss: 2.993017640922263

Epoch: 6| Step: 2
Training loss: 0.37592289529211104
Validation loss: 2.9214825426117956

Epoch: 6| Step: 3
Training loss: 1.5426321700736039
Validation loss: 3.003901818532201

Epoch: 6| Step: 4
Training loss: 0.4949212222557912
Validation loss: 2.9970387042498

Epoch: 6| Step: 5
Training loss: 0.3750268608645707
Validation loss: 2.8967665716823023

Epoch: 6| Step: 6
Training loss: 0.5429755560359183
Validation loss: 3.074283145163859

Epoch: 6| Step: 7
Training loss: 0.4540388494686975
Validation loss: 2.9565862188895453

Epoch: 6| Step: 8
Training loss: 0.6171736896756409
Validation loss: 2.924070923670017

Epoch: 6| Step: 9
Training loss: 0.5919745402032554
Validation loss: 2.9827093099546467

Epoch: 6| Step: 10
Training loss: 0.4676580266794498
Validation loss: 2.9756425852777757

Epoch: 6| Step: 11
Training loss: 0.5293288555548413
Validation loss: 2.9220112923506845

Epoch: 6| Step: 12
Training loss: 0.5917554784214171
Validation loss: 2.9149947597048698

Epoch: 6| Step: 13
Training loss: 0.6599186802747569
Validation loss: 2.9550532213679923

Epoch: 303| Step: 0
Training loss: 0.5828130195349457
Validation loss: 2.893361942095618

Epoch: 6| Step: 1
Training loss: 0.46683664830801436
Validation loss: 2.9080015667303765

Epoch: 6| Step: 2
Training loss: 0.5823151069067692
Validation loss: 2.900851167534333

Epoch: 6| Step: 3
Training loss: 0.7050045112370837
Validation loss: 2.991925552628527

Epoch: 6| Step: 4
Training loss: 0.47874438987213774
Validation loss: 2.99664420948659

Epoch: 6| Step: 5
Training loss: 0.4713986430251393
Validation loss: 3.0086068033486466

Epoch: 6| Step: 6
Training loss: 0.7133413066002476
Validation loss: 3.034193700474226

Epoch: 6| Step: 7
Training loss: 0.5507855787174756
Validation loss: 2.8493821818523486

Epoch: 6| Step: 8
Training loss: 0.4434142225848505
Validation loss: 2.984308804615065

Epoch: 6| Step: 9
Training loss: 0.39334301426795143
Validation loss: 3.0194547116283337

Epoch: 6| Step: 10
Training loss: 0.5107791515271061
Validation loss: 2.9452006270717135

Epoch: 6| Step: 11
Training loss: 1.5387747248654975
Validation loss: 2.959306601593609

Epoch: 6| Step: 12
Training loss: 0.502916176623738
Validation loss: 3.0166583357918992

Epoch: 6| Step: 13
Training loss: 0.5719353565821619
Validation loss: 3.0032572679769634

Epoch: 304| Step: 0
Training loss: 0.3693333682692565
Validation loss: 2.9526448877128124

Epoch: 6| Step: 1
Training loss: 0.6037850874030632
Validation loss: 2.948658129899721

Epoch: 6| Step: 2
Training loss: 0.6320796537784642
Validation loss: 2.985844421799093

Epoch: 6| Step: 3
Training loss: 1.6197372460090584
Validation loss: 2.859541827339776

Epoch: 6| Step: 4
Training loss: 0.4342975403310034
Validation loss: 2.996811841631344

Epoch: 6| Step: 5
Training loss: 0.5162606800258501
Validation loss: 2.9291961800475295

Epoch: 6| Step: 6
Training loss: 0.4705721882777724
Validation loss: 2.87172491700496

Epoch: 6| Step: 7
Training loss: 0.5397600277406056
Validation loss: 2.9647823389366907

Epoch: 6| Step: 8
Training loss: 0.773690230567749
Validation loss: 2.9597478269864466

Epoch: 6| Step: 9
Training loss: 0.66952396063915
Validation loss: 2.8921655622131506

Epoch: 6| Step: 10
Training loss: 0.36980600284492793
Validation loss: 2.870316173071424

Epoch: 6| Step: 11
Training loss: 0.4338612976800958
Validation loss: 3.0333112020698265

Epoch: 6| Step: 12
Training loss: 0.5857421549370615
Validation loss: 3.0014912289854516

Epoch: 6| Step: 13
Training loss: 0.29718889406601284
Validation loss: 3.003160427915283

Epoch: 305| Step: 0
Training loss: 0.4327499151598904
Validation loss: 2.930568104958645

Epoch: 6| Step: 1
Training loss: 0.4593032054202075
Validation loss: 2.976300873025894

Epoch: 6| Step: 2
Training loss: 0.6547004252320962
Validation loss: 2.955889193646296

Epoch: 6| Step: 3
Training loss: 0.5360484517193511
Validation loss: 2.9248342233396682

Epoch: 6| Step: 4
Training loss: 0.5095422774323255
Validation loss: 2.9995204621749094

Epoch: 6| Step: 5
Training loss: 1.507249717242894
Validation loss: 2.9705008045583483

Epoch: 6| Step: 6
Training loss: 0.7455365561944729
Validation loss: 2.9614845515345274

Epoch: 6| Step: 7
Training loss: 0.6191555947982024
Validation loss: 2.9878130510676346

Epoch: 6| Step: 8
Training loss: 0.3699832160467908
Validation loss: 2.878797386730196

Epoch: 6| Step: 9
Training loss: 0.5567203397725479
Validation loss: 2.9595154204953174

Epoch: 6| Step: 10
Training loss: 0.3674997463030815
Validation loss: 2.9908848675184974

Epoch: 6| Step: 11
Training loss: 0.6862828143669861
Validation loss: 3.0054588852513824

Epoch: 6| Step: 12
Training loss: 0.4760348416207149
Validation loss: 2.9413634521288814

Epoch: 6| Step: 13
Training loss: 0.5714758934283356
Validation loss: 2.8889540920683547

Epoch: 306| Step: 0
Training loss: 0.4334658872388694
Validation loss: 2.9193127391211036

Epoch: 6| Step: 1
Training loss: 0.40196675165357754
Validation loss: 2.915841971471187

Epoch: 6| Step: 2
Training loss: 0.5788701899490731
Validation loss: 2.951387476203929

Epoch: 6| Step: 3
Training loss: 0.5685232129520428
Validation loss: 2.8566538399334567

Epoch: 6| Step: 4
Training loss: 0.37352492374541685
Validation loss: 2.8438634675133754

Epoch: 6| Step: 5
Training loss: 0.4768228913881332
Validation loss: 2.926551381348173

Epoch: 6| Step: 6
Training loss: 0.531600163564664
Validation loss: 2.980175145504555

Epoch: 6| Step: 7
Training loss: 0.4894491799843275
Validation loss: 2.9356994115505475

Epoch: 6| Step: 8
Training loss: 0.5219902984806483
Validation loss: 2.97670416440623

Epoch: 6| Step: 9
Training loss: 0.5379593106521137
Validation loss: 2.9424133468007505

Epoch: 6| Step: 10
Training loss: 1.5598868835226438
Validation loss: 2.936291588122945

Epoch: 6| Step: 11
Training loss: 0.36854790224946277
Validation loss: 2.9999650052466733

Epoch: 6| Step: 12
Training loss: 0.6209288564156237
Validation loss: 2.9741301389506667

Epoch: 6| Step: 13
Training loss: 0.4859203176128466
Validation loss: 2.9340731469934695

Epoch: 307| Step: 0
Training loss: 0.4956269358227941
Validation loss: 2.979408072092073

Epoch: 6| Step: 1
Training loss: 0.38426344190799583
Validation loss: 3.023737311797207

Epoch: 6| Step: 2
Training loss: 0.4559348396134757
Validation loss: 2.9950291989982962

Epoch: 6| Step: 3
Training loss: 1.5418560410081212
Validation loss: 3.082823612420609

Epoch: 6| Step: 4
Training loss: 0.4990593734910807
Validation loss: 2.914599630779722

Epoch: 6| Step: 5
Training loss: 0.8153239472866061
Validation loss: 2.9127179300310067

Epoch: 6| Step: 6
Training loss: 0.4766215147155621
Validation loss: 2.943437068582912

Epoch: 6| Step: 7
Training loss: 0.24533368614457987
Validation loss: 3.0350371754321372

Epoch: 6| Step: 8
Training loss: 0.5292914977979427
Validation loss: 3.0967071734086478

Epoch: 6| Step: 9
Training loss: 0.46608143011698416
Validation loss: 3.0182908155822865

Epoch: 6| Step: 10
Training loss: 0.46870476186533705
Validation loss: 3.0189553616780502

Epoch: 6| Step: 11
Training loss: 0.5083682613671873
Validation loss: 2.9655947732942645

Epoch: 6| Step: 12
Training loss: 0.659286965011936
Validation loss: 3.0653046720917314

Epoch: 6| Step: 13
Training loss: 0.37732448963112314
Validation loss: 3.008377629814299

Epoch: 308| Step: 0
Training loss: 0.512074383341105
Validation loss: 3.0436306495948817

Epoch: 6| Step: 1
Training loss: 1.521719565473088
Validation loss: 3.0279972084881654

Epoch: 6| Step: 2
Training loss: 0.4664750046907753
Validation loss: 2.9631220291960676

Epoch: 6| Step: 3
Training loss: 0.487556438357997
Validation loss: 3.039777931396904

Epoch: 6| Step: 4
Training loss: 0.5122910422494171
Validation loss: 2.96537781982648

Epoch: 6| Step: 5
Training loss: 0.54975698477561
Validation loss: 2.999705141200226

Epoch: 6| Step: 6
Training loss: 0.5711527082952583
Validation loss: 2.9569110585574605

Epoch: 6| Step: 7
Training loss: 0.5956172943817645
Validation loss: 2.9549566304035872

Epoch: 6| Step: 8
Training loss: 0.5280427609128332
Validation loss: 3.0367984919263917

Epoch: 6| Step: 9
Training loss: 0.4751021099763947
Validation loss: 2.924393314902908

Epoch: 6| Step: 10
Training loss: 0.27542690281643073
Validation loss: 2.962877642762978

Epoch: 6| Step: 11
Training loss: 0.5760035382069424
Validation loss: 2.91277071195422

Epoch: 6| Step: 12
Training loss: 0.4815560420529742
Validation loss: 2.98949915183681

Epoch: 6| Step: 13
Training loss: 0.6410076580215028
Validation loss: 2.9410744151005592

Epoch: 309| Step: 0
Training loss: 0.5461066707015759
Validation loss: 2.9251363439925053

Epoch: 6| Step: 1
Training loss: 0.47553812213511365
Validation loss: 3.080767908871144

Epoch: 6| Step: 2
Training loss: 0.6691876717244166
Validation loss: 2.9778482058327285

Epoch: 6| Step: 3
Training loss: 0.36068709964363116
Validation loss: 2.8833345045701075

Epoch: 6| Step: 4
Training loss: 0.5980342093733012
Validation loss: 2.918555783243481

Epoch: 6| Step: 5
Training loss: 0.6631133533141728
Validation loss: 2.9043211740325128

Epoch: 6| Step: 6
Training loss: 0.4238774319283398
Validation loss: 2.9140066869332157

Epoch: 6| Step: 7
Training loss: 0.692747055252573
Validation loss: 2.9824656958151374

Epoch: 6| Step: 8
Training loss: 0.6555724960992142
Validation loss: 3.0111027148162157

Epoch: 6| Step: 9
Training loss: 0.3744801255568889
Validation loss: 2.9717774196987987

Epoch: 6| Step: 10
Training loss: 0.6385768154690618
Validation loss: 2.9575561433839095

Epoch: 6| Step: 11
Training loss: 0.6305061508864879
Validation loss: 3.0088522166824205

Epoch: 6| Step: 12
Training loss: 1.5096750565341572
Validation loss: 3.0134267223143927

Epoch: 6| Step: 13
Training loss: 0.5438470392126061
Validation loss: 2.942633087186413

Epoch: 310| Step: 0
Training loss: 0.551304940234461
Validation loss: 2.863849384032516

Epoch: 6| Step: 1
Training loss: 0.4004260163831533
Validation loss: 2.9648373569826703

Epoch: 6| Step: 2
Training loss: 0.46090345741898675
Validation loss: 2.981699571493679

Epoch: 6| Step: 3
Training loss: 0.5744053543919788
Validation loss: 2.959831843282148

Epoch: 6| Step: 4
Training loss: 0.8689670003566837
Validation loss: 3.0143187597697896

Epoch: 6| Step: 5
Training loss: 0.5520308637577177
Validation loss: 2.945137349257521

Epoch: 6| Step: 6
Training loss: 0.4719947726093581
Validation loss: 2.9401367068566557

Epoch: 6| Step: 7
Training loss: 1.4601550123149265
Validation loss: 2.949741948689416

Epoch: 6| Step: 8
Training loss: 0.5481335191488743
Validation loss: 2.9345526823253687

Epoch: 6| Step: 9
Training loss: 0.4099706684064465
Validation loss: 3.056153643960753

Epoch: 6| Step: 10
Training loss: 0.3857835771591678
Validation loss: 2.9914523185157487

Epoch: 6| Step: 11
Training loss: 0.5063814392885755
Validation loss: 2.9776171453723674

Epoch: 6| Step: 12
Training loss: 0.5365115358458071
Validation loss: 2.953785211948114

Epoch: 6| Step: 13
Training loss: 0.5801420337138279
Validation loss: 3.0595943654130875

Epoch: 311| Step: 0
Training loss: 0.5132014219778732
Validation loss: 2.945761648885924

Epoch: 6| Step: 1
Training loss: 0.5772631123021266
Validation loss: 2.964623136023092

Epoch: 6| Step: 2
Training loss: 0.579646556878704
Validation loss: 2.9376698032297335

Epoch: 6| Step: 3
Training loss: 0.49295160230505225
Validation loss: 2.993200079331462

Epoch: 6| Step: 4
Training loss: 0.549469922125069
Validation loss: 2.986907896052425

Epoch: 6| Step: 5
Training loss: 0.5288654272195419
Validation loss: 2.9153137656935697

Epoch: 6| Step: 6
Training loss: 0.5623415882845977
Validation loss: 3.036132288986231

Epoch: 6| Step: 7
Training loss: 0.8757960240855962
Validation loss: 3.067791202032529

Epoch: 6| Step: 8
Training loss: 0.4834566485873067
Validation loss: 3.023798314003321

Epoch: 6| Step: 9
Training loss: 0.5811667454479453
Validation loss: 3.1032836904218932

Epoch: 6| Step: 10
Training loss: 0.4529557734219924
Validation loss: 2.941731671775869

Epoch: 6| Step: 11
Training loss: 1.540505753984016
Validation loss: 3.0409270959478243

Epoch: 6| Step: 12
Training loss: 0.5060959487400892
Validation loss: 2.9222876245515077

Epoch: 6| Step: 13
Training loss: 0.6651606287598166
Validation loss: 3.031367689646769

Epoch: 312| Step: 0
Training loss: 0.6141539517703549
Validation loss: 2.970068762483079

Epoch: 6| Step: 1
Training loss: 0.6249182647665653
Validation loss: 2.9545661598760513

Epoch: 6| Step: 2
Training loss: 0.652529478759174
Validation loss: 2.9628253041901944

Epoch: 6| Step: 3
Training loss: 0.5121105237725334
Validation loss: 3.003182154021286

Epoch: 6| Step: 4
Training loss: 0.5252945822814907
Validation loss: 2.892493638911131

Epoch: 6| Step: 5
Training loss: 0.4521773722476035
Validation loss: 2.8586429013105388

Epoch: 6| Step: 6
Training loss: 0.45996456590262075
Validation loss: 2.9217558783797943

Epoch: 6| Step: 7
Training loss: 0.4087280840350031
Validation loss: 2.990036034063906

Epoch: 6| Step: 8
Training loss: 0.5036725825793972
Validation loss: 2.9011453213941856

Epoch: 6| Step: 9
Training loss: 0.36230090362958384
Validation loss: 2.88562522345626

Epoch: 6| Step: 10
Training loss: 1.4737266475260662
Validation loss: 3.0085789220076866

Epoch: 6| Step: 11
Training loss: 0.5647935995418054
Validation loss: 2.989974070588616

Epoch: 6| Step: 12
Training loss: 0.3852241997814909
Validation loss: 2.9364453580113397

Epoch: 6| Step: 13
Training loss: 0.418324435045712
Validation loss: 2.8562659504540373

Epoch: 313| Step: 0
Training loss: 0.4129565241400712
Validation loss: 2.881714733319337

Epoch: 6| Step: 1
Training loss: 0.3435832833104942
Validation loss: 2.974066541387825

Epoch: 6| Step: 2
Training loss: 0.7902084187927387
Validation loss: 3.003251591825041

Epoch: 6| Step: 3
Training loss: 0.601435363017304
Validation loss: 2.8257287061786087

Epoch: 6| Step: 4
Training loss: 0.6620637996145504
Validation loss: 2.929113876134766

Epoch: 6| Step: 5
Training loss: 0.5713692894055415
Validation loss: 2.9207445021402387

Epoch: 6| Step: 6
Training loss: 0.2970818000092245
Validation loss: 2.9486391150526856

Epoch: 6| Step: 7
Training loss: 0.7111746423955153
Validation loss: 2.936122246533365

Epoch: 6| Step: 8
Training loss: 0.42432083110016633
Validation loss: 2.897597020554305

Epoch: 6| Step: 9
Training loss: 0.4256455791500574
Validation loss: 3.0247524007765696

Epoch: 6| Step: 10
Training loss: 0.7830826435979836
Validation loss: 2.9275116431756434

Epoch: 6| Step: 11
Training loss: 0.3713135118777311
Validation loss: 3.00474102192788

Epoch: 6| Step: 12
Training loss: 1.5369637988709808
Validation loss: 2.982587109018699

Epoch: 6| Step: 13
Training loss: 0.42763587827876487
Validation loss: 2.971935223204206

Epoch: 314| Step: 0
Training loss: 0.4372399953992067
Validation loss: 2.885861542670606

Epoch: 6| Step: 1
Training loss: 0.4303762983955699
Validation loss: 2.9292081991826273

Epoch: 6| Step: 2
Training loss: 0.5831981967888991
Validation loss: 2.8759318652131145

Epoch: 6| Step: 3
Training loss: 0.40522881687368795
Validation loss: 2.940324007548911

Epoch: 6| Step: 4
Training loss: 0.41048507225247777
Validation loss: 2.9415466085974824

Epoch: 6| Step: 5
Training loss: 0.5419813825200427
Validation loss: 2.860090961699283

Epoch: 6| Step: 6
Training loss: 0.5051586349530119
Validation loss: 2.9854888701420177

Epoch: 6| Step: 7
Training loss: 0.48958208374783824
Validation loss: 2.941879605879324

Epoch: 6| Step: 8
Training loss: 1.4993737025889373
Validation loss: 3.0511024166027134

Epoch: 6| Step: 9
Training loss: 0.41315876203846225
Validation loss: 3.064720049794444

Epoch: 6| Step: 10
Training loss: 0.633289298818901
Validation loss: 2.96245705724998

Epoch: 6| Step: 11
Training loss: 0.5097067203324176
Validation loss: 2.9950580555846034

Epoch: 6| Step: 12
Training loss: 0.4561261237515599
Validation loss: 2.9909879838193443

Epoch: 6| Step: 13
Training loss: 0.5552594634292627
Validation loss: 2.9210399447588093

Epoch: 315| Step: 0
Training loss: 0.5685639422917217
Validation loss: 3.0497020940740573

Epoch: 6| Step: 1
Training loss: 0.42309811564449407
Validation loss: 2.9162833007271596

Epoch: 6| Step: 2
Training loss: 0.5647277691853235
Validation loss: 2.9151472539115963

Epoch: 6| Step: 3
Training loss: 1.479169209795991
Validation loss: 2.898460189305531

Epoch: 6| Step: 4
Training loss: 0.2845518945351049
Validation loss: 2.9128603530858435

Epoch: 6| Step: 5
Training loss: 0.3622817574619808
Validation loss: 2.9349219324711027

Epoch: 6| Step: 6
Training loss: 0.6880690647019637
Validation loss: 3.014683195901722

Epoch: 6| Step: 7
Training loss: 0.6756779586263699
Validation loss: 2.988476542821105

Epoch: 6| Step: 8
Training loss: 0.42542609004768583
Validation loss: 2.869412313451484

Epoch: 6| Step: 9
Training loss: 0.3507300163185486
Validation loss: 2.9369485756884828

Epoch: 6| Step: 10
Training loss: 0.4313086877501557
Validation loss: 2.956113174745392

Epoch: 6| Step: 11
Training loss: 0.4665777737671837
Validation loss: 2.9976923067086583

Epoch: 6| Step: 12
Training loss: 0.4519368082198687
Validation loss: 3.033353514831255

Epoch: 6| Step: 13
Training loss: 0.48173992126544496
Validation loss: 2.975617933878541

Epoch: 316| Step: 0
Training loss: 0.5963225599239418
Validation loss: 2.9839912154466393

Epoch: 6| Step: 1
Training loss: 0.519932813980734
Validation loss: 2.9988359471150727

Epoch: 6| Step: 2
Training loss: 0.672338614084041
Validation loss: 3.0163534203768734

Epoch: 6| Step: 3
Training loss: 0.35134344693993363
Validation loss: 3.026863004188206

Epoch: 6| Step: 4
Training loss: 0.35245051024726476
Validation loss: 2.9478171952969587

Epoch: 6| Step: 5
Training loss: 0.47558440221895093
Validation loss: 3.0270742513822735

Epoch: 6| Step: 6
Training loss: 0.5119582918658203
Validation loss: 3.0068166562228567

Epoch: 6| Step: 7
Training loss: 1.4946268325287804
Validation loss: 2.958684219899081

Epoch: 6| Step: 8
Training loss: 0.4847455760612292
Validation loss: 2.936143616077661

Epoch: 6| Step: 9
Training loss: 0.5943367718939263
Validation loss: 2.974867584316301

Epoch: 6| Step: 10
Training loss: 0.7493453347488318
Validation loss: 2.9875561335143566

Epoch: 6| Step: 11
Training loss: 0.48866263181877684
Validation loss: 2.9153483590405354

Epoch: 6| Step: 12
Training loss: 0.5845853845021521
Validation loss: 2.9777309630716933

Epoch: 6| Step: 13
Training loss: 0.6245583404246754
Validation loss: 2.8991721182831593

Epoch: 317| Step: 0
Training loss: 0.5064805683144156
Validation loss: 2.9898617888352423

Epoch: 6| Step: 1
Training loss: 0.7578422304594145
Validation loss: 2.9919974297429164

Epoch: 6| Step: 2
Training loss: 0.6003705886942443
Validation loss: 3.003289115091944

Epoch: 6| Step: 3
Training loss: 0.3991496509689531
Validation loss: 2.937985184012584

Epoch: 6| Step: 4
Training loss: 0.6711023012622297
Validation loss: 2.9746025888553858

Epoch: 6| Step: 5
Training loss: 0.4221260948336396
Validation loss: 2.9645517613402346

Epoch: 6| Step: 6
Training loss: 0.5208654266642122
Validation loss: 2.918181493749774

Epoch: 6| Step: 7
Training loss: 0.5645716189709362
Validation loss: 2.9780866937351953

Epoch: 6| Step: 8
Training loss: 0.4609602906363338
Validation loss: 2.982678875095698

Epoch: 6| Step: 9
Training loss: 0.7755412380658848
Validation loss: 2.9226471531751987

Epoch: 6| Step: 10
Training loss: 1.4732150123231096
Validation loss: 2.9470171190594567

Epoch: 6| Step: 11
Training loss: 0.602153784734027
Validation loss: 2.968489438049775

Epoch: 6| Step: 12
Training loss: 0.6015992091484401
Validation loss: 2.9633612865578507

Epoch: 6| Step: 13
Training loss: 0.5202762167253693
Validation loss: 2.9763059864335126

Epoch: 318| Step: 0
Training loss: 0.5025480433409165
Validation loss: 2.9318669464970046

Epoch: 6| Step: 1
Training loss: 0.5148969770363895
Validation loss: 2.942686574849845

Epoch: 6| Step: 2
Training loss: 0.5097453087744714
Validation loss: 2.9760473544812265

Epoch: 6| Step: 3
Training loss: 0.6106565644179616
Validation loss: 2.8922785660310706

Epoch: 6| Step: 4
Training loss: 0.533436092023997
Validation loss: 2.999627686285816

Epoch: 6| Step: 5
Training loss: 0.5781473722510831
Validation loss: 2.9547789313581547

Epoch: 6| Step: 6
Training loss: 0.5982674359539746
Validation loss: 2.9987873434540457

Epoch: 6| Step: 7
Training loss: 0.6052203253270877
Validation loss: 2.980521645332814

Epoch: 6| Step: 8
Training loss: 0.6766966424685379
Validation loss: 2.9392899071885834

Epoch: 6| Step: 9
Training loss: 1.4548299488178738
Validation loss: 3.0016339541284887

Epoch: 6| Step: 10
Training loss: 0.8403066734375829
Validation loss: 3.030751452790431

Epoch: 6| Step: 11
Training loss: 0.4356326373729264
Validation loss: 3.045213138531034

Epoch: 6| Step: 12
Training loss: 0.3875967328019025
Validation loss: 2.845173224598711

Epoch: 6| Step: 13
Training loss: 0.47566726897766715
Validation loss: 3.0443667920698374

Epoch: 319| Step: 0
Training loss: 0.42879195088715766
Validation loss: 3.053506731932366

Epoch: 6| Step: 1
Training loss: 0.4546303244492147
Validation loss: 2.9342013431252614

Epoch: 6| Step: 2
Training loss: 0.6766315689247262
Validation loss: 3.0031069323326696

Epoch: 6| Step: 3
Training loss: 0.5013942947460247
Validation loss: 3.0073957410473695

Epoch: 6| Step: 4
Training loss: 0.3436773179983181
Validation loss: 2.9448910385509657

Epoch: 6| Step: 5
Training loss: 0.4583044819709868
Validation loss: 3.0595667149368078

Epoch: 6| Step: 6
Training loss: 0.7270093384684735
Validation loss: 2.9402803965693876

Epoch: 6| Step: 7
Training loss: 0.3007546450255429
Validation loss: 2.863223683748709

Epoch: 6| Step: 8
Training loss: 0.4176141714412302
Validation loss: 2.9544283296804656

Epoch: 6| Step: 9
Training loss: 0.5529809408576785
Validation loss: 2.99792612766649

Epoch: 6| Step: 10
Training loss: 0.42483283640237696
Validation loss: 2.876176828213223

Epoch: 6| Step: 11
Training loss: 0.6464739795782533
Validation loss: 2.895728203125308

Epoch: 6| Step: 12
Training loss: 0.2947160621628094
Validation loss: 2.9636470505537154

Epoch: 6| Step: 13
Training loss: 1.45435051871606
Validation loss: 2.970202375146784

Epoch: 320| Step: 0
Training loss: 0.675457915643424
Validation loss: 2.9209885502022424

Epoch: 6| Step: 1
Training loss: 0.608171962755574
Validation loss: 2.9575164007235717

Epoch: 6| Step: 2
Training loss: 0.5159376814695763
Validation loss: 3.048504620205331

Epoch: 6| Step: 3
Training loss: 0.31746057584753
Validation loss: 2.962888881521062

Epoch: 6| Step: 4
Training loss: 0.5031790994500388
Validation loss: 2.9846316055838464

Epoch: 6| Step: 5
Training loss: 0.356617924948654
Validation loss: 2.9822641866850024

Epoch: 6| Step: 6
Training loss: 0.38409252642218683
Validation loss: 2.9232004052855265

Epoch: 6| Step: 7
Training loss: 1.4379615871885654
Validation loss: 2.968614876332281

Epoch: 6| Step: 8
Training loss: 0.4764054148946007
Validation loss: 2.9703160488770335

Epoch: 6| Step: 9
Training loss: 0.5842863597043544
Validation loss: 2.959005955448498

Epoch: 6| Step: 10
Training loss: 0.6644539520778813
Validation loss: 3.008888587184699

Epoch: 6| Step: 11
Training loss: 0.5008703048482187
Validation loss: 2.8703671736226575

Epoch: 6| Step: 12
Training loss: 0.47477719201050006
Validation loss: 2.9298333975173483

Epoch: 6| Step: 13
Training loss: 0.6149591708392651
Validation loss: 2.967561959249454

Epoch: 321| Step: 0
Training loss: 0.33552222866363135
Validation loss: 2.999925837659747

Epoch: 6| Step: 1
Training loss: 0.4768690467852848
Validation loss: 3.023057136628313

Epoch: 6| Step: 2
Training loss: 0.36866459099844623
Validation loss: 3.0488487176161008

Epoch: 6| Step: 3
Training loss: 0.5734613055035499
Validation loss: 2.952335682763973

Epoch: 6| Step: 4
Training loss: 0.34387711862170056
Validation loss: 2.9946435952553285

Epoch: 6| Step: 5
Training loss: 0.5395534325443909
Validation loss: 3.0484017092873295

Epoch: 6| Step: 6
Training loss: 0.34539273438912926
Validation loss: 2.952396121220508

Epoch: 6| Step: 7
Training loss: 0.7289689113753968
Validation loss: 3.013978195527539

Epoch: 6| Step: 8
Training loss: 0.518575463175138
Validation loss: 2.935132080065254

Epoch: 6| Step: 9
Training loss: 0.605781376021763
Validation loss: 2.963994456977998

Epoch: 6| Step: 10
Training loss: 0.380735171679912
Validation loss: 2.982759980741326

Epoch: 6| Step: 11
Training loss: 1.552613374805839
Validation loss: 2.9649898340609533

Epoch: 6| Step: 12
Training loss: 0.5248198404456376
Validation loss: 3.0329776965900854

Epoch: 6| Step: 13
Training loss: 0.6094218505064409
Validation loss: 2.960988563493181

Epoch: 322| Step: 0
Training loss: 0.5473230161668292
Validation loss: 2.9247809934001303

Epoch: 6| Step: 1
Training loss: 0.5836596144107279
Validation loss: 2.9818445898981474

Epoch: 6| Step: 2
Training loss: 0.4887690282127391
Validation loss: 2.982812082761213

Epoch: 6| Step: 3
Training loss: 0.6838914495465479
Validation loss: 2.955061222287767

Epoch: 6| Step: 4
Training loss: 0.528368089246713
Validation loss: 2.9389450495937925

Epoch: 6| Step: 5
Training loss: 0.7658472322510982
Validation loss: 2.9137911631893525

Epoch: 6| Step: 6
Training loss: 0.3955735140258752
Validation loss: 2.9386320976253715

Epoch: 6| Step: 7
Training loss: 0.3879159256442839
Validation loss: 2.8767636321542014

Epoch: 6| Step: 8
Training loss: 0.5330099517455038
Validation loss: 2.941900987631228

Epoch: 6| Step: 9
Training loss: 0.4758627084237339
Validation loss: 2.8671111218832173

Epoch: 6| Step: 10
Training loss: 1.4542742870624883
Validation loss: 2.94018773967312

Epoch: 6| Step: 11
Training loss: 0.4741589799195357
Validation loss: 3.0019945560823604

Epoch: 6| Step: 12
Training loss: 0.46691693473831825
Validation loss: 3.0861859185390066

Epoch: 6| Step: 13
Training loss: 0.6050680988384903
Validation loss: 2.9800734484878326

Epoch: 323| Step: 0
Training loss: 0.43090260099492256
Validation loss: 3.064240901512217

Epoch: 6| Step: 1
Training loss: 0.45453259100376875
Validation loss: 3.045780578726972

Epoch: 6| Step: 2
Training loss: 0.5132351022816745
Validation loss: 2.9784530816520958

Epoch: 6| Step: 3
Training loss: 0.48691446891121976
Validation loss: 3.0273311622932186

Epoch: 6| Step: 4
Training loss: 0.6033200190806763
Validation loss: 2.9342082362510804

Epoch: 6| Step: 5
Training loss: 0.5405405761422326
Validation loss: 2.9794740229340184

Epoch: 6| Step: 6
Training loss: 0.4524703393878339
Validation loss: 2.9782857237093254

Epoch: 6| Step: 7
Training loss: 0.7076982755473172
Validation loss: 3.0233863477955136

Epoch: 6| Step: 8
Training loss: 0.7109598847941845
Validation loss: 3.0420726914466343

Epoch: 6| Step: 9
Training loss: 0.5704309784612668
Validation loss: 2.99278500320758

Epoch: 6| Step: 10
Training loss: 0.33531005060344743
Validation loss: 2.9752627494463413

Epoch: 6| Step: 11
Training loss: 1.4320816255939783
Validation loss: 3.005694825425678

Epoch: 6| Step: 12
Training loss: 0.5622346570104066
Validation loss: 3.0167610255565447

Epoch: 6| Step: 13
Training loss: 0.5941123609572903
Validation loss: 2.9975492082999753

Epoch: 324| Step: 0
Training loss: 0.46198581839857955
Validation loss: 3.0867870593914395

Epoch: 6| Step: 1
Training loss: 0.47203746992329865
Validation loss: 2.9119694124150657

Epoch: 6| Step: 2
Training loss: 0.49588008093917346
Validation loss: 2.901710273404786

Epoch: 6| Step: 3
Training loss: 0.537388233274768
Validation loss: 2.951150318052714

Epoch: 6| Step: 4
Training loss: 0.671374511607775
Validation loss: 2.8900129890369994

Epoch: 6| Step: 5
Training loss: 0.5718245906187444
Validation loss: 2.9225171313451317

Epoch: 6| Step: 6
Training loss: 1.4349182828703608
Validation loss: 2.963747139206279

Epoch: 6| Step: 7
Training loss: 0.609713973619785
Validation loss: 2.9116495760012295

Epoch: 6| Step: 8
Training loss: 0.4446569938677574
Validation loss: 2.917675706616746

Epoch: 6| Step: 9
Training loss: 0.5275757173460393
Validation loss: 3.0137269366729504

Epoch: 6| Step: 10
Training loss: 0.3980423332756373
Validation loss: 3.0843323472412845

Epoch: 6| Step: 11
Training loss: 0.4744386719201873
Validation loss: 3.019969071151974

Epoch: 6| Step: 12
Training loss: 0.5079371959468982
Validation loss: 2.9861145142725594

Epoch: 6| Step: 13
Training loss: 0.5098918013239557
Validation loss: 3.0277739975893025

Epoch: 325| Step: 0
Training loss: 0.3671842940170254
Validation loss: 3.067659935734074

Epoch: 6| Step: 1
Training loss: 0.3608062480726491
Validation loss: 3.0472704508498354

Epoch: 6| Step: 2
Training loss: 0.4503894147501001
Validation loss: 3.026463573849803

Epoch: 6| Step: 3
Training loss: 0.40054162132310284
Validation loss: 2.9285832472971443

Epoch: 6| Step: 4
Training loss: 0.3838752863270205
Validation loss: 2.9046059200109298

Epoch: 6| Step: 5
Training loss: 0.6562017922633029
Validation loss: 2.9457826787180674

Epoch: 6| Step: 6
Training loss: 0.4861601880443637
Validation loss: 2.8659812059675813

Epoch: 6| Step: 7
Training loss: 0.6821673743529121
Validation loss: 2.8947982767877725

Epoch: 6| Step: 8
Training loss: 0.5212535275767591
Validation loss: 2.92790340099385

Epoch: 6| Step: 9
Training loss: 1.535594615519236
Validation loss: 2.980424939821432

Epoch: 6| Step: 10
Training loss: 0.35253671661188196
Validation loss: 2.954286726936229

Epoch: 6| Step: 11
Training loss: 0.5283385324773882
Validation loss: 2.851688329977409

Epoch: 6| Step: 12
Training loss: 0.3032798774527023
Validation loss: 2.9372918481328663

Epoch: 6| Step: 13
Training loss: 0.6953239439976198
Validation loss: 2.9913406302440526

Epoch: 326| Step: 0
Training loss: 0.41945572640373807
Validation loss: 2.9717074202907523

Epoch: 6| Step: 1
Training loss: 0.4081040768714861
Validation loss: 2.937083113286968

Epoch: 6| Step: 2
Training loss: 0.5701247650928846
Validation loss: 2.9071963010423274

Epoch: 6| Step: 3
Training loss: 0.5752945508337793
Validation loss: 2.9646736669192553

Epoch: 6| Step: 4
Training loss: 0.47283007050193987
Validation loss: 2.901833353734474

Epoch: 6| Step: 5
Training loss: 0.3626717201821934
Validation loss: 2.8848162736796183

Epoch: 6| Step: 6
Training loss: 0.517363276964244
Validation loss: 2.9648739859706597

Epoch: 6| Step: 7
Training loss: 0.48141437609090587
Validation loss: 2.8439521438240285

Epoch: 6| Step: 8
Training loss: 0.4328293463117314
Validation loss: 2.903102510308357

Epoch: 6| Step: 9
Training loss: 0.41401161025071964
Validation loss: 2.873861709487671

Epoch: 6| Step: 10
Training loss: 0.45674194243119653
Validation loss: 2.9280275245164913

Epoch: 6| Step: 11
Training loss: 0.4450455919762946
Validation loss: 2.91678439765558

Epoch: 6| Step: 12
Training loss: 1.43925625866617
Validation loss: 2.989298555498809

Epoch: 6| Step: 13
Training loss: 0.5101055312831397
Validation loss: 2.9487743724997846

Epoch: 327| Step: 0
Training loss: 0.4146135370316245
Validation loss: 3.08593298030474

Epoch: 6| Step: 1
Training loss: 0.562828471387664
Validation loss: 2.961233548652335

Epoch: 6| Step: 2
Training loss: 0.46451018089659313
Validation loss: 3.0337477418408856

Epoch: 6| Step: 3
Training loss: 0.4189452591475873
Validation loss: 3.0012654708427546

Epoch: 6| Step: 4
Training loss: 0.44246172674793527
Validation loss: 3.0124091624049227

Epoch: 6| Step: 5
Training loss: 1.435813328933327
Validation loss: 3.0163128715630787

Epoch: 6| Step: 6
Training loss: 0.5792357110873525
Validation loss: 3.007274166664515

Epoch: 6| Step: 7
Training loss: 0.47630018300267785
Validation loss: 2.9720737924284064

Epoch: 6| Step: 8
Training loss: 0.71582855594567
Validation loss: 2.8787182660713433

Epoch: 6| Step: 9
Training loss: 0.4238335921115113
Validation loss: 2.9565272571535806

Epoch: 6| Step: 10
Training loss: 0.38900301834788853
Validation loss: 2.9443137096875525

Epoch: 6| Step: 11
Training loss: 0.5630523301124037
Validation loss: 3.023252601456911

Epoch: 6| Step: 12
Training loss: 0.34065585827820244
Validation loss: 2.9365807034932767

Epoch: 6| Step: 13
Training loss: 0.7705766963747867
Validation loss: 3.0022044427194494

Epoch: 328| Step: 0
Training loss: 0.5805944334921644
Validation loss: 3.086330482151445

Epoch: 6| Step: 1
Training loss: 0.5365528899872426
Validation loss: 3.046112402009046

Epoch: 6| Step: 2
Training loss: 1.468228998507837
Validation loss: 2.9225421218729952

Epoch: 6| Step: 3
Training loss: 0.5248170011472053
Validation loss: 3.0441015417813544

Epoch: 6| Step: 4
Training loss: 0.5214099045060405
Validation loss: 2.9429332320882957

Epoch: 6| Step: 5
Training loss: 0.5702848558388727
Validation loss: 3.0003434355506764

Epoch: 6| Step: 6
Training loss: 0.5159396743035437
Validation loss: 2.9185710865761476

Epoch: 6| Step: 7
Training loss: 0.5763906806958804
Validation loss: 2.9540747270862733

Epoch: 6| Step: 8
Training loss: 0.4269222754443174
Validation loss: 2.862478326662685

Epoch: 6| Step: 9
Training loss: 0.5030835555167047
Validation loss: 2.9592712867553224

Epoch: 6| Step: 10
Training loss: 0.5518694739318876
Validation loss: 2.937084804438396

Epoch: 6| Step: 11
Training loss: 0.43774410658419766
Validation loss: 2.9183576427698474

Epoch: 6| Step: 12
Training loss: 0.5440678621101279
Validation loss: 2.9868885526517928

Epoch: 6| Step: 13
Training loss: 0.5182822566098825
Validation loss: 3.018260311638554

Epoch: 329| Step: 0
Training loss: 0.45498725082016284
Validation loss: 2.896254643774172

Epoch: 6| Step: 1
Training loss: 0.6184438159807084
Validation loss: 2.9262693547202585

Epoch: 6| Step: 2
Training loss: 0.4406768376044225
Validation loss: 2.9348040174029983

Epoch: 6| Step: 3
Training loss: 0.4300842707417475
Validation loss: 2.93132204022841

Epoch: 6| Step: 4
Training loss: 0.4578283482955888
Validation loss: 2.8894844348121

Epoch: 6| Step: 5
Training loss: 0.5973339832574142
Validation loss: 2.9572963956871443

Epoch: 6| Step: 6
Training loss: 0.48073728546968597
Validation loss: 3.0264147311301595

Epoch: 6| Step: 7
Training loss: 0.5553320242949159
Validation loss: 2.9551019123445346

Epoch: 6| Step: 8
Training loss: 1.4672399021983513
Validation loss: 2.9307108265951642

Epoch: 6| Step: 9
Training loss: 0.6687945119358265
Validation loss: 3.0499738405492045

Epoch: 6| Step: 10
Training loss: 0.4568604533258016
Validation loss: 2.9761443691315264

Epoch: 6| Step: 11
Training loss: 0.558698230922432
Validation loss: 2.965841079520299

Epoch: 6| Step: 12
Training loss: 0.5089088342897916
Validation loss: 2.968533785793461

Epoch: 6| Step: 13
Training loss: 0.3857802553345599
Validation loss: 2.992786344225565

Epoch: 330| Step: 0
Training loss: 1.4123905899074687
Validation loss: 2.9708952129994293

Epoch: 6| Step: 1
Training loss: 0.3968397154854915
Validation loss: 2.9203722620265182

Epoch: 6| Step: 2
Training loss: 0.27083987295373835
Validation loss: 2.9701300642431323

Epoch: 6| Step: 3
Training loss: 0.4161378564495783
Validation loss: 2.970899024939747

Epoch: 6| Step: 4
Training loss: 0.5423682205715445
Validation loss: 2.932599728507231

Epoch: 6| Step: 5
Training loss: 0.5032860539611806
Validation loss: 2.9822703558057913

Epoch: 6| Step: 6
Training loss: 0.5765830431744152
Validation loss: 2.9640064824745997

Epoch: 6| Step: 7
Training loss: 0.49240551010650496
Validation loss: 2.980219026022143

Epoch: 6| Step: 8
Training loss: 0.4808830243019507
Validation loss: 2.9835033109039317

Epoch: 6| Step: 9
Training loss: 0.6375882349473618
Validation loss: 3.002667300952056

Epoch: 6| Step: 10
Training loss: 0.522371173883882
Validation loss: 2.9949092322230677

Epoch: 6| Step: 11
Training loss: 0.6320942228465142
Validation loss: 3.0347176606827553

Epoch: 6| Step: 12
Training loss: 0.528309961242244
Validation loss: 2.9247913052481485

Epoch: 6| Step: 13
Training loss: 0.3457379727661052
Validation loss: 2.945266021712569

Epoch: 331| Step: 0
Training loss: 0.5401893668689223
Validation loss: 3.088581121406051

Epoch: 6| Step: 1
Training loss: 0.5351788871042688
Validation loss: 2.916359208568363

Epoch: 6| Step: 2
Training loss: 0.5419833345807105
Validation loss: 2.997366040322291

Epoch: 6| Step: 3
Training loss: 0.5383104800854411
Validation loss: 2.989861323671549

Epoch: 6| Step: 4
Training loss: 0.49943588143531453
Validation loss: 2.875169735196512

Epoch: 6| Step: 5
Training loss: 0.5186686417538776
Validation loss: 3.0020355365521176

Epoch: 6| Step: 6
Training loss: 1.3998978730826546
Validation loss: 2.8931846214639902

Epoch: 6| Step: 7
Training loss: 0.6087888441675925
Validation loss: 2.993796803076057

Epoch: 6| Step: 8
Training loss: 0.40736039338755137
Validation loss: 3.002391100710358

Epoch: 6| Step: 9
Training loss: 0.4496474998079262
Validation loss: 3.018542102634043

Epoch: 6| Step: 10
Training loss: 0.6892115788507224
Validation loss: 2.94408100262325

Epoch: 6| Step: 11
Training loss: 0.6154357096317794
Validation loss: 2.886952873787899

Epoch: 6| Step: 12
Training loss: 0.5387026373452208
Validation loss: 2.9830779207815654

Epoch: 6| Step: 13
Training loss: 0.6565371974842908
Validation loss: 3.0079671580528875

Epoch: 332| Step: 0
Training loss: 0.5448566247301198
Validation loss: 2.9528541508013815

Epoch: 6| Step: 1
Training loss: 0.4789744921255632
Validation loss: 2.9955210098924683

Epoch: 6| Step: 2
Training loss: 0.4074725681854223
Validation loss: 2.878119503958967

Epoch: 6| Step: 3
Training loss: 0.4560003799679495
Validation loss: 3.0081131293594088

Epoch: 6| Step: 4
Training loss: 0.4459682288004762
Validation loss: 2.93851537267872

Epoch: 6| Step: 5
Training loss: 0.40614366973838123
Validation loss: 3.07548917430547

Epoch: 6| Step: 6
Training loss: 0.597675173590768
Validation loss: 2.938111478320954

Epoch: 6| Step: 7
Training loss: 0.39054942353606154
Validation loss: 2.980488521698666

Epoch: 6| Step: 8
Training loss: 1.4253127909239556
Validation loss: 3.005796805712327

Epoch: 6| Step: 9
Training loss: 0.3891991915204844
Validation loss: 2.981508432805744

Epoch: 6| Step: 10
Training loss: 0.39549803545134776
Validation loss: 3.028450436683709

Epoch: 6| Step: 11
Training loss: 0.48534559096533164
Validation loss: 3.009046134791981

Epoch: 6| Step: 12
Training loss: 0.6092287523887243
Validation loss: 2.977609445272405

Epoch: 6| Step: 13
Training loss: 0.34721881692594053
Validation loss: 3.07711842662624

Epoch: 333| Step: 0
Training loss: 0.36573972776776126
Validation loss: 2.9779435872733284

Epoch: 6| Step: 1
Training loss: 0.6047895498191623
Validation loss: 2.8725106062774906

Epoch: 6| Step: 2
Training loss: 0.46729440390944055
Validation loss: 2.924371873082528

Epoch: 6| Step: 3
Training loss: 0.5827631093387262
Validation loss: 3.0067566971364243

Epoch: 6| Step: 4
Training loss: 0.37481844003641684
Validation loss: 2.977341771014612

Epoch: 6| Step: 5
Training loss: 0.4562923130899007
Validation loss: 3.08676481464411

Epoch: 6| Step: 6
Training loss: 0.43476395311059834
Validation loss: 2.9097669780589954

Epoch: 6| Step: 7
Training loss: 0.41327174271318784
Validation loss: 2.968818503141603

Epoch: 6| Step: 8
Training loss: 0.44491418793344994
Validation loss: 2.8859722598684177

Epoch: 6| Step: 9
Training loss: 1.4419656303902268
Validation loss: 2.9256827283092908

Epoch: 6| Step: 10
Training loss: 0.428404348664291
Validation loss: 2.9643186724959505

Epoch: 6| Step: 11
Training loss: 0.5475289113759161
Validation loss: 2.9338321377287064

Epoch: 6| Step: 12
Training loss: 0.6438254913953888
Validation loss: 2.986419031004104

Epoch: 6| Step: 13
Training loss: 0.4233581820589256
Validation loss: 2.972420427857756

Epoch: 334| Step: 0
Training loss: 0.3104750712173089
Validation loss: 2.925564345777092

Epoch: 6| Step: 1
Training loss: 0.482778378858047
Validation loss: 2.862236134057299

Epoch: 6| Step: 2
Training loss: 0.5699760280554181
Validation loss: 2.9939264700742507

Epoch: 6| Step: 3
Training loss: 0.5981260211182491
Validation loss: 2.9719517090554897

Epoch: 6| Step: 4
Training loss: 0.4898040219977884
Validation loss: 2.960040517735895

Epoch: 6| Step: 5
Training loss: 0.4749807309960511
Validation loss: 2.9589014761446872

Epoch: 6| Step: 6
Training loss: 1.4890477567024916
Validation loss: 2.8965078204169186

Epoch: 6| Step: 7
Training loss: 0.5949291266376974
Validation loss: 3.014245068373565

Epoch: 6| Step: 8
Training loss: 0.4803441203920464
Validation loss: 2.883461028966658

Epoch: 6| Step: 9
Training loss: 0.4372958319969795
Validation loss: 3.006447182451974

Epoch: 6| Step: 10
Training loss: 0.49494761134360377
Validation loss: 2.9563181599776627

Epoch: 6| Step: 11
Training loss: 0.6199614802438618
Validation loss: 3.006908198239239

Epoch: 6| Step: 12
Training loss: 0.44571339815220823
Validation loss: 3.0038975193407746

Epoch: 6| Step: 13
Training loss: 0.5469621861304862
Validation loss: 2.967958016747272

Epoch: 335| Step: 0
Training loss: 0.4899279179882435
Validation loss: 2.985515889029408

Epoch: 6| Step: 1
Training loss: 1.4017736609706954
Validation loss: 2.972239922582699

Epoch: 6| Step: 2
Training loss: 0.6573551953341468
Validation loss: 2.9651306040380567

Epoch: 6| Step: 3
Training loss: 0.5774357011430312
Validation loss: 2.983175439403512

Epoch: 6| Step: 4
Training loss: 0.37600093613924
Validation loss: 2.965560377493503

Epoch: 6| Step: 5
Training loss: 0.5942447508410403
Validation loss: 2.951423275815813

Epoch: 6| Step: 6
Training loss: 0.5546425008654229
Validation loss: 2.9841596515711193

Epoch: 6| Step: 7
Training loss: 0.5844246215967909
Validation loss: 2.8674750188234346

Epoch: 6| Step: 8
Training loss: 0.515556908937757
Validation loss: 2.972810277570096

Epoch: 6| Step: 9
Training loss: 0.5158196862017271
Validation loss: 2.945374074169175

Epoch: 6| Step: 10
Training loss: 0.5254551163696098
Validation loss: 2.8862138099213315

Epoch: 6| Step: 11
Training loss: 0.46217271204691784
Validation loss: 2.942612129371791

Epoch: 6| Step: 12
Training loss: 0.5665492436351512
Validation loss: 3.009122013537902

Epoch: 6| Step: 13
Training loss: 0.5341793248595519
Validation loss: 3.0416686480441673

Epoch: 336| Step: 0
Training loss: 0.43084759596687067
Validation loss: 2.9914949311150716

Epoch: 6| Step: 1
Training loss: 0.3106473124528591
Validation loss: 2.960404306950138

Epoch: 6| Step: 2
Training loss: 0.6792685873010765
Validation loss: 2.946752680117202

Epoch: 6| Step: 3
Training loss: 0.6032713855726346
Validation loss: 2.966275612813907

Epoch: 6| Step: 4
Training loss: 0.41569515654366995
Validation loss: 2.930551440540898

Epoch: 6| Step: 5
Training loss: 0.3529449725575103
Validation loss: 2.8482247802408924

Epoch: 6| Step: 6
Training loss: 0.7542462940927916
Validation loss: 2.930978800707042

Epoch: 6| Step: 7
Training loss: 1.4948870620681092
Validation loss: 2.891074975534214

Epoch: 6| Step: 8
Training loss: 0.46917074711867607
Validation loss: 2.947845422178144

Epoch: 6| Step: 9
Training loss: 0.4996207706443243
Validation loss: 2.846322946240544

Epoch: 6| Step: 10
Training loss: 0.45729828230895825
Validation loss: 2.9517584166724635

Epoch: 6| Step: 11
Training loss: 0.5362822666553139
Validation loss: 3.0003786642787005

Epoch: 6| Step: 12
Training loss: 0.7117835240456499
Validation loss: 2.9684503906047213

Epoch: 6| Step: 13
Training loss: 0.31747730902440346
Validation loss: 2.925959311322544

Epoch: 337| Step: 0
Training loss: 0.5117554979015035
Validation loss: 2.917303633391668

Epoch: 6| Step: 1
Training loss: 0.47875209337279806
Validation loss: 3.013377562791875

Epoch: 6| Step: 2
Training loss: 0.66094659298533
Validation loss: 2.897844128737257

Epoch: 6| Step: 3
Training loss: 0.4567539645494304
Validation loss: 3.002492902050157

Epoch: 6| Step: 4
Training loss: 0.4556171679248772
Validation loss: 2.953480088618401

Epoch: 6| Step: 5
Training loss: 0.6551302029876723
Validation loss: 2.9596394131733197

Epoch: 6| Step: 6
Training loss: 0.5258479060507935
Validation loss: 2.965782904700429

Epoch: 6| Step: 7
Training loss: 0.27043575056906227
Validation loss: 2.959061940333756

Epoch: 6| Step: 8
Training loss: 0.5181090888328571
Validation loss: 2.9078237039690804

Epoch: 6| Step: 9
Training loss: 0.6027864662350924
Validation loss: 2.9099115392560253

Epoch: 6| Step: 10
Training loss: 1.3673039849930702
Validation loss: 2.94406457665875

Epoch: 6| Step: 11
Training loss: 0.396215676647247
Validation loss: 2.899110289271581

Epoch: 6| Step: 12
Training loss: 0.5454072328931419
Validation loss: 3.0754505292634406

Epoch: 6| Step: 13
Training loss: 0.57631751337323
Validation loss: 2.919408549390474

Epoch: 338| Step: 0
Training loss: 0.5577890962878824
Validation loss: 3.022501561595933

Epoch: 6| Step: 1
Training loss: 0.40622944046228565
Validation loss: 2.9664552888323943

Epoch: 6| Step: 2
Training loss: 0.4425786071397625
Validation loss: 3.031448790333981

Epoch: 6| Step: 3
Training loss: 0.5712687170856343
Validation loss: 2.9188535575275685

Epoch: 6| Step: 4
Training loss: 0.3664733150246969
Validation loss: 2.9291514130833227

Epoch: 6| Step: 5
Training loss: 0.602448195371126
Validation loss: 2.9880652522060904

Epoch: 6| Step: 6
Training loss: 1.3658915453816665
Validation loss: 2.9353600546416003

Epoch: 6| Step: 7
Training loss: 0.6073489129995497
Validation loss: 2.9721222045643994

Epoch: 6| Step: 8
Training loss: 0.4340921235600894
Validation loss: 2.9912171811594837

Epoch: 6| Step: 9
Training loss: 0.3838646113071578
Validation loss: 2.9592538171681104

Epoch: 6| Step: 10
Training loss: 0.5417476342892892
Validation loss: 3.0342141173927972

Epoch: 6| Step: 11
Training loss: 0.4245392068475977
Validation loss: 3.120889758086777

Epoch: 6| Step: 12
Training loss: 0.6295859413505309
Validation loss: 2.962150788146601

Epoch: 6| Step: 13
Training loss: 0.7665062328764536
Validation loss: 2.9731327030963395

Epoch: 339| Step: 0
Training loss: 0.4333797820426794
Validation loss: 2.999962064715122

Epoch: 6| Step: 1
Training loss: 0.43298995446188093
Validation loss: 3.0556350370145897

Epoch: 6| Step: 2
Training loss: 0.530405551477295
Validation loss: 2.906787658507832

Epoch: 6| Step: 3
Training loss: 0.3416739433471246
Validation loss: 2.950843696852545

Epoch: 6| Step: 4
Training loss: 0.4956475601738094
Validation loss: 3.0307913757712024

Epoch: 6| Step: 5
Training loss: 0.34168050692407587
Validation loss: 2.9270187904780878

Epoch: 6| Step: 6
Training loss: 0.40261827750931434
Validation loss: 2.9572098349258176

Epoch: 6| Step: 7
Training loss: 0.3824618154053406
Validation loss: 2.95624349323226

Epoch: 6| Step: 8
Training loss: 0.49858217083077466
Validation loss: 2.8470680944599804

Epoch: 6| Step: 9
Training loss: 1.4047443382636533
Validation loss: 2.9855463814800514

Epoch: 6| Step: 10
Training loss: 0.40725501164653927
Validation loss: 2.983508265461742

Epoch: 6| Step: 11
Training loss: 0.39456852651821983
Validation loss: 3.026382444609345

Epoch: 6| Step: 12
Training loss: 0.7721651188421624
Validation loss: 3.001230279004245

Epoch: 6| Step: 13
Training loss: 0.6582644742452962
Validation loss: 3.0675840023387164

Epoch: 340| Step: 0
Training loss: 0.5640377641574649
Validation loss: 2.9773314543241365

Epoch: 6| Step: 1
Training loss: 0.4579528905802918
Validation loss: 2.8860474228728688

Epoch: 6| Step: 2
Training loss: 0.40630083499647074
Validation loss: 2.92757699860284

Epoch: 6| Step: 3
Training loss: 0.40659761228831354
Validation loss: 2.997926034884012

Epoch: 6| Step: 4
Training loss: 0.4677309721782636
Validation loss: 2.9919074104231846

Epoch: 6| Step: 5
Training loss: 0.6831352221953528
Validation loss: 3.008236598381862

Epoch: 6| Step: 6
Training loss: 0.5342152250697462
Validation loss: 2.9481437020554058

Epoch: 6| Step: 7
Training loss: 0.3227952016015876
Validation loss: 3.056276147336606

Epoch: 6| Step: 8
Training loss: 0.32242735070324596
Validation loss: 3.015931530594332

Epoch: 6| Step: 9
Training loss: 0.49934066573265434
Validation loss: 2.9781496050292904

Epoch: 6| Step: 10
Training loss: 0.4684186559071718
Validation loss: 3.031954444227641

Epoch: 6| Step: 11
Training loss: 0.4632387582420559
Validation loss: 3.0029129151907115

Epoch: 6| Step: 12
Training loss: 1.3793387018569108
Validation loss: 3.001496564255747

Epoch: 6| Step: 13
Training loss: 0.6380363358670792
Validation loss: 2.909241835199376

Epoch: 341| Step: 0
Training loss: 0.5936122282706228
Validation loss: 2.9934671054619506

Epoch: 6| Step: 1
Training loss: 0.4040168123901636
Validation loss: 2.870879150120988

Epoch: 6| Step: 2
Training loss: 1.457337866217383
Validation loss: 2.992517411625645

Epoch: 6| Step: 3
Training loss: 0.47127795437536396
Validation loss: 2.9230054956498255

Epoch: 6| Step: 4
Training loss: 0.487042174793498
Validation loss: 2.971241424231483

Epoch: 6| Step: 5
Training loss: 0.5947358830665883
Validation loss: 3.021862201209909

Epoch: 6| Step: 6
Training loss: 0.5680792468860707
Validation loss: 3.0260478078196593

Epoch: 6| Step: 7
Training loss: 0.5057379970964742
Validation loss: 2.914623857552288

Epoch: 6| Step: 8
Training loss: 0.4566674373903291
Validation loss: 2.9666760880252814

Epoch: 6| Step: 9
Training loss: 0.470091109271634
Validation loss: 2.9520815262197826

Epoch: 6| Step: 10
Training loss: 0.3667366018935893
Validation loss: 2.909242040079706

Epoch: 6| Step: 11
Training loss: 0.6366380511671995
Validation loss: 2.9525259846817864

Epoch: 6| Step: 12
Training loss: 0.4860478861503913
Validation loss: 3.0148446979242784

Epoch: 6| Step: 13
Training loss: 0.4477169308636441
Validation loss: 3.014923317135984

Epoch: 342| Step: 0
Training loss: 0.5022402287392401
Validation loss: 2.9406030646656998

Epoch: 6| Step: 1
Training loss: 0.4606665445275612
Validation loss: 2.9146309060465008

Epoch: 6| Step: 2
Training loss: 0.36437364633612995
Validation loss: 3.0941338349181033

Epoch: 6| Step: 3
Training loss: 0.5946184132026531
Validation loss: 3.034703139461652

Epoch: 6| Step: 4
Training loss: 0.47232516964866106
Validation loss: 2.907658772177495

Epoch: 6| Step: 5
Training loss: 0.3682265696598111
Validation loss: 2.95491246887194

Epoch: 6| Step: 6
Training loss: 1.4377991738185825
Validation loss: 2.93985250976728

Epoch: 6| Step: 7
Training loss: 0.3567851288801715
Validation loss: 2.9813389272375748

Epoch: 6| Step: 8
Training loss: 0.4969311352575163
Validation loss: 2.972185148520902

Epoch: 6| Step: 9
Training loss: 0.6620793518641293
Validation loss: 2.9040672007913026

Epoch: 6| Step: 10
Training loss: 0.46618861707130854
Validation loss: 3.0039307221671256

Epoch: 6| Step: 11
Training loss: 0.5134197239924334
Validation loss: 3.0342075300376736

Epoch: 6| Step: 12
Training loss: 0.5472400264484658
Validation loss: 3.023912469715608

Epoch: 6| Step: 13
Training loss: 0.3457260986280878
Validation loss: 3.0354831017158053

Epoch: 343| Step: 0
Training loss: 0.24849149698978307
Validation loss: 2.916285589845502

Epoch: 6| Step: 1
Training loss: 0.39370991411974043
Validation loss: 3.004473582624307

Epoch: 6| Step: 2
Training loss: 0.46755855458796153
Validation loss: 3.004613534298328

Epoch: 6| Step: 3
Training loss: 0.3128782367516014
Validation loss: 2.9133064577869305

Epoch: 6| Step: 4
Training loss: 0.3892050302017727
Validation loss: 2.993719566949754

Epoch: 6| Step: 5
Training loss: 0.5546273749633589
Validation loss: 3.003908234237194

Epoch: 6| Step: 6
Training loss: 0.35904998179792796
Validation loss: 2.9386219154785356

Epoch: 6| Step: 7
Training loss: 0.469989520600347
Validation loss: 3.0603304463691363

Epoch: 6| Step: 8
Training loss: 0.41576639509418245
Validation loss: 2.9803527036167594

Epoch: 6| Step: 9
Training loss: 1.4744402453712426
Validation loss: 3.011081903647564

Epoch: 6| Step: 10
Training loss: 0.46816046518050586
Validation loss: 2.9219634642783183

Epoch: 6| Step: 11
Training loss: 0.6324561022048896
Validation loss: 3.016226752927114

Epoch: 6| Step: 12
Training loss: 0.5611352789692192
Validation loss: 2.9867798734040356

Epoch: 6| Step: 13
Training loss: 0.6304758518201895
Validation loss: 2.9959380147911037

Epoch: 344| Step: 0
Training loss: 0.46651365554648877
Validation loss: 3.02062965671068

Epoch: 6| Step: 1
Training loss: 0.42838963522954826
Validation loss: 2.9413068601746137

Epoch: 6| Step: 2
Training loss: 0.3313015267944619
Validation loss: 2.8882989270831256

Epoch: 6| Step: 3
Training loss: 0.5826954220334839
Validation loss: 2.907806403583994

Epoch: 6| Step: 4
Training loss: 0.49889835051540865
Validation loss: 2.9582961084593826

Epoch: 6| Step: 5
Training loss: 0.7003115846082364
Validation loss: 2.9721926353938852

Epoch: 6| Step: 6
Training loss: 0.4876098594613003
Validation loss: 2.9848718945198875

Epoch: 6| Step: 7
Training loss: 0.32888051881512964
Validation loss: 2.9151093185367465

Epoch: 6| Step: 8
Training loss: 0.5656758037955761
Validation loss: 2.9419902004024276

Epoch: 6| Step: 9
Training loss: 0.569496590144438
Validation loss: 3.048362564425077

Epoch: 6| Step: 10
Training loss: 1.3540462538173528
Validation loss: 3.0267392447111883

Epoch: 6| Step: 11
Training loss: 0.4042591685527528
Validation loss: 2.951350100891941

Epoch: 6| Step: 12
Training loss: 0.3398739593057809
Validation loss: 2.98175852854937

Epoch: 6| Step: 13
Training loss: 0.5425555900799015
Validation loss: 3.0130520585183245

Epoch: 345| Step: 0
Training loss: 0.4456628792969649
Validation loss: 3.0745211318844854

Epoch: 6| Step: 1
Training loss: 0.4552334041660393
Validation loss: 2.9600823206666553

Epoch: 6| Step: 2
Training loss: 0.4677981248684275
Validation loss: 2.954286390675435

Epoch: 6| Step: 3
Training loss: 0.5038825332619772
Validation loss: 2.970328530380869

Epoch: 6| Step: 4
Training loss: 0.4854976503274083
Validation loss: 2.987101828670901

Epoch: 6| Step: 5
Training loss: 0.29670806005745937
Validation loss: 2.955966880526769

Epoch: 6| Step: 6
Training loss: 0.46338186474128007
Validation loss: 3.0099625470438887

Epoch: 6| Step: 7
Training loss: 0.4388125179721626
Validation loss: 2.92424907554796

Epoch: 6| Step: 8
Training loss: 0.4828115889161041
Validation loss: 2.8888174505652353

Epoch: 6| Step: 9
Training loss: 0.48421607948297996
Validation loss: 3.0047800738508132

Epoch: 6| Step: 10
Training loss: 1.4151518614192244
Validation loss: 2.9665652953376864

Epoch: 6| Step: 11
Training loss: 0.5924644607637376
Validation loss: 2.913481271713586

Epoch: 6| Step: 12
Training loss: 0.5692138540982534
Validation loss: 3.19193059628467

Epoch: 6| Step: 13
Training loss: 0.46958029644764604
Validation loss: 2.939052442107228

Epoch: 346| Step: 0
Training loss: 0.5572709112372545
Validation loss: 3.0700170424958566

Epoch: 6| Step: 1
Training loss: 0.4226017273376537
Validation loss: 2.9344275754552616

Epoch: 6| Step: 2
Training loss: 0.4447360239207773
Validation loss: 2.9217251145921037

Epoch: 6| Step: 3
Training loss: 0.2990205556579894
Validation loss: 2.904867000413259

Epoch: 6| Step: 4
Training loss: 0.39047051235868274
Validation loss: 2.9259879663541106

Epoch: 6| Step: 5
Training loss: 0.4161777270066582
Validation loss: 2.9304947889475086

Epoch: 6| Step: 6
Training loss: 0.556300866019401
Validation loss: 2.9475214707895137

Epoch: 6| Step: 7
Training loss: 0.48201000531583493
Validation loss: 2.8761297715142367

Epoch: 6| Step: 8
Training loss: 0.5435020243072712
Validation loss: 2.9403283996941383

Epoch: 6| Step: 9
Training loss: 0.5280213700145835
Validation loss: 2.935073567345213

Epoch: 6| Step: 10
Training loss: 0.5838653034800746
Validation loss: 2.8760644352025584

Epoch: 6| Step: 11
Training loss: 0.323879708114908
Validation loss: 2.9146982271690915

Epoch: 6| Step: 12
Training loss: 1.4330960690971555
Validation loss: 2.978347470065485

Epoch: 6| Step: 13
Training loss: 0.44945899509977566
Validation loss: 2.854570963456957

Epoch: 347| Step: 0
Training loss: 0.5036696832395272
Validation loss: 2.920291260624544

Epoch: 6| Step: 1
Training loss: 0.5173864909552872
Validation loss: 2.9644361106004613

Epoch: 6| Step: 2
Training loss: 0.5076327372536422
Validation loss: 2.9553301212753142

Epoch: 6| Step: 3
Training loss: 0.4403335737081666
Validation loss: 3.0661153537917265

Epoch: 6| Step: 4
Training loss: 0.4237322017566543
Validation loss: 3.0103850093527784

Epoch: 6| Step: 5
Training loss: 0.3479107878620426
Validation loss: 2.8728937367129785

Epoch: 6| Step: 6
Training loss: 0.5133790896921336
Validation loss: 3.000558324357908

Epoch: 6| Step: 7
Training loss: 0.4303779256999885
Validation loss: 2.8949295710252594

Epoch: 6| Step: 8
Training loss: 0.5026621579198637
Validation loss: 2.9391280593333744

Epoch: 6| Step: 9
Training loss: 0.6368557367228626
Validation loss: 2.9337418506554096

Epoch: 6| Step: 10
Training loss: 0.4719641797002883
Validation loss: 2.9052545763787276

Epoch: 6| Step: 11
Training loss: 0.5487133462695097
Validation loss: 2.915666467740395

Epoch: 6| Step: 12
Training loss: 1.369301300851322
Validation loss: 3.014344399734741

Epoch: 6| Step: 13
Training loss: 0.3287011605779018
Validation loss: 2.9502648121572115

Epoch: 348| Step: 0
Training loss: 0.4599975117844167
Validation loss: 2.9457061126805795

Epoch: 6| Step: 1
Training loss: 0.5736306221296388
Validation loss: 3.0050560412944027

Epoch: 6| Step: 2
Training loss: 0.4696464073646831
Validation loss: 2.9949786362817443

Epoch: 6| Step: 3
Training loss: 0.5276314692259941
Validation loss: 2.9602995816906006

Epoch: 6| Step: 4
Training loss: 0.393629138047729
Validation loss: 2.97398620075769

Epoch: 6| Step: 5
Training loss: 0.48546836875112326
Validation loss: 2.9182605929398533

Epoch: 6| Step: 6
Training loss: 0.39968922284361175
Validation loss: 2.950665265302617

Epoch: 6| Step: 7
Training loss: 0.5198388013956758
Validation loss: 2.9186864852801673

Epoch: 6| Step: 8
Training loss: 1.4070401832682473
Validation loss: 2.9614396286001483

Epoch: 6| Step: 9
Training loss: 0.5847883527132057
Validation loss: 2.96733186547043

Epoch: 6| Step: 10
Training loss: 0.47310067397738653
Validation loss: 3.0446071303036977

Epoch: 6| Step: 11
Training loss: 0.3719350013091293
Validation loss: 3.005293203088773

Epoch: 6| Step: 12
Training loss: 0.32375479444245553
Validation loss: 2.917909266671154

Epoch: 6| Step: 13
Training loss: 0.48367383413976306
Validation loss: 2.930751759819577

Epoch: 349| Step: 0
Training loss: 0.42778957132738044
Validation loss: 3.0081209098935533

Epoch: 6| Step: 1
Training loss: 0.31127939261640686
Validation loss: 2.9551237362915312

Epoch: 6| Step: 2
Training loss: 0.48602956776685624
Validation loss: 2.9325102503847544

Epoch: 6| Step: 3
Training loss: 1.3961032160527178
Validation loss: 2.833010631771585

Epoch: 6| Step: 4
Training loss: 0.41498656894596975
Validation loss: 3.0015613413591216

Epoch: 6| Step: 5
Training loss: 0.5388317996631667
Validation loss: 2.897754215063095

Epoch: 6| Step: 6
Training loss: 0.49289040101572734
Validation loss: 2.929430042398397

Epoch: 6| Step: 7
Training loss: 0.42769554693536327
Validation loss: 2.963239675643058

Epoch: 6| Step: 8
Training loss: 0.48071124772565565
Validation loss: 2.918250258015092

Epoch: 6| Step: 9
Training loss: 0.6600814641542301
Validation loss: 3.0086431636102207

Epoch: 6| Step: 10
Training loss: 0.42670180173591404
Validation loss: 2.9896186046757096

Epoch: 6| Step: 11
Training loss: 0.49552713912064117
Validation loss: 3.0097953040730605

Epoch: 6| Step: 12
Training loss: 0.45373730560284276
Validation loss: 2.9856512992179187

Epoch: 6| Step: 13
Training loss: 0.6275514023841213
Validation loss: 2.9850127918388916

Epoch: 350| Step: 0
Training loss: 0.41317077198479296
Validation loss: 2.9295964612591168

Epoch: 6| Step: 1
Training loss: 1.4052828960087134
Validation loss: 2.9290054951619817

Epoch: 6| Step: 2
Training loss: 0.5122643103269248
Validation loss: 2.917065720280004

Epoch: 6| Step: 3
Training loss: 0.3479877134790481
Validation loss: 2.9207818881595538

Epoch: 6| Step: 4
Training loss: 0.29829022983004794
Validation loss: 2.9826571461882723

Epoch: 6| Step: 5
Training loss: 0.46174131231804477
Validation loss: 2.9615395100877846

Epoch: 6| Step: 6
Training loss: 0.4939327632083701
Validation loss: 2.9773578265433005

Epoch: 6| Step: 7
Training loss: 0.46278270638415936
Validation loss: 2.934252045817606

Epoch: 6| Step: 8
Training loss: 0.5495969878036434
Validation loss: 2.8898812789247073

Epoch: 6| Step: 9
Training loss: 0.33620826765338635
Validation loss: 2.85555152059914

Epoch: 6| Step: 10
Training loss: 0.5488948577819295
Validation loss: 2.9057930891398835

Epoch: 6| Step: 11
Training loss: 0.5423775342630196
Validation loss: 3.002807601473203

Epoch: 6| Step: 12
Training loss: 0.556450687595381
Validation loss: 2.9244241864999783

Epoch: 6| Step: 13
Training loss: 0.43949099907321504
Validation loss: 2.9927933281313006

Testing loss: 2.6769463428318065
