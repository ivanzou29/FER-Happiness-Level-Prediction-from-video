Epoch: 1| Step: 0
Training loss: 4.28121280670166
Validation loss: 4.740047019162624
Epoch: 7| Step: 1
Training loss: 5.378171443939209
Validation loss: 4.7337354069991076
Epoch: 7| Step: 2
Training loss: 5.135964393615723
Validation loss: 4.730057448791943
Epoch: 7| Step: 3
Training loss: 5.13002347946167
Validation loss: 4.725640242048304
Epoch: 7| Step: 4
Training loss: 6.259879112243652
Validation loss: 4.72295478779635
Epoch: 7| Step: 5
Training loss: 5.243385314941406
Validation loss: 4.715596658720387
Epoch: 7| Step: 6
Training loss: 4.253746032714844
Validation loss: 4.711478247059335
Epoch: 7| Step: 7
Training loss: 4.778286933898926
Validation loss: 4.707898692261401
Epoch: 7| Step: 8
Training loss: 4.270948886871338
Validation loss: 4.702242274936155
Epoch: 7| Step: 9
Training loss: 4.430105686187744
Validation loss: 4.697301665656001
Epoch: 7| Step: 10
Training loss: 4.752081394195557
Validation loss: 4.693639738096608
Epoch: 7| Step: 11
Training loss: 4.7399749755859375
Validation loss: 4.68830724414304
Epoch: 7| Step: 12
Training loss: 4.849208354949951
Validation loss: 4.685378757312144
Epoch: 7| Step: 13
Training loss: 4.950585842132568
Validation loss: 4.676757901692562
Epoch: 7| Step: 14
Training loss: 4.346374034881592
Validation loss: 4.674168291709406
Epoch: 7| Step: 15
Training loss: 4.980832099914551
Validation loss: 4.668752790354996
Epoch: 2| Step: 0
Training loss: 5.504575729370117
Validation loss: 4.664867353096283
Epoch: 7| Step: 1
Training loss: 4.36453104019165
Validation loss: 4.659129105025916
Epoch: 7| Step: 2
Training loss: 4.825528144836426
Validation loss: 4.657630507036936
Epoch: 7| Step: 3
Training loss: 5.039170742034912
Validation loss: 4.650333552051791
Epoch: 7| Step: 4
Training loss: 4.446858882904053
Validation loss: 4.647856993640927
Epoch: 7| Step: 5
Training loss: 4.129210948944092
Validation loss: 4.6426601032558965
Epoch: 7| Step: 6
Training loss: 4.716860294342041
Validation loss: 4.635965429621635
Epoch: 7| Step: 7
Training loss: 5.259434700012207
Validation loss: 4.632526191876089
Epoch: 7| Step: 8
Training loss: 5.442254066467285
Validation loss: 4.628177423271344
Epoch: 7| Step: 9
Training loss: 5.826810359954834
Validation loss: 4.622358984226803
Epoch: 7| Step: 10
Training loss: 5.973719596862793
Validation loss: 4.6169137474444275
Epoch: 7| Step: 11
Training loss: 4.256893634796143
Validation loss: 4.611523621373897
Epoch: 7| Step: 12
Training loss: 3.346343517303467
Validation loss: 4.60518513137488
Epoch: 7| Step: 13
Training loss: 5.125433444976807
Validation loss: 4.6027096569966925
Epoch: 7| Step: 14
Training loss: 4.2708330154418945
Validation loss: 4.59695540572242
Epoch: 7| Step: 15
Training loss: 4.153021812438965
Validation loss: 4.590609337786119
Epoch: 3| Step: 0
Training loss: 5.5026021003723145
Validation loss: 4.585647366887374
Epoch: 7| Step: 1
Training loss: 4.050580024719238
Validation loss: 4.581880514570277
Epoch: 7| Step: 2
Training loss: 4.528048515319824
Validation loss: 4.574095259467475
Epoch: 7| Step: 3
Training loss: 5.051287651062012
Validation loss: 4.56987215289109
Epoch: 7| Step: 4
Training loss: 4.288987159729004
Validation loss: 4.564967340702633
Epoch: 7| Step: 5
Training loss: 4.0349440574646
Validation loss: 4.559321472113081
Epoch: 7| Step: 6
Training loss: 5.789254188537598
Validation loss: 4.5519232749938965
Epoch: 7| Step: 7
Training loss: 5.334432601928711
Validation loss: 4.549043075643855
Epoch: 7| Step: 8
Training loss: 4.42685079574585
Validation loss: 4.540019793476132
Epoch: 7| Step: 9
Training loss: 5.314670562744141
Validation loss: 4.535218163359937
Epoch: 7| Step: 10
Training loss: 4.298436164855957
Validation loss: 4.52995314700998
Epoch: 7| Step: 11
Training loss: 5.268773555755615
Validation loss: 4.522119686757918
Epoch: 7| Step: 12
Training loss: 4.302329063415527
Validation loss: 4.515925822498129
Epoch: 7| Step: 13
Training loss: 4.144251823425293
Validation loss: 4.510838796766542
Epoch: 7| Step: 14
Training loss: 4.566330432891846
Validation loss: 4.503957033157349
Epoch: 7| Step: 15
Training loss: 4.564309597015381
Validation loss: 4.498201397683123
Epoch: 4| Step: 0
Training loss: 4.232438087463379
Validation loss: 4.4911002495306
Epoch: 7| Step: 1
Training loss: 3.6970887184143066
Validation loss: 4.480823715813726
Epoch: 7| Step: 2
Training loss: 5.130765438079834
Validation loss: 4.47641366162746
Epoch: 7| Step: 3
Training loss: 4.645809650421143
Validation loss: 4.468985910895917
Epoch: 7| Step: 4
Training loss: 4.2840704917907715
Validation loss: 4.46113155214049
Epoch: 7| Step: 5
Training loss: 4.963789939880371
Validation loss: 4.455473093677767
Epoch: 7| Step: 6
Training loss: 4.0861382484436035
Validation loss: 4.447413026000098
Epoch: 7| Step: 7
Training loss: 4.645961761474609
Validation loss: 4.440720431238628
Epoch: 7| Step: 8
Training loss: 5.660696029663086
Validation loss: 4.432573397382558
Epoch: 7| Step: 9
Training loss: 4.675303936004639
Validation loss: 4.4268003093252934
Epoch: 7| Step: 10
Training loss: 4.848055362701416
Validation loss: 4.421070918762426
Epoch: 7| Step: 11
Training loss: 4.731133460998535
Validation loss: 4.41018806773124
Epoch: 7| Step: 12
Training loss: 5.200982093811035
Validation loss: 4.403870128041548
Epoch: 7| Step: 13
Training loss: 4.308186054229736
Validation loss: 4.395898595988322
Epoch: 7| Step: 14
Training loss: 3.7795403003692627
Validation loss: 4.388362088649393
Epoch: 7| Step: 15
Training loss: 5.036715507507324
Validation loss: 4.378104528934836
Epoch: 5| Step: 0
Training loss: 3.422825336456299
Validation loss: 4.372824548817367
Epoch: 7| Step: 1
Training loss: 4.047915935516357
Validation loss: 4.36427331828385
Epoch: 7| Step: 2
Training loss: 5.844867706298828
Validation loss: 4.355292934307949
Epoch: 7| Step: 3
Training loss: 4.951386451721191
Validation loss: 4.34758212412004
Epoch: 7| Step: 4
Training loss: 4.580423355102539
Validation loss: 4.339388898808322
Epoch: 7| Step: 5
Training loss: 4.605295658111572
Validation loss: 4.329401817253168
Epoch: 7| Step: 6
Training loss: 4.3633036613464355
Validation loss: 4.32242083034927
Epoch: 7| Step: 7
Training loss: 4.651035308837891
Validation loss: 4.318062408364934
Epoch: 7| Step: 8
Training loss: 4.65712833404541
Validation loss: 4.306659839136137
Epoch: 7| Step: 9
Training loss: 4.550046920776367
Validation loss: 4.2953351761797345
Epoch: 7| Step: 10
Training loss: 3.9448940753936768
Validation loss: 4.289822382892636
Epoch: 7| Step: 11
Training loss: 5.335399627685547
Validation loss: 4.276894579688422
Epoch: 7| Step: 12
Training loss: 4.2588701248168945
Validation loss: 4.266914667843057
Epoch: 7| Step: 13
Training loss: 4.325738430023193
Validation loss: 4.260673505796803
Epoch: 7| Step: 14
Training loss: 4.4382243156433105
Validation loss: 4.252780084129718
Epoch: 7| Step: 15
Training loss: 4.151623249053955
Validation loss: 4.242956062015012
Epoch: 6| Step: 0
Training loss: 4.669718265533447
Validation loss: 4.2340826919610555
Epoch: 7| Step: 1
Training loss: 5.142195701599121
Validation loss: 4.223136455892659
Epoch: 7| Step: 2
Training loss: 5.579649925231934
Validation loss: 4.2150678634643555
Epoch: 7| Step: 3
Training loss: 4.045147895812988
Validation loss: 4.2016047179270135
Epoch: 7| Step: 4
Training loss: 4.00535249710083
Validation loss: 4.194235084725799
Epoch: 7| Step: 5
Training loss: 4.649716854095459
Validation loss: 4.185099780130729
Epoch: 7| Step: 6
Training loss: 3.498387575149536
Validation loss: 4.175012651964915
Epoch: 7| Step: 7
Training loss: 4.599242687225342
Validation loss: 4.162779430691287
Epoch: 7| Step: 8
Training loss: 5.149943828582764
Validation loss: 4.1522747132417965
Epoch: 7| Step: 9
Training loss: 4.782362461090088
Validation loss: 4.143236043641893
Epoch: 7| Step: 10
Training loss: 4.107958793640137
Validation loss: 4.136918709432479
Epoch: 7| Step: 11
Training loss: 3.7168312072753906
Validation loss: 4.118156772723301
Epoch: 7| Step: 12
Training loss: 4.783202171325684
Validation loss: 4.111803037657155
Epoch: 7| Step: 13
Training loss: 3.7197861671447754
Validation loss: 4.098823886981114
Epoch: 7| Step: 14
Training loss: 3.256556272506714
Validation loss: 4.0898831216551415
Epoch: 7| Step: 15
Training loss: 4.3205671310424805
Validation loss: 4.078152069942557
Epoch: 7| Step: 0
Training loss: 3.496089458465576
Validation loss: 4.066205707385386
Epoch: 7| Step: 1
Training loss: 4.1491899490356445
Validation loss: 4.0556448260657225
Epoch: 7| Step: 2
Training loss: 3.9170773029327393
Validation loss: 4.044373412784055
Epoch: 7| Step: 3
Training loss: 5.012154579162598
Validation loss: 4.032453950360525
Epoch: 7| Step: 4
Training loss: 3.9945907592773438
Validation loss: 4.021153772477623
Epoch: 7| Step: 5
Training loss: 4.7811055183410645
Validation loss: 4.006710028476852
Epoch: 7| Step: 6
Training loss: 3.771469831466675
Validation loss: 3.9955145643769407
Epoch: 7| Step: 7
Training loss: 5.091573238372803
Validation loss: 3.9844733793958484
Epoch: 7| Step: 8
Training loss: 5.022503852844238
Validation loss: 3.9733199764498703
Epoch: 7| Step: 9
Training loss: 3.435870409011841
Validation loss: 3.9607167827139658
Epoch: 7| Step: 10
Training loss: 4.162837028503418
Validation loss: 3.9477630107522867
Epoch: 7| Step: 11
Training loss: 4.228893280029297
Validation loss: 3.9314366587631993
Epoch: 7| Step: 12
Training loss: 4.411332607269287
Validation loss: 3.921852719011924
Epoch: 7| Step: 13
Training loss: 4.157177925109863
Validation loss: 3.9075643913351374
Epoch: 7| Step: 14
Training loss: 4.148342609405518
Validation loss: 3.897015336606142
Epoch: 7| Step: 15
Training loss: 3.792433261871338
Validation loss: 3.8815149609133495
Epoch: 8| Step: 0
Training loss: 3.8674094676971436
Validation loss: 3.8657309288601223
Epoch: 7| Step: 1
Training loss: 4.587793827056885
Validation loss: 3.8487966352229495
Epoch: 7| Step: 2
Training loss: 3.547618865966797
Validation loss: 3.83860274184522
Epoch: 7| Step: 3
Training loss: 3.7535877227783203
Validation loss: 3.824094902697227
Epoch: 7| Step: 4
Training loss: 3.987344741821289
Validation loss: 3.8075184033071396
Epoch: 7| Step: 5
Training loss: 4.557446002960205
Validation loss: 3.793687194371395
Epoch: 7| Step: 6
Training loss: 4.165947914123535
Validation loss: 3.7798118213955445
Epoch: 7| Step: 7
Training loss: 4.246065616607666
Validation loss: 3.7631056360203585
Epoch: 7| Step: 8
Training loss: 3.7263855934143066
Validation loss: 3.7478059487377138
Epoch: 7| Step: 9
Training loss: 4.332461833953857
Validation loss: 3.7303707633944723
Epoch: 7| Step: 10
Training loss: 4.5647292137146
Validation loss: 3.7143862470448448
Epoch: 7| Step: 11
Training loss: 3.586409330368042
Validation loss: 3.69975175445886
Epoch: 7| Step: 12
Training loss: 3.5305278301239014
Validation loss: 3.6831661917322833
Epoch: 7| Step: 13
Training loss: 4.713179111480713
Validation loss: 3.6660635231210175
Epoch: 7| Step: 14
Training loss: 4.069415092468262
Validation loss: 3.6532845788722415
Epoch: 7| Step: 15
Training loss: 3.5025570392608643
Validation loss: 3.6338784180099157
Epoch: 9| Step: 0
Training loss: 3.0123982429504395
Validation loss: 3.61881470851761
Epoch: 7| Step: 1
Training loss: 4.998764514923096
Validation loss: 3.6014978079487094
Epoch: 7| Step: 2
Training loss: 4.009418487548828
Validation loss: 3.5770511867331085
Epoch: 7| Step: 3
Training loss: 4.348859786987305
Validation loss: 3.5644797661321626
Epoch: 7| Step: 4
Training loss: 3.8722827434539795
Validation loss: 3.5445365597018235
Epoch: 7| Step: 5
Training loss: 3.238978624343872
Validation loss: 3.5305179520476635
Epoch: 7| Step: 6
Training loss: 4.456489086151123
Validation loss: 3.5094744884710516
Epoch: 7| Step: 7
Training loss: 3.94584584236145
Validation loss: 3.482331203899795
Epoch: 7| Step: 8
Training loss: 4.4638848304748535
Validation loss: 3.468027778666654
Epoch: 7| Step: 9
Training loss: 3.4628562927246094
Validation loss: 3.446670756923209
Epoch: 7| Step: 10
Training loss: 3.2276573181152344
Validation loss: 3.4290428693345985
Epoch: 7| Step: 11
Training loss: 4.256235599517822
Validation loss: 3.411505851814215
Epoch: 7| Step: 12
Training loss: 3.844409942626953
Validation loss: 3.3903474327471614
Epoch: 7| Step: 13
Training loss: 3.0390801429748535
Validation loss: 3.3681347009946974
Epoch: 7| Step: 14
Training loss: 3.009664297103882
Validation loss: 3.3552216677356967
Epoch: 7| Step: 15
Training loss: 4.101574897766113
Validation loss: 3.33203403555232
Epoch: 10| Step: 0
Training loss: 4.191946983337402
Validation loss: 3.309580408411918
Epoch: 7| Step: 1
Training loss: 2.805854320526123
Validation loss: 3.290412185861052
Epoch: 7| Step: 2
Training loss: 3.4366087913513184
Validation loss: 3.2660527984015375
Epoch: 7| Step: 3
Training loss: 3.662780284881592
Validation loss: 3.2508606876400736
Epoch: 7| Step: 4
Training loss: 3.7480857372283936
Validation loss: 3.233106846432034
Epoch: 7| Step: 5
Training loss: 3.4369311332702637
Validation loss: 3.210024502637575
Epoch: 7| Step: 6
Training loss: 2.983121395111084
Validation loss: 3.1871532141733514
Epoch: 7| Step: 7
Training loss: 3.2270545959472656
Validation loss: 3.1662525633256213
Epoch: 7| Step: 8
Training loss: 4.011357307434082
Validation loss: 3.1365247827639684
Epoch: 7| Step: 9
Training loss: 2.8995590209960938
Validation loss: 3.118610018448864
Epoch: 7| Step: 10
Training loss: 3.804079532623291
Validation loss: 3.090773007852568
Epoch: 7| Step: 11
Training loss: 4.007790565490723
Validation loss: 3.071107463013354
Epoch: 7| Step: 12
Training loss: 4.096480846405029
Validation loss: 3.054991288150815
Epoch: 7| Step: 13
Training loss: 2.936885356903076
Validation loss: 3.0263549646885277
Epoch: 7| Step: 14
Training loss: 3.571075916290283
Validation loss: 2.9950985359630997
Epoch: 7| Step: 15
Training loss: 4.286368370056152
Validation loss: 2.9820753310224135
Epoch: 11| Step: 0
Training loss: 4.308197498321533
Validation loss: 2.9527593053502144
Epoch: 7| Step: 1
Training loss: 3.6754367351531982
Validation loss: 2.933360604073504
Epoch: 7| Step: 2
Training loss: 2.618467330932617
Validation loss: 2.9161890136252206
Epoch: 7| Step: 3
Training loss: 2.8520712852478027
Validation loss: 2.882540351195301
Epoch: 7| Step: 4
Training loss: 2.788933277130127
Validation loss: 2.8526219429729656
Epoch: 7| Step: 5
Training loss: 2.991103410720825
Validation loss: 2.8317365234704326
Epoch: 7| Step: 6
Training loss: 2.630171298980713
Validation loss: 2.8125597898908654
Epoch: 7| Step: 7
Training loss: 4.395318984985352
Validation loss: 2.792656341045023
Epoch: 7| Step: 8
Training loss: 2.2619576454162598
Validation loss: 2.76332919031596
Epoch: 7| Step: 9
Training loss: 3.0047669410705566
Validation loss: 2.738270013452434
Epoch: 7| Step: 10
Training loss: 3.8259291648864746
Validation loss: 2.718521185058484
Epoch: 7| Step: 11
Training loss: 4.036880016326904
Validation loss: 2.6902182393794436
Epoch: 7| Step: 12
Training loss: 3.5016448497772217
Validation loss: 2.6838387997030355
Epoch: 7| Step: 13
Training loss: 2.905977725982666
Validation loss: 2.6466126699241803
Epoch: 7| Step: 14
Training loss: 3.3722007274627686
Validation loss: 2.640152428647597
Epoch: 7| Step: 15
Training loss: 3.1914026737213135
Validation loss: 2.61345135222236
Epoch: 12| Step: 0
Training loss: 2.329432249069214
Validation loss: 2.5831246633323834
Epoch: 7| Step: 1
Training loss: 3.096177339553833
Validation loss: 2.5633816753360006
Epoch: 7| Step: 2
Training loss: 3.7392935752868652
Validation loss: 2.5413796112691758
Epoch: 7| Step: 3
Training loss: 3.4389405250549316
Validation loss: 2.5085029190392802
Epoch: 7| Step: 4
Training loss: 3.4598031044006348
Validation loss: 2.4864658674747826
Epoch: 7| Step: 5
Training loss: 3.226330518722534
Validation loss: 2.4593802510405616
Epoch: 7| Step: 6
Training loss: 3.347322940826416
Validation loss: 2.4419923068808136
Epoch: 7| Step: 7
Training loss: 2.946528911590576
Validation loss: 2.4162786933157943
Epoch: 7| Step: 8
Training loss: 3.1049225330352783
Validation loss: 2.3870212637263237
Epoch: 7| Step: 9
Training loss: 3.179863452911377
Validation loss: 2.3702480921642386
Epoch: 7| Step: 10
Training loss: 3.241682529449463
Validation loss: 2.350553217551691
Epoch: 7| Step: 11
Training loss: 2.859405517578125
Validation loss: 2.3065506777317406
Epoch: 7| Step: 12
Training loss: 2.101006031036377
Validation loss: 2.2804447163780814
Epoch: 7| Step: 13
Training loss: 2.6484694480895996
Validation loss: 2.278352967269129
Epoch: 7| Step: 14
Training loss: 2.5047836303710938
Validation loss: 2.2578078465496034
Epoch: 7| Step: 15
Training loss: 2.1202149391174316
Validation loss: 2.2314576605241077
Epoch: 13| Step: 0
Training loss: 2.8113667964935303
Validation loss: 2.21824176191426
Epoch: 7| Step: 1
Training loss: 2.4367103576660156
Validation loss: 2.195931122457381
Epoch: 7| Step: 2
Training loss: 2.8070061206817627
Validation loss: 2.1699131306984443
Epoch: 7| Step: 3
Training loss: 2.7720799446105957
Validation loss: 2.1528677563015504
Epoch: 7| Step: 4
Training loss: 2.368725299835205
Validation loss: 2.119468756716886
Epoch: 7| Step: 5
Training loss: 2.6745200157165527
Validation loss: 2.1047176285613354
Epoch: 7| Step: 6
Training loss: 2.3691742420196533
Validation loss: 2.088897641614187
Epoch: 7| Step: 7
Training loss: 2.4168505668640137
Validation loss: 2.0600538734051823
Epoch: 7| Step: 8
Training loss: 3.195748805999756
Validation loss: 2.049274194154808
Epoch: 7| Step: 9
Training loss: 2.6545188426971436
Validation loss: 2.0291806828203818
Epoch: 7| Step: 10
Training loss: 2.7800889015197754
Validation loss: 2.014073895035888
Epoch: 7| Step: 11
Training loss: 2.5662624835968018
Validation loss: 2.0113939261264937
Epoch: 7| Step: 12
Training loss: 2.392990827560425
Validation loss: 1.9818310952015061
Epoch: 7| Step: 13
Training loss: 2.773275852203369
Validation loss: 1.9541847062625473
Epoch: 7| Step: 14
Training loss: 2.7680442333221436
Validation loss: 1.94202567690568
Epoch: 7| Step: 15
Training loss: 2.083676338195801
Validation loss: 1.9338441358195793
Epoch: 14| Step: 0
Training loss: 2.587984323501587
Validation loss: 1.9125486295000256
Epoch: 7| Step: 1
Training loss: 2.284503936767578
Validation loss: 1.8885432087260186
Epoch: 7| Step: 2
Training loss: 2.785301685333252
Validation loss: 1.876853820231321
Epoch: 7| Step: 3
Training loss: 2.672032117843628
Validation loss: 1.8614168913244344
Epoch: 7| Step: 4
Training loss: 2.314124822616577
Validation loss: 1.8505083331101233
Epoch: 7| Step: 5
Training loss: 2.7147068977355957
Validation loss: 1.8430667986972726
Epoch: 7| Step: 6
Training loss: 1.342202067375183
Validation loss: 1.8270855996248534
Epoch: 7| Step: 7
Training loss: 2.5195164680480957
Validation loss: 1.8166329337538576
Epoch: 7| Step: 8
Training loss: 2.052873373031616
Validation loss: 1.7893206421419872
Epoch: 7| Step: 9
Training loss: 2.324465274810791
Validation loss: 1.7866331596168683
Epoch: 7| Step: 10
Training loss: 2.6264729499816895
Validation loss: 1.7773998281080945
Epoch: 7| Step: 11
Training loss: 2.452357769012451
Validation loss: 1.752020251836708
Epoch: 7| Step: 12
Training loss: 1.8610156774520874
Validation loss: 1.773624604554485
Epoch: 7| Step: 13
Training loss: 2.2664847373962402
Validation loss: 1.7603913605641976
Epoch: 7| Step: 14
Training loss: 2.1982431411743164
Validation loss: 1.7483713283813258
Epoch: 7| Step: 15
Training loss: 2.296553134918213
Validation loss: 1.748589188074894
Epoch: 15| Step: 0
Training loss: 2.202099323272705
Validation loss: 1.737433219127518
Epoch: 7| Step: 1
Training loss: 2.2209339141845703
Validation loss: 1.7263106142016624
Epoch: 7| Step: 2
Training loss: 2.8336217403411865
Validation loss: 1.7285625145589705
Epoch: 7| Step: 3
Training loss: 1.8918451070785522
Validation loss: 1.758131912286333
Epoch: 7| Step: 4
Training loss: 2.313371181488037
Validation loss: 1.7285943382935558
Epoch: 7| Step: 5
Training loss: 2.5256805419921875
Validation loss: 1.734863552258169
Epoch: 7| Step: 6
Training loss: 2.0344908237457275
Validation loss: 1.7516108125233822
Epoch: 7| Step: 7
Training loss: 2.0051846504211426
Validation loss: 1.7464906431788163
Epoch: 7| Step: 8
Training loss: 2.1806328296661377
Validation loss: 1.7497594099250628
Epoch: 7| Step: 9
Training loss: 1.7741718292236328
Validation loss: 1.770381495249357
Epoch: 7| Step: 10
Training loss: 1.7535293102264404
Validation loss: 1.7337908427492321
Epoch: 7| Step: 11
Training loss: 2.205824375152588
Validation loss: 1.736475130636915
Epoch: 7| Step: 12
Training loss: 1.9477370977401733
Validation loss: 1.7592636355393225
Epoch: 7| Step: 13
Training loss: 2.7361373901367188
Validation loss: 1.7489035644119593
Epoch: 7| Step: 14
Training loss: 2.088693141937256
Validation loss: 1.7860842471500096
Epoch: 7| Step: 15
Training loss: 2.257601261138916
Validation loss: 1.7938354332670032
Epoch: 16| Step: 0
Training loss: 2.024730682373047
Validation loss: 1.7971811834856761
Epoch: 7| Step: 1
Training loss: 2.3258416652679443
Validation loss: 1.7994021408849483
Epoch: 7| Step: 2
Training loss: 1.7809064388275146
Validation loss: 1.8261408291274694
Epoch: 7| Step: 3
Training loss: 2.364257335662842
Validation loss: 1.8303410972622658
Epoch: 7| Step: 4
Training loss: 2.4529480934143066
Validation loss: 1.8034514360290637
Epoch: 7| Step: 5
Training loss: 2.358562469482422
Validation loss: 1.8372239226059948
Epoch: 7| Step: 6
Training loss: 1.7484592199325562
Validation loss: 1.8312782426532224
Epoch: 7| Step: 7
Training loss: 2.199580669403076
Validation loss: 1.8423258812307455
Epoch: 7| Step: 8
Training loss: 1.6304006576538086
Validation loss: 1.8390979878336406
Epoch: 7| Step: 9
Training loss: 2.058048725128174
Validation loss: 1.8546707475785729
Epoch: 7| Step: 10
Training loss: 2.077108144760132
Validation loss: 1.877913325810604
Epoch: 7| Step: 11
Training loss: 2.303246259689331
Validation loss: 1.8664689475683858
Epoch: 7| Step: 12
Training loss: 2.550631523132324
Validation loss: 1.8827579064334896
Epoch: 7| Step: 13
Training loss: 1.9207627773284912
Validation loss: 1.893636331283789
Epoch: 7| Step: 14
Training loss: 1.8344900608062744
Validation loss: 1.9117191180908422
Epoch: 7| Step: 15
Training loss: 2.6372528076171875
Validation loss: 1.8838350704248004
Epoch: 17| Step: 0
Training loss: 2.3035755157470703
Validation loss: 1.885006300837016
Epoch: 7| Step: 1
Training loss: 2.2583158016204834
Validation loss: 1.891370707278629
Epoch: 7| Step: 2
Training loss: 1.9683536291122437
Validation loss: 1.8723455881900926
Epoch: 7| Step: 3
Training loss: 1.9696438312530518
Validation loss: 1.8931805650107294
Epoch: 7| Step: 4
Training loss: 1.8476002216339111
Validation loss: 1.8725062034112945
Epoch: 7| Step: 5
Training loss: 1.6855888366699219
Validation loss: 1.8810271453514373
Epoch: 7| Step: 6
Training loss: 1.5579735040664673
Validation loss: 1.9012456454819056
Epoch: 7| Step: 7
Training loss: 2.562516927719116
Validation loss: 1.8945360749745541
Epoch: 7| Step: 8
Training loss: 1.9266185760498047
Validation loss: 1.8851841988323403
Epoch: 7| Step: 9
Training loss: 2.052830219268799
Validation loss: 1.9042924050804522
Epoch: 7| Step: 10
Training loss: 2.392737627029419
Validation loss: 1.8739984841655484
Epoch: 7| Step: 11
Training loss: 1.982507348060608
Validation loss: 1.8857572524667643
Epoch: 7| Step: 12
Training loss: 2.2923500537872314
Validation loss: 1.8767911650294022
Epoch: 7| Step: 13
Training loss: 2.5373058319091797
Validation loss: 1.853853820039214
Epoch: 7| Step: 14
Training loss: 2.3883631229400635
Validation loss: 1.8730108094729965
Epoch: 7| Step: 15
Training loss: 2.2148895263671875
Validation loss: 1.877852621695978
Epoch: 18| Step: 0
Training loss: 2.20784592628479
Validation loss: 1.8850223554981698
Epoch: 7| Step: 1
Training loss: 1.8851604461669922
Validation loss: 1.86435262419337
Epoch: 7| Step: 2
Training loss: 2.0329508781433105
Validation loss: 1.8953511123176958
Epoch: 7| Step: 3
Training loss: 2.1405203342437744
Validation loss: 1.8664904755654095
Epoch: 7| Step: 4
Training loss: 2.176149368286133
Validation loss: 1.8563719687701987
Epoch: 7| Step: 5
Training loss: 1.8915927410125732
Validation loss: 1.8429974549108272
Epoch: 7| Step: 6
Training loss: 2.1441221237182617
Validation loss: 1.8686849719328846
Epoch: 7| Step: 7
Training loss: 2.5262160301208496
Validation loss: 1.8685920101275546
Epoch: 7| Step: 8
Training loss: 1.880213975906372
Validation loss: 1.829815978626553
Epoch: 7| Step: 9
Training loss: 2.345062732696533
Validation loss: 1.8452929644275913
Epoch: 7| Step: 10
Training loss: 1.8611112833023071
Validation loss: 1.8550977320979825
Epoch: 7| Step: 11
Training loss: 2.315774440765381
Validation loss: 1.849264375597453
Epoch: 7| Step: 12
Training loss: 2.149456739425659
Validation loss: 1.839254427299225
Epoch: 7| Step: 13
Training loss: 1.9907760620117188
Validation loss: 1.8482509362611839
Epoch: 7| Step: 14
Training loss: 2.2222800254821777
Validation loss: 1.8379184496488503
Epoch: 7| Step: 15
Training loss: 2.01223087310791
Validation loss: 1.8280586090019282
Epoch: 19| Step: 0
Training loss: 2.5993332862854004
Validation loss: 1.8752576207085478
Epoch: 7| Step: 1
Training loss: 2.5314364433288574
Validation loss: 1.8689138271825776
Epoch: 7| Step: 2
Training loss: 2.7784342765808105
Validation loss: 1.88148566801771
Epoch: 7| Step: 3
Training loss: 2.264744281768799
Validation loss: 1.8270300378044733
Epoch: 7| Step: 4
Training loss: 2.1373558044433594
Validation loss: 1.8592093282466313
Epoch: 7| Step: 5
Training loss: 1.612627387046814
Validation loss: 1.871459758538994
Epoch: 7| Step: 6
Training loss: 1.7915242910385132
Validation loss: 1.8752867926796564
Epoch: 7| Step: 7
Training loss: 1.8188068866729736
Validation loss: 1.874959471414415
Epoch: 7| Step: 8
Training loss: 1.6960703134536743
Validation loss: 1.8637658657787515
Epoch: 7| Step: 9
Training loss: 2.258934497833252
Validation loss: 1.8719751431787615
Epoch: 7| Step: 10
Training loss: 2.3210697174072266
Validation loss: 1.8736363211981684
Epoch: 7| Step: 11
Training loss: 1.912832260131836
Validation loss: 1.8590703876756078
Epoch: 7| Step: 12
Training loss: 1.9788272380828857
Validation loss: 1.8758871280889717
Epoch: 7| Step: 13
Training loss: 2.1593093872070312
Validation loss: 1.8769967384475599
Epoch: 7| Step: 14
Training loss: 2.121692657470703
Validation loss: 1.8564669228286195
Epoch: 7| Step: 15
Training loss: 1.779636025428772
Validation loss: 1.8538338014547773
Epoch: 20| Step: 0
Training loss: 2.3020107746124268
Validation loss: 1.8749749463239163
Epoch: 7| Step: 1
Training loss: 2.2739295959472656
Validation loss: 1.8579225214265234
Epoch: 7| Step: 2
Training loss: 2.3234381675720215
Validation loss: 1.8645232701473098
Epoch: 7| Step: 3
Training loss: 2.0477094650268555
Validation loss: 1.8768440519305443
Epoch: 7| Step: 4
Training loss: 2.986541509628296
Validation loss: 1.8609232876798232
Epoch: 7| Step: 5
Training loss: 2.095654249191284
Validation loss: 1.8775842121179156
Epoch: 7| Step: 6
Training loss: 1.4428993463516235
Validation loss: 1.862986744736596
Epoch: 7| Step: 7
Training loss: 2.5494706630706787
Validation loss: 1.88154102315148
Epoch: 7| Step: 8
Training loss: 2.570380687713623
Validation loss: 1.8684959651754915
Epoch: 7| Step: 9
Training loss: 2.2490363121032715
Validation loss: 1.8775324358356942
Epoch: 7| Step: 10
Training loss: 1.7434730529785156
Validation loss: 1.849639030669233
Epoch: 7| Step: 11
Training loss: 1.408318281173706
Validation loss: 1.8389753557795243
Epoch: 7| Step: 12
Training loss: 2.499110460281372
Validation loss: 1.8320160195124235
Epoch: 7| Step: 13
Training loss: 1.9463971853256226
Validation loss: 1.8421775308444346
Epoch: 7| Step: 14
Training loss: 1.3824338912963867
Validation loss: 1.86350836084901
Epoch: 7| Step: 15
Training loss: 2.0676493644714355
Validation loss: 1.8577191632428616
Epoch: 21| Step: 0
Training loss: 1.2844984531402588
Validation loss: 1.8548856707785626
Epoch: 7| Step: 1
Training loss: 1.5249547958374023
Validation loss: 1.8525496738420115
Epoch: 7| Step: 2
Training loss: 2.151090383529663
Validation loss: 1.850459887827043
Epoch: 7| Step: 3
Training loss: 2.4140429496765137
Validation loss: 1.8686671823048764
Epoch: 7| Step: 4
Training loss: 1.789331078529358
Validation loss: 1.9039153924091257
Epoch: 7| Step: 5
Training loss: 2.2187066078186035
Validation loss: 1.899656288915401
Epoch: 7| Step: 6
Training loss: 2.092942953109741
Validation loss: 1.8657926989973879
Epoch: 7| Step: 7
Training loss: 1.9336469173431396
Validation loss: 1.8852660038488374
Epoch: 7| Step: 8
Training loss: 2.8725273609161377
Validation loss: 1.9032268901523068
Epoch: 7| Step: 9
Training loss: 2.2325663566589355
Validation loss: 1.8796628919436777
Epoch: 7| Step: 10
Training loss: 2.6265740394592285
Validation loss: 1.880934536885872
Epoch: 7| Step: 11
Training loss: 2.089061737060547
Validation loss: 1.903563238733964
Epoch: 7| Step: 12
Training loss: 2.1719067096710205
Validation loss: 1.9041220730157207
Epoch: 7| Step: 13
Training loss: 2.322951555252075
Validation loss: 1.8918146744048854
Epoch: 7| Step: 14
Training loss: 2.219513416290283
Validation loss: 1.8733214800306361
Epoch: 7| Step: 15
Training loss: 1.9330869913101196
Validation loss: 1.8948185684011996
Epoch: 22| Step: 0
Training loss: 2.489593029022217
Validation loss: 1.8677858843220223
Epoch: 7| Step: 1
Training loss: 1.4418292045593262
Validation loss: 1.893397829515471
Epoch: 7| Step: 2
Training loss: 2.372559070587158
Validation loss: 1.8638913151171568
Epoch: 7| Step: 3
Training loss: 2.3201904296875
Validation loss: 1.8798959186608843
Epoch: 7| Step: 4
Training loss: 2.076826810836792
Validation loss: 1.8788994902329479
Epoch: 7| Step: 5
Training loss: 2.8005170822143555
Validation loss: 1.9058069282298467
Epoch: 7| Step: 6
Training loss: 2.1886324882507324
Validation loss: 1.8741991399861069
Epoch: 7| Step: 7
Training loss: 1.6155914068222046
Validation loss: 1.8618359994545257
Epoch: 7| Step: 8
Training loss: 2.1591246128082275
Validation loss: 1.8905890605432525
Epoch: 7| Step: 9
Training loss: 1.7420575618743896
Validation loss: 1.8698591860078222
Epoch: 7| Step: 10
Training loss: 1.9063669443130493
Validation loss: 1.8598232895350284
Epoch: 7| Step: 11
Training loss: 2.3963820934295654
Validation loss: 1.868543068282038
Epoch: 7| Step: 12
Training loss: 2.037078857421875
Validation loss: 1.8578153136822817
Epoch: 7| Step: 13
Training loss: 1.9653123617172241
Validation loss: 1.8625999448968351
Epoch: 7| Step: 14
Training loss: 2.145839214324951
Validation loss: 1.884269908177767
Epoch: 7| Step: 15
Training loss: 2.205583095550537
Validation loss: 1.8767192869735279
Epoch: 23| Step: 0
Training loss: 2.0329411029815674
Validation loss: 1.844595854230922
Epoch: 7| Step: 1
Training loss: 2.074350595474243
Validation loss: 1.8542084119302764
Epoch: 7| Step: 2
Training loss: 1.9921869039535522
Validation loss: 1.8623100664975831
Epoch: 7| Step: 3
Training loss: 2.523489475250244
Validation loss: 1.8518322826289444
Epoch: 7| Step: 4
Training loss: 1.973062515258789
Validation loss: 1.836541731580556
Epoch: 7| Step: 5
Training loss: 2.881568193435669
Validation loss: 1.8693886497895496
Epoch: 7| Step: 6
Training loss: 1.776497483253479
Validation loss: 1.8601263555691396
Epoch: 7| Step: 7
Training loss: 2.1967711448669434
Validation loss: 1.8482402854686162
Epoch: 7| Step: 8
Training loss: 2.2401113510131836
Validation loss: 1.862520974317043
Epoch: 7| Step: 9
Training loss: 1.5686593055725098
Validation loss: 1.8742023912265147
Epoch: 7| Step: 10
Training loss: 1.9458109140396118
Validation loss: 1.8611604326920543
Epoch: 7| Step: 11
Training loss: 1.8899097442626953
Validation loss: 1.8669768614734676
Epoch: 7| Step: 12
Training loss: 2.0435492992401123
Validation loss: 1.8579779889086168
Epoch: 7| Step: 13
Training loss: 2.198090076446533
Validation loss: 1.8707054133037868
Epoch: 7| Step: 14
Training loss: 2.4465606212615967
Validation loss: 1.8657828029111134
Epoch: 7| Step: 15
Training loss: 1.9638456106185913
Validation loss: 1.8562889219188003
Epoch: 24| Step: 0
Training loss: 2.0720736980438232
Validation loss: 1.844303895243638
Epoch: 7| Step: 1
Training loss: 1.6154447793960571
Validation loss: 1.8439817342826788
Epoch: 7| Step: 2
Training loss: 2.212573528289795
Validation loss: 1.8222451758899276
Epoch: 7| Step: 3
Training loss: 1.67523992061615
Validation loss: 1.8513234364900657
Epoch: 7| Step: 4
Training loss: 1.927474021911621
Validation loss: 1.8379716521544422
Epoch: 7| Step: 5
Training loss: 2.1692264080047607
Validation loss: 1.8367067849893364
Epoch: 7| Step: 6
Training loss: 2.4441750049591064
Validation loss: 1.845648521999661
Epoch: 7| Step: 7
Training loss: 2.19195818901062
Validation loss: 1.8487922999498656
Epoch: 7| Step: 8
Training loss: 1.9301716089248657
Validation loss: 1.856462815682665
Epoch: 7| Step: 9
Training loss: 2.5495784282684326
Validation loss: 1.859710770545246
Epoch: 7| Step: 10
Training loss: 2.1361687183380127
Validation loss: 1.857573167883235
Epoch: 7| Step: 11
Training loss: 1.9038770198822021
Validation loss: 1.8517129404081716
Epoch: 7| Step: 12
Training loss: 1.8845374584197998
Validation loss: 1.8592187835158205
Epoch: 7| Step: 13
Training loss: 2.047733783721924
Validation loss: 1.8542924982180697
Epoch: 7| Step: 14
Training loss: 2.4739959239959717
Validation loss: 1.8737843928577231
Epoch: 7| Step: 15
Training loss: 2.5030646324157715
Validation loss: 1.8672395713037724
Epoch: 25| Step: 0
Training loss: 2.0144870281219482
Validation loss: 1.8515790512235901
Epoch: 7| Step: 1
Training loss: 2.327664613723755
Validation loss: 1.8742337724287732
Epoch: 7| Step: 2
Training loss: 1.8997411727905273
Validation loss: 1.886573573668226
Epoch: 7| Step: 3
Training loss: 2.5860486030578613
Validation loss: 1.8802301952307172
Epoch: 7| Step: 4
Training loss: 1.7888834476470947
Validation loss: 1.8698100220385214
Epoch: 7| Step: 5
Training loss: 2.134772777557373
Validation loss: 1.8592573327126263
Epoch: 7| Step: 6
Training loss: 1.745367407798767
Validation loss: 1.871467320181483
Epoch: 7| Step: 7
Training loss: 2.335768222808838
Validation loss: 1.8394416665001738
Epoch: 7| Step: 8
Training loss: 1.768296480178833
Validation loss: 1.87136594340098
Epoch: 7| Step: 9
Training loss: 2.5811166763305664
Validation loss: 1.8663196846735564
Epoch: 7| Step: 10
Training loss: 1.715441107749939
Validation loss: 1.8584054073841452
Epoch: 7| Step: 11
Training loss: 1.69060480594635
Validation loss: 1.869391756949665
Epoch: 7| Step: 12
Training loss: 2.6377153396606445
Validation loss: 1.861455502269937
Epoch: 7| Step: 13
Training loss: 2.052493095397949
Validation loss: 1.8676075386486466
Epoch: 7| Step: 14
Training loss: 2.1108860969543457
Validation loss: 1.863765280881374
Epoch: 7| Step: 15
Training loss: 2.154040575027466
Validation loss: 1.8613942595694561
Epoch: 26| Step: 0
Training loss: 2.3512229919433594
Validation loss: 1.8698967206392356
Epoch: 7| Step: 1
Training loss: 1.7679965496063232
Validation loss: 1.8548085166395998
Epoch: 7| Step: 2
Training loss: 2.241384506225586
Validation loss: 1.859615934838494
Epoch: 7| Step: 3
Training loss: 1.7470098733901978
Validation loss: 1.8960559076542476
Epoch: 7| Step: 4
Training loss: 2.031648635864258
Validation loss: 1.8906227830502627
Epoch: 7| Step: 5
Training loss: 1.9753093719482422
Validation loss: 1.8668221827033613
Epoch: 7| Step: 6
Training loss: 2.5324320793151855
Validation loss: 1.8643689807370412
Epoch: 7| Step: 7
Training loss: 2.0853428840637207
Validation loss: 1.8472173814293291
Epoch: 7| Step: 8
Training loss: 1.8947566747665405
Validation loss: 1.8572612331925535
Epoch: 7| Step: 9
Training loss: 1.6755222082138062
Validation loss: 1.872272241029808
Epoch: 7| Step: 10
Training loss: 2.4389758110046387
Validation loss: 1.874999259015639
Epoch: 7| Step: 11
Training loss: 2.2312703132629395
Validation loss: 1.8504753498722324
Epoch: 7| Step: 12
Training loss: 2.295053482055664
Validation loss: 1.880298185691559
Epoch: 7| Step: 13
Training loss: 1.9833908081054688
Validation loss: 1.8830108899864362
Epoch: 7| Step: 14
Training loss: 2.161682367324829
Validation loss: 1.8674987331568766
Epoch: 7| Step: 15
Training loss: 2.325507402420044
Validation loss: 1.849073525812986
Epoch: 27| Step: 0
Training loss: 2.5193092823028564
Validation loss: 1.870422343555972
Epoch: 7| Step: 1
Training loss: 2.0895848274230957
Validation loss: 1.8690826120994073
Epoch: 7| Step: 2
Training loss: 2.4838075637817383
Validation loss: 1.8852601754579612
Epoch: 7| Step: 3
Training loss: 2.191599130630493
Validation loss: 1.8686638101399373
Epoch: 7| Step: 4
Training loss: 1.6948903799057007
Validation loss: 1.8664648164090494
Epoch: 7| Step: 5
Training loss: 2.4214425086975098
Validation loss: 1.8856516536191212
Epoch: 7| Step: 6
Training loss: 2.232290744781494
Validation loss: 1.8606574569674705
Epoch: 7| Step: 7
Training loss: 2.252561569213867
Validation loss: 1.8605416378528952
Epoch: 7| Step: 8
Training loss: 2.300142765045166
Validation loss: 1.8601804019735872
Epoch: 7| Step: 9
Training loss: 1.1599493026733398
Validation loss: 1.8644101868430487
Epoch: 7| Step: 10
Training loss: 1.8436568975448608
Validation loss: 1.8829599936231434
Epoch: 7| Step: 11
Training loss: 2.106388568878174
Validation loss: 1.8653371677124242
Epoch: 7| Step: 12
Training loss: 1.3976719379425049
Validation loss: 1.846216855289267
Epoch: 7| Step: 13
Training loss: 2.397979736328125
Validation loss: 1.8705125009413246
Epoch: 7| Step: 14
Training loss: 1.9835841655731201
Validation loss: 1.866782004027058
Epoch: 7| Step: 15
Training loss: 2.5788466930389404
Validation loss: 1.8562362614295465
Epoch: 28| Step: 0
Training loss: 1.7209457159042358
Validation loss: 1.8639168576370897
Epoch: 7| Step: 1
Training loss: 2.4913978576660156
Validation loss: 1.8669014414437384
Epoch: 7| Step: 2
Training loss: 2.415485143661499
Validation loss: 1.8530964980022513
Epoch: 7| Step: 3
Training loss: 2.2042431831359863
Validation loss: 1.8638075401457093
Epoch: 7| Step: 4
Training loss: 1.7711565494537354
Validation loss: 1.8703613144030673
Epoch: 7| Step: 5
Training loss: 2.23012113571167
Validation loss: 1.8430728380628627
Epoch: 7| Step: 6
Training loss: 1.5549371242523193
Validation loss: 1.8477241143905858
Epoch: 7| Step: 7
Training loss: 2.6290812492370605
Validation loss: 1.8631001959601752
Epoch: 7| Step: 8
Training loss: 1.6164252758026123
Validation loss: 1.8563976793838062
Epoch: 7| Step: 9
Training loss: 1.5782228708267212
Validation loss: 1.8444055704761753
Epoch: 7| Step: 10
Training loss: 3.0503673553466797
Validation loss: 1.8539079865105719
Epoch: 7| Step: 11
Training loss: 1.7795133590698242
Validation loss: 1.8580047381009988
Epoch: 7| Step: 12
Training loss: 1.8604857921600342
Validation loss: 1.8492165520894441
Epoch: 7| Step: 13
Training loss: 1.9173896312713623
Validation loss: 1.849235776517031
Epoch: 7| Step: 14
Training loss: 2.737126111984253
Validation loss: 1.8628957974824973
Epoch: 7| Step: 15
Training loss: 2.096754550933838
Validation loss: 1.856699310618339
Epoch: 29| Step: 0
Training loss: 2.09837007522583
Validation loss: 1.8480106540721097
Epoch: 7| Step: 1
Training loss: 1.4002310037612915
Validation loss: 1.8724356280813972
Epoch: 7| Step: 2
Training loss: 2.319901466369629
Validation loss: 1.8754350984696861
Epoch: 7| Step: 3
Training loss: 2.0266926288604736
Validation loss: 1.871918424427938
Epoch: 7| Step: 4
Training loss: 2.099867582321167
Validation loss: 1.8587731200156452
Epoch: 7| Step: 5
Training loss: 2.3520474433898926
Validation loss: 1.870645256351224
Epoch: 7| Step: 6
Training loss: 2.1106810569763184
Validation loss: 1.8691280025372403
Epoch: 7| Step: 7
Training loss: 1.9845831394195557
Validation loss: 1.8728719186439788
Epoch: 7| Step: 8
Training loss: 2.3849570751190186
Validation loss: 1.8776436126489433
Epoch: 7| Step: 9
Training loss: 1.806687355041504
Validation loss: 1.882703734816407
Epoch: 7| Step: 10
Training loss: 1.6553847789764404
Validation loss: 1.87461079624917
Epoch: 7| Step: 11
Training loss: 1.859667181968689
Validation loss: 1.8695546199949524
Epoch: 7| Step: 12
Training loss: 2.6486563682556152
Validation loss: 1.885118360142056
Epoch: 7| Step: 13
Training loss: 1.8662998676300049
Validation loss: 1.8753039562444893
Epoch: 7| Step: 14
Training loss: 2.414546012878418
Validation loss: 1.897708069506309
Epoch: 7| Step: 15
Training loss: 2.4309751987457275
Validation loss: 1.8771164537333755
Epoch: 30| Step: 0
Training loss: 2.1895461082458496
Validation loss: 1.8857038629998406
Epoch: 7| Step: 1
Training loss: 2.270191192626953
Validation loss: 1.8390314990667989
Epoch: 7| Step: 2
Training loss: 2.4367430210113525
Validation loss: 1.8598691233628089
Epoch: 7| Step: 3
Training loss: 2.222792863845825
Validation loss: 1.8602388556912648
Epoch: 7| Step: 4
Training loss: 1.5145742893218994
Validation loss: 1.8705072051329579
Epoch: 7| Step: 5
Training loss: 1.681862473487854
Validation loss: 1.8467766912721044
Epoch: 7| Step: 6
Training loss: 1.922533631324768
Validation loss: 1.8641420834356075
Epoch: 7| Step: 7
Training loss: 1.6450233459472656
Validation loss: 1.8405386586841062
Epoch: 7| Step: 8
Training loss: 1.9227955341339111
Validation loss: 1.8613044332257278
Epoch: 7| Step: 9
Training loss: 2.8595683574676514
Validation loss: 1.8712534149773687
Epoch: 7| Step: 10
Training loss: 2.2689433097839355
Validation loss: 1.8495448982115272
Epoch: 7| Step: 11
Training loss: 2.196138858795166
Validation loss: 1.8836756069883167
Epoch: 7| Step: 12
Training loss: 2.3975062370300293
Validation loss: 1.8904086557223643
Epoch: 7| Step: 13
Training loss: 1.8183788061141968
Validation loss: 1.8801397719829203
Epoch: 7| Step: 14
Training loss: 2.084865093231201
Validation loss: 1.879841283928576
Epoch: 7| Step: 15
Training loss: 2.22245454788208
Validation loss: 1.8803206716510033
Epoch: 31| Step: 0
Training loss: 1.5440412759780884
Validation loss: 1.875884839956709
Epoch: 7| Step: 1
Training loss: 2.2793047428131104
Validation loss: 1.8899189242356116
Epoch: 7| Step: 2
Training loss: 2.4111204147338867
Validation loss: 1.8977481581324296
Epoch: 7| Step: 3
Training loss: 2.135925531387329
Validation loss: 1.8773095719248272
Epoch: 7| Step: 4
Training loss: 2.344895601272583
Validation loss: 1.9130733819316617
Epoch: 7| Step: 5
Training loss: 2.3810877799987793
Validation loss: 1.866207885227615
Epoch: 7| Step: 6
Training loss: 1.7950998544692993
Validation loss: 1.904875393394086
Epoch: 7| Step: 7
Training loss: 3.17118501663208
Validation loss: 1.8736627513556172
Epoch: 7| Step: 8
Training loss: 1.4217407703399658
Validation loss: 1.8824133795799969
Epoch: 7| Step: 9
Training loss: 1.912440299987793
Validation loss: 1.8837497157158611
Epoch: 7| Step: 10
Training loss: 2.1688945293426514
Validation loss: 1.8800465134407978
Epoch: 7| Step: 11
Training loss: 2.1891977787017822
Validation loss: 1.8574630974008024
Epoch: 7| Step: 12
Training loss: 2.071298360824585
Validation loss: 1.83160808446596
Epoch: 7| Step: 13
Training loss: 2.337876558303833
Validation loss: 1.8456394217854781
Epoch: 7| Step: 14
Training loss: 1.415876030921936
Validation loss: 1.8556094744222627
Epoch: 7| Step: 15
Training loss: 1.9962800741195679
Validation loss: 1.817553445589628
Epoch: 32| Step: 0
Training loss: 1.933510184288025
Validation loss: 1.8412115368054067
Epoch: 7| Step: 1
Training loss: 2.1563467979431152
Validation loss: 1.872016895589211
Epoch: 7| Step: 2
Training loss: 2.057197093963623
Validation loss: 1.8468038075261837
Epoch: 7| Step: 3
Training loss: 1.5877681970596313
Validation loss: 1.8564292698455371
Epoch: 7| Step: 4
Training loss: 2.4920859336853027
Validation loss: 1.862925778190009
Epoch: 7| Step: 5
Training loss: 2.1794333457946777
Validation loss: 1.857259450198935
Epoch: 7| Step: 6
Training loss: 1.9267657995224
Validation loss: 1.8653421736449647
Epoch: 7| Step: 7
Training loss: 1.715696930885315
Validation loss: 1.8806717164224858
Epoch: 7| Step: 8
Training loss: 1.818172812461853
Validation loss: 1.8661793967802747
Epoch: 7| Step: 9
Training loss: 2.0041182041168213
Validation loss: 1.870379952218035
Epoch: 7| Step: 10
Training loss: 2.2046966552734375
Validation loss: 1.8646867815539134
Epoch: 7| Step: 11
Training loss: 2.1609935760498047
Validation loss: 1.867272912169532
Epoch: 7| Step: 12
Training loss: 2.5615320205688477
Validation loss: 1.8888386204945955
Epoch: 7| Step: 13
Training loss: 2.4224517345428467
Validation loss: 1.8848494814454222
Epoch: 7| Step: 14
Training loss: 2.010303497314453
Validation loss: 1.8726741135549203
Epoch: 7| Step: 15
Training loss: 2.191646099090576
Validation loss: 1.898582033116183
Epoch: 33| Step: 0
Training loss: 1.5364885330200195
Validation loss: 1.88201262281953
Epoch: 7| Step: 1
Training loss: 2.746535539627075
Validation loss: 1.8885469496678964
Epoch: 7| Step: 2
Training loss: 2.5340006351470947
Validation loss: 1.8633044340627656
Epoch: 7| Step: 3
Training loss: 2.044109582901001
Validation loss: 1.8662588750715736
Epoch: 7| Step: 4
Training loss: 2.581726551055908
Validation loss: 1.8762153447103158
Epoch: 7| Step: 5
Training loss: 2.1512765884399414
Validation loss: 1.8799383434460317
Epoch: 7| Step: 6
Training loss: 1.951088309288025
Validation loss: 1.8925209337001225
Epoch: 7| Step: 7
Training loss: 1.8523914813995361
Validation loss: 1.8796003842525344
Epoch: 7| Step: 8
Training loss: 1.9665664434432983
Validation loss: 1.8838996844325993
Epoch: 7| Step: 9
Training loss: 2.134983539581299
Validation loss: 1.8566331477473965
Epoch: 7| Step: 10
Training loss: 2.2725048065185547
Validation loss: 1.8949506385720891
Epoch: 7| Step: 11
Training loss: 2.1507699489593506
Validation loss: 1.9116367213160015
Epoch: 7| Step: 12
Training loss: 2.168856620788574
Validation loss: 1.9094717099512224
Epoch: 7| Step: 13
Training loss: 1.3986823558807373
Validation loss: 1.8982937884845321
Epoch: 7| Step: 14
Training loss: 2.018686294555664
Validation loss: 1.898203807769062
Epoch: 7| Step: 15
Training loss: 2.034114360809326
Validation loss: 1.9076061145864802
Epoch: 34| Step: 0
Training loss: 2.2950046062469482
Validation loss: 1.8825013380256488
Epoch: 7| Step: 1
Training loss: 1.968878149986267
Validation loss: 1.8817912734669746
Epoch: 7| Step: 2
Training loss: 1.866680383682251
Validation loss: 1.8939350123028103
Epoch: 7| Step: 3
Training loss: 2.1884922981262207
Validation loss: 1.910458219994744
Epoch: 7| Step: 4
Training loss: 2.025736093521118
Validation loss: 1.890037190999916
Epoch: 7| Step: 5
Training loss: 1.9493515491485596
Validation loss: 1.8819572676857599
Epoch: 7| Step: 6
Training loss: 2.279689311981201
Validation loss: 1.8747000428412457
Epoch: 7| Step: 7
Training loss: 1.7200357913970947
Validation loss: 1.8737835626808002
Epoch: 7| Step: 8
Training loss: 1.6041234731674194
Validation loss: 1.8816586741440589
Epoch: 7| Step: 9
Training loss: 2.2720065116882324
Validation loss: 1.8650794380860363
Epoch: 7| Step: 10
Training loss: 1.9693273305892944
Validation loss: 1.8783420916083906
Epoch: 7| Step: 11
Training loss: 2.696338415145874
Validation loss: 1.8759048156601061
Epoch: 7| Step: 12
Training loss: 1.938164472579956
Validation loss: 1.8667046414862434
Epoch: 7| Step: 13
Training loss: 2.43788480758667
Validation loss: 1.8648733749664088
Epoch: 7| Step: 14
Training loss: 1.7368266582489014
Validation loss: 1.8714810446869554
Epoch: 7| Step: 15
Training loss: 2.4017107486724854
Validation loss: 1.8688365932848814
Epoch: 35| Step: 0
Training loss: 1.9426281452178955
Validation loss: 1.8939413904286118
Epoch: 7| Step: 1
Training loss: 2.4303040504455566
Validation loss: 1.861579547683112
Epoch: 7| Step: 2
Training loss: 2.427428722381592
Validation loss: 1.8492087374488226
Epoch: 7| Step: 3
Training loss: 1.918859839439392
Validation loss: 1.8905135744767223
Epoch: 7| Step: 4
Training loss: 2.3315937519073486
Validation loss: 1.876375014833409
Epoch: 7| Step: 5
Training loss: 1.8764450550079346
Validation loss: 1.881980539225846
Epoch: 7| Step: 6
Training loss: 2.4030749797821045
Validation loss: 1.8793510498760415
Epoch: 7| Step: 7
Training loss: 1.9288914203643799
Validation loss: 1.859642400158395
Epoch: 7| Step: 8
Training loss: 2.2154788970947266
Validation loss: 1.8856766386855421
Epoch: 7| Step: 9
Training loss: 1.8280467987060547
Validation loss: 1.8777827170255372
Epoch: 7| Step: 10
Training loss: 2.6766037940979004
Validation loss: 1.8704518019724234
Epoch: 7| Step: 11
Training loss: 1.6275551319122314
Validation loss: 1.8730866720350525
Epoch: 7| Step: 12
Training loss: 1.7443870306015015
Validation loss: 1.8684705255700529
Epoch: 7| Step: 13
Training loss: 1.8500694036483765
Validation loss: 1.8933627991367588
Epoch: 7| Step: 14
Training loss: 1.8309240341186523
Validation loss: 1.9093241828808682
Epoch: 7| Step: 15
Training loss: 2.3104093074798584
Validation loss: 1.8911878899704637
Epoch: 36| Step: 0
Training loss: 2.81964373588562
Validation loss: 1.8864490608517215
Epoch: 7| Step: 1
Training loss: 1.7755300998687744
Validation loss: 1.8862810306411852
Epoch: 7| Step: 2
Training loss: 2.042227029800415
Validation loss: 1.89393035456431
Epoch: 7| Step: 3
Training loss: 2.2328107357025146
Validation loss: 1.895370124912948
Epoch: 7| Step: 4
Training loss: 2.051391124725342
Validation loss: 1.9102208871635602
Epoch: 7| Step: 5
Training loss: 2.0917067527770996
Validation loss: 1.8831227992078383
Epoch: 7| Step: 6
Training loss: 2.211519956588745
Validation loss: 1.8929077052383971
Epoch: 7| Step: 7
Training loss: 1.8518810272216797
Validation loss: 1.8729650596920535
Epoch: 7| Step: 8
Training loss: 2.1468911170959473
Validation loss: 1.8795675202239333
Epoch: 7| Step: 9
Training loss: 2.0536868572235107
Validation loss: 1.9046160677354114
Epoch: 7| Step: 10
Training loss: 1.8225218057632446
Validation loss: 1.8897281687894314
Epoch: 7| Step: 11
Training loss: 2.166769504547119
Validation loss: 1.9098214751524891
Epoch: 7| Step: 12
Training loss: 2.106083631515503
Validation loss: 1.9001655321327044
Epoch: 7| Step: 13
Training loss: 1.8574784994125366
Validation loss: 1.891900966493346
Epoch: 7| Step: 14
Training loss: 2.181232452392578
Validation loss: 1.9169544178804905
Epoch: 7| Step: 15
Training loss: 1.8389644622802734
Validation loss: 1.894586314400323
Epoch: 37| Step: 0
Training loss: 1.804608941078186
Validation loss: 1.9159273432313109
Epoch: 7| Step: 1
Training loss: 2.261591911315918
Validation loss: 1.879989521108943
Epoch: 7| Step: 2
Training loss: 1.9152272939682007
Validation loss: 1.8923505536086267
Epoch: 7| Step: 3
Training loss: 1.707607626914978
Validation loss: 1.8984750380618967
Epoch: 7| Step: 4
Training loss: 2.27742075920105
Validation loss: 1.8869374947582218
Epoch: 7| Step: 5
Training loss: 1.8888353109359741
Validation loss: 1.9096521516498044
Epoch: 7| Step: 6
Training loss: 1.6697168350219727
Validation loss: 1.8914834561107827
Epoch: 7| Step: 7
Training loss: 2.4995293617248535
Validation loss: 1.8847943587268856
Epoch: 7| Step: 8
Training loss: 2.3621504306793213
Validation loss: 1.8986859252984576
Epoch: 7| Step: 9
Training loss: 2.657700538635254
Validation loss: 1.895444052682506
Epoch: 7| Step: 10
Training loss: 2.3183584213256836
Validation loss: 1.8951357217143765
Epoch: 7| Step: 11
Training loss: 1.9321746826171875
Validation loss: 1.8777655714707409
Epoch: 7| Step: 12
Training loss: 2.0321311950683594
Validation loss: 1.8872563255776604
Epoch: 7| Step: 13
Training loss: 2.0709140300750732
Validation loss: 1.8536689101363257
Epoch: 7| Step: 14
Training loss: 1.8011529445648193
Validation loss: 1.8555170957990688
Epoch: 7| Step: 15
Training loss: 1.988585114479065
Validation loss: 1.8673079219653452
Epoch: 38| Step: 0
Training loss: 2.507948637008667
Validation loss: 1.8673045377937152
Epoch: 7| Step: 1
Training loss: 1.7909824848175049
Validation loss: 1.8507087933931419
Epoch: 7| Step: 2
Training loss: 2.0612523555755615
Validation loss: 1.8439798320797707
Epoch: 7| Step: 3
Training loss: 1.9601516723632812
Validation loss: 1.8349316840549168
Epoch: 7| Step: 4
Training loss: 2.172651767730713
Validation loss: 1.8582299741909658
Epoch: 7| Step: 5
Training loss: 2.5259170532226562
Validation loss: 1.8787790056612852
Epoch: 7| Step: 6
Training loss: 1.5733377933502197
Validation loss: 1.8536050688448569
Epoch: 7| Step: 7
Training loss: 2.1410179138183594
Validation loss: 1.8729799745751798
Epoch: 7| Step: 8
Training loss: 2.219184160232544
Validation loss: 1.8760863448218477
Epoch: 7| Step: 9
Training loss: 2.441415548324585
Validation loss: 1.864044638846418
Epoch: 7| Step: 10
Training loss: 2.2816219329833984
Validation loss: 1.8452968828969722
Epoch: 7| Step: 11
Training loss: 1.6908016204833984
Validation loss: 1.8469437060596274
Epoch: 7| Step: 12
Training loss: 2.236114978790283
Validation loss: 1.873175587585504
Epoch: 7| Step: 13
Training loss: 1.3464672565460205
Validation loss: 1.8655009955810986
Epoch: 7| Step: 14
Training loss: 2.2269928455352783
Validation loss: 1.8525408206226157
Epoch: 7| Step: 15
Training loss: 2.0961127281188965
Validation loss: 1.8550158267398533
Epoch: 39| Step: 0
Training loss: 2.5599067211151123
Validation loss: 1.8564895511531143
Epoch: 7| Step: 1
Training loss: 2.407313108444214
Validation loss: 1.8689310018964809
Epoch: 7| Step: 2
Training loss: 1.3089072704315186
Validation loss: 1.863234973639893
Epoch: 7| Step: 3
Training loss: 2.3827216625213623
Validation loss: 1.894902092089756
Epoch: 7| Step: 4
Training loss: 1.7301967144012451
Validation loss: 1.8688990495187774
Epoch: 7| Step: 5
Training loss: 1.7841579914093018
Validation loss: 1.8684049510269714
Epoch: 7| Step: 6
Training loss: 1.8583755493164062
Validation loss: 1.8805737812742054
Epoch: 7| Step: 7
Training loss: 2.0955922603607178
Validation loss: 1.9028789842729088
Epoch: 7| Step: 8
Training loss: 1.936192512512207
Validation loss: 1.885432764780607
Epoch: 7| Step: 9
Training loss: 1.9709933996200562
Validation loss: 1.8921344932034718
Epoch: 7| Step: 10
Training loss: 2.15722393989563
Validation loss: 1.8615198958691934
Epoch: 7| Step: 11
Training loss: 2.153855085372925
Validation loss: 1.8753286934585023
Epoch: 7| Step: 12
Training loss: 1.815651535987854
Validation loss: 1.858436406945153
Epoch: 7| Step: 13
Training loss: 1.928035020828247
Validation loss: 1.8770115581347788
Epoch: 7| Step: 14
Training loss: 2.6757564544677734
Validation loss: 1.884399175643921
Epoch: 7| Step: 15
Training loss: 2.2011210918426514
Validation loss: 1.8816102142814253
Epoch: 40| Step: 0
Training loss: 1.8130744695663452
Validation loss: 1.8740791845664704
Epoch: 7| Step: 1
Training loss: 1.7277253866195679
Validation loss: 1.8710073772951854
Epoch: 7| Step: 2
Training loss: 2.001452922821045
Validation loss: 1.8601448270056744
Epoch: 7| Step: 3
Training loss: 1.8195698261260986
Validation loss: 1.8728633175650946
Epoch: 7| Step: 4
Training loss: 1.7856734991073608
Validation loss: 1.875383864203803
Epoch: 7| Step: 5
Training loss: 2.0518558025360107
Validation loss: 1.8702745549112774
Epoch: 7| Step: 6
Training loss: 2.1841323375701904
Validation loss: 1.8683547767803823
Epoch: 7| Step: 7
Training loss: 1.8461711406707764
Validation loss: 1.8542643245175587
Epoch: 7| Step: 8
Training loss: 2.7075998783111572
Validation loss: 1.875968758150828
Epoch: 7| Step: 9
Training loss: 2.5405473709106445
Validation loss: 1.8763856270330415
Epoch: 7| Step: 10
Training loss: 2.0856070518493652
Validation loss: 1.8649621893176072
Epoch: 7| Step: 11
Training loss: 1.6161054372787476
Validation loss: 1.8523280157459725
Epoch: 7| Step: 12
Training loss: 2.3935370445251465
Validation loss: 1.855437439122646
Epoch: 7| Step: 13
Training loss: 1.6871769428253174
Validation loss: 1.8659358024597168
Epoch: 7| Step: 14
Training loss: 2.6788330078125
Validation loss: 1.8719328882025301
Epoch: 7| Step: 15
Training loss: 2.182095527648926
Validation loss: 1.8788364379526041
Epoch: 41| Step: 0
Training loss: 2.10149884223938
Validation loss: 1.8719434995445416
Epoch: 7| Step: 1
Training loss: 1.4317920207977295
Validation loss: 1.8679114846016864
Epoch: 7| Step: 2
Training loss: 1.9791066646575928
Validation loss: 1.8562446489608546
Epoch: 7| Step: 3
Training loss: 2.0224764347076416
Validation loss: 1.8761787388822158
Epoch: 7| Step: 4
Training loss: 2.39192795753479
Validation loss: 1.8794851997773425
Epoch: 7| Step: 5
Training loss: 2.1405749320983887
Validation loss: 1.8521826215785184
Epoch: 7| Step: 6
Training loss: 1.6377099752426147
Validation loss: 1.8795469767755741
Epoch: 7| Step: 7
Training loss: 1.8671220541000366
Validation loss: 1.878604781713417
Epoch: 7| Step: 8
Training loss: 2.5269834995269775
Validation loss: 1.850663706553068
Epoch: 7| Step: 9
Training loss: 2.0054428577423096
Validation loss: 1.890240723280598
Epoch: 7| Step: 10
Training loss: 1.5492421388626099
Validation loss: 1.8773565875540534
Epoch: 7| Step: 11
Training loss: 1.9571590423583984
Validation loss: 1.8916447248390253
Epoch: 7| Step: 12
Training loss: 2.491424083709717
Validation loss: 1.8854226671534478
Epoch: 7| Step: 13
Training loss: 2.6323344707489014
Validation loss: 1.8803856089818392
Epoch: 7| Step: 14
Training loss: 2.072826385498047
Validation loss: 1.8795063795803262
Epoch: 7| Step: 15
Training loss: 2.295508861541748
Validation loss: 1.8786571394625327
Epoch: 42| Step: 0
Training loss: 2.4638850688934326
Validation loss: 1.87976820691884
Epoch: 7| Step: 1
Training loss: 2.203732490539551
Validation loss: 1.8790275261556502
Epoch: 7| Step: 2
Training loss: 2.5067825317382812
Validation loss: 1.8835001703646543
Epoch: 7| Step: 3
Training loss: 2.0196282863616943
Validation loss: 1.8769695132756405
Epoch: 7| Step: 4
Training loss: 1.575016736984253
Validation loss: 1.8791310083951882
Epoch: 7| Step: 5
Training loss: 2.516019344329834
Validation loss: 1.8895435453318863
Epoch: 7| Step: 6
Training loss: 2.4702131748199463
Validation loss: 1.8664191575359097
Epoch: 7| Step: 7
Training loss: 2.4139208793640137
Validation loss: 1.8581905167737454
Epoch: 7| Step: 8
Training loss: 1.7653112411499023
Validation loss: 1.8525888096514365
Epoch: 7| Step: 9
Training loss: 2.307171583175659
Validation loss: 1.8665396781276455
Epoch: 7| Step: 10
Training loss: 1.596057653427124
Validation loss: 1.881075183264643
Epoch: 7| Step: 11
Training loss: 1.5863243341445923
Validation loss: 1.873144919923741
Epoch: 7| Step: 12
Training loss: 2.3217055797576904
Validation loss: 1.8633351797680202
Epoch: 7| Step: 13
Training loss: 1.9606845378875732
Validation loss: 1.89425298464384
Epoch: 7| Step: 14
Training loss: 1.8778053522109985
Validation loss: 1.88670084973891
Epoch: 7| Step: 15
Training loss: 1.703386902809143
Validation loss: 1.8678635101524188
Epoch: 43| Step: 0
Training loss: 1.5106968879699707
Validation loss: 1.8717460700933881
Epoch: 7| Step: 1
Training loss: 1.979089379310608
Validation loss: 1.8655224206636278
Epoch: 7| Step: 2
Training loss: 1.6343014240264893
Validation loss: 1.87780594139648
Epoch: 7| Step: 3
Training loss: 2.4370055198669434
Validation loss: 1.8812298783295447
Epoch: 7| Step: 4
Training loss: 1.9943320751190186
Validation loss: 1.8890876392666385
Epoch: 7| Step: 5
Training loss: 1.6329164505004883
Validation loss: 1.884279679909027
Epoch: 7| Step: 6
Training loss: 1.5943061113357544
Validation loss: 1.9141136596528747
Epoch: 7| Step: 7
Training loss: 1.9396156072616577
Validation loss: 1.8873851316438304
Epoch: 7| Step: 8
Training loss: 1.884803056716919
Validation loss: 1.9088683677234237
Epoch: 7| Step: 9
Training loss: 2.894059181213379
Validation loss: 1.8731110361840229
Epoch: 7| Step: 10
Training loss: 2.2984471321105957
Validation loss: 1.8967996887165866
Epoch: 7| Step: 11
Training loss: 2.036231517791748
Validation loss: 1.9012020423257951
Epoch: 7| Step: 12
Training loss: 1.8902488946914673
Validation loss: 1.8820809923487603
Epoch: 7| Step: 13
Training loss: 2.2853598594665527
Validation loss: 1.8968472549383588
Epoch: 7| Step: 14
Training loss: 2.650761604309082
Validation loss: 1.9038289116440916
Epoch: 7| Step: 15
Training loss: 2.3035879135131836
Validation loss: 1.916344315028019
Epoch: 44| Step: 0
Training loss: 1.5435020923614502
Validation loss: 1.9070783570516023
Epoch: 7| Step: 1
Training loss: 1.9065158367156982
Validation loss: 1.8780752137410555
Epoch: 7| Step: 2
Training loss: 2.290498971939087
Validation loss: 1.9018689994331743
Epoch: 7| Step: 3
Training loss: 1.526282548904419
Validation loss: 1.911046105323078
Epoch: 7| Step: 4
Training loss: 1.7098373174667358
Validation loss: 1.904487141602331
Epoch: 7| Step: 5
Training loss: 2.4241747856140137
Validation loss: 1.8999787877789505
Epoch: 7| Step: 6
Training loss: 1.9664570093154907
Validation loss: 1.9267766338458163
Epoch: 7| Step: 7
Training loss: 2.1899638175964355
Validation loss: 1.8727968579573597
Epoch: 7| Step: 8
Training loss: 2.3439526557922363
Validation loss: 1.8882543311702262
Epoch: 7| Step: 9
Training loss: 2.377788782119751
Validation loss: 1.8972177694169738
Epoch: 7| Step: 10
Training loss: 2.551023006439209
Validation loss: 1.8668318429439188
Epoch: 7| Step: 11
Training loss: 2.029921531677246
Validation loss: 1.8684817526837905
Epoch: 7| Step: 12
Training loss: 1.9204833507537842
Validation loss: 1.8828513485064609
Epoch: 7| Step: 13
Training loss: 2.178025484085083
Validation loss: 1.8911924619468854
Epoch: 7| Step: 14
Training loss: 1.4563496112823486
Validation loss: 1.8771379782999162
Epoch: 7| Step: 15
Training loss: 2.4125592708587646
Validation loss: 1.8741868159753814
Epoch: 45| Step: 0
Training loss: 1.841536283493042
Validation loss: 1.887419719490216
Epoch: 7| Step: 1
Training loss: 2.082033634185791
Validation loss: 1.890746932235553
Epoch: 7| Step: 2
Training loss: 2.084437847137451
Validation loss: 1.8581441392143854
Epoch: 7| Step: 3
Training loss: 1.9979139566421509
Validation loss: 1.893728854844896
Epoch: 7| Step: 4
Training loss: 1.7761354446411133
Validation loss: 1.894362417914027
Epoch: 7| Step: 5
Training loss: 2.0019125938415527
Validation loss: 1.8954772100174169
Epoch: 7| Step: 6
Training loss: 1.6005420684814453
Validation loss: 1.918781835398228
Epoch: 7| Step: 7
Training loss: 2.571641445159912
Validation loss: 1.8979312310115897
Epoch: 7| Step: 8
Training loss: 2.3636679649353027
Validation loss: 1.9042065658157679
Epoch: 7| Step: 9
Training loss: 1.972041368484497
Validation loss: 1.8955944424910511
Epoch: 7| Step: 10
Training loss: 1.6887975931167603
Validation loss: 1.8960413521142314
Epoch: 7| Step: 11
Training loss: 2.286161184310913
Validation loss: 1.9067499869161373
Epoch: 7| Step: 12
Training loss: 2.2672672271728516
Validation loss: 1.888632670580912
Epoch: 7| Step: 13
Training loss: 2.0017752647399902
Validation loss: 1.8897087702648245
Epoch: 7| Step: 14
Training loss: 1.93410325050354
Validation loss: 1.8928440320406028
Epoch: 7| Step: 15
Training loss: 2.4488179683685303
Validation loss: 1.8903955264057186
Epoch: 46| Step: 0
Training loss: 1.8511823415756226
Validation loss: 1.9011859139092535
Epoch: 7| Step: 1
Training loss: 1.8154083490371704
Validation loss: 1.8798246486581487
Epoch: 7| Step: 2
Training loss: 2.350558280944824
Validation loss: 1.9046188181252788
Epoch: 7| Step: 3
Training loss: 2.4570083618164062
Validation loss: 1.9127120457107214
Epoch: 7| Step: 4
Training loss: 2.144986629486084
Validation loss: 1.908014060782014
Epoch: 7| Step: 5
Training loss: 2.0166563987731934
Validation loss: 1.8856983605048638
Epoch: 7| Step: 6
Training loss: 1.3580687046051025
Validation loss: 1.897275989861797
Epoch: 7| Step: 7
Training loss: 2.52756929397583
Validation loss: 1.913696783052074
Epoch: 7| Step: 8
Training loss: 2.4441514015197754
Validation loss: 1.906671433140048
Epoch: 7| Step: 9
Training loss: 1.8621114492416382
Validation loss: 1.9145471209244762
Epoch: 7| Step: 10
Training loss: 2.463639736175537
Validation loss: 1.897107704080266
Epoch: 7| Step: 11
Training loss: 1.886003851890564
Validation loss: 1.896448275168165
Epoch: 7| Step: 12
Training loss: 2.054194688796997
Validation loss: 1.889770799403568
Epoch: 7| Step: 13
Training loss: 1.6028484106063843
Validation loss: 1.884415622237775
Epoch: 7| Step: 14
Training loss: 1.6640894412994385
Validation loss: 1.8892378978592028
Epoch: 7| Step: 15
Training loss: 2.3351001739501953
Validation loss: 1.8958580957042228
Epoch: 47| Step: 0
Training loss: 1.7593902349472046
Validation loss: 1.8997743927317559
Epoch: 7| Step: 1
Training loss: 2.0099399089813232
Validation loss: 1.9020889337114293
Epoch: 7| Step: 2
Training loss: 1.9088852405548096
Validation loss: 1.8872629644201815
Epoch: 7| Step: 3
Training loss: 2.0649397373199463
Validation loss: 1.8825128078460693
Epoch: 7| Step: 4
Training loss: 2.3338136672973633
Validation loss: 1.8863998771571426
Epoch: 7| Step: 5
Training loss: 2.638051748275757
Validation loss: 1.889149939413551
Epoch: 7| Step: 6
Training loss: 2.288954973220825
Validation loss: 1.8706348062419205
Epoch: 7| Step: 7
Training loss: 1.4964783191680908
Validation loss: 1.9210605526999605
Epoch: 7| Step: 8
Training loss: 2.6913840770721436
Validation loss: 1.8789484852509533
Epoch: 7| Step: 9
Training loss: 1.718993902206421
Validation loss: 1.9103105351221648
Epoch: 7| Step: 10
Training loss: 1.7486133575439453
Validation loss: 1.897029942745785
Epoch: 7| Step: 11
Training loss: 1.892671823501587
Validation loss: 1.897375768037151
Epoch: 7| Step: 12
Training loss: 2.2076690196990967
Validation loss: 1.8794399954432206
Epoch: 7| Step: 13
Training loss: 2.6916866302490234
Validation loss: 1.8990004637258515
Epoch: 7| Step: 14
Training loss: 1.815739393234253
Validation loss: 1.9018940119434604
Epoch: 7| Step: 15
Training loss: 1.5425068140029907
Validation loss: 1.864909400185235
Epoch: 48| Step: 0
Training loss: 2.0329391956329346
Validation loss: 1.884054475551029
Epoch: 7| Step: 1
Training loss: 2.2273173332214355
Validation loss: 1.8797095851074876
Epoch: 7| Step: 2
Training loss: 2.2428336143493652
Validation loss: 1.8801823760108125
Epoch: 7| Step: 3
Training loss: 1.8780243396759033
Validation loss: 1.8646914144214108
Epoch: 7| Step: 4
Training loss: 2.2684226036071777
Validation loss: 1.8952973231994847
Epoch: 7| Step: 5
Training loss: 1.1694176197052002
Validation loss: 1.8817659273422023
Epoch: 7| Step: 6
Training loss: 2.248180866241455
Validation loss: 1.8967301965617447
Epoch: 7| Step: 7
Training loss: 2.2141528129577637
Validation loss: 1.8759156465530396
Epoch: 7| Step: 8
Training loss: 2.297499179840088
Validation loss: 1.8997538432800511
Epoch: 7| Step: 9
Training loss: 1.7335708141326904
Validation loss: 1.8805535457117095
Epoch: 7| Step: 10
Training loss: 2.708636522293091
Validation loss: 1.8884188202645282
Epoch: 7| Step: 11
Training loss: 1.9330638647079468
Validation loss: 1.861228549223152
Epoch: 7| Step: 12
Training loss: 1.5180175304412842
Validation loss: 1.8950872790041586
Epoch: 7| Step: 13
Training loss: 2.372785806655884
Validation loss: 1.882407258740432
Epoch: 7| Step: 14
Training loss: 1.8602269887924194
Validation loss: 1.8795961218772175
Epoch: 7| Step: 15
Training loss: 2.055957317352295
Validation loss: 1.8739518321675361
Epoch: 49| Step: 0
Training loss: 1.633399248123169
Validation loss: 1.899964431206957
Epoch: 7| Step: 1
Training loss: 1.8540147542953491
Validation loss: 1.8763494431543692
Epoch: 7| Step: 2
Training loss: 1.7929527759552002
Validation loss: 1.890117243897143
Epoch: 7| Step: 3
Training loss: 1.7532424926757812
Validation loss: 1.8872448806282427
Epoch: 7| Step: 4
Training loss: 1.8106582164764404
Validation loss: 1.8947815672099162
Epoch: 7| Step: 5
Training loss: 1.871654748916626
Validation loss: 1.8897826946038994
Epoch: 7| Step: 6
Training loss: 2.36741304397583
Validation loss: 1.8913194498569845
Epoch: 7| Step: 7
Training loss: 1.958348274230957
Validation loss: 1.8901179797357792
Epoch: 7| Step: 8
Training loss: 1.754626989364624
Validation loss: 1.900416139218447
Epoch: 7| Step: 9
Training loss: 2.9118542671203613
Validation loss: 1.8796022830249595
Epoch: 7| Step: 10
Training loss: 2.2740352153778076
Validation loss: 1.9133480058299552
Epoch: 7| Step: 11
Training loss: 1.5527875423431396
Validation loss: 1.8961738253668916
Epoch: 7| Step: 12
Training loss: 2.334213972091675
Validation loss: 1.8994081251912838
Epoch: 7| Step: 13
Training loss: 2.2985756397247314
Validation loss: 1.897111606254852
Epoch: 7| Step: 14
Training loss: 2.3057053089141846
Validation loss: 1.8984115020834285
Epoch: 7| Step: 15
Training loss: 2.20442271232605
Validation loss: 1.9011048567380837
Epoch: 50| Step: 0
Training loss: 1.8576421737670898
Validation loss: 1.8947481131382127
Epoch: 7| Step: 1
Training loss: 1.6859643459320068
Validation loss: 1.8877555706518159
Epoch: 7| Step: 2
Training loss: 1.362328290939331
Validation loss: 1.872061917250105
Epoch: 7| Step: 3
Training loss: 2.627051830291748
Validation loss: 1.8791463478006047
Epoch: 7| Step: 4
Training loss: 2.2209696769714355
Validation loss: 1.8644922156985715
Epoch: 7| Step: 5
Training loss: 1.5182627439498901
Validation loss: 1.9012325496124707
Epoch: 7| Step: 6
Training loss: 1.8912734985351562
Validation loss: 1.885241394420322
Epoch: 7| Step: 7
Training loss: 2.5645792484283447
Validation loss: 1.871608500858005
Epoch: 7| Step: 8
Training loss: 1.7540628910064697
Validation loss: 1.8772925893179804
Epoch: 7| Step: 9
Training loss: 1.7853155136108398
Validation loss: 1.8924334126410725
Epoch: 7| Step: 10
Training loss: 2.418466091156006
Validation loss: 1.8915429621291675
Epoch: 7| Step: 11
Training loss: 2.295264482498169
Validation loss: 1.890674073061497
Epoch: 7| Step: 12
Training loss: 2.091686964035034
Validation loss: 1.8892148527310049
Epoch: 7| Step: 13
Training loss: 2.292428493499756
Validation loss: 1.8976569553073361
Epoch: 7| Step: 14
Training loss: 2.132436752319336
Validation loss: 1.8900098732049517
Epoch: 7| Step: 15
Training loss: 2.406599760055542
Validation loss: 1.8804388938190268
Epoch: 51| Step: 0
Training loss: 2.058117628097534
Validation loss: 1.8960616442796996
Epoch: 7| Step: 1
Training loss: 2.100365161895752
Validation loss: 1.8627344867308362
Epoch: 7| Step: 2
Training loss: 2.016880512237549
Validation loss: 1.8895827094427973
Epoch: 7| Step: 3
Training loss: 1.7529538869857788
Validation loss: 1.89728983443418
Epoch: 7| Step: 4
Training loss: 1.8575432300567627
Validation loss: 1.893609873682475
Epoch: 7| Step: 5
Training loss: 1.9415581226348877
Validation loss: 1.860314232839955
Epoch: 7| Step: 6
Training loss: 1.904750108718872
Validation loss: 1.8542088415982911
Epoch: 7| Step: 7
Training loss: 2.5875375270843506
Validation loss: 1.8849700517791639
Epoch: 7| Step: 8
Training loss: 1.6222261190414429
Validation loss: 1.872965940468603
Epoch: 7| Step: 9
Training loss: 1.3227603435516357
Validation loss: 1.8679206851575014
Epoch: 7| Step: 10
Training loss: 1.945397973060608
Validation loss: 1.8794350709846552
Epoch: 7| Step: 11
Training loss: 2.5163323879241943
Validation loss: 1.8657092482065982
Epoch: 7| Step: 12
Training loss: 2.2960569858551025
Validation loss: 1.8792285421769397
Epoch: 7| Step: 13
Training loss: 2.570173740386963
Validation loss: 1.860353286317784
Epoch: 7| Step: 14
Training loss: 2.46305513381958
Validation loss: 1.884856064542592
Epoch: 7| Step: 15
Training loss: 1.864723801612854
Validation loss: 1.8673647822235986
Epoch: 52| Step: 0
Training loss: 2.314664840698242
Validation loss: 1.8803281766905202
Epoch: 7| Step: 1
Training loss: 2.44494891166687
Validation loss: 1.8659884346474847
Epoch: 7| Step: 2
Training loss: 1.8885571956634521
Validation loss: 1.860000677245984
Epoch: 7| Step: 3
Training loss: 1.781550645828247
Validation loss: 1.863700723476547
Epoch: 7| Step: 4
Training loss: 2.0710031986236572
Validation loss: 1.8684550652401053
Epoch: 7| Step: 5
Training loss: 2.160322666168213
Validation loss: 1.874286004107633
Epoch: 7| Step: 6
Training loss: 2.475522518157959
Validation loss: 1.8643765243694936
Epoch: 7| Step: 7
Training loss: 1.6145570278167725
Validation loss: 1.8789611205780248
Epoch: 7| Step: 8
Training loss: 2.217583417892456
Validation loss: 1.8682352613202102
Epoch: 7| Step: 9
Training loss: 2.2306556701660156
Validation loss: 1.8485004618871126
Epoch: 7| Step: 10
Training loss: 1.8595497608184814
Validation loss: 1.8387955410017385
Epoch: 7| Step: 11
Training loss: 1.7650772333145142
Validation loss: 1.8548915163218547
Epoch: 7| Step: 12
Training loss: 2.5822033882141113
Validation loss: 1.8470175918057667
Epoch: 7| Step: 13
Training loss: 1.8605676889419556
Validation loss: 1.8534490341762844
Epoch: 7| Step: 14
Training loss: 1.5432705879211426
Validation loss: 1.844805020222561
Epoch: 7| Step: 15
Training loss: 1.8714977502822876
Validation loss: 1.865066404822919
Epoch: 53| Step: 0
Training loss: 1.7164947986602783
Validation loss: 1.8707990320466406
Epoch: 7| Step: 1
Training loss: 2.332645893096924
Validation loss: 1.874562386986163
Epoch: 7| Step: 2
Training loss: 2.469848155975342
Validation loss: 1.8726262077153157
Epoch: 7| Step: 3
Training loss: 2.022456645965576
Validation loss: 1.8724350346078118
Epoch: 7| Step: 4
Training loss: 1.6276180744171143
Validation loss: 1.853525862419348
Epoch: 7| Step: 5
Training loss: 2.5984272956848145
Validation loss: 1.8742385888271194
Epoch: 7| Step: 6
Training loss: 1.7031888961791992
Validation loss: 1.8841617441863465
Epoch: 7| Step: 7
Training loss: 2.147996187210083
Validation loss: 1.850026825349108
Epoch: 7| Step: 8
Training loss: 1.4638367891311646
Validation loss: 1.8559584060161234
Epoch: 7| Step: 9
Training loss: 1.8914600610733032
Validation loss: 1.8566504931278367
Epoch: 7| Step: 10
Training loss: 1.6118392944335938
Validation loss: 1.843508996551843
Epoch: 7| Step: 11
Training loss: 1.6851613521575928
Validation loss: 1.8610108516199126
Epoch: 7| Step: 12
Training loss: 2.4603798389434814
Validation loss: 1.8673678919565764
Epoch: 7| Step: 13
Training loss: 1.9940662384033203
Validation loss: 1.869983872063726
Epoch: 7| Step: 14
Training loss: 2.65960693359375
Validation loss: 1.855728960723328
Epoch: 7| Step: 15
Training loss: 2.2178289890289307
Validation loss: 1.8560500505159228
Epoch: 54| Step: 0
Training loss: 1.792544960975647
Validation loss: 1.877174564402738
Epoch: 7| Step: 1
Training loss: 1.7021396160125732
Validation loss: 1.8549112193018413
Epoch: 7| Step: 2
Training loss: 2.1830575466156006
Validation loss: 1.8773741387634826
Epoch: 7| Step: 3
Training loss: 2.0989654064178467
Validation loss: 1.881120189488363
Epoch: 7| Step: 4
Training loss: 2.5184853076934814
Validation loss: 1.8951891600656852
Epoch: 7| Step: 5
Training loss: 1.899125337600708
Validation loss: 1.9055189520335025
Epoch: 7| Step: 6
Training loss: 1.7000017166137695
Validation loss: 1.8836150795435733
Epoch: 7| Step: 7
Training loss: 1.6785118579864502
Validation loss: 1.8784741034610666
Epoch: 7| Step: 8
Training loss: 2.3210031986236572
Validation loss: 1.8843215815454937
Epoch: 7| Step: 9
Training loss: 2.704291343688965
Validation loss: 1.9004437588959289
Epoch: 7| Step: 10
Training loss: 2.0747714042663574
Validation loss: 1.8975767797703365
Epoch: 7| Step: 11
Training loss: 1.6288461685180664
Validation loss: 1.8757697909856015
Epoch: 7| Step: 12
Training loss: 2.483210563659668
Validation loss: 1.907454705066818
Epoch: 7| Step: 13
Training loss: 2.3829987049102783
Validation loss: 1.8933164061402246
Epoch: 7| Step: 14
Training loss: 1.758819580078125
Validation loss: 1.8898947273226951
Epoch: 7| Step: 15
Training loss: 1.7402366399765015
Validation loss: 1.895402100446413
Epoch: 55| Step: 0
Training loss: 1.5660960674285889
Validation loss: 1.9025806711732054
Epoch: 7| Step: 1
Training loss: 1.8036270141601562
Validation loss: 1.8946671177157395
Epoch: 7| Step: 2
Training loss: 2.060861110687256
Validation loss: 1.8894250607319016
Epoch: 7| Step: 3
Training loss: 2.101661205291748
Validation loss: 1.9043344893901468
Epoch: 7| Step: 4
Training loss: 2.176283121109009
Validation loss: 1.8928293753013337
Epoch: 7| Step: 5
Training loss: 1.803330659866333
Validation loss: 1.911395379107633
Epoch: 7| Step: 6
Training loss: 2.4115262031555176
Validation loss: 1.8949418445285275
Epoch: 7| Step: 7
Training loss: 2.3191728591918945
Validation loss: 1.9072083552106678
Epoch: 7| Step: 8
Training loss: 2.5410664081573486
Validation loss: 1.8821764129528897
Epoch: 7| Step: 9
Training loss: 1.474317193031311
Validation loss: 1.8815391132299848
Epoch: 7| Step: 10
Training loss: 2.016732931137085
Validation loss: 1.8823023700028014
Epoch: 7| Step: 11
Training loss: 2.11360239982605
Validation loss: 1.8914324817039985
Epoch: 7| Step: 12
Training loss: 1.4744840860366821
Validation loss: 1.8841215397814195
Epoch: 7| Step: 13
Training loss: 2.642819404602051
Validation loss: 1.8636222383101209
Epoch: 7| Step: 14
Training loss: 2.122274875640869
Validation loss: 1.86577167785425
Epoch: 7| Step: 15
Training loss: 1.9231109619140625
Validation loss: 1.8803019652263724
Epoch: 56| Step: 0
Training loss: 1.6627662181854248
Validation loss: 1.8833252414524984
Epoch: 7| Step: 1
Training loss: 2.07737398147583
Validation loss: 1.8868860272194843
Epoch: 7| Step: 2
Training loss: 2.1740903854370117
Validation loss: 1.8690581253106646
Epoch: 7| Step: 3
Training loss: 1.9978500604629517
Validation loss: 1.8976472453247728
Epoch: 7| Step: 4
Training loss: 2.2947685718536377
Validation loss: 1.877133178196365
Epoch: 7| Step: 5
Training loss: 1.90390145778656
Validation loss: 1.8744795768381022
Epoch: 7| Step: 6
Training loss: 2.510390520095825
Validation loss: 1.8660594962483688
Epoch: 7| Step: 7
Training loss: 2.269747257232666
Validation loss: 1.8628716846164182
Epoch: 7| Step: 8
Training loss: 1.7108749151229858
Validation loss: 1.8797900282221733
Epoch: 7| Step: 9
Training loss: 2.1597070693969727
Validation loss: 1.8978801991442125
Epoch: 7| Step: 10
Training loss: 2.072352886199951
Validation loss: 1.8826606213617667
Epoch: 7| Step: 11
Training loss: 1.118740200996399
Validation loss: 1.8716609083491265
Epoch: 7| Step: 12
Training loss: 2.1823933124542236
Validation loss: 1.8835747739393933
Epoch: 7| Step: 13
Training loss: 2.118108034133911
Validation loss: 1.8841298021000923
Epoch: 7| Step: 14
Training loss: 2.453886032104492
Validation loss: 1.869058524104331
Epoch: 7| Step: 15
Training loss: 1.8961107730865479
Validation loss: 1.878097888377073
Epoch: 57| Step: 0
Training loss: 1.7802770137786865
Validation loss: 1.8850901529943342
Epoch: 7| Step: 1
Training loss: 2.0538296699523926
Validation loss: 1.8685140266692897
Epoch: 7| Step: 2
Training loss: 1.1190780401229858
Validation loss: 1.898459775842351
Epoch: 7| Step: 3
Training loss: 2.2853169441223145
Validation loss: 1.877536416053772
Epoch: 7| Step: 4
Training loss: 1.7452396154403687
Validation loss: 1.8912749427685636
Epoch: 7| Step: 5
Training loss: 2.0492827892303467
Validation loss: 1.8991926788426132
Epoch: 7| Step: 6
Training loss: 1.9494514465332031
Validation loss: 1.9115271053725866
Epoch: 7| Step: 7
Training loss: 1.992505431175232
Validation loss: 1.9171411819595228
Epoch: 7| Step: 8
Training loss: 1.7803071737289429
Validation loss: 1.9114796129062022
Epoch: 7| Step: 9
Training loss: 2.2385475635528564
Validation loss: 1.9267224562253884
Epoch: 7| Step: 10
Training loss: 2.4786365032196045
Validation loss: 1.909944391079086
Epoch: 7| Step: 11
Training loss: 2.1779322624206543
Validation loss: 1.9095444027468456
Epoch: 7| Step: 12
Training loss: 2.3261218070983887
Validation loss: 1.9069665061484138
Epoch: 7| Step: 13
Training loss: 2.181093692779541
Validation loss: 1.8987415926061946
Epoch: 7| Step: 14
Training loss: 1.9320491552352905
Validation loss: 1.9124163500696636
Epoch: 7| Step: 15
Training loss: 2.6751773357391357
Validation loss: 1.906085231321321
Epoch: 58| Step: 0
Training loss: 2.1837544441223145
Validation loss: 1.8845916866398544
Epoch: 7| Step: 1
Training loss: 1.5241702795028687
Validation loss: 1.8826178869755148
Epoch: 7| Step: 2
Training loss: 2.4228312969207764
Validation loss: 1.877225937603189
Epoch: 7| Step: 3
Training loss: 2.0326733589172363
Validation loss: 1.865477535364439
Epoch: 7| Step: 4
Training loss: 1.6134302616119385
Validation loss: 1.8532983073227698
Epoch: 7| Step: 5
Training loss: 1.9209468364715576
Validation loss: 1.8687504409886093
Epoch: 7| Step: 6
Training loss: 2.087698459625244
Validation loss: 1.8498457387196932
Epoch: 7| Step: 7
Training loss: 2.006981372833252
Validation loss: 1.8511699532433379
Epoch: 7| Step: 8
Training loss: 2.3718161582946777
Validation loss: 1.8427287177216234
Epoch: 7| Step: 9
Training loss: 2.622929811477661
Validation loss: 1.8249582172297745
Epoch: 7| Step: 10
Training loss: 1.8662313222885132
Validation loss: 1.8359312753883197
Epoch: 7| Step: 11
Training loss: 1.7567203044891357
Validation loss: 1.846659427924122
Epoch: 7| Step: 12
Training loss: 1.9061599969863892
Validation loss: 1.8338795325738921
Epoch: 7| Step: 13
Training loss: 2.3892099857330322
Validation loss: 1.8544557789246814
Epoch: 7| Step: 14
Training loss: 2.3278310298919678
Validation loss: 1.8276252738005823
Epoch: 7| Step: 15
Training loss: 1.5610601902008057
Validation loss: 1.833473154109159
Epoch: 59| Step: 0
Training loss: 1.4229882955551147
Validation loss: 1.8374415052880486
Epoch: 7| Step: 1
Training loss: 2.301618814468384
Validation loss: 1.8465052440012102
Epoch: 7| Step: 2
Training loss: 1.605128526687622
Validation loss: 1.846160799479313
Epoch: 7| Step: 3
Training loss: 2.424544334411621
Validation loss: 1.8528539851415071
Epoch: 7| Step: 4
Training loss: 1.9832795858383179
Validation loss: 1.835761996481916
Epoch: 7| Step: 5
Training loss: 2.3709099292755127
Validation loss: 1.852905322321885
Epoch: 7| Step: 6
Training loss: 1.7086387872695923
Validation loss: 1.854871562058977
Epoch: 7| Step: 7
Training loss: 1.832790732383728
Validation loss: 1.8541868642079744
Epoch: 7| Step: 8
Training loss: 2.512012004852295
Validation loss: 1.8476988154349567
Epoch: 7| Step: 9
Training loss: 2.131455898284912
Validation loss: 1.8541930588029272
Epoch: 7| Step: 10
Training loss: 2.1047003269195557
Validation loss: 1.8528017534626473
Epoch: 7| Step: 11
Training loss: 1.817474365234375
Validation loss: 1.8517043110278013
Epoch: 7| Step: 12
Training loss: 2.3491766452789307
Validation loss: 1.8598966178276557
Epoch: 7| Step: 13
Training loss: 1.9431545734405518
Validation loss: 1.8590924096622055
Epoch: 7| Step: 14
Training loss: 1.8545372486114502
Validation loss: 1.8652604603938918
Epoch: 7| Step: 15
Training loss: 2.1257495880126953
Validation loss: 1.84781181383476
Epoch: 60| Step: 0
Training loss: 1.6117874383926392
Validation loss: 1.8741770382407759
Epoch: 7| Step: 1
Training loss: 2.771306276321411
Validation loss: 1.8566276306728664
Epoch: 7| Step: 2
Training loss: 1.4416468143463135
Validation loss: 1.8643909812831192
Epoch: 7| Step: 3
Training loss: 1.853107213973999
Validation loss: 1.8924948551671967
Epoch: 7| Step: 4
Training loss: 2.0144588947296143
Validation loss: 1.8763668322734695
Epoch: 7| Step: 5
Training loss: 1.9829962253570557
Validation loss: 1.8737461086657408
Epoch: 7| Step: 6
Training loss: 2.3258204460144043
Validation loss: 1.8885897955448507
Epoch: 7| Step: 7
Training loss: 1.8084676265716553
Validation loss: 1.876880621738571
Epoch: 7| Step: 8
Training loss: 2.377047061920166
Validation loss: 1.9106625207036518
Epoch: 7| Step: 9
Training loss: 2.0806217193603516
Validation loss: 1.8730609399809255
Epoch: 7| Step: 10
Training loss: 2.509077548980713
Validation loss: 1.9032797496095837
Epoch: 7| Step: 11
Training loss: 2.477581739425659
Validation loss: 1.9137229010355559
Epoch: 7| Step: 12
Training loss: 1.9165788888931274
Validation loss: 1.9158501264860304
Epoch: 7| Step: 13
Training loss: 2.3392443656921387
Validation loss: 1.8900953857161158
Epoch: 7| Step: 14
Training loss: 1.3201215267181396
Validation loss: 1.8888228171163326
Epoch: 7| Step: 15
Training loss: 1.6691160202026367
Validation loss: 1.881375988610357
Epoch: 61| Step: 0
Training loss: 2.1122097969055176
Validation loss: 1.9040069528620878
Epoch: 7| Step: 1
Training loss: 1.943548560142517
Validation loss: 1.8970569243534006
Epoch: 7| Step: 2
Training loss: 1.9733593463897705
Validation loss: 1.9192759853472812
Epoch: 7| Step: 3
Training loss: 1.9746650457382202
Validation loss: 1.9010091625529228
Epoch: 7| Step: 4
Training loss: 1.7132537364959717
Validation loss: 1.8962882654272395
Epoch: 7| Step: 5
Training loss: 1.999023199081421
Validation loss: 1.9019649354673975
Epoch: 7| Step: 6
Training loss: 1.7992995977401733
Validation loss: 1.9104463813973844
Epoch: 7| Step: 7
Training loss: 2.226580858230591
Validation loss: 1.9175946909746677
Epoch: 7| Step: 8
Training loss: 2.085057258605957
Validation loss: 1.9197296564527553
Epoch: 7| Step: 9
Training loss: 1.7547117471694946
Validation loss: 1.922967330157328
Epoch: 7| Step: 10
Training loss: 2.188045024871826
Validation loss: 1.9069227537662863
Epoch: 7| Step: 11
Training loss: 2.2298471927642822
Validation loss: 1.919647249386465
Epoch: 7| Step: 12
Training loss: 1.961601972579956
Validation loss: 1.894569693709449
Epoch: 7| Step: 13
Training loss: 2.0235342979431152
Validation loss: 1.8887476269289745
Epoch: 7| Step: 14
Training loss: 2.173767566680908
Validation loss: 1.9015309347523202
Epoch: 7| Step: 15
Training loss: 2.3166050910949707
Validation loss: 1.8957662325111224
Epoch: 62| Step: 0
Training loss: 1.9373502731323242
Validation loss: 1.9021997108733912
Epoch: 7| Step: 1
Training loss: 1.9009253978729248
Validation loss: 1.8871291129709147
Epoch: 7| Step: 2
Training loss: 1.5409830808639526
Validation loss: 1.877985614666836
Epoch: 7| Step: 3
Training loss: 1.9414056539535522
Validation loss: 1.8813292276945046
Epoch: 7| Step: 4
Training loss: 2.523852825164795
Validation loss: 1.8757180944621135
Epoch: 7| Step: 5
Training loss: 2.0544092655181885
Validation loss: 1.8833655230432964
Epoch: 7| Step: 6
Training loss: 1.7387058734893799
Validation loss: 1.8702839492893906
Epoch: 7| Step: 7
Training loss: 1.8110418319702148
Validation loss: 1.8676184964694564
Epoch: 7| Step: 8
Training loss: 2.0280838012695312
Validation loss: 1.8781415078279784
Epoch: 7| Step: 9
Training loss: 2.02329683303833
Validation loss: 1.8544448828525681
Epoch: 7| Step: 10
Training loss: 2.5305087566375732
Validation loss: 1.861259333521342
Epoch: 7| Step: 11
Training loss: 1.7930835485458374
Validation loss: 1.854522818284069
Epoch: 7| Step: 12
Training loss: 1.77936589717865
Validation loss: 1.88246576734584
Epoch: 7| Step: 13
Training loss: 1.9932382106781006
Validation loss: 1.8711176493185029
Epoch: 7| Step: 14
Training loss: 2.44124174118042
Validation loss: 1.8578785477782325
Epoch: 7| Step: 15
Training loss: 2.2708191871643066
Validation loss: 1.8585970933488805
Epoch: 63| Step: 0
Training loss: 1.9922157526016235
Validation loss: 1.862036805358722
Epoch: 7| Step: 1
Training loss: 1.9114267826080322
Validation loss: 1.8706372418849588
Epoch: 7| Step: 2
Training loss: 2.4306788444519043
Validation loss: 1.8561296059930925
Epoch: 7| Step: 3
Training loss: 0.9971160888671875
Validation loss: 1.8561970570104585
Epoch: 7| Step: 4
Training loss: 1.509677767753601
Validation loss: 1.8459078287906785
Epoch: 7| Step: 5
Training loss: 3.2979931831359863
Validation loss: 1.8515981564418875
Epoch: 7| Step: 6
Training loss: 1.9830827713012695
Validation loss: 1.8433753226300795
Epoch: 7| Step: 7
Training loss: 2.3589282035827637
Validation loss: 1.826954054317886
Epoch: 7| Step: 8
Training loss: 1.8510234355926514
Validation loss: 1.8341478255155275
Epoch: 7| Step: 9
Training loss: 1.7340120077133179
Validation loss: 1.8373012191100087
Epoch: 7| Step: 10
Training loss: 1.7849843502044678
Validation loss: 1.8268781411562034
Epoch: 7| Step: 11
Training loss: 1.6253877878189087
Validation loss: 1.841957991929363
Epoch: 7| Step: 12
Training loss: 2.1100213527679443
Validation loss: 1.8402677182670977
Epoch: 7| Step: 13
Training loss: 2.1561920642852783
Validation loss: 1.8349222047723455
Epoch: 7| Step: 14
Training loss: 2.5754096508026123
Validation loss: 1.840951510470548
Epoch: 7| Step: 15
Training loss: 2.1058058738708496
Validation loss: 1.8542760696342524
Epoch: 64| Step: 0
Training loss: 1.8769237995147705
Validation loss: 1.8377708548264537
Epoch: 7| Step: 1
Training loss: 2.103253126144409
Validation loss: 1.8231830785600402
Epoch: 7| Step: 2
Training loss: 2.417480945587158
Validation loss: 1.8481659537596669
Epoch: 7| Step: 3
Training loss: 1.8460874557495117
Validation loss: 1.8269417062937785
Epoch: 7| Step: 4
Training loss: 1.7242810726165771
Validation loss: 1.8328700991843243
Epoch: 7| Step: 5
Training loss: 2.1060800552368164
Validation loss: 1.857650265419226
Epoch: 7| Step: 6
Training loss: 2.0270984172821045
Validation loss: 1.8533193361844948
Epoch: 7| Step: 7
Training loss: 1.7944114208221436
Validation loss: 1.8641467111573802
Epoch: 7| Step: 8
Training loss: 1.8289811611175537
Validation loss: 1.8702859698439673
Epoch: 7| Step: 9
Training loss: 2.0753798484802246
Validation loss: 1.8725775051459992
Epoch: 7| Step: 10
Training loss: 1.338308572769165
Validation loss: 1.8931249731736217
Epoch: 7| Step: 11
Training loss: 2.5995116233825684
Validation loss: 1.8993867541388643
Epoch: 7| Step: 12
Training loss: 1.983594536781311
Validation loss: 1.9063154664828623
Epoch: 7| Step: 13
Training loss: 2.1710643768310547
Validation loss: 1.8910042236177185
Epoch: 7| Step: 14
Training loss: 2.276986598968506
Validation loss: 1.9003174073404545
Epoch: 7| Step: 15
Training loss: 2.2945070266723633
Validation loss: 1.904756282730926
Epoch: 65| Step: 0
Training loss: 1.7600336074829102
Validation loss: 1.875881095584348
Epoch: 7| Step: 1
Training loss: 2.0659422874450684
Validation loss: 1.879466507932265
Epoch: 7| Step: 2
Training loss: 1.8098167181015015
Validation loss: 1.8828661733394048
Epoch: 7| Step: 3
Training loss: 1.9777710437774658
Validation loss: 1.8723007646396006
Epoch: 7| Step: 4
Training loss: 1.4367387294769287
Validation loss: 1.87051616298209
Epoch: 7| Step: 5
Training loss: 1.494110345840454
Validation loss: 1.8832891853593237
Epoch: 7| Step: 6
Training loss: 1.9595340490341187
Validation loss: 1.8749065905166187
Epoch: 7| Step: 7
Training loss: 2.5598177909851074
Validation loss: 1.8790926864678912
Epoch: 7| Step: 8
Training loss: 1.7303260564804077
Validation loss: 1.8741534107880626
Epoch: 7| Step: 9
Training loss: 2.617090940475464
Validation loss: 1.8771820136969037
Epoch: 7| Step: 10
Training loss: 2.5127487182617188
Validation loss: 1.8965630599920698
Epoch: 7| Step: 11
Training loss: 2.3701634407043457
Validation loss: 1.8826682970678206
Epoch: 7| Step: 12
Training loss: 2.457275867462158
Validation loss: 1.8931755848068128
Epoch: 7| Step: 13
Training loss: 1.9863545894622803
Validation loss: 1.8883640380214444
Epoch: 7| Step: 14
Training loss: 2.1012632846832275
Validation loss: 1.8780744967700767
Epoch: 7| Step: 15
Training loss: 1.4805220365524292
Validation loss: 1.8864437324537648
Epoch: 66| Step: 0
Training loss: 1.73330557346344
Validation loss: 1.8853654123896317
Epoch: 7| Step: 1
Training loss: 1.9654200077056885
Validation loss: 1.8716469299879006
Epoch: 7| Step: 2
Training loss: 2.4680378437042236
Validation loss: 1.8832537759122232
Epoch: 7| Step: 3
Training loss: 1.4387552738189697
Validation loss: 1.8907269453830857
Epoch: 7| Step: 4
Training loss: 1.982627272605896
Validation loss: 1.882710434550004
Epoch: 7| Step: 5
Training loss: 2.1405909061431885
Validation loss: 1.8695732681013697
Epoch: 7| Step: 6
Training loss: 2.4161157608032227
Validation loss: 1.8746424038633167
Epoch: 7| Step: 7
Training loss: 1.9833710193634033
Validation loss: 1.8615255990474344
Epoch: 7| Step: 8
Training loss: 2.1498827934265137
Validation loss: 1.8519007344897702
Epoch: 7| Step: 9
Training loss: 1.7109559774398804
Validation loss: 1.860505562892063
Epoch: 7| Step: 10
Training loss: 2.585012912750244
Validation loss: 1.8460036430427496
Epoch: 7| Step: 11
Training loss: 1.7974138259887695
Validation loss: 1.8484413503742905
Epoch: 7| Step: 12
Training loss: 1.9645763635635376
Validation loss: 1.8345184326171875
Epoch: 7| Step: 13
Training loss: 2.1135544776916504
Validation loss: 1.8475392765278438
Epoch: 7| Step: 14
Training loss: 1.598915457725525
Validation loss: 1.8761538858893965
Epoch: 7| Step: 15
Training loss: 2.393063545227051
Validation loss: 1.8427052686540344
Epoch: 67| Step: 0
Training loss: 1.8871650695800781
Validation loss: 1.8564442747788463
Epoch: 7| Step: 1
Training loss: 2.37499737739563
Validation loss: 1.8587516246082114
Epoch: 7| Step: 2
Training loss: 2.214071750640869
Validation loss: 1.8882856840709987
Epoch: 7| Step: 3
Training loss: 2.712416172027588
Validation loss: 1.8911144587633422
Epoch: 7| Step: 4
Training loss: 2.0487327575683594
Validation loss: 1.8846654917696397
Epoch: 7| Step: 5
Training loss: 1.643310546875
Validation loss: 1.8876624810609886
Epoch: 7| Step: 6
Training loss: 3.073516368865967
Validation loss: 1.8806704128388878
Epoch: 7| Step: 7
Training loss: 1.6971204280853271
Validation loss: 1.8712089807867147
Epoch: 7| Step: 8
Training loss: 1.6225095987319946
Validation loss: 1.8981193561348126
Epoch: 7| Step: 9
Training loss: 1.5904529094696045
Validation loss: 1.877914479310564
Epoch: 7| Step: 10
Training loss: 1.3566747903823853
Validation loss: 1.8786257634059988
Epoch: 7| Step: 11
Training loss: 2.1500983238220215
Validation loss: 1.8854238669649304
Epoch: 7| Step: 12
Training loss: 1.9033420085906982
Validation loss: 1.8744522273111686
Epoch: 7| Step: 13
Training loss: 2.3511528968811035
Validation loss: 1.8805798163516916
Epoch: 7| Step: 14
Training loss: 1.788079023361206
Validation loss: 1.899103758146437
Epoch: 7| Step: 15
Training loss: 1.9556020498275757
Validation loss: 1.8910695897589485
Epoch: 68| Step: 0
Training loss: 1.580763816833496
Validation loss: 1.8724448560810776
Epoch: 7| Step: 1
Training loss: 1.8724143505096436
Validation loss: 1.89973553907957
Epoch: 7| Step: 2
Training loss: 1.9774154424667358
Validation loss: 1.9031848735946546
Epoch: 7| Step: 3
Training loss: 2.702575445175171
Validation loss: 1.905752619393438
Epoch: 7| Step: 4
Training loss: 2.3417930603027344
Validation loss: 1.885313131826387
Epoch: 7| Step: 5
Training loss: 2.28713321685791
Validation loss: 1.8761391588252225
Epoch: 7| Step: 6
Training loss: 1.9842666387557983
Validation loss: 1.8830782698212767
Epoch: 7| Step: 7
Training loss: 2.2353732585906982
Validation loss: 1.882612312440392
Epoch: 7| Step: 8
Training loss: 2.620192527770996
Validation loss: 1.8872916166730922
Epoch: 7| Step: 9
Training loss: 1.8707116842269897
Validation loss: 1.8841149618299744
Epoch: 7| Step: 10
Training loss: 1.7772026062011719
Validation loss: 1.8775069138986602
Epoch: 7| Step: 11
Training loss: 2.177809476852417
Validation loss: 1.8722626253855315
Epoch: 7| Step: 12
Training loss: 1.1861581802368164
Validation loss: 1.884500795131107
Epoch: 7| Step: 13
Training loss: 1.5572683811187744
Validation loss: 1.8828993238133491
Epoch: 7| Step: 14
Training loss: 1.916455864906311
Validation loss: 1.8695124190488308
Epoch: 7| Step: 15
Training loss: 2.1310763359069824
Validation loss: 1.874142019011134
Epoch: 69| Step: 0
Training loss: 2.4044792652130127
Validation loss: 1.8778854205453996
Epoch: 7| Step: 1
Training loss: 1.8838484287261963
Validation loss: 1.8799068018686858
Epoch: 7| Step: 2
Training loss: 1.9246997833251953
Validation loss: 1.861291182984551
Epoch: 7| Step: 3
Training loss: 1.695762038230896
Validation loss: 1.878995248739668
Epoch: 7| Step: 4
Training loss: 1.9567596912384033
Validation loss: 1.845182881080847
Epoch: 7| Step: 5
Training loss: 2.3632864952087402
Validation loss: 1.8489471390950594
Epoch: 7| Step: 6
Training loss: 2.0784645080566406
Validation loss: 1.853205316358333
Epoch: 7| Step: 7
Training loss: 1.6883249282836914
Validation loss: 1.8593206045438917
Epoch: 7| Step: 8
Training loss: 1.8271706104278564
Validation loss: 1.8344999577501695
Epoch: 7| Step: 9
Training loss: 2.272894859313965
Validation loss: 1.8503056507316424
Epoch: 7| Step: 10
Training loss: 2.015308380126953
Validation loss: 1.8493027721377586
Epoch: 7| Step: 11
Training loss: 1.6409237384796143
Validation loss: 1.8408927737380103
Epoch: 7| Step: 12
Training loss: 2.1395082473754883
Validation loss: 1.8595108745767057
Epoch: 7| Step: 13
Training loss: 2.15936017036438
Validation loss: 1.8640187541357904
Epoch: 7| Step: 14
Training loss: 1.8932466506958008
Validation loss: 1.8580824068124346
Epoch: 7| Step: 15
Training loss: 2.323244094848633
Validation loss: 1.8503140511272622
Epoch: 70| Step: 0
Training loss: 1.8889963626861572
Validation loss: 1.8654677867889404
Epoch: 7| Step: 1
Training loss: 2.066464424133301
Validation loss: 1.875766615215823
Epoch: 7| Step: 2
Training loss: 2.2459263801574707
Validation loss: 1.883449673652649
Epoch: 7| Step: 3
Training loss: 1.9373185634613037
Validation loss: 1.8763058056934274
Epoch: 7| Step: 4
Training loss: 1.8404769897460938
Validation loss: 1.8790303854633579
Epoch: 7| Step: 5
Training loss: 2.05436635017395
Validation loss: 1.8793371306906501
Epoch: 7| Step: 6
Training loss: 1.7183215618133545
Validation loss: 1.8874151226427915
Epoch: 7| Step: 7
Training loss: 1.9547984600067139
Validation loss: 1.8894095094941503
Epoch: 7| Step: 8
Training loss: 2.3138267993927
Validation loss: 1.8847301229298543
Epoch: 7| Step: 9
Training loss: 1.654327392578125
Validation loss: 1.8792958645511875
Epoch: 7| Step: 10
Training loss: 1.9976450204849243
Validation loss: 1.8815087268678405
Epoch: 7| Step: 11
Training loss: 2.0971572399139404
Validation loss: 1.889009110361552
Epoch: 7| Step: 12
Training loss: 2.1794962882995605
Validation loss: 1.876163424347802
Epoch: 7| Step: 13
Training loss: 2.007326602935791
Validation loss: 1.8992733337896333
Epoch: 7| Step: 14
Training loss: 1.8710933923721313
Validation loss: 1.8905871283236166
Epoch: 7| Step: 15
Training loss: 2.3516383171081543
Validation loss: 1.8934229226421109
Epoch: 71| Step: 0
Training loss: 1.8608787059783936
Validation loss: 1.8849835721708887
Epoch: 7| Step: 1
Training loss: 2.293452501296997
Validation loss: 1.8780829623448763
Epoch: 7| Step: 2
Training loss: 1.6458828449249268
Validation loss: 1.8665264913504072
Epoch: 7| Step: 3
Training loss: 2.091336250305176
Validation loss: 1.8805322381232281
Epoch: 7| Step: 4
Training loss: 2.3986241817474365
Validation loss: 1.885837096104519
Epoch: 7| Step: 5
Training loss: 2.1663877964019775
Validation loss: 1.8806557861163462
Epoch: 7| Step: 6
Training loss: 2.51358699798584
Validation loss: 1.8956823357575232
Epoch: 7| Step: 7
Training loss: 1.7134513854980469
Validation loss: 1.8634379356027506
Epoch: 7| Step: 8
Training loss: 1.5228482484817505
Validation loss: 1.8689466157405497
Epoch: 7| Step: 9
Training loss: 2.484689950942993
Validation loss: 1.8936665667046746
Epoch: 7| Step: 10
Training loss: 1.971700668334961
Validation loss: 1.8675670898217949
Epoch: 7| Step: 11
Training loss: 2.3688461780548096
Validation loss: 1.8693916077236477
Epoch: 7| Step: 12
Training loss: 1.5721383094787598
Validation loss: 1.8606699233432469
Epoch: 7| Step: 13
Training loss: 2.448493242263794
Validation loss: 1.8785567643831103
Epoch: 7| Step: 14
Training loss: 2.0673344135284424
Validation loss: 1.868162722038708
Epoch: 7| Step: 15
Training loss: 1.3140335083007812
Validation loss: 1.8600392513137927
Epoch: 72| Step: 0
Training loss: 2.282527208328247
Validation loss: 1.836265732916139
Epoch: 7| Step: 1
Training loss: 2.863450050354004
Validation loss: 1.8629528481325657
Epoch: 7| Step: 2
Training loss: 2.3311257362365723
Validation loss: 1.857464884682525
Epoch: 7| Step: 3
Training loss: 1.8978248834609985
Validation loss: 1.8623317840288012
Epoch: 7| Step: 4
Training loss: 1.9050557613372803
Validation loss: 1.8658667605557888
Epoch: 7| Step: 5
Training loss: 1.7789623737335205
Validation loss: 1.8450729083671844
Epoch: 7| Step: 6
Training loss: 1.9910533428192139
Validation loss: 1.867415670868304
Epoch: 7| Step: 7
Training loss: 1.421693205833435
Validation loss: 1.8633612797414656
Epoch: 7| Step: 8
Training loss: 1.8499958515167236
Validation loss: 1.8598550944019565
Epoch: 7| Step: 9
Training loss: 1.5189473628997803
Validation loss: 1.8715609800901345
Epoch: 7| Step: 10
Training loss: 2.0296072959899902
Validation loss: 1.8703701984968117
Epoch: 7| Step: 11
Training loss: 1.973589539527893
Validation loss: 1.8635582820974665
Epoch: 7| Step: 12
Training loss: 1.9010883569717407
Validation loss: 1.8747643369564908
Epoch: 7| Step: 13
Training loss: 2.4779422283172607
Validation loss: 1.877506250957791
Epoch: 7| Step: 14
Training loss: 2.1299941539764404
Validation loss: 1.8742155445565423
Epoch: 7| Step: 15
Training loss: 2.0149054527282715
Validation loss: 1.8656148087206503
Epoch: 73| Step: 0
Training loss: 2.3730971813201904
Validation loss: 1.8728572516132602
Epoch: 7| Step: 1
Training loss: 2.2135887145996094
Validation loss: 1.8646997736512327
Epoch: 7| Step: 2
Training loss: 2.23683500289917
Validation loss: 1.8872860661513513
Epoch: 7| Step: 3
Training loss: 1.52851402759552
Validation loss: 1.861393127510016
Epoch: 7| Step: 4
Training loss: 1.7809298038482666
Validation loss: 1.8837234716621234
Epoch: 7| Step: 5
Training loss: 1.6908466815948486
Validation loss: 1.8909759684432326
Epoch: 7| Step: 6
Training loss: 1.9400184154510498
Validation loss: 1.9018823723141238
Epoch: 7| Step: 7
Training loss: 1.5931679010391235
Validation loss: 1.8838078401071563
Epoch: 7| Step: 8
Training loss: 2.6533992290496826
Validation loss: 1.8796954746726606
Epoch: 7| Step: 9
Training loss: 1.9611297845840454
Validation loss: 1.910770139248251
Epoch: 7| Step: 10
Training loss: 2.2510361671447754
Validation loss: 1.9104312701190975
Epoch: 7| Step: 11
Training loss: 2.4592931270599365
Validation loss: 1.8898946844416558
Epoch: 7| Step: 12
Training loss: 1.5146510601043701
Validation loss: 1.9041053485527313
Epoch: 7| Step: 13
Training loss: 2.229198455810547
Validation loss: 1.8674453488356775
Epoch: 7| Step: 14
Training loss: 2.263033628463745
Validation loss: 1.9090592543855847
Epoch: 7| Step: 15
Training loss: 1.7273566722869873
Validation loss: 1.8799626458463052
Epoch: 74| Step: 0
Training loss: 1.9141664505004883
Validation loss: 1.8817709135494645
Epoch: 7| Step: 1
Training loss: 1.9575313329696655
Validation loss: 1.858226293282543
Epoch: 7| Step: 2
Training loss: 2.294997453689575
Validation loss: 1.8838486388432893
Epoch: 7| Step: 3
Training loss: 2.256301164627075
Validation loss: 1.8751406317992176
Epoch: 7| Step: 4
Training loss: 2.239751100540161
Validation loss: 1.8644949600850935
Epoch: 7| Step: 5
Training loss: 1.8228248357772827
Validation loss: 1.859614432286873
Epoch: 7| Step: 6
Training loss: 1.5356786251068115
Validation loss: 1.8631824563733108
Epoch: 7| Step: 7
Training loss: 1.7371501922607422
Validation loss: 1.8684627383732968
Epoch: 7| Step: 8
Training loss: 2.0484509468078613
Validation loss: 1.873262724430441
Epoch: 7| Step: 9
Training loss: 2.3113296031951904
Validation loss: 1.8721892207646542
Epoch: 7| Step: 10
Training loss: 1.751145362854004
Validation loss: 1.863435412482392
Epoch: 7| Step: 11
Training loss: 1.8340787887573242
Validation loss: 1.861138716876078
Epoch: 7| Step: 12
Training loss: 2.2003464698791504
Validation loss: 1.869393561383803
Epoch: 7| Step: 13
Training loss: 2.1097068786621094
Validation loss: 1.866385170024076
Epoch: 7| Step: 14
Training loss: 1.8766629695892334
Validation loss: 1.8582301122679128
Epoch: 7| Step: 15
Training loss: 2.1905062198638916
Validation loss: 1.8479191210630128
Epoch: 75| Step: 0
Training loss: 2.476109743118286
Validation loss: 1.8634671461667947
Epoch: 7| Step: 1
Training loss: 1.9748506546020508
Validation loss: 1.855888604260177
Epoch: 7| Step: 2
Training loss: 2.505704164505005
Validation loss: 1.8505657628285799
Epoch: 7| Step: 3
Training loss: 2.198427677154541
Validation loss: 1.8526635152830495
Epoch: 7| Step: 4
Training loss: 1.9913947582244873
Validation loss: 1.8619590457394826
Epoch: 7| Step: 5
Training loss: 1.7469552755355835
Validation loss: 1.8563998723201613
Epoch: 7| Step: 6
Training loss: 1.7607431411743164
Validation loss: 1.8456545485009392
Epoch: 7| Step: 7
Training loss: 2.116022825241089
Validation loss: 1.8328371133735712
Epoch: 7| Step: 8
Training loss: 1.7961864471435547
Validation loss: 1.8467718911685531
Epoch: 7| Step: 9
Training loss: 2.149043321609497
Validation loss: 1.8416271381240954
Epoch: 7| Step: 10
Training loss: 2.3035197257995605
Validation loss: 1.838663571172481
Epoch: 7| Step: 11
Training loss: 1.1493059396743774
Validation loss: 1.8410273627411546
Epoch: 7| Step: 12
Training loss: 1.9020198583602905
Validation loss: 1.863189807041086
Epoch: 7| Step: 13
Training loss: 1.6532704830169678
Validation loss: 1.8532307876957406
Epoch: 7| Step: 14
Training loss: 2.2616875171661377
Validation loss: 1.8583800912761002
Epoch: 7| Step: 15
Training loss: 2.225404739379883
Validation loss: 1.8719016081995243
Epoch: 76| Step: 0
Training loss: 2.6786694526672363
Validation loss: 1.8703017603579184
Epoch: 7| Step: 1
Training loss: 2.2911739349365234
Validation loss: 1.865285177025006
Epoch: 7| Step: 2
Training loss: 1.876563310623169
Validation loss: 1.8569992566280227
Epoch: 7| Step: 3
Training loss: 1.8142154216766357
Validation loss: 1.854129064854958
Epoch: 7| Step: 4
Training loss: 2.5421669483184814
Validation loss: 1.8517372145069588
Epoch: 7| Step: 5
Training loss: 1.7211129665374756
Validation loss: 1.8399515709431051
Epoch: 7| Step: 6
Training loss: 2.0844900608062744
Validation loss: 1.8449955664092688
Epoch: 7| Step: 7
Training loss: 2.20666241645813
Validation loss: 1.8620329203365518
Epoch: 7| Step: 8
Training loss: 1.7951877117156982
Validation loss: 1.8593087084859394
Epoch: 7| Step: 9
Training loss: 1.7705920934677124
Validation loss: 1.835307682160851
Epoch: 7| Step: 10
Training loss: 1.4263956546783447
Validation loss: 1.8607008114135524
Epoch: 7| Step: 11
Training loss: 1.909112572669983
Validation loss: 1.8618754165635691
Epoch: 7| Step: 12
Training loss: 2.3570828437805176
Validation loss: 1.8457074937202949
Epoch: 7| Step: 13
Training loss: 1.8802745342254639
Validation loss: 1.861582895834669
Epoch: 7| Step: 14
Training loss: 1.9957592487335205
Validation loss: 1.8484294826178242
Epoch: 7| Step: 15
Training loss: 1.6929031610488892
Validation loss: 1.8689910387821336
Epoch: 77| Step: 0
Training loss: 1.90432870388031
Validation loss: 1.839884763998951
Epoch: 7| Step: 1
Training loss: 2.613884449005127
Validation loss: 1.8561690874236951
Epoch: 7| Step: 2
Training loss: 1.7450653314590454
Validation loss: 1.8691295033736195
Epoch: 7| Step: 3
Training loss: 2.0899269580841064
Validation loss: 1.8641111610604704
Epoch: 7| Step: 4
Training loss: 2.0124893188476562
Validation loss: 1.8472663498610902
Epoch: 7| Step: 5
Training loss: 2.3542368412017822
Validation loss: 1.854164161270471
Epoch: 7| Step: 6
Training loss: 1.9799973964691162
Validation loss: 1.8519246989874532
Epoch: 7| Step: 7
Training loss: 2.524876117706299
Validation loss: 1.8645256123096823
Epoch: 7| Step: 8
Training loss: 1.767925500869751
Validation loss: 1.871560731380106
Epoch: 7| Step: 9
Training loss: 2.5321877002716064
Validation loss: 1.8606948389423836
Epoch: 7| Step: 10
Training loss: 2.0743682384490967
Validation loss: 1.8570924002489597
Epoch: 7| Step: 11
Training loss: 1.7813905477523804
Validation loss: 1.8602307082937777
Epoch: 7| Step: 12
Training loss: 1.4174860715866089
Validation loss: 1.8532951667154436
Epoch: 7| Step: 13
Training loss: 1.992262601852417
Validation loss: 1.8638105118017403
Epoch: 7| Step: 14
Training loss: 1.4493142366409302
Validation loss: 1.883626143709361
Epoch: 7| Step: 15
Training loss: 2.013823986053467
Validation loss: 1.8755123881127338
Epoch: 78| Step: 0
Training loss: 1.8458057641983032
Validation loss: 1.8705387578593742
Epoch: 7| Step: 1
Training loss: 1.8894802331924438
Validation loss: 1.8634161974886339
Epoch: 7| Step: 2
Training loss: 1.9543853998184204
Validation loss: 1.8818732817395984
Epoch: 7| Step: 3
Training loss: 1.7140239477157593
Validation loss: 1.8694951139765679
Epoch: 7| Step: 4
Training loss: 2.2223236560821533
Validation loss: 1.864721073521127
Epoch: 7| Step: 5
Training loss: 1.9604419469833374
Validation loss: 1.868912433548797
Epoch: 7| Step: 6
Training loss: 2.444296360015869
Validation loss: 1.8548155894382394
Epoch: 7| Step: 7
Training loss: 1.7408071756362915
Validation loss: 1.8805399026802119
Epoch: 7| Step: 8
Training loss: 2.1068835258483887
Validation loss: 1.8676093482285094
Epoch: 7| Step: 9
Training loss: 1.6461842060089111
Validation loss: 1.882751574619211
Epoch: 7| Step: 10
Training loss: 1.7125869989395142
Validation loss: 1.8898334914831807
Epoch: 7| Step: 11
Training loss: 2.3939566612243652
Validation loss: 1.8614822660418724
Epoch: 7| Step: 12
Training loss: 2.270164966583252
Validation loss: 1.8749245722516834
Epoch: 7| Step: 13
Training loss: 2.1913154125213623
Validation loss: 1.8660343688168972
Epoch: 7| Step: 14
Training loss: 2.053227663040161
Validation loss: 1.8492474736069604
Epoch: 7| Step: 15
Training loss: 1.986564040184021
Validation loss: 1.8681883160158885
Epoch: 79| Step: 0
Training loss: 1.4062474966049194
Validation loss: 1.856794619731766
Epoch: 7| Step: 1
Training loss: 2.136892795562744
Validation loss: 1.865587623856908
Epoch: 7| Step: 2
Training loss: 1.820259690284729
Validation loss: 1.8668050131351828
Epoch: 7| Step: 3
Training loss: 1.5333513021469116
Validation loss: 1.8572812260483667
Epoch: 7| Step: 4
Training loss: 2.328167200088501
Validation loss: 1.8564657350238278
Epoch: 7| Step: 5
Training loss: 2.05200457572937
Validation loss: 1.8647505962591377
Epoch: 7| Step: 6
Training loss: 2.6507558822631836
Validation loss: 1.8471850542713413
Epoch: 7| Step: 7
Training loss: 2.3656208515167236
Validation loss: 1.8658847234231963
Epoch: 7| Step: 8
Training loss: 2.529515504837036
Validation loss: 1.863927235706247
Epoch: 7| Step: 9
Training loss: 1.155932903289795
Validation loss: 1.8643876477111159
Epoch: 7| Step: 10
Training loss: 2.1461102962493896
Validation loss: 1.8624255682924669
Epoch: 7| Step: 11
Training loss: 2.08882212638855
Validation loss: 1.857019746903893
Epoch: 7| Step: 12
Training loss: 1.8884586095809937
Validation loss: 1.8398646587948146
Epoch: 7| Step: 13
Training loss: 2.0958526134490967
Validation loss: 1.8358687676971766
Epoch: 7| Step: 14
Training loss: 2.335866928100586
Validation loss: 1.8419476678903155
Epoch: 7| Step: 15
Training loss: 1.6036710739135742
Validation loss: 1.8420067708269299
Epoch: 80| Step: 0
Training loss: 2.216503620147705
Validation loss: 1.826564369441794
Epoch: 7| Step: 1
Training loss: 2.740448474884033
Validation loss: 1.8478289027865842
Epoch: 7| Step: 2
Training loss: 1.4842312335968018
Validation loss: 1.8393807411193848
Epoch: 7| Step: 3
Training loss: 1.3415848016738892
Validation loss: 1.8424594916885706
Epoch: 7| Step: 4
Training loss: 2.331547260284424
Validation loss: 1.8462181074156179
Epoch: 7| Step: 5
Training loss: 1.693556547164917
Validation loss: 1.8456926637416264
Epoch: 7| Step: 6
Training loss: 1.7304519414901733
Validation loss: 1.8611261707415683
Epoch: 7| Step: 7
Training loss: 1.6129432916641235
Validation loss: 1.8742884268863595
Epoch: 7| Step: 8
Training loss: 2.332688570022583
Validation loss: 1.8611684685988392
Epoch: 7| Step: 9
Training loss: 2.0470027923583984
Validation loss: 1.8633898882557163
Epoch: 7| Step: 10
Training loss: 2.3681912422180176
Validation loss: 1.8426858409703206
Epoch: 7| Step: 11
Training loss: 2.7162508964538574
Validation loss: 1.8417494502856577
Epoch: 7| Step: 12
Training loss: 1.815076470375061
Validation loss: 1.8485948602072626
Epoch: 7| Step: 13
Training loss: 1.6169599294662476
Validation loss: 1.8347073801987464
Epoch: 7| Step: 14
Training loss: 1.9991881847381592
Validation loss: 1.8462745663073423
Epoch: 7| Step: 15
Training loss: 1.8886321783065796
Validation loss: 1.8463223400733453
Epoch: 81| Step: 0
Training loss: 2.0602118968963623
Validation loss: 1.8622194931661482
Epoch: 7| Step: 1
Training loss: 2.0149950981140137
Validation loss: 1.8565624737911086
Epoch: 7| Step: 2
Training loss: 2.1079211235046387
Validation loss: 1.8707790117469623
Epoch: 7| Step: 3
Training loss: 2.529017448425293
Validation loss: 1.862685935960399
Epoch: 7| Step: 4
Training loss: 1.7810474634170532
Validation loss: 1.8753485130749161
Epoch: 7| Step: 5
Training loss: 1.9039119482040405
Validation loss: 1.870986766952405
Epoch: 7| Step: 6
Training loss: 2.082711696624756
Validation loss: 1.8567202768737463
Epoch: 7| Step: 7
Training loss: 2.252291679382324
Validation loss: 1.8745618655527239
Epoch: 7| Step: 8
Training loss: 1.9220399856567383
Validation loss: 1.8796738454763837
Epoch: 7| Step: 9
Training loss: 1.8070995807647705
Validation loss: 1.87366407123401
Epoch: 7| Step: 10
Training loss: 1.4548161029815674
Validation loss: 1.887669956083778
Epoch: 7| Step: 11
Training loss: 1.687448501586914
Validation loss: 1.880465480063459
Epoch: 7| Step: 12
Training loss: 2.1667513847351074
Validation loss: 1.8935902616102918
Epoch: 7| Step: 13
Training loss: 1.9874274730682373
Validation loss: 1.888097299946298
Epoch: 7| Step: 14
Training loss: 2.047595500946045
Validation loss: 1.8820304210237462
Epoch: 7| Step: 15
Training loss: 2.215916156768799
Validation loss: 1.8760606367811024
Epoch: 82| Step: 0
Training loss: 2.4166743755340576
Validation loss: 1.8812868818104695
Epoch: 7| Step: 1
Training loss: 2.2013518810272217
Validation loss: 1.8886949552906502
Epoch: 7| Step: 2
Training loss: 2.3697972297668457
Validation loss: 1.8836277783345834
Epoch: 7| Step: 3
Training loss: 1.9273545742034912
Validation loss: 1.8782286180866707
Epoch: 7| Step: 4
Training loss: 2.0451817512512207
Validation loss: 1.88997937020638
Epoch: 7| Step: 5
Training loss: 2.341219425201416
Validation loss: 1.898049284228318
Epoch: 7| Step: 6
Training loss: 2.127831220626831
Validation loss: 1.8912164221564642
Epoch: 7| Step: 7
Training loss: 2.524597644805908
Validation loss: 1.8555224113327136
Epoch: 7| Step: 8
Training loss: 1.8258459568023682
Validation loss: 1.879146856369732
Epoch: 7| Step: 9
Training loss: 1.954494833946228
Validation loss: 1.8669361716551747
Epoch: 7| Step: 10
Training loss: 1.461896538734436
Validation loss: 1.8672444803251638
Epoch: 7| Step: 11
Training loss: 1.7072681188583374
Validation loss: 1.8754721408267674
Epoch: 7| Step: 12
Training loss: 2.6174404621124268
Validation loss: 1.8609048265347379
Epoch: 7| Step: 13
Training loss: 1.8341636657714844
Validation loss: 1.864786569163096
Epoch: 7| Step: 14
Training loss: 1.299941062927246
Validation loss: 1.8682801526227444
Epoch: 7| Step: 15
Training loss: 1.534751534461975
Validation loss: 1.8751254853584784
Epoch: 83| Step: 0
Training loss: 2.41626238822937
Validation loss: 1.872088945169243
Epoch: 7| Step: 1
Training loss: 1.89583420753479
Validation loss: 1.8540042613050063
Epoch: 7| Step: 2
Training loss: 1.881216049194336
Validation loss: 1.8576818678876479
Epoch: 7| Step: 3
Training loss: 2.4457664489746094
Validation loss: 1.8666545830184607
Epoch: 7| Step: 4
Training loss: 1.815564751625061
Validation loss: 1.8449093729471988
Epoch: 7| Step: 5
Training loss: 2.163771390914917
Validation loss: 1.8537612818985534
Epoch: 7| Step: 6
Training loss: 2.2981886863708496
Validation loss: 1.8479632610897365
Epoch: 7| Step: 7
Training loss: 2.3993947505950928
Validation loss: 1.8539668090051884
Epoch: 7| Step: 8
Training loss: 1.318979024887085
Validation loss: 1.8484180179431284
Epoch: 7| Step: 9
Training loss: 2.8319339752197266
Validation loss: 1.8557779437346424
Epoch: 7| Step: 10
Training loss: 1.5705409049987793
Validation loss: 1.8592688857222632
Epoch: 7| Step: 11
Training loss: 1.6752946376800537
Validation loss: 1.8444656785443532
Epoch: 7| Step: 12
Training loss: 2.5108132362365723
Validation loss: 1.8589176436979993
Epoch: 7| Step: 13
Training loss: 1.3072636127471924
Validation loss: 1.8698353947495385
Epoch: 7| Step: 14
Training loss: 1.7617921829223633
Validation loss: 1.85914750836736
Epoch: 7| Step: 15
Training loss: 1.7264785766601562
Validation loss: 1.846671304256796
Epoch: 84| Step: 0
Training loss: 2.166152000427246
Validation loss: 1.8565256595611572
Epoch: 7| Step: 1
Training loss: 2.1082606315612793
Validation loss: 1.890082815568224
Epoch: 7| Step: 2
Training loss: 1.7787072658538818
Validation loss: 1.8593712307566361
Epoch: 7| Step: 3
Training loss: 2.143348217010498
Validation loss: 1.8662304878234863
Epoch: 7| Step: 4
Training loss: 2.1700663566589355
Validation loss: 1.856888628692078
Epoch: 7| Step: 5
Training loss: 2.0875940322875977
Validation loss: 1.8673210315567126
Epoch: 7| Step: 6
Training loss: 1.7053428888320923
Validation loss: 1.8718668368222902
Epoch: 7| Step: 7
Training loss: 1.9881560802459717
Validation loss: 1.861822024523783
Epoch: 7| Step: 8
Training loss: 1.1694518327713013
Validation loss: 1.856499543292917
Epoch: 7| Step: 9
Training loss: 2.086973190307617
Validation loss: 1.8605398076901334
Epoch: 7| Step: 10
Training loss: 2.1161186695098877
Validation loss: 1.8615301924643757
Epoch: 7| Step: 11
Training loss: 2.09230375289917
Validation loss: 1.8730483466772725
Epoch: 7| Step: 12
Training loss: 2.058199644088745
Validation loss: 1.867634945636173
Epoch: 7| Step: 13
Training loss: 2.139596462249756
Validation loss: 1.8817331602247498
Epoch: 7| Step: 14
Training loss: 1.9767557382583618
Validation loss: 1.8662419276271793
Epoch: 7| Step: 15
Training loss: 2.213865280151367
Validation loss: 1.8677362229326646
Epoch: 85| Step: 0
Training loss: 1.708200454711914
Validation loss: 1.8718827842808456
Epoch: 7| Step: 1
Training loss: 2.397364854812622
Validation loss: 1.8636341523781097
Epoch: 7| Step: 2
Training loss: 2.8527188301086426
Validation loss: 1.8742831893962064
Epoch: 7| Step: 3
Training loss: 1.4718148708343506
Validation loss: 1.885991136804759
Epoch: 7| Step: 4
Training loss: 2.1872196197509766
Validation loss: 1.8941553067817962
Epoch: 7| Step: 5
Training loss: 1.9932066202163696
Validation loss: 1.8559277700863297
Epoch: 7| Step: 6
Training loss: 2.0822672843933105
Validation loss: 1.8631451910348247
Epoch: 7| Step: 7
Training loss: 2.616790294647217
Validation loss: 1.8687670419542053
Epoch: 7| Step: 8
Training loss: 1.720275640487671
Validation loss: 1.8386908315068526
Epoch: 7| Step: 9
Training loss: 1.4913994073867798
Validation loss: 1.863491319066329
Epoch: 7| Step: 10
Training loss: 1.8270978927612305
Validation loss: 1.8595612889571156
Epoch: 7| Step: 11
Training loss: 2.391509532928467
Validation loss: 1.8657600545197082
Epoch: 7| Step: 12
Training loss: 1.5166338682174683
Validation loss: 1.8460276212623652
Epoch: 7| Step: 13
Training loss: 1.6032230854034424
Validation loss: 1.8586835132228385
Epoch: 7| Step: 14
Training loss: 2.173862934112549
Validation loss: 1.8684348656976824
Epoch: 7| Step: 15
Training loss: 2.2228877544403076
Validation loss: 1.8480532761100386
Epoch: 86| Step: 0
Training loss: 2.565958261489868
Validation loss: 1.845647028881869
Epoch: 7| Step: 1
Training loss: 1.8897616863250732
Validation loss: 1.8599295496082993
Epoch: 7| Step: 2
Training loss: 2.2889530658721924
Validation loss: 1.8611492724727383
Epoch: 7| Step: 3
Training loss: 1.6295287609100342
Validation loss: 1.8690065737250898
Epoch: 7| Step: 4
Training loss: 2.0819249153137207
Validation loss: 1.873426471682761
Epoch: 7| Step: 5
Training loss: 1.9522244930267334
Validation loss: 1.8605747848963565
Epoch: 7| Step: 6
Training loss: 1.836580514907837
Validation loss: 1.8539694607686654
Epoch: 7| Step: 7
Training loss: 2.1856942176818848
Validation loss: 1.8817240994611233
Epoch: 7| Step: 8
Training loss: 1.4321043491363525
Validation loss: 1.8439741880773641
Epoch: 7| Step: 9
Training loss: 1.7974140644073486
Validation loss: 1.871226158931101
Epoch: 7| Step: 10
Training loss: 2.3144874572753906
Validation loss: 1.890305870728527
Epoch: 7| Step: 11
Training loss: 2.0120787620544434
Validation loss: 1.8763149282057507
Epoch: 7| Step: 12
Training loss: 1.7770588397979736
Validation loss: 1.8592600839601146
Epoch: 7| Step: 13
Training loss: 1.8571373224258423
Validation loss: 1.8718587177262889
Epoch: 7| Step: 14
Training loss: 2.2683773040771484
Validation loss: 1.8900790240267198
Epoch: 7| Step: 15
Training loss: 2.1875553131103516
Validation loss: 1.8774427921651937
Epoch: 87| Step: 0
Training loss: 2.491905689239502
Validation loss: 1.8696704288180783
Epoch: 7| Step: 1
Training loss: 2.85406494140625
Validation loss: 1.8686031986483567
Epoch: 7| Step: 2
Training loss: 2.3367388248443604
Validation loss: 1.87114131364891
Epoch: 7| Step: 3
Training loss: 1.2737486362457275
Validation loss: 1.8927136856874973
Epoch: 7| Step: 4
Training loss: 2.169631242752075
Validation loss: 1.8732342608541035
Epoch: 7| Step: 5
Training loss: 1.8126224279403687
Validation loss: 1.8557792919145213
Epoch: 7| Step: 6
Training loss: 1.7273699045181274
Validation loss: 1.8665371781630482
Epoch: 7| Step: 7
Training loss: 1.8531954288482666
Validation loss: 1.864365925891794
Epoch: 7| Step: 8
Training loss: 1.7009060382843018
Validation loss: 1.8359974185339838
Epoch: 7| Step: 9
Training loss: 1.9054529666900635
Validation loss: 1.8414526749000275
Epoch: 7| Step: 10
Training loss: 2.0607757568359375
Validation loss: 1.8494276382940278
Epoch: 7| Step: 11
Training loss: 1.725126028060913
Validation loss: 1.849543915378104
Epoch: 7| Step: 12
Training loss: 1.7412099838256836
Validation loss: 1.833041754557932
Epoch: 7| Step: 13
Training loss: 2.299445152282715
Validation loss: 1.8449450568329515
Epoch: 7| Step: 14
Training loss: 2.281451463699341
Validation loss: 1.8402684343804558
Epoch: 7| Step: 15
Training loss: 1.9792379140853882
Validation loss: 1.8412759484146997
Epoch: 88| Step: 0
Training loss: 2.276792287826538
Validation loss: 1.8447939045995259
Epoch: 7| Step: 1
Training loss: 1.3928823471069336
Validation loss: 1.8578675410730376
Epoch: 7| Step: 2
Training loss: 2.788067102432251
Validation loss: 1.8671105225309192
Epoch: 7| Step: 3
Training loss: 1.7380249500274658
Validation loss: 1.8514876056918137
Epoch: 7| Step: 4
Training loss: 2.1239266395568848
Validation loss: 1.8449800400425205
Epoch: 7| Step: 5
Training loss: 2.7153053283691406
Validation loss: 1.8696942981198537
Epoch: 7| Step: 6
Training loss: 1.536645531654358
Validation loss: 1.853042532214158
Epoch: 7| Step: 7
Training loss: 1.8588340282440186
Validation loss: 1.8682943539653751
Epoch: 7| Step: 8
Training loss: 2.374180316925049
Validation loss: 1.8454354315352954
Epoch: 7| Step: 9
Training loss: 2.061572551727295
Validation loss: 1.866231221946881
Epoch: 7| Step: 10
Training loss: 1.6239917278289795
Validation loss: 1.8573755411793003
Epoch: 7| Step: 11
Training loss: 1.883699655532837
Validation loss: 1.8841202559230996
Epoch: 7| Step: 12
Training loss: 1.200812816619873
Validation loss: 1.8785213643698384
Epoch: 7| Step: 13
Training loss: 1.6223948001861572
Validation loss: 1.8868533347150405
Epoch: 7| Step: 14
Training loss: 2.748091697692871
Validation loss: 1.9045353982088378
Epoch: 7| Step: 15
Training loss: 2.225323438644409
Validation loss: 1.8840362493940395
Epoch: 89| Step: 0
Training loss: 2.16865873336792
Validation loss: 1.8817241517759913
Epoch: 7| Step: 1
Training loss: 1.4059717655181885
Validation loss: 1.8862605832463546
Epoch: 7| Step: 2
Training loss: 1.662532091140747
Validation loss: 1.9015906045762756
Epoch: 7| Step: 3
Training loss: 2.0085320472717285
Validation loss: 1.9053713915159376
Epoch: 7| Step: 4
Training loss: 1.929565191268921
Validation loss: 1.897122179003928
Epoch: 7| Step: 5
Training loss: 1.858412504196167
Validation loss: 1.8888446641482894
Epoch: 7| Step: 6
Training loss: 2.494032859802246
Validation loss: 1.8909027808004146
Epoch: 7| Step: 7
Training loss: 1.9384548664093018
Validation loss: 1.892488965027624
Epoch: 7| Step: 8
Training loss: 2.0067737102508545
Validation loss: 1.9064282504774683
Epoch: 7| Step: 9
Training loss: 2.0866732597351074
Validation loss: 1.8999837225289653
Epoch: 7| Step: 10
Training loss: 2.3245296478271484
Validation loss: 1.8868540525436401
Epoch: 7| Step: 11
Training loss: 2.286423921585083
Validation loss: 1.8730504178314757
Epoch: 7| Step: 12
Training loss: 1.8714338541030884
Validation loss: 1.8935466558813192
Epoch: 7| Step: 13
Training loss: 2.401606559753418
Validation loss: 1.897515880118171
Epoch: 7| Step: 14
Training loss: 2.310781478881836
Validation loss: 1.8719071973142007
Epoch: 7| Step: 15
Training loss: 1.5533826351165771
Validation loss: 1.8755370438527719
Epoch: 90| Step: 0
Training loss: 1.7525701522827148
Validation loss: 1.8759828197012702
Epoch: 7| Step: 1
Training loss: 1.705786108970642
Validation loss: 1.876778865032059
Epoch: 7| Step: 2
Training loss: 2.309072732925415
Validation loss: 1.8633823815009576
Epoch: 7| Step: 3
Training loss: 1.9211046695709229
Validation loss: 1.8714709496326585
Epoch: 7| Step: 4
Training loss: 1.8490583896636963
Validation loss: 1.8706063203674426
Epoch: 7| Step: 5
Training loss: 3.064617156982422
Validation loss: 1.89330115592737
Epoch: 7| Step: 6
Training loss: 2.3758766651153564
Validation loss: 1.8802056449780362
Epoch: 7| Step: 7
Training loss: 1.2953325510025024
Validation loss: 1.8748487585740123
Epoch: 7| Step: 8
Training loss: 1.4167344570159912
Validation loss: 1.8587815735837538
Epoch: 7| Step: 9
Training loss: 2.143794536590576
Validation loss: 1.88154764998731
Epoch: 7| Step: 10
Training loss: 1.9958240985870361
Validation loss: 1.8612757406646399
Epoch: 7| Step: 11
Training loss: 1.5440000295639038
Validation loss: 1.8740095603380271
Epoch: 7| Step: 12
Training loss: 2.1528964042663574
Validation loss: 1.868841233870966
Epoch: 7| Step: 13
Training loss: 2.1818580627441406
Validation loss: 1.8708932245378014
Epoch: 7| Step: 14
Training loss: 1.671868085861206
Validation loss: 1.8814044556171774
Epoch: 7| Step: 15
Training loss: 2.5244123935699463
Validation loss: 1.864845251865524
Epoch: 91| Step: 0
Training loss: 2.1020193099975586
Validation loss: 1.8694059454279839
Epoch: 7| Step: 1
Training loss: 1.7822128534317017
Validation loss: 1.8588516369140407
Epoch: 7| Step: 2
Training loss: 2.571418285369873
Validation loss: 1.8719924148038136
Epoch: 7| Step: 3
Training loss: 1.5182383060455322
Validation loss: 1.8857734735063512
Epoch: 7| Step: 4
Training loss: 2.0989813804626465
Validation loss: 1.8610959018734718
Epoch: 7| Step: 5
Training loss: 1.776079535484314
Validation loss: 1.8553035027689213
Epoch: 7| Step: 6
Training loss: 1.5428452491760254
Validation loss: 1.8882931951138613
Epoch: 7| Step: 7
Training loss: 2.012258529663086
Validation loss: 1.8889389449743916
Epoch: 7| Step: 8
Training loss: 1.7216522693634033
Validation loss: 1.8858849161820446
Epoch: 7| Step: 9
Training loss: 2.104621648788452
Validation loss: 1.8838620606086236
Epoch: 7| Step: 10
Training loss: 2.6929233074188232
Validation loss: 1.8667791241364513
Epoch: 7| Step: 11
Training loss: 2.0957517623901367
Validation loss: 1.8660497511033531
Epoch: 7| Step: 12
Training loss: 1.6075210571289062
Validation loss: 1.8618384582533254
Epoch: 7| Step: 13
Training loss: 2.334433078765869
Validation loss: 1.863061174214315
Epoch: 7| Step: 14
Training loss: 1.8136703968048096
Validation loss: 1.8767559373979088
Epoch: 7| Step: 15
Training loss: 2.2420742511749268
Validation loss: 1.869741180817858
Epoch: 92| Step: 0
Training loss: 1.5598233938217163
Validation loss: 1.8620350823985587
Epoch: 7| Step: 1
Training loss: 1.8078933954238892
Validation loss: 1.8594883989087112
Epoch: 7| Step: 2
Training loss: 2.021397113800049
Validation loss: 1.8408076720272037
Epoch: 7| Step: 3
Training loss: 1.720581293106079
Validation loss: 1.8594226862886827
Epoch: 7| Step: 4
Training loss: 2.389622449874878
Validation loss: 1.8607249731640163
Epoch: 7| Step: 5
Training loss: 2.633781909942627
Validation loss: 1.853924545452749
Epoch: 7| Step: 6
Training loss: 1.31634521484375
Validation loss: 1.8442515023320698
Epoch: 7| Step: 7
Training loss: 2.065220355987549
Validation loss: 1.8501893444884596
Epoch: 7| Step: 8
Training loss: 2.340614080429077
Validation loss: 1.8478013156986923
Epoch: 7| Step: 9
Training loss: 1.5224014520645142
Validation loss: 1.874287429473383
Epoch: 7| Step: 10
Training loss: 2.554736852645874
Validation loss: 1.881580475422976
Epoch: 7| Step: 11
Training loss: 1.8468255996704102
Validation loss: 1.850940647742731
Epoch: 7| Step: 12
Training loss: 1.6374790668487549
Validation loss: 1.8601486494215271
Epoch: 7| Step: 13
Training loss: 1.8143808841705322
Validation loss: 1.8581156927904636
Epoch: 7| Step: 14
Training loss: 2.690436840057373
Validation loss: 1.8808736252270157
Epoch: 7| Step: 15
Training loss: 2.1946117877960205
Validation loss: 1.8823738098144531
Epoch: 93| Step: 0
Training loss: 1.7847087383270264
Validation loss: 1.852237663680701
Epoch: 7| Step: 1
Training loss: 1.90045166015625
Validation loss: 1.8445418532803761
Epoch: 7| Step: 2
Training loss: 2.190739154815674
Validation loss: 1.8430051477692968
Epoch: 7| Step: 3
Training loss: 2.07594633102417
Validation loss: 1.8193103392347156
Epoch: 7| Step: 4
Training loss: 1.7904659509658813
Validation loss: 1.8157360082050022
Epoch: 7| Step: 5
Training loss: 1.767630934715271
Validation loss: 1.8031809758796966
Epoch: 7| Step: 6
Training loss: 2.1372313499450684
Validation loss: 1.8196032398896251
Epoch: 7| Step: 7
Training loss: 2.277296543121338
Validation loss: 1.8267711615390916
Epoch: 7| Step: 8
Training loss: 1.6610357761383057
Validation loss: 1.8223714245309075
Epoch: 7| Step: 9
Training loss: 1.8844362497329712
Validation loss: 1.8274068712330551
Epoch: 7| Step: 10
Training loss: 1.7528034448623657
Validation loss: 1.8131407284908156
Epoch: 7| Step: 11
Training loss: 1.8826115131378174
Validation loss: 1.8309906549590955
Epoch: 7| Step: 12
Training loss: 2.5173654556274414
Validation loss: 1.8229200359728697
Epoch: 7| Step: 13
Training loss: 2.621917247772217
Validation loss: 1.8263477876032
Epoch: 7| Step: 14
Training loss: 2.2517037391662598
Validation loss: 1.8109986387568413
Epoch: 7| Step: 15
Training loss: 1.7677977085113525
Validation loss: 1.810569680851998
Epoch: 94| Step: 0
Training loss: 1.6964229345321655
Validation loss: 1.8033579639393649
Epoch: 7| Step: 1
Training loss: 2.2832932472229004
Validation loss: 1.840543217796216
Epoch: 7| Step: 2
Training loss: 1.408547043800354
Validation loss: 1.8415653954306952
Epoch: 7| Step: 3
Training loss: 1.4623358249664307
Validation loss: 1.8401762555829055
Epoch: 7| Step: 4
Training loss: 1.6637909412384033
Validation loss: 1.8271986417633166
Epoch: 7| Step: 5
Training loss: 2.1601359844207764
Validation loss: 1.8558917122779133
Epoch: 7| Step: 6
Training loss: 2.4465479850769043
Validation loss: 1.8557927316898921
Epoch: 7| Step: 7
Training loss: 1.8809372186660767
Validation loss: 1.8677657774026446
Epoch: 7| Step: 8
Training loss: 1.548292875289917
Validation loss: 1.8613395270683784
Epoch: 7| Step: 9
Training loss: 2.9004886150360107
Validation loss: 1.8850519151138745
Epoch: 7| Step: 10
Training loss: 2.0903701782226562
Validation loss: 1.8684283683625915
Epoch: 7| Step: 11
Training loss: 2.0561530590057373
Validation loss: 1.8864352051302684
Epoch: 7| Step: 12
Training loss: 2.2569379806518555
Validation loss: 1.9020315374401833
Epoch: 7| Step: 13
Training loss: 1.9503589868545532
Validation loss: 1.88795424108025
Epoch: 7| Step: 14
Training loss: 2.1633689403533936
Validation loss: 1.894134481176198
Epoch: 7| Step: 15
Training loss: 1.8750202655792236
Validation loss: 1.8891985733732044
Epoch: 95| Step: 0
Training loss: 2.176828622817993
Validation loss: 1.8851732152829068
Epoch: 7| Step: 1
Training loss: 2.286090850830078
Validation loss: 1.8847428688900076
Epoch: 7| Step: 2
Training loss: 1.8359794616699219
Validation loss: 1.8978637199607684
Epoch: 7| Step: 3
Training loss: 2.559201717376709
Validation loss: 1.9006994705406024
Epoch: 7| Step: 4
Training loss: 2.0187952518463135
Validation loss: 1.8796957053726526
Epoch: 7| Step: 5
Training loss: 2.2978644371032715
Validation loss: 1.8750006569375237
Epoch: 7| Step: 6
Training loss: 1.9916341304779053
Validation loss: 1.8679904020089897
Epoch: 7| Step: 7
Training loss: 1.76680588722229
Validation loss: 1.8589403680760226
Epoch: 7| Step: 8
Training loss: 2.248444080352783
Validation loss: 1.8744905243674628
Epoch: 7| Step: 9
Training loss: 1.6098148822784424
Validation loss: 1.8821370241453321
Epoch: 7| Step: 10
Training loss: 1.5269076824188232
Validation loss: 1.8772902874637851
Epoch: 7| Step: 11
Training loss: 2.513094425201416
Validation loss: 1.8862847578611306
Epoch: 7| Step: 12
Training loss: 2.0193817615509033
Validation loss: 1.8597332873790384
Epoch: 7| Step: 13
Training loss: 2.0557796955108643
Validation loss: 1.8526709096894847
Epoch: 7| Step: 14
Training loss: 1.4236667156219482
Validation loss: 1.8643197292904201
Epoch: 7| Step: 15
Training loss: 1.6883996725082397
Validation loss: 1.8783107215552022
Epoch: 96| Step: 0
Training loss: 2.6330819129943848
Validation loss: 1.867851725585169
Epoch: 7| Step: 1
Training loss: 1.9871937036514282
Validation loss: 1.8648008365425275
Epoch: 7| Step: 2
Training loss: 1.4913420677185059
Validation loss: 1.8727578550791568
Epoch: 7| Step: 3
Training loss: 2.113797664642334
Validation loss: 1.8629779558387591
Epoch: 7| Step: 4
Training loss: 1.8229057788848877
Validation loss: 1.862307562244882
Epoch: 7| Step: 5
Training loss: 2.4215247631073
Validation loss: 1.8778887172397092
Epoch: 7| Step: 6
Training loss: 1.823219656944275
Validation loss: 1.8521128309716424
Epoch: 7| Step: 7
Training loss: 1.917443037033081
Validation loss: 1.8597225585429789
Epoch: 7| Step: 8
Training loss: 1.9311323165893555
Validation loss: 1.8658442420067547
Epoch: 7| Step: 9
Training loss: 2.0070321559906006
Validation loss: 1.8575142913585088
Epoch: 7| Step: 10
Training loss: 2.344050645828247
Validation loss: 1.8647316514159278
Epoch: 7| Step: 11
Training loss: 1.6685459613800049
Validation loss: 1.8500604663821434
Epoch: 7| Step: 12
Training loss: 1.9262205362319946
Validation loss: 1.8717953704243941
Epoch: 7| Step: 13
Training loss: 1.7722959518432617
Validation loss: 1.8639400828656534
Epoch: 7| Step: 14
Training loss: 2.195852756500244
Validation loss: 1.872587868635603
Epoch: 7| Step: 15
Training loss: 1.8475223779678345
Validation loss: 1.8643152079136251
Epoch: 97| Step: 0
Training loss: 1.5504621267318726
Validation loss: 1.8655065821229124
Epoch: 7| Step: 1
Training loss: 1.613785982131958
Validation loss: 1.8687937053845083
Epoch: 7| Step: 2
Training loss: 2.213832378387451
Validation loss: 1.8728568588229393
Epoch: 7| Step: 3
Training loss: 1.7134716510772705
Validation loss: 1.890806563466573
Epoch: 7| Step: 4
Training loss: 2.019646167755127
Validation loss: 1.8628575921916275
Epoch: 7| Step: 5
Training loss: 2.194058656692505
Validation loss: 1.8863765327192896
Epoch: 7| Step: 6
Training loss: 1.940427541732788
Validation loss: 1.8821697835441973
Epoch: 7| Step: 7
Training loss: 1.9746100902557373
Validation loss: 1.8828542481223456
Epoch: 7| Step: 8
Training loss: 1.5452663898468018
Validation loss: 1.8771949997908777
Epoch: 7| Step: 9
Training loss: 2.089506149291992
Validation loss: 1.886627788166348
Epoch: 7| Step: 10
Training loss: 2.0562124252319336
Validation loss: 1.8736705548471684
Epoch: 7| Step: 11
Training loss: 1.5318377017974854
Validation loss: 1.87484051855348
Epoch: 7| Step: 12
Training loss: 2.519636631011963
Validation loss: 1.8780768569424855
Epoch: 7| Step: 13
Training loss: 1.7759463787078857
Validation loss: 1.8537338088742263
Epoch: 7| Step: 14
Training loss: 3.1104557514190674
Validation loss: 1.8823690688867363
Epoch: 7| Step: 15
Training loss: 2.0583314895629883
Validation loss: 1.8581220117404307
Epoch: 98| Step: 0
Training loss: 2.1896934509277344
Validation loss: 1.872518231542848
Epoch: 7| Step: 1
Training loss: 1.993886947631836
Validation loss: 1.8661301341845835
Epoch: 7| Step: 2
Training loss: 2.399186611175537
Validation loss: 1.8646607321800945
Epoch: 7| Step: 3
Training loss: 2.353571891784668
Validation loss: 1.8714841698571074
Epoch: 7| Step: 4
Training loss: 2.5159428119659424
Validation loss: 1.8672581593767346
Epoch: 7| Step: 5
Training loss: 1.598952054977417
Validation loss: 1.8702300709786175
Epoch: 7| Step: 6
Training loss: 1.769171953201294
Validation loss: 1.8791924483484501
Epoch: 7| Step: 7
Training loss: 1.7835947275161743
Validation loss: 1.8415391676717525
Epoch: 7| Step: 8
Training loss: 2.047489643096924
Validation loss: 1.8614651513614242
Epoch: 7| Step: 9
Training loss: 2.1453208923339844
Validation loss: 1.8357437025728842
Epoch: 7| Step: 10
Training loss: 1.9181362390518188
Validation loss: 1.8575247028748767
Epoch: 7| Step: 11
Training loss: 1.4411839246749878
Validation loss: 1.859525940401091
Epoch: 7| Step: 12
Training loss: 2.0254156589508057
Validation loss: 1.866003835801598
Epoch: 7| Step: 13
Training loss: 1.6019706726074219
Validation loss: 1.8536372201905833
Epoch: 7| Step: 14
Training loss: 1.8728735446929932
Validation loss: 1.8615239987270438
Epoch: 7| Step: 15
Training loss: 2.4065604209899902
Validation loss: 1.8423862637375756
Epoch: 99| Step: 0
Training loss: 2.0094785690307617
Validation loss: 1.863456057130004
Epoch: 7| Step: 1
Training loss: 1.988541603088379
Validation loss: 1.8431583488587853
Epoch: 7| Step: 2
Training loss: 1.7581068277359009
Validation loss: 1.8602394182905018
Epoch: 7| Step: 3
Training loss: 1.4813600778579712
Validation loss: 1.8721857542614284
Epoch: 7| Step: 4
Training loss: 2.2804932594299316
Validation loss: 1.8650842999382842
Epoch: 7| Step: 5
Training loss: 1.9455715417861938
Validation loss: 1.848615648935167
Epoch: 7| Step: 6
Training loss: 1.9825210571289062
Validation loss: 1.8536584308679156
Epoch: 7| Step: 7
Training loss: 2.221669912338257
Validation loss: 1.864088696541546
Epoch: 7| Step: 8
Training loss: 1.9536164999008179
Validation loss: 1.8446052160194453
Epoch: 7| Step: 9
Training loss: 1.8865753412246704
Validation loss: 1.8457200870239476
Epoch: 7| Step: 10
Training loss: 2.481102705001831
Validation loss: 1.8650380621711127
Epoch: 7| Step: 11
Training loss: 2.515944242477417
Validation loss: 1.8477961862687584
Epoch: 7| Step: 12
Training loss: 1.728626012802124
Validation loss: 1.8447657283261525
Epoch: 7| Step: 13
Training loss: 1.3418734073638916
Validation loss: 1.8453405949709227
Epoch: 7| Step: 14
Training loss: 2.0522255897521973
Validation loss: 1.8664193985273512
Epoch: 7| Step: 15
Training loss: 2.232679843902588
Validation loss: 1.8784823246139417
Epoch: 100| Step: 0
Training loss: 1.310445785522461
Validation loss: 1.8760062078777835
Epoch: 7| Step: 1
Training loss: 1.6745471954345703
Validation loss: 1.8749407229663657
Epoch: 7| Step: 2
Training loss: 1.4565465450286865
Validation loss: 1.8659803018295507
Epoch: 7| Step: 3
Training loss: 2.4722042083740234
Validation loss: 1.8726961544091754
Epoch: 7| Step: 4
Training loss: 2.1192123889923096
Validation loss: 1.870319824424579
Epoch: 7| Step: 5
Training loss: 2.307145595550537
Validation loss: 1.9136597852912738
Epoch: 7| Step: 6
Training loss: 2.289246082305908
Validation loss: 1.8735946356821402
Epoch: 7| Step: 7
Training loss: 2.602210283279419
Validation loss: 1.8856214336354098
Epoch: 7| Step: 8
Training loss: 2.083237409591675
Validation loss: 1.878879258958556
Epoch: 7| Step: 9
Training loss: 2.209744691848755
Validation loss: 1.8882392181766976
Epoch: 7| Step: 10
Training loss: 1.9999421834945679
Validation loss: 1.858289960476992
Epoch: 7| Step: 11
Training loss: 1.717442274093628
Validation loss: 1.8674641556019405
Epoch: 7| Step: 12
Training loss: 1.7832940816879272
Validation loss: 1.8775241975304033
Epoch: 7| Step: 13
Training loss: 1.7249839305877686
Validation loss: 1.8675199987219393
Epoch: 7| Step: 14
Training loss: 2.0583739280700684
Validation loss: 1.8638687133789062
Epoch: 7| Step: 15
Training loss: 2.1827845573425293
Validation loss: 1.8720453394402703
