Epoch: 1| Step: 0
Training loss: 5.272248129763704
Validation loss: 5.41784547547738

Epoch: 6| Step: 1
Training loss: 4.428652257225632
Validation loss: 5.408162184928029

Epoch: 6| Step: 2
Training loss: 4.688135332920784
Validation loss: 5.39874678892897

Epoch: 6| Step: 3
Training loss: 5.776636540766702
Validation loss: 5.390770627326045

Epoch: 6| Step: 4
Training loss: 5.559288555157211
Validation loss: 5.383631909163728

Epoch: 6| Step: 5
Training loss: 5.65628540702402
Validation loss: 5.376413529111653

Epoch: 6| Step: 6
Training loss: 5.493025605893972
Validation loss: 5.369990535374925

Epoch: 6| Step: 7
Training loss: 4.6461955843025775
Validation loss: 5.363705737973604

Epoch: 6| Step: 8
Training loss: 5.616352979614616
Validation loss: 5.356470268049964

Epoch: 6| Step: 9
Training loss: 5.491512859469399
Validation loss: 5.351988689595023

Epoch: 6| Step: 10
Training loss: 6.050441429490845
Validation loss: 5.345608631544424

Epoch: 6| Step: 11
Training loss: 5.77018974745889
Validation loss: 5.339769513112499

Epoch: 6| Step: 12
Training loss: 6.156943345116996
Validation loss: 5.331863329878382

Epoch: 6| Step: 13
Training loss: 5.880740344091797
Validation loss: 5.322166295422493

Epoch: 2| Step: 0
Training loss: 5.001841778094915
Validation loss: 5.31318531477951

Epoch: 6| Step: 1
Training loss: 5.414252207681481
Validation loss: 5.30599856011191

Epoch: 6| Step: 2
Training loss: 5.8431944557539675
Validation loss: 5.294860937053281

Epoch: 6| Step: 3
Training loss: 5.93499092493432
Validation loss: 5.285268695440539

Epoch: 6| Step: 4
Training loss: 5.130750825602801
Validation loss: 5.273308043598116

Epoch: 6| Step: 5
Training loss: 5.093458108788315
Validation loss: 5.262290223109351

Epoch: 6| Step: 6
Training loss: 4.599188666733722
Validation loss: 5.251160054485707

Epoch: 6| Step: 7
Training loss: 5.157396963461384
Validation loss: 5.2398945872063285

Epoch: 6| Step: 8
Training loss: 5.7637476565460295
Validation loss: 5.226626393412788

Epoch: 6| Step: 9
Training loss: 6.072898520109395
Validation loss: 5.21380792395847

Epoch: 6| Step: 10
Training loss: 5.617923269245573
Validation loss: 5.198871389813744

Epoch: 6| Step: 11
Training loss: 4.701344707562526
Validation loss: 5.182683002769712

Epoch: 6| Step: 12
Training loss: 5.425675085579429
Validation loss: 5.170275238108809

Epoch: 6| Step: 13
Training loss: 4.983495365600329
Validation loss: 5.154516680136998

Epoch: 3| Step: 0
Training loss: 5.197442695041216
Validation loss: 5.135496663778809

Epoch: 6| Step: 1
Training loss: 5.04638329345705
Validation loss: 5.121062107216354

Epoch: 6| Step: 2
Training loss: 5.607926290552814
Validation loss: 5.102377950506694

Epoch: 6| Step: 3
Training loss: 4.249625694397151
Validation loss: 5.083668067208734

Epoch: 6| Step: 4
Training loss: 5.1156206600518015
Validation loss: 5.063614035897982

Epoch: 6| Step: 5
Training loss: 5.743643854964025
Validation loss: 5.044156030055176

Epoch: 6| Step: 6
Training loss: 4.4885793508897
Validation loss: 5.020152994284027

Epoch: 6| Step: 7
Training loss: 5.738275931753832
Validation loss: 4.996109052509875

Epoch: 6| Step: 8
Training loss: 4.882955857270546
Validation loss: 4.97473353657953

Epoch: 6| Step: 9
Training loss: 5.22461594625755
Validation loss: 4.94865933382674

Epoch: 6| Step: 10
Training loss: 5.484645391249011
Validation loss: 4.921943720585067

Epoch: 6| Step: 11
Training loss: 5.018451025241656
Validation loss: 4.8943020421150445

Epoch: 6| Step: 12
Training loss: 4.319976076130497
Validation loss: 4.861448771541792

Epoch: 6| Step: 13
Training loss: 5.176353705075969
Validation loss: 4.829402980776868

Epoch: 4| Step: 0
Training loss: 4.380227589725558
Validation loss: 4.802178746707793

Epoch: 6| Step: 1
Training loss: 4.826239850543144
Validation loss: 4.765811070212717

Epoch: 6| Step: 2
Training loss: 4.587084651095233
Validation loss: 4.729636528883926

Epoch: 6| Step: 3
Training loss: 3.7228500459869163
Validation loss: 4.687003554440293

Epoch: 6| Step: 4
Training loss: 4.897796150822303
Validation loss: 4.651621025997797

Epoch: 6| Step: 5
Training loss: 4.776708103664823
Validation loss: 4.608980737408779

Epoch: 6| Step: 6
Training loss: 4.223776302656524
Validation loss: 4.561987373433805

Epoch: 6| Step: 7
Training loss: 5.503234779003792
Validation loss: 4.5128265650151205

Epoch: 6| Step: 8
Training loss: 4.258395261867882
Validation loss: 4.471643964662672

Epoch: 6| Step: 9
Training loss: 4.943161434821153
Validation loss: 4.417900213086036

Epoch: 6| Step: 10
Training loss: 5.315628566662255
Validation loss: 4.3622172397911765

Epoch: 6| Step: 11
Training loss: 5.245650896935435
Validation loss: 4.293940833532366

Epoch: 6| Step: 12
Training loss: 4.194145509173952
Validation loss: 4.23233715160933

Epoch: 6| Step: 13
Training loss: 3.1139331934334273
Validation loss: 4.1661008196306275

Epoch: 5| Step: 0
Training loss: 4.079183740680772
Validation loss: 4.1033212142711655

Epoch: 6| Step: 1
Training loss: 3.8679686711017967
Validation loss: 4.012565189200421

Epoch: 6| Step: 2
Training loss: 4.250368214532295
Validation loss: 3.950599496955552

Epoch: 6| Step: 3
Training loss: 3.6120858189303684
Validation loss: 3.8624665185820786

Epoch: 6| Step: 4
Training loss: 3.593332415659073
Validation loss: 3.779528433501567

Epoch: 6| Step: 5
Training loss: 3.751870388248678
Validation loss: 3.694607711154584

Epoch: 6| Step: 6
Training loss: 3.90495327597981
Validation loss: 3.5991556837605176

Epoch: 6| Step: 7
Training loss: 3.4790662343649257
Validation loss: 3.5107605461026132

Epoch: 6| Step: 8
Training loss: 4.049870976406176
Validation loss: 3.407653985876399

Epoch: 6| Step: 9
Training loss: 3.2426206000730438
Validation loss: 3.3146504553410963

Epoch: 6| Step: 10
Training loss: 3.5821684932728637
Validation loss: 3.215811712332867

Epoch: 6| Step: 11
Training loss: 2.5237377448726757
Validation loss: 3.0983643975084867

Epoch: 6| Step: 12
Training loss: 3.09673342722804
Validation loss: 3.019875227601156

Epoch: 6| Step: 13
Training loss: 3.144580229383687
Validation loss: 2.9257547795821863

Epoch: 6| Step: 0
Training loss: 3.66435087651161
Validation loss: 2.8464525257553817

Epoch: 6| Step: 1
Training loss: 2.4976246039205683
Validation loss: 2.7688991540900014

Epoch: 6| Step: 2
Training loss: 2.9399556386286667
Validation loss: 2.7332013763193888

Epoch: 6| Step: 3
Training loss: 1.9280871964122872
Validation loss: 2.6743816641492515

Epoch: 6| Step: 4
Training loss: 3.0895739798083786
Validation loss: 2.6338750428925177

Epoch: 6| Step: 5
Training loss: 2.5058818289865
Validation loss: 2.6151647237971023

Epoch: 6| Step: 6
Training loss: 2.191668326470311
Validation loss: 2.5984227553006813

Epoch: 6| Step: 7
Training loss: 2.306987997929142
Validation loss: 2.5959563618544883

Epoch: 6| Step: 8
Training loss: 2.566793984397151
Validation loss: 2.6509769534223597

Epoch: 6| Step: 9
Training loss: 2.6125980048528206
Validation loss: 2.6653168709265467

Epoch: 6| Step: 10
Training loss: 3.174953676621731
Validation loss: 2.7095981041121777

Epoch: 6| Step: 11
Training loss: 2.738613396932854
Validation loss: 2.72748228806882

Epoch: 6| Step: 12
Training loss: 2.3139526341106715
Validation loss: 2.734563374161458

Epoch: 6| Step: 13
Training loss: 2.083170566558341
Validation loss: 2.731966974703904

Epoch: 7| Step: 0
Training loss: 2.7375562200477934
Validation loss: 2.738026845218027

Epoch: 6| Step: 1
Training loss: 2.6303977872897213
Validation loss: 2.7758430185629064

Epoch: 6| Step: 2
Training loss: 2.3428554608010024
Validation loss: 2.7447258484758774

Epoch: 6| Step: 3
Training loss: 3.2079748143280042
Validation loss: 2.7232972334200958

Epoch: 6| Step: 4
Training loss: 2.581988220317986
Validation loss: 2.664094866931694

Epoch: 6| Step: 5
Training loss: 2.7042951752192947
Validation loss: 2.689333962705038

Epoch: 6| Step: 6
Training loss: 2.5597029516615066
Validation loss: 2.6634090364206298

Epoch: 6| Step: 7
Training loss: 1.8787124755929223
Validation loss: 2.6099823265890163

Epoch: 6| Step: 8
Training loss: 2.9991466580128305
Validation loss: 2.6286835786364273

Epoch: 6| Step: 9
Training loss: 2.888575141530267
Validation loss: 2.6468717885063593

Epoch: 6| Step: 10
Training loss: 2.8390645423424132
Validation loss: 2.615833505381562

Epoch: 6| Step: 11
Training loss: 2.2694826104472168
Validation loss: 2.618028723806627

Epoch: 6| Step: 12
Training loss: 1.8482614054442121
Validation loss: 2.63346512098544

Epoch: 6| Step: 13
Training loss: 2.503317634323341
Validation loss: 2.6200977750787264

Epoch: 8| Step: 0
Training loss: 2.1169542697946055
Validation loss: 2.608611248270324

Epoch: 6| Step: 1
Training loss: 1.893017161872399
Validation loss: 2.61578583642527

Epoch: 6| Step: 2
Training loss: 2.021197400939164
Validation loss: 2.595018099830143

Epoch: 6| Step: 3
Training loss: 2.9487398074476436
Validation loss: 2.601518113193902

Epoch: 6| Step: 4
Training loss: 2.70870360753248
Validation loss: 2.600198336519053

Epoch: 6| Step: 5
Training loss: 2.6460300182216985
Validation loss: 2.5937688282968803

Epoch: 6| Step: 6
Training loss: 3.200033789694726
Validation loss: 2.5905820964946447

Epoch: 6| Step: 7
Training loss: 2.5276622070423405
Validation loss: 2.614319477724383

Epoch: 6| Step: 8
Training loss: 2.7494844473568723
Validation loss: 2.585941510615163

Epoch: 6| Step: 9
Training loss: 2.6227119101264798
Validation loss: 2.613014621941403

Epoch: 6| Step: 10
Training loss: 2.317343099441113
Validation loss: 2.5986429811833256

Epoch: 6| Step: 11
Training loss: 2.2666377467760177
Validation loss: 2.6000873098630217

Epoch: 6| Step: 12
Training loss: 2.8324257201028065
Validation loss: 2.596654514297366

Epoch: 6| Step: 13
Training loss: 2.517485315759255
Validation loss: 2.609398421070117

Epoch: 9| Step: 0
Training loss: 2.8811235313214834
Validation loss: 2.598750568002673

Epoch: 6| Step: 1
Training loss: 2.5002281084897877
Validation loss: 2.6005907047928516

Epoch: 6| Step: 2
Training loss: 3.053311635680197
Validation loss: 2.586808471905617

Epoch: 6| Step: 3
Training loss: 2.1723885786590373
Validation loss: 2.590529023690726

Epoch: 6| Step: 4
Training loss: 2.5778005684835326
Validation loss: 2.6132499567504635

Epoch: 6| Step: 5
Training loss: 2.9885684604624827
Validation loss: 2.592826908803027

Epoch: 6| Step: 6
Training loss: 2.3949308824222024
Validation loss: 2.58244181190465

Epoch: 6| Step: 7
Training loss: 2.492294835377178
Validation loss: 2.6188811937729004

Epoch: 6| Step: 8
Training loss: 2.121865148057946
Validation loss: 2.6224164283244256

Epoch: 6| Step: 9
Training loss: 2.2169622821687973
Validation loss: 2.61110798743131

Epoch: 6| Step: 10
Training loss: 2.07899755071704
Validation loss: 2.57602283816945

Epoch: 6| Step: 11
Training loss: 2.5500348855418564
Validation loss: 2.6199074499027843

Epoch: 6| Step: 12
Training loss: 1.9000602662416637
Validation loss: 2.6142611868732892

Epoch: 6| Step: 13
Training loss: 3.2641712219918078
Validation loss: 2.6052456769334795

Epoch: 10| Step: 0
Training loss: 2.5814777190691176
Validation loss: 2.587285592230504

Epoch: 6| Step: 1
Training loss: 2.3357778641366607
Validation loss: 2.610794275306

Epoch: 6| Step: 2
Training loss: 2.2642325496062212
Validation loss: 2.6098365756156268

Epoch: 6| Step: 3
Training loss: 3.1292597919800658
Validation loss: 2.6170955281205566

Epoch: 6| Step: 4
Training loss: 2.6194586621201243
Validation loss: 2.62224502407638

Epoch: 6| Step: 5
Training loss: 2.0355767750964375
Validation loss: 2.63585433542345

Epoch: 6| Step: 6
Training loss: 2.5612925964655955
Validation loss: 2.6550462426123493

Epoch: 6| Step: 7
Training loss: 2.715363157793969
Validation loss: 2.6186492633487304

Epoch: 6| Step: 8
Training loss: 2.2251248185368944
Validation loss: 2.6413427276630412

Epoch: 6| Step: 9
Training loss: 2.5128090777478813
Validation loss: 2.6197928598652744

Epoch: 6| Step: 10
Training loss: 1.7818653315425994
Validation loss: 2.587284317487391

Epoch: 6| Step: 11
Training loss: 3.3902871803015437
Validation loss: 2.6101072277682382

Epoch: 6| Step: 12
Training loss: 2.6901945755652386
Validation loss: 2.582479787121501

Epoch: 6| Step: 13
Training loss: 2.7148818637724776
Validation loss: 2.5758909545158506

Epoch: 11| Step: 0
Training loss: 2.085391884071228
Validation loss: 2.5621573056208584

Epoch: 6| Step: 1
Training loss: 3.236684370951713
Validation loss: 2.6056523065378308

Epoch: 6| Step: 2
Training loss: 2.6363842561268207
Validation loss: 2.591089569452189

Epoch: 6| Step: 3
Training loss: 2.4066290618762345
Validation loss: 2.5858786615629237

Epoch: 6| Step: 4
Training loss: 2.3439324880127876
Validation loss: 2.5901837938409824

Epoch: 6| Step: 5
Training loss: 2.881349104296048
Validation loss: 2.5821897734102226

Epoch: 6| Step: 6
Training loss: 2.1429283947679023
Validation loss: 2.5770628465492442

Epoch: 6| Step: 7
Training loss: 2.329612717429231
Validation loss: 2.5971482470942715

Epoch: 6| Step: 8
Training loss: 2.5827127962432095
Validation loss: 2.58843280606825

Epoch: 6| Step: 9
Training loss: 2.56322841060814
Validation loss: 2.580818110581132

Epoch: 6| Step: 10
Training loss: 2.9160087570038007
Validation loss: 2.5887728049985115

Epoch: 6| Step: 11
Training loss: 2.08655953151554
Validation loss: 2.6054323528441277

Epoch: 6| Step: 12
Training loss: 2.77037382020337
Validation loss: 2.5939090021261024

Epoch: 6| Step: 13
Training loss: 2.394691847725453
Validation loss: 2.5899507511027338

Epoch: 12| Step: 0
Training loss: 2.89498523029783
Validation loss: 2.576965826671215

Epoch: 6| Step: 1
Training loss: 2.3189262590482613
Validation loss: 2.6124429389282917

Epoch: 6| Step: 2
Training loss: 2.647124918879183
Validation loss: 2.5388535477172347

Epoch: 6| Step: 3
Training loss: 2.859786207304535
Validation loss: 2.5683099430099254

Epoch: 6| Step: 4
Training loss: 1.5354471100990021
Validation loss: 2.582372291807137

Epoch: 6| Step: 5
Training loss: 3.0127670106440037
Validation loss: 2.593611579479974

Epoch: 6| Step: 6
Training loss: 2.2480055128281085
Validation loss: 2.5744923208431723

Epoch: 6| Step: 7
Training loss: 2.3359263748363315
Validation loss: 2.571806499546974

Epoch: 6| Step: 8
Training loss: 2.273390621999777
Validation loss: 2.577539658807133

Epoch: 6| Step: 9
Training loss: 2.5927490693005066
Validation loss: 2.6034717293788003

Epoch: 6| Step: 10
Training loss: 2.4963800925719135
Validation loss: 2.5760782613801725

Epoch: 6| Step: 11
Training loss: 2.625257297803244
Validation loss: 2.629395105520674

Epoch: 6| Step: 12
Training loss: 2.2072924434077823
Validation loss: 2.6149560477779556

Epoch: 6| Step: 13
Training loss: 3.0453781754999696
Validation loss: 2.622822812324976

Epoch: 13| Step: 0
Training loss: 2.526349445482734
Validation loss: 2.6295535087636943

Epoch: 6| Step: 1
Training loss: 2.7907260239994596
Validation loss: 2.5566729219833437

Epoch: 6| Step: 2
Training loss: 2.3834689877546924
Validation loss: 2.572115249505806

Epoch: 6| Step: 3
Training loss: 2.522755250142991
Validation loss: 2.5911349170141764

Epoch: 6| Step: 4
Training loss: 2.750790222378686
Validation loss: 2.5536310809494673

Epoch: 6| Step: 5
Training loss: 2.2731234933356768
Validation loss: 2.553782848271997

Epoch: 6| Step: 6
Training loss: 2.5535959133990294
Validation loss: 2.5748220613720023

Epoch: 6| Step: 7
Training loss: 2.8220606745977026
Validation loss: 2.576019845621498

Epoch: 6| Step: 8
Training loss: 2.1886282055059136
Validation loss: 2.577861256065319

Epoch: 6| Step: 9
Training loss: 1.9195372466885243
Validation loss: 2.599556333639402

Epoch: 6| Step: 10
Training loss: 2.8213148370069194
Validation loss: 2.5864060698652245

Epoch: 6| Step: 11
Training loss: 2.910420041001552
Validation loss: 2.599154697458737

Epoch: 6| Step: 12
Training loss: 3.048440697226908
Validation loss: 2.562576664964067

Epoch: 6| Step: 13
Training loss: 1.289633237317899
Validation loss: 2.565867637965782

Epoch: 14| Step: 0
Training loss: 2.3525832485991556
Validation loss: 2.5638826098307215

Epoch: 6| Step: 1
Training loss: 2.7074350383429193
Validation loss: 2.5550951928896075

Epoch: 6| Step: 2
Training loss: 2.0750772025212316
Validation loss: 2.5940549893292117

Epoch: 6| Step: 3
Training loss: 2.140423619063051
Validation loss: 2.5448628377519658

Epoch: 6| Step: 4
Training loss: 2.054835673163982
Validation loss: 2.595196332174689

Epoch: 6| Step: 5
Training loss: 2.7523891301221384
Validation loss: 2.575578190724452

Epoch: 6| Step: 6
Training loss: 3.2066586239635253
Validation loss: 2.5973371496175788

Epoch: 6| Step: 7
Training loss: 1.3844834915945818
Validation loss: 2.5556242738920036

Epoch: 6| Step: 8
Training loss: 2.1534848381732776
Validation loss: 2.564583505113494

Epoch: 6| Step: 9
Training loss: 2.19030342299368
Validation loss: 2.598491838337785

Epoch: 6| Step: 10
Training loss: 2.7843530895942346
Validation loss: 2.561549560941102

Epoch: 6| Step: 11
Training loss: 3.2482785287392697
Validation loss: 2.5695828500764444

Epoch: 6| Step: 12
Training loss: 3.224651371054513
Validation loss: 2.559174356758524

Epoch: 6| Step: 13
Training loss: 2.2296169812519726
Validation loss: 2.5609656213873144

Epoch: 15| Step: 0
Training loss: 2.7371508650032585
Validation loss: 2.562991537076423

Epoch: 6| Step: 1
Training loss: 2.4626392112148783
Validation loss: 2.5721145774772394

Epoch: 6| Step: 2
Training loss: 2.4467654070908447
Validation loss: 2.564995550705767

Epoch: 6| Step: 3
Training loss: 1.785072040867207
Validation loss: 2.558079216935192

Epoch: 6| Step: 4
Training loss: 2.035431416775982
Validation loss: 2.5445564029064527

Epoch: 6| Step: 5
Training loss: 2.427840926393921
Validation loss: 2.5565926450419307

Epoch: 6| Step: 6
Training loss: 2.7012967669010144
Validation loss: 2.5822037001062417

Epoch: 6| Step: 7
Training loss: 2.32728766418264
Validation loss: 2.5452332695263538

Epoch: 6| Step: 8
Training loss: 2.4055062668028295
Validation loss: 2.557866334280669

Epoch: 6| Step: 9
Training loss: 2.764249384089682
Validation loss: 2.5599075943193847

Epoch: 6| Step: 10
Training loss: 2.8556056792151847
Validation loss: 2.5560304803956124

Epoch: 6| Step: 11
Training loss: 2.4558446107969396
Validation loss: 2.5765185119316247

Epoch: 6| Step: 12
Training loss: 2.3841716954661454
Validation loss: 2.581454137037734

Epoch: 6| Step: 13
Training loss: 3.044324854275472
Validation loss: 2.5825437190148723

Epoch: 16| Step: 0
Training loss: 1.587174708162191
Validation loss: 2.566113521578191

Epoch: 6| Step: 1
Training loss: 3.0763634612958355
Validation loss: 2.565717305649823

Epoch: 6| Step: 2
Training loss: 2.400130677639214
Validation loss: 2.5515924305979523

Epoch: 6| Step: 3
Training loss: 2.93350564999619
Validation loss: 2.556498687511027

Epoch: 6| Step: 4
Training loss: 2.9151419514400834
Validation loss: 2.5844965028626614

Epoch: 6| Step: 5
Training loss: 2.385347012720319
Validation loss: 2.574497221345057

Epoch: 6| Step: 6
Training loss: 2.514771500326131
Validation loss: 2.593298279060365

Epoch: 6| Step: 7
Training loss: 2.920250099131835
Validation loss: 2.5773752837127666

Epoch: 6| Step: 8
Training loss: 2.480982065027582
Validation loss: 2.5716831336562436

Epoch: 6| Step: 9
Training loss: 1.5378816983693255
Validation loss: 2.593439949225399

Epoch: 6| Step: 10
Training loss: 2.746158257238211
Validation loss: 2.530218604988198

Epoch: 6| Step: 11
Training loss: 2.1928653857119262
Validation loss: 2.575729760212738

Epoch: 6| Step: 12
Training loss: 3.107926381107001
Validation loss: 2.579367690708017

Epoch: 6| Step: 13
Training loss: 1.6073580945920198
Validation loss: 2.568810840761739

Epoch: 17| Step: 0
Training loss: 2.546832406091539
Validation loss: 2.5622177743951258

Epoch: 6| Step: 1
Training loss: 2.169076557473852
Validation loss: 2.5753048818147155

Epoch: 6| Step: 2
Training loss: 2.930166627487889
Validation loss: 2.566974594379837

Epoch: 6| Step: 3
Training loss: 2.680096742392704
Validation loss: 2.572943456924722

Epoch: 6| Step: 4
Training loss: 2.8218437117049153
Validation loss: 2.5415779681962167

Epoch: 6| Step: 5
Training loss: 2.4123015168917914
Validation loss: 2.5516774042859964

Epoch: 6| Step: 6
Training loss: 3.0204189323226998
Validation loss: 2.5837937272937315

Epoch: 6| Step: 7
Training loss: 1.8981973001617052
Validation loss: 2.549711820113406

Epoch: 6| Step: 8
Training loss: 2.3419497887810032
Validation loss: 2.586675118067132

Epoch: 6| Step: 9
Training loss: 2.2439769024467697
Validation loss: 2.5638998441460963

Epoch: 6| Step: 10
Training loss: 2.9099288134699948
Validation loss: 2.5809953913454757

Epoch: 6| Step: 11
Training loss: 2.155704705768603
Validation loss: 2.5803058686428564

Epoch: 6| Step: 12
Training loss: 1.7678876574196087
Validation loss: 2.5693514804232223

Epoch: 6| Step: 13
Training loss: 2.8848264528962706
Validation loss: 2.575804943823837

Epoch: 18| Step: 0
Training loss: 2.445072832641471
Validation loss: 2.579677337928379

Epoch: 6| Step: 1
Training loss: 2.782166405051198
Validation loss: 2.5834248639370636

Epoch: 6| Step: 2
Training loss: 2.3650849828310996
Validation loss: 2.571067706841389

Epoch: 6| Step: 3
Training loss: 2.6142094764045662
Validation loss: 2.569897464532476

Epoch: 6| Step: 4
Training loss: 2.44983369691028
Validation loss: 2.5364290009877664

Epoch: 6| Step: 5
Training loss: 2.639935465515201
Validation loss: 2.531027670307245

Epoch: 6| Step: 6
Training loss: 2.5605860750062415
Validation loss: 2.557705184745254

Epoch: 6| Step: 7
Training loss: 2.1131964083015555
Validation loss: 2.553676883623626

Epoch: 6| Step: 8
Training loss: 2.807604449699366
Validation loss: 2.573977453782683

Epoch: 6| Step: 9
Training loss: 2.50730657970609
Validation loss: 2.563929693954216

Epoch: 6| Step: 10
Training loss: 2.8016185067701147
Validation loss: 2.553786699327297

Epoch: 6| Step: 11
Training loss: 2.6464223931856186
Validation loss: 2.5693233948337033

Epoch: 6| Step: 12
Training loss: 2.181286843762023
Validation loss: 2.547590112436954

Epoch: 6| Step: 13
Training loss: 1.9903490147690281
Validation loss: 2.5861678006516593

Epoch: 19| Step: 0
Training loss: 2.5306906376431297
Validation loss: 2.558095527266026

Epoch: 6| Step: 1
Training loss: 2.2726987706911412
Validation loss: 2.569099557486586

Epoch: 6| Step: 2
Training loss: 2.4725105519932606
Validation loss: 2.5425113670972737

Epoch: 6| Step: 3
Training loss: 2.6313786889725796
Validation loss: 2.5500973402405935

Epoch: 6| Step: 4
Training loss: 2.930961636997951
Validation loss: 2.5707977980801386

Epoch: 6| Step: 5
Training loss: 2.4290525336523037
Validation loss: 2.5346640494535615

Epoch: 6| Step: 6
Training loss: 2.171077774060452
Validation loss: 2.5337623718090154

Epoch: 6| Step: 7
Training loss: 1.6399781904863846
Validation loss: 2.5666909255908426

Epoch: 6| Step: 8
Training loss: 2.6590893100001605
Validation loss: 2.538828004621297

Epoch: 6| Step: 9
Training loss: 2.9835664143075453
Validation loss: 2.530034169631021

Epoch: 6| Step: 10
Training loss: 2.735243828206848
Validation loss: 2.5459463536658076

Epoch: 6| Step: 11
Training loss: 2.483564904529327
Validation loss: 2.5649859302722318

Epoch: 6| Step: 12
Training loss: 2.13894397972906
Validation loss: 2.544916644302032

Epoch: 6| Step: 13
Training loss: 2.425506035615783
Validation loss: 2.560843668986238

Epoch: 20| Step: 0
Training loss: 2.3042396239537215
Validation loss: 2.5704588457087976

Epoch: 6| Step: 1
Training loss: 3.0611346568336497
Validation loss: 2.5577297236914323

Epoch: 6| Step: 2
Training loss: 1.8842553905780945
Validation loss: 2.5404433501034496

Epoch: 6| Step: 3
Training loss: 2.8338337811577725
Validation loss: 2.555786425302366

Epoch: 6| Step: 4
Training loss: 2.3231574191791458
Validation loss: 2.5479725382166873

Epoch: 6| Step: 5
Training loss: 2.666130985656598
Validation loss: 2.530471383737542

Epoch: 6| Step: 6
Training loss: 2.5193353621161836
Validation loss: 2.5668201161212245

Epoch: 6| Step: 7
Training loss: 2.3648865851211216
Validation loss: 2.5438199979506755

Epoch: 6| Step: 8
Training loss: 2.7390103532665795
Validation loss: 2.557068596852815

Epoch: 6| Step: 9
Training loss: 2.482947749300584
Validation loss: 2.5721528519278993

Epoch: 6| Step: 10
Training loss: 2.5910026983602616
Validation loss: 2.5407057936593493

Epoch: 6| Step: 11
Training loss: 1.749850879855294
Validation loss: 2.531692701644916

Epoch: 6| Step: 12
Training loss: 2.0110205762845257
Validation loss: 2.5464013718268474

Epoch: 6| Step: 13
Training loss: 3.142127289804548
Validation loss: 2.5482869827100303

Epoch: 21| Step: 0
Training loss: 2.7674841370166723
Validation loss: 2.582666231488021

Epoch: 6| Step: 1
Training loss: 2.1849981987987226
Validation loss: 2.5567863856050024

Epoch: 6| Step: 2
Training loss: 2.5401530110085764
Validation loss: 2.5634575969660536

Epoch: 6| Step: 3
Training loss: 2.1762462509447262
Validation loss: 2.5663184117536897

Epoch: 6| Step: 4
Training loss: 2.558883347756743
Validation loss: 2.5719550622813205

Epoch: 6| Step: 5
Training loss: 2.6115848526335275
Validation loss: 2.5369052584606453

Epoch: 6| Step: 6
Training loss: 2.89994439696577
Validation loss: 2.5733572599389056

Epoch: 6| Step: 7
Training loss: 2.6335573133348795
Validation loss: 2.5598967905647503

Epoch: 6| Step: 8
Training loss: 2.4954259991138232
Validation loss: 2.6008288443967764

Epoch: 6| Step: 9
Training loss: 3.062977033558278
Validation loss: 2.5608190435012297

Epoch: 6| Step: 10
Training loss: 2.159656763532852
Validation loss: 2.5768423878051516

Epoch: 6| Step: 11
Training loss: 2.4758226510965233
Validation loss: 2.5879617011908125

Epoch: 6| Step: 12
Training loss: 2.0131896928153123
Validation loss: 2.585686924098889

Epoch: 6| Step: 13
Training loss: 1.7875315683418302
Validation loss: 2.5893672468318107

Epoch: 22| Step: 0
Training loss: 2.3936016026805165
Validation loss: 2.566956869868906

Epoch: 6| Step: 1
Training loss: 2.57769882841266
Validation loss: 2.5699734990847722

Epoch: 6| Step: 2
Training loss: 2.9596414673666884
Validation loss: 2.5775102441129665

Epoch: 6| Step: 3
Training loss: 1.937477603905967
Validation loss: 2.6099198128573002

Epoch: 6| Step: 4
Training loss: 2.399502694740698
Validation loss: 2.613410904675388

Epoch: 6| Step: 5
Training loss: 2.726817733929249
Validation loss: 2.5711212277284363

Epoch: 6| Step: 6
Training loss: 1.86008369339542
Validation loss: 2.592459422682643

Epoch: 6| Step: 7
Training loss: 3.5586627572463243
Validation loss: 2.575760051442213

Epoch: 6| Step: 8
Training loss: 2.110093284099672
Validation loss: 2.5772981955518772

Epoch: 6| Step: 9
Training loss: 2.298509600018711
Validation loss: 2.582770414446084

Epoch: 6| Step: 10
Training loss: 2.1830545213420245
Validation loss: 2.5599829864930013

Epoch: 6| Step: 11
Training loss: 2.6890148949939396
Validation loss: 2.564879777779036

Epoch: 6| Step: 12
Training loss: 2.060650776779106
Validation loss: 2.558979578022912

Epoch: 6| Step: 13
Training loss: 2.542304308176646
Validation loss: 2.569303614104847

Epoch: 23| Step: 0
Training loss: 1.7364975596640608
Validation loss: 2.5440769271338426

Epoch: 6| Step: 1
Training loss: 2.5141147795386796
Validation loss: 2.535199714056865

Epoch: 6| Step: 2
Training loss: 3.0451392291329946
Validation loss: 2.544658078281193

Epoch: 6| Step: 3
Training loss: 1.9636866535384183
Validation loss: 2.545400836458456

Epoch: 6| Step: 4
Training loss: 2.1404474560696003
Validation loss: 2.5572152576309795

Epoch: 6| Step: 5
Training loss: 2.276684935660762
Validation loss: 2.5418830894089495

Epoch: 6| Step: 6
Training loss: 2.3767616364104027
Validation loss: 2.543273493432378

Epoch: 6| Step: 7
Training loss: 2.8142050766820543
Validation loss: 2.5422906005560377

Epoch: 6| Step: 8
Training loss: 2.120782818845313
Validation loss: 2.547510375980389

Epoch: 6| Step: 9
Training loss: 3.2143115209118727
Validation loss: 2.543015502562418

Epoch: 6| Step: 10
Training loss: 2.312744333916947
Validation loss: 2.570305465796835

Epoch: 6| Step: 11
Training loss: 2.342065841843849
Validation loss: 2.5408007809247017

Epoch: 6| Step: 12
Training loss: 2.3171927803787082
Validation loss: 2.543868460931303

Epoch: 6| Step: 13
Training loss: 3.076173735118485
Validation loss: 2.55541299051414

Epoch: 24| Step: 0
Training loss: 2.132172540922215
Validation loss: 2.5538163094696182

Epoch: 6| Step: 1
Training loss: 2.8389123703727233
Validation loss: 2.569799431916808

Epoch: 6| Step: 2
Training loss: 2.3272775221227975
Validation loss: 2.569549107066669

Epoch: 6| Step: 3
Training loss: 2.9239249968295975
Validation loss: 2.553431210779165

Epoch: 6| Step: 4
Training loss: 2.628016146878785
Validation loss: 2.561288523982373

Epoch: 6| Step: 5
Training loss: 2.896492277045863
Validation loss: 2.567774531276508

Epoch: 6| Step: 6
Training loss: 2.1466621970886393
Validation loss: 2.5648704280312113

Epoch: 6| Step: 7
Training loss: 2.115233924140072
Validation loss: 2.5606683837552495

Epoch: 6| Step: 8
Training loss: 2.12916504573076
Validation loss: 2.549713238318429

Epoch: 6| Step: 9
Training loss: 2.0938558978729
Validation loss: 2.5428859777305646

Epoch: 6| Step: 10
Training loss: 2.527382521648847
Validation loss: 2.572033245275229

Epoch: 6| Step: 11
Training loss: 2.220156693813901
Validation loss: 2.572880661026507

Epoch: 6| Step: 12
Training loss: 2.539514119991698
Validation loss: 2.53203124874452

Epoch: 6| Step: 13
Training loss: 2.922474519146998
Validation loss: 2.5685193765018424

Epoch: 25| Step: 0
Training loss: 2.2529427040626904
Validation loss: 2.560553253189162

Epoch: 6| Step: 1
Training loss: 2.4849685823538383
Validation loss: 2.522505691491654

Epoch: 6| Step: 2
Training loss: 2.570277808050928
Validation loss: 2.557344748159112

Epoch: 6| Step: 3
Training loss: 2.3737761707279437
Validation loss: 2.550522187938698

Epoch: 6| Step: 4
Training loss: 2.5400794237590105
Validation loss: 2.5706732746998284

Epoch: 6| Step: 5
Training loss: 2.6234782212932695
Validation loss: 2.5487253531323986

Epoch: 6| Step: 6
Training loss: 2.4612785950680762
Validation loss: 2.549864841444624

Epoch: 6| Step: 7
Training loss: 1.9671471140914687
Validation loss: 2.571725041717275

Epoch: 6| Step: 8
Training loss: 1.6487458288734316
Validation loss: 2.543434221567348

Epoch: 6| Step: 9
Training loss: 2.7610094597532484
Validation loss: 2.550929456127463

Epoch: 6| Step: 10
Training loss: 2.5538074715860457
Validation loss: 2.561774492292333

Epoch: 6| Step: 11
Training loss: 3.5191570256617775
Validation loss: 2.5727905494781873

Epoch: 6| Step: 12
Training loss: 2.244276821163603
Validation loss: 2.554679053989646

Epoch: 6| Step: 13
Training loss: 2.094775503871738
Validation loss: 2.5550161105629066

Epoch: 26| Step: 0
Training loss: 1.6861294726371054
Validation loss: 2.5444232786978875

Epoch: 6| Step: 1
Training loss: 2.7665873431895003
Validation loss: 2.574945728260923

Epoch: 6| Step: 2
Training loss: 2.634317573473513
Validation loss: 2.5221725931153642

Epoch: 6| Step: 3
Training loss: 3.013835949488978
Validation loss: 2.54274547590929

Epoch: 6| Step: 4
Training loss: 2.600855092506931
Validation loss: 2.5378208039042245

Epoch: 6| Step: 5
Training loss: 2.0282796415788824
Validation loss: 2.558141863571865

Epoch: 6| Step: 6
Training loss: 2.055464449000453
Validation loss: 2.5897167207261496

Epoch: 6| Step: 7
Training loss: 2.4104713963455566
Validation loss: 2.552976963042376

Epoch: 6| Step: 8
Training loss: 2.9916827620247757
Validation loss: 2.5572092129738335

Epoch: 6| Step: 9
Training loss: 2.2847357469008323
Validation loss: 2.5644358634125672

Epoch: 6| Step: 10
Training loss: 1.9636422155996265
Validation loss: 2.552905675524978

Epoch: 6| Step: 11
Training loss: 1.8073453281435603
Validation loss: 2.538958292069788

Epoch: 6| Step: 12
Training loss: 3.0425680383928166
Validation loss: 2.570242396734973

Epoch: 6| Step: 13
Training loss: 2.822999387610623
Validation loss: 2.5390238284565054

Epoch: 27| Step: 0
Training loss: 2.2807018718899634
Validation loss: 2.5402175545324974

Epoch: 6| Step: 1
Training loss: 1.9677900365692576
Validation loss: 2.550197813053234

Epoch: 6| Step: 2
Training loss: 2.730331482936434
Validation loss: 2.562479577332037

Epoch: 6| Step: 3
Training loss: 2.0171726406504527
Validation loss: 2.540455331489883

Epoch: 6| Step: 4
Training loss: 2.700461779064912
Validation loss: 2.543326341495261

Epoch: 6| Step: 5
Training loss: 2.4828056320950087
Validation loss: 2.560386980555629

Epoch: 6| Step: 6
Training loss: 2.80336473135161
Validation loss: 2.5656094177739357

Epoch: 6| Step: 7
Training loss: 2.8510395563406075
Validation loss: 2.543663449576277

Epoch: 6| Step: 8
Training loss: 2.687040600213332
Validation loss: 2.5664179630873507

Epoch: 6| Step: 9
Training loss: 2.6381724327538993
Validation loss: 2.5603561116924394

Epoch: 6| Step: 10
Training loss: 2.6940467405505415
Validation loss: 2.5569427910055236

Epoch: 6| Step: 11
Training loss: 2.722690401451432
Validation loss: 2.5591613761112635

Epoch: 6| Step: 12
Training loss: 1.7837600423293598
Validation loss: 2.5497204228394477

Epoch: 6| Step: 13
Training loss: 1.491398467917344
Validation loss: 2.5750885006902435

Epoch: 28| Step: 0
Training loss: 2.1188489862685658
Validation loss: 2.576998547387938

Epoch: 6| Step: 1
Training loss: 2.8709786528269055
Validation loss: 2.5351222760432406

Epoch: 6| Step: 2
Training loss: 2.250590988533558
Validation loss: 2.5497664593982186

Epoch: 6| Step: 3
Training loss: 2.7737032910712376
Validation loss: 2.558988328166966

Epoch: 6| Step: 4
Training loss: 1.857748394013297
Validation loss: 2.5409754037178303

Epoch: 6| Step: 5
Training loss: 1.9596102048618698
Validation loss: 2.528635597928537

Epoch: 6| Step: 6
Training loss: 2.336563689846477
Validation loss: 2.586642404541625

Epoch: 6| Step: 7
Training loss: 2.735735483951816
Validation loss: 2.556540607451448

Epoch: 6| Step: 8
Training loss: 2.331739244438094
Validation loss: 2.5535005150893997

Epoch: 6| Step: 9
Training loss: 2.4231664352278695
Validation loss: 2.5441597504641

Epoch: 6| Step: 10
Training loss: 2.9255551911687987
Validation loss: 2.5473890507390093

Epoch: 6| Step: 11
Training loss: 2.9539438555527444
Validation loss: 2.5355024370801003

Epoch: 6| Step: 12
Training loss: 2.427197127614745
Validation loss: 2.5489784712802046

Epoch: 6| Step: 13
Training loss: 2.2451737883320373
Validation loss: 2.567069491961198

Epoch: 29| Step: 0
Training loss: 2.492070401588729
Validation loss: 2.5587324497979558

Epoch: 6| Step: 1
Training loss: 2.1695976118049307
Validation loss: 2.5538676168250936

Epoch: 6| Step: 2
Training loss: 2.1184286723478416
Validation loss: 2.5448305782591594

Epoch: 6| Step: 3
Training loss: 2.4965208640346965
Validation loss: 2.554974072294322

Epoch: 6| Step: 4
Training loss: 2.3274567944442883
Validation loss: 2.534094950313381

Epoch: 6| Step: 5
Training loss: 2.208402872490185
Validation loss: 2.5597019270875836

Epoch: 6| Step: 6
Training loss: 2.4004035372033714
Validation loss: 2.585238574521274

Epoch: 6| Step: 7
Training loss: 2.141944868174328
Validation loss: 2.579307639398855

Epoch: 6| Step: 8
Training loss: 2.4678858922735296
Validation loss: 2.5498917232538325

Epoch: 6| Step: 9
Training loss: 2.9453254517288174
Validation loss: 2.583894396940795

Epoch: 6| Step: 10
Training loss: 3.2564673997350426
Validation loss: 2.5694244767750596

Epoch: 6| Step: 11
Training loss: 2.5308049128543058
Validation loss: 2.567574879942023

Epoch: 6| Step: 12
Training loss: 2.729988809080557
Validation loss: 2.570107170646113

Epoch: 6| Step: 13
Training loss: 2.2216829069344803
Validation loss: 2.555410533627931

Epoch: 30| Step: 0
Training loss: 2.347373805772549
Validation loss: 2.546411764692861

Epoch: 6| Step: 1
Training loss: 2.1467029574783942
Validation loss: 2.5476272657785595

Epoch: 6| Step: 2
Training loss: 2.558436451510183
Validation loss: 2.559840846255358

Epoch: 6| Step: 3
Training loss: 3.3036146654517813
Validation loss: 2.549078995987717

Epoch: 6| Step: 4
Training loss: 2.5912423018448347
Validation loss: 2.5496912560519247

Epoch: 6| Step: 5
Training loss: 2.333106836043376
Validation loss: 2.565741899609583

Epoch: 6| Step: 6
Training loss: 2.3823772095363207
Validation loss: 2.55081492971839

Epoch: 6| Step: 7
Training loss: 2.4210734363748796
Validation loss: 2.546415018306611

Epoch: 6| Step: 8
Training loss: 1.94926718611539
Validation loss: 2.5481953465127747

Epoch: 6| Step: 9
Training loss: 2.507611323098038
Validation loss: 2.5572379754691505

Epoch: 6| Step: 10
Training loss: 1.9054745832403217
Validation loss: 2.5437984490057026

Epoch: 6| Step: 11
Training loss: 2.6595146312881313
Validation loss: 2.526712408515676

Epoch: 6| Step: 12
Training loss: 2.315289850730467
Validation loss: 2.533621081733061

Epoch: 6| Step: 13
Training loss: 2.7876875023153485
Validation loss: 2.531103522375678

Epoch: 31| Step: 0
Training loss: 2.135191879226432
Validation loss: 2.569692550456902

Epoch: 6| Step: 1
Training loss: 2.0556785601106946
Validation loss: 2.55588594376486

Epoch: 6| Step: 2
Training loss: 2.5958566957486853
Validation loss: 2.5393785015948653

Epoch: 6| Step: 3
Training loss: 2.055751510536059
Validation loss: 2.535094007169792

Epoch: 6| Step: 4
Training loss: 2.7222306344384553
Validation loss: 2.5501342233225803

Epoch: 6| Step: 5
Training loss: 2.6335851062054547
Validation loss: 2.553492524220185

Epoch: 6| Step: 6
Training loss: 2.687833011310765
Validation loss: 2.579340145540185

Epoch: 6| Step: 7
Training loss: 2.560601345155043
Validation loss: 2.526151978486298

Epoch: 6| Step: 8
Training loss: 2.595611088414874
Validation loss: 2.5494107064136613

Epoch: 6| Step: 9
Training loss: 2.664409178609233
Validation loss: 2.5825714454234077

Epoch: 6| Step: 10
Training loss: 1.9736888637822494
Validation loss: 2.5770437882600876

Epoch: 6| Step: 11
Training loss: 2.3452841251900916
Validation loss: 2.560480477262429

Epoch: 6| Step: 12
Training loss: 2.2971767305202917
Validation loss: 2.579812000766176

Epoch: 6| Step: 13
Training loss: 2.9822322482897365
Validation loss: 2.5727012997167966

Epoch: 32| Step: 0
Training loss: 2.484723912335579
Validation loss: 2.5682321185748287

Epoch: 6| Step: 1
Training loss: 1.8966992116101355
Validation loss: 2.561692087233062

Epoch: 6| Step: 2
Training loss: 2.5345740450625596
Validation loss: 2.558185651619216

Epoch: 6| Step: 3
Training loss: 2.5496042991740784
Validation loss: 2.5401575632110127

Epoch: 6| Step: 4
Training loss: 1.887572543537519
Validation loss: 2.5461555822261466

Epoch: 6| Step: 5
Training loss: 3.2226624644826445
Validation loss: 2.5298917760557433

Epoch: 6| Step: 6
Training loss: 2.159000577360273
Validation loss: 2.568341954006586

Epoch: 6| Step: 7
Training loss: 2.2056682868011106
Validation loss: 2.559936807691943

Epoch: 6| Step: 8
Training loss: 1.823609603696563
Validation loss: 2.5492567537502655

Epoch: 6| Step: 9
Training loss: 2.606325297560084
Validation loss: 2.5377651245219663

Epoch: 6| Step: 10
Training loss: 3.1920597149801293
Validation loss: 2.551090800034278

Epoch: 6| Step: 11
Training loss: 2.79481763132162
Validation loss: 2.5449732914080867

Epoch: 6| Step: 12
Training loss: 2.3559362349308826
Validation loss: 2.5578926970241223

Epoch: 6| Step: 13
Training loss: 2.217891150793654
Validation loss: 2.5325631867911453

Epoch: 33| Step: 0
Training loss: 2.8434820363319306
Validation loss: 2.5496434024725754

Epoch: 6| Step: 1
Training loss: 2.1896593607568056
Validation loss: 2.552337716847336

Epoch: 6| Step: 2
Training loss: 2.434874465495034
Validation loss: 2.5415627166461525

Epoch: 6| Step: 3
Training loss: 2.794956337684979
Validation loss: 2.5363841323391094

Epoch: 6| Step: 4
Training loss: 2.7436317053387094
Validation loss: 2.5329072495657936

Epoch: 6| Step: 5
Training loss: 2.198007578724785
Validation loss: 2.5452267046309074

Epoch: 6| Step: 6
Training loss: 2.48920886895906
Validation loss: 2.534819554647653

Epoch: 6| Step: 7
Training loss: 2.220001297684024
Validation loss: 2.567357955663318

Epoch: 6| Step: 8
Training loss: 2.3308609625067915
Validation loss: 2.541701587583024

Epoch: 6| Step: 9
Training loss: 2.3552776404644686
Validation loss: 2.53333769367077

Epoch: 6| Step: 10
Training loss: 1.9389860545419741
Validation loss: 2.530836047951008

Epoch: 6| Step: 11
Training loss: 2.3256119855820554
Validation loss: 2.532469577311591

Epoch: 6| Step: 12
Training loss: 2.616881486453264
Validation loss: 2.5353928716624887

Epoch: 6| Step: 13
Training loss: 2.8269472989492352
Validation loss: 2.5482760049406266

Epoch: 34| Step: 0
Training loss: 2.1642115572608187
Validation loss: 2.5451839426264633

Epoch: 6| Step: 1
Training loss: 3.248971482902906
Validation loss: 2.558562207209551

Epoch: 6| Step: 2
Training loss: 2.386166372857068
Validation loss: 2.540335538545913

Epoch: 6| Step: 3
Training loss: 2.0735109202674833
Validation loss: 2.538203511799557

Epoch: 6| Step: 4
Training loss: 2.9285645634374666
Validation loss: 2.563485196538039

Epoch: 6| Step: 5
Training loss: 2.6011827896285595
Validation loss: 2.566105918400936

Epoch: 6| Step: 6
Training loss: 2.5295730498956344
Validation loss: 2.557984366417127

Epoch: 6| Step: 7
Training loss: 2.928963126594161
Validation loss: 2.5842099291950387

Epoch: 6| Step: 8
Training loss: 2.0321537061588923
Validation loss: 2.564898717304608

Epoch: 6| Step: 9
Training loss: 2.4476075538639632
Validation loss: 2.5841316609829215

Epoch: 6| Step: 10
Training loss: 1.9138032075846905
Validation loss: 2.571312815026108

Epoch: 6| Step: 11
Training loss: 2.9414827658540523
Validation loss: 2.60940419254991

Epoch: 6| Step: 12
Training loss: 1.4982817663386194
Validation loss: 2.5807618961254053

Epoch: 6| Step: 13
Training loss: 2.1993166425745567
Validation loss: 2.548448758984332

Epoch: 35| Step: 0
Training loss: 2.4467897675578865
Validation loss: 2.5785590143650885

Epoch: 6| Step: 1
Training loss: 2.4994101782247893
Validation loss: 2.558656663582222

Epoch: 6| Step: 2
Training loss: 2.1713427433461607
Validation loss: 2.569382117492077

Epoch: 6| Step: 3
Training loss: 2.578458637266031
Validation loss: 2.5359882543173504

Epoch: 6| Step: 4
Training loss: 2.366661894708398
Validation loss: 2.5530362640237865

Epoch: 6| Step: 5
Training loss: 2.191134131632839
Validation loss: 2.5364411736651387

Epoch: 6| Step: 6
Training loss: 2.7265486839840682
Validation loss: 2.551949187405679

Epoch: 6| Step: 7
Training loss: 2.1821793289829166
Validation loss: 2.561031688473284

Epoch: 6| Step: 8
Training loss: 2.999311050143465
Validation loss: 2.527415789953685

Epoch: 6| Step: 9
Training loss: 2.332093817863549
Validation loss: 2.537622005993471

Epoch: 6| Step: 10
Training loss: 2.3773398668531383
Validation loss: 2.54129834450769

Epoch: 6| Step: 11
Training loss: 1.798489450720189
Validation loss: 2.5520746555310585

Epoch: 6| Step: 12
Training loss: 2.998586162561316
Validation loss: 2.541522042792716

Epoch: 6| Step: 13
Training loss: 2.325101386700171
Validation loss: 2.522218565324363

Epoch: 36| Step: 0
Training loss: 2.4023579418724608
Validation loss: 2.5222136105121056

Epoch: 6| Step: 1
Training loss: 2.863748842702871
Validation loss: 2.5455457811136943

Epoch: 6| Step: 2
Training loss: 2.7532658691392284
Validation loss: 2.5268334213007555

Epoch: 6| Step: 3
Training loss: 1.327468799720109
Validation loss: 2.5476506306167983

Epoch: 6| Step: 4
Training loss: 2.5092560128283123
Validation loss: 2.5486813713688603

Epoch: 6| Step: 5
Training loss: 1.905361781572402
Validation loss: 2.552633675124035

Epoch: 6| Step: 6
Training loss: 2.2308644279485543
Validation loss: 2.573518849893476

Epoch: 6| Step: 7
Training loss: 2.852472029606513
Validation loss: 2.5371116303396444

Epoch: 6| Step: 8
Training loss: 2.8978687149859694
Validation loss: 2.566532915725858

Epoch: 6| Step: 9
Training loss: 2.2767094404336423
Validation loss: 2.5613461199290186

Epoch: 6| Step: 10
Training loss: 2.4966037569494017
Validation loss: 2.535838226926229

Epoch: 6| Step: 11
Training loss: 2.6138638016725064
Validation loss: 2.5551159622865867

Epoch: 6| Step: 12
Training loss: 2.4456946711142025
Validation loss: 2.556068521538324

Epoch: 6| Step: 13
Training loss: 2.2799049488131207
Validation loss: 2.544345715350413

Epoch: 37| Step: 0
Training loss: 2.533061191932638
Validation loss: 2.5740111078656462

Epoch: 6| Step: 1
Training loss: 1.8179699145724406
Validation loss: 2.556020188824475

Epoch: 6| Step: 2
Training loss: 2.836389931143407
Validation loss: 2.5737872536303525

Epoch: 6| Step: 3
Training loss: 2.6986943796918665
Validation loss: 2.546195659254229

Epoch: 6| Step: 4
Training loss: 2.141315432393336
Validation loss: 2.560311538197601

Epoch: 6| Step: 5
Training loss: 2.3546616925582677
Validation loss: 2.563765004233614

Epoch: 6| Step: 6
Training loss: 2.435893580913711
Validation loss: 2.545588365330693

Epoch: 6| Step: 7
Training loss: 2.5439700544622155
Validation loss: 2.5575663049430197

Epoch: 6| Step: 8
Training loss: 2.089162783330659
Validation loss: 2.561445298277421

Epoch: 6| Step: 9
Training loss: 3.1168887346545286
Validation loss: 2.531432863388372

Epoch: 6| Step: 10
Training loss: 1.9561492698987692
Validation loss: 2.5593039965843203

Epoch: 6| Step: 11
Training loss: 2.5453158795994097
Validation loss: 2.566535965782992

Epoch: 6| Step: 12
Training loss: 2.122270401756715
Validation loss: 2.5540197590516924

Epoch: 6| Step: 13
Training loss: 2.593625169071113
Validation loss: 2.5460139966461623

Epoch: 38| Step: 0
Training loss: 2.4409166501265442
Validation loss: 2.53128594110035

Epoch: 6| Step: 1
Training loss: 2.3474133154776218
Validation loss: 2.5523989008734693

Epoch: 6| Step: 2
Training loss: 2.888159943175038
Validation loss: 2.550695296159101

Epoch: 6| Step: 3
Training loss: 1.905117886918135
Validation loss: 2.5204131561757674

Epoch: 6| Step: 4
Training loss: 2.7138630584542627
Validation loss: 2.5448224196343547

Epoch: 6| Step: 5
Training loss: 2.164545439118295
Validation loss: 2.546537739709069

Epoch: 6| Step: 6
Training loss: 1.501371471944298
Validation loss: 2.540811462566782

Epoch: 6| Step: 7
Training loss: 2.901826506946274
Validation loss: 2.543664933640427

Epoch: 6| Step: 8
Training loss: 2.811189473316022
Validation loss: 2.5466459518442286

Epoch: 6| Step: 9
Training loss: 2.5154440678516368
Validation loss: 2.530545014844377

Epoch: 6| Step: 10
Training loss: 2.6499991075046405
Validation loss: 2.5204362372594344

Epoch: 6| Step: 11
Training loss: 2.2846441233027086
Validation loss: 2.5689529177918735

Epoch: 6| Step: 12
Training loss: 2.3788591452258596
Validation loss: 2.559381199768283

Epoch: 6| Step: 13
Training loss: 2.4449167144569777
Validation loss: 2.544591148826282

Epoch: 39| Step: 0
Training loss: 2.1897417842929934
Validation loss: 2.5478229201863405

Epoch: 6| Step: 1
Training loss: 2.958514105059982
Validation loss: 2.555629156153916

Epoch: 6| Step: 2
Training loss: 2.4560298364796433
Validation loss: 2.5574737504722616

Epoch: 6| Step: 3
Training loss: 2.8178289156136604
Validation loss: 2.540338862510677

Epoch: 6| Step: 4
Training loss: 2.3079950940957645
Validation loss: 2.536354005353435

Epoch: 6| Step: 5
Training loss: 2.5048521638597694
Validation loss: 2.505505848835823

Epoch: 6| Step: 6
Training loss: 2.1607832869464194
Validation loss: 2.5452091643337362

Epoch: 6| Step: 7
Training loss: 2.495335423430535
Validation loss: 2.5508445899346954

Epoch: 6| Step: 8
Training loss: 2.142475303053535
Validation loss: 2.5308849872153343

Epoch: 6| Step: 9
Training loss: 2.4451767758859546
Validation loss: 2.530074266441866

Epoch: 6| Step: 10
Training loss: 3.1019494418285807
Validation loss: 2.544427667090044

Epoch: 6| Step: 11
Training loss: 2.378690763087738
Validation loss: 2.5271305739182224

Epoch: 6| Step: 12
Training loss: 2.2198647935607867
Validation loss: 2.5305633084424657

Epoch: 6| Step: 13
Training loss: 2.1075469961843054
Validation loss: 2.530209865284301

Epoch: 40| Step: 0
Training loss: 2.140325817724504
Validation loss: 2.542229860996598

Epoch: 6| Step: 1
Training loss: 2.162000865332671
Validation loss: 2.5470468818065206

Epoch: 6| Step: 2
Training loss: 2.4939284028985633
Validation loss: 2.5849949712353903

Epoch: 6| Step: 3
Training loss: 2.8369870096043046
Validation loss: 2.5620975953769776

Epoch: 6| Step: 4
Training loss: 2.704912157166036
Validation loss: 2.59097096733318

Epoch: 6| Step: 5
Training loss: 2.350526701969659
Validation loss: 2.594556491586971

Epoch: 6| Step: 6
Training loss: 2.4153037228932557
Validation loss: 2.629559100003182

Epoch: 6| Step: 7
Training loss: 3.6729517879671327
Validation loss: 2.6407085382914994

Epoch: 6| Step: 8
Training loss: 2.5597796072564196
Validation loss: 2.657566866100763

Epoch: 6| Step: 9
Training loss: 2.339621200549471
Validation loss: 2.614527231858245

Epoch: 6| Step: 10
Training loss: 1.4311244393123608
Validation loss: 2.607586078021546

Epoch: 6| Step: 11
Training loss: 2.380375250397012
Validation loss: 2.6106358753988803

Epoch: 6| Step: 12
Training loss: 2.476016685435782
Validation loss: 2.5793045582267626

Epoch: 6| Step: 13
Training loss: 1.9209355485024073
Validation loss: 2.56761847616718

Epoch: 41| Step: 0
Training loss: 2.2379384469029673
Validation loss: 2.5365478740034075

Epoch: 6| Step: 1
Training loss: 2.770582163811105
Validation loss: 2.5569055787636286

Epoch: 6| Step: 2
Training loss: 2.3614021333845234
Validation loss: 2.5328736454938836

Epoch: 6| Step: 3
Training loss: 2.5390454100987356
Validation loss: 2.5240926767938037

Epoch: 6| Step: 4
Training loss: 1.9738019882999216
Validation loss: 2.545128674130298

Epoch: 6| Step: 5
Training loss: 2.053331050665111
Validation loss: 2.5463518100685225

Epoch: 6| Step: 6
Training loss: 2.833407027090275
Validation loss: 2.516442381315098

Epoch: 6| Step: 7
Training loss: 2.0599809927202366
Validation loss: 2.552212619750513

Epoch: 6| Step: 8
Training loss: 2.7727080769450025
Validation loss: 2.5218686323940305

Epoch: 6| Step: 9
Training loss: 2.3934247943896056
Validation loss: 2.5332911703298664

Epoch: 6| Step: 10
Training loss: 2.3172662434796236
Validation loss: 2.54273317713766

Epoch: 6| Step: 11
Training loss: 2.584666789878991
Validation loss: 2.5358655786569146

Epoch: 6| Step: 12
Training loss: 2.6583136227952244
Validation loss: 2.529421503047835

Epoch: 6| Step: 13
Training loss: 2.3305534651752846
Validation loss: 2.5378542876689267

Epoch: 42| Step: 0
Training loss: 2.352616894338277
Validation loss: 2.5348219766249755

Epoch: 6| Step: 1
Training loss: 1.73385598604751
Validation loss: 2.54061845103691

Epoch: 6| Step: 2
Training loss: 2.638964429967611
Validation loss: 2.530050095349945

Epoch: 6| Step: 3
Training loss: 2.0444077626107267
Validation loss: 2.551066625578657

Epoch: 6| Step: 4
Training loss: 2.2755285131235086
Validation loss: 2.554149574940318

Epoch: 6| Step: 5
Training loss: 2.3994770592945986
Validation loss: 2.5338551062921635

Epoch: 6| Step: 6
Training loss: 3.0183423701010086
Validation loss: 2.538089233098833

Epoch: 6| Step: 7
Training loss: 2.893822133955152
Validation loss: 2.5325375331797377

Epoch: 6| Step: 8
Training loss: 2.2541628580772204
Validation loss: 2.550611302398915

Epoch: 6| Step: 9
Training loss: 2.335316451069478
Validation loss: 2.55005548578869

Epoch: 6| Step: 10
Training loss: 3.064895938270459
Validation loss: 2.595942233410306

Epoch: 6| Step: 11
Training loss: 2.4637171956302018
Validation loss: 2.5607544683653116

Epoch: 6| Step: 12
Training loss: 1.5987502551880157
Validation loss: 2.5671053030639084

Epoch: 6| Step: 13
Training loss: 2.606100986529445
Validation loss: 2.5678954659157855

Epoch: 43| Step: 0
Training loss: 2.5599365438106862
Validation loss: 2.5645875568701153

Epoch: 6| Step: 1
Training loss: 2.380942890057494
Validation loss: 2.5356569897723733

Epoch: 6| Step: 2
Training loss: 2.3529173537759354
Validation loss: 2.556944780201786

Epoch: 6| Step: 3
Training loss: 2.2436919265924855
Validation loss: 2.592165382479447

Epoch: 6| Step: 4
Training loss: 2.350780471086611
Validation loss: 2.573368748370099

Epoch: 6| Step: 5
Training loss: 3.003207558282071
Validation loss: 2.567991513208525

Epoch: 6| Step: 6
Training loss: 2.29691652013918
Validation loss: 2.5556962007944146

Epoch: 6| Step: 7
Training loss: 2.255063399546479
Validation loss: 2.54232021955235

Epoch: 6| Step: 8
Training loss: 3.102958000122609
Validation loss: 2.539689222406969

Epoch: 6| Step: 9
Training loss: 2.339908758161522
Validation loss: 2.5322422861242933

Epoch: 6| Step: 10
Training loss: 2.0345081901019815
Validation loss: 2.5201185384754283

Epoch: 6| Step: 11
Training loss: 1.8904657848564117
Validation loss: 2.523973248655861

Epoch: 6| Step: 12
Training loss: 2.2823289383863155
Validation loss: 2.5502030485007183

Epoch: 6| Step: 13
Training loss: 2.7229693764972454
Validation loss: 2.554321231697717

Epoch: 44| Step: 0
Training loss: 2.800573109829443
Validation loss: 2.5421071895456833

Epoch: 6| Step: 1
Training loss: 2.0773072892655158
Validation loss: 2.5548565232166394

Epoch: 6| Step: 2
Training loss: 2.2538353761739267
Validation loss: 2.5363121199454146

Epoch: 6| Step: 3
Training loss: 2.8112135594144645
Validation loss: 2.5259286652029447

Epoch: 6| Step: 4
Training loss: 2.6782363209684448
Validation loss: 2.5178556799763583

Epoch: 6| Step: 5
Training loss: 2.7838576019142205
Validation loss: 2.5368797114114616

Epoch: 6| Step: 6
Training loss: 1.6910524064238732
Validation loss: 2.552530449347189

Epoch: 6| Step: 7
Training loss: 2.573558114797344
Validation loss: 2.5411441974721933

Epoch: 6| Step: 8
Training loss: 2.5567801301224677
Validation loss: 2.5309109244847376

Epoch: 6| Step: 9
Training loss: 2.6433787236239095
Validation loss: 2.54184636799232

Epoch: 6| Step: 10
Training loss: 2.13092303858408
Validation loss: 2.552430815623115

Epoch: 6| Step: 11
Training loss: 2.210526714647587
Validation loss: 2.506623022679405

Epoch: 6| Step: 12
Training loss: 2.8925212517091996
Validation loss: 2.5256001876497085

Epoch: 6| Step: 13
Training loss: 1.6053297442103551
Validation loss: 2.5153231469307107

Epoch: 45| Step: 0
Training loss: 2.557025830863061
Validation loss: 2.543295796776882

Epoch: 6| Step: 1
Training loss: 2.1126974431150853
Validation loss: 2.564586789903292

Epoch: 6| Step: 2
Training loss: 2.589232037368409
Validation loss: 2.546955302402042

Epoch: 6| Step: 3
Training loss: 2.072683912337785
Validation loss: 2.541962713187208

Epoch: 6| Step: 4
Training loss: 3.2635541126457506
Validation loss: 2.5558368924214303

Epoch: 6| Step: 5
Training loss: 1.7172163623331502
Validation loss: 2.600362919274043

Epoch: 6| Step: 6
Training loss: 2.8951825478669964
Validation loss: 2.5849586009308165

Epoch: 6| Step: 7
Training loss: 2.408167285760791
Validation loss: 2.5871032054316285

Epoch: 6| Step: 8
Training loss: 2.3477494765573463
Validation loss: 2.6260849209322292

Epoch: 6| Step: 9
Training loss: 2.563968330806641
Validation loss: 2.6107211419222316

Epoch: 6| Step: 10
Training loss: 2.382220585580915
Validation loss: 2.601809194971094

Epoch: 6| Step: 11
Training loss: 2.3528200759998787
Validation loss: 2.6228328266232595

Epoch: 6| Step: 12
Training loss: 1.899076566156016
Validation loss: 2.5987751092839937

Epoch: 6| Step: 13
Training loss: 2.4385368880516096
Validation loss: 2.573281912162242

Epoch: 46| Step: 0
Training loss: 2.9000292414802353
Validation loss: 2.587198324631247

Epoch: 6| Step: 1
Training loss: 2.7714036818216767
Validation loss: 2.555441866525021

Epoch: 6| Step: 2
Training loss: 2.436725102031387
Validation loss: 2.534241803828376

Epoch: 6| Step: 3
Training loss: 1.952939200146849
Validation loss: 2.5324312365938133

Epoch: 6| Step: 4
Training loss: 3.0226852703500753
Validation loss: 2.5356512228161674

Epoch: 6| Step: 5
Training loss: 2.392152784258837
Validation loss: 2.5416118480419825

Epoch: 6| Step: 6
Training loss: 2.2268378907269266
Validation loss: 2.545015526095273

Epoch: 6| Step: 7
Training loss: 2.743035948692673
Validation loss: 2.5331126922175398

Epoch: 6| Step: 8
Training loss: 1.754320805075737
Validation loss: 2.5398229154797893

Epoch: 6| Step: 9
Training loss: 1.5162504812870379
Validation loss: 2.544824832091686

Epoch: 6| Step: 10
Training loss: 2.5600749380349184
Validation loss: 2.512656764933076

Epoch: 6| Step: 11
Training loss: 2.897191851919899
Validation loss: 2.5429443889492136

Epoch: 6| Step: 12
Training loss: 2.21560919450683
Validation loss: 2.5496457558205505

Epoch: 6| Step: 13
Training loss: 1.9984736578729674
Validation loss: 2.5114421622980445

Epoch: 47| Step: 0
Training loss: 3.0634267533606163
Validation loss: 2.5463009520850983

Epoch: 6| Step: 1
Training loss: 1.6224991554763548
Validation loss: 2.5373986842532528

Epoch: 6| Step: 2
Training loss: 2.143173371550912
Validation loss: 2.5514972065601262

Epoch: 6| Step: 3
Training loss: 2.847623932161864
Validation loss: 2.5447037067324323

Epoch: 6| Step: 4
Training loss: 2.958563101715266
Validation loss: 2.5422826916785963

Epoch: 6| Step: 5
Training loss: 2.362973834764261
Validation loss: 2.5646959757812975

Epoch: 6| Step: 6
Training loss: 1.825484626907987
Validation loss: 2.574570766339487

Epoch: 6| Step: 7
Training loss: 2.098433309793727
Validation loss: 2.565850982130391

Epoch: 6| Step: 8
Training loss: 2.222399007864855
Validation loss: 2.570307606979397

Epoch: 6| Step: 9
Training loss: 2.5135574848316526
Validation loss: 2.5600712128509557

Epoch: 6| Step: 10
Training loss: 2.645031023907213
Validation loss: 2.5944279240548074

Epoch: 6| Step: 11
Training loss: 2.5887385292849006
Validation loss: 2.5647957217797157

Epoch: 6| Step: 12
Training loss: 2.3837837616120394
Validation loss: 2.5657285882355674

Epoch: 6| Step: 13
Training loss: 2.4277290718591518
Validation loss: 2.5551384421886825

Epoch: 48| Step: 0
Training loss: 2.2214154633401204
Validation loss: 2.533266026037764

Epoch: 6| Step: 1
Training loss: 2.4555077127635756
Validation loss: 2.5202485712011584

Epoch: 6| Step: 2
Training loss: 2.776742690405339
Validation loss: 2.52995091135604

Epoch: 6| Step: 3
Training loss: 1.9447053628279194
Validation loss: 2.5233783380366

Epoch: 6| Step: 4
Training loss: 2.0538590650336737
Validation loss: 2.529382479874737

Epoch: 6| Step: 5
Training loss: 2.872548758389269
Validation loss: 2.541376759197448

Epoch: 6| Step: 6
Training loss: 1.7802551569918206
Validation loss: 2.5187977435286

Epoch: 6| Step: 7
Training loss: 1.8376201304916195
Validation loss: 2.5301575206576796

Epoch: 6| Step: 8
Training loss: 2.1877957825280134
Validation loss: 2.5640798908692273

Epoch: 6| Step: 9
Training loss: 1.9693542037732659
Validation loss: 2.5259524981828885

Epoch: 6| Step: 10
Training loss: 2.487906578996283
Validation loss: 2.531749173775186

Epoch: 6| Step: 11
Training loss: 2.3152698733596515
Validation loss: 2.523570038549822

Epoch: 6| Step: 12
Training loss: 2.967942619961805
Validation loss: 2.5314650581585947

Epoch: 6| Step: 13
Training loss: 3.3207909811486953
Validation loss: 2.5255566055891268

Epoch: 49| Step: 0
Training loss: 2.3279611414651824
Validation loss: 2.522265529214094

Epoch: 6| Step: 1
Training loss: 2.1396515575057125
Validation loss: 2.5494723035793387

Epoch: 6| Step: 2
Training loss: 1.7908787732271294
Validation loss: 2.5364927933145207

Epoch: 6| Step: 3
Training loss: 2.178333696084648
Validation loss: 2.54015037510756

Epoch: 6| Step: 4
Training loss: 2.6768957782360228
Validation loss: 2.5263674627519457

Epoch: 6| Step: 5
Training loss: 3.1523829272174426
Validation loss: 2.553658918989995

Epoch: 6| Step: 6
Training loss: 2.3286197827840933
Validation loss: 2.551967997118111

Epoch: 6| Step: 7
Training loss: 2.5395387173604296
Validation loss: 2.5732138895774646

Epoch: 6| Step: 8
Training loss: 2.188096755236916
Validation loss: 2.574802886183676

Epoch: 6| Step: 9
Training loss: 2.4089304868962578
Validation loss: 2.5408992911744512

Epoch: 6| Step: 10
Training loss: 2.5238620648908716
Validation loss: 2.563861051274922

Epoch: 6| Step: 11
Training loss: 2.59058858480042
Validation loss: 2.5410610373776366

Epoch: 6| Step: 12
Training loss: 2.2163084323880478
Validation loss: 2.561432996213206

Epoch: 6| Step: 13
Training loss: 2.3676835852785647
Validation loss: 2.558842382411013

Epoch: 50| Step: 0
Training loss: 1.6898428583164835
Validation loss: 2.5841704109637966

Epoch: 6| Step: 1
Training loss: 2.3490884636289953
Validation loss: 2.5354984642214227

Epoch: 6| Step: 2
Training loss: 1.6620878583544132
Validation loss: 2.569088544912702

Epoch: 6| Step: 3
Training loss: 2.0368015426120474
Validation loss: 2.5568134976995958

Epoch: 6| Step: 4
Training loss: 2.6682641688224167
Validation loss: 2.5488959253484347

Epoch: 6| Step: 5
Training loss: 2.409735397122071
Validation loss: 2.5824723321442553

Epoch: 6| Step: 6
Training loss: 2.96308889209735
Validation loss: 2.5827878458146802

Epoch: 6| Step: 7
Training loss: 2.8013001284524957
Validation loss: 2.591057080357485

Epoch: 6| Step: 8
Training loss: 2.4846990601898353
Validation loss: 2.574256306259968

Epoch: 6| Step: 9
Training loss: 2.401483546133738
Validation loss: 2.5935760041364473

Epoch: 6| Step: 10
Training loss: 2.5840079031844083
Validation loss: 2.5598909617960084

Epoch: 6| Step: 11
Training loss: 2.4849515042091834
Validation loss: 2.5552899800280513

Epoch: 6| Step: 12
Training loss: 2.6020491777738304
Validation loss: 2.5489775671088406

Epoch: 6| Step: 13
Training loss: 2.0744421887069087
Validation loss: 2.563270763068434

Epoch: 51| Step: 0
Training loss: 1.9117027216567932
Validation loss: 2.5445300113064753

Epoch: 6| Step: 1
Training loss: 1.7892730455735957
Validation loss: 2.5485567028764513

Epoch: 6| Step: 2
Training loss: 2.256309140769656
Validation loss: 2.533228615010256

Epoch: 6| Step: 3
Training loss: 3.428086865333843
Validation loss: 2.5322199089609208

Epoch: 6| Step: 4
Training loss: 3.3575854835790877
Validation loss: 2.545025222018806

Epoch: 6| Step: 5
Training loss: 2.4273433846140997
Validation loss: 2.5238344335012233

Epoch: 6| Step: 6
Training loss: 2.002895524186033
Validation loss: 2.5233891879122985

Epoch: 6| Step: 7
Training loss: 2.102461952110145
Validation loss: 2.5356457065849143

Epoch: 6| Step: 8
Training loss: 2.586550360486721
Validation loss: 2.5431635284442797

Epoch: 6| Step: 9
Training loss: 2.0814839228775006
Validation loss: 2.545086534998745

Epoch: 6| Step: 10
Training loss: 2.187491716641683
Validation loss: 2.52757142666272

Epoch: 6| Step: 11
Training loss: 2.063051901293426
Validation loss: 2.5150509686800566

Epoch: 6| Step: 12
Training loss: 2.069231089176615
Validation loss: 2.534951490255345

Epoch: 6| Step: 13
Training loss: 2.7075723214674365
Validation loss: 2.55869811332956

Epoch: 52| Step: 0
Training loss: 2.324372102182238
Validation loss: 2.5625514823890283

Epoch: 6| Step: 1
Training loss: 2.0727199160751035
Validation loss: 2.542744053818026

Epoch: 6| Step: 2
Training loss: 2.20480434181107
Validation loss: 2.5589171925883956

Epoch: 6| Step: 3
Training loss: 3.096485200402785
Validation loss: 2.5452255727506707

Epoch: 6| Step: 4
Training loss: 2.364111283247135
Validation loss: 2.5586837480941305

Epoch: 6| Step: 5
Training loss: 2.5093743995295243
Validation loss: 2.5749655891020393

Epoch: 6| Step: 6
Training loss: 2.8265712115826744
Validation loss: 2.5794885285614084

Epoch: 6| Step: 7
Training loss: 3.1593091888063243
Validation loss: 2.5749713914633805

Epoch: 6| Step: 8
Training loss: 1.974254240404618
Validation loss: 2.532833765573279

Epoch: 6| Step: 9
Training loss: 1.8118983618502273
Validation loss: 2.556199476991033

Epoch: 6| Step: 10
Training loss: 2.114691357288476
Validation loss: 2.547848801996995

Epoch: 6| Step: 11
Training loss: 2.2399418980011285
Validation loss: 2.5450633105589167

Epoch: 6| Step: 12
Training loss: 2.76001528334878
Validation loss: 2.5244758288502624

Epoch: 6| Step: 13
Training loss: 2.3117731343866392
Validation loss: 2.5400511396571464

Epoch: 53| Step: 0
Training loss: 2.3953148211662656
Validation loss: 2.5250111447456587

Epoch: 6| Step: 1
Training loss: 2.762342671190715
Validation loss: 2.528110040118229

Epoch: 6| Step: 2
Training loss: 2.2448963987578594
Validation loss: 2.5596612853245237

Epoch: 6| Step: 3
Training loss: 2.8664892526182575
Validation loss: 2.5490759484255614

Epoch: 6| Step: 4
Training loss: 1.4929416208881467
Validation loss: 2.5339556389799323

Epoch: 6| Step: 5
Training loss: 3.0278751423742056
Validation loss: 2.5460149486918975

Epoch: 6| Step: 6
Training loss: 2.532785585649914
Validation loss: 2.575666006308438

Epoch: 6| Step: 7
Training loss: 2.099189411124412
Validation loss: 2.569507105524359

Epoch: 6| Step: 8
Training loss: 2.210081224459245
Validation loss: 2.5617472077860115

Epoch: 6| Step: 9
Training loss: 1.9759643011343346
Validation loss: 2.5658414345944074

Epoch: 6| Step: 10
Training loss: 1.7036218880774634
Validation loss: 2.5913395232583123

Epoch: 6| Step: 11
Training loss: 2.956792259889025
Validation loss: 2.5910459157314816

Epoch: 6| Step: 12
Training loss: 1.7008209041656546
Validation loss: 2.583884485476074

Epoch: 6| Step: 13
Training loss: 2.95030247058988
Validation loss: 2.5889130114271506

Epoch: 54| Step: 0
Training loss: 2.515670775950703
Validation loss: 2.5613978427002864

Epoch: 6| Step: 1
Training loss: 2.5568347737708375
Validation loss: 2.530625568495662

Epoch: 6| Step: 2
Training loss: 2.0973429810014514
Validation loss: 2.5343185631755065

Epoch: 6| Step: 3
Training loss: 2.72661164247664
Validation loss: 2.5432809070701685

Epoch: 6| Step: 4
Training loss: 2.2601748452870436
Validation loss: 2.531029020482945

Epoch: 6| Step: 5
Training loss: 2.170401972443092
Validation loss: 2.5318959514749526

Epoch: 6| Step: 6
Training loss: 2.712952230700126
Validation loss: 2.5258641419838614

Epoch: 6| Step: 7
Training loss: 2.5377208745128916
Validation loss: 2.525394637362073

Epoch: 6| Step: 8
Training loss: 2.267903622471712
Validation loss: 2.517139421252881

Epoch: 6| Step: 9
Training loss: 2.5328998604733735
Validation loss: 2.5052146250645126

Epoch: 6| Step: 10
Training loss: 2.6762057002542314
Validation loss: 2.5302156917569194

Epoch: 6| Step: 11
Training loss: 2.7948757250459146
Validation loss: 2.537191239412304

Epoch: 6| Step: 12
Training loss: 1.685350815563631
Validation loss: 2.5314192695691777

Epoch: 6| Step: 13
Training loss: 1.630438287703575
Validation loss: 2.5376093692104287

Epoch: 55| Step: 0
Training loss: 2.5131524296961567
Validation loss: 2.5319435205653793

Epoch: 6| Step: 1
Training loss: 2.639076094651652
Validation loss: 2.5600812397921144

Epoch: 6| Step: 2
Training loss: 2.3506042961541587
Validation loss: 2.551392603191823

Epoch: 6| Step: 3
Training loss: 2.410604722697057
Validation loss: 2.5906506447007844

Epoch: 6| Step: 4
Training loss: 2.556981354718189
Validation loss: 2.58523520837786

Epoch: 6| Step: 5
Training loss: 1.9071300538818619
Validation loss: 2.5973572523088184

Epoch: 6| Step: 6
Training loss: 1.995467175348742
Validation loss: 2.6132220692531294

Epoch: 6| Step: 7
Training loss: 2.3162357981658683
Validation loss: 2.594176092730131

Epoch: 6| Step: 8
Training loss: 3.3561422717885976
Validation loss: 2.5916322388973905

Epoch: 6| Step: 9
Training loss: 2.7283134194379244
Validation loss: 2.5971330235260277

Epoch: 6| Step: 10
Training loss: 2.0996433273054245
Validation loss: 2.5798886364551903

Epoch: 6| Step: 11
Training loss: 2.13848959786162
Validation loss: 2.5715264079111204

Epoch: 6| Step: 12
Training loss: 2.6171226379555868
Validation loss: 2.541262584104089

Epoch: 6| Step: 13
Training loss: 1.9227967571703375
Validation loss: 2.537211106051894

Epoch: 56| Step: 0
Training loss: 2.7470116417481565
Validation loss: 2.527193995602998

Epoch: 6| Step: 1
Training loss: 1.835797243645221
Validation loss: 2.5471258371472865

Epoch: 6| Step: 2
Training loss: 2.611404360768955
Validation loss: 2.530965922548883

Epoch: 6| Step: 3
Training loss: 2.8485245080864137
Validation loss: 2.522220904874621

Epoch: 6| Step: 4
Training loss: 1.6656059306987305
Validation loss: 2.523583477825155

Epoch: 6| Step: 5
Training loss: 2.5579984248963994
Validation loss: 2.533717079544682

Epoch: 6| Step: 6
Training loss: 2.120445756653346
Validation loss: 2.514116676178333

Epoch: 6| Step: 7
Training loss: 2.144768595806859
Validation loss: 2.542815204287788

Epoch: 6| Step: 8
Training loss: 1.9383779812976407
Validation loss: 2.554879028731224

Epoch: 6| Step: 9
Training loss: 2.739039513360388
Validation loss: 2.5551287146593347

Epoch: 6| Step: 10
Training loss: 2.32859101207833
Validation loss: 2.5657034908032794

Epoch: 6| Step: 11
Training loss: 3.028545785805655
Validation loss: 2.5673817909909054

Epoch: 6| Step: 12
Training loss: 2.028077685446385
Validation loss: 2.5420555901140283

Epoch: 6| Step: 13
Training loss: 2.5089676237727527
Validation loss: 2.5378583194695734

Epoch: 57| Step: 0
Training loss: 2.5421331529956914
Validation loss: 2.537778754809875

Epoch: 6| Step: 1
Training loss: 2.395527618363649
Validation loss: 2.5522422792931527

Epoch: 6| Step: 2
Training loss: 1.7467979018338309
Validation loss: 2.5654955157162282

Epoch: 6| Step: 3
Training loss: 1.7604496819223678
Validation loss: 2.553756077442229

Epoch: 6| Step: 4
Training loss: 1.8295728378788323
Validation loss: 2.557680855301236

Epoch: 6| Step: 5
Training loss: 3.255722876000428
Validation loss: 2.5463139358705846

Epoch: 6| Step: 6
Training loss: 2.1365000387951048
Validation loss: 2.5558780303154536

Epoch: 6| Step: 7
Training loss: 2.754540076938694
Validation loss: 2.5742382922899627

Epoch: 6| Step: 8
Training loss: 2.446749523935713
Validation loss: 2.5624375994768274

Epoch: 6| Step: 9
Training loss: 2.292328155300203
Validation loss: 2.589202878281563

Epoch: 6| Step: 10
Training loss: 2.153984538285806
Validation loss: 2.5779254412240973

Epoch: 6| Step: 11
Training loss: 2.1371246454484365
Validation loss: 2.590184729651711

Epoch: 6| Step: 12
Training loss: 2.5514304020005016
Validation loss: 2.5747579454644547

Epoch: 6| Step: 13
Training loss: 3.0104566173256515
Validation loss: 2.5696332627302296

Epoch: 58| Step: 0
Training loss: 2.7744534203363753
Validation loss: 2.5609561177031415

Epoch: 6| Step: 1
Training loss: 3.037156318718794
Validation loss: 2.543656763466002

Epoch: 6| Step: 2
Training loss: 1.2342036164492407
Validation loss: 2.5181710290098653

Epoch: 6| Step: 3
Training loss: 1.980431189547671
Validation loss: 2.5228430615709834

Epoch: 6| Step: 4
Training loss: 1.863204218713645
Validation loss: 2.519742395981911

Epoch: 6| Step: 5
Training loss: 2.8428729035651936
Validation loss: 2.536055794693268

Epoch: 6| Step: 6
Training loss: 2.8389076673563043
Validation loss: 2.5413205635517846

Epoch: 6| Step: 7
Training loss: 2.050429541083526
Validation loss: 2.527999564863924

Epoch: 6| Step: 8
Training loss: 2.5691943301793243
Validation loss: 2.5426323468456444

Epoch: 6| Step: 9
Training loss: 2.3284553447075944
Validation loss: 2.544140180176467

Epoch: 6| Step: 10
Training loss: 2.2124122041858447
Validation loss: 2.553389099730553

Epoch: 6| Step: 11
Training loss: 3.034904400798296
Validation loss: 2.5476854435163343

Epoch: 6| Step: 12
Training loss: 2.2961719500920763
Validation loss: 2.5345777998820007

Epoch: 6| Step: 13
Training loss: 2.6293939418668093
Validation loss: 2.5276420845621597

Epoch: 59| Step: 0
Training loss: 2.5093672736822117
Validation loss: 2.538872125775706

Epoch: 6| Step: 1
Training loss: 2.3053821615972354
Validation loss: 2.539089621374581

Epoch: 6| Step: 2
Training loss: 2.5352273469662765
Validation loss: 2.5482834897885316

Epoch: 6| Step: 3
Training loss: 2.873629699551855
Validation loss: 2.5551975141675407

Epoch: 6| Step: 4
Training loss: 2.3489947827225612
Validation loss: 2.623223006034181

Epoch: 6| Step: 5
Training loss: 1.9437112614245708
Validation loss: 2.6314395301680005

Epoch: 6| Step: 6
Training loss: 2.535720456766337
Validation loss: 2.640505530308891

Epoch: 6| Step: 7
Training loss: 2.3440779392968243
Validation loss: 2.6327280998851372

Epoch: 6| Step: 8
Training loss: 2.757591865510289
Validation loss: 2.6071207889449046

Epoch: 6| Step: 9
Training loss: 2.381929728095214
Validation loss: 2.614376194158955

Epoch: 6| Step: 10
Training loss: 2.0027180322255957
Validation loss: 2.585151652838027

Epoch: 6| Step: 11
Training loss: 2.8783639218446906
Validation loss: 2.559571205167143

Epoch: 6| Step: 12
Training loss: 1.848728376962362
Validation loss: 2.53662334952378

Epoch: 6| Step: 13
Training loss: 2.5616139066181676
Validation loss: 2.5434685453751267

Epoch: 60| Step: 0
Training loss: 1.790372676946668
Validation loss: 2.5225342668386657

Epoch: 6| Step: 1
Training loss: 2.744157827737449
Validation loss: 2.5350968912833247

Epoch: 6| Step: 2
Training loss: 2.7632178051507976
Validation loss: 2.5472792478182598

Epoch: 6| Step: 3
Training loss: 1.9636907816019025
Validation loss: 2.5330083101058207

Epoch: 6| Step: 4
Training loss: 2.3665413053201454
Validation loss: 2.527061324771942

Epoch: 6| Step: 5
Training loss: 2.462659251683997
Validation loss: 2.5350773137308082

Epoch: 6| Step: 6
Training loss: 2.6364074071102648
Validation loss: 2.5612237124492663

Epoch: 6| Step: 7
Training loss: 2.194871851454071
Validation loss: 2.5278226466499305

Epoch: 6| Step: 8
Training loss: 1.7211084310673423
Validation loss: 2.5377232232588787

Epoch: 6| Step: 9
Training loss: 2.6419170762360276
Validation loss: 2.5194791487794737

Epoch: 6| Step: 10
Training loss: 2.7394125610812203
Validation loss: 2.5315905918756596

Epoch: 6| Step: 11
Training loss: 1.9863163620442015
Validation loss: 2.5299714788078216

Epoch: 6| Step: 12
Training loss: 2.5581918182332872
Validation loss: 2.546239598121427

Epoch: 6| Step: 13
Training loss: 2.364231189828423
Validation loss: 2.5257012337760116

Epoch: 61| Step: 0
Training loss: 2.440685440467805
Validation loss: 2.529405651920097

Epoch: 6| Step: 1
Training loss: 2.4116789769735263
Validation loss: 2.548658546077927

Epoch: 6| Step: 2
Training loss: 2.1673740430442914
Validation loss: 2.5665906416999316

Epoch: 6| Step: 3
Training loss: 2.877826130909596
Validation loss: 2.52866678330726

Epoch: 6| Step: 4
Training loss: 1.6859479760665599
Validation loss: 2.521924394882491

Epoch: 6| Step: 5
Training loss: 2.114274727487186
Validation loss: 2.52690472885006

Epoch: 6| Step: 6
Training loss: 2.3387153974427064
Validation loss: 2.5703382481113417

Epoch: 6| Step: 7
Training loss: 2.311599143577004
Validation loss: 2.5621741948373753

Epoch: 6| Step: 8
Training loss: 2.2894476348493504
Validation loss: 2.562479996021625

Epoch: 6| Step: 9
Training loss: 2.5149948562963833
Validation loss: 2.557562731473494

Epoch: 6| Step: 10
Training loss: 2.9746420765191965
Validation loss: 2.6038345481171232

Epoch: 6| Step: 11
Training loss: 2.0685493302764404
Validation loss: 2.5780266945332104

Epoch: 6| Step: 12
Training loss: 2.531532366038462
Validation loss: 2.572452678362569

Epoch: 6| Step: 13
Training loss: 2.5083086230137055
Validation loss: 2.573040142005152

Epoch: 62| Step: 0
Training loss: 1.6897242686816547
Validation loss: 2.5629494590772053

Epoch: 6| Step: 1
Training loss: 2.3879666975756737
Validation loss: 2.5459106585491345

Epoch: 6| Step: 2
Training loss: 2.255681705496689
Validation loss: 2.535924026224692

Epoch: 6| Step: 3
Training loss: 2.064360732913631
Validation loss: 2.547376961574145

Epoch: 6| Step: 4
Training loss: 2.50439000924175
Validation loss: 2.5276628044260225

Epoch: 6| Step: 5
Training loss: 2.1839930078932515
Validation loss: 2.54329949965998

Epoch: 6| Step: 6
Training loss: 1.380460516964984
Validation loss: 2.5155770433486926

Epoch: 6| Step: 7
Training loss: 3.05322074310521
Validation loss: 2.522482834131555

Epoch: 6| Step: 8
Training loss: 2.592986396621464
Validation loss: 2.527934992329617

Epoch: 6| Step: 9
Training loss: 1.733793968957798
Validation loss: 2.5203536473112167

Epoch: 6| Step: 10
Training loss: 3.0835623956772253
Validation loss: 2.536430497117928

Epoch: 6| Step: 11
Training loss: 3.0851675883915792
Validation loss: 2.560992658206138

Epoch: 6| Step: 12
Training loss: 2.4872511044299563
Validation loss: 2.5396566781480403

Epoch: 6| Step: 13
Training loss: 2.0266602527157196
Validation loss: 2.527290324020333

Epoch: 63| Step: 0
Training loss: 2.878118233771142
Validation loss: 2.545015448028106

Epoch: 6| Step: 1
Training loss: 2.5090852639043075
Validation loss: 2.539915784606143

Epoch: 6| Step: 2
Training loss: 3.0611556858972038
Validation loss: 2.5223347446107836

Epoch: 6| Step: 3
Training loss: 2.2128564709067193
Validation loss: 2.5325147192911053

Epoch: 6| Step: 4
Training loss: 1.910783847922801
Validation loss: 2.5673243381887807

Epoch: 6| Step: 5
Training loss: 2.1522223408929366
Validation loss: 2.5574638686823876

Epoch: 6| Step: 6
Training loss: 2.5682948579408555
Validation loss: 2.5484113993225153

Epoch: 6| Step: 7
Training loss: 2.3478741790618947
Validation loss: 2.5492898612937966

Epoch: 6| Step: 8
Training loss: 1.910366429036188
Validation loss: 2.546519342408572

Epoch: 6| Step: 9
Training loss: 1.7629927196731021
Validation loss: 2.545422957248088

Epoch: 6| Step: 10
Training loss: 2.6457031898830827
Validation loss: 2.540359228543351

Epoch: 6| Step: 11
Training loss: 2.083962180279539
Validation loss: 2.560559778789612

Epoch: 6| Step: 12
Training loss: 2.7347964588699747
Validation loss: 2.557364737922809

Epoch: 6| Step: 13
Training loss: 1.927968359818169
Validation loss: 2.5163996670627085

Epoch: 64| Step: 0
Training loss: 2.2819699758147607
Validation loss: 2.542043569375016

Epoch: 6| Step: 1
Training loss: 2.214442625507059
Validation loss: 2.552662878341368

Epoch: 6| Step: 2
Training loss: 2.495522685983304
Validation loss: 2.5202286102655647

Epoch: 6| Step: 3
Training loss: 1.985430639430617
Validation loss: 2.554679520620781

Epoch: 6| Step: 4
Training loss: 2.5647281170986194
Validation loss: 2.5193479170621518

Epoch: 6| Step: 5
Training loss: 2.5157816583415005
Validation loss: 2.523110910860906

Epoch: 6| Step: 6
Training loss: 2.995304247347786
Validation loss: 2.5285267878808093

Epoch: 6| Step: 7
Training loss: 2.496677861649082
Validation loss: 2.5228554415551794

Epoch: 6| Step: 8
Training loss: 2.285855282538941
Validation loss: 2.5456711433887103

Epoch: 6| Step: 9
Training loss: 1.775203346639696
Validation loss: 2.5642809067962022

Epoch: 6| Step: 10
Training loss: 1.6071981874659844
Validation loss: 2.5591031487135916

Epoch: 6| Step: 11
Training loss: 2.380637555198181
Validation loss: 2.571467046569668

Epoch: 6| Step: 12
Training loss: 3.0056261712046415
Validation loss: 2.568266853628996

Epoch: 6| Step: 13
Training loss: 1.8740252186188775
Validation loss: 2.5411907646854823

Epoch: 65| Step: 0
Training loss: 2.21254453452597
Validation loss: 2.5490263295480586

Epoch: 6| Step: 1
Training loss: 2.422066170315384
Validation loss: 2.5504711560446345

Epoch: 6| Step: 2
Training loss: 2.1633204761391482
Validation loss: 2.5734321191172116

Epoch: 6| Step: 3
Training loss: 2.2668234976572945
Validation loss: 2.5561614067065137

Epoch: 6| Step: 4
Training loss: 2.6428556331792223
Validation loss: 2.5645230533840193

Epoch: 6| Step: 5
Training loss: 2.9443514847226337
Validation loss: 2.5616691607047626

Epoch: 6| Step: 6
Training loss: 1.935021014333559
Validation loss: 2.5606854069351845

Epoch: 6| Step: 7
Training loss: 2.3724943294799057
Validation loss: 2.552242543969934

Epoch: 6| Step: 8
Training loss: 2.2234630762855554
Validation loss: 2.5588129701927405

Epoch: 6| Step: 9
Training loss: 1.715169819134137
Validation loss: 2.5613744015857334

Epoch: 6| Step: 10
Training loss: 3.124134706863002
Validation loss: 2.536083629798623

Epoch: 6| Step: 11
Training loss: 1.9597428166729483
Validation loss: 2.5619752703318652

Epoch: 6| Step: 12
Training loss: 2.196859120383465
Validation loss: 2.5414219696781464

Epoch: 6| Step: 13
Training loss: 2.542683434484944
Validation loss: 2.554008977066191

Epoch: 66| Step: 0
Training loss: 2.5640448588822693
Validation loss: 2.5316807886583215

Epoch: 6| Step: 1
Training loss: 2.3879079899530145
Validation loss: 2.537168686633306

Epoch: 6| Step: 2
Training loss: 2.4726245269427816
Validation loss: 2.5208103373295696

Epoch: 6| Step: 3
Training loss: 2.3748621649649033
Validation loss: 2.533866017161327

Epoch: 6| Step: 4
Training loss: 2.738190522915218
Validation loss: 2.5366781375799423

Epoch: 6| Step: 5
Training loss: 1.5233488399431458
Validation loss: 2.5519459642042865

Epoch: 6| Step: 6
Training loss: 2.34117208486626
Validation loss: 2.544925153939513

Epoch: 6| Step: 7
Training loss: 2.6690955623985855
Validation loss: 2.5532314339051165

Epoch: 6| Step: 8
Training loss: 2.9173264620047386
Validation loss: 2.524913265765554

Epoch: 6| Step: 9
Training loss: 1.9579844941917286
Validation loss: 2.5352518135166884

Epoch: 6| Step: 10
Training loss: 2.559798887220943
Validation loss: 2.5534870309693956

Epoch: 6| Step: 11
Training loss: 1.8487927931345933
Validation loss: 2.557044012712096

Epoch: 6| Step: 12
Training loss: 2.364327897266417
Validation loss: 2.533252065593164

Epoch: 6| Step: 13
Training loss: 1.9632715567286139
Validation loss: 2.581450396526016

Epoch: 67| Step: 0
Training loss: 2.018736101699086
Validation loss: 2.5580554269661815

Epoch: 6| Step: 1
Training loss: 2.8221696566728447
Validation loss: 2.561493140800268

Epoch: 6| Step: 2
Training loss: 2.4460475414082
Validation loss: 2.562319206434901

Epoch: 6| Step: 3
Training loss: 1.7004347385579384
Validation loss: 2.5674688499663407

Epoch: 6| Step: 4
Training loss: 2.8806203555506062
Validation loss: 2.5875815843998016

Epoch: 6| Step: 5
Training loss: 1.7605677733567997
Validation loss: 2.5300362113954593

Epoch: 6| Step: 6
Training loss: 2.034817306790804
Validation loss: 2.5626108564263124

Epoch: 6| Step: 7
Training loss: 2.208196551807283
Validation loss: 2.541741922442184

Epoch: 6| Step: 8
Training loss: 2.421598160210759
Validation loss: 2.5679988554870774

Epoch: 6| Step: 9
Training loss: 2.669128255370229
Validation loss: 2.552342511984287

Epoch: 6| Step: 10
Training loss: 1.8398874200712327
Validation loss: 2.5556386718732584

Epoch: 6| Step: 11
Training loss: 2.809834976645031
Validation loss: 2.547282118135277

Epoch: 6| Step: 12
Training loss: 2.344813194724018
Validation loss: 2.5749992919970284

Epoch: 6| Step: 13
Training loss: 2.7508144906442666
Validation loss: 2.5760993320681256

Epoch: 68| Step: 0
Training loss: 1.8712019281831602
Validation loss: 2.553658794505302

Epoch: 6| Step: 1
Training loss: 2.3208227142511095
Validation loss: 2.574255364658831

Epoch: 6| Step: 2
Training loss: 2.1058351555310564
Validation loss: 2.55170513127407

Epoch: 6| Step: 3
Training loss: 2.6114893587448145
Validation loss: 2.5457267278982196

Epoch: 6| Step: 4
Training loss: 2.4070434253041735
Validation loss: 2.5422439753365706

Epoch: 6| Step: 5
Training loss: 2.390628191378589
Validation loss: 2.532750622862056

Epoch: 6| Step: 6
Training loss: 2.6569488503640653
Validation loss: 2.5545711821382877

Epoch: 6| Step: 7
Training loss: 2.108425576625936
Validation loss: 2.5576566809884334

Epoch: 6| Step: 8
Training loss: 2.70986785453876
Validation loss: 2.554364089637618

Epoch: 6| Step: 9
Training loss: 2.070127543698739
Validation loss: 2.525235443972606

Epoch: 6| Step: 10
Training loss: 2.291913961303536
Validation loss: 2.5263382780143537

Epoch: 6| Step: 11
Training loss: 2.821739110705793
Validation loss: 2.5231580313768647

Epoch: 6| Step: 12
Training loss: 1.9085879138009418
Validation loss: 2.553196245286561

Epoch: 6| Step: 13
Training loss: 2.182292297897308
Validation loss: 2.520901313894969

Epoch: 69| Step: 0
Training loss: 2.6011008463034226
Validation loss: 2.532389984565552

Epoch: 6| Step: 1
Training loss: 2.008626216357482
Validation loss: 2.5148812847293085

Epoch: 6| Step: 2
Training loss: 2.3806044056332847
Validation loss: 2.5316677298260037

Epoch: 6| Step: 3
Training loss: 2.4286375076856968
Validation loss: 2.553273407487688

Epoch: 6| Step: 4
Training loss: 2.6160911882938542
Validation loss: 2.549248414447168

Epoch: 6| Step: 5
Training loss: 2.612616256244414
Validation loss: 2.526282030972441

Epoch: 6| Step: 6
Training loss: 2.4314229477117264
Validation loss: 2.5481279095853067

Epoch: 6| Step: 7
Training loss: 2.149320663648295
Validation loss: 2.5175459420470534

Epoch: 6| Step: 8
Training loss: 2.0823770489981723
Validation loss: 2.5315201540606873

Epoch: 6| Step: 9
Training loss: 1.5074513057100432
Validation loss: 2.5634738188229367

Epoch: 6| Step: 10
Training loss: 2.7441931017001964
Validation loss: 2.5503455077574486

Epoch: 6| Step: 11
Training loss: 2.490301201615593
Validation loss: 2.5531777714567645

Epoch: 6| Step: 12
Training loss: 2.305504708961405
Validation loss: 2.5448029247091646

Epoch: 6| Step: 13
Training loss: 2.157396094869055
Validation loss: 2.5343333252264535

Epoch: 70| Step: 0
Training loss: 2.3072359122837094
Validation loss: 2.5512088574947427

Epoch: 6| Step: 1
Training loss: 1.7201191390715056
Validation loss: 2.5778257408238274

Epoch: 6| Step: 2
Training loss: 2.2674551050689886
Validation loss: 2.580500862398369

Epoch: 6| Step: 3
Training loss: 1.5083906419239674
Validation loss: 2.5632451377432375

Epoch: 6| Step: 4
Training loss: 2.1249060890539573
Validation loss: 2.5740985137999974

Epoch: 6| Step: 5
Training loss: 3.4057990659354607
Validation loss: 2.576873922718658

Epoch: 6| Step: 6
Training loss: 2.3428620754582123
Validation loss: 2.6120116110422407

Epoch: 6| Step: 7
Training loss: 3.0242379481840262
Validation loss: 2.5847347416598176

Epoch: 6| Step: 8
Training loss: 2.2814847224466184
Validation loss: 2.580241550195297

Epoch: 6| Step: 9
Training loss: 1.9810647462704003
Validation loss: 2.5589633276760035

Epoch: 6| Step: 10
Training loss: 2.3464246620034506
Validation loss: 2.498533295494104

Epoch: 6| Step: 11
Training loss: 2.268456734863325
Validation loss: 2.547085681150596

Epoch: 6| Step: 12
Training loss: 2.455214467052447
Validation loss: 2.512625736677315

Epoch: 6| Step: 13
Training loss: 2.5046333292851988
Validation loss: 2.537009433249144

Epoch: 71| Step: 0
Training loss: 2.068947165506463
Validation loss: 2.5208368905622955

Epoch: 6| Step: 1
Training loss: 2.6617172523362203
Validation loss: 2.5379400344680536

Epoch: 6| Step: 2
Training loss: 2.4505870349358942
Validation loss: 2.532918984216039

Epoch: 6| Step: 3
Training loss: 2.9274820800545522
Validation loss: 2.5227140919140294

Epoch: 6| Step: 4
Training loss: 2.4881589850505326
Validation loss: 2.5220222874472653

Epoch: 6| Step: 5
Training loss: 2.5765267706823316
Validation loss: 2.523840290436431

Epoch: 6| Step: 6
Training loss: 2.054278314843543
Validation loss: 2.5173410126917837

Epoch: 6| Step: 7
Training loss: 1.8148634398398502
Validation loss: 2.535803321897299

Epoch: 6| Step: 8
Training loss: 1.8090969893317168
Validation loss: 2.5245290468100907

Epoch: 6| Step: 9
Training loss: 2.7621698725984127
Validation loss: 2.5188427203634163

Epoch: 6| Step: 10
Training loss: 2.0575842798151625
Validation loss: 2.5419746014356384

Epoch: 6| Step: 11
Training loss: 2.0040717400522676
Validation loss: 2.556891654143811

Epoch: 6| Step: 12
Training loss: 2.784440514407066
Validation loss: 2.522932822955119

Epoch: 6| Step: 13
Training loss: 1.7829277435954733
Validation loss: 2.5375144503954012

Epoch: 72| Step: 0
Training loss: 2.4211574352809064
Validation loss: 2.546489709835957

Epoch: 6| Step: 1
Training loss: 2.786899957093833
Validation loss: 2.5820482092842405

Epoch: 6| Step: 2
Training loss: 2.671931572923098
Validation loss: 2.561357274388242

Epoch: 6| Step: 3
Training loss: 2.7137267964204415
Validation loss: 2.5777887452602926

Epoch: 6| Step: 4
Training loss: 1.8458025870191488
Validation loss: 2.589223903550892

Epoch: 6| Step: 5
Training loss: 1.938921376271621
Validation loss: 2.624861978505095

Epoch: 6| Step: 6
Training loss: 2.1744882792816793
Validation loss: 2.6429096849415363

Epoch: 6| Step: 7
Training loss: 2.3123284353587725
Validation loss: 2.636256952229873

Epoch: 6| Step: 8
Training loss: 2.6051116652910014
Validation loss: 2.6417835109473637

Epoch: 6| Step: 9
Training loss: 2.088311947740725
Validation loss: 2.6355532031569653

Epoch: 6| Step: 10
Training loss: 1.9771417063171068
Validation loss: 2.601662336997959

Epoch: 6| Step: 11
Training loss: 1.4210128685665855
Validation loss: 2.5731806188525046

Epoch: 6| Step: 12
Training loss: 2.6295718389179394
Validation loss: 2.517778978999361

Epoch: 6| Step: 13
Training loss: 2.9901924354607057
Validation loss: 2.541321079544167

Epoch: 73| Step: 0
Training loss: 2.019449199138619
Validation loss: 2.5230967288622113

Epoch: 6| Step: 1
Training loss: 2.5107982129226603
Validation loss: 2.5107937974050696

Epoch: 6| Step: 2
Training loss: 1.9885882007662026
Validation loss: 2.5358650772242313

Epoch: 6| Step: 3
Training loss: 2.682630607646401
Validation loss: 2.5411201473146403

Epoch: 6| Step: 4
Training loss: 2.6125198874560773
Validation loss: 2.552965398412269

Epoch: 6| Step: 5
Training loss: 1.779509647850214
Validation loss: 2.535110982638679

Epoch: 6| Step: 6
Training loss: 2.4566308500386898
Validation loss: 2.535910675853388

Epoch: 6| Step: 7
Training loss: 2.804126906620857
Validation loss: 2.528579354844641

Epoch: 6| Step: 8
Training loss: 2.462953643839624
Validation loss: 2.5181610403277257

Epoch: 6| Step: 9
Training loss: 1.809190293340391
Validation loss: 2.504692220098403

Epoch: 6| Step: 10
Training loss: 2.1087894333350374
Validation loss: 2.5299369640312865

Epoch: 6| Step: 11
Training loss: 2.832959337421367
Validation loss: 2.526374595699058

Epoch: 6| Step: 12
Training loss: 1.9565533265729076
Validation loss: 2.5277480637779965

Epoch: 6| Step: 13
Training loss: 2.4308334542911862
Validation loss: 2.547227394360369

Epoch: 74| Step: 0
Training loss: 1.8110593134384065
Validation loss: 2.5447366549000208

Epoch: 6| Step: 1
Training loss: 1.7505870243244912
Validation loss: 2.5476282640136807

Epoch: 6| Step: 2
Training loss: 2.5752817833060004
Validation loss: 2.5527434812235965

Epoch: 6| Step: 3
Training loss: 1.7043732434757863
Validation loss: 2.563836245537651

Epoch: 6| Step: 4
Training loss: 1.9794183537583854
Validation loss: 2.5564177133995525

Epoch: 6| Step: 5
Training loss: 3.263053356027858
Validation loss: 2.5712653715706217

Epoch: 6| Step: 6
Training loss: 2.685623045794775
Validation loss: 2.5772035589728106

Epoch: 6| Step: 7
Training loss: 2.115583987944319
Validation loss: 2.5798778239604894

Epoch: 6| Step: 8
Training loss: 2.0718037542691183
Validation loss: 2.5770090635715386

Epoch: 6| Step: 9
Training loss: 2.686377534887591
Validation loss: 2.5927155051790582

Epoch: 6| Step: 10
Training loss: 2.582920308064122
Validation loss: 2.5848297789142545

Epoch: 6| Step: 11
Training loss: 2.6110810510334446
Validation loss: 2.554235575888847

Epoch: 6| Step: 12
Training loss: 1.8604319157105387
Validation loss: 2.544336719629463

Epoch: 6| Step: 13
Training loss: 2.2882995375517536
Validation loss: 2.53066741455591

Epoch: 75| Step: 0
Training loss: 2.705936623416877
Validation loss: 2.5531187072203214

Epoch: 6| Step: 1
Training loss: 2.4228582539710097
Validation loss: 2.5420945281644216

Epoch: 6| Step: 2
Training loss: 1.907371566268377
Validation loss: 2.5358232072453983

Epoch: 6| Step: 3
Training loss: 2.124890941738476
Validation loss: 2.547978027761033

Epoch: 6| Step: 4
Training loss: 1.78330139357346
Validation loss: 2.5231065405144477

Epoch: 6| Step: 5
Training loss: 2.109923453908639
Validation loss: 2.5379461406757606

Epoch: 6| Step: 6
Training loss: 2.872827787363804
Validation loss: 2.5081243588494044

Epoch: 6| Step: 7
Training loss: 2.2305125751632575
Validation loss: 2.544546752045427

Epoch: 6| Step: 8
Training loss: 1.8595986752650382
Validation loss: 2.542485626315107

Epoch: 6| Step: 9
Training loss: 2.275327964869523
Validation loss: 2.509568974846908

Epoch: 6| Step: 10
Training loss: 2.4728157269242144
Validation loss: 2.531741106405126

Epoch: 6| Step: 11
Training loss: 2.8713199448525426
Validation loss: 2.5349391066431224

Epoch: 6| Step: 12
Training loss: 2.5768377616240112
Validation loss: 2.521241026348434

Epoch: 6| Step: 13
Training loss: 1.9347823371989512
Validation loss: 2.5389817288585075

Epoch: 76| Step: 0
Training loss: 2.0241501190317432
Validation loss: 2.5736086348619907

Epoch: 6| Step: 1
Training loss: 2.044018565039485
Validation loss: 2.5808776186612

Epoch: 6| Step: 2
Training loss: 2.5692527928631805
Validation loss: 2.5862004433566

Epoch: 6| Step: 3
Training loss: 2.6409249220045146
Validation loss: 2.609857541236477

Epoch: 6| Step: 4
Training loss: 1.8794688058726954
Validation loss: 2.6009937386354895

Epoch: 6| Step: 5
Training loss: 2.7720682552020652
Validation loss: 2.6351649097519365

Epoch: 6| Step: 6
Training loss: 2.343079331126696
Validation loss: 2.63077030536148

Epoch: 6| Step: 7
Training loss: 3.0335582321410164
Validation loss: 2.6292523802878005

Epoch: 6| Step: 8
Training loss: 2.202275538529959
Validation loss: 2.579104104667315

Epoch: 6| Step: 9
Training loss: 1.9696056383695244
Validation loss: 2.582530548097208

Epoch: 6| Step: 10
Training loss: 1.7550743648065106
Validation loss: 2.542377377769208

Epoch: 6| Step: 11
Training loss: 2.2369404183622628
Validation loss: 2.556153851654084

Epoch: 6| Step: 12
Training loss: 2.461246725364045
Validation loss: 2.543163020638122

Epoch: 6| Step: 13
Training loss: 2.383602424138183
Validation loss: 2.5331888818548762

Epoch: 77| Step: 0
Training loss: 2.2513346422413973
Validation loss: 2.544258849090703

Epoch: 6| Step: 1
Training loss: 2.9690583721421677
Validation loss: 2.526925415446948

Epoch: 6| Step: 2
Training loss: 2.198435777827539
Validation loss: 2.52431405888215

Epoch: 6| Step: 3
Training loss: 1.4586045512538608
Validation loss: 2.536112945247719

Epoch: 6| Step: 4
Training loss: 1.7027021810660918
Validation loss: 2.5392107328525007

Epoch: 6| Step: 5
Training loss: 2.631689358452956
Validation loss: 2.5310154637442466

Epoch: 6| Step: 6
Training loss: 2.378971192925122
Validation loss: 2.5374172416433374

Epoch: 6| Step: 7
Training loss: 2.4878519547257656
Validation loss: 2.5406276788889017

Epoch: 6| Step: 8
Training loss: 2.7106826178698564
Validation loss: 2.5521312916719494

Epoch: 6| Step: 9
Training loss: 2.24590883240159
Validation loss: 2.53130825587923

Epoch: 6| Step: 10
Training loss: 2.289265490179675
Validation loss: 2.542522432271447

Epoch: 6| Step: 11
Training loss: 2.2115862538203563
Validation loss: 2.5478033312473447

Epoch: 6| Step: 12
Training loss: 2.508568385401977
Validation loss: 2.559035277186711

Epoch: 6| Step: 13
Training loss: 2.2098025586752397
Validation loss: 2.5688640992997236

Epoch: 78| Step: 0
Training loss: 2.6079697165573967
Validation loss: 2.571204543762014

Epoch: 6| Step: 1
Training loss: 1.9853647722291725
Validation loss: 2.576335956707221

Epoch: 6| Step: 2
Training loss: 2.4177786362559224
Validation loss: 2.5487060283779828

Epoch: 6| Step: 3
Training loss: 1.8230920616420248
Validation loss: 2.5269429961692595

Epoch: 6| Step: 4
Training loss: 2.519918817090456
Validation loss: 2.5492900795153504

Epoch: 6| Step: 5
Training loss: 1.563459635731686
Validation loss: 2.548768687133732

Epoch: 6| Step: 6
Training loss: 3.1054494029468094
Validation loss: 2.539710023915543

Epoch: 6| Step: 7
Training loss: 2.3872932704080467
Validation loss: 2.547271845817331

Epoch: 6| Step: 8
Training loss: 2.3423084148932514
Validation loss: 2.5581711592409784

Epoch: 6| Step: 9
Training loss: 2.6677794717471475
Validation loss: 2.5130337782346865

Epoch: 6| Step: 10
Training loss: 2.0255787246159302
Validation loss: 2.516515854449359

Epoch: 6| Step: 11
Training loss: 2.438255388635481
Validation loss: 2.516998776781232

Epoch: 6| Step: 12
Training loss: 1.8593628185738713
Validation loss: 2.5270992988235146

Epoch: 6| Step: 13
Training loss: 2.3237712525477803
Validation loss: 2.5336003321772798

Epoch: 79| Step: 0
Training loss: 2.2967025795921474
Validation loss: 2.5638528989628764

Epoch: 6| Step: 1
Training loss: 2.343057453833369
Validation loss: 2.565988646990824

Epoch: 6| Step: 2
Training loss: 2.1268573946116276
Validation loss: 2.5873160169369758

Epoch: 6| Step: 3
Training loss: 2.7983355411462516
Validation loss: 2.6194223000714203

Epoch: 6| Step: 4
Training loss: 2.576485777407211
Validation loss: 2.624636821751875

Epoch: 6| Step: 5
Training loss: 2.8497141242956214
Validation loss: 2.611837066912892

Epoch: 6| Step: 6
Training loss: 2.5257317946147086
Validation loss: 2.633136476530497

Epoch: 6| Step: 7
Training loss: 2.384853002148751
Validation loss: 2.604627237917665

Epoch: 6| Step: 8
Training loss: 1.9386757390392872
Validation loss: 2.5866872693581717

Epoch: 6| Step: 9
Training loss: 1.5837554201727342
Validation loss: 2.56694098736475

Epoch: 6| Step: 10
Training loss: 1.4912407552939377
Validation loss: 2.5853670687737718

Epoch: 6| Step: 11
Training loss: 2.77892317575057
Validation loss: 2.5636904207669273

Epoch: 6| Step: 12
Training loss: 2.0040321236203877
Validation loss: 2.560121611026244

Epoch: 6| Step: 13
Training loss: 2.305365200942531
Validation loss: 2.52174355228533

Epoch: 80| Step: 0
Training loss: 2.0518451946230627
Validation loss: 2.5302525505598576

Epoch: 6| Step: 1
Training loss: 3.1028467397407535
Validation loss: 2.5386117701398523

Epoch: 6| Step: 2
Training loss: 1.9010897974340177
Validation loss: 2.537112366457011

Epoch: 6| Step: 3
Training loss: 2.577057588572544
Validation loss: 2.53877040650108

Epoch: 6| Step: 4
Training loss: 2.6149549384820663
Validation loss: 2.533234246307161

Epoch: 6| Step: 5
Training loss: 1.978196565559853
Validation loss: 2.5608042711999914

Epoch: 6| Step: 6
Training loss: 2.322260697009069
Validation loss: 2.5252481426769338

Epoch: 6| Step: 7
Training loss: 2.346212288945176
Validation loss: 2.531670649234267

Epoch: 6| Step: 8
Training loss: 2.4758942963156403
Validation loss: 2.5420446479612018

Epoch: 6| Step: 9
Training loss: 2.096748254984726
Validation loss: 2.5394764098225697

Epoch: 6| Step: 10
Training loss: 1.9977842812802986
Validation loss: 2.525759169260505

Epoch: 6| Step: 11
Training loss: 2.0819634575032544
Validation loss: 2.5334722395091775

Epoch: 6| Step: 12
Training loss: 1.9776189340544574
Validation loss: 2.5226427525434594

Epoch: 6| Step: 13
Training loss: 2.321540789983429
Validation loss: 2.5457684662125533

Epoch: 81| Step: 0
Training loss: 2.345720708750966
Validation loss: 2.566095187197961

Epoch: 6| Step: 1
Training loss: 2.227924024337777
Validation loss: 2.540762933456622

Epoch: 6| Step: 2
Training loss: 1.6997646814052556
Validation loss: 2.592706263474808

Epoch: 6| Step: 3
Training loss: 2.502804232462358
Validation loss: 2.6343174980527837

Epoch: 6| Step: 4
Training loss: 2.953710265923517
Validation loss: 2.635547338168775

Epoch: 6| Step: 5
Training loss: 1.9276304825727753
Validation loss: 2.6179339582726326

Epoch: 6| Step: 6
Training loss: 2.617214920128049
Validation loss: 2.6368043636033223

Epoch: 6| Step: 7
Training loss: 3.122108953223109
Validation loss: 2.6276396240826236

Epoch: 6| Step: 8
Training loss: 2.1039687211500167
Validation loss: 2.602028042338445

Epoch: 6| Step: 9
Training loss: 1.9982670190077578
Validation loss: 2.6197157609281234

Epoch: 6| Step: 10
Training loss: 1.8724797158867892
Validation loss: 2.575525302452373

Epoch: 6| Step: 11
Training loss: 2.347307277645702
Validation loss: 2.5526187620515612

Epoch: 6| Step: 12
Training loss: 1.895879835739201
Validation loss: 2.540088074751606

Epoch: 6| Step: 13
Training loss: 2.2465366623427814
Validation loss: 2.5324308992368554

Epoch: 82| Step: 0
Training loss: 2.3548633816042295
Validation loss: 2.5515654109728767

Epoch: 6| Step: 1
Training loss: 2.082111292690702
Validation loss: 2.540024028549279

Epoch: 6| Step: 2
Training loss: 1.8824230756912155
Validation loss: 2.5456399633971674

Epoch: 6| Step: 3
Training loss: 2.2867283296009733
Validation loss: 2.512036055816364

Epoch: 6| Step: 4
Training loss: 2.309441683455598
Validation loss: 2.5475439273639537

Epoch: 6| Step: 5
Training loss: 2.172965016349843
Validation loss: 2.531468338831354

Epoch: 6| Step: 6
Training loss: 2.764395920227776
Validation loss: 2.522852842708573

Epoch: 6| Step: 7
Training loss: 2.565685339344746
Validation loss: 2.566364738945383

Epoch: 6| Step: 8
Training loss: 1.4920758909657528
Validation loss: 2.540067831695616

Epoch: 6| Step: 9
Training loss: 2.183558373343796
Validation loss: 2.5510702159359386

Epoch: 6| Step: 10
Training loss: 2.620389795499686
Validation loss: 2.5641961415650307

Epoch: 6| Step: 11
Training loss: 3.257082630977398
Validation loss: 2.5712423449525823

Epoch: 6| Step: 12
Training loss: 2.0482579575221913
Validation loss: 2.545069266964868

Epoch: 6| Step: 13
Training loss: 1.6496757448806965
Validation loss: 2.5735482561666374

Epoch: 83| Step: 0
Training loss: 2.4143599539892056
Validation loss: 2.550223257850455

Epoch: 6| Step: 1
Training loss: 2.823299105217939
Validation loss: 2.572643888482234

Epoch: 6| Step: 2
Training loss: 1.7991267152172599
Validation loss: 2.561895810982911

Epoch: 6| Step: 3
Training loss: 2.398495949893448
Validation loss: 2.5520836239769182

Epoch: 6| Step: 4
Training loss: 2.2874295916952048
Validation loss: 2.5389626116544552

Epoch: 6| Step: 5
Training loss: 1.8251572345253864
Validation loss: 2.56232344786764

Epoch: 6| Step: 6
Training loss: 2.2321048755139103
Validation loss: 2.550395747560504

Epoch: 6| Step: 7
Training loss: 2.3600232579006573
Validation loss: 2.5605449351582963

Epoch: 6| Step: 8
Training loss: 2.3238750812751494
Validation loss: 2.5579955355356967

Epoch: 6| Step: 9
Training loss: 1.8775306154642633
Validation loss: 2.5314502401387116

Epoch: 6| Step: 10
Training loss: 2.5007618696897236
Validation loss: 2.554208965376504

Epoch: 6| Step: 11
Training loss: 1.8839904772402405
Validation loss: 2.5591717016314863

Epoch: 6| Step: 12
Training loss: 1.8177824979879895
Validation loss: 2.5575488492738545

Epoch: 6| Step: 13
Training loss: 2.949903557704194
Validation loss: 2.5386567246371956

Epoch: 84| Step: 0
Training loss: 2.7710734002845188
Validation loss: 2.5457587887286572

Epoch: 6| Step: 1
Training loss: 2.2024899913547444
Validation loss: 2.518939044758548

Epoch: 6| Step: 2
Training loss: 1.9389622000698108
Validation loss: 2.523550001536007

Epoch: 6| Step: 3
Training loss: 2.0517612985602227
Validation loss: 2.542678324204426

Epoch: 6| Step: 4
Training loss: 2.160242889487951
Validation loss: 2.5583298331080377

Epoch: 6| Step: 5
Training loss: 2.336751432454911
Validation loss: 2.5527814156892976

Epoch: 6| Step: 6
Training loss: 2.3717826332733507
Validation loss: 2.549792516283148

Epoch: 6| Step: 7
Training loss: 2.7767506756234335
Validation loss: 2.584606077602622

Epoch: 6| Step: 8
Training loss: 1.8638249209905278
Validation loss: 2.553930825758681

Epoch: 6| Step: 9
Training loss: 2.2292633273359566
Validation loss: 2.58523568486418

Epoch: 6| Step: 10
Training loss: 3.120505190321315
Validation loss: 2.5885697228326734

Epoch: 6| Step: 11
Training loss: 1.663683064502169
Validation loss: 2.568482308775665

Epoch: 6| Step: 12
Training loss: 2.083983574163682
Validation loss: 2.575913808456763

Epoch: 6| Step: 13
Training loss: 2.0613965637400455
Validation loss: 2.588904055449557

Epoch: 85| Step: 0
Training loss: 2.3559872387150227
Validation loss: 2.5163267906108286

Epoch: 6| Step: 1
Training loss: 2.5091570045726894
Validation loss: 2.5102228166334024

Epoch: 6| Step: 2
Training loss: 1.9869255435319038
Validation loss: 2.516563366881475

Epoch: 6| Step: 3
Training loss: 2.051745146431335
Validation loss: 2.542414435363162

Epoch: 6| Step: 4
Training loss: 2.3992260559229166
Validation loss: 2.525092252613492

Epoch: 6| Step: 5
Training loss: 1.9642055073996387
Validation loss: 2.5465581029783086

Epoch: 6| Step: 6
Training loss: 2.2701805879794175
Validation loss: 2.5074543840842742

Epoch: 6| Step: 7
Training loss: 1.823431657979542
Validation loss: 2.5337457166452686

Epoch: 6| Step: 8
Training loss: 2.438082600928733
Validation loss: 2.5569319669534303

Epoch: 6| Step: 9
Training loss: 2.4455872402693113
Validation loss: 2.563903284795905

Epoch: 6| Step: 10
Training loss: 2.404206138652634
Validation loss: 2.519112643378638

Epoch: 6| Step: 11
Training loss: 2.1602092274245104
Validation loss: 2.5228307602796955

Epoch: 6| Step: 12
Training loss: 2.9074215732273454
Validation loss: 2.546958017068885

Epoch: 6| Step: 13
Training loss: 1.679207524764097
Validation loss: 2.549497740031391

Epoch: 86| Step: 0
Training loss: 1.782921124291009
Validation loss: 2.53285659227659

Epoch: 6| Step: 1
Training loss: 2.4678457028398073
Validation loss: 2.547829696738852

Epoch: 6| Step: 2
Training loss: 2.107224562125406
Validation loss: 2.576805794485352

Epoch: 6| Step: 3
Training loss: 2.2409238012211925
Validation loss: 2.5981093697455906

Epoch: 6| Step: 4
Training loss: 2.500801530140258
Validation loss: 2.596479351019137

Epoch: 6| Step: 5
Training loss: 2.248150701304329
Validation loss: 2.5724838345794847

Epoch: 6| Step: 6
Training loss: 2.160546265862213
Validation loss: 2.593032247362186

Epoch: 6| Step: 7
Training loss: 2.963748774920419
Validation loss: 2.5952257913936934

Epoch: 6| Step: 8
Training loss: 1.7871106423962377
Validation loss: 2.5871956675462338

Epoch: 6| Step: 9
Training loss: 2.146834895885203
Validation loss: 2.565901398416207

Epoch: 6| Step: 10
Training loss: 1.445479759641991
Validation loss: 2.5746697902367464

Epoch: 6| Step: 11
Training loss: 2.650392064295851
Validation loss: 2.5720539705928243

Epoch: 6| Step: 12
Training loss: 2.5310608593011605
Validation loss: 2.5537314536326337

Epoch: 6| Step: 13
Training loss: 2.161155979809737
Validation loss: 2.5333239924317197

Epoch: 87| Step: 0
Training loss: 1.3852323490760743
Validation loss: 2.533079098714555

Epoch: 6| Step: 1
Training loss: 2.4647624974226567
Validation loss: 2.5519371198433234

Epoch: 6| Step: 2
Training loss: 2.3844339825895537
Validation loss: 2.54721081163889

Epoch: 6| Step: 3
Training loss: 2.525927375226658
Validation loss: 2.513829935435204

Epoch: 6| Step: 4
Training loss: 2.132385211104597
Validation loss: 2.509805523150765

Epoch: 6| Step: 5
Training loss: 1.7905114981743637
Validation loss: 2.5280119981883415

Epoch: 6| Step: 6
Training loss: 2.2483885610634555
Validation loss: 2.5440863728235876

Epoch: 6| Step: 7
Training loss: 3.202680454574919
Validation loss: 2.5370154790459964

Epoch: 6| Step: 8
Training loss: 1.6987730647550041
Validation loss: 2.564225228597256

Epoch: 6| Step: 9
Training loss: 2.1781059187678595
Validation loss: 2.550410494457002

Epoch: 6| Step: 10
Training loss: 1.9462101715069846
Validation loss: 2.544420678454836

Epoch: 6| Step: 11
Training loss: 2.6223632648848594
Validation loss: 2.5443375473620597

Epoch: 6| Step: 12
Training loss: 2.189293044786309
Validation loss: 2.5523240786813055

Epoch: 6| Step: 13
Training loss: 2.407604381322669
Validation loss: 2.584373269931963

Epoch: 88| Step: 0
Training loss: 2.1498888696737377
Validation loss: 2.5503082615769186

Epoch: 6| Step: 1
Training loss: 1.8594723203178036
Validation loss: 2.5735326382272192

Epoch: 6| Step: 2
Training loss: 2.1183879306619384
Validation loss: 2.5300901526445516

Epoch: 6| Step: 3
Training loss: 1.9900702501481957
Validation loss: 2.527887921559452

Epoch: 6| Step: 4
Training loss: 2.0117802582754085
Validation loss: 2.5688235406179314

Epoch: 6| Step: 5
Training loss: 2.3175555461000354
Validation loss: 2.572256031757097

Epoch: 6| Step: 6
Training loss: 2.3252674974358
Validation loss: 2.5809128917551405

Epoch: 6| Step: 7
Training loss: 2.661377569019543
Validation loss: 2.557991714118142

Epoch: 6| Step: 8
Training loss: 1.9918322078056987
Validation loss: 2.538460324601311

Epoch: 6| Step: 9
Training loss: 2.321138382684463
Validation loss: 2.5222036929810665

Epoch: 6| Step: 10
Training loss: 2.493481147824885
Validation loss: 2.5325659168849506

Epoch: 6| Step: 11
Training loss: 1.9404412371479376
Validation loss: 2.520584635381017

Epoch: 6| Step: 12
Training loss: 2.963648217045088
Validation loss: 2.55278096427714

Epoch: 6| Step: 13
Training loss: 1.992051003959818
Validation loss: 2.5457554016006028

Epoch: 89| Step: 0
Training loss: 2.7416197795008594
Validation loss: 2.523611151327206

Epoch: 6| Step: 1
Training loss: 2.305333554509279
Validation loss: 2.54246508976648

Epoch: 6| Step: 2
Training loss: 1.6241413929230215
Validation loss: 2.5612977549350493

Epoch: 6| Step: 3
Training loss: 2.599267995933674
Validation loss: 2.569214699471769

Epoch: 6| Step: 4
Training loss: 2.372963483938587
Validation loss: 2.5532241347578513

Epoch: 6| Step: 5
Training loss: 2.4386730794737135
Validation loss: 2.554207899705665

Epoch: 6| Step: 6
Training loss: 2.0003376914084257
Validation loss: 2.5496617304762097

Epoch: 6| Step: 7
Training loss: 2.756099352536524
Validation loss: 2.536600548884658

Epoch: 6| Step: 8
Training loss: 1.4934390746014745
Validation loss: 2.5740681489875756

Epoch: 6| Step: 9
Training loss: 2.610664094938597
Validation loss: 2.557922873254647

Epoch: 6| Step: 10
Training loss: 1.9683828465659081
Validation loss: 2.529335436042223

Epoch: 6| Step: 11
Training loss: 2.5266026349203345
Validation loss: 2.5563565400670627

Epoch: 6| Step: 12
Training loss: 1.8267908689407266
Validation loss: 2.5432129882781234

Epoch: 6| Step: 13
Training loss: 1.8898455061161228
Validation loss: 2.539815116258602

Epoch: 90| Step: 0
Training loss: 2.249079728012176
Validation loss: 2.5447112177029627

Epoch: 6| Step: 1
Training loss: 2.129938110025515
Validation loss: 2.554951964211102

Epoch: 6| Step: 2
Training loss: 2.3368657031796385
Validation loss: 2.545303359072831

Epoch: 6| Step: 3
Training loss: 2.1679617117002867
Validation loss: 2.5331352654208383

Epoch: 6| Step: 4
Training loss: 2.1209105242138793
Validation loss: 2.5389482677879234

Epoch: 6| Step: 5
Training loss: 2.6675462067024402
Validation loss: 2.5786169565323056

Epoch: 6| Step: 6
Training loss: 2.468589004868424
Validation loss: 2.5680921679066278

Epoch: 6| Step: 7
Training loss: 1.4901732585968677
Validation loss: 2.5665995516816453

Epoch: 6| Step: 8
Training loss: 1.7542712675003878
Validation loss: 2.592942215478287

Epoch: 6| Step: 9
Training loss: 1.8194253093823056
Validation loss: 2.598362624419471

Epoch: 6| Step: 10
Training loss: 3.104463925732479
Validation loss: 2.57627972157063

Epoch: 6| Step: 11
Training loss: 1.9270817387204833
Validation loss: 2.543429550244089

Epoch: 6| Step: 12
Training loss: 1.6429998738619105
Validation loss: 2.5812787889502333

Epoch: 6| Step: 13
Training loss: 2.685421694525685
Validation loss: 2.564834732905857

Epoch: 91| Step: 0
Training loss: 2.1101052609624262
Validation loss: 2.594439441711028

Epoch: 6| Step: 1
Training loss: 2.0769427385513524
Validation loss: 2.5662706437033886

Epoch: 6| Step: 2
Training loss: 2.0342877487950077
Validation loss: 2.5541778740525496

Epoch: 6| Step: 3
Training loss: 2.378754008014648
Validation loss: 2.5573504195809345

Epoch: 6| Step: 4
Training loss: 2.358677034528138
Validation loss: 2.552923684371767

Epoch: 6| Step: 5
Training loss: 1.744746223730944
Validation loss: 2.5525657716821373

Epoch: 6| Step: 6
Training loss: 2.06024578480011
Validation loss: 2.5385290279916473

Epoch: 6| Step: 7
Training loss: 2.353412496119643
Validation loss: 2.5574496363518873

Epoch: 6| Step: 8
Training loss: 2.2620100976801223
Validation loss: 2.554598302188095

Epoch: 6| Step: 9
Training loss: 2.592920837235523
Validation loss: 2.5542361126078164

Epoch: 6| Step: 10
Training loss: 2.55449673468276
Validation loss: 2.5450258465536773

Epoch: 6| Step: 11
Training loss: 2.2070347068557
Validation loss: 2.548793998090299

Epoch: 6| Step: 12
Training loss: 2.3006645652314086
Validation loss: 2.5334336551662022

Epoch: 6| Step: 13
Training loss: 2.141794372590527
Validation loss: 2.5218487315521396

Epoch: 92| Step: 0
Training loss: 2.010389403584945
Validation loss: 2.5369870511452417

Epoch: 6| Step: 1
Training loss: 2.34165209655935
Validation loss: 2.541728915301712

Epoch: 6| Step: 2
Training loss: 2.175378512189354
Validation loss: 2.563762105872583

Epoch: 6| Step: 3
Training loss: 2.096007197950103
Validation loss: 2.569863385479405

Epoch: 6| Step: 4
Training loss: 2.5815499415482956
Validation loss: 2.5732891312526998

Epoch: 6| Step: 5
Training loss: 2.1563386760666514
Validation loss: 2.6164308583455997

Epoch: 6| Step: 6
Training loss: 2.3016846830899955
Validation loss: 2.5710063488660673

Epoch: 6| Step: 7
Training loss: 2.6287825443359276
Validation loss: 2.578587238219021

Epoch: 6| Step: 8
Training loss: 1.5089981872416252
Validation loss: 2.6142250109326954

Epoch: 6| Step: 9
Training loss: 2.0092515352800273
Validation loss: 2.5676272200848786

Epoch: 6| Step: 10
Training loss: 2.7156551767654555
Validation loss: 2.5635192208752233

Epoch: 6| Step: 11
Training loss: 2.2336851535600033
Validation loss: 2.5515413033079377

Epoch: 6| Step: 12
Training loss: 2.0200670369043814
Validation loss: 2.543117223918205

Epoch: 6| Step: 13
Training loss: 2.259826184568284
Validation loss: 2.538709653154675

Epoch: 93| Step: 0
Training loss: 2.1563371281366615
Validation loss: 2.5482419953860647

Epoch: 6| Step: 1
Training loss: 2.234072364639144
Validation loss: 2.5389600371202756

Epoch: 6| Step: 2
Training loss: 2.9814393949028237
Validation loss: 2.539328192478917

Epoch: 6| Step: 3
Training loss: 2.3885780496955307
Validation loss: 2.513244300090818

Epoch: 6| Step: 4
Training loss: 2.042453445595051
Validation loss: 2.5338399690006166

Epoch: 6| Step: 5
Training loss: 1.7536886033440426
Validation loss: 2.555878807669133

Epoch: 6| Step: 6
Training loss: 2.0034556337665546
Validation loss: 2.542468653197771

Epoch: 6| Step: 7
Training loss: 2.2472485567343523
Validation loss: 2.556368073812052

Epoch: 6| Step: 8
Training loss: 2.556771084900781
Validation loss: 2.568739559526721

Epoch: 6| Step: 9
Training loss: 2.219034096165782
Validation loss: 2.558575082181819

Epoch: 6| Step: 10
Training loss: 1.81921956401159
Validation loss: 2.5613927775140204

Epoch: 6| Step: 11
Training loss: 2.3193731493725354
Validation loss: 2.5680997342571716

Epoch: 6| Step: 12
Training loss: 1.848075319150685
Validation loss: 2.572034326734619

Epoch: 6| Step: 13
Training loss: 2.256286739145352
Validation loss: 2.5629198924353234

Epoch: 94| Step: 0
Training loss: 1.841408098921497
Validation loss: 2.569349640022295

Epoch: 6| Step: 1
Training loss: 1.8769528709514656
Validation loss: 2.5564976616529234

Epoch: 6| Step: 2
Training loss: 2.0821462173640444
Validation loss: 2.5388487427549635

Epoch: 6| Step: 3
Training loss: 2.475662693737344
Validation loss: 2.5579168069676532

Epoch: 6| Step: 4
Training loss: 2.6845468663717873
Validation loss: 2.551771033245865

Epoch: 6| Step: 5
Training loss: 2.1102227661993034
Validation loss: 2.532830408226366

Epoch: 6| Step: 6
Training loss: 1.837809545692647
Validation loss: 2.5311247084264203

Epoch: 6| Step: 7
Training loss: 2.6098062307404586
Validation loss: 2.499665412765509

Epoch: 6| Step: 8
Training loss: 2.2157234718811853
Validation loss: 2.5368869636042404

Epoch: 6| Step: 9
Training loss: 1.918052407361184
Validation loss: 2.546114950529755

Epoch: 6| Step: 10
Training loss: 2.848148507478902
Validation loss: 2.5324968006732664

Epoch: 6| Step: 11
Training loss: 1.9279214290936295
Validation loss: 2.5170367053071847

Epoch: 6| Step: 12
Training loss: 2.3933644275540353
Validation loss: 2.544785108231223

Epoch: 6| Step: 13
Training loss: 1.9941063708913738
Validation loss: 2.5580888322761424

Epoch: 95| Step: 0
Training loss: 1.85429412603727
Validation loss: 2.5836012967913335

Epoch: 6| Step: 1
Training loss: 2.111860379329037
Validation loss: 2.597903484157062

Epoch: 6| Step: 2
Training loss: 2.5396592597991936
Validation loss: 2.6144498408511763

Epoch: 6| Step: 3
Training loss: 2.1355463748398904
Validation loss: 2.6490979566740385

Epoch: 6| Step: 4
Training loss: 2.505423480422753
Validation loss: 2.665166452731266

Epoch: 6| Step: 5
Training loss: 1.7154224435991452
Validation loss: 2.6869326443584347

Epoch: 6| Step: 6
Training loss: 2.0458838705850746
Validation loss: 2.70989872124996

Epoch: 6| Step: 7
Training loss: 2.3397599907405073
Validation loss: 2.693732516356668

Epoch: 6| Step: 8
Training loss: 2.05693366561402
Validation loss: 2.647451301537471

Epoch: 6| Step: 9
Training loss: 3.335497646234317
Validation loss: 2.6240750908603503

Epoch: 6| Step: 10
Training loss: 2.1030098281318703
Validation loss: 2.566020354004628

Epoch: 6| Step: 11
Training loss: 2.0595826989240504
Validation loss: 2.5448730963723536

Epoch: 6| Step: 12
Training loss: 1.6211676523299678
Validation loss: 2.530143032642136

Epoch: 6| Step: 13
Training loss: 2.1482276397858975
Validation loss: 2.554919108897589

Epoch: 96| Step: 0
Training loss: 2.3400714744346263
Validation loss: 2.551445057259399

Epoch: 6| Step: 1
Training loss: 1.7581771811380837
Validation loss: 2.5248724889505594

Epoch: 6| Step: 2
Training loss: 2.948116192395121
Validation loss: 2.5376109037921477

Epoch: 6| Step: 3
Training loss: 2.0769500852931726
Validation loss: 2.5402433495830095

Epoch: 6| Step: 4
Training loss: 2.2011172838727338
Validation loss: 2.5225322032494777

Epoch: 6| Step: 5
Training loss: 2.2597090731363725
Validation loss: 2.545051358672161

Epoch: 6| Step: 6
Training loss: 1.9363349980610758
Validation loss: 2.5366489304846924

Epoch: 6| Step: 7
Training loss: 1.8107908675013844
Validation loss: 2.5487923377241963

Epoch: 6| Step: 8
Training loss: 2.243743462938227
Validation loss: 2.552230976012039

Epoch: 6| Step: 9
Training loss: 1.6331001283932074
Validation loss: 2.5540964918676248

Epoch: 6| Step: 10
Training loss: 2.262825123731036
Validation loss: 2.611298314839548

Epoch: 6| Step: 11
Training loss: 2.9254412587210736
Validation loss: 2.6143703880576403

Epoch: 6| Step: 12
Training loss: 2.1959448070086975
Validation loss: 2.6371580610347216

Epoch: 6| Step: 13
Training loss: 2.4878427547306172
Validation loss: 2.6442532038681725

Epoch: 97| Step: 0
Training loss: 2.3422946734908012
Validation loss: 2.6301372304439568

Epoch: 6| Step: 1
Training loss: 2.558847941810267
Validation loss: 2.6121421501956155

Epoch: 6| Step: 2
Training loss: 1.6634976140135018
Validation loss: 2.5957936964075525

Epoch: 6| Step: 3
Training loss: 2.0869830650735546
Validation loss: 2.5792957614601835

Epoch: 6| Step: 4
Training loss: 2.4645837323233333
Validation loss: 2.5897447846204833

Epoch: 6| Step: 5
Training loss: 1.8875280820260694
Validation loss: 2.555949343757941

Epoch: 6| Step: 6
Training loss: 2.180252603542233
Validation loss: 2.524819136584838

Epoch: 6| Step: 7
Training loss: 2.209457926832809
Validation loss: 2.5442716402633674

Epoch: 6| Step: 8
Training loss: 2.26816106461176
Validation loss: 2.5819346784498522

Epoch: 6| Step: 9
Training loss: 1.638595051834493
Validation loss: 2.548032057034494

Epoch: 6| Step: 10
Training loss: 1.7458259667337481
Validation loss: 2.5437659416980134

Epoch: 6| Step: 11
Training loss: 2.907820738586529
Validation loss: 2.528211025225183

Epoch: 6| Step: 12
Training loss: 2.0274292444566533
Validation loss: 2.5536168428181467

Epoch: 6| Step: 13
Training loss: 2.1847065118751727
Validation loss: 2.546867261379475

Epoch: 98| Step: 0
Training loss: 2.9145855881575686
Validation loss: 2.5474895991698614

Epoch: 6| Step: 1
Training loss: 1.7744086879046286
Validation loss: 2.527802352529641

Epoch: 6| Step: 2
Training loss: 2.223550036887078
Validation loss: 2.538030342216274

Epoch: 6| Step: 3
Training loss: 1.9201206791224865
Validation loss: 2.5657010437711367

Epoch: 6| Step: 4
Training loss: 1.9575817072588522
Validation loss: 2.563405334451907

Epoch: 6| Step: 5
Training loss: 1.7382309124119562
Validation loss: 2.5771174456086965

Epoch: 6| Step: 6
Training loss: 2.442317115238711
Validation loss: 2.5834256176205965

Epoch: 6| Step: 7
Training loss: 2.6289821574119667
Validation loss: 2.5711017081115206

Epoch: 6| Step: 8
Training loss: 2.359659038903017
Validation loss: 2.5599227753803135

Epoch: 6| Step: 9
Training loss: 2.413226232769092
Validation loss: 2.596989045467782

Epoch: 6| Step: 10
Training loss: 1.595789035086008
Validation loss: 2.58877414040674

Epoch: 6| Step: 11
Training loss: 2.263714530746995
Validation loss: 2.559247953920328

Epoch: 6| Step: 12
Training loss: 2.1677134870485935
Validation loss: 2.540830737890726

Epoch: 6| Step: 13
Training loss: 2.115807678359595
Validation loss: 2.5620010169278107

Epoch: 99| Step: 0
Training loss: 2.3333517709639384
Validation loss: 2.547482876306746

Epoch: 6| Step: 1
Training loss: 2.7150719855444407
Validation loss: 2.528575504685576

Epoch: 6| Step: 2
Training loss: 2.3815650551300096
Validation loss: 2.554096507425545

Epoch: 6| Step: 3
Training loss: 1.5889197061272577
Validation loss: 2.52712923738363

Epoch: 6| Step: 4
Training loss: 2.2850410628020246
Validation loss: 2.562259383651251

Epoch: 6| Step: 5
Training loss: 2.2574732964542683
Validation loss: 2.54518879807824

Epoch: 6| Step: 6
Training loss: 1.9701384840376097
Validation loss: 2.536525158847166

Epoch: 6| Step: 7
Training loss: 1.6452846658784923
Validation loss: 2.5228836664319587

Epoch: 6| Step: 8
Training loss: 1.8989956510151524
Validation loss: 2.5510631130984223

Epoch: 6| Step: 9
Training loss: 2.495422941760406
Validation loss: 2.564618986818301

Epoch: 6| Step: 10
Training loss: 2.0454152267222008
Validation loss: 2.549134849128632

Epoch: 6| Step: 11
Training loss: 2.4687548287259937
Validation loss: 2.5737768477944303

Epoch: 6| Step: 12
Training loss: 2.2120556918647263
Validation loss: 2.570451912389148

Epoch: 6| Step: 13
Training loss: 1.994001811517411
Validation loss: 2.6253442992618603

Epoch: 100| Step: 0
Training loss: 2.199356427126463
Validation loss: 2.6082468163723065

Epoch: 6| Step: 1
Training loss: 2.7683137227036916
Validation loss: 2.6837382196725446

Epoch: 6| Step: 2
Training loss: 2.2960246062405685
Validation loss: 2.6468431443088094

Epoch: 6| Step: 3
Training loss: 2.7898208057461016
Validation loss: 2.6639648151107536

Epoch: 6| Step: 4
Training loss: 1.9549099509727688
Validation loss: 2.6274082550621083

Epoch: 6| Step: 5
Training loss: 1.962371787967358
Validation loss: 2.5991412514408894

Epoch: 6| Step: 6
Training loss: 2.075034575576428
Validation loss: 2.5784859452785827

Epoch: 6| Step: 7
Training loss: 2.5257990035599187
Validation loss: 2.561785272616956

Epoch: 6| Step: 8
Training loss: 1.5889886529468125
Validation loss: 2.542273891851261

Epoch: 6| Step: 9
Training loss: 2.116969924388772
Validation loss: 2.5559462966142594

Epoch: 6| Step: 10
Training loss: 1.8222769423089415
Validation loss: 2.54384510821625

Epoch: 6| Step: 11
Training loss: 2.158322651172651
Validation loss: 2.532762726928717

Epoch: 6| Step: 12
Training loss: 2.035159413047866
Validation loss: 2.536692024343154

Epoch: 6| Step: 13
Training loss: 2.272165893233703
Validation loss: 2.5440606323580206

Epoch: 101| Step: 0
Training loss: 1.757041117639171
Validation loss: 2.5367256874840973

Epoch: 6| Step: 1
Training loss: 2.325295386469938
Validation loss: 2.543469435881954

Epoch: 6| Step: 2
Training loss: 1.8295940789040588
Validation loss: 2.565974028338214

Epoch: 6| Step: 3
Training loss: 2.3805784665279637
Validation loss: 2.5270103144232023

Epoch: 6| Step: 4
Training loss: 2.6832868686546782
Validation loss: 2.5266682244306944

Epoch: 6| Step: 5
Training loss: 2.310546255877453
Validation loss: 2.530087490554272

Epoch: 6| Step: 6
Training loss: 2.233775238423933
Validation loss: 2.556627895711125

Epoch: 6| Step: 7
Training loss: 2.4960102670287223
Validation loss: 2.556557424972577

Epoch: 6| Step: 8
Training loss: 2.240369105922934
Validation loss: 2.572469530879751

Epoch: 6| Step: 9
Training loss: 2.2956480524955287
Validation loss: 2.638736162171974

Epoch: 6| Step: 10
Training loss: 2.747290924142363
Validation loss: 2.6103722043118576

Epoch: 6| Step: 11
Training loss: 1.5178512268592241
Validation loss: 2.612382339796999

Epoch: 6| Step: 12
Training loss: 1.48040344577379
Validation loss: 2.6100129586844454

Epoch: 6| Step: 13
Training loss: 1.228706332931659
Validation loss: 2.59569164356824

Epoch: 102| Step: 0
Training loss: 2.783558947923493
Validation loss: 2.58322044607874

Epoch: 6| Step: 1
Training loss: 2.0532667230147776
Validation loss: 2.568864632962321

Epoch: 6| Step: 2
Training loss: 1.9620169901680902
Validation loss: 2.6057996639820957

Epoch: 6| Step: 3
Training loss: 1.9789938466427957
Validation loss: 2.5381458212292705

Epoch: 6| Step: 4
Training loss: 2.679068179616778
Validation loss: 2.5459729334822656

Epoch: 6| Step: 5
Training loss: 2.093972493206902
Validation loss: 2.5551880823373003

Epoch: 6| Step: 6
Training loss: 2.029039206865364
Validation loss: 2.5489644721772713

Epoch: 6| Step: 7
Training loss: 2.562745710548515
Validation loss: 2.566202079126087

Epoch: 6| Step: 8
Training loss: 2.491224718822132
Validation loss: 2.545625610326514

Epoch: 6| Step: 9
Training loss: 1.9327916186599396
Validation loss: 2.538737333946368

Epoch: 6| Step: 10
Training loss: 2.0525470216222717
Validation loss: 2.5585229994914442

Epoch: 6| Step: 11
Training loss: 1.9701326147454739
Validation loss: 2.560720694369804

Epoch: 6| Step: 12
Training loss: 1.525038362239416
Validation loss: 2.577242081629524

Epoch: 6| Step: 13
Training loss: 1.5297194636339875
Validation loss: 2.5549387365960445

Epoch: 103| Step: 0
Training loss: 2.354363379797881
Validation loss: 2.5566941759112467

Epoch: 6| Step: 1
Training loss: 2.4192167398559836
Validation loss: 2.5831080051308857

Epoch: 6| Step: 2
Training loss: 2.0190534192406386
Validation loss: 2.5630332422967053

Epoch: 6| Step: 3
Training loss: 1.821021666341864
Validation loss: 2.5677469236454327

Epoch: 6| Step: 4
Training loss: 1.9194694288620961
Validation loss: 2.5614642709541977

Epoch: 6| Step: 5
Training loss: 1.8415578968269564
Validation loss: 2.5473962730127075

Epoch: 6| Step: 6
Training loss: 1.5793527793755235
Validation loss: 2.575348671204452

Epoch: 6| Step: 7
Training loss: 2.047327355638922
Validation loss: 2.5572687421238633

Epoch: 6| Step: 8
Training loss: 2.742033429721803
Validation loss: 2.592765851198294

Epoch: 6| Step: 9
Training loss: 2.0724629300141797
Validation loss: 2.5879414026808876

Epoch: 6| Step: 10
Training loss: 1.9587835511314429
Validation loss: 2.580324517843805

Epoch: 6| Step: 11
Training loss: 2.566876094085037
Validation loss: 2.549649293630969

Epoch: 6| Step: 12
Training loss: 2.330462415266491
Validation loss: 2.5638004197708915

Epoch: 6| Step: 13
Training loss: 1.9227136162388279
Validation loss: 2.5573996827309693

Epoch: 104| Step: 0
Training loss: 2.3315498711448877
Validation loss: 2.5485162108097033

Epoch: 6| Step: 1
Training loss: 1.5812587029138436
Validation loss: 2.5494982231968355

Epoch: 6| Step: 2
Training loss: 2.001708016626222
Validation loss: 2.563189545564171

Epoch: 6| Step: 3
Training loss: 2.706628546548133
Validation loss: 2.5112668783362144

Epoch: 6| Step: 4
Training loss: 1.774282380226641
Validation loss: 2.554701086663408

Epoch: 6| Step: 5
Training loss: 1.8526486458388673
Validation loss: 2.5625629107188383

Epoch: 6| Step: 6
Training loss: 2.8791689293535527
Validation loss: 2.578407202794498

Epoch: 6| Step: 7
Training loss: 2.225408636565637
Validation loss: 2.606517285272413

Epoch: 6| Step: 8
Training loss: 2.2331456356979533
Validation loss: 2.6087321633626477

Epoch: 6| Step: 9
Training loss: 1.6794781221700688
Validation loss: 2.5820606747488157

Epoch: 6| Step: 10
Training loss: 2.417240852896514
Validation loss: 2.5626561109550057

Epoch: 6| Step: 11
Training loss: 1.8221905888096368
Validation loss: 2.5460927811283574

Epoch: 6| Step: 12
Training loss: 1.7821595396216094
Validation loss: 2.5769491500480743

Epoch: 6| Step: 13
Training loss: 2.2352846868068053
Validation loss: 2.551404182738034

Epoch: 105| Step: 0
Training loss: 2.128654815104811
Validation loss: 2.5551032487296683

Epoch: 6| Step: 1
Training loss: 1.997413393131608
Validation loss: 2.5607742530627386

Epoch: 6| Step: 2
Training loss: 1.8561037924371473
Validation loss: 2.561344506484442

Epoch: 6| Step: 3
Training loss: 2.049521213538038
Validation loss: 2.526080799127394

Epoch: 6| Step: 4
Training loss: 1.822271250954271
Validation loss: 2.5738605718959975

Epoch: 6| Step: 5
Training loss: 2.965773204320062
Validation loss: 2.5638846401382827

Epoch: 6| Step: 6
Training loss: 2.1531375037551372
Validation loss: 2.576913814987899

Epoch: 6| Step: 7
Training loss: 0.9599169452323634
Validation loss: 2.571496182705838

Epoch: 6| Step: 8
Training loss: 1.3049038918866216
Validation loss: 2.5798496989400945

Epoch: 6| Step: 9
Training loss: 2.14131476434057
Validation loss: 2.564483448710227

Epoch: 6| Step: 10
Training loss: 1.4803056048280379
Validation loss: 2.586383485319205

Epoch: 6| Step: 11
Training loss: 2.7824949414257807
Validation loss: 2.5894863213811727

Epoch: 6| Step: 12
Training loss: 2.6985630944936934
Validation loss: 2.580292717102186

Epoch: 6| Step: 13
Training loss: 2.4606981917995325
Validation loss: 2.5633606434604506

Epoch: 106| Step: 0
Training loss: 2.026868113912765
Validation loss: 2.6095099652196243

Epoch: 6| Step: 1
Training loss: 1.8420875942845634
Validation loss: 2.5914060120174685

Epoch: 6| Step: 2
Training loss: 1.3826597312549758
Validation loss: 2.6134307468838998

Epoch: 6| Step: 3
Training loss: 1.8321534463761804
Validation loss: 2.60677367879361

Epoch: 6| Step: 4
Training loss: 1.7537346906802664
Validation loss: 2.6062942867038306

Epoch: 6| Step: 5
Training loss: 1.5690746077917692
Validation loss: 2.5796032992538014

Epoch: 6| Step: 6
Training loss: 2.005849152922469
Validation loss: 2.5846880980278675

Epoch: 6| Step: 7
Training loss: 2.3789715938018703
Validation loss: 2.5912991476788294

Epoch: 6| Step: 8
Training loss: 2.0843886436461965
Validation loss: 2.55460557407679

Epoch: 6| Step: 9
Training loss: 2.0813436034635684
Validation loss: 2.5499398604637746

Epoch: 6| Step: 10
Training loss: 2.6264237675288853
Validation loss: 2.5351916341560528

Epoch: 6| Step: 11
Training loss: 2.707187400376645
Validation loss: 2.536102431835946

Epoch: 6| Step: 12
Training loss: 2.8573205790422707
Validation loss: 2.5601837575794932

Epoch: 6| Step: 13
Training loss: 2.0170631896349267
Validation loss: 2.5426027939983262

Epoch: 107| Step: 0
Training loss: 2.5312497174298163
Validation loss: 2.563586260673691

Epoch: 6| Step: 1
Training loss: 1.879643032090223
Validation loss: 2.5532147345459837

Epoch: 6| Step: 2
Training loss: 2.4630007859111465
Validation loss: 2.567193145343303

Epoch: 6| Step: 3
Training loss: 1.8982133144298765
Validation loss: 2.565793316950217

Epoch: 6| Step: 4
Training loss: 1.8727358180883913
Validation loss: 2.547219173212791

Epoch: 6| Step: 5
Training loss: 1.8114844798708567
Validation loss: 2.564214536013213

Epoch: 6| Step: 6
Training loss: 2.6083366475272123
Validation loss: 2.5695058606228094

Epoch: 6| Step: 7
Training loss: 2.3150563930621346
Validation loss: 2.565091319302112

Epoch: 6| Step: 8
Training loss: 2.6140153022148938
Validation loss: 2.606918335868949

Epoch: 6| Step: 9
Training loss: 1.9651002507929471
Validation loss: 2.612746909670708

Epoch: 6| Step: 10
Training loss: 2.029951179180415
Validation loss: 2.590769184795277

Epoch: 6| Step: 11
Training loss: 1.9233519298815802
Validation loss: 2.5616564098674846

Epoch: 6| Step: 12
Training loss: 2.04910925144689
Validation loss: 2.5784149931601634

Epoch: 6| Step: 13
Training loss: 1.055163014911492
Validation loss: 2.5705977323164713

Epoch: 108| Step: 0
Training loss: 1.7920114791621662
Validation loss: 2.5848301324918217

Epoch: 6| Step: 1
Training loss: 1.8196081673467974
Validation loss: 2.557582338883951

Epoch: 6| Step: 2
Training loss: 1.9779605067893689
Validation loss: 2.579976397734133

Epoch: 6| Step: 3
Training loss: 2.135946800362376
Validation loss: 2.5680524248588115

Epoch: 6| Step: 4
Training loss: 1.5298564564307053
Validation loss: 2.5650467816177174

Epoch: 6| Step: 5
Training loss: 1.8773877516918653
Validation loss: 2.5421725118922476

Epoch: 6| Step: 6
Training loss: 2.23600688109593
Validation loss: 2.5514146876070547

Epoch: 6| Step: 7
Training loss: 1.9655156285555684
Validation loss: 2.5565417187790396

Epoch: 6| Step: 8
Training loss: 2.151939506439198
Validation loss: 2.5999118276464

Epoch: 6| Step: 9
Training loss: 2.051469843472421
Validation loss: 2.5731740557670766

Epoch: 6| Step: 10
Training loss: 2.9060252112957525
Validation loss: 2.5759211590062057

Epoch: 6| Step: 11
Training loss: 1.5578571768488512
Validation loss: 2.5954019119628002

Epoch: 6| Step: 12
Training loss: 2.296263217545347
Validation loss: 2.639487042034369

Epoch: 6| Step: 13
Training loss: 2.4518777385679846
Validation loss: 2.613647116009454

Epoch: 109| Step: 0
Training loss: 1.9897485501326861
Validation loss: 2.5898344366750985

Epoch: 6| Step: 1
Training loss: 2.326113350209676
Validation loss: 2.6278327764311844

Epoch: 6| Step: 2
Training loss: 2.08926914194542
Validation loss: 2.6080568680989216

Epoch: 6| Step: 3
Training loss: 2.1695618970366444
Validation loss: 2.574161997793238

Epoch: 6| Step: 4
Training loss: 2.2606341935599144
Validation loss: 2.5608325122898554

Epoch: 6| Step: 5
Training loss: 1.7129831843667047
Validation loss: 2.5758240884125234

Epoch: 6| Step: 6
Training loss: 1.7134549506448673
Validation loss: 2.5378606994032595

Epoch: 6| Step: 7
Training loss: 1.6445879348807773
Validation loss: 2.557666701859192

Epoch: 6| Step: 8
Training loss: 1.7960173177032877
Validation loss: 2.5848586798775193

Epoch: 6| Step: 9
Training loss: 2.1756164378781535
Validation loss: 2.58690868630096

Epoch: 6| Step: 10
Training loss: 2.8717081878665467
Validation loss: 2.55164197621608

Epoch: 6| Step: 11
Training loss: 2.091436787875025
Validation loss: 2.5568350224309593

Epoch: 6| Step: 12
Training loss: 1.9576642198725411
Validation loss: 2.5854963250892404

Epoch: 6| Step: 13
Training loss: 2.153839754524785
Validation loss: 2.5488925735685717

Epoch: 110| Step: 0
Training loss: 1.8288403277145062
Validation loss: 2.598076685484601

Epoch: 6| Step: 1
Training loss: 2.438662716287563
Validation loss: 2.6072289022790054

Epoch: 6| Step: 2
Training loss: 2.095237089957785
Validation loss: 2.616000339888143

Epoch: 6| Step: 3
Training loss: 1.6372089971888362
Validation loss: 2.5574924107920936

Epoch: 6| Step: 4
Training loss: 2.151684557985383
Validation loss: 2.564867817532153

Epoch: 6| Step: 5
Training loss: 1.9236219576435347
Validation loss: 2.5447835779757675

Epoch: 6| Step: 6
Training loss: 2.1733291478302013
Validation loss: 2.552638438571414

Epoch: 6| Step: 7
Training loss: 2.5734205383223565
Validation loss: 2.576016791367942

Epoch: 6| Step: 8
Training loss: 2.2354865877060135
Validation loss: 2.554362487339193

Epoch: 6| Step: 9
Training loss: 1.426358876732344
Validation loss: 2.5635546708090406

Epoch: 6| Step: 10
Training loss: 2.3226662972724057
Validation loss: 2.566052850383662

Epoch: 6| Step: 11
Training loss: 1.9032278650104784
Validation loss: 2.5982494546941135

Epoch: 6| Step: 12
Training loss: 1.802924744379497
Validation loss: 2.591235738501259

Epoch: 6| Step: 13
Training loss: 1.975471889279433
Validation loss: 2.592977661595629

Epoch: 111| Step: 0
Training loss: 1.7058266027057192
Validation loss: 2.6089944466799473

Epoch: 6| Step: 1
Training loss: 1.6461827192989857
Validation loss: 2.6309051094337406

Epoch: 6| Step: 2
Training loss: 2.375614689034574
Validation loss: 2.6277104265839855

Epoch: 6| Step: 3
Training loss: 2.904474844286614
Validation loss: 2.6068819513306742

Epoch: 6| Step: 4
Training loss: 1.418429213233033
Validation loss: 2.6015735889461964

Epoch: 6| Step: 5
Training loss: 1.805584309014799
Validation loss: 2.640331741090126

Epoch: 6| Step: 6
Training loss: 2.011436664840591
Validation loss: 2.626331642500221

Epoch: 6| Step: 7
Training loss: 1.862457797193183
Validation loss: 2.6745520968400194

Epoch: 6| Step: 8
Training loss: 2.016980801961426
Validation loss: 2.6170226391542015

Epoch: 6| Step: 9
Training loss: 1.8515059707961514
Validation loss: 2.5879669830765195

Epoch: 6| Step: 10
Training loss: 2.493923240514358
Validation loss: 2.5888590909087092

Epoch: 6| Step: 11
Training loss: 2.0560013084407456
Validation loss: 2.596634857605629

Epoch: 6| Step: 12
Training loss: 1.9262987412630033
Validation loss: 2.5643301142843393

Epoch: 6| Step: 13
Training loss: 2.256991121510429
Validation loss: 2.6032685498624106

Epoch: 112| Step: 0
Training loss: 1.9572633160264716
Validation loss: 2.551690243920007

Epoch: 6| Step: 1
Training loss: 2.5586552503343385
Validation loss: 2.5493724568173435

Epoch: 6| Step: 2
Training loss: 1.8524183395858465
Validation loss: 2.532701052850081

Epoch: 6| Step: 3
Training loss: 1.927429855396337
Validation loss: 2.5369906692593927

Epoch: 6| Step: 4
Training loss: 2.154445501269
Validation loss: 2.5692070513395158

Epoch: 6| Step: 5
Training loss: 1.83260806505343
Validation loss: 2.575697709899114

Epoch: 6| Step: 6
Training loss: 2.2807966853152153
Validation loss: 2.5943278699230254

Epoch: 6| Step: 7
Training loss: 1.7087197060679757
Validation loss: 2.601052441394525

Epoch: 6| Step: 8
Training loss: 2.1956710794088985
Validation loss: 2.597205927543274

Epoch: 6| Step: 9
Training loss: 2.1740229023250848
Validation loss: 2.590389986195843

Epoch: 6| Step: 10
Training loss: 2.6082808890468434
Validation loss: 2.5696596129998492

Epoch: 6| Step: 11
Training loss: 2.0354295426283247
Validation loss: 2.5791331776389614

Epoch: 6| Step: 12
Training loss: 1.271536689771978
Validation loss: 2.5672431792716135

Epoch: 6| Step: 13
Training loss: 1.9321164431301345
Validation loss: 2.5663422567362133

Epoch: 113| Step: 0
Training loss: 1.907458188259894
Validation loss: 2.5846831169178883

Epoch: 6| Step: 1
Training loss: 2.2605810383979934
Validation loss: 2.578480751846999

Epoch: 6| Step: 2
Training loss: 1.9381573700131471
Validation loss: 2.58791245169402

Epoch: 6| Step: 3
Training loss: 1.838913344149876
Validation loss: 2.6052369372538795

Epoch: 6| Step: 4
Training loss: 2.500674633552771
Validation loss: 2.592685059539647

Epoch: 6| Step: 5
Training loss: 1.6884209274560311
Validation loss: 2.604485001498687

Epoch: 6| Step: 6
Training loss: 2.199104807529257
Validation loss: 2.6251171857925453

Epoch: 6| Step: 7
Training loss: 2.257464002489116
Validation loss: 2.590245710031814

Epoch: 6| Step: 8
Training loss: 2.088672916033264
Validation loss: 2.5783749391798634

Epoch: 6| Step: 9
Training loss: 1.7531819706600096
Validation loss: 2.5935125893401945

Epoch: 6| Step: 10
Training loss: 2.0255603627194176
Validation loss: 2.5904740860578026

Epoch: 6| Step: 11
Training loss: 1.6907969163507806
Validation loss: 2.604959555401642

Epoch: 6| Step: 12
Training loss: 1.765432904351637
Validation loss: 2.5768324723467315

Epoch: 6| Step: 13
Training loss: 2.084524526194205
Validation loss: 2.5932493684197215

Epoch: 114| Step: 0
Training loss: 1.7072154628775573
Validation loss: 2.5756122790161857

Epoch: 6| Step: 1
Training loss: 2.0555841498347864
Validation loss: 2.632642202784163

Epoch: 6| Step: 2
Training loss: 1.858492345236387
Validation loss: 2.6263076915816628

Epoch: 6| Step: 3
Training loss: 1.5135902825791616
Validation loss: 2.607387158642559

Epoch: 6| Step: 4
Training loss: 1.6098453612135775
Validation loss: 2.6061657264556364

Epoch: 6| Step: 5
Training loss: 2.3172711820919365
Validation loss: 2.6763332567920104

Epoch: 6| Step: 6
Training loss: 1.9099250138627148
Validation loss: 2.6533443340795513

Epoch: 6| Step: 7
Training loss: 2.577756913235876
Validation loss: 2.6982444112434663

Epoch: 6| Step: 8
Training loss: 1.980218393727338
Validation loss: 2.6980144797210643

Epoch: 6| Step: 9
Training loss: 1.6446250471970565
Validation loss: 2.66700458372409

Epoch: 6| Step: 10
Training loss: 1.8029409436938733
Validation loss: 2.6001272433273575

Epoch: 6| Step: 11
Training loss: 2.87427080277852
Validation loss: 2.600057332617191

Epoch: 6| Step: 12
Training loss: 2.243297235822915
Validation loss: 2.538208529329917

Epoch: 6| Step: 13
Training loss: 1.9877860721102112
Validation loss: 2.557294069950712

Epoch: 115| Step: 0
Training loss: 2.684314081391172
Validation loss: 2.5719327293644003

Epoch: 6| Step: 1
Training loss: 2.0603623149351504
Validation loss: 2.5607575485811926

Epoch: 6| Step: 2
Training loss: 1.8179548327770232
Validation loss: 2.569097252892867

Epoch: 6| Step: 3
Training loss: 2.0591301409225835
Validation loss: 2.592779843693043

Epoch: 6| Step: 4
Training loss: 2.0022682202486934
Validation loss: 2.561658457451471

Epoch: 6| Step: 5
Training loss: 1.9418489193277588
Validation loss: 2.5874507506224673

Epoch: 6| Step: 6
Training loss: 1.3854948418533966
Validation loss: 2.5560425286324353

Epoch: 6| Step: 7
Training loss: 1.9972431732951113
Validation loss: 2.556923963497075

Epoch: 6| Step: 8
Training loss: 2.701206121551704
Validation loss: 2.5847973725562445

Epoch: 6| Step: 9
Training loss: 2.2331469168603113
Validation loss: 2.5486363130502006

Epoch: 6| Step: 10
Training loss: 1.685727000419474
Validation loss: 2.5840454709458442

Epoch: 6| Step: 11
Training loss: 1.7792952000498086
Validation loss: 2.638253239708978

Epoch: 6| Step: 12
Training loss: 1.5650005930451558
Validation loss: 2.628010491875192

Epoch: 6| Step: 13
Training loss: 2.012684888225067
Validation loss: 2.677619618137083

Epoch: 116| Step: 0
Training loss: 1.7641526556502258
Validation loss: 2.717521887032794

Epoch: 6| Step: 1
Training loss: 2.434422628894124
Validation loss: 2.707588054132711

Epoch: 6| Step: 2
Training loss: 2.7071596585818916
Validation loss: 2.671073153753799

Epoch: 6| Step: 3
Training loss: 2.486959971941361
Validation loss: 2.6741128662615825

Epoch: 6| Step: 4
Training loss: 1.7377031029201495
Validation loss: 2.6471233427063527

Epoch: 6| Step: 5
Training loss: 1.8764292038355286
Validation loss: 2.6037722683114715

Epoch: 6| Step: 6
Training loss: 1.7802333942373296
Validation loss: 2.565734279843729

Epoch: 6| Step: 7
Training loss: 2.273781661892688
Validation loss: 2.576972927502955

Epoch: 6| Step: 8
Training loss: 2.129793706584039
Validation loss: 2.572795823897781

Epoch: 6| Step: 9
Training loss: 1.7696566842528665
Validation loss: 2.567267859221436

Epoch: 6| Step: 10
Training loss: 1.705216899175302
Validation loss: 2.5672107908307216

Epoch: 6| Step: 11
Training loss: 1.841330670507901
Validation loss: 2.573260285653465

Epoch: 6| Step: 12
Training loss: 1.9456072970772667
Validation loss: 2.562716761779529

Epoch: 6| Step: 13
Training loss: 1.8527488288098444
Validation loss: 2.5433395123271287

Epoch: 117| Step: 0
Training loss: 1.6378106092017384
Validation loss: 2.556343700553885

Epoch: 6| Step: 1
Training loss: 1.7737748417583221
Validation loss: 2.586487649133606

Epoch: 6| Step: 2
Training loss: 2.4781267779465366
Validation loss: 2.595467370403991

Epoch: 6| Step: 3
Training loss: 1.2820970480037297
Validation loss: 2.602362646215435

Epoch: 6| Step: 4
Training loss: 1.7703126777722908
Validation loss: 2.590625320882436

Epoch: 6| Step: 5
Training loss: 2.1649229907288
Validation loss: 2.612675024859093

Epoch: 6| Step: 6
Training loss: 1.9658692491696728
Validation loss: 2.6371278873954638

Epoch: 6| Step: 7
Training loss: 1.7145261709419097
Validation loss: 2.5964866203924712

Epoch: 6| Step: 8
Training loss: 1.6713594729191787
Validation loss: 2.6286341321813373

Epoch: 6| Step: 9
Training loss: 1.885136353395248
Validation loss: 2.6043198248011894

Epoch: 6| Step: 10
Training loss: 2.7236719412470323
Validation loss: 2.6168448152662145

Epoch: 6| Step: 11
Training loss: 2.2166610340056403
Validation loss: 2.606414638475526

Epoch: 6| Step: 12
Training loss: 1.7785214724613199
Validation loss: 2.5957798502776743

Epoch: 6| Step: 13
Training loss: 2.4413691403429643
Validation loss: 2.5865524344520923

Epoch: 118| Step: 0
Training loss: 1.711215480013217
Validation loss: 2.5865066685630245

Epoch: 6| Step: 1
Training loss: 1.6956863342733328
Validation loss: 2.5963089587306984

Epoch: 6| Step: 2
Training loss: 2.0074091999806596
Validation loss: 2.5836114784957473

Epoch: 6| Step: 3
Training loss: 2.812115621791662
Validation loss: 2.633992625851593

Epoch: 6| Step: 4
Training loss: 1.7634832845338575
Validation loss: 2.596462968072614

Epoch: 6| Step: 5
Training loss: 1.9407293417579394
Validation loss: 2.5926123732488384

Epoch: 6| Step: 6
Training loss: 1.7985524847555971
Validation loss: 2.5972515660995192

Epoch: 6| Step: 7
Training loss: 2.0195866176903032
Validation loss: 2.604850058850104

Epoch: 6| Step: 8
Training loss: 2.080967386205553
Validation loss: 2.658128156686274

Epoch: 6| Step: 9
Training loss: 2.0811495461721905
Validation loss: 2.655493879222717

Epoch: 6| Step: 10
Training loss: 2.3382295826493937
Validation loss: 2.6260162233247137

Epoch: 6| Step: 11
Training loss: 1.433073110393844
Validation loss: 2.619444144666845

Epoch: 6| Step: 12
Training loss: 1.9577632304185264
Validation loss: 2.565369805589585

Epoch: 6| Step: 13
Training loss: 1.8199086539432439
Validation loss: 2.5647121743118855

Epoch: 119| Step: 0
Training loss: 1.7580008850876594
Validation loss: 2.5496630707842307

Epoch: 6| Step: 1
Training loss: 2.3109345163322206
Validation loss: 2.6218729163893983

Epoch: 6| Step: 2
Training loss: 2.151512802536285
Validation loss: 2.5731499189112697

Epoch: 6| Step: 3
Training loss: 1.4034324394139932
Validation loss: 2.6054507535649405

Epoch: 6| Step: 4
Training loss: 1.6280165330483172
Validation loss: 2.5732053267886883

Epoch: 6| Step: 5
Training loss: 1.6543345621583427
Validation loss: 2.6128121312778423

Epoch: 6| Step: 6
Training loss: 2.3012456506193835
Validation loss: 2.592409024728414

Epoch: 6| Step: 7
Training loss: 2.4205773599606766
Validation loss: 2.591482749517475

Epoch: 6| Step: 8
Training loss: 2.4104923650735004
Validation loss: 2.626066294071294

Epoch: 6| Step: 9
Training loss: 1.973696111676658
Validation loss: 2.594785047165615

Epoch: 6| Step: 10
Training loss: 1.9146202676038042
Validation loss: 2.577941417901023

Epoch: 6| Step: 11
Training loss: 1.7447033152819171
Validation loss: 2.5871406591298793

Epoch: 6| Step: 12
Training loss: 1.8048630005684427
Validation loss: 2.616351716308645

Epoch: 6| Step: 13
Training loss: 1.6386861334488432
Validation loss: 2.5973276489764814

Epoch: 120| Step: 0
Training loss: 1.1805875262749665
Validation loss: 2.615494365460732

Epoch: 6| Step: 1
Training loss: 1.279665455610837
Validation loss: 2.6092266642120396

Epoch: 6| Step: 2
Training loss: 2.040116662448235
Validation loss: 2.6315230505009435

Epoch: 6| Step: 3
Training loss: 2.291850504581737
Validation loss: 2.692682887140946

Epoch: 6| Step: 4
Training loss: 1.4626592598301291
Validation loss: 2.6825729123907824

Epoch: 6| Step: 5
Training loss: 1.9138608865238085
Validation loss: 2.6820575402061464

Epoch: 6| Step: 6
Training loss: 1.711932515699353
Validation loss: 2.7441345431983315

Epoch: 6| Step: 7
Training loss: 1.785999925111468
Validation loss: 2.714987361777849

Epoch: 6| Step: 8
Training loss: 2.1003801501287644
Validation loss: 2.688675808038864

Epoch: 6| Step: 9
Training loss: 2.4561784534857054
Validation loss: 2.692344660644897

Epoch: 6| Step: 10
Training loss: 2.491782989678549
Validation loss: 2.6376789219147048

Epoch: 6| Step: 11
Training loss: 2.0399066449290357
Validation loss: 2.6171723929960837

Epoch: 6| Step: 12
Training loss: 2.339651364169323
Validation loss: 2.5573804002169043

Epoch: 6| Step: 13
Training loss: 2.058443183387241
Validation loss: 2.590719973330664

Epoch: 121| Step: 0
Training loss: 2.024460817304094
Validation loss: 2.642550080858483

Epoch: 6| Step: 1
Training loss: 1.917684188212813
Validation loss: 2.605165707009282

Epoch: 6| Step: 2
Training loss: 2.0907459628887124
Validation loss: 2.596551095017203

Epoch: 6| Step: 3
Training loss: 2.665275141127343
Validation loss: 2.6242292574503407

Epoch: 6| Step: 4
Training loss: 2.3244396970217
Validation loss: 2.6278530541091687

Epoch: 6| Step: 5
Training loss: 1.6605843025822766
Validation loss: 2.601317385561907

Epoch: 6| Step: 6
Training loss: 1.5060522844020592
Validation loss: 2.6020062347873014

Epoch: 6| Step: 7
Training loss: 2.1360683532236404
Validation loss: 2.6341117875214297

Epoch: 6| Step: 8
Training loss: 1.7809008875261436
Validation loss: 2.652758259282586

Epoch: 6| Step: 9
Training loss: 1.3775434378475107
Validation loss: 2.705572266323626

Epoch: 6| Step: 10
Training loss: 2.0828624447488404
Validation loss: 2.7287338631945426

Epoch: 6| Step: 11
Training loss: 1.862620878457351
Validation loss: 2.776306473708515

Epoch: 6| Step: 12
Training loss: 2.721557570648022
Validation loss: 2.7942610020863037

Epoch: 6| Step: 13
Training loss: 2.1940410366619494
Validation loss: 2.693604212663765

Epoch: 122| Step: 0
Training loss: 1.9298043775491625
Validation loss: 2.651256340243492

Epoch: 6| Step: 1
Training loss: 1.6892908977612207
Validation loss: 2.616265570115345

Epoch: 6| Step: 2
Training loss: 1.6327873848621686
Validation loss: 2.6076167382660946

Epoch: 6| Step: 3
Training loss: 2.087655035417853
Validation loss: 2.602073596318161

Epoch: 6| Step: 4
Training loss: 2.3873169394410203
Validation loss: 2.5987688554841535

Epoch: 6| Step: 5
Training loss: 2.0612659808592526
Validation loss: 2.601293448739585

Epoch: 6| Step: 6
Training loss: 1.9878564167133974
Validation loss: 2.6146165052845163

Epoch: 6| Step: 7
Training loss: 1.590822560570465
Validation loss: 2.599955003911471

Epoch: 6| Step: 8
Training loss: 2.1092589169809206
Validation loss: 2.563669310089972

Epoch: 6| Step: 9
Training loss: 1.04337025889865
Validation loss: 2.612943390815181

Epoch: 6| Step: 10
Training loss: 2.2073042169069814
Validation loss: 2.575541216876012

Epoch: 6| Step: 11
Training loss: 2.0006724657590964
Validation loss: 2.581599027668238

Epoch: 6| Step: 12
Training loss: 2.2445156225662246
Validation loss: 2.5881733673914264

Epoch: 6| Step: 13
Training loss: 1.8132302358831662
Validation loss: 2.576145251996706

Epoch: 123| Step: 0
Training loss: 1.8907249991713377
Validation loss: 2.5954084494605563

Epoch: 6| Step: 1
Training loss: 1.7390113240378384
Validation loss: 2.6151512689279577

Epoch: 6| Step: 2
Training loss: 1.9196264247254335
Validation loss: 2.6405865668334614

Epoch: 6| Step: 3
Training loss: 1.8218517426303502
Validation loss: 2.6514390349093575

Epoch: 6| Step: 4
Training loss: 1.6954340737343687
Validation loss: 2.6387891086876922

Epoch: 6| Step: 5
Training loss: 1.6795016873513888
Validation loss: 2.652662929381123

Epoch: 6| Step: 6
Training loss: 1.6710218587983183
Validation loss: 2.6594689704857246

Epoch: 6| Step: 7
Training loss: 2.8431952637589504
Validation loss: 2.661284026069812

Epoch: 6| Step: 8
Training loss: 1.9113526137494656
Validation loss: 2.650867543875692

Epoch: 6| Step: 9
Training loss: 1.7041336712367223
Validation loss: 2.6196295433363623

Epoch: 6| Step: 10
Training loss: 1.9474003017306596
Validation loss: 2.5810415243793887

Epoch: 6| Step: 11
Training loss: 2.166690263864202
Validation loss: 2.598119479300383

Epoch: 6| Step: 12
Training loss: 1.4499903678574118
Validation loss: 2.5961461163991713

Epoch: 6| Step: 13
Training loss: 1.7576044256190204
Validation loss: 2.6177385044345205

Epoch: 124| Step: 0
Training loss: 2.493993983367784
Validation loss: 2.6051420953549456

Epoch: 6| Step: 1
Training loss: 1.9124413923870152
Validation loss: 2.608411394013532

Epoch: 6| Step: 2
Training loss: 1.7727028421572544
Validation loss: 2.5986712392101636

Epoch: 6| Step: 3
Training loss: 1.710810408379014
Validation loss: 2.5642281109383687

Epoch: 6| Step: 4
Training loss: 2.3164267321962817
Validation loss: 2.6222432965663827

Epoch: 6| Step: 5
Training loss: 1.9398054742128796
Validation loss: 2.636141769010714

Epoch: 6| Step: 6
Training loss: 1.8360091824436986
Validation loss: 2.6453635832527236

Epoch: 6| Step: 7
Training loss: 1.7045693528783077
Validation loss: 2.623844225316667

Epoch: 6| Step: 8
Training loss: 1.2772449140195445
Validation loss: 2.642836974163987

Epoch: 6| Step: 9
Training loss: 1.551760270805164
Validation loss: 2.657524461367481

Epoch: 6| Step: 10
Training loss: 1.702447669055408
Validation loss: 2.6626980625801453

Epoch: 6| Step: 11
Training loss: 2.1730679316428807
Validation loss: 2.6472401120556603

Epoch: 6| Step: 12
Training loss: 2.019270564654784
Validation loss: 2.634947954999381

Epoch: 6| Step: 13
Training loss: 1.7122289234211503
Validation loss: 2.6353924012606234

Epoch: 125| Step: 0
Training loss: 1.5430256120851595
Validation loss: 2.5846482027571938

Epoch: 6| Step: 1
Training loss: 1.6740582907678787
Validation loss: 2.6470177520004885

Epoch: 6| Step: 2
Training loss: 1.8589678406706516
Validation loss: 2.650233467182186

Epoch: 6| Step: 3
Training loss: 1.7010732768902754
Validation loss: 2.608385442836836

Epoch: 6| Step: 4
Training loss: 2.3109424603907422
Validation loss: 2.6819550583867167

Epoch: 6| Step: 5
Training loss: 1.686420236510262
Validation loss: 2.5978394101995828

Epoch: 6| Step: 6
Training loss: 2.656592762093426
Validation loss: 2.605749920529762

Epoch: 6| Step: 7
Training loss: 1.5748541143761168
Validation loss: 2.618302702656793

Epoch: 6| Step: 8
Training loss: 1.5138963102261842
Validation loss: 2.574379629878195

Epoch: 6| Step: 9
Training loss: 1.8336663666150328
Validation loss: 2.612385503641846

Epoch: 6| Step: 10
Training loss: 2.3688388012669708
Validation loss: 2.616358657089673

Epoch: 6| Step: 11
Training loss: 2.233442418674952
Validation loss: 2.646673629769199

Epoch: 6| Step: 12
Training loss: 1.1322574176305307
Validation loss: 2.5986621792431417

Epoch: 6| Step: 13
Training loss: 1.719757824970493
Validation loss: 2.6370952874226785

Epoch: 126| Step: 0
Training loss: 1.8887411142338406
Validation loss: 2.61678913178138

Epoch: 6| Step: 1
Training loss: 1.682609323404613
Validation loss: 2.582928561729745

Epoch: 6| Step: 2
Training loss: 2.32110725945875
Validation loss: 2.59335197703942

Epoch: 6| Step: 3
Training loss: 1.7098138333087538
Validation loss: 2.6004744689789283

Epoch: 6| Step: 4
Training loss: 1.6562056625477626
Validation loss: 2.5851681151530403

Epoch: 6| Step: 5
Training loss: 1.8514747437874854
Validation loss: 2.588720370494103

Epoch: 6| Step: 6
Training loss: 1.692784124780573
Validation loss: 2.6085423799133016

Epoch: 6| Step: 7
Training loss: 1.9651153558742296
Validation loss: 2.6162669826198783

Epoch: 6| Step: 8
Training loss: 2.17725666092342
Validation loss: 2.5574272156094398

Epoch: 6| Step: 9
Training loss: 1.3597126683873766
Validation loss: 2.6331072150902783

Epoch: 6| Step: 10
Training loss: 1.5595690895032774
Validation loss: 2.593984509020109

Epoch: 6| Step: 11
Training loss: 1.7734461712730256
Validation loss: 2.61908202422238

Epoch: 6| Step: 12
Training loss: 2.5682865959270123
Validation loss: 2.6528097575747163

Epoch: 6| Step: 13
Training loss: 1.6877278774542364
Validation loss: 2.674631589256205

Epoch: 127| Step: 0
Training loss: 1.67214728304016
Validation loss: 2.654507158757531

Epoch: 6| Step: 1
Training loss: 1.7289130319771735
Validation loss: 2.6618134596978464

Epoch: 6| Step: 2
Training loss: 1.4756575137235732
Validation loss: 2.6880841322696036

Epoch: 6| Step: 3
Training loss: 2.1867772679541724
Validation loss: 2.742319174536828

Epoch: 6| Step: 4
Training loss: 2.3734151672156387
Validation loss: 2.7557275832051555

Epoch: 6| Step: 5
Training loss: 1.7439999582395636
Validation loss: 2.6800762669306146

Epoch: 6| Step: 6
Training loss: 1.650195589899669
Validation loss: 2.6208957345282764

Epoch: 6| Step: 7
Training loss: 1.7270547846822415
Validation loss: 2.624537790568176

Epoch: 6| Step: 8
Training loss: 1.5724010338138665
Validation loss: 2.599986029245059

Epoch: 6| Step: 9
Training loss: 2.492166835974285
Validation loss: 2.6027387722512016

Epoch: 6| Step: 10
Training loss: 1.7325682981385881
Validation loss: 2.5836878861391086

Epoch: 6| Step: 11
Training loss: 1.9690200983690775
Validation loss: 2.6157336851666875

Epoch: 6| Step: 12
Training loss: 1.551907761988834
Validation loss: 2.620675915436431

Epoch: 6| Step: 13
Training loss: 2.2401752015125247
Validation loss: 2.5930491193725427

Epoch: 128| Step: 0
Training loss: 1.8396676985626081
Validation loss: 2.6260290399530537

Epoch: 6| Step: 1
Training loss: 1.7415087279967105
Validation loss: 2.6092655212217504

Epoch: 6| Step: 2
Training loss: 1.9951769371253798
Validation loss: 2.617397698459064

Epoch: 6| Step: 3
Training loss: 1.9792549582078742
Validation loss: 2.644545163935501

Epoch: 6| Step: 4
Training loss: 2.1308378923069244
Validation loss: 2.623046246318122

Epoch: 6| Step: 5
Training loss: 1.7052436739506844
Validation loss: 2.62742079267277

Epoch: 6| Step: 6
Training loss: 1.5068775500066725
Validation loss: 2.631264205858025

Epoch: 6| Step: 7
Training loss: 1.4826999247740753
Validation loss: 2.6512070599858135

Epoch: 6| Step: 8
Training loss: 1.1357326359564504
Validation loss: 2.654657522312562

Epoch: 6| Step: 9
Training loss: 2.064781314455814
Validation loss: 2.6654228920918794

Epoch: 6| Step: 10
Training loss: 2.6267828563546085
Validation loss: 2.649199624622051

Epoch: 6| Step: 11
Training loss: 1.7524346717924029
Validation loss: 2.66521294029965

Epoch: 6| Step: 12
Training loss: 1.9498830515687144
Validation loss: 2.5740877232950754

Epoch: 6| Step: 13
Training loss: 1.3674876728234506
Validation loss: 2.585671709889883

Epoch: 129| Step: 0
Training loss: 1.5708820581679033
Validation loss: 2.639265082688129

Epoch: 6| Step: 1
Training loss: 2.0370540154195864
Validation loss: 2.594315831002775

Epoch: 6| Step: 2
Training loss: 2.2627684375996733
Validation loss: 2.643482490514753

Epoch: 6| Step: 3
Training loss: 1.7253511762438298
Validation loss: 2.569073162804573

Epoch: 6| Step: 4
Training loss: 1.8047249530027007
Validation loss: 2.6410232033028627

Epoch: 6| Step: 5
Training loss: 1.7382052629985671
Validation loss: 2.6167238042955003

Epoch: 6| Step: 6
Training loss: 1.2279985124908286
Validation loss: 2.63914017624163

Epoch: 6| Step: 7
Training loss: 1.6982419769129038
Validation loss: 2.609616510175365

Epoch: 6| Step: 8
Training loss: 2.6780584516235826
Validation loss: 2.5925630358368528

Epoch: 6| Step: 9
Training loss: 1.1944435301981737
Validation loss: 2.605462603773868

Epoch: 6| Step: 10
Training loss: 1.9470744904863515
Validation loss: 2.5842754789207616

Epoch: 6| Step: 11
Training loss: 2.0864920004154945
Validation loss: 2.6207999430977034

Epoch: 6| Step: 12
Training loss: 1.8468661080548159
Validation loss: 2.5878054354099485

Epoch: 6| Step: 13
Training loss: 1.491889644274455
Validation loss: 2.648707838336496

Epoch: 130| Step: 0
Training loss: 1.7303789171448587
Validation loss: 2.6523008872133

Epoch: 6| Step: 1
Training loss: 1.39063575826191
Validation loss: 2.6240536482519596

Epoch: 6| Step: 2
Training loss: 1.428995767649849
Validation loss: 2.616023367470212

Epoch: 6| Step: 3
Training loss: 1.6003991344431447
Validation loss: 2.65051333715651

Epoch: 6| Step: 4
Training loss: 1.53560633771065
Validation loss: 2.65151429725402

Epoch: 6| Step: 5
Training loss: 1.9335354266377516
Validation loss: 2.658331926538779

Epoch: 6| Step: 6
Training loss: 2.074838204567835
Validation loss: 2.6931727517368875

Epoch: 6| Step: 7
Training loss: 2.9241438435920997
Validation loss: 2.653493056362074

Epoch: 6| Step: 8
Training loss: 2.2632805631700394
Validation loss: 2.652575895162659

Epoch: 6| Step: 9
Training loss: 1.5977208653746637
Validation loss: 2.645917986218952

Epoch: 6| Step: 10
Training loss: 1.6759890269691857
Validation loss: 2.6462787543602433

Epoch: 6| Step: 11
Training loss: 1.3604935176965511
Validation loss: 2.632959997495994

Epoch: 6| Step: 12
Training loss: 1.5984072983499722
Validation loss: 2.596890612515901

Epoch: 6| Step: 13
Training loss: 1.864980758281373
Validation loss: 2.627662050625995

Epoch: 131| Step: 0
Training loss: 2.00529874787706
Validation loss: 2.6373111012386063

Epoch: 6| Step: 1
Training loss: 1.7723851379496307
Validation loss: 2.6635981926099914

Epoch: 6| Step: 2
Training loss: 1.590433971872875
Validation loss: 2.63756136770102

Epoch: 6| Step: 3
Training loss: 1.6239352772927298
Validation loss: 2.602745390556743

Epoch: 6| Step: 4
Training loss: 1.4314006276390339
Validation loss: 2.6193771539969157

Epoch: 6| Step: 5
Training loss: 2.019654969312422
Validation loss: 2.6615334865363285

Epoch: 6| Step: 6
Training loss: 2.088499631641037
Validation loss: 2.6677046161483213

Epoch: 6| Step: 7
Training loss: 1.792988961963963
Validation loss: 2.6540454467527406

Epoch: 6| Step: 8
Training loss: 1.8166074579838618
Validation loss: 2.7005389564565734

Epoch: 6| Step: 9
Training loss: 1.6403259004702138
Validation loss: 2.6359162039387383

Epoch: 6| Step: 10
Training loss: 2.506766888596674
Validation loss: 2.6402196629488666

Epoch: 6| Step: 11
Training loss: 1.601268238854147
Validation loss: 2.641345044442098

Epoch: 6| Step: 12
Training loss: 1.2897923570788312
Validation loss: 2.6691334510742917

Epoch: 6| Step: 13
Training loss: 1.5333582319781223
Validation loss: 2.6641508443881805

Epoch: 132| Step: 0
Training loss: 2.5756282854695645
Validation loss: 2.6770482982515023

Epoch: 6| Step: 1
Training loss: 1.704626418994062
Validation loss: 2.6409426014729473

Epoch: 6| Step: 2
Training loss: 1.806235042100898
Validation loss: 2.6794109146135043

Epoch: 6| Step: 3
Training loss: 1.7601663385162225
Validation loss: 2.6877670598965175

Epoch: 6| Step: 4
Training loss: 1.7420648095418036
Validation loss: 2.7671747265863225

Epoch: 6| Step: 5
Training loss: 2.266625965912361
Validation loss: 2.8154222354003005

Epoch: 6| Step: 6
Training loss: 1.4580568687326623
Validation loss: 2.706219821729365

Epoch: 6| Step: 7
Training loss: 2.0616454463762
Validation loss: 2.715252069371617

Epoch: 6| Step: 8
Training loss: 1.540064219461022
Validation loss: 2.614145133290867

Epoch: 6| Step: 9
Training loss: 1.3477007430098682
Validation loss: 2.6367646842063723

Epoch: 6| Step: 10
Training loss: 1.1333283400893075
Validation loss: 2.630957866166522

Epoch: 6| Step: 11
Training loss: 1.3346664896503475
Validation loss: 2.5797869017173296

Epoch: 6| Step: 12
Training loss: 2.1548477257124925
Validation loss: 2.643234107603269

Epoch: 6| Step: 13
Training loss: 1.7635215450189696
Validation loss: 2.6303075463244294

Epoch: 133| Step: 0
Training loss: 1.7980683717638086
Validation loss: 2.6160846569136633

Epoch: 6| Step: 1
Training loss: 2.0139231039480436
Validation loss: 2.658055353927308

Epoch: 6| Step: 2
Training loss: 1.2586251707790106
Validation loss: 2.6006637716302485

Epoch: 6| Step: 3
Training loss: 1.376812174190978
Validation loss: 2.653650769848985

Epoch: 6| Step: 4
Training loss: 2.3642912921008294
Validation loss: 2.629660201162381

Epoch: 6| Step: 5
Training loss: 1.7939623238510258
Validation loss: 2.6586433997138923

Epoch: 6| Step: 6
Training loss: 1.5485363910403336
Validation loss: 2.6574839698975516

Epoch: 6| Step: 7
Training loss: 1.6490861963214505
Validation loss: 2.619457175488063

Epoch: 6| Step: 8
Training loss: 1.6058513992842713
Validation loss: 2.6249000136694116

Epoch: 6| Step: 9
Training loss: 1.835233382889389
Validation loss: 2.648104516385971

Epoch: 6| Step: 10
Training loss: 1.648829264438202
Validation loss: 2.6540979082033402

Epoch: 6| Step: 11
Training loss: 2.128351373718006
Validation loss: 2.643859657797014

Epoch: 6| Step: 12
Training loss: 1.66123327885487
Validation loss: 2.6623613625908833

Epoch: 6| Step: 13
Training loss: 2.0827678930337967
Validation loss: 2.609503691463633

Epoch: 134| Step: 0
Training loss: 1.2514874191718666
Validation loss: 2.6532232804773703

Epoch: 6| Step: 1
Training loss: 1.530822382794155
Validation loss: 2.6389420241867843

Epoch: 6| Step: 2
Training loss: 1.5111311527088758
Validation loss: 2.676140561076293

Epoch: 6| Step: 3
Training loss: 1.9075508056914094
Validation loss: 2.638842611297479

Epoch: 6| Step: 4
Training loss: 2.848696253203837
Validation loss: 2.64768617188554

Epoch: 6| Step: 5
Training loss: 1.7999541064875586
Validation loss: 2.6151409593060566

Epoch: 6| Step: 6
Training loss: 1.258025394216747
Validation loss: 2.7013854381165503

Epoch: 6| Step: 7
Training loss: 2.2911263493597356
Validation loss: 2.6269837558477898

Epoch: 6| Step: 8
Training loss: 1.3464247674588339
Validation loss: 2.6989153752698773

Epoch: 6| Step: 9
Training loss: 1.3265939302169585
Validation loss: 2.6845623787320623

Epoch: 6| Step: 10
Training loss: 1.4463240923815268
Validation loss: 2.7176696340823185

Epoch: 6| Step: 11
Training loss: 1.790616422569409
Validation loss: 2.7951865898363817

Epoch: 6| Step: 12
Training loss: 1.3644072683575232
Validation loss: 2.747399010437971

Epoch: 6| Step: 13
Training loss: 2.2995838618106537
Validation loss: 2.7920686778704953

Epoch: 135| Step: 0
Training loss: 0.947861568540388
Validation loss: 2.7082348267663003

Epoch: 6| Step: 1
Training loss: 2.2569165415546966
Validation loss: 2.6783914351160023

Epoch: 6| Step: 2
Training loss: 1.946793938138611
Validation loss: 2.6600400924529373

Epoch: 6| Step: 3
Training loss: 1.6367963895386881
Validation loss: 2.6453897349631545

Epoch: 6| Step: 4
Training loss: 1.5690637434343078
Validation loss: 2.6459135258654287

Epoch: 6| Step: 5
Training loss: 1.5072510617825514
Validation loss: 2.6435641723207124

Epoch: 6| Step: 6
Training loss: 1.631829801099324
Validation loss: 2.649002150036813

Epoch: 6| Step: 7
Training loss: 2.8229670408664638
Validation loss: 2.639668601830874

Epoch: 6| Step: 8
Training loss: 2.179195663035554
Validation loss: 2.624185541746698

Epoch: 6| Step: 9
Training loss: 1.8342438373105998
Validation loss: 2.5833715671868367

Epoch: 6| Step: 10
Training loss: 1.7563663892088974
Validation loss: 2.604457996603122

Epoch: 6| Step: 11
Training loss: 1.2844671471575577
Validation loss: 2.621728129586958

Epoch: 6| Step: 12
Training loss: 1.4241477492437453
Validation loss: 2.631430907686519

Epoch: 6| Step: 13
Training loss: 1.6171152587087694
Validation loss: 2.6576607641600067

Epoch: 136| Step: 0
Training loss: 1.108724967820191
Validation loss: 2.634573900973197

Epoch: 6| Step: 1
Training loss: 1.640873699411769
Validation loss: 2.7154079665128106

Epoch: 6| Step: 2
Training loss: 1.8969184229498157
Validation loss: 2.6954496413276976

Epoch: 6| Step: 3
Training loss: 1.8755464393360024
Validation loss: 2.731136896976318

Epoch: 6| Step: 4
Training loss: 1.513743067882236
Validation loss: 2.7016436242358965

Epoch: 6| Step: 5
Training loss: 2.598790430265483
Validation loss: 2.6698464320401825

Epoch: 6| Step: 6
Training loss: 1.316943503301281
Validation loss: 2.6672517437638517

Epoch: 6| Step: 7
Training loss: 1.7158638737489331
Validation loss: 2.6218055482500757

Epoch: 6| Step: 8
Training loss: 2.1360665673730823
Validation loss: 2.636967053436741

Epoch: 6| Step: 9
Training loss: 1.2171666056611086
Validation loss: 2.6480126654397913

Epoch: 6| Step: 10
Training loss: 1.4327794394636106
Validation loss: 2.627195938403536

Epoch: 6| Step: 11
Training loss: 1.776288131959587
Validation loss: 2.654468252952485

Epoch: 6| Step: 12
Training loss: 1.9716662651614083
Validation loss: 2.6449288652033114

Epoch: 6| Step: 13
Training loss: 1.7989756371469003
Validation loss: 2.6701801866221198

Epoch: 137| Step: 0
Training loss: 1.3815132546163515
Validation loss: 2.630067490435755

Epoch: 6| Step: 1
Training loss: 2.3459297724990744
Validation loss: 2.669923601426685

Epoch: 6| Step: 2
Training loss: 1.7634603684041235
Validation loss: 2.7079882010607146

Epoch: 6| Step: 3
Training loss: 1.6968330560772715
Validation loss: 2.72348705953567

Epoch: 6| Step: 4
Training loss: 1.4119941379490273
Validation loss: 2.7516037642738644

Epoch: 6| Step: 5
Training loss: 2.2115227561571635
Validation loss: 2.759525807897677

Epoch: 6| Step: 6
Training loss: 1.646131665517779
Validation loss: 2.6793077531589944

Epoch: 6| Step: 7
Training loss: 1.8215522964513744
Validation loss: 2.6603002000456635

Epoch: 6| Step: 8
Training loss: 1.1945350462289968
Validation loss: 2.6107674726533285

Epoch: 6| Step: 9
Training loss: 1.1724893104212348
Validation loss: 2.6352710055379096

Epoch: 6| Step: 10
Training loss: 2.0684412146669082
Validation loss: 2.61059747259026

Epoch: 6| Step: 11
Training loss: 2.1033310946509554
Validation loss: 2.624506873784288

Epoch: 6| Step: 12
Training loss: 1.8138706680844445
Validation loss: 2.622241296290227

Epoch: 6| Step: 13
Training loss: 1.4346513303311617
Validation loss: 2.631918546928904

Epoch: 138| Step: 0
Training loss: 1.581733581419169
Validation loss: 2.6212984963052524

Epoch: 6| Step: 1
Training loss: 1.8941781570325489
Validation loss: 2.630889477046646

Epoch: 6| Step: 2
Training loss: 1.424098110896373
Validation loss: 2.6216612124361056

Epoch: 6| Step: 3
Training loss: 1.1666626532803486
Validation loss: 2.6265856631209044

Epoch: 6| Step: 4
Training loss: 1.6678891308115906
Validation loss: 2.634874360951596

Epoch: 6| Step: 5
Training loss: 1.7660224939730382
Validation loss: 2.6553699307050262

Epoch: 6| Step: 6
Training loss: 1.2481765321533633
Validation loss: 2.717390356229534

Epoch: 6| Step: 7
Training loss: 1.514156298492546
Validation loss: 2.7048331947393223

Epoch: 6| Step: 8
Training loss: 1.5032328894076104
Validation loss: 2.7196996499173394

Epoch: 6| Step: 9
Training loss: 1.506021651691153
Validation loss: 2.685519856634922

Epoch: 6| Step: 10
Training loss: 1.6947905268681904
Validation loss: 2.7423343745907744

Epoch: 6| Step: 11
Training loss: 2.1272550846693172
Validation loss: 2.6465348392569092

Epoch: 6| Step: 12
Training loss: 1.5567236367255868
Validation loss: 2.6314833367697346

Epoch: 6| Step: 13
Training loss: 2.6772277931591146
Validation loss: 2.630153743567676

Epoch: 139| Step: 0
Training loss: 1.4860477057663648
Validation loss: 2.6124234846917016

Epoch: 6| Step: 1
Training loss: 2.3236440252524284
Validation loss: 2.6861161358074157

Epoch: 6| Step: 2
Training loss: 1.5824296614456048
Validation loss: 2.655066926068354

Epoch: 6| Step: 3
Training loss: 1.7183813913595125
Validation loss: 2.6327269980774775

Epoch: 6| Step: 4
Training loss: 1.6531383146099559
Validation loss: 2.6062268208083608

Epoch: 6| Step: 5
Training loss: 1.7091961364338186
Validation loss: 2.6975460362505475

Epoch: 6| Step: 6
Training loss: 1.647324389648139
Validation loss: 2.641976997927985

Epoch: 6| Step: 7
Training loss: 1.4481171485184234
Validation loss: 2.6683955002531543

Epoch: 6| Step: 8
Training loss: 2.113209608629987
Validation loss: 2.7339092330246295

Epoch: 6| Step: 9
Training loss: 1.3720061915066093
Validation loss: 2.6498266382311777

Epoch: 6| Step: 10
Training loss: 1.555721686589696
Validation loss: 2.6755616035248733

Epoch: 6| Step: 11
Training loss: 1.3081714461128278
Validation loss: 2.6326605567139953

Epoch: 6| Step: 12
Training loss: 1.842579098042726
Validation loss: 2.6478075086502386

Epoch: 6| Step: 13
Training loss: 1.8096419853925279
Validation loss: 2.623755954955578

Epoch: 140| Step: 0
Training loss: 1.676950611367642
Validation loss: 2.6121635536738834

Epoch: 6| Step: 1
Training loss: 1.504905547032807
Validation loss: 2.651774222156552

Epoch: 6| Step: 2
Training loss: 1.2847127873987856
Validation loss: 2.6384479193304933

Epoch: 6| Step: 3
Training loss: 2.5499434446159284
Validation loss: 2.6383702660837414

Epoch: 6| Step: 4
Training loss: 1.3945654429456522
Validation loss: 2.6543663376979025

Epoch: 6| Step: 5
Training loss: 1.0109189086336594
Validation loss: 2.7044383627163953

Epoch: 6| Step: 6
Training loss: 1.6128277083376314
Validation loss: 2.776725102809947

Epoch: 6| Step: 7
Training loss: 1.8659455706067745
Validation loss: 2.7932087686194476

Epoch: 6| Step: 8
Training loss: 1.5311940241333317
Validation loss: 2.7834332644250943

Epoch: 6| Step: 9
Training loss: 1.1530964090581342
Validation loss: 2.72920190385585

Epoch: 6| Step: 10
Training loss: 1.8178386331836955
Validation loss: 2.670224243098411

Epoch: 6| Step: 11
Training loss: 2.1976876764799975
Validation loss: 2.6613221155432205

Epoch: 6| Step: 12
Training loss: 1.5617090893781054
Validation loss: 2.649044451186883

Epoch: 6| Step: 13
Training loss: 2.153339356491751
Validation loss: 2.597381317198059

Epoch: 141| Step: 0
Training loss: 2.1440157800634614
Validation loss: 2.619617423500191

Epoch: 6| Step: 1
Training loss: 1.4016372048361938
Validation loss: 2.6849252802174113

Epoch: 6| Step: 2
Training loss: 1.0835974200240888
Validation loss: 2.676758294961972

Epoch: 6| Step: 3
Training loss: 1.351030851549769
Validation loss: 2.6150905882034556

Epoch: 6| Step: 4
Training loss: 1.5137551955394588
Validation loss: 2.611139138952843

Epoch: 6| Step: 5
Training loss: 1.7220035622678411
Validation loss: 2.648819287293852

Epoch: 6| Step: 6
Training loss: 2.440563331049569
Validation loss: 2.6367929104395262

Epoch: 6| Step: 7
Training loss: 1.6908674196755966
Validation loss: 2.6450565629666847

Epoch: 6| Step: 8
Training loss: 2.3418361733696984
Validation loss: 2.677477949771739

Epoch: 6| Step: 9
Training loss: 1.3563757508514607
Validation loss: 2.742475054409248

Epoch: 6| Step: 10
Training loss: 2.0907180240844747
Validation loss: 2.745336110638268

Epoch: 6| Step: 11
Training loss: 1.8824769033608386
Validation loss: 2.7325372242115313

Epoch: 6| Step: 12
Training loss: 1.5509751052186675
Validation loss: 2.6846610311012173

Epoch: 6| Step: 13
Training loss: 0.87927577409884
Validation loss: 2.642396592180328

Epoch: 142| Step: 0
Training loss: 1.558300325312688
Validation loss: 2.6605730369774

Epoch: 6| Step: 1
Training loss: 1.7109636975377334
Validation loss: 2.6405052142841496

Epoch: 6| Step: 2
Training loss: 1.8405102860822153
Validation loss: 2.688118205567091

Epoch: 6| Step: 3
Training loss: 2.127924197410024
Validation loss: 2.6842929867527237

Epoch: 6| Step: 4
Training loss: 1.6349229816646844
Validation loss: 2.6702859328488344

Epoch: 6| Step: 5
Training loss: 1.4772402706448826
Validation loss: 2.6288115364837736

Epoch: 6| Step: 6
Training loss: 1.6604312444579032
Validation loss: 2.6343237127136208

Epoch: 6| Step: 7
Training loss: 1.7084135486409406
Validation loss: 2.6813094380747895

Epoch: 6| Step: 8
Training loss: 1.3340822242606551
Validation loss: 2.6492489122229705

Epoch: 6| Step: 9
Training loss: 1.0515237333455392
Validation loss: 2.6279953714849627

Epoch: 6| Step: 10
Training loss: 1.357432501223021
Validation loss: 2.7427474389413575

Epoch: 6| Step: 11
Training loss: 1.6797180882707201
Validation loss: 2.767042884946523

Epoch: 6| Step: 12
Training loss: 1.6431866946124656
Validation loss: 2.7681084095456367

Epoch: 6| Step: 13
Training loss: 2.3333572886009315
Validation loss: 2.845979508257162

Epoch: 143| Step: 0
Training loss: 0.9894623464944535
Validation loss: 2.8195928921844486

Epoch: 6| Step: 1
Training loss: 2.265068459391994
Validation loss: 2.8152990329615255

Epoch: 6| Step: 2
Training loss: 1.4926934308277366
Validation loss: 2.7873962867727227

Epoch: 6| Step: 3
Training loss: 1.6665035485871649
Validation loss: 2.7774261161941567

Epoch: 6| Step: 4
Training loss: 1.6284122587043817
Validation loss: 2.6843383437212194

Epoch: 6| Step: 5
Training loss: 2.701481402157867
Validation loss: 2.7156304187084084

Epoch: 6| Step: 6
Training loss: 1.706514607686365
Validation loss: 2.6482176712911607

Epoch: 6| Step: 7
Training loss: 1.6092241086869692
Validation loss: 2.6565258930015885

Epoch: 6| Step: 8
Training loss: 1.1222683272842076
Validation loss: 2.635217897862892

Epoch: 6| Step: 9
Training loss: 1.8043384296977873
Validation loss: 2.655364752963886

Epoch: 6| Step: 10
Training loss: 1.2761793049390815
Validation loss: 2.6040439627667524

Epoch: 6| Step: 11
Training loss: 1.3036996448042049
Validation loss: 2.621658074942267

Epoch: 6| Step: 12
Training loss: 1.7467584560872615
Validation loss: 2.5993947877502976

Epoch: 6| Step: 13
Training loss: 1.2931694497331998
Validation loss: 2.6529171697888607

Epoch: 144| Step: 0
Training loss: 1.389273511823902
Validation loss: 2.6658665504743193

Epoch: 6| Step: 1
Training loss: 2.0034110068921507
Validation loss: 2.6701253921791612

Epoch: 6| Step: 2
Training loss: 1.7447889944786752
Validation loss: 2.65326692211324

Epoch: 6| Step: 3
Training loss: 1.7335170651529195
Validation loss: 2.6484164871987637

Epoch: 6| Step: 4
Training loss: 1.4913919934749864
Validation loss: 2.639119714267689

Epoch: 6| Step: 5
Training loss: 1.293816694669031
Validation loss: 2.6603594388211094

Epoch: 6| Step: 6
Training loss: 1.8458581284119886
Validation loss: 2.686773941376826

Epoch: 6| Step: 7
Training loss: 1.9260127487473706
Validation loss: 2.741844373140221

Epoch: 6| Step: 8
Training loss: 0.8857958187534287
Validation loss: 2.76551659150665

Epoch: 6| Step: 9
Training loss: 1.5160625651994448
Validation loss: 2.6973907124957552

Epoch: 6| Step: 10
Training loss: 1.1577273029894208
Validation loss: 2.77469141736495

Epoch: 6| Step: 11
Training loss: 2.5236948549349614
Validation loss: 2.7398763192935616

Epoch: 6| Step: 12
Training loss: 1.5508767201898437
Validation loss: 2.6827493122874784

Epoch: 6| Step: 13
Training loss: 1.1447023647883436
Validation loss: 2.7301135034452564

Epoch: 145| Step: 0
Training loss: 1.6838215189289012
Validation loss: 2.703547861764771

Epoch: 6| Step: 1
Training loss: 1.1263078399099486
Validation loss: 2.628648100029956

Epoch: 6| Step: 2
Training loss: 1.7300861013077449
Validation loss: 2.6746225488864863

Epoch: 6| Step: 3
Training loss: 1.5647137028424059
Validation loss: 2.7090258862157617

Epoch: 6| Step: 4
Training loss: 1.6950533620485995
Validation loss: 2.654635638171421

Epoch: 6| Step: 5
Training loss: 1.4973101339833046
Validation loss: 2.6060492818675747

Epoch: 6| Step: 6
Training loss: 1.6196701233167414
Validation loss: 2.669515523472533

Epoch: 6| Step: 7
Training loss: 1.2660487843013621
Validation loss: 2.6416590394673114

Epoch: 6| Step: 8
Training loss: 2.4442861920002987
Validation loss: 2.6724742789914613

Epoch: 6| Step: 9
Training loss: 1.2906632166046605
Validation loss: 2.6357609419681354

Epoch: 6| Step: 10
Training loss: 1.3121942436479228
Validation loss: 2.678975462035658

Epoch: 6| Step: 11
Training loss: 1.82108117111097
Validation loss: 2.6872948708724493

Epoch: 6| Step: 12
Training loss: 1.5121499562909324
Validation loss: 2.7174251880191806

Epoch: 6| Step: 13
Training loss: 1.6303150113660245
Validation loss: 2.719241591109215

Epoch: 146| Step: 0
Training loss: 1.360560546946496
Validation loss: 2.6871239672633984

Epoch: 6| Step: 1
Training loss: 1.599620777131409
Validation loss: 2.604783531879422

Epoch: 6| Step: 2
Training loss: 1.253961484649158
Validation loss: 2.648082142923433

Epoch: 6| Step: 3
Training loss: 2.0326498050075825
Validation loss: 2.655538126978306

Epoch: 6| Step: 4
Training loss: 1.7698280472933194
Validation loss: 2.6091697140041

Epoch: 6| Step: 5
Training loss: 1.366226163483441
Validation loss: 2.721206111013749

Epoch: 6| Step: 6
Training loss: 1.492215540757271
Validation loss: 2.6455091943710247

Epoch: 6| Step: 7
Training loss: 1.4051763886745943
Validation loss: 2.662720201308321

Epoch: 6| Step: 8
Training loss: 1.7260050844756345
Validation loss: 2.696432070938866

Epoch: 6| Step: 9
Training loss: 1.439109067546542
Validation loss: 2.6870253239838946

Epoch: 6| Step: 10
Training loss: 1.6866520764671002
Validation loss: 2.6399800794023265

Epoch: 6| Step: 11
Training loss: 1.6033818029953932
Validation loss: 2.6170966516925263

Epoch: 6| Step: 12
Training loss: 2.254860396705386
Validation loss: 2.6479061947867364

Epoch: 6| Step: 13
Training loss: 1.3491184429262775
Validation loss: 2.6504589307206188

Epoch: 147| Step: 0
Training loss: 1.8806944524251057
Validation loss: 2.6280687952854453

Epoch: 6| Step: 1
Training loss: 2.363753039974878
Validation loss: 2.639047245382816

Epoch: 6| Step: 2
Training loss: 1.248985307840715
Validation loss: 2.6954592752344504

Epoch: 6| Step: 3
Training loss: 1.264308433043797
Validation loss: 2.6443109087148478

Epoch: 6| Step: 4
Training loss: 1.2272073787733462
Validation loss: 2.654701858849898

Epoch: 6| Step: 5
Training loss: 1.5612973734843394
Validation loss: 2.6681041320141987

Epoch: 6| Step: 6
Training loss: 1.349017751948779
Validation loss: 2.666868996891679

Epoch: 6| Step: 7
Training loss: 1.7236350948329435
Validation loss: 2.6942824602321727

Epoch: 6| Step: 8
Training loss: 1.680194015426158
Validation loss: 2.707828186071901

Epoch: 6| Step: 9
Training loss: 1.7008810396931775
Validation loss: 2.646852031849814

Epoch: 6| Step: 10
Training loss: 0.9111598952214887
Validation loss: 2.7315252513096557

Epoch: 6| Step: 11
Training loss: 1.761191684686116
Validation loss: 2.743442433004423

Epoch: 6| Step: 12
Training loss: 1.5036159482901186
Validation loss: 2.744677797642244

Epoch: 6| Step: 13
Training loss: 1.6212793450799017
Validation loss: 2.645504861001318

Epoch: 148| Step: 0
Training loss: 1.1622627221238093
Validation loss: 2.6628544847556803

Epoch: 6| Step: 1
Training loss: 1.3371851933854568
Validation loss: 2.6958593136352613

Epoch: 6| Step: 2
Training loss: 1.557599278649005
Validation loss: 2.6904800142633984

Epoch: 6| Step: 3
Training loss: 2.3434127564986404
Validation loss: 2.708200074854458

Epoch: 6| Step: 4
Training loss: 1.229159867003863
Validation loss: 2.6606768949569024

Epoch: 6| Step: 5
Training loss: 1.4365701570570268
Validation loss: 2.66809433231465

Epoch: 6| Step: 6
Training loss: 1.9822714762645863
Validation loss: 2.612487733316294

Epoch: 6| Step: 7
Training loss: 1.1524186966656786
Validation loss: 2.629945380534533

Epoch: 6| Step: 8
Training loss: 1.2038716563131917
Validation loss: 2.653394697819989

Epoch: 6| Step: 9
Training loss: 0.8478158194128592
Validation loss: 2.6486171110121135

Epoch: 6| Step: 10
Training loss: 1.8992076928379023
Validation loss: 2.6845361349632264

Epoch: 6| Step: 11
Training loss: 1.8807800212848804
Validation loss: 2.7083328662774098

Epoch: 6| Step: 12
Training loss: 1.769555771680948
Validation loss: 2.65998011457329

Epoch: 6| Step: 13
Training loss: 1.0867714732672282
Validation loss: 2.6887603214644544

Epoch: 149| Step: 0
Training loss: 1.4519635552910943
Validation loss: 2.695373829314332

Epoch: 6| Step: 1
Training loss: 1.3578529167525197
Validation loss: 2.6611306473376133

Epoch: 6| Step: 2
Training loss: 1.5668232426960416
Validation loss: 2.6972450146910867

Epoch: 6| Step: 3
Training loss: 1.7548661016264036
Validation loss: 2.685248533381032

Epoch: 6| Step: 4
Training loss: 1.772309738730101
Validation loss: 2.670609529573778

Epoch: 6| Step: 5
Training loss: 1.3882361478246685
Validation loss: 2.729111187980078

Epoch: 6| Step: 6
Training loss: 1.4347065860224084
Validation loss: 2.6944020525775363

Epoch: 6| Step: 7
Training loss: 1.6978128865671798
Validation loss: 2.73518297882807

Epoch: 6| Step: 8
Training loss: 2.3116205966193597
Validation loss: 2.6929521038358772

Epoch: 6| Step: 9
Training loss: 1.4477683158273207
Validation loss: 2.701269023451103

Epoch: 6| Step: 10
Training loss: 1.5308200466110318
Validation loss: 2.6874222855088132

Epoch: 6| Step: 11
Training loss: 0.688131908967608
Validation loss: 2.7294334155074975

Epoch: 6| Step: 12
Training loss: 1.702876081562518
Validation loss: 2.697250008911921

Epoch: 6| Step: 13
Training loss: 1.0072431508596191
Validation loss: 2.7083747616069096

Epoch: 150| Step: 0
Training loss: 1.8582452499429527
Validation loss: 2.6984175336195175

Epoch: 6| Step: 1
Training loss: 1.285952057877708
Validation loss: 2.6327102445069377

Epoch: 6| Step: 2
Training loss: 1.7685467337013994
Validation loss: 2.6551826426920737

Epoch: 6| Step: 3
Training loss: 1.4404621288719657
Validation loss: 2.6649266814881263

Epoch: 6| Step: 4
Training loss: 1.837311964729263
Validation loss: 2.6619735985413255

Epoch: 6| Step: 5
Training loss: 1.5470773583805435
Validation loss: 2.687266605799666

Epoch: 6| Step: 6
Training loss: 1.7039564710349513
Validation loss: 2.718515378686699

Epoch: 6| Step: 7
Training loss: 1.472208212939771
Validation loss: 2.7209654218576516

Epoch: 6| Step: 8
Training loss: 1.2005650421851237
Validation loss: 2.715392015747296

Epoch: 6| Step: 9
Training loss: 1.233599310410031
Validation loss: 2.6770570409846757

Epoch: 6| Step: 10
Training loss: 1.2765265600965368
Validation loss: 2.6568934839252245

Epoch: 6| Step: 11
Training loss: 2.132769350167332
Validation loss: 2.7345780215506514

Epoch: 6| Step: 12
Training loss: 1.2769461196609235
Validation loss: 2.741875307401801

Epoch: 6| Step: 13
Training loss: 1.0695613257761087
Validation loss: 2.6665724101892585

Epoch: 151| Step: 0
Training loss: 1.3506732286335896
Validation loss: 2.713767297971638

Epoch: 6| Step: 1
Training loss: 1.3827667228751013
Validation loss: 2.7624333961938676

Epoch: 6| Step: 2
Training loss: 1.5928233575628614
Validation loss: 2.6775968383221804

Epoch: 6| Step: 3
Training loss: 1.8076789140595322
Validation loss: 2.7346403447333127

Epoch: 6| Step: 4
Training loss: 1.4545379660153523
Validation loss: 2.799415315594813

Epoch: 6| Step: 5
Training loss: 1.4689812985366557
Validation loss: 2.7215466785631706

Epoch: 6| Step: 6
Training loss: 1.4728900106662777
Validation loss: 2.7018795635612234

Epoch: 6| Step: 7
Training loss: 1.5205971085843653
Validation loss: 2.6791089678098823

Epoch: 6| Step: 8
Training loss: 1.2091201434835015
Validation loss: 2.66833390827002

Epoch: 6| Step: 9
Training loss: 1.4697087993372167
Validation loss: 2.7078785490010318

Epoch: 6| Step: 10
Training loss: 1.2776536478111973
Validation loss: 2.7366644293914955

Epoch: 6| Step: 11
Training loss: 1.3997357698137247
Validation loss: 2.725775370979183

Epoch: 6| Step: 12
Training loss: 1.7315748825690709
Validation loss: 2.73492084686187

Epoch: 6| Step: 13
Training loss: 2.306027090987106
Validation loss: 2.660389296695337

Epoch: 152| Step: 0
Training loss: 1.0919651181654848
Validation loss: 2.767593028392521

Epoch: 6| Step: 1
Training loss: 1.7429858375713685
Validation loss: 2.737020582375137

Epoch: 6| Step: 2
Training loss: 2.295743391025605
Validation loss: 2.706646046426836

Epoch: 6| Step: 3
Training loss: 1.37450972399389
Validation loss: 2.718709835764299

Epoch: 6| Step: 4
Training loss: 0.8434148405351994
Validation loss: 2.720887173581939

Epoch: 6| Step: 5
Training loss: 1.975275517814377
Validation loss: 2.710662520036592

Epoch: 6| Step: 6
Training loss: 1.6758613478362794
Validation loss: 2.749184921156249

Epoch: 6| Step: 7
Training loss: 1.3470600080766622
Validation loss: 2.684865510450504

Epoch: 6| Step: 8
Training loss: 1.2098290076694564
Validation loss: 2.7132288239321496

Epoch: 6| Step: 9
Training loss: 1.5874394412767592
Validation loss: 2.672834331961915

Epoch: 6| Step: 10
Training loss: 1.730748345583244
Validation loss: 2.731142760382161

Epoch: 6| Step: 11
Training loss: 1.166891309136876
Validation loss: 2.656899107365495

Epoch: 6| Step: 12
Training loss: 1.4518798087110625
Validation loss: 2.626863983419212

Epoch: 6| Step: 13
Training loss: 1.3308535204849032
Validation loss: 2.653993455893146

Epoch: 153| Step: 0
Training loss: 1.1007483429386196
Validation loss: 2.702061056036919

Epoch: 6| Step: 1
Training loss: 1.5816868536692301
Validation loss: 2.700557143219552

Epoch: 6| Step: 2
Training loss: 1.1560829660547098
Validation loss: 2.7141957339810334

Epoch: 6| Step: 3
Training loss: 1.506830241402066
Validation loss: 2.7947139240551144

Epoch: 6| Step: 4
Training loss: 1.1840003797556293
Validation loss: 2.755342942947563

Epoch: 6| Step: 5
Training loss: 1.1046691267112394
Validation loss: 2.7861523516683273

Epoch: 6| Step: 6
Training loss: 0.9279596316276104
Validation loss: 2.8305296957747896

Epoch: 6| Step: 7
Training loss: 1.1746580519134795
Validation loss: 2.748068456287137

Epoch: 6| Step: 8
Training loss: 1.5610486728917081
Validation loss: 2.781461386201888

Epoch: 6| Step: 9
Training loss: 1.7659760522827959
Validation loss: 2.686361973841263

Epoch: 6| Step: 10
Training loss: 2.092436193224846
Validation loss: 2.6857327557593447

Epoch: 6| Step: 11
Training loss: 2.409559871641378
Validation loss: 2.699016719899655

Epoch: 6| Step: 12
Training loss: 1.3377714006526125
Validation loss: 2.655526575048301

Epoch: 6| Step: 13
Training loss: 1.2434024746993388
Validation loss: 2.632471094531274

Epoch: 154| Step: 0
Training loss: 1.3706430851986482
Validation loss: 2.673549253950934

Epoch: 6| Step: 1
Training loss: 1.5467572408222736
Validation loss: 2.6370448986894517

Epoch: 6| Step: 2
Training loss: 1.3725492571415148
Validation loss: 2.6463531874532427

Epoch: 6| Step: 3
Training loss: 1.4463002721543983
Validation loss: 2.6516129203622785

Epoch: 6| Step: 4
Training loss: 1.0787599324888553
Validation loss: 2.690425684949571

Epoch: 6| Step: 5
Training loss: 1.5298212353359986
Validation loss: 2.6613336273857646

Epoch: 6| Step: 6
Training loss: 1.5087723123058892
Validation loss: 2.6789201503395628

Epoch: 6| Step: 7
Training loss: 1.3668173588659362
Validation loss: 2.752103102500154

Epoch: 6| Step: 8
Training loss: 1.7820268242098292
Validation loss: 2.823321624275197

Epoch: 6| Step: 9
Training loss: 1.6832033488002796
Validation loss: 2.8022392943324643

Epoch: 6| Step: 10
Training loss: 1.6065112068552354
Validation loss: 2.720068111466802

Epoch: 6| Step: 11
Training loss: 2.099599836460891
Validation loss: 2.7687548296493762

Epoch: 6| Step: 12
Training loss: 1.477622968329758
Validation loss: 2.7217190779221814

Epoch: 6| Step: 13
Training loss: 1.6915734188644285
Validation loss: 2.6894205165743243

Epoch: 155| Step: 0
Training loss: 1.5725401455071242
Validation loss: 2.6521845953808465

Epoch: 6| Step: 1
Training loss: 1.0774223691762006
Validation loss: 2.717802167515119

Epoch: 6| Step: 2
Training loss: 1.3242029509825637
Validation loss: 2.6956804696972587

Epoch: 6| Step: 3
Training loss: 1.5498493767432469
Validation loss: 2.7084213291447057

Epoch: 6| Step: 4
Training loss: 1.202553551447045
Validation loss: 2.7049428600732757

Epoch: 6| Step: 5
Training loss: 1.3083955984829345
Validation loss: 2.6878842663136515

Epoch: 6| Step: 6
Training loss: 1.6556297436390968
Validation loss: 2.7611709475882913

Epoch: 6| Step: 7
Training loss: 1.417865255482935
Validation loss: 2.7633700040800657

Epoch: 6| Step: 8
Training loss: 1.971242144755869
Validation loss: 2.785812807029381

Epoch: 6| Step: 9
Training loss: 2.266438094937427
Validation loss: 2.718497450926461

Epoch: 6| Step: 10
Training loss: 1.289853679727356
Validation loss: 2.642848852198594

Epoch: 6| Step: 11
Training loss: 1.508336109699764
Validation loss: 2.6441597839644193

Epoch: 6| Step: 12
Training loss: 0.9108004929909358
Validation loss: 2.6748191718899768

Epoch: 6| Step: 13
Training loss: 1.5639139263000128
Validation loss: 2.629764607584008

Epoch: 156| Step: 0
Training loss: 1.6707378334790841
Validation loss: 2.6416759318320633

Epoch: 6| Step: 1
Training loss: 1.5062644008090522
Validation loss: 2.6997405604530016

Epoch: 6| Step: 2
Training loss: 1.2680293662765165
Validation loss: 2.7022770634018065

Epoch: 6| Step: 3
Training loss: 1.4356743373206844
Validation loss: 2.678817763581775

Epoch: 6| Step: 4
Training loss: 1.1279580116844097
Validation loss: 2.6749151531322832

Epoch: 6| Step: 5
Training loss: 2.370347334442967
Validation loss: 2.7092733121369243

Epoch: 6| Step: 6
Training loss: 1.7477007475275408
Validation loss: 2.737525991783829

Epoch: 6| Step: 7
Training loss: 1.3938236525024275
Validation loss: 2.791078908926709

Epoch: 6| Step: 8
Training loss: 1.1565199871851186
Validation loss: 2.715644392698613

Epoch: 6| Step: 9
Training loss: 0.947242091564954
Validation loss: 2.792683947431921

Epoch: 6| Step: 10
Training loss: 1.4760824563531305
Validation loss: 2.7898272437386535

Epoch: 6| Step: 11
Training loss: 1.3524865315836732
Validation loss: 2.696902380222674

Epoch: 6| Step: 12
Training loss: 1.5739554286738955
Validation loss: 2.700546872716354

Epoch: 6| Step: 13
Training loss: 1.5351885532542797
Validation loss: 2.7127304817172284

Epoch: 157| Step: 0
Training loss: 1.2142950456324835
Validation loss: 2.744969318197577

Epoch: 6| Step: 1
Training loss: 1.4608384369091678
Validation loss: 2.690402348928138

Epoch: 6| Step: 2
Training loss: 1.4034591956490678
Validation loss: 2.658791511736465

Epoch: 6| Step: 3
Training loss: 1.7863800728637598
Validation loss: 2.7413218871810323

Epoch: 6| Step: 4
Training loss: 1.475130547387565
Validation loss: 2.7015214989372893

Epoch: 6| Step: 5
Training loss: 1.3036467461373882
Validation loss: 2.6992648866485602

Epoch: 6| Step: 6
Training loss: 1.119056578670837
Validation loss: 2.677696563505679

Epoch: 6| Step: 7
Training loss: 1.218539880099166
Validation loss: 2.7360677656515207

Epoch: 6| Step: 8
Training loss: 2.1515386221342623
Validation loss: 2.6508800005130286

Epoch: 6| Step: 9
Training loss: 1.3329701624433434
Validation loss: 2.6742550695049774

Epoch: 6| Step: 10
Training loss: 1.148530346497321
Validation loss: 2.7049340752578965

Epoch: 6| Step: 11
Training loss: 1.6421585908009337
Validation loss: 2.7128981536841326

Epoch: 6| Step: 12
Training loss: 1.257841785161072
Validation loss: 2.6451150539952653

Epoch: 6| Step: 13
Training loss: 1.3101282488674648
Validation loss: 2.6923913873686525

Epoch: 158| Step: 0
Training loss: 1.071820276047873
Validation loss: 2.612624028256627

Epoch: 6| Step: 1
Training loss: 1.3367163635268275
Validation loss: 2.698888490735831

Epoch: 6| Step: 2
Training loss: 1.7821129833243603
Validation loss: 2.67759704608684

Epoch: 6| Step: 3
Training loss: 1.7753743757421272
Validation loss: 2.68439187106366

Epoch: 6| Step: 4
Training loss: 2.3192053828387182
Validation loss: 2.642489600737051

Epoch: 6| Step: 5
Training loss: 1.3433187369333746
Validation loss: 2.6387234373817257

Epoch: 6| Step: 6
Training loss: 1.0809428666338077
Validation loss: 2.6980879936658333

Epoch: 6| Step: 7
Training loss: 1.422744568917126
Validation loss: 2.664485729976044

Epoch: 6| Step: 8
Training loss: 1.2366946672900954
Validation loss: 2.717968576315589

Epoch: 6| Step: 9
Training loss: 1.1588302895589973
Validation loss: 2.6799125169121107

Epoch: 6| Step: 10
Training loss: 1.1786452988597935
Validation loss: 2.7727759776738754

Epoch: 6| Step: 11
Training loss: 1.3059285822497917
Validation loss: 2.717076528285521

Epoch: 6| Step: 12
Training loss: 1.5820910783922553
Validation loss: 2.7325725027635213

Epoch: 6| Step: 13
Training loss: 1.1578785536401728
Validation loss: 2.720022261939855

Epoch: 159| Step: 0
Training loss: 0.9253741950866752
Validation loss: 2.7601787944484495

Epoch: 6| Step: 1
Training loss: 2.3904023908304413
Validation loss: 2.7012196700031974

Epoch: 6| Step: 2
Training loss: 1.5382679083823416
Validation loss: 2.721777724503415

Epoch: 6| Step: 3
Training loss: 1.5503706304366647
Validation loss: 2.7047788084864015

Epoch: 6| Step: 4
Training loss: 0.9435610032467386
Validation loss: 2.6579979624208208

Epoch: 6| Step: 5
Training loss: 1.454419287715045
Validation loss: 2.66075831773361

Epoch: 6| Step: 6
Training loss: 1.541425411145872
Validation loss: 2.6994746556588742

Epoch: 6| Step: 7
Training loss: 1.5116416260910523
Validation loss: 2.7120502983969064

Epoch: 6| Step: 8
Training loss: 1.0925841521232245
Validation loss: 2.649799308135003

Epoch: 6| Step: 9
Training loss: 1.512106912148238
Validation loss: 2.7060550032117243

Epoch: 6| Step: 10
Training loss: 0.7376415569423406
Validation loss: 2.8041734994821117

Epoch: 6| Step: 11
Training loss: 1.5329686076613556
Validation loss: 2.7552093092418497

Epoch: 6| Step: 12
Training loss: 1.592031562214352
Validation loss: 2.7651347212481383

Epoch: 6| Step: 13
Training loss: 1.2456448024280107
Validation loss: 2.6892494303668513

Epoch: 160| Step: 0
Training loss: 0.9422562430183304
Validation loss: 2.7249555689137983

Epoch: 6| Step: 1
Training loss: 1.4405756679206
Validation loss: 2.67537130292325

Epoch: 6| Step: 2
Training loss: 1.24889210240896
Validation loss: 2.742640806516956

Epoch: 6| Step: 3
Training loss: 1.033518867346294
Validation loss: 2.661550506568358

Epoch: 6| Step: 4
Training loss: 2.182209702244565
Validation loss: 2.6789224346210063

Epoch: 6| Step: 5
Training loss: 1.1393783236155368
Validation loss: 2.6950345471939214

Epoch: 6| Step: 6
Training loss: 1.4102029977589416
Validation loss: 2.74691031024271

Epoch: 6| Step: 7
Training loss: 1.3147163297639943
Validation loss: 2.680621622904225

Epoch: 6| Step: 8
Training loss: 0.912401663040843
Validation loss: 2.7397302411702382

Epoch: 6| Step: 9
Training loss: 0.9240941638443146
Validation loss: 2.694578267954858

Epoch: 6| Step: 10
Training loss: 1.9475402332307516
Validation loss: 2.705484305137033

Epoch: 6| Step: 11
Training loss: 1.5317108083735262
Validation loss: 2.6961134158293896

Epoch: 6| Step: 12
Training loss: 1.7844823320646601
Validation loss: 2.776992396482435

Epoch: 6| Step: 13
Training loss: 1.3461415057088273
Validation loss: 2.780401521909507

Epoch: 161| Step: 0
Training loss: 2.0825333267237967
Validation loss: 2.7504856518864287

Epoch: 6| Step: 1
Training loss: 1.3231277247397686
Validation loss: 2.7762955674129364

Epoch: 6| Step: 2
Training loss: 1.4576059798221637
Validation loss: 2.7339665135033013

Epoch: 6| Step: 3
Training loss: 1.2927133359768712
Validation loss: 2.7516490153673256

Epoch: 6| Step: 4
Training loss: 0.9112846354324249
Validation loss: 2.743692157341305

Epoch: 6| Step: 5
Training loss: 1.1855110778934566
Validation loss: 2.749605237196551

Epoch: 6| Step: 6
Training loss: 1.458501243007524
Validation loss: 2.725894587485608

Epoch: 6| Step: 7
Training loss: 0.9115326260760961
Validation loss: 2.725773548725066

Epoch: 6| Step: 8
Training loss: 0.9744869300509935
Validation loss: 2.739728863311306

Epoch: 6| Step: 9
Training loss: 1.248679226233894
Validation loss: 2.816699742418317

Epoch: 6| Step: 10
Training loss: 1.4858155337879453
Validation loss: 2.8709227772709567

Epoch: 6| Step: 11
Training loss: 1.7966561225600586
Validation loss: 2.754604472933842

Epoch: 6| Step: 12
Training loss: 1.2369536012383473
Validation loss: 2.7411401384137317

Epoch: 6| Step: 13
Training loss: 1.9500223158513124
Validation loss: 2.66796717869427

Epoch: 162| Step: 0
Training loss: 0.9209429668449357
Validation loss: 2.705855194377868

Epoch: 6| Step: 1
Training loss: 1.142728459828056
Validation loss: 2.6863988350330072

Epoch: 6| Step: 2
Training loss: 1.3976325590152554
Validation loss: 2.677922281896737

Epoch: 6| Step: 3
Training loss: 1.2849239614825432
Validation loss: 2.654480617844992

Epoch: 6| Step: 4
Training loss: 1.0163675381488944
Validation loss: 2.603107165656757

Epoch: 6| Step: 5
Training loss: 1.6698307124011114
Validation loss: 2.6577469590598204

Epoch: 6| Step: 6
Training loss: 1.7165450778356923
Validation loss: 2.641004681800815

Epoch: 6| Step: 7
Training loss: 1.4978144936694562
Validation loss: 2.6510745622933483

Epoch: 6| Step: 8
Training loss: 1.7673774057306235
Validation loss: 2.6433591062180066

Epoch: 6| Step: 9
Training loss: 1.323165024200226
Validation loss: 2.7335740433126414

Epoch: 6| Step: 10
Training loss: 1.2240569649854365
Validation loss: 2.6669183825860716

Epoch: 6| Step: 11
Training loss: 0.9263977380323878
Validation loss: 2.6827598879140795

Epoch: 6| Step: 12
Training loss: 0.8642838813600167
Validation loss: 2.769353605311285

Epoch: 6| Step: 13
Training loss: 2.2181779365747203
Validation loss: 2.773964444100132

Epoch: 163| Step: 0
Training loss: 1.027487393044309
Validation loss: 2.8288971284236246

Epoch: 6| Step: 1
Training loss: 2.203591912755773
Validation loss: 2.7939752645797085

Epoch: 6| Step: 2
Training loss: 2.0655640470482863
Validation loss: 2.774568812346671

Epoch: 6| Step: 3
Training loss: 1.052027194095908
Validation loss: 2.7612005572240594

Epoch: 6| Step: 4
Training loss: 1.4986960783637002
Validation loss: 2.711243127603411

Epoch: 6| Step: 5
Training loss: 1.0094119251217224
Validation loss: 2.7543828024341446

Epoch: 6| Step: 6
Training loss: 1.2994320032075872
Validation loss: 2.6900746927680848

Epoch: 6| Step: 7
Training loss: 1.1276409621839
Validation loss: 2.6739891715228747

Epoch: 6| Step: 8
Training loss: 1.4163309522288408
Validation loss: 2.656535548401117

Epoch: 6| Step: 9
Training loss: 0.8958084450450782
Validation loss: 2.6824093666301647

Epoch: 6| Step: 10
Training loss: 1.4223321871333081
Validation loss: 2.7250683469687957

Epoch: 6| Step: 11
Training loss: 0.9308328385438575
Validation loss: 2.6970645535873716

Epoch: 6| Step: 12
Training loss: 1.34303189096485
Validation loss: 2.7282510682436616

Epoch: 6| Step: 13
Training loss: 1.5264133439068557
Validation loss: 2.7259704909011386

Epoch: 164| Step: 0
Training loss: 0.8908809494862553
Validation loss: 2.725359544744936

Epoch: 6| Step: 1
Training loss: 1.4200514953302392
Validation loss: 2.7473497046384217

Epoch: 6| Step: 2
Training loss: 1.1213397776236709
Validation loss: 2.7580440089066594

Epoch: 6| Step: 3
Training loss: 1.288717512725811
Validation loss: 2.7327873779910297

Epoch: 6| Step: 4
Training loss: 1.1355251062154914
Validation loss: 2.7280909017243147

Epoch: 6| Step: 5
Training loss: 1.7732655446043348
Validation loss: 2.754342573514721

Epoch: 6| Step: 6
Training loss: 1.3379003371282978
Validation loss: 2.742088642131646

Epoch: 6| Step: 7
Training loss: 1.079842346835201
Validation loss: 2.74379847374388

Epoch: 6| Step: 8
Training loss: 1.5032859414716058
Validation loss: 2.8045905618022355

Epoch: 6| Step: 9
Training loss: 1.3651217303649517
Validation loss: 2.7351633733739984

Epoch: 6| Step: 10
Training loss: 1.353466258724448
Validation loss: 2.671982196048043

Epoch: 6| Step: 11
Training loss: 1.6440350651586455
Validation loss: 2.6962418875043883

Epoch: 6| Step: 12
Training loss: 1.0960266397259757
Validation loss: 2.6534379622502775

Epoch: 6| Step: 13
Training loss: 2.1286375663664616
Validation loss: 2.721050969562517

Epoch: 165| Step: 0
Training loss: 1.107789424338465
Validation loss: 2.6747997999291706

Epoch: 6| Step: 1
Training loss: 1.2567328801321744
Validation loss: 2.6886707535537746

Epoch: 6| Step: 2
Training loss: 1.2164191919715088
Validation loss: 2.673594168957512

Epoch: 6| Step: 3
Training loss: 1.6223178148773014
Validation loss: 2.700969358379391

Epoch: 6| Step: 4
Training loss: 1.172656904674045
Validation loss: 2.7235493228298666

Epoch: 6| Step: 5
Training loss: 0.8729995953688935
Validation loss: 2.7714028645546542

Epoch: 6| Step: 6
Training loss: 1.272884927698369
Validation loss: 2.734085896058677

Epoch: 6| Step: 7
Training loss: 1.6061002134550635
Validation loss: 2.7299969747198203

Epoch: 6| Step: 8
Training loss: 1.2773366105466333
Validation loss: 2.75370859289012

Epoch: 6| Step: 9
Training loss: 1.3706570443348747
Validation loss: 2.7068550672716922

Epoch: 6| Step: 10
Training loss: 2.091079945236869
Validation loss: 2.7262139156751424

Epoch: 6| Step: 11
Training loss: 0.9627119598837687
Validation loss: 2.651109860685419

Epoch: 6| Step: 12
Training loss: 1.4510195666307748
Validation loss: 2.727647676546382

Epoch: 6| Step: 13
Training loss: 1.1789909984545899
Validation loss: 2.7006075461042194

Epoch: 166| Step: 0
Training loss: 1.2340767415573208
Validation loss: 2.7125341457204217

Epoch: 6| Step: 1
Training loss: 1.3107117777971542
Validation loss: 2.746486268585193

Epoch: 6| Step: 2
Training loss: 1.4712970643792507
Validation loss: 2.751566787361128

Epoch: 6| Step: 3
Training loss: 2.1702463094615987
Validation loss: 2.7020019226829755

Epoch: 6| Step: 4
Training loss: 1.0772406226489433
Validation loss: 2.756899083551999

Epoch: 6| Step: 5
Training loss: 1.3925794946522017
Validation loss: 2.74906967060969

Epoch: 6| Step: 6
Training loss: 1.7473699697597707
Validation loss: 2.738331749378318

Epoch: 6| Step: 7
Training loss: 1.1021167632274664
Validation loss: 2.8268870811027136

Epoch: 6| Step: 8
Training loss: 1.0119539672310884
Validation loss: 2.7649063211061597

Epoch: 6| Step: 9
Training loss: 1.5153328525516156
Validation loss: 2.7990400008304968

Epoch: 6| Step: 10
Training loss: 1.2629513226549929
Validation loss: 2.8113518101931807

Epoch: 6| Step: 11
Training loss: 1.3653189833459396
Validation loss: 2.7815092016014518

Epoch: 6| Step: 12
Training loss: 0.936948232403401
Validation loss: 2.7264873490638473

Epoch: 6| Step: 13
Training loss: 1.256745448556326
Validation loss: 2.704795732688791

Epoch: 167| Step: 0
Training loss: 1.2014748788144938
Validation loss: 2.665924227199351

Epoch: 6| Step: 1
Training loss: 1.3566092933751508
Validation loss: 2.6661160367470775

Epoch: 6| Step: 2
Training loss: 1.393893269586519
Validation loss: 2.692345236247501

Epoch: 6| Step: 3
Training loss: 0.8867424781078066
Validation loss: 2.63705139322437

Epoch: 6| Step: 4
Training loss: 1.900995611042252
Validation loss: 2.6630280873909675

Epoch: 6| Step: 5
Training loss: 2.1096464759478075
Validation loss: 2.71474395495351

Epoch: 6| Step: 6
Training loss: 1.2643760829737989
Validation loss: 2.659329570198441

Epoch: 6| Step: 7
Training loss: 0.9144186646471439
Validation loss: 2.6752219253653036

Epoch: 6| Step: 8
Training loss: 1.0264780436572487
Validation loss: 2.7497393889194846

Epoch: 6| Step: 9
Training loss: 0.8484179682441721
Validation loss: 2.7336356189708817

Epoch: 6| Step: 10
Training loss: 1.399203639372187
Validation loss: 2.8191034996164444

Epoch: 6| Step: 11
Training loss: 1.4974143472162758
Validation loss: 2.7591633572602268

Epoch: 6| Step: 12
Training loss: 1.2820363306738716
Validation loss: 2.7508274336317005

Epoch: 6| Step: 13
Training loss: 1.4675676172330605
Validation loss: 2.7110563869590174

Epoch: 168| Step: 0
Training loss: 1.269669839190219
Validation loss: 2.711061311765586

Epoch: 6| Step: 1
Training loss: 1.5508387480485295
Validation loss: 2.6845551702322816

Epoch: 6| Step: 2
Training loss: 1.250405960918503
Validation loss: 2.766844342359689

Epoch: 6| Step: 3
Training loss: 2.0927964501622043
Validation loss: 2.736560986794223

Epoch: 6| Step: 4
Training loss: 1.3628444901079246
Validation loss: 2.685952650452426

Epoch: 6| Step: 5
Training loss: 0.7098996478337674
Validation loss: 2.7640018980500014

Epoch: 6| Step: 6
Training loss: 1.0330376591718882
Validation loss: 2.746827014537236

Epoch: 6| Step: 7
Training loss: 1.761602156813442
Validation loss: 2.7355193731623344

Epoch: 6| Step: 8
Training loss: 1.2722600630491334
Validation loss: 2.7215509127568307

Epoch: 6| Step: 9
Training loss: 1.1104403471196047
Validation loss: 2.773770823619003

Epoch: 6| Step: 10
Training loss: 1.0516454270017086
Validation loss: 2.7716510445694924

Epoch: 6| Step: 11
Training loss: 1.0991832388514762
Validation loss: 2.7904244311321844

Epoch: 6| Step: 12
Training loss: 1.4410836703955001
Validation loss: 2.7563460992854325

Epoch: 6| Step: 13
Training loss: 1.1807761821408391
Validation loss: 2.7859663959858123

Epoch: 169| Step: 0
Training loss: 1.4566627015875326
Validation loss: 2.7730588412695005

Epoch: 6| Step: 1
Training loss: 1.4202658801930974
Validation loss: 2.7399450626573914

Epoch: 6| Step: 2
Training loss: 1.4312667046117662
Validation loss: 2.794236073036296

Epoch: 6| Step: 3
Training loss: 0.977577323050495
Validation loss: 2.773378484393564

Epoch: 6| Step: 4
Training loss: 1.283609822242866
Validation loss: 2.7008399492806774

Epoch: 6| Step: 5
Training loss: 1.230255689794247
Validation loss: 2.7451861904486736

Epoch: 6| Step: 6
Training loss: 0.7034363375247008
Validation loss: 2.7538924124439954

Epoch: 6| Step: 7
Training loss: 1.448370178699247
Validation loss: 2.7953019504621697

Epoch: 6| Step: 8
Training loss: 1.5179172760407849
Validation loss: 2.727025747796172

Epoch: 6| Step: 9
Training loss: 1.2811829153967311
Validation loss: 2.6918910918158163

Epoch: 6| Step: 10
Training loss: 1.1353664678739992
Validation loss: 2.757571158506907

Epoch: 6| Step: 11
Training loss: 1.4402892377236638
Validation loss: 2.7404962234661285

Epoch: 6| Step: 12
Training loss: 1.9735140606669481
Validation loss: 2.6931796863451383

Epoch: 6| Step: 13
Training loss: 1.1292531889439101
Validation loss: 2.6947780650566915

Epoch: 170| Step: 0
Training loss: 1.944178239068773
Validation loss: 2.665315290603074

Epoch: 6| Step: 1
Training loss: 1.2825707397136776
Validation loss: 2.7228851586999525

Epoch: 6| Step: 2
Training loss: 1.2430602072990418
Validation loss: 2.7337230813495235

Epoch: 6| Step: 3
Training loss: 1.2301273901805405
Validation loss: 2.766382088636929

Epoch: 6| Step: 4
Training loss: 1.0058513159567928
Validation loss: 2.794577985498413

Epoch: 6| Step: 5
Training loss: 0.9195718281493878
Validation loss: 2.814318965879559

Epoch: 6| Step: 6
Training loss: 1.3676584359117434
Validation loss: 2.8005197315144135

Epoch: 6| Step: 7
Training loss: 1.0423309433347185
Validation loss: 2.6979858998334807

Epoch: 6| Step: 8
Training loss: 1.0687742665530777
Validation loss: 2.7127554713125974

Epoch: 6| Step: 9
Training loss: 1.1779449426481958
Validation loss: 2.6620106481696935

Epoch: 6| Step: 10
Training loss: 1.5643947557092723
Validation loss: 2.703419458010636

Epoch: 6| Step: 11
Training loss: 1.136435352143196
Validation loss: 2.6893197781248457

Epoch: 6| Step: 12
Training loss: 1.6739771096727984
Validation loss: 2.6539782589484506

Epoch: 6| Step: 13
Training loss: 1.4255490466684748
Validation loss: 2.7165251942718456

Epoch: 171| Step: 0
Training loss: 1.2480247149343293
Validation loss: 2.7276105788274925

Epoch: 6| Step: 1
Training loss: 1.3627296359231236
Validation loss: 2.701269508890375

Epoch: 6| Step: 2
Training loss: 1.010401984563647
Validation loss: 2.727237410208306

Epoch: 6| Step: 3
Training loss: 0.758397849625746
Validation loss: 2.7836241572073006

Epoch: 6| Step: 4
Training loss: 1.225156233030654
Validation loss: 2.732636405806899

Epoch: 6| Step: 5
Training loss: 1.0943672618232922
Validation loss: 2.781142343444894

Epoch: 6| Step: 6
Training loss: 1.570023998878891
Validation loss: 2.8456598093981604

Epoch: 6| Step: 7
Training loss: 1.380600361360262
Validation loss: 2.8523003934227473

Epoch: 6| Step: 8
Training loss: 1.1077663955456583
Validation loss: 2.8186580775484043

Epoch: 6| Step: 9
Training loss: 1.217371087191473
Validation loss: 2.783860941998498

Epoch: 6| Step: 10
Training loss: 0.9261855839970063
Validation loss: 2.7333345450034208

Epoch: 6| Step: 11
Training loss: 0.9618425836485703
Validation loss: 2.7100473897621558

Epoch: 6| Step: 12
Training loss: 2.337376180215096
Validation loss: 2.735523832671611

Epoch: 6| Step: 13
Training loss: 1.3584066866549491
Validation loss: 2.68381909086489

Epoch: 172| Step: 0
Training loss: 1.2739132419610935
Validation loss: 2.6957090666566845

Epoch: 6| Step: 1
Training loss: 0.9715857378909751
Validation loss: 2.7028256436150144

Epoch: 6| Step: 2
Training loss: 1.2102592291461356
Validation loss: 2.670968152797876

Epoch: 6| Step: 3
Training loss: 2.043461056503652
Validation loss: 2.757850625096112

Epoch: 6| Step: 4
Training loss: 0.9882949405973354
Validation loss: 2.71444052210541

Epoch: 6| Step: 5
Training loss: 1.2439838592119998
Validation loss: 2.7666228410589486

Epoch: 6| Step: 6
Training loss: 1.2342653829455479
Validation loss: 2.7545642688902983

Epoch: 6| Step: 7
Training loss: 1.0897543812414505
Validation loss: 2.7915644033879525

Epoch: 6| Step: 8
Training loss: 1.3754215461269215
Validation loss: 2.7930948153412856

Epoch: 6| Step: 9
Training loss: 1.1199374732377236
Validation loss: 2.736148760278917

Epoch: 6| Step: 10
Training loss: 0.8787288571523314
Validation loss: 2.7729844202314027

Epoch: 6| Step: 11
Training loss: 1.6939200030942827
Validation loss: 2.727709480677177

Epoch: 6| Step: 12
Training loss: 1.6410804479663352
Validation loss: 2.756979019392377

Epoch: 6| Step: 13
Training loss: 1.1821667721469225
Validation loss: 2.694019187936321

Epoch: 173| Step: 0
Training loss: 1.2052001891304727
Validation loss: 2.733537454853099

Epoch: 6| Step: 1
Training loss: 1.1221278402456787
Validation loss: 2.744230431368921

Epoch: 6| Step: 2
Training loss: 1.3526095705899985
Validation loss: 2.6949752080575586

Epoch: 6| Step: 3
Training loss: 1.561412738170827
Validation loss: 2.6393165431473418

Epoch: 6| Step: 4
Training loss: 1.3578427327854097
Validation loss: 2.748578889270382

Epoch: 6| Step: 5
Training loss: 0.9468007313523653
Validation loss: 2.7563383865313202

Epoch: 6| Step: 6
Training loss: 1.371543136811135
Validation loss: 2.8019673182827654

Epoch: 6| Step: 7
Training loss: 0.8384982664514591
Validation loss: 2.761248500415446

Epoch: 6| Step: 8
Training loss: 1.2906614617099583
Validation loss: 2.7435236589113696

Epoch: 6| Step: 9
Training loss: 1.4442210432243032
Validation loss: 2.7733322338490263

Epoch: 6| Step: 10
Training loss: 1.424376414868672
Validation loss: 2.749392601327415

Epoch: 6| Step: 11
Training loss: 2.016907158480875
Validation loss: 2.7895225337845364

Epoch: 6| Step: 12
Training loss: 0.9273613430755017
Validation loss: 2.7414746277134996

Epoch: 6| Step: 13
Training loss: 0.9256932985400921
Validation loss: 2.7339815710498208

Epoch: 174| Step: 0
Training loss: 0.953095388734201
Validation loss: 2.683391017372776

Epoch: 6| Step: 1
Training loss: 1.1537731551040356
Validation loss: 2.7612539616987073

Epoch: 6| Step: 2
Training loss: 0.7411737445250012
Validation loss: 2.695677153019961

Epoch: 6| Step: 3
Training loss: 1.5592828818960098
Validation loss: 2.7027715992200783

Epoch: 6| Step: 4
Training loss: 1.2744547519546008
Validation loss: 2.6635603818408735

Epoch: 6| Step: 5
Training loss: 0.8263466652377786
Validation loss: 2.653032485912559

Epoch: 6| Step: 6
Training loss: 1.0651017478909188
Validation loss: 2.670987351708342

Epoch: 6| Step: 7
Training loss: 1.5359918780708157
Validation loss: 2.6537040776432934

Epoch: 6| Step: 8
Training loss: 2.0209873049043314
Validation loss: 2.7510284176995774

Epoch: 6| Step: 9
Training loss: 1.1181296264143321
Validation loss: 2.693532781848647

Epoch: 6| Step: 10
Training loss: 1.3915457088571928
Validation loss: 2.7091653475078123

Epoch: 6| Step: 11
Training loss: 1.0945975153575085
Validation loss: 2.7386822953264214

Epoch: 6| Step: 12
Training loss: 1.0121887764800486
Validation loss: 2.7207955743838363

Epoch: 6| Step: 13
Training loss: 1.576314057055169
Validation loss: 2.7840139249822435

Epoch: 175| Step: 0
Training loss: 1.606102885474417
Validation loss: 2.767285740962872

Epoch: 6| Step: 1
Training loss: 1.2785879252801189
Validation loss: 2.7332664058989278

Epoch: 6| Step: 2
Training loss: 1.0741430082495187
Validation loss: 2.7597684758975456

Epoch: 6| Step: 3
Training loss: 1.3194791884058534
Validation loss: 2.685262177144278

Epoch: 6| Step: 4
Training loss: 1.1383335664412864
Validation loss: 2.687016539742934

Epoch: 6| Step: 5
Training loss: 1.95014702169336
Validation loss: 2.715229005259033

Epoch: 6| Step: 6
Training loss: 1.161294552099309
Validation loss: 2.7466781667203177

Epoch: 6| Step: 7
Training loss: 1.335117824798381
Validation loss: 2.7353942279423147

Epoch: 6| Step: 8
Training loss: 1.2684332691844784
Validation loss: 2.6792472870731623

Epoch: 6| Step: 9
Training loss: 0.8697765295725469
Validation loss: 2.7331279126952936

Epoch: 6| Step: 10
Training loss: 1.0680215639730548
Validation loss: 2.781040826711105

Epoch: 6| Step: 11
Training loss: 1.3287338656345762
Validation loss: 2.736941791331255

Epoch: 6| Step: 12
Training loss: 0.7958436537534461
Validation loss: 2.663595320830422

Epoch: 6| Step: 13
Training loss: 1.3463940888123789
Validation loss: 2.7918966872311812

Epoch: 176| Step: 0
Training loss: 1.4384029703680308
Validation loss: 2.689242596444364

Epoch: 6| Step: 1
Training loss: 1.162360156272054
Validation loss: 2.719032455621485

Epoch: 6| Step: 2
Training loss: 2.0075714322845646
Validation loss: 2.748085511529506

Epoch: 6| Step: 3
Training loss: 1.2725134931647109
Validation loss: 2.7208935410136026

Epoch: 6| Step: 4
Training loss: 1.6853892936731345
Validation loss: 2.7899589344589293

Epoch: 6| Step: 5
Training loss: 1.2529051875679695
Validation loss: 2.75119527214371

Epoch: 6| Step: 6
Training loss: 0.5143850039578846
Validation loss: 2.7478291873344918

Epoch: 6| Step: 7
Training loss: 1.0389771390571587
Validation loss: 2.7567103473642156

Epoch: 6| Step: 8
Training loss: 0.9685423843885489
Validation loss: 2.744100079400937

Epoch: 6| Step: 9
Training loss: 1.206491886849915
Validation loss: 2.789473303024887

Epoch: 6| Step: 10
Training loss: 1.0099305363175457
Validation loss: 2.7995022132575453

Epoch: 6| Step: 11
Training loss: 1.2963296134138762
Validation loss: 2.790631092687138

Epoch: 6| Step: 12
Training loss: 1.1188305063956854
Validation loss: 2.7763458619677963

Epoch: 6| Step: 13
Training loss: 0.9983783925310341
Validation loss: 2.8704787791595723

Epoch: 177| Step: 0
Training loss: 1.3003476539999304
Validation loss: 2.8331805122525333

Epoch: 6| Step: 1
Training loss: 1.0804069804796885
Validation loss: 2.7047503074201322

Epoch: 6| Step: 2
Training loss: 1.2335980058322429
Validation loss: 2.7147156609705596

Epoch: 6| Step: 3
Training loss: 1.0420155830938718
Validation loss: 2.758880826160996

Epoch: 6| Step: 4
Training loss: 1.1818413177806542
Validation loss: 2.724050010952144

Epoch: 6| Step: 5
Training loss: 1.4653989833140502
Validation loss: 2.708936012897999

Epoch: 6| Step: 6
Training loss: 1.2348395330604935
Validation loss: 2.73527995801997

Epoch: 6| Step: 7
Training loss: 0.7348777592142121
Validation loss: 2.8270209811331304

Epoch: 6| Step: 8
Training loss: 2.069373612468212
Validation loss: 2.704476079495433

Epoch: 6| Step: 9
Training loss: 1.5855407218503572
Validation loss: 2.708640188782369

Epoch: 6| Step: 10
Training loss: 1.1967906912250383
Validation loss: 2.7721076320093743

Epoch: 6| Step: 11
Training loss: 0.9888530177910024
Validation loss: 2.7409678587969926

Epoch: 6| Step: 12
Training loss: 0.9561788382885615
Validation loss: 2.753875068506059

Epoch: 6| Step: 13
Training loss: 1.103006160916011
Validation loss: 2.817312799263663

Epoch: 178| Step: 0
Training loss: 0.9283130005801942
Validation loss: 2.7304050872904924

Epoch: 6| Step: 1
Training loss: 1.2807011242754724
Validation loss: 2.7023459544875426

Epoch: 6| Step: 2
Training loss: 0.8358743233738598
Validation loss: 2.72653864255303

Epoch: 6| Step: 3
Training loss: 0.6533028638759141
Validation loss: 2.6798662843368994

Epoch: 6| Step: 4
Training loss: 1.490996359704919
Validation loss: 2.617872461673016

Epoch: 6| Step: 5
Training loss: 2.173553696247505
Validation loss: 2.6159744108311482

Epoch: 6| Step: 6
Training loss: 1.3450001955563995
Validation loss: 2.7326484533517132

Epoch: 6| Step: 7
Training loss: 1.1106209004701637
Validation loss: 2.7262251680792033

Epoch: 6| Step: 8
Training loss: 1.358749421092369
Validation loss: 2.7721790736129166

Epoch: 6| Step: 9
Training loss: 1.2257527393650454
Validation loss: 2.833980708401405

Epoch: 6| Step: 10
Training loss: 1.4129661820394779
Validation loss: 2.780409861054722

Epoch: 6| Step: 11
Training loss: 1.1868735216883832
Validation loss: 2.800361137147973

Epoch: 6| Step: 12
Training loss: 1.3611716313217672
Validation loss: 2.7900963299937755

Epoch: 6| Step: 13
Training loss: 0.8259874503265312
Validation loss: 2.7399158396871095

Epoch: 179| Step: 0
Training loss: 1.9963907218735852
Validation loss: 2.7784101868335527

Epoch: 6| Step: 1
Training loss: 1.0952323677473983
Validation loss: 2.7238778977100275

Epoch: 6| Step: 2
Training loss: 1.1348107438958113
Validation loss: 2.7242952555401407

Epoch: 6| Step: 3
Training loss: 1.1951375596426153
Validation loss: 2.7339795435182244

Epoch: 6| Step: 4
Training loss: 1.1946985001672514
Validation loss: 2.727067836798072

Epoch: 6| Step: 5
Training loss: 0.896064344088268
Validation loss: 2.768814891000226

Epoch: 6| Step: 6
Training loss: 1.037810582472475
Validation loss: 2.7295425874427783

Epoch: 6| Step: 7
Training loss: 1.8277763621135719
Validation loss: 2.8332504559531713

Epoch: 6| Step: 8
Training loss: 1.2906155103283794
Validation loss: 2.8032955657880914

Epoch: 6| Step: 9
Training loss: 1.2376222993162214
Validation loss: 2.8181093862460167

Epoch: 6| Step: 10
Training loss: 1.00394840374625
Validation loss: 2.803958319868473

Epoch: 6| Step: 11
Training loss: 1.2138865339681641
Validation loss: 2.827270434903759

Epoch: 6| Step: 12
Training loss: 0.8731359653972166
Validation loss: 2.7879541012959708

Epoch: 6| Step: 13
Training loss: 1.0919037085931234
Validation loss: 2.750723700231497

Epoch: 180| Step: 0
Training loss: 0.9914327739657524
Validation loss: 2.7471158046144697

Epoch: 6| Step: 1
Training loss: 2.1121054602576654
Validation loss: 2.691172020717511

Epoch: 6| Step: 2
Training loss: 1.2633756263786462
Validation loss: 2.66565190816329

Epoch: 6| Step: 3
Training loss: 0.7127129320228414
Validation loss: 2.703033504517882

Epoch: 6| Step: 4
Training loss: 1.280634569436731
Validation loss: 2.6537238881040404

Epoch: 6| Step: 5
Training loss: 1.2562132910683839
Validation loss: 2.7214369522473922

Epoch: 6| Step: 6
Training loss: 0.9473279165649537
Validation loss: 2.708301380164603

Epoch: 6| Step: 7
Training loss: 1.3826470572430818
Validation loss: 2.7258319477189343

Epoch: 6| Step: 8
Training loss: 1.1828293047055138
Validation loss: 2.7707087027454476

Epoch: 6| Step: 9
Training loss: 1.0550987289659677
Validation loss: 2.65852392513933

Epoch: 6| Step: 10
Training loss: 1.1304849851506216
Validation loss: 2.6975679331755456

Epoch: 6| Step: 11
Training loss: 1.3224676025835633
Validation loss: 2.720220029523904

Epoch: 6| Step: 12
Training loss: 1.1536858453406542
Validation loss: 2.769488837845946

Epoch: 6| Step: 13
Training loss: 1.3253737732175441
Validation loss: 2.7832225419644328

Epoch: 181| Step: 0
Training loss: 1.3295584628366155
Validation loss: 2.905658347226404

Epoch: 6| Step: 1
Training loss: 0.7899234342894521
Validation loss: 2.8530086525644225

Epoch: 6| Step: 2
Training loss: 1.0287477016307423
Validation loss: 2.8144639681435817

Epoch: 6| Step: 3
Training loss: 1.3166949128287988
Validation loss: 2.857863938925584

Epoch: 6| Step: 4
Training loss: 1.204461779395383
Validation loss: 2.7679913126454525

Epoch: 6| Step: 5
Training loss: 1.1778419154525517
Validation loss: 2.780002056848328

Epoch: 6| Step: 6
Training loss: 1.4547849628647838
Validation loss: 2.7742269619177673

Epoch: 6| Step: 7
Training loss: 2.0768909662432553
Validation loss: 2.785927585905802

Epoch: 6| Step: 8
Training loss: 1.1200004323890396
Validation loss: 2.7010246010528216

Epoch: 6| Step: 9
Training loss: 0.9805569248141873
Validation loss: 2.665281015243627

Epoch: 6| Step: 10
Training loss: 1.1963872627902863
Validation loss: 2.6765060890965113

Epoch: 6| Step: 11
Training loss: 1.087032342526116
Validation loss: 2.668562488385828

Epoch: 6| Step: 12
Training loss: 1.2505732175676716
Validation loss: 2.724225183743172

Epoch: 6| Step: 13
Training loss: 1.0550159084331947
Validation loss: 2.7874335938257255

Epoch: 182| Step: 0
Training loss: 0.7891369019735787
Validation loss: 2.744924340609588

Epoch: 6| Step: 1
Training loss: 1.271464451693826
Validation loss: 2.7323893285398597

Epoch: 6| Step: 2
Training loss: 0.9863582493175878
Validation loss: 2.824747397514351

Epoch: 6| Step: 3
Training loss: 2.0314494108472863
Validation loss: 2.7662931019625114

Epoch: 6| Step: 4
Training loss: 1.372559592546217
Validation loss: 2.743662713587881

Epoch: 6| Step: 5
Training loss: 0.9628758922633682
Validation loss: 2.7547687018722313

Epoch: 6| Step: 6
Training loss: 1.0859387624170664
Validation loss: 2.7582579226908335

Epoch: 6| Step: 7
Training loss: 0.9457668442119798
Validation loss: 2.6979285771366004

Epoch: 6| Step: 8
Training loss: 1.1809955948659476
Validation loss: 2.6949222448027768

Epoch: 6| Step: 9
Training loss: 0.9576612617609249
Validation loss: 2.68837057104018

Epoch: 6| Step: 10
Training loss: 0.9132210534638501
Validation loss: 2.6914713592847948

Epoch: 6| Step: 11
Training loss: 1.476602866615056
Validation loss: 2.7269337500649975

Epoch: 6| Step: 12
Training loss: 1.13348963001019
Validation loss: 2.694843903870732

Epoch: 6| Step: 13
Training loss: 1.518220311483096
Validation loss: 2.7118518324477288

Epoch: 183| Step: 0
Training loss: 1.0001838038325628
Validation loss: 2.671563589527412

Epoch: 6| Step: 1
Training loss: 1.2823227369116743
Validation loss: 2.7448901907353136

Epoch: 6| Step: 2
Training loss: 1.071940221553842
Validation loss: 2.719178498507669

Epoch: 6| Step: 3
Training loss: 1.4661212690970868
Validation loss: 2.7472227117342802

Epoch: 6| Step: 4
Training loss: 0.5832854205845155
Validation loss: 2.828516207732132

Epoch: 6| Step: 5
Training loss: 1.004566257689789
Validation loss: 2.841011734177462

Epoch: 6| Step: 6
Training loss: 0.833371296653684
Validation loss: 2.8230478507290484

Epoch: 6| Step: 7
Training loss: 0.9955161420815323
Validation loss: 2.844069815736893

Epoch: 6| Step: 8
Training loss: 0.9591790213453449
Validation loss: 2.749521199361726

Epoch: 6| Step: 9
Training loss: 1.2267374290566961
Validation loss: 2.790428233284797

Epoch: 6| Step: 10
Training loss: 1.1112056725053068
Validation loss: 2.788290563446506

Epoch: 6| Step: 11
Training loss: 1.254092383904369
Validation loss: 2.837193094648513

Epoch: 6| Step: 12
Training loss: 2.1990998203785597
Validation loss: 2.7885061184585314

Epoch: 6| Step: 13
Training loss: 1.2635378641237476
Validation loss: 2.861662444806044

Epoch: 184| Step: 0
Training loss: 1.0690658437257876
Validation loss: 2.7080869611528837

Epoch: 6| Step: 1
Training loss: 0.7791942634047259
Validation loss: 2.751981974681329

Epoch: 6| Step: 2
Training loss: 1.0978668662448239
Validation loss: 2.7904210846639876

Epoch: 6| Step: 3
Training loss: 0.6906048931457215
Validation loss: 2.682428435508372

Epoch: 6| Step: 4
Training loss: 1.1138860833018278
Validation loss: 2.7108184905593258

Epoch: 6| Step: 5
Training loss: 1.2586875383322234
Validation loss: 2.6669302651140168

Epoch: 6| Step: 6
Training loss: 1.238611604444686
Validation loss: 2.7566847039600897

Epoch: 6| Step: 7
Training loss: 1.0751695898376317
Validation loss: 2.754806191146154

Epoch: 6| Step: 8
Training loss: 2.1412070937793306
Validation loss: 2.8089635443734

Epoch: 6| Step: 9
Training loss: 1.069793463943492
Validation loss: 2.775816535528597

Epoch: 6| Step: 10
Training loss: 1.160604936039085
Validation loss: 2.7062967761830197

Epoch: 6| Step: 11
Training loss: 1.135459123336784
Validation loss: 2.7595071889824343

Epoch: 6| Step: 12
Training loss: 0.967204306707583
Validation loss: 2.8403207762203766

Epoch: 6| Step: 13
Training loss: 1.1293354736403174
Validation loss: 2.7549517295102577

Epoch: 185| Step: 0
Training loss: 0.9119551076861766
Validation loss: 2.771947139702959

Epoch: 6| Step: 1
Training loss: 1.2820101088245826
Validation loss: 2.7630131559897473

Epoch: 6| Step: 2
Training loss: 1.2476934610167192
Validation loss: 2.7440802335598735

Epoch: 6| Step: 3
Training loss: 1.0309536826074015
Validation loss: 2.7623445556312625

Epoch: 6| Step: 4
Training loss: 1.312237758777781
Validation loss: 2.7358588415981027

Epoch: 6| Step: 5
Training loss: 0.8703096564364593
Validation loss: 2.730273733237489

Epoch: 6| Step: 6
Training loss: 2.0373765545291493
Validation loss: 2.708179092905844

Epoch: 6| Step: 7
Training loss: 0.8462490583834347
Validation loss: 2.6806802199061486

Epoch: 6| Step: 8
Training loss: 0.856116794053935
Validation loss: 2.7551326032205115

Epoch: 6| Step: 9
Training loss: 0.8458134532966223
Validation loss: 2.749433401287775

Epoch: 6| Step: 10
Training loss: 1.3083548712121869
Validation loss: 2.8188323542482823

Epoch: 6| Step: 11
Training loss: 1.1693330789266358
Validation loss: 2.7434377401360295

Epoch: 6| Step: 12
Training loss: 1.3355192901806323
Validation loss: 2.8629281874548727

Epoch: 6| Step: 13
Training loss: 0.842116222302438
Validation loss: 2.7055723471014943

Epoch: 186| Step: 0
Training loss: 1.4794398131715663
Validation loss: 2.8294269803441123

Epoch: 6| Step: 1
Training loss: 1.051139798732834
Validation loss: 2.8549958901673604

Epoch: 6| Step: 2
Training loss: 1.3657149750074482
Validation loss: 2.731747874747436

Epoch: 6| Step: 3
Training loss: 1.3616809798149474
Validation loss: 2.7997404369889556

Epoch: 6| Step: 4
Training loss: 1.2474819570394748
Validation loss: 2.79152831166495

Epoch: 6| Step: 5
Training loss: 0.9434507653490594
Validation loss: 2.7907582318496305

Epoch: 6| Step: 6
Training loss: 0.9779216615939129
Validation loss: 2.779742964873269

Epoch: 6| Step: 7
Training loss: 1.3908332497330251
Validation loss: 2.7927084777065545

Epoch: 6| Step: 8
Training loss: 1.2099755188538261
Validation loss: 2.762215964788563

Epoch: 6| Step: 9
Training loss: 1.8894126094364645
Validation loss: 2.7617788060990605

Epoch: 6| Step: 10
Training loss: 1.0909221058668812
Validation loss: 2.7783014476741275

Epoch: 6| Step: 11
Training loss: 0.9866856899446638
Validation loss: 2.7803923038021443

Epoch: 6| Step: 12
Training loss: 0.6976326369233427
Validation loss: 2.7847717576180786

Epoch: 6| Step: 13
Training loss: 1.0052857179782861
Validation loss: 2.708358960152695

Epoch: 187| Step: 0
Training loss: 0.9407857535748155
Validation loss: 2.7512689177137

Epoch: 6| Step: 1
Training loss: 1.3226310641960284
Validation loss: 2.7504883534852276

Epoch: 6| Step: 2
Training loss: 1.1504491716651732
Validation loss: 2.7807290878815087

Epoch: 6| Step: 3
Training loss: 0.9842230361624708
Validation loss: 2.749410710630031

Epoch: 6| Step: 4
Training loss: 1.9650689483271795
Validation loss: 2.721101262997377

Epoch: 6| Step: 5
Training loss: 1.42665152966559
Validation loss: 2.7525621818196466

Epoch: 6| Step: 6
Training loss: 0.850293815544901
Validation loss: 2.714029723419531

Epoch: 6| Step: 7
Training loss: 0.8183223014937386
Validation loss: 2.711753641744997

Epoch: 6| Step: 8
Training loss: 1.0088723693896544
Validation loss: 2.786010454256371

Epoch: 6| Step: 9
Training loss: 0.9799045596067559
Validation loss: 2.7531163663292157

Epoch: 6| Step: 10
Training loss: 1.3521948861929174
Validation loss: 2.7305137474125187

Epoch: 6| Step: 11
Training loss: 1.169076553664056
Validation loss: 2.808227302934305

Epoch: 6| Step: 12
Training loss: 0.8722447886115863
Validation loss: 2.7707561443925828

Epoch: 6| Step: 13
Training loss: 1.128033046197765
Validation loss: 2.829980280316577

Epoch: 188| Step: 0
Training loss: 1.1357567245851952
Validation loss: 2.807054206463367

Epoch: 6| Step: 1
Training loss: 0.8602538383484726
Validation loss: 2.8208723278721832

Epoch: 6| Step: 2
Training loss: 0.945833330672568
Validation loss: 2.761945629737519

Epoch: 6| Step: 3
Training loss: 0.77220263303828
Validation loss: 2.756389117316234

Epoch: 6| Step: 4
Training loss: 1.3753075689163687
Validation loss: 2.7284367485541976

Epoch: 6| Step: 5
Training loss: 1.28484291964549
Validation loss: 2.7243282195839478

Epoch: 6| Step: 6
Training loss: 1.996420637563904
Validation loss: 2.7630304785202666

Epoch: 6| Step: 7
Training loss: 0.706485643150527
Validation loss: 2.7874503868260914

Epoch: 6| Step: 8
Training loss: 1.1537318258620934
Validation loss: 2.7567663901287407

Epoch: 6| Step: 9
Training loss: 0.6520840019206396
Validation loss: 2.785957010870859

Epoch: 6| Step: 10
Training loss: 1.105099296164761
Validation loss: 2.7576031339742855

Epoch: 6| Step: 11
Training loss: 1.1770655819164815
Validation loss: 2.8028991296351036

Epoch: 6| Step: 12
Training loss: 0.9331521941283016
Validation loss: 2.855366688933931

Epoch: 6| Step: 13
Training loss: 1.1300801967756133
Validation loss: 2.8019375154542705

Epoch: 189| Step: 0
Training loss: 1.148512026905267
Validation loss: 2.778622203799127

Epoch: 6| Step: 1
Training loss: 0.7835106757142049
Validation loss: 2.7703415331437076

Epoch: 6| Step: 2
Training loss: 2.0077646450173123
Validation loss: 2.6750182314575293

Epoch: 6| Step: 3
Training loss: 1.1707872046799421
Validation loss: 2.7712381731628954

Epoch: 6| Step: 4
Training loss: 0.7974860148862857
Validation loss: 2.7207070391924164

Epoch: 6| Step: 5
Training loss: 1.4753075973988439
Validation loss: 2.74504227673436

Epoch: 6| Step: 6
Training loss: 1.0465620911245155
Validation loss: 2.7633358377031945

Epoch: 6| Step: 7
Training loss: 1.4349649716132726
Validation loss: 2.7171270927162228

Epoch: 6| Step: 8
Training loss: 0.940421574796264
Validation loss: 2.715025253998056

Epoch: 6| Step: 9
Training loss: 0.7937365418141757
Validation loss: 2.763884260556059

Epoch: 6| Step: 10
Training loss: 0.9264459276122909
Validation loss: 2.824013040806069

Epoch: 6| Step: 11
Training loss: 1.2396902257313824
Validation loss: 2.9115761657418155

Epoch: 6| Step: 12
Training loss: 1.3665334826602558
Validation loss: 2.8991347277194963

Epoch: 6| Step: 13
Training loss: 1.0390545263916626
Validation loss: 2.901536982569105

Epoch: 190| Step: 0
Training loss: 0.9545245292153467
Validation loss: 2.8654691309191676

Epoch: 6| Step: 1
Training loss: 1.0362747771058463
Validation loss: 2.82009027368151

Epoch: 6| Step: 2
Training loss: 1.5229800589014293
Validation loss: 2.7998036798272006

Epoch: 6| Step: 3
Training loss: 1.1727552032908246
Validation loss: 2.739073714418116

Epoch: 6| Step: 4
Training loss: 1.8962639819077962
Validation loss: 2.8149552683779815

Epoch: 6| Step: 5
Training loss: 0.9670355608140304
Validation loss: 2.804402739822151

Epoch: 6| Step: 6
Training loss: 1.0808192878130138
Validation loss: 2.6436141211399367

Epoch: 6| Step: 7
Training loss: 0.8845812203275288
Validation loss: 2.7868381324594274

Epoch: 6| Step: 8
Training loss: 0.8265064184420785
Validation loss: 2.678645073014538

Epoch: 6| Step: 9
Training loss: 1.3277534862825209
Validation loss: 2.7069717701610885

Epoch: 6| Step: 10
Training loss: 0.80650893792097
Validation loss: 2.727122397807195

Epoch: 6| Step: 11
Training loss: 1.0751173110649714
Validation loss: 2.7724544878458355

Epoch: 6| Step: 12
Training loss: 0.7838085621761576
Validation loss: 2.7731146897691823

Epoch: 6| Step: 13
Training loss: 1.0589912484683623
Validation loss: 2.7600735337141287

Epoch: 191| Step: 0
Training loss: 0.7494699671544984
Validation loss: 2.7862699831232725

Epoch: 6| Step: 1
Training loss: 1.061835922950178
Validation loss: 2.7709306016260147

Epoch: 6| Step: 2
Training loss: 1.5451777230667727
Validation loss: 2.7739472686359727

Epoch: 6| Step: 3
Training loss: 1.0346335188858418
Validation loss: 2.7241598216434

Epoch: 6| Step: 4
Training loss: 0.7195182094986905
Validation loss: 2.825105337131426

Epoch: 6| Step: 5
Training loss: 0.8497717691199212
Validation loss: 2.76873664594405

Epoch: 6| Step: 6
Training loss: 0.7868065642032142
Validation loss: 2.6880251349227677

Epoch: 6| Step: 7
Training loss: 1.1199586019358254
Validation loss: 2.7621295413010887

Epoch: 6| Step: 8
Training loss: 1.6954900411292546
Validation loss: 2.7162910683493

Epoch: 6| Step: 9
Training loss: 1.8452964375028589
Validation loss: 2.74305890937525

Epoch: 6| Step: 10
Training loss: 0.8775336164572516
Validation loss: 2.765083532974323

Epoch: 6| Step: 11
Training loss: 0.8486970760828619
Validation loss: 2.809504474942057

Epoch: 6| Step: 12
Training loss: 0.9796020811280792
Validation loss: 2.826243257532818

Epoch: 6| Step: 13
Training loss: 0.7093346941416219
Validation loss: 2.837736835762753

Epoch: 192| Step: 0
Training loss: 1.1738078136241874
Validation loss: 2.7869590143083354

Epoch: 6| Step: 1
Training loss: 1.01572628983342
Validation loss: 2.8165743456237693

Epoch: 6| Step: 2
Training loss: 1.5833500392768656
Validation loss: 2.836973948456683

Epoch: 6| Step: 3
Training loss: 1.1855749789933678
Validation loss: 2.8294168686569003

Epoch: 6| Step: 4
Training loss: 1.0395475130401597
Validation loss: 2.744980754286855

Epoch: 6| Step: 5
Training loss: 0.73280849171012
Validation loss: 2.842988265025505

Epoch: 6| Step: 6
Training loss: 0.6683809447472708
Validation loss: 2.7925834407765584

Epoch: 6| Step: 7
Training loss: 1.1233935011947556
Validation loss: 2.7414643872976887

Epoch: 6| Step: 8
Training loss: 1.0677227236390519
Validation loss: 2.7830545664619266

Epoch: 6| Step: 9
Training loss: 1.0979681148937077
Validation loss: 2.712456796890966

Epoch: 6| Step: 10
Training loss: 1.052245187427104
Validation loss: 2.7685376578855103

Epoch: 6| Step: 11
Training loss: 1.7720220353411922
Validation loss: 2.702307987408438

Epoch: 6| Step: 12
Training loss: 0.8933054425264971
Validation loss: 2.794984487582648

Epoch: 6| Step: 13
Training loss: 1.19320767651236
Validation loss: 2.807121205624838

Epoch: 193| Step: 0
Training loss: 0.9309707888682395
Validation loss: 2.828510995731219

Epoch: 6| Step: 1
Training loss: 0.5358915637379261
Validation loss: 2.8158770313994776

Epoch: 6| Step: 2
Training loss: 1.089987249737282
Validation loss: 2.900451618413808

Epoch: 6| Step: 3
Training loss: 1.437479931235166
Validation loss: 2.8806762568147843

Epoch: 6| Step: 4
Training loss: 1.3600504282409525
Validation loss: 2.8167831161699763

Epoch: 6| Step: 5
Training loss: 0.904987244700542
Validation loss: 2.802778112976269

Epoch: 6| Step: 6
Training loss: 0.8625727719552942
Validation loss: 2.769881268950833

Epoch: 6| Step: 7
Training loss: 1.0739042064348145
Validation loss: 2.831605690738736

Epoch: 6| Step: 8
Training loss: 2.0634559958895795
Validation loss: 2.6901956686070725

Epoch: 6| Step: 9
Training loss: 0.9464362534882151
Validation loss: 2.7906708056089156

Epoch: 6| Step: 10
Training loss: 1.4199626764577156
Validation loss: 2.6832328601847624

Epoch: 6| Step: 11
Training loss: 0.92081882298517
Validation loss: 2.7346632741922248

Epoch: 6| Step: 12
Training loss: 1.2038815584317992
Validation loss: 2.791686959453864

Epoch: 6| Step: 13
Training loss: 0.9221262831811508
Validation loss: 2.820228906521534

Epoch: 194| Step: 0
Training loss: 1.0364080956838142
Validation loss: 2.7770198842436726

Epoch: 6| Step: 1
Training loss: 1.5753139727857441
Validation loss: 2.882012398364197

Epoch: 6| Step: 2
Training loss: 1.9736829446487383
Validation loss: 2.8356795250561606

Epoch: 6| Step: 3
Training loss: 1.3469922185105248
Validation loss: 2.838876425692313

Epoch: 6| Step: 4
Training loss: 0.9510879009550156
Validation loss: 2.9128263440754845

Epoch: 6| Step: 5
Training loss: 1.1315537397945759
Validation loss: 2.84863833641691

Epoch: 6| Step: 6
Training loss: 0.7251233028923998
Validation loss: 2.7632412021112316

Epoch: 6| Step: 7
Training loss: 0.6869188800433497
Validation loss: 2.7472199635313714

Epoch: 6| Step: 8
Training loss: 0.7905404629952931
Validation loss: 2.767836238119989

Epoch: 6| Step: 9
Training loss: 0.5239849643752306
Validation loss: 2.7380573582052845

Epoch: 6| Step: 10
Training loss: 0.5903885453831036
Validation loss: 2.7212211734574887

Epoch: 6| Step: 11
Training loss: 1.161879008564798
Validation loss: 2.7178059542985293

Epoch: 6| Step: 12
Training loss: 1.548847905498098
Validation loss: 2.7847102210678627

Epoch: 6| Step: 13
Training loss: 1.0665385405260464
Validation loss: 2.714892519140046

Epoch: 195| Step: 0
Training loss: 1.1574262873204688
Validation loss: 2.7766819848244473

Epoch: 6| Step: 1
Training loss: 1.0489643938987436
Validation loss: 2.726301696312853

Epoch: 6| Step: 2
Training loss: 0.9485650971253882
Validation loss: 2.806589967203685

Epoch: 6| Step: 3
Training loss: 0.8356569122292429
Validation loss: 2.720172290814964

Epoch: 6| Step: 4
Training loss: 1.0290925548808671
Validation loss: 2.789117992429647

Epoch: 6| Step: 5
Training loss: 1.1224041235574085
Validation loss: 2.7832873879331466

Epoch: 6| Step: 6
Training loss: 0.7076172481476823
Validation loss: 2.8413289142552203

Epoch: 6| Step: 7
Training loss: 0.8452130807453812
Validation loss: 2.837235152982369

Epoch: 6| Step: 8
Training loss: 1.2442121021093633
Validation loss: 2.778689030481622

Epoch: 6| Step: 9
Training loss: 0.8491523653560008
Validation loss: 2.77341926103066

Epoch: 6| Step: 10
Training loss: 2.026236112101061
Validation loss: 2.852661171989501

Epoch: 6| Step: 11
Training loss: 1.1143549509860444
Validation loss: 2.8148230671994035

Epoch: 6| Step: 12
Training loss: 0.7741938274233069
Validation loss: 2.9046989184875573

Epoch: 6| Step: 13
Training loss: 0.8844651813155415
Validation loss: 2.880999469691268

Epoch: 196| Step: 0
Training loss: 1.9709730161990338
Validation loss: 2.8701832683545248

Epoch: 6| Step: 1
Training loss: 0.8095142819073666
Validation loss: 2.81380950677267

Epoch: 6| Step: 2
Training loss: 0.6886205644366019
Validation loss: 2.7908696892155698

Epoch: 6| Step: 3
Training loss: 0.9165512828745299
Validation loss: 2.7855669158455703

Epoch: 6| Step: 4
Training loss: 0.8652247305648998
Validation loss: 2.754561903079717

Epoch: 6| Step: 5
Training loss: 0.7893861163663668
Validation loss: 2.752926511966804

Epoch: 6| Step: 6
Training loss: 1.3088864127317221
Validation loss: 2.7588051152395243

Epoch: 6| Step: 7
Training loss: 0.9501718202609651
Validation loss: 2.7443500190025905

Epoch: 6| Step: 8
Training loss: 1.3024143815409948
Validation loss: 2.728649517497846

Epoch: 6| Step: 9
Training loss: 0.8942500509529216
Validation loss: 2.745677151287821

Epoch: 6| Step: 10
Training loss: 0.6311581497598203
Validation loss: 2.77128805765011

Epoch: 6| Step: 11
Training loss: 1.029028725485419
Validation loss: 2.8154111701249644

Epoch: 6| Step: 12
Training loss: 1.0555738327607889
Validation loss: 2.7963041578995895

Epoch: 6| Step: 13
Training loss: 0.9190224626284405
Validation loss: 2.779107100512314

Epoch: 197| Step: 0
Training loss: 0.8694437248550649
Validation loss: 2.767810683439159

Epoch: 6| Step: 1
Training loss: 0.712658235479833
Validation loss: 2.806310271003165

Epoch: 6| Step: 2
Training loss: 1.0241449837268506
Validation loss: 2.8260336883653525

Epoch: 6| Step: 3
Training loss: 0.8892285961141577
Validation loss: 2.775034069734213

Epoch: 6| Step: 4
Training loss: 0.912581327811722
Validation loss: 2.7892387398566614

Epoch: 6| Step: 5
Training loss: 1.065204096476764
Validation loss: 2.7256948261841156

Epoch: 6| Step: 6
Training loss: 0.9309963341670486
Validation loss: 2.812025779021724

Epoch: 6| Step: 7
Training loss: 0.8390700213842869
Validation loss: 2.7485889513809005

Epoch: 6| Step: 8
Training loss: 1.3292494557745285
Validation loss: 2.713477038140419

Epoch: 6| Step: 9
Training loss: 1.0602007840388072
Validation loss: 2.8264762891981334

Epoch: 6| Step: 10
Training loss: 0.8664409757763317
Validation loss: 2.7741231151480386

Epoch: 6| Step: 11
Training loss: 1.0672868718676165
Validation loss: 2.8169965473723093

Epoch: 6| Step: 12
Training loss: 2.056804885897922
Validation loss: 2.78991325788207

Epoch: 6| Step: 13
Training loss: 1.398635338795765
Validation loss: 2.893853482729809

Epoch: 198| Step: 0
Training loss: 1.2046101309030923
Validation loss: 2.7547766209649005

Epoch: 6| Step: 1
Training loss: 0.7560713911761194
Validation loss: 2.779110317621701

Epoch: 6| Step: 2
Training loss: 0.8813976326507499
Validation loss: 2.7895765498683995

Epoch: 6| Step: 3
Training loss: 0.7376522634406986
Validation loss: 2.740347075280289

Epoch: 6| Step: 4
Training loss: 0.9507330914402398
Validation loss: 2.835773740021395

Epoch: 6| Step: 5
Training loss: 0.9594581195225125
Validation loss: 2.70906000414512

Epoch: 6| Step: 6
Training loss: 0.9784486789606925
Validation loss: 2.7155121270980516

Epoch: 6| Step: 7
Training loss: 1.0227872224056596
Validation loss: 2.812015915642488

Epoch: 6| Step: 8
Training loss: 1.3893569136526454
Validation loss: 2.750613216463607

Epoch: 6| Step: 9
Training loss: 1.1539198103038857
Validation loss: 2.8002307302913527

Epoch: 6| Step: 10
Training loss: 0.8896480355120524
Validation loss: 2.831131083929367

Epoch: 6| Step: 11
Training loss: 0.6985538667348601
Validation loss: 2.804095518353614

Epoch: 6| Step: 12
Training loss: 1.7298633213846686
Validation loss: 2.843436702475635

Epoch: 6| Step: 13
Training loss: 0.868270850291774
Validation loss: 2.77557846317793

Epoch: 199| Step: 0
Training loss: 0.8133245099349943
Validation loss: 2.7711335404375568

Epoch: 6| Step: 1
Training loss: 1.7321454400673937
Validation loss: 2.808414784239805

Epoch: 6| Step: 2
Training loss: 1.0160601343996862
Validation loss: 2.8359181286979553

Epoch: 6| Step: 3
Training loss: 0.6880866278916424
Validation loss: 2.8287240126389994

Epoch: 6| Step: 4
Training loss: 1.0751871079245319
Validation loss: 2.874773928834533

Epoch: 6| Step: 5
Training loss: 0.8816357762478472
Validation loss: 2.8222112701004094

Epoch: 6| Step: 6
Training loss: 1.1678701505857363
Validation loss: 2.8275163392467024

Epoch: 6| Step: 7
Training loss: 1.341476379942989
Validation loss: 2.84731470335172

Epoch: 6| Step: 8
Training loss: 0.6506667825289659
Validation loss: 2.8111325365773734

Epoch: 6| Step: 9
Training loss: 1.3229562147742142
Validation loss: 2.7494891010000653

Epoch: 6| Step: 10
Training loss: 1.4272152730646297
Validation loss: 2.7908947764759966

Epoch: 6| Step: 11
Training loss: 1.0277037479327467
Validation loss: 2.7700008250716137

Epoch: 6| Step: 12
Training loss: 0.9083961199720827
Validation loss: 2.8038536681194994

Epoch: 6| Step: 13
Training loss: 0.8135133439595019
Validation loss: 2.8054636640156474

Epoch: 200| Step: 0
Training loss: 0.5495582963515253
Validation loss: 2.8161230839964597

Epoch: 6| Step: 1
Training loss: 0.691241271600233
Validation loss: 2.8751835142528037

Epoch: 6| Step: 2
Training loss: 0.8268858077192813
Validation loss: 2.8541138126649286

Epoch: 6| Step: 3
Training loss: 0.9413660444482782
Validation loss: 2.824217877667065

Epoch: 6| Step: 4
Training loss: 1.026370091166504
Validation loss: 2.8156007204691913

Epoch: 6| Step: 5
Training loss: 0.8206597456073392
Validation loss: 2.8140793286741195

Epoch: 6| Step: 6
Training loss: 1.1098079105365442
Validation loss: 2.856614995627841

Epoch: 6| Step: 7
Training loss: 1.1794044205514012
Validation loss: 2.8022985812948833

Epoch: 6| Step: 8
Training loss: 1.3831214344170037
Validation loss: 2.791057880883471

Epoch: 6| Step: 9
Training loss: 0.6142842055140625
Validation loss: 2.8141243094194612

Epoch: 6| Step: 10
Training loss: 1.1778902421993558
Validation loss: 2.7758796434672686

Epoch: 6| Step: 11
Training loss: 0.8655851871410275
Validation loss: 2.782563103151375

Epoch: 6| Step: 12
Training loss: 1.8234244665678698
Validation loss: 2.8987102123193123

Epoch: 6| Step: 13
Training loss: 1.393747959221
Validation loss: 2.8768975174159594

Epoch: 201| Step: 0
Training loss: 0.5051046802593926
Validation loss: 2.755177464639752

Epoch: 6| Step: 1
Training loss: 1.2403538443627544
Validation loss: 2.7429051632972907

Epoch: 6| Step: 2
Training loss: 1.1141754307160865
Validation loss: 2.7722027962903746

Epoch: 6| Step: 3
Training loss: 0.7313114547989356
Validation loss: 2.8136760372166565

Epoch: 6| Step: 4
Training loss: 0.624750039661249
Validation loss: 2.7077044612744032

Epoch: 6| Step: 5
Training loss: 1.1451769364755697
Validation loss: 2.8202628345290455

Epoch: 6| Step: 6
Training loss: 1.7196412290059786
Validation loss: 2.851424150289666

Epoch: 6| Step: 7
Training loss: 1.055317951670655
Validation loss: 2.7515994246931657

Epoch: 6| Step: 8
Training loss: 1.0269954656707003
Validation loss: 2.764910452969492

Epoch: 6| Step: 9
Training loss: 0.7310474571708223
Validation loss: 2.7817039833590425

Epoch: 6| Step: 10
Training loss: 0.9431160243715142
Validation loss: 2.7183751545754276

Epoch: 6| Step: 11
Training loss: 0.6911334345456916
Validation loss: 2.7607845613052175

Epoch: 6| Step: 12
Training loss: 1.248762949130838
Validation loss: 2.8042542982839067

Epoch: 6| Step: 13
Training loss: 1.2394970241386265
Validation loss: 2.861478507784693

Epoch: 202| Step: 0
Training loss: 1.164086770438311
Validation loss: 2.757461021150151

Epoch: 6| Step: 1
Training loss: 0.4994858691256742
Validation loss: 2.845396829605687

Epoch: 6| Step: 2
Training loss: 1.2733523100459148
Validation loss: 2.8504550960875714

Epoch: 6| Step: 3
Training loss: 1.0825505852277881
Validation loss: 2.8141483703988475

Epoch: 6| Step: 4
Training loss: 1.170498357257562
Validation loss: 2.814708923109235

Epoch: 6| Step: 5
Training loss: 0.5980292758058896
Validation loss: 2.865134007092162

Epoch: 6| Step: 6
Training loss: 0.906628233805619
Validation loss: 2.781790620073633

Epoch: 6| Step: 7
Training loss: 1.8328052179138223
Validation loss: 2.785529441138788

Epoch: 6| Step: 8
Training loss: 0.810338041680499
Validation loss: 2.7274641424375075

Epoch: 6| Step: 9
Training loss: 1.1290632620523027
Validation loss: 2.7666076954527785

Epoch: 6| Step: 10
Training loss: 0.7683400262705249
Validation loss: 2.7623671256627977

Epoch: 6| Step: 11
Training loss: 0.5988493834104515
Validation loss: 2.8470763151005185

Epoch: 6| Step: 12
Training loss: 1.2868767442733111
Validation loss: 2.868153249191805

Epoch: 6| Step: 13
Training loss: 0.9879582295603484
Validation loss: 2.9294249828131127

Epoch: 203| Step: 0
Training loss: 1.0389746722052215
Validation loss: 2.839212311546753

Epoch: 6| Step: 1
Training loss: 1.8359432139206298
Validation loss: 2.7979392756393415

Epoch: 6| Step: 2
Training loss: 0.977449670261798
Validation loss: 2.9053058526290405

Epoch: 6| Step: 3
Training loss: 1.177824456611443
Validation loss: 2.7723320992311744

Epoch: 6| Step: 4
Training loss: 0.9094072460736572
Validation loss: 2.8165188086561312

Epoch: 6| Step: 5
Training loss: 0.8567921057072968
Validation loss: 2.791495607363874

Epoch: 6| Step: 6
Training loss: 0.7707977716301865
Validation loss: 2.729561308848254

Epoch: 6| Step: 7
Training loss: 1.3895570747757893
Validation loss: 2.7616749013165225

Epoch: 6| Step: 8
Training loss: 0.8817231200111766
Validation loss: 2.8127782613360517

Epoch: 6| Step: 9
Training loss: 0.8473590030806164
Validation loss: 2.837858756040232

Epoch: 6| Step: 10
Training loss: 0.7718226982651994
Validation loss: 2.8503003118356407

Epoch: 6| Step: 11
Training loss: 0.723569797752887
Validation loss: 2.7595372556602293

Epoch: 6| Step: 12
Training loss: 0.8085840196991539
Validation loss: 2.8266926434810777

Epoch: 6| Step: 13
Training loss: 0.6884761945574703
Validation loss: 2.7971947059258673

Epoch: 204| Step: 0
Training loss: 0.7269144333879417
Validation loss: 2.7850198092575114

Epoch: 6| Step: 1
Training loss: 0.8628837395216741
Validation loss: 2.806505157946227

Epoch: 6| Step: 2
Training loss: 1.046818233488182
Validation loss: 2.805437531417507

Epoch: 6| Step: 3
Training loss: 0.8654362634586755
Validation loss: 2.7932190825131946

Epoch: 6| Step: 4
Training loss: 0.8417292167220999
Validation loss: 2.775998461722901

Epoch: 6| Step: 5
Training loss: 1.778902816266552
Validation loss: 2.7504465145238117

Epoch: 6| Step: 6
Training loss: 1.215629985573555
Validation loss: 2.7561471465765672

Epoch: 6| Step: 7
Training loss: 1.3967698879078956
Validation loss: 2.8180629814939597

Epoch: 6| Step: 8
Training loss: 0.6127988533862121
Validation loss: 2.7720682695366436

Epoch: 6| Step: 9
Training loss: 0.9086390607824104
Validation loss: 2.8120975559666452

Epoch: 6| Step: 10
Training loss: 1.041715747948511
Validation loss: 2.69416202188035

Epoch: 6| Step: 11
Training loss: 0.7624004736811797
Validation loss: 2.791949746502148

Epoch: 6| Step: 12
Training loss: 0.9431019623346171
Validation loss: 2.7498952672261705

Epoch: 6| Step: 13
Training loss: 0.6871591286485964
Validation loss: 2.8380740185871205

Epoch: 205| Step: 0
Training loss: 0.8742698961284197
Validation loss: 2.8058352021529394

Epoch: 6| Step: 1
Training loss: 0.7985818571915455
Validation loss: 2.755556330971284

Epoch: 6| Step: 2
Training loss: 1.163898994176348
Validation loss: 2.858201062132761

Epoch: 6| Step: 3
Training loss: 1.1437081772292046
Validation loss: 2.799306072236216

Epoch: 6| Step: 4
Training loss: 0.9114924106585366
Validation loss: 2.7637400552451954

Epoch: 6| Step: 5
Training loss: 0.6862511345761897
Validation loss: 2.77459050957601

Epoch: 6| Step: 6
Training loss: 0.8422361144010795
Validation loss: 2.808865593711847

Epoch: 6| Step: 7
Training loss: 0.7851803524436248
Validation loss: 2.710537209397135

Epoch: 6| Step: 8
Training loss: 0.5831119054650833
Validation loss: 2.8075870695848364

Epoch: 6| Step: 9
Training loss: 0.8609165583727303
Validation loss: 2.793341139218782

Epoch: 6| Step: 10
Training loss: 1.1991826651546247
Validation loss: 2.8340668616985307

Epoch: 6| Step: 11
Training loss: 1.207461579779782
Validation loss: 2.7621393454498357

Epoch: 6| Step: 12
Training loss: 0.893974097373748
Validation loss: 2.81545699758314

Epoch: 6| Step: 13
Training loss: 1.9003571902369378
Validation loss: 2.7698080250081367

Epoch: 206| Step: 0
Training loss: 1.1264012405171933
Validation loss: 2.783410251338868

Epoch: 6| Step: 1
Training loss: 1.06005949339264
Validation loss: 2.8166959334062476

Epoch: 6| Step: 2
Training loss: 0.8362654283408968
Validation loss: 2.789553388036481

Epoch: 6| Step: 3
Training loss: 1.8890685934089975
Validation loss: 2.861620037304006

Epoch: 6| Step: 4
Training loss: 1.3601637119743664
Validation loss: 2.7417187122479683

Epoch: 6| Step: 5
Training loss: 1.385564361195207
Validation loss: 2.772355634269016

Epoch: 6| Step: 6
Training loss: 0.518480112349188
Validation loss: 2.7595926938384654

Epoch: 6| Step: 7
Training loss: 0.8952695639868659
Validation loss: 2.824760761370919

Epoch: 6| Step: 8
Training loss: 0.8635413006887975
Validation loss: 2.773197174405472

Epoch: 6| Step: 9
Training loss: 0.7323173753576604
Validation loss: 2.7310781458277535

Epoch: 6| Step: 10
Training loss: 1.0665280338936214
Validation loss: 2.7620210747390126

Epoch: 6| Step: 11
Training loss: 0.795345484081457
Validation loss: 2.7759506659177817

Epoch: 6| Step: 12
Training loss: 1.27184153519828
Validation loss: 2.764071083666504

Epoch: 6| Step: 13
Training loss: 0.5648095876406103
Validation loss: 2.7789893660449994

Epoch: 207| Step: 0
Training loss: 0.9045044102642955
Validation loss: 2.8395677211124246

Epoch: 6| Step: 1
Training loss: 0.9136518876595632
Validation loss: 2.854108995472191

Epoch: 6| Step: 2
Training loss: 0.9535568384673917
Validation loss: 2.9195706125378513

Epoch: 6| Step: 3
Training loss: 0.9807400271151513
Validation loss: 2.9742970760831327

Epoch: 6| Step: 4
Training loss: 0.7958133207338056
Validation loss: 2.8934587489983947

Epoch: 6| Step: 5
Training loss: 1.2061743796566127
Validation loss: 2.8829837186532026

Epoch: 6| Step: 6
Training loss: 1.0523704225236938
Validation loss: 2.813337512178918

Epoch: 6| Step: 7
Training loss: 0.9305777254516087
Validation loss: 2.8149991129077083

Epoch: 6| Step: 8
Training loss: 1.9237981958530135
Validation loss: 2.7384571811610585

Epoch: 6| Step: 9
Training loss: 1.1913497160959372
Validation loss: 2.826715768089224

Epoch: 6| Step: 10
Training loss: 1.0013058004653386
Validation loss: 2.8239694910076434

Epoch: 6| Step: 11
Training loss: 0.9070532297499037
Validation loss: 2.7298694948063202

Epoch: 6| Step: 12
Training loss: 0.8227223919455937
Validation loss: 2.8364774191769144

Epoch: 6| Step: 13
Training loss: 0.7055149151978
Validation loss: 2.812326213977618

Epoch: 208| Step: 0
Training loss: 1.3075263381405882
Validation loss: 2.8184496785141957

Epoch: 6| Step: 1
Training loss: 0.7439519688114943
Validation loss: 2.8515844196191282

Epoch: 6| Step: 2
Training loss: 1.005652663832517
Validation loss: 2.8016152871401983

Epoch: 6| Step: 3
Training loss: 1.0297643190014882
Validation loss: 2.7979019950506645

Epoch: 6| Step: 4
Training loss: 0.7418484365050965
Validation loss: 2.830714015458077

Epoch: 6| Step: 5
Training loss: 0.7795109657925686
Validation loss: 2.833293428327002

Epoch: 6| Step: 6
Training loss: 1.1948167358712865
Validation loss: 2.827032872431135

Epoch: 6| Step: 7
Training loss: 0.8992220894281735
Validation loss: 2.775960385466823

Epoch: 6| Step: 8
Training loss: 1.8730312820119652
Validation loss: 2.803723607953127

Epoch: 6| Step: 9
Training loss: 0.8284834319986444
Validation loss: 2.8400622899876202

Epoch: 6| Step: 10
Training loss: 0.8632592245891125
Validation loss: 2.7917679630709484

Epoch: 6| Step: 11
Training loss: 0.6438732603268458
Validation loss: 2.832617267179993

Epoch: 6| Step: 12
Training loss: 0.8004257529552367
Validation loss: 2.6872074500251792

Epoch: 6| Step: 13
Training loss: 0.7956203232213461
Validation loss: 2.7898679793648222

Epoch: 209| Step: 0
Training loss: 0.8205331778016417
Validation loss: 2.808960361454989

Epoch: 6| Step: 1
Training loss: 0.7770286956751262
Validation loss: 2.7952072456378407

Epoch: 6| Step: 2
Training loss: 0.6092026784752808
Validation loss: 2.8159378515848754

Epoch: 6| Step: 3
Training loss: 0.8383215660788667
Validation loss: 2.7865550776054047

Epoch: 6| Step: 4
Training loss: 0.6065587476705671
Validation loss: 2.806920819154533

Epoch: 6| Step: 5
Training loss: 0.8811301684239495
Validation loss: 2.780139658596537

Epoch: 6| Step: 6
Training loss: 0.963557323981563
Validation loss: 2.8442119460735373

Epoch: 6| Step: 7
Training loss: 0.8429814122957489
Validation loss: 2.898608577097372

Epoch: 6| Step: 8
Training loss: 1.310787446046837
Validation loss: 2.9143822284074092

Epoch: 6| Step: 9
Training loss: 1.3168063135977222
Validation loss: 2.8331492495107375

Epoch: 6| Step: 10
Training loss: 1.748591332916697
Validation loss: 2.8598639203978857

Epoch: 6| Step: 11
Training loss: 0.7950461100755737
Validation loss: 2.8076836566520442

Epoch: 6| Step: 12
Training loss: 1.2009888548321972
Validation loss: 2.7589301707321474

Epoch: 6| Step: 13
Training loss: 0.9343781946440214
Validation loss: 2.79679945092485

Epoch: 210| Step: 0
Training loss: 0.9475186039650748
Validation loss: 2.757389313501553

Epoch: 6| Step: 1
Training loss: 0.8222565639114392
Validation loss: 2.783677616831308

Epoch: 6| Step: 2
Training loss: 0.8779291104154632
Validation loss: 2.790854127027523

Epoch: 6| Step: 3
Training loss: 0.8315315716198183
Validation loss: 2.833408443539932

Epoch: 6| Step: 4
Training loss: 1.2869152333666323
Validation loss: 2.850599403258063

Epoch: 6| Step: 5
Training loss: 0.9516214173967436
Validation loss: 2.8478610885618116

Epoch: 6| Step: 6
Training loss: 1.66858541984347
Validation loss: 2.8598471635604525

Epoch: 6| Step: 7
Training loss: 1.089314759646681
Validation loss: 2.8334892220714827

Epoch: 6| Step: 8
Training loss: 0.6502737220886822
Validation loss: 2.758043014791212

Epoch: 6| Step: 9
Training loss: 0.7329482971473491
Validation loss: 2.8561716253989946

Epoch: 6| Step: 10
Training loss: 1.0732342456804942
Validation loss: 2.818231380144297

Epoch: 6| Step: 11
Training loss: 0.8322852378345477
Validation loss: 2.7625073175347765

Epoch: 6| Step: 12
Training loss: 0.9025420264183236
Validation loss: 2.7907285442557823

Epoch: 6| Step: 13
Training loss: 1.0107730289489922
Validation loss: 2.8578004236454553

Epoch: 211| Step: 0
Training loss: 0.4976123485034947
Validation loss: 2.786544974337821

Epoch: 6| Step: 1
Training loss: 0.9558206803721284
Validation loss: 2.841992537326934

Epoch: 6| Step: 2
Training loss: 1.5051091919382402
Validation loss: 2.846215321794895

Epoch: 6| Step: 3
Training loss: 0.7294105167452888
Validation loss: 2.8259975376941835

Epoch: 6| Step: 4
Training loss: 0.8013164685511595
Validation loss: 2.86269851867964

Epoch: 6| Step: 5
Training loss: 0.7751549042972817
Validation loss: 2.811200081684692

Epoch: 6| Step: 6
Training loss: 1.6719536450864148
Validation loss: 2.8179861179765235

Epoch: 6| Step: 7
Training loss: 0.5946476324913311
Validation loss: 2.813726510947323

Epoch: 6| Step: 8
Training loss: 0.8848384465107996
Validation loss: 2.8513904537050667

Epoch: 6| Step: 9
Training loss: 0.7826120329292755
Validation loss: 2.8281196327228795

Epoch: 6| Step: 10
Training loss: 1.420314981019861
Validation loss: 2.879826557778074

Epoch: 6| Step: 11
Training loss: 1.0628525205242854
Validation loss: 2.818614318130871

Epoch: 6| Step: 12
Training loss: 0.889699823463665
Validation loss: 2.7812648015574943

Epoch: 6| Step: 13
Training loss: 0.7632855465005699
Validation loss: 2.8478778810424994

Epoch: 212| Step: 0
Training loss: 1.92812083041391
Validation loss: 2.855682824247153

Epoch: 6| Step: 1
Training loss: 0.93640979319971
Validation loss: 2.810551943585542

Epoch: 6| Step: 2
Training loss: 0.7852225584052492
Validation loss: 2.840195943129669

Epoch: 6| Step: 3
Training loss: 0.9314319048904627
Validation loss: 2.8637764065858606

Epoch: 6| Step: 4
Training loss: 0.9144019124365671
Validation loss: 2.8898476045020254

Epoch: 6| Step: 5
Training loss: 0.8784797820585609
Validation loss: 2.791412766615639

Epoch: 6| Step: 6
Training loss: 0.7485729787767846
Validation loss: 2.8830431093849254

Epoch: 6| Step: 7
Training loss: 0.8098476105262554
Validation loss: 2.8565825565764817

Epoch: 6| Step: 8
Training loss: 1.2071939994445473
Validation loss: 2.804175525857233

Epoch: 6| Step: 9
Training loss: 0.8614329925155698
Validation loss: 2.791663914769273

Epoch: 6| Step: 10
Training loss: 0.5766523523795887
Validation loss: 2.7290135600311225

Epoch: 6| Step: 11
Training loss: 0.94753565134901
Validation loss: 2.735413228885285

Epoch: 6| Step: 12
Training loss: 0.9119981456955245
Validation loss: 2.8129026760483633

Epoch: 6| Step: 13
Training loss: 0.7992061848925214
Validation loss: 2.812756795109443

Epoch: 213| Step: 0
Training loss: 0.7831122519269137
Validation loss: 2.8243446585841863

Epoch: 6| Step: 1
Training loss: 0.4633282713161877
Validation loss: 2.7880099578498982

Epoch: 6| Step: 2
Training loss: 0.8751760714356219
Validation loss: 2.842166403813962

Epoch: 6| Step: 3
Training loss: 0.780741716979176
Validation loss: 2.808712592018013

Epoch: 6| Step: 4
Training loss: 0.9636190572365629
Validation loss: 2.858991058643401

Epoch: 6| Step: 5
Training loss: 0.8785375203092151
Validation loss: 2.808146137333746

Epoch: 6| Step: 6
Training loss: 1.655520584425498
Validation loss: 2.838135049143131

Epoch: 6| Step: 7
Training loss: 1.2759940106062997
Validation loss: 2.8034023220026785

Epoch: 6| Step: 8
Training loss: 0.8176765233228636
Validation loss: 2.8297779739326825

Epoch: 6| Step: 9
Training loss: 0.9061876472858731
Validation loss: 2.8034753686081273

Epoch: 6| Step: 10
Training loss: 0.781350777801812
Validation loss: 2.8222057718972327

Epoch: 6| Step: 11
Training loss: 0.956879522012681
Validation loss: 2.803777421308971

Epoch: 6| Step: 12
Training loss: 0.8353881456892538
Validation loss: 2.8682440977237262

Epoch: 6| Step: 13
Training loss: 1.1491735266650627
Validation loss: 2.8170870708916045

Epoch: 214| Step: 0
Training loss: 0.6016808678235837
Validation loss: 2.8049712821183945

Epoch: 6| Step: 1
Training loss: 0.7430700576016708
Validation loss: 2.8697271368637622

Epoch: 6| Step: 2
Training loss: 0.8323815553048706
Validation loss: 2.873418068694778

Epoch: 6| Step: 3
Training loss: 1.1216886317769805
Validation loss: 2.853663063635518

Epoch: 6| Step: 4
Training loss: 0.6578535742179935
Validation loss: 2.8374577730596604

Epoch: 6| Step: 5
Training loss: 0.7793016935500701
Validation loss: 2.8707569988789627

Epoch: 6| Step: 6
Training loss: 0.5863584913386948
Validation loss: 2.8203940340128604

Epoch: 6| Step: 7
Training loss: 0.9394970921242515
Validation loss: 2.773449792969015

Epoch: 6| Step: 8
Training loss: 0.7664908359524731
Validation loss: 2.8671759554070135

Epoch: 6| Step: 9
Training loss: 0.8129684125058986
Validation loss: 2.857312068015729

Epoch: 6| Step: 10
Training loss: 1.142776028700756
Validation loss: 2.8587630820965395

Epoch: 6| Step: 11
Training loss: 1.26958557012695
Validation loss: 2.9422630490789885

Epoch: 6| Step: 12
Training loss: 0.80865397206013
Validation loss: 2.811321908967697

Epoch: 6| Step: 13
Training loss: 1.9860110409593956
Validation loss: 2.8751205612556783

Epoch: 215| Step: 0
Training loss: 1.1582909690647807
Validation loss: 2.83088032103374

Epoch: 6| Step: 1
Training loss: 0.6037591732899945
Validation loss: 2.8254439851825657

Epoch: 6| Step: 2
Training loss: 0.5065926204812582
Validation loss: 2.811785797990184

Epoch: 6| Step: 3
Training loss: 1.112225054937264
Validation loss: 2.8418397880538913

Epoch: 6| Step: 4
Training loss: 1.3152314782287764
Validation loss: 2.854931747380064

Epoch: 6| Step: 5
Training loss: 1.7025008151462748
Validation loss: 2.80338624823393

Epoch: 6| Step: 6
Training loss: 0.767484392262167
Validation loss: 2.849307139428742

Epoch: 6| Step: 7
Training loss: 0.6315052517289728
Validation loss: 2.84043030975663

Epoch: 6| Step: 8
Training loss: 0.9266714009557399
Validation loss: 2.77540180688154

Epoch: 6| Step: 9
Training loss: 0.717388812963585
Validation loss: 2.799862344230428

Epoch: 6| Step: 10
Training loss: 0.6864567123262738
Validation loss: 2.789105868247238

Epoch: 6| Step: 11
Training loss: 0.7306433484308203
Validation loss: 2.782778959020397

Epoch: 6| Step: 12
Training loss: 1.0079055861428703
Validation loss: 2.714968964321471

Epoch: 6| Step: 13
Training loss: 0.7899271316360961
Validation loss: 2.7749113509764585

Epoch: 216| Step: 0
Training loss: 0.6895089059369344
Validation loss: 2.776618759166349

Epoch: 6| Step: 1
Training loss: 1.0163461912269105
Validation loss: 2.843481183883224

Epoch: 6| Step: 2
Training loss: 1.0645688055332438
Validation loss: 2.827055853698657

Epoch: 6| Step: 3
Training loss: 0.6387690432298362
Validation loss: 2.7743731286120705

Epoch: 6| Step: 4
Training loss: 0.4955846472063615
Validation loss: 2.823448452473522

Epoch: 6| Step: 5
Training loss: 2.0336613354056823
Validation loss: 2.7950067798257034

Epoch: 6| Step: 6
Training loss: 1.0418506586976304
Validation loss: 2.910631001980768

Epoch: 6| Step: 7
Training loss: 1.0448322578575144
Validation loss: 2.796123496024659

Epoch: 6| Step: 8
Training loss: 1.1103740545593241
Validation loss: 2.823610042330599

Epoch: 6| Step: 9
Training loss: 0.711525809875437
Validation loss: 2.8035991260640225

Epoch: 6| Step: 10
Training loss: 0.7020660054891831
Validation loss: 2.8454083927369593

Epoch: 6| Step: 11
Training loss: 0.8475417661924832
Validation loss: 2.796724191077073

Epoch: 6| Step: 12
Training loss: 0.5928427138846077
Validation loss: 2.7945998046474525

Epoch: 6| Step: 13
Training loss: 0.9037260227003729
Validation loss: 2.774446653062553

Epoch: 217| Step: 0
Training loss: 1.6739830915720566
Validation loss: 2.7918432568926805

Epoch: 6| Step: 1
Training loss: 0.900514573442637
Validation loss: 2.900269634493296

Epoch: 6| Step: 2
Training loss: 0.7129399530772038
Validation loss: 2.879138980259434

Epoch: 6| Step: 3
Training loss: 0.8052805224617458
Validation loss: 2.931612567398839

Epoch: 6| Step: 4
Training loss: 1.0700609788720634
Validation loss: 2.8147461999115992

Epoch: 6| Step: 5
Training loss: 0.9970909960896409
Validation loss: 2.8997186809323723

Epoch: 6| Step: 6
Training loss: 0.5145972731345672
Validation loss: 2.8531010487816086

Epoch: 6| Step: 7
Training loss: 0.7622328759356519
Validation loss: 2.805039273076055

Epoch: 6| Step: 8
Training loss: 0.8315034723673864
Validation loss: 2.7438403851126654

Epoch: 6| Step: 9
Training loss: 0.8318836636453969
Validation loss: 2.756317079034893

Epoch: 6| Step: 10
Training loss: 0.9502679810763474
Validation loss: 2.804432665228687

Epoch: 6| Step: 11
Training loss: 0.7247657298722993
Validation loss: 2.783077025652163

Epoch: 6| Step: 12
Training loss: 1.0532675898432502
Validation loss: 2.760566654568992

Epoch: 6| Step: 13
Training loss: 1.152862587200281
Validation loss: 2.8706092892845385

Epoch: 218| Step: 0
Training loss: 1.1184315190844138
Validation loss: 2.875156052818504

Epoch: 6| Step: 1
Training loss: 0.8231377043210713
Validation loss: 2.865781129045607

Epoch: 6| Step: 2
Training loss: 0.9473763941860145
Validation loss: 2.8407452886926685

Epoch: 6| Step: 3
Training loss: 0.9728476707504722
Validation loss: 2.9409905790506463

Epoch: 6| Step: 4
Training loss: 0.696669144439702
Validation loss: 2.9955613626074165

Epoch: 6| Step: 5
Training loss: 1.7538362416863746
Validation loss: 2.870669102135154

Epoch: 6| Step: 6
Training loss: 0.9633625104526932
Validation loss: 2.9462996227567

Epoch: 6| Step: 7
Training loss: 0.5512413105528485
Validation loss: 2.867194651249171

Epoch: 6| Step: 8
Training loss: 0.7612736501919215
Validation loss: 2.895323369979697

Epoch: 6| Step: 9
Training loss: 0.5545302692059625
Validation loss: 2.8744072233913904

Epoch: 6| Step: 10
Training loss: 1.20337114664794
Validation loss: 2.848080157424405

Epoch: 6| Step: 11
Training loss: 0.6311930196369462
Validation loss: 2.8352450671789784

Epoch: 6| Step: 12
Training loss: 0.8273685527250048
Validation loss: 2.8058955319154255

Epoch: 6| Step: 13
Training loss: 1.1252611175137066
Validation loss: 2.8479966115904594

Epoch: 219| Step: 0
Training loss: 0.7829796526958057
Validation loss: 2.7543051428520413

Epoch: 6| Step: 1
Training loss: 0.6934451197944345
Validation loss: 2.7751374528539423

Epoch: 6| Step: 2
Training loss: 0.8406696960025067
Validation loss: 2.797821580904841

Epoch: 6| Step: 3
Training loss: 1.4155096583924531
Validation loss: 2.8387370797650924

Epoch: 6| Step: 4
Training loss: 0.5545219926660635
Validation loss: 2.836059427574

Epoch: 6| Step: 5
Training loss: 0.6600389997201536
Validation loss: 2.83777457321784

Epoch: 6| Step: 6
Training loss: 0.8037366341507386
Validation loss: 2.7895238300688403

Epoch: 6| Step: 7
Training loss: 1.7056501375095374
Validation loss: 2.8287756436621674

Epoch: 6| Step: 8
Training loss: 0.9877790901691237
Validation loss: 2.810383855365654

Epoch: 6| Step: 9
Training loss: 0.6075620826740948
Validation loss: 2.881830525476658

Epoch: 6| Step: 10
Training loss: 1.1172943597652412
Validation loss: 2.8104422777129225

Epoch: 6| Step: 11
Training loss: 0.9121480276016936
Validation loss: 2.8192858178960694

Epoch: 6| Step: 12
Training loss: 0.708101800402187
Validation loss: 2.818078280623056

Epoch: 6| Step: 13
Training loss: 0.7483848425831358
Validation loss: 2.8760274764920646

Epoch: 220| Step: 0
Training loss: 1.0373412481899233
Validation loss: 2.8006854038695344

Epoch: 6| Step: 1
Training loss: 0.9898782725587767
Validation loss: 2.8250330467316727

Epoch: 6| Step: 2
Training loss: 1.1000151893260597
Validation loss: 2.810140234376873

Epoch: 6| Step: 3
Training loss: 0.559841922264086
Validation loss: 2.738442728647855

Epoch: 6| Step: 4
Training loss: 0.8101639544011225
Validation loss: 2.864923773678568

Epoch: 6| Step: 5
Training loss: 0.5453549649993353
Validation loss: 2.8284226501522336

Epoch: 6| Step: 6
Training loss: 1.8326553550533946
Validation loss: 2.8770544341171527

Epoch: 6| Step: 7
Training loss: 0.9364513572345337
Validation loss: 2.831797630057448

Epoch: 6| Step: 8
Training loss: 0.5952223541812364
Validation loss: 2.773827381220782

Epoch: 6| Step: 9
Training loss: 0.6678440133684609
Validation loss: 2.8862483390229494

Epoch: 6| Step: 10
Training loss: 0.983127499848211
Validation loss: 2.913678495930864

Epoch: 6| Step: 11
Training loss: 0.6179218510748726
Validation loss: 2.8639428457297056

Epoch: 6| Step: 12
Training loss: 0.9041887057968667
Validation loss: 2.844445014393107

Epoch: 6| Step: 13
Training loss: 0.7715121879875774
Validation loss: 2.934166931423907

Epoch: 221| Step: 0
Training loss: 1.722282178751211
Validation loss: 2.780865274744482

Epoch: 6| Step: 1
Training loss: 0.6271075477445164
Validation loss: 2.7856034770930362

Epoch: 6| Step: 2
Training loss: 0.6349101679630781
Validation loss: 2.8227926886291366

Epoch: 6| Step: 3
Training loss: 1.0377143776260693
Validation loss: 2.8234804489001966

Epoch: 6| Step: 4
Training loss: 0.7634113774805722
Validation loss: 2.7687943468639795

Epoch: 6| Step: 5
Training loss: 1.2328313035582532
Validation loss: 2.8040598642567915

Epoch: 6| Step: 6
Training loss: 0.9284344089986886
Validation loss: 2.814040376786996

Epoch: 6| Step: 7
Training loss: 0.8147919679538914
Validation loss: 2.7108941711422405

Epoch: 6| Step: 8
Training loss: 0.577100103068074
Validation loss: 2.869585757936979

Epoch: 6| Step: 9
Training loss: 0.739699278505228
Validation loss: 2.8568841059207277

Epoch: 6| Step: 10
Training loss: 0.7955526337897011
Validation loss: 2.828220119949148

Epoch: 6| Step: 11
Training loss: 0.8595021934015271
Validation loss: 2.9150114176348274

Epoch: 6| Step: 12
Training loss: 1.0979192018328838
Validation loss: 2.833330720077506

Epoch: 6| Step: 13
Training loss: 0.4783071414104525
Validation loss: 2.8753208589496246

Epoch: 222| Step: 0
Training loss: 0.7683589933362439
Validation loss: 2.821251273548592

Epoch: 6| Step: 1
Training loss: 0.8329624821089512
Validation loss: 2.7705490186332122

Epoch: 6| Step: 2
Training loss: 0.933201535887421
Validation loss: 2.7499447296830613

Epoch: 6| Step: 3
Training loss: 0.7645148968190162
Validation loss: 2.824970192878584

Epoch: 6| Step: 4
Training loss: 0.6672602013100775
Validation loss: 2.83094600535988

Epoch: 6| Step: 5
Training loss: 0.7364955883683868
Validation loss: 2.81107945772007

Epoch: 6| Step: 6
Training loss: 0.537418235059995
Validation loss: 2.813945271763013

Epoch: 6| Step: 7
Training loss: 1.6553150633132616
Validation loss: 2.828910016163859

Epoch: 6| Step: 8
Training loss: 1.0909523743112903
Validation loss: 2.8364853693168257

Epoch: 6| Step: 9
Training loss: 1.1144505834700908
Validation loss: 2.8773261348762773

Epoch: 6| Step: 10
Training loss: 0.7022615853559574
Validation loss: 2.8309386642874195

Epoch: 6| Step: 11
Training loss: 1.193501415633795
Validation loss: 2.764024778014883

Epoch: 6| Step: 12
Training loss: 0.6056750530585364
Validation loss: 2.8419119515556956

Epoch: 6| Step: 13
Training loss: 1.1131311148079825
Validation loss: 2.7984568635152423

Epoch: 223| Step: 0
Training loss: 0.7871782069246406
Validation loss: 2.816224761208653

Epoch: 6| Step: 1
Training loss: 1.1483804597767386
Validation loss: 2.8526534131915957

Epoch: 6| Step: 2
Training loss: 0.7189139303598463
Validation loss: 2.845894993178756

Epoch: 6| Step: 3
Training loss: 0.763929552864734
Validation loss: 2.822260176181483

Epoch: 6| Step: 4
Training loss: 0.489334679083745
Validation loss: 2.900665975701961

Epoch: 6| Step: 5
Training loss: 0.7030480660628636
Validation loss: 2.9050119832678645

Epoch: 6| Step: 6
Training loss: 0.8832536793428907
Validation loss: 2.8566108433941837

Epoch: 6| Step: 7
Training loss: 0.5799613090057119
Validation loss: 2.808177062892814

Epoch: 6| Step: 8
Training loss: 0.8395025225448652
Validation loss: 2.9961666279019123

Epoch: 6| Step: 9
Training loss: 1.7696399781631382
Validation loss: 2.9087451082217717

Epoch: 6| Step: 10
Training loss: 1.0866403295001092
Validation loss: 2.8825106303362817

Epoch: 6| Step: 11
Training loss: 0.9328825727817593
Validation loss: 2.922989957239067

Epoch: 6| Step: 12
Training loss: 0.9304866401496307
Validation loss: 2.8288955341323323

Epoch: 6| Step: 13
Training loss: 0.8936729477966736
Validation loss: 2.8307393953243256

Epoch: 224| Step: 0
Training loss: 0.64923956111232
Validation loss: 2.895188435893326

Epoch: 6| Step: 1
Training loss: 0.7282772952751747
Validation loss: 2.8599584293456513

Epoch: 6| Step: 2
Training loss: 1.7417657452864455
Validation loss: 2.8349168690598283

Epoch: 6| Step: 3
Training loss: 0.6032613570483667
Validation loss: 2.858130053714478

Epoch: 6| Step: 4
Training loss: 0.8753609934417137
Validation loss: 2.7937647683295896

Epoch: 6| Step: 5
Training loss: 0.6563511952079328
Validation loss: 2.8714120978154205

Epoch: 6| Step: 6
Training loss: 0.7237555313557823
Validation loss: 2.77029171050322

Epoch: 6| Step: 7
Training loss: 0.8080266170697148
Validation loss: 2.8205667594218125

Epoch: 6| Step: 8
Training loss: 0.9201950995751912
Validation loss: 2.824825729913855

Epoch: 6| Step: 9
Training loss: 1.1072670157204532
Validation loss: 2.8027062178735886

Epoch: 6| Step: 10
Training loss: 0.555623889402775
Validation loss: 2.8248080337477517

Epoch: 6| Step: 11
Training loss: 0.7792115893818036
Validation loss: 2.8031833763097045

Epoch: 6| Step: 12
Training loss: 1.0781550748749067
Validation loss: 2.795194636092401

Epoch: 6| Step: 13
Training loss: 1.0419553483852197
Validation loss: 2.818359967163616

Epoch: 225| Step: 0
Training loss: 1.189151970082611
Validation loss: 2.8489828625912628

Epoch: 6| Step: 1
Training loss: 0.7303279802267523
Validation loss: 2.88065208249622

Epoch: 6| Step: 2
Training loss: 0.8562165915104418
Validation loss: 2.851850340089585

Epoch: 6| Step: 3
Training loss: 0.6276308241336337
Validation loss: 2.7922908360380103

Epoch: 6| Step: 4
Training loss: 0.7289707919838014
Validation loss: 2.87323955872611

Epoch: 6| Step: 5
Training loss: 0.6741240805137414
Validation loss: 2.9081759890282433

Epoch: 6| Step: 6
Training loss: 0.5373319130159748
Validation loss: 2.8544767355198863

Epoch: 6| Step: 7
Training loss: 0.604559825262287
Validation loss: 2.8168686739772455

Epoch: 6| Step: 8
Training loss: 0.6411932774045592
Validation loss: 2.8309186201149945

Epoch: 6| Step: 9
Training loss: 0.9521725382566798
Validation loss: 2.87413996119898

Epoch: 6| Step: 10
Training loss: 0.6296092304211109
Validation loss: 2.8531110277840033

Epoch: 6| Step: 11
Training loss: 1.7895903495796102
Validation loss: 2.909878342435202

Epoch: 6| Step: 12
Training loss: 0.8335357102385715
Validation loss: 2.814962030022563

Epoch: 6| Step: 13
Training loss: 1.1114957176911937
Validation loss: 2.8634640373807922

Epoch: 226| Step: 0
Training loss: 0.7406559853168425
Validation loss: 2.8659657327414028

Epoch: 6| Step: 1
Training loss: 0.6248537369292704
Validation loss: 2.8135976344933544

Epoch: 6| Step: 2
Training loss: 0.6640192578766138
Validation loss: 2.7471289675340933

Epoch: 6| Step: 3
Training loss: 0.7684645642342688
Validation loss: 2.854377186568823

Epoch: 6| Step: 4
Training loss: 0.5671962359047267
Validation loss: 2.874140286098275

Epoch: 6| Step: 5
Training loss: 0.6857615295133498
Validation loss: 2.873920694187451

Epoch: 6| Step: 6
Training loss: 0.6696033220882112
Validation loss: 2.8875146714095123

Epoch: 6| Step: 7
Training loss: 0.8563224330253884
Validation loss: 2.8174417102812472

Epoch: 6| Step: 8
Training loss: 0.8073672515596549
Validation loss: 2.841672690563212

Epoch: 6| Step: 9
Training loss: 0.6316215233872258
Validation loss: 2.8072389492730454

Epoch: 6| Step: 10
Training loss: 0.6546678089467253
Validation loss: 2.869466445873791

Epoch: 6| Step: 11
Training loss: 1.6775718672433189
Validation loss: 2.828710955480851

Epoch: 6| Step: 12
Training loss: 1.2613432239752242
Validation loss: 2.8260514752819703

Epoch: 6| Step: 13
Training loss: 1.1358505551568867
Validation loss: 2.8210170496322053

Epoch: 227| Step: 0
Training loss: 1.7901837029840506
Validation loss: 2.864580679227582

Epoch: 6| Step: 1
Training loss: 0.9047571250991246
Validation loss: 2.868020652967085

Epoch: 6| Step: 2
Training loss: 0.7950515079006825
Validation loss: 2.808781079520858

Epoch: 6| Step: 3
Training loss: 0.6218409332452375
Validation loss: 2.870337991007727

Epoch: 6| Step: 4
Training loss: 0.7707274381395894
Validation loss: 2.928036047128188

Epoch: 6| Step: 5
Training loss: 0.7529206232101722
Validation loss: 2.9176573206291603

Epoch: 6| Step: 6
Training loss: 0.7942639001429065
Validation loss: 2.9424282829686814

Epoch: 6| Step: 7
Training loss: 0.5800375619185929
Validation loss: 2.8314967280229815

Epoch: 6| Step: 8
Training loss: 0.9560520690321012
Validation loss: 2.8105107654817107

Epoch: 6| Step: 9
Training loss: 1.0050055277847931
Validation loss: 2.860105257987293

Epoch: 6| Step: 10
Training loss: 0.9079728357541192
Validation loss: 2.8814033020676333

Epoch: 6| Step: 11
Training loss: 0.40967929901713945
Validation loss: 2.7706589369040353

Epoch: 6| Step: 12
Training loss: 1.254060539664232
Validation loss: 2.7610395388555555

Epoch: 6| Step: 13
Training loss: 0.7181091353985584
Validation loss: 2.761251860652934

Epoch: 228| Step: 0
Training loss: 0.7126135718863407
Validation loss: 2.815703439696013

Epoch: 6| Step: 1
Training loss: 0.6970669546177376
Validation loss: 2.7906314201893414

Epoch: 6| Step: 2
Training loss: 0.699236587211654
Validation loss: 2.7589936145129252

Epoch: 6| Step: 3
Training loss: 0.8976223108367947
Validation loss: 2.82460073558464

Epoch: 6| Step: 4
Training loss: 0.6954941887232238
Validation loss: 2.8141581698232816

Epoch: 6| Step: 5
Training loss: 0.9230467574756755
Validation loss: 2.830924922534646

Epoch: 6| Step: 6
Training loss: 0.6058477876540174
Validation loss: 2.8653863833167104

Epoch: 6| Step: 7
Training loss: 0.9373086098177335
Validation loss: 2.8760694781299705

Epoch: 6| Step: 8
Training loss: 1.245540196986416
Validation loss: 2.8314926161402854

Epoch: 6| Step: 9
Training loss: 0.5745415591139014
Validation loss: 2.797310495125473

Epoch: 6| Step: 10
Training loss: 1.6293418539675626
Validation loss: 2.8285956509237877

Epoch: 6| Step: 11
Training loss: 0.7078717541681693
Validation loss: 2.858914239166217

Epoch: 6| Step: 12
Training loss: 0.6898183314650768
Validation loss: 2.8702131655301812

Epoch: 6| Step: 13
Training loss: 0.7413669668227755
Validation loss: 2.875575063385583

Epoch: 229| Step: 0
Training loss: 0.5048847604267609
Validation loss: 3.003397752626307

Epoch: 6| Step: 1
Training loss: 1.1976972738407752
Validation loss: 2.853097441569084

Epoch: 6| Step: 2
Training loss: 1.648238689854203
Validation loss: 2.867692215210587

Epoch: 6| Step: 3
Training loss: 0.6661141510071198
Validation loss: 2.9196452508408006

Epoch: 6| Step: 4
Training loss: 0.9165073856049932
Validation loss: 2.8876824600678503

Epoch: 6| Step: 5
Training loss: 0.4972016886011882
Validation loss: 2.9440615128080654

Epoch: 6| Step: 6
Training loss: 0.5999732885772713
Validation loss: 2.8748102263690924

Epoch: 6| Step: 7
Training loss: 0.7744965286891269
Validation loss: 2.919501947424844

Epoch: 6| Step: 8
Training loss: 0.3741651221854456
Validation loss: 2.8281703966406786

Epoch: 6| Step: 9
Training loss: 0.5937827251852259
Validation loss: 2.8335110010279423

Epoch: 6| Step: 10
Training loss: 1.0128716928615669
Validation loss: 2.8616528913699213

Epoch: 6| Step: 11
Training loss: 0.9670915250966778
Validation loss: 2.792865841977081

Epoch: 6| Step: 12
Training loss: 1.069956643750255
Validation loss: 2.829118220532954

Epoch: 6| Step: 13
Training loss: 0.7382651836927853
Validation loss: 2.9093921042163875

Epoch: 230| Step: 0
Training loss: 1.2206682612208881
Validation loss: 2.8464762995077373

Epoch: 6| Step: 1
Training loss: 1.6523867482030976
Validation loss: 2.7835814458700194

Epoch: 6| Step: 2
Training loss: 0.8787061675468585
Validation loss: 2.868645680954142

Epoch: 6| Step: 3
Training loss: 0.9007867367950374
Validation loss: 2.8583447975136393

Epoch: 6| Step: 4
Training loss: 0.6314797672555269
Validation loss: 2.848611721082358

Epoch: 6| Step: 5
Training loss: 0.8302461341921831
Validation loss: 2.861804360954095

Epoch: 6| Step: 6
Training loss: 0.5321696119723766
Validation loss: 2.8801927525867472

Epoch: 6| Step: 7
Training loss: 0.5930652685608324
Validation loss: 2.8348778881033225

Epoch: 6| Step: 8
Training loss: 0.7750362480054408
Validation loss: 2.8464151476545623

Epoch: 6| Step: 9
Training loss: 0.7170351967918053
Validation loss: 2.7788693672701816

Epoch: 6| Step: 10
Training loss: 0.8297913538416385
Validation loss: 2.8096661030378858

Epoch: 6| Step: 11
Training loss: 0.9613325656011729
Validation loss: 2.85521665922387

Epoch: 6| Step: 12
Training loss: 0.9224511948264257
Validation loss: 2.852055748210967

Epoch: 6| Step: 13
Training loss: 0.6238033043707519
Validation loss: 2.8848714393695016

Epoch: 231| Step: 0
Training loss: 0.8770202746945716
Validation loss: 2.8039339659575147

Epoch: 6| Step: 1
Training loss: 0.775401809573282
Validation loss: 2.8730695297001523

Epoch: 6| Step: 2
Training loss: 1.746659223574633
Validation loss: 2.8632909645377214

Epoch: 6| Step: 3
Training loss: 0.7169704383039115
Validation loss: 2.8530855335571363

Epoch: 6| Step: 4
Training loss: 0.48865208086378525
Validation loss: 2.78115690268388

Epoch: 6| Step: 5
Training loss: 0.6802299351983785
Validation loss: 2.7900134975466906

Epoch: 6| Step: 6
Training loss: 0.7338387174764746
Validation loss: 2.8898223724908325

Epoch: 6| Step: 7
Training loss: 0.9020011218332559
Validation loss: 2.8533277229969927

Epoch: 6| Step: 8
Training loss: 0.6476249659659195
Validation loss: 2.805031559631181

Epoch: 6| Step: 9
Training loss: 0.4484129437093135
Validation loss: 2.9140985672451363

Epoch: 6| Step: 10
Training loss: 0.5883164495345495
Validation loss: 2.7870620477583765

Epoch: 6| Step: 11
Training loss: 1.2077435117218396
Validation loss: 2.7770918862930616

Epoch: 6| Step: 12
Training loss: 0.8700988288081478
Validation loss: 2.7931104077248006

Epoch: 6| Step: 13
Training loss: 0.9009073557923163
Validation loss: 2.7560231687091434

Epoch: 232| Step: 0
Training loss: 0.7100758623508293
Validation loss: 2.7844256869182655

Epoch: 6| Step: 1
Training loss: 0.5253299266822526
Validation loss: 2.8814836177048027

Epoch: 6| Step: 2
Training loss: 1.2662516796707204
Validation loss: 2.914232441682835

Epoch: 6| Step: 3
Training loss: 0.7970267880555479
Validation loss: 2.853623921007993

Epoch: 6| Step: 4
Training loss: 0.9468243701857277
Validation loss: 2.8842785561178395

Epoch: 6| Step: 5
Training loss: 0.65523507337077
Validation loss: 2.8831394771684087

Epoch: 6| Step: 6
Training loss: 0.9536595955895105
Validation loss: 2.8035332616696245

Epoch: 6| Step: 7
Training loss: 0.7357760922584723
Validation loss: 2.8585569813224514

Epoch: 6| Step: 8
Training loss: 0.7849385353492817
Validation loss: 2.8038257915056244

Epoch: 6| Step: 9
Training loss: 0.6646052666834559
Validation loss: 2.803967538445277

Epoch: 6| Step: 10
Training loss: 1.6616976415157023
Validation loss: 2.8891221959913276

Epoch: 6| Step: 11
Training loss: 0.40495891085927377
Validation loss: 2.835164843234658

Epoch: 6| Step: 12
Training loss: 0.5162841167676302
Validation loss: 2.8149571458299847

Epoch: 6| Step: 13
Training loss: 0.5268102419641102
Validation loss: 2.8513653552044267

Epoch: 233| Step: 0
Training loss: 0.8862801361878636
Validation loss: 2.797929050155886

Epoch: 6| Step: 1
Training loss: 0.8112721702590987
Validation loss: 2.8901906623667672

Epoch: 6| Step: 2
Training loss: 0.8056903256846234
Validation loss: 2.861314793057678

Epoch: 6| Step: 3
Training loss: 0.7140721393493848
Validation loss: 2.917837021665994

Epoch: 6| Step: 4
Training loss: 0.7048243226993565
Validation loss: 2.776841409270995

Epoch: 6| Step: 5
Training loss: 0.7229020808907756
Validation loss: 2.7562050894309897

Epoch: 6| Step: 6
Training loss: 0.5730390822511956
Validation loss: 2.8331146202567687

Epoch: 6| Step: 7
Training loss: 0.777332861742604
Validation loss: 2.8135249213057327

Epoch: 6| Step: 8
Training loss: 0.7294439787555315
Validation loss: 2.812588881041873

Epoch: 6| Step: 9
Training loss: 0.9937315213386738
Validation loss: 2.853402882497844

Epoch: 6| Step: 10
Training loss: 0.5334782711419834
Validation loss: 2.864444872659882

Epoch: 6| Step: 11
Training loss: 0.7350843939694794
Validation loss: 2.8424618916234254

Epoch: 6| Step: 12
Training loss: 0.6903266452153421
Validation loss: 2.8901593632301563

Epoch: 6| Step: 13
Training loss: 1.8323417351673337
Validation loss: 2.9228129046061317

Epoch: 234| Step: 0
Training loss: 0.6489715674833251
Validation loss: 2.9417407085044713

Epoch: 6| Step: 1
Training loss: 0.6759035077059463
Validation loss: 2.861483895810577

Epoch: 6| Step: 2
Training loss: 1.0750454028100522
Validation loss: 2.882908889275576

Epoch: 6| Step: 3
Training loss: 0.53060469985071
Validation loss: 2.920763099976039

Epoch: 6| Step: 4
Training loss: 0.7384452032267798
Validation loss: 2.9273211607694805

Epoch: 6| Step: 5
Training loss: 0.892766118859383
Validation loss: 2.940131030482285

Epoch: 6| Step: 6
Training loss: 0.5752419936921463
Validation loss: 2.898861904553185

Epoch: 6| Step: 7
Training loss: 0.6208454091435904
Validation loss: 2.9157215131054754

Epoch: 6| Step: 8
Training loss: 1.6120161587399855
Validation loss: 2.8753984838564106

Epoch: 6| Step: 9
Training loss: 0.6868029007979838
Validation loss: 2.8033803800096755

Epoch: 6| Step: 10
Training loss: 0.5208749818044338
Validation loss: 2.9329547143733468

Epoch: 6| Step: 11
Training loss: 0.9751272717574001
Validation loss: 2.920058217687595

Epoch: 6| Step: 12
Training loss: 0.8048726211491369
Validation loss: 2.8213624628874716

Epoch: 6| Step: 13
Training loss: 1.0188877808245789
Validation loss: 2.8269862768107537

Epoch: 235| Step: 0
Training loss: 0.6149431780795203
Validation loss: 2.8221421721845954

Epoch: 6| Step: 1
Training loss: 0.5578247325421469
Validation loss: 2.895868415528535

Epoch: 6| Step: 2
Training loss: 0.6494715385529493
Validation loss: 2.8755427276730385

Epoch: 6| Step: 3
Training loss: 0.5179800524276801
Validation loss: 2.826895107411718

Epoch: 6| Step: 4
Training loss: 0.6166553375990549
Validation loss: 2.8360994571226743

Epoch: 6| Step: 5
Training loss: 0.8468352178259713
Validation loss: 2.8642375298055156

Epoch: 6| Step: 6
Training loss: 0.6345788299374036
Validation loss: 2.8173899632302017

Epoch: 6| Step: 7
Training loss: 0.6774084753242886
Validation loss: 2.861811421516979

Epoch: 6| Step: 8
Training loss: 0.6408615140915258
Validation loss: 2.829633447477344

Epoch: 6| Step: 9
Training loss: 0.906829648609197
Validation loss: 2.9421044914487147

Epoch: 6| Step: 10
Training loss: 0.9089902686635789
Validation loss: 2.9148694268585627

Epoch: 6| Step: 11
Training loss: 0.740340574995426
Validation loss: 2.898825058299111

Epoch: 6| Step: 12
Training loss: 1.6423913076078758
Validation loss: 2.8578745130815415

Epoch: 6| Step: 13
Training loss: 0.7980708704481153
Validation loss: 2.835456408003306

Epoch: 236| Step: 0
Training loss: 0.6583302315707312
Validation loss: 2.816386229381749

Epoch: 6| Step: 1
Training loss: 0.5356323463354565
Validation loss: 2.907103122751171

Epoch: 6| Step: 2
Training loss: 0.5176655821415302
Validation loss: 2.766439156389095

Epoch: 6| Step: 3
Training loss: 0.8306062342330093
Validation loss: 2.881081113740876

Epoch: 6| Step: 4
Training loss: 1.7392197722055955
Validation loss: 2.8388026032976477

Epoch: 6| Step: 5
Training loss: 0.9421162124412245
Validation loss: 2.8284525391816633

Epoch: 6| Step: 6
Training loss: 1.172377211723515
Validation loss: 2.799559088460666

Epoch: 6| Step: 7
Training loss: 0.5713398707040671
Validation loss: 2.820795949428057

Epoch: 6| Step: 8
Training loss: 0.561828583443313
Validation loss: 2.896446236350534

Epoch: 6| Step: 9
Training loss: 0.7646197512179742
Validation loss: 2.9089589295039127

Epoch: 6| Step: 10
Training loss: 0.7244926420302819
Validation loss: 2.9696244340684568

Epoch: 6| Step: 11
Training loss: 1.1682832734561226
Validation loss: 2.894573394976511

Epoch: 6| Step: 12
Training loss: 0.8402655673300209
Validation loss: 2.8777197122750473

Epoch: 6| Step: 13
Training loss: 0.6367808586673908
Validation loss: 2.8634141558948323

Epoch: 237| Step: 0
Training loss: 0.6525174669142147
Validation loss: 2.7754781030501143

Epoch: 6| Step: 1
Training loss: 0.6182834696735896
Validation loss: 2.871506676422741

Epoch: 6| Step: 2
Training loss: 0.4356382128820207
Validation loss: 2.8024351733420723

Epoch: 6| Step: 3
Training loss: 1.0909149484043656
Validation loss: 2.895485607831878

Epoch: 6| Step: 4
Training loss: 0.6696176088205428
Validation loss: 2.927228093668594

Epoch: 6| Step: 5
Training loss: 0.8824208834145671
Validation loss: 2.8803015493216715

Epoch: 6| Step: 6
Training loss: 1.0197591125051206
Validation loss: 2.8777564835548133

Epoch: 6| Step: 7
Training loss: 0.7948827335553151
Validation loss: 2.94452283612948

Epoch: 6| Step: 8
Training loss: 1.5820126379354638
Validation loss: 2.862751230378797

Epoch: 6| Step: 9
Training loss: 1.2049274566784276
Validation loss: 2.8463843164595137

Epoch: 6| Step: 10
Training loss: 0.47616798455618203
Validation loss: 2.9453644279941384

Epoch: 6| Step: 11
Training loss: 0.5191222567211391
Validation loss: 3.0264277296728466

Epoch: 6| Step: 12
Training loss: 0.6225517721363397
Validation loss: 2.9026704298873196

Epoch: 6| Step: 13
Training loss: 0.6447920762791562
Validation loss: 2.8579210986900048

Epoch: 238| Step: 0
Training loss: 1.6049933182051426
Validation loss: 2.919826762033506

Epoch: 6| Step: 1
Training loss: 0.5118503546924188
Validation loss: 2.891502501493521

Epoch: 6| Step: 2
Training loss: 0.733967932029181
Validation loss: 2.827709336057327

Epoch: 6| Step: 3
Training loss: 0.8589587157035259
Validation loss: 2.8158007432493504

Epoch: 6| Step: 4
Training loss: 0.6910573650237295
Validation loss: 2.7758252534850856

Epoch: 6| Step: 5
Training loss: 0.9899072050185194
Validation loss: 2.808612340618888

Epoch: 6| Step: 6
Training loss: 0.7344338007984651
Validation loss: 2.8397009672417406

Epoch: 6| Step: 7
Training loss: 1.0389742706241194
Validation loss: 2.881225259251266

Epoch: 6| Step: 8
Training loss: 0.4177540022443158
Validation loss: 2.882996757428757

Epoch: 6| Step: 9
Training loss: 0.7572665263274596
Validation loss: 2.9104384180965988

Epoch: 6| Step: 10
Training loss: 0.4504802075482681
Validation loss: 2.816623674060826

Epoch: 6| Step: 11
Training loss: 0.8396272602059396
Validation loss: 2.8353546636577205

Epoch: 6| Step: 12
Training loss: 0.6106692044550346
Validation loss: 2.829439928868582

Epoch: 6| Step: 13
Training loss: 0.6928380376284283
Validation loss: 2.8846212913583127

Epoch: 239| Step: 0
Training loss: 0.7280142032657796
Validation loss: 2.8560265841150634

Epoch: 6| Step: 1
Training loss: 0.7270154464056723
Validation loss: 2.8987282935291154

Epoch: 6| Step: 2
Training loss: 0.727553112739226
Validation loss: 2.886588720439549

Epoch: 6| Step: 3
Training loss: 1.5807207872984592
Validation loss: 2.851752051058569

Epoch: 6| Step: 4
Training loss: 0.41793159961485865
Validation loss: 2.8448849673332135

Epoch: 6| Step: 5
Training loss: 1.0802427859622739
Validation loss: 2.828341438905262

Epoch: 6| Step: 6
Training loss: 0.8125647739120084
Validation loss: 2.879005268245363

Epoch: 6| Step: 7
Training loss: 0.9936326683402149
Validation loss: 2.8047130870448886

Epoch: 6| Step: 8
Training loss: 0.6422204874666816
Validation loss: 2.8624756197050774

Epoch: 6| Step: 9
Training loss: 0.705444135268157
Validation loss: 2.8952956260742537

Epoch: 6| Step: 10
Training loss: 0.7753747126486352
Validation loss: 2.899602863095982

Epoch: 6| Step: 11
Training loss: 0.48551410125580724
Validation loss: 2.875717550379001

Epoch: 6| Step: 12
Training loss: 0.621637166612782
Validation loss: 2.884200536453165

Epoch: 6| Step: 13
Training loss: 0.514251526976355
Validation loss: 2.8065722268481132

Epoch: 240| Step: 0
Training loss: 0.3896109770930648
Validation loss: 2.846450864516879

Epoch: 6| Step: 1
Training loss: 0.6690815807688107
Validation loss: 2.8719117052612657

Epoch: 6| Step: 2
Training loss: 0.5052009922818235
Validation loss: 2.8947352836382625

Epoch: 6| Step: 3
Training loss: 1.0780999001055254
Validation loss: 2.8676468068118437

Epoch: 6| Step: 4
Training loss: 0.554260626932352
Validation loss: 2.8097034538154677

Epoch: 6| Step: 5
Training loss: 0.6142007046156692
Validation loss: 2.839042987941887

Epoch: 6| Step: 6
Training loss: 0.7153458629742094
Validation loss: 2.94247307751314

Epoch: 6| Step: 7
Training loss: 1.6661617308900916
Validation loss: 2.8480726721636502

Epoch: 6| Step: 8
Training loss: 0.677072229049788
Validation loss: 2.921690039126853

Epoch: 6| Step: 9
Training loss: 1.11919367000434
Validation loss: 2.8354387921981967

Epoch: 6| Step: 10
Training loss: 0.5709656411237116
Validation loss: 2.932396425552004

Epoch: 6| Step: 11
Training loss: 0.5805738495140239
Validation loss: 2.904222594771181

Epoch: 6| Step: 12
Training loss: 1.0061678811441366
Validation loss: 2.922668743608194

Epoch: 6| Step: 13
Training loss: 0.6548159689484137
Validation loss: 2.9368575590776276

Epoch: 241| Step: 0
Training loss: 0.744589362423365
Validation loss: 2.937988024274094

Epoch: 6| Step: 1
Training loss: 0.9614643420482496
Validation loss: 2.8650319574647525

Epoch: 6| Step: 2
Training loss: 0.846116033456129
Validation loss: 2.816999961011636

Epoch: 6| Step: 3
Training loss: 1.0184406278830829
Validation loss: 2.8567738609796347

Epoch: 6| Step: 4
Training loss: 0.37457921341287725
Validation loss: 2.8938218936544287

Epoch: 6| Step: 5
Training loss: 1.7202286342097315
Validation loss: 2.873503046496469

Epoch: 6| Step: 6
Training loss: 0.675828480034777
Validation loss: 2.8997340014569133

Epoch: 6| Step: 7
Training loss: 0.9729042196736915
Validation loss: 2.8424544824351683

Epoch: 6| Step: 8
Training loss: 0.6221040390190129
Validation loss: 2.936464966036552

Epoch: 6| Step: 9
Training loss: 0.5796217487812483
Validation loss: 2.807899951793551

Epoch: 6| Step: 10
Training loss: 0.4692226411275123
Validation loss: 2.8924169811049425

Epoch: 6| Step: 11
Training loss: 0.7433584512934356
Validation loss: 2.8903312052670262

Epoch: 6| Step: 12
Training loss: 0.7213099956186368
Validation loss: 2.889759518386755

Epoch: 6| Step: 13
Training loss: 0.45172336445380956
Validation loss: 2.866108898488896

Epoch: 242| Step: 0
Training loss: 0.5359850403633922
Validation loss: 2.7962821317874913

Epoch: 6| Step: 1
Training loss: 0.5264578265283417
Validation loss: 2.829999481645948

Epoch: 6| Step: 2
Training loss: 0.8190437314161974
Validation loss: 2.9521366329043333

Epoch: 6| Step: 3
Training loss: 1.6786229508328014
Validation loss: 2.8888479595667618

Epoch: 6| Step: 4
Training loss: 0.662306562110005
Validation loss: 2.9344512593709684

Epoch: 6| Step: 5
Training loss: 0.45112617888789414
Validation loss: 2.8177320487575064

Epoch: 6| Step: 6
Training loss: 0.7280748276349212
Validation loss: 2.820060007164815

Epoch: 6| Step: 7
Training loss: 0.6150981934010025
Validation loss: 2.858323089610911

Epoch: 6| Step: 8
Training loss: 0.988984833812238
Validation loss: 2.849558686225444

Epoch: 6| Step: 9
Training loss: 0.7145011372647267
Validation loss: 2.8381127736323126

Epoch: 6| Step: 10
Training loss: 0.6014944756429383
Validation loss: 2.8327148594610065

Epoch: 6| Step: 11
Training loss: 0.781720020049926
Validation loss: 2.8758616331114277

Epoch: 6| Step: 12
Training loss: 0.5610513576893994
Validation loss: 2.793371076438883

Epoch: 6| Step: 13
Training loss: 0.822826601886265
Validation loss: 2.8337785754328646

Epoch: 243| Step: 0
Training loss: 0.5124485839080525
Validation loss: 2.8039143026949667

Epoch: 6| Step: 1
Training loss: 0.7065180818278085
Validation loss: 2.783466955696983

Epoch: 6| Step: 2
Training loss: 0.9698499771982697
Validation loss: 2.8871137721264306

Epoch: 6| Step: 3
Training loss: 0.9114753430913738
Validation loss: 2.7900312007677126

Epoch: 6| Step: 4
Training loss: 1.6044904043660206
Validation loss: 2.9048749617314464

Epoch: 6| Step: 5
Training loss: 0.6905280101213462
Validation loss: 2.874968832648691

Epoch: 6| Step: 6
Training loss: 0.6495978762124489
Validation loss: 2.8991894222206027

Epoch: 6| Step: 7
Training loss: 0.5276221211708915
Validation loss: 2.886818615223113

Epoch: 6| Step: 8
Training loss: 0.5813135932671741
Validation loss: 2.8653584674225736

Epoch: 6| Step: 9
Training loss: 0.8512628710609741
Validation loss: 2.8815297182002366

Epoch: 6| Step: 10
Training loss: 0.7701771150975567
Validation loss: 2.9504808163377207

Epoch: 6| Step: 11
Training loss: 1.0493034550154676
Validation loss: 2.8639661551789786

Epoch: 6| Step: 12
Training loss: 0.9123091223708373
Validation loss: 2.80769876466631

Epoch: 6| Step: 13
Training loss: 0.625299620336054
Validation loss: 2.7538968422009815

Epoch: 244| Step: 0
Training loss: 0.6510139891781175
Validation loss: 2.7678244944813564

Epoch: 6| Step: 1
Training loss: 0.8699995276022319
Validation loss: 2.794757389441817

Epoch: 6| Step: 2
Training loss: 0.9129569385814983
Validation loss: 2.7749150598259145

Epoch: 6| Step: 3
Training loss: 1.0579865463173035
Validation loss: 2.799166587707694

Epoch: 6| Step: 4
Training loss: 0.5915584272676697
Validation loss: 2.8801788595299955

Epoch: 6| Step: 5
Training loss: 0.6858971290612831
Validation loss: 2.898412308493488

Epoch: 6| Step: 6
Training loss: 1.607043456984888
Validation loss: 2.943686997157215

Epoch: 6| Step: 7
Training loss: 0.8424909168964972
Validation loss: 2.9754154134342716

Epoch: 6| Step: 8
Training loss: 0.9570067733437256
Validation loss: 2.9419828392693557

Epoch: 6| Step: 9
Training loss: 0.6639217227489337
Validation loss: 2.8590478067162626

Epoch: 6| Step: 10
Training loss: 0.7704122312413628
Validation loss: 2.892967127559934

Epoch: 6| Step: 11
Training loss: 0.4630567035433254
Validation loss: 2.834913154608472

Epoch: 6| Step: 12
Training loss: 0.7599555320027896
Validation loss: 2.804564180204371

Epoch: 6| Step: 13
Training loss: 1.0015814911801892
Validation loss: 2.810518456819714

Epoch: 245| Step: 0
Training loss: 1.0181428071040202
Validation loss: 2.8266024908467027

Epoch: 6| Step: 1
Training loss: 0.6375600954789575
Validation loss: 2.8254578801655708

Epoch: 6| Step: 2
Training loss: 0.5812969055528502
Validation loss: 2.7987213575820777

Epoch: 6| Step: 3
Training loss: 0.5875541763487057
Validation loss: 2.8573848698502013

Epoch: 6| Step: 4
Training loss: 0.5424364073788833
Validation loss: 2.8594592417274467

Epoch: 6| Step: 5
Training loss: 0.6471926678534552
Validation loss: 2.9041976381581467

Epoch: 6| Step: 6
Training loss: 0.5736762877508482
Validation loss: 2.9073157321904772

Epoch: 6| Step: 7
Training loss: 0.8773003721171387
Validation loss: 2.925751954608112

Epoch: 6| Step: 8
Training loss: 0.6069687996533215
Validation loss: 2.824670132083071

Epoch: 6| Step: 9
Training loss: 0.702407216226835
Validation loss: 2.831922759685609

Epoch: 6| Step: 10
Training loss: 0.6301448306622225
Validation loss: 2.887234777184667

Epoch: 6| Step: 11
Training loss: 1.5970363766821485
Validation loss: 2.822200294803264

Epoch: 6| Step: 12
Training loss: 0.6197563503258567
Validation loss: 2.911967993241604

Epoch: 6| Step: 13
Training loss: 0.7396684964715926
Validation loss: 2.8643364031163463

Epoch: 246| Step: 0
Training loss: 0.6818966097952059
Validation loss: 2.8542550808839975

Epoch: 6| Step: 1
Training loss: 0.5774467717035471
Validation loss: 2.8482577609160677

Epoch: 6| Step: 2
Training loss: 0.4280074828420701
Validation loss: 2.8821127368757495

Epoch: 6| Step: 3
Training loss: 0.7502366328461189
Validation loss: 2.829576390354845

Epoch: 6| Step: 4
Training loss: 0.6377318811373706
Validation loss: 2.8940833084472732

Epoch: 6| Step: 5
Training loss: 0.6007910401497807
Validation loss: 2.863446441228997

Epoch: 6| Step: 6
Training loss: 0.8007970296654123
Validation loss: 2.8708247398244158

Epoch: 6| Step: 7
Training loss: 0.9645156302424047
Validation loss: 2.830740321797439

Epoch: 6| Step: 8
Training loss: 1.4956084975891628
Validation loss: 2.8394673555851697

Epoch: 6| Step: 9
Training loss: 0.6527383946877697
Validation loss: 2.873581411917959

Epoch: 6| Step: 10
Training loss: 0.5561559340417201
Validation loss: 2.7996988018137197

Epoch: 6| Step: 11
Training loss: 1.046231883631632
Validation loss: 2.839119519319122

Epoch: 6| Step: 12
Training loss: 0.6193194446996264
Validation loss: 2.849140131215853

Epoch: 6| Step: 13
Training loss: 0.8189161859996603
Validation loss: 2.7983755423259513

Epoch: 247| Step: 0
Training loss: 0.6429081217292111
Validation loss: 2.881377444479345

Epoch: 6| Step: 1
Training loss: 1.5311406933443255
Validation loss: 2.8776330776689756

Epoch: 6| Step: 2
Training loss: 0.7253512879748659
Validation loss: 2.873113095929137

Epoch: 6| Step: 3
Training loss: 0.543573002124612
Validation loss: 2.9609297028424644

Epoch: 6| Step: 4
Training loss: 0.43440407991838026
Validation loss: 3.0493987235978413

Epoch: 6| Step: 5
Training loss: 0.9708564376264772
Validation loss: 2.898635555879756

Epoch: 6| Step: 6
Training loss: 0.6542752845959735
Validation loss: 2.9084053387695694

Epoch: 6| Step: 7
Training loss: 0.822285522800093
Validation loss: 2.8275399981726834

Epoch: 6| Step: 8
Training loss: 0.6337762252377452
Validation loss: 2.8807508338265575

Epoch: 6| Step: 9
Training loss: 0.6369391685855523
Validation loss: 2.830718774200332

Epoch: 6| Step: 10
Training loss: 0.6851231496333884
Validation loss: 2.8410760233991703

Epoch: 6| Step: 11
Training loss: 0.5922882507696237
Validation loss: 2.8234333865134515

Epoch: 6| Step: 12
Training loss: 0.6181631464898674
Validation loss: 2.845520656009557

Epoch: 6| Step: 13
Training loss: 0.8912830598646349
Validation loss: 2.8931538010929465

Epoch: 248| Step: 0
Training loss: 0.47226060118420854
Validation loss: 2.8993090118773384

Epoch: 6| Step: 1
Training loss: 0.7606017309938004
Validation loss: 2.8588877889933593

Epoch: 6| Step: 2
Training loss: 0.5226174378631492
Validation loss: 2.827560733825335

Epoch: 6| Step: 3
Training loss: 0.5376873721067496
Validation loss: 2.8553487367193005

Epoch: 6| Step: 4
Training loss: 0.4464657890609866
Validation loss: 2.9263499190717988

Epoch: 6| Step: 5
Training loss: 0.5139768732059518
Validation loss: 2.913194856175083

Epoch: 6| Step: 6
Training loss: 0.5634257328372456
Validation loss: 2.902684044173807

Epoch: 6| Step: 7
Training loss: 0.6088286665076128
Validation loss: 2.9026908410259695

Epoch: 6| Step: 8
Training loss: 0.6179825213377192
Validation loss: 2.8351965742904253

Epoch: 6| Step: 9
Training loss: 1.0380746261253149
Validation loss: 2.8386284887818833

Epoch: 6| Step: 10
Training loss: 0.9335276368805225
Validation loss: 2.9340945179187345

Epoch: 6| Step: 11
Training loss: 0.7906877379724249
Validation loss: 2.943545728157743

Epoch: 6| Step: 12
Training loss: 1.00581830876045
Validation loss: 2.8360037957911697

Epoch: 6| Step: 13
Training loss: 1.5423786048788293
Validation loss: 2.8129335069347694

Epoch: 249| Step: 0
Training loss: 0.6928326177364701
Validation loss: 2.8055702456686675

Epoch: 6| Step: 1
Training loss: 0.917716068635022
Validation loss: 2.921000371846549

Epoch: 6| Step: 2
Training loss: 1.0825140251325913
Validation loss: 2.8634902718211515

Epoch: 6| Step: 3
Training loss: 0.6107000469995421
Validation loss: 2.918042653078628

Epoch: 6| Step: 4
Training loss: 0.5594866358854388
Validation loss: 2.9268710352427996

Epoch: 6| Step: 5
Training loss: 0.509453952263902
Validation loss: 2.961249745193026

Epoch: 6| Step: 6
Training loss: 0.5618945943451874
Validation loss: 2.8653030647308038

Epoch: 6| Step: 7
Training loss: 0.3966704622489122
Validation loss: 2.910587369317741

Epoch: 6| Step: 8
Training loss: 1.5152734565071069
Validation loss: 2.866223567347777

Epoch: 6| Step: 9
Training loss: 0.7018724941844148
Validation loss: 2.90143735687992

Epoch: 6| Step: 10
Training loss: 0.8264048723514792
Validation loss: 2.865899707158307

Epoch: 6| Step: 11
Training loss: 0.5212725376955926
Validation loss: 2.7668480692034594

Epoch: 6| Step: 12
Training loss: 0.7077367224140106
Validation loss: 2.8920167339134526

Epoch: 6| Step: 13
Training loss: 0.7641842579316166
Validation loss: 2.806494369005519

Epoch: 250| Step: 0
Training loss: 0.7344487335849637
Validation loss: 2.841181464923162

Epoch: 6| Step: 1
Training loss: 0.5275726951659765
Validation loss: 2.825720240621901

Epoch: 6| Step: 2
Training loss: 0.43895856366953384
Validation loss: 2.852934624795695

Epoch: 6| Step: 3
Training loss: 0.6979331446358283
Validation loss: 2.856775975229973

Epoch: 6| Step: 4
Training loss: 0.7664514479691219
Validation loss: 2.7583943402515323

Epoch: 6| Step: 5
Training loss: 0.4409956076904981
Validation loss: 2.810803035667419

Epoch: 6| Step: 6
Training loss: 0.4387018351459315
Validation loss: 2.8474649051940655

Epoch: 6| Step: 7
Training loss: 0.6095713763608147
Validation loss: 2.868540196167771

Epoch: 6| Step: 8
Training loss: 0.6467272714190325
Validation loss: 2.8102871702168244

Epoch: 6| Step: 9
Training loss: 0.5991631254516849
Validation loss: 2.818089687938072

Epoch: 6| Step: 10
Training loss: 1.152223794157018
Validation loss: 2.877948589627476

Epoch: 6| Step: 11
Training loss: 0.5783531924263434
Validation loss: 2.8358454693730644

Epoch: 6| Step: 12
Training loss: 0.6542080035988621
Validation loss: 2.8916065508468667

Epoch: 6| Step: 13
Training loss: 1.6129231274822853
Validation loss: 2.8995578105373503

Epoch: 251| Step: 0
Training loss: 0.9805583532964065
Validation loss: 2.9008873442462

Epoch: 6| Step: 1
Training loss: 0.3918574346289505
Validation loss: 2.7986269956463468

Epoch: 6| Step: 2
Training loss: 0.6397001522212513
Validation loss: 2.900237450798889

Epoch: 6| Step: 3
Training loss: 1.5071619241163112
Validation loss: 2.828737111879107

Epoch: 6| Step: 4
Training loss: 0.6957302338824763
Validation loss: 2.8077604979276165

Epoch: 6| Step: 5
Training loss: 0.8663589368307184
Validation loss: 2.8974649146223825

Epoch: 6| Step: 6
Training loss: 0.6004354645087138
Validation loss: 2.908296104090852

Epoch: 6| Step: 7
Training loss: 0.5752467082301209
Validation loss: 2.910638756403116

Epoch: 6| Step: 8
Training loss: 0.5779390551551414
Validation loss: 2.9456929872597457

Epoch: 6| Step: 9
Training loss: 0.8743229017354077
Validation loss: 2.786510963774767

Epoch: 6| Step: 10
Training loss: 0.44242142936122303
Validation loss: 2.850113661769418

Epoch: 6| Step: 11
Training loss: 0.8178252158890976
Validation loss: 2.8030797233879996

Epoch: 6| Step: 12
Training loss: 0.7898558603446895
Validation loss: 2.851168677600037

Epoch: 6| Step: 13
Training loss: 1.0171209615341485
Validation loss: 2.845404650086087

Epoch: 252| Step: 0
Training loss: 0.6452153361327133
Validation loss: 2.759208239552568

Epoch: 6| Step: 1
Training loss: 0.465017206222334
Validation loss: 2.783987091478479

Epoch: 6| Step: 2
Training loss: 0.8049406375677244
Validation loss: 2.8581198697878634

Epoch: 6| Step: 3
Training loss: 0.8160700128452987
Validation loss: 2.867748694107547

Epoch: 6| Step: 4
Training loss: 0.7548212616021791
Validation loss: 2.878014407827204

Epoch: 6| Step: 5
Training loss: 0.8366501524487211
Validation loss: 2.869732343241706

Epoch: 6| Step: 6
Training loss: 1.5035051083314643
Validation loss: 2.8401878389846416

Epoch: 6| Step: 7
Training loss: 0.7317843905422778
Validation loss: 2.83791151605711

Epoch: 6| Step: 8
Training loss: 0.7567449305792725
Validation loss: 2.953125538228842

Epoch: 6| Step: 9
Training loss: 0.5448152718131609
Validation loss: 2.8556778148927626

Epoch: 6| Step: 10
Training loss: 0.9495991074302387
Validation loss: 2.8354244696411426

Epoch: 6| Step: 11
Training loss: 0.46766511622575424
Validation loss: 2.8741010836223895

Epoch: 6| Step: 12
Training loss: 0.5313612877461383
Validation loss: 2.760860959172072

Epoch: 6| Step: 13
Training loss: 0.39125157648445347
Validation loss: 2.8855508343917435

Epoch: 253| Step: 0
Training loss: 0.5853500982246502
Validation loss: 2.8077395452844183

Epoch: 6| Step: 1
Training loss: 0.6907612006059056
Validation loss: 2.8641627933571088

Epoch: 6| Step: 2
Training loss: 0.3612591651889034
Validation loss: 2.845059746470777

Epoch: 6| Step: 3
Training loss: 0.7655791444086331
Validation loss: 2.842235986576681

Epoch: 6| Step: 4
Training loss: 0.6675252948211582
Validation loss: 2.8624297120905755

Epoch: 6| Step: 5
Training loss: 0.788443180688207
Validation loss: 2.9239653319648906

Epoch: 6| Step: 6
Training loss: 1.4139012197336944
Validation loss: 2.865312460381622

Epoch: 6| Step: 7
Training loss: 0.5792216133106588
Validation loss: 2.850871764530517

Epoch: 6| Step: 8
Training loss: 0.6894419077536166
Validation loss: 2.791381840386062

Epoch: 6| Step: 9
Training loss: 0.4851315189514307
Validation loss: 2.879327364539198

Epoch: 6| Step: 10
Training loss: 1.2604753254673653
Validation loss: 2.820441485244253

Epoch: 6| Step: 11
Training loss: 0.7315150636385269
Validation loss: 2.857430191010555

Epoch: 6| Step: 12
Training loss: 0.6001119588663756
Validation loss: 2.908069519567511

Epoch: 6| Step: 13
Training loss: 0.5278470498629421
Validation loss: 2.94920105918311

Epoch: 254| Step: 0
Training loss: 0.6066830179959267
Validation loss: 2.886051298691888

Epoch: 6| Step: 1
Training loss: 0.5552428782906784
Validation loss: 2.8583107306992694

Epoch: 6| Step: 2
Training loss: 1.5272227675969394
Validation loss: 2.833224067731553

Epoch: 6| Step: 3
Training loss: 0.956557736713622
Validation loss: 2.814562726363035

Epoch: 6| Step: 4
Training loss: 0.8163585010053465
Validation loss: 2.811339456806505

Epoch: 6| Step: 5
Training loss: 0.6271583482689246
Validation loss: 2.867506918927919

Epoch: 6| Step: 6
Training loss: 0.45568293382373604
Validation loss: 2.868886806132044

Epoch: 6| Step: 7
Training loss: 0.5892287325866968
Validation loss: 2.831273863792199

Epoch: 6| Step: 8
Training loss: 0.7640776665865352
Validation loss: 2.8304261879208847

Epoch: 6| Step: 9
Training loss: 0.5630413470440838
Validation loss: 2.848802647122988

Epoch: 6| Step: 10
Training loss: 0.6679326990225767
Validation loss: 2.885950184924838

Epoch: 6| Step: 11
Training loss: 0.7676933920315152
Validation loss: 2.9475674551551174

Epoch: 6| Step: 12
Training loss: 0.5441261963256051
Validation loss: 2.87606391018495

Epoch: 6| Step: 13
Training loss: 0.8661273283748901
Validation loss: 2.9119704631488177

Epoch: 255| Step: 0
Training loss: 0.729521642292001
Validation loss: 2.918875652497488

Epoch: 6| Step: 1
Training loss: 0.5743448028264223
Validation loss: 2.9829733654490913

Epoch: 6| Step: 2
Training loss: 0.783820044872149
Validation loss: 2.9173957776236157

Epoch: 6| Step: 3
Training loss: 0.6556801365304444
Validation loss: 2.9434931875894907

Epoch: 6| Step: 4
Training loss: 0.6302361258901777
Validation loss: 2.8673625618885357

Epoch: 6| Step: 5
Training loss: 0.67768582656627
Validation loss: 2.844400380417472

Epoch: 6| Step: 6
Training loss: 0.7672804238162652
Validation loss: 2.83979290090702

Epoch: 6| Step: 7
Training loss: 0.5257013812909946
Validation loss: 2.8192144706237063

Epoch: 6| Step: 8
Training loss: 0.7635344164522754
Validation loss: 2.855617841106438

Epoch: 6| Step: 9
Training loss: 0.47340371795083924
Validation loss: 2.9028056116508694

Epoch: 6| Step: 10
Training loss: 0.5803399314004989
Validation loss: 2.862589684515426

Epoch: 6| Step: 11
Training loss: 1.1110293987480742
Validation loss: 2.8543807921640747

Epoch: 6| Step: 12
Training loss: 1.4432976777927005
Validation loss: 2.8995324848677635

Epoch: 6| Step: 13
Training loss: 0.46975653982964705
Validation loss: 2.9220289437986082

Epoch: 256| Step: 0
Training loss: 0.6574846189026995
Validation loss: 2.8756598530827877

Epoch: 6| Step: 1
Training loss: 0.8704736666522555
Validation loss: 2.8885686209836012

Epoch: 6| Step: 2
Training loss: 0.551752249090453
Validation loss: 2.8395162653308557

Epoch: 6| Step: 3
Training loss: 0.45733384768417246
Validation loss: 2.805666519767658

Epoch: 6| Step: 4
Training loss: 0.47377663228004047
Validation loss: 2.877319423114549

Epoch: 6| Step: 5
Training loss: 0.545753582619805
Validation loss: 2.821008541764511

Epoch: 6| Step: 6
Training loss: 0.8239775390572917
Validation loss: 2.8184760147318433

Epoch: 6| Step: 7
Training loss: 0.9826146689321852
Validation loss: 2.873827515505647

Epoch: 6| Step: 8
Training loss: 0.6097749229176801
Validation loss: 2.8671047742725935

Epoch: 6| Step: 9
Training loss: 0.4891214390056476
Validation loss: 2.8532202792127026

Epoch: 6| Step: 10
Training loss: 1.4573692768291124
Validation loss: 2.8083009244442985

Epoch: 6| Step: 11
Training loss: 1.0518972717030735
Validation loss: 2.8762105107211164

Epoch: 6| Step: 12
Training loss: 0.5927395504561744
Validation loss: 2.838767665067307

Epoch: 6| Step: 13
Training loss: 0.6795335573397138
Validation loss: 2.8660611357742467

Epoch: 257| Step: 0
Training loss: 0.733253718700012
Validation loss: 2.954430851514332

Epoch: 6| Step: 1
Training loss: 1.4580694595662025
Validation loss: 2.8258355218880165

Epoch: 6| Step: 2
Training loss: 0.605837752585404
Validation loss: 2.752894944080785

Epoch: 6| Step: 3
Training loss: 0.7110818150523972
Validation loss: 2.8402338472765534

Epoch: 6| Step: 4
Training loss: 0.8528109856379263
Validation loss: 2.778264132413834

Epoch: 6| Step: 5
Training loss: 0.5264025164975943
Validation loss: 2.8267925629230017

Epoch: 6| Step: 6
Training loss: 0.5005328795868618
Validation loss: 2.9150937925618408

Epoch: 6| Step: 7
Training loss: 0.5759214471245018
Validation loss: 2.837991683361278

Epoch: 6| Step: 8
Training loss: 0.5622217761834997
Validation loss: 2.77312462703028

Epoch: 6| Step: 9
Training loss: 0.6380745430481571
Validation loss: 2.834340930805464

Epoch: 6| Step: 10
Training loss: 0.6657354710920615
Validation loss: 2.856181767578712

Epoch: 6| Step: 11
Training loss: 0.8869283487244202
Validation loss: 2.858389929682846

Epoch: 6| Step: 12
Training loss: 0.8803987165487623
Validation loss: 2.899478989145392

Epoch: 6| Step: 13
Training loss: 0.5326556514648226
Validation loss: 2.9806508366536915

Epoch: 258| Step: 0
Training loss: 1.634048505158863
Validation loss: 2.925791571904078

Epoch: 6| Step: 1
Training loss: 0.8285127487744195
Validation loss: 2.934898631453626

Epoch: 6| Step: 2
Training loss: 0.7283411711991973
Validation loss: 2.8816291289332696

Epoch: 6| Step: 3
Training loss: 0.5691832767965331
Validation loss: 2.9473790508645648

Epoch: 6| Step: 4
Training loss: 0.5147151143784786
Validation loss: 2.8127223315487626

Epoch: 6| Step: 5
Training loss: 0.789825448296749
Validation loss: 2.8556460957350818

Epoch: 6| Step: 6
Training loss: 0.5967343019754768
Validation loss: 2.786948477634843

Epoch: 6| Step: 7
Training loss: 0.5547835575799885
Validation loss: 2.8470764546697627

Epoch: 6| Step: 8
Training loss: 0.48405498269772035
Validation loss: 2.855667573518662

Epoch: 6| Step: 9
Training loss: 0.742928305887933
Validation loss: 2.8997266563854813

Epoch: 6| Step: 10
Training loss: 0.48375985862484155
Validation loss: 2.812326814476266

Epoch: 6| Step: 11
Training loss: 0.6079803793919177
Validation loss: 2.8929451918391806

Epoch: 6| Step: 12
Training loss: 0.41946766263111374
Validation loss: 2.848403407046461

Epoch: 6| Step: 13
Training loss: 0.8711512935773985
Validation loss: 2.886073569060861

Epoch: 259| Step: 0
Training loss: 0.47723416383186135
Validation loss: 2.908507929555432

Epoch: 6| Step: 1
Training loss: 0.5819380000639471
Validation loss: 2.9332702431251874

Epoch: 6| Step: 2
Training loss: 0.5725960412321305
Validation loss: 2.9331624627919806

Epoch: 6| Step: 3
Training loss: 0.9325738227708571
Validation loss: 2.8670880736141955

Epoch: 6| Step: 4
Training loss: 0.6002642506596279
Validation loss: 2.9457773774339313

Epoch: 6| Step: 5
Training loss: 0.8183680422376275
Validation loss: 2.9650520181193802

Epoch: 6| Step: 6
Training loss: 0.726504087663717
Validation loss: 2.8219038118713007

Epoch: 6| Step: 7
Training loss: 0.39669551770822703
Validation loss: 2.832044158555351

Epoch: 6| Step: 8
Training loss: 0.5205438826840093
Validation loss: 2.9189666716635516

Epoch: 6| Step: 9
Training loss: 0.6329943548676975
Validation loss: 2.9013506429742586

Epoch: 6| Step: 10
Training loss: 1.5008855430986954
Validation loss: 2.888691587211062

Epoch: 6| Step: 11
Training loss: 0.7034542584382476
Validation loss: 2.8328279764489435

Epoch: 6| Step: 12
Training loss: 0.6195073530824504
Validation loss: 2.8111449120763248

Epoch: 6| Step: 13
Training loss: 0.6099808444470581
Validation loss: 2.8612756856685073

Epoch: 260| Step: 0
Training loss: 0.5574489947794546
Validation loss: 2.9074228442804335

Epoch: 6| Step: 1
Training loss: 0.5726784528771005
Validation loss: 2.8979311943832724

Epoch: 6| Step: 2
Training loss: 0.6674889966507851
Validation loss: 2.9461862902091256

Epoch: 6| Step: 3
Training loss: 0.7681407080115823
Validation loss: 2.8891889011865075

Epoch: 6| Step: 4
Training loss: 0.5153114637152788
Validation loss: 2.8350911484496395

Epoch: 6| Step: 5
Training loss: 0.6023819778918479
Validation loss: 2.887280152774065

Epoch: 6| Step: 6
Training loss: 0.4455518581185965
Validation loss: 2.8955353828305523

Epoch: 6| Step: 7
Training loss: 1.1036184617459266
Validation loss: 2.904080870103082

Epoch: 6| Step: 8
Training loss: 0.5835730083001959
Validation loss: 2.912218357488552

Epoch: 6| Step: 9
Training loss: 0.6900752127469452
Validation loss: 2.846920244490382

Epoch: 6| Step: 10
Training loss: 0.8037985919603107
Validation loss: 2.922806773133046

Epoch: 6| Step: 11
Training loss: 0.7873275870851827
Validation loss: 2.9395035613708327

Epoch: 6| Step: 12
Training loss: 0.5613098534442119
Validation loss: 2.8738678209450392

Epoch: 6| Step: 13
Training loss: 1.4001213038208165
Validation loss: 2.923188544961029

Epoch: 261| Step: 0
Training loss: 0.8433032089125301
Validation loss: 2.9499185098287253

Epoch: 6| Step: 1
Training loss: 0.6844174463355981
Validation loss: 2.9572854514402134

Epoch: 6| Step: 2
Training loss: 0.4711855873183445
Validation loss: 2.878816593728902

Epoch: 6| Step: 3
Training loss: 0.4412527239339896
Validation loss: 2.839043323855878

Epoch: 6| Step: 4
Training loss: 1.4325194946347308
Validation loss: 2.8193960488419547

Epoch: 6| Step: 5
Training loss: 0.7046280584196204
Validation loss: 2.832176972948091

Epoch: 6| Step: 6
Training loss: 0.4948937026438141
Validation loss: 2.8018047993193553

Epoch: 6| Step: 7
Training loss: 0.4550217687723153
Validation loss: 2.791636236698688

Epoch: 6| Step: 8
Training loss: 0.9986529814729365
Validation loss: 2.806763074907453

Epoch: 6| Step: 9
Training loss: 0.7493779861479782
Validation loss: 2.811785162045744

Epoch: 6| Step: 10
Training loss: 0.37861354573033706
Validation loss: 2.7682562055490365

Epoch: 6| Step: 11
Training loss: 0.771350240514956
Validation loss: 2.8376203995982956

Epoch: 6| Step: 12
Training loss: 0.505107600863281
Validation loss: 2.850519848421497

Epoch: 6| Step: 13
Training loss: 0.7783983064675213
Validation loss: 2.8615648469008876

Epoch: 262| Step: 0
Training loss: 0.6178190645632269
Validation loss: 2.9443217802788095

Epoch: 6| Step: 1
Training loss: 0.7921116147384485
Validation loss: 2.9406163749608876

Epoch: 6| Step: 2
Training loss: 0.4711561911276067
Validation loss: 2.85568450794485

Epoch: 6| Step: 3
Training loss: 0.5441794858749616
Validation loss: 2.8863628961338703

Epoch: 6| Step: 4
Training loss: 0.4865134012664157
Validation loss: 2.881134054591408

Epoch: 6| Step: 5
Training loss: 0.5888516501532572
Validation loss: 2.8654279515621695

Epoch: 6| Step: 6
Training loss: 0.6760281459081288
Validation loss: 2.9230494867129897

Epoch: 6| Step: 7
Training loss: 0.8943058046328516
Validation loss: 3.000462099089897

Epoch: 6| Step: 8
Training loss: 0.8398969766472705
Validation loss: 2.9283486524111373

Epoch: 6| Step: 9
Training loss: 0.5169020357637617
Validation loss: 2.9316604142576868

Epoch: 6| Step: 10
Training loss: 0.8404343768252063
Validation loss: 2.8365282016255264

Epoch: 6| Step: 11
Training loss: 0.5924232869041508
Validation loss: 2.9054117121768885

Epoch: 6| Step: 12
Training loss: 1.446008792897949
Validation loss: 2.9053829772985877

Epoch: 6| Step: 13
Training loss: 0.7538919398081225
Validation loss: 2.8839239719111798

Epoch: 263| Step: 0
Training loss: 0.6803528609282319
Validation loss: 2.8834452912381883

Epoch: 6| Step: 1
Training loss: 0.6044452507272342
Validation loss: 2.8583301796260896

Epoch: 6| Step: 2
Training loss: 0.6258851697265801
Validation loss: 2.8905119315363437

Epoch: 6| Step: 3
Training loss: 0.6372583127487901
Validation loss: 2.887689808253406

Epoch: 6| Step: 4
Training loss: 0.3448512794595617
Validation loss: 2.8782499299356545

Epoch: 6| Step: 5
Training loss: 0.5352729892791472
Validation loss: 2.9053405377842987

Epoch: 6| Step: 6
Training loss: 0.4879047315404464
Validation loss: 2.792769859363784

Epoch: 6| Step: 7
Training loss: 0.6447800589540155
Validation loss: 2.7982928981514075

Epoch: 6| Step: 8
Training loss: 1.102291866733377
Validation loss: 2.852656157328994

Epoch: 6| Step: 9
Training loss: 0.5653680428484466
Validation loss: 2.8314627942867436

Epoch: 6| Step: 10
Training loss: 0.5811717708816774
Validation loss: 2.908823002324153

Epoch: 6| Step: 11
Training loss: 1.4006450852839611
Validation loss: 2.8855283327678722

Epoch: 6| Step: 12
Training loss: 0.719279425972769
Validation loss: 3.007209909030467

Epoch: 6| Step: 13
Training loss: 1.0340382998952842
Validation loss: 3.03974742738431

Epoch: 264| Step: 0
Training loss: 0.48981295097907607
Validation loss: 2.952870595156432

Epoch: 6| Step: 1
Training loss: 0.7153683181256005
Validation loss: 2.900803415227648

Epoch: 6| Step: 2
Training loss: 0.48938364325791595
Validation loss: 2.9015651803525544

Epoch: 6| Step: 3
Training loss: 0.6329261301005774
Validation loss: 2.8755906507273843

Epoch: 6| Step: 4
Training loss: 0.4404526258361125
Validation loss: 2.8954211611805953

Epoch: 6| Step: 5
Training loss: 0.7582225673252263
Validation loss: 2.8834702483141035

Epoch: 6| Step: 6
Training loss: 1.5503214964156742
Validation loss: 2.8312611622481554

Epoch: 6| Step: 7
Training loss: 0.6676723648079848
Validation loss: 2.8238195310387915

Epoch: 6| Step: 8
Training loss: 0.7012506084813489
Validation loss: 2.804819881392973

Epoch: 6| Step: 9
Training loss: 0.8679916845771546
Validation loss: 2.8810347371150566

Epoch: 6| Step: 10
Training loss: 0.9813491090909362
Validation loss: 2.911169311881568

Epoch: 6| Step: 11
Training loss: 0.7191543685536395
Validation loss: 2.870017834917006

Epoch: 6| Step: 12
Training loss: 0.5927715018679142
Validation loss: 2.8787115092429767

Epoch: 6| Step: 13
Training loss: 0.47615136719651296
Validation loss: 2.8810604598562253

Epoch: 265| Step: 0
Training loss: 0.6087598630274553
Validation loss: 2.861724235882796

Epoch: 6| Step: 1
Training loss: 0.6216242701704326
Validation loss: 2.9142524309621876

Epoch: 6| Step: 2
Training loss: 0.4648868476699602
Validation loss: 2.9597069725631497

Epoch: 6| Step: 3
Training loss: 0.5048933784367993
Validation loss: 2.96066069504341

Epoch: 6| Step: 4
Training loss: 0.468702917913409
Validation loss: 2.8646698308658975

Epoch: 6| Step: 5
Training loss: 0.37860854733557564
Validation loss: 2.8484096289279237

Epoch: 6| Step: 6
Training loss: 1.4409453526127591
Validation loss: 2.962829535568483

Epoch: 6| Step: 7
Training loss: 0.8930095406307778
Validation loss: 2.820253408557938

Epoch: 6| Step: 8
Training loss: 0.6161959928946255
Validation loss: 2.8413251802159514

Epoch: 6| Step: 9
Training loss: 0.6638514239377616
Validation loss: 2.8782260458704974

Epoch: 6| Step: 10
Training loss: 0.692522623987089
Validation loss: 2.8553195815255834

Epoch: 6| Step: 11
Training loss: 0.7120679314921072
Validation loss: 2.964061501515726

Epoch: 6| Step: 12
Training loss: 0.7607902149323292
Validation loss: 2.9095672694128845

Epoch: 6| Step: 13
Training loss: 0.45462150750275326
Validation loss: 2.88665414891895

Epoch: 266| Step: 0
Training loss: 0.6792264229477318
Validation loss: 2.8658344703916834

Epoch: 6| Step: 1
Training loss: 0.8206458004990392
Validation loss: 2.8593939622483053

Epoch: 6| Step: 2
Training loss: 0.5293126966075418
Validation loss: 2.8873606902806572

Epoch: 6| Step: 3
Training loss: 0.4964558488887979
Validation loss: 2.931041828346849

Epoch: 6| Step: 4
Training loss: 1.4114512575917644
Validation loss: 2.792503777060008

Epoch: 6| Step: 5
Training loss: 0.4530724790981536
Validation loss: 2.8034858786014856

Epoch: 6| Step: 6
Training loss: 0.5402490576612735
Validation loss: 2.857772489267297

Epoch: 6| Step: 7
Training loss: 0.7771794131064944
Validation loss: 2.8833374813542454

Epoch: 6| Step: 8
Training loss: 0.5053961263897642
Validation loss: 2.9325604674123436

Epoch: 6| Step: 9
Training loss: 0.5888351001506046
Validation loss: 2.8883969079571323

Epoch: 6| Step: 10
Training loss: 0.6531876000150693
Validation loss: 2.920944963427096

Epoch: 6| Step: 11
Training loss: 0.771094539993639
Validation loss: 2.865212892652475

Epoch: 6| Step: 12
Training loss: 0.5850722982284821
Validation loss: 2.822325800657855

Epoch: 6| Step: 13
Training loss: 0.6653171579637788
Validation loss: 2.839769022228187

Epoch: 267| Step: 0
Training loss: 0.8701787342434723
Validation loss: 2.8227602550534394

Epoch: 6| Step: 1
Training loss: 0.48529657248098823
Validation loss: 2.859758042213125

Epoch: 6| Step: 2
Training loss: 0.5833399863090779
Validation loss: 2.741925566680679

Epoch: 6| Step: 3
Training loss: 0.572893286719252
Validation loss: 2.912107178115613

Epoch: 6| Step: 4
Training loss: 0.9194252633696405
Validation loss: 2.799407891837341

Epoch: 6| Step: 5
Training loss: 0.5678984618213644
Validation loss: 2.938286723306175

Epoch: 6| Step: 6
Training loss: 0.8514299902053781
Validation loss: 2.865335626943258

Epoch: 6| Step: 7
Training loss: 0.5955888732409471
Validation loss: 2.9095865600894357

Epoch: 6| Step: 8
Training loss: 0.5472209381221845
Validation loss: 2.84509780579351

Epoch: 6| Step: 9
Training loss: 0.634130189195753
Validation loss: 2.819963625589888

Epoch: 6| Step: 10
Training loss: 0.5143727789421845
Validation loss: 2.833984795641983

Epoch: 6| Step: 11
Training loss: 0.7487677146331763
Validation loss: 2.8749274369080298

Epoch: 6| Step: 12
Training loss: 0.7153729007229556
Validation loss: 2.8528426549786357

Epoch: 6| Step: 13
Training loss: 1.4693156025838485
Validation loss: 2.866109141113136

Epoch: 268| Step: 0
Training loss: 0.7144689776130704
Validation loss: 2.811195805831383

Epoch: 6| Step: 1
Training loss: 0.5811142834786903
Validation loss: 2.887148524439443

Epoch: 6| Step: 2
Training loss: 0.44446278532583194
Validation loss: 2.9097616384704845

Epoch: 6| Step: 3
Training loss: 0.5275497034349169
Validation loss: 2.937682098804649

Epoch: 6| Step: 4
Training loss: 0.6954982166651358
Validation loss: 2.9921369955051875

Epoch: 6| Step: 5
Training loss: 0.6067579756480942
Validation loss: 2.9577865005642865

Epoch: 6| Step: 6
Training loss: 0.6667882738860402
Validation loss: 2.924692301854424

Epoch: 6| Step: 7
Training loss: 0.7038347265082351
Validation loss: 2.8679606324734515

Epoch: 6| Step: 8
Training loss: 0.5090846047189115
Validation loss: 2.952550317463106

Epoch: 6| Step: 9
Training loss: 0.9415689857986258
Validation loss: 2.8288870499591523

Epoch: 6| Step: 10
Training loss: 0.4800589604971737
Validation loss: 2.857679020437757

Epoch: 6| Step: 11
Training loss: 0.5842377996284903
Validation loss: 2.799956770971924

Epoch: 6| Step: 12
Training loss: 0.48524501559779687
Validation loss: 2.7979038768446634

Epoch: 6| Step: 13
Training loss: 1.4910614398396562
Validation loss: 2.828626893753388

Epoch: 269| Step: 0
Training loss: 0.8390796823003204
Validation loss: 2.8345116848357383

Epoch: 6| Step: 1
Training loss: 0.5076467977285477
Validation loss: 2.8756816442944215

Epoch: 6| Step: 2
Training loss: 0.6042171216044594
Validation loss: 2.8304164027021077

Epoch: 6| Step: 3
Training loss: 0.7112310034254778
Validation loss: 2.842945837543711

Epoch: 6| Step: 4
Training loss: 0.5912994963672983
Validation loss: 2.8551804396556353

Epoch: 6| Step: 5
Training loss: 0.8638066897855491
Validation loss: 2.8602709452237822

Epoch: 6| Step: 6
Training loss: 0.458615873410777
Validation loss: 2.9010198285269952

Epoch: 6| Step: 7
Training loss: 0.6020742939289168
Validation loss: 2.88424044894861

Epoch: 6| Step: 8
Training loss: 0.5713899181056681
Validation loss: 3.0001352730028894

Epoch: 6| Step: 9
Training loss: 0.7395746517119584
Validation loss: 2.9538148077722655

Epoch: 6| Step: 10
Training loss: 0.7363449620919819
Validation loss: 2.856732716243768

Epoch: 6| Step: 11
Training loss: 1.3704596028377685
Validation loss: 2.9111397192991557

Epoch: 6| Step: 12
Training loss: 0.3133420566518028
Validation loss: 2.844385432419309

Epoch: 6| Step: 13
Training loss: 0.49400958106560655
Validation loss: 2.916740325724231

Epoch: 270| Step: 0
Training loss: 0.41586033963068797
Validation loss: 2.852386397390599

Epoch: 6| Step: 1
Training loss: 0.5148764870500124
Validation loss: 2.8558961171874833

Epoch: 6| Step: 2
Training loss: 0.8138902946983698
Validation loss: 2.8989468766997097

Epoch: 6| Step: 3
Training loss: 1.4230661956874493
Validation loss: 2.8163311754750358

Epoch: 6| Step: 4
Training loss: 0.80722039841302
Validation loss: 2.7835863422898717

Epoch: 6| Step: 5
Training loss: 0.4913779215690652
Validation loss: 2.887918721014248

Epoch: 6| Step: 6
Training loss: 0.7164049038307579
Validation loss: 2.887397104827246

Epoch: 6| Step: 7
Training loss: 0.4487690872659698
Validation loss: 2.914665466598317

Epoch: 6| Step: 8
Training loss: 0.5548898569564223
Validation loss: 2.8660565604942034

Epoch: 6| Step: 9
Training loss: 0.36249230968605073
Validation loss: 2.9134442966535614

Epoch: 6| Step: 10
Training loss: 0.385800552781373
Validation loss: 2.9049068478232196

Epoch: 6| Step: 11
Training loss: 0.9222892864832222
Validation loss: 2.9700283577503885

Epoch: 6| Step: 12
Training loss: 0.47640672858224503
Validation loss: 2.9259804019962625

Epoch: 6| Step: 13
Training loss: 0.5388496642186107
Validation loss: 2.9309846303799962

Epoch: 271| Step: 0
Training loss: 0.6396390259028499
Validation loss: 2.909467864065424

Epoch: 6| Step: 1
Training loss: 0.5604355864421448
Validation loss: 2.969902203145308

Epoch: 6| Step: 2
Training loss: 0.5965258310997014
Validation loss: 2.9547231880828666

Epoch: 6| Step: 3
Training loss: 0.5871619083660378
Validation loss: 2.8476094894860857

Epoch: 6| Step: 4
Training loss: 0.4340738782771418
Validation loss: 2.8135130576569716

Epoch: 6| Step: 5
Training loss: 0.6063187570023922
Validation loss: 2.830698560018756

Epoch: 6| Step: 6
Training loss: 0.8910363903577693
Validation loss: 2.8548355478956697

Epoch: 6| Step: 7
Training loss: 0.7821833185441546
Validation loss: 2.896590762715044

Epoch: 6| Step: 8
Training loss: 0.6843951078622432
Validation loss: 2.8176079742177635

Epoch: 6| Step: 9
Training loss: 1.4525860843328566
Validation loss: 2.8551415683456054

Epoch: 6| Step: 10
Training loss: 0.6792976752304444
Validation loss: 2.82182991157973

Epoch: 6| Step: 11
Training loss: 0.5957541772197312
Validation loss: 2.8711299695003185

Epoch: 6| Step: 12
Training loss: 0.43616882530866713
Validation loss: 2.8560728450847432

Epoch: 6| Step: 13
Training loss: 0.46574230060673605
Validation loss: 2.832095413358098

Epoch: 272| Step: 0
Training loss: 0.34921365857946507
Validation loss: 2.9035297364887165

Epoch: 6| Step: 1
Training loss: 0.6904874828704007
Validation loss: 2.9523113280245

Epoch: 6| Step: 2
Training loss: 0.45382926734574347
Validation loss: 2.8828051669502206

Epoch: 6| Step: 3
Training loss: 0.6079019691498144
Validation loss: 2.928357051962462

Epoch: 6| Step: 4
Training loss: 0.6946265448126949
Validation loss: 2.902439216833792

Epoch: 6| Step: 5
Training loss: 0.6502235587514205
Validation loss: 2.893865428954046

Epoch: 6| Step: 6
Training loss: 0.6697194541538345
Validation loss: 2.8988935415137114

Epoch: 6| Step: 7
Training loss: 0.6600096274526261
Validation loss: 2.79116902731766

Epoch: 6| Step: 8
Training loss: 1.4711926216857325
Validation loss: 2.8950381982640856

Epoch: 6| Step: 9
Training loss: 0.6214915027605286
Validation loss: 2.883224223577005

Epoch: 6| Step: 10
Training loss: 0.39546071466777905
Validation loss: 2.859480169755897

Epoch: 6| Step: 11
Training loss: 0.6241262049817112
Validation loss: 2.8828770837897992

Epoch: 6| Step: 12
Training loss: 0.7528006397293243
Validation loss: 2.888302132631876

Epoch: 6| Step: 13
Training loss: 0.8182631552128533
Validation loss: 2.8444802321311897

Epoch: 273| Step: 0
Training loss: 0.5002207566730618
Validation loss: 2.8779389866994847

Epoch: 6| Step: 1
Training loss: 0.53241607371785
Validation loss: 2.9043618771928545

Epoch: 6| Step: 2
Training loss: 0.5520086477853103
Validation loss: 2.9007673470578084

Epoch: 6| Step: 3
Training loss: 0.657704920364658
Validation loss: 2.8228604263014825

Epoch: 6| Step: 4
Training loss: 0.4819207001326612
Validation loss: 2.984778198913308

Epoch: 6| Step: 5
Training loss: 0.4911323924431855
Validation loss: 2.8933331012798984

Epoch: 6| Step: 6
Training loss: 0.5582262978038423
Validation loss: 3.0474043557458574

Epoch: 6| Step: 7
Training loss: 0.5378885893828215
Validation loss: 2.9781984254125446

Epoch: 6| Step: 8
Training loss: 1.3900915687231254
Validation loss: 2.9239544871954677

Epoch: 6| Step: 9
Training loss: 0.6083031054611743
Validation loss: 2.853104892755959

Epoch: 6| Step: 10
Training loss: 0.5693643605382382
Validation loss: 2.9863083653516695

Epoch: 6| Step: 11
Training loss: 0.9420703745550641
Validation loss: 2.8943955444977494

Epoch: 6| Step: 12
Training loss: 0.7094641709263309
Validation loss: 2.9578602820055253

Epoch: 6| Step: 13
Training loss: 0.414037721720239
Validation loss: 2.91587629962702

Epoch: 274| Step: 0
Training loss: 0.3777927278656846
Validation loss: 2.9536325331426423

Epoch: 6| Step: 1
Training loss: 0.4547421766617953
Validation loss: 2.863759998718683

Epoch: 6| Step: 2
Training loss: 1.5682978065728839
Validation loss: 2.9285088910703907

Epoch: 6| Step: 3
Training loss: 0.6276299931658625
Validation loss: 2.937531924243359

Epoch: 6| Step: 4
Training loss: 0.7189440258028081
Validation loss: 2.9030081740170193

Epoch: 6| Step: 5
Training loss: 0.7413291786581137
Validation loss: 2.9414121670809092

Epoch: 6| Step: 6
Training loss: 0.3670208735519664
Validation loss: 2.8594891190121463

Epoch: 6| Step: 7
Training loss: 0.5825590774145839
Validation loss: 2.8600933096854058

Epoch: 6| Step: 8
Training loss: 0.6953671251763461
Validation loss: 2.775314827549955

Epoch: 6| Step: 9
Training loss: 0.645077421953267
Validation loss: 2.9139256176746478

Epoch: 6| Step: 10
Training loss: 0.36273024415969574
Validation loss: 2.9495669262562605

Epoch: 6| Step: 11
Training loss: 0.46787074596031414
Validation loss: 2.936839685557204

Epoch: 6| Step: 12
Training loss: 0.6768484123763685
Validation loss: 2.973588113182618

Epoch: 6| Step: 13
Training loss: 0.7927011122773587
Validation loss: 2.981538273211436

Epoch: 275| Step: 0
Training loss: 0.6589038865298281
Validation loss: 3.0290859533485746

Epoch: 6| Step: 1
Training loss: 0.6205481285899953
Validation loss: 2.851168684568483

Epoch: 6| Step: 2
Training loss: 1.4309065994022
Validation loss: 2.8615323042685

Epoch: 6| Step: 3
Training loss: 0.6718667052000917
Validation loss: 2.8993655121797364

Epoch: 6| Step: 4
Training loss: 0.9609809803623718
Validation loss: 2.8861357737313442

Epoch: 6| Step: 5
Training loss: 0.5067754279382831
Validation loss: 2.8316767187840086

Epoch: 6| Step: 6
Training loss: 0.7002997539948529
Validation loss: 2.8635910026229197

Epoch: 6| Step: 7
Training loss: 0.5922935592168502
Validation loss: 2.8719306539152423

Epoch: 6| Step: 8
Training loss: 0.6918432288038452
Validation loss: 2.8094374194652567

Epoch: 6| Step: 9
Training loss: 0.5863046894307562
Validation loss: 2.894464256070754

Epoch: 6| Step: 10
Training loss: 0.415295115753596
Validation loss: 2.831651136824615

Epoch: 6| Step: 11
Training loss: 0.39774443617237515
Validation loss: 2.9178997748281517

Epoch: 6| Step: 12
Training loss: 0.5846079683267793
Validation loss: 2.8917684544467774

Epoch: 6| Step: 13
Training loss: 0.543146447393652
Validation loss: 2.9375529994647427

Epoch: 276| Step: 0
Training loss: 0.42396706619766233
Validation loss: 2.816778094064598

Epoch: 6| Step: 1
Training loss: 0.49511651033434184
Validation loss: 2.8679612005403365

Epoch: 6| Step: 2
Training loss: 0.4871724012236168
Validation loss: 2.7579513673337397

Epoch: 6| Step: 3
Training loss: 0.4935150408322414
Validation loss: 2.883226924836428

Epoch: 6| Step: 4
Training loss: 0.5945304459555123
Validation loss: 2.8593050977712586

Epoch: 6| Step: 5
Training loss: 1.490693787721006
Validation loss: 2.8092139933796023

Epoch: 6| Step: 6
Training loss: 0.5406100684512971
Validation loss: 2.77162261467581

Epoch: 6| Step: 7
Training loss: 0.936721510322328
Validation loss: 2.8428690038229583

Epoch: 6| Step: 8
Training loss: 0.7601998076549308
Validation loss: 2.859803575870882

Epoch: 6| Step: 9
Training loss: 0.6657540711104013
Validation loss: 2.809744014415582

Epoch: 6| Step: 10
Training loss: 0.5999562009083853
Validation loss: 2.876175736771792

Epoch: 6| Step: 11
Training loss: 0.3946013246756185
Validation loss: 2.923109789826359

Epoch: 6| Step: 12
Training loss: 0.7190274242216613
Validation loss: 2.927665141285681

Epoch: 6| Step: 13
Training loss: 0.4441545220904208
Validation loss: 2.901736346932255

Epoch: 277| Step: 0
Training loss: 0.4498426996916434
Validation loss: 2.9786762331826324

Epoch: 6| Step: 1
Training loss: 0.551464982097778
Validation loss: 2.889422027185382

Epoch: 6| Step: 2
Training loss: 0.9966831034535083
Validation loss: 2.855193048710198

Epoch: 6| Step: 3
Training loss: 0.48053091313857077
Validation loss: 2.90147821005756

Epoch: 6| Step: 4
Training loss: 0.40328757682014227
Validation loss: 2.865226483827146

Epoch: 6| Step: 5
Training loss: 0.7433509942452803
Validation loss: 2.8986280846465635

Epoch: 6| Step: 6
Training loss: 0.43091351124895444
Validation loss: 2.8368141493763757

Epoch: 6| Step: 7
Training loss: 0.8120607509249225
Validation loss: 2.851769482490519

Epoch: 6| Step: 8
Training loss: 0.49568709279160156
Validation loss: 2.9033566911139563

Epoch: 6| Step: 9
Training loss: 0.5725655144265561
Validation loss: 2.8388251393478994

Epoch: 6| Step: 10
Training loss: 0.43131513103748936
Validation loss: 2.8761313050829167

Epoch: 6| Step: 11
Training loss: 1.3605963383373159
Validation loss: 2.918053376835861

Epoch: 6| Step: 12
Training loss: 0.6475091746501385
Validation loss: 3.0036215248312708

Epoch: 6| Step: 13
Training loss: 0.46413120185084455
Validation loss: 2.899302995164138

Epoch: 278| Step: 0
Training loss: 0.4511686217615986
Validation loss: 2.950123979366291

Epoch: 6| Step: 1
Training loss: 0.37431381945234976
Validation loss: 2.861512696581005

Epoch: 6| Step: 2
Training loss: 0.48173774055715085
Validation loss: 2.821872297463825

Epoch: 6| Step: 3
Training loss: 0.38434868699235725
Validation loss: 2.876488521411347

Epoch: 6| Step: 4
Training loss: 0.7080350041922786
Validation loss: 2.886170289998685

Epoch: 6| Step: 5
Training loss: 0.6247404990296188
Validation loss: 2.901916602539848

Epoch: 6| Step: 6
Training loss: 1.3322776946805828
Validation loss: 2.819542467097287

Epoch: 6| Step: 7
Training loss: 0.5985647788289706
Validation loss: 2.9099435749897675

Epoch: 6| Step: 8
Training loss: 0.7659237337217694
Validation loss: 2.884470296699642

Epoch: 6| Step: 9
Training loss: 0.660795680853904
Validation loss: 2.900316696851733

Epoch: 6| Step: 10
Training loss: 0.5032562084772026
Validation loss: 2.915123481316187

Epoch: 6| Step: 11
Training loss: 0.37923317009881896
Validation loss: 2.88458370529614

Epoch: 6| Step: 12
Training loss: 0.7696386736717233
Validation loss: 2.8666202216119294

Epoch: 6| Step: 13
Training loss: 0.5392751965178314
Validation loss: 2.8269182303636793

Epoch: 279| Step: 0
Training loss: 0.296144376971009
Validation loss: 2.830568322481616

Epoch: 6| Step: 1
Training loss: 0.5722973915631222
Validation loss: 2.9067905839336654

Epoch: 6| Step: 2
Training loss: 0.4886199691856986
Validation loss: 2.898391449074903

Epoch: 6| Step: 3
Training loss: 0.780811797272172
Validation loss: 2.8725998576320135

Epoch: 6| Step: 4
Training loss: 0.8613560124940817
Validation loss: 2.927943776323063

Epoch: 6| Step: 5
Training loss: 0.5310080201554456
Validation loss: 2.899998356829649

Epoch: 6| Step: 6
Training loss: 0.5071125194620737
Validation loss: 2.880086586961897

Epoch: 6| Step: 7
Training loss: 0.3814050140423344
Validation loss: 2.841074540840228

Epoch: 6| Step: 8
Training loss: 0.5926025999140925
Validation loss: 2.9245939608718365

Epoch: 6| Step: 9
Training loss: 1.4140052994597756
Validation loss: 3.0073740718074875

Epoch: 6| Step: 10
Training loss: 0.726266698202127
Validation loss: 2.9153808665988614

Epoch: 6| Step: 11
Training loss: 0.410417636960556
Validation loss: 2.884843959962957

Epoch: 6| Step: 12
Training loss: 0.380594934456803
Validation loss: 2.8134716051105015

Epoch: 6| Step: 13
Training loss: 0.6028812864775862
Validation loss: 2.8492964846668363

Epoch: 280| Step: 0
Training loss: 0.5054935325431448
Validation loss: 2.8856026260183887

Epoch: 6| Step: 1
Training loss: 0.41974384171113094
Validation loss: 2.8191794869671436

Epoch: 6| Step: 2
Training loss: 0.8561827932560206
Validation loss: 2.768345861167358

Epoch: 6| Step: 3
Training loss: 0.7269326364457663
Validation loss: 2.9097476134688254

Epoch: 6| Step: 4
Training loss: 0.4665206506897105
Validation loss: 2.8374476759871436

Epoch: 6| Step: 5
Training loss: 0.6260281926851021
Validation loss: 2.8579207441389207

Epoch: 6| Step: 6
Training loss: 0.5621284211241055
Validation loss: 2.8936083957418135

Epoch: 6| Step: 7
Training loss: 0.4797559583690511
Validation loss: 2.9286433686249373

Epoch: 6| Step: 8
Training loss: 0.5013030477407187
Validation loss: 2.8831709283136098

Epoch: 6| Step: 9
Training loss: 0.6806634276289969
Validation loss: 2.875573640069134

Epoch: 6| Step: 10
Training loss: 0.8710929973239812
Validation loss: 2.869356947487348

Epoch: 6| Step: 11
Training loss: 0.5345114004045183
Validation loss: 2.9322911065452857

Epoch: 6| Step: 12
Training loss: 0.6629251726237394
Validation loss: 2.8940694752073535

Epoch: 6| Step: 13
Training loss: 1.3322767551632535
Validation loss: 2.8464493009974023

Epoch: 281| Step: 0
Training loss: 0.9379879635239896
Validation loss: 2.894452380960444

Epoch: 6| Step: 1
Training loss: 0.37566358742570344
Validation loss: 2.8204848359238004

Epoch: 6| Step: 2
Training loss: 0.4753208400689345
Validation loss: 2.9582202424117003

Epoch: 6| Step: 3
Training loss: 0.49247451769553774
Validation loss: 2.929346564906187

Epoch: 6| Step: 4
Training loss: 0.5210623587285221
Validation loss: 2.905787379863534

Epoch: 6| Step: 5
Training loss: 0.6134241508628813
Validation loss: 2.850707127032693

Epoch: 6| Step: 6
Training loss: 1.3079014555326172
Validation loss: 2.900041093754375

Epoch: 6| Step: 7
Training loss: 0.173860043370565
Validation loss: 2.8893663776436007

Epoch: 6| Step: 8
Training loss: 0.7373744502126142
Validation loss: 2.8748989778544303

Epoch: 6| Step: 9
Training loss: 0.34246741869069236
Validation loss: 2.811621380365703

Epoch: 6| Step: 10
Training loss: 0.6262707190217569
Validation loss: 2.836522191832832

Epoch: 6| Step: 11
Training loss: 0.4823508886087686
Validation loss: 2.907750634422361

Epoch: 6| Step: 12
Training loss: 0.7736844525898529
Validation loss: 2.8234303324977335

Epoch: 6| Step: 13
Training loss: 0.4783280141077233
Validation loss: 2.912634082703901

Epoch: 282| Step: 0
Training loss: 0.5398966651520997
Validation loss: 2.875044808522321

Epoch: 6| Step: 1
Training loss: 0.5534058391318136
Validation loss: 2.8923721394679083

Epoch: 6| Step: 2
Training loss: 0.8334307295785651
Validation loss: 2.8060713588661623

Epoch: 6| Step: 3
Training loss: 1.3208467655321199
Validation loss: 2.9127597300097094

Epoch: 6| Step: 4
Training loss: 0.483096990131153
Validation loss: 2.8391525917685922

Epoch: 6| Step: 5
Training loss: 0.484755458924993
Validation loss: 2.8761686769317705

Epoch: 6| Step: 6
Training loss: 0.6477310974899483
Validation loss: 2.9196108036773225

Epoch: 6| Step: 7
Training loss: 0.4491550566258585
Validation loss: 2.9611844083156793

Epoch: 6| Step: 8
Training loss: 0.629717428097254
Validation loss: 2.969525741147849

Epoch: 6| Step: 9
Training loss: 0.4314421115271245
Validation loss: 2.9747262732616475

Epoch: 6| Step: 10
Training loss: 0.46734969471702836
Validation loss: 2.9182532944987596

Epoch: 6| Step: 11
Training loss: 0.5502994134182015
Validation loss: 2.8837180847465502

Epoch: 6| Step: 12
Training loss: 0.4688132879130816
Validation loss: 2.8745166814592866

Epoch: 6| Step: 13
Training loss: 0.4114576854781189
Validation loss: 2.9121308252374822

Epoch: 283| Step: 0
Training loss: 0.47266788310718083
Validation loss: 2.929380070132781

Epoch: 6| Step: 1
Training loss: 0.4569028690359934
Validation loss: 2.9022903197869576

Epoch: 6| Step: 2
Training loss: 0.6800338038288799
Validation loss: 2.811116464603069

Epoch: 6| Step: 3
Training loss: 0.6048474477321337
Validation loss: 2.860381555492254

Epoch: 6| Step: 4
Training loss: 0.8641300085367638
Validation loss: 2.866918372777046

Epoch: 6| Step: 5
Training loss: 0.3837524280098513
Validation loss: 2.894965753105667

Epoch: 6| Step: 6
Training loss: 0.5404955571174639
Validation loss: 2.91174792428733

Epoch: 6| Step: 7
Training loss: 1.280612740558051
Validation loss: 2.8534671083921648

Epoch: 6| Step: 8
Training loss: 0.49713206329200527
Validation loss: 2.921143397708262

Epoch: 6| Step: 9
Training loss: 0.4870103088321781
Validation loss: 2.8733780542737644

Epoch: 6| Step: 10
Training loss: 0.6760172128785464
Validation loss: 2.9363692521928146

Epoch: 6| Step: 11
Training loss: 0.4636304713132324
Validation loss: 2.901109188990218

Epoch: 6| Step: 12
Training loss: 0.42812421965701974
Validation loss: 2.901802187023986

Epoch: 6| Step: 13
Training loss: 0.48059750204211027
Validation loss: 2.8155765801661494

Epoch: 284| Step: 0
Training loss: 0.3525100336777368
Validation loss: 2.8697002186313867

Epoch: 6| Step: 1
Training loss: 0.524489015589662
Validation loss: 2.8382958028630076

Epoch: 6| Step: 2
Training loss: 1.0171012712954703
Validation loss: 2.832141630279783

Epoch: 6| Step: 3
Training loss: 0.5615994343953123
Validation loss: 2.866760928984705

Epoch: 6| Step: 4
Training loss: 0.4069421630425818
Validation loss: 2.8283568229291824

Epoch: 6| Step: 5
Training loss: 0.48000715148585227
Validation loss: 2.8772994120283237

Epoch: 6| Step: 6
Training loss: 0.6299184626463559
Validation loss: 2.94689116596576

Epoch: 6| Step: 7
Training loss: 0.554370090845643
Validation loss: 2.913093085199774

Epoch: 6| Step: 8
Training loss: 0.4916394224808355
Validation loss: 2.9281640054607907

Epoch: 6| Step: 9
Training loss: 0.5588247448469532
Validation loss: 2.8896052305844497

Epoch: 6| Step: 10
Training loss: 0.5389179644109177
Validation loss: 2.8559992863131503

Epoch: 6| Step: 11
Training loss: 0.5704138156307835
Validation loss: 2.996414187328772

Epoch: 6| Step: 12
Training loss: 0.7205272346209655
Validation loss: 2.861618051606616

Epoch: 6| Step: 13
Training loss: 1.23643577552964
Validation loss: 2.8801370695839235

Epoch: 285| Step: 0
Training loss: 0.39215961372354907
Validation loss: 2.835291204729571

Epoch: 6| Step: 1
Training loss: 0.43363313238326107
Validation loss: 2.9020636292003403

Epoch: 6| Step: 2
Training loss: 1.2908181459302204
Validation loss: 2.9110913986609606

Epoch: 6| Step: 3
Training loss: 0.5339371097299372
Validation loss: 2.8951364726181077

Epoch: 6| Step: 4
Training loss: 0.7708961658816409
Validation loss: 2.886598067455975

Epoch: 6| Step: 5
Training loss: 0.45783191223129965
Validation loss: 2.849476118068125

Epoch: 6| Step: 6
Training loss: 0.7005195664934428
Validation loss: 2.9018365169451665

Epoch: 6| Step: 7
Training loss: 0.7057399232802405
Validation loss: 3.0293474683014874

Epoch: 6| Step: 8
Training loss: 0.5521480294473367
Validation loss: 2.794023463145

Epoch: 6| Step: 9
Training loss: 0.5858057255387312
Validation loss: 2.9058165004743355

Epoch: 6| Step: 10
Training loss: 0.9429939778642322
Validation loss: 2.8974736848436553

Epoch: 6| Step: 11
Training loss: 0.5997635087212805
Validation loss: 2.905291956567378

Epoch: 6| Step: 12
Training loss: 0.5833675737776775
Validation loss: 2.8730858774863695

Epoch: 6| Step: 13
Training loss: 0.36357933038791
Validation loss: 2.943051483041865

Epoch: 286| Step: 0
Training loss: 0.806538129672605
Validation loss: 2.938332676388874

Epoch: 6| Step: 1
Training loss: 0.5060357923966377
Validation loss: 3.008686193094159

Epoch: 6| Step: 2
Training loss: 0.4670929707863734
Validation loss: 2.9592978467756486

Epoch: 6| Step: 3
Training loss: 0.6684864781694823
Validation loss: 2.875271431922226

Epoch: 6| Step: 4
Training loss: 0.6694491306007251
Validation loss: 2.978473213602592

Epoch: 6| Step: 5
Training loss: 0.48177409987158454
Validation loss: 2.883809386811598

Epoch: 6| Step: 6
Training loss: 1.3885932395764997
Validation loss: 2.9021683747336504

Epoch: 6| Step: 7
Training loss: 0.8134231091873952
Validation loss: 2.806152881847724

Epoch: 6| Step: 8
Training loss: 0.4097274355188518
Validation loss: 2.9223239846111744

Epoch: 6| Step: 9
Training loss: 0.5437015555714014
Validation loss: 2.9555484307553006

Epoch: 6| Step: 10
Training loss: 0.6295157612485605
Validation loss: 2.958215393258575

Epoch: 6| Step: 11
Training loss: 0.57852223641728
Validation loss: 2.9142449452249277

Epoch: 6| Step: 12
Training loss: 0.6109117546413093
Validation loss: 2.955290483138124

Epoch: 6| Step: 13
Training loss: 0.4943098600179373
Validation loss: 2.9723939182526427

Epoch: 287| Step: 0
Training loss: 0.5156819861161999
Validation loss: 3.0294378704066016

Epoch: 6| Step: 1
Training loss: 0.5440070290199035
Validation loss: 2.934304629976074

Epoch: 6| Step: 2
Training loss: 1.2516686745706667
Validation loss: 2.8762261360656165

Epoch: 6| Step: 3
Training loss: 0.45346165351501594
Validation loss: 2.9209047090205225

Epoch: 6| Step: 4
Training loss: 0.42984437679687415
Validation loss: 2.9037788714165345

Epoch: 6| Step: 5
Training loss: 0.48186892120940544
Validation loss: 2.9168713270771427

Epoch: 6| Step: 6
Training loss: 0.5803275808204081
Validation loss: 2.8651195555990645

Epoch: 6| Step: 7
Training loss: 0.8402663830876919
Validation loss: 2.9312023671393646

Epoch: 6| Step: 8
Training loss: 0.6249071052180296
Validation loss: 2.893071323395962

Epoch: 6| Step: 9
Training loss: 0.5513228060419965
Validation loss: 2.9367644153294323

Epoch: 6| Step: 10
Training loss: 0.5177502327996306
Validation loss: 2.88834414837972

Epoch: 6| Step: 11
Training loss: 0.28184236293137993
Validation loss: 2.921732404360646

Epoch: 6| Step: 12
Training loss: 0.6586130150707084
Validation loss: 2.9580486232242373

Epoch: 6| Step: 13
Training loss: 0.6617525202433315
Validation loss: 2.8978204267378262

Epoch: 288| Step: 0
Training loss: 0.541436895518762
Validation loss: 2.904221404411285

Epoch: 6| Step: 1
Training loss: 0.4456973002769472
Validation loss: 2.8692800593139833

Epoch: 6| Step: 2
Training loss: 0.6970202016735133
Validation loss: 2.796222376203108

Epoch: 6| Step: 3
Training loss: 0.38619400797551007
Validation loss: 2.842774443919437

Epoch: 6| Step: 4
Training loss: 1.3587248990601404
Validation loss: 2.8289140475212284

Epoch: 6| Step: 5
Training loss: 0.4320329635061875
Validation loss: 2.8900627620442236

Epoch: 6| Step: 6
Training loss: 0.3415012279882177
Validation loss: 2.8761782788625854

Epoch: 6| Step: 7
Training loss: 0.6854983146835968
Validation loss: 2.887712100387313

Epoch: 6| Step: 8
Training loss: 0.7855965817212013
Validation loss: 2.8836440598818713

Epoch: 6| Step: 9
Training loss: 0.47690057488453014
Validation loss: 2.9663513197261575

Epoch: 6| Step: 10
Training loss: 0.8028817517208863
Validation loss: 2.953022950038999

Epoch: 6| Step: 11
Training loss: 0.4957769088002024
Validation loss: 2.912365539459446

Epoch: 6| Step: 12
Training loss: 0.48881333923658
Validation loss: 2.9401695620368278

Epoch: 6| Step: 13
Training loss: 0.4916268743425454
Validation loss: 2.9084201011903765

Epoch: 289| Step: 0
Training loss: 0.4134130603028345
Validation loss: 2.9530642333329955

Epoch: 6| Step: 1
Training loss: 0.6661749506579978
Validation loss: 2.907098707745564

Epoch: 6| Step: 2
Training loss: 0.4536528636797841
Validation loss: 2.9705634618295282

Epoch: 6| Step: 3
Training loss: 0.4345694724085542
Validation loss: 2.959716853934454

Epoch: 6| Step: 4
Training loss: 0.48276504480910015
Validation loss: 2.933135178404241

Epoch: 6| Step: 5
Training loss: 0.439217025064062
Validation loss: 2.9872453078235424

Epoch: 6| Step: 6
Training loss: 0.685739756345989
Validation loss: 2.887401976579828

Epoch: 6| Step: 7
Training loss: 0.6763702207448273
Validation loss: 2.92172436657378

Epoch: 6| Step: 8
Training loss: 1.456385246839975
Validation loss: 2.9700049040226206

Epoch: 6| Step: 9
Training loss: 0.46715244812387713
Validation loss: 2.904543782564446

Epoch: 6| Step: 10
Training loss: 0.504745494238594
Validation loss: 2.9054643738137482

Epoch: 6| Step: 11
Training loss: 0.35903325624957105
Validation loss: 2.926125900415948

Epoch: 6| Step: 12
Training loss: 0.3425520918555498
Validation loss: 2.8860885765077917

Epoch: 6| Step: 13
Training loss: 0.6093322543288401
Validation loss: 2.920971028505641

Epoch: 290| Step: 0
Training loss: 1.4254430918551872
Validation loss: 2.9026340016031256

Epoch: 6| Step: 1
Training loss: 0.4519266692836662
Validation loss: 2.962458948529655

Epoch: 6| Step: 2
Training loss: 0.4915952601007973
Validation loss: 2.9235365795945807

Epoch: 6| Step: 3
Training loss: 0.5348000559231166
Validation loss: 2.9113680507649096

Epoch: 6| Step: 4
Training loss: 0.5801107480929378
Validation loss: 2.886184904560286

Epoch: 6| Step: 5
Training loss: 0.5593402915714257
Validation loss: 2.81390320423933

Epoch: 6| Step: 6
Training loss: 0.4906208293275875
Validation loss: 2.908927627405423

Epoch: 6| Step: 7
Training loss: 0.5978436394421628
Validation loss: 2.8673677864180758

Epoch: 6| Step: 8
Training loss: 0.6587028530701311
Validation loss: 2.8400063238610795

Epoch: 6| Step: 9
Training loss: 0.5512020857092591
Validation loss: 2.904008472645698

Epoch: 6| Step: 10
Training loss: 0.5570414923412423
Validation loss: 2.8898993741241004

Epoch: 6| Step: 11
Training loss: 0.5925773786566504
Validation loss: 2.8484330933900006

Epoch: 6| Step: 12
Training loss: 0.6419753752231337
Validation loss: 2.840974354427804

Epoch: 6| Step: 13
Training loss: 0.4360856628214816
Validation loss: 2.892486770014948

Epoch: 291| Step: 0
Training loss: 0.6520041992587616
Validation loss: 2.9219001728136273

Epoch: 6| Step: 1
Training loss: 0.8398218551265715
Validation loss: 2.9889050399855197

Epoch: 6| Step: 2
Training loss: 0.6059661298955552
Validation loss: 2.916248936484664

Epoch: 6| Step: 3
Training loss: 0.5874993679367886
Validation loss: 2.939191453001982

Epoch: 6| Step: 4
Training loss: 0.4093519772178171
Validation loss: 2.929127984765999

Epoch: 6| Step: 5
Training loss: 0.46800153104825104
Validation loss: 2.892403909235054

Epoch: 6| Step: 6
Training loss: 0.4942481033383351
Validation loss: 2.8420066799744808

Epoch: 6| Step: 7
Training loss: 0.6866307832622609
Validation loss: 2.842116644872465

Epoch: 6| Step: 8
Training loss: 0.41004357379714934
Validation loss: 2.8701061807987953

Epoch: 6| Step: 9
Training loss: 0.7581666335257322
Validation loss: 2.8919150420786552

Epoch: 6| Step: 10
Training loss: 0.4989983837908026
Validation loss: 2.9127184211569546

Epoch: 6| Step: 11
Training loss: 0.5026034584106304
Validation loss: 2.8248691399122148

Epoch: 6| Step: 12
Training loss: 1.2546320445725796
Validation loss: 2.854157041733006

Epoch: 6| Step: 13
Training loss: 0.6903490507742495
Validation loss: 2.935838100719308

Epoch: 292| Step: 0
Training loss: 0.6283182748293719
Validation loss: 2.961659178272656

Epoch: 6| Step: 1
Training loss: 0.8026162313503044
Validation loss: 2.883466210546728

Epoch: 6| Step: 2
Training loss: 0.5809901097419391
Validation loss: 2.9355496228666933

Epoch: 6| Step: 3
Training loss: 0.46201399192017006
Validation loss: 2.9047223933605135

Epoch: 6| Step: 4
Training loss: 0.49359085198083286
Validation loss: 2.9098889528958702

Epoch: 6| Step: 5
Training loss: 0.39366103029993926
Validation loss: 2.870532074740722

Epoch: 6| Step: 6
Training loss: 1.2663528327571922
Validation loss: 2.8479301484874155

Epoch: 6| Step: 7
Training loss: 0.53838001114794
Validation loss: 2.851209212762189

Epoch: 6| Step: 8
Training loss: 0.527896930046643
Validation loss: 2.9090999589358435

Epoch: 6| Step: 9
Training loss: 0.8684816069382044
Validation loss: 2.924062878721913

Epoch: 6| Step: 10
Training loss: 0.5539917948404417
Validation loss: 2.941773457970673

Epoch: 6| Step: 11
Training loss: 0.4500924777003891
Validation loss: 2.8929979361843112

Epoch: 6| Step: 12
Training loss: 0.49666811516676435
Validation loss: 2.8775663393506132

Epoch: 6| Step: 13
Training loss: 0.40463456503587436
Validation loss: 2.9297905797838135

Epoch: 293| Step: 0
Training loss: 0.44772405327271847
Validation loss: 2.951003387307033

Epoch: 6| Step: 1
Training loss: 0.5364154563978258
Validation loss: 2.869322111251251

Epoch: 6| Step: 2
Training loss: 0.5293780894453927
Validation loss: 2.8745568528241012

Epoch: 6| Step: 3
Training loss: 0.5991409161684247
Validation loss: 2.8990880710759335

Epoch: 6| Step: 4
Training loss: 0.44786602850341206
Validation loss: 2.9583613882391164

Epoch: 6| Step: 5
Training loss: 0.3788895947443415
Validation loss: 2.827600223193976

Epoch: 6| Step: 6
Training loss: 0.4076676575543912
Validation loss: 2.8528265394108487

Epoch: 6| Step: 7
Training loss: 0.9379316607756342
Validation loss: 2.899317749109471

Epoch: 6| Step: 8
Training loss: 1.2808116535162937
Validation loss: 2.897595361210596

Epoch: 6| Step: 9
Training loss: 0.4320413274434724
Validation loss: 2.8624679569188913

Epoch: 6| Step: 10
Training loss: 0.6017179412162772
Validation loss: 2.867723392364356

Epoch: 6| Step: 11
Training loss: 0.3373099392392079
Validation loss: 2.8837799406267997

Epoch: 6| Step: 12
Training loss: 0.5837820461715579
Validation loss: 2.833088925048715

Epoch: 6| Step: 13
Training loss: 0.6288786935396409
Validation loss: 2.822601903748918

Epoch: 294| Step: 0
Training loss: 0.548097279977548
Validation loss: 2.8960658444340566

Epoch: 6| Step: 1
Training loss: 0.43604175182450444
Validation loss: 2.8708322972562015

Epoch: 6| Step: 2
Training loss: 0.35046505770054237
Validation loss: 2.8862609087249274

Epoch: 6| Step: 3
Training loss: 0.8602068256473671
Validation loss: 2.8884413298109926

Epoch: 6| Step: 4
Training loss: 0.6861783458565739
Validation loss: 2.871695886560325

Epoch: 6| Step: 5
Training loss: 0.5094050158684694
Validation loss: 2.8900324583595784

Epoch: 6| Step: 6
Training loss: 0.44443509179778357
Validation loss: 2.952880418663628

Epoch: 6| Step: 7
Training loss: 0.4403855667514026
Validation loss: 2.941721702975791

Epoch: 6| Step: 8
Training loss: 0.4671755734965847
Validation loss: 2.9580657372313524

Epoch: 6| Step: 9
Training loss: 0.5901947240430774
Validation loss: 2.964560252671905

Epoch: 6| Step: 10
Training loss: 0.6890201884316975
Validation loss: 2.915101944049758

Epoch: 6| Step: 11
Training loss: 1.2965946583909829
Validation loss: 3.001750858982311

Epoch: 6| Step: 12
Training loss: 0.5551366733542551
Validation loss: 2.8609350913159357

Epoch: 6| Step: 13
Training loss: 0.42885032942417795
Validation loss: 2.8952990160190795

Epoch: 295| Step: 0
Training loss: 0.4942183000030061
Validation loss: 2.908272985981786

Epoch: 6| Step: 1
Training loss: 0.41031187828812926
Validation loss: 2.867648622053055

Epoch: 6| Step: 2
Training loss: 0.6877674102909095
Validation loss: 2.8422398871874583

Epoch: 6| Step: 3
Training loss: 1.1989326757121093
Validation loss: 2.8696240527895367

Epoch: 6| Step: 4
Training loss: 0.5150015269414246
Validation loss: 2.813678889981031

Epoch: 6| Step: 5
Training loss: 0.5999663840254734
Validation loss: 2.818800840743995

Epoch: 6| Step: 6
Training loss: 0.5674217854178966
Validation loss: 2.876462398612842

Epoch: 6| Step: 7
Training loss: 0.5338087171110787
Validation loss: 2.8554751860984844

Epoch: 6| Step: 8
Training loss: 0.5747301328775409
Validation loss: 2.8320405666154227

Epoch: 6| Step: 9
Training loss: 0.5284251392888237
Validation loss: 2.9780551508597513

Epoch: 6| Step: 10
Training loss: 0.6922062270685966
Validation loss: 2.947834139546028

Epoch: 6| Step: 11
Training loss: 0.5669190288970927
Validation loss: 2.9389416153482015

Epoch: 6| Step: 12
Training loss: 0.4817382509365726
Validation loss: 2.8607975907338004

Epoch: 6| Step: 13
Training loss: 0.6775501671477906
Validation loss: 2.8621353555719034

Epoch: 296| Step: 0
Training loss: 0.5811464894326306
Validation loss: 2.886768813811091

Epoch: 6| Step: 1
Training loss: 0.6331862535058697
Validation loss: 2.8664511723436665

Epoch: 6| Step: 2
Training loss: 0.4078502681387567
Validation loss: 2.8851690404150343

Epoch: 6| Step: 3
Training loss: 0.45074231063876796
Validation loss: 2.847572161458162

Epoch: 6| Step: 4
Training loss: 0.4802956152872474
Validation loss: 2.9307879741963268

Epoch: 6| Step: 5
Training loss: 0.9593080491055862
Validation loss: 2.9404067139206878

Epoch: 6| Step: 6
Training loss: 0.5007794384618597
Validation loss: 2.942460518363862

Epoch: 6| Step: 7
Training loss: 0.5605456521688807
Validation loss: 2.9329229367599163

Epoch: 6| Step: 8
Training loss: 0.4554171629493199
Validation loss: 2.943328121485979

Epoch: 6| Step: 9
Training loss: 1.200274471841552
Validation loss: 2.9444968175928623

Epoch: 6| Step: 10
Training loss: 0.5555397524837776
Validation loss: 2.994880639565175

Epoch: 6| Step: 11
Training loss: 0.6876531127012144
Validation loss: 2.952328879070019

Epoch: 6| Step: 12
Training loss: 0.616071246919151
Validation loss: 2.907392120174903

Epoch: 6| Step: 13
Training loss: 0.5206521068628183
Validation loss: 2.885169921864643

Epoch: 297| Step: 0
Training loss: 0.6357689542746263
Validation loss: 2.8608153698567707

Epoch: 6| Step: 1
Training loss: 0.7884943965986108
Validation loss: 2.8157103053869377

Epoch: 6| Step: 2
Training loss: 0.4267522257214403
Validation loss: 2.8581519507716786

Epoch: 6| Step: 3
Training loss: 0.35280757410683905
Validation loss: 2.866317020946402

Epoch: 6| Step: 4
Training loss: 0.3354067268833789
Validation loss: 2.8469594374137497

Epoch: 6| Step: 5
Training loss: 0.4784667943835149
Validation loss: 2.856422025145459

Epoch: 6| Step: 6
Training loss: 0.5570569539392703
Validation loss: 2.9518040388749136

Epoch: 6| Step: 7
Training loss: 0.49708609565304157
Validation loss: 2.8733367324205665

Epoch: 6| Step: 8
Training loss: 1.1707922447479477
Validation loss: 2.8857678820503714

Epoch: 6| Step: 9
Training loss: 0.6915031623809395
Validation loss: 2.989365112279828

Epoch: 6| Step: 10
Training loss: 0.5972250835463514
Validation loss: 2.936916793933933

Epoch: 6| Step: 11
Training loss: 0.5962233476260084
Validation loss: 2.950263330592451

Epoch: 6| Step: 12
Training loss: 0.43032165894356844
Validation loss: 2.919388813194917

Epoch: 6| Step: 13
Training loss: 0.37305454426017126
Validation loss: 2.867298993706889

Epoch: 298| Step: 0
Training loss: 0.5286237088789996
Validation loss: 2.914361810525511

Epoch: 6| Step: 1
Training loss: 1.2061951343135264
Validation loss: 2.9479820437421487

Epoch: 6| Step: 2
Training loss: 0.5546281541051586
Validation loss: 2.831034419572873

Epoch: 6| Step: 3
Training loss: 0.29389636370404
Validation loss: 2.9425486068362496

Epoch: 6| Step: 4
Training loss: 0.5464954148786877
Validation loss: 2.9096893004196516

Epoch: 6| Step: 5
Training loss: 0.7553331381614323
Validation loss: 2.8211604892636566

Epoch: 6| Step: 6
Training loss: 0.7561299630732331
Validation loss: 2.917054148321279

Epoch: 6| Step: 7
Training loss: 0.5533090306837608
Validation loss: 2.970828884454921

Epoch: 6| Step: 8
Training loss: 0.34774155588134015
Validation loss: 2.8510271310116333

Epoch: 6| Step: 9
Training loss: 0.6801802942437098
Validation loss: 2.885894699068441

Epoch: 6| Step: 10
Training loss: 0.3256617914820486
Validation loss: 2.92292254840008

Epoch: 6| Step: 11
Training loss: 0.4626705918284134
Validation loss: 2.8949780516157553

Epoch: 6| Step: 12
Training loss: 0.5413024362444075
Validation loss: 2.8528326123580587

Epoch: 6| Step: 13
Training loss: 0.5459364876085403
Validation loss: 2.9040957981768796

Epoch: 299| Step: 0
Training loss: 0.5741842090831691
Validation loss: 2.866988505180422

Epoch: 6| Step: 1
Training loss: 0.4969826641637988
Validation loss: 2.869101471933507

Epoch: 6| Step: 2
Training loss: 0.5668241340502387
Validation loss: 2.913558636860165

Epoch: 6| Step: 3
Training loss: 0.5917988641787294
Validation loss: 2.9392821675178604

Epoch: 6| Step: 4
Training loss: 0.5227313616370304
Validation loss: 2.9968116825165256

Epoch: 6| Step: 5
Training loss: 0.7525781189173933
Validation loss: 3.02478671464835

Epoch: 6| Step: 6
Training loss: 0.4284284003896176
Validation loss: 3.0158124743546004

Epoch: 6| Step: 7
Training loss: 0.48010364089090607
Validation loss: 2.8766650478436575

Epoch: 6| Step: 8
Training loss: 0.3759324481399536
Validation loss: 2.850071221850386

Epoch: 6| Step: 9
Training loss: 0.5100400339570033
Validation loss: 2.868744845583073

Epoch: 6| Step: 10
Training loss: 0.5711691967016056
Validation loss: 2.9161650271680264

Epoch: 6| Step: 11
Training loss: 1.3059117860400817
Validation loss: 2.898847360756612

Epoch: 6| Step: 12
Training loss: 0.8739159544595718
Validation loss: 2.9293916680065473

Epoch: 6| Step: 13
Training loss: 0.5285934052676239
Validation loss: 2.9026251442999573

Epoch: 300| Step: 0
Training loss: 0.4142780642525451
Validation loss: 2.8676406820963773

Epoch: 6| Step: 1
Training loss: 0.6398408556675919
Validation loss: 2.9096480162593084

Epoch: 6| Step: 2
Training loss: 0.5012378271627299
Validation loss: 2.9192434554073907

Epoch: 6| Step: 3
Training loss: 0.38557181156915066
Validation loss: 2.818089081617175

Epoch: 6| Step: 4
Training loss: 1.1177471333097737
Validation loss: 2.864859901717661

Epoch: 6| Step: 5
Training loss: 0.40816231117453283
Validation loss: 2.9359527598321646

Epoch: 6| Step: 6
Training loss: 0.7046234270896768
Validation loss: 2.8917192329737094

Epoch: 6| Step: 7
Training loss: 0.5729129502147007
Validation loss: 2.8791889274461635

Epoch: 6| Step: 8
Training loss: 0.4409446328043804
Validation loss: 2.912490038656901

Epoch: 6| Step: 9
Training loss: 0.7313647155768843
Validation loss: 2.9192708049754885

Epoch: 6| Step: 10
Training loss: 0.6315539525287459
Validation loss: 2.908491698893002

Epoch: 6| Step: 11
Training loss: 0.46722308058470235
Validation loss: 2.8609913633239086

Epoch: 6| Step: 12
Training loss: 0.4160903362115508
Validation loss: 2.8701841682509053

Epoch: 6| Step: 13
Training loss: 0.7062702614907662
Validation loss: 2.949489704005254

Epoch: 301| Step: 0
Training loss: 0.5780853567192026
Validation loss: 2.825924939675319

Epoch: 6| Step: 1
Training loss: 0.9505307584618895
Validation loss: 2.8527509538152316

Epoch: 6| Step: 2
Training loss: 0.5049749471096606
Validation loss: 2.8545344224855422

Epoch: 6| Step: 3
Training loss: 0.52363266793704
Validation loss: 2.8391443481851972

Epoch: 6| Step: 4
Training loss: 0.5292116216151869
Validation loss: 2.8836509360616085

Epoch: 6| Step: 5
Training loss: 0.347438765660585
Validation loss: 2.8939869755493812

Epoch: 6| Step: 6
Training loss: 0.4509429350781193
Validation loss: 2.9052107809026144

Epoch: 6| Step: 7
Training loss: 1.1999614788866215
Validation loss: 3.01566549876794

Epoch: 6| Step: 8
Training loss: 0.6301109669611075
Validation loss: 2.982914365797829

Epoch: 6| Step: 9
Training loss: 0.3877292301129485
Validation loss: 2.872120009062277

Epoch: 6| Step: 10
Training loss: 0.44150943731544595
Validation loss: 2.8985729340120514

Epoch: 6| Step: 11
Training loss: 0.514745453407325
Validation loss: 2.8332682396386253

Epoch: 6| Step: 12
Training loss: 0.677414876509951
Validation loss: 2.893905798588286

Epoch: 6| Step: 13
Training loss: 0.468806199837397
Validation loss: 2.942731581514511

Epoch: 302| Step: 0
Training loss: 0.6233079178068991
Validation loss: 2.9595496314466656

Epoch: 6| Step: 1
Training loss: 0.6070796088124292
Validation loss: 2.86453428515434

Epoch: 6| Step: 2
Training loss: 1.1448357082754563
Validation loss: 2.8480592014351376

Epoch: 6| Step: 3
Training loss: 0.4527705055545374
Validation loss: 2.9503877525024356

Epoch: 6| Step: 4
Training loss: 0.519461232680182
Validation loss: 2.921722680131767

Epoch: 6| Step: 5
Training loss: 0.3787979482446651
Validation loss: 2.9587219054727254

Epoch: 6| Step: 6
Training loss: 0.5667103970240477
Validation loss: 2.9697597459575955

Epoch: 6| Step: 7
Training loss: 0.6077940067723822
Validation loss: 2.9888749872906177

Epoch: 6| Step: 8
Training loss: 0.7201641517515205
Validation loss: 2.965628270963762

Epoch: 6| Step: 9
Training loss: 0.65848134666561
Validation loss: 2.9145697730846227

Epoch: 6| Step: 10
Training loss: 0.7224977061621344
Validation loss: 2.8546475726952605

Epoch: 6| Step: 11
Training loss: 0.5186397102036903
Validation loss: 2.9354430294725655

Epoch: 6| Step: 12
Training loss: 0.5372053026020008
Validation loss: 2.8529259753299385

Epoch: 6| Step: 13
Training loss: 0.5944123589119693
Validation loss: 2.9196257476171996

Epoch: 303| Step: 0
Training loss: 1.2345984534321437
Validation loss: 2.8758139771044338

Epoch: 6| Step: 1
Training loss: 0.6002060595964421
Validation loss: 2.9138534920935233

Epoch: 6| Step: 2
Training loss: 0.8321030993176157
Validation loss: 2.8689519042394402

Epoch: 6| Step: 3
Training loss: 0.38249867089981837
Validation loss: 2.9335406112768334

Epoch: 6| Step: 4
Training loss: 0.41992867042898235
Validation loss: 2.8859219481650356

Epoch: 6| Step: 5
Training loss: 0.4676757901714051
Validation loss: 2.957844832657242

Epoch: 6| Step: 6
Training loss: 0.2645916754741627
Validation loss: 2.8962185463962458

Epoch: 6| Step: 7
Training loss: 0.4479177460176933
Validation loss: 2.788699143335144

Epoch: 6| Step: 8
Training loss: 0.5033317070212627
Validation loss: 3.0111978610665933

Epoch: 6| Step: 9
Training loss: 0.5770224290055279
Validation loss: 2.890725177025666

Epoch: 6| Step: 10
Training loss: 0.5668944523932035
Validation loss: 2.927558444053543

Epoch: 6| Step: 11
Training loss: 0.43619443028513344
Validation loss: 2.889529830081578

Epoch: 6| Step: 12
Training loss: 0.35797938656999534
Validation loss: 2.9407643178759737

Epoch: 6| Step: 13
Training loss: 0.5708693568379046
Validation loss: 2.9309893890114167

Epoch: 304| Step: 0
Training loss: 1.2551953115882621
Validation loss: 3.011825302356779

Epoch: 6| Step: 1
Training loss: 0.3682535604070439
Validation loss: 2.908270717883173

Epoch: 6| Step: 2
Training loss: 0.5603688984287069
Validation loss: 2.8402711178536486

Epoch: 6| Step: 3
Training loss: 0.8655978229539398
Validation loss: 2.947490463629673

Epoch: 6| Step: 4
Training loss: 0.5934104450440555
Validation loss: 2.823781677446673

Epoch: 6| Step: 5
Training loss: 0.47016194997763466
Validation loss: 2.9564110371317183

Epoch: 6| Step: 6
Training loss: 0.6655862716368594
Validation loss: 2.8948990574853175

Epoch: 6| Step: 7
Training loss: 0.3247682327301626
Validation loss: 2.8818746555769117

Epoch: 6| Step: 8
Training loss: 0.4259437460941655
Validation loss: 2.9157116870593085

Epoch: 6| Step: 9
Training loss: 0.4649468636147401
Validation loss: 2.9412661549040355

Epoch: 6| Step: 10
Training loss: 0.4564091287356925
Validation loss: 2.990073856071003

Epoch: 6| Step: 11
Training loss: 0.4609789748848351
Validation loss: 2.936034872035056

Epoch: 6| Step: 12
Training loss: 0.445872573670549
Validation loss: 2.839362438190071

Epoch: 6| Step: 13
Training loss: 0.5480210149296185
Validation loss: 2.9364575369243933

Epoch: 305| Step: 0
Training loss: 0.45891112696777575
Validation loss: 2.882339231932461

Epoch: 6| Step: 1
Training loss: 0.581570538973092
Validation loss: 2.931952615563191

Epoch: 6| Step: 2
Training loss: 0.6077888337065783
Validation loss: 2.8619373423766037

Epoch: 6| Step: 3
Training loss: 0.32582997202460623
Validation loss: 2.902584238815053

Epoch: 6| Step: 4
Training loss: 0.8004258274214089
Validation loss: 2.9474313199381523

Epoch: 6| Step: 5
Training loss: 0.6300037829724523
Validation loss: 2.8789850342390166

Epoch: 6| Step: 6
Training loss: 0.49885353137193766
Validation loss: 2.943471574406208

Epoch: 6| Step: 7
Training loss: 0.4844565784298652
Validation loss: 2.8820030364753633

Epoch: 6| Step: 8
Training loss: 0.38298801369000895
Validation loss: 2.9659339800102256

Epoch: 6| Step: 9
Training loss: 0.44348351173328954
Validation loss: 2.8812422779170093

Epoch: 6| Step: 10
Training loss: 1.0951990610278879
Validation loss: 2.864874451612069

Epoch: 6| Step: 11
Training loss: 0.47443358379984474
Validation loss: 2.89056836321908

Epoch: 6| Step: 12
Training loss: 0.521850885759234
Validation loss: 2.924821955269526

Epoch: 6| Step: 13
Training loss: 0.5318176938842396
Validation loss: 2.9092401824975216

Epoch: 306| Step: 0
Training loss: 0.6245403506923667
Validation loss: 2.9371058963972008

Epoch: 6| Step: 1
Training loss: 1.1049550618661337
Validation loss: 2.9422447357039885

Epoch: 6| Step: 2
Training loss: 0.7570400430426514
Validation loss: 2.8672421456239183

Epoch: 6| Step: 3
Training loss: 0.5197202009050399
Validation loss: 2.838407689470364

Epoch: 6| Step: 4
Training loss: 0.574896639365836
Validation loss: 2.9094524582202195

Epoch: 6| Step: 5
Training loss: 0.47700754865835276
Validation loss: 2.886725508734018

Epoch: 6| Step: 6
Training loss: 0.38993755886091497
Validation loss: 2.929673109231149

Epoch: 6| Step: 7
Training loss: 0.5293576251424723
Validation loss: 2.9192777843999447

Epoch: 6| Step: 8
Training loss: 0.4590897784038907
Validation loss: 2.934355466301644

Epoch: 6| Step: 9
Training loss: 0.6837573918251629
Validation loss: 2.9422372604108573

Epoch: 6| Step: 10
Training loss: 0.40232345381719176
Validation loss: 3.020069141849069

Epoch: 6| Step: 11
Training loss: 0.8248451347650175
Validation loss: 2.9161762415604153

Epoch: 6| Step: 12
Training loss: 0.44759326911191455
Validation loss: 3.0120001437565844

Epoch: 6| Step: 13
Training loss: 0.28796530315304725
Validation loss: 2.9848449896175997

Epoch: 307| Step: 0
Training loss: 0.6664906930137717
Validation loss: 2.930695722240097

Epoch: 6| Step: 1
Training loss: 0.5751142979094385
Validation loss: 2.984198666567624

Epoch: 6| Step: 2
Training loss: 0.3279395260451095
Validation loss: 2.9238828808098227

Epoch: 6| Step: 3
Training loss: 0.28661612875178233
Validation loss: 2.924922435090715

Epoch: 6| Step: 4
Training loss: 0.40028997877558004
Validation loss: 2.9911364177538173

Epoch: 6| Step: 5
Training loss: 0.4056142637774573
Validation loss: 2.9248366008666893

Epoch: 6| Step: 6
Training loss: 0.4665355509533488
Validation loss: 2.8892570282946144

Epoch: 6| Step: 7
Training loss: 0.5859691611319001
Validation loss: 2.8741430719354084

Epoch: 6| Step: 8
Training loss: 0.4379412435494379
Validation loss: 2.930883666940326

Epoch: 6| Step: 9
Training loss: 0.42668479451894287
Validation loss: 2.848577879632249

Epoch: 6| Step: 10
Training loss: 1.08925128542877
Validation loss: 2.8933183236838835

Epoch: 6| Step: 11
Training loss: 0.525994361664102
Validation loss: 2.843281602536116

Epoch: 6| Step: 12
Training loss: 0.6868028791015678
Validation loss: 2.8146202572523706

Epoch: 6| Step: 13
Training loss: 0.4737593648885749
Validation loss: 2.7914134570246794

Epoch: 308| Step: 0
Training loss: 0.44642087963834837
Validation loss: 2.8697789648274563

Epoch: 6| Step: 1
Training loss: 0.3963399539492922
Validation loss: 2.894225467758594

Epoch: 6| Step: 2
Training loss: 0.3804450691576912
Validation loss: 2.931086220737617

Epoch: 6| Step: 3
Training loss: 0.5550602479830377
Validation loss: 2.873763938229523

Epoch: 6| Step: 4
Training loss: 0.4250089658464642
Validation loss: 2.8803193874000175

Epoch: 6| Step: 5
Training loss: 0.8372315702554227
Validation loss: 2.9053653341339696

Epoch: 6| Step: 6
Training loss: 0.5029711067402834
Validation loss: 2.871572074922606

Epoch: 6| Step: 7
Training loss: 1.0957394626188224
Validation loss: 2.8393843680234303

Epoch: 6| Step: 8
Training loss: 0.40192454452408166
Validation loss: 2.894779985717033

Epoch: 6| Step: 9
Training loss: 0.47167396936840333
Validation loss: 2.858090589927769

Epoch: 6| Step: 10
Training loss: 0.44977203793945786
Validation loss: 2.8709879953019817

Epoch: 6| Step: 11
Training loss: 0.4066727529360846
Validation loss: 2.851062246538023

Epoch: 6| Step: 12
Training loss: 0.5416661011864082
Validation loss: 2.9070828929490906

Epoch: 6| Step: 13
Training loss: 0.4966569692056473
Validation loss: 2.825832836076458

Epoch: 309| Step: 0
Training loss: 0.3318941281979069
Validation loss: 2.9069588729841347

Epoch: 6| Step: 1
Training loss: 0.293626047929085
Validation loss: 2.892066891499878

Epoch: 6| Step: 2
Training loss: 0.5807610290636144
Validation loss: 2.8422196291183535

Epoch: 6| Step: 3
Training loss: 0.5522379988423628
Validation loss: 2.9383962089257936

Epoch: 6| Step: 4
Training loss: 0.2657133404305486
Validation loss: 2.9093025474390943

Epoch: 6| Step: 5
Training loss: 0.47288376872992594
Validation loss: 2.8253246514674695

Epoch: 6| Step: 6
Training loss: 1.1419534654806662
Validation loss: 2.8763542302960685

Epoch: 6| Step: 7
Training loss: 0.5062171230708012
Validation loss: 2.9169592211094693

Epoch: 6| Step: 8
Training loss: 0.3522431248940831
Validation loss: 2.8660789792966277

Epoch: 6| Step: 9
Training loss: 0.5029709882351626
Validation loss: 2.9347724967614433

Epoch: 6| Step: 10
Training loss: 0.46913352217685134
Validation loss: 2.8860109912965264

Epoch: 6| Step: 11
Training loss: 0.583073802389063
Validation loss: 2.8572483040447487

Epoch: 6| Step: 12
Training loss: 0.7512878645813628
Validation loss: 2.8795391544762974

Epoch: 6| Step: 13
Training loss: 0.5833989657082608
Validation loss: 2.9061765217123288

Epoch: 310| Step: 0
Training loss: 0.6172064766199774
Validation loss: 3.0011472362807954

Epoch: 6| Step: 1
Training loss: 0.5748500856598386
Validation loss: 2.963289640109522

Epoch: 6| Step: 2
Training loss: 0.5763085154780486
Validation loss: 2.9732421885691744

Epoch: 6| Step: 3
Training loss: 0.2940686749611633
Validation loss: 2.927299916862525

Epoch: 6| Step: 4
Training loss: 0.5957175581387402
Validation loss: 2.921478890617328

Epoch: 6| Step: 5
Training loss: 0.44151152984105607
Validation loss: 3.0090875474459993

Epoch: 6| Step: 6
Training loss: 0.6925590086491696
Validation loss: 2.8877793610422393

Epoch: 6| Step: 7
Training loss: 0.6114680462206046
Validation loss: 2.9222064178782374

Epoch: 6| Step: 8
Training loss: 0.3335681798278747
Validation loss: 2.9578842081847845

Epoch: 6| Step: 9
Training loss: 0.522644609626731
Validation loss: 2.949192402366183

Epoch: 6| Step: 10
Training loss: 0.4703658704163152
Validation loss: 2.9524736577559225

Epoch: 6| Step: 11
Training loss: 1.2299774642368524
Validation loss: 2.8784031836054753

Epoch: 6| Step: 12
Training loss: 0.4039629418672726
Validation loss: 2.93565408727042

Epoch: 6| Step: 13
Training loss: 0.4393975794974235
Validation loss: 2.940989606241198

Epoch: 311| Step: 0
Training loss: 0.40862106757082006
Validation loss: 2.885068498301833

Epoch: 6| Step: 1
Training loss: 0.3633890709791913
Validation loss: 2.9384187790089276

Epoch: 6| Step: 2
Training loss: 0.3212874624102324
Validation loss: 2.8220325694936403

Epoch: 6| Step: 3
Training loss: 0.7511700007771852
Validation loss: 2.8762311372631646

Epoch: 6| Step: 4
Training loss: 0.6239641427059954
Validation loss: 2.8712664009481648

Epoch: 6| Step: 5
Training loss: 0.5704206076802365
Validation loss: 2.879143769375133

Epoch: 6| Step: 6
Training loss: 0.40275970734512784
Validation loss: 2.934283260581094

Epoch: 6| Step: 7
Training loss: 0.39969347295406576
Validation loss: 2.928133091869593

Epoch: 6| Step: 8
Training loss: 0.5809728228176092
Validation loss: 2.910232379096783

Epoch: 6| Step: 9
Training loss: 0.565772603202511
Validation loss: 2.8841701711747083

Epoch: 6| Step: 10
Training loss: 0.25939039506379846
Validation loss: 2.9273601867143744

Epoch: 6| Step: 11
Training loss: 0.3799419994385896
Validation loss: 2.8545115789206563

Epoch: 6| Step: 12
Training loss: 1.0460776523664859
Validation loss: 2.937018415866741

Epoch: 6| Step: 13
Training loss: 0.5467858378068579
Validation loss: 2.8538642685979867

Epoch: 312| Step: 0
Training loss: 0.4131033422532502
Validation loss: 2.8087863705742886

Epoch: 6| Step: 1
Training loss: 0.47324819777478555
Validation loss: 2.9072053631107955

Epoch: 6| Step: 2
Training loss: 0.6861258558815962
Validation loss: 2.871406963676484

Epoch: 6| Step: 3
Training loss: 0.4618844149795267
Validation loss: 2.9255935751358595

Epoch: 6| Step: 4
Training loss: 0.4809345995324154
Validation loss: 2.9379514523159442

Epoch: 6| Step: 5
Training loss: 0.459810657613158
Validation loss: 2.8398426585870924

Epoch: 6| Step: 6
Training loss: 0.38540708255020617
Validation loss: 2.89281565506377

Epoch: 6| Step: 7
Training loss: 0.59498876044132
Validation loss: 2.9088202292097014

Epoch: 6| Step: 8
Training loss: 0.4996136424320075
Validation loss: 2.8364654413910078

Epoch: 6| Step: 9
Training loss: 0.4892615129707785
Validation loss: 2.8761240240783947

Epoch: 6| Step: 10
Training loss: 0.44558596997859956
Validation loss: 2.9020201278854323

Epoch: 6| Step: 11
Training loss: 0.4138001024388057
Validation loss: 2.9632887684875633

Epoch: 6| Step: 12
Training loss: 0.5660352346789383
Validation loss: 2.9200635520559923

Epoch: 6| Step: 13
Training loss: 1.14018868240122
Validation loss: 2.883726779649692

Epoch: 313| Step: 0
Training loss: 0.508281461878069
Validation loss: 2.927905531739425

Epoch: 6| Step: 1
Training loss: 0.5457608453893587
Validation loss: 2.8486946351207694

Epoch: 6| Step: 2
Training loss: 1.0645725568212236
Validation loss: 2.941663267297555

Epoch: 6| Step: 3
Training loss: 0.44779668539144324
Validation loss: 2.8699793860950136

Epoch: 6| Step: 4
Training loss: 0.511952150420471
Validation loss: 2.886685582419068

Epoch: 6| Step: 5
Training loss: 0.4106338263714131
Validation loss: 2.9030893154572306

Epoch: 6| Step: 6
Training loss: 0.3670407265665434
Validation loss: 2.9213024809267467

Epoch: 6| Step: 7
Training loss: 0.39339953220409435
Validation loss: 2.899898506997448

Epoch: 6| Step: 8
Training loss: 0.43812681322906155
Validation loss: 2.9549831216268787

Epoch: 6| Step: 9
Training loss: 0.5994767778637904
Validation loss: 2.8704120406221842

Epoch: 6| Step: 10
Training loss: 0.40588355042873625
Validation loss: 2.9010051996665975

Epoch: 6| Step: 11
Training loss: 0.4397716639312997
Validation loss: 2.926846957363261

Epoch: 6| Step: 12
Training loss: 0.48099656305651517
Validation loss: 2.922657567723873

Epoch: 6| Step: 13
Training loss: 0.7323485477616722
Validation loss: 2.8858919865369126

Epoch: 314| Step: 0
Training loss: 0.4207610151579573
Validation loss: 2.8900253636216244

Epoch: 6| Step: 1
Training loss: 0.47643752100860776
Validation loss: 2.9434424685819573

Epoch: 6| Step: 2
Training loss: 0.38355265317587756
Validation loss: 2.8865710036994408

Epoch: 6| Step: 3
Training loss: 0.4871511886503089
Validation loss: 2.963403552188526

Epoch: 6| Step: 4
Training loss: 0.4656540355974044
Validation loss: 2.9857033640917505

Epoch: 6| Step: 5
Training loss: 0.42988124294245783
Validation loss: 2.846579817017322

Epoch: 6| Step: 6
Training loss: 0.4592374063591457
Validation loss: 2.821368434551392

Epoch: 6| Step: 7
Training loss: 0.39301567934999143
Validation loss: 2.856749533078613

Epoch: 6| Step: 8
Training loss: 0.420541457031998
Validation loss: 2.890983765479008

Epoch: 6| Step: 9
Training loss: 0.40594555377679564
Validation loss: 2.931418908410101

Epoch: 6| Step: 10
Training loss: 0.6403555419664186
Validation loss: 2.833260343583862

Epoch: 6| Step: 11
Training loss: 1.2599822575213089
Validation loss: 2.831144922929721

Epoch: 6| Step: 12
Training loss: 0.45425159888020245
Validation loss: 2.929854921431502

Epoch: 6| Step: 13
Training loss: 0.5371808923444746
Validation loss: 2.9038267663712367

Epoch: 315| Step: 0
Training loss: 0.5396383775400885
Validation loss: 2.784718126361104

Epoch: 6| Step: 1
Training loss: 0.5374063399130081
Validation loss: 2.847233088919726

Epoch: 6| Step: 2
Training loss: 0.3218128260034631
Validation loss: 2.9042528872139957

Epoch: 6| Step: 3
Training loss: 0.4859036657691658
Validation loss: 2.9100737353068724

Epoch: 6| Step: 4
Training loss: 0.481365514490919
Validation loss: 2.9001635735518323

Epoch: 6| Step: 5
Training loss: 0.4643580680317137
Validation loss: 2.909542863963077

Epoch: 6| Step: 6
Training loss: 0.42502451503396826
Validation loss: 2.931068766182579

Epoch: 6| Step: 7
Training loss: 0.5177815163642935
Validation loss: 3.022019887696758

Epoch: 6| Step: 8
Training loss: 0.36226616832041686
Validation loss: 2.997368864086708

Epoch: 6| Step: 9
Training loss: 0.5245274824246348
Validation loss: 2.971763286235791

Epoch: 6| Step: 10
Training loss: 1.0364084982592419
Validation loss: 2.9068152995633825

Epoch: 6| Step: 11
Training loss: 0.7479477062177674
Validation loss: 2.8627526461898536

Epoch: 6| Step: 12
Training loss: 0.3024721425013311
Validation loss: 2.905352108528683

Epoch: 6| Step: 13
Training loss: 0.5434291726209751
Validation loss: 2.922306266957237

Epoch: 316| Step: 0
Training loss: 0.3512769387052473
Validation loss: 2.9445628216377537

Epoch: 6| Step: 1
Training loss: 1.1076316029393054
Validation loss: 2.9585312566678597

Epoch: 6| Step: 2
Training loss: 0.3294732007501526
Validation loss: 2.8945616438656026

Epoch: 6| Step: 3
Training loss: 0.37711477025678974
Validation loss: 2.82644616135898

Epoch: 6| Step: 4
Training loss: 0.5922213250316045
Validation loss: 3.005233676391439

Epoch: 6| Step: 5
Training loss: 0.8030095800443513
Validation loss: 2.93551498331465

Epoch: 6| Step: 6
Training loss: 0.57874643588359
Validation loss: 2.883636763396664

Epoch: 6| Step: 7
Training loss: 0.4264207639422197
Validation loss: 2.9521958976898866

Epoch: 6| Step: 8
Training loss: 0.40232460198624204
Validation loss: 2.9858067325347917

Epoch: 6| Step: 9
Training loss: 0.44694869294125344
Validation loss: 2.9055805734230398

Epoch: 6| Step: 10
Training loss: 0.49539986089697535
Validation loss: 2.859651354166424

Epoch: 6| Step: 11
Training loss: 0.5694146077421103
Validation loss: 2.8745025190531575

Epoch: 6| Step: 12
Training loss: 0.6011556265000304
Validation loss: 2.8754610438327295

Epoch: 6| Step: 13
Training loss: 0.3175250512287581
Validation loss: 2.8743322813328605

Epoch: 317| Step: 0
Training loss: 0.6158548284331603
Validation loss: 2.8875625265048015

Epoch: 6| Step: 1
Training loss: 0.45219421155017886
Validation loss: 2.9719207027436316

Epoch: 6| Step: 2
Training loss: 0.6450919746648361
Validation loss: 3.0211684578226854

Epoch: 6| Step: 3
Training loss: 0.42832689745529545
Validation loss: 2.9683471941816193

Epoch: 6| Step: 4
Training loss: 0.7131735044494646
Validation loss: 2.926675833757971

Epoch: 6| Step: 5
Training loss: 0.7757001974707762
Validation loss: 2.938930406699826

Epoch: 6| Step: 6
Training loss: 0.49613540955087476
Validation loss: 2.889641046165441

Epoch: 6| Step: 7
Training loss: 0.5019742612433487
Validation loss: 2.987292868856957

Epoch: 6| Step: 8
Training loss: 0.3601196700777201
Validation loss: 2.8901904698846432

Epoch: 6| Step: 9
Training loss: 0.418034076042059
Validation loss: 2.8445624005013257

Epoch: 6| Step: 10
Training loss: 0.5781743827554926
Validation loss: 2.9349713771319026

Epoch: 6| Step: 11
Training loss: 0.36365731575870275
Validation loss: 2.9643428012386854

Epoch: 6| Step: 12
Training loss: 0.9407704845978916
Validation loss: 2.885333853037018

Epoch: 6| Step: 13
Training loss: 0.324620400251866
Validation loss: 2.8642547326472956

Epoch: 318| Step: 0
Training loss: 0.386667248157497
Validation loss: 2.8531935812767006

Epoch: 6| Step: 1
Training loss: 1.0023305676515881
Validation loss: 2.8392756548460842

Epoch: 6| Step: 2
Training loss: 0.556203141542607
Validation loss: 2.863592986952209

Epoch: 6| Step: 3
Training loss: 0.7664573971230327
Validation loss: 2.947637690810839

Epoch: 6| Step: 4
Training loss: 0.39470117516585523
Validation loss: 2.9105565830495963

Epoch: 6| Step: 5
Training loss: 0.4775842750536482
Validation loss: 2.896562008922334

Epoch: 6| Step: 6
Training loss: 0.3875277755380988
Validation loss: 2.7861999582069896

Epoch: 6| Step: 7
Training loss: 0.4910221533390654
Validation loss: 2.919387629018941

Epoch: 6| Step: 8
Training loss: 0.48784448544453723
Validation loss: 2.8902200363634605

Epoch: 6| Step: 9
Training loss: 0.4035135688249282
Validation loss: 2.821078209740455

Epoch: 6| Step: 10
Training loss: 0.5274989712058787
Validation loss: 2.7839573602251964

Epoch: 6| Step: 11
Training loss: 0.4569526017815889
Validation loss: 2.8779132843844555

Epoch: 6| Step: 12
Training loss: 0.5449123586828662
Validation loss: 2.950626682269433

Epoch: 6| Step: 13
Training loss: 0.5507444815841894
Validation loss: 2.9476357900214603

Epoch: 319| Step: 0
Training loss: 0.5756717386230294
Validation loss: 2.884379442624149

Epoch: 6| Step: 1
Training loss: 0.4378693928535157
Validation loss: 2.946124409310629

Epoch: 6| Step: 2
Training loss: 0.5831205939466827
Validation loss: 2.8682773746512025

Epoch: 6| Step: 3
Training loss: 0.44440280285439804
Validation loss: 2.8881325156950517

Epoch: 6| Step: 4
Training loss: 0.3367050849637641
Validation loss: 2.9293166404810487

Epoch: 6| Step: 5
Training loss: 0.4966841811120472
Validation loss: 2.8976619947699986

Epoch: 6| Step: 6
Training loss: 0.768807395095071
Validation loss: 2.901657879147999

Epoch: 6| Step: 7
Training loss: 0.5901558157889193
Validation loss: 2.879607585778542

Epoch: 6| Step: 8
Training loss: 0.94317618856181
Validation loss: 2.9069277748966127

Epoch: 6| Step: 9
Training loss: 0.4018855031540902
Validation loss: 2.8619384809013892

Epoch: 6| Step: 10
Training loss: 0.526132279954511
Validation loss: 2.8155108407178306

Epoch: 6| Step: 11
Training loss: 0.4141339654248513
Validation loss: 2.830941738276101

Epoch: 6| Step: 12
Training loss: 0.4979192832122537
Validation loss: 2.889263155323312

Epoch: 6| Step: 13
Training loss: 0.40898382556663415
Validation loss: 2.8843017563314945

Epoch: 320| Step: 0
Training loss: 0.574907992092072
Validation loss: 2.8716755041900455

Epoch: 6| Step: 1
Training loss: 0.4997455426275442
Validation loss: 2.907829621059788

Epoch: 6| Step: 2
Training loss: 0.9132973818826777
Validation loss: 2.8741501782273295

Epoch: 6| Step: 3
Training loss: 0.5147801616108136
Validation loss: 2.895919954024417

Epoch: 6| Step: 4
Training loss: 0.5033721458973667
Validation loss: 2.8160050768228486

Epoch: 6| Step: 5
Training loss: 0.7645303725177743
Validation loss: 2.821068152641936

Epoch: 6| Step: 6
Training loss: 0.6644316376581865
Validation loss: 2.9021438933710737

Epoch: 6| Step: 7
Training loss: 0.6813284260115228
Validation loss: 2.905751462446191

Epoch: 6| Step: 8
Training loss: 0.3725916696567331
Validation loss: 2.9793042949195496

Epoch: 6| Step: 9
Training loss: 0.43452695137320124
Validation loss: 2.93987555525923

Epoch: 6| Step: 10
Training loss: 0.6105404492880282
Validation loss: 2.9136203092877477

Epoch: 6| Step: 11
Training loss: 0.5646688187785986
Validation loss: 2.9651423569031303

Epoch: 6| Step: 12
Training loss: 0.30419525094911815
Validation loss: 2.9849231875582944

Epoch: 6| Step: 13
Training loss: 0.44447713432029157
Validation loss: 3.040999082350036

Epoch: 321| Step: 0
Training loss: 0.4061673520455091
Validation loss: 2.9893349179901167

Epoch: 6| Step: 1
Training loss: 0.38861382592481275
Validation loss: 2.9391283432492057

Epoch: 6| Step: 2
Training loss: 0.3693368985361782
Validation loss: 2.820079184450761

Epoch: 6| Step: 3
Training loss: 0.3317902195035947
Validation loss: 2.8570882689847052

Epoch: 6| Step: 4
Training loss: 0.42516655252991725
Validation loss: 2.9236993517110053

Epoch: 6| Step: 5
Training loss: 0.6419308309593965
Validation loss: 2.860446874945696

Epoch: 6| Step: 6
Training loss: 0.5135393443129247
Validation loss: 2.733910730093773

Epoch: 6| Step: 7
Training loss: 0.41575356409560343
Validation loss: 2.9592917908971508

Epoch: 6| Step: 8
Training loss: 0.4763712890248232
Validation loss: 2.859485825577933

Epoch: 6| Step: 9
Training loss: 0.4053667443652555
Validation loss: 2.857501891261532

Epoch: 6| Step: 10
Training loss: 0.40549319640095227
Validation loss: 2.842623868428036

Epoch: 6| Step: 11
Training loss: 0.6208780501943353
Validation loss: 2.9406940599386617

Epoch: 6| Step: 12
Training loss: 0.396574414181729
Validation loss: 2.9321206665770294

Epoch: 6| Step: 13
Training loss: 1.0586070380133492
Validation loss: 2.858055185365817

Epoch: 322| Step: 0
Training loss: 0.2126498829759446
Validation loss: 2.8267485920561897

Epoch: 6| Step: 1
Training loss: 0.4546632963470003
Validation loss: 2.840325763693947

Epoch: 6| Step: 2
Training loss: 0.4153996236564353
Validation loss: 2.9467578582835814

Epoch: 6| Step: 3
Training loss: 0.9754249355895038
Validation loss: 2.905170212736408

Epoch: 6| Step: 4
Training loss: 0.4859749304286613
Validation loss: 2.9230396581119984

Epoch: 6| Step: 5
Training loss: 0.607490363966888
Validation loss: 2.895551727287837

Epoch: 6| Step: 6
Training loss: 0.5294522553586354
Validation loss: 2.894651210562519

Epoch: 6| Step: 7
Training loss: 0.6178726787133807
Validation loss: 2.960524061287659

Epoch: 6| Step: 8
Training loss: 0.5503451196554824
Validation loss: 2.913637800179802

Epoch: 6| Step: 9
Training loss: 0.5322307341525874
Validation loss: 2.8563411404560153

Epoch: 6| Step: 10
Training loss: 0.4976503776072071
Validation loss: 2.8926663862865505

Epoch: 6| Step: 11
Training loss: 0.45373848787526666
Validation loss: 2.8397007713372977

Epoch: 6| Step: 12
Training loss: 0.32138497216797063
Validation loss: 2.845828878940058

Epoch: 6| Step: 13
Training loss: 0.6272055334702236
Validation loss: 2.8905516744025452

Epoch: 323| Step: 0
Training loss: 0.28168943302328375
Validation loss: 2.8996293187285285

Epoch: 6| Step: 1
Training loss: 0.9028255613021958
Validation loss: 2.885898664592179

Epoch: 6| Step: 2
Training loss: 0.500773308701416
Validation loss: 2.8732913924812378

Epoch: 6| Step: 3
Training loss: 0.6838379777869456
Validation loss: 2.9254991491291844

Epoch: 6| Step: 4
Training loss: 0.6435195149142843
Validation loss: 2.932216261621992

Epoch: 6| Step: 5
Training loss: 0.5070549816814119
Validation loss: 2.9450803036149633

Epoch: 6| Step: 6
Training loss: 0.5020420277753813
Validation loss: 2.8680196138417995

Epoch: 6| Step: 7
Training loss: 0.7044914954181822
Validation loss: 2.856139487390003

Epoch: 6| Step: 8
Training loss: 0.3712269192723266
Validation loss: 2.9738118569310648

Epoch: 6| Step: 9
Training loss: 0.7008373556993095
Validation loss: 2.9731531651042045

Epoch: 6| Step: 10
Training loss: 0.43413039668556985
Validation loss: 2.8696973523232496

Epoch: 6| Step: 11
Training loss: 0.6940269158115632
Validation loss: 2.8776833547798115

Epoch: 6| Step: 12
Training loss: 0.44793003823777333
Validation loss: 2.9899919919530826

Epoch: 6| Step: 13
Training loss: 0.4745853559279553
Validation loss: 2.9676993133704204

Epoch: 324| Step: 0
Training loss: 0.5448893328831775
Validation loss: 2.9559073283854294

Epoch: 6| Step: 1
Training loss: 0.44570537436182645
Validation loss: 2.978313048097437

Epoch: 6| Step: 2
Training loss: 0.5244779920770043
Validation loss: 2.875415841035089

Epoch: 6| Step: 3
Training loss: 0.522396047965475
Validation loss: 2.8943424068870898

Epoch: 6| Step: 4
Training loss: 0.5632080813647664
Validation loss: 2.8867382140099194

Epoch: 6| Step: 5
Training loss: 0.5393828946416571
Validation loss: 2.9295745353112683

Epoch: 6| Step: 6
Training loss: 1.0157580948698863
Validation loss: 2.7934153522097533

Epoch: 6| Step: 7
Training loss: 0.5510522162347615
Validation loss: 2.8932163205049015

Epoch: 6| Step: 8
Training loss: 0.5037911453671349
Validation loss: 2.763955296517889

Epoch: 6| Step: 9
Training loss: 0.5436070484487567
Validation loss: 2.8057915968057228

Epoch: 6| Step: 10
Training loss: 0.44047297499715315
Validation loss: 2.895230681101698

Epoch: 6| Step: 11
Training loss: 0.6929841651621167
Validation loss: 2.810590321742058

Epoch: 6| Step: 12
Training loss: 0.6863132985423666
Validation loss: 2.816952247268601

Epoch: 6| Step: 13
Training loss: 0.7244748713029839
Validation loss: 2.8551638780092996

Epoch: 325| Step: 0
Training loss: 0.5822072627040136
Validation loss: 2.8440660294094275

Epoch: 6| Step: 1
Training loss: 1.0234879342967367
Validation loss: 2.87195200299736

Epoch: 6| Step: 2
Training loss: 0.3868511820904393
Validation loss: 2.8627990066748326

Epoch: 6| Step: 3
Training loss: 0.5532674207362241
Validation loss: 2.904164978056042

Epoch: 6| Step: 4
Training loss: 0.48615178967375694
Validation loss: 2.898744763918884

Epoch: 6| Step: 5
Training loss: 0.5855117777153712
Validation loss: 2.8915484628694292

Epoch: 6| Step: 6
Training loss: 0.5077022432795028
Validation loss: 2.855394953005901

Epoch: 6| Step: 7
Training loss: 0.4724275650532121
Validation loss: 2.9197445070284895

Epoch: 6| Step: 8
Training loss: 0.7467883007851523
Validation loss: 2.9414656499274585

Epoch: 6| Step: 9
Training loss: 0.5404833712865016
Validation loss: 2.965420391714152

Epoch: 6| Step: 10
Training loss: 0.40511773117215805
Validation loss: 2.917195399361696

Epoch: 6| Step: 11
Training loss: 0.3934898228353213
Validation loss: 2.9917080979059554

Epoch: 6| Step: 12
Training loss: 0.286086667867492
Validation loss: 2.9119769040019734

Epoch: 6| Step: 13
Training loss: 0.26862644970708144
Validation loss: 2.955027981349702

Epoch: 326| Step: 0
Training loss: 0.4101361587689899
Validation loss: 2.968830308329899

Epoch: 6| Step: 1
Training loss: 0.4719592227677632
Validation loss: 2.9712741895650425

Epoch: 6| Step: 2
Training loss: 0.30366934095875525
Validation loss: 2.8745490287137927

Epoch: 6| Step: 3
Training loss: 1.0898320460631072
Validation loss: 2.9050062245812756

Epoch: 6| Step: 4
Training loss: 0.6432294935670915
Validation loss: 2.9324890440692566

Epoch: 6| Step: 5
Training loss: 0.3964591746472513
Validation loss: 2.9603925889655933

Epoch: 6| Step: 6
Training loss: 0.3518949632080394
Validation loss: 2.8789986846177054

Epoch: 6| Step: 7
Training loss: 0.5563323388611713
Validation loss: 2.9594466617317248

Epoch: 6| Step: 8
Training loss: 0.4332694309904845
Validation loss: 2.9490818556115066

Epoch: 6| Step: 9
Training loss: 0.3329291936075606
Validation loss: 2.8845168591652066

Epoch: 6| Step: 10
Training loss: 0.3662677771644736
Validation loss: 2.9359172858922356

Epoch: 6| Step: 11
Training loss: 0.4829547888454293
Validation loss: 2.8900707641438528

Epoch: 6| Step: 12
Training loss: 0.35264651280432313
Validation loss: 2.8826114132985285

Epoch: 6| Step: 13
Training loss: 0.41226509731794614
Validation loss: 2.83423156151022

Epoch: 327| Step: 0
Training loss: 1.055990586787953
Validation loss: 2.8740655444671983

Epoch: 6| Step: 1
Training loss: 0.37987077002572484
Validation loss: 2.8482568540921185

Epoch: 6| Step: 2
Training loss: 0.3074975038248798
Validation loss: 2.945728559307913

Epoch: 6| Step: 3
Training loss: 0.4505597540594068
Validation loss: 2.873117646141618

Epoch: 6| Step: 4
Training loss: 0.48424860628052546
Validation loss: 2.899230389309114

Epoch: 6| Step: 5
Training loss: 0.40896464230099633
Validation loss: 2.9272515236170795

Epoch: 6| Step: 6
Training loss: 0.46471088979072556
Validation loss: 2.9132029311357464

Epoch: 6| Step: 7
Training loss: 0.6990785511477922
Validation loss: 2.7932845499548007

Epoch: 6| Step: 8
Training loss: 0.5295177435256933
Validation loss: 2.9880949606413143

Epoch: 6| Step: 9
Training loss: 0.517696208799089
Validation loss: 2.85165757669605

Epoch: 6| Step: 10
Training loss: 0.36138674286322364
Validation loss: 2.879708525535533

Epoch: 6| Step: 11
Training loss: 0.47282589476799286
Validation loss: 2.896976839790472

Epoch: 6| Step: 12
Training loss: 0.4264998016110995
Validation loss: 2.832114032105486

Epoch: 6| Step: 13
Training loss: 0.4742711121560907
Validation loss: 2.9574248078462335

Epoch: 328| Step: 0
Training loss: 0.3281391912752059
Validation loss: 2.942583541699708

Epoch: 6| Step: 1
Training loss: 0.3518546268263545
Validation loss: 2.977451381975052

Epoch: 6| Step: 2
Training loss: 0.47876351611328183
Validation loss: 2.986064119979602

Epoch: 6| Step: 3
Training loss: 0.46946680575627575
Validation loss: 2.861039544005692

Epoch: 6| Step: 4
Training loss: 0.9517803400052043
Validation loss: 2.9447272922607484

Epoch: 6| Step: 5
Training loss: 0.43547745224080314
Validation loss: 2.8469871429119102

Epoch: 6| Step: 6
Training loss: 0.49248489598771605
Validation loss: 2.8904705659319774

Epoch: 6| Step: 7
Training loss: 0.676937943523305
Validation loss: 2.928218938025681

Epoch: 6| Step: 8
Training loss: 0.3584666589984062
Validation loss: 2.8934802276338307

Epoch: 6| Step: 9
Training loss: 0.40063751796262836
Validation loss: 2.849626136261606

Epoch: 6| Step: 10
Training loss: 0.5219997188450433
Validation loss: 2.8823070823956614

Epoch: 6| Step: 11
Training loss: 0.48427630003416466
Validation loss: 2.882057359824824

Epoch: 6| Step: 12
Training loss: 0.4875287475423907
Validation loss: 2.9726647515996203

Epoch: 6| Step: 13
Training loss: 0.4847436394266793
Validation loss: 2.9089958727866234

Epoch: 329| Step: 0
Training loss: 0.2761574613271135
Validation loss: 2.9129794292393676

Epoch: 6| Step: 1
Training loss: 0.5496847994305936
Validation loss: 2.943221627538923

Epoch: 6| Step: 2
Training loss: 0.4404486675359651
Validation loss: 2.9656779138140914

Epoch: 6| Step: 3
Training loss: 0.6164965564634706
Validation loss: 2.9508525440833564

Epoch: 6| Step: 4
Training loss: 0.9827370716254789
Validation loss: 2.8562820744400397

Epoch: 6| Step: 5
Training loss: 0.36199823050303587
Validation loss: 2.949076701737032

Epoch: 6| Step: 6
Training loss: 0.5433946763945648
Validation loss: 2.933158412146686

Epoch: 6| Step: 7
Training loss: 0.4277379806575607
Validation loss: 2.9319897366925685

Epoch: 6| Step: 8
Training loss: 0.4877745784313294
Validation loss: 2.8966306142315674

Epoch: 6| Step: 9
Training loss: 0.3856841224716626
Validation loss: 2.9193020948539177

Epoch: 6| Step: 10
Training loss: 0.41150074349912125
Validation loss: 2.927253301896359

Epoch: 6| Step: 11
Training loss: 0.7667863173688344
Validation loss: 2.918580998300396

Epoch: 6| Step: 12
Training loss: 0.4711482369210282
Validation loss: 2.9619638883410078

Epoch: 6| Step: 13
Training loss: 0.47301783011846155
Validation loss: 2.8125702036820077

Epoch: 330| Step: 0
Training loss: 0.4927532184337019
Validation loss: 2.9442591111517613

Epoch: 6| Step: 1
Training loss: 0.5035741732038471
Validation loss: 3.0262835346324555

Epoch: 6| Step: 2
Training loss: 0.5419498186476638
Validation loss: 2.930134934908396

Epoch: 6| Step: 3
Training loss: 0.6702198444698488
Validation loss: 2.8954310423616327

Epoch: 6| Step: 4
Training loss: 0.48615464023186994
Validation loss: 2.873941268031432

Epoch: 6| Step: 5
Training loss: 0.356889860341519
Validation loss: 2.8718990796739696

Epoch: 6| Step: 6
Training loss: 0.9667569238904559
Validation loss: 2.946725804748133

Epoch: 6| Step: 7
Training loss: 0.5202323943554557
Validation loss: 2.883936386401501

Epoch: 6| Step: 8
Training loss: 0.526957730894553
Validation loss: 2.895952830604916

Epoch: 6| Step: 9
Training loss: 0.40827736795406894
Validation loss: 2.9325397221660108

Epoch: 6| Step: 10
Training loss: 0.40458878745590976
Validation loss: 2.871322837219055

Epoch: 6| Step: 11
Training loss: 0.4855366743371199
Validation loss: 2.8853512812802182

Epoch: 6| Step: 12
Training loss: 0.37745451318405276
Validation loss: 2.9676644197595667

Epoch: 6| Step: 13
Training loss: 0.5636602991386643
Validation loss: 2.8888100983703855

Epoch: 331| Step: 0
Training loss: 0.4147680497291725
Validation loss: 2.845804764663333

Epoch: 6| Step: 1
Training loss: 0.46271041388160555
Validation loss: 2.8945700453656458

Epoch: 6| Step: 2
Training loss: 0.5434216593209948
Validation loss: 2.8431075771309757

Epoch: 6| Step: 3
Training loss: 0.9357913022497442
Validation loss: 2.8940695781845696

Epoch: 6| Step: 4
Training loss: 0.6175584764630382
Validation loss: 2.8678523651840626

Epoch: 6| Step: 5
Training loss: 0.30736630820961663
Validation loss: 2.8618401079118962

Epoch: 6| Step: 6
Training loss: 0.6409805288243828
Validation loss: 2.8665537675168458

Epoch: 6| Step: 7
Training loss: 0.42705705220686246
Validation loss: 2.8746531456957856

Epoch: 6| Step: 8
Training loss: 0.3505667040976274
Validation loss: 2.8237915278726464

Epoch: 6| Step: 9
Training loss: 0.4265021948752325
Validation loss: 2.870356527816956

Epoch: 6| Step: 10
Training loss: 0.3743608113499395
Validation loss: 2.92582532835057

Epoch: 6| Step: 11
Training loss: 0.6037981180796653
Validation loss: 2.9224824596930503

Epoch: 6| Step: 12
Training loss: 0.420661806647272
Validation loss: 3.0011492223421365

Epoch: 6| Step: 13
Training loss: 0.307784492167294
Validation loss: 2.9637042483141296

Epoch: 332| Step: 0
Training loss: 0.38001752881980577
Validation loss: 2.920398196151421

Epoch: 6| Step: 1
Training loss: 0.37761590435156933
Validation loss: 2.853407143844368

Epoch: 6| Step: 2
Training loss: 0.3966014858228117
Validation loss: 2.9504666077944215

Epoch: 6| Step: 3
Training loss: 0.37521852642887277
Validation loss: 2.934926332700586

Epoch: 6| Step: 4
Training loss: 0.41699023994509155
Validation loss: 2.915600286544616

Epoch: 6| Step: 5
Training loss: 0.4772416263103487
Validation loss: 2.8130884897060286

Epoch: 6| Step: 6
Training loss: 0.3825004434583001
Validation loss: 2.927919429048323

Epoch: 6| Step: 7
Training loss: 0.28599757360799605
Validation loss: 2.8717210149317616

Epoch: 6| Step: 8
Training loss: 0.36142989091616157
Validation loss: 2.8828958363190993

Epoch: 6| Step: 9
Training loss: 0.88037007818941
Validation loss: 2.9376643249867134

Epoch: 6| Step: 10
Training loss: 0.6699227647247189
Validation loss: 2.926865577516955

Epoch: 6| Step: 11
Training loss: 0.5795455954291433
Validation loss: 2.897219776539813

Epoch: 6| Step: 12
Training loss: 0.5350588967534277
Validation loss: 2.870971317232576

Epoch: 6| Step: 13
Training loss: 0.4319522130042039
Validation loss: 2.9505335826323367

Epoch: 333| Step: 0
Training loss: 0.5362656503452121
Validation loss: 2.8800994043061237

Epoch: 6| Step: 1
Training loss: 0.4522547092329628
Validation loss: 2.84858076719129

Epoch: 6| Step: 2
Training loss: 0.43715015115505146
Validation loss: 2.8872843021895553

Epoch: 6| Step: 3
Training loss: 0.37955170153453927
Validation loss: 2.8820687207207305

Epoch: 6| Step: 4
Training loss: 0.3516994209689357
Validation loss: 2.874135205222109

Epoch: 6| Step: 5
Training loss: 0.4287080525711766
Validation loss: 2.8713729826413723

Epoch: 6| Step: 6
Training loss: 1.0366793385699173
Validation loss: 2.845650509444091

Epoch: 6| Step: 7
Training loss: 0.6132159836172155
Validation loss: 2.9815973000927283

Epoch: 6| Step: 8
Training loss: 0.33924704816274764
Validation loss: 2.965586050439035

Epoch: 6| Step: 9
Training loss: 0.39097343163823645
Validation loss: 2.880404547870897

Epoch: 6| Step: 10
Training loss: 0.4035866622213828
Validation loss: 2.9468910850606407

Epoch: 6| Step: 11
Training loss: 0.435824421262097
Validation loss: 2.9655851660928327

Epoch: 6| Step: 12
Training loss: 0.4001988579745205
Validation loss: 2.893414774977586

Epoch: 6| Step: 13
Training loss: 0.45989589676761156
Validation loss: 2.919556219538427

Epoch: 334| Step: 0
Training loss: 0.4035686993476512
Validation loss: 2.879214611473152

Epoch: 6| Step: 1
Training loss: 0.524930106914757
Validation loss: 2.868592447291358

Epoch: 6| Step: 2
Training loss: 0.3886576127545779
Validation loss: 2.852430307382232

Epoch: 6| Step: 3
Training loss: 0.5891481301882198
Validation loss: 2.9903008312213344

Epoch: 6| Step: 4
Training loss: 0.30864601658379975
Validation loss: 2.8666172413298554

Epoch: 6| Step: 5
Training loss: 0.40935998554214054
Validation loss: 2.8761741755953536

Epoch: 6| Step: 6
Training loss: 0.46372247948436357
Validation loss: 2.935462393764375

Epoch: 6| Step: 7
Training loss: 0.32971702100011036
Validation loss: 2.9180545683620096

Epoch: 6| Step: 8
Training loss: 0.3648626506410557
Validation loss: 2.897512516239354

Epoch: 6| Step: 9
Training loss: 0.7265070412091776
Validation loss: 2.9383768031135498

Epoch: 6| Step: 10
Training loss: 0.9088056637009917
Validation loss: 2.9453218900090703

Epoch: 6| Step: 11
Training loss: 0.4191065480226102
Validation loss: 2.931187373768621

Epoch: 6| Step: 12
Training loss: 0.46883067390500377
Validation loss: 2.8629781121063402

Epoch: 6| Step: 13
Training loss: 0.5065262276372656
Validation loss: 2.842102090322262

Epoch: 335| Step: 0
Training loss: 0.6442181607062591
Validation loss: 2.9319687976686106

Epoch: 6| Step: 1
Training loss: 0.38245904915200957
Validation loss: 2.9114480516028105

Epoch: 6| Step: 2
Training loss: 0.8491104239374196
Validation loss: 2.9235981230901595

Epoch: 6| Step: 3
Training loss: 0.4777110751467496
Validation loss: 2.8659752302064407

Epoch: 6| Step: 4
Training loss: 0.6323102912694579
Validation loss: 2.969838903063281

Epoch: 6| Step: 5
Training loss: 0.4928875591807325
Validation loss: 2.880341046789797

Epoch: 6| Step: 6
Training loss: 0.45722983194947847
Validation loss: 2.9320607859554237

Epoch: 6| Step: 7
Training loss: 0.44762982195590195
Validation loss: 3.0079191246785366

Epoch: 6| Step: 8
Training loss: 0.4205789437664254
Validation loss: 2.8812351615341623

Epoch: 6| Step: 9
Training loss: 0.4351860399168307
Validation loss: 2.960317877334344

Epoch: 6| Step: 10
Training loss: 0.4730189326985351
Validation loss: 2.919277144648422

Epoch: 6| Step: 11
Training loss: 0.5587620514971725
Validation loss: 2.907213003656379

Epoch: 6| Step: 12
Training loss: 0.3890024054509297
Validation loss: 2.8737735896769125

Epoch: 6| Step: 13
Training loss: 0.46416693388944336
Validation loss: 2.8363351534348458

Epoch: 336| Step: 0
Training loss: 0.3035374971067179
Validation loss: 2.8972295692946446

Epoch: 6| Step: 1
Training loss: 0.5048115014012869
Validation loss: 2.905773971566826

Epoch: 6| Step: 2
Training loss: 0.5009215029079674
Validation loss: 2.867110110147094

Epoch: 6| Step: 3
Training loss: 0.2898453344831317
Validation loss: 2.923087264665593

Epoch: 6| Step: 4
Training loss: 0.36516664254347914
Validation loss: 2.9639622144637263

Epoch: 6| Step: 5
Training loss: 0.4348770773339937
Validation loss: 2.9183715378900104

Epoch: 6| Step: 6
Training loss: 0.4171798069562501
Validation loss: 2.887138711254429

Epoch: 6| Step: 7
Training loss: 1.0966988185664375
Validation loss: 2.92652929001713

Epoch: 6| Step: 8
Training loss: 0.40836486167571606
Validation loss: 2.9325348847491295

Epoch: 6| Step: 9
Training loss: 0.4586718530123729
Validation loss: 2.8930799352487817

Epoch: 6| Step: 10
Training loss: 0.3971845335890883
Validation loss: 2.9162090941676606

Epoch: 6| Step: 11
Training loss: 0.3165649557630327
Validation loss: 2.86399121262536

Epoch: 6| Step: 12
Training loss: 0.4327259658902753
Validation loss: 2.9818119007375374

Epoch: 6| Step: 13
Training loss: 0.37121726540381744
Validation loss: 2.9140457957371084

Epoch: 337| Step: 0
Training loss: 0.3571488009537232
Validation loss: 2.8772874384546943

Epoch: 6| Step: 1
Training loss: 1.043907685846267
Validation loss: 2.8747480116168096

Epoch: 6| Step: 2
Training loss: 0.33998731891040024
Validation loss: 2.8809372782545926

Epoch: 6| Step: 3
Training loss: 0.40297869237768563
Validation loss: 2.891541042035945

Epoch: 6| Step: 4
Training loss: 0.43529273859807793
Validation loss: 2.9513607103585824

Epoch: 6| Step: 5
Training loss: 0.4556779959878761
Validation loss: 2.9179097841595545

Epoch: 6| Step: 6
Training loss: 0.6165036626120717
Validation loss: 2.8920838257577097

Epoch: 6| Step: 7
Training loss: 0.293802803447571
Validation loss: 2.8696363699007144

Epoch: 6| Step: 8
Training loss: 0.38623044945949503
Validation loss: 2.860248147474023

Epoch: 6| Step: 9
Training loss: 0.5065192554425085
Validation loss: 2.956461399254105

Epoch: 6| Step: 10
Training loss: 0.5469669264779509
Validation loss: 2.8220960590325888

Epoch: 6| Step: 11
Training loss: 0.4699666129590685
Validation loss: 2.8535290212314597

Epoch: 6| Step: 12
Training loss: 0.3132369649889138
Validation loss: 2.960741209369753

Epoch: 6| Step: 13
Training loss: 0.41989323717982024
Validation loss: 2.8993806221407157

Epoch: 338| Step: 0
Training loss: 0.3830749624039073
Validation loss: 2.951608554419529

Epoch: 6| Step: 1
Training loss: 0.4397646160320852
Validation loss: 2.8567460695698537

Epoch: 6| Step: 2
Training loss: 0.6126028305460329
Validation loss: 2.8381794456328504

Epoch: 6| Step: 3
Training loss: 0.44379763011789564
Validation loss: 2.9107859226853923

Epoch: 6| Step: 4
Training loss: 0.3700628316214515
Validation loss: 2.9210473722721346

Epoch: 6| Step: 5
Training loss: 0.37412200903724546
Validation loss: 2.903088603700071

Epoch: 6| Step: 6
Training loss: 0.5279832706221422
Validation loss: 2.88525638525342

Epoch: 6| Step: 7
Training loss: 0.40530202374121305
Validation loss: 2.956630583897395

Epoch: 6| Step: 8
Training loss: 0.8934394136710552
Validation loss: 2.903302177768617

Epoch: 6| Step: 9
Training loss: 0.3789502934292791
Validation loss: 2.9092980265038237

Epoch: 6| Step: 10
Training loss: 0.3724595684472434
Validation loss: 2.949589612939491

Epoch: 6| Step: 11
Training loss: 0.5074576678731217
Validation loss: 2.928502527283719

Epoch: 6| Step: 12
Training loss: 0.3203203386417608
Validation loss: 2.851506648104572

Epoch: 6| Step: 13
Training loss: 0.6930936707208891
Validation loss: 2.8865162972437806

Epoch: 339| Step: 0
Training loss: 0.4037334183042677
Validation loss: 2.905959665159437

Epoch: 6| Step: 1
Training loss: 0.4017841187702773
Validation loss: 2.8845800203617227

Epoch: 6| Step: 2
Training loss: 0.8156005314923922
Validation loss: 2.95212657809748

Epoch: 6| Step: 3
Training loss: 0.41714981994771333
Validation loss: 2.876365309792129

Epoch: 6| Step: 4
Training loss: 0.33919313788310534
Validation loss: 2.905350699799856

Epoch: 6| Step: 5
Training loss: 0.45978124716769164
Validation loss: 2.9502793314524958

Epoch: 6| Step: 6
Training loss: 0.4619694489063033
Validation loss: 2.877293756696123

Epoch: 6| Step: 7
Training loss: 0.39351396373635167
Validation loss: 2.8911927705194995

Epoch: 6| Step: 8
Training loss: 0.5786247928295147
Validation loss: 2.9313760189467635

Epoch: 6| Step: 9
Training loss: 0.288685178643734
Validation loss: 2.943459789012047

Epoch: 6| Step: 10
Training loss: 0.49967169413996776
Validation loss: 2.9500548266041253

Epoch: 6| Step: 11
Training loss: 0.41427603199994684
Validation loss: 2.9068373630066255

Epoch: 6| Step: 12
Training loss: 0.3544908633877324
Validation loss: 2.949994360384965

Epoch: 6| Step: 13
Training loss: 0.7233624693353943
Validation loss: 2.9338604856170556

Epoch: 340| Step: 0
Training loss: 0.33559410153665487
Validation loss: 2.939065096940376

Epoch: 6| Step: 1
Training loss: 0.8786831042682227
Validation loss: 2.9510110558402154

Epoch: 6| Step: 2
Training loss: 0.5005769976629914
Validation loss: 2.8957277502850567

Epoch: 6| Step: 3
Training loss: 0.4666309780143611
Validation loss: 2.975551844152096

Epoch: 6| Step: 4
Training loss: 0.3918284760012779
Validation loss: 2.9187363411191014

Epoch: 6| Step: 5
Training loss: 0.3990503907961617
Validation loss: 2.9007619224101027

Epoch: 6| Step: 6
Training loss: 0.6741909211428152
Validation loss: 2.886389948074864

Epoch: 6| Step: 7
Training loss: 0.6506917903452017
Validation loss: 2.8965059615274193

Epoch: 6| Step: 8
Training loss: 0.27914328453490306
Validation loss: 2.9321700094043477

Epoch: 6| Step: 9
Training loss: 0.5215631204079149
Validation loss: 2.909916742014265

Epoch: 6| Step: 10
Training loss: 0.5036451565232672
Validation loss: 2.9545022218826813

Epoch: 6| Step: 11
Training loss: 0.35323036655809825
Validation loss: 2.870758445346175

Epoch: 6| Step: 12
Training loss: 0.4327393783332431
Validation loss: 2.972620198135216

Epoch: 6| Step: 13
Training loss: 0.42014439918996
Validation loss: 2.983960680470743

Epoch: 341| Step: 0
Training loss: 0.35787763877212925
Validation loss: 2.840057008231558

Epoch: 6| Step: 1
Training loss: 0.3084221495583604
Validation loss: 3.0389084699311

Epoch: 6| Step: 2
Training loss: 0.4855519117246022
Validation loss: 3.005964680942836

Epoch: 6| Step: 3
Training loss: 0.3940929962506723
Validation loss: 2.9591125259094597

Epoch: 6| Step: 4
Training loss: 0.475547491317307
Validation loss: 2.943027746819178

Epoch: 6| Step: 5
Training loss: 0.47813359795113786
Validation loss: 2.9423278134963615

Epoch: 6| Step: 6
Training loss: 0.7214753683753824
Validation loss: 2.873413408326047

Epoch: 6| Step: 7
Training loss: 0.4312752260210744
Validation loss: 2.9206484023651216

Epoch: 6| Step: 8
Training loss: 0.7911313196039238
Validation loss: 2.922423965644121

Epoch: 6| Step: 9
Training loss: 0.5719081556370672
Validation loss: 2.916101841504762

Epoch: 6| Step: 10
Training loss: 0.468203002939856
Validation loss: 2.9062011878723863

Epoch: 6| Step: 11
Training loss: 0.3020985972176504
Validation loss: 2.9184592505856055

Epoch: 6| Step: 12
Training loss: 0.6184502733018882
Validation loss: 2.918372681630418

Epoch: 6| Step: 13
Training loss: 0.4229913176655547
Validation loss: 2.951978760408133

Epoch: 342| Step: 0
Training loss: 0.3985943018222699
Validation loss: 2.9783124743945995

Epoch: 6| Step: 1
Training loss: 0.5128827433623335
Validation loss: 2.8883922992710533

Epoch: 6| Step: 2
Training loss: 0.48026607859939735
Validation loss: 2.8468080852641

Epoch: 6| Step: 3
Training loss: 0.42779157421576364
Validation loss: 2.899404660864192

Epoch: 6| Step: 4
Training loss: 0.54499742537949
Validation loss: 2.8822608840414383

Epoch: 6| Step: 5
Training loss: 0.9347182010364492
Validation loss: 2.940542552736751

Epoch: 6| Step: 6
Training loss: 0.6909793678203885
Validation loss: 2.919122034795797

Epoch: 6| Step: 7
Training loss: 0.27235898807461606
Validation loss: 2.8920800473314934

Epoch: 6| Step: 8
Training loss: 0.40456267386953837
Validation loss: 2.875835891504365

Epoch: 6| Step: 9
Training loss: 0.38168909707991583
Validation loss: 2.943252369151243

Epoch: 6| Step: 10
Training loss: 0.41565240755277594
Validation loss: 2.9230955298020755

Epoch: 6| Step: 11
Training loss: 0.5969198589544035
Validation loss: 2.9077855637259495

Epoch: 6| Step: 12
Training loss: 0.4189902861670923
Validation loss: 2.9706055313522177

Epoch: 6| Step: 13
Training loss: 0.29783441462949345
Validation loss: 2.9208310960297625

Epoch: 343| Step: 0
Training loss: 0.980574127248929
Validation loss: 2.961503805928895

Epoch: 6| Step: 1
Training loss: 0.37357333119112895
Validation loss: 2.9070292149473165

Epoch: 6| Step: 2
Training loss: 0.2582747044227156
Validation loss: 2.8853707751722832

Epoch: 6| Step: 3
Training loss: 0.3877438723807373
Validation loss: 2.842139434268211

Epoch: 6| Step: 4
Training loss: 0.3777925503735409
Validation loss: 2.8407002818501472

Epoch: 6| Step: 5
Training loss: 0.3438182459623099
Validation loss: 2.854201676276977

Epoch: 6| Step: 6
Training loss: 0.4488764246357911
Validation loss: 2.8609492375487067

Epoch: 6| Step: 7
Training loss: 0.361691616845057
Validation loss: 2.919830218761603

Epoch: 6| Step: 8
Training loss: 0.45022437276987687
Validation loss: 2.8915575739778276

Epoch: 6| Step: 9
Training loss: 0.4684168585466011
Validation loss: 2.861877027684299

Epoch: 6| Step: 10
Training loss: 0.3523042694776208
Validation loss: 2.8778833222232922

Epoch: 6| Step: 11
Training loss: 0.5222346305923012
Validation loss: 2.966021351243756

Epoch: 6| Step: 12
Training loss: 0.3693507166850241
Validation loss: 2.917185305850146

Epoch: 6| Step: 13
Training loss: 0.696972569020263
Validation loss: 2.901770246275872

Epoch: 344| Step: 0
Training loss: 0.6253952922086957
Validation loss: 2.900021677922749

Epoch: 6| Step: 1
Training loss: 0.3428311204330419
Validation loss: 2.916204379548305

Epoch: 6| Step: 2
Training loss: 0.4123318871471719
Validation loss: 2.922652238090023

Epoch: 6| Step: 3
Training loss: 0.5077173290569731
Validation loss: 2.976252729128126

Epoch: 6| Step: 4
Training loss: 0.3743846533522644
Validation loss: 2.917975749561063

Epoch: 6| Step: 5
Training loss: 0.5417877911587963
Validation loss: 2.9182563990617543

Epoch: 6| Step: 6
Training loss: 0.8215227917129092
Validation loss: 2.9524936236561126

Epoch: 6| Step: 7
Training loss: 0.31629492131569104
Validation loss: 2.903958706043746

Epoch: 6| Step: 8
Training loss: 0.314643067989554
Validation loss: 2.907428263333869

Epoch: 6| Step: 9
Training loss: 0.45082868594220427
Validation loss: 2.9810707480911818

Epoch: 6| Step: 10
Training loss: 0.33592998141369473
Validation loss: 3.0030429560277496

Epoch: 6| Step: 11
Training loss: 0.4149427953038316
Validation loss: 2.9149614844550387

Epoch: 6| Step: 12
Training loss: 0.451366267085736
Validation loss: 2.9568701380618005

Epoch: 6| Step: 13
Training loss: 0.38917484040359046
Validation loss: 2.9182103477051426

Epoch: 345| Step: 0
Training loss: 0.39132004890782585
Validation loss: 2.986233204309627

Epoch: 6| Step: 1
Training loss: 0.37617689468029347
Validation loss: 2.9272545914875265

Epoch: 6| Step: 2
Training loss: 0.41280979819788927
Validation loss: 2.820923856093215

Epoch: 6| Step: 3
Training loss: 0.5510287168551994
Validation loss: 2.865002151852388

Epoch: 6| Step: 4
Training loss: 0.37487232498455997
Validation loss: 2.938828688627712

Epoch: 6| Step: 5
Training loss: 0.5206206523260362
Validation loss: 2.913923149424667

Epoch: 6| Step: 6
Training loss: 0.7189319214510331
Validation loss: 2.9042609459904236

Epoch: 6| Step: 7
Training loss: 0.33254731408116966
Validation loss: 2.9904125849041443

Epoch: 6| Step: 8
Training loss: 0.44370800544931316
Validation loss: 2.9209639000834673

Epoch: 6| Step: 9
Training loss: 0.43578551045848757
Validation loss: 2.934812736970866

Epoch: 6| Step: 10
Training loss: 0.9278960398308612
Validation loss: 2.9489943800034326

Epoch: 6| Step: 11
Training loss: 0.3916948925493648
Validation loss: 2.903020246824311

Epoch: 6| Step: 12
Training loss: 0.4524019655179061
Validation loss: 2.9647906084621476

Epoch: 6| Step: 13
Training loss: 0.4399824218598273
Validation loss: 2.905063845129302

Epoch: 346| Step: 0
Training loss: 0.36882061686243967
Validation loss: 2.8767408131635372

Epoch: 6| Step: 1
Training loss: 0.45861826153678764
Validation loss: 2.9249891525458667

Epoch: 6| Step: 2
Training loss: 0.33594153645774033
Validation loss: 2.88296338852081

Epoch: 6| Step: 3
Training loss: 0.4161107487345194
Validation loss: 2.921454768297119

Epoch: 6| Step: 4
Training loss: 0.3969668004353616
Validation loss: 2.9155246587879464

Epoch: 6| Step: 5
Training loss: 0.350318424096495
Validation loss: 2.9156624336742554

Epoch: 6| Step: 6
Training loss: 0.648254092832121
Validation loss: 2.9252107995304986

Epoch: 6| Step: 7
Training loss: 0.8337083131814721
Validation loss: 2.9241581800382415

Epoch: 6| Step: 8
Training loss: 0.3571818019716162
Validation loss: 2.898172632061399

Epoch: 6| Step: 9
Training loss: 0.29093334135613297
Validation loss: 2.981081918260776

Epoch: 6| Step: 10
Training loss: 0.479898207048436
Validation loss: 2.9627348880495616

Epoch: 6| Step: 11
Training loss: 0.34874538666398147
Validation loss: 3.044194729878662

Epoch: 6| Step: 12
Training loss: 0.37677837926753865
Validation loss: 2.9394260882615955

Epoch: 6| Step: 13
Training loss: 0.4359453029686232
Validation loss: 2.8667517390676274

Epoch: 347| Step: 0
Training loss: 0.8310243128101595
Validation loss: 2.942384554624754

Epoch: 6| Step: 1
Training loss: 0.3745239335397033
Validation loss: 2.9089877178483183

Epoch: 6| Step: 2
Training loss: 0.36080296473786383
Validation loss: 2.916689196000053

Epoch: 6| Step: 3
Training loss: 0.42567361993694225
Validation loss: 2.9460289418529046

Epoch: 6| Step: 4
Training loss: 0.2727702856011484
Validation loss: 2.9286328125434182

Epoch: 6| Step: 5
Training loss: 0.46894110916459136
Validation loss: 2.8916575194405616

Epoch: 6| Step: 6
Training loss: 0.5296992781688373
Validation loss: 2.891839399501317

Epoch: 6| Step: 7
Training loss: 0.36196186060895913
Validation loss: 2.8863015086260306

Epoch: 6| Step: 8
Training loss: 0.40855609654658565
Validation loss: 2.9296367590006973

Epoch: 6| Step: 9
Training loss: 0.58748153698094
Validation loss: 2.912949241187219

Epoch: 6| Step: 10
Training loss: 0.6551636832771055
Validation loss: 2.9190185102072124

Epoch: 6| Step: 11
Training loss: 0.5935356104434566
Validation loss: 2.8840035973313496

Epoch: 6| Step: 12
Training loss: 0.43438063350290207
Validation loss: 2.9715070804941863

Epoch: 6| Step: 13
Training loss: 0.411410276608406
Validation loss: 2.987610745472238

Epoch: 348| Step: 0
Training loss: 0.30058679859417275
Validation loss: 2.915404187311543

Epoch: 6| Step: 1
Training loss: 0.318144111171672
Validation loss: 2.8937342580829872

Epoch: 6| Step: 2
Training loss: 0.3340568017785853
Validation loss: 2.9825259567116085

Epoch: 6| Step: 3
Training loss: 0.32373119371427944
Validation loss: 2.951956462265093

Epoch: 6| Step: 4
Training loss: 0.4207369147060547
Validation loss: 2.8189540419840617

Epoch: 6| Step: 5
Training loss: 0.26801931943934126
Validation loss: 2.887022615853972

Epoch: 6| Step: 6
Training loss: 0.39113210187531416
Validation loss: 2.890817103145634

Epoch: 6| Step: 7
Training loss: 0.46208192706718215
Validation loss: 2.902901857229819

Epoch: 6| Step: 8
Training loss: 0.9564914037135724
Validation loss: 2.927606153575144

Epoch: 6| Step: 9
Training loss: 0.25666359460424776
Validation loss: 2.8855609283924415

Epoch: 6| Step: 10
Training loss: 0.6084924567059873
Validation loss: 2.872206740785446

Epoch: 6| Step: 11
Training loss: 0.40158696897892354
Validation loss: 2.8679094505708838

Epoch: 6| Step: 12
Training loss: 0.48645717946092004
Validation loss: 2.8997946249927145

Epoch: 6| Step: 13
Training loss: 0.41317980626389267
Validation loss: 2.8095986978411642

Epoch: 349| Step: 0
Training loss: 0.339754235328257
Validation loss: 2.8821431307241894

Epoch: 6| Step: 1
Training loss: 0.4242960372969917
Validation loss: 2.8697502331705222

Epoch: 6| Step: 2
Training loss: 0.6257995259905855
Validation loss: 2.877249183450715

Epoch: 6| Step: 3
Training loss: 0.44363082440578994
Validation loss: 2.911261582024634

Epoch: 6| Step: 4
Training loss: 0.41377759524516766
Validation loss: 2.8550981036654695

Epoch: 6| Step: 5
Training loss: 0.7613734318427879
Validation loss: 2.779386203069335

Epoch: 6| Step: 6
Training loss: 0.45237376981485217
Validation loss: 2.9974309464603888

Epoch: 6| Step: 7
Training loss: 0.373329275402228
Validation loss: 2.906463232387413

Epoch: 6| Step: 8
Training loss: 0.3971963512595927
Validation loss: 2.9189035738745948

Epoch: 6| Step: 9
Training loss: 0.4859300999215951
Validation loss: 2.9458177910538175

Epoch: 6| Step: 10
Training loss: 0.36765859697973263
Validation loss: 2.880489098842842

Epoch: 6| Step: 11
Training loss: 0.5042836454208942
Validation loss: 2.9985954785073243

Epoch: 6| Step: 12
Training loss: 0.5917239506172881
Validation loss: 2.959580753938787

Epoch: 6| Step: 13
Training loss: 0.4866937082868805
Validation loss: 2.9263490025001277

Epoch: 350| Step: 0
Training loss: 0.5349761771308174
Validation loss: 2.9627012771927648

Epoch: 6| Step: 1
Training loss: 0.3402782490731347
Validation loss: 2.883764893606744

Epoch: 6| Step: 2
Training loss: 0.5854917992767619
Validation loss: 2.892674944397259

Epoch: 6| Step: 3
Training loss: 0.41372078164301485
Validation loss: 2.948291327905242

Epoch: 6| Step: 4
Training loss: 0.37850476653878434
Validation loss: 2.9407206120826643

Epoch: 6| Step: 5
Training loss: 0.42145512137302427
Validation loss: 2.8936589583046803

Epoch: 6| Step: 6
Training loss: 0.5282192168755887
Validation loss: 2.8309751729511015

Epoch: 6| Step: 7
Training loss: 0.3155870665048301
Validation loss: 2.8994005630571205

Epoch: 6| Step: 8
Training loss: 0.40883904528343756
Validation loss: 2.8908711921395316

Epoch: 6| Step: 9
Training loss: 0.45608399519595555
Validation loss: 2.8790972718314536

Epoch: 6| Step: 10
Training loss: 0.32368273260830377
Validation loss: 2.9198739990936406

Epoch: 6| Step: 11
Training loss: 0.8512871323271614
Validation loss: 2.90114982764045

Epoch: 6| Step: 12
Training loss: 0.4929983634940913
Validation loss: 2.9153831973155326

Epoch: 6| Step: 13
Training loss: 0.35036881505479417
Validation loss: 2.88985819913097

Epoch: 351| Step: 0
Training loss: 0.43208438622405554
Validation loss: 2.915114934584565

Epoch: 6| Step: 1
Training loss: 0.3892363852935621
Validation loss: 3.004300862532331

Epoch: 6| Step: 2
Training loss: 0.5282183705693967
Validation loss: 3.008245950488215

Epoch: 6| Step: 3
Training loss: 0.5043597287840639
Validation loss: 2.9073908354409985

Epoch: 6| Step: 4
Training loss: 0.5218920025368615
Validation loss: 2.9596039411910477

Epoch: 6| Step: 5
Training loss: 0.399210105996509
Validation loss: 2.9274206589334546

Epoch: 6| Step: 6
Training loss: 0.35172423774915373
Validation loss: 2.961360327491836

Epoch: 6| Step: 7
Training loss: 0.30446723165273465
Validation loss: 2.873102183688079

Epoch: 6| Step: 8
Training loss: 0.4444972657150686
Validation loss: 2.977343792974985

Epoch: 6| Step: 9
Training loss: 0.3491913518036021
Validation loss: 2.9783098060078537

Epoch: 6| Step: 10
Training loss: 0.5793945446236225
Validation loss: 2.9551876877305703

Epoch: 6| Step: 11
Training loss: 0.8929756331157648
Validation loss: 2.9230519200682967

Epoch: 6| Step: 12
Training loss: 0.3397642239883599
Validation loss: 2.959634566345406

Epoch: 6| Step: 13
Training loss: 0.3921952159472123
Validation loss: 2.932536510772501

Epoch: 352| Step: 0
Training loss: 0.26425112922376653
Validation loss: 2.9438258836904607

Epoch: 6| Step: 1
Training loss: 0.45027312229013416
Validation loss: 2.856819191833157

Epoch: 6| Step: 2
Training loss: 0.3783360743353332
Validation loss: 2.9253430244171685

Epoch: 6| Step: 3
Training loss: 0.43777680155514265
Validation loss: 2.857825423917613

Epoch: 6| Step: 4
Training loss: 0.34039700078169655
Validation loss: 2.9722703373263726

Epoch: 6| Step: 5
Training loss: 0.4708829828967423
Validation loss: 2.8990537634350537

Epoch: 6| Step: 6
Training loss: 0.7151724471361863
Validation loss: 2.8532691760366773

Epoch: 6| Step: 7
Training loss: 0.7568846853000368
Validation loss: 2.8693130887979517

Epoch: 6| Step: 8
Training loss: 0.436205976800799
Validation loss: 2.9379479898584457

Epoch: 6| Step: 9
Training loss: 0.427186275109277
Validation loss: 2.924773874263816

Epoch: 6| Step: 10
Training loss: 0.4331414896921064
Validation loss: 2.8806093131121253

Epoch: 6| Step: 11
Training loss: 0.3221450001928835
Validation loss: 2.881982134121915

Epoch: 6| Step: 12
Training loss: 0.4150224570150085
Validation loss: 2.9698616623476695

Epoch: 6| Step: 13
Training loss: 0.4177717297105807
Validation loss: 2.9494093136557304

Epoch: 353| Step: 0
Training loss: 0.3544957604766778
Validation loss: 3.005238370343091

Epoch: 6| Step: 1
Training loss: 0.38016168316879523
Validation loss: 3.0065800177028104

Epoch: 6| Step: 2
Training loss: 0.4849940927381704
Validation loss: 2.900275183370029

Epoch: 6| Step: 3
Training loss: 0.390874001295853
Validation loss: 3.0242484727609518

Epoch: 6| Step: 4
Training loss: 0.3956483379368634
Validation loss: 2.9368829552552924

Epoch: 6| Step: 5
Training loss: 0.44429656472622064
Validation loss: 2.939975872005664

Epoch: 6| Step: 6
Training loss: 0.36162107809150695
Validation loss: 2.846071783625536

Epoch: 6| Step: 7
Training loss: 0.3810500230215296
Validation loss: 2.890003818060653

Epoch: 6| Step: 8
Training loss: 0.4959154634681729
Validation loss: 2.9160871520386196

Epoch: 6| Step: 9
Training loss: 0.41671983459125544
Validation loss: 2.882236412813731

Epoch: 6| Step: 10
Training loss: 0.5942873781683313
Validation loss: 2.9004400144197278

Epoch: 6| Step: 11
Training loss: 0.4168422170213765
Validation loss: 2.890926159815947

Epoch: 6| Step: 12
Training loss: 0.7045974572418701
Validation loss: 2.936102013667591

Epoch: 6| Step: 13
Training loss: 0.4231541984434564
Validation loss: 2.9941288134330923

Epoch: 354| Step: 0
Training loss: 0.3198507283413412
Validation loss: 2.870022888468921

Epoch: 6| Step: 1
Training loss: 0.35163524722733425
Validation loss: 2.8771085470550943

Epoch: 6| Step: 2
Training loss: 0.3036241560712623
Validation loss: 3.00232331064417

Epoch: 6| Step: 3
Training loss: 0.29313382902045637
Validation loss: 2.8609094723589568

Epoch: 6| Step: 4
Training loss: 0.6975471291633982
Validation loss: 2.918771969415075

Epoch: 6| Step: 5
Training loss: 0.6451545475840078
Validation loss: 2.8574388268420536

Epoch: 6| Step: 6
Training loss: 0.3385486589834505
Validation loss: 2.923528601135781

Epoch: 6| Step: 7
Training loss: 0.5324900123841567
Validation loss: 2.8869747862191057

Epoch: 6| Step: 8
Training loss: 0.3448239802097996
Validation loss: 2.9734153897747504

Epoch: 6| Step: 9
Training loss: 0.4626237768070982
Validation loss: 2.91266348274926

Epoch: 6| Step: 10
Training loss: 0.35444485266896825
Validation loss: 2.9468821045785525

Epoch: 6| Step: 11
Training loss: 0.44695806131502513
Validation loss: 2.9426273886201506

Epoch: 6| Step: 12
Training loss: 0.521899054880889
Validation loss: 2.8806761257705227

Epoch: 6| Step: 13
Training loss: 0.4928692833716225
Validation loss: 2.914606679332523

Epoch: 355| Step: 0
Training loss: 0.39461682590722486
Validation loss: 2.8183337285563956

Epoch: 6| Step: 1
Training loss: 0.632469743751323
Validation loss: 2.901723803184628

Epoch: 6| Step: 2
Training loss: 0.3968231182278957
Validation loss: 2.8292147396836826

Epoch: 6| Step: 3
Training loss: 0.4474916511694531
Validation loss: 2.85068682459067

Epoch: 6| Step: 4
Training loss: 0.33707623103329426
Validation loss: 2.9300927860944403

Epoch: 6| Step: 5
Training loss: 0.3546809174855313
Validation loss: 2.8922559244039867

Epoch: 6| Step: 6
Training loss: 0.5520944564226644
Validation loss: 2.941990565081936

Epoch: 6| Step: 7
Training loss: 0.3860872101857046
Validation loss: 2.999274974208889

Epoch: 6| Step: 8
Training loss: 0.7736403459366583
Validation loss: 3.0215027736045292

Epoch: 6| Step: 9
Training loss: 0.4234962042623794
Validation loss: 2.9420735352482725

Epoch: 6| Step: 10
Training loss: 0.6004265550473744
Validation loss: 2.9458574217621245

Epoch: 6| Step: 11
Training loss: 0.38166699977232765
Validation loss: 2.917782397534885

Epoch: 6| Step: 12
Training loss: 0.24288246977898265
Validation loss: 2.938784487559936

Epoch: 6| Step: 13
Training loss: 0.425620319856072
Validation loss: 2.8453051608006863

Epoch: 356| Step: 0
Training loss: 0.4841629610176995
Validation loss: 2.8917673551488763

Epoch: 6| Step: 1
Training loss: 0.4744955797703047
Validation loss: 2.8654316888611144

Epoch: 6| Step: 2
Training loss: 0.8931226676125633
Validation loss: 2.85002621588445

Epoch: 6| Step: 3
Training loss: 0.5565863331870343
Validation loss: 2.901574095670489

Epoch: 6| Step: 4
Training loss: 0.3619265575279771
Validation loss: 2.9035692053749314

Epoch: 6| Step: 5
Training loss: 0.40015357839220556
Validation loss: 2.978052742432733

Epoch: 6| Step: 6
Training loss: 0.42534944529395763
Validation loss: 2.9153473776746477

Epoch: 6| Step: 7
Training loss: 0.4282058138346209
Validation loss: 2.9825772967558364

Epoch: 6| Step: 8
Training loss: 0.3638816711852113
Validation loss: 2.9347793750059172

Epoch: 6| Step: 9
Training loss: 0.46490542219072517
Validation loss: 2.9103834503033235

Epoch: 6| Step: 10
Training loss: 0.40116667553764707
Validation loss: 2.982109781293397

Epoch: 6| Step: 11
Training loss: 0.42918751844964653
Validation loss: 2.9204815348414956

Epoch: 6| Step: 12
Training loss: 0.3690348478676978
Validation loss: 2.9220031329396443

Epoch: 6| Step: 13
Training loss: 0.36066231083369676
Validation loss: 2.979007254294716

Epoch: 357| Step: 0
Training loss: 0.39198699020186667
Validation loss: 2.9244922197185925

Epoch: 6| Step: 1
Training loss: 0.4280750537891217
Validation loss: 2.8945384297901775

Epoch: 6| Step: 2
Training loss: 0.45879496460581737
Validation loss: 2.889567069897382

Epoch: 6| Step: 3
Training loss: 0.3513330452548812
Validation loss: 2.9053997997511183

Epoch: 6| Step: 4
Training loss: 0.3551302335501868
Validation loss: 2.9240059451331093

Epoch: 6| Step: 5
Training loss: 0.2325907182087153
Validation loss: 2.8514043755432565

Epoch: 6| Step: 6
Training loss: 0.5084036980326397
Validation loss: 2.9851438919925743

Epoch: 6| Step: 7
Training loss: 0.5168469716859727
Validation loss: 2.936672635269017

Epoch: 6| Step: 8
Training loss: 0.36347988809727627
Validation loss: 2.90457357915447

Epoch: 6| Step: 9
Training loss: 0.5156226880570801
Validation loss: 2.890175298128357

Epoch: 6| Step: 10
Training loss: 0.7353009412953767
Validation loss: 2.9236264886600165

Epoch: 6| Step: 11
Training loss: 0.5523432773442384
Validation loss: 2.8638728746183713

Epoch: 6| Step: 12
Training loss: 0.4429086082577122
Validation loss: 2.8978658696834203

Epoch: 6| Step: 13
Training loss: 0.34700225008144325
Validation loss: 2.9293657863725167

Epoch: 358| Step: 0
Training loss: 0.4679111604488301
Validation loss: 2.9076539753634685

Epoch: 6| Step: 1
Training loss: 0.34291119537917425
Validation loss: 2.875730642826683

Epoch: 6| Step: 2
Training loss: 0.5730111015402785
Validation loss: 2.9010582768748328

Epoch: 6| Step: 3
Training loss: 0.4356623269922752
Validation loss: 2.886971909533789

Epoch: 6| Step: 4
Training loss: 0.47497103690638365
Validation loss: 2.8433699021963617

Epoch: 6| Step: 5
Training loss: 0.3674182167008991
Validation loss: 2.8793382324869823

Epoch: 6| Step: 6
Training loss: 0.4605629902771178
Validation loss: 2.8286542871375

Epoch: 6| Step: 7
Training loss: 0.2610516087363196
Validation loss: 2.888809341829161

Epoch: 6| Step: 8
Training loss: 0.5433282553936716
Validation loss: 2.916448780277336

Epoch: 6| Step: 9
Training loss: 0.5273228959092715
Validation loss: 3.0109438231130765

Epoch: 6| Step: 10
Training loss: 0.7597274182281626
Validation loss: 2.9645400195376665

Epoch: 6| Step: 11
Training loss: 0.408977813813812
Validation loss: 2.8820743735770082

Epoch: 6| Step: 12
Training loss: 0.525495809356865
Validation loss: 2.9180432931008

Epoch: 6| Step: 13
Training loss: 0.3967179047559378
Validation loss: 2.9072075363628347

Epoch: 359| Step: 0
Training loss: 0.4130260884101787
Validation loss: 2.863266435266518

Epoch: 6| Step: 1
Training loss: 0.5191798922209938
Validation loss: 2.8091258401392625

Epoch: 6| Step: 2
Training loss: 0.4474013343386987
Validation loss: 2.8971447388002525

Epoch: 6| Step: 3
Training loss: 0.4728401078700388
Validation loss: 2.865699097629743

Epoch: 6| Step: 4
Training loss: 0.33558907293471907
Validation loss: 2.880954864126319

Epoch: 6| Step: 5
Training loss: 0.7571782476258981
Validation loss: 2.95969703745548

Epoch: 6| Step: 6
Training loss: 0.37960675954850004
Validation loss: 2.9808797690386624

Epoch: 6| Step: 7
Training loss: 0.6976045057495198
Validation loss: 2.9411018690297026

Epoch: 6| Step: 8
Training loss: 0.6050472392011741
Validation loss: 2.990343925318125

Epoch: 6| Step: 9
Training loss: 0.38326687996973896
Validation loss: 2.9022865067283856

Epoch: 6| Step: 10
Training loss: 0.38467342220797723
Validation loss: 2.9490806159876186

Epoch: 6| Step: 11
Training loss: 0.5301119451338808
Validation loss: 2.8543164336921047

Epoch: 6| Step: 12
Training loss: 0.6247892262774825
Validation loss: 2.886194590194581

Epoch: 6| Step: 13
Training loss: 0.6592055026050407
Validation loss: 2.8526522848906812

Epoch: 360| Step: 0
Training loss: 0.6081155820550507
Validation loss: 2.8753431502402464

Epoch: 6| Step: 1
Training loss: 0.3398771488834478
Validation loss: 2.9184160413156373

Epoch: 6| Step: 2
Training loss: 0.314364391151694
Validation loss: 2.838320589934806

Epoch: 6| Step: 3
Training loss: 0.41221342535963384
Validation loss: 2.9137565718109895

Epoch: 6| Step: 4
Training loss: 0.7568146339617651
Validation loss: 2.9588066626837457

Epoch: 6| Step: 5
Training loss: 0.4856324639845277
Validation loss: 2.959516709455128

Epoch: 6| Step: 6
Training loss: 0.6024891045879218
Validation loss: 2.9676175283132786

Epoch: 6| Step: 7
Training loss: 0.4487302196946143
Validation loss: 2.9387055216238096

Epoch: 6| Step: 8
Training loss: 0.4465105104181187
Validation loss: 2.8954292308143

Epoch: 6| Step: 9
Training loss: 0.49782398696740404
Validation loss: 2.9107663054948367

Epoch: 6| Step: 10
Training loss: 0.4787533383713704
Validation loss: 2.857037775485805

Epoch: 6| Step: 11
Training loss: 0.4838852098058429
Validation loss: 2.8862413726585183

Epoch: 6| Step: 12
Training loss: 0.3178314559294635
Validation loss: 2.936180156420037

Epoch: 6| Step: 13
Training loss: 0.6100269156130484
Validation loss: 2.924536500925291

Epoch: 361| Step: 0
Training loss: 0.4357321648703935
Validation loss: 2.8372083746547663

Epoch: 6| Step: 1
Training loss: 0.4356571280345602
Validation loss: 2.947157857621314

Epoch: 6| Step: 2
Training loss: 0.6050055423987126
Validation loss: 2.9598811873118875

Epoch: 6| Step: 3
Training loss: 0.4638847588674435
Validation loss: 2.9237979266438305

Epoch: 6| Step: 4
Training loss: 0.3388971760697167
Validation loss: 2.9363929881096134

Epoch: 6| Step: 5
Training loss: 0.4106473616458268
Validation loss: 2.909253663600123

Epoch: 6| Step: 6
Training loss: 0.5224607663733657
Validation loss: 2.9326201820083013

Epoch: 6| Step: 7
Training loss: 0.4726061676226302
Validation loss: 2.877661744429209

Epoch: 6| Step: 8
Training loss: 0.3930162859883716
Validation loss: 2.8666119738469846

Epoch: 6| Step: 9
Training loss: 0.30744006189161804
Validation loss: 2.9125979563949276

Epoch: 6| Step: 10
Training loss: 0.3365471874143338
Validation loss: 2.8423371071330954

Epoch: 6| Step: 11
Training loss: 0.44155304079932073
Validation loss: 2.881493905225984

Epoch: 6| Step: 12
Training loss: 0.8146142594368555
Validation loss: 2.8099808607886376

Epoch: 6| Step: 13
Training loss: 0.34005629809683047
Validation loss: 2.9888973091397646

Epoch: 362| Step: 0
Training loss: 0.6784768558510128
Validation loss: 2.939305298595476

Epoch: 6| Step: 1
Training loss: 0.50352546439608
Validation loss: 2.9742186388423715

Epoch: 6| Step: 2
Training loss: 0.44899639763374644
Validation loss: 2.979472815960035

Epoch: 6| Step: 3
Training loss: 0.42831103327450065
Validation loss: 3.0182854770852567

Epoch: 6| Step: 4
Training loss: 0.45604330044566005
Validation loss: 3.000993782587421

Epoch: 6| Step: 5
Training loss: 0.41963933266374204
Validation loss: 2.887807734441167

Epoch: 6| Step: 6
Training loss: 0.41984706478421685
Validation loss: 2.9582429567599906

Epoch: 6| Step: 7
Training loss: 0.3428468326773897
Validation loss: 2.85026186191783

Epoch: 6| Step: 8
Training loss: 0.4243474494631796
Validation loss: 2.8214287138473817

Epoch: 6| Step: 9
Training loss: 0.4849061514811371
Validation loss: 2.887367351176862

Epoch: 6| Step: 10
Training loss: 0.6190641337897411
Validation loss: 2.9103568261852466

Epoch: 6| Step: 11
Training loss: 0.3632906635664485
Validation loss: 3.0529011139634714

Epoch: 6| Step: 12
Training loss: 0.46958483423547714
Validation loss: 3.0495530447194352

Epoch: 6| Step: 13
Training loss: 0.5433531299399466
Validation loss: 2.991830045831048

Epoch: 363| Step: 0
Training loss: 0.5316549889209805
Validation loss: 3.056398509291247

Epoch: 6| Step: 1
Training loss: 0.37474667416726093
Validation loss: 2.9848942596177572

Epoch: 6| Step: 2
Training loss: 0.5761638576143729
Validation loss: 2.928700028895573

Epoch: 6| Step: 3
Training loss: 0.3406536711429063
Validation loss: 2.9323366250927454

Epoch: 6| Step: 4
Training loss: 0.35605156458219095
Validation loss: 2.8850941162139994

Epoch: 6| Step: 5
Training loss: 0.3268572863963351
Validation loss: 2.9569813544810346

Epoch: 6| Step: 6
Training loss: 0.41929551361926287
Validation loss: 2.805087189455433

Epoch: 6| Step: 7
Training loss: 0.6579259181162386
Validation loss: 2.85721157479528

Epoch: 6| Step: 8
Training loss: 0.40953361845295827
Validation loss: 2.930429607073325

Epoch: 6| Step: 9
Training loss: 0.2730774825463396
Validation loss: 2.9299102969754127

Epoch: 6| Step: 10
Training loss: 0.531527923365447
Validation loss: 2.882065218701767

Epoch: 6| Step: 11
Training loss: 0.4689364539298341
Validation loss: 2.983561553075484

Epoch: 6| Step: 12
Training loss: 0.6404783034420629
Validation loss: 2.932959300455403

Epoch: 6| Step: 13
Training loss: 0.4236137093879492
Validation loss: 3.035879866307721

Epoch: 364| Step: 0
Training loss: 0.34667440061164595
Validation loss: 2.987235397793969

Epoch: 6| Step: 1
Training loss: 0.49150742367176126
Validation loss: 2.889407394615955

Epoch: 6| Step: 2
Training loss: 0.4798178411834685
Validation loss: 2.939181421508037

Epoch: 6| Step: 3
Training loss: 0.29908165741790427
Validation loss: 2.946857927258774

Epoch: 6| Step: 4
Training loss: 0.4638112887783194
Validation loss: 2.9533110329566066

Epoch: 6| Step: 5
Training loss: 0.5403804148610741
Validation loss: 2.8556818919513067

Epoch: 6| Step: 6
Training loss: 0.5093414471112744
Validation loss: 2.9906614842808596

Epoch: 6| Step: 7
Training loss: 0.26952696534220366
Validation loss: 2.885604471275892

Epoch: 6| Step: 8
Training loss: 0.37182649247975347
Validation loss: 2.96632694610235

Epoch: 6| Step: 9
Training loss: 0.5558410255475595
Validation loss: 2.99110525826503

Epoch: 6| Step: 10
Training loss: 0.45899645201032746
Validation loss: 2.982439395409238

Epoch: 6| Step: 11
Training loss: 0.6104552646277156
Validation loss: 2.9432272979526983

Epoch: 6| Step: 12
Training loss: 0.4729706372821054
Validation loss: 2.966445215582312

Epoch: 6| Step: 13
Training loss: 0.4258218098491549
Validation loss: 2.920559945873495

Epoch: 365| Step: 0
Training loss: 0.5311641904306201
Validation loss: 2.9299630946763418

Epoch: 6| Step: 1
Training loss: 0.30960722982937433
Validation loss: 2.907471239555075

Epoch: 6| Step: 2
Training loss: 0.34399079428805623
Validation loss: 2.945933188041428

Epoch: 6| Step: 3
Training loss: 0.4813217097274219
Validation loss: 2.85826848200269

Epoch: 6| Step: 4
Training loss: 0.4364754567243163
Validation loss: 2.9114998875327034

Epoch: 6| Step: 5
Training loss: 0.4628440575977581
Validation loss: 2.895452273062937

Epoch: 6| Step: 6
Training loss: 0.39553017258721523
Validation loss: 2.898679909932779

Epoch: 6| Step: 7
Training loss: 0.5075717942423008
Validation loss: 2.8655099422051826

Epoch: 6| Step: 8
Training loss: 0.37473367134540025
Validation loss: 2.9361103639708976

Epoch: 6| Step: 9
Training loss: 0.4947096070623128
Validation loss: 2.8782487564457537

Epoch: 6| Step: 10
Training loss: 0.8200175890548037
Validation loss: 2.9656714689997585

Epoch: 6| Step: 11
Training loss: 0.3790783835257239
Validation loss: 2.8336322056457437

Epoch: 6| Step: 12
Training loss: 0.45619715685069256
Validation loss: 2.917947492475245

Epoch: 6| Step: 13
Training loss: 0.45596286412910125
Validation loss: 2.968348693493771

Epoch: 366| Step: 0
Training loss: 0.3182273075946421
Validation loss: 2.868623573104838

Epoch: 6| Step: 1
Training loss: 0.41753066804027467
Validation loss: 2.9262194235343664

Epoch: 6| Step: 2
Training loss: 0.4326941634814903
Validation loss: 2.8943574744264873

Epoch: 6| Step: 3
Training loss: 0.4499683097436101
Validation loss: 2.9560364192401942

Epoch: 6| Step: 4
Training loss: 0.4560420751359254
Validation loss: 2.9239641496423583

Epoch: 6| Step: 5
Training loss: 0.37818708698235654
Validation loss: 2.9378664315739895

Epoch: 6| Step: 6
Training loss: 0.8780541252232656
Validation loss: 2.9158356890614834

Epoch: 6| Step: 7
Training loss: 0.2630195035365767
Validation loss: 2.93841247725361

Epoch: 6| Step: 8
Training loss: 0.5028084321743592
Validation loss: 3.0008936716539276

Epoch: 6| Step: 9
Training loss: 0.3763094530626891
Validation loss: 2.9015373249430585

Epoch: 6| Step: 10
Training loss: 0.28831565879019205
Validation loss: 3.073392337686402

Epoch: 6| Step: 11
Training loss: 0.3812439957130273
Validation loss: 2.859472867197631

Epoch: 6| Step: 12
Training loss: 0.4094168401404992
Validation loss: 2.8922309332275256

Epoch: 6| Step: 13
Training loss: 0.4554993804002017
Validation loss: 2.888103835917085

Epoch: 367| Step: 0
Training loss: 0.40115956229060595
Validation loss: 2.8632787242147937

Epoch: 6| Step: 1
Training loss: 0.3595112252160786
Validation loss: 2.8690756004241327

Epoch: 6| Step: 2
Training loss: 0.35762289262488706
Validation loss: 2.903889247573231

Epoch: 6| Step: 3
Training loss: 0.5319644387485103
Validation loss: 2.855656239781276

Epoch: 6| Step: 4
Training loss: 0.3796069165652837
Validation loss: 2.853530469468932

Epoch: 6| Step: 5
Training loss: 0.4686854318017903
Validation loss: 2.869721612000242

Epoch: 6| Step: 6
Training loss: 0.4580869951916631
Validation loss: 2.9051748495177265

Epoch: 6| Step: 7
Training loss: 0.3899107888781445
Validation loss: 2.9310437398974543

Epoch: 6| Step: 8
Training loss: 0.38340732527238575
Validation loss: 2.974298772795002

Epoch: 6| Step: 9
Training loss: 0.3637873088409778
Validation loss: 3.0459858697424473

Epoch: 6| Step: 10
Training loss: 0.27701436214534636
Validation loss: 2.99871077916441

Epoch: 6| Step: 11
Training loss: 0.39798920787383846
Validation loss: 2.998452602107912

Epoch: 6| Step: 12
Training loss: 0.7130590788506486
Validation loss: 2.9801110235863355

Epoch: 6| Step: 13
Training loss: 0.6659550121838504
Validation loss: 2.9475145009476567

Epoch: 368| Step: 0
Training loss: 0.5832077526974384
Validation loss: 2.9427045343875275

Epoch: 6| Step: 1
Training loss: 0.399715021064286
Validation loss: 2.9307277070434976

Epoch: 6| Step: 2
Training loss: 0.26966484186814854
Validation loss: 2.879843639902038

Epoch: 6| Step: 3
Training loss: 0.3901603796591035
Validation loss: 2.936070412223706

Epoch: 6| Step: 4
Training loss: 0.6397757600053026
Validation loss: 2.9275208188127566

Epoch: 6| Step: 5
Training loss: 0.3838134447268469
Validation loss: 2.8791607727417374

Epoch: 6| Step: 6
Training loss: 0.4366005438992148
Validation loss: 2.9131587641009533

Epoch: 6| Step: 7
Training loss: 0.4967002165373608
Validation loss: 2.959011353893269

Epoch: 6| Step: 8
Training loss: 0.3631924141174096
Validation loss: 2.9322835719988927

Epoch: 6| Step: 9
Training loss: 0.2440264473001749
Validation loss: 2.992566163593888

Epoch: 6| Step: 10
Training loss: 0.4740306638364093
Validation loss: 2.859257457658833

Epoch: 6| Step: 11
Training loss: 0.36241339520457094
Validation loss: 2.933414160814179

Epoch: 6| Step: 12
Training loss: 0.4975555689366931
Validation loss: 2.93174877301892

Epoch: 6| Step: 13
Training loss: 0.5873336434718918
Validation loss: 2.9020664635410074

Epoch: 369| Step: 0
Training loss: 0.506217917850389
Validation loss: 2.9610919492728596

Epoch: 6| Step: 1
Training loss: 0.45054829427417187
Validation loss: 2.916028270791959

Epoch: 6| Step: 2
Training loss: 0.3988726240808777
Validation loss: 2.924111773183215

Epoch: 6| Step: 3
Training loss: 0.35673151936611375
Validation loss: 2.9622924308115

Epoch: 6| Step: 4
Training loss: 0.42000497394977077
Validation loss: 2.9960501881946797

Epoch: 6| Step: 5
Training loss: 0.4594624403690453
Validation loss: 2.9241138455401816

Epoch: 6| Step: 6
Training loss: 0.5895061410935113
Validation loss: 2.884375736764116

Epoch: 6| Step: 7
Training loss: 0.32881280926369194
Validation loss: 2.9187656660837153

Epoch: 6| Step: 8
Training loss: 0.25010920166154516
Validation loss: 2.885219062254345

Epoch: 6| Step: 9
Training loss: 0.8043336182733573
Validation loss: 2.8878786598390094

Epoch: 6| Step: 10
Training loss: 0.4437580416850667
Validation loss: 2.918973124305548

Epoch: 6| Step: 11
Training loss: 0.5555324297966097
Validation loss: 2.906038652617616

Epoch: 6| Step: 12
Training loss: 0.5112151368619369
Validation loss: 2.928741668611172

Epoch: 6| Step: 13
Training loss: 0.41225788640517147
Validation loss: 2.8920733835495906

Epoch: 370| Step: 0
Training loss: 0.45915838960478667
Validation loss: 2.9774666228239948

Epoch: 6| Step: 1
Training loss: 0.2726601723331449
Validation loss: 2.985948676982184

Epoch: 6| Step: 2
Training loss: 0.45459341668549236
Validation loss: 2.9379556451301085

Epoch: 6| Step: 3
Training loss: 0.3328712384680736
Validation loss: 2.943818378666715

Epoch: 6| Step: 4
Training loss: 0.2954114803568272
Validation loss: 2.924584035558562

Epoch: 6| Step: 5
Training loss: 0.3938616367301934
Validation loss: 2.9204896304732295

Epoch: 6| Step: 6
Training loss: 0.5101141487263009
Validation loss: 2.9658977124553854

Epoch: 6| Step: 7
Training loss: 0.3621348268191474
Validation loss: 2.924239278156159

Epoch: 6| Step: 8
Training loss: 0.49228182902968304
Validation loss: 2.9285480097367103

Epoch: 6| Step: 9
Training loss: 0.41524276222521816
Validation loss: 2.8791426652569463

Epoch: 6| Step: 10
Training loss: 0.49612626397223436
Validation loss: 3.0015937624826874

Epoch: 6| Step: 11
Training loss: 0.3449865122936704
Validation loss: 2.883713620158522

Epoch: 6| Step: 12
Training loss: 0.6054160064366366
Validation loss: 2.848691782549675

Epoch: 6| Step: 13
Training loss: 0.5016861736374646
Validation loss: 2.94411408372472

Epoch: 371| Step: 0
Training loss: 0.3960326679992695
Validation loss: 2.87081164576547

Epoch: 6| Step: 1
Training loss: 0.39960719431471375
Validation loss: 2.8957630167229476

Epoch: 6| Step: 2
Training loss: 0.48300597317380495
Validation loss: 2.864663602686927

Epoch: 6| Step: 3
Training loss: 0.4355531871663278
Validation loss: 2.822809918814652

Epoch: 6| Step: 4
Training loss: 0.2860127219808506
Validation loss: 2.8693027714528077

Epoch: 6| Step: 5
Training loss: 0.4387227240395424
Validation loss: 2.8945707454895486

Epoch: 6| Step: 6
Training loss: 0.4423553087724625
Validation loss: 2.8196763495004546

Epoch: 6| Step: 7
Training loss: 0.44286079773295656
Validation loss: 2.870405174258575

Epoch: 6| Step: 8
Training loss: 0.6239655039464953
Validation loss: 2.8490419021056566

Epoch: 6| Step: 9
Training loss: 0.4259305044930537
Validation loss: 2.9409616108092025

Epoch: 6| Step: 10
Training loss: 0.34444601946687703
Validation loss: 2.928463502993102

Epoch: 6| Step: 11
Training loss: 0.5091697747509749
Validation loss: 3.0076219110257543

Epoch: 6| Step: 12
Training loss: 0.305496084351271
Validation loss: 2.96409002280239

Epoch: 6| Step: 13
Training loss: 0.31987716585971165
Validation loss: 2.9996816346995105

Epoch: 372| Step: 0
Training loss: 0.3555054069314425
Validation loss: 3.0388863192943965

Epoch: 6| Step: 1
Training loss: 0.24918071043956022
Validation loss: 2.920355512214839

Epoch: 6| Step: 2
Training loss: 0.520754356754298
Validation loss: 2.9233109996454343

Epoch: 6| Step: 3
Training loss: 0.4617365038148429
Validation loss: 3.0258498182997218

Epoch: 6| Step: 4
Training loss: 0.46047041551944384
Validation loss: 2.947496186497416

Epoch: 6| Step: 5
Training loss: 0.7629584372638099
Validation loss: 2.7749229357446112

Epoch: 6| Step: 6
Training loss: 0.5601356672817619
Validation loss: 2.835685992056858

Epoch: 6| Step: 7
Training loss: 0.3489825420617585
Validation loss: 2.876888373691442

Epoch: 6| Step: 8
Training loss: 0.3315362494213363
Validation loss: 2.911374158558014

Epoch: 6| Step: 9
Training loss: 0.40241566728215167
Validation loss: 2.839538117009334

Epoch: 6| Step: 10
Training loss: 0.38075583591108986
Validation loss: 2.99355539208357

Epoch: 6| Step: 11
Training loss: 0.4037687196614079
Validation loss: 2.9372467987019726

Epoch: 6| Step: 12
Training loss: 0.5087303669583367
Validation loss: 2.943403520866891

Epoch: 6| Step: 13
Training loss: 0.44867047561568096
Validation loss: 2.92435354278317

Epoch: 373| Step: 0
Training loss: 0.3611691511820098
Validation loss: 2.8833225698398794

Epoch: 6| Step: 1
Training loss: 0.4248405704470505
Validation loss: 2.8990883177934146

Epoch: 6| Step: 2
Training loss: 0.3186062867493532
Validation loss: 2.9314711909558544

Epoch: 6| Step: 3
Training loss: 0.4833603660927244
Validation loss: 2.942670411172215

Epoch: 6| Step: 4
Training loss: 0.7528291429807418
Validation loss: 2.863070561323707

Epoch: 6| Step: 5
Training loss: 0.4810615542158296
Validation loss: 2.881552857805963

Epoch: 6| Step: 6
Training loss: 0.6081740208830427
Validation loss: 2.8541366037238065

Epoch: 6| Step: 7
Training loss: 0.3938742539977742
Validation loss: 2.9661183923931755

Epoch: 6| Step: 8
Training loss: 0.346289250975685
Validation loss: 2.9768942099941924

Epoch: 6| Step: 9
Training loss: 0.3717420436492559
Validation loss: 3.0190839020723623

Epoch: 6| Step: 10
Training loss: 0.33309664618115853
Validation loss: 2.9939328275215296

Epoch: 6| Step: 11
Training loss: 0.3882613961806464
Validation loss: 2.9144807026271633

Epoch: 6| Step: 12
Training loss: 0.3885869264022732
Validation loss: 2.9057339582707433

Epoch: 6| Step: 13
Training loss: 0.41546824087604545
Validation loss: 2.8441984361032353

Epoch: 374| Step: 0
Training loss: 0.32651804069242074
Validation loss: 2.843723981689369

Epoch: 6| Step: 1
Training loss: 0.5704718589227824
Validation loss: 2.8703896833497007

Epoch: 6| Step: 2
Training loss: 0.46081049834385407
Validation loss: 2.8210327975712612

Epoch: 6| Step: 3
Training loss: 0.5175964640121459
Validation loss: 2.8943114409596453

Epoch: 6| Step: 4
Training loss: 0.41560493937100607
Validation loss: 2.907036746603473

Epoch: 6| Step: 5
Training loss: 0.5720237767706413
Validation loss: 2.884921865810099

Epoch: 6| Step: 6
Training loss: 0.2281526960256268
Validation loss: 2.8318867262872023

Epoch: 6| Step: 7
Training loss: 0.4359013094629238
Validation loss: 2.843614777644236

Epoch: 6| Step: 8
Training loss: 0.4428390609108553
Validation loss: 2.887581262367048

Epoch: 6| Step: 9
Training loss: 0.39621291239728706
Validation loss: 2.8847931946866368

Epoch: 6| Step: 10
Training loss: 0.6743677162576062
Validation loss: 2.9023364526067343

Epoch: 6| Step: 11
Training loss: 0.5118872969178517
Validation loss: 2.9177749344727233

Epoch: 6| Step: 12
Training loss: 0.35230010326908057
Validation loss: 2.847124912697689

Epoch: 6| Step: 13
Training loss: 0.2105570028130409
Validation loss: 2.868269311750842

Epoch: 375| Step: 0
Training loss: 0.5460278079668279
Validation loss: 2.9563707145578246

Epoch: 6| Step: 1
Training loss: 0.43780331655777893
Validation loss: 2.905292339530597

Epoch: 6| Step: 2
Training loss: 0.6829931181760623
Validation loss: 2.90112955632558

Epoch: 6| Step: 3
Training loss: 0.4210754871831471
Validation loss: 2.924694448525925

Epoch: 6| Step: 4
Training loss: 0.31388047005654524
Validation loss: 2.8445717040128247

Epoch: 6| Step: 5
Training loss: 0.4138053239327792
Validation loss: 2.8175253300401195

Epoch: 6| Step: 6
Training loss: 0.4582186215797322
Validation loss: 2.845270833117627

Epoch: 6| Step: 7
Training loss: 0.4450411388047772
Validation loss: 2.8109778629816877

Epoch: 6| Step: 8
Training loss: 0.35479017611668545
Validation loss: 2.931303672055141

Epoch: 6| Step: 9
Training loss: 0.4650023534417842
Validation loss: 2.8475322792338074

Epoch: 6| Step: 10
Training loss: 0.3191232935706304
Validation loss: 2.9551467030315073

Epoch: 6| Step: 11
Training loss: 0.42531194108061604
Validation loss: 2.9633561642228217

Epoch: 6| Step: 12
Training loss: 0.4414785545342117
Validation loss: 2.8916208562236267

Epoch: 6| Step: 13
Training loss: 0.36076298412608926
Validation loss: 2.7988442107486184

Epoch: 376| Step: 0
Training loss: 0.3110522710142701
Validation loss: 2.90324760865214

Epoch: 6| Step: 1
Training loss: 0.5194398613193209
Validation loss: 2.9364374416907673

Epoch: 6| Step: 2
Training loss: 0.7659364183745885
Validation loss: 2.836538932365899

Epoch: 6| Step: 3
Training loss: 0.449490075478134
Validation loss: 2.993376851569084

Epoch: 6| Step: 4
Training loss: 0.34564991988767857
Validation loss: 3.010761575618897

Epoch: 6| Step: 5
Training loss: 0.4079142374168332
Validation loss: 2.9646051350209883

Epoch: 6| Step: 6
Training loss: 0.4128386566746518
Validation loss: 2.9645673365819265

Epoch: 6| Step: 7
Training loss: 0.3567153534829864
Validation loss: 2.9244396221763034

Epoch: 6| Step: 8
Training loss: 0.45482797255256807
Validation loss: 2.9355264621954675

Epoch: 6| Step: 9
Training loss: 0.3716939790095912
Validation loss: 2.9102633394682162

Epoch: 6| Step: 10
Training loss: 0.3646084527036103
Validation loss: 2.9188303460573986

Epoch: 6| Step: 11
Training loss: 0.5850644792169363
Validation loss: 2.874442834354371

Epoch: 6| Step: 12
Training loss: 0.359845599667909
Validation loss: 2.907699613106889

Epoch: 6| Step: 13
Training loss: 0.2508951196001263
Validation loss: 2.887954124090717

Epoch: 377| Step: 0
Training loss: 0.39879139909518396
Validation loss: 2.9139558228849

Epoch: 6| Step: 1
Training loss: 0.497587373479565
Validation loss: 2.8792768677205394

Epoch: 6| Step: 2
Training loss: 0.3333193532674433
Validation loss: 2.9132424326477873

Epoch: 6| Step: 3
Training loss: 0.4676273890446765
Validation loss: 2.9193210557785583

Epoch: 6| Step: 4
Training loss: 0.677843222548387
Validation loss: 2.9539851663320777

Epoch: 6| Step: 5
Training loss: 0.3256253214667961
Validation loss: 2.933772691601816

Epoch: 6| Step: 6
Training loss: 0.4446250561791085
Validation loss: 2.956159939513114

Epoch: 6| Step: 7
Training loss: 0.3779204019987878
Validation loss: 2.90388304877555

Epoch: 6| Step: 8
Training loss: 0.3692126330023531
Validation loss: 2.955240127953596

Epoch: 6| Step: 9
Training loss: 0.3705229535425136
Validation loss: 2.904215028452273

Epoch: 6| Step: 10
Training loss: 0.40840525391124666
Validation loss: 2.858846674681303

Epoch: 6| Step: 11
Training loss: 0.5203198062967982
Validation loss: 2.8707350180243636

Epoch: 6| Step: 12
Training loss: 0.31547871967374613
Validation loss: 2.872433484344563

Epoch: 6| Step: 13
Training loss: 0.5385042976926917
Validation loss: 2.856205961192588

Epoch: 378| Step: 0
Training loss: 0.4353519568050031
Validation loss: 2.86938547535616

Epoch: 6| Step: 1
Training loss: 0.32987865086262946
Validation loss: 2.9105392852562737

Epoch: 6| Step: 2
Training loss: 0.43040486188778404
Validation loss: 2.8618522710786927

Epoch: 6| Step: 3
Training loss: 0.46734405114544575
Validation loss: 2.9026595260914574

Epoch: 6| Step: 4
Training loss: 0.4986181087395432
Validation loss: 2.9489071308749737

Epoch: 6| Step: 5
Training loss: 0.24284567153459086
Validation loss: 2.975502339327938

Epoch: 6| Step: 6
Training loss: 0.32297734362164354
Validation loss: 2.9446034813362507

Epoch: 6| Step: 7
Training loss: 0.30939349832043894
Validation loss: 2.891856424406528

Epoch: 6| Step: 8
Training loss: 0.3852137555568925
Validation loss: 2.8682961602898938

Epoch: 6| Step: 9
Training loss: 0.3959092916422543
Validation loss: 2.939853145041327

Epoch: 6| Step: 10
Training loss: 0.5209826509695276
Validation loss: 2.960755355184618

Epoch: 6| Step: 11
Training loss: 0.33198708633218404
Validation loss: 2.833178380394156

Epoch: 6| Step: 12
Training loss: 0.35114841446464934
Validation loss: 2.928184720641188

Epoch: 6| Step: 13
Training loss: 0.4433392423520395
Validation loss: 2.9335521520652947

Epoch: 379| Step: 0
Training loss: 0.2961818231930922
Validation loss: 2.907043089035628

Epoch: 6| Step: 1
Training loss: 0.28965947650392754
Validation loss: 2.9435574862089062

Epoch: 6| Step: 2
Training loss: 0.3592283322788946
Validation loss: 2.9134129404529516

Epoch: 6| Step: 3
Training loss: 0.521347971017807
Validation loss: 2.9545228667162724

Epoch: 6| Step: 4
Training loss: 0.42123491684712416
Validation loss: 2.8913555974679976

Epoch: 6| Step: 5
Training loss: 0.3795018774533981
Validation loss: 2.841462175687516

Epoch: 6| Step: 6
Training loss: 0.6777098813426736
Validation loss: 2.9217715457546056

Epoch: 6| Step: 7
Training loss: 0.2863543957658122
Validation loss: 2.8890439220138546

Epoch: 6| Step: 8
Training loss: 0.3538156785079268
Validation loss: 2.9295266340383734

Epoch: 6| Step: 9
Training loss: 0.35326110782423886
Validation loss: 2.8603817083042853

Epoch: 6| Step: 10
Training loss: 0.4443474904329566
Validation loss: 2.9340250957007754

Epoch: 6| Step: 11
Training loss: 0.3773205404469107
Validation loss: 2.9464121552487557

Epoch: 6| Step: 12
Training loss: 0.3226504253757663
Validation loss: 2.8471242078849337

Epoch: 6| Step: 13
Training loss: 0.33434267511720034
Validation loss: 2.905455066976581

Epoch: 380| Step: 0
Training loss: 0.3892566365072552
Validation loss: 3.014146867503713

Epoch: 6| Step: 1
Training loss: 0.40842402563656605
Validation loss: 2.981643132080826

Epoch: 6| Step: 2
Training loss: 0.4846804793812899
Validation loss: 2.9030182415372345

Epoch: 6| Step: 3
Training loss: 0.39311638745333194
Validation loss: 2.903826150583975

Epoch: 6| Step: 4
Training loss: 0.5240259137061353
Validation loss: 2.9491572561021373

Epoch: 6| Step: 5
Training loss: 0.3537481818135583
Validation loss: 2.918770471864581

Epoch: 6| Step: 6
Training loss: 0.3545730960875789
Validation loss: 2.873539415397934

Epoch: 6| Step: 7
Training loss: 0.28653189263743434
Validation loss: 2.944857399450532

Epoch: 6| Step: 8
Training loss: 0.4775017097702173
Validation loss: 2.9727882091960445

Epoch: 6| Step: 9
Training loss: 0.614508791352372
Validation loss: 2.879869538857946

Epoch: 6| Step: 10
Training loss: 0.4455911868563626
Validation loss: 2.8917897120377654

Epoch: 6| Step: 11
Training loss: 0.4458263343933103
Validation loss: 2.9253079379972253

Epoch: 6| Step: 12
Training loss: 0.2813367577361523
Validation loss: 2.919220328709406

Epoch: 6| Step: 13
Training loss: 0.635800055757516
Validation loss: 2.9658032164438386

Epoch: 381| Step: 0
Training loss: 0.548274755648713
Validation loss: 2.925488418708305

Epoch: 6| Step: 1
Training loss: 0.31031323887102225
Validation loss: 3.0250928160454684

Epoch: 6| Step: 2
Training loss: 0.5541710127992312
Validation loss: 2.952953380731294

Epoch: 6| Step: 3
Training loss: 0.5412378233581675
Validation loss: 2.9594471316759723

Epoch: 6| Step: 4
Training loss: 0.42690532936827386
Validation loss: 2.8968718859653406

Epoch: 6| Step: 5
Training loss: 0.2826912298536289
Validation loss: 2.9426938396985904

Epoch: 6| Step: 6
Training loss: 0.4006799908298668
Validation loss: 2.9404248090078746

Epoch: 6| Step: 7
Training loss: 0.7857350355975393
Validation loss: 2.887461771856468

Epoch: 6| Step: 8
Training loss: 0.598778313383458
Validation loss: 2.8789953306883933

Epoch: 6| Step: 9
Training loss: 0.6203708880640066
Validation loss: 2.9534388649544168

Epoch: 6| Step: 10
Training loss: 0.3577036971204832
Validation loss: 2.8906904195994967

Epoch: 6| Step: 11
Training loss: 0.38568454746370473
Validation loss: 2.9258206903424777

Epoch: 6| Step: 12
Training loss: 0.3714515166085965
Validation loss: 2.944756952132203

Epoch: 6| Step: 13
Training loss: 0.4001596296198243
Validation loss: 2.9657737000585023

Epoch: 382| Step: 0
Training loss: 0.3537364712476995
Validation loss: 2.903956201955178

Epoch: 6| Step: 1
Training loss: 0.4062033039545598
Validation loss: 2.894795881453378

Epoch: 6| Step: 2
Training loss: 0.7108881587418301
Validation loss: 2.881150963461012

Epoch: 6| Step: 3
Training loss: 0.37315846317083157
Validation loss: 2.8821286955818826

Epoch: 6| Step: 4
Training loss: 0.505393797138736
Validation loss: 2.910970771013796

Epoch: 6| Step: 5
Training loss: 0.41625036861071146
Validation loss: 2.906217157868799

Epoch: 6| Step: 6
Training loss: 0.33805968625094335
Validation loss: 3.0163969326789295

Epoch: 6| Step: 7
Training loss: 0.38134451069920483
Validation loss: 3.002712851038173

Epoch: 6| Step: 8
Training loss: 0.3890466847709792
Validation loss: 2.9201257266668894

Epoch: 6| Step: 9
Training loss: 0.24310344875106663
Validation loss: 2.9447596779106777

Epoch: 6| Step: 10
Training loss: 0.3476170828540806
Validation loss: 2.9296829427047886

Epoch: 6| Step: 11
Training loss: 0.2955406972434591
Validation loss: 2.9540647326819163

Epoch: 6| Step: 12
Training loss: 0.394357057396001
Validation loss: 2.959384292754448

Epoch: 6| Step: 13
Training loss: 0.3655271733472398
Validation loss: 2.9956636613345653

Epoch: 383| Step: 0
Training loss: 0.27342179117038523
Validation loss: 2.9263910355027223

Epoch: 6| Step: 1
Training loss: 0.3757995981665996
Validation loss: 2.926172723457262

Epoch: 6| Step: 2
Training loss: 0.35722839872243906
Validation loss: 2.9562125103477364

Epoch: 6| Step: 3
Training loss: 0.5527035869744956
Validation loss: 2.9418818885879796

Epoch: 6| Step: 4
Training loss: 0.4617935894568679
Validation loss: 2.927533849253912

Epoch: 6| Step: 5
Training loss: 0.36835881351496924
Validation loss: 2.8982903785074408

Epoch: 6| Step: 6
Training loss: 0.3830062803931282
Validation loss: 2.911888177266968

Epoch: 6| Step: 7
Training loss: 0.3342203455526209
Validation loss: 2.86586379592322

Epoch: 6| Step: 8
Training loss: 0.3164212258644824
Validation loss: 2.957066618465552

Epoch: 6| Step: 9
Training loss: 0.401060688096148
Validation loss: 2.9405742412514537

Epoch: 6| Step: 10
Training loss: 0.353744580223972
Validation loss: 2.8773440190209043

Epoch: 6| Step: 11
Training loss: 0.39855953292495994
Validation loss: 2.880377632854079

Epoch: 6| Step: 12
Training loss: 0.6256185093789766
Validation loss: 2.907281877006214

Epoch: 6| Step: 13
Training loss: 0.4203509777565923
Validation loss: 2.9473313378418826

Epoch: 384| Step: 0
Training loss: 0.32371085957650164
Validation loss: 2.9131487384454497

Epoch: 6| Step: 1
Training loss: 0.36161837905165634
Validation loss: 2.9010225406109855

Epoch: 6| Step: 2
Training loss: 0.5334210072913748
Validation loss: 2.9464261271038623

Epoch: 6| Step: 3
Training loss: 0.25394979250291616
Validation loss: 2.8767276493414378

Epoch: 6| Step: 4
Training loss: 0.391048487940973
Validation loss: 2.93620151200959

Epoch: 6| Step: 5
Training loss: 0.3968839464155467
Validation loss: 2.858082644272965

Epoch: 6| Step: 6
Training loss: 0.3441495957001009
Validation loss: 2.970702576579742

Epoch: 6| Step: 7
Training loss: 0.35269845122688687
Validation loss: 2.8640362905026966

Epoch: 6| Step: 8
Training loss: 0.41524911389609453
Validation loss: 2.8315580687449446

Epoch: 6| Step: 9
Training loss: 0.42299397737530786
Validation loss: 2.8245944331220625

Epoch: 6| Step: 10
Training loss: 0.6771627428487403
Validation loss: 2.8933350652112333

Epoch: 6| Step: 11
Training loss: 0.3362470021699196
Validation loss: 2.8897042534978756

Epoch: 6| Step: 12
Training loss: 0.4601771176695508
Validation loss: 2.929335102503848

Epoch: 6| Step: 13
Training loss: 0.3220694204749529
Validation loss: 2.8999241309271637

Epoch: 385| Step: 0
Training loss: 0.40128505636833595
Validation loss: 2.910075824488157

Epoch: 6| Step: 1
Training loss: 0.39848009517596933
Validation loss: 2.9075474047875876

Epoch: 6| Step: 2
Training loss: 0.40281508901398844
Validation loss: 2.9141117599728252

Epoch: 6| Step: 3
Training loss: 0.4308997999025714
Validation loss: 2.8503620564668557

Epoch: 6| Step: 4
Training loss: 0.30311075009938115
Validation loss: 2.871743583232124

Epoch: 6| Step: 5
Training loss: 0.7319994305806473
Validation loss: 2.924073994877475

Epoch: 6| Step: 6
Training loss: 0.4017290957234068
Validation loss: 2.959269648566284

Epoch: 6| Step: 7
Training loss: 0.41000901258844
Validation loss: 2.9132764777201308

Epoch: 6| Step: 8
Training loss: 0.546458330822197
Validation loss: 2.9681746745201725

Epoch: 6| Step: 9
Training loss: 0.4256825113862523
Validation loss: 2.9582617083909657

Epoch: 6| Step: 10
Training loss: 0.4447552389851654
Validation loss: 2.95326595878245

Epoch: 6| Step: 11
Training loss: 0.42948253251239576
Validation loss: 2.997210967822821

Epoch: 6| Step: 12
Training loss: 0.3955935726670123
Validation loss: 2.9697908551123473

Epoch: 6| Step: 13
Training loss: 0.40630541936962616
Validation loss: 2.976069558911617

Epoch: 386| Step: 0
Training loss: 0.5927011863755836
Validation loss: 2.9392933951034004

Epoch: 6| Step: 1
Training loss: 0.4290210410451206
Validation loss: 2.854151709487223

Epoch: 6| Step: 2
Training loss: 0.39702623669650483
Validation loss: 2.860528723588692

Epoch: 6| Step: 3
Training loss: 0.31461557492554787
Validation loss: 2.849502460373138

Epoch: 6| Step: 4
Training loss: 0.2888869190505515
Validation loss: 2.859159888842547

Epoch: 6| Step: 5
Training loss: 0.5268321345891994
Validation loss: 2.9170416091429052

Epoch: 6| Step: 6
Training loss: 0.3924572696933953
Validation loss: 2.8615930844687023

Epoch: 6| Step: 7
Training loss: 0.3898011484357221
Validation loss: 2.884908574031353

Epoch: 6| Step: 8
Training loss: 0.3386076887260464
Validation loss: 2.8874658177982377

Epoch: 6| Step: 9
Training loss: 0.3922973501766483
Validation loss: 2.8004666075878935

Epoch: 6| Step: 10
Training loss: 0.35719692468098935
Validation loss: 2.934212475041431

Epoch: 6| Step: 11
Training loss: 0.5737887738409101
Validation loss: 2.944810171825953

Epoch: 6| Step: 12
Training loss: 0.4645825301221852
Validation loss: 2.8980723902539816

Epoch: 6| Step: 13
Training loss: 0.4478787879304565
Validation loss: 2.9115125665862425

Epoch: 387| Step: 0
Training loss: 0.36998974057742884
Validation loss: 2.8448210714844264

Epoch: 6| Step: 1
Training loss: 0.35099582566186366
Validation loss: 2.8959558904680054

Epoch: 6| Step: 2
Training loss: 0.5402379971573793
Validation loss: 2.9375389989333787

Epoch: 6| Step: 3
Training loss: 0.39152014211748154
Validation loss: 2.926440651456995

Epoch: 6| Step: 4
Training loss: 0.4468922284946688
Validation loss: 2.8534041706506508

Epoch: 6| Step: 5
Training loss: 0.4417962233642306
Validation loss: 2.9086209268843213

Epoch: 6| Step: 6
Training loss: 0.3402075190844878
Validation loss: 2.9751908486856444

Epoch: 6| Step: 7
Training loss: 0.2801238933713299
Validation loss: 3.0442659080515564

Epoch: 6| Step: 8
Training loss: 0.41469142940703463
Validation loss: 2.9503939613388406

Epoch: 6| Step: 9
Training loss: 0.517621193299509
Validation loss: 2.972166498103519

Epoch: 6| Step: 10
Training loss: 0.48024394040551815
Validation loss: 2.9500876521434725

Epoch: 6| Step: 11
Training loss: 0.26972508026091446
Validation loss: 2.872118756974037

Epoch: 6| Step: 12
Training loss: 0.5882663729991523
Validation loss: 2.896154157215912

Epoch: 6| Step: 13
Training loss: 0.3632834649787565
Validation loss: 2.915266372959638

Epoch: 388| Step: 0
Training loss: 0.2948939329135736
Validation loss: 2.8958730809253437

Epoch: 6| Step: 1
Training loss: 0.5403961601376438
Validation loss: 2.8918318694870595

Epoch: 6| Step: 2
Training loss: 0.4592181482924406
Validation loss: 2.910010806551921

Epoch: 6| Step: 3
Training loss: 0.2232369162804087
Validation loss: 2.856016622256322

Epoch: 6| Step: 4
Training loss: 0.5943880417493069
Validation loss: 2.905748289822215

Epoch: 6| Step: 5
Training loss: 0.48948781285588777
Validation loss: 2.917765769043623

Epoch: 6| Step: 6
Training loss: 0.30144952871694214
Validation loss: 2.8917869225890316

Epoch: 6| Step: 7
Training loss: 0.2574299372566792
Validation loss: 2.93560975041908

Epoch: 6| Step: 8
Training loss: 0.49928078482399013
Validation loss: 2.897189287120586

Epoch: 6| Step: 9
Training loss: 0.3218775175051707
Validation loss: 2.8311809938398795

Epoch: 6| Step: 10
Training loss: 0.388530475448466
Validation loss: 2.9315806803546045

Epoch: 6| Step: 11
Training loss: 0.5129477324582443
Validation loss: 2.8994482425342323

Epoch: 6| Step: 12
Training loss: 0.44092641761094664
Validation loss: 2.8507616703988075

Epoch: 6| Step: 13
Training loss: 0.39439072325205654
Validation loss: 2.872563048009182

Epoch: 389| Step: 0
Training loss: 0.35282694931445935
Validation loss: 2.918850970921263

Epoch: 6| Step: 1
Training loss: 0.3584178534713309
Validation loss: 2.9523667265216758

Epoch: 6| Step: 2
Training loss: 0.4192273451087153
Validation loss: 2.873531422576164

Epoch: 6| Step: 3
Training loss: 0.4376694317119257
Validation loss: 2.978514304238949

Epoch: 6| Step: 4
Training loss: 0.37608399280653976
Validation loss: 3.011825856482511

Epoch: 6| Step: 5
Training loss: 0.4323005120012074
Validation loss: 3.003131278696685

Epoch: 6| Step: 6
Training loss: 0.6060792122002354
Validation loss: 2.9065236061949205

Epoch: 6| Step: 7
Training loss: 0.4210379738750339
Validation loss: 2.8792978449158997

Epoch: 6| Step: 8
Training loss: 0.42630805227131935
Validation loss: 2.9407486098089275

Epoch: 6| Step: 9
Training loss: 0.2929365140346101
Validation loss: 2.866258711581904

Epoch: 6| Step: 10
Training loss: 0.38389473350928927
Validation loss: 2.9317542894232864

Epoch: 6| Step: 11
Training loss: 0.4386454301643678
Validation loss: 2.843375142860775

Epoch: 6| Step: 12
Training loss: 0.6487784351151658
Validation loss: 2.931465348695359

Epoch: 6| Step: 13
Training loss: 0.44346792093871107
Validation loss: 2.865932026885152

Epoch: 390| Step: 0
Training loss: 0.41959116133225666
Validation loss: 2.870098524540235

Epoch: 6| Step: 1
Training loss: 0.4325070897662362
Validation loss: 2.853753405722258

Epoch: 6| Step: 2
Training loss: 0.3751274925309289
Validation loss: 2.907288396585872

Epoch: 6| Step: 3
Training loss: 0.31320013056727375
Validation loss: 2.889964562653097

Epoch: 6| Step: 4
Training loss: 0.42088983442891703
Validation loss: 2.886559591693493

Epoch: 6| Step: 5
Training loss: 0.26293965147501513
Validation loss: 2.9264281728656822

Epoch: 6| Step: 6
Training loss: 0.4605613078540536
Validation loss: 2.8260284436642196

Epoch: 6| Step: 7
Training loss: 0.3317107168115274
Validation loss: 2.877217432792203

Epoch: 6| Step: 8
Training loss: 0.5063293218282156
Validation loss: 2.9390800839239

Epoch: 6| Step: 9
Training loss: 0.3317264953442158
Validation loss: 2.936829158936367

Epoch: 6| Step: 10
Training loss: 0.7016516189215091
Validation loss: 2.8785559735744766

Epoch: 6| Step: 11
Training loss: 0.38849917845105236
Validation loss: 2.882543218729253

Epoch: 6| Step: 12
Training loss: 0.23522784515105147
Validation loss: 2.949445730068437

Epoch: 6| Step: 13
Training loss: 0.39365932692151756
Validation loss: 2.8550191474000797

Epoch: 391| Step: 0
Training loss: 0.5309791154813406
Validation loss: 2.909188497529355

Epoch: 6| Step: 1
Training loss: 0.42662690553259164
Validation loss: 3.019218609586182

Epoch: 6| Step: 2
Training loss: 0.22264171017471945
Validation loss: 2.97488040737123

Epoch: 6| Step: 3
Training loss: 0.33747505254730237
Validation loss: 2.943716842993779

Epoch: 6| Step: 4
Training loss: 0.6544867852015647
Validation loss: 2.9499264707938417

Epoch: 6| Step: 5
Training loss: 0.40129918545669524
Validation loss: 2.8964232157284258

Epoch: 6| Step: 6
Training loss: 0.42424266951482154
Validation loss: 2.905983533231074

Epoch: 6| Step: 7
Training loss: 0.38834866067137985
Validation loss: 2.9399855493765625

Epoch: 6| Step: 8
Training loss: 0.3113796895017441
Validation loss: 2.963574955132589

Epoch: 6| Step: 9
Training loss: 0.30778893414442
Validation loss: 2.8881881064613237

Epoch: 6| Step: 10
Training loss: 0.37836921623958786
Validation loss: 2.8707410530868462

Epoch: 6| Step: 11
Training loss: 0.3416164466926125
Validation loss: 2.8514540838943523

Epoch: 6| Step: 12
Training loss: 0.5246033282581237
Validation loss: 2.8507562899853705

Epoch: 6| Step: 13
Training loss: 0.36985624671777584
Validation loss: 2.851695826649095

Epoch: 392| Step: 0
Training loss: 0.39798748557864927
Validation loss: 2.953551825032579

Epoch: 6| Step: 1
Training loss: 0.39863972113536783
Validation loss: 2.8694606020032354

Epoch: 6| Step: 2
Training loss: 0.42792087129732936
Validation loss: 2.954187945319312

Epoch: 6| Step: 3
Training loss: 0.4827825456728177
Validation loss: 2.962303671789835

Epoch: 6| Step: 4
Training loss: 0.4405449422518916
Validation loss: 2.9886239846346014

Epoch: 6| Step: 5
Training loss: 0.3267842557414468
Validation loss: 2.936279746844522

Epoch: 6| Step: 6
Training loss: 0.2723051329836049
Validation loss: 2.9275689565028253

Epoch: 6| Step: 7
Training loss: 0.6009925272361175
Validation loss: 3.0150909609803875

Epoch: 6| Step: 8
Training loss: 0.39980241321090165
Validation loss: 2.937890304175202

Epoch: 6| Step: 9
Training loss: 0.37270383391090794
Validation loss: 3.0279081872587126

Epoch: 6| Step: 10
Training loss: 0.3349914425675024
Validation loss: 3.054212944717525

Epoch: 6| Step: 11
Training loss: 0.2971728111070627
Validation loss: 2.912054875403492

Epoch: 6| Step: 12
Training loss: 0.47243989769087086
Validation loss: 2.9413511314141814

Epoch: 6| Step: 13
Training loss: 0.3981810473720244
Validation loss: 2.90684585889132

Epoch: 393| Step: 0
Training loss: 0.3801093909017064
Validation loss: 2.965869777963222

Epoch: 6| Step: 1
Training loss: 0.3344425716931658
Validation loss: 2.9919132010658323

Epoch: 6| Step: 2
Training loss: 0.3871730101601192
Validation loss: 2.8700330370819165

Epoch: 6| Step: 3
Training loss: 0.43728296823136065
Validation loss: 2.8083213564412652

Epoch: 6| Step: 4
Training loss: 0.36315216314125076
Validation loss: 2.9251195263690564

Epoch: 6| Step: 5
Training loss: 0.5719762858346802
Validation loss: 2.925131439994362

Epoch: 6| Step: 6
Training loss: 0.3396045347140415
Validation loss: 2.9012375268389996

Epoch: 6| Step: 7
Training loss: 0.4394984582194777
Validation loss: 2.963868340497785

Epoch: 6| Step: 8
Training loss: 0.4352951006345688
Validation loss: 2.9381714317289918

Epoch: 6| Step: 9
Training loss: 0.3201483212704474
Validation loss: 2.9313640764781814

Epoch: 6| Step: 10
Training loss: 0.491773915985838
Validation loss: 2.9810202818629215

Epoch: 6| Step: 11
Training loss: 0.4726309336037847
Validation loss: 2.936142350690991

Epoch: 6| Step: 12
Training loss: 0.4971210026703813
Validation loss: 2.7633023755264805

Epoch: 6| Step: 13
Training loss: 0.44388230191721123
Validation loss: 2.930585338768619

Epoch: 394| Step: 0
Training loss: 0.3925939528277929
Validation loss: 2.9310888846663894

Epoch: 6| Step: 1
Training loss: 0.37933156633691817
Validation loss: 2.888802787422808

Epoch: 6| Step: 2
Training loss: 0.38679436223819025
Validation loss: 2.8568523653833844

Epoch: 6| Step: 3
Training loss: 0.39775966506187027
Validation loss: 2.9419208564477417

Epoch: 6| Step: 4
Training loss: 0.3217650948075849
Validation loss: 2.9557807996276018

Epoch: 6| Step: 5
Training loss: 0.508195321963644
Validation loss: 2.8139333392799073

Epoch: 6| Step: 6
Training loss: 0.2504901848733708
Validation loss: 2.912101829172784

Epoch: 6| Step: 7
Training loss: 0.6075830276485699
Validation loss: 2.9382127478817424

Epoch: 6| Step: 8
Training loss: 0.5533865057242654
Validation loss: 2.985189776018932

Epoch: 6| Step: 9
Training loss: 0.41722322089610064
Validation loss: 2.895898068113855

Epoch: 6| Step: 10
Training loss: 0.4078899258890903
Validation loss: 2.8867284407257277

Epoch: 6| Step: 11
Training loss: 0.381814004799879
Validation loss: 2.857969164286674

Epoch: 6| Step: 12
Training loss: 0.47485304491662084
Validation loss: 2.8382018746266153

Epoch: 6| Step: 13
Training loss: 0.522295603037992
Validation loss: 2.9377853444347126

Epoch: 395| Step: 0
Training loss: 0.3032103949139441
Validation loss: 2.8860920874130116

Epoch: 6| Step: 1
Training loss: 0.4146026111638329
Validation loss: 2.9897002663600136

Epoch: 6| Step: 2
Training loss: 0.4261795420879196
Validation loss: 2.9792303643163875

Epoch: 6| Step: 3
Training loss: 0.5619032926724009
Validation loss: 2.8729731560884906

Epoch: 6| Step: 4
Training loss: 0.362763908115663
Validation loss: 2.9405737682910584

Epoch: 6| Step: 5
Training loss: 0.31980527865405417
Validation loss: 2.972668534536289

Epoch: 6| Step: 6
Training loss: 0.5288356728282114
Validation loss: 2.8559071369131432

Epoch: 6| Step: 7
Training loss: 0.42800337463011107
Validation loss: 2.9912524908012648

Epoch: 6| Step: 8
Training loss: 0.4580172474749478
Validation loss: 2.9638242983451257

Epoch: 6| Step: 9
Training loss: 0.3051431256942405
Validation loss: 2.9163951520336506

Epoch: 6| Step: 10
Training loss: 0.455745812974907
Validation loss: 2.896565191608094

Epoch: 6| Step: 11
Training loss: 0.4140649471570521
Validation loss: 2.838722773849294

Epoch: 6| Step: 12
Training loss: 0.4929259074557645
Validation loss: 2.8460630644363025

Epoch: 6| Step: 13
Training loss: 0.4681891105612951
Validation loss: 2.848852128880109

Epoch: 396| Step: 0
Training loss: 0.49231627459965943
Validation loss: 2.8070876708546195

Epoch: 6| Step: 1
Training loss: 0.3415142089406691
Validation loss: 2.8588887480422627

Epoch: 6| Step: 2
Training loss: 0.43974379357387194
Validation loss: 2.9306598863717053

Epoch: 6| Step: 3
Training loss: 0.30606494002706525
Validation loss: 2.8756124839186987

Epoch: 6| Step: 4
Training loss: 0.25446191287069714
Validation loss: 2.925124892261032

Epoch: 6| Step: 5
Training loss: 0.4225916250748523
Validation loss: 2.9929244658598533

Epoch: 6| Step: 6
Training loss: 0.39929092859577275
Validation loss: 2.9268807084259163

Epoch: 6| Step: 7
Training loss: 0.3774300360108213
Validation loss: 2.9161819236844475

Epoch: 6| Step: 8
Training loss: 0.4442211631685204
Validation loss: 2.919250805820411

Epoch: 6| Step: 9
Training loss: 0.5226340033981236
Validation loss: 2.9524888794959003

Epoch: 6| Step: 10
Training loss: 0.39280394327074264
Validation loss: 2.933975106894534

Epoch: 6| Step: 11
Training loss: 0.36583493066553413
Validation loss: 2.9005310093121297

Epoch: 6| Step: 12
Training loss: 0.3087807583642356
Validation loss: 2.8910406415262697

Epoch: 6| Step: 13
Training loss: 0.6153312970066094
Validation loss: 2.9119075617375545

Epoch: 397| Step: 0
Training loss: 0.4216936569408935
Validation loss: 2.942431794172559

Epoch: 6| Step: 1
Training loss: 0.3198619325256144
Validation loss: 2.8768329306065294

Epoch: 6| Step: 2
Training loss: 0.3501232036808706
Validation loss: 2.949747902933744

Epoch: 6| Step: 3
Training loss: 0.4124919327033735
Validation loss: 2.899781319166993

Epoch: 6| Step: 4
Training loss: 0.3771855324707294
Validation loss: 2.8750479459219984

Epoch: 6| Step: 5
Training loss: 0.3987704176443805
Validation loss: 2.881004393639878

Epoch: 6| Step: 6
Training loss: 0.2576983806155108
Validation loss: 2.8782187425532024

Epoch: 6| Step: 7
Training loss: 0.4281027440043089
Validation loss: 2.8700642095753306

Epoch: 6| Step: 8
Training loss: 0.5188106616297481
Validation loss: 2.875775674864458

Epoch: 6| Step: 9
Training loss: 0.5409135412312875
Validation loss: 2.943736956028207

Epoch: 6| Step: 10
Training loss: 0.33505814812724255
Validation loss: 2.876817198056726

Epoch: 6| Step: 11
Training loss: 0.4400093288678958
Validation loss: 2.9039394942925805

Epoch: 6| Step: 12
Training loss: 0.3420773254769916
Validation loss: 2.911142135310012

Epoch: 6| Step: 13
Training loss: 0.3324448421805648
Validation loss: 2.9294651608339772

Epoch: 398| Step: 0
Training loss: 0.3395635392362524
Validation loss: 2.925916409734103

Epoch: 6| Step: 1
Training loss: 0.5674519324426823
Validation loss: 2.957042309409877

Epoch: 6| Step: 2
Training loss: 0.4746719758619964
Validation loss: 2.939215909694812

Epoch: 6| Step: 3
Training loss: 0.2539721770160367
Validation loss: 2.9001971692988255

Epoch: 6| Step: 4
Training loss: 0.284362419604703
Validation loss: 2.8941481006779943

Epoch: 6| Step: 5
Training loss: 0.3598479807278267
Validation loss: 2.9459012199539956

Epoch: 6| Step: 6
Training loss: 0.46975257468418874
Validation loss: 2.9361966535589485

Epoch: 6| Step: 7
Training loss: 0.36175402722624783
Validation loss: 2.896681796218406

Epoch: 6| Step: 8
Training loss: 0.28503926372690874
Validation loss: 2.8901251764588496

Epoch: 6| Step: 9
Training loss: 0.3779281103608888
Validation loss: 2.936519120854583

Epoch: 6| Step: 10
Training loss: 0.46009800320481986
Validation loss: 2.884228297532812

Epoch: 6| Step: 11
Training loss: 0.38037181849282087
Validation loss: 2.8309727165967304

Epoch: 6| Step: 12
Training loss: 0.4164104110767522
Validation loss: 2.8622695641307843

Epoch: 6| Step: 13
Training loss: 0.27007369038077966
Validation loss: 2.8997129254371203

Epoch: 399| Step: 0
Training loss: 0.3838817688305746
Validation loss: 2.930564701574275

Epoch: 6| Step: 1
Training loss: 0.31412346660939544
Validation loss: 2.9704606732462717

Epoch: 6| Step: 2
Training loss: 0.27217316555814614
Validation loss: 2.9207810990854868

Epoch: 6| Step: 3
Training loss: 0.4297950956707382
Validation loss: 2.941511391241943

Epoch: 6| Step: 4
Training loss: 0.3488006935568518
Validation loss: 3.026753791011651

Epoch: 6| Step: 5
Training loss: 0.43160525561107854
Validation loss: 2.9987138534345474

Epoch: 6| Step: 6
Training loss: 0.48726864912750006
Validation loss: 2.933654730341223

Epoch: 6| Step: 7
Training loss: 0.43494746954304936
Validation loss: 2.981307885269794

Epoch: 6| Step: 8
Training loss: 0.20349354505201442
Validation loss: 2.8890749237690185

Epoch: 6| Step: 9
Training loss: 0.33327874715216693
Validation loss: 2.928604970356683

Epoch: 6| Step: 10
Training loss: 0.34323966551002105
Validation loss: 2.9625166722189347

Epoch: 6| Step: 11
Training loss: 0.39581635296523104
Validation loss: 2.890821089408445

Epoch: 6| Step: 12
Training loss: 0.38373289595146143
Validation loss: 2.906168331516433

Epoch: 6| Step: 13
Training loss: 0.33585977764154307
Validation loss: 2.9511663948915383

Epoch: 400| Step: 0
Training loss: 0.3979377978973688
Validation loss: 2.8939946921852857

Epoch: 6| Step: 1
Training loss: 0.3074528573115434
Validation loss: 2.953337094933875

Epoch: 6| Step: 2
Training loss: 0.43621412408429494
Validation loss: 3.0229360869450077

Epoch: 6| Step: 3
Training loss: 0.3595386630027244
Validation loss: 2.9105067236221456

Epoch: 6| Step: 4
Training loss: 0.3851540633133722
Validation loss: 2.923389429933765

Epoch: 6| Step: 5
Training loss: 0.3571123127137374
Validation loss: 2.949872562112758

Epoch: 6| Step: 6
Training loss: 0.2860692184656098
Validation loss: 2.8668069751542697

Epoch: 6| Step: 7
Training loss: 0.3943840923258711
Validation loss: 2.9222506657325322

Epoch: 6| Step: 8
Training loss: 0.5266133654558991
Validation loss: 2.9281104017916335

Epoch: 6| Step: 9
Training loss: 0.4211627634711952
Validation loss: 2.910583089295073

Epoch: 6| Step: 10
Training loss: 0.3809428196974496
Validation loss: 2.90964680080542

Epoch: 6| Step: 11
Training loss: 0.4463797379079094
Validation loss: 2.945456409395779

Epoch: 6| Step: 12
Training loss: 0.5383810629023895
Validation loss: 2.922581442771469

Epoch: 6| Step: 13
Training loss: 0.43624292018140703
Validation loss: 2.948249923866064

Testing loss: 2.692222943784613
