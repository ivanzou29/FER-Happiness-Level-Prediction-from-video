Epoch: 1| Step: 0
Training loss: 6.859273227640505
Validation loss: 6.1395683123565865

Epoch: 6| Step: 1
Training loss: 5.112221021432139
Validation loss: 6.112912505934996

Epoch: 6| Step: 2
Training loss: 6.09248659779699
Validation loss: 6.092118186585731

Epoch: 6| Step: 3
Training loss: 5.637747836533216
Validation loss: 6.072596005523272

Epoch: 6| Step: 4
Training loss: 6.2077281409445595
Validation loss: 6.053446324606082

Epoch: 6| Step: 5
Training loss: 6.630221630321833
Validation loss: 6.035055827567621

Epoch: 6| Step: 6
Training loss: 5.680090468854788
Validation loss: 6.017012795225325

Epoch: 6| Step: 7
Training loss: 6.926709555577885
Validation loss: 6.000243473411227

Epoch: 6| Step: 8
Training loss: 5.996943330996679
Validation loss: 5.980213627438864

Epoch: 6| Step: 9
Training loss: 6.350547418502474
Validation loss: 5.965422816419815

Epoch: 6| Step: 10
Training loss: 6.527655821758968
Validation loss: 5.94392943701398

Epoch: 6| Step: 11
Training loss: 6.15424542782368
Validation loss: 5.928603859428082

Epoch: 6| Step: 12
Training loss: 5.681870913174164
Validation loss: 5.909063755542105

Epoch: 6| Step: 13
Training loss: 5.528098550218928
Validation loss: 5.892214586749856

Epoch: 2| Step: 0
Training loss: 5.8507240825421825
Validation loss: 5.873239726959914

Epoch: 6| Step: 1
Training loss: 6.408977839581144
Validation loss: 5.856662783736344

Epoch: 6| Step: 2
Training loss: 5.776402436098074
Validation loss: 5.837358185204769

Epoch: 6| Step: 3
Training loss: 5.651645029323372
Validation loss: 5.82029737090805

Epoch: 6| Step: 4
Training loss: 5.874515594640948
Validation loss: 5.796759317208598

Epoch: 6| Step: 5
Training loss: 6.258170318850878
Validation loss: 5.778289091683373

Epoch: 6| Step: 6
Training loss: 6.002225780904212
Validation loss: 5.750934359058297

Epoch: 6| Step: 7
Training loss: 6.62990978334936
Validation loss: 5.727952345268024

Epoch: 6| Step: 8
Training loss: 5.726276385353319
Validation loss: 5.704749864404358

Epoch: 6| Step: 9
Training loss: 5.7550829107044175
Validation loss: 5.6780632736498395

Epoch: 6| Step: 10
Training loss: 5.541200986336056
Validation loss: 5.650902062257688

Epoch: 6| Step: 11
Training loss: 5.710955868964132
Validation loss: 5.620579996284094

Epoch: 6| Step: 12
Training loss: 5.478095565168443
Validation loss: 5.5893353422727925

Epoch: 6| Step: 13
Training loss: 4.915711434023349
Validation loss: 5.558989427878885

Epoch: 3| Step: 0
Training loss: 4.454084968828715
Validation loss: 5.524957155547726

Epoch: 6| Step: 1
Training loss: 5.769122626440372
Validation loss: 5.496808571095124

Epoch: 6| Step: 2
Training loss: 5.346542610257659
Validation loss: 5.461939758389478

Epoch: 6| Step: 3
Training loss: 4.910861623956476
Validation loss: 5.426690095308859

Epoch: 6| Step: 4
Training loss: 5.620247761976856
Validation loss: 5.390510948559489

Epoch: 6| Step: 5
Training loss: 5.765562145024935
Validation loss: 5.350093207334689

Epoch: 6| Step: 6
Training loss: 5.4043805192072405
Validation loss: 5.304883935481438

Epoch: 6| Step: 7
Training loss: 5.560086187339593
Validation loss: 5.264385586904229

Epoch: 6| Step: 8
Training loss: 4.634173805978113
Validation loss: 5.218041986799746

Epoch: 6| Step: 9
Training loss: 5.413103114965755
Validation loss: 5.177771857034975

Epoch: 6| Step: 10
Training loss: 5.687477530969525
Validation loss: 5.128189800007238

Epoch: 6| Step: 11
Training loss: 5.488533204292303
Validation loss: 5.078912824505116

Epoch: 6| Step: 12
Training loss: 5.560175892359835
Validation loss: 5.0181948534101375

Epoch: 6| Step: 13
Training loss: 5.303342218845164
Validation loss: 4.959652872038998

Epoch: 4| Step: 0
Training loss: 5.871917565289442
Validation loss: 4.90656893396139

Epoch: 6| Step: 1
Training loss: 5.782547098999578
Validation loss: 4.8406959011335315

Epoch: 6| Step: 2
Training loss: 5.044933595248678
Validation loss: 4.772060097745773

Epoch: 6| Step: 3
Training loss: 4.201357331520853
Validation loss: 4.70015307508595

Epoch: 6| Step: 4
Training loss: 4.336308094030282
Validation loss: 4.63524290752134

Epoch: 6| Step: 5
Training loss: 4.059617178772353
Validation loss: 4.561434895810288

Epoch: 6| Step: 6
Training loss: 5.073924983377117
Validation loss: 4.488856965655467

Epoch: 6| Step: 7
Training loss: 4.360731125871949
Validation loss: 4.405604213709398

Epoch: 6| Step: 8
Training loss: 4.225489002347534
Validation loss: 4.321858502529135

Epoch: 6| Step: 9
Training loss: 3.212343970639752
Validation loss: 4.2536617100173615

Epoch: 6| Step: 10
Training loss: 4.069494710762963
Validation loss: 4.159786106412284

Epoch: 6| Step: 11
Training loss: 3.8429398341912493
Validation loss: 4.06003785471189

Epoch: 6| Step: 12
Training loss: 4.168775457164353
Validation loss: 3.9819631619489

Epoch: 6| Step: 13
Training loss: 4.0315665187332215
Validation loss: 3.872122075302918

Epoch: 5| Step: 0
Training loss: 4.121492686555689
Validation loss: 3.789939396121205

Epoch: 6| Step: 1
Training loss: 3.2791607699569427
Validation loss: 3.6992836838756302

Epoch: 6| Step: 2
Training loss: 3.2938334097968798
Validation loss: 3.594638327673166

Epoch: 6| Step: 3
Training loss: 4.405436555704541
Validation loss: 3.475113230170947

Epoch: 6| Step: 4
Training loss: 3.3137814903993417
Validation loss: 3.3693282660232478

Epoch: 6| Step: 5
Training loss: 2.719636268418098
Validation loss: 3.265405869622873

Epoch: 6| Step: 6
Training loss: 3.556209833491519
Validation loss: 3.1414467162048108

Epoch: 6| Step: 7
Training loss: 2.847596637536191
Validation loss: 3.063182573092006

Epoch: 6| Step: 8
Training loss: 3.057582098419308
Validation loss: 2.9876698651829905

Epoch: 6| Step: 9
Training loss: 2.448064650803851
Validation loss: 2.8972298298857075

Epoch: 6| Step: 10
Training loss: 3.0951767531104917
Validation loss: 2.837381890089242

Epoch: 6| Step: 11
Training loss: 3.186309442515644
Validation loss: 2.7671619893008677

Epoch: 6| Step: 12
Training loss: 1.9197466470535354
Validation loss: 2.749983816388223

Epoch: 6| Step: 13
Training loss: 3.338531271947587
Validation loss: 2.706725440428578

Epoch: 6| Step: 0
Training loss: 2.5018858472487455
Validation loss: 2.6919853720539146

Epoch: 6| Step: 1
Training loss: 2.5756348577290846
Validation loss: 2.6937852891113656

Epoch: 6| Step: 2
Training loss: 1.79991622305989
Validation loss: 2.7266780970861584

Epoch: 6| Step: 3
Training loss: 2.391297688305293
Validation loss: 2.722749027110868

Epoch: 6| Step: 4
Training loss: 2.4867665038465754
Validation loss: 2.7573704351730397

Epoch: 6| Step: 5
Training loss: 2.63265556071452
Validation loss: 2.761169839469392

Epoch: 6| Step: 6
Training loss: 3.2204481663600664
Validation loss: 2.785973185198198

Epoch: 6| Step: 7
Training loss: 3.1642993979602565
Validation loss: 2.8120231930674766

Epoch: 6| Step: 8
Training loss: 3.0053846989563087
Validation loss: 2.796980147276638

Epoch: 6| Step: 9
Training loss: 2.3361695853691793
Validation loss: 2.786152023639625

Epoch: 6| Step: 10
Training loss: 2.700953851977159
Validation loss: 2.8192659445780794

Epoch: 6| Step: 11
Training loss: 2.958527482516789
Validation loss: 2.798632376889527

Epoch: 6| Step: 12
Training loss: 2.90038503524293
Validation loss: 2.780518967926261

Epoch: 6| Step: 13
Training loss: 2.53323550119056
Validation loss: 2.774641679993468

Epoch: 7| Step: 0
Training loss: 2.762670112999248
Validation loss: 2.748256029214315

Epoch: 6| Step: 1
Training loss: 3.2123559941770456
Validation loss: 2.759668433549339

Epoch: 6| Step: 2
Training loss: 2.875414611111068
Validation loss: 2.7221339275244487

Epoch: 6| Step: 3
Training loss: 2.562830461732874
Validation loss: 2.74674297850191

Epoch: 6| Step: 4
Training loss: 3.035489607759097
Validation loss: 2.7200699594560667

Epoch: 6| Step: 5
Training loss: 3.0897054725696043
Validation loss: 2.6949878294368577

Epoch: 6| Step: 6
Training loss: 2.956096304835882
Validation loss: 2.6975049523374994

Epoch: 6| Step: 7
Training loss: 2.1394358206775776
Validation loss: 2.712576701285449

Epoch: 6| Step: 8
Training loss: 1.8161403666498694
Validation loss: 2.6740056218858776

Epoch: 6| Step: 9
Training loss: 2.804422605113446
Validation loss: 2.6872310947466884

Epoch: 6| Step: 10
Training loss: 2.1180926988468194
Validation loss: 2.7096363649942528

Epoch: 6| Step: 11
Training loss: 2.1981230965769587
Validation loss: 2.6837669216736555

Epoch: 6| Step: 12
Training loss: 2.7562793652274196
Validation loss: 2.683688070017705

Epoch: 6| Step: 13
Training loss: 2.010703295368164
Validation loss: 2.683678593745001

Epoch: 8| Step: 0
Training loss: 2.310751692270569
Validation loss: 2.6958722846289507

Epoch: 6| Step: 1
Training loss: 2.2654295738385284
Validation loss: 2.674328248477942

Epoch: 6| Step: 2
Training loss: 2.911000297061508
Validation loss: 2.717382430545858

Epoch: 6| Step: 3
Training loss: 3.1545472036891025
Validation loss: 2.693050131634667

Epoch: 6| Step: 4
Training loss: 2.6029159187163975
Validation loss: 2.6974978520782846

Epoch: 6| Step: 5
Training loss: 2.1725234566180553
Validation loss: 2.6942455889108325

Epoch: 6| Step: 6
Training loss: 2.00047964066736
Validation loss: 2.67267523042105

Epoch: 6| Step: 7
Training loss: 3.2028629847104177
Validation loss: 2.68372410916172

Epoch: 6| Step: 8
Training loss: 2.645031654875183
Validation loss: 2.676923521939434

Epoch: 6| Step: 9
Training loss: 2.1865861346177935
Validation loss: 2.669969306678895

Epoch: 6| Step: 10
Training loss: 2.347060548479992
Validation loss: 2.685262857850824

Epoch: 6| Step: 11
Training loss: 2.145759605943551
Validation loss: 2.6722765912609443

Epoch: 6| Step: 12
Training loss: 3.2955018569276624
Validation loss: 2.6857597128017723

Epoch: 6| Step: 13
Training loss: 2.877710308804367
Validation loss: 2.6895536663882593

Epoch: 9| Step: 0
Training loss: 2.877435896198377
Validation loss: 2.7010535533529216

Epoch: 6| Step: 1
Training loss: 2.989847169370268
Validation loss: 2.6959330116329827

Epoch: 6| Step: 2
Training loss: 2.1817287061868855
Validation loss: 2.656748915547431

Epoch: 6| Step: 3
Training loss: 2.776171902481708
Validation loss: 2.667042070031951

Epoch: 6| Step: 4
Training loss: 2.722917979288016
Validation loss: 2.6709673940624308

Epoch: 6| Step: 5
Training loss: 2.4497477615677896
Validation loss: 2.6616569091611653

Epoch: 6| Step: 6
Training loss: 2.348121025807051
Validation loss: 2.694556722781426

Epoch: 6| Step: 7
Training loss: 2.2459077708329636
Validation loss: 2.6729297006298682

Epoch: 6| Step: 8
Training loss: 2.673483470385512
Validation loss: 2.6963030335680234

Epoch: 6| Step: 9
Training loss: 3.1356580943352723
Validation loss: 2.67493626230427

Epoch: 6| Step: 10
Training loss: 2.84977134992023
Validation loss: 2.7021001295177007

Epoch: 6| Step: 11
Training loss: 1.9562050299304943
Validation loss: 2.6953539490392164

Epoch: 6| Step: 12
Training loss: 2.791274275650671
Validation loss: 2.664241124762176

Epoch: 6| Step: 13
Training loss: 2.2541403293540014
Validation loss: 2.684520252399829

Epoch: 10| Step: 0
Training loss: 2.1161541546085187
Validation loss: 2.6908708915637147

Epoch: 6| Step: 1
Training loss: 2.508504896749576
Validation loss: 2.680934204497948

Epoch: 6| Step: 2
Training loss: 2.3093470136833387
Validation loss: 2.6488814905451425

Epoch: 6| Step: 3
Training loss: 2.5283908473166155
Validation loss: 2.673474329522512

Epoch: 6| Step: 4
Training loss: 2.7363118314836545
Validation loss: 2.680191185475446

Epoch: 6| Step: 5
Training loss: 2.197299153390026
Validation loss: 2.690314142846502

Epoch: 6| Step: 6
Training loss: 2.9258146602419
Validation loss: 2.682030516321645

Epoch: 6| Step: 7
Training loss: 2.410035561580172
Validation loss: 2.6853639038639883

Epoch: 6| Step: 8
Training loss: 2.9161103035847837
Validation loss: 2.6896851401903907

Epoch: 6| Step: 9
Training loss: 2.700242727460057
Validation loss: 2.6776021363159708

Epoch: 6| Step: 10
Training loss: 2.3501546200146226
Validation loss: 2.682244255362932

Epoch: 6| Step: 11
Training loss: 3.404068554538675
Validation loss: 2.6884035173759124

Epoch: 6| Step: 12
Training loss: 2.2700526677546233
Validation loss: 2.690917717713236

Epoch: 6| Step: 13
Training loss: 2.79550469784179
Validation loss: 2.6972407865381958

Epoch: 11| Step: 0
Training loss: 2.1923698713774518
Validation loss: 2.6909570711317774

Epoch: 6| Step: 1
Training loss: 2.1811938259466204
Validation loss: 2.6673744027417023

Epoch: 6| Step: 2
Training loss: 2.8884618965265143
Validation loss: 2.6656140892577698

Epoch: 6| Step: 3
Training loss: 2.656073800021085
Validation loss: 2.662494253770242

Epoch: 6| Step: 4
Training loss: 2.536560422081805
Validation loss: 2.6683882778625616

Epoch: 6| Step: 5
Training loss: 2.1817354815155094
Validation loss: 2.659458989551469

Epoch: 6| Step: 6
Training loss: 2.3423139114316593
Validation loss: 2.670101782005324

Epoch: 6| Step: 7
Training loss: 2.323648847704348
Validation loss: 2.660016056648112

Epoch: 6| Step: 8
Training loss: 2.692299040057354
Validation loss: 2.658108020270499

Epoch: 6| Step: 9
Training loss: 1.8412236507936295
Validation loss: 2.690157544818029

Epoch: 6| Step: 10
Training loss: 2.7000083817245932
Validation loss: 2.6731042246575725

Epoch: 6| Step: 11
Training loss: 3.1319761610622
Validation loss: 2.6694230174279654

Epoch: 6| Step: 12
Training loss: 2.7963469449027762
Validation loss: 2.680257249176486

Epoch: 6| Step: 13
Training loss: 3.1602298836446168
Validation loss: 2.653687741014513

Epoch: 12| Step: 0
Training loss: 2.4334840214026214
Validation loss: 2.6585305091973135

Epoch: 6| Step: 1
Training loss: 2.7644047173238055
Validation loss: 2.65201426853371

Epoch: 6| Step: 2
Training loss: 2.583753879730604
Validation loss: 2.6690512565301834

Epoch: 6| Step: 3
Training loss: 2.76895906162824
Validation loss: 2.6840721566458874

Epoch: 6| Step: 4
Training loss: 2.3508876706721673
Validation loss: 2.6395398982166856

Epoch: 6| Step: 5
Training loss: 2.5112762773353268
Validation loss: 2.6837215180315224

Epoch: 6| Step: 6
Training loss: 2.3968816923721965
Validation loss: 2.686775065389528

Epoch: 6| Step: 7
Training loss: 2.908854804157038
Validation loss: 2.688432915986025

Epoch: 6| Step: 8
Training loss: 2.5433848988349808
Validation loss: 2.663497596428848

Epoch: 6| Step: 9
Training loss: 2.9719593569619343
Validation loss: 2.66956367685095

Epoch: 6| Step: 10
Training loss: 2.477315216718171
Validation loss: 2.6524575180501246

Epoch: 6| Step: 11
Training loss: 2.3720535271444505
Validation loss: 2.618049274732733

Epoch: 6| Step: 12
Training loss: 2.1467296123556068
Validation loss: 2.671730230919408

Epoch: 6| Step: 13
Training loss: 2.7065633614405162
Validation loss: 2.65710922256913

Epoch: 13| Step: 0
Training loss: 3.004524633602757
Validation loss: 2.6625039919971036

Epoch: 6| Step: 1
Training loss: 2.5737378332546172
Validation loss: 2.6622050681655667

Epoch: 6| Step: 2
Training loss: 2.722383022965444
Validation loss: 2.6651115999359805

Epoch: 6| Step: 3
Training loss: 2.183184481295641
Validation loss: 2.6627410863098526

Epoch: 6| Step: 4
Training loss: 2.824238672885296
Validation loss: 2.682802752842023

Epoch: 6| Step: 5
Training loss: 2.036465448885793
Validation loss: 2.6750327146912385

Epoch: 6| Step: 6
Training loss: 2.250159893712384
Validation loss: 2.6711582761804795

Epoch: 6| Step: 7
Training loss: 2.540860616308732
Validation loss: 2.696553999390486

Epoch: 6| Step: 8
Training loss: 3.0948656941054455
Validation loss: 2.653635690736464

Epoch: 6| Step: 9
Training loss: 2.486272315322668
Validation loss: 2.661660492168694

Epoch: 6| Step: 10
Training loss: 2.604449528908712
Validation loss: 2.6385883851752694

Epoch: 6| Step: 11
Training loss: 2.641797770266372
Validation loss: 2.681685411894698

Epoch: 6| Step: 12
Training loss: 2.2472481323601086
Validation loss: 2.696477518446423

Epoch: 6| Step: 13
Training loss: 2.5825028674099597
Validation loss: 2.6705121362478597

Epoch: 14| Step: 0
Training loss: 2.8187012019025164
Validation loss: 2.6582547868785813

Epoch: 6| Step: 1
Training loss: 2.6082798835551086
Validation loss: 2.641537194634174

Epoch: 6| Step: 2
Training loss: 2.9161286175676095
Validation loss: 2.640398681693347

Epoch: 6| Step: 3
Training loss: 2.1034949964894967
Validation loss: 2.6652932107025924

Epoch: 6| Step: 4
Training loss: 2.4552402002799147
Validation loss: 2.641244413120507

Epoch: 6| Step: 5
Training loss: 2.9531143430487274
Validation loss: 2.6284618861808338

Epoch: 6| Step: 6
Training loss: 2.1887870272168315
Validation loss: 2.6544973986784117

Epoch: 6| Step: 7
Training loss: 2.3673893304273568
Validation loss: 2.6654334395620682

Epoch: 6| Step: 8
Training loss: 2.325981843426493
Validation loss: 2.658913626957162

Epoch: 6| Step: 9
Training loss: 2.1478854493155235
Validation loss: 2.669700637577273

Epoch: 6| Step: 10
Training loss: 2.250175681143208
Validation loss: 2.6667752144496686

Epoch: 6| Step: 11
Training loss: 2.384853701952809
Validation loss: 2.638303575241492

Epoch: 6| Step: 12
Training loss: 3.316807375531753
Validation loss: 2.6349700101922853

Epoch: 6| Step: 13
Training loss: 2.852534214787476
Validation loss: 2.6384504344381723

Epoch: 15| Step: 0
Training loss: 2.272434708231202
Validation loss: 2.6331574679048884

Epoch: 6| Step: 1
Training loss: 2.6513339158248486
Validation loss: 2.665575718247122

Epoch: 6| Step: 2
Training loss: 2.354008413301405
Validation loss: 2.642682795438168

Epoch: 6| Step: 3
Training loss: 2.5921940560283843
Validation loss: 2.6572072865961007

Epoch: 6| Step: 4
Training loss: 3.310252020654407
Validation loss: 2.6542354199553766

Epoch: 6| Step: 5
Training loss: 2.905478098096013
Validation loss: 2.6520355300211014

Epoch: 6| Step: 6
Training loss: 2.455690439565448
Validation loss: 2.661380525311364

Epoch: 6| Step: 7
Training loss: 2.6565585686466435
Validation loss: 2.6793908046703865

Epoch: 6| Step: 8
Training loss: 2.7560310986152574
Validation loss: 2.6993781639387358

Epoch: 6| Step: 9
Training loss: 2.4752551939439464
Validation loss: 2.685462963296069

Epoch: 6| Step: 10
Training loss: 2.350565752957843
Validation loss: 2.6725298876469483

Epoch: 6| Step: 11
Training loss: 2.6892434608441675
Validation loss: 2.676996843200065

Epoch: 6| Step: 12
Training loss: 2.3090493515906183
Validation loss: 2.6764848289941066

Epoch: 6| Step: 13
Training loss: 1.8448602598661037
Validation loss: 2.6448062995985624

Epoch: 16| Step: 0
Training loss: 2.5212200803404614
Validation loss: 2.6315573956000233

Epoch: 6| Step: 1
Training loss: 2.457776755565931
Validation loss: 2.645048345425632

Epoch: 6| Step: 2
Training loss: 2.172871752012944
Validation loss: 2.6439681700379043

Epoch: 6| Step: 3
Training loss: 2.8305036963280505
Validation loss: 2.6497015698054835

Epoch: 6| Step: 4
Training loss: 2.040188416400324
Validation loss: 2.639487313017211

Epoch: 6| Step: 5
Training loss: 2.428153777473603
Validation loss: 2.6301764961556797

Epoch: 6| Step: 6
Training loss: 2.3256873355621535
Validation loss: 2.6329436453465194

Epoch: 6| Step: 7
Training loss: 2.2897758544101956
Validation loss: 2.6311460327968317

Epoch: 6| Step: 8
Training loss: 2.525502402302006
Validation loss: 2.6524230315953745

Epoch: 6| Step: 9
Training loss: 2.7822274194343186
Validation loss: 2.6355394075984355

Epoch: 6| Step: 10
Training loss: 3.265936585669754
Validation loss: 2.646112086913286

Epoch: 6| Step: 11
Training loss: 2.6960536656457696
Validation loss: 2.6445875964789747

Epoch: 6| Step: 12
Training loss: 2.412455298449404
Validation loss: 2.64610708627718

Epoch: 6| Step: 13
Training loss: 2.9359173670997603
Validation loss: 2.658591939690312

Epoch: 17| Step: 0
Training loss: 2.268410489659481
Validation loss: 2.6476016905997493

Epoch: 6| Step: 1
Training loss: 2.960752295184854
Validation loss: 2.6373742011805636

Epoch: 6| Step: 2
Training loss: 2.6269256250012734
Validation loss: 2.6266031138441805

Epoch: 6| Step: 3
Training loss: 2.6109165046984626
Validation loss: 2.6368760502365514

Epoch: 6| Step: 4
Training loss: 2.598658685222104
Validation loss: 2.6476389413408365

Epoch: 6| Step: 5
Training loss: 3.059801119156921
Validation loss: 2.656717670633923

Epoch: 6| Step: 6
Training loss: 2.557427479749615
Validation loss: 2.663998838915109

Epoch: 6| Step: 7
Training loss: 1.9721417350941517
Validation loss: 2.6574548419741313

Epoch: 6| Step: 8
Training loss: 1.84361318306922
Validation loss: 2.6551342135340867

Epoch: 6| Step: 9
Training loss: 2.816398461869433
Validation loss: 2.6549316725047643

Epoch: 6| Step: 10
Training loss: 1.6865124108462637
Validation loss: 2.6350976703163256

Epoch: 6| Step: 11
Training loss: 2.737506403109931
Validation loss: 2.639714236326717

Epoch: 6| Step: 12
Training loss: 2.920765385583387
Validation loss: 2.628964699808182

Epoch: 6| Step: 13
Training loss: 2.6935580085610553
Validation loss: 2.628860866236137

Epoch: 18| Step: 0
Training loss: 2.0699134298088593
Validation loss: 2.6403640527847276

Epoch: 6| Step: 1
Training loss: 2.4632613578402127
Validation loss: 2.6257441086673805

Epoch: 6| Step: 2
Training loss: 2.7379200652264
Validation loss: 2.639392444740534

Epoch: 6| Step: 3
Training loss: 2.917472092365067
Validation loss: 2.6180096753521807

Epoch: 6| Step: 4
Training loss: 1.9873639522029238
Validation loss: 2.6287420333956844

Epoch: 6| Step: 5
Training loss: 2.3698401365807817
Validation loss: 2.6528784953021862

Epoch: 6| Step: 6
Training loss: 2.6852588623968927
Validation loss: 2.620846156304733

Epoch: 6| Step: 7
Training loss: 1.3225051460093884
Validation loss: 2.602887554108687

Epoch: 6| Step: 8
Training loss: 2.5308509794726857
Validation loss: 2.667563545878761

Epoch: 6| Step: 9
Training loss: 2.7858338033447723
Validation loss: 2.6529196112654203

Epoch: 6| Step: 10
Training loss: 2.4354546597543627
Validation loss: 2.6221634964868508

Epoch: 6| Step: 11
Training loss: 3.1971577956484847
Validation loss: 2.632304941638784

Epoch: 6| Step: 12
Training loss: 3.1242168208061685
Validation loss: 2.6448981717512887

Epoch: 6| Step: 13
Training loss: 2.594708828476046
Validation loss: 2.6369306314366616

Epoch: 19| Step: 0
Training loss: 2.5427296609594863
Validation loss: 2.6479791865457623

Epoch: 6| Step: 1
Training loss: 1.9110262709029027
Validation loss: 2.6117283151390382

Epoch: 6| Step: 2
Training loss: 2.518814245119321
Validation loss: 2.636217294740035

Epoch: 6| Step: 3
Training loss: 2.26342308645519
Validation loss: 2.62404815128388

Epoch: 6| Step: 4
Training loss: 2.4443969962784355
Validation loss: 2.6174781751770304

Epoch: 6| Step: 5
Training loss: 2.6526026199149557
Validation loss: 2.636982167590279

Epoch: 6| Step: 6
Training loss: 2.180306951628672
Validation loss: 2.617356320530258

Epoch: 6| Step: 7
Training loss: 2.7784303237776027
Validation loss: 2.6247741057065364

Epoch: 6| Step: 8
Training loss: 2.240563419192772
Validation loss: 2.623037240244312

Epoch: 6| Step: 9
Training loss: 3.3941425412603206
Validation loss: 2.6422398537010188

Epoch: 6| Step: 10
Training loss: 2.4329909654254362
Validation loss: 2.625491247683294

Epoch: 6| Step: 11
Training loss: 3.0114008120929734
Validation loss: 2.6325954570411607

Epoch: 6| Step: 12
Training loss: 2.063604810333709
Validation loss: 2.626621562922293

Epoch: 6| Step: 13
Training loss: 2.6771377577735294
Validation loss: 2.6411835119325247

Epoch: 20| Step: 0
Training loss: 1.6330501985700883
Validation loss: 2.623137433914311

Epoch: 6| Step: 1
Training loss: 3.0376525589421277
Validation loss: 2.624653959929378

Epoch: 6| Step: 2
Training loss: 3.1399325845855652
Validation loss: 2.618989967149276

Epoch: 6| Step: 3
Training loss: 2.332930757216928
Validation loss: 2.609506066965249

Epoch: 6| Step: 4
Training loss: 2.109707841397929
Validation loss: 2.634095563205469

Epoch: 6| Step: 5
Training loss: 2.478321209099501
Validation loss: 2.6545065974042594

Epoch: 6| Step: 6
Training loss: 2.2567708605664976
Validation loss: 2.5931097948730795

Epoch: 6| Step: 7
Training loss: 2.8735429139790143
Validation loss: 2.6070007212688706

Epoch: 6| Step: 8
Training loss: 2.415587107372289
Validation loss: 2.639271752429754

Epoch: 6| Step: 9
Training loss: 2.450664185004211
Validation loss: 2.601858708317437

Epoch: 6| Step: 10
Training loss: 3.0249021467034845
Validation loss: 2.6231040616972545

Epoch: 6| Step: 11
Training loss: 2.793726592851249
Validation loss: 2.6496704292489803

Epoch: 6| Step: 12
Training loss: 2.6299003999945705
Validation loss: 2.607539027864677

Epoch: 6| Step: 13
Training loss: 1.8134201608000136
Validation loss: 2.625117935074523

Epoch: 21| Step: 0
Training loss: 2.2954381483781665
Validation loss: 2.6411810596072534

Epoch: 6| Step: 1
Training loss: 2.644183047204104
Validation loss: 2.6051470373468173

Epoch: 6| Step: 2
Training loss: 2.5752920596220332
Validation loss: 2.607455897496216

Epoch: 6| Step: 3
Training loss: 2.617912897955961
Validation loss: 2.6315289320082806

Epoch: 6| Step: 4
Training loss: 2.7316243314536677
Validation loss: 2.62346633128867

Epoch: 6| Step: 5
Training loss: 2.6509301262694183
Validation loss: 2.639579114381168

Epoch: 6| Step: 6
Training loss: 2.5541607141555036
Validation loss: 2.6234933677178978

Epoch: 6| Step: 7
Training loss: 3.030371941881085
Validation loss: 2.65083700912718

Epoch: 6| Step: 8
Training loss: 1.8837965297204906
Validation loss: 2.614381080697582

Epoch: 6| Step: 9
Training loss: 2.232268507554442
Validation loss: 2.59871887041597

Epoch: 6| Step: 10
Training loss: 2.192578551256528
Validation loss: 2.6052276179471723

Epoch: 6| Step: 11
Training loss: 2.480578418620156
Validation loss: 2.600346323936446

Epoch: 6| Step: 12
Training loss: 2.919053944480323
Validation loss: 2.634833921052102

Epoch: 6| Step: 13
Training loss: 2.4271350467613635
Validation loss: 2.635601132738398

Epoch: 22| Step: 0
Training loss: 2.5996667868496006
Validation loss: 2.608733945515975

Epoch: 6| Step: 1
Training loss: 1.774616001124337
Validation loss: 2.633077787321154

Epoch: 6| Step: 2
Training loss: 2.979823291326883
Validation loss: 2.606343364186769

Epoch: 6| Step: 3
Training loss: 2.626181291265145
Validation loss: 2.609295240390079

Epoch: 6| Step: 4
Training loss: 2.2399927755648052
Validation loss: 2.615084343030824

Epoch: 6| Step: 5
Training loss: 2.8573381016641486
Validation loss: 2.59773244339717

Epoch: 6| Step: 6
Training loss: 2.652181943472072
Validation loss: 2.6320707821502722

Epoch: 6| Step: 7
Training loss: 2.2770178219747375
Validation loss: 2.5990524096589493

Epoch: 6| Step: 8
Training loss: 2.827440041902172
Validation loss: 2.61311828682977

Epoch: 6| Step: 9
Training loss: 2.528463266043613
Validation loss: 2.623819888224434

Epoch: 6| Step: 10
Training loss: 2.1200942464788297
Validation loss: 2.6348726266408433

Epoch: 6| Step: 11
Training loss: 3.004473371012228
Validation loss: 2.608277293650371

Epoch: 6| Step: 12
Training loss: 2.2205578597977844
Validation loss: 2.6156665235084846

Epoch: 6| Step: 13
Training loss: 2.448061242129135
Validation loss: 2.608399732392548

Epoch: 23| Step: 0
Training loss: 1.856619066738859
Validation loss: 2.6117736238570117

Epoch: 6| Step: 1
Training loss: 2.621235282249044
Validation loss: 2.611018685357664

Epoch: 6| Step: 2
Training loss: 2.2629273237627046
Validation loss: 2.630252548198652

Epoch: 6| Step: 3
Training loss: 2.199165302934859
Validation loss: 2.603767155837838

Epoch: 6| Step: 4
Training loss: 2.7001919572198863
Validation loss: 2.624772955143018

Epoch: 6| Step: 5
Training loss: 2.927819065652994
Validation loss: 2.61287787593013

Epoch: 6| Step: 6
Training loss: 2.0013149230452494
Validation loss: 2.5931498587737636

Epoch: 6| Step: 7
Training loss: 2.343689574416379
Validation loss: 2.609000873965664

Epoch: 6| Step: 8
Training loss: 1.7531785708587586
Validation loss: 2.606801787709311

Epoch: 6| Step: 9
Training loss: 2.647109877648773
Validation loss: 2.615986395646903

Epoch: 6| Step: 10
Training loss: 1.9164650299599966
Validation loss: 2.608121818481426

Epoch: 6| Step: 11
Training loss: 3.80127878255337
Validation loss: 2.6174387948775446

Epoch: 6| Step: 12
Training loss: 2.8296652967318097
Validation loss: 2.6146502441922808

Epoch: 6| Step: 13
Training loss: 2.3878127367598405
Validation loss: 2.6325028083595496

Epoch: 24| Step: 0
Training loss: 2.1369740335389036
Validation loss: 2.6023808319677775

Epoch: 6| Step: 1
Training loss: 2.277623049848712
Validation loss: 2.615840060174886

Epoch: 6| Step: 2
Training loss: 2.704852924544014
Validation loss: 2.6181969057797954

Epoch: 6| Step: 3
Training loss: 2.6769353229460147
Validation loss: 2.6093796141806367

Epoch: 6| Step: 4
Training loss: 2.416761845873861
Validation loss: 2.628321521682501

Epoch: 6| Step: 5
Training loss: 2.698843856812051
Validation loss: 2.6199171265024015

Epoch: 6| Step: 6
Training loss: 2.9741056620664543
Validation loss: 2.6065516625845904

Epoch: 6| Step: 7
Training loss: 1.7372446462581943
Validation loss: 2.6250944120594886

Epoch: 6| Step: 8
Training loss: 2.4475370288576626
Validation loss: 2.6416715395267762

Epoch: 6| Step: 9
Training loss: 3.1736975634203173
Validation loss: 2.6709241309083724

Epoch: 6| Step: 10
Training loss: 3.219624520912969
Validation loss: 2.6471711828865017

Epoch: 6| Step: 11
Training loss: 2.109349681561017
Validation loss: 2.6340010890876373

Epoch: 6| Step: 12
Training loss: 1.7669288074894482
Validation loss: 2.6353652004197317

Epoch: 6| Step: 13
Training loss: 2.2950028035930057
Validation loss: 2.5946479989341142

Epoch: 25| Step: 0
Training loss: 2.0152841915651045
Validation loss: 2.6424844729455463

Epoch: 6| Step: 1
Training loss: 2.1576272739959537
Validation loss: 2.608262234065104

Epoch: 6| Step: 2
Training loss: 3.174718324677016
Validation loss: 2.6342939666798664

Epoch: 6| Step: 3
Training loss: 2.6131274259310113
Validation loss: 2.6261776295900123

Epoch: 6| Step: 4
Training loss: 2.6613739856311143
Validation loss: 2.6042515600990237

Epoch: 6| Step: 5
Training loss: 2.5734781638420268
Validation loss: 2.6079111009367635

Epoch: 6| Step: 6
Training loss: 2.4013955827037132
Validation loss: 2.5791266451079005

Epoch: 6| Step: 7
Training loss: 2.2774471828730447
Validation loss: 2.599411075785326

Epoch: 6| Step: 8
Training loss: 2.5444025313392524
Validation loss: 2.618960987656467

Epoch: 6| Step: 9
Training loss: 2.0287779804587145
Validation loss: 2.599262431260862

Epoch: 6| Step: 10
Training loss: 2.2823162983468053
Validation loss: 2.606107039765452

Epoch: 6| Step: 11
Training loss: 2.483266523175084
Validation loss: 2.5727868040931408

Epoch: 6| Step: 12
Training loss: 2.818770137469642
Validation loss: 2.6115127912842664

Epoch: 6| Step: 13
Training loss: 2.865511453723132
Validation loss: 2.578439959158607

Epoch: 26| Step: 0
Training loss: 3.2742345017218337
Validation loss: 2.61004409282656

Epoch: 6| Step: 1
Training loss: 2.224486122367581
Validation loss: 2.593816503568431

Epoch: 6| Step: 2
Training loss: 2.4996150674112787
Validation loss: 2.5826680700924904

Epoch: 6| Step: 3
Training loss: 2.6619049911797887
Validation loss: 2.5922961009375287

Epoch: 6| Step: 4
Training loss: 2.4894934176457397
Validation loss: 2.5854865427177858

Epoch: 6| Step: 5
Training loss: 2.099545556806277
Validation loss: 2.5971188708825443

Epoch: 6| Step: 6
Training loss: 2.148574214400135
Validation loss: 2.60458315507002

Epoch: 6| Step: 7
Training loss: 2.5495576362626124
Validation loss: 2.608418546347048

Epoch: 6| Step: 8
Training loss: 1.8038563321204804
Validation loss: 2.619795256372701

Epoch: 6| Step: 9
Training loss: 2.0204881065148874
Validation loss: 2.6207459963350344

Epoch: 6| Step: 10
Training loss: 2.6694007705448426
Validation loss: 2.63400074211058

Epoch: 6| Step: 11
Training loss: 3.1210185818936407
Validation loss: 2.6269447751958377

Epoch: 6| Step: 12
Training loss: 2.9354294317512566
Validation loss: 2.649817378271318

Epoch: 6| Step: 13
Training loss: 2.511556427309774
Validation loss: 2.6294449003561167

Epoch: 27| Step: 0
Training loss: 2.5699013610197365
Validation loss: 2.621060715612627

Epoch: 6| Step: 1
Training loss: 2.3511936240609166
Validation loss: 2.633486381340556

Epoch: 6| Step: 2
Training loss: 3.6436291525742925
Validation loss: 2.636395582951738

Epoch: 6| Step: 3
Training loss: 2.2250562424998606
Validation loss: 2.6014286957660926

Epoch: 6| Step: 4
Training loss: 1.9906037262119651
Validation loss: 2.6004546195937523

Epoch: 6| Step: 5
Training loss: 2.4305212424141986
Validation loss: 2.586169183499953

Epoch: 6| Step: 6
Training loss: 2.474888569799126
Validation loss: 2.5926474023946677

Epoch: 6| Step: 7
Training loss: 1.9635084100498958
Validation loss: 2.5936019885869985

Epoch: 6| Step: 8
Training loss: 2.3586614679279614
Validation loss: 2.5968141036806442

Epoch: 6| Step: 9
Training loss: 2.30527915472317
Validation loss: 2.6230645121163474

Epoch: 6| Step: 10
Training loss: 2.8857261592723233
Validation loss: 2.596406809210332

Epoch: 6| Step: 11
Training loss: 2.7384801076821605
Validation loss: 2.6108174705652565

Epoch: 6| Step: 12
Training loss: 1.590109912983965
Validation loss: 2.5942974814977746

Epoch: 6| Step: 13
Training loss: 2.715947691047114
Validation loss: 2.6129499452548393

Epoch: 28| Step: 0
Training loss: 2.31246958532179
Validation loss: 2.5865376862177616

Epoch: 6| Step: 1
Training loss: 3.264757543093445
Validation loss: 2.598568435400985

Epoch: 6| Step: 2
Training loss: 2.2932700587939996
Validation loss: 2.603195334801287

Epoch: 6| Step: 3
Training loss: 2.048169607515428
Validation loss: 2.585865661299355

Epoch: 6| Step: 4
Training loss: 2.996424769849426
Validation loss: 2.60479183068166

Epoch: 6| Step: 5
Training loss: 1.7299275466873518
Validation loss: 2.574630881831107

Epoch: 6| Step: 6
Training loss: 2.4773375444626238
Validation loss: 2.612379723537789

Epoch: 6| Step: 7
Training loss: 2.464598049486412
Validation loss: 2.5851129021943855

Epoch: 6| Step: 8
Training loss: 2.6724763606197324
Validation loss: 2.6261633308510346

Epoch: 6| Step: 9
Training loss: 3.045881373439296
Validation loss: 2.6019294105819366

Epoch: 6| Step: 10
Training loss: 2.029032861683192
Validation loss: 2.6021087958803215

Epoch: 6| Step: 11
Training loss: 2.743028995261927
Validation loss: 2.5801352938089748

Epoch: 6| Step: 12
Training loss: 1.8367603811643318
Validation loss: 2.5757591412449394

Epoch: 6| Step: 13
Training loss: 2.489255513803372
Validation loss: 2.579216358114916

Epoch: 29| Step: 0
Training loss: 2.1627481924527228
Validation loss: 2.6080746027762793

Epoch: 6| Step: 1
Training loss: 2.7295173439135896
Validation loss: 2.5789026185813

Epoch: 6| Step: 2
Training loss: 2.6675386989828827
Validation loss: 2.6281169974393865

Epoch: 6| Step: 3
Training loss: 2.5764647715710627
Validation loss: 2.6247386083188866

Epoch: 6| Step: 4
Training loss: 2.8444957384146976
Validation loss: 2.6075637988304154

Epoch: 6| Step: 5
Training loss: 2.434736788582144
Validation loss: 2.6448924476760416

Epoch: 6| Step: 6
Training loss: 2.858754241766741
Validation loss: 2.612521879965436

Epoch: 6| Step: 7
Training loss: 2.3564161732812945
Validation loss: 2.6024371291208976

Epoch: 6| Step: 8
Training loss: 2.561453908135893
Validation loss: 2.6186916906257927

Epoch: 6| Step: 9
Training loss: 2.2752743146909307
Validation loss: 2.606594576420075

Epoch: 6| Step: 10
Training loss: 2.189759204986698
Validation loss: 2.5735718874805324

Epoch: 6| Step: 11
Training loss: 2.840155037422549
Validation loss: 2.5968516851021994

Epoch: 6| Step: 12
Training loss: 1.6094443297035903
Validation loss: 2.596226945755432

Epoch: 6| Step: 13
Training loss: 2.5990795853844317
Validation loss: 2.5976565406435848

Epoch: 30| Step: 0
Training loss: 2.8244939435210874
Validation loss: 2.601049714438185

Epoch: 6| Step: 1
Training loss: 2.692399283307889
Validation loss: 2.599373386141328

Epoch: 6| Step: 2
Training loss: 1.956664761093399
Validation loss: 2.585619189445121

Epoch: 6| Step: 3
Training loss: 2.3782056957694766
Validation loss: 2.577217728470023

Epoch: 6| Step: 4
Training loss: 2.8211997372227846
Validation loss: 2.5899867598000053

Epoch: 6| Step: 5
Training loss: 2.552045383300958
Validation loss: 2.5955672657901494

Epoch: 6| Step: 6
Training loss: 2.8148399791327
Validation loss: 2.5925602616332744

Epoch: 6| Step: 7
Training loss: 1.844153408595281
Validation loss: 2.595662082474895

Epoch: 6| Step: 8
Training loss: 2.4209876619171924
Validation loss: 2.598400168151666

Epoch: 6| Step: 9
Training loss: 1.953630305728277
Validation loss: 2.6066806611208206

Epoch: 6| Step: 10
Training loss: 2.2222123331273766
Validation loss: 2.5922630674611824

Epoch: 6| Step: 11
Training loss: 2.930546748995292
Validation loss: 2.611359365196024

Epoch: 6| Step: 12
Training loss: 2.4725394801429315
Validation loss: 2.627721405186313

Epoch: 6| Step: 13
Training loss: 2.5883647671485877
Validation loss: 2.6289928132949636

Epoch: 31| Step: 0
Training loss: 3.040016946243436
Validation loss: 2.5981174757457506

Epoch: 6| Step: 1
Training loss: 1.992673567770916
Validation loss: 2.5978418193110833

Epoch: 6| Step: 2
Training loss: 2.5509529464910132
Validation loss: 2.595647883539009

Epoch: 6| Step: 3
Training loss: 2.8980247018523473
Validation loss: 2.605658703942357

Epoch: 6| Step: 4
Training loss: 2.1021528017671645
Validation loss: 2.610254196708732

Epoch: 6| Step: 5
Training loss: 2.1309315418362065
Validation loss: 2.5790374374265816

Epoch: 6| Step: 6
Training loss: 2.3912185231364
Validation loss: 2.590189531429311

Epoch: 6| Step: 7
Training loss: 2.5848351286914006
Validation loss: 2.6078823487847274

Epoch: 6| Step: 8
Training loss: 2.2167050245976934
Validation loss: 2.5586480753715026

Epoch: 6| Step: 9
Training loss: 2.369317434180645
Validation loss: 2.5850390499444003

Epoch: 6| Step: 10
Training loss: 2.3142425570088583
Validation loss: 2.5785613182074965

Epoch: 6| Step: 11
Training loss: 2.3073820235655256
Validation loss: 2.575597984976389

Epoch: 6| Step: 12
Training loss: 3.1173475028445594
Validation loss: 2.594700298336723

Epoch: 6| Step: 13
Training loss: 2.473081820296363
Validation loss: 2.5860441249289834

Epoch: 32| Step: 0
Training loss: 1.6949060190078513
Validation loss: 2.5963554012457624

Epoch: 6| Step: 1
Training loss: 2.2445232705898235
Validation loss: 2.585602937474683

Epoch: 6| Step: 2
Training loss: 2.8431996242602375
Validation loss: 2.586540559057502

Epoch: 6| Step: 3
Training loss: 1.8327881117919305
Validation loss: 2.5812309898680152

Epoch: 6| Step: 4
Training loss: 2.6968965602468224
Validation loss: 2.6156171348146646

Epoch: 6| Step: 5
Training loss: 3.288745855823952
Validation loss: 2.5831575538964633

Epoch: 6| Step: 6
Training loss: 2.583255725638282
Validation loss: 2.578520835004741

Epoch: 6| Step: 7
Training loss: 2.8258291799937933
Validation loss: 2.5670888332693353

Epoch: 6| Step: 8
Training loss: 2.087316278836125
Validation loss: 2.5646596817150873

Epoch: 6| Step: 9
Training loss: 2.415078946041473
Validation loss: 2.56849770215762

Epoch: 6| Step: 10
Training loss: 2.99922488053717
Validation loss: 2.5909339754277485

Epoch: 6| Step: 11
Training loss: 2.1173850104626077
Validation loss: 2.5873599639568226

Epoch: 6| Step: 12
Training loss: 2.165320516211687
Validation loss: 2.5880476993899526

Epoch: 6| Step: 13
Training loss: 2.505603994318091
Validation loss: 2.599779413414844

Epoch: 33| Step: 0
Training loss: 2.6027628560850236
Validation loss: 2.604596328894144

Epoch: 6| Step: 1
Training loss: 3.143226419156361
Validation loss: 2.6083919173254024

Epoch: 6| Step: 2
Training loss: 1.996904242216383
Validation loss: 2.647596197496892

Epoch: 6| Step: 3
Training loss: 2.3026204813065956
Validation loss: 2.5913266117285856

Epoch: 6| Step: 4
Training loss: 2.2037903342447964
Validation loss: 2.6288684768570434

Epoch: 6| Step: 5
Training loss: 2.3489058686774205
Validation loss: 2.6326459158427924

Epoch: 6| Step: 6
Training loss: 2.4544052379388135
Validation loss: 2.675605237234819

Epoch: 6| Step: 7
Training loss: 2.6574837007498235
Validation loss: 2.6444427535530726

Epoch: 6| Step: 8
Training loss: 2.6935206552396505
Validation loss: 2.6379388844802625

Epoch: 6| Step: 9
Training loss: 2.2991953437383725
Validation loss: 2.6248612897040036

Epoch: 6| Step: 10
Training loss: 2.1219993049268098
Validation loss: 2.633498769303679

Epoch: 6| Step: 11
Training loss: 2.5324716328032917
Validation loss: 2.64432945965393

Epoch: 6| Step: 12
Training loss: 2.841980100407686
Validation loss: 2.5808044381556985

Epoch: 6| Step: 13
Training loss: 2.422328389706004
Validation loss: 2.617560653275264

Epoch: 34| Step: 0
Training loss: 1.8133534362440653
Validation loss: 2.5660880020672785

Epoch: 6| Step: 1
Training loss: 2.3219397390794843
Validation loss: 2.5845117854890636

Epoch: 6| Step: 2
Training loss: 2.3923270954087785
Validation loss: 2.5779270905334863

Epoch: 6| Step: 3
Training loss: 2.2044445441978358
Validation loss: 2.573327442279391

Epoch: 6| Step: 4
Training loss: 2.931439905582911
Validation loss: 2.5919612246937174

Epoch: 6| Step: 5
Training loss: 2.7680325993068062
Validation loss: 2.5886866466875365

Epoch: 6| Step: 6
Training loss: 3.398875802375059
Validation loss: 2.5800172585395584

Epoch: 6| Step: 7
Training loss: 2.041446738821532
Validation loss: 2.5998000856716605

Epoch: 6| Step: 8
Training loss: 2.1459662633912213
Validation loss: 2.5983461310034994

Epoch: 6| Step: 9
Training loss: 2.5265791383477354
Validation loss: 2.576779316820356

Epoch: 6| Step: 10
Training loss: 2.3826931282535133
Validation loss: 2.57321080882987

Epoch: 6| Step: 11
Training loss: 2.6770218026972996
Validation loss: 2.5740349742101074

Epoch: 6| Step: 12
Training loss: 2.2546116933153426
Validation loss: 2.566529168950204

Epoch: 6| Step: 13
Training loss: 2.5953118091745395
Validation loss: 2.5548334264734285

Epoch: 35| Step: 0
Training loss: 2.3539754964352078
Validation loss: 2.561327348059049

Epoch: 6| Step: 1
Training loss: 2.5849220149010526
Validation loss: 2.5821344198217093

Epoch: 6| Step: 2
Training loss: 3.038671473277387
Validation loss: 2.592895290387378

Epoch: 6| Step: 3
Training loss: 1.8905331297692851
Validation loss: 2.601574566481886

Epoch: 6| Step: 4
Training loss: 2.7212442816979565
Validation loss: 2.6303175094657707

Epoch: 6| Step: 5
Training loss: 2.8821239941493437
Validation loss: 2.6274422229254446

Epoch: 6| Step: 6
Training loss: 1.920091250953273
Validation loss: 2.5989103803370757

Epoch: 6| Step: 7
Training loss: 2.6962627118075835
Validation loss: 2.6244841326069595

Epoch: 6| Step: 8
Training loss: 2.2153475825819324
Validation loss: 2.639344049540701

Epoch: 6| Step: 9
Training loss: 2.7352355474828167
Validation loss: 2.630580616403842

Epoch: 6| Step: 10
Training loss: 2.329065939192982
Validation loss: 2.609506447654409

Epoch: 6| Step: 11
Training loss: 2.0434390050168174
Validation loss: 2.621917504203648

Epoch: 6| Step: 12
Training loss: 2.110465100088174
Validation loss: 2.605977326666058

Epoch: 6| Step: 13
Training loss: 2.7615225154325587
Validation loss: 2.59027455056688

Epoch: 36| Step: 0
Training loss: 2.7173356509936593
Validation loss: 2.615504483781551

Epoch: 6| Step: 1
Training loss: 2.4073176801974254
Validation loss: 2.6084528071998374

Epoch: 6| Step: 2
Training loss: 3.067419033085655
Validation loss: 2.600780365671512

Epoch: 6| Step: 3
Training loss: 2.5368490577455862
Validation loss: 2.607687032982928

Epoch: 6| Step: 4
Training loss: 2.6619250540898607
Validation loss: 2.608099939996995

Epoch: 6| Step: 5
Training loss: 2.244552481551221
Validation loss: 2.5904945948120464

Epoch: 6| Step: 6
Training loss: 2.143815273703612
Validation loss: 2.5821387518175705

Epoch: 6| Step: 7
Training loss: 2.400421018229573
Validation loss: 2.5738266688261837

Epoch: 6| Step: 8
Training loss: 2.8226606152012677
Validation loss: 2.5969420710906093

Epoch: 6| Step: 9
Training loss: 2.137465100812161
Validation loss: 2.5693013715575628

Epoch: 6| Step: 10
Training loss: 2.163078001537361
Validation loss: 2.5877917538355515

Epoch: 6| Step: 11
Training loss: 2.0099544751529823
Validation loss: 2.563990477380114

Epoch: 6| Step: 12
Training loss: 2.781551216187458
Validation loss: 2.5909133704620135

Epoch: 6| Step: 13
Training loss: 2.3121494336789974
Validation loss: 2.5928667625207265

Epoch: 37| Step: 0
Training loss: 2.5697988443283415
Validation loss: 2.5694531798572227

Epoch: 6| Step: 1
Training loss: 2.094405000631717
Validation loss: 2.5723195998414417

Epoch: 6| Step: 2
Training loss: 2.003974065692777
Validation loss: 2.604294618642114

Epoch: 6| Step: 3
Training loss: 2.3325613879336604
Validation loss: 2.595095327692982

Epoch: 6| Step: 4
Training loss: 2.168893208021717
Validation loss: 2.5926783542475884

Epoch: 6| Step: 5
Training loss: 2.751838762927152
Validation loss: 2.617862291788844

Epoch: 6| Step: 6
Training loss: 2.138074483132513
Validation loss: 2.6190357647148637

Epoch: 6| Step: 7
Training loss: 2.5572702959854943
Validation loss: 2.6136547025155266

Epoch: 6| Step: 8
Training loss: 1.9420128225891264
Validation loss: 2.665125466065874

Epoch: 6| Step: 9
Training loss: 2.479152348153789
Validation loss: 2.6631833039909645

Epoch: 6| Step: 10
Training loss: 3.460766514672666
Validation loss: 2.6533967644651013

Epoch: 6| Step: 11
Training loss: 2.4227494168688755
Validation loss: 2.660962714962258

Epoch: 6| Step: 12
Training loss: 2.3988600368020165
Validation loss: 2.6623224148456166

Epoch: 6| Step: 13
Training loss: 3.060442797967135
Validation loss: 2.6372075284813685

Epoch: 38| Step: 0
Training loss: 2.6102845211532153
Validation loss: 2.577434439603874

Epoch: 6| Step: 1
Training loss: 2.6088043319827614
Validation loss: 2.599994373926776

Epoch: 6| Step: 2
Training loss: 2.197258897559146
Validation loss: 2.5936280340603823

Epoch: 6| Step: 3
Training loss: 2.3167758280149098
Validation loss: 2.585161966775011

Epoch: 6| Step: 4
Training loss: 1.678252631933341
Validation loss: 2.5821913276639994

Epoch: 6| Step: 5
Training loss: 2.450640349492066
Validation loss: 2.578030547906823

Epoch: 6| Step: 6
Training loss: 2.649734134652849
Validation loss: 2.572123406528201

Epoch: 6| Step: 7
Training loss: 2.5695165079911177
Validation loss: 2.588402993205814

Epoch: 6| Step: 8
Training loss: 2.4713859489066796
Validation loss: 2.5583924813738417

Epoch: 6| Step: 9
Training loss: 2.7829251334578506
Validation loss: 2.583427186512144

Epoch: 6| Step: 10
Training loss: 2.2636377498236677
Validation loss: 2.5776457369994024

Epoch: 6| Step: 11
Training loss: 2.4956254833286886
Validation loss: 2.581662150215482

Epoch: 6| Step: 12
Training loss: 2.4863997551727666
Validation loss: 2.5668130413856973

Epoch: 6| Step: 13
Training loss: 2.5106676432620656
Validation loss: 2.5867829799022566

Epoch: 39| Step: 0
Training loss: 1.6237242165530754
Validation loss: 2.5865801332524154

Epoch: 6| Step: 1
Training loss: 3.0448291659234683
Validation loss: 2.541114783691894

Epoch: 6| Step: 2
Training loss: 1.7125714308048967
Validation loss: 2.584416036960397

Epoch: 6| Step: 3
Training loss: 2.584200549436094
Validation loss: 2.5829427228970143

Epoch: 6| Step: 4
Training loss: 2.524710508313251
Validation loss: 2.5871999833881376

Epoch: 6| Step: 5
Training loss: 2.7607537597586433
Validation loss: 2.5758683163420772

Epoch: 6| Step: 6
Training loss: 2.949189485316312
Validation loss: 2.575989673139672

Epoch: 6| Step: 7
Training loss: 3.1093394215144143
Validation loss: 2.5782375426726167

Epoch: 6| Step: 8
Training loss: 2.3510452664851553
Validation loss: 2.5478594228989517

Epoch: 6| Step: 9
Training loss: 2.166062405272844
Validation loss: 2.573157786964315

Epoch: 6| Step: 10
Training loss: 2.3865719014894573
Validation loss: 2.597943864163545

Epoch: 6| Step: 11
Training loss: 2.6708286311147384
Validation loss: 2.562522903588137

Epoch: 6| Step: 12
Training loss: 2.0409919116819215
Validation loss: 2.580021848216439

Epoch: 6| Step: 13
Training loss: 1.9995533921366968
Validation loss: 2.582666216102204

Epoch: 40| Step: 0
Training loss: 2.228375683736073
Validation loss: 2.5697891645621644

Epoch: 6| Step: 1
Training loss: 1.651923087751939
Validation loss: 2.581077842113002

Epoch: 6| Step: 2
Training loss: 2.5406959326720195
Validation loss: 2.5903107465180537

Epoch: 6| Step: 3
Training loss: 2.9126734145768745
Validation loss: 2.594557793387761

Epoch: 6| Step: 4
Training loss: 2.8751709928663747
Validation loss: 2.5951214730185335

Epoch: 6| Step: 5
Training loss: 2.6675591664067206
Validation loss: 2.6048916125553503

Epoch: 6| Step: 6
Training loss: 2.196294490252853
Validation loss: 2.6312306195751236

Epoch: 6| Step: 7
Training loss: 2.3326664607435066
Validation loss: 2.575725880256157

Epoch: 6| Step: 8
Training loss: 3.147773161435635
Validation loss: 2.6420698558169042

Epoch: 6| Step: 9
Training loss: 2.4840179762627494
Validation loss: 2.583929967175295

Epoch: 6| Step: 10
Training loss: 2.597059046424011
Validation loss: 2.587095940411172

Epoch: 6| Step: 11
Training loss: 2.247542628816452
Validation loss: 2.6108823674923634

Epoch: 6| Step: 12
Training loss: 2.0018378396683696
Validation loss: 2.58410750345874

Epoch: 6| Step: 13
Training loss: 2.368486306200632
Validation loss: 2.56372996019417

Epoch: 41| Step: 0
Training loss: 2.468554428659542
Validation loss: 2.5980462644342395

Epoch: 6| Step: 1
Training loss: 2.4514135720292383
Validation loss: 2.5794395409247435

Epoch: 6| Step: 2
Training loss: 2.1606716210342727
Validation loss: 2.5954394219720145

Epoch: 6| Step: 3
Training loss: 3.555867898321722
Validation loss: 2.5833578390579364

Epoch: 6| Step: 4
Training loss: 1.95714880919521
Validation loss: 2.6025397648431667

Epoch: 6| Step: 5
Training loss: 2.1429496449986303
Validation loss: 2.5797735935003128

Epoch: 6| Step: 6
Training loss: 3.0624487736368593
Validation loss: 2.5733829544237707

Epoch: 6| Step: 7
Training loss: 2.7864175858890317
Validation loss: 2.58874034055206

Epoch: 6| Step: 8
Training loss: 2.192156494965446
Validation loss: 2.611745115818985

Epoch: 6| Step: 9
Training loss: 2.623505666550365
Validation loss: 2.587747023334965

Epoch: 6| Step: 10
Training loss: 2.636956731158468
Validation loss: 2.574151369639899

Epoch: 6| Step: 11
Training loss: 1.5015351863603783
Validation loss: 2.5739943271921244

Epoch: 6| Step: 12
Training loss: 2.351921586409846
Validation loss: 2.5784056847877657

Epoch: 6| Step: 13
Training loss: 1.9593493348894147
Validation loss: 2.619288277974081

Epoch: 42| Step: 0
Training loss: 1.8665580167258309
Validation loss: 2.614146987756658

Epoch: 6| Step: 1
Training loss: 2.706612602768195
Validation loss: 2.5699789029800404

Epoch: 6| Step: 2
Training loss: 2.5421900809567415
Validation loss: 2.5818522319591657

Epoch: 6| Step: 3
Training loss: 2.1375760828944435
Validation loss: 2.5942171357887793

Epoch: 6| Step: 4
Training loss: 2.7340478319896713
Validation loss: 2.582357535087036

Epoch: 6| Step: 5
Training loss: 2.749942692246227
Validation loss: 2.59268405566274

Epoch: 6| Step: 6
Training loss: 2.5148702875439493
Validation loss: 2.5963772562595167

Epoch: 6| Step: 7
Training loss: 2.121006747827223
Validation loss: 2.595231946552104

Epoch: 6| Step: 8
Training loss: 2.8632717574770172
Validation loss: 2.6019522343502173

Epoch: 6| Step: 9
Training loss: 2.70325271216549
Validation loss: 2.601312856371516

Epoch: 6| Step: 10
Training loss: 1.894329005192427
Validation loss: 2.610413183000396

Epoch: 6| Step: 11
Training loss: 2.4239656346343246
Validation loss: 2.583494071164178

Epoch: 6| Step: 12
Training loss: 2.2406332231314847
Validation loss: 2.5637903531285517

Epoch: 6| Step: 13
Training loss: 2.5157985271999963
Validation loss: 2.5998061994314603

Epoch: 43| Step: 0
Training loss: 2.1675370619970065
Validation loss: 2.568817492338586

Epoch: 6| Step: 1
Training loss: 1.8951109323768898
Validation loss: 2.5802104645526347

Epoch: 6| Step: 2
Training loss: 1.9840967178458315
Validation loss: 2.589383383100565

Epoch: 6| Step: 3
Training loss: 2.0100675157813153
Validation loss: 2.5694379700473173

Epoch: 6| Step: 4
Training loss: 2.8510004195069505
Validation loss: 2.601741544043929

Epoch: 6| Step: 5
Training loss: 2.870003878760292
Validation loss: 2.6148723022129965

Epoch: 6| Step: 6
Training loss: 2.8335672356790425
Validation loss: 2.574060198812292

Epoch: 6| Step: 7
Training loss: 2.1524465435979763
Validation loss: 2.583894935188372

Epoch: 6| Step: 8
Training loss: 3.422638272375606
Validation loss: 2.5777306611543573

Epoch: 6| Step: 9
Training loss: 2.595238499789292
Validation loss: 2.5836900700602716

Epoch: 6| Step: 10
Training loss: 2.3174608991466257
Validation loss: 2.561750534991226

Epoch: 6| Step: 11
Training loss: 2.2577442832065926
Validation loss: 2.569413450128613

Epoch: 6| Step: 12
Training loss: 2.6128443878823107
Validation loss: 2.602807420131834

Epoch: 6| Step: 13
Training loss: 2.0293781752542435
Validation loss: 2.5585445176064088

Epoch: 44| Step: 0
Training loss: 2.5780561958148422
Validation loss: 2.5657332499346164

Epoch: 6| Step: 1
Training loss: 2.1444509800408915
Validation loss: 2.5760967869356137

Epoch: 6| Step: 2
Training loss: 2.1244653141299255
Validation loss: 2.555151132243242

Epoch: 6| Step: 3
Training loss: 2.252432038597608
Validation loss: 2.593090371818351

Epoch: 6| Step: 4
Training loss: 1.9989571832915618
Validation loss: 2.5867987328993385

Epoch: 6| Step: 5
Training loss: 2.0393484799305917
Validation loss: 2.6140997972732922

Epoch: 6| Step: 6
Training loss: 2.0438816226490086
Validation loss: 2.595446418677008

Epoch: 6| Step: 7
Training loss: 2.669426671883174
Validation loss: 2.639898873737975

Epoch: 6| Step: 8
Training loss: 2.504902514999268
Validation loss: 2.6227731644751624

Epoch: 6| Step: 9
Training loss: 3.010918457731203
Validation loss: 2.6174244787621506

Epoch: 6| Step: 10
Training loss: 3.0058804734984843
Validation loss: 2.633068958926283

Epoch: 6| Step: 11
Training loss: 2.6623657730009276
Validation loss: 2.6718933669977796

Epoch: 6| Step: 12
Training loss: 2.3264713430896338
Validation loss: 2.5931131584563385

Epoch: 6| Step: 13
Training loss: 2.432539955116821
Validation loss: 2.62397148025044

Epoch: 45| Step: 0
Training loss: 1.5949983382739557
Validation loss: 2.590828042534642

Epoch: 6| Step: 1
Training loss: 2.4552527269232316
Validation loss: 2.577683859951261

Epoch: 6| Step: 2
Training loss: 2.8039565980248655
Validation loss: 2.58969524680829

Epoch: 6| Step: 3
Training loss: 2.1964566653201683
Validation loss: 2.5970642792065832

Epoch: 6| Step: 4
Training loss: 2.166103020737415
Validation loss: 2.5782086214318083

Epoch: 6| Step: 5
Training loss: 2.2380641545704503
Validation loss: 2.571647969604614

Epoch: 6| Step: 6
Training loss: 2.1687372168788093
Validation loss: 2.575790319175131

Epoch: 6| Step: 7
Training loss: 2.1057914529049264
Validation loss: 2.5667829774124176

Epoch: 6| Step: 8
Training loss: 2.6045599271749547
Validation loss: 2.5804624961833453

Epoch: 6| Step: 9
Training loss: 3.1597035464525534
Validation loss: 2.5712592208565916

Epoch: 6| Step: 10
Training loss: 2.4517719400582774
Validation loss: 2.574884956530617

Epoch: 6| Step: 11
Training loss: 2.999876178729302
Validation loss: 2.5818776572170785

Epoch: 6| Step: 12
Training loss: 1.8123839768731307
Validation loss: 2.545282415934654

Epoch: 6| Step: 13
Training loss: 2.6471725638892174
Validation loss: 2.5472153980279733

Epoch: 46| Step: 0
Training loss: 2.8485512916322167
Validation loss: 2.5715317544595333

Epoch: 6| Step: 1
Training loss: 1.4527401158054507
Validation loss: 2.5732836184945413

Epoch: 6| Step: 2
Training loss: 2.9313774422797287
Validation loss: 2.574858659735471

Epoch: 6| Step: 3
Training loss: 2.63373511021863
Validation loss: 2.5638638100362456

Epoch: 6| Step: 4
Training loss: 2.8179367922373926
Validation loss: 2.61566386495905

Epoch: 6| Step: 5
Training loss: 2.2181600941633186
Validation loss: 2.5790754165489287

Epoch: 6| Step: 6
Training loss: 2.1514084128483164
Validation loss: 2.579182725732096

Epoch: 6| Step: 7
Training loss: 2.7490544861146264
Validation loss: 2.5843974172841504

Epoch: 6| Step: 8
Training loss: 2.701931905118532
Validation loss: 2.5997573653738364

Epoch: 6| Step: 9
Training loss: 2.6041428425016995
Validation loss: 2.5607446613056872

Epoch: 6| Step: 10
Training loss: 2.251957465744136
Validation loss: 2.5809680406024653

Epoch: 6| Step: 11
Training loss: 2.045680971810545
Validation loss: 2.5411498737765683

Epoch: 6| Step: 12
Training loss: 1.9610753713826636
Validation loss: 2.5750653230844174

Epoch: 6| Step: 13
Training loss: 2.389568219944975
Validation loss: 2.5724072022749036

Epoch: 47| Step: 0
Training loss: 2.6509358822764684
Validation loss: 2.580134400556076

Epoch: 6| Step: 1
Training loss: 1.963433003812818
Validation loss: 2.5936086531889124

Epoch: 6| Step: 2
Training loss: 2.6668168760750706
Validation loss: 2.637741048925486

Epoch: 6| Step: 3
Training loss: 2.1402889461282326
Validation loss: 2.6245763149148456

Epoch: 6| Step: 4
Training loss: 3.027881756629361
Validation loss: 2.626042643366179

Epoch: 6| Step: 5
Training loss: 2.872449323906029
Validation loss: 2.597573277575254

Epoch: 6| Step: 6
Training loss: 2.1431829386500136
Validation loss: 2.583660448549745

Epoch: 6| Step: 7
Training loss: 2.202963424060373
Validation loss: 2.590634784749031

Epoch: 6| Step: 8
Training loss: 2.791586025458757
Validation loss: 2.56694801530756

Epoch: 6| Step: 9
Training loss: 2.12403488682259
Validation loss: 2.5608422569452935

Epoch: 6| Step: 10
Training loss: 2.4968659783917704
Validation loss: 2.5598818111456043

Epoch: 6| Step: 11
Training loss: 2.578015504303589
Validation loss: 2.5724031396640954

Epoch: 6| Step: 12
Training loss: 2.143059119287993
Validation loss: 2.5705456845331445

Epoch: 6| Step: 13
Training loss: 2.217851483724152
Validation loss: 2.5833594695173994

Epoch: 48| Step: 0
Training loss: 2.2008718237014153
Validation loss: 2.567038757633976

Epoch: 6| Step: 1
Training loss: 1.8844113980600605
Validation loss: 2.5521033824729984

Epoch: 6| Step: 2
Training loss: 2.9296435543579054
Validation loss: 2.5830864224313332

Epoch: 6| Step: 3
Training loss: 2.1895162826807257
Validation loss: 2.558847390529596

Epoch: 6| Step: 4
Training loss: 2.4756726131276197
Validation loss: 2.58362800445473

Epoch: 6| Step: 5
Training loss: 2.3068277023125803
Validation loss: 2.585394734164852

Epoch: 6| Step: 6
Training loss: 2.8187016248252457
Validation loss: 2.6013496013968873

Epoch: 6| Step: 7
Training loss: 2.1840404947460175
Validation loss: 2.5860786207402393

Epoch: 6| Step: 8
Training loss: 2.278707890710014
Validation loss: 2.564243801044862

Epoch: 6| Step: 9
Training loss: 2.7279185773047363
Validation loss: 2.602907674997903

Epoch: 6| Step: 10
Training loss: 2.857893596518421
Validation loss: 2.5807293963440228

Epoch: 6| Step: 11
Training loss: 2.2957016419605023
Validation loss: 2.578997516374993

Epoch: 6| Step: 12
Training loss: 1.7261467342440733
Validation loss: 2.566494812929991

Epoch: 6| Step: 13
Training loss: 2.765523876345751
Validation loss: 2.5775678244496816

Epoch: 49| Step: 0
Training loss: 2.5389013620743075
Validation loss: 2.609351472120374

Epoch: 6| Step: 1
Training loss: 2.0908987644377817
Validation loss: 2.5629052407742807

Epoch: 6| Step: 2
Training loss: 3.237474808171474
Validation loss: 2.5760468709800297

Epoch: 6| Step: 3
Training loss: 2.856615579861238
Validation loss: 2.6122775961163365

Epoch: 6| Step: 4
Training loss: 2.4218173112458943
Validation loss: 2.595064864037038

Epoch: 6| Step: 5
Training loss: 2.1019630475847726
Validation loss: 2.6235811546728685

Epoch: 6| Step: 6
Training loss: 2.162794381980591
Validation loss: 2.62959208807417

Epoch: 6| Step: 7
Training loss: 2.7055469753887396
Validation loss: 2.585557423729689

Epoch: 6| Step: 8
Training loss: 2.298167585113753
Validation loss: 2.5835779187079138

Epoch: 6| Step: 9
Training loss: 2.048446401522898
Validation loss: 2.5909350643346656

Epoch: 6| Step: 10
Training loss: 2.5509041585709564
Validation loss: 2.5610636120122345

Epoch: 6| Step: 11
Training loss: 2.39628658706521
Validation loss: 2.572791313999413

Epoch: 6| Step: 12
Training loss: 2.099629587475384
Validation loss: 2.5747282211923954

Epoch: 6| Step: 13
Training loss: 2.457655980388271
Validation loss: 2.5663672163117575

Epoch: 50| Step: 0
Training loss: 2.097053995465997
Validation loss: 2.563243075924327

Epoch: 6| Step: 1
Training loss: 2.0721176626753586
Validation loss: 2.542846082940907

Epoch: 6| Step: 2
Training loss: 3.248654013460024
Validation loss: 2.585464749336125

Epoch: 6| Step: 3
Training loss: 2.9976302960276136
Validation loss: 2.5912729561195706

Epoch: 6| Step: 4
Training loss: 2.3224183875322826
Validation loss: 2.5582025049247386

Epoch: 6| Step: 5
Training loss: 1.9378532579845156
Validation loss: 2.5743644337392126

Epoch: 6| Step: 6
Training loss: 2.456572812831163
Validation loss: 2.5936520875887834

Epoch: 6| Step: 7
Training loss: 2.2397784007677854
Validation loss: 2.573366401275422

Epoch: 6| Step: 8
Training loss: 2.3505772145532995
Validation loss: 2.5835286933083683

Epoch: 6| Step: 9
Training loss: 2.000149482862815
Validation loss: 2.5699769084105775

Epoch: 6| Step: 10
Training loss: 2.120527160168367
Validation loss: 2.611527520201449

Epoch: 6| Step: 11
Training loss: 2.7263946918778394
Validation loss: 2.6287402496906824

Epoch: 6| Step: 12
Training loss: 2.523185977269831
Validation loss: 2.6020067272917866

Epoch: 6| Step: 13
Training loss: 2.6031944494611468
Validation loss: 2.5812502866410783

Epoch: 51| Step: 0
Training loss: 2.954835103915785
Validation loss: 2.561335702333872

Epoch: 6| Step: 1
Training loss: 2.792237085927834
Validation loss: 2.5875748505262623

Epoch: 6| Step: 2
Training loss: 2.5195397665190367
Validation loss: 2.5679502134676344

Epoch: 6| Step: 3
Training loss: 1.993307001052662
Validation loss: 2.5608593565535878

Epoch: 6| Step: 4
Training loss: 2.082932268320701
Validation loss: 2.567796196249981

Epoch: 6| Step: 5
Training loss: 2.639733790500605
Validation loss: 2.5872892321561767

Epoch: 6| Step: 6
Training loss: 2.738947679775502
Validation loss: 2.560322239321553

Epoch: 6| Step: 7
Training loss: 2.6714099680119494
Validation loss: 2.5523832702846483

Epoch: 6| Step: 8
Training loss: 2.530429188959963
Validation loss: 2.556654255682287

Epoch: 6| Step: 9
Training loss: 2.163547936695058
Validation loss: 2.572214275244385

Epoch: 6| Step: 10
Training loss: 1.954409123761136
Validation loss: 2.553638596783496

Epoch: 6| Step: 11
Training loss: 2.340393918781272
Validation loss: 2.543781797068172

Epoch: 6| Step: 12
Training loss: 1.926791902792533
Validation loss: 2.589671685902555

Epoch: 6| Step: 13
Training loss: 2.6052110535979733
Validation loss: 2.6073887588360094

Epoch: 52| Step: 0
Training loss: 1.6634047376841565
Validation loss: 2.6022040690094634

Epoch: 6| Step: 1
Training loss: 2.6275888120557367
Validation loss: 2.617544288418454

Epoch: 6| Step: 2
Training loss: 2.0566975439877075
Validation loss: 2.605419610287872

Epoch: 6| Step: 3
Training loss: 1.9996911048767245
Validation loss: 2.632100175887495

Epoch: 6| Step: 4
Training loss: 2.693927353687285
Validation loss: 2.6386374794398075

Epoch: 6| Step: 5
Training loss: 2.5464372317167454
Validation loss: 2.624637669579542

Epoch: 6| Step: 6
Training loss: 2.7208758406850513
Validation loss: 2.6208794359802847

Epoch: 6| Step: 7
Training loss: 3.41618563979792
Validation loss: 2.6155764503485264

Epoch: 6| Step: 8
Training loss: 2.6436158346848515
Validation loss: 2.622698168229722

Epoch: 6| Step: 9
Training loss: 2.289280383055167
Validation loss: 2.5759212901280932

Epoch: 6| Step: 10
Training loss: 1.7651099069756573
Validation loss: 2.5849954323940394

Epoch: 6| Step: 11
Training loss: 2.5616585815474178
Validation loss: 2.5707513884762245

Epoch: 6| Step: 12
Training loss: 2.2122967858391047
Validation loss: 2.5650443804336325

Epoch: 6| Step: 13
Training loss: 2.3313025992751792
Validation loss: 2.5994450044052733

Epoch: 53| Step: 0
Training loss: 2.3487536107837963
Validation loss: 2.57780149337485

Epoch: 6| Step: 1
Training loss: 2.1412309220639383
Validation loss: 2.5948614473785123

Epoch: 6| Step: 2
Training loss: 2.5709422537195286
Validation loss: 2.5505580755787394

Epoch: 6| Step: 3
Training loss: 2.035330210332956
Validation loss: 2.608909710118742

Epoch: 6| Step: 4
Training loss: 3.075346181348018
Validation loss: 2.587260258513139

Epoch: 6| Step: 5
Training loss: 1.6876688272300502
Validation loss: 2.6154323784967675

Epoch: 6| Step: 6
Training loss: 2.421819083275863
Validation loss: 2.6406592041448853

Epoch: 6| Step: 7
Training loss: 2.656407968648347
Validation loss: 2.60597859226528

Epoch: 6| Step: 8
Training loss: 2.5969031597497363
Validation loss: 2.5962872332353633

Epoch: 6| Step: 9
Training loss: 2.5485753661191874
Validation loss: 2.589560522488957

Epoch: 6| Step: 10
Training loss: 1.8527739863028838
Validation loss: 2.604639816534222

Epoch: 6| Step: 11
Training loss: 2.524191256638758
Validation loss: 2.581183867265459

Epoch: 6| Step: 12
Training loss: 2.7279331729735823
Validation loss: 2.5879398518804666

Epoch: 6| Step: 13
Training loss: 2.344522272669261
Validation loss: 2.5850683866563733

Epoch: 54| Step: 0
Training loss: 2.949773107305462
Validation loss: 2.6065174987028006

Epoch: 6| Step: 1
Training loss: 2.1418436855479284
Validation loss: 2.5738934401561955

Epoch: 6| Step: 2
Training loss: 2.5651380404383515
Validation loss: 2.60098810126763

Epoch: 6| Step: 3
Training loss: 2.6593741500978645
Validation loss: 2.571510599987641

Epoch: 6| Step: 4
Training loss: 2.7662154607258436
Validation loss: 2.5557961425546365

Epoch: 6| Step: 5
Training loss: 2.4397166028149213
Validation loss: 2.5739133940267407

Epoch: 6| Step: 6
Training loss: 2.321245924083806
Validation loss: 2.5586380738745853

Epoch: 6| Step: 7
Training loss: 1.895008837092989
Validation loss: 2.60473039756131

Epoch: 6| Step: 8
Training loss: 2.167306939913139
Validation loss: 2.5753571265751964

Epoch: 6| Step: 9
Training loss: 2.6361300341033367
Validation loss: 2.601154665821528

Epoch: 6| Step: 10
Training loss: 2.3830748366732126
Validation loss: 2.592368834416737

Epoch: 6| Step: 11
Training loss: 1.973609497597011
Validation loss: 2.6064074425288397

Epoch: 6| Step: 12
Training loss: 2.4423358581739563
Validation loss: 2.622205313789233

Epoch: 6| Step: 13
Training loss: 2.2782137797237216
Validation loss: 2.54870740037022

Epoch: 55| Step: 0
Training loss: 2.703240981948897
Validation loss: 2.599565138274461

Epoch: 6| Step: 1
Training loss: 1.8271095520481377
Validation loss: 2.575797322972952

Epoch: 6| Step: 2
Training loss: 1.842352515312944
Validation loss: 2.5959147875779447

Epoch: 6| Step: 3
Training loss: 2.213317021957103
Validation loss: 2.572103369250778

Epoch: 6| Step: 4
Training loss: 2.323911810089664
Validation loss: 2.5903085451682295

Epoch: 6| Step: 5
Training loss: 1.8765389802270358
Validation loss: 2.5844276222981883

Epoch: 6| Step: 6
Training loss: 2.790855622026483
Validation loss: 2.5898241260028656

Epoch: 6| Step: 7
Training loss: 2.361299853790644
Validation loss: 2.5562425171821093

Epoch: 6| Step: 8
Training loss: 2.6258329250763537
Validation loss: 2.5586733274242275

Epoch: 6| Step: 9
Training loss: 2.877548746579357
Validation loss: 2.5853556336589882

Epoch: 6| Step: 10
Training loss: 2.509128213530998
Validation loss: 2.561953649195397

Epoch: 6| Step: 11
Training loss: 2.639044474872761
Validation loss: 2.5701755692049293

Epoch: 6| Step: 12
Training loss: 2.887187831898049
Validation loss: 2.547528890908248

Epoch: 6| Step: 13
Training loss: 1.877912357625284
Validation loss: 2.54103150535037

Epoch: 56| Step: 0
Training loss: 2.3019017857099566
Validation loss: 2.5527363830418413

Epoch: 6| Step: 1
Training loss: 2.718572939664777
Validation loss: 2.5666450222968824

Epoch: 6| Step: 2
Training loss: 1.726983618839151
Validation loss: 2.6042677643543493

Epoch: 6| Step: 3
Training loss: 2.6901455654763646
Validation loss: 2.5648134534791143

Epoch: 6| Step: 4
Training loss: 1.8694650972285787
Validation loss: 2.6017300358039273

Epoch: 6| Step: 5
Training loss: 3.2275790998367686
Validation loss: 2.60251874027107

Epoch: 6| Step: 6
Training loss: 2.10192334789033
Validation loss: 2.5877730663157124

Epoch: 6| Step: 7
Training loss: 2.8750590442731156
Validation loss: 2.612787052671345

Epoch: 6| Step: 8
Training loss: 1.9011091107114495
Validation loss: 2.5951287768193625

Epoch: 6| Step: 9
Training loss: 2.1114332541689076
Validation loss: 2.6132715488286085

Epoch: 6| Step: 10
Training loss: 2.458769312415715
Validation loss: 2.6189808636782255

Epoch: 6| Step: 11
Training loss: 2.0294387958674376
Validation loss: 2.6139291702321543

Epoch: 6| Step: 12
Training loss: 2.2330691916802627
Validation loss: 2.6019196289056716

Epoch: 6| Step: 13
Training loss: 2.6942274480355306
Validation loss: 2.5794363520746337

Epoch: 57| Step: 0
Training loss: 2.035513994694022
Validation loss: 2.553455860826836

Epoch: 6| Step: 1
Training loss: 2.498178486045068
Validation loss: 2.5891874238323904

Epoch: 6| Step: 2
Training loss: 2.492810306038811
Validation loss: 2.5556400556922383

Epoch: 6| Step: 3
Training loss: 2.4079951113717777
Validation loss: 2.574043356709371

Epoch: 6| Step: 4
Training loss: 1.6327945397954364
Validation loss: 2.5695533906905403

Epoch: 6| Step: 5
Training loss: 1.9805222001847909
Validation loss: 2.578518877863873

Epoch: 6| Step: 6
Training loss: 2.718918279942704
Validation loss: 2.5988802977767835

Epoch: 6| Step: 7
Training loss: 2.292277607255095
Validation loss: 2.569727327623529

Epoch: 6| Step: 8
Training loss: 2.257779131052074
Validation loss: 2.5907455262913603

Epoch: 6| Step: 9
Training loss: 2.6831809535702305
Validation loss: 2.60327884544599

Epoch: 6| Step: 10
Training loss: 2.22629799861238
Validation loss: 2.567434049946064

Epoch: 6| Step: 11
Training loss: 2.5138900176081456
Validation loss: 2.5701235283332453

Epoch: 6| Step: 12
Training loss: 2.4802155613276553
Validation loss: 2.581115975953074

Epoch: 6| Step: 13
Training loss: 2.9501621783661505
Validation loss: 2.558588842333875

Epoch: 58| Step: 0
Training loss: 2.3417904609547797
Validation loss: 2.59119669546435

Epoch: 6| Step: 1
Training loss: 2.4851750459173085
Validation loss: 2.5732127700079634

Epoch: 6| Step: 2
Training loss: 2.358787514004677
Validation loss: 2.559039702632822

Epoch: 6| Step: 3
Training loss: 2.3745337580748993
Validation loss: 2.533975099746855

Epoch: 6| Step: 4
Training loss: 1.8682514814312
Validation loss: 2.5572932541810576

Epoch: 6| Step: 5
Training loss: 3.1023341835583427
Validation loss: 2.533926698457479

Epoch: 6| Step: 6
Training loss: 2.018985755783251
Validation loss: 2.5543208272273454

Epoch: 6| Step: 7
Training loss: 2.774687321548293
Validation loss: 2.5657745776170904

Epoch: 6| Step: 8
Training loss: 2.5825301018850357
Validation loss: 2.5958747586965223

Epoch: 6| Step: 9
Training loss: 2.383068133540344
Validation loss: 2.5998549714354375

Epoch: 6| Step: 10
Training loss: 2.6776556647576606
Validation loss: 2.6226791839915027

Epoch: 6| Step: 11
Training loss: 1.568189941983296
Validation loss: 2.6184245056735596

Epoch: 6| Step: 12
Training loss: 2.1536008621803586
Validation loss: 2.583426632785824

Epoch: 6| Step: 13
Training loss: 2.5788064691792902
Validation loss: 2.5975320657287395

Epoch: 59| Step: 0
Training loss: 1.3982238180054478
Validation loss: 2.592759766815027

Epoch: 6| Step: 1
Training loss: 2.4427581218099963
Validation loss: 2.5925161268737527

Epoch: 6| Step: 2
Training loss: 2.6379865297056018
Validation loss: 2.5906157956268525

Epoch: 6| Step: 3
Training loss: 2.3783483493101896
Validation loss: 2.5900778609494024

Epoch: 6| Step: 4
Training loss: 2.853123235127466
Validation loss: 2.5642265148036367

Epoch: 6| Step: 5
Training loss: 2.6157501373072227
Validation loss: 2.606202029511715

Epoch: 6| Step: 6
Training loss: 2.1109481031940747
Validation loss: 2.5459929579052822

Epoch: 6| Step: 7
Training loss: 2.2427767202035542
Validation loss: 2.5453908453542455

Epoch: 6| Step: 8
Training loss: 2.05563819850861
Validation loss: 2.5583148911108595

Epoch: 6| Step: 9
Training loss: 1.9635424694056265
Validation loss: 2.556146638579076

Epoch: 6| Step: 10
Training loss: 2.508912032615401
Validation loss: 2.571041046440071

Epoch: 6| Step: 11
Training loss: 2.7791898147861955
Validation loss: 2.5817449875590217

Epoch: 6| Step: 12
Training loss: 2.9769080254362477
Validation loss: 2.5694925532834674

Epoch: 6| Step: 13
Training loss: 1.8188689569851717
Validation loss: 2.5630323585871793

Epoch: 60| Step: 0
Training loss: 2.3387891019715688
Validation loss: 2.558559015635235

Epoch: 6| Step: 1
Training loss: 2.0595811940353843
Validation loss: 2.5703613369368994

Epoch: 6| Step: 2
Training loss: 1.87901010840896
Validation loss: 2.5719634747341606

Epoch: 6| Step: 3
Training loss: 3.075738746789294
Validation loss: 2.555070029889706

Epoch: 6| Step: 4
Training loss: 1.906766977716997
Validation loss: 2.5563670168133297

Epoch: 6| Step: 5
Training loss: 2.2782599305851416
Validation loss: 2.6091858039535074

Epoch: 6| Step: 6
Training loss: 2.0845673022002296
Validation loss: 2.556340172008096

Epoch: 6| Step: 7
Training loss: 2.6517155258629344
Validation loss: 2.5448053918365052

Epoch: 6| Step: 8
Training loss: 2.1958202711533583
Validation loss: 2.5864218328396724

Epoch: 6| Step: 9
Training loss: 2.4661448773090533
Validation loss: 2.603428840383175

Epoch: 6| Step: 10
Training loss: 1.5292670197087785
Validation loss: 2.5876430791343035

Epoch: 6| Step: 11
Training loss: 2.1620010858862986
Validation loss: 2.5910454863218284

Epoch: 6| Step: 12
Training loss: 2.319854074525703
Validation loss: 2.5871709549890096

Epoch: 6| Step: 13
Training loss: 3.536369461193846
Validation loss: 2.6024616203690645

Epoch: 61| Step: 0
Training loss: 2.8995237551349353
Validation loss: 2.5814038782690147

Epoch: 6| Step: 1
Training loss: 2.062703902829262
Validation loss: 2.587298109253011

Epoch: 6| Step: 2
Training loss: 2.218950074537184
Validation loss: 2.55955356134927

Epoch: 6| Step: 3
Training loss: 3.1208633509687544
Validation loss: 2.598746424249437

Epoch: 6| Step: 4
Training loss: 1.9688307730438697
Validation loss: 2.5975034128606636

Epoch: 6| Step: 5
Training loss: 1.5678028910393573
Validation loss: 2.5663898531362377

Epoch: 6| Step: 6
Training loss: 1.802760164318174
Validation loss: 2.555462734176846

Epoch: 6| Step: 7
Training loss: 2.567921276947724
Validation loss: 2.580352968780465

Epoch: 6| Step: 8
Training loss: 2.710270340586208
Validation loss: 2.597725299883102

Epoch: 6| Step: 9
Training loss: 2.66909306128044
Validation loss: 2.5895459064736457

Epoch: 6| Step: 10
Training loss: 2.6477998849331223
Validation loss: 2.6075943679045377

Epoch: 6| Step: 11
Training loss: 1.8691934958766216
Validation loss: 2.575731264369284

Epoch: 6| Step: 12
Training loss: 1.890453992944149
Validation loss: 2.5947284040443317

Epoch: 6| Step: 13
Training loss: 2.6159748969083942
Validation loss: 2.5594172348866255

Epoch: 62| Step: 0
Training loss: 2.67702091208588
Validation loss: 2.551015433232004

Epoch: 6| Step: 1
Training loss: 2.3226076841489554
Validation loss: 2.5798072797915896

Epoch: 6| Step: 2
Training loss: 2.422589596566772
Validation loss: 2.555956992694443

Epoch: 6| Step: 3
Training loss: 2.0022201136753064
Validation loss: 2.5701934725054096

Epoch: 6| Step: 4
Training loss: 2.0013413699448512
Validation loss: 2.563499178347658

Epoch: 6| Step: 5
Training loss: 2.3561003741205315
Validation loss: 2.541136457036703

Epoch: 6| Step: 6
Training loss: 2.446379310024434
Validation loss: 2.568863202127571

Epoch: 6| Step: 7
Training loss: 2.9392248730420545
Validation loss: 2.5695789221778376

Epoch: 6| Step: 8
Training loss: 2.570218348300524
Validation loss: 2.5561248748673306

Epoch: 6| Step: 9
Training loss: 2.039763932874456
Validation loss: 2.554322740682769

Epoch: 6| Step: 10
Training loss: 2.511126743631832
Validation loss: 2.5985955167930332

Epoch: 6| Step: 11
Training loss: 1.862267176265833
Validation loss: 2.5834514503752977

Epoch: 6| Step: 12
Training loss: 1.9594119395495904
Validation loss: 2.618406431350168

Epoch: 6| Step: 13
Training loss: 2.937838595740757
Validation loss: 2.6310225834734515

Epoch: 63| Step: 0
Training loss: 2.269119093955831
Validation loss: 2.57830615707637

Epoch: 6| Step: 1
Training loss: 2.289813234300941
Validation loss: 2.5891664596555897

Epoch: 6| Step: 2
Training loss: 2.386521551348588
Validation loss: 2.6220542788829304

Epoch: 6| Step: 3
Training loss: 2.2692561023844857
Validation loss: 2.625063289908723

Epoch: 6| Step: 4
Training loss: 2.388207902864549
Validation loss: 2.595627851808425

Epoch: 6| Step: 5
Training loss: 1.7159913552606685
Validation loss: 2.5651748931480545

Epoch: 6| Step: 6
Training loss: 2.30774106255405
Validation loss: 2.626781434377376

Epoch: 6| Step: 7
Training loss: 1.936746820059446
Validation loss: 2.588211987773191

Epoch: 6| Step: 8
Training loss: 2.9394863798471884
Validation loss: 2.6085045175370056

Epoch: 6| Step: 9
Training loss: 2.1255282699079725
Validation loss: 2.62539108330094

Epoch: 6| Step: 10
Training loss: 2.66531441098866
Validation loss: 2.5717589724924887

Epoch: 6| Step: 11
Training loss: 2.818957566022093
Validation loss: 2.585351745093647

Epoch: 6| Step: 12
Training loss: 2.062840751474137
Validation loss: 2.5719685886268477

Epoch: 6| Step: 13
Training loss: 2.656996408944652
Validation loss: 2.5605210206690368

Epoch: 64| Step: 0
Training loss: 2.2791173712253805
Validation loss: 2.553887151469939

Epoch: 6| Step: 1
Training loss: 2.183309410294176
Validation loss: 2.5427415221810605

Epoch: 6| Step: 2
Training loss: 1.9519983322652352
Validation loss: 2.5561470272151015

Epoch: 6| Step: 3
Training loss: 3.131969157645611
Validation loss: 2.55082289003089

Epoch: 6| Step: 4
Training loss: 1.617843568565086
Validation loss: 2.5514045798836094

Epoch: 6| Step: 5
Training loss: 2.897665491652491
Validation loss: 2.5822581904679027

Epoch: 6| Step: 6
Training loss: 2.403792873085528
Validation loss: 2.5636329704888774

Epoch: 6| Step: 7
Training loss: 2.4375846065607334
Validation loss: 2.576600134370159

Epoch: 6| Step: 8
Training loss: 2.498070353620607
Validation loss: 2.57204236041871

Epoch: 6| Step: 9
Training loss: 1.780812728481782
Validation loss: 2.5544058268240764

Epoch: 6| Step: 10
Training loss: 2.2616557110844604
Validation loss: 2.5752042158559036

Epoch: 6| Step: 11
Training loss: 2.3067483255048087
Validation loss: 2.558809305288635

Epoch: 6| Step: 12
Training loss: 1.7863252847875408
Validation loss: 2.6273413010910134

Epoch: 6| Step: 13
Training loss: 3.2311827897953
Validation loss: 2.5702407966050496

Epoch: 65| Step: 0
Training loss: 2.423458147975536
Validation loss: 2.5832071401681294

Epoch: 6| Step: 1
Training loss: 2.2980957939028785
Validation loss: 2.5576012469971463

Epoch: 6| Step: 2
Training loss: 2.417070212597924
Validation loss: 2.5473775699334897

Epoch: 6| Step: 3
Training loss: 2.9583345511707075
Validation loss: 2.585241479545629

Epoch: 6| Step: 4
Training loss: 2.789532619145431
Validation loss: 2.525663545498936

Epoch: 6| Step: 5
Training loss: 2.572575184842037
Validation loss: 2.541299243593119

Epoch: 6| Step: 6
Training loss: 2.190076890579783
Validation loss: 2.5824033283457606

Epoch: 6| Step: 7
Training loss: 2.524463929028752
Validation loss: 2.5381728428102472

Epoch: 6| Step: 8
Training loss: 2.752615378557587
Validation loss: 2.5673070494726913

Epoch: 6| Step: 9
Training loss: 1.9624884198084023
Validation loss: 2.5527438158961524

Epoch: 6| Step: 10
Training loss: 1.5682930938282595
Validation loss: 2.5580976398346036

Epoch: 6| Step: 11
Training loss: 2.3065396382886694
Validation loss: 2.5792250473079004

Epoch: 6| Step: 12
Training loss: 1.9352122305271862
Validation loss: 2.565349034015817

Epoch: 6| Step: 13
Training loss: 2.0316434039108087
Validation loss: 2.5594740035300605

Epoch: 66| Step: 0
Training loss: 2.5778590209625523
Validation loss: 2.5676411483878607

Epoch: 6| Step: 1
Training loss: 2.3980434230662158
Validation loss: 2.5650953625109985

Epoch: 6| Step: 2
Training loss: 1.7925211029725845
Validation loss: 2.593786599387433

Epoch: 6| Step: 3
Training loss: 2.994601797083496
Validation loss: 2.5826001716381515

Epoch: 6| Step: 4
Training loss: 2.7166504042281048
Validation loss: 2.5934580136836276

Epoch: 6| Step: 5
Training loss: 2.52305576519567
Validation loss: 2.578433802442558

Epoch: 6| Step: 6
Training loss: 2.7102070904535194
Validation loss: 2.5629984983295193

Epoch: 6| Step: 7
Training loss: 2.53983414881947
Validation loss: 2.598849511528002

Epoch: 6| Step: 8
Training loss: 1.7665931950292442
Validation loss: 2.544419694578394

Epoch: 6| Step: 9
Training loss: 2.2954764747087175
Validation loss: 2.5598697033645155

Epoch: 6| Step: 10
Training loss: 2.1590666135306242
Validation loss: 2.562895736530317

Epoch: 6| Step: 11
Training loss: 2.1027043867160784
Validation loss: 2.535865892052291

Epoch: 6| Step: 12
Training loss: 2.404778959779453
Validation loss: 2.5585303223491502

Epoch: 6| Step: 13
Training loss: 1.3490966617941336
Validation loss: 2.5862093702848887

Epoch: 67| Step: 0
Training loss: 2.5735147581564823
Validation loss: 2.6052483461142493

Epoch: 6| Step: 1
Training loss: 2.759932527132011
Validation loss: 2.6127358149155997

Epoch: 6| Step: 2
Training loss: 2.5739255052174084
Validation loss: 2.5564701809371675

Epoch: 6| Step: 3
Training loss: 2.379401896038905
Validation loss: 2.5550225647678295

Epoch: 6| Step: 4
Training loss: 1.8963387273299468
Validation loss: 2.578764479734098

Epoch: 6| Step: 5
Training loss: 2.16129255156937
Validation loss: 2.6040782048777147

Epoch: 6| Step: 6
Training loss: 2.3148920214457887
Validation loss: 2.5704623007674607

Epoch: 6| Step: 7
Training loss: 3.0609712482985127
Validation loss: 2.5910932730450957

Epoch: 6| Step: 8
Training loss: 2.2587500081064955
Validation loss: 2.554143958641614

Epoch: 6| Step: 9
Training loss: 2.355926722198174
Validation loss: 2.5612867863875604

Epoch: 6| Step: 10
Training loss: 2.19591798950926
Validation loss: 2.5492280259052764

Epoch: 6| Step: 11
Training loss: 1.6429167952873276
Validation loss: 2.5722377411594133

Epoch: 6| Step: 12
Training loss: 2.125979926860567
Validation loss: 2.6041260728851094

Epoch: 6| Step: 13
Training loss: 2.276797089962363
Validation loss: 2.5659579229465463

Epoch: 68| Step: 0
Training loss: 1.8460964853441635
Validation loss: 2.592404962806835

Epoch: 6| Step: 1
Training loss: 1.8243957041617287
Validation loss: 2.6134566099502186

Epoch: 6| Step: 2
Training loss: 1.8115079071942106
Validation loss: 2.5738719345735777

Epoch: 6| Step: 3
Training loss: 2.0208421949474142
Validation loss: 2.611910944941815

Epoch: 6| Step: 4
Training loss: 2.808856808541926
Validation loss: 2.639762609686824

Epoch: 6| Step: 5
Training loss: 2.3712566388911496
Validation loss: 2.6110774518835322

Epoch: 6| Step: 6
Training loss: 2.3834205727071773
Validation loss: 2.618862105999449

Epoch: 6| Step: 7
Training loss: 2.271212193327149
Validation loss: 2.643090686396459

Epoch: 6| Step: 8
Training loss: 2.369489098540917
Validation loss: 2.638461413532838

Epoch: 6| Step: 9
Training loss: 2.670317614234058
Validation loss: 2.631917588212398

Epoch: 6| Step: 10
Training loss: 3.198768891505707
Validation loss: 2.5692409457707006

Epoch: 6| Step: 11
Training loss: 2.1080994316697095
Validation loss: 2.5451534748454527

Epoch: 6| Step: 12
Training loss: 2.38982602400003
Validation loss: 2.565760592719798

Epoch: 6| Step: 13
Training loss: 2.2481516557629226
Validation loss: 2.6003236159640353

Epoch: 69| Step: 0
Training loss: 2.694370713377648
Validation loss: 2.5493292655686255

Epoch: 6| Step: 1
Training loss: 2.1075810468663136
Validation loss: 2.5579042238424874

Epoch: 6| Step: 2
Training loss: 1.6253336050478233
Validation loss: 2.548793920138863

Epoch: 6| Step: 3
Training loss: 3.212550145808008
Validation loss: 2.5497518802055774

Epoch: 6| Step: 4
Training loss: 2.1101605118359292
Validation loss: 2.5412224918245783

Epoch: 6| Step: 5
Training loss: 2.2029792250434186
Validation loss: 2.5935051277727226

Epoch: 6| Step: 6
Training loss: 1.3505478065387326
Validation loss: 2.551571048520577

Epoch: 6| Step: 7
Training loss: 2.4116520869041294
Validation loss: 2.6082372107379785

Epoch: 6| Step: 8
Training loss: 3.120181832516937
Validation loss: 2.602706604145827

Epoch: 6| Step: 9
Training loss: 2.0040947005687273
Validation loss: 2.5821224317739637

Epoch: 6| Step: 10
Training loss: 2.771008526610324
Validation loss: 2.5551295388958715

Epoch: 6| Step: 11
Training loss: 2.1752175057933325
Validation loss: 2.633750303268717

Epoch: 6| Step: 12
Training loss: 2.283698244474073
Validation loss: 2.635146331994635

Epoch: 6| Step: 13
Training loss: 2.0957477205763055
Validation loss: 2.5965814723712293

Epoch: 70| Step: 0
Training loss: 2.5308620956272034
Validation loss: 2.576478120013209

Epoch: 6| Step: 1
Training loss: 2.6108281092668078
Validation loss: 2.5804188089738087

Epoch: 6| Step: 2
Training loss: 2.0782924957464424
Validation loss: 2.588261584679206

Epoch: 6| Step: 3
Training loss: 2.186023977121991
Validation loss: 2.5570424897929493

Epoch: 6| Step: 4
Training loss: 2.8422324354783437
Validation loss: 2.5875074340418664

Epoch: 6| Step: 5
Training loss: 2.0869317703316934
Validation loss: 2.609505183766183

Epoch: 6| Step: 6
Training loss: 2.25088928450645
Validation loss: 2.567839486961925

Epoch: 6| Step: 7
Training loss: 2.4702833218573494
Validation loss: 2.5377700489710184

Epoch: 6| Step: 8
Training loss: 2.378270156580851
Validation loss: 2.604520824509989

Epoch: 6| Step: 9
Training loss: 1.7992691675659636
Validation loss: 2.572009499402299

Epoch: 6| Step: 10
Training loss: 2.4060326019767277
Validation loss: 2.5690608817994347

Epoch: 6| Step: 11
Training loss: 2.476369471202561
Validation loss: 2.545462265276453

Epoch: 6| Step: 12
Training loss: 2.06760122436558
Validation loss: 2.5604312889068543

Epoch: 6| Step: 13
Training loss: 2.196435607119112
Validation loss: 2.555652634416916

Epoch: 71| Step: 0
Training loss: 2.1689568544619173
Validation loss: 2.603926492424085

Epoch: 6| Step: 1
Training loss: 2.358817836835186
Validation loss: 2.5693583316520585

Epoch: 6| Step: 2
Training loss: 1.9575416371483478
Validation loss: 2.5893648912197347

Epoch: 6| Step: 3
Training loss: 2.7707938475890628
Validation loss: 2.5589938794850813

Epoch: 6| Step: 4
Training loss: 1.7797518000989476
Validation loss: 2.5669774271942583

Epoch: 6| Step: 5
Training loss: 2.1826855676508803
Validation loss: 2.5841408410904374

Epoch: 6| Step: 6
Training loss: 1.831555725720369
Validation loss: 2.54266416539191

Epoch: 6| Step: 7
Training loss: 1.7466750574759724
Validation loss: 2.5679036208681807

Epoch: 6| Step: 8
Training loss: 2.2248227466744117
Validation loss: 2.615466137265691

Epoch: 6| Step: 9
Training loss: 2.4287231101423945
Validation loss: 2.5363734398851583

Epoch: 6| Step: 10
Training loss: 2.9859359413833584
Validation loss: 2.5822151030135743

Epoch: 6| Step: 11
Training loss: 2.645461489362342
Validation loss: 2.550458170052411

Epoch: 6| Step: 12
Training loss: 2.519611493392725
Validation loss: 2.624785982217595

Epoch: 6| Step: 13
Training loss: 2.5858414277730573
Validation loss: 2.621198687132265

Epoch: 72| Step: 0
Training loss: 2.566523301055028
Validation loss: 2.635229847937032

Epoch: 6| Step: 1
Training loss: 1.5679792843832099
Validation loss: 2.564538362068986

Epoch: 6| Step: 2
Training loss: 2.9236824850480025
Validation loss: 2.603957043158185

Epoch: 6| Step: 3
Training loss: 2.522352617266285
Validation loss: 2.572179570323907

Epoch: 6| Step: 4
Training loss: 2.201541845848822
Validation loss: 2.5888270342981943

Epoch: 6| Step: 5
Training loss: 2.261424834502463
Validation loss: 2.5731052967892647

Epoch: 6| Step: 6
Training loss: 2.458916697279051
Validation loss: 2.58494195281425

Epoch: 6| Step: 7
Training loss: 2.678857613670209
Validation loss: 2.6026939016805324

Epoch: 6| Step: 8
Training loss: 2.3350840767012375
Validation loss: 2.576718480385791

Epoch: 6| Step: 9
Training loss: 2.1083314928290533
Validation loss: 2.607402368060614

Epoch: 6| Step: 10
Training loss: 2.1891913278751916
Validation loss: 2.5816800354261944

Epoch: 6| Step: 11
Training loss: 2.4213729830315947
Validation loss: 2.5774821857585417

Epoch: 6| Step: 12
Training loss: 1.6708350824488032
Validation loss: 2.5716255490354945

Epoch: 6| Step: 13
Training loss: 2.177019133526221
Validation loss: 2.5797325131890507

Epoch: 73| Step: 0
Training loss: 2.3229351185520533
Validation loss: 2.560060976327945

Epoch: 6| Step: 1
Training loss: 2.1286645594601468
Validation loss: 2.545347727045306

Epoch: 6| Step: 2
Training loss: 2.4949549314292794
Validation loss: 2.586271035926391

Epoch: 6| Step: 3
Training loss: 1.886161579767127
Validation loss: 2.5968742398147295

Epoch: 6| Step: 4
Training loss: 2.020595602098361
Validation loss: 2.5616420457095654

Epoch: 6| Step: 5
Training loss: 2.623208479117615
Validation loss: 2.5949762348907215

Epoch: 6| Step: 6
Training loss: 1.696073018724421
Validation loss: 2.578468947153511

Epoch: 6| Step: 7
Training loss: 3.218468218570784
Validation loss: 2.5784291714111616

Epoch: 6| Step: 8
Training loss: 2.504716239283615
Validation loss: 2.6166400393773324

Epoch: 6| Step: 9
Training loss: 1.904725011967822
Validation loss: 2.595125790991319

Epoch: 6| Step: 10
Training loss: 2.4078218354694614
Validation loss: 2.643835046541063

Epoch: 6| Step: 11
Training loss: 2.064709491384557
Validation loss: 2.640661070086372

Epoch: 6| Step: 12
Training loss: 2.6774293153980064
Validation loss: 2.637374562780465

Epoch: 6| Step: 13
Training loss: 1.90934577082911
Validation loss: 2.5859458900154206

Epoch: 74| Step: 0
Training loss: 2.016434854262437
Validation loss: 2.5260004308946353

Epoch: 6| Step: 1
Training loss: 2.620260046363965
Validation loss: 2.5727272478770056

Epoch: 6| Step: 2
Training loss: 2.3167315764447425
Validation loss: 2.5794247982368703

Epoch: 6| Step: 3
Training loss: 3.3181939760225303
Validation loss: 2.5517136027003686

Epoch: 6| Step: 4
Training loss: 1.9234003976052558
Validation loss: 2.5177920940851086

Epoch: 6| Step: 5
Training loss: 2.2908638906354697
Validation loss: 2.56114056821512

Epoch: 6| Step: 6
Training loss: 2.0341531987143555
Validation loss: 2.5652152306899696

Epoch: 6| Step: 7
Training loss: 1.7957708532287486
Validation loss: 2.581507842799771

Epoch: 6| Step: 8
Training loss: 2.616121627348314
Validation loss: 2.581992514084558

Epoch: 6| Step: 9
Training loss: 2.121215592005809
Validation loss: 2.591011102646469

Epoch: 6| Step: 10
Training loss: 2.6901183569584033
Validation loss: 2.5581589656972974

Epoch: 6| Step: 11
Training loss: 1.9395205513872598
Validation loss: 2.6138812689197732

Epoch: 6| Step: 12
Training loss: 1.905337944092365
Validation loss: 2.597680893401081

Epoch: 6| Step: 13
Training loss: 2.2529621758534732
Validation loss: 2.5681179614886234

Epoch: 75| Step: 0
Training loss: 2.507578140669056
Validation loss: 2.6013624249906937

Epoch: 6| Step: 1
Training loss: 2.3358360447109714
Validation loss: 2.589134076881978

Epoch: 6| Step: 2
Training loss: 2.493898002037748
Validation loss: 2.561974634418691

Epoch: 6| Step: 3
Training loss: 2.496967956569578
Validation loss: 2.57237344997132

Epoch: 6| Step: 4
Training loss: 2.7513942651911694
Validation loss: 2.5728116548140583

Epoch: 6| Step: 5
Training loss: 1.994346854580038
Validation loss: 2.558381748880364

Epoch: 6| Step: 6
Training loss: 2.2070504786911247
Validation loss: 2.5443463869046945

Epoch: 6| Step: 7
Training loss: 1.8761100661965462
Validation loss: 2.5476113797498106

Epoch: 6| Step: 8
Training loss: 2.282305329660747
Validation loss: 2.581799256737331

Epoch: 6| Step: 9
Training loss: 2.3931293210747504
Validation loss: 2.5558267555446537

Epoch: 6| Step: 10
Training loss: 2.6339876625507808
Validation loss: 2.5467668131997945

Epoch: 6| Step: 11
Training loss: 1.923950749086124
Validation loss: 2.565522837802187

Epoch: 6| Step: 12
Training loss: 1.7352134808510442
Validation loss: 2.5485851420489336

Epoch: 6| Step: 13
Training loss: 2.244623117395869
Validation loss: 2.5940433703968204

Testing loss: 2.1127951769430027
