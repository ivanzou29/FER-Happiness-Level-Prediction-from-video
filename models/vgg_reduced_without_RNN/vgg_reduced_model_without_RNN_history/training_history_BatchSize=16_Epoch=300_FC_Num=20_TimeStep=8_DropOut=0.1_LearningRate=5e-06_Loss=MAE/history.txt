Epoch: 1| Step: 0
Training loss: 4.097617149353027
Validation loss: 4.450871070226033

Epoch: 6| Step: 1
Training loss: 4.202910900115967
Validation loss: 4.434847950935364

Epoch: 6| Step: 2
Training loss: 4.856080055236816
Validation loss: 4.417370676994324

Epoch: 6| Step: 3
Training loss: 5.1844305992126465
Validation loss: 4.403368433316548

Epoch: 6| Step: 4
Training loss: 4.837313652038574
Validation loss: 4.38837484518687

Epoch: 6| Step: 5
Training loss: 5.590055465698242
Validation loss: 4.373470942179362

Epoch: 6| Step: 6
Training loss: 4.861248016357422
Validation loss: 4.357326070467631

Epoch: 6| Step: 7
Training loss: 3.951653003692627
Validation loss: 4.347213705380757

Epoch: 6| Step: 8
Training loss: 5.126458168029785
Validation loss: 4.335609118143718

Epoch: 6| Step: 9
Training loss: 4.149530410766602
Validation loss: 4.32319712638855

Epoch: 6| Step: 10
Training loss: 3.938307523727417
Validation loss: 4.308190623919169

Epoch: 6| Step: 11
Training loss: 2.977916717529297
Validation loss: 4.298226833343506

Epoch: 6| Step: 12
Training loss: 6.107309341430664
Validation loss: 4.283368468284607

Epoch: 6| Step: 13
Training loss: 2.822429656982422
Validation loss: 4.268572012583415

Epoch: 2| Step: 0
Training loss: 4.354551315307617
Validation loss: 4.258879105250041

Epoch: 6| Step: 1
Training loss: 5.114720344543457
Validation loss: 4.240025798479716

Epoch: 6| Step: 2
Training loss: 4.104992866516113
Validation loss: 4.2280376354853315

Epoch: 6| Step: 3
Training loss: 3.2347123622894287
Validation loss: 4.210162878036499

Epoch: 6| Step: 4
Training loss: 4.693533420562744
Validation loss: 4.19174853960673

Epoch: 6| Step: 5
Training loss: 4.087830543518066
Validation loss: 4.169677178064982

Epoch: 6| Step: 6
Training loss: 5.276823043823242
Validation loss: 4.148803194363912

Epoch: 6| Step: 7
Training loss: 5.0236310958862305
Validation loss: 4.128098050753276

Epoch: 6| Step: 8
Training loss: 4.29427433013916
Validation loss: 4.105318625768025

Epoch: 6| Step: 9
Training loss: 2.910419464111328
Validation loss: 4.077378670374553

Epoch: 6| Step: 10
Training loss: 4.038543224334717
Validation loss: 4.055391867955525

Epoch: 6| Step: 11
Training loss: 3.8094959259033203
Validation loss: 4.032764554023743

Epoch: 6| Step: 12
Training loss: 4.550652503967285
Validation loss: 4.007092197736104

Epoch: 6| Step: 13
Training loss: 4.228316307067871
Validation loss: 3.976050615310669

Epoch: 3| Step: 0
Training loss: 3.556868314743042
Validation loss: 3.9501720666885376

Epoch: 6| Step: 1
Training loss: 4.995450019836426
Validation loss: 3.9216095209121704

Epoch: 6| Step: 2
Training loss: 3.318164110183716
Validation loss: 3.889272848765055

Epoch: 6| Step: 3
Training loss: 4.089548587799072
Validation loss: 3.8580267429351807

Epoch: 6| Step: 4
Training loss: 2.7298760414123535
Validation loss: 3.8201828002929688

Epoch: 6| Step: 5
Training loss: 3.2962868213653564
Validation loss: 3.7865785360336304

Epoch: 6| Step: 6
Training loss: 4.445953369140625
Validation loss: 3.746419588724772

Epoch: 6| Step: 7
Training loss: 3.7355425357818604
Validation loss: 3.708340366681417

Epoch: 6| Step: 8
Training loss: 3.6785755157470703
Validation loss: 3.664860208829244

Epoch: 6| Step: 9
Training loss: 3.6932902336120605
Validation loss: 3.6260151068369546

Epoch: 6| Step: 10
Training loss: 3.3470730781555176
Validation loss: 3.585525075594584

Epoch: 6| Step: 11
Training loss: 4.878931999206543
Validation loss: 3.5371740659077964

Epoch: 6| Step: 12
Training loss: 3.3658266067504883
Validation loss: 3.489306926727295

Epoch: 6| Step: 13
Training loss: 4.730899810791016
Validation loss: 3.431144952774048

Epoch: 4| Step: 0
Training loss: 4.074125289916992
Validation loss: 3.3721755743026733

Epoch: 6| Step: 1
Training loss: 3.982619047164917
Validation loss: 3.322139024734497

Epoch: 6| Step: 2
Training loss: 3.0506134033203125
Validation loss: 3.266135811805725

Epoch: 6| Step: 3
Training loss: 3.164705276489258
Validation loss: 3.201277017593384

Epoch: 6| Step: 4
Training loss: 3.062079906463623
Validation loss: 3.1549397706985474

Epoch: 6| Step: 5
Training loss: 3.248465061187744
Validation loss: 3.0871995290120444

Epoch: 6| Step: 6
Training loss: 4.021808624267578
Validation loss: 3.019613027572632

Epoch: 6| Step: 7
Training loss: 2.9458799362182617
Validation loss: 2.9729186296463013

Epoch: 6| Step: 8
Training loss: 3.3379645347595215
Validation loss: 2.8904295762379966

Epoch: 6| Step: 9
Training loss: 2.195070743560791
Validation loss: 2.812406818072001

Epoch: 6| Step: 10
Training loss: 1.9968394041061401
Validation loss: 2.7530991236368814

Epoch: 6| Step: 11
Training loss: 2.653810977935791
Validation loss: 2.6788829565048218

Epoch: 6| Step: 12
Training loss: 2.4964897632598877
Validation loss: 2.602816661198934

Epoch: 6| Step: 13
Training loss: 2.8319971561431885
Validation loss: 2.5400843222935996

Epoch: 5| Step: 0
Training loss: 2.8520755767822266
Validation loss: 2.4530720313390098

Epoch: 6| Step: 1
Training loss: 2.2217979431152344
Validation loss: 2.3976577520370483

Epoch: 6| Step: 2
Training loss: 2.462817668914795
Validation loss: 2.3332974712053933

Epoch: 6| Step: 3
Training loss: 2.0621252059936523
Validation loss: 2.280797759691874

Epoch: 6| Step: 4
Training loss: 1.718640685081482
Validation loss: 2.226345936457316

Epoch: 6| Step: 5
Training loss: 2.4288105964660645
Validation loss: 2.1855472524960837

Epoch: 6| Step: 6
Training loss: 1.5874199867248535
Validation loss: 2.1597943703333535

Epoch: 6| Step: 7
Training loss: 2.3347744941711426
Validation loss: 2.126233677069346

Epoch: 6| Step: 8
Training loss: 2.378109931945801
Validation loss: 2.142684976259867

Epoch: 6| Step: 9
Training loss: 2.3784019947052
Validation loss: 2.110652585824331

Epoch: 6| Step: 10
Training loss: 2.4805214405059814
Validation loss: 2.125550071398417

Epoch: 6| Step: 11
Training loss: 2.7164835929870605
Validation loss: 2.132417837778727

Epoch: 6| Step: 12
Training loss: 1.2794713973999023
Validation loss: 2.1474382678667703

Epoch: 6| Step: 13
Training loss: 1.3934149742126465
Validation loss: 2.1500540574391684

Epoch: 6| Step: 0
Training loss: 2.046233654022217
Validation loss: 2.1750034292538962

Epoch: 6| Step: 1
Training loss: 3.119994640350342
Validation loss: 2.1887541015942893

Epoch: 6| Step: 2
Training loss: 2.1051526069641113
Validation loss: 2.1743886272112527

Epoch: 6| Step: 3
Training loss: 1.9717053174972534
Validation loss: 2.2121059695879617

Epoch: 6| Step: 4
Training loss: 2.3703179359436035
Validation loss: 2.169965306917826

Epoch: 6| Step: 5
Training loss: 1.4472072124481201
Validation loss: 2.2021236022313437

Epoch: 6| Step: 6
Training loss: 2.3986599445343018
Validation loss: 2.2051390012105307

Epoch: 6| Step: 7
Training loss: 1.8025414943695068
Validation loss: 2.2112369934717813

Epoch: 6| Step: 8
Training loss: 2.550961971282959
Validation loss: 2.190680225690206

Epoch: 6| Step: 9
Training loss: 1.6150822639465332
Validation loss: 2.167281528313955

Epoch: 6| Step: 10
Training loss: 2.458038806915283
Validation loss: 2.1467525362968445

Epoch: 6| Step: 11
Training loss: 2.599428653717041
Validation loss: 2.125483214855194

Epoch: 6| Step: 12
Training loss: 1.3907488584518433
Validation loss: 2.1288646856943765

Epoch: 6| Step: 13
Training loss: 1.5010504722595215
Validation loss: 2.1243247985839844

Epoch: 7| Step: 0
Training loss: 2.5133893489837646
Validation loss: 2.0924278696378074

Epoch: 6| Step: 1
Training loss: 2.846015214920044
Validation loss: 2.0970599253972373

Epoch: 6| Step: 2
Training loss: 1.745988130569458
Validation loss: 2.1280929843584695

Epoch: 6| Step: 3
Training loss: 2.148649215698242
Validation loss: 2.147029678026835

Epoch: 6| Step: 4
Training loss: 2.233018159866333
Validation loss: 2.1190818548202515

Epoch: 6| Step: 5
Training loss: 2.604038953781128
Validation loss: 2.141152799129486

Epoch: 6| Step: 6
Training loss: 1.8764088153839111
Validation loss: 2.13953431447347

Epoch: 6| Step: 7
Training loss: 2.388091564178467
Validation loss: 2.1432193319002786

Epoch: 6| Step: 8
Training loss: 2.3539304733276367
Validation loss: 2.1250822146733603

Epoch: 6| Step: 9
Training loss: 1.9087426662445068
Validation loss: 2.1526841123898826

Epoch: 6| Step: 10
Training loss: 1.9103611707687378
Validation loss: 2.1323293248812356

Epoch: 6| Step: 11
Training loss: 1.2802526950836182
Validation loss: 2.13972008228302

Epoch: 6| Step: 12
Training loss: 1.8274381160736084
Validation loss: 2.1287087202072144

Epoch: 6| Step: 13
Training loss: 2.0793397426605225
Validation loss: 2.143652399381002

Epoch: 8| Step: 0
Training loss: 2.5391228199005127
Validation loss: 2.1259913047154746

Epoch: 6| Step: 1
Training loss: 2.00431752204895
Validation loss: 2.1097030440966287

Epoch: 6| Step: 2
Training loss: 1.7451175451278687
Validation loss: 2.1208452781041465

Epoch: 6| Step: 3
Training loss: 2.3352386951446533
Validation loss: 2.1079819003740945

Epoch: 6| Step: 4
Training loss: 2.2349491119384766
Validation loss: 2.082025130589803

Epoch: 6| Step: 5
Training loss: 1.791777491569519
Validation loss: 2.085174262523651

Epoch: 6| Step: 6
Training loss: 1.607488751411438
Validation loss: 2.1132487058639526

Epoch: 6| Step: 7
Training loss: 1.9467390775680542
Validation loss: 2.097284416357676

Epoch: 6| Step: 8
Training loss: 1.7216458320617676
Validation loss: 2.092196464538574

Epoch: 6| Step: 9
Training loss: 2.5117549896240234
Validation loss: 2.1179046630859375

Epoch: 6| Step: 10
Training loss: 2.1131882667541504
Validation loss: 2.0935644706090293

Epoch: 6| Step: 11
Training loss: 1.5430779457092285
Validation loss: 2.115580936272939

Epoch: 6| Step: 12
Training loss: 2.5980186462402344
Validation loss: 2.13587878147761

Epoch: 6| Step: 13
Training loss: 2.4820268154144287
Validation loss: 2.1155831813812256

Epoch: 9| Step: 0
Training loss: 1.5180282592773438
Validation loss: 2.108680009841919

Epoch: 6| Step: 1
Training loss: 1.9039500951766968
Validation loss: 2.0929084420204163

Epoch: 6| Step: 2
Training loss: 2.235714912414551
Validation loss: 2.1252238750457764

Epoch: 6| Step: 3
Training loss: 1.997916579246521
Validation loss: 2.0969865322113037

Epoch: 6| Step: 4
Training loss: 2.0519371032714844
Validation loss: 2.0883933504422507

Epoch: 6| Step: 5
Training loss: 1.931429147720337
Validation loss: 2.103598415851593

Epoch: 6| Step: 6
Training loss: 2.463533878326416
Validation loss: 2.099621335665385

Epoch: 6| Step: 7
Training loss: 1.8876484632492065
Validation loss: 2.0881919264793396

Epoch: 6| Step: 8
Training loss: 2.0611135959625244
Validation loss: 2.1030899484952292

Epoch: 6| Step: 9
Training loss: 2.332130193710327
Validation loss: 2.0928796331087747

Epoch: 6| Step: 10
Training loss: 1.9862024784088135
Validation loss: 2.0896781285603843

Epoch: 6| Step: 11
Training loss: 1.9601308107376099
Validation loss: 2.0988683501879373

Epoch: 6| Step: 12
Training loss: 2.633148670196533
Validation loss: 2.079087416330973

Epoch: 6| Step: 13
Training loss: 1.6680227518081665
Validation loss: 2.0969576636950173

Epoch: 10| Step: 0
Training loss: 2.0011560916900635
Validation loss: 2.1081850131352744

Epoch: 6| Step: 1
Training loss: 2.415012836456299
Validation loss: 2.079858402411143

Epoch: 6| Step: 2
Training loss: 1.9322295188903809
Validation loss: 2.083052933216095

Epoch: 6| Step: 3
Training loss: 2.396958351135254
Validation loss: 2.0857481559117637

Epoch: 6| Step: 4
Training loss: 2.1143784523010254
Validation loss: 2.078505198160807

Epoch: 6| Step: 5
Training loss: 2.0295958518981934
Validation loss: 2.0974668661753335

Epoch: 6| Step: 6
Training loss: 1.8780014514923096
Validation loss: 2.079865833123525

Epoch: 6| Step: 7
Training loss: 1.6842628717422485
Validation loss: 2.096478740374247

Epoch: 6| Step: 8
Training loss: 1.9303233623504639
Validation loss: 2.071131447950999

Epoch: 6| Step: 9
Training loss: 1.9749701023101807
Validation loss: 2.092307448387146

Epoch: 6| Step: 10
Training loss: 2.5777406692504883
Validation loss: 2.085892120997111

Epoch: 6| Step: 11
Training loss: 1.9379773139953613
Validation loss: 2.071011741956075

Epoch: 6| Step: 12
Training loss: 2.053956985473633
Validation loss: 2.0895047386487327

Epoch: 6| Step: 13
Training loss: 1.695732593536377
Validation loss: 2.0712267756462097

Epoch: 11| Step: 0
Training loss: 2.1643481254577637
Validation loss: 2.0837432543436685

Epoch: 6| Step: 1
Training loss: 2.3087971210479736
Validation loss: 2.1017145911852517

Epoch: 6| Step: 2
Training loss: 2.219358444213867
Validation loss: 2.0955471793810525

Epoch: 6| Step: 3
Training loss: 1.539627194404602
Validation loss: 2.0966440041859946

Epoch: 6| Step: 4
Training loss: 2.522878646850586
Validation loss: 2.0884875853856406

Epoch: 6| Step: 5
Training loss: 1.9735157489776611
Validation loss: 2.072115182876587

Epoch: 6| Step: 6
Training loss: 2.5255866050720215
Validation loss: 2.0653884212176004

Epoch: 6| Step: 7
Training loss: 2.1335673332214355
Validation loss: 2.0899190505345664

Epoch: 6| Step: 8
Training loss: 1.7732994556427002
Validation loss: 2.078749199708303

Epoch: 6| Step: 9
Training loss: 1.7840399742126465
Validation loss: 2.094331900278727

Epoch: 6| Step: 10
Training loss: 2.020918846130371
Validation loss: 2.085545778274536

Epoch: 6| Step: 11
Training loss: 1.6521759033203125
Validation loss: 2.079938451449076

Epoch: 6| Step: 12
Training loss: 2.265336275100708
Validation loss: 2.081587334473928

Epoch: 6| Step: 13
Training loss: 1.5555598735809326
Validation loss: 2.073340038458506

Epoch: 12| Step: 0
Training loss: 1.9047576189041138
Validation loss: 2.074725011984507

Epoch: 6| Step: 1
Training loss: 1.8181959390640259
Validation loss: 2.077867269515991

Epoch: 6| Step: 2
Training loss: 2.123528480529785
Validation loss: 2.068342904249827

Epoch: 6| Step: 3
Training loss: 2.3802857398986816
Validation loss: 2.0671806931495667

Epoch: 6| Step: 4
Training loss: 2.0960967540740967
Validation loss: 2.0768535137176514

Epoch: 6| Step: 5
Training loss: 2.5821826457977295
Validation loss: 2.089110811551412

Epoch: 6| Step: 6
Training loss: 1.034116506576538
Validation loss: 2.0936598976453147

Epoch: 6| Step: 7
Training loss: 2.4390738010406494
Validation loss: 2.0816442370414734

Epoch: 6| Step: 8
Training loss: 1.8800331354141235
Validation loss: 2.0789554913838706

Epoch: 6| Step: 9
Training loss: 1.9996819496154785
Validation loss: 2.0732776323954263

Epoch: 6| Step: 10
Training loss: 1.82962965965271
Validation loss: 2.108661433060964

Epoch: 6| Step: 11
Training loss: 1.7379350662231445
Validation loss: 2.1059696276982627

Epoch: 6| Step: 12
Training loss: 1.97719144821167
Validation loss: 2.0692859490712485

Epoch: 6| Step: 13
Training loss: 2.541344404220581
Validation loss: 2.079128921031952

Epoch: 13| Step: 0
Training loss: 2.8249192237854004
Validation loss: 2.0913586815198264

Epoch: 6| Step: 1
Training loss: 2.0188164710998535
Validation loss: 2.0641422669092813

Epoch: 6| Step: 2
Training loss: 2.0181961059570312
Validation loss: 2.0559842189153037

Epoch: 6| Step: 3
Training loss: 2.631962776184082
Validation loss: 2.0734448432922363

Epoch: 6| Step: 4
Training loss: 1.225478172302246
Validation loss: 2.080445726712545

Epoch: 6| Step: 5
Training loss: 2.14404034614563
Validation loss: 2.0982176065444946

Epoch: 6| Step: 6
Training loss: 1.567319393157959
Validation loss: 2.063238282998403

Epoch: 6| Step: 7
Training loss: 1.7888712882995605
Validation loss: 2.053700029850006

Epoch: 6| Step: 8
Training loss: 2.5744051933288574
Validation loss: 2.068126916885376

Epoch: 6| Step: 9
Training loss: 1.8060004711151123
Validation loss: 2.0846617420514426

Epoch: 6| Step: 10
Training loss: 2.6658403873443604
Validation loss: 2.069854120413462

Epoch: 6| Step: 11
Training loss: 1.6992567777633667
Validation loss: 2.0883015791575112

Epoch: 6| Step: 12
Training loss: 1.4285674095153809
Validation loss: 2.0651712814966836

Epoch: 6| Step: 13
Training loss: 1.698062777519226
Validation loss: 2.09119842449824

Epoch: 14| Step: 0
Training loss: 2.0816121101379395
Validation loss: 2.0776344935099282

Epoch: 6| Step: 1
Training loss: 2.1156697273254395
Validation loss: 2.0882059931755066

Epoch: 6| Step: 2
Training loss: 1.8085787296295166
Validation loss: 2.075447122255961

Epoch: 6| Step: 3
Training loss: 1.2292969226837158
Validation loss: 2.0601612528165183

Epoch: 6| Step: 4
Training loss: 2.228759765625
Validation loss: 2.0615593791007996

Epoch: 6| Step: 5
Training loss: 2.302980661392212
Validation loss: 2.0666043957074485

Epoch: 6| Step: 6
Training loss: 2.707958698272705
Validation loss: 2.07917187611262

Epoch: 6| Step: 7
Training loss: 1.9584304094314575
Validation loss: 2.0722395181655884

Epoch: 6| Step: 8
Training loss: 2.18214750289917
Validation loss: 2.06455405553182

Epoch: 6| Step: 9
Training loss: 1.9037423133850098
Validation loss: 2.0792012214660645

Epoch: 6| Step: 10
Training loss: 1.5172991752624512
Validation loss: 2.0795035560925803

Epoch: 6| Step: 11
Training loss: 2.018548011779785
Validation loss: 2.0570051074028015

Epoch: 6| Step: 12
Training loss: 1.8100121021270752
Validation loss: 2.061570465564728

Epoch: 6| Step: 13
Training loss: 2.2072882652282715
Validation loss: 2.079716205596924

Epoch: 15| Step: 0
Training loss: 1.6460230350494385
Validation loss: 2.0624423027038574

Epoch: 6| Step: 1
Training loss: 1.6449686288833618
Validation loss: 2.0652254819869995

Epoch: 6| Step: 2
Training loss: 2.1445116996765137
Validation loss: 2.077391743659973

Epoch: 6| Step: 3
Training loss: 2.0815083980560303
Validation loss: 2.0752281546592712

Epoch: 6| Step: 4
Training loss: 1.9652645587921143
Validation loss: 2.0698573191960654

Epoch: 6| Step: 5
Training loss: 2.161050796508789
Validation loss: 2.064941147963206

Epoch: 6| Step: 6
Training loss: 2.1351492404937744
Validation loss: 2.0795768896738687

Epoch: 6| Step: 7
Training loss: 1.9832713603973389
Validation loss: 2.0803095400333405

Epoch: 6| Step: 8
Training loss: 3.2645492553710938
Validation loss: 2.0496464172999063

Epoch: 6| Step: 9
Training loss: 2.007780075073242
Validation loss: 2.0421249071756997

Epoch: 6| Step: 10
Training loss: 1.8507840633392334
Validation loss: 2.0499274929364524

Epoch: 6| Step: 11
Training loss: 1.718196988105774
Validation loss: 2.04262504975001

Epoch: 6| Step: 12
Training loss: 1.923970341682434
Validation loss: 2.0514264901479087

Epoch: 6| Step: 13
Training loss: 1.363004207611084
Validation loss: 2.061971286932627

Epoch: 16| Step: 0
Training loss: 2.088871479034424
Validation loss: 2.07204004128774

Epoch: 6| Step: 1
Training loss: 1.9789067506790161
Validation loss: 2.0631475845972695

Epoch: 6| Step: 2
Training loss: 2.606915235519409
Validation loss: 2.032688577969869

Epoch: 6| Step: 3
Training loss: 1.996654748916626
Validation loss: 2.0646406610806785

Epoch: 6| Step: 4
Training loss: 2.029480457305908
Validation loss: 2.0459396839141846

Epoch: 6| Step: 5
Training loss: 1.7366054058074951
Validation loss: 2.05704536040624

Epoch: 6| Step: 6
Training loss: 2.112581968307495
Validation loss: 2.0643101135889688

Epoch: 6| Step: 7
Training loss: 1.9861459732055664
Validation loss: 2.0571489334106445

Epoch: 6| Step: 8
Training loss: 2.6314854621887207
Validation loss: 2.0763288935025535

Epoch: 6| Step: 9
Training loss: 1.4870526790618896
Validation loss: 2.0560302138328552

Epoch: 6| Step: 10
Training loss: 1.9379594326019287
Validation loss: 2.101274232069651

Epoch: 6| Step: 11
Training loss: 1.5846126079559326
Validation loss: 2.0582275986671448

Epoch: 6| Step: 12
Training loss: 2.0509848594665527
Validation loss: 2.075599114100138

Epoch: 6| Step: 13
Training loss: 1.8257203102111816
Validation loss: 2.089951674143473

Epoch: 17| Step: 0
Training loss: 1.848597526550293
Validation loss: 2.083843688170115

Epoch: 6| Step: 1
Training loss: 2.1091904640197754
Validation loss: 2.0650742451349893

Epoch: 6| Step: 2
Training loss: 2.476367950439453
Validation loss: 2.075696329275767

Epoch: 6| Step: 3
Training loss: 2.3050928115844727
Validation loss: 2.049888253211975

Epoch: 6| Step: 4
Training loss: 2.4277267456054688
Validation loss: 2.0766493479410806

Epoch: 6| Step: 5
Training loss: 1.2776893377304077
Validation loss: 2.046900530656179

Epoch: 6| Step: 6
Training loss: 2.0206048488616943
Validation loss: 2.0715233286221824

Epoch: 6| Step: 7
Training loss: 2.279414176940918
Validation loss: 2.0474203626314798

Epoch: 6| Step: 8
Training loss: 1.2787033319473267
Validation loss: 2.056486129760742

Epoch: 6| Step: 9
Training loss: 2.4981837272644043
Validation loss: 2.0449950297673545

Epoch: 6| Step: 10
Training loss: 1.992776870727539
Validation loss: 2.041526714960734

Epoch: 6| Step: 11
Training loss: 1.7585816383361816
Validation loss: 2.0566311478614807

Epoch: 6| Step: 12
Training loss: 2.1155195236206055
Validation loss: 2.0283718506495156

Epoch: 6| Step: 13
Training loss: 1.8166753053665161
Validation loss: 2.063883662223816

Epoch: 18| Step: 0
Training loss: 1.8611407279968262
Validation loss: 2.061986764272054

Epoch: 6| Step: 1
Training loss: 1.857396125793457
Validation loss: 2.0698282718658447

Epoch: 6| Step: 2
Training loss: 2.3167428970336914
Validation loss: 2.044878045717875

Epoch: 6| Step: 3
Training loss: 1.934929609298706
Validation loss: 2.054453651110331

Epoch: 6| Step: 4
Training loss: 1.9273828268051147
Validation loss: 2.072349230448405

Epoch: 6| Step: 5
Training loss: 1.8692940473556519
Validation loss: 2.0780075788497925

Epoch: 6| Step: 6
Training loss: 2.611867666244507
Validation loss: 2.0455573201179504

Epoch: 6| Step: 7
Training loss: 1.881134033203125
Validation loss: 2.030661324659983

Epoch: 6| Step: 8
Training loss: 1.2740298509597778
Validation loss: 2.067161520322164

Epoch: 6| Step: 9
Training loss: 1.6562575101852417
Validation loss: 2.087489744027456

Epoch: 6| Step: 10
Training loss: 2.5165817737579346
Validation loss: 2.0560415188471475

Epoch: 6| Step: 11
Training loss: 1.413208246231079
Validation loss: 2.0485735336939492

Epoch: 6| Step: 12
Training loss: 2.499509334564209
Validation loss: 2.056389649709066

Epoch: 6| Step: 13
Training loss: 2.2290730476379395
Validation loss: 2.0577505826950073

Epoch: 19| Step: 0
Training loss: 2.231020450592041
Validation loss: 2.0794114669164023

Epoch: 6| Step: 1
Training loss: 1.7137242555618286
Validation loss: 2.0608463486035666

Epoch: 6| Step: 2
Training loss: 1.8950444459915161
Validation loss: 2.05691929658254

Epoch: 6| Step: 3
Training loss: 1.4869060516357422
Validation loss: 2.0753162503242493

Epoch: 6| Step: 4
Training loss: 2.3001787662506104
Validation loss: 2.0515705744425454

Epoch: 6| Step: 5
Training loss: 1.9919893741607666
Validation loss: 2.0405933459599814

Epoch: 6| Step: 6
Training loss: 2.0348541736602783
Validation loss: 2.0416373014450073

Epoch: 6| Step: 7
Training loss: 1.6722707748413086
Validation loss: 2.0535704493522644

Epoch: 6| Step: 8
Training loss: 2.109621524810791
Validation loss: 2.051575481891632

Epoch: 6| Step: 9
Training loss: 1.6316519975662231
Validation loss: 2.051323195298513

Epoch: 6| Step: 10
Training loss: 2.633295774459839
Validation loss: 2.05664590994517

Epoch: 6| Step: 11
Training loss: 2.040524482727051
Validation loss: 2.055085758368174

Epoch: 6| Step: 12
Training loss: 1.653235673904419
Validation loss: 2.0402416388193765

Epoch: 6| Step: 13
Training loss: 2.372323513031006
Validation loss: 2.0461063583691916

Epoch: 20| Step: 0
Training loss: 1.012184500694275
Validation loss: 2.0526012579600015

Epoch: 6| Step: 1
Training loss: 2.320998191833496
Validation loss: 2.0537258187929788

Epoch: 6| Step: 2
Training loss: 2.208354949951172
Validation loss: 2.0456760923067727

Epoch: 6| Step: 3
Training loss: 1.764830231666565
Validation loss: 2.042656977971395

Epoch: 6| Step: 4
Training loss: 1.886082410812378
Validation loss: 2.051820397377014

Epoch: 6| Step: 5
Training loss: 2.043638229370117
Validation loss: 2.0301186243693032

Epoch: 6| Step: 6
Training loss: 2.05122971534729
Validation loss: 2.0445884267489114

Epoch: 6| Step: 7
Training loss: 2.7465267181396484
Validation loss: 2.044408897558848

Epoch: 6| Step: 8
Training loss: 1.8656089305877686
Validation loss: 2.053753435611725

Epoch: 6| Step: 9
Training loss: 1.9242697954177856
Validation loss: 2.0510968367258706

Epoch: 6| Step: 10
Training loss: 1.8573325872421265
Validation loss: 2.0388076106707254

Epoch: 6| Step: 11
Training loss: 1.8241047859191895
Validation loss: 2.049925923347473

Epoch: 6| Step: 12
Training loss: 2.305746555328369
Validation loss: 2.063354810078939

Epoch: 6| Step: 13
Training loss: 2.007500410079956
Validation loss: 2.043403228123983

Epoch: 21| Step: 0
Training loss: 1.3940184116363525
Validation loss: 2.051140566666921

Epoch: 6| Step: 1
Training loss: 2.1267755031585693
Validation loss: 2.02768083413442

Epoch: 6| Step: 2
Training loss: 2.798398494720459
Validation loss: 2.04772158463796

Epoch: 6| Step: 3
Training loss: 1.6074684858322144
Validation loss: 2.0366384784380593

Epoch: 6| Step: 4
Training loss: 2.227663993835449
Validation loss: 2.023689389228821

Epoch: 6| Step: 5
Training loss: 2.2049732208251953
Validation loss: 2.036818524201711

Epoch: 6| Step: 6
Training loss: 2.320380210876465
Validation loss: 2.0343756079673767

Epoch: 6| Step: 7
Training loss: 2.3352580070495605
Validation loss: 2.0366511940956116

Epoch: 6| Step: 8
Training loss: 2.1607418060302734
Validation loss: 2.0341650247573853

Epoch: 6| Step: 9
Training loss: 2.3037190437316895
Validation loss: 2.044460872809092

Epoch: 6| Step: 10
Training loss: 1.8904883861541748
Validation loss: 2.0344334840774536

Epoch: 6| Step: 11
Training loss: 1.3156239986419678
Validation loss: 2.046691040198008

Epoch: 6| Step: 12
Training loss: 1.6891165971755981
Validation loss: 2.0455059806505838

Epoch: 6| Step: 13
Training loss: 1.402341604232788
Validation loss: 2.043418606122335

Epoch: 22| Step: 0
Training loss: 1.9885386228561401
Validation loss: 2.0350347757339478

Epoch: 6| Step: 1
Training loss: 2.233353614807129
Validation loss: 2.0179431438446045

Epoch: 6| Step: 2
Training loss: 2.0338122844696045
Validation loss: 2.0412546396255493

Epoch: 6| Step: 3
Training loss: 1.710489273071289
Validation loss: 2.05228590965271

Epoch: 6| Step: 4
Training loss: 1.4029279947280884
Validation loss: 2.0500412384668985

Epoch: 6| Step: 5
Training loss: 1.9315568208694458
Validation loss: 2.048879623413086

Epoch: 6| Step: 6
Training loss: 2.620487689971924
Validation loss: 2.04960306485494

Epoch: 6| Step: 7
Training loss: 1.8881728649139404
Validation loss: 2.0309675137201944

Epoch: 6| Step: 8
Training loss: 1.8977611064910889
Validation loss: 2.053048253059387

Epoch: 6| Step: 9
Training loss: 1.2960679531097412
Validation loss: 2.054624835650126

Epoch: 6| Step: 10
Training loss: 2.516286849975586
Validation loss: 2.0491848389307656

Epoch: 6| Step: 11
Training loss: 2.644038677215576
Validation loss: 2.020542562007904

Epoch: 6| Step: 12
Training loss: 1.7672971487045288
Validation loss: 2.029172499974569

Epoch: 6| Step: 13
Training loss: 1.8621748685836792
Validation loss: 2.035547455151876

Epoch: 23| Step: 0
Training loss: 2.3699278831481934
Validation loss: 2.0232409238815308

Epoch: 6| Step: 1
Training loss: 2.2746729850769043
Validation loss: 2.0435798168182373

Epoch: 6| Step: 2
Training loss: 1.7838083505630493
Validation loss: 2.055660347143809

Epoch: 6| Step: 3
Training loss: 2.15177845954895
Validation loss: 2.0330489675203958

Epoch: 6| Step: 4
Training loss: 2.003713607788086
Validation loss: 2.04750927289327

Epoch: 6| Step: 5
Training loss: 1.364613652229309
Validation loss: 2.017502268155416

Epoch: 6| Step: 6
Training loss: 1.8754889965057373
Validation loss: 2.033083140850067

Epoch: 6| Step: 7
Training loss: 1.189401626586914
Validation loss: 2.029026369253794

Epoch: 6| Step: 8
Training loss: 2.7072970867156982
Validation loss: 2.06036510070165

Epoch: 6| Step: 9
Training loss: 2.123255968093872
Validation loss: 2.050999025503794

Epoch: 6| Step: 10
Training loss: 1.7493345737457275
Validation loss: 2.072730541229248

Epoch: 6| Step: 11
Training loss: 1.738393783569336
Validation loss: 2.065676967302958

Epoch: 6| Step: 12
Training loss: 2.758911371231079
Validation loss: 2.042861978212992

Epoch: 6| Step: 13
Training loss: 1.8655136823654175
Validation loss: 2.0502420465151467

Epoch: 24| Step: 0
Training loss: 1.4038008451461792
Validation loss: 2.039927124977112

Epoch: 6| Step: 1
Training loss: 2.6333062648773193
Validation loss: 2.0480343302090964

Epoch: 6| Step: 2
Training loss: 2.0535638332366943
Validation loss: 2.0313501358032227

Epoch: 6| Step: 3
Training loss: 2.4540491104125977
Validation loss: 2.0285659631093345

Epoch: 6| Step: 4
Training loss: 1.6497324705123901
Validation loss: 2.0515683690706887

Epoch: 6| Step: 5
Training loss: 2.305210590362549
Validation loss: 2.0538567105929055

Epoch: 6| Step: 6
Training loss: 2.446455955505371
Validation loss: 2.03275199731191

Epoch: 6| Step: 7
Training loss: 1.7011913061141968
Validation loss: 2.0173816879590354

Epoch: 6| Step: 8
Training loss: 2.289987087249756
Validation loss: 2.039041976133982

Epoch: 6| Step: 9
Training loss: 1.919166088104248
Validation loss: 2.0568012992540994

Epoch: 6| Step: 10
Training loss: 1.0618000030517578
Validation loss: 2.0461310545603433

Epoch: 6| Step: 11
Training loss: 1.8405390977859497
Validation loss: 2.03381739060084

Epoch: 6| Step: 12
Training loss: 1.6838120222091675
Validation loss: 2.035053869088491

Epoch: 6| Step: 13
Training loss: 2.3786778450012207
Validation loss: 2.032752434412638

Epoch: 25| Step: 0
Training loss: 2.187539577484131
Validation loss: 2.0346456368764243

Epoch: 6| Step: 1
Training loss: 1.954068899154663
Validation loss: 2.0285640160242715

Epoch: 6| Step: 2
Training loss: 2.3804969787597656
Validation loss: 2.0301036636034646

Epoch: 6| Step: 3
Training loss: 2.286287546157837
Validation loss: 2.0462822914123535

Epoch: 6| Step: 4
Training loss: 2.1345252990722656
Validation loss: 2.0390541156133017

Epoch: 6| Step: 5
Training loss: 2.069448471069336
Validation loss: 2.031528741121292

Epoch: 6| Step: 6
Training loss: 2.2474687099456787
Validation loss: 2.058961033821106

Epoch: 6| Step: 7
Training loss: 1.9172297716140747
Validation loss: 2.032056212425232

Epoch: 6| Step: 8
Training loss: 1.596409797668457
Validation loss: 2.0391461849212646

Epoch: 6| Step: 9
Training loss: 1.9079102277755737
Validation loss: 2.05147914091746

Epoch: 6| Step: 10
Training loss: 2.0305373668670654
Validation loss: 2.060649653275808

Epoch: 6| Step: 11
Training loss: 2.3325703144073486
Validation loss: 2.0496225158373513

Epoch: 6| Step: 12
Training loss: 1.138506531715393
Validation loss: 2.0742149353027344

Epoch: 6| Step: 13
Training loss: 1.1915004253387451
Validation loss: 2.0486469070116677

Epoch: 26| Step: 0
Training loss: 2.266218662261963
Validation loss: 2.0427613655726113

Epoch: 6| Step: 1
Training loss: 2.384800434112549
Validation loss: 2.0211138923962912

Epoch: 6| Step: 2
Training loss: 2.6350936889648438
Validation loss: 2.0088625947634378

Epoch: 6| Step: 3
Training loss: 2.0952160358428955
Validation loss: 2.0393312772115073

Epoch: 6| Step: 4
Training loss: 1.8062351942062378
Validation loss: 2.0263662139574685

Epoch: 6| Step: 5
Training loss: 1.3864291906356812
Validation loss: 2.0400906999905906

Epoch: 6| Step: 6
Training loss: 1.6424739360809326
Validation loss: 2.030839463075002

Epoch: 6| Step: 7
Training loss: 1.495120882987976
Validation loss: 2.03404966990153

Epoch: 6| Step: 8
Training loss: 2.1349480152130127
Validation loss: 2.0250216126441956

Epoch: 6| Step: 9
Training loss: 1.6487557888031006
Validation loss: 2.020891487598419

Epoch: 6| Step: 10
Training loss: 2.0568206310272217
Validation loss: 2.028713901837667

Epoch: 6| Step: 11
Training loss: 2.2627854347229004
Validation loss: 2.0064059694608054

Epoch: 6| Step: 12
Training loss: 1.912033200263977
Validation loss: 2.0455187559127808

Epoch: 6| Step: 13
Training loss: 1.649498701095581
Validation loss: 2.020534118016561

Epoch: 27| Step: 0
Training loss: 1.7423291206359863
Validation loss: 2.016130725542704

Epoch: 6| Step: 1
Training loss: 1.3941030502319336
Validation loss: 2.019083778063456

Epoch: 6| Step: 2
Training loss: 1.9248507022857666
Validation loss: 2.038242518901825

Epoch: 6| Step: 3
Training loss: 1.9805618524551392
Validation loss: 2.026381492614746

Epoch: 6| Step: 4
Training loss: 2.133822202682495
Validation loss: 2.044121265411377

Epoch: 6| Step: 5
Training loss: 2.3611128330230713
Validation loss: 2.031803250312805

Epoch: 6| Step: 6
Training loss: 2.5803310871124268
Validation loss: 2.028015375137329

Epoch: 6| Step: 7
Training loss: 1.6037312746047974
Validation loss: 2.04036283493042

Epoch: 6| Step: 8
Training loss: 2.503612756729126
Validation loss: 2.049929916858673

Epoch: 6| Step: 9
Training loss: 1.5130972862243652
Validation loss: 2.0311810771624246

Epoch: 6| Step: 10
Training loss: 1.910868763923645
Validation loss: 2.041400671005249

Epoch: 6| Step: 11
Training loss: 2.1440629959106445
Validation loss: 2.0295403599739075

Epoch: 6| Step: 12
Training loss: 1.9533662796020508
Validation loss: 2.0168955524762473

Epoch: 6| Step: 13
Training loss: 1.7092465162277222
Validation loss: 2.0323091546694436

Epoch: 28| Step: 0
Training loss: 2.550625801086426
Validation loss: 2.0412506461143494

Epoch: 6| Step: 1
Training loss: 1.6942498683929443
Validation loss: 2.04056453704834

Epoch: 6| Step: 2
Training loss: 1.8549871444702148
Validation loss: 2.0354592204093933

Epoch: 6| Step: 3
Training loss: 1.827648401260376
Validation loss: 2.0320854584376016

Epoch: 6| Step: 4
Training loss: 2.1256332397460938
Validation loss: 2.0431833465894065

Epoch: 6| Step: 5
Training loss: 1.8775008916854858
Validation loss: 2.0464912056922913

Epoch: 6| Step: 6
Training loss: 2.1204867362976074
Validation loss: 2.0217717488606772

Epoch: 6| Step: 7
Training loss: 2.279238700866699
Validation loss: 2.0324114561080933

Epoch: 6| Step: 8
Training loss: 1.78117036819458
Validation loss: 2.0376394788424173

Epoch: 6| Step: 9
Training loss: 2.730419158935547
Validation loss: 2.0616618394851685

Epoch: 6| Step: 10
Training loss: 1.4215433597564697
Validation loss: 2.0428451895713806

Epoch: 6| Step: 11
Training loss: 1.5357677936553955
Validation loss: 2.0388719042142234

Epoch: 6| Step: 12
Training loss: 1.5149126052856445
Validation loss: 2.0259010394414267

Epoch: 6| Step: 13
Training loss: 2.392805814743042
Validation loss: 2.041151543458303

Epoch: 29| Step: 0
Training loss: 2.338804244995117
Validation loss: 2.0267964005470276

Epoch: 6| Step: 1
Training loss: 1.5045952796936035
Validation loss: 2.030493219693502

Epoch: 6| Step: 2
Training loss: 1.9610763788223267
Validation loss: 2.0282682379086814

Epoch: 6| Step: 3
Training loss: 2.216369152069092
Validation loss: 2.0540124773979187

Epoch: 6| Step: 4
Training loss: 2.1453633308410645
Validation loss: 2.0812437534332275

Epoch: 6| Step: 5
Training loss: 2.7399559020996094
Validation loss: 2.0861993630727134

Epoch: 6| Step: 6
Training loss: 1.7026456594467163
Validation loss: 2.0948319832483926

Epoch: 6| Step: 7
Training loss: 2.4250545501708984
Validation loss: 2.0930762887001038

Epoch: 6| Step: 8
Training loss: 2.063406229019165
Validation loss: 2.065378785133362

Epoch: 6| Step: 9
Training loss: 2.665175437927246
Validation loss: 2.0626579920450845

Epoch: 6| Step: 10
Training loss: 1.7181577682495117
Validation loss: 2.0385104020436606

Epoch: 6| Step: 11
Training loss: 1.4686156511306763
Validation loss: 2.0302263696988425

Epoch: 6| Step: 12
Training loss: 1.3531537055969238
Validation loss: 2.0366798837979636

Epoch: 6| Step: 13
Training loss: 1.6512949466705322
Validation loss: 2.023035744825999

Epoch: 30| Step: 0
Training loss: 1.4517395496368408
Validation loss: 2.025710145632426

Epoch: 6| Step: 1
Training loss: 2.022794723510742
Validation loss: 2.0182565649350486

Epoch: 6| Step: 2
Training loss: 1.7957277297973633
Validation loss: 2.025874118010203

Epoch: 6| Step: 3
Training loss: 1.5629611015319824
Validation loss: 2.0165916085243225

Epoch: 6| Step: 4
Training loss: 1.8258047103881836
Validation loss: 2.0297715862592063

Epoch: 6| Step: 5
Training loss: 2.8301243782043457
Validation loss: 2.022067983945211

Epoch: 6| Step: 6
Training loss: 2.1113412380218506
Validation loss: 2.026389936606089

Epoch: 6| Step: 7
Training loss: 1.9829843044281006
Validation loss: 2.01218310991923

Epoch: 6| Step: 8
Training loss: 1.7097688913345337
Validation loss: 2.011930505434672

Epoch: 6| Step: 9
Training loss: 1.846116065979004
Validation loss: 2.034567872683207

Epoch: 6| Step: 10
Training loss: 1.5099791288375854
Validation loss: 2.0154536167780557

Epoch: 6| Step: 11
Training loss: 2.310763359069824
Validation loss: 2.0293497244517007

Epoch: 6| Step: 12
Training loss: 2.481513023376465
Validation loss: 2.0269543727238974

Epoch: 6| Step: 13
Training loss: 2.138076066970825
Validation loss: 2.039098044236501

Epoch: 31| Step: 0
Training loss: 2.3223915100097656
Validation loss: 2.0354087551434836

Epoch: 6| Step: 1
Training loss: 2.485724449157715
Validation loss: 2.0423542261123657

Epoch: 6| Step: 2
Training loss: 1.7580323219299316
Validation loss: 2.0589523116747537

Epoch: 6| Step: 3
Training loss: 1.341389536857605
Validation loss: 2.0426830848058066

Epoch: 6| Step: 4
Training loss: 1.3728532791137695
Validation loss: 2.020924687385559

Epoch: 6| Step: 5
Training loss: 1.7927296161651611
Validation loss: 2.02234955628713

Epoch: 6| Step: 6
Training loss: 2.151841402053833
Validation loss: 2.050675650437673

Epoch: 6| Step: 7
Training loss: 2.226560354232788
Validation loss: 2.0417760213216147

Epoch: 6| Step: 8
Training loss: 1.7038547992706299
Validation loss: 2.0446824431419373

Epoch: 6| Step: 9
Training loss: 2.0125603675842285
Validation loss: 2.0473039547602334

Epoch: 6| Step: 10
Training loss: 1.1467639207839966
Validation loss: 2.0218231479326882

Epoch: 6| Step: 11
Training loss: 1.9091205596923828
Validation loss: 2.029745360215505

Epoch: 6| Step: 12
Training loss: 1.8521363735198975
Validation loss: 2.0380444526672363

Epoch: 6| Step: 13
Training loss: 3.0530893802642822
Validation loss: 2.0689865748087564

Epoch: 32| Step: 0
Training loss: 2.2195487022399902
Validation loss: 2.0422622760136924

Epoch: 6| Step: 1
Training loss: 1.7136461734771729
Validation loss: 2.0490954518318176

Epoch: 6| Step: 2
Training loss: 1.5585979223251343
Validation loss: 2.0732073982556662

Epoch: 6| Step: 3
Training loss: 2.0308356285095215
Validation loss: 2.0412784616152444

Epoch: 6| Step: 4
Training loss: 2.3958921432495117
Validation loss: 2.0322869618733725

Epoch: 6| Step: 5
Training loss: 1.7355084419250488
Validation loss: 2.049996078014374

Epoch: 6| Step: 6
Training loss: 1.7670708894729614
Validation loss: 2.051350017388662

Epoch: 6| Step: 7
Training loss: 2.0848121643066406
Validation loss: 2.033018251260122

Epoch: 6| Step: 8
Training loss: 1.594977855682373
Validation loss: 2.073672612508138

Epoch: 6| Step: 9
Training loss: 2.1416854858398438
Validation loss: 2.0496572256088257

Epoch: 6| Step: 10
Training loss: 1.7080332040786743
Validation loss: 2.063989043235779

Epoch: 6| Step: 11
Training loss: 2.156198501586914
Validation loss: 2.0410232146581015

Epoch: 6| Step: 12
Training loss: 2.06821346282959
Validation loss: 2.0287847320238748

Epoch: 6| Step: 13
Training loss: 1.9381763935089111
Validation loss: 2.023553649584452

Epoch: 33| Step: 0
Training loss: 2.0027055740356445
Validation loss: 2.0154647628466287

Epoch: 6| Step: 1
Training loss: 1.4668779373168945
Validation loss: 2.0251261790593467

Epoch: 6| Step: 2
Training loss: 2.2085373401641846
Validation loss: 2.010350485642751

Epoch: 6| Step: 3
Training loss: 1.8330714702606201
Validation loss: 2.0128427545229592

Epoch: 6| Step: 4
Training loss: 2.1253857612609863
Validation loss: 2.0322853128115335

Epoch: 6| Step: 5
Training loss: 1.8962457180023193
Validation loss: 2.001997232437134

Epoch: 6| Step: 6
Training loss: 2.0039682388305664
Validation loss: 2.0273523330688477

Epoch: 6| Step: 7
Training loss: 1.6987273693084717
Validation loss: 2.0342223842938743

Epoch: 6| Step: 8
Training loss: 2.0464532375335693
Validation loss: 2.0291718443234763

Epoch: 6| Step: 9
Training loss: 1.484018325805664
Validation loss: 2.015267848968506

Epoch: 6| Step: 10
Training loss: 1.9799188375473022
Validation loss: 2.0053600072860718

Epoch: 6| Step: 11
Training loss: 2.5454201698303223
Validation loss: 2.020926078160604

Epoch: 6| Step: 12
Training loss: 2.0671932697296143
Validation loss: 2.009197950363159

Epoch: 6| Step: 13
Training loss: 2.1720635890960693
Validation loss: 2.0236621101697287

Epoch: 34| Step: 0
Training loss: 2.462270975112915
Validation loss: 2.016348640124003

Epoch: 6| Step: 1
Training loss: 1.4737886190414429
Validation loss: 2.018356362978617

Epoch: 6| Step: 2
Training loss: 1.882240891456604
Validation loss: 2.028290867805481

Epoch: 6| Step: 3
Training loss: 2.1853890419006348
Validation loss: 2.0220077435175576

Epoch: 6| Step: 4
Training loss: 1.5777218341827393
Validation loss: 2.0447339614232383

Epoch: 6| Step: 5
Training loss: 2.3239810466766357
Validation loss: 2.056846559047699

Epoch: 6| Step: 6
Training loss: 1.96852707862854
Validation loss: 2.0530243515968323

Epoch: 6| Step: 7
Training loss: 1.6169350147247314
Validation loss: 2.067079186439514

Epoch: 6| Step: 8
Training loss: 1.8446044921875
Validation loss: 2.0759543776512146

Epoch: 6| Step: 9
Training loss: 2.3043627738952637
Validation loss: 2.091728409131368

Epoch: 6| Step: 10
Training loss: 1.7805521488189697
Validation loss: 2.067845265070597

Epoch: 6| Step: 11
Training loss: 2.3940160274505615
Validation loss: 2.065630634625753

Epoch: 6| Step: 12
Training loss: 1.8593790531158447
Validation loss: 2.075200398763021

Epoch: 6| Step: 13
Training loss: 1.6093096733093262
Validation loss: 2.039351165294647

Epoch: 35| Step: 0
Training loss: 1.8511996269226074
Validation loss: 2.030366579691569

Epoch: 6| Step: 1
Training loss: 1.604519009590149
Validation loss: 2.023909052213033

Epoch: 6| Step: 2
Training loss: 1.848836064338684
Validation loss: 2.009781281153361

Epoch: 6| Step: 3
Training loss: 2.008889675140381
Validation loss: 2.0343476931254068

Epoch: 6| Step: 4
Training loss: 1.8792563676834106
Validation loss: 1.9994610945383708

Epoch: 6| Step: 5
Training loss: 1.5033340454101562
Validation loss: 2.026486357053121

Epoch: 6| Step: 6
Training loss: 2.1157925128936768
Validation loss: 2.0370262463887534

Epoch: 6| Step: 7
Training loss: 1.9147521257400513
Validation loss: 1.9895972609519958

Epoch: 6| Step: 8
Training loss: 2.3309555053710938
Validation loss: 2.017092148462931

Epoch: 6| Step: 9
Training loss: 1.7674747705459595
Validation loss: 2.050384740034739

Epoch: 6| Step: 10
Training loss: 1.4101245403289795
Validation loss: 2.0088569124539695

Epoch: 6| Step: 11
Training loss: 2.2134857177734375
Validation loss: 2.0044753551483154

Epoch: 6| Step: 12
Training loss: 2.0001742839813232
Validation loss: 2.033723751703898

Epoch: 6| Step: 13
Training loss: 2.840872287750244
Validation loss: 2.031818151473999

Epoch: 36| Step: 0
Training loss: 1.54105544090271
Validation loss: 2.021147827307383

Epoch: 6| Step: 1
Training loss: 2.0385797023773193
Validation loss: 2.0252522230148315

Epoch: 6| Step: 2
Training loss: 1.568446159362793
Validation loss: 2.0517181555430093

Epoch: 6| Step: 3
Training loss: 1.8717083930969238
Validation loss: 2.0602277914683023

Epoch: 6| Step: 4
Training loss: 1.0364247560501099
Validation loss: 2.0857585668563843

Epoch: 6| Step: 5
Training loss: 1.4947545528411865
Validation loss: 2.0626068909962973

Epoch: 6| Step: 6
Training loss: 2.291626453399658
Validation loss: 2.0705717404683432

Epoch: 6| Step: 7
Training loss: 2.2386484146118164
Validation loss: 2.062942683696747

Epoch: 6| Step: 8
Training loss: 2.214120864868164
Validation loss: 2.0700100660324097

Epoch: 6| Step: 9
Training loss: 1.6589316129684448
Validation loss: 2.050750811894735

Epoch: 6| Step: 10
Training loss: 1.9791584014892578
Validation loss: 2.0443455378214517

Epoch: 6| Step: 11
Training loss: 2.333712100982666
Validation loss: 2.0430922309557595

Epoch: 6| Step: 12
Training loss: 2.084667205810547
Validation loss: 2.043473263581594

Epoch: 6| Step: 13
Training loss: 2.6567482948303223
Validation loss: 2.033818562825521

Epoch: 37| Step: 0
Training loss: 1.5256104469299316
Validation loss: 2.0187186201413474

Epoch: 6| Step: 1
Training loss: 1.7102587223052979
Validation loss: 2.018332024415334

Epoch: 6| Step: 2
Training loss: 2.2316243648529053
Validation loss: 2.0365962584813437

Epoch: 6| Step: 3
Training loss: 2.0395116806030273
Validation loss: 1.9962849815686543

Epoch: 6| Step: 4
Training loss: 1.9857676029205322
Validation loss: 2.010838429133097

Epoch: 6| Step: 5
Training loss: 2.4328725337982178
Validation loss: 2.0356416503588357

Epoch: 6| Step: 6
Training loss: 1.5883069038391113
Validation loss: 2.0043659607569375

Epoch: 6| Step: 7
Training loss: 1.79541015625
Validation loss: 2.0148590803146362

Epoch: 6| Step: 8
Training loss: 2.410540819168091
Validation loss: 2.0090889732042947

Epoch: 6| Step: 9
Training loss: 1.903444766998291
Validation loss: 2.0164142648379006

Epoch: 6| Step: 10
Training loss: 1.7974516153335571
Validation loss: 1.995338996251424

Epoch: 6| Step: 11
Training loss: 2.158665180206299
Validation loss: 2.009878396987915

Epoch: 6| Step: 12
Training loss: 2.002091884613037
Validation loss: 2.0219296415646872

Epoch: 6| Step: 13
Training loss: 1.6028227806091309
Validation loss: 1.998043378194173

Epoch: 38| Step: 0
Training loss: 1.4624935388565063
Validation loss: 2.034956395626068

Epoch: 6| Step: 1
Training loss: 2.2940011024475098
Validation loss: 2.02662726243337

Epoch: 6| Step: 2
Training loss: 1.967970371246338
Validation loss: 2.0324224630991616

Epoch: 6| Step: 3
Training loss: 2.0210020542144775
Validation loss: 2.034573018550873

Epoch: 6| Step: 4
Training loss: 1.8037428855895996
Validation loss: 2.034349203109741

Epoch: 6| Step: 5
Training loss: 2.4160025119781494
Validation loss: 2.033425788084666

Epoch: 6| Step: 6
Training loss: 1.990180492401123
Validation loss: 2.0341744422912598

Epoch: 6| Step: 7
Training loss: 1.2891185283660889
Validation loss: 2.02707709868749

Epoch: 6| Step: 8
Training loss: 1.618100881576538
Validation loss: 2.027531643708547

Epoch: 6| Step: 9
Training loss: 1.984802007675171
Validation loss: 2.0039936304092407

Epoch: 6| Step: 10
Training loss: 2.316812515258789
Validation loss: 2.002086083094279

Epoch: 6| Step: 11
Training loss: 1.6449041366577148
Validation loss: 2.001904765764872

Epoch: 6| Step: 12
Training loss: 2.3525285720825195
Validation loss: 2.003925919532776

Epoch: 6| Step: 13
Training loss: 2.0336735248565674
Validation loss: 2.0327771504720054

Epoch: 39| Step: 0
Training loss: 1.3921356201171875
Validation loss: 2.0352567235628762

Epoch: 6| Step: 1
Training loss: 2.5395381450653076
Validation loss: 2.0615782539049783

Epoch: 6| Step: 2
Training loss: 1.6701991558074951
Validation loss: 2.049566169579824

Epoch: 6| Step: 3
Training loss: 1.4078037738800049
Validation loss: 2.022496819496155

Epoch: 6| Step: 4
Training loss: 2.2347302436828613
Validation loss: 2.019220550855001

Epoch: 6| Step: 5
Training loss: 1.85371994972229
Validation loss: 2.0358232657114663

Epoch: 6| Step: 6
Training loss: 1.1775078773498535
Validation loss: 2.0174079736073813

Epoch: 6| Step: 7
Training loss: 1.766808032989502
Validation loss: 2.023051162560781

Epoch: 6| Step: 8
Training loss: 2.081089496612549
Validation loss: 2.0183473428090415

Epoch: 6| Step: 9
Training loss: 1.690701961517334
Validation loss: 2.0386985143025718

Epoch: 6| Step: 10
Training loss: 2.6418092250823975
Validation loss: 2.0400884548823037

Epoch: 6| Step: 11
Training loss: 2.0272862911224365
Validation loss: 2.063543160756429

Epoch: 6| Step: 12
Training loss: 2.202817440032959
Validation loss: 2.0302725235621133

Epoch: 6| Step: 13
Training loss: 2.2188313007354736
Validation loss: 2.0438021222750344

Epoch: 40| Step: 0
Training loss: 2.211578369140625
Validation loss: 2.0210429032643638

Epoch: 6| Step: 1
Training loss: 2.217958927154541
Validation loss: 2.045073846975962

Epoch: 6| Step: 2
Training loss: 2.1799979209899902
Validation loss: 2.0422214468320212

Epoch: 6| Step: 3
Training loss: 1.49839186668396
Validation loss: 2.061357617378235

Epoch: 6| Step: 4
Training loss: 1.4262604713439941
Validation loss: 2.0803568959236145

Epoch: 6| Step: 5
Training loss: 2.561056613922119
Validation loss: 2.0701574087142944

Epoch: 6| Step: 6
Training loss: 1.9032399654388428
Validation loss: 2.077262838681539

Epoch: 6| Step: 7
Training loss: 2.669938087463379
Validation loss: 2.0496641198794046

Epoch: 6| Step: 8
Training loss: 1.515470266342163
Validation loss: 2.0615047216415405

Epoch: 6| Step: 9
Training loss: 1.652848482131958
Validation loss: 2.042510767777761

Epoch: 6| Step: 10
Training loss: 1.8541147708892822
Validation loss: 2.0217275619506836

Epoch: 6| Step: 11
Training loss: 2.1965904235839844
Validation loss: 2.016978919506073

Epoch: 6| Step: 12
Training loss: 1.9643075466156006
Validation loss: 2.0222155849138894

Epoch: 6| Step: 13
Training loss: 1.4087564945220947
Validation loss: 2.0141401886940002

Epoch: 41| Step: 0
Training loss: 2.1227214336395264
Validation loss: 2.0400534868240356

Epoch: 6| Step: 1
Training loss: 1.884519100189209
Validation loss: 2.0143065055211387

Epoch: 6| Step: 2
Training loss: 1.3036456108093262
Validation loss: 2.0296932260195413

Epoch: 6| Step: 3
Training loss: 1.963258981704712
Validation loss: 2.01594485839208

Epoch: 6| Step: 4
Training loss: 1.4172639846801758
Validation loss: 2.0030829310417175

Epoch: 6| Step: 5
Training loss: 2.209303855895996
Validation loss: 2.0010476311047873

Epoch: 6| Step: 6
Training loss: 1.4524067640304565
Validation loss: 2.001838187376658

Epoch: 6| Step: 7
Training loss: 2.1874823570251465
Validation loss: 2.010162870089213

Epoch: 6| Step: 8
Training loss: 1.9686741828918457
Validation loss: 2.014390786488851

Epoch: 6| Step: 9
Training loss: 2.800445079803467
Validation loss: 2.018670082092285

Epoch: 6| Step: 10
Training loss: 1.647470474243164
Validation loss: 2.0063787698745728

Epoch: 6| Step: 11
Training loss: 1.1923880577087402
Validation loss: 2.042901595433553

Epoch: 6| Step: 12
Training loss: 2.5121841430664062
Validation loss: 2.052463630835215

Epoch: 6| Step: 13
Training loss: 2.020963191986084
Validation loss: 2.042145033677419

Epoch: 42| Step: 0
Training loss: 1.851771593093872
Validation loss: 2.0344520012537637

Epoch: 6| Step: 1
Training loss: 1.4827998876571655
Validation loss: 2.06876673301061

Epoch: 6| Step: 2
Training loss: 1.7308954000473022
Validation loss: 2.0554969708124795

Epoch: 6| Step: 3
Training loss: 1.65796959400177
Validation loss: 2.0673203269640603

Epoch: 6| Step: 4
Training loss: 1.8806054592132568
Validation loss: 2.0916635592778525

Epoch: 6| Step: 5
Training loss: 1.9758058786392212
Validation loss: 2.062659521897634

Epoch: 6| Step: 6
Training loss: 2.2707555294036865
Validation loss: 2.085728426774343

Epoch: 6| Step: 7
Training loss: 1.2417893409729004
Validation loss: 2.041317125161489

Epoch: 6| Step: 8
Training loss: 2.2650160789489746
Validation loss: 2.028916835784912

Epoch: 6| Step: 9
Training loss: 2.0726850032806396
Validation loss: 2.033023993174235

Epoch: 6| Step: 10
Training loss: 1.777137041091919
Validation loss: 2.009552796681722

Epoch: 6| Step: 11
Training loss: 2.4060819149017334
Validation loss: 2.0312275886535645

Epoch: 6| Step: 12
Training loss: 2.2807235717773438
Validation loss: 2.0163898865381875

Epoch: 6| Step: 13
Training loss: 2.214513063430786
Validation loss: 2.016058623790741

Epoch: 43| Step: 0
Training loss: 1.628164291381836
Validation loss: 1.9916502038637798

Epoch: 6| Step: 1
Training loss: 1.9794875383377075
Validation loss: 2.023345947265625

Epoch: 6| Step: 2
Training loss: 1.8529027700424194
Validation loss: 2.041568696498871

Epoch: 6| Step: 3
Training loss: 1.5350327491760254
Validation loss: 2.0497265060742698

Epoch: 6| Step: 4
Training loss: 2.3200013637542725
Validation loss: 2.045245806376139

Epoch: 6| Step: 5
Training loss: 1.9899961948394775
Validation loss: 2.019907752672831

Epoch: 6| Step: 6
Training loss: 2.2976694107055664
Validation loss: 2.0249884923299155

Epoch: 6| Step: 7
Training loss: 2.404357433319092
Validation loss: 2.058325628439585

Epoch: 6| Step: 8
Training loss: 1.4104160070419312
Validation loss: 2.050539970397949

Epoch: 6| Step: 9
Training loss: 1.8005088567733765
Validation loss: 2.075318197409312

Epoch: 6| Step: 10
Training loss: 1.6678147315979004
Validation loss: 2.0454490780830383

Epoch: 6| Step: 11
Training loss: 1.6974154710769653
Validation loss: 2.067187706629435

Epoch: 6| Step: 12
Training loss: 1.75641667842865
Validation loss: 2.04233851035436

Epoch: 6| Step: 13
Training loss: 2.651948928833008
Validation loss: 2.0335118571917215

Epoch: 44| Step: 0
Training loss: 1.2712595462799072
Validation loss: 2.013243099053701

Epoch: 6| Step: 1
Training loss: 1.8794803619384766
Validation loss: 2.0312787294387817

Epoch: 6| Step: 2
Training loss: 2.029726982116699
Validation loss: 2.0384575923283896

Epoch: 6| Step: 3
Training loss: 1.5793558359146118
Validation loss: 2.0193792581558228

Epoch: 6| Step: 4
Training loss: 1.8733954429626465
Validation loss: 2.0254449446996055

Epoch: 6| Step: 5
Training loss: 2.1982102394104004
Validation loss: 2.0153403679529824

Epoch: 6| Step: 6
Training loss: 2.6493709087371826
Validation loss: 2.012930770715078

Epoch: 6| Step: 7
Training loss: 1.8076540231704712
Validation loss: 2.0333173274993896

Epoch: 6| Step: 8
Training loss: 2.0499136447906494
Validation loss: 2.0166776378949485

Epoch: 6| Step: 9
Training loss: 2.002018928527832
Validation loss: 1.9979657729466755

Epoch: 6| Step: 10
Training loss: 1.7358582019805908
Validation loss: 2.029375751813253

Epoch: 6| Step: 11
Training loss: 2.0672802925109863
Validation loss: 2.0231435100237527

Epoch: 6| Step: 12
Training loss: 1.8782596588134766
Validation loss: 2.033414343992869

Epoch: 6| Step: 13
Training loss: 1.8421971797943115
Validation loss: 2.0161824226379395

Epoch: 45| Step: 0
Training loss: 1.8267685174942017
Validation loss: 1.9920273820559184

Epoch: 6| Step: 1
Training loss: 2.2763543128967285
Validation loss: 2.0394516785939536

Epoch: 6| Step: 2
Training loss: 2.047637939453125
Validation loss: 2.026941736539205

Epoch: 6| Step: 3
Training loss: 2.273014545440674
Validation loss: 2.0164050261179605

Epoch: 6| Step: 4
Training loss: 1.791471004486084
Validation loss: 2.0444679856300354

Epoch: 6| Step: 5
Training loss: 2.132110118865967
Validation loss: 2.032853901386261

Epoch: 6| Step: 6
Training loss: 1.8884360790252686
Validation loss: 2.0487271547317505

Epoch: 6| Step: 7
Training loss: 1.9090299606323242
Validation loss: 2.0400333205858865

Epoch: 6| Step: 8
Training loss: 1.9510217905044556
Validation loss: 2.0303817788759866

Epoch: 6| Step: 9
Training loss: 1.7555748224258423
Validation loss: 2.0309181014696756

Epoch: 6| Step: 10
Training loss: 1.7935725450515747
Validation loss: 2.073265492916107

Epoch: 6| Step: 11
Training loss: 1.9374982118606567
Validation loss: 2.056107779343923

Epoch: 6| Step: 12
Training loss: 2.0279085636138916
Validation loss: 2.0479257702827454

Epoch: 6| Step: 13
Training loss: 1.2526296377182007
Validation loss: 2.032568792502085

Epoch: 46| Step: 0
Training loss: 1.7310380935668945
Validation loss: 2.0368089278539023

Epoch: 6| Step: 1
Training loss: 1.7019877433776855
Validation loss: 2.040372093518575

Epoch: 6| Step: 2
Training loss: 2.356419324874878
Validation loss: 2.0549967288970947

Epoch: 6| Step: 3
Training loss: 1.2549800872802734
Validation loss: 2.0238311290740967

Epoch: 6| Step: 4
Training loss: 2.379969835281372
Validation loss: 2.0325875083605447

Epoch: 6| Step: 5
Training loss: 1.4478986263275146
Validation loss: 2.052441895008087

Epoch: 6| Step: 6
Training loss: 2.268400192260742
Validation loss: 2.0460633635520935

Epoch: 6| Step: 7
Training loss: 1.4406864643096924
Validation loss: 2.032564123471578

Epoch: 6| Step: 8
Training loss: 3.3292391300201416
Validation loss: 2.0273732344309487

Epoch: 6| Step: 9
Training loss: 0.9766350984573364
Validation loss: 2.006923715273539

Epoch: 6| Step: 10
Training loss: 2.137845993041992
Validation loss: 2.0264586011568704

Epoch: 6| Step: 11
Training loss: 2.0111398696899414
Validation loss: 2.016615867614746

Epoch: 6| Step: 12
Training loss: 1.7784059047698975
Validation loss: 2.030479888121287

Epoch: 6| Step: 13
Training loss: 2.104226589202881
Validation loss: 1.9698412815729778

Epoch: 47| Step: 0
Training loss: 1.8073530197143555
Validation loss: 2.019983232021332

Epoch: 6| Step: 1
Training loss: 2.2901997566223145
Validation loss: 2.0147266586621604

Epoch: 6| Step: 2
Training loss: 1.8576860427856445
Validation loss: 1.9882221817970276

Epoch: 6| Step: 3
Training loss: 1.8998665809631348
Validation loss: 2.009875218073527

Epoch: 6| Step: 4
Training loss: 2.167604446411133
Validation loss: 2.0273557305336

Epoch: 6| Step: 5
Training loss: 1.258801817893982
Validation loss: 2.0222618778546653

Epoch: 6| Step: 6
Training loss: 2.2631404399871826
Validation loss: 2.0216596325238547

Epoch: 6| Step: 7
Training loss: 1.706008791923523
Validation loss: 2.0353622833887735

Epoch: 6| Step: 8
Training loss: 1.4725980758666992
Validation loss: 2.0044230222702026

Epoch: 6| Step: 9
Training loss: 2.4701895713806152
Validation loss: 2.0314230720202127

Epoch: 6| Step: 10
Training loss: 1.7036457061767578
Validation loss: 2.0357864101727805

Epoch: 6| Step: 11
Training loss: 1.8267149925231934
Validation loss: 2.0286303758621216

Epoch: 6| Step: 12
Training loss: 1.9039720296859741
Validation loss: 2.0306075612703958

Epoch: 6| Step: 13
Training loss: 2.1962337493896484
Validation loss: 2.0596835215886435

Epoch: 48| Step: 0
Training loss: 1.469963788986206
Validation loss: 2.057043890158335

Epoch: 6| Step: 1
Training loss: 2.347299575805664
Validation loss: 2.0581050713857016

Epoch: 6| Step: 2
Training loss: 2.2186203002929688
Validation loss: 2.033669412136078

Epoch: 6| Step: 3
Training loss: 1.862865686416626
Validation loss: 2.0370373129844666

Epoch: 6| Step: 4
Training loss: 2.7844529151916504
Validation loss: 2.0575937628746033

Epoch: 6| Step: 5
Training loss: 1.7370483875274658
Validation loss: 2.0082037250200906

Epoch: 6| Step: 6
Training loss: 1.9988051652908325
Validation loss: 2.02637787659963

Epoch: 6| Step: 7
Training loss: 2.002075672149658
Validation loss: 2.0388028422991433

Epoch: 6| Step: 8
Training loss: 1.4087401628494263
Validation loss: 2.021555403868357

Epoch: 6| Step: 9
Training loss: 2.18537974357605
Validation loss: 2.017300566037496

Epoch: 6| Step: 10
Training loss: 1.8128756284713745
Validation loss: 2.0173529187838235

Epoch: 6| Step: 11
Training loss: 1.8063123226165771
Validation loss: 2.007258733113607

Epoch: 6| Step: 12
Training loss: 1.6786878108978271
Validation loss: 2.022060294946035

Epoch: 6| Step: 13
Training loss: 1.3752548694610596
Validation loss: 2.0020853877067566

Epoch: 49| Step: 0
Training loss: 1.3401159048080444
Validation loss: 2.0031432708104453

Epoch: 6| Step: 1
Training loss: 1.8468331098556519
Validation loss: 2.008570114771525

Epoch: 6| Step: 2
Training loss: 2.1981794834136963
Validation loss: 2.031719982624054

Epoch: 6| Step: 3
Training loss: 1.518049955368042
Validation loss: 2.0264026721318564

Epoch: 6| Step: 4
Training loss: 1.8879826068878174
Validation loss: 2.0141815344492593

Epoch: 6| Step: 5
Training loss: 2.1007800102233887
Validation loss: 2.0318474968274436

Epoch: 6| Step: 6
Training loss: 2.4940991401672363
Validation loss: 2.052956521511078

Epoch: 6| Step: 7
Training loss: 1.3826425075531006
Validation loss: 2.0326427817344666

Epoch: 6| Step: 8
Training loss: 2.334564685821533
Validation loss: 2.05759725968043

Epoch: 6| Step: 9
Training loss: 1.6207057237625122
Validation loss: 2.035157064596812

Epoch: 6| Step: 10
Training loss: 1.9270646572113037
Validation loss: 2.029321034749349

Epoch: 6| Step: 11
Training loss: 2.0525665283203125
Validation loss: 2.046111583709717

Epoch: 6| Step: 12
Training loss: 1.4257909059524536
Validation loss: 2.033818085988363

Epoch: 6| Step: 13
Training loss: 2.4316186904907227
Validation loss: 2.026837925116221

Epoch: 50| Step: 0
Training loss: 1.8812479972839355
Validation loss: 2.0233731865882874

Epoch: 6| Step: 1
Training loss: 2.1854166984558105
Validation loss: 2.0198505322138467

Epoch: 6| Step: 2
Training loss: 2.3510003089904785
Validation loss: 2.0178924798965454

Epoch: 6| Step: 3
Training loss: 1.9610072374343872
Validation loss: 1.9954712390899658

Epoch: 6| Step: 4
Training loss: 1.578904151916504
Validation loss: 1.9907280604044597

Epoch: 6| Step: 5
Training loss: 1.2282981872558594
Validation loss: 2.0263850490252175

Epoch: 6| Step: 6
Training loss: 2.128176689147949
Validation loss: 2.022968331972758

Epoch: 6| Step: 7
Training loss: 2.2406134605407715
Validation loss: 2.0217732191085815

Epoch: 6| Step: 8
Training loss: 2.204285144805908
Validation loss: 2.0446762442588806

Epoch: 6| Step: 9
Training loss: 1.5821291208267212
Validation loss: 2.0257967511812844

Epoch: 6| Step: 10
Training loss: 1.7056940793991089
Validation loss: 1.996864378452301

Epoch: 6| Step: 11
Training loss: 1.9340596199035645
Validation loss: 2.0197747349739075

Epoch: 6| Step: 12
Training loss: 1.6252506971359253
Validation loss: 2.034290611743927

Epoch: 6| Step: 13
Training loss: 1.8479037284851074
Validation loss: 2.0439971486727395

Epoch: 51| Step: 0
Training loss: 1.3576033115386963
Validation loss: 2.0449364384015403

Epoch: 6| Step: 1
Training loss: 1.2782280445098877
Validation loss: 2.041475792725881

Epoch: 6| Step: 2
Training loss: 1.398645281791687
Validation loss: 2.0675294995307922

Epoch: 6| Step: 3
Training loss: 2.00460147857666
Validation loss: 2.047597269217173

Epoch: 6| Step: 4
Training loss: 1.9931914806365967
Validation loss: 2.0500428875287375

Epoch: 6| Step: 5
Training loss: 3.1206917762756348
Validation loss: 2.0392704407374063

Epoch: 6| Step: 6
Training loss: 2.0575695037841797
Validation loss: 2.0524123907089233

Epoch: 6| Step: 7
Training loss: 1.5896236896514893
Validation loss: 2.0039297938346863

Epoch: 6| Step: 8
Training loss: 1.8790277242660522
Validation loss: 2.015864094098409

Epoch: 6| Step: 9
Training loss: 2.199303388595581
Validation loss: 2.012607475121816

Epoch: 6| Step: 10
Training loss: 1.8676512241363525
Validation loss: 2.007231851418813

Epoch: 6| Step: 11
Training loss: 2.2907705307006836
Validation loss: 2.0116748611132302

Epoch: 6| Step: 12
Training loss: 1.5530359745025635
Validation loss: 2.0151599844296775

Epoch: 6| Step: 13
Training loss: 1.7963354587554932
Validation loss: 2.0172373255093894

Epoch: 52| Step: 0
Training loss: 2.4845316410064697
Validation loss: 2.0213303764661155

Epoch: 6| Step: 1
Training loss: 2.2001547813415527
Validation loss: 2.0311535596847534

Epoch: 6| Step: 2
Training loss: 2.042464256286621
Validation loss: 2.0178380409876504

Epoch: 6| Step: 3
Training loss: 1.5961252450942993
Validation loss: 2.0096611181894937

Epoch: 6| Step: 4
Training loss: 2.3154563903808594
Validation loss: 2.034235199292501

Epoch: 6| Step: 5
Training loss: 1.9862667322158813
Validation loss: 2.0267606178919473

Epoch: 6| Step: 6
Training loss: 1.723202109336853
Validation loss: 2.0308231314023337

Epoch: 6| Step: 7
Training loss: 1.2630454301834106
Validation loss: 2.0184617042541504

Epoch: 6| Step: 8
Training loss: 2.3049683570861816
Validation loss: 1.9948798418045044

Epoch: 6| Step: 9
Training loss: 1.8771865367889404
Validation loss: 2.0280913710594177

Epoch: 6| Step: 10
Training loss: 2.0513219833374023
Validation loss: 2.03291255235672

Epoch: 6| Step: 11
Training loss: 1.450540542602539
Validation loss: 2.0288864374160767

Epoch: 6| Step: 12
Training loss: 1.6999179124832153
Validation loss: 2.0375438928604126

Epoch: 6| Step: 13
Training loss: 1.5882351398468018
Validation loss: 2.048147896925608

Epoch: 53| Step: 0
Training loss: 1.5400917530059814
Validation loss: 2.0305967926979065

Epoch: 6| Step: 1
Training loss: 2.1903209686279297
Validation loss: 2.066431204477946

Epoch: 6| Step: 2
Training loss: 1.6504759788513184
Validation loss: 2.033689339955648

Epoch: 6| Step: 3
Training loss: 1.0932190418243408
Validation loss: 2.0451731284459433

Epoch: 6| Step: 4
Training loss: 2.7878904342651367
Validation loss: 2.0426657994588218

Epoch: 6| Step: 5
Training loss: 1.7402400970458984
Validation loss: 2.050903002421061

Epoch: 6| Step: 6
Training loss: 1.6530954837799072
Validation loss: 2.0393870870272317

Epoch: 6| Step: 7
Training loss: 2.335663318634033
Validation loss: 2.0281165838241577

Epoch: 6| Step: 8
Training loss: 1.7119405269622803
Validation loss: 2.002542038758596

Epoch: 6| Step: 9
Training loss: 1.6494393348693848
Validation loss: 2.0219691594441733

Epoch: 6| Step: 10
Training loss: 2.1289689540863037
Validation loss: 2.0197768410046897

Epoch: 6| Step: 11
Training loss: 2.5865776538848877
Validation loss: 2.0195712447166443

Epoch: 6| Step: 12
Training loss: 1.439943552017212
Validation loss: 2.014271934827169

Epoch: 6| Step: 13
Training loss: 1.8874976634979248
Validation loss: 2.025508681933085

Epoch: 54| Step: 0
Training loss: 2.3162214756011963
Validation loss: 2.012384573618571

Epoch: 6| Step: 1
Training loss: 1.3106050491333008
Validation loss: 2.0251033306121826

Epoch: 6| Step: 2
Training loss: 2.023847818374634
Validation loss: 2.024014870325724

Epoch: 6| Step: 3
Training loss: 2.008617639541626
Validation loss: 2.0389800469080606

Epoch: 6| Step: 4
Training loss: 2.381885051727295
Validation loss: 2.045761207739512

Epoch: 6| Step: 5
Training loss: 1.586714506149292
Validation loss: 2.0472623109817505

Epoch: 6| Step: 6
Training loss: 1.6700927019119263
Validation loss: 2.0813048481941223

Epoch: 6| Step: 7
Training loss: 2.0464231967926025
Validation loss: 2.078761418660482

Epoch: 6| Step: 8
Training loss: 1.5788462162017822
Validation loss: 2.080445965131124

Epoch: 6| Step: 9
Training loss: 1.5442445278167725
Validation loss: 2.067992607752482

Epoch: 6| Step: 10
Training loss: 2.2076961994171143
Validation loss: 2.058160364627838

Epoch: 6| Step: 11
Training loss: 2.1426429748535156
Validation loss: 2.022709627946218

Epoch: 6| Step: 12
Training loss: 1.903628945350647
Validation loss: 2.038252810637156

Epoch: 6| Step: 13
Training loss: 1.926777958869934
Validation loss: 2.031559109687805

Epoch: 55| Step: 0
Training loss: 1.9378716945648193
Validation loss: 2.0421825846036277

Epoch: 6| Step: 1
Training loss: 1.1222000122070312
Validation loss: 2.0121841430664062

Epoch: 6| Step: 2
Training loss: 2.376924991607666
Validation loss: 2.0230021278063455

Epoch: 6| Step: 3
Training loss: 1.5460824966430664
Validation loss: 2.025588115056356

Epoch: 6| Step: 4
Training loss: 2.1138737201690674
Validation loss: 2.0006500283877053

Epoch: 6| Step: 5
Training loss: 1.880109429359436
Validation loss: 2.0207050840059915

Epoch: 6| Step: 6
Training loss: 1.383681297302246
Validation loss: 2.0374993681907654

Epoch: 6| Step: 7
Training loss: 2.3720102310180664
Validation loss: 2.037002960840861

Epoch: 6| Step: 8
Training loss: 1.7223434448242188
Validation loss: 2.033230781555176

Epoch: 6| Step: 9
Training loss: 2.1830220222473145
Validation loss: 2.016673187414805

Epoch: 6| Step: 10
Training loss: 2.178666830062866
Validation loss: 2.0376205444335938

Epoch: 6| Step: 11
Training loss: 1.8472483158111572
Validation loss: 2.0491575996081033

Epoch: 6| Step: 12
Training loss: 1.6725058555603027
Validation loss: 2.0370657642682395

Epoch: 6| Step: 13
Training loss: 2.0640830993652344
Validation loss: 2.0211191972096763

Epoch: 56| Step: 0
Training loss: 1.6686582565307617
Validation loss: 2.0356361865997314

Epoch: 6| Step: 1
Training loss: 2.104889392852783
Validation loss: 2.018915832042694

Epoch: 6| Step: 2
Training loss: 1.7933603525161743
Validation loss: 2.028646230697632

Epoch: 6| Step: 3
Training loss: 2.2626779079437256
Validation loss: 2.044120212395986

Epoch: 6| Step: 4
Training loss: 1.8520872592926025
Validation loss: 2.0452071825663247

Epoch: 6| Step: 5
Training loss: 2.4596517086029053
Validation loss: 2.053832491238912

Epoch: 6| Step: 6
Training loss: 1.9767696857452393
Validation loss: 2.085585296154022

Epoch: 6| Step: 7
Training loss: 1.356733798980713
Validation loss: 2.065419097741445

Epoch: 6| Step: 8
Training loss: 1.9477365016937256
Validation loss: 2.0626458128293357

Epoch: 6| Step: 9
Training loss: 1.9794245958328247
Validation loss: 2.043177088101705

Epoch: 6| Step: 10
Training loss: 1.9003455638885498
Validation loss: 2.0639569759368896

Epoch: 6| Step: 11
Training loss: 1.5726885795593262
Validation loss: 2.0349451303482056

Epoch: 6| Step: 12
Training loss: 1.9270981550216675
Validation loss: 2.0409380892912545

Epoch: 6| Step: 13
Training loss: 1.5941526889801025
Validation loss: 2.0424137512842813

Epoch: 57| Step: 0
Training loss: 1.502741813659668
Validation loss: 2.0103718042373657

Epoch: 6| Step: 1
Training loss: 1.442546010017395
Validation loss: 2.012014150619507

Epoch: 6| Step: 2
Training loss: 3.0037834644317627
Validation loss: 2.0134126345316568

Epoch: 6| Step: 3
Training loss: 2.17553448677063
Validation loss: 2.0271979371706643

Epoch: 6| Step: 4
Training loss: 1.866231918334961
Validation loss: 2.016017178694407

Epoch: 6| Step: 5
Training loss: 2.2519521713256836
Validation loss: 2.0061318278312683

Epoch: 6| Step: 6
Training loss: 2.046964645385742
Validation loss: 2.017374257246653

Epoch: 6| Step: 7
Training loss: 1.0278326272964478
Validation loss: 2.0334033568700156

Epoch: 6| Step: 8
Training loss: 1.6182044744491577
Validation loss: 2.0212950110435486

Epoch: 6| Step: 9
Training loss: 1.9357426166534424
Validation loss: 2.0163857340812683

Epoch: 6| Step: 10
Training loss: 1.827439785003662
Validation loss: 2.0118201772371926

Epoch: 6| Step: 11
Training loss: 1.6469804048538208
Validation loss: 2.037483553091685

Epoch: 6| Step: 12
Training loss: 1.9772897958755493
Validation loss: 2.031272292137146

Epoch: 6| Step: 13
Training loss: 1.8579208850860596
Validation loss: 2.0591391126314798

Epoch: 58| Step: 0
Training loss: 2.13187313079834
Validation loss: 2.031435549259186

Epoch: 6| Step: 1
Training loss: 1.5713090896606445
Validation loss: 2.050157368183136

Epoch: 6| Step: 2
Training loss: 1.6322513818740845
Validation loss: 2.0465020736058555

Epoch: 6| Step: 3
Training loss: 2.119556427001953
Validation loss: 2.066452165444692

Epoch: 6| Step: 4
Training loss: 1.761637568473816
Validation loss: 2.045706888039907

Epoch: 6| Step: 5
Training loss: 1.9476573467254639
Validation loss: 2.0429755647977195

Epoch: 6| Step: 6
Training loss: 2.047586441040039
Validation loss: 2.0846497217814126

Epoch: 6| Step: 7
Training loss: 1.7801592350006104
Validation loss: 2.0621331334114075

Epoch: 6| Step: 8
Training loss: 2.1805105209350586
Validation loss: 2.058780074119568

Epoch: 6| Step: 9
Training loss: 1.740194320678711
Validation loss: 2.0685309966405234

Epoch: 6| Step: 10
Training loss: 2.3455591201782227
Validation loss: 2.0659259955088296

Epoch: 6| Step: 11
Training loss: 1.4374032020568848
Validation loss: 2.0405357480049133

Epoch: 6| Step: 12
Training loss: 1.5328097343444824
Validation loss: 2.0308390061060586

Epoch: 6| Step: 13
Training loss: 1.999406337738037
Validation loss: 2.041256606578827

Epoch: 59| Step: 0
Training loss: 1.7110035419464111
Validation loss: 2.023776968320211

Epoch: 6| Step: 1
Training loss: 1.576418399810791
Validation loss: 2.0194435715675354

Epoch: 6| Step: 2
Training loss: 2.192265033721924
Validation loss: 2.0209023356437683

Epoch: 6| Step: 3
Training loss: 2.246922016143799
Validation loss: 2.0165425737698874

Epoch: 6| Step: 4
Training loss: 2.3342790603637695
Validation loss: 2.0274563431739807

Epoch: 6| Step: 5
Training loss: 1.895810604095459
Validation loss: 2.022587458292643

Epoch: 6| Step: 6
Training loss: 1.8177015781402588
Validation loss: 2.0103982289632163

Epoch: 6| Step: 7
Training loss: 1.5770561695098877
Validation loss: 2.047653079032898

Epoch: 6| Step: 8
Training loss: 1.7314279079437256
Validation loss: 2.0103670557339988

Epoch: 6| Step: 9
Training loss: 1.8843681812286377
Validation loss: 2.0516499678293862

Epoch: 6| Step: 10
Training loss: 1.4129228591918945
Validation loss: 2.0264160434405007

Epoch: 6| Step: 11
Training loss: 2.066572427749634
Validation loss: 2.048508604367574

Epoch: 6| Step: 12
Training loss: 2.00557017326355
Validation loss: 2.0343504548072815

Epoch: 6| Step: 13
Training loss: 1.6207228899002075
Validation loss: 2.040986200173696

Epoch: 60| Step: 0
Training loss: 1.7607375383377075
Validation loss: 2.0334765513738

Epoch: 6| Step: 1
Training loss: 2.513072967529297
Validation loss: 2.032580335934957

Epoch: 6| Step: 2
Training loss: 2.843904972076416
Validation loss: 1.9953924616177876

Epoch: 6| Step: 3
Training loss: 1.183092474937439
Validation loss: 2.016865293184916

Epoch: 6| Step: 4
Training loss: 2.2517857551574707
Validation loss: 2.0419065952301025

Epoch: 6| Step: 5
Training loss: 1.6049809455871582
Validation loss: 2.0053417881329856

Epoch: 6| Step: 6
Training loss: 2.1874184608459473
Validation loss: 2.029135306676229

Epoch: 6| Step: 7
Training loss: 1.6869813203811646
Validation loss: 2.0234678983688354

Epoch: 6| Step: 8
Training loss: 1.967841386795044
Validation loss: 2.0267823139826455

Epoch: 6| Step: 9
Training loss: 1.916013240814209
Validation loss: 2.0410301287968955

Epoch: 6| Step: 10
Training loss: 1.6882002353668213
Validation loss: 2.0742051204045615

Epoch: 6| Step: 11
Training loss: 1.1566303968429565
Validation loss: 2.0378261605898538

Epoch: 6| Step: 12
Training loss: 2.104783535003662
Validation loss: 2.075219710667928

Epoch: 6| Step: 13
Training loss: 1.177961826324463
Validation loss: 2.057061771551768

Epoch: 61| Step: 0
Training loss: 1.991090178489685
Validation loss: 2.041872243086497

Epoch: 6| Step: 1
Training loss: 1.111504077911377
Validation loss: 2.06175434589386

Epoch: 6| Step: 2
Training loss: 1.3243083953857422
Validation loss: 2.079520662625631

Epoch: 6| Step: 3
Training loss: 1.4126759767532349
Validation loss: 2.055344025293986

Epoch: 6| Step: 4
Training loss: 2.4132184982299805
Validation loss: 2.0594990650812783

Epoch: 6| Step: 5
Training loss: 2.036400556564331
Validation loss: 2.057704130808512

Epoch: 6| Step: 6
Training loss: 1.6721243858337402
Validation loss: 2.074381947517395

Epoch: 6| Step: 7
Training loss: 2.3272933959960938
Validation loss: 2.064012030760447

Epoch: 6| Step: 8
Training loss: 2.3549227714538574
Validation loss: 2.0524354378382363

Epoch: 6| Step: 9
Training loss: 1.967778205871582
Validation loss: 2.047447144985199

Epoch: 6| Step: 10
Training loss: 2.1422176361083984
Validation loss: 2.0763235290845237

Epoch: 6| Step: 11
Training loss: 1.87890625
Validation loss: 2.047626515229543

Epoch: 6| Step: 12
Training loss: 1.9420751333236694
Validation loss: 2.028319478034973

Epoch: 6| Step: 13
Training loss: 1.6541777849197388
Validation loss: 2.023231267929077

Epoch: 62| Step: 0
Training loss: 1.819871425628662
Validation loss: 2.0361123283704123

Epoch: 6| Step: 1
Training loss: 1.5779139995574951
Validation loss: 2.023656725883484

Epoch: 6| Step: 2
Training loss: 0.8027981519699097
Validation loss: 2.02521812915802

Epoch: 6| Step: 3
Training loss: 1.9102306365966797
Validation loss: 2.0076545675595603

Epoch: 6| Step: 4
Training loss: 2.519991397857666
Validation loss: 2.035828113555908

Epoch: 6| Step: 5
Training loss: 2.0301976203918457
Validation loss: 2.024438222249349

Epoch: 6| Step: 6
Training loss: 1.5395238399505615
Validation loss: 2.0395140647888184

Epoch: 6| Step: 7
Training loss: 2.3324825763702393
Validation loss: 2.059402823448181

Epoch: 6| Step: 8
Training loss: 2.408627986907959
Validation loss: 2.039029876391093

Epoch: 6| Step: 9
Training loss: 1.6591224670410156
Validation loss: 2.0372058351834617

Epoch: 6| Step: 10
Training loss: 1.68582284450531
Validation loss: 2.024822235107422

Epoch: 6| Step: 11
Training loss: 2.2769484519958496
Validation loss: 2.043193062146505

Epoch: 6| Step: 12
Training loss: 2.003188133239746
Validation loss: 2.0290367205937705

Epoch: 6| Step: 13
Training loss: 1.3418495655059814
Validation loss: 2.0310864051183066

Epoch: 63| Step: 0
Training loss: 1.5572618246078491
Validation loss: 2.0436293284098306

Epoch: 6| Step: 1
Training loss: 1.4223523139953613
Validation loss: 2.022032082080841

Epoch: 6| Step: 2
Training loss: 1.265180230140686
Validation loss: 2.062057614326477

Epoch: 6| Step: 3
Training loss: 2.126222610473633
Validation loss: 2.0341670314470925

Epoch: 6| Step: 4
Training loss: 2.3109302520751953
Validation loss: 2.062764366467794

Epoch: 6| Step: 5
Training loss: 1.8827576637268066
Validation loss: 2.0806728998819985

Epoch: 6| Step: 6
Training loss: 2.2250192165374756
Validation loss: 2.0341726541519165

Epoch: 6| Step: 7
Training loss: 2.1904613971710205
Validation loss: 2.027445058027903

Epoch: 6| Step: 8
Training loss: 2.30964994430542
Validation loss: 2.0297839641571045

Epoch: 6| Step: 9
Training loss: 1.7097210884094238
Validation loss: 2.015886068344116

Epoch: 6| Step: 10
Training loss: 1.1944974660873413
Validation loss: 2.029506206512451

Epoch: 6| Step: 11
Training loss: 2.3961503505706787
Validation loss: 2.0248661239941916

Epoch: 6| Step: 12
Training loss: 1.8969939947128296
Validation loss: 2.02203776439031

Epoch: 6| Step: 13
Training loss: 1.1788368225097656
Validation loss: 2.0006432135899863

Epoch: 64| Step: 0
Training loss: 2.510546922683716
Validation loss: 2.0208483735720315

Epoch: 6| Step: 1
Training loss: 1.4956881999969482
Validation loss: 2.025690217812856

Epoch: 6| Step: 2
Training loss: 1.874617338180542
Validation loss: 2.028815805912018

Epoch: 6| Step: 3
Training loss: 1.485438585281372
Validation loss: 2.0252202351888022

Epoch: 6| Step: 4
Training loss: 1.7082936763763428
Validation loss: 2.0034940441449485

Epoch: 6| Step: 5
Training loss: 1.2644898891448975
Validation loss: 2.041823705037435

Epoch: 6| Step: 6
Training loss: 1.727240800857544
Validation loss: 2.0319528182347617

Epoch: 6| Step: 7
Training loss: 1.9444313049316406
Validation loss: 2.0556361277898154

Epoch: 6| Step: 8
Training loss: 1.85238516330719
Validation loss: 2.034881591796875

Epoch: 6| Step: 9
Training loss: 1.821664810180664
Validation loss: 2.039572238922119

Epoch: 6| Step: 10
Training loss: 3.1481223106384277
Validation loss: 2.069939057032267

Epoch: 6| Step: 11
Training loss: 1.5807514190673828
Validation loss: 2.05634198586146

Epoch: 6| Step: 12
Training loss: 1.8436321020126343
Validation loss: 2.061658044656118

Epoch: 6| Step: 13
Training loss: 1.5093247890472412
Validation loss: 2.042916019757589

Epoch: 65| Step: 0
Training loss: 1.6235769987106323
Validation loss: 2.0860541462898254

Epoch: 6| Step: 1
Training loss: 1.735457181930542
Validation loss: 2.0852414766947427

Epoch: 6| Step: 2
Training loss: 1.426922082901001
Validation loss: 2.0362277030944824

Epoch: 6| Step: 3
Training loss: 2.3970770835876465
Validation loss: 2.049252688884735

Epoch: 6| Step: 4
Training loss: 1.359083890914917
Validation loss: 2.028788208961487

Epoch: 6| Step: 5
Training loss: 1.9183635711669922
Validation loss: 2.0804277857144675

Epoch: 6| Step: 6
Training loss: 1.8054122924804688
Validation loss: 2.0400699575742087

Epoch: 6| Step: 7
Training loss: 2.097271203994751
Validation loss: 2.021528879801432

Epoch: 6| Step: 8
Training loss: 1.831425666809082
Validation loss: 2.062110940615336

Epoch: 6| Step: 9
Training loss: 2.378213405609131
Validation loss: 2.031157076358795

Epoch: 6| Step: 10
Training loss: 1.8259706497192383
Validation loss: 2.051463464895884

Epoch: 6| Step: 11
Training loss: 1.8917570114135742
Validation loss: 2.038087805112203

Epoch: 6| Step: 12
Training loss: 1.376523733139038
Validation loss: 2.0573596159617105

Epoch: 6| Step: 13
Training loss: 2.180062770843506
Validation loss: 2.0225278536478677

Epoch: 66| Step: 0
Training loss: 2.391082763671875
Validation loss: 2.030829826990763

Epoch: 6| Step: 1
Training loss: 1.9577536582946777
Validation loss: 2.034415364265442

Epoch: 6| Step: 2
Training loss: 1.8761664628982544
Validation loss: 2.0525479118029275

Epoch: 6| Step: 3
Training loss: 1.5888230800628662
Validation loss: 2.0341047048568726

Epoch: 6| Step: 4
Training loss: 1.1029282808303833
Validation loss: 2.021726985772451

Epoch: 6| Step: 5
Training loss: 1.7554781436920166
Validation loss: 2.0315229892730713

Epoch: 6| Step: 6
Training loss: 2.5261058807373047
Validation loss: 2.0534484585126243

Epoch: 6| Step: 7
Training loss: 1.5785951614379883
Validation loss: 2.0578444798787436

Epoch: 6| Step: 8
Training loss: 1.958510160446167
Validation loss: 2.0381516416867576

Epoch: 6| Step: 9
Training loss: 1.835838794708252
Validation loss: 2.034876008828481

Epoch: 6| Step: 10
Training loss: 2.23380446434021
Validation loss: 2.0374481280644736

Epoch: 6| Step: 11
Training loss: 1.4136956930160522
Validation loss: 2.0271517435709634

Epoch: 6| Step: 12
Training loss: 2.1125845909118652
Validation loss: 2.02638578414917

Epoch: 6| Step: 13
Training loss: 1.3415039777755737
Validation loss: 2.0319700638453164

Epoch: 67| Step: 0
Training loss: 1.3223249912261963
Validation loss: 2.027825355529785

Epoch: 6| Step: 1
Training loss: 1.7060840129852295
Validation loss: 2.02416584889094

Epoch: 6| Step: 2
Training loss: 2.025484561920166
Validation loss: 2.0275044639905295

Epoch: 6| Step: 3
Training loss: 2.166367530822754
Validation loss: 2.049754778544108

Epoch: 6| Step: 4
Training loss: 2.163707971572876
Validation loss: 2.0445095896720886

Epoch: 6| Step: 5
Training loss: 1.4617893695831299
Validation loss: 2.0234157840410867

Epoch: 6| Step: 6
Training loss: 2.1472525596618652
Validation loss: 2.0389906962712607

Epoch: 6| Step: 7
Training loss: 1.9010009765625
Validation loss: 2.0338675578435264

Epoch: 6| Step: 8
Training loss: 2.0457262992858887
Validation loss: 2.0165717005729675

Epoch: 6| Step: 9
Training loss: 1.1173689365386963
Validation loss: 2.003619452317556

Epoch: 6| Step: 10
Training loss: 1.6069303750991821
Validation loss: 2.03324286142985

Epoch: 6| Step: 11
Training loss: 2.455078601837158
Validation loss: 2.048503299554189

Epoch: 6| Step: 12
Training loss: 1.5739803314208984
Validation loss: 2.054180641969045

Epoch: 6| Step: 13
Training loss: 1.6149065494537354
Validation loss: 2.0414398113886514

Epoch: 68| Step: 0
Training loss: 2.181204319000244
Validation loss: 2.0700793266296387

Epoch: 6| Step: 1
Training loss: 1.234368085861206
Validation loss: 2.0348501205444336

Epoch: 6| Step: 2
Training loss: 1.9635043144226074
Validation loss: 2.072951356569926

Epoch: 6| Step: 3
Training loss: 1.9540621042251587
Validation loss: 2.068238059679667

Epoch: 6| Step: 4
Training loss: 2.1605846881866455
Validation loss: 2.057629326979319

Epoch: 6| Step: 5
Training loss: 1.554740309715271
Validation loss: 2.062017560005188

Epoch: 6| Step: 6
Training loss: 2.1534295082092285
Validation loss: 2.063912272453308

Epoch: 6| Step: 7
Training loss: 2.550450325012207
Validation loss: 2.059401194254557

Epoch: 6| Step: 8
Training loss: 1.3675566911697388
Validation loss: 2.062691648801168

Epoch: 6| Step: 9
Training loss: 1.9225537776947021
Validation loss: 2.014274795850118

Epoch: 6| Step: 10
Training loss: 2.107388496398926
Validation loss: 2.0131713350613913

Epoch: 6| Step: 11
Training loss: 1.2745599746704102
Validation loss: 2.0368475317955017

Epoch: 6| Step: 12
Training loss: 1.9859340190887451
Validation loss: 2.016787827014923

Epoch: 6| Step: 13
Training loss: 1.2709150314331055
Validation loss: 2.0257529616355896

Epoch: 69| Step: 0
Training loss: 1.5704772472381592
Validation loss: 2.039963722229004

Epoch: 6| Step: 1
Training loss: 2.021643877029419
Validation loss: 2.053071896235148

Epoch: 6| Step: 2
Training loss: 1.607135534286499
Validation loss: 2.0371129512786865

Epoch: 6| Step: 3
Training loss: 2.00130558013916
Validation loss: 2.0355343023935952

Epoch: 6| Step: 4
Training loss: 1.7219882011413574
Validation loss: 2.0208619236946106

Epoch: 6| Step: 5
Training loss: 1.845353364944458
Validation loss: 2.0369339187939963

Epoch: 6| Step: 6
Training loss: 2.0168299674987793
Validation loss: 2.0898208816846213

Epoch: 6| Step: 7
Training loss: 2.387514352798462
Validation loss: 2.069725672403971

Epoch: 6| Step: 8
Training loss: 1.8455543518066406
Validation loss: 2.034260332584381

Epoch: 6| Step: 9
Training loss: 1.7926530838012695
Validation loss: 2.0653855403264365

Epoch: 6| Step: 10
Training loss: 1.7933357954025269
Validation loss: 2.0361346006393433

Epoch: 6| Step: 11
Training loss: 2.221856117248535
Validation loss: 2.0432342489560447

Epoch: 6| Step: 12
Training loss: 1.4119161367416382
Validation loss: 2.0781161785125732

Epoch: 6| Step: 13
Training loss: 1.223109245300293
Validation loss: 2.087044894695282

Epoch: 70| Step: 0
Training loss: 2.000502586364746
Validation loss: 2.0425487558046975

Epoch: 6| Step: 1
Training loss: 1.6209882497787476
Validation loss: 2.04477858543396

Epoch: 6| Step: 2
Training loss: 2.022731304168701
Validation loss: 2.0493735472361245

Epoch: 6| Step: 3
Training loss: 2.413508176803589
Validation loss: 2.0334022839864097

Epoch: 6| Step: 4
Training loss: 1.579246997833252
Validation loss: 2.046891212463379

Epoch: 6| Step: 5
Training loss: 2.010531425476074
Validation loss: 2.0471055706342063

Epoch: 6| Step: 6
Training loss: 2.13887619972229
Validation loss: 2.0430774887402854

Epoch: 6| Step: 7
Training loss: 1.9936487674713135
Validation loss: 2.0142398277918496

Epoch: 6| Step: 8
Training loss: 1.6063005924224854
Validation loss: 2.0176629026730857

Epoch: 6| Step: 9
Training loss: 2.283778190612793
Validation loss: 2.0057623386383057

Epoch: 6| Step: 10
Training loss: 1.3178932666778564
Validation loss: 1.9933617512385051

Epoch: 6| Step: 11
Training loss: 1.2737185955047607
Validation loss: 2.030496040980021

Epoch: 6| Step: 12
Training loss: 1.1963988542556763
Validation loss: 2.026653230190277

Epoch: 6| Step: 13
Training loss: 1.9337034225463867
Validation loss: 2.045933504899343

Epoch: 71| Step: 0
Training loss: 1.408362627029419
Validation loss: 2.046599249045054

Epoch: 6| Step: 1
Training loss: 1.9982945919036865
Validation loss: 2.0258933901786804

Epoch: 6| Step: 2
Training loss: 1.840502142906189
Validation loss: 2.035838464895884

Epoch: 6| Step: 3
Training loss: 1.3304609060287476
Validation loss: 2.057648162047068

Epoch: 6| Step: 4
Training loss: 1.980124592781067
Validation loss: 2.027510384718577

Epoch: 6| Step: 5
Training loss: 1.5170013904571533
Validation loss: 2.0640838940938315

Epoch: 6| Step: 6
Training loss: 2.041900634765625
Validation loss: 2.081179221471151

Epoch: 6| Step: 7
Training loss: 2.5281286239624023
Validation loss: 2.055111587047577

Epoch: 6| Step: 8
Training loss: 2.089143991470337
Validation loss: 2.0416358709335327

Epoch: 6| Step: 9
Training loss: 1.7097314596176147
Validation loss: 2.043934921423594

Epoch: 6| Step: 10
Training loss: 1.5183098316192627
Validation loss: 2.0702869494756064

Epoch: 6| Step: 11
Training loss: 1.6083390712738037
Validation loss: 2.0561509331067405

Epoch: 6| Step: 12
Training loss: 1.9548624753952026
Validation loss: 2.0673242608706155

Epoch: 6| Step: 13
Training loss: 1.7279400825500488
Validation loss: 2.0322853128115335

Epoch: 72| Step: 0
Training loss: 1.3938589096069336
Validation loss: 2.0546015898386636

Epoch: 6| Step: 1
Training loss: 1.9405237436294556
Validation loss: 2.047860403855642

Epoch: 6| Step: 2
Training loss: 2.263010025024414
Validation loss: 2.0341461896896362

Epoch: 6| Step: 3
Training loss: 2.1613411903381348
Validation loss: 2.0388052264849343

Epoch: 6| Step: 4
Training loss: 2.34934139251709
Validation loss: 2.045516232649485

Epoch: 6| Step: 5
Training loss: 1.804068922996521
Validation loss: 2.0364922285079956

Epoch: 6| Step: 6
Training loss: 1.8597500324249268
Validation loss: 2.039635161558787

Epoch: 6| Step: 7
Training loss: 1.2488768100738525
Validation loss: 2.024487833182017

Epoch: 6| Step: 8
Training loss: 1.694549322128296
Validation loss: 2.0450552503267923

Epoch: 6| Step: 9
Training loss: 1.9844061136245728
Validation loss: 2.0137982169787088

Epoch: 6| Step: 10
Training loss: 1.4430413246154785
Validation loss: 2.047010898590088

Epoch: 6| Step: 11
Training loss: 1.5534698963165283
Validation loss: 2.0406627853711448

Epoch: 6| Step: 12
Training loss: 1.7264924049377441
Validation loss: 2.048402031262716

Epoch: 6| Step: 13
Training loss: 1.812158226966858
Validation loss: 2.0460142890612283

Epoch: 73| Step: 0
Training loss: 1.951353907585144
Validation loss: 2.047132213910421

Epoch: 6| Step: 1
Training loss: 1.3089416027069092
Validation loss: 2.0608683029810586

Epoch: 6| Step: 2
Training loss: 2.08681583404541
Validation loss: 2.0777304569880166

Epoch: 6| Step: 3
Training loss: 0.7417916059494019
Validation loss: 2.018249233563741

Epoch: 6| Step: 4
Training loss: 1.9651422500610352
Validation loss: 2.0584366718928018

Epoch: 6| Step: 5
Training loss: 1.1659764051437378
Validation loss: 2.0406904220581055

Epoch: 6| Step: 6
Training loss: 2.0176403522491455
Validation loss: 2.034225066502889

Epoch: 6| Step: 7
Training loss: 2.213974714279175
Validation loss: 2.038296182950338

Epoch: 6| Step: 8
Training loss: 2.54714298248291
Validation loss: 1.998772124449412

Epoch: 6| Step: 9
Training loss: 2.0024027824401855
Validation loss: 2.037793278694153

Epoch: 6| Step: 10
Training loss: 1.8139581680297852
Validation loss: 2.0276187856992087

Epoch: 6| Step: 11
Training loss: 1.9851396083831787
Validation loss: 2.0278804699579873

Epoch: 6| Step: 12
Training loss: 1.687459945678711
Validation loss: 2.022518813610077

Epoch: 6| Step: 13
Training loss: 1.9632809162139893
Validation loss: 2.0681720773379006

Epoch: 74| Step: 0
Training loss: 1.5388435125350952
Validation loss: 2.041898330052694

Epoch: 6| Step: 1
Training loss: 1.8906056880950928
Validation loss: 2.049717605113983

Epoch: 6| Step: 2
Training loss: 1.495413064956665
Validation loss: 2.0472861727078757

Epoch: 6| Step: 3
Training loss: 1.5476136207580566
Validation loss: 2.0675164659818015

Epoch: 6| Step: 4
Training loss: 1.1841073036193848
Validation loss: 2.0904802083969116

Epoch: 6| Step: 5
Training loss: 1.4478085041046143
Validation loss: 2.086946109930674

Epoch: 6| Step: 6
Training loss: 2.1320581436157227
Validation loss: 2.0892959038416543

Epoch: 6| Step: 7
Training loss: 2.046715021133423
Validation loss: 2.0509603222211203

Epoch: 6| Step: 8
Training loss: 2.2826457023620605
Validation loss: 2.0834483901659646

Epoch: 6| Step: 9
Training loss: 1.871565580368042
Validation loss: 2.0640806953112283

Epoch: 6| Step: 10
Training loss: 1.3567090034484863
Validation loss: 2.0678962071736655

Epoch: 6| Step: 11
Training loss: 1.7161493301391602
Validation loss: 2.0830252965291343

Epoch: 6| Step: 12
Training loss: 2.5419974327087402
Validation loss: 2.026583433151245

Epoch: 6| Step: 13
Training loss: 2.160733222961426
Validation loss: 2.0297143260637918

Epoch: 75| Step: 0
Training loss: 1.5582762956619263
Validation loss: 2.0493342677752175

Epoch: 6| Step: 1
Training loss: 1.947317361831665
Validation loss: 2.0385666886965432

Epoch: 6| Step: 2
Training loss: 1.2776826620101929
Validation loss: 2.052061756451925

Epoch: 6| Step: 3
Training loss: 2.6934328079223633
Validation loss: 2.033816933631897

Epoch: 6| Step: 4
Training loss: 1.329222559928894
Validation loss: 2.0481167435646057

Epoch: 6| Step: 5
Training loss: 1.9953324794769287
Validation loss: 2.0503492951393127

Epoch: 6| Step: 6
Training loss: 1.5358937978744507
Validation loss: 2.051174839337667

Epoch: 6| Step: 7
Training loss: 1.8950891494750977
Validation loss: 2.030511498451233

Epoch: 6| Step: 8
Training loss: 2.1423635482788086
Validation loss: 2.0390520890553794

Epoch: 6| Step: 9
Training loss: 1.1360464096069336
Validation loss: 2.0488979617754617

Epoch: 6| Step: 10
Training loss: 2.2171471118927
Validation loss: 2.0054547588030496

Epoch: 6| Step: 11
Training loss: 1.781272053718567
Validation loss: 2.0290374954541526

Epoch: 6| Step: 12
Training loss: 1.37701416015625
Validation loss: 2.0294962724049888

Epoch: 6| Step: 13
Training loss: 1.910217046737671
Validation loss: 2.0563725431760154

Epoch: 76| Step: 0
Training loss: 1.5055142641067505
Validation loss: 2.030581613381704

Epoch: 6| Step: 1
Training loss: 1.386817216873169
Validation loss: 2.045430858929952

Epoch: 6| Step: 2
Training loss: 2.2555243968963623
Validation loss: 2.058968981107076

Epoch: 6| Step: 3
Training loss: 1.1862131357192993
Validation loss: 2.0744957526524863

Epoch: 6| Step: 4
Training loss: 2.17726993560791
Validation loss: 2.0282453298568726

Epoch: 6| Step: 5
Training loss: 1.9956220388412476
Validation loss: 2.079111178716024

Epoch: 6| Step: 6
Training loss: 1.713905692100525
Validation loss: 2.078041156133016

Epoch: 6| Step: 7
Training loss: 1.8294792175292969
Validation loss: 2.060534119606018

Epoch: 6| Step: 8
Training loss: 1.7252881526947021
Validation loss: 2.0351574619611106

Epoch: 6| Step: 9
Training loss: 1.7348222732543945
Validation loss: 2.034057855606079

Epoch: 6| Step: 10
Training loss: 2.161499500274658
Validation loss: 2.022055983543396

Epoch: 6| Step: 11
Training loss: 1.783677339553833
Validation loss: 2.0410715142885842

Epoch: 6| Step: 12
Training loss: 1.666849970817566
Validation loss: 2.053022583325704

Epoch: 6| Step: 13
Training loss: 1.7048085927963257
Validation loss: 2.056383411089579

Epoch: 77| Step: 0
Training loss: 1.3958139419555664
Validation loss: 2.03642338514328

Epoch: 6| Step: 1
Training loss: 1.2956140041351318
Validation loss: 2.068053722381592

Epoch: 6| Step: 2
Training loss: 2.386514186859131
Validation loss: 2.0646294355392456

Epoch: 6| Step: 3
Training loss: 1.6788880825042725
Validation loss: 2.032294591267904

Epoch: 6| Step: 4
Training loss: 2.0785207748413086
Validation loss: 2.0394938786824546

Epoch: 6| Step: 5
Training loss: 2.2967774868011475
Validation loss: 2.060058911641439

Epoch: 6| Step: 6
Training loss: 1.48667311668396
Validation loss: 2.044214109579722

Epoch: 6| Step: 7
Training loss: 1.5621007680892944
Validation loss: 2.067104697227478

Epoch: 6| Step: 8
Training loss: 1.9546078443527222
Validation loss: 2.051408052444458

Epoch: 6| Step: 9
Training loss: 2.3905043601989746
Validation loss: 2.034488558769226

Epoch: 6| Step: 10
Training loss: 1.7160037755966187
Validation loss: 2.024852673212687

Epoch: 6| Step: 11
Training loss: 2.1271634101867676
Validation loss: 2.0555910070737204

Epoch: 6| Step: 12
Training loss: 1.1724724769592285
Validation loss: 2.0451456705729165

Epoch: 6| Step: 13
Training loss: 1.2515168190002441
Validation loss: 2.0391651590665183

Epoch: 78| Step: 0
Training loss: 1.898949146270752
Validation loss: 2.0533159176508584

Epoch: 6| Step: 1
Training loss: 1.7847874164581299
Validation loss: 2.0508612791697183

Epoch: 6| Step: 2
Training loss: 1.6851452589035034
Validation loss: 2.0325673818588257

Epoch: 6| Step: 3
Training loss: 1.2452385425567627
Validation loss: 2.0837157169977822

Epoch: 6| Step: 4
Training loss: 1.706130027770996
Validation loss: 2.0401519338289895

Epoch: 6| Step: 5
Training loss: 1.7528414726257324
Validation loss: 2.0380979776382446

Epoch: 6| Step: 6
Training loss: 2.1774797439575195
Validation loss: 2.0358185172080994

Epoch: 6| Step: 7
Training loss: 1.9287470579147339
Validation loss: 2.022581100463867

Epoch: 6| Step: 8
Training loss: 1.1476001739501953
Validation loss: 2.08258980512619

Epoch: 6| Step: 9
Training loss: 1.3933868408203125
Validation loss: 2.07010289033254

Epoch: 6| Step: 10
Training loss: 2.3731746673583984
Validation loss: 2.0894791881243386

Epoch: 6| Step: 11
Training loss: 2.36437726020813
Validation loss: 2.058520038922628

Epoch: 6| Step: 12
Training loss: 1.6312614679336548
Validation loss: 2.06257700920105

Epoch: 6| Step: 13
Training loss: 1.576092004776001
Validation loss: 2.0386783679326377

Epoch: 79| Step: 0
Training loss: 2.029797315597534
Validation loss: 2.0587952931722007

Epoch: 6| Step: 1
Training loss: 1.854992389678955
Validation loss: 2.0390641689300537

Epoch: 6| Step: 2
Training loss: 1.7394938468933105
Validation loss: 2.0246535340944924

Epoch: 6| Step: 3
Training loss: 1.3750145435333252
Validation loss: 2.031312187512716

Epoch: 6| Step: 4
Training loss: 2.667236804962158
Validation loss: 2.0554086764653525

Epoch: 6| Step: 5
Training loss: 1.5830755233764648
Validation loss: 2.04118674993515

Epoch: 6| Step: 6
Training loss: 1.5288381576538086
Validation loss: 2.073064307371775

Epoch: 6| Step: 7
Training loss: 1.3361268043518066
Validation loss: 2.0242159366607666

Epoch: 6| Step: 8
Training loss: 1.5206220149993896
Validation loss: 2.063057323296865

Epoch: 6| Step: 9
Training loss: 2.3503189086914062
Validation loss: 2.052899638811747

Epoch: 6| Step: 10
Training loss: 1.7403563261032104
Validation loss: 2.065541366736094

Epoch: 6| Step: 11
Training loss: 2.075777530670166
Validation loss: 2.0431326627731323

Epoch: 6| Step: 12
Training loss: 1.27717125415802
Validation loss: 2.038089950879415

Epoch: 6| Step: 13
Training loss: 1.5455377101898193
Validation loss: 2.027446985244751

Epoch: 80| Step: 0
Training loss: 1.833074927330017
Validation loss: 2.024347941080729

Epoch: 6| Step: 1
Training loss: 1.586059331893921
Validation loss: 2.050186117490133

Epoch: 6| Step: 2
Training loss: 1.4871532917022705
Validation loss: 2.0291915933291116

Epoch: 6| Step: 3
Training loss: 1.7863061428070068
Validation loss: 2.045552690823873

Epoch: 6| Step: 4
Training loss: 2.4287006855010986
Validation loss: 2.063584486643473

Epoch: 6| Step: 5
Training loss: 1.6510711908340454
Validation loss: 2.064293126265208

Epoch: 6| Step: 6
Training loss: 1.2287158966064453
Validation loss: 2.0618823965390525

Epoch: 6| Step: 7
Training loss: 1.905468225479126
Validation loss: 2.0369540055592856

Epoch: 6| Step: 8
Training loss: 1.115350604057312
Validation loss: 2.077478528022766

Epoch: 6| Step: 9
Training loss: 1.8361445665359497
Validation loss: 2.0343932708104453

Epoch: 6| Step: 10
Training loss: 2.036956548690796
Validation loss: 2.016169329484304

Epoch: 6| Step: 11
Training loss: 1.6701035499572754
Validation loss: 2.03508992989858

Epoch: 6| Step: 12
Training loss: 2.2078113555908203
Validation loss: 2.0352863868077598

Epoch: 6| Step: 13
Training loss: 1.9095642566680908
Validation loss: 2.034844438234965

Epoch: 81| Step: 0
Training loss: 1.444014310836792
Validation loss: 2.036404252052307

Epoch: 6| Step: 1
Training loss: 1.9520939588546753
Validation loss: 2.0140050252278647

Epoch: 6| Step: 2
Training loss: 2.0741539001464844
Validation loss: 2.0405595699946084

Epoch: 6| Step: 3
Training loss: 1.6007912158966064
Validation loss: 2.0203387339909873

Epoch: 6| Step: 4
Training loss: 1.4557322263717651
Validation loss: 2.0421401262283325

Epoch: 6| Step: 5
Training loss: 1.794295072555542
Validation loss: 2.0682659347852073

Epoch: 6| Step: 6
Training loss: 1.9816546440124512
Validation loss: 2.0456637144088745

Epoch: 6| Step: 7
Training loss: 1.5090677738189697
Validation loss: 2.055901209513346

Epoch: 6| Step: 8
Training loss: 1.4661154747009277
Validation loss: 2.0736135443051658

Epoch: 6| Step: 9
Training loss: 1.665324091911316
Validation loss: 2.067879597345988

Epoch: 6| Step: 10
Training loss: 1.9016045331954956
Validation loss: 2.0994319717089334

Epoch: 6| Step: 11
Training loss: 2.4731132984161377
Validation loss: 2.0615843137105307

Epoch: 6| Step: 12
Training loss: 2.0357797145843506
Validation loss: 2.0381691455841064

Epoch: 6| Step: 13
Training loss: 1.3486385345458984
Validation loss: 2.040959676106771

Epoch: 82| Step: 0
Training loss: 1.5451750755310059
Validation loss: 2.042371074358622

Epoch: 6| Step: 1
Training loss: 1.8380542993545532
Validation loss: 2.0619997382164

Epoch: 6| Step: 2
Training loss: 1.7439817190170288
Validation loss: 2.042755742867788

Epoch: 6| Step: 3
Training loss: 2.3379297256469727
Validation loss: 2.0248321692148843

Epoch: 6| Step: 4
Training loss: 1.7428884506225586
Validation loss: 2.0597681800524392

Epoch: 6| Step: 5
Training loss: 1.436023473739624
Validation loss: 2.078218917051951

Epoch: 6| Step: 6
Training loss: 1.6528880596160889
Validation loss: 2.04477459192276

Epoch: 6| Step: 7
Training loss: 1.607600450515747
Validation loss: 2.0788930455843606

Epoch: 6| Step: 8
Training loss: 1.3982291221618652
Validation loss: 2.1068020264307656

Epoch: 6| Step: 9
Training loss: 1.312269687652588
Validation loss: 2.09754745165507

Epoch: 6| Step: 10
Training loss: 2.4485549926757812
Validation loss: 2.122940480709076

Epoch: 6| Step: 11
Training loss: 2.1007096767425537
Validation loss: 2.061385750770569

Epoch: 6| Step: 12
Training loss: 1.4937148094177246
Validation loss: 2.0796223084131875

Epoch: 6| Step: 13
Training loss: 1.8339951038360596
Validation loss: 2.062229593594869

Epoch: 83| Step: 0
Training loss: 2.028026580810547
Validation loss: 2.060863713423411

Epoch: 6| Step: 1
Training loss: 1.2691266536712646
Validation loss: 2.0370328028996787

Epoch: 6| Step: 2
Training loss: 1.7189044952392578
Validation loss: 2.026768426100413

Epoch: 6| Step: 3
Training loss: 0.9883354902267456
Validation loss: 2.027674376964569

Epoch: 6| Step: 4
Training loss: 1.7864289283752441
Validation loss: 2.0247757832209268

Epoch: 6| Step: 5
Training loss: 2.264887809753418
Validation loss: 2.0489054322242737

Epoch: 6| Step: 6
Training loss: 1.5035769939422607
Validation loss: 2.0128016273180642

Epoch: 6| Step: 7
Training loss: 2.138230800628662
Validation loss: 2.0174655516942344

Epoch: 6| Step: 8
Training loss: 1.6233532428741455
Validation loss: 2.017468969027201

Epoch: 6| Step: 9
Training loss: 2.031460762023926
Validation loss: 2.028591513633728

Epoch: 6| Step: 10
Training loss: 1.7689592838287354
Validation loss: 2.056521395842234

Epoch: 6| Step: 11
Training loss: 1.5349656343460083
Validation loss: 2.0697362422943115

Epoch: 6| Step: 12
Training loss: 1.5961782932281494
Validation loss: 2.0585800607999167

Epoch: 6| Step: 13
Training loss: 1.8253722190856934
Validation loss: 2.0402026573816934

Epoch: 84| Step: 0
Training loss: 1.5998902320861816
Validation loss: 2.0755577286084494

Epoch: 6| Step: 1
Training loss: 1.5528295040130615
Validation loss: 2.107853333155314

Epoch: 6| Step: 2
Training loss: 1.9122416973114014
Validation loss: 2.09064390261968

Epoch: 6| Step: 3
Training loss: 2.238727569580078
Validation loss: 2.1009325782457986

Epoch: 6| Step: 4
Training loss: 1.4357987642288208
Validation loss: 2.077207605044047

Epoch: 6| Step: 5
Training loss: 1.808539867401123
Validation loss: 2.069097956021627

Epoch: 6| Step: 6
Training loss: 2.489170551300049
Validation loss: 2.0793431401252747

Epoch: 6| Step: 7
Training loss: 0.9030415415763855
Validation loss: 2.1002033352851868

Epoch: 6| Step: 8
Training loss: 1.5633959770202637
Validation loss: 2.129434963067373

Epoch: 6| Step: 9
Training loss: 2.076663017272949
Validation loss: 2.106014927228292

Epoch: 6| Step: 10
Training loss: 1.4442322254180908
Validation loss: 2.0752457976341248

Epoch: 6| Step: 11
Training loss: 1.7767740488052368
Validation loss: 2.0779441197713218

Epoch: 6| Step: 12
Training loss: 2.041233539581299
Validation loss: 2.061697522799174

Epoch: 6| Step: 13
Training loss: 1.3785367012023926
Validation loss: 2.037619868914286

Epoch: 85| Step: 0
Training loss: 2.047975778579712
Validation loss: 2.031119704246521

Epoch: 6| Step: 1
Training loss: 1.834850788116455
Validation loss: 2.032135844230652

Epoch: 6| Step: 2
Training loss: 2.1953210830688477
Validation loss: 2.0508411725362143

Epoch: 6| Step: 3
Training loss: 2.3881888389587402
Validation loss: 2.0477359692255654

Epoch: 6| Step: 4
Training loss: 1.5956426858901978
Validation loss: 2.0137142141660056

Epoch: 6| Step: 5
Training loss: 1.5188324451446533
Validation loss: 2.0201037923494973

Epoch: 6| Step: 6
Training loss: 2.202875852584839
Validation loss: 2.058060626188914

Epoch: 6| Step: 7
Training loss: 1.3129220008850098
Validation loss: 2.023473083972931

Epoch: 6| Step: 8
Training loss: 1.9992660284042358
Validation loss: 2.045069853464762

Epoch: 6| Step: 9
Training loss: 1.7713536024093628
Validation loss: 2.020255446434021

Epoch: 6| Step: 10
Training loss: 1.374174952507019
Validation loss: 2.061295767625173

Epoch: 6| Step: 11
Training loss: 1.5970194339752197
Validation loss: 2.1171036760012307

Epoch: 6| Step: 12
Training loss: 1.1698541641235352
Validation loss: 2.1029075384140015

Epoch: 6| Step: 13
Training loss: 1.214149832725525
Validation loss: 2.0624128580093384

Epoch: 86| Step: 0
Training loss: 1.4571723937988281
Validation loss: 2.106926997502645

Epoch: 6| Step: 1
Training loss: 2.2392938137054443
Validation loss: 2.1133582393328347

Epoch: 6| Step: 2
Training loss: 1.1840286254882812
Validation loss: 2.0923115809758506

Epoch: 6| Step: 3
Training loss: 1.7600388526916504
Validation loss: 2.0494245886802673

Epoch: 6| Step: 4
Training loss: 1.6389139890670776
Validation loss: 2.0883890986442566

Epoch: 6| Step: 5
Training loss: 2.1922969818115234
Validation loss: 2.05613766113917

Epoch: 6| Step: 6
Training loss: 1.5546578168869019
Validation loss: 2.055493493874868

Epoch: 6| Step: 7
Training loss: 1.62826406955719
Validation loss: 2.0505878925323486

Epoch: 6| Step: 8
Training loss: 1.8407479524612427
Validation loss: 2.032058358192444

Epoch: 6| Step: 9
Training loss: 1.3550509214401245
Validation loss: 2.0888978640238443

Epoch: 6| Step: 10
Training loss: 1.8313008546829224
Validation loss: 2.0260048508644104

Epoch: 6| Step: 11
Training loss: 1.756668210029602
Validation loss: 2.067029297351837

Epoch: 6| Step: 12
Training loss: 1.4059706926345825
Validation loss: 2.0317023595174155

Epoch: 6| Step: 13
Training loss: 2.0831429958343506
Validation loss: 2.065056622028351

Epoch: 87| Step: 0
Training loss: 1.491045355796814
Validation loss: 2.043010632197062

Epoch: 6| Step: 1
Training loss: 1.9934773445129395
Validation loss: 2.042020301024119

Epoch: 6| Step: 2
Training loss: 2.2100026607513428
Validation loss: 2.063284436861674

Epoch: 6| Step: 3
Training loss: 1.8040742874145508
Validation loss: 2.0534719030062356

Epoch: 6| Step: 4
Training loss: 2.91325306892395
Validation loss: 2.0526274840037027

Epoch: 6| Step: 5
Training loss: 1.3230884075164795
Validation loss: 2.0341774423917136

Epoch: 6| Step: 6
Training loss: 1.454654335975647
Validation loss: 2.041328271230062

Epoch: 6| Step: 7
Training loss: 1.4819254875183105
Validation loss: 2.0461345116297402

Epoch: 6| Step: 8
Training loss: 1.3508247137069702
Validation loss: 2.059142212073008

Epoch: 6| Step: 9
Training loss: 1.4063324928283691
Validation loss: 2.0344538489977517

Epoch: 6| Step: 10
Training loss: 1.4318294525146484
Validation loss: 2.0363828341166177

Epoch: 6| Step: 11
Training loss: 2.2726917266845703
Validation loss: 2.077993094921112

Epoch: 6| Step: 12
Training loss: 1.3216503858566284
Validation loss: 2.051282544930776

Epoch: 6| Step: 13
Training loss: 1.4047179222106934
Validation loss: 2.0605000058809915

Epoch: 88| Step: 0
Training loss: 1.4298168420791626
Validation loss: 2.0602925022443137

Epoch: 6| Step: 1
Training loss: 2.468240976333618
Validation loss: 2.0358811815579734

Epoch: 6| Step: 2
Training loss: 1.4263288974761963
Validation loss: 2.048762838045756

Epoch: 6| Step: 3
Training loss: 1.4727461338043213
Validation loss: 2.0439860423405967

Epoch: 6| Step: 4
Training loss: 1.2598533630371094
Validation loss: 2.0330113569895425

Epoch: 6| Step: 5
Training loss: 1.348691463470459
Validation loss: 2.0546764135360718

Epoch: 6| Step: 6
Training loss: 1.9049381017684937
Validation loss: 2.0408742229143777

Epoch: 6| Step: 7
Training loss: 1.461103916168213
Validation loss: 2.0440503557523093

Epoch: 6| Step: 8
Training loss: 1.6751245260238647
Validation loss: 2.038874705632528

Epoch: 6| Step: 9
Training loss: 1.6874682903289795
Validation loss: 2.0466265281041465

Epoch: 6| Step: 10
Training loss: 1.144493579864502
Validation loss: 2.0747493902842202

Epoch: 6| Step: 11
Training loss: 1.7380238771438599
Validation loss: 2.0632668932278952

Epoch: 6| Step: 12
Training loss: 2.449026107788086
Validation loss: 2.098734219868978

Epoch: 6| Step: 13
Training loss: 1.6685649156570435
Validation loss: 2.098014493783315

Epoch: 89| Step: 0
Training loss: 1.4644471406936646
Validation loss: 2.123319407304128

Epoch: 6| Step: 1
Training loss: 1.5657461881637573
Validation loss: 2.1025922099749246

Epoch: 6| Step: 2
Training loss: 1.5495606660842896
Validation loss: 2.1214499870936074

Epoch: 6| Step: 3
Training loss: 1.3692854642868042
Validation loss: 2.122671206792196

Epoch: 6| Step: 4
Training loss: 1.2341341972351074
Validation loss: 2.0939119855562844

Epoch: 6| Step: 5
Training loss: 1.63221275806427
Validation loss: 2.1233606139818826

Epoch: 6| Step: 6
Training loss: 1.7666702270507812
Validation loss: 2.091255327065786

Epoch: 6| Step: 7
Training loss: 1.6917582750320435
Validation loss: 2.051276425520579

Epoch: 6| Step: 8
Training loss: 1.8716180324554443
Validation loss: 2.0411386688550315

Epoch: 6| Step: 9
Training loss: 1.621648907661438
Validation loss: 2.0693606535593667

Epoch: 6| Step: 10
Training loss: 1.6019999980926514
Validation loss: 2.062084714571635

Epoch: 6| Step: 11
Training loss: 2.043938398361206
Validation loss: 2.018251617749532

Epoch: 6| Step: 12
Training loss: 2.1787803173065186
Validation loss: 2.0486228863398233

Epoch: 6| Step: 13
Training loss: 1.9421488046646118
Validation loss: 2.046261787414551

Epoch: 90| Step: 0
Training loss: 1.4348654747009277
Validation loss: 2.036952018737793

Epoch: 6| Step: 1
Training loss: 2.011532783508301
Validation loss: 2.070220490296682

Epoch: 6| Step: 2
Training loss: 1.9593548774719238
Validation loss: 2.0338613589604697

Epoch: 6| Step: 3
Training loss: 1.732253074645996
Validation loss: 2.0494818886121116

Epoch: 6| Step: 4
Training loss: 1.4939086437225342
Validation loss: 2.0507129629453025

Epoch: 6| Step: 5
Training loss: 1.0858497619628906
Validation loss: 2.032752255598704

Epoch: 6| Step: 6
Training loss: 1.4859453439712524
Validation loss: 2.062446574370066

Epoch: 6| Step: 7
Training loss: 2.1259756088256836
Validation loss: 2.062723914782206

Epoch: 6| Step: 8
Training loss: 1.7294869422912598
Validation loss: 2.0448506474494934

Epoch: 6| Step: 9
Training loss: 1.5409663915634155
Validation loss: 2.06315549214681

Epoch: 6| Step: 10
Training loss: 1.387416958808899
Validation loss: 2.092228372891744

Epoch: 6| Step: 11
Training loss: 1.913702368736267
Validation loss: 2.1016032298405967

Epoch: 6| Step: 12
Training loss: 1.4134284257888794
Validation loss: 2.1593920985857644

Epoch: 6| Step: 13
Training loss: 2.0851290225982666
Validation loss: 2.1498214403788247

Epoch: 91| Step: 0
Training loss: 1.9473555088043213
Validation loss: 2.1302319169044495

Epoch: 6| Step: 1
Training loss: 1.4508726596832275
Validation loss: 2.1324878334999084

Epoch: 6| Step: 2
Training loss: 1.9311684370040894
Validation loss: 2.0867027044296265

Epoch: 6| Step: 3
Training loss: 1.1673754453659058
Validation loss: 2.0757731596628823

Epoch: 6| Step: 4
Training loss: 1.6065003871917725
Validation loss: 2.073923170566559

Epoch: 6| Step: 5
Training loss: 2.3224663734436035
Validation loss: 2.0736815333366394

Epoch: 6| Step: 6
Training loss: 1.7034375667572021
Validation loss: 2.0181842048962912

Epoch: 6| Step: 7
Training loss: 1.74747896194458
Validation loss: 2.052713374296824

Epoch: 6| Step: 8
Training loss: 1.7412084341049194
Validation loss: 2.0211137930552163

Epoch: 6| Step: 9
Training loss: 0.962727963924408
Validation loss: 2.015528678894043

Epoch: 6| Step: 10
Training loss: 1.8775290250778198
Validation loss: 2.030099550882975

Epoch: 6| Step: 11
Training loss: 1.8073620796203613
Validation loss: 2.0627281665802

Epoch: 6| Step: 12
Training loss: 1.5074976682662964
Validation loss: 2.0646073818206787

Epoch: 6| Step: 13
Training loss: 1.4188429117202759
Validation loss: 2.0728771487871804

Epoch: 92| Step: 0
Training loss: 1.4205760955810547
Validation loss: 2.051371157169342

Epoch: 6| Step: 1
Training loss: 1.2924374341964722
Validation loss: 2.0931442379951477

Epoch: 6| Step: 2
Training loss: 1.5029430389404297
Validation loss: 2.0955920815467834

Epoch: 6| Step: 3
Training loss: 2.009275436401367
Validation loss: 2.1077345808347068

Epoch: 6| Step: 4
Training loss: 1.678389310836792
Validation loss: 2.081536134084066

Epoch: 6| Step: 5
Training loss: 1.8168493509292603
Validation loss: 2.0875818133354187

Epoch: 6| Step: 6
Training loss: 1.7570786476135254
Validation loss: 2.0638742248217263

Epoch: 6| Step: 7
Training loss: 2.465186595916748
Validation loss: 2.1051307320594788

Epoch: 6| Step: 8
Training loss: 1.396807074546814
Validation loss: 2.0647850831349692

Epoch: 6| Step: 9
Training loss: 1.4238896369934082
Validation loss: 2.062908490498861

Epoch: 6| Step: 10
Training loss: 1.5323381423950195
Validation loss: 2.0408296386400857

Epoch: 6| Step: 11
Training loss: 1.4568358659744263
Validation loss: 2.064754843711853

Epoch: 6| Step: 12
Training loss: 1.8416798114776611
Validation loss: 2.0594135324160256

Epoch: 6| Step: 13
Training loss: 1.579111099243164
Validation loss: 2.0419227282206216

Epoch: 93| Step: 0
Training loss: 1.1536180973052979
Validation loss: 2.087000568707784

Epoch: 6| Step: 1
Training loss: 1.7526054382324219
Validation loss: 2.094595452149709

Epoch: 6| Step: 2
Training loss: 2.0616064071655273
Validation loss: 2.0652581652005515

Epoch: 6| Step: 3
Training loss: 1.7937819957733154
Validation loss: 2.0602963964144387

Epoch: 6| Step: 4
Training loss: 1.5619717836380005
Validation loss: 2.0923084815343223

Epoch: 6| Step: 5
Training loss: 1.3326876163482666
Validation loss: 2.070733149846395

Epoch: 6| Step: 6
Training loss: 1.6786836385726929
Validation loss: 2.0440542499224343

Epoch: 6| Step: 7
Training loss: 2.0390686988830566
Validation loss: 2.073384920756022

Epoch: 6| Step: 8
Training loss: 1.4707893133163452
Validation loss: 2.0681321024894714

Epoch: 6| Step: 9
Training loss: 2.2603297233581543
Validation loss: 2.0577169259389243

Epoch: 6| Step: 10
Training loss: 1.278854489326477
Validation loss: 2.0688325564066568

Epoch: 6| Step: 11
Training loss: 2.057612895965576
Validation loss: 2.0526990493138633

Epoch: 6| Step: 12
Training loss: 1.2294009923934937
Validation loss: 2.0606346130371094

Epoch: 6| Step: 13
Training loss: 1.1998008489608765
Validation loss: 2.0770005186398826

Epoch: 94| Step: 0
Training loss: 1.9276862144470215
Validation loss: 2.080777168273926

Epoch: 6| Step: 1
Training loss: 1.6270146369934082
Validation loss: 2.0958907206853232

Epoch: 6| Step: 2
Training loss: 1.5634644031524658
Validation loss: 2.0818025867144265

Epoch: 6| Step: 3
Training loss: 1.0532619953155518
Validation loss: 2.1185460488001504

Epoch: 6| Step: 4
Training loss: 1.3740402460098267
Validation loss: 2.122623940308889

Epoch: 6| Step: 5
Training loss: 2.325157403945923
Validation loss: 2.0901194413503013

Epoch: 6| Step: 6
Training loss: 1.2478495836257935
Validation loss: 2.1098016500473022

Epoch: 6| Step: 7
Training loss: 1.9258333444595337
Validation loss: 2.1157829562822976

Epoch: 6| Step: 8
Training loss: 1.6262526512145996
Validation loss: 2.0664920608202615

Epoch: 6| Step: 9
Training loss: 1.3503139019012451
Validation loss: 2.061638573805491

Epoch: 6| Step: 10
Training loss: 1.7168622016906738
Validation loss: 2.088232457637787

Epoch: 6| Step: 11
Training loss: 1.7911415100097656
Validation loss: 2.047730584939321

Epoch: 6| Step: 12
Training loss: 1.2353014945983887
Validation loss: 2.0467965602874756

Epoch: 6| Step: 13
Training loss: 1.9204561710357666
Validation loss: 2.049083630243937

Epoch: 95| Step: 0
Training loss: 1.4611847400665283
Validation loss: 2.076124608516693

Epoch: 6| Step: 1
Training loss: 1.916588306427002
Validation loss: 2.0532318154970803

Epoch: 6| Step: 2
Training loss: 1.344139814376831
Validation loss: 2.044475018978119

Epoch: 6| Step: 3
Training loss: 1.4587180614471436
Validation loss: 2.0505781968434653

Epoch: 6| Step: 4
Training loss: 1.3586753606796265
Validation loss: 2.0597712198893228

Epoch: 6| Step: 5
Training loss: 1.6527421474456787
Validation loss: 2.06772647301356

Epoch: 6| Step: 6
Training loss: 2.0466935634613037
Validation loss: 2.067737062772115

Epoch: 6| Step: 7
Training loss: 1.8145997524261475
Validation loss: 2.043110807736715

Epoch: 6| Step: 8
Training loss: 1.6934548616409302
Validation loss: 2.0738724867502847

Epoch: 6| Step: 9
Training loss: 1.6545395851135254
Validation loss: 2.1093060771624246

Epoch: 6| Step: 10
Training loss: 1.6044670343399048
Validation loss: 2.1104572415351868

Epoch: 6| Step: 11
Training loss: 1.965017557144165
Validation loss: 2.150729020436605

Epoch: 6| Step: 12
Training loss: 1.4299089908599854
Validation loss: 2.1418509682019553

Epoch: 6| Step: 13
Training loss: 1.829153299331665
Validation loss: 2.1311256289482117

Epoch: 96| Step: 0
Training loss: 1.0895452499389648
Validation loss: 2.1388716101646423

Epoch: 6| Step: 1
Training loss: 1.9286469221115112
Validation loss: 2.065526604652405

Epoch: 6| Step: 2
Training loss: 1.582250952720642
Validation loss: 2.0820826292037964

Epoch: 6| Step: 3
Training loss: 1.4051861763000488
Validation loss: 2.079697072505951

Epoch: 6| Step: 4
Training loss: 1.5019280910491943
Validation loss: 2.076578160127004

Epoch: 6| Step: 5
Training loss: 1.4462106227874756
Validation loss: 2.0410573879877725

Epoch: 6| Step: 6
Training loss: 1.6133036613464355
Validation loss: 2.0651681621869407

Epoch: 6| Step: 7
Training loss: 1.3699672222137451
Validation loss: 2.0414838790893555

Epoch: 6| Step: 8
Training loss: 2.200705051422119
Validation loss: 2.024613002936045

Epoch: 6| Step: 9
Training loss: 1.7696589231491089
Validation loss: 2.0610870520273843

Epoch: 6| Step: 10
Training loss: 1.6844422817230225
Validation loss: 2.028075178464254

Epoch: 6| Step: 11
Training loss: 2.40346097946167
Validation loss: 2.0381468733151755

Epoch: 6| Step: 12
Training loss: 1.7713236808776855
Validation loss: 2.0497727394104004

Epoch: 6| Step: 13
Training loss: 0.7964409589767456
Validation loss: 2.042267898718516

Epoch: 97| Step: 0
Training loss: 1.9717998504638672
Validation loss: 2.0416237314542136

Epoch: 6| Step: 1
Training loss: 1.3362007141113281
Validation loss: 2.096537192662557

Epoch: 6| Step: 2
Training loss: 1.3021819591522217
Validation loss: 2.0891378124554953

Epoch: 6| Step: 3
Training loss: 2.668304443359375
Validation loss: 2.10815038283666

Epoch: 6| Step: 4
Training loss: 1.6523828506469727
Validation loss: 2.113855759302775

Epoch: 6| Step: 5
Training loss: 1.531601905822754
Validation loss: 2.072182377179464

Epoch: 6| Step: 6
Training loss: 1.5072879791259766
Validation loss: 2.087174435456594

Epoch: 6| Step: 7
Training loss: 1.5713952779769897
Validation loss: 2.098883787790934

Epoch: 6| Step: 8
Training loss: 1.3655354976654053
Validation loss: 2.082211911678314

Epoch: 6| Step: 9
Training loss: 1.019227147102356
Validation loss: 2.0590693950653076

Epoch: 6| Step: 10
Training loss: 1.9748930931091309
Validation loss: 2.0444751977920532

Epoch: 6| Step: 11
Training loss: 1.5896458625793457
Validation loss: 2.0620481371879578

Epoch: 6| Step: 12
Training loss: 1.3156328201293945
Validation loss: 2.06283301115036

Epoch: 6| Step: 13
Training loss: 2.002072334289551
Validation loss: 2.058044135570526

Epoch: 98| Step: 0
Training loss: 1.5326060056686401
Validation loss: 2.0374232729276023

Epoch: 6| Step: 1
Training loss: 1.7280066013336182
Validation loss: 2.0795257290204368

Epoch: 6| Step: 2
Training loss: 1.4066098928451538
Validation loss: 2.066441377003988

Epoch: 6| Step: 3
Training loss: 1.6722419261932373
Validation loss: 2.059293289979299

Epoch: 6| Step: 4
Training loss: 1.0903609991073608
Validation loss: 2.0750715335210166

Epoch: 6| Step: 5
Training loss: 1.6716439723968506
Validation loss: 2.0614054600397744

Epoch: 6| Step: 6
Training loss: 1.7941761016845703
Validation loss: 2.069786528746287

Epoch: 6| Step: 7
Training loss: 1.7553462982177734
Validation loss: 2.061014552911123

Epoch: 6| Step: 8
Training loss: 1.2913110256195068
Validation loss: 2.0867857138315835

Epoch: 6| Step: 9
Training loss: 2.7930307388305664
Validation loss: 2.1057332158088684

Epoch: 6| Step: 10
Training loss: 1.6723381280899048
Validation loss: 2.1094762881596885

Epoch: 6| Step: 11
Training loss: 1.206181526184082
Validation loss: 2.131226142247518

Epoch: 6| Step: 12
Training loss: 1.2516326904296875
Validation loss: 2.101968069871267

Epoch: 6| Step: 13
Training loss: 1.2775685787200928
Validation loss: 2.1043951908747354

Epoch: 99| Step: 0
Training loss: 1.160451889038086
Validation loss: 2.084534307320913

Epoch: 6| Step: 1
Training loss: 1.470076560974121
Validation loss: 2.0352317293485007

Epoch: 6| Step: 2
Training loss: 1.7781262397766113
Validation loss: 2.083427647749583

Epoch: 6| Step: 3
Training loss: 1.5656273365020752
Validation loss: 2.0560073057810464

Epoch: 6| Step: 4
Training loss: 1.4539103507995605
Validation loss: 2.0835865338643393

Epoch: 6| Step: 5
Training loss: 1.6685436964035034
Validation loss: 2.1038349270820618

Epoch: 6| Step: 6
Training loss: 1.9416444301605225
Validation loss: 2.0611329674720764

Epoch: 6| Step: 7
Training loss: 2.195354700088501
Validation loss: 2.098254640897115

Epoch: 6| Step: 8
Training loss: 1.1491971015930176
Validation loss: 2.0800363620122275

Epoch: 6| Step: 9
Training loss: 1.526308536529541
Validation loss: 2.101036787033081

Epoch: 6| Step: 10
Training loss: 2.027297019958496
Validation loss: 2.100189963976542

Epoch: 6| Step: 11
Training loss: 1.7094494104385376
Validation loss: 2.081722835699717

Epoch: 6| Step: 12
Training loss: 1.6224366426467896
Validation loss: 2.115029275417328

Epoch: 6| Step: 13
Training loss: 1.0128569602966309
Validation loss: 2.1146979331970215

Epoch: 100| Step: 0
Training loss: 1.4414453506469727
Validation loss: 2.149354934692383

Epoch: 6| Step: 1
Training loss: 1.8522858619689941
Validation loss: 2.1571873227755227

Epoch: 6| Step: 2
Training loss: 1.7983574867248535
Validation loss: 2.152401248613993

Epoch: 6| Step: 3
Training loss: 1.552700400352478
Validation loss: 2.1430863539377847

Epoch: 6| Step: 4
Training loss: 1.4844892024993896
Validation loss: 2.1144238313039145

Epoch: 6| Step: 5
Training loss: 1.2167291641235352
Validation loss: 2.127864936987559

Epoch: 6| Step: 6
Training loss: 2.1939563751220703
Validation loss: 2.097115377585093

Epoch: 6| Step: 7
Training loss: 0.9281405806541443
Validation loss: 2.0839133858680725

Epoch: 6| Step: 8
Training loss: 1.2031723260879517
Validation loss: 2.0704784194628396

Epoch: 6| Step: 9
Training loss: 1.9539927244186401
Validation loss: 2.070973515510559

Epoch: 6| Step: 10
Training loss: 1.9466816186904907
Validation loss: 2.0742204984029136

Epoch: 6| Step: 11
Training loss: 1.3943872451782227
Validation loss: 2.083007514476776

Epoch: 6| Step: 12
Training loss: 1.590182900428772
Validation loss: 2.0616528391838074

Epoch: 6| Step: 13
Training loss: 2.015989065170288
Validation loss: 2.105686902999878

Epoch: 101| Step: 0
Training loss: 1.5807337760925293
Validation loss: 2.052497645219167

Epoch: 6| Step: 1
Training loss: 1.5664936304092407
Validation loss: 2.0582062403361

Epoch: 6| Step: 2
Training loss: 1.440443754196167
Validation loss: 2.030748983224233

Epoch: 6| Step: 3
Training loss: 1.969316005706787
Validation loss: 2.0925695101420083

Epoch: 6| Step: 4
Training loss: 1.5573198795318604
Validation loss: 2.0756511290868125

Epoch: 6| Step: 5
Training loss: 1.8593753576278687
Validation loss: 2.088739891846975

Epoch: 6| Step: 6
Training loss: 1.2421529293060303
Validation loss: 2.1053823033968606

Epoch: 6| Step: 7
Training loss: 1.4099854230880737
Validation loss: 2.098406950632731

Epoch: 6| Step: 8
Training loss: 1.1856565475463867
Validation loss: 2.1131007075309753

Epoch: 6| Step: 9
Training loss: 1.0965557098388672
Validation loss: 2.130861739317576

Epoch: 6| Step: 10
Training loss: 1.8495783805847168
Validation loss: 2.1306816140810647

Epoch: 6| Step: 11
Training loss: 2.138637065887451
Validation loss: 2.08057431379954

Epoch: 6| Step: 12
Training loss: 1.608690619468689
Validation loss: 2.0617515643437705

Epoch: 6| Step: 13
Training loss: 1.8862698078155518
Validation loss: 2.076309402783712

Epoch: 102| Step: 0
Training loss: 1.6339960098266602
Validation loss: 2.0615243315696716

Epoch: 6| Step: 1
Training loss: 1.8892426490783691
Validation loss: 2.0744481881459556

Epoch: 6| Step: 2
Training loss: 2.0417377948760986
Validation loss: 2.052486697832743

Epoch: 6| Step: 3
Training loss: 1.308997631072998
Validation loss: 2.0921960274378457

Epoch: 6| Step: 4
Training loss: 1.6257882118225098
Validation loss: 2.067033509413401

Epoch: 6| Step: 5
Training loss: 1.6874847412109375
Validation loss: 2.0411020119984946

Epoch: 6| Step: 6
Training loss: 1.9306797981262207
Validation loss: 2.051041225592295

Epoch: 6| Step: 7
Training loss: 1.489417552947998
Validation loss: 2.0586874882380166

Epoch: 6| Step: 8
Training loss: 1.5587023496627808
Validation loss: 2.1042691270510354

Epoch: 6| Step: 9
Training loss: 1.7880561351776123
Validation loss: 2.1033729116121926

Epoch: 6| Step: 10
Training loss: 1.3606528043746948
Validation loss: 2.1562299529711404

Epoch: 6| Step: 11
Training loss: 1.4107210636138916
Validation loss: 2.126281499862671

Epoch: 6| Step: 12
Training loss: 1.4266152381896973
Validation loss: 2.144664982954661

Epoch: 6| Step: 13
Training loss: 1.2784547805786133
Validation loss: 2.186185638109843

Epoch: 103| Step: 0
Training loss: 1.4935877323150635
Validation loss: 2.1179207960764566

Epoch: 6| Step: 1
Training loss: 1.2516107559204102
Validation loss: 2.142735699812571

Epoch: 6| Step: 2
Training loss: 1.4990997314453125
Validation loss: 2.092829704284668

Epoch: 6| Step: 3
Training loss: 1.4734470844268799
Validation loss: 2.0597875714302063

Epoch: 6| Step: 4
Training loss: 0.983538806438446
Validation loss: 2.048010230064392

Epoch: 6| Step: 5
Training loss: 1.6537230014801025
Validation loss: 2.0511556466420493

Epoch: 6| Step: 6
Training loss: 1.892674446105957
Validation loss: 2.071042239665985

Epoch: 6| Step: 7
Training loss: 1.3992280960083008
Validation loss: 2.0661874810854592

Epoch: 6| Step: 8
Training loss: 2.1460483074188232
Validation loss: 2.055612047513326

Epoch: 6| Step: 9
Training loss: 2.378420352935791
Validation loss: 2.0814652840296426

Epoch: 6| Step: 10
Training loss: 1.959939956665039
Validation loss: 2.041906197865804

Epoch: 6| Step: 11
Training loss: 1.4232439994812012
Validation loss: 2.0679509242375693

Epoch: 6| Step: 12
Training loss: 1.6881000995635986
Validation loss: 2.08138374487559

Epoch: 6| Step: 13
Training loss: 1.1993471384048462
Validation loss: 2.0992003679275513

Epoch: 104| Step: 0
Training loss: 1.3915982246398926
Validation loss: 2.103536903858185

Epoch: 6| Step: 1
Training loss: 1.3816068172454834
Validation loss: 2.1039183537165322

Epoch: 6| Step: 2
Training loss: 2.2656874656677246
Validation loss: 2.117511252562205

Epoch: 6| Step: 3
Training loss: 1.542563557624817
Validation loss: 2.0870408415794373

Epoch: 6| Step: 4
Training loss: 1.441248893737793
Validation loss: 2.1082125902175903

Epoch: 6| Step: 5
Training loss: 1.595790147781372
Validation loss: 2.1184469064076743

Epoch: 6| Step: 6
Training loss: 1.8856290578842163
Validation loss: 2.1027878522872925

Epoch: 6| Step: 7
Training loss: 1.8407995700836182
Validation loss: 2.077826221783956

Epoch: 6| Step: 8
Training loss: 1.8165208101272583
Validation loss: 2.084605018297831

Epoch: 6| Step: 9
Training loss: 1.8275569677352905
Validation loss: 2.095461289087931

Epoch: 6| Step: 10
Training loss: 1.233347773551941
Validation loss: 2.0269590417544046

Epoch: 6| Step: 11
Training loss: 1.0604469776153564
Validation loss: 2.0826934576034546

Epoch: 6| Step: 12
Training loss: 1.4144619703292847
Validation loss: 2.082658807436625

Epoch: 6| Step: 13
Training loss: 0.9054730534553528
Validation loss: 2.072621683279673

Epoch: 105| Step: 0
Training loss: 1.3367210626602173
Validation loss: 2.0665770371754966

Epoch: 6| Step: 1
Training loss: 1.6708381175994873
Validation loss: 2.1107780933380127

Epoch: 6| Step: 2
Training loss: 1.8446578979492188
Validation loss: 2.071957051753998

Epoch: 6| Step: 3
Training loss: 1.9251477718353271
Validation loss: 2.0872368017832437

Epoch: 6| Step: 4
Training loss: 1.3605217933654785
Validation loss: 2.081165055433909

Epoch: 6| Step: 5
Training loss: 1.3454004526138306
Validation loss: 2.137644668420156

Epoch: 6| Step: 6
Training loss: 1.0251390933990479
Validation loss: 2.132879137992859

Epoch: 6| Step: 7
Training loss: 2.102077007293701
Validation loss: 2.092660824457804

Epoch: 6| Step: 8
Training loss: 1.400399923324585
Validation loss: 2.095691760381063

Epoch: 6| Step: 9
Training loss: 1.4272353649139404
Validation loss: 2.0634523232777915

Epoch: 6| Step: 10
Training loss: 1.6625022888183594
Validation loss: 2.1110425194104514

Epoch: 6| Step: 11
Training loss: 1.5345134735107422
Validation loss: 2.0862170457839966

Epoch: 6| Step: 12
Training loss: 1.472065806388855
Validation loss: 2.0769707759221396

Epoch: 6| Step: 13
Training loss: 1.3353030681610107
Validation loss: 2.067417641480764

Epoch: 106| Step: 0
Training loss: 0.8911454677581787
Validation loss: 2.065677841504415

Epoch: 6| Step: 1
Training loss: 0.9958351850509644
Validation loss: 2.071277836958567

Epoch: 6| Step: 2
Training loss: 0.8778513073921204
Validation loss: 2.0857255856196084

Epoch: 6| Step: 3
Training loss: 1.4527883529663086
Validation loss: 2.063146432240804

Epoch: 6| Step: 4
Training loss: 1.3495328426361084
Validation loss: 2.0961801608403525

Epoch: 6| Step: 5
Training loss: 1.6547611951828003
Validation loss: 2.132968227068583

Epoch: 6| Step: 6
Training loss: 2.1457557678222656
Validation loss: 2.0919795433680215

Epoch: 6| Step: 7
Training loss: 1.4914636611938477
Validation loss: 2.1084367632865906

Epoch: 6| Step: 8
Training loss: 1.8697550296783447
Validation loss: 2.0832966764767966

Epoch: 6| Step: 9
Training loss: 1.468407392501831
Validation loss: 2.0384592016537986

Epoch: 6| Step: 10
Training loss: 2.0217559337615967
Validation loss: 2.0573366284370422

Epoch: 6| Step: 11
Training loss: 1.559434413909912
Validation loss: 2.0758971571922302

Epoch: 6| Step: 12
Training loss: 2.1164064407348633
Validation loss: 2.0765342911084494

Epoch: 6| Step: 13
Training loss: 1.6768414974212646
Validation loss: 2.045197347799937

Epoch: 107| Step: 0
Training loss: 1.4241403341293335
Validation loss: 2.0793453057607016

Epoch: 6| Step: 1
Training loss: 1.3921910524368286
Validation loss: 2.066668609778086

Epoch: 6| Step: 2
Training loss: 2.0020840167999268
Validation loss: 2.091537654399872

Epoch: 6| Step: 3
Training loss: 1.5345168113708496
Validation loss: 2.0895334482192993

Epoch: 6| Step: 4
Training loss: 1.4440600872039795
Validation loss: 2.08137180407842

Epoch: 6| Step: 5
Training loss: 1.1639823913574219
Validation loss: 2.0792675216992698

Epoch: 6| Step: 6
Training loss: 0.9806475639343262
Validation loss: 2.090894023577372

Epoch: 6| Step: 7
Training loss: 1.3024224042892456
Validation loss: 2.0711028774579368

Epoch: 6| Step: 8
Training loss: 1.4684350490570068
Validation loss: 2.0932530562082925

Epoch: 6| Step: 9
Training loss: 1.5489771366119385
Validation loss: 2.1043803691864014

Epoch: 6| Step: 10
Training loss: 1.818251371383667
Validation loss: 2.0427791674931846

Epoch: 6| Step: 11
Training loss: 1.6114180088043213
Validation loss: 2.047626256942749

Epoch: 6| Step: 12
Training loss: 1.6266188621520996
Validation loss: 2.074862023194631

Epoch: 6| Step: 13
Training loss: 2.055814266204834
Validation loss: 2.062116046746572

Epoch: 108| Step: 0
Training loss: 1.3028773069381714
Validation loss: 2.06034650405248

Epoch: 6| Step: 1
Training loss: 1.602421522140503
Validation loss: 2.10012157758077

Epoch: 6| Step: 2
Training loss: 1.0515820980072021
Validation loss: 2.0821788708368936

Epoch: 6| Step: 3
Training loss: 1.4188882112503052
Validation loss: 2.0958943168322244

Epoch: 6| Step: 4
Training loss: 1.0947339534759521
Validation loss: 2.151382863521576

Epoch: 6| Step: 5
Training loss: 1.5008091926574707
Validation loss: 2.1146939595540366

Epoch: 6| Step: 6
Training loss: 1.5096931457519531
Validation loss: 2.1132928133010864

Epoch: 6| Step: 7
Training loss: 1.7076400518417358
Validation loss: 2.1041141152381897

Epoch: 6| Step: 8
Training loss: 1.5596257448196411
Validation loss: 2.114633480707804

Epoch: 6| Step: 9
Training loss: 1.890176773071289
Validation loss: 2.0841607252756753

Epoch: 6| Step: 10
Training loss: 0.8805233240127563
Validation loss: 2.0893120169639587

Epoch: 6| Step: 11
Training loss: 1.3686494827270508
Validation loss: 2.0884790817896524

Epoch: 6| Step: 12
Training loss: 1.118157982826233
Validation loss: 2.0558632413546243

Epoch: 6| Step: 13
Training loss: 3.065418243408203
Validation loss: 2.0826285680135093

Epoch: 109| Step: 0
Training loss: 1.7300702333450317
Validation loss: 2.0854247411092124

Epoch: 6| Step: 1
Training loss: 1.7519798278808594
Validation loss: 2.096424639225006

Epoch: 6| Step: 2
Training loss: 1.160490870475769
Validation loss: 2.0823240081469216

Epoch: 6| Step: 3
Training loss: 1.5671459436416626
Validation loss: 2.0636386473973594

Epoch: 6| Step: 4
Training loss: 1.1717764139175415
Validation loss: 2.0287306706110635

Epoch: 6| Step: 5
Training loss: 1.8422337770462036
Validation loss: 2.092454671859741

Epoch: 6| Step: 6
Training loss: 1.7381763458251953
Validation loss: 2.0965530276298523

Epoch: 6| Step: 7
Training loss: 1.2638965845108032
Validation loss: 2.1373429894447327

Epoch: 6| Step: 8
Training loss: 1.6508454084396362
Validation loss: 2.137428422768911

Epoch: 6| Step: 9
Training loss: 1.6848069429397583
Validation loss: 2.1175939440727234

Epoch: 6| Step: 10
Training loss: 0.9759225845336914
Validation loss: 2.087656339009603

Epoch: 6| Step: 11
Training loss: 1.2685496807098389
Validation loss: 2.1118611693382263

Epoch: 6| Step: 12
Training loss: 1.754399061203003
Validation loss: 2.0829949577649436

Epoch: 6| Step: 13
Training loss: 2.0099878311157227
Validation loss: 2.109965741634369

Epoch: 110| Step: 0
Training loss: 0.9050960540771484
Validation loss: 2.123569051424662

Epoch: 6| Step: 1
Training loss: 1.327565312385559
Validation loss: 2.0926923553148904

Epoch: 6| Step: 2
Training loss: 1.4264341592788696
Validation loss: 2.083134571711222

Epoch: 6| Step: 3
Training loss: 1.9103174209594727
Validation loss: 2.066564361254374

Epoch: 6| Step: 4
Training loss: 1.1819658279418945
Validation loss: 2.054612457752228

Epoch: 6| Step: 5
Training loss: 0.7545444369316101
Validation loss: 2.050112803777059

Epoch: 6| Step: 6
Training loss: 1.9255865812301636
Validation loss: 2.063299516836802

Epoch: 6| Step: 7
Training loss: 1.334930419921875
Validation loss: 2.078615446885427

Epoch: 6| Step: 8
Training loss: 1.7037583589553833
Validation loss: 2.085600952307383

Epoch: 6| Step: 9
Training loss: 1.0064802169799805
Validation loss: 2.1299830277760825

Epoch: 6| Step: 10
Training loss: 1.2976939678192139
Validation loss: 2.0850531657536826

Epoch: 6| Step: 11
Training loss: 1.2578752040863037
Validation loss: 2.0972736477851868

Epoch: 6| Step: 12
Training loss: 2.3708291053771973
Validation loss: 2.093807260195414

Epoch: 6| Step: 13
Training loss: 2.122276544570923
Validation loss: 2.0746302604675293

Epoch: 111| Step: 0
Training loss: 1.240382194519043
Validation loss: 2.095774749914805

Epoch: 6| Step: 1
Training loss: 1.790886402130127
Validation loss: 2.0674654841423035

Epoch: 6| Step: 2
Training loss: 1.7780351638793945
Validation loss: 2.0649494528770447

Epoch: 6| Step: 3
Training loss: 0.8884558081626892
Validation loss: 2.09101672967275

Epoch: 6| Step: 4
Training loss: 1.104055404663086
Validation loss: 2.0894566774368286

Epoch: 6| Step: 5
Training loss: 1.5776959657669067
Validation loss: 2.114312986532847

Epoch: 6| Step: 6
Training loss: 1.674649953842163
Validation loss: 2.056453208128611

Epoch: 6| Step: 7
Training loss: 1.6866302490234375
Validation loss: 2.086399793624878

Epoch: 6| Step: 8
Training loss: 1.7795683145523071
Validation loss: 2.068477431933085

Epoch: 6| Step: 9
Training loss: 1.4595177173614502
Validation loss: 2.1025260289510093

Epoch: 6| Step: 10
Training loss: 1.7664493322372437
Validation loss: 2.0789227286974588

Epoch: 6| Step: 11
Training loss: 1.1350817680358887
Validation loss: 2.0328029791514077

Epoch: 6| Step: 12
Training loss: 1.4576231241226196
Validation loss: 2.078850249449412

Epoch: 6| Step: 13
Training loss: 1.2735522985458374
Validation loss: 2.0718599955240884

Epoch: 112| Step: 0
Training loss: 1.2725526094436646
Validation loss: 2.08674289782842

Epoch: 6| Step: 1
Training loss: 1.6767470836639404
Validation loss: 2.0454620122909546

Epoch: 6| Step: 2
Training loss: 1.266552448272705
Validation loss: 2.0827576915423074

Epoch: 6| Step: 3
Training loss: 1.7602696418762207
Validation loss: 2.0515928069750466

Epoch: 6| Step: 4
Training loss: 1.3922004699707031
Validation loss: 2.0535950660705566

Epoch: 6| Step: 5
Training loss: 0.8248922824859619
Validation loss: 2.0861933827400208

Epoch: 6| Step: 6
Training loss: 1.7132279872894287
Validation loss: 2.0648246010144553

Epoch: 6| Step: 7
Training loss: 0.9633429050445557
Validation loss: 2.0541222294171653

Epoch: 6| Step: 8
Training loss: 2.377915859222412
Validation loss: 2.050107220808665

Epoch: 6| Step: 9
Training loss: 1.516954779624939
Validation loss: 2.1005340019861856

Epoch: 6| Step: 10
Training loss: 1.5413918495178223
Validation loss: 2.0739808877309165

Epoch: 6| Step: 11
Training loss: 1.4371428489685059
Validation loss: 2.080615679423014

Epoch: 6| Step: 12
Training loss: 1.345055103302002
Validation loss: 2.0638503432273865

Epoch: 6| Step: 13
Training loss: 1.4681427478790283
Validation loss: 2.088536183039347

Epoch: 113| Step: 0
Training loss: 1.459146499633789
Validation loss: 2.0631389021873474

Epoch: 6| Step: 1
Training loss: 1.0036031007766724
Validation loss: 2.061847686767578

Epoch: 6| Step: 2
Training loss: 1.7450913190841675
Validation loss: 2.032764275868734

Epoch: 6| Step: 3
Training loss: 1.7655184268951416
Validation loss: 2.1108866135279336

Epoch: 6| Step: 4
Training loss: 1.3684983253479004
Validation loss: 2.063310662905375

Epoch: 6| Step: 5
Training loss: 0.9780837893486023
Validation loss: 2.1157243649164834

Epoch: 6| Step: 6
Training loss: 1.2046871185302734
Validation loss: 2.1088502208391824

Epoch: 6| Step: 7
Training loss: 1.615755319595337
Validation loss: 2.0675007700920105

Epoch: 6| Step: 8
Training loss: 1.0119712352752686
Validation loss: 2.076216181119283

Epoch: 6| Step: 9
Training loss: 1.8123654127120972
Validation loss: 2.1060195366541543

Epoch: 6| Step: 10
Training loss: 2.4223201274871826
Validation loss: 2.072170893351237

Epoch: 6| Step: 11
Training loss: 0.9861539006233215
Validation loss: 2.122474948565165

Epoch: 6| Step: 12
Training loss: 1.4071458578109741
Validation loss: 2.071654121081034

Epoch: 6| Step: 13
Training loss: 1.4229142665863037
Validation loss: 2.0846126278241477

Epoch: 114| Step: 0
Training loss: 1.3407588005065918
Validation loss: 2.1154040694236755

Epoch: 6| Step: 1
Training loss: 1.4101488590240479
Validation loss: 2.1392807960510254

Epoch: 6| Step: 2
Training loss: 1.3180501461029053
Validation loss: 2.116826911767324

Epoch: 6| Step: 3
Training loss: 1.2990895509719849
Validation loss: 2.0743797620137534

Epoch: 6| Step: 4
Training loss: 1.5467169284820557
Validation loss: 2.132468104362488

Epoch: 6| Step: 5
Training loss: 1.0836418867111206
Validation loss: 2.058724284172058

Epoch: 6| Step: 6
Training loss: 1.7953777313232422
Validation loss: 2.0875824292500815

Epoch: 6| Step: 7
Training loss: 1.643898606300354
Validation loss: 2.093138098716736

Epoch: 6| Step: 8
Training loss: 1.6008812189102173
Validation loss: 2.051645298798879

Epoch: 6| Step: 9
Training loss: 1.5928874015808105
Validation loss: 2.0720725456873574

Epoch: 6| Step: 10
Training loss: 0.9172289371490479
Validation loss: 2.0885499517122903

Epoch: 6| Step: 11
Training loss: 0.8642001152038574
Validation loss: 2.0754751364390054

Epoch: 6| Step: 12
Training loss: 1.6211981773376465
Validation loss: 2.083648145198822

Epoch: 6| Step: 13
Training loss: 2.0360724925994873
Validation loss: 2.137444853782654

Epoch: 115| Step: 0
Training loss: 1.597480058670044
Validation loss: 2.056656221548716

Epoch: 6| Step: 1
Training loss: 0.9705935716629028
Validation loss: 2.089842061201731

Epoch: 6| Step: 2
Training loss: 1.227499008178711
Validation loss: 2.133163551489512

Epoch: 6| Step: 3
Training loss: 1.0921385288238525
Validation loss: 2.118593434492747

Epoch: 6| Step: 4
Training loss: 1.1741706132888794
Validation loss: 2.1018505692481995

Epoch: 6| Step: 5
Training loss: 1.315044641494751
Validation loss: 2.075786550839742

Epoch: 6| Step: 6
Training loss: 1.703101396560669
Validation loss: 2.0927964647610984

Epoch: 6| Step: 7
Training loss: 1.7808548212051392
Validation loss: 2.081974824269613

Epoch: 6| Step: 8
Training loss: 1.1281465291976929
Validation loss: 2.0857120354970298

Epoch: 6| Step: 9
Training loss: 1.6105101108551025
Validation loss: 2.0391101042429605

Epoch: 6| Step: 10
Training loss: 1.3754141330718994
Validation loss: 2.0614261428515115

Epoch: 6| Step: 11
Training loss: 2.299929618835449
Validation loss: 2.069498042265574

Epoch: 6| Step: 12
Training loss: 1.7307519912719727
Validation loss: 2.1178531845410666

Epoch: 6| Step: 13
Training loss: 1.1773828268051147
Validation loss: 2.1311394373575845

Epoch: 116| Step: 0
Training loss: 0.8982426524162292
Validation loss: 2.113307019074758

Epoch: 6| Step: 1
Training loss: 1.7663209438323975
Validation loss: 2.1027650038401284

Epoch: 6| Step: 2
Training loss: 1.1329470872879028
Validation loss: 2.1223463813463845

Epoch: 6| Step: 3
Training loss: 1.098318338394165
Validation loss: 2.063276469707489

Epoch: 6| Step: 4
Training loss: 1.424482822418213
Validation loss: 2.1004636685053506

Epoch: 6| Step: 5
Training loss: 1.2863318920135498
Validation loss: 2.127050757408142

Epoch: 6| Step: 6
Training loss: 1.244214415550232
Validation loss: 2.126325249671936

Epoch: 6| Step: 7
Training loss: 1.6811161041259766
Validation loss: 2.123558680216471

Epoch: 6| Step: 8
Training loss: 1.2608447074890137
Validation loss: 2.1190120379130044

Epoch: 6| Step: 9
Training loss: 1.7703404426574707
Validation loss: 2.1055671771367392

Epoch: 6| Step: 10
Training loss: 1.335017442703247
Validation loss: 2.054301460584005

Epoch: 6| Step: 11
Training loss: 1.454127311706543
Validation loss: 2.0472243229548135

Epoch: 6| Step: 12
Training loss: 1.7869011163711548
Validation loss: 2.0752479235331216

Epoch: 6| Step: 13
Training loss: 1.7306171655654907
Validation loss: 2.065103511015574

Epoch: 117| Step: 0
Training loss: 1.6852881908416748
Validation loss: 2.0697361628214517

Epoch: 6| Step: 1
Training loss: 1.108360767364502
Validation loss: 2.0853466788927713

Epoch: 6| Step: 2
Training loss: 1.3727476596832275
Validation loss: 2.033494234085083

Epoch: 6| Step: 3
Training loss: 1.752740740776062
Validation loss: 2.11131622393926

Epoch: 6| Step: 4
Training loss: 1.5809842348098755
Validation loss: 2.059415558973948

Epoch: 6| Step: 5
Training loss: 0.9406330585479736
Validation loss: 2.1337499419848123

Epoch: 6| Step: 6
Training loss: 1.1650575399398804
Validation loss: 2.112872898578644

Epoch: 6| Step: 7
Training loss: 1.5241544246673584
Validation loss: 2.110087196032206

Epoch: 6| Step: 8
Training loss: 1.962220311164856
Validation loss: 2.084043323993683

Epoch: 6| Step: 9
Training loss: 1.183600902557373
Validation loss: 2.1349442998568215

Epoch: 6| Step: 10
Training loss: 1.3100039958953857
Validation loss: 2.1196709275245667

Epoch: 6| Step: 11
Training loss: 1.0592072010040283
Validation loss: 2.1000287930170694

Epoch: 6| Step: 12
Training loss: 1.6446559429168701
Validation loss: 2.1177587509155273

Epoch: 6| Step: 13
Training loss: 1.3114542961120605
Validation loss: 2.109452227751414

Epoch: 118| Step: 0
Training loss: 0.9103078842163086
Validation loss: 2.083099921544393

Epoch: 6| Step: 1
Training loss: 1.4736011028289795
Validation loss: 2.1173951625823975

Epoch: 6| Step: 2
Training loss: 1.2648615837097168
Validation loss: 2.0907488465309143

Epoch: 6| Step: 3
Training loss: 1.2828649282455444
Validation loss: 2.09309720993042

Epoch: 6| Step: 4
Training loss: 1.161577582359314
Validation loss: 2.0774627129236856

Epoch: 6| Step: 5
Training loss: 1.5711065530776978
Validation loss: 2.0832176009813943

Epoch: 6| Step: 6
Training loss: 1.4789085388183594
Validation loss: 2.081327438354492

Epoch: 6| Step: 7
Training loss: 1.2994844913482666
Validation loss: 2.0561949014663696

Epoch: 6| Step: 8
Training loss: 1.9353187084197998
Validation loss: 2.0970112880071006

Epoch: 6| Step: 9
Training loss: 1.6649649143218994
Validation loss: 2.136244237422943

Epoch: 6| Step: 10
Training loss: 1.3752214908599854
Validation loss: 2.1522521376609802

Epoch: 6| Step: 11
Training loss: 1.466725468635559
Validation loss: 2.0880921681722007

Epoch: 6| Step: 12
Training loss: 1.271449327468872
Validation loss: 2.113450547059377

Epoch: 6| Step: 13
Training loss: 1.4664872884750366
Validation loss: 2.130934158960978

Epoch: 119| Step: 0
Training loss: 1.5850685834884644
Validation loss: 2.080904245376587

Epoch: 6| Step: 1
Training loss: 1.5422630310058594
Validation loss: 2.117910365263621

Epoch: 6| Step: 2
Training loss: 1.5045942068099976
Validation loss: 2.1049485405286155

Epoch: 6| Step: 3
Training loss: 1.478032112121582
Validation loss: 2.0519205927848816

Epoch: 6| Step: 4
Training loss: 1.4058549404144287
Validation loss: 2.1192835569381714

Epoch: 6| Step: 5
Training loss: 1.2700729370117188
Validation loss: 2.068357507387797

Epoch: 6| Step: 6
Training loss: 0.7364615201950073
Validation loss: 2.1120419104894004

Epoch: 6| Step: 7
Training loss: 1.3681334257125854
Validation loss: 2.0998463233311973

Epoch: 6| Step: 8
Training loss: 1.295413613319397
Validation loss: 2.0978141029675803

Epoch: 6| Step: 9
Training loss: 1.3320536613464355
Validation loss: 2.1079001228014627

Epoch: 6| Step: 10
Training loss: 2.3893380165100098
Validation loss: 2.1246452927589417

Epoch: 6| Step: 11
Training loss: 1.582643985748291
Validation loss: 2.129675249258677

Epoch: 6| Step: 12
Training loss: 1.8499774932861328
Validation loss: 2.0842055678367615

Epoch: 6| Step: 13
Training loss: 0.8847253918647766
Validation loss: 2.1090080539385476

Epoch: 120| Step: 0
Training loss: 1.5707380771636963
Validation loss: 2.095745583375295

Epoch: 6| Step: 1
Training loss: 1.777318000793457
Validation loss: 2.069177210330963

Epoch: 6| Step: 2
Training loss: 1.400687575340271
Validation loss: 2.055515686670939

Epoch: 6| Step: 3
Training loss: 1.3996039628982544
Validation loss: 2.128800908724467

Epoch: 6| Step: 4
Training loss: 1.52733314037323
Validation loss: 2.104284644126892

Epoch: 6| Step: 5
Training loss: 1.0958292484283447
Validation loss: 2.1133042176564536

Epoch: 6| Step: 6
Training loss: 1.4914119243621826
Validation loss: 2.0730579694112143

Epoch: 6| Step: 7
Training loss: 1.3087095022201538
Validation loss: 2.086150050163269

Epoch: 6| Step: 8
Training loss: 1.51743483543396
Validation loss: 2.102469325065613

Epoch: 6| Step: 9
Training loss: 1.1828124523162842
Validation loss: 2.0888404051462808

Epoch: 6| Step: 10
Training loss: 1.2088217735290527
Validation loss: 2.0842907428741455

Epoch: 6| Step: 11
Training loss: 1.179776668548584
Validation loss: 2.103868325551351

Epoch: 6| Step: 12
Training loss: 1.7133538722991943
Validation loss: 2.100918432076772

Epoch: 6| Step: 13
Training loss: 1.1216106414794922
Validation loss: 2.0787085692087808

Epoch: 121| Step: 0
Training loss: 1.3536460399627686
Validation loss: 2.111045559247335

Epoch: 6| Step: 1
Training loss: 1.143239974975586
Validation loss: 2.0843423207600913

Epoch: 6| Step: 2
Training loss: 1.720585823059082
Validation loss: 2.109653949737549

Epoch: 6| Step: 3
Training loss: 1.100359320640564
Validation loss: 2.115215261777242

Epoch: 6| Step: 4
Training loss: 0.9158714413642883
Validation loss: 2.107760568459829

Epoch: 6| Step: 5
Training loss: 1.6621448993682861
Validation loss: 2.0907950401306152

Epoch: 6| Step: 6
Training loss: 1.7730450630187988
Validation loss: 2.0541613698005676

Epoch: 6| Step: 7
Training loss: 1.6498942375183105
Validation loss: 2.0569456418355307

Epoch: 6| Step: 8
Training loss: 1.2501813173294067
Validation loss: 2.053726057211558

Epoch: 6| Step: 9
Training loss: 1.3354835510253906
Validation loss: 2.059457838535309

Epoch: 6| Step: 10
Training loss: 1.2713788747787476
Validation loss: 2.065053860346476

Epoch: 6| Step: 11
Training loss: 1.1452146768569946
Validation loss: 2.0758848190307617

Epoch: 6| Step: 12
Training loss: 1.400710940361023
Validation loss: 2.1024688482284546

Epoch: 6| Step: 13
Training loss: 1.3383283615112305
Validation loss: 2.133563061555227

Epoch: 122| Step: 0
Training loss: 1.3524079322814941
Validation loss: 2.1007258693377175

Epoch: 6| Step: 1
Training loss: 1.5986976623535156
Validation loss: 2.140727957089742

Epoch: 6| Step: 2
Training loss: 1.492008924484253
Validation loss: 2.0916018883387246

Epoch: 6| Step: 3
Training loss: 1.4612572193145752
Validation loss: 2.089758316675822

Epoch: 6| Step: 4
Training loss: 1.2061567306518555
Validation loss: 2.0842336614926658

Epoch: 6| Step: 5
Training loss: 1.388642430305481
Validation loss: 2.081214507420858

Epoch: 6| Step: 6
Training loss: 1.4513015747070312
Validation loss: 2.056816359361013

Epoch: 6| Step: 7
Training loss: 0.9791828989982605
Validation loss: 2.09187642733256

Epoch: 6| Step: 8
Training loss: 2.028625965118408
Validation loss: 2.0983986457188926

Epoch: 6| Step: 9
Training loss: 1.4028340578079224
Validation loss: 2.089124321937561

Epoch: 6| Step: 10
Training loss: 1.3835127353668213
Validation loss: 2.082616448402405

Epoch: 6| Step: 11
Training loss: 1.4410516023635864
Validation loss: 2.0538129409154258

Epoch: 6| Step: 12
Training loss: 1.3778183460235596
Validation loss: 2.0735859274864197

Epoch: 6| Step: 13
Training loss: 0.9715599417686462
Validation loss: 2.1013417641321817

Epoch: 123| Step: 0
Training loss: 0.9663487672805786
Validation loss: 2.1389483412106833

Epoch: 6| Step: 1
Training loss: 1.3876404762268066
Validation loss: 2.1253842314084372

Epoch: 6| Step: 2
Training loss: 1.375071406364441
Validation loss: 2.136264979839325

Epoch: 6| Step: 3
Training loss: 0.8660778999328613
Validation loss: 2.1141722202301025

Epoch: 6| Step: 4
Training loss: 1.2960789203643799
Validation loss: 2.0667397379875183

Epoch: 6| Step: 5
Training loss: 0.9528331160545349
Validation loss: 2.1076536774635315

Epoch: 6| Step: 6
Training loss: 1.630333662033081
Validation loss: 2.078500747680664

Epoch: 6| Step: 7
Training loss: 1.761930227279663
Validation loss: 2.096748491128286

Epoch: 6| Step: 8
Training loss: 1.8917946815490723
Validation loss: 2.1015594402949014

Epoch: 6| Step: 9
Training loss: 1.1711093187332153
Validation loss: 2.1180802385012307

Epoch: 6| Step: 10
Training loss: 1.1809113025665283
Validation loss: 2.0566075642903647

Epoch: 6| Step: 11
Training loss: 1.9668833017349243
Validation loss: 2.0884422262509665

Epoch: 6| Step: 12
Training loss: 1.7721924781799316
Validation loss: 2.0916702349980674

Epoch: 6| Step: 13
Training loss: 1.6088660955429077
Validation loss: 2.0884220202763877

Epoch: 124| Step: 0
Training loss: 1.1078639030456543
Validation loss: 2.1351651350657144

Epoch: 6| Step: 1
Training loss: 1.267104148864746
Validation loss: 2.098509152730306

Epoch: 6| Step: 2
Training loss: 1.2175750732421875
Validation loss: 2.112165153026581

Epoch: 6| Step: 3
Training loss: 1.1566908359527588
Validation loss: 2.097132941087087

Epoch: 6| Step: 4
Training loss: 1.1037623882293701
Validation loss: 2.168711225191752

Epoch: 6| Step: 5
Training loss: 1.6226716041564941
Validation loss: 2.0736011266708374

Epoch: 6| Step: 6
Training loss: 1.2002053260803223
Validation loss: 2.1282613476117453

Epoch: 6| Step: 7
Training loss: 1.7101019620895386
Validation loss: 2.0786148508389792

Epoch: 6| Step: 8
Training loss: 1.5117461681365967
Validation loss: 2.0714458227157593

Epoch: 6| Step: 9
Training loss: 0.9843509793281555
Validation loss: 2.0565332770347595

Epoch: 6| Step: 10
Training loss: 1.3469563722610474
Validation loss: 2.0701732834180198

Epoch: 6| Step: 11
Training loss: 1.3644766807556152
Validation loss: 2.0865493615468345

Epoch: 6| Step: 12
Training loss: 1.6119029521942139
Validation loss: 2.091055671374003

Epoch: 6| Step: 13
Training loss: 1.788649082183838
Validation loss: 2.09934930006663

Epoch: 125| Step: 0
Training loss: 0.9560011625289917
Validation loss: 2.078695515791575

Epoch: 6| Step: 1
Training loss: 1.2995247840881348
Validation loss: 2.080730398495992

Epoch: 6| Step: 2
Training loss: 1.7466243505477905
Validation loss: 2.1258620023727417

Epoch: 6| Step: 3
Training loss: 1.080383062362671
Validation loss: 2.1299109856287637

Epoch: 6| Step: 4
Training loss: 1.8948417901992798
Validation loss: 2.090475102265676

Epoch: 6| Step: 5
Training loss: 1.1783268451690674
Validation loss: 2.154431184132894

Epoch: 6| Step: 6
Training loss: 1.0537774562835693
Validation loss: 2.0613319476445517

Epoch: 6| Step: 7
Training loss: 1.0499706268310547
Validation loss: 2.077522615591685

Epoch: 6| Step: 8
Training loss: 1.2397434711456299
Validation loss: 2.1137393514315286

Epoch: 6| Step: 9
Training loss: 1.1538162231445312
Validation loss: 2.0685748060544333

Epoch: 6| Step: 10
Training loss: 1.8318657875061035
Validation loss: 2.071338951587677

Epoch: 6| Step: 11
Training loss: 1.5154433250427246
Validation loss: 2.050037145614624

Epoch: 6| Step: 12
Training loss: 1.4433245658874512
Validation loss: 2.069280445575714

Epoch: 6| Step: 13
Training loss: 1.2443634271621704
Validation loss: 2.101941784222921

Epoch: 126| Step: 0
Training loss: 1.0863853693008423
Validation loss: 2.10526837905248

Epoch: 6| Step: 1
Training loss: 1.3190162181854248
Validation loss: 2.121950407822927

Epoch: 6| Step: 2
Training loss: 1.1653226613998413
Validation loss: 2.098107854525248

Epoch: 6| Step: 3
Training loss: 1.251760721206665
Validation loss: 2.076157033443451

Epoch: 6| Step: 4
Training loss: 1.332184910774231
Validation loss: 2.0868283112843833

Epoch: 6| Step: 5
Training loss: 1.4085614681243896
Validation loss: 2.1179322004318237

Epoch: 6| Step: 6
Training loss: 1.5666232109069824
Validation loss: 2.112673342227936

Epoch: 6| Step: 7
Training loss: 1.5374515056610107
Validation loss: 2.140942613283793

Epoch: 6| Step: 8
Training loss: 1.19693922996521
Validation loss: 2.085463285446167

Epoch: 6| Step: 9
Training loss: 1.3283319473266602
Validation loss: 2.0836919148763022

Epoch: 6| Step: 10
Training loss: 0.7816603183746338
Validation loss: 2.0849860310554504

Epoch: 6| Step: 11
Training loss: 1.377685785293579
Validation loss: 2.080955723921458

Epoch: 6| Step: 12
Training loss: 1.1802787780761719
Validation loss: 2.1011773347854614

Epoch: 6| Step: 13
Training loss: 1.8937382698059082
Validation loss: 2.063648442427317

Epoch: 127| Step: 0
Training loss: 1.3192192316055298
Validation loss: 2.0384945472081504

Epoch: 6| Step: 1
Training loss: 1.6763231754302979
Validation loss: 2.0764118432998657

Epoch: 6| Step: 2
Training loss: 0.8962671756744385
Validation loss: 2.1100383599599204

Epoch: 6| Step: 3
Training loss: 1.732933521270752
Validation loss: 2.123934328556061

Epoch: 6| Step: 4
Training loss: 0.9912462830543518
Validation loss: 2.073322137196859

Epoch: 6| Step: 5
Training loss: 1.2462437152862549
Validation loss: 2.1019127368927

Epoch: 6| Step: 6
Training loss: 1.3893263339996338
Validation loss: 2.084168235460917

Epoch: 6| Step: 7
Training loss: 1.2394146919250488
Validation loss: 2.1231839656829834

Epoch: 6| Step: 8
Training loss: 1.0921766757965088
Validation loss: 2.143170694510142

Epoch: 6| Step: 9
Training loss: 1.44477379322052
Validation loss: 2.175304392973582

Epoch: 6| Step: 10
Training loss: 1.7958571910858154
Validation loss: 2.1934829354286194

Epoch: 6| Step: 11
Training loss: 1.285035252571106
Validation loss: 2.1793499191602073

Epoch: 6| Step: 12
Training loss: 1.3418424129486084
Validation loss: 2.180317540963491

Epoch: 6| Step: 13
Training loss: 1.1929752826690674
Validation loss: 2.1669358015060425

Epoch: 128| Step: 0
Training loss: 1.0604205131530762
Validation loss: 2.1468742887179055

Epoch: 6| Step: 1
Training loss: 1.0074493885040283
Validation loss: 2.147090494632721

Epoch: 6| Step: 2
Training loss: 0.9095332026481628
Validation loss: 2.067813833554586

Epoch: 6| Step: 3
Training loss: 1.375880241394043
Validation loss: 2.0962201754252114

Epoch: 6| Step: 4
Training loss: 1.7675135135650635
Validation loss: 2.0806840459505715

Epoch: 6| Step: 5
Training loss: 1.1352689266204834
Validation loss: 2.0967047413190207

Epoch: 6| Step: 6
Training loss: 1.1295008659362793
Validation loss: 2.0987238685290017

Epoch: 6| Step: 7
Training loss: 1.671291470527649
Validation loss: 2.078251759211222

Epoch: 6| Step: 8
Training loss: 1.3473777770996094
Validation loss: 2.099366029103597

Epoch: 6| Step: 9
Training loss: 1.2219607830047607
Validation loss: 2.095726490020752

Epoch: 6| Step: 10
Training loss: 1.3230290412902832
Validation loss: 2.1039901971817017

Epoch: 6| Step: 11
Training loss: 0.9102169871330261
Validation loss: 2.0643257101376853

Epoch: 6| Step: 12
Training loss: 1.9716458320617676
Validation loss: 2.1120739181836448

Epoch: 6| Step: 13
Training loss: 1.600712537765503
Validation loss: 2.0849677125612893

Epoch: 129| Step: 0
Training loss: 1.5431222915649414
Validation loss: 2.0937045415242515

Epoch: 6| Step: 1
Training loss: 1.017303466796875
Validation loss: 2.130020876725515

Epoch: 6| Step: 2
Training loss: 1.1195876598358154
Validation loss: 2.095975716908773

Epoch: 6| Step: 3
Training loss: 1.1569337844848633
Validation loss: 2.1096846063931785

Epoch: 6| Step: 4
Training loss: 1.756251573562622
Validation loss: 2.084395627180735

Epoch: 6| Step: 5
Training loss: 1.1370123624801636
Validation loss: 2.0936068495114646

Epoch: 6| Step: 6
Training loss: 1.8461421728134155
Validation loss: 2.0739970405896506

Epoch: 6| Step: 7
Training loss: 1.437464714050293
Validation loss: 2.0784316261609397

Epoch: 6| Step: 8
Training loss: 1.7110753059387207
Validation loss: 2.0590087374051413

Epoch: 6| Step: 9
Training loss: 1.1762125492095947
Validation loss: 2.09747580687205

Epoch: 6| Step: 10
Training loss: 1.4170864820480347
Validation loss: 2.1013463536898294

Epoch: 6| Step: 11
Training loss: 0.9884026050567627
Validation loss: 2.0897528727849326

Epoch: 6| Step: 12
Training loss: 1.0901837348937988
Validation loss: 2.1217421690622964

Epoch: 6| Step: 13
Training loss: 1.0439205169677734
Validation loss: 2.128234604994456

Epoch: 130| Step: 0
Training loss: 0.9106464385986328
Validation loss: 2.121569514274597

Epoch: 6| Step: 1
Training loss: 0.6955935955047607
Validation loss: 2.1358982721964517

Epoch: 6| Step: 2
Training loss: 1.5995241403579712
Validation loss: 2.0881085991859436

Epoch: 6| Step: 3
Training loss: 1.5927313566207886
Validation loss: 2.0631694197654724

Epoch: 6| Step: 4
Training loss: 1.1747713088989258
Validation loss: 2.0821132262547812

Epoch: 6| Step: 5
Training loss: 1.2472295761108398
Validation loss: 2.096173127492269

Epoch: 6| Step: 6
Training loss: 1.6075372695922852
Validation loss: 2.093876620133718

Epoch: 6| Step: 7
Training loss: 1.4993164539337158
Validation loss: 2.112102746963501

Epoch: 6| Step: 8
Training loss: 1.97958242893219
Validation loss: 2.092640539010366

Epoch: 6| Step: 9
Training loss: 1.5260183811187744
Validation loss: 2.128495713075002

Epoch: 6| Step: 10
Training loss: 1.0219438076019287
Validation loss: 2.0930456121762595

Epoch: 6| Step: 11
Training loss: 0.9319520592689514
Validation loss: 2.0884552597999573

Epoch: 6| Step: 12
Training loss: 0.8719823956489563
Validation loss: 2.1220659216245017

Epoch: 6| Step: 13
Training loss: 1.4257251024246216
Validation loss: 2.0843161741892495

Epoch: 131| Step: 0
Training loss: 0.9250988960266113
Validation loss: 2.127551794052124

Epoch: 6| Step: 1
Training loss: 1.678298830986023
Validation loss: 2.1006754636764526

Epoch: 6| Step: 2
Training loss: 0.7590160369873047
Validation loss: 2.096137742201487

Epoch: 6| Step: 3
Training loss: 0.8737362027168274
Validation loss: 2.103694498538971

Epoch: 6| Step: 4
Training loss: 1.9601755142211914
Validation loss: 2.0622753302256265

Epoch: 6| Step: 5
Training loss: 1.4718341827392578
Validation loss: 2.078000485897064

Epoch: 6| Step: 6
Training loss: 1.735755443572998
Validation loss: 2.0894678831100464

Epoch: 6| Step: 7
Training loss: 1.0716376304626465
Validation loss: 2.047143340110779

Epoch: 6| Step: 8
Training loss: 1.0243096351623535
Validation loss: 2.117718835671743

Epoch: 6| Step: 9
Training loss: 1.6407828330993652
Validation loss: 2.1098190546035767

Epoch: 6| Step: 10
Training loss: 1.2419764995574951
Validation loss: 2.1196992794672647

Epoch: 6| Step: 11
Training loss: 0.9804801940917969
Validation loss: 2.097365061442057

Epoch: 6| Step: 12
Training loss: 1.5181547403335571
Validation loss: 2.1622833410898843

Epoch: 6| Step: 13
Training loss: 1.2512601613998413
Validation loss: 2.1400657097498574

Epoch: 132| Step: 0
Training loss: 0.9745716452598572
Validation loss: 2.14200896024704

Epoch: 6| Step: 1
Training loss: 1.2080979347229004
Validation loss: 2.1032445232073465

Epoch: 6| Step: 2
Training loss: 0.7680518627166748
Validation loss: 2.086386779944102

Epoch: 6| Step: 3
Training loss: 1.481594204902649
Validation loss: 2.102890193462372

Epoch: 6| Step: 4
Training loss: 1.220738172531128
Validation loss: 2.0497795939445496

Epoch: 6| Step: 5
Training loss: 1.4020516872406006
Validation loss: 2.111943562825521

Epoch: 6| Step: 6
Training loss: 1.5413131713867188
Validation loss: 2.096083104610443

Epoch: 6| Step: 7
Training loss: 1.339824914932251
Validation loss: 2.0821382204691568

Epoch: 6| Step: 8
Training loss: 1.283055305480957
Validation loss: 2.1063085794448853

Epoch: 6| Step: 9
Training loss: 1.2921395301818848
Validation loss: 2.1751399636268616

Epoch: 6| Step: 10
Training loss: 2.112682342529297
Validation loss: 2.1096417903900146

Epoch: 6| Step: 11
Training loss: 1.546994686126709
Validation loss: 2.183824896812439

Epoch: 6| Step: 12
Training loss: 1.312666893005371
Validation loss: 2.1359092394510903

Epoch: 6| Step: 13
Training loss: 0.8232902884483337
Validation loss: 2.1373663942019143

Epoch: 133| Step: 0
Training loss: 0.7895079255104065
Validation loss: 2.0922264655431113

Epoch: 6| Step: 1
Training loss: 1.2311525344848633
Validation loss: 2.102121114730835

Epoch: 6| Step: 2
Training loss: 1.9690994024276733
Validation loss: 2.0997284849484763

Epoch: 6| Step: 3
Training loss: 1.3233193159103394
Validation loss: 2.0613786578178406

Epoch: 6| Step: 4
Training loss: 1.162246584892273
Validation loss: 2.093746324380239

Epoch: 6| Step: 5
Training loss: 1.6098512411117554
Validation loss: 2.106401721636454

Epoch: 6| Step: 6
Training loss: 0.7958227396011353
Validation loss: 2.0632446010907493

Epoch: 6| Step: 7
Training loss: 1.2681739330291748
Validation loss: 2.093675374984741

Epoch: 6| Step: 8
Training loss: 1.36868155002594
Validation loss: 2.073135793209076

Epoch: 6| Step: 9
Training loss: 0.9076526165008545
Validation loss: 2.0930825670560202

Epoch: 6| Step: 10
Training loss: 1.1182702779769897
Validation loss: 2.1419928073883057

Epoch: 6| Step: 11
Training loss: 1.6861172914505005
Validation loss: 2.0897430380185447

Epoch: 6| Step: 12
Training loss: 1.0545393228530884
Validation loss: 2.1204450726509094

Epoch: 6| Step: 13
Training loss: 1.2243499755859375
Validation loss: 2.120569169521332

Epoch: 134| Step: 0
Training loss: 1.0031237602233887
Validation loss: 2.0968856811523438

Epoch: 6| Step: 1
Training loss: 1.6205615997314453
Validation loss: 2.0562461614608765

Epoch: 6| Step: 2
Training loss: 1.250333547592163
Validation loss: 2.083210587501526

Epoch: 6| Step: 3
Training loss: 1.2684986591339111
Validation loss: 2.06217630704244

Epoch: 6| Step: 4
Training loss: 1.3142398595809937
Validation loss: 2.048193116982778

Epoch: 6| Step: 5
Training loss: 1.3164913654327393
Validation loss: 2.0683775742848716

Epoch: 6| Step: 6
Training loss: 1.1787976026535034
Validation loss: 2.081546644369761

Epoch: 6| Step: 7
Training loss: 1.2778245210647583
Validation loss: 2.1248603463172913

Epoch: 6| Step: 8
Training loss: 1.3055086135864258
Validation loss: 2.0957555373509726

Epoch: 6| Step: 9
Training loss: 1.216137409210205
Validation loss: 2.1145947376887

Epoch: 6| Step: 10
Training loss: 0.8918889760971069
Validation loss: 2.1179078618685403

Epoch: 6| Step: 11
Training loss: 1.5385066270828247
Validation loss: 2.1388591130574546

Epoch: 6| Step: 12
Training loss: 1.422621250152588
Validation loss: 2.1241581042607627

Epoch: 6| Step: 13
Training loss: 0.7597713470458984
Validation loss: 2.0606115063031516

Epoch: 135| Step: 0
Training loss: 1.077580213546753
Validation loss: 2.0798596342404685

Epoch: 6| Step: 1
Training loss: 1.071725606918335
Validation loss: 2.097336490948995

Epoch: 6| Step: 2
Training loss: 1.1925538778305054
Validation loss: 2.0682412584622702

Epoch: 6| Step: 3
Training loss: 1.3292211294174194
Validation loss: 2.045863608519236

Epoch: 6| Step: 4
Training loss: 0.7635283470153809
Validation loss: 2.033651570479075

Epoch: 6| Step: 5
Training loss: 1.1928675174713135
Validation loss: 2.0543665488560996

Epoch: 6| Step: 6
Training loss: 1.4471399784088135
Validation loss: 2.0840521454811096

Epoch: 6| Step: 7
Training loss: 0.9375600218772888
Validation loss: 2.112048069636027

Epoch: 6| Step: 8
Training loss: 1.394100546836853
Validation loss: 2.0681496063868203

Epoch: 6| Step: 9
Training loss: 1.228192925453186
Validation loss: 2.0551721652348838

Epoch: 6| Step: 10
Training loss: 0.978811502456665
Validation loss: 2.1231074134508767

Epoch: 6| Step: 11
Training loss: 1.6665465831756592
Validation loss: 2.089373509089152

Epoch: 6| Step: 12
Training loss: 1.5346012115478516
Validation loss: 2.16160253683726

Epoch: 6| Step: 13
Training loss: 1.4505789279937744
Validation loss: 2.2057831088701882

Epoch: 136| Step: 0
Training loss: 1.1991422176361084
Validation loss: 2.1950315833091736

Epoch: 6| Step: 1
Training loss: 1.367182731628418
Validation loss: 2.114046295483907

Epoch: 6| Step: 2
Training loss: 1.766359567642212
Validation loss: 2.1031414270401

Epoch: 6| Step: 3
Training loss: 1.1720235347747803
Validation loss: 2.0774298906326294

Epoch: 6| Step: 4
Training loss: 1.6644649505615234
Validation loss: 2.096725881099701

Epoch: 6| Step: 5
Training loss: 1.3143560886383057
Validation loss: 2.0850777626037598

Epoch: 6| Step: 6
Training loss: 1.011121392250061
Validation loss: 2.104694664478302

Epoch: 6| Step: 7
Training loss: 1.2849040031433105
Validation loss: 2.0877004067103067

Epoch: 6| Step: 8
Training loss: 1.7827352285385132
Validation loss: 2.0559678077697754

Epoch: 6| Step: 9
Training loss: 1.5145496129989624
Validation loss: 2.0564072926839194

Epoch: 6| Step: 10
Training loss: 0.9600774645805359
Validation loss: 2.082113206386566

Epoch: 6| Step: 11
Training loss: 1.0362048149108887
Validation loss: 2.0614515940348306

Epoch: 6| Step: 12
Training loss: 0.896787166595459
Validation loss: 2.0740086237589517

Epoch: 6| Step: 13
Training loss: 1.20222008228302
Validation loss: 2.159111042817434

Epoch: 137| Step: 0
Training loss: 1.430293321609497
Validation loss: 2.146645704905192

Epoch: 6| Step: 1
Training loss: 0.7045609354972839
Validation loss: 2.1766851345698037

Epoch: 6| Step: 2
Training loss: 1.6695224046707153
Validation loss: 2.189612865447998

Epoch: 6| Step: 3
Training loss: 1.491729736328125
Validation loss: 2.112581968307495

Epoch: 6| Step: 4
Training loss: 1.4627572298049927
Validation loss: 2.114201545715332

Epoch: 6| Step: 5
Training loss: 0.8765876293182373
Validation loss: 2.112634778022766

Epoch: 6| Step: 6
Training loss: 1.1949830055236816
Validation loss: 2.078334947427114

Epoch: 6| Step: 7
Training loss: 1.562998652458191
Validation loss: 2.145457943280538

Epoch: 6| Step: 8
Training loss: 0.5982756018638611
Validation loss: 2.1085161169370017

Epoch: 6| Step: 9
Training loss: 1.0978063344955444
Validation loss: 2.1244177420934043

Epoch: 6| Step: 10
Training loss: 1.5894720554351807
Validation loss: 2.0833449959754944

Epoch: 6| Step: 11
Training loss: 1.8765900135040283
Validation loss: 2.0586109161376953

Epoch: 6| Step: 12
Training loss: 0.85487961769104
Validation loss: 2.1141432921091714

Epoch: 6| Step: 13
Training loss: 0.5600351095199585
Validation loss: 2.1025678316752114

Epoch: 138| Step: 0
Training loss: 1.6628518104553223
Validation loss: 2.1245694756507874

Epoch: 6| Step: 1
Training loss: 0.9143092632293701
Validation loss: 2.129278222719828

Epoch: 6| Step: 2
Training loss: 1.413533091545105
Validation loss: 2.1452262798945108

Epoch: 6| Step: 3
Training loss: 1.15294349193573
Validation loss: 2.1107860803604126

Epoch: 6| Step: 4
Training loss: 1.5483770370483398
Validation loss: 2.1410648226737976

Epoch: 6| Step: 5
Training loss: 1.1644606590270996
Validation loss: 2.120436449845632

Epoch: 6| Step: 6
Training loss: 0.7422289252281189
Validation loss: 2.152620792388916

Epoch: 6| Step: 7
Training loss: 1.2295066118240356
Validation loss: 2.0977903405825296

Epoch: 6| Step: 8
Training loss: 0.874058187007904
Validation loss: 2.122338056564331

Epoch: 6| Step: 9
Training loss: 0.9084866046905518
Validation loss: 2.1092198292414346

Epoch: 6| Step: 10
Training loss: 1.369638442993164
Validation loss: 2.1104684869448342

Epoch: 6| Step: 11
Training loss: 1.3116399049758911
Validation loss: 2.1025936206181846

Epoch: 6| Step: 12
Training loss: 1.1056759357452393
Validation loss: 2.0831514994303384

Epoch: 6| Step: 13
Training loss: 1.4958138465881348
Validation loss: 2.090747872988383

Epoch: 139| Step: 0
Training loss: 1.0636276006698608
Validation loss: 2.0758960048357644

Epoch: 6| Step: 1
Training loss: 1.3041086196899414
Validation loss: 2.1066876451174417

Epoch: 6| Step: 2
Training loss: 0.8502378463745117
Validation loss: 2.0614285866419473

Epoch: 6| Step: 3
Training loss: 1.0764774084091187
Validation loss: 2.087024430433909

Epoch: 6| Step: 4
Training loss: 1.6324472427368164
Validation loss: 2.088336626688639

Epoch: 6| Step: 5
Training loss: 0.9601324200630188
Validation loss: 2.099124809106191

Epoch: 6| Step: 6
Training loss: 1.072988510131836
Validation loss: 2.1434788505236306

Epoch: 6| Step: 7
Training loss: 0.6867672801017761
Validation loss: 2.093514839808146

Epoch: 6| Step: 8
Training loss: 2.0558066368103027
Validation loss: 2.1461391846338906

Epoch: 6| Step: 9
Training loss: 1.006078839302063
Validation loss: 2.1357016960779824

Epoch: 6| Step: 10
Training loss: 1.8735532760620117
Validation loss: 2.165093978246053

Epoch: 6| Step: 11
Training loss: 1.0944808721542358
Validation loss: 2.0630690852801004

Epoch: 6| Step: 12
Training loss: 1.2672433853149414
Validation loss: 2.0906625390052795

Epoch: 6| Step: 13
Training loss: 1.1958370208740234
Validation loss: 2.0714242458343506

Epoch: 140| Step: 0
Training loss: 1.1525044441223145
Validation loss: 2.1034874320030212

Epoch: 6| Step: 1
Training loss: 1.461907148361206
Validation loss: 2.054647167523702

Epoch: 6| Step: 2
Training loss: 0.8002914190292358
Validation loss: 2.0534536242485046

Epoch: 6| Step: 3
Training loss: 1.011695384979248
Validation loss: 2.068108081817627

Epoch: 6| Step: 4
Training loss: 1.291632890701294
Validation loss: 2.157105584939321

Epoch: 6| Step: 5
Training loss: 0.9570995569229126
Validation loss: 2.100004494190216

Epoch: 6| Step: 6
Training loss: 1.074587345123291
Validation loss: 2.107112010320028

Epoch: 6| Step: 7
Training loss: 0.8022944927215576
Validation loss: 2.1286296049753823

Epoch: 6| Step: 8
Training loss: 0.6453039646148682
Validation loss: 2.1255181630452475

Epoch: 6| Step: 9
Training loss: 2.3998987674713135
Validation loss: 2.1156402428944907

Epoch: 6| Step: 10
Training loss: 1.1864802837371826
Validation loss: 2.1000487407048545

Epoch: 6| Step: 11
Training loss: 1.344721794128418
Validation loss: 2.0482011437416077

Epoch: 6| Step: 12
Training loss: 1.504485845565796
Validation loss: 2.068532109260559

Epoch: 6| Step: 13
Training loss: 1.3969584703445435
Validation loss: 2.0597712794939675

Epoch: 141| Step: 0
Training loss: 1.1343995332717896
Validation loss: 2.085353672504425

Epoch: 6| Step: 1
Training loss: 1.2474379539489746
Validation loss: 2.1006171703338623

Epoch: 6| Step: 2
Training loss: 1.0821874141693115
Validation loss: 2.09841920932134

Epoch: 6| Step: 3
Training loss: 0.9341741800308228
Validation loss: 2.129964033762614

Epoch: 6| Step: 4
Training loss: 1.3746875524520874
Validation loss: 2.070396641890208

Epoch: 6| Step: 5
Training loss: 1.0215309858322144
Validation loss: 2.1150858799616494

Epoch: 6| Step: 6
Training loss: 1.0498692989349365
Validation loss: 2.1583590110143027

Epoch: 6| Step: 7
Training loss: 1.4031707048416138
Validation loss: 2.199768364429474

Epoch: 6| Step: 8
Training loss: 1.4496204853057861
Validation loss: 2.129724085330963

Epoch: 6| Step: 9
Training loss: 0.9593436121940613
Validation loss: 2.2511279185613

Epoch: 6| Step: 10
Training loss: 1.2319915294647217
Validation loss: 2.176433563232422

Epoch: 6| Step: 11
Training loss: 1.2925302982330322
Validation loss: 2.17682284116745

Epoch: 6| Step: 12
Training loss: 1.272139549255371
Validation loss: 2.1435550649960837

Epoch: 6| Step: 13
Training loss: 1.3094537258148193
Validation loss: 2.065599878629049

Epoch: 142| Step: 0
Training loss: 1.3361698389053345
Validation loss: 2.0961406230926514

Epoch: 6| Step: 1
Training loss: 1.0626084804534912
Validation loss: 2.0530911684036255

Epoch: 6| Step: 2
Training loss: 1.2760887145996094
Validation loss: 2.0490328272183738

Epoch: 6| Step: 3
Training loss: 1.7563321590423584
Validation loss: 2.0701910654703775

Epoch: 6| Step: 4
Training loss: 0.9561060667037964
Validation loss: 2.100015560785929

Epoch: 6| Step: 5
Training loss: 0.6668908596038818
Validation loss: 2.1243753830591836

Epoch: 6| Step: 6
Training loss: 1.0545437335968018
Validation loss: 2.1200764775276184

Epoch: 6| Step: 7
Training loss: 0.9591048955917358
Validation loss: 2.0953327218691506

Epoch: 6| Step: 8
Training loss: 1.443598985671997
Validation loss: 2.1534217596054077

Epoch: 6| Step: 9
Training loss: 1.2590590715408325
Validation loss: 2.1005966464678445

Epoch: 6| Step: 10
Training loss: 1.658432960510254
Validation loss: 2.1880198319753013

Epoch: 6| Step: 11
Training loss: 1.3361313343048096
Validation loss: 2.156616965929667

Epoch: 6| Step: 12
Training loss: 1.068650245666504
Validation loss: 2.204425017038981

Epoch: 6| Step: 13
Training loss: 1.321576714515686
Validation loss: 2.15126762787501

Epoch: 143| Step: 0
Training loss: 1.452183485031128
Validation loss: 2.180553158124288

Epoch: 6| Step: 1
Training loss: 0.9737881422042847
Validation loss: 2.1283071637153625

Epoch: 6| Step: 2
Training loss: 1.531599998474121
Validation loss: 2.124312082926432

Epoch: 6| Step: 3
Training loss: 1.324655532836914
Validation loss: 2.0757456024487815

Epoch: 6| Step: 4
Training loss: 1.34396231174469
Validation loss: 2.0784889260927835

Epoch: 6| Step: 5
Training loss: 1.0128226280212402
Validation loss: 2.1025030811627707

Epoch: 6| Step: 6
Training loss: 0.5798521041870117
Validation loss: 2.107426385084788

Epoch: 6| Step: 7
Training loss: 1.4429290294647217
Validation loss: 2.1313658555348716

Epoch: 6| Step: 8
Training loss: 1.3056204319000244
Validation loss: 2.0750426054000854

Epoch: 6| Step: 9
Training loss: 1.0631585121154785
Validation loss: 2.113689661026001

Epoch: 6| Step: 10
Training loss: 1.1010137796401978
Validation loss: 2.0731342236200967

Epoch: 6| Step: 11
Training loss: 0.9788221716880798
Validation loss: 2.144624571005503

Epoch: 6| Step: 12
Training loss: 1.5071334838867188
Validation loss: 2.1922324101130166

Epoch: 6| Step: 13
Training loss: 1.529799222946167
Validation loss: 2.213192900021871

Epoch: 144| Step: 0
Training loss: 0.9135308265686035
Validation loss: 2.1495749155680337

Epoch: 6| Step: 1
Training loss: 1.7316828966140747
Validation loss: 2.184904416402181

Epoch: 6| Step: 2
Training loss: 1.5624160766601562
Validation loss: 2.18796706199646

Epoch: 6| Step: 3
Training loss: 0.988555908203125
Validation loss: 2.1506830851236978

Epoch: 6| Step: 4
Training loss: 0.8466847538948059
Validation loss: 2.1117878357569375

Epoch: 6| Step: 5
Training loss: 1.0999994277954102
Validation loss: 2.0988155206044516

Epoch: 6| Step: 6
Training loss: 1.4078514575958252
Validation loss: 2.076091945171356

Epoch: 6| Step: 7
Training loss: 0.9516281485557556
Validation loss: 2.092557986577352

Epoch: 6| Step: 8
Training loss: 1.1879593133926392
Validation loss: 2.0902874072392783

Epoch: 6| Step: 9
Training loss: 1.2342723608016968
Validation loss: 2.088732063770294

Epoch: 6| Step: 10
Training loss: 1.218336820602417
Validation loss: 2.139120578765869

Epoch: 6| Step: 11
Training loss: 1.1594318151474
Validation loss: 2.098950465520223

Epoch: 6| Step: 12
Training loss: 0.946891188621521
Validation loss: 2.0945724844932556

Epoch: 6| Step: 13
Training loss: 1.1356143951416016
Validation loss: 2.0949172178904214

Epoch: 145| Step: 0
Training loss: 0.9097907543182373
Validation loss: 2.1261199514071145

Epoch: 6| Step: 1
Training loss: 1.1082031726837158
Validation loss: 2.134196639060974

Epoch: 6| Step: 2
Training loss: 1.013504981994629
Validation loss: 2.1495997508366904

Epoch: 6| Step: 3
Training loss: 1.4598363637924194
Validation loss: 2.1334256331125894

Epoch: 6| Step: 4
Training loss: 0.8921651840209961
Validation loss: 2.1207696199417114

Epoch: 6| Step: 5
Training loss: 1.095304012298584
Validation loss: 2.0689339637756348

Epoch: 6| Step: 6
Training loss: 1.3432058095932007
Validation loss: 2.0851765473683677

Epoch: 6| Step: 7
Training loss: 1.3116049766540527
Validation loss: 2.081300656000773

Epoch: 6| Step: 8
Training loss: 1.3455997705459595
Validation loss: 2.0844806830088296

Epoch: 6| Step: 9
Training loss: 1.4687743186950684
Validation loss: 2.060289661089579

Epoch: 6| Step: 10
Training loss: 0.9860481023788452
Validation loss: 2.0586124658584595

Epoch: 6| Step: 11
Training loss: 1.3238143920898438
Validation loss: 2.116986393928528

Epoch: 6| Step: 12
Training loss: 1.1980829238891602
Validation loss: 2.09048463900884

Epoch: 6| Step: 13
Training loss: 0.9360436797142029
Validation loss: 2.131863832473755

Epoch: 146| Step: 0
Training loss: 1.2054002285003662
Validation loss: 2.141252338886261

Epoch: 6| Step: 1
Training loss: 1.398532748222351
Validation loss: 2.213532487551371

Epoch: 6| Step: 2
Training loss: 0.8815555572509766
Validation loss: 2.2295615673065186

Epoch: 6| Step: 3
Training loss: 1.6812560558319092
Validation loss: 2.1805027524630227

Epoch: 6| Step: 4
Training loss: 1.0934888124465942
Validation loss: 2.151379426320394

Epoch: 6| Step: 5
Training loss: 0.9581266641616821
Validation loss: 2.1246996323267617

Epoch: 6| Step: 6
Training loss: 0.9187537431716919
Validation loss: 2.085333983103434

Epoch: 6| Step: 7
Training loss: 1.6020578145980835
Validation loss: 2.10431561867396

Epoch: 6| Step: 8
Training loss: 1.3998422622680664
Validation loss: 2.0974687337875366

Epoch: 6| Step: 9
Training loss: 1.1071290969848633
Validation loss: 2.0813162326812744

Epoch: 6| Step: 10
Training loss: 0.9215186834335327
Validation loss: 2.1220497488975525

Epoch: 6| Step: 11
Training loss: 0.6965792179107666
Validation loss: 2.1204267938931785

Epoch: 6| Step: 12
Training loss: 1.0693222284317017
Validation loss: 2.1466678977012634

Epoch: 6| Step: 13
Training loss: 1.1732124090194702
Validation loss: 2.1166922648747764

Epoch: 147| Step: 0
Training loss: 1.1471295356750488
Validation loss: 2.1762346227963767

Epoch: 6| Step: 1
Training loss: 1.1758043766021729
Validation loss: 2.1860137383143106

Epoch: 6| Step: 2
Training loss: 1.1408963203430176
Validation loss: 2.115816056728363

Epoch: 6| Step: 3
Training loss: 1.2614996433258057
Validation loss: 2.1305095553398132

Epoch: 6| Step: 4
Training loss: 1.0954463481903076
Validation loss: 2.064693033695221

Epoch: 6| Step: 5
Training loss: 1.3276262283325195
Validation loss: 2.090258797009786

Epoch: 6| Step: 6
Training loss: 1.646191120147705
Validation loss: 2.1204001704851785

Epoch: 6| Step: 7
Training loss: 0.9252049922943115
Validation loss: 2.113240400950114

Epoch: 6| Step: 8
Training loss: 1.028210163116455
Validation loss: 2.0514991680781045

Epoch: 6| Step: 9
Training loss: 0.9863071441650391
Validation loss: 2.0944340427716575

Epoch: 6| Step: 10
Training loss: 1.351076364517212
Validation loss: 2.078945199648539

Epoch: 6| Step: 11
Training loss: 1.0638930797576904
Validation loss: 2.1195860306421914

Epoch: 6| Step: 12
Training loss: 0.9275585412979126
Validation loss: 2.1260644793510437

Epoch: 6| Step: 13
Training loss: 1.062631607055664
Validation loss: 2.108346382776896

Epoch: 148| Step: 0
Training loss: 1.0998129844665527
Validation loss: 2.137540618578593

Epoch: 6| Step: 1
Training loss: 1.0096559524536133
Validation loss: 2.1325953006744385

Epoch: 6| Step: 2
Training loss: 0.9837665557861328
Validation loss: 2.1683460474014282

Epoch: 6| Step: 3
Training loss: 1.4649102687835693
Validation loss: 2.1776005824406943

Epoch: 6| Step: 4
Training loss: 1.670027732849121
Validation loss: 2.1427040497461953

Epoch: 6| Step: 5
Training loss: 1.2689642906188965
Validation loss: 2.120285669962565

Epoch: 6| Step: 6
Training loss: 1.1524388790130615
Validation loss: 2.124199151992798

Epoch: 6| Step: 7
Training loss: 0.8831869959831238
Validation loss: 2.069368580977122

Epoch: 6| Step: 8
Training loss: 0.9301271438598633
Validation loss: 2.0719929933547974

Epoch: 6| Step: 9
Training loss: 1.001721739768982
Validation loss: 2.104891856511434

Epoch: 6| Step: 10
Training loss: 0.7959505915641785
Validation loss: 2.080436885356903

Epoch: 6| Step: 11
Training loss: 0.8608099818229675
Validation loss: 2.095838725566864

Epoch: 6| Step: 12
Training loss: 1.325962781906128
Validation loss: 2.0869961182276406

Epoch: 6| Step: 13
Training loss: 0.8657657504081726
Validation loss: 2.109825531641642

Epoch: 149| Step: 0
Training loss: 0.7163678407669067
Validation loss: 2.0832186341285706

Epoch: 6| Step: 1
Training loss: 1.587965965270996
Validation loss: 2.1327202121416726

Epoch: 6| Step: 2
Training loss: 1.0483286380767822
Validation loss: 2.1158105731010437

Epoch: 6| Step: 3
Training loss: 1.5475249290466309
Validation loss: 2.188019891579946

Epoch: 6| Step: 4
Training loss: 1.1898095607757568
Validation loss: 2.148181597391764

Epoch: 6| Step: 5
Training loss: 1.0545672178268433
Validation loss: 2.083378573258718

Epoch: 6| Step: 6
Training loss: 1.2361756563186646
Validation loss: 2.1287133495012918

Epoch: 6| Step: 7
Training loss: 1.3688557147979736
Validation loss: 2.141544242699941

Epoch: 6| Step: 8
Training loss: 0.9445483088493347
Validation loss: 2.083353817462921

Epoch: 6| Step: 9
Training loss: 0.9836318492889404
Validation loss: 2.0546651085217795

Epoch: 6| Step: 10
Training loss: 1.205822229385376
Validation loss: 2.1067170898119607

Epoch: 6| Step: 11
Training loss: 0.8319281339645386
Validation loss: 2.096739133199056

Epoch: 6| Step: 12
Training loss: 0.5871320962905884
Validation loss: 2.1206807692845664

Epoch: 6| Step: 13
Training loss: 0.8536295890808105
Validation loss: 2.1240089734395347

Epoch: 150| Step: 0
Training loss: 1.6532520055770874
Validation loss: 2.1477253238360086

Epoch: 6| Step: 1
Training loss: 1.2574273347854614
Validation loss: 2.128705004851023

Epoch: 6| Step: 2
Training loss: 1.0320582389831543
Validation loss: 2.1145828564961753

Epoch: 6| Step: 3
Training loss: 0.8904495239257812
Validation loss: 2.1398862997690835

Epoch: 6| Step: 4
Training loss: 1.0096468925476074
Validation loss: 2.135806083679199

Epoch: 6| Step: 5
Training loss: 1.3196361064910889
Validation loss: 2.1626452207565308

Epoch: 6| Step: 6
Training loss: 0.8611481785774231
Validation loss: 2.0850064158439636

Epoch: 6| Step: 7
Training loss: 1.0972836017608643
Validation loss: 2.1120731234550476

Epoch: 6| Step: 8
Training loss: 0.9071307182312012
Validation loss: 2.1086466709772744

Epoch: 6| Step: 9
Training loss: 1.3468341827392578
Validation loss: 2.1168617804845176

Epoch: 6| Step: 10
Training loss: 1.4171552658081055
Validation loss: 2.129132946332296

Epoch: 6| Step: 11
Training loss: 1.119308352470398
Validation loss: 2.1481261253356934

Epoch: 6| Step: 12
Training loss: 0.6717202663421631
Validation loss: 2.101410965124766

Epoch: 6| Step: 13
Training loss: 0.9717974066734314
Validation loss: 2.1278600891431174

Epoch: 151| Step: 0
Training loss: 1.449138879776001
Validation loss: 2.1224514047304788

Epoch: 6| Step: 1
Training loss: 1.0296902656555176
Validation loss: 2.071460207303365

Epoch: 6| Step: 2
Training loss: 0.7081620693206787
Validation loss: 2.0562097231547036

Epoch: 6| Step: 3
Training loss: 0.9214006066322327
Validation loss: 2.0970831314722695

Epoch: 6| Step: 4
Training loss: 0.95916348695755
Validation loss: 2.09109765291214

Epoch: 6| Step: 5
Training loss: 0.6385886073112488
Validation loss: 2.0990642507870994

Epoch: 6| Step: 6
Training loss: 1.1182273626327515
Validation loss: 2.14738921324412

Epoch: 6| Step: 7
Training loss: 0.9145352840423584
Validation loss: 2.064651449521383

Epoch: 6| Step: 8
Training loss: 0.837785542011261
Validation loss: 2.0989641547203064

Epoch: 6| Step: 9
Training loss: 1.2810133695602417
Validation loss: 2.1068193713823953

Epoch: 6| Step: 10
Training loss: 1.275048017501831
Validation loss: 2.084161718686422

Epoch: 6| Step: 11
Training loss: 2.042752742767334
Validation loss: 2.166198194026947

Epoch: 6| Step: 12
Training loss: 1.0548901557922363
Validation loss: 2.1570858558019004

Epoch: 6| Step: 13
Training loss: 1.005521535873413
Validation loss: 2.1513144969940186

Epoch: 152| Step: 0
Training loss: 1.6893270015716553
Validation loss: 2.1086036960283914

Epoch: 6| Step: 1
Training loss: 1.6942579746246338
Validation loss: 2.1017741362253823

Epoch: 6| Step: 2
Training loss: 1.025559425354004
Validation loss: 2.083579162756602

Epoch: 6| Step: 3
Training loss: 1.0058354139328003
Validation loss: 2.0753548542658486

Epoch: 6| Step: 4
Training loss: 0.8189655542373657
Validation loss: 2.080111006895701

Epoch: 6| Step: 5
Training loss: 0.9700818061828613
Validation loss: 2.1020705501238504

Epoch: 6| Step: 6
Training loss: 0.9210285544395447
Validation loss: 2.0883801182111106

Epoch: 6| Step: 7
Training loss: 1.054494857788086
Validation loss: 2.122760991255442

Epoch: 6| Step: 8
Training loss: 1.270882248878479
Validation loss: 2.095288018385569

Epoch: 6| Step: 9
Training loss: 1.127315640449524
Validation loss: 2.1385291616121926

Epoch: 6| Step: 10
Training loss: 1.2372844219207764
Validation loss: 2.1312828063964844

Epoch: 6| Step: 11
Training loss: 0.752617597579956
Validation loss: 2.133460203806559

Epoch: 6| Step: 12
Training loss: 0.8518271446228027
Validation loss: 2.167200267314911

Epoch: 6| Step: 13
Training loss: 0.9802438020706177
Validation loss: 2.2190628051757812

Epoch: 153| Step: 0
Training loss: 1.504805088043213
Validation loss: 2.206083079179128

Epoch: 6| Step: 1
Training loss: 0.9584405422210693
Validation loss: 2.1653454105059304

Epoch: 6| Step: 2
Training loss: 0.48834699392318726
Validation loss: 2.117007394631704

Epoch: 6| Step: 3
Training loss: 0.8983086943626404
Validation loss: 2.0750534931818643

Epoch: 6| Step: 4
Training loss: 1.881361484527588
Validation loss: 2.088432868321737

Epoch: 6| Step: 5
Training loss: 1.2266923189163208
Validation loss: 2.091155211130778

Epoch: 6| Step: 6
Training loss: 1.6008307933807373
Validation loss: 2.130708932876587

Epoch: 6| Step: 7
Training loss: 1.2164161205291748
Validation loss: 2.1128926277160645

Epoch: 6| Step: 8
Training loss: 0.8480071425437927
Validation loss: 2.110951562722524

Epoch: 6| Step: 9
Training loss: 0.8516848087310791
Validation loss: 2.0567113757133484

Epoch: 6| Step: 10
Training loss: 1.2062416076660156
Validation loss: 2.1116928259531655

Epoch: 6| Step: 11
Training loss: 1.4168304204940796
Validation loss: 2.128861745198568

Epoch: 6| Step: 12
Training loss: 1.0266956090927124
Validation loss: 2.141344745953878

Epoch: 6| Step: 13
Training loss: 0.8567186594009399
Validation loss: 2.1478653152783713

Epoch: 154| Step: 0
Training loss: 0.9972540736198425
Validation loss: 2.174592932065328

Epoch: 6| Step: 1
Training loss: 1.0066407918930054
Validation loss: 2.137813091278076

Epoch: 6| Step: 2
Training loss: 0.9763606786727905
Validation loss: 2.118725518385569

Epoch: 6| Step: 3
Training loss: 0.9045073390007019
Validation loss: 2.157203435897827

Epoch: 6| Step: 4
Training loss: 1.1670804023742676
Validation loss: 2.1390124758084617

Epoch: 6| Step: 5
Training loss: 0.750282883644104
Validation loss: 2.092585484186808

Epoch: 6| Step: 6
Training loss: 1.3181447982788086
Validation loss: 2.0704785188039145

Epoch: 6| Step: 7
Training loss: 1.1812868118286133
Validation loss: 2.004480461279551

Epoch: 6| Step: 8
Training loss: 0.8835890293121338
Validation loss: 2.0541449983914695

Epoch: 6| Step: 9
Training loss: 1.5064418315887451
Validation loss: 2.0903610388437905

Epoch: 6| Step: 10
Training loss: 1.0447779893875122
Validation loss: 2.0619121392567954

Epoch: 6| Step: 11
Training loss: 0.9495431184768677
Validation loss: 2.1289910475413003

Epoch: 6| Step: 12
Training loss: 0.6541728973388672
Validation loss: 2.113322933514913

Epoch: 6| Step: 13
Training loss: 1.4508872032165527
Validation loss: 2.089496990044912

Epoch: 155| Step: 0
Training loss: 1.1593806743621826
Validation loss: 2.0965306758880615

Epoch: 6| Step: 1
Training loss: 0.759443998336792
Validation loss: 2.120028018951416

Epoch: 6| Step: 2
Training loss: 0.903705358505249
Validation loss: 2.11148468653361

Epoch: 6| Step: 3
Training loss: 1.2497907876968384
Validation loss: 2.1082159876823425

Epoch: 6| Step: 4
Training loss: 1.1248923540115356
Validation loss: 2.104915221532186

Epoch: 6| Step: 5
Training loss: 0.8778693675994873
Validation loss: 2.11171285311381

Epoch: 6| Step: 6
Training loss: 1.0808262825012207
Validation loss: 2.0535388390223184

Epoch: 6| Step: 7
Training loss: 0.6979122757911682
Validation loss: 2.129746596018473

Epoch: 6| Step: 8
Training loss: 1.2640353441238403
Validation loss: 2.0577811002731323

Epoch: 6| Step: 9
Training loss: 1.0766922235488892
Validation loss: 2.083698272705078

Epoch: 6| Step: 10
Training loss: 0.5964065194129944
Validation loss: 2.097918232282003

Epoch: 6| Step: 11
Training loss: 2.0019474029541016
Validation loss: 2.1238743464152017

Epoch: 6| Step: 12
Training loss: 0.8590754270553589
Validation loss: 2.0951613585154214

Epoch: 6| Step: 13
Training loss: 0.9909441471099854
Validation loss: 2.0960744818051658

Epoch: 156| Step: 0
Training loss: 0.7548593282699585
Validation loss: 2.0933120449384055

Epoch: 6| Step: 1
Training loss: 1.2384573221206665
Validation loss: 2.1435989141464233

Epoch: 6| Step: 2
Training loss: 1.8012195825576782
Validation loss: 2.0861500104268393

Epoch: 6| Step: 3
Training loss: 1.0171681642532349
Validation loss: 2.1265738805135093

Epoch: 6| Step: 4
Training loss: 0.9256809949874878
Validation loss: 2.13789834578832

Epoch: 6| Step: 5
Training loss: 1.0856637954711914
Validation loss: 2.1347446839014688

Epoch: 6| Step: 6
Training loss: 0.8468686938285828
Validation loss: 2.108564337094625

Epoch: 6| Step: 7
Training loss: 1.0484790802001953
Validation loss: 2.1460506916046143

Epoch: 6| Step: 8
Training loss: 1.1212513446807861
Validation loss: 2.0903287331263223

Epoch: 6| Step: 9
Training loss: 1.0884641408920288
Validation loss: 2.1277969678243003

Epoch: 6| Step: 10
Training loss: 0.8326990604400635
Validation loss: 2.094931979974111

Epoch: 6| Step: 11
Training loss: 0.5809791088104248
Validation loss: 2.13579527537028

Epoch: 6| Step: 12
Training loss: 0.8407511711120605
Validation loss: 2.1146045923233032

Epoch: 6| Step: 13
Training loss: 1.552527904510498
Validation loss: 2.1026066740353904

Epoch: 157| Step: 0
Training loss: 0.9208507537841797
Validation loss: 2.0541531840960183

Epoch: 6| Step: 1
Training loss: 1.3594603538513184
Validation loss: 2.1448006629943848

Epoch: 6| Step: 2
Training loss: 0.7742236256599426
Validation loss: 2.085350771745046

Epoch: 6| Step: 3
Training loss: 1.1455585956573486
Validation loss: 2.108077029387156

Epoch: 6| Step: 4
Training loss: 1.5119765996932983
Validation loss: 2.1307116945584617

Epoch: 6| Step: 5
Training loss: 0.4866952896118164
Validation loss: 2.112433155377706

Epoch: 6| Step: 6
Training loss: 1.282119631767273
Validation loss: 2.155946930249532

Epoch: 6| Step: 7
Training loss: 1.2898763418197632
Validation loss: 2.1598925590515137

Epoch: 6| Step: 8
Training loss: 0.9948626756668091
Validation loss: 2.1436477104822793

Epoch: 6| Step: 9
Training loss: 0.7856793999671936
Validation loss: 2.1484405398368835

Epoch: 6| Step: 10
Training loss: 0.5309593677520752
Validation loss: 2.167159636815389

Epoch: 6| Step: 11
Training loss: 1.0792680978775024
Validation loss: 2.1645388007164

Epoch: 6| Step: 12
Training loss: 1.3683279752731323
Validation loss: 2.1137020190556846

Epoch: 6| Step: 13
Training loss: 0.9933147430419922
Validation loss: 2.126410126686096

Epoch: 158| Step: 0
Training loss: 1.394730567932129
Validation loss: 2.0861727794011435

Epoch: 6| Step: 1
Training loss: 1.3950119018554688
Validation loss: 2.075276772181193

Epoch: 6| Step: 2
Training loss: 1.2610647678375244
Validation loss: 2.1038760344187417

Epoch: 6| Step: 3
Training loss: 0.8920188546180725
Validation loss: 2.1144973834355674

Epoch: 6| Step: 4
Training loss: 0.9766883850097656
Validation loss: 2.09180078903834

Epoch: 6| Step: 5
Training loss: 1.1489874124526978
Validation loss: 2.0918259024620056

Epoch: 6| Step: 6
Training loss: 1.1013665199279785
Validation loss: 2.1432830095291138

Epoch: 6| Step: 7
Training loss: 1.334396243095398
Validation loss: 2.137997289498647

Epoch: 6| Step: 8
Training loss: 0.6579669713973999
Validation loss: 2.163426458835602

Epoch: 6| Step: 9
Training loss: 0.841427206993103
Validation loss: 2.1255079905192056

Epoch: 6| Step: 10
Training loss: 1.026494026184082
Validation loss: 2.197093983491262

Epoch: 6| Step: 11
Training loss: 0.6043920516967773
Validation loss: 2.148469090461731

Epoch: 6| Step: 12
Training loss: 1.049250602722168
Validation loss: 2.09605473279953

Epoch: 6| Step: 13
Training loss: 0.7503894567489624
Validation loss: 2.099241932233175

Epoch: 159| Step: 0
Training loss: 1.126940369606018
Validation loss: 2.11866295337677

Epoch: 6| Step: 1
Training loss: 0.899614691734314
Validation loss: 2.088105301062266

Epoch: 6| Step: 2
Training loss: 1.0816981792449951
Validation loss: 2.0635011196136475

Epoch: 6| Step: 3
Training loss: 1.4335330724716187
Validation loss: 2.0831376711527505

Epoch: 6| Step: 4
Training loss: 0.923113226890564
Validation loss: 2.115720272064209

Epoch: 6| Step: 5
Training loss: 0.681621253490448
Validation loss: 2.0721211234728494

Epoch: 6| Step: 6
Training loss: 0.9975571632385254
Validation loss: 2.139602760473887

Epoch: 6| Step: 7
Training loss: 1.6864255666732788
Validation loss: 2.1294578115145364

Epoch: 6| Step: 8
Training loss: 0.7678708434104919
Validation loss: 2.1287906169891357

Epoch: 6| Step: 9
Training loss: 0.9593005180358887
Validation loss: 2.103809654712677

Epoch: 6| Step: 10
Training loss: 1.0996638536453247
Validation loss: 2.1278320948282876

Epoch: 6| Step: 11
Training loss: 1.1571810245513916
Validation loss: 2.07345179716746

Epoch: 6| Step: 12
Training loss: 0.64723801612854
Validation loss: 2.0834129055341086

Epoch: 6| Step: 13
Training loss: 1.1448532342910767
Validation loss: 2.107977648576101

Epoch: 160| Step: 0
Training loss: 0.8533912897109985
Validation loss: 2.0490838090578714

Epoch: 6| Step: 1
Training loss: 0.8485820293426514
Validation loss: 2.124403993288676

Epoch: 6| Step: 2
Training loss: 0.8621088266372681
Validation loss: 2.1308717926343284

Epoch: 6| Step: 3
Training loss: 1.6170419454574585
Validation loss: 2.123672902584076

Epoch: 6| Step: 4
Training loss: 0.8974885940551758
Validation loss: 2.139754831790924

Epoch: 6| Step: 5
Training loss: 1.2857587337493896
Validation loss: 2.1155133048693338

Epoch: 6| Step: 6
Training loss: 0.8350844979286194
Validation loss: 2.1732138196627298

Epoch: 6| Step: 7
Training loss: 0.6587859392166138
Validation loss: 2.1041033466657004

Epoch: 6| Step: 8
Training loss: 1.1359328031539917
Validation loss: 2.1086514592170715

Epoch: 6| Step: 9
Training loss: 1.2062820196151733
Validation loss: 2.0991840958595276

Epoch: 6| Step: 10
Training loss: 0.985507607460022
Validation loss: 2.1213054855664573

Epoch: 6| Step: 11
Training loss: 0.8716890215873718
Validation loss: 2.0981973012288413

Epoch: 6| Step: 12
Training loss: 0.9404579997062683
Validation loss: 2.092279533545176

Epoch: 6| Step: 13
Training loss: 1.058455467224121
Validation loss: 2.061900715033213

Epoch: 161| Step: 0
Training loss: 1.6882128715515137
Validation loss: 2.095109204451243

Epoch: 6| Step: 1
Training loss: 0.8058597445487976
Validation loss: 2.0906973679860434

Epoch: 6| Step: 2
Training loss: 0.9226223826408386
Validation loss: 2.057941714922587

Epoch: 6| Step: 3
Training loss: 1.1415071487426758
Validation loss: 2.122867484887441

Epoch: 6| Step: 4
Training loss: 0.7815120816230774
Validation loss: 2.1456512212753296

Epoch: 6| Step: 5
Training loss: 0.9952009320259094
Validation loss: 2.089486837387085

Epoch: 6| Step: 6
Training loss: 0.7519882917404175
Validation loss: 2.1428354183832803

Epoch: 6| Step: 7
Training loss: 0.6928093433380127
Validation loss: 2.1280896266301474

Epoch: 6| Step: 8
Training loss: 1.093989372253418
Validation loss: 2.0965088605880737

Epoch: 6| Step: 9
Training loss: 0.8900673985481262
Validation loss: 2.106915990511576

Epoch: 6| Step: 10
Training loss: 0.7787236571311951
Validation loss: 2.102739234765371

Epoch: 6| Step: 11
Training loss: 1.444347620010376
Validation loss: 2.133600095907847

Epoch: 6| Step: 12
Training loss: 1.2813324928283691
Validation loss: 2.1087343295415244

Epoch: 6| Step: 13
Training loss: 0.5330362915992737
Validation loss: 2.130431870619456

Epoch: 162| Step: 0
Training loss: 0.8467282056808472
Validation loss: 2.1214330196380615

Epoch: 6| Step: 1
Training loss: 0.792130172252655
Validation loss: 2.1010400652885437

Epoch: 6| Step: 2
Training loss: 1.2739434242248535
Validation loss: 2.12032683690389

Epoch: 6| Step: 3
Training loss: 1.2897224426269531
Validation loss: 2.1168042421340942

Epoch: 6| Step: 4
Training loss: 0.8850618004798889
Validation loss: 2.1049437324206033

Epoch: 6| Step: 5
Training loss: 0.9166778922080994
Validation loss: 2.1734277804692588

Epoch: 6| Step: 6
Training loss: 0.6791934967041016
Validation loss: 2.113095839818319

Epoch: 6| Step: 7
Training loss: 0.8951072692871094
Validation loss: 2.1204614639282227

Epoch: 6| Step: 8
Training loss: 0.9216739535331726
Validation loss: 2.054629107316335

Epoch: 6| Step: 9
Training loss: 1.4534552097320557
Validation loss: 2.0536197622617087

Epoch: 6| Step: 10
Training loss: 0.920094907283783
Validation loss: 2.1081927021344504

Epoch: 6| Step: 11
Training loss: 1.0418031215667725
Validation loss: 2.0219501654307046

Epoch: 6| Step: 12
Training loss: 0.7411291003227234
Validation loss: 2.0929590662320456

Epoch: 6| Step: 13
Training loss: 1.3179001808166504
Validation loss: 2.0879305005073547

Epoch: 163| Step: 0
Training loss: 0.7742758393287659
Validation loss: 2.1158512433369956

Epoch: 6| Step: 1
Training loss: 1.1384015083312988
Validation loss: 2.1365457574526467

Epoch: 6| Step: 2
Training loss: 0.7914143800735474
Validation loss: 2.152162571748098

Epoch: 6| Step: 3
Training loss: 1.137580156326294
Validation loss: 2.1311114033063254

Epoch: 6| Step: 4
Training loss: 1.0071055889129639
Validation loss: 2.0536016821861267

Epoch: 6| Step: 5
Training loss: 1.103257656097412
Validation loss: 2.1232104500134787

Epoch: 6| Step: 6
Training loss: 0.7105776071548462
Validation loss: 2.107553243637085

Epoch: 6| Step: 7
Training loss: 1.5666322708129883
Validation loss: 2.078922907511393

Epoch: 6| Step: 8
Training loss: 0.7263567447662354
Validation loss: 2.0975453654925027

Epoch: 6| Step: 9
Training loss: 1.2457717657089233
Validation loss: 2.0733922123908997

Epoch: 6| Step: 10
Training loss: 0.8179516196250916
Validation loss: 2.117060422897339

Epoch: 6| Step: 11
Training loss: 1.2086292505264282
Validation loss: 2.0943170388539634

Epoch: 6| Step: 12
Training loss: 1.1905748844146729
Validation loss: 2.074193994204203

Epoch: 6| Step: 13
Training loss: 0.4623880982398987
Validation loss: 2.0783653060595193

Epoch: 164| Step: 0
Training loss: 1.3572527170181274
Validation loss: 2.1546649734179177

Epoch: 6| Step: 1
Training loss: 0.6979146003723145
Validation loss: 2.146168529987335

Epoch: 6| Step: 2
Training loss: 1.0523630380630493
Validation loss: 2.2139381170272827

Epoch: 6| Step: 3
Training loss: 0.9237545728683472
Validation loss: 2.1308597127596536

Epoch: 6| Step: 4
Training loss: 1.297247290611267
Validation loss: 2.1401159962018332

Epoch: 6| Step: 5
Training loss: 1.237044095993042
Validation loss: 2.1290530363718667

Epoch: 6| Step: 6
Training loss: 0.6978818774223328
Validation loss: 2.1160012682278952

Epoch: 6| Step: 7
Training loss: 1.235476016998291
Validation loss: 2.1040976643562317

Epoch: 6| Step: 8
Training loss: 0.7881945371627808
Validation loss: 2.1057506799697876

Epoch: 6| Step: 9
Training loss: 0.6853048801422119
Validation loss: 2.1429786483446756

Epoch: 6| Step: 10
Training loss: 1.0872973203659058
Validation loss: 2.082977076371511

Epoch: 6| Step: 11
Training loss: 0.8812626600265503
Validation loss: 2.0681682030359902

Epoch: 6| Step: 12
Training loss: 0.9465605616569519
Validation loss: 2.132449229558309

Epoch: 6| Step: 13
Training loss: 1.0418803691864014
Validation loss: 2.1078038811683655

Epoch: 165| Step: 0
Training loss: 0.9597539901733398
Validation loss: 2.1085818807284036

Epoch: 6| Step: 1
Training loss: 0.9741244316101074
Validation loss: 2.0909386475880942

Epoch: 6| Step: 2
Training loss: 1.1357355117797852
Validation loss: 2.0941177010536194

Epoch: 6| Step: 3
Training loss: 0.9245961308479309
Validation loss: 2.0841978589693704

Epoch: 6| Step: 4
Training loss: 0.821855902671814
Validation loss: 2.1292894085248313

Epoch: 6| Step: 5
Training loss: 0.5954850912094116
Validation loss: 2.1260411938031516

Epoch: 6| Step: 6
Training loss: 1.2302203178405762
Validation loss: 2.135636647542318

Epoch: 6| Step: 7
Training loss: 1.054194450378418
Validation loss: 2.1890604297320047

Epoch: 6| Step: 8
Training loss: 1.070986270904541
Validation loss: 2.1848211884498596

Epoch: 6| Step: 9
Training loss: 1.8408381938934326
Validation loss: 2.1606929699579873

Epoch: 6| Step: 10
Training loss: 0.5712509155273438
Validation loss: 2.1189423402150473

Epoch: 6| Step: 11
Training loss: 0.6960191130638123
Validation loss: 2.1273292700449624

Epoch: 6| Step: 12
Training loss: 1.0560877323150635
Validation loss: 2.078051825364431

Epoch: 6| Step: 13
Training loss: 1.134712815284729
Validation loss: 2.0797696908315024

Epoch: 166| Step: 0
Training loss: 0.8173986673355103
Validation loss: 2.1091491977373757

Epoch: 6| Step: 1
Training loss: 0.9308323860168457
Validation loss: 2.059439222017924

Epoch: 6| Step: 2
Training loss: 0.7555571794509888
Validation loss: 2.1077793637911477

Epoch: 6| Step: 3
Training loss: 1.0329413414001465
Validation loss: 2.068157414595286

Epoch: 6| Step: 4
Training loss: 1.0172139406204224
Validation loss: 2.0707009633382163

Epoch: 6| Step: 5
Training loss: 1.1925549507141113
Validation loss: 2.0906633933385215

Epoch: 6| Step: 6
Training loss: 1.3732986450195312
Validation loss: 2.110966165860494

Epoch: 6| Step: 7
Training loss: 0.8385733962059021
Validation loss: 2.144649783770243

Epoch: 6| Step: 8
Training loss: 1.455195426940918
Validation loss: 2.1821369926134744

Epoch: 6| Step: 9
Training loss: 1.2831920385360718
Validation loss: 2.196783204873403

Epoch: 6| Step: 10
Training loss: 1.0244710445404053
Validation loss: 2.114886442820231

Epoch: 6| Step: 11
Training loss: 1.080145001411438
Validation loss: 2.100823918978373

Epoch: 6| Step: 12
Training loss: 1.0720367431640625
Validation loss: 2.0822046597798667

Epoch: 6| Step: 13
Training loss: 0.5164142847061157
Validation loss: 2.095018486181895

Epoch: 167| Step: 0
Training loss: 0.8935244679450989
Validation loss: 2.0824461380640664

Epoch: 6| Step: 1
Training loss: 0.9251803755760193
Validation loss: 2.101434071858724

Epoch: 6| Step: 2
Training loss: 0.817878782749176
Validation loss: 2.1119867960611978

Epoch: 6| Step: 3
Training loss: 1.0826510190963745
Validation loss: 2.06984814008077

Epoch: 6| Step: 4
Training loss: 0.6582454442977905
Validation loss: 2.091921945412954

Epoch: 6| Step: 5
Training loss: 0.7617499828338623
Validation loss: 2.0794875820477805

Epoch: 6| Step: 6
Training loss: 0.8443374633789062
Validation loss: 2.1147696375846863

Epoch: 6| Step: 7
Training loss: 0.6241989135742188
Validation loss: 2.107605218887329

Epoch: 6| Step: 8
Training loss: 1.758242130279541
Validation loss: 2.0734641949335733

Epoch: 6| Step: 9
Training loss: 1.0617687702178955
Validation loss: 2.109447697798411

Epoch: 6| Step: 10
Training loss: 0.9394412040710449
Validation loss: 2.1367200215657554

Epoch: 6| Step: 11
Training loss: 1.284440517425537
Validation loss: 2.1360615491867065

Epoch: 6| Step: 12
Training loss: 0.9691029787063599
Validation loss: 2.090811332066854

Epoch: 6| Step: 13
Training loss: 0.7286980152130127
Validation loss: 2.0722932616869607

Epoch: 168| Step: 0
Training loss: 0.6308797597885132
Validation loss: 2.1577104330062866

Epoch: 6| Step: 1
Training loss: 0.7895921468734741
Validation loss: 2.115983804066976

Epoch: 6| Step: 2
Training loss: 0.6382671594619751
Validation loss: 2.1273892919222512

Epoch: 6| Step: 3
Training loss: 1.288503646850586
Validation loss: 2.0884023110071817

Epoch: 6| Step: 4
Training loss: 1.0753401517868042
Validation loss: 2.0738909244537354

Epoch: 6| Step: 5
Training loss: 0.8992908596992493
Validation loss: 2.1005579630533853

Epoch: 6| Step: 6
Training loss: 0.7407203912734985
Validation loss: 2.036593039830526

Epoch: 6| Step: 7
Training loss: 1.3799759149551392
Validation loss: 2.078671673933665

Epoch: 6| Step: 8
Training loss: 0.839034914970398
Validation loss: 2.093732992808024

Epoch: 6| Step: 9
Training loss: 1.3150168657302856
Validation loss: 2.0911889473597207

Epoch: 6| Step: 10
Training loss: 0.4598773717880249
Validation loss: 2.1315044164657593

Epoch: 6| Step: 11
Training loss: 1.2133502960205078
Validation loss: 2.1733041405677795

Epoch: 6| Step: 12
Training loss: 0.8829350471496582
Validation loss: 2.1116103331247964

Epoch: 6| Step: 13
Training loss: 1.327901840209961
Validation loss: 2.1556957165400186

Epoch: 169| Step: 0
Training loss: 1.0333993434906006
Validation loss: 2.113584558169047

Epoch: 6| Step: 1
Training loss: 0.8342453837394714
Validation loss: 2.131814400355021

Epoch: 6| Step: 2
Training loss: 1.0694327354431152
Validation loss: 2.1050028800964355

Epoch: 6| Step: 3
Training loss: 0.9089769124984741
Validation loss: 2.0572858452796936

Epoch: 6| Step: 4
Training loss: 0.8165150880813599
Validation loss: 2.0956836541493735

Epoch: 6| Step: 5
Training loss: 0.9824976325035095
Validation loss: 2.116408109664917

Epoch: 6| Step: 6
Training loss: 1.1298069953918457
Validation loss: 2.0449409087498984

Epoch: 6| Step: 7
Training loss: 0.4783649444580078
Validation loss: 2.0524646242459617

Epoch: 6| Step: 8
Training loss: 1.2567269802093506
Validation loss: 2.088827987511953

Epoch: 6| Step: 9
Training loss: 0.5775192975997925
Validation loss: 2.0643908778826394

Epoch: 6| Step: 10
Training loss: 1.6718398332595825
Validation loss: 2.1317527691523233

Epoch: 6| Step: 11
Training loss: 0.873098611831665
Validation loss: 2.0985737840334573

Epoch: 6| Step: 12
Training loss: 0.6990436911582947
Validation loss: 2.0939780871073403

Epoch: 6| Step: 13
Training loss: 0.6855719685554504
Validation loss: 2.075776914755503

Epoch: 170| Step: 0
Training loss: 1.0064539909362793
Validation loss: 2.116822838783264

Epoch: 6| Step: 1
Training loss: 1.0033824443817139
Validation loss: 2.113029678662618

Epoch: 6| Step: 2
Training loss: 0.7379601001739502
Validation loss: 2.0812602837880454

Epoch: 6| Step: 3
Training loss: 0.782795786857605
Validation loss: 2.0856029788653054

Epoch: 6| Step: 4
Training loss: 0.9603879451751709
Validation loss: 2.1312437653541565

Epoch: 6| Step: 5
Training loss: 1.028464913368225
Validation loss: 2.1211469372113547

Epoch: 6| Step: 6
Training loss: 1.3874508142471313
Validation loss: 2.0968465010325112

Epoch: 6| Step: 7
Training loss: 0.9988356232643127
Validation loss: 2.1209904750188193

Epoch: 6| Step: 8
Training loss: 0.6183493137359619
Validation loss: 2.072702725728353

Epoch: 6| Step: 9
Training loss: 0.6617733836174011
Validation loss: 2.091730852921804

Epoch: 6| Step: 10
Training loss: 1.0831952095031738
Validation loss: 2.0913589000701904

Epoch: 6| Step: 11
Training loss: 0.7125296592712402
Validation loss: 2.097265601158142

Epoch: 6| Step: 12
Training loss: 0.8100219368934631
Validation loss: 2.0876936117808023

Epoch: 6| Step: 13
Training loss: 1.5299344062805176
Validation loss: 2.0864623188972473

Epoch: 171| Step: 0
Training loss: 1.0348210334777832
Validation loss: 2.0857823292414346

Epoch: 6| Step: 1
Training loss: 1.370445966720581
Validation loss: 2.067888617515564

Epoch: 6| Step: 2
Training loss: 0.8188742995262146
Validation loss: 2.0923217137654624

Epoch: 6| Step: 3
Training loss: 0.8608648777008057
Validation loss: 2.094687501589457

Epoch: 6| Step: 4
Training loss: 0.7110115885734558
Validation loss: 2.1599191625912986

Epoch: 6| Step: 5
Training loss: 0.958560049533844
Validation loss: 2.104446311791738

Epoch: 6| Step: 6
Training loss: 0.8761000633239746
Validation loss: 2.0947761138280234

Epoch: 6| Step: 7
Training loss: 0.8642128705978394
Validation loss: 2.11616317431132

Epoch: 6| Step: 8
Training loss: 0.7392653822898865
Validation loss: 2.099558711051941

Epoch: 6| Step: 9
Training loss: 1.3484655618667603
Validation loss: 2.133224884668986

Epoch: 6| Step: 10
Training loss: 0.9836738109588623
Validation loss: 2.1452305714289346

Epoch: 6| Step: 11
Training loss: 0.8242319226264954
Validation loss: 2.1523624857266745

Epoch: 6| Step: 12
Training loss: 0.7729589939117432
Validation loss: 2.1114051143328347

Epoch: 6| Step: 13
Training loss: 0.6685579419136047
Validation loss: 2.095421294371287

Epoch: 172| Step: 0
Training loss: 1.1680619716644287
Validation loss: 2.107888400554657

Epoch: 6| Step: 1
Training loss: 0.861745297908783
Validation loss: 2.1169204115867615

Epoch: 6| Step: 2
Training loss: 1.1795768737792969
Validation loss: 2.0662395556767783

Epoch: 6| Step: 3
Training loss: 0.985258936882019
Validation loss: 2.112505475680033

Epoch: 6| Step: 4
Training loss: 0.9300310611724854
Validation loss: 2.106745441754659

Epoch: 6| Step: 5
Training loss: 1.0586693286895752
Validation loss: 2.1702515482902527

Epoch: 6| Step: 6
Training loss: 1.523787021636963
Validation loss: 2.094884475072225

Epoch: 6| Step: 7
Training loss: 1.1315914392471313
Validation loss: 2.104674061139425

Epoch: 6| Step: 8
Training loss: 1.0225846767425537
Validation loss: 2.1062646309534707

Epoch: 6| Step: 9
Training loss: 0.4363664984703064
Validation loss: 2.1356013417243958

Epoch: 6| Step: 10
Training loss: 0.856143593788147
Validation loss: 2.086788018544515

Epoch: 6| Step: 11
Training loss: 0.5749780535697937
Validation loss: 2.0690787633260093

Epoch: 6| Step: 12
Training loss: 0.5539878606796265
Validation loss: 2.11871991554896

Epoch: 6| Step: 13
Training loss: 0.9624200463294983
Validation loss: 2.097809930642446

Epoch: 173| Step: 0
Training loss: 1.021628499031067
Validation loss: 2.0434271097183228

Epoch: 6| Step: 1
Training loss: 0.8930619359016418
Validation loss: 2.093006193637848

Epoch: 6| Step: 2
Training loss: 1.351045846939087
Validation loss: 2.1080907583236694

Epoch: 6| Step: 3
Training loss: 1.1460306644439697
Validation loss: 2.069015463193258

Epoch: 6| Step: 4
Training loss: 1.4893726110458374
Validation loss: 2.1596853335698447

Epoch: 6| Step: 5
Training loss: 0.6008042693138123
Validation loss: 2.165116548538208

Epoch: 6| Step: 6
Training loss: 0.6010355949401855
Validation loss: 2.0940744479497275

Epoch: 6| Step: 7
Training loss: 0.33480244874954224
Validation loss: 2.1381986339886985

Epoch: 6| Step: 8
Training loss: 1.011582851409912
Validation loss: 2.112268110116323

Epoch: 6| Step: 9
Training loss: 1.0033074617385864
Validation loss: 2.1252344051996865

Epoch: 6| Step: 10
Training loss: 0.9295430183410645
Validation loss: 2.08489982287089

Epoch: 6| Step: 11
Training loss: 0.8057510852813721
Validation loss: 2.0573822061220803

Epoch: 6| Step: 12
Training loss: 0.8125650882720947
Validation loss: 2.0913018584251404

Epoch: 6| Step: 13
Training loss: 0.6165384650230408
Validation loss: 2.044382174809774

Epoch: 174| Step: 0
Training loss: 1.4095104932785034
Validation loss: 2.101125637690226

Epoch: 6| Step: 1
Training loss: 0.5846880078315735
Validation loss: 2.082261860370636

Epoch: 6| Step: 2
Training loss: 1.2201247215270996
Validation loss: 2.071223497390747

Epoch: 6| Step: 3
Training loss: 0.8679503202438354
Validation loss: 2.0930221478144326

Epoch: 6| Step: 4
Training loss: 1.1333650350570679
Validation loss: 2.0965579549471536

Epoch: 6| Step: 5
Training loss: 0.8627464771270752
Validation loss: 2.1149472196896872

Epoch: 6| Step: 6
Training loss: 0.834047794342041
Validation loss: 2.1450859904289246

Epoch: 6| Step: 7
Training loss: 1.0188895463943481
Validation loss: 2.1512285470962524

Epoch: 6| Step: 8
Training loss: 0.5080995559692383
Validation loss: 2.102525075276693

Epoch: 6| Step: 9
Training loss: 0.8179870247840881
Validation loss: 2.1124244133631387

Epoch: 6| Step: 10
Training loss: 0.9572927355766296
Validation loss: 2.0593062043190002

Epoch: 6| Step: 11
Training loss: 1.693094253540039
Validation loss: 2.094797889391581

Epoch: 6| Step: 12
Training loss: 0.5578780174255371
Validation loss: 2.0735976298650107

Epoch: 6| Step: 13
Training loss: 0.9099302291870117
Validation loss: 2.066858152548472

Epoch: 175| Step: 0
Training loss: 0.5910025835037231
Validation loss: 2.09418394168218

Epoch: 6| Step: 1
Training loss: 1.0255918502807617
Validation loss: 2.123803714911143

Epoch: 6| Step: 2
Training loss: 0.47324511408805847
Validation loss: 2.0939956108729043

Epoch: 6| Step: 3
Training loss: 1.2017992734909058
Validation loss: 2.110629975795746

Epoch: 6| Step: 4
Training loss: 1.2836582660675049
Validation loss: 2.1389465729395547

Epoch: 6| Step: 5
Training loss: 1.071582317352295
Validation loss: 2.1344141562779746

Epoch: 6| Step: 6
Training loss: 0.524085283279419
Validation loss: 2.1236406167348227

Epoch: 6| Step: 7
Training loss: 1.064825177192688
Validation loss: 2.1486125191052756

Epoch: 6| Step: 8
Training loss: 0.9141982793807983
Validation loss: 2.139200965563456

Epoch: 6| Step: 9
Training loss: 1.096118450164795
Validation loss: 2.0943981409072876

Epoch: 6| Step: 10
Training loss: 0.5374191999435425
Validation loss: 2.1451014280319214

Epoch: 6| Step: 11
Training loss: 0.4921793043613434
Validation loss: 2.1234822869300842

Epoch: 6| Step: 12
Training loss: 1.1104097366333008
Validation loss: 2.0615739822387695

Epoch: 6| Step: 13
Training loss: 1.099846601486206
Validation loss: 2.0816147526105246

Epoch: 176| Step: 0
Training loss: 1.1034748554229736
Validation loss: 2.101638436317444

Epoch: 6| Step: 1
Training loss: 0.9312856793403625
Validation loss: 2.0869314869244895

Epoch: 6| Step: 2
Training loss: 0.9025216102600098
Validation loss: 2.0722840229670205

Epoch: 6| Step: 3
Training loss: 0.8375728130340576
Validation loss: 2.0821385780970254

Epoch: 6| Step: 4
Training loss: 1.0358622074127197
Validation loss: 2.0887323021888733

Epoch: 6| Step: 5
Training loss: 1.0648831129074097
Validation loss: 2.111574868361155

Epoch: 6| Step: 6
Training loss: 0.3958362638950348
Validation loss: 2.0953754782676697

Epoch: 6| Step: 7
Training loss: 0.5803886651992798
Validation loss: 2.072958827018738

Epoch: 6| Step: 8
Training loss: 0.9210008978843689
Validation loss: 2.0642863512039185

Epoch: 6| Step: 9
Training loss: 0.8693161606788635
Validation loss: 2.1234925389289856

Epoch: 6| Step: 10
Training loss: 1.0486544370651245
Validation loss: 2.105884393056234

Epoch: 6| Step: 11
Training loss: 0.7576881647109985
Validation loss: 2.07287726799647

Epoch: 6| Step: 12
Training loss: 0.7116923332214355
Validation loss: 2.1344864765803018

Epoch: 6| Step: 13
Training loss: 1.1506009101867676
Validation loss: 2.134155531724294

Epoch: 177| Step: 0
Training loss: 0.9534651041030884
Validation loss: 2.0588022271792092

Epoch: 6| Step: 1
Training loss: 0.5623394846916199
Validation loss: 2.092785199483236

Epoch: 6| Step: 2
Training loss: 0.5884711742401123
Validation loss: 2.0731002489725747

Epoch: 6| Step: 3
Training loss: 1.6600501537322998
Validation loss: 2.08159073193868

Epoch: 6| Step: 4
Training loss: 0.8258918523788452
Validation loss: 2.0656752983729043

Epoch: 6| Step: 5
Training loss: 0.5731860995292664
Validation loss: 2.036699573198954

Epoch: 6| Step: 6
Training loss: 0.7209993004798889
Validation loss: 2.088938295841217

Epoch: 6| Step: 7
Training loss: 0.9963656663894653
Validation loss: 2.1043105125427246

Epoch: 6| Step: 8
Training loss: 0.7069680690765381
Validation loss: 2.118388056755066

Epoch: 6| Step: 9
Training loss: 0.7888026237487793
Validation loss: 2.083532154560089

Epoch: 6| Step: 10
Training loss: 1.0243151187896729
Validation loss: 2.109882573286692

Epoch: 6| Step: 11
Training loss: 0.8087993860244751
Validation loss: 2.1627963383992515

Epoch: 6| Step: 12
Training loss: 1.1043024063110352
Validation loss: 2.1364132364590964

Epoch: 6| Step: 13
Training loss: 1.085291862487793
Validation loss: 2.0940098762512207

Epoch: 178| Step: 0
Training loss: 0.7402222156524658
Validation loss: 2.0834848483403525

Epoch: 6| Step: 1
Training loss: 1.6321301460266113
Validation loss: 2.1036476492881775

Epoch: 6| Step: 2
Training loss: 1.1925455331802368
Validation loss: 2.0928717454274497

Epoch: 6| Step: 3
Training loss: 0.9348452091217041
Validation loss: 2.102262775103251

Epoch: 6| Step: 4
Training loss: 0.881530225276947
Validation loss: 2.111247460047404

Epoch: 6| Step: 5
Training loss: 0.7804847955703735
Validation loss: 2.0743303298950195

Epoch: 6| Step: 6
Training loss: 0.7069056630134583
Validation loss: 2.0762767791748047

Epoch: 6| Step: 7
Training loss: 0.7404260635375977
Validation loss: 2.0881675084431968

Epoch: 6| Step: 8
Training loss: 0.6976438760757446
Validation loss: 2.0822954773902893

Epoch: 6| Step: 9
Training loss: 0.6953191757202148
Validation loss: 2.081238547960917

Epoch: 6| Step: 10
Training loss: 0.9138674736022949
Validation loss: 2.0484171907107034

Epoch: 6| Step: 11
Training loss: 0.6264917850494385
Validation loss: 2.0643513401349387

Epoch: 6| Step: 12
Training loss: 0.7649309635162354
Validation loss: 2.057263135910034

Epoch: 6| Step: 13
Training loss: 1.0629907846450806
Validation loss: 2.1019528905550637

Epoch: 179| Step: 0
Training loss: 0.8909081220626831
Validation loss: 2.0268848737080893

Epoch: 6| Step: 1
Training loss: 0.48539718985557556
Validation loss: 2.078596035639445

Epoch: 6| Step: 2
Training loss: 0.8134174942970276
Validation loss: 2.0590830643971763

Epoch: 6| Step: 3
Training loss: 0.9429039359092712
Validation loss: 2.0633382002512612

Epoch: 6| Step: 4
Training loss: 0.8657071590423584
Validation loss: 2.0463741620381675

Epoch: 6| Step: 5
Training loss: 1.3336584568023682
Validation loss: 2.089454690615336

Epoch: 6| Step: 6
Training loss: 0.5497267842292786
Validation loss: 2.0925319592158

Epoch: 6| Step: 7
Training loss: 0.79155433177948
Validation loss: 2.0710677107175193

Epoch: 6| Step: 8
Training loss: 0.9612332582473755
Validation loss: 2.116301655769348

Epoch: 6| Step: 9
Training loss: 0.7461560964584351
Validation loss: 2.0734780629475913

Epoch: 6| Step: 10
Training loss: 0.6201796531677246
Validation loss: 2.066574136416117

Epoch: 6| Step: 11
Training loss: 0.9397149085998535
Validation loss: 2.1510074138641357

Epoch: 6| Step: 12
Training loss: 1.1359803676605225
Validation loss: 2.1359243988990784

Epoch: 6| Step: 13
Training loss: 0.9770543575286865
Validation loss: 2.0999639431635537

Epoch: 180| Step: 0
Training loss: 1.0951862335205078
Validation loss: 2.0915048718452454

Epoch: 6| Step: 1
Training loss: 0.6079243421554565
Validation loss: 2.0560456911722818

Epoch: 6| Step: 2
Training loss: 0.5595902800559998
Validation loss: 2.1133843262990317

Epoch: 6| Step: 3
Training loss: 1.0370560884475708
Validation loss: 2.1236319343249

Epoch: 6| Step: 4
Training loss: 0.6966968178749084
Validation loss: 2.1325305302937827

Epoch: 6| Step: 5
Training loss: 1.334498405456543
Validation loss: 2.130708614985148

Epoch: 6| Step: 6
Training loss: 1.0583734512329102
Validation loss: 2.098445256551107

Epoch: 6| Step: 7
Training loss: 0.6250445246696472
Validation loss: 2.1216788490613303

Epoch: 6| Step: 8
Training loss: 0.7599405646324158
Validation loss: 2.119283159573873

Epoch: 6| Step: 9
Training loss: 1.2152141332626343
Validation loss: 2.0894436637560525

Epoch: 6| Step: 10
Training loss: 0.5707147121429443
Validation loss: 2.116624573866526

Epoch: 6| Step: 11
Training loss: 0.8303496837615967
Validation loss: 2.0948506593704224

Epoch: 6| Step: 12
Training loss: 0.7968862056732178
Validation loss: 2.0983076890309653

Epoch: 6| Step: 13
Training loss: 0.7565126419067383
Validation loss: 2.093290646870931

Epoch: 181| Step: 0
Training loss: 0.8268613815307617
Validation loss: 2.0707724889119468

Epoch: 6| Step: 1
Training loss: 0.8283364176750183
Validation loss: 2.08079065879186

Epoch: 6| Step: 2
Training loss: 0.7033178806304932
Validation loss: 2.0623177886009216

Epoch: 6| Step: 3
Training loss: 0.41265013813972473
Validation loss: 2.1165370543797812

Epoch: 6| Step: 4
Training loss: 0.8661733269691467
Validation loss: 2.088344613711039

Epoch: 6| Step: 5
Training loss: 0.8848215341567993
Validation loss: 2.0437480409940085

Epoch: 6| Step: 6
Training loss: 0.7712578773498535
Validation loss: 2.105501373608907

Epoch: 6| Step: 7
Training loss: 0.6808528900146484
Validation loss: 2.10831489165624

Epoch: 6| Step: 8
Training loss: 1.0223881006240845
Validation loss: 2.1574957569440207

Epoch: 6| Step: 9
Training loss: 0.8473753333091736
Validation loss: 2.147568464279175

Epoch: 6| Step: 10
Training loss: 1.3948554992675781
Validation loss: 2.1266656716664634

Epoch: 6| Step: 11
Training loss: 1.0108921527862549
Validation loss: 2.1022583643595376

Epoch: 6| Step: 12
Training loss: 0.7349540591239929
Validation loss: 2.096658706665039

Epoch: 6| Step: 13
Training loss: 0.9922721982002258
Validation loss: 2.1113462249437966

Epoch: 182| Step: 0
Training loss: 0.5116163492202759
Validation loss: 2.076081693172455

Epoch: 6| Step: 1
Training loss: 0.8701581358909607
Validation loss: 2.0871214667956033

Epoch: 6| Step: 2
Training loss: 1.1443756818771362
Validation loss: 2.103032390276591

Epoch: 6| Step: 3
Training loss: 0.41679325699806213
Validation loss: 2.1341148614883423

Epoch: 6| Step: 4
Training loss: 1.0986766815185547
Validation loss: 2.1126843293507895

Epoch: 6| Step: 5
Training loss: 0.8328828811645508
Validation loss: 2.0792450110117593

Epoch: 6| Step: 6
Training loss: 0.7303226590156555
Validation loss: 2.1044281125068665

Epoch: 6| Step: 7
Training loss: 0.8205724954605103
Validation loss: 2.1244117816289267

Epoch: 6| Step: 8
Training loss: 0.6358275413513184
Validation loss: 2.102269450823466

Epoch: 6| Step: 9
Training loss: 0.6760302782058716
Validation loss: 2.1487711469332376

Epoch: 6| Step: 10
Training loss: 0.9149231910705566
Validation loss: 2.106854955355326

Epoch: 6| Step: 11
Training loss: 1.2590683698654175
Validation loss: 2.0757335424423218

Epoch: 6| Step: 12
Training loss: 1.1354588270187378
Validation loss: 2.1210209131240845

Epoch: 6| Step: 13
Training loss: 0.7899342775344849
Validation loss: 2.1323907176653543

Epoch: 183| Step: 0
Training loss: 1.0332491397857666
Validation loss: 2.1148423155148826

Epoch: 6| Step: 1
Training loss: 0.8676364421844482
Validation loss: 2.0898626844088235

Epoch: 6| Step: 2
Training loss: 0.5184299945831299
Validation loss: 2.070747216542562

Epoch: 6| Step: 3
Training loss: 0.5900480151176453
Validation loss: 2.109247108300527

Epoch: 6| Step: 4
Training loss: 0.42188793420791626
Validation loss: 2.1011866529782615

Epoch: 6| Step: 5
Training loss: 1.1917585134506226
Validation loss: 2.084340254465739

Epoch: 6| Step: 6
Training loss: 0.6649202108383179
Validation loss: 2.1561966935793557

Epoch: 6| Step: 7
Training loss: 1.0822668075561523
Validation loss: 2.1283674438794455

Epoch: 6| Step: 8
Training loss: 0.7650505304336548
Validation loss: 2.1327077349027

Epoch: 6| Step: 9
Training loss: 0.7382341027259827
Validation loss: 2.100738445917765

Epoch: 6| Step: 10
Training loss: 1.5375103950500488
Validation loss: 2.071224848429362

Epoch: 6| Step: 11
Training loss: 0.9333611130714417
Validation loss: 2.074148933092753

Epoch: 6| Step: 12
Training loss: 0.7821313142776489
Validation loss: 2.056008815765381

Epoch: 6| Step: 13
Training loss: 0.6921429634094238
Validation loss: 2.112354834874471

Epoch: 184| Step: 0
Training loss: 0.8191644549369812
Validation loss: 2.104698439439138

Epoch: 6| Step: 1
Training loss: 0.7845636010169983
Validation loss: 2.1035452485084534

Epoch: 6| Step: 2
Training loss: 1.081963062286377
Validation loss: 2.140712082386017

Epoch: 6| Step: 3
Training loss: 1.1135826110839844
Validation loss: 2.1685717900594077

Epoch: 6| Step: 4
Training loss: 0.7611410617828369
Validation loss: 2.145726482073466

Epoch: 6| Step: 5
Training loss: 0.8423385620117188
Validation loss: 2.102576990922292

Epoch: 6| Step: 6
Training loss: 0.5455435514450073
Validation loss: 2.153794546922048

Epoch: 6| Step: 7
Training loss: 1.457728624343872
Validation loss: 2.129017194112142

Epoch: 6| Step: 8
Training loss: 1.405239462852478
Validation loss: 2.101386805375417

Epoch: 6| Step: 9
Training loss: 0.813920259475708
Validation loss: 2.0699205001195273

Epoch: 6| Step: 10
Training loss: 0.6202453970909119
Validation loss: 2.122785051663717

Epoch: 6| Step: 11
Training loss: 0.6821549534797668
Validation loss: 2.0380251010258994

Epoch: 6| Step: 12
Training loss: 0.7878046631813049
Validation loss: 2.0911306142807007

Epoch: 6| Step: 13
Training loss: 0.5226147770881653
Validation loss: 2.1171027024586997

Epoch: 185| Step: 0
Training loss: 1.3853983879089355
Validation loss: 2.133253812789917

Epoch: 6| Step: 1
Training loss: 0.37099799513816833
Validation loss: 2.078437646230062

Epoch: 6| Step: 2
Training loss: 1.2190495729446411
Validation loss: 2.1101091504096985

Epoch: 6| Step: 3
Training loss: 0.9122046232223511
Validation loss: 2.1012727419535318

Epoch: 6| Step: 4
Training loss: 1.0672647953033447
Validation loss: 2.1068606774012246

Epoch: 6| Step: 5
Training loss: 0.9253392815589905
Validation loss: 2.133622328440348

Epoch: 6| Step: 6
Training loss: 0.7812772989273071
Validation loss: 2.146657725175222

Epoch: 6| Step: 7
Training loss: 0.3304499387741089
Validation loss: 2.1101209123929343

Epoch: 6| Step: 8
Training loss: 0.7015005350112915
Validation loss: 2.074065546194712

Epoch: 6| Step: 9
Training loss: 0.570137619972229
Validation loss: 2.1128299037615457

Epoch: 6| Step: 10
Training loss: 0.6888574361801147
Validation loss: 2.1096256573994956

Epoch: 6| Step: 11
Training loss: 0.43947067856788635
Validation loss: 2.0664865175882974

Epoch: 6| Step: 12
Training loss: 1.286892294883728
Validation loss: 2.08744349082311

Epoch: 6| Step: 13
Training loss: 1.0102770328521729
Validation loss: 2.0701163609822593

Epoch: 186| Step: 0
Training loss: 0.8485838770866394
Validation loss: 2.1009581089019775

Epoch: 6| Step: 1
Training loss: 0.8946332931518555
Validation loss: 2.1002148191134133

Epoch: 6| Step: 2
Training loss: 1.1506783962249756
Validation loss: 2.131104369958242

Epoch: 6| Step: 3
Training loss: 0.47826772928237915
Validation loss: 2.1432941357294717

Epoch: 6| Step: 4
Training loss: 0.5044540166854858
Validation loss: 2.144574304421743

Epoch: 6| Step: 5
Training loss: 1.2195419073104858
Validation loss: 2.1423800786336265

Epoch: 6| Step: 6
Training loss: 1.0091371536254883
Validation loss: 2.105023125807444

Epoch: 6| Step: 7
Training loss: 0.8380153179168701
Validation loss: 2.083048681418101

Epoch: 6| Step: 8
Training loss: 0.8695000410079956
Validation loss: 2.0931878884633384

Epoch: 6| Step: 9
Training loss: 0.7625480890274048
Validation loss: 2.0968111157417297

Epoch: 6| Step: 10
Training loss: 0.35434383153915405
Validation loss: 2.047706663608551

Epoch: 6| Step: 11
Training loss: 1.2618355751037598
Validation loss: 2.111526449521383

Epoch: 6| Step: 12
Training loss: 0.981436014175415
Validation loss: 2.096306880315145

Epoch: 6| Step: 13
Training loss: 0.49073562026023865
Validation loss: 2.0853257377942405

Epoch: 187| Step: 0
Training loss: 0.3517581820487976
Validation loss: 2.074002722899119

Epoch: 6| Step: 1
Training loss: 0.7246909141540527
Validation loss: 2.1135696172714233

Epoch: 6| Step: 2
Training loss: 0.6648614406585693
Validation loss: 2.095617175102234

Epoch: 6| Step: 3
Training loss: 0.5562747716903687
Validation loss: 2.1051767667134604

Epoch: 6| Step: 4
Training loss: 0.7070106863975525
Validation loss: 2.1224907835324607

Epoch: 6| Step: 5
Training loss: 0.9260162711143494
Validation loss: 2.1294724146525064

Epoch: 6| Step: 6
Training loss: 0.7873498201370239
Validation loss: 2.183513601620992

Epoch: 6| Step: 7
Training loss: 1.018468976020813
Validation loss: 2.1325635512669883

Epoch: 6| Step: 8
Training loss: 1.100769281387329
Validation loss: 2.1159208019574485

Epoch: 6| Step: 9
Training loss: 0.6763103604316711
Validation loss: 2.070280353228251

Epoch: 6| Step: 10
Training loss: 0.8782152533531189
Validation loss: 2.056385040283203

Epoch: 6| Step: 11
Training loss: 0.9447492361068726
Validation loss: 2.0404059290885925

Epoch: 6| Step: 12
Training loss: 0.6960275769233704
Validation loss: 2.072392245133718

Epoch: 6| Step: 13
Training loss: 1.341166377067566
Validation loss: 2.1210064689318338

Epoch: 188| Step: 0
Training loss: 0.8686230182647705
Validation loss: 2.0561135013898215

Epoch: 6| Step: 1
Training loss: 1.5866239070892334
Validation loss: 2.1026253700256348

Epoch: 6| Step: 2
Training loss: 0.33783966302871704
Validation loss: 2.045639435450236

Epoch: 6| Step: 3
Training loss: 0.8592556715011597
Validation loss: 2.1003316839536033

Epoch: 6| Step: 4
Training loss: 1.0141769647598267
Validation loss: 2.098812480767568

Epoch: 6| Step: 5
Training loss: 1.0247315168380737
Validation loss: 2.1359468698501587

Epoch: 6| Step: 6
Training loss: 1.0930927991867065
Validation loss: 2.0937888423601785

Epoch: 6| Step: 7
Training loss: 1.0520453453063965
Validation loss: 2.122360408306122

Epoch: 6| Step: 8
Training loss: 0.44053521752357483
Validation loss: 2.0922951698303223

Epoch: 6| Step: 9
Training loss: 1.0325441360473633
Validation loss: 2.037760376930237

Epoch: 6| Step: 10
Training loss: 0.627241849899292
Validation loss: 2.056887984275818

Epoch: 6| Step: 11
Training loss: 0.8458237648010254
Validation loss: 2.0572816729545593

Epoch: 6| Step: 12
Training loss: 0.46447068452835083
Validation loss: 2.1201052069664

Epoch: 6| Step: 13
Training loss: 0.6542375087738037
Validation loss: 2.142356057961782

Epoch: 189| Step: 0
Training loss: 0.9999602437019348
Validation loss: 2.0994020104408264

Epoch: 6| Step: 1
Training loss: 1.223914623260498
Validation loss: 2.1106908520062766

Epoch: 6| Step: 2
Training loss: 0.6991169452667236
Validation loss: 2.076224684715271

Epoch: 6| Step: 3
Training loss: 0.6598541736602783
Validation loss: 2.1104689637819924

Epoch: 6| Step: 4
Training loss: 0.8881434202194214
Validation loss: 2.171476205190023

Epoch: 6| Step: 5
Training loss: 1.3423526287078857
Validation loss: 2.1027797857920327

Epoch: 6| Step: 6
Training loss: 0.5974390506744385
Validation loss: 2.1033567587534585

Epoch: 6| Step: 7
Training loss: 0.6759927272796631
Validation loss: 2.1228992342948914

Epoch: 6| Step: 8
Training loss: 0.5154184103012085
Validation loss: 2.117702861626943

Epoch: 6| Step: 9
Training loss: 0.4980798065662384
Validation loss: 2.1159791946411133

Epoch: 6| Step: 10
Training loss: 1.2953112125396729
Validation loss: 2.118849734465281

Epoch: 6| Step: 11
Training loss: 0.9601807594299316
Validation loss: 2.095071017742157

Epoch: 6| Step: 12
Training loss: 0.5460593700408936
Validation loss: 2.090423325697581

Epoch: 6| Step: 13
Training loss: 0.6165872812271118
Validation loss: 2.0976916948954263

Epoch: 190| Step: 0
Training loss: 0.6251409649848938
Validation loss: 2.081915636857351

Epoch: 6| Step: 1
Training loss: 0.9177767038345337
Validation loss: 2.113267997900645

Epoch: 6| Step: 2
Training loss: 0.7276836037635803
Validation loss: 2.085454046726227

Epoch: 6| Step: 3
Training loss: 1.077373743057251
Validation loss: 2.0764675736427307

Epoch: 6| Step: 4
Training loss: 0.36827248334884644
Validation loss: 2.1018811066945395

Epoch: 6| Step: 5
Training loss: 0.7819030284881592
Validation loss: 2.086998681227366

Epoch: 6| Step: 6
Training loss: 0.6386322975158691
Validation loss: 2.089206337928772

Epoch: 6| Step: 7
Training loss: 0.7793518304824829
Validation loss: 2.110749304294586

Epoch: 6| Step: 8
Training loss: 0.9136943817138672
Validation loss: 2.09917159875234

Epoch: 6| Step: 9
Training loss: 0.5834455490112305
Validation loss: 2.0875731309254966

Epoch: 6| Step: 10
Training loss: 1.3077369928359985
Validation loss: 2.0839494466781616

Epoch: 6| Step: 11
Training loss: 1.084453821182251
Validation loss: 2.0654549400011697

Epoch: 6| Step: 12
Training loss: 0.8010711669921875
Validation loss: 2.0859217047691345

Epoch: 6| Step: 13
Training loss: 0.5225296020507812
Validation loss: 2.1523956656455994

Epoch: 191| Step: 0
Training loss: 1.2554067373275757
Validation loss: 2.1135854721069336

Epoch: 6| Step: 1
Training loss: 1.1771557331085205
Validation loss: 2.1255335807800293

Epoch: 6| Step: 2
Training loss: 0.42951130867004395
Validation loss: 2.1207595666249595

Epoch: 6| Step: 3
Training loss: 0.631879448890686
Validation loss: 2.0703912576039634

Epoch: 6| Step: 4
Training loss: 0.860108494758606
Validation loss: 2.128077983856201

Epoch: 6| Step: 5
Training loss: 1.2571933269500732
Validation loss: 2.0492197473843894

Epoch: 6| Step: 6
Training loss: 0.5148588418960571
Validation loss: 2.0715123613675437

Epoch: 6| Step: 7
Training loss: 0.7656702399253845
Validation loss: 2.1113945841789246

Epoch: 6| Step: 8
Training loss: 0.6969732046127319
Validation loss: 2.0951598286628723

Epoch: 6| Step: 9
Training loss: 0.49075788259506226
Validation loss: 2.108746349811554

Epoch: 6| Step: 10
Training loss: 1.2254475355148315
Validation loss: 2.0893721183141074

Epoch: 6| Step: 11
Training loss: 0.8277802467346191
Validation loss: 2.075507620970408

Epoch: 6| Step: 12
Training loss: 0.38626915216445923
Validation loss: 2.0843281149864197

Epoch: 6| Step: 13
Training loss: 0.7213525772094727
Validation loss: 2.0884824792544046

Epoch: 192| Step: 0
Training loss: 0.39756864309310913
Validation loss: 2.0691471894582114

Epoch: 6| Step: 1
Training loss: 0.7499425411224365
Validation loss: 2.0460344155629477

Epoch: 6| Step: 2
Training loss: 0.44268861413002014
Validation loss: 2.10308047135671

Epoch: 6| Step: 3
Training loss: 0.9854766130447388
Validation loss: 2.1507833997408548

Epoch: 6| Step: 4
Training loss: 0.8663373589515686
Validation loss: 2.109860976537069

Epoch: 6| Step: 5
Training loss: 0.7612540125846863
Validation loss: 2.1051788131395974

Epoch: 6| Step: 6
Training loss: 0.6724716424942017
Validation loss: 2.0753276149431863

Epoch: 6| Step: 7
Training loss: 1.0857017040252686
Validation loss: 2.165388504664103

Epoch: 6| Step: 8
Training loss: 1.2043559551239014
Validation loss: 2.0871094266573587

Epoch: 6| Step: 9
Training loss: 0.6909534931182861
Validation loss: 2.0853882431983948

Epoch: 6| Step: 10
Training loss: 0.9430031776428223
Validation loss: 2.086192230383555

Epoch: 6| Step: 11
Training loss: 0.6827288866043091
Validation loss: 2.0890315175056458

Epoch: 6| Step: 12
Training loss: 0.6918011903762817
Validation loss: 2.0816405614217124

Epoch: 6| Step: 13
Training loss: 0.6029770970344543
Validation loss: 2.0831982096036277

Epoch: 193| Step: 0
Training loss: 0.779893159866333
Validation loss: 2.09011439482371

Epoch: 6| Step: 1
Training loss: 0.7500433325767517
Validation loss: 2.1479259729385376

Epoch: 6| Step: 2
Training loss: 0.8031090497970581
Validation loss: 2.1234788298606873

Epoch: 6| Step: 3
Training loss: 0.5529812574386597
Validation loss: 2.108325739701589

Epoch: 6| Step: 4
Training loss: 0.6780775785446167
Validation loss: 2.099291662375132

Epoch: 6| Step: 5
Training loss: 0.707813560962677
Validation loss: 2.0546825329462686

Epoch: 6| Step: 6
Training loss: 0.9544774293899536
Validation loss: 2.1043474078178406

Epoch: 6| Step: 7
Training loss: 1.0496461391448975
Validation loss: 2.026225427786509

Epoch: 6| Step: 8
Training loss: 0.8445910215377808
Validation loss: 2.0340035557746887

Epoch: 6| Step: 9
Training loss: 0.7015653252601624
Validation loss: 2.1244876782099404

Epoch: 6| Step: 10
Training loss: 0.5163125395774841
Validation loss: 2.0978633165359497

Epoch: 6| Step: 11
Training loss: 0.9434154033660889
Validation loss: 2.1212145487467446

Epoch: 6| Step: 12
Training loss: 1.5522847175598145
Validation loss: 2.101665496826172

Epoch: 6| Step: 13
Training loss: 0.3183436393737793
Validation loss: 2.107131242752075

Epoch: 194| Step: 0
Training loss: 0.7687785625457764
Validation loss: 2.0809218287467957

Epoch: 6| Step: 1
Training loss: 1.2282658815383911
Validation loss: 2.0848299662272134

Epoch: 6| Step: 2
Training loss: 1.162123680114746
Validation loss: 2.050124724706014

Epoch: 6| Step: 3
Training loss: 1.2765166759490967
Validation loss: 2.0756866931915283

Epoch: 6| Step: 4
Training loss: 0.9497095942497253
Validation loss: 2.0949092308680215

Epoch: 6| Step: 5
Training loss: 0.7246100902557373
Validation loss: 2.114184240500132

Epoch: 6| Step: 6
Training loss: 0.5899257659912109
Validation loss: 2.1340827345848083

Epoch: 6| Step: 7
Training loss: 0.4545721709728241
Validation loss: 2.08456818262736

Epoch: 6| Step: 8
Training loss: 0.5760923624038696
Validation loss: 2.133050322532654

Epoch: 6| Step: 9
Training loss: 0.5990694165229797
Validation loss: 2.0612591902414956

Epoch: 6| Step: 10
Training loss: 0.8242316246032715
Validation loss: 2.114923059940338

Epoch: 6| Step: 11
Training loss: 0.567716658115387
Validation loss: 2.0356498757998147

Epoch: 6| Step: 12
Training loss: 0.5128760933876038
Validation loss: 2.0539260506629944

Epoch: 6| Step: 13
Training loss: 0.5393565893173218
Validation loss: 2.06623238325119

Epoch: 195| Step: 0
Training loss: 0.6828914880752563
Validation loss: 2.0988051891326904

Epoch: 6| Step: 1
Training loss: 0.9411802887916565
Validation loss: 2.1243004401524863

Epoch: 6| Step: 2
Training loss: 0.7492094039916992
Validation loss: 2.108931561311086

Epoch: 6| Step: 3
Training loss: 0.37199461460113525
Validation loss: 2.093894879023234

Epoch: 6| Step: 4
Training loss: 0.7679555416107178
Validation loss: 2.1309466560681662

Epoch: 6| Step: 5
Training loss: 1.0536515712738037
Validation loss: 2.1370602448781333

Epoch: 6| Step: 6
Training loss: 0.5273358821868896
Validation loss: 2.100794017314911

Epoch: 6| Step: 7
Training loss: 0.9848071336746216
Validation loss: 2.0541600783665976

Epoch: 6| Step: 8
Training loss: 0.43115994334220886
Validation loss: 2.039886216322581

Epoch: 6| Step: 9
Training loss: 1.1900641918182373
Validation loss: 2.087616761525472

Epoch: 6| Step: 10
Training loss: 0.44449901580810547
Validation loss: 2.027517040570577

Epoch: 6| Step: 11
Training loss: 0.7251935601234436
Validation loss: 2.0830694437026978

Epoch: 6| Step: 12
Training loss: 0.5296562314033508
Validation loss: 2.0982482632001243

Epoch: 6| Step: 13
Training loss: 1.1998413801193237
Validation loss: 2.1127222975095115

Epoch: 196| Step: 0
Training loss: 1.0155850648880005
Validation loss: 2.1485559940338135

Epoch: 6| Step: 1
Training loss: 0.7651237845420837
Validation loss: 2.1377599438031516

Epoch: 6| Step: 2
Training loss: 0.49607041478157043
Validation loss: 2.151458660761515

Epoch: 6| Step: 3
Training loss: 0.4994557797908783
Validation loss: 2.1111651261647544

Epoch: 6| Step: 4
Training loss: 0.7499347925186157
Validation loss: 2.0624447067578635

Epoch: 6| Step: 5
Training loss: 0.6277480721473694
Validation loss: 2.0606855750083923

Epoch: 6| Step: 6
Training loss: 0.6815146207809448
Validation loss: 2.0910125176111856

Epoch: 6| Step: 7
Training loss: 0.8412590026855469
Validation loss: 2.1137390534083047

Epoch: 6| Step: 8
Training loss: 0.46530506014823914
Validation loss: 2.1139939427375793

Epoch: 6| Step: 9
Training loss: 1.0613993406295776
Validation loss: 2.091839631398519

Epoch: 6| Step: 10
Training loss: 0.60182124376297
Validation loss: 2.1146745483080545

Epoch: 6| Step: 11
Training loss: 1.5114259719848633
Validation loss: 2.1248494386672974

Epoch: 6| Step: 12
Training loss: 0.8635753393173218
Validation loss: 2.0916404525438943

Epoch: 6| Step: 13
Training loss: 0.9822106957435608
Validation loss: 2.132295310497284

Epoch: 197| Step: 0
Training loss: 1.0876877307891846
Validation loss: 2.1119107007980347

Epoch: 6| Step: 1
Training loss: 0.9169648289680481
Validation loss: 2.095849613348643

Epoch: 6| Step: 2
Training loss: 0.41487181186676025
Validation loss: 2.0580299695332847

Epoch: 6| Step: 3
Training loss: 0.7435990571975708
Validation loss: 2.075832982858022

Epoch: 6| Step: 4
Training loss: 0.9386381506919861
Validation loss: 2.0331393480300903

Epoch: 6| Step: 5
Training loss: 0.6366163492202759
Validation loss: 2.0864532391230264

Epoch: 6| Step: 6
Training loss: 1.231799602508545
Validation loss: 2.0706785122553506

Epoch: 6| Step: 7
Training loss: 0.2988823652267456
Validation loss: 2.092934727668762

Epoch: 6| Step: 8
Training loss: 0.5136516690254211
Validation loss: 2.0980353355407715

Epoch: 6| Step: 9
Training loss: 0.9428813457489014
Validation loss: 2.132800201574961

Epoch: 6| Step: 10
Training loss: 0.49241653084754944
Validation loss: 2.136107583840688

Epoch: 6| Step: 11
Training loss: 0.7940672636032104
Validation loss: 2.1421780983606973

Epoch: 6| Step: 12
Training loss: 1.3197968006134033
Validation loss: 2.1253335078557334

Epoch: 6| Step: 13
Training loss: 0.8961344957351685
Validation loss: 2.108363767464956

Epoch: 198| Step: 0
Training loss: 0.9808861017227173
Validation loss: 2.1113171180089316

Epoch: 6| Step: 1
Training loss: 0.5792336463928223
Validation loss: 2.1225507060686746

Epoch: 6| Step: 2
Training loss: 0.46012020111083984
Validation loss: 2.038475592931112

Epoch: 6| Step: 3
Training loss: 0.9876381158828735
Validation loss: 2.088001847267151

Epoch: 6| Step: 4
Training loss: 0.3186204433441162
Validation loss: 2.1396719813346863

Epoch: 6| Step: 5
Training loss: 0.3775757849216461
Validation loss: 2.120393971602122

Epoch: 6| Step: 6
Training loss: 0.8262864351272583
Validation loss: 2.0806657473246255

Epoch: 6| Step: 7
Training loss: 0.7482435703277588
Validation loss: 2.156472623348236

Epoch: 6| Step: 8
Training loss: 0.7287722826004028
Validation loss: 2.1206740538279214

Epoch: 6| Step: 9
Training loss: 0.7881524562835693
Validation loss: 2.1062006751696267

Epoch: 6| Step: 10
Training loss: 0.9351404905319214
Validation loss: 2.1138325134913125

Epoch: 6| Step: 11
Training loss: 0.9187857508659363
Validation loss: 2.1184233029683432

Epoch: 6| Step: 12
Training loss: 1.3348627090454102
Validation loss: 2.1092694203058877

Epoch: 6| Step: 13
Training loss: 0.6516328454017639
Validation loss: 2.088455339272817

Epoch: 199| Step: 0
Training loss: 1.229236364364624
Validation loss: 2.0983508626619973

Epoch: 6| Step: 1
Training loss: 0.6275282502174377
Validation loss: 2.106223185857137

Epoch: 6| Step: 2
Training loss: 0.904062807559967
Validation loss: 2.095643321673075

Epoch: 6| Step: 3
Training loss: 0.3640356659889221
Validation loss: 2.1418067812919617

Epoch: 6| Step: 4
Training loss: 0.5073793530464172
Validation loss: 2.1102405389149985

Epoch: 6| Step: 5
Training loss: 0.6490769982337952
Validation loss: 2.1211305459340415

Epoch: 6| Step: 6
Training loss: 1.165742039680481
Validation loss: 2.139013727506002

Epoch: 6| Step: 7
Training loss: 0.934645414352417
Validation loss: 2.1102056304613748

Epoch: 6| Step: 8
Training loss: 0.37954026460647583
Validation loss: 2.1227295994758606

Epoch: 6| Step: 9
Training loss: 0.7640437483787537
Validation loss: 2.108287235101064

Epoch: 6| Step: 10
Training loss: 0.9725325107574463
Validation loss: 2.1185189882914224

Epoch: 6| Step: 11
Training loss: 0.42042508721351624
Validation loss: 2.0599627693494162

Epoch: 6| Step: 12
Training loss: 0.6666299700737
Validation loss: 2.1054321924845376

Epoch: 6| Step: 13
Training loss: 0.8236449956893921
Validation loss: 2.0913745760917664

Epoch: 200| Step: 0
Training loss: 0.48599982261657715
Validation loss: 2.1498414278030396

Epoch: 6| Step: 1
Training loss: 1.093130111694336
Validation loss: 2.1426050662994385

Epoch: 6| Step: 2
Training loss: 0.9682841300964355
Validation loss: 2.1180686553319297

Epoch: 6| Step: 3
Training loss: 0.7301518321037292
Validation loss: 2.167029778162638

Epoch: 6| Step: 4
Training loss: 1.023210883140564
Validation loss: 2.092347264289856

Epoch: 6| Step: 5
Training loss: 0.6212843060493469
Validation loss: 2.1328784227371216

Epoch: 6| Step: 6
Training loss: 0.8617439270019531
Validation loss: 2.0464704235394797

Epoch: 6| Step: 7
Training loss: 0.6132077574729919
Validation loss: 2.0833049416542053

Epoch: 6| Step: 8
Training loss: 0.8822845816612244
Validation loss: 2.0972793300946555

Epoch: 6| Step: 9
Training loss: 0.5615397691726685
Validation loss: 2.079702854156494

Epoch: 6| Step: 10
Training loss: 0.7886154651641846
Validation loss: 2.0678526560465493

Epoch: 6| Step: 11
Training loss: 0.5975736379623413
Validation loss: 2.127038896083832

Epoch: 6| Step: 12
Training loss: 0.999755322933197
Validation loss: 2.118039826552073

Epoch: 6| Step: 13
Training loss: 0.7928324341773987
Validation loss: 2.103226661682129

Epoch: 201| Step: 0
Training loss: 0.7004691958427429
Validation loss: 2.1349209348360696

Epoch: 6| Step: 1
Training loss: 1.0692310333251953
Validation loss: 2.1313560406366983

Epoch: 6| Step: 2
Training loss: 1.1478466987609863
Validation loss: 2.165769934654236

Epoch: 6| Step: 3
Training loss: 0.8313589692115784
Validation loss: 2.1207677125930786

Epoch: 6| Step: 4
Training loss: 0.7420968413352966
Validation loss: 2.0696030060450235

Epoch: 6| Step: 5
Training loss: 0.5043448209762573
Validation loss: 2.0778481562932334

Epoch: 6| Step: 6
Training loss: 0.989021897315979
Validation loss: 2.1033032536506653

Epoch: 6| Step: 7
Training loss: 0.6539904475212097
Validation loss: 2.121163864930471

Epoch: 6| Step: 8
Training loss: 0.4623374938964844
Validation loss: 2.0695818662643433

Epoch: 6| Step: 9
Training loss: 0.7974177002906799
Validation loss: 2.1176277796427407

Epoch: 6| Step: 10
Training loss: 0.51282799243927
Validation loss: 2.0725987354914346

Epoch: 6| Step: 11
Training loss: 0.722135066986084
Validation loss: 2.0833550492922464

Epoch: 6| Step: 12
Training loss: 1.0238410234451294
Validation loss: 2.097730060418447

Epoch: 6| Step: 13
Training loss: 0.5440449714660645
Validation loss: 2.126556177934011

Epoch: 202| Step: 0
Training loss: 0.5815236568450928
Validation loss: 2.1207241813341775

Epoch: 6| Step: 1
Training loss: 0.44662976264953613
Validation loss: 2.1235966086387634

Epoch: 6| Step: 2
Training loss: 0.6577262282371521
Validation loss: 2.1370776295661926

Epoch: 6| Step: 3
Training loss: 0.7391000986099243
Validation loss: 2.1671324173609414

Epoch: 6| Step: 4
Training loss: 0.7409076690673828
Validation loss: 2.1005156437555947

Epoch: 6| Step: 5
Training loss: 0.4940972626209259
Validation loss: 2.1113692124684653

Epoch: 6| Step: 6
Training loss: 0.7213318943977356
Validation loss: 2.1175574461619058

Epoch: 6| Step: 7
Training loss: 1.2044305801391602
Validation loss: 2.079415440559387

Epoch: 6| Step: 8
Training loss: 1.1568162441253662
Validation loss: 2.103395104408264

Epoch: 6| Step: 9
Training loss: 0.8663232326507568
Validation loss: 2.120234032471975

Epoch: 6| Step: 10
Training loss: 0.3373277187347412
Validation loss: 2.066921651363373

Epoch: 6| Step: 11
Training loss: 1.1201249361038208
Validation loss: 2.0835069020589194

Epoch: 6| Step: 12
Training loss: 0.7996038198471069
Validation loss: 2.1314677794774375

Epoch: 6| Step: 13
Training loss: 0.9486357569694519
Validation loss: 2.077719509601593

Epoch: 203| Step: 0
Training loss: 0.9069728851318359
Validation loss: 2.0888031919797263

Epoch: 6| Step: 1
Training loss: 0.5511637926101685
Validation loss: 2.1398098270098367

Epoch: 6| Step: 2
Training loss: 0.4878893494606018
Validation loss: 2.134478588898977

Epoch: 6| Step: 3
Training loss: 0.6024032831192017
Validation loss: 2.064817170302073

Epoch: 6| Step: 4
Training loss: 0.8286092281341553
Validation loss: 2.117529730002085

Epoch: 6| Step: 5
Training loss: 0.4420398473739624
Validation loss: 2.129624923070272

Epoch: 6| Step: 6
Training loss: 0.9312753677368164
Validation loss: 2.0596686204274497

Epoch: 6| Step: 7
Training loss: 0.8297370076179504
Validation loss: 2.1477787693341575

Epoch: 6| Step: 8
Training loss: 0.5511182546615601
Validation loss: 2.0923165480295816

Epoch: 6| Step: 9
Training loss: 0.6919700503349304
Validation loss: 2.093412220478058

Epoch: 6| Step: 10
Training loss: 0.42071783542633057
Validation loss: 2.0593366225560508

Epoch: 6| Step: 11
Training loss: 1.234695553779602
Validation loss: 2.097788949807485

Epoch: 6| Step: 12
Training loss: 0.856670618057251
Validation loss: 2.141303618748983

Epoch: 6| Step: 13
Training loss: 0.983916163444519
Validation loss: 2.124181071917216

Epoch: 204| Step: 0
Training loss: 0.9220460057258606
Validation loss: 2.0845342675844827

Epoch: 6| Step: 1
Training loss: 0.8155251741409302
Validation loss: 2.052657206853231

Epoch: 6| Step: 2
Training loss: 0.6486356258392334
Validation loss: 2.1015639106432595

Epoch: 6| Step: 3
Training loss: 0.7355448603630066
Validation loss: 2.0884744127591452

Epoch: 6| Step: 4
Training loss: 0.9681673049926758
Validation loss: 2.0959907174110413

Epoch: 6| Step: 5
Training loss: 0.5951535701751709
Validation loss: 2.066026449203491

Epoch: 6| Step: 6
Training loss: 0.5762473344802856
Validation loss: 2.14825838804245

Epoch: 6| Step: 7
Training loss: 0.7871318459510803
Validation loss: 2.098424255847931

Epoch: 6| Step: 8
Training loss: 0.5536447763442993
Validation loss: 2.054040869077047

Epoch: 6| Step: 9
Training loss: 0.4443487226963043
Validation loss: 2.092557509740194

Epoch: 6| Step: 10
Training loss: 0.9851542711257935
Validation loss: 2.0352408488591514

Epoch: 6| Step: 11
Training loss: 0.38357383012771606
Validation loss: 2.0793527563412986

Epoch: 6| Step: 12
Training loss: 1.0428578853607178
Validation loss: 2.0953967571258545

Epoch: 6| Step: 13
Training loss: 0.6267690658569336
Validation loss: 2.1222506562868753

Epoch: 205| Step: 0
Training loss: 1.1935300827026367
Validation loss: 2.1380107204119363

Epoch: 6| Step: 1
Training loss: 0.5433661937713623
Validation loss: 2.1290219823519387

Epoch: 6| Step: 2
Training loss: 0.9052070379257202
Validation loss: 2.0852127075195312

Epoch: 6| Step: 3
Training loss: 1.3458855152130127
Validation loss: 2.122486631075541

Epoch: 6| Step: 4
Training loss: 0.7854166030883789
Validation loss: 2.0663177768389382

Epoch: 6| Step: 5
Training loss: 0.70638507604599
Validation loss: 2.0969661672910056

Epoch: 6| Step: 6
Training loss: 0.4370986223220825
Validation loss: 2.1431734959284463

Epoch: 6| Step: 7
Training loss: 0.7417739629745483
Validation loss: 2.1030601263046265

Epoch: 6| Step: 8
Training loss: 0.49137744307518005
Validation loss: 2.096454699834188

Epoch: 6| Step: 9
Training loss: 0.5055067539215088
Validation loss: 2.032818555831909

Epoch: 6| Step: 10
Training loss: 0.37319114804267883
Validation loss: 2.104913512865702

Epoch: 6| Step: 11
Training loss: 0.7397932410240173
Validation loss: 2.0927761991818747

Epoch: 6| Step: 12
Training loss: 0.6777130961418152
Validation loss: 2.0793931086858115

Epoch: 6| Step: 13
Training loss: 1.0085511207580566
Validation loss: 2.113326291243235

Epoch: 206| Step: 0
Training loss: 0.8545562028884888
Validation loss: 2.114237646261851

Epoch: 6| Step: 1
Training loss: 0.6728864312171936
Validation loss: 2.0758546392122903

Epoch: 6| Step: 2
Training loss: 1.0593986511230469
Validation loss: 2.1211317777633667

Epoch: 6| Step: 3
Training loss: 1.1341791152954102
Validation loss: 2.1195354064305625

Epoch: 6| Step: 4
Training loss: 0.7997124195098877
Validation loss: 2.0636473099390664

Epoch: 6| Step: 5
Training loss: 0.5208766460418701
Validation loss: 2.0858946641286216

Epoch: 6| Step: 6
Training loss: 0.6595814228057861
Validation loss: 2.053186853726705

Epoch: 6| Step: 7
Training loss: 0.4738740921020508
Validation loss: 2.0702568689982095

Epoch: 6| Step: 8
Training loss: 0.6928350329399109
Validation loss: 2.0842384894688926

Epoch: 6| Step: 9
Training loss: 0.5949274301528931
Validation loss: 2.090402921040853

Epoch: 6| Step: 10
Training loss: 0.7148470282554626
Validation loss: 2.1018839677174888

Epoch: 6| Step: 11
Training loss: 0.8427980542182922
Validation loss: 2.1293721795082092

Epoch: 6| Step: 12
Training loss: 0.6875577569007874
Validation loss: 2.0872235894203186

Epoch: 6| Step: 13
Training loss: 0.9180075526237488
Validation loss: 2.0825874408086142

Epoch: 207| Step: 0
Training loss: 0.5643647909164429
Validation loss: 2.0895690520604453

Epoch: 6| Step: 1
Training loss: 0.6449939608573914
Validation loss: 2.063462714354197

Epoch: 6| Step: 2
Training loss: 0.61680668592453
Validation loss: 2.0631616910298667

Epoch: 6| Step: 3
Training loss: 0.7425023317337036
Validation loss: 2.0853565335273743

Epoch: 6| Step: 4
Training loss: 0.47043660283088684
Validation loss: 2.0992421309153237

Epoch: 6| Step: 5
Training loss: 1.1156080961227417
Validation loss: 2.0640876293182373

Epoch: 6| Step: 6
Training loss: 0.6614769697189331
Validation loss: 2.0860509276390076

Epoch: 6| Step: 7
Training loss: 0.6505287885665894
Validation loss: 2.146011451880137

Epoch: 6| Step: 8
Training loss: 0.7726208567619324
Validation loss: 2.187255620956421

Epoch: 6| Step: 9
Training loss: 1.07309889793396
Validation loss: 2.1536789933840432

Epoch: 6| Step: 10
Training loss: 0.756182074546814
Validation loss: 2.131701946258545

Epoch: 6| Step: 11
Training loss: 0.5679397583007812
Validation loss: 2.129968603452047

Epoch: 6| Step: 12
Training loss: 0.35967540740966797
Validation loss: 2.0825124382972717

Epoch: 6| Step: 13
Training loss: 1.251692295074463
Validation loss: 2.097058892250061

Epoch: 208| Step: 0
Training loss: 0.9209677577018738
Validation loss: 2.119434177875519

Epoch: 6| Step: 1
Training loss: 0.5662201642990112
Validation loss: 2.1094401677449546

Epoch: 6| Step: 2
Training loss: 0.6234791874885559
Validation loss: 2.0910590489705405

Epoch: 6| Step: 3
Training loss: 1.153409481048584
Validation loss: 2.117551326751709

Epoch: 6| Step: 4
Training loss: 0.8066866397857666
Validation loss: 2.0645963549613953

Epoch: 6| Step: 5
Training loss: 0.6672911643981934
Validation loss: 2.090534746646881

Epoch: 6| Step: 6
Training loss: 0.6594794988632202
Validation loss: 2.11206978559494

Epoch: 6| Step: 7
Training loss: 0.2854633331298828
Validation loss: 2.1193260550498962

Epoch: 6| Step: 8
Training loss: 0.7013006210327148
Validation loss: 2.1291548212369285

Epoch: 6| Step: 9
Training loss: 0.6355942487716675
Validation loss: 2.0864281256993613

Epoch: 6| Step: 10
Training loss: 0.5562092661857605
Validation loss: 2.1300245920817056

Epoch: 6| Step: 11
Training loss: 0.806552529335022
Validation loss: 2.0841403802235923

Epoch: 6| Step: 12
Training loss: 0.5786494016647339
Validation loss: 2.1706811587015786

Epoch: 6| Step: 13
Training loss: 1.1775575876235962
Validation loss: 2.128074367841085

Epoch: 209| Step: 0
Training loss: 0.3010661005973816
Validation loss: 2.1446547508239746

Epoch: 6| Step: 1
Training loss: 0.7043908834457397
Validation loss: 2.074124256769816

Epoch: 6| Step: 2
Training loss: 0.4353083372116089
Validation loss: 2.0822983980178833

Epoch: 6| Step: 3
Training loss: 0.9725534915924072
Validation loss: 2.0602394938468933

Epoch: 6| Step: 4
Training loss: 0.7266110181808472
Validation loss: 2.1324687798817954

Epoch: 6| Step: 5
Training loss: 0.46699225902557373
Validation loss: 2.1411258776982627

Epoch: 6| Step: 6
Training loss: 0.49081942439079285
Validation loss: 2.055213987827301

Epoch: 6| Step: 7
Training loss: 0.8526493310928345
Validation loss: 2.0839724938074746

Epoch: 6| Step: 8
Training loss: 0.6279664039611816
Validation loss: 2.1038556496302285

Epoch: 6| Step: 9
Training loss: 0.8920180797576904
Validation loss: 2.081276814142863

Epoch: 6| Step: 10
Training loss: 0.8778252005577087
Validation loss: 2.098821977774302

Epoch: 6| Step: 11
Training loss: 0.613603949546814
Validation loss: 2.0993435184160867

Epoch: 6| Step: 12
Training loss: 1.2397043704986572
Validation loss: 2.115328311920166

Epoch: 6| Step: 13
Training loss: 0.9376121759414673
Validation loss: 2.0737277070681253

Epoch: 210| Step: 0
Training loss: 0.7921335697174072
Validation loss: 2.0965842803319297

Epoch: 6| Step: 1
Training loss: 0.42747578024864197
Validation loss: 2.0864553451538086

Epoch: 6| Step: 2
Training loss: 0.8975028991699219
Validation loss: 2.065892497698466

Epoch: 6| Step: 3
Training loss: 0.5502533316612244
Validation loss: 2.0898877382278442

Epoch: 6| Step: 4
Training loss: 0.5587868690490723
Validation loss: 2.12652721007665

Epoch: 6| Step: 5
Training loss: 0.5416313409805298
Validation loss: 2.098217864831289

Epoch: 6| Step: 6
Training loss: 0.597847580909729
Validation loss: 2.053861995538076

Epoch: 6| Step: 7
Training loss: 0.7159905433654785
Validation loss: 2.106245736281077

Epoch: 6| Step: 8
Training loss: 1.11836838722229
Validation loss: 2.0904091596603394

Epoch: 6| Step: 9
Training loss: 1.309269905090332
Validation loss: 2.060482462247213

Epoch: 6| Step: 10
Training loss: 0.4650918245315552
Validation loss: 2.0727368195851645

Epoch: 6| Step: 11
Training loss: 0.7099777460098267
Validation loss: 2.1206628481547036

Epoch: 6| Step: 12
Training loss: 0.6432290077209473
Validation loss: 2.152389963467916

Epoch: 6| Step: 13
Training loss: 0.7727210521697998
Validation loss: 2.195104718208313

Epoch: 211| Step: 0
Training loss: 0.6984735131263733
Validation loss: 2.130380074183146

Epoch: 6| Step: 1
Training loss: 0.5683713555335999
Validation loss: 2.1296602487564087

Epoch: 6| Step: 2
Training loss: 1.0401867628097534
Validation loss: 2.0930357774098716

Epoch: 6| Step: 3
Training loss: 0.7626234292984009
Validation loss: 2.1342116594314575

Epoch: 6| Step: 4
Training loss: 0.5461800694465637
Validation loss: 2.0787489811579385

Epoch: 6| Step: 5
Training loss: 0.6814103126525879
Validation loss: 2.096058487892151

Epoch: 6| Step: 6
Training loss: 0.9460711479187012
Validation loss: 2.0806074937184653

Epoch: 6| Step: 7
Training loss: 0.797982931137085
Validation loss: 2.080995420614878

Epoch: 6| Step: 8
Training loss: 0.554198145866394
Validation loss: 2.0851930975914

Epoch: 6| Step: 9
Training loss: 0.5116878747940063
Validation loss: 2.1527053912480674

Epoch: 6| Step: 10
Training loss: 0.9347270727157593
Validation loss: 2.097307880719503

Epoch: 6| Step: 11
Training loss: 0.7965327501296997
Validation loss: 2.143324633439382

Epoch: 6| Step: 12
Training loss: 0.7068381905555725
Validation loss: 2.119349936644236

Epoch: 6| Step: 13
Training loss: 0.5058287978172302
Validation loss: 2.125144104162852

Epoch: 212| Step: 0
Training loss: 0.9097568392753601
Validation loss: 2.065820316473643

Epoch: 6| Step: 1
Training loss: 0.4934912323951721
Validation loss: 2.1038821935653687

Epoch: 6| Step: 2
Training loss: 0.9091875553131104
Validation loss: 2.098090728123983

Epoch: 6| Step: 3
Training loss: 0.9391491413116455
Validation loss: 2.082326869169871

Epoch: 6| Step: 4
Training loss: 0.9518516659736633
Validation loss: 2.0848270654678345

Epoch: 6| Step: 5
Training loss: 0.5076155662536621
Validation loss: 2.0621473590532937

Epoch: 6| Step: 6
Training loss: 0.5519100427627563
Validation loss: 2.1144781510035195

Epoch: 6| Step: 7
Training loss: 0.4595005214214325
Validation loss: 2.080270846684774

Epoch: 6| Step: 8
Training loss: 0.6424554586410522
Validation loss: 2.138225038846334

Epoch: 6| Step: 9
Training loss: 0.6267757415771484
Validation loss: 2.1201252341270447

Epoch: 6| Step: 10
Training loss: 0.611220121383667
Validation loss: 2.137183745702108

Epoch: 6| Step: 11
Training loss: 0.5062003135681152
Validation loss: 2.107946276664734

Epoch: 6| Step: 12
Training loss: 0.5797187089920044
Validation loss: 2.055144409338633

Epoch: 6| Step: 13
Training loss: 0.9309923052787781
Validation loss: 2.0800692637761435

Epoch: 213| Step: 0
Training loss: 0.4642016291618347
Validation loss: 2.097101092338562

Epoch: 6| Step: 1
Training loss: 0.7744091749191284
Validation loss: 2.1074074308077493

Epoch: 6| Step: 2
Training loss: 0.5966774225234985
Validation loss: 2.120804170767466

Epoch: 6| Step: 3
Training loss: 0.6953269839286804
Validation loss: 2.1090118686358132

Epoch: 6| Step: 4
Training loss: 1.1497209072113037
Validation loss: 2.1139843861262

Epoch: 6| Step: 5
Training loss: 0.935944676399231
Validation loss: 2.120609919230143

Epoch: 6| Step: 6
Training loss: 0.44835206866264343
Validation loss: 2.136392513910929

Epoch: 6| Step: 7
Training loss: 0.4873932898044586
Validation loss: 2.133420248826345

Epoch: 6| Step: 8
Training loss: 0.8186132311820984
Validation loss: 2.0865474144617715

Epoch: 6| Step: 9
Training loss: 0.74615478515625
Validation loss: 2.112600644429525

Epoch: 6| Step: 10
Training loss: 0.638519287109375
Validation loss: 2.0686755180358887

Epoch: 6| Step: 11
Training loss: 0.6656840443611145
Validation loss: 2.0885483225186667

Epoch: 6| Step: 12
Training loss: 0.7606557011604309
Validation loss: 2.104060192902883

Epoch: 6| Step: 13
Training loss: 0.5056100487709045
Validation loss: 2.0664769808451333

Epoch: 214| Step: 0
Training loss: 0.7838222980499268
Validation loss: 2.085894445578257

Epoch: 6| Step: 1
Training loss: 0.8172448873519897
Validation loss: 2.194724758466085

Epoch: 6| Step: 2
Training loss: 0.6708157062530518
Validation loss: 2.105169415473938

Epoch: 6| Step: 3
Training loss: 0.7471210360527039
Validation loss: 2.1566399137179055

Epoch: 6| Step: 4
Training loss: 0.6766576766967773
Validation loss: 2.154260198275248

Epoch: 6| Step: 5
Training loss: 1.2244791984558105
Validation loss: 2.0928580363591514

Epoch: 6| Step: 6
Training loss: 0.512822151184082
Validation loss: 2.080245614051819

Epoch: 6| Step: 7
Training loss: 0.4513990879058838
Validation loss: 2.1093840996424356

Epoch: 6| Step: 8
Training loss: 0.4613886773586273
Validation loss: 2.0976880391438804

Epoch: 6| Step: 9
Training loss: 0.46952587366104126
Validation loss: 2.084133803844452

Epoch: 6| Step: 10
Training loss: 1.3415164947509766
Validation loss: 2.1266062458356223

Epoch: 6| Step: 11
Training loss: 0.611764132976532
Validation loss: 2.182428856690725

Epoch: 6| Step: 12
Training loss: 0.8015122413635254
Validation loss: 2.163884480794271

Epoch: 6| Step: 13
Training loss: 0.4659399390220642
Validation loss: 2.1476285060246787

Epoch: 215| Step: 0
Training loss: 0.6555883288383484
Validation loss: 2.0977110664049783

Epoch: 6| Step: 1
Training loss: 0.638267993927002
Validation loss: 2.098072568575541

Epoch: 6| Step: 2
Training loss: 0.5925962924957275
Validation loss: 2.1009947061538696

Epoch: 6| Step: 3
Training loss: 0.3697301149368286
Validation loss: 2.0818782448768616

Epoch: 6| Step: 4
Training loss: 1.0111122131347656
Validation loss: 2.087196628252665

Epoch: 6| Step: 5
Training loss: 0.637188196182251
Validation loss: 2.1146346728006997

Epoch: 6| Step: 6
Training loss: 0.9916286468505859
Validation loss: 2.050581236680349

Epoch: 6| Step: 7
Training loss: 0.4979943633079529
Validation loss: 2.129698395729065

Epoch: 6| Step: 8
Training loss: 0.8184346556663513
Validation loss: 2.150089124838511

Epoch: 6| Step: 9
Training loss: 1.2237884998321533
Validation loss: 2.1567931373914084

Epoch: 6| Step: 10
Training loss: 1.0341328382492065
Validation loss: 2.174843410650889

Epoch: 6| Step: 11
Training loss: 0.7095650434494019
Validation loss: 2.1368574698766074

Epoch: 6| Step: 12
Training loss: 0.30323559045791626
Validation loss: 2.1113972663879395

Epoch: 6| Step: 13
Training loss: 0.4703533947467804
Validation loss: 2.1022602319717407

Epoch: 216| Step: 0
Training loss: 0.7091530561447144
Validation loss: 2.0788851181666055

Epoch: 6| Step: 1
Training loss: 0.4367098808288574
Validation loss: 2.0279953479766846

Epoch: 6| Step: 2
Training loss: 0.6013826727867126
Validation loss: 2.073530614376068

Epoch: 6| Step: 3
Training loss: 0.8053930997848511
Validation loss: 2.12971955537796

Epoch: 6| Step: 4
Training loss: 0.7241982221603394
Validation loss: 2.096158027648926

Epoch: 6| Step: 5
Training loss: 0.7105721235275269
Validation loss: 2.1420522133509317

Epoch: 6| Step: 6
Training loss: 0.7434083223342896
Validation loss: 2.1101505557696023

Epoch: 6| Step: 7
Training loss: 0.4896022081375122
Validation loss: 2.09807425737381

Epoch: 6| Step: 8
Training loss: 0.5269941091537476
Validation loss: 2.1084132194519043

Epoch: 6| Step: 9
Training loss: 0.8727082014083862
Validation loss: 2.115247925122579

Epoch: 6| Step: 10
Training loss: 0.5944786667823792
Validation loss: 2.104600270589193

Epoch: 6| Step: 11
Training loss: 0.7566083073616028
Validation loss: 2.1125750144322715

Epoch: 6| Step: 12
Training loss: 1.257712960243225
Validation loss: 2.120364507039388

Epoch: 6| Step: 13
Training loss: 0.33748865127563477
Validation loss: 2.0855769515037537

Epoch: 217| Step: 0
Training loss: 0.42646652460098267
Validation loss: 2.111883024374644

Epoch: 6| Step: 1
Training loss: 0.4928012192249298
Validation loss: 2.0724532206853232

Epoch: 6| Step: 2
Training loss: 0.9581564664840698
Validation loss: 2.119192282358805

Epoch: 6| Step: 3
Training loss: 0.31098753213882446
Validation loss: 2.09358016649882

Epoch: 6| Step: 4
Training loss: 0.5809799432754517
Validation loss: 2.1403717199961343

Epoch: 6| Step: 5
Training loss: 0.7515473365783691
Validation loss: 2.0768831173578897

Epoch: 6| Step: 6
Training loss: 1.0622870922088623
Validation loss: 2.0960576931635537

Epoch: 6| Step: 7
Training loss: 1.1130074262619019
Validation loss: 2.0958408315976462

Epoch: 6| Step: 8
Training loss: 0.6166149377822876
Validation loss: 2.1144354542096457

Epoch: 6| Step: 9
Training loss: 0.9391474723815918
Validation loss: 2.1059122482935586

Epoch: 6| Step: 10
Training loss: 0.48922979831695557
Validation loss: 2.12739364306132

Epoch: 6| Step: 11
Training loss: 0.5699949264526367
Validation loss: 2.0988060434659324

Epoch: 6| Step: 12
Training loss: 0.6183507442474365
Validation loss: 2.0807718634605408

Epoch: 6| Step: 13
Training loss: 0.609138011932373
Validation loss: 2.1035424868265786

Epoch: 218| Step: 0
Training loss: 0.7824243307113647
Validation loss: 2.080260753631592

Epoch: 6| Step: 1
Training loss: 0.7592540979385376
Validation loss: 2.0984701116879783

Epoch: 6| Step: 2
Training loss: 0.3242148756980896
Validation loss: 2.0916517774264016

Epoch: 6| Step: 3
Training loss: 0.5266516804695129
Validation loss: 2.116117835044861

Epoch: 6| Step: 4
Training loss: 0.561517059803009
Validation loss: 2.105788250764211

Epoch: 6| Step: 5
Training loss: 0.5965322256088257
Validation loss: 2.03813902537028

Epoch: 6| Step: 6
Training loss: 0.5303739309310913
Validation loss: 2.077050507068634

Epoch: 6| Step: 7
Training loss: 0.6174260377883911
Validation loss: 2.0420945286750793

Epoch: 6| Step: 8
Training loss: 1.4400843381881714
Validation loss: 2.1011978586514792

Epoch: 6| Step: 9
Training loss: 0.6578975915908813
Validation loss: 2.0980469385782876

Epoch: 6| Step: 10
Training loss: 0.6294609904289246
Validation loss: 2.0972862243652344

Epoch: 6| Step: 11
Training loss: 0.7008566856384277
Validation loss: 2.142193694909414

Epoch: 6| Step: 12
Training loss: 0.5836288928985596
Validation loss: 2.085285723209381

Epoch: 6| Step: 13
Training loss: 0.8008379936218262
Validation loss: 2.1426807244618735

Epoch: 219| Step: 0
Training loss: 0.8650721311569214
Validation loss: 2.183275580406189

Epoch: 6| Step: 1
Training loss: 1.1872146129608154
Validation loss: 2.12949001789093

Epoch: 6| Step: 2
Training loss: 0.5033259391784668
Validation loss: 2.0885242025057473

Epoch: 6| Step: 3
Training loss: 0.5366538763046265
Validation loss: 2.099402368068695

Epoch: 6| Step: 4
Training loss: 0.7880691885948181
Validation loss: 2.08904496828715

Epoch: 6| Step: 5
Training loss: 0.7240064144134521
Validation loss: 2.0914006431897483

Epoch: 6| Step: 6
Training loss: 0.5873556137084961
Validation loss: 2.045303761959076

Epoch: 6| Step: 7
Training loss: 0.5470803380012512
Validation loss: 2.1590669353803

Epoch: 6| Step: 8
Training loss: 0.433712363243103
Validation loss: 2.1383713285128274

Epoch: 6| Step: 9
Training loss: 0.9144220948219299
Validation loss: 2.1439805030822754

Epoch: 6| Step: 10
Training loss: 0.9991294145584106
Validation loss: 2.198971152305603

Epoch: 6| Step: 11
Training loss: 0.21339991688728333
Validation loss: 2.1371997396151223

Epoch: 6| Step: 12
Training loss: 0.38966864347457886
Validation loss: 2.122185548146566

Epoch: 6| Step: 13
Training loss: 0.8008322715759277
Validation loss: 2.080160895983378

Epoch: 220| Step: 0
Training loss: 1.0029289722442627
Validation loss: 2.118512213230133

Epoch: 6| Step: 1
Training loss: 0.5794805884361267
Validation loss: 2.090273936589559

Epoch: 6| Step: 2
Training loss: 0.5662087202072144
Validation loss: 2.095690985520681

Epoch: 6| Step: 3
Training loss: 0.6202335953712463
Validation loss: 2.0843917528788247

Epoch: 6| Step: 4
Training loss: 0.441495418548584
Validation loss: 2.109263300895691

Epoch: 6| Step: 5
Training loss: 0.5203180909156799
Validation loss: 2.1272270878156028

Epoch: 6| Step: 6
Training loss: 0.8351051807403564
Validation loss: 2.1649855176607766

Epoch: 6| Step: 7
Training loss: 0.6710577011108398
Validation loss: 2.150788903236389

Epoch: 6| Step: 8
Training loss: 1.4205689430236816
Validation loss: 2.142172157764435

Epoch: 6| Step: 9
Training loss: 0.6958832144737244
Validation loss: 2.047708511352539

Epoch: 6| Step: 10
Training loss: 0.5866600275039673
Validation loss: 2.107451637585958

Epoch: 6| Step: 11
Training loss: 0.8449965715408325
Validation loss: 2.106703261534373

Epoch: 6| Step: 12
Training loss: 0.4609411358833313
Validation loss: 2.1109988490740457

Epoch: 6| Step: 13
Training loss: 0.3672742247581482
Validation loss: 2.117524007956187

Epoch: 221| Step: 0
Training loss: 0.9093334674835205
Validation loss: 2.0552069743474326

Epoch: 6| Step: 1
Training loss: 1.078416347503662
Validation loss: 2.1313098470369973

Epoch: 6| Step: 2
Training loss: 0.4821191430091858
Validation loss: 2.124977191289266

Epoch: 6| Step: 3
Training loss: 0.5058954358100891
Validation loss: 2.1070110201835632

Epoch: 6| Step: 4
Training loss: 0.5529710054397583
Validation loss: 2.1403604547182717

Epoch: 6| Step: 5
Training loss: 0.888767421245575
Validation loss: 2.1331010262171426

Epoch: 6| Step: 6
Training loss: 0.44911229610443115
Validation loss: 2.071026543776194

Epoch: 6| Step: 7
Training loss: 0.5642427802085876
Validation loss: 2.105077942212423

Epoch: 6| Step: 8
Training loss: 0.2748587131500244
Validation loss: 2.078220466772715

Epoch: 6| Step: 9
Training loss: 0.3523986339569092
Validation loss: 2.0924333333969116

Epoch: 6| Step: 10
Training loss: 0.6125096678733826
Validation loss: 2.08286585410436

Epoch: 6| Step: 11
Training loss: 0.6975731253623962
Validation loss: 2.086893320083618

Epoch: 6| Step: 12
Training loss: 0.5665635466575623
Validation loss: 2.134071628252665

Epoch: 6| Step: 13
Training loss: 1.1929070949554443
Validation loss: 2.1455593506495156

Epoch: 222| Step: 0
Training loss: 0.568244218826294
Validation loss: 2.145044485727946

Epoch: 6| Step: 1
Training loss: 0.7729513645172119
Validation loss: 2.0966924826304116

Epoch: 6| Step: 2
Training loss: 0.6247944831848145
Validation loss: 2.058578312397003

Epoch: 6| Step: 3
Training loss: 0.6704027056694031
Validation loss: 2.0864482522010803

Epoch: 6| Step: 4
Training loss: 0.31283149123191833
Validation loss: 2.0749645233154297

Epoch: 6| Step: 5
Training loss: 0.9215089082717896
Validation loss: 2.124648849169413

Epoch: 6| Step: 6
Training loss: 0.8870500922203064
Validation loss: 2.104395786921183

Epoch: 6| Step: 7
Training loss: 0.7118144631385803
Validation loss: 2.090691248575846

Epoch: 6| Step: 8
Training loss: 1.213316559791565
Validation loss: 2.1132514079411826

Epoch: 6| Step: 9
Training loss: 0.5759665369987488
Validation loss: 2.0623878240585327

Epoch: 6| Step: 10
Training loss: 0.5802837014198303
Validation loss: 2.1524219711621604

Epoch: 6| Step: 11
Training loss: 0.3097500801086426
Validation loss: 2.1170936822891235

Epoch: 6| Step: 12
Training loss: 0.5797821283340454
Validation loss: 2.125329593817393

Epoch: 6| Step: 13
Training loss: 0.6973571181297302
Validation loss: 2.1051379442214966

Epoch: 223| Step: 0
Training loss: 0.5587864518165588
Validation loss: 2.095208545525869

Epoch: 6| Step: 1
Training loss: 0.438032865524292
Validation loss: 2.062108596165975

Epoch: 6| Step: 2
Training loss: 0.6807125806808472
Validation loss: 2.0647852222124734

Epoch: 6| Step: 3
Training loss: 0.6824196577072144
Validation loss: 2.0770992239316306

Epoch: 6| Step: 4
Training loss: 0.9697638750076294
Validation loss: 2.029595990975698

Epoch: 6| Step: 5
Training loss: 0.38149139285087585
Validation loss: 2.1372748017311096

Epoch: 6| Step: 6
Training loss: 0.49850958585739136
Validation loss: 2.09077250957489

Epoch: 6| Step: 7
Training loss: 0.7856438755989075
Validation loss: 2.1282612085342407

Epoch: 6| Step: 8
Training loss: 0.5237458944320679
Validation loss: 2.1112699111302695

Epoch: 6| Step: 9
Training loss: 0.7067028284072876
Validation loss: 2.1349257230758667

Epoch: 6| Step: 10
Training loss: 0.8745189905166626
Validation loss: 2.0998501777648926

Epoch: 6| Step: 11
Training loss: 0.6228768825531006
Validation loss: 2.093412617842356

Epoch: 6| Step: 12
Training loss: 1.0998609066009521
Validation loss: 2.0838063955307007

Epoch: 6| Step: 13
Training loss: 0.6999447345733643
Validation loss: 2.112195869286855

Epoch: 224| Step: 0
Training loss: 0.6327913999557495
Validation loss: 2.0916480819384256

Epoch: 6| Step: 1
Training loss: 1.1128158569335938
Validation loss: 2.0781964858373008

Epoch: 6| Step: 2
Training loss: 0.5608636140823364
Validation loss: 2.092769682407379

Epoch: 6| Step: 3
Training loss: 0.7368676066398621
Validation loss: 2.1204219261805215

Epoch: 6| Step: 4
Training loss: 0.6817319989204407
Validation loss: 2.120098074277242

Epoch: 6| Step: 5
Training loss: 0.5011621713638306
Validation loss: 2.117649475733439

Epoch: 6| Step: 6
Training loss: 0.6395261883735657
Validation loss: 2.084739009539286

Epoch: 6| Step: 7
Training loss: 0.6627157330513
Validation loss: 2.1227155526479087

Epoch: 6| Step: 8
Training loss: 0.42628800868988037
Validation loss: 2.0362462401390076

Epoch: 6| Step: 9
Training loss: 0.8755713105201721
Validation loss: 2.1027182141939798

Epoch: 6| Step: 10
Training loss: 0.6911672949790955
Validation loss: 2.094540774822235

Epoch: 6| Step: 11
Training loss: 0.7461709976196289
Validation loss: 2.124510029951731

Epoch: 6| Step: 12
Training loss: 0.3213890492916107
Validation loss: 2.1765072345733643

Epoch: 6| Step: 13
Training loss: 0.7515195608139038
Validation loss: 2.1403584480285645

Epoch: 225| Step: 0
Training loss: 0.7897998094558716
Validation loss: 2.1359540025393167

Epoch: 6| Step: 1
Training loss: 0.4992657005786896
Validation loss: 2.1180098056793213

Epoch: 6| Step: 2
Training loss: 0.3604779541492462
Validation loss: 2.1108486652374268

Epoch: 6| Step: 3
Training loss: 0.8445676565170288
Validation loss: 2.136272589365641

Epoch: 6| Step: 4
Training loss: 0.5744035243988037
Validation loss: 2.1181046764055886

Epoch: 6| Step: 5
Training loss: 0.6349982023239136
Validation loss: 2.105323016643524

Epoch: 6| Step: 6
Training loss: 0.44856613874435425
Validation loss: 2.071822007497152

Epoch: 6| Step: 7
Training loss: 0.6776637434959412
Validation loss: 2.092300514380137

Epoch: 6| Step: 8
Training loss: 0.7935256958007812
Validation loss: 2.0861948331197104

Epoch: 6| Step: 9
Training loss: 1.0536659955978394
Validation loss: 2.1102038621902466

Epoch: 6| Step: 10
Training loss: 0.38979876041412354
Validation loss: 2.124435027440389

Epoch: 6| Step: 11
Training loss: 0.5454335808753967
Validation loss: 2.0692485769589744

Epoch: 6| Step: 12
Training loss: 1.1191099882125854
Validation loss: 2.0563644766807556

Epoch: 6| Step: 13
Training loss: 0.5963548421859741
Validation loss: 2.064735551675161

Epoch: 226| Step: 0
Training loss: 0.4809800684452057
Validation loss: 2.0817560156186423

Epoch: 6| Step: 1
Training loss: 0.6397923231124878
Validation loss: 2.1165153980255127

Epoch: 6| Step: 2
Training loss: 0.6096898317337036
Validation loss: 2.111861288547516

Epoch: 6| Step: 3
Training loss: 0.9447994232177734
Validation loss: 2.0485673348108926

Epoch: 6| Step: 4
Training loss: 0.9267400503158569
Validation loss: 2.081951677799225

Epoch: 6| Step: 5
Training loss: 0.5386971235275269
Validation loss: 2.1310811638832092

Epoch: 6| Step: 6
Training loss: 0.6626338958740234
Validation loss: 2.1407852371533713

Epoch: 6| Step: 7
Training loss: 0.6702733635902405
Validation loss: 2.0801994999249778

Epoch: 6| Step: 8
Training loss: 0.6306748390197754
Validation loss: 2.1274969379107156

Epoch: 6| Step: 9
Training loss: 0.46991822123527527
Validation loss: 2.090786794821421

Epoch: 6| Step: 10
Training loss: 0.4578927457332611
Validation loss: 2.100340028603872

Epoch: 6| Step: 11
Training loss: 0.38796210289001465
Validation loss: 2.112995525201162

Epoch: 6| Step: 12
Training loss: 0.5258205533027649
Validation loss: 2.1004165410995483

Epoch: 6| Step: 13
Training loss: 1.1080952882766724
Validation loss: 2.1142942905426025

Epoch: 227| Step: 0
Training loss: 0.7701407670974731
Validation loss: 2.113006810347239

Epoch: 6| Step: 1
Training loss: 0.7333405017852783
Validation loss: 2.1226292053858438

Epoch: 6| Step: 2
Training loss: 0.8797668218612671
Validation loss: 2.1477609872817993

Epoch: 6| Step: 3
Training loss: 0.5471388101577759
Validation loss: 2.1266296903292337

Epoch: 6| Step: 4
Training loss: 0.6396141052246094
Validation loss: 2.0940139293670654

Epoch: 6| Step: 5
Training loss: 0.9236150979995728
Validation loss: 2.0840057134628296

Epoch: 6| Step: 6
Training loss: 0.5086337924003601
Validation loss: 2.09678053855896

Epoch: 6| Step: 7
Training loss: 0.7973499298095703
Validation loss: 2.0974007844924927

Epoch: 6| Step: 8
Training loss: 0.49187564849853516
Validation loss: 2.071899632612864

Epoch: 6| Step: 9
Training loss: 0.6765637993812561
Validation loss: 2.1205654740333557

Epoch: 6| Step: 10
Training loss: 0.693532407283783
Validation loss: 2.1117867628733316

Epoch: 6| Step: 11
Training loss: 0.333381712436676
Validation loss: 2.093619247277578

Epoch: 6| Step: 12
Training loss: 0.6311875581741333
Validation loss: 2.1097922325134277

Epoch: 6| Step: 13
Training loss: 0.8881409764289856
Validation loss: 2.1400087475776672

Epoch: 228| Step: 0
Training loss: 0.6274438500404358
Validation loss: 2.1511497696240744

Epoch: 6| Step: 1
Training loss: 0.8153698444366455
Validation loss: 2.142457107702891

Epoch: 6| Step: 2
Training loss: 0.520439863204956
Validation loss: 2.1483423113822937

Epoch: 6| Step: 3
Training loss: 0.896128237247467
Validation loss: 2.1003507574399314

Epoch: 6| Step: 4
Training loss: 0.32391488552093506
Validation loss: 2.1101585626602173

Epoch: 6| Step: 5
Training loss: 0.5949805974960327
Validation loss: 2.1158566077550254

Epoch: 6| Step: 6
Training loss: 0.37098684906959534
Validation loss: 2.1160729924837747

Epoch: 6| Step: 7
Training loss: 0.8164559602737427
Validation loss: 2.138704697291056

Epoch: 6| Step: 8
Training loss: 0.8596716523170471
Validation loss: 2.1133528351783752

Epoch: 6| Step: 9
Training loss: 0.6353400945663452
Validation loss: 2.1083432038625083

Epoch: 6| Step: 10
Training loss: 1.2411737442016602
Validation loss: 2.160388986269633

Epoch: 6| Step: 11
Training loss: 0.473113477230072
Validation loss: 2.129732092221578

Epoch: 6| Step: 12
Training loss: 0.38195568323135376
Validation loss: 2.1342939138412476

Epoch: 6| Step: 13
Training loss: 1.0555369853973389
Validation loss: 2.119734545548757

Epoch: 229| Step: 0
Training loss: 0.6311221122741699
Validation loss: 2.0983856121699014

Epoch: 6| Step: 1
Training loss: 0.2339264303445816
Validation loss: 2.1005640029907227

Epoch: 6| Step: 2
Training loss: 0.6803578734397888
Validation loss: 2.0830866495768228

Epoch: 6| Step: 3
Training loss: 1.0623873472213745
Validation loss: 2.126859704653422

Epoch: 6| Step: 4
Training loss: 0.7467570304870605
Validation loss: 2.114525854587555

Epoch: 6| Step: 5
Training loss: 0.4434919059276581
Validation loss: 2.1488468249638877

Epoch: 6| Step: 6
Training loss: 0.4889656603336334
Validation loss: 2.1572409868240356

Epoch: 6| Step: 7
Training loss: 0.48354601860046387
Validation loss: 2.1356575091679892

Epoch: 6| Step: 8
Training loss: 0.7821546792984009
Validation loss: 2.1039731899897256

Epoch: 6| Step: 9
Training loss: 0.4616384506225586
Validation loss: 2.1482387582461038

Epoch: 6| Step: 10
Training loss: 1.172485113143921
Validation loss: 2.0534499486287436

Epoch: 6| Step: 11
Training loss: 0.48764488101005554
Validation loss: 2.0688843727111816

Epoch: 6| Step: 12
Training loss: 0.7128086090087891
Validation loss: 2.1125237147013345

Epoch: 6| Step: 13
Training loss: 0.5580066442489624
Validation loss: 2.1128722627957663

Epoch: 230| Step: 0
Training loss: 0.5407149195671082
Validation loss: 2.1054545243581138

Epoch: 6| Step: 1
Training loss: 0.6550576686859131
Validation loss: 2.0987452467282615

Epoch: 6| Step: 2
Training loss: 0.708991289138794
Validation loss: 2.1285338600476584

Epoch: 6| Step: 3
Training loss: 1.2755793333053589
Validation loss: 2.088714838027954

Epoch: 6| Step: 4
Training loss: 0.8672502040863037
Validation loss: 2.1435478727022805

Epoch: 6| Step: 5
Training loss: 0.5164618492126465
Validation loss: 2.1343912283579507

Epoch: 6| Step: 6
Training loss: 0.4865114986896515
Validation loss: 2.0846910874048867

Epoch: 6| Step: 7
Training loss: 0.4795142710208893
Validation loss: 2.1369383136431375

Epoch: 6| Step: 8
Training loss: 0.7277118563652039
Validation loss: 2.1305537025133767

Epoch: 6| Step: 9
Training loss: 0.31192347407341003
Validation loss: 2.13026628891627

Epoch: 6| Step: 10
Training loss: 0.7056392431259155
Validation loss: 2.0855125188827515

Epoch: 6| Step: 11
Training loss: 0.560100257396698
Validation loss: 2.1483139197031655

Epoch: 6| Step: 12
Training loss: 0.8172979950904846
Validation loss: 2.0689448714256287

Epoch: 6| Step: 13
Training loss: 0.6513186693191528
Validation loss: 2.0607725183169046

Epoch: 231| Step: 0
Training loss: 0.8578836917877197
Validation loss: 2.0859359304110208

Epoch: 6| Step: 1
Training loss: 0.45309698581695557
Validation loss: 2.116286118825277

Epoch: 6| Step: 2
Training loss: 0.3730015754699707
Validation loss: 2.101686656475067

Epoch: 6| Step: 3
Training loss: 0.5487366914749146
Validation loss: 2.1176595091819763

Epoch: 6| Step: 4
Training loss: 0.5354615449905396
Validation loss: 2.1328043937683105

Epoch: 6| Step: 5
Training loss: 0.583106279373169
Validation loss: 2.1505529284477234

Epoch: 6| Step: 6
Training loss: 0.6408523321151733
Validation loss: 2.1318764885266623

Epoch: 6| Step: 7
Training loss: 1.0698118209838867
Validation loss: 2.0832383831342063

Epoch: 6| Step: 8
Training loss: 0.5888296365737915
Validation loss: 2.0702399214108786

Epoch: 6| Step: 9
Training loss: 0.4959910213947296
Validation loss: 2.109198292096456

Epoch: 6| Step: 10
Training loss: 0.6971052289009094
Validation loss: 2.07929398616155

Epoch: 6| Step: 11
Training loss: 0.29137974977493286
Validation loss: 2.1567326188087463

Epoch: 6| Step: 12
Training loss: 0.7621290683746338
Validation loss: 2.1135119795799255

Epoch: 6| Step: 13
Training loss: 0.9378082752227783
Validation loss: 2.08007683356603

Epoch: 232| Step: 0
Training loss: 0.6579262614250183
Validation loss: 2.0940975546836853

Epoch: 6| Step: 1
Training loss: 0.6433205604553223
Validation loss: 2.119029978911082

Epoch: 6| Step: 2
Training loss: 0.24991394579410553
Validation loss: 2.131950259208679

Epoch: 6| Step: 3
Training loss: 0.5752884149551392
Validation loss: 2.105064352353414

Epoch: 6| Step: 4
Training loss: 0.7095456123352051
Validation loss: 2.0970837275187173

Epoch: 6| Step: 5
Training loss: 0.9254262447357178
Validation loss: 2.1018147071202598

Epoch: 6| Step: 6
Training loss: 0.3964669108390808
Validation loss: 2.1426533261934915

Epoch: 6| Step: 7
Training loss: 0.5599220395088196
Validation loss: 2.0883601307868958

Epoch: 6| Step: 8
Training loss: 0.36569130420684814
Validation loss: 2.1134303410847983

Epoch: 6| Step: 9
Training loss: 0.8683544397354126
Validation loss: 2.153776923815409

Epoch: 6| Step: 10
Training loss: 1.0003896951675415
Validation loss: 2.0987332860628762

Epoch: 6| Step: 11
Training loss: 0.6089422106742859
Validation loss: 2.1484809120496116

Epoch: 6| Step: 12
Training loss: 0.4099697768688202
Validation loss: 2.0888994336128235

Epoch: 6| Step: 13
Training loss: 0.43618276715278625
Validation loss: 2.1342513163884482

Epoch: 233| Step: 0
Training loss: 0.4908561408519745
Validation loss: 2.107442001501719

Epoch: 6| Step: 1
Training loss: 0.6022967100143433
Validation loss: 2.1716532707214355

Epoch: 6| Step: 2
Training loss: 0.38199615478515625
Validation loss: 2.1431236267089844

Epoch: 6| Step: 3
Training loss: 0.6002232432365417
Validation loss: 2.1339698831240335

Epoch: 6| Step: 4
Training loss: 0.7101094722747803
Validation loss: 2.08492511510849

Epoch: 6| Step: 5
Training loss: 0.9280521869659424
Validation loss: 2.102750221888224

Epoch: 6| Step: 6
Training loss: 1.1415292024612427
Validation loss: 2.120019316673279

Epoch: 6| Step: 7
Training loss: 0.7555773854255676
Validation loss: 2.103764235973358

Epoch: 6| Step: 8
Training loss: 0.47784358263015747
Validation loss: 2.06260214249293

Epoch: 6| Step: 9
Training loss: 0.8235988616943359
Validation loss: 2.1249739130338035

Epoch: 6| Step: 10
Training loss: 0.43353569507598877
Validation loss: 2.1251301765441895

Epoch: 6| Step: 11
Training loss: 0.7088125944137573
Validation loss: 2.1726837356885276

Epoch: 6| Step: 12
Training loss: 0.6761792898178101
Validation loss: 2.1076740026474

Epoch: 6| Step: 13
Training loss: 0.7698245048522949
Validation loss: 2.1648650566736856

Epoch: 234| Step: 0
Training loss: 0.687328040599823
Validation loss: 2.1117836236953735

Epoch: 6| Step: 1
Training loss: 1.1324454545974731
Validation loss: 2.1413177450497947

Epoch: 6| Step: 2
Training loss: 0.5006003379821777
Validation loss: 2.134643773237864

Epoch: 6| Step: 3
Training loss: 0.7855919003486633
Validation loss: 2.1008402903874717

Epoch: 6| Step: 4
Training loss: 0.8302779793739319
Validation loss: 2.079540193080902

Epoch: 6| Step: 5
Training loss: 0.6050622463226318
Validation loss: 2.095067838827769

Epoch: 6| Step: 6
Training loss: 0.8697192668914795
Validation loss: 2.125884691874186

Epoch: 6| Step: 7
Training loss: 0.442430704832077
Validation loss: 2.1348052422205606

Epoch: 6| Step: 8
Training loss: 0.46589910984039307
Validation loss: 2.1531270345052085

Epoch: 6| Step: 9
Training loss: 0.5847548842430115
Validation loss: 2.059413115183512

Epoch: 6| Step: 10
Training loss: 0.62537682056427
Validation loss: 2.1451762318611145

Epoch: 6| Step: 11
Training loss: 0.657210648059845
Validation loss: 2.1330589850743613

Epoch: 6| Step: 12
Training loss: 0.6384556293487549
Validation loss: 2.137029767036438

Epoch: 6| Step: 13
Training loss: 0.5805221796035767
Validation loss: 2.1054542462031045

Epoch: 235| Step: 0
Training loss: 0.7152677774429321
Validation loss: 2.09257702032725

Epoch: 6| Step: 1
Training loss: 0.46379202604293823
Validation loss: 2.083885133266449

Epoch: 6| Step: 2
Training loss: 0.249226376414299
Validation loss: 2.1405771176020303

Epoch: 6| Step: 3
Training loss: 0.6087425947189331
Validation loss: 2.092695951461792

Epoch: 6| Step: 4
Training loss: 0.37811920046806335
Validation loss: 2.1309253772099814

Epoch: 6| Step: 5
Training loss: 0.8410503268241882
Validation loss: 2.132666806379954

Epoch: 6| Step: 6
Training loss: 0.7138205766677856
Validation loss: 2.1053318977355957

Epoch: 6| Step: 7
Training loss: 0.29986441135406494
Validation loss: 2.1370755632718406

Epoch: 6| Step: 8
Training loss: 0.5333232283592224
Validation loss: 2.098854104677836

Epoch: 6| Step: 9
Training loss: 1.119050145149231
Validation loss: 2.1157211860020957

Epoch: 6| Step: 10
Training loss: 0.5088295936584473
Validation loss: 2.0887165665626526

Epoch: 6| Step: 11
Training loss: 0.598821759223938
Validation loss: 2.108817458152771

Epoch: 6| Step: 12
Training loss: 0.2949266731739044
Validation loss: 2.0596540768941245

Epoch: 6| Step: 13
Training loss: 1.4394290447235107
Validation loss: 2.064961830774943

Epoch: 236| Step: 0
Training loss: 1.1896101236343384
Validation loss: 2.1278080542882285

Epoch: 6| Step: 1
Training loss: 0.39751896262168884
Validation loss: 2.082668592532476

Epoch: 6| Step: 2
Training loss: 0.35347187519073486
Validation loss: 2.177180528640747

Epoch: 6| Step: 3
Training loss: 0.48807114362716675
Validation loss: 2.0840907096862793

Epoch: 6| Step: 4
Training loss: 0.5138891339302063
Validation loss: 2.0866715709368386

Epoch: 6| Step: 5
Training loss: 0.9153800010681152
Validation loss: 2.1511518160502114

Epoch: 6| Step: 6
Training loss: 0.465930700302124
Validation loss: 2.152421752611796

Epoch: 6| Step: 7
Training loss: 0.5916209816932678
Validation loss: 2.120386819044749

Epoch: 6| Step: 8
Training loss: 0.31156405806541443
Validation loss: 2.1069528261820474

Epoch: 6| Step: 9
Training loss: 0.6104253530502319
Validation loss: 2.146412948767344

Epoch: 6| Step: 10
Training loss: 1.1040350198745728
Validation loss: 2.1409395337104797

Epoch: 6| Step: 11
Training loss: 0.5747414827346802
Validation loss: 2.124492605527242

Epoch: 6| Step: 12
Training loss: 0.44274377822875977
Validation loss: 2.154693086942037

Epoch: 6| Step: 13
Training loss: 0.43542715907096863
Validation loss: 2.086873988310496

Epoch: 237| Step: 0
Training loss: 0.44219064712524414
Validation loss: 2.068131426970164

Epoch: 6| Step: 1
Training loss: 0.2865293025970459
Validation loss: 2.098277429739634

Epoch: 6| Step: 2
Training loss: 0.7373570203781128
Validation loss: 2.102970858414968

Epoch: 6| Step: 3
Training loss: 0.8471121191978455
Validation loss: 2.083485503991445

Epoch: 6| Step: 4
Training loss: 0.7275383472442627
Validation loss: 2.1128001610438027

Epoch: 6| Step: 5
Training loss: 0.2851718068122864
Validation loss: 2.1381492416063943

Epoch: 6| Step: 6
Training loss: 0.7386828660964966
Validation loss: 2.0982512831687927

Epoch: 6| Step: 7
Training loss: 0.3529707193374634
Validation loss: 2.143646478652954

Epoch: 6| Step: 8
Training loss: 0.30328792333602905
Validation loss: 2.0640508929888406

Epoch: 6| Step: 9
Training loss: 0.4588254392147064
Validation loss: 2.0988707741101584

Epoch: 6| Step: 10
Training loss: 0.6290987730026245
Validation loss: 2.057008604208628

Epoch: 6| Step: 11
Training loss: 1.372713327407837
Validation loss: 2.140535295009613

Epoch: 6| Step: 12
Training loss: 0.27136683464050293
Validation loss: 2.145861645539602

Epoch: 6| Step: 13
Training loss: 1.214140772819519
Validation loss: 2.095562199751536

Epoch: 238| Step: 0
Training loss: 0.9981284141540527
Validation loss: 2.1320828994115195

Epoch: 6| Step: 1
Training loss: 0.4216790795326233
Validation loss: 2.1143664518992105

Epoch: 6| Step: 2
Training loss: 0.3093396723270416
Validation loss: 2.1003217697143555

Epoch: 6| Step: 3
Training loss: 0.3476003408432007
Validation loss: 2.141689658164978

Epoch: 6| Step: 4
Training loss: 0.8516489863395691
Validation loss: 2.0898351271947226

Epoch: 6| Step: 5
Training loss: 0.4448079764842987
Validation loss: 2.10297167301178

Epoch: 6| Step: 6
Training loss: 0.6988170146942139
Validation loss: 2.147682785987854

Epoch: 6| Step: 7
Training loss: 1.307205319404602
Validation loss: 2.102669874827067

Epoch: 6| Step: 8
Training loss: 0.4106123745441437
Validation loss: 2.1252523064613342

Epoch: 6| Step: 9
Training loss: 0.663642168045044
Validation loss: 2.064173440138499

Epoch: 6| Step: 10
Training loss: 0.3507137894630432
Validation loss: 2.081522047519684

Epoch: 6| Step: 11
Training loss: 0.5563715696334839
Validation loss: 2.113512078921

Epoch: 6| Step: 12
Training loss: 0.9619814157485962
Validation loss: 2.0925877888997397

Epoch: 6| Step: 13
Training loss: 0.2723692059516907
Validation loss: 2.0869179566701255

Epoch: 239| Step: 0
Training loss: 0.3286815285682678
Validation loss: 2.1177914142608643

Epoch: 6| Step: 1
Training loss: 0.49485135078430176
Validation loss: 2.0914511481920877

Epoch: 6| Step: 2
Training loss: 0.7525455951690674
Validation loss: 2.172682782014211

Epoch: 6| Step: 3
Training loss: 0.8346298933029175
Validation loss: 2.091040849685669

Epoch: 6| Step: 4
Training loss: 0.9121114015579224
Validation loss: 2.0840371449788413

Epoch: 6| Step: 5
Training loss: 0.9960297346115112
Validation loss: 2.12864096959432

Epoch: 6| Step: 6
Training loss: 0.5303726196289062
Validation loss: 2.1384445428848267

Epoch: 6| Step: 7
Training loss: 0.6695364713668823
Validation loss: 2.0915051897366843

Epoch: 6| Step: 8
Training loss: 0.6253458857536316
Validation loss: 2.14750341574351

Epoch: 6| Step: 9
Training loss: 0.3490046262741089
Validation loss: 2.135346293449402

Epoch: 6| Step: 10
Training loss: 0.5986880660057068
Validation loss: 2.1833534836769104

Epoch: 6| Step: 11
Training loss: 0.45002007484436035
Validation loss: 2.1238067150115967

Epoch: 6| Step: 12
Training loss: 0.3205522298812866
Validation loss: 2.144260307153066

Epoch: 6| Step: 13
Training loss: 0.63335120677948
Validation loss: 2.0846569736798606

Epoch: 240| Step: 0
Training loss: 0.6079047918319702
Validation loss: 2.055366814136505

Epoch: 6| Step: 1
Training loss: 0.6027103066444397
Validation loss: 2.1532196402549744

Epoch: 6| Step: 2
Training loss: 0.5705032348632812
Validation loss: 2.118917187054952

Epoch: 6| Step: 3
Training loss: 0.8671209216117859
Validation loss: 2.163853863875071

Epoch: 6| Step: 4
Training loss: 0.46265774965286255
Validation loss: 2.1008276542027793

Epoch: 6| Step: 5
Training loss: 0.5710581541061401
Validation loss: 2.087993005911509

Epoch: 6| Step: 6
Training loss: 0.5851737260818481
Validation loss: 2.141708036263784

Epoch: 6| Step: 7
Training loss: 0.8066900968551636
Validation loss: 2.156889021396637

Epoch: 6| Step: 8
Training loss: 0.7807949781417847
Validation loss: 2.118352015813192

Epoch: 6| Step: 9
Training loss: 0.41850513219833374
Validation loss: 2.1756048997243247

Epoch: 6| Step: 10
Training loss: 0.9554029107093811
Validation loss: 2.1692662835121155

Epoch: 6| Step: 11
Training loss: 0.25985702872276306
Validation loss: 2.133803347746531

Epoch: 6| Step: 12
Training loss: 1.057520866394043
Validation loss: 2.110083738962809

Epoch: 6| Step: 13
Training loss: 0.5301302671432495
Validation loss: 2.1373964746793113

Epoch: 241| Step: 0
Training loss: 0.4212634861469269
Validation loss: 2.0612226923306785

Epoch: 6| Step: 1
Training loss: 0.7633258104324341
Validation loss: 2.113156716028849

Epoch: 6| Step: 2
Training loss: 1.0531394481658936
Validation loss: 2.0867233872413635

Epoch: 6| Step: 3
Training loss: 0.8267637491226196
Validation loss: 2.1364306211471558

Epoch: 6| Step: 4
Training loss: 0.41681647300720215
Validation loss: 2.0882745385169983

Epoch: 6| Step: 5
Training loss: 0.27675965428352356
Validation loss: 2.0753984451293945

Epoch: 6| Step: 6
Training loss: 0.7375301122665405
Validation loss: 2.141392966111501

Epoch: 6| Step: 7
Training loss: 0.6491549015045166
Validation loss: 2.2080265482266745

Epoch: 6| Step: 8
Training loss: 0.42725932598114014
Validation loss: 2.1633538603782654

Epoch: 6| Step: 9
Training loss: 0.9589796662330627
Validation loss: 2.160325547059377

Epoch: 6| Step: 10
Training loss: 0.6764159202575684
Validation loss: 2.16106770435969

Epoch: 6| Step: 11
Training loss: 0.5073171854019165
Validation loss: 2.1034679611523948

Epoch: 6| Step: 12
Training loss: 0.5528558492660522
Validation loss: 2.0757875045140586

Epoch: 6| Step: 13
Training loss: 0.5255765318870544
Validation loss: 2.1121189991633096

Epoch: 242| Step: 0
Training loss: 0.5517321825027466
Validation loss: 2.0856939256191254

Epoch: 6| Step: 1
Training loss: 0.5816613435745239
Validation loss: 2.0830866495768228

Epoch: 6| Step: 2
Training loss: 0.439628541469574
Validation loss: 2.094932198524475

Epoch: 6| Step: 3
Training loss: 0.5922235250473022
Validation loss: 2.1375513672828674

Epoch: 6| Step: 4
Training loss: 0.44775694608688354
Validation loss: 2.0961441000302634

Epoch: 6| Step: 5
Training loss: 1.2839744091033936
Validation loss: 2.1125125885009766

Epoch: 6| Step: 6
Training loss: 0.7775161266326904
Validation loss: 2.163349231084188

Epoch: 6| Step: 7
Training loss: 0.7236733436584473
Validation loss: 2.141705095767975

Epoch: 6| Step: 8
Training loss: 0.8533540964126587
Validation loss: 2.1300995349884033

Epoch: 6| Step: 9
Training loss: 0.7073615789413452
Validation loss: 2.1159336964289346

Epoch: 6| Step: 10
Training loss: 0.8569375276565552
Validation loss: 2.058010518550873

Epoch: 6| Step: 11
Training loss: 0.3520488142967224
Validation loss: 2.060685177644094

Epoch: 6| Step: 12
Training loss: 0.5090833306312561
Validation loss: 2.0976306398709617

Epoch: 6| Step: 13
Training loss: 0.2589491903781891
Validation loss: 2.0929887890815735

Epoch: 243| Step: 0
Training loss: 0.55550217628479
Validation loss: 2.127058267593384

Epoch: 6| Step: 1
Training loss: 0.4910828173160553
Validation loss: 2.111827035744985

Epoch: 6| Step: 2
Training loss: 0.42693203687667847
Validation loss: 2.0955459475517273

Epoch: 6| Step: 3
Training loss: 1.1390384435653687
Validation loss: 2.0981966257095337

Epoch: 6| Step: 4
Training loss: 0.2725200951099396
Validation loss: 2.0786110560099282

Epoch: 6| Step: 5
Training loss: 0.4255823493003845
Validation loss: 2.1000364621480307

Epoch: 6| Step: 6
Training loss: 0.9494184255599976
Validation loss: 2.0831868251164756

Epoch: 6| Step: 7
Training loss: 0.2205706536769867
Validation loss: 2.0917522509892783

Epoch: 6| Step: 8
Training loss: 0.47017261385917664
Validation loss: 2.14323482910792

Epoch: 6| Step: 9
Training loss: 0.7944990992546082
Validation loss: 2.077800909678141

Epoch: 6| Step: 10
Training loss: 0.5718659162521362
Validation loss: 2.142549733320872

Epoch: 6| Step: 11
Training loss: 0.4796169102191925
Validation loss: 2.098169505596161

Epoch: 6| Step: 12
Training loss: 0.6546220779418945
Validation loss: 2.080353081226349

Epoch: 6| Step: 13
Training loss: 0.7364595532417297
Validation loss: 2.0864753325780234

Epoch: 244| Step: 0
Training loss: 0.35288476943969727
Validation loss: 2.090202728907267

Epoch: 6| Step: 1
Training loss: 0.9369808435440063
Validation loss: 2.145353933175405

Epoch: 6| Step: 2
Training loss: 0.48882174491882324
Validation loss: 2.126089930534363

Epoch: 6| Step: 3
Training loss: 0.6594198942184448
Validation loss: 2.073763926823934

Epoch: 6| Step: 4
Training loss: 0.7430069446563721
Validation loss: 2.098506967226664

Epoch: 6| Step: 5
Training loss: 0.7847177386283875
Validation loss: 2.092868208885193

Epoch: 6| Step: 6
Training loss: 0.28984808921813965
Validation loss: 2.094663838545481

Epoch: 6| Step: 7
Training loss: 0.8364392518997192
Validation loss: 2.1187060276667276

Epoch: 6| Step: 8
Training loss: 0.5029008388519287
Validation loss: 2.065559764703115

Epoch: 6| Step: 9
Training loss: 0.6960769295692444
Validation loss: 2.1246092716852822

Epoch: 6| Step: 10
Training loss: 0.3234021067619324
Validation loss: 2.0981641709804535

Epoch: 6| Step: 11
Training loss: 0.5149379372596741
Validation loss: 2.089554707209269

Epoch: 6| Step: 12
Training loss: 0.5067716240882874
Validation loss: 2.104870617389679

Epoch: 6| Step: 13
Training loss: 0.4174878001213074
Validation loss: 2.0784494479497275

Epoch: 245| Step: 0
Training loss: 0.8257628679275513
Validation loss: 2.12311460574468

Epoch: 6| Step: 1
Training loss: 0.7287763953208923
Validation loss: 2.12699294090271

Epoch: 6| Step: 2
Training loss: 1.0063130855560303
Validation loss: 2.1285293102264404

Epoch: 6| Step: 3
Training loss: 0.3595409095287323
Validation loss: 2.1372853914896646

Epoch: 6| Step: 4
Training loss: 0.588822603225708
Validation loss: 2.135426719983419

Epoch: 6| Step: 5
Training loss: 0.7336241602897644
Validation loss: 2.120912194252014

Epoch: 6| Step: 6
Training loss: 0.5705858469009399
Validation loss: 2.1138987143834433

Epoch: 6| Step: 7
Training loss: 0.4502088725566864
Validation loss: 2.1149768233299255

Epoch: 6| Step: 8
Training loss: 0.48785144090652466
Validation loss: 2.0804463823636374

Epoch: 6| Step: 9
Training loss: 0.3051489293575287
Validation loss: 2.1376688480377197

Epoch: 6| Step: 10
Training loss: 0.5639720559120178
Validation loss: 2.127067824204763

Epoch: 6| Step: 11
Training loss: 0.7548438906669617
Validation loss: 2.146749436855316

Epoch: 6| Step: 12
Training loss: 0.44367194175720215
Validation loss: 2.1294875939687095

Epoch: 6| Step: 13
Training loss: 0.3908248543739319
Validation loss: 2.1068964203198752

Epoch: 246| Step: 0
Training loss: 0.7169032096862793
Validation loss: 2.118493219216665

Epoch: 6| Step: 1
Training loss: 0.41814124584198
Validation loss: 2.070782423019409

Epoch: 6| Step: 2
Training loss: 0.7345907688140869
Validation loss: 2.0950868725776672

Epoch: 6| Step: 3
Training loss: 1.0000019073486328
Validation loss: 2.07395068804423

Epoch: 6| Step: 4
Training loss: 0.5785104036331177
Validation loss: 2.1428409218788147

Epoch: 6| Step: 5
Training loss: 1.110224962234497
Validation loss: 2.114357054233551

Epoch: 6| Step: 6
Training loss: 0.41502317786216736
Validation loss: 2.096581141153971

Epoch: 6| Step: 7
Training loss: 0.3399702310562134
Validation loss: 2.1331432461738586

Epoch: 6| Step: 8
Training loss: 0.5267173647880554
Validation loss: 2.175067126750946

Epoch: 6| Step: 9
Training loss: 0.6180351972579956
Validation loss: 2.1347408294677734

Epoch: 6| Step: 10
Training loss: 0.38307565450668335
Validation loss: 2.071922500928243

Epoch: 6| Step: 11
Training loss: 0.3698330521583557
Validation loss: 2.1135221123695374

Epoch: 6| Step: 12
Training loss: 0.5150527358055115
Validation loss: 2.1469547947247825

Epoch: 6| Step: 13
Training loss: 0.3823258876800537
Validation loss: 2.165570875008901

Epoch: 247| Step: 0
Training loss: 0.6380654573440552
Validation loss: 2.1141238609949746

Epoch: 6| Step: 1
Training loss: 0.4747414290904999
Validation loss: 2.0970569849014282

Epoch: 6| Step: 2
Training loss: 0.5357662439346313
Validation loss: 2.1147208015124

Epoch: 6| Step: 3
Training loss: 0.23244161903858185
Validation loss: 2.127231498559316

Epoch: 6| Step: 4
Training loss: 0.4588293433189392
Validation loss: 2.112493614355723

Epoch: 6| Step: 5
Training loss: 0.6960045099258423
Validation loss: 2.1645818750063577

Epoch: 6| Step: 6
Training loss: 0.6082417964935303
Validation loss: 2.1211143930753074

Epoch: 6| Step: 7
Training loss: 0.8854204416275024
Validation loss: 2.1319344639778137

Epoch: 6| Step: 8
Training loss: 0.6409733295440674
Validation loss: 2.162133435408274

Epoch: 6| Step: 9
Training loss: 0.5988088846206665
Validation loss: 2.1592727502187095

Epoch: 6| Step: 10
Training loss: 0.7076566219329834
Validation loss: 2.1140750447909036

Epoch: 6| Step: 11
Training loss: 0.4541241228580475
Validation loss: 2.133493661880493

Epoch: 6| Step: 12
Training loss: 0.7144380211830139
Validation loss: 2.1208494504292807

Epoch: 6| Step: 13
Training loss: 0.7874765396118164
Validation loss: 2.1219027241071067

Epoch: 248| Step: 0
Training loss: 0.7109622359275818
Validation loss: 2.1297295093536377

Epoch: 6| Step: 1
Training loss: 1.0561671257019043
Validation loss: 2.1174189249674478

Epoch: 6| Step: 2
Training loss: 0.8244397640228271
Validation loss: 2.1233007113138833

Epoch: 6| Step: 3
Training loss: 0.33545947074890137
Validation loss: 2.1774372458457947

Epoch: 6| Step: 4
Training loss: 0.43569275736808777
Validation loss: 2.1370134154955545

Epoch: 6| Step: 5
Training loss: 0.31160929799079895
Validation loss: 2.1363980372746787

Epoch: 6| Step: 6
Training loss: 0.7680390477180481
Validation loss: 2.141331672668457

Epoch: 6| Step: 7
Training loss: 0.43171191215515137
Validation loss: 2.063717305660248

Epoch: 6| Step: 8
Training loss: 0.45030999183654785
Validation loss: 2.1202296018600464

Epoch: 6| Step: 9
Training loss: 0.7567978501319885
Validation loss: 2.08458419640859

Epoch: 6| Step: 10
Training loss: 0.3458622395992279
Validation loss: 2.16191295782725

Epoch: 6| Step: 11
Training loss: 0.8638335466384888
Validation loss: 2.0831088622411094

Epoch: 6| Step: 12
Training loss: 0.3831748366355896
Validation loss: 2.1220677693684897

Epoch: 6| Step: 13
Training loss: 0.4473249316215515
Validation loss: 2.0766287446022034

Epoch: 249| Step: 0
Training loss: 0.47220444679260254
Validation loss: 2.087075193723043

Epoch: 6| Step: 1
Training loss: 0.7915948629379272
Validation loss: 2.128397305806478

Epoch: 6| Step: 2
Training loss: 0.8690060377120972
Validation loss: 2.068552871545156

Epoch: 6| Step: 3
Training loss: 0.4408993721008301
Validation loss: 2.074076493581136

Epoch: 6| Step: 4
Training loss: 0.5085291862487793
Validation loss: 2.108215034008026

Epoch: 6| Step: 5
Training loss: 0.5143586993217468
Validation loss: 2.1339577436447144

Epoch: 6| Step: 6
Training loss: 0.4435581862926483
Validation loss: 2.125182271003723

Epoch: 6| Step: 7
Training loss: 0.7735781669616699
Validation loss: 2.1233076453208923

Epoch: 6| Step: 8
Training loss: 0.4800218939781189
Validation loss: 2.139971892038981

Epoch: 6| Step: 9
Training loss: 0.9293391704559326
Validation loss: 2.112729549407959

Epoch: 6| Step: 10
Training loss: 0.4799240827560425
Validation loss: 2.1707014441490173

Epoch: 6| Step: 11
Training loss: 0.5003981590270996
Validation loss: 2.1443856159845986

Epoch: 6| Step: 12
Training loss: 0.23711436986923218
Validation loss: 2.1482101877530417

Epoch: 6| Step: 13
Training loss: 0.581222414970398
Validation loss: 2.1373828053474426

Epoch: 250| Step: 0
Training loss: 0.9592136144638062
Validation loss: 2.123242358366648

Epoch: 6| Step: 1
Training loss: 0.6255079507827759
Validation loss: 2.151795427004496

Epoch: 6| Step: 2
Training loss: 0.22227108478546143
Validation loss: 2.1090346773465476

Epoch: 6| Step: 3
Training loss: 0.8952980041503906
Validation loss: 2.1026593844095864

Epoch: 6| Step: 4
Training loss: 0.29069414734840393
Validation loss: 2.0658531983693442

Epoch: 6| Step: 5
Training loss: 0.7837005257606506
Validation loss: 2.1021799643834433

Epoch: 6| Step: 6
Training loss: 0.7859230041503906
Validation loss: 2.083701471487681

Epoch: 6| Step: 7
Training loss: 0.4037843942642212
Validation loss: 2.0573860009511313

Epoch: 6| Step: 8
Training loss: 0.49174588918685913
Validation loss: 2.0664478739102683

Epoch: 6| Step: 9
Training loss: 0.5251349806785583
Validation loss: 2.136789560317993

Epoch: 6| Step: 10
Training loss: 0.6254090070724487
Validation loss: 2.1357494393984475

Epoch: 6| Step: 11
Training loss: 0.5169607996940613
Validation loss: 2.0649600625038147

Epoch: 6| Step: 12
Training loss: 0.4892939031124115
Validation loss: 2.1309296091397605

Epoch: 6| Step: 13
Training loss: 0.29892075061798096
Validation loss: 2.1076203187306723

Epoch: 251| Step: 0
Training loss: 0.7921194434165955
Validation loss: 2.120494226614634

Epoch: 6| Step: 1
Training loss: 0.28822019696235657
Validation loss: 2.1171253323554993

Epoch: 6| Step: 2
Training loss: 0.3134208619594574
Validation loss: 2.1089389324188232

Epoch: 6| Step: 3
Training loss: 0.4886356592178345
Validation loss: 2.1062870621681213

Epoch: 6| Step: 4
Training loss: 0.5311145186424255
Validation loss: 2.1276210943857827

Epoch: 6| Step: 5
Training loss: 1.8490781784057617
Validation loss: 2.114919145901998

Epoch: 6| Step: 6
Training loss: 0.34285807609558105
Validation loss: 2.1325674653053284

Epoch: 6| Step: 7
Training loss: 0.5412268042564392
Validation loss: 2.1039521296819053

Epoch: 6| Step: 8
Training loss: 0.7439500689506531
Validation loss: 2.1221745212872825

Epoch: 6| Step: 9
Training loss: 0.6816564798355103
Validation loss: 2.1239006916681924

Epoch: 6| Step: 10
Training loss: 0.48100176453590393
Validation loss: 2.098916510740916

Epoch: 6| Step: 11
Training loss: 0.5881962180137634
Validation loss: 2.1354087392489114

Epoch: 6| Step: 12
Training loss: 0.3743220567703247
Validation loss: 2.1801737745602927

Epoch: 6| Step: 13
Training loss: 0.2905503213405609
Validation loss: 2.1952320535977683

Epoch: 252| Step: 0
Training loss: 0.5608539581298828
Validation loss: 2.172213832537333

Epoch: 6| Step: 1
Training loss: 0.488668829202652
Validation loss: 2.1076559821764627

Epoch: 6| Step: 2
Training loss: 0.5634833574295044
Validation loss: 2.1325201789538064

Epoch: 6| Step: 3
Training loss: 0.5219123959541321
Validation loss: 2.083376963933309

Epoch: 6| Step: 4
Training loss: 0.3619876503944397
Validation loss: 2.1336819330851235

Epoch: 6| Step: 5
Training loss: 0.632551908493042
Validation loss: 2.1082231203715005

Epoch: 6| Step: 6
Training loss: 0.630048394203186
Validation loss: 2.112431287765503

Epoch: 6| Step: 7
Training loss: 0.30875110626220703
Validation loss: 2.1054531137148538

Epoch: 6| Step: 8
Training loss: 0.5565026998519897
Validation loss: 2.1290738185246787

Epoch: 6| Step: 9
Training loss: 0.755763828754425
Validation loss: 2.112422545750936

Epoch: 6| Step: 10
Training loss: 0.9836220741271973
Validation loss: 2.151727875073751

Epoch: 6| Step: 11
Training loss: 0.5295475721359253
Validation loss: 2.1061971386273703

Epoch: 6| Step: 12
Training loss: 0.6114245653152466
Validation loss: 2.0941296418507895

Epoch: 6| Step: 13
Training loss: 0.5198550224304199
Validation loss: 2.1564356486002603

Epoch: 253| Step: 0
Training loss: 0.1884281188249588
Validation loss: 2.1550228595733643

Epoch: 6| Step: 1
Training loss: 0.38438230752944946
Validation loss: 2.118293205897013

Epoch: 6| Step: 2
Training loss: 0.34166836738586426
Validation loss: 2.104322830835978

Epoch: 6| Step: 3
Training loss: 0.7366415858268738
Validation loss: 2.1077290972073874

Epoch: 6| Step: 4
Training loss: 0.45868879556655884
Validation loss: 2.1214099327723184

Epoch: 6| Step: 5
Training loss: 0.5300154685974121
Validation loss: 2.0841041803359985

Epoch: 6| Step: 6
Training loss: 0.5569772720336914
Validation loss: 2.0728440483411155

Epoch: 6| Step: 7
Training loss: 0.6228641867637634
Validation loss: 2.0856671929359436

Epoch: 6| Step: 8
Training loss: 0.2631170451641083
Validation loss: 2.106047749519348

Epoch: 6| Step: 9
Training loss: 0.5337298512458801
Validation loss: 2.0837088227272034

Epoch: 6| Step: 10
Training loss: 0.4586260914802551
Validation loss: 2.1273881991704306

Epoch: 6| Step: 11
Training loss: 1.0621907711029053
Validation loss: 2.132542530695597

Epoch: 6| Step: 12
Training loss: 0.8002910614013672
Validation loss: 2.1290345589319863

Epoch: 6| Step: 13
Training loss: 0.8933875560760498
Validation loss: 2.1378947695096335

Epoch: 254| Step: 0
Training loss: 0.3233717083930969
Validation loss: 2.110205372174581

Epoch: 6| Step: 1
Training loss: 0.4366235136985779
Validation loss: 2.098861356576284

Epoch: 6| Step: 2
Training loss: 0.3504546880722046
Validation loss: 2.0820157726605735

Epoch: 6| Step: 3
Training loss: 0.48538848757743835
Validation loss: 2.103527049223582

Epoch: 6| Step: 4
Training loss: 0.42140865325927734
Validation loss: 2.1131911873817444

Epoch: 6| Step: 5
Training loss: 0.6233428716659546
Validation loss: 2.085852305094401

Epoch: 6| Step: 6
Training loss: 0.38213661313056946
Validation loss: 2.150633076826731

Epoch: 6| Step: 7
Training loss: 0.489462673664093
Validation loss: 2.145899752775828

Epoch: 6| Step: 8
Training loss: 0.8218234181404114
Validation loss: 2.0960062940915427

Epoch: 6| Step: 9
Training loss: 0.8968090415000916
Validation loss: 2.1446622411410012

Epoch: 6| Step: 10
Training loss: 0.8319661021232605
Validation loss: 2.100279211997986

Epoch: 6| Step: 11
Training loss: 0.5546201467514038
Validation loss: 2.1167979637781777

Epoch: 6| Step: 12
Training loss: 0.5141707062721252
Validation loss: 2.112107535203298

Epoch: 6| Step: 13
Training loss: 0.6721606254577637
Validation loss: 2.135648330052694

Epoch: 255| Step: 0
Training loss: 0.4904344081878662
Validation loss: 2.121240019798279

Epoch: 6| Step: 1
Training loss: 0.6514478325843811
Validation loss: 2.1063737670580545

Epoch: 6| Step: 2
Training loss: 0.7112436294555664
Validation loss: 2.125510056813558

Epoch: 6| Step: 3
Training loss: 0.5080413818359375
Validation loss: 2.082285165786743

Epoch: 6| Step: 4
Training loss: 0.5749537348747253
Validation loss: 2.085971156756083

Epoch: 6| Step: 5
Training loss: 0.8065218925476074
Validation loss: 2.07630862792333

Epoch: 6| Step: 6
Training loss: 0.5119743347167969
Validation loss: 2.09117982784907

Epoch: 6| Step: 7
Training loss: 0.9789394736289978
Validation loss: 2.0941765109697976

Epoch: 6| Step: 8
Training loss: 0.2951006293296814
Validation loss: 2.055093675851822

Epoch: 6| Step: 9
Training loss: 0.4658891558647156
Validation loss: 2.1433616479237876

Epoch: 6| Step: 10
Training loss: 0.4516548812389374
Validation loss: 2.1007095774014792

Epoch: 6| Step: 11
Training loss: 0.19023117423057556
Validation loss: 2.1089518467585244

Epoch: 6| Step: 12
Training loss: 0.5915553569793701
Validation loss: 2.140941838423411

Epoch: 6| Step: 13
Training loss: 0.38627612590789795
Validation loss: 2.1495232780774436

Epoch: 256| Step: 0
Training loss: 0.3534454107284546
Validation loss: 2.0759447614351907

Epoch: 6| Step: 1
Training loss: 0.4846877455711365
Validation loss: 2.126899778842926

Epoch: 6| Step: 2
Training loss: 0.35741230845451355
Validation loss: 2.1372342507044473

Epoch: 6| Step: 3
Training loss: 0.4518566429615021
Validation loss: 2.1308289964993796

Epoch: 6| Step: 4
Training loss: 0.6932637095451355
Validation loss: 2.1651232639948526

Epoch: 6| Step: 5
Training loss: 0.5032874345779419
Validation loss: 2.1154369115829468

Epoch: 6| Step: 6
Training loss: 0.5430980324745178
Validation loss: 2.1730376879374185

Epoch: 6| Step: 7
Training loss: 0.579109787940979
Validation loss: 2.1470505396525064

Epoch: 6| Step: 8
Training loss: 0.5916920900344849
Validation loss: 2.169633229573568

Epoch: 6| Step: 9
Training loss: 1.0202795267105103
Validation loss: 2.1866153875986734

Epoch: 6| Step: 10
Training loss: 0.2576511800289154
Validation loss: 2.1465858221054077

Epoch: 6| Step: 11
Training loss: 0.6614813208580017
Validation loss: 2.135517696539561

Epoch: 6| Step: 12
Training loss: 1.1333527565002441
Validation loss: 2.091903587182363

Epoch: 6| Step: 13
Training loss: 0.5228700637817383
Validation loss: 2.0783852537473044

Epoch: 257| Step: 0
Training loss: 0.5994362235069275
Validation loss: 2.132680296897888

Epoch: 6| Step: 1
Training loss: 0.8636599779129028
Validation loss: 2.0955191055933633

Epoch: 6| Step: 2
Training loss: 0.3663069009780884
Validation loss: 2.12802517414093

Epoch: 6| Step: 3
Training loss: 0.8771376609802246
Validation loss: 2.1076716780662537

Epoch: 6| Step: 4
Training loss: 0.3661954998970032
Validation loss: 2.152728815873464

Epoch: 6| Step: 5
Training loss: 0.6144843697547913
Validation loss: 2.136219342549642

Epoch: 6| Step: 6
Training loss: 0.41062861680984497
Validation loss: 2.09744801123937

Epoch: 6| Step: 7
Training loss: 0.7873290181159973
Validation loss: 2.1299800674120584

Epoch: 6| Step: 8
Training loss: 0.4304450750350952
Validation loss: 2.1366432507832847

Epoch: 6| Step: 9
Training loss: 0.36966827511787415
Validation loss: 2.1070449550946555

Epoch: 6| Step: 10
Training loss: 0.7520811557769775
Validation loss: 2.107603927453359

Epoch: 6| Step: 11
Training loss: 0.4258069396018982
Validation loss: 2.0860859553019204

Epoch: 6| Step: 12
Training loss: 0.673139214515686
Validation loss: 2.13065497080485

Epoch: 6| Step: 13
Training loss: 0.5084531307220459
Validation loss: 2.1446831822395325

Epoch: 258| Step: 0
Training loss: 0.4935091733932495
Validation loss: 2.1216354767481485

Epoch: 6| Step: 1
Training loss: 0.554085373878479
Validation loss: 2.20872430006663

Epoch: 6| Step: 2
Training loss: 0.7698267698287964
Validation loss: 2.1534615953763327

Epoch: 6| Step: 3
Training loss: 0.5603306293487549
Validation loss: 2.1890255212783813

Epoch: 6| Step: 4
Training loss: 0.4388299584388733
Validation loss: 2.130626400311788

Epoch: 6| Step: 5
Training loss: 0.683806836605072
Validation loss: 2.0974020759264627

Epoch: 6| Step: 6
Training loss: 0.8379555344581604
Validation loss: 2.1216009060541787

Epoch: 6| Step: 7
Training loss: 0.45493730902671814
Validation loss: 2.104043165842692

Epoch: 6| Step: 8
Training loss: 0.5287275910377502
Validation loss: 2.1016727487246194

Epoch: 6| Step: 9
Training loss: 0.2952059209346771
Validation loss: 2.1455055475234985

Epoch: 6| Step: 10
Training loss: 0.552064836025238
Validation loss: 2.1441986362139382

Epoch: 6| Step: 11
Training loss: 0.6981193423271179
Validation loss: 2.1368527015050254

Epoch: 6| Step: 12
Training loss: 0.6570907831192017
Validation loss: 2.111898342768351

Epoch: 6| Step: 13
Training loss: 0.38938450813293457
Validation loss: 2.1042760213216147

Epoch: 259| Step: 0
Training loss: 0.9003361463546753
Validation loss: 2.1347625652949014

Epoch: 6| Step: 1
Training loss: 0.23130986094474792
Validation loss: 2.1083503564198813

Epoch: 6| Step: 2
Training loss: 0.3531752824783325
Validation loss: 2.121011813481649

Epoch: 6| Step: 3
Training loss: 0.8013998866081238
Validation loss: 2.1353918512662253

Epoch: 6| Step: 4
Training loss: 0.33274880051612854
Validation loss: 2.0872522592544556

Epoch: 6| Step: 5
Training loss: 0.26834824681282043
Validation loss: 2.0782347122828164

Epoch: 6| Step: 6
Training loss: 0.4379134774208069
Validation loss: 2.1564181645711265

Epoch: 6| Step: 7
Training loss: 0.9576226472854614
Validation loss: 2.1018609205881753

Epoch: 6| Step: 8
Training loss: 0.4689246416091919
Validation loss: 2.1164872447649636

Epoch: 6| Step: 9
Training loss: 0.6032999157905579
Validation loss: 2.119536499182383

Epoch: 6| Step: 10
Training loss: 0.19480931758880615
Validation loss: 2.1139293909072876

Epoch: 6| Step: 11
Training loss: 0.8939021825790405
Validation loss: 2.0935651858647666

Epoch: 6| Step: 12
Training loss: 0.2893734574317932
Validation loss: 2.141034742196401

Epoch: 6| Step: 13
Training loss: 0.8730031251907349
Validation loss: 2.110461393992106

Epoch: 260| Step: 0
Training loss: 0.477615088224411
Validation loss: 2.132883608341217

Epoch: 6| Step: 1
Training loss: 0.47480934858322144
Validation loss: 2.0854333440462747

Epoch: 6| Step: 2
Training loss: 0.5680128335952759
Validation loss: 2.0916123191515603

Epoch: 6| Step: 3
Training loss: 0.4492139220237732
Validation loss: 2.123278776804606

Epoch: 6| Step: 4
Training loss: 0.820941686630249
Validation loss: 2.120678643385569

Epoch: 6| Step: 5
Training loss: 0.6059936285018921
Validation loss: 2.146789232889811

Epoch: 6| Step: 6
Training loss: 0.7832196950912476
Validation loss: 2.1797614097595215

Epoch: 6| Step: 7
Training loss: 0.33587202429771423
Validation loss: 2.123482326666514

Epoch: 6| Step: 8
Training loss: 0.3514019250869751
Validation loss: 2.161689043045044

Epoch: 6| Step: 9
Training loss: 1.077775001525879
Validation loss: 2.1379966735839844

Epoch: 6| Step: 10
Training loss: 0.5189012885093689
Validation loss: 2.1512293815612793

Epoch: 6| Step: 11
Training loss: 0.40523916482925415
Validation loss: 2.1111428340276084

Epoch: 6| Step: 12
Training loss: 0.7828587293624878
Validation loss: 2.1415665547053018

Epoch: 6| Step: 13
Training loss: 0.5075512528419495
Validation loss: 2.1445997953414917

Epoch: 261| Step: 0
Training loss: 0.657741367816925
Validation loss: 2.1530375878016152

Epoch: 6| Step: 1
Training loss: 0.6029819846153259
Validation loss: 2.145500739415487

Epoch: 6| Step: 2
Training loss: 0.4140673875808716
Validation loss: 2.196304182211558

Epoch: 6| Step: 3
Training loss: 0.2943965792655945
Validation loss: 2.1112928986549377

Epoch: 6| Step: 4
Training loss: 0.3569680452346802
Validation loss: 2.125515401363373

Epoch: 6| Step: 5
Training loss: 0.4064919054508209
Validation loss: 2.0941781401634216

Epoch: 6| Step: 6
Training loss: 0.49870049953460693
Validation loss: 2.1297853191693625

Epoch: 6| Step: 7
Training loss: 0.939182460308075
Validation loss: 2.0867010752360025

Epoch: 6| Step: 8
Training loss: 0.940382719039917
Validation loss: 2.099486231803894

Epoch: 6| Step: 9
Training loss: 0.8082661032676697
Validation loss: 2.1415125131607056

Epoch: 6| Step: 10
Training loss: 0.5708979964256287
Validation loss: 2.1485167940457663

Epoch: 6| Step: 11
Training loss: 0.22017866373062134
Validation loss: 2.157436490058899

Epoch: 6| Step: 12
Training loss: 0.8068011999130249
Validation loss: 2.1674867073694863

Epoch: 6| Step: 13
Training loss: 0.14704550802707672
Validation loss: 2.158169229825338

Epoch: 262| Step: 0
Training loss: 0.6499508023262024
Validation loss: 2.157465477784475

Epoch: 6| Step: 1
Training loss: 0.6005167365074158
Validation loss: 2.099923392136892

Epoch: 6| Step: 2
Training loss: 0.26717910170555115
Validation loss: 2.1297531127929688

Epoch: 6| Step: 3
Training loss: 0.3776776194572449
Validation loss: 2.0715001424153647

Epoch: 6| Step: 4
Training loss: 0.5126163363456726
Validation loss: 2.204874555269877

Epoch: 6| Step: 5
Training loss: 0.27152907848358154
Validation loss: 2.107473313808441

Epoch: 6| Step: 6
Training loss: 1.0454487800598145
Validation loss: 2.0940961639086404

Epoch: 6| Step: 7
Training loss: 0.7605538368225098
Validation loss: 2.150141179561615

Epoch: 6| Step: 8
Training loss: 0.7706217765808105
Validation loss: 2.0856683452924094

Epoch: 6| Step: 9
Training loss: 0.6182190775871277
Validation loss: 2.0943198998769126

Epoch: 6| Step: 10
Training loss: 0.5324413776397705
Validation loss: 2.16020667552948

Epoch: 6| Step: 11
Training loss: 0.6235664486885071
Validation loss: 2.1640319228172302

Epoch: 6| Step: 12
Training loss: 0.3580048084259033
Validation loss: 2.1318695147832236

Epoch: 6| Step: 13
Training loss: 0.48364168405532837
Validation loss: 2.1265608270963035

Epoch: 263| Step: 0
Training loss: 0.32658958435058594
Validation loss: 2.1162707606951394

Epoch: 6| Step: 1
Training loss: 0.48566925525665283
Validation loss: 2.119963745276133

Epoch: 6| Step: 2
Training loss: 0.4718858599662781
Validation loss: 2.125292102495829

Epoch: 6| Step: 3
Training loss: 0.5045927166938782
Validation loss: 2.1305251518885293

Epoch: 6| Step: 4
Training loss: 0.42819732427597046
Validation loss: 2.0927218198776245

Epoch: 6| Step: 5
Training loss: 0.5858389139175415
Validation loss: 2.0858159263928733

Epoch: 6| Step: 6
Training loss: 0.4727291762828827
Validation loss: 2.1458562215169272

Epoch: 6| Step: 7
Training loss: 0.3677150011062622
Validation loss: 2.0516464908917746

Epoch: 6| Step: 8
Training loss: 0.34674790501594543
Validation loss: 2.115094522635142

Epoch: 6| Step: 9
Training loss: 0.4147011339664459
Validation loss: 2.1002657810846963

Epoch: 6| Step: 10
Training loss: 0.3568892180919647
Validation loss: 2.121364732583364

Epoch: 6| Step: 11
Training loss: 1.5623494386672974
Validation loss: 2.093924860159556

Epoch: 6| Step: 12
Training loss: 0.5650694966316223
Validation loss: 2.0549689133961997

Epoch: 6| Step: 13
Training loss: 0.6584509611129761
Validation loss: 2.1117818355560303

Epoch: 264| Step: 0
Training loss: 0.49405351281166077
Validation loss: 2.111570417881012

Epoch: 6| Step: 1
Training loss: 0.6128519773483276
Validation loss: 2.121062397956848

Epoch: 6| Step: 2
Training loss: 0.29544997215270996
Validation loss: 2.0900171995162964

Epoch: 6| Step: 3
Training loss: 0.658440351486206
Validation loss: 2.0931652784347534

Epoch: 6| Step: 4
Training loss: 0.6973936557769775
Validation loss: 2.067653695742289

Epoch: 6| Step: 5
Training loss: 0.44625282287597656
Validation loss: 2.098385294278463

Epoch: 6| Step: 6
Training loss: 0.4054832458496094
Validation loss: 2.1143341263135276

Epoch: 6| Step: 7
Training loss: 0.49799060821533203
Validation loss: 2.105165402094523

Epoch: 6| Step: 8
Training loss: 0.5389565229415894
Validation loss: 2.1434155305226645

Epoch: 6| Step: 9
Training loss: 0.8732402324676514
Validation loss: 2.0957345167795816

Epoch: 6| Step: 10
Training loss: 0.3731468915939331
Validation loss: 2.121484339237213

Epoch: 6| Step: 11
Training loss: 0.376653254032135
Validation loss: 2.0794275999069214

Epoch: 6| Step: 12
Training loss: 0.9379215240478516
Validation loss: 2.0761029918988547

Epoch: 6| Step: 13
Training loss: 0.2995679974555969
Validation loss: 2.120217263698578

Epoch: 265| Step: 0
Training loss: 0.4495149254798889
Validation loss: 2.1105341712633767

Epoch: 6| Step: 1
Training loss: 0.7740356922149658
Validation loss: 2.1606363455454507

Epoch: 6| Step: 2
Training loss: 0.7823060154914856
Validation loss: 2.0973147551218667

Epoch: 6| Step: 3
Training loss: 0.384307324886322
Validation loss: 2.0738144914309182

Epoch: 6| Step: 4
Training loss: 0.5783646106719971
Validation loss: 2.151611566543579

Epoch: 6| Step: 5
Training loss: 0.5860081911087036
Validation loss: 2.0883052150408425

Epoch: 6| Step: 6
Training loss: 0.3044254183769226
Validation loss: 2.1456400950749717

Epoch: 6| Step: 7
Training loss: 0.7428023815155029
Validation loss: 2.0965671936670938

Epoch: 6| Step: 8
Training loss: 0.5933140516281128
Validation loss: 2.1159367163976035

Epoch: 6| Step: 9
Training loss: 0.371843159198761
Validation loss: 2.130121429761251

Epoch: 6| Step: 10
Training loss: 0.412075400352478
Validation loss: 2.0574145317077637

Epoch: 6| Step: 11
Training loss: 0.6201925277709961
Validation loss: 2.102264404296875

Epoch: 6| Step: 12
Training loss: 0.3594309687614441
Validation loss: 2.1239224473635354

Epoch: 6| Step: 13
Training loss: 0.5938995480537415
Validation loss: 2.076917886734009

Epoch: 266| Step: 0
Training loss: 0.5688213109970093
Validation loss: 2.0588093201319375

Epoch: 6| Step: 1
Training loss: 0.43624359369277954
Validation loss: 2.140305538972219

Epoch: 6| Step: 2
Training loss: 0.7121769189834595
Validation loss: 2.0966779390970864

Epoch: 6| Step: 3
Training loss: 0.3269992172718048
Validation loss: 2.103285789489746

Epoch: 6| Step: 4
Training loss: 0.5135916471481323
Validation loss: 2.0790563027064004

Epoch: 6| Step: 5
Training loss: 0.7156046628952026
Validation loss: 2.1782888770103455

Epoch: 6| Step: 6
Training loss: 0.6887956261634827
Validation loss: 2.1007279753684998

Epoch: 6| Step: 7
Training loss: 0.2262924164533615
Validation loss: 2.1514590978622437

Epoch: 6| Step: 8
Training loss: 0.7485238313674927
Validation loss: 2.1595098972320557

Epoch: 6| Step: 9
Training loss: 0.38263756036758423
Validation loss: 2.1540128588676453

Epoch: 6| Step: 10
Training loss: 0.6781783103942871
Validation loss: 2.1358779668807983

Epoch: 6| Step: 11
Training loss: 0.46902650594711304
Validation loss: 2.134483516216278

Epoch: 6| Step: 12
Training loss: 0.24140667915344238
Validation loss: 2.15194563070933

Epoch: 6| Step: 13
Training loss: 0.7242331504821777
Validation loss: 2.139166831970215

Epoch: 267| Step: 0
Training loss: 0.2586495280265808
Validation loss: 2.124500036239624

Epoch: 6| Step: 1
Training loss: 0.44890695810317993
Validation loss: 2.1209383805592856

Epoch: 6| Step: 2
Training loss: 0.5186329483985901
Validation loss: 2.113544444243113

Epoch: 6| Step: 3
Training loss: 0.5931916832923889
Validation loss: 2.0800148447354636

Epoch: 6| Step: 4
Training loss: 0.5179843902587891
Validation loss: 2.126590927441915

Epoch: 6| Step: 5
Training loss: 0.47882890701293945
Validation loss: 2.120545824368795

Epoch: 6| Step: 6
Training loss: 0.4200279414653778
Validation loss: 2.0792638262112937

Epoch: 6| Step: 7
Training loss: 0.13215717673301697
Validation loss: 2.117837150891622

Epoch: 6| Step: 8
Training loss: 0.7181631326675415
Validation loss: 2.0811848243077598

Epoch: 6| Step: 9
Training loss: 0.32633355259895325
Validation loss: 2.1237796346346536

Epoch: 6| Step: 10
Training loss: 1.1144356727600098
Validation loss: 2.1564898689587912

Epoch: 6| Step: 11
Training loss: 0.5384714603424072
Validation loss: 2.125506043434143

Epoch: 6| Step: 12
Training loss: 0.46440836787223816
Validation loss: 2.1319026350975037

Epoch: 6| Step: 13
Training loss: 0.751157283782959
Validation loss: 2.1221540172894797

Epoch: 268| Step: 0
Training loss: 0.31557682156562805
Validation loss: 2.1529992818832397

Epoch: 6| Step: 1
Training loss: 1.3272106647491455
Validation loss: 2.0920984745025635

Epoch: 6| Step: 2
Training loss: 0.6388373970985413
Validation loss: 2.119538644949595

Epoch: 6| Step: 3
Training loss: 0.3832007348537445
Validation loss: 2.0953225096066794

Epoch: 6| Step: 4
Training loss: 0.37935227155685425
Validation loss: 2.1157319744428

Epoch: 6| Step: 5
Training loss: 0.8517186641693115
Validation loss: 2.135429302851359

Epoch: 6| Step: 6
Training loss: 0.6876046657562256
Validation loss: 2.1361933747927346

Epoch: 6| Step: 7
Training loss: 0.34879806637763977
Validation loss: 2.1291826963424683

Epoch: 6| Step: 8
Training loss: 0.4103204309940338
Validation loss: 2.147075891494751

Epoch: 6| Step: 9
Training loss: 0.3462842106819153
Validation loss: 2.148742953936259

Epoch: 6| Step: 10
Training loss: 0.7355789542198181
Validation loss: 2.1549452344576516

Epoch: 6| Step: 11
Training loss: 0.3685114085674286
Validation loss: 2.1535771091779075

Epoch: 6| Step: 12
Training loss: 0.2134060114622116
Validation loss: 2.1360280513763428

Epoch: 6| Step: 13
Training loss: 0.4289529323577881
Validation loss: 2.1214842001597085

Epoch: 269| Step: 0
Training loss: 0.39622288942337036
Validation loss: 2.085598329703013

Epoch: 6| Step: 1
Training loss: 0.4413282573223114
Validation loss: 2.1259888807932534

Epoch: 6| Step: 2
Training loss: 0.2599776089191437
Validation loss: 2.112206816673279

Epoch: 6| Step: 3
Training loss: 0.9785289764404297
Validation loss: 2.143353899319967

Epoch: 6| Step: 4
Training loss: 0.3286701440811157
Validation loss: 2.06487238407135

Epoch: 6| Step: 5
Training loss: 0.3025543987751007
Validation loss: 2.1273951530456543

Epoch: 6| Step: 6
Training loss: 0.5725209712982178
Validation loss: 2.087901532649994

Epoch: 6| Step: 7
Training loss: 0.4087287187576294
Validation loss: 2.066608250141144

Epoch: 6| Step: 8
Training loss: 0.49748557806015015
Validation loss: 2.095770001411438

Epoch: 6| Step: 9
Training loss: 0.7528259754180908
Validation loss: 2.176228861014048

Epoch: 6| Step: 10
Training loss: 1.0016882419586182
Validation loss: 2.144483049710592

Epoch: 6| Step: 11
Training loss: 0.4037548005580902
Validation loss: 2.11750320593516

Epoch: 6| Step: 12
Training loss: 0.4849916696548462
Validation loss: 2.087313791116079

Epoch: 6| Step: 13
Training loss: 0.27797383069992065
Validation loss: 2.178034722805023

Epoch: 270| Step: 0
Training loss: 0.5215553641319275
Validation loss: 2.1389361222585044

Epoch: 6| Step: 1
Training loss: 0.6931971907615662
Validation loss: 2.1355374654134116

Epoch: 6| Step: 2
Training loss: 0.4026808440685272
Validation loss: 2.146787722905477

Epoch: 6| Step: 3
Training loss: 0.3340727686882019
Validation loss: 2.1256460348765054

Epoch: 6| Step: 4
Training loss: 0.7422699332237244
Validation loss: 2.1169277826944985

Epoch: 6| Step: 5
Training loss: 0.5744861960411072
Validation loss: 2.1281877160072327

Epoch: 6| Step: 6
Training loss: 0.5048436522483826
Validation loss: 2.1205976804097495

Epoch: 6| Step: 7
Training loss: 0.49506351351737976
Validation loss: 2.154219468434652

Epoch: 6| Step: 8
Training loss: 0.30856218934059143
Validation loss: 2.1187549034754434

Epoch: 6| Step: 9
Training loss: 0.36632147431373596
Validation loss: 2.113205154736837

Epoch: 6| Step: 10
Training loss: 0.26109403371810913
Validation loss: 2.1221978863080344

Epoch: 6| Step: 11
Training loss: 0.317427396774292
Validation loss: 2.133354902267456

Epoch: 6| Step: 12
Training loss: 0.8218850493431091
Validation loss: 2.1537251273790994

Epoch: 6| Step: 13
Training loss: 1.0441182851791382
Validation loss: 2.087595363457998

Epoch: 271| Step: 0
Training loss: 0.24305424094200134
Validation loss: 2.109173059463501

Epoch: 6| Step: 1
Training loss: 0.7860145568847656
Validation loss: 2.092721422513326

Epoch: 6| Step: 2
Training loss: 0.3357031047344208
Validation loss: 2.0836866895357766

Epoch: 6| Step: 3
Training loss: 0.7123961448669434
Validation loss: 2.096985121568044

Epoch: 6| Step: 4
Training loss: 0.5349112749099731
Validation loss: 2.089002251625061

Epoch: 6| Step: 5
Training loss: 0.46414750814437866
Validation loss: 2.095538020133972

Epoch: 6| Step: 6
Training loss: 0.4516807198524475
Validation loss: 2.1121339400609336

Epoch: 6| Step: 7
Training loss: 0.3871992826461792
Validation loss: 2.1341100136439004

Epoch: 6| Step: 8
Training loss: 0.5964747667312622
Validation loss: 2.096754272778829

Epoch: 6| Step: 9
Training loss: 0.49999094009399414
Validation loss: 2.1648834943771362

Epoch: 6| Step: 10
Training loss: 0.7865700125694275
Validation loss: 2.1516870061556497

Epoch: 6| Step: 11
Training loss: 0.461719810962677
Validation loss: 2.0983397165934243

Epoch: 6| Step: 12
Training loss: 0.4914904236793518
Validation loss: 2.1356456677118936

Epoch: 6| Step: 13
Training loss: 0.6772996187210083
Validation loss: 2.0652429660161338

Epoch: 272| Step: 0
Training loss: 0.5369536876678467
Validation loss: 2.0551472703615823

Epoch: 6| Step: 1
Training loss: 0.4499322772026062
Validation loss: 2.094462811946869

Epoch: 6| Step: 2
Training loss: 0.8564796447753906
Validation loss: 2.0901310443878174

Epoch: 6| Step: 3
Training loss: 0.588139533996582
Validation loss: 2.124022920926412

Epoch: 6| Step: 4
Training loss: 0.20114608108997345
Validation loss: 2.1511521339416504

Epoch: 6| Step: 5
Training loss: 0.4897393584251404
Validation loss: 2.1487661401430764

Epoch: 6| Step: 6
Training loss: 0.29674050211906433
Validation loss: 2.1822371085484824

Epoch: 6| Step: 7
Training loss: 0.7198716998100281
Validation loss: 2.151279032230377

Epoch: 6| Step: 8
Training loss: 0.6215130090713501
Validation loss: 2.198768138885498

Epoch: 6| Step: 9
Training loss: 0.6244188547134399
Validation loss: 2.1399304270744324

Epoch: 6| Step: 10
Training loss: 0.5384525060653687
Validation loss: 2.1037863890329995

Epoch: 6| Step: 11
Training loss: 0.39284706115722656
Validation loss: 2.1165216167767844

Epoch: 6| Step: 12
Training loss: 0.8154290914535522
Validation loss: 2.1353598833084106

Epoch: 6| Step: 13
Training loss: 0.9343928694725037
Validation loss: 2.091887334982554

Epoch: 273| Step: 0
Training loss: 0.5856338739395142
Validation loss: 2.1254972418149314

Epoch: 6| Step: 1
Training loss: 0.33043673634529114
Validation loss: 2.0997591416041055

Epoch: 6| Step: 2
Training loss: 0.45421820878982544
Validation loss: 2.1447903315226235

Epoch: 6| Step: 3
Training loss: 0.29134413599967957
Validation loss: 2.1279717882474265

Epoch: 6| Step: 4
Training loss: 0.6967546939849854
Validation loss: 2.1733146707216897

Epoch: 6| Step: 5
Training loss: 0.5353344678878784
Validation loss: 2.1304834485054016

Epoch: 6| Step: 6
Training loss: 0.7820698618888855
Validation loss: 2.130198578039805

Epoch: 6| Step: 7
Training loss: 1.0101385116577148
Validation loss: 2.0807326237360635

Epoch: 6| Step: 8
Training loss: 0.7290011048316956
Validation loss: 2.0958635409673056

Epoch: 6| Step: 9
Training loss: 0.4442140758037567
Validation loss: 2.1149954001108804

Epoch: 6| Step: 10
Training loss: 0.49940216541290283
Validation loss: 2.091498057047526

Epoch: 6| Step: 11
Training loss: 0.702765166759491
Validation loss: 2.1077821254730225

Epoch: 6| Step: 12
Training loss: 0.3478187322616577
Validation loss: 2.1152127981185913

Epoch: 6| Step: 13
Training loss: 0.5261258482933044
Validation loss: 2.1245577732721963

Epoch: 274| Step: 0
Training loss: 0.34710222482681274
Validation loss: 2.1213058829307556

Epoch: 6| Step: 1
Training loss: 0.4967276453971863
Validation loss: 2.1165610949198403

Epoch: 6| Step: 2
Training loss: 0.486737459897995
Validation loss: 2.151101768016815

Epoch: 6| Step: 3
Training loss: 0.42673200368881226
Validation loss: 2.112347503503164

Epoch: 6| Step: 4
Training loss: 0.44914883375167847
Validation loss: 2.113996426264445

Epoch: 6| Step: 5
Training loss: 0.42900925874710083
Validation loss: 2.1317429741223655

Epoch: 6| Step: 6
Training loss: 0.4048706889152527
Validation loss: 2.1464339097340903

Epoch: 6| Step: 7
Training loss: 0.4105886220932007
Validation loss: 2.0841013391812644

Epoch: 6| Step: 8
Training loss: 0.8408266305923462
Validation loss: 2.094536622365316

Epoch: 6| Step: 9
Training loss: 0.5842841863632202
Validation loss: 2.097578545411428

Epoch: 6| Step: 10
Training loss: 0.6850336194038391
Validation loss: 2.1589234670003257

Epoch: 6| Step: 11
Training loss: 1.0311062335968018
Validation loss: 2.1430996457735696

Epoch: 6| Step: 12
Training loss: 0.18336725234985352
Validation loss: 2.1044904390970864

Epoch: 6| Step: 13
Training loss: 0.5919910669326782
Validation loss: 2.138879934946696

Epoch: 275| Step: 0
Training loss: 0.49038830399513245
Validation loss: 2.1488287647565207

Epoch: 6| Step: 1
Training loss: 0.8407245874404907
Validation loss: 2.1531342267990112

Epoch: 6| Step: 2
Training loss: 0.8290039896965027
Validation loss: 2.0986839532852173

Epoch: 6| Step: 3
Training loss: 0.35354259610176086
Validation loss: 2.123019357522329

Epoch: 6| Step: 4
Training loss: 0.5656875967979431
Validation loss: 2.125150481859843

Epoch: 6| Step: 5
Training loss: 0.3603331744670868
Validation loss: 2.070157766342163

Epoch: 6| Step: 6
Training loss: 0.42019158601760864
Validation loss: 2.081209639708201

Epoch: 6| Step: 7
Training loss: 0.5667939186096191
Validation loss: 2.1452927788098655

Epoch: 6| Step: 8
Training loss: 0.6055111885070801
Validation loss: 2.1012364824612937

Epoch: 6| Step: 9
Training loss: 0.3512634038925171
Validation loss: 2.1596886912981668

Epoch: 6| Step: 10
Training loss: 0.43535199761390686
Validation loss: 2.135482370853424

Epoch: 6| Step: 11
Training loss: 0.37838178873062134
Validation loss: 2.154654542605082

Epoch: 6| Step: 12
Training loss: 0.9100363254547119
Validation loss: 2.0918447573979697

Epoch: 6| Step: 13
Training loss: 0.23771683871746063
Validation loss: 2.077262361844381

Epoch: 276| Step: 0
Training loss: 0.46043306589126587
Validation loss: 2.15754900376002

Epoch: 6| Step: 1
Training loss: 0.22232474386692047
Validation loss: 2.1428678234418235

Epoch: 6| Step: 2
Training loss: 0.4112425446510315
Validation loss: 2.089533189932505

Epoch: 6| Step: 3
Training loss: 0.8056831955909729
Validation loss: 2.1227897802988687

Epoch: 6| Step: 4
Training loss: 1.0572316646575928
Validation loss: 2.133365531762441

Epoch: 6| Step: 5
Training loss: 0.27463293075561523
Validation loss: 2.135164817174276

Epoch: 6| Step: 6
Training loss: 0.5106213092803955
Validation loss: 2.1515767176946006

Epoch: 6| Step: 7
Training loss: 0.7263588905334473
Validation loss: 2.1118878523508706

Epoch: 6| Step: 8
Training loss: 0.3010382652282715
Validation loss: 2.1017942825953164

Epoch: 6| Step: 9
Training loss: 0.7276955842971802
Validation loss: 2.1134042143821716

Epoch: 6| Step: 10
Training loss: 0.37503957748413086
Validation loss: 2.0983606775601706

Epoch: 6| Step: 11
Training loss: 0.43950584530830383
Validation loss: 2.128068765004476

Epoch: 6| Step: 12
Training loss: 0.5587432384490967
Validation loss: 2.1323134700457254

Epoch: 6| Step: 13
Training loss: 0.1919296383857727
Validation loss: 2.1376790006955466

Epoch: 277| Step: 0
Training loss: 0.3270479440689087
Validation loss: 2.1161120732625327

Epoch: 6| Step: 1
Training loss: 0.77873295545578
Validation loss: 2.1087490916252136

Epoch: 6| Step: 2
Training loss: 0.395721435546875
Validation loss: 2.143491586049398

Epoch: 6| Step: 3
Training loss: 0.42671695351600647
Validation loss: 2.143664757410685

Epoch: 6| Step: 4
Training loss: 0.5685905814170837
Validation loss: 2.151162644227346

Epoch: 6| Step: 5
Training loss: 0.3921467661857605
Validation loss: 2.105767528216044

Epoch: 6| Step: 6
Training loss: 0.40165942907333374
Validation loss: 2.0785663723945618

Epoch: 6| Step: 7
Training loss: 0.4282529354095459
Validation loss: 2.116399089495341

Epoch: 6| Step: 8
Training loss: 0.6171382665634155
Validation loss: 2.1169617772102356

Epoch: 6| Step: 9
Training loss: 0.4156682789325714
Validation loss: 2.1539677580197654

Epoch: 6| Step: 10
Training loss: 0.3049372434616089
Validation loss: 2.1297876040140786

Epoch: 6| Step: 11
Training loss: 0.8441159725189209
Validation loss: 2.1440123518308005

Epoch: 6| Step: 12
Training loss: 0.42651861906051636
Validation loss: 2.1141120195388794

Epoch: 6| Step: 13
Training loss: 0.8663994669914246
Validation loss: 2.16042560338974

Epoch: 278| Step: 0
Training loss: 0.41699331998825073
Validation loss: 2.155673702557882

Epoch: 6| Step: 1
Training loss: 0.37073957920074463
Validation loss: 2.0921239455540976

Epoch: 6| Step: 2
Training loss: 0.3475518524646759
Validation loss: 2.184699376424154

Epoch: 6| Step: 3
Training loss: 0.5239595770835876
Validation loss: 2.1252335707346597

Epoch: 6| Step: 4
Training loss: 0.42013227939605713
Validation loss: 2.154330611228943

Epoch: 6| Step: 5
Training loss: 0.6786748170852661
Validation loss: 2.090951979160309

Epoch: 6| Step: 6
Training loss: 0.39411434531211853
Validation loss: 2.1364955504735312

Epoch: 6| Step: 7
Training loss: 0.5000672936439514
Validation loss: 2.1013265450795493

Epoch: 6| Step: 8
Training loss: 0.25217747688293457
Validation loss: 2.122711718082428

Epoch: 6| Step: 9
Training loss: 0.45641258358955383
Validation loss: 2.1446382800738015

Epoch: 6| Step: 10
Training loss: 0.6438135504722595
Validation loss: 2.071502466996511

Epoch: 6| Step: 11
Training loss: 0.8094570636749268
Validation loss: 2.098246614138285

Epoch: 6| Step: 12
Training loss: 1.0337376594543457
Validation loss: 2.128537972768148

Epoch: 6| Step: 13
Training loss: 0.5958060026168823
Validation loss: 2.108301103115082

Epoch: 279| Step: 0
Training loss: 0.36568695306777954
Validation loss: 2.1313161055246987

Epoch: 6| Step: 1
Training loss: 0.5196505784988403
Validation loss: 2.1401060024897256

Epoch: 6| Step: 2
Training loss: 1.0075751543045044
Validation loss: 2.1340742905934653

Epoch: 6| Step: 3
Training loss: 0.5148152112960815
Validation loss: 2.1405754685401917

Epoch: 6| Step: 4
Training loss: 0.3614265024662018
Validation loss: 2.1117355028788247

Epoch: 6| Step: 5
Training loss: 0.538175106048584
Validation loss: 2.180026392141978

Epoch: 6| Step: 6
Training loss: 0.41680359840393066
Validation loss: 2.1293104887008667

Epoch: 6| Step: 7
Training loss: 0.4562304615974426
Validation loss: 2.0827422539393106

Epoch: 6| Step: 8
Training loss: 0.9258432388305664
Validation loss: 2.0942222674687705

Epoch: 6| Step: 9
Training loss: 0.6155086755752563
Validation loss: 2.125442683696747

Epoch: 6| Step: 10
Training loss: 0.5402524471282959
Validation loss: 2.093490262826284

Epoch: 6| Step: 11
Training loss: 0.32742077112197876
Validation loss: 2.0919798811276755

Epoch: 6| Step: 12
Training loss: 0.4970099925994873
Validation loss: 2.1721812089284263

Epoch: 6| Step: 13
Training loss: 0.3091006278991699
Validation loss: 2.079487681388855

Epoch: 280| Step: 0
Training loss: 0.8183446526527405
Validation loss: 2.114367047945658

Epoch: 6| Step: 1
Training loss: 0.6920596361160278
Validation loss: 2.121790806452433

Epoch: 6| Step: 2
Training loss: 0.4476242661476135
Validation loss: 2.0623980363210044

Epoch: 6| Step: 3
Training loss: 0.5407224893569946
Validation loss: 2.1465256611506143

Epoch: 6| Step: 4
Training loss: 0.5245674848556519
Validation loss: 2.0631885131200156

Epoch: 6| Step: 5
Training loss: 0.8582724332809448
Validation loss: 2.066216508547465

Epoch: 6| Step: 6
Training loss: 0.25110873579978943
Validation loss: 2.1235596338907876

Epoch: 6| Step: 7
Training loss: 0.29033249616622925
Validation loss: 2.1069952845573425

Epoch: 6| Step: 8
Training loss: 0.6725869178771973
Validation loss: 2.111639757951101

Epoch: 6| Step: 9
Training loss: 0.2953298091888428
Validation loss: 2.1406584779421487

Epoch: 6| Step: 10
Training loss: 0.5563255548477173
Validation loss: 2.102373480796814

Epoch: 6| Step: 11
Training loss: 0.29404133558273315
Validation loss: 2.115219473838806

Epoch: 6| Step: 12
Training loss: 0.3738504648208618
Validation loss: 2.143463055292765

Epoch: 6| Step: 13
Training loss: 0.40717482566833496
Validation loss: 2.1199608047803244

Epoch: 281| Step: 0
Training loss: 0.4148116111755371
Validation loss: 2.1270224849383035

Epoch: 6| Step: 1
Training loss: 0.6269992589950562
Validation loss: 2.1490801572799683

Epoch: 6| Step: 2
Training loss: 0.6764321327209473
Validation loss: 2.1498224337895713

Epoch: 6| Step: 3
Training loss: 0.6269073486328125
Validation loss: 2.069609542687734

Epoch: 6| Step: 4
Training loss: 0.3022744953632355
Validation loss: 2.121050556500753

Epoch: 6| Step: 5
Training loss: 0.5864923000335693
Validation loss: 2.1299827098846436

Epoch: 6| Step: 6
Training loss: 0.6597311496734619
Validation loss: 2.126236915588379

Epoch: 6| Step: 7
Training loss: 0.42242321372032166
Validation loss: 2.123018185297648

Epoch: 6| Step: 8
Training loss: 0.32208308577537537
Validation loss: 2.1058423121770224

Epoch: 6| Step: 9
Training loss: 0.41326385736465454
Validation loss: 2.105178793271383

Epoch: 6| Step: 10
Training loss: 0.31140226125717163
Validation loss: 2.0976252953211465

Epoch: 6| Step: 11
Training loss: 0.22946235537528992
Validation loss: 2.140940487384796

Epoch: 6| Step: 12
Training loss: 0.6868528723716736
Validation loss: 2.1350786089897156

Epoch: 6| Step: 13
Training loss: 0.6978534460067749
Validation loss: 2.121316413084666

Epoch: 282| Step: 0
Training loss: 0.3415449261665344
Validation loss: 2.1510921120643616

Epoch: 6| Step: 1
Training loss: 0.5674596428871155
Validation loss: 2.1606847047805786

Epoch: 6| Step: 2
Training loss: 0.808814287185669
Validation loss: 2.1145556370417276

Epoch: 6| Step: 3
Training loss: 0.49887531995773315
Validation loss: 2.1893760164578757

Epoch: 6| Step: 4
Training loss: 0.6888165473937988
Validation loss: 2.139367858568827

Epoch: 6| Step: 5
Training loss: 0.47990286350250244
Validation loss: 2.1528420050938926

Epoch: 6| Step: 6
Training loss: 0.7050331234931946
Validation loss: 2.0948790113131204

Epoch: 6| Step: 7
Training loss: 0.5981861352920532
Validation loss: 2.1501882473627725

Epoch: 6| Step: 8
Training loss: 0.26061639189720154
Validation loss: 2.1316253940264382

Epoch: 6| Step: 9
Training loss: 0.2641390860080719
Validation loss: 2.136680801709493

Epoch: 6| Step: 10
Training loss: 0.5626084804534912
Validation loss: 2.142959415912628

Epoch: 6| Step: 11
Training loss: 1.0339124202728271
Validation loss: 2.1112573544184365

Epoch: 6| Step: 12
Training loss: 0.2905585765838623
Validation loss: 2.12071430683136

Epoch: 6| Step: 13
Training loss: 0.4373776316642761
Validation loss: 2.139806389808655

Epoch: 283| Step: 0
Training loss: 0.5011511445045471
Validation loss: 2.1304274598757424

Epoch: 6| Step: 1
Training loss: 0.5778708457946777
Validation loss: 2.100995043913523

Epoch: 6| Step: 2
Training loss: 0.1607489436864853
Validation loss: 2.0878796776135764

Epoch: 6| Step: 3
Training loss: 0.1816006749868393
Validation loss: 2.100300431251526

Epoch: 6| Step: 4
Training loss: 0.7264775037765503
Validation loss: 2.1155242721239724

Epoch: 6| Step: 5
Training loss: 0.20371508598327637
Validation loss: 2.1301987369855246

Epoch: 6| Step: 6
Training loss: 0.18077971041202545
Validation loss: 2.0811281204223633

Epoch: 6| Step: 7
Training loss: 0.6278493404388428
Validation loss: 2.0825913548469543

Epoch: 6| Step: 8
Training loss: 1.0768671035766602
Validation loss: 2.162785212198893

Epoch: 6| Step: 9
Training loss: 0.9951955676078796
Validation loss: 2.1636845072110495

Epoch: 6| Step: 10
Training loss: 0.36956238746643066
Validation loss: 2.1261165340741477

Epoch: 6| Step: 11
Training loss: 0.30406448245048523
Validation loss: 2.1731114188830056

Epoch: 6| Step: 12
Training loss: 0.5018919706344604
Validation loss: 2.139009654521942

Epoch: 6| Step: 13
Training loss: 0.33596327900886536
Validation loss: 2.1302581826845803

Epoch: 284| Step: 0
Training loss: 0.46012985706329346
Validation loss: 2.102342128753662

Epoch: 6| Step: 1
Training loss: 0.7530089616775513
Validation loss: 2.0963015953699746

Epoch: 6| Step: 2
Training loss: 0.582184910774231
Validation loss: 2.1291927695274353

Epoch: 6| Step: 3
Training loss: 0.4522297978401184
Validation loss: 2.098214109738668

Epoch: 6| Step: 4
Training loss: 0.49362629652023315
Validation loss: 2.145265579223633

Epoch: 6| Step: 5
Training loss: 0.6766386032104492
Validation loss: 2.1043737729390464

Epoch: 6| Step: 6
Training loss: 0.7391579151153564
Validation loss: 2.123018185297648

Epoch: 6| Step: 7
Training loss: 0.2869536280632019
Validation loss: 2.1093711455663047

Epoch: 6| Step: 8
Training loss: 0.3176587224006653
Validation loss: 2.1639748215675354

Epoch: 6| Step: 9
Training loss: 0.4245971441268921
Validation loss: 2.1403934160868325

Epoch: 6| Step: 10
Training loss: 0.7919460535049438
Validation loss: 2.1023895939191184

Epoch: 6| Step: 11
Training loss: 0.5785210132598877
Validation loss: 2.1146844029426575

Epoch: 6| Step: 12
Training loss: 0.5063332319259644
Validation loss: 2.130800803502401

Epoch: 6| Step: 13
Training loss: 0.27492451667785645
Validation loss: 2.111100653807322

Epoch: 285| Step: 0
Training loss: 0.4286205768585205
Validation loss: 2.13035386800766

Epoch: 6| Step: 1
Training loss: 0.5341389775276184
Validation loss: 2.16715000073115

Epoch: 6| Step: 2
Training loss: 0.892261803150177
Validation loss: 2.137875278790792

Epoch: 6| Step: 3
Training loss: 0.7096309661865234
Validation loss: 2.1433228055636087

Epoch: 6| Step: 4
Training loss: 0.35821646451950073
Validation loss: 2.2071433464686074

Epoch: 6| Step: 5
Training loss: 0.42847880721092224
Validation loss: 2.1321218808492026

Epoch: 6| Step: 6
Training loss: 0.28999799489974976
Validation loss: 2.1498621304829917

Epoch: 6| Step: 7
Training loss: 0.4778001606464386
Validation loss: 2.1301761269569397

Epoch: 6| Step: 8
Training loss: 0.48328685760498047
Validation loss: 2.1156915028889975

Epoch: 6| Step: 9
Training loss: 0.29962050914764404
Validation loss: 2.160405615965525

Epoch: 6| Step: 10
Training loss: 0.5980409383773804
Validation loss: 2.1672484278678894

Epoch: 6| Step: 11
Training loss: 0.5945892333984375
Validation loss: 2.1074618697166443

Epoch: 6| Step: 12
Training loss: 0.33685004711151123
Validation loss: 2.11070050795873

Epoch: 6| Step: 13
Training loss: 0.8484860062599182
Validation loss: 2.1423274278640747

Epoch: 286| Step: 0
Training loss: 0.32206249237060547
Validation loss: 2.1484938661257424

Epoch: 6| Step: 1
Training loss: 0.5096563100814819
Validation loss: 2.122762938340505

Epoch: 6| Step: 2
Training loss: 0.27089953422546387
Validation loss: 2.196815311908722

Epoch: 6| Step: 3
Training loss: 0.47577235102653503
Validation loss: 2.197475572427114

Epoch: 6| Step: 4
Training loss: 0.8701217174530029
Validation loss: 2.113336980342865

Epoch: 6| Step: 5
Training loss: 0.6070177555084229
Validation loss: 2.1305465698242188

Epoch: 6| Step: 6
Training loss: 0.23071029782295227
Validation loss: 2.0789423982302346

Epoch: 6| Step: 7
Training loss: 0.42633241415023804
Validation loss: 2.1839918891588845

Epoch: 6| Step: 8
Training loss: 0.7534226179122925
Validation loss: 2.138019939263662

Epoch: 6| Step: 9
Training loss: 0.3634219169616699
Validation loss: 2.098060111204783

Epoch: 6| Step: 10
Training loss: 0.39018556475639343
Validation loss: 2.086755355199178

Epoch: 6| Step: 11
Training loss: 0.3092304468154907
Validation loss: 2.105687936147054

Epoch: 6| Step: 12
Training loss: 0.4463461637496948
Validation loss: 2.126676340897878

Epoch: 6| Step: 13
Training loss: 0.6205105185508728
Validation loss: 2.138354023297628

Epoch: 287| Step: 0
Training loss: 0.8542376160621643
Validation loss: 2.121600866317749

Epoch: 6| Step: 1
Training loss: 0.32388609647750854
Validation loss: 2.170243044694265

Epoch: 6| Step: 2
Training loss: 0.37893128395080566
Validation loss: 2.147466321786245

Epoch: 6| Step: 3
Training loss: 0.3737616240978241
Validation loss: 2.0981271465619407

Epoch: 6| Step: 4
Training loss: 1.2021785974502563
Validation loss: 2.131369094053904

Epoch: 6| Step: 5
Training loss: 0.4132441580295563
Validation loss: 2.127009550730387

Epoch: 6| Step: 6
Training loss: 0.6773791313171387
Validation loss: 2.132436295350393

Epoch: 6| Step: 7
Training loss: 0.2607008218765259
Validation loss: 2.133203943570455

Epoch: 6| Step: 8
Training loss: 0.2953541874885559
Validation loss: 2.1332714557647705

Epoch: 6| Step: 9
Training loss: 0.6377677321434021
Validation loss: 2.170326312383016

Epoch: 6| Step: 10
Training loss: 0.28762298822402954
Validation loss: 2.1611589789390564

Epoch: 6| Step: 11
Training loss: 0.7032158374786377
Validation loss: 2.182870864868164

Epoch: 6| Step: 12
Training loss: 0.2061348259449005
Validation loss: 2.109426279862722

Epoch: 6| Step: 13
Training loss: 0.3659511208534241
Validation loss: 2.1522144277890525

Epoch: 288| Step: 0
Training loss: 0.5181862711906433
Validation loss: 2.123838186264038

Epoch: 6| Step: 1
Training loss: 0.3648691773414612
Validation loss: 2.106697698434194

Epoch: 6| Step: 2
Training loss: 0.5855562686920166
Validation loss: 2.122312088807424

Epoch: 6| Step: 3
Training loss: 0.5448199510574341
Validation loss: 2.079696476459503

Epoch: 6| Step: 4
Training loss: 0.554553747177124
Validation loss: 2.14363956451416

Epoch: 6| Step: 5
Training loss: 0.5206665992736816
Validation loss: 2.1128172477086387

Epoch: 6| Step: 6
Training loss: 0.28018489480018616
Validation loss: 2.1421396334966025

Epoch: 6| Step: 7
Training loss: 0.9829747676849365
Validation loss: 2.141635537147522

Epoch: 6| Step: 8
Training loss: 0.4820413589477539
Validation loss: 2.137304107348124

Epoch: 6| Step: 9
Training loss: 0.22423458099365234
Validation loss: 2.157769203186035

Epoch: 6| Step: 10
Training loss: 0.4806820750236511
Validation loss: 2.172658304373423

Epoch: 6| Step: 11
Training loss: 0.5127582550048828
Validation loss: 2.140744209289551

Epoch: 6| Step: 12
Training loss: 0.37171173095703125
Validation loss: 2.11641256014506

Epoch: 6| Step: 13
Training loss: 0.4479573965072632
Validation loss: 2.1442055304845176

Epoch: 289| Step: 0
Training loss: 0.39555448293685913
Validation loss: 2.101466258366903

Epoch: 6| Step: 1
Training loss: 0.4329094886779785
Validation loss: 2.0468472838401794

Epoch: 6| Step: 2
Training loss: 0.30032166838645935
Validation loss: 2.1247915029525757

Epoch: 6| Step: 3
Training loss: 0.6252050995826721
Validation loss: 2.1350518465042114

Epoch: 6| Step: 4
Training loss: 0.4853556156158447
Validation loss: 2.103610416253408

Epoch: 6| Step: 5
Training loss: 0.7334518432617188
Validation loss: 2.1749492088953652

Epoch: 6| Step: 6
Training loss: 0.3386808931827545
Validation loss: 2.1582030057907104

Epoch: 6| Step: 7
Training loss: 0.5686231255531311
Validation loss: 2.1504228909810386

Epoch: 6| Step: 8
Training loss: 0.3719687759876251
Validation loss: 2.1108736991882324

Epoch: 6| Step: 9
Training loss: 0.23760809004306793
Validation loss: 2.1437944968541465

Epoch: 6| Step: 10
Training loss: 0.6815232634544373
Validation loss: 2.0865788062413535

Epoch: 6| Step: 11
Training loss: 0.692638635635376
Validation loss: 2.09478231271108

Epoch: 6| Step: 12
Training loss: 0.7009878158569336
Validation loss: 2.1190810799598694

Epoch: 6| Step: 13
Training loss: 0.3887113928794861
Validation loss: 2.089102109273275

Epoch: 290| Step: 0
Training loss: 0.6681174039840698
Validation loss: 2.085488418738047

Epoch: 6| Step: 1
Training loss: 0.5524539947509766
Validation loss: 2.0977487762769065

Epoch: 6| Step: 2
Training loss: 0.36242178082466125
Validation loss: 2.1290637056032815

Epoch: 6| Step: 3
Training loss: 0.44690823554992676
Validation loss: 2.1407536268234253

Epoch: 6| Step: 4
Training loss: 0.308054655790329
Validation loss: 2.1657646695772805

Epoch: 6| Step: 5
Training loss: 0.8863312005996704
Validation loss: 2.113383094469706

Epoch: 6| Step: 6
Training loss: 0.6306583285331726
Validation loss: 2.1630524396896362

Epoch: 6| Step: 7
Training loss: 0.5597561001777649
Validation loss: 2.1268921494483948

Epoch: 6| Step: 8
Training loss: 0.3945533037185669
Validation loss: 2.142401874065399

Epoch: 6| Step: 9
Training loss: 0.49030807614326477
Validation loss: 2.1351325710614524

Epoch: 6| Step: 10
Training loss: 0.5153557062149048
Validation loss: 2.107962131500244

Epoch: 6| Step: 11
Training loss: 0.5169601440429688
Validation loss: 2.1424131790796914

Epoch: 6| Step: 12
Training loss: 0.33832040429115295
Validation loss: 2.1511309146881104

Epoch: 6| Step: 13
Training loss: 0.331481397151947
Validation loss: 2.088123102982839

Epoch: 291| Step: 0
Training loss: 0.25896358489990234
Validation loss: 2.1356558203697205

Epoch: 6| Step: 1
Training loss: 0.658581018447876
Validation loss: 2.158577084541321

Epoch: 6| Step: 2
Training loss: 0.4838373363018036
Validation loss: 2.1715195178985596

Epoch: 6| Step: 3
Training loss: 0.28776806592941284
Validation loss: 2.160774290561676

Epoch: 6| Step: 4
Training loss: 0.9411970376968384
Validation loss: 2.144418021043142

Epoch: 6| Step: 5
Training loss: 0.52122962474823
Validation loss: 2.12102202574412

Epoch: 6| Step: 6
Training loss: 0.5099727511405945
Validation loss: 2.1045276721318564

Epoch: 6| Step: 7
Training loss: 0.4314582049846649
Validation loss: 2.1193617979685464

Epoch: 6| Step: 8
Training loss: 0.44481539726257324
Validation loss: 2.122186303138733

Epoch: 6| Step: 9
Training loss: 0.620332658290863
Validation loss: 2.081227640310923

Epoch: 6| Step: 10
Training loss: 0.3490695357322693
Validation loss: 2.1361658374468484

Epoch: 6| Step: 11
Training loss: 0.5111498832702637
Validation loss: 2.100820024808248

Epoch: 6| Step: 12
Training loss: 0.994621992111206
Validation loss: 2.141793171564738

Epoch: 6| Step: 13
Training loss: 0.4210101068019867
Validation loss: 2.1294263203938804

Epoch: 292| Step: 0
Training loss: 0.2990262806415558
Validation loss: 2.1129340132077536

Epoch: 6| Step: 1
Training loss: 0.4739686846733093
Validation loss: 2.111130177974701

Epoch: 6| Step: 2
Training loss: 0.28587430715560913
Validation loss: 2.1468045115470886

Epoch: 6| Step: 3
Training loss: 0.5359662771224976
Validation loss: 2.124293863773346

Epoch: 6| Step: 4
Training loss: 1.0224239826202393
Validation loss: 2.148997942606608

Epoch: 6| Step: 5
Training loss: 0.32666903734207153
Validation loss: 2.0597731272379556

Epoch: 6| Step: 6
Training loss: 0.41756752133369446
Validation loss: 2.093237559000651

Epoch: 6| Step: 7
Training loss: 0.5751487016677856
Validation loss: 2.135775645573934

Epoch: 6| Step: 8
Training loss: 0.42696046829223633
Validation loss: 2.0972072879473367

Epoch: 6| Step: 9
Training loss: 0.37995022535324097
Validation loss: 2.166616221268972

Epoch: 6| Step: 10
Training loss: 0.7275418639183044
Validation loss: 2.137355009714762

Epoch: 6| Step: 11
Training loss: 0.5158246755599976
Validation loss: 2.139493227005005

Epoch: 6| Step: 12
Training loss: 0.6111431121826172
Validation loss: 2.129539648691813

Epoch: 6| Step: 13
Training loss: 0.5957797765731812
Validation loss: 2.125336488087972

Epoch: 293| Step: 0
Training loss: 0.244358628988266
Validation loss: 2.146519144376119

Epoch: 6| Step: 1
Training loss: 0.4772079586982727
Validation loss: 2.0982638597488403

Epoch: 6| Step: 2
Training loss: 0.46381545066833496
Validation loss: 2.1271252234776816

Epoch: 6| Step: 3
Training loss: 0.3709508776664734
Validation loss: 2.120195766290029

Epoch: 6| Step: 4
Training loss: 0.3438093662261963
Validation loss: 2.124486207962036

Epoch: 6| Step: 5
Training loss: 0.7021384239196777
Validation loss: 2.1370168725649514

Epoch: 6| Step: 6
Training loss: 0.5315238237380981
Validation loss: 2.1884040236473083

Epoch: 6| Step: 7
Training loss: 0.9332091808319092
Validation loss: 2.1632610162099204

Epoch: 6| Step: 8
Training loss: 0.3831127882003784
Validation loss: 2.186253309249878

Epoch: 6| Step: 9
Training loss: 0.5064225196838379
Validation loss: 2.1297288139661155

Epoch: 6| Step: 10
Training loss: 0.6363109350204468
Validation loss: 2.193185329437256

Epoch: 6| Step: 11
Training loss: 0.5574578046798706
Validation loss: 2.1385848919550576

Epoch: 6| Step: 12
Training loss: 0.5085722208023071
Validation loss: 2.1220820347468057

Epoch: 6| Step: 13
Training loss: 0.5473660826683044
Validation loss: 2.138610601425171

Epoch: 294| Step: 0
Training loss: 0.9485422968864441
Validation loss: 2.1141393184661865

Epoch: 6| Step: 1
Training loss: 0.7032465934753418
Validation loss: 2.082687556743622

Epoch: 6| Step: 2
Training loss: 0.7837483882904053
Validation loss: 2.096173942089081

Epoch: 6| Step: 3
Training loss: 0.303165078163147
Validation loss: 2.128077983856201

Epoch: 6| Step: 4
Training loss: 0.713180422782898
Validation loss: 2.1171981493631997

Epoch: 6| Step: 5
Training loss: 0.684988260269165
Validation loss: 2.091872255007426

Epoch: 6| Step: 6
Training loss: 0.346245139837265
Validation loss: 2.1754586497942605

Epoch: 6| Step: 7
Training loss: 0.43756210803985596
Validation loss: 2.1436489820480347

Epoch: 6| Step: 8
Training loss: 0.775652289390564
Validation loss: 2.1452670892079673

Epoch: 6| Step: 9
Training loss: 0.2662807106971741
Validation loss: 2.107349177201589

Epoch: 6| Step: 10
Training loss: 0.4114111363887787
Validation loss: 2.145950675010681

Epoch: 6| Step: 11
Training loss: 0.40542975068092346
Validation loss: 2.1305453975995383

Epoch: 6| Step: 12
Training loss: 0.36758577823638916
Validation loss: 2.1114120483398438

Epoch: 6| Step: 13
Training loss: 0.23660075664520264
Validation loss: 2.192299783229828

Epoch: 295| Step: 0
Training loss: 0.7104945182800293
Validation loss: 2.141995151837667

Epoch: 6| Step: 1
Training loss: 0.504538893699646
Validation loss: 2.119970997174581

Epoch: 6| Step: 2
Training loss: 0.30651187896728516
Validation loss: 2.1707309683163962

Epoch: 6| Step: 3
Training loss: 0.6625910997390747
Validation loss: 2.1498461167017617

Epoch: 6| Step: 4
Training loss: 0.5538129806518555
Validation loss: 2.154443303743998

Epoch: 6| Step: 5
Training loss: 0.30220919847488403
Validation loss: 2.1467191179593406

Epoch: 6| Step: 6
Training loss: 0.3275664150714874
Validation loss: 2.1356738011042276

Epoch: 6| Step: 7
Training loss: 1.0974977016448975
Validation loss: 2.110953470071157

Epoch: 6| Step: 8
Training loss: 0.4164406657218933
Validation loss: 2.12825075785319

Epoch: 6| Step: 9
Training loss: 0.4143061637878418
Validation loss: 2.1157710750897727

Epoch: 6| Step: 10
Training loss: 0.2746328115463257
Validation loss: 2.11812961101532

Epoch: 6| Step: 11
Training loss: 0.32958537340164185
Validation loss: 2.1289605299631753

Epoch: 6| Step: 12
Training loss: 0.41396719217300415
Validation loss: 2.1408612926801047

Epoch: 6| Step: 13
Training loss: 0.6482759714126587
Validation loss: 2.128138462702433

Epoch: 296| Step: 0
Training loss: 0.5545620322227478
Validation loss: 2.1108383735020957

Epoch: 6| Step: 1
Training loss: 0.6238892078399658
Validation loss: 2.1200249195098877

Epoch: 6| Step: 2
Training loss: 0.3873400092124939
Validation loss: 2.111529290676117

Epoch: 6| Step: 3
Training loss: 0.269396036863327
Validation loss: 2.104362507661184

Epoch: 6| Step: 4
Training loss: 1.1535255908966064
Validation loss: 2.1513553460439048

Epoch: 6| Step: 5
Training loss: 0.8792252540588379
Validation loss: 2.154910902182261

Epoch: 6| Step: 6
Training loss: 0.23326635360717773
Validation loss: 2.123139500617981

Epoch: 6| Step: 7
Training loss: 0.3867630660533905
Validation loss: 2.087858955065409

Epoch: 6| Step: 8
Training loss: 0.32907575368881226
Validation loss: 2.153271953264872

Epoch: 6| Step: 9
Training loss: 0.44618359208106995
Validation loss: 2.1569031476974487

Epoch: 6| Step: 10
Training loss: 0.50900799036026
Validation loss: 2.1394463380177817

Epoch: 6| Step: 11
Training loss: 0.4199843108654022
Validation loss: 2.1237851778666177

Epoch: 6| Step: 12
Training loss: 0.4072270393371582
Validation loss: 2.1528409719467163

Epoch: 6| Step: 13
Training loss: 0.446505069732666
Validation loss: 2.153967042764028

Epoch: 297| Step: 0
Training loss: 0.3379567265510559
Validation loss: 2.154930909474691

Epoch: 6| Step: 1
Training loss: 0.36025768518447876
Validation loss: 2.1004329125086465

Epoch: 6| Step: 2
Training loss: 0.5400307774543762
Validation loss: 2.1581127047538757

Epoch: 6| Step: 3
Training loss: 0.9194334745407104
Validation loss: 2.156003991762797

Epoch: 6| Step: 4
Training loss: 0.9210541844367981
Validation loss: 2.1391730904579163

Epoch: 6| Step: 5
Training loss: 0.3488008379936218
Validation loss: 2.139503618081411

Epoch: 6| Step: 6
Training loss: 0.4029158353805542
Validation loss: 2.1064428885777793

Epoch: 6| Step: 7
Training loss: 0.3836243748664856
Validation loss: 2.133557160695394

Epoch: 6| Step: 8
Training loss: 0.46065303683280945
Validation loss: 2.1566936572392783

Epoch: 6| Step: 9
Training loss: 0.42487332224845886
Validation loss: 2.1514537731806436

Epoch: 6| Step: 10
Training loss: 0.34082919359207153
Validation loss: 2.192946970462799

Epoch: 6| Step: 11
Training loss: 0.7959370613098145
Validation loss: 2.1337489088376365

Epoch: 6| Step: 12
Training loss: 0.37976476550102234
Validation loss: 2.1105881333351135

Epoch: 6| Step: 13
Training loss: 0.1628713309764862
Validation loss: 2.1377526124318442

Epoch: 298| Step: 0
Training loss: 0.31816351413726807
Validation loss: 2.0742018818855286

Epoch: 6| Step: 1
Training loss: 1.0485286712646484
Validation loss: 2.14046440521876

Epoch: 6| Step: 2
Training loss: 0.33250677585601807
Validation loss: 2.174355069796244

Epoch: 6| Step: 3
Training loss: 0.31293171644210815
Validation loss: 2.2062259713808694

Epoch: 6| Step: 4
Training loss: 0.7842348217964172
Validation loss: 2.1550574700037637

Epoch: 6| Step: 5
Training loss: 0.6975421905517578
Validation loss: 2.121853470802307

Epoch: 6| Step: 6
Training loss: 0.18321257829666138
Validation loss: 2.1718350052833557

Epoch: 6| Step: 7
Training loss: 0.4233313798904419
Validation loss: 2.1308710972468057

Epoch: 6| Step: 8
Training loss: 0.24636416137218475
Validation loss: 2.1358158389727273

Epoch: 6| Step: 9
Training loss: 0.5014611482620239
Validation loss: 2.138676722844442

Epoch: 6| Step: 10
Training loss: 0.32718369364738464
Validation loss: 2.164321263631185

Epoch: 6| Step: 11
Training loss: 0.24673062562942505
Validation loss: 2.078182021776835

Epoch: 6| Step: 12
Training loss: 0.8280700445175171
Validation loss: 2.1128881176312766

Epoch: 6| Step: 13
Training loss: 0.39313170313835144
Validation loss: 2.083789110183716

Epoch: 299| Step: 0
Training loss: 0.5040470957756042
Validation loss: 2.096139589945475

Epoch: 6| Step: 1
Training loss: 0.37969741225242615
Validation loss: 2.160408079624176

Epoch: 6| Step: 2
Training loss: 0.603458046913147
Validation loss: 2.0824990272521973

Epoch: 6| Step: 3
Training loss: 0.368438184261322
Validation loss: 2.1465194821357727

Epoch: 6| Step: 4
Training loss: 0.30216625332832336
Validation loss: 2.098039189974467

Epoch: 6| Step: 5
Training loss: 0.7586337327957153
Validation loss: 2.087914764881134

Epoch: 6| Step: 6
Training loss: 0.5520985126495361
Validation loss: 2.1067156195640564

Epoch: 6| Step: 7
Training loss: 0.4575154781341553
Validation loss: 2.1478794614473977

Epoch: 6| Step: 8
Training loss: 0.6481963396072388
Validation loss: 2.1246321400006614

Epoch: 6| Step: 9
Training loss: 0.22055041790008545
Validation loss: 2.090875963370005

Epoch: 6| Step: 10
Training loss: 0.5254023671150208
Validation loss: 2.1346193750699363

Epoch: 6| Step: 11
Training loss: 0.6001559495925903
Validation loss: 2.112936019897461

Epoch: 6| Step: 12
Training loss: 0.3821948766708374
Validation loss: 2.065164784590403

Epoch: 6| Step: 13
Training loss: 0.5580234527587891
Validation loss: 2.113189180692037

Epoch: 300| Step: 0
Training loss: 0.5179356336593628
Validation loss: 2.1279460390408835

Epoch: 6| Step: 1
Training loss: 0.32832562923431396
Validation loss: 2.1150086323420205

Epoch: 6| Step: 2
Training loss: 0.7808656096458435
Validation loss: 2.13832680384318

Epoch: 6| Step: 3
Training loss: 0.30869558453559875
Validation loss: 2.1923436721165976

Epoch: 6| Step: 4
Training loss: 0.6479203701019287
Validation loss: 2.195028007030487

Epoch: 6| Step: 5
Training loss: 0.37257421016693115
Validation loss: 2.0976197123527527

Epoch: 6| Step: 6
Training loss: 0.34625673294067383
Validation loss: 2.1095121105511985

Epoch: 6| Step: 7
Training loss: 0.40844836831092834
Validation loss: 2.133872071901957

Epoch: 6| Step: 8
Training loss: 0.9592921137809753
Validation loss: 2.0862982670466104

Epoch: 6| Step: 9
Training loss: 0.2601828873157501
Validation loss: 2.122762759526571

Epoch: 6| Step: 10
Training loss: 0.7786436080932617
Validation loss: 2.1347177823384604

Epoch: 6| Step: 11
Training loss: 0.4361865818500519
Validation loss: 2.1425093015034995

Epoch: 6| Step: 12
Training loss: 0.29193758964538574
Validation loss: 2.1242833137512207

Epoch: 6| Step: 13
Training loss: 0.5244781970977783
Validation loss: 2.1562668879826865

Testing loss: 2.152417851866578
