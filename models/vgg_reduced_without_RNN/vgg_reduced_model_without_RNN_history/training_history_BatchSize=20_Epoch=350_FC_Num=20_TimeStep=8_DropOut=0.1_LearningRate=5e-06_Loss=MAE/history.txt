Epoch: 1| Step: 0
Training loss: 6.449178218841553
Validation loss: 7.1154691974322

Epoch: 5| Step: 1
Training loss: 7.0643181800842285
Validation loss: 7.104289809862773

Epoch: 5| Step: 2
Training loss: 7.618014335632324
Validation loss: 7.0921869079271955

Epoch: 5| Step: 3
Training loss: 7.0098981857299805
Validation loss: 7.083721458911896

Epoch: 5| Step: 4
Training loss: 8.331602096557617
Validation loss: 7.071547011534373

Epoch: 5| Step: 5
Training loss: 7.033412933349609
Validation loss: 7.0623159011205034

Epoch: 5| Step: 6
Training loss: 7.109433174133301
Validation loss: 7.051466584205627

Epoch: 5| Step: 7
Training loss: 7.732198238372803
Validation loss: 7.0427588025728864

Epoch: 5| Step: 8
Training loss: 7.035003662109375
Validation loss: 7.033141533533732

Epoch: 5| Step: 9
Training loss: 7.072296142578125
Validation loss: 7.020606458187103

Epoch: 5| Step: 10
Training loss: 6.399428844451904
Validation loss: 7.011466840902965

Epoch: 5| Step: 11
Training loss: 5.1286468505859375
Validation loss: 7.000196675459544

Epoch: 2| Step: 0
Training loss: 6.656715393066406
Validation loss: 6.98653628428777

Epoch: 5| Step: 1
Training loss: 8.2469482421875
Validation loss: 6.9760298530260725

Epoch: 5| Step: 2
Training loss: 6.777423858642578
Validation loss: 6.962863107522328

Epoch: 5| Step: 3
Training loss: 6.840981483459473
Validation loss: 6.948093076546987

Epoch: 5| Step: 4
Training loss: 6.621481895446777
Validation loss: 6.935993432998657

Epoch: 5| Step: 5
Training loss: 7.815390586853027
Validation loss: 6.921370645364125

Epoch: 5| Step: 6
Training loss: 6.249834060668945
Validation loss: 6.905285676320394

Epoch: 5| Step: 7
Training loss: 6.4464287757873535
Validation loss: 6.891439259052277

Epoch: 5| Step: 8
Training loss: 7.212071418762207
Validation loss: 6.872949759165446

Epoch: 5| Step: 9
Training loss: 6.166513442993164
Validation loss: 6.859906733036041

Epoch: 5| Step: 10
Training loss: 7.3538947105407715
Validation loss: 6.840587417284648

Epoch: 5| Step: 11
Training loss: 9.408509254455566
Validation loss: 6.820627391338348

Epoch: 3| Step: 0
Training loss: 7.649404048919678
Validation loss: 6.802754441897075

Epoch: 5| Step: 1
Training loss: 7.520941734313965
Validation loss: 6.782378673553467

Epoch: 5| Step: 2
Training loss: 6.942657470703125
Validation loss: 6.763584077358246

Epoch: 5| Step: 3
Training loss: 6.669473171234131
Validation loss: 6.740769247214

Epoch: 5| Step: 4
Training loss: 5.6272687911987305
Validation loss: 6.723827560742696

Epoch: 5| Step: 5
Training loss: 7.142878532409668
Validation loss: 6.698286652565002

Epoch: 5| Step: 6
Training loss: 7.193173408508301
Validation loss: 6.674190282821655

Epoch: 5| Step: 7
Training loss: 5.941368103027344
Validation loss: 6.6498449842135114

Epoch: 5| Step: 8
Training loss: 6.425425052642822
Validation loss: 6.620785216490428

Epoch: 5| Step: 9
Training loss: 6.39147424697876
Validation loss: 6.589357435703278

Epoch: 5| Step: 10
Training loss: 6.441430568695068
Validation loss: 6.559757749239604

Epoch: 5| Step: 11
Training loss: 8.903864860534668
Validation loss: 6.53155384461085

Epoch: 4| Step: 0
Training loss: 6.101498603820801
Validation loss: 6.500324249267578

Epoch: 5| Step: 1
Training loss: 5.519902229309082
Validation loss: 6.461290061473846

Epoch: 5| Step: 2
Training loss: 7.098379611968994
Validation loss: 6.43160233894984

Epoch: 5| Step: 3
Training loss: 6.986773490905762
Validation loss: 6.393867452939351

Epoch: 5| Step: 4
Training loss: 6.279349327087402
Validation loss: 6.357031424840291

Epoch: 5| Step: 5
Training loss: 6.434648036956787
Validation loss: 6.314033925533295

Epoch: 5| Step: 6
Training loss: 6.933730125427246
Validation loss: 6.270720660686493

Epoch: 5| Step: 7
Training loss: 5.9798736572265625
Validation loss: 6.226726373036702

Epoch: 5| Step: 8
Training loss: 7.027708530426025
Validation loss: 6.174368580182393

Epoch: 5| Step: 9
Training loss: 6.635427951812744
Validation loss: 6.133464912573497

Epoch: 5| Step: 10
Training loss: 6.0026750564575195
Validation loss: 6.073428769906362

Epoch: 5| Step: 11
Training loss: 2.0973129272460938
Validation loss: 6.022488971551259

Epoch: 5| Step: 0
Training loss: 6.4104437828063965
Validation loss: 5.964327375094096

Epoch: 5| Step: 1
Training loss: 4.833693027496338
Validation loss: 5.903617521127065

Epoch: 5| Step: 2
Training loss: 6.722237586975098
Validation loss: 5.841770927111308

Epoch: 5| Step: 3
Training loss: 5.29331111907959
Validation loss: 5.7844626903533936

Epoch: 5| Step: 4
Training loss: 5.280356407165527
Validation loss: 5.702855010827382

Epoch: 5| Step: 5
Training loss: 5.795881271362305
Validation loss: 5.634351849555969

Epoch: 5| Step: 6
Training loss: 5.3855438232421875
Validation loss: 5.564711729685466

Epoch: 5| Step: 7
Training loss: 5.33888578414917
Validation loss: 5.480224410692851

Epoch: 5| Step: 8
Training loss: 6.367410182952881
Validation loss: 5.399633765220642

Epoch: 5| Step: 9
Training loss: 5.403927326202393
Validation loss: 5.306479871273041

Epoch: 5| Step: 10
Training loss: 5.942509174346924
Validation loss: 5.219446231921514

Epoch: 5| Step: 11
Training loss: 4.89520788192749
Validation loss: 5.118498504161835

Epoch: 6| Step: 0
Training loss: 4.370196342468262
Validation loss: 5.025604248046875

Epoch: 5| Step: 1
Training loss: 5.697901725769043
Validation loss: 4.92772102355957

Epoch: 5| Step: 2
Training loss: 5.170557498931885
Validation loss: 4.805314560731252

Epoch: 5| Step: 3
Training loss: 4.898045063018799
Validation loss: 4.706819295883179

Epoch: 5| Step: 4
Training loss: 5.076937198638916
Validation loss: 4.601426223913829

Epoch: 5| Step: 5
Training loss: 4.602334022521973
Validation loss: 4.466770430405934

Epoch: 5| Step: 6
Training loss: 3.756450653076172
Validation loss: 4.325385967890422

Epoch: 5| Step: 7
Training loss: 3.7822105884552
Validation loss: 4.232937385638555

Epoch: 5| Step: 8
Training loss: 4.304515361785889
Validation loss: 4.0634479423364

Epoch: 5| Step: 9
Training loss: 4.037113189697266
Validation loss: 3.950262208779653

Epoch: 5| Step: 10
Training loss: 4.09493350982666
Validation loss: 3.799890329440435

Epoch: 5| Step: 11
Training loss: 3.602691650390625
Validation loss: 3.6646811266740165

Epoch: 7| Step: 0
Training loss: 2.859030246734619
Validation loss: 3.5081639885902405

Epoch: 5| Step: 1
Training loss: 3.832766056060791
Validation loss: 3.37110702196757

Epoch: 5| Step: 2
Training loss: 3.5436477661132812
Validation loss: 3.2339219550291696

Epoch: 5| Step: 3
Training loss: 3.4522407054901123
Validation loss: 3.12150502204895

Epoch: 5| Step: 4
Training loss: 2.2664780616760254
Validation loss: 2.9485303461551666

Epoch: 5| Step: 5
Training loss: 2.657770872116089
Validation loss: 2.8333423137664795

Epoch: 5| Step: 6
Training loss: 2.9197604656219482
Validation loss: 2.678514003753662

Epoch: 5| Step: 7
Training loss: 2.304780960083008
Validation loss: 2.5835073788960776

Epoch: 5| Step: 8
Training loss: 2.757024049758911
Validation loss: 2.4921598533789315

Epoch: 5| Step: 9
Training loss: 2.2725791931152344
Validation loss: 2.3516380886236825

Epoch: 5| Step: 10
Training loss: 2.2269787788391113
Validation loss: 2.270825276772181

Epoch: 5| Step: 11
Training loss: 1.5518770217895508
Validation loss: 2.243959387143453

Epoch: 8| Step: 0
Training loss: 2.2917239665985107
Validation loss: 2.205238416790962

Epoch: 5| Step: 1
Training loss: 2.339282751083374
Validation loss: 2.2353343764940896

Epoch: 5| Step: 2
Training loss: 1.7594480514526367
Validation loss: 2.231502259771029

Epoch: 5| Step: 3
Training loss: 2.332458734512329
Validation loss: 2.270957479874293

Epoch: 5| Step: 4
Training loss: 1.8334169387817383
Validation loss: 2.3390530943870544

Epoch: 5| Step: 5
Training loss: 2.0988821983337402
Validation loss: 2.4543754706780114

Epoch: 5| Step: 6
Training loss: 2.8402016162872314
Validation loss: 2.406245251496633

Epoch: 5| Step: 7
Training loss: 3.4365341663360596
Validation loss: 2.514098952213923

Epoch: 5| Step: 8
Training loss: 2.7397944927215576
Validation loss: 2.439773971835772

Epoch: 5| Step: 9
Training loss: 2.4337995052337646
Validation loss: 2.3809418181578317

Epoch: 5| Step: 10
Training loss: 1.503828525543213
Validation loss: 2.2744288245836892

Epoch: 5| Step: 11
Training loss: 2.184873580932617
Validation loss: 2.27478389441967

Epoch: 9| Step: 0
Training loss: 2.5700135231018066
Validation loss: 2.281022330125173

Epoch: 5| Step: 1
Training loss: 2.241694927215576
Validation loss: 2.2270448307196298

Epoch: 5| Step: 2
Training loss: 2.223865032196045
Validation loss: 2.196369548638662

Epoch: 5| Step: 3
Training loss: 2.1487581729888916
Validation loss: 2.2061509639024734

Epoch: 5| Step: 4
Training loss: 1.52910578250885
Validation loss: 2.190482219060262

Epoch: 5| Step: 5
Training loss: 2.4060306549072266
Validation loss: 2.0813167293866477

Epoch: 5| Step: 6
Training loss: 2.3228938579559326
Validation loss: 2.177139033873876

Epoch: 5| Step: 7
Training loss: 1.671036958694458
Validation loss: 2.1725389858086905

Epoch: 5| Step: 8
Training loss: 2.6071951389312744
Validation loss: 2.185957297682762

Epoch: 5| Step: 9
Training loss: 2.217395782470703
Validation loss: 2.17188007136186

Epoch: 5| Step: 10
Training loss: 1.7956287860870361
Validation loss: 2.22040918469429

Epoch: 5| Step: 11
Training loss: 1.8528510332107544
Validation loss: 2.2096062302589417

Epoch: 10| Step: 0
Training loss: 2.4881062507629395
Validation loss: 2.1780625929435096

Epoch: 5| Step: 1
Training loss: 2.271488666534424
Validation loss: 2.261762981613477

Epoch: 5| Step: 2
Training loss: 2.2234063148498535
Validation loss: 2.1813752899567285

Epoch: 5| Step: 3
Training loss: 2.1448910236358643
Validation loss: 2.1736818850040436

Epoch: 5| Step: 4
Training loss: 1.333308458328247
Validation loss: 2.1358187049627304

Epoch: 5| Step: 5
Training loss: 1.9027618169784546
Validation loss: 2.1475516806046167

Epoch: 5| Step: 6
Training loss: 2.2053585052490234
Validation loss: 2.1700639526049295

Epoch: 5| Step: 7
Training loss: 1.6786034107208252
Validation loss: 2.193436066309611

Epoch: 5| Step: 8
Training loss: 2.5369625091552734
Validation loss: 2.209978053967158

Epoch: 5| Step: 9
Training loss: 2.0626797676086426
Validation loss: 2.164120684067408

Epoch: 5| Step: 10
Training loss: 2.2507011890411377
Validation loss: 2.1856095840533576

Epoch: 5| Step: 11
Training loss: 2.596723794937134
Validation loss: 2.2132055213054023

Epoch: 11| Step: 0
Training loss: 2.315185308456421
Validation loss: 2.201448937257131

Epoch: 5| Step: 1
Training loss: 1.66265869140625
Validation loss: 2.1394024143616357

Epoch: 5| Step: 2
Training loss: 1.802893042564392
Validation loss: 2.176175465186437

Epoch: 5| Step: 3
Training loss: 2.087782382965088
Validation loss: 2.167231818040212

Epoch: 5| Step: 4
Training loss: 1.606392502784729
Validation loss: 2.1305799881617227

Epoch: 5| Step: 5
Training loss: 2.4364538192749023
Validation loss: 2.1735804776350656

Epoch: 5| Step: 6
Training loss: 2.4233384132385254
Validation loss: 2.1748808224995932

Epoch: 5| Step: 7
Training loss: 1.9192225933074951
Validation loss: 2.2051154524087906

Epoch: 5| Step: 8
Training loss: 2.518519878387451
Validation loss: 2.207113186518351

Epoch: 5| Step: 9
Training loss: 2.0855050086975098
Validation loss: 2.166283994913101

Epoch: 5| Step: 10
Training loss: 2.108219861984253
Validation loss: 2.204405054450035

Epoch: 5| Step: 11
Training loss: 4.2286376953125
Validation loss: 2.219385345776876

Epoch: 12| Step: 0
Training loss: 2.157078742980957
Validation loss: 2.1444468200206757

Epoch: 5| Step: 1
Training loss: 1.709917426109314
Validation loss: 2.1976554840803146

Epoch: 5| Step: 2
Training loss: 2.359126091003418
Validation loss: 2.168161009748777

Epoch: 5| Step: 3
Training loss: 1.6705892086029053
Validation loss: 2.166031370560328

Epoch: 5| Step: 4
Training loss: 1.9114068746566772
Validation loss: 2.1533770312865577

Epoch: 5| Step: 5
Training loss: 2.0259788036346436
Validation loss: 2.1766186952590942

Epoch: 5| Step: 6
Training loss: 2.146716594696045
Validation loss: 2.171683063109716

Epoch: 5| Step: 7
Training loss: 2.953153610229492
Validation loss: 2.1609904915094376

Epoch: 5| Step: 8
Training loss: 2.3489222526550293
Validation loss: 2.136244058609009

Epoch: 5| Step: 9
Training loss: 1.7279739379882812
Validation loss: 2.1442717611789703

Epoch: 5| Step: 10
Training loss: 2.059931993484497
Validation loss: 2.148542453845342

Epoch: 5| Step: 11
Training loss: 2.1586759090423584
Validation loss: 2.182967116435369

Epoch: 13| Step: 0
Training loss: 1.8632643222808838
Validation loss: 2.161614795525869

Epoch: 5| Step: 1
Training loss: 2.251652240753174
Validation loss: 2.1544219901164374

Epoch: 5| Step: 2
Training loss: 1.8443704843521118
Validation loss: 2.153029372294744

Epoch: 5| Step: 3
Training loss: 2.2830746173858643
Validation loss: 2.1789293736219406

Epoch: 5| Step: 4
Training loss: 1.3723130226135254
Validation loss: 2.1866130034128823

Epoch: 5| Step: 5
Training loss: 2.479750156402588
Validation loss: 2.160567820072174

Epoch: 5| Step: 6
Training loss: 2.036463975906372
Validation loss: 2.153179864088694

Epoch: 5| Step: 7
Training loss: 2.3210031986236572
Validation loss: 2.148274372021357

Epoch: 5| Step: 8
Training loss: 2.397022247314453
Validation loss: 2.1479310989379883

Epoch: 5| Step: 9
Training loss: 2.225625514984131
Validation loss: 2.1328268895546594

Epoch: 5| Step: 10
Training loss: 1.9677950143814087
Validation loss: 2.1696204245090485

Epoch: 5| Step: 11
Training loss: 1.4413665533065796
Validation loss: 2.1470830688873925

Epoch: 14| Step: 0
Training loss: 1.9924094676971436
Validation loss: 2.182736858725548

Epoch: 5| Step: 1
Training loss: 2.119493007659912
Validation loss: 2.186575790246328

Epoch: 5| Step: 2
Training loss: 2.0889134407043457
Validation loss: 2.1501785020033517

Epoch: 5| Step: 3
Training loss: 1.8113012313842773
Validation loss: 2.1278299689292908

Epoch: 5| Step: 4
Training loss: 2.4485466480255127
Validation loss: 2.2079266160726547

Epoch: 5| Step: 5
Training loss: 2.0505921840667725
Validation loss: 2.14124396443367

Epoch: 5| Step: 6
Training loss: 1.9971309900283813
Validation loss: 2.1660329500834146

Epoch: 5| Step: 7
Training loss: 2.0336358547210693
Validation loss: 2.1547479132811227

Epoch: 5| Step: 8
Training loss: 1.6054767370224
Validation loss: 2.1435970862706504

Epoch: 5| Step: 9
Training loss: 2.4600720405578613
Validation loss: 2.108698219060898

Epoch: 5| Step: 10
Training loss: 2.0729610919952393
Validation loss: 2.106292818983396

Epoch: 5| Step: 11
Training loss: 1.8505818843841553
Validation loss: 2.130216583609581

Epoch: 15| Step: 0
Training loss: 2.6146538257598877
Validation loss: 2.1210760126511254

Epoch: 5| Step: 1
Training loss: 2.6235992908477783
Validation loss: 2.2261301477750144

Epoch: 5| Step: 2
Training loss: 1.6520116329193115
Validation loss: 2.1950891315937042

Epoch: 5| Step: 3
Training loss: 2.565028429031372
Validation loss: 2.1602522234121957

Epoch: 5| Step: 4
Training loss: 1.8433986902236938
Validation loss: 2.145490671197573

Epoch: 5| Step: 5
Training loss: 1.5308887958526611
Validation loss: 2.1906348963578544

Epoch: 5| Step: 6
Training loss: 1.8399360179901123
Validation loss: 2.1931914190451303

Epoch: 5| Step: 7
Training loss: 2.2607274055480957
Validation loss: 2.2083344161510468

Epoch: 5| Step: 8
Training loss: 1.9773105382919312
Validation loss: 2.1850746423006058

Epoch: 5| Step: 9
Training loss: 1.877306342124939
Validation loss: 2.1449409623940787

Epoch: 5| Step: 10
Training loss: 2.130194664001465
Validation loss: 2.1988848050435386

Epoch: 5| Step: 11
Training loss: 2.7520065307617188
Validation loss: 2.0985379219055176

Epoch: 16| Step: 0
Training loss: 1.845855951309204
Validation loss: 2.1530957420667014

Epoch: 5| Step: 1
Training loss: 2.2011122703552246
Validation loss: 2.1580746422211328

Epoch: 5| Step: 2
Training loss: 2.496088981628418
Validation loss: 2.154194508989652

Epoch: 5| Step: 3
Training loss: 1.6877918243408203
Validation loss: 2.2080198178688684

Epoch: 5| Step: 4
Training loss: 2.4158530235290527
Validation loss: 2.1351806074380875

Epoch: 5| Step: 5
Training loss: 1.8465843200683594
Validation loss: 2.1532015254100165

Epoch: 5| Step: 6
Training loss: 1.8442682027816772
Validation loss: 2.089304173986117

Epoch: 5| Step: 7
Training loss: 1.8400506973266602
Validation loss: 2.1642546902100244

Epoch: 5| Step: 8
Training loss: 2.4743969440460205
Validation loss: 2.1683132648468018

Epoch: 5| Step: 9
Training loss: 2.037886619567871
Validation loss: 2.1995848963658013

Epoch: 5| Step: 10
Training loss: 1.8393723964691162
Validation loss: 2.183942750096321

Epoch: 5| Step: 11
Training loss: 1.7616147994995117
Validation loss: 2.1091253807147345

Epoch: 17| Step: 0
Training loss: 1.5500566959381104
Validation loss: 2.172069162130356

Epoch: 5| Step: 1
Training loss: 2.557703733444214
Validation loss: 2.141423672437668

Epoch: 5| Step: 2
Training loss: 1.6647125482559204
Validation loss: 2.1422666162252426

Epoch: 5| Step: 3
Training loss: 2.5776963233947754
Validation loss: 2.12750543653965

Epoch: 5| Step: 4
Training loss: 1.934830665588379
Validation loss: 2.128461162249247

Epoch: 5| Step: 5
Training loss: 2.5159385204315186
Validation loss: 2.1558088610569635

Epoch: 5| Step: 6
Training loss: 1.9203084707260132
Validation loss: 2.122603173057238

Epoch: 5| Step: 7
Training loss: 1.5049138069152832
Validation loss: 2.1194093326727548

Epoch: 5| Step: 8
Training loss: 2.6700527667999268
Validation loss: 2.2089176028966904

Epoch: 5| Step: 9
Training loss: 1.850395917892456
Validation loss: 2.088204895456632

Epoch: 5| Step: 10
Training loss: 1.7882057428359985
Validation loss: 2.145459602276484

Epoch: 5| Step: 11
Training loss: 1.179181694984436
Validation loss: 2.06692769130071

Epoch: 18| Step: 0
Training loss: 2.4056715965270996
Validation loss: 2.1697298288345337

Epoch: 5| Step: 1
Training loss: 2.004793167114258
Validation loss: 2.137479921181997

Epoch: 5| Step: 2
Training loss: 1.4992549419403076
Validation loss: 2.1131191651026406

Epoch: 5| Step: 3
Training loss: 2.494243860244751
Validation loss: 2.2026109248399734

Epoch: 5| Step: 4
Training loss: 1.6999809741973877
Validation loss: 2.1924657821655273

Epoch: 5| Step: 5
Training loss: 2.339354991912842
Validation loss: 2.195964048306147

Epoch: 5| Step: 6
Training loss: 1.742770791053772
Validation loss: 2.2051552087068558

Epoch: 5| Step: 7
Training loss: 2.398693561553955
Validation loss: 2.15579883257548

Epoch: 5| Step: 8
Training loss: 1.9836513996124268
Validation loss: 2.1240968306859336

Epoch: 5| Step: 9
Training loss: 2.3031303882598877
Validation loss: 2.1767246574163437

Epoch: 5| Step: 10
Training loss: 1.9212799072265625
Validation loss: 2.097855086127917

Epoch: 5| Step: 11
Training loss: 2.752845525741577
Validation loss: 2.1818000773588815

Epoch: 19| Step: 0
Training loss: 1.7292282581329346
Validation loss: 2.1796301901340485

Epoch: 5| Step: 1
Training loss: 1.749646782875061
Validation loss: 2.1263038317362466

Epoch: 5| Step: 2
Training loss: 2.6739423274993896
Validation loss: 2.1152272323767343

Epoch: 5| Step: 3
Training loss: 1.9197170734405518
Validation loss: 2.0652765035629272

Epoch: 5| Step: 4
Training loss: 2.1382081508636475
Validation loss: 2.079516644279162

Epoch: 5| Step: 5
Training loss: 2.088883876800537
Validation loss: 2.1177500983079276

Epoch: 5| Step: 6
Training loss: 2.0290141105651855
Validation loss: 2.170345281561216

Epoch: 5| Step: 7
Training loss: 1.718910813331604
Validation loss: 2.1981872419516244

Epoch: 5| Step: 8
Training loss: 1.9873234033584595
Validation loss: 2.1426181147495904

Epoch: 5| Step: 9
Training loss: 1.9448283910751343
Validation loss: 2.113578940431277

Epoch: 5| Step: 10
Training loss: 2.317448854446411
Validation loss: 2.15239808956782

Epoch: 5| Step: 11
Training loss: 2.3247909545898438
Validation loss: 2.157345543305079

Epoch: 20| Step: 0
Training loss: 2.574583053588867
Validation loss: 2.187552829583486

Epoch: 5| Step: 1
Training loss: 1.8791433572769165
Validation loss: 2.160556743542353

Epoch: 5| Step: 2
Training loss: 2.3809571266174316
Validation loss: 2.1478021989266076

Epoch: 5| Step: 3
Training loss: 2.069932460784912
Validation loss: 2.1463108907143273

Epoch: 5| Step: 4
Training loss: 1.655432939529419
Validation loss: 2.1114270836114883

Epoch: 5| Step: 5
Training loss: 2.470484972000122
Validation loss: 2.1930211981137595

Epoch: 5| Step: 6
Training loss: 2.1141321659088135
Validation loss: 2.16222774485747

Epoch: 5| Step: 7
Training loss: 2.0243828296661377
Validation loss: 2.179584095875422

Epoch: 5| Step: 8
Training loss: 2.050222158432007
Validation loss: 2.1967949867248535

Epoch: 5| Step: 9
Training loss: 1.7735528945922852
Validation loss: 2.180091912547747

Epoch: 5| Step: 10
Training loss: 1.8172550201416016
Validation loss: 2.1974519342184067

Epoch: 5| Step: 11
Training loss: 3.2293081283569336
Validation loss: 2.125242824355761

Epoch: 21| Step: 0
Training loss: 2.0768883228302
Validation loss: 2.180835689107577

Epoch: 5| Step: 1
Training loss: 2.357520580291748
Validation loss: 2.125496278206507

Epoch: 5| Step: 2
Training loss: 1.9850928783416748
Validation loss: 2.1095846394697824

Epoch: 5| Step: 3
Training loss: 2.364182710647583
Validation loss: 2.087677856286367

Epoch: 5| Step: 4
Training loss: 1.6882768869400024
Validation loss: 2.20987298587958

Epoch: 5| Step: 5
Training loss: 1.8765535354614258
Validation loss: 2.1184908598661423

Epoch: 5| Step: 6
Training loss: 2.561081886291504
Validation loss: 2.0719286104043326

Epoch: 5| Step: 7
Training loss: 1.7495832443237305
Validation loss: 2.1251579572757087

Epoch: 5| Step: 8
Training loss: 1.8231080770492554
Validation loss: 2.05936765174071

Epoch: 5| Step: 9
Training loss: 1.908089280128479
Validation loss: 2.1260316322247186

Epoch: 5| Step: 10
Training loss: 2.1981136798858643
Validation loss: 2.1703946391741433

Epoch: 5| Step: 11
Training loss: 1.1151665449142456
Validation loss: 2.143748710552851

Epoch: 22| Step: 0
Training loss: 1.8430235385894775
Validation loss: 2.1374306033054986

Epoch: 5| Step: 1
Training loss: 1.3254187107086182
Validation loss: 2.1071836352348328

Epoch: 5| Step: 2
Training loss: 2.129246473312378
Validation loss: 2.1039977272351584

Epoch: 5| Step: 3
Training loss: 2.3196520805358887
Validation loss: 2.100942408045133

Epoch: 5| Step: 4
Training loss: 1.8533744812011719
Validation loss: 2.0944087455670037

Epoch: 5| Step: 5
Training loss: 2.249979257583618
Validation loss: 2.1403979063034058

Epoch: 5| Step: 6
Training loss: 2.5393218994140625
Validation loss: 2.112484355767568

Epoch: 5| Step: 7
Training loss: 2.159540891647339
Validation loss: 2.1130568782488504

Epoch: 5| Step: 8
Training loss: 2.470534086227417
Validation loss: 2.0433838168780007

Epoch: 5| Step: 9
Training loss: 2.013822317123413
Validation loss: 2.1403551250696182

Epoch: 5| Step: 10
Training loss: 2.1179375648498535
Validation loss: 2.088870048522949

Epoch: 5| Step: 11
Training loss: 1.69492506980896
Validation loss: 2.1319180776675544

Epoch: 23| Step: 0
Training loss: 2.6857855319976807
Validation loss: 2.1514538377523422

Epoch: 5| Step: 1
Training loss: 1.6110811233520508
Validation loss: 2.1863038589557013

Epoch: 5| Step: 2
Training loss: 2.63263201713562
Validation loss: 2.1022024055322013

Epoch: 5| Step: 3
Training loss: 2.007248878479004
Validation loss: 2.130198488632838

Epoch: 5| Step: 4
Training loss: 1.8235588073730469
Validation loss: 2.1276591221491494

Epoch: 5| Step: 5
Training loss: 1.7706584930419922
Validation loss: 2.148696725567182

Epoch: 5| Step: 6
Training loss: 1.7259191274642944
Validation loss: 2.1269251505533853

Epoch: 5| Step: 7
Training loss: 1.9621479511260986
Validation loss: 2.157404417792956

Epoch: 5| Step: 8
Training loss: 1.8562285900115967
Validation loss: 2.1734668215115867

Epoch: 5| Step: 9
Training loss: 1.8138446807861328
Validation loss: 2.079570318261782

Epoch: 5| Step: 10
Training loss: 2.5986168384552
Validation loss: 2.142782911658287

Epoch: 5| Step: 11
Training loss: 1.0965253114700317
Validation loss: 2.119389792283376

Epoch: 24| Step: 0
Training loss: 2.180915355682373
Validation loss: 2.1299336006244025

Epoch: 5| Step: 1
Training loss: 2.237520694732666
Validation loss: 2.167386765281359

Epoch: 5| Step: 2
Training loss: 1.7799142599105835
Validation loss: 2.114020437002182

Epoch: 5| Step: 3
Training loss: 1.848035216331482
Validation loss: 2.1298017551501593

Epoch: 5| Step: 4
Training loss: 1.9792953729629517
Validation loss: 2.1564116179943085

Epoch: 5| Step: 5
Training loss: 2.3025288581848145
Validation loss: 2.0714943607648215

Epoch: 5| Step: 6
Training loss: 2.1532928943634033
Validation loss: 2.1009879112243652

Epoch: 5| Step: 7
Training loss: 2.062135934829712
Validation loss: 2.140336811542511

Epoch: 5| Step: 8
Training loss: 1.9939210414886475
Validation loss: 2.13332732518514

Epoch: 5| Step: 9
Training loss: 2.3611602783203125
Validation loss: 2.1397065420945487

Epoch: 5| Step: 10
Training loss: 1.905576467514038
Validation loss: 2.1010404974222183

Epoch: 5| Step: 11
Training loss: 0.34596890211105347
Validation loss: 2.134106010198593

Epoch: 25| Step: 0
Training loss: 1.8711789846420288
Validation loss: 2.163874313235283

Epoch: 5| Step: 1
Training loss: 2.482800245285034
Validation loss: 2.1220593303442

Epoch: 5| Step: 2
Training loss: 1.518420934677124
Validation loss: 2.0563460687796273

Epoch: 5| Step: 3
Training loss: 2.248579502105713
Validation loss: 2.0626400460799537

Epoch: 5| Step: 4
Training loss: 1.9819921255111694
Validation loss: 2.149312749505043

Epoch: 5| Step: 5
Training loss: 2.1358165740966797
Validation loss: 2.171528935432434

Epoch: 5| Step: 6
Training loss: 2.035753011703491
Validation loss: 2.0760114639997482

Epoch: 5| Step: 7
Training loss: 2.3148465156555176
Validation loss: 2.1405034363269806

Epoch: 5| Step: 8
Training loss: 2.1741857528686523
Validation loss: 2.0866968433062234

Epoch: 5| Step: 9
Training loss: 2.2626423835754395
Validation loss: 2.160376946131388

Epoch: 5| Step: 10
Training loss: 1.513161063194275
Validation loss: 2.1069425841172538

Epoch: 5| Step: 11
Training loss: 3.168919801712036
Validation loss: 2.1385388672351837

Epoch: 26| Step: 0
Training loss: 1.4425972700119019
Validation loss: 2.1475450893243155

Epoch: 5| Step: 1
Training loss: 2.0820281505584717
Validation loss: 2.1048240611950555

Epoch: 5| Step: 2
Training loss: 2.1199772357940674
Validation loss: 2.1314925104379654

Epoch: 5| Step: 3
Training loss: 1.6645317077636719
Validation loss: 2.1630887488524118

Epoch: 5| Step: 4
Training loss: 1.98273503780365
Validation loss: 2.1261935929457345

Epoch: 5| Step: 5
Training loss: 2.1767590045928955
Validation loss: 2.054248794913292

Epoch: 5| Step: 6
Training loss: 2.2231829166412354
Validation loss: 2.1540722250938416

Epoch: 5| Step: 7
Training loss: 2.4430437088012695
Validation loss: 2.1617532471815744

Epoch: 5| Step: 8
Training loss: 1.6783758401870728
Validation loss: 2.1878990083932877

Epoch: 5| Step: 9
Training loss: 2.500958204269409
Validation loss: 2.135833352804184

Epoch: 5| Step: 10
Training loss: 2.646833896636963
Validation loss: 2.0707548509041467

Epoch: 5| Step: 11
Training loss: 2.1360182762145996
Validation loss: 2.1733079502979913

Epoch: 27| Step: 0
Training loss: 2.1782360076904297
Validation loss: 2.117407495776812

Epoch: 5| Step: 1
Training loss: 2.6029043197631836
Validation loss: 2.116886859138807

Epoch: 5| Step: 2
Training loss: 2.0484299659729004
Validation loss: 2.161663055419922

Epoch: 5| Step: 3
Training loss: 1.9269630908966064
Validation loss: 2.1123280823230743

Epoch: 5| Step: 4
Training loss: 2.4342496395111084
Validation loss: 2.119054446617762

Epoch: 5| Step: 5
Training loss: 2.140389919281006
Validation loss: 2.068486308058103

Epoch: 5| Step: 6
Training loss: 1.8802448511123657
Validation loss: 2.1004637827475867

Epoch: 5| Step: 7
Training loss: 1.425083041191101
Validation loss: 2.1049276938041053

Epoch: 5| Step: 8
Training loss: 1.9323453903198242
Validation loss: 2.1175197760264077

Epoch: 5| Step: 9
Training loss: 2.1376700401306152
Validation loss: 2.0306459019581475

Epoch: 5| Step: 10
Training loss: 1.6700928211212158
Validation loss: 2.1724194486935935

Epoch: 5| Step: 11
Training loss: 2.3034768104553223
Validation loss: 2.0998714913924537

Epoch: 28| Step: 0
Training loss: 2.486999750137329
Validation loss: 2.147354304790497

Epoch: 5| Step: 1
Training loss: 2.2848782539367676
Validation loss: 2.05634435514609

Epoch: 5| Step: 2
Training loss: 2.2085890769958496
Validation loss: 2.0790676921606064

Epoch: 5| Step: 3
Training loss: 1.9088901281356812
Validation loss: 2.0959446132183075

Epoch: 5| Step: 4
Training loss: 1.5062525272369385
Validation loss: 2.1500722716252008

Epoch: 5| Step: 5
Training loss: 1.8685258626937866
Validation loss: 2.1064581274986267

Epoch: 5| Step: 6
Training loss: 1.661920189857483
Validation loss: 2.10137348373731

Epoch: 5| Step: 7
Training loss: 2.0799641609191895
Validation loss: 2.1045963962872825

Epoch: 5| Step: 8
Training loss: 2.2500674724578857
Validation loss: 2.1003872454166412

Epoch: 5| Step: 9
Training loss: 2.2116198539733887
Validation loss: 2.0875664254029593

Epoch: 5| Step: 10
Training loss: 1.9479576349258423
Validation loss: 2.138655180732409

Epoch: 5| Step: 11
Training loss: 1.5420546531677246
Validation loss: 2.2097234427928925

Epoch: 29| Step: 0
Training loss: 2.4750804901123047
Validation loss: 2.1415012925863266

Epoch: 5| Step: 1
Training loss: 1.9777085781097412
Validation loss: 2.1843243489662805

Epoch: 5| Step: 2
Training loss: 1.8783375024795532
Validation loss: 2.156249170502027

Epoch: 5| Step: 3
Training loss: 1.783936858177185
Validation loss: 2.165789117415746

Epoch: 5| Step: 4
Training loss: 2.181128740310669
Validation loss: 2.236047476530075

Epoch: 5| Step: 5
Training loss: 2.0981998443603516
Validation loss: 2.1563015480836234

Epoch: 5| Step: 6
Training loss: 1.8520866632461548
Validation loss: 2.2246263325214386

Epoch: 5| Step: 7
Training loss: 1.8624894618988037
Validation loss: 2.1464866002400718

Epoch: 5| Step: 8
Training loss: 2.0695033073425293
Validation loss: 2.141858716805776

Epoch: 5| Step: 9
Training loss: 2.1803367137908936
Validation loss: 2.150612915555636

Epoch: 5| Step: 10
Training loss: 2.5284721851348877
Validation loss: 2.1837736616532006

Epoch: 5| Step: 11
Training loss: 1.5150187015533447
Validation loss: 2.114884460965792

Epoch: 30| Step: 0
Training loss: 1.7795324325561523
Validation loss: 2.0736156751712165

Epoch: 5| Step: 1
Training loss: 2.534472703933716
Validation loss: 2.1251566112041473

Epoch: 5| Step: 2
Training loss: 1.8033180236816406
Validation loss: 2.0951236287752786

Epoch: 5| Step: 3
Training loss: 2.029292345046997
Validation loss: 2.17311721543471

Epoch: 5| Step: 4
Training loss: 2.0027973651885986
Validation loss: 2.1471859216690063

Epoch: 5| Step: 5
Training loss: 2.424525737762451
Validation loss: 2.1777495245138803

Epoch: 5| Step: 6
Training loss: 2.1711807250976562
Validation loss: 2.1766186555226645

Epoch: 5| Step: 7
Training loss: 1.946368932723999
Validation loss: 2.1790944735209146

Epoch: 5| Step: 8
Training loss: 2.0966591835021973
Validation loss: 2.220329831043879

Epoch: 5| Step: 9
Training loss: 2.261404514312744
Validation loss: 2.1602187057336173

Epoch: 5| Step: 10
Training loss: 1.943703293800354
Validation loss: 2.1541588256756463

Epoch: 5| Step: 11
Training loss: 1.7143843173980713
Validation loss: 2.1686116258303323

Epoch: 31| Step: 0
Training loss: 1.855800986289978
Validation loss: 2.1199022382497787

Epoch: 5| Step: 1
Training loss: 2.3132948875427246
Validation loss: 2.1069187223911285

Epoch: 5| Step: 2
Training loss: 1.5084092617034912
Validation loss: 2.105015844106674

Epoch: 5| Step: 3
Training loss: 1.403986930847168
Validation loss: 2.120353654026985

Epoch: 5| Step: 4
Training loss: 1.916959524154663
Validation loss: 2.1356240113576255

Epoch: 5| Step: 5
Training loss: 2.28019380569458
Validation loss: 2.108999917904536

Epoch: 5| Step: 6
Training loss: 2.033872604370117
Validation loss: 2.111812869707743

Epoch: 5| Step: 7
Training loss: 2.0224404335021973
Validation loss: 2.145826285084089

Epoch: 5| Step: 8
Training loss: 2.5731360912323
Validation loss: 2.107589532931646

Epoch: 5| Step: 9
Training loss: 1.8015251159667969
Validation loss: 2.138640597462654

Epoch: 5| Step: 10
Training loss: 2.1529057025909424
Validation loss: 2.1800655275583267

Epoch: 5| Step: 11
Training loss: 1.3043485879898071
Validation loss: 2.162873089313507

Epoch: 32| Step: 0
Training loss: 1.7160310745239258
Validation loss: 2.156011293331782

Epoch: 5| Step: 1
Training loss: 1.913949966430664
Validation loss: 2.1940301011006036

Epoch: 5| Step: 2
Training loss: 2.495591640472412
Validation loss: 2.2283139675855637

Epoch: 5| Step: 3
Training loss: 1.8373267650604248
Validation loss: 2.2756317953268685

Epoch: 5| Step: 4
Training loss: 2.219639301300049
Validation loss: 2.222191338737806

Epoch: 5| Step: 5
Training loss: 2.1909444332122803
Validation loss: 2.203242306907972

Epoch: 5| Step: 6
Training loss: 1.8903560638427734
Validation loss: 2.1392373740673065

Epoch: 5| Step: 7
Training loss: 2.1502492427825928
Validation loss: 2.113733778397242

Epoch: 5| Step: 8
Training loss: 1.8338829278945923
Validation loss: 2.111081530650457

Epoch: 5| Step: 9
Training loss: 2.2047510147094727
Validation loss: 2.061476548512777

Epoch: 5| Step: 10
Training loss: 1.909690499305725
Validation loss: 2.1300750921169915

Epoch: 5| Step: 11
Training loss: 1.2335889339447021
Validation loss: 2.0639170010884604

Epoch: 33| Step: 0
Training loss: 2.370166301727295
Validation loss: 2.058338448405266

Epoch: 5| Step: 1
Training loss: 1.8355436325073242
Validation loss: 2.1412842869758606

Epoch: 5| Step: 2
Training loss: 2.392367124557495
Validation loss: 2.0878129601478577

Epoch: 5| Step: 3
Training loss: 2.410020351409912
Validation loss: 2.0140981525182724

Epoch: 5| Step: 4
Training loss: 1.6404520273208618
Validation loss: 2.094503159324328

Epoch: 5| Step: 5
Training loss: 2.466656446456909
Validation loss: 2.096846103668213

Epoch: 5| Step: 6
Training loss: 1.9396741390228271
Validation loss: 2.1042848080396652

Epoch: 5| Step: 7
Training loss: 2.0323169231414795
Validation loss: 2.1789369185765586

Epoch: 5| Step: 8
Training loss: 1.889552354812622
Validation loss: 2.1085991313060126

Epoch: 5| Step: 9
Training loss: 1.7844241857528687
Validation loss: 2.140507231156031

Epoch: 5| Step: 10
Training loss: 2.0652947425842285
Validation loss: 2.067776173353195

Epoch: 5| Step: 11
Training loss: 1.1190413236618042
Validation loss: 2.0423851211865744

Epoch: 34| Step: 0
Training loss: 2.246103525161743
Validation loss: 2.1809699336687722

Epoch: 5| Step: 1
Training loss: 2.104037046432495
Validation loss: 2.1389956325292587

Epoch: 5| Step: 2
Training loss: 2.1347925662994385
Validation loss: 2.127180347839991

Epoch: 5| Step: 3
Training loss: 1.9688365459442139
Validation loss: 2.113359654943148

Epoch: 5| Step: 4
Training loss: 1.8113950490951538
Validation loss: 2.1289961338043213

Epoch: 5| Step: 5
Training loss: 2.6564173698425293
Validation loss: 2.1518124838670096

Epoch: 5| Step: 6
Training loss: 2.2609524726867676
Validation loss: 2.065338914593061

Epoch: 5| Step: 7
Training loss: 1.9270747900009155
Validation loss: 2.115129068493843

Epoch: 5| Step: 8
Training loss: 1.8378639221191406
Validation loss: 2.1955705732107162

Epoch: 5| Step: 9
Training loss: 1.7224795818328857
Validation loss: 2.1305242578188577

Epoch: 5| Step: 10
Training loss: 1.7777704000473022
Validation loss: 2.1148552348216376

Epoch: 5| Step: 11
Training loss: 1.412938117980957
Validation loss: 2.1338646759589515

Epoch: 35| Step: 0
Training loss: 2.2284820079803467
Validation loss: 2.1411970456441245

Epoch: 5| Step: 1
Training loss: 1.3261317014694214
Validation loss: 2.1372668792804084

Epoch: 5| Step: 2
Training loss: 1.9317512512207031
Validation loss: 2.0564990788698196

Epoch: 5| Step: 3
Training loss: 2.0198874473571777
Validation loss: 2.096467832724253

Epoch: 5| Step: 4
Training loss: 2.07008695602417
Validation loss: 2.138334279259046

Epoch: 5| Step: 5
Training loss: 2.223065137863159
Validation loss: 2.0995156864325204

Epoch: 5| Step: 6
Training loss: 2.2942862510681152
Validation loss: 2.0835955341657004

Epoch: 5| Step: 7
Training loss: 2.145505428314209
Validation loss: 2.1178486247857413

Epoch: 5| Step: 8
Training loss: 2.18432354927063
Validation loss: 2.1251601179440818

Epoch: 5| Step: 9
Training loss: 1.9018131494522095
Validation loss: 2.1055982410907745

Epoch: 5| Step: 10
Training loss: 1.946352243423462
Validation loss: 2.13019227484862

Epoch: 5| Step: 11
Training loss: 2.8224873542785645
Validation loss: 2.139340485135714

Epoch: 36| Step: 0
Training loss: 1.4093679189682007
Validation loss: 2.122924586137136

Epoch: 5| Step: 1
Training loss: 2.4050183296203613
Validation loss: 2.0931472380956015

Epoch: 5| Step: 2
Training loss: 1.7541898488998413
Validation loss: 2.067738965153694

Epoch: 5| Step: 3
Training loss: 1.7743231058120728
Validation loss: 2.085532635450363

Epoch: 5| Step: 4
Training loss: 1.9327991008758545
Validation loss: 2.1442696352799735

Epoch: 5| Step: 5
Training loss: 1.4216340780258179
Validation loss: 2.090061773856481

Epoch: 5| Step: 6
Training loss: 1.7288367748260498
Validation loss: 2.1219518184661865

Epoch: 5| Step: 7
Training loss: 2.810075521469116
Validation loss: 2.112598349650701

Epoch: 5| Step: 8
Training loss: 2.2361083030700684
Validation loss: 2.160079022248586

Epoch: 5| Step: 9
Training loss: 2.401282548904419
Validation loss: 2.040007730325063

Epoch: 5| Step: 10
Training loss: 1.8034509420394897
Validation loss: 1.9982578506072362

Epoch: 5| Step: 11
Training loss: 1.9626476764678955
Validation loss: 2.102240651845932

Epoch: 37| Step: 0
Training loss: 2.209113597869873
Validation loss: 2.043252636988958

Epoch: 5| Step: 1
Training loss: 1.147594690322876
Validation loss: 2.075123275319735

Epoch: 5| Step: 2
Training loss: 2.1931116580963135
Validation loss: 2.1356632312138877

Epoch: 5| Step: 3
Training loss: 2.068352222442627
Validation loss: 2.0670141130685806

Epoch: 5| Step: 4
Training loss: 1.6468021869659424
Validation loss: 2.0797998309135437

Epoch: 5| Step: 5
Training loss: 2.6956872940063477
Validation loss: 2.0621078113714852

Epoch: 5| Step: 6
Training loss: 2.5672099590301514
Validation loss: 2.125313033660253

Epoch: 5| Step: 7
Training loss: 2.0821728706359863
Validation loss: 2.1790786385536194

Epoch: 5| Step: 8
Training loss: 1.9838974475860596
Validation loss: 2.162554124991099

Epoch: 5| Step: 9
Training loss: 2.1327879428863525
Validation loss: 2.0698492527008057

Epoch: 5| Step: 10
Training loss: 1.3484874963760376
Validation loss: 2.164274459083875

Epoch: 5| Step: 11
Training loss: 0.8366787433624268
Validation loss: 2.0608252932627997

Epoch: 38| Step: 0
Training loss: 1.9582865238189697
Validation loss: 2.1463868468999863

Epoch: 5| Step: 1
Training loss: 2.168900728225708
Validation loss: 2.033993740876516

Epoch: 5| Step: 2
Training loss: 2.4635915756225586
Validation loss: 2.13473146657149

Epoch: 5| Step: 3
Training loss: 2.730051279067993
Validation loss: 2.086792786916097

Epoch: 5| Step: 4
Training loss: 1.7848583459854126
Validation loss: 2.044912358125051

Epoch: 5| Step: 5
Training loss: 1.9446258544921875
Validation loss: 2.0963972558577857

Epoch: 5| Step: 6
Training loss: 1.542842149734497
Validation loss: 2.073145126303037

Epoch: 5| Step: 7
Training loss: 2.0608420372009277
Validation loss: 2.0887622435887656

Epoch: 5| Step: 8
Training loss: 1.145892858505249
Validation loss: 2.1289948721726737

Epoch: 5| Step: 9
Training loss: 1.9847133159637451
Validation loss: 2.0944065004587173

Epoch: 5| Step: 10
Training loss: 2.117079973220825
Validation loss: 2.1246491273244223

Epoch: 5| Step: 11
Training loss: 2.521749258041382
Validation loss: 2.1043735394875207

Epoch: 39| Step: 0
Training loss: 2.0927557945251465
Validation loss: 2.0439692586660385

Epoch: 5| Step: 1
Training loss: 1.6506702899932861
Validation loss: 2.0796343137820563

Epoch: 5| Step: 2
Training loss: 2.3261923789978027
Validation loss: 2.155065322915713

Epoch: 5| Step: 3
Training loss: 1.7981846332550049
Validation loss: 2.117947300275167

Epoch: 5| Step: 4
Training loss: 2.907529354095459
Validation loss: 2.1916122684876123

Epoch: 5| Step: 5
Training loss: 2.085956573486328
Validation loss: 2.1426315357287726

Epoch: 5| Step: 6
Training loss: 1.9153196811676025
Validation loss: 2.1526792446772256

Epoch: 5| Step: 7
Training loss: 1.9399687051773071
Validation loss: 2.10042996207873

Epoch: 5| Step: 8
Training loss: 2.0843849182128906
Validation loss: 2.150291015704473

Epoch: 5| Step: 9
Training loss: 1.3484019041061401
Validation loss: 2.11711186170578

Epoch: 5| Step: 10
Training loss: 1.7241178750991821
Validation loss: 2.1169214198986688

Epoch: 5| Step: 11
Training loss: 3.187037467956543
Validation loss: 2.064139281709989

Epoch: 40| Step: 0
Training loss: 1.6863765716552734
Validation loss: 2.1062147269646325

Epoch: 5| Step: 1
Training loss: 2.20296049118042
Validation loss: 2.089882954955101

Epoch: 5| Step: 2
Training loss: 1.469594955444336
Validation loss: 2.090771128733953

Epoch: 5| Step: 3
Training loss: 2.1936519145965576
Validation loss: 2.137264291445414

Epoch: 5| Step: 4
Training loss: 1.9025852680206299
Validation loss: 2.084809939066569

Epoch: 5| Step: 5
Training loss: 1.793749213218689
Validation loss: 2.1644460360209146

Epoch: 5| Step: 6
Training loss: 1.630200982093811
Validation loss: 2.094234451651573

Epoch: 5| Step: 7
Training loss: 2.104858875274658
Validation loss: 2.1613999009132385

Epoch: 5| Step: 8
Training loss: 2.1657681465148926
Validation loss: 2.1357945054769516

Epoch: 5| Step: 9
Training loss: 2.062349796295166
Validation loss: 2.057347039381663

Epoch: 5| Step: 10
Training loss: 2.240661144256592
Validation loss: 2.133600523074468

Epoch: 5| Step: 11
Training loss: 1.035465121269226
Validation loss: 2.057543784379959

Epoch: 41| Step: 0
Training loss: 2.308345079421997
Validation loss: 2.0775458365678787

Epoch: 5| Step: 1
Training loss: 2.337745189666748
Validation loss: 2.136747181415558

Epoch: 5| Step: 2
Training loss: 1.6439130306243896
Validation loss: 2.136462241411209

Epoch: 5| Step: 3
Training loss: 1.4930598735809326
Validation loss: 2.1401776373386383

Epoch: 5| Step: 4
Training loss: 2.0810999870300293
Validation loss: 2.1335383554299674

Epoch: 5| Step: 5
Training loss: 2.0822055339813232
Validation loss: 2.159122039874395

Epoch: 5| Step: 6
Training loss: 2.152158498764038
Validation loss: 2.132293959458669

Epoch: 5| Step: 7
Training loss: 2.1490113735198975
Validation loss: 2.169779822230339

Epoch: 5| Step: 8
Training loss: 2.00005841255188
Validation loss: 2.0773601283629737

Epoch: 5| Step: 9
Training loss: 1.9595286846160889
Validation loss: 2.061985100309054

Epoch: 5| Step: 10
Training loss: 1.6330459117889404
Validation loss: 2.08479035894076

Epoch: 5| Step: 11
Training loss: 1.4141219854354858
Validation loss: 2.0333372304836907

Epoch: 42| Step: 0
Training loss: 1.6393760442733765
Validation loss: 2.1358837286631265

Epoch: 5| Step: 1
Training loss: 2.0562586784362793
Validation loss: 2.11392272512118

Epoch: 5| Step: 2
Training loss: 2.213426113128662
Validation loss: 2.087240328391393

Epoch: 5| Step: 3
Training loss: 1.772962212562561
Validation loss: 2.1045006612936654

Epoch: 5| Step: 4
Training loss: 2.3731555938720703
Validation loss: 2.1630977392196655

Epoch: 5| Step: 5
Training loss: 1.9745757579803467
Validation loss: 2.1413016517957053

Epoch: 5| Step: 6
Training loss: 1.6756099462509155
Validation loss: 2.13787442445755

Epoch: 5| Step: 7
Training loss: 1.9448192119598389
Validation loss: 2.1600758035977683

Epoch: 5| Step: 8
Training loss: 2.2539706230163574
Validation loss: 2.184332107504209

Epoch: 5| Step: 9
Training loss: 2.3272902965545654
Validation loss: 2.1227097511291504

Epoch: 5| Step: 10
Training loss: 1.739723801612854
Validation loss: 2.074436436096827

Epoch: 5| Step: 11
Training loss: 1.7816227674484253
Validation loss: 2.111697241663933

Epoch: 43| Step: 0
Training loss: 1.5795434713363647
Validation loss: 2.0992049972216287

Epoch: 5| Step: 1
Training loss: 2.339290142059326
Validation loss: 2.034735386570295

Epoch: 5| Step: 2
Training loss: 2.121547222137451
Validation loss: 2.0766173601150513

Epoch: 5| Step: 3
Training loss: 1.5846366882324219
Validation loss: 2.060321941971779

Epoch: 5| Step: 4
Training loss: 1.8594152927398682
Validation loss: 2.1071162670850754

Epoch: 5| Step: 5
Training loss: 2.128754138946533
Validation loss: 2.18551504611969

Epoch: 5| Step: 6
Training loss: 1.941756248474121
Validation loss: 2.1132603933413825

Epoch: 5| Step: 7
Training loss: 2.8981852531433105
Validation loss: 2.0637308905522027

Epoch: 5| Step: 8
Training loss: 1.8190128803253174
Validation loss: 2.074183091521263

Epoch: 5| Step: 9
Training loss: 1.3568155765533447
Validation loss: 2.076607793569565

Epoch: 5| Step: 10
Training loss: 2.1827471256256104
Validation loss: 2.1883188287417092

Epoch: 5| Step: 11
Training loss: 1.4557889699935913
Validation loss: 2.1560190419356027

Epoch: 44| Step: 0
Training loss: 2.002458333969116
Validation loss: 2.099728216727575

Epoch: 5| Step: 1
Training loss: 2.1469531059265137
Validation loss: 2.085641990105311

Epoch: 5| Step: 2
Training loss: 1.7421436309814453
Validation loss: 2.12589593231678

Epoch: 5| Step: 3
Training loss: 1.8556064367294312
Validation loss: 2.1412698725859323

Epoch: 5| Step: 4
Training loss: 2.4106504917144775
Validation loss: 2.108392079671224

Epoch: 5| Step: 5
Training loss: 2.339447498321533
Validation loss: 2.067119891444842

Epoch: 5| Step: 6
Training loss: 2.274942398071289
Validation loss: 2.121213818589846

Epoch: 5| Step: 7
Training loss: 2.048015832901001
Validation loss: 2.0412851721048355

Epoch: 5| Step: 8
Training loss: 2.1109797954559326
Validation loss: 2.168361489971479

Epoch: 5| Step: 9
Training loss: 1.8156840801239014
Validation loss: 2.0839901516834893

Epoch: 5| Step: 10
Training loss: 2.0933330059051514
Validation loss: 2.11763488749663

Epoch: 5| Step: 11
Training loss: 2.4311563968658447
Validation loss: 2.1050886313120523

Epoch: 45| Step: 0
Training loss: 1.9357916116714478
Validation loss: 2.1212755839029946

Epoch: 5| Step: 1
Training loss: 2.4195454120635986
Validation loss: 2.0524303764104843

Epoch: 5| Step: 2
Training loss: 1.363722562789917
Validation loss: 2.128609776496887

Epoch: 5| Step: 3
Training loss: 1.4869053363800049
Validation loss: 2.1684583723545074

Epoch: 5| Step: 4
Training loss: 1.9651556015014648
Validation loss: 2.205710619688034

Epoch: 5| Step: 5
Training loss: 2.4393768310546875
Validation loss: 2.1781809528668723

Epoch: 5| Step: 6
Training loss: 2.0328030586242676
Validation loss: 2.2044544915358224

Epoch: 5| Step: 7
Training loss: 1.9152570962905884
Validation loss: 2.19392021993796

Epoch: 5| Step: 8
Training loss: 2.1966922283172607
Validation loss: 2.2126323183377585

Epoch: 5| Step: 9
Training loss: 2.683549642562866
Validation loss: 2.156269853313764

Epoch: 5| Step: 10
Training loss: 1.7303516864776611
Validation loss: 2.1752740194400153

Epoch: 5| Step: 11
Training loss: 2.206183671951294
Validation loss: 2.171738783518473

Epoch: 46| Step: 0
Training loss: 2.295060396194458
Validation loss: 2.100781559944153

Epoch: 5| Step: 1
Training loss: 1.7128868103027344
Validation loss: 2.0947893261909485

Epoch: 5| Step: 2
Training loss: 2.1919970512390137
Validation loss: 1.9856336861848831

Epoch: 5| Step: 3
Training loss: 1.875181794166565
Validation loss: 2.1424206495285034

Epoch: 5| Step: 4
Training loss: 2.0799288749694824
Validation loss: 2.1344886968533197

Epoch: 5| Step: 5
Training loss: 1.6528091430664062
Validation loss: 2.1196804443995156

Epoch: 5| Step: 6
Training loss: 2.1685590744018555
Validation loss: 2.1017151872316995

Epoch: 5| Step: 7
Training loss: 1.7748241424560547
Validation loss: 2.103610480825106

Epoch: 5| Step: 8
Training loss: 2.2000110149383545
Validation loss: 2.098553786675135

Epoch: 5| Step: 9
Training loss: 1.7499854564666748
Validation loss: 2.074548383553823

Epoch: 5| Step: 10
Training loss: 1.7974939346313477
Validation loss: 2.0771387269099555

Epoch: 5| Step: 11
Training loss: 1.5905393362045288
Validation loss: 2.0711697041988373

Epoch: 47| Step: 0
Training loss: 1.8660709857940674
Validation loss: 2.058590387304624

Epoch: 5| Step: 1
Training loss: 1.6835085153579712
Validation loss: 2.1054612745841346

Epoch: 5| Step: 2
Training loss: 1.6155738830566406
Validation loss: 2.098194753130277

Epoch: 5| Step: 3
Training loss: 1.8640342950820923
Validation loss: 2.06735668083032

Epoch: 5| Step: 4
Training loss: 2.0142922401428223
Validation loss: 2.11752358575662

Epoch: 5| Step: 5
Training loss: 1.7912819385528564
Validation loss: 2.248650978008906

Epoch: 5| Step: 6
Training loss: 2.6480319499969482
Validation loss: 2.128738676508268

Epoch: 5| Step: 7
Training loss: 2.3874874114990234
Validation loss: 2.1440347333749137

Epoch: 5| Step: 8
Training loss: 1.9511957168579102
Validation loss: 2.1279991070429483

Epoch: 5| Step: 9
Training loss: 1.5832065343856812
Validation loss: 2.1614335725704827

Epoch: 5| Step: 10
Training loss: 1.652368187904358
Validation loss: 2.144069125254949

Epoch: 5| Step: 11
Training loss: 3.1916542053222656
Validation loss: 2.097999463478724

Epoch: 48| Step: 0
Training loss: 2.215977430343628
Validation loss: 2.1036762396494546

Epoch: 5| Step: 1
Training loss: 2.223733901977539
Validation loss: 2.1141613026460013

Epoch: 5| Step: 2
Training loss: 1.5741827487945557
Validation loss: 2.113414833943049

Epoch: 5| Step: 3
Training loss: 1.6370575428009033
Validation loss: 2.176536043485006

Epoch: 5| Step: 4
Training loss: 1.401837706565857
Validation loss: 2.130752662817637

Epoch: 5| Step: 5
Training loss: 1.4265921115875244
Validation loss: 2.094054405887922

Epoch: 5| Step: 6
Training loss: 2.345913887023926
Validation loss: 2.104115520914396

Epoch: 5| Step: 7
Training loss: 2.5416038036346436
Validation loss: 2.033234397570292

Epoch: 5| Step: 8
Training loss: 2.157116413116455
Validation loss: 2.0893990248441696

Epoch: 5| Step: 9
Training loss: 2.1074748039245605
Validation loss: 2.0602726340293884

Epoch: 5| Step: 10
Training loss: 1.8678232431411743
Validation loss: 2.0434988290071487

Epoch: 5| Step: 11
Training loss: 3.3225955963134766
Validation loss: 2.091340790192286

Epoch: 49| Step: 0
Training loss: 1.5923446416854858
Validation loss: 1.9890516300996144

Epoch: 5| Step: 1
Training loss: 1.9070446491241455
Validation loss: 2.060309886932373

Epoch: 5| Step: 2
Training loss: 1.7544864416122437
Validation loss: 2.005453715721766

Epoch: 5| Step: 3
Training loss: 2.2605834007263184
Validation loss: 2.0926038970549903

Epoch: 5| Step: 4
Training loss: 2.104264736175537
Validation loss: 2.1424116094907126

Epoch: 5| Step: 5
Training loss: 1.8989890813827515
Validation loss: 2.04714368780454

Epoch: 5| Step: 6
Training loss: 2.457009792327881
Validation loss: 2.079632803797722

Epoch: 5| Step: 7
Training loss: 1.6689380407333374
Validation loss: 2.111335337162018

Epoch: 5| Step: 8
Training loss: 2.005066156387329
Validation loss: 2.0142264862855277

Epoch: 5| Step: 9
Training loss: 2.13381028175354
Validation loss: 2.1141747583945594

Epoch: 5| Step: 10
Training loss: 2.2709293365478516
Validation loss: 2.150747408469518

Epoch: 5| Step: 11
Training loss: 2.2749805450439453
Validation loss: 2.076277414957682

Epoch: 50| Step: 0
Training loss: 2.150646686553955
Validation loss: 2.1347121596336365

Epoch: 5| Step: 1
Training loss: 1.3168694972991943
Validation loss: 2.113949919740359

Epoch: 5| Step: 2
Training loss: 2.3011703491210938
Validation loss: 2.1532978316148124

Epoch: 5| Step: 3
Training loss: 2.328547954559326
Validation loss: 2.104095314939817

Epoch: 5| Step: 4
Training loss: 2.1072192192077637
Validation loss: 2.11299729347229

Epoch: 5| Step: 5
Training loss: 2.5615134239196777
Validation loss: 2.0842729906241098

Epoch: 5| Step: 6
Training loss: 2.440187931060791
Validation loss: 2.1192477494478226

Epoch: 5| Step: 7
Training loss: 1.610241174697876
Validation loss: 2.158635367949804

Epoch: 5| Step: 8
Training loss: 1.8064037561416626
Validation loss: 2.175064116716385

Epoch: 5| Step: 9
Training loss: 1.948894739151001
Validation loss: 2.125138600667318

Epoch: 5| Step: 10
Training loss: 1.3560516834259033
Validation loss: 2.0836606671412787

Epoch: 5| Step: 11
Training loss: 0.7382315397262573
Validation loss: 2.0999891658624015

Epoch: 51| Step: 0
Training loss: 1.8530244827270508
Validation loss: 2.1335680782794952

Epoch: 5| Step: 1
Training loss: 2.1812644004821777
Validation loss: 2.1181108156840005

Epoch: 5| Step: 2
Training loss: 1.7180391550064087
Validation loss: 2.1107704689105353

Epoch: 5| Step: 3
Training loss: 2.019853115081787
Validation loss: 2.0945014407237372

Epoch: 5| Step: 4
Training loss: 1.5187114477157593
Validation loss: 2.0422929426034293

Epoch: 5| Step: 5
Training loss: 1.3879270553588867
Validation loss: 2.114367683728536

Epoch: 5| Step: 6
Training loss: 1.7205216884613037
Validation loss: 2.0390577962001166

Epoch: 5| Step: 7
Training loss: 1.9845815896987915
Validation loss: 2.0637796223163605

Epoch: 5| Step: 8
Training loss: 1.9813501834869385
Validation loss: 2.2351166357596717

Epoch: 5| Step: 9
Training loss: 2.02333402633667
Validation loss: 2.1124389519294104

Epoch: 5| Step: 10
Training loss: 2.6832282543182373
Validation loss: 2.1300098349650702

Epoch: 5| Step: 11
Training loss: 2.8863773345947266
Validation loss: 2.0729386657476425

Epoch: 52| Step: 0
Training loss: 2.2026331424713135
Validation loss: 2.160233442982038

Epoch: 5| Step: 1
Training loss: 1.768526315689087
Validation loss: 2.1050939013560614

Epoch: 5| Step: 2
Training loss: 1.5335588455200195
Validation loss: 2.0567051817973456

Epoch: 5| Step: 3
Training loss: 2.4268150329589844
Validation loss: 2.0964926977952323

Epoch: 5| Step: 4
Training loss: 1.1112573146820068
Validation loss: 2.0208816876014075

Epoch: 5| Step: 5
Training loss: 1.8752483129501343
Validation loss: 2.080395152171453

Epoch: 5| Step: 6
Training loss: 2.8172802925109863
Validation loss: 2.0769645323355994

Epoch: 5| Step: 7
Training loss: 2.614210367202759
Validation loss: 2.0272899915774665

Epoch: 5| Step: 8
Training loss: 1.4230705499649048
Validation loss: 2.144202301899592

Epoch: 5| Step: 9
Training loss: 1.9257959127426147
Validation loss: 2.103180915117264

Epoch: 5| Step: 10
Training loss: 2.322338819503784
Validation loss: 2.085659086704254

Epoch: 5| Step: 11
Training loss: 1.1574578285217285
Validation loss: 2.113370234767596

Epoch: 53| Step: 0
Training loss: 1.6959047317504883
Validation loss: 2.1389582753181458

Epoch: 5| Step: 1
Training loss: 2.334228992462158
Validation loss: 2.066672772169113

Epoch: 5| Step: 2
Training loss: 2.1901416778564453
Validation loss: 2.069412589073181

Epoch: 5| Step: 3
Training loss: 2.3478429317474365
Validation loss: 2.120594729979833

Epoch: 5| Step: 4
Training loss: 1.9611018896102905
Validation loss: 2.094573045770327

Epoch: 5| Step: 5
Training loss: 1.9342553615570068
Validation loss: 2.093343665202459

Epoch: 5| Step: 6
Training loss: 1.6361576318740845
Validation loss: 2.1018038988113403

Epoch: 5| Step: 7
Training loss: 1.8573439121246338
Validation loss: 2.0525237023830414

Epoch: 5| Step: 8
Training loss: 1.916433334350586
Validation loss: 2.137764493624369

Epoch: 5| Step: 9
Training loss: 1.4661604166030884
Validation loss: 2.144011120001475

Epoch: 5| Step: 10
Training loss: 1.9155454635620117
Validation loss: 2.119536037246386

Epoch: 5| Step: 11
Training loss: 2.839536190032959
Validation loss: 2.1464129189650216

Epoch: 54| Step: 0
Training loss: 1.9067802429199219
Validation loss: 2.1259268820285797

Epoch: 5| Step: 1
Training loss: 2.310669422149658
Validation loss: 2.2091841995716095

Epoch: 5| Step: 2
Training loss: 1.5998797416687012
Validation loss: 2.09297422071298

Epoch: 5| Step: 3
Training loss: 1.6921370029449463
Validation loss: 2.0764252046744027

Epoch: 5| Step: 4
Training loss: 1.6078646183013916
Validation loss: 2.1351772596438727

Epoch: 5| Step: 5
Training loss: 1.9285719394683838
Validation loss: 2.1417827705542245

Epoch: 5| Step: 6
Training loss: 2.155284881591797
Validation loss: 2.1413181871175766

Epoch: 5| Step: 7
Training loss: 2.0851340293884277
Validation loss: 2.1495693822701774

Epoch: 5| Step: 8
Training loss: 2.37797212600708
Validation loss: 2.119572634498278

Epoch: 5| Step: 9
Training loss: 2.149526357650757
Validation loss: 2.148006464044253

Epoch: 5| Step: 10
Training loss: 1.4360872507095337
Validation loss: 2.1065991520881653

Epoch: 5| Step: 11
Training loss: 2.9300317764282227
Validation loss: 2.107094014684359

Epoch: 55| Step: 0
Training loss: 1.2003015279769897
Validation loss: 2.125131373604139

Epoch: 5| Step: 1
Training loss: 1.6350425481796265
Validation loss: 2.067974090576172

Epoch: 5| Step: 2
Training loss: 2.5694994926452637
Validation loss: 2.08122385541598

Epoch: 5| Step: 3
Training loss: 2.3066632747650146
Validation loss: 2.068553845087687

Epoch: 5| Step: 4
Training loss: 1.6930930614471436
Validation loss: 2.107347016533216

Epoch: 5| Step: 5
Training loss: 1.771406888961792
Validation loss: 2.034793049097061

Epoch: 5| Step: 6
Training loss: 1.8472421169281006
Validation loss: 2.098829726378123

Epoch: 5| Step: 7
Training loss: 1.834580659866333
Validation loss: 2.0710770189762115

Epoch: 5| Step: 8
Training loss: 2.0050833225250244
Validation loss: 2.0670889566342034

Epoch: 5| Step: 9
Training loss: 2.171583652496338
Validation loss: 2.1300154328346252

Epoch: 5| Step: 10
Training loss: 2.1605286598205566
Validation loss: 2.1345030665397644

Epoch: 5| Step: 11
Training loss: 1.4214491844177246
Validation loss: 2.097174435853958

Epoch: 56| Step: 0
Training loss: 1.7539228200912476
Validation loss: 2.090324948231379

Epoch: 5| Step: 1
Training loss: 2.1896369457244873
Validation loss: 2.0939130932092667

Epoch: 5| Step: 2
Training loss: 2.151306629180908
Validation loss: 2.0634989192088447

Epoch: 5| Step: 3
Training loss: 1.897460699081421
Validation loss: 2.0786254902680716

Epoch: 5| Step: 4
Training loss: 1.9457082748413086
Validation loss: 2.103816643357277

Epoch: 5| Step: 5
Training loss: 1.8588159084320068
Validation loss: 2.0702060411373773

Epoch: 5| Step: 6
Training loss: 2.4155142307281494
Validation loss: 2.1381093760331473

Epoch: 5| Step: 7
Training loss: 2.058398723602295
Validation loss: 2.1308538913726807

Epoch: 5| Step: 8
Training loss: 1.937061071395874
Validation loss: 2.1457004050413766

Epoch: 5| Step: 9
Training loss: 1.96967351436615
Validation loss: 2.207757458090782

Epoch: 5| Step: 10
Training loss: 1.8565479516983032
Validation loss: 2.248776604731878

Epoch: 5| Step: 11
Training loss: 1.6309596300125122
Validation loss: 2.1457655827204385

Epoch: 57| Step: 0
Training loss: 1.7605558633804321
Validation loss: 2.1003679732481637

Epoch: 5| Step: 1
Training loss: 1.5395225286483765
Validation loss: 2.0901549061139426

Epoch: 5| Step: 2
Training loss: 2.088925838470459
Validation loss: 2.0580649226903915

Epoch: 5| Step: 3
Training loss: 1.9825494289398193
Validation loss: 2.055446336666743

Epoch: 5| Step: 4
Training loss: 2.065394163131714
Validation loss: 2.099368487795194

Epoch: 5| Step: 5
Training loss: 1.7812092304229736
Validation loss: 2.110216279824575

Epoch: 5| Step: 6
Training loss: 2.6078381538391113
Validation loss: 2.0348216543594995

Epoch: 5| Step: 7
Training loss: 1.996742844581604
Validation loss: 2.1260524839162827

Epoch: 5| Step: 8
Training loss: 2.248656749725342
Validation loss: 2.172168011466662

Epoch: 5| Step: 9
Training loss: 1.9716631174087524
Validation loss: 2.181358387072881

Epoch: 5| Step: 10
Training loss: 1.3488794565200806
Validation loss: 2.116588150461515

Epoch: 5| Step: 11
Training loss: 3.2070937156677246
Validation loss: 2.1341824531555176

Epoch: 58| Step: 0
Training loss: 2.0853652954101562
Validation loss: 2.0782953649759293

Epoch: 5| Step: 1
Training loss: 2.15753436088562
Validation loss: 2.085785190264384

Epoch: 5| Step: 2
Training loss: 1.7382606267929077
Validation loss: 2.144474317630132

Epoch: 5| Step: 3
Training loss: 1.8517024517059326
Validation loss: 2.0872730116049447

Epoch: 5| Step: 4
Training loss: 2.3519582748413086
Validation loss: 2.057398716608683

Epoch: 5| Step: 5
Training loss: 1.7761207818984985
Validation loss: 2.1222094545761743

Epoch: 5| Step: 6
Training loss: 2.6190884113311768
Validation loss: 2.2226629555225372

Epoch: 5| Step: 7
Training loss: 1.8079208135604858
Validation loss: 2.153236831227938

Epoch: 5| Step: 8
Training loss: 1.880590796470642
Validation loss: 2.1349603831768036

Epoch: 5| Step: 9
Training loss: 1.9320329427719116
Validation loss: 2.1803458531697593

Epoch: 5| Step: 10
Training loss: 1.735491156578064
Validation loss: 2.154394348462423

Epoch: 5| Step: 11
Training loss: 1.662855625152588
Validation loss: 2.162868082523346

Epoch: 59| Step: 0
Training loss: 1.0541834831237793
Validation loss: 2.1360504229863486

Epoch: 5| Step: 1
Training loss: 2.077434539794922
Validation loss: 2.1053588141997657

Epoch: 5| Step: 2
Training loss: 2.4858908653259277
Validation loss: 2.128847822546959

Epoch: 5| Step: 3
Training loss: 1.64669930934906
Validation loss: 2.1470846931139627

Epoch: 5| Step: 4
Training loss: 1.8183122873306274
Validation loss: 2.113749315341314

Epoch: 5| Step: 5
Training loss: 2.031244993209839
Validation loss: 2.008606101075808

Epoch: 5| Step: 6
Training loss: 2.5184428691864014
Validation loss: 2.1098890900611877

Epoch: 5| Step: 7
Training loss: 2.2791197299957275
Validation loss: 2.1108328551054

Epoch: 5| Step: 8
Training loss: 2.203798294067383
Validation loss: 2.118723601102829

Epoch: 5| Step: 9
Training loss: 1.8520677089691162
Validation loss: 2.1585750579833984

Epoch: 5| Step: 10
Training loss: 1.9752137660980225
Validation loss: 2.1081231037775674

Epoch: 5| Step: 11
Training loss: 2.1028404235839844
Validation loss: 2.117247467239698

Epoch: 60| Step: 0
Training loss: 1.5895323753356934
Validation loss: 2.0898694843053818

Epoch: 5| Step: 1
Training loss: 2.1330726146698
Validation loss: 2.0979498277107873

Epoch: 5| Step: 2
Training loss: 2.0628702640533447
Validation loss: 2.115813429156939

Epoch: 5| Step: 3
Training loss: 1.866268515586853
Validation loss: 2.099570428331693

Epoch: 5| Step: 4
Training loss: 1.6112596988677979
Validation loss: 2.067911426226298

Epoch: 5| Step: 5
Training loss: 1.3828449249267578
Validation loss: 2.0929193099339805

Epoch: 5| Step: 6
Training loss: 1.5200347900390625
Validation loss: 2.1323360204696655

Epoch: 5| Step: 7
Training loss: 2.4030838012695312
Validation loss: 1.9974493434031804

Epoch: 5| Step: 8
Training loss: 2.3387656211853027
Validation loss: 2.196870411435763

Epoch: 5| Step: 9
Training loss: 1.5857222080230713
Validation loss: 2.0925088276465735

Epoch: 5| Step: 10
Training loss: 2.083585023880005
Validation loss: 2.1138050059477487

Epoch: 5| Step: 11
Training loss: 1.9358279705047607
Validation loss: 2.141892224550247

Epoch: 61| Step: 0
Training loss: 1.9786256551742554
Validation loss: 2.119833290576935

Epoch: 5| Step: 1
Training loss: 1.8551642894744873
Validation loss: 2.1011358201503754

Epoch: 5| Step: 2
Training loss: 1.6340219974517822
Validation loss: 2.123142421245575

Epoch: 5| Step: 3
Training loss: 1.6378686428070068
Validation loss: 2.0850536475578942

Epoch: 5| Step: 4
Training loss: 2.1944985389709473
Validation loss: 2.126457909742991

Epoch: 5| Step: 5
Training loss: 1.7053849697113037
Validation loss: 2.181285714109739

Epoch: 5| Step: 6
Training loss: 1.5724546909332275
Validation loss: 2.204005926847458

Epoch: 5| Step: 7
Training loss: 1.9030838012695312
Validation loss: 2.142736926674843

Epoch: 5| Step: 8
Training loss: 2.619255542755127
Validation loss: 2.1043302764495215

Epoch: 5| Step: 9
Training loss: 2.4228179454803467
Validation loss: 2.1005820284287133

Epoch: 5| Step: 10
Training loss: 1.872449278831482
Validation loss: 2.1079701582590737

Epoch: 5| Step: 11
Training loss: 1.4934080839157104
Validation loss: 2.14063590268294

Epoch: 62| Step: 0
Training loss: 2.569430112838745
Validation loss: 2.081439961989721

Epoch: 5| Step: 1
Training loss: 1.7225109338760376
Validation loss: 2.0641772001981735

Epoch: 5| Step: 2
Training loss: 1.8012727499008179
Validation loss: 2.131968006491661

Epoch: 5| Step: 3
Training loss: 1.9868005514144897
Validation loss: 2.0493202904860177

Epoch: 5| Step: 4
Training loss: 2.083503484725952
Validation loss: 2.102421820163727

Epoch: 5| Step: 5
Training loss: 1.917331337928772
Validation loss: 2.0616113543510437

Epoch: 5| Step: 6
Training loss: 1.9928795099258423
Validation loss: 2.110910177230835

Epoch: 5| Step: 7
Training loss: 2.4259772300720215
Validation loss: 2.109358921647072

Epoch: 5| Step: 8
Training loss: 1.8076188564300537
Validation loss: 2.1395383526881537

Epoch: 5| Step: 9
Training loss: 1.6869392395019531
Validation loss: 2.0433489133914313

Epoch: 5| Step: 10
Training loss: 2.2352192401885986
Validation loss: 2.0705427527427673

Epoch: 5| Step: 11
Training loss: 1.4232298135757446
Validation loss: 2.0761126577854156

Epoch: 63| Step: 0
Training loss: 1.9538860321044922
Validation loss: 2.1801985005537667

Epoch: 5| Step: 1
Training loss: 2.1255757808685303
Validation loss: 2.054544990261396

Epoch: 5| Step: 2
Training loss: 1.5588480234146118
Validation loss: 2.1241004963715873

Epoch: 5| Step: 3
Training loss: 1.9233529567718506
Validation loss: 2.0852436472972236

Epoch: 5| Step: 4
Training loss: 2.0231807231903076
Validation loss: 2.0393174986044564

Epoch: 5| Step: 5
Training loss: 2.386974334716797
Validation loss: 2.1265480667352676

Epoch: 5| Step: 6
Training loss: 1.820439338684082
Validation loss: 2.121514543890953

Epoch: 5| Step: 7
Training loss: 1.9884744882583618
Validation loss: 2.0969191789627075

Epoch: 5| Step: 8
Training loss: 2.1575167179107666
Validation loss: 2.0694568355878196

Epoch: 5| Step: 9
Training loss: 1.6379213333129883
Validation loss: 2.121768673261007

Epoch: 5| Step: 10
Training loss: 1.7707183361053467
Validation loss: 2.091909800966581

Epoch: 5| Step: 11
Training loss: 2.1145341396331787
Validation loss: 2.057615876197815

Epoch: 64| Step: 0
Training loss: 1.7999637126922607
Validation loss: 2.154358610510826

Epoch: 5| Step: 1
Training loss: 1.7867625951766968
Validation loss: 2.062141567468643

Epoch: 5| Step: 2
Training loss: 1.97211492061615
Validation loss: 2.0780635376771293

Epoch: 5| Step: 3
Training loss: 2.6442668437957764
Validation loss: 2.077634776631991

Epoch: 5| Step: 4
Training loss: 2.0305299758911133
Validation loss: 2.098642269770304

Epoch: 5| Step: 5
Training loss: 1.868558645248413
Validation loss: 2.138183608651161

Epoch: 5| Step: 6
Training loss: 1.747542142868042
Validation loss: 2.100656117002169

Epoch: 5| Step: 7
Training loss: 1.5674411058425903
Validation loss: 2.0978228648503623

Epoch: 5| Step: 8
Training loss: 2.1225197315216064
Validation loss: 2.096929430961609

Epoch: 5| Step: 9
Training loss: 1.5246012210845947
Validation loss: 2.17330993215243

Epoch: 5| Step: 10
Training loss: 2.001675844192505
Validation loss: 2.038495366772016

Epoch: 5| Step: 11
Training loss: 1.392618179321289
Validation loss: 2.058254281679789

Epoch: 65| Step: 0
Training loss: 1.7295337915420532
Validation loss: 2.074982484181722

Epoch: 5| Step: 1
Training loss: 1.553127408027649
Validation loss: 2.1583059231440225

Epoch: 5| Step: 2
Training loss: 2.2094788551330566
Validation loss: 2.152575800816218

Epoch: 5| Step: 3
Training loss: 1.899397611618042
Validation loss: 2.0952842136224112

Epoch: 5| Step: 4
Training loss: 2.099989175796509
Validation loss: 2.0950790842374167

Epoch: 5| Step: 5
Training loss: 1.917435884475708
Validation loss: 2.083811476826668

Epoch: 5| Step: 6
Training loss: 2.3286643028259277
Validation loss: 2.1148033241430917

Epoch: 5| Step: 7
Training loss: 2.21362566947937
Validation loss: 2.023511399825414

Epoch: 5| Step: 8
Training loss: 1.5193710327148438
Validation loss: 2.058130368590355

Epoch: 5| Step: 9
Training loss: 2.163116693496704
Validation loss: 2.154908910393715

Epoch: 5| Step: 10
Training loss: 1.8909168243408203
Validation loss: 2.0656439661979675

Epoch: 5| Step: 11
Training loss: 2.5219154357910156
Validation loss: 2.1629788478215537

Epoch: 66| Step: 0
Training loss: 1.9803907871246338
Validation loss: 2.1369934578736625

Epoch: 5| Step: 1
Training loss: 2.1566083431243896
Validation loss: 2.11535607278347

Epoch: 5| Step: 2
Training loss: 2.342935562133789
Validation loss: 2.2133063773314157

Epoch: 5| Step: 3
Training loss: 1.4399434328079224
Validation loss: 2.156338761250178

Epoch: 5| Step: 4
Training loss: 2.0440638065338135
Validation loss: 2.0961904426415763

Epoch: 5| Step: 5
Training loss: 1.8412491083145142
Validation loss: 2.120356077949206

Epoch: 5| Step: 6
Training loss: 1.9211612939834595
Validation loss: 2.140503699580828

Epoch: 5| Step: 7
Training loss: 1.7395493984222412
Validation loss: 2.1614781618118286

Epoch: 5| Step: 8
Training loss: 1.6645176410675049
Validation loss: 2.1620099196831384

Epoch: 5| Step: 9
Training loss: 2.283552646636963
Validation loss: 2.1083756536245346

Epoch: 5| Step: 10
Training loss: 1.8259769678115845
Validation loss: 2.0409144461154938

Epoch: 5| Step: 11
Training loss: 2.932060956954956
Validation loss: 2.121577421824137

Epoch: 67| Step: 0
Training loss: 1.7192920446395874
Validation loss: 2.077945833404859

Epoch: 5| Step: 1
Training loss: 1.7057822942733765
Validation loss: 2.1459713727235794

Epoch: 5| Step: 2
Training loss: 1.8049428462982178
Validation loss: 2.0339304159084954

Epoch: 5| Step: 3
Training loss: 1.9080498218536377
Validation loss: 2.0862930913766227

Epoch: 5| Step: 4
Training loss: 1.8987388610839844
Validation loss: 2.130171537399292

Epoch: 5| Step: 5
Training loss: 2.5134785175323486
Validation loss: 2.11394756535689

Epoch: 5| Step: 6
Training loss: 2.567913770675659
Validation loss: 2.155012627442678

Epoch: 5| Step: 7
Training loss: 1.6085035800933838
Validation loss: 2.1236727982759476

Epoch: 5| Step: 8
Training loss: 2.496825933456421
Validation loss: 2.0954340348641076

Epoch: 5| Step: 9
Training loss: 1.6219136714935303
Validation loss: 2.1254076957702637

Epoch: 5| Step: 10
Training loss: 1.3835363388061523
Validation loss: 2.080272138118744

Epoch: 5| Step: 11
Training loss: 1.881470799446106
Validation loss: 2.0717694212992988

Epoch: 68| Step: 0
Training loss: 1.772170066833496
Validation loss: 2.0215564966201782

Epoch: 5| Step: 1
Training loss: 2.2642581462860107
Validation loss: 2.084575648109118

Epoch: 5| Step: 2
Training loss: 1.8852754831314087
Validation loss: 2.090513288974762

Epoch: 5| Step: 3
Training loss: 2.010962963104248
Validation loss: 2.1164955844481788

Epoch: 5| Step: 4
Training loss: 1.7942014932632446
Validation loss: 2.0217402329047522

Epoch: 5| Step: 5
Training loss: 1.5756157636642456
Validation loss: 2.1959320455789566

Epoch: 5| Step: 6
Training loss: 2.1679129600524902
Validation loss: 2.202608029047648

Epoch: 5| Step: 7
Training loss: 1.3060327768325806
Validation loss: 2.19790381193161

Epoch: 5| Step: 8
Training loss: 2.1978116035461426
Validation loss: 2.150910422205925

Epoch: 5| Step: 9
Training loss: 2.298231601715088
Validation loss: 2.230531652768453

Epoch: 5| Step: 10
Training loss: 2.459564208984375
Validation loss: 2.2201756636301675

Epoch: 5| Step: 11
Training loss: 1.4572558403015137
Validation loss: 2.1780598759651184

Epoch: 69| Step: 0
Training loss: 2.082047700881958
Validation loss: 2.240878696242968

Epoch: 5| Step: 1
Training loss: 1.7159353494644165
Validation loss: 2.1841635505358377

Epoch: 5| Step: 2
Training loss: 2.481041431427002
Validation loss: 2.1920144110918045

Epoch: 5| Step: 3
Training loss: 1.6565532684326172
Validation loss: 2.146894554297129

Epoch: 5| Step: 4
Training loss: 1.4156626462936401
Validation loss: 2.181369503339132

Epoch: 5| Step: 5
Training loss: 2.0598366260528564
Validation loss: 2.186613063017527

Epoch: 5| Step: 6
Training loss: 1.7398204803466797
Validation loss: 2.1751005351543427

Epoch: 5| Step: 7
Training loss: 1.6928777694702148
Validation loss: 2.1442260096470513

Epoch: 5| Step: 8
Training loss: 1.9856879711151123
Validation loss: 2.1322124054034552

Epoch: 5| Step: 9
Training loss: 2.5298612117767334
Validation loss: 2.111679052313169

Epoch: 5| Step: 10
Training loss: 1.956486463546753
Validation loss: 2.097994009653727

Epoch: 5| Step: 11
Training loss: 2.775660991668701
Validation loss: 2.0970059434572854

Epoch: 70| Step: 0
Training loss: 2.17079496383667
Validation loss: 2.150508090853691

Epoch: 5| Step: 1
Training loss: 1.8415762186050415
Validation loss: 2.1549295534690223

Epoch: 5| Step: 2
Training loss: 2.061495065689087
Validation loss: 2.1668304155270257

Epoch: 5| Step: 3
Training loss: 2.241920232772827
Validation loss: 2.1459843665361404

Epoch: 5| Step: 4
Training loss: 1.7365583181381226
Validation loss: 2.0599568833907447

Epoch: 5| Step: 5
Training loss: 1.5950881242752075
Validation loss: 2.089533199866613

Epoch: 5| Step: 6
Training loss: 2.2634589672088623
Validation loss: 2.0588917980591455

Epoch: 5| Step: 7
Training loss: 2.0017895698547363
Validation loss: 2.0856781552235284

Epoch: 5| Step: 8
Training loss: 2.3250911235809326
Validation loss: 2.116961802045504

Epoch: 5| Step: 9
Training loss: 1.6378940343856812
Validation loss: 2.087240293622017

Epoch: 5| Step: 10
Training loss: 1.7770450115203857
Validation loss: 2.0911219169696174

Epoch: 5| Step: 11
Training loss: 2.083111047744751
Validation loss: 2.089290281136831

Epoch: 71| Step: 0
Training loss: 1.9487873315811157
Validation loss: 2.0619312127431235

Epoch: 5| Step: 1
Training loss: 1.8074419498443604
Validation loss: 2.093530813852946

Epoch: 5| Step: 2
Training loss: 2.2908074855804443
Validation loss: 2.1215470929940543

Epoch: 5| Step: 3
Training loss: 2.076559543609619
Validation loss: 2.0862253854672113

Epoch: 5| Step: 4
Training loss: 1.7797825336456299
Validation loss: 2.16607765853405

Epoch: 5| Step: 5
Training loss: 2.1149752140045166
Validation loss: 2.134936809539795

Epoch: 5| Step: 6
Training loss: 1.5226385593414307
Validation loss: 2.1051723857720694

Epoch: 5| Step: 7
Training loss: 2.1067614555358887
Validation loss: 2.127037559946378

Epoch: 5| Step: 8
Training loss: 1.32170832157135
Validation loss: 2.065518488486608

Epoch: 5| Step: 9
Training loss: 2.1910970211029053
Validation loss: 2.1088139762481055

Epoch: 5| Step: 10
Training loss: 1.9262714385986328
Validation loss: 2.068170373638471

Epoch: 5| Step: 11
Training loss: 1.5221165418624878
Validation loss: 2.0844919681549072

Epoch: 72| Step: 0
Training loss: 2.08273983001709
Validation loss: 2.111875201265017

Epoch: 5| Step: 1
Training loss: 2.4090394973754883
Validation loss: 2.079671939214071

Epoch: 5| Step: 2
Training loss: 1.8376251459121704
Validation loss: 2.1215690076351166

Epoch: 5| Step: 3
Training loss: 1.5373237133026123
Validation loss: 2.134936675429344

Epoch: 5| Step: 4
Training loss: 1.7752259969711304
Validation loss: 2.080781822403272

Epoch: 5| Step: 5
Training loss: 2.2264835834503174
Validation loss: 2.077080344160398

Epoch: 5| Step: 6
Training loss: 2.3120315074920654
Validation loss: 2.0807368457317352

Epoch: 5| Step: 7
Training loss: 2.0918681621551514
Validation loss: 2.066053415338198

Epoch: 5| Step: 8
Training loss: 2.030089855194092
Validation loss: 2.092463647325834

Epoch: 5| Step: 9
Training loss: 1.4627656936645508
Validation loss: 2.144157106677691

Epoch: 5| Step: 10
Training loss: 1.7521415948867798
Validation loss: 2.1301026393969855

Epoch: 5| Step: 11
Training loss: 1.1222472190856934
Validation loss: 2.101801797747612

Epoch: 73| Step: 0
Training loss: 2.2846245765686035
Validation loss: 2.0921340882778168

Epoch: 5| Step: 1
Training loss: 1.8006350994110107
Validation loss: 2.092937007546425

Epoch: 5| Step: 2
Training loss: 2.028777599334717
Validation loss: 2.177596777677536

Epoch: 5| Step: 3
Training loss: 1.7913494110107422
Validation loss: 2.1089121599992118

Epoch: 5| Step: 4
Training loss: 1.5814858675003052
Validation loss: 2.1437891026337943

Epoch: 5| Step: 5
Training loss: 1.6667327880859375
Validation loss: 2.078502058982849

Epoch: 5| Step: 6
Training loss: 1.5028867721557617
Validation loss: 2.076261267066002

Epoch: 5| Step: 7
Training loss: 2.747891902923584
Validation loss: 2.099764267603556

Epoch: 5| Step: 8
Training loss: 1.9737259149551392
Validation loss: 2.1171595056851706

Epoch: 5| Step: 9
Training loss: 2.1713032722473145
Validation loss: 2.1031642258167267

Epoch: 5| Step: 10
Training loss: 2.0557451248168945
Validation loss: 2.1120197474956512

Epoch: 5| Step: 11
Training loss: 1.2661761045455933
Validation loss: 2.113345513741175

Epoch: 74| Step: 0
Training loss: 1.4467681646347046
Validation loss: 2.102079465985298

Epoch: 5| Step: 1
Training loss: 1.3814036846160889
Validation loss: 2.0641598254442215

Epoch: 5| Step: 2
Training loss: 1.8200304508209229
Validation loss: 2.1031205356121063

Epoch: 5| Step: 3
Training loss: 1.571016550064087
Validation loss: 2.1418346563975015

Epoch: 5| Step: 4
Training loss: 2.4053187370300293
Validation loss: 2.004240329066912

Epoch: 5| Step: 5
Training loss: 1.8102810382843018
Validation loss: 2.054654354850451

Epoch: 5| Step: 6
Training loss: 1.8327534198760986
Validation loss: 2.078599601984024

Epoch: 5| Step: 7
Training loss: 2.403594493865967
Validation loss: 2.054142494996389

Epoch: 5| Step: 8
Training loss: 1.7594188451766968
Validation loss: 2.0300150513648987

Epoch: 5| Step: 9
Training loss: 2.3201262950897217
Validation loss: 2.0642441660165787

Epoch: 5| Step: 10
Training loss: 1.8230804204940796
Validation loss: 2.1264761686325073

Epoch: 5| Step: 11
Training loss: 3.500386953353882
Validation loss: 2.0840315222740173

Epoch: 75| Step: 0
Training loss: 1.884751319885254
Validation loss: 2.142072409391403

Epoch: 5| Step: 1
Training loss: 1.9278331995010376
Validation loss: 2.147309511899948

Epoch: 5| Step: 2
Training loss: 1.909043312072754
Validation loss: 2.115460455417633

Epoch: 5| Step: 3
Training loss: 1.8606199026107788
Validation loss: 2.048514078060786

Epoch: 5| Step: 4
Training loss: 2.8224356174468994
Validation loss: 2.1373054534196854

Epoch: 5| Step: 5
Training loss: 1.568083643913269
Validation loss: 2.0850525349378586

Epoch: 5| Step: 6
Training loss: 2.153465509414673
Validation loss: 2.0303797076145806

Epoch: 5| Step: 7
Training loss: 1.859522819519043
Validation loss: 2.1463519036769867

Epoch: 5| Step: 8
Training loss: 1.821958303451538
Validation loss: 2.0749643246332803

Epoch: 5| Step: 9
Training loss: 1.5797115564346313
Validation loss: 2.1173366804917655

Epoch: 5| Step: 10
Training loss: 1.9556900262832642
Validation loss: 2.0828556964794793

Epoch: 5| Step: 11
Training loss: 1.8157485723495483
Validation loss: 2.1485605339209237

Epoch: 76| Step: 0
Training loss: 2.031153678894043
Validation loss: 2.087020695209503

Epoch: 5| Step: 1
Training loss: 2.0939931869506836
Validation loss: 2.1061846067508063

Epoch: 5| Step: 2
Training loss: 1.6479597091674805
Validation loss: 2.1169656912485757

Epoch: 5| Step: 3
Training loss: 1.349543809890747
Validation loss: 2.122818519671758

Epoch: 5| Step: 4
Training loss: 1.4359228610992432
Validation loss: 2.1512425740559897

Epoch: 5| Step: 5
Training loss: 2.3779120445251465
Validation loss: 2.2137366086244583

Epoch: 5| Step: 6
Training loss: 2.6660473346710205
Validation loss: 2.176317428549131

Epoch: 5| Step: 7
Training loss: 2.191254138946533
Validation loss: 2.2696674466133118

Epoch: 5| Step: 8
Training loss: 1.5032711029052734
Validation loss: 2.2281031161546707

Epoch: 5| Step: 9
Training loss: 1.8433862924575806
Validation loss: 2.2677125483751297

Epoch: 5| Step: 10
Training loss: 2.2723774909973145
Validation loss: 2.214545542995135

Epoch: 5| Step: 11
Training loss: 2.277935743331909
Validation loss: 2.1454462110996246

Epoch: 77| Step: 0
Training loss: 2.0927300453186035
Validation loss: 2.2060299714406333

Epoch: 5| Step: 1
Training loss: 2.036329746246338
Validation loss: 2.1404167314370475

Epoch: 5| Step: 2
Training loss: 2.126616954803467
Validation loss: 2.15063214302063

Epoch: 5| Step: 3
Training loss: 1.8878917694091797
Validation loss: 2.117663989464442

Epoch: 5| Step: 4
Training loss: 1.9649417400360107
Validation loss: 2.0570319443941116

Epoch: 5| Step: 5
Training loss: 1.9766746759414673
Validation loss: 2.0530751645565033

Epoch: 5| Step: 6
Training loss: 1.6268272399902344
Validation loss: 2.05120387673378

Epoch: 5| Step: 7
Training loss: 2.1999874114990234
Validation loss: 2.2038329044977822

Epoch: 5| Step: 8
Training loss: 1.9814621210098267
Validation loss: 2.1100365618864694

Epoch: 5| Step: 9
Training loss: 2.2152698040008545
Validation loss: 2.0929375489552817

Epoch: 5| Step: 10
Training loss: 1.9571723937988281
Validation loss: 2.0184353987375894

Epoch: 5| Step: 11
Training loss: 0.8172473907470703
Validation loss: 2.110822374622027

Epoch: 78| Step: 0
Training loss: 1.2841109037399292
Validation loss: 2.057482068737348

Epoch: 5| Step: 1
Training loss: 1.7608439922332764
Validation loss: 2.0734922687212625

Epoch: 5| Step: 2
Training loss: 2.0935347080230713
Validation loss: 2.0630114575227103

Epoch: 5| Step: 3
Training loss: 1.4259116649627686
Validation loss: 2.1416441897551217

Epoch: 5| Step: 4
Training loss: 2.1539878845214844
Validation loss: 2.1001427421967187

Epoch: 5| Step: 5
Training loss: 1.5516138076782227
Validation loss: 2.0344916383425393

Epoch: 5| Step: 6
Training loss: 1.7104787826538086
Validation loss: 2.0713092188040414

Epoch: 5| Step: 7
Training loss: 1.7185777425765991
Validation loss: 2.0980934848388038

Epoch: 5| Step: 8
Training loss: 2.757467746734619
Validation loss: 2.116557757059733

Epoch: 5| Step: 9
Training loss: 1.5012366771697998
Validation loss: 2.143041431903839

Epoch: 5| Step: 10
Training loss: 2.651639461517334
Validation loss: 2.1119485944509506

Epoch: 5| Step: 11
Training loss: 1.314893364906311
Validation loss: 2.17155613998572

Epoch: 79| Step: 0
Training loss: 1.8101409673690796
Validation loss: 2.1532191783189774

Epoch: 5| Step: 1
Training loss: 1.8839412927627563
Validation loss: 2.046328142285347

Epoch: 5| Step: 2
Training loss: 2.1290693283081055
Validation loss: 2.1456005573272705

Epoch: 5| Step: 3
Training loss: 1.7758811712265015
Validation loss: 2.1747973958651223

Epoch: 5| Step: 4
Training loss: 1.7391712665557861
Validation loss: 2.16062863667806

Epoch: 5| Step: 5
Training loss: 1.5798149108886719
Validation loss: 2.1261234432458878

Epoch: 5| Step: 6
Training loss: 1.8414573669433594
Validation loss: 2.101120928923289

Epoch: 5| Step: 7
Training loss: 2.226370334625244
Validation loss: 2.16228386759758

Epoch: 5| Step: 8
Training loss: 1.7685673236846924
Validation loss: 2.195591444770495

Epoch: 5| Step: 9
Training loss: 2.5433945655822754
Validation loss: 2.0827448864777884

Epoch: 5| Step: 10
Training loss: 1.5918298959732056
Validation loss: 2.1029877116282782

Epoch: 5| Step: 11
Training loss: 1.5956653356552124
Validation loss: 2.0704913834730783

Epoch: 80| Step: 0
Training loss: 1.8136993646621704
Validation loss: 2.0963067362705865

Epoch: 5| Step: 1
Training loss: 1.5003974437713623
Validation loss: 2.1296206464370093

Epoch: 5| Step: 2
Training loss: 2.0423941612243652
Validation loss: 2.042516047755877

Epoch: 5| Step: 3
Training loss: 1.8702600002288818
Validation loss: 2.076602026820183

Epoch: 5| Step: 4
Training loss: 2.35544490814209
Validation loss: 1.933757205804189

Epoch: 5| Step: 5
Training loss: 2.5226502418518066
Validation loss: 2.0924302687247596

Epoch: 5| Step: 6
Training loss: 2.3508777618408203
Validation loss: 2.0941825856765113

Epoch: 5| Step: 7
Training loss: 1.9291969537734985
Validation loss: 2.10563916961352

Epoch: 5| Step: 8
Training loss: 1.9130884408950806
Validation loss: 2.0448929369449615

Epoch: 5| Step: 9
Training loss: 1.4372848272323608
Validation loss: 2.069945305585861

Epoch: 5| Step: 10
Training loss: 1.2911592721939087
Validation loss: 2.0146498332420983

Epoch: 5| Step: 11
Training loss: 3.486509084701538
Validation loss: 2.0787078638871512

Epoch: 81| Step: 0
Training loss: 1.9141685962677002
Validation loss: 2.1262886921564736

Epoch: 5| Step: 1
Training loss: 1.5973775386810303
Validation loss: 2.0984950810670853

Epoch: 5| Step: 2
Training loss: 1.393102765083313
Validation loss: 2.064568728208542

Epoch: 5| Step: 3
Training loss: 1.4482901096343994
Validation loss: 2.1313967208067575

Epoch: 5| Step: 4
Training loss: 1.8682377338409424
Validation loss: 2.2105488777160645

Epoch: 5| Step: 5
Training loss: 1.7881933450698853
Validation loss: 2.178597112496694

Epoch: 5| Step: 6
Training loss: 2.122636318206787
Validation loss: 2.0990885297457376

Epoch: 5| Step: 7
Training loss: 2.0785675048828125
Validation loss: 2.135182499885559

Epoch: 5| Step: 8
Training loss: 2.703680992126465
Validation loss: 2.051625063021978

Epoch: 5| Step: 9
Training loss: 1.9901052713394165
Validation loss: 2.0882684886455536

Epoch: 5| Step: 10
Training loss: 2.091826915740967
Validation loss: 2.1098787089188895

Epoch: 5| Step: 11
Training loss: 1.6295695304870605
Validation loss: 2.1416844725608826

Epoch: 82| Step: 0
Training loss: 1.6867471933364868
Validation loss: 2.061619386076927

Epoch: 5| Step: 1
Training loss: 2.091000556945801
Validation loss: 2.0424220661322274

Epoch: 5| Step: 2
Training loss: 2.021040439605713
Validation loss: 2.079659422238668

Epoch: 5| Step: 3
Training loss: 2.1653311252593994
Validation loss: 2.154780695835749

Epoch: 5| Step: 4
Training loss: 2.00272536277771
Validation loss: 2.0104904075463614

Epoch: 5| Step: 5
Training loss: 1.6999622583389282
Validation loss: 2.039460996786753

Epoch: 5| Step: 6
Training loss: 1.7821972370147705
Validation loss: 2.050397276878357

Epoch: 5| Step: 7
Training loss: 1.5411418676376343
Validation loss: 2.1122379153966904

Epoch: 5| Step: 8
Training loss: 2.1884989738464355
Validation loss: 2.086001838246981

Epoch: 5| Step: 9
Training loss: 1.8326148986816406
Validation loss: 2.164642701546351

Epoch: 5| Step: 10
Training loss: 1.6724395751953125
Validation loss: 2.090585341056188

Epoch: 5| Step: 11
Training loss: 1.7653305530548096
Validation loss: 2.0799652139345803

Epoch: 83| Step: 0
Training loss: 1.6907031536102295
Validation loss: 2.037852570414543

Epoch: 5| Step: 1
Training loss: 1.2971117496490479
Validation loss: 2.113142415881157

Epoch: 5| Step: 2
Training loss: 1.6285158395767212
Validation loss: 2.215974966684977

Epoch: 5| Step: 3
Training loss: 2.358715772628784
Validation loss: 2.170858234167099

Epoch: 5| Step: 4
Training loss: 1.8321834802627563
Validation loss: 2.251116911570231

Epoch: 5| Step: 5
Training loss: 2.541639804840088
Validation loss: 2.2287850926319757

Epoch: 5| Step: 6
Training loss: 1.889747977256775
Validation loss: 2.1286917328834534

Epoch: 5| Step: 7
Training loss: 1.9895340204238892
Validation loss: 2.1721825003623962

Epoch: 5| Step: 8
Training loss: 1.5569064617156982
Validation loss: 2.143295799692472

Epoch: 5| Step: 9
Training loss: 2.5510687828063965
Validation loss: 2.1422851781050363

Epoch: 5| Step: 10
Training loss: 2.1069376468658447
Validation loss: 2.074135129650434

Epoch: 5| Step: 11
Training loss: 0.9342932105064392
Validation loss: 2.154171655575434

Epoch: 84| Step: 0
Training loss: 2.1601338386535645
Validation loss: 2.1406593521436057

Epoch: 5| Step: 1
Training loss: 2.1206493377685547
Validation loss: 2.0961992939313254

Epoch: 5| Step: 2
Training loss: 1.8917415142059326
Validation loss: 2.1024526407321296

Epoch: 5| Step: 3
Training loss: 1.7415316104888916
Validation loss: 2.077589134375254

Epoch: 5| Step: 4
Training loss: 1.8088537454605103
Validation loss: 2.0143805841604867

Epoch: 5| Step: 5
Training loss: 1.6462364196777344
Validation loss: 2.0952234119176865

Epoch: 5| Step: 6
Training loss: 2.300854444503784
Validation loss: 2.0817642360925674

Epoch: 5| Step: 7
Training loss: 1.9134223461151123
Validation loss: 2.0664279560248056

Epoch: 5| Step: 8
Training loss: 1.2359917163848877
Validation loss: 2.047734792033831

Epoch: 5| Step: 9
Training loss: 2.1129348278045654
Validation loss: 2.161468431353569

Epoch: 5| Step: 10
Training loss: 1.637926459312439
Validation loss: 2.143237372239431

Epoch: 5| Step: 11
Training loss: 2.294995069503784
Validation loss: 2.1684141953786216

Epoch: 85| Step: 0
Training loss: 1.4356369972229004
Validation loss: 2.065732921163241

Epoch: 5| Step: 1
Training loss: 2.08073353767395
Validation loss: 2.051828756928444

Epoch: 5| Step: 2
Training loss: 2.003801107406616
Validation loss: 2.140189990401268

Epoch: 5| Step: 3
Training loss: 1.3969826698303223
Validation loss: 2.125816747546196

Epoch: 5| Step: 4
Training loss: 2.056239604949951
Validation loss: 2.080571010708809

Epoch: 5| Step: 5
Training loss: 1.9394416809082031
Validation loss: 2.069752166668574

Epoch: 5| Step: 6
Training loss: 1.8432468175888062
Validation loss: 2.154428561528524

Epoch: 5| Step: 7
Training loss: 2.0914244651794434
Validation loss: 2.0921809623638787

Epoch: 5| Step: 8
Training loss: 2.284925937652588
Validation loss: 2.0385810136795044

Epoch: 5| Step: 9
Training loss: 2.2186172008514404
Validation loss: 2.0638250758250556

Epoch: 5| Step: 10
Training loss: 1.2577736377716064
Validation loss: 2.1396822929382324

Epoch: 5| Step: 11
Training loss: 1.7161519527435303
Validation loss: 2.0631184180577598

Epoch: 86| Step: 0
Training loss: 1.9188225269317627
Validation loss: 2.1001220792531967

Epoch: 5| Step: 1
Training loss: 1.8451350927352905
Validation loss: 2.1281728545824685

Epoch: 5| Step: 2
Training loss: 1.9022279977798462
Validation loss: 2.1504202584425607

Epoch: 5| Step: 3
Training loss: 2.0527024269104004
Validation loss: 2.0502849916617074

Epoch: 5| Step: 4
Training loss: 2.293365716934204
Validation loss: 2.0508734981218972

Epoch: 5| Step: 5
Training loss: 1.4244298934936523
Validation loss: 2.089546412229538

Epoch: 5| Step: 6
Training loss: 2.0166079998016357
Validation loss: 2.015767311056455

Epoch: 5| Step: 7
Training loss: 1.809644341468811
Validation loss: 2.0833600958188376

Epoch: 5| Step: 8
Training loss: 1.9615272283554077
Validation loss: 2.015027478337288

Epoch: 5| Step: 9
Training loss: 2.1552255153656006
Validation loss: 2.103122999270757

Epoch: 5| Step: 10
Training loss: 1.5161854028701782
Validation loss: 2.0802775621414185

Epoch: 5| Step: 11
Training loss: 0.7779819369316101
Validation loss: 2.106081301967303

Epoch: 87| Step: 0
Training loss: 1.554992914199829
Validation loss: 2.1079197426637015

Epoch: 5| Step: 1
Training loss: 1.610253930091858
Validation loss: 2.21888267993927

Epoch: 5| Step: 2
Training loss: 1.7186189889907837
Validation loss: 2.17555163304011

Epoch: 5| Step: 3
Training loss: 2.340634822845459
Validation loss: 2.120919575293859

Epoch: 5| Step: 4
Training loss: 1.2367527484893799
Validation loss: 2.135097543398539

Epoch: 5| Step: 5
Training loss: 2.4799771308898926
Validation loss: 2.2411355525255203

Epoch: 5| Step: 6
Training loss: 2.480330467224121
Validation loss: 2.1806616882483163

Epoch: 5| Step: 7
Training loss: 2.6453566551208496
Validation loss: 2.1390626778205237

Epoch: 5| Step: 8
Training loss: 1.5339795351028442
Validation loss: 2.1713496297597885

Epoch: 5| Step: 9
Training loss: 1.827596664428711
Validation loss: 2.160073528687159

Epoch: 5| Step: 10
Training loss: 1.9824711084365845
Validation loss: 2.0526482363541922

Epoch: 5| Step: 11
Training loss: 1.4518910646438599
Validation loss: 2.1603069454431534

Epoch: 88| Step: 0
Training loss: 1.7016956806182861
Validation loss: 2.050423542658488

Epoch: 5| Step: 1
Training loss: 1.3818979263305664
Validation loss: 2.0888406733671823

Epoch: 5| Step: 2
Training loss: 1.942732572555542
Validation loss: 2.110875298579534

Epoch: 5| Step: 3
Training loss: 1.6286624670028687
Validation loss: 2.0664686361948648

Epoch: 5| Step: 4
Training loss: 2.1266448497772217
Validation loss: 2.0952444871266684

Epoch: 5| Step: 5
Training loss: 1.5342445373535156
Validation loss: 2.094544996817907

Epoch: 5| Step: 6
Training loss: 1.787757158279419
Validation loss: 2.07880732913812

Epoch: 5| Step: 7
Training loss: 2.6785173416137695
Validation loss: 2.06397674481074

Epoch: 5| Step: 8
Training loss: 2.299358367919922
Validation loss: 2.04570942123731

Epoch: 5| Step: 9
Training loss: 1.8578590154647827
Validation loss: 2.16854860385259

Epoch: 5| Step: 10
Training loss: 1.7618175745010376
Validation loss: 2.0751939515272775

Epoch: 5| Step: 11
Training loss: 1.1663144826889038
Validation loss: 2.1306773175795874

Epoch: 89| Step: 0
Training loss: 1.7402524948120117
Validation loss: 2.0468452076117196

Epoch: 5| Step: 1
Training loss: 1.9201072454452515
Validation loss: 2.092615028222402

Epoch: 5| Step: 2
Training loss: 2.4508039951324463
Validation loss: 2.059526334206263

Epoch: 5| Step: 3
Training loss: 1.6166484355926514
Validation loss: 2.0663716991742453

Epoch: 5| Step: 4
Training loss: 1.3962342739105225
Validation loss: 2.0813722064097724

Epoch: 5| Step: 5
Training loss: 2.0287201404571533
Validation loss: 2.103786210219065

Epoch: 5| Step: 6
Training loss: 1.872957468032837
Validation loss: 2.076976706584295

Epoch: 5| Step: 7
Training loss: 2.0345377922058105
Validation loss: 2.115843122204145

Epoch: 5| Step: 8
Training loss: 1.6480547189712524
Validation loss: 2.10373322168986

Epoch: 5| Step: 9
Training loss: 2.107314348220825
Validation loss: 2.0267129788796105

Epoch: 5| Step: 10
Training loss: 1.663447380065918
Validation loss: 2.101846069097519

Epoch: 5| Step: 11
Training loss: 1.353729248046875
Validation loss: 2.0605570574601493

Epoch: 90| Step: 0
Training loss: 1.764554738998413
Validation loss: 2.122290422519048

Epoch: 5| Step: 1
Training loss: 2.3525643348693848
Validation loss: 2.120366464058558

Epoch: 5| Step: 2
Training loss: 1.9303855895996094
Validation loss: 2.145725945631663

Epoch: 5| Step: 3
Training loss: 2.0133414268493652
Validation loss: 2.0673772543668747

Epoch: 5| Step: 4
Training loss: 2.056213855743408
Validation loss: 2.1611597587664924

Epoch: 5| Step: 5
Training loss: 1.9994170665740967
Validation loss: 2.1164954751729965

Epoch: 5| Step: 6
Training loss: 1.5452486276626587
Validation loss: 2.112903411189715

Epoch: 5| Step: 7
Training loss: 1.8493839502334595
Validation loss: 2.1274272054433823

Epoch: 5| Step: 8
Training loss: 2.066183567047119
Validation loss: 2.1844999392827353

Epoch: 5| Step: 9
Training loss: 1.2543728351593018
Validation loss: 2.131792818506559

Epoch: 5| Step: 10
Training loss: 1.623429298400879
Validation loss: 2.096849804123243

Epoch: 5| Step: 11
Training loss: 2.79783034324646
Validation loss: 2.143542463580767

Epoch: 91| Step: 0
Training loss: 1.5524426698684692
Validation loss: 2.1731510013341904

Epoch: 5| Step: 1
Training loss: 1.807185411453247
Validation loss: 2.1005196968714395

Epoch: 5| Step: 2
Training loss: 1.7898603677749634
Validation loss: 2.0893947382767997

Epoch: 5| Step: 3
Training loss: 1.7667019367218018
Validation loss: 2.1972212294737496

Epoch: 5| Step: 4
Training loss: 2.089726209640503
Validation loss: 2.010559380054474

Epoch: 5| Step: 5
Training loss: 1.7669750452041626
Validation loss: 2.1397261867920556

Epoch: 5| Step: 6
Training loss: 1.7718242406845093
Validation loss: 2.0945091197888055

Epoch: 5| Step: 7
Training loss: 1.513749361038208
Validation loss: 2.074369579553604

Epoch: 5| Step: 8
Training loss: 1.3728394508361816
Validation loss: 2.0807753751675286

Epoch: 5| Step: 9
Training loss: 2.0149848461151123
Validation loss: 2.130363409717878

Epoch: 5| Step: 10
Training loss: 2.9269587993621826
Validation loss: 2.1148636837800345

Epoch: 5| Step: 11
Training loss: 1.8536996841430664
Validation loss: 2.179764613509178

Epoch: 92| Step: 0
Training loss: 1.5717252492904663
Validation loss: 2.055738459030787

Epoch: 5| Step: 1
Training loss: 2.049074172973633
Validation loss: 2.1844662576913834

Epoch: 5| Step: 2
Training loss: 2.3897507190704346
Validation loss: 2.051846673091253

Epoch: 5| Step: 3
Training loss: 1.7651026248931885
Validation loss: 2.0379556665817895

Epoch: 5| Step: 4
Training loss: 1.9106477499008179
Validation loss: 2.0664155731598535

Epoch: 5| Step: 5
Training loss: 1.5651609897613525
Validation loss: 2.037474364042282

Epoch: 5| Step: 6
Training loss: 1.5406402349472046
Validation loss: 2.0733047227064767

Epoch: 5| Step: 7
Training loss: 2.27972412109375
Validation loss: 2.0798141409953437

Epoch: 5| Step: 8
Training loss: 1.4734485149383545
Validation loss: 2.0837771693865457

Epoch: 5| Step: 9
Training loss: 1.5780888795852661
Validation loss: 2.0865007738272348

Epoch: 5| Step: 10
Training loss: 2.012702465057373
Validation loss: 2.0590478579203286

Epoch: 5| Step: 11
Training loss: 2.810790538787842
Validation loss: 2.0385937889417014

Epoch: 93| Step: 0
Training loss: 1.799007773399353
Validation loss: 2.0808210968971252

Epoch: 5| Step: 1
Training loss: 1.8182401657104492
Validation loss: 2.0099693089723587

Epoch: 5| Step: 2
Training loss: 1.7900758981704712
Validation loss: 2.066961338122686

Epoch: 5| Step: 3
Training loss: 1.5851154327392578
Validation loss: 2.0530238449573517

Epoch: 5| Step: 4
Training loss: 2.007237672805786
Validation loss: 2.081517517566681

Epoch: 5| Step: 5
Training loss: 1.6769459247589111
Validation loss: 2.0849335392316184

Epoch: 5| Step: 6
Training loss: 2.6577930450439453
Validation loss: 2.046237329641978

Epoch: 5| Step: 7
Training loss: 2.066112756729126
Validation loss: 2.0532483557860055

Epoch: 5| Step: 8
Training loss: 1.5655699968338013
Validation loss: 2.1372812539339066

Epoch: 5| Step: 9
Training loss: 1.9704406261444092
Validation loss: 2.058041031161944

Epoch: 5| Step: 10
Training loss: 1.900525450706482
Validation loss: 2.0750589867432914

Epoch: 5| Step: 11
Training loss: 1.0579031705856323
Validation loss: 2.103023479382197

Epoch: 94| Step: 0
Training loss: 1.2403013706207275
Validation loss: 2.139382695158323

Epoch: 5| Step: 1
Training loss: 1.9979877471923828
Validation loss: 2.1011451383431754

Epoch: 5| Step: 2
Training loss: 2.080207586288452
Validation loss: 2.145228703816732

Epoch: 5| Step: 3
Training loss: 1.6593046188354492
Validation loss: 2.129382918278376

Epoch: 5| Step: 4
Training loss: 2.5412731170654297
Validation loss: 2.1819945871829987

Epoch: 5| Step: 5
Training loss: 1.9342107772827148
Validation loss: 2.1030165602763495

Epoch: 5| Step: 6
Training loss: 2.158475399017334
Validation loss: 2.1696482449769974

Epoch: 5| Step: 7
Training loss: 1.456512451171875
Validation loss: 2.0830120891332626

Epoch: 5| Step: 8
Training loss: 1.6554540395736694
Validation loss: 2.1428066343069077

Epoch: 5| Step: 9
Training loss: 2.1301429271698
Validation loss: 1.9991249839464824

Epoch: 5| Step: 10
Training loss: 1.5950957536697388
Validation loss: 1.9752247283856075

Epoch: 5| Step: 11
Training loss: 2.873596668243408
Validation loss: 2.139268606901169

Epoch: 95| Step: 0
Training loss: 1.9813740253448486
Validation loss: 2.1224079926808677

Epoch: 5| Step: 1
Training loss: 1.6388347148895264
Validation loss: 2.108372315764427

Epoch: 5| Step: 2
Training loss: 2.2217321395874023
Validation loss: 2.133609155813853

Epoch: 5| Step: 3
Training loss: 1.959395170211792
Validation loss: 2.139507015546163

Epoch: 5| Step: 4
Training loss: 1.7200260162353516
Validation loss: 2.16641973455747

Epoch: 5| Step: 5
Training loss: 1.6270420551300049
Validation loss: 2.1448833296696344

Epoch: 5| Step: 6
Training loss: 1.9784882068634033
Validation loss: 2.170332377155622

Epoch: 5| Step: 7
Training loss: 1.700362205505371
Validation loss: 2.0852225720882416

Epoch: 5| Step: 8
Training loss: 1.988918662071228
Validation loss: 2.145135392745336

Epoch: 5| Step: 9
Training loss: 1.9496879577636719
Validation loss: 2.119280288616816

Epoch: 5| Step: 10
Training loss: 1.9348186254501343
Validation loss: 2.0853674560785294

Epoch: 5| Step: 11
Training loss: 2.210824966430664
Validation loss: 2.1088752349217734

Epoch: 96| Step: 0
Training loss: 2.1744296550750732
Validation loss: 2.126595323284467

Epoch: 5| Step: 1
Training loss: 1.8750019073486328
Validation loss: 2.159824480613073

Epoch: 5| Step: 2
Training loss: 1.8935219049453735
Validation loss: 2.1474561939636865

Epoch: 5| Step: 3
Training loss: 1.660576581954956
Validation loss: 2.1163208285967507

Epoch: 5| Step: 4
Training loss: 2.1970770359039307
Validation loss: 2.1140330086151757

Epoch: 5| Step: 5
Training loss: 1.8767246007919312
Validation loss: 2.1007847636938095

Epoch: 5| Step: 6
Training loss: 1.5360677242279053
Validation loss: 2.1742845426003137

Epoch: 5| Step: 7
Training loss: 1.6773866415023804
Validation loss: 2.165061354637146

Epoch: 5| Step: 8
Training loss: 1.061632752418518
Validation loss: 2.1174652675787606

Epoch: 5| Step: 9
Training loss: 1.7483526468276978
Validation loss: 2.1289633214473724

Epoch: 5| Step: 10
Training loss: 2.4031176567077637
Validation loss: 2.033629894256592

Epoch: 5| Step: 11
Training loss: 2.5174217224121094
Validation loss: 1.9748203754425049

Epoch: 97| Step: 0
Training loss: 1.7820850610733032
Validation loss: 2.092777892947197

Epoch: 5| Step: 1
Training loss: 2.0183990001678467
Validation loss: 2.1012704223394394

Epoch: 5| Step: 2
Training loss: 1.4385572671890259
Validation loss: 2.055288260181745

Epoch: 5| Step: 3
Training loss: 1.7558071613311768
Validation loss: 2.0843639820814133

Epoch: 5| Step: 4
Training loss: 1.4810247421264648
Validation loss: 2.0904064575831094

Epoch: 5| Step: 5
Training loss: 1.4903383255004883
Validation loss: 2.0581180353959403

Epoch: 5| Step: 6
Training loss: 2.3470261096954346
Validation loss: 2.081448475519816

Epoch: 5| Step: 7
Training loss: 1.522099494934082
Validation loss: 2.0202504048744836

Epoch: 5| Step: 8
Training loss: 2.0477280616760254
Validation loss: 2.091854323943456

Epoch: 5| Step: 9
Training loss: 2.698026418685913
Validation loss: 2.132033516963323

Epoch: 5| Step: 10
Training loss: 1.7477846145629883
Validation loss: 2.074253390232722

Epoch: 5| Step: 11
Training loss: 4.039660453796387
Validation loss: 2.05250217517217

Epoch: 98| Step: 0
Training loss: 2.1478090286254883
Validation loss: 2.1658716847499213

Epoch: 5| Step: 1
Training loss: 1.869733214378357
Validation loss: 2.1064676543076835

Epoch: 5| Step: 2
Training loss: 1.7684240341186523
Validation loss: 2.096617420514425

Epoch: 5| Step: 3
Training loss: 1.952042818069458
Validation loss: 2.108715146780014

Epoch: 5| Step: 4
Training loss: 1.8201091289520264
Validation loss: 2.045532912015915

Epoch: 5| Step: 5
Training loss: 1.7216962575912476
Validation loss: 2.1148474415143332

Epoch: 5| Step: 6
Training loss: 2.0137104988098145
Validation loss: 2.0257408122221627

Epoch: 5| Step: 7
Training loss: 1.8377456665039062
Validation loss: 2.0393202006816864

Epoch: 5| Step: 8
Training loss: 1.5283915996551514
Validation loss: 2.1107578724622726

Epoch: 5| Step: 9
Training loss: 2.115269184112549
Validation loss: 2.1023318767547607

Epoch: 5| Step: 10
Training loss: 1.8609330654144287
Validation loss: 2.0830810417731604

Epoch: 5| Step: 11
Training loss: 0.9675465226173401
Validation loss: 2.0692154318094254

Epoch: 99| Step: 0
Training loss: 1.3953704833984375
Validation loss: 2.0745511005322137

Epoch: 5| Step: 1
Training loss: 1.49696946144104
Validation loss: 2.0111673126618066

Epoch: 5| Step: 2
Training loss: 1.6187063455581665
Validation loss: 2.1000107328097024

Epoch: 5| Step: 3
Training loss: 1.461105227470398
Validation loss: 2.0496907234191895

Epoch: 5| Step: 4
Training loss: 1.759819746017456
Validation loss: 2.162548234065374

Epoch: 5| Step: 5
Training loss: 1.6641069650650024
Validation loss: 2.1511146326859794

Epoch: 5| Step: 6
Training loss: 2.216616153717041
Validation loss: 2.1417869329452515

Epoch: 5| Step: 7
Training loss: 2.0430798530578613
Validation loss: 2.1511063128709793

Epoch: 5| Step: 8
Training loss: 1.761443853378296
Validation loss: 2.109385699033737

Epoch: 5| Step: 9
Training loss: 2.265326499938965
Validation loss: 2.1007278164227805

Epoch: 5| Step: 10
Training loss: 2.1612937450408936
Validation loss: 2.072595546642939

Epoch: 5| Step: 11
Training loss: 1.0740301609039307
Validation loss: 2.093752453724543

Epoch: 100| Step: 0
Training loss: 1.711019515991211
Validation loss: 2.109609067440033

Epoch: 5| Step: 1
Training loss: 2.417786121368408
Validation loss: 2.104632024963697

Epoch: 5| Step: 2
Training loss: 1.5019357204437256
Validation loss: 2.0434138427178064

Epoch: 5| Step: 3
Training loss: 1.8829600811004639
Validation loss: 2.109004477659861

Epoch: 5| Step: 4
Training loss: 2.1083133220672607
Validation loss: 2.123957316080729

Epoch: 5| Step: 5
Training loss: 1.8286018371582031
Validation loss: 2.081170822183291

Epoch: 5| Step: 6
Training loss: 1.8194020986557007
Validation loss: 2.0633531510829926

Epoch: 5| Step: 7
Training loss: 1.9334688186645508
Validation loss: 2.0968788464864097

Epoch: 5| Step: 8
Training loss: 1.712567687034607
Validation loss: 2.1119621296723685

Epoch: 5| Step: 9
Training loss: 2.1253695487976074
Validation loss: 2.077338606119156

Epoch: 5| Step: 10
Training loss: 1.928957223892212
Validation loss: 2.1093525936206183

Epoch: 5| Step: 11
Training loss: 1.6464037895202637
Validation loss: 2.1209424634774527

Epoch: 101| Step: 0
Training loss: 1.3842216730117798
Validation loss: 2.0623916486899057

Epoch: 5| Step: 1
Training loss: 2.063728094100952
Validation loss: 2.134832873940468

Epoch: 5| Step: 2
Training loss: 2.0120012760162354
Validation loss: 2.1883416374524436

Epoch: 5| Step: 3
Training loss: 1.3728591203689575
Validation loss: 2.0608118226130805

Epoch: 5| Step: 4
Training loss: 1.8684356212615967
Validation loss: 2.104136069615682

Epoch: 5| Step: 5
Training loss: 1.701479196548462
Validation loss: 2.161262035369873

Epoch: 5| Step: 6
Training loss: 1.9838460683822632
Validation loss: 2.1769968221584954

Epoch: 5| Step: 7
Training loss: 1.9938781261444092
Validation loss: 2.147581328948339

Epoch: 5| Step: 8
Training loss: 1.7692193984985352
Validation loss: 2.184083253145218

Epoch: 5| Step: 9
Training loss: 2.109457492828369
Validation loss: 2.1907401084899902

Epoch: 5| Step: 10
Training loss: 2.099980354309082
Validation loss: 2.1124197840690613

Epoch: 5| Step: 11
Training loss: 2.077366352081299
Validation loss: 2.1791381488243737

Epoch: 102| Step: 0
Training loss: 1.9006099700927734
Validation loss: 2.178536146879196

Epoch: 5| Step: 1
Training loss: 2.2866158485412598
Validation loss: 2.1519790589809418

Epoch: 5| Step: 2
Training loss: 2.0611746311187744
Validation loss: 2.099814683198929

Epoch: 5| Step: 3
Training loss: 1.700313925743103
Validation loss: 2.115603749950727

Epoch: 5| Step: 4
Training loss: 1.8089821338653564
Validation loss: 2.0915366113185883

Epoch: 5| Step: 5
Training loss: 1.707373857498169
Validation loss: 2.050863429903984

Epoch: 5| Step: 6
Training loss: 1.8442039489746094
Validation loss: 2.088056201736132

Epoch: 5| Step: 7
Training loss: 1.483410358428955
Validation loss: 2.0382990588744483

Epoch: 5| Step: 8
Training loss: 2.055471897125244
Validation loss: 2.088387961188952

Epoch: 5| Step: 9
Training loss: 1.8472248315811157
Validation loss: 2.090505376458168

Epoch: 5| Step: 10
Training loss: 1.3692338466644287
Validation loss: 2.0469699005285897

Epoch: 5| Step: 11
Training loss: 1.5554360151290894
Validation loss: 1.9918246070543926

Epoch: 103| Step: 0
Training loss: 1.7738029956817627
Validation loss: 2.020723377664884

Epoch: 5| Step: 1
Training loss: 1.5424989461898804
Validation loss: 2.040233006079992

Epoch: 5| Step: 2
Training loss: 2.7780232429504395
Validation loss: 2.117422958215078

Epoch: 5| Step: 3
Training loss: 1.2230427265167236
Validation loss: 2.1197220782438913

Epoch: 5| Step: 4
Training loss: 1.9268985986709595
Validation loss: 2.1320366809765496

Epoch: 5| Step: 5
Training loss: 1.9288173913955688
Validation loss: 2.0589089741309485

Epoch: 5| Step: 6
Training loss: 2.133049488067627
Validation loss: 2.1361375004053116

Epoch: 5| Step: 7
Training loss: 1.734291672706604
Validation loss: 2.0992704232533774

Epoch: 5| Step: 8
Training loss: 1.6775554418563843
Validation loss: 2.1033590883016586

Epoch: 5| Step: 9
Training loss: 1.3103097677230835
Validation loss: 2.1075458327929177

Epoch: 5| Step: 10
Training loss: 2.0611562728881836
Validation loss: 2.084072530269623

Epoch: 5| Step: 11
Training loss: 1.465469241142273
Validation loss: 2.03510690232118

Epoch: 104| Step: 0
Training loss: 2.1775574684143066
Validation loss: 2.079158663749695

Epoch: 5| Step: 1
Training loss: 1.8184658288955688
Validation loss: 2.0067588289578757

Epoch: 5| Step: 2
Training loss: 1.5831210613250732
Validation loss: 2.0393047581116357

Epoch: 5| Step: 3
Training loss: 1.979886770248413
Validation loss: 2.104961777726809

Epoch: 5| Step: 4
Training loss: 2.2589783668518066
Validation loss: 2.1123356918493905

Epoch: 5| Step: 5
Training loss: 1.6231825351715088
Validation loss: 2.074699744582176

Epoch: 5| Step: 6
Training loss: 1.5150073766708374
Validation loss: 2.1034648766120276

Epoch: 5| Step: 7
Training loss: 2.0531864166259766
Validation loss: 2.164717892805735

Epoch: 5| Step: 8
Training loss: 1.9438976049423218
Validation loss: 2.1087483763694763

Epoch: 5| Step: 9
Training loss: 1.837860107421875
Validation loss: 2.03256427248319

Epoch: 5| Step: 10
Training loss: 1.7748419046401978
Validation loss: 2.0551355431477227

Epoch: 5| Step: 11
Training loss: 1.5354903936386108
Validation loss: 2.1917743335167565

Epoch: 105| Step: 0
Training loss: 2.208801746368408
Validation loss: 2.1064305702845254

Epoch: 5| Step: 1
Training loss: 1.775123953819275
Validation loss: 2.0098334650198617

Epoch: 5| Step: 2
Training loss: 2.085075616836548
Validation loss: 2.102757453918457

Epoch: 5| Step: 3
Training loss: 1.3716641664505005
Validation loss: 2.137356619040171

Epoch: 5| Step: 4
Training loss: 2.1847095489501953
Validation loss: 2.109100808699926

Epoch: 5| Step: 5
Training loss: 1.763475775718689
Validation loss: 2.054370880126953

Epoch: 5| Step: 6
Training loss: 2.1167755126953125
Validation loss: 2.1357673505942025

Epoch: 5| Step: 7
Training loss: 1.4904345273971558
Validation loss: 2.125138521194458

Epoch: 5| Step: 8
Training loss: 1.4934237003326416
Validation loss: 2.108006556828817

Epoch: 5| Step: 9
Training loss: 2.0133681297302246
Validation loss: 2.0846419980128608

Epoch: 5| Step: 10
Training loss: 1.3159186840057373
Validation loss: 2.166751811901728

Epoch: 5| Step: 11
Training loss: 2.06158709526062
Validation loss: 2.1683722883462906

Epoch: 106| Step: 0
Training loss: 1.8442680835723877
Validation loss: 2.118974188963572

Epoch: 5| Step: 1
Training loss: 1.9086923599243164
Validation loss: 2.064361264308294

Epoch: 5| Step: 2
Training loss: 2.256679058074951
Validation loss: 2.1104971915483475

Epoch: 5| Step: 3
Training loss: 1.94146728515625
Validation loss: 2.063330719868342

Epoch: 5| Step: 4
Training loss: 1.6212279796600342
Validation loss: 2.0788542528947196

Epoch: 5| Step: 5
Training loss: 0.9797834157943726
Validation loss: 2.026307870944341

Epoch: 5| Step: 6
Training loss: 1.8734279870986938
Validation loss: 2.0412085155646005

Epoch: 5| Step: 7
Training loss: 2.1701693534851074
Validation loss: 2.1376229226589203

Epoch: 5| Step: 8
Training loss: 2.581204652786255
Validation loss: 2.0776642858982086

Epoch: 5| Step: 9
Training loss: 1.4843075275421143
Validation loss: 2.081127554178238

Epoch: 5| Step: 10
Training loss: 1.6604297161102295
Validation loss: 2.154639517267545

Epoch: 5| Step: 11
Training loss: 1.0668503046035767
Validation loss: 2.1122467120488486

Epoch: 107| Step: 0
Training loss: 1.873353362083435
Validation loss: 2.0509001264969506

Epoch: 5| Step: 1
Training loss: 2.5640861988067627
Validation loss: 2.0370660622914634

Epoch: 5| Step: 2
Training loss: 1.2774229049682617
Validation loss: 2.0929971983035407

Epoch: 5| Step: 3
Training loss: 2.0775632858276367
Validation loss: 2.103484441836675

Epoch: 5| Step: 4
Training loss: 2.072218894958496
Validation loss: 2.1179328858852386

Epoch: 5| Step: 5
Training loss: 1.3465015888214111
Validation loss: 2.047199070453644

Epoch: 5| Step: 6
Training loss: 1.6707477569580078
Validation loss: 2.0414892037709556

Epoch: 5| Step: 7
Training loss: 1.92983078956604
Validation loss: 2.018344650665919

Epoch: 5| Step: 8
Training loss: 1.6870445013046265
Validation loss: 2.0462489326794944

Epoch: 5| Step: 9
Training loss: 1.8755251169204712
Validation loss: 2.0894441505273185

Epoch: 5| Step: 10
Training loss: 1.8958766460418701
Validation loss: 2.093756486972173

Epoch: 5| Step: 11
Training loss: 0.899539589881897
Validation loss: 2.042588765422503

Epoch: 108| Step: 0
Training loss: 1.8083089590072632
Validation loss: 2.011040469010671

Epoch: 5| Step: 1
Training loss: 1.276300072669983
Validation loss: 2.126499970753988

Epoch: 5| Step: 2
Training loss: 2.0529332160949707
Validation loss: 2.1887850016355515

Epoch: 5| Step: 3
Training loss: 2.2290024757385254
Validation loss: 2.070111334323883

Epoch: 5| Step: 4
Training loss: 1.5538065433502197
Validation loss: 2.126526196797689

Epoch: 5| Step: 5
Training loss: 1.9304864406585693
Validation loss: 2.1894929806391397

Epoch: 5| Step: 6
Training loss: 2.2082200050354004
Validation loss: 2.1036485532919564

Epoch: 5| Step: 7
Training loss: 1.8316195011138916
Validation loss: 2.2232790489991507

Epoch: 5| Step: 8
Training loss: 1.569029450416565
Validation loss: 2.081335117419561

Epoch: 5| Step: 9
Training loss: 1.6349414587020874
Validation loss: 2.1442490418752036

Epoch: 5| Step: 10
Training loss: 1.8070096969604492
Validation loss: 2.1388841470082602

Epoch: 5| Step: 11
Training loss: 1.6891602277755737
Validation loss: 2.0966168890396752

Epoch: 109| Step: 0
Training loss: 1.9894065856933594
Validation loss: 2.054655080040296

Epoch: 5| Step: 1
Training loss: 2.0832934379577637
Validation loss: 2.083012501398722

Epoch: 5| Step: 2
Training loss: 2.141788959503174
Validation loss: 2.085268944501877

Epoch: 5| Step: 3
Training loss: 1.59233558177948
Validation loss: 2.047483821709951

Epoch: 5| Step: 4
Training loss: 2.2605319023132324
Validation loss: 2.0586948891480765

Epoch: 5| Step: 5
Training loss: 1.7915408611297607
Validation loss: 2.10658723115921

Epoch: 5| Step: 6
Training loss: 1.5961291790008545
Validation loss: 2.0340338548024497

Epoch: 5| Step: 7
Training loss: 1.688137412071228
Validation loss: 2.0621247440576553

Epoch: 5| Step: 8
Training loss: 1.6936546564102173
Validation loss: 2.05486898124218

Epoch: 5| Step: 9
Training loss: 1.9474319219589233
Validation loss: 2.1244070529937744

Epoch: 5| Step: 10
Training loss: 1.6924679279327393
Validation loss: 2.0974067946275077

Epoch: 5| Step: 11
Training loss: 1.6665641069412231
Validation loss: 2.087608739733696

Epoch: 110| Step: 0
Training loss: 2.013890266418457
Validation loss: 2.0374643752972283

Epoch: 5| Step: 1
Training loss: 1.6589596271514893
Validation loss: 2.153495877981186

Epoch: 5| Step: 2
Training loss: 1.651209831237793
Validation loss: 2.1476505398750305

Epoch: 5| Step: 3
Training loss: 1.591693639755249
Validation loss: 2.142318770289421

Epoch: 5| Step: 4
Training loss: 1.6327476501464844
Validation loss: 2.1262374222278595

Epoch: 5| Step: 5
Training loss: 1.270771861076355
Validation loss: 2.0966674337784448

Epoch: 5| Step: 6
Training loss: 1.7998195886611938
Validation loss: 2.129678855339686

Epoch: 5| Step: 7
Training loss: 1.7848526239395142
Validation loss: 2.136511887113253

Epoch: 5| Step: 8
Training loss: 2.674037456512451
Validation loss: 2.066074550151825

Epoch: 5| Step: 9
Training loss: 1.3173898458480835
Validation loss: 2.1024410128593445

Epoch: 5| Step: 10
Training loss: 2.230677843093872
Validation loss: 2.1637950042883554

Epoch: 5| Step: 11
Training loss: 1.655274510383606
Validation loss: 2.0739566683769226

Epoch: 111| Step: 0
Training loss: 1.571882963180542
Validation loss: 2.0847510546445847

Epoch: 5| Step: 1
Training loss: 1.7801662683486938
Validation loss: 2.0769225607315698

Epoch: 5| Step: 2
Training loss: 1.1167888641357422
Validation loss: 2.0807913492123284

Epoch: 5| Step: 3
Training loss: 2.0781314373016357
Validation loss: 2.1248974800109863

Epoch: 5| Step: 4
Training loss: 1.4061434268951416
Validation loss: 2.104166090488434

Epoch: 5| Step: 5
Training loss: 2.0197384357452393
Validation loss: 2.009231040875117

Epoch: 5| Step: 6
Training loss: 1.4881254434585571
Validation loss: 2.10790978372097

Epoch: 5| Step: 7
Training loss: 1.894132375717163
Validation loss: 2.1367844541867576

Epoch: 5| Step: 8
Training loss: 1.5193458795547485
Validation loss: 2.1737843602895737

Epoch: 5| Step: 9
Training loss: 2.45090913772583
Validation loss: 2.0923153509696326

Epoch: 5| Step: 10
Training loss: 2.333216428756714
Validation loss: 2.179510553677877

Epoch: 5| Step: 11
Training loss: 3.0665674209594727
Validation loss: 2.1596456170082092

Epoch: 112| Step: 0
Training loss: 1.9122291803359985
Validation loss: 2.1341364880402884

Epoch: 5| Step: 1
Training loss: 1.9094762802124023
Validation loss: 2.1329613427321115

Epoch: 5| Step: 2
Training loss: 1.5957300662994385
Validation loss: 2.170492668946584

Epoch: 5| Step: 3
Training loss: 2.134880542755127
Validation loss: 2.0798912197351456

Epoch: 5| Step: 4
Training loss: 1.8586273193359375
Validation loss: 2.0798286497592926

Epoch: 5| Step: 5
Training loss: 2.042719841003418
Validation loss: 2.0811764548222222

Epoch: 5| Step: 6
Training loss: 2.1360507011413574
Validation loss: 2.1546880304813385

Epoch: 5| Step: 7
Training loss: 2.306272268295288
Validation loss: 2.148987203836441

Epoch: 5| Step: 8
Training loss: 1.2615392208099365
Validation loss: 2.09746652841568

Epoch: 5| Step: 9
Training loss: 1.5796167850494385
Validation loss: 2.072050392627716

Epoch: 5| Step: 10
Training loss: 1.5797579288482666
Validation loss: 2.115173821647962

Epoch: 5| Step: 11
Training loss: 1.6887682676315308
Validation loss: 2.0412966211636863

Epoch: 113| Step: 0
Training loss: 1.5414860248565674
Validation loss: 2.1527299682299295

Epoch: 5| Step: 1
Training loss: 1.385596513748169
Validation loss: 2.082120031118393

Epoch: 5| Step: 2
Training loss: 1.6516773700714111
Validation loss: 2.1021845688422522

Epoch: 5| Step: 3
Training loss: 2.4087135791778564
Validation loss: 2.0342339177926383

Epoch: 5| Step: 4
Training loss: 2.159637212753296
Validation loss: 2.0386697749296823

Epoch: 5| Step: 5
Training loss: 1.5142465829849243
Validation loss: 2.0909827947616577

Epoch: 5| Step: 6
Training loss: 1.9825630187988281
Validation loss: 2.0623753368854523

Epoch: 5| Step: 7
Training loss: 1.7869174480438232
Validation loss: 2.070619667569796

Epoch: 5| Step: 8
Training loss: 1.6795822381973267
Validation loss: 2.129910329977671

Epoch: 5| Step: 9
Training loss: 1.985190749168396
Validation loss: 2.093552460273107

Epoch: 5| Step: 10
Training loss: 1.6289949417114258
Validation loss: 2.029287805159887

Epoch: 5| Step: 11
Training loss: 1.3934547901153564
Validation loss: 2.024775301416715

Epoch: 114| Step: 0
Training loss: 2.0227935314178467
Validation loss: 2.091744214296341

Epoch: 5| Step: 1
Training loss: 1.4291393756866455
Validation loss: 2.158759186665217

Epoch: 5| Step: 2
Training loss: 1.798474907875061
Validation loss: 2.1527178337176642

Epoch: 5| Step: 3
Training loss: 1.8367633819580078
Validation loss: 2.226560026407242

Epoch: 5| Step: 4
Training loss: 1.8364448547363281
Validation loss: 2.236470560232798

Epoch: 5| Step: 5
Training loss: 2.1720590591430664
Validation loss: 2.2596774846315384

Epoch: 5| Step: 6
Training loss: 1.4110137224197388
Validation loss: 2.248334586620331

Epoch: 5| Step: 7
Training loss: 1.3055311441421509
Validation loss: 2.2359183728694916

Epoch: 5| Step: 8
Training loss: 2.829672336578369
Validation loss: 2.218701849381129

Epoch: 5| Step: 9
Training loss: 1.9046781063079834
Validation loss: 2.2192447781562805

Epoch: 5| Step: 10
Training loss: 1.8586076498031616
Validation loss: 2.166973094145457

Epoch: 5| Step: 11
Training loss: 2.261843681335449
Validation loss: 2.0785782734553018

Epoch: 115| Step: 0
Training loss: 1.2547309398651123
Validation loss: 2.115757723649343

Epoch: 5| Step: 1
Training loss: 2.3552181720733643
Validation loss: 2.101146494348844

Epoch: 5| Step: 2
Training loss: 1.42205810546875
Validation loss: 2.0296482046445212

Epoch: 5| Step: 3
Training loss: 1.9943230152130127
Validation loss: 2.055863067507744

Epoch: 5| Step: 4
Training loss: 1.7337223291397095
Validation loss: 2.0525039583444595

Epoch: 5| Step: 5
Training loss: 1.2868835926055908
Validation loss: 2.0750341713428497

Epoch: 5| Step: 6
Training loss: 1.5063419342041016
Validation loss: 2.056383873025576

Epoch: 5| Step: 7
Training loss: 2.3716349601745605
Validation loss: 2.0659745236237845

Epoch: 5| Step: 8
Training loss: 2.4161694049835205
Validation loss: 2.1390384385983148

Epoch: 5| Step: 9
Training loss: 1.8603461980819702
Validation loss: 2.1428219228982925

Epoch: 5| Step: 10
Training loss: 1.8020493984222412
Validation loss: 2.0723094989856086

Epoch: 5| Step: 11
Training loss: 2.273731231689453
Validation loss: 2.0047176629304886

Epoch: 116| Step: 0
Training loss: 1.7151451110839844
Validation loss: 2.1058309376239777

Epoch: 5| Step: 1
Training loss: 2.1538636684417725
Validation loss: 2.1234932392835617

Epoch: 5| Step: 2
Training loss: 1.0860174894332886
Validation loss: 2.1297601014375687

Epoch: 5| Step: 3
Training loss: 1.6502692699432373
Validation loss: 2.1367609898249307

Epoch: 5| Step: 4
Training loss: 1.9296114444732666
Validation loss: 2.133146435022354

Epoch: 5| Step: 5
Training loss: 2.1652472019195557
Validation loss: 2.0966222087542215

Epoch: 5| Step: 6
Training loss: 2.223724603652954
Validation loss: 2.1425867130359015

Epoch: 5| Step: 7
Training loss: 1.6090492010116577
Validation loss: 2.1054896215597787

Epoch: 5| Step: 8
Training loss: 2.1982314586639404
Validation loss: 2.1309325248003006

Epoch: 5| Step: 9
Training loss: 1.7482115030288696
Validation loss: 2.125270406405131

Epoch: 5| Step: 10
Training loss: 1.7337995767593384
Validation loss: 2.068953757484754

Epoch: 5| Step: 11
Training loss: 2.0372657775878906
Validation loss: 2.1249598364035287

Epoch: 117| Step: 0
Training loss: 1.4832682609558105
Validation loss: 2.0172795355319977

Epoch: 5| Step: 1
Training loss: 1.5464770793914795
Validation loss: 2.013553356130918

Epoch: 5| Step: 2
Training loss: 1.9835249185562134
Validation loss: 2.1194335967302322

Epoch: 5| Step: 3
Training loss: 1.6742963790893555
Validation loss: 2.101335808634758

Epoch: 5| Step: 4
Training loss: 1.7312402725219727
Validation loss: 2.097159375747045

Epoch: 5| Step: 5
Training loss: 1.8120990991592407
Validation loss: 2.051859507958094

Epoch: 5| Step: 6
Training loss: 2.1369473934173584
Validation loss: 2.034821957349777

Epoch: 5| Step: 7
Training loss: 1.3485215902328491
Validation loss: 2.058674226204554

Epoch: 5| Step: 8
Training loss: 1.8003648519515991
Validation loss: 2.0494607985019684

Epoch: 5| Step: 9
Training loss: 2.120731830596924
Validation loss: 2.1047227134307227

Epoch: 5| Step: 10
Training loss: 2.2911429405212402
Validation loss: 2.0821646749973297

Epoch: 5| Step: 11
Training loss: 2.4047927856445312
Validation loss: 2.1044385731220245

Epoch: 118| Step: 0
Training loss: 2.0104854106903076
Validation loss: 2.0366700142621994

Epoch: 5| Step: 1
Training loss: 1.9349510669708252
Validation loss: 2.0889851450920105

Epoch: 5| Step: 2
Training loss: 1.8457515239715576
Validation loss: 2.1128549774487815

Epoch: 5| Step: 3
Training loss: 2.077960968017578
Validation loss: 2.0685694168011346

Epoch: 5| Step: 4
Training loss: 1.6773799657821655
Validation loss: 2.0579907248417535

Epoch: 5| Step: 5
Training loss: 1.5849732160568237
Validation loss: 2.073219135403633

Epoch: 5| Step: 6
Training loss: 1.5896799564361572
Validation loss: 2.048909733692805

Epoch: 5| Step: 7
Training loss: 1.068288803100586
Validation loss: 2.119237020611763

Epoch: 5| Step: 8
Training loss: 1.8340946435928345
Validation loss: 2.107129524151484

Epoch: 5| Step: 9
Training loss: 1.8223953247070312
Validation loss: 2.0741842488447824

Epoch: 5| Step: 10
Training loss: 2.152510643005371
Validation loss: 2.0447143415609994

Epoch: 5| Step: 11
Training loss: 1.5723806619644165
Validation loss: 2.0984507699807486

Epoch: 119| Step: 0
Training loss: 1.6760149002075195
Validation loss: 2.1613467981417975

Epoch: 5| Step: 1
Training loss: 1.7213748693466187
Validation loss: 2.0869379937648773

Epoch: 5| Step: 2
Training loss: 1.5192794799804688
Validation loss: 2.0974018623431525

Epoch: 5| Step: 3
Training loss: 2.0382883548736572
Validation loss: 2.0668832510709763

Epoch: 5| Step: 4
Training loss: 1.866803526878357
Validation loss: 2.094006066521009

Epoch: 5| Step: 5
Training loss: 1.6391150951385498
Validation loss: 2.037318636973699

Epoch: 5| Step: 6
Training loss: 1.8703597784042358
Validation loss: 2.108224352200826

Epoch: 5| Step: 7
Training loss: 1.6095250844955444
Validation loss: 2.0905214895804725

Epoch: 5| Step: 8
Training loss: 1.8630338907241821
Validation loss: 2.095199669400851

Epoch: 5| Step: 9
Training loss: 1.5636928081512451
Validation loss: 2.1578063319126763

Epoch: 5| Step: 10
Training loss: 1.9217458963394165
Validation loss: 2.1336734841267266

Epoch: 5| Step: 11
Training loss: 1.6502430438995361
Validation loss: 2.1364290664593377

Epoch: 120| Step: 0
Training loss: 1.322913408279419
Validation loss: 2.072704533735911

Epoch: 5| Step: 1
Training loss: 1.771558403968811
Validation loss: 2.117068553964297

Epoch: 5| Step: 2
Training loss: 1.7572158575057983
Validation loss: 2.191400468349457

Epoch: 5| Step: 3
Training loss: 1.424176573753357
Validation loss: 2.0874547561009726

Epoch: 5| Step: 4
Training loss: 1.6476558446884155
Validation loss: 2.0748339792092643

Epoch: 5| Step: 5
Training loss: 1.9589399099349976
Validation loss: 2.2266706228256226

Epoch: 5| Step: 6
Training loss: 2.095930576324463
Validation loss: 2.09264212846756

Epoch: 5| Step: 7
Training loss: 1.6401256322860718
Validation loss: 2.0737762649854026

Epoch: 5| Step: 8
Training loss: 1.644322395324707
Validation loss: 1.9889431198438008

Epoch: 5| Step: 9
Training loss: 1.947967529296875
Validation loss: 2.069556991259257

Epoch: 5| Step: 10
Training loss: 1.8060328960418701
Validation loss: 2.1115606923898063

Epoch: 5| Step: 11
Training loss: 4.495086669921875
Validation loss: 2.150493770837784

Epoch: 121| Step: 0
Training loss: 1.7330729961395264
Validation loss: 2.141431455810865

Epoch: 5| Step: 1
Training loss: 1.3506619930267334
Validation loss: 2.0199299653371177

Epoch: 5| Step: 2
Training loss: 2.446227550506592
Validation loss: 2.0739688873291016

Epoch: 5| Step: 3
Training loss: 1.6502196788787842
Validation loss: 2.063733791311582

Epoch: 5| Step: 4
Training loss: 1.5597718954086304
Validation loss: 2.086457515756289

Epoch: 5| Step: 5
Training loss: 1.533947229385376
Validation loss: 2.1759355813264847

Epoch: 5| Step: 6
Training loss: 1.9504226446151733
Validation loss: 2.0978354066610336

Epoch: 5| Step: 7
Training loss: 1.4631439447402954
Validation loss: 2.0862964391708374

Epoch: 5| Step: 8
Training loss: 2.336540699005127
Validation loss: 2.101943328976631

Epoch: 5| Step: 9
Training loss: 1.5479427576065063
Validation loss: 1.9568294485410054

Epoch: 5| Step: 10
Training loss: 1.7500145435333252
Validation loss: 2.0534277508656182

Epoch: 5| Step: 11
Training loss: 1.5755033493041992
Validation loss: 2.1132728656133017

Epoch: 122| Step: 0
Training loss: 2.3995747566223145
Validation loss: 2.077396353085836

Epoch: 5| Step: 1
Training loss: 1.488337755203247
Validation loss: 2.028535544872284

Epoch: 5| Step: 2
Training loss: 1.7836767435073853
Validation loss: 2.174443155527115

Epoch: 5| Step: 3
Training loss: 1.3583860397338867
Validation loss: 2.013092488050461

Epoch: 5| Step: 4
Training loss: 1.700750708580017
Validation loss: 2.1050908962885537

Epoch: 5| Step: 5
Training loss: 1.7513113021850586
Validation loss: 2.051011269291242

Epoch: 5| Step: 6
Training loss: 2.092580795288086
Validation loss: 2.0842458208402

Epoch: 5| Step: 7
Training loss: 1.950202226638794
Validation loss: 2.069427783290545

Epoch: 5| Step: 8
Training loss: 1.4289448261260986
Validation loss: 2.1531953563292823

Epoch: 5| Step: 9
Training loss: 2.0788369178771973
Validation loss: 2.0798862973848977

Epoch: 5| Step: 10
Training loss: 1.306431531906128
Validation loss: 2.1337093164523444

Epoch: 5| Step: 11
Training loss: 1.066784381866455
Validation loss: 2.1196883022785187

Epoch: 123| Step: 0
Training loss: 2.1448254585266113
Validation loss: 2.149995893239975

Epoch: 5| Step: 1
Training loss: 1.9069101810455322
Validation loss: 2.143351157506307

Epoch: 5| Step: 2
Training loss: 1.8367265462875366
Validation loss: 2.1109990576903024

Epoch: 5| Step: 3
Training loss: 1.8143622875213623
Validation loss: 2.0878935108582177

Epoch: 5| Step: 4
Training loss: 1.5930101871490479
Validation loss: 2.0182660867770514

Epoch: 5| Step: 5
Training loss: 1.6826152801513672
Validation loss: 2.146995961666107

Epoch: 5| Step: 6
Training loss: 2.033764362335205
Validation loss: 2.0848447481791177

Epoch: 5| Step: 7
Training loss: 1.7768003940582275
Validation loss: 2.0759084026018777

Epoch: 5| Step: 8
Training loss: 1.8479057550430298
Validation loss: 2.1172504226366677

Epoch: 5| Step: 9
Training loss: 1.5314505100250244
Validation loss: 2.087711215019226

Epoch: 5| Step: 10
Training loss: 1.3879345655441284
Validation loss: 2.043772672613462

Epoch: 5| Step: 11
Training loss: 1.7107939720153809
Validation loss: 2.1226797004540763

Epoch: 124| Step: 0
Training loss: 1.7657196521759033
Validation loss: 2.0905956029891968

Epoch: 5| Step: 1
Training loss: 1.9254672527313232
Validation loss: 2.049581194917361

Epoch: 5| Step: 2
Training loss: 1.7230396270751953
Validation loss: 2.1909715036551156

Epoch: 5| Step: 3
Training loss: 1.6596877574920654
Validation loss: 2.110311652223269

Epoch: 5| Step: 4
Training loss: 2.2207138538360596
Validation loss: 2.1322443584601083

Epoch: 5| Step: 5
Training loss: 1.6272592544555664
Validation loss: 2.1457232534885406

Epoch: 5| Step: 6
Training loss: 2.0981552600860596
Validation loss: 2.2117211123307547

Epoch: 5| Step: 7
Training loss: 1.6136058568954468
Validation loss: 2.074851860602697

Epoch: 5| Step: 8
Training loss: 1.9778839349746704
Validation loss: 2.1033285011847815

Epoch: 5| Step: 9
Training loss: 1.2979800701141357
Validation loss: 2.1012346843878427

Epoch: 5| Step: 10
Training loss: 1.6745589971542358
Validation loss: 2.103596786657969

Epoch: 5| Step: 11
Training loss: 0.7197229862213135
Validation loss: 2.1288258930047355

Epoch: 125| Step: 0
Training loss: 1.3809927701950073
Validation loss: 2.032935837904612

Epoch: 5| Step: 1
Training loss: 1.7991536855697632
Validation loss: 2.1056042412916818

Epoch: 5| Step: 2
Training loss: 2.1272988319396973
Validation loss: 2.0558987905581794

Epoch: 5| Step: 3
Training loss: 1.3523463010787964
Validation loss: 2.0490123877922692

Epoch: 5| Step: 4
Training loss: 1.8180614709854126
Validation loss: 2.2137806018193564

Epoch: 5| Step: 5
Training loss: 1.8038856983184814
Validation loss: 2.131267433365186

Epoch: 5| Step: 6
Training loss: 1.7889009714126587
Validation loss: 2.08074019352595

Epoch: 5| Step: 7
Training loss: 2.0339279174804688
Validation loss: 2.1065402378638587

Epoch: 5| Step: 8
Training loss: 1.6483938694000244
Validation loss: 2.0605048338572183

Epoch: 5| Step: 9
Training loss: 2.057542324066162
Validation loss: 1.9824921935796738

Epoch: 5| Step: 10
Training loss: 1.5805779695510864
Validation loss: 2.1036994407574334

Epoch: 5| Step: 11
Training loss: 1.0163198709487915
Validation loss: 2.1166474322477975

Epoch: 126| Step: 0
Training loss: 2.090578079223633
Validation loss: 2.0725271652142205

Epoch: 5| Step: 1
Training loss: 2.066232204437256
Validation loss: 2.125263959169388

Epoch: 5| Step: 2
Training loss: 1.6476523876190186
Validation loss: 2.106107383966446

Epoch: 5| Step: 3
Training loss: 2.3571553230285645
Validation loss: 2.2094919880231223

Epoch: 5| Step: 4
Training loss: 1.9834390878677368
Validation loss: 2.092498779296875

Epoch: 5| Step: 5
Training loss: 1.978621244430542
Validation loss: 2.070098633567492

Epoch: 5| Step: 6
Training loss: 1.3206180334091187
Validation loss: 2.1754718522230783

Epoch: 5| Step: 7
Training loss: 1.23592209815979
Validation loss: 2.0606024712324142

Epoch: 5| Step: 8
Training loss: 1.493281602859497
Validation loss: 2.1079512486855188

Epoch: 5| Step: 9
Training loss: 1.052127718925476
Validation loss: 2.1090051184097924

Epoch: 5| Step: 10
Training loss: 1.9684112071990967
Validation loss: 2.0314682722091675

Epoch: 5| Step: 11
Training loss: 1.563291311264038
Validation loss: 2.180018186569214

Epoch: 127| Step: 0
Training loss: 2.2321937084198
Validation loss: 2.070671930909157

Epoch: 5| Step: 1
Training loss: 1.7501070499420166
Validation loss: 2.0926923900842667

Epoch: 5| Step: 2
Training loss: 1.7844318151474
Validation loss: 2.0953842202822366

Epoch: 5| Step: 3
Training loss: 1.2079321146011353
Validation loss: 2.118269369006157

Epoch: 5| Step: 4
Training loss: 1.8193317651748657
Validation loss: 2.1787678549687066

Epoch: 5| Step: 5
Training loss: 1.3753221035003662
Validation loss: 2.062782049179077

Epoch: 5| Step: 6
Training loss: 1.6021232604980469
Validation loss: 2.182053412000338

Epoch: 5| Step: 7
Training loss: 2.0621354579925537
Validation loss: 2.1877843787272773

Epoch: 5| Step: 8
Training loss: 2.0899245738983154
Validation loss: 2.1287852227687836

Epoch: 5| Step: 9
Training loss: 1.6630680561065674
Validation loss: 2.077745412786802

Epoch: 5| Step: 10
Training loss: 2.3434231281280518
Validation loss: 2.1167095353206

Epoch: 5| Step: 11
Training loss: 1.0887552499771118
Validation loss: 2.0189692080020905

Epoch: 128| Step: 0
Training loss: 1.889090895652771
Validation loss: 2.0939539670944214

Epoch: 5| Step: 1
Training loss: 1.793046236038208
Validation loss: 2.088297814130783

Epoch: 5| Step: 2
Training loss: 1.752729058265686
Validation loss: 2.077296108007431

Epoch: 5| Step: 3
Training loss: 2.322155714035034
Validation loss: 2.1683830867211022

Epoch: 5| Step: 4
Training loss: 1.445907473564148
Validation loss: 2.148909558852514

Epoch: 5| Step: 5
Training loss: 1.7056066989898682
Validation loss: 2.1319010307391486

Epoch: 5| Step: 6
Training loss: 1.7210718393325806
Validation loss: 2.131075163682302

Epoch: 5| Step: 7
Training loss: 1.9971672296524048
Validation loss: 2.098881463209788

Epoch: 5| Step: 8
Training loss: 2.048614978790283
Validation loss: 2.0846734096606574

Epoch: 5| Step: 9
Training loss: 1.1837973594665527
Validation loss: 2.1464913884798684

Epoch: 5| Step: 10
Training loss: 1.8786531686782837
Validation loss: 2.0915330400069556

Epoch: 5| Step: 11
Training loss: 0.9650213718414307
Validation loss: 2.123572498559952

Epoch: 129| Step: 0
Training loss: 1.8443233966827393
Validation loss: 2.1095229983329773

Epoch: 5| Step: 1
Training loss: 1.5583425760269165
Validation loss: 2.138282264272372

Epoch: 5| Step: 2
Training loss: 1.263634443283081
Validation loss: 2.1617903312047324

Epoch: 5| Step: 3
Training loss: 1.4437286853790283
Validation loss: 2.120560258626938

Epoch: 5| Step: 4
Training loss: 2.233402729034424
Validation loss: 2.1154821713765464

Epoch: 5| Step: 5
Training loss: 2.135343551635742
Validation loss: 2.1033535997072854

Epoch: 5| Step: 6
Training loss: 1.8329732418060303
Validation loss: 2.137666071454684

Epoch: 5| Step: 7
Training loss: 1.3915716409683228
Validation loss: 2.1303985863924026

Epoch: 5| Step: 8
Training loss: 1.8609485626220703
Validation loss: 2.100605388482412

Epoch: 5| Step: 9
Training loss: 1.807286024093628
Validation loss: 2.107444723447164

Epoch: 5| Step: 10
Training loss: 1.7909984588623047
Validation loss: 2.148255944252014

Epoch: 5| Step: 11
Training loss: 0.9036256074905396
Validation loss: 2.0429733941952386

Epoch: 130| Step: 0
Training loss: 1.8289062976837158
Validation loss: 2.0570252587397895

Epoch: 5| Step: 1
Training loss: 1.146451711654663
Validation loss: 2.0836139967044196

Epoch: 5| Step: 2
Training loss: 2.5122909545898438
Validation loss: 2.1422606458266578

Epoch: 5| Step: 3
Training loss: 1.69219970703125
Validation loss: 2.1279412110646567

Epoch: 5| Step: 4
Training loss: 1.434072494506836
Validation loss: 2.110763192176819

Epoch: 5| Step: 5
Training loss: 1.6100904941558838
Validation loss: 2.1442452520132065

Epoch: 5| Step: 6
Training loss: 2.236116409301758
Validation loss: 2.1189279556274414

Epoch: 5| Step: 7
Training loss: 1.6437532901763916
Validation loss: 2.082105169693629

Epoch: 5| Step: 8
Training loss: 1.6619952917099
Validation loss: 2.097532187898954

Epoch: 5| Step: 9
Training loss: 1.858867883682251
Validation loss: 2.0939423690239587

Epoch: 5| Step: 10
Training loss: 1.6550668478012085
Validation loss: 2.13289837539196

Epoch: 5| Step: 11
Training loss: 1.9238512516021729
Validation loss: 2.0736647794644036

Epoch: 131| Step: 0
Training loss: 1.1622098684310913
Validation loss: 2.1485422998666763

Epoch: 5| Step: 1
Training loss: 1.954157829284668
Validation loss: 2.1230252236127853

Epoch: 5| Step: 2
Training loss: 2.1324074268341064
Validation loss: 2.1816200415293374

Epoch: 5| Step: 3
Training loss: 1.449020504951477
Validation loss: 2.1699844102064767

Epoch: 5| Step: 4
Training loss: 1.4251673221588135
Validation loss: 2.11591437458992

Epoch: 5| Step: 5
Training loss: 2.632206439971924
Validation loss: 2.093777909874916

Epoch: 5| Step: 6
Training loss: 1.5338385105133057
Validation loss: 2.1028804828723273

Epoch: 5| Step: 7
Training loss: 1.835831880569458
Validation loss: 2.0696981896956763

Epoch: 5| Step: 8
Training loss: 1.9028661251068115
Validation loss: 2.0718478659788766

Epoch: 5| Step: 9
Training loss: 1.3486454486846924
Validation loss: 2.0835880090792975

Epoch: 5| Step: 10
Training loss: 1.7662336826324463
Validation loss: 2.09451291958491

Epoch: 5| Step: 11
Training loss: 1.299076795578003
Validation loss: 2.137036681175232

Epoch: 132| Step: 0
Training loss: 1.8713279962539673
Validation loss: 2.0965218792359033

Epoch: 5| Step: 1
Training loss: 1.3091703653335571
Validation loss: 2.0984063943227134

Epoch: 5| Step: 2
Training loss: 1.720018982887268
Validation loss: 2.1014776676893234

Epoch: 5| Step: 3
Training loss: 2.3494575023651123
Validation loss: 2.0535659193992615

Epoch: 5| Step: 4
Training loss: 1.2631220817565918
Validation loss: 2.1075607339541116

Epoch: 5| Step: 5
Training loss: 0.918252170085907
Validation loss: 2.0415221005678177

Epoch: 5| Step: 6
Training loss: 1.6730983257293701
Validation loss: 2.1174219250679016

Epoch: 5| Step: 7
Training loss: 1.9212539196014404
Validation loss: 2.0985044489304223

Epoch: 5| Step: 8
Training loss: 1.710510015487671
Validation loss: 2.1664351522922516

Epoch: 5| Step: 9
Training loss: 2.1628477573394775
Validation loss: 2.166118085384369

Epoch: 5| Step: 10
Training loss: 1.747633695602417
Validation loss: 2.092071905732155

Epoch: 5| Step: 11
Training loss: 2.4394383430480957
Validation loss: 2.122319142023722

Epoch: 133| Step: 0
Training loss: 1.7655754089355469
Validation loss: 2.120030239224434

Epoch: 5| Step: 1
Training loss: 1.5337111949920654
Validation loss: 2.119356393814087

Epoch: 5| Step: 2
Training loss: 1.6275078058242798
Validation loss: 2.091806655128797

Epoch: 5| Step: 3
Training loss: 1.4791630506515503
Validation loss: 2.0919897655646005

Epoch: 5| Step: 4
Training loss: 1.9383935928344727
Validation loss: 2.169609397649765

Epoch: 5| Step: 5
Training loss: 1.805066704750061
Validation loss: 2.1672601203123727

Epoch: 5| Step: 6
Training loss: 1.6870418787002563
Validation loss: 2.0689900517463684

Epoch: 5| Step: 7
Training loss: 2.1145331859588623
Validation loss: 2.102330063780149

Epoch: 5| Step: 8
Training loss: 1.6441866159439087
Validation loss: 2.011860807736715

Epoch: 5| Step: 9
Training loss: 1.505308747291565
Validation loss: 2.1412024249633155

Epoch: 5| Step: 10
Training loss: 1.7282354831695557
Validation loss: 2.1188649435838065

Epoch: 5| Step: 11
Training loss: 2.8637523651123047
Validation loss: 2.1318693359692893

Epoch: 134| Step: 0
Training loss: 1.7673906087875366
Validation loss: 2.0894045929114022

Epoch: 5| Step: 1
Training loss: 1.3232676982879639
Validation loss: 2.0853784730037055

Epoch: 5| Step: 2
Training loss: 1.544523000717163
Validation loss: 2.084237352013588

Epoch: 5| Step: 3
Training loss: 1.4785115718841553
Validation loss: 2.1015668710072837

Epoch: 5| Step: 4
Training loss: 2.2592265605926514
Validation loss: 2.0659978489081063

Epoch: 5| Step: 5
Training loss: 1.8887943029403687
Validation loss: 2.062581275900205

Epoch: 5| Step: 6
Training loss: 1.9115917682647705
Validation loss: 2.0744297802448273

Epoch: 5| Step: 7
Training loss: 1.7282915115356445
Validation loss: 2.168822859724363

Epoch: 5| Step: 8
Training loss: 2.008085250854492
Validation loss: 2.09282257159551

Epoch: 5| Step: 9
Training loss: 1.810519814491272
Validation loss: 2.0983687887589135

Epoch: 5| Step: 10
Training loss: 1.64158034324646
Validation loss: 2.034383778770765

Epoch: 5| Step: 11
Training loss: 1.458316445350647
Validation loss: 2.0679930647214255

Epoch: 135| Step: 0
Training loss: 1.5571415424346924
Validation loss: 2.061587999264399

Epoch: 5| Step: 1
Training loss: 1.696479082107544
Validation loss: 2.0991996377706528

Epoch: 5| Step: 2
Training loss: 1.2118552923202515
Validation loss: 2.1777135133743286

Epoch: 5| Step: 3
Training loss: 2.1623637676239014
Validation loss: 2.1560936868190765

Epoch: 5| Step: 4
Training loss: 2.0754988193511963
Validation loss: 2.0975999981164932

Epoch: 5| Step: 5
Training loss: 1.59542715549469
Validation loss: 2.0769039193789163

Epoch: 5| Step: 6
Training loss: 1.982980728149414
Validation loss: 2.095083773136139

Epoch: 5| Step: 7
Training loss: 1.6062839031219482
Validation loss: 2.0994930267333984

Epoch: 5| Step: 8
Training loss: 1.7682745456695557
Validation loss: 2.038542300462723

Epoch: 5| Step: 9
Training loss: 2.0419933795928955
Validation loss: 2.1587628374497094

Epoch: 5| Step: 10
Training loss: 1.5254430770874023
Validation loss: 2.1226653258005777

Epoch: 5| Step: 11
Training loss: 1.6073365211486816
Validation loss: 2.079103410243988

Epoch: 136| Step: 0
Training loss: 1.565505027770996
Validation loss: 2.1187073389689126

Epoch: 5| Step: 1
Training loss: 1.992632508277893
Validation loss: 2.1638289988040924

Epoch: 5| Step: 2
Training loss: 1.5642859935760498
Validation loss: 2.0839791943629584

Epoch: 5| Step: 3
Training loss: 1.9881126880645752
Validation loss: 2.0919223676125207

Epoch: 5| Step: 4
Training loss: 1.9906145334243774
Validation loss: 2.100146472454071

Epoch: 5| Step: 5
Training loss: 1.6176481246948242
Validation loss: 2.0689457754294076

Epoch: 5| Step: 6
Training loss: 1.7308261394500732
Validation loss: 2.046951433022817

Epoch: 5| Step: 7
Training loss: 1.3907675743103027
Validation loss: 2.0890294909477234

Epoch: 5| Step: 8
Training loss: 1.4722018241882324
Validation loss: 2.0645635426044464

Epoch: 5| Step: 9
Training loss: 1.7286040782928467
Validation loss: 2.0112656950950623

Epoch: 5| Step: 10
Training loss: 1.9891666173934937
Validation loss: 2.0451692591110864

Epoch: 5| Step: 11
Training loss: 1.671890377998352
Validation loss: 2.0507862120866776

Epoch: 137| Step: 0
Training loss: 1.8748061656951904
Validation loss: 2.0369728108247123

Epoch: 5| Step: 1
Training loss: 1.21761953830719
Validation loss: 2.1362189004818597

Epoch: 5| Step: 2
Training loss: 1.7124145030975342
Validation loss: 2.1429011474053064

Epoch: 5| Step: 3
Training loss: 1.750279188156128
Validation loss: 2.0608402689297995

Epoch: 5| Step: 4
Training loss: 1.2946844100952148
Validation loss: 2.0738330433766046

Epoch: 5| Step: 5
Training loss: 1.6219091415405273
Validation loss: 2.187307208776474

Epoch: 5| Step: 6
Training loss: 1.2229212522506714
Validation loss: 2.0572258730729422

Epoch: 5| Step: 7
Training loss: 2.086761474609375
Validation loss: 2.102688560883204

Epoch: 5| Step: 8
Training loss: 2.4914424419403076
Validation loss: 2.07034540673097

Epoch: 5| Step: 9
Training loss: 1.7646516561508179
Validation loss: 2.0829114516576133

Epoch: 5| Step: 10
Training loss: 1.9010941982269287
Validation loss: 2.030512740214666

Epoch: 5| Step: 11
Training loss: 1.887258768081665
Validation loss: 2.1202073792616525

Epoch: 138| Step: 0
Training loss: 1.7610912322998047
Validation loss: 2.1493997077147164

Epoch: 5| Step: 1
Training loss: 1.3930447101593018
Validation loss: 2.013081098596255

Epoch: 5| Step: 2
Training loss: 1.0428310632705688
Validation loss: 2.143677065769831

Epoch: 5| Step: 3
Training loss: 1.2925759553909302
Validation loss: 2.06238029897213

Epoch: 5| Step: 4
Training loss: 1.3962538242340088
Validation loss: 2.13655919333299

Epoch: 5| Step: 5
Training loss: 2.3247694969177246
Validation loss: 2.062521532177925

Epoch: 5| Step: 6
Training loss: 2.5685715675354004
Validation loss: 2.115006446838379

Epoch: 5| Step: 7
Training loss: 1.8732411861419678
Validation loss: 2.1386128862698874

Epoch: 5| Step: 8
Training loss: 1.4228053092956543
Validation loss: 2.0703584104776382

Epoch: 5| Step: 9
Training loss: 1.8499805927276611
Validation loss: 2.0861843725045524

Epoch: 5| Step: 10
Training loss: 1.47196364402771
Validation loss: 2.072484736641248

Epoch: 5| Step: 11
Training loss: 2.3828859329223633
Validation loss: 2.1177646120389304

Epoch: 139| Step: 0
Training loss: 1.4566786289215088
Validation loss: 2.1018384446700416

Epoch: 5| Step: 1
Training loss: 1.8528242111206055
Validation loss: 2.067469303806623

Epoch: 5| Step: 2
Training loss: 2.710176944732666
Validation loss: 2.0891365160544715

Epoch: 5| Step: 3
Training loss: 1.3009147644042969
Validation loss: 2.056684752305349

Epoch: 5| Step: 4
Training loss: 1.2948684692382812
Validation loss: 2.0771449555953345

Epoch: 5| Step: 5
Training loss: 1.796677827835083
Validation loss: 2.1629227499167123

Epoch: 5| Step: 6
Training loss: 2.0371720790863037
Validation loss: 2.006305714448293

Epoch: 5| Step: 7
Training loss: 1.925492525100708
Validation loss: 1.979295700788498

Epoch: 5| Step: 8
Training loss: 1.6171743869781494
Validation loss: 2.106454759836197

Epoch: 5| Step: 9
Training loss: 1.3436357975006104
Validation loss: 2.1126715540885925

Epoch: 5| Step: 10
Training loss: 1.7995140552520752
Validation loss: 2.102789352337519

Epoch: 5| Step: 11
Training loss: 0.7397139072418213
Validation loss: 2.101030647754669

Epoch: 140| Step: 0
Training loss: 1.5321439504623413
Validation loss: 2.0734989841779075

Epoch: 5| Step: 1
Training loss: 1.5270506143569946
Validation loss: 2.1182191371917725

Epoch: 5| Step: 2
Training loss: 1.50417959690094
Validation loss: 2.0832363863786063

Epoch: 5| Step: 3
Training loss: 1.6586039066314697
Validation loss: 2.0504978199799857

Epoch: 5| Step: 4
Training loss: 1.5441614389419556
Validation loss: 2.1557712952295938

Epoch: 5| Step: 5
Training loss: 2.4175705909729004
Validation loss: 2.103639821211497

Epoch: 5| Step: 6
Training loss: 1.1203346252441406
Validation loss: 2.1843441228071847

Epoch: 5| Step: 7
Training loss: 2.0773658752441406
Validation loss: 2.083824579914411

Epoch: 5| Step: 8
Training loss: 1.9373228549957275
Validation loss: 2.0740159898996353

Epoch: 5| Step: 9
Training loss: 1.3944963216781616
Validation loss: 2.06870307524999

Epoch: 5| Step: 10
Training loss: 1.6518398523330688
Validation loss: 2.1287508606910706

Epoch: 5| Step: 11
Training loss: 2.2210745811462402
Validation loss: 2.099740982055664

Epoch: 141| Step: 0
Training loss: 1.6936527490615845
Validation loss: 2.071565414468447

Epoch: 5| Step: 1
Training loss: 1.5649888515472412
Validation loss: 2.100013181567192

Epoch: 5| Step: 2
Training loss: 1.7726695537567139
Validation loss: 2.120924492677053

Epoch: 5| Step: 3
Training loss: 1.5385582447052002
Validation loss: 2.1032400677601495

Epoch: 5| Step: 4
Training loss: 1.6126800775527954
Validation loss: 2.094156558314959

Epoch: 5| Step: 5
Training loss: 1.6536887884140015
Validation loss: 2.1929456144571304

Epoch: 5| Step: 6
Training loss: 1.8984142541885376
Validation loss: 2.149227743347486

Epoch: 5| Step: 7
Training loss: 1.719430685043335
Validation loss: 2.0883008539676666

Epoch: 5| Step: 8
Training loss: 1.6928751468658447
Validation loss: 2.0733609596888223

Epoch: 5| Step: 9
Training loss: 1.781134009361267
Validation loss: 2.137819290161133

Epoch: 5| Step: 10
Training loss: 1.5442397594451904
Validation loss: 2.1087266554435096

Epoch: 5| Step: 11
Training loss: 2.1809864044189453
Validation loss: 2.106750095884005

Epoch: 142| Step: 0
Training loss: 1.4043165445327759
Validation loss: 2.073106129964193

Epoch: 5| Step: 1
Training loss: 1.2758640050888062
Validation loss: 2.032849301894506

Epoch: 5| Step: 2
Training loss: 1.3960363864898682
Validation loss: 2.0238256653149924

Epoch: 5| Step: 3
Training loss: 1.4466209411621094
Validation loss: 2.1306129693984985

Epoch: 5| Step: 4
Training loss: 1.5860486030578613
Validation loss: 2.077366809050242

Epoch: 5| Step: 5
Training loss: 2.0330193042755127
Validation loss: 2.063021411498388

Epoch: 5| Step: 6
Training loss: 1.7308908700942993
Validation loss: 2.0906171997388205

Epoch: 5| Step: 7
Training loss: 2.1821703910827637
Validation loss: 2.0888242522875466

Epoch: 5| Step: 8
Training loss: 1.3904842138290405
Validation loss: 2.0972299625476203

Epoch: 5| Step: 9
Training loss: 2.1891398429870605
Validation loss: 2.100546901424726

Epoch: 5| Step: 10
Training loss: 1.5410425662994385
Validation loss: 2.1036631067593894

Epoch: 5| Step: 11
Training loss: 1.9651823043823242
Validation loss: 2.0900255690018334

Epoch: 143| Step: 0
Training loss: 1.6419668197631836
Validation loss: 2.1522045830885568

Epoch: 5| Step: 1
Training loss: 1.4856597185134888
Validation loss: 2.0148959010839462

Epoch: 5| Step: 2
Training loss: 1.6774957180023193
Validation loss: 2.1530376970767975

Epoch: 5| Step: 3
Training loss: 2.614690065383911
Validation loss: 2.060319632291794

Epoch: 5| Step: 4
Training loss: 1.0978467464447021
Validation loss: 2.1517477681239447

Epoch: 5| Step: 5
Training loss: 1.7360903024673462
Validation loss: 2.0679178486267724

Epoch: 5| Step: 6
Training loss: 1.7255818843841553
Validation loss: 2.077454869945844

Epoch: 5| Step: 7
Training loss: 1.6021751165390015
Validation loss: 2.058841660618782

Epoch: 5| Step: 8
Training loss: 1.365096092224121
Validation loss: 2.0662426352500916

Epoch: 5| Step: 9
Training loss: 1.6540861129760742
Validation loss: 2.143177568912506

Epoch: 5| Step: 10
Training loss: 1.405118703842163
Validation loss: 2.078317254781723

Epoch: 5| Step: 11
Training loss: 1.312612533569336
Validation loss: 2.073010270794233

Epoch: 144| Step: 0
Training loss: 1.866141676902771
Validation loss: 2.090295225381851

Epoch: 5| Step: 1
Training loss: 1.77242112159729
Validation loss: 2.105279708902041

Epoch: 5| Step: 2
Training loss: 2.2097830772399902
Validation loss: 2.0938207705815635

Epoch: 5| Step: 3
Training loss: 1.423774003982544
Validation loss: 2.0924996634324393

Epoch: 5| Step: 4
Training loss: 1.3478200435638428
Validation loss: 2.165090560913086

Epoch: 5| Step: 5
Training loss: 1.36849045753479
Validation loss: 2.125184843937556

Epoch: 5| Step: 6
Training loss: 1.5274769067764282
Validation loss: 2.039233843485514

Epoch: 5| Step: 7
Training loss: 1.4263696670532227
Validation loss: 2.132802759607633

Epoch: 5| Step: 8
Training loss: 1.7075793743133545
Validation loss: 2.138970116774241

Epoch: 5| Step: 9
Training loss: 1.588477611541748
Validation loss: 2.134754955768585

Epoch: 5| Step: 10
Training loss: 1.7411037683486938
Validation loss: 2.130778357386589

Epoch: 5| Step: 11
Training loss: 1.6231452226638794
Validation loss: 2.08912555873394

Epoch: 145| Step: 0
Training loss: 1.494244933128357
Validation loss: 2.067244902253151

Epoch: 5| Step: 1
Training loss: 1.2708673477172852
Validation loss: 2.0713049322366714

Epoch: 5| Step: 2
Training loss: 1.757685661315918
Validation loss: 2.0907351225614548

Epoch: 5| Step: 3
Training loss: 1.6252853870391846
Validation loss: 2.0024114648501077

Epoch: 5| Step: 4
Training loss: 1.9298181533813477
Validation loss: 2.1073628962039948

Epoch: 5| Step: 5
Training loss: 1.435144066810608
Validation loss: 2.0898759067058563

Epoch: 5| Step: 6
Training loss: 2.4732539653778076
Validation loss: 2.037310406565666

Epoch: 5| Step: 7
Training loss: 1.399203896522522
Validation loss: 2.0501343260208764

Epoch: 5| Step: 8
Training loss: 1.9030287265777588
Validation loss: 2.1635437359412513

Epoch: 5| Step: 9
Training loss: 1.0272959470748901
Validation loss: 2.1250677903493247

Epoch: 5| Step: 10
Training loss: 1.5910606384277344
Validation loss: 2.0843105167150497

Epoch: 5| Step: 11
Training loss: 1.5987269878387451
Validation loss: 2.1013304044802985

Epoch: 146| Step: 0
Training loss: 1.4862074851989746
Validation loss: 2.073596571882566

Epoch: 5| Step: 1
Training loss: 1.3115569353103638
Validation loss: 2.07327493528525

Epoch: 5| Step: 2
Training loss: 2.142103672027588
Validation loss: 2.1114209045966468

Epoch: 5| Step: 3
Training loss: 1.8514621257781982
Validation loss: 2.0671323984861374

Epoch: 5| Step: 4
Training loss: 1.4698989391326904
Validation loss: 2.1028650303681693

Epoch: 5| Step: 5
Training loss: 1.6126680374145508
Validation loss: 2.0809601098299026

Epoch: 5| Step: 6
Training loss: 1.152743935585022
Validation loss: 2.167705714702606

Epoch: 5| Step: 7
Training loss: 1.9718761444091797
Validation loss: 2.120149234930674

Epoch: 5| Step: 8
Training loss: 1.6199973821640015
Validation loss: 2.086438919107119

Epoch: 5| Step: 9
Training loss: 1.8590924739837646
Validation loss: 2.041705444455147

Epoch: 5| Step: 10
Training loss: 1.8432785272598267
Validation loss: 2.0139147539933524

Epoch: 5| Step: 11
Training loss: 1.3361952304840088
Validation loss: 2.0516505440076194

Epoch: 147| Step: 0
Training loss: 1.7676935195922852
Validation loss: 2.1029505083958306

Epoch: 5| Step: 1
Training loss: 1.3040478229522705
Validation loss: 2.074750060836474

Epoch: 5| Step: 2
Training loss: 2.2328059673309326
Validation loss: 2.08241959909598

Epoch: 5| Step: 3
Training loss: 1.731001615524292
Validation loss: 2.0350300321976342

Epoch: 5| Step: 4
Training loss: 1.4971754550933838
Validation loss: 2.145998309055964

Epoch: 5| Step: 5
Training loss: 1.353651762008667
Validation loss: 2.1160476058721542

Epoch: 5| Step: 6
Training loss: 1.2137820720672607
Validation loss: 2.068229337533315

Epoch: 5| Step: 7
Training loss: 1.608486533164978
Validation loss: 2.050154452522596

Epoch: 5| Step: 8
Training loss: 1.6023002862930298
Validation loss: 2.171513338883718

Epoch: 5| Step: 9
Training loss: 1.6141479015350342
Validation loss: 2.0913427621126175

Epoch: 5| Step: 10
Training loss: 1.5884279012680054
Validation loss: 2.137157375613848

Epoch: 5| Step: 11
Training loss: 2.2690610885620117
Validation loss: 2.115556245048841

Epoch: 148| Step: 0
Training loss: 1.6831210851669312
Validation loss: 2.097179134686788

Epoch: 5| Step: 1
Training loss: 1.549917221069336
Validation loss: 2.187319109837214

Epoch: 5| Step: 2
Training loss: 1.325391173362732
Validation loss: 2.1066484997669854

Epoch: 5| Step: 3
Training loss: 1.4814854860305786
Validation loss: 2.0800307045380273

Epoch: 5| Step: 4
Training loss: 1.9932807683944702
Validation loss: 2.0729176849126816

Epoch: 5| Step: 5
Training loss: 1.3775529861450195
Validation loss: 2.117905000845591

Epoch: 5| Step: 6
Training loss: 1.476959466934204
Validation loss: 2.0065073370933533

Epoch: 5| Step: 7
Training loss: 1.0265015363693237
Validation loss: 2.0641185343265533

Epoch: 5| Step: 8
Training loss: 1.7444900274276733
Validation loss: 2.103093236684799

Epoch: 5| Step: 9
Training loss: 1.7347205877304077
Validation loss: 2.0042128761609397

Epoch: 5| Step: 10
Training loss: 2.178640604019165
Validation loss: 2.1065358370542526

Epoch: 5| Step: 11
Training loss: 3.167832612991333
Validation loss: 2.170248677333196

Epoch: 149| Step: 0
Training loss: 1.876712441444397
Validation loss: 2.109599987665812

Epoch: 5| Step: 1
Training loss: 1.519014596939087
Validation loss: 2.1191432823737464

Epoch: 5| Step: 2
Training loss: 1.6927802562713623
Validation loss: 2.088521013657252

Epoch: 5| Step: 3
Training loss: 1.4049689769744873
Validation loss: 2.1465828816095986

Epoch: 5| Step: 4
Training loss: 1.5990173816680908
Validation loss: 2.019553522268931

Epoch: 5| Step: 5
Training loss: 1.1654736995697021
Validation loss: 2.057348902026812

Epoch: 5| Step: 6
Training loss: 1.9968993663787842
Validation loss: 2.065144638220469

Epoch: 5| Step: 7
Training loss: 1.6970081329345703
Validation loss: 2.082652101914088

Epoch: 5| Step: 8
Training loss: 1.5340543985366821
Validation loss: 2.0814626763264337

Epoch: 5| Step: 9
Training loss: 1.4670175313949585
Validation loss: 2.1225180427233377

Epoch: 5| Step: 10
Training loss: 1.5573090314865112
Validation loss: 2.1633300681908927

Epoch: 5| Step: 11
Training loss: 1.7233400344848633
Validation loss: 2.097860818107923

Epoch: 150| Step: 0
Training loss: 2.0377769470214844
Validation loss: 2.1798245906829834

Epoch: 5| Step: 1
Training loss: 1.7813857793807983
Validation loss: 2.087620442112287

Epoch: 5| Step: 2
Training loss: 1.685772180557251
Validation loss: 2.172891075412432

Epoch: 5| Step: 3
Training loss: 2.375593662261963
Validation loss: 2.170473982890447

Epoch: 5| Step: 4
Training loss: 1.872722864151001
Validation loss: 2.1317208111286163

Epoch: 5| Step: 5
Training loss: 1.3431994915008545
Validation loss: 2.0918168822924295

Epoch: 5| Step: 6
Training loss: 1.3544641733169556
Validation loss: 2.1266020139058432

Epoch: 5| Step: 7
Training loss: 1.4430269002914429
Validation loss: 2.1309937089681625

Epoch: 5| Step: 8
Training loss: 1.3072402477264404
Validation loss: 2.113913595676422

Epoch: 5| Step: 9
Training loss: 1.9151580333709717
Validation loss: 2.0856721897919974

Epoch: 5| Step: 10
Training loss: 1.211716651916504
Validation loss: 2.0860394338766732

Epoch: 5| Step: 11
Training loss: 1.265906810760498
Validation loss: 2.123687962690989

Epoch: 151| Step: 0
Training loss: 1.2306239604949951
Validation loss: 2.0929928670326867

Epoch: 5| Step: 1
Training loss: 1.532950758934021
Validation loss: 2.1711128850777945

Epoch: 5| Step: 2
Training loss: 1.4522950649261475
Validation loss: 2.104156975944837

Epoch: 5| Step: 3
Training loss: 1.5843727588653564
Validation loss: 2.171655053893725

Epoch: 5| Step: 4
Training loss: 1.3479554653167725
Validation loss: 2.1232108026742935

Epoch: 5| Step: 5
Training loss: 1.8842318058013916
Validation loss: 2.1452082693576813

Epoch: 5| Step: 6
Training loss: 1.8839267492294312
Validation loss: 2.238406111796697

Epoch: 5| Step: 7
Training loss: 2.0113329887390137
Validation loss: 2.096239651242892

Epoch: 5| Step: 8
Training loss: 1.086150050163269
Validation loss: 2.1844549576441445

Epoch: 5| Step: 9
Training loss: 2.2414000034332275
Validation loss: 2.1603313932816186

Epoch: 5| Step: 10
Training loss: 2.0471808910369873
Validation loss: 2.1011374096075692

Epoch: 5| Step: 11
Training loss: 0.8301625847816467
Validation loss: 2.0474137564500174

Epoch: 152| Step: 0
Training loss: 1.1008687019348145
Validation loss: 2.1377062598864236

Epoch: 5| Step: 1
Training loss: 1.862174391746521
Validation loss: 2.1365912755330405

Epoch: 5| Step: 2
Training loss: 1.6407747268676758
Validation loss: 2.0981849978367486

Epoch: 5| Step: 3
Training loss: 1.9284403324127197
Validation loss: 2.098846490184466

Epoch: 5| Step: 4
Training loss: 1.6806236505508423
Validation loss: 2.0219887594381967

Epoch: 5| Step: 5
Training loss: 1.4712833166122437
Validation loss: 2.058953041831652

Epoch: 5| Step: 6
Training loss: 1.599783182144165
Validation loss: 2.0750254640976586

Epoch: 5| Step: 7
Training loss: 1.8177518844604492
Validation loss: 2.1099451382954917

Epoch: 5| Step: 8
Training loss: 1.5657445192337036
Validation loss: 2.0487694392601647

Epoch: 5| Step: 9
Training loss: 1.4415409564971924
Validation loss: 2.1604345391194024

Epoch: 5| Step: 10
Training loss: 1.2570157051086426
Validation loss: 2.086904212832451

Epoch: 5| Step: 11
Training loss: 2.563915729522705
Validation loss: 2.125773181517919

Epoch: 153| Step: 0
Training loss: 1.7221790552139282
Validation loss: 2.1097896297772727

Epoch: 5| Step: 1
Training loss: 1.5016533136367798
Validation loss: 2.2242671251296997

Epoch: 5| Step: 2
Training loss: 1.0887044668197632
Validation loss: 2.1808986167112985

Epoch: 5| Step: 3
Training loss: 1.5310118198394775
Validation loss: 2.158793797095617

Epoch: 5| Step: 4
Training loss: 1.3316007852554321
Validation loss: 2.1406892190376916

Epoch: 5| Step: 5
Training loss: 1.5392658710479736
Validation loss: 2.1226642529169717

Epoch: 5| Step: 6
Training loss: 1.7123762369155884
Validation loss: 2.0775252083937326

Epoch: 5| Step: 7
Training loss: 1.8426049947738647
Validation loss: 2.1015072961648307

Epoch: 5| Step: 8
Training loss: 2.173038959503174
Validation loss: 2.1010636389255524

Epoch: 5| Step: 9
Training loss: 1.4704288244247437
Validation loss: 2.149066468079885

Epoch: 5| Step: 10
Training loss: 1.557165503501892
Validation loss: 2.07183904449145

Epoch: 5| Step: 11
Training loss: 1.499878168106079
Validation loss: 2.0687211404244104

Epoch: 154| Step: 0
Training loss: 1.5005524158477783
Validation loss: 2.1121621429920197

Epoch: 5| Step: 1
Training loss: 1.6705697774887085
Validation loss: 2.1374259293079376

Epoch: 5| Step: 2
Training loss: 1.285402774810791
Validation loss: 2.0773516496022544

Epoch: 5| Step: 3
Training loss: 1.6295349597930908
Validation loss: 2.141879692673683

Epoch: 5| Step: 4
Training loss: 1.0160648822784424
Validation loss: 2.0981702456871667

Epoch: 5| Step: 5
Training loss: 1.5314821004867554
Validation loss: 2.087775448958079

Epoch: 5| Step: 6
Training loss: 2.2276291847229004
Validation loss: 2.207004909714063

Epoch: 5| Step: 7
Training loss: 1.323846459388733
Validation loss: 2.1625202347834906

Epoch: 5| Step: 8
Training loss: 2.087808609008789
Validation loss: 2.163821205496788

Epoch: 5| Step: 9
Training loss: 1.8676589727401733
Validation loss: 2.140589267015457

Epoch: 5| Step: 10
Training loss: 1.581651210784912
Validation loss: 2.1130840132633844

Epoch: 5| Step: 11
Training loss: 1.0715259313583374
Validation loss: 2.11480846007665

Epoch: 155| Step: 0
Training loss: 1.251114845275879
Validation loss: 2.136111860473951

Epoch: 5| Step: 1
Training loss: 2.027078866958618
Validation loss: 2.108230178554853

Epoch: 5| Step: 2
Training loss: 1.4847804307937622
Validation loss: 2.0864981214205423

Epoch: 5| Step: 3
Training loss: 2.0476789474487305
Validation loss: 2.1547759075959525

Epoch: 5| Step: 4
Training loss: 1.4702613353729248
Validation loss: 2.121207132935524

Epoch: 5| Step: 5
Training loss: 1.8365812301635742
Validation loss: 2.1099569896856942

Epoch: 5| Step: 6
Training loss: 1.6083672046661377
Validation loss: 2.092840547362963

Epoch: 5| Step: 7
Training loss: 1.881434440612793
Validation loss: 2.1670494973659515

Epoch: 5| Step: 8
Training loss: 1.3798673152923584
Validation loss: 2.1254733751217523

Epoch: 5| Step: 9
Training loss: 1.428320050239563
Validation loss: 2.0801908522844315

Epoch: 5| Step: 10
Training loss: 1.7235243320465088
Validation loss: 2.0569594899813333

Epoch: 5| Step: 11
Training loss: 0.9292049407958984
Validation loss: 2.092133949200312

Epoch: 156| Step: 0
Training loss: 1.6541484594345093
Validation loss: 2.1319659699996314

Epoch: 5| Step: 1
Training loss: 1.46700918674469
Validation loss: 2.075649614135424

Epoch: 5| Step: 2
Training loss: 1.6723735332489014
Validation loss: 2.1072136610746384

Epoch: 5| Step: 3
Training loss: 2.041259288787842
Validation loss: 2.1631830632686615

Epoch: 5| Step: 4
Training loss: 1.6919177770614624
Validation loss: 2.150132656097412

Epoch: 5| Step: 5
Training loss: 1.828486442565918
Validation loss: 2.1494506696859994

Epoch: 5| Step: 6
Training loss: 1.4460322856903076
Validation loss: 2.1133054296175637

Epoch: 5| Step: 7
Training loss: 1.7775108814239502
Validation loss: 2.1065202752749124

Epoch: 5| Step: 8
Training loss: 1.3442037105560303
Validation loss: 2.169923613468806

Epoch: 5| Step: 9
Training loss: 1.02042555809021
Validation loss: 2.119876444339752

Epoch: 5| Step: 10
Training loss: 1.678786039352417
Validation loss: 2.0933268119891486

Epoch: 5| Step: 11
Training loss: 1.7951159477233887
Validation loss: 2.0943320095539093

Epoch: 157| Step: 0
Training loss: 2.3802943229675293
Validation loss: 2.1290060232083

Epoch: 5| Step: 1
Training loss: 1.267493486404419
Validation loss: 2.129085953036944

Epoch: 5| Step: 2
Training loss: 1.893082857131958
Validation loss: 2.1934451162815094

Epoch: 5| Step: 3
Training loss: 2.0894477367401123
Validation loss: 2.1843892435232797

Epoch: 5| Step: 4
Training loss: 1.6503832340240479
Validation loss: 2.1544769605000815

Epoch: 5| Step: 5
Training loss: 1.1868841648101807
Validation loss: 2.1546622862418494

Epoch: 5| Step: 6
Training loss: 1.6118643283843994
Validation loss: 2.09955395758152

Epoch: 5| Step: 7
Training loss: 1.2654860019683838
Validation loss: 2.056401694814364

Epoch: 5| Step: 8
Training loss: 1.431748628616333
Validation loss: 2.06821641822656

Epoch: 5| Step: 9
Training loss: 1.8112192153930664
Validation loss: 2.175246020158132

Epoch: 5| Step: 10
Training loss: 1.6787185668945312
Validation loss: 2.1065064122279487

Epoch: 5| Step: 11
Training loss: 2.397515058517456
Validation loss: 2.1717052161693573

Epoch: 158| Step: 0
Training loss: 1.6178171634674072
Validation loss: 2.1240664621194205

Epoch: 5| Step: 1
Training loss: 2.2112369537353516
Validation loss: 2.1935123056173325

Epoch: 5| Step: 2
Training loss: 1.4867534637451172
Validation loss: 2.1643016189336777

Epoch: 5| Step: 3
Training loss: 1.4408162832260132
Validation loss: 2.1173569411039352

Epoch: 5| Step: 4
Training loss: 1.8393560647964478
Validation loss: 2.089012290040652

Epoch: 5| Step: 5
Training loss: 1.4076850414276123
Validation loss: 2.038271506627401

Epoch: 5| Step: 6
Training loss: 1.4019221067428589
Validation loss: 2.120264917612076

Epoch: 5| Step: 7
Training loss: 1.213597297668457
Validation loss: 2.1585059811671576

Epoch: 5| Step: 8
Training loss: 1.955767273902893
Validation loss: 2.101250097155571

Epoch: 5| Step: 9
Training loss: 1.677768349647522
Validation loss: 2.107041299343109

Epoch: 5| Step: 10
Training loss: 1.8121929168701172
Validation loss: 2.125512724121412

Epoch: 5| Step: 11
Training loss: 2.069936752319336
Validation loss: 2.018471156557401

Epoch: 159| Step: 0
Training loss: 1.3533128499984741
Validation loss: 2.093764250477155

Epoch: 5| Step: 1
Training loss: 1.5331212282180786
Validation loss: 2.179859588543574

Epoch: 5| Step: 2
Training loss: 1.3400604724884033
Validation loss: 2.233333627382914

Epoch: 5| Step: 3
Training loss: 1.4500818252563477
Validation loss: 2.2415772825479507

Epoch: 5| Step: 4
Training loss: 1.8354034423828125
Validation loss: 2.243991141517957

Epoch: 5| Step: 5
Training loss: 1.2988367080688477
Validation loss: 2.300316095352173

Epoch: 5| Step: 6
Training loss: 2.094362735748291
Validation loss: 2.1757645905017853

Epoch: 5| Step: 7
Training loss: 1.41144859790802
Validation loss: 2.165043200055758

Epoch: 5| Step: 8
Training loss: 1.922690749168396
Validation loss: 2.078246613343557

Epoch: 5| Step: 9
Training loss: 1.6805282831192017
Validation loss: 2.157504161198934

Epoch: 5| Step: 10
Training loss: 1.5197175741195679
Validation loss: 2.112377032637596

Epoch: 5| Step: 11
Training loss: 1.4053276777267456
Validation loss: 2.0623888025681176

Epoch: 160| Step: 0
Training loss: 1.180696964263916
Validation loss: 2.0361958046754203

Epoch: 5| Step: 1
Training loss: 1.4958370923995972
Validation loss: 2.06565098464489

Epoch: 5| Step: 2
Training loss: 1.8320575952529907
Validation loss: 2.124092390139898

Epoch: 5| Step: 3
Training loss: 1.778249979019165
Validation loss: 2.044045865535736

Epoch: 5| Step: 4
Training loss: 1.9360191822052002
Validation loss: 2.0940904766321182

Epoch: 5| Step: 5
Training loss: 1.6441558599472046
Validation loss: 2.1056153575579324

Epoch: 5| Step: 6
Training loss: 1.2039395570755005
Validation loss: 2.088701913754145

Epoch: 5| Step: 7
Training loss: 2.1072115898132324
Validation loss: 2.0745674719413123

Epoch: 5| Step: 8
Training loss: 1.2860710620880127
Validation loss: 2.094232271114985

Epoch: 5| Step: 9
Training loss: 1.6745655536651611
Validation loss: 2.107512111465136

Epoch: 5| Step: 10
Training loss: 1.670193076133728
Validation loss: 2.096278101205826

Epoch: 5| Step: 11
Training loss: 0.4844248592853546
Validation loss: 2.087990169723829

Epoch: 161| Step: 0
Training loss: 1.663476586341858
Validation loss: 2.1529038151105246

Epoch: 5| Step: 1
Training loss: 1.316275715827942
Validation loss: 2.1155996372302375

Epoch: 5| Step: 2
Training loss: 1.5838552713394165
Validation loss: 2.0795525858799615

Epoch: 5| Step: 3
Training loss: 1.087437391281128
Validation loss: 2.109835277001063

Epoch: 5| Step: 4
Training loss: 1.2573919296264648
Validation loss: 2.128153016169866

Epoch: 5| Step: 5
Training loss: 1.9447177648544312
Validation loss: 2.1363063206275306

Epoch: 5| Step: 6
Training loss: 1.9161746501922607
Validation loss: 2.1042236238718033

Epoch: 5| Step: 7
Training loss: 1.8694143295288086
Validation loss: 2.1504064003626504

Epoch: 5| Step: 8
Training loss: 1.4388558864593506
Validation loss: 2.149940143028895

Epoch: 5| Step: 9
Training loss: 1.2216018438339233
Validation loss: 2.099011321862539

Epoch: 5| Step: 10
Training loss: 1.717768907546997
Validation loss: 2.078092485666275

Epoch: 5| Step: 11
Training loss: 1.37330162525177
Validation loss: 2.137710317969322

Epoch: 162| Step: 0
Training loss: 1.1675050258636475
Validation loss: 2.040636400381724

Epoch: 5| Step: 1
Training loss: 1.2148993015289307
Validation loss: 2.075407087802887

Epoch: 5| Step: 2
Training loss: 1.9167454242706299
Validation loss: 2.118216643730799

Epoch: 5| Step: 3
Training loss: 1.6522808074951172
Validation loss: 2.128265062967936

Epoch: 5| Step: 4
Training loss: 1.6900317668914795
Validation loss: 2.090146561463674

Epoch: 5| Step: 5
Training loss: 1.4603021144866943
Validation loss: 2.1477342446645102

Epoch: 5| Step: 6
Training loss: 1.5850380659103394
Validation loss: 2.1302988628546395

Epoch: 5| Step: 7
Training loss: 1.3196251392364502
Validation loss: 2.1094304273525872

Epoch: 5| Step: 8
Training loss: 2.280703544616699
Validation loss: 2.103969156742096

Epoch: 5| Step: 9
Training loss: 1.5397788286209106
Validation loss: 2.102354278167089

Epoch: 5| Step: 10
Training loss: 1.2729648351669312
Validation loss: 2.020502279202143

Epoch: 5| Step: 11
Training loss: 0.9775713086128235
Validation loss: 2.110898122191429

Epoch: 163| Step: 0
Training loss: 1.7293363809585571
Validation loss: 2.026015351215998

Epoch: 5| Step: 1
Training loss: 1.3952977657318115
Validation loss: 2.1380913654963174

Epoch: 5| Step: 2
Training loss: 1.8082683086395264
Validation loss: 2.1175889571507773

Epoch: 5| Step: 3
Training loss: 1.3911064863204956
Validation loss: 2.123960644006729

Epoch: 5| Step: 4
Training loss: 1.5997226238250732
Validation loss: 2.0680094212293625

Epoch: 5| Step: 5
Training loss: 1.3645045757293701
Validation loss: 2.098330025871595

Epoch: 5| Step: 6
Training loss: 1.7276370525360107
Validation loss: 2.0807350873947144

Epoch: 5| Step: 7
Training loss: 1.7050068378448486
Validation loss: 2.076816141605377

Epoch: 5| Step: 8
Training loss: 1.6640510559082031
Validation loss: 2.104994679490725

Epoch: 5| Step: 9
Training loss: 1.6289560794830322
Validation loss: 2.0741350750128427

Epoch: 5| Step: 10
Training loss: 1.3203107118606567
Validation loss: 2.132436603307724

Epoch: 5| Step: 11
Training loss: 1.3512545824050903
Validation loss: 2.1477958063284555

Epoch: 164| Step: 0
Training loss: 1.3158897161483765
Validation loss: 2.068551003932953

Epoch: 5| Step: 1
Training loss: 1.8964073657989502
Validation loss: 2.1592964629332223

Epoch: 5| Step: 2
Training loss: 1.41161048412323
Validation loss: 2.084370960791906

Epoch: 5| Step: 3
Training loss: 1.3324323892593384
Validation loss: 2.0947143932183585

Epoch: 5| Step: 4
Training loss: 2.1286990642547607
Validation loss: 2.0442854265371957

Epoch: 5| Step: 5
Training loss: 1.1320233345031738
Validation loss: 2.1386211017767587

Epoch: 5| Step: 6
Training loss: 1.5980358123779297
Validation loss: 2.146580085158348

Epoch: 5| Step: 7
Training loss: 1.288881540298462
Validation loss: 2.116575211286545

Epoch: 5| Step: 8
Training loss: 1.7070585489273071
Validation loss: 2.0536145170529685

Epoch: 5| Step: 9
Training loss: 1.6927322149276733
Validation loss: 2.0589496393998465

Epoch: 5| Step: 10
Training loss: 1.0194050073623657
Validation loss: 2.156548430522283

Epoch: 5| Step: 11
Training loss: 2.4170219898223877
Validation loss: 2.146937628587087

Epoch: 165| Step: 0
Training loss: 1.974639892578125
Validation loss: 2.045320674777031

Epoch: 5| Step: 1
Training loss: 1.5406800508499146
Validation loss: 2.0809926241636276

Epoch: 5| Step: 2
Training loss: 1.5365391969680786
Validation loss: 2.0777428398529687

Epoch: 5| Step: 3
Training loss: 1.0692192316055298
Validation loss: 2.163822134335836

Epoch: 5| Step: 4
Training loss: 1.1276214122772217
Validation loss: 2.0942452351252236

Epoch: 5| Step: 5
Training loss: 1.1859805583953857
Validation loss: 2.094301755229632

Epoch: 5| Step: 6
Training loss: 1.6663753986358643
Validation loss: 2.055675690372785

Epoch: 5| Step: 7
Training loss: 1.5083799362182617
Validation loss: 2.15798486272494

Epoch: 5| Step: 8
Training loss: 2.1605489253997803
Validation loss: 2.1112946420907974

Epoch: 5| Step: 9
Training loss: 1.7952533960342407
Validation loss: 2.152793064713478

Epoch: 5| Step: 10
Training loss: 1.3665950298309326
Validation loss: 2.161083738009135

Epoch: 5| Step: 11
Training loss: 0.5276949405670166
Validation loss: 2.2078884641329446

Epoch: 166| Step: 0
Training loss: 1.527942419052124
Validation loss: 2.3262942731380463

Epoch: 5| Step: 1
Training loss: 1.6658437252044678
Validation loss: 2.2867869238058725

Epoch: 5| Step: 2
Training loss: 1.9756805896759033
Validation loss: 2.33060551683108

Epoch: 5| Step: 3
Training loss: 1.7886689901351929
Validation loss: 2.2666329791148505

Epoch: 5| Step: 4
Training loss: 1.7072131633758545
Validation loss: 2.273859759171804

Epoch: 5| Step: 5
Training loss: 1.7414016723632812
Validation loss: 2.215101699034373

Epoch: 5| Step: 6
Training loss: 1.1959296464920044
Validation loss: 2.1799773077170053

Epoch: 5| Step: 7
Training loss: 1.353995442390442
Validation loss: 2.1257292528947196

Epoch: 5| Step: 8
Training loss: 1.649958610534668
Validation loss: 2.0780144184827805

Epoch: 5| Step: 9
Training loss: 1.573386549949646
Validation loss: 2.1616866191228232

Epoch: 5| Step: 10
Training loss: 1.525085210800171
Validation loss: 2.1026094804207482

Epoch: 5| Step: 11
Training loss: 2.076457977294922
Validation loss: 2.0886625548203788

Epoch: 167| Step: 0
Training loss: 1.409847617149353
Validation loss: 2.1205500861008963

Epoch: 5| Step: 1
Training loss: 1.7622429132461548
Validation loss: 2.1149014234542847

Epoch: 5| Step: 2
Training loss: 1.7031663656234741
Validation loss: 2.0889513989289603

Epoch: 5| Step: 3
Training loss: 0.8610799908638
Validation loss: 2.081025004386902

Epoch: 5| Step: 4
Training loss: 1.4922425746917725
Validation loss: 2.126084471742312

Epoch: 5| Step: 5
Training loss: 1.010080099105835
Validation loss: 2.064142718911171

Epoch: 5| Step: 6
Training loss: 1.403127908706665
Validation loss: 2.0748391499121985

Epoch: 5| Step: 7
Training loss: 2.149186372756958
Validation loss: 2.1619820098082223

Epoch: 5| Step: 8
Training loss: 1.6057037115097046
Validation loss: 2.113276263078054

Epoch: 5| Step: 9
Training loss: 1.615910291671753
Validation loss: 2.1410449147224426

Epoch: 5| Step: 10
Training loss: 1.3975574970245361
Validation loss: 2.1731020708878837

Epoch: 5| Step: 11
Training loss: 0.583915114402771
Validation loss: 2.143295203646024

Epoch: 168| Step: 0
Training loss: 1.5633447170257568
Validation loss: 2.135398199160894

Epoch: 5| Step: 1
Training loss: 1.6045221090316772
Validation loss: 2.1638008256753287

Epoch: 5| Step: 2
Training loss: 1.5767778158187866
Validation loss: 2.182509501775106

Epoch: 5| Step: 3
Training loss: 0.8907106518745422
Validation loss: 2.1229603389898934

Epoch: 5| Step: 4
Training loss: 1.8844331502914429
Validation loss: 2.13649753232797

Epoch: 5| Step: 5
Training loss: 1.2212889194488525
Validation loss: 2.173061023155848

Epoch: 5| Step: 6
Training loss: 1.1732566356658936
Validation loss: 2.1280189603567123

Epoch: 5| Step: 7
Training loss: 1.7066675424575806
Validation loss: 2.1223865151405334

Epoch: 5| Step: 8
Training loss: 1.4306061267852783
Validation loss: 2.0655406763156257

Epoch: 5| Step: 9
Training loss: 1.4085242748260498
Validation loss: 2.1015332539876304

Epoch: 5| Step: 10
Training loss: 2.0611157417297363
Validation loss: 2.0413904239734015

Epoch: 5| Step: 11
Training loss: 1.8772042989730835
Validation loss: 2.058061435818672

Epoch: 169| Step: 0
Training loss: 2.0370194911956787
Validation loss: 2.1150772869586945

Epoch: 5| Step: 1
Training loss: 1.3484753370285034
Validation loss: 2.110661596059799

Epoch: 5| Step: 2
Training loss: 1.0599005222320557
Validation loss: 2.10709972679615

Epoch: 5| Step: 3
Training loss: 1.3429285287857056
Validation loss: 2.1534833113352456

Epoch: 5| Step: 4
Training loss: 1.6748443841934204
Validation loss: 2.1331182022889457

Epoch: 5| Step: 5
Training loss: 1.5532935857772827
Validation loss: 2.060974955558777

Epoch: 5| Step: 6
Training loss: 1.5802252292633057
Validation loss: 2.231213311354319

Epoch: 5| Step: 7
Training loss: 1.0347657203674316
Validation loss: 2.1432254711786904

Epoch: 5| Step: 8
Training loss: 1.695291519165039
Validation loss: 2.1215463876724243

Epoch: 5| Step: 9
Training loss: 1.7138162851333618
Validation loss: 2.181938981016477

Epoch: 5| Step: 10
Training loss: 1.386793851852417
Validation loss: 2.1875781466563544

Epoch: 5| Step: 11
Training loss: 0.8524810075759888
Validation loss: 2.0929208000501

Epoch: 170| Step: 0
Training loss: 0.9255828857421875
Validation loss: 2.167037626107534

Epoch: 5| Step: 1
Training loss: 1.4693002700805664
Validation loss: 2.140103831887245

Epoch: 5| Step: 2
Training loss: 1.9222729206085205
Validation loss: 2.123302549123764

Epoch: 5| Step: 3
Training loss: 1.3936502933502197
Validation loss: 2.1038821885983148

Epoch: 5| Step: 4
Training loss: 1.8425365686416626
Validation loss: 2.1435143103202186

Epoch: 5| Step: 5
Training loss: 1.4992973804473877
Validation loss: 2.1304231882095337

Epoch: 5| Step: 6
Training loss: 1.6044104099273682
Validation loss: 2.104286715388298

Epoch: 5| Step: 7
Training loss: 1.8101155757904053
Validation loss: 2.1619247098763785

Epoch: 5| Step: 8
Training loss: 1.0934648513793945
Validation loss: 2.1270285844802856

Epoch: 5| Step: 9
Training loss: 1.432447075843811
Validation loss: 2.0827837040026984

Epoch: 5| Step: 10
Training loss: 1.3900725841522217
Validation loss: 2.0973177403211594

Epoch: 5| Step: 11
Training loss: 1.0070421695709229
Validation loss: 2.196599389115969

Epoch: 171| Step: 0
Training loss: 1.0367050170898438
Validation loss: 2.129694312810898

Epoch: 5| Step: 1
Training loss: 1.333182454109192
Validation loss: 2.140898714462916

Epoch: 5| Step: 2
Training loss: 1.2978804111480713
Validation loss: 2.075535555680593

Epoch: 5| Step: 3
Training loss: 1.9633632898330688
Validation loss: 2.0893688400586448

Epoch: 5| Step: 4
Training loss: 1.3134870529174805
Validation loss: 2.1041684498389563

Epoch: 5| Step: 5
Training loss: 1.530875563621521
Validation loss: 2.118652572234472

Epoch: 5| Step: 6
Training loss: 1.3856691122055054
Validation loss: 2.051068067550659

Epoch: 5| Step: 7
Training loss: 1.9256521463394165
Validation loss: 2.080727423230807

Epoch: 5| Step: 8
Training loss: 1.5816103219985962
Validation loss: 2.221216708421707

Epoch: 5| Step: 9
Training loss: 1.3298574686050415
Validation loss: 2.1075206299622855

Epoch: 5| Step: 10
Training loss: 1.8070123195648193
Validation loss: 2.169609626134237

Epoch: 5| Step: 11
Training loss: 1.342583417892456
Validation loss: 2.058670957883199

Epoch: 172| Step: 0
Training loss: 1.3680860996246338
Validation loss: 2.0979790737231574

Epoch: 5| Step: 1
Training loss: 1.3689963817596436
Validation loss: 2.076642553011576

Epoch: 5| Step: 2
Training loss: 1.3934944868087769
Validation loss: 2.0980434666077294

Epoch: 5| Step: 3
Training loss: 1.1793696880340576
Validation loss: 2.0427309324344

Epoch: 5| Step: 4
Training loss: 1.7022712230682373
Validation loss: 2.135324478149414

Epoch: 5| Step: 5
Training loss: 1.7429897785186768
Validation loss: 2.144696667790413

Epoch: 5| Step: 6
Training loss: 1.681614637374878
Validation loss: 2.084284702936808

Epoch: 5| Step: 7
Training loss: 1.193947434425354
Validation loss: 2.1167618284622827

Epoch: 5| Step: 8
Training loss: 1.312361717224121
Validation loss: 2.1215860247612

Epoch: 5| Step: 9
Training loss: 1.702945351600647
Validation loss: 2.1627067923545837

Epoch: 5| Step: 10
Training loss: 1.3606252670288086
Validation loss: 2.121327062447866

Epoch: 5| Step: 11
Training loss: 0.9283473491668701
Validation loss: 2.152196461955706

Epoch: 173| Step: 0
Training loss: 1.0621259212493896
Validation loss: 2.1871416022380195

Epoch: 5| Step: 1
Training loss: 1.2933776378631592
Validation loss: 2.1271202812592187

Epoch: 5| Step: 2
Training loss: 1.7542892694473267
Validation loss: 2.107786883910497

Epoch: 5| Step: 3
Training loss: 1.4629576206207275
Validation loss: 2.1907736162344613

Epoch: 5| Step: 4
Training loss: 1.2598196268081665
Validation loss: 2.1267400085926056

Epoch: 5| Step: 5
Training loss: 1.9605920314788818
Validation loss: 2.0860961774984994

Epoch: 5| Step: 6
Training loss: 1.548946738243103
Validation loss: 2.1356571118036904

Epoch: 5| Step: 7
Training loss: 1.7975075244903564
Validation loss: 2.1212492088476815

Epoch: 5| Step: 8
Training loss: 1.8164293766021729
Validation loss: 2.098918452858925

Epoch: 5| Step: 9
Training loss: 1.5244344472885132
Validation loss: 2.081444720427195

Epoch: 5| Step: 10
Training loss: 1.316014289855957
Validation loss: 2.129964937766393

Epoch: 5| Step: 11
Training loss: 1.1835895776748657
Validation loss: 2.121515562136968

Epoch: 174| Step: 0
Training loss: 1.2768481969833374
Validation loss: 2.109127322832743

Epoch: 5| Step: 1
Training loss: 2.097418785095215
Validation loss: 2.073022330800692

Epoch: 5| Step: 2
Training loss: 1.3915891647338867
Validation loss: 2.1553384214639664

Epoch: 5| Step: 3
Training loss: 1.5758898258209229
Validation loss: 2.1014735947052636

Epoch: 5| Step: 4
Training loss: 1.5703469514846802
Validation loss: 2.048337529102961

Epoch: 5| Step: 5
Training loss: 1.2153111696243286
Validation loss: 2.1589809457461038

Epoch: 5| Step: 6
Training loss: 1.279109239578247
Validation loss: 2.082123359044393

Epoch: 5| Step: 7
Training loss: 1.004620909690857
Validation loss: 2.184096078077952

Epoch: 5| Step: 8
Training loss: 1.5897650718688965
Validation loss: 2.1214995433886847

Epoch: 5| Step: 9
Training loss: 1.021188497543335
Validation loss: 2.166483928759893

Epoch: 5| Step: 10
Training loss: 1.7108056545257568
Validation loss: 2.126700465877851

Epoch: 5| Step: 11
Training loss: 1.4437291622161865
Validation loss: 2.1365194420019784

Epoch: 175| Step: 0
Training loss: 1.3371165990829468
Validation loss: 2.2027579297622046

Epoch: 5| Step: 1
Training loss: 1.966528296470642
Validation loss: 2.1011353383461633

Epoch: 5| Step: 2
Training loss: 0.878426730632782
Validation loss: 2.1248056987921395

Epoch: 5| Step: 3
Training loss: 0.8548526763916016
Validation loss: 2.096721440553665

Epoch: 5| Step: 4
Training loss: 1.2236251831054688
Validation loss: 2.081196372707685

Epoch: 5| Step: 5
Training loss: 1.3307464122772217
Validation loss: 2.1078240871429443

Epoch: 5| Step: 6
Training loss: 1.9549076557159424
Validation loss: 2.1055268744627633

Epoch: 5| Step: 7
Training loss: 1.323283076286316
Validation loss: 2.107063819964727

Epoch: 5| Step: 8
Training loss: 1.4856168031692505
Validation loss: 2.1029199957847595

Epoch: 5| Step: 9
Training loss: 1.9198423624038696
Validation loss: 2.147738734881083

Epoch: 5| Step: 10
Training loss: 1.8404428958892822
Validation loss: 2.0854115337133408

Epoch: 5| Step: 11
Training loss: 1.3060200214385986
Validation loss: 2.162527769804001

Epoch: 176| Step: 0
Training loss: 1.122742772102356
Validation loss: 2.151536598801613

Epoch: 5| Step: 1
Training loss: 1.9603713750839233
Validation loss: 2.174048274755478

Epoch: 5| Step: 2
Training loss: 1.7413866519927979
Validation loss: 2.1300535003344216

Epoch: 5| Step: 3
Training loss: 1.6610214710235596
Validation loss: 2.1738689293464026

Epoch: 5| Step: 4
Training loss: 1.52078115940094
Validation loss: 2.1786964535713196

Epoch: 5| Step: 5
Training loss: 1.1592650413513184
Validation loss: 2.1329722702503204

Epoch: 5| Step: 6
Training loss: 1.3250541687011719
Validation loss: 2.1556842972834906

Epoch: 5| Step: 7
Training loss: 1.4921764135360718
Validation loss: 2.176913241545359

Epoch: 5| Step: 8
Training loss: 1.1833620071411133
Validation loss: 2.1255658864974976

Epoch: 5| Step: 9
Training loss: 1.3964492082595825
Validation loss: 2.1116482466459274

Epoch: 5| Step: 10
Training loss: 1.2641611099243164
Validation loss: 2.0556927770376205

Epoch: 5| Step: 11
Training loss: 1.9786880016326904
Validation loss: 2.1202104638020196

Epoch: 177| Step: 0
Training loss: 1.363277792930603
Validation loss: 2.1335909267266593

Epoch: 5| Step: 1
Training loss: 2.0917255878448486
Validation loss: 2.0808695455392203

Epoch: 5| Step: 2
Training loss: 1.2514430284500122
Validation loss: 2.1331032613913217

Epoch: 5| Step: 3
Training loss: 1.295243501663208
Validation loss: 2.0907691717147827

Epoch: 5| Step: 4
Training loss: 1.101793646812439
Validation loss: 2.0581994553407035

Epoch: 5| Step: 5
Training loss: 1.3356181383132935
Validation loss: 2.2043459117412567

Epoch: 5| Step: 6
Training loss: 1.4631106853485107
Validation loss: 2.16341495513916

Epoch: 5| Step: 7
Training loss: 1.715990662574768
Validation loss: 2.165908381342888

Epoch: 5| Step: 8
Training loss: 1.7390410900115967
Validation loss: 2.1448270628849664

Epoch: 5| Step: 9
Training loss: 0.9180179834365845
Validation loss: 2.1781155268351235

Epoch: 5| Step: 10
Training loss: 1.8093936443328857
Validation loss: 2.164920245607694

Epoch: 5| Step: 11
Training loss: 1.9341011047363281
Validation loss: 2.1558436254660287

Epoch: 178| Step: 0
Training loss: 1.5100294351577759
Validation loss: 2.034819404284159

Epoch: 5| Step: 1
Training loss: 1.5322630405426025
Validation loss: 2.0715209196011224

Epoch: 5| Step: 2
Training loss: 0.8332265615463257
Validation loss: 2.156402885913849

Epoch: 5| Step: 3
Training loss: 2.030688524246216
Validation loss: 2.1191387871901193

Epoch: 5| Step: 4
Training loss: 1.2525943517684937
Validation loss: 2.15285853544871

Epoch: 5| Step: 5
Training loss: 1.6182382106781006
Validation loss: 2.149053062001864

Epoch: 5| Step: 6
Training loss: 1.8191276788711548
Validation loss: 2.103379468123118

Epoch: 5| Step: 7
Training loss: 1.18230140209198
Validation loss: 2.093438814083735

Epoch: 5| Step: 8
Training loss: 1.8732101917266846
Validation loss: 2.0957659035921097

Epoch: 5| Step: 9
Training loss: 1.167751431465149
Validation loss: 2.1209940115610757

Epoch: 5| Step: 10
Training loss: 1.2197519540786743
Validation loss: 2.1397849718729653

Epoch: 5| Step: 11
Training loss: 1.0816733837127686
Validation loss: 2.0739902357260385

Epoch: 179| Step: 0
Training loss: 1.8669525384902954
Validation loss: 2.1411465207735696

Epoch: 5| Step: 1
Training loss: 1.601804494857788
Validation loss: 2.169180696209272

Epoch: 5| Step: 2
Training loss: 1.2029532194137573
Validation loss: 2.1338555614153543

Epoch: 5| Step: 3
Training loss: 1.5472310781478882
Validation loss: 2.195210427045822

Epoch: 5| Step: 4
Training loss: 1.3917286396026611
Validation loss: 2.151496112346649

Epoch: 5| Step: 5
Training loss: 1.2790193557739258
Validation loss: 2.1404690941174827

Epoch: 5| Step: 6
Training loss: 0.9683563113212585
Validation loss: 2.0925528158744178

Epoch: 5| Step: 7
Training loss: 1.3850224018096924
Validation loss: 2.1627495835224786

Epoch: 5| Step: 8
Training loss: 1.3143634796142578
Validation loss: 2.0993315478165946

Epoch: 5| Step: 9
Training loss: 1.1851166486740112
Validation loss: 2.077294265230497

Epoch: 5| Step: 10
Training loss: 1.459183931350708
Validation loss: 2.1758296539386115

Epoch: 5| Step: 11
Training loss: 2.347203493118286
Validation loss: 2.0681461493174234

Epoch: 180| Step: 0
Training loss: 1.3686769008636475
Validation loss: 2.101035386323929

Epoch: 5| Step: 1
Training loss: 1.7917531728744507
Validation loss: 2.1378781298796334

Epoch: 5| Step: 2
Training loss: 1.8644301891326904
Validation loss: 2.1604762077331543

Epoch: 5| Step: 3
Training loss: 1.0125343799591064
Validation loss: 2.0784857918818793

Epoch: 5| Step: 4
Training loss: 1.1894521713256836
Validation loss: 2.1432751268148422

Epoch: 5| Step: 5
Training loss: 1.1764498949050903
Validation loss: 2.093648041288058

Epoch: 5| Step: 6
Training loss: 1.3561680316925049
Validation loss: 2.207571491599083

Epoch: 5| Step: 7
Training loss: 1.5462863445281982
Validation loss: 2.1392277578512826

Epoch: 5| Step: 8
Training loss: 1.6254488229751587
Validation loss: 2.0495255341132483

Epoch: 5| Step: 9
Training loss: 1.1605784893035889
Validation loss: 2.1375024567047753

Epoch: 5| Step: 10
Training loss: 1.757420301437378
Validation loss: 2.1782748649517694

Epoch: 5| Step: 11
Training loss: 1.5261211395263672
Validation loss: 2.1884720722834268

Epoch: 181| Step: 0
Training loss: 1.0504114627838135
Validation loss: 2.169035464525223

Epoch: 5| Step: 1
Training loss: 1.5173273086547852
Validation loss: 2.1364706655343375

Epoch: 5| Step: 2
Training loss: 0.9994071125984192
Validation loss: 2.164262533187866

Epoch: 5| Step: 3
Training loss: 1.1271495819091797
Validation loss: 2.1333376467227936

Epoch: 5| Step: 4
Training loss: 1.1324583292007446
Validation loss: 2.112546682357788

Epoch: 5| Step: 5
Training loss: 1.307985544204712
Validation loss: 2.1670774817466736

Epoch: 5| Step: 6
Training loss: 1.8122574090957642
Validation loss: 2.1219779352347055

Epoch: 5| Step: 7
Training loss: 1.6412321329116821
Validation loss: 2.1804440220197043

Epoch: 5| Step: 8
Training loss: 1.5208872556686401
Validation loss: 2.1224204202493033

Epoch: 5| Step: 9
Training loss: 2.0763375759124756
Validation loss: 2.2187605698903403

Epoch: 5| Step: 10
Training loss: 1.1085739135742188
Validation loss: 2.101737211147944

Epoch: 5| Step: 11
Training loss: 1.6270040273666382
Validation loss: 2.0969438950220742

Epoch: 182| Step: 0
Training loss: 0.7088309526443481
Validation loss: 2.0650090475877128

Epoch: 5| Step: 1
Training loss: 1.585019826889038
Validation loss: 2.2276165783405304

Epoch: 5| Step: 2
Training loss: 1.2113136053085327
Validation loss: 2.1034303307533264

Epoch: 5| Step: 3
Training loss: 1.3605337142944336
Validation loss: 2.182696064313253

Epoch: 5| Step: 4
Training loss: 2.3630599975585938
Validation loss: 2.165089468161265

Epoch: 5| Step: 5
Training loss: 1.405696153640747
Validation loss: 2.169633294145266

Epoch: 5| Step: 6
Training loss: 1.398759126663208
Validation loss: 2.091325983405113

Epoch: 5| Step: 7
Training loss: 1.530163049697876
Validation loss: 2.1388719975948334

Epoch: 5| Step: 8
Training loss: 0.9692732095718384
Validation loss: 2.1717379838228226

Epoch: 5| Step: 9
Training loss: 1.3205019235610962
Validation loss: 2.0801609456539154

Epoch: 5| Step: 10
Training loss: 1.0674817562103271
Validation loss: 2.1277074118455253

Epoch: 5| Step: 11
Training loss: 2.105241298675537
Validation loss: 2.171590874592463

Epoch: 183| Step: 0
Training loss: 0.9706462621688843
Validation loss: 2.077654873331388

Epoch: 5| Step: 1
Training loss: 1.764379858970642
Validation loss: 2.0911973665157952

Epoch: 5| Step: 2
Training loss: 1.286689281463623
Validation loss: 2.1445795198281608

Epoch: 5| Step: 3
Training loss: 1.1085652112960815
Validation loss: 2.1848327418168387

Epoch: 5| Step: 4
Training loss: 1.314880609512329
Validation loss: 2.1380996803442636

Epoch: 5| Step: 5
Training loss: 1.8194373846054077
Validation loss: 2.1172251949707666

Epoch: 5| Step: 6
Training loss: 1.5975242853164673
Validation loss: 2.195698603987694

Epoch: 5| Step: 7
Training loss: 0.8542459607124329
Validation loss: 2.1859226326147714

Epoch: 5| Step: 8
Training loss: 1.3121007680892944
Validation loss: 2.11225655178229

Epoch: 5| Step: 9
Training loss: 1.6135129928588867
Validation loss: 2.101993744572004

Epoch: 5| Step: 10
Training loss: 1.373988151550293
Validation loss: 2.160042146841685

Epoch: 5| Step: 11
Training loss: 2.67077898979187
Validation loss: 2.179940933982531

Epoch: 184| Step: 0
Training loss: 1.9506568908691406
Validation loss: 2.156841278076172

Epoch: 5| Step: 1
Training loss: 1.2865021228790283
Validation loss: 2.1367475589116416

Epoch: 5| Step: 2
Training loss: 1.1825844049453735
Validation loss: 2.0663425674041114

Epoch: 5| Step: 3
Training loss: 1.5521202087402344
Validation loss: 2.0961561550696692

Epoch: 5| Step: 4
Training loss: 0.8683069348335266
Validation loss: 2.1005612711111703

Epoch: 5| Step: 5
Training loss: 0.8337418437004089
Validation loss: 2.1658783654371896

Epoch: 5| Step: 6
Training loss: 1.20831298828125
Validation loss: 2.035475413004557

Epoch: 5| Step: 7
Training loss: 0.9597634077072144
Validation loss: 2.1898309340079627

Epoch: 5| Step: 8
Training loss: 1.6918630599975586
Validation loss: 2.169325510660807

Epoch: 5| Step: 9
Training loss: 1.521633267402649
Validation loss: 2.2311699042717614

Epoch: 5| Step: 10
Training loss: 1.5252680778503418
Validation loss: 2.1931138038635254

Epoch: 5| Step: 11
Training loss: 0.9441631436347961
Validation loss: 2.15114326775074

Epoch: 185| Step: 0
Training loss: 1.3048021793365479
Validation loss: 2.2838125179211297

Epoch: 5| Step: 1
Training loss: 1.4851101636886597
Validation loss: 2.225978637735049

Epoch: 5| Step: 2
Training loss: 1.560970664024353
Validation loss: 2.2393832355737686

Epoch: 5| Step: 3
Training loss: 2.0478878021240234
Validation loss: 2.1744434386491776

Epoch: 5| Step: 4
Training loss: 1.3154653310775757
Validation loss: 2.2058720936377845

Epoch: 5| Step: 5
Training loss: 1.3460214138031006
Validation loss: 2.135547856489817

Epoch: 5| Step: 6
Training loss: 0.9388402700424194
Validation loss: 2.16200419763724

Epoch: 5| Step: 7
Training loss: 1.6356019973754883
Validation loss: 2.181663637359937

Epoch: 5| Step: 8
Training loss: 1.6300404071807861
Validation loss: 2.193356826901436

Epoch: 5| Step: 9
Training loss: 1.235364556312561
Validation loss: 2.183805376291275

Epoch: 5| Step: 10
Training loss: 1.4088077545166016
Validation loss: 2.1585400899251304

Epoch: 5| Step: 11
Training loss: 1.3333288431167603
Validation loss: 2.18416898449262

Epoch: 186| Step: 0
Training loss: 1.2636638879776
Validation loss: 2.158402979373932

Epoch: 5| Step: 1
Training loss: 1.4839189052581787
Validation loss: 2.1544448087612786

Epoch: 5| Step: 2
Training loss: 1.8820312023162842
Validation loss: 2.106383134921392

Epoch: 5| Step: 3
Training loss: 1.208094835281372
Validation loss: 2.136136462291082

Epoch: 5| Step: 4
Training loss: 1.319146752357483
Validation loss: 2.14624751607577

Epoch: 5| Step: 5
Training loss: 0.8796404004096985
Validation loss: 2.1834967782100043

Epoch: 5| Step: 6
Training loss: 1.524590253829956
Validation loss: 2.102584719657898

Epoch: 5| Step: 7
Training loss: 1.2166022062301636
Validation loss: 2.1659076114495597

Epoch: 5| Step: 8
Training loss: 1.1452929973602295
Validation loss: 2.1080360114574432

Epoch: 5| Step: 9
Training loss: 1.2280834913253784
Validation loss: 2.1038365761439004

Epoch: 5| Step: 10
Training loss: 1.5695613622665405
Validation loss: 2.158689960837364

Epoch: 5| Step: 11
Training loss: 1.1728098392486572
Validation loss: 2.1423457910617194

Epoch: 187| Step: 0
Training loss: 1.373626708984375
Validation loss: 2.1076130668322244

Epoch: 5| Step: 1
Training loss: 1.9390255212783813
Validation loss: 2.1806990702946982

Epoch: 5| Step: 2
Training loss: 1.1158579587936401
Validation loss: 2.1359347999095917

Epoch: 5| Step: 3
Training loss: 1.8318462371826172
Validation loss: 2.1337857792774835

Epoch: 5| Step: 4
Training loss: 1.3809864521026611
Validation loss: 2.1795342564582825

Epoch: 5| Step: 5
Training loss: 1.4663736820220947
Validation loss: 2.0913840730985007

Epoch: 5| Step: 6
Training loss: 0.7529510259628296
Validation loss: 2.1245557069778442

Epoch: 5| Step: 7
Training loss: 1.6532888412475586
Validation loss: 2.0542901108662286

Epoch: 5| Step: 8
Training loss: 1.0292413234710693
Validation loss: 2.1964816004037857

Epoch: 5| Step: 9
Training loss: 1.0381700992584229
Validation loss: 2.1188344061374664

Epoch: 5| Step: 10
Training loss: 1.2592179775238037
Validation loss: 2.1282971998055777

Epoch: 5| Step: 11
Training loss: 1.1752700805664062
Validation loss: 2.201612209280332

Epoch: 188| Step: 0
Training loss: 0.8883345723152161
Validation loss: 2.1091776688893638

Epoch: 5| Step: 1
Training loss: 0.9690677523612976
Validation loss: 2.1806934227546058

Epoch: 5| Step: 2
Training loss: 1.1944419145584106
Validation loss: 2.1683261543512344

Epoch: 5| Step: 3
Training loss: 1.3390328884124756
Validation loss: 2.2149460961421332

Epoch: 5| Step: 4
Training loss: 1.3401687145233154
Validation loss: 2.2425569693247476

Epoch: 5| Step: 5
Training loss: 1.6806358098983765
Validation loss: 2.205887089172999

Epoch: 5| Step: 6
Training loss: 1.282806396484375
Validation loss: 2.175928602615992

Epoch: 5| Step: 7
Training loss: 1.8805453777313232
Validation loss: 2.1656058927377067

Epoch: 5| Step: 8
Training loss: 1.5057483911514282
Validation loss: 2.1169199347496033

Epoch: 5| Step: 9
Training loss: 1.2359956502914429
Validation loss: 2.187558392683665

Epoch: 5| Step: 10
Training loss: 1.5332595109939575
Validation loss: 2.2100556194782257

Epoch: 5| Step: 11
Training loss: 1.281907558441162
Validation loss: 2.054032320777575

Epoch: 189| Step: 0
Training loss: 1.1409090757369995
Validation loss: 2.124577114979426

Epoch: 5| Step: 1
Training loss: 1.3994293212890625
Validation loss: 2.117282415429751

Epoch: 5| Step: 2
Training loss: 1.2633522748947144
Validation loss: 2.1172159959872565

Epoch: 5| Step: 3
Training loss: 1.5012595653533936
Validation loss: 2.1361783941586814

Epoch: 5| Step: 4
Training loss: 1.3525022268295288
Validation loss: 2.1776909083127975

Epoch: 5| Step: 5
Training loss: 1.013778567314148
Validation loss: 2.1521749794483185

Epoch: 5| Step: 6
Training loss: 1.374986171722412
Validation loss: 2.171679606040319

Epoch: 5| Step: 7
Training loss: 1.2508857250213623
Validation loss: 2.1513067136208215

Epoch: 5| Step: 8
Training loss: 1.558882713317871
Validation loss: 2.127301037311554

Epoch: 5| Step: 9
Training loss: 1.0002808570861816
Validation loss: 2.1002597212791443

Epoch: 5| Step: 10
Training loss: 1.6497280597686768
Validation loss: 2.110930929581324

Epoch: 5| Step: 11
Training loss: 0.9878299832344055
Validation loss: 2.135619526108106

Epoch: 190| Step: 0
Training loss: 1.3721199035644531
Validation loss: 2.1906079153219857

Epoch: 5| Step: 1
Training loss: 1.719323754310608
Validation loss: 2.2047061175107956

Epoch: 5| Step: 2
Training loss: 1.8429744243621826
Validation loss: 2.138849660754204

Epoch: 5| Step: 3
Training loss: 1.052678108215332
Validation loss: 2.230364516377449

Epoch: 5| Step: 4
Training loss: 1.3208482265472412
Validation loss: 2.185661569237709

Epoch: 5| Step: 5
Training loss: 1.2920124530792236
Validation loss: 2.1877846270799637

Epoch: 5| Step: 6
Training loss: 1.2876590490341187
Validation loss: 2.1554028540849686

Epoch: 5| Step: 7
Training loss: 1.504719614982605
Validation loss: 2.2204984724521637

Epoch: 5| Step: 8
Training loss: 0.7593428492546082
Validation loss: 2.1713529278834662

Epoch: 5| Step: 9
Training loss: 0.9180242419242859
Validation loss: 2.2469702462355294

Epoch: 5| Step: 10
Training loss: 1.3854094743728638
Validation loss: 2.0809121628602347

Epoch: 5| Step: 11
Training loss: 0.6753096580505371
Validation loss: 2.1344670255978904

Epoch: 191| Step: 0
Training loss: 1.19960618019104
Validation loss: 2.070315192143122

Epoch: 5| Step: 1
Training loss: 1.5208740234375
Validation loss: 2.1395954539378486

Epoch: 5| Step: 2
Training loss: 1.3015458583831787
Validation loss: 2.1111839363972345

Epoch: 5| Step: 3
Training loss: 1.4100136756896973
Validation loss: 2.1150569717089334

Epoch: 5| Step: 4
Training loss: 1.6640393733978271
Validation loss: 2.178094203273455

Epoch: 5| Step: 5
Training loss: 1.2201383113861084
Validation loss: 2.167288064956665

Epoch: 5| Step: 6
Training loss: 1.2314834594726562
Validation loss: 2.150733088453611

Epoch: 5| Step: 7
Training loss: 0.9709209203720093
Validation loss: 2.116708313425382

Epoch: 5| Step: 8
Training loss: 1.6848223209381104
Validation loss: 2.1507295270760856

Epoch: 5| Step: 9
Training loss: 1.3088133335113525
Validation loss: 2.148480316003164

Epoch: 5| Step: 10
Training loss: 1.3048988580703735
Validation loss: 2.2036002377669015

Epoch: 5| Step: 11
Training loss: 0.6218411326408386
Validation loss: 2.0439628809690475

Epoch: 192| Step: 0
Training loss: 1.3859232664108276
Validation loss: 2.1298659443855286

Epoch: 5| Step: 1
Training loss: 1.844171166419983
Validation loss: 2.073967253168424

Epoch: 5| Step: 2
Training loss: 1.0755393505096436
Validation loss: 2.0878043373425803

Epoch: 5| Step: 3
Training loss: 1.1529544591903687
Validation loss: 2.1206914484500885

Epoch: 5| Step: 4
Training loss: 1.5611145496368408
Validation loss: 2.142356658975283

Epoch: 5| Step: 5
Training loss: 1.2239755392074585
Validation loss: 2.1359518071015677

Epoch: 5| Step: 6
Training loss: 1.4346009492874146
Validation loss: 2.1441146234671273

Epoch: 5| Step: 7
Training loss: 0.6333048939704895
Validation loss: 2.1243161211411157

Epoch: 5| Step: 8
Training loss: 1.033202886581421
Validation loss: 2.190888981024424

Epoch: 5| Step: 9
Training loss: 1.2536293268203735
Validation loss: 2.189361497759819

Epoch: 5| Step: 10
Training loss: 1.4517205953598022
Validation loss: 2.161878446737925

Epoch: 5| Step: 11
Training loss: 1.1191484928131104
Validation loss: 2.179737771550814

Epoch: 193| Step: 0
Training loss: 1.1123460531234741
Validation loss: 2.220384935537974

Epoch: 5| Step: 1
Training loss: 1.6837785243988037
Validation loss: 2.1104924033085504

Epoch: 5| Step: 2
Training loss: 1.0818217992782593
Validation loss: 2.095100333293279

Epoch: 5| Step: 3
Training loss: 1.8657119274139404
Validation loss: 2.1536671121915183

Epoch: 5| Step: 4
Training loss: 1.4688730239868164
Validation loss: 2.1592420637607574

Epoch: 5| Step: 5
Training loss: 1.1648746728897095
Validation loss: 2.181803067525228

Epoch: 5| Step: 6
Training loss: 1.2351568937301636
Validation loss: 2.2098692456881204

Epoch: 5| Step: 7
Training loss: 1.2391520738601685
Validation loss: 2.19794899225235

Epoch: 5| Step: 8
Training loss: 1.227912425994873
Validation loss: 2.1915022929509482

Epoch: 5| Step: 9
Training loss: 1.2523759603500366
Validation loss: 2.1983665078878403

Epoch: 5| Step: 10
Training loss: 1.1703388690948486
Validation loss: 2.1581344356139502

Epoch: 5| Step: 11
Training loss: 2.2934439182281494
Validation loss: 2.157181436816851

Epoch: 194| Step: 0
Training loss: 0.8219515681266785
Validation loss: 2.1533601135015488

Epoch: 5| Step: 1
Training loss: 1.3305922746658325
Validation loss: 2.1442063500483832

Epoch: 5| Step: 2
Training loss: 1.1863789558410645
Validation loss: 2.1977234333753586

Epoch: 5| Step: 3
Training loss: 1.6556293964385986
Validation loss: 2.1728997230529785

Epoch: 5| Step: 4
Training loss: 1.1750948429107666
Validation loss: 2.029950256148974

Epoch: 5| Step: 5
Training loss: 1.5380463600158691
Validation loss: 2.0767989506324134

Epoch: 5| Step: 6
Training loss: 1.1084200143814087
Validation loss: 2.0924284855524697

Epoch: 5| Step: 7
Training loss: 1.7759660482406616
Validation loss: 2.171975707014402

Epoch: 5| Step: 8
Training loss: 1.331749439239502
Validation loss: 2.1291382014751434

Epoch: 5| Step: 9
Training loss: 1.1293164491653442
Validation loss: 2.1161022931337357

Epoch: 5| Step: 10
Training loss: 1.0880005359649658
Validation loss: 2.1341682970523834

Epoch: 5| Step: 11
Training loss: 1.4123420715332031
Validation loss: 2.1953099071979523

Epoch: 195| Step: 0
Training loss: 1.6809629201889038
Validation loss: 2.142239511013031

Epoch: 5| Step: 1
Training loss: 1.397864818572998
Validation loss: 2.191020796696345

Epoch: 5| Step: 2
Training loss: 1.3261950016021729
Validation loss: 2.2031586319208145

Epoch: 5| Step: 3
Training loss: 1.2715237140655518
Validation loss: 2.1238035957018533

Epoch: 5| Step: 4
Training loss: 0.8214460611343384
Validation loss: 2.156523441274961

Epoch: 5| Step: 5
Training loss: 1.2501479387283325
Validation loss: 2.116287872195244

Epoch: 5| Step: 6
Training loss: 0.9164284467697144
Validation loss: 2.1183832933505378

Epoch: 5| Step: 7
Training loss: 1.0788377523422241
Validation loss: 2.154617135723432

Epoch: 5| Step: 8
Training loss: 1.3682748079299927
Validation loss: 2.172041912873586

Epoch: 5| Step: 9
Training loss: 1.0529515743255615
Validation loss: 2.129813035329183

Epoch: 5| Step: 10
Training loss: 1.2406935691833496
Validation loss: 2.1799490253130593

Epoch: 5| Step: 11
Training loss: 1.6111340522766113
Validation loss: 2.2133994698524475

Epoch: 196| Step: 0
Training loss: 1.0503060817718506
Validation loss: 2.102876752614975

Epoch: 5| Step: 1
Training loss: 1.205793023109436
Validation loss: 2.159553368886312

Epoch: 5| Step: 2
Training loss: 1.3436510562896729
Validation loss: 2.190009946624438

Epoch: 5| Step: 3
Training loss: 1.61312997341156
Validation loss: 2.1916245917479196

Epoch: 5| Step: 4
Training loss: 1.090258002281189
Validation loss: 2.24085825184981

Epoch: 5| Step: 5
Training loss: 1.3410699367523193
Validation loss: 2.1927785774072013

Epoch: 5| Step: 6
Training loss: 1.1394500732421875
Validation loss: 2.1208156645298004

Epoch: 5| Step: 7
Training loss: 1.0478017330169678
Validation loss: 2.093509847919146

Epoch: 5| Step: 8
Training loss: 1.2135564088821411
Validation loss: 2.189755151669184

Epoch: 5| Step: 9
Training loss: 1.3931827545166016
Validation loss: 2.2106040666500726

Epoch: 5| Step: 10
Training loss: 1.3739826679229736
Validation loss: 2.155417333046595

Epoch: 5| Step: 11
Training loss: 1.7814812660217285
Validation loss: 2.2452588180700936

Epoch: 197| Step: 0
Training loss: 1.5262174606323242
Validation loss: 2.2379129032293954

Epoch: 5| Step: 1
Training loss: 1.2751070261001587
Validation loss: 2.2221092780431113

Epoch: 5| Step: 2
Training loss: 1.4993059635162354
Validation loss: 2.157892013589541

Epoch: 5| Step: 3
Training loss: 1.488581657409668
Validation loss: 2.1705320179462433

Epoch: 5| Step: 4
Training loss: 1.0712424516677856
Validation loss: 2.172605037689209

Epoch: 5| Step: 5
Training loss: 0.9074430465698242
Validation loss: 2.128739655017853

Epoch: 5| Step: 6
Training loss: 1.235087275505066
Validation loss: 2.1951717535654702

Epoch: 5| Step: 7
Training loss: 1.301086664199829
Validation loss: 2.14999653895696

Epoch: 5| Step: 8
Training loss: 1.7781760692596436
Validation loss: 2.21984871228536

Epoch: 5| Step: 9
Training loss: 1.0227410793304443
Validation loss: 2.1117527385552726

Epoch: 5| Step: 10
Training loss: 1.1135648488998413
Validation loss: 2.193585773309072

Epoch: 5| Step: 11
Training loss: 0.5016006231307983
Validation loss: 2.119508738319079

Epoch: 198| Step: 0
Training loss: 1.1434307098388672
Validation loss: 2.11105186243852

Epoch: 5| Step: 1
Training loss: 1.0032905340194702
Validation loss: 2.185284594694773

Epoch: 5| Step: 2
Training loss: 0.8152692914009094
Validation loss: 2.1336117138465247

Epoch: 5| Step: 3
Training loss: 1.2087756395339966
Validation loss: 2.2064162393411

Epoch: 5| Step: 4
Training loss: 1.2784135341644287
Validation loss: 2.1470645715792975

Epoch: 5| Step: 5
Training loss: 1.2709394693374634
Validation loss: 2.185671418905258

Epoch: 5| Step: 6
Training loss: 1.5130952596664429
Validation loss: 2.1306868145863214

Epoch: 5| Step: 7
Training loss: 0.9608853459358215
Validation loss: 2.1915608992179236

Epoch: 5| Step: 8
Training loss: 1.274709939956665
Validation loss: 2.1874343156814575

Epoch: 5| Step: 9
Training loss: 1.7385247945785522
Validation loss: 2.1609951108694077

Epoch: 5| Step: 10
Training loss: 0.992626965045929
Validation loss: 2.161701202392578

Epoch: 5| Step: 11
Training loss: 1.3049964904785156
Validation loss: 2.219645400842031

Epoch: 199| Step: 0
Training loss: 1.1921055316925049
Validation loss: 2.1193273067474365

Epoch: 5| Step: 1
Training loss: 1.6137832403182983
Validation loss: 2.1681264142195382

Epoch: 5| Step: 2
Training loss: 0.8804235458374023
Validation loss: 2.1944258511066437

Epoch: 5| Step: 3
Training loss: 1.2802518606185913
Validation loss: 2.134304011861483

Epoch: 5| Step: 4
Training loss: 0.7652338743209839
Validation loss: 2.183743347724279

Epoch: 5| Step: 5
Training loss: 1.6950862407684326
Validation loss: 2.190956433614095

Epoch: 5| Step: 6
Training loss: 1.0675777196884155
Validation loss: 2.1526318540175757

Epoch: 5| Step: 7
Training loss: 1.3641345500946045
Validation loss: 2.137147217988968

Epoch: 5| Step: 8
Training loss: 1.1771790981292725
Validation loss: 2.178869922955831

Epoch: 5| Step: 9
Training loss: 1.2406971454620361
Validation loss: 2.210102746884028

Epoch: 5| Step: 10
Training loss: 1.2650706768035889
Validation loss: 2.211466297507286

Epoch: 5| Step: 11
Training loss: 0.23459666967391968
Validation loss: 2.2096959352493286

Epoch: 200| Step: 0
Training loss: 1.2181389331817627
Validation loss: 2.155432030558586

Epoch: 5| Step: 1
Training loss: 1.3267711400985718
Validation loss: 2.116169343392054

Epoch: 5| Step: 2
Training loss: 1.4246894121170044
Validation loss: 2.2246376474698386

Epoch: 5| Step: 3
Training loss: 1.344544768333435
Validation loss: 2.1732913653055825

Epoch: 5| Step: 4
Training loss: 0.9768613576889038
Validation loss: 2.1914352973302207

Epoch: 5| Step: 5
Training loss: 1.6732418537139893
Validation loss: 2.1388077636559806

Epoch: 5| Step: 6
Training loss: 1.2538299560546875
Validation loss: 2.216474244991938

Epoch: 5| Step: 7
Training loss: 1.334065318107605
Validation loss: 2.1678170959154763

Epoch: 5| Step: 8
Training loss: 1.0760103464126587
Validation loss: 2.225118468205134

Epoch: 5| Step: 9
Training loss: 1.1471991539001465
Validation loss: 2.35627818107605

Epoch: 5| Step: 10
Training loss: 1.3007242679595947
Validation loss: 2.180821567773819

Epoch: 5| Step: 11
Training loss: 1.4404382705688477
Validation loss: 2.2084575593471527

Epoch: 201| Step: 0
Training loss: 1.037019968032837
Validation loss: 2.2172529101371765

Epoch: 5| Step: 1
Training loss: 1.015014886856079
Validation loss: 2.204524040222168

Epoch: 5| Step: 2
Training loss: 1.2178194522857666
Validation loss: 2.1439620753129325

Epoch: 5| Step: 3
Training loss: 1.3660619258880615
Validation loss: 2.1668321192264557

Epoch: 5| Step: 4
Training loss: 1.2679646015167236
Validation loss: 2.180243199070295

Epoch: 5| Step: 5
Training loss: 1.2916487455368042
Validation loss: 2.178091898560524

Epoch: 5| Step: 6
Training loss: 1.1847940683364868
Validation loss: 2.2085940738519034

Epoch: 5| Step: 7
Training loss: 0.954611599445343
Validation loss: 2.129431034127871

Epoch: 5| Step: 8
Training loss: 1.9473237991333008
Validation loss: 2.180009494225184

Epoch: 5| Step: 9
Training loss: 0.9419762492179871
Validation loss: 2.255394622683525

Epoch: 5| Step: 10
Training loss: 1.2763298749923706
Validation loss: 2.1700819532076516

Epoch: 5| Step: 11
Training loss: 2.599841594696045
Validation loss: 2.225196808576584

Epoch: 202| Step: 0
Training loss: 1.447000503540039
Validation loss: 2.2261231740315757

Epoch: 5| Step: 1
Training loss: 1.3097501993179321
Validation loss: 2.2483138044675193

Epoch: 5| Step: 2
Training loss: 1.8030859231948853
Validation loss: 2.1895525505145392

Epoch: 5| Step: 3
Training loss: 1.3338191509246826
Validation loss: 2.197602113087972

Epoch: 5| Step: 4
Training loss: 0.9067090749740601
Validation loss: 2.1138788163661957

Epoch: 5| Step: 5
Training loss: 1.2878313064575195
Validation loss: 2.1623029311498008

Epoch: 5| Step: 6
Training loss: 1.8227401971817017
Validation loss: 2.133323540290197

Epoch: 5| Step: 7
Training loss: 1.3373074531555176
Validation loss: 2.228027512629827

Epoch: 5| Step: 8
Training loss: 0.9394274950027466
Validation loss: 2.2342385252316794

Epoch: 5| Step: 9
Training loss: 1.102846384048462
Validation loss: 2.1802307118972144

Epoch: 5| Step: 10
Training loss: 1.135683298110962
Validation loss: 2.174334163467089

Epoch: 5| Step: 11
Training loss: 0.9943696856498718
Validation loss: 2.112060566743215

Epoch: 203| Step: 0
Training loss: 0.6812058687210083
Validation loss: 2.2241062025229135

Epoch: 5| Step: 1
Training loss: 1.6518961191177368
Validation loss: 2.1936855216821036

Epoch: 5| Step: 2
Training loss: 1.4044042825698853
Validation loss: 2.2364185452461243

Epoch: 5| Step: 3
Training loss: 1.7509441375732422
Validation loss: 2.203110913435618

Epoch: 5| Step: 4
Training loss: 1.7536414861679077
Validation loss: 2.2420560121536255

Epoch: 5| Step: 5
Training loss: 1.1766687631607056
Validation loss: 2.237765451272329

Epoch: 5| Step: 6
Training loss: 0.9306885004043579
Validation loss: 2.182290941476822

Epoch: 5| Step: 7
Training loss: 1.513824462890625
Validation loss: 2.190189838409424

Epoch: 5| Step: 8
Training loss: 1.0897033214569092
Validation loss: 2.1356060256560645

Epoch: 5| Step: 9
Training loss: 0.7705071568489075
Validation loss: 2.1726776907841363

Epoch: 5| Step: 10
Training loss: 1.079689383506775
Validation loss: 2.120298147201538

Epoch: 5| Step: 11
Training loss: 0.2782599925994873
Validation loss: 2.258101135492325

Epoch: 204| Step: 0
Training loss: 0.8659793734550476
Validation loss: 2.1438187460104623

Epoch: 5| Step: 1
Training loss: 1.1173985004425049
Validation loss: 2.1910962611436844

Epoch: 5| Step: 2
Training loss: 1.534970998764038
Validation loss: 2.1316820482412973

Epoch: 5| Step: 3
Training loss: 1.0559098720550537
Validation loss: 2.1438602407773337

Epoch: 5| Step: 4
Training loss: 1.1344777345657349
Validation loss: 2.2406533608833947

Epoch: 5| Step: 5
Training loss: 1.101644515991211
Validation loss: 2.1893400301535926

Epoch: 5| Step: 6
Training loss: 0.9874000549316406
Validation loss: 2.2635672638813653

Epoch: 5| Step: 7
Training loss: 0.9687156677246094
Validation loss: 2.178540458281835

Epoch: 5| Step: 8
Training loss: 1.2945760488510132
Validation loss: 2.2424454987049103

Epoch: 5| Step: 9
Training loss: 1.7511018514633179
Validation loss: 2.175592710574468

Epoch: 5| Step: 10
Training loss: 1.5092308521270752
Validation loss: 2.175247768561045

Epoch: 5| Step: 11
Training loss: 0.7991259694099426
Validation loss: 2.233795856436094

Epoch: 205| Step: 0
Training loss: 1.0386512279510498
Validation loss: 2.1432217558224997

Epoch: 5| Step: 1
Training loss: 1.4649851322174072
Validation loss: 2.1073715140422187

Epoch: 5| Step: 2
Training loss: 0.8989179730415344
Validation loss: 2.156367669502894

Epoch: 5| Step: 3
Training loss: 1.1207762956619263
Validation loss: 2.224666014313698

Epoch: 5| Step: 4
Training loss: 1.1115009784698486
Validation loss: 2.2482888599236808

Epoch: 5| Step: 5
Training loss: 1.0051639080047607
Validation loss: 2.172001302242279

Epoch: 5| Step: 6
Training loss: 1.4099401235580444
Validation loss: 2.234574427207311

Epoch: 5| Step: 7
Training loss: 1.109195351600647
Validation loss: 2.2045109421014786

Epoch: 5| Step: 8
Training loss: 0.9774863123893738
Validation loss: 2.20686266819636

Epoch: 5| Step: 9
Training loss: 1.6992051601409912
Validation loss: 2.122917056083679

Epoch: 5| Step: 10
Training loss: 1.5624403953552246
Validation loss: 2.1798682709534964

Epoch: 5| Step: 11
Training loss: 1.064514398574829
Validation loss: 2.2258984247843423

Epoch: 206| Step: 0
Training loss: 1.1074693202972412
Validation loss: 2.2219878882169724

Epoch: 5| Step: 1
Training loss: 1.2110790014266968
Validation loss: 2.211744343241056

Epoch: 5| Step: 2
Training loss: 1.6365633010864258
Validation loss: 2.128550499677658

Epoch: 5| Step: 3
Training loss: 1.1732348203659058
Validation loss: 2.177007039388021

Epoch: 5| Step: 4
Training loss: 1.4515035152435303
Validation loss: 2.179208899537722

Epoch: 5| Step: 5
Training loss: 1.5597734451293945
Validation loss: 2.165491064389547

Epoch: 5| Step: 6
Training loss: 1.2852137088775635
Validation loss: 2.176026920477549

Epoch: 5| Step: 7
Training loss: 1.209341049194336
Validation loss: 2.1530290246009827

Epoch: 5| Step: 8
Training loss: 1.0661921501159668
Validation loss: 2.238697816928228

Epoch: 5| Step: 9
Training loss: 1.1743721961975098
Validation loss: 2.169408828020096

Epoch: 5| Step: 10
Training loss: 1.366081953048706
Validation loss: 2.2370340476433435

Epoch: 5| Step: 11
Training loss: 0.7199110984802246
Validation loss: 2.208999370535215

Epoch: 207| Step: 0
Training loss: 1.1646595001220703
Validation loss: 2.1247573097546897

Epoch: 5| Step: 1
Training loss: 1.1712418794631958
Validation loss: 2.145492121577263

Epoch: 5| Step: 2
Training loss: 1.1346582174301147
Validation loss: 2.2161606748898826

Epoch: 5| Step: 3
Training loss: 1.6303714513778687
Validation loss: 2.17635748287042

Epoch: 5| Step: 4
Training loss: 0.9902162551879883
Validation loss: 2.1377604752779007

Epoch: 5| Step: 5
Training loss: 1.098020076751709
Validation loss: 2.205637057622274

Epoch: 5| Step: 6
Training loss: 1.2471389770507812
Validation loss: 2.196784640351931

Epoch: 5| Step: 7
Training loss: 1.251050353050232
Validation loss: 2.1733258416255317

Epoch: 5| Step: 8
Training loss: 0.7636345624923706
Validation loss: 2.1466730535030365

Epoch: 5| Step: 9
Training loss: 1.533672571182251
Validation loss: 2.2541169077157974

Epoch: 5| Step: 10
Training loss: 1.1024219989776611
Validation loss: 2.2192202657461166

Epoch: 5| Step: 11
Training loss: 0.7380391359329224
Validation loss: 2.205976292490959

Epoch: 208| Step: 0
Training loss: 0.6845753192901611
Validation loss: 2.1932436724503837

Epoch: 5| Step: 1
Training loss: 1.2251076698303223
Validation loss: 2.1764309803644815

Epoch: 5| Step: 2
Training loss: 1.1219282150268555
Validation loss: 2.139895314971606

Epoch: 5| Step: 3
Training loss: 1.38306725025177
Validation loss: 2.313441718618075

Epoch: 5| Step: 4
Training loss: 1.3982067108154297
Validation loss: 2.216217984755834

Epoch: 5| Step: 5
Training loss: 1.2509276866912842
Validation loss: 2.205172965923945

Epoch: 5| Step: 6
Training loss: 1.0885307788848877
Validation loss: 2.191681439677874

Epoch: 5| Step: 7
Training loss: 1.609259009361267
Validation loss: 2.2499071856339774

Epoch: 5| Step: 8
Training loss: 0.7480444312095642
Validation loss: 2.2342728724082312

Epoch: 5| Step: 9
Training loss: 1.4964747428894043
Validation loss: 2.200715810060501

Epoch: 5| Step: 10
Training loss: 0.9549165964126587
Validation loss: 2.233462909857432

Epoch: 5| Step: 11
Training loss: 0.22648227214813232
Validation loss: 2.1674414028724036

Epoch: 209| Step: 0
Training loss: 1.6513324975967407
Validation loss: 2.190927411119143

Epoch: 5| Step: 1
Training loss: 1.1622262001037598
Validation loss: 2.3245162765185037

Epoch: 5| Step: 2
Training loss: 1.4729652404785156
Validation loss: 2.173048476378123

Epoch: 5| Step: 3
Training loss: 1.4586210250854492
Validation loss: 2.227741609017054

Epoch: 5| Step: 4
Training loss: 0.945285439491272
Validation loss: 2.1703602274258933

Epoch: 5| Step: 5
Training loss: 0.7620981335639954
Validation loss: 2.1773105611403785

Epoch: 5| Step: 6
Training loss: 1.097743034362793
Validation loss: 2.2215058505535126

Epoch: 5| Step: 7
Training loss: 0.9155101776123047
Validation loss: 2.2374999821186066

Epoch: 5| Step: 8
Training loss: 1.220764398574829
Validation loss: 2.3021273414293923

Epoch: 5| Step: 9
Training loss: 0.7672485113143921
Validation loss: 2.1717742582162223

Epoch: 5| Step: 10
Training loss: 0.9142570495605469
Validation loss: 2.223097870747248

Epoch: 5| Step: 11
Training loss: 2.4155285358428955
Validation loss: 2.207140326499939

Epoch: 210| Step: 0
Training loss: 1.1143656969070435
Validation loss: 2.1790125717719397

Epoch: 5| Step: 1
Training loss: 1.321793794631958
Validation loss: 2.251453469196955

Epoch: 5| Step: 2
Training loss: 0.8326939344406128
Validation loss: 2.2142394930124283

Epoch: 5| Step: 3
Training loss: 0.795394241809845
Validation loss: 2.2743677695592246

Epoch: 5| Step: 4
Training loss: 1.0924087762832642
Validation loss: 2.120603173971176

Epoch: 5| Step: 5
Training loss: 1.1870191097259521
Validation loss: 2.1289628744125366

Epoch: 5| Step: 6
Training loss: 1.1487681865692139
Validation loss: 2.2176534781853356

Epoch: 5| Step: 7
Training loss: 1.6285781860351562
Validation loss: 2.1830408771832785

Epoch: 5| Step: 8
Training loss: 1.2848048210144043
Validation loss: 2.2442392905553183

Epoch: 5| Step: 9
Training loss: 1.4009071588516235
Validation loss: 2.1811397622028985

Epoch: 5| Step: 10
Training loss: 0.8377838134765625
Validation loss: 2.227097903688749

Epoch: 5| Step: 11
Training loss: 1.1608192920684814
Validation loss: 2.2356696824232736

Epoch: 211| Step: 0
Training loss: 0.5380197763442993
Validation loss: 2.17459774017334

Epoch: 5| Step: 1
Training loss: 0.9557669758796692
Validation loss: 2.1414221028486886

Epoch: 5| Step: 2
Training loss: 1.0116569995880127
Validation loss: 2.209364046653112

Epoch: 5| Step: 3
Training loss: 1.3610668182373047
Validation loss: 2.2274866501490274

Epoch: 5| Step: 4
Training loss: 1.125555157661438
Validation loss: 2.20391354461511

Epoch: 5| Step: 5
Training loss: 1.1275099515914917
Validation loss: 2.176992411414782

Epoch: 5| Step: 6
Training loss: 0.985223650932312
Validation loss: 2.141590416431427

Epoch: 5| Step: 7
Training loss: 1.4253928661346436
Validation loss: 2.164943834145864

Epoch: 5| Step: 8
Training loss: 1.5906497240066528
Validation loss: 2.1926203866799674

Epoch: 5| Step: 9
Training loss: 1.4935506582260132
Validation loss: 2.1678736756245294

Epoch: 5| Step: 10
Training loss: 1.3460853099822998
Validation loss: 2.2680418541034064

Epoch: 5| Step: 11
Training loss: 0.6822569966316223
Validation loss: 2.1816985607147217

Epoch: 212| Step: 0
Training loss: 1.2958929538726807
Validation loss: 2.223475605249405

Epoch: 5| Step: 1
Training loss: 1.5317741632461548
Validation loss: 2.223999490340551

Epoch: 5| Step: 2
Training loss: 0.7864521741867065
Validation loss: 2.1321308513482413

Epoch: 5| Step: 3
Training loss: 1.1284230947494507
Validation loss: 2.228150427341461

Epoch: 5| Step: 4
Training loss: 1.4156603813171387
Validation loss: 2.251465529203415

Epoch: 5| Step: 5
Training loss: 1.0013635158538818
Validation loss: 2.2134803781906762

Epoch: 5| Step: 6
Training loss: 0.9729474782943726
Validation loss: 2.2112326522668204

Epoch: 5| Step: 7
Training loss: 1.0795567035675049
Validation loss: 2.250367025534312

Epoch: 5| Step: 8
Training loss: 1.0752451419830322
Validation loss: 2.210824261109034

Epoch: 5| Step: 9
Training loss: 1.2973483800888062
Validation loss: 2.1386549721161523

Epoch: 5| Step: 10
Training loss: 0.8012197613716125
Validation loss: 2.211240589618683

Epoch: 5| Step: 11
Training loss: 0.3052428066730499
Validation loss: 2.1558276414871216

Epoch: 213| Step: 0
Training loss: 1.291053056716919
Validation loss: 2.203983103235563

Epoch: 5| Step: 1
Training loss: 0.8908470273017883
Validation loss: 2.2240257064501443

Epoch: 5| Step: 2
Training loss: 0.9717409014701843
Validation loss: 2.231449246406555

Epoch: 5| Step: 3
Training loss: 1.597485899925232
Validation loss: 2.1918066143989563

Epoch: 5| Step: 4
Training loss: 0.8494377136230469
Validation loss: 2.185671105980873

Epoch: 5| Step: 5
Training loss: 1.3300632238388062
Validation loss: 2.1986546516418457

Epoch: 5| Step: 6
Training loss: 0.9972406625747681
Validation loss: 2.2097765654325485

Epoch: 5| Step: 7
Training loss: 0.8689073324203491
Validation loss: 2.1661667774120965

Epoch: 5| Step: 8
Training loss: 1.3636434078216553
Validation loss: 2.2123640378316245

Epoch: 5| Step: 9
Training loss: 1.3093464374542236
Validation loss: 2.1915951122840247

Epoch: 5| Step: 10
Training loss: 1.4314390420913696
Validation loss: 2.163955435156822

Epoch: 5| Step: 11
Training loss: 1.1625604629516602
Validation loss: 2.245911573370298

Epoch: 214| Step: 0
Training loss: 1.2889883518218994
Validation loss: 2.1328515162070594

Epoch: 5| Step: 1
Training loss: 1.010923147201538
Validation loss: 2.1809412986040115

Epoch: 5| Step: 2
Training loss: 1.0479785203933716
Validation loss: 2.1387414932250977

Epoch: 5| Step: 3
Training loss: 1.3846427202224731
Validation loss: 2.1194932609796524

Epoch: 5| Step: 4
Training loss: 1.6589053869247437
Validation loss: 2.180907040834427

Epoch: 5| Step: 5
Training loss: 0.9552030563354492
Validation loss: 2.142286797364553

Epoch: 5| Step: 6
Training loss: 1.102278470993042
Validation loss: 2.2274174243211746

Epoch: 5| Step: 7
Training loss: 0.6955225467681885
Validation loss: 2.2534618427356086

Epoch: 5| Step: 8
Training loss: 1.5084642171859741
Validation loss: 2.281760036945343

Epoch: 5| Step: 9
Training loss: 1.0943794250488281
Validation loss: 2.1823418537775674

Epoch: 5| Step: 10
Training loss: 1.154280662536621
Validation loss: 2.2037076155344644

Epoch: 5| Step: 11
Training loss: 0.5610520839691162
Validation loss: 2.204036215941111

Epoch: 215| Step: 0
Training loss: 1.1374849081039429
Validation loss: 2.119264006614685

Epoch: 5| Step: 1
Training loss: 0.831089973449707
Validation loss: 2.1488536496957145

Epoch: 5| Step: 2
Training loss: 1.1477314233779907
Validation loss: 2.1984364638725915

Epoch: 5| Step: 3
Training loss: 1.3379909992218018
Validation loss: 2.280731682976087

Epoch: 5| Step: 4
Training loss: 1.7116295099258423
Validation loss: 2.261839176217715

Epoch: 5| Step: 5
Training loss: 1.4077138900756836
Validation loss: 2.137637197971344

Epoch: 5| Step: 6
Training loss: 1.2921175956726074
Validation loss: 2.158807178338369

Epoch: 5| Step: 7
Training loss: 0.6703922152519226
Validation loss: 2.220916191736857

Epoch: 5| Step: 8
Training loss: 0.903506875038147
Validation loss: 2.1478546857833862

Epoch: 5| Step: 9
Training loss: 0.8577683568000793
Validation loss: 2.2262162963549295

Epoch: 5| Step: 10
Training loss: 1.1255042552947998
Validation loss: 2.15138707558314

Epoch: 5| Step: 11
Training loss: 1.604176640510559
Validation loss: 2.229311873515447

Epoch: 216| Step: 0
Training loss: 0.8757271766662598
Validation loss: 2.24014242986838

Epoch: 5| Step: 1
Training loss: 1.578555703163147
Validation loss: 2.3107005258401236

Epoch: 5| Step: 2
Training loss: 1.4637688398361206
Validation loss: 2.2739217281341553

Epoch: 5| Step: 3
Training loss: 1.2874664068222046
Validation loss: 2.215104262034098

Epoch: 5| Step: 4
Training loss: 1.2697964906692505
Validation loss: 2.2011349350214005

Epoch: 5| Step: 5
Training loss: 1.0847501754760742
Validation loss: 2.182216008504232

Epoch: 5| Step: 6
Training loss: 1.070786714553833
Validation loss: 2.1954169968763986

Epoch: 5| Step: 7
Training loss: 1.1351497173309326
Validation loss: 2.2277767012516656

Epoch: 5| Step: 8
Training loss: 1.3303496837615967
Validation loss: 2.2191304365793862

Epoch: 5| Step: 9
Training loss: 1.2179760932922363
Validation loss: 2.2502471357584

Epoch: 5| Step: 10
Training loss: 1.4439443349838257
Validation loss: 2.1702731400728226

Epoch: 5| Step: 11
Training loss: 1.8258121013641357
Validation loss: 2.1945865154266357

Epoch: 217| Step: 0
Training loss: 1.106395959854126
Validation loss: 2.191094473004341

Epoch: 5| Step: 1
Training loss: 1.0427258014678955
Validation loss: 2.100380778312683

Epoch: 5| Step: 2
Training loss: 0.5178425908088684
Validation loss: 2.2131811330715814

Epoch: 5| Step: 3
Training loss: 1.3045800924301147
Validation loss: 2.227642446756363

Epoch: 5| Step: 4
Training loss: 1.2266523838043213
Validation loss: 2.149174710114797

Epoch: 5| Step: 5
Training loss: 1.3763573169708252
Validation loss: 2.235203335682551

Epoch: 5| Step: 6
Training loss: 0.9378092885017395
Validation loss: 2.2037213345368705

Epoch: 5| Step: 7
Training loss: 1.251002550125122
Validation loss: 2.155626724163691

Epoch: 5| Step: 8
Training loss: 1.2494523525238037
Validation loss: 2.172889252503713

Epoch: 5| Step: 9
Training loss: 1.1210036277770996
Validation loss: 2.2473932007948556

Epoch: 5| Step: 10
Training loss: 1.091597080230713
Validation loss: 2.2148512999216714

Epoch: 5| Step: 11
Training loss: 1.2939585447311401
Validation loss: 2.1772029350201287

Epoch: 218| Step: 0
Training loss: 1.0546705722808838
Validation loss: 2.241178199648857

Epoch: 5| Step: 1
Training loss: 0.9903527498245239
Validation loss: 2.1814159601926804

Epoch: 5| Step: 2
Training loss: 1.3615039587020874
Validation loss: 2.1304544806480408

Epoch: 5| Step: 3
Training loss: 0.9341266751289368
Validation loss: 2.216656059026718

Epoch: 5| Step: 4
Training loss: 1.5003143548965454
Validation loss: 2.2584283351898193

Epoch: 5| Step: 5
Training loss: 1.1556684970855713
Validation loss: 2.1838851074377694

Epoch: 5| Step: 6
Training loss: 1.1415174007415771
Validation loss: 2.1877306401729584

Epoch: 5| Step: 7
Training loss: 0.9479877352714539
Validation loss: 2.213676691055298

Epoch: 5| Step: 8
Training loss: 0.9120306968688965
Validation loss: 2.200739338994026

Epoch: 5| Step: 9
Training loss: 1.1495606899261475
Validation loss: 2.150378187497457

Epoch: 5| Step: 10
Training loss: 0.8166302442550659
Validation loss: 2.23725026845932

Epoch: 5| Step: 11
Training loss: 1.4691989421844482
Validation loss: 2.247279942035675

Epoch: 219| Step: 0
Training loss: 1.318723440170288
Validation loss: 2.16301562388738

Epoch: 5| Step: 1
Training loss: 0.8454059362411499
Validation loss: 2.351971526940664

Epoch: 5| Step: 2
Training loss: 0.7922733426094055
Validation loss: 2.178884044289589

Epoch: 5| Step: 3
Training loss: 0.8400529623031616
Validation loss: 2.195415253440539

Epoch: 5| Step: 4
Training loss: 1.0962706804275513
Validation loss: 2.2204477787017822

Epoch: 5| Step: 5
Training loss: 1.263385534286499
Validation loss: 2.273260553677877

Epoch: 5| Step: 6
Training loss: 1.3903217315673828
Validation loss: 2.1703055699666343

Epoch: 5| Step: 7
Training loss: 1.1857773065567017
Validation loss: 2.241835663715998

Epoch: 5| Step: 8
Training loss: 1.027155876159668
Validation loss: 2.226660370826721

Epoch: 5| Step: 9
Training loss: 1.1134138107299805
Validation loss: 2.1988656421502433

Epoch: 5| Step: 10
Training loss: 1.036985158920288
Validation loss: 2.2455794413884482

Epoch: 5| Step: 11
Training loss: 0.6916537284851074
Validation loss: 2.1083433081706366

Epoch: 220| Step: 0
Training loss: 0.8368251919746399
Validation loss: 2.157557358344396

Epoch: 5| Step: 1
Training loss: 1.3573706150054932
Validation loss: 2.1610477715730667

Epoch: 5| Step: 2
Training loss: 0.9831026196479797
Validation loss: 2.145981088280678

Epoch: 5| Step: 3
Training loss: 0.8726530075073242
Validation loss: 2.208574334780375

Epoch: 5| Step: 4
Training loss: 1.2490171194076538
Validation loss: 2.1968372662862143

Epoch: 5| Step: 5
Training loss: 0.829460620880127
Validation loss: 2.1779177139202752

Epoch: 5| Step: 6
Training loss: 0.7508746385574341
Validation loss: 2.142129768927892

Epoch: 5| Step: 7
Training loss: 0.9014908075332642
Validation loss: 2.1839295625686646

Epoch: 5| Step: 8
Training loss: 1.1046345233917236
Validation loss: 2.2129759738842645

Epoch: 5| Step: 9
Training loss: 1.279097318649292
Validation loss: 2.150886317094167

Epoch: 5| Step: 10
Training loss: 1.3169236183166504
Validation loss: 2.1720781326293945

Epoch: 5| Step: 11
Training loss: 1.3796130418777466
Validation loss: 2.2278286616007485

Epoch: 221| Step: 0
Training loss: 1.0008366107940674
Validation loss: 2.2238754282395043

Epoch: 5| Step: 1
Training loss: 1.2098087072372437
Validation loss: 2.2150196532408395

Epoch: 5| Step: 2
Training loss: 0.7233380079269409
Validation loss: 2.276522010564804

Epoch: 5| Step: 3
Training loss: 1.1694895029067993
Validation loss: 2.225235809882482

Epoch: 5| Step: 4
Training loss: 0.7652618288993835
Validation loss: 2.210907315214475

Epoch: 5| Step: 5
Training loss: 0.778060257434845
Validation loss: 2.2006518840789795

Epoch: 5| Step: 6
Training loss: 1.51645028591156
Validation loss: 2.298903206984202

Epoch: 5| Step: 7
Training loss: 0.9711236953735352
Validation loss: 2.2172787189483643

Epoch: 5| Step: 8
Training loss: 1.312721610069275
Validation loss: 2.20218433936437

Epoch: 5| Step: 9
Training loss: 1.0795783996582031
Validation loss: 2.141879310210546

Epoch: 5| Step: 10
Training loss: 1.0564281940460205
Validation loss: 2.2213988602161407

Epoch: 5| Step: 11
Training loss: 2.714063882827759
Validation loss: 2.194106807311376

Epoch: 222| Step: 0
Training loss: 1.6982005834579468
Validation loss: 2.2322224428256354

Epoch: 5| Step: 1
Training loss: 1.0385382175445557
Validation loss: 2.202518403530121

Epoch: 5| Step: 2
Training loss: 1.0630160570144653
Validation loss: 2.2168350716431937

Epoch: 5| Step: 3
Training loss: 1.160422682762146
Validation loss: 2.257243111729622

Epoch: 5| Step: 4
Training loss: 1.156759262084961
Validation loss: 2.2126985092957816

Epoch: 5| Step: 5
Training loss: 1.0854456424713135
Validation loss: 2.2355874280134835

Epoch: 5| Step: 6
Training loss: 1.0545302629470825
Validation loss: 2.223985508084297

Epoch: 5| Step: 7
Training loss: 0.9156328439712524
Validation loss: 2.2129294077555337

Epoch: 5| Step: 8
Training loss: 1.012498140335083
Validation loss: 2.135085418820381

Epoch: 5| Step: 9
Training loss: 0.8459205627441406
Validation loss: 2.1554780453443527

Epoch: 5| Step: 10
Training loss: 0.9196571111679077
Validation loss: 2.1717315713564553

Epoch: 5| Step: 11
Training loss: 0.4702885150909424
Validation loss: 2.2350366512934365

Epoch: 223| Step: 0
Training loss: 0.8226784467697144
Validation loss: 2.2059828539689383

Epoch: 5| Step: 1
Training loss: 1.0644274950027466
Validation loss: 2.231767321626345

Epoch: 5| Step: 2
Training loss: 1.0504236221313477
Validation loss: 2.1831965893507004

Epoch: 5| Step: 3
Training loss: 1.0060548782348633
Validation loss: 2.2111991991599402

Epoch: 5| Step: 4
Training loss: 0.6935311555862427
Validation loss: 2.1826617618401847

Epoch: 5| Step: 5
Training loss: 1.2007410526275635
Validation loss: 2.222920313477516

Epoch: 5| Step: 6
Training loss: 1.1257421970367432
Validation loss: 2.2654996862014136

Epoch: 5| Step: 7
Training loss: 1.7309831380844116
Validation loss: 2.2302243212858834

Epoch: 5| Step: 8
Training loss: 1.403306245803833
Validation loss: 2.26113431652387

Epoch: 5| Step: 9
Training loss: 0.9395623207092285
Validation loss: 2.2385022739569345

Epoch: 5| Step: 10
Training loss: 1.1442615985870361
Validation loss: 2.258726571997007

Epoch: 5| Step: 11
Training loss: 1.5761463642120361
Validation loss: 2.222464829683304

Epoch: 224| Step: 0
Training loss: 0.7308486700057983
Validation loss: 2.2020554890235267

Epoch: 5| Step: 1
Training loss: 1.433145523071289
Validation loss: 2.2568422903617225

Epoch: 5| Step: 2
Training loss: 0.8529537320137024
Validation loss: 2.2041092813014984

Epoch: 5| Step: 3
Training loss: 1.3821768760681152
Validation loss: 2.186274543404579

Epoch: 5| Step: 4
Training loss: 0.6360543966293335
Validation loss: 2.2189784745375314

Epoch: 5| Step: 5
Training loss: 1.3081713914871216
Validation loss: 2.2394984116156897

Epoch: 5| Step: 6
Training loss: 1.174425482749939
Validation loss: 2.2564622511466346

Epoch: 5| Step: 7
Training loss: 0.735040009021759
Validation loss: 2.25569956501325

Epoch: 5| Step: 8
Training loss: 1.1831271648406982
Validation loss: 2.176500360171

Epoch: 5| Step: 9
Training loss: 0.7606236338615417
Validation loss: 2.1921874384085336

Epoch: 5| Step: 10
Training loss: 1.4863401651382446
Validation loss: 2.2631310572226844

Epoch: 5| Step: 11
Training loss: 0.701291024684906
Validation loss: 2.136220042904218

Epoch: 225| Step: 0
Training loss: 1.3074840307235718
Validation loss: 2.1758221089839935

Epoch: 5| Step: 1
Training loss: 1.2241907119750977
Validation loss: 2.2040753960609436

Epoch: 5| Step: 2
Training loss: 0.7303903698921204
Validation loss: 2.311744292577108

Epoch: 5| Step: 3
Training loss: 0.8678406476974487
Validation loss: 2.236414144436518

Epoch: 5| Step: 4
Training loss: 1.1061772108078003
Validation loss: 2.1909110645453134

Epoch: 5| Step: 5
Training loss: 0.9515804052352905
Validation loss: 2.208202968041102

Epoch: 5| Step: 6
Training loss: 1.4150758981704712
Validation loss: 2.203082407514254

Epoch: 5| Step: 7
Training loss: 1.0276620388031006
Validation loss: 2.150287469228109

Epoch: 5| Step: 8
Training loss: 1.1512293815612793
Validation loss: 2.246066997448603

Epoch: 5| Step: 9
Training loss: 0.7299289107322693
Validation loss: 2.165019412835439

Epoch: 5| Step: 10
Training loss: 1.3067121505737305
Validation loss: 2.2578700284163156

Epoch: 5| Step: 11
Training loss: 0.4703080654144287
Validation loss: 2.2244094808896384

Epoch: 226| Step: 0
Training loss: 1.0485756397247314
Validation loss: 2.2030449211597443

Epoch: 5| Step: 1
Training loss: 0.6634443998336792
Validation loss: 2.142798145612081

Epoch: 5| Step: 2
Training loss: 0.8695377111434937
Validation loss: 2.2220521668593087

Epoch: 5| Step: 3
Training loss: 1.608281135559082
Validation loss: 2.18228871623675

Epoch: 5| Step: 4
Training loss: 1.0862338542938232
Validation loss: 2.241668701171875

Epoch: 5| Step: 5
Training loss: 1.188612937927246
Validation loss: 2.2204469392697015

Epoch: 5| Step: 6
Training loss: 1.1028404235839844
Validation loss: 2.158457413315773

Epoch: 5| Step: 7
Training loss: 0.9460992813110352
Validation loss: 2.2887270549933114

Epoch: 5| Step: 8
Training loss: 0.9344537854194641
Validation loss: 2.212953488032023

Epoch: 5| Step: 9
Training loss: 1.2832438945770264
Validation loss: 2.218991513053576

Epoch: 5| Step: 10
Training loss: 0.8681346774101257
Validation loss: 2.1577311555544534

Epoch: 5| Step: 11
Training loss: 2.460995674133301
Validation loss: 2.231221834818522

Epoch: 227| Step: 0
Training loss: 1.2809600830078125
Validation loss: 2.2605273524920144

Epoch: 5| Step: 1
Training loss: 1.0880448818206787
Validation loss: 2.161270926396052

Epoch: 5| Step: 2
Training loss: 0.7544513940811157
Validation loss: 2.2209230214357376

Epoch: 5| Step: 3
Training loss: 0.8060625791549683
Validation loss: 2.2573384642601013

Epoch: 5| Step: 4
Training loss: 0.8847772479057312
Validation loss: 2.1983520885308585

Epoch: 5| Step: 5
Training loss: 1.17440664768219
Validation loss: 2.184395655989647

Epoch: 5| Step: 6
Training loss: 1.1164350509643555
Validation loss: 2.1696007450421653

Epoch: 5| Step: 7
Training loss: 0.7795191407203674
Validation loss: 2.264489382505417

Epoch: 5| Step: 8
Training loss: 1.2123256921768188
Validation loss: 2.1542471647262573

Epoch: 5| Step: 9
Training loss: 0.9877580404281616
Validation loss: 2.2145759413639703

Epoch: 5| Step: 10
Training loss: 1.3042632341384888
Validation loss: 2.1886858493089676

Epoch: 5| Step: 11
Training loss: 1.8428150415420532
Validation loss: 2.246528575817744

Epoch: 228| Step: 0
Training loss: 0.7210486531257629
Validation loss: 2.2014038463433585

Epoch: 5| Step: 1
Training loss: 1.164718508720398
Validation loss: 2.2011419037977853

Epoch: 5| Step: 2
Training loss: 1.1472015380859375
Validation loss: 2.2006066093842187

Epoch: 5| Step: 3
Training loss: 1.4893964529037476
Validation loss: 2.1506321132183075

Epoch: 5| Step: 4
Training loss: 1.1014984846115112
Validation loss: 2.2402401516834893

Epoch: 5| Step: 5
Training loss: 1.1504650115966797
Validation loss: 2.2570142348607383

Epoch: 5| Step: 6
Training loss: 0.9794939160346985
Validation loss: 2.1649525463581085

Epoch: 5| Step: 7
Training loss: 1.0526376962661743
Validation loss: 2.21244086821874

Epoch: 5| Step: 8
Training loss: 0.9198368191719055
Validation loss: 2.214059794942538

Epoch: 5| Step: 9
Training loss: 0.7474859952926636
Validation loss: 2.162107249101003

Epoch: 5| Step: 10
Training loss: 0.8530299067497253
Validation loss: 2.176673630873362

Epoch: 5| Step: 11
Training loss: 0.49494659900665283
Validation loss: 2.286522537469864

Epoch: 229| Step: 0
Training loss: 0.5098122954368591
Validation loss: 2.2438890834649405

Epoch: 5| Step: 1
Training loss: 0.9591237902641296
Validation loss: 2.262543812394142

Epoch: 5| Step: 2
Training loss: 0.9808956384658813
Validation loss: 2.1424176891644797

Epoch: 5| Step: 3
Training loss: 1.0059995651245117
Validation loss: 2.209667315085729

Epoch: 5| Step: 4
Training loss: 1.2988961935043335
Validation loss: 2.189712941646576

Epoch: 5| Step: 5
Training loss: 1.348554015159607
Validation loss: 2.1714115887880325

Epoch: 5| Step: 6
Training loss: 0.9689317941665649
Validation loss: 2.1712607393662133

Epoch: 5| Step: 7
Training loss: 0.9574285745620728
Validation loss: 2.2281190852324166

Epoch: 5| Step: 8
Training loss: 1.2529197931289673
Validation loss: 2.230184033513069

Epoch: 5| Step: 9
Training loss: 1.3264890909194946
Validation loss: 2.200097754597664

Epoch: 5| Step: 10
Training loss: 1.1800336837768555
Validation loss: 2.205283502737681

Epoch: 5| Step: 11
Training loss: 0.853785514831543
Validation loss: 2.1976072440544763

Epoch: 230| Step: 0
Training loss: 1.3557214736938477
Validation loss: 2.1643203099568686

Epoch: 5| Step: 1
Training loss: 1.2018846273422241
Validation loss: 2.185352345307668

Epoch: 5| Step: 2
Training loss: 1.3018975257873535
Validation loss: 2.1756794353326163

Epoch: 5| Step: 3
Training loss: 0.8361013531684875
Validation loss: 2.1717953930298486

Epoch: 5| Step: 4
Training loss: 1.2083065509796143
Validation loss: 2.2682730704545975

Epoch: 5| Step: 5
Training loss: 0.9381402134895325
Validation loss: 2.2058527767658234

Epoch: 5| Step: 6
Training loss: 0.829248309135437
Validation loss: 2.2213394939899445

Epoch: 5| Step: 7
Training loss: 1.3952252864837646
Validation loss: 2.2071809669335685

Epoch: 5| Step: 8
Training loss: 1.077345848083496
Validation loss: 2.140533223748207

Epoch: 5| Step: 9
Training loss: 0.58591228723526
Validation loss: 2.1871143331130347

Epoch: 5| Step: 10
Training loss: 1.0665514469146729
Validation loss: 2.197929327686628

Epoch: 5| Step: 11
Training loss: 1.4197874069213867
Validation loss: 2.1612232575813928

Epoch: 231| Step: 0
Training loss: 1.1070191860198975
Validation loss: 2.1243351797262826

Epoch: 5| Step: 1
Training loss: 0.9561087489128113
Validation loss: 2.2035180032253265

Epoch: 5| Step: 2
Training loss: 0.7858133316040039
Validation loss: 2.189476062854131

Epoch: 5| Step: 3
Training loss: 1.301398515701294
Validation loss: 2.164111390709877

Epoch: 5| Step: 4
Training loss: 1.2800378799438477
Validation loss: 2.1355743457873664

Epoch: 5| Step: 5
Training loss: 1.3903977870941162
Validation loss: 2.222316106160482

Epoch: 5| Step: 6
Training loss: 0.7581341862678528
Validation loss: 2.1774025013049445

Epoch: 5| Step: 7
Training loss: 0.80369633436203
Validation loss: 2.187368169426918

Epoch: 5| Step: 8
Training loss: 0.8453437089920044
Validation loss: 2.2019306073586145

Epoch: 5| Step: 9
Training loss: 1.0492770671844482
Validation loss: 2.2233912348747253

Epoch: 5| Step: 10
Training loss: 1.005412220954895
Validation loss: 2.1526557256778083

Epoch: 5| Step: 11
Training loss: 0.37965330481529236
Validation loss: 2.2145992716153464

Epoch: 232| Step: 0
Training loss: 1.098928689956665
Validation loss: 2.2082927227020264

Epoch: 5| Step: 1
Training loss: 0.5395809412002563
Validation loss: 2.1889266669750214

Epoch: 5| Step: 2
Training loss: 0.6539513468742371
Validation loss: 2.20901058614254

Epoch: 5| Step: 3
Training loss: 0.9202097058296204
Validation loss: 2.16022981206576

Epoch: 5| Step: 4
Training loss: 1.1399469375610352
Validation loss: 2.1750411639610925

Epoch: 5| Step: 5
Training loss: 0.6666716933250427
Validation loss: 2.221978942553202

Epoch: 5| Step: 6
Training loss: 1.660729169845581
Validation loss: 2.1320173194011054

Epoch: 5| Step: 7
Training loss: 1.279298186302185
Validation loss: 2.207224657138189

Epoch: 5| Step: 8
Training loss: 1.318002462387085
Validation loss: 2.2479983071486154

Epoch: 5| Step: 9
Training loss: 1.061025857925415
Validation loss: 2.207857077320417

Epoch: 5| Step: 10
Training loss: 0.8939038515090942
Validation loss: 2.2127553621927896

Epoch: 5| Step: 11
Training loss: 0.28491920232772827
Validation loss: 2.1246093610922494

Epoch: 233| Step: 0
Training loss: 1.0349094867706299
Validation loss: 2.1631674667199454

Epoch: 5| Step: 1
Training loss: 1.2964686155319214
Validation loss: 2.21761521200339

Epoch: 5| Step: 2
Training loss: 0.8077122569084167
Validation loss: 2.2604143669207892

Epoch: 5| Step: 3
Training loss: 1.4772522449493408
Validation loss: 2.2303152779738107

Epoch: 5| Step: 4
Training loss: 1.1054067611694336
Validation loss: 2.30792065958182

Epoch: 5| Step: 5
Training loss: 0.9578289985656738
Validation loss: 2.2621615330378213

Epoch: 5| Step: 6
Training loss: 0.9977512359619141
Validation loss: 2.19235368569692

Epoch: 5| Step: 7
Training loss: 0.7865852117538452
Validation loss: 2.219594051440557

Epoch: 5| Step: 8
Training loss: 0.570301353931427
Validation loss: 2.1318819522857666

Epoch: 5| Step: 9
Training loss: 1.2306486368179321
Validation loss: 2.2551156282424927

Epoch: 5| Step: 10
Training loss: 1.0870033502578735
Validation loss: 2.1779094437758126

Epoch: 5| Step: 11
Training loss: 1.1999399662017822
Validation loss: 2.2416969935099282

Epoch: 234| Step: 0
Training loss: 1.4623467922210693
Validation loss: 2.2902233749628067

Epoch: 5| Step: 1
Training loss: 0.8948208093643188
Validation loss: 2.222601224978765

Epoch: 5| Step: 2
Training loss: 0.9989199638366699
Validation loss: 2.255104641119639

Epoch: 5| Step: 3
Training loss: 1.1140170097351074
Validation loss: 2.1522486011187234

Epoch: 5| Step: 4
Training loss: 1.1656792163848877
Validation loss: 2.2663863400618234

Epoch: 5| Step: 5
Training loss: 0.8876670002937317
Validation loss: 2.2519088784853616

Epoch: 5| Step: 6
Training loss: 0.7769651412963867
Validation loss: 2.202850714325905

Epoch: 5| Step: 7
Training loss: 0.767656683921814
Validation loss: 2.2192986408869424

Epoch: 5| Step: 8
Training loss: 1.00711989402771
Validation loss: 2.212659294406573

Epoch: 5| Step: 9
Training loss: 1.3602604866027832
Validation loss: 2.1882076263427734

Epoch: 5| Step: 10
Training loss: 0.7182283997535706
Validation loss: 2.207158808906873

Epoch: 5| Step: 11
Training loss: 0.6389189958572388
Validation loss: 2.2153343856334686

Epoch: 235| Step: 0
Training loss: 0.70808345079422
Validation loss: 2.2342823346455893

Epoch: 5| Step: 1
Training loss: 1.1047195196151733
Validation loss: 2.2436076502005258

Epoch: 5| Step: 2
Training loss: 1.1505458354949951
Validation loss: 2.224315196275711

Epoch: 5| Step: 3
Training loss: 1.127116084098816
Validation loss: 2.1660364121198654

Epoch: 5| Step: 4
Training loss: 1.3582179546356201
Validation loss: 2.1963444451491037

Epoch: 5| Step: 5
Training loss: 0.7675843238830566
Validation loss: 2.1932116548220315

Epoch: 5| Step: 6
Training loss: 0.9829270243644714
Validation loss: 2.254066616296768

Epoch: 5| Step: 7
Training loss: 1.1905229091644287
Validation loss: 2.1729800701141357

Epoch: 5| Step: 8
Training loss: 1.0529494285583496
Validation loss: 2.196487953265508

Epoch: 5| Step: 9
Training loss: 1.073875069618225
Validation loss: 2.280779873331388

Epoch: 5| Step: 10
Training loss: 0.7055163383483887
Validation loss: 2.2044558078050613

Epoch: 5| Step: 11
Training loss: 1.004355549812317
Validation loss: 2.181771238644918

Epoch: 236| Step: 0
Training loss: 0.9578704833984375
Validation loss: 2.1799267530441284

Epoch: 5| Step: 1
Training loss: 0.7719788551330566
Validation loss: 2.2176081190506616

Epoch: 5| Step: 2
Training loss: 1.3482024669647217
Validation loss: 2.119398057460785

Epoch: 5| Step: 3
Training loss: 1.1131328344345093
Validation loss: 2.170708199342092

Epoch: 5| Step: 4
Training loss: 0.6716147661209106
Validation loss: 2.206326792637507

Epoch: 5| Step: 5
Training loss: 0.7430143356323242
Validation loss: 2.0993590652942657

Epoch: 5| Step: 6
Training loss: 0.7261751294136047
Validation loss: 2.2332948545614877

Epoch: 5| Step: 7
Training loss: 1.2552934885025024
Validation loss: 2.211583827932676

Epoch: 5| Step: 8
Training loss: 0.9505969285964966
Validation loss: 2.2275512367486954

Epoch: 5| Step: 9
Training loss: 0.9384970664978027
Validation loss: 2.183583045999209

Epoch: 5| Step: 10
Training loss: 0.9295666813850403
Validation loss: 2.2177904148896537

Epoch: 5| Step: 11
Training loss: 0.37361955642700195
Validation loss: 2.278004159530004

Epoch: 237| Step: 0
Training loss: 0.7422117590904236
Validation loss: 2.1956025610367456

Epoch: 5| Step: 1
Training loss: 1.2358038425445557
Validation loss: 2.289475287000338

Epoch: 5| Step: 2
Training loss: 0.7858376502990723
Validation loss: 2.2139617999394736

Epoch: 5| Step: 3
Training loss: 0.8274925351142883
Validation loss: 2.1724618623654046

Epoch: 5| Step: 4
Training loss: 1.1979525089263916
Validation loss: 2.237579514582952

Epoch: 5| Step: 5
Training loss: 0.6371304392814636
Validation loss: 2.1869389414787292

Epoch: 5| Step: 6
Training loss: 1.1487916707992554
Validation loss: 2.2181639820337296

Epoch: 5| Step: 7
Training loss: 1.23822820186615
Validation loss: 2.209005907177925

Epoch: 5| Step: 8
Training loss: 1.2056387662887573
Validation loss: 2.180123825867971

Epoch: 5| Step: 9
Training loss: 1.1037497520446777
Validation loss: 2.2334058582782745

Epoch: 5| Step: 10
Training loss: 0.9987428784370422
Validation loss: 2.2361472050348916

Epoch: 5| Step: 11
Training loss: 1.4954077005386353
Validation loss: 2.242449680964152

Epoch: 238| Step: 0
Training loss: 0.7135016322135925
Validation loss: 2.2013736367225647

Epoch: 5| Step: 1
Training loss: 1.2278090715408325
Validation loss: 2.2141889135042825

Epoch: 5| Step: 2
Training loss: 0.887069046497345
Validation loss: 2.209527383248011

Epoch: 5| Step: 3
Training loss: 0.7955570220947266
Validation loss: 2.2471725145975747

Epoch: 5| Step: 4
Training loss: 1.101336121559143
Validation loss: 2.2279821236928306

Epoch: 5| Step: 5
Training loss: 0.9332019090652466
Validation loss: 2.1910431683063507

Epoch: 5| Step: 6
Training loss: 1.079824686050415
Validation loss: 2.278655563791593

Epoch: 5| Step: 7
Training loss: 1.565934419631958
Validation loss: 2.249698117375374

Epoch: 5| Step: 8
Training loss: 0.8541065454483032
Validation loss: 2.1380251149336496

Epoch: 5| Step: 9
Training loss: 1.1710054874420166
Validation loss: 2.2692469358444214

Epoch: 5| Step: 10
Training loss: 0.8582345843315125
Validation loss: 2.2901633977890015

Epoch: 5| Step: 11
Training loss: 0.776343822479248
Validation loss: 2.1968507121006646

Epoch: 239| Step: 0
Training loss: 0.8683489561080933
Validation loss: 2.164590766032537

Epoch: 5| Step: 1
Training loss: 0.6881663203239441
Validation loss: 2.195607513189316

Epoch: 5| Step: 2
Training loss: 0.7201153039932251
Validation loss: 2.2868774781624475

Epoch: 5| Step: 3
Training loss: 0.7619775533676147
Validation loss: 2.15717122455438

Epoch: 5| Step: 4
Training loss: 0.9777059555053711
Validation loss: 2.2482057909170785

Epoch: 5| Step: 5
Training loss: 1.0748580694198608
Validation loss: 2.1910689373811087

Epoch: 5| Step: 6
Training loss: 0.8830784559249878
Validation loss: 2.190903902053833

Epoch: 5| Step: 7
Training loss: 1.4933122396469116
Validation loss: 2.1453420370817184

Epoch: 5| Step: 8
Training loss: 0.9382098317146301
Validation loss: 2.275608311096827

Epoch: 5| Step: 9
Training loss: 0.7241849303245544
Validation loss: 2.258318473895391

Epoch: 5| Step: 10
Training loss: 0.9803527593612671
Validation loss: 2.2531399528185525

Epoch: 5| Step: 11
Training loss: 1.062943458557129
Validation loss: 2.2786148389180503

Epoch: 240| Step: 0
Training loss: 1.2820559740066528
Validation loss: 2.2749947806199393

Epoch: 5| Step: 1
Training loss: 1.4584437608718872
Validation loss: 2.28385536869367

Epoch: 5| Step: 2
Training loss: 1.0785377025604248
Validation loss: 2.2348894824584327

Epoch: 5| Step: 3
Training loss: 0.9075549840927124
Validation loss: 2.2696526646614075

Epoch: 5| Step: 4
Training loss: 0.8251445889472961
Validation loss: 2.2383787532647452

Epoch: 5| Step: 5
Training loss: 0.8232558965682983
Validation loss: 2.184966708223025

Epoch: 5| Step: 6
Training loss: 0.7110229730606079
Validation loss: 2.224124069015185

Epoch: 5| Step: 7
Training loss: 0.8303159475326538
Validation loss: 2.2372570782899857

Epoch: 5| Step: 8
Training loss: 0.957187831401825
Validation loss: 2.2448984185854592

Epoch: 5| Step: 9
Training loss: 1.0703452825546265
Validation loss: 2.225228731830915

Epoch: 5| Step: 10
Training loss: 0.7889231443405151
Validation loss: 2.1449825018644333

Epoch: 5| Step: 11
Training loss: 1.6902079582214355
Validation loss: 2.231362005074819

Epoch: 241| Step: 0
Training loss: 0.5540431141853333
Validation loss: 2.216948459545771

Epoch: 5| Step: 1
Training loss: 1.0349640846252441
Validation loss: 2.206448122859001

Epoch: 5| Step: 2
Training loss: 1.1947104930877686
Validation loss: 2.1646505196889243

Epoch: 5| Step: 3
Training loss: 1.0264673233032227
Validation loss: 2.2283484637737274

Epoch: 5| Step: 4
Training loss: 0.8405808210372925
Validation loss: 2.3060357173283896

Epoch: 5| Step: 5
Training loss: 0.9703415632247925
Validation loss: 2.2102766235669455

Epoch: 5| Step: 6
Training loss: 0.7947463989257812
Validation loss: 2.1193092515071235

Epoch: 5| Step: 7
Training loss: 0.8491706848144531
Validation loss: 2.1682990392049155

Epoch: 5| Step: 8
Training loss: 0.9285674095153809
Validation loss: 2.2272566656271615

Epoch: 5| Step: 9
Training loss: 0.48728054761886597
Validation loss: 2.2050386369228363

Epoch: 5| Step: 10
Training loss: 1.8193747997283936
Validation loss: 2.2102036823829017

Epoch: 5| Step: 11
Training loss: 0.6547141671180725
Validation loss: 2.227364733815193

Epoch: 242| Step: 0
Training loss: 0.6558098793029785
Validation loss: 2.209530641635259

Epoch: 5| Step: 1
Training loss: 1.2741222381591797
Validation loss: 2.204973737398783

Epoch: 5| Step: 2
Training loss: 1.0129854679107666
Validation loss: 2.164269099632899

Epoch: 5| Step: 3
Training loss: 0.7101042866706848
Validation loss: 2.1642097930113473

Epoch: 5| Step: 4
Training loss: 0.9124218225479126
Validation loss: 2.1536156137784324

Epoch: 5| Step: 5
Training loss: 0.6614279747009277
Validation loss: 2.215899924437205

Epoch: 5| Step: 6
Training loss: 1.0219553709030151
Validation loss: 2.242177332441012

Epoch: 5| Step: 7
Training loss: 0.9008058309555054
Validation loss: 2.209610333045324

Epoch: 5| Step: 8
Training loss: 0.8767352104187012
Validation loss: 2.1916824728250504

Epoch: 5| Step: 9
Training loss: 0.7131315469741821
Validation loss: 2.15247709552447

Epoch: 5| Step: 10
Training loss: 1.237647533416748
Validation loss: 2.1889982720216117

Epoch: 5| Step: 11
Training loss: 1.3845025300979614
Validation loss: 2.192974343895912

Epoch: 243| Step: 0
Training loss: 1.2632931470870972
Validation loss: 2.2265872955322266

Epoch: 5| Step: 1
Training loss: 1.1266794204711914
Validation loss: 2.2040984531243644

Epoch: 5| Step: 2
Training loss: 0.8804302215576172
Validation loss: 2.1600691825151443

Epoch: 5| Step: 3
Training loss: 1.1857572793960571
Validation loss: 2.2021728505690894

Epoch: 5| Step: 4
Training loss: 1.2970874309539795
Validation loss: 2.1793523033459983

Epoch: 5| Step: 5
Training loss: 0.7129265069961548
Validation loss: 2.236603538195292

Epoch: 5| Step: 6
Training loss: 0.9063594937324524
Validation loss: 2.1630499213933945

Epoch: 5| Step: 7
Training loss: 0.7178492546081543
Validation loss: 2.1621410846710205

Epoch: 5| Step: 8
Training loss: 0.8677433729171753
Validation loss: 2.236649587750435

Epoch: 5| Step: 9
Training loss: 1.3821357488632202
Validation loss: 2.1990521599849067

Epoch: 5| Step: 10
Training loss: 0.8928640484809875
Validation loss: 2.2926304638385773

Epoch: 5| Step: 11
Training loss: 0.7668541073799133
Validation loss: 2.2706087629000344

Epoch: 244| Step: 0
Training loss: 1.0486094951629639
Validation loss: 2.2057116329669952

Epoch: 5| Step: 1
Training loss: 1.0477776527404785
Validation loss: 2.2480299174785614

Epoch: 5| Step: 2
Training loss: 0.7406870126724243
Validation loss: 2.227483252684275

Epoch: 5| Step: 3
Training loss: 0.6391980051994324
Validation loss: 2.1412301063537598

Epoch: 5| Step: 4
Training loss: 0.8877512812614441
Validation loss: 2.1635097563266754

Epoch: 5| Step: 5
Training loss: 1.4857982397079468
Validation loss: 2.1852373679478965

Epoch: 5| Step: 6
Training loss: 0.8719645738601685
Validation loss: 2.1832164525985718

Epoch: 5| Step: 7
Training loss: 1.008879542350769
Validation loss: 2.215286443630854

Epoch: 5| Step: 8
Training loss: 0.4684526324272156
Validation loss: 2.2480063239733377

Epoch: 5| Step: 9
Training loss: 1.4591938257217407
Validation loss: 2.1949379543463388

Epoch: 5| Step: 10
Training loss: 0.9005287289619446
Validation loss: 2.267954498529434

Epoch: 5| Step: 11
Training loss: 0.7670806050300598
Validation loss: 2.231173803408941

Epoch: 245| Step: 0
Training loss: 0.6991291046142578
Validation loss: 2.1950196574131646

Epoch: 5| Step: 1
Training loss: 0.7239281535148621
Validation loss: 2.1684196144342422

Epoch: 5| Step: 2
Training loss: 0.7230371236801147
Validation loss: 2.2340194980303445

Epoch: 5| Step: 3
Training loss: 1.1486438512802124
Validation loss: 2.292457098762194

Epoch: 5| Step: 4
Training loss: 1.0331581830978394
Validation loss: 2.222712596257528

Epoch: 5| Step: 5
Training loss: 0.9522565007209778
Validation loss: 2.3160606076320014

Epoch: 5| Step: 6
Training loss: 0.8233510851860046
Validation loss: 2.268386428554853

Epoch: 5| Step: 7
Training loss: 1.121139645576477
Validation loss: 2.2444808085759482

Epoch: 5| Step: 8
Training loss: 0.7530869245529175
Validation loss: 2.190905506412188

Epoch: 5| Step: 9
Training loss: 0.9389283061027527
Validation loss: 2.1783847212791443

Epoch: 5| Step: 10
Training loss: 1.263413667678833
Validation loss: 2.189751456181208

Epoch: 5| Step: 11
Training loss: 1.152246356010437
Validation loss: 2.172966574629148

Epoch: 246| Step: 0
Training loss: 1.0905901193618774
Validation loss: 2.1915538360675177

Epoch: 5| Step: 1
Training loss: 0.9824085235595703
Validation loss: 2.2797978719075522

Epoch: 5| Step: 2
Training loss: 0.9707950353622437
Validation loss: 2.2001117716232934

Epoch: 5| Step: 3
Training loss: 1.0125519037246704
Validation loss: 2.224053015311559

Epoch: 5| Step: 4
Training loss: 0.9814680218696594
Validation loss: 2.2567273676395416

Epoch: 5| Step: 5
Training loss: 0.7907490730285645
Validation loss: 2.233378291130066

Epoch: 5| Step: 6
Training loss: 1.2070280313491821
Validation loss: 2.1273073852062225

Epoch: 5| Step: 7
Training loss: 0.5960728526115417
Validation loss: 2.1993130346139274

Epoch: 5| Step: 8
Training loss: 0.744419276714325
Validation loss: 2.262407789627711

Epoch: 5| Step: 9
Training loss: 0.8126923441886902
Validation loss: 2.1671909789244332

Epoch: 5| Step: 10
Training loss: 1.086418867111206
Validation loss: 2.235404605666796

Epoch: 5| Step: 11
Training loss: 0.5934597253799438
Validation loss: 2.1921355426311493

Epoch: 247| Step: 0
Training loss: 1.0108627080917358
Validation loss: 2.217318723599116

Epoch: 5| Step: 1
Training loss: 0.7662969827651978
Validation loss: 2.2404784659544625

Epoch: 5| Step: 2
Training loss: 0.9826359748840332
Validation loss: 2.2396355966726937

Epoch: 5| Step: 3
Training loss: 0.8303513526916504
Validation loss: 2.191157042980194

Epoch: 5| Step: 4
Training loss: 0.6546789407730103
Validation loss: 2.2231819729010263

Epoch: 5| Step: 5
Training loss: 1.007422685623169
Validation loss: 2.1574249068895974

Epoch: 5| Step: 6
Training loss: 1.372733235359192
Validation loss: 2.219735855857531

Epoch: 5| Step: 7
Training loss: 1.0487823486328125
Validation loss: 2.1916021406650543

Epoch: 5| Step: 8
Training loss: 0.9242222905158997
Validation loss: 2.198994984229406

Epoch: 5| Step: 9
Training loss: 0.7687743306159973
Validation loss: 2.1764361759026847

Epoch: 5| Step: 10
Training loss: 0.9205989837646484
Validation loss: 2.205279697974523

Epoch: 5| Step: 11
Training loss: 1.331762671470642
Validation loss: 2.215246627728144

Epoch: 248| Step: 0
Training loss: 1.3818002939224243
Validation loss: 2.13136954108874

Epoch: 5| Step: 1
Training loss: 0.9886002540588379
Validation loss: 2.319766332705816

Epoch: 5| Step: 2
Training loss: 1.167519211769104
Validation loss: 2.261864716808001

Epoch: 5| Step: 3
Training loss: 0.8553084135055542
Validation loss: 2.2545972168445587

Epoch: 5| Step: 4
Training loss: 0.81818687915802
Validation loss: 2.178782636920611

Epoch: 5| Step: 5
Training loss: 0.8341232538223267
Validation loss: 2.265632520119349

Epoch: 5| Step: 6
Training loss: 0.9793651700019836
Validation loss: 2.1477144956588745

Epoch: 5| Step: 7
Training loss: 0.8419994115829468
Validation loss: 2.121370459596316

Epoch: 5| Step: 8
Training loss: 0.7904481887817383
Validation loss: 2.233057568470637

Epoch: 5| Step: 9
Training loss: 1.1342490911483765
Validation loss: 2.129334772626559

Epoch: 5| Step: 10
Training loss: 0.7437409162521362
Validation loss: 2.3219111214081445

Epoch: 5| Step: 11
Training loss: 0.3184612989425659
Validation loss: 2.244637429714203

Epoch: 249| Step: 0
Training loss: 1.388462781906128
Validation loss: 2.2174651622772217

Epoch: 5| Step: 1
Training loss: 0.8023968935012817
Validation loss: 2.27609113852183

Epoch: 5| Step: 2
Training loss: 1.2046054601669312
Validation loss: 2.198655550678571

Epoch: 5| Step: 3
Training loss: 0.7949687838554382
Validation loss: 2.336466188232104

Epoch: 5| Step: 4
Training loss: 0.6427674293518066
Validation loss: 2.239312027891477

Epoch: 5| Step: 5
Training loss: 0.7780085802078247
Validation loss: 2.184131274620692

Epoch: 5| Step: 6
Training loss: 0.6789239048957825
Validation loss: 2.1754024972518287

Epoch: 5| Step: 7
Training loss: 1.2421704530715942
Validation loss: 2.2042644917964935

Epoch: 5| Step: 8
Training loss: 1.0691856145858765
Validation loss: 2.2424219449361167

Epoch: 5| Step: 9
Training loss: 1.3729678392410278
Validation loss: 2.240453859170278

Epoch: 5| Step: 10
Training loss: 1.1499359607696533
Validation loss: 2.20052898923556

Epoch: 5| Step: 11
Training loss: 0.47056105732917786
Validation loss: 2.2821826934814453

Epoch: 250| Step: 0
Training loss: 0.890032947063446
Validation loss: 2.2169382075468698

Epoch: 5| Step: 1
Training loss: 0.7743998765945435
Validation loss: 2.228880579272906

Epoch: 5| Step: 2
Training loss: 1.0741307735443115
Validation loss: 2.20901812116305

Epoch: 5| Step: 3
Training loss: 0.9617753028869629
Validation loss: 2.1719482839107513

Epoch: 5| Step: 4
Training loss: 0.7841178178787231
Validation loss: 2.173735777537028

Epoch: 5| Step: 5
Training loss: 1.0291982889175415
Validation loss: 2.2008534719546637

Epoch: 5| Step: 6
Training loss: 0.6429627537727356
Validation loss: 2.1233501185973487

Epoch: 5| Step: 7
Training loss: 0.6580368876457214
Validation loss: 2.215891033411026

Epoch: 5| Step: 8
Training loss: 1.4074382781982422
Validation loss: 2.2195134113232293

Epoch: 5| Step: 9
Training loss: 1.0092650651931763
Validation loss: 2.149026627341906

Epoch: 5| Step: 10
Training loss: 0.8330696225166321
Validation loss: 2.213818738857905

Epoch: 5| Step: 11
Training loss: 1.0311936140060425
Validation loss: 2.1995814939339957

Epoch: 251| Step: 0
Training loss: 1.2419040203094482
Validation loss: 2.256100674470266

Epoch: 5| Step: 1
Training loss: 0.6029919385910034
Validation loss: 2.2092104852199554

Epoch: 5| Step: 2
Training loss: 0.7774596810340881
Validation loss: 2.1900327801704407

Epoch: 5| Step: 3
Training loss: 0.8116313815116882
Validation loss: 2.242880488435427

Epoch: 5| Step: 4
Training loss: 1.0647213459014893
Validation loss: 2.2481075525283813

Epoch: 5| Step: 5
Training loss: 0.8373192548751831
Validation loss: 2.1881232857704163

Epoch: 5| Step: 6
Training loss: 1.1349241733551025
Validation loss: 2.203568711876869

Epoch: 5| Step: 7
Training loss: 1.5091025829315186
Validation loss: 2.2443943272034326

Epoch: 5| Step: 8
Training loss: 0.8979376554489136
Validation loss: 2.1912540992101035

Epoch: 5| Step: 9
Training loss: 0.6592139601707458
Validation loss: 2.201580216487249

Epoch: 5| Step: 10
Training loss: 0.5614940524101257
Validation loss: 2.2574838598569236

Epoch: 5| Step: 11
Training loss: 0.7074015140533447
Validation loss: 2.256742646296819

Epoch: 252| Step: 0
Training loss: 1.2830976247787476
Validation loss: 2.2377518514792123

Epoch: 5| Step: 1
Training loss: 0.6440407037734985
Validation loss: 2.1761131385962167

Epoch: 5| Step: 2
Training loss: 0.8094165921211243
Validation loss: 2.2069030851125717

Epoch: 5| Step: 3
Training loss: 0.9346284866333008
Validation loss: 2.2053525894880295

Epoch: 5| Step: 4
Training loss: 0.820081889629364
Validation loss: 2.2199460864067078

Epoch: 5| Step: 5
Training loss: 0.8569425344467163
Validation loss: 2.164319639404615

Epoch: 5| Step: 6
Training loss: 0.9331125020980835
Validation loss: 2.135087803006172

Epoch: 5| Step: 7
Training loss: 0.6397409439086914
Validation loss: 2.291780153910319

Epoch: 5| Step: 8
Training loss: 1.1949985027313232
Validation loss: 2.205076366662979

Epoch: 5| Step: 9
Training loss: 0.9158976674079895
Validation loss: 2.1886328955491385

Epoch: 5| Step: 10
Training loss: 0.8460687398910522
Validation loss: 2.25733146071434

Epoch: 5| Step: 11
Training loss: 0.2892113924026489
Validation loss: 2.2396799524625144

Epoch: 253| Step: 0
Training loss: 0.8319820165634155
Validation loss: 2.2093473821878433

Epoch: 5| Step: 1
Training loss: 1.327162504196167
Validation loss: 2.2544143001238504

Epoch: 5| Step: 2
Training loss: 1.133934497833252
Validation loss: 2.1804864406585693

Epoch: 5| Step: 3
Training loss: 0.9949789047241211
Validation loss: 2.2726964950561523

Epoch: 5| Step: 4
Training loss: 0.8503740429878235
Validation loss: 2.1494537045558295

Epoch: 5| Step: 5
Training loss: 0.880200982093811
Validation loss: 2.2160401145617166

Epoch: 5| Step: 6
Training loss: 0.873979389667511
Validation loss: 2.177061984936396

Epoch: 5| Step: 7
Training loss: 0.8669508695602417
Validation loss: 2.191327934463819

Epoch: 5| Step: 8
Training loss: 0.5896508693695068
Validation loss: 2.143563613295555

Epoch: 5| Step: 9
Training loss: 0.9263091087341309
Validation loss: 2.2671840488910675

Epoch: 5| Step: 10
Training loss: 0.9127500653266907
Validation loss: 2.1801109512646994

Epoch: 5| Step: 11
Training loss: 0.7160865068435669
Validation loss: 2.2175066570440927

Epoch: 254| Step: 0
Training loss: 0.9963235855102539
Validation loss: 2.2038093308607736

Epoch: 5| Step: 1
Training loss: 0.5400167107582092
Validation loss: 2.224897623062134

Epoch: 5| Step: 2
Training loss: 0.9212216138839722
Validation loss: 2.199904590845108

Epoch: 5| Step: 3
Training loss: 1.2338685989379883
Validation loss: 2.241635024547577

Epoch: 5| Step: 4
Training loss: 0.5006107091903687
Validation loss: 2.2110325346390405

Epoch: 5| Step: 5
Training loss: 1.1699327230453491
Validation loss: 2.187349244952202

Epoch: 5| Step: 6
Training loss: 0.9176643490791321
Validation loss: 2.253492295742035

Epoch: 5| Step: 7
Training loss: 0.8052207231521606
Validation loss: 2.1967890560626984

Epoch: 5| Step: 8
Training loss: 0.9307867884635925
Validation loss: 2.1552164802948632

Epoch: 5| Step: 9
Training loss: 0.9286454916000366
Validation loss: 2.1920133332411447

Epoch: 5| Step: 10
Training loss: 0.7761832475662231
Validation loss: 2.2435247798760733

Epoch: 5| Step: 11
Training loss: 1.2159349918365479
Validation loss: 2.228626102209091

Epoch: 255| Step: 0
Training loss: 0.6527507901191711
Validation loss: 2.2335727314154306

Epoch: 5| Step: 1
Training loss: 0.9593126177787781
Validation loss: 2.230040689309438

Epoch: 5| Step: 2
Training loss: 0.9244672656059265
Validation loss: 2.1921113232771554

Epoch: 5| Step: 3
Training loss: 0.891924262046814
Validation loss: 2.196689714988073

Epoch: 5| Step: 4
Training loss: 1.0398733615875244
Validation loss: 2.2054874499638877

Epoch: 5| Step: 5
Training loss: 0.7610378265380859
Validation loss: 2.187385971347491

Epoch: 5| Step: 6
Training loss: 0.9553980827331543
Validation loss: 2.277286484837532

Epoch: 5| Step: 7
Training loss: 0.8561514019966125
Validation loss: 2.2311490923166275

Epoch: 5| Step: 8
Training loss: 0.9233525991439819
Validation loss: 2.241501599550247

Epoch: 5| Step: 9
Training loss: 0.7456455230712891
Validation loss: 2.2700033287207284

Epoch: 5| Step: 10
Training loss: 1.2436033487319946
Validation loss: 2.2146882712841034

Epoch: 5| Step: 11
Training loss: 0.20779234170913696
Validation loss: 2.275332639614741

Epoch: 256| Step: 0
Training loss: 0.7785224318504333
Validation loss: 2.244839052359263

Epoch: 5| Step: 1
Training loss: 0.8779985308647156
Validation loss: 2.2004376550515494

Epoch: 5| Step: 2
Training loss: 0.727294921875
Validation loss: 2.270299961169561

Epoch: 5| Step: 3
Training loss: 1.2076364755630493
Validation loss: 2.1910177071889243

Epoch: 5| Step: 4
Training loss: 0.534687876701355
Validation loss: 2.2304112364848456

Epoch: 5| Step: 5
Training loss: 1.332276701927185
Validation loss: 2.2341705014308295

Epoch: 5| Step: 6
Training loss: 0.9975202679634094
Validation loss: 2.2565287401278815

Epoch: 5| Step: 7
Training loss: 1.0554704666137695
Validation loss: 2.1900769720474877

Epoch: 5| Step: 8
Training loss: 0.48011869192123413
Validation loss: 2.2312632898489633

Epoch: 5| Step: 9
Training loss: 1.056309461593628
Validation loss: 2.1801801323890686

Epoch: 5| Step: 10
Training loss: 0.7083407640457153
Validation loss: 2.222493534286817

Epoch: 5| Step: 11
Training loss: 0.37281471490859985
Validation loss: 2.219130963087082

Epoch: 257| Step: 0
Training loss: 0.9582328796386719
Validation loss: 2.1929831008116403

Epoch: 5| Step: 1
Training loss: 0.9903125762939453
Validation loss: 2.1735157718261084

Epoch: 5| Step: 2
Training loss: 1.1962947845458984
Validation loss: 2.264722386995951

Epoch: 5| Step: 3
Training loss: 0.8958737254142761
Validation loss: 2.26898659269015

Epoch: 5| Step: 4
Training loss: 0.9565011262893677
Validation loss: 2.3085830410321555

Epoch: 5| Step: 5
Training loss: 0.7992885112762451
Validation loss: 2.2056295971075692

Epoch: 5| Step: 6
Training loss: 0.7181072235107422
Validation loss: 2.2607070257266364

Epoch: 5| Step: 7
Training loss: 0.5938757061958313
Validation loss: 2.2765353371699653

Epoch: 5| Step: 8
Training loss: 0.6049131155014038
Validation loss: 2.222755044698715

Epoch: 5| Step: 9
Training loss: 1.2623214721679688
Validation loss: 2.2550186862548194

Epoch: 5| Step: 10
Training loss: 0.9641860723495483
Validation loss: 2.2566450983285904

Epoch: 5| Step: 11
Training loss: 0.49453985691070557
Validation loss: 2.201692303021749

Epoch: 258| Step: 0
Training loss: 1.246383547782898
Validation loss: 2.245493312676748

Epoch: 5| Step: 1
Training loss: 1.0258668661117554
Validation loss: 2.206920156876246

Epoch: 5| Step: 2
Training loss: 0.3682960271835327
Validation loss: 2.2264467974503837

Epoch: 5| Step: 3
Training loss: 0.6074568033218384
Validation loss: 2.271438499291738

Epoch: 5| Step: 4
Training loss: 0.8703212738037109
Validation loss: 2.2081627448399863

Epoch: 5| Step: 5
Training loss: 0.9551733136177063
Validation loss: 2.168542578816414

Epoch: 5| Step: 6
Training loss: 0.6725172996520996
Validation loss: 2.1682916631301246

Epoch: 5| Step: 7
Training loss: 0.9869905710220337
Validation loss: 2.241822193066279

Epoch: 5| Step: 8
Training loss: 1.0022878646850586
Validation loss: 2.24045596520106

Epoch: 5| Step: 9
Training loss: 0.9433392286300659
Validation loss: 2.1762331624825797

Epoch: 5| Step: 10
Training loss: 0.6331365704536438
Validation loss: 2.2622921566168466

Epoch: 5| Step: 11
Training loss: 0.5119245052337646
Validation loss: 2.187594920396805

Epoch: 259| Step: 0
Training loss: 1.0462143421173096
Validation loss: 2.1907494515180588

Epoch: 5| Step: 1
Training loss: 0.6798824071884155
Validation loss: 2.216993361711502

Epoch: 5| Step: 2
Training loss: 0.9909700155258179
Validation loss: 2.279276599486669

Epoch: 5| Step: 3
Training loss: 0.8619577288627625
Validation loss: 2.217587331930796

Epoch: 5| Step: 4
Training loss: 0.72468501329422
Validation loss: 2.202875778079033

Epoch: 5| Step: 5
Training loss: 1.0217390060424805
Validation loss: 2.2037595560153327

Epoch: 5| Step: 6
Training loss: 0.9573943018913269
Validation loss: 2.1946507592995963

Epoch: 5| Step: 7
Training loss: 0.7689342498779297
Validation loss: 2.227136249343554

Epoch: 5| Step: 8
Training loss: 0.7955392599105835
Validation loss: 2.254839469989141

Epoch: 5| Step: 9
Training loss: 0.9058807492256165
Validation loss: 2.2593093862136207

Epoch: 5| Step: 10
Training loss: 0.9601678848266602
Validation loss: 2.199236353238424

Epoch: 5| Step: 11
Training loss: 1.1354444026947021
Validation loss: 2.2354938785235086

Epoch: 260| Step: 0
Training loss: 1.266786813735962
Validation loss: 2.296810880303383

Epoch: 5| Step: 1
Training loss: 0.7763417959213257
Validation loss: 2.303958088159561

Epoch: 5| Step: 2
Training loss: 0.7955654859542847
Validation loss: 2.32597508529822

Epoch: 5| Step: 3
Training loss: 0.6649945974349976
Validation loss: 2.1953279425700507

Epoch: 5| Step: 4
Training loss: 1.019190788269043
Validation loss: 2.176137109597524

Epoch: 5| Step: 5
Training loss: 0.46956387162208557
Validation loss: 2.2564672430356345

Epoch: 5| Step: 6
Training loss: 0.6637985706329346
Validation loss: 2.2364463110764823

Epoch: 5| Step: 7
Training loss: 1.0271472930908203
Validation loss: 2.1842643320560455

Epoch: 5| Step: 8
Training loss: 0.8402964472770691
Validation loss: 2.2175944248835244

Epoch: 5| Step: 9
Training loss: 0.6325399875640869
Validation loss: 2.182209849357605

Epoch: 5| Step: 10
Training loss: 0.921890914440155
Validation loss: 2.218945066134135

Epoch: 5| Step: 11
Training loss: 1.8369700908660889
Validation loss: 2.116832911968231

Epoch: 261| Step: 0
Training loss: 0.7985748052597046
Validation loss: 2.233147700627645

Epoch: 5| Step: 1
Training loss: 1.0071295499801636
Validation loss: 2.2161746521790824

Epoch: 5| Step: 2
Training loss: 0.5493178367614746
Validation loss: 2.2495163083076477

Epoch: 5| Step: 3
Training loss: 0.7606792449951172
Validation loss: 2.3182032456000647

Epoch: 5| Step: 4
Training loss: 1.0415153503417969
Validation loss: 2.240411842862765

Epoch: 5| Step: 5
Training loss: 0.7886598706245422
Validation loss: 2.229234923919042

Epoch: 5| Step: 6
Training loss: 1.0849382877349854
Validation loss: 2.201669236024221

Epoch: 5| Step: 7
Training loss: 1.0739048719406128
Validation loss: 2.2756202618281045

Epoch: 5| Step: 8
Training loss: 0.9942089915275574
Validation loss: 2.27055116991202

Epoch: 5| Step: 9
Training loss: 0.7625223994255066
Validation loss: 2.3131425976753235

Epoch: 5| Step: 10
Training loss: 0.7623559236526489
Validation loss: 2.236884663502375

Epoch: 5| Step: 11
Training loss: 2.2947146892547607
Validation loss: 2.233936900893847

Epoch: 262| Step: 0
Training loss: 0.9802045822143555
Validation loss: 2.2294597029685974

Epoch: 5| Step: 1
Training loss: 0.7371324300765991
Validation loss: 2.242182289560636

Epoch: 5| Step: 2
Training loss: 0.7967647314071655
Validation loss: 2.209387719631195

Epoch: 5| Step: 3
Training loss: 0.8251389265060425
Validation loss: 2.192181959748268

Epoch: 5| Step: 4
Training loss: 1.018334150314331
Validation loss: 2.2364574472109475

Epoch: 5| Step: 5
Training loss: 0.9089673757553101
Validation loss: 2.283164689938227

Epoch: 5| Step: 6
Training loss: 0.942279040813446
Validation loss: 2.281163061658541

Epoch: 5| Step: 7
Training loss: 0.5946099162101746
Validation loss: 2.172979270418485

Epoch: 5| Step: 8
Training loss: 0.6738241910934448
Validation loss: 2.3061336874961853

Epoch: 5| Step: 9
Training loss: 0.7310792207717896
Validation loss: 2.245619128147761

Epoch: 5| Step: 10
Training loss: 1.2191522121429443
Validation loss: 2.2735124826431274

Epoch: 5| Step: 11
Training loss: 0.3937376141548157
Validation loss: 2.23475681245327

Epoch: 263| Step: 0
Training loss: 0.4718788266181946
Validation loss: 2.2922910948594413

Epoch: 5| Step: 1
Training loss: 1.0121560096740723
Validation loss: 2.253349632024765

Epoch: 5| Step: 2
Training loss: 0.9207813143730164
Validation loss: 2.2099708716074624

Epoch: 5| Step: 3
Training loss: 0.8564834594726562
Validation loss: 2.235021243492762

Epoch: 5| Step: 4
Training loss: 1.161655068397522
Validation loss: 2.177320664127668

Epoch: 5| Step: 5
Training loss: 0.5903541445732117
Validation loss: 2.2298712531725564

Epoch: 5| Step: 6
Training loss: 0.8555569648742676
Validation loss: 2.1638805121183395

Epoch: 5| Step: 7
Training loss: 1.436669111251831
Validation loss: 2.1437549044688544

Epoch: 5| Step: 8
Training loss: 0.5284274816513062
Validation loss: 2.1629601617654166

Epoch: 5| Step: 9
Training loss: 0.7570371627807617
Validation loss: 2.2998372614383698

Epoch: 5| Step: 10
Training loss: 0.7349169850349426
Validation loss: 2.2112900962432227

Epoch: 5| Step: 11
Training loss: 0.4101719856262207
Validation loss: 2.2570458004872003

Epoch: 264| Step: 0
Training loss: 0.7181324362754822
Validation loss: 2.2254796226819358

Epoch: 5| Step: 1
Training loss: 0.7616735696792603
Validation loss: 2.1979856292406716

Epoch: 5| Step: 2
Training loss: 0.848790168762207
Validation loss: 2.2178643941879272

Epoch: 5| Step: 3
Training loss: 0.9229788780212402
Validation loss: 2.17659984032313

Epoch: 5| Step: 4
Training loss: 0.5815210342407227
Validation loss: 2.2588462134202323

Epoch: 5| Step: 5
Training loss: 0.9235156178474426
Validation loss: 2.2327326287825904

Epoch: 5| Step: 6
Training loss: 0.7998529672622681
Validation loss: 2.1892600605885186

Epoch: 5| Step: 7
Training loss: 0.8724386096000671
Validation loss: 2.2621631820996604

Epoch: 5| Step: 8
Training loss: 0.6364356875419617
Validation loss: 2.2215598126252494

Epoch: 5| Step: 9
Training loss: 1.2423908710479736
Validation loss: 2.162327935298284

Epoch: 5| Step: 10
Training loss: 0.6396105885505676
Validation loss: 2.18089097738266

Epoch: 5| Step: 11
Training loss: 1.3371402025222778
Validation loss: 2.2056755324204764

Epoch: 265| Step: 0
Training loss: 0.6848396062850952
Validation loss: 2.2518562177817025

Epoch: 5| Step: 1
Training loss: 1.2759168148040771
Validation loss: 2.2913601994514465

Epoch: 5| Step: 2
Training loss: 1.0197066068649292
Validation loss: 2.1785684625307717

Epoch: 5| Step: 3
Training loss: 0.761445939540863
Validation loss: 2.2319117287794747

Epoch: 5| Step: 4
Training loss: 0.8991507291793823
Validation loss: 2.189560443162918

Epoch: 5| Step: 5
Training loss: 0.843944251537323
Validation loss: 2.203981031974157

Epoch: 5| Step: 6
Training loss: 0.6742960214614868
Validation loss: 2.1930847813685737

Epoch: 5| Step: 7
Training loss: 0.9374653697013855
Validation loss: 2.251979033152262

Epoch: 5| Step: 8
Training loss: 0.7798944711685181
Validation loss: 2.2134397824605307

Epoch: 5| Step: 9
Training loss: 0.7102735638618469
Validation loss: 2.2013705472151437

Epoch: 5| Step: 10
Training loss: 1.0073846578598022
Validation loss: 2.1596969117720923

Epoch: 5| Step: 11
Training loss: 1.131386399269104
Validation loss: 2.2977285037438073

Epoch: 266| Step: 0
Training loss: 0.5010011196136475
Validation loss: 2.2290545801321664

Epoch: 5| Step: 1
Training loss: 0.8751109838485718
Validation loss: 2.2481242616971335

Epoch: 5| Step: 2
Training loss: 0.8398558497428894
Validation loss: 2.1977554659048715

Epoch: 5| Step: 3
Training loss: 1.0703907012939453
Validation loss: 2.2392449378967285

Epoch: 5| Step: 4
Training loss: 1.0563067197799683
Validation loss: 2.2208769222100577

Epoch: 5| Step: 5
Training loss: 0.646239161491394
Validation loss: 2.2630009949207306

Epoch: 5| Step: 6
Training loss: 1.0140293836593628
Validation loss: 2.2871602376302085

Epoch: 5| Step: 7
Training loss: 0.8575018048286438
Validation loss: 2.178652375936508

Epoch: 5| Step: 8
Training loss: 0.8123428225517273
Validation loss: 2.209915116429329

Epoch: 5| Step: 9
Training loss: 0.8287487030029297
Validation loss: 2.1812573870023093

Epoch: 5| Step: 10
Training loss: 0.6897159218788147
Validation loss: 2.2588170568148294

Epoch: 5| Step: 11
Training loss: 1.1747885942459106
Validation loss: 2.240704302986463

Epoch: 267| Step: 0
Training loss: 0.3925418555736542
Validation loss: 2.1781075994173684

Epoch: 5| Step: 1
Training loss: 0.6397567987442017
Validation loss: 2.156568929553032

Epoch: 5| Step: 2
Training loss: 0.6894611120223999
Validation loss: 2.2526652415593467

Epoch: 5| Step: 3
Training loss: 1.2727158069610596
Validation loss: 2.2037872672080994

Epoch: 5| Step: 4
Training loss: 0.7087199091911316
Validation loss: 2.2243282794952393

Epoch: 5| Step: 5
Training loss: 0.8020431399345398
Validation loss: 2.2262086023887

Epoch: 5| Step: 6
Training loss: 0.7432463765144348
Validation loss: 2.2063804070154824

Epoch: 5| Step: 7
Training loss: 0.8248196840286255
Validation loss: 2.1726052463054657

Epoch: 5| Step: 8
Training loss: 0.7865960597991943
Validation loss: 2.2313664058844247

Epoch: 5| Step: 9
Training loss: 1.0189087390899658
Validation loss: 2.1985965818166733

Epoch: 5| Step: 10
Training loss: 1.1553943157196045
Validation loss: 2.22879895567894

Epoch: 5| Step: 11
Training loss: 1.646059274673462
Validation loss: 2.2598850627740226

Epoch: 268| Step: 0
Training loss: 0.6431118249893188
Validation loss: 2.1681272039810815

Epoch: 5| Step: 1
Training loss: 0.5616718530654907
Validation loss: 2.177283853292465

Epoch: 5| Step: 2
Training loss: 0.6239425539970398
Validation loss: 2.269973417123159

Epoch: 5| Step: 3
Training loss: 0.6702966094017029
Validation loss: 2.1974488645792007

Epoch: 5| Step: 4
Training loss: 1.2755998373031616
Validation loss: 2.189114804069201

Epoch: 5| Step: 5
Training loss: 1.1528068780899048
Validation loss: 2.2641805758078895

Epoch: 5| Step: 6
Training loss: 0.6898943185806274
Validation loss: 2.172242154677709

Epoch: 5| Step: 7
Training loss: 0.737129807472229
Validation loss: 2.2744080225626626

Epoch: 5| Step: 8
Training loss: 1.195619821548462
Validation loss: 2.1689809411764145

Epoch: 5| Step: 9
Training loss: 0.6425277590751648
Validation loss: 2.253412425518036

Epoch: 5| Step: 10
Training loss: 0.9057475328445435
Validation loss: 2.231354927023252

Epoch: 5| Step: 11
Training loss: 0.49755576252937317
Validation loss: 2.268613268931707

Epoch: 269| Step: 0
Training loss: 0.6128511428833008
Validation loss: 2.2266411582628884

Epoch: 5| Step: 1
Training loss: 0.6675794720649719
Validation loss: 2.2051835109790168

Epoch: 5| Step: 2
Training loss: 0.8195849657058716
Validation loss: 2.215375875433286

Epoch: 5| Step: 3
Training loss: 0.9586095809936523
Validation loss: 2.245010102788607

Epoch: 5| Step: 4
Training loss: 0.7800034284591675
Validation loss: 2.2265502313772836

Epoch: 5| Step: 5
Training loss: 0.9862362146377563
Validation loss: 2.2188265721003213

Epoch: 5| Step: 6
Training loss: 0.8117935061454773
Validation loss: 2.183144281307856

Epoch: 5| Step: 7
Training loss: 0.9366288185119629
Validation loss: 2.2027018815279007

Epoch: 5| Step: 8
Training loss: 0.5127672553062439
Validation loss: 2.2073525289694467

Epoch: 5| Step: 9
Training loss: 0.7874945402145386
Validation loss: 2.2159567028284073

Epoch: 5| Step: 10
Training loss: 0.8447786569595337
Validation loss: 2.222861647605896

Epoch: 5| Step: 11
Training loss: 1.004550576210022
Validation loss: 2.209266056617101

Epoch: 270| Step: 0
Training loss: 0.8630098104476929
Validation loss: 2.2309793531894684

Epoch: 5| Step: 1
Training loss: 0.8196321725845337
Validation loss: 2.2570177614688873

Epoch: 5| Step: 2
Training loss: 0.7706448435783386
Validation loss: 2.1920726150274277

Epoch: 5| Step: 3
Training loss: 0.936700165271759
Validation loss: 2.1872235337893167

Epoch: 5| Step: 4
Training loss: 0.7079300880432129
Validation loss: 2.2411261399586997

Epoch: 5| Step: 5
Training loss: 0.5181141495704651
Validation loss: 2.218141039212545

Epoch: 5| Step: 6
Training loss: 0.829311192035675
Validation loss: 2.3031111458937326

Epoch: 5| Step: 7
Training loss: 0.7731568217277527
Validation loss: 2.220479001601537

Epoch: 5| Step: 8
Training loss: 0.5205227136611938
Validation loss: 2.2899778683980307

Epoch: 5| Step: 9
Training loss: 1.4626392126083374
Validation loss: 2.2070850233236947

Epoch: 5| Step: 10
Training loss: 1.1259586811065674
Validation loss: 2.2369358241558075

Epoch: 5| Step: 11
Training loss: 0.3723123073577881
Validation loss: 2.1990213692188263

Epoch: 271| Step: 0
Training loss: 0.6132084727287292
Validation loss: 2.246956840157509

Epoch: 5| Step: 1
Training loss: 1.20298171043396
Validation loss: 2.254403298099836

Epoch: 5| Step: 2
Training loss: 1.038806676864624
Validation loss: 2.1886898825565972

Epoch: 5| Step: 3
Training loss: 0.654708206653595
Validation loss: 2.244246691465378

Epoch: 5| Step: 4
Training loss: 0.8771737813949585
Validation loss: 2.1748217741648355

Epoch: 5| Step: 5
Training loss: 0.6321514248847961
Validation loss: 2.2411084274450936

Epoch: 5| Step: 6
Training loss: 0.6553049087524414
Validation loss: 2.24983674287796

Epoch: 5| Step: 7
Training loss: 0.9757946729660034
Validation loss: 2.2439541816711426

Epoch: 5| Step: 8
Training loss: 0.6323373913764954
Validation loss: 2.23040501276652

Epoch: 5| Step: 9
Training loss: 0.8186287879943848
Validation loss: 2.221119523048401

Epoch: 5| Step: 10
Training loss: 0.9534810185432434
Validation loss: 2.235989605387052

Epoch: 5| Step: 11
Training loss: 1.001814365386963
Validation loss: 2.2182571291923523

Epoch: 272| Step: 0
Training loss: 0.48836928606033325
Validation loss: 2.2175390472014747

Epoch: 5| Step: 1
Training loss: 0.9872832298278809
Validation loss: 2.161108752091726

Epoch: 5| Step: 2
Training loss: 0.9595340490341187
Validation loss: 2.222125162680944

Epoch: 5| Step: 3
Training loss: 0.8001529574394226
Validation loss: 2.1650401254494986

Epoch: 5| Step: 4
Training loss: 1.1423975229263306
Validation loss: 2.168878828485807

Epoch: 5| Step: 5
Training loss: 1.2130793333053589
Validation loss: 2.1145221143960953

Epoch: 5| Step: 6
Training loss: 0.5638373494148254
Validation loss: 2.2629947115977607

Epoch: 5| Step: 7
Training loss: 0.47774738073349
Validation loss: 2.1453387836615243

Epoch: 5| Step: 8
Training loss: 0.9192047119140625
Validation loss: 2.140472168723742

Epoch: 5| Step: 9
Training loss: 0.6946592926979065
Validation loss: 2.1935419936974845

Epoch: 5| Step: 10
Training loss: 1.017944097518921
Validation loss: 2.1488552689552307

Epoch: 5| Step: 11
Training loss: 1.4851748943328857
Validation loss: 2.1805631120999656

Epoch: 273| Step: 0
Training loss: 1.1083003282546997
Validation loss: 2.1969937284787497

Epoch: 5| Step: 1
Training loss: 1.0982303619384766
Validation loss: 2.2077486415704093

Epoch: 5| Step: 2
Training loss: 0.9958437085151672
Validation loss: 2.1872984766960144

Epoch: 5| Step: 3
Training loss: 0.949073314666748
Validation loss: 2.207896957794825

Epoch: 5| Step: 4
Training loss: 0.5067645907402039
Validation loss: 2.227480486035347

Epoch: 5| Step: 5
Training loss: 0.962759792804718
Validation loss: 2.204239989320437

Epoch: 5| Step: 6
Training loss: 0.711805522441864
Validation loss: 2.2365550994873047

Epoch: 5| Step: 7
Training loss: 0.6388084292411804
Validation loss: 2.278591667612394

Epoch: 5| Step: 8
Training loss: 0.46521490812301636
Validation loss: 2.170003667473793

Epoch: 5| Step: 9
Training loss: 0.6988935470581055
Validation loss: 2.221308226386706

Epoch: 5| Step: 10
Training loss: 0.6942055821418762
Validation loss: 2.223939855893453

Epoch: 5| Step: 11
Training loss: 0.6691737771034241
Validation loss: 2.234299490849177

Epoch: 274| Step: 0
Training loss: 0.611980140209198
Validation loss: 2.214638282855352

Epoch: 5| Step: 1
Training loss: 1.2298561334609985
Validation loss: 2.219425698121389

Epoch: 5| Step: 2
Training loss: 0.7339963912963867
Validation loss: 2.2939852525790534

Epoch: 5| Step: 3
Training loss: 0.5231727361679077
Validation loss: 2.20926042397817

Epoch: 5| Step: 4
Training loss: 0.8597081303596497
Validation loss: 2.187579497694969

Epoch: 5| Step: 5
Training loss: 0.6800539493560791
Validation loss: 2.2254395733277

Epoch: 5| Step: 6
Training loss: 1.2433161735534668
Validation loss: 2.2961658388376236

Epoch: 5| Step: 7
Training loss: 0.48332110047340393
Validation loss: 2.254672338565191

Epoch: 5| Step: 8
Training loss: 0.7747815847396851
Validation loss: 2.2280169228712716

Epoch: 5| Step: 9
Training loss: 0.5074154138565063
Validation loss: 2.175680622458458

Epoch: 5| Step: 10
Training loss: 1.4111518859863281
Validation loss: 2.207256327072779

Epoch: 5| Step: 11
Training loss: 0.40764936804771423
Validation loss: 2.3027338484923043

Epoch: 275| Step: 0
Training loss: 0.690739631652832
Validation loss: 2.2449478656053543

Epoch: 5| Step: 1
Training loss: 0.7454290986061096
Validation loss: 2.304470251003901

Epoch: 5| Step: 2
Training loss: 0.6805300712585449
Validation loss: 2.22164286673069

Epoch: 5| Step: 3
Training loss: 0.9423149824142456
Validation loss: 2.20907823741436

Epoch: 5| Step: 4
Training loss: 0.632940411567688
Validation loss: 2.2933831264575324

Epoch: 5| Step: 5
Training loss: 0.5931898355484009
Validation loss: 2.200794671972593

Epoch: 5| Step: 6
Training loss: 0.7650267481803894
Validation loss: 2.145144691069921

Epoch: 5| Step: 7
Training loss: 0.8626998662948608
Validation loss: 2.2504798670609794

Epoch: 5| Step: 8
Training loss: 0.9846417307853699
Validation loss: 2.2086969316005707

Epoch: 5| Step: 9
Training loss: 0.8533012270927429
Validation loss: 2.2807696809371314

Epoch: 5| Step: 10
Training loss: 1.4080395698547363
Validation loss: 2.2006245801846185

Epoch: 5| Step: 11
Training loss: 1.4256367683410645
Validation loss: 2.221820294857025

Epoch: 276| Step: 0
Training loss: 1.157676339149475
Validation loss: 2.2594786137342453

Epoch: 5| Step: 1
Training loss: 1.0084611177444458
Validation loss: 2.2422052721182504

Epoch: 5| Step: 2
Training loss: 0.8509368896484375
Validation loss: 2.1909982562065125

Epoch: 5| Step: 3
Training loss: 0.7902606129646301
Validation loss: 2.2817657589912415

Epoch: 5| Step: 4
Training loss: 0.9511641263961792
Validation loss: 2.2484329690535865

Epoch: 5| Step: 5
Training loss: 0.9075851440429688
Validation loss: 2.227527598539988

Epoch: 5| Step: 6
Training loss: 1.3769296407699585
Validation loss: 2.2392645428578057

Epoch: 5| Step: 7
Training loss: 0.4918902516365051
Validation loss: 2.193720370531082

Epoch: 5| Step: 8
Training loss: 0.6755945086479187
Validation loss: 2.242769956588745

Epoch: 5| Step: 9
Training loss: 0.9905662536621094
Validation loss: 2.227140868703524

Epoch: 5| Step: 10
Training loss: 0.8195204734802246
Validation loss: 2.2197572886943817

Epoch: 5| Step: 11
Training loss: 0.4536163806915283
Validation loss: 2.2556072970231376

Epoch: 277| Step: 0
Training loss: 1.010530948638916
Validation loss: 2.2362578908602395

Epoch: 5| Step: 1
Training loss: 0.7368362545967102
Validation loss: 2.2071880946556726

Epoch: 5| Step: 2
Training loss: 0.9192526936531067
Validation loss: 2.1842017769813538

Epoch: 5| Step: 3
Training loss: 0.7186845541000366
Validation loss: 2.17423515021801

Epoch: 5| Step: 4
Training loss: 0.7265334725379944
Validation loss: 2.191903923948606

Epoch: 5| Step: 5
Training loss: 0.6680809259414673
Validation loss: 2.199920708934466

Epoch: 5| Step: 6
Training loss: 0.8867279887199402
Validation loss: 2.2405656526486077

Epoch: 5| Step: 7
Training loss: 0.591763973236084
Validation loss: 2.2777459621429443

Epoch: 5| Step: 8
Training loss: 1.0389809608459473
Validation loss: 2.2131479382514954

Epoch: 5| Step: 9
Training loss: 1.369197130203247
Validation loss: 2.179060329993566

Epoch: 5| Step: 10
Training loss: 0.656948447227478
Validation loss: 2.2351996997992196

Epoch: 5| Step: 11
Training loss: 0.5731619596481323
Validation loss: 2.2767022053400674

Epoch: 278| Step: 0
Training loss: 0.7533921599388123
Validation loss: 2.2594618052244186

Epoch: 5| Step: 1
Training loss: 0.5383387804031372
Validation loss: 2.1926721384127936

Epoch: 5| Step: 2
Training loss: 0.7316537499427795
Validation loss: 2.2199666996796927

Epoch: 5| Step: 3
Training loss: 0.5616846680641174
Validation loss: 2.2844365934530892

Epoch: 5| Step: 4
Training loss: 0.9026373028755188
Validation loss: 2.197986364364624

Epoch: 5| Step: 5
Training loss: 1.2181810140609741
Validation loss: 2.298359235127767

Epoch: 5| Step: 6
Training loss: 0.7835871577262878
Validation loss: 2.238918016354243

Epoch: 5| Step: 7
Training loss: 0.43336692452430725
Validation loss: 2.181277856230736

Epoch: 5| Step: 8
Training loss: 1.0929787158966064
Validation loss: 2.2554468711217246

Epoch: 5| Step: 9
Training loss: 0.7282620668411255
Validation loss: 2.264465535680453

Epoch: 5| Step: 10
Training loss: 0.9497424960136414
Validation loss: 2.2045225898424783

Epoch: 5| Step: 11
Training loss: 1.372361183166504
Validation loss: 2.2385792831579843

Epoch: 279| Step: 0
Training loss: 0.6971331834793091
Validation loss: 2.1967377761999765

Epoch: 5| Step: 1
Training loss: 0.6570645570755005
Validation loss: 2.260484422246615

Epoch: 5| Step: 2
Training loss: 0.7540866732597351
Validation loss: 2.2333353559176126

Epoch: 5| Step: 3
Training loss: 0.8563812375068665
Validation loss: 2.197537069519361

Epoch: 5| Step: 4
Training loss: 1.1438244581222534
Validation loss: 2.2177945176760354

Epoch: 5| Step: 5
Training loss: 1.0115045309066772
Validation loss: 2.249582956234614

Epoch: 5| Step: 6
Training loss: 0.6324151754379272
Validation loss: 2.2437373797098794

Epoch: 5| Step: 7
Training loss: 0.8237130045890808
Validation loss: 2.262913624445597

Epoch: 5| Step: 8
Training loss: 0.7918540835380554
Validation loss: 2.2323218981424966

Epoch: 5| Step: 9
Training loss: 0.6816167831420898
Validation loss: 2.2064429819583893

Epoch: 5| Step: 10
Training loss: 0.7122259736061096
Validation loss: 2.2113725344340005

Epoch: 5| Step: 11
Training loss: 1.3204028606414795
Validation loss: 2.1814472377300262

Epoch: 280| Step: 0
Training loss: 0.8863736987113953
Validation loss: 2.2653850466012955

Epoch: 5| Step: 1
Training loss: 0.7493883967399597
Validation loss: 2.198430687189102

Epoch: 5| Step: 2
Training loss: 0.478370726108551
Validation loss: 2.173662061492602

Epoch: 5| Step: 3
Training loss: 0.910772979259491
Validation loss: 2.1741172124942145

Epoch: 5| Step: 4
Training loss: 0.8546980023384094
Validation loss: 2.26024496058623

Epoch: 5| Step: 5
Training loss: 0.7414853572845459
Validation loss: 2.2918812880913415

Epoch: 5| Step: 6
Training loss: 0.7478166222572327
Validation loss: 2.2217230945825577

Epoch: 5| Step: 7
Training loss: 1.1316611766815186
Validation loss: 2.2884528587261834

Epoch: 5| Step: 8
Training loss: 0.5561400651931763
Validation loss: 2.265717178583145

Epoch: 5| Step: 9
Training loss: 0.9726161956787109
Validation loss: 2.238326961795489

Epoch: 5| Step: 10
Training loss: 1.0365123748779297
Validation loss: 2.1626116732756295

Epoch: 5| Step: 11
Training loss: 0.7102556228637695
Validation loss: 2.1797553300857544

Epoch: 281| Step: 0
Training loss: 0.5700588226318359
Validation loss: 2.1737250089645386

Epoch: 5| Step: 1
Training loss: 1.001414179801941
Validation loss: 2.2277007400989532

Epoch: 5| Step: 2
Training loss: 0.7162624001502991
Validation loss: 2.2272457977135978

Epoch: 5| Step: 3
Training loss: 0.5870780944824219
Validation loss: 2.183895379304886

Epoch: 5| Step: 4
Training loss: 0.5325621366500854
Validation loss: 2.1967072635889053

Epoch: 5| Step: 5
Training loss: 0.612338662147522
Validation loss: 2.1817557911078134

Epoch: 5| Step: 6
Training loss: 0.7789754867553711
Validation loss: 2.194543664654096

Epoch: 5| Step: 7
Training loss: 0.4417346119880676
Validation loss: 2.203034450610479

Epoch: 5| Step: 8
Training loss: 0.9355300664901733
Validation loss: 2.1576108932495117

Epoch: 5| Step: 9
Training loss: 1.1383626461029053
Validation loss: 2.2635307361682258

Epoch: 5| Step: 10
Training loss: 1.0072729587554932
Validation loss: 2.1935564279556274

Epoch: 5| Step: 11
Training loss: 1.081445336341858
Validation loss: 2.21459569533666

Epoch: 282| Step: 0
Training loss: 0.5895400047302246
Validation loss: 2.1508424431085587

Epoch: 5| Step: 1
Training loss: 0.744347095489502
Validation loss: 2.1413177947203317

Epoch: 5| Step: 2
Training loss: 0.7048729658126831
Validation loss: 2.1386592288812003

Epoch: 5| Step: 3
Training loss: 0.6910850405693054
Validation loss: 2.177854984998703

Epoch: 5| Step: 4
Training loss: 0.9362868070602417
Validation loss: 2.2123456646998725

Epoch: 5| Step: 5
Training loss: 0.9037286043167114
Validation loss: 2.2117677529652915

Epoch: 5| Step: 6
Training loss: 0.5499622225761414
Validation loss: 2.271495540936788

Epoch: 5| Step: 7
Training loss: 0.8032206296920776
Validation loss: 2.1660897533098855

Epoch: 5| Step: 8
Training loss: 0.9493853449821472
Validation loss: 2.250527709722519

Epoch: 5| Step: 9
Training loss: 0.7829773426055908
Validation loss: 2.188328037659327

Epoch: 5| Step: 10
Training loss: 0.9920832514762878
Validation loss: 2.1483757396539054

Epoch: 5| Step: 11
Training loss: 0.3926916718482971
Validation loss: 2.201315258940061

Epoch: 283| Step: 0
Training loss: 0.8122545480728149
Validation loss: 2.1876651446024575

Epoch: 5| Step: 1
Training loss: 0.8097982406616211
Validation loss: 2.207783048351606

Epoch: 5| Step: 2
Training loss: 0.4324163794517517
Validation loss: 2.251370926698049

Epoch: 5| Step: 3
Training loss: 0.8834419250488281
Validation loss: 2.1677198658386865

Epoch: 5| Step: 4
Training loss: 0.8050495982170105
Validation loss: 2.197691132624944

Epoch: 5| Step: 5
Training loss: 0.8653348088264465
Validation loss: 2.191777835289637

Epoch: 5| Step: 6
Training loss: 0.917931079864502
Validation loss: 2.26548570394516

Epoch: 5| Step: 7
Training loss: 0.8420819044113159
Validation loss: 2.232383042573929

Epoch: 5| Step: 8
Training loss: 0.5279049277305603
Validation loss: 2.2457551062107086

Epoch: 5| Step: 9
Training loss: 0.9236807823181152
Validation loss: 2.1314983467260995

Epoch: 5| Step: 10
Training loss: 0.5121228694915771
Validation loss: 2.2843371480703354

Epoch: 5| Step: 11
Training loss: 1.457186222076416
Validation loss: 2.2291257232427597

Epoch: 284| Step: 0
Training loss: 0.7386921644210815
Validation loss: 2.276621942718824

Epoch: 5| Step: 1
Training loss: 0.6896883249282837
Validation loss: 2.2175863683223724

Epoch: 5| Step: 2
Training loss: 0.623311460018158
Validation loss: 2.2889533191919327

Epoch: 5| Step: 3
Training loss: 0.6108266115188599
Validation loss: 2.199132959047953

Epoch: 5| Step: 4
Training loss: 0.4812992513179779
Validation loss: 2.232747127612432

Epoch: 5| Step: 5
Training loss: 0.8636213541030884
Validation loss: 2.1712988714377084

Epoch: 5| Step: 6
Training loss: 0.7111279368400574
Validation loss: 2.247561991214752

Epoch: 5| Step: 7
Training loss: 0.443624347448349
Validation loss: 2.1788592785596848

Epoch: 5| Step: 8
Training loss: 0.9717315435409546
Validation loss: 2.2912813325723014

Epoch: 5| Step: 9
Training loss: 1.4942214488983154
Validation loss: 2.3225621730089188

Epoch: 5| Step: 10
Training loss: 0.6530120372772217
Validation loss: 2.2480134665966034

Epoch: 5| Step: 11
Training loss: 0.6499388813972473
Validation loss: 2.212249750892321

Epoch: 285| Step: 0
Training loss: 0.4343968331813812
Validation loss: 2.1982367634773254

Epoch: 5| Step: 1
Training loss: 0.5157263278961182
Validation loss: 2.230932265520096

Epoch: 5| Step: 2
Training loss: 0.6828328967094421
Validation loss: 2.1442275842030845

Epoch: 5| Step: 3
Training loss: 0.8028039932250977
Validation loss: 2.223142703374227

Epoch: 5| Step: 4
Training loss: 0.6649187803268433
Validation loss: 2.18781316280365

Epoch: 5| Step: 5
Training loss: 1.0137354135513306
Validation loss: 2.213601142168045

Epoch: 5| Step: 6
Training loss: 1.0379081964492798
Validation loss: 2.2701381842295327

Epoch: 5| Step: 7
Training loss: 0.9040414690971375
Validation loss: 2.188374395171801

Epoch: 5| Step: 8
Training loss: 0.8721855282783508
Validation loss: 2.230835661292076

Epoch: 5| Step: 9
Training loss: 0.8393532633781433
Validation loss: 2.205435494581858

Epoch: 5| Step: 10
Training loss: 0.6700378656387329
Validation loss: 2.185225556294123

Epoch: 5| Step: 11
Training loss: 0.4403448700904846
Validation loss: 2.2312417924404144

Epoch: 286| Step: 0
Training loss: 1.1382181644439697
Validation loss: 2.235864828030268

Epoch: 5| Step: 1
Training loss: 0.6065767407417297
Validation loss: 2.1934695641199746

Epoch: 5| Step: 2
Training loss: 0.8677858114242554
Validation loss: 2.176236256957054

Epoch: 5| Step: 3
Training loss: 0.9501850008964539
Validation loss: 2.2921356161435447

Epoch: 5| Step: 4
Training loss: 0.7862507104873657
Validation loss: 2.2060345659653344

Epoch: 5| Step: 5
Training loss: 1.015015959739685
Validation loss: 2.205767144759496

Epoch: 5| Step: 6
Training loss: 1.1323374509811401
Validation loss: 2.179497316479683

Epoch: 5| Step: 7
Training loss: 0.4887167513370514
Validation loss: 2.189318766196569

Epoch: 5| Step: 8
Training loss: 0.5274820327758789
Validation loss: 2.1924819946289062

Epoch: 5| Step: 9
Training loss: 0.5468482971191406
Validation loss: 2.216661031047503

Epoch: 5| Step: 10
Training loss: 0.3452836871147156
Validation loss: 2.1628089298804603

Epoch: 5| Step: 11
Training loss: 0.31793904304504395
Validation loss: 2.1502983073393502

Epoch: 287| Step: 0
Training loss: 0.6776107549667358
Validation loss: 2.206271082162857

Epoch: 5| Step: 1
Training loss: 0.8545109033584595
Validation loss: 2.1379148960113525

Epoch: 5| Step: 2
Training loss: 1.167052984237671
Validation loss: 2.256799285610517

Epoch: 5| Step: 3
Training loss: 0.5499553680419922
Validation loss: 2.131489788492521

Epoch: 5| Step: 4
Training loss: 0.5032128691673279
Validation loss: 2.2440866827964783

Epoch: 5| Step: 5
Training loss: 0.6338427662849426
Validation loss: 2.1844551811615625

Epoch: 5| Step: 6
Training loss: 0.7772272825241089
Validation loss: 2.1800914903481803

Epoch: 5| Step: 7
Training loss: 1.0286352634429932
Validation loss: 2.2116085837284722

Epoch: 5| Step: 8
Training loss: 0.769307553768158
Validation loss: 2.204370597998301

Epoch: 5| Step: 9
Training loss: 0.798544704914093
Validation loss: 2.1845225244760513

Epoch: 5| Step: 10
Training loss: 0.554924488067627
Validation loss: 2.121735389033953

Epoch: 5| Step: 11
Training loss: 0.7176543474197388
Validation loss: 2.2108009258906045

Epoch: 288| Step: 0
Training loss: 0.6313660144805908
Validation loss: 2.1919749081134796

Epoch: 5| Step: 1
Training loss: 1.139496088027954
Validation loss: 2.189296161135038

Epoch: 5| Step: 2
Training loss: 0.641459584236145
Validation loss: 2.199118748307228

Epoch: 5| Step: 3
Training loss: 0.8321629762649536
Validation loss: 2.243281523386637

Epoch: 5| Step: 4
Training loss: 0.8398101925849915
Validation loss: 2.2303819259007773

Epoch: 5| Step: 5
Training loss: 0.6148091554641724
Validation loss: 2.1737819661696753

Epoch: 5| Step: 6
Training loss: 0.7482882738113403
Validation loss: 2.208625003695488

Epoch: 5| Step: 7
Training loss: 0.7044626474380493
Validation loss: 2.272564396262169

Epoch: 5| Step: 8
Training loss: 1.2177501916885376
Validation loss: 2.2105487436056137

Epoch: 5| Step: 9
Training loss: 0.6368724703788757
Validation loss: 2.2257523238658905

Epoch: 5| Step: 10
Training loss: 0.45039910078048706
Validation loss: 2.173097471396128

Epoch: 5| Step: 11
Training loss: 0.906427264213562
Validation loss: 2.2592141876618066

Epoch: 289| Step: 0
Training loss: 1.0534087419509888
Validation loss: 2.2631046772003174

Epoch: 5| Step: 1
Training loss: 0.5080395936965942
Validation loss: 2.11062620083491

Epoch: 5| Step: 2
Training loss: 1.059637427330017
Validation loss: 2.184315567215284

Epoch: 5| Step: 3
Training loss: 0.6219111680984497
Validation loss: 2.183912525574366

Epoch: 5| Step: 4
Training loss: 0.5676984786987305
Validation loss: 2.1993740797042847

Epoch: 5| Step: 5
Training loss: 0.5681713819503784
Validation loss: 2.1694175948699317

Epoch: 5| Step: 6
Training loss: 0.728318989276886
Validation loss: 2.1827012101809182

Epoch: 5| Step: 7
Training loss: 1.0689356327056885
Validation loss: 2.19099423289299

Epoch: 5| Step: 8
Training loss: 0.8971104621887207
Validation loss: 2.1927044490973153

Epoch: 5| Step: 9
Training loss: 0.805305004119873
Validation loss: 2.2244661698738732

Epoch: 5| Step: 10
Training loss: 0.6617927551269531
Validation loss: 2.2182932992776236

Epoch: 5| Step: 11
Training loss: 0.28931164741516113
Validation loss: 2.206539715329806

Epoch: 290| Step: 0
Training loss: 0.5568750500679016
Validation loss: 2.3339246759812036

Epoch: 5| Step: 1
Training loss: 0.5922640562057495
Validation loss: 2.1589208195606866

Epoch: 5| Step: 2
Training loss: 0.7000905871391296
Validation loss: 2.2797797272602716

Epoch: 5| Step: 3
Training loss: 0.7382262349128723
Validation loss: 2.1903380006551743

Epoch: 5| Step: 4
Training loss: 1.2390081882476807
Validation loss: 2.228698958953222

Epoch: 5| Step: 5
Training loss: 1.0975208282470703
Validation loss: 2.2424849023421607

Epoch: 5| Step: 6
Training loss: 0.5530689358711243
Validation loss: 2.2908244033654532

Epoch: 5| Step: 7
Training loss: 0.501933217048645
Validation loss: 2.222414866089821

Epoch: 5| Step: 8
Training loss: 0.7753012180328369
Validation loss: 2.195601532856623

Epoch: 5| Step: 9
Training loss: 0.6593373417854309
Validation loss: 2.202192301551501

Epoch: 5| Step: 10
Training loss: 1.1206793785095215
Validation loss: 2.302260627349218

Epoch: 5| Step: 11
Training loss: 0.6912410855293274
Validation loss: 2.2469972322384515

Epoch: 291| Step: 0
Training loss: 0.9327142834663391
Validation loss: 2.2364675104618073

Epoch: 5| Step: 1
Training loss: 0.8904770016670227
Validation loss: 2.2155757447083793

Epoch: 5| Step: 2
Training loss: 0.8148788213729858
Validation loss: 2.238080620765686

Epoch: 5| Step: 3
Training loss: 0.6365713477134705
Validation loss: 2.13175896803538

Epoch: 5| Step: 4
Training loss: 0.4769919514656067
Validation loss: 2.1751591513554254

Epoch: 5| Step: 5
Training loss: 1.1329691410064697
Validation loss: 2.212828685839971

Epoch: 5| Step: 6
Training loss: 0.800153374671936
Validation loss: 2.1914833982785544

Epoch: 5| Step: 7
Training loss: 0.708721935749054
Validation loss: 2.2179897477229438

Epoch: 5| Step: 8
Training loss: 0.8110629320144653
Validation loss: 2.207167019446691

Epoch: 5| Step: 9
Training loss: 0.8395284414291382
Validation loss: 2.166053290168444

Epoch: 5| Step: 10
Training loss: 0.8236048817634583
Validation loss: 2.263323575258255

Epoch: 5| Step: 11
Training loss: 0.5566729307174683
Validation loss: 2.19385035832723

Epoch: 292| Step: 0
Training loss: 0.7893508672714233
Validation loss: 2.252204403281212

Epoch: 5| Step: 1
Training loss: 0.2684442698955536
Validation loss: 2.169364795088768

Epoch: 5| Step: 2
Training loss: 0.6821778416633606
Validation loss: 2.184208184480667

Epoch: 5| Step: 3
Training loss: 1.4726084470748901
Validation loss: 2.2243771056334176

Epoch: 5| Step: 4
Training loss: 0.648923397064209
Validation loss: 2.2786022424697876

Epoch: 5| Step: 5
Training loss: 0.5081168413162231
Validation loss: 2.134769265850385

Epoch: 5| Step: 6
Training loss: 0.6777294278144836
Validation loss: 2.1771911283334098

Epoch: 5| Step: 7
Training loss: 0.754635214805603
Validation loss: 2.205632438262304

Epoch: 5| Step: 8
Training loss: 1.0537052154541016
Validation loss: 2.2150780856609344

Epoch: 5| Step: 9
Training loss: 0.5158621072769165
Validation loss: 2.227182929714521

Epoch: 5| Step: 10
Training loss: 0.7839944362640381
Validation loss: 2.2637334366639457

Epoch: 5| Step: 11
Training loss: 1.1303045749664307
Validation loss: 2.2002738267183304

Epoch: 293| Step: 0
Training loss: 0.7862799167633057
Validation loss: 2.232568750778834

Epoch: 5| Step: 1
Training loss: 1.1798235177993774
Validation loss: 2.2562758525212607

Epoch: 5| Step: 2
Training loss: 0.8899490237236023
Validation loss: 2.2532569468021393

Epoch: 5| Step: 3
Training loss: 1.0730491876602173
Validation loss: 2.2476989924907684

Epoch: 5| Step: 4
Training loss: 0.7955114245414734
Validation loss: 2.24298025170962

Epoch: 5| Step: 5
Training loss: 0.4323674142360687
Validation loss: 2.24305160343647

Epoch: 5| Step: 6
Training loss: 0.7055673599243164
Validation loss: 2.18968258301417

Epoch: 5| Step: 7
Training loss: 0.7962929010391235
Validation loss: 2.2204780081907907

Epoch: 5| Step: 8
Training loss: 0.5741729736328125
Validation loss: 2.2606741885344186

Epoch: 5| Step: 9
Training loss: 1.031072974205017
Validation loss: 2.228979229927063

Epoch: 5| Step: 10
Training loss: 0.45148977637290955
Validation loss: 2.1796650886535645

Epoch: 5| Step: 11
Training loss: 1.2605445384979248
Validation loss: 2.215245708823204

Epoch: 294| Step: 0
Training loss: 0.9148243069648743
Validation loss: 2.2462011675039926

Epoch: 5| Step: 1
Training loss: 0.37614768743515015
Validation loss: 2.227127810319265

Epoch: 5| Step: 2
Training loss: 0.754478394985199
Validation loss: 2.2216944644848504

Epoch: 5| Step: 3
Training loss: 0.9061689376831055
Validation loss: 2.191147188345591

Epoch: 5| Step: 4
Training loss: 0.7076323628425598
Validation loss: 2.1895789057016373

Epoch: 5| Step: 5
Training loss: 0.9618333578109741
Validation loss: 2.19444311161836

Epoch: 5| Step: 6
Training loss: 0.5734149217605591
Validation loss: 2.1759046067794166

Epoch: 5| Step: 7
Training loss: 0.6043006181716919
Validation loss: 2.237002616127332

Epoch: 5| Step: 8
Training loss: 0.5972753167152405
Validation loss: 2.2006972233454385

Epoch: 5| Step: 9
Training loss: 0.9069671630859375
Validation loss: 2.1986951331297555

Epoch: 5| Step: 10
Training loss: 0.4593602120876312
Validation loss: 2.2270677983760834

Epoch: 5| Step: 11
Training loss: 1.381414771080017
Validation loss: 2.189710502823194

Epoch: 295| Step: 0
Training loss: 0.7564659714698792
Validation loss: 2.255713403224945

Epoch: 5| Step: 1
Training loss: 0.5573523640632629
Validation loss: 2.2204921493927636

Epoch: 5| Step: 2
Training loss: 0.6464356184005737
Validation loss: 2.1758038252592087

Epoch: 5| Step: 3
Training loss: 0.7391073107719421
Validation loss: 2.2349388698736825

Epoch: 5| Step: 4
Training loss: 0.8114277720451355
Validation loss: 2.232091794411341

Epoch: 5| Step: 5
Training loss: 0.4780499339103699
Validation loss: 2.2339636186758676

Epoch: 5| Step: 6
Training loss: 0.7893111109733582
Validation loss: 2.2064704596996307

Epoch: 5| Step: 7
Training loss: 0.8641756176948547
Validation loss: 2.1883550385634103

Epoch: 5| Step: 8
Training loss: 0.9424884915351868
Validation loss: 2.1441258837779364

Epoch: 5| Step: 9
Training loss: 0.658531665802002
Validation loss: 2.208166698614756

Epoch: 5| Step: 10
Training loss: 0.9422761797904968
Validation loss: 2.2462795972824097

Epoch: 5| Step: 11
Training loss: 0.8015491962432861
Validation loss: 2.260311742623647

Epoch: 296| Step: 0
Training loss: 0.4585610330104828
Validation loss: 2.2093444963296256

Epoch: 5| Step: 1
Training loss: 0.48793286085128784
Validation loss: 2.218491718173027

Epoch: 5| Step: 2
Training loss: 0.5704948306083679
Validation loss: 2.1908547977606454

Epoch: 5| Step: 3
Training loss: 0.6044546365737915
Validation loss: 2.1686241775751114

Epoch: 5| Step: 4
Training loss: 0.9980104565620422
Validation loss: 2.2349734604358673

Epoch: 5| Step: 5
Training loss: 0.6142522692680359
Validation loss: 2.2283992369969687

Epoch: 5| Step: 6
Training loss: 0.5888550281524658
Validation loss: 2.1778391549984613

Epoch: 5| Step: 7
Training loss: 0.9750984311103821
Validation loss: 2.2363660087188086

Epoch: 5| Step: 8
Training loss: 0.8086711764335632
Validation loss: 2.2019514391819635

Epoch: 5| Step: 9
Training loss: 0.5630429983139038
Validation loss: 2.1193813532590866

Epoch: 5| Step: 10
Training loss: 0.9569858312606812
Validation loss: 2.2197313706080117

Epoch: 5| Step: 11
Training loss: 0.7913933992385864
Validation loss: 2.217747946580251

Epoch: 297| Step: 0
Training loss: 0.6858055591583252
Validation loss: 2.272885968287786

Epoch: 5| Step: 1
Training loss: 0.6883951425552368
Validation loss: 2.2412444005409875

Epoch: 5| Step: 2
Training loss: 0.8087493777275085
Validation loss: 2.2168945322434106

Epoch: 5| Step: 3
Training loss: 0.5868090987205505
Validation loss: 2.207933430870374

Epoch: 5| Step: 4
Training loss: 0.603181004524231
Validation loss: 2.325343827406565

Epoch: 5| Step: 5
Training loss: 0.7296956777572632
Validation loss: 2.1934146036704383

Epoch: 5| Step: 6
Training loss: 0.8637732267379761
Validation loss: 2.196128472685814

Epoch: 5| Step: 7
Training loss: 0.5403531789779663
Validation loss: 2.2411973675092063

Epoch: 5| Step: 8
Training loss: 0.8378650546073914
Validation loss: 2.176693692803383

Epoch: 5| Step: 9
Training loss: 1.0193597078323364
Validation loss: 2.1588791062434516

Epoch: 5| Step: 10
Training loss: 0.7942525744438171
Validation loss: 2.159123877684275

Epoch: 5| Step: 11
Training loss: 0.4982230067253113
Validation loss: 2.1812125742435455

Epoch: 298| Step: 0
Training loss: 0.4955357611179352
Validation loss: 2.2322793503602347

Epoch: 5| Step: 1
Training loss: 0.5836540460586548
Validation loss: 2.2405964533487954

Epoch: 5| Step: 2
Training loss: 0.7403443455696106
Validation loss: 2.179383784532547

Epoch: 5| Step: 3
Training loss: 0.6133516430854797
Validation loss: 2.2009007384379706

Epoch: 5| Step: 4
Training loss: 0.7988890409469604
Validation loss: 2.2101029654343924

Epoch: 5| Step: 5
Training loss: 0.8738638758659363
Validation loss: 2.2478527228037515

Epoch: 5| Step: 6
Training loss: 0.6965421438217163
Validation loss: 2.198758323987325

Epoch: 5| Step: 7
Training loss: 0.8633090853691101
Validation loss: 2.1848652561505637

Epoch: 5| Step: 8
Training loss: 0.7645357847213745
Validation loss: 2.196160137653351

Epoch: 5| Step: 9
Training loss: 0.6912358999252319
Validation loss: 2.1882772942384086

Epoch: 5| Step: 10
Training loss: 1.0919383764266968
Validation loss: 2.306361804405848

Epoch: 5| Step: 11
Training loss: 0.18584227561950684
Validation loss: 2.2269488324721656

Epoch: 299| Step: 0
Training loss: 0.8984247446060181
Validation loss: 2.162232001622518

Epoch: 5| Step: 1
Training loss: 0.9069391489028931
Validation loss: 2.20547287662824

Epoch: 5| Step: 2
Training loss: 0.5898511409759521
Validation loss: 2.2400591671466827

Epoch: 5| Step: 3
Training loss: 1.2869728803634644
Validation loss: 2.251692151029905

Epoch: 5| Step: 4
Training loss: 0.7671844363212585
Validation loss: 2.2111047506332397

Epoch: 5| Step: 5
Training loss: 0.9972790479660034
Validation loss: 2.225491245587667

Epoch: 5| Step: 6
Training loss: 0.7035495638847351
Validation loss: 2.210784286260605

Epoch: 5| Step: 7
Training loss: 0.656094491481781
Validation loss: 2.185950348774592

Epoch: 5| Step: 8
Training loss: 1.152064561843872
Validation loss: 2.1620653768380484

Epoch: 5| Step: 9
Training loss: 0.7971602082252502
Validation loss: 2.2475496331850686

Epoch: 5| Step: 10
Training loss: 0.6769089698791504
Validation loss: 2.235521877805392

Epoch: 5| Step: 11
Training loss: 0.519302248954773
Validation loss: 2.183574209610621

Epoch: 300| Step: 0
Training loss: 0.4943167567253113
Validation loss: 2.1723905901114144

Epoch: 5| Step: 1
Training loss: 0.4562405049800873
Validation loss: 2.13767417271932

Epoch: 5| Step: 2
Training loss: 1.1068567037582397
Validation loss: 2.208035171031952

Epoch: 5| Step: 3
Training loss: 0.7535122632980347
Validation loss: 2.1793261021375656

Epoch: 5| Step: 4
Training loss: 0.4129827618598938
Validation loss: 2.235080142815908

Epoch: 5| Step: 5
Training loss: 0.5577904582023621
Validation loss: 2.214417969187101

Epoch: 5| Step: 6
Training loss: 0.7812013626098633
Validation loss: 2.2600569476683936

Epoch: 5| Step: 7
Training loss: 1.1238231658935547
Validation loss: 2.165722002585729

Epoch: 5| Step: 8
Training loss: 0.7488362193107605
Validation loss: 2.246468817194303

Epoch: 5| Step: 9
Training loss: 0.6213604211807251
Validation loss: 2.2172241856654487

Epoch: 5| Step: 10
Training loss: 0.7980011701583862
Validation loss: 2.187798857688904

Epoch: 5| Step: 11
Training loss: 0.8755525946617126
Validation loss: 2.2966859340667725

Epoch: 301| Step: 0
Training loss: 0.5770224928855896
Validation loss: 2.162930359443029

Epoch: 5| Step: 1
Training loss: 0.7671902179718018
Validation loss: 2.256933977206548

Epoch: 5| Step: 2
Training loss: 0.6831615567207336
Validation loss: 2.203843911488851

Epoch: 5| Step: 3
Training loss: 0.3538910746574402
Validation loss: 2.1982880930105844

Epoch: 5| Step: 4
Training loss: 0.4841129183769226
Validation loss: 2.2877983202536902

Epoch: 5| Step: 5
Training loss: 1.0272605419158936
Validation loss: 2.2196664214134216

Epoch: 5| Step: 6
Training loss: 0.7742049098014832
Validation loss: 2.2907783885796866

Epoch: 5| Step: 7
Training loss: 0.7915058732032776
Validation loss: 2.267919530471166

Epoch: 5| Step: 8
Training loss: 0.7672480344772339
Validation loss: 2.2665813068548837

Epoch: 5| Step: 9
Training loss: 0.7689043283462524
Validation loss: 2.229223887125651

Epoch: 5| Step: 10
Training loss: 0.7515755891799927
Validation loss: 2.2155445416768393

Epoch: 5| Step: 11
Training loss: 0.2629324793815613
Validation loss: 2.262513975302378

Epoch: 302| Step: 0
Training loss: 0.8455628156661987
Validation loss: 2.2631786366303763

Epoch: 5| Step: 1
Training loss: 0.4944375157356262
Validation loss: 2.236309915781021

Epoch: 5| Step: 2
Training loss: 0.7454171776771545
Validation loss: 2.1684307356675467

Epoch: 5| Step: 3
Training loss: 0.6392034292221069
Validation loss: 2.183709040284157

Epoch: 5| Step: 4
Training loss: 0.39710158109664917
Validation loss: 2.2287520468235016

Epoch: 5| Step: 5
Training loss: 1.0269224643707275
Validation loss: 2.2037951747576394

Epoch: 5| Step: 6
Training loss: 0.6748791933059692
Validation loss: 2.1773981799681983

Epoch: 5| Step: 7
Training loss: 0.43323826789855957
Validation loss: 2.2210256656010947

Epoch: 5| Step: 8
Training loss: 0.8190563321113586
Validation loss: 2.217554191748301

Epoch: 5| Step: 9
Training loss: 0.6352350115776062
Validation loss: 2.218141953150431

Epoch: 5| Step: 10
Training loss: 0.8193723559379578
Validation loss: 2.199797362089157

Epoch: 5| Step: 11
Training loss: 1.9000442028045654
Validation loss: 2.2632700552543006

Epoch: 303| Step: 0
Training loss: 0.8026286959648132
Validation loss: 2.2510232031345367

Epoch: 5| Step: 1
Training loss: 0.9263314008712769
Validation loss: 2.14445228377978

Epoch: 5| Step: 2
Training loss: 0.8437075614929199
Validation loss: 2.2155872831741967

Epoch: 5| Step: 3
Training loss: 0.8698536157608032
Validation loss: 2.269077738126119

Epoch: 5| Step: 4
Training loss: 0.8010238409042358
Validation loss: 2.237902114788691

Epoch: 5| Step: 5
Training loss: 0.6534377336502075
Validation loss: 2.23176379998525

Epoch: 5| Step: 6
Training loss: 0.8178951144218445
Validation loss: 2.2477916280428567

Epoch: 5| Step: 7
Training loss: 0.5098562240600586
Validation loss: 2.2422905464967093

Epoch: 5| Step: 8
Training loss: 0.44740429520606995
Validation loss: 2.217618465423584

Epoch: 5| Step: 9
Training loss: 0.34566718339920044
Validation loss: 2.195442631840706

Epoch: 5| Step: 10
Training loss: 0.4770778715610504
Validation loss: 2.2282901306947074

Epoch: 5| Step: 11
Training loss: 1.1500370502471924
Validation loss: 2.2063673585653305

Epoch: 304| Step: 0
Training loss: 0.5228684544563293
Validation loss: 2.266419659058253

Epoch: 5| Step: 1
Training loss: 0.7145153880119324
Validation loss: 2.167638902862867

Epoch: 5| Step: 2
Training loss: 0.8878634572029114
Validation loss: 2.1999059319496155

Epoch: 5| Step: 3
Training loss: 0.8045428395271301
Validation loss: 2.210458825031916

Epoch: 5| Step: 4
Training loss: 1.0991848707199097
Validation loss: 2.1948969960212708

Epoch: 5| Step: 5
Training loss: 0.4706273674964905
Validation loss: 2.2566416015227637

Epoch: 5| Step: 6
Training loss: 0.6613167524337769
Validation loss: 2.1871939450502396

Epoch: 5| Step: 7
Training loss: 0.633880615234375
Validation loss: 2.2455580135186515

Epoch: 5| Step: 8
Training loss: 0.6974993944168091
Validation loss: 2.1666221717993417

Epoch: 5| Step: 9
Training loss: 0.6617735624313354
Validation loss: 2.233541121085485

Epoch: 5| Step: 10
Training loss: 0.5107767581939697
Validation loss: 2.1846274038155875

Epoch: 5| Step: 11
Training loss: 0.7218945026397705
Validation loss: 2.2750365932782493

Epoch: 305| Step: 0
Training loss: 0.7060710191726685
Validation loss: 2.2245739698410034

Epoch: 5| Step: 1
Training loss: 0.8254774212837219
Validation loss: 2.2052403887112937

Epoch: 5| Step: 2
Training loss: 0.8299720883369446
Validation loss: 2.2525542279084525

Epoch: 5| Step: 3
Training loss: 1.2529405355453491
Validation loss: 2.249232014020284

Epoch: 5| Step: 4
Training loss: 0.687225341796875
Validation loss: 2.227393716573715

Epoch: 5| Step: 5
Training loss: 1.111145257949829
Validation loss: 2.251747637987137

Epoch: 5| Step: 6
Training loss: 0.566158652305603
Validation loss: 2.2324012517929077

Epoch: 5| Step: 7
Training loss: 0.49854716658592224
Validation loss: 2.1879756848017373

Epoch: 5| Step: 8
Training loss: 0.7220715284347534
Validation loss: 2.2054669857025146

Epoch: 5| Step: 9
Training loss: 0.40446823835372925
Validation loss: 2.2360643396774926

Epoch: 5| Step: 10
Training loss: 0.5279285311698914
Validation loss: 2.261084963877996

Epoch: 5| Step: 11
Training loss: 1.2391326427459717
Validation loss: 2.1596864759922028

Epoch: 306| Step: 0
Training loss: 0.809344470500946
Validation loss: 2.2911868393421173

Epoch: 5| Step: 1
Training loss: 0.4687274098396301
Validation loss: 2.250418558716774

Epoch: 5| Step: 2
Training loss: 0.5198851823806763
Validation loss: 2.2319357494513192

Epoch: 5| Step: 3
Training loss: 0.6558969020843506
Validation loss: 2.247806489467621

Epoch: 5| Step: 4
Training loss: 1.0041711330413818
Validation loss: 2.23636631667614

Epoch: 5| Step: 5
Training loss: 0.7674497365951538
Validation loss: 2.249972403049469

Epoch: 5| Step: 6
Training loss: 0.8174336552619934
Validation loss: 2.1734720518191657

Epoch: 5| Step: 7
Training loss: 0.9156268239021301
Validation loss: 2.2412580251693726

Epoch: 5| Step: 8
Training loss: 0.5359731912612915
Validation loss: 2.2765823006629944

Epoch: 5| Step: 9
Training loss: 0.4338926672935486
Validation loss: 2.194681018590927

Epoch: 5| Step: 10
Training loss: 0.4881325662136078
Validation loss: 2.1814827968676886

Epoch: 5| Step: 11
Training loss: 1.2286138534545898
Validation loss: 2.2266742885112762

Epoch: 307| Step: 0
Training loss: 0.8206232786178589
Validation loss: 2.286906987428665

Epoch: 5| Step: 1
Training loss: 0.6996051073074341
Validation loss: 2.2285289963086448

Epoch: 5| Step: 2
Training loss: 0.5610305070877075
Validation loss: 2.263587315877279

Epoch: 5| Step: 3
Training loss: 0.51335209608078
Validation loss: 2.1958008408546448

Epoch: 5| Step: 4
Training loss: 0.7127143740653992
Validation loss: 2.22652830183506

Epoch: 5| Step: 5
Training loss: 0.8195926547050476
Validation loss: 2.240976572036743

Epoch: 5| Step: 6
Training loss: 0.6628301739692688
Validation loss: 2.2474692364533744

Epoch: 5| Step: 7
Training loss: 0.9452055096626282
Validation loss: 2.1617675721645355

Epoch: 5| Step: 8
Training loss: 0.6224058866500854
Validation loss: 2.1852621883153915

Epoch: 5| Step: 9
Training loss: 0.4254183769226074
Validation loss: 2.2141644060611725

Epoch: 5| Step: 10
Training loss: 0.6290225386619568
Validation loss: 2.2187903622786203

Epoch: 5| Step: 11
Training loss: 0.80929034948349
Validation loss: 2.2004670153061547

Epoch: 308| Step: 0
Training loss: 0.8270349502563477
Validation loss: 2.1467917263507843

Epoch: 5| Step: 1
Training loss: 0.8822189569473267
Validation loss: 2.211778069535891

Epoch: 5| Step: 2
Training loss: 0.5442959666252136
Validation loss: 2.2463253339131675

Epoch: 5| Step: 3
Training loss: 0.647186815738678
Validation loss: 2.1568287909030914

Epoch: 5| Step: 4
Training loss: 0.733842670917511
Validation loss: 2.201169734199842

Epoch: 5| Step: 5
Training loss: 0.8533540964126587
Validation loss: 2.184409057100614

Epoch: 5| Step: 6
Training loss: 0.5461614727973938
Validation loss: 2.242406869928042

Epoch: 5| Step: 7
Training loss: 0.7766785025596619
Validation loss: 2.167800103624662

Epoch: 5| Step: 8
Training loss: 0.7877559661865234
Validation loss: 2.2085367192824683

Epoch: 5| Step: 9
Training loss: 0.798959493637085
Validation loss: 2.2312557995319366

Epoch: 5| Step: 10
Training loss: 0.41501522064208984
Validation loss: 2.2307257652282715

Epoch: 5| Step: 11
Training loss: 0.32093435525894165
Validation loss: 2.1997294425964355

Epoch: 309| Step: 0
Training loss: 0.5912305116653442
Validation loss: 2.1660419950882592

Epoch: 5| Step: 1
Training loss: 0.8189217448234558
Validation loss: 2.215546021858851

Epoch: 5| Step: 2
Training loss: 0.7773641347885132
Validation loss: 2.241945286591848

Epoch: 5| Step: 3
Training loss: 0.46252328157424927
Validation loss: 2.2031206289927163

Epoch: 5| Step: 4
Training loss: 0.8916481137275696
Validation loss: 2.2298914889494577

Epoch: 5| Step: 5
Training loss: 0.724096417427063
Validation loss: 2.1830561657746634

Epoch: 5| Step: 6
Training loss: 0.4678179621696472
Validation loss: 2.1835968295733132

Epoch: 5| Step: 7
Training loss: 0.6328029632568359
Validation loss: 2.234511141975721

Epoch: 5| Step: 8
Training loss: 0.9436253309249878
Validation loss: 2.211170122027397

Epoch: 5| Step: 9
Training loss: 0.9328243136405945
Validation loss: 2.2440221905708313

Epoch: 5| Step: 10
Training loss: 0.6887237429618835
Validation loss: 2.2004875540733337

Epoch: 5| Step: 11
Training loss: 0.6623451709747314
Validation loss: 2.2339709202448526

Epoch: 310| Step: 0
Training loss: 0.7762304544448853
Validation loss: 2.2443120082219443

Epoch: 5| Step: 1
Training loss: 0.801240086555481
Validation loss: 2.2090120216210685

Epoch: 5| Step: 2
Training loss: 0.4637680947780609
Validation loss: 2.2479089399178824

Epoch: 5| Step: 3
Training loss: 0.5964316725730896
Validation loss: 2.2495832045873008

Epoch: 5| Step: 4
Training loss: 0.6330984830856323
Validation loss: 2.2687681516011557

Epoch: 5| Step: 5
Training loss: 0.9437470436096191
Validation loss: 2.206087817748388

Epoch: 5| Step: 6
Training loss: 0.5934836268424988
Validation loss: 2.2151491940021515

Epoch: 5| Step: 7
Training loss: 0.5378736257553101
Validation loss: 2.2272712141275406

Epoch: 5| Step: 8
Training loss: 0.37694281339645386
Validation loss: 2.2302428980668387

Epoch: 5| Step: 9
Training loss: 0.8628298044204712
Validation loss: 2.3210822145144143

Epoch: 5| Step: 10
Training loss: 0.6778804659843445
Validation loss: 2.2859098613262177

Epoch: 5| Step: 11
Training loss: 1.388276219367981
Validation loss: 2.164260615905126

Epoch: 311| Step: 0
Training loss: 0.8130567669868469
Validation loss: 2.257256358861923

Epoch: 5| Step: 1
Training loss: 1.0579124689102173
Validation loss: 2.2175393303235373

Epoch: 5| Step: 2
Training loss: 0.6995798349380493
Validation loss: 2.225328971942266

Epoch: 5| Step: 3
Training loss: 0.591354489326477
Validation loss: 2.203379904230436

Epoch: 5| Step: 4
Training loss: 0.8618285059928894
Validation loss: 2.164989451567332

Epoch: 5| Step: 5
Training loss: 0.5756327509880066
Validation loss: 2.2088069319725037

Epoch: 5| Step: 6
Training loss: 0.465449720621109
Validation loss: 2.2588734229405723

Epoch: 5| Step: 7
Training loss: 0.6599025130271912
Validation loss: 2.1465737024943032

Epoch: 5| Step: 8
Training loss: 0.7744618058204651
Validation loss: 2.19231046239535

Epoch: 5| Step: 9
Training loss: 0.622509241104126
Validation loss: 2.200346206625303

Epoch: 5| Step: 10
Training loss: 0.7800046801567078
Validation loss: 2.2085686922073364

Epoch: 5| Step: 11
Training loss: 0.5866382122039795
Validation loss: 2.255908618370692

Epoch: 312| Step: 0
Training loss: 0.7022111415863037
Validation loss: 2.1758946031332016

Epoch: 5| Step: 1
Training loss: 0.69667649269104
Validation loss: 2.1162022252877555

Epoch: 5| Step: 2
Training loss: 0.5691231489181519
Validation loss: 2.1796341041723886

Epoch: 5| Step: 3
Training loss: 0.5044552087783813
Validation loss: 2.170070300499598

Epoch: 5| Step: 4
Training loss: 1.1270774602890015
Validation loss: 2.169057309627533

Epoch: 5| Step: 5
Training loss: 0.8555706143379211
Validation loss: 2.1900597314039865

Epoch: 5| Step: 6
Training loss: 0.7238682508468628
Validation loss: 2.1985193888346353

Epoch: 5| Step: 7
Training loss: 0.6381550431251526
Validation loss: 2.217517212033272

Epoch: 5| Step: 8
Training loss: 0.6455340385437012
Validation loss: 2.198262040813764

Epoch: 5| Step: 9
Training loss: 0.4970100522041321
Validation loss: 2.2053748766581216

Epoch: 5| Step: 10
Training loss: 0.6968831419944763
Validation loss: 2.196913629770279

Epoch: 5| Step: 11
Training loss: 0.4259275197982788
Validation loss: 2.118677020072937

Epoch: 313| Step: 0
Training loss: 0.5262793302536011
Validation loss: 2.209064483642578

Epoch: 5| Step: 1
Training loss: 0.4338626265525818
Validation loss: 2.232565159598986

Epoch: 5| Step: 2
Training loss: 0.6428361535072327
Validation loss: 2.2327074706554413

Epoch: 5| Step: 3
Training loss: 0.767296314239502
Validation loss: 2.210217207670212

Epoch: 5| Step: 4
Training loss: 0.8333784937858582
Validation loss: 2.2411037584145865

Epoch: 5| Step: 5
Training loss: 0.698040246963501
Validation loss: 2.2347825864950814

Epoch: 5| Step: 6
Training loss: 0.4491254389286041
Validation loss: 2.2209585458040237

Epoch: 5| Step: 7
Training loss: 0.7669164538383484
Validation loss: 2.2010200768709183

Epoch: 5| Step: 8
Training loss: 0.7856084108352661
Validation loss: 2.150141860047976

Epoch: 5| Step: 9
Training loss: 0.7467470765113831
Validation loss: 2.217479964097341

Epoch: 5| Step: 10
Training loss: 0.6551027894020081
Validation loss: 2.2384338726600013

Epoch: 5| Step: 11
Training loss: 0.47324490547180176
Validation loss: 2.25417131682237

Epoch: 314| Step: 0
Training loss: 0.4486359655857086
Validation loss: 2.2357108940680823

Epoch: 5| Step: 1
Training loss: 0.6238295435905457
Validation loss: 2.2307492097218833

Epoch: 5| Step: 2
Training loss: 0.8142830729484558
Validation loss: 2.2010129739840827

Epoch: 5| Step: 3
Training loss: 1.23565673828125
Validation loss: 2.186409205198288

Epoch: 5| Step: 4
Training loss: 0.6944641470909119
Validation loss: 2.221911688645681

Epoch: 5| Step: 5
Training loss: 0.6126836538314819
Validation loss: 2.2257217268149057

Epoch: 5| Step: 6
Training loss: 0.8893911242485046
Validation loss: 2.190727969010671

Epoch: 5| Step: 7
Training loss: 0.4941399097442627
Validation loss: 2.2828529526789985

Epoch: 5| Step: 8
Training loss: 0.42204490303993225
Validation loss: 2.1744508743286133

Epoch: 5| Step: 9
Training loss: 0.6901389360427856
Validation loss: 2.1966109524170556

Epoch: 5| Step: 10
Training loss: 0.6612533330917358
Validation loss: 2.199591110150019

Epoch: 5| Step: 11
Training loss: 0.48998796939849854
Validation loss: 2.207270254691442

Epoch: 315| Step: 0
Training loss: 0.5976659655570984
Validation loss: 2.1727952708800635

Epoch: 5| Step: 1
Training loss: 0.7784802913665771
Validation loss: 2.2336070090532303

Epoch: 5| Step: 2
Training loss: 0.6276783347129822
Validation loss: 2.246841182311376

Epoch: 5| Step: 3
Training loss: 0.810917854309082
Validation loss: 2.2375626116991043

Epoch: 5| Step: 4
Training loss: 0.48147231340408325
Validation loss: 2.2184113959471383

Epoch: 5| Step: 5
Training loss: 0.7909135818481445
Validation loss: 2.207229902346929

Epoch: 5| Step: 6
Training loss: 0.9551019668579102
Validation loss: 2.2218035558859506

Epoch: 5| Step: 7
Training loss: 0.7201646566390991
Validation loss: 2.198042462269465

Epoch: 5| Step: 8
Training loss: 0.8012560606002808
Validation loss: 2.2339467902978263

Epoch: 5| Step: 9
Training loss: 0.5411700010299683
Validation loss: 2.197892035047213

Epoch: 5| Step: 10
Training loss: 0.525598406791687
Validation loss: 2.305792565147082

Epoch: 5| Step: 11
Training loss: 0.24496662616729736
Validation loss: 2.197007770339648

Epoch: 316| Step: 0
Training loss: 0.9508034586906433
Validation loss: 2.25740618010362

Epoch: 5| Step: 1
Training loss: 0.5367649793624878
Validation loss: 2.151568502187729

Epoch: 5| Step: 2
Training loss: 0.5714998841285706
Validation loss: 2.210107679168383

Epoch: 5| Step: 3
Training loss: 0.39889296889305115
Validation loss: 2.1987258940935135

Epoch: 5| Step: 4
Training loss: 0.6356602907180786
Validation loss: 2.2439081420501075

Epoch: 5| Step: 5
Training loss: 1.0311980247497559
Validation loss: 2.229084849357605

Epoch: 5| Step: 6
Training loss: 0.5676462650299072
Validation loss: 2.2031122346719108

Epoch: 5| Step: 7
Training loss: 0.8754064440727234
Validation loss: 2.226623997092247

Epoch: 5| Step: 8
Training loss: 0.677585244178772
Validation loss: 2.2641013463338218

Epoch: 5| Step: 9
Training loss: 0.5029574036598206
Validation loss: 2.1428430378437042

Epoch: 5| Step: 10
Training loss: 0.623082160949707
Validation loss: 2.220901886622111

Epoch: 5| Step: 11
Training loss: 1.003784418106079
Validation loss: 2.162892868121465

Epoch: 317| Step: 0
Training loss: 0.7998435497283936
Validation loss: 2.2053238103787103

Epoch: 5| Step: 1
Training loss: 0.5580741167068481
Validation loss: 2.298650026321411

Epoch: 5| Step: 2
Training loss: 0.48509588837623596
Validation loss: 2.249167521794637

Epoch: 5| Step: 3
Training loss: 0.7943661212921143
Validation loss: 2.2563810547192893

Epoch: 5| Step: 4
Training loss: 0.6233755350112915
Validation loss: 2.2016232212384543

Epoch: 5| Step: 5
Training loss: 0.570435643196106
Validation loss: 2.231581007440885

Epoch: 5| Step: 6
Training loss: 0.4552784860134125
Validation loss: 2.184207042058309

Epoch: 5| Step: 7
Training loss: 0.8048269152641296
Validation loss: 2.26176247994105

Epoch: 5| Step: 8
Training loss: 1.0632598400115967
Validation loss: 2.1523964504400888

Epoch: 5| Step: 9
Training loss: 0.6896249055862427
Validation loss: 2.2361281514167786

Epoch: 5| Step: 10
Training loss: 0.6078439354896545
Validation loss: 2.1903309722741446

Epoch: 5| Step: 11
Training loss: 0.5553983449935913
Validation loss: 2.1891031563282013

Epoch: 318| Step: 0
Training loss: 0.560879111289978
Validation loss: 2.185615907112757

Epoch: 5| Step: 1
Training loss: 0.9296144247055054
Validation loss: 2.2327297727266946

Epoch: 5| Step: 2
Training loss: 0.3897600769996643
Validation loss: 2.1720019231239953

Epoch: 5| Step: 3
Training loss: 0.7140864133834839
Validation loss: 2.2351036270459494

Epoch: 5| Step: 4
Training loss: 0.6637924909591675
Validation loss: 2.1906167616446814

Epoch: 5| Step: 5
Training loss: 0.6556687355041504
Validation loss: 2.213756740093231

Epoch: 5| Step: 6
Training loss: 0.6061455607414246
Validation loss: 2.274871369202932

Epoch: 5| Step: 7
Training loss: 0.516085147857666
Validation loss: 2.2222448140382767

Epoch: 5| Step: 8
Training loss: 0.36189010739326477
Validation loss: 2.219521716237068

Epoch: 5| Step: 9
Training loss: 0.8380783200263977
Validation loss: 2.139313062032064

Epoch: 5| Step: 10
Training loss: 0.81513911485672
Validation loss: 2.2312368899583817

Epoch: 5| Step: 11
Training loss: 0.6025182604789734
Validation loss: 2.1596152087052665

Epoch: 319| Step: 0
Training loss: 0.4396371841430664
Validation loss: 2.2058318456014

Epoch: 5| Step: 1
Training loss: 0.6814893484115601
Validation loss: 2.1414404461781182

Epoch: 5| Step: 2
Training loss: 0.9637333750724792
Validation loss: 2.243618259827296

Epoch: 5| Step: 3
Training loss: 0.6559040546417236
Validation loss: 2.229644924402237

Epoch: 5| Step: 4
Training loss: 0.9132767915725708
Validation loss: 2.1924413591623306

Epoch: 5| Step: 5
Training loss: 0.6307393908500671
Validation loss: 2.2215610494216285

Epoch: 5| Step: 6
Training loss: 0.48278799653053284
Validation loss: 2.174303566416105

Epoch: 5| Step: 7
Training loss: 0.5738205313682556
Validation loss: 2.2028755346934

Epoch: 5| Step: 8
Training loss: 0.7078544497489929
Validation loss: 2.2099992831548056

Epoch: 5| Step: 9
Training loss: 0.9547598958015442
Validation loss: 2.207336495320002

Epoch: 5| Step: 10
Training loss: 0.33177679777145386
Validation loss: 2.198763057589531

Epoch: 5| Step: 11
Training loss: 0.3674106001853943
Validation loss: 2.1973416904608407

Epoch: 320| Step: 0
Training loss: 1.3113477230072021
Validation loss: 2.1600330720345178

Epoch: 5| Step: 1
Training loss: 0.5805827975273132
Validation loss: 2.1791519224643707

Epoch: 5| Step: 2
Training loss: 0.43863025307655334
Validation loss: 2.2180024882157645

Epoch: 5| Step: 3
Training loss: 0.5850444436073303
Validation loss: 2.255259076754252

Epoch: 5| Step: 4
Training loss: 0.4288439154624939
Validation loss: 2.1604276299476624

Epoch: 5| Step: 5
Training loss: 0.6650460958480835
Validation loss: 2.2367305755615234

Epoch: 5| Step: 6
Training loss: 0.4956997036933899
Validation loss: 2.265186071395874

Epoch: 5| Step: 7
Training loss: 0.6535056829452515
Validation loss: 2.1491844803094864

Epoch: 5| Step: 8
Training loss: 0.40516242384910583
Validation loss: 2.233149935801824

Epoch: 5| Step: 9
Training loss: 0.6611753702163696
Validation loss: 2.165083939830462

Epoch: 5| Step: 10
Training loss: 0.7488264441490173
Validation loss: 2.234133909145991

Epoch: 5| Step: 11
Training loss: 1.52946937084198
Validation loss: 2.228356043497721

Epoch: 321| Step: 0
Training loss: 0.8027321100234985
Validation loss: 2.2413510928551355

Epoch: 5| Step: 1
Training loss: 0.36807072162628174
Validation loss: 2.15647100408872

Epoch: 5| Step: 2
Training loss: 0.6865460276603699
Validation loss: 2.2519659946362176

Epoch: 5| Step: 3
Training loss: 0.5455507040023804
Validation loss: 2.201198548078537

Epoch: 5| Step: 4
Training loss: 0.7038648724555969
Validation loss: 2.3128416736920676

Epoch: 5| Step: 5
Training loss: 0.7305052876472473
Validation loss: 2.18281818429629

Epoch: 5| Step: 6
Training loss: 0.5668724775314331
Validation loss: 2.2228006571531296

Epoch: 5| Step: 7
Training loss: 0.8052485585212708
Validation loss: 2.251072039206823

Epoch: 5| Step: 8
Training loss: 0.7289844751358032
Validation loss: 2.2194395065307617

Epoch: 5| Step: 9
Training loss: 0.9962625503540039
Validation loss: 2.199295183022817

Epoch: 5| Step: 10
Training loss: 0.6141816973686218
Validation loss: 2.2201545039812722

Epoch: 5| Step: 11
Training loss: 0.6040576696395874
Validation loss: 2.18955560028553

Epoch: 322| Step: 0
Training loss: 0.7046388983726501
Validation loss: 2.1775903701782227

Epoch: 5| Step: 1
Training loss: 0.4480668902397156
Validation loss: 2.245053698619207

Epoch: 5| Step: 2
Training loss: 0.8900995254516602
Validation loss: 2.223877862095833

Epoch: 5| Step: 3
Training loss: 0.5142549276351929
Validation loss: 2.2105427434047065

Epoch: 5| Step: 4
Training loss: 0.6253509521484375
Validation loss: 2.2613903482755027

Epoch: 5| Step: 5
Training loss: 0.5684830546379089
Validation loss: 2.2463193237781525

Epoch: 5| Step: 6
Training loss: 0.8633068203926086
Validation loss: 2.1926703254381814

Epoch: 5| Step: 7
Training loss: 0.7860130071640015
Validation loss: 2.22891957561175

Epoch: 5| Step: 8
Training loss: 0.7140969038009644
Validation loss: 2.193620204925537

Epoch: 5| Step: 9
Training loss: 0.8331922292709351
Validation loss: 2.153518964846929

Epoch: 5| Step: 10
Training loss: 0.5601768493652344
Validation loss: 2.252591167887052

Epoch: 5| Step: 11
Training loss: 0.3428371548652649
Validation loss: 2.2403669903675714

Epoch: 323| Step: 0
Training loss: 0.7409966588020325
Validation loss: 2.238765279452006

Epoch: 5| Step: 1
Training loss: 0.9289509057998657
Validation loss: 2.2094168215990067

Epoch: 5| Step: 2
Training loss: 0.5203776359558105
Validation loss: 2.19012180964152

Epoch: 5| Step: 3
Training loss: 0.8857904672622681
Validation loss: 2.2712246477603912

Epoch: 5| Step: 4
Training loss: 1.0591727495193481
Validation loss: 2.2018381555875144

Epoch: 5| Step: 5
Training loss: 0.5581378936767578
Validation loss: 2.250136842330297

Epoch: 5| Step: 6
Training loss: 0.6825195550918579
Validation loss: 2.176255484422048

Epoch: 5| Step: 7
Training loss: 0.5722898244857788
Validation loss: 2.198043609658877

Epoch: 5| Step: 8
Training loss: 0.4257466793060303
Validation loss: 2.2120556930700936

Epoch: 5| Step: 9
Training loss: 0.7574140429496765
Validation loss: 2.2210698227087655

Epoch: 5| Step: 10
Training loss: 0.4929788112640381
Validation loss: 2.210472340385119

Epoch: 5| Step: 11
Training loss: 0.6970357298851013
Validation loss: 2.164050350586573

Epoch: 324| Step: 0
Training loss: 0.674481213092804
Validation loss: 2.2317438473304114

Epoch: 5| Step: 1
Training loss: 0.49662262201309204
Validation loss: 2.173493653535843

Epoch: 5| Step: 2
Training loss: 0.4275006353855133
Validation loss: 2.156919156511625

Epoch: 5| Step: 3
Training loss: 0.9330736994743347
Validation loss: 2.195663650830587

Epoch: 5| Step: 4
Training loss: 0.9331134557723999
Validation loss: 2.206323653459549

Epoch: 5| Step: 5
Training loss: 0.6492747664451599
Validation loss: 2.269487832983335

Epoch: 5| Step: 6
Training loss: 0.893227219581604
Validation loss: 2.2013823638359704

Epoch: 5| Step: 7
Training loss: 0.7152490615844727
Validation loss: 2.190135583281517

Epoch: 5| Step: 8
Training loss: 0.8043714761734009
Validation loss: 2.2512174248695374

Epoch: 5| Step: 9
Training loss: 0.595930278301239
Validation loss: 2.2704642663399377

Epoch: 5| Step: 10
Training loss: 0.47676077485084534
Validation loss: 2.2104814052581787

Epoch: 5| Step: 11
Training loss: 0.29526638984680176
Validation loss: 2.2613654186328254

Epoch: 325| Step: 0
Training loss: 0.5742519497871399
Validation loss: 2.2511441806952157

Epoch: 5| Step: 1
Training loss: 0.9217780828475952
Validation loss: 2.2629696329434714

Epoch: 5| Step: 2
Training loss: 0.9749941825866699
Validation loss: 2.2801384329795837

Epoch: 5| Step: 3
Training loss: 0.7487859725952148
Validation loss: 2.259800205628077

Epoch: 5| Step: 4
Training loss: 0.6832219958305359
Validation loss: 2.281229923168818

Epoch: 5| Step: 5
Training loss: 0.9259781837463379
Validation loss: 2.2807352542877197

Epoch: 5| Step: 6
Training loss: 0.3969053626060486
Validation loss: 2.1910655399163566

Epoch: 5| Step: 7
Training loss: 0.6577250957489014
Validation loss: 2.2461635917425156

Epoch: 5| Step: 8
Training loss: 0.6182846426963806
Validation loss: 2.1730297207832336

Epoch: 5| Step: 9
Training loss: 0.7740036249160767
Validation loss: 2.188300520181656

Epoch: 5| Step: 10
Training loss: 0.7578070759773254
Validation loss: 2.2396606703599296

Epoch: 5| Step: 11
Training loss: 1.2500669956207275
Validation loss: 2.205527355273565

Epoch: 326| Step: 0
Training loss: 0.6398937106132507
Validation loss: 2.252920096119245

Epoch: 5| Step: 1
Training loss: 0.7386740446090698
Validation loss: 2.232570389906565

Epoch: 5| Step: 2
Training loss: 0.3235775828361511
Validation loss: 2.1597542663415275

Epoch: 5| Step: 3
Training loss: 0.7001004815101624
Validation loss: 2.285311530033747

Epoch: 5| Step: 4
Training loss: 0.5846644639968872
Validation loss: 2.19634972512722

Epoch: 5| Step: 5
Training loss: 0.49003663659095764
Validation loss: 2.2471825579802194

Epoch: 5| Step: 6
Training loss: 1.1012312173843384
Validation loss: 2.250382353862127

Epoch: 5| Step: 7
Training loss: 0.8310583233833313
Validation loss: 2.234915852546692

Epoch: 5| Step: 8
Training loss: 0.8614143133163452
Validation loss: 2.2705415238936744

Epoch: 5| Step: 9
Training loss: 0.5880781412124634
Validation loss: 2.2132707983255386

Epoch: 5| Step: 10
Training loss: 0.4680294990539551
Validation loss: 2.257760211825371

Epoch: 5| Step: 11
Training loss: 0.9358397126197815
Validation loss: 2.2090217669804892

Epoch: 327| Step: 0
Training loss: 0.8012624979019165
Validation loss: 2.250448688864708

Epoch: 5| Step: 1
Training loss: 0.6541637182235718
Validation loss: 2.230976030230522

Epoch: 5| Step: 2
Training loss: 1.0693199634552002
Validation loss: 2.1804137974977493

Epoch: 5| Step: 3
Training loss: 0.8109806776046753
Validation loss: 2.184527357419332

Epoch: 5| Step: 4
Training loss: 0.5029104948043823
Validation loss: 2.214515129725138

Epoch: 5| Step: 5
Training loss: 0.47604823112487793
Validation loss: 2.1726716607809067

Epoch: 5| Step: 6
Training loss: 0.7615765333175659
Validation loss: 2.225471466779709

Epoch: 5| Step: 7
Training loss: 0.7762780785560608
Validation loss: 2.260127604007721

Epoch: 5| Step: 8
Training loss: 0.7238008975982666
Validation loss: 2.174464702606201

Epoch: 5| Step: 9
Training loss: 0.5861703157424927
Validation loss: 2.304577420155207

Epoch: 5| Step: 10
Training loss: 0.4533056318759918
Validation loss: 2.2327847878138223

Epoch: 5| Step: 11
Training loss: 0.2005179524421692
Validation loss: 2.231711099545161

Epoch: 328| Step: 0
Training loss: 0.5001696348190308
Validation loss: 2.1752740939458213

Epoch: 5| Step: 1
Training loss: 0.8559341430664062
Validation loss: 2.193829521536827

Epoch: 5| Step: 2
Training loss: 0.8222866058349609
Validation loss: 2.2698229203621545

Epoch: 5| Step: 3
Training loss: 0.9046999216079712
Validation loss: 2.2010357081890106

Epoch: 5| Step: 4
Training loss: 0.6355991363525391
Validation loss: 2.2391271690527597

Epoch: 5| Step: 5
Training loss: 0.8349390029907227
Validation loss: 2.208489939570427

Epoch: 5| Step: 6
Training loss: 0.4308788776397705
Validation loss: 2.2440686176220574

Epoch: 5| Step: 7
Training loss: 0.5922046303749084
Validation loss: 2.26586976647377

Epoch: 5| Step: 8
Training loss: 0.45190101861953735
Validation loss: 2.2199791222810745

Epoch: 5| Step: 9
Training loss: 0.6866098642349243
Validation loss: 2.198959489663442

Epoch: 5| Step: 10
Training loss: 0.5976959466934204
Validation loss: 2.169375797112783

Epoch: 5| Step: 11
Training loss: 0.17192566394805908
Validation loss: 2.2579681326945624

Epoch: 329| Step: 0
Training loss: 0.5279180407524109
Validation loss: 2.139273077249527

Epoch: 5| Step: 1
Training loss: 0.41257476806640625
Validation loss: 2.255363335212072

Epoch: 5| Step: 2
Training loss: 1.0402946472167969
Validation loss: 2.2515653520822525

Epoch: 5| Step: 3
Training loss: 0.6070140600204468
Validation loss: 2.2166349391142526

Epoch: 5| Step: 4
Training loss: 0.7265962362289429
Validation loss: 2.2174972792466483

Epoch: 5| Step: 5
Training loss: 0.5808831453323364
Validation loss: 2.2090153147776923

Epoch: 5| Step: 6
Training loss: 0.6314297914505005
Validation loss: 2.2122989197572074

Epoch: 5| Step: 7
Training loss: 0.715691089630127
Validation loss: 2.2018617540597916

Epoch: 5| Step: 8
Training loss: 0.8901828527450562
Validation loss: 2.234316552678744

Epoch: 5| Step: 9
Training loss: 0.5702292919158936
Validation loss: 2.2064983248710632

Epoch: 5| Step: 10
Training loss: 0.7395322322845459
Validation loss: 2.175792803366979

Epoch: 5| Step: 11
Training loss: 0.9774136543273926
Validation loss: 2.186451554298401

Epoch: 330| Step: 0
Training loss: 0.74500572681427
Validation loss: 2.1823253681262336

Epoch: 5| Step: 1
Training loss: 0.7361315488815308
Validation loss: 2.1753503531217575

Epoch: 5| Step: 2
Training loss: 0.4501402974128723
Validation loss: 2.206767196456591

Epoch: 5| Step: 3
Training loss: 0.6510919332504272
Validation loss: 2.137597476442655

Epoch: 5| Step: 4
Training loss: 0.4554673135280609
Validation loss: 2.227498566110929

Epoch: 5| Step: 5
Training loss: 0.747286319732666
Validation loss: 2.227764591574669

Epoch: 5| Step: 6
Training loss: 0.4232897162437439
Validation loss: 2.297810345888138

Epoch: 5| Step: 7
Training loss: 0.7106558680534363
Validation loss: 2.21625949939092

Epoch: 5| Step: 8
Training loss: 0.6124979257583618
Validation loss: 2.240445206562678

Epoch: 5| Step: 9
Training loss: 0.42257532477378845
Validation loss: 2.187498723467191

Epoch: 5| Step: 10
Training loss: 1.188718318939209
Validation loss: 2.256848285595576

Epoch: 5| Step: 11
Training loss: 0.589207649230957
Validation loss: 2.193350613117218

Epoch: 331| Step: 0
Training loss: 0.403616338968277
Validation loss: 2.2134566952784858

Epoch: 5| Step: 1
Training loss: 0.5753174424171448
Validation loss: 2.1664641747872033

Epoch: 5| Step: 2
Training loss: 0.6946200132369995
Validation loss: 2.156349470218023

Epoch: 5| Step: 3
Training loss: 0.5637532472610474
Validation loss: 2.1863535046577454

Epoch: 5| Step: 4
Training loss: 0.38281241059303284
Validation loss: 2.143963853518168

Epoch: 5| Step: 5
Training loss: 0.5797222852706909
Validation loss: 2.228834569454193

Epoch: 5| Step: 6
Training loss: 0.6361957788467407
Validation loss: 2.237795054912567

Epoch: 5| Step: 7
Training loss: 0.861236572265625
Validation loss: 2.2848798433939614

Epoch: 5| Step: 8
Training loss: 0.739382803440094
Validation loss: 2.2141408572594323

Epoch: 5| Step: 9
Training loss: 0.561931312084198
Validation loss: 2.2348570923010507

Epoch: 5| Step: 10
Training loss: 0.8238922357559204
Validation loss: 2.1151995211839676

Epoch: 5| Step: 11
Training loss: 0.3206366300582886
Validation loss: 2.2475561698277793

Epoch: 332| Step: 0
Training loss: 0.6562150716781616
Validation loss: 2.2561064660549164

Epoch: 5| Step: 1
Training loss: 0.5874456763267517
Validation loss: 2.2124670247236886

Epoch: 5| Step: 2
Training loss: 0.7345058917999268
Validation loss: 2.264404977361361

Epoch: 5| Step: 3
Training loss: 0.5230408906936646
Validation loss: 2.2507873475551605

Epoch: 5| Step: 4
Training loss: 0.6295740604400635
Validation loss: 2.1759290446837745

Epoch: 5| Step: 5
Training loss: 0.7749750018119812
Validation loss: 2.248020942012469

Epoch: 5| Step: 6
Training loss: 0.7327354550361633
Validation loss: 2.219654063383738

Epoch: 5| Step: 7
Training loss: 1.2418591976165771
Validation loss: 2.2704287469387054

Epoch: 5| Step: 8
Training loss: 0.5126340389251709
Validation loss: 2.2555896639823914

Epoch: 5| Step: 9
Training loss: 0.5251180529594421
Validation loss: 2.220670680205027

Epoch: 5| Step: 10
Training loss: 0.49898606538772583
Validation loss: 2.171067923307419

Epoch: 5| Step: 11
Training loss: 0.5743950605392456
Validation loss: 2.1996654768784842

Epoch: 333| Step: 0
Training loss: 0.4042200446128845
Validation loss: 2.154365688562393

Epoch: 5| Step: 1
Training loss: 1.1137244701385498
Validation loss: 2.1992973387241364

Epoch: 5| Step: 2
Training loss: 0.6502767205238342
Validation loss: 2.150085141261419

Epoch: 5| Step: 3
Training loss: 1.2778769731521606
Validation loss: 2.2713276743888855

Epoch: 5| Step: 4
Training loss: 0.4455426335334778
Validation loss: 2.1653545250495276

Epoch: 5| Step: 5
Training loss: 0.3892601430416107
Validation loss: 2.1826142321030297

Epoch: 5| Step: 6
Training loss: 0.7445127964019775
Validation loss: 2.209597498178482

Epoch: 5| Step: 7
Training loss: 0.6084617376327515
Validation loss: 2.1875374714533486

Epoch: 5| Step: 8
Training loss: 0.41094809770584106
Validation loss: 2.1949277420838675

Epoch: 5| Step: 9
Training loss: 0.5976744294166565
Validation loss: 2.2542425394058228

Epoch: 5| Step: 10
Training loss: 0.7116988897323608
Validation loss: 2.237749675909678

Epoch: 5| Step: 11
Training loss: 0.6227115392684937
Validation loss: 2.2278274993101754

Epoch: 334| Step: 0
Training loss: 0.4566280245780945
Validation loss: 2.1741439451773963

Epoch: 5| Step: 1
Training loss: 0.6784485578536987
Validation loss: 2.2132471005121865

Epoch: 5| Step: 2
Training loss: 0.5041050910949707
Validation loss: 2.130607401331266

Epoch: 5| Step: 3
Training loss: 0.9573289752006531
Validation loss: 2.2492177387078605

Epoch: 5| Step: 4
Training loss: 0.5835192799568176
Validation loss: 2.235835760831833

Epoch: 5| Step: 5
Training loss: 0.49332132935523987
Validation loss: 2.190612335999807

Epoch: 5| Step: 6
Training loss: 1.0808794498443604
Validation loss: 2.203030119339625

Epoch: 5| Step: 7
Training loss: 0.5912928581237793
Validation loss: 2.198883041739464

Epoch: 5| Step: 8
Training loss: 0.6836220622062683
Validation loss: 2.2045851399501166

Epoch: 5| Step: 9
Training loss: 0.58726567029953
Validation loss: 2.1816270550092063

Epoch: 5| Step: 10
Training loss: 0.43029093742370605
Validation loss: 2.216623122493426

Epoch: 5| Step: 11
Training loss: 0.4566570520401001
Validation loss: 2.323666572570801

Epoch: 335| Step: 0
Training loss: 0.8775480389595032
Validation loss: 2.211422155300776

Epoch: 5| Step: 1
Training loss: 0.6093798875808716
Validation loss: 2.2483729918797812

Epoch: 5| Step: 2
Training loss: 0.38045379519462585
Validation loss: 2.2647064924240112

Epoch: 5| Step: 3
Training loss: 0.42742887139320374
Validation loss: 2.2591182043155036

Epoch: 5| Step: 4
Training loss: 0.5835383534431458
Validation loss: 2.2317360242207847

Epoch: 5| Step: 5
Training loss: 0.8971608877182007
Validation loss: 2.206715444723765

Epoch: 5| Step: 6
Training loss: 0.6105838418006897
Validation loss: 2.2567547261714935

Epoch: 5| Step: 7
Training loss: 0.9595354199409485
Validation loss: 2.1927109509706497

Epoch: 5| Step: 8
Training loss: 0.5932613015174866
Validation loss: 2.230827490488688

Epoch: 5| Step: 9
Training loss: 0.6373046636581421
Validation loss: 2.249220222234726

Epoch: 5| Step: 10
Training loss: 0.4218279719352722
Validation loss: 2.2284553050994873

Epoch: 5| Step: 11
Training loss: 0.16326603293418884
Validation loss: 2.2865856091181436

Epoch: 336| Step: 0
Training loss: 0.5982540249824524
Validation loss: 2.171689748764038

Epoch: 5| Step: 1
Training loss: 0.4142552316188812
Validation loss: 2.255038489898046

Epoch: 5| Step: 2
Training loss: 0.9955406188964844
Validation loss: 2.227062667409579

Epoch: 5| Step: 3
Training loss: 0.5659142732620239
Validation loss: 2.26983871559302

Epoch: 5| Step: 4
Training loss: 0.5328119993209839
Validation loss: 2.190077712138494

Epoch: 5| Step: 5
Training loss: 0.4391920566558838
Validation loss: 2.229411701361338

Epoch: 5| Step: 6
Training loss: 0.8671285510063171
Validation loss: 2.1903991798559823

Epoch: 5| Step: 7
Training loss: 0.846548855304718
Validation loss: 2.176524539788564

Epoch: 5| Step: 8
Training loss: 0.35593581199645996
Validation loss: 2.2529807736476264

Epoch: 5| Step: 9
Training loss: 0.5491629242897034
Validation loss: 2.1944413781166077

Epoch: 5| Step: 10
Training loss: 0.8543699383735657
Validation loss: 2.170457601547241

Epoch: 5| Step: 11
Training loss: 0.5495945811271667
Validation loss: 2.220480422178904

Epoch: 337| Step: 0
Training loss: 0.8396918177604675
Validation loss: 2.1441477040449777

Epoch: 5| Step: 1
Training loss: 0.35808706283569336
Validation loss: 2.3231281836827598

Epoch: 5| Step: 2
Training loss: 0.7124565243721008
Validation loss: 2.2432901511589685

Epoch: 5| Step: 3
Training loss: 0.4810267984867096
Validation loss: 2.262715364495913

Epoch: 5| Step: 4
Training loss: 0.9386078119277954
Validation loss: 2.282496357957522

Epoch: 5| Step: 5
Training loss: 0.5560291409492493
Validation loss: 2.222333406408628

Epoch: 5| Step: 6
Training loss: 0.3832474648952484
Validation loss: 2.2396461963653564

Epoch: 5| Step: 7
Training loss: 0.6403170824050903
Validation loss: 2.250882148742676

Epoch: 5| Step: 8
Training loss: 0.3316860795021057
Validation loss: 2.2233229875564575

Epoch: 5| Step: 9
Training loss: 0.9885589480400085
Validation loss: 2.1970809350411096

Epoch: 5| Step: 10
Training loss: 0.6565290689468384
Validation loss: 2.2624681492646537

Epoch: 5| Step: 11
Training loss: 1.3071815967559814
Validation loss: 2.256072759628296

Epoch: 338| Step: 0
Training loss: 0.7814638018608093
Validation loss: 2.2153268406788507

Epoch: 5| Step: 1
Training loss: 0.907940685749054
Validation loss: 2.305523097515106

Epoch: 5| Step: 2
Training loss: 0.6469283699989319
Validation loss: 2.2325577388207116

Epoch: 5| Step: 3
Training loss: 0.5524719953536987
Validation loss: 2.1946219305197396

Epoch: 5| Step: 4
Training loss: 1.145857572555542
Validation loss: 2.2105345129966736

Epoch: 5| Step: 5
Training loss: 0.7530931234359741
Validation loss: 2.2074288030465445

Epoch: 5| Step: 6
Training loss: 0.5014427900314331
Validation loss: 2.2179397543271384

Epoch: 5| Step: 7
Training loss: 0.42282646894454956
Validation loss: 2.157042309641838

Epoch: 5| Step: 8
Training loss: 0.7117554545402527
Validation loss: 2.2201456427574158

Epoch: 5| Step: 9
Training loss: 0.6665350198745728
Validation loss: 2.18210107088089

Epoch: 5| Step: 10
Training loss: 0.4582001268863678
Validation loss: 2.216741383075714

Epoch: 5| Step: 11
Training loss: 0.633823037147522
Validation loss: 2.224290281534195

Epoch: 339| Step: 0
Training loss: 0.5453462600708008
Validation loss: 2.2191004753112793

Epoch: 5| Step: 1
Training loss: 0.7123204469680786
Validation loss: 2.2043711245059967

Epoch: 5| Step: 2
Training loss: 1.0600650310516357
Validation loss: 2.223816225926081

Epoch: 5| Step: 3
Training loss: 0.6249006986618042
Validation loss: 2.150568981965383

Epoch: 5| Step: 4
Training loss: 0.5052267909049988
Validation loss: 2.2007136593262353

Epoch: 5| Step: 5
Training loss: 0.3987793028354645
Validation loss: 2.1380001405874887

Epoch: 5| Step: 6
Training loss: 0.6063491106033325
Validation loss: 2.1518386205037436

Epoch: 5| Step: 7
Training loss: 0.8002339601516724
Validation loss: 2.2504930744568505

Epoch: 5| Step: 8
Training loss: 0.7115458250045776
Validation loss: 2.186906715234121

Epoch: 5| Step: 9
Training loss: 0.6365662813186646
Validation loss: 2.2039127399524054

Epoch: 5| Step: 10
Training loss: 0.578243613243103
Validation loss: 2.183775395154953

Epoch: 5| Step: 11
Training loss: 0.32589977979660034
Validation loss: 2.1318102727333703

Epoch: 340| Step: 0
Training loss: 0.7974351048469543
Validation loss: 2.189492772022883

Epoch: 5| Step: 1
Training loss: 0.5124858021736145
Validation loss: 2.1961009005705514

Epoch: 5| Step: 2
Training loss: 0.8523592948913574
Validation loss: 2.2333168983459473

Epoch: 5| Step: 3
Training loss: 0.3119131028652191
Validation loss: 2.212841053803762

Epoch: 5| Step: 4
Training loss: 0.7675901651382446
Validation loss: 2.182625502347946

Epoch: 5| Step: 5
Training loss: 0.4802214205265045
Validation loss: 2.148712694644928

Epoch: 5| Step: 6
Training loss: 0.36248984932899475
Validation loss: 2.22100692987442

Epoch: 5| Step: 7
Training loss: 0.5448509454727173
Validation loss: 2.2793780465920768

Epoch: 5| Step: 8
Training loss: 1.1881611347198486
Validation loss: 2.2420985649029412

Epoch: 5| Step: 9
Training loss: 0.5495147705078125
Validation loss: 2.26406263311704

Epoch: 5| Step: 10
Training loss: 0.46487289667129517
Validation loss: 2.2240188171466193

Epoch: 5| Step: 11
Training loss: 0.326504111289978
Validation loss: 2.1825970311959586

Epoch: 341| Step: 0
Training loss: 0.5981652140617371
Validation loss: 2.174201875925064

Epoch: 5| Step: 1
Training loss: 0.4590187966823578
Validation loss: 2.1938243558009467

Epoch: 5| Step: 2
Training loss: 1.0102407932281494
Validation loss: 2.1592755913734436

Epoch: 5| Step: 3
Training loss: 0.6476000547409058
Validation loss: 2.2505443543195724

Epoch: 5| Step: 4
Training loss: 0.3960942029953003
Validation loss: 2.2911877632141113

Epoch: 5| Step: 5
Training loss: 0.6126857399940491
Validation loss: 2.237953801949819

Epoch: 5| Step: 6
Training loss: 0.4341403841972351
Validation loss: 2.241761177778244

Epoch: 5| Step: 7
Training loss: 0.6557807922363281
Validation loss: 2.229335809747378

Epoch: 5| Step: 8
Training loss: 0.570304274559021
Validation loss: 2.205257828036944

Epoch: 5| Step: 9
Training loss: 0.5124351382255554
Validation loss: 2.3471345802148185

Epoch: 5| Step: 10
Training loss: 0.7276080846786499
Validation loss: 2.278014878431956

Epoch: 5| Step: 11
Training loss: 0.4032125473022461
Validation loss: 2.2390346626440683

Epoch: 342| Step: 0
Training loss: 0.5626623630523682
Validation loss: 2.2411982268095016

Epoch: 5| Step: 1
Training loss: 0.34675297141075134
Validation loss: 2.2616668542226157

Epoch: 5| Step: 2
Training loss: 1.0815601348876953
Validation loss: 2.2132440507411957

Epoch: 5| Step: 3
Training loss: 0.34827980399131775
Validation loss: 2.2011855244636536

Epoch: 5| Step: 4
Training loss: 1.0348196029663086
Validation loss: 2.216656744480133

Epoch: 5| Step: 5
Training loss: 0.7066270112991333
Validation loss: 2.1900186787048974

Epoch: 5| Step: 6
Training loss: 0.3268737196922302
Validation loss: 2.274421284596125

Epoch: 5| Step: 7
Training loss: 0.8211132884025574
Validation loss: 2.2439449479182563

Epoch: 5| Step: 8
Training loss: 0.474213182926178
Validation loss: 2.2260488967100778

Epoch: 5| Step: 9
Training loss: 0.5850277543067932
Validation loss: 2.2354406217734017

Epoch: 5| Step: 10
Training loss: 0.46408653259277344
Validation loss: 2.20905672510465

Epoch: 5| Step: 11
Training loss: 0.389235258102417
Validation loss: 2.1990714967250824

Epoch: 343| Step: 0
Training loss: 1.1595871448516846
Validation loss: 2.2116614133119583

Epoch: 5| Step: 1
Training loss: 0.4513013958930969
Validation loss: 2.2138827741146088

Epoch: 5| Step: 2
Training loss: 0.564812958240509
Validation loss: 2.2166481763124466

Epoch: 5| Step: 3
Training loss: 0.7105374932289124
Validation loss: 2.235836128393809

Epoch: 5| Step: 4
Training loss: 0.7924470901489258
Validation loss: 2.2411915560563407

Epoch: 5| Step: 5
Training loss: 0.44990482926368713
Validation loss: 2.236386532584826

Epoch: 5| Step: 6
Training loss: 0.8773485422134399
Validation loss: 2.242453411221504

Epoch: 5| Step: 7
Training loss: 0.3458307385444641
Validation loss: 2.2294477224349976

Epoch: 5| Step: 8
Training loss: 0.34936103224754333
Validation loss: 2.216683010260264

Epoch: 5| Step: 9
Training loss: 0.49585121870040894
Validation loss: 2.2682583729426065

Epoch: 5| Step: 10
Training loss: 0.4936397969722748
Validation loss: 2.249035427967707

Epoch: 5| Step: 11
Training loss: 0.46164727210998535
Validation loss: 2.226479480663935

Epoch: 344| Step: 0
Training loss: 0.7674565315246582
Validation loss: 2.2827812830607095

Epoch: 5| Step: 1
Training loss: 0.3997364938259125
Validation loss: 2.221850961446762

Epoch: 5| Step: 2
Training loss: 0.45622819662094116
Validation loss: 2.2046633064746857

Epoch: 5| Step: 3
Training loss: 0.549004077911377
Validation loss: 2.2365584621826806

Epoch: 5| Step: 4
Training loss: 0.7747408747673035
Validation loss: 2.257792333761851

Epoch: 5| Step: 5
Training loss: 0.4519921839237213
Validation loss: 2.260004540284475

Epoch: 5| Step: 6
Training loss: 0.5123065114021301
Validation loss: 2.205795466899872

Epoch: 5| Step: 7
Training loss: 0.4272294044494629
Validation loss: 2.232394278049469

Epoch: 5| Step: 8
Training loss: 0.939972996711731
Validation loss: 2.1994676341613135

Epoch: 5| Step: 9
Training loss: 0.3457222580909729
Validation loss: 2.2638038794199624

Epoch: 5| Step: 10
Training loss: 0.6770223379135132
Validation loss: 2.1804835746685662

Epoch: 5| Step: 11
Training loss: 0.3911281228065491
Validation loss: 2.2332251369953156

Epoch: 345| Step: 0
Training loss: 0.6103672981262207
Validation loss: 2.230505252877871

Epoch: 5| Step: 1
Training loss: 0.5422662496566772
Validation loss: 2.2153022388617196

Epoch: 5| Step: 2
Training loss: 0.8269081115722656
Validation loss: 2.1809122065703073

Epoch: 5| Step: 3
Training loss: 0.638774037361145
Validation loss: 2.2185455660025277

Epoch: 5| Step: 4
Training loss: 0.5345883369445801
Validation loss: 2.244267001748085

Epoch: 5| Step: 5
Training loss: 0.8625132441520691
Validation loss: 2.2577551156282425

Epoch: 5| Step: 6
Training loss: 0.5863040089607239
Validation loss: 2.1788232823212943

Epoch: 5| Step: 7
Training loss: 0.6391042470932007
Validation loss: 2.279373208681742

Epoch: 5| Step: 8
Training loss: 0.428821325302124
Validation loss: 2.2205262184143066

Epoch: 5| Step: 9
Training loss: 0.5694777965545654
Validation loss: 2.219855790336927

Epoch: 5| Step: 10
Training loss: 0.5600281357765198
Validation loss: 2.238599956035614

Epoch: 5| Step: 11
Training loss: 2.1991677284240723
Validation loss: 2.2323004702727

Epoch: 346| Step: 0
Training loss: 0.6335853338241577
Validation loss: 2.249893014629682

Epoch: 5| Step: 1
Training loss: 0.4249366819858551
Validation loss: 2.220460424820582

Epoch: 5| Step: 2
Training loss: 0.41249021887779236
Validation loss: 2.2428088386853537

Epoch: 5| Step: 3
Training loss: 0.8808377981185913
Validation loss: 2.252388447523117

Epoch: 5| Step: 4
Training loss: 0.7271146178245544
Validation loss: 2.185932010412216

Epoch: 5| Step: 5
Training loss: 0.48017650842666626
Validation loss: 2.193805714448293

Epoch: 5| Step: 6
Training loss: 0.8585475087165833
Validation loss: 2.2648487240076065

Epoch: 5| Step: 7
Training loss: 0.6768099069595337
Validation loss: 2.2528362472852073

Epoch: 5| Step: 8
Training loss: 0.6671023964881897
Validation loss: 2.1866876731316247

Epoch: 5| Step: 9
Training loss: 0.5448746085166931
Validation loss: 2.254462252060572

Epoch: 5| Step: 10
Training loss: 0.610288679599762
Validation loss: 2.306387777129809

Epoch: 5| Step: 11
Training loss: 0.7586110234260559
Validation loss: 2.2484098374843597

Epoch: 347| Step: 0
Training loss: 0.5166987776756287
Validation loss: 2.2263125081857047

Epoch: 5| Step: 1
Training loss: 0.7358772158622742
Validation loss: 2.182324339946111

Epoch: 5| Step: 2
Training loss: 0.45819157361984253
Validation loss: 2.2144124060869217

Epoch: 5| Step: 3
Training loss: 1.241194486618042
Validation loss: 2.1621037473281226

Epoch: 5| Step: 4
Training loss: 0.5573757290840149
Validation loss: 2.225292295217514

Epoch: 5| Step: 5
Training loss: 0.4033898711204529
Validation loss: 2.245551993449529

Epoch: 5| Step: 6
Training loss: 0.36423763632774353
Validation loss: 2.2141141990820565

Epoch: 5| Step: 7
Training loss: 0.7413760423660278
Validation loss: 2.163995439807574

Epoch: 5| Step: 8
Training loss: 0.8863126635551453
Validation loss: 2.246880665421486

Epoch: 5| Step: 9
Training loss: 0.5043483972549438
Validation loss: 2.172517483433088

Epoch: 5| Step: 10
Training loss: 0.3609946072101593
Validation loss: 2.1242099603017173

Epoch: 5| Step: 11
Training loss: 0.3999640941619873
Validation loss: 2.2541349728902182

Epoch: 348| Step: 0
Training loss: 0.6474794149398804
Validation loss: 2.23414812485377

Epoch: 5| Step: 1
Training loss: 0.5780537724494934
Validation loss: 2.266659369071325

Epoch: 5| Step: 2
Training loss: 0.4706335663795471
Validation loss: 2.232316335042318

Epoch: 5| Step: 3
Training loss: 0.575859785079956
Validation loss: 2.1914436717828116

Epoch: 5| Step: 4
Training loss: 0.4795225262641907
Validation loss: 2.209992786248525

Epoch: 5| Step: 5
Training loss: 1.0296154022216797
Validation loss: 2.1914503375689187

Epoch: 5| Step: 6
Training loss: 0.3561953008174896
Validation loss: 2.156648894151052

Epoch: 5| Step: 7
Training loss: 0.6066943407058716
Validation loss: 2.205370510617892

Epoch: 5| Step: 8
Training loss: 0.5840253829956055
Validation loss: 2.2047673215468726

Epoch: 5| Step: 9
Training loss: 0.988629162311554
Validation loss: 2.2800501386324563

Epoch: 5| Step: 10
Training loss: 0.5807363390922546
Validation loss: 2.2201511214176812

Epoch: 5| Step: 11
Training loss: 0.2760319411754608
Validation loss: 2.1472777326901755

Epoch: 349| Step: 0
Training loss: 1.0072791576385498
Validation loss: 2.1800365447998047

Epoch: 5| Step: 1
Training loss: 0.5334999561309814
Validation loss: 2.2110750675201416

Epoch: 5| Step: 2
Training loss: 0.45173054933547974
Validation loss: 2.1889094362656274

Epoch: 5| Step: 3
Training loss: 0.5681473612785339
Validation loss: 2.206637278199196

Epoch: 5| Step: 4
Training loss: 0.6053122282028198
Validation loss: 2.171467865506808

Epoch: 5| Step: 5
Training loss: 0.6732853651046753
Validation loss: 2.183360199133555

Epoch: 5| Step: 6
Training loss: 0.7886934280395508
Validation loss: 2.187456210454305

Epoch: 5| Step: 7
Training loss: 0.6758600473403931
Validation loss: 2.169167548418045

Epoch: 5| Step: 8
Training loss: 0.6596862077713013
Validation loss: 2.2391197929779687

Epoch: 5| Step: 9
Training loss: 0.3950185775756836
Validation loss: 2.181617687145869

Epoch: 5| Step: 10
Training loss: 0.3867191672325134
Validation loss: 2.189216767748197

Epoch: 5| Step: 11
Training loss: 0.21860897541046143
Validation loss: 2.217864761749903

Epoch: 350| Step: 0
Training loss: 0.7169800996780396
Validation loss: 2.212498585383097

Epoch: 5| Step: 1
Training loss: 0.5098920464515686
Validation loss: 2.2249672412872314

Epoch: 5| Step: 2
Training loss: 0.7415549755096436
Validation loss: 2.1832857032616935

Epoch: 5| Step: 3
Training loss: 0.590693473815918
Validation loss: 2.235745847225189

Epoch: 5| Step: 4
Training loss: 1.0583553314208984
Validation loss: 2.181290715932846

Epoch: 5| Step: 5
Training loss: 0.6159417033195496
Validation loss: 2.195832053820292

Epoch: 5| Step: 6
Training loss: 0.3665604293346405
Validation loss: 2.2675799628098807

Epoch: 5| Step: 7
Training loss: 0.5167847871780396
Validation loss: 2.200474147995313

Epoch: 5| Step: 8
Training loss: 0.3990343511104584
Validation loss: 2.174285744627317

Epoch: 5| Step: 9
Training loss: 0.4834413528442383
Validation loss: 2.237806727488836

Epoch: 5| Step: 10
Training loss: 0.533066987991333
Validation loss: 2.227057605981827

Epoch: 5| Step: 11
Training loss: 0.8633160591125488
Validation loss: 2.2485149204730988

Testing loss: 2.07814937444042
