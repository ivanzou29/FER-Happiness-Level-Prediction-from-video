Epoch: 1| Step: 0
Training loss: 7.4728823925203995
Validation loss: 7.622200999340074

Epoch: 6| Step: 1
Training loss: 7.03980626316523
Validation loss: 7.6031560635614825

Epoch: 6| Step: 2
Training loss: 7.183123242816064
Validation loss: 7.583611437829743

Epoch: 6| Step: 3
Training loss: 8.225436083703395
Validation loss: 7.564172985307789

Epoch: 6| Step: 4
Training loss: 7.428090017041361
Validation loss: 7.544584380799509

Epoch: 6| Step: 5
Training loss: 7.763360351454336
Validation loss: 7.524506563925522

Epoch: 6| Step: 6
Training loss: 8.257211943038984
Validation loss: 7.504701878342418

Epoch: 6| Step: 7
Training loss: 6.832929583771323
Validation loss: 7.4864412029327445

Epoch: 6| Step: 8
Training loss: 7.796113674628813
Validation loss: 7.46817125022674

Epoch: 6| Step: 9
Training loss: 7.717847763643904
Validation loss: 7.44495234330507

Epoch: 6| Step: 10
Training loss: 7.503559031041484
Validation loss: 7.420912381036216

Epoch: 6| Step: 11
Training loss: 8.348103162755933
Validation loss: 7.40465999656389

Epoch: 6| Step: 12
Training loss: 7.313623586555457
Validation loss: 7.377668986163103

Epoch: 6| Step: 13
Training loss: 7.2746853685017445
Validation loss: 7.358801039811463

Epoch: 2| Step: 0
Training loss: 6.8715228911254975
Validation loss: 7.333649397310047

Epoch: 6| Step: 1
Training loss: 6.842334618372968
Validation loss: 7.306493177628251

Epoch: 6| Step: 2
Training loss: 6.679256313751192
Validation loss: 7.280245339168614

Epoch: 6| Step: 3
Training loss: 8.255866536917287
Validation loss: 7.2572188995233535

Epoch: 6| Step: 4
Training loss: 8.002079693363802
Validation loss: 7.22604305565553

Epoch: 6| Step: 5
Training loss: 6.7681110563072036
Validation loss: 7.195975174764037

Epoch: 6| Step: 6
Training loss: 7.512263888744249
Validation loss: 7.168828579007203

Epoch: 6| Step: 7
Training loss: 7.672602166483477
Validation loss: 7.137461110914902

Epoch: 6| Step: 8
Training loss: 7.123070706619717
Validation loss: 7.102293362304303

Epoch: 6| Step: 9
Training loss: 8.06078042315218
Validation loss: 7.067908407671725

Epoch: 6| Step: 10
Training loss: 6.042730128207261
Validation loss: 7.028680312043961

Epoch: 6| Step: 11
Training loss: 6.864619238088559
Validation loss: 6.995916651520628

Epoch: 6| Step: 12
Training loss: 7.908415124736198
Validation loss: 6.958882186471972

Epoch: 6| Step: 13
Training loss: 6.381285018899535
Validation loss: 6.924700640325897

Epoch: 3| Step: 0
Training loss: 7.307473566279594
Validation loss: 6.879834180578354

Epoch: 6| Step: 1
Training loss: 5.77582093055827
Validation loss: 6.831290691844367

Epoch: 6| Step: 2
Training loss: 6.327921244790696
Validation loss: 6.787299626380268

Epoch: 6| Step: 3
Training loss: 7.698605587028026
Validation loss: 6.752652718432842

Epoch: 6| Step: 4
Training loss: 6.625673079937391
Validation loss: 6.697261732798762

Epoch: 6| Step: 5
Training loss: 6.373752247491453
Validation loss: 6.65827135129621

Epoch: 6| Step: 6
Training loss: 7.497073556259068
Validation loss: 6.5975146401722204

Epoch: 6| Step: 7
Training loss: 5.939949895474051
Validation loss: 6.554171360383614

Epoch: 6| Step: 8
Training loss: 5.998209368219819
Validation loss: 6.493918288017283

Epoch: 6| Step: 9
Training loss: 7.594749604668819
Validation loss: 6.438293111887659

Epoch: 6| Step: 10
Training loss: 6.332358971315632
Validation loss: 6.372755415955756

Epoch: 6| Step: 11
Training loss: 6.359747198586721
Validation loss: 6.33240043729536

Epoch: 6| Step: 12
Training loss: 5.853022924084059
Validation loss: 6.266724906136725

Epoch: 6| Step: 13
Training loss: 6.9045283730638225
Validation loss: 6.194435573888946

Epoch: 4| Step: 0
Training loss: 5.441533138551048
Validation loss: 6.123085008063408

Epoch: 6| Step: 1
Training loss: 7.13547856287783
Validation loss: 6.064102066043327

Epoch: 6| Step: 2
Training loss: 6.458602834021222
Validation loss: 5.992328507854432

Epoch: 6| Step: 3
Training loss: 5.7571575563521025
Validation loss: 5.910731558019223

Epoch: 6| Step: 4
Training loss: 6.222906669180414
Validation loss: 5.847883099046381

Epoch: 6| Step: 5
Training loss: 5.069718101233693
Validation loss: 5.7617296742481185

Epoch: 6| Step: 6
Training loss: 5.822868697276511
Validation loss: 5.67862864702844

Epoch: 6| Step: 7
Training loss: 5.440607695576659
Validation loss: 5.589689631617819

Epoch: 6| Step: 8
Training loss: 5.815089807579488
Validation loss: 5.500023321622474

Epoch: 6| Step: 9
Training loss: 5.917483349524064
Validation loss: 5.403500984425951

Epoch: 6| Step: 10
Training loss: 5.170502725504382
Validation loss: 5.308606504940067

Epoch: 6| Step: 11
Training loss: 4.38197555302565
Validation loss: 5.2276449332326775

Epoch: 6| Step: 12
Training loss: 5.0231379157120175
Validation loss: 5.129108116049165

Epoch: 6| Step: 13
Training loss: 5.519559586135686
Validation loss: 5.014994802526163

Epoch: 5| Step: 0
Training loss: 4.570336913997292
Validation loss: 4.924432887104127

Epoch: 6| Step: 1
Training loss: 4.160579405562431
Validation loss: 4.799154727737901

Epoch: 6| Step: 2
Training loss: 4.648650246247665
Validation loss: 4.683772016096331

Epoch: 6| Step: 3
Training loss: 4.198852636656289
Validation loss: 4.588338384841446

Epoch: 6| Step: 4
Training loss: 5.0319410524781825
Validation loss: 4.466342428642316

Epoch: 6| Step: 5
Training loss: 4.677132292606651
Validation loss: 4.350966571978419

Epoch: 6| Step: 6
Training loss: 3.299076159081201
Validation loss: 4.233286249594787

Epoch: 6| Step: 7
Training loss: 4.2586447366123155
Validation loss: 4.113020388406059

Epoch: 6| Step: 8
Training loss: 4.380854150409279
Validation loss: 3.957993215036255

Epoch: 6| Step: 9
Training loss: 3.9216653836225643
Validation loss: 3.848927884461061

Epoch: 6| Step: 10
Training loss: 3.448017468472372
Validation loss: 3.7472558047297397

Epoch: 6| Step: 11
Training loss: 3.9227560201210574
Validation loss: 3.6238835248748735

Epoch: 6| Step: 12
Training loss: 3.3362230808491256
Validation loss: 3.4972251155465255

Epoch: 6| Step: 13
Training loss: 4.16294951889876
Validation loss: 3.3715620308701078

Epoch: 6| Step: 0
Training loss: 3.698128979816007
Validation loss: 3.275701597157997

Epoch: 6| Step: 1
Training loss: 2.737895856828626
Validation loss: 3.1766088829775994

Epoch: 6| Step: 2
Training loss: 2.815754512132621
Validation loss: 3.0909709457805823

Epoch: 6| Step: 3
Training loss: 3.4811597281622277
Validation loss: 3.011157836664919

Epoch: 6| Step: 4
Training loss: 2.2723723862742777
Validation loss: 2.9467367679864904

Epoch: 6| Step: 5
Training loss: 2.6644348600259553
Validation loss: 2.9072987158068098

Epoch: 6| Step: 6
Training loss: 3.4791095447229208
Validation loss: 2.916856505255858

Epoch: 6| Step: 7
Training loss: 2.522086617479046
Validation loss: 2.879540244642881

Epoch: 6| Step: 8
Training loss: 2.6644739633105194
Validation loss: 2.883563005160671

Epoch: 6| Step: 9
Training loss: 2.478605468660735
Validation loss: 2.9672739341431145

Epoch: 6| Step: 10
Training loss: 2.9677449984755366
Validation loss: 3.0053485108226137

Epoch: 6| Step: 11
Training loss: 3.7952279494107177
Validation loss: 2.9817021435595326

Epoch: 6| Step: 12
Training loss: 2.8692955146670203
Validation loss: 3.058743631938026

Epoch: 6| Step: 13
Training loss: 3.2641297343968474
Validation loss: 3.019196577718049

Epoch: 7| Step: 0
Training loss: 3.1168007670501456
Validation loss: 3.015826664903458

Epoch: 6| Step: 1
Training loss: 2.6967406980948745
Validation loss: 2.9637535077603467

Epoch: 6| Step: 2
Training loss: 3.83958718266383
Validation loss: 3.012966796249761

Epoch: 6| Step: 3
Training loss: 3.012855325217817
Validation loss: 3.0136705169048366

Epoch: 6| Step: 4
Training loss: 2.7238540094552497
Validation loss: 2.9815901233713027

Epoch: 6| Step: 5
Training loss: 2.8631883218421046
Validation loss: 2.976111590656964

Epoch: 6| Step: 6
Training loss: 2.341550685232167
Validation loss: 3.0107597674742177

Epoch: 6| Step: 7
Training loss: 3.450325914551548
Validation loss: 2.9352264398612067

Epoch: 6| Step: 8
Training loss: 2.070305244864941
Validation loss: 2.9440320213950235

Epoch: 6| Step: 9
Training loss: 2.616827550020098
Validation loss: 2.877863246020034

Epoch: 6| Step: 10
Training loss: 2.259946771349333
Validation loss: 2.896633069780402

Epoch: 6| Step: 11
Training loss: 3.100678978672926
Validation loss: 2.9231376843533745

Epoch: 6| Step: 12
Training loss: 2.596557292944489
Validation loss: 2.8776178604191402

Epoch: 6| Step: 13
Training loss: 2.6427907696051913
Validation loss: 2.896562242136495

Epoch: 8| Step: 0
Training loss: 2.53386035590414
Validation loss: 2.854049573478022

Epoch: 6| Step: 1
Training loss: 2.998366546984081
Validation loss: 2.8944662055061725

Epoch: 6| Step: 2
Training loss: 3.0820272274015257
Validation loss: 2.879041056968406

Epoch: 6| Step: 3
Training loss: 2.8241758646683452
Validation loss: 2.8422873371996014

Epoch: 6| Step: 4
Training loss: 2.9697819572583484
Validation loss: 2.879587763085259

Epoch: 6| Step: 5
Training loss: 2.6944207084457994
Validation loss: 2.85855529931665

Epoch: 6| Step: 6
Training loss: 2.122712867944878
Validation loss: 2.834934698358592

Epoch: 6| Step: 7
Training loss: 3.3793775637690824
Validation loss: 2.9093928554053927

Epoch: 6| Step: 8
Training loss: 2.5113612464884
Validation loss: 2.854075776112476

Epoch: 6| Step: 9
Training loss: 3.1365983495728247
Validation loss: 2.8716187842597147

Epoch: 6| Step: 10
Training loss: 3.5672400545450382
Validation loss: 2.859123482959444

Epoch: 6| Step: 11
Training loss: 2.064092079430015
Validation loss: 2.8952521465919294

Epoch: 6| Step: 12
Training loss: 2.6871958715772246
Validation loss: 2.9120635402798403

Epoch: 6| Step: 13
Training loss: 2.5472724464019803
Validation loss: 2.8798858894373964

Epoch: 9| Step: 0
Training loss: 3.4834588048017703
Validation loss: 2.890336972569978

Epoch: 6| Step: 1
Training loss: 2.6385919091498415
Validation loss: 2.8113079087809365

Epoch: 6| Step: 2
Training loss: 2.888852787607357
Validation loss: 2.8575978271657307

Epoch: 6| Step: 3
Training loss: 1.9483560552759582
Validation loss: 2.815307755685228

Epoch: 6| Step: 4
Training loss: 3.1257585749224415
Validation loss: 2.862352623956213

Epoch: 6| Step: 5
Training loss: 2.9480311143493507
Validation loss: 2.797728665744536

Epoch: 6| Step: 6
Training loss: 2.4039756628508835
Validation loss: 2.913630817473695

Epoch: 6| Step: 7
Training loss: 2.7058476314121873
Validation loss: 2.81402433554134

Epoch: 6| Step: 8
Training loss: 2.1130017785039117
Validation loss: 2.8366367119157476

Epoch: 6| Step: 9
Training loss: 2.684618181042626
Validation loss: 2.8134077302721456

Epoch: 6| Step: 10
Training loss: 3.554589037527124
Validation loss: 2.8261460604276287

Epoch: 6| Step: 11
Training loss: 3.318334371686997
Validation loss: 2.858965276327813

Epoch: 6| Step: 12
Training loss: 2.441095683371706
Validation loss: 2.8803956911888715

Epoch: 6| Step: 13
Training loss: 2.158751543195799
Validation loss: 2.854008347698462

Epoch: 10| Step: 0
Training loss: 2.0811025756309687
Validation loss: 2.8474321525736364

Epoch: 6| Step: 1
Training loss: 1.791541901022043
Validation loss: 2.86579233261319

Epoch: 6| Step: 2
Training loss: 3.298458930180413
Validation loss: 2.8489549184682255

Epoch: 6| Step: 3
Training loss: 2.265898063252303
Validation loss: 2.841644807397737

Epoch: 6| Step: 4
Training loss: 2.996835151860909
Validation loss: 2.8428231150563943

Epoch: 6| Step: 5
Training loss: 3.1600041488427077
Validation loss: 2.833390380247679

Epoch: 6| Step: 6
Training loss: 2.47804769272741
Validation loss: 2.8046618418817144

Epoch: 6| Step: 7
Training loss: 2.7818846246419593
Validation loss: 2.8373835776443754

Epoch: 6| Step: 8
Training loss: 2.0619366194255524
Validation loss: 2.812232463969074

Epoch: 6| Step: 9
Training loss: 2.6804994292853657
Validation loss: 2.8744048318008155

Epoch: 6| Step: 10
Training loss: 2.8503274829840004
Validation loss: 2.753438432787345

Epoch: 6| Step: 11
Training loss: 3.5795940731649583
Validation loss: 2.809352059672

Epoch: 6| Step: 12
Training loss: 3.010569549867168
Validation loss: 2.8039856920797837

Epoch: 6| Step: 13
Training loss: 2.6132859941333995
Validation loss: 2.7787729583995304

Epoch: 11| Step: 0
Training loss: 3.185482808023745
Validation loss: 2.834984737536809

Epoch: 6| Step: 1
Training loss: 2.7715172365806375
Validation loss: 2.8074031423164287

Epoch: 6| Step: 2
Training loss: 3.6221263939780783
Validation loss: 2.8410571836539344

Epoch: 6| Step: 3
Training loss: 2.233521198323261
Validation loss: 2.848791774272175

Epoch: 6| Step: 4
Training loss: 2.469844527197085
Validation loss: 2.796317643478721

Epoch: 6| Step: 5
Training loss: 3.0277116711911636
Validation loss: 2.796456858032477

Epoch: 6| Step: 6
Training loss: 2.6806873647097405
Validation loss: 2.8097314276811325

Epoch: 6| Step: 7
Training loss: 2.5551347720140942
Validation loss: 2.7631993692993375

Epoch: 6| Step: 8
Training loss: 3.074284670364154
Validation loss: 2.8176169859533564

Epoch: 6| Step: 9
Training loss: 2.298900308180658
Validation loss: 2.798147057889467

Epoch: 6| Step: 10
Training loss: 1.975925991417586
Validation loss: 2.757010850392214

Epoch: 6| Step: 11
Training loss: 2.810757245427753
Validation loss: 2.7509380387983104

Epoch: 6| Step: 12
Training loss: 2.094122554599334
Validation loss: 2.8052208480999647

Epoch: 6| Step: 13
Training loss: 2.9131939695648628
Validation loss: 2.8626502756932637

Epoch: 12| Step: 0
Training loss: 1.7960706154294521
Validation loss: 2.815804835710903

Epoch: 6| Step: 1
Training loss: 3.4968867761108546
Validation loss: 2.820047367838928

Epoch: 6| Step: 2
Training loss: 2.302642225083141
Validation loss: 2.790487400947184

Epoch: 6| Step: 3
Training loss: 2.1812098939372873
Validation loss: 2.827462724731719

Epoch: 6| Step: 4
Training loss: 2.272397357229916
Validation loss: 2.7631718734795543

Epoch: 6| Step: 5
Training loss: 2.969232459769104
Validation loss: 2.894208127277762

Epoch: 6| Step: 6
Training loss: 2.6827049060501524
Validation loss: 2.884183562797898

Epoch: 6| Step: 7
Training loss: 2.6736640517592933
Validation loss: 2.9179689134140685

Epoch: 6| Step: 8
Training loss: 2.7716332812964253
Validation loss: 2.8862062927655066

Epoch: 6| Step: 9
Training loss: 3.3372828609395544
Validation loss: 2.9063546220002863

Epoch: 6| Step: 10
Training loss: 2.523824939569312
Validation loss: 2.901539694169709

Epoch: 6| Step: 11
Training loss: 3.1614738518440344
Validation loss: 2.758875309769094

Epoch: 6| Step: 12
Training loss: 3.6219975106005906
Validation loss: 2.8532811389884984

Epoch: 6| Step: 13
Training loss: 2.1764612967136654
Validation loss: 2.780729895262555

Epoch: 13| Step: 0
Training loss: 2.1865088260872896
Validation loss: 2.8184334931791164

Epoch: 6| Step: 1
Training loss: 3.353370019043401
Validation loss: 2.749159178648949

Epoch: 6| Step: 2
Training loss: 2.552275939731866
Validation loss: 2.7447794866321806

Epoch: 6| Step: 3
Training loss: 1.9018298949259391
Validation loss: 2.7963951594293777

Epoch: 6| Step: 4
Training loss: 2.223328822168047
Validation loss: 2.8042100023508123

Epoch: 6| Step: 5
Training loss: 2.644948636225105
Validation loss: 2.7936540096442144

Epoch: 6| Step: 6
Training loss: 2.0974193702086303
Validation loss: 2.8496918277433614

Epoch: 6| Step: 7
Training loss: 2.6091242686891882
Validation loss: 2.9301156913648843

Epoch: 6| Step: 8
Training loss: 3.960948214243707
Validation loss: 2.8446248424051856

Epoch: 6| Step: 9
Training loss: 2.9094112799622676
Validation loss: 2.82593834014726

Epoch: 6| Step: 10
Training loss: 2.668338688549773
Validation loss: 2.8336537170655736

Epoch: 6| Step: 11
Training loss: 2.7487859647097217
Validation loss: 2.7579927610680857

Epoch: 6| Step: 12
Training loss: 2.8005978831515232
Validation loss: 2.7142872045508097

Epoch: 6| Step: 13
Training loss: 2.984021869957682
Validation loss: 2.7610775186510876

Epoch: 14| Step: 0
Training loss: 3.60716662203502
Validation loss: 2.7812212538930234

Epoch: 6| Step: 1
Training loss: 2.5338511347711714
Validation loss: 2.7814414854960665

Epoch: 6| Step: 2
Training loss: 2.9724153077658615
Validation loss: 2.7754630988275983

Epoch: 6| Step: 3
Training loss: 3.4934320131104037
Validation loss: 2.733948127487037

Epoch: 6| Step: 4
Training loss: 2.8171475475861403
Validation loss: 2.7737918394582572

Epoch: 6| Step: 5
Training loss: 2.434541422844285
Validation loss: 2.7460111530556266

Epoch: 6| Step: 6
Training loss: 2.560080525800699
Validation loss: 2.7533947913843915

Epoch: 6| Step: 7
Training loss: 2.59435770659908
Validation loss: 2.778885110970065

Epoch: 6| Step: 8
Training loss: 1.6505870092801735
Validation loss: 2.8424642821309876

Epoch: 6| Step: 9
Training loss: 3.0353535670256715
Validation loss: 2.7619134599606645

Epoch: 6| Step: 10
Training loss: 2.958344061030606
Validation loss: 2.8526598765363813

Epoch: 6| Step: 11
Training loss: 2.204440758819131
Validation loss: 2.759938300567248

Epoch: 6| Step: 12
Training loss: 2.063348537793731
Validation loss: 2.7603827756324706

Epoch: 6| Step: 13
Training loss: 2.301062885656878
Validation loss: 2.7404615254148066

Epoch: 15| Step: 0
Training loss: 2.639144753438517
Validation loss: 2.8116827731150753

Epoch: 6| Step: 1
Training loss: 2.298522565915538
Validation loss: 2.7309089127590442

Epoch: 6| Step: 2
Training loss: 2.4567723463802005
Validation loss: 2.756489033616849

Epoch: 6| Step: 3
Training loss: 2.4927328344199196
Validation loss: 2.7670938359295656

Epoch: 6| Step: 4
Training loss: 2.7337839414201515
Validation loss: 2.797159858845192

Epoch: 6| Step: 5
Training loss: 2.3649770154098215
Validation loss: 2.7478922800674352

Epoch: 6| Step: 6
Training loss: 2.744985603753366
Validation loss: 2.8231689556225223

Epoch: 6| Step: 7
Training loss: 3.1788813438386727
Validation loss: 2.7843726127091952

Epoch: 6| Step: 8
Training loss: 2.840502047422021
Validation loss: 2.694168142744471

Epoch: 6| Step: 9
Training loss: 2.341968520541746
Validation loss: 2.78897749969864

Epoch: 6| Step: 10
Training loss: 2.6877460810643656
Validation loss: 2.7339388399582987

Epoch: 6| Step: 11
Training loss: 2.607174796638509
Validation loss: 2.731301896848332

Epoch: 6| Step: 12
Training loss: 2.412580609333749
Validation loss: 2.738912207684949

Epoch: 6| Step: 13
Training loss: 3.1359616098584273
Validation loss: 2.7236072224039107

Epoch: 16| Step: 0
Training loss: 2.5989331771051014
Validation loss: 2.7705917731135026

Epoch: 6| Step: 1
Training loss: 2.7936978328877897
Validation loss: 2.7900857482002195

Epoch: 6| Step: 2
Training loss: 1.6489115390495754
Validation loss: 2.70390793591711

Epoch: 6| Step: 3
Training loss: 3.048311491551335
Validation loss: 2.6637533237789186

Epoch: 6| Step: 4
Training loss: 2.6524330989299836
Validation loss: 2.7322454825039437

Epoch: 6| Step: 5
Training loss: 1.6371293383696162
Validation loss: 2.7797563806998014

Epoch: 6| Step: 6
Training loss: 2.5580783936490685
Validation loss: 2.6896115664756675

Epoch: 6| Step: 7
Training loss: 3.013352718994214
Validation loss: 2.7455796782089426

Epoch: 6| Step: 8
Training loss: 2.7581715984890107
Validation loss: 2.697935617348431

Epoch: 6| Step: 9
Training loss: 3.5769120871703994
Validation loss: 2.7172913566397514

Epoch: 6| Step: 10
Training loss: 2.9987706208563587
Validation loss: 2.769514506172389

Epoch: 6| Step: 11
Training loss: 1.9530030479505032
Validation loss: 2.8124305292662526

Epoch: 6| Step: 12
Training loss: 2.9918015034360006
Validation loss: 2.7403870093935363

Epoch: 6| Step: 13
Training loss: 2.4443901686952443
Validation loss: 2.7478060640563178

Epoch: 17| Step: 0
Training loss: 3.575719832929923
Validation loss: 2.7599811042378386

Epoch: 6| Step: 1
Training loss: 2.221895271992118
Validation loss: 2.7025863463575837

Epoch: 6| Step: 2
Training loss: 2.9485421926795823
Validation loss: 2.7821434100512126

Epoch: 6| Step: 3
Training loss: 1.931347090863831
Validation loss: 2.6834985382055248

Epoch: 6| Step: 4
Training loss: 2.5726232837611778
Validation loss: 2.7135757961555305

Epoch: 6| Step: 5
Training loss: 2.251382826678569
Validation loss: 2.8139116912257656

Epoch: 6| Step: 6
Training loss: 2.467961438908726
Validation loss: 2.760675473346618

Epoch: 6| Step: 7
Training loss: 2.697333686516827
Validation loss: 2.810886683277721

Epoch: 6| Step: 8
Training loss: 3.172474170336174
Validation loss: 2.788192143062551

Epoch: 6| Step: 9
Training loss: 3.2318476878620164
Validation loss: 2.796406520202559

Epoch: 6| Step: 10
Training loss: 2.411216465552191
Validation loss: 2.8204143361368317

Epoch: 6| Step: 11
Training loss: 2.6035043611733553
Validation loss: 2.7541855402158886

Epoch: 6| Step: 12
Training loss: 2.257742910401668
Validation loss: 2.7760464427875897

Epoch: 6| Step: 13
Training loss: 2.4856948705362854
Validation loss: 2.775961444738152

Epoch: 18| Step: 0
Training loss: 2.712104656045603
Validation loss: 2.6923081612848567

Epoch: 6| Step: 1
Training loss: 1.3922932080554244
Validation loss: 2.7791969351047183

Epoch: 6| Step: 2
Training loss: 2.806968675102266
Validation loss: 2.69255514588432

Epoch: 6| Step: 3
Training loss: 2.6712100445227493
Validation loss: 2.6853054016675295

Epoch: 6| Step: 4
Training loss: 2.520801407372782
Validation loss: 2.6844631306425604

Epoch: 6| Step: 5
Training loss: 2.647269472454597
Validation loss: 2.7283319599409923

Epoch: 6| Step: 6
Training loss: 2.896989897884496
Validation loss: 2.706005201067347

Epoch: 6| Step: 7
Training loss: 3.014414489980969
Validation loss: 2.693984776272389

Epoch: 6| Step: 8
Training loss: 2.5684824634834804
Validation loss: 2.65805281252188

Epoch: 6| Step: 9
Training loss: 1.9046455885646916
Validation loss: 2.6815729505460295

Epoch: 6| Step: 10
Training loss: 3.4180107419295513
Validation loss: 2.70526078361475

Epoch: 6| Step: 11
Training loss: 2.678978384075267
Validation loss: 2.673101325927343

Epoch: 6| Step: 12
Training loss: 2.5642441187201004
Validation loss: 2.7405217428557624

Epoch: 6| Step: 13
Training loss: 2.824388849773583
Validation loss: 2.694893388827544

Epoch: 19| Step: 0
Training loss: 2.758037093313515
Validation loss: 2.7360849610535105

Epoch: 6| Step: 1
Training loss: 3.7531717238745688
Validation loss: 2.7132882105412834

Epoch: 6| Step: 2
Training loss: 2.024870964931243
Validation loss: 2.714614426695094

Epoch: 6| Step: 3
Training loss: 1.6999484194615895
Validation loss: 2.6730171424571965

Epoch: 6| Step: 4
Training loss: 2.8624168017427887
Validation loss: 2.7279879861503735

Epoch: 6| Step: 5
Training loss: 2.2997215434147877
Validation loss: 2.6956962717659483

Epoch: 6| Step: 6
Training loss: 2.687490596311219
Validation loss: 2.7324409256971545

Epoch: 6| Step: 7
Training loss: 1.7770763824911309
Validation loss: 2.7110051743033408

Epoch: 6| Step: 8
Training loss: 2.7477843288650847
Validation loss: 2.738905345342004

Epoch: 6| Step: 9
Training loss: 2.401633553083634
Validation loss: 2.697719085606728

Epoch: 6| Step: 10
Training loss: 3.116186913541444
Validation loss: 2.717233044632176

Epoch: 6| Step: 11
Training loss: 2.3711101399441255
Validation loss: 2.657018707344491

Epoch: 6| Step: 12
Training loss: 2.2780221546961252
Validation loss: 2.732195016070421

Epoch: 6| Step: 13
Training loss: 2.9389575020805667
Validation loss: 2.7810418554706944

Epoch: 20| Step: 0
Training loss: 2.6233220868513847
Validation loss: 2.758445631048154

Epoch: 6| Step: 1
Training loss: 2.7173805734173735
Validation loss: 2.7129245917965608

Epoch: 6| Step: 2
Training loss: 2.5392947985682253
Validation loss: 2.754670511886828

Epoch: 6| Step: 3
Training loss: 3.423241190154687
Validation loss: 2.7322245397743647

Epoch: 6| Step: 4
Training loss: 2.3529856484782434
Validation loss: 2.694920652350267

Epoch: 6| Step: 5
Training loss: 2.789626462535096
Validation loss: 2.7369790601987423

Epoch: 6| Step: 6
Training loss: 2.885747640381904
Validation loss: 2.71526799169036

Epoch: 6| Step: 7
Training loss: 2.1877914234590636
Validation loss: 2.7018625034358306

Epoch: 6| Step: 8
Training loss: 2.4277596138634276
Validation loss: 2.7576329908583013

Epoch: 6| Step: 9
Training loss: 2.573449536534541
Validation loss: 2.733835090739744

Epoch: 6| Step: 10
Training loss: 2.9769738581403065
Validation loss: 2.6821266987757544

Epoch: 6| Step: 11
Training loss: 2.2298871833763108
Validation loss: 2.6957187217471628

Epoch: 6| Step: 12
Training loss: 2.909127072629697
Validation loss: 2.685211907968759

Epoch: 6| Step: 13
Training loss: 1.8112134642565596
Validation loss: 2.694030161816436

Epoch: 21| Step: 0
Training loss: 2.330602057771913
Validation loss: 2.6602516549320985

Epoch: 6| Step: 1
Training loss: 2.0517273673223095
Validation loss: 2.690819981414789

Epoch: 6| Step: 2
Training loss: 2.541759009846477
Validation loss: 2.714149353359411

Epoch: 6| Step: 3
Training loss: 2.60740523315148
Validation loss: 2.7183456851047887

Epoch: 6| Step: 4
Training loss: 3.0633827027281497
Validation loss: 2.6771470197135483

Epoch: 6| Step: 5
Training loss: 2.3702171754120265
Validation loss: 2.7038337645633135

Epoch: 6| Step: 6
Training loss: 2.655332159899121
Validation loss: 2.663222179464601

Epoch: 6| Step: 7
Training loss: 2.434145257218588
Validation loss: 2.7589187708607263

Epoch: 6| Step: 8
Training loss: 2.0919739891317035
Validation loss: 2.7068443068651504

Epoch: 6| Step: 9
Training loss: 1.6387945227027032
Validation loss: 2.677519667476318

Epoch: 6| Step: 10
Training loss: 3.5022473613231577
Validation loss: 2.6925038469736333

Epoch: 6| Step: 11
Training loss: 2.932118132330851
Validation loss: 2.661874015779859

Epoch: 6| Step: 12
Training loss: 2.748846419006421
Validation loss: 2.6860585006256974

Epoch: 6| Step: 13
Training loss: 3.074551749704156
Validation loss: 2.7853025422056814

Epoch: 22| Step: 0
Training loss: 2.413396749699469
Validation loss: 2.690460186443321

Epoch: 6| Step: 1
Training loss: 2.728071696841098
Validation loss: 2.788160717925009

Epoch: 6| Step: 2
Training loss: 1.7593791846433915
Validation loss: 2.6511796317083776

Epoch: 6| Step: 3
Training loss: 2.733194325176541
Validation loss: 2.667612658037089

Epoch: 6| Step: 4
Training loss: 2.1540606897529977
Validation loss: 2.6778994601405053

Epoch: 6| Step: 5
Training loss: 2.574023782064483
Validation loss: 2.6569674252317577

Epoch: 6| Step: 6
Training loss: 2.7955047831282056
Validation loss: 2.673692899061259

Epoch: 6| Step: 7
Training loss: 3.4609220689554414
Validation loss: 2.720643009307586

Epoch: 6| Step: 8
Training loss: 3.4878582842149135
Validation loss: 2.6638696028305517

Epoch: 6| Step: 9
Training loss: 2.1336997844952847
Validation loss: 2.7738296159959526

Epoch: 6| Step: 10
Training loss: 2.977757011486667
Validation loss: 2.680830286427637

Epoch: 6| Step: 11
Training loss: 2.228743278249381
Validation loss: 2.7694537712849043

Epoch: 6| Step: 12
Training loss: 2.7111255239753262
Validation loss: 2.750127630450946

Epoch: 6| Step: 13
Training loss: 1.9645481380197023
Validation loss: 2.6745966978660847

Epoch: 23| Step: 0
Training loss: 2.0323351968952026
Validation loss: 2.69962379519056

Epoch: 6| Step: 1
Training loss: 2.0905632705584414
Validation loss: 2.6424934653709933

Epoch: 6| Step: 2
Training loss: 2.98106864201633
Validation loss: 2.649984217542759

Epoch: 6| Step: 3
Training loss: 2.5781325831446242
Validation loss: 2.651110415263625

Epoch: 6| Step: 4
Training loss: 2.460201286516659
Validation loss: 2.7251218033612568

Epoch: 6| Step: 5
Training loss: 2.7941096609845903
Validation loss: 2.690912829875106

Epoch: 6| Step: 6
Training loss: 2.6717871935955766
Validation loss: 2.7096255643055365

Epoch: 6| Step: 7
Training loss: 2.547420607088701
Validation loss: 2.64388668106791

Epoch: 6| Step: 8
Training loss: 2.9522936422795314
Validation loss: 2.773259811798504

Epoch: 6| Step: 9
Training loss: 2.156741321260168
Validation loss: 2.633253443588554

Epoch: 6| Step: 10
Training loss: 2.4951320938889365
Validation loss: 2.7546302078298703

Epoch: 6| Step: 11
Training loss: 2.424733990895749
Validation loss: 2.692029580923482

Epoch: 6| Step: 12
Training loss: 2.837012893609809
Validation loss: 2.612532846344708

Epoch: 6| Step: 13
Training loss: 2.768886733284743
Validation loss: 2.695943476585307

Epoch: 24| Step: 0
Training loss: 2.9612212435162215
Validation loss: 2.6676287753272376

Epoch: 6| Step: 1
Training loss: 2.6820046774405952
Validation loss: 2.6911326999736356

Epoch: 6| Step: 2
Training loss: 2.768356267691303
Validation loss: 2.620713738430258

Epoch: 6| Step: 3
Training loss: 2.5924083502965924
Validation loss: 2.7363299692689105

Epoch: 6| Step: 4
Training loss: 2.449877587977701
Validation loss: 2.605605213837116

Epoch: 6| Step: 5
Training loss: 3.371255139215079
Validation loss: 2.6931922718757795

Epoch: 6| Step: 6
Training loss: 2.144993911058725
Validation loss: 2.689749685432649

Epoch: 6| Step: 7
Training loss: 2.948690647564471
Validation loss: 2.6779563954596943

Epoch: 6| Step: 8
Training loss: 1.3268680683373595
Validation loss: 2.686100928287169

Epoch: 6| Step: 9
Training loss: 2.6192746167254524
Validation loss: 2.7260467857708286

Epoch: 6| Step: 10
Training loss: 2.204535283187669
Validation loss: 2.679855726946798

Epoch: 6| Step: 11
Training loss: 2.3391087672079514
Validation loss: 2.6475906443485386

Epoch: 6| Step: 12
Training loss: 2.4882207890086314
Validation loss: 2.6906637894171137

Epoch: 6| Step: 13
Training loss: 2.414258337873345
Validation loss: 2.695596991373664

Epoch: 25| Step: 0
Training loss: 2.0728610492957555
Validation loss: 2.663265522971679

Epoch: 6| Step: 1
Training loss: 3.17549415407407
Validation loss: 2.6779596895693434

Epoch: 6| Step: 2
Training loss: 2.574530482772747
Validation loss: 2.5959257475770356

Epoch: 6| Step: 3
Training loss: 2.606683313588144
Validation loss: 2.6363594318972217

Epoch: 6| Step: 4
Training loss: 2.1189368646639486
Validation loss: 2.652879311636254

Epoch: 6| Step: 5
Training loss: 2.8713946749185126
Validation loss: 2.631648356229231

Epoch: 6| Step: 6
Training loss: 3.131151477230742
Validation loss: 2.6659647991473108

Epoch: 6| Step: 7
Training loss: 2.8677214663189017
Validation loss: 2.6711767373624604

Epoch: 6| Step: 8
Training loss: 3.0753869596324055
Validation loss: 2.683591987946148

Epoch: 6| Step: 9
Training loss: 1.9178168397866462
Validation loss: 2.68492249784848

Epoch: 6| Step: 10
Training loss: 1.7862557462222102
Validation loss: 2.642504510373417

Epoch: 6| Step: 11
Training loss: 2.634093383361818
Validation loss: 2.690241236239685

Epoch: 6| Step: 12
Training loss: 2.741599864976856
Validation loss: 2.706961054256502

Epoch: 6| Step: 13
Training loss: 2.2633091106813414
Validation loss: 2.6469319283024286

Epoch: 26| Step: 0
Training loss: 2.576828046616583
Validation loss: 2.691331660284896

Epoch: 6| Step: 1
Training loss: 3.93177306269117
Validation loss: 2.5956295128328497

Epoch: 6| Step: 2
Training loss: 2.2030087704131116
Validation loss: 2.6836415026995684

Epoch: 6| Step: 3
Training loss: 2.62369177780506
Validation loss: 2.660881134170929

Epoch: 6| Step: 4
Training loss: 2.2642020130545797
Validation loss: 2.66012691233287

Epoch: 6| Step: 5
Training loss: 2.0012818043628022
Validation loss: 2.6956483935714846

Epoch: 6| Step: 6
Training loss: 2.8584463143517755
Validation loss: 2.6411564910940437

Epoch: 6| Step: 7
Training loss: 2.147063991884686
Validation loss: 2.635248688984861

Epoch: 6| Step: 8
Training loss: 2.3893079932194596
Validation loss: 2.6391864898807627

Epoch: 6| Step: 9
Training loss: 2.9483047787016923
Validation loss: 2.6841749425375774

Epoch: 6| Step: 10
Training loss: 2.291578452984506
Validation loss: 2.5899604245578067

Epoch: 6| Step: 11
Training loss: 2.6253325842021122
Validation loss: 2.7126612977151088

Epoch: 6| Step: 12
Training loss: 1.6480021692882074
Validation loss: 2.6626355030758893

Epoch: 6| Step: 13
Training loss: 2.254640879317578
Validation loss: 2.671264593584048

Epoch: 27| Step: 0
Training loss: 2.966654308879131
Validation loss: 2.6552132172587632

Epoch: 6| Step: 1
Training loss: 2.4232125803243383
Validation loss: 2.7011311404562544

Epoch: 6| Step: 2
Training loss: 2.208237795892464
Validation loss: 2.7051098836602163

Epoch: 6| Step: 3
Training loss: 2.520637777850857
Validation loss: 2.6094222226314643

Epoch: 6| Step: 4
Training loss: 2.7558055631816605
Validation loss: 2.6576683072598186

Epoch: 6| Step: 5
Training loss: 2.9144507755422944
Validation loss: 2.6170833737740233

Epoch: 6| Step: 6
Training loss: 2.6970600157535722
Validation loss: 2.6304179998747235

Epoch: 6| Step: 7
Training loss: 2.8546076153214424
Validation loss: 2.6089695826826618

Epoch: 6| Step: 8
Training loss: 2.871275105879368
Validation loss: 2.6623708475753567

Epoch: 6| Step: 9
Training loss: 1.4659983242852808
Validation loss: 2.677025157330986

Epoch: 6| Step: 10
Training loss: 2.4181786663285196
Validation loss: 2.6053617532656252

Epoch: 6| Step: 11
Training loss: 2.341803289027653
Validation loss: 2.6088272707672178

Epoch: 6| Step: 12
Training loss: 2.1058413825153615
Validation loss: 2.6294959938641163

Epoch: 6| Step: 13
Training loss: 2.5772309573753396
Validation loss: 2.68250702422432

Epoch: 28| Step: 0
Training loss: 2.5051900396386277
Validation loss: 2.5740078814152945

Epoch: 6| Step: 1
Training loss: 2.750129523261469
Validation loss: 2.616506732823395

Epoch: 6| Step: 2
Training loss: 2.5223985546873764
Validation loss: 2.648180518721894

Epoch: 6| Step: 3
Training loss: 3.327232993495552
Validation loss: 2.6721624922427023

Epoch: 6| Step: 4
Training loss: 1.567410344627738
Validation loss: 2.68546300768666

Epoch: 6| Step: 5
Training loss: 2.4029595803025634
Validation loss: 2.639937964153641

Epoch: 6| Step: 6
Training loss: 1.6298263476026653
Validation loss: 2.6979500070129516

Epoch: 6| Step: 7
Training loss: 2.618613876410195
Validation loss: 2.676440511827118

Epoch: 6| Step: 8
Training loss: 2.4797417003186184
Validation loss: 2.7108236356746076

Epoch: 6| Step: 9
Training loss: 2.525861491171479
Validation loss: 2.5984887799134597

Epoch: 6| Step: 10
Training loss: 2.810202274576626
Validation loss: 2.6423391312564886

Epoch: 6| Step: 11
Training loss: 2.707241826309912
Validation loss: 2.6997444167262072

Epoch: 6| Step: 12
Training loss: 2.3743578394033475
Validation loss: 2.646287448589848

Epoch: 6| Step: 13
Training loss: 2.710589735607865
Validation loss: 2.662892223475374

Epoch: 29| Step: 0
Training loss: 2.026866349476185
Validation loss: 2.6708242867525365

Epoch: 6| Step: 1
Training loss: 2.9648471274375527
Validation loss: 2.6838862645155634

Epoch: 6| Step: 2
Training loss: 2.758075215305056
Validation loss: 2.6195467208100554

Epoch: 6| Step: 3
Training loss: 2.605732459773356
Validation loss: 2.629750660776031

Epoch: 6| Step: 4
Training loss: 2.242594931133682
Validation loss: 2.6840182380018724

Epoch: 6| Step: 5
Training loss: 2.9059459568257116
Validation loss: 2.677152437339892

Epoch: 6| Step: 6
Training loss: 2.204482289475653
Validation loss: 2.6996224115809735

Epoch: 6| Step: 7
Training loss: 2.33635062452592
Validation loss: 2.5942236226617434

Epoch: 6| Step: 8
Training loss: 2.412403511924509
Validation loss: 2.53501936391624

Epoch: 6| Step: 9
Training loss: 2.8290865617590746
Validation loss: 2.6273169207708427

Epoch: 6| Step: 10
Training loss: 2.3735184314784394
Validation loss: 2.6066556759657056

Epoch: 6| Step: 11
Training loss: 2.7005106019304788
Validation loss: 2.599440020999767

Epoch: 6| Step: 12
Training loss: 2.487795604221494
Validation loss: 2.658887511121176

Epoch: 6| Step: 13
Training loss: 2.7388750811889295
Validation loss: 2.6048734748411544

Epoch: 30| Step: 0
Training loss: 2.6392470155832584
Validation loss: 2.610127353898373

Epoch: 6| Step: 1
Training loss: 2.8636650879425267
Validation loss: 2.5930065790159866

Epoch: 6| Step: 2
Training loss: 2.4147902691045875
Validation loss: 2.62171565569266

Epoch: 6| Step: 3
Training loss: 3.4502037430462384
Validation loss: 2.557140250038488

Epoch: 6| Step: 4
Training loss: 2.259073189274644
Validation loss: 2.661692276220149

Epoch: 6| Step: 5
Training loss: 2.351931419456135
Validation loss: 2.6617358387140158

Epoch: 6| Step: 6
Training loss: 2.370042545886365
Validation loss: 2.642270149428678

Epoch: 6| Step: 7
Training loss: 1.8512218821964057
Validation loss: 2.663755128790794

Epoch: 6| Step: 8
Training loss: 2.0621143327275124
Validation loss: 2.7269945212275237

Epoch: 6| Step: 9
Training loss: 2.6673055916528754
Validation loss: 2.7566725812784725

Epoch: 6| Step: 10
Training loss: 2.425054813040819
Validation loss: 2.6659167894387603

Epoch: 6| Step: 11
Training loss: 2.455683643381629
Validation loss: 2.673333794109403

Epoch: 6| Step: 12
Training loss: 3.1514342176497716
Validation loss: 2.695332358466812

Epoch: 6| Step: 13
Training loss: 2.8577727951703786
Validation loss: 2.6684231983121274

Epoch: 31| Step: 0
Training loss: 2.1157334180180083
Validation loss: 2.7402101870480045

Epoch: 6| Step: 1
Training loss: 2.2054052794428145
Validation loss: 2.761008826505467

Epoch: 6| Step: 2
Training loss: 2.0144231007342954
Validation loss: 2.6631285073347435

Epoch: 6| Step: 3
Training loss: 2.780984244347596
Validation loss: 2.619850966968653

Epoch: 6| Step: 4
Training loss: 2.617141131089939
Validation loss: 2.61734709751256

Epoch: 6| Step: 5
Training loss: 2.8515777169435594
Validation loss: 2.589316642902233

Epoch: 6| Step: 6
Training loss: 2.4317983798287925
Validation loss: 2.5948599619678743

Epoch: 6| Step: 7
Training loss: 1.9190732180456516
Validation loss: 2.6175234299090513

Epoch: 6| Step: 8
Training loss: 2.3216166828778597
Validation loss: 2.6936144801345145

Epoch: 6| Step: 9
Training loss: 2.1136199059316434
Validation loss: 2.568434596440847

Epoch: 6| Step: 10
Training loss: 2.627403249075397
Validation loss: 2.5948665008310177

Epoch: 6| Step: 11
Training loss: 2.5666125721205826
Validation loss: 2.6199851650322787

Epoch: 6| Step: 12
Training loss: 3.276420890720454
Validation loss: 2.6488606612819336

Epoch: 6| Step: 13
Training loss: 2.6865052444801565
Validation loss: 2.5859122529578924

Epoch: 32| Step: 0
Training loss: 2.490477354873792
Validation loss: 2.666974233731945

Epoch: 6| Step: 1
Training loss: 2.7876418312836937
Validation loss: 2.70275770569584

Epoch: 6| Step: 2
Training loss: 2.2625369369273716
Validation loss: 2.698603087386199

Epoch: 6| Step: 3
Training loss: 2.6758903091369803
Validation loss: 2.688514798806185

Epoch: 6| Step: 4
Training loss: 2.8402433468432084
Validation loss: 2.6504519742922685

Epoch: 6| Step: 5
Training loss: 2.3277903066625205
Validation loss: 2.65403081904582

Epoch: 6| Step: 6
Training loss: 2.9706950993275876
Validation loss: 2.608924392808004

Epoch: 6| Step: 7
Training loss: 3.038597247836262
Validation loss: 2.6557312402731466

Epoch: 6| Step: 8
Training loss: 1.973464830319552
Validation loss: 2.650397911427208

Epoch: 6| Step: 9
Training loss: 2.425850834977198
Validation loss: 2.627568509654188

Epoch: 6| Step: 10
Training loss: 2.3753771231539993
Validation loss: 2.5899448595596564

Epoch: 6| Step: 11
Training loss: 1.9650235103336398
Validation loss: 2.6635184082002388

Epoch: 6| Step: 12
Training loss: 2.007286269994455
Validation loss: 2.604278826523474

Epoch: 6| Step: 13
Training loss: 2.8791142754726615
Validation loss: 2.6864610926148136

Epoch: 33| Step: 0
Training loss: 2.875629356163753
Validation loss: 2.5929077496794948

Epoch: 6| Step: 1
Training loss: 2.283917996345749
Validation loss: 2.6724043948157132

Epoch: 6| Step: 2
Training loss: 2.8836036981676134
Validation loss: 2.638296978359239

Epoch: 6| Step: 3
Training loss: 1.7804712299699572
Validation loss: 2.5774038057479296

Epoch: 6| Step: 4
Training loss: 2.433883723193724
Validation loss: 2.6630983220646973

Epoch: 6| Step: 5
Training loss: 2.276210286916319
Validation loss: 2.740758692091451

Epoch: 6| Step: 6
Training loss: 2.0733976588844882
Validation loss: 2.6017754117276293

Epoch: 6| Step: 7
Training loss: 2.6716294203660853
Validation loss: 2.6201470793143233

Epoch: 6| Step: 8
Training loss: 1.8040000630101702
Validation loss: 2.6650360804459923

Epoch: 6| Step: 9
Training loss: 2.9681360513397452
Validation loss: 2.5973419687700683

Epoch: 6| Step: 10
Training loss: 3.0971392937369755
Validation loss: 2.698712034089456

Epoch: 6| Step: 11
Training loss: 1.8740710818469677
Validation loss: 2.6245203942443824

Epoch: 6| Step: 12
Training loss: 2.5210189330658475
Validation loss: 2.6496032429828085

Epoch: 6| Step: 13
Training loss: 2.752416416045969
Validation loss: 2.5494771664500875

Epoch: 34| Step: 0
Training loss: 3.0478066609456844
Validation loss: 2.6238277633505454

Epoch: 6| Step: 1
Training loss: 1.9464790492680628
Validation loss: 2.6188825441744967

Epoch: 6| Step: 2
Training loss: 2.6054468797397794
Validation loss: 2.6024487487505397

Epoch: 6| Step: 3
Training loss: 3.0280493129408517
Validation loss: 2.6838824150681013

Epoch: 6| Step: 4
Training loss: 2.267138482056195
Validation loss: 2.6082805843524195

Epoch: 6| Step: 5
Training loss: 2.3041844740369783
Validation loss: 2.636946544461756

Epoch: 6| Step: 6
Training loss: 1.5953775211425794
Validation loss: 2.6549356911480504

Epoch: 6| Step: 7
Training loss: 2.1689578437700807
Validation loss: 2.636795035306568

Epoch: 6| Step: 8
Training loss: 2.703568085975978
Validation loss: 2.624641272844069

Epoch: 6| Step: 9
Training loss: 2.30992725670624
Validation loss: 2.646470557595531

Epoch: 6| Step: 10
Training loss: 2.744026284873233
Validation loss: 2.612156434412731

Epoch: 6| Step: 11
Training loss: 2.074971035674754
Validation loss: 2.649074586594185

Epoch: 6| Step: 12
Training loss: 2.6356098471141047
Validation loss: 2.615244828598102

Epoch: 6| Step: 13
Training loss: 2.9705551281141105
Validation loss: 2.617960209435557

Epoch: 35| Step: 0
Training loss: 2.340491814892202
Validation loss: 2.5907040984652507

Epoch: 6| Step: 1
Training loss: 2.4038029898656244
Validation loss: 2.586196748121673

Epoch: 6| Step: 2
Training loss: 2.58360245030971
Validation loss: 2.646264684363388

Epoch: 6| Step: 3
Training loss: 2.568669776870398
Validation loss: 2.62306008485908

Epoch: 6| Step: 4
Training loss: 2.823762511233661
Validation loss: 2.617898159428172

Epoch: 6| Step: 5
Training loss: 1.7539787022636235
Validation loss: 2.6141030806458194

Epoch: 6| Step: 6
Training loss: 2.4138392866818434
Validation loss: 2.6265118952801987

Epoch: 6| Step: 7
Training loss: 2.5887518835129972
Validation loss: 2.545443602624611

Epoch: 6| Step: 8
Training loss: 2.4090899267898047
Validation loss: 2.5686087638347654

Epoch: 6| Step: 9
Training loss: 2.153145587086357
Validation loss: 2.582790861291045

Epoch: 6| Step: 10
Training loss: 2.5461102607147232
Validation loss: 2.5707856025984324

Epoch: 6| Step: 11
Training loss: 1.972537741547787
Validation loss: 2.6670742667143945

Epoch: 6| Step: 12
Training loss: 2.313802506950023
Validation loss: 2.6299217647137754

Epoch: 6| Step: 13
Training loss: 3.446626788805756
Validation loss: 2.638856095952404

Epoch: 36| Step: 0
Training loss: 2.213996631016705
Validation loss: 2.6072802101540926

Epoch: 6| Step: 1
Training loss: 2.0626363998161867
Validation loss: 2.7296294822124434

Epoch: 6| Step: 2
Training loss: 2.7238036793167515
Validation loss: 2.6052509695349695

Epoch: 6| Step: 3
Training loss: 2.610809388775876
Validation loss: 2.599000694729814

Epoch: 6| Step: 4
Training loss: 1.891577614636096
Validation loss: 2.6584137425075403

Epoch: 6| Step: 5
Training loss: 2.6295719295861506
Validation loss: 2.5739120431893223

Epoch: 6| Step: 6
Training loss: 2.1353080039561116
Validation loss: 2.6177582227631015

Epoch: 6| Step: 7
Training loss: 2.841719856398328
Validation loss: 2.5328172768781747

Epoch: 6| Step: 8
Training loss: 3.2631179458199973
Validation loss: 2.5596534922160115

Epoch: 6| Step: 9
Training loss: 3.331996331697164
Validation loss: 2.617365831970436

Epoch: 6| Step: 10
Training loss: 2.1143604280092005
Validation loss: 2.627620569687688

Epoch: 6| Step: 11
Training loss: 2.4602072949412275
Validation loss: 2.5638715283527187

Epoch: 6| Step: 12
Training loss: 1.9938677714132327
Validation loss: 2.634912093238606

Epoch: 6| Step: 13
Training loss: 2.514798046216999
Validation loss: 2.6620772376841275

Epoch: 37| Step: 0
Training loss: 2.2480099672524165
Validation loss: 2.6637798767228316

Epoch: 6| Step: 1
Training loss: 2.2722601185037283
Validation loss: 2.6620271277742344

Epoch: 6| Step: 2
Training loss: 2.419140459427473
Validation loss: 2.6628550667328796

Epoch: 6| Step: 3
Training loss: 2.591360715202097
Validation loss: 2.7161479058750007

Epoch: 6| Step: 4
Training loss: 3.127810320808169
Validation loss: 2.589232789361568

Epoch: 6| Step: 5
Training loss: 2.5187750576088606
Validation loss: 2.535450687561562

Epoch: 6| Step: 6
Training loss: 2.179756190813918
Validation loss: 2.6707215524294106

Epoch: 6| Step: 7
Training loss: 3.1689725477932105
Validation loss: 2.5795514254742153

Epoch: 6| Step: 8
Training loss: 2.26150643467246
Validation loss: 2.560729725640353

Epoch: 6| Step: 9
Training loss: 2.285178159951054
Validation loss: 2.634180628498089

Epoch: 6| Step: 10
Training loss: 2.8413600730133024
Validation loss: 2.5746245693845946

Epoch: 6| Step: 11
Training loss: 2.622324715603028
Validation loss: 2.6189444418912426

Epoch: 6| Step: 12
Training loss: 2.312383391043551
Validation loss: 2.6176683581986477

Epoch: 6| Step: 13
Training loss: 2.797911723556943
Validation loss: 2.655321400209098

Epoch: 38| Step: 0
Training loss: 2.8026100902049333
Validation loss: 2.597770699869475

Epoch: 6| Step: 1
Training loss: 1.9172045395271906
Validation loss: 2.6278784879329753

Epoch: 6| Step: 2
Training loss: 2.7657306888019586
Validation loss: 2.6677478346953043

Epoch: 6| Step: 3
Training loss: 2.909970107301899
Validation loss: 2.6322413427757803

Epoch: 6| Step: 4
Training loss: 2.1029586975641936
Validation loss: 2.66395224066186

Epoch: 6| Step: 5
Training loss: 2.5053391663668005
Validation loss: 2.6715346894850893

Epoch: 6| Step: 6
Training loss: 2.30778972224499
Validation loss: 2.633849802755993

Epoch: 6| Step: 7
Training loss: 2.2306638188082677
Validation loss: 2.6724228399549346

Epoch: 6| Step: 8
Training loss: 2.8249234788371527
Validation loss: 2.652220568186516

Epoch: 6| Step: 9
Training loss: 2.853431068541001
Validation loss: 2.6188248404382533

Epoch: 6| Step: 10
Training loss: 2.5176082399163744
Validation loss: 2.602257957330766

Epoch: 6| Step: 11
Training loss: 2.734540487458774
Validation loss: 2.689532169610853

Epoch: 6| Step: 12
Training loss: 1.7045494911839632
Validation loss: 2.668074814720704

Epoch: 6| Step: 13
Training loss: 2.0889685393539668
Validation loss: 2.6989063426263455

Epoch: 39| Step: 0
Training loss: 2.394614885621371
Validation loss: 2.661334792005194

Epoch: 6| Step: 1
Training loss: 2.051237161004557
Validation loss: 2.6434438132841165

Epoch: 6| Step: 2
Training loss: 1.9144013396869377
Validation loss: 2.630122726608417

Epoch: 6| Step: 3
Training loss: 2.8498419600721188
Validation loss: 2.6274483933539323

Epoch: 6| Step: 4
Training loss: 2.824894530091369
Validation loss: 2.5994951054435935

Epoch: 6| Step: 5
Training loss: 2.6375367654705753
Validation loss: 2.5851567022147024

Epoch: 6| Step: 6
Training loss: 2.433982756798882
Validation loss: 2.642217062121715

Epoch: 6| Step: 7
Training loss: 2.2730409466419834
Validation loss: 2.5852506710826657

Epoch: 6| Step: 8
Training loss: 2.2653017010709635
Validation loss: 2.56837221633157

Epoch: 6| Step: 9
Training loss: 2.0881197940107277
Validation loss: 2.624719907561533

Epoch: 6| Step: 10
Training loss: 2.6806889656174775
Validation loss: 2.6538677079145168

Epoch: 6| Step: 11
Training loss: 2.707556295188296
Validation loss: 2.5988619575647207

Epoch: 6| Step: 12
Training loss: 2.72431201474323
Validation loss: 2.677333869541097

Epoch: 6| Step: 13
Training loss: 2.5352391962668133
Validation loss: 2.5858724995076066

Epoch: 40| Step: 0
Training loss: 2.352893946678517
Validation loss: 2.5860906826413887

Epoch: 6| Step: 1
Training loss: 2.288571666392992
Validation loss: 2.643652344952471

Epoch: 6| Step: 2
Training loss: 2.4930232927601437
Validation loss: 2.6491270789850145

Epoch: 6| Step: 3
Training loss: 2.2365752370977217
Validation loss: 2.555291511766992

Epoch: 6| Step: 4
Training loss: 3.1775915187618784
Validation loss: 2.6864957781446774

Epoch: 6| Step: 5
Training loss: 2.4199112344651055
Validation loss: 2.6879525801585773

Epoch: 6| Step: 6
Training loss: 2.1529402832169184
Validation loss: 2.6910180567184376

Epoch: 6| Step: 7
Training loss: 2.91086924990441
Validation loss: 2.6390071178743586

Epoch: 6| Step: 8
Training loss: 1.9075723032915832
Validation loss: 2.6551921907345526

Epoch: 6| Step: 9
Training loss: 2.3733159167832953
Validation loss: 2.624900891688587

Epoch: 6| Step: 10
Training loss: 1.9790363737351808
Validation loss: 2.6209134429753007

Epoch: 6| Step: 11
Training loss: 2.6855330255324708
Validation loss: 2.674745545807583

Epoch: 6| Step: 12
Training loss: 2.3167926022263963
Validation loss: 2.533502800715005

Epoch: 6| Step: 13
Training loss: 2.7768191071422503
Validation loss: 2.6093586142628924

Epoch: 41| Step: 0
Training loss: 1.8399919259889344
Validation loss: 2.6458197215373414

Epoch: 6| Step: 1
Training loss: 2.631011437408978
Validation loss: 2.611421281460175

Epoch: 6| Step: 2
Training loss: 2.7061609407708027
Validation loss: 2.644140563084196

Epoch: 6| Step: 3
Training loss: 1.9107484114162534
Validation loss: 2.5953064350606203

Epoch: 6| Step: 4
Training loss: 2.9112712183531655
Validation loss: 2.641573259786091

Epoch: 6| Step: 5
Training loss: 2.0754285254985594
Validation loss: 2.6185868503001575

Epoch: 6| Step: 6
Training loss: 2.659305386018762
Validation loss: 2.6079865071682904

Epoch: 6| Step: 7
Training loss: 2.1601818559174055
Validation loss: 2.701525117326112

Epoch: 6| Step: 8
Training loss: 2.915097132221018
Validation loss: 2.616466411492349

Epoch: 6| Step: 9
Training loss: 3.0237330408081986
Validation loss: 2.584579080244746

Epoch: 6| Step: 10
Training loss: 2.6143773720967847
Validation loss: 2.567015306111855

Epoch: 6| Step: 11
Training loss: 2.197803319626826
Validation loss: 2.5264633351125463

Epoch: 6| Step: 12
Training loss: 2.5613370908318753
Validation loss: 2.6912793635709384

Epoch: 6| Step: 13
Training loss: 2.3965776918083703
Validation loss: 2.635619631906467

Epoch: 42| Step: 0
Training loss: 2.2622432331207847
Validation loss: 2.5965321338589025

Epoch: 6| Step: 1
Training loss: 1.6210412442080504
Validation loss: 2.6089640920099724

Epoch: 6| Step: 2
Training loss: 2.532090224226911
Validation loss: 2.6764217454756163

Epoch: 6| Step: 3
Training loss: 2.5461102607147232
Validation loss: 2.7229171766549656

Epoch: 6| Step: 4
Training loss: 2.761891835790055
Validation loss: 2.5935285389432345

Epoch: 6| Step: 5
Training loss: 3.44849205786305
Validation loss: 2.753920686291672

Epoch: 6| Step: 6
Training loss: 1.8834718048480559
Validation loss: 2.659880023941933

Epoch: 6| Step: 7
Training loss: 1.6781784731054694
Validation loss: 2.6228954113338143

Epoch: 6| Step: 8
Training loss: 2.4891133736046887
Validation loss: 2.5543648207831673

Epoch: 6| Step: 9
Training loss: 1.8525924715136444
Validation loss: 2.6146238914069517

Epoch: 6| Step: 10
Training loss: 3.563875702374124
Validation loss: 2.644019674220254

Epoch: 6| Step: 11
Training loss: 2.4220866449231613
Validation loss: 2.670373528208928

Epoch: 6| Step: 12
Training loss: 2.2747365903843777
Validation loss: 2.5694825476034984

Epoch: 6| Step: 13
Training loss: 2.7466366748036526
Validation loss: 2.6104674726830788

Epoch: 43| Step: 0
Training loss: 1.918924004434019
Validation loss: 2.6278395810385557

Epoch: 6| Step: 1
Training loss: 2.3106736884380057
Validation loss: 2.6140231992781238

Epoch: 6| Step: 2
Training loss: 2.6084899315020946
Validation loss: 2.5981570265460587

Epoch: 6| Step: 3
Training loss: 2.0986116815624167
Validation loss: 2.551434155374508

Epoch: 6| Step: 4
Training loss: 2.5669957243137396
Validation loss: 2.610831411973636

Epoch: 6| Step: 5
Training loss: 2.3451215672652634
Validation loss: 2.6635388319238866

Epoch: 6| Step: 6
Training loss: 2.530363610566368
Validation loss: 2.622882276394924

Epoch: 6| Step: 7
Training loss: 2.9690728263004895
Validation loss: 2.6320372212569545

Epoch: 6| Step: 8
Training loss: 2.893247826919788
Validation loss: 2.591669734470559

Epoch: 6| Step: 9
Training loss: 3.029611990480994
Validation loss: 2.5121355991322467

Epoch: 6| Step: 10
Training loss: 1.9966946945813075
Validation loss: 2.6042747144536795

Epoch: 6| Step: 11
Training loss: 2.678334331009811
Validation loss: 2.511351531352772

Epoch: 6| Step: 12
Training loss: 1.6759764373142652
Validation loss: 2.6340657165389434

Epoch: 6| Step: 13
Training loss: 2.796551648420593
Validation loss: 2.6802590282482526

Epoch: 44| Step: 0
Training loss: 1.9432109220151488
Validation loss: 2.6506861440197533

Epoch: 6| Step: 1
Training loss: 1.9107571458274886
Validation loss: 2.601376989889237

Epoch: 6| Step: 2
Training loss: 2.6381988214296554
Validation loss: 2.6006950176958767

Epoch: 6| Step: 3
Training loss: 3.1479328214852336
Validation loss: 2.57428722454531

Epoch: 6| Step: 4
Training loss: 1.913801837221584
Validation loss: 2.5903025930771073

Epoch: 6| Step: 5
Training loss: 2.271875743000061
Validation loss: 2.6070547238288517

Epoch: 6| Step: 6
Training loss: 2.9924279656659585
Validation loss: 2.5878393703159417

Epoch: 6| Step: 7
Training loss: 2.9490522122888336
Validation loss: 2.5885075209352815

Epoch: 6| Step: 8
Training loss: 2.418950733460569
Validation loss: 2.6742360649324723

Epoch: 6| Step: 9
Training loss: 2.634900812819336
Validation loss: 2.638358661576624

Epoch: 6| Step: 10
Training loss: 1.8990913175750697
Validation loss: 2.6098618196031924

Epoch: 6| Step: 11
Training loss: 2.18136543034083
Validation loss: 2.6165430898298387

Epoch: 6| Step: 12
Training loss: 2.3273533303895
Validation loss: 2.582189496414402

Epoch: 6| Step: 13
Training loss: 2.667572394177885
Validation loss: 2.593765320024096

Epoch: 45| Step: 0
Training loss: 1.6607009532645263
Validation loss: 2.589933858908193

Epoch: 6| Step: 1
Training loss: 3.110020556121305
Validation loss: 2.5902083549253034

Epoch: 6| Step: 2
Training loss: 2.039020640210298
Validation loss: 2.6401898027354362

Epoch: 6| Step: 3
Training loss: 2.537506377865147
Validation loss: 2.5486721882675085

Epoch: 6| Step: 4
Training loss: 1.7077529743287627
Validation loss: 2.6101644696073216

Epoch: 6| Step: 5
Training loss: 3.053180293477603
Validation loss: 2.615454210837698

Epoch: 6| Step: 6
Training loss: 2.091008683422417
Validation loss: 2.610451147080587

Epoch: 6| Step: 7
Training loss: 2.0704147601513894
Validation loss: 2.563673603538354

Epoch: 6| Step: 8
Training loss: 2.5999875728603628
Validation loss: 2.594346433644763

Epoch: 6| Step: 9
Training loss: 3.145733374887539
Validation loss: 2.571859495194252

Epoch: 6| Step: 10
Training loss: 2.2294902626059363
Validation loss: 2.5933825067828353

Epoch: 6| Step: 11
Training loss: 2.602710917168322
Validation loss: 2.63868142254973

Epoch: 6| Step: 12
Training loss: 2.4946842900517994
Validation loss: 2.549899483862556

Epoch: 6| Step: 13
Training loss: 2.266393807293867
Validation loss: 2.5798074954317265

Epoch: 46| Step: 0
Training loss: 2.3042074447067886
Validation loss: 2.5950693046022653

Epoch: 6| Step: 1
Training loss: 1.8153462916647305
Validation loss: 2.6284984406463057

Epoch: 6| Step: 2
Training loss: 2.836418342285068
Validation loss: 2.6982895557849256

Epoch: 6| Step: 3
Training loss: 2.5705544030354317
Validation loss: 2.642350658129283

Epoch: 6| Step: 4
Training loss: 2.3080942610825046
Validation loss: 2.6980118581310015

Epoch: 6| Step: 5
Training loss: 2.4042000894410513
Validation loss: 2.6343919674291865

Epoch: 6| Step: 6
Training loss: 2.2737011314203044
Validation loss: 2.6927466964694333

Epoch: 6| Step: 7
Training loss: 3.2057740213255306
Validation loss: 2.625716770042117

Epoch: 6| Step: 8
Training loss: 3.0292970324085227
Validation loss: 2.620316793445458

Epoch: 6| Step: 9
Training loss: 1.7787281722916324
Validation loss: 2.5850672337921323

Epoch: 6| Step: 10
Training loss: 2.3360742637378293
Validation loss: 2.59612937165812

Epoch: 6| Step: 11
Training loss: 2.5803396249837407
Validation loss: 2.6419670561951194

Epoch: 6| Step: 12
Training loss: 2.6113620889947198
Validation loss: 2.6464529188100188

Epoch: 6| Step: 13
Training loss: 2.279796712245155
Validation loss: 2.641392643271144

Epoch: 47| Step: 0
Training loss: 2.140400895688164
Validation loss: 2.5825393030721595

Epoch: 6| Step: 1
Training loss: 1.9407005946475067
Validation loss: 2.5605017926990086

Epoch: 6| Step: 2
Training loss: 2.6173205896955736
Validation loss: 2.5605877820395917

Epoch: 6| Step: 3
Training loss: 2.6213036806997763
Validation loss: 2.5760947045525975

Epoch: 6| Step: 4
Training loss: 2.268065722971506
Validation loss: 2.632564038665781

Epoch: 6| Step: 5
Training loss: 2.4572134753943677
Validation loss: 2.691604909591895

Epoch: 6| Step: 6
Training loss: 2.277525068494762
Validation loss: 2.565016727925881

Epoch: 6| Step: 7
Training loss: 2.3641924654073256
Validation loss: 2.5873978900265184

Epoch: 6| Step: 8
Training loss: 2.5725877888846775
Validation loss: 2.524800714805572

Epoch: 6| Step: 9
Training loss: 3.033930743428467
Validation loss: 2.531512313563184

Epoch: 6| Step: 10
Training loss: 2.892730935520935
Validation loss: 2.6298280019203437

Epoch: 6| Step: 11
Training loss: 2.6170823716642326
Validation loss: 2.5808223293103927

Epoch: 6| Step: 12
Training loss: 2.252992864747311
Validation loss: 2.620724291471243

Epoch: 6| Step: 13
Training loss: 2.3087763318768593
Validation loss: 2.5847236112189678

Epoch: 48| Step: 0
Training loss: 2.9430298396110124
Validation loss: 2.6084213798539433

Epoch: 6| Step: 1
Training loss: 2.763584310809142
Validation loss: 2.6076279690905113

Epoch: 6| Step: 2
Training loss: 2.608789252592267
Validation loss: 2.5618140690458326

Epoch: 6| Step: 3
Training loss: 2.3873585843850544
Validation loss: 2.6070984600527156

Epoch: 6| Step: 4
Training loss: 2.465375114513252
Validation loss: 2.5613480901916907

Epoch: 6| Step: 5
Training loss: 2.0997808342055078
Validation loss: 2.6592274900976

Epoch: 6| Step: 6
Training loss: 3.0529005672932255
Validation loss: 2.632087690760323

Epoch: 6| Step: 7
Training loss: 2.418350904397821
Validation loss: 2.606102861966789

Epoch: 6| Step: 8
Training loss: 1.7708497514150634
Validation loss: 2.6368933650466246

Epoch: 6| Step: 9
Training loss: 1.8338011303763702
Validation loss: 2.6483833810083675

Epoch: 6| Step: 10
Training loss: 2.0480242116584724
Validation loss: 2.579165963299665

Epoch: 6| Step: 11
Training loss: 2.1626952772227486
Validation loss: 2.624157013336804

Epoch: 6| Step: 12
Training loss: 2.788711824997933
Validation loss: 2.6187766038124476

Epoch: 6| Step: 13
Training loss: 2.6934055825101746
Validation loss: 2.6269371060588496

Epoch: 49| Step: 0
Training loss: 2.9940899809195405
Validation loss: 2.5946616596704195

Epoch: 6| Step: 1
Training loss: 2.4170267121902906
Validation loss: 2.6771847202284667

Epoch: 6| Step: 2
Training loss: 2.8477172007794653
Validation loss: 2.5981463818423136

Epoch: 6| Step: 3
Training loss: 1.8814890155213089
Validation loss: 2.659565729816772

Epoch: 6| Step: 4
Training loss: 2.1468837599041173
Validation loss: 2.5406522811169414

Epoch: 6| Step: 5
Training loss: 2.578558498119183
Validation loss: 2.6490375360450615

Epoch: 6| Step: 6
Training loss: 3.11485842167193
Validation loss: 2.596921949884108

Epoch: 6| Step: 7
Training loss: 2.4963942273785142
Validation loss: 2.606993816542526

Epoch: 6| Step: 8
Training loss: 1.8775695995124078
Validation loss: 2.543728935035758

Epoch: 6| Step: 9
Training loss: 1.8298609389953082
Validation loss: 2.6114015304987492

Epoch: 6| Step: 10
Training loss: 2.0480842803734762
Validation loss: 2.5890286151983837

Epoch: 6| Step: 11
Training loss: 2.8513369118281022
Validation loss: 2.532390274854139

Epoch: 6| Step: 12
Training loss: 2.037621233557128
Validation loss: 2.5087412444403654

Epoch: 6| Step: 13
Training loss: 2.2650168819514134
Validation loss: 2.519070763116353

Epoch: 50| Step: 0
Training loss: 2.3213906400327353
Validation loss: 2.540109224974713

Epoch: 6| Step: 1
Training loss: 2.7028690283089736
Validation loss: 2.608694722629234

Epoch: 6| Step: 2
Training loss: 2.0890797011609523
Validation loss: 2.681575484479068

Epoch: 6| Step: 3
Training loss: 1.7346703905001604
Validation loss: 2.6647407809326276

Epoch: 6| Step: 4
Training loss: 2.839663409314252
Validation loss: 2.705252954592171

Epoch: 6| Step: 5
Training loss: 2.7443336717573024
Validation loss: 2.618058093064414

Epoch: 6| Step: 6
Training loss: 2.5095100718020786
Validation loss: 2.6472472870707415

Epoch: 6| Step: 7
Training loss: 1.7538964625979698
Validation loss: 2.7405548307105665

Epoch: 6| Step: 8
Training loss: 3.0475175228976394
Validation loss: 2.7052434804163497

Epoch: 6| Step: 9
Training loss: 2.6515803860818097
Validation loss: 2.676052315526088

Epoch: 6| Step: 10
Training loss: 2.8708773369224234
Validation loss: 2.610988795569681

Epoch: 6| Step: 11
Training loss: 3.07111082302754
Validation loss: 2.593815921420657

Epoch: 6| Step: 12
Training loss: 1.5336339648935617
Validation loss: 2.6211152319826114

Epoch: 6| Step: 13
Training loss: 2.0403169595158706
Validation loss: 2.550492368174062

Epoch: 51| Step: 0
Training loss: 2.646257701893204
Validation loss: 2.600049530682357

Epoch: 6| Step: 1
Training loss: 2.532956148812419
Validation loss: 2.6519561469382578

Epoch: 6| Step: 2
Training loss: 2.2256632812772863
Validation loss: 2.6401265593739476

Epoch: 6| Step: 3
Training loss: 2.847977733910777
Validation loss: 2.6297081852637856

Epoch: 6| Step: 4
Training loss: 2.6746464682862596
Validation loss: 2.60121560289847

Epoch: 6| Step: 5
Training loss: 2.521038982315427
Validation loss: 2.682393952922412

Epoch: 6| Step: 6
Training loss: 3.2003428215927454
Validation loss: 2.6523182661267692

Epoch: 6| Step: 7
Training loss: 2.583530377492353
Validation loss: 2.6378120322156073

Epoch: 6| Step: 8
Training loss: 2.335075908464437
Validation loss: 2.6022477111532702

Epoch: 6| Step: 9
Training loss: 2.264290146739553
Validation loss: 2.638699237522551

Epoch: 6| Step: 10
Training loss: 1.7962325564753965
Validation loss: 2.5609609277354575

Epoch: 6| Step: 11
Training loss: 2.445625845725939
Validation loss: 2.604554724708323

Epoch: 6| Step: 12
Training loss: 2.5829234464601227
Validation loss: 2.5981797228664636

Epoch: 6| Step: 13
Training loss: 2.1647005207941725
Validation loss: 2.6890271305859113

Epoch: 52| Step: 0
Training loss: 2.736417694041728
Validation loss: 2.630994959874861

Epoch: 6| Step: 1
Training loss: 2.222199458429516
Validation loss: 2.7889800215350133

Epoch: 6| Step: 2
Training loss: 2.6131750521443093
Validation loss: 2.7289532488206647

Epoch: 6| Step: 3
Training loss: 3.6541443328580887
Validation loss: 2.8399278155184056

Epoch: 6| Step: 4
Training loss: 3.011992327068632
Validation loss: 2.689845008343836

Epoch: 6| Step: 5
Training loss: 2.5708837367165445
Validation loss: 2.6673290552567233

Epoch: 6| Step: 6
Training loss: 2.5366859934401
Validation loss: 2.616339611663977

Epoch: 6| Step: 7
Training loss: 1.9301143282297661
Validation loss: 2.619122221842

Epoch: 6| Step: 8
Training loss: 2.244142112366239
Validation loss: 2.562826554495113

Epoch: 6| Step: 9
Training loss: 1.8344262578973982
Validation loss: 2.632308428738272

Epoch: 6| Step: 10
Training loss: 2.8206942397684114
Validation loss: 2.6023653030839053

Epoch: 6| Step: 11
Training loss: 1.933404223468777
Validation loss: 2.533142387154146

Epoch: 6| Step: 12
Training loss: 2.4146410795014983
Validation loss: 2.599173945247255

Epoch: 6| Step: 13
Training loss: 2.2179259798307194
Validation loss: 2.552582693226944

Epoch: 53| Step: 0
Training loss: 3.296548257699899
Validation loss: 2.5332249130923787

Epoch: 6| Step: 1
Training loss: 2.2868681404988807
Validation loss: 2.517192375988207

Epoch: 6| Step: 2
Training loss: 2.9828271496804177
Validation loss: 2.6624037723733087

Epoch: 6| Step: 3
Training loss: 2.534017298205073
Validation loss: 2.5788485658009583

Epoch: 6| Step: 4
Training loss: 2.4339955887515514
Validation loss: 2.589475794487843

Epoch: 6| Step: 5
Training loss: 2.5528307592266875
Validation loss: 2.5953664836440367

Epoch: 6| Step: 6
Training loss: 2.3806873287535257
Validation loss: 2.547746255769007

Epoch: 6| Step: 7
Training loss: 2.1728820661482464
Validation loss: 2.5937517464873165

Epoch: 6| Step: 8
Training loss: 2.537113697732557
Validation loss: 2.597303017522903

Epoch: 6| Step: 9
Training loss: 2.231660487779188
Validation loss: 2.577231327413673

Epoch: 6| Step: 10
Training loss: 1.9564882541638298
Validation loss: 2.5631547417039484

Epoch: 6| Step: 11
Training loss: 2.31904356709853
Validation loss: 2.624341942788755

Epoch: 6| Step: 12
Training loss: 2.7403043274437304
Validation loss: 2.54410215591108

Epoch: 6| Step: 13
Training loss: 1.8940306955929698
Validation loss: 2.570563051945983

Epoch: 54| Step: 0
Training loss: 2.7172537007529076
Validation loss: 2.6268633329604496

Epoch: 6| Step: 1
Training loss: 2.381507791497209
Validation loss: 2.6375158164829213

Epoch: 6| Step: 2
Training loss: 2.376110319299422
Validation loss: 2.724882787114256

Epoch: 6| Step: 3
Training loss: 2.9504582711859806
Validation loss: 2.7142263757940666

Epoch: 6| Step: 4
Training loss: 2.367032590524882
Validation loss: 2.606397121189269

Epoch: 6| Step: 5
Training loss: 2.673114778982105
Validation loss: 2.5789008158129896

Epoch: 6| Step: 6
Training loss: 2.968034999476535
Validation loss: 2.565818157970934

Epoch: 6| Step: 7
Training loss: 2.5480918551645577
Validation loss: 2.6022896881580557

Epoch: 6| Step: 8
Training loss: 2.918167454747125
Validation loss: 2.5480648919879445

Epoch: 6| Step: 9
Training loss: 2.005625323910448
Validation loss: 2.532679919209274

Epoch: 6| Step: 10
Training loss: 2.0294883718446473
Validation loss: 2.5235132259190856

Epoch: 6| Step: 11
Training loss: 1.9415693924513064
Validation loss: 2.5603382792836245

Epoch: 6| Step: 12
Training loss: 1.9993806118303574
Validation loss: 2.5498804874712375

Epoch: 6| Step: 13
Training loss: 2.55698508440366
Validation loss: 2.593935641956803

Epoch: 55| Step: 0
Training loss: 2.5316854973553746
Validation loss: 2.569472619208665

Epoch: 6| Step: 1
Training loss: 2.9403010872015196
Validation loss: 2.5124667543454344

Epoch: 6| Step: 2
Training loss: 2.2596405970638718
Validation loss: 2.64100621648748

Epoch: 6| Step: 3
Training loss: 1.8976436258071234
Validation loss: 2.5909855216321245

Epoch: 6| Step: 4
Training loss: 1.8995350620199833
Validation loss: 2.60699252095166

Epoch: 6| Step: 5
Training loss: 2.123907593823717
Validation loss: 2.5836962680799984

Epoch: 6| Step: 6
Training loss: 1.8297604149705604
Validation loss: 2.6017756866382524

Epoch: 6| Step: 7
Training loss: 2.2964807288758475
Validation loss: 2.6570364367568926

Epoch: 6| Step: 8
Training loss: 3.0197693803659416
Validation loss: 2.655838668988648

Epoch: 6| Step: 9
Training loss: 2.394585613486171
Validation loss: 2.5695030460605603

Epoch: 6| Step: 10
Training loss: 2.3095748546466965
Validation loss: 2.6515779283861844

Epoch: 6| Step: 11
Training loss: 1.8498935823505438
Validation loss: 2.6085169098900494

Epoch: 6| Step: 12
Training loss: 2.5444689660184032
Validation loss: 2.5711577628601696

Epoch: 6| Step: 13
Training loss: 3.373532011290418
Validation loss: 2.6136788606015835

Epoch: 56| Step: 0
Training loss: 2.1941314452585257
Validation loss: 2.545139197094667

Epoch: 6| Step: 1
Training loss: 2.8315584195803014
Validation loss: 2.51699464841811

Epoch: 6| Step: 2
Training loss: 2.6414138247751673
Validation loss: 2.623478796859004

Epoch: 6| Step: 3
Training loss: 2.201964160457756
Validation loss: 2.58255439725629

Epoch: 6| Step: 4
Training loss: 1.8923558910737286
Validation loss: 2.568485078044149

Epoch: 6| Step: 5
Training loss: 2.2352365820008067
Validation loss: 2.575944953663017

Epoch: 6| Step: 6
Training loss: 2.1739031426577466
Validation loss: 2.5504802158188897

Epoch: 6| Step: 7
Training loss: 2.3831908879249633
Validation loss: 2.626984965948023

Epoch: 6| Step: 8
Training loss: 2.4224772043011855
Validation loss: 2.582828746759171

Epoch: 6| Step: 9
Training loss: 2.7726048898763436
Validation loss: 2.598731745218025

Epoch: 6| Step: 10
Training loss: 2.802389324361083
Validation loss: 2.5974543366320946

Epoch: 6| Step: 11
Training loss: 2.7409764411412065
Validation loss: 2.6249013988202186

Epoch: 6| Step: 12
Training loss: 1.9175158430138795
Validation loss: 2.593800080823185

Epoch: 6| Step: 13
Training loss: 2.411930562546049
Validation loss: 2.581333114111053

Epoch: 57| Step: 0
Training loss: 2.374401016996531
Validation loss: 2.621442473134517

Epoch: 6| Step: 1
Training loss: 2.687662696349403
Validation loss: 2.6267410287238833

Epoch: 6| Step: 2
Training loss: 2.3152786263526175
Validation loss: 2.6179480211573196

Epoch: 6| Step: 3
Training loss: 2.2468929030085816
Validation loss: 2.643652359983354

Epoch: 6| Step: 4
Training loss: 1.929234130976021
Validation loss: 2.5838788569159554

Epoch: 6| Step: 5
Training loss: 1.9374286269300973
Validation loss: 2.514927532423565

Epoch: 6| Step: 6
Training loss: 2.1951914037789173
Validation loss: 2.5974487833720232

Epoch: 6| Step: 7
Training loss: 1.9616937281001414
Validation loss: 2.659700807485754

Epoch: 6| Step: 8
Training loss: 3.2561156613101296
Validation loss: 2.593506215600118

Epoch: 6| Step: 9
Training loss: 2.3492785543549637
Validation loss: 2.5718997587956673

Epoch: 6| Step: 10
Training loss: 2.077335293664036
Validation loss: 2.563229511284889

Epoch: 6| Step: 11
Training loss: 2.6977049893048104
Validation loss: 2.544814026763363

Epoch: 6| Step: 12
Training loss: 3.160679041902295
Validation loss: 2.611307528787142

Epoch: 6| Step: 13
Training loss: 2.1454988113929874
Validation loss: 2.5587579650208294

Epoch: 58| Step: 0
Training loss: 1.916714881898667
Validation loss: 2.57070969253889

Epoch: 6| Step: 1
Training loss: 1.8324772468809274
Validation loss: 2.5782593740258757

Epoch: 6| Step: 2
Training loss: 2.0897807744600234
Validation loss: 2.6482718236784977

Epoch: 6| Step: 3
Training loss: 3.116569438648523
Validation loss: 2.5776680127109968

Epoch: 6| Step: 4
Training loss: 2.4215631099576598
Validation loss: 2.602663404823563

Epoch: 6| Step: 5
Training loss: 2.3339138898221976
Validation loss: 2.6343166985929227

Epoch: 6| Step: 6
Training loss: 2.40022891860221
Validation loss: 2.5999896819570187

Epoch: 6| Step: 7
Training loss: 2.292322642913219
Validation loss: 2.632841025178141

Epoch: 6| Step: 8
Training loss: 3.120913771308707
Validation loss: 2.669200532809322

Epoch: 6| Step: 9
Training loss: 2.3957454720571474
Validation loss: 2.5466548613912106

Epoch: 6| Step: 10
Training loss: 2.390114025284887
Validation loss: 2.533841850875506

Epoch: 6| Step: 11
Training loss: 2.569974094364207
Validation loss: 2.5884132634840125

Epoch: 6| Step: 12
Training loss: 2.452230302484026
Validation loss: 2.555735630679982

Epoch: 6| Step: 13
Training loss: 2.3034159627944426
Validation loss: 2.6612779788864915

Epoch: 59| Step: 0
Training loss: 2.3352544800258306
Validation loss: 2.6039965968229417

Epoch: 6| Step: 1
Training loss: 2.084315666029092
Validation loss: 2.5697558108393745

Epoch: 6| Step: 2
Training loss: 2.8140144509254195
Validation loss: 2.500405596574195

Epoch: 6| Step: 3
Training loss: 2.2662155960089043
Validation loss: 2.592506876795056

Epoch: 6| Step: 4
Training loss: 2.360989353057367
Validation loss: 2.562919830417887

Epoch: 6| Step: 5
Training loss: 1.9165991964765854
Validation loss: 2.6583784514119118

Epoch: 6| Step: 6
Training loss: 2.9629981286116687
Validation loss: 2.5805313286010776

Epoch: 6| Step: 7
Training loss: 1.516892836897713
Validation loss: 2.6106183407739443

Epoch: 6| Step: 8
Training loss: 1.9191166381454996
Validation loss: 2.6136852915711266

Epoch: 6| Step: 9
Training loss: 3.254715213300534
Validation loss: 2.5936014829958096

Epoch: 6| Step: 10
Training loss: 2.3122774996553934
Validation loss: 2.5605022505094968

Epoch: 6| Step: 11
Training loss: 2.5263988963269077
Validation loss: 2.604050173379129

Epoch: 6| Step: 12
Training loss: 1.946084417062721
Validation loss: 2.558174234800779

Epoch: 6| Step: 13
Training loss: 3.0338821780940406
Validation loss: 2.6206349910852227

Epoch: 60| Step: 0
Training loss: 2.132334673108818
Validation loss: 2.5600696451677507

Epoch: 6| Step: 1
Training loss: 2.5643689852854816
Validation loss: 2.608693595438529

Epoch: 6| Step: 2
Training loss: 2.721696156211387
Validation loss: 2.580830936112572

Epoch: 6| Step: 3
Training loss: 1.8861340234694712
Validation loss: 2.598937381718543

Epoch: 6| Step: 4
Training loss: 2.5728302193352
Validation loss: 2.5392441669910526

Epoch: 6| Step: 5
Training loss: 1.41935708253437
Validation loss: 2.516383275966708

Epoch: 6| Step: 6
Training loss: 2.860314720283813
Validation loss: 2.6058227588336127

Epoch: 6| Step: 7
Training loss: 2.4996518846376508
Validation loss: 2.5142104316150093

Epoch: 6| Step: 8
Training loss: 2.71625184790684
Validation loss: 2.5763185125326

Epoch: 6| Step: 9
Training loss: 2.168969275742792
Validation loss: 2.548250439341212

Epoch: 6| Step: 10
Training loss: 2.7241805638141345
Validation loss: 2.513671290099445

Epoch: 6| Step: 11
Training loss: 2.5354430707958286
Validation loss: 2.5333858003537157

Epoch: 6| Step: 12
Training loss: 2.38405709203421
Validation loss: 2.590068732568445

Epoch: 6| Step: 13
Training loss: 2.3491466190185926
Validation loss: 2.626670192528148

Epoch: 61| Step: 0
Training loss: 2.1198094872577737
Validation loss: 2.6205581595378

Epoch: 6| Step: 1
Training loss: 2.532907484886854
Validation loss: 2.5431425051845666

Epoch: 6| Step: 2
Training loss: 2.379198980251163
Validation loss: 2.602275655178691

Epoch: 6| Step: 3
Training loss: 2.4022523443929362
Validation loss: 2.63173601459778

Epoch: 6| Step: 4
Training loss: 2.429804464879598
Validation loss: 2.6271264908886143

Epoch: 6| Step: 5
Training loss: 2.9035623900507943
Validation loss: 2.6642764426023424

Epoch: 6| Step: 6
Training loss: 2.4504238735128236
Validation loss: 2.646009429317982

Epoch: 6| Step: 7
Training loss: 1.9254191524399038
Validation loss: 2.646373022911094

Epoch: 6| Step: 8
Training loss: 3.2203975275725982
Validation loss: 2.5642184256395244

Epoch: 6| Step: 9
Training loss: 1.9485455957940911
Validation loss: 2.577136133301198

Epoch: 6| Step: 10
Training loss: 2.475986642404001
Validation loss: 2.6072324533986797

Epoch: 6| Step: 11
Training loss: 2.6612912976029177
Validation loss: 2.5804484368977176

Epoch: 6| Step: 12
Training loss: 1.9959811124729805
Validation loss: 2.5880395618502408

Epoch: 6| Step: 13
Training loss: 1.83714812925498
Validation loss: 2.573693321682219

Epoch: 62| Step: 0
Training loss: 2.810169356323256
Validation loss: 2.6038630702752177

Epoch: 6| Step: 1
Training loss: 1.877188486194558
Validation loss: 2.5656242785683165

Epoch: 6| Step: 2
Training loss: 2.356525747014871
Validation loss: 2.5416940677187223

Epoch: 6| Step: 3
Training loss: 2.837814172501245
Validation loss: 2.5905609288592695

Epoch: 6| Step: 4
Training loss: 2.0829357022064716
Validation loss: 2.6479859693948797

Epoch: 6| Step: 5
Training loss: 2.83550601755848
Validation loss: 2.5572867202451977

Epoch: 6| Step: 6
Training loss: 2.115896584505784
Validation loss: 2.586331524750918

Epoch: 6| Step: 7
Training loss: 2.044335223761161
Validation loss: 2.5342332818373396

Epoch: 6| Step: 8
Training loss: 2.406709107036227
Validation loss: 2.65347116261716

Epoch: 6| Step: 9
Training loss: 2.4421869845398927
Validation loss: 2.588657727060626

Epoch: 6| Step: 10
Training loss: 2.1016238746047873
Validation loss: 2.642129337897082

Epoch: 6| Step: 11
Training loss: 2.616819532347286
Validation loss: 2.563053443503305

Epoch: 6| Step: 12
Training loss: 2.0503826807630916
Validation loss: 2.656878124095534

Epoch: 6| Step: 13
Training loss: 2.0029982504415655
Validation loss: 2.6551256380688777

Epoch: 63| Step: 0
Training loss: 2.413051455230916
Validation loss: 2.607774163496347

Epoch: 6| Step: 1
Training loss: 2.4094679481795236
Validation loss: 2.6831228776898635

Epoch: 6| Step: 2
Training loss: 1.8729825928668886
Validation loss: 2.6291830551031663

Epoch: 6| Step: 3
Training loss: 3.0112467394692777
Validation loss: 2.670052916541764

Epoch: 6| Step: 4
Training loss: 2.6448557892626385
Validation loss: 2.746641087328061

Epoch: 6| Step: 5
Training loss: 2.4234076787711256
Validation loss: 2.6893568942847725

Epoch: 6| Step: 6
Training loss: 2.5380637684199185
Validation loss: 2.660228995263529

Epoch: 6| Step: 7
Training loss: 1.3220270073969929
Validation loss: 2.7074816513966136

Epoch: 6| Step: 8
Training loss: 2.780997618464685
Validation loss: 2.6497290058846517

Epoch: 6| Step: 9
Training loss: 2.7852303814753037
Validation loss: 2.6075841884121758

Epoch: 6| Step: 10
Training loss: 2.616917929359866
Validation loss: 2.6433355801714296

Epoch: 6| Step: 11
Training loss: 2.416562955099803
Validation loss: 2.4932118127486014

Epoch: 6| Step: 12
Training loss: 1.964260431845319
Validation loss: 2.5540594793068703

Epoch: 6| Step: 13
Training loss: 1.7744559837852032
Validation loss: 2.6257320927221146

Epoch: 64| Step: 0
Training loss: 2.3171669545616473
Validation loss: 2.597793353676454

Epoch: 6| Step: 1
Training loss: 3.0886184828642125
Validation loss: 2.6608800738879097

Epoch: 6| Step: 2
Training loss: 2.0843801792886834
Validation loss: 2.58080514641375

Epoch: 6| Step: 3
Training loss: 2.5601185222845704
Validation loss: 2.586089729983726

Epoch: 6| Step: 4
Training loss: 1.9136060520803633
Validation loss: 2.5706211047827434

Epoch: 6| Step: 5
Training loss: 2.2283142694282154
Validation loss: 2.504796989016661

Epoch: 6| Step: 6
Training loss: 2.7249415260130685
Validation loss: 2.6009057851386554

Epoch: 6| Step: 7
Training loss: 2.416802588838809
Validation loss: 2.5911762536082694

Epoch: 6| Step: 8
Training loss: 1.8602549930849495
Validation loss: 2.6404356578232027

Epoch: 6| Step: 9
Training loss: 2.3417563542287656
Validation loss: 2.524883442571111

Epoch: 6| Step: 10
Training loss: 2.327688701122007
Validation loss: 2.600209584103018

Epoch: 6| Step: 11
Training loss: 2.628216906742425
Validation loss: 2.667600160367069

Epoch: 6| Step: 12
Training loss: 2.8133137691263497
Validation loss: 2.6326322107060696

Epoch: 6| Step: 13
Training loss: 1.862980016514174
Validation loss: 2.5982961378030973

Epoch: 65| Step: 0
Training loss: 2.544478336073346
Validation loss: 2.5304246820701546

Epoch: 6| Step: 1
Training loss: 2.2920673944774
Validation loss: 2.587559179037783

Epoch: 6| Step: 2
Training loss: 1.753502338348039
Validation loss: 2.6344168856161785

Epoch: 6| Step: 3
Training loss: 1.9177324262103976
Validation loss: 2.5581335221667527

Epoch: 6| Step: 4
Training loss: 2.4874047572626043
Validation loss: 2.5366034077874384

Epoch: 6| Step: 5
Training loss: 2.802638248297106
Validation loss: 2.580841652234024

Epoch: 6| Step: 6
Training loss: 2.7629692127943826
Validation loss: 2.6221934407436294

Epoch: 6| Step: 7
Training loss: 2.3747194024016443
Validation loss: 2.5622627024372155

Epoch: 6| Step: 8
Training loss: 2.3171897965340738
Validation loss: 2.5400652973913087

Epoch: 6| Step: 9
Training loss: 2.8293710566434855
Validation loss: 2.5544584056857493

Epoch: 6| Step: 10
Training loss: 2.987648491780285
Validation loss: 2.5638375861850067

Epoch: 6| Step: 11
Training loss: 2.186565744621963
Validation loss: 2.598960973296166

Epoch: 6| Step: 12
Training loss: 2.0876332223377507
Validation loss: 2.586344169302288

Epoch: 6| Step: 13
Training loss: 2.1988826515212523
Validation loss: 2.576588652635937

Epoch: 66| Step: 0
Training loss: 2.6766905638727354
Validation loss: 2.57526986365383

Epoch: 6| Step: 1
Training loss: 1.8769580789395472
Validation loss: 2.6161589617927907

Epoch: 6| Step: 2
Training loss: 2.0106909635595276
Validation loss: 2.649337330621098

Epoch: 6| Step: 3
Training loss: 1.5070957990698044
Validation loss: 2.661055253791412

Epoch: 6| Step: 4
Training loss: 2.316774284369713
Validation loss: 2.6485855076185847

Epoch: 6| Step: 5
Training loss: 2.0145532878645818
Validation loss: 2.7084165535881186

Epoch: 6| Step: 6
Training loss: 2.112942314115158
Validation loss: 2.6956962717659483

Epoch: 6| Step: 7
Training loss: 2.9448465236703987
Validation loss: 2.7630164421734564

Epoch: 6| Step: 8
Training loss: 2.1783230794107324
Validation loss: 2.766262246834659

Epoch: 6| Step: 9
Training loss: 1.9421371833992174
Validation loss: 2.6382909462641115

Epoch: 6| Step: 10
Training loss: 2.3198959027975574
Validation loss: 2.6615870395502697

Epoch: 6| Step: 11
Training loss: 2.3663044406051057
Validation loss: 2.6179703637610197

Epoch: 6| Step: 12
Training loss: 2.6218057907481698
Validation loss: 2.6737716665128706

Epoch: 6| Step: 13
Training loss: 3.3248426701316154
Validation loss: 2.6224105566849563

Epoch: 67| Step: 0
Training loss: 3.15881243639137
Validation loss: 2.57864963318302

Epoch: 6| Step: 1
Training loss: 1.9176258161267175
Validation loss: 2.6020510866739204

Epoch: 6| Step: 2
Training loss: 2.5078638374564277
Validation loss: 2.5942252769266334

Epoch: 6| Step: 3
Training loss: 2.225996621484926
Validation loss: 2.5964972719006405

Epoch: 6| Step: 4
Training loss: 2.7734489333226042
Validation loss: 2.5872469503409494

Epoch: 6| Step: 5
Training loss: 1.754719501043899
Validation loss: 2.575806162540814

Epoch: 6| Step: 6
Training loss: 2.2511994026085684
Validation loss: 2.6176246999082786

Epoch: 6| Step: 7
Training loss: 2.0793962534078307
Validation loss: 2.6020070136315607

Epoch: 6| Step: 8
Training loss: 2.5317368215852833
Validation loss: 2.5913527107400802

Epoch: 6| Step: 9
Training loss: 2.4385428520850474
Validation loss: 2.550294106171766

Epoch: 6| Step: 10
Training loss: 1.939888742933712
Validation loss: 2.55028159450444

Epoch: 6| Step: 11
Training loss: 2.1332278563332454
Validation loss: 2.557926857888595

Epoch: 6| Step: 12
Training loss: 3.4555142107497345
Validation loss: 2.656116317676189

Epoch: 6| Step: 13
Training loss: 2.1486514453133774
Validation loss: 2.6077366175809953

Epoch: 68| Step: 0
Training loss: 2.5765504595010795
Validation loss: 2.5670339899491394

Epoch: 6| Step: 1
Training loss: 2.6772966312283955
Validation loss: 2.6116253710534876

Epoch: 6| Step: 2
Training loss: 2.6559579127665423
Validation loss: 2.6931463262894417

Epoch: 6| Step: 3
Training loss: 2.512509329859174
Validation loss: 2.5881119082869843

Epoch: 6| Step: 4
Training loss: 2.6204174550737105
Validation loss: 2.609204391414704

Epoch: 6| Step: 5
Training loss: 1.5351995796902764
Validation loss: 2.5470388472886656

Epoch: 6| Step: 6
Training loss: 2.2460268757028254
Validation loss: 2.641686837352998

Epoch: 6| Step: 7
Training loss: 1.9733204544888612
Validation loss: 2.5397262488174976

Epoch: 6| Step: 8
Training loss: 2.314510296465554
Validation loss: 2.594714318685534

Epoch: 6| Step: 9
Training loss: 2.951681278680109
Validation loss: 2.5503298957454854

Epoch: 6| Step: 10
Training loss: 2.1405548306958484
Validation loss: 2.5935545008874965

Epoch: 6| Step: 11
Training loss: 2.441262300443742
Validation loss: 2.5523640588521235

Epoch: 6| Step: 12
Training loss: 2.6657482194763094
Validation loss: 2.580075506786064

Epoch: 6| Step: 13
Training loss: 2.2369310390874397
Validation loss: 2.540318871729953

Epoch: 69| Step: 0
Training loss: 1.8609635435343084
Validation loss: 2.6279565268036333

Epoch: 6| Step: 1
Training loss: 1.9146730033234818
Validation loss: 2.6771788573879762

Epoch: 6| Step: 2
Training loss: 2.099151816967389
Validation loss: 2.6100258082238037

Epoch: 6| Step: 3
Training loss: 2.2547491603147214
Validation loss: 2.708167090571238

Epoch: 6| Step: 4
Training loss: 2.267603569315148
Validation loss: 2.659974512585214

Epoch: 6| Step: 5
Training loss: 2.499097661253637
Validation loss: 2.6901230099003626

Epoch: 6| Step: 6
Training loss: 1.6413054009040686
Validation loss: 2.6942616501204357

Epoch: 6| Step: 7
Training loss: 2.3801086093259483
Validation loss: 2.6723531105632787

Epoch: 6| Step: 8
Training loss: 2.096259819103303
Validation loss: 2.6559258955150553

Epoch: 6| Step: 9
Training loss: 2.639955334141047
Validation loss: 2.6932140492787315

Epoch: 6| Step: 10
Training loss: 2.801823505895922
Validation loss: 2.592405568263474

Epoch: 6| Step: 11
Training loss: 1.8183384616521912
Validation loss: 2.5536438251767297

Epoch: 6| Step: 12
Training loss: 3.493577787082253
Validation loss: 2.4778510912021554

Epoch: 6| Step: 13
Training loss: 2.2086293603909213
Validation loss: 2.576070101455454

Epoch: 70| Step: 0
Training loss: 2.4605171934603436
Validation loss: 2.6519236917885665

Epoch: 6| Step: 1
Training loss: 1.772041140778398
Validation loss: 2.5253164974307363

Epoch: 6| Step: 2
Training loss: 2.0861738549673694
Validation loss: 2.5883308084266403

Epoch: 6| Step: 3
Training loss: 1.9643998298689997
Validation loss: 2.6144679729245803

Epoch: 6| Step: 4
Training loss: 2.3526543905287944
Validation loss: 2.5474903010919014

Epoch: 6| Step: 5
Training loss: 2.2304106001614366
Validation loss: 2.6243367189717977

Epoch: 6| Step: 6
Training loss: 2.4845541643521005
Validation loss: 2.626695176403926

Epoch: 6| Step: 7
Training loss: 3.220304835799498
Validation loss: 2.5920041961272933

Epoch: 6| Step: 8
Training loss: 2.2152755827645403
Validation loss: 2.5538438965397376

Epoch: 6| Step: 9
Training loss: 2.3280658074349097
Validation loss: 2.5362304230008546

Epoch: 6| Step: 10
Training loss: 2.2246657474063616
Validation loss: 2.5146707656017213

Epoch: 6| Step: 11
Training loss: 3.279415816875863
Validation loss: 2.5989962150142047

Epoch: 6| Step: 12
Training loss: 2.2038779629119523
Validation loss: 2.62438244594418

Epoch: 6| Step: 13
Training loss: 2.303156664357627
Validation loss: 2.6581785493789574

Epoch: 71| Step: 0
Training loss: 1.7184328653620273
Validation loss: 2.572944059239001

Epoch: 6| Step: 1
Training loss: 2.1800805834653985
Validation loss: 2.5898844551274576

Epoch: 6| Step: 2
Training loss: 1.9372490751151292
Validation loss: 2.6609474532873993

Epoch: 6| Step: 3
Training loss: 2.9969035699176665
Validation loss: 2.607361509693514

Epoch: 6| Step: 4
Training loss: 2.617457953755696
Validation loss: 2.7007232462633612

Epoch: 6| Step: 5
Training loss: 1.989626566099296
Validation loss: 2.6089635741650725

Epoch: 6| Step: 6
Training loss: 1.861965586650562
Validation loss: 2.6330431375877974

Epoch: 6| Step: 7
Training loss: 2.2357938303131304
Validation loss: 2.6268994709950184

Epoch: 6| Step: 8
Training loss: 2.4375264092995415
Validation loss: 2.6207889809870926

Epoch: 6| Step: 9
Training loss: 1.9744924931406425
Validation loss: 2.628548222233531

Epoch: 6| Step: 10
Training loss: 3.044186858799345
Validation loss: 2.557075869486309

Epoch: 6| Step: 11
Training loss: 2.1411537575457182
Validation loss: 2.6345621817063156

Epoch: 6| Step: 12
Training loss: 2.58125032512672
Validation loss: 2.60483611593851

Epoch: 6| Step: 13
Training loss: 2.853609536549274
Validation loss: 2.579699449763741

Epoch: 72| Step: 0
Training loss: 2.4072233931267166
Validation loss: 2.5949662509063773

Epoch: 6| Step: 1
Training loss: 2.5370524270095443
Validation loss: 2.5014361389129514

Epoch: 6| Step: 2
Training loss: 2.2427845867663527
Validation loss: 2.453257935763087

Epoch: 6| Step: 3
Training loss: 1.9425648354176046
Validation loss: 2.525048008704712

Epoch: 6| Step: 4
Training loss: 2.5789896122108282
Validation loss: 2.526365787646782

Epoch: 6| Step: 5
Training loss: 2.5778676222439585
Validation loss: 2.57627349028412

Epoch: 6| Step: 6
Training loss: 1.6338823090078185
Validation loss: 2.5688088916917717

Epoch: 6| Step: 7
Training loss: 1.3271231968200856
Validation loss: 2.512174573861027

Epoch: 6| Step: 8
Training loss: 1.9309798635048239
Validation loss: 2.5327243043580534

Epoch: 6| Step: 9
Training loss: 1.9929039956956207
Validation loss: 2.5639335762635342

Epoch: 6| Step: 10
Training loss: 2.38285992684615
Validation loss: 2.588073608838893

Epoch: 6| Step: 11
Training loss: 3.5020793460155315
Validation loss: 2.5657774814483334

Epoch: 6| Step: 12
Training loss: 2.9340364856076606
Validation loss: 2.529070021423596

Epoch: 6| Step: 13
Training loss: 2.12388334667323
Validation loss: 2.6073332391691895

Epoch: 73| Step: 0
Training loss: 1.7017821171098815
Validation loss: 2.5619637618300017

Epoch: 6| Step: 1
Training loss: 2.6555743087344035
Validation loss: 2.6356119427814733

Epoch: 6| Step: 2
Training loss: 2.439066456920437
Validation loss: 2.657174207682619

Epoch: 6| Step: 3
Training loss: 2.0210646926212563
Validation loss: 2.582896016134717

Epoch: 6| Step: 4
Training loss: 2.415062755772373
Validation loss: 2.5951379180253986

Epoch: 6| Step: 5
Training loss: 2.406036862928892
Validation loss: 2.651148156286253

Epoch: 6| Step: 6
Training loss: 2.3885620790638855
Validation loss: 2.549550435697207

Epoch: 6| Step: 7
Training loss: 1.6375104132168303
Validation loss: 2.627392322077314

Epoch: 6| Step: 8
Training loss: 1.7323804504189881
Validation loss: 2.567501165506754

Epoch: 6| Step: 9
Training loss: 2.7631446362418735
Validation loss: 2.64528001921936

Epoch: 6| Step: 10
Training loss: 2.9132181943870785
Validation loss: 2.6032893928437266

Epoch: 6| Step: 11
Training loss: 2.1358111753689872
Validation loss: 2.587795070587502

Epoch: 6| Step: 12
Training loss: 2.684491802689756
Validation loss: 2.4986633621750025

Epoch: 6| Step: 13
Training loss: 2.310844137847693
Validation loss: 2.548596726555094

Epoch: 74| Step: 0
Training loss: 2.2660447356680917
Validation loss: 2.575557702047803

Epoch: 6| Step: 1
Training loss: 2.7481121172070537
Validation loss: 2.5913929934809956

Epoch: 6| Step: 2
Training loss: 2.0477457305673683
Validation loss: 2.6187354828668106

Epoch: 6| Step: 3
Training loss: 2.358155396379577
Validation loss: 2.548627145377804

Epoch: 6| Step: 4
Training loss: 1.9156551663635617
Validation loss: 2.598910502654272

Epoch: 6| Step: 5
Training loss: 1.8784816206600785
Validation loss: 2.6660032241775085

Epoch: 6| Step: 6
Training loss: 3.23034003484504
Validation loss: 2.6939613383293626

Epoch: 6| Step: 7
Training loss: 2.176069641176944
Validation loss: 2.651557270165529

Epoch: 6| Step: 8
Training loss: 2.6153359311522255
Validation loss: 2.763037180275458

Epoch: 6| Step: 9
Training loss: 2.4634677050552334
Validation loss: 2.6317628603800065

Epoch: 6| Step: 10
Training loss: 2.302522321131033
Validation loss: 2.6398192310577544

Epoch: 6| Step: 11
Training loss: 2.7828839249523685
Validation loss: 2.6193579636455686

Epoch: 6| Step: 12
Training loss: 1.9303130707285259
Validation loss: 2.5423197819127

Epoch: 6| Step: 13
Training loss: 1.8158538306475396
Validation loss: 2.560948111306737

Epoch: 75| Step: 0
Training loss: 1.813397809990696
Validation loss: 2.510277666435686

Epoch: 6| Step: 1
Training loss: 2.1426172939674046
Validation loss: 2.6132596275906206

Epoch: 6| Step: 2
Training loss: 2.379682542641699
Validation loss: 2.5608821972315585

Epoch: 6| Step: 3
Training loss: 3.3163556386008555
Validation loss: 2.531944132632973

Epoch: 6| Step: 4
Training loss: 2.085303049361944
Validation loss: 2.618798924173461

Epoch: 6| Step: 5
Training loss: 2.123469081753278
Validation loss: 2.6206456809088734

Epoch: 6| Step: 6
Training loss: 2.4643863791682663
Validation loss: 2.562439305276738

Epoch: 6| Step: 7
Training loss: 1.9924646521368072
Validation loss: 2.5389561244493506

Epoch: 6| Step: 8
Training loss: 2.655315818322133
Validation loss: 2.639490625027479

Epoch: 6| Step: 9
Training loss: 2.3798271113198433
Validation loss: 2.6388727126267084

Epoch: 6| Step: 10
Training loss: 1.8129362041823702
Validation loss: 2.5603317919187107

Epoch: 6| Step: 11
Training loss: 2.1146170577443377
Validation loss: 2.5960071348377336

Epoch: 6| Step: 12
Training loss: 3.1622342325951878
Validation loss: 2.5711874974995848

Epoch: 6| Step: 13
Training loss: 2.011386999534339
Validation loss: 2.599257336670156

Epoch: 76| Step: 0
Training loss: 2.7907858260781273
Validation loss: 2.5790181009851296

Epoch: 6| Step: 1
Training loss: 2.514020135402845
Validation loss: 2.642401261483416

Epoch: 6| Step: 2
Training loss: 2.0410753159258928
Validation loss: 2.647615490844761

Epoch: 6| Step: 3
Training loss: 2.464050261975693
Validation loss: 2.589846657530321

Epoch: 6| Step: 4
Training loss: 2.178842250777227
Validation loss: 2.630319956812381

Epoch: 6| Step: 5
Training loss: 2.068542529994193
Validation loss: 2.5263124196304747

Epoch: 6| Step: 6
Training loss: 2.866977278567152
Validation loss: 2.5558512814313135

Epoch: 6| Step: 7
Training loss: 1.8403725805595095
Validation loss: 2.5043638925010128

Epoch: 6| Step: 8
Training loss: 2.7116796703374617
Validation loss: 2.5916897507975443

Epoch: 6| Step: 9
Training loss: 2.3973318527494336
Validation loss: 2.602902942481045

Epoch: 6| Step: 10
Training loss: 1.789507748033069
Validation loss: 2.565724073658482

Epoch: 6| Step: 11
Training loss: 2.083333079020167
Validation loss: 2.4820167897297196

Epoch: 6| Step: 12
Training loss: 2.4012038589166926
Validation loss: 2.5449077286696715

Epoch: 6| Step: 13
Training loss: 1.8864969000691034
Validation loss: 2.642249561305086

Epoch: 77| Step: 0
Training loss: 2.2335756379200724
Validation loss: 2.564269889024224

Epoch: 6| Step: 1
Training loss: 2.036376236011181
Validation loss: 2.6555883593330996

Epoch: 6| Step: 2
Training loss: 2.0746915748902075
Validation loss: 2.600595212321324

Epoch: 6| Step: 3
Training loss: 2.9759328581711606
Validation loss: 2.5099353302455367

Epoch: 6| Step: 4
Training loss: 2.5581026261108706
Validation loss: 2.557218753891444

Epoch: 6| Step: 5
Training loss: 2.0198444293329314
Validation loss: 2.5858862527031516

Epoch: 6| Step: 6
Training loss: 2.033274653896091
Validation loss: 2.6396020265884275

Epoch: 6| Step: 7
Training loss: 2.8949331810179304
Validation loss: 2.5969574028862703

Epoch: 6| Step: 8
Training loss: 2.193305459043478
Validation loss: 2.670652872218811

Epoch: 6| Step: 9
Training loss: 2.511721787517603
Validation loss: 2.5823938958625705

Epoch: 6| Step: 10
Training loss: 2.6175824678649993
Validation loss: 2.6351992450836557

Epoch: 6| Step: 11
Training loss: 2.466168562969986
Validation loss: 2.597840832722834

Epoch: 6| Step: 12
Training loss: 2.0604008482765224
Validation loss: 2.5710436893095894

Epoch: 6| Step: 13
Training loss: 1.7602764577915666
Validation loss: 2.5940390889181697

Epoch: 78| Step: 0
Training loss: 1.8415268895311665
Validation loss: 2.5767111706642956

Epoch: 6| Step: 1
Training loss: 2.6289392613779894
Validation loss: 2.629082555276848

Epoch: 6| Step: 2
Training loss: 1.8790743746652716
Validation loss: 2.5897135445308703

Epoch: 6| Step: 3
Training loss: 2.2099136839706173
Validation loss: 2.578447772541788

Epoch: 6| Step: 4
Training loss: 2.2587918068373947
Validation loss: 2.5877658492423468

Epoch: 6| Step: 5
Training loss: 2.507742146963914
Validation loss: 2.5937860172329477

Epoch: 6| Step: 6
Training loss: 2.5990340859503247
Validation loss: 2.5810607224989353

Epoch: 6| Step: 7
Training loss: 2.3368803947245667
Validation loss: 2.585847482334201

Epoch: 6| Step: 8
Training loss: 3.056561375769781
Validation loss: 2.5380384052518203

Epoch: 6| Step: 9
Training loss: 1.810522776816772
Validation loss: 2.554337192669714

Epoch: 6| Step: 10
Training loss: 1.9340602735813854
Validation loss: 2.5772922134141867

Epoch: 6| Step: 11
Training loss: 1.8781871410886306
Validation loss: 2.565426357321822

Epoch: 6| Step: 12
Training loss: 2.1047829836431218
Validation loss: 2.5418073948740716

Epoch: 6| Step: 13
Training loss: 2.5267658781672013
Validation loss: 2.555095130682249

Epoch: 79| Step: 0
Training loss: 1.9757040217621302
Validation loss: 2.584034545134587

Epoch: 6| Step: 1
Training loss: 2.274870535551799
Validation loss: 2.5038465233878813

Epoch: 6| Step: 2
Training loss: 1.590473921820157
Validation loss: 2.575916307491666

Epoch: 6| Step: 3
Training loss: 2.686557782035786
Validation loss: 2.593085176988522

Epoch: 6| Step: 4
Training loss: 2.8611751372283303
Validation loss: 2.580393592632343

Epoch: 6| Step: 5
Training loss: 2.007838861314665
Validation loss: 2.604983489044641

Epoch: 6| Step: 6
Training loss: 3.001436843108471
Validation loss: 2.5677216679740726

Epoch: 6| Step: 7
Training loss: 3.026214507129999
Validation loss: 2.5908524288023065

Epoch: 6| Step: 8
Training loss: 2.4403364843771898
Validation loss: 2.541235626650403

Epoch: 6| Step: 9
Training loss: 1.6462507885443698
Validation loss: 2.5893230576476634

Epoch: 6| Step: 10
Training loss: 1.8456511313567874
Validation loss: 2.5548016661663686

Epoch: 6| Step: 11
Training loss: 2.432382542439341
Validation loss: 2.5273097732201824

Epoch: 6| Step: 12
Training loss: 2.260190562763433
Validation loss: 2.581500131035057

Epoch: 6| Step: 13
Training loss: 2.422535467842843
Validation loss: 2.5728736801777914

Epoch: 80| Step: 0
Training loss: 2.53412982399161
Validation loss: 2.56442159229967

Epoch: 6| Step: 1
Training loss: 2.0818736748532256
Validation loss: 2.5485578566648446

Epoch: 6| Step: 2
Training loss: 2.0197291028263447
Validation loss: 2.553639203651117

Epoch: 6| Step: 3
Training loss: 2.219394536492343
Validation loss: 2.667296474311125

Epoch: 6| Step: 4
Training loss: 2.808983363264228
Validation loss: 2.670970205845647

Epoch: 6| Step: 5
Training loss: 2.091049958561301
Validation loss: 2.633234686351821

Epoch: 6| Step: 6
Training loss: 2.32819146183055
Validation loss: 2.5436543733335313

Epoch: 6| Step: 7
Training loss: 2.5475462982492845
Validation loss: 2.6052253148073166

Epoch: 6| Step: 8
Training loss: 2.305716902156864
Validation loss: 2.560745460458312

Epoch: 6| Step: 9
Training loss: 2.508569620943644
Validation loss: 2.720485031321385

Epoch: 6| Step: 10
Training loss: 2.2451026388379742
Validation loss: 2.5620774486716322

Epoch: 6| Step: 11
Training loss: 1.8430198258085462
Validation loss: 2.533058211378462

Epoch: 6| Step: 12
Training loss: 2.3115133294165346
Validation loss: 2.6525924933028313

Epoch: 6| Step: 13
Training loss: 2.379765297512832
Validation loss: 2.5894902651188207

Epoch: 81| Step: 0
Training loss: 2.462276324652473
Validation loss: 2.596260908333801

Epoch: 6| Step: 1
Training loss: 1.5104262077644053
Validation loss: 2.5927693608234583

Epoch: 6| Step: 2
Training loss: 2.3761430298689463
Validation loss: 2.5866565300146394

Epoch: 6| Step: 3
Training loss: 2.8527672299944618
Validation loss: 2.648626615210754

Epoch: 6| Step: 4
Training loss: 2.797988073404019
Validation loss: 2.4719596793632177

Epoch: 6| Step: 5
Training loss: 2.4836619571464853
Validation loss: 2.5353522242117226

Epoch: 6| Step: 6
Training loss: 2.285955722863969
Validation loss: 2.5350926278099855

Epoch: 6| Step: 7
Training loss: 2.0578380261621527
Validation loss: 2.5468017630003255

Epoch: 6| Step: 8
Training loss: 2.1785940620265096
Validation loss: 2.6042288709204926

Epoch: 6| Step: 9
Training loss: 2.1123773753674686
Validation loss: 2.5486675265446532

Epoch: 6| Step: 10
Training loss: 2.0525794292883277
Validation loss: 2.470087429525032

Epoch: 6| Step: 11
Training loss: 1.676124519811791
Validation loss: 2.4951534261143458

Epoch: 6| Step: 12
Training loss: 2.271982677904101
Validation loss: 2.6254028435057486

Epoch: 6| Step: 13
Training loss: 2.5598190984288145
Validation loss: 2.546703293829887

Epoch: 82| Step: 0
Training loss: 1.5942839681671472
Validation loss: 2.6188711491908587

Epoch: 6| Step: 1
Training loss: 2.680850830242375
Validation loss: 2.6072419636696074

Epoch: 6| Step: 2
Training loss: 2.1908604559290206
Validation loss: 2.633285781777078

Epoch: 6| Step: 3
Training loss: 2.384161295381976
Validation loss: 2.7184171801775787

Epoch: 6| Step: 4
Training loss: 2.670991450334274
Validation loss: 2.643919460315555

Epoch: 6| Step: 5
Training loss: 2.184392083664698
Validation loss: 2.685408169950228

Epoch: 6| Step: 6
Training loss: 2.0660649326013685
Validation loss: 2.644048514320708

Epoch: 6| Step: 7
Training loss: 2.031897104331401
Validation loss: 2.578736943532238

Epoch: 6| Step: 8
Training loss: 2.177329698947755
Validation loss: 2.580565297569535

Epoch: 6| Step: 9
Training loss: 2.381542830596856
Validation loss: 2.6122297862120223

Epoch: 6| Step: 10
Training loss: 2.029944836848877
Validation loss: 2.5336828745660784

Epoch: 6| Step: 11
Training loss: 2.251591966953745
Validation loss: 2.4618160233830295

Epoch: 6| Step: 12
Training loss: 2.5141083309531567
Validation loss: 2.585915234057865

Epoch: 6| Step: 13
Training loss: 2.4192695631359915
Validation loss: 2.5774745544499713

Epoch: 83| Step: 0
Training loss: 2.3890446444555833
Validation loss: 2.5562661180555453

Epoch: 6| Step: 1
Training loss: 1.5377783670650913
Validation loss: 2.538116826721623

Epoch: 6| Step: 2
Training loss: 1.769211696040325
Validation loss: 2.597294786587587

Epoch: 6| Step: 3
Training loss: 2.140744950769331
Validation loss: 2.526985815252203

Epoch: 6| Step: 4
Training loss: 2.610219122213075
Validation loss: 2.624526404997669

Epoch: 6| Step: 5
Training loss: 2.7392259565326813
Validation loss: 2.6172385595095116

Epoch: 6| Step: 6
Training loss: 1.8937624285702412
Validation loss: 2.577213241727974

Epoch: 6| Step: 7
Training loss: 2.734243771265083
Validation loss: 2.533371934680311

Epoch: 6| Step: 8
Training loss: 2.457176216348945
Validation loss: 2.5030738688821486

Epoch: 6| Step: 9
Training loss: 2.099515804601035
Validation loss: 2.605822537721776

Epoch: 6| Step: 10
Training loss: 2.9857331226456068
Validation loss: 2.661305885403057

Epoch: 6| Step: 11
Training loss: 1.6128479604328148
Validation loss: 2.618503076691514

Epoch: 6| Step: 12
Training loss: 2.6785795629468656
Validation loss: 2.6314177247486534

Epoch: 6| Step: 13
Training loss: 2.136165679821092
Validation loss: 2.6738275899949246

Epoch: 84| Step: 0
Training loss: 2.2185416325258007
Validation loss: 2.7156081040723388

Epoch: 6| Step: 1
Training loss: 2.478268393833194
Validation loss: 2.642023487440999

Epoch: 6| Step: 2
Training loss: 2.2005780154290706
Validation loss: 2.676605231394384

Epoch: 6| Step: 3
Training loss: 2.2017955691855473
Validation loss: 2.5879688716551295

Epoch: 6| Step: 4
Training loss: 2.1541425938494023
Validation loss: 2.5564830042717217

Epoch: 6| Step: 5
Training loss: 2.3510816722525933
Validation loss: 2.5249663171315624

Epoch: 6| Step: 6
Training loss: 1.902008716446953
Validation loss: 2.5667912055636872

Epoch: 6| Step: 7
Training loss: 1.9636944240036527
Validation loss: 2.603344754533059

Epoch: 6| Step: 8
Training loss: 2.518069767501271
Validation loss: 2.556156525461201

Epoch: 6| Step: 9
Training loss: 2.496143227148036
Validation loss: 2.5532926587665656

Epoch: 6| Step: 10
Training loss: 3.1290868357004737
Validation loss: 2.5932746819366264

Epoch: 6| Step: 11
Training loss: 2.094107070765037
Validation loss: 2.4622826830505904

Epoch: 6| Step: 12
Training loss: 2.1832412680902635
Validation loss: 2.539597471561356

Epoch: 6| Step: 13
Training loss: 1.9988458402652647
Validation loss: 2.5435540950985067

Epoch: 85| Step: 0
Training loss: 1.8954883163683742
Validation loss: 2.600020913198922

Epoch: 6| Step: 1
Training loss: 2.0888587412901938
Validation loss: 2.6552734375

Epoch: 6| Step: 2
Training loss: 2.221551979502581
Validation loss: 2.5656085659279806

Epoch: 6| Step: 3
Training loss: 1.9993581934154252
Validation loss: 2.542896213073163

Epoch: 6| Step: 4
Training loss: 2.4785456373773913
Validation loss: 2.621431930563846

Epoch: 6| Step: 5
Training loss: 2.492501074696025
Validation loss: 2.6496473641558898

Epoch: 6| Step: 6
Training loss: 1.8472688361511262
Validation loss: 2.6705533452698615

Epoch: 6| Step: 7
Training loss: 2.1103639897973983
Validation loss: 2.6062569786606504

Epoch: 6| Step: 8
Training loss: 2.640089714375474
Validation loss: 2.5669070703041657

Epoch: 6| Step: 9
Training loss: 2.3832195997333057
Validation loss: 2.5595302585930333

Epoch: 6| Step: 10
Training loss: 2.708943185857559
Validation loss: 2.582405459497468

Epoch: 6| Step: 11
Training loss: 2.1785430638345082
Validation loss: 2.591114114282866

Epoch: 6| Step: 12
Training loss: 2.0055942973125442
Validation loss: 2.642293000704533

Epoch: 6| Step: 13
Training loss: 2.8586431515186725
Validation loss: 2.553254451761648

Epoch: 86| Step: 0
Training loss: 2.0440842334762386
Validation loss: 2.551137076655369

Epoch: 6| Step: 1
Training loss: 2.5110298980063224
Validation loss: 2.5737513733894595

Epoch: 6| Step: 2
Training loss: 1.5425572100004161
Validation loss: 2.584772006764844

Epoch: 6| Step: 3
Training loss: 2.2231959540814525
Validation loss: 2.542425907321982

Epoch: 6| Step: 4
Training loss: 2.041553714767746
Validation loss: 2.6406122843118323

Epoch: 6| Step: 5
Training loss: 2.0084564719959315
Validation loss: 2.6641905335268197

Epoch: 6| Step: 6
Training loss: 2.9135512652674906
Validation loss: 2.5687694304412787

Epoch: 6| Step: 7
Training loss: 2.390722434856996
Validation loss: 2.4854242919992493

Epoch: 6| Step: 8
Training loss: 1.1041190059140278
Validation loss: 2.579343072613375

Epoch: 6| Step: 9
Training loss: 2.1843374006230682
Validation loss: 2.6038168150822996

Epoch: 6| Step: 10
Training loss: 3.110144438501969
Validation loss: 2.523877077031871

Epoch: 6| Step: 11
Training loss: 1.8298910364948882
Validation loss: 2.5489660466904587

Epoch: 6| Step: 12
Training loss: 2.2286804833645246
Validation loss: 2.564128567566819

Epoch: 6| Step: 13
Training loss: 2.2999168546823925
Validation loss: 2.525827400060431

Epoch: 87| Step: 0
Training loss: 1.9911992033892854
Validation loss: 2.5858313316839867

Epoch: 6| Step: 1
Training loss: 2.536595387186273
Validation loss: 2.5673906595335816

Epoch: 6| Step: 2
Training loss: 2.23979383558707
Validation loss: 2.634240024739518

Epoch: 6| Step: 3
Training loss: 1.9993176488351228
Validation loss: 2.5692904990419443

Epoch: 6| Step: 4
Training loss: 2.574520851665727
Validation loss: 2.554651787028983

Epoch: 6| Step: 5
Training loss: 3.3498311583828895
Validation loss: 2.572296227360237

Epoch: 6| Step: 6
Training loss: 2.2686406553206333
Validation loss: 2.544045137971626

Epoch: 6| Step: 7
Training loss: 1.5505809126048289
Validation loss: 2.5732838037975285

Epoch: 6| Step: 8
Training loss: 2.646802639563266
Validation loss: 2.533189375974137

Epoch: 6| Step: 9
Training loss: 1.2043161811976262
Validation loss: 2.512344132202

Epoch: 6| Step: 10
Training loss: 2.165560207526139
Validation loss: 2.6420040254150727

Epoch: 6| Step: 11
Training loss: 1.8969888065391978
Validation loss: 2.504150632615468

Epoch: 6| Step: 12
Training loss: 2.2227283325306257
Validation loss: 2.613163024022304

Epoch: 6| Step: 13
Training loss: 1.976115722823652
Validation loss: 2.544929400940602

Epoch: 88| Step: 0
Training loss: 2.4264827088785976
Validation loss: 2.5210732957947837

Epoch: 6| Step: 1
Training loss: 2.106796836613963
Validation loss: 2.55532502318611

Epoch: 6| Step: 2
Training loss: 1.8556489555788678
Validation loss: 2.5632154659940083

Epoch: 6| Step: 3
Training loss: 2.871558908162832
Validation loss: 2.5328825721092256

Epoch: 6| Step: 4
Training loss: 2.339069219157851
Validation loss: 2.581264333862211

Epoch: 6| Step: 5
Training loss: 2.2461534044387914
Validation loss: 2.57952850363217

Epoch: 6| Step: 6
Training loss: 2.4059345979941846
Validation loss: 2.543260283198095

Epoch: 6| Step: 7
Training loss: 2.035624210496889
Validation loss: 2.6061551449572993

Epoch: 6| Step: 8
Training loss: 2.2101788516623375
Validation loss: 2.5030024618760796

Epoch: 6| Step: 9
Training loss: 2.304260835108695
Validation loss: 2.5388037603544076

Epoch: 6| Step: 10
Training loss: 2.0663356372327906
Validation loss: 2.543899311179376

Epoch: 6| Step: 11
Training loss: 1.9241100433904315
Validation loss: 2.540238398643051

Epoch: 6| Step: 12
Training loss: 1.9081943164259012
Validation loss: 2.5324538394076344

Epoch: 6| Step: 13
Training loss: 1.57908586011828
Validation loss: 2.6255887294759077

Epoch: 89| Step: 0
Training loss: 2.5089171641584516
Validation loss: 2.6315191395555395

Epoch: 6| Step: 1
Training loss: 2.709505785961066
Validation loss: 2.669586197746514

Epoch: 6| Step: 2
Training loss: 2.3143966732303194
Validation loss: 2.5883277687001476

Epoch: 6| Step: 3
Training loss: 1.7324013004564978
Validation loss: 2.6183432688808868

Epoch: 6| Step: 4
Training loss: 1.832435156701493
Validation loss: 2.616597935711386

Epoch: 6| Step: 5
Training loss: 3.380926227404462
Validation loss: 2.556332399863627

Epoch: 6| Step: 6
Training loss: 1.8068876520305701
Validation loss: 2.645558370485196

Epoch: 6| Step: 7
Training loss: 1.8362880940183102
Validation loss: 2.5808514984012203

Epoch: 6| Step: 8
Training loss: 2.1037939767666622
Validation loss: 2.6277711863722963

Epoch: 6| Step: 9
Training loss: 1.8113765523334076
Validation loss: 2.5673533433471016

Epoch: 6| Step: 10
Training loss: 1.7382102008829696
Validation loss: 2.6216586812215623

Epoch: 6| Step: 11
Training loss: 2.860339059538652
Validation loss: 2.6549598851977936

Epoch: 6| Step: 12
Training loss: 1.703250005491641
Validation loss: 2.6031058833964744

Epoch: 6| Step: 13
Training loss: 2.441767453748873
Validation loss: 2.6083735449700622

Epoch: 90| Step: 0
Training loss: 2.048435693619293
Validation loss: 2.583201610119222

Epoch: 6| Step: 1
Training loss: 2.1417146679833836
Validation loss: 2.601038791307096

Epoch: 6| Step: 2
Training loss: 1.9375447298854824
Validation loss: 2.643243127544848

Epoch: 6| Step: 3
Training loss: 2.431650135680447
Validation loss: 2.5911517016984953

Epoch: 6| Step: 4
Training loss: 2.6805060112502783
Validation loss: 2.631342521846989

Epoch: 6| Step: 5
Training loss: 2.536726783995834
Validation loss: 2.5625825729091942

Epoch: 6| Step: 6
Training loss: 2.6142586332939035
Validation loss: 2.5717718123002347

Epoch: 6| Step: 7
Training loss: 2.0214572480818767
Validation loss: 2.532810138542052

Epoch: 6| Step: 8
Training loss: 1.7280407959219612
Validation loss: 2.533207799494932

Epoch: 6| Step: 9
Training loss: 2.0565648078528733
Validation loss: 2.5453404209017636

Epoch: 6| Step: 10
Training loss: 2.1231809571994
Validation loss: 2.5041539173362346

Epoch: 6| Step: 11
Training loss: 2.369413732777109
Validation loss: 2.4814824473467203

Epoch: 6| Step: 12
Training loss: 2.664778627143979
Validation loss: 2.5469543039031652

Epoch: 6| Step: 13
Training loss: 2.026012887889243
Validation loss: 2.594384050812201

Epoch: 91| Step: 0
Training loss: 2.5067880980351984
Validation loss: 2.5570164290869952

Epoch: 6| Step: 1
Training loss: 1.882339228113797
Validation loss: 2.64580120357519

Epoch: 6| Step: 2
Training loss: 1.9665162872214164
Validation loss: 2.6436537728859975

Epoch: 6| Step: 3
Training loss: 1.778993817344931
Validation loss: 2.646765031748289

Epoch: 6| Step: 4
Training loss: 2.405792985592561
Validation loss: 2.528520391766091

Epoch: 6| Step: 5
Training loss: 3.378438540154977
Validation loss: 2.588565163662428

Epoch: 6| Step: 6
Training loss: 1.5331440324997676
Validation loss: 2.688334948930848

Epoch: 6| Step: 7
Training loss: 2.0710641324268546
Validation loss: 2.4983835557653165

Epoch: 6| Step: 8
Training loss: 2.7710098172154662
Validation loss: 2.5948907572660502

Epoch: 6| Step: 9
Training loss: 1.8626585745670958
Validation loss: 2.6062223382666536

Epoch: 6| Step: 10
Training loss: 1.6106325439939617
Validation loss: 2.5823312989999954

Epoch: 6| Step: 11
Training loss: 2.453552889104404
Validation loss: 2.5661412551763685

Epoch: 6| Step: 12
Training loss: 2.1780359717937374
Validation loss: 2.501628996683832

Epoch: 6| Step: 13
Training loss: 1.80161118983356
Validation loss: 2.523582879475813

Epoch: 92| Step: 0
Training loss: 2.2729944800306927
Validation loss: 2.525572244869945

Epoch: 6| Step: 1
Training loss: 2.5096383266597697
Validation loss: 2.4663112360677624

Epoch: 6| Step: 2
Training loss: 2.6208856218597356
Validation loss: 2.544260543651461

Epoch: 6| Step: 3
Training loss: 2.2886219837632007
Validation loss: 2.5398902209029997

Epoch: 6| Step: 4
Training loss: 1.8585076112096157
Validation loss: 2.5230321489695666

Epoch: 6| Step: 5
Training loss: 1.6129832881622255
Validation loss: 2.6034300156426484

Epoch: 6| Step: 6
Training loss: 2.415080525574111
Validation loss: 2.5910527939442622

Epoch: 6| Step: 7
Training loss: 2.345414651352674
Validation loss: 2.5693171157447163

Epoch: 6| Step: 8
Training loss: 2.2373299432841742
Validation loss: 2.623267904149928

Epoch: 6| Step: 9
Training loss: 1.6400550942354606
Validation loss: 2.5755901012356626

Epoch: 6| Step: 10
Training loss: 1.2571492312241876
Validation loss: 2.5060858402412385

Epoch: 6| Step: 11
Training loss: 2.546660806272997
Validation loss: 2.6051076994419504

Epoch: 6| Step: 12
Training loss: 2.2578697329332345
Validation loss: 2.577136881114456

Epoch: 6| Step: 13
Training loss: 2.6484850313765755
Validation loss: 2.5211326300593377

Epoch: 93| Step: 0
Training loss: 2.632383951235768
Validation loss: 2.5082629661786373

Epoch: 6| Step: 1
Training loss: 2.2071722205047837
Validation loss: 2.5510505506849652

Epoch: 6| Step: 2
Training loss: 2.289716086966053
Validation loss: 2.5668919150692475

Epoch: 6| Step: 3
Training loss: 1.5706579483164822
Validation loss: 2.5486327270598226

Epoch: 6| Step: 4
Training loss: 2.0629923839641156
Validation loss: 2.5477575009637077

Epoch: 6| Step: 5
Training loss: 1.8960538114122378
Validation loss: 2.488358971995344

Epoch: 6| Step: 6
Training loss: 2.1138574516285775
Validation loss: 2.5511401295432994

Epoch: 6| Step: 7
Training loss: 2.333700276086708
Validation loss: 2.5938575293377695

Epoch: 6| Step: 8
Training loss: 1.7898902144409827
Validation loss: 2.6122976751025426

Epoch: 6| Step: 9
Training loss: 2.1812711042459867
Validation loss: 2.5610171578947316

Epoch: 6| Step: 10
Training loss: 1.9790439634601
Validation loss: 2.5484377897080366

Epoch: 6| Step: 11
Training loss: 1.9840367547060862
Validation loss: 2.5201009574477293

Epoch: 6| Step: 12
Training loss: 2.9347472583404715
Validation loss: 2.613319157210002

Epoch: 6| Step: 13
Training loss: 2.3538520287650906
Validation loss: 2.6261641025309985

Epoch: 94| Step: 0
Training loss: 1.2302389263297326
Validation loss: 2.6414883347816387

Epoch: 6| Step: 1
Training loss: 1.6352584989158037
Validation loss: 2.5411226805669282

Epoch: 6| Step: 2
Training loss: 2.4293367678551347
Validation loss: 2.5531996692335928

Epoch: 6| Step: 3
Training loss: 2.509672431848317
Validation loss: 2.5879938529677107

Epoch: 6| Step: 4
Training loss: 2.681592080940353
Validation loss: 2.6504740878751942

Epoch: 6| Step: 5
Training loss: 2.2237263066368156
Validation loss: 2.5992646326713107

Epoch: 6| Step: 6
Training loss: 2.895376228829291
Validation loss: 2.573818239305078

Epoch: 6| Step: 7
Training loss: 2.182461631061845
Validation loss: 2.5382646921169028

Epoch: 6| Step: 8
Training loss: 2.03609428826715
Validation loss: 2.562580417518718

Epoch: 6| Step: 9
Training loss: 1.8647513997576055
Validation loss: 2.5493298812555873

Epoch: 6| Step: 10
Training loss: 2.4412932591040803
Validation loss: 2.541539663258109

Epoch: 6| Step: 11
Training loss: 1.8194247196995226
Validation loss: 2.53368017704239

Epoch: 6| Step: 12
Training loss: 1.9978244392924958
Validation loss: 2.5275793579904735

Epoch: 6| Step: 13
Training loss: 2.292434656174965
Validation loss: 2.539402286584173

Epoch: 95| Step: 0
Training loss: 1.9224057588929948
Validation loss: 2.512399315279583

Epoch: 6| Step: 1
Training loss: 2.3072260954231623
Validation loss: 2.557704842953901

Epoch: 6| Step: 2
Training loss: 1.8361912978042234
Validation loss: 2.5633183854968995

Epoch: 6| Step: 3
Training loss: 2.5869662264111213
Validation loss: 2.530046797132363

Epoch: 6| Step: 4
Training loss: 2.614226895741962
Validation loss: 2.59420453727015

Epoch: 6| Step: 5
Training loss: 2.227408693370996
Validation loss: 2.606852456160514

Epoch: 6| Step: 6
Training loss: 2.29208268522073
Validation loss: 2.573299515898105

Epoch: 6| Step: 7
Training loss: 2.4748340435453082
Validation loss: 2.5693267818236087

Epoch: 6| Step: 8
Training loss: 1.977018642941582
Validation loss: 2.585390138656504

Epoch: 6| Step: 9
Training loss: 1.48938059816577
Validation loss: 2.5998807326495927

Epoch: 6| Step: 10
Training loss: 2.1964578593358297
Validation loss: 2.6468910045657847

Epoch: 6| Step: 11
Training loss: 2.5772061646859785
Validation loss: 2.6003481729618083

Epoch: 6| Step: 12
Training loss: 2.070649432709736
Validation loss: 2.6555806532098996

Epoch: 6| Step: 13
Training loss: 1.7624473672136953
Validation loss: 2.657805619332753

Epoch: 96| Step: 0
Training loss: 2.3511720250781334
Validation loss: 2.6034205982888445

Epoch: 6| Step: 1
Training loss: 2.1462177808739384
Validation loss: 2.5677371278170966

Epoch: 6| Step: 2
Training loss: 2.2060582539604305
Validation loss: 2.526380839960373

Epoch: 6| Step: 3
Training loss: 1.7421664933789955
Validation loss: 2.579982712488142

Epoch: 6| Step: 4
Training loss: 2.0625077449768763
Validation loss: 2.469466479670025

Epoch: 6| Step: 5
Training loss: 2.6619510281684726
Validation loss: 2.512179081856795

Epoch: 6| Step: 6
Training loss: 2.0479621620855166
Validation loss: 2.4768557049043607

Epoch: 6| Step: 7
Training loss: 2.2843320745983
Validation loss: 2.5429561241606047

Epoch: 6| Step: 8
Training loss: 1.8107460348635442
Validation loss: 2.5746705464831527

Epoch: 6| Step: 9
Training loss: 1.9657193426589141
Validation loss: 2.5031032534324176

Epoch: 6| Step: 10
Training loss: 2.4334842173509554
Validation loss: 2.617301703091739

Epoch: 6| Step: 11
Training loss: 2.866022938894085
Validation loss: 2.521390905797484

Epoch: 6| Step: 12
Training loss: 2.339509000698515
Validation loss: 2.5937592379853607

Epoch: 6| Step: 13
Training loss: 1.8033460114692104
Validation loss: 2.575553598121592

Epoch: 97| Step: 0
Training loss: 1.7623059294428947
Validation loss: 2.6455043427989198

Epoch: 6| Step: 1
Training loss: 3.110798418891606
Validation loss: 2.6841933734097725

Epoch: 6| Step: 2
Training loss: 2.3181267407108126
Validation loss: 2.6731322752846363

Epoch: 6| Step: 3
Training loss: 2.2028059491663394
Validation loss: 2.5774606330349195

Epoch: 6| Step: 4
Training loss: 1.9372441522813009
Validation loss: 2.5214893391247855

Epoch: 6| Step: 5
Training loss: 1.8316682565744087
Validation loss: 2.599280134217099

Epoch: 6| Step: 6
Training loss: 1.8753322942649295
Validation loss: 2.608503839649984

Epoch: 6| Step: 7
Training loss: 1.8590939734162977
Validation loss: 2.557625483979719

Epoch: 6| Step: 8
Training loss: 2.3273152216775976
Validation loss: 2.4991808502958226

Epoch: 6| Step: 9
Training loss: 2.339574120068321
Validation loss: 2.4823628320282896

Epoch: 6| Step: 10
Training loss: 1.356489868750529
Validation loss: 2.525304782526615

Epoch: 6| Step: 11
Training loss: 2.3506703252664716
Validation loss: 2.5276447099260824

Epoch: 6| Step: 12
Training loss: 2.449232864947615
Validation loss: 2.611268793467276

Epoch: 6| Step: 13
Training loss: 1.884778907215181
Validation loss: 2.5462668693331993

Epoch: 98| Step: 0
Training loss: 2.0381932068156163
Validation loss: 2.5349417871516575

Epoch: 6| Step: 1
Training loss: 1.7311708563056172
Validation loss: 2.5339464809202528

Epoch: 6| Step: 2
Training loss: 2.50995143098688
Validation loss: 2.5780386862129663

Epoch: 6| Step: 3
Training loss: 2.721295622906217
Validation loss: 2.5919598909275123

Epoch: 6| Step: 4
Training loss: 2.140972582588519
Validation loss: 2.4936916870335972

Epoch: 6| Step: 5
Training loss: 2.3048430826722646
Validation loss: 2.6109801664277272

Epoch: 6| Step: 6
Training loss: 1.9108809206205781
Validation loss: 2.5792265571292283

Epoch: 6| Step: 7
Training loss: 2.754087531433658
Validation loss: 2.621034866937482

Epoch: 6| Step: 8
Training loss: 1.7781035088445452
Validation loss: 2.5116687016224692

Epoch: 6| Step: 9
Training loss: 1.9541684224568865
Validation loss: 2.6364119136908255

Epoch: 6| Step: 10
Training loss: 1.5659986617324977
Validation loss: 2.589225607050638

Epoch: 6| Step: 11
Training loss: 2.126824100949153
Validation loss: 2.6413686784811805

Epoch: 6| Step: 12
Training loss: 1.5303078691982308
Validation loss: 2.514827167369015

Epoch: 6| Step: 13
Training loss: 2.2472671230290615
Validation loss: 2.5965572240787114

Epoch: 99| Step: 0
Training loss: 1.8786443896632248
Validation loss: 2.6757661767985197

Epoch: 6| Step: 1
Training loss: 1.6521668395801028
Validation loss: 2.6204961407191516

Epoch: 6| Step: 2
Training loss: 1.7710576158496532
Validation loss: 2.4964121027006363

Epoch: 6| Step: 3
Training loss: 2.8023777538796324
Validation loss: 2.5600690631069107

Epoch: 6| Step: 4
Training loss: 2.2063569515770145
Validation loss: 2.5473063753048195

Epoch: 6| Step: 5
Training loss: 2.356812759504203
Validation loss: 2.551823915544373

Epoch: 6| Step: 6
Training loss: 2.384554666971976
Validation loss: 2.527409202360986

Epoch: 6| Step: 7
Training loss: 2.14794139335995
Validation loss: 2.5722817217941834

Epoch: 6| Step: 8
Training loss: 1.9473136199576728
Validation loss: 2.5760472797518266

Epoch: 6| Step: 9
Training loss: 2.1231677065718317
Validation loss: 2.6156650347211343

Epoch: 6| Step: 10
Training loss: 1.6494874909647304
Validation loss: 2.578343206862236

Epoch: 6| Step: 11
Training loss: 1.7921878884538731
Validation loss: 2.614872682120908

Epoch: 6| Step: 12
Training loss: 2.4329486316380486
Validation loss: 2.5896322663630853

Epoch: 6| Step: 13
Training loss: 2.53600335919973
Validation loss: 2.5628563702897003

Epoch: 100| Step: 0
Training loss: 1.932267414225294
Validation loss: 2.623894004341154

Epoch: 6| Step: 1
Training loss: 2.0361009627305147
Validation loss: 2.594804924607273

Epoch: 6| Step: 2
Training loss: 1.9190607322556765
Validation loss: 2.5885018563743176

Epoch: 6| Step: 3
Training loss: 2.6566843911811775
Validation loss: 2.6517684080297097

Epoch: 6| Step: 4
Training loss: 2.1990257707016445
Validation loss: 2.607264047482237

Epoch: 6| Step: 5
Training loss: 2.1630990538188675
Validation loss: 2.5809046701342537

Epoch: 6| Step: 6
Training loss: 2.3492177635320197
Validation loss: 2.6665160365079945

Epoch: 6| Step: 7
Training loss: 2.170761152105912
Validation loss: 2.5734573033058608

Epoch: 6| Step: 8
Training loss: 1.3605587069719511
Validation loss: 2.593542174933379

Epoch: 6| Step: 9
Training loss: 2.341558627241601
Validation loss: 2.61744872350544

Epoch: 6| Step: 10
Training loss: 2.260135709350794
Validation loss: 2.5501817950102548

Epoch: 6| Step: 11
Training loss: 2.7331859510121257
Validation loss: 2.624328058011786

Epoch: 6| Step: 12
Training loss: 1.4337838278174604
Validation loss: 2.626794209453737

Epoch: 6| Step: 13
Training loss: 1.9165166575013703
Validation loss: 2.503562050587983

Epoch: 101| Step: 0
Training loss: 1.9790046893310504
Validation loss: 2.5420623585935553

Epoch: 6| Step: 1
Training loss: 2.219511626713071
Validation loss: 2.5137682552676988

Epoch: 6| Step: 2
Training loss: 1.7119575142446186
Validation loss: 2.6157568214344815

Epoch: 6| Step: 3
Training loss: 2.052397289238498
Validation loss: 2.6424340366008883

Epoch: 6| Step: 4
Training loss: 2.0844001962948977
Validation loss: 2.6663393450559263

Epoch: 6| Step: 5
Training loss: 2.4562381501433705
Validation loss: 2.660582961459089

Epoch: 6| Step: 6
Training loss: 2.2256140043891715
Validation loss: 2.6513624215829634

Epoch: 6| Step: 7
Training loss: 1.690891108132924
Validation loss: 2.580223947620747

Epoch: 6| Step: 8
Training loss: 1.8842181898066093
Validation loss: 2.552342418572614

Epoch: 6| Step: 9
Training loss: 1.9119246396531984
Validation loss: 2.571040304581472

Epoch: 6| Step: 10
Training loss: 2.139716519448278
Validation loss: 2.497244747127699

Epoch: 6| Step: 11
Training loss: 1.957946258871158
Validation loss: 2.626011244948077

Epoch: 6| Step: 12
Training loss: 2.8442600337821626
Validation loss: 2.5506733690925887

Epoch: 6| Step: 13
Training loss: 2.3104634983371706
Validation loss: 2.5347960480226024

Epoch: 102| Step: 0
Training loss: 2.355411661699359
Validation loss: 2.6616698975405098

Epoch: 6| Step: 1
Training loss: 2.7098133053818327
Validation loss: 2.529886891245361

Epoch: 6| Step: 2
Training loss: 2.7771895697139457
Validation loss: 2.4812719131129874

Epoch: 6| Step: 3
Training loss: 1.8737703741898712
Validation loss: 2.6356341356458812

Epoch: 6| Step: 4
Training loss: 2.2041755498215547
Validation loss: 2.580900836448145

Epoch: 6| Step: 5
Training loss: 1.8531841146422692
Validation loss: 2.5840872976921885

Epoch: 6| Step: 6
Training loss: 1.7977735843355436
Validation loss: 2.494297613123759

Epoch: 6| Step: 7
Training loss: 2.1606627934433025
Validation loss: 2.557273287166475

Epoch: 6| Step: 8
Training loss: 1.930812615799452
Validation loss: 2.613990615187719

Epoch: 6| Step: 9
Training loss: 2.0700655807942563
Validation loss: 2.5633694949118953

Epoch: 6| Step: 10
Training loss: 1.9116427326561034
Validation loss: 2.5533100423754895

Epoch: 6| Step: 11
Training loss: 1.9128042016537228
Validation loss: 2.623702682351958

Epoch: 6| Step: 12
Training loss: 2.001523986969994
Validation loss: 2.588224246994708

Epoch: 6| Step: 13
Training loss: 1.2838548836954318
Validation loss: 2.6684162291501647

Epoch: 103| Step: 0
Training loss: 2.4862120931659453
Validation loss: 2.690852846075078

Epoch: 6| Step: 1
Training loss: 2.073162377394012
Validation loss: 2.692574286798261

Epoch: 6| Step: 2
Training loss: 2.8417861361480945
Validation loss: 2.6475204635564107

Epoch: 6| Step: 3
Training loss: 2.364405542711329
Validation loss: 2.7123599905512354

Epoch: 6| Step: 4
Training loss: 2.6281268252480934
Validation loss: 2.631191958574831

Epoch: 6| Step: 5
Training loss: 1.6632138089420045
Validation loss: 2.590982868430929

Epoch: 6| Step: 6
Training loss: 1.934092694267343
Validation loss: 2.5774874891192714

Epoch: 6| Step: 7
Training loss: 2.3684380882052065
Validation loss: 2.5699909167494113

Epoch: 6| Step: 8
Training loss: 1.5938144745594405
Validation loss: 2.5815490487848853

Epoch: 6| Step: 9
Training loss: 2.3532833253808136
Validation loss: 2.6104829000933307

Epoch: 6| Step: 10
Training loss: 1.693643407529184
Validation loss: 2.573616787151133

Epoch: 6| Step: 11
Training loss: 1.649084895135337
Validation loss: 2.5041193720138106

Epoch: 6| Step: 12
Training loss: 2.4006016811518465
Validation loss: 2.561072161091688

Epoch: 6| Step: 13
Training loss: 1.9128966225640485
Validation loss: 2.604553000721487

Epoch: 104| Step: 0
Training loss: 1.9311211083124986
Validation loss: 2.582411852942039

Epoch: 6| Step: 1
Training loss: 2.326540414104581
Validation loss: 2.6418755483826044

Epoch: 6| Step: 2
Training loss: 2.1323581533000766
Validation loss: 2.4893321358804354

Epoch: 6| Step: 3
Training loss: 1.8246777628857516
Validation loss: 2.541262240101261

Epoch: 6| Step: 4
Training loss: 1.801171250220153
Validation loss: 2.5201491275945056

Epoch: 6| Step: 5
Training loss: 1.7836162176400543
Validation loss: 2.585200901131992

Epoch: 6| Step: 6
Training loss: 1.9539207363392417
Validation loss: 2.620796486171506

Epoch: 6| Step: 7
Training loss: 1.8016482436196564
Validation loss: 2.541383732749612

Epoch: 6| Step: 8
Training loss: 1.9885328691973014
Validation loss: 2.5662451876920214

Epoch: 6| Step: 9
Training loss: 2.174422601813096
Validation loss: 2.6256305754633464

Epoch: 6| Step: 10
Training loss: 2.427178660691365
Validation loss: 2.5372552631536704

Epoch: 6| Step: 11
Training loss: 1.8817526972621998
Validation loss: 2.6082135811840326

Epoch: 6| Step: 12
Training loss: 1.7008639384308326
Validation loss: 2.6379039973262683

Epoch: 6| Step: 13
Training loss: 2.723361696992837
Validation loss: 2.568949731392633

Epoch: 105| Step: 0
Training loss: 2.222722754799201
Validation loss: 2.550812483981381

Epoch: 6| Step: 1
Training loss: 2.2101262090211606
Validation loss: 2.6285502177102376

Epoch: 6| Step: 2
Training loss: 2.0450421929145572
Validation loss: 2.6098228572787296

Epoch: 6| Step: 3
Training loss: 2.0421151297952385
Validation loss: 2.549916890603852

Epoch: 6| Step: 4
Training loss: 1.7801375010241456
Validation loss: 2.636696204571822

Epoch: 6| Step: 5
Training loss: 1.7008294550346679
Validation loss: 2.575800392913571

Epoch: 6| Step: 6
Training loss: 1.9348779594516554
Validation loss: 2.534907598698744

Epoch: 6| Step: 7
Training loss: 1.781045199215323
Validation loss: 2.5780497222082865

Epoch: 6| Step: 8
Training loss: 2.8161136723897195
Validation loss: 2.489519020005355

Epoch: 6| Step: 9
Training loss: 2.050848445699731
Validation loss: 2.4427436929080684

Epoch: 6| Step: 10
Training loss: 1.8952381191769407
Validation loss: 2.563099651420617

Epoch: 6| Step: 11
Training loss: 2.320313733033132
Validation loss: 2.559305797630326

Epoch: 6| Step: 12
Training loss: 1.8133655980456045
Validation loss: 2.4998390463833213

Epoch: 6| Step: 13
Training loss: 2.253512396027382
Validation loss: 2.499412372192374

Epoch: 106| Step: 0
Training loss: 1.658362427013786
Validation loss: 2.464611076742711

Epoch: 6| Step: 1
Training loss: 2.4673980681014864
Validation loss: 2.57815986378534

Epoch: 6| Step: 2
Training loss: 1.704353729216034
Validation loss: 2.50618248053439

Epoch: 6| Step: 3
Training loss: 1.2597517145852641
Validation loss: 2.5553900854010685

Epoch: 6| Step: 4
Training loss: 2.4745260343540627
Validation loss: 2.6211523891812134

Epoch: 6| Step: 5
Training loss: 1.9609134262248615
Validation loss: 2.5460357687505977

Epoch: 6| Step: 6
Training loss: 2.456861723614331
Validation loss: 2.606647261143263

Epoch: 6| Step: 7
Training loss: 1.6275785968043555
Validation loss: 2.6431307819766556

Epoch: 6| Step: 8
Training loss: 2.1823723777345783
Validation loss: 2.50361145156754

Epoch: 6| Step: 9
Training loss: 2.070937382663662
Validation loss: 2.5904433533012448

Epoch: 6| Step: 10
Training loss: 1.8404475231777975
Validation loss: 2.5171878217195336

Epoch: 6| Step: 11
Training loss: 2.0686968563203285
Validation loss: 2.584842138727453

Epoch: 6| Step: 12
Training loss: 2.9440926775546252
Validation loss: 2.498762340950908

Epoch: 6| Step: 13
Training loss: 1.9244773427690494
Validation loss: 2.5543433063489442

Epoch: 107| Step: 0
Training loss: 1.9993166352100806
Validation loss: 2.633254454634527

Epoch: 6| Step: 1
Training loss: 1.519041399217688
Validation loss: 2.5500600514789618

Epoch: 6| Step: 2
Training loss: 1.8676219737959863
Validation loss: 2.5657198533348113

Epoch: 6| Step: 3
Training loss: 2.3173455686666893
Validation loss: 2.507306389527043

Epoch: 6| Step: 4
Training loss: 2.589346491283584
Validation loss: 2.5957960844556527

Epoch: 6| Step: 5
Training loss: 1.9354766617404846
Validation loss: 2.6414061525170514

Epoch: 6| Step: 6
Training loss: 2.1145310293659945
Validation loss: 2.7000007435126516

Epoch: 6| Step: 7
Training loss: 2.5353867436327775
Validation loss: 2.756942179433649

Epoch: 6| Step: 8
Training loss: 1.8014513204764615
Validation loss: 2.6919779324933115

Epoch: 6| Step: 9
Training loss: 2.62456735951194
Validation loss: 2.5846472495678574

Epoch: 6| Step: 10
Training loss: 1.7523029705307829
Validation loss: 2.532668418794638

Epoch: 6| Step: 11
Training loss: 1.520600166039619
Validation loss: 2.5446874042585765

Epoch: 6| Step: 12
Training loss: 2.0733318839522976
Validation loss: 2.582603987415534

Epoch: 6| Step: 13
Training loss: 2.097050812083358
Validation loss: 2.5618255316872154

Epoch: 108| Step: 0
Training loss: 2.0709242582667726
Validation loss: 2.521227093883954

Epoch: 6| Step: 1
Training loss: 2.107586137452566
Validation loss: 2.500119007774831

Epoch: 6| Step: 2
Training loss: 2.977341277202299
Validation loss: 2.6216510117781455

Epoch: 6| Step: 3
Training loss: 2.4864740680973934
Validation loss: 2.493909537837789

Epoch: 6| Step: 4
Training loss: 2.1581030360699724
Validation loss: 2.5372271668281297

Epoch: 6| Step: 5
Training loss: 2.395658094106382
Validation loss: 2.4755951669936023

Epoch: 6| Step: 6
Training loss: 1.8880629401060764
Validation loss: 2.5803512979222196

Epoch: 6| Step: 7
Training loss: 2.0183988897679646
Validation loss: 2.5103688426758466

Epoch: 6| Step: 8
Training loss: 1.7932317536714233
Validation loss: 2.5962816927840717

Epoch: 6| Step: 9
Training loss: 2.0628664095843687
Validation loss: 2.6610080216105403

Epoch: 6| Step: 10
Training loss: 1.9581166073071057
Validation loss: 2.6219321746715107

Epoch: 6| Step: 11
Training loss: 1.8008703511799602
Validation loss: 2.6294185749490686

Epoch: 6| Step: 12
Training loss: 1.1027196663589383
Validation loss: 2.5992624006857037

Epoch: 6| Step: 13
Training loss: 1.9704063350831202
Validation loss: 2.6557508411010535

Epoch: 109| Step: 0
Training loss: 3.501643067658211
Validation loss: 2.648016349442844

Epoch: 6| Step: 1
Training loss: 1.700143146098034
Validation loss: 2.5542333512264093

Epoch: 6| Step: 2
Training loss: 2.208616730361631
Validation loss: 2.5401438909358527

Epoch: 6| Step: 3
Training loss: 1.57335925243871
Validation loss: 2.544205622128544

Epoch: 6| Step: 4
Training loss: 1.5213488223373675
Validation loss: 2.55404033493667

Epoch: 6| Step: 5
Training loss: 1.8529118638876738
Validation loss: 2.5622437201641435

Epoch: 6| Step: 6
Training loss: 1.9680536643286661
Validation loss: 2.4985888631114204

Epoch: 6| Step: 7
Training loss: 2.1798663322345964
Validation loss: 2.5709062255797055

Epoch: 6| Step: 8
Training loss: 2.324593752573114
Validation loss: 2.6023634173183448

Epoch: 6| Step: 9
Training loss: 1.8497078536019567
Validation loss: 2.551087404409366

Epoch: 6| Step: 10
Training loss: 1.3407744353267559
Validation loss: 2.5951332478990348

Epoch: 6| Step: 11
Training loss: 2.1632226078437755
Validation loss: 2.525205097429829

Epoch: 6| Step: 12
Training loss: 1.5742369998602899
Validation loss: 2.5229337049602454

Epoch: 6| Step: 13
Training loss: 1.8262817349767377
Validation loss: 2.6486805942113856

Epoch: 110| Step: 0
Training loss: 2.0406350104888222
Validation loss: 2.727263264928644

Epoch: 6| Step: 1
Training loss: 1.671349630075275
Validation loss: 2.6402594258741234

Epoch: 6| Step: 2
Training loss: 1.8427353346078963
Validation loss: 2.6250105812222797

Epoch: 6| Step: 3
Training loss: 2.055672645097879
Validation loss: 2.647358324704655

Epoch: 6| Step: 4
Training loss: 2.785166179965643
Validation loss: 2.698540565099594

Epoch: 6| Step: 5
Training loss: 2.1173629406525305
Validation loss: 2.53764220592489

Epoch: 6| Step: 6
Training loss: 2.2253406049648823
Validation loss: 2.519513586016892

Epoch: 6| Step: 7
Training loss: 2.1056032721694056
Validation loss: 2.518525136118757

Epoch: 6| Step: 8
Training loss: 1.8484919716555175
Validation loss: 2.545728725858554

Epoch: 6| Step: 9
Training loss: 2.178236173969628
Validation loss: 2.447292480970876

Epoch: 6| Step: 10
Training loss: 1.8209976413131261
Validation loss: 2.5555600728349797

Epoch: 6| Step: 11
Training loss: 2.245998320832818
Validation loss: 2.603277471686265

Epoch: 6| Step: 12
Training loss: 2.0739136667261953
Validation loss: 2.469440444134434

Epoch: 6| Step: 13
Training loss: 1.590540627750637
Validation loss: 2.598821652984091

Epoch: 111| Step: 0
Training loss: 1.606910077145798
Validation loss: 2.60631682068617

Epoch: 6| Step: 1
Training loss: 1.9134797123774727
Validation loss: 2.640555266112252

Epoch: 6| Step: 2
Training loss: 2.278574066485165
Validation loss: 2.6028019088265215

Epoch: 6| Step: 3
Training loss: 2.639903675402812
Validation loss: 2.6517954256296736

Epoch: 6| Step: 4
Training loss: 1.7696770277459495
Validation loss: 2.566606549595206

Epoch: 6| Step: 5
Training loss: 1.8606901886898697
Validation loss: 2.6578391613334125

Epoch: 6| Step: 6
Training loss: 1.7222911075775555
Validation loss: 2.634054311809816

Epoch: 6| Step: 7
Training loss: 1.9803851409057256
Validation loss: 2.5266033269178214

Epoch: 6| Step: 8
Training loss: 2.45334745722658
Validation loss: 2.5368040790467123

Epoch: 6| Step: 9
Training loss: 2.2070756485785856
Validation loss: 2.4784380592772353

Epoch: 6| Step: 10
Training loss: 1.8809457602622959
Validation loss: 2.5250571833011697

Epoch: 6| Step: 11
Training loss: 1.685379249839571
Validation loss: 2.6016875152029497

Epoch: 6| Step: 12
Training loss: 1.9928610467164476
Validation loss: 2.5879422318213257

Epoch: 6| Step: 13
Training loss: 2.235349535993238
Validation loss: 2.581983741865674

Epoch: 112| Step: 0
Training loss: 2.4208070430761577
Validation loss: 2.491008914346057

Epoch: 6| Step: 1
Training loss: 1.7333712723443573
Validation loss: 2.5269952029600455

Epoch: 6| Step: 2
Training loss: 1.4715401951040565
Validation loss: 2.5424336125731655

Epoch: 6| Step: 3
Training loss: 1.7665897535579953
Validation loss: 2.5729641517447805

Epoch: 6| Step: 4
Training loss: 2.127905262093066
Validation loss: 2.5962131708110654

Epoch: 6| Step: 5
Training loss: 1.6371372752996798
Validation loss: 2.578189425193298

Epoch: 6| Step: 6
Training loss: 2.6340319246053356
Validation loss: 2.628748314143916

Epoch: 6| Step: 7
Training loss: 1.9823488118655876
Validation loss: 2.5451452938367587

Epoch: 6| Step: 8
Training loss: 1.8867511628014548
Validation loss: 2.6786520155636864

Epoch: 6| Step: 9
Training loss: 1.9212526383688984
Validation loss: 2.6199551121188547

Epoch: 6| Step: 10
Training loss: 1.761021715128861
Validation loss: 2.683602560251906

Epoch: 6| Step: 11
Training loss: 1.9339526527313413
Validation loss: 2.6752839826012993

Epoch: 6| Step: 12
Training loss: 2.112042809847244
Validation loss: 2.5206535580006757

Epoch: 6| Step: 13
Training loss: 2.0606302976670343
Validation loss: 2.5903330437085677

Epoch: 113| Step: 0
Training loss: 2.536864658737815
Validation loss: 2.5316209403557206

Epoch: 6| Step: 1
Training loss: 2.0676711020652965
Validation loss: 2.583853397524339

Epoch: 6| Step: 2
Training loss: 2.143080256972073
Validation loss: 2.609032621783339

Epoch: 6| Step: 3
Training loss: 1.8624159365122903
Validation loss: 2.5638856320436823

Epoch: 6| Step: 4
Training loss: 2.598909417088953
Validation loss: 2.4979964015813625

Epoch: 6| Step: 5
Training loss: 1.3591870583587768
Validation loss: 2.5425153680697647

Epoch: 6| Step: 6
Training loss: 1.6680340720614377
Validation loss: 2.476862587382289

Epoch: 6| Step: 7
Training loss: 2.093132725152072
Validation loss: 2.5045869470355635

Epoch: 6| Step: 8
Training loss: 1.8659310043597555
Validation loss: 2.5747762721745815

Epoch: 6| Step: 9
Training loss: 1.748300203688894
Validation loss: 2.549230621244781

Epoch: 6| Step: 10
Training loss: 1.0756584368866628
Validation loss: 2.615237299884493

Epoch: 6| Step: 11
Training loss: 2.137026023738423
Validation loss: 2.600453641637064

Epoch: 6| Step: 12
Training loss: 1.699782775576373
Validation loss: 2.5907103563948257

Epoch: 6| Step: 13
Training loss: 2.197983606653978
Validation loss: 2.5995347346427153

Epoch: 114| Step: 0
Training loss: 1.9701373948919367
Validation loss: 2.563333236320636

Epoch: 6| Step: 1
Training loss: 1.9597386194641526
Validation loss: 2.6565871080892887

Epoch: 6| Step: 2
Training loss: 2.0233620883630787
Validation loss: 2.3931292380528464

Epoch: 6| Step: 3
Training loss: 2.111939178602502
Validation loss: 2.5137610470304423

Epoch: 6| Step: 4
Training loss: 2.1218673953115292
Validation loss: 2.5582318775632715

Epoch: 6| Step: 5
Training loss: 1.1529332608893463
Validation loss: 2.540952337182052

Epoch: 6| Step: 6
Training loss: 2.3326190354698366
Validation loss: 2.5604641588450447

Epoch: 6| Step: 7
Training loss: 1.7138319919374054
Validation loss: 2.551674834794173

Epoch: 6| Step: 8
Training loss: 1.6292246409033757
Validation loss: 2.5231955838451228

Epoch: 6| Step: 9
Training loss: 2.1210863313492503
Validation loss: 2.5457256664811543

Epoch: 6| Step: 10
Training loss: 1.6161997261695737
Validation loss: 2.625326772060045

Epoch: 6| Step: 11
Training loss: 2.064707528339495
Validation loss: 2.7147395491328177

Epoch: 6| Step: 12
Training loss: 2.2149468722548677
Validation loss: 2.6605225402827353

Epoch: 6| Step: 13
Training loss: 2.2803730781562552
Validation loss: 2.491040610653256

Epoch: 115| Step: 0
Training loss: 1.5718123072716956
Validation loss: 2.656142198955658

Epoch: 6| Step: 1
Training loss: 1.6412911652096838
Validation loss: 2.594506333470892

Epoch: 6| Step: 2
Training loss: 2.0073740439609566
Validation loss: 2.646860378905068

Epoch: 6| Step: 3
Training loss: 1.7620076621383705
Validation loss: 2.491305140248585

Epoch: 6| Step: 4
Training loss: 1.8885155882370048
Validation loss: 2.6226099502041724

Epoch: 6| Step: 5
Training loss: 1.552473706131795
Validation loss: 2.497949395006436

Epoch: 6| Step: 6
Training loss: 2.2833035775726267
Validation loss: 2.6641747832291474

Epoch: 6| Step: 7
Training loss: 1.6293663637483293
Validation loss: 2.607331684662465

Epoch: 6| Step: 8
Training loss: 2.073767891427845
Validation loss: 2.629317759199167

Epoch: 6| Step: 9
Training loss: 1.8160545747009467
Validation loss: 2.5913060788902595

Epoch: 6| Step: 10
Training loss: 2.3769856233655524
Validation loss: 2.6010340553898503

Epoch: 6| Step: 11
Training loss: 2.1389055237666783
Validation loss: 2.4662449033684197

Epoch: 6| Step: 12
Training loss: 1.7589983521714552
Validation loss: 2.5899970544825317

Epoch: 6| Step: 13
Training loss: 2.757371126900335
Validation loss: 2.5875429699657686

Epoch: 116| Step: 0
Training loss: 2.103888150153937
Validation loss: 2.4288035887524155

Epoch: 6| Step: 1
Training loss: 1.528377797566065
Validation loss: 2.5578300132144136

Epoch: 6| Step: 2
Training loss: 2.142026122488666
Validation loss: 2.5534778340273125

Epoch: 6| Step: 3
Training loss: 2.628993130703582
Validation loss: 2.5239484602330573

Epoch: 6| Step: 4
Training loss: 1.671239429060973
Validation loss: 2.6317852970835345

Epoch: 6| Step: 5
Training loss: 1.523252192255418
Validation loss: 2.5729890470838725

Epoch: 6| Step: 6
Training loss: 1.8666754623046917
Validation loss: 2.4840140250409495

Epoch: 6| Step: 7
Training loss: 1.349574263870906
Validation loss: 2.528541764469422

Epoch: 6| Step: 8
Training loss: 2.216152120925704
Validation loss: 2.519628510088806

Epoch: 6| Step: 9
Training loss: 1.3261918753238031
Validation loss: 2.590583108855481

Epoch: 6| Step: 10
Training loss: 1.6897138978657378
Validation loss: 2.5226502031836837

Epoch: 6| Step: 11
Training loss: 2.5844703961147544
Validation loss: 2.5502086890600872

Epoch: 6| Step: 12
Training loss: 1.936668402112401
Validation loss: 2.567274731488845

Epoch: 6| Step: 13
Training loss: 1.8579000184513164
Validation loss: 2.4523351090088488

Epoch: 117| Step: 0
Training loss: 1.3293956288331985
Validation loss: 2.560198091117128

Epoch: 6| Step: 1
Training loss: 2.590038907852439
Validation loss: 2.4503294775122133

Epoch: 6| Step: 2
Training loss: 1.5416855510208034
Validation loss: 2.5540539717173063

Epoch: 6| Step: 3
Training loss: 1.8853660773415357
Validation loss: 2.569391783326432

Epoch: 6| Step: 4
Training loss: 2.6188370246357033
Validation loss: 2.5958508482250817

Epoch: 6| Step: 5
Training loss: 1.8825324392373386
Validation loss: 2.504499439549398

Epoch: 6| Step: 6
Training loss: 1.8106564320952472
Validation loss: 2.5370581594558823

Epoch: 6| Step: 7
Training loss: 1.217688758677538
Validation loss: 2.691977622511174

Epoch: 6| Step: 8
Training loss: 1.6293459511506094
Validation loss: 2.6361637237742066

Epoch: 6| Step: 9
Training loss: 2.788782869741165
Validation loss: 2.7096902578078303

Epoch: 6| Step: 10
Training loss: 1.1954287802790606
Validation loss: 2.6110921832564222

Epoch: 6| Step: 11
Training loss: 1.5180711963930134
Validation loss: 2.62561251291007

Epoch: 6| Step: 12
Training loss: 1.5395369209998915
Validation loss: 2.566644774587167

Epoch: 6| Step: 13
Training loss: 2.0569821153010683
Validation loss: 2.5177439577557106

Epoch: 118| Step: 0
Training loss: 2.545069610453121
Validation loss: 2.505933380421677

Epoch: 6| Step: 1
Training loss: 1.562895991691103
Validation loss: 2.594988668878864

Epoch: 6| Step: 2
Training loss: 1.6882346638011596
Validation loss: 2.510468428356444

Epoch: 6| Step: 3
Training loss: 1.7388068958136078
Validation loss: 2.5189573595436703

Epoch: 6| Step: 4
Training loss: 2.188069405698003
Validation loss: 2.537669702627388

Epoch: 6| Step: 5
Training loss: 2.0239876842350246
Validation loss: 2.6347587025454606

Epoch: 6| Step: 6
Training loss: 1.1247912319178035
Validation loss: 2.564335499080469

Epoch: 6| Step: 7
Training loss: 1.2948975711802972
Validation loss: 2.5889226273651746

Epoch: 6| Step: 8
Training loss: 2.108280038976749
Validation loss: 2.5045428327290646

Epoch: 6| Step: 9
Training loss: 2.0036247308497552
Validation loss: 2.5885353983771853

Epoch: 6| Step: 10
Training loss: 2.0685184406789103
Validation loss: 2.621149645236376

Epoch: 6| Step: 11
Training loss: 2.2538392901597755
Validation loss: 2.5916265198356867

Epoch: 6| Step: 12
Training loss: 1.3663720014848264
Validation loss: 2.497855092854811

Epoch: 6| Step: 13
Training loss: 1.9293166819743415
Validation loss: 2.6603519257564665

Epoch: 119| Step: 0
Training loss: 2.0723578947559997
Validation loss: 2.555589320355957

Epoch: 6| Step: 1
Training loss: 1.9315290428464633
Validation loss: 2.5428605610871444

Epoch: 6| Step: 2
Training loss: 1.7142780735208896
Validation loss: 2.5672869126924063

Epoch: 6| Step: 3
Training loss: 1.8532486975621671
Validation loss: 2.47353170363707

Epoch: 6| Step: 4
Training loss: 2.6285401949596574
Validation loss: 2.533839137838762

Epoch: 6| Step: 5
Training loss: 1.8816152224450444
Validation loss: 2.444404587878308

Epoch: 6| Step: 6
Training loss: 2.221877352127139
Validation loss: 2.4934220719058366

Epoch: 6| Step: 7
Training loss: 1.9802294705095755
Validation loss: 2.616647404601843

Epoch: 6| Step: 8
Training loss: 1.6143126065923472
Validation loss: 2.5483964771342404

Epoch: 6| Step: 9
Training loss: 1.246901199715686
Validation loss: 2.61417006966545

Epoch: 6| Step: 10
Training loss: 1.947873065752911
Validation loss: 2.4998251694900895

Epoch: 6| Step: 11
Training loss: 2.2558847401171365
Validation loss: 2.7213494016371387

Epoch: 6| Step: 12
Training loss: 1.633443464082551
Validation loss: 2.5954636577427412

Epoch: 6| Step: 13
Training loss: 1.2906941577772357
Validation loss: 2.514254684483832

Epoch: 120| Step: 0
Training loss: 1.5475485520149297
Validation loss: 2.4696056959352837

Epoch: 6| Step: 1
Training loss: 2.1054384020598094
Validation loss: 2.5147803173852488

Epoch: 6| Step: 2
Training loss: 1.502927625232097
Validation loss: 2.491122824559769

Epoch: 6| Step: 3
Training loss: 1.7175403152687172
Validation loss: 2.608022343028885

Epoch: 6| Step: 4
Training loss: 1.4061752299458388
Validation loss: 2.5964573591278883

Epoch: 6| Step: 5
Training loss: 1.32569402476329
Validation loss: 2.627147946229943

Epoch: 6| Step: 6
Training loss: 1.9426522199965865
Validation loss: 2.4826445240825255

Epoch: 6| Step: 7
Training loss: 1.7519001862385666
Validation loss: 2.617037003019044

Epoch: 6| Step: 8
Training loss: 2.5653940001562328
Validation loss: 2.5441733074466

Epoch: 6| Step: 9
Training loss: 2.038171332288025
Validation loss: 2.6299765657848266

Epoch: 6| Step: 10
Training loss: 1.7848293414131673
Validation loss: 2.624846847547188

Epoch: 6| Step: 11
Training loss: 1.9268719600191984
Validation loss: 2.5902303231681802

Epoch: 6| Step: 12
Training loss: 2.499338825533532
Validation loss: 2.6923286175176666

Epoch: 6| Step: 13
Training loss: 1.7452453327146602
Validation loss: 2.638730808732193

Epoch: 121| Step: 0
Training loss: 2.477295102327806
Validation loss: 2.562783962116139

Epoch: 6| Step: 1
Training loss: 1.6090072656139063
Validation loss: 2.5119260363279445

Epoch: 6| Step: 2
Training loss: 1.755036667334781
Validation loss: 2.552017480947799

Epoch: 6| Step: 3
Training loss: 0.9636644577279027
Validation loss: 2.6401745865391217

Epoch: 6| Step: 4
Training loss: 1.5083890613075317
Validation loss: 2.614390488968626

Epoch: 6| Step: 5
Training loss: 2.092845892352847
Validation loss: 2.6106409744213543

Epoch: 6| Step: 6
Training loss: 2.2129638875229007
Validation loss: 2.5859833681585145

Epoch: 6| Step: 7
Training loss: 1.7651444853088127
Validation loss: 2.506165546950829

Epoch: 6| Step: 8
Training loss: 1.5543661887759315
Validation loss: 2.597970324963758

Epoch: 6| Step: 9
Training loss: 1.7739434549809434
Validation loss: 2.566209573627054

Epoch: 6| Step: 10
Training loss: 1.6751789709101137
Validation loss: 2.558950151853136

Epoch: 6| Step: 11
Training loss: 2.333056967126849
Validation loss: 2.6002739052891464

Epoch: 6| Step: 12
Training loss: 1.8530514038293069
Validation loss: 2.661503342896734

Epoch: 6| Step: 13
Training loss: 2.0282965683040883
Validation loss: 2.9003639365529965

Epoch: 122| Step: 0
Training loss: 1.7782799571117813
Validation loss: 2.9217015723235833

Epoch: 6| Step: 1
Training loss: 2.4539338740336674
Validation loss: 2.9039867161113313

Epoch: 6| Step: 2
Training loss: 2.286827897522186
Validation loss: 2.8895752108862447

Epoch: 6| Step: 3
Training loss: 1.8629914704197685
Validation loss: 2.726749038509121

Epoch: 6| Step: 4
Training loss: 1.8912128133704422
Validation loss: 2.823104828666829

Epoch: 6| Step: 5
Training loss: 1.8258471521539157
Validation loss: 2.6103973974524934

Epoch: 6| Step: 6
Training loss: 1.5881321196713643
Validation loss: 2.4966959179699804

Epoch: 6| Step: 7
Training loss: 2.3055383178597637
Validation loss: 2.548342432197542

Epoch: 6| Step: 8
Training loss: 1.7771735141258163
Validation loss: 2.572543064334063

Epoch: 6| Step: 9
Training loss: 2.488185048302221
Validation loss: 2.6014178811507014

Epoch: 6| Step: 10
Training loss: 1.9303285097801788
Validation loss: 2.51183751103835

Epoch: 6| Step: 11
Training loss: 1.978564729674293
Validation loss: 2.5973998896937687

Epoch: 6| Step: 12
Training loss: 2.1237768130885937
Validation loss: 2.5099621647570634

Epoch: 6| Step: 13
Training loss: 1.7096393834048929
Validation loss: 2.5590428858437133

Epoch: 123| Step: 0
Training loss: 2.0433733158441836
Validation loss: 2.591813019139504

Epoch: 6| Step: 1
Training loss: 1.505220705749279
Validation loss: 2.6279538958079587

Epoch: 6| Step: 2
Training loss: 1.9183083911382321
Validation loss: 2.7316300265252376

Epoch: 6| Step: 3
Training loss: 2.5869922158117156
Validation loss: 2.705102788672725

Epoch: 6| Step: 4
Training loss: 1.9482089008747892
Validation loss: 2.605111695797509

Epoch: 6| Step: 5
Training loss: 1.6308235575688839
Validation loss: 2.720958382817828

Epoch: 6| Step: 6
Training loss: 2.5593338922313023
Validation loss: 2.5539400210695042

Epoch: 6| Step: 7
Training loss: 1.609962874511679
Validation loss: 2.6283179159040824

Epoch: 6| Step: 8
Training loss: 1.6333111453333358
Validation loss: 2.5047788879767436

Epoch: 6| Step: 9
Training loss: 1.878914878650925
Validation loss: 2.5193345892594254

Epoch: 6| Step: 10
Training loss: 1.4830302521751122
Validation loss: 2.5720287185902753

Epoch: 6| Step: 11
Training loss: 2.2029474065098307
Validation loss: 2.555287499697566

Epoch: 6| Step: 12
Training loss: 1.5645625425024898
Validation loss: 2.531508993705572

Epoch: 6| Step: 13
Training loss: 1.8020391807953855
Validation loss: 2.489094895101955

Epoch: 124| Step: 0
Training loss: 1.554412434076945
Validation loss: 2.497051980402986

Epoch: 6| Step: 1
Training loss: 1.663425233986704
Validation loss: 2.529533777716568

Epoch: 6| Step: 2
Training loss: 1.2703131512667216
Validation loss: 2.6079510822047745

Epoch: 6| Step: 3
Training loss: 2.142781862571453
Validation loss: 2.7003184984285697

Epoch: 6| Step: 4
Training loss: 1.9868496460570406
Validation loss: 2.651245354182663

Epoch: 6| Step: 5
Training loss: 1.2023671227873374
Validation loss: 2.7467751740538957

Epoch: 6| Step: 6
Training loss: 2.0786584155196457
Validation loss: 2.7260511295872014

Epoch: 6| Step: 7
Training loss: 1.7332673530980942
Validation loss: 2.7306606823758153

Epoch: 6| Step: 8
Training loss: 2.0388772814585128
Validation loss: 2.614033574113191

Epoch: 6| Step: 9
Training loss: 2.06738315847157
Validation loss: 2.5674842494245

Epoch: 6| Step: 10
Training loss: 2.229741554166416
Validation loss: 2.4330129323203553

Epoch: 6| Step: 11
Training loss: 2.4752500889358835
Validation loss: 2.487657821223814

Epoch: 6| Step: 12
Training loss: 1.4941477258052267
Validation loss: 2.578192769710811

Epoch: 6| Step: 13
Training loss: 1.8647332441991493
Validation loss: 2.61015461983773

Epoch: 125| Step: 0
Training loss: 2.247189355753171
Validation loss: 2.598527529883534

Epoch: 6| Step: 1
Training loss: 1.3077929423520827
Validation loss: 2.564374749641304

Epoch: 6| Step: 2
Training loss: 2.294062754749637
Validation loss: 2.4805759837282544

Epoch: 6| Step: 3
Training loss: 2.0034950235950957
Validation loss: 2.5918170206628037

Epoch: 6| Step: 4
Training loss: 2.4885619767197076
Validation loss: 2.6470478354228058

Epoch: 6| Step: 5
Training loss: 1.3418033605249466
Validation loss: 2.6032334651995233

Epoch: 6| Step: 6
Training loss: 1.814061380233222
Validation loss: 2.639550315772871

Epoch: 6| Step: 7
Training loss: 2.156764314652846
Validation loss: 2.5658735228469047

Epoch: 6| Step: 8
Training loss: 1.7993548985663925
Validation loss: 2.7525106009343583

Epoch: 6| Step: 9
Training loss: 1.9312790704903353
Validation loss: 2.577110244951739

Epoch: 6| Step: 10
Training loss: 1.1610584283332175
Validation loss: 2.5007538294736316

Epoch: 6| Step: 11
Training loss: 1.3337109845505017
Validation loss: 2.586436020970877

Epoch: 6| Step: 12
Training loss: 1.5245699854695036
Validation loss: 2.5424800467669373

Epoch: 6| Step: 13
Training loss: 1.9101135623585204
Validation loss: 2.584581109668694

Epoch: 126| Step: 0
Training loss: 1.2098458568658605
Validation loss: 2.513145077389671

Epoch: 6| Step: 1
Training loss: 2.611889022128623
Validation loss: 2.584149944280427

Epoch: 6| Step: 2
Training loss: 2.26139805551042
Validation loss: 2.6190716542136054

Epoch: 6| Step: 3
Training loss: 1.1300305110897018
Validation loss: 2.582725966231478

Epoch: 6| Step: 4
Training loss: 2.0799985771907927
Validation loss: 2.6084942121119186

Epoch: 6| Step: 5
Training loss: 1.3987833373296075
Validation loss: 2.5536479643137815

Epoch: 6| Step: 6
Training loss: 2.293927124003297
Validation loss: 2.6110999826324894

Epoch: 6| Step: 7
Training loss: 1.819386520952068
Validation loss: 2.580062970124871

Epoch: 6| Step: 8
Training loss: 1.6339739451484752
Validation loss: 2.718067244232399

Epoch: 6| Step: 9
Training loss: 1.5740410110433627
Validation loss: 2.6766589282277486

Epoch: 6| Step: 10
Training loss: 1.5191984228908393
Validation loss: 2.602908087184448

Epoch: 6| Step: 11
Training loss: 1.2034890751075384
Validation loss: 2.569948412183241

Epoch: 6| Step: 12
Training loss: 1.411104512178372
Validation loss: 2.5711834484161056

Epoch: 6| Step: 13
Training loss: 2.2979827078225936
Validation loss: 2.572582320961998

Epoch: 127| Step: 0
Training loss: 1.520318462364055
Validation loss: 2.5114164036958675

Epoch: 6| Step: 1
Training loss: 1.8296787799265812
Validation loss: 2.5301223173842007

Epoch: 6| Step: 2
Training loss: 1.45687611753731
Validation loss: 2.624578298271288

Epoch: 6| Step: 3
Training loss: 1.1947465441873926
Validation loss: 2.5929494794432357

Epoch: 6| Step: 4
Training loss: 1.7296011581856363
Validation loss: 2.5081149480386804

Epoch: 6| Step: 5
Training loss: 1.739608566497109
Validation loss: 2.6027387493504612

Epoch: 6| Step: 6
Training loss: 1.7994398305065056
Validation loss: 2.5441146745397414

Epoch: 6| Step: 7
Training loss: 1.649281796289827
Validation loss: 2.559838083158449

Epoch: 6| Step: 8
Training loss: 1.924980693571699
Validation loss: 2.535918479247966

Epoch: 6| Step: 9
Training loss: 1.6903023233810839
Validation loss: 2.6312575309204678

Epoch: 6| Step: 10
Training loss: 2.009092880069169
Validation loss: 2.621136061909127

Epoch: 6| Step: 11
Training loss: 1.4666396055470492
Validation loss: 2.6299999922521518

Epoch: 6| Step: 12
Training loss: 2.1388047547189983
Validation loss: 2.6384366389677605

Epoch: 6| Step: 13
Training loss: 2.4717958227852423
Validation loss: 2.7074035124347993

Epoch: 128| Step: 0
Training loss: 2.0916149583886785
Validation loss: 2.6664576647235294

Epoch: 6| Step: 1
Training loss: 1.2140256819671609
Validation loss: 2.61853769878769

Epoch: 6| Step: 2
Training loss: 2.716535960214484
Validation loss: 2.570333757090378

Epoch: 6| Step: 3
Training loss: 2.0936146023370434
Validation loss: 2.5742981377006435

Epoch: 6| Step: 4
Training loss: 1.9828348265248381
Validation loss: 2.497362987208171

Epoch: 6| Step: 5
Training loss: 1.6767395409558863
Validation loss: 2.607093834213936

Epoch: 6| Step: 6
Training loss: 1.6608920273248573
Validation loss: 2.595477566798906

Epoch: 6| Step: 7
Training loss: 1.681195668757194
Validation loss: 2.5101663192925407

Epoch: 6| Step: 8
Training loss: 1.8115764764388425
Validation loss: 2.5820147676850773

Epoch: 6| Step: 9
Training loss: 1.1477515838685237
Validation loss: 2.5919050832743724

Epoch: 6| Step: 10
Training loss: 1.368058630116338
Validation loss: 2.5891744862235693

Epoch: 6| Step: 11
Training loss: 1.8792188864118184
Validation loss: 2.671980560180623

Epoch: 6| Step: 12
Training loss: 1.3390927893329885
Validation loss: 2.530836424772828

Epoch: 6| Step: 13
Training loss: 2.0540586024006102
Validation loss: 2.542648318680427

Epoch: 129| Step: 0
Training loss: 1.666185341315236
Validation loss: 2.6102381361800235

Epoch: 6| Step: 1
Training loss: 2.06217017570996
Validation loss: 2.5677543517367933

Epoch: 6| Step: 2
Training loss: 1.5458865620102142
Validation loss: 2.5410599114607297

Epoch: 6| Step: 3
Training loss: 1.642555191297242
Validation loss: 2.5774957833069068

Epoch: 6| Step: 4
Training loss: 2.303435007916082
Validation loss: 2.5607067051481613

Epoch: 6| Step: 5
Training loss: 1.1543107136834367
Validation loss: 2.5417434545288673

Epoch: 6| Step: 6
Training loss: 1.7040197839215283
Validation loss: 2.545661137735915

Epoch: 6| Step: 7
Training loss: 1.8792056283344414
Validation loss: 2.6186785346016053

Epoch: 6| Step: 8
Training loss: 1.417504605078912
Validation loss: 2.617785803886542

Epoch: 6| Step: 9
Training loss: 1.4376436244699184
Validation loss: 2.60707886686385

Epoch: 6| Step: 10
Training loss: 1.6189448441882013
Validation loss: 2.681088673466591

Epoch: 6| Step: 11
Training loss: 1.8323586502829083
Validation loss: 2.599009914051975

Epoch: 6| Step: 12
Training loss: 1.637176668117083
Validation loss: 2.5969620391300086

Epoch: 6| Step: 13
Training loss: 1.977807357860962
Validation loss: 2.634594126766775

Epoch: 130| Step: 0
Training loss: 1.5534727632107355
Validation loss: 2.5883813164908527

Epoch: 6| Step: 1
Training loss: 1.826591435342748
Validation loss: 2.56395110470068

Epoch: 6| Step: 2
Training loss: 1.58241105406712
Validation loss: 2.4583808333985773

Epoch: 6| Step: 3
Training loss: 1.6065477147263267
Validation loss: 2.607931990616291

Epoch: 6| Step: 4
Training loss: 1.5986235658521526
Validation loss: 2.5819679825765336

Epoch: 6| Step: 5
Training loss: 1.16732841978958
Validation loss: 2.6507498400036122

Epoch: 6| Step: 6
Training loss: 1.5034676841254264
Validation loss: 2.533105790016541

Epoch: 6| Step: 7
Training loss: 1.5733070478560427
Validation loss: 2.5627534167270336

Epoch: 6| Step: 8
Training loss: 1.2377123563802013
Validation loss: 2.5627300190228386

Epoch: 6| Step: 9
Training loss: 1.3580373123588056
Validation loss: 2.519863909069116

Epoch: 6| Step: 10
Training loss: 1.0986303168374432
Validation loss: 2.5256094074405144

Epoch: 6| Step: 11
Training loss: 2.4327997715689924
Validation loss: 2.555734371296354

Epoch: 6| Step: 12
Training loss: 2.54033922228072
Validation loss: 2.6038707921112545

Epoch: 6| Step: 13
Training loss: 2.384820610993341
Validation loss: 2.5494351927121413

Epoch: 131| Step: 0
Training loss: 1.7259199923363449
Validation loss: 2.6852124851003416

Epoch: 6| Step: 1
Training loss: 1.6633775761109135
Validation loss: 2.775109559837588

Epoch: 6| Step: 2
Training loss: 1.6831680786422023
Validation loss: 2.8005979044343516

Epoch: 6| Step: 3
Training loss: 1.7410270349900263
Validation loss: 2.752185097910606

Epoch: 6| Step: 4
Training loss: 1.3470350962500865
Validation loss: 2.7093091722797804

Epoch: 6| Step: 5
Training loss: 1.9339311401708401
Validation loss: 2.8650573176497316

Epoch: 6| Step: 6
Training loss: 2.1316728726143332
Validation loss: 2.6563332338943044

Epoch: 6| Step: 7
Training loss: 2.1038051962000544
Validation loss: 2.6188626067138836

Epoch: 6| Step: 8
Training loss: 2.256083106633997
Validation loss: 2.648389352606499

Epoch: 6| Step: 9
Training loss: 1.7128363397362842
Validation loss: 2.5832062556687516

Epoch: 6| Step: 10
Training loss: 2.014806300240853
Validation loss: 2.529170983911524

Epoch: 6| Step: 11
Training loss: 1.6050563013297174
Validation loss: 2.5839648141502627

Epoch: 6| Step: 12
Training loss: 1.7581939961455548
Validation loss: 2.614708131240914

Epoch: 6| Step: 13
Training loss: 1.671996067690446
Validation loss: 2.5680047586947565

Epoch: 132| Step: 0
Training loss: 1.4656877451400288
Validation loss: 2.6557460531259096

Epoch: 6| Step: 1
Training loss: 2.025343303072418
Validation loss: 2.4891639154004155

Epoch: 6| Step: 2
Training loss: 1.944494174896563
Validation loss: 2.5637708241946666

Epoch: 6| Step: 3
Training loss: 1.6322008657446838
Validation loss: 2.4985936500750157

Epoch: 6| Step: 4
Training loss: 1.491477917427485
Validation loss: 2.607896930599382

Epoch: 6| Step: 5
Training loss: 1.719540223614278
Validation loss: 2.696950368760013

Epoch: 6| Step: 6
Training loss: 1.805702749594007
Validation loss: 2.7732885616231253

Epoch: 6| Step: 7
Training loss: 2.1998483085354787
Validation loss: 2.7611380348283006

Epoch: 6| Step: 8
Training loss: 2.255396728634219
Validation loss: 2.5977749216607697

Epoch: 6| Step: 9
Training loss: 2.0213638343438958
Validation loss: 2.6360641458113094

Epoch: 6| Step: 10
Training loss: 1.7745540649742406
Validation loss: 2.7003519611781135

Epoch: 6| Step: 11
Training loss: 1.488688415739746
Validation loss: 2.644866696696118

Epoch: 6| Step: 12
Training loss: 1.68604646883875
Validation loss: 2.460141476049447

Epoch: 6| Step: 13
Training loss: 1.5364405571722834
Validation loss: 2.5363059393020495

Epoch: 133| Step: 0
Training loss: 1.7792095074941616
Validation loss: 2.6124482930008215

Epoch: 6| Step: 1
Training loss: 1.6280702783097918
Validation loss: 2.5183734766977204

Epoch: 6| Step: 2
Training loss: 1.5502938145913048
Validation loss: 2.457297484059635

Epoch: 6| Step: 3
Training loss: 1.511248059393786
Validation loss: 2.4821501392311265

Epoch: 6| Step: 4
Training loss: 1.5504291432565622
Validation loss: 2.457750701289044

Epoch: 6| Step: 5
Training loss: 1.8010619104092322
Validation loss: 2.531885765829357

Epoch: 6| Step: 6
Training loss: 1.7573097696900082
Validation loss: 2.670961101013079

Epoch: 6| Step: 7
Training loss: 1.1786392809586974
Validation loss: 2.5955489327870245

Epoch: 6| Step: 8
Training loss: 1.7797411501118265
Validation loss: 2.702907590263287

Epoch: 6| Step: 9
Training loss: 2.377409565967599
Validation loss: 2.626581941495219

Epoch: 6| Step: 10
Training loss: 1.474542436912005
Validation loss: 2.603576026057508

Epoch: 6| Step: 11
Training loss: 2.011928984387922
Validation loss: 2.491262712766804

Epoch: 6| Step: 12
Training loss: 1.7897296311335333
Validation loss: 2.6180227436693198

Epoch: 6| Step: 13
Training loss: 1.5613182176357232
Validation loss: 2.654836413162472

Epoch: 134| Step: 0
Training loss: 1.778179265754628
Validation loss: 2.515225791452431

Epoch: 6| Step: 1
Training loss: 1.5269091053548751
Validation loss: 2.5341734389348742

Epoch: 6| Step: 2
Training loss: 1.8945172810776898
Validation loss: 2.5874034955737906

Epoch: 6| Step: 3
Training loss: 1.857046512577951
Validation loss: 2.511375035903837

Epoch: 6| Step: 4
Training loss: 1.9749757934245769
Validation loss: 2.5817459879937865

Epoch: 6| Step: 5
Training loss: 1.81960548128253
Validation loss: 2.45862448848568

Epoch: 6| Step: 6
Training loss: 1.1742183398501758
Validation loss: 2.573831130594496

Epoch: 6| Step: 7
Training loss: 1.250247215620303
Validation loss: 2.6347590192594637

Epoch: 6| Step: 8
Training loss: 2.1237816403318273
Validation loss: 2.4931305124625616

Epoch: 6| Step: 9
Training loss: 1.7814094070581923
Validation loss: 2.6739698381304007

Epoch: 6| Step: 10
Training loss: 1.6329666867990027
Validation loss: 2.6533578873062122

Epoch: 6| Step: 11
Training loss: 2.3456008723680193
Validation loss: 2.7136590728450463

Epoch: 6| Step: 12
Training loss: 1.2706445126365147
Validation loss: 2.592465201217584

Epoch: 6| Step: 13
Training loss: 1.5709159033379563
Validation loss: 2.554309152006895

Epoch: 135| Step: 0
Training loss: 1.6714571136440997
Validation loss: 2.513879885461279

Epoch: 6| Step: 1
Training loss: 1.3763108507332453
Validation loss: 2.5502190819917785

Epoch: 6| Step: 2
Training loss: 1.7065128613000462
Validation loss: 2.585481155865856

Epoch: 6| Step: 3
Training loss: 2.3299150178007224
Validation loss: 2.4936884204014405

Epoch: 6| Step: 4
Training loss: 1.6000700160442656
Validation loss: 2.600040758253624

Epoch: 6| Step: 5
Training loss: 2.0046570916073505
Validation loss: 2.5222304599849634

Epoch: 6| Step: 6
Training loss: 1.6948261178549213
Validation loss: 2.684383403867061

Epoch: 6| Step: 7
Training loss: 1.28881408147288
Validation loss: 2.669071623028768

Epoch: 6| Step: 8
Training loss: 2.016904676069515
Validation loss: 2.5498870170097283

Epoch: 6| Step: 9
Training loss: 1.536597044119871
Validation loss: 2.551315306233092

Epoch: 6| Step: 10
Training loss: 1.1580190785735494
Validation loss: 2.5756522139676163

Epoch: 6| Step: 11
Training loss: 1.8547040467781521
Validation loss: 2.5576685506667163

Epoch: 6| Step: 12
Training loss: 1.8959838332360153
Validation loss: 2.5888550234172727

Epoch: 6| Step: 13
Training loss: 1.5323276231161596
Validation loss: 2.5997442816645653

Epoch: 136| Step: 0
Training loss: 2.474187632859811
Validation loss: 2.5646710231817713

Epoch: 6| Step: 1
Training loss: 1.2709619529966134
Validation loss: 2.6463400638361954

Epoch: 6| Step: 2
Training loss: 1.7057296714102506
Validation loss: 2.7134812849261762

Epoch: 6| Step: 3
Training loss: 1.883276537936228
Validation loss: 2.502093281171612

Epoch: 6| Step: 4
Training loss: 1.498631488864592
Validation loss: 2.7065748643770715

Epoch: 6| Step: 5
Training loss: 1.2550934017425868
Validation loss: 2.653154821269465

Epoch: 6| Step: 6
Training loss: 1.3832846228897648
Validation loss: 2.553838590758647

Epoch: 6| Step: 7
Training loss: 1.6404245889963482
Validation loss: 2.578561888388912

Epoch: 6| Step: 8
Training loss: 1.6471494008150405
Validation loss: 2.6298734596521474

Epoch: 6| Step: 9
Training loss: 1.4633661981743007
Validation loss: 2.6028731884924636

Epoch: 6| Step: 10
Training loss: 1.6535703466612546
Validation loss: 2.5774102655596227

Epoch: 6| Step: 11
Training loss: 1.8844456850778546
Validation loss: 2.5577869647815117

Epoch: 6| Step: 12
Training loss: 1.7090168105180894
Validation loss: 2.5170978317849326

Epoch: 6| Step: 13
Training loss: 1.2623596925480693
Validation loss: 2.568961703571248

Epoch: 137| Step: 0
Training loss: 1.749843931050789
Validation loss: 2.4834490796024777

Epoch: 6| Step: 1
Training loss: 1.7658352346921617
Validation loss: 2.5649194228099668

Epoch: 6| Step: 2
Training loss: 1.4168191248069824
Validation loss: 2.5307405218097445

Epoch: 6| Step: 3
Training loss: 1.7506508298178407
Validation loss: 2.5208579973848035

Epoch: 6| Step: 4
Training loss: 1.623643602463621
Validation loss: 2.6491971497183378

Epoch: 6| Step: 5
Training loss: 1.8675928035080254
Validation loss: 2.4531814827865417

Epoch: 6| Step: 6
Training loss: 1.5762629334949971
Validation loss: 2.565931054592187

Epoch: 6| Step: 7
Training loss: 2.1362703679309654
Validation loss: 2.566981777028896

Epoch: 6| Step: 8
Training loss: 1.3460542306617234
Validation loss: 2.5610908262240657

Epoch: 6| Step: 9
Training loss: 2.3550678879981524
Validation loss: 2.6604877102974327

Epoch: 6| Step: 10
Training loss: 1.7192917403512242
Validation loss: 2.5934395891607034

Epoch: 6| Step: 11
Training loss: 1.1572877505579815
Validation loss: 2.624618411712146

Epoch: 6| Step: 12
Training loss: 1.1416393629461434
Validation loss: 2.5795063210104474

Epoch: 6| Step: 13
Training loss: 1.8143117334240109
Validation loss: 2.630972546638054

Epoch: 138| Step: 0
Training loss: 1.463114050392787
Validation loss: 2.5881638254353168

Epoch: 6| Step: 1
Training loss: 1.1910861226227585
Validation loss: 2.528819106058595

Epoch: 6| Step: 2
Training loss: 1.4909858858552143
Validation loss: 2.5523868821423616

Epoch: 6| Step: 3
Training loss: 1.0704818368873774
Validation loss: 2.5505309437281394

Epoch: 6| Step: 4
Training loss: 1.9345375300888494
Validation loss: 2.505469220721148

Epoch: 6| Step: 5
Training loss: 1.7714470940381817
Validation loss: 2.554719759458416

Epoch: 6| Step: 6
Training loss: 1.2333759175930552
Validation loss: 2.5506486142595324

Epoch: 6| Step: 7
Training loss: 1.6054148421321308
Validation loss: 2.6034211172362944

Epoch: 6| Step: 8
Training loss: 2.452813389904703
Validation loss: 2.5834535960435123

Epoch: 6| Step: 9
Training loss: 1.6229618201709695
Validation loss: 2.563598288900592

Epoch: 6| Step: 10
Training loss: 1.3029949608190823
Validation loss: 2.60568216604121

Epoch: 6| Step: 11
Training loss: 1.7728011548267486
Validation loss: 2.5900411784704676

Epoch: 6| Step: 12
Training loss: 1.879439438887673
Validation loss: 2.618974354677024

Epoch: 6| Step: 13
Training loss: 1.889567055539218
Validation loss: 2.59583700240005

Epoch: 139| Step: 0
Training loss: 1.5419481209563917
Validation loss: 2.660397197997677

Epoch: 6| Step: 1
Training loss: 1.5991696974961007
Validation loss: 2.558726843558471

Epoch: 6| Step: 2
Training loss: 1.6382565068535284
Validation loss: 2.680301962822092

Epoch: 6| Step: 3
Training loss: 1.2385180033398233
Validation loss: 2.644898821530701

Epoch: 6| Step: 4
Training loss: 1.3608002042660343
Validation loss: 2.4904456434201703

Epoch: 6| Step: 5
Training loss: 1.6548330615806657
Validation loss: 2.4679810980439303

Epoch: 6| Step: 6
Training loss: 1.8641758336725849
Validation loss: 2.6180897538177352

Epoch: 6| Step: 7
Training loss: 1.487331938666136
Validation loss: 2.6085819554488325

Epoch: 6| Step: 8
Training loss: 1.7272851044608373
Validation loss: 2.596847278188407

Epoch: 6| Step: 9
Training loss: 1.1702548716964647
Validation loss: 2.533145759774167

Epoch: 6| Step: 10
Training loss: 1.6580811939858704
Validation loss: 2.5414983558166657

Epoch: 6| Step: 11
Training loss: 2.4422031902412042
Validation loss: 2.5851233930546957

Epoch: 6| Step: 12
Training loss: 1.8971318280027472
Validation loss: 2.6541528389020077

Epoch: 6| Step: 13
Training loss: 1.1980070273554653
Validation loss: 2.7076578447186543

Epoch: 140| Step: 0
Training loss: 1.7960317208562262
Validation loss: 2.8042814479725378

Epoch: 6| Step: 1
Training loss: 1.5807308173969663
Validation loss: 2.7340017227426947

Epoch: 6| Step: 2
Training loss: 1.0973441878400338
Validation loss: 2.767668484558987

Epoch: 6| Step: 3
Training loss: 1.5511085299428202
Validation loss: 2.7123941983919853

Epoch: 6| Step: 4
Training loss: 1.1269417006840783
Validation loss: 2.6513017228336135

Epoch: 6| Step: 5
Training loss: 1.2184024706548087
Validation loss: 2.6499452303378814

Epoch: 6| Step: 6
Training loss: 1.3308055977667217
Validation loss: 2.6131625374220184

Epoch: 6| Step: 7
Training loss: 2.2355811858156267
Validation loss: 2.5781056181824527

Epoch: 6| Step: 8
Training loss: 1.4665129649658621
Validation loss: 2.4343893629375946

Epoch: 6| Step: 9
Training loss: 1.8148467557753305
Validation loss: 2.5948585684375334

Epoch: 6| Step: 10
Training loss: 1.516650138317775
Validation loss: 2.5221429423290673

Epoch: 6| Step: 11
Training loss: 1.8261287908520605
Validation loss: 2.625311038345277

Epoch: 6| Step: 12
Training loss: 1.4509977130937597
Validation loss: 2.564543343569742

Epoch: 6| Step: 13
Training loss: 2.040548784079901
Validation loss: 2.5726310066894547

Epoch: 141| Step: 0
Training loss: 1.2090066590358457
Validation loss: 2.565972433289511

Epoch: 6| Step: 1
Training loss: 1.5998330058927321
Validation loss: 2.4993506700940973

Epoch: 6| Step: 2
Training loss: 1.541007889219335
Validation loss: 2.5015625679862756

Epoch: 6| Step: 3
Training loss: 1.3025167989837316
Validation loss: 2.5607279643899195

Epoch: 6| Step: 4
Training loss: 2.556420534596574
Validation loss: 2.4688337287707656

Epoch: 6| Step: 5
Training loss: 1.5367727529077257
Validation loss: 2.49682157647913

Epoch: 6| Step: 6
Training loss: 1.5846608101642015
Validation loss: 2.551431102838391

Epoch: 6| Step: 7
Training loss: 1.1691031162249472
Validation loss: 2.6500742757932407

Epoch: 6| Step: 8
Training loss: 1.8405437717098265
Validation loss: 2.6532088429353515

Epoch: 6| Step: 9
Training loss: 1.998458506672847
Validation loss: 2.5833013337727326

Epoch: 6| Step: 10
Training loss: 1.4582668107618815
Validation loss: 2.5810860631822785

Epoch: 6| Step: 11
Training loss: 1.2514387910164955
Validation loss: 2.5870609359357406

Epoch: 6| Step: 12
Training loss: 1.235332166195308
Validation loss: 2.590212205517654

Epoch: 6| Step: 13
Training loss: 1.2747066235072224
Validation loss: 2.6790568478049033

Epoch: 142| Step: 0
Training loss: 1.5750620360494296
Validation loss: 2.5909735592006196

Epoch: 6| Step: 1
Training loss: 1.7529790589756842
Validation loss: 2.639081274236463

Epoch: 6| Step: 2
Training loss: 1.7693211849737525
Validation loss: 2.613884719789455

Epoch: 6| Step: 3
Training loss: 1.2884934527608656
Validation loss: 2.548342525755838

Epoch: 6| Step: 4
Training loss: 2.417771437672097
Validation loss: 2.584185587881281

Epoch: 6| Step: 5
Training loss: 1.6572473510085712
Validation loss: 2.596983200493846

Epoch: 6| Step: 6
Training loss: 1.5743839754618827
Validation loss: 2.528351163866224

Epoch: 6| Step: 7
Training loss: 1.4946641590705365
Validation loss: 2.5769788409928487

Epoch: 6| Step: 8
Training loss: 1.4417359510027974
Validation loss: 2.56972012945359

Epoch: 6| Step: 9
Training loss: 1.330445495151358
Validation loss: 2.690682899481266

Epoch: 6| Step: 10
Training loss: 1.8818685610941963
Validation loss: 2.5410970351802273

Epoch: 6| Step: 11
Training loss: 1.251005435940941
Validation loss: 2.642305565438343

Epoch: 6| Step: 12
Training loss: 1.1956288536157238
Validation loss: 2.6172153300613386

Epoch: 6| Step: 13
Training loss: 1.5445188823816456
Validation loss: 2.63626885991158

Epoch: 143| Step: 0
Training loss: 1.491431878790401
Validation loss: 2.47142845232428

Epoch: 6| Step: 1
Training loss: 1.3058238306208965
Validation loss: 2.604018670009303

Epoch: 6| Step: 2
Training loss: 1.7886717257111207
Validation loss: 2.4975572573004734

Epoch: 6| Step: 3
Training loss: 1.3222636415813227
Validation loss: 2.568801621338372

Epoch: 6| Step: 4
Training loss: 1.2476142527487428
Validation loss: 2.534753329523076

Epoch: 6| Step: 5
Training loss: 2.3771427928320645
Validation loss: 2.5992979440643604

Epoch: 6| Step: 6
Training loss: 1.4713469738629728
Validation loss: 2.535587973490049

Epoch: 6| Step: 7
Training loss: 2.1645644944967986
Validation loss: 2.4766394826835603

Epoch: 6| Step: 8
Training loss: 1.7173798388296286
Validation loss: 2.678084358254149

Epoch: 6| Step: 9
Training loss: 1.4108576839679174
Validation loss: 2.612517180074514

Epoch: 6| Step: 10
Training loss: 1.2536716895401359
Validation loss: 2.6557869900347786

Epoch: 6| Step: 11
Training loss: 1.793442075663378
Validation loss: 2.654185161995237

Epoch: 6| Step: 12
Training loss: 1.2400183782446128
Validation loss: 2.6095722299073927

Epoch: 6| Step: 13
Training loss: 1.5000060399251771
Validation loss: 2.6106374583800576

Epoch: 144| Step: 0
Training loss: 1.3119122687902962
Validation loss: 2.551791097815884

Epoch: 6| Step: 1
Training loss: 1.905611650489598
Validation loss: 2.548431693046498

Epoch: 6| Step: 2
Training loss: 1.2295645646296232
Validation loss: 2.5342990423282012

Epoch: 6| Step: 3
Training loss: 1.4046664328687342
Validation loss: 2.521370307751447

Epoch: 6| Step: 4
Training loss: 1.5762517405416392
Validation loss: 2.5320158847623935

Epoch: 6| Step: 5
Training loss: 2.5643014855740414
Validation loss: 2.5133330604146646

Epoch: 6| Step: 6
Training loss: 0.9587257797981701
Validation loss: 2.568460494880424

Epoch: 6| Step: 7
Training loss: 1.4904161894792805
Validation loss: 2.5887046215157636

Epoch: 6| Step: 8
Training loss: 1.3392344610307203
Validation loss: 2.6226083062677614

Epoch: 6| Step: 9
Training loss: 1.7155233439917155
Validation loss: 2.6141156896700433

Epoch: 6| Step: 10
Training loss: 0.9286185137370329
Validation loss: 2.6239969062670636

Epoch: 6| Step: 11
Training loss: 1.4707954448686473
Validation loss: 2.7689468061252027

Epoch: 6| Step: 12
Training loss: 2.0200961888894606
Validation loss: 2.601101220584359

Epoch: 6| Step: 13
Training loss: 1.421216539779176
Validation loss: 2.581757793094736

Epoch: 145| Step: 0
Training loss: 0.783407360664246
Validation loss: 2.5749176419614903

Epoch: 6| Step: 1
Training loss: 1.6961898291533992
Validation loss: 2.62207740484376

Epoch: 6| Step: 2
Training loss: 1.7811884283834842
Validation loss: 2.541159459352692

Epoch: 6| Step: 3
Training loss: 1.6577133336011163
Validation loss: 2.5955440337580016

Epoch: 6| Step: 4
Training loss: 1.3939528775206966
Validation loss: 2.542288193508986

Epoch: 6| Step: 5
Training loss: 1.4818963487648744
Validation loss: 2.516600709855065

Epoch: 6| Step: 6
Training loss: 1.3189709410513988
Validation loss: 2.509896906525102

Epoch: 6| Step: 7
Training loss: 1.5347579944214103
Validation loss: 2.5687404876805116

Epoch: 6| Step: 8
Training loss: 1.5444005576118147
Validation loss: 2.4622254972224753

Epoch: 6| Step: 9
Training loss: 1.0819106051945542
Validation loss: 2.523637690835999

Epoch: 6| Step: 10
Training loss: 2.3357307061867663
Validation loss: 2.61110520249458

Epoch: 6| Step: 11
Training loss: 1.576710888899056
Validation loss: 2.615022832601828

Epoch: 6| Step: 12
Training loss: 1.51485077264662
Validation loss: 2.59737836455677

Epoch: 6| Step: 13
Training loss: 1.617962342916832
Validation loss: 2.8389264653782407

Epoch: 146| Step: 0
Training loss: 1.2658968974852833
Validation loss: 2.65953995655881

Epoch: 6| Step: 1
Training loss: 2.1192028405685654
Validation loss: 2.6968078151097763

Epoch: 6| Step: 2
Training loss: 1.4830530805547866
Validation loss: 2.5972588486109007

Epoch: 6| Step: 3
Training loss: 1.5861841771001441
Validation loss: 2.648806820965526

Epoch: 6| Step: 4
Training loss: 1.9644664606933886
Validation loss: 2.5737567307549574

Epoch: 6| Step: 5
Training loss: 1.577075118022906
Validation loss: 2.674608880562001

Epoch: 6| Step: 6
Training loss: 1.3259596732122159
Validation loss: 2.547377928709446

Epoch: 6| Step: 7
Training loss: 1.6772218571984328
Validation loss: 2.6017974350310524

Epoch: 6| Step: 8
Training loss: 1.524566623206602
Validation loss: 2.5918801243282723

Epoch: 6| Step: 9
Training loss: 1.086125309573022
Validation loss: 2.5430499101491986

Epoch: 6| Step: 10
Training loss: 1.5082185030619786
Validation loss: 2.556902237483422

Epoch: 6| Step: 11
Training loss: 1.4426094140616532
Validation loss: 2.5813880769562383

Epoch: 6| Step: 12
Training loss: 1.1836365544098326
Validation loss: 2.497335126269597

Epoch: 6| Step: 13
Training loss: 1.6403126010469598
Validation loss: 2.5976305355625358

Epoch: 147| Step: 0
Training loss: 1.6505345027891605
Validation loss: 2.5541446276196695

Epoch: 6| Step: 1
Training loss: 1.8940385000712623
Validation loss: 2.5413962256797444

Epoch: 6| Step: 2
Training loss: 1.4972805166760421
Validation loss: 2.5812893646662314

Epoch: 6| Step: 3
Training loss: 2.4820010761255578
Validation loss: 2.530456968183689

Epoch: 6| Step: 4
Training loss: 0.9227647528614946
Validation loss: 2.565967895912535

Epoch: 6| Step: 5
Training loss: 1.317215984574981
Validation loss: 2.55919444868319

Epoch: 6| Step: 6
Training loss: 1.672191554253343
Validation loss: 2.607943052479481

Epoch: 6| Step: 7
Training loss: 1.3368800892494495
Validation loss: 2.664709763936263

Epoch: 6| Step: 8
Training loss: 1.1830520649317313
Validation loss: 2.6274361583480315

Epoch: 6| Step: 9
Training loss: 1.3738414044642713
Validation loss: 2.7176106137220875

Epoch: 6| Step: 10
Training loss: 1.31109612179304
Validation loss: 2.6174225127571558

Epoch: 6| Step: 11
Training loss: 1.0599601907272338
Validation loss: 2.7357618611396517

Epoch: 6| Step: 12
Training loss: 1.8868547157594802
Validation loss: 2.618996218181073

Epoch: 6| Step: 13
Training loss: 1.7674549713226293
Validation loss: 2.6670977025558016

Epoch: 148| Step: 0
Training loss: 1.0292035807940523
Validation loss: 2.592532565416009

Epoch: 6| Step: 1
Training loss: 1.5238470847390977
Validation loss: 2.54601774239782

Epoch: 6| Step: 2
Training loss: 1.5018751821148746
Validation loss: 2.541098755305726

Epoch: 6| Step: 3
Training loss: 1.458058994465434
Validation loss: 2.520012672029151

Epoch: 6| Step: 4
Training loss: 2.13887197176806
Validation loss: 2.58831404383002

Epoch: 6| Step: 5
Training loss: 1.6914622801911512
Validation loss: 2.513551999157946

Epoch: 6| Step: 6
Training loss: 1.2225044326857883
Validation loss: 2.516629636462622

Epoch: 6| Step: 7
Training loss: 1.5362735012109892
Validation loss: 2.5022221543940883

Epoch: 6| Step: 8
Training loss: 1.1560889466989308
Validation loss: 2.5486264593601766

Epoch: 6| Step: 9
Training loss: 1.4984976874745102
Validation loss: 2.5964571219144066

Epoch: 6| Step: 10
Training loss: 1.5074490123875235
Validation loss: 2.597820037802716

Epoch: 6| Step: 11
Training loss: 1.3641637006450482
Validation loss: 2.5097982085372728

Epoch: 6| Step: 12
Training loss: 1.3901928862522381
Validation loss: 2.4696852204289246

Epoch: 6| Step: 13
Training loss: 1.7391474590815845
Validation loss: 2.644396975257739

Epoch: 149| Step: 0
Training loss: 1.918814292103954
Validation loss: 2.584738892502561

Epoch: 6| Step: 1
Training loss: 1.0670002271728847
Validation loss: 2.6483214811496385

Epoch: 6| Step: 2
Training loss: 1.4208761206902945
Validation loss: 2.56561524129507

Epoch: 6| Step: 3
Training loss: 2.094736350865825
Validation loss: 2.6727267240695944

Epoch: 6| Step: 4
Training loss: 1.3097778428961528
Validation loss: 2.6465509497795527

Epoch: 6| Step: 5
Training loss: 1.5734265324230232
Validation loss: 2.517629847304753

Epoch: 6| Step: 6
Training loss: 1.2051300087120287
Validation loss: 2.5666715116166134

Epoch: 6| Step: 7
Training loss: 1.2023899756079068
Validation loss: 2.5139754358314055

Epoch: 6| Step: 8
Training loss: 1.3823592310560642
Validation loss: 2.5252370804882722

Epoch: 6| Step: 9
Training loss: 1.3251936033346108
Validation loss: 2.569915191955582

Epoch: 6| Step: 10
Training loss: 2.0934053963003145
Validation loss: 2.5335869538777422

Epoch: 6| Step: 11
Training loss: 0.8997601268905383
Validation loss: 2.581651853080133

Epoch: 6| Step: 12
Training loss: 1.4310857886850865
Validation loss: 2.605077879114369

Epoch: 6| Step: 13
Training loss: 1.5614028130200215
Validation loss: 2.502125837572225

Epoch: 150| Step: 0
Training loss: 0.9790340124053105
Validation loss: 2.676662891982265

Epoch: 6| Step: 1
Training loss: 1.4028486867593757
Validation loss: 2.6889939850068076

Epoch: 6| Step: 2
Training loss: 1.4830448816701312
Validation loss: 2.5197914639730845

Epoch: 6| Step: 3
Training loss: 1.6326358097245155
Validation loss: 2.626923673670293

Epoch: 6| Step: 4
Training loss: 0.7540008011264744
Validation loss: 2.6341630620387693

Epoch: 6| Step: 5
Training loss: 1.7575713945975406
Validation loss: 2.5818013806921853

Epoch: 6| Step: 6
Training loss: 1.318349744973509
Validation loss: 2.5286693211783007

Epoch: 6| Step: 7
Training loss: 1.5754291434181977
Validation loss: 2.605374206322247

Epoch: 6| Step: 8
Training loss: 1.6386562342118949
Validation loss: 2.582193851400812

Epoch: 6| Step: 9
Training loss: 1.7038849701180074
Validation loss: 2.6594212319957244

Epoch: 6| Step: 10
Training loss: 0.8613560470933894
Validation loss: 2.708768814483961

Epoch: 6| Step: 11
Training loss: 1.9768727778983977
Validation loss: 2.5813916636241268

Epoch: 6| Step: 12
Training loss: 1.4917873624991296
Validation loss: 2.6103846334657064

Epoch: 6| Step: 13
Training loss: 1.582317486523665
Validation loss: 2.594974565791718

Testing loss: 2.5403553825088303
