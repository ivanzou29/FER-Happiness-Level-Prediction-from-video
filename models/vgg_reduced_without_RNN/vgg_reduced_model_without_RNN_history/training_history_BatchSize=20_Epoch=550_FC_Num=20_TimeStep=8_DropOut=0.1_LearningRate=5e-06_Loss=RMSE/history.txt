Epoch: 1| Step: 0
Training loss: 3.3549279875211386
Validation loss: 3.2812544323119246

Epoch: 5| Step: 1
Training loss: 3.435597118467881
Validation loss: 3.2733030784763226

Epoch: 5| Step: 2
Training loss: 3.4266878187761187
Validation loss: 3.2614622887086147

Epoch: 5| Step: 3
Training loss: 3.1805370798550685
Validation loss: 3.2537137845115054

Epoch: 5| Step: 4
Training loss: 3.8354213390636147
Validation loss: 3.2435548526419855

Epoch: 5| Step: 5
Training loss: 3.518616619936139
Validation loss: 3.2361302059157793

Epoch: 5| Step: 6
Training loss: 2.9321195959599273
Validation loss: 3.2239560675215064

Epoch: 5| Step: 7
Training loss: 3.8231959158678226
Validation loss: 3.217161508819246

Epoch: 5| Step: 8
Training loss: 3.335364978269851
Validation loss: 3.2093076568243863

Epoch: 5| Step: 9
Training loss: 3.228054782218225
Validation loss: 3.1985310866158283

Epoch: 5| Step: 10
Training loss: 2.8578543866958372
Validation loss: 3.1896551301443044

Epoch: 5| Step: 11
Training loss: 3.3863084449948673
Validation loss: 3.180739382651483

Epoch: 2| Step: 0
Training loss: 3.1854444869734966
Validation loss: 3.171503170499781

Epoch: 5| Step: 1
Training loss: 3.2769673327952966
Validation loss: 3.162622847954162

Epoch: 5| Step: 2
Training loss: 2.939333404434883
Validation loss: 3.1542870110986443

Epoch: 5| Step: 3
Training loss: 3.1524844226860695
Validation loss: 3.1413232081006677

Epoch: 5| Step: 4
Training loss: 3.3028235984584735
Validation loss: 3.131813536927558

Epoch: 5| Step: 5
Training loss: 3.6052007937230797
Validation loss: 3.121058266907088

Epoch: 5| Step: 6
Training loss: 2.92907382895744
Validation loss: 3.1084669023524736

Epoch: 5| Step: 7
Training loss: 3.8694706505987
Validation loss: 3.098271088035612

Epoch: 5| Step: 8
Training loss: 3.033293516994638
Validation loss: 3.0841497337070938

Epoch: 5| Step: 9
Training loss: 3.060218116615979
Validation loss: 3.0728628649554564

Epoch: 5| Step: 10
Training loss: 2.934063626182601
Validation loss: 3.0571358341531933

Epoch: 5| Step: 11
Training loss: 3.931074682550567
Validation loss: 3.045212662249166

Epoch: 3| Step: 0
Training loss: 3.362945929812619
Validation loss: 3.0270416338718253

Epoch: 5| Step: 1
Training loss: 3.233705902919613
Validation loss: 3.015820317375118

Epoch: 5| Step: 2
Training loss: 2.9507599902327697
Validation loss: 2.9954550376040845

Epoch: 5| Step: 3
Training loss: 3.4096382857637693
Validation loss: 2.9823590538271927

Epoch: 5| Step: 4
Training loss: 3.2238854485789474
Validation loss: 2.9605795007245064

Epoch: 5| Step: 5
Training loss: 3.2325637832331937
Validation loss: 2.942892778855866

Epoch: 5| Step: 6
Training loss: 2.9913258718838636
Validation loss: 2.9291884306636766

Epoch: 5| Step: 7
Training loss: 3.096198914113768
Validation loss: 2.9075815370431384

Epoch: 5| Step: 8
Training loss: 2.6057220290123944
Validation loss: 2.8869556541432826

Epoch: 5| Step: 9
Training loss: 2.278528968357338
Validation loss: 2.86786977149797

Epoch: 5| Step: 10
Training loss: 2.877338619263855
Validation loss: 2.850365238460887

Epoch: 5| Step: 11
Training loss: 3.7414899267468624
Validation loss: 2.8334308506976074

Epoch: 4| Step: 0
Training loss: 3.116483298090627
Validation loss: 2.8190474803622974

Epoch: 5| Step: 1
Training loss: 2.932309698904276
Validation loss: 2.790257045841199

Epoch: 5| Step: 2
Training loss: 2.5721071233555017
Validation loss: 2.769409987678387

Epoch: 5| Step: 3
Training loss: 2.5241386455174037
Validation loss: 2.741616290121462

Epoch: 5| Step: 4
Training loss: 2.573348272985203
Validation loss: 2.7340465493710147

Epoch: 5| Step: 5
Training loss: 2.7650520895109265
Validation loss: 2.706288326130061

Epoch: 5| Step: 6
Training loss: 2.7460458243950945
Validation loss: 2.683655795028383

Epoch: 5| Step: 7
Training loss: 2.8083484102140632
Validation loss: 2.6695967920280737

Epoch: 5| Step: 8
Training loss: 2.6482233281592555
Validation loss: 2.6524136084157095

Epoch: 5| Step: 9
Training loss: 2.9617086327333957
Validation loss: 2.6360629097306107

Epoch: 5| Step: 10
Training loss: 2.8466095014396555
Validation loss: 2.6206991180011743

Epoch: 5| Step: 11
Training loss: 2.538950005019934
Validation loss: 2.6053561901693514

Epoch: 5| Step: 0
Training loss: 2.0824917682975017
Validation loss: 2.597910156843467

Epoch: 5| Step: 1
Training loss: 2.7511263188072066
Validation loss: 2.5885110171452457

Epoch: 5| Step: 2
Training loss: 2.361951520113806
Validation loss: 2.574079487593142

Epoch: 5| Step: 3
Training loss: 2.1470486677576663
Validation loss: 2.579288782567982

Epoch: 5| Step: 4
Training loss: 2.7761501746713706
Validation loss: 2.5804481096680876

Epoch: 5| Step: 5
Training loss: 2.6289771695370003
Validation loss: 2.5869824851772365

Epoch: 5| Step: 6
Training loss: 2.452718130010206
Validation loss: 2.5909858973742708

Epoch: 5| Step: 7
Training loss: 2.691222518163994
Validation loss: 2.600323088757744

Epoch: 5| Step: 8
Training loss: 2.4070306477705348
Validation loss: 2.606862169787645

Epoch: 5| Step: 9
Training loss: 2.56538814515399
Validation loss: 2.6209515657627787

Epoch: 5| Step: 10
Training loss: 3.1737842545044908
Validation loss: 2.6262634090412322

Epoch: 5| Step: 11
Training loss: 2.1874400539358763
Validation loss: 2.6278138859926985

Epoch: 6| Step: 0
Training loss: 2.116215331350711
Validation loss: 2.625791691421955

Epoch: 5| Step: 1
Training loss: 3.2362232179738055
Validation loss: 2.635416378930922

Epoch: 5| Step: 2
Training loss: 2.012606704442062
Validation loss: 2.6271969026243243

Epoch: 5| Step: 3
Training loss: 2.5436828829372096
Validation loss: 2.6294265428706063

Epoch: 5| Step: 4
Training loss: 2.3580017135264453
Validation loss: 2.621952687424638

Epoch: 5| Step: 5
Training loss: 2.260399837401949
Validation loss: 2.6166094734740692

Epoch: 5| Step: 6
Training loss: 3.0754987482779406
Validation loss: 2.6043078740300922

Epoch: 5| Step: 7
Training loss: 2.1187301589802003
Validation loss: 2.6094020187288742

Epoch: 5| Step: 8
Training loss: 3.277140923681341
Validation loss: 2.5997468189310893

Epoch: 5| Step: 9
Training loss: 2.3453532521000393
Validation loss: 2.5878037501694213

Epoch: 5| Step: 10
Training loss: 2.4523916910036037
Validation loss: 2.586049130307419

Epoch: 5| Step: 11
Training loss: 2.6477127208748903
Validation loss: 2.5835742562505146

Epoch: 7| Step: 0
Training loss: 2.3187001595705894
Validation loss: 2.5802119314460987

Epoch: 5| Step: 1
Training loss: 2.5244541069115978
Validation loss: 2.582779203224523

Epoch: 5| Step: 2
Training loss: 2.1810485528214185
Validation loss: 2.5736278305281477

Epoch: 5| Step: 3
Training loss: 2.656914392294599
Validation loss: 2.5741884097606027

Epoch: 5| Step: 4
Training loss: 2.582226998300489
Validation loss: 2.5672644308198933

Epoch: 5| Step: 5
Training loss: 3.018775677621124
Validation loss: 2.5637347107742445

Epoch: 5| Step: 6
Training loss: 2.365026916931403
Validation loss: 2.5644419840066845

Epoch: 5| Step: 7
Training loss: 2.414367656494159
Validation loss: 2.5628827282175806

Epoch: 5| Step: 8
Training loss: 2.477420309346025
Validation loss: 2.5530075942724815

Epoch: 5| Step: 9
Training loss: 2.4592339326179107
Validation loss: 2.568172580516198

Epoch: 5| Step: 10
Training loss: 2.5832692927964795
Validation loss: 2.557732461878328

Epoch: 5| Step: 11
Training loss: 3.557200455322374
Validation loss: 2.5594523108065483

Epoch: 8| Step: 0
Training loss: 2.242947333382112
Validation loss: 2.5505399448664683

Epoch: 5| Step: 1
Training loss: 2.680745886160147
Validation loss: 2.5532461566418645

Epoch: 5| Step: 2
Training loss: 2.612137480045919
Validation loss: 2.5398686073265706

Epoch: 5| Step: 3
Training loss: 2.7338855414329264
Validation loss: 2.5513158007354853

Epoch: 5| Step: 4
Training loss: 2.631182247929639
Validation loss: 2.543228765067473

Epoch: 5| Step: 5
Training loss: 2.3609069499091127
Validation loss: 2.547209856140125

Epoch: 5| Step: 6
Training loss: 2.326835121388902
Validation loss: 2.549243714809198

Epoch: 5| Step: 7
Training loss: 2.423635519706966
Validation loss: 2.5517761447820746

Epoch: 5| Step: 8
Training loss: 2.6466449083575716
Validation loss: 2.5400318271289963

Epoch: 5| Step: 9
Training loss: 2.3887543184489886
Validation loss: 2.5370307461851893

Epoch: 5| Step: 10
Training loss: 2.7635623977598653
Validation loss: 2.5483464590994105

Epoch: 5| Step: 11
Training loss: 2.633608824970528
Validation loss: 2.5392375122789312

Epoch: 9| Step: 0
Training loss: 2.791658875943221
Validation loss: 2.5474261797153797

Epoch: 5| Step: 1
Training loss: 2.735504265975903
Validation loss: 2.546491418516574

Epoch: 5| Step: 2
Training loss: 3.069300982391237
Validation loss: 2.546480037043587

Epoch: 5| Step: 3
Training loss: 2.371888984166512
Validation loss: 2.5458411047005756

Epoch: 5| Step: 4
Training loss: 2.05090796669524
Validation loss: 2.5390446667167206

Epoch: 5| Step: 5
Training loss: 2.2626308255808443
Validation loss: 2.540331017946854

Epoch: 5| Step: 6
Training loss: 1.8937405853541054
Validation loss: 2.5311008299526763

Epoch: 5| Step: 7
Training loss: 2.9211517907717504
Validation loss: 2.548048260134934

Epoch: 5| Step: 8
Training loss: 2.062751985820128
Validation loss: 2.541366595914513

Epoch: 5| Step: 9
Training loss: 3.044622126342104
Validation loss: 2.5500266111144736

Epoch: 5| Step: 10
Training loss: 2.2249211200919246
Validation loss: 2.547875018856828

Epoch: 5| Step: 11
Training loss: 1.7365309228887005
Validation loss: 2.5455302840595433

Epoch: 10| Step: 0
Training loss: 2.4380482766157208
Validation loss: 2.534331216367297

Epoch: 5| Step: 1
Training loss: 2.396227287300256
Validation loss: 2.540848847960434

Epoch: 5| Step: 2
Training loss: 2.549980096178353
Validation loss: 2.540155588244463

Epoch: 5| Step: 3
Training loss: 2.833127818414417
Validation loss: 2.5393406759613946

Epoch: 5| Step: 4
Training loss: 2.4828114897892157
Validation loss: 2.5444519319509737

Epoch: 5| Step: 5
Training loss: 2.423330251262372
Validation loss: 2.544247213596956

Epoch: 5| Step: 6
Training loss: 2.7025710403746066
Validation loss: 2.545100102657457

Epoch: 5| Step: 7
Training loss: 2.6347646296154994
Validation loss: 2.5497287333257646

Epoch: 5| Step: 8
Training loss: 2.09518554211843
Validation loss: 2.5425242412978144

Epoch: 5| Step: 9
Training loss: 2.6148169870320537
Validation loss: 2.5332995190266865

Epoch: 5| Step: 10
Training loss: 2.207972503069344
Validation loss: 2.5357917808022425

Epoch: 5| Step: 11
Training loss: 2.92404371752327
Validation loss: 2.542626986412854

Epoch: 11| Step: 0
Training loss: 2.2704784104279074
Validation loss: 2.5219517163185614

Epoch: 5| Step: 1
Training loss: 2.7075974173733157
Validation loss: 2.5317951408139607

Epoch: 5| Step: 2
Training loss: 2.581315811463596
Validation loss: 2.5118457609804925

Epoch: 5| Step: 3
Training loss: 1.9926935488173516
Validation loss: 2.5244469213161085

Epoch: 5| Step: 4
Training loss: 2.445168682902654
Validation loss: 2.5257454662421384

Epoch: 5| Step: 5
Training loss: 2.205304197577132
Validation loss: 2.52552666018687

Epoch: 5| Step: 6
Training loss: 2.97730860533
Validation loss: 2.520179010755525

Epoch: 5| Step: 7
Training loss: 2.6445939973630495
Validation loss: 2.515452704837845

Epoch: 5| Step: 8
Training loss: 2.213261006831954
Validation loss: 2.523450211688799

Epoch: 5| Step: 9
Training loss: 2.7637018101017903
Validation loss: 2.5229293421818797

Epoch: 5| Step: 10
Training loss: 2.442744359860318
Validation loss: 2.520932626476395

Epoch: 5| Step: 11
Training loss: 3.094779565753902
Validation loss: 2.5103015253298913

Epoch: 12| Step: 0
Training loss: 2.4765697202366654
Validation loss: 2.5191542587349063

Epoch: 5| Step: 1
Training loss: 2.063633578347865
Validation loss: 2.5202560052690735

Epoch: 5| Step: 2
Training loss: 2.324310044491131
Validation loss: 2.516131924560697

Epoch: 5| Step: 3
Training loss: 2.31396170119076
Validation loss: 2.508435965072183

Epoch: 5| Step: 4
Training loss: 2.6199408325037252
Validation loss: 2.5163859565024747

Epoch: 5| Step: 5
Training loss: 2.9484018166974932
Validation loss: 2.511865246714203

Epoch: 5| Step: 6
Training loss: 2.6938538073299587
Validation loss: 2.526829369943092

Epoch: 5| Step: 7
Training loss: 2.401044391842921
Validation loss: 2.525781894710894

Epoch: 5| Step: 8
Training loss: 2.6558763128975715
Validation loss: 2.5078605734395567

Epoch: 5| Step: 9
Training loss: 2.8659893307643656
Validation loss: 2.5239236755027754

Epoch: 5| Step: 10
Training loss: 2.152044867448453
Validation loss: 2.5242658422798527

Epoch: 5| Step: 11
Training loss: 0.5957828155745118
Validation loss: 2.5096814726539165

Epoch: 13| Step: 0
Training loss: 2.0995782610339973
Validation loss: 2.515046722573449

Epoch: 5| Step: 1
Training loss: 2.5820228472643625
Validation loss: 2.511978958597055

Epoch: 5| Step: 2
Training loss: 1.9839061874121646
Validation loss: 2.5264006893736832

Epoch: 5| Step: 3
Training loss: 2.539637855484856
Validation loss: 2.5247617579262314

Epoch: 5| Step: 4
Training loss: 2.609857114921972
Validation loss: 2.5235243232206868

Epoch: 5| Step: 5
Training loss: 2.5310179050615558
Validation loss: 2.5284701416287385

Epoch: 5| Step: 6
Training loss: 2.811050889430198
Validation loss: 2.5274213555914145

Epoch: 5| Step: 7
Training loss: 2.591997496739109
Validation loss: 2.536311285676942

Epoch: 5| Step: 8
Training loss: 2.462413817315997
Validation loss: 2.5297189760439207

Epoch: 5| Step: 9
Training loss: 2.3170097298316996
Validation loss: 2.5310287025637317

Epoch: 5| Step: 10
Training loss: 2.453540936822149
Validation loss: 2.5230920395719245

Epoch: 5| Step: 11
Training loss: 3.6379056933711604
Validation loss: 2.5324826908492866

Epoch: 14| Step: 0
Training loss: 2.3861828591046748
Validation loss: 2.5139779411148315

Epoch: 5| Step: 1
Training loss: 3.1354617667941405
Validation loss: 2.5156026013879744

Epoch: 5| Step: 2
Training loss: 2.959486633579949
Validation loss: 2.5033143445368653

Epoch: 5| Step: 3
Training loss: 2.2174547740018626
Validation loss: 2.5016853612099195

Epoch: 5| Step: 4
Training loss: 3.068084918203474
Validation loss: 2.505726807542376

Epoch: 5| Step: 5
Training loss: 1.918122512651697
Validation loss: 2.5042652501606697

Epoch: 5| Step: 6
Training loss: 2.3701271462437563
Validation loss: 2.4999329557965715

Epoch: 5| Step: 7
Training loss: 2.0070602254531855
Validation loss: 2.488358069750644

Epoch: 5| Step: 8
Training loss: 2.327060737830293
Validation loss: 2.5020400386328707

Epoch: 5| Step: 9
Training loss: 2.2499942779468256
Validation loss: 2.503151389533358

Epoch: 5| Step: 10
Training loss: 2.5054065417092497
Validation loss: 2.4950534123122976

Epoch: 5| Step: 11
Training loss: 1.5486233011781871
Validation loss: 2.498244277038249

Epoch: 15| Step: 0
Training loss: 2.6338350478002597
Validation loss: 2.5018557654403866

Epoch: 5| Step: 1
Training loss: 2.45190846595611
Validation loss: 2.4987151261466387

Epoch: 5| Step: 2
Training loss: 2.6323738977962594
Validation loss: 2.4891740044799717

Epoch: 5| Step: 3
Training loss: 2.5207036092708353
Validation loss: 2.4881074725941263

Epoch: 5| Step: 4
Training loss: 2.8368076639363426
Validation loss: 2.4928071020134133

Epoch: 5| Step: 5
Training loss: 2.2493049819703206
Validation loss: 2.5046080321462414

Epoch: 5| Step: 6
Training loss: 2.6038547990341407
Validation loss: 2.4943570028477966

Epoch: 5| Step: 7
Training loss: 2.1676712519345784
Validation loss: 2.4904610803668996

Epoch: 5| Step: 8
Training loss: 2.7209062466239957
Validation loss: 2.502065929497363

Epoch: 5| Step: 9
Training loss: 2.109896899050184
Validation loss: 2.5022450499373687

Epoch: 5| Step: 10
Training loss: 2.1428403876421593
Validation loss: 2.495876682894261

Epoch: 5| Step: 11
Training loss: 2.7071570164913736
Validation loss: 2.4929070106734623

Epoch: 16| Step: 0
Training loss: 2.937306823871738
Validation loss: 2.5092033775677907

Epoch: 5| Step: 1
Training loss: 2.640113826234091
Validation loss: 2.506296917958966

Epoch: 5| Step: 2
Training loss: 2.5429021823684526
Validation loss: 2.503604055370478

Epoch: 5| Step: 3
Training loss: 2.431817105794586
Validation loss: 2.5180630647199345

Epoch: 5| Step: 4
Training loss: 2.159710967541229
Validation loss: 2.515106321454911

Epoch: 5| Step: 5
Training loss: 2.636102629838741
Validation loss: 2.5131374523136105

Epoch: 5| Step: 6
Training loss: 2.543676977960603
Validation loss: 2.514173744605999

Epoch: 5| Step: 7
Training loss: 2.3453572166698615
Validation loss: 2.5257409037970233

Epoch: 5| Step: 8
Training loss: 2.6737549174773165
Validation loss: 2.5232395728311032

Epoch: 5| Step: 9
Training loss: 2.2102514489855944
Validation loss: 2.528267378662436

Epoch: 5| Step: 10
Training loss: 1.8626432146144738
Validation loss: 2.5123678923902264

Epoch: 5| Step: 11
Training loss: 2.652942438213625
Validation loss: 2.5085842058334236

Epoch: 17| Step: 0
Training loss: 2.7473689410925908
Validation loss: 2.506291535303653

Epoch: 5| Step: 1
Training loss: 1.9753306172485596
Validation loss: 2.4898372198808616

Epoch: 5| Step: 2
Training loss: 2.6588863080679017
Validation loss: 2.4871726009112605

Epoch: 5| Step: 3
Training loss: 2.5101793000213384
Validation loss: 2.4892173136243496

Epoch: 5| Step: 4
Training loss: 2.5803185581220704
Validation loss: 2.4909560769656256

Epoch: 5| Step: 5
Training loss: 2.385386793013392
Validation loss: 2.492733655376651

Epoch: 5| Step: 6
Training loss: 2.29002906780868
Validation loss: 2.497916390453723

Epoch: 5| Step: 7
Training loss: 2.6432959236522002
Validation loss: 2.493858669975847

Epoch: 5| Step: 8
Training loss: 2.1583179011830342
Validation loss: 2.4887271523492656

Epoch: 5| Step: 9
Training loss: 2.4415996993670896
Validation loss: 2.4895680372547693

Epoch: 5| Step: 10
Training loss: 2.4570128132381615
Validation loss: 2.508614511878166

Epoch: 5| Step: 11
Training loss: 3.0456640722695076
Validation loss: 2.5056406006391216

Epoch: 18| Step: 0
Training loss: 2.416648196007309
Validation loss: 2.4819756003434903

Epoch: 5| Step: 1
Training loss: 2.6109952179460625
Validation loss: 2.481794576674755

Epoch: 5| Step: 2
Training loss: 2.978919670340869
Validation loss: 2.4894084642890415

Epoch: 5| Step: 3
Training loss: 2.3259070155154995
Validation loss: 2.495634443661841

Epoch: 5| Step: 4
Training loss: 2.1869122396756047
Validation loss: 2.4891346696096126

Epoch: 5| Step: 5
Training loss: 2.6542553761587593
Validation loss: 2.491888283412774

Epoch: 5| Step: 6
Training loss: 2.210556159140691
Validation loss: 2.4881898552814445

Epoch: 5| Step: 7
Training loss: 2.5764968817447897
Validation loss: 2.4862188578426596

Epoch: 5| Step: 8
Training loss: 2.571909399717973
Validation loss: 2.485626353403448

Epoch: 5| Step: 9
Training loss: 2.180472393299368
Validation loss: 2.478434483948728

Epoch: 5| Step: 10
Training loss: 2.4971243532111873
Validation loss: 2.472262852908753

Epoch: 5| Step: 11
Training loss: 2.319040791253531
Validation loss: 2.478481483875643

Epoch: 19| Step: 0
Training loss: 2.9378541773475413
Validation loss: 2.4879153315456906

Epoch: 5| Step: 1
Training loss: 2.309741565895805
Validation loss: 2.4796869242298314

Epoch: 5| Step: 2
Training loss: 1.9898513560155355
Validation loss: 2.4902533317293174

Epoch: 5| Step: 3
Training loss: 2.2007331580180938
Validation loss: 2.4858583564396155

Epoch: 5| Step: 4
Training loss: 2.34130304393568
Validation loss: 2.4825882354465465

Epoch: 5| Step: 5
Training loss: 2.3355169523714556
Validation loss: 2.477466193743831

Epoch: 5| Step: 6
Training loss: 2.2729162293692173
Validation loss: 2.500057037020763

Epoch: 5| Step: 7
Training loss: 2.6232555587594777
Validation loss: 2.4920280230129315

Epoch: 5| Step: 8
Training loss: 2.3802735857432564
Validation loss: 2.4921660965465784

Epoch: 5| Step: 9
Training loss: 2.6835274722869977
Validation loss: 2.5116376710484545

Epoch: 5| Step: 10
Training loss: 2.9213220409672425
Validation loss: 2.5086494625735694

Epoch: 5| Step: 11
Training loss: 1.4026646154017612
Validation loss: 2.50387582745571

Epoch: 20| Step: 0
Training loss: 2.172165995252526
Validation loss: 2.524283850808445

Epoch: 5| Step: 1
Training loss: 2.6030653086913236
Validation loss: 2.526064553435687

Epoch: 5| Step: 2
Training loss: 2.3839326820725892
Validation loss: 2.523565200550643

Epoch: 5| Step: 3
Training loss: 2.0260942022447104
Validation loss: 2.5179325265672654

Epoch: 5| Step: 4
Training loss: 2.7112245435209945
Validation loss: 2.515153382599814

Epoch: 5| Step: 5
Training loss: 2.4806333952800372
Validation loss: 2.51295642210221

Epoch: 5| Step: 6
Training loss: 2.33666950098683
Validation loss: 2.5064041921062055

Epoch: 5| Step: 7
Training loss: 2.5318809005604517
Validation loss: 2.503307441526944

Epoch: 5| Step: 8
Training loss: 2.62848849328628
Validation loss: 2.5172248989099786

Epoch: 5| Step: 9
Training loss: 2.2348840307064677
Validation loss: 2.4961910596971935

Epoch: 5| Step: 10
Training loss: 2.6817755835372474
Validation loss: 2.4964808809075585

Epoch: 5| Step: 11
Training loss: 3.210203212116943
Validation loss: 2.4911796899837384

Epoch: 21| Step: 0
Training loss: 2.5911989650678318
Validation loss: 2.4933280367930997

Epoch: 5| Step: 1
Training loss: 2.445944999818817
Validation loss: 2.504895598519593

Epoch: 5| Step: 2
Training loss: 2.3942888893330094
Validation loss: 2.4840107176875055

Epoch: 5| Step: 3
Training loss: 2.440428612851154
Validation loss: 2.499070749832496

Epoch: 5| Step: 4
Training loss: 2.261650229356593
Validation loss: 2.4768990208804373

Epoch: 5| Step: 5
Training loss: 1.869368169600527
Validation loss: 2.4845377071050327

Epoch: 5| Step: 6
Training loss: 2.8548680207166233
Validation loss: 2.471937982212564

Epoch: 5| Step: 7
Training loss: 2.6416071583235556
Validation loss: 2.4853779669597516

Epoch: 5| Step: 8
Training loss: 2.4789120091883246
Validation loss: 2.479352492626241

Epoch: 5| Step: 9
Training loss: 2.4989233559665975
Validation loss: 2.4825433660831875

Epoch: 5| Step: 10
Training loss: 2.3600384114259163
Validation loss: 2.4826422512740076

Epoch: 5| Step: 11
Training loss: 2.7472702696733986
Validation loss: 2.4834389072630394

Epoch: 22| Step: 0
Training loss: 2.3622321204038617
Validation loss: 2.4807540869610767

Epoch: 5| Step: 1
Training loss: 2.1721768615400676
Validation loss: 2.4795721641403925

Epoch: 5| Step: 2
Training loss: 2.8337020260149464
Validation loss: 2.465004405384628

Epoch: 5| Step: 3
Training loss: 2.0550757211809976
Validation loss: 2.47899312659487

Epoch: 5| Step: 4
Training loss: 2.055687606567963
Validation loss: 2.474154855384742

Epoch: 5| Step: 5
Training loss: 2.5520576216252366
Validation loss: 2.4801682858449534

Epoch: 5| Step: 6
Training loss: 2.8358330825624702
Validation loss: 2.4768588894565484

Epoch: 5| Step: 7
Training loss: 2.5582955455992202
Validation loss: 2.484225440571865

Epoch: 5| Step: 8
Training loss: 2.261742362786929
Validation loss: 2.49690500049607

Epoch: 5| Step: 9
Training loss: 2.4191846116999502
Validation loss: 2.4912049320736243

Epoch: 5| Step: 10
Training loss: 2.7194085036195106
Validation loss: 2.4855574387054045

Epoch: 5| Step: 11
Training loss: 2.092485416047058
Validation loss: 2.491049400045981

Epoch: 23| Step: 0
Training loss: 2.3489041431432525
Validation loss: 2.483664820989055

Epoch: 5| Step: 1
Training loss: 2.5579525675607484
Validation loss: 2.4885977838660422

Epoch: 5| Step: 2
Training loss: 2.079762437532187
Validation loss: 2.481120745257386

Epoch: 5| Step: 3
Training loss: 2.616228799164484
Validation loss: 2.4992479961592395

Epoch: 5| Step: 4
Training loss: 2.7560535905884627
Validation loss: 2.5018410777945697

Epoch: 5| Step: 5
Training loss: 2.203086365705966
Validation loss: 2.49868276385069

Epoch: 5| Step: 6
Training loss: 2.81563300365534
Validation loss: 2.4948607072190008

Epoch: 5| Step: 7
Training loss: 2.61835401358917
Validation loss: 2.482341257822713

Epoch: 5| Step: 8
Training loss: 2.3652722759659457
Validation loss: 2.4865240462853775

Epoch: 5| Step: 9
Training loss: 2.328257614557477
Validation loss: 2.4899986045774765

Epoch: 5| Step: 10
Training loss: 2.028069573866156
Validation loss: 2.486313753168922

Epoch: 5| Step: 11
Training loss: 2.716057946358077
Validation loss: 2.482558760131663

Epoch: 24| Step: 0
Training loss: 2.6627161645670903
Validation loss: 2.484287548325392

Epoch: 5| Step: 1
Training loss: 2.384409784985709
Validation loss: 2.4879618489124753

Epoch: 5| Step: 2
Training loss: 2.276315028158861
Validation loss: 2.4872882943823202

Epoch: 5| Step: 3
Training loss: 2.355685349053459
Validation loss: 2.5000116546677087

Epoch: 5| Step: 4
Training loss: 2.2308756495573308
Validation loss: 2.5030637127965107

Epoch: 5| Step: 5
Training loss: 2.1943667943980865
Validation loss: 2.5091412134873883

Epoch: 5| Step: 6
Training loss: 2.3493036212312415
Validation loss: 2.5206022406232456

Epoch: 5| Step: 7
Training loss: 2.517191997123883
Validation loss: 2.516683450594465

Epoch: 5| Step: 8
Training loss: 2.840662695169825
Validation loss: 2.5192744713179245

Epoch: 5| Step: 9
Training loss: 2.462825281182387
Validation loss: 2.505287198248274

Epoch: 5| Step: 10
Training loss: 2.44415089862817
Validation loss: 2.493858912964968

Epoch: 5| Step: 11
Training loss: 3.252110896135265
Validation loss: 2.498006264100723

Epoch: 25| Step: 0
Training loss: 2.3951901000838225
Validation loss: 2.4928786854945852

Epoch: 5| Step: 1
Training loss: 2.49422589113747
Validation loss: 2.4966012183151607

Epoch: 5| Step: 2
Training loss: 3.0053240898664884
Validation loss: 2.4911537896588274

Epoch: 5| Step: 3
Training loss: 2.0114572892136104
Validation loss: 2.499382135413324

Epoch: 5| Step: 4
Training loss: 2.584403329161209
Validation loss: 2.4975489283399854

Epoch: 5| Step: 5
Training loss: 1.8335609150284244
Validation loss: 2.498474506026976

Epoch: 5| Step: 6
Training loss: 1.7429854272089857
Validation loss: 2.5138918077218926

Epoch: 5| Step: 7
Training loss: 2.8096201245529997
Validation loss: 2.512480185795936

Epoch: 5| Step: 8
Training loss: 2.0017717381623017
Validation loss: 2.4798169178192384

Epoch: 5| Step: 9
Training loss: 2.7531415161607318
Validation loss: 2.4937572219412623

Epoch: 5| Step: 10
Training loss: 2.885661219253266
Validation loss: 2.497931413365715

Epoch: 5| Step: 11
Training loss: 1.784235677273853
Validation loss: 2.483477984339592

Epoch: 26| Step: 0
Training loss: 2.9863761863059475
Validation loss: 2.4749396549600386

Epoch: 5| Step: 1
Training loss: 2.3833835605406177
Validation loss: 2.4770272357407395

Epoch: 5| Step: 2
Training loss: 2.613568345794391
Validation loss: 2.480504621912172

Epoch: 5| Step: 3
Training loss: 2.4274713645369688
Validation loss: 2.482851448977929

Epoch: 5| Step: 4
Training loss: 2.2168861404797213
Validation loss: 2.4874839084111153

Epoch: 5| Step: 5
Training loss: 2.7669845084420865
Validation loss: 2.476043723050297

Epoch: 5| Step: 6
Training loss: 2.556474533106409
Validation loss: 2.4884813408920143

Epoch: 5| Step: 7
Training loss: 2.3061781378407415
Validation loss: 2.4766516985308304

Epoch: 5| Step: 8
Training loss: 2.4949004614779935
Validation loss: 2.48257899193583

Epoch: 5| Step: 9
Training loss: 1.8260910587481907
Validation loss: 2.4741915556080976

Epoch: 5| Step: 10
Training loss: 2.141396710591325
Validation loss: 2.4788020885026345

Epoch: 5| Step: 11
Training loss: 1.3611348040890914
Validation loss: 2.460126054791899

Epoch: 27| Step: 0
Training loss: 2.1639051690044866
Validation loss: 2.454720899296816

Epoch: 5| Step: 1
Training loss: 3.031518039454022
Validation loss: 2.4566939526232656

Epoch: 5| Step: 2
Training loss: 2.4025701152561445
Validation loss: 2.4590091234435816

Epoch: 5| Step: 3
Training loss: 2.4486985817807962
Validation loss: 2.4623117313610545

Epoch: 5| Step: 4
Training loss: 1.6742298262919961
Validation loss: 2.458389812294838

Epoch: 5| Step: 5
Training loss: 2.4439578463076668
Validation loss: 2.4486929589210233

Epoch: 5| Step: 6
Training loss: 2.6480451535181193
Validation loss: 2.4577525484598746

Epoch: 5| Step: 7
Training loss: 2.4886197469242854
Validation loss: 2.469063887781422

Epoch: 5| Step: 8
Training loss: 2.4970324069216723
Validation loss: 2.4547455571765697

Epoch: 5| Step: 9
Training loss: 2.2222346490936378
Validation loss: 2.455805510665473

Epoch: 5| Step: 10
Training loss: 2.5868941551470717
Validation loss: 2.452855105445393

Epoch: 5| Step: 11
Training loss: 2.3666310679306006
Validation loss: 2.4640983990150813

Epoch: 28| Step: 0
Training loss: 2.537861795424601
Validation loss: 2.449065230494886

Epoch: 5| Step: 1
Training loss: 2.133442544625245
Validation loss: 2.4569084245945283

Epoch: 5| Step: 2
Training loss: 2.5231694412758783
Validation loss: 2.464902329995653

Epoch: 5| Step: 3
Training loss: 1.7795526548882377
Validation loss: 2.4811635683765987

Epoch: 5| Step: 4
Training loss: 2.130102650850804
Validation loss: 2.482816215145852

Epoch: 5| Step: 5
Training loss: 2.5129825147695226
Validation loss: 2.4759405901580367

Epoch: 5| Step: 6
Training loss: 2.7131697289383396
Validation loss: 2.5058943443009016

Epoch: 5| Step: 7
Training loss: 2.1994800039788567
Validation loss: 2.5039412307081124

Epoch: 5| Step: 8
Training loss: 2.5673264431632727
Validation loss: 2.526508627659073

Epoch: 5| Step: 9
Training loss: 2.6855458984373226
Validation loss: 2.521658294770571

Epoch: 5| Step: 10
Training loss: 2.5559805767712294
Validation loss: 2.5081303990186585

Epoch: 5| Step: 11
Training loss: 3.7230335856932846
Validation loss: 2.4982685769179764

Epoch: 29| Step: 0
Training loss: 2.407897880372219
Validation loss: 2.4842777073201088

Epoch: 5| Step: 1
Training loss: 2.829554749634076
Validation loss: 2.4874874347899762

Epoch: 5| Step: 2
Training loss: 2.6541334807887855
Validation loss: 2.472791162861023

Epoch: 5| Step: 3
Training loss: 2.217183809499109
Validation loss: 2.471144910876339

Epoch: 5| Step: 4
Training loss: 2.6634550324932325
Validation loss: 2.4681698242146006

Epoch: 5| Step: 5
Training loss: 2.517145775248489
Validation loss: 2.4667910215620967

Epoch: 5| Step: 6
Training loss: 2.7263699438968083
Validation loss: 2.46389108455488

Epoch: 5| Step: 7
Training loss: 2.0592798468642908
Validation loss: 2.4505319314692517

Epoch: 5| Step: 8
Training loss: 1.759842916436122
Validation loss: 2.4576274833715157

Epoch: 5| Step: 9
Training loss: 2.74470452321726
Validation loss: 2.454108885250559

Epoch: 5| Step: 10
Training loss: 1.9498290671721907
Validation loss: 2.4599702538847317

Epoch: 5| Step: 11
Training loss: 1.6507676275208454
Validation loss: 2.4698298502951834

Epoch: 30| Step: 0
Training loss: 2.5166913728153912
Validation loss: 2.464320353431716

Epoch: 5| Step: 1
Training loss: 2.903138823214534
Validation loss: 2.4663303021593523

Epoch: 5| Step: 2
Training loss: 2.7832040672969898
Validation loss: 2.4552285637154907

Epoch: 5| Step: 3
Training loss: 2.1908297672970627
Validation loss: 2.47073705597146

Epoch: 5| Step: 4
Training loss: 3.098750533288169
Validation loss: 2.463201597478381

Epoch: 5| Step: 5
Training loss: 1.8865652081108528
Validation loss: 2.473650249907182

Epoch: 5| Step: 6
Training loss: 1.841339798943348
Validation loss: 2.4713011247887255

Epoch: 5| Step: 7
Training loss: 2.2868314422687828
Validation loss: 2.473522679301479

Epoch: 5| Step: 8
Training loss: 1.5814503297823956
Validation loss: 2.4694333599432055

Epoch: 5| Step: 9
Training loss: 2.324026096597983
Validation loss: 2.485629440791558

Epoch: 5| Step: 10
Training loss: 2.661581455874015
Validation loss: 2.47879316551109

Epoch: 5| Step: 11
Training loss: 2.59776813008011
Validation loss: 2.496123781854355

Epoch: 31| Step: 0
Training loss: 2.2634263518502746
Validation loss: 2.476482650801324

Epoch: 5| Step: 1
Training loss: 2.633657348190809
Validation loss: 2.470084839507981

Epoch: 5| Step: 2
Training loss: 2.60633042026189
Validation loss: 2.4625570629498723

Epoch: 5| Step: 3
Training loss: 2.049648473420139
Validation loss: 2.4718701487548653

Epoch: 5| Step: 4
Training loss: 2.2039055489934856
Validation loss: 2.4604413778779817

Epoch: 5| Step: 5
Training loss: 2.33793039694397
Validation loss: 2.4578137245991627

Epoch: 5| Step: 6
Training loss: 2.6507272190351627
Validation loss: 2.4597585932333423

Epoch: 5| Step: 7
Training loss: 2.690696943962751
Validation loss: 2.4511731881065955

Epoch: 5| Step: 8
Training loss: 2.3553503206001998
Validation loss: 2.452753881255497

Epoch: 5| Step: 9
Training loss: 2.65156213314164
Validation loss: 2.444524014296551

Epoch: 5| Step: 10
Training loss: 2.06952534232299
Validation loss: 2.4480074006708428

Epoch: 5| Step: 11
Training loss: 2.7900188954031373
Validation loss: 2.448385730740602

Epoch: 32| Step: 0
Training loss: 2.3247874870391483
Validation loss: 2.4502870743456517

Epoch: 5| Step: 1
Training loss: 2.1143173526547088
Validation loss: 2.4413869343311423

Epoch: 5| Step: 2
Training loss: 2.3972259344153493
Validation loss: 2.4479960300214945

Epoch: 5| Step: 3
Training loss: 2.1554441189991853
Validation loss: 2.449964658164384

Epoch: 5| Step: 4
Training loss: 2.5815810649348827
Validation loss: 2.45023034644544

Epoch: 5| Step: 5
Training loss: 2.008762357587137
Validation loss: 2.4502206767859795

Epoch: 5| Step: 6
Training loss: 2.4607616543387762
Validation loss: 2.456565554039912

Epoch: 5| Step: 7
Training loss: 2.710527284570364
Validation loss: 2.470377783784329

Epoch: 5| Step: 8
Training loss: 2.4976380634809123
Validation loss: 2.462812268681833

Epoch: 5| Step: 9
Training loss: 2.7030069843615507
Validation loss: 2.4511258104512255

Epoch: 5| Step: 10
Training loss: 2.609330867919511
Validation loss: 2.473598676271031

Epoch: 5| Step: 11
Training loss: 1.9766638205873908
Validation loss: 2.4533829927947064

Epoch: 33| Step: 0
Training loss: 2.814913244181004
Validation loss: 2.4845760751921353

Epoch: 5| Step: 1
Training loss: 1.9600559395962238
Validation loss: 2.472695599926353

Epoch: 5| Step: 2
Training loss: 2.3623151838078096
Validation loss: 2.4615114582176574

Epoch: 5| Step: 3
Training loss: 2.3886937337703347
Validation loss: 2.4836964450310552

Epoch: 5| Step: 4
Training loss: 2.2734565865151337
Validation loss: 2.480738657686855

Epoch: 5| Step: 5
Training loss: 2.319818309213558
Validation loss: 2.488062806574296

Epoch: 5| Step: 6
Training loss: 2.5668399624305978
Validation loss: 2.4906013886510365

Epoch: 5| Step: 7
Training loss: 2.551799483311207
Validation loss: 2.475384493224223

Epoch: 5| Step: 8
Training loss: 1.8527053975512018
Validation loss: 2.4730510687733505

Epoch: 5| Step: 9
Training loss: 2.452011536028112
Validation loss: 2.4691918758301066

Epoch: 5| Step: 10
Training loss: 2.850778299436247
Validation loss: 2.4534689182305196

Epoch: 5| Step: 11
Training loss: 2.018443539627094
Validation loss: 2.4675411250376116

Epoch: 34| Step: 0
Training loss: 2.3375082699226515
Validation loss: 2.465003426080661

Epoch: 5| Step: 1
Training loss: 2.793457842064753
Validation loss: 2.4506266966657173

Epoch: 5| Step: 2
Training loss: 2.7474492120604452
Validation loss: 2.472755799742808

Epoch: 5| Step: 3
Training loss: 2.2108259948002846
Validation loss: 2.4685956307125614

Epoch: 5| Step: 4
Training loss: 2.398312941308332
Validation loss: 2.482398880662726

Epoch: 5| Step: 5
Training loss: 1.8727075549861156
Validation loss: 2.4694049747005606

Epoch: 5| Step: 6
Training loss: 2.110390199857433
Validation loss: 2.4776653738255408

Epoch: 5| Step: 7
Training loss: 2.6143069684804723
Validation loss: 2.460596159821779

Epoch: 5| Step: 8
Training loss: 2.3846778447322268
Validation loss: 2.471008440736711

Epoch: 5| Step: 9
Training loss: 2.109163400845189
Validation loss: 2.468948191320777

Epoch: 5| Step: 10
Training loss: 2.760644166796533
Validation loss: 2.4673891944574233

Epoch: 5| Step: 11
Training loss: 1.654242468505613
Validation loss: 2.465986991259668

Epoch: 35| Step: 0
Training loss: 2.2895447935748905
Validation loss: 2.4553303656005565

Epoch: 5| Step: 1
Training loss: 2.36642413530867
Validation loss: 2.453128251804537

Epoch: 5| Step: 2
Training loss: 1.9778914978191766
Validation loss: 2.4510175233347082

Epoch: 5| Step: 3
Training loss: 3.11541544707892
Validation loss: 2.444626708954129

Epoch: 5| Step: 4
Training loss: 2.02136984975252
Validation loss: 2.4472299478319695

Epoch: 5| Step: 5
Training loss: 2.024402049756327
Validation loss: 2.4471294977150966

Epoch: 5| Step: 6
Training loss: 2.3381343450005168
Validation loss: 2.4423213677988085

Epoch: 5| Step: 7
Training loss: 2.56980162764094
Validation loss: 2.456459243652815

Epoch: 5| Step: 8
Training loss: 2.5345828873007203
Validation loss: 2.435612628439727

Epoch: 5| Step: 9
Training loss: 2.300016991925706
Validation loss: 2.4379941773555007

Epoch: 5| Step: 10
Training loss: 2.2460623299432796
Validation loss: 2.4568169383600136

Epoch: 5| Step: 11
Training loss: 3.836283557455461
Validation loss: 2.4560255692299857

Epoch: 36| Step: 0
Training loss: 2.4099238699447425
Validation loss: 2.458393432938597

Epoch: 5| Step: 1
Training loss: 2.699862148156656
Validation loss: 2.454105153038798

Epoch: 5| Step: 2
Training loss: 2.2762146861454693
Validation loss: 2.4430611171975976

Epoch: 5| Step: 3
Training loss: 2.0042591044573785
Validation loss: 2.448808736111325

Epoch: 5| Step: 4
Training loss: 2.9051861200113733
Validation loss: 2.452322557334882

Epoch: 5| Step: 5
Training loss: 2.1579518996173226
Validation loss: 2.4475459298294537

Epoch: 5| Step: 6
Training loss: 2.3295358568826963
Validation loss: 2.4405501103033496

Epoch: 5| Step: 7
Training loss: 1.940395652499388
Validation loss: 2.4409569044493216

Epoch: 5| Step: 8
Training loss: 2.6574322033162328
Validation loss: 2.456894329483126

Epoch: 5| Step: 9
Training loss: 2.499993705741588
Validation loss: 2.4573337669911193

Epoch: 5| Step: 10
Training loss: 2.405360466160523
Validation loss: 2.456763604186982

Epoch: 5| Step: 11
Training loss: 1.412486425689018
Validation loss: 2.455900857100894

Epoch: 37| Step: 0
Training loss: 2.139546366232636
Validation loss: 2.4641165287768363

Epoch: 5| Step: 1
Training loss: 2.424915693724956
Validation loss: 2.452172999712863

Epoch: 5| Step: 2
Training loss: 2.2395330260784814
Validation loss: 2.4707441243626094

Epoch: 5| Step: 3
Training loss: 2.8389896330985116
Validation loss: 2.4688643095054035

Epoch: 5| Step: 4
Training loss: 2.7128003670471985
Validation loss: 2.477434492178622

Epoch: 5| Step: 5
Training loss: 2.695960367817021
Validation loss: 2.4833659336064566

Epoch: 5| Step: 6
Training loss: 2.2170069120279567
Validation loss: 2.473119787686768

Epoch: 5| Step: 7
Training loss: 1.66552734375
Validation loss: 2.4625339718716717

Epoch: 5| Step: 8
Training loss: 2.7512632416298612
Validation loss: 2.471592749256471

Epoch: 5| Step: 9
Training loss: 1.9375564197816373
Validation loss: 2.4496814183297837

Epoch: 5| Step: 10
Training loss: 2.639225063884415
Validation loss: 2.447680132510237

Epoch: 5| Step: 11
Training loss: 0.5284949840679352
Validation loss: 2.43527146296234

Epoch: 38| Step: 0
Training loss: 2.0153350621547386
Validation loss: 2.4511766532456227

Epoch: 5| Step: 1
Training loss: 2.769337721332471
Validation loss: 2.4387594457926034

Epoch: 5| Step: 2
Training loss: 2.2663823407558015
Validation loss: 2.447530693034491

Epoch: 5| Step: 3
Training loss: 1.828900686171655
Validation loss: 2.449809273445301

Epoch: 5| Step: 4
Training loss: 2.1243035914379544
Validation loss: 2.4369320737643925

Epoch: 5| Step: 5
Training loss: 2.591951689016796
Validation loss: 2.4480135993162935

Epoch: 5| Step: 6
Training loss: 2.413380251774374
Validation loss: 2.437325188082119

Epoch: 5| Step: 7
Training loss: 2.041168645205826
Validation loss: 2.439011842607674

Epoch: 5| Step: 8
Training loss: 2.4988292813950643
Validation loss: 2.4447233508013446

Epoch: 5| Step: 9
Training loss: 2.481766200720088
Validation loss: 2.4447150511101228

Epoch: 5| Step: 10
Training loss: 2.950821720054833
Validation loss: 2.460612623780946

Epoch: 5| Step: 11
Training loss: 2.5554381034877043
Validation loss: 2.4436191631132105

Epoch: 39| Step: 0
Training loss: 2.4823460961277526
Validation loss: 2.4351409802301265

Epoch: 5| Step: 1
Training loss: 2.247902104068662
Validation loss: 2.4560212938833206

Epoch: 5| Step: 2
Training loss: 2.702587272653483
Validation loss: 2.4442650701776096

Epoch: 5| Step: 3
Training loss: 2.7408245644719567
Validation loss: 2.441612277683724

Epoch: 5| Step: 4
Training loss: 2.0949865077638097
Validation loss: 2.4333468904400632

Epoch: 5| Step: 5
Training loss: 2.5913931008190194
Validation loss: 2.4471402147557346

Epoch: 5| Step: 6
Training loss: 2.1344861740268586
Validation loss: 2.4397643201058354

Epoch: 5| Step: 7
Training loss: 2.440072975787148
Validation loss: 2.4412444974085603

Epoch: 5| Step: 8
Training loss: 2.2152512594274762
Validation loss: 2.4421720315935955

Epoch: 5| Step: 9
Training loss: 2.035598560380567
Validation loss: 2.431737825833226

Epoch: 5| Step: 10
Training loss: 2.426442718005811
Validation loss: 2.435370425858647

Epoch: 5| Step: 11
Training loss: 2.0900095080656764
Validation loss: 2.4292055492222793

Epoch: 40| Step: 0
Training loss: 2.282000483560469
Validation loss: 2.433854886612778

Epoch: 5| Step: 1
Training loss: 2.2033178366819706
Validation loss: 2.4499244220909806

Epoch: 5| Step: 2
Training loss: 2.0655715496863767
Validation loss: 2.4496080899294777

Epoch: 5| Step: 3
Training loss: 1.7711043281390721
Validation loss: 2.469898882056083

Epoch: 5| Step: 4
Training loss: 2.2550058839302523
Validation loss: 2.4695507312276983

Epoch: 5| Step: 5
Training loss: 2.394068911351765
Validation loss: 2.462367285300427

Epoch: 5| Step: 6
Training loss: 2.5106788487793024
Validation loss: 2.4804779493106253

Epoch: 5| Step: 7
Training loss: 2.796195688278708
Validation loss: 2.468204639251502

Epoch: 5| Step: 8
Training loss: 2.9099738761542007
Validation loss: 2.483017796646602

Epoch: 5| Step: 9
Training loss: 2.751357697073591
Validation loss: 2.470763029596107

Epoch: 5| Step: 10
Training loss: 2.058687095769674
Validation loss: 2.4612546625572667

Epoch: 5| Step: 11
Training loss: 2.1671939599477894
Validation loss: 2.470025063251127

Epoch: 41| Step: 0
Training loss: 1.6353982410081358
Validation loss: 2.45246768049681

Epoch: 5| Step: 1
Training loss: 2.5316076143805732
Validation loss: 2.4633977671904006

Epoch: 5| Step: 2
Training loss: 2.28532338631571
Validation loss: 2.44643135393009

Epoch: 5| Step: 3
Training loss: 2.460885958661654
Validation loss: 2.460241782529861

Epoch: 5| Step: 4
Training loss: 2.7848069666152075
Validation loss: 2.4545130518150966

Epoch: 5| Step: 5
Training loss: 2.4141859498294664
Validation loss: 2.452582388393888

Epoch: 5| Step: 6
Training loss: 2.3021418591362703
Validation loss: 2.4493145414416575

Epoch: 5| Step: 7
Training loss: 2.2578916964781333
Validation loss: 2.4594435542115813

Epoch: 5| Step: 8
Training loss: 2.6926041859027325
Validation loss: 2.440018355503768

Epoch: 5| Step: 9
Training loss: 2.518815664945212
Validation loss: 2.4614429903352653

Epoch: 5| Step: 10
Training loss: 1.7616122397559733
Validation loss: 2.435609302266232

Epoch: 5| Step: 11
Training loss: 2.752618669936637
Validation loss: 2.4281966939755706

Epoch: 42| Step: 0
Training loss: 2.1766500330820553
Validation loss: 2.4376036996872092

Epoch: 5| Step: 1
Training loss: 1.9475502716745112
Validation loss: 2.4273056261375356

Epoch: 5| Step: 2
Training loss: 1.9396639399129387
Validation loss: 2.4326604295396947

Epoch: 5| Step: 3
Training loss: 1.9661261618600638
Validation loss: 2.4370592811125

Epoch: 5| Step: 4
Training loss: 2.604826474844398
Validation loss: 2.4357164329521472

Epoch: 5| Step: 5
Training loss: 2.1295050942439966
Validation loss: 2.434691131201303

Epoch: 5| Step: 6
Training loss: 2.5771433493046114
Validation loss: 2.4366370695089152

Epoch: 5| Step: 7
Training loss: 2.452635309217816
Validation loss: 2.4541687820200933

Epoch: 5| Step: 8
Training loss: 2.2446691091645223
Validation loss: 2.457807789139417

Epoch: 5| Step: 9
Training loss: 2.676586169279055
Validation loss: 2.443820290883874

Epoch: 5| Step: 10
Training loss: 2.9343228304026914
Validation loss: 2.4489776070789753

Epoch: 5| Step: 11
Training loss: 3.703445613840286
Validation loss: 2.44367930479957

Epoch: 43| Step: 0
Training loss: 2.496862636339804
Validation loss: 2.4406132012740227

Epoch: 5| Step: 1
Training loss: 2.686496458538653
Validation loss: 2.4368447458222477

Epoch: 5| Step: 2
Training loss: 1.9309037425912965
Validation loss: 2.454007433457219

Epoch: 5| Step: 3
Training loss: 1.9854965044469715
Validation loss: 2.433632953913799

Epoch: 5| Step: 4
Training loss: 2.2602719965285187
Validation loss: 2.4224921393882055

Epoch: 5| Step: 5
Training loss: 2.688423885074644
Validation loss: 2.425908612088252

Epoch: 5| Step: 6
Training loss: 2.515456484250466
Validation loss: 2.4215439067656295

Epoch: 5| Step: 7
Training loss: 2.3353945506191813
Validation loss: 2.4154612738628534

Epoch: 5| Step: 8
Training loss: 2.4063514588999673
Validation loss: 2.425889381869392

Epoch: 5| Step: 9
Training loss: 2.338356628120672
Validation loss: 2.428955282618429

Epoch: 5| Step: 10
Training loss: 2.5356442021561265
Validation loss: 2.4294908450107835

Epoch: 5| Step: 11
Training loss: 1.8829773636813136
Validation loss: 2.4279181732304864

Epoch: 44| Step: 0
Training loss: 2.1095799099329757
Validation loss: 2.4263677824735583

Epoch: 5| Step: 1
Training loss: 2.3994677191802736
Validation loss: 2.4338928638900006

Epoch: 5| Step: 2
Training loss: 1.9778664249681979
Validation loss: 2.4383541591295534

Epoch: 5| Step: 3
Training loss: 1.8941910585756494
Validation loss: 2.448595633935389

Epoch: 5| Step: 4
Training loss: 2.4381135021761002
Validation loss: 2.479726845634037

Epoch: 5| Step: 5
Training loss: 2.6485777511144977
Validation loss: 2.5020187810045047

Epoch: 5| Step: 6
Training loss: 1.9821691192202928
Validation loss: 2.4961575861624725

Epoch: 5| Step: 7
Training loss: 2.1833266639122275
Validation loss: 2.4918463741572157

Epoch: 5| Step: 8
Training loss: 2.8006191658992736
Validation loss: 2.509062585191262

Epoch: 5| Step: 9
Training loss: 2.934409280887516
Validation loss: 2.5019876247928865

Epoch: 5| Step: 10
Training loss: 2.399290647581544
Validation loss: 2.4722622742843403

Epoch: 5| Step: 11
Training loss: 3.1791943816797215
Validation loss: 2.46053236194882

Epoch: 45| Step: 0
Training loss: 2.6120170877023323
Validation loss: 2.43494043292374

Epoch: 5| Step: 1
Training loss: 2.3229608802408084
Validation loss: 2.4312539565602513

Epoch: 5| Step: 2
Training loss: 2.031970908542453
Validation loss: 2.4305898170478444

Epoch: 5| Step: 3
Training loss: 1.6527775765355661
Validation loss: 2.4456996184736557

Epoch: 5| Step: 4
Training loss: 2.775999277636959
Validation loss: 2.428743311849414

Epoch: 5| Step: 5
Training loss: 2.719915469062227
Validation loss: 2.431427086540104

Epoch: 5| Step: 6
Training loss: 2.2807354281393897
Validation loss: 2.4150572643835844

Epoch: 5| Step: 7
Training loss: 2.226914548648516
Validation loss: 2.4393429635847284

Epoch: 5| Step: 8
Training loss: 1.7838522658140723
Validation loss: 2.430754040076617

Epoch: 5| Step: 9
Training loss: 2.663301868308555
Validation loss: 2.426311744102141

Epoch: 5| Step: 10
Training loss: 2.308883209929317
Validation loss: 2.4340080696380717

Epoch: 5| Step: 11
Training loss: 2.75094085551019
Validation loss: 2.424323294464293

Epoch: 46| Step: 0
Training loss: 1.8768187920394621
Validation loss: 2.4264287939200826

Epoch: 5| Step: 1
Training loss: 2.546558664721359
Validation loss: 2.435344921183262

Epoch: 5| Step: 2
Training loss: 2.1587070342859143
Validation loss: 2.428076223098691

Epoch: 5| Step: 3
Training loss: 2.4494840974059873
Validation loss: 2.4144084192883275

Epoch: 5| Step: 4
Training loss: 1.9831756812303067
Validation loss: 2.429279338084121

Epoch: 5| Step: 5
Training loss: 2.2150644128531294
Validation loss: 2.4187351053848807

Epoch: 5| Step: 6
Training loss: 2.028987387296939
Validation loss: 2.436073458394604

Epoch: 5| Step: 7
Training loss: 2.8543065911588767
Validation loss: 2.4390916436894106

Epoch: 5| Step: 8
Training loss: 2.8025960535880663
Validation loss: 2.4350677075982654

Epoch: 5| Step: 9
Training loss: 2.260425362518976
Validation loss: 2.4202207966180644

Epoch: 5| Step: 10
Training loss: 2.636285590867152
Validation loss: 2.438928291624771

Epoch: 5| Step: 11
Training loss: 1.887516840171216
Validation loss: 2.4377288262642813

Epoch: 47| Step: 0
Training loss: 2.344474680445962
Validation loss: 2.4425843837065484

Epoch: 5| Step: 1
Training loss: 2.1381135115862615
Validation loss: 2.4293528875311767

Epoch: 5| Step: 2
Training loss: 2.340917477841012
Validation loss: 2.4363125941111954

Epoch: 5| Step: 3
Training loss: 2.5601518618720975
Validation loss: 2.4263747078535083

Epoch: 5| Step: 4
Training loss: 2.5644886394984674
Validation loss: 2.4189698874239496

Epoch: 5| Step: 5
Training loss: 2.3009808231965474
Validation loss: 2.4164648170416

Epoch: 5| Step: 6
Training loss: 2.057649978789197
Validation loss: 2.429734105913275

Epoch: 5| Step: 7
Training loss: 2.9162448759724793
Validation loss: 2.4215218850582434

Epoch: 5| Step: 8
Training loss: 1.8821991993988445
Validation loss: 2.415142910117119

Epoch: 5| Step: 9
Training loss: 2.375420181850832
Validation loss: 2.4329786303961876

Epoch: 5| Step: 10
Training loss: 1.9858140308286703
Validation loss: 2.4290183884681205

Epoch: 5| Step: 11
Training loss: 2.756150649998483
Validation loss: 2.430539455057738

Epoch: 48| Step: 0
Training loss: 2.5011745554742686
Validation loss: 2.43288964157613

Epoch: 5| Step: 1
Training loss: 1.6012578162688191
Validation loss: 2.4490331126167306

Epoch: 5| Step: 2
Training loss: 2.710357428061454
Validation loss: 2.441085045602091

Epoch: 5| Step: 3
Training loss: 2.2965430194954037
Validation loss: 2.4466857750919098

Epoch: 5| Step: 4
Training loss: 2.3589422574352206
Validation loss: 2.433796926704642

Epoch: 5| Step: 5
Training loss: 2.4254889319770285
Validation loss: 2.4494153298272128

Epoch: 5| Step: 6
Training loss: 2.420204817246234
Validation loss: 2.4373817496674914

Epoch: 5| Step: 7
Training loss: 2.319288650833749
Validation loss: 2.4332961445953933

Epoch: 5| Step: 8
Training loss: 2.3647401956519722
Validation loss: 2.416033852420306

Epoch: 5| Step: 9
Training loss: 2.0223990467277524
Validation loss: 2.4344360012561608

Epoch: 5| Step: 10
Training loss: 2.490558917270971
Validation loss: 2.4288401419141192

Epoch: 5| Step: 11
Training loss: 2.489585738134353
Validation loss: 2.4299309374501856

Epoch: 49| Step: 0
Training loss: 2.192085364879234
Validation loss: 2.437890172362483

Epoch: 5| Step: 1
Training loss: 2.385122511494205
Validation loss: 2.4463797120375452

Epoch: 5| Step: 2
Training loss: 2.223246356953834
Validation loss: 2.437036099264493

Epoch: 5| Step: 3
Training loss: 2.313455745012396
Validation loss: 2.4501668746714964

Epoch: 5| Step: 4
Training loss: 1.800098347626237
Validation loss: 2.451013214934049

Epoch: 5| Step: 5
Training loss: 2.1414742003567206
Validation loss: 2.4510054695211556

Epoch: 5| Step: 6
Training loss: 2.3197116266450526
Validation loss: 2.452208045914559

Epoch: 5| Step: 7
Training loss: 2.399349176059718
Validation loss: 2.45712059760163

Epoch: 5| Step: 8
Training loss: 2.5181688040461836
Validation loss: 2.453947304025271

Epoch: 5| Step: 9
Training loss: 2.3855009327848484
Validation loss: 2.4766678772658532

Epoch: 5| Step: 10
Training loss: 2.38612950320021
Validation loss: 2.4410773622874764

Epoch: 5| Step: 11
Training loss: 4.193727104931799
Validation loss: 2.4412676148789103

Epoch: 50| Step: 0
Training loss: 2.1109228036229144
Validation loss: 2.4432422092479684

Epoch: 5| Step: 1
Training loss: 1.7046581681872268
Validation loss: 2.4193555955988204

Epoch: 5| Step: 2
Training loss: 3.12961954089697
Validation loss: 2.429263266992231

Epoch: 5| Step: 3
Training loss: 1.9576774946398625
Validation loss: 2.4223003260085134

Epoch: 5| Step: 4
Training loss: 2.643014943629441
Validation loss: 2.4208235026984504

Epoch: 5| Step: 5
Training loss: 2.2403707022123145
Validation loss: 2.427298193877429

Epoch: 5| Step: 6
Training loss: 2.6654144168152727
Validation loss: 2.420606087957864

Epoch: 5| Step: 7
Training loss: 1.9133811516496229
Validation loss: 2.42835445367268

Epoch: 5| Step: 8
Training loss: 2.7527581168545208
Validation loss: 2.4215260572190025

Epoch: 5| Step: 9
Training loss: 2.0794579382804637
Validation loss: 2.425798564527621

Epoch: 5| Step: 10
Training loss: 2.5405284229799023
Validation loss: 2.4044873151599924

Epoch: 5| Step: 11
Training loss: 1.5915124182664544
Validation loss: 2.411650391847583

Epoch: 51| Step: 0
Training loss: 2.0993753276164875
Validation loss: 2.4165399651089414

Epoch: 5| Step: 1
Training loss: 2.442503073933443
Validation loss: 2.449741881585641

Epoch: 5| Step: 2
Training loss: 2.7425188261097064
Validation loss: 2.4642404784288594

Epoch: 5| Step: 3
Training loss: 2.0789796606245985
Validation loss: 2.4670962536853676

Epoch: 5| Step: 4
Training loss: 2.2350250578975466
Validation loss: 2.4684587258521264

Epoch: 5| Step: 5
Training loss: 2.52948897527014
Validation loss: 2.500517330685015

Epoch: 5| Step: 6
Training loss: 2.4337326671451396
Validation loss: 2.4763516979172864

Epoch: 5| Step: 7
Training loss: 1.7114907680912201
Validation loss: 2.475093171022874

Epoch: 5| Step: 8
Training loss: 2.588633995533086
Validation loss: 2.462246222901466

Epoch: 5| Step: 9
Training loss: 2.306185788136831
Validation loss: 2.4468429902744946

Epoch: 5| Step: 10
Training loss: 2.215825369616034
Validation loss: 2.4534961861019164

Epoch: 5| Step: 11
Training loss: 2.886561491403283
Validation loss: 2.471350105424337

Epoch: 52| Step: 0
Training loss: 2.539461638549748
Validation loss: 2.4576354827802165

Epoch: 5| Step: 1
Training loss: 2.225555941959999
Validation loss: 2.4534293105457183

Epoch: 5| Step: 2
Training loss: 1.8686286759304325
Validation loss: 2.455759213460287

Epoch: 5| Step: 3
Training loss: 2.368843632359792
Validation loss: 2.4467394588666034

Epoch: 5| Step: 4
Training loss: 2.8490833950081957
Validation loss: 2.4461712817114125

Epoch: 5| Step: 5
Training loss: 1.9389803983534684
Validation loss: 2.442735917207427

Epoch: 5| Step: 6
Training loss: 2.1036826858132223
Validation loss: 2.4366824702751897

Epoch: 5| Step: 7
Training loss: 2.325952937587322
Validation loss: 2.4402006341246114

Epoch: 5| Step: 8
Training loss: 1.9268499353333324
Validation loss: 2.4408695658487205

Epoch: 5| Step: 9
Training loss: 2.850987541029677
Validation loss: 2.436944221647697

Epoch: 5| Step: 10
Training loss: 2.2663898097917707
Validation loss: 2.4565870027962338

Epoch: 5| Step: 11
Training loss: 2.1180451967858103
Validation loss: 2.4334351440473148

Epoch: 53| Step: 0
Training loss: 2.156476879623019
Validation loss: 2.4332234328961633

Epoch: 5| Step: 1
Training loss: 2.6895061368572617
Validation loss: 2.4192512738628316

Epoch: 5| Step: 2
Training loss: 2.3460443075472495
Validation loss: 2.4096492602991875

Epoch: 5| Step: 3
Training loss: 2.459390208331809
Validation loss: 2.413224693188042

Epoch: 5| Step: 4
Training loss: 2.681983697982502
Validation loss: 2.4255728148321887

Epoch: 5| Step: 5
Training loss: 1.8938690601351658
Validation loss: 2.4284674554761745

Epoch: 5| Step: 6
Training loss: 2.3497475752295953
Validation loss: 2.4233878138171216

Epoch: 5| Step: 7
Training loss: 2.6201918026554156
Validation loss: 2.433147652827046

Epoch: 5| Step: 8
Training loss: 2.257005382269449
Validation loss: 2.4366889362278625

Epoch: 5| Step: 9
Training loss: 2.012042862050719
Validation loss: 2.4131894924988164

Epoch: 5| Step: 10
Training loss: 2.3165942882876793
Validation loss: 2.429953798703876

Epoch: 5| Step: 11
Training loss: 2.0575571653413327
Validation loss: 2.4173132090480007

Epoch: 54| Step: 0
Training loss: 1.7831725068821964
Validation loss: 2.4223162505460563

Epoch: 5| Step: 1
Training loss: 2.666866136084256
Validation loss: 2.4160714704534825

Epoch: 5| Step: 2
Training loss: 2.5836084485969657
Validation loss: 2.4131087031024503

Epoch: 5| Step: 3
Training loss: 2.5617453231433784
Validation loss: 2.4298113436685655

Epoch: 5| Step: 4
Training loss: 2.41388412853611
Validation loss: 2.423741722564964

Epoch: 5| Step: 5
Training loss: 1.7459518750474452
Validation loss: 2.4319827021724265

Epoch: 5| Step: 6
Training loss: 2.1799432201165536
Validation loss: 2.427821367771103

Epoch: 5| Step: 7
Training loss: 2.2877840501537596
Validation loss: 2.42127682671811

Epoch: 5| Step: 8
Training loss: 1.826472260764461
Validation loss: 2.424182022739353

Epoch: 5| Step: 9
Training loss: 2.173299747492267
Validation loss: 2.45235781406835

Epoch: 5| Step: 10
Training loss: 2.3762930311614117
Validation loss: 2.446589456415327

Epoch: 5| Step: 11
Training loss: 4.288348918540043
Validation loss: 2.4641875669693656

Epoch: 55| Step: 0
Training loss: 2.3071936478184782
Validation loss: 2.454420160879126

Epoch: 5| Step: 1
Training loss: 2.1535802705895497
Validation loss: 2.4538042136532123

Epoch: 5| Step: 2
Training loss: 2.395707456073861
Validation loss: 2.4454638746084347

Epoch: 5| Step: 3
Training loss: 2.08444823632554
Validation loss: 2.42029812248069

Epoch: 5| Step: 4
Training loss: 2.4565565078171177
Validation loss: 2.4421471938803476

Epoch: 5| Step: 5
Training loss: 2.1057991518789723
Validation loss: 2.4240990548022756

Epoch: 5| Step: 6
Training loss: 2.2641863234247834
Validation loss: 2.4287378554826686

Epoch: 5| Step: 7
Training loss: 2.578705970732218
Validation loss: 2.4205112555442496

Epoch: 5| Step: 8
Training loss: 1.9924014705864672
Validation loss: 2.416073703093504

Epoch: 5| Step: 9
Training loss: 2.1992685098930456
Validation loss: 2.421851861494548

Epoch: 5| Step: 10
Training loss: 2.678907275262271
Validation loss: 2.4253795002384053

Epoch: 5| Step: 11
Training loss: 2.976310819463447
Validation loss: 2.434143269698618

Epoch: 56| Step: 0
Training loss: 2.083223212828566
Validation loss: 2.4288774184557416

Epoch: 5| Step: 1
Training loss: 2.132746657029397
Validation loss: 2.411817908341607

Epoch: 5| Step: 2
Training loss: 2.918754339112808
Validation loss: 2.41181640081301

Epoch: 5| Step: 3
Training loss: 2.462073460540456
Validation loss: 2.4086124539461076

Epoch: 5| Step: 4
Training loss: 2.320428504998131
Validation loss: 2.4177947919036953

Epoch: 5| Step: 5
Training loss: 2.125835478853972
Validation loss: 2.4147661411991166

Epoch: 5| Step: 6
Training loss: 1.9742207281467323
Validation loss: 2.4040837424558887

Epoch: 5| Step: 7
Training loss: 2.5937367634263158
Validation loss: 2.4143350585186707

Epoch: 5| Step: 8
Training loss: 2.4605652542748047
Validation loss: 2.414343437958247

Epoch: 5| Step: 9
Training loss: 2.3580038368446252
Validation loss: 2.429452052672828

Epoch: 5| Step: 10
Training loss: 1.819319753119271
Validation loss: 2.4288604612585605

Epoch: 5| Step: 11
Training loss: 2.38065498106834
Validation loss: 2.4207584924887384

Epoch: 57| Step: 0
Training loss: 2.2550843331750245
Validation loss: 2.4241064272040402

Epoch: 5| Step: 1
Training loss: 1.5143876678277026
Validation loss: 2.427818998630151

Epoch: 5| Step: 2
Training loss: 2.2800438187387218
Validation loss: 2.4354852761904486

Epoch: 5| Step: 3
Training loss: 1.9984237300586305
Validation loss: 2.469191829563051

Epoch: 5| Step: 4
Training loss: 2.921604409157475
Validation loss: 2.4736219732943385

Epoch: 5| Step: 5
Training loss: 2.6273589660948025
Validation loss: 2.4934386019894133

Epoch: 5| Step: 6
Training loss: 2.0070749553526417
Validation loss: 2.499836431556523

Epoch: 5| Step: 7
Training loss: 2.172275423968638
Validation loss: 2.5173449944751223

Epoch: 5| Step: 8
Training loss: 2.859335810491773
Validation loss: 2.5169822396071213

Epoch: 5| Step: 9
Training loss: 2.2546538860012197
Validation loss: 2.508796380055745

Epoch: 5| Step: 10
Training loss: 2.2099295431444963
Validation loss: 2.4721183573470014

Epoch: 5| Step: 11
Training loss: 2.4431413756041556
Validation loss: 2.4666884784335537

Epoch: 58| Step: 0
Training loss: 1.6181604526919227
Validation loss: 2.426286887331167

Epoch: 5| Step: 1
Training loss: 2.907585575487707
Validation loss: 2.433512397006397

Epoch: 5| Step: 2
Training loss: 1.9839231922910112
Validation loss: 2.4069773515995543

Epoch: 5| Step: 3
Training loss: 2.116986367219142
Validation loss: 2.4072796117419406

Epoch: 5| Step: 4
Training loss: 2.1112337188363957
Validation loss: 2.4081884849332282

Epoch: 5| Step: 5
Training loss: 1.9264829645500154
Validation loss: 2.414701473932391

Epoch: 5| Step: 6
Training loss: 2.2793564972520075
Validation loss: 2.4114949647223525

Epoch: 5| Step: 7
Training loss: 2.017582851821665
Validation loss: 2.4267861132439483

Epoch: 5| Step: 8
Training loss: 2.63241637558086
Validation loss: 2.429702492981472

Epoch: 5| Step: 9
Training loss: 2.874589641973478
Validation loss: 2.421948614334801

Epoch: 5| Step: 10
Training loss: 2.6232223849684866
Validation loss: 2.4076312505821367

Epoch: 5| Step: 11
Training loss: 2.16140043495183
Validation loss: 2.4098051774815956

Epoch: 59| Step: 0
Training loss: 2.392025406501595
Validation loss: 2.415288702226116

Epoch: 5| Step: 1
Training loss: 1.6846315942204841
Validation loss: 2.4141497097291125

Epoch: 5| Step: 2
Training loss: 2.3943079086618564
Validation loss: 2.4184389247841622

Epoch: 5| Step: 3
Training loss: 1.9399639582481314
Validation loss: 2.4233976725280195

Epoch: 5| Step: 4
Training loss: 2.794562721235199
Validation loss: 2.432863455524398

Epoch: 5| Step: 5
Training loss: 1.6402473378333553
Validation loss: 2.4433140332481917

Epoch: 5| Step: 6
Training loss: 2.3657046668723924
Validation loss: 2.457536474622112

Epoch: 5| Step: 7
Training loss: 2.7069664268934193
Validation loss: 2.4766013566588043

Epoch: 5| Step: 8
Training loss: 2.4508585573844206
Validation loss: 2.483590877995686

Epoch: 5| Step: 9
Training loss: 2.381106306731709
Validation loss: 2.47415867981393

Epoch: 5| Step: 10
Training loss: 2.249599421128569
Validation loss: 2.471846780965543

Epoch: 5| Step: 11
Training loss: 2.2793168538581865
Validation loss: 2.4591315167120196

Epoch: 60| Step: 0
Training loss: 2.6444264874351737
Validation loss: 2.442418641818123

Epoch: 5| Step: 1
Training loss: 2.638414349190653
Validation loss: 2.459376151679616

Epoch: 5| Step: 2
Training loss: 2.0161624162432634
Validation loss: 2.4165782597145204

Epoch: 5| Step: 3
Training loss: 2.035469133630776
Validation loss: 2.410871497499482

Epoch: 5| Step: 4
Training loss: 2.327842746496634
Validation loss: 2.4093333178459333

Epoch: 5| Step: 5
Training loss: 2.100241887830123
Validation loss: 2.4268141680492676

Epoch: 5| Step: 6
Training loss: 2.042930237970537
Validation loss: 2.4049605324659886

Epoch: 5| Step: 7
Training loss: 2.2601439374475594
Validation loss: 2.4171197085664824

Epoch: 5| Step: 8
Training loss: 2.3066086859756916
Validation loss: 2.412032655636168

Epoch: 5| Step: 9
Training loss: 2.4249572828797428
Validation loss: 2.3997790615720946

Epoch: 5| Step: 10
Training loss: 2.160296526970809
Validation loss: 2.416872403551431

Epoch: 5| Step: 11
Training loss: 3.271286287146563
Validation loss: 2.4255359789802977

Epoch: 61| Step: 0
Training loss: 2.3325523931541348
Validation loss: 2.4272602300616604

Epoch: 5| Step: 1
Training loss: 2.687660922178425
Validation loss: 2.413094656792283

Epoch: 5| Step: 2
Training loss: 1.7408352380757055
Validation loss: 2.4184325538062508

Epoch: 5| Step: 3
Training loss: 2.602612441068032
Validation loss: 2.41421537933697

Epoch: 5| Step: 4
Training loss: 2.792600466048818
Validation loss: 2.410997723008342

Epoch: 5| Step: 5
Training loss: 2.2837898016239824
Validation loss: 2.410708862295223

Epoch: 5| Step: 6
Training loss: 1.8220210100296264
Validation loss: 2.4226201049509593

Epoch: 5| Step: 7
Training loss: 2.1910943065980737
Validation loss: 2.4218337414416324

Epoch: 5| Step: 8
Training loss: 1.8813151503526169
Validation loss: 2.422249609165224

Epoch: 5| Step: 9
Training loss: 2.3011829692603576
Validation loss: 2.4276449443276196

Epoch: 5| Step: 10
Training loss: 2.0750654830711253
Validation loss: 2.4216489194128674

Epoch: 5| Step: 11
Training loss: 2.395168997390792
Validation loss: 2.4164801859980956

Epoch: 62| Step: 0
Training loss: 2.2027605986382928
Validation loss: 2.4333210828605574

Epoch: 5| Step: 1
Training loss: 2.3231207810662
Validation loss: 2.4287564987001433

Epoch: 5| Step: 2
Training loss: 2.297452581536864
Validation loss: 2.4394558758156393

Epoch: 5| Step: 3
Training loss: 1.7728833916750686
Validation loss: 2.4353520841386604

Epoch: 5| Step: 4
Training loss: 2.527379974624475
Validation loss: 2.4379898765004073

Epoch: 5| Step: 5
Training loss: 2.701485638382782
Validation loss: 2.451508501705019

Epoch: 5| Step: 6
Training loss: 2.0976721622708854
Validation loss: 2.452602646727924

Epoch: 5| Step: 7
Training loss: 2.2408004883552843
Validation loss: 2.448272372164832

Epoch: 5| Step: 8
Training loss: 2.085998191379191
Validation loss: 2.453724870817052

Epoch: 5| Step: 9
Training loss: 2.0394363937466116
Validation loss: 2.4511832106532063

Epoch: 5| Step: 10
Training loss: 2.270830265241411
Validation loss: 2.4597065061948715

Epoch: 5| Step: 11
Training loss: 3.1852663479139887
Validation loss: 2.4450881375703024

Epoch: 63| Step: 0
Training loss: 2.3610780140171452
Validation loss: 2.423701143383877

Epoch: 5| Step: 1
Training loss: 1.768469957484235
Validation loss: 2.410422946676669

Epoch: 5| Step: 2
Training loss: 2.5712513238127346
Validation loss: 2.408534895212592

Epoch: 5| Step: 3
Training loss: 2.2341407706460092
Validation loss: 2.4200281423122507

Epoch: 5| Step: 4
Training loss: 2.249597089508366
Validation loss: 2.429160008713075

Epoch: 5| Step: 5
Training loss: 2.1697874946084084
Validation loss: 2.431740820274571

Epoch: 5| Step: 6
Training loss: 2.1126243148431536
Validation loss: 2.4124236835175767

Epoch: 5| Step: 7
Training loss: 2.3007498513946767
Validation loss: 2.4459735009474057

Epoch: 5| Step: 8
Training loss: 2.8236856762102023
Validation loss: 2.4147605956549714

Epoch: 5| Step: 9
Training loss: 2.454932646283911
Validation loss: 2.4149881664259993

Epoch: 5| Step: 10
Training loss: 1.7661499323375958
Validation loss: 2.4081166342873717

Epoch: 5| Step: 11
Training loss: 2.880780917893517
Validation loss: 2.4236561982941294

Epoch: 64| Step: 0
Training loss: 2.132065079624368
Validation loss: 2.408732388829094

Epoch: 5| Step: 1
Training loss: 2.6028550061801408
Validation loss: 2.4138763668724184

Epoch: 5| Step: 2
Training loss: 2.7256231138016846
Validation loss: 2.4124365457283705

Epoch: 5| Step: 3
Training loss: 2.0152117874882025
Validation loss: 2.4237879058919236

Epoch: 5| Step: 4
Training loss: 2.7298667145774553
Validation loss: 2.4244781655303713

Epoch: 5| Step: 5
Training loss: 1.6402365088307
Validation loss: 2.434307991643231

Epoch: 5| Step: 6
Training loss: 1.9856259465538029
Validation loss: 2.4178326619296047

Epoch: 5| Step: 7
Training loss: 2.0488985265922097
Validation loss: 2.4471855708630073

Epoch: 5| Step: 8
Training loss: 1.948473158986516
Validation loss: 2.437860274791948

Epoch: 5| Step: 9
Training loss: 2.4815800137460857
Validation loss: 2.47001695113601

Epoch: 5| Step: 10
Training loss: 1.9777593796061226
Validation loss: 2.4560646173214504

Epoch: 5| Step: 11
Training loss: 2.9783942726303554
Validation loss: 2.4554740568292397

Epoch: 65| Step: 0
Training loss: 2.4891149061568543
Validation loss: 2.4365694927177044

Epoch: 5| Step: 1
Training loss: 2.388012224942454
Validation loss: 2.433365686138407

Epoch: 5| Step: 2
Training loss: 2.1839710653435436
Validation loss: 2.433057786225628

Epoch: 5| Step: 3
Training loss: 1.669608531800146
Validation loss: 2.4168876116699543

Epoch: 5| Step: 4
Training loss: 2.7538513610997164
Validation loss: 2.423667537626838

Epoch: 5| Step: 5
Training loss: 2.026642959397508
Validation loss: 2.420388739878921

Epoch: 5| Step: 6
Training loss: 2.464018718400675
Validation loss: 2.410837885969575

Epoch: 5| Step: 7
Training loss: 2.431055989896815
Validation loss: 2.4175093999723973

Epoch: 5| Step: 8
Training loss: 2.0580562925063544
Validation loss: 2.4087025520793217

Epoch: 5| Step: 9
Training loss: 2.205519004516775
Validation loss: 2.4311083883967757

Epoch: 5| Step: 10
Training loss: 1.7807471920892615
Validation loss: 2.425769316500081

Epoch: 5| Step: 11
Training loss: 2.574441393658027
Validation loss: 2.416520070419982

Epoch: 66| Step: 0
Training loss: 2.6125269144670447
Validation loss: 2.404046308743179

Epoch: 5| Step: 1
Training loss: 1.8218207271075686
Validation loss: 2.422641575406058

Epoch: 5| Step: 2
Training loss: 2.1025203521505507
Validation loss: 2.4103812221425756

Epoch: 5| Step: 3
Training loss: 2.4374086411790366
Validation loss: 2.4124413430457166

Epoch: 5| Step: 4
Training loss: 2.1857203192320394
Validation loss: 2.4048021964616764

Epoch: 5| Step: 5
Training loss: 2.1737619888650688
Validation loss: 2.415502729689537

Epoch: 5| Step: 6
Training loss: 2.0877037999611128
Validation loss: 2.417693913893547

Epoch: 5| Step: 7
Training loss: 2.071294932916893
Validation loss: 2.4256386420634546

Epoch: 5| Step: 8
Training loss: 2.3322540125690185
Validation loss: 2.406213673404104

Epoch: 5| Step: 9
Training loss: 2.4722164299238645
Validation loss: 2.4185057697484944

Epoch: 5| Step: 10
Training loss: 2.3251185110098107
Validation loss: 2.4217102281857903

Epoch: 5| Step: 11
Training loss: 1.51908526703505
Validation loss: 2.44312255345942

Epoch: 67| Step: 0
Training loss: 2.3800450998729414
Validation loss: 2.459800372727159

Epoch: 5| Step: 1
Training loss: 2.265354008746233
Validation loss: 2.4952082846895993

Epoch: 5| Step: 2
Training loss: 1.9044010388178196
Validation loss: 2.497148484970833

Epoch: 5| Step: 3
Training loss: 2.291992603589651
Validation loss: 2.5196230179193364

Epoch: 5| Step: 4
Training loss: 1.8726773180868619
Validation loss: 2.4932075294483855

Epoch: 5| Step: 5
Training loss: 2.659359088495979
Validation loss: 2.489990150593041

Epoch: 5| Step: 6
Training loss: 2.8080915869587106
Validation loss: 2.4969905919614654

Epoch: 5| Step: 7
Training loss: 2.1123632668931687
Validation loss: 2.459741422847027

Epoch: 5| Step: 8
Training loss: 2.1544456119325432
Validation loss: 2.467631271649086

Epoch: 5| Step: 9
Training loss: 2.0697906412225446
Validation loss: 2.439888248776809

Epoch: 5| Step: 10
Training loss: 2.10645436730205
Validation loss: 2.4415722477746513

Epoch: 5| Step: 11
Training loss: 2.319070502903377
Validation loss: 2.430431669044941

Epoch: 68| Step: 0
Training loss: 2.216361143334246
Validation loss: 2.4271172055894676

Epoch: 5| Step: 1
Training loss: 2.102600748775773
Validation loss: 2.409060201682976

Epoch: 5| Step: 2
Training loss: 2.5098899721445416
Validation loss: 2.4227656213765005

Epoch: 5| Step: 3
Training loss: 2.5126328770055872
Validation loss: 2.436080513182285

Epoch: 5| Step: 4
Training loss: 1.9725853633419204
Validation loss: 2.4130075324389284

Epoch: 5| Step: 5
Training loss: 2.887496987873835
Validation loss: 2.423421218492723

Epoch: 5| Step: 6
Training loss: 1.531935791278624
Validation loss: 2.427264887577697

Epoch: 5| Step: 7
Training loss: 2.0399195013806395
Validation loss: 2.4201157363691452

Epoch: 5| Step: 8
Training loss: 2.2514699796453836
Validation loss: 2.4103795241316224

Epoch: 5| Step: 9
Training loss: 1.9042197500407647
Validation loss: 2.4316816375010983

Epoch: 5| Step: 10
Training loss: 2.21029783235675
Validation loss: 2.4365753311002685

Epoch: 5| Step: 11
Training loss: 2.3483432773716166
Validation loss: 2.4303087480818646

Epoch: 69| Step: 0
Training loss: 2.0147431092940247
Validation loss: 2.4262193272980888

Epoch: 5| Step: 1
Training loss: 2.183919756033508
Validation loss: 2.456547028860398

Epoch: 5| Step: 2
Training loss: 2.133306313383334
Validation loss: 2.4455972714911227

Epoch: 5| Step: 3
Training loss: 1.7680891278357398
Validation loss: 2.4496767263836166

Epoch: 5| Step: 4
Training loss: 2.4025422301138577
Validation loss: 2.4498535217885697

Epoch: 5| Step: 5
Training loss: 2.182678795271452
Validation loss: 2.4657191894745387

Epoch: 5| Step: 6
Training loss: 1.9203567710845093
Validation loss: 2.4458733992947708

Epoch: 5| Step: 7
Training loss: 2.349800336756217
Validation loss: 2.4528762221486327

Epoch: 5| Step: 8
Training loss: 1.9899177336821012
Validation loss: 2.450663970161344

Epoch: 5| Step: 9
Training loss: 2.927717762315276
Validation loss: 2.461368575513189

Epoch: 5| Step: 10
Training loss: 2.2046264510215106
Validation loss: 2.439920959325911

Epoch: 5| Step: 11
Training loss: 2.6892285665317734
Validation loss: 2.4528639061188375

Epoch: 70| Step: 0
Training loss: 2.2219175911428026
Validation loss: 2.431265029599267

Epoch: 5| Step: 1
Training loss: 2.6120346129374608
Validation loss: 2.4112802539982128

Epoch: 5| Step: 2
Training loss: 2.2632159875816784
Validation loss: 2.4140207231480697

Epoch: 5| Step: 3
Training loss: 1.9900128631559453
Validation loss: 2.4255639765722816

Epoch: 5| Step: 4
Training loss: 1.9639737760886886
Validation loss: 2.4180110584639314

Epoch: 5| Step: 5
Training loss: 2.220062512385389
Validation loss: 2.408655611395134

Epoch: 5| Step: 6
Training loss: 2.039488298528929
Validation loss: 2.416385650053625

Epoch: 5| Step: 7
Training loss: 2.253801525201907
Validation loss: 2.4120981275370887

Epoch: 5| Step: 8
Training loss: 2.122071773073876
Validation loss: 2.4216625222962427

Epoch: 5| Step: 9
Training loss: 2.08321840605039
Validation loss: 2.4068830573878985

Epoch: 5| Step: 10
Training loss: 2.596787937141695
Validation loss: 2.4017402738660985

Epoch: 5| Step: 11
Training loss: 1.7663240652355319
Validation loss: 2.4226061588945154

Epoch: 71| Step: 0
Training loss: 2.0739581560421887
Validation loss: 2.4344249916085356

Epoch: 5| Step: 1
Training loss: 2.253947292331044
Validation loss: 2.4656845730223362

Epoch: 5| Step: 2
Training loss: 2.344528475857968
Validation loss: 2.5073294010870253

Epoch: 5| Step: 3
Training loss: 1.6438685733396008
Validation loss: 2.5096312094786386

Epoch: 5| Step: 4
Training loss: 2.2490114583579692
Validation loss: 2.497720915341381

Epoch: 5| Step: 5
Training loss: 2.485462454549671
Validation loss: 2.515504052234162

Epoch: 5| Step: 6
Training loss: 2.162170574697032
Validation loss: 2.533375369735432

Epoch: 5| Step: 7
Training loss: 1.970251388872652
Validation loss: 2.522829531722342

Epoch: 5| Step: 8
Training loss: 2.4823916213550357
Validation loss: 2.510226168600147

Epoch: 5| Step: 9
Training loss: 2.6085220130545825
Validation loss: 2.4831598977088993

Epoch: 5| Step: 10
Training loss: 2.043080080693238
Validation loss: 2.4772729386148478

Epoch: 5| Step: 11
Training loss: 1.62742477852573
Validation loss: 2.445743071944691

Epoch: 72| Step: 0
Training loss: 2.4755762103790655
Validation loss: 2.4110400961148906

Epoch: 5| Step: 1
Training loss: 1.7711916916213863
Validation loss: 2.4094713331162287

Epoch: 5| Step: 2
Training loss: 2.2546186726111177
Validation loss: 2.4072707888529945

Epoch: 5| Step: 3
Training loss: 2.6378055847460558
Validation loss: 2.427012959607447

Epoch: 5| Step: 4
Training loss: 2.08829653499217
Validation loss: 2.4134298357672486

Epoch: 5| Step: 5
Training loss: 2.3547056363223042
Validation loss: 2.4083640278660843

Epoch: 5| Step: 6
Training loss: 2.462789365545785
Validation loss: 2.419506818405564

Epoch: 5| Step: 7
Training loss: 2.264053536365106
Validation loss: 2.4134673173955843

Epoch: 5| Step: 8
Training loss: 1.9322808634686492
Validation loss: 2.4111780219296404

Epoch: 5| Step: 9
Training loss: 2.119588243876126
Validation loss: 2.426462996015384

Epoch: 5| Step: 10
Training loss: 1.8618240256244891
Validation loss: 2.4380417246264035

Epoch: 5| Step: 11
Training loss: 2.66963306977455
Validation loss: 2.420636038583909

Epoch: 73| Step: 0
Training loss: 2.0871580746148997
Validation loss: 2.4379708495568355

Epoch: 5| Step: 1
Training loss: 2.4293585551544163
Validation loss: 2.429035487703477

Epoch: 5| Step: 2
Training loss: 1.8330812353144201
Validation loss: 2.41629939467398

Epoch: 5| Step: 3
Training loss: 2.373745436340091
Validation loss: 2.439721362777731

Epoch: 5| Step: 4
Training loss: 1.930696725448445
Validation loss: 2.4424174622939376

Epoch: 5| Step: 5
Training loss: 2.3330004545457435
Validation loss: 2.4354486351318916

Epoch: 5| Step: 6
Training loss: 2.2640347918071364
Validation loss: 2.4417002630580535

Epoch: 5| Step: 7
Training loss: 2.241862416376978
Validation loss: 2.426778364190438

Epoch: 5| Step: 8
Training loss: 2.1806107073354015
Validation loss: 2.419398707174559

Epoch: 5| Step: 9
Training loss: 2.0045467193479998
Validation loss: 2.410122414160273

Epoch: 5| Step: 10
Training loss: 2.1944396975287535
Validation loss: 2.4163514677116167

Epoch: 5| Step: 11
Training loss: 2.9142577077818155
Validation loss: 2.430346508951495

Epoch: 74| Step: 0
Training loss: 1.8375209391951404
Validation loss: 2.4087047936117556

Epoch: 5| Step: 1
Training loss: 1.7023536965445925
Validation loss: 2.425171692085901

Epoch: 5| Step: 2
Training loss: 2.108227792241795
Validation loss: 2.432693641550501

Epoch: 5| Step: 3
Training loss: 2.474396055883057
Validation loss: 2.421933501572735

Epoch: 5| Step: 4
Training loss: 2.4303046420935273
Validation loss: 2.4235037177471663

Epoch: 5| Step: 5
Training loss: 1.9372948568705992
Validation loss: 2.4181387147755253

Epoch: 5| Step: 6
Training loss: 2.1157291358550965
Validation loss: 2.4011813258985306

Epoch: 5| Step: 7
Training loss: 2.4021801900622157
Validation loss: 2.4324198994675226

Epoch: 5| Step: 8
Training loss: 2.0298714287918673
Validation loss: 2.4152513085029317

Epoch: 5| Step: 9
Training loss: 2.1295183054380633
Validation loss: 2.440912946581547

Epoch: 5| Step: 10
Training loss: 2.3909746300832344
Validation loss: 2.4288058587700863

Epoch: 5| Step: 11
Training loss: 2.7845912108727777
Validation loss: 2.440418371098254

Epoch: 75| Step: 0
Training loss: 2.624586981115629
Validation loss: 2.44285098854284

Epoch: 5| Step: 1
Training loss: 2.3481359515367535
Validation loss: 2.4560872636357467

Epoch: 5| Step: 2
Training loss: 2.5276718280465706
Validation loss: 2.4723328935899564

Epoch: 5| Step: 3
Training loss: 1.6995690697160841
Validation loss: 2.433372965145921

Epoch: 5| Step: 4
Training loss: 2.613183719656818
Validation loss: 2.45641818178565

Epoch: 5| Step: 5
Training loss: 1.8111542276634136
Validation loss: 2.4335687920773905

Epoch: 5| Step: 6
Training loss: 2.232676467328769
Validation loss: 2.4194374410352966

Epoch: 5| Step: 7
Training loss: 1.975659914465476
Validation loss: 2.4258497006335813

Epoch: 5| Step: 8
Training loss: 2.4187656254226697
Validation loss: 2.425880352295379

Epoch: 5| Step: 9
Training loss: 1.6022504864003144
Validation loss: 2.410188185255106

Epoch: 5| Step: 10
Training loss: 1.9383372681966757
Validation loss: 2.413346459077957

Epoch: 5| Step: 11
Training loss: 1.2417445322664789
Validation loss: 2.44084399857106

Epoch: 76| Step: 0
Training loss: 2.0068835770273132
Validation loss: 2.424264192867258

Epoch: 5| Step: 1
Training loss: 2.4821939551336634
Validation loss: 2.437816925312132

Epoch: 5| Step: 2
Training loss: 1.5496285331816881
Validation loss: 2.4351680882198496

Epoch: 5| Step: 3
Training loss: 2.0126162998880215
Validation loss: 2.438917436670407

Epoch: 5| Step: 4
Training loss: 2.1297713175769224
Validation loss: 2.440889219341262

Epoch: 5| Step: 5
Training loss: 2.5737827609081347
Validation loss: 2.43108918704996

Epoch: 5| Step: 6
Training loss: 2.0677998968521183
Validation loss: 2.436844052795533

Epoch: 5| Step: 7
Training loss: 2.509485370113749
Validation loss: 2.431848433882222

Epoch: 5| Step: 8
Training loss: 2.3040321582165886
Validation loss: 2.4670862434390233

Epoch: 5| Step: 9
Training loss: 2.359477059891616
Validation loss: 2.451882898316508

Epoch: 5| Step: 10
Training loss: 1.2514805608589228
Validation loss: 2.428079807117855

Epoch: 5| Step: 11
Training loss: 2.2437642896616916
Validation loss: 2.4370292816313954

Epoch: 77| Step: 0
Training loss: 1.534895236512806
Validation loss: 2.426539578465668

Epoch: 5| Step: 1
Training loss: 2.517364563921318
Validation loss: 2.4373720738676585

Epoch: 5| Step: 2
Training loss: 2.3479072830116485
Validation loss: 2.437004293671093

Epoch: 5| Step: 3
Training loss: 2.3619764524960862
Validation loss: 2.4320467200003195

Epoch: 5| Step: 4
Training loss: 2.0988755758045166
Validation loss: 2.42746677903368

Epoch: 5| Step: 5
Training loss: 1.463555830302095
Validation loss: 2.402471957623609

Epoch: 5| Step: 6
Training loss: 2.2585606374988645
Validation loss: 2.4214718206196806

Epoch: 5| Step: 7
Training loss: 2.2930430931503833
Validation loss: 2.4354645919870364

Epoch: 5| Step: 8
Training loss: 1.9492078639397294
Validation loss: 2.439339673041183

Epoch: 5| Step: 9
Training loss: 2.5924860620813726
Validation loss: 2.4441836456110546

Epoch: 5| Step: 10
Training loss: 1.6153898706280807
Validation loss: 2.4204844677001303

Epoch: 5| Step: 11
Training loss: 3.030123314441215
Validation loss: 2.4318236173640857

Epoch: 78| Step: 0
Training loss: 2.3683750711405693
Validation loss: 2.4225443663600736

Epoch: 5| Step: 1
Training loss: 2.06438718057077
Validation loss: 2.41485381505344

Epoch: 5| Step: 2
Training loss: 2.215563460384506
Validation loss: 2.4239350735136216

Epoch: 5| Step: 3
Training loss: 1.9417101739203035
Validation loss: 2.423584709885966

Epoch: 5| Step: 4
Training loss: 2.0768350598848233
Validation loss: 2.4224366757029547

Epoch: 5| Step: 5
Training loss: 1.8845465181904195
Validation loss: 2.413298493176859

Epoch: 5| Step: 6
Training loss: 2.492225192272276
Validation loss: 2.4189938276115424

Epoch: 5| Step: 7
Training loss: 2.310733636062065
Validation loss: 2.4211327533138562

Epoch: 5| Step: 8
Training loss: 1.9829001164599012
Validation loss: 2.403495818334002

Epoch: 5| Step: 9
Training loss: 2.15089414766521
Validation loss: 2.4190827752732877

Epoch: 5| Step: 10
Training loss: 1.5913949657970854
Validation loss: 2.424263897826898

Epoch: 5| Step: 11
Training loss: 3.4914623762166093
Validation loss: 2.4129483307100426

Epoch: 79| Step: 0
Training loss: 1.771342380136386
Validation loss: 2.416527792760582

Epoch: 5| Step: 1
Training loss: 1.4819381789210369
Validation loss: 2.47832333756

Epoch: 5| Step: 2
Training loss: 2.4427185925971147
Validation loss: 2.4894697623637425

Epoch: 5| Step: 3
Training loss: 1.9246467513923857
Validation loss: 2.509319589366512

Epoch: 5| Step: 4
Training loss: 2.021092532599532
Validation loss: 2.542992657667714

Epoch: 5| Step: 5
Training loss: 2.263969711181979
Validation loss: 2.488933216320641

Epoch: 5| Step: 6
Training loss: 2.5576195179745493
Validation loss: 2.482064890510962

Epoch: 5| Step: 7
Training loss: 2.266185822627576
Validation loss: 2.459878130371267

Epoch: 5| Step: 8
Training loss: 2.2539329064444065
Validation loss: 2.4318469755358145

Epoch: 5| Step: 9
Training loss: 2.5052306768381913
Validation loss: 2.430081320243762

Epoch: 5| Step: 10
Training loss: 1.866111413366948
Validation loss: 2.3976582266645177

Epoch: 5| Step: 11
Training loss: 2.681374155295612
Validation loss: 2.405862122604487

Epoch: 80| Step: 0
Training loss: 1.884091018357155
Validation loss: 2.410958387952315

Epoch: 5| Step: 1
Training loss: 2.0834201667491463
Validation loss: 2.409729320565749

Epoch: 5| Step: 2
Training loss: 1.934498892962508
Validation loss: 2.4072849392986067

Epoch: 5| Step: 3
Training loss: 2.3878255172831975
Validation loss: 2.3991628848409663

Epoch: 5| Step: 4
Training loss: 2.1659172180221264
Validation loss: 2.414774879107817

Epoch: 5| Step: 5
Training loss: 2.1454353580733647
Validation loss: 2.4027162216609628

Epoch: 5| Step: 6
Training loss: 2.6108274700327456
Validation loss: 2.427240638110309

Epoch: 5| Step: 7
Training loss: 2.015120213900637
Validation loss: 2.4137194162331297

Epoch: 5| Step: 8
Training loss: 2.2419469617955716
Validation loss: 2.4163008747379155

Epoch: 5| Step: 9
Training loss: 2.151642229851032
Validation loss: 2.428466539161448

Epoch: 5| Step: 10
Training loss: 1.7833956460969558
Validation loss: 2.424576177954147

Epoch: 5| Step: 11
Training loss: 2.5404172129664606
Validation loss: 2.4500638405273873

Epoch: 81| Step: 0
Training loss: 2.0603679850516228
Validation loss: 2.43726352212924

Epoch: 5| Step: 1
Training loss: 1.8044231270693372
Validation loss: 2.4442569375972507

Epoch: 5| Step: 2
Training loss: 1.9849179944219555
Validation loss: 2.443369413335413

Epoch: 5| Step: 3
Training loss: 1.8852673114891834
Validation loss: 2.4290306904415107

Epoch: 5| Step: 4
Training loss: 2.4984391108084822
Validation loss: 2.4215768589557785

Epoch: 5| Step: 5
Training loss: 2.3739120601637436
Validation loss: 2.4259326291726415

Epoch: 5| Step: 6
Training loss: 1.8898933192829335
Validation loss: 2.4212643048230342

Epoch: 5| Step: 7
Training loss: 2.4070039038759212
Validation loss: 2.41794479144608

Epoch: 5| Step: 8
Training loss: 2.2222254223270688
Validation loss: 2.407928141713847

Epoch: 5| Step: 9
Training loss: 2.136878752078935
Validation loss: 2.419737065000684

Epoch: 5| Step: 10
Training loss: 1.7959533981700186
Validation loss: 2.4300908758624753

Epoch: 5| Step: 11
Training loss: 2.2498465591668517
Validation loss: 2.410593202407767

Epoch: 82| Step: 0
Training loss: 2.5978772521120037
Validation loss: 2.4055188975693027

Epoch: 5| Step: 1
Training loss: 2.3386991882513324
Validation loss: 2.412269568432817

Epoch: 5| Step: 2
Training loss: 2.2500916568313047
Validation loss: 2.3924098343602194

Epoch: 5| Step: 3
Training loss: 1.6445606075031405
Validation loss: 2.4076790838887416

Epoch: 5| Step: 4
Training loss: 1.845356386908
Validation loss: 2.401731769798725

Epoch: 5| Step: 5
Training loss: 2.345071953846935
Validation loss: 2.4008933136648465

Epoch: 5| Step: 6
Training loss: 1.8513733328588402
Validation loss: 2.3997059179971054

Epoch: 5| Step: 7
Training loss: 1.8816179466979517
Validation loss: 2.4217622915314174

Epoch: 5| Step: 8
Training loss: 2.0404971399602685
Validation loss: 2.4162452648239454

Epoch: 5| Step: 9
Training loss: 1.8689824498772638
Validation loss: 2.412021770250679

Epoch: 5| Step: 10
Training loss: 2.4800575215836766
Validation loss: 2.4371945972341735

Epoch: 5| Step: 11
Training loss: 0.923113201533434
Validation loss: 2.432686711699538

Epoch: 83| Step: 0
Training loss: 2.275422687877639
Validation loss: 2.449477916676384

Epoch: 5| Step: 1
Training loss: 1.9342322326136012
Validation loss: 2.4404088457410023

Epoch: 5| Step: 2
Training loss: 2.172100137801311
Validation loss: 2.4669179295194485

Epoch: 5| Step: 3
Training loss: 1.903910843284429
Validation loss: 2.472154973278664

Epoch: 5| Step: 4
Training loss: 2.7470789047090567
Validation loss: 2.4400404565908396

Epoch: 5| Step: 5
Training loss: 2.0430777467786987
Validation loss: 2.4502528561296293

Epoch: 5| Step: 6
Training loss: 1.9397133521054553
Validation loss: 2.422006029255663

Epoch: 5| Step: 7
Training loss: 2.177152520012769
Validation loss: 2.40968728307361

Epoch: 5| Step: 8
Training loss: 2.0100617037739203
Validation loss: 2.4165038774734056

Epoch: 5| Step: 9
Training loss: 1.8246011925336023
Validation loss: 2.4176568799266733

Epoch: 5| Step: 10
Training loss: 1.8999110025342396
Validation loss: 2.3974314846449087

Epoch: 5| Step: 11
Training loss: 1.8349134470512651
Validation loss: 2.4032186946288276

Epoch: 84| Step: 0
Training loss: 1.7821037521899044
Validation loss: 2.4040043495649828

Epoch: 5| Step: 1
Training loss: 2.421080822093086
Validation loss: 2.4333047547251625

Epoch: 5| Step: 2
Training loss: 1.9461253356208048
Validation loss: 2.4429646962759137

Epoch: 5| Step: 3
Training loss: 1.9718122735301318
Validation loss: 2.4417737373977153

Epoch: 5| Step: 4
Training loss: 1.5604562745035349
Validation loss: 2.463268233939466

Epoch: 5| Step: 5
Training loss: 2.39788056409113
Validation loss: 2.469655697712056

Epoch: 5| Step: 6
Training loss: 2.4083764724651706
Validation loss: 2.430975990414055

Epoch: 5| Step: 7
Training loss: 2.338426163730164
Validation loss: 2.414679286971289

Epoch: 5| Step: 8
Training loss: 1.6082760660652589
Validation loss: 2.4415507810408976

Epoch: 5| Step: 9
Training loss: 2.4255275624379617
Validation loss: 2.4391844321252223

Epoch: 5| Step: 10
Training loss: 1.8177161303100668
Validation loss: 2.4349895778840285

Epoch: 5| Step: 11
Training loss: 2.1359305034933076
Validation loss: 2.422944534160084

Epoch: 85| Step: 0
Training loss: 1.5704630309875518
Validation loss: 2.42639156573834

Epoch: 5| Step: 1
Training loss: 2.6387113600684238
Validation loss: 2.417078938067282

Epoch: 5| Step: 2
Training loss: 1.8863001767835346
Validation loss: 2.4212635868225

Epoch: 5| Step: 3
Training loss: 2.3162888083832622
Validation loss: 2.3994105785004565

Epoch: 5| Step: 4
Training loss: 1.458044604829232
Validation loss: 2.396060521646122

Epoch: 5| Step: 5
Training loss: 1.9288977732883494
Validation loss: 2.404921933074902

Epoch: 5| Step: 6
Training loss: 2.1210563192700427
Validation loss: 2.421663615528275

Epoch: 5| Step: 7
Training loss: 1.917802667516448
Validation loss: 2.393290535877113

Epoch: 5| Step: 8
Training loss: 2.3534817895000377
Validation loss: 2.414132089445159

Epoch: 5| Step: 9
Training loss: 1.98464765703022
Validation loss: 2.376991119122903

Epoch: 5| Step: 10
Training loss: 2.179623838746075
Validation loss: 2.412139484665472

Epoch: 5| Step: 11
Training loss: 3.1638581386549562
Validation loss: 2.4068506944278223

Epoch: 86| Step: 0
Training loss: 1.98655280808897
Validation loss: 2.4563400112933937

Epoch: 5| Step: 1
Training loss: 1.9226330758457104
Validation loss: 2.4477515584306753

Epoch: 5| Step: 2
Training loss: 2.228170356449349
Validation loss: 2.4729825206837637

Epoch: 5| Step: 3
Training loss: 2.3232252546080594
Validation loss: 2.463788176791886

Epoch: 5| Step: 4
Training loss: 2.041457833748985
Validation loss: 2.452000917255869

Epoch: 5| Step: 5
Training loss: 1.770333956447849
Validation loss: 2.4876637194061133

Epoch: 5| Step: 6
Training loss: 2.2164599998714785
Validation loss: 2.46871109219566

Epoch: 5| Step: 7
Training loss: 1.8427405746109198
Validation loss: 2.4713842164367597

Epoch: 5| Step: 8
Training loss: 1.887004001449442
Validation loss: 2.46298390231265

Epoch: 5| Step: 9
Training loss: 2.5818120312220616
Validation loss: 2.430118735131016

Epoch: 5| Step: 10
Training loss: 1.7887892202026918
Validation loss: 2.4198708373633204

Epoch: 5| Step: 11
Training loss: 2.233687288314445
Validation loss: 2.4152159296374403

Epoch: 87| Step: 0
Training loss: 1.7153573972247367
Validation loss: 2.4141152488270454

Epoch: 5| Step: 1
Training loss: 2.3819497469542426
Validation loss: 2.415731723298198

Epoch: 5| Step: 2
Training loss: 1.9117360827085441
Validation loss: 2.4086853744892203

Epoch: 5| Step: 3
Training loss: 2.0715727802872625
Validation loss: 2.416900028822248

Epoch: 5| Step: 4
Training loss: 1.7208601049722227
Validation loss: 2.4126849889244877

Epoch: 5| Step: 5
Training loss: 1.7252015839148225
Validation loss: 2.400070309768068

Epoch: 5| Step: 6
Training loss: 2.484778125613354
Validation loss: 2.419120598444294

Epoch: 5| Step: 7
Training loss: 2.101321295187366
Validation loss: 2.4250920617433795

Epoch: 5| Step: 8
Training loss: 2.401773822449079
Validation loss: 2.4307419225601765

Epoch: 5| Step: 9
Training loss: 1.6854337121630454
Validation loss: 2.4332549245549293

Epoch: 5| Step: 10
Training loss: 2.3192071304693282
Validation loss: 2.4457687626643807

Epoch: 5| Step: 11
Training loss: 0.26310413130598026
Validation loss: 2.426536829383395

Epoch: 88| Step: 0
Training loss: 1.7939142132068921
Validation loss: 2.4277549798018945

Epoch: 5| Step: 1
Training loss: 2.4762266876032246
Validation loss: 2.44443680721111

Epoch: 5| Step: 2
Training loss: 2.3496066352657032
Validation loss: 2.4545086281314528

Epoch: 5| Step: 3
Training loss: 2.1837949711274707
Validation loss: 2.4362521686286596

Epoch: 5| Step: 4
Training loss: 2.1617289055908677
Validation loss: 2.421758648938545

Epoch: 5| Step: 5
Training loss: 1.3500962435006172
Validation loss: 2.455853993360536

Epoch: 5| Step: 6
Training loss: 2.117094481279372
Validation loss: 2.4799839577297007

Epoch: 5| Step: 7
Training loss: 2.1564353089246957
Validation loss: 2.5070819048005464

Epoch: 5| Step: 8
Training loss: 1.5260155407575458
Validation loss: 2.4805136488808297

Epoch: 5| Step: 9
Training loss: 1.9897207508930552
Validation loss: 2.4634463726643503

Epoch: 5| Step: 10
Training loss: 2.1194972428188943
Validation loss: 2.4538490538928373

Epoch: 5| Step: 11
Training loss: 1.8415759572033112
Validation loss: 2.428323086645186

Epoch: 89| Step: 0
Training loss: 1.704981710498073
Validation loss: 2.3965339147726894

Epoch: 5| Step: 1
Training loss: 1.7877627653109762
Validation loss: 2.4219425397089744

Epoch: 5| Step: 2
Training loss: 2.19861622987356
Validation loss: 2.421996082847697

Epoch: 5| Step: 3
Training loss: 2.3563575902199267
Validation loss: 2.4143965900432454

Epoch: 5| Step: 4
Training loss: 1.6325423459786808
Validation loss: 2.4089110840267685

Epoch: 5| Step: 5
Training loss: 2.407724399427778
Validation loss: 2.4317807117641976

Epoch: 5| Step: 6
Training loss: 1.8270912834293196
Validation loss: 2.4117698070055087

Epoch: 5| Step: 7
Training loss: 2.0090403086756483
Validation loss: 2.428083720484336

Epoch: 5| Step: 8
Training loss: 1.7131143595640959
Validation loss: 2.4314200550219645

Epoch: 5| Step: 9
Training loss: 2.1825010674158305
Validation loss: 2.4276599458316577

Epoch: 5| Step: 10
Training loss: 2.4156311271954958
Validation loss: 2.4194929529447307

Epoch: 5| Step: 11
Training loss: 1.6819627832066937
Validation loss: 2.43790308154497

Epoch: 90| Step: 0
Training loss: 1.6960583289975433
Validation loss: 2.4988670484039686

Epoch: 5| Step: 1
Training loss: 1.927875672083106
Validation loss: 2.4749066506227044

Epoch: 5| Step: 2
Training loss: 2.225111853541908
Validation loss: 2.498796133417316

Epoch: 5| Step: 3
Training loss: 1.7985501649301483
Validation loss: 2.4700646783041424

Epoch: 5| Step: 4
Training loss: 1.4833732838912068
Validation loss: 2.44791837786892

Epoch: 5| Step: 5
Training loss: 3.026724041914512
Validation loss: 2.466048601617773

Epoch: 5| Step: 6
Training loss: 2.570056659059081
Validation loss: 2.4971307939393874

Epoch: 5| Step: 7
Training loss: 1.4346555680610262
Validation loss: 2.4488948626117497

Epoch: 5| Step: 8
Training loss: 1.7171768618558743
Validation loss: 2.4381049518108093

Epoch: 5| Step: 9
Training loss: 2.136918918083552
Validation loss: 2.4283510930121657

Epoch: 5| Step: 10
Training loss: 1.8806685908480247
Validation loss: 2.3911499494249773

Epoch: 5| Step: 11
Training loss: 1.6549144614434983
Validation loss: 2.412535858546645

Epoch: 91| Step: 0
Training loss: 1.7515044557480433
Validation loss: 2.430020488396234

Epoch: 5| Step: 1
Training loss: 2.226599656179832
Validation loss: 2.4371886054451153

Epoch: 5| Step: 2
Training loss: 2.087039385019555
Validation loss: 2.404890190193126

Epoch: 5| Step: 3
Training loss: 1.9078275687757493
Validation loss: 2.413104977462498

Epoch: 5| Step: 4
Training loss: 2.0482778619384217
Validation loss: 2.420565474678133

Epoch: 5| Step: 5
Training loss: 1.8050066512981244
Validation loss: 2.4286571926729636

Epoch: 5| Step: 6
Training loss: 1.6531597314081414
Validation loss: 2.4551668234547503

Epoch: 5| Step: 7
Training loss: 1.7125474853614775
Validation loss: 2.458678493407009

Epoch: 5| Step: 8
Training loss: 2.8433810822687673
Validation loss: 2.462277587457467

Epoch: 5| Step: 9
Training loss: 1.5121049412332472
Validation loss: 2.458344493183301

Epoch: 5| Step: 10
Training loss: 2.193481767998204
Validation loss: 2.459523572881296

Epoch: 5| Step: 11
Training loss: 2.3827949898498537
Validation loss: 2.4693069714987006

Epoch: 92| Step: 0
Training loss: 2.0007545716675454
Validation loss: 2.429524353862814

Epoch: 5| Step: 1
Training loss: 2.2035092498952165
Validation loss: 2.4212010543135167

Epoch: 5| Step: 2
Training loss: 2.082776592886636
Validation loss: 2.4004718838153356

Epoch: 5| Step: 3
Training loss: 2.3521860506274495
Validation loss: 2.4072952312298384

Epoch: 5| Step: 4
Training loss: 2.017604831396939
Validation loss: 2.4151930049746664

Epoch: 5| Step: 5
Training loss: 2.1007241771544987
Validation loss: 2.404252259258584

Epoch: 5| Step: 6
Training loss: 2.08076412726972
Validation loss: 2.39631875275979

Epoch: 5| Step: 7
Training loss: 1.6256790209648775
Validation loss: 2.4024914745202035

Epoch: 5| Step: 8
Training loss: 1.4397718472672076
Validation loss: 2.4152828987615207

Epoch: 5| Step: 9
Training loss: 2.159489947956959
Validation loss: 2.4236687939060517

Epoch: 5| Step: 10
Training loss: 1.7319499064242698
Validation loss: 2.409747051370052

Epoch: 5| Step: 11
Training loss: 2.79154981302171
Validation loss: 2.438822049481641

Epoch: 93| Step: 0
Training loss: 2.1699524198317106
Validation loss: 2.491231290444267

Epoch: 5| Step: 1
Training loss: 1.8355354031084372
Validation loss: 2.487099670899292

Epoch: 5| Step: 2
Training loss: 2.1842607765730913
Validation loss: 2.5103984366476544

Epoch: 5| Step: 3
Training loss: 1.8318966163341208
Validation loss: 2.5369280054557666

Epoch: 5| Step: 4
Training loss: 2.1999368528493397
Validation loss: 2.503827304557661

Epoch: 5| Step: 5
Training loss: 1.940750717538379
Validation loss: 2.48735858093514

Epoch: 5| Step: 6
Training loss: 2.2666690919900523
Validation loss: 2.458898601899449

Epoch: 5| Step: 7
Training loss: 2.0035241787096236
Validation loss: 2.4355892288861125

Epoch: 5| Step: 8
Training loss: 1.557068501518289
Validation loss: 2.405912206315081

Epoch: 5| Step: 9
Training loss: 1.7757159817302475
Validation loss: 2.4102901501919507

Epoch: 5| Step: 10
Training loss: 2.260673004475991
Validation loss: 2.441347570095587

Epoch: 5| Step: 11
Training loss: 2.5155088030593418
Validation loss: 2.4367514606158487

Epoch: 94| Step: 0
Training loss: 2.2931635967176516
Validation loss: 2.4022973074210108

Epoch: 5| Step: 1
Training loss: 1.7129984248655685
Validation loss: 2.418381544301247

Epoch: 5| Step: 2
Training loss: 2.3812552945135734
Validation loss: 2.4452114592163285

Epoch: 5| Step: 3
Training loss: 1.7464947336086374
Validation loss: 2.47031382432613

Epoch: 5| Step: 4
Training loss: 2.046234962627174
Validation loss: 2.5301204955641685

Epoch: 5| Step: 5
Training loss: 2.402879509459682
Validation loss: 2.557785962743319

Epoch: 5| Step: 6
Training loss: 2.0537810556265934
Validation loss: 2.51683733537214

Epoch: 5| Step: 7
Training loss: 1.9353466373034074
Validation loss: 2.494872238567682

Epoch: 5| Step: 8
Training loss: 2.050212556007496
Validation loss: 2.441780631288445

Epoch: 5| Step: 9
Training loss: 1.683625046158148
Validation loss: 2.4194054595204526

Epoch: 5| Step: 10
Training loss: 1.5691391086167445
Validation loss: 2.406658352637614

Epoch: 5| Step: 11
Training loss: 2.0912041060205264
Validation loss: 2.407214033546883

Epoch: 95| Step: 0
Training loss: 2.208095705694799
Validation loss: 2.3926216837752046

Epoch: 5| Step: 1
Training loss: 1.7769435557780509
Validation loss: 2.3872020958323863

Epoch: 5| Step: 2
Training loss: 1.794901485555609
Validation loss: 2.403985468935568

Epoch: 5| Step: 3
Training loss: 2.2016541461266104
Validation loss: 2.4045995030652403

Epoch: 5| Step: 4
Training loss: 1.9783192543722181
Validation loss: 2.3954254501165373

Epoch: 5| Step: 5
Training loss: 2.2163307002264157
Validation loss: 2.423679852414069

Epoch: 5| Step: 6
Training loss: 1.8874360610540588
Validation loss: 2.4103810696513492

Epoch: 5| Step: 7
Training loss: 2.0882573746823065
Validation loss: 2.433465912442676

Epoch: 5| Step: 8
Training loss: 2.0298217447124802
Validation loss: 2.4113516705008857

Epoch: 5| Step: 9
Training loss: 1.5943185128882904
Validation loss: 2.4290761147749023

Epoch: 5| Step: 10
Training loss: 1.8438693509023414
Validation loss: 2.442456644562363

Epoch: 5| Step: 11
Training loss: 2.5856499180689205
Validation loss: 2.438008169852878

Epoch: 96| Step: 0
Training loss: 2.508486458127273
Validation loss: 2.431713490243412

Epoch: 5| Step: 1
Training loss: 2.1022904847540924
Validation loss: 2.398362664909769

Epoch: 5| Step: 2
Training loss: 1.6315268241461203
Validation loss: 2.4391005632622442

Epoch: 5| Step: 3
Training loss: 1.4879827725736041
Validation loss: 2.4100661876633076

Epoch: 5| Step: 4
Training loss: 1.9402184642602482
Validation loss: 2.427419456379318

Epoch: 5| Step: 5
Training loss: 1.9801121979530716
Validation loss: 2.4097926145276736

Epoch: 5| Step: 6
Training loss: 1.9006448479631826
Validation loss: 2.4218513077428168

Epoch: 5| Step: 7
Training loss: 1.9855580445342618
Validation loss: 2.4201557373805542

Epoch: 5| Step: 8
Training loss: 1.8689548954223179
Validation loss: 2.423769134287257

Epoch: 5| Step: 9
Training loss: 2.3413455073178437
Validation loss: 2.4322356357832553

Epoch: 5| Step: 10
Training loss: 1.7397832317815507
Validation loss: 2.4351973049507945

Epoch: 5| Step: 11
Training loss: 0.9991761032201866
Validation loss: 2.4312819495957947

Epoch: 97| Step: 0
Training loss: 2.112436855659058
Validation loss: 2.446770608070921

Epoch: 5| Step: 1
Training loss: 1.9055778694267456
Validation loss: 2.4795521842445742

Epoch: 5| Step: 2
Training loss: 2.0409663290249007
Validation loss: 2.4925788823198185

Epoch: 5| Step: 3
Training loss: 1.7309719068912988
Validation loss: 2.462248990615688

Epoch: 5| Step: 4
Training loss: 1.7074877654456937
Validation loss: 2.4311443777439714

Epoch: 5| Step: 5
Training loss: 2.138672989797084
Validation loss: 2.439907855208499

Epoch: 5| Step: 6
Training loss: 1.9621880787597814
Validation loss: 2.4099877379462935

Epoch: 5| Step: 7
Training loss: 2.054087736252436
Validation loss: 2.4502501762231015

Epoch: 5| Step: 8
Training loss: 2.155458940993164
Validation loss: 2.4325194418947977

Epoch: 5| Step: 9
Training loss: 2.181618440219846
Validation loss: 2.3868575193662864

Epoch: 5| Step: 10
Training loss: 1.552767310602936
Validation loss: 2.4307254769707507

Epoch: 5| Step: 11
Training loss: 1.5806215386826041
Validation loss: 2.4227017232413433

Epoch: 98| Step: 0
Training loss: 1.5642185678273324
Validation loss: 2.4372191185792946

Epoch: 5| Step: 1
Training loss: 1.7544885021495025
Validation loss: 2.4782643332322

Epoch: 5| Step: 2
Training loss: 1.776407653448346
Validation loss: 2.4958237694528926

Epoch: 5| Step: 3
Training loss: 1.8891006503737253
Validation loss: 2.5408008982196977

Epoch: 5| Step: 4
Training loss: 1.9254255295118647
Validation loss: 2.5362815299219914

Epoch: 5| Step: 5
Training loss: 2.2196616865244376
Validation loss: 2.541876680004502

Epoch: 5| Step: 6
Training loss: 1.7647402411743747
Validation loss: 2.520325642421612

Epoch: 5| Step: 7
Training loss: 2.8741720914877065
Validation loss: 2.4654332507423864

Epoch: 5| Step: 8
Training loss: 1.5939864188971435
Validation loss: 2.434281037312356

Epoch: 5| Step: 9
Training loss: 2.225100710014774
Validation loss: 2.405956403152073

Epoch: 5| Step: 10
Training loss: 1.5026070668034412
Validation loss: 2.430027327737086

Epoch: 5| Step: 11
Training loss: 2.4023245958014354
Validation loss: 2.4147523842768974

Epoch: 99| Step: 0
Training loss: 1.3616497256479199
Validation loss: 2.4118476262334587

Epoch: 5| Step: 1
Training loss: 1.7336563821062267
Validation loss: 2.436992288760551

Epoch: 5| Step: 2
Training loss: 1.766023573997815
Validation loss: 2.4260601245827123

Epoch: 5| Step: 3
Training loss: 2.1770513310126085
Validation loss: 2.4590769804105097

Epoch: 5| Step: 4
Training loss: 2.0925229020956206
Validation loss: 2.4834747482737907

Epoch: 5| Step: 5
Training loss: 2.1106122944556454
Validation loss: 2.468787784528704

Epoch: 5| Step: 6
Training loss: 2.219188593107802
Validation loss: 2.4790244716181715

Epoch: 5| Step: 7
Training loss: 2.2002944619179337
Validation loss: 2.5177265949136753

Epoch: 5| Step: 8
Training loss: 1.7363945827059546
Validation loss: 2.502866075659711

Epoch: 5| Step: 9
Training loss: 2.180904035266398
Validation loss: 2.4629851849216626

Epoch: 5| Step: 10
Training loss: 1.6300719410285138
Validation loss: 2.4460646454695874

Epoch: 5| Step: 11
Training loss: 0.8366782925723846
Validation loss: 2.4463409641671143

Epoch: 100| Step: 0
Training loss: 1.7972463472854272
Validation loss: 2.4199960167184735

Epoch: 5| Step: 1
Training loss: 1.2674079392838091
Validation loss: 2.442108732756496

Epoch: 5| Step: 2
Training loss: 1.6982325004665495
Validation loss: 2.4166138221180846

Epoch: 5| Step: 3
Training loss: 2.193363723003259
Validation loss: 2.425385312310948

Epoch: 5| Step: 4
Training loss: 2.2187843857370697
Validation loss: 2.4271492614851113

Epoch: 5| Step: 5
Training loss: 2.103679285793247
Validation loss: 2.4400006085340333

Epoch: 5| Step: 6
Training loss: 2.3745158856539885
Validation loss: 2.4259584784969426

Epoch: 5| Step: 7
Training loss: 1.4275834907928167
Validation loss: 2.4371765280731474

Epoch: 5| Step: 8
Training loss: 2.236295928056982
Validation loss: 2.438209890853101

Epoch: 5| Step: 9
Training loss: 1.4945010479808207
Validation loss: 2.425064601480135

Epoch: 5| Step: 10
Training loss: 1.6056117530118892
Validation loss: 2.433093526260859

Epoch: 5| Step: 11
Training loss: 2.3094720347747746
Validation loss: 2.445750634995654

Epoch: 101| Step: 0
Training loss: 1.8607145340827544
Validation loss: 2.470785123044889

Epoch: 5| Step: 1
Training loss: 2.079269782231499
Validation loss: 2.532048025039366

Epoch: 5| Step: 2
Training loss: 1.8743111934657948
Validation loss: 2.523152117737406

Epoch: 5| Step: 3
Training loss: 1.9160589277407925
Validation loss: 2.5791547683837837

Epoch: 5| Step: 4
Training loss: 1.356361205292684
Validation loss: 2.592595950539498

Epoch: 5| Step: 5
Training loss: 1.9551075753081266
Validation loss: 2.5582349646996394

Epoch: 5| Step: 6
Training loss: 1.7868772929264607
Validation loss: 2.5028789394560844

Epoch: 5| Step: 7
Training loss: 2.4146907445689063
Validation loss: 2.463811852852715

Epoch: 5| Step: 8
Training loss: 1.7455952933488394
Validation loss: 2.4401913257178687

Epoch: 5| Step: 9
Training loss: 2.2093833610236175
Validation loss: 2.4425409472497486

Epoch: 5| Step: 10
Training loss: 1.5423736583587329
Validation loss: 2.4064146167213454

Epoch: 5| Step: 11
Training loss: 1.6955359527006895
Validation loss: 2.429037933362794

Epoch: 102| Step: 0
Training loss: 1.6128326605157821
Validation loss: 2.428748919541895

Epoch: 5| Step: 1
Training loss: 1.7866262314381922
Validation loss: 2.443962910996115

Epoch: 5| Step: 2
Training loss: 1.2743954945815692
Validation loss: 2.4521525210912833

Epoch: 5| Step: 3
Training loss: 2.194458601968972
Validation loss: 2.434076574607046

Epoch: 5| Step: 4
Training loss: 2.2438905209713287
Validation loss: 2.431838172333744

Epoch: 5| Step: 5
Training loss: 1.7600612921229246
Validation loss: 2.4727606005593277

Epoch: 5| Step: 6
Training loss: 1.8076341361349202
Validation loss: 2.4731366161484636

Epoch: 5| Step: 7
Training loss: 2.335049769914662
Validation loss: 2.490154776703496

Epoch: 5| Step: 8
Training loss: 2.48493490567522
Validation loss: 2.53475503827688

Epoch: 5| Step: 9
Training loss: 1.6982077210643127
Validation loss: 2.4993786119055144

Epoch: 5| Step: 10
Training loss: 1.42281930608062
Validation loss: 2.471217586145249

Epoch: 5| Step: 11
Training loss: 2.011663521314099
Validation loss: 2.4816991282642094

Epoch: 103| Step: 0
Training loss: 1.6114129061502722
Validation loss: 2.429175422079056

Epoch: 5| Step: 1
Training loss: 2.00026677259811
Validation loss: 2.4514153226652553

Epoch: 5| Step: 2
Training loss: 1.5694586866664673
Validation loss: 2.4430042560706617

Epoch: 5| Step: 3
Training loss: 1.6323464198404225
Validation loss: 2.4666617289270345

Epoch: 5| Step: 4
Training loss: 2.135934968401309
Validation loss: 2.4498467013024214

Epoch: 5| Step: 5
Training loss: 1.7813249538780378
Validation loss: 2.461774326521546

Epoch: 5| Step: 6
Training loss: 1.8542112566554712
Validation loss: 2.4605109879591325

Epoch: 5| Step: 7
Training loss: 2.0834413373290137
Validation loss: 2.4539272430114623

Epoch: 5| Step: 8
Training loss: 1.9195456926969252
Validation loss: 2.4244008418678753

Epoch: 5| Step: 9
Training loss: 1.8559956976865364
Validation loss: 2.4616809065240552

Epoch: 5| Step: 10
Training loss: 2.0779398211814653
Validation loss: 2.420284302598333

Epoch: 5| Step: 11
Training loss: 1.066496345710485
Validation loss: 2.4238089725414977

Epoch: 104| Step: 0
Training loss: 2.2309631761686273
Validation loss: 2.428640906808661

Epoch: 5| Step: 1
Training loss: 2.091242755118052
Validation loss: 2.410815168974463

Epoch: 5| Step: 2
Training loss: 1.8252341081099595
Validation loss: 2.4430816943901816

Epoch: 5| Step: 3
Training loss: 2.1661691705819823
Validation loss: 2.4429145934670693

Epoch: 5| Step: 4
Training loss: 1.6511888007259194
Validation loss: 2.461762914540879

Epoch: 5| Step: 5
Training loss: 1.9290873099937331
Validation loss: 2.4418286743925033

Epoch: 5| Step: 6
Training loss: 1.5765867384530312
Validation loss: 2.4613775192944494

Epoch: 5| Step: 7
Training loss: 1.4659297731968841
Validation loss: 2.4687029475947244

Epoch: 5| Step: 8
Training loss: 1.7230169563056885
Validation loss: 2.4991335519727547

Epoch: 5| Step: 9
Training loss: 1.9396604367619543
Validation loss: 2.501975447281922

Epoch: 5| Step: 10
Training loss: 1.8250550144212263
Validation loss: 2.4703984611751033

Epoch: 5| Step: 11
Training loss: 0.32102707497774513
Validation loss: 2.4433501741727515

Epoch: 105| Step: 0
Training loss: 1.8429770708401605
Validation loss: 2.4670951141460984

Epoch: 5| Step: 1
Training loss: 1.8609495788745931
Validation loss: 2.450427842411199

Epoch: 5| Step: 2
Training loss: 1.5592883099327852
Validation loss: 2.4556008861985994

Epoch: 5| Step: 3
Training loss: 1.6486935529669693
Validation loss: 2.4428905420458773

Epoch: 5| Step: 4
Training loss: 2.1885613182912875
Validation loss: 2.4373512365313963

Epoch: 5| Step: 5
Training loss: 1.592889516075033
Validation loss: 2.4331031047542386

Epoch: 5| Step: 6
Training loss: 2.2071387340738178
Validation loss: 2.4427785582028827

Epoch: 5| Step: 7
Training loss: 1.6850684980058828
Validation loss: 2.439785360777073

Epoch: 5| Step: 8
Training loss: 2.0173197873541726
Validation loss: 2.434018358770755

Epoch: 5| Step: 9
Training loss: 1.6374348460040928
Validation loss: 2.457975298191982

Epoch: 5| Step: 10
Training loss: 2.1467354985963776
Validation loss: 2.4588193951710764

Epoch: 5| Step: 11
Training loss: 0.6912662989469393
Validation loss: 2.443872025476599

Epoch: 106| Step: 0
Training loss: 1.662378524701958
Validation loss: 2.4843140680610354

Epoch: 5| Step: 1
Training loss: 2.15488180345304
Validation loss: 2.5092431757859073

Epoch: 5| Step: 2
Training loss: 2.0868555684654493
Validation loss: 2.5224056082759363

Epoch: 5| Step: 3
Training loss: 2.2162019309367422
Validation loss: 2.492780963547904

Epoch: 5| Step: 4
Training loss: 2.0198126768370672
Validation loss: 2.470797924690781

Epoch: 5| Step: 5
Training loss: 1.942593002645905
Validation loss: 2.4808890679949576

Epoch: 5| Step: 6
Training loss: 1.1926912475872489
Validation loss: 2.4548583133351234

Epoch: 5| Step: 7
Training loss: 1.8615817270507513
Validation loss: 2.4523631206621195

Epoch: 5| Step: 8
Training loss: 1.8445264183669445
Validation loss: 2.4221934980753668

Epoch: 5| Step: 9
Training loss: 1.6222879813785056
Validation loss: 2.4279125677108753

Epoch: 5| Step: 10
Training loss: 1.5949098443169205
Validation loss: 2.450304264359154

Epoch: 5| Step: 11
Training loss: 0.9327872715386663
Validation loss: 2.445342517705103

Epoch: 107| Step: 0
Training loss: 2.3257115290515986
Validation loss: 2.4312119234988425

Epoch: 5| Step: 1
Training loss: 1.799542975686033
Validation loss: 2.458094138022756

Epoch: 5| Step: 2
Training loss: 1.325680896060791
Validation loss: 2.425509754494454

Epoch: 5| Step: 3
Training loss: 1.5992549741189686
Validation loss: 2.4124780164715167

Epoch: 5| Step: 4
Training loss: 2.0163822378083416
Validation loss: 2.4145538628342846

Epoch: 5| Step: 5
Training loss: 1.6963334064035118
Validation loss: 2.427680049993264

Epoch: 5| Step: 6
Training loss: 1.9539926661585107
Validation loss: 2.405352045102283

Epoch: 5| Step: 7
Training loss: 2.0407415616684528
Validation loss: 2.4279308449304082

Epoch: 5| Step: 8
Training loss: 2.0082475361627874
Validation loss: 2.4740163749444846

Epoch: 5| Step: 9
Training loss: 1.5712655434943539
Validation loss: 2.4714241312706613

Epoch: 5| Step: 10
Training loss: 1.713213725918532
Validation loss: 2.4799588177386735

Epoch: 5| Step: 11
Training loss: 0.6857093335970523
Validation loss: 2.518351086752331

Epoch: 108| Step: 0
Training loss: 2.284751608471816
Validation loss: 2.5381173746770522

Epoch: 5| Step: 1
Training loss: 2.339583393571354
Validation loss: 2.506792286798829

Epoch: 5| Step: 2
Training loss: 1.4486216011451865
Validation loss: 2.443125918197817

Epoch: 5| Step: 3
Training loss: 2.2471694095516273
Validation loss: 2.4318648269428773

Epoch: 5| Step: 4
Training loss: 1.7066631836905304
Validation loss: 2.4165684101804152

Epoch: 5| Step: 5
Training loss: 1.286201307229594
Validation loss: 2.438889087293448

Epoch: 5| Step: 6
Training loss: 1.6948515797227846
Validation loss: 2.4222976971989185

Epoch: 5| Step: 7
Training loss: 2.0389697759014958
Validation loss: 2.4348866236439437

Epoch: 5| Step: 8
Training loss: 1.5663098997701317
Validation loss: 2.408167467268411

Epoch: 5| Step: 9
Training loss: 1.333868108237366
Validation loss: 2.4465781847466093

Epoch: 5| Step: 10
Training loss: 1.8912117418048933
Validation loss: 2.470543137749493

Epoch: 5| Step: 11
Training loss: 0.762469464613053
Validation loss: 2.4739647226083803

Epoch: 109| Step: 0
Training loss: 1.7426833058817655
Validation loss: 2.5239334327727896

Epoch: 5| Step: 1
Training loss: 2.0025325476278986
Validation loss: 2.5284820815289972

Epoch: 5| Step: 2
Training loss: 1.4939571093386372
Validation loss: 2.473618234379849

Epoch: 5| Step: 3
Training loss: 2.021700197944456
Validation loss: 2.464778278607776

Epoch: 5| Step: 4
Training loss: 1.9497570448913355
Validation loss: 2.4493813833361333

Epoch: 5| Step: 5
Training loss: 1.7702565843416336
Validation loss: 2.4543112500664432

Epoch: 5| Step: 6
Training loss: 1.4128381054403023
Validation loss: 2.4670234147264583

Epoch: 5| Step: 7
Training loss: 2.153215346081093
Validation loss: 2.446405664077503

Epoch: 5| Step: 8
Training loss: 1.8616259117526373
Validation loss: 2.4409406904737674

Epoch: 5| Step: 9
Training loss: 1.729855809900604
Validation loss: 2.4651879233042453

Epoch: 5| Step: 10
Training loss: 1.5757309534446013
Validation loss: 2.470331158488113

Epoch: 5| Step: 11
Training loss: 1.0172376300981234
Validation loss: 2.4601099086033886

Epoch: 110| Step: 0
Training loss: 1.0590397644754295
Validation loss: 2.4733913909733496

Epoch: 5| Step: 1
Training loss: 1.789922515854374
Validation loss: 2.5037327278304513

Epoch: 5| Step: 2
Training loss: 1.767199261775452
Validation loss: 2.4631557296711275

Epoch: 5| Step: 3
Training loss: 2.116168125143773
Validation loss: 2.466594257827717

Epoch: 5| Step: 4
Training loss: 1.3339183785462565
Validation loss: 2.477144696368856

Epoch: 5| Step: 5
Training loss: 1.7771639219423432
Validation loss: 2.4826189268564907

Epoch: 5| Step: 6
Training loss: 2.0253349451046514
Validation loss: 2.471545274672623

Epoch: 5| Step: 7
Training loss: 1.3821924834708155
Validation loss: 2.490409703284588

Epoch: 5| Step: 8
Training loss: 2.3369038601950303
Validation loss: 2.4989785968891294

Epoch: 5| Step: 9
Training loss: 0.9834096504488902
Validation loss: 2.492668986272315

Epoch: 5| Step: 10
Training loss: 2.016009390203617
Validation loss: 2.4545679202092576

Epoch: 5| Step: 11
Training loss: 2.88602588892036
Validation loss: 2.4325654585728937

Epoch: 111| Step: 0
Training loss: 2.041369539814753
Validation loss: 2.4718099655489083

Epoch: 5| Step: 1
Training loss: 2.3269029520647475
Validation loss: 2.4451930856848194

Epoch: 5| Step: 2
Training loss: 1.6735152282614647
Validation loss: 2.440902869654844

Epoch: 5| Step: 3
Training loss: 2.0136382491433475
Validation loss: 2.451065900115122

Epoch: 5| Step: 4
Training loss: 1.6445888047102744
Validation loss: 2.4525878058893897

Epoch: 5| Step: 5
Training loss: 1.4135026192197224
Validation loss: 2.4642833771984134

Epoch: 5| Step: 6
Training loss: 1.4226557505908908
Validation loss: 2.4632932458406613

Epoch: 5| Step: 7
Training loss: 1.3662173071297639
Validation loss: 2.4792525866924113

Epoch: 5| Step: 8
Training loss: 1.813087236707428
Validation loss: 2.528689702626117

Epoch: 5| Step: 9
Training loss: 1.9185366285146586
Validation loss: 2.503775380444451

Epoch: 5| Step: 10
Training loss: 2.06485301956365
Validation loss: 2.4903666462394907

Epoch: 5| Step: 11
Training loss: 0.864593819857201
Validation loss: 2.45915845719866

Epoch: 112| Step: 0
Training loss: 1.5531697748434665
Validation loss: 2.4667802187411905

Epoch: 5| Step: 1
Training loss: 1.931656423722045
Validation loss: 2.453210262266618

Epoch: 5| Step: 2
Training loss: 1.741088862908235
Validation loss: 2.471282629673334

Epoch: 5| Step: 3
Training loss: 2.01160935780398
Validation loss: 2.454759616063609

Epoch: 5| Step: 4
Training loss: 1.6862771583898142
Validation loss: 2.45325187792347

Epoch: 5| Step: 5
Training loss: 1.817913521131437
Validation loss: 2.4972659379885416

Epoch: 5| Step: 6
Training loss: 1.9611652135665583
Validation loss: 2.4362569557483402

Epoch: 5| Step: 7
Training loss: 1.583518753571873
Validation loss: 2.475833412456308

Epoch: 5| Step: 8
Training loss: 1.7001625684535382
Validation loss: 2.4845843556800933

Epoch: 5| Step: 9
Training loss: 1.5579472398406422
Validation loss: 2.478390276910355

Epoch: 5| Step: 10
Training loss: 1.9742247738008492
Validation loss: 2.5105802290145935

Epoch: 5| Step: 11
Training loss: 0.8732767506522935
Validation loss: 2.5368730093801024

Epoch: 113| Step: 0
Training loss: 1.5572748938160108
Validation loss: 2.555038906275227

Epoch: 5| Step: 1
Training loss: 1.6330059612233108
Validation loss: 2.51006457061149

Epoch: 5| Step: 2
Training loss: 2.378879189924606
Validation loss: 2.4961956801320135

Epoch: 5| Step: 3
Training loss: 2.0603286410647925
Validation loss: 2.456498034121933

Epoch: 5| Step: 4
Training loss: 1.4720741153489256
Validation loss: 2.4338006655685325

Epoch: 5| Step: 5
Training loss: 2.017741430270775
Validation loss: 2.4215424052919423

Epoch: 5| Step: 6
Training loss: 1.5948802455801185
Validation loss: 2.456524564719217

Epoch: 5| Step: 7
Training loss: 1.679210364417612
Validation loss: 2.4821412362798774

Epoch: 5| Step: 8
Training loss: 1.732840400381752
Validation loss: 2.4652452942822927

Epoch: 5| Step: 9
Training loss: 1.4549229481538524
Validation loss: 2.5126620331354435

Epoch: 5| Step: 10
Training loss: 1.8209578389330916
Validation loss: 2.4978802833951135

Epoch: 5| Step: 11
Training loss: 1.1292944639926377
Validation loss: 2.5081855757865323

Epoch: 114| Step: 0
Training loss: 1.6541727102763404
Validation loss: 2.470662482810694

Epoch: 5| Step: 1
Training loss: 1.788694252195756
Validation loss: 2.455871961506867

Epoch: 5| Step: 2
Training loss: 1.3486576506187133
Validation loss: 2.440252799627163

Epoch: 5| Step: 3
Training loss: 1.6966364740309596
Validation loss: 2.455427429712479

Epoch: 5| Step: 4
Training loss: 1.869606526027417
Validation loss: 2.456744012988837

Epoch: 5| Step: 5
Training loss: 1.619584891152751
Validation loss: 2.476108252646809

Epoch: 5| Step: 6
Training loss: 1.8574650034425069
Validation loss: 2.445649254861647

Epoch: 5| Step: 7
Training loss: 1.9330611911606321
Validation loss: 2.4525131628867336

Epoch: 5| Step: 8
Training loss: 1.6421454514075455
Validation loss: 2.4956684257613557

Epoch: 5| Step: 9
Training loss: 1.6410325770239176
Validation loss: 2.41993514276192

Epoch: 5| Step: 10
Training loss: 1.8391208402832546
Validation loss: 2.481041777495434

Epoch: 5| Step: 11
Training loss: 2.0522799583253133
Validation loss: 2.4737204601303278

Epoch: 115| Step: 0
Training loss: 1.882364306783724
Validation loss: 2.4535798139171714

Epoch: 5| Step: 1
Training loss: 1.6507741268092737
Validation loss: 2.478411947636587

Epoch: 5| Step: 2
Training loss: 1.280852605086919
Validation loss: 2.4282953663238067

Epoch: 5| Step: 3
Training loss: 1.57548422862845
Validation loss: 2.4864670324366496

Epoch: 5| Step: 4
Training loss: 1.002836971584688
Validation loss: 2.4629131520809353

Epoch: 5| Step: 5
Training loss: 1.7110652788775542
Validation loss: 2.444764292146143

Epoch: 5| Step: 6
Training loss: 2.2948463459978106
Validation loss: 2.44139665932361

Epoch: 5| Step: 7
Training loss: 1.781113201041505
Validation loss: 2.445920687799204

Epoch: 5| Step: 8
Training loss: 1.9401019683074443
Validation loss: 2.464310110193864

Epoch: 5| Step: 9
Training loss: 1.693486438810677
Validation loss: 2.407569577098701

Epoch: 5| Step: 10
Training loss: 1.6973028497158555
Validation loss: 2.4765078200632638

Epoch: 5| Step: 11
Training loss: 2.7183898161027713
Validation loss: 2.4795023680181596

Epoch: 116| Step: 0
Training loss: 2.090976415274017
Validation loss: 2.5036195103818466

Epoch: 5| Step: 1
Training loss: 1.6765534015845927
Validation loss: 2.45916353905674

Epoch: 5| Step: 2
Training loss: 1.5256273230097805
Validation loss: 2.4539417195056625

Epoch: 5| Step: 3
Training loss: 1.561955929445836
Validation loss: 2.443737727489696

Epoch: 5| Step: 4
Training loss: 1.5161065192079477
Validation loss: 2.4497046021704225

Epoch: 5| Step: 5
Training loss: 1.6849282058679662
Validation loss: 2.466389352335586

Epoch: 5| Step: 6
Training loss: 1.461858122729422
Validation loss: 2.461820643769875

Epoch: 5| Step: 7
Training loss: 2.2404698827618157
Validation loss: 2.458022697402651

Epoch: 5| Step: 8
Training loss: 1.8719225105280808
Validation loss: 2.4459686962916454

Epoch: 5| Step: 9
Training loss: 1.8823950846947122
Validation loss: 2.446437528144344

Epoch: 5| Step: 10
Training loss: 1.5792502744311212
Validation loss: 2.507486027019105

Epoch: 5| Step: 11
Training loss: 1.041139291141954
Validation loss: 2.540883454959372

Epoch: 117| Step: 0
Training loss: 2.0576668956457165
Validation loss: 2.5310442923329353

Epoch: 5| Step: 1
Training loss: 1.5494326629926314
Validation loss: 2.5077184736741858

Epoch: 5| Step: 2
Training loss: 1.6513350634210975
Validation loss: 2.4732976225265406

Epoch: 5| Step: 3
Training loss: 1.497921616391779
Validation loss: 2.4880612174761345

Epoch: 5| Step: 4
Training loss: 1.6683872242905067
Validation loss: 2.4679271115256927

Epoch: 5| Step: 5
Training loss: 1.6700475812746514
Validation loss: 2.4305132927323463

Epoch: 5| Step: 6
Training loss: 1.8121974297896277
Validation loss: 2.440462749003346

Epoch: 5| Step: 7
Training loss: 1.4492455657369974
Validation loss: 2.4531176257174505

Epoch: 5| Step: 8
Training loss: 1.9355467518210734
Validation loss: 2.4614823964272308

Epoch: 5| Step: 9
Training loss: 1.6912576024236334
Validation loss: 2.4459305653478447

Epoch: 5| Step: 10
Training loss: 1.5399986556901886
Validation loss: 2.4404937829348303

Epoch: 5| Step: 11
Training loss: 2.0065551858438058
Validation loss: 2.4362771214886623

Epoch: 118| Step: 0
Training loss: 1.7205974706629195
Validation loss: 2.453732694690174

Epoch: 5| Step: 1
Training loss: 1.9517242291326027
Validation loss: 2.484972803899593

Epoch: 5| Step: 2
Training loss: 1.4105146380628075
Validation loss: 2.4563598807220326

Epoch: 5| Step: 3
Training loss: 1.4226405000940803
Validation loss: 2.457002854903336

Epoch: 5| Step: 4
Training loss: 1.6554979740315918
Validation loss: 2.476305203153853

Epoch: 5| Step: 5
Training loss: 1.869665185870743
Validation loss: 2.474965259359558

Epoch: 5| Step: 6
Training loss: 1.2887893387333997
Validation loss: 2.4659007849325016

Epoch: 5| Step: 7
Training loss: 1.9256171413856817
Validation loss: 2.4504438111824953

Epoch: 5| Step: 8
Training loss: 1.9614768939187628
Validation loss: 2.4941907940874506

Epoch: 5| Step: 9
Training loss: 1.548691578795368
Validation loss: 2.4902775699634065

Epoch: 5| Step: 10
Training loss: 1.6927706036973655
Validation loss: 2.493635651748132

Epoch: 5| Step: 11
Training loss: 0.46670965553007626
Validation loss: 2.5200649474935406

Epoch: 119| Step: 0
Training loss: 1.6101824022119184
Validation loss: 2.546639098025272

Epoch: 5| Step: 1
Training loss: 1.486166585597895
Validation loss: 2.505075301817082

Epoch: 5| Step: 2
Training loss: 1.33745243665315
Validation loss: 2.502406865075385

Epoch: 5| Step: 3
Training loss: 1.6920965957528904
Validation loss: 2.4709765497829355

Epoch: 5| Step: 4
Training loss: 1.2270240158398258
Validation loss: 2.444624636491722

Epoch: 5| Step: 5
Training loss: 1.9091413489197255
Validation loss: 2.4551089337220775

Epoch: 5| Step: 6
Training loss: 1.715867764332999
Validation loss: 2.4789737170864923

Epoch: 5| Step: 7
Training loss: 1.3508762094579276
Validation loss: 2.449761763978802

Epoch: 5| Step: 8
Training loss: 1.81874324626914
Validation loss: 2.4950211936366524

Epoch: 5| Step: 9
Training loss: 1.637109168199887
Validation loss: 2.4657922361682836

Epoch: 5| Step: 10
Training loss: 2.316817403138643
Validation loss: 2.526627760991685

Epoch: 5| Step: 11
Training loss: 1.7697233723139218
Validation loss: 2.4721991109898833

Epoch: 120| Step: 0
Training loss: 1.7502075480955173
Validation loss: 2.5206964918043706

Epoch: 5| Step: 1
Training loss: 1.2580254415962704
Validation loss: 2.5765337956119105

Epoch: 5| Step: 2
Training loss: 1.496777012431049
Validation loss: 2.5530899450104845

Epoch: 5| Step: 3
Training loss: 1.8982967120426417
Validation loss: 2.5538861012240166

Epoch: 5| Step: 4
Training loss: 1.7694964205448869
Validation loss: 2.5713282223704175

Epoch: 5| Step: 5
Training loss: 1.8960987645834622
Validation loss: 2.5039866727628186

Epoch: 5| Step: 6
Training loss: 1.2646715316725807
Validation loss: 2.5490687542937955

Epoch: 5| Step: 7
Training loss: 1.9661117921286517
Validation loss: 2.483211036738734

Epoch: 5| Step: 8
Training loss: 2.106837802446565
Validation loss: 2.4573324996242136

Epoch: 5| Step: 9
Training loss: 1.3865113868947379
Validation loss: 2.459543751828892

Epoch: 5| Step: 10
Training loss: 1.6000820109091696
Validation loss: 2.446350291812636

Epoch: 5| Step: 11
Training loss: 1.204621560831555
Validation loss: 2.4659241103681886

Epoch: 121| Step: 0
Training loss: 1.3475969384451625
Validation loss: 2.434512434912964

Epoch: 5| Step: 1
Training loss: 2.0714586072538745
Validation loss: 2.5094211683384846

Epoch: 5| Step: 2
Training loss: 1.8176622211834033
Validation loss: 2.52758296795475

Epoch: 5| Step: 3
Training loss: 1.2988109616170953
Validation loss: 2.559616129209327

Epoch: 5| Step: 4
Training loss: 1.942737330270585
Validation loss: 2.5324591468423066

Epoch: 5| Step: 5
Training loss: 1.922471178828412
Validation loss: 2.514888080918417

Epoch: 5| Step: 6
Training loss: 1.6147916433844305
Validation loss: 2.5045154840073596

Epoch: 5| Step: 7
Training loss: 1.8917291742940168
Validation loss: 2.4603009848945185

Epoch: 5| Step: 8
Training loss: 1.4092973116758714
Validation loss: 2.4593185084672036

Epoch: 5| Step: 9
Training loss: 1.5322712976211328
Validation loss: 2.4443081020914654

Epoch: 5| Step: 10
Training loss: 1.3255584151880315
Validation loss: 2.433455939393891

Epoch: 5| Step: 11
Training loss: 1.0684019425470537
Validation loss: 2.4921425563223645

Epoch: 122| Step: 0
Training loss: 1.6488148768041186
Validation loss: 2.442924011458429

Epoch: 5| Step: 1
Training loss: 1.8896068006556244
Validation loss: 2.427334118985527

Epoch: 5| Step: 2
Training loss: 1.290265117652047
Validation loss: 2.4739963903344253

Epoch: 5| Step: 3
Training loss: 1.8293269192209671
Validation loss: 2.499852478125283

Epoch: 5| Step: 4
Training loss: 1.6306214301763653
Validation loss: 2.5113918394264965

Epoch: 5| Step: 5
Training loss: 1.9204084181517052
Validation loss: 2.504732635338861

Epoch: 5| Step: 6
Training loss: 1.3541955162300876
Validation loss: 2.4930727591196993

Epoch: 5| Step: 7
Training loss: 1.317822020480254
Validation loss: 2.4632982546429814

Epoch: 5| Step: 8
Training loss: 1.4304273181625748
Validation loss: 2.481297049808989

Epoch: 5| Step: 9
Training loss: 1.8820117181419225
Validation loss: 2.4386753586355145

Epoch: 5| Step: 10
Training loss: 1.5621597682554067
Validation loss: 2.4565715187863826

Epoch: 5| Step: 11
Training loss: 1.5542043577367521
Validation loss: 2.4956332037065057

Epoch: 123| Step: 0
Training loss: 1.0537057333774407
Validation loss: 2.470163890109265

Epoch: 5| Step: 1
Training loss: 1.506205280320735
Validation loss: 2.4624543293882666

Epoch: 5| Step: 2
Training loss: 1.8790309174670323
Validation loss: 2.476474319155672

Epoch: 5| Step: 3
Training loss: 1.4920377007034489
Validation loss: 2.4871301947999873

Epoch: 5| Step: 4
Training loss: 1.4387936783166786
Validation loss: 2.4883707650220885

Epoch: 5| Step: 5
Training loss: 1.742904515538305
Validation loss: 2.469535827310663

Epoch: 5| Step: 6
Training loss: 2.007525590517349
Validation loss: 2.4694687042634738

Epoch: 5| Step: 7
Training loss: 1.474003911296567
Validation loss: 2.472403229618735

Epoch: 5| Step: 8
Training loss: 1.6836501817915164
Validation loss: 2.5558385054560135

Epoch: 5| Step: 9
Training loss: 1.5787439171318245
Validation loss: 2.560875932357995

Epoch: 5| Step: 10
Training loss: 1.9751836618905754
Validation loss: 2.5106043817979113

Epoch: 5| Step: 11
Training loss: 0.9811771159226101
Validation loss: 2.505298975033721

Epoch: 124| Step: 0
Training loss: 2.1101454846454613
Validation loss: 2.529449986520689

Epoch: 5| Step: 1
Training loss: 1.8749046937244376
Validation loss: 2.502873918574592

Epoch: 5| Step: 2
Training loss: 1.5777811865627973
Validation loss: 2.4990749793571694

Epoch: 5| Step: 3
Training loss: 1.1968454740781749
Validation loss: 2.484974402968082

Epoch: 5| Step: 4
Training loss: 1.44184310619861
Validation loss: 2.5072649162829617

Epoch: 5| Step: 5
Training loss: 1.7893727129389636
Validation loss: 2.51831141077527

Epoch: 5| Step: 6
Training loss: 2.037247825884481
Validation loss: 2.4444816282784485

Epoch: 5| Step: 7
Training loss: 1.3955171236404293
Validation loss: 2.455652275513278

Epoch: 5| Step: 8
Training loss: 1.1657854680525843
Validation loss: 2.4886545453206446

Epoch: 5| Step: 9
Training loss: 1.7090083703672583
Validation loss: 2.5664161418722222

Epoch: 5| Step: 10
Training loss: 1.4820787839450602
Validation loss: 2.5194512011998076

Epoch: 5| Step: 11
Training loss: 1.1956283052421703
Validation loss: 2.54726271613324

Epoch: 125| Step: 0
Training loss: 1.3088211089803297
Validation loss: 2.561134583246581

Epoch: 5| Step: 1
Training loss: 1.5606541220774461
Validation loss: 2.6517966993311415

Epoch: 5| Step: 2
Training loss: 1.34137222700123
Validation loss: 2.548418564124813

Epoch: 5| Step: 3
Training loss: 2.1788843787768735
Validation loss: 2.546645721693521

Epoch: 5| Step: 4
Training loss: 1.5132101425298874
Validation loss: 2.5201283301874535

Epoch: 5| Step: 5
Training loss: 1.8261861056013047
Validation loss: 2.49378046608323

Epoch: 5| Step: 6
Training loss: 1.19088653735685
Validation loss: 2.4863660699106958

Epoch: 5| Step: 7
Training loss: 1.6858506089269911
Validation loss: 2.44838886711738

Epoch: 5| Step: 8
Training loss: 1.4322784793131071
Validation loss: 2.4969702760154266

Epoch: 5| Step: 9
Training loss: 1.805929309927394
Validation loss: 2.482056269421031

Epoch: 5| Step: 10
Training loss: 1.9888175435947373
Validation loss: 2.4717881746471666

Epoch: 5| Step: 11
Training loss: 1.356526646328107
Validation loss: 2.5169493977991073

Epoch: 126| Step: 0
Training loss: 1.160619264423124
Validation loss: 2.4935179540283423

Epoch: 5| Step: 1
Training loss: 1.3378958374812921
Validation loss: 2.59976674250113

Epoch: 5| Step: 2
Training loss: 2.019459116254375
Validation loss: 2.546302832553322

Epoch: 5| Step: 3
Training loss: 1.518475084579597
Validation loss: 2.5749660346960765

Epoch: 5| Step: 4
Training loss: 1.7417061316051137
Validation loss: 2.505246924792404

Epoch: 5| Step: 5
Training loss: 1.956959797359996
Validation loss: 2.5326996015849152

Epoch: 5| Step: 6
Training loss: 1.4052907427052963
Validation loss: 2.492991685418113

Epoch: 5| Step: 7
Training loss: 1.1647959197245386
Validation loss: 2.542145368699373

Epoch: 5| Step: 8
Training loss: 1.4959877713667507
Validation loss: 2.488419321841628

Epoch: 5| Step: 9
Training loss: 1.6121732218036715
Validation loss: 2.479918511504203

Epoch: 5| Step: 10
Training loss: 1.7341159936460264
Validation loss: 2.4805725997051136

Epoch: 5| Step: 11
Training loss: 1.0632545933125308
Validation loss: 2.4897920143315098

Epoch: 127| Step: 0
Training loss: 1.6767848284260696
Validation loss: 2.502442678559763

Epoch: 5| Step: 1
Training loss: 1.4032415634709052
Validation loss: 2.5202008720283926

Epoch: 5| Step: 2
Training loss: 2.097305922139753
Validation loss: 2.4908106597088784

Epoch: 5| Step: 3
Training loss: 1.4624966548001106
Validation loss: 2.4977928233261526

Epoch: 5| Step: 4
Training loss: 1.3724346939559233
Validation loss: 2.5512004428008352

Epoch: 5| Step: 5
Training loss: 1.2418229149856805
Validation loss: 2.530280049044374

Epoch: 5| Step: 6
Training loss: 1.2844866367653214
Validation loss: 2.541492824915053

Epoch: 5| Step: 7
Training loss: 1.708251935678907
Validation loss: 2.5548953556036444

Epoch: 5| Step: 8
Training loss: 1.6226942870632095
Validation loss: 2.514533036926541

Epoch: 5| Step: 9
Training loss: 1.85251139216453
Validation loss: 2.5044868022352396

Epoch: 5| Step: 10
Training loss: 1.3772798624005524
Validation loss: 2.482134658601295

Epoch: 5| Step: 11
Training loss: 0.9909141359248519
Validation loss: 2.46368327281568

Epoch: 128| Step: 0
Training loss: 1.3713316099767716
Validation loss: 2.458246164204268

Epoch: 5| Step: 1
Training loss: 1.637399609232933
Validation loss: 2.4218383499161633

Epoch: 5| Step: 2
Training loss: 1.4705842110634888
Validation loss: 2.4749933761289693

Epoch: 5| Step: 3
Training loss: 1.1138198352844244
Validation loss: 2.498011811750751

Epoch: 5| Step: 4
Training loss: 1.357678154553436
Validation loss: 2.4729777765369416

Epoch: 5| Step: 5
Training loss: 2.1840433330079656
Validation loss: 2.5239610670145503

Epoch: 5| Step: 6
Training loss: 1.5027419302036242
Validation loss: 2.5575043938773985

Epoch: 5| Step: 7
Training loss: 1.9850730569304793
Validation loss: 2.615026986652702

Epoch: 5| Step: 8
Training loss: 1.669091161936414
Validation loss: 2.5646303110341777

Epoch: 5| Step: 9
Training loss: 1.804156733155894
Validation loss: 2.491333419518405

Epoch: 5| Step: 10
Training loss: 1.2861415715017088
Validation loss: 2.519194911222607

Epoch: 5| Step: 11
Training loss: 1.2014013551911733
Validation loss: 2.459862200633415

Epoch: 129| Step: 0
Training loss: 1.7029445447600682
Validation loss: 2.4689153060616627

Epoch: 5| Step: 1
Training loss: 1.4177513271131175
Validation loss: 2.492635596957407

Epoch: 5| Step: 2
Training loss: 1.454913197841639
Validation loss: 2.5286364897304234

Epoch: 5| Step: 3
Training loss: 1.647045180270244
Validation loss: 2.4732949394740347

Epoch: 5| Step: 4
Training loss: 1.5126462156382412
Validation loss: 2.457225963678467

Epoch: 5| Step: 5
Training loss: 1.059560524328349
Validation loss: 2.4832911476343327

Epoch: 5| Step: 6
Training loss: 1.8074188700680458
Validation loss: 2.476354359605755

Epoch: 5| Step: 7
Training loss: 1.5333153944762925
Validation loss: 2.548401260196267

Epoch: 5| Step: 8
Training loss: 1.6999856555557928
Validation loss: 2.559018394427707

Epoch: 5| Step: 9
Training loss: 1.5412651604543335
Validation loss: 2.5542632478829237

Epoch: 5| Step: 10
Training loss: 1.8600810016919223
Validation loss: 2.540510885437181

Epoch: 5| Step: 11
Training loss: 1.5577710879837203
Validation loss: 2.537424320038229

Epoch: 130| Step: 0
Training loss: 1.6335862074266931
Validation loss: 2.50880425986734

Epoch: 5| Step: 1
Training loss: 1.2219295596846722
Validation loss: 2.510477315927232

Epoch: 5| Step: 2
Training loss: 1.6955488189670653
Validation loss: 2.5148738130477257

Epoch: 5| Step: 3
Training loss: 2.0035936732717197
Validation loss: 2.507667517506698

Epoch: 5| Step: 4
Training loss: 1.5799740072116235
Validation loss: 2.435798572871272

Epoch: 5| Step: 5
Training loss: 1.0191091197047033
Validation loss: 2.524290454428126

Epoch: 5| Step: 6
Training loss: 1.3390355021760818
Validation loss: 2.5478514143374853

Epoch: 5| Step: 7
Training loss: 1.1853456530672746
Validation loss: 2.523782751756671

Epoch: 5| Step: 8
Training loss: 1.9854581384907355
Validation loss: 2.575443009504765

Epoch: 5| Step: 9
Training loss: 1.8542166571003793
Validation loss: 2.5680523823070387

Epoch: 5| Step: 10
Training loss: 1.3995230100592932
Validation loss: 2.5544651218573637

Epoch: 5| Step: 11
Training loss: 0.6964851306648028
Validation loss: 2.491321776090292

Epoch: 131| Step: 0
Training loss: 1.2507404041947725
Validation loss: 2.499282344491164

Epoch: 5| Step: 1
Training loss: 1.9211974151304838
Validation loss: 2.470428250468425

Epoch: 5| Step: 2
Training loss: 1.2036009998739545
Validation loss: 2.5069141462426003

Epoch: 5| Step: 3
Training loss: 1.6427792892016215
Validation loss: 2.509935510330604

Epoch: 5| Step: 4
Training loss: 1.4272962907857198
Validation loss: 2.476035008777937

Epoch: 5| Step: 5
Training loss: 1.1023412886929356
Validation loss: 2.4941395615446234

Epoch: 5| Step: 6
Training loss: 1.3785034542351782
Validation loss: 2.487752865314287

Epoch: 5| Step: 7
Training loss: 1.530987386176872
Validation loss: 2.5793454624121153

Epoch: 5| Step: 8
Training loss: 1.988129555661913
Validation loss: 2.530647614311208

Epoch: 5| Step: 9
Training loss: 1.5282417642804238
Validation loss: 2.5235051617443296

Epoch: 5| Step: 10
Training loss: 2.025631690692533
Validation loss: 2.5248666757220746

Epoch: 5| Step: 11
Training loss: 2.1825303438050154
Validation loss: 2.537918517797264

Epoch: 132| Step: 0
Training loss: 1.5634289840902456
Validation loss: 2.4871598475999543

Epoch: 5| Step: 1
Training loss: 1.2585538965565677
Validation loss: 2.484724510047413

Epoch: 5| Step: 2
Training loss: 1.619889365762987
Validation loss: 2.4577003340237815

Epoch: 5| Step: 3
Training loss: 1.1855232952858692
Validation loss: 2.4872974105586727

Epoch: 5| Step: 4
Training loss: 1.4383094001597043
Validation loss: 2.47346878160499

Epoch: 5| Step: 5
Training loss: 1.1795497081190114
Validation loss: 2.4459394741964213

Epoch: 5| Step: 6
Training loss: 1.851302052138922
Validation loss: 2.478439870988815

Epoch: 5| Step: 7
Training loss: 1.8489240043211301
Validation loss: 2.521021837222134

Epoch: 5| Step: 8
Training loss: 1.504595155348173
Validation loss: 2.445983591506061

Epoch: 5| Step: 9
Training loss: 1.8031081517852172
Validation loss: 2.5106810902724224

Epoch: 5| Step: 10
Training loss: 1.5599155414166337
Validation loss: 2.542554420200108

Epoch: 5| Step: 11
Training loss: 1.743009364853091
Validation loss: 2.540329205403363

Epoch: 133| Step: 0
Training loss: 1.4209065754975287
Validation loss: 2.4938870915755573

Epoch: 5| Step: 1
Training loss: 1.6123938532941848
Validation loss: 2.5271816486649246

Epoch: 5| Step: 2
Training loss: 1.2490212900532507
Validation loss: 2.5200233826549017

Epoch: 5| Step: 3
Training loss: 1.503437315917653
Validation loss: 2.4827619870366737

Epoch: 5| Step: 4
Training loss: 1.5565004752330256
Validation loss: 2.4368201065631596

Epoch: 5| Step: 5
Training loss: 1.5516523321755034
Validation loss: 2.4924774001310794

Epoch: 5| Step: 6
Training loss: 1.3285887862095618
Validation loss: 2.4480568433085588

Epoch: 5| Step: 7
Training loss: 1.2980454460087962
Validation loss: 2.4386390689938917

Epoch: 5| Step: 8
Training loss: 2.14675360146213
Validation loss: 2.4949464584038514

Epoch: 5| Step: 9
Training loss: 1.1483471374254137
Validation loss: 2.487334084608545

Epoch: 5| Step: 10
Training loss: 1.3763593543295174
Validation loss: 2.4882288377832182

Epoch: 5| Step: 11
Training loss: 2.2885954188298263
Validation loss: 2.5269975125352517

Epoch: 134| Step: 0
Training loss: 1.2025164762070066
Validation loss: 2.55126893550008

Epoch: 5| Step: 1
Training loss: 1.8054898282664886
Validation loss: 2.532324198036978

Epoch: 5| Step: 2
Training loss: 1.4248494487003853
Validation loss: 2.5454372451153544

Epoch: 5| Step: 3
Training loss: 1.7467751080335598
Validation loss: 2.496262681445245

Epoch: 5| Step: 4
Training loss: 1.6169490177655128
Validation loss: 2.5420108442272795

Epoch: 5| Step: 5
Training loss: 1.6856759420864753
Validation loss: 2.4849782647142393

Epoch: 5| Step: 6
Training loss: 1.581974961021183
Validation loss: 2.5167896544381376

Epoch: 5| Step: 7
Training loss: 1.3539510799850922
Validation loss: 2.550002473318858

Epoch: 5| Step: 8
Training loss: 1.6094127761703465
Validation loss: 2.562478736075899

Epoch: 5| Step: 9
Training loss: 1.225248957657074
Validation loss: 2.5111120587837585

Epoch: 5| Step: 10
Training loss: 1.5716226909926625
Validation loss: 2.584394434433375

Epoch: 5| Step: 11
Training loss: 1.3607225425707137
Validation loss: 2.6049069814615957

Epoch: 135| Step: 0
Training loss: 1.154496900135503
Validation loss: 2.576822917309196

Epoch: 5| Step: 1
Training loss: 1.3100671472885133
Validation loss: 2.535237119508486

Epoch: 5| Step: 2
Training loss: 2.224035602689406
Validation loss: 2.5595617972160394

Epoch: 5| Step: 3
Training loss: 1.1399158729498218
Validation loss: 2.4820280045234067

Epoch: 5| Step: 4
Training loss: 1.5365923117289764
Validation loss: 2.5033177613113935

Epoch: 5| Step: 5
Training loss: 1.7033209731716699
Validation loss: 2.4820354650147656

Epoch: 5| Step: 6
Training loss: 1.4067652288290176
Validation loss: 2.5074179389472255

Epoch: 5| Step: 7
Training loss: 1.7856295102295814
Validation loss: 2.4819866872438645

Epoch: 5| Step: 8
Training loss: 1.283391047496938
Validation loss: 2.4991658011071705

Epoch: 5| Step: 9
Training loss: 1.6011079468799896
Validation loss: 2.5006421933277876

Epoch: 5| Step: 10
Training loss: 1.1072820881345242
Validation loss: 2.545521331550616

Epoch: 5| Step: 11
Training loss: 1.066750271818825
Validation loss: 2.5191101077102434

Epoch: 136| Step: 0
Training loss: 1.5618478558499218
Validation loss: 2.537631861309556

Epoch: 5| Step: 1
Training loss: 1.4270045219248157
Validation loss: 2.596717873405267

Epoch: 5| Step: 2
Training loss: 1.2415819431475266
Validation loss: 2.5723866419999024

Epoch: 5| Step: 3
Training loss: 1.0621837257437163
Validation loss: 2.5355734459814867

Epoch: 5| Step: 4
Training loss: 1.6965239103674568
Validation loss: 2.4758959835002554

Epoch: 5| Step: 5
Training loss: 1.1882735292884863
Validation loss: 2.4616560255376814

Epoch: 5| Step: 6
Training loss: 1.4507157236481045
Validation loss: 2.4824401550660378

Epoch: 5| Step: 7
Training loss: 1.30918028483035
Validation loss: 2.4930865540579976

Epoch: 5| Step: 8
Training loss: 1.6472408778588914
Validation loss: 2.492352849882213

Epoch: 5| Step: 9
Training loss: 1.8456419596553273
Validation loss: 2.4875752531901867

Epoch: 5| Step: 10
Training loss: 1.614794522491569
Validation loss: 2.567237487139136

Epoch: 5| Step: 11
Training loss: 1.386250849483632
Validation loss: 2.499966819860891

Epoch: 137| Step: 0
Training loss: 1.3521803397404968
Validation loss: 2.506152751554775

Epoch: 5| Step: 1
Training loss: 1.6446186685772963
Validation loss: 2.514094574310562

Epoch: 5| Step: 2
Training loss: 1.411271222464349
Validation loss: 2.505819945249408

Epoch: 5| Step: 3
Training loss: 1.8251090317646723
Validation loss: 2.486247742365622

Epoch: 5| Step: 4
Training loss: 1.4484620290775887
Validation loss: 2.464900564757098

Epoch: 5| Step: 5
Training loss: 1.5778160170426951
Validation loss: 2.532320251575501

Epoch: 5| Step: 6
Training loss: 1.1494122475194093
Validation loss: 2.536965769168065

Epoch: 5| Step: 7
Training loss: 1.5042016469986244
Validation loss: 2.4949869956771464

Epoch: 5| Step: 8
Training loss: 0.9209826401597627
Validation loss: 2.4881785904064615

Epoch: 5| Step: 9
Training loss: 1.2969301510769424
Validation loss: 2.484663616665834

Epoch: 5| Step: 10
Training loss: 1.8658597047733059
Validation loss: 2.543657560176326

Epoch: 5| Step: 11
Training loss: 1.7710095560988877
Validation loss: 2.51204838426362

Epoch: 138| Step: 0
Training loss: 1.6530007934060704
Validation loss: 2.5418401226411347

Epoch: 5| Step: 1
Training loss: 1.5065111464155492
Validation loss: 2.5987081515594253

Epoch: 5| Step: 2
Training loss: 2.0279232071702538
Validation loss: 2.57337962295681

Epoch: 5| Step: 3
Training loss: 1.3582738165112795
Validation loss: 2.505058471786598

Epoch: 5| Step: 4
Training loss: 1.5358926108738336
Validation loss: 2.5095629104305983

Epoch: 5| Step: 5
Training loss: 1.1058692341496057
Validation loss: 2.5345725693934797

Epoch: 5| Step: 6
Training loss: 1.7826237651343737
Validation loss: 2.488944747192498

Epoch: 5| Step: 7
Training loss: 1.3416242419025424
Validation loss: 2.5222876126529936

Epoch: 5| Step: 8
Training loss: 1.4886890563533903
Validation loss: 2.4790896689588675

Epoch: 5| Step: 9
Training loss: 1.107936463730881
Validation loss: 2.5125560600833556

Epoch: 5| Step: 10
Training loss: 1.0465987680870779
Validation loss: 2.5535423831005533

Epoch: 5| Step: 11
Training loss: 0.7831433432730074
Validation loss: 2.53940837558386

Epoch: 139| Step: 0
Training loss: 1.1580068798322005
Validation loss: 2.5109215673175775

Epoch: 5| Step: 1
Training loss: 1.5355818840311635
Validation loss: 2.5315968664360873

Epoch: 5| Step: 2
Training loss: 1.7665253765659965
Validation loss: 2.513447527987364

Epoch: 5| Step: 3
Training loss: 1.2101159539110684
Validation loss: 2.5394896201810178

Epoch: 5| Step: 4
Training loss: 1.3960270059317956
Validation loss: 2.5570814521508716

Epoch: 5| Step: 5
Training loss: 1.158392339113758
Validation loss: 2.5335509454336482

Epoch: 5| Step: 6
Training loss: 1.2544667545016983
Validation loss: 2.501958203316785

Epoch: 5| Step: 7
Training loss: 1.3674922930345126
Validation loss: 2.5574057580135

Epoch: 5| Step: 8
Training loss: 1.3322046340459757
Validation loss: 2.5546723014387216

Epoch: 5| Step: 9
Training loss: 1.8556136867734663
Validation loss: 2.525503373880599

Epoch: 5| Step: 10
Training loss: 1.469012622485584
Validation loss: 2.4955637313884447

Epoch: 5| Step: 11
Training loss: 0.8237681671362099
Validation loss: 2.4894613105738714

Epoch: 140| Step: 0
Training loss: 1.5658483106144887
Validation loss: 2.5630122754308693

Epoch: 5| Step: 1
Training loss: 1.265396804017272
Validation loss: 2.520916134811651

Epoch: 5| Step: 2
Training loss: 0.8235096706200088
Validation loss: 2.5234256858273554

Epoch: 5| Step: 3
Training loss: 1.1833556285065223
Validation loss: 2.5750140908852615

Epoch: 5| Step: 4
Training loss: 1.064347400139444
Validation loss: 2.559321875015024

Epoch: 5| Step: 5
Training loss: 1.7638177315016756
Validation loss: 2.587698568259098

Epoch: 5| Step: 6
Training loss: 1.782569530356165
Validation loss: 2.5344187874231414

Epoch: 5| Step: 7
Training loss: 1.624298017438221
Validation loss: 2.496039416339194

Epoch: 5| Step: 8
Training loss: 1.5999397802941293
Validation loss: 2.5239846902925556

Epoch: 5| Step: 9
Training loss: 1.4552617923617253
Validation loss: 2.5211855482047247

Epoch: 5| Step: 10
Training loss: 1.2737682357695632
Validation loss: 2.509228493771162

Epoch: 5| Step: 11
Training loss: 1.387590676858679
Validation loss: 2.5018402002655553

Epoch: 141| Step: 0
Training loss: 1.4735776411868202
Validation loss: 2.4648607498283988

Epoch: 5| Step: 1
Training loss: 1.961774973973236
Validation loss: 2.5463950479187742

Epoch: 5| Step: 2
Training loss: 1.3401769551824443
Validation loss: 2.4927936781383524

Epoch: 5| Step: 3
Training loss: 1.334531881146672
Validation loss: 2.4821915578458804

Epoch: 5| Step: 4
Training loss: 1.138042243156715
Validation loss: 2.5679991340135637

Epoch: 5| Step: 5
Training loss: 1.6260415187381903
Validation loss: 2.5951355523394875

Epoch: 5| Step: 6
Training loss: 1.5404534420417868
Validation loss: 2.5846495556704867

Epoch: 5| Step: 7
Training loss: 1.4938218518457547
Validation loss: 2.590194340868559

Epoch: 5| Step: 8
Training loss: 1.6506307754502227
Validation loss: 2.556154080948699

Epoch: 5| Step: 9
Training loss: 1.313248829438599
Validation loss: 2.520637032981204

Epoch: 5| Step: 10
Training loss: 1.2803027675594876
Validation loss: 2.5203249684084708

Epoch: 5| Step: 11
Training loss: 1.1205415329323438
Validation loss: 2.514629656774022

Epoch: 142| Step: 0
Training loss: 1.7232412439209914
Validation loss: 2.504912108410505

Epoch: 5| Step: 1
Training loss: 1.49134315449177
Validation loss: 2.525984857189128

Epoch: 5| Step: 2
Training loss: 1.5570933067867316
Validation loss: 2.5277809264148297

Epoch: 5| Step: 3
Training loss: 1.341657117647739
Validation loss: 2.527712402499774

Epoch: 5| Step: 4
Training loss: 1.4208895443772387
Validation loss: 2.5567684175644794

Epoch: 5| Step: 5
Training loss: 1.179874632689739
Validation loss: 2.589171758267549

Epoch: 5| Step: 6
Training loss: 1.6260064016359255
Validation loss: 2.5601760087440564

Epoch: 5| Step: 7
Training loss: 0.8969526543045769
Validation loss: 2.531849256466394

Epoch: 5| Step: 8
Training loss: 1.5260067133974564
Validation loss: 2.5124261017270393

Epoch: 5| Step: 9
Training loss: 1.2412907944628253
Validation loss: 2.6118861695630655

Epoch: 5| Step: 10
Training loss: 1.211249920320459
Validation loss: 2.5166339470039514

Epoch: 5| Step: 11
Training loss: 2.229714715440017
Validation loss: 2.5359482510147457

Epoch: 143| Step: 0
Training loss: 1.764819611362769
Validation loss: 2.5290881626812025

Epoch: 5| Step: 1
Training loss: 1.4731707496320348
Validation loss: 2.500282529919819

Epoch: 5| Step: 2
Training loss: 1.092301526754839
Validation loss: 2.4635863404259237

Epoch: 5| Step: 3
Training loss: 1.8923291809312424
Validation loss: 2.463690583215644

Epoch: 5| Step: 4
Training loss: 1.5897230247756082
Validation loss: 2.544173680340691

Epoch: 5| Step: 5
Training loss: 1.0292687312699458
Validation loss: 2.599934588887181

Epoch: 5| Step: 6
Training loss: 1.1406949165550002
Validation loss: 2.5269114946674884

Epoch: 5| Step: 7
Training loss: 1.6511937822450333
Validation loss: 2.584751049052727

Epoch: 5| Step: 8
Training loss: 1.2988772275434022
Validation loss: 2.5430834070971464

Epoch: 5| Step: 9
Training loss: 1.101950664984044
Validation loss: 2.565806004640005

Epoch: 5| Step: 10
Training loss: 1.0555881187089773
Validation loss: 2.5434851505421485

Epoch: 5| Step: 11
Training loss: 0.656517882394817
Validation loss: 2.627024301465174

Epoch: 144| Step: 0
Training loss: 1.7548739815703653
Validation loss: 2.56963561323474

Epoch: 5| Step: 1
Training loss: 0.9925579671002592
Validation loss: 2.5276672003009453

Epoch: 5| Step: 2
Training loss: 1.104487006784932
Validation loss: 2.57920307776695

Epoch: 5| Step: 3
Training loss: 1.4241842444629536
Validation loss: 2.505562879465211

Epoch: 5| Step: 4
Training loss: 1.4858383193746287
Validation loss: 2.5950320744385085

Epoch: 5| Step: 5
Training loss: 1.829853903144797
Validation loss: 2.5624077633020277

Epoch: 5| Step: 6
Training loss: 1.1322781058689386
Validation loss: 2.562176067532901

Epoch: 5| Step: 7
Training loss: 1.0724820055930364
Validation loss: 2.5258146256077385

Epoch: 5| Step: 8
Training loss: 1.0923808110950455
Validation loss: 2.500759092957938

Epoch: 5| Step: 9
Training loss: 1.264794677762627
Validation loss: 2.477244887819943

Epoch: 5| Step: 10
Training loss: 1.829830710705252
Validation loss: 2.5571914013528243

Epoch: 5| Step: 11
Training loss: 0.5875210788678905
Validation loss: 2.554608132843397

Epoch: 145| Step: 0
Training loss: 1.1318102381950796
Validation loss: 2.5041206811585113

Epoch: 5| Step: 1
Training loss: 0.9379635618448586
Validation loss: 2.582344115092531

Epoch: 5| Step: 2
Training loss: 1.3488134750688636
Validation loss: 2.5907669953382655

Epoch: 5| Step: 3
Training loss: 1.0984430717229279
Validation loss: 2.614327801354276

Epoch: 5| Step: 4
Training loss: 1.6657744006059132
Validation loss: 2.610077359894027

Epoch: 5| Step: 5
Training loss: 1.5849698877933902
Validation loss: 2.5455142268889306

Epoch: 5| Step: 6
Training loss: 1.3660854148326858
Validation loss: 2.53790937208051

Epoch: 5| Step: 7
Training loss: 1.1308546313250571
Validation loss: 2.5195626781780467

Epoch: 5| Step: 8
Training loss: 1.2411242559075177
Validation loss: 2.502744582752623

Epoch: 5| Step: 9
Training loss: 1.6210743362918862
Validation loss: 2.495536208630006

Epoch: 5| Step: 10
Training loss: 2.0011605233580294
Validation loss: 2.549288569499753

Epoch: 5| Step: 11
Training loss: 0.8041186868522665
Validation loss: 2.5201312077767497

Epoch: 146| Step: 0
Training loss: 1.1906887207601673
Validation loss: 2.5072930947872756

Epoch: 5| Step: 1
Training loss: 1.4166878623872743
Validation loss: 2.593057953764693

Epoch: 5| Step: 2
Training loss: 1.7070142801868533
Validation loss: 2.6022468980234477

Epoch: 5| Step: 3
Training loss: 1.8431555872798417
Validation loss: 2.633110252168241

Epoch: 5| Step: 4
Training loss: 1.102512518104538
Validation loss: 2.6127330241096063

Epoch: 5| Step: 5
Training loss: 1.3855693082926528
Validation loss: 2.5006112066802375

Epoch: 5| Step: 6
Training loss: 1.3727952881308703
Validation loss: 2.589389283594084

Epoch: 5| Step: 7
Training loss: 1.6584721179696582
Validation loss: 2.5663048711114143

Epoch: 5| Step: 8
Training loss: 1.0921616055934873
Validation loss: 2.510230608860891

Epoch: 5| Step: 9
Training loss: 0.8364204366483142
Validation loss: 2.488702507830443

Epoch: 5| Step: 10
Training loss: 1.452512468425661
Validation loss: 2.495785838971749

Epoch: 5| Step: 11
Training loss: 1.1191054733108434
Validation loss: 2.5233673070193596

Epoch: 147| Step: 0
Training loss: 1.556816904767379
Validation loss: 2.4635016106755825

Epoch: 5| Step: 1
Training loss: 1.3882707534247247
Validation loss: 2.425748905738202

Epoch: 5| Step: 2
Training loss: 0.9457585567094338
Validation loss: 2.546232458399714

Epoch: 5| Step: 3
Training loss: 1.6747074554957113
Validation loss: 2.5270565013189574

Epoch: 5| Step: 4
Training loss: 1.7259881630775635
Validation loss: 2.5365335811025322

Epoch: 5| Step: 5
Training loss: 1.2471303425009446
Validation loss: 2.56958912078402

Epoch: 5| Step: 6
Training loss: 0.9924308898847868
Validation loss: 2.5496294771538452

Epoch: 5| Step: 7
Training loss: 1.1662231976208526
Validation loss: 2.5722720088894007

Epoch: 5| Step: 8
Training loss: 1.7119348136310057
Validation loss: 2.5878187560652433

Epoch: 5| Step: 9
Training loss: 1.36305540995993
Validation loss: 2.5081468539502234

Epoch: 5| Step: 10
Training loss: 1.2622211034938469
Validation loss: 2.5649908005243947

Epoch: 5| Step: 11
Training loss: 1.051444486029647
Validation loss: 2.4994007505015814

Epoch: 148| Step: 0
Training loss: 1.0597627948367456
Validation loss: 2.4860478053625483

Epoch: 5| Step: 1
Training loss: 1.189359864836716
Validation loss: 2.493279774788851

Epoch: 5| Step: 2
Training loss: 1.4780020987324145
Validation loss: 2.4922399644899955

Epoch: 5| Step: 3
Training loss: 0.9500325485978011
Validation loss: 2.5316533407040978

Epoch: 5| Step: 4
Training loss: 1.3737786243708923
Validation loss: 2.489942980902433

Epoch: 5| Step: 5
Training loss: 1.7830045658466032
Validation loss: 2.5381382869161953

Epoch: 5| Step: 6
Training loss: 1.6071280191130124
Validation loss: 2.612775420085594

Epoch: 5| Step: 7
Training loss: 1.5219467302842757
Validation loss: 2.5730797018425458

Epoch: 5| Step: 8
Training loss: 1.1531907928636456
Validation loss: 2.5877535532991853

Epoch: 5| Step: 9
Training loss: 0.9945745514150504
Validation loss: 2.593994960171439

Epoch: 5| Step: 10
Training loss: 1.6596979204187237
Validation loss: 2.591634400791423

Epoch: 5| Step: 11
Training loss: 0.6047804334724972
Validation loss: 2.5401087439342436

Epoch: 149| Step: 0
Training loss: 1.0016408214207395
Validation loss: 2.537558433880914

Epoch: 5| Step: 1
Training loss: 1.0160370211051493
Validation loss: 2.504903851495719

Epoch: 5| Step: 2
Training loss: 1.0104801446435308
Validation loss: 2.5441962901153716

Epoch: 5| Step: 3
Training loss: 1.3085983959514076
Validation loss: 2.507892864837063

Epoch: 5| Step: 4
Training loss: 1.7152915144081589
Validation loss: 2.4942121463120976

Epoch: 5| Step: 5
Training loss: 1.2683842568736896
Validation loss: 2.4662511790305466

Epoch: 5| Step: 6
Training loss: 1.127738269234974
Validation loss: 2.489276720795541

Epoch: 5| Step: 7
Training loss: 1.6621932872564609
Validation loss: 2.5140383674786273

Epoch: 5| Step: 8
Training loss: 1.4205960400940372
Validation loss: 2.5818725206271953

Epoch: 5| Step: 9
Training loss: 1.8559308891994386
Validation loss: 2.60359621030573

Epoch: 5| Step: 10
Training loss: 1.0250516785410428
Validation loss: 2.628913469384962

Epoch: 5| Step: 11
Training loss: 1.481649204976558
Validation loss: 2.522327781408824

Epoch: 150| Step: 0
Training loss: 1.7390697962358526
Validation loss: 2.5703345803159783

Epoch: 5| Step: 1
Training loss: 1.3129955446177863
Validation loss: 2.527906574311699

Epoch: 5| Step: 2
Training loss: 1.2076571425075444
Validation loss: 2.5140814221549044

Epoch: 5| Step: 3
Training loss: 1.3607715141954675
Validation loss: 2.489300202320166

Epoch: 5| Step: 4
Training loss: 1.6479009686223485
Validation loss: 2.4689661345856075

Epoch: 5| Step: 5
Training loss: 1.1840063200665956
Validation loss: 2.4988158441531714

Epoch: 5| Step: 6
Training loss: 1.6204589336150537
Validation loss: 2.5027155790163493

Epoch: 5| Step: 7
Training loss: 1.4115754908212423
Validation loss: 2.5487425730099558

Epoch: 5| Step: 8
Training loss: 0.9711501322280863
Validation loss: 2.554667372629125

Epoch: 5| Step: 9
Training loss: 0.9245578392116082
Validation loss: 2.535106875933637

Epoch: 5| Step: 10
Training loss: 1.0081253748950392
Validation loss: 2.569180100965026

Epoch: 5| Step: 11
Training loss: 0.6347908836621158
Validation loss: 2.5951012190272493

Epoch: 151| Step: 0
Training loss: 1.7322853490454677
Validation loss: 2.6056348413147505

Epoch: 5| Step: 1
Training loss: 0.9936352477606388
Validation loss: 2.5880259294946564

Epoch: 5| Step: 2
Training loss: 1.3756245148522277
Validation loss: 2.5874867019680177

Epoch: 5| Step: 3
Training loss: 1.1553661473690446
Validation loss: 2.6288132218881652

Epoch: 5| Step: 4
Training loss: 1.3529407772261184
Validation loss: 2.5735091011263678

Epoch: 5| Step: 5
Training loss: 1.586058438204603
Validation loss: 2.572253903782506

Epoch: 5| Step: 6
Training loss: 1.32197817857424
Validation loss: 2.536489479975557

Epoch: 5| Step: 7
Training loss: 1.28639476891932
Validation loss: 2.5690387982700167

Epoch: 5| Step: 8
Training loss: 1.3120862217751517
Validation loss: 2.4648793455234843

Epoch: 5| Step: 9
Training loss: 1.3151239324412543
Validation loss: 2.5625828714073724

Epoch: 5| Step: 10
Training loss: 1.2627975528684872
Validation loss: 2.484863465151034

Epoch: 5| Step: 11
Training loss: 0.8993071617855095
Validation loss: 2.536898683761812

Epoch: 152| Step: 0
Training loss: 1.7888923130963543
Validation loss: 2.566608972540919

Epoch: 5| Step: 1
Training loss: 0.8031286677414085
Validation loss: 2.647874117693733

Epoch: 5| Step: 2
Training loss: 1.1238033500117717
Validation loss: 2.7008113477973974

Epoch: 5| Step: 3
Training loss: 1.190356232752858
Validation loss: 2.7093607616527087

Epoch: 5| Step: 4
Training loss: 1.34921404600842
Validation loss: 2.6969060269100034

Epoch: 5| Step: 5
Training loss: 1.4946860122114973
Validation loss: 2.61484715028695

Epoch: 5| Step: 6
Training loss: 0.8599000887165718
Validation loss: 2.586410840249208

Epoch: 5| Step: 7
Training loss: 1.0585122165038026
Validation loss: 2.545482082974013

Epoch: 5| Step: 8
Training loss: 1.4608075905225577
Validation loss: 2.5461698620806885

Epoch: 5| Step: 9
Training loss: 1.8186221153157216
Validation loss: 2.545033059920331

Epoch: 5| Step: 10
Training loss: 1.6409339250632062
Validation loss: 2.5339829169427417

Epoch: 5| Step: 11
Training loss: 1.3192168435445888
Validation loss: 2.510381673962062

Epoch: 153| Step: 0
Training loss: 1.4752975777919994
Validation loss: 2.5235847493170356

Epoch: 5| Step: 1
Training loss: 1.8509722706486462
Validation loss: 2.551053860688314

Epoch: 5| Step: 2
Training loss: 1.580628778913935
Validation loss: 2.5588758764440165

Epoch: 5| Step: 3
Training loss: 0.9305202377000286
Validation loss: 2.585780789178198

Epoch: 5| Step: 4
Training loss: 1.0987691972637341
Validation loss: 2.6001794783682874

Epoch: 5| Step: 5
Training loss: 1.060181837679708
Validation loss: 2.6008255519055883

Epoch: 5| Step: 6
Training loss: 1.1238881020557085
Validation loss: 2.5740356457372973

Epoch: 5| Step: 7
Training loss: 1.6624425605660476
Validation loss: 2.6218491445000813

Epoch: 5| Step: 8
Training loss: 1.0286018587523238
Validation loss: 2.4788206176842906

Epoch: 5| Step: 9
Training loss: 1.0002619876996552
Validation loss: 2.4510669255174427

Epoch: 5| Step: 10
Training loss: 1.4833707122522175
Validation loss: 2.456310835740941

Epoch: 5| Step: 11
Training loss: 0.9725452957293715
Validation loss: 2.4442954380745947

Epoch: 154| Step: 0
Training loss: 1.4036547130334514
Validation loss: 2.5142452037673615

Epoch: 5| Step: 1
Training loss: 1.4628547694621248
Validation loss: 2.5022440296271724

Epoch: 5| Step: 2
Training loss: 1.0081272668688854
Validation loss: 2.5212057143359696

Epoch: 5| Step: 3
Training loss: 0.9884370824214163
Validation loss: 2.498130055291128

Epoch: 5| Step: 4
Training loss: 1.4054223061946147
Validation loss: 2.4975655265704426

Epoch: 5| Step: 5
Training loss: 1.436506674517678
Validation loss: 2.5476154273040947

Epoch: 5| Step: 6
Training loss: 1.279507824926386
Validation loss: 2.48257413207624

Epoch: 5| Step: 7
Training loss: 1.5250185855921123
Validation loss: 2.5671258746795766

Epoch: 5| Step: 8
Training loss: 1.4441517885956545
Validation loss: 2.6874865635085037

Epoch: 5| Step: 9
Training loss: 1.329082996202294
Validation loss: 2.740974632617359

Epoch: 5| Step: 10
Training loss: 1.1109812216867083
Validation loss: 2.7249781132323645

Epoch: 5| Step: 11
Training loss: 1.4995469362774614
Validation loss: 2.725692553765896

Epoch: 155| Step: 0
Training loss: 1.046576784844582
Validation loss: 2.6662404283476047

Epoch: 5| Step: 1
Training loss: 1.5356784543898179
Validation loss: 2.508397597591223

Epoch: 5| Step: 2
Training loss: 1.252887728100752
Validation loss: 2.5936972716153917

Epoch: 5| Step: 3
Training loss: 1.0339077311876033
Validation loss: 2.5353282680057974

Epoch: 5| Step: 4
Training loss: 1.5125961714505836
Validation loss: 2.581981171753794

Epoch: 5| Step: 5
Training loss: 1.2335336449483671
Validation loss: 2.5662384791238697

Epoch: 5| Step: 6
Training loss: 1.6256992596212727
Validation loss: 2.6041825764487965

Epoch: 5| Step: 7
Training loss: 1.435741842096272
Validation loss: 2.586487121027502

Epoch: 5| Step: 8
Training loss: 1.6099034154839507
Validation loss: 2.5473151889458654

Epoch: 5| Step: 9
Training loss: 1.2526629692545501
Validation loss: 2.6215984087952493

Epoch: 5| Step: 10
Training loss: 1.0778953197023382
Validation loss: 2.643980956003461

Epoch: 5| Step: 11
Training loss: 1.0054909633266442
Validation loss: 2.6811236582217104

Epoch: 156| Step: 0
Training loss: 1.4117846188064156
Validation loss: 2.705093943782601

Epoch: 5| Step: 1
Training loss: 1.167285987549247
Validation loss: 2.7077593500842725

Epoch: 5| Step: 2
Training loss: 1.1168750245916688
Validation loss: 2.6526668877972632

Epoch: 5| Step: 3
Training loss: 0.7584938840022288
Validation loss: 2.5720276158855238

Epoch: 5| Step: 4
Training loss: 1.2847997292631157
Validation loss: 2.5784231726335016

Epoch: 5| Step: 5
Training loss: 1.9557264169672817
Validation loss: 2.5573597074781382

Epoch: 5| Step: 6
Training loss: 1.11052257660198
Validation loss: 2.5569684134444346

Epoch: 5| Step: 7
Training loss: 1.830162543076989
Validation loss: 2.540705488680933

Epoch: 5| Step: 8
Training loss: 1.6331344360125677
Validation loss: 2.5412369792208738

Epoch: 5| Step: 9
Training loss: 1.2708086834794268
Validation loss: 2.563271596313516

Epoch: 5| Step: 10
Training loss: 1.0909700760448273
Validation loss: 2.5494917803339634

Epoch: 5| Step: 11
Training loss: 1.02440405478012
Validation loss: 2.4809719106018666

Epoch: 157| Step: 0
Training loss: 1.3095100041896177
Validation loss: 2.606758898245019

Epoch: 5| Step: 1
Training loss: 1.5892950137311752
Validation loss: 2.6347353937984686

Epoch: 5| Step: 2
Training loss: 1.4935843435710197
Validation loss: 2.6356082527473466

Epoch: 5| Step: 3
Training loss: 1.0595406101827645
Validation loss: 2.6098205848391576

Epoch: 5| Step: 4
Training loss: 1.0584151339019143
Validation loss: 2.6213478802785537

Epoch: 5| Step: 5
Training loss: 1.0898918770175632
Validation loss: 2.548489587354029

Epoch: 5| Step: 6
Training loss: 1.4140563458893622
Validation loss: 2.5147386513734045

Epoch: 5| Step: 7
Training loss: 1.970420189500277
Validation loss: 2.558105340598304

Epoch: 5| Step: 8
Training loss: 1.3592275342209048
Validation loss: 2.530113302503295

Epoch: 5| Step: 9
Training loss: 1.0685634941082616
Validation loss: 2.541187793666466

Epoch: 5| Step: 10
Training loss: 1.421816059609643
Validation loss: 2.5563388429730662

Epoch: 5| Step: 11
Training loss: 1.3107329235110476
Validation loss: 2.5762187306633284

Epoch: 158| Step: 0
Training loss: 1.1177093247512635
Validation loss: 2.5682213537071172

Epoch: 5| Step: 1
Training loss: 0.8028749217603949
Validation loss: 2.5934638819241522

Epoch: 5| Step: 2
Training loss: 1.1234106917492044
Validation loss: 2.626690369503509

Epoch: 5| Step: 3
Training loss: 1.1170403977229106
Validation loss: 2.5960192730613847

Epoch: 5| Step: 4
Training loss: 1.4713655274439257
Validation loss: 2.664442592738543

Epoch: 5| Step: 5
Training loss: 1.5265197872874838
Validation loss: 2.5939116178662727

Epoch: 5| Step: 6
Training loss: 1.2465817443632161
Validation loss: 2.5421961808637707

Epoch: 5| Step: 7
Training loss: 1.1076743293973181
Validation loss: 2.5077257309714973

Epoch: 5| Step: 8
Training loss: 1.5671317306438524
Validation loss: 2.518903142424205

Epoch: 5| Step: 9
Training loss: 1.1468300501358748
Validation loss: 2.5896297115143065

Epoch: 5| Step: 10
Training loss: 1.2728832887725992
Validation loss: 2.522807626286781

Epoch: 5| Step: 11
Training loss: 0.8143097822258311
Validation loss: 2.5220203494855062

Epoch: 159| Step: 0
Training loss: 1.5408174220505435
Validation loss: 2.542807715064026

Epoch: 5| Step: 1
Training loss: 1.3839556177194852
Validation loss: 2.5311227892083057

Epoch: 5| Step: 2
Training loss: 0.7275159588928105
Validation loss: 2.5556476239249193

Epoch: 5| Step: 3
Training loss: 1.2792158960236253
Validation loss: 2.51846191621936

Epoch: 5| Step: 4
Training loss: 0.9374675427222451
Validation loss: 2.5442507393914524

Epoch: 5| Step: 5
Training loss: 0.7442221208936943
Validation loss: 2.573830439715653

Epoch: 5| Step: 6
Training loss: 1.4574257160709736
Validation loss: 2.571384855544031

Epoch: 5| Step: 7
Training loss: 1.2738913914873602
Validation loss: 2.5247489505388794

Epoch: 5| Step: 8
Training loss: 1.4648186846813838
Validation loss: 2.548168626140009

Epoch: 5| Step: 9
Training loss: 1.239793401704212
Validation loss: 2.5293506277845763

Epoch: 5| Step: 10
Training loss: 1.2992373173270653
Validation loss: 2.486203670258639

Epoch: 5| Step: 11
Training loss: 1.5295487899156477
Validation loss: 2.483863819962376

Epoch: 160| Step: 0
Training loss: 1.2040869595151855
Validation loss: 2.5146316478378616

Epoch: 5| Step: 1
Training loss: 1.1147274328233026
Validation loss: 2.4633407201664816

Epoch: 5| Step: 2
Training loss: 1.2000303224865132
Validation loss: 2.550308604359558

Epoch: 5| Step: 3
Training loss: 1.2091367067866448
Validation loss: 2.556157331877769

Epoch: 5| Step: 4
Training loss: 1.2252317365099734
Validation loss: 2.502945428472071

Epoch: 5| Step: 5
Training loss: 1.1563283017425576
Validation loss: 2.6148970492990196

Epoch: 5| Step: 6
Training loss: 1.5091395097659206
Validation loss: 2.5308764382205338

Epoch: 5| Step: 7
Training loss: 1.339643991776912
Validation loss: 2.6053373407551805

Epoch: 5| Step: 8
Training loss: 1.1596726459609625
Validation loss: 2.5532663185606386

Epoch: 5| Step: 9
Training loss: 1.7120272157814238
Validation loss: 2.4978894185819627

Epoch: 5| Step: 10
Training loss: 1.0268799057400446
Validation loss: 2.5433809089950095

Epoch: 5| Step: 11
Training loss: 0.5873503880025476
Validation loss: 2.531609560699339

Epoch: 161| Step: 0
Training loss: 0.9714300247039263
Validation loss: 2.452210039048418

Epoch: 5| Step: 1
Training loss: 1.173551352269241
Validation loss: 2.5372714097863778

Epoch: 5| Step: 2
Training loss: 0.8389491795003448
Validation loss: 2.536447659469381

Epoch: 5| Step: 3
Training loss: 1.6010084729134246
Validation loss: 2.53354656368845

Epoch: 5| Step: 4
Training loss: 0.914389103632723
Validation loss: 2.515130569015032

Epoch: 5| Step: 5
Training loss: 1.3902819349616555
Validation loss: 2.6009367494781803

Epoch: 5| Step: 6
Training loss: 1.4449814700882206
Validation loss: 2.6190783696903224

Epoch: 5| Step: 7
Training loss: 0.9524575382189685
Validation loss: 2.593580397457326

Epoch: 5| Step: 8
Training loss: 1.615964417802345
Validation loss: 2.565402732294143

Epoch: 5| Step: 9
Training loss: 1.2730189378592829
Validation loss: 2.6001127363791463

Epoch: 5| Step: 10
Training loss: 1.2202097635823619
Validation loss: 2.5370476147204797

Epoch: 5| Step: 11
Training loss: 0.8823444172036073
Validation loss: 2.5410356220276573

Epoch: 162| Step: 0
Training loss: 1.100118895087366
Validation loss: 2.5269625070110457

Epoch: 5| Step: 1
Training loss: 1.1990669477478204
Validation loss: 2.496646419943019

Epoch: 5| Step: 2
Training loss: 0.8504736001673444
Validation loss: 2.541937447543621

Epoch: 5| Step: 3
Training loss: 0.9808080929468947
Validation loss: 2.5565879841614474

Epoch: 5| Step: 4
Training loss: 1.111055793312364
Validation loss: 2.599053707296746

Epoch: 5| Step: 5
Training loss: 1.5538280929618362
Validation loss: 2.5972391276452518

Epoch: 5| Step: 6
Training loss: 0.7386467649487766
Validation loss: 2.539858772423495

Epoch: 5| Step: 7
Training loss: 1.198582781921895
Validation loss: 2.63500943386095

Epoch: 5| Step: 8
Training loss: 1.3209264106727217
Validation loss: 2.5126223562822685

Epoch: 5| Step: 9
Training loss: 1.7344994715109465
Validation loss: 2.573634118399726

Epoch: 5| Step: 10
Training loss: 1.2938584323721936
Validation loss: 2.510786034621446

Epoch: 5| Step: 11
Training loss: 1.8297221713930518
Validation loss: 2.5919294268306436

Epoch: 163| Step: 0
Training loss: 0.939742045872975
Validation loss: 2.567670840569323

Epoch: 5| Step: 1
Training loss: 1.0454172261554493
Validation loss: 2.6209237450518876

Epoch: 5| Step: 2
Training loss: 1.8973301927380137
Validation loss: 2.6194525487196163

Epoch: 5| Step: 3
Training loss: 1.398231746945258
Validation loss: 2.654539810601868

Epoch: 5| Step: 4
Training loss: 1.1296120519492237
Validation loss: 2.571695039029783

Epoch: 5| Step: 5
Training loss: 0.7760434801391987
Validation loss: 2.5752305824160744

Epoch: 5| Step: 6
Training loss: 1.210648385266638
Validation loss: 2.551882647713799

Epoch: 5| Step: 7
Training loss: 0.9040174279052146
Validation loss: 2.5634749581468195

Epoch: 5| Step: 8
Training loss: 1.3033204826264546
Validation loss: 2.577075821832942

Epoch: 5| Step: 9
Training loss: 1.281323965775395
Validation loss: 2.6264093698965727

Epoch: 5| Step: 10
Training loss: 1.1837639009652452
Validation loss: 2.539885460925576

Epoch: 5| Step: 11
Training loss: 0.6448847639287831
Validation loss: 2.5516361753094157

Epoch: 164| Step: 0
Training loss: 1.159280825591946
Validation loss: 2.5729724624442376

Epoch: 5| Step: 1
Training loss: 0.6950566539040041
Validation loss: 2.5470125789186935

Epoch: 5| Step: 2
Training loss: 0.8315059095850527
Validation loss: 2.5302465474957265

Epoch: 5| Step: 3
Training loss: 1.3378356031255467
Validation loss: 2.560169711100384

Epoch: 5| Step: 4
Training loss: 1.2526204299135344
Validation loss: 2.567168327301741

Epoch: 5| Step: 5
Training loss: 1.0382958932824213
Validation loss: 2.612506631906661

Epoch: 5| Step: 6
Training loss: 1.246634291357676
Validation loss: 2.5646075095476317

Epoch: 5| Step: 7
Training loss: 1.4725356318205687
Validation loss: 2.546275676818809

Epoch: 5| Step: 8
Training loss: 0.956053845850386
Validation loss: 2.5818927937453693

Epoch: 5| Step: 9
Training loss: 1.3640817734797592
Validation loss: 2.556462323698579

Epoch: 5| Step: 10
Training loss: 1.4667778572647787
Validation loss: 2.578168105718742

Epoch: 5| Step: 11
Training loss: 1.5904948333061506
Validation loss: 2.6002482320200455

Epoch: 165| Step: 0
Training loss: 1.4612917547077
Validation loss: 2.5945683034908016

Epoch: 5| Step: 1
Training loss: 0.9860712000033949
Validation loss: 2.585822080742803

Epoch: 5| Step: 2
Training loss: 1.71000876106561
Validation loss: 2.617840859008057

Epoch: 5| Step: 3
Training loss: 0.865000846123695
Validation loss: 2.5705935470458607

Epoch: 5| Step: 4
Training loss: 1.0805555395656432
Validation loss: 2.6280634390159885

Epoch: 5| Step: 5
Training loss: 1.395163213896399
Validation loss: 2.6310006877553196

Epoch: 5| Step: 6
Training loss: 1.440586260028537
Validation loss: 2.5603422252385735

Epoch: 5| Step: 7
Training loss: 0.717778669065756
Validation loss: 2.561948503679261

Epoch: 5| Step: 8
Training loss: 1.0896473369192832
Validation loss: 2.5817649403876075

Epoch: 5| Step: 9
Training loss: 1.0167947341949166
Validation loss: 2.574391048147067

Epoch: 5| Step: 10
Training loss: 0.8978274056896512
Validation loss: 2.533141491056095

Epoch: 5| Step: 11
Training loss: 1.053127123550402
Validation loss: 2.5513907965598337

Epoch: 166| Step: 0
Training loss: 0.8324575988464867
Validation loss: 2.55675403954425

Epoch: 5| Step: 1
Training loss: 1.1291310439643265
Validation loss: 2.6093564442109964

Epoch: 5| Step: 2
Training loss: 1.7171547161995786
Validation loss: 2.5881568512641295

Epoch: 5| Step: 3
Training loss: 1.5805059921696532
Validation loss: 2.7470111680085587

Epoch: 5| Step: 4
Training loss: 1.4055832871845497
Validation loss: 2.6194914057358187

Epoch: 5| Step: 5
Training loss: 1.2392305892707778
Validation loss: 2.60359218873076

Epoch: 5| Step: 6
Training loss: 1.083536581389211
Validation loss: 2.598286935064942

Epoch: 5| Step: 7
Training loss: 1.2848496462661037
Validation loss: 2.544304472988198

Epoch: 5| Step: 8
Training loss: 1.11648852483624
Validation loss: 2.5307269203462357

Epoch: 5| Step: 9
Training loss: 1.140759185840976
Validation loss: 2.4819369679123544

Epoch: 5| Step: 10
Training loss: 1.162991434224828
Validation loss: 2.533070419863

Epoch: 5| Step: 11
Training loss: 0.8103450661796728
Validation loss: 2.5130349008960344

Epoch: 167| Step: 0
Training loss: 0.8736341920326235
Validation loss: 2.5545524927020935

Epoch: 5| Step: 1
Training loss: 0.7720930571406112
Validation loss: 2.551509287883358

Epoch: 5| Step: 2
Training loss: 1.3516059824393154
Validation loss: 2.6183237522499527

Epoch: 5| Step: 3
Training loss: 1.2542534938594034
Validation loss: 2.543578055847893

Epoch: 5| Step: 4
Training loss: 1.0983681321793852
Validation loss: 2.5991002937844807

Epoch: 5| Step: 5
Training loss: 1.3432192974262964
Validation loss: 2.534619819773154

Epoch: 5| Step: 6
Training loss: 1.1577541259382382
Validation loss: 2.524260840325271

Epoch: 5| Step: 7
Training loss: 1.7621367438661655
Validation loss: 2.4869448208392892

Epoch: 5| Step: 8
Training loss: 0.8508755073842866
Validation loss: 2.537056311291538

Epoch: 5| Step: 9
Training loss: 1.4236558095639635
Validation loss: 2.5349207466510086

Epoch: 5| Step: 10
Training loss: 1.1590973102508422
Validation loss: 2.4944810269082107

Epoch: 5| Step: 11
Training loss: 0.747524706709697
Validation loss: 2.5815461723144697

Epoch: 168| Step: 0
Training loss: 0.9460845505812905
Validation loss: 2.547409945360299

Epoch: 5| Step: 1
Training loss: 0.7309651447628155
Validation loss: 2.509878066496704

Epoch: 5| Step: 2
Training loss: 0.9760641428592933
Validation loss: 2.5718583673099253

Epoch: 5| Step: 3
Training loss: 1.4792276378834817
Validation loss: 2.5638570681142903

Epoch: 5| Step: 4
Training loss: 0.8768648302789542
Validation loss: 2.5990056445772454

Epoch: 5| Step: 5
Training loss: 1.4874298784413433
Validation loss: 2.565058524150095

Epoch: 5| Step: 6
Training loss: 0.7797905068402061
Validation loss: 2.5907852739882964

Epoch: 5| Step: 7
Training loss: 1.192566453693554
Validation loss: 2.6328800958696608

Epoch: 5| Step: 8
Training loss: 1.2551074112753042
Validation loss: 2.6116188475238244

Epoch: 5| Step: 9
Training loss: 1.2634470531811044
Validation loss: 2.536267966007368

Epoch: 5| Step: 10
Training loss: 1.4426929551095682
Validation loss: 2.5936435692946826

Epoch: 5| Step: 11
Training loss: 1.3794618951333222
Validation loss: 2.5850612792401426

Epoch: 169| Step: 0
Training loss: 0.698401052902243
Validation loss: 2.5934544858381225

Epoch: 5| Step: 1
Training loss: 1.8113829360313172
Validation loss: 2.552010343766476

Epoch: 5| Step: 2
Training loss: 0.9216796538718142
Validation loss: 2.593464870177451

Epoch: 5| Step: 3
Training loss: 0.9801093730909182
Validation loss: 2.5214460405961336

Epoch: 5| Step: 4
Training loss: 1.2805289123440833
Validation loss: 2.599658343672885

Epoch: 5| Step: 5
Training loss: 1.3594334907663783
Validation loss: 2.5879744222257504

Epoch: 5| Step: 6
Training loss: 0.7736685436677441
Validation loss: 2.6092804988720797

Epoch: 5| Step: 7
Training loss: 1.4240597718317127
Validation loss: 2.6055147642602963

Epoch: 5| Step: 8
Training loss: 0.9489761482071232
Validation loss: 2.6037301206264805

Epoch: 5| Step: 9
Training loss: 0.9642165767266251
Validation loss: 2.584058276614451

Epoch: 5| Step: 10
Training loss: 1.1933730603820951
Validation loss: 2.57954486704458

Epoch: 5| Step: 11
Training loss: 0.9780550727589047
Validation loss: 2.5598057601361495

Epoch: 170| Step: 0
Training loss: 0.9469722018064258
Validation loss: 2.59827330485901

Epoch: 5| Step: 1
Training loss: 0.9233656324379037
Validation loss: 2.5928054108357452

Epoch: 5| Step: 2
Training loss: 1.8001647026155603
Validation loss: 2.5142072509100593

Epoch: 5| Step: 3
Training loss: 1.1140863017446114
Validation loss: 2.575009523145726

Epoch: 5| Step: 4
Training loss: 1.4039346495713498
Validation loss: 2.559500157591804

Epoch: 5| Step: 5
Training loss: 0.8430745989055555
Validation loss: 2.5698827811392597

Epoch: 5| Step: 6
Training loss: 1.2383704890396854
Validation loss: 2.6131283383187314

Epoch: 5| Step: 7
Training loss: 1.418710813947455
Validation loss: 2.6575295564007306

Epoch: 5| Step: 8
Training loss: 0.9194282130460253
Validation loss: 2.6438416483920535

Epoch: 5| Step: 9
Training loss: 1.056049569429554
Validation loss: 2.700907574988464

Epoch: 5| Step: 10
Training loss: 0.8361674553997519
Validation loss: 2.562083127065259

Epoch: 5| Step: 11
Training loss: 1.3896079469680847
Validation loss: 2.57146798919181

Epoch: 171| Step: 0
Training loss: 1.3043704532823708
Validation loss: 2.5789478664975194

Epoch: 5| Step: 1
Training loss: 0.8161925989972201
Validation loss: 2.584877200152045

Epoch: 5| Step: 2
Training loss: 1.2040766630668902
Validation loss: 2.577066631977441

Epoch: 5| Step: 3
Training loss: 1.2896097119929977
Validation loss: 2.5362438656936597

Epoch: 5| Step: 4
Training loss: 1.1415594793154948
Validation loss: 2.584917514629904

Epoch: 5| Step: 5
Training loss: 1.2313071165052833
Validation loss: 2.587712330944205

Epoch: 5| Step: 6
Training loss: 1.093799807913061
Validation loss: 2.5918288335528277

Epoch: 5| Step: 7
Training loss: 1.5910005976629664
Validation loss: 2.570411564271607

Epoch: 5| Step: 8
Training loss: 1.145004903541293
Validation loss: 2.6617889398028085

Epoch: 5| Step: 9
Training loss: 0.7868401608924028
Validation loss: 2.5929862376289323

Epoch: 5| Step: 10
Training loss: 0.954001695761383
Validation loss: 2.604224701552635

Epoch: 5| Step: 11
Training loss: 0.4494325543660539
Validation loss: 2.645421722013933

Epoch: 172| Step: 0
Training loss: 1.0831222817661452
Validation loss: 2.611909644183225

Epoch: 5| Step: 1
Training loss: 1.384516296753694
Validation loss: 2.6243622701514373

Epoch: 5| Step: 2
Training loss: 1.0588737764933496
Validation loss: 2.646077054105003

Epoch: 5| Step: 3
Training loss: 0.8075278070108571
Validation loss: 2.5646071125098433

Epoch: 5| Step: 4
Training loss: 0.9375380826208826
Validation loss: 2.632571821597575

Epoch: 5| Step: 5
Training loss: 1.4058792049263333
Validation loss: 2.579129160288387

Epoch: 5| Step: 6
Training loss: 1.1920208455765622
Validation loss: 2.577662027577642

Epoch: 5| Step: 7
Training loss: 1.2010250839231145
Validation loss: 2.6219696082413195

Epoch: 5| Step: 8
Training loss: 1.0338312269815917
Validation loss: 2.629222969826653

Epoch: 5| Step: 9
Training loss: 0.9938016362240304
Validation loss: 2.516126555048696

Epoch: 5| Step: 10
Training loss: 1.2191905179214457
Validation loss: 2.513080471036134

Epoch: 5| Step: 11
Training loss: 1.2273568660780712
Validation loss: 2.58091250684838

Epoch: 173| Step: 0
Training loss: 0.9726205535834102
Validation loss: 2.5655328899023164

Epoch: 5| Step: 1
Training loss: 1.2020926071329352
Validation loss: 2.557906453079667

Epoch: 5| Step: 2
Training loss: 1.116837453355141
Validation loss: 2.605284703897127

Epoch: 5| Step: 3
Training loss: 1.2129901838982542
Validation loss: 2.6136880756591205

Epoch: 5| Step: 4
Training loss: 1.1159554470288757
Validation loss: 2.6072600963376438

Epoch: 5| Step: 5
Training loss: 1.3824831467992953
Validation loss: 2.6059019309142823

Epoch: 5| Step: 6
Training loss: 1.4971255735784972
Validation loss: 2.6247725558519424

Epoch: 5| Step: 7
Training loss: 0.9448269629623423
Validation loss: 2.662529609706564

Epoch: 5| Step: 8
Training loss: 1.1093998221185961
Validation loss: 2.6379212055931474

Epoch: 5| Step: 9
Training loss: 0.866569023561736
Validation loss: 2.602151935692148

Epoch: 5| Step: 10
Training loss: 1.1781004278317069
Validation loss: 2.655951157757057

Epoch: 5| Step: 11
Training loss: 0.4473746887231529
Validation loss: 2.6078307518187955

Epoch: 174| Step: 0
Training loss: 1.0181656969717003
Validation loss: 2.5592067847983464

Epoch: 5| Step: 1
Training loss: 1.0850872306213708
Validation loss: 2.5498295771458968

Epoch: 5| Step: 2
Training loss: 0.8072797261657378
Validation loss: 2.5849823412209036

Epoch: 5| Step: 3
Training loss: 1.1834424617754984
Validation loss: 2.5850299691000838

Epoch: 5| Step: 4
Training loss: 0.7830946316809425
Validation loss: 2.5918554641015596

Epoch: 5| Step: 5
Training loss: 0.9271689207596036
Validation loss: 2.621308254934091

Epoch: 5| Step: 6
Training loss: 1.6392525154572688
Validation loss: 2.593795607445453

Epoch: 5| Step: 7
Training loss: 0.9192382799531731
Validation loss: 2.5733652007047843

Epoch: 5| Step: 8
Training loss: 0.9551180653714116
Validation loss: 2.527989292785548

Epoch: 5| Step: 9
Training loss: 1.049042919477329
Validation loss: 2.5959810615730663

Epoch: 5| Step: 10
Training loss: 1.1345770411621035
Validation loss: 2.6023470905014916

Epoch: 5| Step: 11
Training loss: 2.3103173755422484
Validation loss: 2.49977867617028

Epoch: 175| Step: 0
Training loss: 0.9594407869826522
Validation loss: 2.5877600448581

Epoch: 5| Step: 1
Training loss: 0.9273382043712854
Validation loss: 2.5394473444449357

Epoch: 5| Step: 2
Training loss: 1.2636464041216824
Validation loss: 2.542582768271762

Epoch: 5| Step: 3
Training loss: 0.9182886743042564
Validation loss: 2.524670416815922

Epoch: 5| Step: 4
Training loss: 1.5993621597877732
Validation loss: 2.568974748774059

Epoch: 5| Step: 5
Training loss: 1.1224925389710956
Validation loss: 2.5802219070695607

Epoch: 5| Step: 6
Training loss: 1.117028178345404
Validation loss: 2.6250244434671846

Epoch: 5| Step: 7
Training loss: 1.414246773699755
Validation loss: 2.558014514381593

Epoch: 5| Step: 8
Training loss: 0.9478000038095455
Validation loss: 2.6286107351127765

Epoch: 5| Step: 9
Training loss: 0.9914974606568506
Validation loss: 2.5291989654875144

Epoch: 5| Step: 10
Training loss: 1.1135907730013503
Validation loss: 2.5353989291504475

Epoch: 5| Step: 11
Training loss: 1.4408332492143656
Validation loss: 2.5387318850725116

Epoch: 176| Step: 0
Training loss: 0.9514342147969899
Validation loss: 2.564737386025038

Epoch: 5| Step: 1
Training loss: 1.7017601914193818
Validation loss: 2.5405365015485972

Epoch: 5| Step: 2
Training loss: 0.8057476208444873
Validation loss: 2.6032747852207083

Epoch: 5| Step: 3
Training loss: 0.8774391985203688
Validation loss: 2.587330714660449

Epoch: 5| Step: 4
Training loss: 1.5021637569207298
Validation loss: 2.571537892932407

Epoch: 5| Step: 5
Training loss: 1.149330674146982
Validation loss: 2.5954395329702167

Epoch: 5| Step: 6
Training loss: 1.0891185795316627
Validation loss: 2.6268608067586134

Epoch: 5| Step: 7
Training loss: 1.0718465795725134
Validation loss: 2.5592194313896015

Epoch: 5| Step: 8
Training loss: 1.0180577412700798
Validation loss: 2.597556312569881

Epoch: 5| Step: 9
Training loss: 1.0955337692724922
Validation loss: 2.581168691941699

Epoch: 5| Step: 10
Training loss: 0.5255648526172966
Validation loss: 2.6333166445332057

Epoch: 5| Step: 11
Training loss: 1.6553039007843926
Validation loss: 2.5808546835782282

Epoch: 177| Step: 0
Training loss: 1.164965234737096
Validation loss: 2.5653590848607775

Epoch: 5| Step: 1
Training loss: 0.8464541723393337
Validation loss: 2.558392139674309

Epoch: 5| Step: 2
Training loss: 1.3129545060619592
Validation loss: 2.582192031694486

Epoch: 5| Step: 3
Training loss: 0.9540029140923736
Validation loss: 2.560056742788079

Epoch: 5| Step: 4
Training loss: 0.91794027730735
Validation loss: 2.5718586647315256

Epoch: 5| Step: 5
Training loss: 0.7313679754832303
Validation loss: 2.564028834358862

Epoch: 5| Step: 6
Training loss: 0.6055747646917007
Validation loss: 2.5474808407263634

Epoch: 5| Step: 7
Training loss: 1.3515100193308538
Validation loss: 2.671357154856916

Epoch: 5| Step: 8
Training loss: 0.9860228717677595
Validation loss: 2.543100624161402

Epoch: 5| Step: 9
Training loss: 1.5999186197088782
Validation loss: 2.6027675087048907

Epoch: 5| Step: 10
Training loss: 0.8105752227605946
Validation loss: 2.52662149178407

Epoch: 5| Step: 11
Training loss: 1.4421352620857035
Validation loss: 2.615072437654334

Epoch: 178| Step: 0
Training loss: 0.8905027539865531
Validation loss: 2.664113097395561

Epoch: 5| Step: 1
Training loss: 0.9310815441178474
Validation loss: 2.6149327524654598

Epoch: 5| Step: 2
Training loss: 1.0137079780044151
Validation loss: 2.6179206732169256

Epoch: 5| Step: 3
Training loss: 1.7380962144758116
Validation loss: 2.570953084474099

Epoch: 5| Step: 4
Training loss: 1.3193648509507583
Validation loss: 2.569671562541577

Epoch: 5| Step: 5
Training loss: 0.7834635465694962
Validation loss: 2.633448764427921

Epoch: 5| Step: 6
Training loss: 0.7044395450375869
Validation loss: 2.585022498419649

Epoch: 5| Step: 7
Training loss: 1.112263532217117
Validation loss: 2.630519256847118

Epoch: 5| Step: 8
Training loss: 0.8427829145161678
Validation loss: 2.638101975051981

Epoch: 5| Step: 9
Training loss: 1.1753128487490863
Validation loss: 2.6142518389366054

Epoch: 5| Step: 10
Training loss: 1.1560912152110592
Validation loss: 2.5842432693495154

Epoch: 5| Step: 11
Training loss: 0.2047691833786549
Validation loss: 2.575612159449533

Epoch: 179| Step: 0
Training loss: 0.6623913099991638
Validation loss: 2.551229890214237

Epoch: 5| Step: 1
Training loss: 0.9803516272390448
Validation loss: 2.604731879250031

Epoch: 5| Step: 2
Training loss: 1.4424482678106896
Validation loss: 2.5573670336668566

Epoch: 5| Step: 3
Training loss: 0.7191987502661127
Validation loss: 2.5433014721851674

Epoch: 5| Step: 4
Training loss: 1.032545143415196
Validation loss: 2.5087028222304

Epoch: 5| Step: 5
Training loss: 1.5432409891359535
Validation loss: 2.618213213438249

Epoch: 5| Step: 6
Training loss: 0.730599661943288
Validation loss: 2.551004821575647

Epoch: 5| Step: 7
Training loss: 1.0293789854360484
Validation loss: 2.5548032643009493

Epoch: 5| Step: 8
Training loss: 1.211980063264999
Validation loss: 2.6019605803620305

Epoch: 5| Step: 9
Training loss: 1.0577989247745583
Validation loss: 2.6491939773383786

Epoch: 5| Step: 10
Training loss: 1.190651476307848
Validation loss: 2.610142220036299

Epoch: 5| Step: 11
Training loss: 0.8703758463243904
Validation loss: 2.652400484821956

Epoch: 180| Step: 0
Training loss: 1.1192854809176114
Validation loss: 2.590311716798828

Epoch: 5| Step: 1
Training loss: 0.9692560535406185
Validation loss: 2.58327603404785

Epoch: 5| Step: 2
Training loss: 1.0049652569966714
Validation loss: 2.6585001073041723

Epoch: 5| Step: 3
Training loss: 0.9396115365768313
Validation loss: 2.5649944217396907

Epoch: 5| Step: 4
Training loss: 1.454492725153486
Validation loss: 2.564764956331941

Epoch: 5| Step: 5
Training loss: 0.9701617936258414
Validation loss: 2.623738254334849

Epoch: 5| Step: 6
Training loss: 1.2626930938960836
Validation loss: 2.6427799400599365

Epoch: 5| Step: 7
Training loss: 1.232419360078159
Validation loss: 2.6153832930466963

Epoch: 5| Step: 8
Training loss: 0.820727942489587
Validation loss: 2.6626760393249786

Epoch: 5| Step: 9
Training loss: 0.5667746036710047
Validation loss: 2.60174013510819

Epoch: 5| Step: 10
Training loss: 1.0333981537228218
Validation loss: 2.5607166675301425

Epoch: 5| Step: 11
Training loss: 0.2857238137836283
Validation loss: 2.5659300712205666

Epoch: 181| Step: 0
Training loss: 1.0633448439506217
Validation loss: 2.611071204721482

Epoch: 5| Step: 1
Training loss: 1.5605277775251198
Validation loss: 2.6355636515483196

Epoch: 5| Step: 2
Training loss: 1.0366085013991708
Validation loss: 2.6056286154167045

Epoch: 5| Step: 3
Training loss: 1.127333181943682
Validation loss: 2.5986126126365963

Epoch: 5| Step: 4
Training loss: 1.1123187271049315
Validation loss: 2.633152853891401

Epoch: 5| Step: 5
Training loss: 0.8722362125561127
Validation loss: 2.550066642887699

Epoch: 5| Step: 6
Training loss: 0.9038773092715983
Validation loss: 2.5628832825063887

Epoch: 5| Step: 7
Training loss: 1.5215330299756107
Validation loss: 2.5742239597482017

Epoch: 5| Step: 8
Training loss: 0.6985174103494229
Validation loss: 2.618123184258718

Epoch: 5| Step: 9
Training loss: 0.8893153281979539
Validation loss: 2.58529790015832

Epoch: 5| Step: 10
Training loss: 0.917000929980706
Validation loss: 2.550929600216891

Epoch: 5| Step: 11
Training loss: 0.9371301557264992
Validation loss: 2.6389837450134204

Epoch: 182| Step: 0
Training loss: 0.9003775506714972
Validation loss: 2.6529514476145173

Epoch: 5| Step: 1
Training loss: 0.778882215123314
Validation loss: 2.580394749509585

Epoch: 5| Step: 2
Training loss: 1.5287503451006197
Validation loss: 2.6092555405155675

Epoch: 5| Step: 3
Training loss: 1.0536375683120744
Validation loss: 2.5838464655444526

Epoch: 5| Step: 4
Training loss: 1.2553092736565266
Validation loss: 2.602857910626045

Epoch: 5| Step: 5
Training loss: 0.9903855067385138
Validation loss: 2.5279086865656026

Epoch: 5| Step: 6
Training loss: 0.7679368362703309
Validation loss: 2.6141957278141663

Epoch: 5| Step: 7
Training loss: 1.124490092537921
Validation loss: 2.586566729405216

Epoch: 5| Step: 8
Training loss: 1.2732805026580343
Validation loss: 2.6672799490497687

Epoch: 5| Step: 9
Training loss: 0.7103091806517955
Validation loss: 2.6565637122756027

Epoch: 5| Step: 10
Training loss: 1.0997011407264703
Validation loss: 2.6054798604489067

Epoch: 5| Step: 11
Training loss: 0.8353004523770307
Validation loss: 2.6282146464271507

Epoch: 183| Step: 0
Training loss: 0.9676407339070784
Validation loss: 2.6360531906490663

Epoch: 5| Step: 1
Training loss: 1.0474332772720725
Validation loss: 2.6570805634870047

Epoch: 5| Step: 2
Training loss: 0.8127303897224952
Validation loss: 2.6183421913723977

Epoch: 5| Step: 3
Training loss: 1.0491218368753477
Validation loss: 2.6166296445045756

Epoch: 5| Step: 4
Training loss: 1.0392512099915363
Validation loss: 2.6304403574111497

Epoch: 5| Step: 5
Training loss: 1.5339917918337536
Validation loss: 2.609268601279387

Epoch: 5| Step: 6
Training loss: 1.0716879144780014
Validation loss: 2.576103909444058

Epoch: 5| Step: 7
Training loss: 0.7172917209270308
Validation loss: 2.555191497783558

Epoch: 5| Step: 8
Training loss: 0.9267981051176619
Validation loss: 2.5688277906471364

Epoch: 5| Step: 9
Training loss: 1.1945077019335781
Validation loss: 2.619789640502955

Epoch: 5| Step: 10
Training loss: 1.0059448798419386
Validation loss: 2.562046483853747

Epoch: 5| Step: 11
Training loss: 1.0586554590235722
Validation loss: 2.60063970655607

Epoch: 184| Step: 0
Training loss: 1.5967541971815953
Validation loss: 2.5997654738779

Epoch: 5| Step: 1
Training loss: 1.391060321692865
Validation loss: 2.6824107480081065

Epoch: 5| Step: 2
Training loss: 0.8470567261932469
Validation loss: 2.5632347394929913

Epoch: 5| Step: 3
Training loss: 0.7668364146877574
Validation loss: 2.557649413890544

Epoch: 5| Step: 4
Training loss: 0.893510994598593
Validation loss: 2.5960779275870234

Epoch: 5| Step: 5
Training loss: 0.8078219651160233
Validation loss: 2.558567840988561

Epoch: 5| Step: 6
Training loss: 1.14131525135163
Validation loss: 2.4717850317900827

Epoch: 5| Step: 7
Training loss: 1.0618095398428888
Validation loss: 2.5902890474166913

Epoch: 5| Step: 8
Training loss: 1.1856869861444224
Validation loss: 2.5401559323971603

Epoch: 5| Step: 9
Training loss: 0.9393580144690463
Validation loss: 2.6198858727011527

Epoch: 5| Step: 10
Training loss: 0.6042811652461285
Validation loss: 2.6305288528692548

Epoch: 5| Step: 11
Training loss: 0.25078587394087953
Validation loss: 2.56550382156821

Epoch: 185| Step: 0
Training loss: 1.0980327679933315
Validation loss: 2.6100939561599223

Epoch: 5| Step: 1
Training loss: 1.499869817806676
Validation loss: 2.7032283880788706

Epoch: 5| Step: 2
Training loss: 1.19703390794625
Validation loss: 2.647888899466737

Epoch: 5| Step: 3
Training loss: 0.9275731318039095
Validation loss: 2.593994374234058

Epoch: 5| Step: 4
Training loss: 1.1480735669273157
Validation loss: 2.5881534774013177

Epoch: 5| Step: 5
Training loss: 1.1086542178888936
Validation loss: 2.5403999855368102

Epoch: 5| Step: 6
Training loss: 0.8917533686782525
Validation loss: 2.5845236356122734

Epoch: 5| Step: 7
Training loss: 0.9918832387503909
Validation loss: 2.640713827531452

Epoch: 5| Step: 8
Training loss: 0.7520481198239859
Validation loss: 2.626033980466637

Epoch: 5| Step: 9
Training loss: 1.037429788810513
Validation loss: 2.6000835369365514

Epoch: 5| Step: 10
Training loss: 1.0358166585323285
Validation loss: 2.5957604357207678

Epoch: 5| Step: 11
Training loss: 0.6827022079326464
Validation loss: 2.713585135074519

Epoch: 186| Step: 0
Training loss: 1.0146328701848075
Validation loss: 2.7344528695780634

Epoch: 5| Step: 1
Training loss: 1.1164326818819545
Validation loss: 2.735454811145948

Epoch: 5| Step: 2
Training loss: 1.2414563504402896
Validation loss: 2.5924259889302146

Epoch: 5| Step: 3
Training loss: 0.7895960373137463
Validation loss: 2.5777525122156137

Epoch: 5| Step: 4
Training loss: 1.8555949921075172
Validation loss: 2.6615067394853744

Epoch: 5| Step: 5
Training loss: 0.8858856455110938
Validation loss: 2.6017161105363655

Epoch: 5| Step: 6
Training loss: 0.747710787419327
Validation loss: 2.5565813959661616

Epoch: 5| Step: 7
Training loss: 0.9270135588945442
Validation loss: 2.5916827113696477

Epoch: 5| Step: 8
Training loss: 0.990628617337238
Validation loss: 2.6008294020572844

Epoch: 5| Step: 9
Training loss: 1.2804502456752391
Validation loss: 2.590229241635444

Epoch: 5| Step: 10
Training loss: 1.0709666459831846
Validation loss: 2.575778968816967

Epoch: 5| Step: 11
Training loss: 0.4913376783066061
Validation loss: 2.6400783319062757

Epoch: 187| Step: 0
Training loss: 1.2332491992056223
Validation loss: 2.725780666442733

Epoch: 5| Step: 1
Training loss: 1.3322176537176014
Validation loss: 2.763033464470604

Epoch: 5| Step: 2
Training loss: 0.7958207730272422
Validation loss: 2.6498131006837915

Epoch: 5| Step: 3
Training loss: 0.7747217940310364
Validation loss: 2.599177522660072

Epoch: 5| Step: 4
Training loss: 1.471952153672189
Validation loss: 2.528662772208672

Epoch: 5| Step: 5
Training loss: 1.1803777835113853
Validation loss: 2.6093145428200084

Epoch: 5| Step: 6
Training loss: 0.8602122649785631
Validation loss: 2.6152244037782806

Epoch: 5| Step: 7
Training loss: 1.2150877189367846
Validation loss: 2.586353717971741

Epoch: 5| Step: 8
Training loss: 1.418461485443738
Validation loss: 2.5521820373651076

Epoch: 5| Step: 9
Training loss: 0.9612545947893946
Validation loss: 2.554358158794975

Epoch: 5| Step: 10
Training loss: 0.684374728268086
Validation loss: 2.614295323658159

Epoch: 5| Step: 11
Training loss: 1.4419390926328313
Validation loss: 2.579988257137455

Epoch: 188| Step: 0
Training loss: 0.9992168757560517
Validation loss: 2.6281521505857723

Epoch: 5| Step: 1
Training loss: 1.0406648141387085
Validation loss: 2.628632684751222

Epoch: 5| Step: 2
Training loss: 1.0690706943085295
Validation loss: 2.6042321076117982

Epoch: 5| Step: 3
Training loss: 0.8519150940156253
Validation loss: 2.5820926999442424

Epoch: 5| Step: 4
Training loss: 1.1250710464931926
Validation loss: 2.6357910181878714

Epoch: 5| Step: 5
Training loss: 1.691057552488456
Validation loss: 2.6290166604000365

Epoch: 5| Step: 6
Training loss: 0.8345722208284699
Validation loss: 2.5826525534605427

Epoch: 5| Step: 7
Training loss: 0.9902919173215801
Validation loss: 2.5749002923457063

Epoch: 5| Step: 8
Training loss: 0.7359369994726727
Validation loss: 2.576317914863163

Epoch: 5| Step: 9
Training loss: 0.8725025092802062
Validation loss: 2.598193927083369

Epoch: 5| Step: 10
Training loss: 1.0243836899319554
Validation loss: 2.614786369424337

Epoch: 5| Step: 11
Training loss: 0.9027477862601128
Validation loss: 2.6311352534882912

Epoch: 189| Step: 0
Training loss: 1.1276750549634376
Validation loss: 2.6301278067369975

Epoch: 5| Step: 1
Training loss: 1.2509271044636305
Validation loss: 2.6319891928059107

Epoch: 5| Step: 2
Training loss: 1.1437194340691657
Validation loss: 2.6074754345139923

Epoch: 5| Step: 3
Training loss: 1.450836841214559
Validation loss: 2.629667514808948

Epoch: 5| Step: 4
Training loss: 0.8265677871967669
Validation loss: 2.6284621942049733

Epoch: 5| Step: 5
Training loss: 1.0848152344362565
Validation loss: 2.539126539156358

Epoch: 5| Step: 6
Training loss: 0.8212133638057332
Validation loss: 2.627420331398649

Epoch: 5| Step: 7
Training loss: 0.9095916306493944
Validation loss: 2.556961653341438

Epoch: 5| Step: 8
Training loss: 0.6070174069587475
Validation loss: 2.649119969060702

Epoch: 5| Step: 9
Training loss: 1.043311130746505
Validation loss: 2.5999267445539136

Epoch: 5| Step: 10
Training loss: 0.7777424082396249
Validation loss: 2.573739960002291

Epoch: 5| Step: 11
Training loss: 1.3068579705404486
Validation loss: 2.6323001412085545

Epoch: 190| Step: 0
Training loss: 1.1440135839696166
Validation loss: 2.6067179288014715

Epoch: 5| Step: 1
Training loss: 0.9939352546613281
Validation loss: 2.6522159798455935

Epoch: 5| Step: 2
Training loss: 1.0540074169107891
Validation loss: 2.7038298663593063

Epoch: 5| Step: 3
Training loss: 1.0969108684359212
Validation loss: 2.5911767405035655

Epoch: 5| Step: 4
Training loss: 0.8883633927048189
Validation loss: 2.60952258692028

Epoch: 5| Step: 5
Training loss: 0.977957103566651
Validation loss: 2.5468373871192633

Epoch: 5| Step: 6
Training loss: 0.6500339159920243
Validation loss: 2.63265487772594

Epoch: 5| Step: 7
Training loss: 0.8281075097882153
Validation loss: 2.581282991532521

Epoch: 5| Step: 8
Training loss: 1.5492473867042542
Validation loss: 2.654927511668435

Epoch: 5| Step: 9
Training loss: 1.2110845168914257
Validation loss: 2.6587030154214997

Epoch: 5| Step: 10
Training loss: 0.7798892568565137
Validation loss: 2.662622612680518

Epoch: 5| Step: 11
Training loss: 0.6318694257631828
Validation loss: 2.6689211503149615

Epoch: 191| Step: 0
Training loss: 1.0285566009576703
Validation loss: 2.6559816561519307

Epoch: 5| Step: 1
Training loss: 0.8111907240220643
Validation loss: 2.6423615495868265

Epoch: 5| Step: 2
Training loss: 0.7040141946922128
Validation loss: 2.587121732677382

Epoch: 5| Step: 3
Training loss: 0.9463713839442588
Validation loss: 2.6116974977630307

Epoch: 5| Step: 4
Training loss: 0.8906365778655693
Validation loss: 2.6230511962370264

Epoch: 5| Step: 5
Training loss: 0.7681488943457397
Validation loss: 2.669359984731158

Epoch: 5| Step: 6
Training loss: 0.8678816002220215
Validation loss: 2.6251574423667896

Epoch: 5| Step: 7
Training loss: 1.455682861829122
Validation loss: 2.5998786540324654

Epoch: 5| Step: 8
Training loss: 1.047593624510415
Validation loss: 2.5360746674451073

Epoch: 5| Step: 9
Training loss: 0.9763004409126366
Validation loss: 2.5491567075916635

Epoch: 5| Step: 10
Training loss: 1.0935277440546316
Validation loss: 2.558306103715737

Epoch: 5| Step: 11
Training loss: 1.47718152184807
Validation loss: 2.65209257109762

Epoch: 192| Step: 0
Training loss: 0.9482276043227224
Validation loss: 2.5604951389186894

Epoch: 5| Step: 1
Training loss: 1.2050866817621908
Validation loss: 2.5812260944531045

Epoch: 5| Step: 2
Training loss: 1.437632844840337
Validation loss: 2.5845254998012153

Epoch: 5| Step: 3
Training loss: 1.0383664431326731
Validation loss: 2.629717247821704

Epoch: 5| Step: 4
Training loss: 0.9976902453336921
Validation loss: 2.6612989927894404

Epoch: 5| Step: 5
Training loss: 1.2526143867355966
Validation loss: 2.5772136002050745

Epoch: 5| Step: 6
Training loss: 0.7376406276917579
Validation loss: 2.5777577186757235

Epoch: 5| Step: 7
Training loss: 0.7854537020854966
Validation loss: 2.640949071376495

Epoch: 5| Step: 8
Training loss: 0.643968509884505
Validation loss: 2.5857906818488723

Epoch: 5| Step: 9
Training loss: 0.8234678346088055
Validation loss: 2.6840001723490308

Epoch: 5| Step: 10
Training loss: 0.5867975915999157
Validation loss: 2.5926995505744492

Epoch: 5| Step: 11
Training loss: 1.0517828043144064
Validation loss: 2.704870527727426

Epoch: 193| Step: 0
Training loss: 1.031025428595287
Validation loss: 2.6617634175990914

Epoch: 5| Step: 1
Training loss: 1.036988389596714
Validation loss: 2.718445903389275

Epoch: 5| Step: 2
Training loss: 0.7682383951613453
Validation loss: 2.5905858199865297

Epoch: 5| Step: 3
Training loss: 0.8904113513274379
Validation loss: 2.6492881234093932

Epoch: 5| Step: 4
Training loss: 1.0510367043979478
Validation loss: 2.6327987730911664

Epoch: 5| Step: 5
Training loss: 0.9614127619817449
Validation loss: 2.566671213593935

Epoch: 5| Step: 6
Training loss: 1.345355826465507
Validation loss: 2.594649595498095

Epoch: 5| Step: 7
Training loss: 0.7386004852704443
Validation loss: 2.5845268335603135

Epoch: 5| Step: 8
Training loss: 1.0060834024071672
Validation loss: 2.5868463906998502

Epoch: 5| Step: 9
Training loss: 1.1528242758038054
Validation loss: 2.546686056262578

Epoch: 5| Step: 10
Training loss: 0.7962622437067255
Validation loss: 2.615684301538897

Epoch: 5| Step: 11
Training loss: 0.5132984501063009
Validation loss: 2.6439641741761575

Epoch: 194| Step: 0
Training loss: 0.961292325391405
Validation loss: 2.5737737792999154

Epoch: 5| Step: 1
Training loss: 0.5169591117052187
Validation loss: 2.658758811224676

Epoch: 5| Step: 2
Training loss: 0.9766528278537799
Validation loss: 2.676469585307652

Epoch: 5| Step: 3
Training loss: 1.0778334956061109
Validation loss: 2.579766779558805

Epoch: 5| Step: 4
Training loss: 1.0695646694582428
Validation loss: 2.5941231432383467

Epoch: 5| Step: 5
Training loss: 1.0827829111963907
Validation loss: 2.608022045922371

Epoch: 5| Step: 6
Training loss: 1.1801592660363112
Validation loss: 2.6494183744776736

Epoch: 5| Step: 7
Training loss: 0.9742671388602071
Validation loss: 2.6599861236260516

Epoch: 5| Step: 8
Training loss: 0.823027052095209
Validation loss: 2.6909492078774586

Epoch: 5| Step: 9
Training loss: 1.4081500462701655
Validation loss: 2.6197312059244946

Epoch: 5| Step: 10
Training loss: 0.6934769221854836
Validation loss: 2.6474756915615796

Epoch: 5| Step: 11
Training loss: 0.8768469527443129
Validation loss: 2.6447281118546684

Epoch: 195| Step: 0
Training loss: 0.9541548496386361
Validation loss: 2.6380689164072906

Epoch: 5| Step: 1
Training loss: 1.0548106933983323
Validation loss: 2.5992573118277913

Epoch: 5| Step: 2
Training loss: 0.815421683449209
Validation loss: 2.5795501777178944

Epoch: 5| Step: 3
Training loss: 1.0943185146183274
Validation loss: 2.6810945611045427

Epoch: 5| Step: 4
Training loss: 0.6300745236127727
Validation loss: 2.6646430798996112

Epoch: 5| Step: 5
Training loss: 1.4612989335559203
Validation loss: 2.660119997992135

Epoch: 5| Step: 6
Training loss: 0.8004689421719602
Validation loss: 2.71476378105814

Epoch: 5| Step: 7
Training loss: 1.0998559814154518
Validation loss: 2.660519194712176

Epoch: 5| Step: 8
Training loss: 0.8544387887890998
Validation loss: 2.6259972914462417

Epoch: 5| Step: 9
Training loss: 0.8055790156934733
Validation loss: 2.5269651488059703

Epoch: 5| Step: 10
Training loss: 0.8296507329750537
Validation loss: 2.6573856076710496

Epoch: 5| Step: 11
Training loss: 1.0203248658533526
Validation loss: 2.6637295191380392

Epoch: 196| Step: 0
Training loss: 1.0641829681541952
Validation loss: 2.5842002457466084

Epoch: 5| Step: 1
Training loss: 0.8583978125664321
Validation loss: 2.5560982490458137

Epoch: 5| Step: 2
Training loss: 1.6130594096396758
Validation loss: 2.6033845350034994

Epoch: 5| Step: 3
Training loss: 0.9158826784395414
Validation loss: 2.6803869774758105

Epoch: 5| Step: 4
Training loss: 0.8927066635300203
Validation loss: 2.723047017715969

Epoch: 5| Step: 5
Training loss: 0.7449206971837831
Validation loss: 2.7442976140812516

Epoch: 5| Step: 6
Training loss: 1.0824190952646664
Validation loss: 2.747925185179985

Epoch: 5| Step: 7
Training loss: 0.6383658793081505
Validation loss: 2.6711915017534054

Epoch: 5| Step: 8
Training loss: 0.8676237778758763
Validation loss: 2.6425459324806453

Epoch: 5| Step: 9
Training loss: 1.1375714017654825
Validation loss: 2.638706721883537

Epoch: 5| Step: 10
Training loss: 1.0538558506773865
Validation loss: 2.667638904443121

Epoch: 5| Step: 11
Training loss: 1.1167740490272913
Validation loss: 2.6105703482684905

Epoch: 197| Step: 0
Training loss: 0.8058358673942142
Validation loss: 2.6356457559179733

Epoch: 5| Step: 1
Training loss: 0.7428893134073153
Validation loss: 2.649614753250902

Epoch: 5| Step: 2
Training loss: 1.0930503787465176
Validation loss: 2.67534513237572

Epoch: 5| Step: 3
Training loss: 1.2398658986027256
Validation loss: 2.6799154879727958

Epoch: 5| Step: 4
Training loss: 0.9584229918017106
Validation loss: 2.633424561364913

Epoch: 5| Step: 5
Training loss: 0.8790175642942865
Validation loss: 2.623465661054322

Epoch: 5| Step: 6
Training loss: 0.6436602631771753
Validation loss: 2.6012674590127816

Epoch: 5| Step: 7
Training loss: 1.010462330576141
Validation loss: 2.5331384851056122

Epoch: 5| Step: 8
Training loss: 0.9616331048383658
Validation loss: 2.5561872584968235

Epoch: 5| Step: 9
Training loss: 0.8025840005851725
Validation loss: 2.57017571221538

Epoch: 5| Step: 10
Training loss: 1.1902094598959896
Validation loss: 2.611751346154601

Epoch: 5| Step: 11
Training loss: 0.6037026273019088
Validation loss: 2.594153874524326

Epoch: 198| Step: 0
Training loss: 0.7028002518824396
Validation loss: 2.6045805462330187

Epoch: 5| Step: 1
Training loss: 0.9247153217839588
Validation loss: 2.610907704099422

Epoch: 5| Step: 2
Training loss: 0.7750348637030073
Validation loss: 2.6098994719729194

Epoch: 5| Step: 3
Training loss: 0.8429607656134338
Validation loss: 2.542691267884301

Epoch: 5| Step: 4
Training loss: 1.524796803804512
Validation loss: 2.5822921963488943

Epoch: 5| Step: 5
Training loss: 0.7906170629773912
Validation loss: 2.61738669173577

Epoch: 5| Step: 6
Training loss: 1.340280578403918
Validation loss: 2.5582708412225355

Epoch: 5| Step: 7
Training loss: 0.808598836247024
Validation loss: 2.614392989222361

Epoch: 5| Step: 8
Training loss: 0.6319986690993118
Validation loss: 2.5983785289588064

Epoch: 5| Step: 9
Training loss: 0.8500050642760262
Validation loss: 2.6231864765177932

Epoch: 5| Step: 10
Training loss: 1.062176486859152
Validation loss: 2.660598098275973

Epoch: 5| Step: 11
Training loss: 0.6205338167355606
Validation loss: 2.650542132836188

Epoch: 199| Step: 0
Training loss: 0.9950547128519661
Validation loss: 2.633248603389211

Epoch: 5| Step: 1
Training loss: 0.9721322237472086
Validation loss: 2.5935276809459515

Epoch: 5| Step: 2
Training loss: 1.1417709238011555
Validation loss: 2.5751183828282413

Epoch: 5| Step: 3
Training loss: 0.7345000627230727
Validation loss: 2.553362935596393

Epoch: 5| Step: 4
Training loss: 0.8578197624857997
Validation loss: 2.6285174395458157

Epoch: 5| Step: 5
Training loss: 1.2009879118686628
Validation loss: 2.59857410095553

Epoch: 5| Step: 6
Training loss: 0.6448610791224998
Validation loss: 2.691249674915011

Epoch: 5| Step: 7
Training loss: 1.265009318230728
Validation loss: 2.6608634677100107

Epoch: 5| Step: 8
Training loss: 0.9578565503394217
Validation loss: 2.6414141218866756

Epoch: 5| Step: 9
Training loss: 0.809763481553181
Validation loss: 2.6521142964279933

Epoch: 5| Step: 10
Training loss: 0.9608694533159085
Validation loss: 2.6335149180804134

Epoch: 5| Step: 11
Training loss: 0.32940984261170125
Validation loss: 2.6392836653292617

Epoch: 200| Step: 0
Training loss: 0.7721953773482684
Validation loss: 2.6206801496070913

Epoch: 5| Step: 1
Training loss: 0.6384237198129036
Validation loss: 2.6289177224077545

Epoch: 5| Step: 2
Training loss: 0.5302159961478963
Validation loss: 2.5847596543029665

Epoch: 5| Step: 3
Training loss: 0.7710374527528921
Validation loss: 2.6001818891322195

Epoch: 5| Step: 4
Training loss: 1.179078153157006
Validation loss: 2.568231948379643

Epoch: 5| Step: 5
Training loss: 0.954249484758885
Validation loss: 2.529954763348566

Epoch: 5| Step: 6
Training loss: 0.6752702401639874
Validation loss: 2.612038773642244

Epoch: 5| Step: 7
Training loss: 0.5551734192864224
Validation loss: 2.5949077205567654

Epoch: 5| Step: 8
Training loss: 1.4476933844590485
Validation loss: 2.6060824474537365

Epoch: 5| Step: 9
Training loss: 1.2257218122203581
Validation loss: 2.5875120565038325

Epoch: 5| Step: 10
Training loss: 1.034929531389022
Validation loss: 2.6254666345096624

Epoch: 5| Step: 11
Training loss: 1.1487653614631805
Validation loss: 2.5465661468148943

Epoch: 201| Step: 0
Training loss: 0.7653636096914839
Validation loss: 2.612483147440555

Epoch: 5| Step: 1
Training loss: 0.7173805043603753
Validation loss: 2.5497668022536963

Epoch: 5| Step: 2
Training loss: 0.7894611295948293
Validation loss: 2.6090674723549894

Epoch: 5| Step: 3
Training loss: 0.92970170082338
Validation loss: 2.6147116646041932

Epoch: 5| Step: 4
Training loss: 0.9097330312758105
Validation loss: 2.5975680037497892

Epoch: 5| Step: 5
Training loss: 1.0542475029832352
Validation loss: 2.5857720451783552

Epoch: 5| Step: 6
Training loss: 1.0311906970919205
Validation loss: 2.685605616071592

Epoch: 5| Step: 7
Training loss: 1.4560873538369132
Validation loss: 2.645168193930106

Epoch: 5| Step: 8
Training loss: 1.0431118413370628
Validation loss: 2.7483339392470723

Epoch: 5| Step: 9
Training loss: 1.030691111001697
Validation loss: 2.687950776612598

Epoch: 5| Step: 10
Training loss: 0.7992805002172243
Validation loss: 2.653654955148539

Epoch: 5| Step: 11
Training loss: 0.6426882200221289
Validation loss: 2.637001708118511

Epoch: 202| Step: 0
Training loss: 0.9365079717383379
Validation loss: 2.5518936547357316

Epoch: 5| Step: 1
Training loss: 0.9654782946106022
Validation loss: 2.6034308169556213

Epoch: 5| Step: 2
Training loss: 0.9050181007155786
Validation loss: 2.7013683233864807

Epoch: 5| Step: 3
Training loss: 0.6781022450369274
Validation loss: 2.716473163156915

Epoch: 5| Step: 4
Training loss: 1.008027874311417
Validation loss: 2.570983254241268

Epoch: 5| Step: 5
Training loss: 0.9793109212628072
Validation loss: 2.6631228112527574

Epoch: 5| Step: 6
Training loss: 0.918460470757947
Validation loss: 2.6971687411826935

Epoch: 5| Step: 7
Training loss: 0.8493111975076889
Validation loss: 2.6164954375979246

Epoch: 5| Step: 8
Training loss: 0.8976944877906564
Validation loss: 2.620585275250836

Epoch: 5| Step: 9
Training loss: 0.594951367915205
Validation loss: 2.670732064095225

Epoch: 5| Step: 10
Training loss: 1.283342002657718
Validation loss: 2.521399561812139

Epoch: 5| Step: 11
Training loss: 0.5488100965260663
Validation loss: 2.695170456833754

Epoch: 203| Step: 0
Training loss: 0.7700640387967493
Validation loss: 2.643128036418502

Epoch: 5| Step: 1
Training loss: 0.8489708967780948
Validation loss: 2.5871437386491216

Epoch: 5| Step: 2
Training loss: 1.1529140806749296
Validation loss: 2.586873752255449

Epoch: 5| Step: 3
Training loss: 0.6659591069110695
Validation loss: 2.5790948989283278

Epoch: 5| Step: 4
Training loss: 1.44800807014872
Validation loss: 2.6160411354808284

Epoch: 5| Step: 5
Training loss: 0.8576497880772505
Validation loss: 2.5820643028032793

Epoch: 5| Step: 6
Training loss: 0.7794350714273665
Validation loss: 2.577935425695401

Epoch: 5| Step: 7
Training loss: 0.7089321653200182
Validation loss: 2.5970187100378017

Epoch: 5| Step: 8
Training loss: 0.948185676438681
Validation loss: 2.6007546515654965

Epoch: 5| Step: 9
Training loss: 1.0200790745807513
Validation loss: 2.654656104040072

Epoch: 5| Step: 10
Training loss: 0.7085988070844815
Validation loss: 2.587036855684301

Epoch: 5| Step: 11
Training loss: 1.209989016301769
Validation loss: 2.65383863762557

Epoch: 204| Step: 0
Training loss: 1.154282209945442
Validation loss: 2.5965626759471094

Epoch: 5| Step: 1
Training loss: 0.9061642968003735
Validation loss: 2.6699158399393244

Epoch: 5| Step: 2
Training loss: 0.8721687970399368
Validation loss: 2.6753786401363717

Epoch: 5| Step: 3
Training loss: 0.8319201686298475
Validation loss: 2.723642974064964

Epoch: 5| Step: 4
Training loss: 0.8958547537852373
Validation loss: 2.666352508089768

Epoch: 5| Step: 5
Training loss: 0.8229188476404833
Validation loss: 2.635204922358249

Epoch: 5| Step: 6
Training loss: 1.3258084008353952
Validation loss: 2.62429111990775

Epoch: 5| Step: 7
Training loss: 0.6275245937907945
Validation loss: 2.6439290377608735

Epoch: 5| Step: 8
Training loss: 0.6506700116142232
Validation loss: 2.6402028741456274

Epoch: 5| Step: 9
Training loss: 0.7449082947939921
Validation loss: 2.6690307968264264

Epoch: 5| Step: 10
Training loss: 0.9518746476351211
Validation loss: 2.6435946106993384

Epoch: 5| Step: 11
Training loss: 0.4320333084140187
Validation loss: 2.6400195449047814

Epoch: 205| Step: 0
Training loss: 0.8537641290079198
Validation loss: 2.6529875860135883

Epoch: 5| Step: 1
Training loss: 1.622030405820247
Validation loss: 2.7062943681775664

Epoch: 5| Step: 2
Training loss: 0.7178912630492441
Validation loss: 2.6623482395255684

Epoch: 5| Step: 3
Training loss: 0.8716363970045473
Validation loss: 2.7297433481688254

Epoch: 5| Step: 4
Training loss: 1.1298168166396187
Validation loss: 2.6618810617820197

Epoch: 5| Step: 5
Training loss: 0.5250347307615558
Validation loss: 2.68145011490012

Epoch: 5| Step: 6
Training loss: 0.8714355003642056
Validation loss: 2.6333585110700097

Epoch: 5| Step: 7
Training loss: 0.9050568585949359
Validation loss: 2.7052264892434987

Epoch: 5| Step: 8
Training loss: 0.9185905136464068
Validation loss: 2.61187365627201

Epoch: 5| Step: 9
Training loss: 0.7823002431698216
Validation loss: 2.6352870002078923

Epoch: 5| Step: 10
Training loss: 0.6812906541855507
Validation loss: 2.616045437911072

Epoch: 5| Step: 11
Training loss: 0.3270069556546411
Validation loss: 2.615862246091591

Epoch: 206| Step: 0
Training loss: 0.933672722066055
Validation loss: 2.6651172339918148

Epoch: 5| Step: 1
Training loss: 0.6506572096855906
Validation loss: 2.6877760671426003

Epoch: 5| Step: 2
Training loss: 1.0345139148010492
Validation loss: 2.7347610855010376

Epoch: 5| Step: 3
Training loss: 0.6518553315923311
Validation loss: 2.7225975895039487

Epoch: 5| Step: 4
Training loss: 1.1745214969199116
Validation loss: 2.7566915688914055

Epoch: 5| Step: 5
Training loss: 0.5851534875211203
Validation loss: 2.677581189144856

Epoch: 5| Step: 6
Training loss: 0.8274599679904213
Validation loss: 2.735524292058758

Epoch: 5| Step: 7
Training loss: 0.5847341260153914
Validation loss: 2.668396408634917

Epoch: 5| Step: 8
Training loss: 1.4633760550887724
Validation loss: 2.611910439091329

Epoch: 5| Step: 9
Training loss: 0.9080062160531245
Validation loss: 2.6219931630790585

Epoch: 5| Step: 10
Training loss: 0.7461845782052063
Validation loss: 2.6621627074599705

Epoch: 5| Step: 11
Training loss: 1.3777514152457289
Validation loss: 2.5997550726725307

Epoch: 207| Step: 0
Training loss: 1.3834155648084285
Validation loss: 2.628689126376933

Epoch: 5| Step: 1
Training loss: 0.7318444175422342
Validation loss: 2.6337114793446594

Epoch: 5| Step: 2
Training loss: 0.5837465650469663
Validation loss: 2.6144122578149216

Epoch: 5| Step: 3
Training loss: 0.756019358498107
Validation loss: 2.586858425979748

Epoch: 5| Step: 4
Training loss: 0.5825325771767081
Validation loss: 2.691150832179256

Epoch: 5| Step: 5
Training loss: 0.7578816333186635
Validation loss: 2.721324355891486

Epoch: 5| Step: 6
Training loss: 0.8172590191618553
Validation loss: 2.5622933195858213

Epoch: 5| Step: 7
Training loss: 0.9030723767640417
Validation loss: 2.776380050724201

Epoch: 5| Step: 8
Training loss: 0.9182021473360306
Validation loss: 2.669487189231743

Epoch: 5| Step: 9
Training loss: 0.8293901891402699
Validation loss: 2.635808019768773

Epoch: 5| Step: 10
Training loss: 1.0787187130171398
Validation loss: 2.665423391513671

Epoch: 5| Step: 11
Training loss: 0.7621718013033517
Validation loss: 2.662329127570077

Epoch: 208| Step: 0
Training loss: 0.8775456726925602
Validation loss: 2.6053863809768285

Epoch: 5| Step: 1
Training loss: 0.7567593049660976
Validation loss: 2.5891491978459857

Epoch: 5| Step: 2
Training loss: 0.7158711872002624
Validation loss: 2.6022705435822577

Epoch: 5| Step: 3
Training loss: 0.7519883977370367
Validation loss: 2.605570008132298

Epoch: 5| Step: 4
Training loss: 0.7010289421079263
Validation loss: 2.6619156440216836

Epoch: 5| Step: 5
Training loss: 0.9530302532193459
Validation loss: 2.638640256024486

Epoch: 5| Step: 6
Training loss: 0.8856229354845103
Validation loss: 2.674039662819278

Epoch: 5| Step: 7
Training loss: 1.2646649805113699
Validation loss: 2.6398564749594753

Epoch: 5| Step: 8
Training loss: 0.8289857026329407
Validation loss: 2.627970536055214

Epoch: 5| Step: 9
Training loss: 1.0182759826252321
Validation loss: 2.6506972841814984

Epoch: 5| Step: 10
Training loss: 1.0960048321352893
Validation loss: 2.6819930320836978

Epoch: 5| Step: 11
Training loss: 1.367134267588121
Validation loss: 2.6287496235759984

Epoch: 209| Step: 0
Training loss: 0.7575888549510593
Validation loss: 2.5846231775770745

Epoch: 5| Step: 1
Training loss: 0.7228274168461827
Validation loss: 2.5944830191889663

Epoch: 5| Step: 2
Training loss: 0.9288360479342456
Validation loss: 2.5629385092266603

Epoch: 5| Step: 3
Training loss: 1.0024290386018608
Validation loss: 2.6207128590082576

Epoch: 5| Step: 4
Training loss: 1.1843993212132697
Validation loss: 2.6037125471256695

Epoch: 5| Step: 5
Training loss: 0.720090404040352
Validation loss: 2.5997849311275694

Epoch: 5| Step: 6
Training loss: 0.6966579792136597
Validation loss: 2.5807010072980385

Epoch: 5| Step: 7
Training loss: 1.0532610253572574
Validation loss: 2.709787630605245

Epoch: 5| Step: 8
Training loss: 1.1406153848321188
Validation loss: 2.6760855620038395

Epoch: 5| Step: 9
Training loss: 0.8238464888818119
Validation loss: 2.629774349906806

Epoch: 5| Step: 10
Training loss: 0.7073138604780952
Validation loss: 2.6355297619724047

Epoch: 5| Step: 11
Training loss: 0.6727526720788483
Validation loss: 2.682009800048179

Epoch: 210| Step: 0
Training loss: 0.6221384104010906
Validation loss: 2.612751067340105

Epoch: 5| Step: 1
Training loss: 0.7151991997511652
Validation loss: 2.619645146215607

Epoch: 5| Step: 2
Training loss: 0.7287029608435881
Validation loss: 2.63249625731924

Epoch: 5| Step: 3
Training loss: 0.6858975852875417
Validation loss: 2.6728555913673433

Epoch: 5| Step: 4
Training loss: 1.3199220339551176
Validation loss: 2.6278585128756906

Epoch: 5| Step: 5
Training loss: 0.7315112747580272
Validation loss: 2.670452633509022

Epoch: 5| Step: 6
Training loss: 1.1169752439523524
Validation loss: 2.6220980111760057

Epoch: 5| Step: 7
Training loss: 0.9941954831799075
Validation loss: 2.6551489923031113

Epoch: 5| Step: 8
Training loss: 0.9562648273390579
Validation loss: 2.624743256047664

Epoch: 5| Step: 9
Training loss: 1.0598555923558404
Validation loss: 2.703165186324211

Epoch: 5| Step: 10
Training loss: 0.667943831308034
Validation loss: 2.6536644712522977

Epoch: 5| Step: 11
Training loss: 0.7596404455465509
Validation loss: 2.5811490635691503

Epoch: 211| Step: 0
Training loss: 0.4873427565388095
Validation loss: 2.620357935069302

Epoch: 5| Step: 1
Training loss: 0.6293405253676588
Validation loss: 2.6074625228780475

Epoch: 5| Step: 2
Training loss: 0.6887165706365851
Validation loss: 2.5440610072210386

Epoch: 5| Step: 3
Training loss: 0.8810470956193257
Validation loss: 2.6420201109251416

Epoch: 5| Step: 4
Training loss: 1.126234436943751
Validation loss: 2.5824957817833454

Epoch: 5| Step: 5
Training loss: 0.6377474192526358
Validation loss: 2.5427346656516217

Epoch: 5| Step: 6
Training loss: 0.9875512121900302
Validation loss: 2.6394149821929074

Epoch: 5| Step: 7
Training loss: 0.8237042742297003
Validation loss: 2.5914743544276035

Epoch: 5| Step: 8
Training loss: 1.384015179925701
Validation loss: 2.6436986171217183

Epoch: 5| Step: 9
Training loss: 0.8576673708024627
Validation loss: 2.6759698434716634

Epoch: 5| Step: 10
Training loss: 0.7513922246654061
Validation loss: 2.601199020638991

Epoch: 5| Step: 11
Training loss: 1.0156565734650558
Validation loss: 2.727404465332366

Epoch: 212| Step: 0
Training loss: 0.8270175294298316
Validation loss: 2.621426769160444

Epoch: 5| Step: 1
Training loss: 0.6154717123827564
Validation loss: 2.6382614106379427

Epoch: 5| Step: 2
Training loss: 0.8282339636173947
Validation loss: 2.6261218943301756

Epoch: 5| Step: 3
Training loss: 0.736743516394464
Validation loss: 2.6369335849978195

Epoch: 5| Step: 4
Training loss: 0.7179529082467251
Validation loss: 2.6115442765261085

Epoch: 5| Step: 5
Training loss: 0.6466093374759807
Validation loss: 2.6217831360247166

Epoch: 5| Step: 6
Training loss: 1.3883455432264875
Validation loss: 2.602083999709041

Epoch: 5| Step: 7
Training loss: 0.7498978306798083
Validation loss: 2.5704123700807275

Epoch: 5| Step: 8
Training loss: 0.755835559873936
Validation loss: 2.5587074856315795

Epoch: 5| Step: 9
Training loss: 1.2301431376435392
Validation loss: 2.573521526889583

Epoch: 5| Step: 10
Training loss: 0.5139400811801479
Validation loss: 2.638345091543145

Epoch: 5| Step: 11
Training loss: 0.8622999871580558
Validation loss: 2.690253757971772

Epoch: 213| Step: 0
Training loss: 1.0849913173099592
Validation loss: 2.6721558376793846

Epoch: 5| Step: 1
Training loss: 1.1782643405260957
Validation loss: 2.6862565202309923

Epoch: 5| Step: 2
Training loss: 1.232620489254783
Validation loss: 2.6991213805343217

Epoch: 5| Step: 3
Training loss: 0.9616273404272297
Validation loss: 2.76163623907777

Epoch: 5| Step: 4
Training loss: 0.8464312513411338
Validation loss: 2.680897846230289

Epoch: 5| Step: 5
Training loss: 0.6069538975432193
Validation loss: 2.549753781505336

Epoch: 5| Step: 6
Training loss: 0.8415347441279495
Validation loss: 2.573713809761388

Epoch: 5| Step: 7
Training loss: 0.8942341206916119
Validation loss: 2.5815416219048917

Epoch: 5| Step: 8
Training loss: 0.7988261476972587
Validation loss: 2.5588694494282676

Epoch: 5| Step: 9
Training loss: 0.859557045814919
Validation loss: 2.61961666126832

Epoch: 5| Step: 10
Training loss: 0.7464096439149456
Validation loss: 2.582862262434915

Epoch: 5| Step: 11
Training loss: 0.6754237646176678
Validation loss: 2.5752599614283413

Epoch: 214| Step: 0
Training loss: 0.7981027980336214
Validation loss: 2.6469599335249834

Epoch: 5| Step: 1
Training loss: 0.9873326087271148
Validation loss: 2.64545921561741

Epoch: 5| Step: 2
Training loss: 0.8957269664574278
Validation loss: 2.6649512284285053

Epoch: 5| Step: 3
Training loss: 0.7873594203993701
Validation loss: 2.7275629840388667

Epoch: 5| Step: 4
Training loss: 0.8407166668570776
Validation loss: 2.672341813472235

Epoch: 5| Step: 5
Training loss: 1.002889868253164
Validation loss: 2.7306702175225173

Epoch: 5| Step: 6
Training loss: 0.9575060231191171
Validation loss: 2.6592683584704386

Epoch: 5| Step: 7
Training loss: 0.826418576032315
Validation loss: 2.5479946990604243

Epoch: 5| Step: 8
Training loss: 1.2006589709375421
Validation loss: 2.6338059789378123

Epoch: 5| Step: 9
Training loss: 0.9272729629713496
Validation loss: 2.5869569027268233

Epoch: 5| Step: 10
Training loss: 0.9073064499945209
Validation loss: 2.578780374167807

Epoch: 5| Step: 11
Training loss: 0.8616314481501973
Validation loss: 2.6284730619538106

Epoch: 215| Step: 0
Training loss: 1.3516120240063032
Validation loss: 2.5256147017249715

Epoch: 5| Step: 1
Training loss: 0.6516708741292064
Validation loss: 2.5481889373914215

Epoch: 5| Step: 2
Training loss: 1.2065430181511776
Validation loss: 2.642455463518322

Epoch: 5| Step: 3
Training loss: 0.9033782115629524
Validation loss: 2.70483664709826

Epoch: 5| Step: 4
Training loss: 0.8961589945792926
Validation loss: 2.711270098479085

Epoch: 5| Step: 5
Training loss: 0.8158252601756617
Validation loss: 2.702582960963916

Epoch: 5| Step: 6
Training loss: 1.1837333873803624
Validation loss: 2.619882067617816

Epoch: 5| Step: 7
Training loss: 0.675833749661237
Validation loss: 2.6259444482933785

Epoch: 5| Step: 8
Training loss: 0.8205689528908368
Validation loss: 2.640904620562545

Epoch: 5| Step: 9
Training loss: 0.7963147531406715
Validation loss: 2.6606603248478873

Epoch: 5| Step: 10
Training loss: 0.9301316298371685
Validation loss: 2.6009964045409673

Epoch: 5| Step: 11
Training loss: 0.5100194657107708
Validation loss: 2.603316715136966

Epoch: 216| Step: 0
Training loss: 1.2870472269292659
Validation loss: 2.6201942556684026

Epoch: 5| Step: 1
Training loss: 0.6160432856511281
Validation loss: 2.7061952673506915

Epoch: 5| Step: 2
Training loss: 0.7217019455797744
Validation loss: 2.697946475881809

Epoch: 5| Step: 3
Training loss: 1.0098072980475352
Validation loss: 2.6853455550132854

Epoch: 5| Step: 4
Training loss: 0.6195758529327817
Validation loss: 2.624222704683871

Epoch: 5| Step: 5
Training loss: 0.9415204623891146
Validation loss: 2.668137118238373

Epoch: 5| Step: 6
Training loss: 1.0060938885826871
Validation loss: 2.6529191132343417

Epoch: 5| Step: 7
Training loss: 0.780511888871684
Validation loss: 2.659535343492807

Epoch: 5| Step: 8
Training loss: 0.7636401079600053
Validation loss: 2.6387752999292

Epoch: 5| Step: 9
Training loss: 0.5391360246577864
Validation loss: 2.63984045529167

Epoch: 5| Step: 10
Training loss: 1.0509545279083867
Validation loss: 2.6386365796375015

Epoch: 5| Step: 11
Training loss: 0.6409669289233171
Validation loss: 2.6913195089933715

Epoch: 217| Step: 0
Training loss: 1.2914154310875103
Validation loss: 2.7081483166416676

Epoch: 5| Step: 1
Training loss: 0.841529821532707
Validation loss: 2.6251761778489913

Epoch: 5| Step: 2
Training loss: 0.949095761215894
Validation loss: 2.634817309069423

Epoch: 5| Step: 3
Training loss: 0.755592279285811
Validation loss: 2.6980553275944703

Epoch: 5| Step: 4
Training loss: 0.4519439630395792
Validation loss: 2.6397120197262716

Epoch: 5| Step: 5
Training loss: 0.7834836690450793
Validation loss: 2.664513164821202

Epoch: 5| Step: 6
Training loss: 0.8424972842028395
Validation loss: 2.7259204075662367

Epoch: 5| Step: 7
Training loss: 0.6840650840909134
Validation loss: 2.611733294115679

Epoch: 5| Step: 8
Training loss: 1.0083678142442425
Validation loss: 2.653980658274814

Epoch: 5| Step: 9
Training loss: 0.48049137403364933
Validation loss: 2.6538456787587736

Epoch: 5| Step: 10
Training loss: 0.7642349547807294
Validation loss: 2.588371414531619

Epoch: 5| Step: 11
Training loss: 0.7528863441667797
Validation loss: 2.612581441604591

Epoch: 218| Step: 0
Training loss: 0.6267337831317172
Validation loss: 2.6750273781857876

Epoch: 5| Step: 1
Training loss: 0.7947532981187341
Validation loss: 2.6500756740261657

Epoch: 5| Step: 2
Training loss: 1.3011783303083782
Validation loss: 2.5906545981697713

Epoch: 5| Step: 3
Training loss: 0.8126018900440646
Validation loss: 2.5932069501035624

Epoch: 5| Step: 4
Training loss: 0.7146175005634211
Validation loss: 2.6263041586892144

Epoch: 5| Step: 5
Training loss: 0.68715895516723
Validation loss: 2.6407806098578637

Epoch: 5| Step: 6
Training loss: 0.8276545069760605
Validation loss: 2.6148867386748154

Epoch: 5| Step: 7
Training loss: 0.7885201733850213
Validation loss: 2.634943502467101

Epoch: 5| Step: 8
Training loss: 0.6352265782382709
Validation loss: 2.611047741586555

Epoch: 5| Step: 9
Training loss: 1.0725451940515518
Validation loss: 2.6366524111090692

Epoch: 5| Step: 10
Training loss: 0.6251109501587637
Validation loss: 2.6584825707541606

Epoch: 5| Step: 11
Training loss: 0.6466218508310582
Validation loss: 2.64110158723873

Epoch: 219| Step: 0
Training loss: 0.9216146263057156
Validation loss: 2.627536445150771

Epoch: 5| Step: 1
Training loss: 1.1453210494696835
Validation loss: 2.634407967436203

Epoch: 5| Step: 2
Training loss: 0.391656353320969
Validation loss: 2.604359525532802

Epoch: 5| Step: 3
Training loss: 0.8171960031566636
Validation loss: 2.559787768660093

Epoch: 5| Step: 4
Training loss: 0.6099765938036071
Validation loss: 2.5969980538933433

Epoch: 5| Step: 5
Training loss: 0.41320348199030876
Validation loss: 2.6026055743203673

Epoch: 5| Step: 6
Training loss: 1.4729520060586154
Validation loss: 2.614963609592362

Epoch: 5| Step: 7
Training loss: 0.678028823255342
Validation loss: 2.626093303733115

Epoch: 5| Step: 8
Training loss: 0.7893414901180924
Validation loss: 2.589722620460183

Epoch: 5| Step: 9
Training loss: 0.5724085085862232
Validation loss: 2.639250662890018

Epoch: 5| Step: 10
Training loss: 0.7424352533515357
Validation loss: 2.602739707364597

Epoch: 5| Step: 11
Training loss: 0.662729406224639
Validation loss: 2.6670528736936774

Epoch: 220| Step: 0
Training loss: 0.5804375199841335
Validation loss: 2.657379654419926

Epoch: 5| Step: 1
Training loss: 0.9041823444384275
Validation loss: 2.632370180580112

Epoch: 5| Step: 2
Training loss: 0.6818322292239061
Validation loss: 2.6531783201553334

Epoch: 5| Step: 3
Training loss: 1.1081863805442398
Validation loss: 2.6194359946819743

Epoch: 5| Step: 4
Training loss: 0.6453796351796659
Validation loss: 2.6271223521883194

Epoch: 5| Step: 5
Training loss: 0.6032510319403348
Validation loss: 2.6320867056857975

Epoch: 5| Step: 6
Training loss: 0.6149534764952186
Validation loss: 2.5837512652414514

Epoch: 5| Step: 7
Training loss: 0.8314851213226223
Validation loss: 2.748528993813921

Epoch: 5| Step: 8
Training loss: 1.1915810878853534
Validation loss: 2.664279164502603

Epoch: 5| Step: 9
Training loss: 0.9180611097257897
Validation loss: 2.7231108852800188

Epoch: 5| Step: 10
Training loss: 0.6291469800365939
Validation loss: 2.723951871559157

Epoch: 5| Step: 11
Training loss: 0.6367254432373229
Validation loss: 2.7092593749533194

Epoch: 221| Step: 0
Training loss: 0.6391101698129401
Validation loss: 2.64905770578326

Epoch: 5| Step: 1
Training loss: 0.6194158237295353
Validation loss: 2.582101013964752

Epoch: 5| Step: 2
Training loss: 0.5242498556308793
Validation loss: 2.615903697021978

Epoch: 5| Step: 3
Training loss: 0.483477560946742
Validation loss: 2.603834509965284

Epoch: 5| Step: 4
Training loss: 0.779579321747134
Validation loss: 2.649066880272652

Epoch: 5| Step: 5
Training loss: 0.716211230442059
Validation loss: 2.626951922448319

Epoch: 5| Step: 6
Training loss: 0.6252052208622667
Validation loss: 2.6679611057006287

Epoch: 5| Step: 7
Training loss: 0.6963074241667523
Validation loss: 2.6604628944015145

Epoch: 5| Step: 8
Training loss: 0.6087432423085327
Validation loss: 2.5764870035135026

Epoch: 5| Step: 9
Training loss: 1.4425131416713863
Validation loss: 2.6305580221446783

Epoch: 5| Step: 10
Training loss: 0.9850755953463194
Validation loss: 2.681397814407211

Epoch: 5| Step: 11
Training loss: 1.9362945498321573
Validation loss: 2.6878186598826455

Epoch: 222| Step: 0
Training loss: 0.6712004358046961
Validation loss: 2.6346229267619274

Epoch: 5| Step: 1
Training loss: 1.2014226388080114
Validation loss: 2.5646649612360433

Epoch: 5| Step: 2
Training loss: 0.6376771091824863
Validation loss: 2.627169170736933

Epoch: 5| Step: 3
Training loss: 0.9248171586965181
Validation loss: 2.5885074595308932

Epoch: 5| Step: 4
Training loss: 1.167601869047524
Validation loss: 2.5258597410045094

Epoch: 5| Step: 5
Training loss: 0.7790737741008812
Validation loss: 2.6390934345516963

Epoch: 5| Step: 6
Training loss: 0.8796250180538122
Validation loss: 2.6499388986117167

Epoch: 5| Step: 7
Training loss: 0.5846895788941769
Validation loss: 2.6311550639733507

Epoch: 5| Step: 8
Training loss: 0.801235051781865
Validation loss: 2.653631995816726

Epoch: 5| Step: 9
Training loss: 0.8796167850021333
Validation loss: 2.724231098490935

Epoch: 5| Step: 10
Training loss: 0.857495350394141
Validation loss: 2.702284364322588

Epoch: 5| Step: 11
Training loss: 0.5720190877697341
Validation loss: 2.665261327957704

Epoch: 223| Step: 0
Training loss: 0.6108619692032973
Validation loss: 2.6921824243593258

Epoch: 5| Step: 1
Training loss: 0.506054961934341
Validation loss: 2.6294184238265683

Epoch: 5| Step: 2
Training loss: 0.8175339644489695
Validation loss: 2.6271607875876373

Epoch: 5| Step: 3
Training loss: 0.6888603709797286
Validation loss: 2.616021145985723

Epoch: 5| Step: 4
Training loss: 1.2278913358145171
Validation loss: 2.6866728004932985

Epoch: 5| Step: 5
Training loss: 0.7035614989985977
Validation loss: 2.721055281194952

Epoch: 5| Step: 6
Training loss: 0.7481511693216069
Validation loss: 2.713665255894552

Epoch: 5| Step: 7
Training loss: 1.2520682390586384
Validation loss: 2.7222034528440973

Epoch: 5| Step: 8
Training loss: 0.8745808619306327
Validation loss: 2.813850128220262

Epoch: 5| Step: 9
Training loss: 0.9244711253214954
Validation loss: 2.7156247522714705

Epoch: 5| Step: 10
Training loss: 0.5240225298202223
Validation loss: 2.7098849339180133

Epoch: 5| Step: 11
Training loss: 0.4099477328735968
Validation loss: 2.7062258712714855

Epoch: 224| Step: 0
Training loss: 0.9268190385795048
Validation loss: 2.7127602502169097

Epoch: 5| Step: 1
Training loss: 0.5840302771450433
Validation loss: 2.6340515605623773

Epoch: 5| Step: 2
Training loss: 0.5249356423395195
Validation loss: 2.672450975795733

Epoch: 5| Step: 3
Training loss: 0.5822578859397124
Validation loss: 2.750292462634004

Epoch: 5| Step: 4
Training loss: 0.9900066407298842
Validation loss: 2.6885578454077828

Epoch: 5| Step: 5
Training loss: 0.9081736570110132
Validation loss: 2.674501685790903

Epoch: 5| Step: 6
Training loss: 0.6937589541707962
Validation loss: 2.666317404037931

Epoch: 5| Step: 7
Training loss: 0.8259103780530207
Validation loss: 2.6944953527480684

Epoch: 5| Step: 8
Training loss: 0.5430971446647593
Validation loss: 2.6393079501635572

Epoch: 5| Step: 9
Training loss: 0.741679328817513
Validation loss: 2.711744878993441

Epoch: 5| Step: 10
Training loss: 1.3241785093961855
Validation loss: 2.714501529045562

Epoch: 5| Step: 11
Training loss: 0.3334952894790357
Validation loss: 2.6579041790572937

Epoch: 225| Step: 0
Training loss: 0.6205596786882096
Validation loss: 2.695537097068743

Epoch: 5| Step: 1
Training loss: 0.8203696458075967
Validation loss: 2.646488886943129

Epoch: 5| Step: 2
Training loss: 0.9388731437098975
Validation loss: 2.6939471947079783

Epoch: 5| Step: 3
Training loss: 0.9427664652792412
Validation loss: 2.6476159448483365

Epoch: 5| Step: 4
Training loss: 0.4649387871536876
Validation loss: 2.671158168328719

Epoch: 5| Step: 5
Training loss: 0.41882623078256437
Validation loss: 2.6502090388148334

Epoch: 5| Step: 6
Training loss: 0.6045077172473808
Validation loss: 2.6532032640923138

Epoch: 5| Step: 7
Training loss: 0.6205587902267484
Validation loss: 2.6966505295392853

Epoch: 5| Step: 8
Training loss: 0.8231839015685966
Validation loss: 2.666601393814732

Epoch: 5| Step: 9
Training loss: 0.710582392949366
Validation loss: 2.5999880733888907

Epoch: 5| Step: 10
Training loss: 0.7928377616445373
Validation loss: 2.646373619774384

Epoch: 5| Step: 11
Training loss: 2.22944737981282
Validation loss: 2.6125235606687136

Epoch: 226| Step: 0
Training loss: 0.5801983846728073
Validation loss: 2.6197898642279087

Epoch: 5| Step: 1
Training loss: 0.8153348399296791
Validation loss: 2.6349553369118506

Epoch: 5| Step: 2
Training loss: 0.6605298040655458
Validation loss: 2.6064986024232404

Epoch: 5| Step: 3
Training loss: 0.725532745424195
Validation loss: 2.6106858035328018

Epoch: 5| Step: 4
Training loss: 0.4678043203970238
Validation loss: 2.6306413287810577

Epoch: 5| Step: 5
Training loss: 1.2453055923634093
Validation loss: 2.6589553482476083

Epoch: 5| Step: 6
Training loss: 0.9382834022363885
Validation loss: 2.6499090729414725

Epoch: 5| Step: 7
Training loss: 0.6587296369470845
Validation loss: 2.7045088186143182

Epoch: 5| Step: 8
Training loss: 0.5649368958552798
Validation loss: 2.6689888571071503

Epoch: 5| Step: 9
Training loss: 0.6507122630616843
Validation loss: 2.6278533470834216

Epoch: 5| Step: 10
Training loss: 1.1517969418186524
Validation loss: 2.6193567386440586

Epoch: 5| Step: 11
Training loss: 0.6025457397288804
Validation loss: 2.538556796845272

Epoch: 227| Step: 0
Training loss: 0.7535085864650491
Validation loss: 2.6362226438632894

Epoch: 5| Step: 1
Training loss: 0.7288977717553552
Validation loss: 2.6326718637125417

Epoch: 5| Step: 2
Training loss: 0.48761189167031993
Validation loss: 2.615574767808901

Epoch: 5| Step: 3
Training loss: 0.8693001932831806
Validation loss: 2.6491711780893272

Epoch: 5| Step: 4
Training loss: 0.5753872717858711
Validation loss: 2.679728968292951

Epoch: 5| Step: 5
Training loss: 0.8231413248886493
Validation loss: 2.7261263107687763

Epoch: 5| Step: 6
Training loss: 0.7116656504481592
Validation loss: 2.6894258171325944

Epoch: 5| Step: 7
Training loss: 1.2115963035907447
Validation loss: 2.6470513931702024

Epoch: 5| Step: 8
Training loss: 0.4271207265843843
Validation loss: 2.7011143256929846

Epoch: 5| Step: 9
Training loss: 0.48793893640560115
Validation loss: 2.6411157449221943

Epoch: 5| Step: 10
Training loss: 1.043664707193776
Validation loss: 2.5754551945040527

Epoch: 5| Step: 11
Training loss: 0.2260777615296365
Validation loss: 2.644161320576842

Epoch: 228| Step: 0
Training loss: 0.5322480083659453
Validation loss: 2.6805090242727427

Epoch: 5| Step: 1
Training loss: 1.3990579432825896
Validation loss: 2.666195236695241

Epoch: 5| Step: 2
Training loss: 0.9969134978032728
Validation loss: 2.5925476320722822

Epoch: 5| Step: 3
Training loss: 0.7264881301062477
Validation loss: 2.6045590842540136

Epoch: 5| Step: 4
Training loss: 0.6673403901998285
Validation loss: 2.6798872544227472

Epoch: 5| Step: 5
Training loss: 0.5633571769344545
Validation loss: 2.6542135884755087

Epoch: 5| Step: 6
Training loss: 0.6630593970132043
Validation loss: 2.593917967631585

Epoch: 5| Step: 7
Training loss: 0.5987064135859583
Validation loss: 2.592298107075347

Epoch: 5| Step: 8
Training loss: 0.6212925143057552
Validation loss: 2.7038806307494796

Epoch: 5| Step: 9
Training loss: 0.7587111738725345
Validation loss: 2.5635030225568927

Epoch: 5| Step: 10
Training loss: 0.7273969063351922
Validation loss: 2.694445624520567

Epoch: 5| Step: 11
Training loss: 0.4051996738453237
Validation loss: 2.5997464196174707

Epoch: 229| Step: 0
Training loss: 0.6636633851674163
Validation loss: 2.5999937243874935

Epoch: 5| Step: 1
Training loss: 0.6170576900672203
Validation loss: 2.6833414202522854

Epoch: 5| Step: 2
Training loss: 0.5652698033848472
Validation loss: 2.5784359407279585

Epoch: 5| Step: 3
Training loss: 0.49987538096019196
Validation loss: 2.6225820902669867

Epoch: 5| Step: 4
Training loss: 0.7609256234309424
Validation loss: 2.696578077913112

Epoch: 5| Step: 5
Training loss: 0.6514862043320974
Validation loss: 2.635805858301427

Epoch: 5| Step: 6
Training loss: 0.5193627449912606
Validation loss: 2.680324341603023

Epoch: 5| Step: 7
Training loss: 1.1210468561552986
Validation loss: 2.7105144570077746

Epoch: 5| Step: 8
Training loss: 0.6814153348146106
Validation loss: 2.654881843067745

Epoch: 5| Step: 9
Training loss: 1.091305753631651
Validation loss: 2.7298634758256

Epoch: 5| Step: 10
Training loss: 1.0051925671120105
Validation loss: 2.735518966431485

Epoch: 5| Step: 11
Training loss: 0.45271071865098816
Validation loss: 2.6505725435527534

Epoch: 230| Step: 0
Training loss: 0.43056938532012606
Validation loss: 2.6663154554551802

Epoch: 5| Step: 1
Training loss: 1.0289540597616176
Validation loss: 2.6475506500799986

Epoch: 5| Step: 2
Training loss: 0.6861671619411951
Validation loss: 2.7151640998045012

Epoch: 5| Step: 3
Training loss: 0.8776050684591277
Validation loss: 2.657027665535598

Epoch: 5| Step: 4
Training loss: 0.772511438390002
Validation loss: 2.6377257056181787

Epoch: 5| Step: 5
Training loss: 0.5290951784409895
Validation loss: 2.6968528400393295

Epoch: 5| Step: 6
Training loss: 1.224982878506958
Validation loss: 2.6291024341283777

Epoch: 5| Step: 7
Training loss: 0.5427579951002747
Validation loss: 2.6397823366109616

Epoch: 5| Step: 8
Training loss: 0.7384301898221549
Validation loss: 2.6806638401496947

Epoch: 5| Step: 9
Training loss: 0.7127559168799824
Validation loss: 2.702159257046153

Epoch: 5| Step: 10
Training loss: 0.5446530844780113
Validation loss: 2.691588555719254

Epoch: 5| Step: 11
Training loss: 0.6245221695610852
Validation loss: 2.6737193310015877

Epoch: 231| Step: 0
Training loss: 0.39279582501861426
Validation loss: 2.6442973128751106

Epoch: 5| Step: 1
Training loss: 0.6999238364473952
Validation loss: 2.6951287395842414

Epoch: 5| Step: 2
Training loss: 0.979344487107471
Validation loss: 2.5961755724937

Epoch: 5| Step: 3
Training loss: 1.063251902492677
Validation loss: 2.688057305711224

Epoch: 5| Step: 4
Training loss: 0.6427628271988479
Validation loss: 2.6031600697915334

Epoch: 5| Step: 5
Training loss: 0.7148178596185584
Validation loss: 2.7127268471474366

Epoch: 5| Step: 6
Training loss: 0.841966899508895
Validation loss: 2.6483993471261353

Epoch: 5| Step: 7
Training loss: 0.46635107675732557
Validation loss: 2.5898403936779584

Epoch: 5| Step: 8
Training loss: 0.6646411842670092
Validation loss: 2.6439013404756273

Epoch: 5| Step: 9
Training loss: 0.8761136937477955
Validation loss: 2.63762434866659

Epoch: 5| Step: 10
Training loss: 0.6432491150103818
Validation loss: 2.6584773990753043

Epoch: 5| Step: 11
Training loss: 0.6696918637644848
Validation loss: 2.70801405430783

Epoch: 232| Step: 0
Training loss: 0.7041821056757612
Validation loss: 2.6614956352372

Epoch: 5| Step: 1
Training loss: 0.7900985865101484
Validation loss: 2.612070195496704

Epoch: 5| Step: 2
Training loss: 0.6285361628617551
Validation loss: 2.6005548429235756

Epoch: 5| Step: 3
Training loss: 0.9226896598122428
Validation loss: 2.639139523162315

Epoch: 5| Step: 4
Training loss: 1.2758467648673508
Validation loss: 2.6633655423228757

Epoch: 5| Step: 5
Training loss: 0.6249566539992187
Validation loss: 2.72563864022463

Epoch: 5| Step: 6
Training loss: 0.5091263134735945
Validation loss: 2.6521876555604162

Epoch: 5| Step: 7
Training loss: 0.7162543798316072
Validation loss: 2.6860080614302744

Epoch: 5| Step: 8
Training loss: 0.9336746372312591
Validation loss: 2.669562255333983

Epoch: 5| Step: 9
Training loss: 0.4844677282604464
Validation loss: 2.543962314814924

Epoch: 5| Step: 10
Training loss: 0.5934732946816734
Validation loss: 2.715086041074181

Epoch: 5| Step: 11
Training loss: 0.30163156775901656
Validation loss: 2.662394522576026

Epoch: 233| Step: 0
Training loss: 1.2120780249870948
Validation loss: 2.6297547141219435

Epoch: 5| Step: 1
Training loss: 0.8727070191726267
Validation loss: 2.6085412640816665

Epoch: 5| Step: 2
Training loss: 0.5664704648152549
Validation loss: 2.6642728631128354

Epoch: 5| Step: 3
Training loss: 0.8344966199725287
Validation loss: 2.687142632994859

Epoch: 5| Step: 4
Training loss: 0.6713608393449737
Validation loss: 2.7274165232396093

Epoch: 5| Step: 5
Training loss: 0.8549028379880692
Validation loss: 2.6404164060709205

Epoch: 5| Step: 6
Training loss: 0.9894609007471497
Validation loss: 2.685270443647693

Epoch: 5| Step: 7
Training loss: 0.5272616852378414
Validation loss: 2.6932878196603576

Epoch: 5| Step: 8
Training loss: 0.5280887004408394
Validation loss: 2.6964348064318644

Epoch: 5| Step: 9
Training loss: 0.5533803662836332
Validation loss: 2.570786294295552

Epoch: 5| Step: 10
Training loss: 0.4964999991058703
Validation loss: 2.6719910520220074

Epoch: 5| Step: 11
Training loss: 0.4924517482270276
Validation loss: 2.576415614623279

Epoch: 234| Step: 0
Training loss: 1.0646252974110817
Validation loss: 2.648826593045038

Epoch: 5| Step: 1
Training loss: 1.114601075693731
Validation loss: 2.6496437011666822

Epoch: 5| Step: 2
Training loss: 0.5942610248109493
Validation loss: 2.716149602919706

Epoch: 5| Step: 3
Training loss: 0.7316120604454852
Validation loss: 2.74347853088808

Epoch: 5| Step: 4
Training loss: 0.625171327950187
Validation loss: 2.704298650305782

Epoch: 5| Step: 5
Training loss: 0.5428989832123956
Validation loss: 2.646961322143961

Epoch: 5| Step: 6
Training loss: 0.48997245874174583
Validation loss: 2.6783133450561243

Epoch: 5| Step: 7
Training loss: 0.7067994849615482
Validation loss: 2.6074425095254834

Epoch: 5| Step: 8
Training loss: 0.9009205878314765
Validation loss: 2.6969034079259657

Epoch: 5| Step: 9
Training loss: 0.7383318283275252
Validation loss: 2.632595936276027

Epoch: 5| Step: 10
Training loss: 0.5773075097547617
Validation loss: 2.616610012585132

Epoch: 5| Step: 11
Training loss: 0.26388327989277943
Validation loss: 2.6648315333974804

Epoch: 235| Step: 0
Training loss: 0.8106083122776901
Validation loss: 2.686015539716589

Epoch: 5| Step: 1
Training loss: 0.9376775891266466
Validation loss: 2.642292105906728

Epoch: 5| Step: 2
Training loss: 0.7008198994298893
Validation loss: 2.705920326791363

Epoch: 5| Step: 3
Training loss: 0.8367443647123649
Validation loss: 2.6047581280745855

Epoch: 5| Step: 4
Training loss: 0.5348842792940793
Validation loss: 2.6706653072470687

Epoch: 5| Step: 5
Training loss: 0.8429973212094355
Validation loss: 2.6310499085001653

Epoch: 5| Step: 6
Training loss: 1.0851498498583705
Validation loss: 2.649052596330777

Epoch: 5| Step: 7
Training loss: 0.6927666077923804
Validation loss: 2.6956659315648435

Epoch: 5| Step: 8
Training loss: 0.6239435088021068
Validation loss: 2.6586272615810556

Epoch: 5| Step: 9
Training loss: 0.7278091236656956
Validation loss: 2.6710462902368164

Epoch: 5| Step: 10
Training loss: 0.5592776027257209
Validation loss: 2.7052694755659035

Epoch: 5| Step: 11
Training loss: 0.3476237592623563
Validation loss: 2.655681646539974

Epoch: 236| Step: 0
Training loss: 0.5570003484899503
Validation loss: 2.5864267184204377

Epoch: 5| Step: 1
Training loss: 1.0396202712800577
Validation loss: 2.665850128141991

Epoch: 5| Step: 2
Training loss: 0.7917392764339436
Validation loss: 2.654741685511521

Epoch: 5| Step: 3
Training loss: 0.7087131958947422
Validation loss: 2.670450851624183

Epoch: 5| Step: 4
Training loss: 1.156425101965797
Validation loss: 2.661882356781447

Epoch: 5| Step: 5
Training loss: 0.7046399643929574
Validation loss: 2.62783118112624

Epoch: 5| Step: 6
Training loss: 0.8474378875882335
Validation loss: 2.6536104513747616

Epoch: 5| Step: 7
Training loss: 0.5013711130414288
Validation loss: 2.6703950304105315

Epoch: 5| Step: 8
Training loss: 0.6073113245805949
Validation loss: 2.5962056576960233

Epoch: 5| Step: 9
Training loss: 0.534804764757993
Validation loss: 2.6653647665829108

Epoch: 5| Step: 10
Training loss: 0.36439844847750824
Validation loss: 2.7076754149911957

Epoch: 5| Step: 11
Training loss: 0.8189118189004584
Validation loss: 2.7165034830682027

Epoch: 237| Step: 0
Training loss: 0.5083634835301879
Validation loss: 2.6884197908544167

Epoch: 5| Step: 1
Training loss: 1.152559214992588
Validation loss: 2.725701036600509

Epoch: 5| Step: 2
Training loss: 0.8293644249133361
Validation loss: 2.6839684452003696

Epoch: 5| Step: 3
Training loss: 0.4810075452583531
Validation loss: 2.6493367831710537

Epoch: 5| Step: 4
Training loss: 0.529738210540614
Validation loss: 2.6884484650455036

Epoch: 5| Step: 5
Training loss: 0.6465984601087136
Validation loss: 2.678161279142546

Epoch: 5| Step: 6
Training loss: 0.7851961799450926
Validation loss: 2.6807971506717596

Epoch: 5| Step: 7
Training loss: 0.5479812876471976
Validation loss: 2.7768440673408032

Epoch: 5| Step: 8
Training loss: 0.9600502508144548
Validation loss: 2.663880357826989

Epoch: 5| Step: 9
Training loss: 0.6962169807863976
Validation loss: 2.6683198540490265

Epoch: 5| Step: 10
Training loss: 0.7068012348140515
Validation loss: 2.641766314677838

Epoch: 5| Step: 11
Training loss: 0.4688065494759301
Validation loss: 2.743616907140171

Epoch: 238| Step: 0
Training loss: 0.4868606348330241
Validation loss: 2.639193261450891

Epoch: 5| Step: 1
Training loss: 0.6771541387264614
Validation loss: 2.6690811697714825

Epoch: 5| Step: 2
Training loss: 0.5607094877747598
Validation loss: 2.6278198098250254

Epoch: 5| Step: 3
Training loss: 0.5048776770206964
Validation loss: 2.6787579687952046

Epoch: 5| Step: 4
Training loss: 0.5523699580210855
Validation loss: 2.6168322801318364

Epoch: 5| Step: 5
Training loss: 0.5922543611249177
Validation loss: 2.7117860475609943

Epoch: 5| Step: 6
Training loss: 0.8058024339626362
Validation loss: 2.627306511424408

Epoch: 5| Step: 7
Training loss: 0.5133922091177885
Validation loss: 2.6746899683607004

Epoch: 5| Step: 8
Training loss: 0.7021265358088863
Validation loss: 2.647352622834831

Epoch: 5| Step: 9
Training loss: 0.8694966819177793
Validation loss: 2.696663264644569

Epoch: 5| Step: 10
Training loss: 1.268983505634822
Validation loss: 2.675586465024767

Epoch: 5| Step: 11
Training loss: 0.20549501098948547
Validation loss: 2.6990100984211307

Epoch: 239| Step: 0
Training loss: 0.5568356088819976
Validation loss: 2.647984153633877

Epoch: 5| Step: 1
Training loss: 0.825379408666728
Validation loss: 2.7221349566500717

Epoch: 5| Step: 2
Training loss: 0.5324626993717297
Validation loss: 2.609343766503324

Epoch: 5| Step: 3
Training loss: 0.7063866094952561
Validation loss: 2.6191114195983465

Epoch: 5| Step: 4
Training loss: 0.6356773050368528
Validation loss: 2.614329699388973

Epoch: 5| Step: 5
Training loss: 1.0852882035883475
Validation loss: 2.7171620814352146

Epoch: 5| Step: 6
Training loss: 0.7665686727866992
Validation loss: 2.786310396396987

Epoch: 5| Step: 7
Training loss: 0.9005964461809456
Validation loss: 2.712171953261271

Epoch: 5| Step: 8
Training loss: 0.6015019076658774
Validation loss: 2.7229517006073545

Epoch: 5| Step: 9
Training loss: 0.645153392730912
Validation loss: 2.6741961496898736

Epoch: 5| Step: 10
Training loss: 0.6934833684383265
Validation loss: 2.6505514577269658

Epoch: 5| Step: 11
Training loss: 0.5319939621281563
Validation loss: 2.726272800798552

Epoch: 240| Step: 0
Training loss: 0.5696537445999322
Validation loss: 2.6582622946591776

Epoch: 5| Step: 1
Training loss: 1.0567206107448524
Validation loss: 2.7091869085097997

Epoch: 5| Step: 2
Training loss: 0.9852571319306461
Validation loss: 2.709767234684088

Epoch: 5| Step: 3
Training loss: 0.3639351077530968
Validation loss: 2.6361620393008884

Epoch: 5| Step: 4
Training loss: 0.6012104044385134
Validation loss: 2.7158722299283773

Epoch: 5| Step: 5
Training loss: 0.5418410906802056
Validation loss: 2.789367545121682

Epoch: 5| Step: 6
Training loss: 0.9020341944947943
Validation loss: 2.606661522117117

Epoch: 5| Step: 7
Training loss: 0.9156656471057442
Validation loss: 2.6683234039102435

Epoch: 5| Step: 8
Training loss: 0.583679732151221
Validation loss: 2.674863549344213

Epoch: 5| Step: 9
Training loss: 0.6540729879822411
Validation loss: 2.7426700511616935

Epoch: 5| Step: 10
Training loss: 0.8436861014012269
Validation loss: 2.6532806816599925

Epoch: 5| Step: 11
Training loss: 0.6723717250584652
Validation loss: 2.635179201115308

Epoch: 241| Step: 0
Training loss: 0.6511942621054442
Validation loss: 2.7661176160176297

Epoch: 5| Step: 1
Training loss: 0.538138496061326
Validation loss: 2.659561482849278

Epoch: 5| Step: 2
Training loss: 0.8513761193930806
Validation loss: 2.695441802235854

Epoch: 5| Step: 3
Training loss: 0.8645948539487205
Validation loss: 2.6502339376050337

Epoch: 5| Step: 4
Training loss: 0.6343117367623993
Validation loss: 2.691157794145942

Epoch: 5| Step: 5
Training loss: 1.0919865697621718
Validation loss: 2.678557258598752

Epoch: 5| Step: 6
Training loss: 0.5838666561218976
Validation loss: 2.667876220111359

Epoch: 5| Step: 7
Training loss: 0.5796859134539257
Validation loss: 2.6813675495276743

Epoch: 5| Step: 8
Training loss: 0.7335331738439077
Validation loss: 2.6908605822440377

Epoch: 5| Step: 9
Training loss: 0.8193476861377387
Validation loss: 2.569199267852933

Epoch: 5| Step: 10
Training loss: 0.532373026722146
Validation loss: 2.678854450456672

Epoch: 5| Step: 11
Training loss: 1.5826179829227915
Validation loss: 2.695228195714839

Epoch: 242| Step: 0
Training loss: 0.6347108553219412
Validation loss: 2.704391939647786

Epoch: 5| Step: 1
Training loss: 0.5091081961957151
Validation loss: 2.6433198145965267

Epoch: 5| Step: 2
Training loss: 0.7023498288783682
Validation loss: 2.684925241367865

Epoch: 5| Step: 3
Training loss: 1.1521369360559701
Validation loss: 2.6929339616249552

Epoch: 5| Step: 4
Training loss: 0.542913145881922
Validation loss: 2.727339195816607

Epoch: 5| Step: 5
Training loss: 0.7101146421424124
Validation loss: 2.6179776607351535

Epoch: 5| Step: 6
Training loss: 0.8389663016016099
Validation loss: 2.6374287231058693

Epoch: 5| Step: 7
Training loss: 0.5976040387254613
Validation loss: 2.678625967931296

Epoch: 5| Step: 8
Training loss: 0.7712132617355278
Validation loss: 2.6375585033533238

Epoch: 5| Step: 9
Training loss: 0.7793626494603005
Validation loss: 2.7120230568932024

Epoch: 5| Step: 10
Training loss: 0.5454824975105361
Validation loss: 2.6827600249229744

Epoch: 5| Step: 11
Training loss: 0.5671738783196371
Validation loss: 2.6387388125347657

Epoch: 243| Step: 0
Training loss: 0.6121145923735398
Validation loss: 2.6623595752906546

Epoch: 5| Step: 1
Training loss: 0.7799169229623258
Validation loss: 2.7121545879337514

Epoch: 5| Step: 2
Training loss: 0.7031539487177624
Validation loss: 2.7117765156168834

Epoch: 5| Step: 3
Training loss: 0.4857402450222048
Validation loss: 2.662214949248004

Epoch: 5| Step: 4
Training loss: 0.4213923413022017
Validation loss: 2.685238060043938

Epoch: 5| Step: 5
Training loss: 0.9518423048028665
Validation loss: 2.740567791340599

Epoch: 5| Step: 6
Training loss: 0.7286312226327362
Validation loss: 2.674492604123797

Epoch: 5| Step: 7
Training loss: 0.47900679934499973
Validation loss: 2.7213262979397657

Epoch: 5| Step: 8
Training loss: 1.017172236408617
Validation loss: 2.7245915274451384

Epoch: 5| Step: 9
Training loss: 0.5025105924581172
Validation loss: 2.7022041670743056

Epoch: 5| Step: 10
Training loss: 0.5966406526923939
Validation loss: 2.680825283851511

Epoch: 5| Step: 11
Training loss: 1.4659678304246953
Validation loss: 2.699034559900194

Epoch: 244| Step: 0
Training loss: 0.7504609201639542
Validation loss: 2.7020009630972375

Epoch: 5| Step: 1
Training loss: 0.8890442455811134
Validation loss: 2.7300505784057245

Epoch: 5| Step: 2
Training loss: 0.6346133709755543
Validation loss: 2.701711104810205

Epoch: 5| Step: 3
Training loss: 0.44021780664902493
Validation loss: 2.6534354239101403

Epoch: 5| Step: 4
Training loss: 0.4630287382854937
Validation loss: 2.6987561180442357

Epoch: 5| Step: 5
Training loss: 0.8455827376243042
Validation loss: 2.628458167211687

Epoch: 5| Step: 6
Training loss: 0.6189017331354107
Validation loss: 2.6053533990843607

Epoch: 5| Step: 7
Training loss: 0.7560122628554576
Validation loss: 2.645056326355942

Epoch: 5| Step: 8
Training loss: 0.6839994697931253
Validation loss: 2.6437487174617944

Epoch: 5| Step: 9
Training loss: 0.9644775313375087
Validation loss: 2.6917261119061378

Epoch: 5| Step: 10
Training loss: 0.4795826750794154
Validation loss: 2.626446681028694

Epoch: 5| Step: 11
Training loss: 0.39808701077940645
Validation loss: 2.6128795621073824

Epoch: 245| Step: 0
Training loss: 0.4893348770209285
Validation loss: 2.6341208537855705

Epoch: 5| Step: 1
Training loss: 0.5916884168692521
Validation loss: 2.71024447587347

Epoch: 5| Step: 2
Training loss: 0.7493842696888386
Validation loss: 2.671169407202535

Epoch: 5| Step: 3
Training loss: 0.43485314241519346
Validation loss: 2.639801408590515

Epoch: 5| Step: 4
Training loss: 0.8177032754016769
Validation loss: 2.67932347752887

Epoch: 5| Step: 5
Training loss: 0.4751809998789813
Validation loss: 2.6434168982275152

Epoch: 5| Step: 6
Training loss: 0.7841104783316326
Validation loss: 2.621298530413145

Epoch: 5| Step: 7
Training loss: 0.7643532213553543
Validation loss: 2.6663059919546472

Epoch: 5| Step: 8
Training loss: 1.0253465624833444
Validation loss: 2.6532630844038003

Epoch: 5| Step: 9
Training loss: 0.8341370918475636
Validation loss: 2.7087529676521167

Epoch: 5| Step: 10
Training loss: 0.5137412600922443
Validation loss: 2.7138047789391377

Epoch: 5| Step: 11
Training loss: 0.3215100070751569
Validation loss: 2.616860303780575

Epoch: 246| Step: 0
Training loss: 0.7231148166978043
Validation loss: 2.675298858002982

Epoch: 5| Step: 1
Training loss: 0.6554572221472017
Validation loss: 2.6983212581263802

Epoch: 5| Step: 2
Training loss: 0.646437674964867
Validation loss: 2.6513327468124532

Epoch: 5| Step: 3
Training loss: 1.0594574055086967
Validation loss: 2.7065363950475767

Epoch: 5| Step: 4
Training loss: 0.5115604883898949
Validation loss: 2.6564437234583638

Epoch: 5| Step: 5
Training loss: 0.6160372626859214
Validation loss: 2.7146760774423857

Epoch: 5| Step: 6
Training loss: 0.6676363647842105
Validation loss: 2.647332488888254

Epoch: 5| Step: 7
Training loss: 0.595606361409757
Validation loss: 2.6821824369442386

Epoch: 5| Step: 8
Training loss: 0.7707963797157127
Validation loss: 2.600344280074238

Epoch: 5| Step: 9
Training loss: 0.7014802132587247
Validation loss: 2.6788176894139255

Epoch: 5| Step: 10
Training loss: 0.7832197534788895
Validation loss: 2.699452965562806

Epoch: 5| Step: 11
Training loss: 0.33860496027141584
Validation loss: 2.661799076212984

Epoch: 247| Step: 0
Training loss: 0.43249051756193524
Validation loss: 2.6863370567499825

Epoch: 5| Step: 1
Training loss: 1.1212135277539335
Validation loss: 2.702160473920703

Epoch: 5| Step: 2
Training loss: 0.7172693259905427
Validation loss: 2.6639125778060735

Epoch: 5| Step: 3
Training loss: 0.6375987051302111
Validation loss: 2.674890415377252

Epoch: 5| Step: 4
Training loss: 0.5639927448455373
Validation loss: 2.70794800927221

Epoch: 5| Step: 5
Training loss: 0.6967483653489761
Validation loss: 2.643677562896629

Epoch: 5| Step: 6
Training loss: 0.920328750855467
Validation loss: 2.6905669078691994

Epoch: 5| Step: 7
Training loss: 0.7700948442530976
Validation loss: 2.558334481107556

Epoch: 5| Step: 8
Training loss: 0.5119389067686283
Validation loss: 2.6233187544279044

Epoch: 5| Step: 9
Training loss: 0.5774583065373254
Validation loss: 2.7281455278443603

Epoch: 5| Step: 10
Training loss: 0.6640307699364494
Validation loss: 2.6217795326211553

Epoch: 5| Step: 11
Training loss: 0.49866224680956706
Validation loss: 2.726798261416174

Epoch: 248| Step: 0
Training loss: 0.5393027723803101
Validation loss: 2.6384573095556108

Epoch: 5| Step: 1
Training loss: 0.573114280142833
Validation loss: 2.6836248115618733

Epoch: 5| Step: 2
Training loss: 0.8399111698502025
Validation loss: 2.6939185735142113

Epoch: 5| Step: 3
Training loss: 0.5242279120154845
Validation loss: 2.6461673673396695

Epoch: 5| Step: 4
Training loss: 0.6032787463045568
Validation loss: 2.7253386001319844

Epoch: 5| Step: 5
Training loss: 0.714678135432318
Validation loss: 2.6665372755031185

Epoch: 5| Step: 6
Training loss: 0.7110173107245015
Validation loss: 2.6147552271617247

Epoch: 5| Step: 7
Training loss: 0.9871866851832259
Validation loss: 2.6582955543580002

Epoch: 5| Step: 8
Training loss: 0.677980581630022
Validation loss: 2.6608360363022334

Epoch: 5| Step: 9
Training loss: 0.5899294860373113
Validation loss: 2.7070627362070168

Epoch: 5| Step: 10
Training loss: 0.7677871380701726
Validation loss: 2.6896281465913634

Epoch: 5| Step: 11
Training loss: 1.3449444009144795
Validation loss: 2.6613063557350984

Epoch: 249| Step: 0
Training loss: 0.5953930907879765
Validation loss: 2.7302416960361144

Epoch: 5| Step: 1
Training loss: 0.9471624888481738
Validation loss: 2.607135885606317

Epoch: 5| Step: 2
Training loss: 0.6341022722640607
Validation loss: 2.79088577100125

Epoch: 5| Step: 3
Training loss: 0.505257473027279
Validation loss: 2.657760160911221

Epoch: 5| Step: 4
Training loss: 1.1169193719674924
Validation loss: 2.644844585058066

Epoch: 5| Step: 5
Training loss: 0.560294330342747
Validation loss: 2.651092567529769

Epoch: 5| Step: 6
Training loss: 0.5223474397109631
Validation loss: 2.669971025633551

Epoch: 5| Step: 7
Training loss: 0.5393445203264945
Validation loss: 2.6734298881334704

Epoch: 5| Step: 8
Training loss: 0.5205013138757223
Validation loss: 2.6304254473724917

Epoch: 5| Step: 9
Training loss: 0.7598451705125493
Validation loss: 2.656370766082243

Epoch: 5| Step: 10
Training loss: 0.6275375114490611
Validation loss: 2.6797242973032875

Epoch: 5| Step: 11
Training loss: 0.4550758492736235
Validation loss: 2.738432455128233

Epoch: 250| Step: 0
Training loss: 0.5744882327552092
Validation loss: 2.6990300290591547

Epoch: 5| Step: 1
Training loss: 0.6517367708526544
Validation loss: 2.667743705019493

Epoch: 5| Step: 2
Training loss: 0.9367980872528069
Validation loss: 2.68384537865974

Epoch: 5| Step: 3
Training loss: 0.6926207140432118
Validation loss: 2.706797099296453

Epoch: 5| Step: 4
Training loss: 0.5351847620141922
Validation loss: 2.701009466438083

Epoch: 5| Step: 5
Training loss: 0.8214623521291625
Validation loss: 2.7074348879059142

Epoch: 5| Step: 6
Training loss: 1.034108679101414
Validation loss: 2.757412648233963

Epoch: 5| Step: 7
Training loss: 0.7887514464399856
Validation loss: 2.7726617758058008

Epoch: 5| Step: 8
Training loss: 0.6278627161172016
Validation loss: 2.850660611714795

Epoch: 5| Step: 9
Training loss: 0.6551763971507506
Validation loss: 2.8040035302849193

Epoch: 5| Step: 10
Training loss: 0.5907554149452158
Validation loss: 2.772415793188954

Epoch: 5| Step: 11
Training loss: 0.7756024895167223
Validation loss: 2.738011113300066

Epoch: 251| Step: 0
Training loss: 0.5573379699390203
Validation loss: 2.788018302742926

Epoch: 5| Step: 1
Training loss: 0.46388771413259683
Validation loss: 2.686413415920593

Epoch: 5| Step: 2
Training loss: 0.759991766608965
Validation loss: 2.634931366356579

Epoch: 5| Step: 3
Training loss: 0.7204011527428732
Validation loss: 2.708171811544772

Epoch: 5| Step: 4
Training loss: 0.612262900841569
Validation loss: 2.6754732757573447

Epoch: 5| Step: 5
Training loss: 0.5053751922293804
Validation loss: 2.670110766992083

Epoch: 5| Step: 6
Training loss: 0.8666810971366941
Validation loss: 2.6825082703818715

Epoch: 5| Step: 7
Training loss: 0.7740663226344711
Validation loss: 2.658623902415828

Epoch: 5| Step: 8
Training loss: 0.9121954344312566
Validation loss: 2.73907473717912

Epoch: 5| Step: 9
Training loss: 0.6992351167777232
Validation loss: 2.780639431402167

Epoch: 5| Step: 10
Training loss: 0.612195724696884
Validation loss: 2.7428872645671705

Epoch: 5| Step: 11
Training loss: 1.0657247524613136
Validation loss: 2.7219314559121153

Epoch: 252| Step: 0
Training loss: 0.585385940351773
Validation loss: 2.7398651048248475

Epoch: 5| Step: 1
Training loss: 0.9400862624276595
Validation loss: 2.654067777431315

Epoch: 5| Step: 2
Training loss: 0.6411604388195409
Validation loss: 2.6907569017027293

Epoch: 5| Step: 3
Training loss: 0.4897640145123671
Validation loss: 2.6949252859421073

Epoch: 5| Step: 4
Training loss: 0.6742047128288022
Validation loss: 2.5771994152667106

Epoch: 5| Step: 5
Training loss: 0.6223616703718315
Validation loss: 2.629378364723446

Epoch: 5| Step: 6
Training loss: 0.7089266162390994
Validation loss: 2.7702997107299336

Epoch: 5| Step: 7
Training loss: 0.9356395699405632
Validation loss: 2.6948056836397134

Epoch: 5| Step: 8
Training loss: 0.6161671666772802
Validation loss: 2.783118238437314

Epoch: 5| Step: 9
Training loss: 0.7244648750773185
Validation loss: 2.6982924385007454

Epoch: 5| Step: 10
Training loss: 0.8916337842017904
Validation loss: 2.801492746977274

Epoch: 5| Step: 11
Training loss: 0.5455484377180233
Validation loss: 2.656161033786047

Epoch: 253| Step: 0
Training loss: 0.5529152402401855
Validation loss: 2.6748016271983377

Epoch: 5| Step: 1
Training loss: 0.7239311725452239
Validation loss: 2.660186315544914

Epoch: 5| Step: 2
Training loss: 0.7382060017662422
Validation loss: 2.675837209445883

Epoch: 5| Step: 3
Training loss: 0.628556811949229
Validation loss: 2.690363701889863

Epoch: 5| Step: 4
Training loss: 0.6754353029157653
Validation loss: 2.5940230045881867

Epoch: 5| Step: 5
Training loss: 0.39026692190755474
Validation loss: 2.660792053990438

Epoch: 5| Step: 6
Training loss: 1.1704680070835252
Validation loss: 2.6579661528800567

Epoch: 5| Step: 7
Training loss: 0.6224036169695992
Validation loss: 2.66202179878284

Epoch: 5| Step: 8
Training loss: 0.8069649476163873
Validation loss: 2.6951226872489564

Epoch: 5| Step: 9
Training loss: 0.4454072884850161
Validation loss: 2.6111916539917392

Epoch: 5| Step: 10
Training loss: 0.6727585416809385
Validation loss: 2.6892060475932955

Epoch: 5| Step: 11
Training loss: 0.31895334031606964
Validation loss: 2.661157140591443

Epoch: 254| Step: 0
Training loss: 0.7505728203061351
Validation loss: 2.6470883138993955

Epoch: 5| Step: 1
Training loss: 0.6618193044454074
Validation loss: 2.7498558505165036

Epoch: 5| Step: 2
Training loss: 0.6323250199832038
Validation loss: 2.661333179455079

Epoch: 5| Step: 3
Training loss: 0.820926654338892
Validation loss: 2.6425029502414294

Epoch: 5| Step: 4
Training loss: 0.6358846806516119
Validation loss: 2.713318598993896

Epoch: 5| Step: 5
Training loss: 0.7006674309438111
Validation loss: 2.6780131292550724

Epoch: 5| Step: 6
Training loss: 0.8609982505452706
Validation loss: 2.6430397504515595

Epoch: 5| Step: 7
Training loss: 0.738880055915728
Validation loss: 2.7056490078832676

Epoch: 5| Step: 8
Training loss: 0.4279303080189958
Validation loss: 2.7149685142628015

Epoch: 5| Step: 9
Training loss: 0.4786979172366646
Validation loss: 2.712657891935793

Epoch: 5| Step: 10
Training loss: 0.5001294743271731
Validation loss: 2.6301104436101457

Epoch: 5| Step: 11
Training loss: 0.9443898703353002
Validation loss: 2.726988889332822

Epoch: 255| Step: 0
Training loss: 0.6111490151783223
Validation loss: 2.6658469234091133

Epoch: 5| Step: 1
Training loss: 0.8284642945988873
Validation loss: 2.6371610934475402

Epoch: 5| Step: 2
Training loss: 1.0928962099926713
Validation loss: 2.6732774440967124

Epoch: 5| Step: 3
Training loss: 0.668147481463378
Validation loss: 2.6332970577972645

Epoch: 5| Step: 4
Training loss: 0.8488913472589654
Validation loss: 2.7061001642931135

Epoch: 5| Step: 5
Training loss: 0.38930503991292054
Validation loss: 2.6714349276469718

Epoch: 5| Step: 6
Training loss: 0.7643543520717376
Validation loss: 2.755961604827755

Epoch: 5| Step: 7
Training loss: 0.7452857150657013
Validation loss: 2.671816265657844

Epoch: 5| Step: 8
Training loss: 0.5204306539921533
Validation loss: 2.751819871790255

Epoch: 5| Step: 9
Training loss: 0.5520810960928253
Validation loss: 2.6921595223822314

Epoch: 5| Step: 10
Training loss: 0.5522864046233449
Validation loss: 2.7487075651292527

Epoch: 5| Step: 11
Training loss: 0.23538089110426424
Validation loss: 2.7047202083520556

Epoch: 256| Step: 0
Training loss: 0.6055815314803328
Validation loss: 2.6273826994756275

Epoch: 5| Step: 1
Training loss: 0.8552724186206715
Validation loss: 2.6470481506664387

Epoch: 5| Step: 2
Training loss: 0.47377457217805635
Validation loss: 2.658740674821372

Epoch: 5| Step: 3
Training loss: 0.5245123119418367
Validation loss: 2.661553395484042

Epoch: 5| Step: 4
Training loss: 0.5497974510461968
Validation loss: 2.739796239801566

Epoch: 5| Step: 5
Training loss: 0.597180295428659
Validation loss: 2.604701694204995

Epoch: 5| Step: 6
Training loss: 0.7751144570770334
Validation loss: 2.6698466515705306

Epoch: 5| Step: 7
Training loss: 0.5197806942634683
Validation loss: 2.6826728043856503

Epoch: 5| Step: 8
Training loss: 1.123418225798185
Validation loss: 2.7010490553215782

Epoch: 5| Step: 9
Training loss: 0.4559939913824386
Validation loss: 2.6542737415719415

Epoch: 5| Step: 10
Training loss: 0.6657969991329286
Validation loss: 2.704141987794276

Epoch: 5| Step: 11
Training loss: 0.73328745239678
Validation loss: 2.783444321203134

Epoch: 257| Step: 0
Training loss: 0.48108805309563885
Validation loss: 2.637866481070037

Epoch: 5| Step: 1
Training loss: 0.5101696182065067
Validation loss: 2.6116292262046104

Epoch: 5| Step: 2
Training loss: 0.6533799764306095
Validation loss: 2.6852707229585073

Epoch: 5| Step: 3
Training loss: 0.41376463054593515
Validation loss: 2.674653696062802

Epoch: 5| Step: 4
Training loss: 0.3405456638686576
Validation loss: 2.7160008514615517

Epoch: 5| Step: 5
Training loss: 0.5966452231185654
Validation loss: 2.6571602365033575

Epoch: 5| Step: 6
Training loss: 0.9165714749125417
Validation loss: 2.6624128019951643

Epoch: 5| Step: 7
Training loss: 0.6457788126502847
Validation loss: 2.702496439007752

Epoch: 5| Step: 8
Training loss: 1.0519481546912786
Validation loss: 2.755478160075253

Epoch: 5| Step: 9
Training loss: 0.8289841927170565
Validation loss: 2.6578774907925222

Epoch: 5| Step: 10
Training loss: 0.6769458459989975
Validation loss: 2.6591338266823232

Epoch: 5| Step: 11
Training loss: 0.4370433774594532
Validation loss: 2.73249710266667

Epoch: 258| Step: 0
Training loss: 0.6332536737220245
Validation loss: 2.713243930661417

Epoch: 5| Step: 1
Training loss: 0.6094098692478854
Validation loss: 2.7083115515688885

Epoch: 5| Step: 2
Training loss: 0.43266318530926445
Validation loss: 2.707458865991254

Epoch: 5| Step: 3
Training loss: 0.44541598673531596
Validation loss: 2.718774280220441

Epoch: 5| Step: 4
Training loss: 0.5867434744063655
Validation loss: 2.6655121752946815

Epoch: 5| Step: 5
Training loss: 0.8440362656607531
Validation loss: 2.739880815220279

Epoch: 5| Step: 6
Training loss: 0.4787268814550759
Validation loss: 2.699211466549856

Epoch: 5| Step: 7
Training loss: 0.4874861232298643
Validation loss: 2.7526248015632095

Epoch: 5| Step: 8
Training loss: 0.6666953905195999
Validation loss: 2.632055681310946

Epoch: 5| Step: 9
Training loss: 1.2164555984904484
Validation loss: 2.60300585369913

Epoch: 5| Step: 10
Training loss: 0.5970163597360593
Validation loss: 2.6457217836268856

Epoch: 5| Step: 11
Training loss: 0.28591910964943534
Validation loss: 2.690623708053438

Epoch: 259| Step: 0
Training loss: 0.5887855485846587
Validation loss: 2.719318524107885

Epoch: 5| Step: 1
Training loss: 0.7493358691564033
Validation loss: 2.704133714691632

Epoch: 5| Step: 2
Training loss: 0.6984972507938794
Validation loss: 2.692479899891333

Epoch: 5| Step: 3
Training loss: 0.8997960641065613
Validation loss: 2.817251597962544

Epoch: 5| Step: 4
Training loss: 0.46825914113724537
Validation loss: 2.7040679367471023

Epoch: 5| Step: 5
Training loss: 0.6928629427773839
Validation loss: 2.635486512647004

Epoch: 5| Step: 6
Training loss: 0.3541986600599571
Validation loss: 2.6493431725809664

Epoch: 5| Step: 7
Training loss: 0.8145462092715025
Validation loss: 2.6755410933561357

Epoch: 5| Step: 8
Training loss: 0.4454740599306094
Validation loss: 2.664164898229145

Epoch: 5| Step: 9
Training loss: 0.7317445598695919
Validation loss: 2.746540335331655

Epoch: 5| Step: 10
Training loss: 0.5807317525580842
Validation loss: 2.7037989413881274

Epoch: 5| Step: 11
Training loss: 0.4354384591004568
Validation loss: 2.7438884144065363

Epoch: 260| Step: 0
Training loss: 0.44461686193221645
Validation loss: 2.6631258476725685

Epoch: 5| Step: 1
Training loss: 0.5089509087873463
Validation loss: 2.7247235911139214

Epoch: 5| Step: 2
Training loss: 0.6154302860355161
Validation loss: 2.6921593692466286

Epoch: 5| Step: 3
Training loss: 0.6925564051975202
Validation loss: 2.724281785383551

Epoch: 5| Step: 4
Training loss: 0.9474788465126428
Validation loss: 2.644168207144286

Epoch: 5| Step: 5
Training loss: 0.742780508749497
Validation loss: 2.656393426874999

Epoch: 5| Step: 6
Training loss: 0.5384672997763809
Validation loss: 2.658164912352534

Epoch: 5| Step: 7
Training loss: 0.9738894079506446
Validation loss: 2.646545799828179

Epoch: 5| Step: 8
Training loss: 0.4322099685069223
Validation loss: 2.694023550206518

Epoch: 5| Step: 9
Training loss: 0.5549886450164393
Validation loss: 2.7096917279301076

Epoch: 5| Step: 10
Training loss: 0.694796467144428
Validation loss: 2.705223022693289

Epoch: 5| Step: 11
Training loss: 0.3754330558494771
Validation loss: 2.7861716161557943

Epoch: 261| Step: 0
Training loss: 0.6464157298543021
Validation loss: 2.6667835848231127

Epoch: 5| Step: 1
Training loss: 0.46327671415479044
Validation loss: 2.6947379674723373

Epoch: 5| Step: 2
Training loss: 0.41614958348054587
Validation loss: 2.6396183563072704

Epoch: 5| Step: 3
Training loss: 0.8064944894605939
Validation loss: 2.693198704785492

Epoch: 5| Step: 4
Training loss: 0.7192507119279665
Validation loss: 2.617152911285037

Epoch: 5| Step: 5
Training loss: 0.8806074166962217
Validation loss: 2.6911583367799166

Epoch: 5| Step: 6
Training loss: 0.45410454861879407
Validation loss: 2.6939278976071876

Epoch: 5| Step: 7
Training loss: 0.5789959249913076
Validation loss: 2.6669285739988506

Epoch: 5| Step: 8
Training loss: 0.8896414361839456
Validation loss: 2.712805068971853

Epoch: 5| Step: 9
Training loss: 0.4848595164787674
Validation loss: 2.6644429767637035

Epoch: 5| Step: 10
Training loss: 0.5312213890000708
Validation loss: 2.714538655873427

Epoch: 5| Step: 11
Training loss: 0.7628991004953546
Validation loss: 2.688449359261494

Epoch: 262| Step: 0
Training loss: 0.8392517132234515
Validation loss: 2.6240257279263375

Epoch: 5| Step: 1
Training loss: 0.614969977832334
Validation loss: 2.6687574137838572

Epoch: 5| Step: 2
Training loss: 0.5153520902250595
Validation loss: 2.7453929355962208

Epoch: 5| Step: 3
Training loss: 0.6368682077436844
Validation loss: 2.6767985319844194

Epoch: 5| Step: 4
Training loss: 0.5191595138661215
Validation loss: 2.745074076061247

Epoch: 5| Step: 5
Training loss: 0.8750698197982774
Validation loss: 2.746530182525658

Epoch: 5| Step: 6
Training loss: 0.5525362717904212
Validation loss: 2.7874622936863185

Epoch: 5| Step: 7
Training loss: 0.6929779938056551
Validation loss: 2.78009558589959

Epoch: 5| Step: 8
Training loss: 0.4868842778772588
Validation loss: 2.6635621012019564

Epoch: 5| Step: 9
Training loss: 0.4884037016867341
Validation loss: 2.70915292418589

Epoch: 5| Step: 10
Training loss: 0.665226488408252
Validation loss: 2.7059477729101604

Epoch: 5| Step: 11
Training loss: 0.27790986966901104
Validation loss: 2.7655390566243505

Epoch: 263| Step: 0
Training loss: 0.8516634959953795
Validation loss: 2.703792735776274

Epoch: 5| Step: 1
Training loss: 0.7272549272791912
Validation loss: 2.6225970373210696

Epoch: 5| Step: 2
Training loss: 0.7549359893821612
Validation loss: 2.723115795581932

Epoch: 5| Step: 3
Training loss: 0.4741821406906152
Validation loss: 2.6997074102589016

Epoch: 5| Step: 4
Training loss: 0.6341396355559565
Validation loss: 2.7632827251165435

Epoch: 5| Step: 5
Training loss: 0.674863379392362
Validation loss: 2.7801354707555848

Epoch: 5| Step: 6
Training loss: 0.571255335668107
Validation loss: 2.6659719815250926

Epoch: 5| Step: 7
Training loss: 0.4129166853808807
Validation loss: 2.7638934708215976

Epoch: 5| Step: 8
Training loss: 0.33500782274250784
Validation loss: 2.7848240215934923

Epoch: 5| Step: 9
Training loss: 0.39488214053308984
Validation loss: 2.7752631397752388

Epoch: 5| Step: 10
Training loss: 0.33369245654603147
Validation loss: 2.7191390858953515

Epoch: 5| Step: 11
Training loss: 1.284369926721062
Validation loss: 2.724076395533605

Epoch: 264| Step: 0
Training loss: 0.5815011497086027
Validation loss: 2.637491228893575

Epoch: 5| Step: 1
Training loss: 0.5084562183069279
Validation loss: 2.6830916288954367

Epoch: 5| Step: 2
Training loss: 0.8373231544531465
Validation loss: 2.76386436987203

Epoch: 5| Step: 3
Training loss: 0.6213091111028867
Validation loss: 2.727694443136315

Epoch: 5| Step: 4
Training loss: 0.4464818258538153
Validation loss: 2.7102880185437606

Epoch: 5| Step: 5
Training loss: 0.5783423968694174
Validation loss: 2.6813837230714106

Epoch: 5| Step: 6
Training loss: 0.4567291532904884
Validation loss: 2.6643981722120045

Epoch: 5| Step: 7
Training loss: 0.8976042158883751
Validation loss: 2.750132705636531

Epoch: 5| Step: 8
Training loss: 0.6687922170272875
Validation loss: 2.7592296507338676

Epoch: 5| Step: 9
Training loss: 0.7180250492375249
Validation loss: 2.7332935810590557

Epoch: 5| Step: 10
Training loss: 0.587500281029492
Validation loss: 2.7524063607092164

Epoch: 5| Step: 11
Training loss: 0.3326562160816238
Validation loss: 2.7173770382893685

Epoch: 265| Step: 0
Training loss: 0.5876423257538769
Validation loss: 2.6116128489051995

Epoch: 5| Step: 1
Training loss: 0.5353075634962013
Validation loss: 2.6984147762069974

Epoch: 5| Step: 2
Training loss: 0.5601122829574494
Validation loss: 2.662917669575916

Epoch: 5| Step: 3
Training loss: 0.6172711762310352
Validation loss: 2.6864902758218516

Epoch: 5| Step: 4
Training loss: 0.619434178794261
Validation loss: 2.6377102379374846

Epoch: 5| Step: 5
Training loss: 1.099955042007011
Validation loss: 2.7844604507617783

Epoch: 5| Step: 6
Training loss: 0.8984417459138802
Validation loss: 2.80196548885346

Epoch: 5| Step: 7
Training loss: 0.9017770812661381
Validation loss: 2.798269155249935

Epoch: 5| Step: 8
Training loss: 0.9151689076993375
Validation loss: 2.881764632415489

Epoch: 5| Step: 9
Training loss: 0.42206579768190255
Validation loss: 2.670444507137298

Epoch: 5| Step: 10
Training loss: 0.591713222722624
Validation loss: 2.6608088995575003

Epoch: 5| Step: 11
Training loss: 0.2591142446748958
Validation loss: 2.6964940673972237

Epoch: 266| Step: 0
Training loss: 0.7391043217703609
Validation loss: 2.683846570524934

Epoch: 5| Step: 1
Training loss: 0.6749107840530076
Validation loss: 2.640296345635487

Epoch: 5| Step: 2
Training loss: 0.5905589384645183
Validation loss: 2.667385849358923

Epoch: 5| Step: 3
Training loss: 0.9079669932550448
Validation loss: 2.677848577904452

Epoch: 5| Step: 4
Training loss: 0.6363323419945204
Validation loss: 2.59420456790492

Epoch: 5| Step: 5
Training loss: 0.5583476344692063
Validation loss: 2.704667538768113

Epoch: 5| Step: 6
Training loss: 0.9181510581933787
Validation loss: 2.7142305774872786

Epoch: 5| Step: 7
Training loss: 0.9924433821280367
Validation loss: 2.760521232975659

Epoch: 5| Step: 8
Training loss: 0.5211809968900608
Validation loss: 2.7891110310040927

Epoch: 5| Step: 9
Training loss: 0.701027220359413
Validation loss: 2.7260111713173525

Epoch: 5| Step: 10
Training loss: 0.5771112575270501
Validation loss: 2.6925465272633766

Epoch: 5| Step: 11
Training loss: 0.8722897175640387
Validation loss: 2.6060951505562295

Epoch: 267| Step: 0
Training loss: 0.7538876704165005
Validation loss: 2.6578134199227206

Epoch: 5| Step: 1
Training loss: 0.5231758716417949
Validation loss: 2.7133792906715075

Epoch: 5| Step: 2
Training loss: 0.43181195893435276
Validation loss: 2.6558677809733218

Epoch: 5| Step: 3
Training loss: 0.6346524416445662
Validation loss: 2.695176604894744

Epoch: 5| Step: 4
Training loss: 0.6926559963866944
Validation loss: 2.815748429777185

Epoch: 5| Step: 5
Training loss: 0.7547454116747526
Validation loss: 2.7894312866763515

Epoch: 5| Step: 6
Training loss: 0.6297286917037184
Validation loss: 2.740663483515151

Epoch: 5| Step: 7
Training loss: 0.9502736889466457
Validation loss: 2.8026378229503863

Epoch: 5| Step: 8
Training loss: 0.8710668585351351
Validation loss: 2.8241282053283583

Epoch: 5| Step: 9
Training loss: 0.6194680488358075
Validation loss: 2.694756543599431

Epoch: 5| Step: 10
Training loss: 0.5030388574721105
Validation loss: 2.784420292489855

Epoch: 5| Step: 11
Training loss: 0.5960746232110181
Validation loss: 2.69144142175881

Epoch: 268| Step: 0
Training loss: 0.8985923633621122
Validation loss: 2.7265887218187244

Epoch: 5| Step: 1
Training loss: 0.7020440587756502
Validation loss: 2.7639557332087294

Epoch: 5| Step: 2
Training loss: 0.7330683182368309
Validation loss: 2.731495501834881

Epoch: 5| Step: 3
Training loss: 0.516063648100171
Validation loss: 2.6998714848385736

Epoch: 5| Step: 4
Training loss: 0.719365975516393
Validation loss: 2.7047929597418774

Epoch: 5| Step: 5
Training loss: 0.48872289901973365
Validation loss: 2.760503685977158

Epoch: 5| Step: 6
Training loss: 0.7672575458318378
Validation loss: 2.7041928197970457

Epoch: 5| Step: 7
Training loss: 0.9078045370307494
Validation loss: 2.762008040337964

Epoch: 5| Step: 8
Training loss: 0.5676023547677491
Validation loss: 2.734900251530396

Epoch: 5| Step: 9
Training loss: 0.8527835176490796
Validation loss: 2.683986755349311

Epoch: 5| Step: 10
Training loss: 0.5458383544176482
Validation loss: 2.687816885814615

Epoch: 5| Step: 11
Training loss: 0.609396249449531
Validation loss: 2.627519019530203

Epoch: 269| Step: 0
Training loss: 0.6660514889007667
Validation loss: 2.638317341285124

Epoch: 5| Step: 1
Training loss: 0.7024118833835722
Validation loss: 2.633727930453567

Epoch: 5| Step: 2
Training loss: 0.49080779442571076
Validation loss: 2.691753516380588

Epoch: 5| Step: 3
Training loss: 0.6118025477515
Validation loss: 2.693263879548729

Epoch: 5| Step: 4
Training loss: 0.4672907367560422
Validation loss: 2.720448383674781

Epoch: 5| Step: 5
Training loss: 0.6069690206044255
Validation loss: 2.632322437472346

Epoch: 5| Step: 6
Training loss: 0.5614562948139201
Validation loss: 2.713975819777619

Epoch: 5| Step: 7
Training loss: 0.5171743869559715
Validation loss: 2.685623940951528

Epoch: 5| Step: 8
Training loss: 0.5874334946995151
Validation loss: 2.7812757133695403

Epoch: 5| Step: 9
Training loss: 0.7874149836713563
Validation loss: 2.7498628625487878

Epoch: 5| Step: 10
Training loss: 1.0086673984482912
Validation loss: 2.7345557888755048

Epoch: 5| Step: 11
Training loss: 0.500635309720411
Validation loss: 2.662279645550017

Epoch: 270| Step: 0
Training loss: 1.1075442076701338
Validation loss: 2.7574468843999638

Epoch: 5| Step: 1
Training loss: 0.727194521435264
Validation loss: 2.765216703861853

Epoch: 5| Step: 2
Training loss: 0.377690024864119
Validation loss: 2.7529189231493407

Epoch: 5| Step: 3
Training loss: 0.54639601848689
Validation loss: 2.7299525619351352

Epoch: 5| Step: 4
Training loss: 0.5786987241601401
Validation loss: 2.734158022309877

Epoch: 5| Step: 5
Training loss: 0.5277462024055146
Validation loss: 2.8151972799696505

Epoch: 5| Step: 6
Training loss: 0.6528441970821474
Validation loss: 2.7667099177089813

Epoch: 5| Step: 7
Training loss: 0.44879320969990877
Validation loss: 2.7200413264379484

Epoch: 5| Step: 8
Training loss: 0.5947576555414394
Validation loss: 2.686310201650467

Epoch: 5| Step: 9
Training loss: 0.5514423650176544
Validation loss: 2.7110987971652425

Epoch: 5| Step: 10
Training loss: 0.7576174140805926
Validation loss: 2.70021675749777

Epoch: 5| Step: 11
Training loss: 0.5103815092577493
Validation loss: 2.690343155020299

Epoch: 271| Step: 0
Training loss: 0.43123142990267116
Validation loss: 2.7409221414142912

Epoch: 5| Step: 1
Training loss: 0.5118720138145973
Validation loss: 2.7111889981773007

Epoch: 5| Step: 2
Training loss: 0.747983247526012
Validation loss: 2.697805398072763

Epoch: 5| Step: 3
Training loss: 0.8055362854402958
Validation loss: 2.6924333684097577

Epoch: 5| Step: 4
Training loss: 0.604611238702745
Validation loss: 2.709715884014594

Epoch: 5| Step: 5
Training loss: 0.6106749631496516
Validation loss: 2.734458736772382

Epoch: 5| Step: 6
Training loss: 0.4523163848136628
Validation loss: 2.6726715525308276

Epoch: 5| Step: 7
Training loss: 0.8263117894948004
Validation loss: 2.636649841538442

Epoch: 5| Step: 8
Training loss: 0.5154368895518644
Validation loss: 2.6792792369771594

Epoch: 5| Step: 9
Training loss: 0.45215990616360746
Validation loss: 2.6803042199815392

Epoch: 5| Step: 10
Training loss: 0.5896469192005181
Validation loss: 2.7819264835783653

Epoch: 5| Step: 11
Training loss: 0.6134036968476767
Validation loss: 2.685707150387187

Epoch: 272| Step: 0
Training loss: 0.492515666489808
Validation loss: 2.6759048359121826

Epoch: 5| Step: 1
Training loss: 0.5246593959931471
Validation loss: 2.696095003805548

Epoch: 5| Step: 2
Training loss: 0.6859547415197905
Validation loss: 2.7293282174690794

Epoch: 5| Step: 3
Training loss: 0.5143674485126231
Validation loss: 2.690600100530178

Epoch: 5| Step: 4
Training loss: 0.44092415333209284
Validation loss: 2.648192849201247

Epoch: 5| Step: 5
Training loss: 0.6935190151347033
Validation loss: 2.6652124482930692

Epoch: 5| Step: 6
Training loss: 0.5106182932792626
Validation loss: 2.712252075537697

Epoch: 5| Step: 7
Training loss: 0.9356245992146196
Validation loss: 2.6823142683441095

Epoch: 5| Step: 8
Training loss: 0.6087372939881084
Validation loss: 2.6712898037398953

Epoch: 5| Step: 9
Training loss: 0.6250041246278084
Validation loss: 2.679939243365755

Epoch: 5| Step: 10
Training loss: 0.5136329723174844
Validation loss: 2.6869759640148043

Epoch: 5| Step: 11
Training loss: 0.6351535022859155
Validation loss: 2.7035570332281353

Epoch: 273| Step: 0
Training loss: 0.38376677547903804
Validation loss: 2.6687847172416843

Epoch: 5| Step: 1
Training loss: 0.7650111715585632
Validation loss: 2.74465185722596

Epoch: 5| Step: 2
Training loss: 0.6500081034301939
Validation loss: 2.749923520758681

Epoch: 5| Step: 3
Training loss: 0.5150269016165397
Validation loss: 2.6647652736662355

Epoch: 5| Step: 4
Training loss: 0.7968753739898402
Validation loss: 2.7071208452789763

Epoch: 5| Step: 5
Training loss: 0.7014574409783577
Validation loss: 2.609877164950672

Epoch: 5| Step: 6
Training loss: 0.9398891206541296
Validation loss: 2.707582231442856

Epoch: 5| Step: 7
Training loss: 0.3732225294141391
Validation loss: 2.788310921182377

Epoch: 5| Step: 8
Training loss: 0.5307224964574976
Validation loss: 2.69311320558652

Epoch: 5| Step: 9
Training loss: 0.5229852345207591
Validation loss: 2.8102874494745667

Epoch: 5| Step: 10
Training loss: 0.7187057979094571
Validation loss: 2.9117940573800527

Epoch: 5| Step: 11
Training loss: 0.553098201641331
Validation loss: 2.795630421407588

Epoch: 274| Step: 0
Training loss: 0.9251721466817059
Validation loss: 2.7560610572341777

Epoch: 5| Step: 1
Training loss: 0.500184799852463
Validation loss: 2.737737571736867

Epoch: 5| Step: 2
Training loss: 0.8343165359302293
Validation loss: 2.6637709486979118

Epoch: 5| Step: 3
Training loss: 0.7771540271282867
Validation loss: 2.691665330587317

Epoch: 5| Step: 4
Training loss: 0.5770187877772983
Validation loss: 2.629976667770867

Epoch: 5| Step: 5
Training loss: 0.6035126868117824
Validation loss: 2.6047343983096156

Epoch: 5| Step: 6
Training loss: 0.6532120550809252
Validation loss: 2.634613149579703

Epoch: 5| Step: 7
Training loss: 0.45872279078688444
Validation loss: 2.689662433015646

Epoch: 5| Step: 8
Training loss: 0.5371478812546548
Validation loss: 2.6786288996237926

Epoch: 5| Step: 9
Training loss: 0.5454502073931862
Validation loss: 2.6462811625445766

Epoch: 5| Step: 10
Training loss: 0.5035701192483238
Validation loss: 2.675578023799175

Epoch: 5| Step: 11
Training loss: 0.4331376193906834
Validation loss: 2.6877178835705937

Epoch: 275| Step: 0
Training loss: 0.4741294852239985
Validation loss: 2.6474764832955198

Epoch: 5| Step: 1
Training loss: 0.7825898697162097
Validation loss: 2.703699954853212

Epoch: 5| Step: 2
Training loss: 0.4668738170082803
Validation loss: 2.6305351369041383

Epoch: 5| Step: 3
Training loss: 0.6777188961668987
Validation loss: 2.6912271802708148

Epoch: 5| Step: 4
Training loss: 0.495515546486492
Validation loss: 2.667371900009675

Epoch: 5| Step: 5
Training loss: 0.6691893640550834
Validation loss: 2.6564393032161107

Epoch: 5| Step: 6
Training loss: 0.6552672520898454
Validation loss: 2.6465775401853584

Epoch: 5| Step: 7
Training loss: 0.6727828169253433
Validation loss: 2.6400064688239655

Epoch: 5| Step: 8
Training loss: 0.612840943909192
Validation loss: 2.685096963822297

Epoch: 5| Step: 9
Training loss: 0.4241085443258434
Validation loss: 2.7132249428877833

Epoch: 5| Step: 10
Training loss: 0.6245019358688171
Validation loss: 2.797921627780685

Epoch: 5| Step: 11
Training loss: 0.3829974292240567
Validation loss: 2.770106321817968

Epoch: 276| Step: 0
Training loss: 0.9526441956055093
Validation loss: 2.8280491089868898

Epoch: 5| Step: 1
Training loss: 0.8520832744184876
Validation loss: 2.772791078839375

Epoch: 5| Step: 2
Training loss: 0.6233696415427825
Validation loss: 2.7213159634526267

Epoch: 5| Step: 3
Training loss: 0.6974161664084523
Validation loss: 2.640648452383778

Epoch: 5| Step: 4
Training loss: 0.5825825071227578
Validation loss: 2.6849153051154344

Epoch: 5| Step: 5
Training loss: 0.662673462345341
Validation loss: 2.7091324153128586

Epoch: 5| Step: 6
Training loss: 0.477735186597208
Validation loss: 2.636197933046413

Epoch: 5| Step: 7
Training loss: 0.6548093013308457
Validation loss: 2.6578183947958847

Epoch: 5| Step: 8
Training loss: 0.6323674603261772
Validation loss: 2.7571465009563605

Epoch: 5| Step: 9
Training loss: 0.45581018726761724
Validation loss: 2.706853276320228

Epoch: 5| Step: 10
Training loss: 0.5487737119587186
Validation loss: 2.7556312911833585

Epoch: 5| Step: 11
Training loss: 0.637952697125906
Validation loss: 2.729133708890749

Epoch: 277| Step: 0
Training loss: 0.6262426182888613
Validation loss: 2.7679468060545185

Epoch: 5| Step: 1
Training loss: 0.5053389534428042
Validation loss: 2.7459713441456115

Epoch: 5| Step: 2
Training loss: 0.7957770693864107
Validation loss: 2.648794934019297

Epoch: 5| Step: 3
Training loss: 0.3527291649215026
Validation loss: 2.6941881239504917

Epoch: 5| Step: 4
Training loss: 0.918748954201447
Validation loss: 2.6979271558363767

Epoch: 5| Step: 5
Training loss: 0.5286309814872424
Validation loss: 2.725475338649034

Epoch: 5| Step: 6
Training loss: 0.5934841414086748
Validation loss: 2.6468008642762326

Epoch: 5| Step: 7
Training loss: 0.5980373488950087
Validation loss: 2.7188688321653

Epoch: 5| Step: 8
Training loss: 0.5934419585789166
Validation loss: 2.651836873059954

Epoch: 5| Step: 9
Training loss: 0.5860725247255059
Validation loss: 2.7102902104118645

Epoch: 5| Step: 10
Training loss: 0.6060212598476972
Validation loss: 2.668730467398021

Epoch: 5| Step: 11
Training loss: 0.4776502764487108
Validation loss: 2.669030378102454

Epoch: 278| Step: 0
Training loss: 0.6031845320341124
Validation loss: 2.7109024346069024

Epoch: 5| Step: 1
Training loss: 0.6317820931416882
Validation loss: 2.717758973686612

Epoch: 5| Step: 2
Training loss: 0.579191204164169
Validation loss: 2.6570479110857916

Epoch: 5| Step: 3
Training loss: 0.7443144988128374
Validation loss: 2.7341464828188804

Epoch: 5| Step: 4
Training loss: 0.44354402167305895
Validation loss: 2.7298751225776785

Epoch: 5| Step: 5
Training loss: 0.6399507230548781
Validation loss: 2.7391507976116016

Epoch: 5| Step: 6
Training loss: 0.5729361241822334
Validation loss: 2.68606039790207

Epoch: 5| Step: 7
Training loss: 0.5413430115068729
Validation loss: 2.6732444748495108

Epoch: 5| Step: 8
Training loss: 0.439182588166814
Validation loss: 2.7026178806731584

Epoch: 5| Step: 9
Training loss: 0.40767158689997157
Validation loss: 2.684274926649844

Epoch: 5| Step: 10
Training loss: 0.6618487540022161
Validation loss: 2.7595588730823293

Epoch: 5| Step: 11
Training loss: 1.5761537231761473
Validation loss: 2.6690879362140616

Epoch: 279| Step: 0
Training loss: 0.508964786460004
Validation loss: 2.73075112486737

Epoch: 5| Step: 1
Training loss: 0.7366876913180305
Validation loss: 2.7323738950125676

Epoch: 5| Step: 2
Training loss: 0.4620421314731961
Validation loss: 2.653147235383285

Epoch: 5| Step: 3
Training loss: 0.6152483741741872
Validation loss: 2.664958594330368

Epoch: 5| Step: 4
Training loss: 0.9764395979791783
Validation loss: 2.668992739201495

Epoch: 5| Step: 5
Training loss: 0.5084749742330594
Validation loss: 2.7586610513430707

Epoch: 5| Step: 6
Training loss: 0.7490551082674476
Validation loss: 2.670450957644504

Epoch: 5| Step: 7
Training loss: 0.393215402358041
Validation loss: 2.7052598986278737

Epoch: 5| Step: 8
Training loss: 0.3458604723936861
Validation loss: 2.6757404203617967

Epoch: 5| Step: 9
Training loss: 0.5374294645026145
Validation loss: 2.6542862495918924

Epoch: 5| Step: 10
Training loss: 0.550708251877308
Validation loss: 2.8403969024407805

Epoch: 5| Step: 11
Training loss: 0.38867062899135824
Validation loss: 2.7684035774090625

Epoch: 280| Step: 0
Training loss: 0.5913050404952979
Validation loss: 2.6237616910669437

Epoch: 5| Step: 1
Training loss: 0.7629643355317443
Validation loss: 2.770483655782792

Epoch: 5| Step: 2
Training loss: 0.4435527396652743
Validation loss: 2.7892646146428284

Epoch: 5| Step: 3
Training loss: 0.7014287621481478
Validation loss: 2.6962140662496235

Epoch: 5| Step: 4
Training loss: 0.7967728568043206
Validation loss: 2.7024622676225536

Epoch: 5| Step: 5
Training loss: 0.5858498825685846
Validation loss: 2.6935971297826287

Epoch: 5| Step: 6
Training loss: 0.4572701604068465
Validation loss: 2.7591635192784785

Epoch: 5| Step: 7
Training loss: 0.505359889104353
Validation loss: 2.7911546092824655

Epoch: 5| Step: 8
Training loss: 0.593348668637851
Validation loss: 2.807892318734557

Epoch: 5| Step: 9
Training loss: 0.6098057129491911
Validation loss: 2.7256444534987274

Epoch: 5| Step: 10
Training loss: 0.6967404949920966
Validation loss: 2.764181094215822

Epoch: 5| Step: 11
Training loss: 0.4098335631628324
Validation loss: 2.6598152057794002

Epoch: 281| Step: 0
Training loss: 0.662055787024995
Validation loss: 2.6425665088970605

Epoch: 5| Step: 1
Training loss: 0.7631039275838012
Validation loss: 2.6372084061698438

Epoch: 5| Step: 2
Training loss: 0.6007812678581403
Validation loss: 2.6873261706002762

Epoch: 5| Step: 3
Training loss: 0.47300442568944506
Validation loss: 2.6293662482641094

Epoch: 5| Step: 4
Training loss: 0.398487181464526
Validation loss: 2.6984561665501747

Epoch: 5| Step: 5
Training loss: 0.51566066040646
Validation loss: 2.731541489731012

Epoch: 5| Step: 6
Training loss: 0.4592711830902094
Validation loss: 2.772079568745014

Epoch: 5| Step: 7
Training loss: 0.43833139306111596
Validation loss: 2.760673666932345

Epoch: 5| Step: 8
Training loss: 0.7587778294344288
Validation loss: 2.742813230962599

Epoch: 5| Step: 9
Training loss: 0.5617338366863357
Validation loss: 2.7129129876207676

Epoch: 5| Step: 10
Training loss: 0.8512721835479431
Validation loss: 2.759426041156586

Epoch: 5| Step: 11
Training loss: 0.307494196449346
Validation loss: 2.6840706058708017

Epoch: 282| Step: 0
Training loss: 0.6189009867547645
Validation loss: 2.7419619743732673

Epoch: 5| Step: 1
Training loss: 0.4021319970970905
Validation loss: 2.726779553828771

Epoch: 5| Step: 2
Training loss: 0.4415636878999901
Validation loss: 2.7122815416264623

Epoch: 5| Step: 3
Training loss: 0.6279006405485227
Validation loss: 2.6810036254831267

Epoch: 5| Step: 4
Training loss: 0.82494484977185
Validation loss: 2.769709453579687

Epoch: 5| Step: 5
Training loss: 0.45968353912908416
Validation loss: 2.7136709538788555

Epoch: 5| Step: 6
Training loss: 0.8805194207193712
Validation loss: 2.758356125431072

Epoch: 5| Step: 7
Training loss: 0.5985720231771523
Validation loss: 2.8025554604307263

Epoch: 5| Step: 8
Training loss: 0.5068902370641537
Validation loss: 2.7997744642546194

Epoch: 5| Step: 9
Training loss: 0.3634204802787932
Validation loss: 2.6701448352572785

Epoch: 5| Step: 10
Training loss: 0.5882181668242439
Validation loss: 2.6900000882887323

Epoch: 5| Step: 11
Training loss: 0.9024268768465189
Validation loss: 2.703023838803678

Epoch: 283| Step: 0
Training loss: 0.503285935530218
Validation loss: 2.6492404170768795

Epoch: 5| Step: 1
Training loss: 0.6151467397127631
Validation loss: 2.694337978272393

Epoch: 5| Step: 2
Training loss: 0.6212003844268578
Validation loss: 2.741269380883923

Epoch: 5| Step: 3
Training loss: 0.6785076468113411
Validation loss: 2.7332305402345334

Epoch: 5| Step: 4
Training loss: 0.42800588134040296
Validation loss: 2.7239400061920187

Epoch: 5| Step: 5
Training loss: 0.4466793599062887
Validation loss: 2.7118231749331936

Epoch: 5| Step: 6
Training loss: 0.5438724105990752
Validation loss: 2.7421170050823913

Epoch: 5| Step: 7
Training loss: 0.7218607880485561
Validation loss: 2.6751532975654326

Epoch: 5| Step: 8
Training loss: 0.8594986566529752
Validation loss: 2.7157694823149106

Epoch: 5| Step: 9
Training loss: 0.7268012280145704
Validation loss: 2.682586177224998

Epoch: 5| Step: 10
Training loss: 0.35560548688589205
Validation loss: 2.7208042185327312

Epoch: 5| Step: 11
Training loss: 0.8580124891168005
Validation loss: 2.7245180394987325

Epoch: 284| Step: 0
Training loss: 0.5597186998609339
Validation loss: 2.7190442382786153

Epoch: 5| Step: 1
Training loss: 0.5774517004862176
Validation loss: 2.7524822512466423

Epoch: 5| Step: 2
Training loss: 0.5799490531381527
Validation loss: 2.728873966381739

Epoch: 5| Step: 3
Training loss: 0.5106805067581468
Validation loss: 2.635292202318617

Epoch: 5| Step: 4
Training loss: 0.6172198757902826
Validation loss: 2.7326330140171993

Epoch: 5| Step: 5
Training loss: 0.416298980208162
Validation loss: 2.6722171408229776

Epoch: 5| Step: 6
Training loss: 0.8072157095994776
Validation loss: 2.6757046987902124

Epoch: 5| Step: 7
Training loss: 0.8246654366754145
Validation loss: 2.6870814448455627

Epoch: 5| Step: 8
Training loss: 0.42093874213949445
Validation loss: 2.7705879975221697

Epoch: 5| Step: 9
Training loss: 0.525187626871468
Validation loss: 2.797734584881665

Epoch: 5| Step: 10
Training loss: 0.37497585934183747
Validation loss: 2.727122889572576

Epoch: 5| Step: 11
Training loss: 1.179852202583097
Validation loss: 2.7385202032394185

Epoch: 285| Step: 0
Training loss: 0.6196094747371783
Validation loss: 2.820831546942532

Epoch: 5| Step: 1
Training loss: 0.7776026462370582
Validation loss: 2.792393950244707

Epoch: 5| Step: 2
Training loss: 0.6432254858078961
Validation loss: 2.847260369585448

Epoch: 5| Step: 3
Training loss: 0.7898994765729433
Validation loss: 2.7891443990299676

Epoch: 5| Step: 4
Training loss: 0.4579264684477912
Validation loss: 2.787948335992128

Epoch: 5| Step: 5
Training loss: 1.1750567665997036
Validation loss: 2.721667408901222

Epoch: 5| Step: 6
Training loss: 0.6114081187211142
Validation loss: 2.8025408315789235

Epoch: 5| Step: 7
Training loss: 0.6671959494562716
Validation loss: 2.7937327053720984

Epoch: 5| Step: 8
Training loss: 0.43628049230171634
Validation loss: 2.7767089676315733

Epoch: 5| Step: 9
Training loss: 0.6346697690920308
Validation loss: 2.719198372652428

Epoch: 5| Step: 10
Training loss: 0.732474404040797
Validation loss: 2.7668376175123224

Epoch: 5| Step: 11
Training loss: 0.5185630783293002
Validation loss: 2.791844093083931

Epoch: 286| Step: 0
Training loss: 0.4677443047293498
Validation loss: 2.7529341873686084

Epoch: 5| Step: 1
Training loss: 0.5878988880071037
Validation loss: 2.7007031037421307

Epoch: 5| Step: 2
Training loss: 0.5321745400858351
Validation loss: 2.7789308865934803

Epoch: 5| Step: 3
Training loss: 0.596877294805619
Validation loss: 2.7714568717654653

Epoch: 5| Step: 4
Training loss: 0.6411154660538506
Validation loss: 2.7520014855869204

Epoch: 5| Step: 5
Training loss: 0.5109282641494756
Validation loss: 2.7593594499886454

Epoch: 5| Step: 6
Training loss: 1.049703733336293
Validation loss: 2.6634714360253176

Epoch: 5| Step: 7
Training loss: 0.422635963926175
Validation loss: 2.728988628307146

Epoch: 5| Step: 8
Training loss: 0.7474689691539191
Validation loss: 2.65364041139138

Epoch: 5| Step: 9
Training loss: 0.505205062645881
Validation loss: 2.6907615646162935

Epoch: 5| Step: 10
Training loss: 0.5889917751120105
Validation loss: 2.6875998641097287

Epoch: 5| Step: 11
Training loss: 0.9311823327486797
Validation loss: 2.6567349533493023

Epoch: 287| Step: 0
Training loss: 0.46959473471126734
Validation loss: 2.735999756342011

Epoch: 5| Step: 1
Training loss: 0.7389516057698642
Validation loss: 2.6896286378251326

Epoch: 5| Step: 2
Training loss: 0.7295695599603507
Validation loss: 2.7221184832946044

Epoch: 5| Step: 3
Training loss: 0.7649917319106544
Validation loss: 2.676379921574844

Epoch: 5| Step: 4
Training loss: 0.529918966666374
Validation loss: 2.752447473306033

Epoch: 5| Step: 5
Training loss: 0.6773846738215693
Validation loss: 2.685187070845591

Epoch: 5| Step: 6
Training loss: 0.6284117798400447
Validation loss: 2.7372764125946416

Epoch: 5| Step: 7
Training loss: 0.38988751412329536
Validation loss: 2.713475958137808

Epoch: 5| Step: 8
Training loss: 0.47412884094006014
Validation loss: 2.6518728768050024

Epoch: 5| Step: 9
Training loss: 0.5883744995458682
Validation loss: 2.74549224256421

Epoch: 5| Step: 10
Training loss: 0.5618947799816255
Validation loss: 2.704926979809262

Epoch: 5| Step: 11
Training loss: 0.2818796738535235
Validation loss: 2.712651186566384

Epoch: 288| Step: 0
Training loss: 0.7780740269277385
Validation loss: 2.663943510856828

Epoch: 5| Step: 1
Training loss: 0.8162278340880352
Validation loss: 2.7229620726656325

Epoch: 5| Step: 2
Training loss: 0.5921551718229201
Validation loss: 2.723243518690309

Epoch: 5| Step: 3
Training loss: 0.5416225238076996
Validation loss: 2.6875117028151623

Epoch: 5| Step: 4
Training loss: 0.6267956449764526
Validation loss: 2.703754120310811

Epoch: 5| Step: 5
Training loss: 0.5450573824500216
Validation loss: 2.7070446555359378

Epoch: 5| Step: 6
Training loss: 0.7077139830080706
Validation loss: 2.7221614911696568

Epoch: 5| Step: 7
Training loss: 0.6570180531014438
Validation loss: 2.660314897837649

Epoch: 5| Step: 8
Training loss: 0.5575560688254675
Validation loss: 2.774620341199138

Epoch: 5| Step: 9
Training loss: 0.389441585848096
Validation loss: 2.664174604247957

Epoch: 5| Step: 10
Training loss: 0.48433537474952687
Validation loss: 2.714974687012191

Epoch: 5| Step: 11
Training loss: 0.36333725610344847
Validation loss: 2.639485521519016

Epoch: 289| Step: 0
Training loss: 0.7303669496478109
Validation loss: 2.7220484466999273

Epoch: 5| Step: 1
Training loss: 0.491097545238932
Validation loss: 2.66204805926254

Epoch: 5| Step: 2
Training loss: 0.4528972776989391
Validation loss: 2.656458547296626

Epoch: 5| Step: 3
Training loss: 0.699656365550781
Validation loss: 2.634280187153335

Epoch: 5| Step: 4
Training loss: 0.38955050506926275
Validation loss: 2.708310425490309

Epoch: 5| Step: 5
Training loss: 0.43540160146991724
Validation loss: 2.7559559654433023

Epoch: 5| Step: 6
Training loss: 0.7362663587167951
Validation loss: 2.7036295623867788

Epoch: 5| Step: 7
Training loss: 0.6733274507108241
Validation loss: 2.73534797433066

Epoch: 5| Step: 8
Training loss: 0.575218524043543
Validation loss: 2.7106938577856687

Epoch: 5| Step: 9
Training loss: 0.5766120393141202
Validation loss: 2.7066875935044616

Epoch: 5| Step: 10
Training loss: 0.42670098107468557
Validation loss: 2.72415421306167

Epoch: 5| Step: 11
Training loss: 0.3617535329288993
Validation loss: 2.7423804868223636

Epoch: 290| Step: 0
Training loss: 0.46999544945502447
Validation loss: 2.73113353969795

Epoch: 5| Step: 1
Training loss: 0.5188261137126211
Validation loss: 2.704175131382402

Epoch: 5| Step: 2
Training loss: 0.5122369079313113
Validation loss: 2.680980044411723

Epoch: 5| Step: 3
Training loss: 0.6711098061751352
Validation loss: 2.7291729735284593

Epoch: 5| Step: 4
Training loss: 0.5666232778496515
Validation loss: 2.8158767809192

Epoch: 5| Step: 5
Training loss: 0.48173458547235865
Validation loss: 2.6322459848050674

Epoch: 5| Step: 6
Training loss: 0.5990399567646282
Validation loss: 2.729332101093282

Epoch: 5| Step: 7
Training loss: 0.624055100474952
Validation loss: 2.727190781485676

Epoch: 5| Step: 8
Training loss: 0.7389259954287902
Validation loss: 2.7961104571658795

Epoch: 5| Step: 9
Training loss: 0.8226651922104027
Validation loss: 2.676205395869237

Epoch: 5| Step: 10
Training loss: 0.8019705152228694
Validation loss: 2.682442136204434

Epoch: 5| Step: 11
Training loss: 0.35986460629844247
Validation loss: 2.7017067108289052

Epoch: 291| Step: 0
Training loss: 0.4913616214736871
Validation loss: 2.7027725548566863

Epoch: 5| Step: 1
Training loss: 0.4871219911754034
Validation loss: 2.718928141256895

Epoch: 5| Step: 2
Training loss: 0.7892029892143176
Validation loss: 2.727715078306841

Epoch: 5| Step: 3
Training loss: 0.503065605685742
Validation loss: 2.6830129388202666

Epoch: 5| Step: 4
Training loss: 0.42695948115274224
Validation loss: 2.764220475562564

Epoch: 5| Step: 5
Training loss: 0.6330590415405928
Validation loss: 2.7563759481612866

Epoch: 5| Step: 6
Training loss: 0.6455977430618525
Validation loss: 2.6736398857737083

Epoch: 5| Step: 7
Training loss: 0.3965111709334342
Validation loss: 2.7221087247733893

Epoch: 5| Step: 8
Training loss: 0.42976151609164187
Validation loss: 2.728488469608791

Epoch: 5| Step: 9
Training loss: 0.4793437409436067
Validation loss: 2.753147863119209

Epoch: 5| Step: 10
Training loss: 0.5316598657493937
Validation loss: 2.7168043453242743

Epoch: 5| Step: 11
Training loss: 0.3080980810860602
Validation loss: 2.6994867849613544

Epoch: 292| Step: 0
Training loss: 0.3951052465440009
Validation loss: 2.7198908739662127

Epoch: 5| Step: 1
Training loss: 0.6460682892770178
Validation loss: 2.725791720188624

Epoch: 5| Step: 2
Training loss: 0.486714374406229
Validation loss: 2.689521206926944

Epoch: 5| Step: 3
Training loss: 0.5914572317102629
Validation loss: 2.6957573970396145

Epoch: 5| Step: 4
Training loss: 0.5786535063977934
Validation loss: 2.6510560660480187

Epoch: 5| Step: 5
Training loss: 0.680867891154428
Validation loss: 2.6954427346725147

Epoch: 5| Step: 6
Training loss: 0.4888752185681566
Validation loss: 2.724067862054915

Epoch: 5| Step: 7
Training loss: 0.45168612018911264
Validation loss: 2.7484340038064072

Epoch: 5| Step: 8
Training loss: 0.4561668437792028
Validation loss: 2.834774178067178

Epoch: 5| Step: 9
Training loss: 0.6851797397810497
Validation loss: 2.7359138481937646

Epoch: 5| Step: 10
Training loss: 0.8426238421194635
Validation loss: 2.725619562028888

Epoch: 5| Step: 11
Training loss: 0.29422703419842006
Validation loss: 2.7679655404699894

Epoch: 293| Step: 0
Training loss: 0.35180952082877215
Validation loss: 2.7710391317153813

Epoch: 5| Step: 1
Training loss: 0.7217015326346369
Validation loss: 2.65997027000506

Epoch: 5| Step: 2
Training loss: 0.5287235434656626
Validation loss: 2.672722509165525

Epoch: 5| Step: 3
Training loss: 0.49787590233742335
Validation loss: 2.7325328688929216

Epoch: 5| Step: 4
Training loss: 0.5229028846880011
Validation loss: 2.7946705788508845

Epoch: 5| Step: 5
Training loss: 0.4151494317002733
Validation loss: 2.752934580700799

Epoch: 5| Step: 6
Training loss: 0.535719804508302
Validation loss: 2.7601325332712476

Epoch: 5| Step: 7
Training loss: 0.6396947014072052
Validation loss: 2.7692428388478594

Epoch: 5| Step: 8
Training loss: 0.5091098059960996
Validation loss: 2.7531231427339775

Epoch: 5| Step: 9
Training loss: 0.621248933610826
Validation loss: 2.7663757630644876

Epoch: 5| Step: 10
Training loss: 0.7912420631601214
Validation loss: 2.7453581004154177

Epoch: 5| Step: 11
Training loss: 0.38813585671614514
Validation loss: 2.663987316215475

Epoch: 294| Step: 0
Training loss: 0.586614675218431
Validation loss: 2.7008884820973984

Epoch: 5| Step: 1
Training loss: 0.41883272378763053
Validation loss: 2.72617910507795

Epoch: 5| Step: 2
Training loss: 0.626404233811736
Validation loss: 2.67667221865864

Epoch: 5| Step: 3
Training loss: 0.42889179768211433
Validation loss: 2.7419010385865716

Epoch: 5| Step: 4
Training loss: 0.7006730029006869
Validation loss: 2.807590728192804

Epoch: 5| Step: 5
Training loss: 0.5935988484781463
Validation loss: 2.7894109299944274

Epoch: 5| Step: 6
Training loss: 0.4701490504739535
Validation loss: 2.757868527571827

Epoch: 5| Step: 7
Training loss: 0.4939587676846662
Validation loss: 2.6472396016981983

Epoch: 5| Step: 8
Training loss: 0.6022224769273073
Validation loss: 2.7584833152385797

Epoch: 5| Step: 9
Training loss: 0.4814546750533688
Validation loss: 2.6895510106960225

Epoch: 5| Step: 10
Training loss: 0.7192366652460842
Validation loss: 2.7245608417741423

Epoch: 5| Step: 11
Training loss: 0.6335297746262462
Validation loss: 2.7343540445160555

Epoch: 295| Step: 0
Training loss: 0.6541394400144528
Validation loss: 2.6699228089076774

Epoch: 5| Step: 1
Training loss: 0.5748069760545648
Validation loss: 2.6451870036226004

Epoch: 5| Step: 2
Training loss: 0.5909701575056268
Validation loss: 2.679687333176499

Epoch: 5| Step: 3
Training loss: 0.4128969089170622
Validation loss: 2.7091492316468155

Epoch: 5| Step: 4
Training loss: 0.6690374826015079
Validation loss: 2.703923421704364

Epoch: 5| Step: 5
Training loss: 0.49045774986470686
Validation loss: 2.7418583113544557

Epoch: 5| Step: 6
Training loss: 0.7561622820968028
Validation loss: 2.7137791657194716

Epoch: 5| Step: 7
Training loss: 0.5474477765681929
Validation loss: 2.673594369601944

Epoch: 5| Step: 8
Training loss: 0.5200630277253462
Validation loss: 2.7075582140907284

Epoch: 5| Step: 9
Training loss: 0.500977454826051
Validation loss: 2.69086131506538

Epoch: 5| Step: 10
Training loss: 0.7906213601974719
Validation loss: 2.6851024394026024

Epoch: 5| Step: 11
Training loss: 0.538150762678976
Validation loss: 2.6644690605178813

Epoch: 296| Step: 0
Training loss: 0.5248170295402658
Validation loss: 2.71505534493254

Epoch: 5| Step: 1
Training loss: 0.5180707782125845
Validation loss: 2.7040215073189615

Epoch: 5| Step: 2
Training loss: 0.47601256925051916
Validation loss: 2.684482747418313

Epoch: 5| Step: 3
Training loss: 0.7667937408398761
Validation loss: 2.6240161156939665

Epoch: 5| Step: 4
Training loss: 0.5619037169776011
Validation loss: 2.713328059618587

Epoch: 5| Step: 5
Training loss: 0.5527924146610022
Validation loss: 2.721651644471575

Epoch: 5| Step: 6
Training loss: 0.6659898501244219
Validation loss: 2.7018683917649904

Epoch: 5| Step: 7
Training loss: 0.566054083423899
Validation loss: 2.736893937767769

Epoch: 5| Step: 8
Training loss: 0.7319050096830584
Validation loss: 2.72547572136437

Epoch: 5| Step: 9
Training loss: 0.5156119084863715
Validation loss: 2.6271130519056234

Epoch: 5| Step: 10
Training loss: 0.6777087599781036
Validation loss: 2.68677748534291

Epoch: 5| Step: 11
Training loss: 0.3464450525723062
Validation loss: 2.6613577894017713

Epoch: 297| Step: 0
Training loss: 0.5728647006193374
Validation loss: 2.6939125000220145

Epoch: 5| Step: 1
Training loss: 0.5483289192721597
Validation loss: 2.6509347468151296

Epoch: 5| Step: 2
Training loss: 0.8632115124458872
Validation loss: 2.6581458899105193

Epoch: 5| Step: 3
Training loss: 0.4439608657200212
Validation loss: 2.663693638358506

Epoch: 5| Step: 4
Training loss: 0.5435602547637687
Validation loss: 2.7391636397640293

Epoch: 5| Step: 5
Training loss: 0.41028841704838576
Validation loss: 2.7016176585473337

Epoch: 5| Step: 6
Training loss: 0.39825568071062667
Validation loss: 2.739685949910577

Epoch: 5| Step: 7
Training loss: 0.5903952843135305
Validation loss: 2.7034198144512014

Epoch: 5| Step: 8
Training loss: 0.5749349992749319
Validation loss: 2.688201493005149

Epoch: 5| Step: 9
Training loss: 0.44142226806203994
Validation loss: 2.733353451232222

Epoch: 5| Step: 10
Training loss: 0.645902942679825
Validation loss: 2.7373335536596533

Epoch: 5| Step: 11
Training loss: 0.5806594145300437
Validation loss: 2.6740332878395185

Epoch: 298| Step: 0
Training loss: 0.703979587439168
Validation loss: 2.76184647195986

Epoch: 5| Step: 1
Training loss: 0.47069848719167967
Validation loss: 2.7158539061358713

Epoch: 5| Step: 2
Training loss: 0.4598800199244534
Validation loss: 2.679432140376095

Epoch: 5| Step: 3
Training loss: 0.6817034716995765
Validation loss: 2.6836735779699294

Epoch: 5| Step: 4
Training loss: 0.6925524462109656
Validation loss: 2.673485034733324

Epoch: 5| Step: 5
Training loss: 0.5697912943790575
Validation loss: 2.6758760662868233

Epoch: 5| Step: 6
Training loss: 0.29322221599808285
Validation loss: 2.722056752942278

Epoch: 5| Step: 7
Training loss: 0.48806144344544233
Validation loss: 2.6426931742913893

Epoch: 5| Step: 8
Training loss: 0.5882189774704574
Validation loss: 2.7206866794882396

Epoch: 5| Step: 9
Training loss: 0.727768133571131
Validation loss: 2.7321858680205664

Epoch: 5| Step: 10
Training loss: 0.4868856551065837
Validation loss: 2.758081900286308

Epoch: 5| Step: 11
Training loss: 0.5075345085419475
Validation loss: 2.7622283796259017

Epoch: 299| Step: 0
Training loss: 0.7129740627006443
Validation loss: 2.672354222054684

Epoch: 5| Step: 1
Training loss: 0.3320001587616012
Validation loss: 2.734905387664613

Epoch: 5| Step: 2
Training loss: 0.5993550907682894
Validation loss: 2.698878280137533

Epoch: 5| Step: 3
Training loss: 0.4085308931043197
Validation loss: 2.720729293752161

Epoch: 5| Step: 4
Training loss: 0.45324307580446743
Validation loss: 2.7006110516851325

Epoch: 5| Step: 5
Training loss: 0.3156301375244801
Validation loss: 2.681084327203219

Epoch: 5| Step: 6
Training loss: 0.2915857605890807
Validation loss: 2.681893466662746

Epoch: 5| Step: 7
Training loss: 0.5456575739205286
Validation loss: 2.64847860238768

Epoch: 5| Step: 8
Training loss: 0.6622100123439757
Validation loss: 2.7157537019387106

Epoch: 5| Step: 9
Training loss: 0.57610832769099
Validation loss: 2.689605102825241

Epoch: 5| Step: 10
Training loss: 0.5777087646337863
Validation loss: 2.712712021348073

Epoch: 5| Step: 11
Training loss: 1.1368024867306437
Validation loss: 2.6737705221721657

Epoch: 300| Step: 0
Training loss: 0.6312184448664487
Validation loss: 2.7763662500387714

Epoch: 5| Step: 1
Training loss: 0.6034311278612746
Validation loss: 2.7689438462839306

Epoch: 5| Step: 2
Training loss: 0.4305308821574764
Validation loss: 2.719283983254446

Epoch: 5| Step: 3
Training loss: 0.35469915059990564
Validation loss: 2.7368440506985476

Epoch: 5| Step: 4
Training loss: 0.49248996402468087
Validation loss: 2.697298156998791

Epoch: 5| Step: 5
Training loss: 0.543154595493856
Validation loss: 2.6754152999083893

Epoch: 5| Step: 6
Training loss: 0.5621091756495585
Validation loss: 2.6485030804731946

Epoch: 5| Step: 7
Training loss: 0.4550835277580475
Validation loss: 2.6665533881167924

Epoch: 5| Step: 8
Training loss: 0.5022566059754736
Validation loss: 2.692311231205609

Epoch: 5| Step: 9
Training loss: 0.6751403194738356
Validation loss: 2.694733407288202

Epoch: 5| Step: 10
Training loss: 0.43687803472029735
Validation loss: 2.7506993228203833

Epoch: 5| Step: 11
Training loss: 0.3455862828448409
Validation loss: 2.7397223402276385

Epoch: 301| Step: 0
Training loss: 0.5323354067315171
Validation loss: 2.731263735785378

Epoch: 5| Step: 1
Training loss: 0.46543295567397996
Validation loss: 2.8076045700010868

Epoch: 5| Step: 2
Training loss: 0.3906281661858988
Validation loss: 2.7739522250360458

Epoch: 5| Step: 3
Training loss: 0.5988315669270018
Validation loss: 2.719482681233763

Epoch: 5| Step: 4
Training loss: 0.5079192416173032
Validation loss: 2.748347002353609

Epoch: 5| Step: 5
Training loss: 0.4526789047845133
Validation loss: 2.605124577138489

Epoch: 5| Step: 6
Training loss: 0.7754595747494628
Validation loss: 2.6542946743201647

Epoch: 5| Step: 7
Training loss: 0.318450002116022
Validation loss: 2.626611967753723

Epoch: 5| Step: 8
Training loss: 0.5139499970208324
Validation loss: 2.7309696936784134

Epoch: 5| Step: 9
Training loss: 0.7010940040977295
Validation loss: 2.7075148788517662

Epoch: 5| Step: 10
Training loss: 0.4796637793276882
Validation loss: 2.676292318650659

Epoch: 5| Step: 11
Training loss: 0.9541487589381422
Validation loss: 2.720115453926294

Epoch: 302| Step: 0
Training loss: 0.6114482822491097
Validation loss: 2.7272466477076764

Epoch: 5| Step: 1
Training loss: 0.49998791501222484
Validation loss: 2.7281128921327498

Epoch: 5| Step: 2
Training loss: 0.7643021814153721
Validation loss: 2.7913041887719126

Epoch: 5| Step: 3
Training loss: 0.654840977598496
Validation loss: 2.689209675164696

Epoch: 5| Step: 4
Training loss: 0.4189483357922855
Validation loss: 2.6509317751268817

Epoch: 5| Step: 5
Training loss: 0.5745297063579058
Validation loss: 2.7265888857726126

Epoch: 5| Step: 6
Training loss: 0.6302264555119876
Validation loss: 2.676363604582934

Epoch: 5| Step: 7
Training loss: 0.600759093591616
Validation loss: 2.6951179876491502

Epoch: 5| Step: 8
Training loss: 0.353940318743559
Validation loss: 2.705562235162293

Epoch: 5| Step: 9
Training loss: 0.3561715106497857
Validation loss: 2.6233419374044518

Epoch: 5| Step: 10
Training loss: 0.6074742481676185
Validation loss: 2.815098921600076

Epoch: 5| Step: 11
Training loss: 0.3863346427159396
Validation loss: 2.7329960679434127

Epoch: 303| Step: 0
Training loss: 0.6217000149619334
Validation loss: 2.6585333191875837

Epoch: 5| Step: 1
Training loss: 0.529867336386056
Validation loss: 2.6740282911227307

Epoch: 5| Step: 2
Training loss: 0.37502175506429924
Validation loss: 2.6522388577963874

Epoch: 5| Step: 3
Training loss: 0.5157466802652001
Validation loss: 2.7717076131690592

Epoch: 5| Step: 4
Training loss: 0.4674722103794358
Validation loss: 2.6996728797537615

Epoch: 5| Step: 5
Training loss: 0.44986393248905454
Validation loss: 2.7353122594411907

Epoch: 5| Step: 6
Training loss: 0.6093601078267807
Validation loss: 2.7421734004369167

Epoch: 5| Step: 7
Training loss: 0.719701510320756
Validation loss: 2.716842709485378

Epoch: 5| Step: 8
Training loss: 0.6791634786761144
Validation loss: 2.6627641275219913

Epoch: 5| Step: 9
Training loss: 0.6386044201240646
Validation loss: 2.710004636853229

Epoch: 5| Step: 10
Training loss: 0.46919436055710634
Validation loss: 2.76403055368453

Epoch: 5| Step: 11
Training loss: 0.31959193290014093
Validation loss: 2.683624137843335

Epoch: 304| Step: 0
Training loss: 0.525024683689952
Validation loss: 2.7406484953026515

Epoch: 5| Step: 1
Training loss: 0.7570648437856747
Validation loss: 2.748693423114659

Epoch: 5| Step: 2
Training loss: 0.3346585613316607
Validation loss: 2.767554380628642

Epoch: 5| Step: 3
Training loss: 0.37678648669977893
Validation loss: 2.7407012635961565

Epoch: 5| Step: 4
Training loss: 0.6399060145673557
Validation loss: 2.728659327260613

Epoch: 5| Step: 5
Training loss: 0.5469853970951281
Validation loss: 2.7426983573916632

Epoch: 5| Step: 6
Training loss: 0.6640952158330093
Validation loss: 2.737616058688011

Epoch: 5| Step: 7
Training loss: 0.40259525623141923
Validation loss: 2.779409120803606

Epoch: 5| Step: 8
Training loss: 0.6713391762286313
Validation loss: 2.7492851354098624

Epoch: 5| Step: 9
Training loss: 0.400395723636077
Validation loss: 2.6795118513455605

Epoch: 5| Step: 10
Training loss: 0.38859120207450903
Validation loss: 2.7416362226432724

Epoch: 5| Step: 11
Training loss: 0.2952014154073658
Validation loss: 2.6895604902863965

Epoch: 305| Step: 0
Training loss: 0.3814664257669694
Validation loss: 2.7159767403030326

Epoch: 5| Step: 1
Training loss: 0.5955208421322036
Validation loss: 2.7620603861776054

Epoch: 5| Step: 2
Training loss: 0.6644477624245086
Validation loss: 2.723517728124666

Epoch: 5| Step: 3
Training loss: 0.6096796350250459
Validation loss: 2.7801065058740453

Epoch: 5| Step: 4
Training loss: 0.6263994285343384
Validation loss: 2.804188520130028

Epoch: 5| Step: 5
Training loss: 0.48851279300153716
Validation loss: 2.708756598385489

Epoch: 5| Step: 6
Training loss: 0.7191047622217418
Validation loss: 2.7101504404521277

Epoch: 5| Step: 7
Training loss: 0.6516048106628326
Validation loss: 2.7755048971254923

Epoch: 5| Step: 8
Training loss: 0.4306357238165087
Validation loss: 2.6720241966010954

Epoch: 5| Step: 9
Training loss: 0.4642470721654233
Validation loss: 2.719819855930478

Epoch: 5| Step: 10
Training loss: 0.4448239172590053
Validation loss: 2.6583458541906095

Epoch: 5| Step: 11
Training loss: 0.4134665825404767
Validation loss: 2.6920645840172055

Epoch: 306| Step: 0
Training loss: 0.5397616565518156
Validation loss: 2.733301540563961

Epoch: 5| Step: 1
Training loss: 0.6131376353448312
Validation loss: 2.72376113868316

Epoch: 5| Step: 2
Training loss: 0.5236995098204228
Validation loss: 2.711605880089594

Epoch: 5| Step: 3
Training loss: 0.6842378470192128
Validation loss: 2.7183463356000246

Epoch: 5| Step: 4
Training loss: 0.413507089042092
Validation loss: 2.6967573448911706

Epoch: 5| Step: 5
Training loss: 0.5435542236501597
Validation loss: 2.773569213175271

Epoch: 5| Step: 6
Training loss: 0.5993790075269583
Validation loss: 2.6829252729225033

Epoch: 5| Step: 7
Training loss: 0.3462973299454231
Validation loss: 2.6269285709032433

Epoch: 5| Step: 8
Training loss: 0.6114143335172155
Validation loss: 2.679473527348914

Epoch: 5| Step: 9
Training loss: 0.7813162584817847
Validation loss: 2.7341333155316265

Epoch: 5| Step: 10
Training loss: 0.3595527955470807
Validation loss: 2.74588563943535

Epoch: 5| Step: 11
Training loss: 0.7432595791884279
Validation loss: 2.728209645639369

Epoch: 307| Step: 0
Training loss: 0.6181841179606045
Validation loss: 2.6831421969638907

Epoch: 5| Step: 1
Training loss: 0.40464123052665235
Validation loss: 2.7749676007306836

Epoch: 5| Step: 2
Training loss: 0.7444096276775252
Validation loss: 2.819842664870222

Epoch: 5| Step: 3
Training loss: 0.5117995220238741
Validation loss: 2.730731756798559

Epoch: 5| Step: 4
Training loss: 0.4729609807576404
Validation loss: 2.744014951604377

Epoch: 5| Step: 5
Training loss: 0.5336828623765728
Validation loss: 2.659644624315713

Epoch: 5| Step: 6
Training loss: 0.44470075784571045
Validation loss: 2.695200006468633

Epoch: 5| Step: 7
Training loss: 0.5082563661194447
Validation loss: 2.6762734139190463

Epoch: 5| Step: 8
Training loss: 0.8413942086465919
Validation loss: 2.6660917464533824

Epoch: 5| Step: 9
Training loss: 0.5212148191165542
Validation loss: 2.7089616095684868

Epoch: 5| Step: 10
Training loss: 0.6248534746073895
Validation loss: 2.704067312207149

Epoch: 5| Step: 11
Training loss: 0.46104425067007976
Validation loss: 2.7216954809669796

Epoch: 308| Step: 0
Training loss: 0.3966054496623487
Validation loss: 2.691600443750731

Epoch: 5| Step: 1
Training loss: 0.4613721705380693
Validation loss: 2.692693073271276

Epoch: 5| Step: 2
Training loss: 0.5435538124354313
Validation loss: 2.7775799256964686

Epoch: 5| Step: 3
Training loss: 0.3619097590512281
Validation loss: 2.702109623905851

Epoch: 5| Step: 4
Training loss: 0.7498514505139199
Validation loss: 2.6841187127914536

Epoch: 5| Step: 5
Training loss: 0.5754373814995061
Validation loss: 2.737940195187934

Epoch: 5| Step: 6
Training loss: 0.512959817139869
Validation loss: 2.6639707405941206

Epoch: 5| Step: 7
Training loss: 0.6332109162535511
Validation loss: 2.6876769562061074

Epoch: 5| Step: 8
Training loss: 0.44289079346841165
Validation loss: 2.6456930969399686

Epoch: 5| Step: 9
Training loss: 0.5516164142745261
Validation loss: 2.701683409739187

Epoch: 5| Step: 10
Training loss: 0.3712287055115333
Validation loss: 2.6109507023347995

Epoch: 5| Step: 11
Training loss: 0.5360790288244262
Validation loss: 2.7887217708009833

Epoch: 309| Step: 0
Training loss: 0.3979561647148317
Validation loss: 2.6979162493574096

Epoch: 5| Step: 1
Training loss: 0.3657906727512088
Validation loss: 2.730555349713026

Epoch: 5| Step: 2
Training loss: 0.47064243416074203
Validation loss: 2.6658732095577835

Epoch: 5| Step: 3
Training loss: 0.5374691399875009
Validation loss: 2.657434517283014

Epoch: 5| Step: 4
Training loss: 0.4061099691406826
Validation loss: 2.7116427846232827

Epoch: 5| Step: 5
Training loss: 0.45260466922019504
Validation loss: 2.6778420598928667

Epoch: 5| Step: 6
Training loss: 0.6637487455668691
Validation loss: 2.7579894797044036

Epoch: 5| Step: 7
Training loss: 0.337014799675998
Validation loss: 2.6755637161672836

Epoch: 5| Step: 8
Training loss: 0.5768327963322378
Validation loss: 2.7281677016987005

Epoch: 5| Step: 9
Training loss: 0.7127858124068118
Validation loss: 2.6846151467293

Epoch: 5| Step: 10
Training loss: 0.5222412217800783
Validation loss: 2.71818629811687

Epoch: 5| Step: 11
Training loss: 0.6955894818625105
Validation loss: 2.7510140817846405

Epoch: 310| Step: 0
Training loss: 0.49235742148664047
Validation loss: 2.704179212769341

Epoch: 5| Step: 1
Training loss: 0.7664572415901849
Validation loss: 2.8185156313837343

Epoch: 5| Step: 2
Training loss: 0.41307067842910844
Validation loss: 2.719456233818503

Epoch: 5| Step: 3
Training loss: 0.42499124223437124
Validation loss: 2.7362248802629465

Epoch: 5| Step: 4
Training loss: 0.49440358820746566
Validation loss: 2.651394572622971

Epoch: 5| Step: 5
Training loss: 0.5274966265584097
Validation loss: 2.681890103301992

Epoch: 5| Step: 6
Training loss: 0.5903134023599912
Validation loss: 2.8312805899735225

Epoch: 5| Step: 7
Training loss: 0.42619181445615173
Validation loss: 2.7952949902217257

Epoch: 5| Step: 8
Training loss: 0.5878777993662989
Validation loss: 2.758540269104054

Epoch: 5| Step: 9
Training loss: 0.5388225076478569
Validation loss: 2.7752633330692644

Epoch: 5| Step: 10
Training loss: 0.510907119174381
Validation loss: 2.758633946021747

Epoch: 5| Step: 11
Training loss: 0.5131273465677892
Validation loss: 2.7623851714858736

Epoch: 311| Step: 0
Training loss: 0.4730323997191757
Validation loss: 2.7112474768172383

Epoch: 5| Step: 1
Training loss: 0.38532920652679914
Validation loss: 2.6296822270389426

Epoch: 5| Step: 2
Training loss: 0.49012306743125045
Validation loss: 2.6472681140179657

Epoch: 5| Step: 3
Training loss: 0.4712260969762942
Validation loss: 2.7764602235852656

Epoch: 5| Step: 4
Training loss: 0.6303968830580433
Validation loss: 2.7835404148179412

Epoch: 5| Step: 5
Training loss: 0.7485005171015296
Validation loss: 2.730146688332744

Epoch: 5| Step: 6
Training loss: 0.7744627813381606
Validation loss: 2.690324932442905

Epoch: 5| Step: 7
Training loss: 0.48255273071289556
Validation loss: 2.739690014656102

Epoch: 5| Step: 8
Training loss: 0.6338993911052403
Validation loss: 2.7120460273926303

Epoch: 5| Step: 9
Training loss: 0.7087864875483891
Validation loss: 2.8056407148091482

Epoch: 5| Step: 10
Training loss: 0.614428522256454
Validation loss: 2.7026672012369817

Epoch: 5| Step: 11
Training loss: 0.3324513862680215
Validation loss: 2.729781079230401

Epoch: 312| Step: 0
Training loss: 0.7030381890854152
Validation loss: 2.7840790558139803

Epoch: 5| Step: 1
Training loss: 0.5735269128592526
Validation loss: 2.6710307402913314

Epoch: 5| Step: 2
Training loss: 0.4253826900754465
Validation loss: 2.662395418080193

Epoch: 5| Step: 3
Training loss: 0.5324079571903848
Validation loss: 2.682004362601777

Epoch: 5| Step: 4
Training loss: 0.6552114443156786
Validation loss: 2.7496725378717963

Epoch: 5| Step: 5
Training loss: 0.6994195575173346
Validation loss: 2.7397505173720824

Epoch: 5| Step: 6
Training loss: 0.5347303380253964
Validation loss: 2.7475213617270176

Epoch: 5| Step: 7
Training loss: 0.6084141859340039
Validation loss: 2.773493913963274

Epoch: 5| Step: 8
Training loss: 0.5750222844491052
Validation loss: 2.723345789164941

Epoch: 5| Step: 9
Training loss: 0.40774093818535284
Validation loss: 2.7346185630223534

Epoch: 5| Step: 10
Training loss: 0.39670145265266615
Validation loss: 2.6729941896260563

Epoch: 5| Step: 11
Training loss: 0.29554461737226007
Validation loss: 2.73641813149682

Epoch: 313| Step: 0
Training loss: 0.45296282990380954
Validation loss: 2.681641947502149

Epoch: 5| Step: 1
Training loss: 0.3605736975647859
Validation loss: 2.662011189281517

Epoch: 5| Step: 2
Training loss: 0.49816160189603376
Validation loss: 2.6605036504491384

Epoch: 5| Step: 3
Training loss: 0.6162514166980113
Validation loss: 2.7294291717042816

Epoch: 5| Step: 4
Training loss: 0.8284037139000707
Validation loss: 2.7494327545343586

Epoch: 5| Step: 5
Training loss: 0.3900008746895396
Validation loss: 2.721281143133512

Epoch: 5| Step: 6
Training loss: 0.4871083630487841
Validation loss: 2.6781857233274162

Epoch: 5| Step: 7
Training loss: 0.5582768001213568
Validation loss: 2.6900032162381198

Epoch: 5| Step: 8
Training loss: 0.44906597027270634
Validation loss: 2.788195994577152

Epoch: 5| Step: 9
Training loss: 0.4688076778530536
Validation loss: 2.7211907199284004

Epoch: 5| Step: 10
Training loss: 0.411522451869398
Validation loss: 2.7097032450823906

Epoch: 5| Step: 11
Training loss: 0.8903310524911157
Validation loss: 2.7304724246224565

Epoch: 314| Step: 0
Training loss: 0.5368522722276293
Validation loss: 2.715285117591202

Epoch: 5| Step: 1
Training loss: 0.7302575035427985
Validation loss: 2.6737664017984937

Epoch: 5| Step: 2
Training loss: 0.6542397317557952
Validation loss: 2.714932911824368

Epoch: 5| Step: 3
Training loss: 0.7146669596533862
Validation loss: 2.730028916544655

Epoch: 5| Step: 4
Training loss: 0.4812011563917029
Validation loss: 2.639059061424977

Epoch: 5| Step: 5
Training loss: 0.44489811138027446
Validation loss: 2.7110338074857925

Epoch: 5| Step: 6
Training loss: 0.6135791128116084
Validation loss: 2.7464357274401796

Epoch: 5| Step: 7
Training loss: 0.5269774966475183
Validation loss: 2.7265745543438435

Epoch: 5| Step: 8
Training loss: 0.525699397116539
Validation loss: 2.7159448673053412

Epoch: 5| Step: 9
Training loss: 0.49874800155832033
Validation loss: 2.743942861795536

Epoch: 5| Step: 10
Training loss: 0.5020596580410689
Validation loss: 2.736135264971558

Epoch: 5| Step: 11
Training loss: 0.8270834364678793
Validation loss: 2.6801259652468676

Epoch: 315| Step: 0
Training loss: 0.3737318331472004
Validation loss: 2.6622496073771478

Epoch: 5| Step: 1
Training loss: 0.6695785977548834
Validation loss: 2.6840114684854792

Epoch: 5| Step: 2
Training loss: 0.7653463206795325
Validation loss: 2.677617293788626

Epoch: 5| Step: 3
Training loss: 0.7309618422885678
Validation loss: 2.7315351216628323

Epoch: 5| Step: 4
Training loss: 0.4139779562379636
Validation loss: 2.696131628760286

Epoch: 5| Step: 5
Training loss: 0.3323365546892685
Validation loss: 2.740917958891707

Epoch: 5| Step: 6
Training loss: 0.6201806704248839
Validation loss: 2.664305950835735

Epoch: 5| Step: 7
Training loss: 0.4692136696544589
Validation loss: 2.74913717229986

Epoch: 5| Step: 8
Training loss: 0.49007735454365586
Validation loss: 2.6496414178883496

Epoch: 5| Step: 9
Training loss: 0.3560972840090677
Validation loss: 2.70981594854842

Epoch: 5| Step: 10
Training loss: 0.31280038225176204
Validation loss: 2.7488780767518897

Epoch: 5| Step: 11
Training loss: 0.5135303490908871
Validation loss: 2.7266701309981487

Epoch: 316| Step: 0
Training loss: 0.34257961564299744
Validation loss: 2.728076681966931

Epoch: 5| Step: 1
Training loss: 0.6533197194825177
Validation loss: 2.708694006061371

Epoch: 5| Step: 2
Training loss: 0.7084438480855048
Validation loss: 2.7570787017304483

Epoch: 5| Step: 3
Training loss: 0.46110665725021366
Validation loss: 2.7645227423215584

Epoch: 5| Step: 4
Training loss: 0.5267335540311546
Validation loss: 2.6444286775441745

Epoch: 5| Step: 5
Training loss: 0.40992285127634387
Validation loss: 2.7451047531781785

Epoch: 5| Step: 6
Training loss: 0.4384677605711941
Validation loss: 2.7252682999984272

Epoch: 5| Step: 7
Training loss: 0.5223986437016124
Validation loss: 2.6949046872246054

Epoch: 5| Step: 8
Training loss: 0.6086290146058139
Validation loss: 2.698458033021383

Epoch: 5| Step: 9
Training loss: 0.8354131890380725
Validation loss: 2.669806899539407

Epoch: 5| Step: 10
Training loss: 0.68045572734858
Validation loss: 2.7482362712201533

Epoch: 5| Step: 11
Training loss: 0.2911374138084986
Validation loss: 2.7115154877797796

Epoch: 317| Step: 0
Training loss: 0.5323978253514324
Validation loss: 2.7242060318330794

Epoch: 5| Step: 1
Training loss: 0.4023805249638624
Validation loss: 2.7096140339912176

Epoch: 5| Step: 2
Training loss: 0.5573264999436542
Validation loss: 2.744850010888181

Epoch: 5| Step: 3
Training loss: 0.5073511815914592
Validation loss: 2.722625699412333

Epoch: 5| Step: 4
Training loss: 0.5933939719645774
Validation loss: 2.7657880968469195

Epoch: 5| Step: 5
Training loss: 0.2940612893682647
Validation loss: 2.743706270823822

Epoch: 5| Step: 6
Training loss: 0.37014255084496084
Validation loss: 2.7162899382642807

Epoch: 5| Step: 7
Training loss: 0.43991962679554575
Validation loss: 2.7631946165111363

Epoch: 5| Step: 8
Training loss: 0.4163877586853849
Validation loss: 2.630874826319349

Epoch: 5| Step: 9
Training loss: 0.6349326046149361
Validation loss: 2.6070607176934733

Epoch: 5| Step: 10
Training loss: 0.6417473521428751
Validation loss: 2.629523380089523

Epoch: 5| Step: 11
Training loss: 0.5814557142163395
Validation loss: 2.746801466928637

Epoch: 318| Step: 0
Training loss: 0.8930915340936817
Validation loss: 2.7130163249222887

Epoch: 5| Step: 1
Training loss: 0.39276714424239806
Validation loss: 2.718077799396811

Epoch: 5| Step: 2
Training loss: 0.42529184755162197
Validation loss: 2.737048268315446

Epoch: 5| Step: 3
Training loss: 0.5978556780220157
Validation loss: 2.743262581048074

Epoch: 5| Step: 4
Training loss: 0.5873033498806527
Validation loss: 2.7598866919626306

Epoch: 5| Step: 5
Training loss: 0.37034193477261396
Validation loss: 2.663283097033477

Epoch: 5| Step: 6
Training loss: 0.5094803051834109
Validation loss: 2.6668642996528735

Epoch: 5| Step: 7
Training loss: 0.49163504279262316
Validation loss: 2.7023007674271438

Epoch: 5| Step: 8
Training loss: 0.6019812030915115
Validation loss: 2.712895729567301

Epoch: 5| Step: 9
Training loss: 0.5870139089444174
Validation loss: 2.6871466071633656

Epoch: 5| Step: 10
Training loss: 0.6537132734992668
Validation loss: 2.7182016294660527

Epoch: 5| Step: 11
Training loss: 0.39801105416704025
Validation loss: 2.7209937202204033

Epoch: 319| Step: 0
Training loss: 0.31872541061624465
Validation loss: 2.7075665207578496

Epoch: 5| Step: 1
Training loss: 0.4751192658421339
Validation loss: 2.699115819298007

Epoch: 5| Step: 2
Training loss: 0.6055517570447436
Validation loss: 2.764481647598194

Epoch: 5| Step: 3
Training loss: 0.5214625150406441
Validation loss: 2.6559722867411786

Epoch: 5| Step: 4
Training loss: 0.6535939098470129
Validation loss: 2.6792368088158094

Epoch: 5| Step: 5
Training loss: 0.6065464887515344
Validation loss: 2.6758429712755367

Epoch: 5| Step: 6
Training loss: 0.3961370290252138
Validation loss: 2.672837416816198

Epoch: 5| Step: 7
Training loss: 0.6276460425202366
Validation loss: 2.654587094251341

Epoch: 5| Step: 8
Training loss: 0.6248468211337731
Validation loss: 2.643251196608168

Epoch: 5| Step: 9
Training loss: 0.5885052683779992
Validation loss: 2.638202225429111

Epoch: 5| Step: 10
Training loss: 0.4653079495998488
Validation loss: 2.6632823901940066

Epoch: 5| Step: 11
Training loss: 0.26187321389165047
Validation loss: 2.7082962889460926

Epoch: 320| Step: 0
Training loss: 0.3719248449755632
Validation loss: 2.655142830127646

Epoch: 5| Step: 1
Training loss: 0.6207004957581537
Validation loss: 2.7172388393296787

Epoch: 5| Step: 2
Training loss: 0.7115830226078048
Validation loss: 2.698534711843875

Epoch: 5| Step: 3
Training loss: 0.3958426482794447
Validation loss: 2.7316620001676437

Epoch: 5| Step: 4
Training loss: 0.5433914953921867
Validation loss: 2.7514487626272337

Epoch: 5| Step: 5
Training loss: 0.6367108397197235
Validation loss: 2.7685543896799976

Epoch: 5| Step: 6
Training loss: 0.39680569411554895
Validation loss: 2.7048374844782748

Epoch: 5| Step: 7
Training loss: 0.5607157329934613
Validation loss: 2.704435409413088

Epoch: 5| Step: 8
Training loss: 0.5998859823691772
Validation loss: 2.683681962267647

Epoch: 5| Step: 9
Training loss: 0.5036284989770158
Validation loss: 2.6291620093262575

Epoch: 5| Step: 10
Training loss: 0.3940770206604587
Validation loss: 2.7246236347294763

Epoch: 5| Step: 11
Training loss: 0.3694790898098833
Validation loss: 2.7586067576080557

Epoch: 321| Step: 0
Training loss: 0.5195002152201085
Validation loss: 2.721275121584276

Epoch: 5| Step: 1
Training loss: 0.5960964717777854
Validation loss: 2.7405890853541077

Epoch: 5| Step: 2
Training loss: 0.4555428550986404
Validation loss: 2.730409016681186

Epoch: 5| Step: 3
Training loss: 0.5525180676470649
Validation loss: 2.7536667848187655

Epoch: 5| Step: 4
Training loss: 0.4706454578071868
Validation loss: 2.8106958324625007

Epoch: 5| Step: 5
Training loss: 0.40862806916389766
Validation loss: 2.718532999374563

Epoch: 5| Step: 6
Training loss: 0.7616073918250346
Validation loss: 2.7026283381193457

Epoch: 5| Step: 7
Training loss: 0.5103889542147507
Validation loss: 2.7664380467894807

Epoch: 5| Step: 8
Training loss: 0.6060339473872253
Validation loss: 2.7684253229577536

Epoch: 5| Step: 9
Training loss: 0.6071919683821113
Validation loss: 2.7246667926531

Epoch: 5| Step: 10
Training loss: 0.6145147808010665
Validation loss: 2.754161471180673

Epoch: 5| Step: 11
Training loss: 0.5805473869936465
Validation loss: 2.7743057360521073

Epoch: 322| Step: 0
Training loss: 0.45290352900851155
Validation loss: 2.703565144582569

Epoch: 5| Step: 1
Training loss: 0.5697620818868651
Validation loss: 2.702706302710769

Epoch: 5| Step: 2
Training loss: 0.5025489328766457
Validation loss: 2.790477326157074

Epoch: 5| Step: 3
Training loss: 0.3999793941435495
Validation loss: 2.719896042095875

Epoch: 5| Step: 4
Training loss: 0.5015286086566307
Validation loss: 2.7367778901274753

Epoch: 5| Step: 5
Training loss: 0.8253217792097675
Validation loss: 2.704677092093062

Epoch: 5| Step: 6
Training loss: 0.4665913787918487
Validation loss: 2.7182203193418726

Epoch: 5| Step: 7
Training loss: 0.40610998748689664
Validation loss: 2.6947833550768236

Epoch: 5| Step: 8
Training loss: 0.33888192928030353
Validation loss: 2.670691650121964

Epoch: 5| Step: 9
Training loss: 0.6282239494387509
Validation loss: 2.6726120123779222

Epoch: 5| Step: 10
Training loss: 0.34893464131374036
Validation loss: 2.7282881244831847

Epoch: 5| Step: 11
Training loss: 0.9792539814645808
Validation loss: 2.7203204526425298

Epoch: 323| Step: 0
Training loss: 0.7381795984758845
Validation loss: 2.638146122891025

Epoch: 5| Step: 1
Training loss: 0.6088476833871779
Validation loss: 2.661145491730235

Epoch: 5| Step: 2
Training loss: 0.5370317715155895
Validation loss: 2.6454400098111934

Epoch: 5| Step: 3
Training loss: 0.3723338437893669
Validation loss: 2.5969287475030574

Epoch: 5| Step: 4
Training loss: 0.5680573437633313
Validation loss: 2.6702630458275363

Epoch: 5| Step: 5
Training loss: 0.6164648920165602
Validation loss: 2.6556046318984285

Epoch: 5| Step: 6
Training loss: 0.39753049574538213
Validation loss: 2.664745862168168

Epoch: 5| Step: 7
Training loss: 0.5166283872739301
Validation loss: 2.7023618903557103

Epoch: 5| Step: 8
Training loss: 0.3610742037611097
Validation loss: 2.6240171643716788

Epoch: 5| Step: 9
Training loss: 0.5320856870341787
Validation loss: 2.6940907607244364

Epoch: 5| Step: 10
Training loss: 0.3898742136395429
Validation loss: 2.6925614142903576

Epoch: 5| Step: 11
Training loss: 0.7872888251646444
Validation loss: 2.6802171382074964

Epoch: 324| Step: 0
Training loss: 0.4960936598890328
Validation loss: 2.6815677307846073

Epoch: 5| Step: 1
Training loss: 0.3597049442439295
Validation loss: 2.768734220484194

Epoch: 5| Step: 2
Training loss: 0.47669183820783834
Validation loss: 2.6967599566496196

Epoch: 5| Step: 3
Training loss: 0.3875894474035857
Validation loss: 2.5685314918545705

Epoch: 5| Step: 4
Training loss: 0.4465196877546448
Validation loss: 2.7253803871359437

Epoch: 5| Step: 5
Training loss: 0.5461189766270317
Validation loss: 2.714876122590404

Epoch: 5| Step: 6
Training loss: 0.7128097697351622
Validation loss: 2.725331718191308

Epoch: 5| Step: 7
Training loss: 0.36475442777250955
Validation loss: 2.6796610453702057

Epoch: 5| Step: 8
Training loss: 0.5676718942222687
Validation loss: 2.628996172534231

Epoch: 5| Step: 9
Training loss: 0.44824960075015974
Validation loss: 2.701344971570849

Epoch: 5| Step: 10
Training loss: 0.4970853012613041
Validation loss: 2.6596197221149045

Epoch: 5| Step: 11
Training loss: 0.2535791050177858
Validation loss: 2.6785086846193327

Epoch: 325| Step: 0
Training loss: 0.5211583522116734
Validation loss: 2.725363984428154

Epoch: 5| Step: 1
Training loss: 0.40914569067099893
Validation loss: 2.641773660615985

Epoch: 5| Step: 2
Training loss: 0.6015618559598571
Validation loss: 2.6841595611746665

Epoch: 5| Step: 3
Training loss: 0.48872157270293365
Validation loss: 2.685978673264668

Epoch: 5| Step: 4
Training loss: 0.4246616341894295
Validation loss: 2.7296318277796896

Epoch: 5| Step: 5
Training loss: 0.3197088601368081
Validation loss: 2.728136320698756

Epoch: 5| Step: 6
Training loss: 0.5897539083004468
Validation loss: 2.561388154456251

Epoch: 5| Step: 7
Training loss: 0.5188367690630141
Validation loss: 2.6403993852529495

Epoch: 5| Step: 8
Training loss: 0.43784363058043796
Validation loss: 2.7195780724397176

Epoch: 5| Step: 9
Training loss: 0.587770620879189
Validation loss: 2.6561728709373567

Epoch: 5| Step: 10
Training loss: 0.34038577209613485
Validation loss: 2.6364775182316613

Epoch: 5| Step: 11
Training loss: 0.6108472840414801
Validation loss: 2.7063141203663195

Epoch: 326| Step: 0
Training loss: 0.48034439958857666
Validation loss: 2.7967612671415303

Epoch: 5| Step: 1
Training loss: 0.7344387513754582
Validation loss: 2.6591093026254677

Epoch: 5| Step: 2
Training loss: 0.48855985703863036
Validation loss: 2.67483775264771

Epoch: 5| Step: 3
Training loss: 0.4573445835503429
Validation loss: 2.677455918227908

Epoch: 5| Step: 4
Training loss: 0.5491900082443332
Validation loss: 2.7457842953190617

Epoch: 5| Step: 5
Training loss: 0.4126221779302397
Validation loss: 2.7343684714103142

Epoch: 5| Step: 6
Training loss: 0.35707179367280706
Validation loss: 2.7454182357849217

Epoch: 5| Step: 7
Training loss: 0.5312043619187207
Validation loss: 2.715707611302394

Epoch: 5| Step: 8
Training loss: 0.48558307552652674
Validation loss: 2.6723336538127707

Epoch: 5| Step: 9
Training loss: 0.3407688921857007
Validation loss: 2.6741290112423153

Epoch: 5| Step: 10
Training loss: 0.44967318230395886
Validation loss: 2.725550368051983

Epoch: 5| Step: 11
Training loss: 0.5431317969666204
Validation loss: 2.736906772361445

Epoch: 327| Step: 0
Training loss: 0.47807402183182496
Validation loss: 2.7147223173285644

Epoch: 5| Step: 1
Training loss: 0.5384537120200532
Validation loss: 2.6991194482728376

Epoch: 5| Step: 2
Training loss: 0.3807224320921935
Validation loss: 2.6581247595176944

Epoch: 5| Step: 3
Training loss: 0.7912466583060861
Validation loss: 2.702796416258138

Epoch: 5| Step: 4
Training loss: 0.5642235893099024
Validation loss: 2.6815922698726915

Epoch: 5| Step: 5
Training loss: 0.5773162597801432
Validation loss: 2.73685643543708

Epoch: 5| Step: 6
Training loss: 0.49035103614260445
Validation loss: 2.7196427447075067

Epoch: 5| Step: 7
Training loss: 0.34861166539956584
Validation loss: 2.6782217289457337

Epoch: 5| Step: 8
Training loss: 0.4508270994038624
Validation loss: 2.677978719650494

Epoch: 5| Step: 9
Training loss: 0.5696735722298295
Validation loss: 2.685807297535337

Epoch: 5| Step: 10
Training loss: 0.28251836138950187
Validation loss: 2.6684640635926797

Epoch: 5| Step: 11
Training loss: 0.48429873081374153
Validation loss: 2.736718835376038

Epoch: 328| Step: 0
Training loss: 0.2968905595416267
Validation loss: 2.712569083815121

Epoch: 5| Step: 1
Training loss: 0.36587741159752746
Validation loss: 2.6697856326015796

Epoch: 5| Step: 2
Training loss: 0.5179148316549057
Validation loss: 2.710389975187415

Epoch: 5| Step: 3
Training loss: 0.6650976303683546
Validation loss: 2.6736375356719746

Epoch: 5| Step: 4
Training loss: 0.7099042657326635
Validation loss: 2.662738750839074

Epoch: 5| Step: 5
Training loss: 0.5468135254231495
Validation loss: 2.7157633296617534

Epoch: 5| Step: 6
Training loss: 0.576347660469449
Validation loss: 2.699921871088056

Epoch: 5| Step: 7
Training loss: 0.607167991250173
Validation loss: 2.78666000468273

Epoch: 5| Step: 8
Training loss: 0.5055779812220743
Validation loss: 2.790113149693403

Epoch: 5| Step: 9
Training loss: 0.4734117444274979
Validation loss: 2.788266304270345

Epoch: 5| Step: 10
Training loss: 0.6219371371639536
Validation loss: 2.7064820503611235

Epoch: 5| Step: 11
Training loss: 0.5035435753900445
Validation loss: 2.7314063751242204

Epoch: 329| Step: 0
Training loss: 0.359099572826738
Validation loss: 2.627872696542897

Epoch: 5| Step: 1
Training loss: 0.4908417969876903
Validation loss: 2.734936963417854

Epoch: 5| Step: 2
Training loss: 0.6418887907810645
Validation loss: 2.7405818683531695

Epoch: 5| Step: 3
Training loss: 0.4333119378707323
Validation loss: 2.722133967667654

Epoch: 5| Step: 4
Training loss: 0.6741067503798974
Validation loss: 2.66515998197914

Epoch: 5| Step: 5
Training loss: 0.5463745824916538
Validation loss: 2.759694268810801

Epoch: 5| Step: 6
Training loss: 0.43312705759217524
Validation loss: 2.7184098458432024

Epoch: 5| Step: 7
Training loss: 0.5307395109217378
Validation loss: 2.7631312224507814

Epoch: 5| Step: 8
Training loss: 0.5694807074664185
Validation loss: 2.6937045806749427

Epoch: 5| Step: 9
Training loss: 0.4658326761136454
Validation loss: 2.7443354201497905

Epoch: 5| Step: 10
Training loss: 0.43837225338108315
Validation loss: 2.592702284397555

Epoch: 5| Step: 11
Training loss: 0.27595323219683865
Validation loss: 2.66439154672671

Epoch: 330| Step: 0
Training loss: 0.7025839525335502
Validation loss: 2.7308079040941267

Epoch: 5| Step: 1
Training loss: 0.4542746921414193
Validation loss: 2.730453136437652

Epoch: 5| Step: 2
Training loss: 0.5742598797866233
Validation loss: 2.6388386359086717

Epoch: 5| Step: 3
Training loss: 0.4899857943285691
Validation loss: 2.6866527319648137

Epoch: 5| Step: 4
Training loss: 0.417311534945035
Validation loss: 2.7359764350518585

Epoch: 5| Step: 5
Training loss: 0.4102829147213279
Validation loss: 2.7330525933476757

Epoch: 5| Step: 6
Training loss: 0.4652970612105815
Validation loss: 2.646912498613837

Epoch: 5| Step: 7
Training loss: 0.4328132512330514
Validation loss: 2.7152583585523318

Epoch: 5| Step: 8
Training loss: 0.39299040823799236
Validation loss: 2.683458953240946

Epoch: 5| Step: 9
Training loss: 0.4945471075567915
Validation loss: 2.6935996284319668

Epoch: 5| Step: 10
Training loss: 0.3703100260720328
Validation loss: 2.715190896359462

Epoch: 5| Step: 11
Training loss: 0.7804178765473065
Validation loss: 2.7444031722156788

Epoch: 331| Step: 0
Training loss: 0.45432220349016605
Validation loss: 2.692877553250176

Epoch: 5| Step: 1
Training loss: 0.4599028305638883
Validation loss: 2.67468747990216

Epoch: 5| Step: 2
Training loss: 0.4444443622810897
Validation loss: 2.703867338117868

Epoch: 5| Step: 3
Training loss: 0.42264093522902363
Validation loss: 2.6861743725650777

Epoch: 5| Step: 4
Training loss: 0.41750782659469976
Validation loss: 2.599813436576041

Epoch: 5| Step: 5
Training loss: 0.6921123842767543
Validation loss: 2.701952413496639

Epoch: 5| Step: 6
Training loss: 0.4686710768061888
Validation loss: 2.6959133676286258

Epoch: 5| Step: 7
Training loss: 0.48646419414063824
Validation loss: 2.7108216787729376

Epoch: 5| Step: 8
Training loss: 0.5223483811109565
Validation loss: 2.7040528595775783

Epoch: 5| Step: 9
Training loss: 0.5857011191079466
Validation loss: 2.7926918159251573

Epoch: 5| Step: 10
Training loss: 0.7929063218070534
Validation loss: 2.7837989178353295

Epoch: 5| Step: 11
Training loss: 0.29549777410365957
Validation loss: 2.8029320978297805

Epoch: 332| Step: 0
Training loss: 0.5144528446182263
Validation loss: 2.6917600652908584

Epoch: 5| Step: 1
Training loss: 0.38910874777460214
Validation loss: 2.6778874556406045

Epoch: 5| Step: 2
Training loss: 0.7368308862839523
Validation loss: 2.6782559870613794

Epoch: 5| Step: 3
Training loss: 0.31627767799847223
Validation loss: 2.673814330008536

Epoch: 5| Step: 4
Training loss: 0.46500333082380263
Validation loss: 2.6932180292423866

Epoch: 5| Step: 5
Training loss: 0.4442322662476281
Validation loss: 2.6984680243265693

Epoch: 5| Step: 6
Training loss: 0.693847699202255
Validation loss: 2.693125024180111

Epoch: 5| Step: 7
Training loss: 0.32698757714769694
Validation loss: 2.701013372390516

Epoch: 5| Step: 8
Training loss: 0.400665077490096
Validation loss: 2.6380281112485147

Epoch: 5| Step: 9
Training loss: 0.48926618801112937
Validation loss: 2.5874762130110787

Epoch: 5| Step: 10
Training loss: 0.4308651997232164
Validation loss: 2.698004600878931

Epoch: 5| Step: 11
Training loss: 0.24938355380998223
Validation loss: 2.7363155490859445

Epoch: 333| Step: 0
Training loss: 0.45479489791754396
Validation loss: 2.6814820144767855

Epoch: 5| Step: 1
Training loss: 0.5144272098951141
Validation loss: 2.7233180496449583

Epoch: 5| Step: 2
Training loss: 0.3311396014485245
Validation loss: 2.6907385120970657

Epoch: 5| Step: 3
Training loss: 0.44316152115450846
Validation loss: 2.6696216588409714

Epoch: 5| Step: 4
Training loss: 0.5084277021124036
Validation loss: 2.7205315412796116

Epoch: 5| Step: 5
Training loss: 0.40406868433515974
Validation loss: 2.794352646074703

Epoch: 5| Step: 6
Training loss: 0.45133028098224187
Validation loss: 2.645263671875

Epoch: 5| Step: 7
Training loss: 0.5838957244030528
Validation loss: 2.669706924295177

Epoch: 5| Step: 8
Training loss: 0.7758116840028508
Validation loss: 2.70616376370884

Epoch: 5| Step: 9
Training loss: 0.328923638579597
Validation loss: 2.653250318831825

Epoch: 5| Step: 10
Training loss: 0.42537965996852367
Validation loss: 2.701974090881612

Epoch: 5| Step: 11
Training loss: 0.16032454905487425
Validation loss: 2.6457171314483974

Epoch: 334| Step: 0
Training loss: 0.6149880294487692
Validation loss: 2.7881725219892957

Epoch: 5| Step: 1
Training loss: 0.5852093559175626
Validation loss: 2.8227093304907243

Epoch: 5| Step: 2
Training loss: 0.44432564189007917
Validation loss: 2.7022135379413643

Epoch: 5| Step: 3
Training loss: 0.680224809159848
Validation loss: 2.7139021303961637

Epoch: 5| Step: 4
Training loss: 0.37365347789639936
Validation loss: 2.7477485080849493

Epoch: 5| Step: 5
Training loss: 0.4396769144536793
Validation loss: 2.670332766553274

Epoch: 5| Step: 6
Training loss: 0.5153091503656733
Validation loss: 2.7413478301172263

Epoch: 5| Step: 7
Training loss: 0.44194431762119385
Validation loss: 2.739958934394988

Epoch: 5| Step: 8
Training loss: 0.5508231830190732
Validation loss: 2.658149290789321

Epoch: 5| Step: 9
Training loss: 0.21329377874667674
Validation loss: 2.690149442889339

Epoch: 5| Step: 10
Training loss: 0.505464554405193
Validation loss: 2.7308044063561763

Epoch: 5| Step: 11
Training loss: 0.6622666703801277
Validation loss: 2.737395915719219

Epoch: 335| Step: 0
Training loss: 0.5606982462058032
Validation loss: 2.7140821417765966

Epoch: 5| Step: 1
Training loss: 0.527653723143903
Validation loss: 2.7257830863896158

Epoch: 5| Step: 2
Training loss: 0.5951019755899094
Validation loss: 2.687546101256041

Epoch: 5| Step: 3
Training loss: 0.4782009725112471
Validation loss: 2.7691851526541247

Epoch: 5| Step: 4
Training loss: 0.5154659719585988
Validation loss: 2.7194331578732793

Epoch: 5| Step: 5
Training loss: 0.4116003680639503
Validation loss: 2.6994635383104004

Epoch: 5| Step: 6
Training loss: 0.28457700345794346
Validation loss: 2.7162757042729075

Epoch: 5| Step: 7
Training loss: 0.37990687669176904
Validation loss: 2.6914250742748127

Epoch: 5| Step: 8
Training loss: 0.3796413605524265
Validation loss: 2.8068159026982715

Epoch: 5| Step: 9
Training loss: 0.5200424547470907
Validation loss: 2.6812846703944304

Epoch: 5| Step: 10
Training loss: 0.5630595285373446
Validation loss: 2.7013940266988272

Epoch: 5| Step: 11
Training loss: 0.3811655623313364
Validation loss: 2.7220919082119606

Epoch: 336| Step: 0
Training loss: 0.6236985245756772
Validation loss: 2.7660644203712224

Epoch: 5| Step: 1
Training loss: 0.594339554870007
Validation loss: 2.6885766397443382

Epoch: 5| Step: 2
Training loss: 0.3430376691805796
Validation loss: 2.7168028991617805

Epoch: 5| Step: 3
Training loss: 0.48492452766697136
Validation loss: 2.667588366475185

Epoch: 5| Step: 4
Training loss: 0.48274765134681596
Validation loss: 2.747198585311712

Epoch: 5| Step: 5
Training loss: 0.39994908619745406
Validation loss: 2.6702554676207195

Epoch: 5| Step: 6
Training loss: 0.2884500433239216
Validation loss: 2.6836905797436996

Epoch: 5| Step: 7
Training loss: 0.5345839064196842
Validation loss: 2.7464663097728073

Epoch: 5| Step: 8
Training loss: 0.5843324676375968
Validation loss: 2.662271451319333

Epoch: 5| Step: 9
Training loss: 0.3910072744965994
Validation loss: 2.7361872779961525

Epoch: 5| Step: 10
Training loss: 0.43833336477799295
Validation loss: 2.670591559206307

Epoch: 5| Step: 11
Training loss: 0.3833599069271747
Validation loss: 2.726443112299943

Epoch: 337| Step: 0
Training loss: 0.5645039149470441
Validation loss: 2.6984418900274996

Epoch: 5| Step: 1
Training loss: 0.4504001176401157
Validation loss: 2.6672374268506984

Epoch: 5| Step: 2
Training loss: 0.31520937379680863
Validation loss: 2.7091445160434198

Epoch: 5| Step: 3
Training loss: 0.3712247516896113
Validation loss: 2.74376946922468

Epoch: 5| Step: 4
Training loss: 0.3154378482483358
Validation loss: 2.7034145505174543

Epoch: 5| Step: 5
Training loss: 0.4245987491629221
Validation loss: 2.740525935045269

Epoch: 5| Step: 6
Training loss: 0.35912733251316736
Validation loss: 2.679339120237706

Epoch: 5| Step: 7
Training loss: 0.5270592381193104
Validation loss: 2.688474016595982

Epoch: 5| Step: 8
Training loss: 0.6006640871887341
Validation loss: 2.7621301563092415

Epoch: 5| Step: 9
Training loss: 0.5525050412030041
Validation loss: 2.738016356073359

Epoch: 5| Step: 10
Training loss: 0.3843898971896207
Validation loss: 2.7539304799846915

Epoch: 5| Step: 11
Training loss: 0.6989932415844238
Validation loss: 2.679193163800557

Epoch: 338| Step: 0
Training loss: 0.5111689635317335
Validation loss: 2.6953296716115425

Epoch: 5| Step: 1
Training loss: 0.5389456691465658
Validation loss: 2.700520118460688

Epoch: 5| Step: 2
Training loss: 0.6597221346626446
Validation loss: 2.669925748296243

Epoch: 5| Step: 3
Training loss: 0.5625643693333253
Validation loss: 2.6693580588378745

Epoch: 5| Step: 4
Training loss: 0.6658110542134851
Validation loss: 2.7568703483859975

Epoch: 5| Step: 5
Training loss: 0.4845773366582753
Validation loss: 2.6663721593761474

Epoch: 5| Step: 6
Training loss: 0.4334288618661299
Validation loss: 2.697622564234181

Epoch: 5| Step: 7
Training loss: 0.5348299800026295
Validation loss: 2.8564276244221753

Epoch: 5| Step: 8
Training loss: 0.5218140206716322
Validation loss: 2.765025970182963

Epoch: 5| Step: 9
Training loss: 0.5474537103497779
Validation loss: 2.780197347964931

Epoch: 5| Step: 10
Training loss: 0.49580646817438007
Validation loss: 2.7808912381583317

Epoch: 5| Step: 11
Training loss: 0.6751317116485506
Validation loss: 2.8305287902905127

Epoch: 339| Step: 0
Training loss: 0.40798878860496873
Validation loss: 2.6979091354520297

Epoch: 5| Step: 1
Training loss: 0.6273711525144863
Validation loss: 2.669542616367005

Epoch: 5| Step: 2
Training loss: 0.3417171167230842
Validation loss: 2.744116185487858

Epoch: 5| Step: 3
Training loss: 0.5300404017272174
Validation loss: 2.748708537322319

Epoch: 5| Step: 4
Training loss: 0.5617693818555354
Validation loss: 2.717994069647337

Epoch: 5| Step: 5
Training loss: 0.4543494911589386
Validation loss: 2.6812082837230418

Epoch: 5| Step: 6
Training loss: 0.5297791089534615
Validation loss: 2.7171794860528626

Epoch: 5| Step: 7
Training loss: 0.659269968137647
Validation loss: 2.7681085315638514

Epoch: 5| Step: 8
Training loss: 0.4453142400339497
Validation loss: 2.746655102471278

Epoch: 5| Step: 9
Training loss: 0.4170920902264045
Validation loss: 2.7602227964638235

Epoch: 5| Step: 10
Training loss: 0.6743291346780224
Validation loss: 2.793645834492104

Epoch: 5| Step: 11
Training loss: 0.1357069724530737
Validation loss: 2.706912413791931

Epoch: 340| Step: 0
Training loss: 0.2758722625202516
Validation loss: 2.722867183094601

Epoch: 5| Step: 1
Training loss: 0.7643912748910784
Validation loss: 2.7327859130229126

Epoch: 5| Step: 2
Training loss: 0.5039867070749777
Validation loss: 2.67723519764075

Epoch: 5| Step: 3
Training loss: 0.4621659735153857
Validation loss: 2.6745248336879945

Epoch: 5| Step: 4
Training loss: 0.4163044209173842
Validation loss: 2.6686829578635543

Epoch: 5| Step: 5
Training loss: 0.5145151736669806
Validation loss: 2.7049576384775884

Epoch: 5| Step: 6
Training loss: 0.42397312900803613
Validation loss: 2.665590331048524

Epoch: 5| Step: 7
Training loss: 0.4322659722317656
Validation loss: 2.7188305714971124

Epoch: 5| Step: 8
Training loss: 0.5225674814699239
Validation loss: 2.792437917775702

Epoch: 5| Step: 9
Training loss: 0.6268386260915357
Validation loss: 2.6549433055997915

Epoch: 5| Step: 10
Training loss: 0.43083090804848223
Validation loss: 2.729615659883839

Epoch: 5| Step: 11
Training loss: 0.6261985968244189
Validation loss: 2.752250660716991

Epoch: 341| Step: 0
Training loss: 0.50760018238383
Validation loss: 2.7324259650940785

Epoch: 5| Step: 1
Training loss: 0.3701643095994871
Validation loss: 2.6911842243539024

Epoch: 5| Step: 2
Training loss: 0.5692894002173223
Validation loss: 2.700199193876948

Epoch: 5| Step: 3
Training loss: 0.4897294654951843
Validation loss: 2.727847466001619

Epoch: 5| Step: 4
Training loss: 0.5078635850300028
Validation loss: 2.7187634354474977

Epoch: 5| Step: 5
Training loss: 0.5709151128212219
Validation loss: 2.6696824862009514

Epoch: 5| Step: 6
Training loss: 0.5316304079036807
Validation loss: 2.7186881200829642

Epoch: 5| Step: 7
Training loss: 0.38351178041241857
Validation loss: 2.659402382900554

Epoch: 5| Step: 8
Training loss: 0.4412225661786503
Validation loss: 2.6583108144412226

Epoch: 5| Step: 9
Training loss: 0.4177013682817675
Validation loss: 2.683476770804515

Epoch: 5| Step: 10
Training loss: 0.47203050918293676
Validation loss: 2.64866336770848

Epoch: 5| Step: 11
Training loss: 0.4186512375130263
Validation loss: 2.6670902494442084

Epoch: 342| Step: 0
Training loss: 0.48181390483877534
Validation loss: 2.693482423608278

Epoch: 5| Step: 1
Training loss: 0.632525155091179
Validation loss: 2.6344036497441423

Epoch: 5| Step: 2
Training loss: 0.4786488872952281
Validation loss: 2.663941310687868

Epoch: 5| Step: 3
Training loss: 0.5776060197787288
Validation loss: 2.6511791314769124

Epoch: 5| Step: 4
Training loss: 0.5628004860959261
Validation loss: 2.693010521072213

Epoch: 5| Step: 5
Training loss: 0.3574452835505545
Validation loss: 2.7329313190934186

Epoch: 5| Step: 6
Training loss: 0.4699810076488016
Validation loss: 2.7073353151210675

Epoch: 5| Step: 7
Training loss: 0.5256039211296762
Validation loss: 2.6783628795060705

Epoch: 5| Step: 8
Training loss: 0.3997843921245377
Validation loss: 2.7260972239034773

Epoch: 5| Step: 9
Training loss: 0.3828068363004279
Validation loss: 2.7018982744240283

Epoch: 5| Step: 10
Training loss: 0.44166189572018694
Validation loss: 2.7659448090324794

Epoch: 5| Step: 11
Training loss: 0.5120602407388144
Validation loss: 2.6828364007381746

Epoch: 343| Step: 0
Training loss: 0.6582211002419639
Validation loss: 2.7019074110431003

Epoch: 5| Step: 1
Training loss: 0.4002486744905786
Validation loss: 2.738884827124202

Epoch: 5| Step: 2
Training loss: 0.4987665250378163
Validation loss: 2.69053625875377

Epoch: 5| Step: 3
Training loss: 0.3510373431749798
Validation loss: 2.633050822895752

Epoch: 5| Step: 4
Training loss: 0.6588975768935308
Validation loss: 2.728066413107572

Epoch: 5| Step: 5
Training loss: 0.5277680562055366
Validation loss: 2.654823380125465

Epoch: 5| Step: 6
Training loss: 0.5345532716676847
Validation loss: 2.7145986761995036

Epoch: 5| Step: 7
Training loss: 0.4778432208976289
Validation loss: 2.7571444075896765

Epoch: 5| Step: 8
Training loss: 0.44211258540089177
Validation loss: 2.7316695171195478

Epoch: 5| Step: 9
Training loss: 0.4069168779470403
Validation loss: 2.6518528652113993

Epoch: 5| Step: 10
Training loss: 0.5421421427814481
Validation loss: 2.7136278279122674

Epoch: 5| Step: 11
Training loss: 0.22605607555247356
Validation loss: 2.7518826311629296

Epoch: 344| Step: 0
Training loss: 0.5043690648255591
Validation loss: 2.70726931407273

Epoch: 5| Step: 1
Training loss: 0.39863151613629316
Validation loss: 2.7037413230753238

Epoch: 5| Step: 2
Training loss: 0.5362334721470196
Validation loss: 2.6730628505602705

Epoch: 5| Step: 3
Training loss: 0.44154971669153115
Validation loss: 2.6769583162043746

Epoch: 5| Step: 4
Training loss: 0.32901657546603985
Validation loss: 2.699858744629109

Epoch: 5| Step: 5
Training loss: 0.48105111533173367
Validation loss: 2.6275494169360467

Epoch: 5| Step: 6
Training loss: 0.5403270264101955
Validation loss: 2.699953517469551

Epoch: 5| Step: 7
Training loss: 0.5474340850744471
Validation loss: 2.7137680117950747

Epoch: 5| Step: 8
Training loss: 0.6422345248637655
Validation loss: 2.661779549780148

Epoch: 5| Step: 9
Training loss: 0.4715372190277789
Validation loss: 2.6773437040648256

Epoch: 5| Step: 10
Training loss: 0.5772445521223573
Validation loss: 2.6966423789666636

Epoch: 5| Step: 11
Training loss: 0.23296497907343428
Validation loss: 2.6959431817984734

Epoch: 345| Step: 0
Training loss: 0.4312162081982664
Validation loss: 2.626761564434132

Epoch: 5| Step: 1
Training loss: 0.49697368409584036
Validation loss: 2.701603937428798

Epoch: 5| Step: 2
Training loss: 0.40423795482664526
Validation loss: 2.6331609387846036

Epoch: 5| Step: 3
Training loss: 0.27916203425013314
Validation loss: 2.650610888143073

Epoch: 5| Step: 4
Training loss: 0.597343113465086
Validation loss: 2.697695098282009

Epoch: 5| Step: 5
Training loss: 0.3652961189180285
Validation loss: 2.691137694463474

Epoch: 5| Step: 6
Training loss: 0.4082913463116463
Validation loss: 2.695105046199017

Epoch: 5| Step: 7
Training loss: 0.5377106231715582
Validation loss: 2.731492206824224

Epoch: 5| Step: 8
Training loss: 0.48873462228412956
Validation loss: 2.6157986879885

Epoch: 5| Step: 9
Training loss: 0.4276380038454443
Validation loss: 2.6986382352895006

Epoch: 5| Step: 10
Training loss: 0.5187398863576366
Validation loss: 2.686418687282108

Epoch: 5| Step: 11
Training loss: 0.40677152683265694
Validation loss: 2.746529249348161

Epoch: 346| Step: 0
Training loss: 0.33595453263506786
Validation loss: 2.692228308907298

Epoch: 5| Step: 1
Training loss: 0.6176192789281807
Validation loss: 2.7130336517794738

Epoch: 5| Step: 2
Training loss: 0.3460096089056928
Validation loss: 2.657376387135462

Epoch: 5| Step: 3
Training loss: 0.5343597778026102
Validation loss: 2.7126622828268236

Epoch: 5| Step: 4
Training loss: 0.6163637966142754
Validation loss: 2.626072978421033

Epoch: 5| Step: 5
Training loss: 0.4021638078980557
Validation loss: 2.6451057775411386

Epoch: 5| Step: 6
Training loss: 0.5358686508574954
Validation loss: 2.7100139220960484

Epoch: 5| Step: 7
Training loss: 0.394404022551445
Validation loss: 2.7304137901556063

Epoch: 5| Step: 8
Training loss: 0.40469970537433686
Validation loss: 2.732360242903396

Epoch: 5| Step: 9
Training loss: 0.39984544062732186
Validation loss: 2.7644127202132367

Epoch: 5| Step: 10
Training loss: 0.4890048806613911
Validation loss: 2.701129003677839

Epoch: 5| Step: 11
Training loss: 0.44593623465216153
Validation loss: 2.788850902719366

Epoch: 347| Step: 0
Training loss: 0.4757921840870807
Validation loss: 2.757966302936138

Epoch: 5| Step: 1
Training loss: 0.5221493085755626
Validation loss: 2.6278144152443748

Epoch: 5| Step: 2
Training loss: 0.657398127797301
Validation loss: 2.8163275035302373

Epoch: 5| Step: 3
Training loss: 0.3447693752255142
Validation loss: 2.7275881363928973

Epoch: 5| Step: 4
Training loss: 0.38112861702148204
Validation loss: 2.7006407293903223

Epoch: 5| Step: 5
Training loss: 0.5050462941393967
Validation loss: 2.655612824255651

Epoch: 5| Step: 6
Training loss: 0.3855114017079451
Validation loss: 2.658549300950762

Epoch: 5| Step: 7
Training loss: 0.4971544085938556
Validation loss: 2.6579175912995283

Epoch: 5| Step: 8
Training loss: 0.4131459221901926
Validation loss: 2.6461837579049043

Epoch: 5| Step: 9
Training loss: 0.38513791038692136
Validation loss: 2.6756309244294796

Epoch: 5| Step: 10
Training loss: 0.5125718322283909
Validation loss: 2.672594040606916

Epoch: 5| Step: 11
Training loss: 0.3353837350510395
Validation loss: 2.739944696465771

Epoch: 348| Step: 0
Training loss: 0.40782005186140746
Validation loss: 2.6888821803148075

Epoch: 5| Step: 1
Training loss: 0.6625695893788466
Validation loss: 2.734775473922883

Epoch: 5| Step: 2
Training loss: 0.47394106557501636
Validation loss: 2.7283630109962163

Epoch: 5| Step: 3
Training loss: 0.4074760057254023
Validation loss: 2.722251747108016

Epoch: 5| Step: 4
Training loss: 0.43638243307373775
Validation loss: 2.691601174525247

Epoch: 5| Step: 5
Training loss: 0.5571815940556768
Validation loss: 2.7050897242254934

Epoch: 5| Step: 6
Training loss: 0.6296706677783094
Validation loss: 2.639132222590328

Epoch: 5| Step: 7
Training loss: 0.5833129595422932
Validation loss: 2.640300309423254

Epoch: 5| Step: 8
Training loss: 0.5326670092846975
Validation loss: 2.6675147828821943

Epoch: 5| Step: 9
Training loss: 0.42727033273876297
Validation loss: 2.6412623499677705

Epoch: 5| Step: 10
Training loss: 0.4766891498809707
Validation loss: 2.6676575128693854

Epoch: 5| Step: 11
Training loss: 0.6174447211723599
Validation loss: 2.692995164352676

Epoch: 349| Step: 0
Training loss: 0.43123386601660907
Validation loss: 2.72612303477678

Epoch: 5| Step: 1
Training loss: 0.6545496438128978
Validation loss: 2.687201350274333

Epoch: 5| Step: 2
Training loss: 0.5468053228404554
Validation loss: 2.703688751999008

Epoch: 5| Step: 3
Training loss: 0.3466487602085715
Validation loss: 2.6885579174594567

Epoch: 5| Step: 4
Training loss: 0.3973357169733992
Validation loss: 2.6959124979976625

Epoch: 5| Step: 5
Training loss: 0.39286556443873216
Validation loss: 2.700425632212555

Epoch: 5| Step: 6
Training loss: 0.5835750765794011
Validation loss: 2.733300999027604

Epoch: 5| Step: 7
Training loss: 0.42830772816287543
Validation loss: 2.6405373395104696

Epoch: 5| Step: 8
Training loss: 0.32753604302922457
Validation loss: 2.687511647369222

Epoch: 5| Step: 9
Training loss: 0.3747725989365018
Validation loss: 2.6925362003777207

Epoch: 5| Step: 10
Training loss: 0.3956091856846608
Validation loss: 2.644424169599144

Epoch: 5| Step: 11
Training loss: 0.4378439198614037
Validation loss: 2.70767893343466

Epoch: 350| Step: 0
Training loss: 0.5851078517644513
Validation loss: 2.7274149060517012

Epoch: 5| Step: 1
Training loss: 0.4693187124684697
Validation loss: 2.7588073837887213

Epoch: 5| Step: 2
Training loss: 0.4312878889218707
Validation loss: 2.713503558476424

Epoch: 5| Step: 3
Training loss: 0.44110585008619274
Validation loss: 2.7123392239106954

Epoch: 5| Step: 4
Training loss: 0.43234373453165736
Validation loss: 2.673972546448411

Epoch: 5| Step: 5
Training loss: 0.597261859689823
Validation loss: 2.7348734228818685

Epoch: 5| Step: 6
Training loss: 0.36447957015508076
Validation loss: 2.6893229438045663

Epoch: 5| Step: 7
Training loss: 0.5046892809762621
Validation loss: 2.6863990125335095

Epoch: 5| Step: 8
Training loss: 0.41761188780961733
Validation loss: 2.7217188279013773

Epoch: 5| Step: 9
Training loss: 0.37576618997132527
Validation loss: 2.6980531036951607

Epoch: 5| Step: 10
Training loss: 0.43397328373756255
Validation loss: 2.7027752563660394

Epoch: 5| Step: 11
Training loss: 0.6398750893692816
Validation loss: 2.6464213271097363

Epoch: 351| Step: 0
Training loss: 0.4425180830466483
Validation loss: 2.6814208323810527

Epoch: 5| Step: 1
Training loss: 0.36488501011184926
Validation loss: 2.7187335317120236

Epoch: 5| Step: 2
Training loss: 0.584626243762899
Validation loss: 2.6702052619223737

Epoch: 5| Step: 3
Training loss: 0.4240033714715951
Validation loss: 2.735619116630035

Epoch: 5| Step: 4
Training loss: 0.34679797666288337
Validation loss: 2.744558846855899

Epoch: 5| Step: 5
Training loss: 0.5512560698332905
Validation loss: 2.6620131596739856

Epoch: 5| Step: 6
Training loss: 0.4443672420666861
Validation loss: 2.653967104485391

Epoch: 5| Step: 7
Training loss: 0.5394271778051236
Validation loss: 2.7146547356908086

Epoch: 5| Step: 8
Training loss: 0.39318927242526563
Validation loss: 2.725172397135611

Epoch: 5| Step: 9
Training loss: 0.372857949715244
Validation loss: 2.7056776904048836

Epoch: 5| Step: 10
Training loss: 0.4801532050351817
Validation loss: 2.672036625247533

Epoch: 5| Step: 11
Training loss: 0.4454928919506623
Validation loss: 2.7135613758642956

Epoch: 352| Step: 0
Training loss: 0.4269379120094434
Validation loss: 2.784598832886186

Epoch: 5| Step: 1
Training loss: 0.4026245322593381
Validation loss: 2.6407647989349488

Epoch: 5| Step: 2
Training loss: 0.648430514010749
Validation loss: 2.8041004923191637

Epoch: 5| Step: 3
Training loss: 0.2838443468594305
Validation loss: 2.7501655658819666

Epoch: 5| Step: 4
Training loss: 0.4588488764318997
Validation loss: 2.6747388085335793

Epoch: 5| Step: 5
Training loss: 0.43890981361080483
Validation loss: 2.670359291275329

Epoch: 5| Step: 6
Training loss: 0.4794345984283474
Validation loss: 2.684650227992462

Epoch: 5| Step: 7
Training loss: 0.4480415676504346
Validation loss: 2.672854606451072

Epoch: 5| Step: 8
Training loss: 0.4972962950592442
Validation loss: 2.6880332173845254

Epoch: 5| Step: 9
Training loss: 0.4254713067781002
Validation loss: 2.730449547288539

Epoch: 5| Step: 10
Training loss: 0.3508262023499324
Validation loss: 2.7018130247861873

Epoch: 5| Step: 11
Training loss: 0.2616819526652907
Validation loss: 2.712076609246604

Epoch: 353| Step: 0
Training loss: 0.5644492706906414
Validation loss: 2.661027146787628

Epoch: 5| Step: 1
Training loss: 0.6334991967784002
Validation loss: 2.709524073857352

Epoch: 5| Step: 2
Training loss: 0.500459162167388
Validation loss: 2.695345453622948

Epoch: 5| Step: 3
Training loss: 0.40766864446335443
Validation loss: 2.7548224347771146

Epoch: 5| Step: 4
Training loss: 0.4532150146261003
Validation loss: 2.693557888697849

Epoch: 5| Step: 5
Training loss: 0.4171753599422153
Validation loss: 2.709661009174394

Epoch: 5| Step: 6
Training loss: 0.6594864421156555
Validation loss: 2.7018470517961064

Epoch: 5| Step: 7
Training loss: 0.5799417817148581
Validation loss: 2.664280309191334

Epoch: 5| Step: 8
Training loss: 0.47668095976845665
Validation loss: 2.6885975585196373

Epoch: 5| Step: 9
Training loss: 0.47271017287182077
Validation loss: 2.6257454517560825

Epoch: 5| Step: 10
Training loss: 0.42682367859687625
Validation loss: 2.665207103306633

Epoch: 5| Step: 11
Training loss: 0.45448975736577363
Validation loss: 2.7594776907763974

Epoch: 354| Step: 0
Training loss: 0.3920096271400744
Validation loss: 2.6847187776889356

Epoch: 5| Step: 1
Training loss: 0.4884731068387863
Validation loss: 2.7250643442589126

Epoch: 5| Step: 2
Training loss: 0.4304862314818149
Validation loss: 2.6650835990795496

Epoch: 5| Step: 3
Training loss: 0.4714547957881693
Validation loss: 2.6704113987524347

Epoch: 5| Step: 4
Training loss: 0.38488177177887045
Validation loss: 2.657581410798342

Epoch: 5| Step: 5
Training loss: 0.3785513562796011
Validation loss: 2.7445270994730353

Epoch: 5| Step: 6
Training loss: 0.43061016896014553
Validation loss: 2.6467264325130455

Epoch: 5| Step: 7
Training loss: 0.6120672906504852
Validation loss: 2.698339290484693

Epoch: 5| Step: 8
Training loss: 0.6500479222018213
Validation loss: 2.6662409536974567

Epoch: 5| Step: 9
Training loss: 0.4834488659381338
Validation loss: 2.713340756720933

Epoch: 5| Step: 10
Training loss: 0.3649860292530544
Validation loss: 2.6732012169602197

Epoch: 5| Step: 11
Training loss: 0.8446378275399796
Validation loss: 2.7169380032494725

Epoch: 355| Step: 0
Training loss: 0.4702684920496368
Validation loss: 2.7425590437320535

Epoch: 5| Step: 1
Training loss: 0.3228968132232743
Validation loss: 2.7011453604712785

Epoch: 5| Step: 2
Training loss: 0.4178358026995054
Validation loss: 2.6951916395723403

Epoch: 5| Step: 3
Training loss: 0.29661789854015047
Validation loss: 2.6357699648700916

Epoch: 5| Step: 4
Training loss: 0.44425697044159257
Validation loss: 2.6276628918066773

Epoch: 5| Step: 5
Training loss: 0.608403384952421
Validation loss: 2.5964875041938416

Epoch: 5| Step: 6
Training loss: 0.5877431133147514
Validation loss: 2.6674931531876056

Epoch: 5| Step: 7
Training loss: 0.41060631899674654
Validation loss: 2.7292374329941103

Epoch: 5| Step: 8
Training loss: 0.4621102882047322
Validation loss: 2.7475482205378774

Epoch: 5| Step: 9
Training loss: 0.441686321966798
Validation loss: 2.6994769299072403

Epoch: 5| Step: 10
Training loss: 0.4439138398802244
Validation loss: 2.751253671336032

Epoch: 5| Step: 11
Training loss: 0.7960604075748522
Validation loss: 2.7581882599042564

Epoch: 356| Step: 0
Training loss: 0.43156511845992457
Validation loss: 2.744806933254997

Epoch: 5| Step: 1
Training loss: 0.4415804426431331
Validation loss: 2.7586581416840317

Epoch: 5| Step: 2
Training loss: 0.57989288352169
Validation loss: 2.692424457916558

Epoch: 5| Step: 3
Training loss: 0.3812397353557136
Validation loss: 2.6909693680341342

Epoch: 5| Step: 4
Training loss: 0.5996700343162388
Validation loss: 2.796824147563074

Epoch: 5| Step: 5
Training loss: 0.44123509557477325
Validation loss: 2.7776165384278997

Epoch: 5| Step: 6
Training loss: 0.5880710667073249
Validation loss: 2.750182481693419

Epoch: 5| Step: 7
Training loss: 0.35603936476806897
Validation loss: 2.7071886883816383

Epoch: 5| Step: 8
Training loss: 0.47424121596084756
Validation loss: 2.713207609929428

Epoch: 5| Step: 9
Training loss: 0.5937246267016941
Validation loss: 2.7458845197212427

Epoch: 5| Step: 10
Training loss: 0.5072168818605047
Validation loss: 2.7134304237383287

Epoch: 5| Step: 11
Training loss: 0.27356859879104434
Validation loss: 2.6712351064366477

Epoch: 357| Step: 0
Training loss: 0.47174321412228
Validation loss: 2.636851650703383

Epoch: 5| Step: 1
Training loss: 0.3827708863976172
Validation loss: 2.7508667136367237

Epoch: 5| Step: 2
Training loss: 0.5314465888308417
Validation loss: 2.66497499233534

Epoch: 5| Step: 3
Training loss: 0.46695215044818217
Validation loss: 2.6902535401066867

Epoch: 5| Step: 4
Training loss: 0.3681222502341816
Validation loss: 2.6424404427016133

Epoch: 5| Step: 5
Training loss: 0.46174395858703554
Validation loss: 2.6526912448466162

Epoch: 5| Step: 6
Training loss: 0.5287020955581219
Validation loss: 2.6219585714558993

Epoch: 5| Step: 7
Training loss: 0.5943649019171741
Validation loss: 2.6350231417134977

Epoch: 5| Step: 8
Training loss: 0.48120304535027386
Validation loss: 2.6323595364818946

Epoch: 5| Step: 9
Training loss: 0.3112888230006814
Validation loss: 2.6532231681523983

Epoch: 5| Step: 10
Training loss: 0.3612461306354836
Validation loss: 2.628571115324629

Epoch: 5| Step: 11
Training loss: 0.17031137177329883
Validation loss: 2.614553597016459

Epoch: 358| Step: 0
Training loss: 0.4185327841919236
Validation loss: 2.7070690627620033

Epoch: 5| Step: 1
Training loss: 0.2518288061695244
Validation loss: 2.687714823187764

Epoch: 5| Step: 2
Training loss: 0.7065168163676663
Validation loss: 2.731957913160671

Epoch: 5| Step: 3
Training loss: 0.5051129405095576
Validation loss: 2.663058038445807

Epoch: 5| Step: 4
Training loss: 0.5370927842785665
Validation loss: 2.709398563902923

Epoch: 5| Step: 5
Training loss: 0.3831708554243157
Validation loss: 2.7123243392225453

Epoch: 5| Step: 6
Training loss: 0.46595802110988266
Validation loss: 2.7821584746541954

Epoch: 5| Step: 7
Training loss: 0.4691755747104698
Validation loss: 2.6763720748809603

Epoch: 5| Step: 8
Training loss: 0.36084727691303725
Validation loss: 2.7797153217766715

Epoch: 5| Step: 9
Training loss: 0.4084596694731943
Validation loss: 2.8258813314562254

Epoch: 5| Step: 10
Training loss: 0.40093519812240536
Validation loss: 2.6196504116212553

Epoch: 5| Step: 11
Training loss: 0.19386205931995967
Validation loss: 2.711027904252678

Epoch: 359| Step: 0
Training loss: 0.5585574158275678
Validation loss: 2.735361350043247

Epoch: 5| Step: 1
Training loss: 0.4436495667290267
Validation loss: 2.6917860910084026

Epoch: 5| Step: 2
Training loss: 0.4802447471410811
Validation loss: 2.7542186550845074

Epoch: 5| Step: 3
Training loss: 0.5524464318901742
Validation loss: 2.722960303252928

Epoch: 5| Step: 4
Training loss: 0.42086859152491835
Validation loss: 2.732646482996478

Epoch: 5| Step: 5
Training loss: 0.37058741509211446
Validation loss: 2.7506691631495186

Epoch: 5| Step: 6
Training loss: 0.34710698188954464
Validation loss: 2.7462858491924047

Epoch: 5| Step: 7
Training loss: 0.30315505301555074
Validation loss: 2.732043280287303

Epoch: 5| Step: 8
Training loss: 0.3408180389765681
Validation loss: 2.7548894619560023

Epoch: 5| Step: 9
Training loss: 0.44240709789723276
Validation loss: 2.71756980207122

Epoch: 5| Step: 10
Training loss: 0.3491803845830596
Validation loss: 2.7174609058595496

Epoch: 5| Step: 11
Training loss: 0.4840983246659838
Validation loss: 2.680842772446358

Epoch: 360| Step: 0
Training loss: 0.5504842999287103
Validation loss: 2.7609003123161058

Epoch: 5| Step: 1
Training loss: 0.2889263760461244
Validation loss: 2.6935946624793847

Epoch: 5| Step: 2
Training loss: 0.4072115229841428
Validation loss: 2.755464831541336

Epoch: 5| Step: 3
Training loss: 0.3318461519300434
Validation loss: 2.677654692737

Epoch: 5| Step: 4
Training loss: 0.4665830273976691
Validation loss: 2.725796377836674

Epoch: 5| Step: 5
Training loss: 0.6014927414910393
Validation loss: 2.7111345085800305

Epoch: 5| Step: 6
Training loss: 0.5246574078780618
Validation loss: 2.6899404866786014

Epoch: 5| Step: 7
Training loss: 0.4199004411771836
Validation loss: 2.720088687624259

Epoch: 5| Step: 8
Training loss: 0.49133663199847366
Validation loss: 2.6403498252282884

Epoch: 5| Step: 9
Training loss: 0.45205657882747036
Validation loss: 2.7961405565867445

Epoch: 5| Step: 10
Training loss: 0.505019916387189
Validation loss: 2.739375843898287

Epoch: 5| Step: 11
Training loss: 0.3336432203646474
Validation loss: 2.68106581196821

Epoch: 361| Step: 0
Training loss: 0.3718721357603924
Validation loss: 2.659242602876665

Epoch: 5| Step: 1
Training loss: 0.43763466874081414
Validation loss: 2.7214520572170544

Epoch: 5| Step: 2
Training loss: 0.4058211153444535
Validation loss: 2.7251082753184908

Epoch: 5| Step: 3
Training loss: 0.4384974791161815
Validation loss: 2.687824307324745

Epoch: 5| Step: 4
Training loss: 0.4537147433137336
Validation loss: 2.706685787761341

Epoch: 5| Step: 5
Training loss: 0.38748622608315664
Validation loss: 2.6395693442664707

Epoch: 5| Step: 6
Training loss: 0.4192212314368765
Validation loss: 2.688510248389093

Epoch: 5| Step: 7
Training loss: 0.47514926359590637
Validation loss: 2.7165132251557766

Epoch: 5| Step: 8
Training loss: 0.48287601176666195
Validation loss: 2.694645888597008

Epoch: 5| Step: 9
Training loss: 0.3444021497779523
Validation loss: 2.7421474761795284

Epoch: 5| Step: 10
Training loss: 0.28044767645932434
Validation loss: 2.6477052882352576

Epoch: 5| Step: 11
Training loss: 0.2419747756592997
Validation loss: 2.6853202141564743

Epoch: 362| Step: 0
Training loss: 0.4833329589886147
Validation loss: 2.7145715151627376

Epoch: 5| Step: 1
Training loss: 0.3766477860231097
Validation loss: 2.6778346812026665

Epoch: 5| Step: 2
Training loss: 0.3767413992542374
Validation loss: 2.7358263396565796

Epoch: 5| Step: 3
Training loss: 0.4254964523458904
Validation loss: 2.7440816128540884

Epoch: 5| Step: 4
Training loss: 0.45175875850434954
Validation loss: 2.6970936515285033

Epoch: 5| Step: 5
Training loss: 0.33724902543605084
Validation loss: 2.691427512193323

Epoch: 5| Step: 6
Training loss: 0.39366256333421695
Validation loss: 2.692456262523112

Epoch: 5| Step: 7
Training loss: 0.4433487206073721
Validation loss: 2.6691234653389704

Epoch: 5| Step: 8
Training loss: 0.25750937125365925
Validation loss: 2.7263586957340027

Epoch: 5| Step: 9
Training loss: 0.5508031637823956
Validation loss: 2.721623170446305

Epoch: 5| Step: 10
Training loss: 0.6167485329912457
Validation loss: 2.696950272990064

Epoch: 5| Step: 11
Training loss: 0.36603769909585226
Validation loss: 2.705194676868711

Epoch: 363| Step: 0
Training loss: 0.49444386823611075
Validation loss: 2.685520925685474

Epoch: 5| Step: 1
Training loss: 0.3830662489707755
Validation loss: 2.772652291912866

Epoch: 5| Step: 2
Training loss: 0.3626507445660801
Validation loss: 2.7143975236488

Epoch: 5| Step: 3
Training loss: 0.5756516516497531
Validation loss: 2.783930511902721

Epoch: 5| Step: 4
Training loss: 0.47264333975318507
Validation loss: 2.73793879465827

Epoch: 5| Step: 5
Training loss: 0.21813289416273285
Validation loss: 2.7497842407839195

Epoch: 5| Step: 6
Training loss: 0.31603864814626087
Validation loss: 2.718031477709162

Epoch: 5| Step: 7
Training loss: 0.5354695760310368
Validation loss: 2.7041801936237904

Epoch: 5| Step: 8
Training loss: 0.44194853226134956
Validation loss: 2.750794025143376

Epoch: 5| Step: 9
Training loss: 0.23236495210512267
Validation loss: 2.696839844292935

Epoch: 5| Step: 10
Training loss: 0.48764497117502653
Validation loss: 2.6849362912661747

Epoch: 5| Step: 11
Training loss: 0.6478080451985138
Validation loss: 2.7002193879841396

Epoch: 364| Step: 0
Training loss: 0.30210370236268097
Validation loss: 2.673870821032111

Epoch: 5| Step: 1
Training loss: 0.3795783384408336
Validation loss: 2.674701225821083

Epoch: 5| Step: 2
Training loss: 0.29131079432199497
Validation loss: 2.7283546001566332

Epoch: 5| Step: 3
Training loss: 0.5295329394500697
Validation loss: 2.646167521259788

Epoch: 5| Step: 4
Training loss: 0.4070017168749277
Validation loss: 2.6297183848890833

Epoch: 5| Step: 5
Training loss: 0.4692254833814249
Validation loss: 2.746693411370114

Epoch: 5| Step: 6
Training loss: 0.24930631241348505
Validation loss: 2.6657709887449648

Epoch: 5| Step: 7
Training loss: 0.5298003163783539
Validation loss: 2.686690600440838

Epoch: 5| Step: 8
Training loss: 0.3961824667629392
Validation loss: 2.681446424964668

Epoch: 5| Step: 9
Training loss: 0.5454855024157789
Validation loss: 2.6811374674777855

Epoch: 5| Step: 10
Training loss: 0.5258007788467733
Validation loss: 2.648340472879343

Epoch: 5| Step: 11
Training loss: 0.30700138762172885
Validation loss: 2.7120771458636725

Epoch: 365| Step: 0
Training loss: 0.5773916748555963
Validation loss: 2.598492354446535

Epoch: 5| Step: 1
Training loss: 0.4117216844834162
Validation loss: 2.630098523154761

Epoch: 5| Step: 2
Training loss: 0.46685934247338173
Validation loss: 2.7526463108692063

Epoch: 5| Step: 3
Training loss: 0.498224294140046
Validation loss: 2.6823711858770536

Epoch: 5| Step: 4
Training loss: 0.4237664876672883
Validation loss: 2.640936033752321

Epoch: 5| Step: 5
Training loss: 0.3182050646922528
Validation loss: 2.7422492336413895

Epoch: 5| Step: 6
Training loss: 0.4564859936091531
Validation loss: 2.655150574936032

Epoch: 5| Step: 7
Training loss: 0.2895221149220132
Validation loss: 2.6525347551459206

Epoch: 5| Step: 8
Training loss: 0.3905039599763683
Validation loss: 2.7356302032496753

Epoch: 5| Step: 9
Training loss: 0.4256597573068833
Validation loss: 2.635654739638464

Epoch: 5| Step: 10
Training loss: 0.5819281672394194
Validation loss: 2.7062758547287156

Epoch: 5| Step: 11
Training loss: 0.2854390766692463
Validation loss: 2.6648972360445016

Epoch: 366| Step: 0
Training loss: 0.454422720275162
Validation loss: 2.7109554081306078

Epoch: 5| Step: 1
Training loss: 0.39163483742303806
Validation loss: 2.680823897950993

Epoch: 5| Step: 2
Training loss: 0.4005163600094741
Validation loss: 2.6830620218079413

Epoch: 5| Step: 3
Training loss: 0.41897031624968517
Validation loss: 2.672101158103655

Epoch: 5| Step: 4
Training loss: 0.2917142202008259
Validation loss: 2.700199245383334

Epoch: 5| Step: 5
Training loss: 0.48603519365349995
Validation loss: 2.661017220229365

Epoch: 5| Step: 6
Training loss: 0.339568871012671
Validation loss: 2.671375882412582

Epoch: 5| Step: 7
Training loss: 0.4119131696898478
Validation loss: 2.6691135428381694

Epoch: 5| Step: 8
Training loss: 0.40337977305881445
Validation loss: 2.709270360437357

Epoch: 5| Step: 9
Training loss: 0.2906016022482465
Validation loss: 2.6998555765850174

Epoch: 5| Step: 10
Training loss: 0.5614263566724689
Validation loss: 2.682358614385464

Epoch: 5| Step: 11
Training loss: 0.7437388218913232
Validation loss: 2.687679063021445

Epoch: 367| Step: 0
Training loss: 0.3035279363543425
Validation loss: 2.701134387914878

Epoch: 5| Step: 1
Training loss: 0.48141505705377424
Validation loss: 2.6794834040703055

Epoch: 5| Step: 2
Training loss: 0.5995499770973093
Validation loss: 2.692469659455482

Epoch: 5| Step: 3
Training loss: 0.364523251442077
Validation loss: 2.7308887818959944

Epoch: 5| Step: 4
Training loss: 0.4442439895903804
Validation loss: 2.6774583336182034

Epoch: 5| Step: 5
Training loss: 0.29983967629707314
Validation loss: 2.6850695302569068

Epoch: 5| Step: 6
Training loss: 0.2693309869235188
Validation loss: 2.6917707088506795

Epoch: 5| Step: 7
Training loss: 0.374405309886244
Validation loss: 2.6611470241342134

Epoch: 5| Step: 8
Training loss: 0.37016378627720176
Validation loss: 2.66899418707608

Epoch: 5| Step: 9
Training loss: 0.41625500449760644
Validation loss: 2.6807957165831655

Epoch: 5| Step: 10
Training loss: 0.512970681490415
Validation loss: 2.7101285352230935

Epoch: 5| Step: 11
Training loss: 0.44748609015088364
Validation loss: 2.649466840623985

Epoch: 368| Step: 0
Training loss: 0.3542661129888346
Validation loss: 2.629478755016426

Epoch: 5| Step: 1
Training loss: 0.6627083603675963
Validation loss: 2.6726394474378936

Epoch: 5| Step: 2
Training loss: 0.39287893433016396
Validation loss: 2.6700743543556196

Epoch: 5| Step: 3
Training loss: 0.3013396096606254
Validation loss: 2.694098780740646

Epoch: 5| Step: 4
Training loss: 0.4806981663267596
Validation loss: 2.7542408264225293

Epoch: 5| Step: 5
Training loss: 0.43138774524034124
Validation loss: 2.7653724425780415

Epoch: 5| Step: 6
Training loss: 0.4281318942440735
Validation loss: 2.7005644340759822

Epoch: 5| Step: 7
Training loss: 0.4144968058356062
Validation loss: 2.696926299086488

Epoch: 5| Step: 8
Training loss: 0.3193404521098054
Validation loss: 2.703070535276468

Epoch: 5| Step: 9
Training loss: 0.4636325443494277
Validation loss: 2.731944233518807

Epoch: 5| Step: 10
Training loss: 0.42693435194898494
Validation loss: 2.6997211870123747

Epoch: 5| Step: 11
Training loss: 0.2292194206394404
Validation loss: 2.706485269376399

Epoch: 369| Step: 0
Training loss: 0.3307448318355912
Validation loss: 2.6491554322434014

Epoch: 5| Step: 1
Training loss: 0.39914014979401585
Validation loss: 2.6902472404747293

Epoch: 5| Step: 2
Training loss: 0.4182210321296429
Validation loss: 2.66164634299317

Epoch: 5| Step: 3
Training loss: 0.48329443535268074
Validation loss: 2.7341682446740814

Epoch: 5| Step: 4
Training loss: 0.2711350093522275
Validation loss: 2.7020615597163578

Epoch: 5| Step: 5
Training loss: 0.3649486709455547
Validation loss: 2.6698399651889537

Epoch: 5| Step: 6
Training loss: 0.3936814702661265
Validation loss: 2.7616470485877556

Epoch: 5| Step: 7
Training loss: 0.5146855842170196
Validation loss: 2.6588340569214224

Epoch: 5| Step: 8
Training loss: 0.3235048454310925
Validation loss: 2.659264271661418

Epoch: 5| Step: 9
Training loss: 0.32011360878657596
Validation loss: 2.714780024597047

Epoch: 5| Step: 10
Training loss: 0.5622412298289425
Validation loss: 2.7112376828322056

Epoch: 5| Step: 11
Training loss: 0.28643843697318294
Validation loss: 2.711537118021904

Epoch: 370| Step: 0
Training loss: 0.3256193151911307
Validation loss: 2.692729224315204

Epoch: 5| Step: 1
Training loss: 0.41266874344274407
Validation loss: 2.68722218548737

Epoch: 5| Step: 2
Training loss: 0.3712310135607019
Validation loss: 2.7632315744369955

Epoch: 5| Step: 3
Training loss: 0.480156680850808
Validation loss: 2.702316832226849

Epoch: 5| Step: 4
Training loss: 0.4789126092385876
Validation loss: 2.71571069500986

Epoch: 5| Step: 5
Training loss: 0.3842562872075084
Validation loss: 2.700701187325692

Epoch: 5| Step: 6
Training loss: 0.3842209964917669
Validation loss: 2.6759863818912177

Epoch: 5| Step: 7
Training loss: 0.4470712664232789
Validation loss: 2.7045494214767825

Epoch: 5| Step: 8
Training loss: 0.42328697147213035
Validation loss: 2.71870988326602

Epoch: 5| Step: 9
Training loss: 0.4228974068614252
Validation loss: 2.6983002950822486

Epoch: 5| Step: 10
Training loss: 0.497114917724826
Validation loss: 2.6904976302543337

Epoch: 5| Step: 11
Training loss: 0.2380404584600136
Validation loss: 2.7519237046556406

Epoch: 371| Step: 0
Training loss: 0.3965862876064376
Validation loss: 2.6534971427002394

Epoch: 5| Step: 1
Training loss: 0.5398301449950753
Validation loss: 2.760819029123787

Epoch: 5| Step: 2
Training loss: 0.4487404640587178
Validation loss: 2.7489260107994786

Epoch: 5| Step: 3
Training loss: 0.36756370426960805
Validation loss: 2.731305377582115

Epoch: 5| Step: 4
Training loss: 0.6181435483689464
Validation loss: 2.688846675820152

Epoch: 5| Step: 5
Training loss: 0.37516894111313864
Validation loss: 2.725592680298244

Epoch: 5| Step: 6
Training loss: 0.43238121468719803
Validation loss: 2.613001308072942

Epoch: 5| Step: 7
Training loss: 0.3602161928550915
Validation loss: 2.768364826130819

Epoch: 5| Step: 8
Training loss: 0.4923769117135683
Validation loss: 2.7415342213912868

Epoch: 5| Step: 9
Training loss: 0.3825615430077379
Validation loss: 2.7018444982685526

Epoch: 5| Step: 10
Training loss: 0.5050428125910676
Validation loss: 2.740960438019511

Epoch: 5| Step: 11
Training loss: 0.1872776222762421
Validation loss: 2.747356437412702

Epoch: 372| Step: 0
Training loss: 0.5089127578764306
Validation loss: 2.689338229146163

Epoch: 5| Step: 1
Training loss: 0.38536484043390995
Validation loss: 2.6529089578734526

Epoch: 5| Step: 2
Training loss: 0.5086454163075095
Validation loss: 2.618800291687695

Epoch: 5| Step: 3
Training loss: 0.5095142899550473
Validation loss: 2.7168142143114866

Epoch: 5| Step: 4
Training loss: 0.45562707756625836
Validation loss: 2.6530470404911384

Epoch: 5| Step: 5
Training loss: 0.4201999010057346
Validation loss: 2.693501900933011

Epoch: 5| Step: 6
Training loss: 0.4652910404624129
Validation loss: 2.662800867695242

Epoch: 5| Step: 7
Training loss: 0.38454384390595964
Validation loss: 2.651086238543849

Epoch: 5| Step: 8
Training loss: 0.32229910011982554
Validation loss: 2.7145038602373734

Epoch: 5| Step: 9
Training loss: 0.4946876332854563
Validation loss: 2.733234262027835

Epoch: 5| Step: 10
Training loss: 0.3011513699330815
Validation loss: 2.7142418027106765

Epoch: 5| Step: 11
Training loss: 0.5415784751794327
Validation loss: 2.6655229013022455

Epoch: 373| Step: 0
Training loss: 0.7033057086575668
Validation loss: 2.6730791654024992

Epoch: 5| Step: 1
Training loss: 0.5465701752304236
Validation loss: 2.6526788079494517

Epoch: 5| Step: 2
Training loss: 0.278720674832538
Validation loss: 2.6798178527089602

Epoch: 5| Step: 3
Training loss: 0.41421808162881346
Validation loss: 2.754682333240507

Epoch: 5| Step: 4
Training loss: 0.46601259113868637
Validation loss: 2.7925118523906556

Epoch: 5| Step: 5
Training loss: 0.47577937459341163
Validation loss: 2.809411900199842

Epoch: 5| Step: 6
Training loss: 0.36433869964609417
Validation loss: 2.676411393490044

Epoch: 5| Step: 7
Training loss: 0.5175472322277395
Validation loss: 2.732148471957699

Epoch: 5| Step: 8
Training loss: 0.4042498243292602
Validation loss: 2.6620240191972178

Epoch: 5| Step: 9
Training loss: 0.49044965295475035
Validation loss: 2.653211613631561

Epoch: 5| Step: 10
Training loss: 0.43307586190267244
Validation loss: 2.7013311442588805

Epoch: 5| Step: 11
Training loss: 0.43662629419829
Validation loss: 2.756825213625972

Epoch: 374| Step: 0
Training loss: 0.4176281227319334
Validation loss: 2.69192584023206

Epoch: 5| Step: 1
Training loss: 0.41036477010933853
Validation loss: 2.688459609468169

Epoch: 5| Step: 2
Training loss: 0.6305077579725858
Validation loss: 2.7382727789282995

Epoch: 5| Step: 3
Training loss: 0.3449314578357092
Validation loss: 2.7449876557265416

Epoch: 5| Step: 4
Training loss: 0.3532011414193538
Validation loss: 2.666989013938175

Epoch: 5| Step: 5
Training loss: 0.36253388756173244
Validation loss: 2.720775430763246

Epoch: 5| Step: 6
Training loss: 0.39173795460511773
Validation loss: 2.72715353548766

Epoch: 5| Step: 7
Training loss: 0.524982620133234
Validation loss: 2.7457323229902433

Epoch: 5| Step: 8
Training loss: 0.5578822960450199
Validation loss: 2.72772262070314

Epoch: 5| Step: 9
Training loss: 0.40224709321981655
Validation loss: 2.6908655938520014

Epoch: 5| Step: 10
Training loss: 0.47438657892241337
Validation loss: 2.7293667331678386

Epoch: 5| Step: 11
Training loss: 0.24376814848021153
Validation loss: 2.673844899584006

Epoch: 375| Step: 0
Training loss: 0.4838237240278711
Validation loss: 2.7384326872985936

Epoch: 5| Step: 1
Training loss: 0.39564863923787424
Validation loss: 2.715703547241299

Epoch: 5| Step: 2
Training loss: 0.5217492506006303
Validation loss: 2.7736763112584684

Epoch: 5| Step: 3
Training loss: 0.4439614698739899
Validation loss: 2.6876269317932744

Epoch: 5| Step: 4
Training loss: 0.4073805300690437
Validation loss: 2.7786015927416567

Epoch: 5| Step: 5
Training loss: 0.5754656585436314
Validation loss: 2.7838629653168327

Epoch: 5| Step: 6
Training loss: 0.5326247099683358
Validation loss: 2.7747261348967114

Epoch: 5| Step: 7
Training loss: 0.6028795563147769
Validation loss: 2.6714914466737167

Epoch: 5| Step: 8
Training loss: 0.48189859156864856
Validation loss: 2.700604198693224

Epoch: 5| Step: 9
Training loss: 0.3883906358113525
Validation loss: 2.693675162152762

Epoch: 5| Step: 10
Training loss: 0.3619195582574203
Validation loss: 2.6822030852175125

Epoch: 5| Step: 11
Training loss: 0.3084191419864062
Validation loss: 2.7336497789230005

Epoch: 376| Step: 0
Training loss: 0.4563592388071765
Validation loss: 2.72292930733379

Epoch: 5| Step: 1
Training loss: 0.5530659250728199
Validation loss: 2.6751181344658566

Epoch: 5| Step: 2
Training loss: 0.33162939773804073
Validation loss: 2.703039355382083

Epoch: 5| Step: 3
Training loss: 0.2960769442215107
Validation loss: 2.72755576535055

Epoch: 5| Step: 4
Training loss: 0.5047868825654547
Validation loss: 2.667805528465189

Epoch: 5| Step: 5
Training loss: 0.5489127748852457
Validation loss: 2.6782905117956575

Epoch: 5| Step: 6
Training loss: 0.31861496243430565
Validation loss: 2.6736737604493785

Epoch: 5| Step: 7
Training loss: 0.5103400490794618
Validation loss: 2.743151698996202

Epoch: 5| Step: 8
Training loss: 0.4016901095495341
Validation loss: 2.733337776007957

Epoch: 5| Step: 9
Training loss: 0.25427416042248907
Validation loss: 2.778761117981293

Epoch: 5| Step: 10
Training loss: 0.630171646017106
Validation loss: 2.7453226025966666

Epoch: 5| Step: 11
Training loss: 0.21765001503037118
Validation loss: 2.71512023835164

Epoch: 377| Step: 0
Training loss: 0.2893576404027848
Validation loss: 2.690748772043129

Epoch: 5| Step: 1
Training loss: 0.44213307723113476
Validation loss: 2.656622853009565

Epoch: 5| Step: 2
Training loss: 0.4022380727110381
Validation loss: 2.702943656145268

Epoch: 5| Step: 3
Training loss: 0.3420272159992026
Validation loss: 2.705043380275464

Epoch: 5| Step: 4
Training loss: 0.5924881023709344
Validation loss: 2.756702711305212

Epoch: 5| Step: 5
Training loss: 0.3827045833519522
Validation loss: 2.68193632691815

Epoch: 5| Step: 6
Training loss: 0.43277703081352714
Validation loss: 2.741483520102993

Epoch: 5| Step: 7
Training loss: 0.4727297323815673
Validation loss: 2.6717141272168012

Epoch: 5| Step: 8
Training loss: 0.46812392386196905
Validation loss: 2.716741517904126

Epoch: 5| Step: 9
Training loss: 0.4190675072651741
Validation loss: 2.745592714619613

Epoch: 5| Step: 10
Training loss: 0.37688564032468763
Validation loss: 2.6780559050891664

Epoch: 5| Step: 11
Training loss: 0.32116011376955217
Validation loss: 2.689242951069958

Epoch: 378| Step: 0
Training loss: 0.47098539127890315
Validation loss: 2.773062720967506

Epoch: 5| Step: 1
Training loss: 0.30008017591169367
Validation loss: 2.6671362341773683

Epoch: 5| Step: 2
Training loss: 0.4187490363608133
Validation loss: 2.7712735182573343

Epoch: 5| Step: 3
Training loss: 0.40266285436067134
Validation loss: 2.75515685487092

Epoch: 5| Step: 4
Training loss: 0.2658537272599717
Validation loss: 2.7213250458298495

Epoch: 5| Step: 5
Training loss: 0.6306578606625177
Validation loss: 2.6931408080449093

Epoch: 5| Step: 6
Training loss: 0.352018590293978
Validation loss: 2.675212196299975

Epoch: 5| Step: 7
Training loss: 0.3787682272047169
Validation loss: 2.6859245339924485

Epoch: 5| Step: 8
Training loss: 0.4581668146678306
Validation loss: 2.631195096026796

Epoch: 5| Step: 9
Training loss: 0.5054138460366252
Validation loss: 2.6844444388784936

Epoch: 5| Step: 10
Training loss: 0.3380961261802925
Validation loss: 2.6866030120250377

Epoch: 5| Step: 11
Training loss: 0.37681092658626325
Validation loss: 2.7165683930901867

Epoch: 379| Step: 0
Training loss: 0.3968920561361921
Validation loss: 2.6868245399695927

Epoch: 5| Step: 1
Training loss: 0.4011267617181908
Validation loss: 2.6998396443208605

Epoch: 5| Step: 2
Training loss: 0.28121640746515164
Validation loss: 2.6479314585066738

Epoch: 5| Step: 3
Training loss: 0.3773806228155623
Validation loss: 2.7315603574552307

Epoch: 5| Step: 4
Training loss: 0.5297553691312891
Validation loss: 2.790270642532594

Epoch: 5| Step: 5
Training loss: 0.5694171723242067
Validation loss: 2.637824742572335

Epoch: 5| Step: 6
Training loss: 0.2349237772538224
Validation loss: 2.7265513546487243

Epoch: 5| Step: 7
Training loss: 0.47611748914435376
Validation loss: 2.689286311084457

Epoch: 5| Step: 8
Training loss: 0.48158039418714393
Validation loss: 2.6666884098557317

Epoch: 5| Step: 9
Training loss: 0.46020983787119146
Validation loss: 2.68299829502125

Epoch: 5| Step: 10
Training loss: 0.37376785509971844
Validation loss: 2.7407403661383505

Epoch: 5| Step: 11
Training loss: 0.36256707656094606
Validation loss: 2.6677824879719068

Epoch: 380| Step: 0
Training loss: 0.3045900017681978
Validation loss: 2.7200304355858607

Epoch: 5| Step: 1
Training loss: 0.40760472803672676
Validation loss: 2.748603484270762

Epoch: 5| Step: 2
Training loss: 0.30075862105817003
Validation loss: 2.7107525010247957

Epoch: 5| Step: 3
Training loss: 0.48994504133810696
Validation loss: 2.6989409013423487

Epoch: 5| Step: 4
Training loss: 0.4000584783126962
Validation loss: 2.6680767657418594

Epoch: 5| Step: 5
Training loss: 0.36524763440221847
Validation loss: 2.7877004415922415

Epoch: 5| Step: 6
Training loss: 0.6817307289709572
Validation loss: 2.7488552441817067

Epoch: 5| Step: 7
Training loss: 0.34646431048764187
Validation loss: 2.7052325006129396

Epoch: 5| Step: 8
Training loss: 0.39817025066706513
Validation loss: 2.7385123568466114

Epoch: 5| Step: 9
Training loss: 0.4244355801474458
Validation loss: 2.689623418923435

Epoch: 5| Step: 10
Training loss: 0.4190942103985212
Validation loss: 2.6664456683215576

Epoch: 5| Step: 11
Training loss: 0.27983484276377135
Validation loss: 2.7481290926514936

Epoch: 381| Step: 0
Training loss: 0.6192673754989896
Validation loss: 2.759693286088964

Epoch: 5| Step: 1
Training loss: 0.40869067703601314
Validation loss: 2.7649336631478842

Epoch: 5| Step: 2
Training loss: 0.5297100242394318
Validation loss: 2.6982158595634735

Epoch: 5| Step: 3
Training loss: 0.4177053280989432
Validation loss: 2.8743207274188576

Epoch: 5| Step: 4
Training loss: 0.5515376639245279
Validation loss: 2.756766440578247

Epoch: 5| Step: 5
Training loss: 0.4078180056963981
Validation loss: 2.695511476110541

Epoch: 5| Step: 6
Training loss: 0.4055568761002076
Validation loss: 2.7911344395683937

Epoch: 5| Step: 7
Training loss: 0.5292660749982692
Validation loss: 2.814983839391798

Epoch: 5| Step: 8
Training loss: 0.4463091956340679
Validation loss: 2.7650033356276817

Epoch: 5| Step: 9
Training loss: 0.380076498751479
Validation loss: 2.7392817550038955

Epoch: 5| Step: 10
Training loss: 0.41820499838059005
Validation loss: 2.6868793377068907

Epoch: 5| Step: 11
Training loss: 0.16673295495922208
Validation loss: 2.7061512201501956

Epoch: 382| Step: 0
Training loss: 0.5572021596694876
Validation loss: 2.6749692329823995

Epoch: 5| Step: 1
Training loss: 0.39774915662852317
Validation loss: 2.658382816113252

Epoch: 5| Step: 2
Training loss: 0.4067822967196986
Validation loss: 2.6696384226447325

Epoch: 5| Step: 3
Training loss: 0.4853172520382138
Validation loss: 2.691635048289844

Epoch: 5| Step: 4
Training loss: 0.41034423516552543
Validation loss: 2.7544103643508584

Epoch: 5| Step: 5
Training loss: 0.542629822258567
Validation loss: 2.7177022508168367

Epoch: 5| Step: 6
Training loss: 0.46796980142873296
Validation loss: 2.7778834280479456

Epoch: 5| Step: 7
Training loss: 0.4030540640467687
Validation loss: 2.748503118660249

Epoch: 5| Step: 8
Training loss: 0.338846497357545
Validation loss: 2.786514200856714

Epoch: 5| Step: 9
Training loss: 0.34196278496341437
Validation loss: 2.672963913217268

Epoch: 5| Step: 10
Training loss: 0.4027558965695314
Validation loss: 2.688001083265003

Epoch: 5| Step: 11
Training loss: 0.15939760795758445
Validation loss: 2.688958422877885

Epoch: 383| Step: 0
Training loss: 0.5141764436263162
Validation loss: 2.775903610079306

Epoch: 5| Step: 1
Training loss: 0.5499886294836833
Validation loss: 2.7350702618925187

Epoch: 5| Step: 2
Training loss: 0.49953865582724943
Validation loss: 2.7466875395678088

Epoch: 5| Step: 3
Training loss: 0.4372484471700848
Validation loss: 2.627904462084886

Epoch: 5| Step: 4
Training loss: 0.4298078888521941
Validation loss: 2.6790532732312653

Epoch: 5| Step: 5
Training loss: 0.30572883236599807
Validation loss: 2.7664681674133154

Epoch: 5| Step: 6
Training loss: 0.3626848883869253
Validation loss: 2.8113900678915877

Epoch: 5| Step: 7
Training loss: 0.33263799542913436
Validation loss: 2.6766285578052456

Epoch: 5| Step: 8
Training loss: 0.39094579875380125
Validation loss: 2.6418794966401395

Epoch: 5| Step: 9
Training loss: 0.464518120455356
Validation loss: 2.696400692701503

Epoch: 5| Step: 10
Training loss: 0.4227925318861392
Validation loss: 2.711057856340485

Epoch: 5| Step: 11
Training loss: 0.2944011259128068
Validation loss: 2.7091479005714163

Epoch: 384| Step: 0
Training loss: 0.294517087722393
Validation loss: 2.6463658755565875

Epoch: 5| Step: 1
Training loss: 0.42329841243834604
Validation loss: 2.6877002160951378

Epoch: 5| Step: 2
Training loss: 0.48547812947278673
Validation loss: 2.6508632323815333

Epoch: 5| Step: 3
Training loss: 0.5655932939189191
Validation loss: 2.565072493510914

Epoch: 5| Step: 4
Training loss: 0.42931141433878434
Validation loss: 2.642054928687726

Epoch: 5| Step: 5
Training loss: 0.45353456600566916
Validation loss: 2.7384756638698864

Epoch: 5| Step: 6
Training loss: 0.46405947263610003
Validation loss: 2.6893070710415583

Epoch: 5| Step: 7
Training loss: 0.6094410200301968
Validation loss: 2.777966282461867

Epoch: 5| Step: 8
Training loss: 0.4851387678058783
Validation loss: 2.7589943886476656

Epoch: 5| Step: 9
Training loss: 0.4569271164639032
Validation loss: 2.7050001810277102

Epoch: 5| Step: 10
Training loss: 0.23208349904774125
Validation loss: 2.687149947308816

Epoch: 5| Step: 11
Training loss: 0.2782857103756041
Validation loss: 2.7177124857307278

Epoch: 385| Step: 0
Training loss: 0.4273520202115422
Validation loss: 2.743549023409638

Epoch: 5| Step: 1
Training loss: 0.6125830058859497
Validation loss: 2.7156027631650344

Epoch: 5| Step: 2
Training loss: 0.556207454854544
Validation loss: 2.6098999706005364

Epoch: 5| Step: 3
Training loss: 0.42495091870140506
Validation loss: 2.711994928663758

Epoch: 5| Step: 4
Training loss: 0.5110505961734245
Validation loss: 2.8044415280186215

Epoch: 5| Step: 5
Training loss: 0.4472453350145829
Validation loss: 2.692180258338415

Epoch: 5| Step: 6
Training loss: 0.47792773821222384
Validation loss: 2.773034946795549

Epoch: 5| Step: 7
Training loss: 0.45185499782797417
Validation loss: 2.6979611011415185

Epoch: 5| Step: 8
Training loss: 0.3791867427261912
Validation loss: 2.7852613082410564

Epoch: 5| Step: 9
Training loss: 0.33594995298148256
Validation loss: 2.68515148604526

Epoch: 5| Step: 10
Training loss: 0.24475692779839925
Validation loss: 2.668369581459617

Epoch: 5| Step: 11
Training loss: 0.6520388456003205
Validation loss: 2.687334377153368

Epoch: 386| Step: 0
Training loss: 0.389352097794498
Validation loss: 2.7274828380449216

Epoch: 5| Step: 1
Training loss: 0.5073713880975675
Validation loss: 2.7145024402966027

Epoch: 5| Step: 2
Training loss: 0.5473008541337494
Validation loss: 2.657972263660291

Epoch: 5| Step: 3
Training loss: 0.5888463359829224
Validation loss: 2.7309763322449734

Epoch: 5| Step: 4
Training loss: 0.4417292839173318
Validation loss: 2.76486444162813

Epoch: 5| Step: 5
Training loss: 0.43576017211842033
Validation loss: 2.7114999299455893

Epoch: 5| Step: 6
Training loss: 0.39593012362551194
Validation loss: 2.755334910109492

Epoch: 5| Step: 7
Training loss: 0.2807957238875336
Validation loss: 2.750426840890244

Epoch: 5| Step: 8
Training loss: 0.3234196547408948
Validation loss: 2.6690807584992546

Epoch: 5| Step: 9
Training loss: 0.34562001064348424
Validation loss: 2.681918506528715

Epoch: 5| Step: 10
Training loss: 0.4673615236770197
Validation loss: 2.699368992997746

Epoch: 5| Step: 11
Training loss: 0.4457901684938243
Validation loss: 2.665276950699443

Epoch: 387| Step: 0
Training loss: 0.3191988356134622
Validation loss: 2.755473541783405

Epoch: 5| Step: 1
Training loss: 0.4321503887116947
Validation loss: 2.680396113295888

Epoch: 5| Step: 2
Training loss: 0.32567679928579574
Validation loss: 2.7379505939168656

Epoch: 5| Step: 3
Training loss: 0.41073527563848694
Validation loss: 2.751355783444261

Epoch: 5| Step: 4
Training loss: 0.4723497926285774
Validation loss: 2.773510057100206

Epoch: 5| Step: 5
Training loss: 0.4772984809450105
Validation loss: 2.7889982442283827

Epoch: 5| Step: 6
Training loss: 0.47531477386512566
Validation loss: 2.719506867242919

Epoch: 5| Step: 7
Training loss: 0.5400528862892922
Validation loss: 2.7070760828721276

Epoch: 5| Step: 8
Training loss: 0.3922047903801306
Validation loss: 2.718245015436502

Epoch: 5| Step: 9
Training loss: 0.4385163388976187
Validation loss: 2.7352029400722766

Epoch: 5| Step: 10
Training loss: 0.4671746485036549
Validation loss: 2.7222128114299773

Epoch: 5| Step: 11
Training loss: 0.3335794369845405
Validation loss: 2.628359366938901

Epoch: 388| Step: 0
Training loss: 0.3659587144118221
Validation loss: 2.7007333763204415

Epoch: 5| Step: 1
Training loss: 0.286765275137611
Validation loss: 2.7968550704444906

Epoch: 5| Step: 2
Training loss: 0.4570045626420902
Validation loss: 2.757616906078591

Epoch: 5| Step: 3
Training loss: 0.4599268064368976
Validation loss: 2.756264281722456

Epoch: 5| Step: 4
Training loss: 0.4195172511771871
Validation loss: 2.695795924375738

Epoch: 5| Step: 5
Training loss: 0.39398968228758124
Validation loss: 2.679292013865891

Epoch: 5| Step: 6
Training loss: 0.4294873204807688
Validation loss: 2.6770502872629165

Epoch: 5| Step: 7
Training loss: 0.43096788549595827
Validation loss: 2.6724425042215127

Epoch: 5| Step: 8
Training loss: 0.4179154299657189
Validation loss: 2.671282057378636

Epoch: 5| Step: 9
Training loss: 0.38165405702722255
Validation loss: 2.6323238828735853

Epoch: 5| Step: 10
Training loss: 0.39802426993710005
Validation loss: 2.788680900875813

Epoch: 5| Step: 11
Training loss: 0.7242759904184529
Validation loss: 2.7158395674396827

Epoch: 389| Step: 0
Training loss: 0.5332432267196574
Validation loss: 2.66893141968907

Epoch: 5| Step: 1
Training loss: 0.5023848165334636
Validation loss: 2.7151348808673936

Epoch: 5| Step: 2
Training loss: 0.47876435646762294
Validation loss: 2.7932678133678404

Epoch: 5| Step: 3
Training loss: 0.4079811551309335
Validation loss: 2.793777700794637

Epoch: 5| Step: 4
Training loss: 0.7004942528504569
Validation loss: 2.6577935651896714

Epoch: 5| Step: 5
Training loss: 0.5305872878837014
Validation loss: 2.658000608526906

Epoch: 5| Step: 6
Training loss: 0.43972408841939925
Validation loss: 2.6824333980607777

Epoch: 5| Step: 7
Training loss: 0.46549042030540533
Validation loss: 2.6425234461670213

Epoch: 5| Step: 8
Training loss: 0.6695522923762816
Validation loss: 2.724511932125462

Epoch: 5| Step: 9
Training loss: 0.582212893412904
Validation loss: 2.6567136846000974

Epoch: 5| Step: 10
Training loss: 0.6132049270080457
Validation loss: 2.647942728434079

Epoch: 5| Step: 11
Training loss: 0.2616340585581155
Validation loss: 2.6848543178087887

Epoch: 390| Step: 0
Training loss: 0.4299639246190409
Validation loss: 2.7040688606985928

Epoch: 5| Step: 1
Training loss: 0.49222488866817654
Validation loss: 2.7659970049479856

Epoch: 5| Step: 2
Training loss: 0.5177020230538725
Validation loss: 2.8017341521469503

Epoch: 5| Step: 3
Training loss: 0.5867055563833775
Validation loss: 2.806957979959776

Epoch: 5| Step: 4
Training loss: 0.5169770403214963
Validation loss: 2.787348793330729

Epoch: 5| Step: 5
Training loss: 0.37842988026237867
Validation loss: 2.7058590970067447

Epoch: 5| Step: 6
Training loss: 0.49845528406447054
Validation loss: 2.7559441279250763

Epoch: 5| Step: 7
Training loss: 0.37348101853137305
Validation loss: 2.6412367272062327

Epoch: 5| Step: 8
Training loss: 0.42561368532307864
Validation loss: 2.653943736107605

Epoch: 5| Step: 9
Training loss: 0.5225866148765594
Validation loss: 2.634353300030119

Epoch: 5| Step: 10
Training loss: 0.4128821300834501
Validation loss: 2.6187671430173842

Epoch: 5| Step: 11
Training loss: 0.32648717750794237
Validation loss: 2.6301759031707417

Epoch: 391| Step: 0
Training loss: 0.539635367689108
Validation loss: 2.6540879669578596

Epoch: 5| Step: 1
Training loss: 0.5052697416390821
Validation loss: 2.7282777253377537

Epoch: 5| Step: 2
Training loss: 0.33273432847842455
Validation loss: 2.690690468151532

Epoch: 5| Step: 3
Training loss: 0.3504002113689477
Validation loss: 2.682887595682182

Epoch: 5| Step: 4
Training loss: 0.2586868660147862
Validation loss: 2.7400176437707846

Epoch: 5| Step: 5
Training loss: 0.4143436844674144
Validation loss: 2.7238013524371323

Epoch: 5| Step: 6
Training loss: 0.4259220905273322
Validation loss: 2.661359801337904

Epoch: 5| Step: 7
Training loss: 0.4032281950526093
Validation loss: 2.7080946902749

Epoch: 5| Step: 8
Training loss: 0.35774483186626227
Validation loss: 2.682220759272429

Epoch: 5| Step: 9
Training loss: 0.44148365118574606
Validation loss: 2.6696721862260877

Epoch: 5| Step: 10
Training loss: 0.37254491458443095
Validation loss: 2.6407442065988596

Epoch: 5| Step: 11
Training loss: 0.5668259479787845
Validation loss: 2.6818038472148595

Epoch: 392| Step: 0
Training loss: 0.3843710565752405
Validation loss: 2.6799563336996237

Epoch: 5| Step: 1
Training loss: 0.39116633099497006
Validation loss: 2.6874233538025836

Epoch: 5| Step: 2
Training loss: 0.3236800394724998
Validation loss: 2.6676738272543856

Epoch: 5| Step: 3
Training loss: 0.3255606766794505
Validation loss: 2.73683622127895

Epoch: 5| Step: 4
Training loss: 0.5063829106240539
Validation loss: 2.767861860757607

Epoch: 5| Step: 5
Training loss: 0.507471938743324
Validation loss: 2.7830474096094115

Epoch: 5| Step: 6
Training loss: 0.3690544310357117
Validation loss: 2.751938259643229

Epoch: 5| Step: 7
Training loss: 0.43875768948199023
Validation loss: 2.7373263571084814

Epoch: 5| Step: 8
Training loss: 0.38121274547224393
Validation loss: 2.755865351622923

Epoch: 5| Step: 9
Training loss: 0.6566365783675643
Validation loss: 2.683813290636675

Epoch: 5| Step: 10
Training loss: 0.5460737080095646
Validation loss: 2.721241103870206

Epoch: 5| Step: 11
Training loss: 0.7521746420623072
Validation loss: 2.680096305011188

Epoch: 393| Step: 0
Training loss: 0.30594908128352033
Validation loss: 2.7387125833736223

Epoch: 5| Step: 1
Training loss: 0.531327298094593
Validation loss: 2.7386017075393623

Epoch: 5| Step: 2
Training loss: 0.422150310117921
Validation loss: 2.6848174539121272

Epoch: 5| Step: 3
Training loss: 0.4022182898602889
Validation loss: 2.7605823083279297

Epoch: 5| Step: 4
Training loss: 0.3895553056899333
Validation loss: 2.7096014110821116

Epoch: 5| Step: 5
Training loss: 0.49623685559946057
Validation loss: 2.7249751384429253

Epoch: 5| Step: 6
Training loss: 0.5023348355132645
Validation loss: 2.7028083432043912

Epoch: 5| Step: 7
Training loss: 0.3982281228238986
Validation loss: 2.6941091458848487

Epoch: 5| Step: 8
Training loss: 0.4416995803996834
Validation loss: 2.7368348419630237

Epoch: 5| Step: 9
Training loss: 0.25557819961665235
Validation loss: 2.739581018647544

Epoch: 5| Step: 10
Training loss: 0.35679797141263964
Validation loss: 2.7553856161058095

Epoch: 5| Step: 11
Training loss: 0.5697342540913564
Validation loss: 2.664998834310328

Epoch: 394| Step: 0
Training loss: 0.3464973722512375
Validation loss: 2.631953928607996

Epoch: 5| Step: 1
Training loss: 0.5371681319956609
Validation loss: 2.685449657183284

Epoch: 5| Step: 2
Training loss: 0.3115364837306341
Validation loss: 2.7692171357172795

Epoch: 5| Step: 3
Training loss: 0.5330617528608939
Validation loss: 2.7304304608674235

Epoch: 5| Step: 4
Training loss: 0.4069748976755075
Validation loss: 2.777494996035166

Epoch: 5| Step: 5
Training loss: 0.42043985755909286
Validation loss: 2.7633692886899306

Epoch: 5| Step: 6
Training loss: 0.4779635767736247
Validation loss: 2.7719728856111554

Epoch: 5| Step: 7
Training loss: 0.5849330175802542
Validation loss: 2.7818666267483265

Epoch: 5| Step: 8
Training loss: 0.5667329043589384
Validation loss: 2.7187089588093025

Epoch: 5| Step: 9
Training loss: 0.3871166609647177
Validation loss: 2.6661793473384052

Epoch: 5| Step: 10
Training loss: 0.37649302494634873
Validation loss: 2.7304851147657434

Epoch: 5| Step: 11
Training loss: 0.5491062423486005
Validation loss: 2.6346708431025787

Epoch: 395| Step: 0
Training loss: 0.42497490289860806
Validation loss: 2.6417358251498033

Epoch: 5| Step: 1
Training loss: 0.3255581707204274
Validation loss: 2.6580973054525603

Epoch: 5| Step: 2
Training loss: 0.3237614336351398
Validation loss: 2.701076124309613

Epoch: 5| Step: 3
Training loss: 0.5025835642438023
Validation loss: 2.704099152539705

Epoch: 5| Step: 4
Training loss: 0.3419102943794153
Validation loss: 2.655947458577916

Epoch: 5| Step: 5
Training loss: 0.5515361509432285
Validation loss: 2.757679587557292

Epoch: 5| Step: 6
Training loss: 0.47668789949121537
Validation loss: 2.7133405077587134

Epoch: 5| Step: 7
Training loss: 0.5839322682484887
Validation loss: 2.6378745967077326

Epoch: 5| Step: 8
Training loss: 0.460937403016161
Validation loss: 2.6747439190583027

Epoch: 5| Step: 9
Training loss: 0.4153377759488194
Validation loss: 2.660675890597667

Epoch: 5| Step: 10
Training loss: 0.3569500837156831
Validation loss: 2.613622338083955

Epoch: 5| Step: 11
Training loss: 0.826208091284738
Validation loss: 2.6404160599369

Epoch: 396| Step: 0
Training loss: 0.3963713085396046
Validation loss: 2.6765557275119662

Epoch: 5| Step: 1
Training loss: 0.37695709779849695
Validation loss: 2.70501602413722

Epoch: 5| Step: 2
Training loss: 0.4081875738804753
Validation loss: 2.6460113177671367

Epoch: 5| Step: 3
Training loss: 0.47316678115919036
Validation loss: 2.7114992466664734

Epoch: 5| Step: 4
Training loss: 0.32635974613018287
Validation loss: 2.7543334503334997

Epoch: 5| Step: 5
Training loss: 0.3454819634549082
Validation loss: 2.7352363283416357

Epoch: 5| Step: 6
Training loss: 0.5246130141460799
Validation loss: 2.812596764489373

Epoch: 5| Step: 7
Training loss: 0.3573267659036324
Validation loss: 2.676165602801071

Epoch: 5| Step: 8
Training loss: 0.42919147645045086
Validation loss: 2.738672367303206

Epoch: 5| Step: 9
Training loss: 0.6781995864141311
Validation loss: 2.724546237154756

Epoch: 5| Step: 10
Training loss: 0.4316486340638466
Validation loss: 2.6922054645147813

Epoch: 5| Step: 11
Training loss: 0.23327610369177867
Validation loss: 2.688646814821709

Epoch: 397| Step: 0
Training loss: 0.40676293636118205
Validation loss: 2.6532892219033264

Epoch: 5| Step: 1
Training loss: 0.4785490997439107
Validation loss: 2.7028480895106677

Epoch: 5| Step: 2
Training loss: 0.2978962098725367
Validation loss: 2.6884860218610074

Epoch: 5| Step: 3
Training loss: 0.4480675916197548
Validation loss: 2.7311223002419602

Epoch: 5| Step: 4
Training loss: 0.28319023366066254
Validation loss: 2.62723674543036

Epoch: 5| Step: 5
Training loss: 0.5373449745175363
Validation loss: 2.7369964023172013

Epoch: 5| Step: 6
Training loss: 0.3555274328063944
Validation loss: 2.6471561569299533

Epoch: 5| Step: 7
Training loss: 0.39570544920951417
Validation loss: 2.779333186320091

Epoch: 5| Step: 8
Training loss: 0.3983383616358854
Validation loss: 2.7090834984754126

Epoch: 5| Step: 9
Training loss: 0.3730726582669479
Validation loss: 2.730589002181486

Epoch: 5| Step: 10
Training loss: 0.38598918491491035
Validation loss: 2.6820052108145096

Epoch: 5| Step: 11
Training loss: 0.24141347929861032
Validation loss: 2.685257197622667

Epoch: 398| Step: 0
Training loss: 0.33023879976649595
Validation loss: 2.643096335444991

Epoch: 5| Step: 1
Training loss: 0.4790636311198578
Validation loss: 2.630714165168927

Epoch: 5| Step: 2
Training loss: 0.4335004860865366
Validation loss: 2.726570796134154

Epoch: 5| Step: 3
Training loss: 0.41404770878698105
Validation loss: 2.639746465261117

Epoch: 5| Step: 4
Training loss: 0.4756171120329142
Validation loss: 2.6776848215034357

Epoch: 5| Step: 5
Training loss: 0.450772029841917
Validation loss: 2.658230495755753

Epoch: 5| Step: 6
Training loss: 0.45942050423009123
Validation loss: 2.655884687697043

Epoch: 5| Step: 7
Training loss: 0.28353998604602704
Validation loss: 2.697896402545566

Epoch: 5| Step: 8
Training loss: 0.35558792883093193
Validation loss: 2.734790477976673

Epoch: 5| Step: 9
Training loss: 0.39760251534671814
Validation loss: 2.742255124003647

Epoch: 5| Step: 10
Training loss: 0.35533342824881564
Validation loss: 2.752001117389798

Epoch: 5| Step: 11
Training loss: 0.14504838906816708
Validation loss: 2.7547324526201074

Epoch: 399| Step: 0
Training loss: 0.21989697100225933
Validation loss: 2.7525715219997386

Epoch: 5| Step: 1
Training loss: 0.45784260387197784
Validation loss: 2.686655636410595

Epoch: 5| Step: 2
Training loss: 0.5245414877430218
Validation loss: 2.6804663820922436

Epoch: 5| Step: 3
Training loss: 0.45441127592937747
Validation loss: 2.7735017760086405

Epoch: 5| Step: 4
Training loss: 0.4028602728914133
Validation loss: 2.641262985597154

Epoch: 5| Step: 5
Training loss: 0.43639107218516665
Validation loss: 2.7084381187170945

Epoch: 5| Step: 6
Training loss: 0.4473704086232248
Validation loss: 2.714154118829132

Epoch: 5| Step: 7
Training loss: 0.3379132588473795
Validation loss: 2.7778927295794604

Epoch: 5| Step: 8
Training loss: 0.44051449925464836
Validation loss: 2.7389518036482454

Epoch: 5| Step: 9
Training loss: 0.3707730363015632
Validation loss: 2.7056511117191113

Epoch: 5| Step: 10
Training loss: 0.49937910032916455
Validation loss: 2.7092991072875985

Epoch: 5| Step: 11
Training loss: 0.3401473322703876
Validation loss: 2.68486262811847

Epoch: 400| Step: 0
Training loss: 0.6118440248872687
Validation loss: 2.7121151977869213

Epoch: 5| Step: 1
Training loss: 0.44208014367822795
Validation loss: 2.7500542288548524

Epoch: 5| Step: 2
Training loss: 0.4584900161941613
Validation loss: 2.7678334547529295

Epoch: 5| Step: 3
Training loss: 0.4370092636977129
Validation loss: 2.757724803794588

Epoch: 5| Step: 4
Training loss: 0.4957168228505376
Validation loss: 2.779670280987888

Epoch: 5| Step: 5
Training loss: 0.3718800696660531
Validation loss: 2.6822564477676223

Epoch: 5| Step: 6
Training loss: 0.5000335860893056
Validation loss: 2.69889745350387

Epoch: 5| Step: 7
Training loss: 0.46951922244187616
Validation loss: 2.689363020544361

Epoch: 5| Step: 8
Training loss: 0.32132535225126146
Validation loss: 2.703867115838647

Epoch: 5| Step: 9
Training loss: 0.37472108561564393
Validation loss: 2.6809156363492783

Epoch: 5| Step: 10
Training loss: 0.3733313509378991
Validation loss: 2.7048315383400126

Epoch: 5| Step: 11
Training loss: 0.42333627103114146
Validation loss: 2.707737267753865

Epoch: 401| Step: 0
Training loss: 0.5549120381388487
Validation loss: 2.6968018807363143

Epoch: 5| Step: 1
Training loss: 0.326054603372821
Validation loss: 2.6937059783878836

Epoch: 5| Step: 2
Training loss: 0.43952020768914557
Validation loss: 2.78447601657443

Epoch: 5| Step: 3
Training loss: 0.452308840549325
Validation loss: 2.7231218148849754

Epoch: 5| Step: 4
Training loss: 0.47266280745063827
Validation loss: 2.6899062924330135

Epoch: 5| Step: 5
Training loss: 0.4997689189984213
Validation loss: 2.7754264791643815

Epoch: 5| Step: 6
Training loss: 0.22859785442617808
Validation loss: 2.70056942951519

Epoch: 5| Step: 7
Training loss: 0.22735522788526116
Validation loss: 2.7670137507011168

Epoch: 5| Step: 8
Training loss: 0.28648751572592634
Validation loss: 2.7283531765011335

Epoch: 5| Step: 9
Training loss: 0.3389348449005121
Validation loss: 2.718694591322989

Epoch: 5| Step: 10
Training loss: 0.3957409960143596
Validation loss: 2.770120071208448

Epoch: 5| Step: 11
Training loss: 0.4043759807651424
Validation loss: 2.7245628270920914

Epoch: 402| Step: 0
Training loss: 0.2739384286174139
Validation loss: 2.7072531905943795

Epoch: 5| Step: 1
Training loss: 0.34493150103606085
Validation loss: 2.7087884166042975

Epoch: 5| Step: 2
Training loss: 0.3265812868436382
Validation loss: 2.7164420273898466

Epoch: 5| Step: 3
Training loss: 0.4858976550187552
Validation loss: 2.7478770059167767

Epoch: 5| Step: 4
Training loss: 0.21873962003058836
Validation loss: 2.691392452830258

Epoch: 5| Step: 5
Training loss: 0.5134009165160882
Validation loss: 2.7875711530319895

Epoch: 5| Step: 6
Training loss: 0.356076988237483
Validation loss: 2.764655349131714

Epoch: 5| Step: 7
Training loss: 0.36418623642892917
Validation loss: 2.69978516115416

Epoch: 5| Step: 8
Training loss: 0.33059496171640707
Validation loss: 2.7367500145124835

Epoch: 5| Step: 9
Training loss: 0.4158055845333763
Validation loss: 2.753526633501246

Epoch: 5| Step: 10
Training loss: 0.2686623374885583
Validation loss: 2.6813033397262567

Epoch: 5| Step: 11
Training loss: 0.27198999647545197
Validation loss: 2.6903319297795214

Epoch: 403| Step: 0
Training loss: 0.2633119033265252
Validation loss: 2.718218736883765

Epoch: 5| Step: 1
Training loss: 0.5053611275247675
Validation loss: 2.6546538063621874

Epoch: 5| Step: 2
Training loss: 0.3589797541639534
Validation loss: 2.7677217570534363

Epoch: 5| Step: 3
Training loss: 0.5001252136802073
Validation loss: 2.718538177394058

Epoch: 5| Step: 4
Training loss: 0.4460292535711924
Validation loss: 2.7004064494634594

Epoch: 5| Step: 5
Training loss: 0.345289133325604
Validation loss: 2.7413528128433136

Epoch: 5| Step: 6
Training loss: 0.4534165661091977
Validation loss: 2.72236494187049

Epoch: 5| Step: 7
Training loss: 0.396206349576939
Validation loss: 2.6334555130291157

Epoch: 5| Step: 8
Training loss: 0.4258434005313726
Validation loss: 2.697793539225041

Epoch: 5| Step: 9
Training loss: 0.28716677137414665
Validation loss: 2.6612665750558646

Epoch: 5| Step: 10
Training loss: 0.42847006598200876
Validation loss: 2.693041876100796

Epoch: 5| Step: 11
Training loss: 0.2568656120998006
Validation loss: 2.7454104091067166

Epoch: 404| Step: 0
Training loss: 0.3884062314510379
Validation loss: 2.6758425109236232

Epoch: 5| Step: 1
Training loss: 0.32169227459664007
Validation loss: 2.7382158751399808

Epoch: 5| Step: 2
Training loss: 0.3265684880159397
Validation loss: 2.701017276498344

Epoch: 5| Step: 3
Training loss: 0.30162788729781653
Validation loss: 2.736162161122243

Epoch: 5| Step: 4
Training loss: 0.45313239913687176
Validation loss: 2.7082561017297566

Epoch: 5| Step: 5
Training loss: 0.3064577808846258
Validation loss: 2.741972939337917

Epoch: 5| Step: 6
Training loss: 0.4919848857608879
Validation loss: 2.6963468695346493

Epoch: 5| Step: 7
Training loss: 0.49214406805810923
Validation loss: 2.714118406883553

Epoch: 5| Step: 8
Training loss: 0.42139831739179356
Validation loss: 2.755734014329604

Epoch: 5| Step: 9
Training loss: 0.3296030451638556
Validation loss: 2.801039552149903

Epoch: 5| Step: 10
Training loss: 0.3580962526057691
Validation loss: 2.750078554187455

Epoch: 5| Step: 11
Training loss: 0.23926945093613886
Validation loss: 2.63510145342835

Epoch: 405| Step: 0
Training loss: 0.6002555869039882
Validation loss: 2.803469971856511

Epoch: 5| Step: 1
Training loss: 0.4079760234568636
Validation loss: 2.751056343630709

Epoch: 5| Step: 2
Training loss: 0.3418546464325297
Validation loss: 2.6974043279881004

Epoch: 5| Step: 3
Training loss: 0.44267561361535646
Validation loss: 2.646441950346551

Epoch: 5| Step: 4
Training loss: 0.428434382677041
Validation loss: 2.736249390258303

Epoch: 5| Step: 5
Training loss: 0.3781035661533752
Validation loss: 2.6858095056832267

Epoch: 5| Step: 6
Training loss: 0.33878948848965446
Validation loss: 2.7184408421329054

Epoch: 5| Step: 7
Training loss: 0.38362197539056053
Validation loss: 2.619595284555812

Epoch: 5| Step: 8
Training loss: 0.30889916094921954
Validation loss: 2.6841534656005415

Epoch: 5| Step: 9
Training loss: 0.4739525728259905
Validation loss: 2.659445415121935

Epoch: 5| Step: 10
Training loss: 0.49444915728906597
Validation loss: 2.7138152335438623

Epoch: 5| Step: 11
Training loss: 0.555326389360156
Validation loss: 2.689012970247502

Epoch: 406| Step: 0
Training loss: 0.4834275053898495
Validation loss: 2.6681966428296633

Epoch: 5| Step: 1
Training loss: 0.43513609669997605
Validation loss: 2.6653686930903198

Epoch: 5| Step: 2
Training loss: 0.38719671747967926
Validation loss: 2.664136398946127

Epoch: 5| Step: 3
Training loss: 0.3901407291745727
Validation loss: 2.732683181538374

Epoch: 5| Step: 4
Training loss: 0.3393163534990104
Validation loss: 2.656062770303562

Epoch: 5| Step: 5
Training loss: 0.29462302773907567
Validation loss: 2.704142649053608

Epoch: 5| Step: 6
Training loss: 0.36210155704951535
Validation loss: 2.6435995860256805

Epoch: 5| Step: 7
Training loss: 0.4488564232519932
Validation loss: 2.6762996050843073

Epoch: 5| Step: 8
Training loss: 0.3699694819365404
Validation loss: 2.667411626879104

Epoch: 5| Step: 9
Training loss: 0.43473610447881433
Validation loss: 2.7636006915627034

Epoch: 5| Step: 10
Training loss: 0.4565154531418303
Validation loss: 2.6543556190036464

Epoch: 5| Step: 11
Training loss: 0.31481622381546903
Validation loss: 2.6859175029821705

Epoch: 407| Step: 0
Training loss: 0.4620239901238367
Validation loss: 2.711894713751627

Epoch: 5| Step: 1
Training loss: 0.39770764466564623
Validation loss: 2.661418900816675

Epoch: 5| Step: 2
Training loss: 0.34759986077235633
Validation loss: 2.729367401054816

Epoch: 5| Step: 3
Training loss: 0.4551805863845996
Validation loss: 2.6964701870666543

Epoch: 5| Step: 4
Training loss: 0.27545777983305236
Validation loss: 2.706528305444345

Epoch: 5| Step: 5
Training loss: 0.5413776109395102
Validation loss: 2.749715996295556

Epoch: 5| Step: 6
Training loss: 0.47955144760737456
Validation loss: 2.6812059532228907

Epoch: 5| Step: 7
Training loss: 0.453236845616728
Validation loss: 2.714765976631143

Epoch: 5| Step: 8
Training loss: 0.37965719784982466
Validation loss: 2.746993433453701

Epoch: 5| Step: 9
Training loss: 0.5328243433287698
Validation loss: 2.7655534717052923

Epoch: 5| Step: 10
Training loss: 0.295807122470796
Validation loss: 2.790382852760041

Epoch: 5| Step: 11
Training loss: 0.45428408984416935
Validation loss: 2.666056978047052

Epoch: 408| Step: 0
Training loss: 0.4984329970823079
Validation loss: 2.7638114040275936

Epoch: 5| Step: 1
Training loss: 0.5455333601298988
Validation loss: 2.7660889712301038

Epoch: 5| Step: 2
Training loss: 0.3651197733062601
Validation loss: 2.7378111166795067

Epoch: 5| Step: 3
Training loss: 0.4478627346157556
Validation loss: 2.7388427782615676

Epoch: 5| Step: 4
Training loss: 0.34438712507180924
Validation loss: 2.6467996594824514

Epoch: 5| Step: 5
Training loss: 0.3790940871133045
Validation loss: 2.6708713750961777

Epoch: 5| Step: 6
Training loss: 0.49041996820527434
Validation loss: 2.6914166550419014

Epoch: 5| Step: 7
Training loss: 0.4117373011714775
Validation loss: 2.7149097626708367

Epoch: 5| Step: 8
Training loss: 0.6347974094356038
Validation loss: 2.716138517248603

Epoch: 5| Step: 9
Training loss: 0.40585898875712867
Validation loss: 2.6662688231724054

Epoch: 5| Step: 10
Training loss: 0.3783707324664157
Validation loss: 2.668831897405109

Epoch: 5| Step: 11
Training loss: 0.5473587076777033
Validation loss: 2.6827413175896995

Epoch: 409| Step: 0
Training loss: 0.5909073190229033
Validation loss: 2.718619582822687

Epoch: 5| Step: 1
Training loss: 0.320754629963962
Validation loss: 2.736766049514191

Epoch: 5| Step: 2
Training loss: 0.4371668705357435
Validation loss: 2.6963536320293375

Epoch: 5| Step: 3
Training loss: 0.37538274464984434
Validation loss: 2.6273460878952957

Epoch: 5| Step: 4
Training loss: 0.43008447862413623
Validation loss: 2.6419475185505776

Epoch: 5| Step: 5
Training loss: 0.3865726657415808
Validation loss: 2.6877747217864654

Epoch: 5| Step: 6
Training loss: 0.4571808627175473
Validation loss: 2.701125346141843

Epoch: 5| Step: 7
Training loss: 0.4874210257017621
Validation loss: 2.691864830926683

Epoch: 5| Step: 8
Training loss: 0.4891648042335776
Validation loss: 2.7434473865790183

Epoch: 5| Step: 9
Training loss: 0.41408740274650024
Validation loss: 2.6928995803612827

Epoch: 5| Step: 10
Training loss: 0.3696682303107213
Validation loss: 2.730577189302771

Epoch: 5| Step: 11
Training loss: 0.3671056778017965
Validation loss: 2.7486787642054584

Epoch: 410| Step: 0
Training loss: 0.25752631110885327
Validation loss: 2.6809213353876333

Epoch: 5| Step: 1
Training loss: 0.5711880847340621
Validation loss: 2.733603272299268

Epoch: 5| Step: 2
Training loss: 0.3074198740951005
Validation loss: 2.7658716907142082

Epoch: 5| Step: 3
Training loss: 0.31770628657489475
Validation loss: 2.786509441489335

Epoch: 5| Step: 4
Training loss: 0.30046581473183903
Validation loss: 2.6767058805270962

Epoch: 5| Step: 5
Training loss: 0.5386384042102014
Validation loss: 2.7123800501692688

Epoch: 5| Step: 6
Training loss: 0.34688866992167705
Validation loss: 2.6854366987342924

Epoch: 5| Step: 7
Training loss: 0.4321819380638825
Validation loss: 2.662303481811731

Epoch: 5| Step: 8
Training loss: 0.39202025141516295
Validation loss: 2.707221376348829

Epoch: 5| Step: 9
Training loss: 0.4106694779773313
Validation loss: 2.7455419960127334

Epoch: 5| Step: 10
Training loss: 0.39810593216536005
Validation loss: 2.7724473215458327

Epoch: 5| Step: 11
Training loss: 0.19448574560391477
Validation loss: 2.661454200119323

Epoch: 411| Step: 0
Training loss: 0.2653949807488718
Validation loss: 2.7241451838772273

Epoch: 5| Step: 1
Training loss: 0.4038371176372452
Validation loss: 2.688168656905923

Epoch: 5| Step: 2
Training loss: 0.2957823119469394
Validation loss: 2.6990771847675425

Epoch: 5| Step: 3
Training loss: 0.41583371550683224
Validation loss: 2.7173409153786032

Epoch: 5| Step: 4
Training loss: 0.33057235644801763
Validation loss: 2.659618919055201

Epoch: 5| Step: 5
Training loss: 0.4338759285947929
Validation loss: 2.6988558858854477

Epoch: 5| Step: 6
Training loss: 0.4746133466640742
Validation loss: 2.7267381689834447

Epoch: 5| Step: 7
Training loss: 0.4072953858982172
Validation loss: 2.7222299520281172

Epoch: 5| Step: 8
Training loss: 0.17370038214272546
Validation loss: 2.7419179927039874

Epoch: 5| Step: 9
Training loss: 0.2733375639171319
Validation loss: 2.706714106959875

Epoch: 5| Step: 10
Training loss: 0.2894898168703299
Validation loss: 2.7081494574605625

Epoch: 5| Step: 11
Training loss: 0.43211838876457576
Validation loss: 2.6440149157237323

Epoch: 412| Step: 0
Training loss: 0.27083163383146286
Validation loss: 2.748382054475015

Epoch: 5| Step: 1
Training loss: 0.3344033051034846
Validation loss: 2.6987792014644305

Epoch: 5| Step: 2
Training loss: 0.2886820944911581
Validation loss: 2.6669223198433594

Epoch: 5| Step: 3
Training loss: 0.46340390812238813
Validation loss: 2.6509637177904533

Epoch: 5| Step: 4
Training loss: 0.3970851949819587
Validation loss: 2.648645510986619

Epoch: 5| Step: 5
Training loss: 0.3657528058855086
Validation loss: 2.706306844999684

Epoch: 5| Step: 6
Training loss: 0.5377204886354205
Validation loss: 2.7184817375456998

Epoch: 5| Step: 7
Training loss: 0.5363017443165321
Validation loss: 2.689465166525293

Epoch: 5| Step: 8
Training loss: 0.4820320314867804
Validation loss: 2.7456709715828866

Epoch: 5| Step: 9
Training loss: 0.3438987193481147
Validation loss: 2.679451360205405

Epoch: 5| Step: 10
Training loss: 0.4416486024161387
Validation loss: 2.7126017142707455

Epoch: 5| Step: 11
Training loss: 0.5641365615535674
Validation loss: 2.7185084392762042

Epoch: 413| Step: 0
Training loss: 0.35695029244454346
Validation loss: 2.7276642348734996

Epoch: 5| Step: 1
Training loss: 0.5308468074026735
Validation loss: 2.7619752454553015

Epoch: 5| Step: 2
Training loss: 0.3566549233519119
Validation loss: 2.664892438408165

Epoch: 5| Step: 3
Training loss: 0.38347811150410427
Validation loss: 2.7114176219668806

Epoch: 5| Step: 4
Training loss: 0.48636283903818234
Validation loss: 2.6784655469827108

Epoch: 5| Step: 5
Training loss: 0.3804464987763294
Validation loss: 2.685888054647614

Epoch: 5| Step: 6
Training loss: 0.5345578990494313
Validation loss: 2.730307945860964

Epoch: 5| Step: 7
Training loss: 0.40729503833451614
Validation loss: 2.7031849834276986

Epoch: 5| Step: 8
Training loss: 0.38656189174496314
Validation loss: 2.728123382940756

Epoch: 5| Step: 9
Training loss: 0.41722918527202185
Validation loss: 2.697267186603835

Epoch: 5| Step: 10
Training loss: 0.5068078887763549
Validation loss: 2.661985977085522

Epoch: 5| Step: 11
Training loss: 0.3236082372733355
Validation loss: 2.768485639048615

Epoch: 414| Step: 0
Training loss: 0.27589157210450665
Validation loss: 2.779367667159128

Epoch: 5| Step: 1
Training loss: 0.31008444850987305
Validation loss: 2.717890398928911

Epoch: 5| Step: 2
Training loss: 0.4951249372188044
Validation loss: 2.6895084269223113

Epoch: 5| Step: 3
Training loss: 0.3695535519989338
Validation loss: 2.733190559713425

Epoch: 5| Step: 4
Training loss: 0.35001189220184015
Validation loss: 2.761399242978119

Epoch: 5| Step: 5
Training loss: 0.2988159576132992
Validation loss: 2.6662891624890275

Epoch: 5| Step: 6
Training loss: 0.5357720945593398
Validation loss: 2.6152903194963

Epoch: 5| Step: 7
Training loss: 0.4142539463465314
Validation loss: 2.717986467359808

Epoch: 5| Step: 8
Training loss: 0.353695123109368
Validation loss: 2.649848712045468

Epoch: 5| Step: 9
Training loss: 0.5411246289776054
Validation loss: 2.676121384287236

Epoch: 5| Step: 10
Training loss: 0.34123046810370017
Validation loss: 2.680767030944486

Epoch: 5| Step: 11
Training loss: 0.28129704399847555
Validation loss: 2.7499749623228125

Epoch: 415| Step: 0
Training loss: 0.3434142510456368
Validation loss: 2.6533212559950705

Epoch: 5| Step: 1
Training loss: 0.4148418182213125
Validation loss: 2.723992861108906

Epoch: 5| Step: 2
Training loss: 0.36464717396873264
Validation loss: 2.7095206458027934

Epoch: 5| Step: 3
Training loss: 0.2622600196418909
Validation loss: 2.7261573468624833

Epoch: 5| Step: 4
Training loss: 0.5396087753405234
Validation loss: 2.7781356133343014

Epoch: 5| Step: 5
Training loss: 0.4205710073453318
Validation loss: 2.671410756371092

Epoch: 5| Step: 6
Training loss: 0.36312676293081403
Validation loss: 2.736366531280433

Epoch: 5| Step: 7
Training loss: 0.4256790283406375
Validation loss: 2.706842090186729

Epoch: 5| Step: 8
Training loss: 0.3029440246180043
Validation loss: 2.640441075527674

Epoch: 5| Step: 9
Training loss: 0.23119494420720488
Validation loss: 2.7268609263450156

Epoch: 5| Step: 10
Training loss: 0.36894269208245084
Validation loss: 2.7186011039768454

Epoch: 5| Step: 11
Training loss: 0.26833643974901145
Validation loss: 2.6696976867776736

Epoch: 416| Step: 0
Training loss: 0.32648345775525606
Validation loss: 2.7455780500100895

Epoch: 5| Step: 1
Training loss: 0.5001630219296336
Validation loss: 2.645945867012587

Epoch: 5| Step: 2
Training loss: 0.3107627981700735
Validation loss: 2.724894693947181

Epoch: 5| Step: 3
Training loss: 0.2757337069933224
Validation loss: 2.7301267119520864

Epoch: 5| Step: 4
Training loss: 0.4214292219701923
Validation loss: 2.6111089157428937

Epoch: 5| Step: 5
Training loss: 0.5400523344481971
Validation loss: 2.7005250569638237

Epoch: 5| Step: 6
Training loss: 0.3927017320976982
Validation loss: 2.674315979067021

Epoch: 5| Step: 7
Training loss: 0.30543470461264643
Validation loss: 2.68183284588301

Epoch: 5| Step: 8
Training loss: 0.38589177188933776
Validation loss: 2.730363078839933

Epoch: 5| Step: 9
Training loss: 0.45952139746912696
Validation loss: 2.684364223051513

Epoch: 5| Step: 10
Training loss: 0.37259790855543545
Validation loss: 2.670525509348256

Epoch: 5| Step: 11
Training loss: 0.40204196092827615
Validation loss: 2.7146146572430268

Epoch: 417| Step: 0
Training loss: 0.30598021418519283
Validation loss: 2.7224952288919475

Epoch: 5| Step: 1
Training loss: 0.4133292128885657
Validation loss: 2.761836688352975

Epoch: 5| Step: 2
Training loss: 0.49852759405036734
Validation loss: 2.6691270011049104

Epoch: 5| Step: 3
Training loss: 0.4530030941583843
Validation loss: 2.6994470590846698

Epoch: 5| Step: 4
Training loss: 0.4312239487007945
Validation loss: 2.696258062092119

Epoch: 5| Step: 5
Training loss: 0.3338169325102338
Validation loss: 2.6865246799456415

Epoch: 5| Step: 6
Training loss: 0.403218346515221
Validation loss: 2.714445008925285

Epoch: 5| Step: 7
Training loss: 0.23527557285941558
Validation loss: 2.7210855062401667

Epoch: 5| Step: 8
Training loss: 0.30413994127378474
Validation loss: 2.722341357811774

Epoch: 5| Step: 9
Training loss: 0.3076566398389525
Validation loss: 2.704152402609973

Epoch: 5| Step: 10
Training loss: 0.3900812560799476
Validation loss: 2.688168934067856

Epoch: 5| Step: 11
Training loss: 0.1652300423759775
Validation loss: 2.731697308205761

Epoch: 418| Step: 0
Training loss: 0.29030874026094683
Validation loss: 2.6545420821822847

Epoch: 5| Step: 1
Training loss: 0.2626481563403556
Validation loss: 2.7508817870136855

Epoch: 5| Step: 2
Training loss: 0.38056840785956014
Validation loss: 2.7277962426461446

Epoch: 5| Step: 3
Training loss: 0.26918673957662387
Validation loss: 2.7075219858638278

Epoch: 5| Step: 4
Training loss: 0.3741941933747669
Validation loss: 2.770453772445301

Epoch: 5| Step: 5
Training loss: 0.4780122873430843
Validation loss: 2.6768997713282245

Epoch: 5| Step: 6
Training loss: 0.26304309895509853
Validation loss: 2.733273027983709

Epoch: 5| Step: 7
Training loss: 0.43989999726541096
Validation loss: 2.6664399606976965

Epoch: 5| Step: 8
Training loss: 0.29593543649133297
Validation loss: 2.713999613793031

Epoch: 5| Step: 9
Training loss: 0.3322645601838085
Validation loss: 2.7466707487118427

Epoch: 5| Step: 10
Training loss: 0.4000664119424906
Validation loss: 2.7036320021605076

Epoch: 5| Step: 11
Training loss: 0.1966595072086303
Validation loss: 2.7202590539813887

Epoch: 419| Step: 0
Training loss: 0.4358783538236424
Validation loss: 2.723792077723224

Epoch: 5| Step: 1
Training loss: 0.2952903063068909
Validation loss: 2.6886201675366643

Epoch: 5| Step: 2
Training loss: 0.3785831214083538
Validation loss: 2.690411927060159

Epoch: 5| Step: 3
Training loss: 0.3768295915808169
Validation loss: 2.6810878879531868

Epoch: 5| Step: 4
Training loss: 0.381197148708976
Validation loss: 2.676891191368113

Epoch: 5| Step: 5
Training loss: 0.4635050434117985
Validation loss: 2.703318770855848

Epoch: 5| Step: 6
Training loss: 0.41942828244986424
Validation loss: 2.6970371865030995

Epoch: 5| Step: 7
Training loss: 0.24667232106763437
Validation loss: 2.7537137372340226

Epoch: 5| Step: 8
Training loss: 0.2796624332255519
Validation loss: 2.6899429684127396

Epoch: 5| Step: 9
Training loss: 0.6148338588515191
Validation loss: 2.717623751401099

Epoch: 5| Step: 10
Training loss: 0.3542281499489599
Validation loss: 2.7520306343694902

Epoch: 5| Step: 11
Training loss: 0.30258640241541657
Validation loss: 2.751579838730069

Epoch: 420| Step: 0
Training loss: 0.2884053932166468
Validation loss: 2.749467854236576

Epoch: 5| Step: 1
Training loss: 0.34206149076051184
Validation loss: 2.764422045508695

Epoch: 5| Step: 2
Training loss: 0.31301655991229504
Validation loss: 2.702886670140562

Epoch: 5| Step: 3
Training loss: 0.33872075723573675
Validation loss: 2.694582585079604

Epoch: 5| Step: 4
Training loss: 0.47261887394693824
Validation loss: 2.722723144118127

Epoch: 5| Step: 5
Training loss: 0.47066686023605964
Validation loss: 2.804682218923883

Epoch: 5| Step: 6
Training loss: 0.43241443575944427
Validation loss: 2.7551223648927743

Epoch: 5| Step: 7
Training loss: 0.4071592096848748
Validation loss: 2.6596997056466676

Epoch: 5| Step: 8
Training loss: 0.3198414805172908
Validation loss: 2.7433651553583807

Epoch: 5| Step: 9
Training loss: 0.3927654180177528
Validation loss: 2.6501950684013464

Epoch: 5| Step: 10
Training loss: 0.32780280643455184
Validation loss: 2.748332478951282

Epoch: 5| Step: 11
Training loss: 0.2524799782302706
Validation loss: 2.6949358064146067

Epoch: 421| Step: 0
Training loss: 0.3845017588566508
Validation loss: 2.6632112987161274

Epoch: 5| Step: 1
Training loss: 0.258158321792976
Validation loss: 2.669065586045576

Epoch: 5| Step: 2
Training loss: 0.3190706300026595
Validation loss: 2.6508158017353964

Epoch: 5| Step: 3
Training loss: 0.31813344369036306
Validation loss: 2.6688526303571143

Epoch: 5| Step: 4
Training loss: 0.4177571768358221
Validation loss: 2.651116856606047

Epoch: 5| Step: 5
Training loss: 0.4721730181671577
Validation loss: 2.6860085977076813

Epoch: 5| Step: 6
Training loss: 0.4554338006667286
Validation loss: 2.67198208079378

Epoch: 5| Step: 7
Training loss: 0.43154289899947634
Validation loss: 2.6703607346888303

Epoch: 5| Step: 8
Training loss: 0.42852040360323934
Validation loss: 2.6915655029013204

Epoch: 5| Step: 9
Training loss: 0.3808615659993068
Validation loss: 2.7486551131772745

Epoch: 5| Step: 10
Training loss: 0.3515701505040509
Validation loss: 2.685753861282349

Epoch: 5| Step: 11
Training loss: 0.2559856656390149
Validation loss: 2.6330602097313935

Epoch: 422| Step: 0
Training loss: 0.39280071875143235
Validation loss: 2.6620795923938063

Epoch: 5| Step: 1
Training loss: 0.5065412013514147
Validation loss: 2.5989454583796427

Epoch: 5| Step: 2
Training loss: 0.45577072680660213
Validation loss: 2.632116397406226

Epoch: 5| Step: 3
Training loss: 0.31109065304818795
Validation loss: 2.6918998066397073

Epoch: 5| Step: 4
Training loss: 0.3708891856891246
Validation loss: 2.6952210857719403

Epoch: 5| Step: 5
Training loss: 0.3468675561054632
Validation loss: 2.7144333856311134

Epoch: 5| Step: 6
Training loss: 0.43844884772104176
Validation loss: 2.7262229434738585

Epoch: 5| Step: 7
Training loss: 0.4165817492101933
Validation loss: 2.727897575864758

Epoch: 5| Step: 8
Training loss: 0.4871546145357922
Validation loss: 2.6157365221429028

Epoch: 5| Step: 9
Training loss: 0.4527936908087761
Validation loss: 2.703364203642713

Epoch: 5| Step: 10
Training loss: 0.3646282531676854
Validation loss: 2.7095751018615206

Epoch: 5| Step: 11
Training loss: 0.3092725145729616
Validation loss: 2.666876255059243

Epoch: 423| Step: 0
Training loss: 0.46084868658449163
Validation loss: 2.7188118638932885

Epoch: 5| Step: 1
Training loss: 0.33731985671011744
Validation loss: 2.729193557480593

Epoch: 5| Step: 2
Training loss: 0.3164982014547714
Validation loss: 2.749844340774054

Epoch: 5| Step: 3
Training loss: 0.4342169707468758
Validation loss: 2.698269737490503

Epoch: 5| Step: 4
Training loss: 0.3760973847692596
Validation loss: 2.7000967751631855

Epoch: 5| Step: 5
Training loss: 0.5516573924277166
Validation loss: 2.68672419594903

Epoch: 5| Step: 6
Training loss: 0.37791440868789644
Validation loss: 2.6961765802379634

Epoch: 5| Step: 7
Training loss: 0.3713238454516337
Validation loss: 2.693211020961389

Epoch: 5| Step: 8
Training loss: 0.3303442113878714
Validation loss: 2.6811881205688337

Epoch: 5| Step: 9
Training loss: 0.6673851586965706
Validation loss: 2.681985812974151

Epoch: 5| Step: 10
Training loss: 0.3926068575388911
Validation loss: 2.6882957714560334

Epoch: 5| Step: 11
Training loss: 0.33460798658269514
Validation loss: 2.674965474687279

Epoch: 424| Step: 0
Training loss: 0.28359743488954825
Validation loss: 2.701156296205866

Epoch: 5| Step: 1
Training loss: 0.41422480874827006
Validation loss: 2.6643724829846587

Epoch: 5| Step: 2
Training loss: 0.27187115403447654
Validation loss: 2.7186848278199878

Epoch: 5| Step: 3
Training loss: 0.422747240126324
Validation loss: 2.7399559559292843

Epoch: 5| Step: 4
Training loss: 0.3025449344663598
Validation loss: 2.708056125148

Epoch: 5| Step: 5
Training loss: 0.3038448639484102
Validation loss: 2.7244714152821956

Epoch: 5| Step: 6
Training loss: 0.399093573965318
Validation loss: 2.7104525503372776

Epoch: 5| Step: 7
Training loss: 0.3665241580432817
Validation loss: 2.696931885096892

Epoch: 5| Step: 8
Training loss: 0.2318840295133717
Validation loss: 2.6683292024410883

Epoch: 5| Step: 9
Training loss: 0.45324564018404023
Validation loss: 2.690896704376379

Epoch: 5| Step: 10
Training loss: 0.3528835800612859
Validation loss: 2.6613376736895398

Epoch: 5| Step: 11
Training loss: 0.2735371408114746
Validation loss: 2.663137116713863

Epoch: 425| Step: 0
Training loss: 0.41130730919547015
Validation loss: 2.6537560217644245

Epoch: 5| Step: 1
Training loss: 0.39056739382364547
Validation loss: 2.68459722940923

Epoch: 5| Step: 2
Training loss: 0.4876818831141227
Validation loss: 2.6540526333141194

Epoch: 5| Step: 3
Training loss: 0.36877156534013283
Validation loss: 2.692920308774405

Epoch: 5| Step: 4
Training loss: 0.28128676703986105
Validation loss: 2.6538617598733234

Epoch: 5| Step: 5
Training loss: 0.4019128102659267
Validation loss: 2.7017018314789545

Epoch: 5| Step: 6
Training loss: 0.30725158279110587
Validation loss: 2.7386292160760637

Epoch: 5| Step: 7
Training loss: 0.5213137572561135
Validation loss: 2.7046598549467062

Epoch: 5| Step: 8
Training loss: 0.44552725917144265
Validation loss: 2.730616385889498

Epoch: 5| Step: 9
Training loss: 0.3765222725809145
Validation loss: 2.6068298544031183

Epoch: 5| Step: 10
Training loss: 0.4055465513348229
Validation loss: 2.6544398329418724

Epoch: 5| Step: 11
Training loss: 0.5006264993499896
Validation loss: 2.669705013536374

Epoch: 426| Step: 0
Training loss: 0.3949067623216307
Validation loss: 2.6404454585929487

Epoch: 5| Step: 1
Training loss: 0.3705655203336045
Validation loss: 2.6847977322781036

Epoch: 5| Step: 2
Training loss: 0.3576027459437595
Validation loss: 2.71966654576046

Epoch: 5| Step: 3
Training loss: 0.2939554257094755
Validation loss: 2.6439416642300175

Epoch: 5| Step: 4
Training loss: 0.3239510016618537
Validation loss: 2.737918729996609

Epoch: 5| Step: 5
Training loss: 0.4296443917584891
Validation loss: 2.752941992656537

Epoch: 5| Step: 6
Training loss: 0.5163034830260727
Validation loss: 2.7003902279874543

Epoch: 5| Step: 7
Training loss: 0.42073098234782996
Validation loss: 2.790122392651976

Epoch: 5| Step: 8
Training loss: 0.39555620439027644
Validation loss: 2.7074809212392545

Epoch: 5| Step: 9
Training loss: 0.27104410656899336
Validation loss: 2.7172134449359753

Epoch: 5| Step: 10
Training loss: 0.3453708280089783
Validation loss: 2.7095564220131725

Epoch: 5| Step: 11
Training loss: 0.15333796357034785
Validation loss: 2.688428230557884

Epoch: 427| Step: 0
Training loss: 0.4128225402130859
Validation loss: 2.671567203869949

Epoch: 5| Step: 1
Training loss: 0.5143666083855335
Validation loss: 2.7115871959131876

Epoch: 5| Step: 2
Training loss: 0.4389402151359222
Validation loss: 2.707792608984522

Epoch: 5| Step: 3
Training loss: 0.3064469618841049
Validation loss: 2.7266508632794975

Epoch: 5| Step: 4
Training loss: 0.2763610273018382
Validation loss: 2.7480910387356174

Epoch: 5| Step: 5
Training loss: 0.42003035807452777
Validation loss: 2.7698470537764877

Epoch: 5| Step: 6
Training loss: 0.46229440784830694
Validation loss: 2.747610010895638

Epoch: 5| Step: 7
Training loss: 0.2672737367230313
Validation loss: 2.676747580574462

Epoch: 5| Step: 8
Training loss: 0.4407184102762332
Validation loss: 2.7028431093092036

Epoch: 5| Step: 9
Training loss: 0.46117748866476543
Validation loss: 2.7611122274673714

Epoch: 5| Step: 10
Training loss: 0.4167035285220831
Validation loss: 2.679518973312595

Epoch: 5| Step: 11
Training loss: 0.2785267917272401
Validation loss: 2.662445091970857

Epoch: 428| Step: 0
Training loss: 0.2778152702116189
Validation loss: 2.705134363427606

Epoch: 5| Step: 1
Training loss: 0.44527359842738745
Validation loss: 2.756048234343546

Epoch: 5| Step: 2
Training loss: 0.38171017812441255
Validation loss: 2.7493253154793433

Epoch: 5| Step: 3
Training loss: 0.43059670749841583
Validation loss: 2.6137313683209262

Epoch: 5| Step: 4
Training loss: 0.5051658914048905
Validation loss: 2.6671702491844496

Epoch: 5| Step: 5
Training loss: 0.4227590129259237
Validation loss: 2.721584775118607

Epoch: 5| Step: 6
Training loss: 0.42833729930753534
Validation loss: 2.6799779128474017

Epoch: 5| Step: 7
Training loss: 0.45894882389121133
Validation loss: 2.6711011178561335

Epoch: 5| Step: 8
Training loss: 0.32581058068279994
Validation loss: 2.71684896207562

Epoch: 5| Step: 9
Training loss: 0.45444778861574797
Validation loss: 2.667089839727325

Epoch: 5| Step: 10
Training loss: 0.34736303758974624
Validation loss: 2.660551414323451

Epoch: 5| Step: 11
Training loss: 0.23984402833605592
Validation loss: 2.710870791447234

Epoch: 429| Step: 0
Training loss: 0.36462543335301356
Validation loss: 2.741751205934285

Epoch: 5| Step: 1
Training loss: 0.4865398176047627
Validation loss: 2.7659980285283066

Epoch: 5| Step: 2
Training loss: 0.33562431596441195
Validation loss: 2.7124315481733925

Epoch: 5| Step: 3
Training loss: 0.39492485505591796
Validation loss: 2.644072030266717

Epoch: 5| Step: 4
Training loss: 0.4010870854143925
Validation loss: 2.702317232926582

Epoch: 5| Step: 5
Training loss: 0.35686860751892086
Validation loss: 2.6577139242417

Epoch: 5| Step: 6
Training loss: 0.41936665579259114
Validation loss: 2.6194650220135753

Epoch: 5| Step: 7
Training loss: 0.3906644419784694
Validation loss: 2.7258373706274206

Epoch: 5| Step: 8
Training loss: 0.3957409960143596
Validation loss: 2.621432824902903

Epoch: 5| Step: 9
Training loss: 0.33787495791766275
Validation loss: 2.6705626858435143

Epoch: 5| Step: 10
Training loss: 0.3164813694261504
Validation loss: 2.7341783761674123

Epoch: 5| Step: 11
Training loss: 0.3687730806207273
Validation loss: 2.7382021469466666

Epoch: 430| Step: 0
Training loss: 0.3079150740608528
Validation loss: 2.667881369847039

Epoch: 5| Step: 1
Training loss: 0.30923499108561975
Validation loss: 2.726659527120671

Epoch: 5| Step: 2
Training loss: 0.4214226805723203
Validation loss: 2.785626928534071

Epoch: 5| Step: 3
Training loss: 0.2747357203978867
Validation loss: 2.723197605891965

Epoch: 5| Step: 4
Training loss: 0.49073853727994954
Validation loss: 2.679078230256017

Epoch: 5| Step: 5
Training loss: 0.35584475992886405
Validation loss: 2.732223558079977

Epoch: 5| Step: 6
Training loss: 0.37958238190504834
Validation loss: 2.7020453003819696

Epoch: 5| Step: 7
Training loss: 0.31761901282575455
Validation loss: 2.815443804799567

Epoch: 5| Step: 8
Training loss: 0.37056425365509804
Validation loss: 2.7435429439174306

Epoch: 5| Step: 9
Training loss: 0.3569004236508455
Validation loss: 2.642422989424159

Epoch: 5| Step: 10
Training loss: 0.33191559965287953
Validation loss: 2.7906198116366747

Epoch: 5| Step: 11
Training loss: 0.16131157640091506
Validation loss: 2.7057927331932077

Epoch: 431| Step: 0
Training loss: 0.30226868528077455
Validation loss: 2.68284769066622

Epoch: 5| Step: 1
Training loss: 0.45685575653441546
Validation loss: 2.696112958938584

Epoch: 5| Step: 2
Training loss: 0.2728704021396764
Validation loss: 2.7259250540614843

Epoch: 5| Step: 3
Training loss: 0.3672105092083338
Validation loss: 2.683856049905969

Epoch: 5| Step: 4
Training loss: 0.31168277695440955
Validation loss: 2.6931735337255196

Epoch: 5| Step: 5
Training loss: 0.45586762277812126
Validation loss: 2.7058256913494176

Epoch: 5| Step: 6
Training loss: 0.4202955490721618
Validation loss: 2.7080420221258237

Epoch: 5| Step: 7
Training loss: 0.36225964865198296
Validation loss: 2.6383874769573206

Epoch: 5| Step: 8
Training loss: 0.39171421780301946
Validation loss: 2.699969535526258

Epoch: 5| Step: 9
Training loss: 0.3298039623859318
Validation loss: 2.6634481510359813

Epoch: 5| Step: 10
Training loss: 0.5130828845714155
Validation loss: 2.7418263080656793

Epoch: 5| Step: 11
Training loss: 0.45952016521990485
Validation loss: 2.618572016929178

Epoch: 432| Step: 0
Training loss: 0.37888574053128116
Validation loss: 2.6200328561673696

Epoch: 5| Step: 1
Training loss: 0.4880911953121215
Validation loss: 2.6341172220038063

Epoch: 5| Step: 2
Training loss: 0.4119037639547818
Validation loss: 2.674061614774916

Epoch: 5| Step: 3
Training loss: 0.33107629216008316
Validation loss: 2.6786103006600124

Epoch: 5| Step: 4
Training loss: 0.48873375333920077
Validation loss: 2.7130385949665397

Epoch: 5| Step: 5
Training loss: 0.30178123062274353
Validation loss: 2.6569830612214096

Epoch: 5| Step: 6
Training loss: 0.4509540048329417
Validation loss: 2.644368567221864

Epoch: 5| Step: 7
Training loss: 0.3420426166505122
Validation loss: 2.7087027750151336

Epoch: 5| Step: 8
Training loss: 0.36506424475646243
Validation loss: 2.6493819436698263

Epoch: 5| Step: 9
Training loss: 0.3835160349573465
Validation loss: 2.739381814780358

Epoch: 5| Step: 10
Training loss: 0.2542138510562018
Validation loss: 2.6367712849222396

Epoch: 5| Step: 11
Training loss: 0.5580756712640971
Validation loss: 2.703142798186933

Epoch: 433| Step: 0
Training loss: 0.34127264965961873
Validation loss: 2.723043610333682

Epoch: 5| Step: 1
Training loss: 0.3459542757668749
Validation loss: 2.68911079438734

Epoch: 5| Step: 2
Training loss: 0.491544606391791
Validation loss: 2.644368631085815

Epoch: 5| Step: 3
Training loss: 0.2889980553624287
Validation loss: 2.65843558807382

Epoch: 5| Step: 4
Training loss: 0.3884771808295222
Validation loss: 2.64883994061542

Epoch: 5| Step: 5
Training loss: 0.3578134486756388
Validation loss: 2.6563245089683516

Epoch: 5| Step: 6
Training loss: 0.478401964663176
Validation loss: 2.67825382090507

Epoch: 5| Step: 7
Training loss: 0.2766989209842702
Validation loss: 2.77150909290936

Epoch: 5| Step: 8
Training loss: 0.3943523341223358
Validation loss: 2.7028564951878224

Epoch: 5| Step: 9
Training loss: 0.3878218975050503
Validation loss: 2.661774867818874

Epoch: 5| Step: 10
Training loss: 0.3678017004237713
Validation loss: 2.722569763911605

Epoch: 5| Step: 11
Training loss: 0.5683649855923406
Validation loss: 2.804576124213095

Epoch: 434| Step: 0
Training loss: 0.4332102892793205
Validation loss: 2.744365537211999

Epoch: 5| Step: 1
Training loss: 0.44223112490965577
Validation loss: 2.7380286810863277

Epoch: 5| Step: 2
Training loss: 0.27034538432848604
Validation loss: 2.7104268541274106

Epoch: 5| Step: 3
Training loss: 0.4216540252382588
Validation loss: 2.6725450608772783

Epoch: 5| Step: 4
Training loss: 0.5062568605217139
Validation loss: 2.687204462997404

Epoch: 5| Step: 5
Training loss: 0.5222853035596903
Validation loss: 2.7206456456042587

Epoch: 5| Step: 6
Training loss: 0.5197089615529051
Validation loss: 2.7065558628502564

Epoch: 5| Step: 7
Training loss: 0.3185709852660612
Validation loss: 2.710095233510785

Epoch: 5| Step: 8
Training loss: 0.49957173603119615
Validation loss: 2.7172618845548326

Epoch: 5| Step: 9
Training loss: 0.45707953434388054
Validation loss: 2.7633973721073284

Epoch: 5| Step: 10
Training loss: 0.451836909169989
Validation loss: 2.7259515188896692

Epoch: 5| Step: 11
Training loss: 0.2792810822403459
Validation loss: 2.71758513141515

Epoch: 435| Step: 0
Training loss: 0.5360589037260096
Validation loss: 2.7162909001166082

Epoch: 5| Step: 1
Training loss: 0.5475405866132665
Validation loss: 2.699014187618513

Epoch: 5| Step: 2
Training loss: 0.4603141351892209
Validation loss: 2.7411322596554153

Epoch: 5| Step: 3
Training loss: 0.3661531936896915
Validation loss: 2.6507597469226307

Epoch: 5| Step: 4
Training loss: 0.32903882342707413
Validation loss: 2.6941166238083043

Epoch: 5| Step: 5
Training loss: 0.383318508248518
Validation loss: 2.70767697426024

Epoch: 5| Step: 6
Training loss: 0.46335494820630485
Validation loss: 2.7179056551909695

Epoch: 5| Step: 7
Training loss: 0.3148783184412737
Validation loss: 2.663751477742781

Epoch: 5| Step: 8
Training loss: 0.3418373955822051
Validation loss: 2.7282611033720756

Epoch: 5| Step: 9
Training loss: 0.33260290638252493
Validation loss: 2.7166902442115726

Epoch: 5| Step: 10
Training loss: 0.49827624256564196
Validation loss: 2.6862831262463382

Epoch: 5| Step: 11
Training loss: 0.23235231849350152
Validation loss: 2.6857659896703185

Epoch: 436| Step: 0
Training loss: 0.346583769517948
Validation loss: 2.6857431938778515

Epoch: 5| Step: 1
Training loss: 0.46947705786026644
Validation loss: 2.630864238474919

Epoch: 5| Step: 2
Training loss: 0.4613342678814217
Validation loss: 2.693113533881487

Epoch: 5| Step: 3
Training loss: 0.463431336277662
Validation loss: 2.740379730233983

Epoch: 5| Step: 4
Training loss: 0.3902898876887712
Validation loss: 2.7529364715813744

Epoch: 5| Step: 5
Training loss: 0.4044617026651668
Validation loss: 2.7113829767984092

Epoch: 5| Step: 6
Training loss: 0.4408002592772727
Validation loss: 2.6656249266576366

Epoch: 5| Step: 7
Training loss: 0.43535640640268025
Validation loss: 2.770726253237844

Epoch: 5| Step: 8
Training loss: 0.301478012385551
Validation loss: 2.6554727501730118

Epoch: 5| Step: 9
Training loss: 0.40000120624717983
Validation loss: 2.6002332214451327

Epoch: 5| Step: 10
Training loss: 0.37169826860032307
Validation loss: 2.7055690388786315

Epoch: 5| Step: 11
Training loss: 0.3341947863148146
Validation loss: 2.667272786954052

Epoch: 437| Step: 0
Training loss: 0.4092201813756169
Validation loss: 2.6625319192432655

Epoch: 5| Step: 1
Training loss: 0.31968229216867194
Validation loss: 2.6925911512031653

Epoch: 5| Step: 2
Training loss: 0.364087103147425
Validation loss: 2.674652503815293

Epoch: 5| Step: 3
Training loss: 0.4171251893390321
Validation loss: 2.703862168743482

Epoch: 5| Step: 4
Training loss: 0.2468647233417563
Validation loss: 2.6991080571032118

Epoch: 5| Step: 5
Training loss: 0.4468158476033524
Validation loss: 2.7202733547747306

Epoch: 5| Step: 6
Training loss: 0.3013924420616571
Validation loss: 2.6759531713048585

Epoch: 5| Step: 7
Training loss: 0.43141779606782893
Validation loss: 2.7448572166669734

Epoch: 5| Step: 8
Training loss: 0.4086161809712346
Validation loss: 2.692366481801122

Epoch: 5| Step: 9
Training loss: 0.45761478698595803
Validation loss: 2.693527312341677

Epoch: 5| Step: 10
Training loss: 0.29560264432305716
Validation loss: 2.7125261106274485

Epoch: 5| Step: 11
Training loss: 0.4030834915910565
Validation loss: 2.7297982814809307

Epoch: 438| Step: 0
Training loss: 0.3735250633721221
Validation loss: 2.787542005259512

Epoch: 5| Step: 1
Training loss: 0.40248242553110863
Validation loss: 2.751310061749963

Epoch: 5| Step: 2
Training loss: 0.33640221677950133
Validation loss: 2.708143929436552

Epoch: 5| Step: 3
Training loss: 0.3676291103048947
Validation loss: 2.760169040921307

Epoch: 5| Step: 4
Training loss: 0.27774750508150126
Validation loss: 2.678184758917673

Epoch: 5| Step: 5
Training loss: 0.3211257658726939
Validation loss: 2.7215168893644996

Epoch: 5| Step: 6
Training loss: 0.3246479755132567
Validation loss: 2.788263015780081

Epoch: 5| Step: 7
Training loss: 0.41617767329945143
Validation loss: 2.651903444578597

Epoch: 5| Step: 8
Training loss: 0.2776839225215769
Validation loss: 2.725835555703604

Epoch: 5| Step: 9
Training loss: 0.3524057236532462
Validation loss: 2.743502621226689

Epoch: 5| Step: 10
Training loss: 0.5149749067822647
Validation loss: 2.7369144672812817

Epoch: 5| Step: 11
Training loss: 0.25613878732716794
Validation loss: 2.745584381889095

Epoch: 439| Step: 0
Training loss: 0.4516415483920271
Validation loss: 2.7610993182996295

Epoch: 5| Step: 1
Training loss: 0.3947274881434169
Validation loss: 2.741431045891172

Epoch: 5| Step: 2
Training loss: 0.5755358272572838
Validation loss: 2.7769589521957148

Epoch: 5| Step: 3
Training loss: 0.279421771740565
Validation loss: 2.737665554306818

Epoch: 5| Step: 4
Training loss: 0.29437110959051743
Validation loss: 2.649689789975111

Epoch: 5| Step: 5
Training loss: 0.31901264449399136
Validation loss: 2.640730883941467

Epoch: 5| Step: 6
Training loss: 0.528410334506394
Validation loss: 2.667625133304847

Epoch: 5| Step: 7
Training loss: 0.41623125174402525
Validation loss: 2.6524430763399764

Epoch: 5| Step: 8
Training loss: 0.30671845195598374
Validation loss: 2.6358287128551106

Epoch: 5| Step: 9
Training loss: 0.38624092406192767
Validation loss: 2.7671585213601184

Epoch: 5| Step: 10
Training loss: 0.3138412659533576
Validation loss: 2.6707906437426345

Epoch: 5| Step: 11
Training loss: 0.21535977035704265
Validation loss: 2.719440259308972

Epoch: 440| Step: 0
Training loss: 0.473528695214851
Validation loss: 2.7539312375064577

Epoch: 5| Step: 1
Training loss: 0.41156588327788424
Validation loss: 2.7866465864435295

Epoch: 5| Step: 2
Training loss: 0.3010322959831834
Validation loss: 2.735435632541642

Epoch: 5| Step: 3
Training loss: 0.34353093189303546
Validation loss: 2.6949552105700962

Epoch: 5| Step: 4
Training loss: 0.4789911670915665
Validation loss: 2.636889458298932

Epoch: 5| Step: 5
Training loss: 0.38609319241466883
Validation loss: 2.5399103558608367

Epoch: 5| Step: 6
Training loss: 0.39576684451929084
Validation loss: 2.709779724844014

Epoch: 5| Step: 7
Training loss: 0.368003790092128
Validation loss: 2.660925792609351

Epoch: 5| Step: 8
Training loss: 0.35759441192787045
Validation loss: 2.6970348733640024

Epoch: 5| Step: 9
Training loss: 0.39059194424955956
Validation loss: 2.655572902174104

Epoch: 5| Step: 10
Training loss: 0.39230285786923097
Validation loss: 2.708443244513378

Epoch: 5| Step: 11
Training loss: 0.4335801234123121
Validation loss: 2.687996493173102

Epoch: 441| Step: 0
Training loss: 0.41069500371440304
Validation loss: 2.6416118891920184

Epoch: 5| Step: 1
Training loss: 0.3164353769341527
Validation loss: 2.725136508788856

Epoch: 5| Step: 2
Training loss: 0.38981410737567884
Validation loss: 2.6919170018658334

Epoch: 5| Step: 3
Training loss: 0.36878663705408643
Validation loss: 2.6858697019804008

Epoch: 5| Step: 4
Training loss: 0.21096085489751276
Validation loss: 2.679707956189668

Epoch: 5| Step: 5
Training loss: 0.5903271090394591
Validation loss: 2.6712111341760694

Epoch: 5| Step: 6
Training loss: 0.29461284893357864
Validation loss: 2.6922963077418873

Epoch: 5| Step: 7
Training loss: 0.32765702527217805
Validation loss: 2.657725530207278

Epoch: 5| Step: 8
Training loss: 0.4039789875875973
Validation loss: 2.6945888966961604

Epoch: 5| Step: 9
Training loss: 0.32319156676776617
Validation loss: 2.729262054877864

Epoch: 5| Step: 10
Training loss: 0.34514868721505776
Validation loss: 2.711656176520019

Epoch: 5| Step: 11
Training loss: 0.10169606412885428
Validation loss: 2.6685769433723503

Epoch: 442| Step: 0
Training loss: 0.2922658881436336
Validation loss: 2.6815552536983907

Epoch: 5| Step: 1
Training loss: 0.3894721375686668
Validation loss: 2.6435387710375853

Epoch: 5| Step: 2
Training loss: 0.3318731155808967
Validation loss: 2.6444683208331567

Epoch: 5| Step: 3
Training loss: 0.3093348188027184
Validation loss: 2.6641846570061913

Epoch: 5| Step: 4
Training loss: 0.2788882968370917
Validation loss: 2.697403436740771

Epoch: 5| Step: 5
Training loss: 0.41400255813015613
Validation loss: 2.6250309790947948

Epoch: 5| Step: 6
Training loss: 0.3377916709343406
Validation loss: 2.706601378936762

Epoch: 5| Step: 7
Training loss: 0.27993176731577185
Validation loss: 2.6967771116771524

Epoch: 5| Step: 8
Training loss: 0.46520494805194906
Validation loss: 2.72033356993095

Epoch: 5| Step: 9
Training loss: 0.32568476046191647
Validation loss: 2.685769237213519

Epoch: 5| Step: 10
Training loss: 0.34185398169700104
Validation loss: 2.692903439052872

Epoch: 5| Step: 11
Training loss: 0.20696682197401958
Validation loss: 2.6896983293218035

Epoch: 443| Step: 0
Training loss: 0.3827132855515274
Validation loss: 2.661776579002965

Epoch: 5| Step: 1
Training loss: 0.49165731969397075
Validation loss: 2.6964936658321665

Epoch: 5| Step: 2
Training loss: 0.34736006689421006
Validation loss: 2.699203075284295

Epoch: 5| Step: 3
Training loss: 0.3114115475224581
Validation loss: 2.714427127476674

Epoch: 5| Step: 4
Training loss: 0.3308558584339389
Validation loss: 2.6793134037095108

Epoch: 5| Step: 5
Training loss: 0.32614567360173013
Validation loss: 2.786363007646972

Epoch: 5| Step: 6
Training loss: 0.24729187270147604
Validation loss: 2.698854067540583

Epoch: 5| Step: 7
Training loss: 0.3430977615634765
Validation loss: 2.7530100308796834

Epoch: 5| Step: 8
Training loss: 0.4306990248140535
Validation loss: 2.779198200460619

Epoch: 5| Step: 9
Training loss: 0.5046487704790535
Validation loss: 2.715652242976749

Epoch: 5| Step: 10
Training loss: 0.37173398654108203
Validation loss: 2.748437833325147

Epoch: 5| Step: 11
Training loss: 0.30499966842211224
Validation loss: 2.667558987652607

Epoch: 444| Step: 0
Training loss: 0.49346817761969536
Validation loss: 2.6622381032269002

Epoch: 5| Step: 1
Training loss: 0.4840640639002184
Validation loss: 2.727079570166369

Epoch: 5| Step: 2
Training loss: 0.4744633422485099
Validation loss: 2.6877689966232947

Epoch: 5| Step: 3
Training loss: 0.5565516618276297
Validation loss: 2.7334269342348754

Epoch: 5| Step: 4
Training loss: 0.3199299644779587
Validation loss: 2.7648585994336425

Epoch: 5| Step: 5
Training loss: 0.2994767921464189
Validation loss: 2.7215774091691167

Epoch: 5| Step: 6
Training loss: 0.568742446010854
Validation loss: 2.79152605191327

Epoch: 5| Step: 7
Training loss: 0.4520909250152284
Validation loss: 2.821025800454452

Epoch: 5| Step: 8
Training loss: 0.40181104337992224
Validation loss: 2.7541934970543394

Epoch: 5| Step: 9
Training loss: 0.37241341698310576
Validation loss: 2.7133539956201984

Epoch: 5| Step: 10
Training loss: 0.382080994626247
Validation loss: 2.7850495470035317

Epoch: 5| Step: 11
Training loss: 0.49049452607914157
Validation loss: 2.699096871995208

Epoch: 445| Step: 0
Training loss: 0.41692298118325327
Validation loss: 2.7909146489287218

Epoch: 5| Step: 1
Training loss: 0.5671558549948863
Validation loss: 2.7436946809734475

Epoch: 5| Step: 2
Training loss: 0.42363558847899335
Validation loss: 2.717991302855731

Epoch: 5| Step: 3
Training loss: 0.2999785226842849
Validation loss: 2.746445544207126

Epoch: 5| Step: 4
Training loss: 0.29423577035059845
Validation loss: 2.6806896141330707

Epoch: 5| Step: 5
Training loss: 0.4174556970218309
Validation loss: 2.7502865353051344

Epoch: 5| Step: 6
Training loss: 0.34662988869197575
Validation loss: 2.7300104748987213

Epoch: 5| Step: 7
Training loss: 0.5141881226906437
Validation loss: 2.699287288548241

Epoch: 5| Step: 8
Training loss: 0.46666043573999477
Validation loss: 2.690236620428726

Epoch: 5| Step: 9
Training loss: 0.328817250404347
Validation loss: 2.7551729251675185

Epoch: 5| Step: 10
Training loss: 0.2849707588035477
Validation loss: 2.688641649436841

Epoch: 5| Step: 11
Training loss: 0.3670483995298541
Validation loss: 2.6884626024915854

Epoch: 446| Step: 0
Training loss: 0.44954623020048046
Validation loss: 2.680928305391415

Epoch: 5| Step: 1
Training loss: 0.4261149752191067
Validation loss: 2.695959269742783

Epoch: 5| Step: 2
Training loss: 0.35445738061944504
Validation loss: 2.686720006701564

Epoch: 5| Step: 3
Training loss: 0.32860087899870044
Validation loss: 2.695555765350903

Epoch: 5| Step: 4
Training loss: 0.33177653247403727
Validation loss: 2.6736743066318147

Epoch: 5| Step: 5
Training loss: 0.3684302665317465
Validation loss: 2.747375738905089

Epoch: 5| Step: 6
Training loss: 0.3875400991611479
Validation loss: 2.671884131462451

Epoch: 5| Step: 7
Training loss: 0.5182526709307875
Validation loss: 2.6841517039141234

Epoch: 5| Step: 8
Training loss: 0.2979652062911981
Validation loss: 2.7424001040734356

Epoch: 5| Step: 9
Training loss: 0.3322956827373428
Validation loss: 2.732727880750919

Epoch: 5| Step: 10
Training loss: 0.2998784996399358
Validation loss: 2.725123560434371

Epoch: 5| Step: 11
Training loss: 0.38128581504193104
Validation loss: 2.7041373112167175

Epoch: 447| Step: 0
Training loss: 0.43108648226986707
Validation loss: 2.690126885499446

Epoch: 5| Step: 1
Training loss: 0.35423355546120927
Validation loss: 2.7355361543886825

Epoch: 5| Step: 2
Training loss: 0.2878363870075138
Validation loss: 2.701062034493851

Epoch: 5| Step: 3
Training loss: 0.4116384699401799
Validation loss: 2.7406822811913103

Epoch: 5| Step: 4
Training loss: 0.32333194143488914
Validation loss: 2.700132437095244

Epoch: 5| Step: 5
Training loss: 0.4220609431747179
Validation loss: 2.695459957051336

Epoch: 5| Step: 6
Training loss: 0.27049445384398574
Validation loss: 2.7371676834085354

Epoch: 5| Step: 7
Training loss: 0.37814476733911856
Validation loss: 2.670667185701284

Epoch: 5| Step: 8
Training loss: 0.3390201146577969
Validation loss: 2.743287444607695

Epoch: 5| Step: 9
Training loss: 0.2726077159543153
Validation loss: 2.698228270653239

Epoch: 5| Step: 10
Training loss: 0.3237640915753304
Validation loss: 2.700329632490818

Epoch: 5| Step: 11
Training loss: 0.28861413153617155
Validation loss: 2.704498537405602

Epoch: 448| Step: 0
Training loss: 0.4261394883532547
Validation loss: 2.647148403743191

Epoch: 5| Step: 1
Training loss: 0.34997741677451005
Validation loss: 2.6826942487400616

Epoch: 5| Step: 2
Training loss: 0.29544168099159895
Validation loss: 2.6701027195705724

Epoch: 5| Step: 3
Training loss: 0.44042736991729303
Validation loss: 2.6293124432561696

Epoch: 5| Step: 4
Training loss: 0.36109421865778657
Validation loss: 2.675251736189449

Epoch: 5| Step: 5
Training loss: 0.4932410907076086
Validation loss: 2.691976729467196

Epoch: 5| Step: 6
Training loss: 0.2862176866908335
Validation loss: 2.7374459378900595

Epoch: 5| Step: 7
Training loss: 0.30047665072332913
Validation loss: 2.7873465337546404

Epoch: 5| Step: 8
Training loss: 0.43836416320415644
Validation loss: 2.723203147132839

Epoch: 5| Step: 9
Training loss: 0.293463568844705
Validation loss: 2.7030742471446993

Epoch: 5| Step: 10
Training loss: 0.4495019103212255
Validation loss: 2.7091070439389835

Epoch: 5| Step: 11
Training loss: 0.25296011487655695
Validation loss: 2.7031924252195276

Epoch: 449| Step: 0
Training loss: 0.4154105285617036
Validation loss: 2.6890110233336766

Epoch: 5| Step: 1
Training loss: 0.38613595300380416
Validation loss: 2.7154498606058723

Epoch: 5| Step: 2
Training loss: 0.4578275834290578
Validation loss: 2.693182696254652

Epoch: 5| Step: 3
Training loss: 0.3136510868238547
Validation loss: 2.732273965812896

Epoch: 5| Step: 4
Training loss: 0.49570386689643864
Validation loss: 2.773489716087555

Epoch: 5| Step: 5
Training loss: 0.29816855150479604
Validation loss: 2.6807512557505175

Epoch: 5| Step: 6
Training loss: 0.4521464930712949
Validation loss: 2.7513205128509997

Epoch: 5| Step: 7
Training loss: 0.27482706939930035
Validation loss: 2.6737933160091827

Epoch: 5| Step: 8
Training loss: 0.4334846221787822
Validation loss: 2.654221766412454

Epoch: 5| Step: 9
Training loss: 0.2779626924563424
Validation loss: 2.675375649184768

Epoch: 5| Step: 10
Training loss: 0.3200786248487872
Validation loss: 2.714453263410176

Epoch: 5| Step: 11
Training loss: 0.2738602095675184
Validation loss: 2.6780492429133838

Epoch: 450| Step: 0
Training loss: 0.36619472213449145
Validation loss: 2.7005057351338047

Epoch: 5| Step: 1
Training loss: 0.31105251054242733
Validation loss: 2.6809098668943383

Epoch: 5| Step: 2
Training loss: 0.24603712853475998
Validation loss: 2.6832535818245424

Epoch: 5| Step: 3
Training loss: 0.48384870116148293
Validation loss: 2.682664379903199

Epoch: 5| Step: 4
Training loss: 0.34116239240609236
Validation loss: 2.725584803979306

Epoch: 5| Step: 5
Training loss: 0.37872142806728526
Validation loss: 2.6977360246390782

Epoch: 5| Step: 6
Training loss: 0.2804192884605092
Validation loss: 2.745622937289745

Epoch: 5| Step: 7
Training loss: 0.4056750410391538
Validation loss: 2.6583441052970955

Epoch: 5| Step: 8
Training loss: 0.22874527990182436
Validation loss: 2.682694819007205

Epoch: 5| Step: 9
Training loss: 0.33294378431392735
Validation loss: 2.731765781006385

Epoch: 5| Step: 10
Training loss: 0.3312885055114504
Validation loss: 2.686434223963716

Epoch: 5| Step: 11
Training loss: 0.2286912780964654
Validation loss: 2.73101997905418

Epoch: 451| Step: 0
Training loss: 0.30682043404266296
Validation loss: 2.6743169634450874

Epoch: 5| Step: 1
Training loss: 0.3014996977127673
Validation loss: 2.6933866061022846

Epoch: 5| Step: 2
Training loss: 0.3257512446977691
Validation loss: 2.6556833335949896

Epoch: 5| Step: 3
Training loss: 0.3821370530228841
Validation loss: 2.735221648158537

Epoch: 5| Step: 4
Training loss: 0.3086070407950857
Validation loss: 2.7634992871352297

Epoch: 5| Step: 5
Training loss: 0.2745532975655141
Validation loss: 2.6503217215449375

Epoch: 5| Step: 6
Training loss: 0.4178351786014411
Validation loss: 2.676323683952417

Epoch: 5| Step: 7
Training loss: 0.3856132968010826
Validation loss: 2.7089005255379677

Epoch: 5| Step: 8
Training loss: 0.2788484882198843
Validation loss: 2.666695528817944

Epoch: 5| Step: 9
Training loss: 0.49718069413548266
Validation loss: 2.7620016382089627

Epoch: 5| Step: 10
Training loss: 0.34197777456851747
Validation loss: 2.75549560568398

Epoch: 5| Step: 11
Training loss: 0.24409299004284685
Validation loss: 2.699806451188631

Epoch: 452| Step: 0
Training loss: 0.24522859389729984
Validation loss: 2.6711050005996895

Epoch: 5| Step: 1
Training loss: 0.26334845876461815
Validation loss: 2.655746632920234

Epoch: 5| Step: 2
Training loss: 0.36066536821236217
Validation loss: 2.7223932256857015

Epoch: 5| Step: 3
Training loss: 0.28832299775321685
Validation loss: 2.635848565326458

Epoch: 5| Step: 4
Training loss: 0.30913942114591036
Validation loss: 2.67722265769102

Epoch: 5| Step: 5
Training loss: 0.36155378151473494
Validation loss: 2.6823389931858417

Epoch: 5| Step: 6
Training loss: 0.2716045113826865
Validation loss: 2.6964364514104924

Epoch: 5| Step: 7
Training loss: 0.40643242261502416
Validation loss: 2.6754249094160953

Epoch: 5| Step: 8
Training loss: 0.2508340572006663
Validation loss: 2.642026115705924

Epoch: 5| Step: 9
Training loss: 0.2650822114502992
Validation loss: 2.7177105264787658

Epoch: 5| Step: 10
Training loss: 0.4240787837219913
Validation loss: 2.7120080642425575

Epoch: 5| Step: 11
Training loss: 0.3621034294553865
Validation loss: 2.705598790708663

Epoch: 453| Step: 0
Training loss: 0.37567009263237966
Validation loss: 2.7016950621476616

Epoch: 5| Step: 1
Training loss: 0.30993297765686034
Validation loss: 2.720596238350936

Epoch: 5| Step: 2
Training loss: 0.40014458516794943
Validation loss: 2.6400647481350044

Epoch: 5| Step: 3
Training loss: 0.304809484760607
Validation loss: 2.662750693057089

Epoch: 5| Step: 4
Training loss: 0.42323229698521353
Validation loss: 2.681423922176116

Epoch: 5| Step: 5
Training loss: 0.4718872940280888
Validation loss: 2.6766989069509655

Epoch: 5| Step: 6
Training loss: 0.4497362390366972
Validation loss: 2.665662573981505

Epoch: 5| Step: 7
Training loss: 0.1880208074000826
Validation loss: 2.6989274224283233

Epoch: 5| Step: 8
Training loss: 0.49141423472117046
Validation loss: 2.637823571339062

Epoch: 5| Step: 9
Training loss: 0.493347738072874
Validation loss: 2.7362485842746858

Epoch: 5| Step: 10
Training loss: 0.43772720499888046
Validation loss: 2.7075933998426183

Epoch: 5| Step: 11
Training loss: 0.34432608925188657
Validation loss: 2.7442073139671392

Epoch: 454| Step: 0
Training loss: 0.44225370026135374
Validation loss: 2.77853948871689

Epoch: 5| Step: 1
Training loss: 0.38787061441826876
Validation loss: 2.7910566636154535

Epoch: 5| Step: 2
Training loss: 0.45442111349328956
Validation loss: 2.685554905734915

Epoch: 5| Step: 3
Training loss: 0.40270753728502073
Validation loss: 2.718740116116034

Epoch: 5| Step: 4
Training loss: 0.4291488044996787
Validation loss: 2.7084455185665828

Epoch: 5| Step: 5
Training loss: 0.5165730055648259
Validation loss: 2.6977525069519372

Epoch: 5| Step: 6
Training loss: 0.3372362227499505
Validation loss: 2.679518457980894

Epoch: 5| Step: 7
Training loss: 0.25678716856481953
Validation loss: 2.697956406485977

Epoch: 5| Step: 8
Training loss: 0.28676849682058486
Validation loss: 2.7845228668977744

Epoch: 5| Step: 9
Training loss: 0.38756343799115217
Validation loss: 2.754467662103504

Epoch: 5| Step: 10
Training loss: 0.39634502950087497
Validation loss: 2.694078127767723

Epoch: 5| Step: 11
Training loss: 0.20043410968976177
Validation loss: 2.7682780670890117

Epoch: 455| Step: 0
Training loss: 0.4064835463967604
Validation loss: 2.769323749238754

Epoch: 5| Step: 1
Training loss: 0.38177122850731576
Validation loss: 2.7062602520896064

Epoch: 5| Step: 2
Training loss: 0.3829333250921139
Validation loss: 2.6829329764098544

Epoch: 5| Step: 3
Training loss: 0.4489269635805431
Validation loss: 2.685863517820839

Epoch: 5| Step: 4
Training loss: 0.41401942047004503
Validation loss: 2.6172336099842446

Epoch: 5| Step: 5
Training loss: 0.3670910241832868
Validation loss: 2.7379351010299686

Epoch: 5| Step: 6
Training loss: 0.4388535202471921
Validation loss: 2.680720107159161

Epoch: 5| Step: 7
Training loss: 0.28436941518644354
Validation loss: 2.6758186857477395

Epoch: 5| Step: 8
Training loss: 0.34968350865844966
Validation loss: 2.780731320682503

Epoch: 5| Step: 9
Training loss: 0.3562671372825856
Validation loss: 2.76972107086559

Epoch: 5| Step: 10
Training loss: 0.4722283057525314
Validation loss: 2.7860301796984817

Epoch: 5| Step: 11
Training loss: 0.48103178576133093
Validation loss: 2.799488711082098

Epoch: 456| Step: 0
Training loss: 0.36274944881263255
Validation loss: 2.774480845529201

Epoch: 5| Step: 1
Training loss: 0.254160562947469
Validation loss: 2.7255659459163506

Epoch: 5| Step: 2
Training loss: 0.38400734088631183
Validation loss: 2.6982587918978598

Epoch: 5| Step: 3
Training loss: 0.320018191155802
Validation loss: 2.7328031908723345

Epoch: 5| Step: 4
Training loss: 0.33627086555166164
Validation loss: 2.731004679651999

Epoch: 5| Step: 5
Training loss: 0.4228564960288841
Validation loss: 2.761325054533048

Epoch: 5| Step: 6
Training loss: 0.3069211806221623
Validation loss: 2.6831749298203365

Epoch: 5| Step: 7
Training loss: 0.35367294099013835
Validation loss: 2.68118930620503

Epoch: 5| Step: 8
Training loss: 0.37695559565075415
Validation loss: 2.728769933581446

Epoch: 5| Step: 9
Training loss: 0.33368743277872553
Validation loss: 2.7711063635307545

Epoch: 5| Step: 10
Training loss: 0.46970947932467855
Validation loss: 2.7284321427459255

Epoch: 5| Step: 11
Training loss: 0.5493377003251182
Validation loss: 2.6472684404931313

Epoch: 457| Step: 0
Training loss: 0.35183969801668413
Validation loss: 2.683117679455931

Epoch: 5| Step: 1
Training loss: 0.31339274679297685
Validation loss: 2.6904120267552627

Epoch: 5| Step: 2
Training loss: 0.41900511628238807
Validation loss: 2.6904982653287757

Epoch: 5| Step: 3
Training loss: 0.36616243168345763
Validation loss: 2.65295381791316

Epoch: 5| Step: 4
Training loss: 0.34682276822245606
Validation loss: 2.692694678109013

Epoch: 5| Step: 5
Training loss: 0.3233739808961951
Validation loss: 2.698922144211535

Epoch: 5| Step: 6
Training loss: 0.4297645326401822
Validation loss: 2.680945624716295

Epoch: 5| Step: 7
Training loss: 0.3779851986040849
Validation loss: 2.7534623133184555

Epoch: 5| Step: 8
Training loss: 0.40483915661319086
Validation loss: 2.681982512697486

Epoch: 5| Step: 9
Training loss: 0.2941357195522397
Validation loss: 2.6454155522008334

Epoch: 5| Step: 10
Training loss: 0.4044772865133168
Validation loss: 2.7267868110035227

Epoch: 5| Step: 11
Training loss: 0.21333152716370016
Validation loss: 2.68299200797505

Epoch: 458| Step: 0
Training loss: 0.3760483115957301
Validation loss: 2.6952924239290907

Epoch: 5| Step: 1
Training loss: 0.41725064917685883
Validation loss: 2.6389450639607097

Epoch: 5| Step: 2
Training loss: 0.3992764112184261
Validation loss: 2.6870951865142763

Epoch: 5| Step: 3
Training loss: 0.3725375748250944
Validation loss: 2.6803384255362963

Epoch: 5| Step: 4
Training loss: 0.26410877623606116
Validation loss: 2.685747244093633

Epoch: 5| Step: 5
Training loss: 0.27500263234525885
Validation loss: 2.6734271681181094

Epoch: 5| Step: 6
Training loss: 0.5007747667580313
Validation loss: 2.663674472655222

Epoch: 5| Step: 7
Training loss: 0.272601539128815
Validation loss: 2.760717941733657

Epoch: 5| Step: 8
Training loss: 0.3983238656556197
Validation loss: 2.7599482024844755

Epoch: 5| Step: 9
Training loss: 0.35307812886044593
Validation loss: 2.7139994051547744

Epoch: 5| Step: 10
Training loss: 0.252009422459119
Validation loss: 2.7008606719254034

Epoch: 5| Step: 11
Training loss: 0.27716475069775787
Validation loss: 2.747521265911984

Epoch: 459| Step: 0
Training loss: 0.4090282733606957
Validation loss: 2.6975305212177974

Epoch: 5| Step: 1
Training loss: 0.41471613269836893
Validation loss: 2.7275679373154587

Epoch: 5| Step: 2
Training loss: 0.3724410245280185
Validation loss: 2.768476808272283

Epoch: 5| Step: 3
Training loss: 0.3127508229741125
Validation loss: 2.6896536204527957

Epoch: 5| Step: 4
Training loss: 0.35890600451077814
Validation loss: 2.7243974646557856

Epoch: 5| Step: 5
Training loss: 0.3261832617867918
Validation loss: 2.697038184688307

Epoch: 5| Step: 6
Training loss: 0.4042741336047267
Validation loss: 2.7400647104295475

Epoch: 5| Step: 7
Training loss: 0.4544099642380978
Validation loss: 2.7454351338074066

Epoch: 5| Step: 8
Training loss: 0.30674506188749473
Validation loss: 2.6736733331637215

Epoch: 5| Step: 9
Training loss: 0.6067696900145493
Validation loss: 2.650139665821827

Epoch: 5| Step: 10
Training loss: 0.23212124912598348
Validation loss: 2.647731413064677

Epoch: 5| Step: 11
Training loss: 0.50310852426599
Validation loss: 2.7060630208087546

Epoch: 460| Step: 0
Training loss: 0.4041083075807185
Validation loss: 2.751069312562784

Epoch: 5| Step: 1
Training loss: 0.46925711221848304
Validation loss: 2.674437794029514

Epoch: 5| Step: 2
Training loss: 0.37804190376798735
Validation loss: 2.6633291083359256

Epoch: 5| Step: 3
Training loss: 0.403715867970722
Validation loss: 2.693791355514817

Epoch: 5| Step: 4
Training loss: 0.6094468392306052
Validation loss: 2.7122789283324584

Epoch: 5| Step: 5
Training loss: 0.3584264593577471
Validation loss: 2.7025977522726805

Epoch: 5| Step: 6
Training loss: 0.4754552015266553
Validation loss: 2.684769907137185

Epoch: 5| Step: 7
Training loss: 0.5150767214579635
Validation loss: 2.651932685920503

Epoch: 5| Step: 8
Training loss: 0.3857791738040966
Validation loss: 2.691759371465109

Epoch: 5| Step: 9
Training loss: 0.4596468101868814
Validation loss: 2.650872929017608

Epoch: 5| Step: 10
Training loss: 0.3859486280991404
Validation loss: 2.7374185716952453

Epoch: 5| Step: 11
Training loss: 0.5131010067124157
Validation loss: 2.665452324274569

Epoch: 461| Step: 0
Training loss: 0.3675450349643379
Validation loss: 2.729917569755814

Epoch: 5| Step: 1
Training loss: 0.31218381621790636
Validation loss: 2.7456884614143426

Epoch: 5| Step: 2
Training loss: 0.4155509215859117
Validation loss: 2.77253475630645

Epoch: 5| Step: 3
Training loss: 0.4161710851628518
Validation loss: 2.8146538646302353

Epoch: 5| Step: 4
Training loss: 0.43384355789286927
Validation loss: 2.798033763729274

Epoch: 5| Step: 5
Training loss: 0.3894262612584874
Validation loss: 2.7301025254172604

Epoch: 5| Step: 6
Training loss: 0.4549817159143939
Validation loss: 2.7883102300051226

Epoch: 5| Step: 7
Training loss: 0.46697897132542127
Validation loss: 2.766978677904378

Epoch: 5| Step: 8
Training loss: 0.5002038063481044
Validation loss: 2.7152977909077975

Epoch: 5| Step: 9
Training loss: 0.4675443243495077
Validation loss: 2.6431731056820325

Epoch: 5| Step: 10
Training loss: 0.39897415073337134
Validation loss: 2.7581763239157513

Epoch: 5| Step: 11
Training loss: 0.16937769426687405
Validation loss: 2.7315019027272265

Epoch: 462| Step: 0
Training loss: 0.3919290329218266
Validation loss: 2.722520070476364

Epoch: 5| Step: 1
Training loss: 0.40015151164427015
Validation loss: 2.7639885962428594

Epoch: 5| Step: 2
Training loss: 0.5087200271718827
Validation loss: 2.7803831964249732

Epoch: 5| Step: 3
Training loss: 0.41852228107752987
Validation loss: 2.7603661886434256

Epoch: 5| Step: 4
Training loss: 0.24370955749160136
Validation loss: 2.785176127729778

Epoch: 5| Step: 5
Training loss: 0.3638085875570303
Validation loss: 2.745066150691604

Epoch: 5| Step: 6
Training loss: 0.3656192322626583
Validation loss: 2.7323410098562277

Epoch: 5| Step: 7
Training loss: 0.31488602025554063
Validation loss: 2.6989234067148162

Epoch: 5| Step: 8
Training loss: 0.3494289827866139
Validation loss: 2.7711814874368317

Epoch: 5| Step: 9
Training loss: 0.250061712992678
Validation loss: 2.7048719233431577

Epoch: 5| Step: 10
Training loss: 0.4015598066959529
Validation loss: 2.7009888405617

Epoch: 5| Step: 11
Training loss: 0.5092098670505409
Validation loss: 2.7286498852053067

Epoch: 463| Step: 0
Training loss: 0.542603513976381
Validation loss: 2.711184865052769

Epoch: 5| Step: 1
Training loss: 0.3234535517372105
Validation loss: 2.794224810095354

Epoch: 5| Step: 2
Training loss: 0.3203073245304958
Validation loss: 2.751279146911559

Epoch: 5| Step: 3
Training loss: 0.3179003208394575
Validation loss: 2.730827964616988

Epoch: 5| Step: 4
Training loss: 0.4555517032781535
Validation loss: 2.723712119845266

Epoch: 5| Step: 5
Training loss: 0.3598416450031445
Validation loss: 2.726016590225121

Epoch: 5| Step: 6
Training loss: 0.3065935937081855
Validation loss: 2.750562585014061

Epoch: 5| Step: 7
Training loss: 0.2851363135906607
Validation loss: 2.652616746174687

Epoch: 5| Step: 8
Training loss: 0.37933115386853566
Validation loss: 2.6754654932391215

Epoch: 5| Step: 9
Training loss: 0.3587002431942594
Validation loss: 2.6164211916333144

Epoch: 5| Step: 10
Training loss: 0.26922377034275874
Validation loss: 2.6840161949347543

Epoch: 5| Step: 11
Training loss: 0.4193503282740154
Validation loss: 2.7144966434172964

Epoch: 464| Step: 0
Training loss: 0.41961584250622774
Validation loss: 2.723600554933462

Epoch: 5| Step: 1
Training loss: 0.3836704294048924
Validation loss: 2.6872638036745005

Epoch: 5| Step: 2
Training loss: 0.47089989692401707
Validation loss: 2.6380478737371944

Epoch: 5| Step: 3
Training loss: 0.2580438500647739
Validation loss: 2.62883202956745

Epoch: 5| Step: 4
Training loss: 0.29044748699386885
Validation loss: 2.6531925219782844

Epoch: 5| Step: 5
Training loss: 0.2773866620244558
Validation loss: 2.717939965019933

Epoch: 5| Step: 6
Training loss: 0.41692705561462856
Validation loss: 2.725151064678087

Epoch: 5| Step: 7
Training loss: 0.3851744711320581
Validation loss: 2.7033881718999675

Epoch: 5| Step: 8
Training loss: 0.40999578334221737
Validation loss: 2.6787997073582774

Epoch: 5| Step: 9
Training loss: 0.2611928467085767
Validation loss: 2.6845623528288636

Epoch: 5| Step: 10
Training loss: 0.392699436404011
Validation loss: 2.6698051674558902

Epoch: 5| Step: 11
Training loss: 0.7144941298375135
Validation loss: 2.6440982999498175

Epoch: 465| Step: 0
Training loss: 0.4362211268688372
Validation loss: 2.630256060680287

Epoch: 5| Step: 1
Training loss: 0.3909201079478496
Validation loss: 2.6449159748982676

Epoch: 5| Step: 2
Training loss: 0.3328192168440017
Validation loss: 2.725248247761296

Epoch: 5| Step: 3
Training loss: 0.5402424931002426
Validation loss: 2.653731419933535

Epoch: 5| Step: 4
Training loss: 0.3331241013083583
Validation loss: 2.7087801026820877

Epoch: 5| Step: 5
Training loss: 0.2934832569152399
Validation loss: 2.70712496259059

Epoch: 5| Step: 6
Training loss: 0.4269621335935077
Validation loss: 2.7359671180991154

Epoch: 5| Step: 7
Training loss: 0.4855362600208126
Validation loss: 2.759854005054017

Epoch: 5| Step: 8
Training loss: 0.28337852045235784
Validation loss: 2.688642076191117

Epoch: 5| Step: 9
Training loss: 0.33847200948621303
Validation loss: 2.726583274900613

Epoch: 5| Step: 10
Training loss: 0.23014532445289218
Validation loss: 2.7221295446127383

Epoch: 5| Step: 11
Training loss: 0.4016577789436622
Validation loss: 2.6698629786244585

Epoch: 466| Step: 0
Training loss: 0.4567760015591835
Validation loss: 2.684357128742549

Epoch: 5| Step: 1
Training loss: 0.3680269304676162
Validation loss: 2.671108165552187

Epoch: 5| Step: 2
Training loss: 0.33690512824997426
Validation loss: 2.686612836653071

Epoch: 5| Step: 3
Training loss: 0.21206818526685992
Validation loss: 2.6893945640037353

Epoch: 5| Step: 4
Training loss: 0.24303319389171138
Validation loss: 2.7160110104907207

Epoch: 5| Step: 5
Training loss: 0.2781119386413469
Validation loss: 2.7564590382041105

Epoch: 5| Step: 6
Training loss: 0.2631052923410767
Validation loss: 2.745034883256653

Epoch: 5| Step: 7
Training loss: 0.46319209715734416
Validation loss: 2.6993982905856417

Epoch: 5| Step: 8
Training loss: 0.32653072741051664
Validation loss: 2.699139054221841

Epoch: 5| Step: 9
Training loss: 0.3827863606462052
Validation loss: 2.770470922953061

Epoch: 5| Step: 10
Training loss: 0.21850377939608837
Validation loss: 2.679219467321092

Epoch: 5| Step: 11
Training loss: 0.24121968643445557
Validation loss: 2.7022042332476666

Epoch: 467| Step: 0
Training loss: 0.20012710153571137
Validation loss: 2.6775659554102305

Epoch: 5| Step: 1
Training loss: 0.29531286229510006
Validation loss: 2.7143689808466602

Epoch: 5| Step: 2
Training loss: 0.30030787981430984
Validation loss: 2.7796454605317256

Epoch: 5| Step: 3
Training loss: 0.2921391503216796
Validation loss: 2.735343492744125

Epoch: 5| Step: 4
Training loss: 0.3921465802977558
Validation loss: 2.671132443699975

Epoch: 5| Step: 5
Training loss: 0.31152095016395326
Validation loss: 2.7154215648322664

Epoch: 5| Step: 6
Training loss: 0.31914304454544634
Validation loss: 2.6825687425828924

Epoch: 5| Step: 7
Training loss: 0.37617431988421723
Validation loss: 2.6350738631638535

Epoch: 5| Step: 8
Training loss: 0.46378173040947707
Validation loss: 2.7235111662136973

Epoch: 5| Step: 9
Training loss: 0.4173320127069939
Validation loss: 2.6550167287477913

Epoch: 5| Step: 10
Training loss: 0.3223191072416629
Validation loss: 2.662427200820548

Epoch: 5| Step: 11
Training loss: 0.2611424092688496
Validation loss: 2.680107751039557

Epoch: 468| Step: 0
Training loss: 0.41847090102793705
Validation loss: 2.7070476059926403

Epoch: 5| Step: 1
Training loss: 0.44624351753206687
Validation loss: 2.6705560086944318

Epoch: 5| Step: 2
Training loss: 0.3216819332301505
Validation loss: 2.6510936317272202

Epoch: 5| Step: 3
Training loss: 0.313935535065541
Validation loss: 2.7585392319528044

Epoch: 5| Step: 4
Training loss: 0.36244157945205635
Validation loss: 2.690794621968158

Epoch: 5| Step: 5
Training loss: 0.3496275529451147
Validation loss: 2.720665804791176

Epoch: 5| Step: 6
Training loss: 0.34809113209345566
Validation loss: 2.6550930271026996

Epoch: 5| Step: 7
Training loss: 0.31617649590593905
Validation loss: 2.6728911373101627

Epoch: 5| Step: 8
Training loss: 0.4427531126226331
Validation loss: 2.7214321082724755

Epoch: 5| Step: 9
Training loss: 0.3103501398475262
Validation loss: 2.6473810307455836

Epoch: 5| Step: 10
Training loss: 0.25404013991641405
Validation loss: 2.727607992967291

Epoch: 5| Step: 11
Training loss: 0.40606470650720305
Validation loss: 2.7386363040092343

Epoch: 469| Step: 0
Training loss: 0.3756877830515728
Validation loss: 2.656653646579205

Epoch: 5| Step: 1
Training loss: 0.38545359185470546
Validation loss: 2.6856148968954066

Epoch: 5| Step: 2
Training loss: 0.3813802043393405
Validation loss: 2.6891505806044504

Epoch: 5| Step: 3
Training loss: 0.4903056636209712
Validation loss: 2.695096585015098

Epoch: 5| Step: 4
Training loss: 0.3249347891858654
Validation loss: 2.706757928463829

Epoch: 5| Step: 5
Training loss: 0.38091960332950375
Validation loss: 2.7542563141522516

Epoch: 5| Step: 6
Training loss: 0.3022932961724755
Validation loss: 2.7248193475354734

Epoch: 5| Step: 7
Training loss: 0.321278650178864
Validation loss: 2.7364257206962237

Epoch: 5| Step: 8
Training loss: 0.27426791117225
Validation loss: 2.761785108028954

Epoch: 5| Step: 9
Training loss: 0.3835776137242489
Validation loss: 2.7584109138880617

Epoch: 5| Step: 10
Training loss: 0.3615349461203903
Validation loss: 2.756436318885354

Epoch: 5| Step: 11
Training loss: 0.7476994676366393
Validation loss: 2.7299399239004827

Epoch: 470| Step: 0
Training loss: 0.4321060088389837
Validation loss: 2.7857610287546573

Epoch: 5| Step: 1
Training loss: 0.32910036262270836
Validation loss: 2.6594513992350737

Epoch: 5| Step: 2
Training loss: 0.3918776074312092
Validation loss: 2.7141175687067975

Epoch: 5| Step: 3
Training loss: 0.3835867817045741
Validation loss: 2.7318304483886693

Epoch: 5| Step: 4
Training loss: 0.46807334062265554
Validation loss: 2.7300305904053253

Epoch: 5| Step: 5
Training loss: 0.441694047666917
Validation loss: 2.734921905682921

Epoch: 5| Step: 6
Training loss: 0.34001376842922576
Validation loss: 2.7258013379679826

Epoch: 5| Step: 7
Training loss: 0.48119185084001015
Validation loss: 2.75511444138534

Epoch: 5| Step: 8
Training loss: 0.5330261942991653
Validation loss: 2.8060872827265593

Epoch: 5| Step: 9
Training loss: 0.33022622166304455
Validation loss: 2.7846460753473243

Epoch: 5| Step: 10
Training loss: 0.49392534172620506
Validation loss: 2.7210275420550114

Epoch: 5| Step: 11
Training loss: 0.18684689701197138
Validation loss: 2.707840674169927

Epoch: 471| Step: 0
Training loss: 0.3166842946157031
Validation loss: 2.7687312424758437

Epoch: 5| Step: 1
Training loss: 0.39545918860420204
Validation loss: 2.7031053972360364

Epoch: 5| Step: 2
Training loss: 0.19906844284432984
Validation loss: 2.7323828170198947

Epoch: 5| Step: 3
Training loss: 0.35083689513780736
Validation loss: 2.7096507970082273

Epoch: 5| Step: 4
Training loss: 0.3666723574211207
Validation loss: 2.683484404222727

Epoch: 5| Step: 5
Training loss: 0.46000007090360673
Validation loss: 2.7006833068372993

Epoch: 5| Step: 6
Training loss: 0.379478572929114
Validation loss: 2.684273860803909

Epoch: 5| Step: 7
Training loss: 0.4589545057601504
Validation loss: 2.699565962649055

Epoch: 5| Step: 8
Training loss: 0.39665646881864447
Validation loss: 2.680802119949557

Epoch: 5| Step: 9
Training loss: 0.3922187526758501
Validation loss: 2.654612294389726

Epoch: 5| Step: 10
Training loss: 0.534954812779764
Validation loss: 2.6615025702655255

Epoch: 5| Step: 11
Training loss: 0.1982837783706384
Validation loss: 2.6769870036911345

Epoch: 472| Step: 0
Training loss: 0.2936341549334047
Validation loss: 2.721852600350022

Epoch: 5| Step: 1
Training loss: 0.30800838724395985
Validation loss: 2.6388304554732778

Epoch: 5| Step: 2
Training loss: 0.43710803456991537
Validation loss: 2.6518486620832573

Epoch: 5| Step: 3
Training loss: 0.35683052463946524
Validation loss: 2.7153451945875227

Epoch: 5| Step: 4
Training loss: 0.2237992229741996
Validation loss: 2.674682878104818

Epoch: 5| Step: 5
Training loss: 0.43300972517844616
Validation loss: 2.7580081700980172

Epoch: 5| Step: 6
Training loss: 0.3903762215916761
Validation loss: 2.655700896110718

Epoch: 5| Step: 7
Training loss: 0.3816784389976326
Validation loss: 2.707538630581845

Epoch: 5| Step: 8
Training loss: 0.3522259703562763
Validation loss: 2.711816661652961

Epoch: 5| Step: 9
Training loss: 0.4514974105017196
Validation loss: 2.732442523550163

Epoch: 5| Step: 10
Training loss: 0.3131778042064554
Validation loss: 2.7047896120015174

Epoch: 5| Step: 11
Training loss: 0.23616547938352178
Validation loss: 2.716844658393705

Epoch: 473| Step: 0
Training loss: 0.37884210259849443
Validation loss: 2.674301958140846

Epoch: 5| Step: 1
Training loss: 0.3019886553588251
Validation loss: 2.6372921882888236

Epoch: 5| Step: 2
Training loss: 0.3361665698782448
Validation loss: 2.6914624862073895

Epoch: 5| Step: 3
Training loss: 0.36470182627672254
Validation loss: 2.6799214764200983

Epoch: 5| Step: 4
Training loss: 0.37341651777752427
Validation loss: 2.6651255182500977

Epoch: 5| Step: 5
Training loss: 0.34586633181075666
Validation loss: 2.6840833155380452

Epoch: 5| Step: 6
Training loss: 0.3421139690354667
Validation loss: 2.7296611262741286

Epoch: 5| Step: 7
Training loss: 0.3238159228005752
Validation loss: 2.750825369763762

Epoch: 5| Step: 8
Training loss: 0.40679268169787647
Validation loss: 2.7039405092399966

Epoch: 5| Step: 9
Training loss: 0.3167972150770213
Validation loss: 2.7034056486585274

Epoch: 5| Step: 10
Training loss: 0.3580854748922335
Validation loss: 2.63206873650303

Epoch: 5| Step: 11
Training loss: 0.31337568852623254
Validation loss: 2.691318313055274

Epoch: 474| Step: 0
Training loss: 0.38513713657703347
Validation loss: 2.684481019253108

Epoch: 5| Step: 1
Training loss: 0.3749283483717055
Validation loss: 2.7158605414150676

Epoch: 5| Step: 2
Training loss: 0.47342688419538986
Validation loss: 2.740682081833678

Epoch: 5| Step: 3
Training loss: 0.3162177784340563
Validation loss: 2.6807080615566496

Epoch: 5| Step: 4
Training loss: 0.3562765270529406
Validation loss: 2.717353659534926

Epoch: 5| Step: 5
Training loss: 0.4652671648668695
Validation loss: 2.742495786648565

Epoch: 5| Step: 6
Training loss: 0.2598959230309423
Validation loss: 2.662411977390472

Epoch: 5| Step: 7
Training loss: 0.2766715486700898
Validation loss: 2.6952580727504465

Epoch: 5| Step: 8
Training loss: 0.3651883101355586
Validation loss: 2.701635350836765

Epoch: 5| Step: 9
Training loss: 0.4821983159175468
Validation loss: 2.686413726544778

Epoch: 5| Step: 10
Training loss: 0.2792556839025525
Validation loss: 2.7186328526539767

Epoch: 5| Step: 11
Training loss: 0.4090919855855014
Validation loss: 2.701222413519575

Epoch: 475| Step: 0
Training loss: 0.49035773681895983
Validation loss: 2.7517740603349568

Epoch: 5| Step: 1
Training loss: 0.3795116150615237
Validation loss: 2.673919531274795

Epoch: 5| Step: 2
Training loss: 0.2506832977281286
Validation loss: 2.719691055221306

Epoch: 5| Step: 3
Training loss: 0.26001652811775094
Validation loss: 2.7099850105384884

Epoch: 5| Step: 4
Training loss: 0.35907108475903005
Validation loss: 2.6820247511169653

Epoch: 5| Step: 5
Training loss: 0.40191512748465197
Validation loss: 2.7375677088778674

Epoch: 5| Step: 6
Training loss: 0.28467914435040853
Validation loss: 2.66998952106915

Epoch: 5| Step: 7
Training loss: 0.3505550997886946
Validation loss: 2.618870561232635

Epoch: 5| Step: 8
Training loss: 0.43540709437871117
Validation loss: 2.7409491899309426

Epoch: 5| Step: 9
Training loss: 0.3424003831584126
Validation loss: 2.719745895709683

Epoch: 5| Step: 10
Training loss: 0.22174474626959925
Validation loss: 2.7805283910463108

Epoch: 5| Step: 11
Training loss: 0.400058515560152
Validation loss: 2.6670191961462253

Epoch: 476| Step: 0
Training loss: 0.38557113524753744
Validation loss: 2.6316432224128934

Epoch: 5| Step: 1
Training loss: 0.33656184264590816
Validation loss: 2.715959333464376

Epoch: 5| Step: 2
Training loss: 0.39882076753560747
Validation loss: 2.6334212964240957

Epoch: 5| Step: 3
Training loss: 0.32228501001489607
Validation loss: 2.641552324006554

Epoch: 5| Step: 4
Training loss: 0.3083811522574842
Validation loss: 2.6693141667019784

Epoch: 5| Step: 5
Training loss: 0.4417570627421875
Validation loss: 2.660776395581797

Epoch: 5| Step: 6
Training loss: 0.3569176248926028
Validation loss: 2.680097909978605

Epoch: 5| Step: 7
Training loss: 0.29515054187333944
Validation loss: 2.7275149440734774

Epoch: 5| Step: 8
Training loss: 0.24311948467216105
Validation loss: 2.6807591785633202

Epoch: 5| Step: 9
Training loss: 0.30846182502128283
Validation loss: 2.7034837451648634

Epoch: 5| Step: 10
Training loss: 0.4122936325000675
Validation loss: 2.6445881636940927

Epoch: 5| Step: 11
Training loss: 0.5903666622583519
Validation loss: 2.7509595143479766

Epoch: 477| Step: 0
Training loss: 0.3790474068324889
Validation loss: 2.7182786430616384

Epoch: 5| Step: 1
Training loss: 0.4115739390377339
Validation loss: 2.690660222879292

Epoch: 5| Step: 2
Training loss: 0.3643074308662142
Validation loss: 2.7107365631771514

Epoch: 5| Step: 3
Training loss: 0.31059827319243655
Validation loss: 2.6526526082607402

Epoch: 5| Step: 4
Training loss: 0.5221165743224011
Validation loss: 2.7067852633274327

Epoch: 5| Step: 5
Training loss: 0.2756816597741315
Validation loss: 2.6709129802672904

Epoch: 5| Step: 6
Training loss: 0.3074061320635139
Validation loss: 2.662291198029121

Epoch: 5| Step: 7
Training loss: 0.3445094994839477
Validation loss: 2.6552058505114897

Epoch: 5| Step: 8
Training loss: 0.35460226068211764
Validation loss: 2.7055199291012473

Epoch: 5| Step: 9
Training loss: 0.29889288057298496
Validation loss: 2.7263451301037156

Epoch: 5| Step: 10
Training loss: 0.36652852846537504
Validation loss: 2.695777079031149

Epoch: 5| Step: 11
Training loss: 0.5379223583559547
Validation loss: 2.7564014610893466

Epoch: 478| Step: 0
Training loss: 0.387945176329027
Validation loss: 2.7252697434913538

Epoch: 5| Step: 1
Training loss: 0.4252507641038079
Validation loss: 2.663042152752669

Epoch: 5| Step: 2
Training loss: 0.44538166111395444
Validation loss: 2.6833074140234765

Epoch: 5| Step: 3
Training loss: 0.3976995328419421
Validation loss: 2.665974390551751

Epoch: 5| Step: 4
Training loss: 0.4055570046988308
Validation loss: 2.714301053699373

Epoch: 5| Step: 5
Training loss: 0.3220436719028388
Validation loss: 2.6739484501234867

Epoch: 5| Step: 6
Training loss: 0.38412282471517245
Validation loss: 2.7131919574479344

Epoch: 5| Step: 7
Training loss: 0.41701457479446813
Validation loss: 2.7763563422707866

Epoch: 5| Step: 8
Training loss: 0.22605811076112567
Validation loss: 2.6405997641898105

Epoch: 5| Step: 9
Training loss: 0.2720301514263199
Validation loss: 2.7349445839695155

Epoch: 5| Step: 10
Training loss: 0.36624751607684036
Validation loss: 2.681916950804209

Epoch: 5| Step: 11
Training loss: 0.32045032280848984
Validation loss: 2.719621569777358

Epoch: 479| Step: 0
Training loss: 0.3128347273102684
Validation loss: 2.7239517275047556

Epoch: 5| Step: 1
Training loss: 0.33048994569013823
Validation loss: 2.711038157035424

Epoch: 5| Step: 2
Training loss: 0.25616124232575427
Validation loss: 2.68081649041174

Epoch: 5| Step: 3
Training loss: 0.4526422494099813
Validation loss: 2.6946113964566245

Epoch: 5| Step: 4
Training loss: 0.4478215257010605
Validation loss: 2.7089572823546466

Epoch: 5| Step: 5
Training loss: 0.28618640853380456
Validation loss: 2.667506098253167

Epoch: 5| Step: 6
Training loss: 0.30496926606216024
Validation loss: 2.7429072240703345

Epoch: 5| Step: 7
Training loss: 0.37457070016756366
Validation loss: 2.6950374333914238

Epoch: 5| Step: 8
Training loss: 0.3345781925518274
Validation loss: 2.6866438485194943

Epoch: 5| Step: 9
Training loss: 0.4002778801699868
Validation loss: 2.6960960981398774

Epoch: 5| Step: 10
Training loss: 0.37103198691922806
Validation loss: 2.723554680981226

Epoch: 5| Step: 11
Training loss: 0.18633022587069642
Validation loss: 2.7800575014383626

Epoch: 480| Step: 0
Training loss: 0.3415033115188704
Validation loss: 2.683064726501976

Epoch: 5| Step: 1
Training loss: 0.35390909964317346
Validation loss: 2.6872247713936877

Epoch: 5| Step: 2
Training loss: 0.32755244346587126
Validation loss: 2.6535852510813736

Epoch: 5| Step: 3
Training loss: 0.31681454770315765
Validation loss: 2.720047938719727

Epoch: 5| Step: 4
Training loss: 0.42857355162685057
Validation loss: 2.6885160144664515

Epoch: 5| Step: 5
Training loss: 0.29568073082083485
Validation loss: 2.6295252085982086

Epoch: 5| Step: 6
Training loss: 0.35725254988377675
Validation loss: 2.684896856999071

Epoch: 5| Step: 7
Training loss: 0.3702259960623026
Validation loss: 2.689524446242171

Epoch: 5| Step: 8
Training loss: 0.33239672125244774
Validation loss: 2.629348543851754

Epoch: 5| Step: 9
Training loss: 0.3991946711435871
Validation loss: 2.731297885088009

Epoch: 5| Step: 10
Training loss: 0.33664749214638245
Validation loss: 2.625846052821991

Epoch: 5| Step: 11
Training loss: 0.1337442531866265
Validation loss: 2.7062972460374923

Epoch: 481| Step: 0
Training loss: 0.3999472605686674
Validation loss: 2.6948305261142647

Epoch: 5| Step: 1
Training loss: 0.43748128374119954
Validation loss: 2.7230089343217787

Epoch: 5| Step: 2
Training loss: 0.41119857225935574
Validation loss: 2.778223469794513

Epoch: 5| Step: 3
Training loss: 0.3364472846036836
Validation loss: 2.658733084322491

Epoch: 5| Step: 4
Training loss: 0.31058187707341756
Validation loss: 2.7186824563650513

Epoch: 5| Step: 5
Training loss: 0.40747980892733376
Validation loss: 2.681177197870711

Epoch: 5| Step: 6
Training loss: 0.3315195965850614
Validation loss: 2.6788703258201227

Epoch: 5| Step: 7
Training loss: 0.2873502745725117
Validation loss: 2.6886867113584807

Epoch: 5| Step: 8
Training loss: 0.31167965741844045
Validation loss: 2.6901002325648995

Epoch: 5| Step: 9
Training loss: 0.3669073375246842
Validation loss: 2.681197472260092

Epoch: 5| Step: 10
Training loss: 0.40721606051215753
Validation loss: 2.715784670017372

Epoch: 5| Step: 11
Training loss: 0.203054947877909
Validation loss: 2.705199691299385

Epoch: 482| Step: 0
Training loss: 0.23595870124851756
Validation loss: 2.7364920495120657

Epoch: 5| Step: 1
Training loss: 0.4940431822945804
Validation loss: 2.6789694362459446

Epoch: 5| Step: 2
Training loss: 0.44287402100526174
Validation loss: 2.6805660968753333

Epoch: 5| Step: 3
Training loss: 0.35244819547900447
Validation loss: 2.6806047684319676

Epoch: 5| Step: 4
Training loss: 0.32776294897412495
Validation loss: 2.726444336554116

Epoch: 5| Step: 5
Training loss: 0.24027131734752027
Validation loss: 2.6977169755850317

Epoch: 5| Step: 6
Training loss: 0.32080884020479333
Validation loss: 2.726020638911118

Epoch: 5| Step: 7
Training loss: 0.3900611431842097
Validation loss: 2.734999016901661

Epoch: 5| Step: 8
Training loss: 0.2810569736581251
Validation loss: 2.7190710367830797

Epoch: 5| Step: 9
Training loss: 0.3305822055934604
Validation loss: 2.7418698020852745

Epoch: 5| Step: 10
Training loss: 0.3989767838072076
Validation loss: 2.681590925118698

Epoch: 5| Step: 11
Training loss: 0.19942359116941202
Validation loss: 2.699147651792254

Epoch: 483| Step: 0
Training loss: 0.38962705931182023
Validation loss: 2.6805461327206546

Epoch: 5| Step: 1
Training loss: 0.35820070471824744
Validation loss: 2.6398297415906655

Epoch: 5| Step: 2
Training loss: 0.4117737257444375
Validation loss: 2.7185817206032366

Epoch: 5| Step: 3
Training loss: 0.2757650089614751
Validation loss: 2.709923945910488

Epoch: 5| Step: 4
Training loss: 0.3387524193328949
Validation loss: 2.7079733878367747

Epoch: 5| Step: 5
Training loss: 0.25238777343522073
Validation loss: 2.6719231145739104

Epoch: 5| Step: 6
Training loss: 0.3372812454038429
Validation loss: 2.730632960775839

Epoch: 5| Step: 7
Training loss: 0.4062929680915942
Validation loss: 2.7695522119242644

Epoch: 5| Step: 8
Training loss: 0.4351729425759144
Validation loss: 2.7231924239642757

Epoch: 5| Step: 9
Training loss: 0.26051048813974653
Validation loss: 2.6237434187635875

Epoch: 5| Step: 10
Training loss: 0.3627964805135279
Validation loss: 2.6727794729947334

Epoch: 5| Step: 11
Training loss: 0.48411159121153186
Validation loss: 2.698942955196085

Epoch: 484| Step: 0
Training loss: 0.2803253497917696
Validation loss: 2.7179520557779395

Epoch: 5| Step: 1
Training loss: 0.2827506693276427
Validation loss: 2.743621487457276

Epoch: 5| Step: 2
Training loss: 0.33130422544194155
Validation loss: 2.6915364300858853

Epoch: 5| Step: 3
Training loss: 0.3302568143860609
Validation loss: 2.6768366716104905

Epoch: 5| Step: 4
Training loss: 0.3657561670084587
Validation loss: 2.6085888102727344

Epoch: 5| Step: 5
Training loss: 0.32594510721489267
Validation loss: 2.660724939475548

Epoch: 5| Step: 6
Training loss: 0.27852216394567747
Validation loss: 2.6889503616692063

Epoch: 5| Step: 7
Training loss: 0.3720585778656206
Validation loss: 2.692219154199862

Epoch: 5| Step: 8
Training loss: 0.33082119970307416
Validation loss: 2.66071244305577

Epoch: 5| Step: 9
Training loss: 0.33897510316313906
Validation loss: 2.6128610502167917

Epoch: 5| Step: 10
Training loss: 0.2395996376723247
Validation loss: 2.674899573684047

Epoch: 5| Step: 11
Training loss: 0.6676895271862536
Validation loss: 2.700758813484004

Epoch: 485| Step: 0
Training loss: 0.29662455485359157
Validation loss: 2.7010320248905564

Epoch: 5| Step: 1
Training loss: 0.35567954384273015
Validation loss: 2.7328620866886477

Epoch: 5| Step: 2
Training loss: 0.4262156239404803
Validation loss: 2.6995994310467735

Epoch: 5| Step: 3
Training loss: 0.3199562673748342
Validation loss: 2.6634713465110917

Epoch: 5| Step: 4
Training loss: 0.23164270731358308
Validation loss: 2.742053221542217

Epoch: 5| Step: 5
Training loss: 0.4899727476579636
Validation loss: 2.6849798910239233

Epoch: 5| Step: 6
Training loss: 0.2817460030963575
Validation loss: 2.653177488936344

Epoch: 5| Step: 7
Training loss: 0.3995302772733911
Validation loss: 2.673333522841414

Epoch: 5| Step: 8
Training loss: 0.2911526658149853
Validation loss: 2.710917631254208

Epoch: 5| Step: 9
Training loss: 0.4070283146494276
Validation loss: 2.6285433695906733

Epoch: 5| Step: 10
Training loss: 0.2829463583998547
Validation loss: 2.681833425593879

Epoch: 5| Step: 11
Training loss: 0.37787795390426654
Validation loss: 2.6934898110669026

Epoch: 486| Step: 0
Training loss: 0.38185900059974365
Validation loss: 2.741461220225748

Epoch: 5| Step: 1
Training loss: 0.4044394495101629
Validation loss: 2.7353496340411523

Epoch: 5| Step: 2
Training loss: 0.2475553884806598
Validation loss: 2.6434338714307737

Epoch: 5| Step: 3
Training loss: 0.35292127606618107
Validation loss: 2.6957473293561143

Epoch: 5| Step: 4
Training loss: 0.3825377821494301
Validation loss: 2.723746721254931

Epoch: 5| Step: 5
Training loss: 0.34945521871927554
Validation loss: 2.6700562762105324

Epoch: 5| Step: 6
Training loss: 0.28530739997993515
Validation loss: 2.6635082391713265

Epoch: 5| Step: 7
Training loss: 0.3541526534543234
Validation loss: 2.721898331452736

Epoch: 5| Step: 8
Training loss: 0.2555094794373694
Validation loss: 2.685456526652579

Epoch: 5| Step: 9
Training loss: 0.3676449178885785
Validation loss: 2.728108154687658

Epoch: 5| Step: 10
Training loss: 0.25887274198961047
Validation loss: 2.6063436500501087

Epoch: 5| Step: 11
Training loss: 0.45795267907912623
Validation loss: 2.7000251702618923

Epoch: 487| Step: 0
Training loss: 0.2967469541574946
Validation loss: 2.61172184892144

Epoch: 5| Step: 1
Training loss: 0.39812266308684
Validation loss: 2.6219296702405295

Epoch: 5| Step: 2
Training loss: 0.27255233817608304
Validation loss: 2.6975604869152434

Epoch: 5| Step: 3
Training loss: 0.40518694954404755
Validation loss: 2.70764932186633

Epoch: 5| Step: 4
Training loss: 0.30068410815758356
Validation loss: 2.7056242720850507

Epoch: 5| Step: 5
Training loss: 0.4095870109650417
Validation loss: 2.676534816690084

Epoch: 5| Step: 6
Training loss: 0.39189391983330546
Validation loss: 2.696517192285914

Epoch: 5| Step: 7
Training loss: 0.24171988658970703
Validation loss: 2.7251633093541465

Epoch: 5| Step: 8
Training loss: 0.31195461843177547
Validation loss: 2.695226876193417

Epoch: 5| Step: 9
Training loss: 0.2733977288886789
Validation loss: 2.6981596720675896

Epoch: 5| Step: 10
Training loss: 0.2451724639816459
Validation loss: 2.6991183698863033

Epoch: 5| Step: 11
Training loss: 0.1800170136894737
Validation loss: 2.6728147746462647

Epoch: 488| Step: 0
Training loss: 0.22374251227929862
Validation loss: 2.661045510262822

Epoch: 5| Step: 1
Training loss: 0.3115881132236356
Validation loss: 2.6664766837533103

Epoch: 5| Step: 2
Training loss: 0.3871100401656117
Validation loss: 2.6990272189033155

Epoch: 5| Step: 3
Training loss: 0.2852004813810168
Validation loss: 2.6546908271743255

Epoch: 5| Step: 4
Training loss: 0.39070696924397336
Validation loss: 2.6543598219046323

Epoch: 5| Step: 5
Training loss: 0.34241968360041264
Validation loss: 2.6779568369002993

Epoch: 5| Step: 6
Training loss: 0.28622014662560863
Validation loss: 2.652863119715435

Epoch: 5| Step: 7
Training loss: 0.30958741197984113
Validation loss: 2.707686608688583

Epoch: 5| Step: 8
Training loss: 0.3279243718728066
Validation loss: 2.7284211870806185

Epoch: 5| Step: 9
Training loss: 0.3643066332624962
Validation loss: 2.7211964039802576

Epoch: 5| Step: 10
Training loss: 0.3757102320255293
Validation loss: 2.705810262341639

Epoch: 5| Step: 11
Training loss: 0.33249540983703
Validation loss: 2.696989619418846

Epoch: 489| Step: 0
Training loss: 0.30654752739478586
Validation loss: 2.714042098796435

Epoch: 5| Step: 1
Training loss: 0.33221636828840045
Validation loss: 2.657821257866677

Epoch: 5| Step: 2
Training loss: 0.27735453571247365
Validation loss: 2.700047175854753

Epoch: 5| Step: 3
Training loss: 0.3950475204227732
Validation loss: 2.665031648362059

Epoch: 5| Step: 4
Training loss: 0.32548785869160074
Validation loss: 2.661440990463656

Epoch: 5| Step: 5
Training loss: 0.255700637264487
Validation loss: 2.6312925968059693

Epoch: 5| Step: 6
Training loss: 0.27484112561020935
Validation loss: 2.6340341912430176

Epoch: 5| Step: 7
Training loss: 0.39011853764152254
Validation loss: 2.706572273100799

Epoch: 5| Step: 8
Training loss: 0.34830864760470653
Validation loss: 2.696628722788189

Epoch: 5| Step: 9
Training loss: 0.19540562317035576
Validation loss: 2.6657642586016776

Epoch: 5| Step: 10
Training loss: 0.2896907140189331
Validation loss: 2.6962780167573195

Epoch: 5| Step: 11
Training loss: 0.12760225281610119
Validation loss: 2.6736653001806596

Epoch: 490| Step: 0
Training loss: 0.35552286427846663
Validation loss: 2.7136699599813947

Epoch: 5| Step: 1
Training loss: 0.27051300429447045
Validation loss: 2.7536915832975035

Epoch: 5| Step: 2
Training loss: 0.36462770146653073
Validation loss: 2.6053018854898164

Epoch: 5| Step: 3
Training loss: 0.4041550613323309
Validation loss: 2.6505364715470647

Epoch: 5| Step: 4
Training loss: 0.2504136567376555
Validation loss: 2.6732095523478283

Epoch: 5| Step: 5
Training loss: 0.1871799180719492
Validation loss: 2.7210588078934563

Epoch: 5| Step: 6
Training loss: 0.20250420891249513
Validation loss: 2.674899436272538

Epoch: 5| Step: 7
Training loss: 0.5107411080051779
Validation loss: 2.691965285931157

Epoch: 5| Step: 8
Training loss: 0.4294585745210502
Validation loss: 2.761417365276899

Epoch: 5| Step: 9
Training loss: 0.3531387385506198
Validation loss: 2.6927313493129903

Epoch: 5| Step: 10
Training loss: 0.2864007183858117
Validation loss: 2.6289583062151958

Epoch: 5| Step: 11
Training loss: 0.2997257364799366
Validation loss: 2.6838842842716453

Epoch: 491| Step: 0
Training loss: 0.22100712086621482
Validation loss: 2.7150572073104002

Epoch: 5| Step: 1
Training loss: 0.3082695839787339
Validation loss: 2.7060374114045955

Epoch: 5| Step: 2
Training loss: 0.5607105507956214
Validation loss: 2.631336009446404

Epoch: 5| Step: 3
Training loss: 0.3533635734529656
Validation loss: 2.6955614868743325

Epoch: 5| Step: 4
Training loss: 0.3184462586715432
Validation loss: 2.7267653308760478

Epoch: 5| Step: 5
Training loss: 0.3167207591177059
Validation loss: 2.6521266273466813

Epoch: 5| Step: 6
Training loss: 0.3236485833680531
Validation loss: 2.655243022632737

Epoch: 5| Step: 7
Training loss: 0.17335134656107784
Validation loss: 2.648076406973436

Epoch: 5| Step: 8
Training loss: 0.2612720064312738
Validation loss: 2.68875941257316

Epoch: 5| Step: 9
Training loss: 0.2981601554807534
Validation loss: 2.7545949881791834

Epoch: 5| Step: 10
Training loss: 0.295105516971704
Validation loss: 2.7246105016343716

Epoch: 5| Step: 11
Training loss: 0.30826358999798464
Validation loss: 2.73515002574937

Epoch: 492| Step: 0
Training loss: 0.3343513881510776
Validation loss: 2.6950453989856062

Epoch: 5| Step: 1
Training loss: 0.2738406615169619
Validation loss: 2.6751331203380166

Epoch: 5| Step: 2
Training loss: 0.25284286245968934
Validation loss: 2.6524849518394924

Epoch: 5| Step: 3
Training loss: 0.3031899131996559
Validation loss: 2.63376125669435

Epoch: 5| Step: 4
Training loss: 0.41898817007667394
Validation loss: 2.5988149711703743

Epoch: 5| Step: 5
Training loss: 0.2880261892656571
Validation loss: 2.6417454443556236

Epoch: 5| Step: 6
Training loss: 0.2261439683395954
Validation loss: 2.6464168338204

Epoch: 5| Step: 7
Training loss: 0.2809842894335039
Validation loss: 2.722063241720294

Epoch: 5| Step: 8
Training loss: 0.3846387702453055
Validation loss: 2.709542926246729

Epoch: 5| Step: 9
Training loss: 0.386011382224216
Validation loss: 2.6906767596126246

Epoch: 5| Step: 10
Training loss: 0.4498450847048103
Validation loss: 2.7061456770314227

Epoch: 5| Step: 11
Training loss: 0.30191812300052245
Validation loss: 2.697917475510013

Epoch: 493| Step: 0
Training loss: 0.41283802502227096
Validation loss: 2.7151712416756926

Epoch: 5| Step: 1
Training loss: 0.3866270322601354
Validation loss: 2.669525597052524

Epoch: 5| Step: 2
Training loss: 0.4075796302853895
Validation loss: 2.6734404114455232

Epoch: 5| Step: 3
Training loss: 0.3039050325305549
Validation loss: 2.7336264503037095

Epoch: 5| Step: 4
Training loss: 0.33731085589963994
Validation loss: 2.674547517095619

Epoch: 5| Step: 5
Training loss: 0.4722651132181706
Validation loss: 2.744318810376182

Epoch: 5| Step: 6
Training loss: 0.34127369758221066
Validation loss: 2.6469065011652178

Epoch: 5| Step: 7
Training loss: 0.5504094756169471
Validation loss: 2.7646542082734977

Epoch: 5| Step: 8
Training loss: 0.39368779130008313
Validation loss: 2.78319465859001

Epoch: 5| Step: 9
Training loss: 0.3862066635338281
Validation loss: 2.753921166057187

Epoch: 5| Step: 10
Training loss: 0.3494479696540399
Validation loss: 2.8177903258028065

Epoch: 5| Step: 11
Training loss: 0.20651762606209864
Validation loss: 2.7168293120739784

Epoch: 494| Step: 0
Training loss: 0.3785294694602759
Validation loss: 2.7121757222662057

Epoch: 5| Step: 1
Training loss: 0.3152739314487914
Validation loss: 2.7286873401373937

Epoch: 5| Step: 2
Training loss: 0.45591348099796897
Validation loss: 2.6918284394649974

Epoch: 5| Step: 3
Training loss: 0.3824718867361182
Validation loss: 2.6944966210123313

Epoch: 5| Step: 4
Training loss: 0.28816984861940004
Validation loss: 2.768473349155144

Epoch: 5| Step: 5
Training loss: 0.4099814269464597
Validation loss: 2.6776736841760016

Epoch: 5| Step: 6
Training loss: 0.2305551140818014
Validation loss: 2.6712313205742433

Epoch: 5| Step: 7
Training loss: 0.33047729823823113
Validation loss: 2.7271773656997236

Epoch: 5| Step: 8
Training loss: 0.3631184941429595
Validation loss: 2.6830412968374295

Epoch: 5| Step: 9
Training loss: 0.3195210075135851
Validation loss: 2.7151913244289885

Epoch: 5| Step: 10
Training loss: 0.35217367664683463
Validation loss: 2.629941735432085

Epoch: 5| Step: 11
Training loss: 0.1517847884073789
Validation loss: 2.668634487067277

Epoch: 495| Step: 0
Training loss: 0.3187740877811117
Validation loss: 2.7114339698188354

Epoch: 5| Step: 1
Training loss: 0.3327090021846086
Validation loss: 2.735591436198656

Epoch: 5| Step: 2
Training loss: 0.30283922410164704
Validation loss: 2.725364873821952

Epoch: 5| Step: 3
Training loss: 0.2403874723558111
Validation loss: 2.682887010644943

Epoch: 5| Step: 4
Training loss: 0.3100386365339908
Validation loss: 2.7373534320833035

Epoch: 5| Step: 5
Training loss: 0.3013851741385073
Validation loss: 2.7349427060757727

Epoch: 5| Step: 6
Training loss: 0.30859180642976636
Validation loss: 2.692078615755302

Epoch: 5| Step: 7
Training loss: 0.2726441727726108
Validation loss: 2.6873188401309864

Epoch: 5| Step: 8
Training loss: 0.4165182524845535
Validation loss: 2.7690637836941945

Epoch: 5| Step: 9
Training loss: 0.42588551145949616
Validation loss: 2.7074199175475564

Epoch: 5| Step: 10
Training loss: 0.44085520554253643
Validation loss: 2.6907416059604157

Epoch: 5| Step: 11
Training loss: 0.3208683355030896
Validation loss: 2.699923988585108

Epoch: 496| Step: 0
Training loss: 0.2751799244094607
Validation loss: 2.748475446903546

Epoch: 5| Step: 1
Training loss: 0.2619985820990335
Validation loss: 2.71963851850122

Epoch: 5| Step: 2
Training loss: 0.4033259098135643
Validation loss: 2.7302341605988762

Epoch: 5| Step: 3
Training loss: 0.285930405721573
Validation loss: 2.674486883957725

Epoch: 5| Step: 4
Training loss: 0.2888381061268761
Validation loss: 2.735814756366576

Epoch: 5| Step: 5
Training loss: 0.3672725700690644
Validation loss: 2.697796750195942

Epoch: 5| Step: 6
Training loss: 0.43137872958388007
Validation loss: 2.7134521101062155

Epoch: 5| Step: 7
Training loss: 0.2786705356712229
Validation loss: 2.7561748926910727

Epoch: 5| Step: 8
Training loss: 0.27001437135701956
Validation loss: 2.749333355036053

Epoch: 5| Step: 9
Training loss: 0.30225323004609794
Validation loss: 2.691171699568438

Epoch: 5| Step: 10
Training loss: 0.3315791698799048
Validation loss: 2.7068793183994484

Epoch: 5| Step: 11
Training loss: 0.3875813737151407
Validation loss: 2.700208249788293

Epoch: 497| Step: 0
Training loss: 0.29398282340859566
Validation loss: 2.710170149875191

Epoch: 5| Step: 1
Training loss: 0.3092416649375922
Validation loss: 2.757554385287883

Epoch: 5| Step: 2
Training loss: 0.40355437278273726
Validation loss: 2.6963495627448633

Epoch: 5| Step: 3
Training loss: 0.41620359517230704
Validation loss: 2.7556822080233534

Epoch: 5| Step: 4
Training loss: 0.33095661612423016
Validation loss: 2.657017630564895

Epoch: 5| Step: 5
Training loss: 0.3434063320578115
Validation loss: 2.67724402696204

Epoch: 5| Step: 6
Training loss: 0.3352708856120411
Validation loss: 2.700631364101123

Epoch: 5| Step: 7
Training loss: 0.3705300718065003
Validation loss: 2.7313677754385686

Epoch: 5| Step: 8
Training loss: 0.34548946825736093
Validation loss: 2.6883910424537554

Epoch: 5| Step: 9
Training loss: 0.2589105572799768
Validation loss: 2.674118713534616

Epoch: 5| Step: 10
Training loss: 0.2939963945886222
Validation loss: 2.6812477425993313

Epoch: 5| Step: 11
Training loss: 0.12220502667934376
Validation loss: 2.70428300870795

Epoch: 498| Step: 0
Training loss: 0.2576620501020991
Validation loss: 2.670576572028228

Epoch: 5| Step: 1
Training loss: 0.28449242546409953
Validation loss: 2.6889267579269984

Epoch: 5| Step: 2
Training loss: 0.36680410538474645
Validation loss: 2.653087008069072

Epoch: 5| Step: 3
Training loss: 0.2754097384049338
Validation loss: 2.7093011111223566

Epoch: 5| Step: 4
Training loss: 0.34035131763776494
Validation loss: 2.725353650671558

Epoch: 5| Step: 5
Training loss: 0.430816657956788
Validation loss: 2.645585759412072

Epoch: 5| Step: 6
Training loss: 0.28734521845763344
Validation loss: 2.66485215954333

Epoch: 5| Step: 7
Training loss: 0.2919649347453905
Validation loss: 2.6762015613577392

Epoch: 5| Step: 8
Training loss: 0.32873544221997913
Validation loss: 2.725407637282916

Epoch: 5| Step: 9
Training loss: 0.2598358575628167
Validation loss: 2.736080398981568

Epoch: 5| Step: 10
Training loss: 0.31547980604216336
Validation loss: 2.6955958894660914

Epoch: 5| Step: 11
Training loss: 0.21488541285819499
Validation loss: 2.682488263280197

Epoch: 499| Step: 0
Training loss: 0.3370093390602673
Validation loss: 2.7253961263525186

Epoch: 5| Step: 1
Training loss: 0.3897187019037947
Validation loss: 2.6836697097089512

Epoch: 5| Step: 2
Training loss: 0.22710246656609867
Validation loss: 2.702520431502488

Epoch: 5| Step: 3
Training loss: 0.34755180161461524
Validation loss: 2.720358723396176

Epoch: 5| Step: 4
Training loss: 0.33432061296746846
Validation loss: 2.7068936238205668

Epoch: 5| Step: 5
Training loss: 0.26997728344933386
Validation loss: 2.720271134431767

Epoch: 5| Step: 6
Training loss: 0.3415123654573141
Validation loss: 2.731321966472875

Epoch: 5| Step: 7
Training loss: 0.3735522895822985
Validation loss: 2.666486815382844

Epoch: 5| Step: 8
Training loss: 0.3942730124584266
Validation loss: 2.7121482549275386

Epoch: 5| Step: 9
Training loss: 0.3131494092469153
Validation loss: 2.690205934316134

Epoch: 5| Step: 10
Training loss: 0.3723030463800791
Validation loss: 2.690852945753846

Epoch: 5| Step: 11
Training loss: 0.14054335767364062
Validation loss: 2.706462560004424

Epoch: 500| Step: 0
Training loss: 0.39164638500593124
Validation loss: 2.6521622188809455

Epoch: 5| Step: 1
Training loss: 0.3897420440899294
Validation loss: 2.6527322963046798

Epoch: 5| Step: 2
Training loss: 0.3953764520715563
Validation loss: 2.7191665483775354

Epoch: 5| Step: 3
Training loss: 0.42643697799165375
Validation loss: 2.6680739583560062

Epoch: 5| Step: 4
Training loss: 0.4796920639467107
Validation loss: 2.684257447463252

Epoch: 5| Step: 5
Training loss: 0.4853271539641
Validation loss: 2.671507042278613

Epoch: 5| Step: 6
Training loss: 0.3594662509006587
Validation loss: 2.6250339990260865

Epoch: 5| Step: 7
Training loss: 0.33416712930739256
Validation loss: 2.6753162026317514

Epoch: 5| Step: 8
Training loss: 0.41425639237264317
Validation loss: 2.708843547494869

Epoch: 5| Step: 9
Training loss: 0.31267938233779485
Validation loss: 2.717889565570491

Epoch: 5| Step: 10
Training loss: 0.32007474914737005
Validation loss: 2.7441700527654107

Epoch: 5| Step: 11
Training loss: 0.6301605558543861
Validation loss: 2.7231836925488526

Epoch: 501| Step: 0
Training loss: 0.28561935965981045
Validation loss: 2.7263280918970954

Epoch: 5| Step: 1
Training loss: 0.3479930874655928
Validation loss: 2.7239073912097855

Epoch: 5| Step: 2
Training loss: 0.5006360240679741
Validation loss: 2.6915024664981697

Epoch: 5| Step: 3
Training loss: 0.4789220524182999
Validation loss: 2.6930858610573973

Epoch: 5| Step: 4
Training loss: 0.3378859723603197
Validation loss: 2.6597281142740306

Epoch: 5| Step: 5
Training loss: 0.5048538288230816
Validation loss: 2.6964052832237484

Epoch: 5| Step: 6
Training loss: 0.23045916456558746
Validation loss: 2.69727190087408

Epoch: 5| Step: 7
Training loss: 0.2785913051598505
Validation loss: 2.6496749882553186

Epoch: 5| Step: 8
Training loss: 0.44698584855697154
Validation loss: 2.6818038990745445

Epoch: 5| Step: 9
Training loss: 0.4011158028318229
Validation loss: 2.715496491558403

Epoch: 5| Step: 10
Training loss: 0.4829822636876218
Validation loss: 2.697801318090048

Epoch: 5| Step: 11
Training loss: 0.4545602266393004
Validation loss: 2.7184907398622777

Epoch: 502| Step: 0
Training loss: 0.4714784370560444
Validation loss: 2.631301366979687

Epoch: 5| Step: 1
Training loss: 0.24476946905960859
Validation loss: 2.6417581132249364

Epoch: 5| Step: 2
Training loss: 0.49278816022738464
Validation loss: 2.6805270059796875

Epoch: 5| Step: 3
Training loss: 0.46762675173507073
Validation loss: 2.629201637212829

Epoch: 5| Step: 4
Training loss: 0.28375054430804375
Validation loss: 2.68753167806482

Epoch: 5| Step: 5
Training loss: 0.3559818128376322
Validation loss: 2.6746674272987634

Epoch: 5| Step: 6
Training loss: 0.33013099608127106
Validation loss: 2.688436659149484

Epoch: 5| Step: 7
Training loss: 0.47332094287381715
Validation loss: 2.6964269683620197

Epoch: 5| Step: 8
Training loss: 0.32339289629488294
Validation loss: 2.6890869445399033

Epoch: 5| Step: 9
Training loss: 0.3538972680844693
Validation loss: 2.6706823769537573

Epoch: 5| Step: 10
Training loss: 0.4534949568212554
Validation loss: 2.743000743146641

Epoch: 5| Step: 11
Training loss: 0.2723123151898058
Validation loss: 2.6556498055134874

Epoch: 503| Step: 0
Training loss: 0.31456201456897676
Validation loss: 2.6974334517263934

Epoch: 5| Step: 1
Training loss: 0.3499086473659989
Validation loss: 2.6995375500640626

Epoch: 5| Step: 2
Training loss: 0.25360359346719896
Validation loss: 2.738258445162279

Epoch: 5| Step: 3
Training loss: 0.512378034965645
Validation loss: 2.6676867993722118

Epoch: 5| Step: 4
Training loss: 0.45389008879000375
Validation loss: 2.6474142507847693

Epoch: 5| Step: 5
Training loss: 0.3474911286916348
Validation loss: 2.726000329825292

Epoch: 5| Step: 6
Training loss: 0.2826129815474747
Validation loss: 2.7396862943807707

Epoch: 5| Step: 7
Training loss: 0.3187999835747843
Validation loss: 2.7154518781935693

Epoch: 5| Step: 8
Training loss: 0.397506430082076
Validation loss: 2.7159601344959623

Epoch: 5| Step: 9
Training loss: 0.4017058009193876
Validation loss: 2.7084500263212443

Epoch: 5| Step: 10
Training loss: 0.2860827743991696
Validation loss: 2.6953735860637984

Epoch: 5| Step: 11
Training loss: 0.06564655233879438
Validation loss: 2.7095544421983417

Epoch: 504| Step: 0
Training loss: 0.3360157587139375
Validation loss: 2.6732648762914186

Epoch: 5| Step: 1
Training loss: 0.36874525907669303
Validation loss: 2.7219159265909263

Epoch: 5| Step: 2
Training loss: 0.4433305537733026
Validation loss: 2.698331544463955

Epoch: 5| Step: 3
Training loss: 0.30713448572473245
Validation loss: 2.7432412045800563

Epoch: 5| Step: 4
Training loss: 0.3611785785400333
Validation loss: 2.6966902892449838

Epoch: 5| Step: 5
Training loss: 0.4070960185528833
Validation loss: 2.676468538623293

Epoch: 5| Step: 6
Training loss: 0.2572296808585287
Validation loss: 2.695819670648951

Epoch: 5| Step: 7
Training loss: 0.3332258165331606
Validation loss: 2.7090515260411436

Epoch: 5| Step: 8
Training loss: 0.37849045582206126
Validation loss: 2.7021259931453185

Epoch: 5| Step: 9
Training loss: 0.28229005884695657
Validation loss: 2.726503391590687

Epoch: 5| Step: 10
Training loss: 0.30110482979913505
Validation loss: 2.715121076218864

Epoch: 5| Step: 11
Training loss: 0.11768170891865322
Validation loss: 2.703888798080273

Epoch: 505| Step: 0
Training loss: 0.3066564179259365
Validation loss: 2.7203454893720362

Epoch: 5| Step: 1
Training loss: 0.30404348045370266
Validation loss: 2.717557312987735

Epoch: 5| Step: 2
Training loss: 0.37126418767335945
Validation loss: 2.7110064348439717

Epoch: 5| Step: 3
Training loss: 0.4390318822536441
Validation loss: 2.699672644250079

Epoch: 5| Step: 4
Training loss: 0.3370059786373778
Validation loss: 2.7055910581282507

Epoch: 5| Step: 5
Training loss: 0.27527882626605743
Validation loss: 2.721672657607478

Epoch: 5| Step: 6
Training loss: 0.3039409343079112
Validation loss: 2.6399960003868306

Epoch: 5| Step: 7
Training loss: 0.48256608606791357
Validation loss: 2.661901184583802

Epoch: 5| Step: 8
Training loss: 0.2650154918514907
Validation loss: 2.705223187942076

Epoch: 5| Step: 9
Training loss: 0.44507708098905313
Validation loss: 2.7127244027362987

Epoch: 5| Step: 10
Training loss: 0.25368705971927036
Validation loss: 2.734810618260345

Epoch: 5| Step: 11
Training loss: 0.3306761070802239
Validation loss: 2.662831757700459

Epoch: 506| Step: 0
Training loss: 0.41068134301620585
Validation loss: 2.67942929298225

Epoch: 5| Step: 1
Training loss: 0.4365619241359793
Validation loss: 2.7331959425794716

Epoch: 5| Step: 2
Training loss: 0.25687698210348314
Validation loss: 2.6577914571106604

Epoch: 5| Step: 3
Training loss: 0.34103133437425576
Validation loss: 2.705241060456818

Epoch: 5| Step: 4
Training loss: 0.3684085064805225
Validation loss: 2.7476558303145744

Epoch: 5| Step: 5
Training loss: 0.2736044510295969
Validation loss: 2.681513043077841

Epoch: 5| Step: 6
Training loss: 0.3905411248757686
Validation loss: 2.7169479850979807

Epoch: 5| Step: 7
Training loss: 0.2591134683147318
Validation loss: 2.7399938418442145

Epoch: 5| Step: 8
Training loss: 0.3554536585695848
Validation loss: 2.7038122159854376

Epoch: 5| Step: 9
Training loss: 0.3134480638711061
Validation loss: 2.6593399587938227

Epoch: 5| Step: 10
Training loss: 0.25336555718082115
Validation loss: 2.7019112348101206

Epoch: 5| Step: 11
Training loss: 0.09483205191319007
Validation loss: 2.705045748997738

Epoch: 507| Step: 0
Training loss: 0.3222773000740876
Validation loss: 2.7468787310809653

Epoch: 5| Step: 1
Training loss: 0.36143828078978346
Validation loss: 2.687673651829251

Epoch: 5| Step: 2
Training loss: 0.2890541616732127
Validation loss: 2.6742107265306356

Epoch: 5| Step: 3
Training loss: 0.21054025614849986
Validation loss: 2.7034446255387854

Epoch: 5| Step: 4
Training loss: 0.3352392169546712
Validation loss: 2.6822180074312145

Epoch: 5| Step: 5
Training loss: 0.2863793986834784
Validation loss: 2.6954476364093396

Epoch: 5| Step: 6
Training loss: 0.3403478150832935
Validation loss: 2.6919280618126606

Epoch: 5| Step: 7
Training loss: 0.3879431021574567
Validation loss: 2.677223644710941

Epoch: 5| Step: 8
Training loss: 0.32400015850269304
Validation loss: 2.6970714524061097

Epoch: 5| Step: 9
Training loss: 0.41290737468197053
Validation loss: 2.6851402483498386

Epoch: 5| Step: 10
Training loss: 0.21247965841544691
Validation loss: 2.718696622945704

Epoch: 5| Step: 11
Training loss: 0.3473895475094365
Validation loss: 2.7691403836374726

Epoch: 508| Step: 0
Training loss: 0.3752676088419115
Validation loss: 2.7827213892157174

Epoch: 5| Step: 1
Training loss: 0.274508924819478
Validation loss: 2.725960152155209

Epoch: 5| Step: 2
Training loss: 0.24913095883134975
Validation loss: 2.6507838235608947

Epoch: 5| Step: 3
Training loss: 0.33224880720388
Validation loss: 2.7104356797822287

Epoch: 5| Step: 4
Training loss: 0.3816956752715489
Validation loss: 2.7301547043147076

Epoch: 5| Step: 5
Training loss: 0.31747581879828385
Validation loss: 2.7140063926974753

Epoch: 5| Step: 6
Training loss: 0.3428651301235564
Validation loss: 2.6891159625652423

Epoch: 5| Step: 7
Training loss: 0.3194242466136583
Validation loss: 2.725482435276097

Epoch: 5| Step: 8
Training loss: 0.33095409474177434
Validation loss: 2.735138327002221

Epoch: 5| Step: 9
Training loss: 0.32076986735829993
Validation loss: 2.7555388893521564

Epoch: 5| Step: 10
Training loss: 0.2507186633293785
Validation loss: 2.716920006578657

Epoch: 5| Step: 11
Training loss: 0.15204413000711572
Validation loss: 2.7018533262203706

Epoch: 509| Step: 0
Training loss: 0.4311829466451479
Validation loss: 2.711794663647671

Epoch: 5| Step: 1
Training loss: 0.33563405015844705
Validation loss: 2.7034206890165136

Epoch: 5| Step: 2
Training loss: 0.3096222217251901
Validation loss: 2.6586293951532065

Epoch: 5| Step: 3
Training loss: 0.2850417991779698
Validation loss: 2.7077441338773864

Epoch: 5| Step: 4
Training loss: 0.22328872529337357
Validation loss: 2.7436558160569233

Epoch: 5| Step: 5
Training loss: 0.46309462611149466
Validation loss: 2.6956633961360024

Epoch: 5| Step: 6
Training loss: 0.3962368497862611
Validation loss: 2.690718981541063

Epoch: 5| Step: 7
Training loss: 0.36210297678672265
Validation loss: 2.727572828667266

Epoch: 5| Step: 8
Training loss: 0.3076158069397964
Validation loss: 2.7261399613003894

Epoch: 5| Step: 9
Training loss: 0.2750094054521046
Validation loss: 2.8035303737774555

Epoch: 5| Step: 10
Training loss: 0.32348085794682135
Validation loss: 2.713721246811567

Epoch: 5| Step: 11
Training loss: 0.2622819221712496
Validation loss: 2.7405144495544547

Epoch: 510| Step: 0
Training loss: 0.4462027768919408
Validation loss: 2.7116951227326496

Epoch: 5| Step: 1
Training loss: 0.2926516024276006
Validation loss: 2.6837718336309617

Epoch: 5| Step: 2
Training loss: 0.3063223334934617
Validation loss: 2.732580518900258

Epoch: 5| Step: 3
Training loss: 0.4281921201842818
Validation loss: 2.6850495144915487

Epoch: 5| Step: 4
Training loss: 0.39243737349832425
Validation loss: 2.6550477542162554

Epoch: 5| Step: 5
Training loss: 0.4425907614672432
Validation loss: 2.654607483778873

Epoch: 5| Step: 6
Training loss: 0.29927642704619706
Validation loss: 2.6482785795200092

Epoch: 5| Step: 7
Training loss: 0.2599061858129061
Validation loss: 2.687691957064946

Epoch: 5| Step: 8
Training loss: 0.37081127458322005
Validation loss: 2.661259859651237

Epoch: 5| Step: 9
Training loss: 0.38624177282021727
Validation loss: 2.7144034927492413

Epoch: 5| Step: 10
Training loss: 0.28304188841076316
Validation loss: 2.717479631902686

Epoch: 5| Step: 11
Training loss: 0.40520180678157786
Validation loss: 2.718344479130064

Epoch: 511| Step: 0
Training loss: 0.4441154016530681
Validation loss: 2.709580045858711

Epoch: 5| Step: 1
Training loss: 0.2843303477684714
Validation loss: 2.738701113855513

Epoch: 5| Step: 2
Training loss: 0.3333961035317694
Validation loss: 2.6863310696614064

Epoch: 5| Step: 3
Training loss: 0.33325313805449824
Validation loss: 2.683202501231116

Epoch: 5| Step: 4
Training loss: 0.4498767843038836
Validation loss: 2.6608327527279036

Epoch: 5| Step: 5
Training loss: 0.34636329935218335
Validation loss: 2.71911807875421

Epoch: 5| Step: 6
Training loss: 0.27358320986032
Validation loss: 2.7085455640143694

Epoch: 5| Step: 7
Training loss: 0.27945632651193214
Validation loss: 2.68951419640013

Epoch: 5| Step: 8
Training loss: 0.33319719584333757
Validation loss: 2.711017614787694

Epoch: 5| Step: 9
Training loss: 0.3621916067501135
Validation loss: 2.7171743511447026

Epoch: 5| Step: 10
Training loss: 0.4424103987220979
Validation loss: 2.719752470357648

Epoch: 5| Step: 11
Training loss: 0.20575943353992585
Validation loss: 2.7674638091468866

Epoch: 512| Step: 0
Training loss: 0.431409575474739
Validation loss: 2.745087711986148

Epoch: 5| Step: 1
Training loss: 0.2758032365847285
Validation loss: 2.6878370454416474

Epoch: 5| Step: 2
Training loss: 0.3577269206089941
Validation loss: 2.6915602582284923

Epoch: 5| Step: 3
Training loss: 0.31353096178015516
Validation loss: 2.7609343972914595

Epoch: 5| Step: 4
Training loss: 0.3499209438174463
Validation loss: 2.693938571321622

Epoch: 5| Step: 5
Training loss: 0.2683445055977514
Validation loss: 2.7314679960114323

Epoch: 5| Step: 6
Training loss: 0.40259201760198027
Validation loss: 2.7155081212769816

Epoch: 5| Step: 7
Training loss: 0.3218105339565146
Validation loss: 2.6552872726979766

Epoch: 5| Step: 8
Training loss: 0.33362778929955417
Validation loss: 2.714115978366347

Epoch: 5| Step: 9
Training loss: 0.2874784627393876
Validation loss: 2.71638496068029

Epoch: 5| Step: 10
Training loss: 0.39898068670028725
Validation loss: 2.6850701407169066

Epoch: 5| Step: 11
Training loss: 0.31823012882010215
Validation loss: 2.6991431321824546

Epoch: 513| Step: 0
Training loss: 0.39827302268005965
Validation loss: 2.6546167363851607

Epoch: 5| Step: 1
Training loss: 0.259843828863062
Validation loss: 2.6973008787230066

Epoch: 5| Step: 2
Training loss: 0.30021806728713857
Validation loss: 2.664868640214923

Epoch: 5| Step: 3
Training loss: 0.2368785894494371
Validation loss: 2.714618916887018

Epoch: 5| Step: 4
Training loss: 0.2742654391153223
Validation loss: 2.6399994773274202

Epoch: 5| Step: 5
Training loss: 0.3517068142859067
Validation loss: 2.678727084435798

Epoch: 5| Step: 6
Training loss: 0.26653972369667533
Validation loss: 2.6750011040040587

Epoch: 5| Step: 7
Training loss: 0.27535991632758683
Validation loss: 2.6560813775488668

Epoch: 5| Step: 8
Training loss: 0.3070178293493325
Validation loss: 2.6549250308789234

Epoch: 5| Step: 9
Training loss: 0.40033609902879436
Validation loss: 2.732963281146589

Epoch: 5| Step: 10
Training loss: 0.31011042124205157
Validation loss: 2.665613725898517

Epoch: 5| Step: 11
Training loss: 0.27190442145306754
Validation loss: 2.667431598094385

Epoch: 514| Step: 0
Training loss: 0.24687887019733282
Validation loss: 2.6998912821769046

Epoch: 5| Step: 1
Training loss: 0.43912904445524165
Validation loss: 2.5968327070113486

Epoch: 5| Step: 2
Training loss: 0.3891739214636854
Validation loss: 2.666713387606543

Epoch: 5| Step: 3
Training loss: 0.35456815804052527
Validation loss: 2.6552369205367135

Epoch: 5| Step: 4
Training loss: 0.27773273751893446
Validation loss: 2.6098003992463585

Epoch: 5| Step: 5
Training loss: 0.3117125364750326
Validation loss: 2.623896949860773

Epoch: 5| Step: 6
Training loss: 0.28611270977137404
Validation loss: 2.662135360340928

Epoch: 5| Step: 7
Training loss: 0.38697159333175263
Validation loss: 2.680978477026433

Epoch: 5| Step: 8
Training loss: 0.29084442530596966
Validation loss: 2.6982281197029203

Epoch: 5| Step: 9
Training loss: 0.3846555639563478
Validation loss: 2.707704608027601

Epoch: 5| Step: 10
Training loss: 0.21787194731035175
Validation loss: 2.666325917427702

Epoch: 5| Step: 11
Training loss: 0.22593994767167738
Validation loss: 2.694437067250075

Epoch: 515| Step: 0
Training loss: 0.3472460995517556
Validation loss: 2.674220221494269

Epoch: 5| Step: 1
Training loss: 0.3989532162443569
Validation loss: 2.7427705632147883

Epoch: 5| Step: 2
Training loss: 0.3363567109758475
Validation loss: 2.637545725801221

Epoch: 5| Step: 3
Training loss: 0.2289943571072187
Validation loss: 2.7415556002984123

Epoch: 5| Step: 4
Training loss: 0.2881342313988107
Validation loss: 2.695442970545769

Epoch: 5| Step: 5
Training loss: 0.30268128452539894
Validation loss: 2.687258794591232

Epoch: 5| Step: 6
Training loss: 0.3211554971433529
Validation loss: 2.7390710886044287

Epoch: 5| Step: 7
Training loss: 0.3193359724972207
Validation loss: 2.7160354816163177

Epoch: 5| Step: 8
Training loss: 0.34849137287462434
Validation loss: 2.6996432631646248

Epoch: 5| Step: 9
Training loss: 0.2721313889979622
Validation loss: 2.6896907763267097

Epoch: 5| Step: 10
Training loss: 0.3123929913412633
Validation loss: 2.736661278544739

Epoch: 5| Step: 11
Training loss: 0.130743380992173
Validation loss: 2.709776267784672

Epoch: 516| Step: 0
Training loss: 0.26808188694235763
Validation loss: 2.671102345160741

Epoch: 5| Step: 1
Training loss: 0.24930088818223958
Validation loss: 2.6408925231310345

Epoch: 5| Step: 2
Training loss: 0.22935678261594403
Validation loss: 2.623400664548995

Epoch: 5| Step: 3
Training loss: 0.28642864362429016
Validation loss: 2.6438909344274366

Epoch: 5| Step: 4
Training loss: 0.2511830945868483
Validation loss: 2.7265255951957013

Epoch: 5| Step: 5
Training loss: 0.19416370139565978
Validation loss: 2.6631368220258693

Epoch: 5| Step: 6
Training loss: 0.40239391199387775
Validation loss: 2.6825281143907542

Epoch: 5| Step: 7
Training loss: 0.3183661735136405
Validation loss: 2.6624739078502855

Epoch: 5| Step: 8
Training loss: 0.30277822853680886
Validation loss: 2.7245000017424816

Epoch: 5| Step: 9
Training loss: 0.307057941043428
Validation loss: 2.717022626589916

Epoch: 5| Step: 10
Training loss: 0.34373898922018364
Validation loss: 2.644805255407757

Epoch: 5| Step: 11
Training loss: 0.4137925581639016
Validation loss: 2.6509060378439018

Epoch: 517| Step: 0
Training loss: 0.3178519317898592
Validation loss: 2.6705365611701155

Epoch: 5| Step: 1
Training loss: 0.31479818946843036
Validation loss: 2.6709633846627256

Epoch: 5| Step: 2
Training loss: 0.3211556479387244
Validation loss: 2.687766431568828

Epoch: 5| Step: 3
Training loss: 0.4720273997033937
Validation loss: 2.6496057137579268

Epoch: 5| Step: 4
Training loss: 0.27720043347880086
Validation loss: 2.688587811347582

Epoch: 5| Step: 5
Training loss: 0.4772387069027441
Validation loss: 2.6915311152297647

Epoch: 5| Step: 6
Training loss: 0.3567282611850507
Validation loss: 2.729143103772042

Epoch: 5| Step: 7
Training loss: 0.4375896362032863
Validation loss: 2.7524043521639308

Epoch: 5| Step: 8
Training loss: 0.3664483076737049
Validation loss: 2.6313933444449904

Epoch: 5| Step: 9
Training loss: 0.4876268350223923
Validation loss: 2.6968918121686127

Epoch: 5| Step: 10
Training loss: 0.2716810625426806
Validation loss: 2.7034176445725984

Epoch: 5| Step: 11
Training loss: 0.32760811011402746
Validation loss: 2.6937094081289663

Epoch: 518| Step: 0
Training loss: 0.315181268238956
Validation loss: 2.724631692482756

Epoch: 5| Step: 1
Training loss: 0.4145306154340423
Validation loss: 2.667416818478401

Epoch: 5| Step: 2
Training loss: 0.24967107890705414
Validation loss: 2.685482324922624

Epoch: 5| Step: 3
Training loss: 0.2674926147822962
Validation loss: 2.687667774907355

Epoch: 5| Step: 4
Training loss: 0.36590015702970125
Validation loss: 2.6215487604936576

Epoch: 5| Step: 5
Training loss: 0.31910347132789574
Validation loss: 2.6202354333380034

Epoch: 5| Step: 6
Training loss: 0.33050975004132527
Validation loss: 2.680333229314793

Epoch: 5| Step: 7
Training loss: 0.33602999367554903
Validation loss: 2.6724923668000917

Epoch: 5| Step: 8
Training loss: 0.1965503566672234
Validation loss: 2.667521754399274

Epoch: 5| Step: 9
Training loss: 0.29874442679900903
Validation loss: 2.7176609434092653

Epoch: 5| Step: 10
Training loss: 0.3152971727485221
Validation loss: 2.6937600903421637

Epoch: 5| Step: 11
Training loss: 0.1533182836507695
Validation loss: 2.666844061573778

Epoch: 519| Step: 0
Training loss: 0.4450035194461392
Validation loss: 2.674964895344874

Epoch: 5| Step: 1
Training loss: 0.4033575710424011
Validation loss: 2.6864924723149763

Epoch: 5| Step: 2
Training loss: 0.37171374278726843
Validation loss: 2.656033765181815

Epoch: 5| Step: 3
Training loss: 0.3292880562792685
Validation loss: 2.659589457801924

Epoch: 5| Step: 4
Training loss: 0.34398628913577284
Validation loss: 2.6540059296749665

Epoch: 5| Step: 5
Training loss: 0.351836860412424
Validation loss: 2.7016861013066054

Epoch: 5| Step: 6
Training loss: 0.28480423141022315
Validation loss: 2.7556286595170922

Epoch: 5| Step: 7
Training loss: 0.30404764627242886
Validation loss: 2.712064008787996

Epoch: 5| Step: 8
Training loss: 0.38532822040872083
Validation loss: 2.746855104336024

Epoch: 5| Step: 9
Training loss: 0.4255804410792224
Validation loss: 2.7558470432177713

Epoch: 5| Step: 10
Training loss: 0.28901108722720115
Validation loss: 2.7268440006536228

Epoch: 5| Step: 11
Training loss: 0.14890650014666174
Validation loss: 2.7284381903708415

Epoch: 520| Step: 0
Training loss: 0.29997836124343746
Validation loss: 2.745630615017912

Epoch: 5| Step: 1
Training loss: 0.3028299857485373
Validation loss: 2.6726198589602066

Epoch: 5| Step: 2
Training loss: 0.383358021732396
Validation loss: 2.695535099586221

Epoch: 5| Step: 3
Training loss: 0.26964457520602536
Validation loss: 2.694278076258496

Epoch: 5| Step: 4
Training loss: 0.31104246217779663
Validation loss: 2.709308886280519

Epoch: 5| Step: 5
Training loss: 0.32087252669575617
Validation loss: 2.7315417079398245

Epoch: 5| Step: 6
Training loss: 0.28632742607166706
Validation loss: 2.706360771079423

Epoch: 5| Step: 7
Training loss: 0.405407049376037
Validation loss: 2.706401496652373

Epoch: 5| Step: 8
Training loss: 0.28044068931957766
Validation loss: 2.666124804151085

Epoch: 5| Step: 9
Training loss: 0.30829112992693447
Validation loss: 2.670080649494923

Epoch: 5| Step: 10
Training loss: 0.32230051025228323
Validation loss: 2.73623586277209

Epoch: 5| Step: 11
Training loss: 0.28176528034391146
Validation loss: 2.6696876547788553

Epoch: 521| Step: 0
Training loss: 0.3263912034572662
Validation loss: 2.6769817471557023

Epoch: 5| Step: 1
Training loss: 0.47232053199310053
Validation loss: 2.6841117325670143

Epoch: 5| Step: 2
Training loss: 0.22944212022419563
Validation loss: 2.6791905200859447

Epoch: 5| Step: 3
Training loss: 0.22611087971446886
Validation loss: 2.661054731150937

Epoch: 5| Step: 4
Training loss: 0.2919063888596847
Validation loss: 2.699400638500667

Epoch: 5| Step: 5
Training loss: 0.2804990651103197
Validation loss: 2.660402832702261

Epoch: 5| Step: 6
Training loss: 0.3160014801254798
Validation loss: 2.6486456591367706

Epoch: 5| Step: 7
Training loss: 0.2705938980343554
Validation loss: 2.627791532572779

Epoch: 5| Step: 8
Training loss: 0.2965620298552731
Validation loss: 2.6766208454519616

Epoch: 5| Step: 9
Training loss: 0.3405367045624243
Validation loss: 2.6603408054856605

Epoch: 5| Step: 10
Training loss: 0.27376147559686553
Validation loss: 2.7162546603576407

Epoch: 5| Step: 11
Training loss: 0.27664033581110725
Validation loss: 2.7078763881982026

Epoch: 522| Step: 0
Training loss: 0.3494632671376026
Validation loss: 2.657104586589587

Epoch: 5| Step: 1
Training loss: 0.2883298584810433
Validation loss: 2.687122640065434

Epoch: 5| Step: 2
Training loss: 0.28241881583893025
Validation loss: 2.761032713518618

Epoch: 5| Step: 3
Training loss: 0.31364403169980876
Validation loss: 2.6722798514799497

Epoch: 5| Step: 4
Training loss: 0.3924114195979919
Validation loss: 2.694921124188146

Epoch: 5| Step: 5
Training loss: 0.4116386509383009
Validation loss: 2.707322028443503

Epoch: 5| Step: 6
Training loss: 0.26727754179952196
Validation loss: 2.6418676687709985

Epoch: 5| Step: 7
Training loss: 0.2483468682139083
Validation loss: 2.685772640101954

Epoch: 5| Step: 8
Training loss: 0.23986287584372276
Validation loss: 2.723101475059299

Epoch: 5| Step: 9
Training loss: 0.31956260406071657
Validation loss: 2.74646370549518

Epoch: 5| Step: 10
Training loss: 0.25028236655449315
Validation loss: 2.702344844303606

Epoch: 5| Step: 11
Training loss: 0.31276839174917453
Validation loss: 2.6759444509517887

Epoch: 523| Step: 0
Training loss: 0.28333550351845116
Validation loss: 2.677443403428858

Epoch: 5| Step: 1
Training loss: 0.22802926334332793
Validation loss: 2.728415856691161

Epoch: 5| Step: 2
Training loss: 0.30416672779544235
Validation loss: 2.721716990156514

Epoch: 5| Step: 3
Training loss: 0.31759202370722933
Validation loss: 2.7040589470316303

Epoch: 5| Step: 4
Training loss: 0.3182745159300102
Validation loss: 2.7136533034504455

Epoch: 5| Step: 5
Training loss: 0.38831719552563804
Validation loss: 2.7046478369948836

Epoch: 5| Step: 6
Training loss: 0.21463514083761887
Validation loss: 2.694348252164492

Epoch: 5| Step: 7
Training loss: 0.22878406114730881
Validation loss: 2.7292827491727745

Epoch: 5| Step: 8
Training loss: 0.29121990842452705
Validation loss: 2.7109398489143977

Epoch: 5| Step: 9
Training loss: 0.38473560971372295
Validation loss: 2.712794020900767

Epoch: 5| Step: 10
Training loss: 0.2936176869499519
Validation loss: 2.655729990902494

Epoch: 5| Step: 11
Training loss: 0.47923197163047015
Validation loss: 2.7122118407155424

Epoch: 524| Step: 0
Training loss: 0.20222830001087577
Validation loss: 2.6729576044275256

Epoch: 5| Step: 1
Training loss: 0.3027756816616957
Validation loss: 2.683298093749981

Epoch: 5| Step: 2
Training loss: 0.30702244015544317
Validation loss: 2.652005040560617

Epoch: 5| Step: 3
Training loss: 0.29830830059216684
Validation loss: 2.709272021456267

Epoch: 5| Step: 4
Training loss: 0.3012684801970561
Validation loss: 2.656147969848184

Epoch: 5| Step: 5
Training loss: 0.38888549684944984
Validation loss: 2.674340710991808

Epoch: 5| Step: 6
Training loss: 0.37601351865982546
Validation loss: 2.732637220126629

Epoch: 5| Step: 7
Training loss: 0.4175747235180138
Validation loss: 2.6214053503646104

Epoch: 5| Step: 8
Training loss: 0.31093414918253776
Validation loss: 2.705825904289302

Epoch: 5| Step: 9
Training loss: 0.5056403728076734
Validation loss: 2.7279472987972864

Epoch: 5| Step: 10
Training loss: 0.3759903744228947
Validation loss: 2.7124617374668962

Epoch: 5| Step: 11
Training loss: 0.12052470758052897
Validation loss: 2.6754004771379396

Epoch: 525| Step: 0
Training loss: 0.3041213105734837
Validation loss: 2.6475630660405827

Epoch: 5| Step: 1
Training loss: 0.2424582997825911
Validation loss: 2.6729235794461643

Epoch: 5| Step: 2
Training loss: 0.24728601260150326
Validation loss: 2.6091874677689284

Epoch: 5| Step: 3
Training loss: 0.27492571878740785
Validation loss: 2.6673151596140334

Epoch: 5| Step: 4
Training loss: 0.2801603693959757
Validation loss: 2.6456287084635033

Epoch: 5| Step: 5
Training loss: 0.3815683466270459
Validation loss: 2.633676358910234

Epoch: 5| Step: 6
Training loss: 0.4517099878813186
Validation loss: 2.6303374413003517

Epoch: 5| Step: 7
Training loss: 0.37711949210211426
Validation loss: 2.7221888720703404

Epoch: 5| Step: 8
Training loss: 0.36248086105992233
Validation loss: 2.6294932548480925

Epoch: 5| Step: 9
Training loss: 0.30367449330191604
Validation loss: 2.7096988952230525

Epoch: 5| Step: 10
Training loss: 0.31641636349562463
Validation loss: 2.739284739642468

Epoch: 5| Step: 11
Training loss: 0.32651387632947465
Validation loss: 2.6768738495222086

Epoch: 526| Step: 0
Training loss: 0.3295439963771883
Validation loss: 2.7127545960947272

Epoch: 5| Step: 1
Training loss: 0.2866324011474725
Validation loss: 2.6911612677397647

Epoch: 5| Step: 2
Training loss: 0.3248321406907868
Validation loss: 2.6861848015710827

Epoch: 5| Step: 3
Training loss: 0.3697484779210516
Validation loss: 2.5778973488530634

Epoch: 5| Step: 4
Training loss: 0.4463691556083787
Validation loss: 2.686212271822899

Epoch: 5| Step: 5
Training loss: 0.48023401124145176
Validation loss: 2.643391884491635

Epoch: 5| Step: 6
Training loss: 0.323045595897647
Validation loss: 2.6979877187634584

Epoch: 5| Step: 7
Training loss: 0.3904823805806285
Validation loss: 2.6858256691225515

Epoch: 5| Step: 8
Training loss: 0.23839891373975708
Validation loss: 2.73903395338138

Epoch: 5| Step: 9
Training loss: 0.40308334371932036
Validation loss: 2.7465175267309694

Epoch: 5| Step: 10
Training loss: 0.3589510282650269
Validation loss: 2.7429340972783094

Epoch: 5| Step: 11
Training loss: 0.38013673352036326
Validation loss: 2.743518303550489

Epoch: 527| Step: 0
Training loss: 0.3876670615715471
Validation loss: 2.699131163276949

Epoch: 5| Step: 1
Training loss: 0.2449666050854639
Validation loss: 2.7293261864806513

Epoch: 5| Step: 2
Training loss: 0.274500347975387
Validation loss: 2.677512558742292

Epoch: 5| Step: 3
Training loss: 0.36057752022326983
Validation loss: 2.681570690749926

Epoch: 5| Step: 4
Training loss: 0.35789144136593454
Validation loss: 2.6981817628287077

Epoch: 5| Step: 5
Training loss: 0.29521707577481504
Validation loss: 2.6327367633977903

Epoch: 5| Step: 6
Training loss: 0.32149903413485115
Validation loss: 2.6522982166934432

Epoch: 5| Step: 7
Training loss: 0.29440102468246193
Validation loss: 2.697929379839505

Epoch: 5| Step: 8
Training loss: 0.2690252585561995
Validation loss: 2.662019697784001

Epoch: 5| Step: 9
Training loss: 0.3204599366819806
Validation loss: 2.6832581244960294

Epoch: 5| Step: 10
Training loss: 0.3511131593969579
Validation loss: 2.704522537851249

Epoch: 5| Step: 11
Training loss: 0.33157676558226906
Validation loss: 2.676005474265068

Epoch: 528| Step: 0
Training loss: 0.3265559852899388
Validation loss: 2.6916865999607653

Epoch: 5| Step: 1
Training loss: 0.3032042394871663
Validation loss: 2.6738917526874237

Epoch: 5| Step: 2
Training loss: 0.3355872746084504
Validation loss: 2.6440649292921212

Epoch: 5| Step: 3
Training loss: 0.2537893613109265
Validation loss: 2.6590626878013937

Epoch: 5| Step: 4
Training loss: 0.2939097487521768
Validation loss: 2.652353465568565

Epoch: 5| Step: 5
Training loss: 0.3329960325959854
Validation loss: 2.622174543775236

Epoch: 5| Step: 6
Training loss: 0.2783460906287842
Validation loss: 2.739936738130855

Epoch: 5| Step: 7
Training loss: 0.2465580390362238
Validation loss: 2.688404600060443

Epoch: 5| Step: 8
Training loss: 0.26660167428597703
Validation loss: 2.692752016304689

Epoch: 5| Step: 9
Training loss: 0.3719649278274037
Validation loss: 2.713357671453559

Epoch: 5| Step: 10
Training loss: 0.34013159389616204
Validation loss: 2.6764054231710883

Epoch: 5| Step: 11
Training loss: 0.14360356958330547
Validation loss: 2.7111958354067096

Epoch: 529| Step: 0
Training loss: 0.2570740498907422
Validation loss: 2.738506708735793

Epoch: 5| Step: 1
Training loss: 0.3777309555640576
Validation loss: 2.690317824311877

Epoch: 5| Step: 2
Training loss: 0.24721463326990356
Validation loss: 2.7103961876856184

Epoch: 5| Step: 3
Training loss: 0.2725788531262247
Validation loss: 2.6394944526523503

Epoch: 5| Step: 4
Training loss: 0.21111092678976656
Validation loss: 2.7068102123886746

Epoch: 5| Step: 5
Training loss: 0.21378066869087073
Validation loss: 2.6734500763577067

Epoch: 5| Step: 6
Training loss: 0.33778285915468964
Validation loss: 2.710994331431094

Epoch: 5| Step: 7
Training loss: 0.3844601730633955
Validation loss: 2.706217883523689

Epoch: 5| Step: 8
Training loss: 0.3249353394925388
Validation loss: 2.7105420691771966

Epoch: 5| Step: 9
Training loss: 0.3117518170823077
Validation loss: 2.6649635260437687

Epoch: 5| Step: 10
Training loss: 0.23467621520908222
Validation loss: 2.6900185254113773

Epoch: 5| Step: 11
Training loss: 0.3409776624980187
Validation loss: 2.708350278116673

Epoch: 530| Step: 0
Training loss: 0.3441599438859693
Validation loss: 2.7153581383519114

Epoch: 5| Step: 1
Training loss: 0.30526588025443385
Validation loss: 2.6858705489724377

Epoch: 5| Step: 2
Training loss: 0.3098739554859637
Validation loss: 2.672471515255707

Epoch: 5| Step: 3
Training loss: 0.24519395575969202
Validation loss: 2.6427454062570392

Epoch: 5| Step: 4
Training loss: 0.31000555591065254
Validation loss: 2.707790178462655

Epoch: 5| Step: 5
Training loss: 0.22994923632636585
Validation loss: 2.6857467854393673

Epoch: 5| Step: 6
Training loss: 0.35901520174350765
Validation loss: 2.617944057677902

Epoch: 5| Step: 7
Training loss: 0.2584860413156401
Validation loss: 2.713935601359419

Epoch: 5| Step: 8
Training loss: 0.26873267084629693
Validation loss: 2.658903722397771

Epoch: 5| Step: 9
Training loss: 0.48513362297330614
Validation loss: 2.662737609218427

Epoch: 5| Step: 10
Training loss: 0.2926982520981806
Validation loss: 2.7161547818254412

Epoch: 5| Step: 11
Training loss: 0.2569026497766221
Validation loss: 2.7100930378193913

Epoch: 531| Step: 0
Training loss: 0.24607996674948776
Validation loss: 2.7169479887543284

Epoch: 5| Step: 1
Training loss: 0.3446901642600438
Validation loss: 2.693339977789306

Epoch: 5| Step: 2
Training loss: 0.19923694377921808
Validation loss: 2.6641752754273593

Epoch: 5| Step: 3
Training loss: 0.24088736696570684
Validation loss: 2.646510609476798

Epoch: 5| Step: 4
Training loss: 0.284832718615169
Validation loss: 2.6663134249037626

Epoch: 5| Step: 5
Training loss: 0.31535341976492554
Validation loss: 2.7074846435720747

Epoch: 5| Step: 6
Training loss: 0.36414945079794003
Validation loss: 2.6894480368853024

Epoch: 5| Step: 7
Training loss: 0.43155665897115264
Validation loss: 2.667785379448367

Epoch: 5| Step: 8
Training loss: 0.24724602011388636
Validation loss: 2.7064841131740898

Epoch: 5| Step: 9
Training loss: 0.3102026777326199
Validation loss: 2.632644629102539

Epoch: 5| Step: 10
Training loss: 0.3733456798020488
Validation loss: 2.716158322201646

Epoch: 5| Step: 11
Training loss: 0.3063262980649134
Validation loss: 2.707963090434004

Epoch: 532| Step: 0
Training loss: 0.413156814446701
Validation loss: 2.749507762463717

Epoch: 5| Step: 1
Training loss: 0.3650969588492899
Validation loss: 2.6989028900431222

Epoch: 5| Step: 2
Training loss: 0.28912287158982525
Validation loss: 2.7412261690668576

Epoch: 5| Step: 3
Training loss: 0.26513164648891147
Validation loss: 2.632573570631444

Epoch: 5| Step: 4
Training loss: 0.41220200207282826
Validation loss: 2.7319707527622086

Epoch: 5| Step: 5
Training loss: 0.3879412584400843
Validation loss: 2.6881757337649965

Epoch: 5| Step: 6
Training loss: 0.2976952064232662
Validation loss: 2.6564505912736354

Epoch: 5| Step: 7
Training loss: 0.2952556994475129
Validation loss: 2.641785417458872

Epoch: 5| Step: 8
Training loss: 0.28598620203219594
Validation loss: 2.7038628080269906

Epoch: 5| Step: 9
Training loss: 0.2792330715688429
Validation loss: 2.642865998197753

Epoch: 5| Step: 10
Training loss: 0.4638499688416076
Validation loss: 2.6992701973177864

Epoch: 5| Step: 11
Training loss: 0.4696257040827258
Validation loss: 2.6629396982937408

Epoch: 533| Step: 0
Training loss: 0.34251024189135726
Validation loss: 2.6452421193637745

Epoch: 5| Step: 1
Training loss: 0.35331317732034295
Validation loss: 2.67254521699532

Epoch: 5| Step: 2
Training loss: 0.3594304954139478
Validation loss: 2.6573099901102686

Epoch: 5| Step: 3
Training loss: 0.3716912127986585
Validation loss: 2.6992539009274976

Epoch: 5| Step: 4
Training loss: 0.2994173262505964
Validation loss: 2.700099188695783

Epoch: 5| Step: 5
Training loss: 0.2833927966344516
Validation loss: 2.6683104832862408

Epoch: 5| Step: 6
Training loss: 0.2912300395265274
Validation loss: 2.7120045221114273

Epoch: 5| Step: 7
Training loss: 0.4191378171174351
Validation loss: 2.789181818043822

Epoch: 5| Step: 8
Training loss: 0.2770660514509269
Validation loss: 2.6763212192840244

Epoch: 5| Step: 9
Training loss: 0.3768626880374386
Validation loss: 2.6583305139636293

Epoch: 5| Step: 10
Training loss: 0.35802009424098713
Validation loss: 2.7248912414813855

Epoch: 5| Step: 11
Training loss: 0.27166736391091145
Validation loss: 2.7237595302665403

Epoch: 534| Step: 0
Training loss: 0.2528640779803825
Validation loss: 2.7315683365576806

Epoch: 5| Step: 1
Training loss: 0.39295770314883066
Validation loss: 2.726239995091227

Epoch: 5| Step: 2
Training loss: 0.2192913832212971
Validation loss: 2.7927507648898944

Epoch: 5| Step: 3
Training loss: 0.25901375858481046
Validation loss: 2.676409931069349

Epoch: 5| Step: 4
Training loss: 0.3095384575371978
Validation loss: 2.773250333532835

Epoch: 5| Step: 5
Training loss: 0.2798016661454629
Validation loss: 2.7096904521133145

Epoch: 5| Step: 6
Training loss: 0.40126301696792527
Validation loss: 2.690603877600133

Epoch: 5| Step: 7
Training loss: 0.3798936974699274
Validation loss: 2.679345864482433

Epoch: 5| Step: 8
Training loss: 0.39578265777590527
Validation loss: 2.6920177925776194

Epoch: 5| Step: 9
Training loss: 0.3644907311502506
Validation loss: 2.673068952843212

Epoch: 5| Step: 10
Training loss: 0.3191742910793329
Validation loss: 2.6421531115549386

Epoch: 5| Step: 11
Training loss: 0.4947442902085656
Validation loss: 2.7426829456545683

Epoch: 535| Step: 0
Training loss: 0.24768314576539008
Validation loss: 2.748940502155655

Epoch: 5| Step: 1
Training loss: 0.29310869053607647
Validation loss: 2.6821862480904066

Epoch: 5| Step: 2
Training loss: 0.4256019914880746
Validation loss: 2.6694088796259225

Epoch: 5| Step: 3
Training loss: 0.3022995071174296
Validation loss: 2.6518208470967535

Epoch: 5| Step: 4
Training loss: 0.42446585987351004
Validation loss: 2.7000172819067214

Epoch: 5| Step: 5
Training loss: 0.267022732910791
Validation loss: 2.66544315773308

Epoch: 5| Step: 6
Training loss: 0.30572880799609864
Validation loss: 2.712987591827932

Epoch: 5| Step: 7
Training loss: 0.3257746533428096
Validation loss: 2.710832493018993

Epoch: 5| Step: 8
Training loss: 0.2989011438455069
Validation loss: 2.6326642999339755

Epoch: 5| Step: 9
Training loss: 0.2903982051776495
Validation loss: 2.6541067639652063

Epoch: 5| Step: 10
Training loss: 0.33790458253466515
Validation loss: 2.6929710132164035

Epoch: 5| Step: 11
Training loss: 0.34381354351540655
Validation loss: 2.6884590145581795

Epoch: 536| Step: 0
Training loss: 0.33118264080239995
Validation loss: 2.742509035132103

Epoch: 5| Step: 1
Training loss: 0.3893371715508874
Validation loss: 2.7208505149218976

Epoch: 5| Step: 2
Training loss: 0.298527909609885
Validation loss: 2.744986352886608

Epoch: 5| Step: 3
Training loss: 0.29807455751744083
Validation loss: 2.7270245529457147

Epoch: 5| Step: 4
Training loss: 0.2562774562082764
Validation loss: 2.784142550931374

Epoch: 5| Step: 5
Training loss: 0.2770491365014819
Validation loss: 2.6515739870768584

Epoch: 5| Step: 6
Training loss: 0.3328617032711942
Validation loss: 2.6933478857011584

Epoch: 5| Step: 7
Training loss: 0.3241476647455445
Validation loss: 2.6832833108227847

Epoch: 5| Step: 8
Training loss: 0.27606033166124927
Validation loss: 2.759606006035179

Epoch: 5| Step: 9
Training loss: 0.3157111881154387
Validation loss: 2.682114890979979

Epoch: 5| Step: 10
Training loss: 0.3746810788772829
Validation loss: 2.714355179622603

Epoch: 5| Step: 11
Training loss: 0.23592029407743867
Validation loss: 2.7186909775155237

Epoch: 537| Step: 0
Training loss: 0.26807995537874896
Validation loss: 2.7339443430772383

Epoch: 5| Step: 1
Training loss: 0.34770970522931993
Validation loss: 2.7393136393342843

Epoch: 5| Step: 2
Training loss: 0.29832627036127
Validation loss: 2.7318857797319676

Epoch: 5| Step: 3
Training loss: 0.4442727180193525
Validation loss: 2.7169988188293495

Epoch: 5| Step: 4
Training loss: 0.3198964510586355
Validation loss: 2.75107681981865

Epoch: 5| Step: 5
Training loss: 0.2740086720757971
Validation loss: 2.7522350498072585

Epoch: 5| Step: 6
Training loss: 0.3384304585345144
Validation loss: 2.733686345892384

Epoch: 5| Step: 7
Training loss: 0.29969432675856905
Validation loss: 2.780248015001337

Epoch: 5| Step: 8
Training loss: 0.27370804617612116
Validation loss: 2.659989357827823

Epoch: 5| Step: 9
Training loss: 0.3327030118199391
Validation loss: 2.6457239013228584

Epoch: 5| Step: 10
Training loss: 0.28629073384156645
Validation loss: 2.7270197516815866

Epoch: 5| Step: 11
Training loss: 0.27664473921897986
Validation loss: 2.7314134963483756

Epoch: 538| Step: 0
Training loss: 0.43743952265038955
Validation loss: 2.766167951976786

Epoch: 5| Step: 1
Training loss: 0.45016562142592687
Validation loss: 2.7422714619040853

Epoch: 5| Step: 2
Training loss: 0.4039939076913239
Validation loss: 2.7387438323071764

Epoch: 5| Step: 3
Training loss: 0.3737177383890184
Validation loss: 2.750858902460398

Epoch: 5| Step: 4
Training loss: 0.33258025837402866
Validation loss: 2.6457443272395462

Epoch: 5| Step: 5
Training loss: 0.3401766275830223
Validation loss: 2.666818384732234

Epoch: 5| Step: 6
Training loss: 0.3643066946166903
Validation loss: 2.6747504669038347

Epoch: 5| Step: 7
Training loss: 0.21754284269583327
Validation loss: 2.6417275747162816

Epoch: 5| Step: 8
Training loss: 0.28889638406300283
Validation loss: 2.6418363700673404

Epoch: 5| Step: 9
Training loss: 0.3416570977096069
Validation loss: 2.672632533873927

Epoch: 5| Step: 10
Training loss: 0.46706004684765723
Validation loss: 2.663116331804802

Epoch: 5| Step: 11
Training loss: 0.2755373570631889
Validation loss: 2.679904725044238

Epoch: 539| Step: 0
Training loss: 0.3218281290500946
Validation loss: 2.6885925851754604

Epoch: 5| Step: 1
Training loss: 0.2888714571438033
Validation loss: 2.699825253689212

Epoch: 5| Step: 2
Training loss: 0.2652133669279386
Validation loss: 2.708672899575714

Epoch: 5| Step: 3
Training loss: 0.3452310733676137
Validation loss: 2.7440823187918046

Epoch: 5| Step: 4
Training loss: 0.3313333919208163
Validation loss: 2.6898710267383454

Epoch: 5| Step: 5
Training loss: 0.34637943213912914
Validation loss: 2.7100166823693623

Epoch: 5| Step: 6
Training loss: 0.301738368028239
Validation loss: 2.667301260174549

Epoch: 5| Step: 7
Training loss: 0.39696417279815194
Validation loss: 2.6960260672167475

Epoch: 5| Step: 8
Training loss: 0.27120862994722605
Validation loss: 2.6693634364494603

Epoch: 5| Step: 9
Training loss: 0.3751909643950899
Validation loss: 2.6194098872539975

Epoch: 5| Step: 10
Training loss: 0.3434565765664196
Validation loss: 2.696896578664487

Epoch: 5| Step: 11
Training loss: 0.30500263642907
Validation loss: 2.707956787978649

Epoch: 540| Step: 0
Training loss: 0.2862777603214883
Validation loss: 2.6470220078347375

Epoch: 5| Step: 1
Training loss: 0.36227184465542733
Validation loss: 2.6888551104891754

Epoch: 5| Step: 2
Training loss: 0.3959037588445967
Validation loss: 2.6779260360421704

Epoch: 5| Step: 3
Training loss: 0.29191516893877256
Validation loss: 2.7655590573942557

Epoch: 5| Step: 4
Training loss: 0.2942281483887814
Validation loss: 2.714429819216799

Epoch: 5| Step: 5
Training loss: 0.3997873180438488
Validation loss: 2.677239114159839

Epoch: 5| Step: 6
Training loss: 0.2715295712839154
Validation loss: 2.7199796110328673

Epoch: 5| Step: 7
Training loss: 0.3329051242581234
Validation loss: 2.693700118314789

Epoch: 5| Step: 8
Training loss: 0.37832581413179933
Validation loss: 2.668407018808836

Epoch: 5| Step: 9
Training loss: 0.3515018622768227
Validation loss: 2.6506857055330344

Epoch: 5| Step: 10
Training loss: 0.28593972106237736
Validation loss: 2.689800139409827

Epoch: 5| Step: 11
Training loss: 0.226637186696936
Validation loss: 2.724057946410842

Epoch: 541| Step: 0
Training loss: 0.2711294310116667
Validation loss: 2.7509643713306664

Epoch: 5| Step: 1
Training loss: 0.2642852571591176
Validation loss: 2.7084143638715683

Epoch: 5| Step: 2
Training loss: 0.3331532091002504
Validation loss: 2.71597337891548

Epoch: 5| Step: 3
Training loss: 0.3103347029526853
Validation loss: 2.729351624683622

Epoch: 5| Step: 4
Training loss: 0.37345717869068357
Validation loss: 2.715234965214258

Epoch: 5| Step: 5
Training loss: 0.3372893192432628
Validation loss: 2.6868086727823517

Epoch: 5| Step: 6
Training loss: 0.32135515779603097
Validation loss: 2.6971796322685977

Epoch: 5| Step: 7
Training loss: 0.34414078434259576
Validation loss: 2.654870967426498

Epoch: 5| Step: 8
Training loss: 0.27402378987665554
Validation loss: 2.6860199408743712

Epoch: 5| Step: 9
Training loss: 0.3151440936662774
Validation loss: 2.717850057509028

Epoch: 5| Step: 10
Training loss: 0.398467829428809
Validation loss: 2.6973063663588794

Epoch: 5| Step: 11
Training loss: 0.39726346145685903
Validation loss: 2.7183053833323494

Epoch: 542| Step: 0
Training loss: 0.3154658364760832
Validation loss: 2.683369275014277

Epoch: 5| Step: 1
Training loss: 0.28096106045366015
Validation loss: 2.7216914951965774

Epoch: 5| Step: 2
Training loss: 0.40187376775597156
Validation loss: 2.693097871584889

Epoch: 5| Step: 3
Training loss: 0.28119433699904367
Validation loss: 2.718986387682184

Epoch: 5| Step: 4
Training loss: 0.36852612892693754
Validation loss: 2.7222567958052735

Epoch: 5| Step: 5
Training loss: 0.21453705484603788
Validation loss: 2.7238077440570225

Epoch: 5| Step: 6
Training loss: 0.32048753282546905
Validation loss: 2.715478717637791

Epoch: 5| Step: 7
Training loss: 0.37184751152574425
Validation loss: 2.6938331672297706

Epoch: 5| Step: 8
Training loss: 0.2225118302564869
Validation loss: 2.720143169498936

Epoch: 5| Step: 9
Training loss: 0.2518878379039572
Validation loss: 2.669761796164783

Epoch: 5| Step: 10
Training loss: 0.2462201021169194
Validation loss: 2.7034521217349106

Epoch: 5| Step: 11
Training loss: 0.14197128304680554
Validation loss: 2.7217413388065363

Epoch: 543| Step: 0
Training loss: 0.2800231374181257
Validation loss: 2.73041256040461

Epoch: 5| Step: 1
Training loss: 0.3330378812487848
Validation loss: 2.7258325472278293

Epoch: 5| Step: 2
Training loss: 0.28842704105116274
Validation loss: 2.729380251022842

Epoch: 5| Step: 3
Training loss: 0.3185922671849952
Validation loss: 2.692806859430517

Epoch: 5| Step: 4
Training loss: 0.2826257805878878
Validation loss: 2.744450666803015

Epoch: 5| Step: 5
Training loss: 0.3806133355857364
Validation loss: 2.722386909199235

Epoch: 5| Step: 6
Training loss: 0.31444614710677254
Validation loss: 2.6982582911902386

Epoch: 5| Step: 7
Training loss: 0.3376586426416699
Validation loss: 2.6636691245826447

Epoch: 5| Step: 8
Training loss: 0.39980638258611484
Validation loss: 2.6736359101063254

Epoch: 5| Step: 9
Training loss: 0.2966293020953207
Validation loss: 2.6958208793301366

Epoch: 5| Step: 10
Training loss: 0.3685469520941714
Validation loss: 2.7013078583171684

Epoch: 5| Step: 11
Training loss: 0.22474042137906214
Validation loss: 2.728833343204685

Epoch: 544| Step: 0
Training loss: 0.3173020832387413
Validation loss: 2.69303437674894

Epoch: 5| Step: 1
Training loss: 0.44167766834747885
Validation loss: 2.6935729821996643

Epoch: 5| Step: 2
Training loss: 0.34028708381427
Validation loss: 2.7732819813568987

Epoch: 5| Step: 3
Training loss: 0.33922550264979556
Validation loss: 2.691795101413374

Epoch: 5| Step: 4
Training loss: 0.3243081417713517
Validation loss: 2.671406524515987

Epoch: 5| Step: 5
Training loss: 0.26674796196428036
Validation loss: 2.6509689640850715

Epoch: 5| Step: 6
Training loss: 0.3189997872378797
Validation loss: 2.6600799250844744

Epoch: 5| Step: 7
Training loss: 0.5629637449001273
Validation loss: 2.7068740153187947

Epoch: 5| Step: 8
Training loss: 0.3495294596797161
Validation loss: 2.732059450179439

Epoch: 5| Step: 9
Training loss: 0.37208525059466985
Validation loss: 2.7315710023146087

Epoch: 5| Step: 10
Training loss: 0.3699457581815282
Validation loss: 2.6564347726471498

Epoch: 5| Step: 11
Training loss: 0.2450281870693965
Validation loss: 2.6655996815595975

Epoch: 545| Step: 0
Training loss: 0.35659082656262403
Validation loss: 2.751526080411661

Epoch: 5| Step: 1
Training loss: 0.4609442564905533
Validation loss: 2.746532631210838

Epoch: 5| Step: 2
Training loss: 0.4272059132891809
Validation loss: 2.7167253226596375

Epoch: 5| Step: 3
Training loss: 0.38068577649194985
Validation loss: 2.7305905374517763

Epoch: 5| Step: 4
Training loss: 0.3362932650125938
Validation loss: 2.678898738814584

Epoch: 5| Step: 5
Training loss: 0.2675742824306381
Validation loss: 2.6431443800583665

Epoch: 5| Step: 6
Training loss: 0.33936229671497614
Validation loss: 2.611748531474906

Epoch: 5| Step: 7
Training loss: 0.3572222668205426
Validation loss: 2.6783283965044116

Epoch: 5| Step: 8
Training loss: 0.3416092166730148
Validation loss: 2.6258890447837353

Epoch: 5| Step: 9
Training loss: 0.2976799392284653
Validation loss: 2.611883917935785

Epoch: 5| Step: 10
Training loss: 0.29725682650364
Validation loss: 2.685053073682913

Epoch: 5| Step: 11
Training loss: 0.23099398972538512
Validation loss: 2.6744920878235954

Epoch: 546| Step: 0
Training loss: 0.25048563399970236
Validation loss: 2.695809135200663

Epoch: 5| Step: 1
Training loss: 0.43785538884687025
Validation loss: 2.683450305405138

Epoch: 5| Step: 2
Training loss: 0.33363106092362355
Validation loss: 2.7302682354548655

Epoch: 5| Step: 3
Training loss: 0.2580694161160688
Validation loss: 2.71892651902019

Epoch: 5| Step: 4
Training loss: 0.4403829613235851
Validation loss: 2.7017819296550685

Epoch: 5| Step: 5
Training loss: 0.24551580320478172
Validation loss: 2.6752954287957764

Epoch: 5| Step: 6
Training loss: 0.2926757619028527
Validation loss: 2.669783824224981

Epoch: 5| Step: 7
Training loss: 0.2925433694647478
Validation loss: 2.701359560043742

Epoch: 5| Step: 8
Training loss: 0.4422265254616164
Validation loss: 2.663896232927886

Epoch: 5| Step: 9
Training loss: 0.27288188342605435
Validation loss: 2.677088185811871

Epoch: 5| Step: 10
Training loss: 0.28042555877583625
Validation loss: 2.713729992199294

Epoch: 5| Step: 11
Training loss: 0.2982133138153744
Validation loss: 2.6974239832314075

Epoch: 547| Step: 0
Training loss: 0.2402134552817876
Validation loss: 2.7219939482166398

Epoch: 5| Step: 1
Training loss: 0.32262124756127664
Validation loss: 2.778514320290639

Epoch: 5| Step: 2
Training loss: 0.36412485677400047
Validation loss: 2.722534395881606

Epoch: 5| Step: 3
Training loss: 0.37741554635549074
Validation loss: 2.7252511384128346

Epoch: 5| Step: 4
Training loss: 0.31517646947859923
Validation loss: 2.7147442568471076

Epoch: 5| Step: 5
Training loss: 0.30262439329708124
Validation loss: 2.680930973330651

Epoch: 5| Step: 6
Training loss: 0.3380409193120408
Validation loss: 2.6530368444312162

Epoch: 5| Step: 7
Training loss: 0.3414243248142008
Validation loss: 2.69324608800369

Epoch: 5| Step: 8
Training loss: 0.29577331919246935
Validation loss: 2.6220604847227174

Epoch: 5| Step: 9
Training loss: 0.2753428153884918
Validation loss: 2.662646863734401

Epoch: 5| Step: 10
Training loss: 0.39821322992027247
Validation loss: 2.6690227014846553

Epoch: 5| Step: 11
Training loss: 0.36887333795424476
Validation loss: 2.7150706720082027

Epoch: 548| Step: 0
Training loss: 0.33681114946987567
Validation loss: 2.660008202763628

Epoch: 5| Step: 1
Training loss: 0.36837198067998206
Validation loss: 2.6677337215297405

Epoch: 5| Step: 2
Training loss: 0.2703948215312168
Validation loss: 2.673053944249598

Epoch: 5| Step: 3
Training loss: 0.4138282077033774
Validation loss: 2.710536406762938

Epoch: 5| Step: 4
Training loss: 0.34440527578634395
Validation loss: 2.701051004592009

Epoch: 5| Step: 5
Training loss: 0.32175807866266914
Validation loss: 2.6622554116741117

Epoch: 5| Step: 6
Training loss: 0.26520867539229187
Validation loss: 2.6775760358039977

Epoch: 5| Step: 7
Training loss: 0.359627717764632
Validation loss: 2.7120495877843114

Epoch: 5| Step: 8
Training loss: 0.38000162811306964
Validation loss: 2.655756927053874

Epoch: 5| Step: 9
Training loss: 0.2982781404160302
Validation loss: 2.612875651771323

Epoch: 5| Step: 10
Training loss: 0.2917290589605869
Validation loss: 2.65019611421698

Epoch: 5| Step: 11
Training loss: 0.35892863126197105
Validation loss: 2.69177998687092

Epoch: 549| Step: 0
Training loss: 0.2873011357381581
Validation loss: 2.683721079389948

Epoch: 5| Step: 1
Training loss: 0.4176883291589891
Validation loss: 2.668010422775369

Epoch: 5| Step: 2
Training loss: 0.3817698428812055
Validation loss: 2.671396569589627

Epoch: 5| Step: 3
Training loss: 0.3724045341204408
Validation loss: 2.6792785287961123

Epoch: 5| Step: 4
Training loss: 0.2503213307493399
Validation loss: 2.629309492468673

Epoch: 5| Step: 5
Training loss: 0.39952296705316553
Validation loss: 2.6610736618700863

Epoch: 5| Step: 6
Training loss: 0.2874931184318271
Validation loss: 2.683344866943056

Epoch: 5| Step: 7
Training loss: 0.4087012140516894
Validation loss: 2.703657516770731

Epoch: 5| Step: 8
Training loss: 0.3473690218018131
Validation loss: 2.7185569161147134

Epoch: 5| Step: 9
Training loss: 0.29799138523777197
Validation loss: 2.6850578611948333

Epoch: 5| Step: 10
Training loss: 0.215340689833203
Validation loss: 2.660490081349704

Epoch: 5| Step: 11
Training loss: 0.32746830575765246
Validation loss: 2.621171104021194

Epoch: 550| Step: 0
Training loss: 0.2908271076543463
Validation loss: 2.6669376441744728

Epoch: 5| Step: 1
Training loss: 0.3011510111982598
Validation loss: 2.7104077733153202

Epoch: 5| Step: 2
Training loss: 0.40768803491225436
Validation loss: 2.7004369957520726

Epoch: 5| Step: 3
Training loss: 0.2651914817498545
Validation loss: 2.698511707321508

Epoch: 5| Step: 4
Training loss: 0.3021021732944755
Validation loss: 2.6786390279383916

Epoch: 5| Step: 5
Training loss: 0.22629542064772287
Validation loss: 2.7737029723148594

Epoch: 5| Step: 6
Training loss: 0.41422407128863475
Validation loss: 2.7753964897664702

Epoch: 5| Step: 7
Training loss: 0.33025971332822673
Validation loss: 2.724082255902847

Epoch: 5| Step: 8
Training loss: 0.32673420658338
Validation loss: 2.7863057828601336

Epoch: 5| Step: 9
Training loss: 0.2387285021769816
Validation loss: 2.692414322425297

Epoch: 5| Step: 10
Training loss: 0.3345095982999152
Validation loss: 2.697852109384607

Epoch: 5| Step: 11
Training loss: 0.7846090962911717
Validation loss: 2.6567558816622308

Testing loss: 2.5753614731346848
