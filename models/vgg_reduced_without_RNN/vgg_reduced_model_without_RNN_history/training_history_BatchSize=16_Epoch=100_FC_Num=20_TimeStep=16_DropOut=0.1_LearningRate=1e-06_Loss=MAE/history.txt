Epoch: 1| Step: 0
Training loss: 3.6774239540100098
Validation loss: 3.8044825903803323
Epoch: 9| Step: 1
Training loss: 3.9162678718566895
Validation loss: 3.8023131133841095
Epoch: 9| Step: 2
Training loss: 3.9536986351013184
Validation loss: 3.7989370051047784
Epoch: 9| Step: 3
Training loss: 3.5078840255737305
Validation loss: 3.79699804971544
Epoch: 9| Step: 4
Training loss: 3.4835944175720215
Validation loss: 3.7946380248172678
Epoch: 9| Step: 5
Training loss: 4.361260890960693
Validation loss: 3.79369724397179
Epoch: 9| Step: 6
Training loss: 4.572766304016113
Validation loss: 3.7914544043781087
Epoch: 9| Step: 7
Training loss: 3.8811168670654297
Validation loss: 3.7877975436423323
Epoch: 9| Step: 8
Training loss: 3.8487558364868164
Validation loss: 3.782289047035382
Epoch: 9| Step: 9
Training loss: 4.48201847076416
Validation loss: 3.7815070718312436
Epoch: 9| Step: 10
Training loss: 3.2775797843933105
Validation loss: 3.7814206802587713
Epoch: 9| Step: 11
Training loss: 4.781170845031738
Validation loss: 3.777031883061361
Epoch: 9| Step: 12
Training loss: 3.9552435874938965
Validation loss: 3.775218154029023
Epoch: 9| Step: 13
Training loss: 2.716038703918457
Validation loss: 3.7717916742503212
Epoch: 9| Step: 14
Training loss: 4.573338508605957
Validation loss: 3.7693680996517482
Epoch: 9| Step: 15
Training loss: 4.203530311584473
Validation loss: 3.7671719317813572
Epoch: 9| Step: 16
Training loss: 4.329661846160889
Validation loss: 3.76241505574837
Epoch: 9| Step: 17
Training loss: 3.9507250785827637
Validation loss: 3.761074100466941
Epoch: 9| Step: 18
Training loss: 5.21240234375
Validation loss: 3.75749239475607
Epoch: 9| Step: 19
Training loss: 3.8416848182678223
Validation loss: 3.753525275978253
Epoch: 2| Step: 0
Training loss: 2.920696258544922
Validation loss: 3.752767741251335
Epoch: 9| Step: 1
Training loss: 3.7079288959503174
Validation loss: 3.748685687565975
Epoch: 9| Step: 2
Training loss: 3.239961624145508
Validation loss: 3.744844913482666
Epoch: 9| Step: 3
Training loss: 4.831131935119629
Validation loss: 3.7449684194523654
Epoch: 9| Step: 4
Training loss: 3.7522852420806885
Validation loss: 3.740771048360591
Epoch: 9| Step: 5
Training loss: 4.309451103210449
Validation loss: 3.737884634690319
Epoch: 9| Step: 6
Training loss: 3.578664779663086
Validation loss: 3.7339890637843727
Epoch: 9| Step: 7
Training loss: 3.770954132080078
Validation loss: 3.7308948726105173
Epoch: 9| Step: 8
Training loss: 3.6939282417297363
Validation loss: 3.728375642419719
Epoch: 9| Step: 9
Training loss: 3.8904361724853516
Validation loss: 3.7261468009125416
Epoch: 9| Step: 10
Training loss: 4.835998058319092
Validation loss: 3.720328159469495
Epoch: 9| Step: 11
Training loss: 3.241722822189331
Validation loss: 3.717019792940977
Epoch: 9| Step: 12
Training loss: 4.136802673339844
Validation loss: 3.7133851462988545
Epoch: 9| Step: 13
Training loss: 4.057226657867432
Validation loss: 3.7110970689238405
Epoch: 9| Step: 14
Training loss: 4.974562168121338
Validation loss: 3.7052908235316653
Epoch: 9| Step: 15
Training loss: 4.510149955749512
Validation loss: 3.705599187947006
Epoch: 9| Step: 16
Training loss: 4.101953506469727
Validation loss: 3.6998676636236176
Epoch: 9| Step: 17
Training loss: 3.3462657928466797
Validation loss: 3.6959054470062256
Epoch: 9| Step: 18
Training loss: 4.291342258453369
Validation loss: 3.690778078792764
Epoch: 9| Step: 19
Training loss: 4.384561061859131
Validation loss: 3.688957682616419
Epoch: 3| Step: 0
Training loss: 2.534060478210449
Validation loss: 3.684713468277197
Epoch: 9| Step: 1
Training loss: 4.499689102172852
Validation loss: 3.681447303552422
Epoch: 9| Step: 2
Training loss: 3.8672897815704346
Validation loss: 3.677421880282944
Epoch: 9| Step: 3
Training loss: 3.961660385131836
Validation loss: 3.674998231928983
Epoch: 9| Step: 4
Training loss: 3.4259679317474365
Validation loss: 3.669545142770671
Epoch: 9| Step: 5
Training loss: 3.479600429534912
Validation loss: 3.6665124978950554
Epoch: 9| Step: 6
Training loss: 4.658393859863281
Validation loss: 3.663565248036556
Epoch: 9| Step: 7
Training loss: 3.5765867233276367
Validation loss: 3.6588998749959383
Epoch: 9| Step: 8
Training loss: 4.449350357055664
Validation loss: 3.655197231032008
Epoch: 9| Step: 9
Training loss: 4.824206352233887
Validation loss: 3.650263669679491
Epoch: 9| Step: 10
Training loss: 3.6430773735046387
Validation loss: 3.645611630926887
Epoch: 9| Step: 11
Training loss: 4.273313522338867
Validation loss: 3.640080431382433
Epoch: 9| Step: 12
Training loss: 3.556941509246826
Validation loss: 3.6384774609435375
Epoch: 9| Step: 13
Training loss: 3.8978700637817383
Validation loss: 3.63160083962859
Epoch: 9| Step: 14
Training loss: 4.581817626953125
Validation loss: 3.628144596978057
Epoch: 9| Step: 15
Training loss: 4.275503158569336
Validation loss: 3.624220129397276
Epoch: 9| Step: 16
Training loss: 3.671569347381592
Validation loss: 3.6181028626805585
Epoch: 9| Step: 17
Training loss: 3.8761963844299316
Validation loss: 3.6150218994497396
Epoch: 9| Step: 18
Training loss: 2.940382480621338
Validation loss: 3.6096667591616405
Epoch: 9| Step: 19
Training loss: 4.328953266143799
Validation loss: 3.6043730176610054
Epoch: 4| Step: 0
Training loss: 4.26537561416626
Validation loss: 3.6014841700629363
Epoch: 9| Step: 1
Training loss: 3.47682523727417
Validation loss: 3.5951290010548322
Epoch: 9| Step: 2
Training loss: 4.414813995361328
Validation loss: 3.589377092800552
Epoch: 9| Step: 3
Training loss: 3.3631558418273926
Validation loss: 3.586412697387256
Epoch: 9| Step: 4
Training loss: 3.8595077991485596
Validation loss: 3.5810620167272553
Epoch: 9| Step: 5
Training loss: 3.149623394012451
Validation loss: 3.575760573791943
Epoch: 9| Step: 6
Training loss: 3.6927199363708496
Validation loss: 3.5701710337357557
Epoch: 9| Step: 7
Training loss: 4.463029861450195
Validation loss: 3.5677526923392318
Epoch: 9| Step: 8
Training loss: 3.185614824295044
Validation loss: 3.5642187338081195
Epoch: 9| Step: 9
Training loss: 3.6767024993896484
Validation loss: 3.557884048214919
Epoch: 9| Step: 10
Training loss: 4.171618461608887
Validation loss: 3.552629717819982
Epoch: 9| Step: 11
Training loss: 3.8763580322265625
Validation loss: 3.546313640882643
Epoch: 9| Step: 12
Training loss: 3.9674437046051025
Validation loss: 3.5413184114497342
Epoch: 9| Step: 13
Training loss: 3.6135172843933105
Validation loss: 3.5362584024882144
Epoch: 9| Step: 14
Training loss: 3.4164843559265137
Validation loss: 3.5322848549849697
Epoch: 9| Step: 15
Training loss: 4.504604339599609
Validation loss: 3.526177775087974
Epoch: 9| Step: 16
Training loss: 3.205683708190918
Validation loss: 3.5220783254225476
Epoch: 9| Step: 17
Training loss: 4.609402656555176
Validation loss: 3.51592691167653
Epoch: 9| Step: 18
Training loss: 3.669492244720459
Validation loss: 3.511593173733718
Epoch: 9| Step: 19
Training loss: 4.327062129974365
Validation loss: 3.5059196949005127
Epoch: 5| Step: 0
Training loss: 4.084946632385254
Validation loss: 3.5001828927787946
Epoch: 9| Step: 1
Training loss: 4.142200469970703
Validation loss: 3.4944263207826682
Epoch: 9| Step: 2
Training loss: 3.9086999893188477
Validation loss: 3.488827024432395
Epoch: 9| Step: 3
Training loss: 4.968168258666992
Validation loss: 3.4805759217241685
Epoch: 9| Step: 4
Training loss: 3.379517078399658
Validation loss: 3.478232572404601
Epoch: 9| Step: 5
Training loss: 4.257845878601074
Validation loss: 3.469219288380026
Epoch: 9| Step: 6
Training loss: 3.820068597793579
Validation loss: 3.46415238414737
Epoch: 9| Step: 7
Training loss: 3.1129512786865234
Validation loss: 3.459465929072538
Epoch: 9| Step: 8
Training loss: 3.4598233699798584
Validation loss: 3.4548282228785454
Epoch: 9| Step: 9
Training loss: 4.044511795043945
Validation loss: 3.4495965148047576
Epoch: 9| Step: 10
Training loss: 3.8339505195617676
Validation loss: 3.4424586690587105
Epoch: 9| Step: 11
Training loss: 3.3423280715942383
Validation loss: 3.435254899717921
Epoch: 9| Step: 12
Training loss: 3.292121410369873
Validation loss: 3.4252242235828647
Epoch: 9| Step: 13
Training loss: 4.524441719055176
Validation loss: 3.4246643189903643
Epoch: 9| Step: 14
Training loss: 4.064506530761719
Validation loss: 3.4173697224623867
Epoch: 9| Step: 15
Training loss: 3.7552435398101807
Validation loss: 3.4110704102962135
Epoch: 9| Step: 16
Training loss: 3.1401164531707764
Validation loss: 3.4055036177738107
Epoch: 9| Step: 17
Training loss: 3.5579614639282227
Validation loss: 3.395948048118207
Epoch: 9| Step: 18
Training loss: 3.4518158435821533
Validation loss: 3.3950954890079634
Epoch: 9| Step: 19
Training loss: 3.068682909011841
Validation loss: 3.3827630392939065
Epoch: 6| Step: 0
Training loss: 2.955535888671875
Validation loss: 3.37614600092387
Epoch: 9| Step: 1
Training loss: 3.9239308834075928
Validation loss: 3.371783268537453
Epoch: 9| Step: 2
Training loss: 3.03658390045166
Validation loss: 3.361191708406956
Epoch: 9| Step: 3
Training loss: 3.661752700805664
Validation loss: 3.3580811435370137
Epoch: 9| Step: 4
Training loss: 3.170536994934082
Validation loss: 3.3480358209541374
Epoch: 9| Step: 5
Training loss: 3.668727159500122
Validation loss: 3.3421104554649737
Epoch: 9| Step: 6
Training loss: 3.8505539894104004
Validation loss: 3.3366759869692135
Epoch: 9| Step: 7
Training loss: 3.9095077514648438
Validation loss: 3.326293718900612
Epoch: 9| Step: 8
Training loss: 3.7777066230773926
Validation loss: 3.3227573881904
Epoch: 9| Step: 9
Training loss: 3.729093313217163
Validation loss: 3.3107065416926105
Epoch: 9| Step: 10
Training loss: 4.116209983825684
Validation loss: 3.3093299951484734
Epoch: 9| Step: 11
Training loss: 3.590512752532959
Validation loss: 3.3016034304666864
Epoch: 9| Step: 12
Training loss: 3.722034454345703
Validation loss: 3.2927204104636214
Epoch: 9| Step: 13
Training loss: 3.7721245288848877
Validation loss: 3.2858907919135882
Epoch: 9| Step: 14
Training loss: 3.921964645385742
Validation loss: 3.2782056811902165
Epoch: 9| Step: 15
Training loss: 3.9850058555603027
Validation loss: 3.264509709618932
Epoch: 9| Step: 16
Training loss: 4.318772792816162
Validation loss: 3.2597897773166356
Epoch: 9| Step: 17
Training loss: 3.2837910652160645
Validation loss: 3.250814834087015
Epoch: 9| Step: 18
Training loss: 3.8883111476898193
Validation loss: 3.239088049895472
Epoch: 9| Step: 19
Training loss: 2.7779250144958496
Validation loss: 3.2281657774671375
Epoch: 7| Step: 0
Training loss: 3.176088333129883
Validation loss: 3.2228427121965146
Epoch: 9| Step: 1
Training loss: 3.254880905151367
Validation loss: 3.207964224781064
Epoch: 9| Step: 2
Training loss: 3.4844722747802734
Validation loss: 3.2069004302402195
Epoch: 9| Step: 3
Training loss: 3.270979404449463
Validation loss: 3.1973617334160016
Epoch: 9| Step: 4
Training loss: 3.071268320083618
Validation loss: 3.186442785125842
Epoch: 9| Step: 5
Training loss: 3.5643703937530518
Validation loss: 3.175147768404844
Epoch: 9| Step: 6
Training loss: 4.500682830810547
Validation loss: 3.163983439370025
Epoch: 9| Step: 7
Training loss: 4.630321979522705
Validation loss: 3.1525443972443505
Epoch: 9| Step: 8
Training loss: 3.2199976444244385
Validation loss: 3.1493643016266306
Epoch: 9| Step: 9
Training loss: 4.550970077514648
Validation loss: 3.137432017772318
Epoch: 9| Step: 10
Training loss: 2.9881339073181152
Validation loss: 3.1261258657030067
Epoch: 9| Step: 11
Training loss: 3.0767712593078613
Validation loss: 3.1161894438078077
Epoch: 9| Step: 12
Training loss: 4.294610023498535
Validation loss: 3.10730189385174
Epoch: 9| Step: 13
Training loss: 3.690762519836426
Validation loss: 3.0949573431083626
Epoch: 9| Step: 14
Training loss: 3.8491690158843994
Validation loss: 3.088555639596294
Epoch: 9| Step: 15
Training loss: 2.5518622398376465
Validation loss: 3.072646604167472
Epoch: 9| Step: 16
Training loss: 3.8745996952056885
Validation loss: 3.0595671358726007
Epoch: 9| Step: 17
Training loss: 2.845608711242676
Validation loss: 3.047486716894795
Epoch: 9| Step: 18
Training loss: 3.925107002258301
Validation loss: 3.0416314567593363
Epoch: 9| Step: 19
Training loss: 2.6598026752471924
Validation loss: 3.0298881616523796
Epoch: 8| Step: 0
Training loss: 3.677171230316162
Validation loss: 3.019480815036691
Epoch: 9| Step: 1
Training loss: 3.0073394775390625
Validation loss: 3.012024423201307
Epoch: 9| Step: 2
Training loss: 3.581799030303955
Validation loss: 3.0019553170787345
Epoch: 9| Step: 3
Training loss: 3.138862133026123
Validation loss: 2.987535845461509
Epoch: 9| Step: 4
Training loss: 3.855708360671997
Validation loss: 2.976838833994145
Epoch: 9| Step: 5
Training loss: 4.358827590942383
Validation loss: 2.9605206585616517
Epoch: 9| Step: 6
Training loss: 2.8639309406280518
Validation loss: 2.9560719582674313
Epoch: 9| Step: 7
Training loss: 2.3421640396118164
Validation loss: 2.9446275834556963
Epoch: 9| Step: 8
Training loss: 2.5675220489501953
Validation loss: 2.932133796403734
Epoch: 9| Step: 9
Training loss: 3.102617025375366
Validation loss: 2.926516318492752
Epoch: 9| Step: 10
Training loss: 4.009235858917236
Validation loss: 2.914052124503705
Epoch: 9| Step: 11
Training loss: 3.2938311100006104
Validation loss: 2.9072322639629995
Epoch: 9| Step: 12
Training loss: 3.0699455738067627
Validation loss: 2.89055084153045
Epoch: 9| Step: 13
Training loss: 2.8533504009246826
Validation loss: 2.882285082082954
Epoch: 9| Step: 14
Training loss: 3.4150097370147705
Validation loss: 2.87227137311757
Epoch: 9| Step: 15
Training loss: 2.8319602012634277
Validation loss: 2.859943499668039
Epoch: 9| Step: 16
Training loss: 3.977735757827759
Validation loss: 2.8460957746711566
Epoch: 9| Step: 17
Training loss: 3.989375114440918
Validation loss: 2.8360849078610646
Epoch: 9| Step: 18
Training loss: 3.0266337394714355
Validation loss: 2.8232619127781273
Epoch: 9| Step: 19
Training loss: 4.070822715759277
Validation loss: 2.811904058181982
Epoch: 9| Step: 0
Training loss: 3.401893377304077
Validation loss: 2.7978911451298556
Epoch: 9| Step: 1
Training loss: 3.081986427307129
Validation loss: 2.788571409184298
Epoch: 9| Step: 2
Training loss: 2.540703773498535
Validation loss: 2.7704198806405924
Epoch: 9| Step: 3
Training loss: 3.7559001445770264
Validation loss: 2.7606700392935775
Epoch: 9| Step: 4
Training loss: 2.665712356567383
Validation loss: 2.73562941448294
Epoch: 9| Step: 5
Training loss: 2.7484917640686035
Validation loss: 2.7283107599766137
Epoch: 9| Step: 6
Training loss: 4.25167179107666
Validation loss: 2.716431986513755
Epoch: 9| Step: 7
Training loss: 3.9018163681030273
Validation loss: 2.698692632236069
Epoch: 9| Step: 8
Training loss: 3.4483754634857178
Validation loss: 2.6839963223436754
Epoch: 9| Step: 9
Training loss: 3.4159278869628906
Validation loss: 2.669156757190073
Epoch: 9| Step: 10
Training loss: 2.7030210494995117
Validation loss: 2.654912554102836
Epoch: 9| Step: 11
Training loss: 3.3354525566101074
Validation loss: 2.6396295029482397
Epoch: 9| Step: 12
Training loss: 3.5059456825256348
Validation loss: 2.6287581440356136
Epoch: 9| Step: 13
Training loss: 2.911123752593994
Validation loss: 2.615843025042856
Epoch: 9| Step: 14
Training loss: 2.8346328735351562
Validation loss: 2.601759486918827
Epoch: 9| Step: 15
Training loss: 2.5182461738586426
Validation loss: 2.5857128839698627
Epoch: 9| Step: 16
Training loss: 2.501208782196045
Validation loss: 2.5728227852059784
Epoch: 9| Step: 17
Training loss: 3.3520617485046387
Validation loss: 2.5591278710811256
Epoch: 9| Step: 18
Training loss: 3.5320725440979004
Validation loss: 2.547800444870544
Epoch: 9| Step: 19
Training loss: 2.742762804031372
Validation loss: 2.5329423019354294
Epoch: 10| Step: 0
Training loss: 2.9755663871765137
Validation loss: 2.5198859585274893
Epoch: 9| Step: 1
Training loss: 3.0949525833129883
Validation loss: 2.5103423080855993
Epoch: 9| Step: 2
Training loss: 2.689415454864502
Validation loss: 2.4969126474943093
Epoch: 9| Step: 3
Training loss: 3.353633403778076
Validation loss: 2.488071570293509
Epoch: 9| Step: 4
Training loss: 2.967634439468384
Validation loss: 2.4791621304244447
Epoch: 9| Step: 5
Training loss: 3.030296564102173
Validation loss: 2.458018714575459
Epoch: 9| Step: 6
Training loss: 3.3254168033599854
Validation loss: 2.44055909218548
Epoch: 9| Step: 7
Training loss: 2.8306021690368652
Validation loss: 2.4319755670835645
Epoch: 9| Step: 8
Training loss: 2.633401393890381
Validation loss: 2.4154201874630057
Epoch: 9| Step: 9
Training loss: 2.7144761085510254
Validation loss: 2.395865728529237
Epoch: 9| Step: 10
Training loss: 2.2837116718292236
Validation loss: 2.3925664973773544
Epoch: 9| Step: 11
Training loss: 2.896266222000122
Validation loss: 2.3701461562149815
Epoch: 9| Step: 12
Training loss: 2.630509376525879
Validation loss: 2.3507433023384148
Epoch: 9| Step: 13
Training loss: 2.908304214477539
Validation loss: 2.3507744579864065
Epoch: 9| Step: 14
Training loss: 3.273165225982666
Validation loss: 2.329377724969987
Epoch: 9| Step: 15
Training loss: 2.9852824211120605
Validation loss: 2.311962895256152
Epoch: 9| Step: 16
Training loss: 3.0448710918426514
Validation loss: 2.2953834259252752
Epoch: 9| Step: 17
Training loss: 2.642925977706909
Validation loss: 2.2767127314917475
Epoch: 9| Step: 18
Training loss: 2.9304051399230957
Validation loss: 2.2653564995141338
Epoch: 9| Step: 19
Training loss: 2.8909478187561035
Validation loss: 2.2476869967343998
Epoch: 11| Step: 0
Training loss: 2.7652459144592285
Validation loss: 2.2346442431854685
Epoch: 9| Step: 1
Training loss: 2.8090758323669434
Validation loss: 2.2159329970105945
Epoch: 9| Step: 2
Training loss: 3.117274284362793
Validation loss: 2.2087052871855044
Epoch: 9| Step: 3
Training loss: 3.2414276599884033
Validation loss: 2.1807724314627888
Epoch: 9| Step: 4
Training loss: 2.6450605392456055
Validation loss: 2.1710845000452275
Epoch: 9| Step: 5
Training loss: 1.6506589651107788
Validation loss: 2.1577879713593626
Epoch: 9| Step: 6
Training loss: 2.2488527297973633
Validation loss: 2.141061503252537
Epoch: 9| Step: 7
Training loss: 2.4627609252929688
Validation loss: 2.1340733166221235
Epoch: 9| Step: 8
Training loss: 2.308199882507324
Validation loss: 2.11182516598873
Epoch: 9| Step: 9
Training loss: 2.5445356369018555
Validation loss: 2.096565008163452
Epoch: 9| Step: 10
Training loss: 2.5579946041107178
Validation loss: 2.082734266631037
Epoch: 9| Step: 11
Training loss: 2.5411760807037354
Validation loss: 2.0592046555855292
Epoch: 9| Step: 12
Training loss: 3.0204310417175293
Validation loss: 2.0425805736788742
Epoch: 9| Step: 13
Training loss: 2.5138354301452637
Validation loss: 2.0249853683032577
Epoch: 9| Step: 14
Training loss: 2.216427803039551
Validation loss: 2.0187074709281645
Epoch: 9| Step: 15
Training loss: 2.8319833278656006
Validation loss: 2.004262543410706
Epoch: 9| Step: 16
Training loss: 3.2286441326141357
Validation loss: 1.9808308709439615
Epoch: 9| Step: 17
Training loss: 2.316749095916748
Validation loss: 1.976290618772987
Epoch: 9| Step: 18
Training loss: 2.863846778869629
Validation loss: 1.960088266743173
Epoch: 9| Step: 19
Training loss: 2.321969747543335
Validation loss: 1.948252538125292
Epoch: 12| Step: 0
Training loss: 2.1247904300689697
Validation loss: 1.9266482943253551
Epoch: 9| Step: 1
Training loss: 2.3104631900787354
Validation loss: 1.915034654329149
Epoch: 9| Step: 2
Training loss: 2.2679691314697266
Validation loss: 1.9015017687845572
Epoch: 9| Step: 3
Training loss: 2.858038902282715
Validation loss: 1.8808193901459949
Epoch: 9| Step: 4
Training loss: 2.3611364364624023
Validation loss: 1.8555618027131335
Epoch: 9| Step: 5
Training loss: 2.7809460163116455
Validation loss: 1.8549543327564815
Epoch: 9| Step: 6
Training loss: 1.7844746112823486
Validation loss: 1.8474629182609723
Epoch: 9| Step: 7
Training loss: 2.6934165954589844
Validation loss: 1.8318169983170873
Epoch: 9| Step: 8
Training loss: 2.3617591857910156
Validation loss: 1.834690250081124
Epoch: 9| Step: 9
Training loss: 2.3815274238586426
Validation loss: 1.8206407063298946
Epoch: 9| Step: 10
Training loss: 2.352062225341797
Validation loss: 1.8123876276633721
Epoch: 9| Step: 11
Training loss: 2.037621259689331
Validation loss: 1.7922718919438423
Epoch: 9| Step: 12
Training loss: 1.9203523397445679
Validation loss: 1.8000331430984058
Epoch: 9| Step: 13
Training loss: 2.4241273403167725
Validation loss: 1.7810719150433438
Epoch: 9| Step: 14
Training loss: 1.776875615119934
Validation loss: 1.7779986558200644
Epoch: 9| Step: 15
Training loss: 2.346574068069458
Validation loss: 1.7672455165026
Epoch: 9| Step: 16
Training loss: 2.4744391441345215
Validation loss: 1.770900914137312
Epoch: 9| Step: 17
Training loss: 2.4850573539733887
Validation loss: 1.7569270185429415
Epoch: 9| Step: 18
Training loss: 2.6754255294799805
Validation loss: 1.7623372129399142
Epoch: 9| Step: 19
Training loss: 2.6350793838500977
Validation loss: 1.7540697013731483
Epoch: 13| Step: 0
Training loss: 2.4956789016723633
Validation loss: 1.7371086130896918
Epoch: 9| Step: 1
Training loss: 2.513915538787842
Validation loss: 1.7416390703736448
Epoch: 9| Step: 2
Training loss: 2.893925189971924
Validation loss: 1.7530722986879965
Epoch: 9| Step: 3
Training loss: 1.9608962535858154
Validation loss: 1.7392380190410202
Epoch: 9| Step: 4
Training loss: 1.6119251251220703
Validation loss: 1.7535687976603886
Epoch: 9| Step: 5
Training loss: 2.1075339317321777
Validation loss: 1.738749218501633
Epoch: 9| Step: 6
Training loss: 1.8348461389541626
Validation loss: 1.7534486304084174
Epoch: 9| Step: 7
Training loss: 2.3130452632904053
Validation loss: 1.7411670624780997
Epoch: 9| Step: 8
Training loss: 2.6876564025878906
Validation loss: 1.750649896457041
Epoch: 9| Step: 9
Training loss: 1.442049264907837
Validation loss: 1.739859727646807
Epoch: 9| Step: 10
Training loss: 2.0982162952423096
Validation loss: 1.7476107383803499
Epoch: 9| Step: 11
Training loss: 2.287169933319092
Validation loss: 1.752008812890636
Epoch: 9| Step: 12
Training loss: 2.194767475128174
Validation loss: 1.7630921739468473
Epoch: 9| Step: 13
Training loss: 1.3770283460617065
Validation loss: 1.7679309527651013
Epoch: 9| Step: 14
Training loss: 2.8133554458618164
Validation loss: 1.7630761021332775
Epoch: 9| Step: 15
Training loss: 2.0561389923095703
Validation loss: 1.766472509439043
Epoch: 9| Step: 16
Training loss: 2.5236024856567383
Validation loss: 1.7871357391206482
Epoch: 9| Step: 17
Training loss: 1.7092576026916504
Validation loss: 1.7728295394842573
Epoch: 9| Step: 18
Training loss: 2.4892568588256836
Validation loss: 1.7778257320253112
Epoch: 9| Step: 19
Training loss: 2.394796371459961
Validation loss: 1.775464844360626
Epoch: 14| Step: 0
Training loss: 2.1110129356384277
Validation loss: 1.7867416949580899
Epoch: 9| Step: 1
Training loss: 1.1622179746627808
Validation loss: 1.796325416016064
Epoch: 9| Step: 2
Training loss: 2.926287889480591
Validation loss: 1.8204474800782238
Epoch: 9| Step: 3
Training loss: 2.3744454383850098
Validation loss: 1.8224783921413283
Epoch: 9| Step: 4
Training loss: 2.6250643730163574
Validation loss: 1.825103548790911
Epoch: 9| Step: 5
Training loss: 1.9370533227920532
Validation loss: 1.8239606979081957
Epoch: 9| Step: 6
Training loss: 2.4724650382995605
Validation loss: 1.846875746473134
Epoch: 9| Step: 7
Training loss: 1.995989441871643
Validation loss: 1.8283863153389033
Epoch: 9| Step: 8
Training loss: 2.128012180328369
Validation loss: 1.8492879764639216
Epoch: 9| Step: 9
Training loss: 1.9150941371917725
Validation loss: 1.8411917918020015
Epoch: 9| Step: 10
Training loss: 2.179250478744507
Validation loss: 1.8624870545572514
Epoch: 9| Step: 11
Training loss: 2.1632003784179688
Validation loss: 1.8584453201980042
Epoch: 9| Step: 12
Training loss: 2.008498430252075
Validation loss: 1.8471619997093145
Epoch: 9| Step: 13
Training loss: 2.1548423767089844
Validation loss: 1.8617715475370558
Epoch: 9| Step: 14
Training loss: 2.103877067565918
Validation loss: 1.8553483057365143
Epoch: 9| Step: 15
Training loss: 1.705320119857788
Validation loss: 1.8765938736551957
Epoch: 9| Step: 16
Training loss: 1.5412651300430298
Validation loss: 1.8576342562119739
Epoch: 9| Step: 17
Training loss: 2.404226303100586
Validation loss: 1.872848889810576
Epoch: 9| Step: 18
Training loss: 1.8031394481658936
Validation loss: 1.8765455321442308
Epoch: 9| Step: 19
Training loss: 2.6679635047912598
Validation loss: 1.8732850997568034
Epoch: 15| Step: 0
Training loss: 1.956854224205017
Validation loss: 1.878925769449138
Epoch: 9| Step: 1
Training loss: 2.036928176879883
Validation loss: 1.8913428766264333
Epoch: 9| Step: 2
Training loss: 1.3320938348770142
Validation loss: 1.889361708284282
Epoch: 9| Step: 3
Training loss: 1.3611282110214233
Validation loss: 1.8781117569628378
Epoch: 9| Step: 4
Training loss: 1.7197726964950562
Validation loss: 1.8673798986476102
Epoch: 9| Step: 5
Training loss: 2.031630754470825
Validation loss: 1.8739759441759947
Epoch: 9| Step: 6
Training loss: 2.099180221557617
Validation loss: 1.8690305322194272
Epoch: 9| Step: 7
Training loss: 2.262500762939453
Validation loss: 1.8850774696404986
Epoch: 9| Step: 8
Training loss: 2.4072422981262207
Validation loss: 1.8643776907337655
Epoch: 9| Step: 9
Training loss: 2.4871420860290527
Validation loss: 1.8736155702055788
Epoch: 9| Step: 10
Training loss: 1.9476008415222168
Validation loss: 1.8611857753863437
Epoch: 9| Step: 11
Training loss: 2.0306878089904785
Validation loss: 1.8879748797245164
Epoch: 9| Step: 12
Training loss: 1.9520796537399292
Validation loss: 1.8560512048735036
Epoch: 9| Step: 13
Training loss: 2.483184337615967
Validation loss: 1.8731310204636278
Epoch: 9| Step: 14
Training loss: 2.628176212310791
Validation loss: 1.8548414226916197
Epoch: 9| Step: 15
Training loss: 2.7577784061431885
Validation loss: 1.8826623537557587
Epoch: 9| Step: 16
Training loss: 2.2416465282440186
Validation loss: 1.858925582693635
Epoch: 9| Step: 17
Training loss: 1.9435564279556274
Validation loss: 1.8663309323701927
Epoch: 9| Step: 18
Training loss: 2.165505886077881
Validation loss: 1.863372722118021
Epoch: 9| Step: 19
Training loss: 2.4042556285858154
Validation loss: 1.8562707901000977
Epoch: 16| Step: 0
Training loss: 1.6424734592437744
Validation loss: 1.862777922650893
Epoch: 9| Step: 1
Training loss: 1.9926528930664062
Validation loss: 1.8505809247064933
Epoch: 9| Step: 2
Training loss: 1.6865354776382446
Validation loss: 1.8622134675224908
Epoch: 9| Step: 3
Training loss: 1.7995200157165527
Validation loss: 1.8446345826704724
Epoch: 9| Step: 4
Training loss: 1.4449422359466553
Validation loss: 1.8394301889611662
Epoch: 9| Step: 5
Training loss: 2.6624412536621094
Validation loss: 1.8457562443163755
Epoch: 9| Step: 6
Training loss: 1.7711881399154663
Validation loss: 1.8348602862666836
Epoch: 9| Step: 7
Training loss: 2.3093881607055664
Validation loss: 1.8593279603573916
Epoch: 9| Step: 8
Training loss: 1.7559919357299805
Validation loss: 1.8408329958538356
Epoch: 9| Step: 9
Training loss: 2.1780588626861572
Validation loss: 1.852948646751239
Epoch: 9| Step: 10
Training loss: 1.8779276609420776
Validation loss: 1.8473382553608297
Epoch: 9| Step: 11
Training loss: 2.4587745666503906
Validation loss: 1.841908582680517
Epoch: 9| Step: 12
Training loss: 2.5129990577697754
Validation loss: 1.8403628301277435
Epoch: 9| Step: 13
Training loss: 2.4292142391204834
Validation loss: 1.8654135388436077
Epoch: 9| Step: 14
Training loss: 2.4694273471832275
Validation loss: 1.8536771741702402
Epoch: 9| Step: 15
Training loss: 2.1039180755615234
Validation loss: 1.8515079012877649
Epoch: 9| Step: 16
Training loss: 2.582901954650879
Validation loss: 1.8356532947622615
Epoch: 9| Step: 17
Training loss: 2.357433319091797
Validation loss: 1.8363687760538334
Epoch: 9| Step: 18
Training loss: 2.0222396850585938
Validation loss: 1.8585704299185772
Epoch: 9| Step: 19
Training loss: 1.9564526081085205
Validation loss: 1.8412567128380426
Epoch: 17| Step: 0
Training loss: 2.9127187728881836
Validation loss: 1.8493669521894387
Epoch: 9| Step: 1
Training loss: 2.17441463470459
Validation loss: 1.8487743156419383
Epoch: 9| Step: 2
Training loss: 2.407024383544922
Validation loss: 1.857105016708374
Epoch: 9| Step: 3
Training loss: 1.8995163440704346
Validation loss: 1.8325245560501977
Epoch: 9| Step: 4
Training loss: 2.328887701034546
Validation loss: 1.852606137879461
Epoch: 9| Step: 5
Training loss: 1.7195460796356201
Validation loss: 1.849936041042959
Epoch: 9| Step: 6
Training loss: 1.9061837196350098
Validation loss: 1.844918937134228
Epoch: 9| Step: 7
Training loss: 2.2658398151397705
Validation loss: 1.845322968290864
Epoch: 9| Step: 8
Training loss: 1.9240474700927734
Validation loss: 1.8392036304199437
Epoch: 9| Step: 9
Training loss: 1.6686930656433105
Validation loss: 1.8287654557674051
Epoch: 9| Step: 10
Training loss: 1.5006985664367676
Validation loss: 1.8306472936122538
Epoch: 9| Step: 11
Training loss: 1.551389455795288
Validation loss: 1.8332241945129504
Epoch: 9| Step: 12
Training loss: 2.4480302333831787
Validation loss: 1.8278618810845793
Epoch: 9| Step: 13
Training loss: 2.531940460205078
Validation loss: 1.827405159421962
Epoch: 9| Step: 14
Training loss: 2.269078254699707
Validation loss: 1.8167748198234777
Epoch: 9| Step: 15
Training loss: 2.0578927993774414
Validation loss: 1.8396557492317913
Epoch: 9| Step: 16
Training loss: 2.2531721591949463
Validation loss: 1.8314816454331653
Epoch: 9| Step: 17
Training loss: 2.2483038902282715
Validation loss: 1.8295805831607297
Epoch: 9| Step: 18
Training loss: 2.119229793548584
Validation loss: 1.8526403603793906
Epoch: 9| Step: 19
Training loss: 1.7646329402923584
Validation loss: 1.8538187544980496
Epoch: 18| Step: 0
Training loss: 1.7438559532165527
Validation loss: 1.8379056204994806
Epoch: 9| Step: 1
Training loss: 1.8460805416107178
Validation loss: 1.8484048534640305
Epoch: 9| Step: 2
Training loss: 1.7174615859985352
Validation loss: 1.8523302103975694
Epoch: 9| Step: 3
Training loss: 1.9382420778274536
Validation loss: 1.873538705942442
Epoch: 9| Step: 4
Training loss: 2.3113327026367188
Validation loss: 1.8752510290351703
Epoch: 9| Step: 5
Training loss: 1.2737327814102173
Validation loss: 1.8652068179288357
Epoch: 9| Step: 6
Training loss: 2.2987077236175537
Validation loss: 1.8865303933191642
Epoch: 9| Step: 7
Training loss: 2.099022626876831
Validation loss: 1.8782284654301704
Epoch: 9| Step: 8
Training loss: 2.1873741149902344
Validation loss: 1.875387551115571
Epoch: 9| Step: 9
Training loss: 3.0213699340820312
Validation loss: 1.8915740019983525
Epoch: 9| Step: 10
Training loss: 1.442178726196289
Validation loss: 1.8745501684627945
Epoch: 9| Step: 11
Training loss: 2.3510050773620605
Validation loss: 1.8815794780099993
Epoch: 9| Step: 12
Training loss: 1.980543613433838
Validation loss: 1.8714925247988254
Epoch: 9| Step: 13
Training loss: 2.3083341121673584
Validation loss: 1.860418426904747
Epoch: 9| Step: 14
Training loss: 1.7403767108917236
Validation loss: 1.8697010055720378
Epoch: 9| Step: 15
Training loss: 1.9915087223052979
Validation loss: 1.8813150083418373
Epoch: 9| Step: 16
Training loss: 2.350189208984375
Validation loss: 1.8737943524079357
Epoch: 9| Step: 17
Training loss: 2.434250831604004
Validation loss: 1.8631616221915046
Epoch: 9| Step: 18
Training loss: 2.183795928955078
Validation loss: 1.8644712417245768
Epoch: 9| Step: 19
Training loss: 2.7743077278137207
Validation loss: 1.8527717693246526
Epoch: 19| Step: 0
Training loss: 2.411437511444092
Validation loss: 1.858646184420414
Epoch: 9| Step: 1
Training loss: 1.3247157335281372
Validation loss: 1.8515135084124779
Epoch: 9| Step: 2
Training loss: 1.6778701543807983
Validation loss: 1.877325857285973
Epoch: 9| Step: 3
Training loss: 2.091761589050293
Validation loss: 1.8724539820238841
Epoch: 9| Step: 4
Training loss: 1.7179068326950073
Validation loss: 1.8700658554653469
Epoch: 9| Step: 5
Training loss: 2.143259286880493
Validation loss: 1.8639864304082856
Epoch: 9| Step: 6
Training loss: 2.365345001220703
Validation loss: 1.867434668026382
Epoch: 9| Step: 7
Training loss: 2.62514591217041
Validation loss: 1.8717433154154166
Epoch: 9| Step: 8
Training loss: 2.8959407806396484
Validation loss: 1.8851871336106774
Epoch: 9| Step: 9
Training loss: 1.6490068435668945
Validation loss: 1.8803754264502217
Epoch: 9| Step: 10
Training loss: 1.8971405029296875
Validation loss: 1.8928385810028734
Epoch: 9| Step: 11
Training loss: 2.7872211933135986
Validation loss: 1.8720791219807358
Epoch: 9| Step: 12
Training loss: 1.9722415208816528
Validation loss: 1.8688332245504256
Epoch: 9| Step: 13
Training loss: 2.270780563354492
Validation loss: 1.857644864981123
Epoch: 9| Step: 14
Training loss: 2.2526538372039795
Validation loss: 1.8734034411341167
Epoch: 9| Step: 15
Training loss: 1.9923495054244995
Validation loss: 1.8624990449534904
Epoch: 9| Step: 16
Training loss: 2.4280917644500732
Validation loss: 1.8542733767049775
Epoch: 9| Step: 17
Training loss: 1.9311778545379639
Validation loss: 1.8477084302216125
Epoch: 9| Step: 18
Training loss: 1.489354133605957
Validation loss: 1.8418211010720233
Epoch: 9| Step: 19
Training loss: 1.8398797512054443
Validation loss: 1.8452000060527445
Epoch: 20| Step: 0
Training loss: 2.441753387451172
Validation loss: 1.8380937104602513
Epoch: 9| Step: 1
Training loss: 1.9175519943237305
Validation loss: 1.8340295441716694
Epoch: 9| Step: 2
Training loss: 1.6580880880355835
Validation loss: 1.8348744301487216
Epoch: 9| Step: 3
Training loss: 2.1903014183044434
Validation loss: 1.8450469593349978
Epoch: 9| Step: 4
Training loss: 2.1389989852905273
Validation loss: 1.8451794257266916
Epoch: 9| Step: 5
Training loss: 1.8091986179351807
Validation loss: 1.86098163162204
Epoch: 9| Step: 6
Training loss: 1.9775372743606567
Validation loss: 1.85916550639722
Epoch: 9| Step: 7
Training loss: 1.8625162839889526
Validation loss: 1.8451108289279525
Epoch: 9| Step: 8
Training loss: 2.084674835205078
Validation loss: 1.8557418550518776
Epoch: 9| Step: 9
Training loss: 2.068509578704834
Validation loss: 1.860058020344741
Epoch: 9| Step: 10
Training loss: 2.239955425262451
Validation loss: 1.8542334947654668
Epoch: 9| Step: 11
Training loss: 2.695230722427368
Validation loss: 1.8676928907847232
Epoch: 9| Step: 12
Training loss: 2.8458404541015625
Validation loss: 1.8578046937640622
Epoch: 9| Step: 13
Training loss: 1.5991311073303223
Validation loss: 1.8652011636349795
Epoch: 9| Step: 14
Training loss: 1.8651039600372314
Validation loss: 1.8696435544130614
Epoch: 9| Step: 15
Training loss: 1.8627650737762451
Validation loss: 1.8770462377465886
Epoch: 9| Step: 16
Training loss: 1.94681978225708
Validation loss: 1.8818887943844143
Epoch: 9| Step: 17
Training loss: 2.2522478103637695
Validation loss: 1.8698686841580507
Epoch: 9| Step: 18
Training loss: 1.7440156936645508
Validation loss: 1.8818316879889947
Epoch: 9| Step: 19
Training loss: 2.6457977294921875
Validation loss: 1.8596242014452709
Epoch: 21| Step: 0
Training loss: 2.160097599029541
Validation loss: 1.872051254450846
Epoch: 9| Step: 1
Training loss: 1.9999243021011353
Validation loss: 1.8776370518499141
Epoch: 9| Step: 2
Training loss: 2.522282123565674
Validation loss: 1.8865164475475285
Epoch: 9| Step: 3
Training loss: 1.990342140197754
Validation loss: 1.856162036065575
Epoch: 9| Step: 4
Training loss: 1.9172413349151611
Validation loss: 1.8552148239218074
Epoch: 9| Step: 5
Training loss: 2.0992820262908936
Validation loss: 1.8402008101236906
Epoch: 9| Step: 6
Training loss: 1.5951080322265625
Validation loss: 1.835040387489813
Epoch: 9| Step: 7
Training loss: 1.9177229404449463
Validation loss: 1.8546555453924825
Epoch: 9| Step: 8
Training loss: 1.6906543970108032
Validation loss: 1.8304038699582326
Epoch: 9| Step: 9
Training loss: 1.4684157371520996
Validation loss: 1.8541229800354662
Epoch: 9| Step: 10
Training loss: 2.374685764312744
Validation loss: 1.857834475503551
Epoch: 9| Step: 11
Training loss: 2.2020015716552734
Validation loss: 1.8457411261771222
Epoch: 9| Step: 12
Training loss: 2.2269458770751953
Validation loss: 1.8534587767484376
Epoch: 9| Step: 13
Training loss: 2.1595849990844727
Validation loss: 1.839807358577097
Epoch: 9| Step: 14
Training loss: 2.273770809173584
Validation loss: 1.844443909555888
Epoch: 9| Step: 15
Training loss: 2.3100152015686035
Validation loss: 1.8387062866910755
Epoch: 9| Step: 16
Training loss: 1.9187500476837158
Validation loss: 1.8426664870419949
Epoch: 9| Step: 17
Training loss: 2.7655789852142334
Validation loss: 1.8423007143487176
Epoch: 9| Step: 18
Training loss: 2.397722005844116
Validation loss: 1.8440024578314034
Epoch: 9| Step: 19
Training loss: 1.6792219877243042
Validation loss: 1.835728216514313
Epoch: 22| Step: 0
Training loss: 2.386584758758545
Validation loss: 1.8383513243078329
Epoch: 9| Step: 1
Training loss: 2.0466105937957764
Validation loss: 1.8494026180651548
Epoch: 9| Step: 2
Training loss: 2.1060612201690674
Validation loss: 1.8351992360121911
Epoch: 9| Step: 3
Training loss: 2.399685859680176
Validation loss: 1.8405876828612184
Epoch: 9| Step: 4
Training loss: 1.288966417312622
Validation loss: 1.8420598695604065
Epoch: 9| Step: 5
Training loss: 2.62095308303833
Validation loss: 1.8431684833636386
Epoch: 9| Step: 6
Training loss: 2.054408311843872
Validation loss: 1.8519806724658114
Epoch: 9| Step: 7
Training loss: 1.904966115951538
Validation loss: 1.8465374545227708
Epoch: 9| Step: 8
Training loss: 2.022697687149048
Validation loss: 1.8283568226176201
Epoch: 9| Step: 9
Training loss: 1.8163894414901733
Validation loss: 1.850640844098098
Epoch: 9| Step: 10
Training loss: 1.737989068031311
Validation loss: 1.8453552208358435
Epoch: 9| Step: 11
Training loss: 2.0161314010620117
Validation loss: 1.8481135737124106
Epoch: 9| Step: 12
Training loss: 1.8272175788879395
Validation loss: 1.8553331292790474
Epoch: 9| Step: 13
Training loss: 2.1070241928100586
Validation loss: 1.8581830177375738
Epoch: 9| Step: 14
Training loss: 2.1719131469726562
Validation loss: 1.8451063530050593
Epoch: 9| Step: 15
Training loss: 2.2410147190093994
Validation loss: 1.8573806766125796
Epoch: 9| Step: 16
Training loss: 2.1521103382110596
Validation loss: 1.8660367907380029
Epoch: 9| Step: 17
Training loss: 2.4648029804229736
Validation loss: 1.8640021763259558
Epoch: 9| Step: 18
Training loss: 2.680818557739258
Validation loss: 1.8815544088967413
Epoch: 9| Step: 19
Training loss: 1.4200921058654785
Validation loss: 1.8554205131187713
Epoch: 23| Step: 0
Training loss: 1.997727632522583
Validation loss: 1.8587367002912563
Epoch: 9| Step: 1
Training loss: 2.30558443069458
Validation loss: 1.8646727706030977
Epoch: 9| Step: 2
Training loss: 1.9957722425460815
Validation loss: 1.8558285768083531
Epoch: 9| Step: 3
Training loss: 2.0465619564056396
Validation loss: 1.8747308014108122
Epoch: 9| Step: 4
Training loss: 2.336491107940674
Validation loss: 1.8687291419763359
Epoch: 9| Step: 5
Training loss: 1.754189372062683
Validation loss: 1.860889075471343
Epoch: 9| Step: 6
Training loss: 2.0722904205322266
Validation loss: 1.8632399469828433
Epoch: 9| Step: 7
Training loss: 2.2658557891845703
Validation loss: 1.8759436127093199
Epoch: 9| Step: 8
Training loss: 2.3284497261047363
Validation loss: 1.868412400321137
Epoch: 9| Step: 9
Training loss: 2.219627618789673
Validation loss: 1.885755990906585
Epoch: 9| Step: 10
Training loss: 1.801568627357483
Validation loss: 1.8692703761642786
Epoch: 9| Step: 11
Training loss: 2.079801082611084
Validation loss: 1.8821721505775726
Epoch: 9| Step: 12
Training loss: 1.5152082443237305
Validation loss: 1.8789923388323337
Epoch: 9| Step: 13
Training loss: 2.5102152824401855
Validation loss: 1.8907552940382375
Epoch: 9| Step: 14
Training loss: 2.4998111724853516
Validation loss: 1.8957597883485204
Epoch: 9| Step: 15
Training loss: 2.451315402984619
Validation loss: 1.8870461836135646
Epoch: 9| Step: 16
Training loss: 2.1230530738830566
Validation loss: 1.8879740924286328
Epoch: 9| Step: 17
Training loss: 2.006466865539551
Validation loss: 1.8628256269496122
Epoch: 9| Step: 18
Training loss: 1.551010251045227
Validation loss: 1.8727730495466604
Epoch: 9| Step: 19
Training loss: 1.875577688217163
Validation loss: 1.862656940659173
Epoch: 24| Step: 0
Training loss: 1.5225677490234375
Validation loss: 1.8675861358642578
Epoch: 9| Step: 1
Training loss: 2.1096601486206055
Validation loss: 1.859541205193499
Epoch: 9| Step: 2
Training loss: 2.057760238647461
Validation loss: 1.8717945033697774
Epoch: 9| Step: 3
Training loss: 1.8482071161270142
Validation loss: 1.884503086693853
Epoch: 9| Step: 4
Training loss: 2.2994720935821533
Validation loss: 1.898657725869323
Epoch: 9| Step: 5
Training loss: 2.735154628753662
Validation loss: 1.881319142931657
Epoch: 9| Step: 6
Training loss: 2.4470291137695312
Validation loss: 1.876718436213706
Epoch: 9| Step: 7
Training loss: 2.404299020767212
Validation loss: 1.8914159647852398
Epoch: 9| Step: 8
Training loss: 2.7390472888946533
Validation loss: 1.889115009376471
Epoch: 9| Step: 9
Training loss: 1.9602019786834717
Validation loss: 1.8861701171175183
Epoch: 9| Step: 10
Training loss: 1.4015531539916992
Validation loss: 1.8923673904199394
Epoch: 9| Step: 11
Training loss: 2.4102983474731445
Validation loss: 1.8690507514871282
Epoch: 9| Step: 12
Training loss: 1.9323488473892212
Validation loss: 1.8713929807539467
Epoch: 9| Step: 13
Training loss: 2.172358989715576
Validation loss: 1.880971414579762
Epoch: 9| Step: 14
Training loss: 1.8852723836898804
Validation loss: 1.868835898612043
Epoch: 9| Step: 15
Training loss: 2.1993236541748047
Validation loss: 1.8721806128248035
Epoch: 9| Step: 16
Training loss: 1.8820074796676636
Validation loss: 1.869538847491038
Epoch: 9| Step: 17
Training loss: 1.2495813369750977
Validation loss: 1.859768891506058
Epoch: 9| Step: 18
Training loss: 2.618281841278076
Validation loss: 1.875809138627361
Epoch: 9| Step: 19
Training loss: 1.6572625637054443
Validation loss: 1.871480107307434
Epoch: 25| Step: 0
Training loss: 2.3275721073150635
Validation loss: 1.8728749083100462
Epoch: 9| Step: 1
Training loss: 2.166839122772217
Validation loss: 1.8544859731797692
Epoch: 9| Step: 2
Training loss: 2.0487163066864014
Validation loss: 1.8590910589094642
Epoch: 9| Step: 3
Training loss: 2.3773860931396484
Validation loss: 1.8779795006882372
Epoch: 9| Step: 4
Training loss: 1.7949233055114746
Validation loss: 1.8847587082883437
Epoch: 9| Step: 5
Training loss: 1.7238435745239258
Validation loss: 1.872421367562932
Epoch: 9| Step: 6
Training loss: 1.9886624813079834
Validation loss: 1.8591435084240042
Epoch: 9| Step: 7
Training loss: 2.0356075763702393
Validation loss: 1.8767566946770649
Epoch: 9| Step: 8
Training loss: 2.0350797176361084
Validation loss: 1.8825991205174288
Epoch: 9| Step: 9
Training loss: 2.6330251693725586
Validation loss: 1.8759850889658756
Epoch: 9| Step: 10
Training loss: 2.7239503860473633
Validation loss: 1.8652981039431455
Epoch: 9| Step: 11
Training loss: 2.0571765899658203
Validation loss: 1.8585706477542576
Epoch: 9| Step: 12
Training loss: 2.273576498031616
Validation loss: 1.85735097034372
Epoch: 9| Step: 13
Training loss: 2.1596059799194336
Validation loss: 1.839768109561728
Epoch: 9| Step: 14
Training loss: 1.5790072679519653
Validation loss: 1.8517682209289332
Epoch: 9| Step: 15
Training loss: 1.5295697450637817
Validation loss: 1.8569838820601539
Epoch: 9| Step: 16
Training loss: 1.968721866607666
Validation loss: 1.8507876344721952
Epoch: 9| Step: 17
Training loss: 1.7424606084823608
Validation loss: 1.8472007633113174
Epoch: 9| Step: 18
Training loss: 1.8187564611434937
Validation loss: 1.863293904194729
Epoch: 9| Step: 19
Training loss: 2.523371696472168
Validation loss: 1.8688795206358106
Epoch: 26| Step: 0
Training loss: 1.8059372901916504
Validation loss: 1.853797289964964
Epoch: 9| Step: 1
Training loss: 1.9333454370498657
Validation loss: 1.8629876452384235
Epoch: 9| Step: 2
Training loss: 1.8632099628448486
Validation loss: 1.8595748187826693
Epoch: 9| Step: 3
Training loss: 2.8939404487609863
Validation loss: 1.8626397222066098
Epoch: 9| Step: 4
Training loss: 2.231550455093384
Validation loss: 1.8668246680884053
Epoch: 9| Step: 5
Training loss: 2.328031063079834
Validation loss: 1.874954686748038
Epoch: 9| Step: 6
Training loss: 2.4209916591644287
Validation loss: 1.8839942920122215
Epoch: 9| Step: 7
Training loss: 1.826441764831543
Validation loss: 1.8862972379588394
Epoch: 9| Step: 8
Training loss: 2.088132381439209
Validation loss: 1.8726150697941402
Epoch: 9| Step: 9
Training loss: 2.0590639114379883
Validation loss: 1.8800933215257933
Epoch: 9| Step: 10
Training loss: 2.4670894145965576
Validation loss: 1.8818627733120816
Epoch: 9| Step: 11
Training loss: 1.7571563720703125
Validation loss: 1.8656478905849319
Epoch: 9| Step: 12
Training loss: 2.3665974140167236
Validation loss: 1.8701911092662125
Epoch: 9| Step: 13
Training loss: 1.5863919258117676
Validation loss: 1.8579878729882
Epoch: 9| Step: 14
Training loss: 1.9828025102615356
Validation loss: 1.867696409602817
Epoch: 9| Step: 15
Training loss: 1.5408309698104858
Validation loss: 1.8677836493622484
Epoch: 9| Step: 16
Training loss: 1.3905739784240723
Validation loss: 1.8778455746259621
Epoch: 9| Step: 17
Training loss: 2.571451425552368
Validation loss: 1.8694303344479568
Epoch: 9| Step: 18
Training loss: 2.0136098861694336
Validation loss: 1.8944539938041631
Epoch: 9| Step: 19
Training loss: 2.0662436485290527
Validation loss: 1.881256621518581
Epoch: 27| Step: 0
Training loss: 2.6828088760375977
Validation loss: 1.8839108952515418
Epoch: 9| Step: 1
Training loss: 2.3285961151123047
Validation loss: 1.8766626522695418
Epoch: 9| Step: 2
Training loss: 2.395111083984375
Validation loss: 1.8754117934823893
Epoch: 9| Step: 3
Training loss: 1.476995825767517
Validation loss: 1.8962992849967462
Epoch: 9| Step: 4
Training loss: 1.962651252746582
Validation loss: 1.8862588071137023
Epoch: 9| Step: 5
Training loss: 1.511474847793579
Validation loss: 1.8637570117017348
Epoch: 9| Step: 6
Training loss: 1.9920461177825928
Validation loss: 1.880434581701704
Epoch: 9| Step: 7
Training loss: 1.592350721359253
Validation loss: 1.884877806087192
Epoch: 9| Step: 8
Training loss: 2.008331537246704
Validation loss: 1.886151841218523
Epoch: 9| Step: 9
Training loss: 2.2416296005249023
Validation loss: 1.905959270840926
Epoch: 9| Step: 10
Training loss: 2.2326135635375977
Validation loss: 1.8849725706114187
Epoch: 9| Step: 11
Training loss: 2.332923650741577
Validation loss: 1.901818733421161
Epoch: 9| Step: 12
Training loss: 2.7120518684387207
Validation loss: 1.9126499462470734
Epoch: 9| Step: 13
Training loss: 1.9581905603408813
Validation loss: 1.9007529843625406
Epoch: 9| Step: 14
Training loss: 2.7269229888916016
Validation loss: 1.8894867811271612
Epoch: 9| Step: 15
Training loss: 2.4688947200775146
Validation loss: 1.8986673037782849
Epoch: 9| Step: 16
Training loss: 2.1885557174682617
Validation loss: 1.902914836252336
Epoch: 9| Step: 17
Training loss: 1.603834867477417
Validation loss: 1.9012686108513701
Epoch: 9| Step: 18
Training loss: 1.4205152988433838
Validation loss: 1.909109564993879
Epoch: 9| Step: 19
Training loss: 1.4200550317764282
Validation loss: 1.903652111403376
Epoch: 28| Step: 0
Training loss: 2.1353635787963867
Validation loss: 1.9025627897797728
Epoch: 9| Step: 1
Training loss: 1.7886922359466553
Validation loss: 1.880995872209398
Epoch: 9| Step: 2
Training loss: 2.034886121749878
Validation loss: 1.8915849340905388
Epoch: 9| Step: 3
Training loss: 1.6346015930175781
Validation loss: 1.8988352756706073
Epoch: 9| Step: 4
Training loss: 2.1579177379608154
Validation loss: 1.876812830245752
Epoch: 9| Step: 5
Training loss: 2.4575815200805664
Validation loss: 1.877485808708685
Epoch: 9| Step: 6
Training loss: 2.1921045780181885
Validation loss: 1.893762538758971
Epoch: 9| Step: 7
Training loss: 1.927290678024292
Validation loss: 1.886016768517254
Epoch: 9| Step: 8
Training loss: 2.461735248565674
Validation loss: 1.8899450387886103
Epoch: 9| Step: 9
Training loss: 2.035386800765991
Validation loss: 1.876528319695013
Epoch: 9| Step: 10
Training loss: 1.6579303741455078
Validation loss: 1.8663323337225606
Epoch: 9| Step: 11
Training loss: 1.7843354940414429
Validation loss: 1.8796796438505323
Epoch: 9| Step: 12
Training loss: 1.4530150890350342
Validation loss: 1.8764745854645324
Epoch: 9| Step: 13
Training loss: 1.9639708995819092
Validation loss: 1.8851840436029776
Epoch: 9| Step: 14
Training loss: 2.3053345680236816
Validation loss: 1.8703234521605128
Epoch: 9| Step: 15
Training loss: 2.4525251388549805
Validation loss: 1.8812516824804622
Epoch: 9| Step: 16
Training loss: 1.9013251066207886
Validation loss: 1.8682202229396903
Epoch: 9| Step: 17
Training loss: 1.9392194747924805
Validation loss: 1.8754655131333167
Epoch: 9| Step: 18
Training loss: 2.3560338020324707
Validation loss: 1.8692696128817772
Epoch: 9| Step: 19
Training loss: 2.45823335647583
Validation loss: 1.8667546948083014
Epoch: 29| Step: 0
Training loss: 2.4125828742980957
Validation loss: 1.8801773632173058
Epoch: 9| Step: 1
Training loss: 1.4741822481155396
Validation loss: 1.8774899270037095
Epoch: 9| Step: 2
Training loss: 1.7656795978546143
Validation loss: 1.846166390309231
Epoch: 9| Step: 3
Training loss: 2.3544607162475586
Validation loss: 1.8706110055498082
Epoch: 9| Step: 4
Training loss: 1.8486791849136353
Validation loss: 1.8696799775679334
Epoch: 9| Step: 5
Training loss: 2.256274700164795
Validation loss: 1.864952372990066
Epoch: 9| Step: 6
Training loss: 2.2641513347625732
Validation loss: 1.8791772341556687
Epoch: 9| Step: 7
Training loss: 3.163292407989502
Validation loss: 1.87258525374982
Epoch: 9| Step: 8
Training loss: 2.039351463317871
Validation loss: 1.869594288386887
Epoch: 9| Step: 9
Training loss: 2.1783013343811035
Validation loss: 1.8624094475945123
Epoch: 9| Step: 10
Training loss: 2.307396411895752
Validation loss: 1.8562337803326066
Epoch: 9| Step: 11
Training loss: 2.1306803226470947
Validation loss: 1.8653143421351481
Epoch: 9| Step: 12
Training loss: 1.8573319911956787
Validation loss: 1.8505670972865262
Epoch: 9| Step: 13
Training loss: 2.0198254585266113
Validation loss: 1.858699002711893
Epoch: 9| Step: 14
Training loss: 2.5155601501464844
Validation loss: 1.8707005445905727
Epoch: 9| Step: 15
Training loss: 1.4811432361602783
Validation loss: 1.8655245578546318
Epoch: 9| Step: 16
Training loss: 1.8421744108200073
Validation loss: 1.8590588295202461
Epoch: 9| Step: 17
Training loss: 2.025486469268799
Validation loss: 1.8609367617600256
Epoch: 9| Step: 18
Training loss: 1.7305210828781128
Validation loss: 1.8679785102391415
Epoch: 9| Step: 19
Training loss: 1.610626220703125
Validation loss: 1.8582343128945331
Epoch: 30| Step: 0
Training loss: 1.2500929832458496
Validation loss: 1.8836605120048249
Epoch: 9| Step: 1
Training loss: 1.7292968034744263
Validation loss: 1.8852514311564055
Epoch: 9| Step: 2
Training loss: 2.0009520053863525
Validation loss: 1.8730099398455173
Epoch: 9| Step: 3
Training loss: 2.0752222537994385
Validation loss: 1.882088781260758
Epoch: 9| Step: 4
Training loss: 2.2404544353485107
Validation loss: 1.885356837896992
Epoch: 9| Step: 5
Training loss: 1.6726263761520386
Validation loss: 1.8751074084275061
Epoch: 9| Step: 6
Training loss: 1.8709702491760254
Validation loss: 1.8743711881500353
Epoch: 9| Step: 7
Training loss: 3.4150853157043457
Validation loss: 1.87796001468631
Epoch: 9| Step: 8
Training loss: 1.6202343702316284
Validation loss: 1.8792210620084255
Epoch: 9| Step: 9
Training loss: 1.995976448059082
Validation loss: 1.8739083182039877
Epoch: 9| Step: 10
Training loss: 2.327484130859375
Validation loss: 1.856728666120296
Epoch: 9| Step: 11
Training loss: 1.7271310091018677
Validation loss: 1.8628947563308607
Epoch: 9| Step: 12
Training loss: 1.5245023965835571
Validation loss: 1.8688514524226567
Epoch: 9| Step: 13
Training loss: 1.694566249847412
Validation loss: 1.8660469038023366
Epoch: 9| Step: 14
Training loss: 2.6085410118103027
Validation loss: 1.8672169198235162
Epoch: 9| Step: 15
Training loss: 2.195070743560791
Validation loss: 1.8582303575474581
Epoch: 9| Step: 16
Training loss: 2.270328998565674
Validation loss: 1.8544038954398614
Epoch: 9| Step: 17
Training loss: 2.262005567550659
Validation loss: 1.8582685988584011
Epoch: 9| Step: 18
Training loss: 2.9092559814453125
Validation loss: 1.8738958200962423
Epoch: 9| Step: 19
Training loss: 1.5976604223251343
Validation loss: 1.861669360304908
Epoch: 31| Step: 0
Training loss: 3.1940228939056396
Validation loss: 1.861579495368244
Epoch: 9| Step: 1
Training loss: 2.32535982131958
Validation loss: 1.8738100108482856
Epoch: 9| Step: 2
Training loss: 1.4424488544464111
Validation loss: 1.8811670773320919
Epoch: 9| Step: 3
Training loss: 1.7819446325302124
Validation loss: 1.8884043710694896
Epoch: 9| Step: 4
Training loss: 1.6590052843093872
Validation loss: 1.8864244076845458
Epoch: 9| Step: 5
Training loss: 2.5403871536254883
Validation loss: 1.8918666196384017
Epoch: 9| Step: 6
Training loss: 1.6245720386505127
Validation loss: 1.9081942494824635
Epoch: 9| Step: 7
Training loss: 1.803032398223877
Validation loss: 1.89102786050426
Epoch: 9| Step: 8
Training loss: 2.1095287799835205
Validation loss: 1.8917795402540578
Epoch: 9| Step: 9
Training loss: 1.9843521118164062
Validation loss: 1.8752556173063868
Epoch: 9| Step: 10
Training loss: 2.153195381164551
Validation loss: 1.9037954438504556
Epoch: 9| Step: 11
Training loss: 2.3450536727905273
Validation loss: 1.8985989496862288
Epoch: 9| Step: 12
Training loss: 1.5317649841308594
Validation loss: 1.9223093223228729
Epoch: 9| Step: 13
Training loss: 2.5456130504608154
Validation loss: 1.9152322132810413
Epoch: 9| Step: 14
Training loss: 1.9472434520721436
Validation loss: 1.9136079129555243
Epoch: 9| Step: 15
Training loss: 2.0639774799346924
Validation loss: 1.8969150215601749
Epoch: 9| Step: 16
Training loss: 2.209289073944092
Validation loss: 1.9036496405978856
Epoch: 9| Step: 17
Training loss: 1.6088589429855347
Validation loss: 1.8867528935988171
Epoch: 9| Step: 18
Training loss: 2.4313387870788574
Validation loss: 1.8853655873442725
Epoch: 9| Step: 19
Training loss: 1.6108129024505615
Validation loss: 1.8897380502961523
Epoch: 32| Step: 0
Training loss: 2.7905590534210205
Validation loss: 1.879952279783839
Epoch: 9| Step: 1
Training loss: 2.09291410446167
Validation loss: 1.874260934994375
Epoch: 9| Step: 2
Training loss: 2.2519333362579346
Validation loss: 1.8663078812386493
Epoch: 9| Step: 3
Training loss: 1.7097500562667847
Validation loss: 1.8706805517347596
Epoch: 9| Step: 4
Training loss: 1.8904013633728027
Validation loss: 1.8911603457636113
Epoch: 9| Step: 5
Training loss: 1.9654974937438965
Validation loss: 1.8914299268516706
Epoch: 9| Step: 6
Training loss: 2.6168313026428223
Validation loss: 1.8676161843238117
Epoch: 9| Step: 7
Training loss: 2.2273151874542236
Validation loss: 1.887730039280953
Epoch: 9| Step: 8
Training loss: 1.3122344017028809
Validation loss: 1.8884741453815708
Epoch: 9| Step: 9
Training loss: 1.512913465499878
Validation loss: 1.896237603194422
Epoch: 9| Step: 10
Training loss: 1.6630804538726807
Validation loss: 1.9077866746367311
Epoch: 9| Step: 11
Training loss: 1.675081729888916
Validation loss: 1.8960059435247518
Epoch: 9| Step: 12
Training loss: 2.3870961666107178
Validation loss: 1.9213726820705606
Epoch: 9| Step: 13
Training loss: 2.3721275329589844
Validation loss: 1.9104013631669738
Epoch: 9| Step: 14
Training loss: 1.8489253520965576
Validation loss: 1.9054552848390538
Epoch: 9| Step: 15
Training loss: 2.2371857166290283
Validation loss: 1.9161259819277756
Epoch: 9| Step: 16
Training loss: 1.5975127220153809
Validation loss: 1.9085922198329899
Epoch: 9| Step: 17
Training loss: 2.296471118927002
Validation loss: 1.911491388897244
Epoch: 9| Step: 18
Training loss: 2.406357765197754
Validation loss: 1.8969133260438769
Epoch: 9| Step: 19
Training loss: 1.9245392084121704
Validation loss: 1.899351059961662
Epoch: 33| Step: 0
Training loss: 2.5572550296783447
Validation loss: 1.9063726174745628
Epoch: 9| Step: 1
Training loss: 1.6965587139129639
Validation loss: 1.9035577911267179
Epoch: 9| Step: 2
Training loss: 2.3076939582824707
Validation loss: 1.8939464212321548
Epoch: 9| Step: 3
Training loss: 2.5440549850463867
Validation loss: 1.8846817110939849
Epoch: 9| Step: 4
Training loss: 1.4430572986602783
Validation loss: 1.8889209323649785
Epoch: 9| Step: 5
Training loss: 2.278285264968872
Validation loss: 1.8749675424836523
Epoch: 9| Step: 6
Training loss: 1.7775614261627197
Validation loss: 1.8675783280846026
Epoch: 9| Step: 7
Training loss: 2.489626884460449
Validation loss: 1.870798637541078
Epoch: 9| Step: 8
Training loss: 2.0898752212524414
Validation loss: 1.8722189870669688
Epoch: 9| Step: 9
Training loss: 2.044949531555176
Validation loss: 1.8800107549420364
Epoch: 9| Step: 10
Training loss: 2.2539572715759277
Validation loss: 1.8753957662651006
Epoch: 9| Step: 11
Training loss: 2.102879047393799
Validation loss: 1.8671562157088903
Epoch: 9| Step: 12
Training loss: 1.8228552341461182
Validation loss: 1.868423864995833
Epoch: 9| Step: 13
Training loss: 2.333505868911743
Validation loss: 1.8526770554000525
Epoch: 9| Step: 14
Training loss: 1.8438682556152344
Validation loss: 1.8618172167016447
Epoch: 9| Step: 15
Training loss: 1.8108495473861694
Validation loss: 1.8542607585303217
Epoch: 9| Step: 16
Training loss: 1.9090030193328857
Validation loss: 1.8463193589834859
Epoch: 9| Step: 17
Training loss: 1.1478731632232666
Validation loss: 1.8403002049425523
Epoch: 9| Step: 18
Training loss: 2.306612730026245
Validation loss: 1.8438193952436928
Epoch: 9| Step: 19
Training loss: 1.824169635772705
Validation loss: 1.8528599344569145
Epoch: 34| Step: 0
Training loss: 2.627629280090332
Validation loss: 1.8636260650140777
Epoch: 9| Step: 1
Training loss: 2.4363443851470947
Validation loss: 1.8717157686357018
Epoch: 9| Step: 2
Training loss: 1.9030158519744873
Validation loss: 1.862918925799912
Epoch: 9| Step: 3
Training loss: 1.8012295961380005
Validation loss: 1.87243955941509
Epoch: 9| Step: 4
Training loss: 1.3411688804626465
Validation loss: 1.8676229663890043
Epoch: 9| Step: 5
Training loss: 2.487365961074829
Validation loss: 1.862851899304836
Epoch: 9| Step: 6
Training loss: 2.5525097846984863
Validation loss: 1.8597456319726628
Epoch: 9| Step: 7
Training loss: 2.364625930786133
Validation loss: 1.8489414582149588
Epoch: 9| Step: 8
Training loss: 1.0043373107910156
Validation loss: 1.8536219871301445
Epoch: 9| Step: 9
Training loss: 2.043560028076172
Validation loss: 1.861890127332948
Epoch: 9| Step: 10
Training loss: 1.9182238578796387
Validation loss: 1.866071496936057
Epoch: 9| Step: 11
Training loss: 1.554200530052185
Validation loss: 1.8428963894466701
Epoch: 9| Step: 12
Training loss: 1.593386173248291
Validation loss: 1.860234402066512
Epoch: 9| Step: 13
Training loss: 1.9874600172042847
Validation loss: 1.8596966858390425
Epoch: 9| Step: 14
Training loss: 2.883945941925049
Validation loss: 1.8674683768114597
Epoch: 9| Step: 15
Training loss: 1.916802167892456
Validation loss: 1.856610841888318
Epoch: 9| Step: 16
Training loss: 2.4137485027313232
Validation loss: 1.8569675829770753
Epoch: 9| Step: 17
Training loss: 2.8317580223083496
Validation loss: 1.8509390019684386
Epoch: 9| Step: 18
Training loss: 1.9171383380889893
Validation loss: 1.8435083104552126
Epoch: 9| Step: 19
Training loss: 1.1586819887161255
Validation loss: 1.8630028478533245
Epoch: 35| Step: 0
Training loss: 2.523615837097168
Validation loss: 1.8705030182282703
Epoch: 9| Step: 1
Training loss: 1.6695914268493652
Validation loss: 1.8863327503204346
Epoch: 9| Step: 2
Training loss: 1.7943648099899292
Validation loss: 1.8805391719873004
Epoch: 9| Step: 3
Training loss: 2.5747392177581787
Validation loss: 1.8842065137067288
Epoch: 9| Step: 4
Training loss: 2.347325086593628
Validation loss: 1.8965808410438703
Epoch: 9| Step: 5
Training loss: 1.951482892036438
Validation loss: 1.9073920695901774
Epoch: 9| Step: 6
Training loss: 2.058566093444824
Validation loss: 1.8979860741457493
Epoch: 9| Step: 7
Training loss: 1.8511760234832764
Validation loss: 1.8918565708956272
Epoch: 9| Step: 8
Training loss: 1.7156929969787598
Validation loss: 1.880809480337788
Epoch: 9| Step: 9
Training loss: 1.7304043769836426
Validation loss: 1.888288232919981
Epoch: 9| Step: 10
Training loss: 1.5613312721252441
Validation loss: 1.887447576728656
Epoch: 9| Step: 11
Training loss: 2.4789044857025146
Validation loss: 1.9003489463449381
Epoch: 9| Step: 12
Training loss: 2.035189628601074
Validation loss: 1.8909181999645646
Epoch: 9| Step: 13
Training loss: 2.106959819793701
Validation loss: 1.8918653769458798
Epoch: 9| Step: 14
Training loss: 2.2546041011810303
Validation loss: 1.9123156362300298
Epoch: 9| Step: 15
Training loss: 2.2992477416992188
Validation loss: 1.906457380425158
Epoch: 9| Step: 16
Training loss: 1.327282190322876
Validation loss: 1.905624048315364
Epoch: 9| Step: 17
Training loss: 2.244509696960449
Validation loss: 1.8907724738978653
Epoch: 9| Step: 18
Training loss: 2.579164743423462
Validation loss: 1.8897075567314092
Epoch: 9| Step: 19
Training loss: 1.7318309545516968
Validation loss: 1.8869511146339581
Epoch: 36| Step: 0
Training loss: 2.3225083351135254
Validation loss: 1.9083883076262989
Epoch: 9| Step: 1
Training loss: 2.3228883743286133
Validation loss: 1.885879725003414
Epoch: 9| Step: 2
Training loss: 1.6289587020874023
Validation loss: 1.8915961697804842
Epoch: 9| Step: 3
Training loss: 2.0178356170654297
Validation loss: 1.8893880518220312
Epoch: 9| Step: 4
Training loss: 2.3622546195983887
Validation loss: 1.8964343482641866
Epoch: 9| Step: 5
Training loss: 1.9533963203430176
Validation loss: 1.9087242059570422
Epoch: 9| Step: 6
Training loss: 1.961050033569336
Validation loss: 1.898664841549002
Epoch: 9| Step: 7
Training loss: 2.099187135696411
Validation loss: 1.8965062211743362
Epoch: 9| Step: 8
Training loss: 1.489264965057373
Validation loss: 1.8947522177113045
Epoch: 9| Step: 9
Training loss: 2.188977003097534
Validation loss: 1.882036598466283
Epoch: 9| Step: 10
Training loss: 1.6736280918121338
Validation loss: 1.8938945154491946
Epoch: 9| Step: 11
Training loss: 2.3659465312957764
Validation loss: 1.8720925874847303
Epoch: 9| Step: 12
Training loss: 1.9550204277038574
Validation loss: 1.8967708795190714
Epoch: 9| Step: 13
Training loss: 2.324225664138794
Validation loss: 1.89626389098682
Epoch: 9| Step: 14
Training loss: 1.9914865493774414
Validation loss: 1.8915261913546555
Epoch: 9| Step: 15
Training loss: 2.1126627922058105
Validation loss: 1.89603518067504
Epoch: 9| Step: 16
Training loss: 2.458709239959717
Validation loss: 1.8850603395228764
Epoch: 9| Step: 17
Training loss: 1.6218416690826416
Validation loss: 1.8945641500486745
Epoch: 9| Step: 18
Training loss: 2.153627872467041
Validation loss: 1.8962690950297623
Epoch: 9| Step: 19
Training loss: 1.6093645095825195
Validation loss: 1.878551309057277
Epoch: 37| Step: 0
Training loss: 0.9819743633270264
Validation loss: 1.889087438583374
Epoch: 9| Step: 1
Training loss: 1.770453929901123
Validation loss: 1.8973732552082418
Epoch: 9| Step: 2
Training loss: 2.131539821624756
Validation loss: 1.8777262349780515
Epoch: 9| Step: 3
Training loss: 1.4882198572158813
Validation loss: 1.871213164260919
Epoch: 9| Step: 4
Training loss: 1.8755807876586914
Validation loss: 1.866391808866597
Epoch: 9| Step: 5
Training loss: 2.024949550628662
Validation loss: 1.8608424311919178
Epoch: 9| Step: 6
Training loss: 2.1933183670043945
Validation loss: 1.8497032210123625
Epoch: 9| Step: 7
Training loss: 2.1231560707092285
Validation loss: 1.859065472650871
Epoch: 9| Step: 8
Training loss: 2.4214959144592285
Validation loss: 1.8650657307329794
Epoch: 9| Step: 9
Training loss: 2.166802406311035
Validation loss: 1.8385290645009322
Epoch: 9| Step: 10
Training loss: 1.8142189979553223
Validation loss: 1.845153577893758
Epoch: 9| Step: 11
Training loss: 2.7407078742980957
Validation loss: 1.865096704565364
Epoch: 9| Step: 12
Training loss: 2.1033480167388916
Validation loss: 1.8471198630847518
Epoch: 9| Step: 13
Training loss: 2.324388027191162
Validation loss: 1.8739921429174409
Epoch: 9| Step: 14
Training loss: 1.9394203424453735
Validation loss: 1.863565623331413
Epoch: 9| Step: 15
Training loss: 2.1267824172973633
Validation loss: 1.8534553496957682
Epoch: 9| Step: 16
Training loss: 1.5606392621994019
Validation loss: 1.8602802753448486
Epoch: 9| Step: 17
Training loss: 2.2272448539733887
Validation loss: 1.8574291133194518
Epoch: 9| Step: 18
Training loss: 2.7764339447021484
Validation loss: 1.864683297898272
Epoch: 9| Step: 19
Training loss: 1.840043544769287
Validation loss: 1.8635004132771664
Epoch: 38| Step: 0
Training loss: 2.3558921813964844
Validation loss: 1.872783829839967
Epoch: 9| Step: 1
Training loss: 2.2466540336608887
Validation loss: 1.863688847143873
Epoch: 9| Step: 2
Training loss: 1.6861401796340942
Validation loss: 1.8884310250659642
Epoch: 9| Step: 3
Training loss: 2.425172805786133
Validation loss: 1.8758446998733411
Epoch: 9| Step: 4
Training loss: 1.9453648328781128
Validation loss: 1.8713542343043594
Epoch: 9| Step: 5
Training loss: 1.4234473705291748
Validation loss: 1.8746610125191778
Epoch: 9| Step: 6
Training loss: 1.931667447090149
Validation loss: 1.873399780808593
Epoch: 9| Step: 7
Training loss: 1.5050547122955322
Validation loss: 1.8793396949768066
Epoch: 9| Step: 8
Training loss: 2.348924160003662
Validation loss: 1.8893598206609272
Epoch: 9| Step: 9
Training loss: 1.8265490531921387
Validation loss: 1.8631495674737066
Epoch: 9| Step: 10
Training loss: 1.456710696220398
Validation loss: 1.8698480618085793
Epoch: 9| Step: 11
Training loss: 2.0997936725616455
Validation loss: 1.8743525700603458
Epoch: 9| Step: 12
Training loss: 2.358686923980713
Validation loss: 1.8934066518605184
Epoch: 9| Step: 13
Training loss: 2.4822733402252197
Validation loss: 1.8794715387358083
Epoch: 9| Step: 14
Training loss: 1.971144676208496
Validation loss: 1.8778123795557364
Epoch: 9| Step: 15
Training loss: 2.7629599571228027
Validation loss: 1.859806824931138
Epoch: 9| Step: 16
Training loss: 1.7388484477996826
Validation loss: 1.8649828554057388
Epoch: 9| Step: 17
Training loss: 1.7158310413360596
Validation loss: 1.8573662548614063
Epoch: 9| Step: 18
Training loss: 2.074150562286377
Validation loss: 1.8739370150531796
Epoch: 9| Step: 19
Training loss: 2.3377442359924316
Validation loss: 1.8576754931923296
Epoch: 39| Step: 0
Training loss: 1.4554815292358398
Validation loss: 1.8680014996219882
Epoch: 9| Step: 1
Training loss: 1.86957585811615
Validation loss: 1.8729923886360882
Epoch: 9| Step: 2
Training loss: 2.050410270690918
Validation loss: 1.859613607255675
Epoch: 9| Step: 3
Training loss: 2.076643228530884
Validation loss: 1.8762084108462436
Epoch: 9| Step: 4
Training loss: 2.454770565032959
Validation loss: 1.873090115382517
Epoch: 9| Step: 5
Training loss: 1.4577258825302124
Validation loss: 1.8741477290503412
Epoch: 9| Step: 6
Training loss: 2.1002650260925293
Validation loss: 1.9063575370706243
Epoch: 9| Step: 7
Training loss: 2.4935503005981445
Validation loss: 1.9002013884002356
Epoch: 9| Step: 8
Training loss: 1.482609748840332
Validation loss: 1.9032829922737835
Epoch: 9| Step: 9
Training loss: 1.8570492267608643
Validation loss: 1.8967589774577738
Epoch: 9| Step: 10
Training loss: 2.110861301422119
Validation loss: 1.895141010661777
Epoch: 9| Step: 11
Training loss: 2.0004894733428955
Validation loss: 1.8916336066431279
Epoch: 9| Step: 12
Training loss: 1.9727206230163574
Validation loss: 1.9048586826530292
Epoch: 9| Step: 13
Training loss: 2.2953171730041504
Validation loss: 1.908251676628058
Epoch: 9| Step: 14
Training loss: 2.094379425048828
Validation loss: 1.9103708901851297
Epoch: 9| Step: 15
Training loss: 2.185265302658081
Validation loss: 1.905512607354912
Epoch: 9| Step: 16
Training loss: 2.1493265628814697
Validation loss: 1.891917716684959
Epoch: 9| Step: 17
Training loss: 2.0573880672454834
Validation loss: 1.9060721671838554
Epoch: 9| Step: 18
Training loss: 2.443782329559326
Validation loss: 1.9053406329463711
Epoch: 9| Step: 19
Training loss: 2.016965389251709
Validation loss: 1.8965110641589267
Epoch: 40| Step: 0
Training loss: 1.3837974071502686
Validation loss: 1.896654906890375
Epoch: 9| Step: 1
Training loss: 2.6890010833740234
Validation loss: 1.8928225880904164
Epoch: 9| Step: 2
Training loss: 2.340693950653076
Validation loss: 1.875816307479529
Epoch: 9| Step: 3
Training loss: 1.8514783382415771
Validation loss: 1.8757584532387823
Epoch: 9| Step: 4
Training loss: 1.5978009700775146
Validation loss: 1.8706333242731987
Epoch: 9| Step: 5
Training loss: 1.2036511898040771
Validation loss: 1.8610822408319376
Epoch: 9| Step: 6
Training loss: 2.1671218872070312
Validation loss: 1.8531483257417198
Epoch: 9| Step: 7
Training loss: 2.427828788757324
Validation loss: 1.8724373467534565
Epoch: 9| Step: 8
Training loss: 1.5477105379104614
Validation loss: 1.853805475097766
Epoch: 9| Step: 9
Training loss: 1.9135388135910034
Validation loss: 1.8639745669399235
Epoch: 9| Step: 10
Training loss: 1.9394407272338867
Validation loss: 1.8500571242339319
Epoch: 9| Step: 11
Training loss: 2.0814356803894043
Validation loss: 1.8602985924096416
Epoch: 9| Step: 12
Training loss: 2.158909320831299
Validation loss: 1.8544066363959004
Epoch: 9| Step: 13
Training loss: 2.553194522857666
Validation loss: 1.8471120064207118
Epoch: 9| Step: 14
Training loss: 2.1552939414978027
Validation loss: 1.8549359959664105
Epoch: 9| Step: 15
Training loss: 2.129887342453003
Validation loss: 1.8444815951285602
Epoch: 9| Step: 16
Training loss: 2.7706780433654785
Validation loss: 1.860351830077686
Epoch: 9| Step: 17
Training loss: 1.7131376266479492
Validation loss: 1.850989041568564
Epoch: 9| Step: 18
Training loss: 2.0334181785583496
Validation loss: 1.8715070520373558
Epoch: 9| Step: 19
Training loss: 1.8156200647354126
Validation loss: 1.854486941433639
Epoch: 41| Step: 0
Training loss: 1.6325771808624268
Validation loss: 1.8639858935376723
Epoch: 9| Step: 1
Training loss: 2.4399189949035645
Validation loss: 1.8634916621146442
Epoch: 9| Step: 2
Training loss: 1.694759488105774
Validation loss: 1.8718942961246847
Epoch: 9| Step: 3
Training loss: 1.938839316368103
Validation loss: 1.87766279333787
Epoch: 9| Step: 4
Training loss: 1.948318600654602
Validation loss: 1.8528584679253668
Epoch: 9| Step: 5
Training loss: 2.854034662246704
Validation loss: 1.8766573307325514
Epoch: 9| Step: 6
Training loss: 2.181833505630493
Validation loss: 1.8799245151684438
Epoch: 9| Step: 7
Training loss: 1.9242123365402222
Validation loss: 1.8635989796343466
Epoch: 9| Step: 8
Training loss: 1.8117074966430664
Validation loss: 1.8792595108635992
Epoch: 9| Step: 9
Training loss: 2.273834705352783
Validation loss: 1.869550776996201
Epoch: 9| Step: 10
Training loss: 2.292982578277588
Validation loss: 1.8760491618149573
Epoch: 9| Step: 11
Training loss: 2.4385488033294678
Validation loss: 1.8493091322535233
Epoch: 9| Step: 12
Training loss: 2.311431407928467
Validation loss: 1.8538697314776962
Epoch: 9| Step: 13
Training loss: 1.7461016178131104
Validation loss: 1.8558874361806637
Epoch: 9| Step: 14
Training loss: 1.9534504413604736
Validation loss: 1.849380122671882
Epoch: 9| Step: 15
Training loss: 2.258483409881592
Validation loss: 1.8512444616221695
Epoch: 9| Step: 16
Training loss: 1.7485132217407227
Validation loss: 1.8570380005047475
Epoch: 9| Step: 17
Training loss: 2.0901849269866943
Validation loss: 1.8360851136900538
Epoch: 9| Step: 18
Training loss: 1.0047531127929688
Validation loss: 1.839319712824101
Epoch: 9| Step: 19
Training loss: 2.0467514991760254
Validation loss: 1.8483669414794703
Epoch: 42| Step: 0
Training loss: 1.6460089683532715
Validation loss: 1.8390139718707517
Epoch: 9| Step: 1
Training loss: 1.5578010082244873
Validation loss: 1.851480513167896
Epoch: 9| Step: 2
Training loss: 2.6207454204559326
Validation loss: 1.8537002107222302
Epoch: 9| Step: 3
Training loss: 2.245262384414673
Validation loss: 1.8543281529447158
Epoch: 9| Step: 4
Training loss: 2.29339861869812
Validation loss: 1.8784817757366372
Epoch: 9| Step: 5
Training loss: 2.325578451156616
Validation loss: 1.8730684493085463
Epoch: 9| Step: 6
Training loss: 2.0886011123657227
Validation loss: 1.8826874606043316
Epoch: 9| Step: 7
Training loss: 2.372319221496582
Validation loss: 1.8641234344715694
Epoch: 9| Step: 8
Training loss: 2.206906795501709
Validation loss: 1.8584198565791836
Epoch: 9| Step: 9
Training loss: 2.2621560096740723
Validation loss: 1.8753266068671246
Epoch: 9| Step: 10
Training loss: 2.212411642074585
Validation loss: 1.8825870495048358
Epoch: 9| Step: 11
Training loss: 1.8156533241271973
Validation loss: 1.8724943759630053
Epoch: 9| Step: 12
Training loss: 1.4003596305847168
Validation loss: 1.8810811557358118
Epoch: 9| Step: 13
Training loss: 2.0828030109405518
Validation loss: 1.859945924162007
Epoch: 9| Step: 14
Training loss: 2.013639211654663
Validation loss: 1.8662221431732178
Epoch: 9| Step: 15
Training loss: 1.9166955947875977
Validation loss: 1.8874900375338768
Epoch: 9| Step: 16
Training loss: 1.8773695230484009
Validation loss: 1.8796768908878025
Epoch: 9| Step: 17
Training loss: 2.2491087913513184
Validation loss: 1.882172764634057
Epoch: 9| Step: 18
Training loss: 1.2757854461669922
Validation loss: 1.8901314906936755
Epoch: 9| Step: 19
Training loss: 1.898455023765564
Validation loss: 1.9021357598064614
Epoch: 43| Step: 0
Training loss: 2.8102240562438965
Validation loss: 1.882223169580638
Epoch: 9| Step: 1
Training loss: 1.2539864778518677
Validation loss: 1.899902805149984
Epoch: 9| Step: 2
Training loss: 1.4165908098220825
Validation loss: 1.9003616708645719
Epoch: 9| Step: 3
Training loss: 2.386887788772583
Validation loss: 1.891061705651043
Epoch: 9| Step: 4
Training loss: 1.8491613864898682
Validation loss: 1.8933236264496398
Epoch: 9| Step: 5
Training loss: 1.9226422309875488
Validation loss: 1.912676858387405
Epoch: 9| Step: 6
Training loss: 1.8308968544006348
Validation loss: 1.9094439856440044
Epoch: 9| Step: 7
Training loss: 2.2876758575439453
Validation loss: 1.9069273540441938
Epoch: 9| Step: 8
Training loss: 2.229254722595215
Validation loss: 1.9003254166609949
Epoch: 9| Step: 9
Training loss: 1.7242189645767212
Validation loss: 1.892754987847033
Epoch: 9| Step: 10
Training loss: 1.8650281429290771
Validation loss: 1.901435262007679
Epoch: 9| Step: 11
Training loss: 2.0004000663757324
Validation loss: 1.8845814698034054
Epoch: 9| Step: 12
Training loss: 1.876023292541504
Validation loss: 1.8973244857445037
Epoch: 9| Step: 13
Training loss: 1.8583030700683594
Validation loss: 1.8870979813363056
Epoch: 9| Step: 14
Training loss: 2.2100226879119873
Validation loss: 1.8858388456509267
Epoch: 9| Step: 15
Training loss: 1.8442027568817139
Validation loss: 1.8812459501431142
Epoch: 9| Step: 16
Training loss: 1.8776369094848633
Validation loss: 1.8886819794881258
Epoch: 9| Step: 17
Training loss: 2.849169969558716
Validation loss: 1.8935866896197093
Epoch: 9| Step: 18
Training loss: 1.8490501642227173
Validation loss: 1.8823566977068675
Epoch: 9| Step: 19
Training loss: 2.266508102416992
Validation loss: 1.891349657834005
Epoch: 44| Step: 0
Training loss: 2.2615859508514404
Validation loss: 1.8782531554750401
Epoch: 9| Step: 1
Training loss: 2.323838472366333
Validation loss: 1.8866736082721958
Epoch: 9| Step: 2
Training loss: 2.0932960510253906
Validation loss: 1.8724399367682367
Epoch: 9| Step: 3
Training loss: 1.6263258457183838
Validation loss: 1.880272319848589
Epoch: 9| Step: 4
Training loss: 1.15574312210083
Validation loss: 1.8892315754787528
Epoch: 9| Step: 5
Training loss: 1.5059632062911987
Validation loss: 1.873045891308956
Epoch: 9| Step: 6
Training loss: 2.0323872566223145
Validation loss: 1.8663003461824046
Epoch: 9| Step: 7
Training loss: 1.5245063304901123
Validation loss: 1.8604511888764745
Epoch: 9| Step: 8
Training loss: 2.047422170639038
Validation loss: 1.880615384458638
Epoch: 9| Step: 9
Training loss: 2.5588064193725586
Validation loss: 1.878634397074473
Epoch: 9| Step: 10
Training loss: 1.7029629945755005
Validation loss: 1.8903271362935896
Epoch: 9| Step: 11
Training loss: 1.266453504562378
Validation loss: 1.8758408114206877
Epoch: 9| Step: 12
Training loss: 2.0693299770355225
Validation loss: 1.8870526449285823
Epoch: 9| Step: 13
Training loss: 1.509016990661621
Validation loss: 1.8924924564018524
Epoch: 9| Step: 14
Training loss: 1.8054119348526
Validation loss: 1.8955181656981543
Epoch: 9| Step: 15
Training loss: 2.240821599960327
Validation loss: 1.8986232229273954
Epoch: 9| Step: 16
Training loss: 2.2508108615875244
Validation loss: 1.9180845236606736
Epoch: 9| Step: 17
Training loss: 2.8105580806732178
Validation loss: 1.9114377001206653
Epoch: 9| Step: 18
Training loss: 3.1897530555725098
Validation loss: 1.9066393023772206
Epoch: 9| Step: 19
Training loss: 2.2599539756774902
Validation loss: 1.900057595410793
Epoch: 45| Step: 0
Training loss: 2.1399872303009033
Validation loss: 1.8987404511129256
Epoch: 9| Step: 1
Training loss: 1.9620985984802246
Validation loss: 1.8840903163813858
Epoch: 9| Step: 2
Training loss: 1.9581565856933594
Validation loss: 1.893904179977856
Epoch: 9| Step: 3
Training loss: 2.1213974952697754
Validation loss: 1.8616995159670604
Epoch: 9| Step: 4
Training loss: 1.9263590574264526
Validation loss: 1.8795547751214008
Epoch: 9| Step: 5
Training loss: 2.0429749488830566
Validation loss: 1.8536929689722954
Epoch: 9| Step: 6
Training loss: 1.6962289810180664
Validation loss: 1.8496456300611976
Epoch: 9| Step: 7
Training loss: 1.783968448638916
Validation loss: 1.8724278340236746
Epoch: 9| Step: 8
Training loss: 2.631160259246826
Validation loss: 1.8576176638225856
Epoch: 9| Step: 9
Training loss: 2.214841604232788
Validation loss: 1.851268807761103
Epoch: 9| Step: 10
Training loss: 1.8733633756637573
Validation loss: 1.8272460510404847
Epoch: 9| Step: 11
Training loss: 1.8354493379592896
Validation loss: 1.8439747884119158
Epoch: 9| Step: 12
Training loss: 1.6138757467269897
Validation loss: 1.824346219892982
Epoch: 9| Step: 13
Training loss: 1.5179977416992188
Validation loss: 1.830831648634492
Epoch: 9| Step: 14
Training loss: 2.103188991546631
Validation loss: 1.8360317516669953
Epoch: 9| Step: 15
Training loss: 2.1803269386291504
Validation loss: 1.8296734532006353
Epoch: 9| Step: 16
Training loss: 2.4940829277038574
Validation loss: 1.8372886875550525
Epoch: 9| Step: 17
Training loss: 2.5115151405334473
Validation loss: 1.8158361165643595
Epoch: 9| Step: 18
Training loss: 1.9045078754425049
Validation loss: 1.8380998295845745
Epoch: 9| Step: 19
Training loss: 1.7249902486801147
Validation loss: 1.8309261532996197
Epoch: 46| Step: 0
Training loss: 2.9402899742126465
Validation loss: 1.8508464895564019
Epoch: 9| Step: 1
Training loss: 1.647249698638916
Validation loss: 1.8666518943772898
Epoch: 9| Step: 2
Training loss: 1.4296139478683472
Validation loss: 1.849646936217658
Epoch: 9| Step: 3
Training loss: 1.5168390274047852
Validation loss: 1.835752977741708
Epoch: 9| Step: 4
Training loss: 2.1061930656433105
Validation loss: 1.8431859702515088
Epoch: 9| Step: 5
Training loss: 2.213838577270508
Validation loss: 1.8564615215328957
Epoch: 9| Step: 6
Training loss: 2.131985902786255
Validation loss: 1.8645828902292594
Epoch: 9| Step: 7
Training loss: 2.1178364753723145
Validation loss: 1.8472564391952624
Epoch: 9| Step: 8
Training loss: 2.4511234760284424
Validation loss: 1.852913867655418
Epoch: 9| Step: 9
Training loss: 1.9041935205459595
Validation loss: 1.8454565135695093
Epoch: 9| Step: 10
Training loss: 2.113772392272949
Validation loss: 1.8384571229811195
Epoch: 9| Step: 11
Training loss: 1.5022902488708496
Validation loss: 1.8503809549825654
Epoch: 9| Step: 12
Training loss: 1.4862679243087769
Validation loss: 1.8493132025217838
Epoch: 9| Step: 13
Training loss: 1.9486093521118164
Validation loss: 1.853634460366887
Epoch: 9| Step: 14
Training loss: 2.4835205078125
Validation loss: 1.864955065919341
Epoch: 9| Step: 15
Training loss: 2.2332797050476074
Validation loss: 1.8497974083577986
Epoch: 9| Step: 16
Training loss: 2.0614800453186035
Validation loss: 1.8614389407548972
Epoch: 9| Step: 17
Training loss: 2.026885986328125
Validation loss: 1.8541406281560444
Epoch: 9| Step: 18
Training loss: 2.0458030700683594
Validation loss: 1.8574318422687996
Epoch: 9| Step: 19
Training loss: 1.777197241783142
Validation loss: 1.8570394052875985
Epoch: 47| Step: 0
Training loss: 2.1028432846069336
Validation loss: 1.860561429167823
Epoch: 9| Step: 1
Training loss: 1.5552465915679932
Validation loss: 1.8678420867851313
Epoch: 9| Step: 2
Training loss: 2.319262981414795
Validation loss: 1.8701347344213253
Epoch: 9| Step: 3
Training loss: 1.6831822395324707
Validation loss: 1.8781049577452296
Epoch: 9| Step: 4
Training loss: 2.3597960472106934
Validation loss: 1.875731530807001
Epoch: 9| Step: 5
Training loss: 2.1152496337890625
Validation loss: 1.8800010629695096
Epoch: 9| Step: 6
Training loss: 1.7435201406478882
Validation loss: 1.8759931274455228
Epoch: 9| Step: 7
Training loss: 2.2917044162750244
Validation loss: 1.880189461673764
Epoch: 9| Step: 8
Training loss: 2.217287302017212
Validation loss: 1.8918438377997857
Epoch: 9| Step: 9
Training loss: 2.160104274749756
Validation loss: 1.8889613014330966
Epoch: 9| Step: 10
Training loss: 2.4511983394622803
Validation loss: 1.8716719639387063
Epoch: 9| Step: 11
Training loss: 1.5468114614486694
Validation loss: 1.8991181455927788
Epoch: 9| Step: 12
Training loss: 1.9403949975967407
Validation loss: 1.8868220632882426
Epoch: 9| Step: 13
Training loss: 1.4548226594924927
Validation loss: 1.8991666311840358
Epoch: 9| Step: 14
Training loss: 2.0517287254333496
Validation loss: 1.8975649034376625
Epoch: 9| Step: 15
Training loss: 2.2025468349456787
Validation loss: 1.904477073991899
Epoch: 9| Step: 16
Training loss: 1.7146375179290771
Validation loss: 1.9087473256982488
Epoch: 9| Step: 17
Training loss: 1.6444883346557617
Validation loss: 1.893656473365619
Epoch: 9| Step: 18
Training loss: 2.3804662227630615
Validation loss: 1.8988689861709265
Epoch: 9| Step: 19
Training loss: 2.167249917984009
Validation loss: 1.8957401625544048
Epoch: 48| Step: 0
Training loss: 2.1068339347839355
Validation loss: 1.8999752320831629
Epoch: 9| Step: 1
Training loss: 2.1355061531066895
Validation loss: 1.8993454596979156
Epoch: 9| Step: 2
Training loss: 1.3377697467803955
Validation loss: 1.9069772495640267
Epoch: 9| Step: 3
Training loss: 2.631720542907715
Validation loss: 1.9015414594746323
Epoch: 9| Step: 4
Training loss: 2.288787603378296
Validation loss: 1.8944724841083553
Epoch: 9| Step: 5
Training loss: 2.0831995010375977
Validation loss: 1.8754365667164754
Epoch: 9| Step: 6
Training loss: 2.730970859527588
Validation loss: 1.889909288008436
Epoch: 9| Step: 7
Training loss: 2.2463440895080566
Validation loss: 1.8827050975758395
Epoch: 9| Step: 8
Training loss: 1.623378038406372
Validation loss: 1.8534663666924127
Epoch: 9| Step: 9
Training loss: 2.093647003173828
Validation loss: 1.880193926447587
Epoch: 9| Step: 10
Training loss: 1.4943772554397583
Validation loss: 1.8683928928786901
Epoch: 9| Step: 11
Training loss: 2.3331549167633057
Validation loss: 1.8686302360013234
Epoch: 9| Step: 12
Training loss: 1.7010940313339233
Validation loss: 1.8455227673482553
Epoch: 9| Step: 13
Training loss: 1.592731237411499
Validation loss: 1.8561149552571687
Epoch: 9| Step: 14
Training loss: 2.12384033203125
Validation loss: 1.8513958754299356
Epoch: 9| Step: 15
Training loss: 1.2810909748077393
Validation loss: 1.8449305776211855
Epoch: 9| Step: 16
Training loss: 1.7390292882919312
Validation loss: 1.8523018583119344
Epoch: 9| Step: 17
Training loss: 2.1805989742279053
Validation loss: 1.8446239979147054
Epoch: 9| Step: 18
Training loss: 2.23441743850708
Validation loss: 1.8646330430353288
Epoch: 9| Step: 19
Training loss: 2.2465405464172363
Validation loss: 1.8306980647629114
Epoch: 49| Step: 0
Training loss: 1.5373780727386475
Validation loss: 1.8554602869980628
Epoch: 9| Step: 1
Training loss: 2.2854955196380615
Validation loss: 1.8370642653472131
Epoch: 9| Step: 2
Training loss: 1.6847631931304932
Validation loss: 1.8534967624883858
Epoch: 9| Step: 3
Training loss: 2.1714541912078857
Validation loss: 1.8466615917013705
Epoch: 9| Step: 4
Training loss: 1.9387143850326538
Validation loss: 1.8448945652666708
Epoch: 9| Step: 5
Training loss: 2.5694289207458496
Validation loss: 1.842496241596963
Epoch: 9| Step: 6
Training loss: 1.7478448152542114
Validation loss: 1.8330719385215704
Epoch: 9| Step: 7
Training loss: 2.1504740715026855
Validation loss: 1.8472115015812058
Epoch: 9| Step: 8
Training loss: 2.0925827026367188
Validation loss: 1.8397229009395024
Epoch: 9| Step: 9
Training loss: 1.962569236755371
Validation loss: 1.839927559276279
Epoch: 9| Step: 10
Training loss: 1.8850281238555908
Validation loss: 1.831837927694801
Epoch: 9| Step: 11
Training loss: 1.5561416149139404
Validation loss: 1.8547944019166687
Epoch: 9| Step: 12
Training loss: 2.5954251289367676
Validation loss: 1.8531971749641913
Epoch: 9| Step: 13
Training loss: 2.030318260192871
Validation loss: 1.856023226710532
Epoch: 9| Step: 14
Training loss: 1.8587565422058105
Validation loss: 1.861180645098789
Epoch: 9| Step: 15
Training loss: 2.1506309509277344
Validation loss: 1.8565270986488398
Epoch: 9| Step: 16
Training loss: 2.0538783073425293
Validation loss: 1.8692078993474837
Epoch: 9| Step: 17
Training loss: 1.7760136127471924
Validation loss: 1.8736920991389872
Epoch: 9| Step: 18
Training loss: 1.4868502616882324
Validation loss: 1.880538391552383
Epoch: 9| Step: 19
Training loss: 2.7330875396728516
Validation loss: 1.8853680555769008
Epoch: 50| Step: 0
Training loss: 1.930612564086914
Validation loss: 1.9058193397178924
Epoch: 9| Step: 1
Training loss: 1.8386372327804565
Validation loss: 1.8846361122543005
Epoch: 9| Step: 2
Training loss: 1.6201752424240112
Validation loss: 1.8854856062278473
Epoch: 9| Step: 3
Training loss: 2.474733829498291
Validation loss: 1.8950129430071057
Epoch: 9| Step: 4
Training loss: 2.2001078128814697
Validation loss: 1.8853326847227356
Epoch: 9| Step: 5
Training loss: 2.1210227012634277
Validation loss: 1.898650520139461
Epoch: 9| Step: 6
Training loss: 1.674370288848877
Validation loss: 1.8880526153303736
Epoch: 9| Step: 7
Training loss: 1.4864046573638916
Validation loss: 1.885804946474034
Epoch: 9| Step: 8
Training loss: 2.237941026687622
Validation loss: 1.9046321000984248
Epoch: 9| Step: 9
Training loss: 1.9025121927261353
Validation loss: 1.8839933700698743
Epoch: 9| Step: 10
Training loss: 1.9906270503997803
Validation loss: 1.8866109865174876
Epoch: 9| Step: 11
Training loss: 1.792004942893982
Validation loss: 1.8805473485438944
Epoch: 9| Step: 12
Training loss: 1.5577409267425537
Validation loss: 1.8781103607561949
Epoch: 9| Step: 13
Training loss: 2.0599255561828613
Validation loss: 1.8813710384231677
Epoch: 9| Step: 14
Training loss: 2.358247756958008
Validation loss: 1.88689706737189
Epoch: 9| Step: 15
Training loss: 2.673463821411133
Validation loss: 1.8790906127408253
Epoch: 9| Step: 16
Training loss: 1.8383008241653442
Validation loss: 1.8763263611484775
Epoch: 9| Step: 17
Training loss: 1.9205222129821777
Validation loss: 1.880026867063783
Epoch: 9| Step: 18
Training loss: 2.348806381225586
Validation loss: 1.856991111803398
Epoch: 9| Step: 19
Training loss: 2.0908408164978027
Validation loss: 1.8711390529605125
Epoch: 51| Step: 0
Training loss: 1.7381267547607422
Validation loss: 1.8673026030012172
Epoch: 9| Step: 1
Training loss: 2.3567397594451904
Validation loss: 1.8527610739358038
Epoch: 9| Step: 2
Training loss: 2.467850685119629
Validation loss: 1.8944536576168143
Epoch: 9| Step: 3
Training loss: 1.783486247062683
Validation loss: 1.8636536632510399
Epoch: 9| Step: 4
Training loss: 1.2278342247009277
Validation loss: 1.8522403660438043
Epoch: 9| Step: 5
Training loss: 2.0265111923217773
Validation loss: 1.859504004176572
Epoch: 9| Step: 6
Training loss: 2.2463130950927734
Validation loss: 1.8749546730261055
Epoch: 9| Step: 7
Training loss: 1.6041133403778076
Validation loss: 1.8680263560452908
Epoch: 9| Step: 8
Training loss: 2.229245662689209
Validation loss: 1.864066182280616
Epoch: 9| Step: 9
Training loss: 1.9304838180541992
Validation loss: 1.8538740281578447
Epoch: 9| Step: 10
Training loss: 1.8000609874725342
Validation loss: 1.8483176188503239
Epoch: 9| Step: 11
Training loss: 1.715033769607544
Validation loss: 1.8745788207157053
Epoch: 9| Step: 12
Training loss: 2.3063771724700928
Validation loss: 1.8540012965099417
Epoch: 9| Step: 13
Training loss: 2.0018138885498047
Validation loss: 1.8332979610498004
Epoch: 9| Step: 14
Training loss: 1.6566839218139648
Validation loss: 1.856487419965456
Epoch: 9| Step: 15
Training loss: 1.3967221975326538
Validation loss: 1.853494855139753
Epoch: 9| Step: 16
Training loss: 2.037482976913452
Validation loss: 1.8431608908468013
Epoch: 9| Step: 17
Training loss: 2.632455348968506
Validation loss: 1.837415438761814
Epoch: 9| Step: 18
Training loss: 2.318392753601074
Validation loss: 1.8656053688886354
Epoch: 9| Step: 19
Training loss: 2.725895404815674
Validation loss: 1.8566120339812135
Epoch: 52| Step: 0
Training loss: 2.1504111289978027
Validation loss: 1.8475069956813785
Epoch: 9| Step: 1
Training loss: 1.710127592086792
Validation loss: 1.858555474727274
Epoch: 9| Step: 2
Training loss: 1.8758268356323242
Validation loss: 1.855901137530375
Epoch: 9| Step: 3
Training loss: 2.4236865043640137
Validation loss: 1.8606457590199204
Epoch: 9| Step: 4
Training loss: 1.5870939493179321
Validation loss: 1.8655069474693682
Epoch: 9| Step: 5
Training loss: 1.611616611480713
Validation loss: 1.8733074219106771
Epoch: 9| Step: 6
Training loss: 2.413806915283203
Validation loss: 1.8563674079428474
Epoch: 9| Step: 7
Training loss: 1.7490237951278687
Validation loss: 1.8637082473837214
Epoch: 9| Step: 8
Training loss: 2.59600830078125
Validation loss: 1.8731700396366258
Epoch: 9| Step: 9
Training loss: 2.211921215057373
Validation loss: 1.8633783626899445
Epoch: 9| Step: 10
Training loss: 2.279137134552002
Validation loss: 1.8714771913967545
Epoch: 9| Step: 11
Training loss: 1.6002272367477417
Validation loss: 1.866240066590069
Epoch: 9| Step: 12
Training loss: 1.6825817823410034
Validation loss: 1.8806039172110798
Epoch: 9| Step: 13
Training loss: 2.1697709560394287
Validation loss: 1.873781109885346
Epoch: 9| Step: 14
Training loss: 1.9645931720733643
Validation loss: 1.8818103435228197
Epoch: 9| Step: 15
Training loss: 1.8848165273666382
Validation loss: 1.8858772284692997
Epoch: 9| Step: 16
Training loss: 1.7959558963775635
Validation loss: 1.873808232142771
Epoch: 9| Step: 17
Training loss: 2.158982038497925
Validation loss: 1.8683985274472683
Epoch: 9| Step: 18
Training loss: 1.980114221572876
Validation loss: 1.8778261297898327
Epoch: 9| Step: 19
Training loss: 2.2177557945251465
Validation loss: 1.8723675415670271
Epoch: 53| Step: 0
Training loss: 2.557668447494507
Validation loss: 1.8688532877311432
Epoch: 9| Step: 1
Training loss: 1.90133798122406
Validation loss: 1.8638488354442788
Epoch: 9| Step: 2
Training loss: 2.434990406036377
Validation loss: 1.8871568595762733
Epoch: 9| Step: 3
Training loss: 1.8813103437423706
Validation loss: 1.868561871617818
Epoch: 9| Step: 4
Training loss: 2.142441511154175
Validation loss: 1.8788168404599745
Epoch: 9| Step: 5
Training loss: 1.9670307636260986
Validation loss: 1.8886061229294153
Epoch: 9| Step: 6
Training loss: 1.9726097583770752
Validation loss: 1.8929320376553982
Epoch: 9| Step: 7
Training loss: 1.7822000980377197
Validation loss: 1.8726240911072107
Epoch: 9| Step: 8
Training loss: 2.035118341445923
Validation loss: 1.8776791696068194
Epoch: 9| Step: 9
Training loss: 1.8517295122146606
Validation loss: 1.870214849067249
Epoch: 9| Step: 10
Training loss: 2.0598604679107666
Validation loss: 1.9111832320261344
Epoch: 9| Step: 11
Training loss: 1.2112035751342773
Validation loss: 1.8961904108953134
Epoch: 9| Step: 12
Training loss: 2.5157828330993652
Validation loss: 1.8944248355549873
Epoch: 9| Step: 13
Training loss: 1.5164649486541748
Validation loss: 1.8816502403012283
Epoch: 9| Step: 14
Training loss: 1.7893896102905273
Validation loss: 1.8969902460523647
Epoch: 9| Step: 15
Training loss: 2.0438485145568848
Validation loss: 1.8871617240013836
Epoch: 9| Step: 16
Training loss: 1.3877657651901245
Validation loss: 1.8718911074905944
Epoch: 9| Step: 17
Training loss: 1.8271549940109253
Validation loss: 1.8702970691722074
Epoch: 9| Step: 18
Training loss: 2.1759729385375977
Validation loss: 1.8687043190002441
Epoch: 9| Step: 19
Training loss: 3.001704216003418
Validation loss: 1.8626319838942385
Epoch: 54| Step: 0
Training loss: 2.2664670944213867
Validation loss: 1.868393735919925
Epoch: 9| Step: 1
Training loss: 1.4075448513031006
Validation loss: 1.860701343138441
Epoch: 9| Step: 2
Training loss: 2.3854169845581055
Validation loss: 1.855735433187416
Epoch: 9| Step: 3
Training loss: 1.9888567924499512
Validation loss: 1.8522576839803793
Epoch: 9| Step: 4
Training loss: 2.681734561920166
Validation loss: 1.8593406497145728
Epoch: 9| Step: 5
Training loss: 1.5672000646591187
Validation loss: 1.860573034492328
Epoch: 9| Step: 6
Training loss: 2.1826019287109375
Validation loss: 1.8446182132624893
Epoch: 9| Step: 7
Training loss: 1.5966523885726929
Validation loss: 1.8616736175345003
Epoch: 9| Step: 8
Training loss: 2.1761698722839355
Validation loss: 1.8494279521832364
Epoch: 9| Step: 9
Training loss: 2.167771816253662
Validation loss: 1.8384999457023126
Epoch: 9| Step: 10
Training loss: 1.9424293041229248
Validation loss: 1.8590721689539849
Epoch: 9| Step: 11
Training loss: 2.1600794792175293
Validation loss: 1.857952149651891
Epoch: 9| Step: 12
Training loss: 1.9745638370513916
Validation loss: 1.8575688248915638
Epoch: 9| Step: 13
Training loss: 2.057994842529297
Validation loss: 1.839533170350164
Epoch: 9| Step: 14
Training loss: 2.032252311706543
Validation loss: 1.8560796667345993
Epoch: 9| Step: 15
Training loss: 1.4612115621566772
Validation loss: 1.8499281380673964
Epoch: 9| Step: 16
Training loss: 2.238990545272827
Validation loss: 1.8484029341087067
Epoch: 9| Step: 17
Training loss: 2.2059290409088135
Validation loss: 1.8464863832048375
Epoch: 9| Step: 18
Training loss: 1.8030215501785278
Validation loss: 1.8214844242274333
Epoch: 9| Step: 19
Training loss: 1.7419638633728027
Validation loss: 1.8442106718639675
Epoch: 55| Step: 0
Training loss: 1.690005898475647
Validation loss: 1.8330607954546703
Epoch: 9| Step: 1
Training loss: 2.416274070739746
Validation loss: 1.8281631058068584
Epoch: 9| Step: 2
Training loss: 1.7907583713531494
Validation loss: 1.8315666407989941
Epoch: 9| Step: 3
Training loss: 1.6476504802703857
Validation loss: 1.8330504491174822
Epoch: 9| Step: 4
Training loss: 1.9751605987548828
Validation loss: 1.8602212693193834
Epoch: 9| Step: 5
Training loss: 1.8790524005889893
Validation loss: 1.8510380237222575
Epoch: 9| Step: 6
Training loss: 1.9790918827056885
Validation loss: 1.8397045641494312
Epoch: 9| Step: 7
Training loss: 2.1150994300842285
Validation loss: 1.8391644302889598
Epoch: 9| Step: 8
Training loss: 2.415156364440918
Validation loss: 1.8466303811656486
Epoch: 9| Step: 9
Training loss: 2.3060708045959473
Validation loss: 1.8341912039749915
Epoch: 9| Step: 10
Training loss: 2.3549623489379883
Validation loss: 1.8455264551176442
Epoch: 9| Step: 11
Training loss: 1.7392776012420654
Validation loss: 1.8294291959392082
Epoch: 9| Step: 12
Training loss: 2.3178625106811523
Validation loss: 1.8296397572798695
Epoch: 9| Step: 13
Training loss: 1.9739676713943481
Validation loss: 1.8474369169139175
Epoch: 9| Step: 14
Training loss: 2.272315263748169
Validation loss: 1.844024382906852
Epoch: 9| Step: 15
Training loss: 2.0120387077331543
Validation loss: 1.8361792066972034
Epoch: 9| Step: 16
Training loss: 1.755002737045288
Validation loss: 1.8372069434296312
Epoch: 9| Step: 17
Training loss: 2.073134422302246
Validation loss: 1.8376814821641223
Epoch: 9| Step: 18
Training loss: 1.7102890014648438
Validation loss: 1.8371861795727298
Epoch: 9| Step: 19
Training loss: 1.7582987546920776
Validation loss: 1.8453612413337763
Epoch: 56| Step: 0
Training loss: 2.2132954597473145
Validation loss: 1.8432753000328008
Epoch: 9| Step: 1
Training loss: 2.0893101692199707
Validation loss: 1.8342442109430437
Epoch: 9| Step: 2
Training loss: 1.334627389907837
Validation loss: 1.857586412978687
Epoch: 9| Step: 3
Training loss: 1.5301949977874756
Validation loss: 1.8481512910170521
Epoch: 9| Step: 4
Training loss: 1.884501338005066
Validation loss: 1.8515793822652145
Epoch: 9| Step: 5
Training loss: 2.085437297821045
Validation loss: 1.862110697108207
Epoch: 9| Step: 6
Training loss: 2.206879138946533
Validation loss: 1.8515674081637705
Epoch: 9| Step: 7
Training loss: 2.463698625564575
Validation loss: 1.866367762894939
Epoch: 9| Step: 8
Training loss: 2.175058364868164
Validation loss: 1.873070600221483
Epoch: 9| Step: 9
Training loss: 1.4908201694488525
Validation loss: 1.8415492515769794
Epoch: 9| Step: 10
Training loss: 1.9916744232177734
Validation loss: 1.849992672316462
Epoch: 9| Step: 11
Training loss: 2.2480673789978027
Validation loss: 1.8467348479538512
Epoch: 9| Step: 12
Training loss: 2.3895416259765625
Validation loss: 1.848300725436039
Epoch: 9| Step: 13
Training loss: 1.800630807876587
Validation loss: 1.8517011035260538
Epoch: 9| Step: 14
Training loss: 2.494663715362549
Validation loss: 1.855099575982677
Epoch: 9| Step: 15
Training loss: 2.143113851547241
Validation loss: 1.8648910616799224
Epoch: 9| Step: 16
Training loss: 1.7707667350769043
Validation loss: 1.8600411466557345
Epoch: 9| Step: 17
Training loss: 2.080860137939453
Validation loss: 1.8585855128953783
Epoch: 9| Step: 18
Training loss: 2.172830104827881
Validation loss: 1.8725443332315348
Epoch: 9| Step: 19
Training loss: 1.4442455768585205
Validation loss: 1.8538246549290718
Epoch: 57| Step: 0
Training loss: 1.5331933498382568
Validation loss: 1.862068780892187
Epoch: 9| Step: 1
Training loss: 1.9708735942840576
Validation loss: 1.8583713135273336
Epoch: 9| Step: 2
Training loss: 2.7811779975891113
Validation loss: 1.85728769336673
Epoch: 9| Step: 3
Training loss: 2.8928518295288086
Validation loss: 1.8440571080008856
Epoch: 9| Step: 4
Training loss: 1.9969837665557861
Validation loss: 1.855713768828687
Epoch: 9| Step: 5
Training loss: 1.8571549654006958
Validation loss: 1.8507876241807457
Epoch: 9| Step: 6
Training loss: 1.5215580463409424
Validation loss: 1.8391323235395143
Epoch: 9| Step: 7
Training loss: 2.189920425415039
Validation loss: 1.8549136497991547
Epoch: 9| Step: 8
Training loss: 1.6990551948547363
Validation loss: 1.8328113187131265
Epoch: 9| Step: 9
Training loss: 1.8548301458358765
Validation loss: 1.8395555585408383
Epoch: 9| Step: 10
Training loss: 2.1533451080322266
Validation loss: 1.830899573916154
Epoch: 9| Step: 11
Training loss: 2.5555615425109863
Validation loss: 1.8512108360263084
Epoch: 9| Step: 12
Training loss: 1.829769492149353
Validation loss: 1.8280397276226565
Epoch: 9| Step: 13
Training loss: 1.9259079694747925
Validation loss: 1.8342687466161713
Epoch: 9| Step: 14
Training loss: 1.83817720413208
Validation loss: 1.8509278468948474
Epoch: 9| Step: 15
Training loss: 1.9357026815414429
Validation loss: 1.8578068695480017
Epoch: 9| Step: 16
Training loss: 1.594448447227478
Validation loss: 1.8578561055574485
Epoch: 9| Step: 17
Training loss: 2.3260719776153564
Validation loss: 1.843729100639014
Epoch: 9| Step: 18
Training loss: 1.4522697925567627
Validation loss: 1.868518789895147
Epoch: 9| Step: 19
Training loss: 1.9223681688308716
Validation loss: 1.8674630870064386
Epoch: 58| Step: 0
Training loss: 1.9630043506622314
Validation loss: 1.8635194370214887
Epoch: 9| Step: 1
Training loss: 2.224729537963867
Validation loss: 1.867250246967343
Epoch: 9| Step: 2
Training loss: 2.474738121032715
Validation loss: 1.8692402299359547
Epoch: 9| Step: 3
Training loss: 1.6725966930389404
Validation loss: 1.8525905437606702
Epoch: 9| Step: 4
Training loss: 1.52252197265625
Validation loss: 1.8468338396909425
Epoch: 9| Step: 5
Training loss: 2.5071229934692383
Validation loss: 1.8542277770076725
Epoch: 9| Step: 6
Training loss: 1.7022693157196045
Validation loss: 1.8556298369126354
Epoch: 9| Step: 7
Training loss: 2.696315288543701
Validation loss: 1.8470195823436162
Epoch: 9| Step: 8
Training loss: 1.8950875997543335
Validation loss: 1.858924862292173
Epoch: 9| Step: 9
Training loss: 1.6486127376556396
Validation loss: 1.851781292784986
Epoch: 9| Step: 10
Training loss: 2.3652291297912598
Validation loss: 1.839849858832874
Epoch: 9| Step: 11
Training loss: 1.744832992553711
Validation loss: 1.8567654486182783
Epoch: 9| Step: 12
Training loss: 2.0439114570617676
Validation loss: 1.855591338315456
Epoch: 9| Step: 13
Training loss: 1.8500804901123047
Validation loss: 1.8656861790650183
Epoch: 9| Step: 14
Training loss: 1.58432137966156
Validation loss: 1.8513377072999804
Epoch: 9| Step: 15
Training loss: 2.12467885017395
Validation loss: 1.8706527459535667
Epoch: 9| Step: 16
Training loss: 2.0045790672302246
Validation loss: 1.8710534478263032
Epoch: 9| Step: 17
Training loss: 1.831113338470459
Validation loss: 1.8536742754119764
Epoch: 9| Step: 18
Training loss: 2.4807090759277344
Validation loss: 1.8723435067444396
Epoch: 9| Step: 19
Training loss: 1.6626129150390625
Validation loss: 1.8811335297797223
Epoch: 59| Step: 0
Training loss: 2.4861364364624023
Validation loss: 1.8715909547943006
Epoch: 9| Step: 1
Training loss: 2.099097967147827
Validation loss: 1.8601760178161182
Epoch: 9| Step: 2
Training loss: 2.482072114944458
Validation loss: 1.8451278707106336
Epoch: 9| Step: 3
Training loss: 1.679304599761963
Validation loss: 1.8576830951429957
Epoch: 9| Step: 4
Training loss: 1.7026559114456177
Validation loss: 1.8672291306282978
Epoch: 9| Step: 5
Training loss: 1.9964655637741089
Validation loss: 1.8651368763807008
Epoch: 9| Step: 6
Training loss: 1.8590428829193115
Validation loss: 1.8644030360009174
Epoch: 9| Step: 7
Training loss: 1.555288314819336
Validation loss: 1.8768111716071478
Epoch: 9| Step: 8
Training loss: 1.8279579877853394
Validation loss: 1.884840135094073
Epoch: 9| Step: 9
Training loss: 2.0482420921325684
Validation loss: 1.8625821321130656
Epoch: 9| Step: 10
Training loss: 2.3986196517944336
Validation loss: 1.8753609142715124
Epoch: 9| Step: 11
Training loss: 2.1755576133728027
Validation loss: 1.8782401187814397
Epoch: 9| Step: 12
Training loss: 1.5915464162826538
Validation loss: 1.9048288537443971
Epoch: 9| Step: 13
Training loss: 1.944847822189331
Validation loss: 1.8803730817149868
Epoch: 9| Step: 14
Training loss: 2.056659460067749
Validation loss: 1.8836342336462557
Epoch: 9| Step: 15
Training loss: 2.4625437259674072
Validation loss: 1.87817246793843
Epoch: 9| Step: 16
Training loss: 2.599080801010132
Validation loss: 1.8741645770107243
Epoch: 9| Step: 17
Training loss: 1.5934364795684814
Validation loss: 1.8551444492751745
Epoch: 9| Step: 18
Training loss: 1.2928776741027832
Validation loss: 1.8389463236006043
Epoch: 9| Step: 19
Training loss: 2.058889150619507
Validation loss: 1.8619152273205544
Epoch: 60| Step: 0
Training loss: 1.5644997358322144
Validation loss: 1.865455822978946
Epoch: 9| Step: 1
Training loss: 1.7369672060012817
Validation loss: 1.8505880592538297
Epoch: 9| Step: 2
Training loss: 2.2111635208129883
Validation loss: 1.849037394249182
Epoch: 9| Step: 3
Training loss: 1.6052740812301636
Validation loss: 1.850426703048267
Epoch: 9| Step: 4
Training loss: 1.5890278816223145
Validation loss: 1.8462810104699443
Epoch: 9| Step: 5
Training loss: 1.829777717590332
Validation loss: 1.835078429832733
Epoch: 9| Step: 6
Training loss: 1.959681749343872
Validation loss: 1.8346858359069276
Epoch: 9| Step: 7
Training loss: 1.6316077709197998
Validation loss: 1.8406236403280025
Epoch: 9| Step: 8
Training loss: 1.7102402448654175
Validation loss: 1.8396735328564542
Epoch: 9| Step: 9
Training loss: 1.8837661743164062
Validation loss: 1.848488142164491
Epoch: 9| Step: 10
Training loss: 2.655184507369995
Validation loss: 1.8400228092138715
Epoch: 9| Step: 11
Training loss: 2.3989782333374023
Validation loss: 1.8290537732968228
Epoch: 9| Step: 12
Training loss: 2.315688371658325
Validation loss: 1.8343934266687296
Epoch: 9| Step: 13
Training loss: 2.6875967979431152
Validation loss: 1.8428030871658874
Epoch: 9| Step: 14
Training loss: 1.9403209686279297
Validation loss: 1.8258410580724262
Epoch: 9| Step: 15
Training loss: 2.3050999641418457
Validation loss: 1.8406756267273168
Epoch: 9| Step: 16
Training loss: 1.7112109661102295
Validation loss: 1.8204653932036257
Epoch: 9| Step: 17
Training loss: 2.898559093475342
Validation loss: 1.835618549113651
Epoch: 9| Step: 18
Training loss: 1.399016261100769
Validation loss: 1.8298268283871437
Epoch: 9| Step: 19
Training loss: 2.017467737197876
Validation loss: 1.8355356369087164
Epoch: 61| Step: 0
Training loss: 2.2328152656555176
Validation loss: 1.8389344704236916
Epoch: 9| Step: 1
Training loss: 1.6234407424926758
Validation loss: 1.8550297253423458
Epoch: 9| Step: 2
Training loss: 1.7791361808776855
Validation loss: 1.8450508820924827
Epoch: 9| Step: 3
Training loss: 1.7349798679351807
Validation loss: 1.8454473027222449
Epoch: 9| Step: 4
Training loss: 2.452570915222168
Validation loss: 1.8485267162322998
Epoch: 9| Step: 5
Training loss: 1.7975654602050781
Validation loss: 1.844093206117479
Epoch: 9| Step: 6
Training loss: 2.5360097885131836
Validation loss: 1.8438130977342455
Epoch: 9| Step: 7
Training loss: 2.017880439758301
Validation loss: 1.8472678815718178
Epoch: 9| Step: 8
Training loss: 2.019432306289673
Validation loss: 1.8495229216788311
Epoch: 9| Step: 9
Training loss: 2.0901405811309814
Validation loss: 1.8501678456505426
Epoch: 9| Step: 10
Training loss: 1.7511985301971436
Validation loss: 1.8456605681412512
Epoch: 9| Step: 11
Training loss: 2.5645623207092285
Validation loss: 1.8576551135495412
Epoch: 9| Step: 12
Training loss: 1.8157439231872559
Validation loss: 1.8548242196762303
Epoch: 9| Step: 13
Training loss: 2.0954012870788574
Validation loss: 1.8567267390463849
Epoch: 9| Step: 14
Training loss: 2.281141519546509
Validation loss: 1.8508669729713056
Epoch: 9| Step: 15
Training loss: 1.6365654468536377
Validation loss: 1.847109876948295
Epoch: 9| Step: 16
Training loss: 1.908169150352478
Validation loss: 1.8337708222780296
Epoch: 9| Step: 17
Training loss: 1.744469165802002
Validation loss: 1.8388751642309504
Epoch: 9| Step: 18
Training loss: 2.3115763664245605
Validation loss: 1.8465483222933983
Epoch: 9| Step: 19
Training loss: 1.584137201309204
Validation loss: 1.8495755890290515
Epoch: 62| Step: 0
Training loss: 2.09072208404541
Validation loss: 1.8401148490768542
Epoch: 9| Step: 1
Training loss: 2.200812816619873
Validation loss: 1.8502377571819497
Epoch: 9| Step: 2
Training loss: 1.7537131309509277
Validation loss: 1.8460840938760221
Epoch: 9| Step: 3
Training loss: 2.3697257041931152
Validation loss: 1.8490566384020468
Epoch: 9| Step: 4
Training loss: 2.531033515930176
Validation loss: 1.8462882642265703
Epoch: 9| Step: 5
Training loss: 2.0673840045928955
Validation loss: 1.84942023016566
Epoch: 9| Step: 6
Training loss: 2.5079705715179443
Validation loss: 1.841313030222337
Epoch: 9| Step: 7
Training loss: 1.5871691703796387
Validation loss: 1.8419229435406144
Epoch: 9| Step: 8
Training loss: 2.17500638961792
Validation loss: 1.8416964947748526
Epoch: 9| Step: 9
Training loss: 2.2126710414886475
Validation loss: 1.849430560208053
Epoch: 9| Step: 10
Training loss: 2.0245652198791504
Validation loss: 1.8469441794663024
Epoch: 9| Step: 11
Training loss: 1.6652864217758179
Validation loss: 1.832266711502624
Epoch: 9| Step: 12
Training loss: 1.4901354312896729
Validation loss: 1.8436833285599303
Epoch: 9| Step: 13
Training loss: 2.578054904937744
Validation loss: 1.8433739512944394
Epoch: 9| Step: 14
Training loss: 1.6257977485656738
Validation loss: 1.817336997539877
Epoch: 9| Step: 15
Training loss: 2.458698272705078
Validation loss: 1.8275480193199871
Epoch: 9| Step: 16
Training loss: 1.5727076530456543
Validation loss: 1.8238460751746197
Epoch: 9| Step: 17
Training loss: 2.2645163536071777
Validation loss: 1.847301369090732
Epoch: 9| Step: 18
Training loss: 1.281463623046875
Validation loss: 1.8412778446142621
Epoch: 9| Step: 19
Training loss: 1.440756916999817
Validation loss: 1.844995407749423
Epoch: 63| Step: 0
Training loss: 2.0460410118103027
Validation loss: 1.8240743532455226
Epoch: 9| Step: 1
Training loss: 1.8539156913757324
Validation loss: 1.8439973601334387
Epoch: 9| Step: 2
Training loss: 2.050339937210083
Validation loss: 1.849590650994143
Epoch: 9| Step: 3
Training loss: 1.8524999618530273
Validation loss: 1.8638123050868083
Epoch: 9| Step: 4
Training loss: 1.5034124851226807
Validation loss: 1.8440708925398133
Epoch: 9| Step: 5
Training loss: 1.8349610567092896
Validation loss: 1.8474722809071162
Epoch: 9| Step: 6
Training loss: 2.3174171447753906
Validation loss: 1.8489387043946082
Epoch: 9| Step: 7
Training loss: 1.3521199226379395
Validation loss: 1.8466126764420983
Epoch: 9| Step: 8
Training loss: 1.5342631340026855
Validation loss: 1.8524300606130697
Epoch: 9| Step: 9
Training loss: 2.147836685180664
Validation loss: 1.8680004550398683
Epoch: 9| Step: 10
Training loss: 2.6949520111083984
Validation loss: 1.8558970132320047
Epoch: 9| Step: 11
Training loss: 2.0166237354278564
Validation loss: 1.8507707685017758
Epoch: 9| Step: 12
Training loss: 2.728874683380127
Validation loss: 1.8539131802620648
Epoch: 9| Step: 13
Training loss: 1.1420409679412842
Validation loss: 1.8481307921649741
Epoch: 9| Step: 14
Training loss: 2.0691730976104736
Validation loss: 1.8498426255562324
Epoch: 9| Step: 15
Training loss: 2.3578014373779297
Validation loss: 1.8560413473801647
Epoch: 9| Step: 16
Training loss: 2.084087371826172
Validation loss: 1.845160949144432
Epoch: 9| Step: 17
Training loss: 1.5522902011871338
Validation loss: 1.843226630910695
Epoch: 9| Step: 18
Training loss: 2.32882022857666
Validation loss: 1.8561841755462207
Epoch: 9| Step: 19
Training loss: 2.5375747680664062
Validation loss: 1.8661425628250452
Epoch: 64| Step: 0
Training loss: 2.20603084564209
Validation loss: 1.8481833180077643
Epoch: 9| Step: 1
Training loss: 2.183474540710449
Validation loss: 1.8447067497445524
Epoch: 9| Step: 2
Training loss: 2.303480863571167
Validation loss: 1.856228070293399
Epoch: 9| Step: 3
Training loss: 1.5627449750900269
Validation loss: 1.8529015445023131
Epoch: 9| Step: 4
Training loss: 2.4486231803894043
Validation loss: 1.8593111424137363
Epoch: 9| Step: 5
Training loss: 1.8399240970611572
Validation loss: 1.840615145594096
Epoch: 9| Step: 6
Training loss: 1.8876383304595947
Validation loss: 1.859582733764923
Epoch: 9| Step: 7
Training loss: 2.1279468536376953
Validation loss: 1.86063611764702
Epoch: 9| Step: 8
Training loss: 1.355987548828125
Validation loss: 1.8389615789591838
Epoch: 9| Step: 9
Training loss: 1.2808501720428467
Validation loss: 1.828741002425873
Epoch: 9| Step: 10
Training loss: 1.7547411918640137
Validation loss: 1.8442633597970866
Epoch: 9| Step: 11
Training loss: 2.368985176086426
Validation loss: 1.841117513265541
Epoch: 9| Step: 12
Training loss: 2.377776622772217
Validation loss: 1.8546264892001805
Epoch: 9| Step: 13
Training loss: 2.403352975845337
Validation loss: 1.8507729880243755
Epoch: 9| Step: 14
Training loss: 2.8138678073883057
Validation loss: 1.8649181513477573
Epoch: 9| Step: 15
Training loss: 1.9513535499572754
Validation loss: 1.8405687491670788
Epoch: 9| Step: 16
Training loss: 1.726974606513977
Validation loss: 1.864279132952793
Epoch: 9| Step: 17
Training loss: 2.0377442836761475
Validation loss: 1.8532551415532612
Epoch: 9| Step: 18
Training loss: 1.4250500202178955
Validation loss: 1.836026595650817
Epoch: 9| Step: 19
Training loss: 1.9846107959747314
Validation loss: 1.8482854014677967
Epoch: 65| Step: 0
Training loss: 2.673640489578247
Validation loss: 1.849005767767378
Epoch: 9| Step: 1
Training loss: 2.0208725929260254
Validation loss: 1.8391325044975007
Epoch: 9| Step: 2
Training loss: 2.1899843215942383
Validation loss: 1.8434848716790728
Epoch: 9| Step: 3
Training loss: 1.7272037267684937
Validation loss: 1.8526181102656631
Epoch: 9| Step: 4
Training loss: 2.3749940395355225
Validation loss: 1.8405233287125182
Epoch: 9| Step: 5
Training loss: 1.7095160484313965
Validation loss: 1.8364445820129176
Epoch: 9| Step: 6
Training loss: 1.7515678405761719
Validation loss: 1.849695729694778
Epoch: 9| Step: 7
Training loss: 2.6692028045654297
Validation loss: 1.825738277366693
Epoch: 9| Step: 8
Training loss: 1.3386651277542114
Validation loss: 1.8350290137229206
Epoch: 9| Step: 9
Training loss: 1.4261343479156494
Validation loss: 1.8315651468235812
Epoch: 9| Step: 10
Training loss: 2.2305023670196533
Validation loss: 1.8207506361625176
Epoch: 9| Step: 11
Training loss: 2.128180980682373
Validation loss: 1.833276419330844
Epoch: 9| Step: 12
Training loss: 1.5782389640808105
Validation loss: 1.8367823559603245
Epoch: 9| Step: 13
Training loss: 2.442462205886841
Validation loss: 1.840014913956896
Epoch: 9| Step: 14
Training loss: 1.767182469367981
Validation loss: 1.8163935829409592
Epoch: 9| Step: 15
Training loss: 1.8429644107818604
Validation loss: 1.8181845464294764
Epoch: 9| Step: 16
Training loss: 1.8040730953216553
Validation loss: 1.8279949966952098
Epoch: 9| Step: 17
Training loss: 2.242337703704834
Validation loss: 1.8264399320959188
Epoch: 9| Step: 18
Training loss: 2.169402599334717
Validation loss: 1.8537936142022662
Epoch: 9| Step: 19
Training loss: 1.6607762575149536
Validation loss: 1.8463197440552197
Epoch: 66| Step: 0
Training loss: 2.7623000144958496
Validation loss: 1.8530812272064978
Epoch: 9| Step: 1
Training loss: 2.045297622680664
Validation loss: 1.8577151470047106
Epoch: 9| Step: 2
Training loss: 1.9577606916427612
Validation loss: 1.8413423891547773
Epoch: 9| Step: 3
Training loss: 1.715333104133606
Validation loss: 1.8483896083969007
Epoch: 9| Step: 4
Training loss: 1.4345920085906982
Validation loss: 1.8474302977966748
Epoch: 9| Step: 5
Training loss: 1.6988890171051025
Validation loss: 1.848666418370583
Epoch: 9| Step: 6
Training loss: 1.407488226890564
Validation loss: 1.8510653020666659
Epoch: 9| Step: 7
Training loss: 1.84377121925354
Validation loss: 1.8538541708061163
Epoch: 9| Step: 8
Training loss: 2.303551197052002
Validation loss: 1.8688008793824011
Epoch: 9| Step: 9
Training loss: 1.7743877172470093
Validation loss: 1.8726841460028998
Epoch: 9| Step: 10
Training loss: 1.9376800060272217
Validation loss: 1.8768226431428099
Epoch: 9| Step: 11
Training loss: 2.2816264629364014
Validation loss: 1.8840246149104276
Epoch: 9| Step: 12
Training loss: 1.7089262008666992
Validation loss: 1.8938136503850813
Epoch: 9| Step: 13
Training loss: 1.794825792312622
Validation loss: 1.8859958262752285
Epoch: 9| Step: 14
Training loss: 1.8743674755096436
Validation loss: 1.9042453062620095
Epoch: 9| Step: 15
Training loss: 2.4204866886138916
Validation loss: 1.8889330316790574
Epoch: 9| Step: 16
Training loss: 1.7333709001541138
Validation loss: 1.8976740065238458
Epoch: 9| Step: 17
Training loss: 2.560002326965332
Validation loss: 1.9088325551945529
Epoch: 9| Step: 18
Training loss: 2.504190444946289
Validation loss: 1.9039019431999262
Epoch: 9| Step: 19
Training loss: 2.20631742477417
Validation loss: 1.8773261317246253
Epoch: 67| Step: 0
Training loss: 2.2235639095306396
Validation loss: 1.8911071046650838
Epoch: 9| Step: 1
Training loss: 2.4751391410827637
Validation loss: 1.8752671317230882
Epoch: 9| Step: 2
Training loss: 1.7348358631134033
Validation loss: 1.8621067597711687
Epoch: 9| Step: 3
Training loss: 2.0466835498809814
Validation loss: 1.8605360135757665
Epoch: 9| Step: 4
Training loss: 1.8589558601379395
Validation loss: 1.8546928433205585
Epoch: 9| Step: 5
Training loss: 1.5890934467315674
Validation loss: 1.8390116605827276
Epoch: 9| Step: 6
Training loss: 1.590486764907837
Validation loss: 1.8356824693062324
Epoch: 9| Step: 7
Training loss: 2.7164461612701416
Validation loss: 1.8346692598123344
Epoch: 9| Step: 8
Training loss: 1.7224429845809937
Validation loss: 1.8348117629401117
Epoch: 9| Step: 9
Training loss: 1.8314871788024902
Validation loss: 1.8196255869145015
Epoch: 9| Step: 10
Training loss: 1.9948198795318604
Validation loss: 1.8100904423555881
Epoch: 9| Step: 11
Training loss: 2.4462826251983643
Validation loss: 1.8046658382141332
Epoch: 9| Step: 12
Training loss: 2.3173065185546875
Validation loss: 1.8271905020844164
Epoch: 9| Step: 13
Training loss: 1.9207360744476318
Validation loss: 1.818038428430077
Epoch: 9| Step: 14
Training loss: 2.2410402297973633
Validation loss: 1.809189091483466
Epoch: 9| Step: 15
Training loss: 1.9883970022201538
Validation loss: 1.8103375966600377
Epoch: 9| Step: 16
Training loss: 1.9771661758422852
Validation loss: 1.8316354554334133
Epoch: 9| Step: 17
Training loss: 1.4629619121551514
Validation loss: 1.8351386193748858
Epoch: 9| Step: 18
Training loss: 1.7749302387237549
Validation loss: 1.818194995681159
Epoch: 9| Step: 19
Training loss: 1.9847806692123413
Validation loss: 1.8344037146877041
Epoch: 68| Step: 0
Training loss: 1.5730924606323242
Validation loss: 1.846564438703249
Epoch: 9| Step: 1
Training loss: 2.524601459503174
Validation loss: 1.8435236841654605
Epoch: 9| Step: 2
Training loss: 2.0659968852996826
Validation loss: 1.8420749679743815
Epoch: 9| Step: 3
Training loss: 1.4109951257705688
Validation loss: 1.8425291948181262
Epoch: 9| Step: 4
Training loss: 2.0049800872802734
Validation loss: 1.840523479653777
Epoch: 9| Step: 5
Training loss: 2.112548351287842
Validation loss: 1.8516112951923618
Epoch: 9| Step: 6
Training loss: 2.2631561756134033
Validation loss: 1.827348803444732
Epoch: 9| Step: 7
Training loss: 1.3429511785507202
Validation loss: 1.8410812907939336
Epoch: 9| Step: 8
Training loss: 1.6621631383895874
Validation loss: 1.8558228530472132
Epoch: 9| Step: 9
Training loss: 2.2615396976470947
Validation loss: 1.844005281119038
Epoch: 9| Step: 10
Training loss: 1.801340103149414
Validation loss: 1.86900152491151
Epoch: 9| Step: 11
Training loss: 2.514341354370117
Validation loss: 1.8650667427255094
Epoch: 9| Step: 12
Training loss: 2.250443458557129
Validation loss: 1.8540158426161293
Epoch: 9| Step: 13
Training loss: 2.4103217124938965
Validation loss: 1.8625660663028416
Epoch: 9| Step: 14
Training loss: 2.158602237701416
Validation loss: 1.8510989448149426
Epoch: 9| Step: 15
Training loss: 2.181659698486328
Validation loss: 1.854894648352973
Epoch: 9| Step: 16
Training loss: 1.9263617992401123
Validation loss: 1.8530570826084494
Epoch: 9| Step: 17
Training loss: 1.7659742832183838
Validation loss: 1.8529532247310063
Epoch: 9| Step: 18
Training loss: 1.9875986576080322
Validation loss: 1.8493019067983834
Epoch: 9| Step: 19
Training loss: 1.5095854997634888
Validation loss: 1.8601429856938423
Epoch: 69| Step: 0
Training loss: 2.4880290031433105
Validation loss: 1.8694498264532295
Epoch: 9| Step: 1
Training loss: 3.2498645782470703
Validation loss: 1.868307542457855
Epoch: 9| Step: 2
Training loss: 1.9531443119049072
Validation loss: 1.8743370728527042
Epoch: 9| Step: 3
Training loss: 2.2216644287109375
Validation loss: 1.878853650401822
Epoch: 9| Step: 4
Training loss: 1.8001832962036133
Validation loss: 1.8623088623979966
Epoch: 9| Step: 5
Training loss: 2.0353448390960693
Validation loss: 1.8530200462547137
Epoch: 9| Step: 6
Training loss: 1.8261805772781372
Validation loss: 1.8522729582066157
Epoch: 9| Step: 7
Training loss: 1.6804336309432983
Validation loss: 1.8609982085742538
Epoch: 9| Step: 8
Training loss: 1.4934828281402588
Validation loss: 1.8595000599785674
Epoch: 9| Step: 9
Training loss: 2.3356847763061523
Validation loss: 1.8550869277912936
Epoch: 9| Step: 10
Training loss: 1.515040636062622
Validation loss: 1.8528976766325587
Epoch: 9| Step: 11
Training loss: 2.34336519241333
Validation loss: 1.8593337132776384
Epoch: 9| Step: 12
Training loss: 1.5310122966766357
Validation loss: 1.8546747286542713
Epoch: 9| Step: 13
Training loss: 1.5552692413330078
Validation loss: 1.855852573038005
Epoch: 9| Step: 14
Training loss: 2.096022844314575
Validation loss: 1.8543989967099197
Epoch: 9| Step: 15
Training loss: 2.2189159393310547
Validation loss: 1.8457822851139865
Epoch: 9| Step: 16
Training loss: 1.6150619983673096
Validation loss: 1.8638956538207239
Epoch: 9| Step: 17
Training loss: 1.888031005859375
Validation loss: 1.8587627565260414
Epoch: 9| Step: 18
Training loss: 1.986810564994812
Validation loss: 1.8505047988548553
Epoch: 9| Step: 19
Training loss: 1.9008800983428955
Validation loss: 1.8417330457152223
Epoch: 70| Step: 0
Training loss: 1.7945263385772705
Validation loss: 1.8704975028689816
Epoch: 9| Step: 1
Training loss: 1.517723798751831
Validation loss: 1.865045128966407
Epoch: 9| Step: 2
Training loss: 1.8746697902679443
Validation loss: 1.8740684068460258
Epoch: 9| Step: 3
Training loss: 2.4462900161743164
Validation loss: 1.850183254523243
Epoch: 9| Step: 4
Training loss: 1.7274699211120605
Validation loss: 1.8600396209483525
Epoch: 9| Step: 5
Training loss: 2.416980504989624
Validation loss: 1.8604621372634558
Epoch: 9| Step: 6
Training loss: 1.899156093597412
Validation loss: 1.8621338219951382
Epoch: 9| Step: 7
Training loss: 2.3317203521728516
Validation loss: 1.8509823709940738
Epoch: 9| Step: 8
Training loss: 1.702049732208252
Validation loss: 1.8587267690425298
Epoch: 9| Step: 9
Training loss: 2.4719676971435547
Validation loss: 1.8329259285823905
Epoch: 9| Step: 10
Training loss: 1.9003934860229492
Validation loss: 1.8505732743002528
Epoch: 9| Step: 11
Training loss: 2.206800937652588
Validation loss: 1.817050567633814
Epoch: 9| Step: 12
Training loss: 1.970433235168457
Validation loss: 1.8260906840399873
Epoch: 9| Step: 13
Training loss: 2.6954994201660156
Validation loss: 1.8181487364734676
Epoch: 9| Step: 14
Training loss: 1.8037265539169312
Validation loss: 1.8304156125020639
Epoch: 9| Step: 15
Training loss: 1.8723478317260742
Validation loss: 1.817206759246991
Epoch: 9| Step: 16
Training loss: 1.6765391826629639
Validation loss: 1.810514997235305
Epoch: 9| Step: 17
Training loss: 2.2632222175598145
Validation loss: 1.8201697661722307
Epoch: 9| Step: 18
Training loss: 1.928585171699524
Validation loss: 1.8293393858902747
Epoch: 9| Step: 19
Training loss: 1.4504492282867432
Validation loss: 1.825683415364876
Epoch: 71| Step: 0
Training loss: 2.3185477256774902
Validation loss: 1.8341050439601323
Epoch: 9| Step: 1
Training loss: 2.044888496398926
Validation loss: 1.8226317355958679
Epoch: 9| Step: 2
Training loss: 2.5631613731384277
Validation loss: 1.8573307733741595
Epoch: 9| Step: 3
Training loss: 2.224698781967163
Validation loss: 1.8189167736245573
Epoch: 9| Step: 4
Training loss: 1.6232924461364746
Validation loss: 1.826884701097612
Epoch: 9| Step: 5
Training loss: 1.5666054487228394
Validation loss: 1.8401714932146689
Epoch: 9| Step: 6
Training loss: 2.2698867321014404
Validation loss: 1.8252793233171642
Epoch: 9| Step: 7
Training loss: 1.5839582681655884
Validation loss: 1.8245292344539286
Epoch: 9| Step: 8
Training loss: 1.9761912822723389
Validation loss: 1.8373736503312914
Epoch: 9| Step: 9
Training loss: 1.8743406534194946
Validation loss: 1.844124776853932
Epoch: 9| Step: 10
Training loss: 2.4263648986816406
Validation loss: 1.856418073606148
Epoch: 9| Step: 11
Training loss: 2.0655770301818848
Validation loss: 1.8593280615566445
Epoch: 9| Step: 12
Training loss: 1.7890372276306152
Validation loss: 1.856757171720052
Epoch: 9| Step: 13
Training loss: 2.74367356300354
Validation loss: 1.8616823652665393
Epoch: 9| Step: 14
Training loss: 1.9602329730987549
Validation loss: 1.8544980630600194
Epoch: 9| Step: 15
Training loss: 1.7932590246200562
Validation loss: 1.8438214535335842
Epoch: 9| Step: 16
Training loss: 1.7767455577850342
Validation loss: 1.844004596737649
Epoch: 9| Step: 17
Training loss: 1.8889113664627075
Validation loss: 1.8526439709629086
Epoch: 9| Step: 18
Training loss: 0.9320775270462036
Validation loss: 1.8400573713316335
Epoch: 9| Step: 19
Training loss: 2.1869969367980957
Validation loss: 1.8471288869706848
Epoch: 72| Step: 0
Training loss: 2.1040565967559814
Validation loss: 1.8502506060565975
Epoch: 9| Step: 1
Training loss: 1.8119990825653076
Validation loss: 1.8575032837956928
Epoch: 9| Step: 2
Training loss: 1.9697682857513428
Validation loss: 1.8567020490015154
Epoch: 9| Step: 3
Training loss: 1.9374544620513916
Validation loss: 1.8506013935418437
Epoch: 9| Step: 4
Training loss: 1.7489795684814453
Validation loss: 1.8517910001946867
Epoch: 9| Step: 5
Training loss: 1.862836241722107
Validation loss: 1.8554151607074325
Epoch: 9| Step: 6
Training loss: 1.8060014247894287
Validation loss: 1.875272513293534
Epoch: 9| Step: 7
Training loss: 1.8257173299789429
Validation loss: 1.846296321573875
Epoch: 9| Step: 8
Training loss: 1.6803312301635742
Validation loss: 1.8711068201408112
Epoch: 9| Step: 9
Training loss: 2.533919095993042
Validation loss: 1.85104417457855
Epoch: 9| Step: 10
Training loss: 2.294473171234131
Validation loss: 1.8600487700469202
Epoch: 9| Step: 11
Training loss: 2.0429868698120117
Validation loss: 1.8380420825464263
Epoch: 9| Step: 12
Training loss: 1.9718611240386963
Validation loss: 1.8599799211076695
Epoch: 9| Step: 13
Training loss: 1.727220892906189
Validation loss: 1.8503086592653673
Epoch: 9| Step: 14
Training loss: 1.4679508209228516
Validation loss: 1.8516365049554289
Epoch: 9| Step: 15
Training loss: 2.0495481491088867
Validation loss: 1.84256908018812
Epoch: 9| Step: 16
Training loss: 2.3720240592956543
Validation loss: 1.8501749776250167
Epoch: 9| Step: 17
Training loss: 2.009989023208618
Validation loss: 1.8541817545033188
Epoch: 9| Step: 18
Training loss: 2.091718912124634
Validation loss: 1.8479992734442512
Epoch: 9| Step: 19
Training loss: 2.340111255645752
Validation loss: 1.856272820946124
Epoch: 73| Step: 0
Training loss: 1.9146146774291992
Validation loss: 1.8501084090994417
Epoch: 9| Step: 1
Training loss: 2.2435965538024902
Validation loss: 1.84251049353922
Epoch: 9| Step: 2
Training loss: 1.7049806118011475
Validation loss: 1.8345582416589312
Epoch: 9| Step: 3
Training loss: 1.90079927444458
Validation loss: 1.8482979355956153
Epoch: 9| Step: 4
Training loss: 2.0530803203582764
Validation loss: 1.8513731150318393
Epoch: 9| Step: 5
Training loss: 1.890000581741333
Validation loss: 1.8388873561680745
Epoch: 9| Step: 6
Training loss: 2.149458169937134
Validation loss: 1.8342986715783318
Epoch: 9| Step: 7
Training loss: 2.2078073024749756
Validation loss: 1.8542691743631157
Epoch: 9| Step: 8
Training loss: 2.213016986846924
Validation loss: 1.856217735962902
Epoch: 9| Step: 9
Training loss: 2.026179790496826
Validation loss: 1.8535551964807853
Epoch: 9| Step: 10
Training loss: 1.7332215309143066
Validation loss: 1.8360583224742533
Epoch: 9| Step: 11
Training loss: 2.1235904693603516
Validation loss: 1.8466546895692675
Epoch: 9| Step: 12
Training loss: 1.7039732933044434
Validation loss: 1.8644763874493058
Epoch: 9| Step: 13
Training loss: 2.4033799171447754
Validation loss: 1.8555271462570848
Epoch: 9| Step: 14
Training loss: 1.976749062538147
Validation loss: 1.8485837771738176
Epoch: 9| Step: 15
Training loss: 2.220578193664551
Validation loss: 1.8516779083142179
Epoch: 9| Step: 16
Training loss: 1.6328842639923096
Validation loss: 1.8536241886427076
Epoch: 9| Step: 17
Training loss: 1.8525210618972778
Validation loss: 1.846819924793655
Epoch: 9| Step: 18
Training loss: 1.7550160884857178
Validation loss: 1.8525389552974014
Epoch: 9| Step: 19
Training loss: 2.0595860481262207
Validation loss: 1.8378967629919807
Epoch: 74| Step: 0
Training loss: 1.9833860397338867
Validation loss: 1.8372980184692274
Epoch: 9| Step: 1
Training loss: 2.520031452178955
Validation loss: 1.8465530151943508
Epoch: 9| Step: 2
Training loss: 2.4036688804626465
Validation loss: 1.8382633418487988
Epoch: 9| Step: 3
Training loss: 1.656614899635315
Validation loss: 1.8370500056863688
Epoch: 9| Step: 4
Training loss: 1.6431653499603271
Validation loss: 1.8666214994389376
Epoch: 9| Step: 5
Training loss: 1.9598805904388428
Validation loss: 1.8430247787091372
Epoch: 9| Step: 6
Training loss: 2.2430078983306885
Validation loss: 1.8469044287427723
Epoch: 9| Step: 7
Training loss: 3.0099291801452637
Validation loss: 1.8420967935658188
Epoch: 9| Step: 8
Training loss: 2.4347848892211914
Validation loss: 1.8421742367229874
Epoch: 9| Step: 9
Training loss: 1.5230804681777954
Validation loss: 1.85469567432678
Epoch: 9| Step: 10
Training loss: 2.205716609954834
Validation loss: 1.8364442792727793
Epoch: 9| Step: 11
Training loss: 2.251614809036255
Validation loss: 1.8193034413907168
Epoch: 9| Step: 12
Training loss: 1.6166921854019165
Validation loss: 1.8185689363548223
Epoch: 9| Step: 13
Training loss: 1.8467214107513428
Validation loss: 1.822337047659236
Epoch: 9| Step: 14
Training loss: 1.617656946182251
Validation loss: 1.8073411545307516
Epoch: 9| Step: 15
Training loss: 1.1424529552459717
Validation loss: 1.8133479073750887
Epoch: 9| Step: 16
Training loss: 2.4842090606689453
Validation loss: 1.8388906194151735
Epoch: 9| Step: 17
Training loss: 2.019075870513916
Validation loss: 1.8082551999057797
Epoch: 9| Step: 18
Training loss: 1.6852221488952637
Validation loss: 1.8167237086261776
Epoch: 9| Step: 19
Training loss: 1.60929274559021
Validation loss: 1.8213862815349222
Epoch: 75| Step: 0
Training loss: 1.8474504947662354
Validation loss: 1.8297070710779093
Epoch: 9| Step: 1
Training loss: 2.2071645259857178
Validation loss: 1.833655680683877
Epoch: 9| Step: 2
Training loss: 2.1184492111206055
Validation loss: 1.8346337277254612
Epoch: 9| Step: 3
Training loss: 1.3187129497528076
Validation loss: 1.8394787791821596
Epoch: 9| Step: 4
Training loss: 1.8050017356872559
Validation loss: 1.825239167796622
Epoch: 9| Step: 5
Training loss: 2.1022732257843018
Validation loss: 1.8458995295943117
Epoch: 9| Step: 6
Training loss: 2.2605977058410645
Validation loss: 1.8598340295201583
Epoch: 9| Step: 7
Training loss: 1.178654432296753
Validation loss: 1.8392470483299639
Epoch: 9| Step: 8
Training loss: 2.2532505989074707
Validation loss: 1.84343812105467
Epoch: 9| Step: 9
Training loss: 2.2368555068969727
Validation loss: 1.8497206461515359
Epoch: 9| Step: 10
Training loss: 1.8877997398376465
Validation loss: 1.8602018870895716
Epoch: 9| Step: 11
Training loss: 2.5163893699645996
Validation loss: 1.8404129769304673
Epoch: 9| Step: 12
Training loss: 1.5157796144485474
Validation loss: 1.8491609002188814
Epoch: 9| Step: 13
Training loss: 1.703053593635559
Validation loss: 1.8670953743749386
Epoch: 9| Step: 14
Training loss: 2.070058822631836
Validation loss: 1.8538536673827137
Epoch: 9| Step: 15
Training loss: 2.139895439147949
Validation loss: 1.866535567551208
Epoch: 9| Step: 16
Training loss: 2.437640905380249
Validation loss: 1.8730218616320933
Epoch: 9| Step: 17
Training loss: 1.265195369720459
Validation loss: 1.8734865814661807
Epoch: 9| Step: 18
Training loss: 2.44301438331604
Validation loss: 1.852995102354091
Epoch: 9| Step: 19
Training loss: 2.4297738075256348
Validation loss: 1.8486413269591846
Epoch: 76| Step: 0
Training loss: 1.2475661039352417
Validation loss: 1.8515340518608367
Epoch: 9| Step: 1
Training loss: 1.2531826496124268
Validation loss: 1.8399725783643106
Epoch: 9| Step: 2
Training loss: 2.76644229888916
Validation loss: 1.8625944312527882
Epoch: 9| Step: 3
Training loss: 0.9817492365837097
Validation loss: 1.8565779898664077
Epoch: 9| Step: 4
Training loss: 1.6493172645568848
Validation loss: 1.8411719799041748
Epoch: 9| Step: 5
Training loss: 1.861281156539917
Validation loss: 1.833355888188314
Epoch: 9| Step: 6
Training loss: 1.9533237218856812
Validation loss: 1.8392000412769456
Epoch: 9| Step: 7
Training loss: 2.2575297355651855
Validation loss: 1.830776462452017
Epoch: 9| Step: 8
Training loss: 2.3278331756591797
Validation loss: 1.8250907916816876
Epoch: 9| Step: 9
Training loss: 1.6549510955810547
Validation loss: 1.8159381176927964
Epoch: 9| Step: 10
Training loss: 2.102935314178467
Validation loss: 1.8163017583407943
Epoch: 9| Step: 11
Training loss: 2.293447971343994
Validation loss: 1.8120929354386364
Epoch: 9| Step: 12
Training loss: 2.24112606048584
Validation loss: 1.8186752221567168
Epoch: 9| Step: 13
Training loss: 2.0277230739593506
Validation loss: 1.8113262138778357
Epoch: 9| Step: 14
Training loss: 2.4519264698028564
Validation loss: 1.8361705670253836
Epoch: 9| Step: 15
Training loss: 2.231276035308838
Validation loss: 1.8244238525843448
Epoch: 9| Step: 16
Training loss: 1.9847922325134277
Validation loss: 1.8243172220188937
Epoch: 9| Step: 17
Training loss: 2.2236618995666504
Validation loss: 1.8313851519454298
Epoch: 9| Step: 18
Training loss: 2.1298561096191406
Validation loss: 1.8267284022818366
Epoch: 9| Step: 19
Training loss: 2.1844193935394287
Validation loss: 1.8195041726819046
Epoch: 77| Step: 0
Training loss: 1.1571590900421143
Validation loss: 1.834934399282332
Epoch: 9| Step: 1
Training loss: 1.6068406105041504
Validation loss: 1.8391041944352844
Epoch: 9| Step: 2
Training loss: 2.053659200668335
Validation loss: 1.8397293862679023
Epoch: 9| Step: 3
Training loss: 1.904444694519043
Validation loss: 1.8300545884550905
Epoch: 9| Step: 4
Training loss: 2.4723422527313232
Validation loss: 1.8357667922973633
Epoch: 9| Step: 5
Training loss: 2.098813533782959
Validation loss: 1.8364792864957302
Epoch: 9| Step: 6
Training loss: 2.680541753768921
Validation loss: 1.8401207263521153
Epoch: 9| Step: 7
Training loss: 2.176953077316284
Validation loss: 1.835560137419392
Epoch: 9| Step: 8
Training loss: 1.955561637878418
Validation loss: 1.832231138249953
Epoch: 9| Step: 9
Training loss: 1.708913803100586
Validation loss: 1.8393297692854627
Epoch: 9| Step: 10
Training loss: 2.0752851963043213
Validation loss: 1.82074264056391
Epoch: 9| Step: 11
Training loss: 1.9391562938690186
Validation loss: 1.8239956433824498
Epoch: 9| Step: 12
Training loss: 2.333220958709717
Validation loss: 1.825594785402147
Epoch: 9| Step: 13
Training loss: 2.0509815216064453
Validation loss: 1.8012101821762194
Epoch: 9| Step: 14
Training loss: 2.648766279220581
Validation loss: 1.813623810843598
Epoch: 9| Step: 15
Training loss: 1.270988941192627
Validation loss: 1.806086701454876
Epoch: 9| Step: 16
Training loss: 1.881348967552185
Validation loss: 1.8095555631376856
Epoch: 9| Step: 17
Training loss: 1.971700668334961
Validation loss: 1.7949739746052584
Epoch: 9| Step: 18
Training loss: 1.6664903163909912
Validation loss: 1.8117091887288814
Epoch: 9| Step: 19
Training loss: 1.8914834260940552
Validation loss: 1.8143934749013229
Epoch: 78| Step: 0
Training loss: 1.6104609966278076
Validation loss: 1.823053523790922
Epoch: 9| Step: 1
Training loss: 1.6415069103240967
Validation loss: 1.7972401740739672
Epoch: 9| Step: 2
Training loss: 2.1012110710144043
Validation loss: 1.8074263171326341
Epoch: 9| Step: 3
Training loss: 1.838798999786377
Validation loss: 1.8129153877711124
Epoch: 9| Step: 4
Training loss: 3.4400830268859863
Validation loss: 1.8311543336017526
Epoch: 9| Step: 5
Training loss: 1.6977159976959229
Validation loss: 1.8017526907886532
Epoch: 9| Step: 6
Training loss: 2.4188389778137207
Validation loss: 1.8046313447060345
Epoch: 9| Step: 7
Training loss: 2.0783047676086426
Validation loss: 1.825256481445093
Epoch: 9| Step: 8
Training loss: 1.8639378547668457
Validation loss: 1.8215211072414041
Epoch: 9| Step: 9
Training loss: 1.4984735250473022
Validation loss: 1.8221906792345663
Epoch: 9| Step: 10
Training loss: 1.38087797164917
Validation loss: 1.820410853667225
Epoch: 9| Step: 11
Training loss: 1.8294090032577515
Validation loss: 1.8196042861869868
Epoch: 9| Step: 12
Training loss: 2.528815746307373
Validation loss: 1.8444426943072312
Epoch: 9| Step: 13
Training loss: 1.8234373331069946
Validation loss: 1.814745686894698
Epoch: 9| Step: 14
Training loss: 2.1980557441711426
Validation loss: 1.8260499376187223
Epoch: 9| Step: 15
Training loss: 2.752265691757202
Validation loss: 1.8176104885211093
Epoch: 9| Step: 16
Training loss: 1.8710120916366577
Validation loss: 1.8188779611381696
Epoch: 9| Step: 17
Training loss: 1.5203895568847656
Validation loss: 1.8260337448806214
Epoch: 9| Step: 18
Training loss: 1.6663358211517334
Validation loss: 1.8146000886134963
Epoch: 9| Step: 19
Training loss: 1.717368721961975
Validation loss: 1.813332451333245
Epoch: 79| Step: 0
Training loss: 1.7632412910461426
Validation loss: 1.8243405012775669
Epoch: 9| Step: 1
Training loss: 2.022826671600342
Validation loss: 1.8372049520341613
Epoch: 9| Step: 2
Training loss: 1.7544479370117188
Validation loss: 1.8223542686846617
Epoch: 9| Step: 3
Training loss: 2.174968719482422
Validation loss: 1.8432416049696558
Epoch: 9| Step: 4
Training loss: 2.0670738220214844
Validation loss: 1.8302810740985458
Epoch: 9| Step: 5
Training loss: 2.564629554748535
Validation loss: 1.8411641875616938
Epoch: 9| Step: 6
Training loss: 1.936671495437622
Validation loss: 1.8623914872999672
Epoch: 9| Step: 7
Training loss: 1.7142858505249023
Validation loss: 1.8524246232972728
Epoch: 9| Step: 8
Training loss: 2.0454764366149902
Validation loss: 1.8455020841077077
Epoch: 9| Step: 9
Training loss: 1.8974239826202393
Validation loss: 1.853908937612026
Epoch: 9| Step: 10
Training loss: 1.7917200326919556
Validation loss: 1.860576305458014
Epoch: 9| Step: 11
Training loss: 2.136833429336548
Validation loss: 1.8461717358596033
Epoch: 9| Step: 12
Training loss: 2.2725086212158203
Validation loss: 1.8517031232230097
Epoch: 9| Step: 13
Training loss: 2.3075881004333496
Validation loss: 1.8461932063960342
Epoch: 9| Step: 14
Training loss: 1.7519943714141846
Validation loss: 1.8729588865376205
Epoch: 9| Step: 15
Training loss: 2.2954697608947754
Validation loss: 1.8477944753152862
Epoch: 9| Step: 16
Training loss: 1.3599375486373901
Validation loss: 1.863194554829769
Epoch: 9| Step: 17
Training loss: 1.7349462509155273
Validation loss: 1.8669098358360126
Epoch: 9| Step: 18
Training loss: 1.9551005363464355
Validation loss: 1.8533145094946992
Epoch: 9| Step: 19
Training loss: 2.015043020248413
Validation loss: 1.8525209349694012
Epoch: 80| Step: 0
Training loss: 1.7131474018096924
Validation loss: 1.8422822626374609
Epoch: 9| Step: 1
Training loss: 1.2728724479675293
Validation loss: 1.8449412841591046
Epoch: 9| Step: 2
Training loss: 2.0158746242523193
Validation loss: 1.8453224408540794
Epoch: 9| Step: 3
Training loss: 2.5478382110595703
Validation loss: 1.8410329364186568
Epoch: 9| Step: 4
Training loss: 2.624311923980713
Validation loss: 1.8521835598156606
Epoch: 9| Step: 5
Training loss: 1.6488239765167236
Validation loss: 1.8457398183054203
Epoch: 9| Step: 6
Training loss: 1.2512662410736084
Validation loss: 1.8379935703689245
Epoch: 9| Step: 7
Training loss: 2.9019670486450195
Validation loss: 1.8317338819984053
Epoch: 9| Step: 8
Training loss: 1.1327077150344849
Validation loss: 1.8490396017650905
Epoch: 9| Step: 9
Training loss: 1.5406759977340698
Validation loss: 1.8431637570154753
Epoch: 9| Step: 10
Training loss: 3.049450635910034
Validation loss: 1.848998128939018
Epoch: 9| Step: 11
Training loss: 2.0051393508911133
Validation loss: 1.8430813062105247
Epoch: 9| Step: 12
Training loss: 1.8121269941329956
Validation loss: 1.8535114432410371
Epoch: 9| Step: 13
Training loss: 2.1794285774230957
Validation loss: 1.8363225194190045
Epoch: 9| Step: 14
Training loss: 2.5622992515563965
Validation loss: 1.847492777186332
Epoch: 9| Step: 15
Training loss: 1.6309317350387573
Validation loss: 1.8505156434697212
Epoch: 9| Step: 16
Training loss: 1.9943296909332275
Validation loss: 1.8686247883940772
Epoch: 9| Step: 17
Training loss: 2.083202838897705
Validation loss: 1.8588037293591946
Epoch: 9| Step: 18
Training loss: 2.0193498134613037
Validation loss: 1.856315307479968
Epoch: 9| Step: 19
Training loss: 1.6891934871673584
Validation loss: 1.8416709342448832
Epoch: 81| Step: 0
Training loss: 1.8026854991912842
Validation loss: 1.835621305506864
Epoch: 9| Step: 1
Training loss: 2.117297649383545
Validation loss: 1.844021152249343
Epoch: 9| Step: 2
Training loss: 1.2732518911361694
Validation loss: 1.8439860952843865
Epoch: 9| Step: 3
Training loss: 2.3330626487731934
Validation loss: 1.8481387920516859
Epoch: 9| Step: 4
Training loss: 1.8930315971374512
Validation loss: 1.8498622290522075
Epoch: 9| Step: 5
Training loss: 1.5806694030761719
Validation loss: 1.8605192556655665
Epoch: 9| Step: 6
Training loss: 2.507230758666992
Validation loss: 1.8389887183690243
Epoch: 9| Step: 7
Training loss: 1.8461010456085205
Validation loss: 1.852593454525625
Epoch: 9| Step: 8
Training loss: 1.6311386823654175
Validation loss: 1.843657621376806
Epoch: 9| Step: 9
Training loss: 2.338977575302124
Validation loss: 1.856159332844851
Epoch: 9| Step: 10
Training loss: 1.6707690954208374
Validation loss: 1.8479255069074014
Epoch: 9| Step: 11
Training loss: 2.3029720783233643
Validation loss: 1.8433884407976548
Epoch: 9| Step: 12
Training loss: 1.8091386556625366
Validation loss: 1.846534458853358
Epoch: 9| Step: 13
Training loss: 2.108139753341675
Validation loss: 1.8507581443237744
Epoch: 9| Step: 14
Training loss: 1.6486797332763672
Validation loss: 1.866646065128793
Epoch: 9| Step: 15
Training loss: 2.337146520614624
Validation loss: 1.853914450398452
Epoch: 9| Step: 16
Training loss: 1.9829506874084473
Validation loss: 1.8618254781626968
Epoch: 9| Step: 17
Training loss: 2.480020761489868
Validation loss: 1.854316853790832
Epoch: 9| Step: 18
Training loss: 2.114983081817627
Validation loss: 1.869184589214462
Epoch: 9| Step: 19
Training loss: 1.710089921951294
Validation loss: 1.8509926855992929
Epoch: 82| Step: 0
Training loss: 2.7089827060699463
Validation loss: 1.8714337108804167
Epoch: 9| Step: 1
Training loss: 2.0374302864074707
Validation loss: 1.8538235520287383
Epoch: 9| Step: 2
Training loss: 2.702096462249756
Validation loss: 1.8404885847791492
Epoch: 9| Step: 3
Training loss: 1.7674765586853027
Validation loss: 1.8378903788628338
Epoch: 9| Step: 4
Training loss: 1.3932334184646606
Validation loss: 1.8390555613332515
Epoch: 9| Step: 5
Training loss: 1.6492083072662354
Validation loss: 1.8397290260671713
Epoch: 9| Step: 6
Training loss: 2.4911136627197266
Validation loss: 1.8518595927053219
Epoch: 9| Step: 7
Training loss: 1.8280693292617798
Validation loss: 1.8232927656859803
Epoch: 9| Step: 8
Training loss: 1.6404107809066772
Validation loss: 1.8219742895030289
Epoch: 9| Step: 9
Training loss: 1.654268503189087
Validation loss: 1.833197257501616
Epoch: 9| Step: 10
Training loss: 1.8613801002502441
Validation loss: 1.8195106460036135
Epoch: 9| Step: 11
Training loss: 1.9873807430267334
Validation loss: 1.8086584592037063
Epoch: 9| Step: 12
Training loss: 2.0800139904022217
Validation loss: 1.8138066032807605
Epoch: 9| Step: 13
Training loss: 1.6848807334899902
Validation loss: 1.8197785375787199
Epoch: 9| Step: 14
Training loss: 2.7523794174194336
Validation loss: 1.8289261576083067
Epoch: 9| Step: 15
Training loss: 2.218846321105957
Validation loss: 1.8009329579716964
Epoch: 9| Step: 16
Training loss: 2.1041157245635986
Validation loss: 1.818997297355597
Epoch: 9| Step: 17
Training loss: 1.663296103477478
Validation loss: 1.8204847222609486
Epoch: 9| Step: 18
Training loss: 1.3809555768966675
Validation loss: 1.8220266078015883
Epoch: 9| Step: 19
Training loss: 1.826134443283081
Validation loss: 1.8059628815959683
Epoch: 83| Step: 0
Training loss: 1.3556052446365356
Validation loss: 1.8410186201548404
Epoch: 9| Step: 1
Training loss: 1.6972099542617798
Validation loss: 1.8269743610629074
Epoch: 9| Step: 2
Training loss: 1.602219581604004
Validation loss: 1.845779316030818
Epoch: 9| Step: 3
Training loss: 2.4820477962493896
Validation loss: 1.8281365984635387
Epoch: 9| Step: 4
Training loss: 2.4326632022857666
Validation loss: 1.843636685138126
Epoch: 9| Step: 5
Training loss: 2.3529629707336426
Validation loss: 1.842581062865772
Epoch: 9| Step: 6
Training loss: 2.075701951980591
Validation loss: 1.8451685605289267
Epoch: 9| Step: 7
Training loss: 1.9903234243392944
Validation loss: 1.8502107867234046
Epoch: 9| Step: 8
Training loss: 1.7391269207000732
Validation loss: 1.8447122256532849
Epoch: 9| Step: 9
Training loss: 1.9417765140533447
Validation loss: 1.8513180523467578
Epoch: 9| Step: 10
Training loss: 1.940121054649353
Validation loss: 1.8550229449923947
Epoch: 9| Step: 11
Training loss: 2.415720224380493
Validation loss: 1.835310426547373
Epoch: 9| Step: 12
Training loss: 2.589106559753418
Validation loss: 1.8444047325806652
Epoch: 9| Step: 13
Training loss: 2.938721179962158
Validation loss: 1.858730333314525
Epoch: 9| Step: 14
Training loss: 1.7421565055847168
Validation loss: 1.865408586941177
Epoch: 9| Step: 15
Training loss: 1.4116863012313843
Validation loss: 1.853074044632397
Epoch: 9| Step: 16
Training loss: 1.060950756072998
Validation loss: 1.8707167407591565
Epoch: 9| Step: 17
Training loss: 1.3320444822311401
Validation loss: 1.8473119169688053
Epoch: 9| Step: 18
Training loss: 2.400404214859009
Validation loss: 1.8614469577940247
Epoch: 9| Step: 19
Training loss: 2.024448871612549
Validation loss: 1.86425857406726
Epoch: 84| Step: 0
Training loss: 1.7812036275863647
Validation loss: 1.839931861959773
Epoch: 9| Step: 1
Training loss: 2.021031379699707
Validation loss: 1.8624258015653212
Epoch: 9| Step: 2
Training loss: 2.246671199798584
Validation loss: 1.852016093919603
Epoch: 9| Step: 3
Training loss: 2.0200960636138916
Validation loss: 1.8499790601593127
Epoch: 9| Step: 4
Training loss: 1.7055524587631226
Validation loss: 1.8605317023160646
Epoch: 9| Step: 5
Training loss: 2.215823173522949
Validation loss: 1.8483024672638597
Epoch: 9| Step: 6
Training loss: 1.7001729011535645
Validation loss: 1.836426210918015
Epoch: 9| Step: 7
Training loss: 1.9790008068084717
Validation loss: 1.8417296495369013
Epoch: 9| Step: 8
Training loss: 2.0165295600891113
Validation loss: 1.8252807795572623
Epoch: 9| Step: 9
Training loss: 1.6252275705337524
Validation loss: 1.835743332080704
Epoch: 9| Step: 10
Training loss: 1.8965824842453003
Validation loss: 1.8257281385737358
Epoch: 9| Step: 11
Training loss: 1.8669393062591553
Validation loss: 1.8306148721159792
Epoch: 9| Step: 12
Training loss: 2.2561254501342773
Validation loss: 1.8400816025493814
Epoch: 9| Step: 13
Training loss: 1.754695177078247
Validation loss: 1.8216322583260296
Epoch: 9| Step: 14
Training loss: 1.9104162454605103
Validation loss: 1.83524918127403
Epoch: 9| Step: 15
Training loss: 1.756011962890625
Validation loss: 1.8388115870866844
Epoch: 9| Step: 16
Training loss: 2.016634225845337
Validation loss: 1.8266007634375592
Epoch: 9| Step: 17
Training loss: 1.8194869756698608
Validation loss: 1.8457129378970578
Epoch: 9| Step: 18
Training loss: 2.2368855476379395
Validation loss: 1.8386049502187496
Epoch: 9| Step: 19
Training loss: 2.54276704788208
Validation loss: 1.8413754512937806
Epoch: 85| Step: 0
Training loss: 2.0083181858062744
Validation loss: 1.8377553927812644
Epoch: 9| Step: 1
Training loss: 2.1966772079467773
Validation loss: 1.8283619820642814
Epoch: 9| Step: 2
Training loss: 1.9153920412063599
Validation loss: 1.8460870483796374
Epoch: 9| Step: 3
Training loss: 1.9695796966552734
Validation loss: 1.8330471695755883
Epoch: 9| Step: 4
Training loss: 1.5255476236343384
Validation loss: 1.838663364485871
Epoch: 9| Step: 5
Training loss: 1.9848061800003052
Validation loss: 1.8372360202048321
Epoch: 9| Step: 6
Training loss: 2.288778305053711
Validation loss: 1.8448264152883627
Epoch: 9| Step: 7
Training loss: 2.0129218101501465
Validation loss: 1.8631147609340202
Epoch: 9| Step: 8
Training loss: 2.380520820617676
Validation loss: 1.8584990072593415
Epoch: 9| Step: 9
Training loss: 1.4199671745300293
Validation loss: 1.8483415670532117
Epoch: 9| Step: 10
Training loss: 1.9782700538635254
Validation loss: 1.8684672040047405
Epoch: 9| Step: 11
Training loss: 2.3228304386138916
Validation loss: 1.8695450052082967
Epoch: 9| Step: 12
Training loss: 2.6943016052246094
Validation loss: 1.8664924223645984
Epoch: 9| Step: 13
Training loss: 1.9834024906158447
Validation loss: 1.8807780176615543
Epoch: 9| Step: 14
Training loss: 1.5923655033111572
Validation loss: 1.8955427253846642
Epoch: 9| Step: 15
Training loss: 1.7887696027755737
Validation loss: 1.8768912039214758
Epoch: 9| Step: 16
Training loss: 1.9095053672790527
Validation loss: 1.875942819410091
Epoch: 9| Step: 17
Training loss: 1.7061043977737427
Validation loss: 1.8747707468142611
Epoch: 9| Step: 18
Training loss: 1.4060227870941162
Validation loss: 1.8880635817273914
Epoch: 9| Step: 19
Training loss: 2.305419921875
Validation loss: 1.8852321981526108
Epoch: 86| Step: 0
Training loss: 2.024871349334717
Validation loss: 1.8999796788469494
Epoch: 9| Step: 1
Training loss: 2.17423677444458
Validation loss: 1.8968968923143346
Epoch: 9| Step: 2
Training loss: 2.1504387855529785
Validation loss: 1.8932170893648546
Epoch: 9| Step: 3
Training loss: 1.5659910440444946
Validation loss: 1.8980250238514633
Epoch: 9| Step: 4
Training loss: 1.8454991579055786
Validation loss: 1.8921311647771932
Epoch: 9| Step: 5
Training loss: 2.170297145843506
Validation loss: 1.8734886243188982
Epoch: 9| Step: 6
Training loss: 2.036170482635498
Validation loss: 1.8968239242224385
Epoch: 9| Step: 7
Training loss: 2.3881137371063232
Validation loss: 1.8883425314649402
Epoch: 9| Step: 8
Training loss: 1.8795435428619385
Validation loss: 1.8865727606437188
Epoch: 9| Step: 9
Training loss: 1.7698352336883545
Validation loss: 1.8882888135292548
Epoch: 9| Step: 10
Training loss: 2.3795981407165527
Validation loss: 1.8841804386042862
Epoch: 9| Step: 11
Training loss: 1.7522395849227905
Validation loss: 1.8857224948114628
Epoch: 9| Step: 12
Training loss: 1.7693473100662231
Validation loss: 1.8706627646796137
Epoch: 9| Step: 13
Training loss: 1.9992263317108154
Validation loss: 1.8654560228045896
Epoch: 9| Step: 14
Training loss: 2.0143024921417236
Validation loss: 1.8708149512037098
Epoch: 9| Step: 15
Training loss: 2.2680602073669434
Validation loss: 1.8582043158922263
Epoch: 9| Step: 16
Training loss: 1.5745056867599487
Validation loss: 1.857997041812046
Epoch: 9| Step: 17
Training loss: 1.5227317810058594
Validation loss: 1.856455934133461
Epoch: 9| Step: 18
Training loss: 2.390364646911621
Validation loss: 1.8416224658060416
Epoch: 9| Step: 19
Training loss: 1.8548195362091064
Validation loss: 1.8532478569222868
Epoch: 87| Step: 0
Training loss: 1.8884656429290771
Validation loss: 1.843642469790342
Epoch: 9| Step: 1
Training loss: 1.884678602218628
Validation loss: 1.8408755038281996
Epoch: 9| Step: 2
Training loss: 1.8384640216827393
Validation loss: 1.8232488040443804
Epoch: 9| Step: 3
Training loss: 2.034111261367798
Validation loss: 1.8551205996986773
Epoch: 9| Step: 4
Training loss: 1.7032041549682617
Validation loss: 1.8316595545775598
Epoch: 9| Step: 5
Training loss: 2.290616512298584
Validation loss: 1.8435606107437352
Epoch: 9| Step: 6
Training loss: 1.8657433986663818
Validation loss: 1.8328484185308003
Epoch: 9| Step: 7
Training loss: 1.943650484085083
Validation loss: 1.8371484777052625
Epoch: 9| Step: 8
Training loss: 2.178739309310913
Validation loss: 1.8247276458808843
Epoch: 9| Step: 9
Training loss: 1.7056162357330322
Validation loss: 1.8284920342534565
Epoch: 9| Step: 10
Training loss: 2.1967992782592773
Validation loss: 1.809786602747526
Epoch: 9| Step: 11
Training loss: 2.4808573722839355
Validation loss: 1.8340199302426345
Epoch: 9| Step: 12
Training loss: 2.349618434906006
Validation loss: 1.8307038742861301
Epoch: 9| Step: 13
Training loss: 1.5111525058746338
Validation loss: 1.843994812142077
Epoch: 9| Step: 14
Training loss: 1.9035923480987549
Validation loss: 1.8251555394783294
Epoch: 9| Step: 15
Training loss: 1.7822169065475464
Validation loss: 1.8332605602072298
Epoch: 9| Step: 16
Training loss: 1.555816411972046
Validation loss: 1.8148023413239622
Epoch: 9| Step: 17
Training loss: 2.2342050075531006
Validation loss: 1.832724066947004
Epoch: 9| Step: 18
Training loss: 2.454174757003784
Validation loss: 1.8315021905967657
Epoch: 9| Step: 19
Training loss: 1.548011302947998
Validation loss: 1.8558166575946395
Epoch: 88| Step: 0
Training loss: 2.0213897228240967
Validation loss: 1.835003926599626
Epoch: 9| Step: 1
Training loss: 2.2311506271362305
Validation loss: 1.8544202296853922
Epoch: 9| Step: 2
Training loss: 1.788519263267517
Validation loss: 1.8553037574822955
Epoch: 9| Step: 3
Training loss: 2.3812384605407715
Validation loss: 1.8581107820538307
Epoch: 9| Step: 4
Training loss: 1.516498327255249
Validation loss: 1.8450227058191093
Epoch: 9| Step: 5
Training loss: 2.2789759635925293
Validation loss: 1.8334450584521396
Epoch: 9| Step: 6
Training loss: 1.6778947114944458
Validation loss: 1.8544483390643443
Epoch: 9| Step: 7
Training loss: 1.7873104810714722
Validation loss: 1.8474702637830227
Epoch: 9| Step: 8
Training loss: 1.6190600395202637
Validation loss: 1.8357090058086587
Epoch: 9| Step: 9
Training loss: 1.5519357919692993
Validation loss: 1.8324341139347433
Epoch: 9| Step: 10
Training loss: 2.3979997634887695
Validation loss: 1.8394457633546788
Epoch: 9| Step: 11
Training loss: 2.042724609375
Validation loss: 1.830805649002679
Epoch: 9| Step: 12
Training loss: 2.3582496643066406
Validation loss: 1.8341145026598045
Epoch: 9| Step: 13
Training loss: 1.8528801202774048
Validation loss: 1.8251205048115133
Epoch: 9| Step: 14
Training loss: 2.0079283714294434
Validation loss: 1.8396556325953641
Epoch: 9| Step: 15
Training loss: 2.80082368850708
Validation loss: 1.8331058428441878
Epoch: 9| Step: 16
Training loss: 1.6233117580413818
Validation loss: 1.8433683964845946
Epoch: 9| Step: 17
Training loss: 1.9181147813796997
Validation loss: 1.8203470964225934
Epoch: 9| Step: 18
Training loss: 1.3447842597961426
Validation loss: 1.8329701200663615
Epoch: 9| Step: 19
Training loss: 2.224677324295044
Validation loss: 1.8390368308952387
Epoch: 89| Step: 0
Training loss: 2.3211913108825684
Validation loss: 1.8283289336472106
Epoch: 9| Step: 1
Training loss: 1.8551596403121948
Validation loss: 1.8361426686211455
Epoch: 9| Step: 2
Training loss: 1.4738713502883911
Validation loss: 1.8309503545006403
Epoch: 9| Step: 3
Training loss: 2.143078327178955
Validation loss: 1.838174763343317
Epoch: 9| Step: 4
Training loss: 2.1821799278259277
Validation loss: 1.8256000657733396
Epoch: 9| Step: 5
Training loss: 1.6817798614501953
Validation loss: 1.8240330082049472
Epoch: 9| Step: 6
Training loss: 1.7290914058685303
Validation loss: 1.8225389264470382
Epoch: 9| Step: 7
Training loss: 1.581813097000122
Validation loss: 1.8273670913504183
Epoch: 9| Step: 8
Training loss: 2.2383100986480713
Validation loss: 1.8404009144940823
Epoch: 9| Step: 9
Training loss: 2.3150529861450195
Validation loss: 1.8573393753106646
Epoch: 9| Step: 10
Training loss: 1.1035149097442627
Validation loss: 1.8430666760574999
Epoch: 9| Step: 11
Training loss: 1.6482043266296387
Validation loss: 1.8518603654216519
Epoch: 9| Step: 12
Training loss: 1.6953260898590088
Validation loss: 1.857387123348044
Epoch: 9| Step: 13
Training loss: 2.13116455078125
Validation loss: 1.849758934631622
Epoch: 9| Step: 14
Training loss: 2.4313268661499023
Validation loss: 1.8518345115853727
Epoch: 9| Step: 15
Training loss: 2.374011516571045
Validation loss: 1.8632349101759547
Epoch: 9| Step: 16
Training loss: 1.4875520467758179
Validation loss: 1.8696103859290802
Epoch: 9| Step: 17
Training loss: 2.240043878555298
Validation loss: 1.844730015281293
Epoch: 9| Step: 18
Training loss: 2.689922571182251
Validation loss: 1.848720499079862
Epoch: 9| Step: 19
Training loss: 2.3343310356140137
Validation loss: 1.8545299982853074
Epoch: 90| Step: 0
Training loss: 1.3248846530914307
Validation loss: 1.8518713498287063
Epoch: 9| Step: 1
Training loss: 1.8056060075759888
Validation loss: 1.8416408600567056
Epoch: 9| Step: 2
Training loss: 2.4859189987182617
Validation loss: 1.8475730299092026
Epoch: 9| Step: 3
Training loss: 1.9307975769042969
Validation loss: 1.8469343940131098
Epoch: 9| Step: 4
Training loss: 2.0164237022399902
Validation loss: 1.8442311467026635
Epoch: 9| Step: 5
Training loss: 1.738694429397583
Validation loss: 1.8317118608694283
Epoch: 9| Step: 6
Training loss: 1.5571956634521484
Validation loss: 1.853994806893438
Epoch: 9| Step: 7
Training loss: 2.2280187606811523
Validation loss: 1.8389189320502521
Epoch: 9| Step: 8
Training loss: 2.052699089050293
Validation loss: 1.8449192784673019
Epoch: 9| Step: 9
Training loss: 1.5579378604888916
Validation loss: 1.853456273353357
Epoch: 9| Step: 10
Training loss: 1.6974468231201172
Validation loss: 1.8442598632771334
Epoch: 9| Step: 11
Training loss: 1.65673828125
Validation loss: 1.8392470174556157
Epoch: 9| Step: 12
Training loss: 1.8957452774047852
Validation loss: 1.8486294257555076
Epoch: 9| Step: 13
Training loss: 2.6830835342407227
Validation loss: 1.8488169428255918
Epoch: 9| Step: 14
Training loss: 2.9391896724700928
Validation loss: 1.8272379851169724
Epoch: 9| Step: 15
Training loss: 1.8188955783843994
Validation loss: 1.8444870821863628
Epoch: 9| Step: 16
Training loss: 2.2149524688720703
Validation loss: 1.8524422251063286
Epoch: 9| Step: 17
Training loss: 1.4203319549560547
Validation loss: 1.8509652914760781
Epoch: 9| Step: 18
Training loss: 2.262270927429199
Validation loss: 1.8378614084326106
Epoch: 9| Step: 19
Training loss: 2.010023593902588
Validation loss: 1.8572266402004434
Epoch: 91| Step: 0
Training loss: 2.456923484802246
Validation loss: 1.8289413546486724
Epoch: 9| Step: 1
Training loss: 2.3998160362243652
Validation loss: 1.837325853409527
Epoch: 9| Step: 2
Training loss: 1.5722137689590454
Validation loss: 1.8285990721887821
Epoch: 9| Step: 3
Training loss: 2.1127281188964844
Validation loss: 1.8409245563067977
Epoch: 9| Step: 4
Training loss: 1.7778284549713135
Validation loss: 1.8200626656305876
Epoch: 9| Step: 5
Training loss: 1.4830713272094727
Validation loss: 1.8183291438672182
Epoch: 9| Step: 6
Training loss: 1.5756314992904663
Validation loss: 1.8174711525869027
Epoch: 9| Step: 7
Training loss: 2.595919370651245
Validation loss: 1.813622730241405
Epoch: 9| Step: 8
Training loss: 1.6036040782928467
Validation loss: 1.8242949153021943
Epoch: 9| Step: 9
Training loss: 2.641683340072632
Validation loss: 1.8198888636321473
Epoch: 9| Step: 10
Training loss: 1.9958935976028442
Validation loss: 1.824994136961244
Epoch: 9| Step: 11
Training loss: 1.4709616899490356
Validation loss: 1.8279777893917166
Epoch: 9| Step: 12
Training loss: 2.2237050533294678
Validation loss: 1.8271508834344878
Epoch: 9| Step: 13
Training loss: 1.711108684539795
Validation loss: 1.8179731892167235
Epoch: 9| Step: 14
Training loss: 2.05533766746521
Validation loss: 1.817620310851996
Epoch: 9| Step: 15
Training loss: 2.0627477169036865
Validation loss: 1.8226146998165322
Epoch: 9| Step: 16
Training loss: 1.8784189224243164
Validation loss: 1.8286958778504845
Epoch: 9| Step: 17
Training loss: 1.9650212526321411
Validation loss: 1.8418555688514984
Epoch: 9| Step: 18
Training loss: 2.2875101566314697
Validation loss: 1.831456107201336
Epoch: 9| Step: 19
Training loss: 1.6978988647460938
Validation loss: 1.82462869445197
Epoch: 92| Step: 0
Training loss: 2.26408052444458
Validation loss: 1.8437229858027946
Epoch: 9| Step: 1
Training loss: 1.7360472679138184
Validation loss: 1.8230074232430766
Epoch: 9| Step: 2
Training loss: 2.7455148696899414
Validation loss: 1.8298579385812335
Epoch: 9| Step: 3
Training loss: 1.8202214241027832
Validation loss: 1.842647027626312
Epoch: 9| Step: 4
Training loss: 2.346072196960449
Validation loss: 1.8435449257171412
Epoch: 9| Step: 5
Training loss: 2.428811550140381
Validation loss: 1.815358050435567
Epoch: 9| Step: 6
Training loss: 1.9797673225402832
Validation loss: 1.8154520027929073
Epoch: 9| Step: 7
Training loss: 2.4643518924713135
Validation loss: 1.8275591486649547
Epoch: 9| Step: 8
Training loss: 1.6550601720809937
Validation loss: 1.821915027048948
Epoch: 9| Step: 9
Training loss: 2.640745162963867
Validation loss: 1.8192284364494489
Epoch: 9| Step: 10
Training loss: 1.332337498664856
Validation loss: 1.8257978905876764
Epoch: 9| Step: 11
Training loss: 1.812347173690796
Validation loss: 1.8189966318418653
Epoch: 9| Step: 12
Training loss: 1.9767118692398071
Validation loss: 1.8137572532077488
Epoch: 9| Step: 13
Training loss: 2.0552878379821777
Validation loss: 1.8189253172428488
Epoch: 9| Step: 14
Training loss: 2.141218423843384
Validation loss: 1.7978943629230526
Epoch: 9| Step: 15
Training loss: 1.4911307096481323
Validation loss: 1.796729386281624
Epoch: 9| Step: 16
Training loss: 1.4924843311309814
Validation loss: 1.7947364093588412
Epoch: 9| Step: 17
Training loss: 1.806337594985962
Validation loss: 1.7893557385574999
Epoch: 9| Step: 18
Training loss: 1.3916587829589844
Validation loss: 1.8018227841356675
Epoch: 9| Step: 19
Training loss: 2.0210299491882324
Validation loss: 1.7943347014969202
Epoch: 93| Step: 0
Training loss: 1.6909018754959106
Validation loss: 1.8072915377376748
Epoch: 9| Step: 1
Training loss: 2.2161190509796143
Validation loss: 1.7927212372100612
Epoch: 9| Step: 2
Training loss: 1.935430645942688
Validation loss: 1.7976714278296602
Epoch: 9| Step: 3
Training loss: 1.3516252040863037
Validation loss: 1.7873647221558386
Epoch: 9| Step: 4
Training loss: 1.740013599395752
Validation loss: 1.8031841413580256
Epoch: 9| Step: 5
Training loss: 2.3928442001342773
Validation loss: 1.8151131319485123
Epoch: 9| Step: 6
Training loss: 1.8990503549575806
Validation loss: 1.802441290814242
Epoch: 9| Step: 7
Training loss: 1.9117927551269531
Validation loss: 1.8058880627584115
Epoch: 9| Step: 8
Training loss: 2.378512382507324
Validation loss: 1.8181213251978374
Epoch: 9| Step: 9
Training loss: 2.008403778076172
Validation loss: 1.8387425743418633
Epoch: 9| Step: 10
Training loss: 1.1818804740905762
Validation loss: 1.810703689245869
Epoch: 9| Step: 11
Training loss: 2.910810947418213
Validation loss: 1.8161794693349935
Epoch: 9| Step: 12
Training loss: 2.183171510696411
Validation loss: 1.815794365011531
Epoch: 9| Step: 13
Training loss: 1.9840147495269775
Validation loss: 1.835709567550275
Epoch: 9| Step: 14
Training loss: 1.4862747192382812
Validation loss: 1.8394728161448197
Epoch: 9| Step: 15
Training loss: 1.3924310207366943
Validation loss: 1.8151917955000623
Epoch: 9| Step: 16
Training loss: 2.1687116622924805
Validation loss: 1.8428566610212807
Epoch: 9| Step: 17
Training loss: 2.362891912460327
Validation loss: 1.8294301478982828
Epoch: 9| Step: 18
Training loss: 2.1708905696868896
Validation loss: 1.8377333099035909
Epoch: 9| Step: 19
Training loss: 1.8859164714813232
Validation loss: 1.8490469129823095
Epoch: 94| Step: 0
Training loss: 1.8120906352996826
Validation loss: 1.8338686545118152
Epoch: 9| Step: 1
Training loss: 1.1300742626190186
Validation loss: 1.8595586792170573
Epoch: 9| Step: 2
Training loss: 1.9929604530334473
Validation loss: 1.8567226096022902
Epoch: 9| Step: 3
Training loss: 1.6265674829483032
Validation loss: 1.8367328669527452
Epoch: 9| Step: 4
Training loss: 1.6950502395629883
Validation loss: 1.8594455864789674
Epoch: 9| Step: 5
Training loss: 2.371535301208496
Validation loss: 1.8547697084413157
Epoch: 9| Step: 6
Training loss: 2.1574172973632812
Validation loss: 1.858423425996904
Epoch: 9| Step: 7
Training loss: 1.8745023012161255
Validation loss: 1.8497998534346656
Epoch: 9| Step: 8
Training loss: 1.9908462762832642
Validation loss: 1.8678302464725303
Epoch: 9| Step: 9
Training loss: 1.987350344657898
Validation loss: 1.8544714553750676
Epoch: 9| Step: 10
Training loss: 2.5132813453674316
Validation loss: 1.8741988869879742
Epoch: 9| Step: 11
Training loss: 1.9158728122711182
Validation loss: 1.8798805998383665
Epoch: 9| Step: 12
Training loss: 1.8004400730133057
Validation loss: 1.8727951847392021
Epoch: 9| Step: 13
Training loss: 1.4593451023101807
Validation loss: 1.8787805287958048
Epoch: 9| Step: 14
Training loss: 1.60052490234375
Validation loss: 1.8644538405987856
Epoch: 9| Step: 15
Training loss: 2.3550634384155273
Validation loss: 1.8740972169011616
Epoch: 9| Step: 16
Training loss: 2.3774518966674805
Validation loss: 1.8592018832405695
Epoch: 9| Step: 17
Training loss: 2.4835903644561768
Validation loss: 1.8472293589612563
Epoch: 9| Step: 18
Training loss: 2.494098663330078
Validation loss: 1.852844873778254
Epoch: 9| Step: 19
Training loss: 1.7502765655517578
Validation loss: 1.8433859468364029
Epoch: 95| Step: 0
Training loss: 2.8297791481018066
Validation loss: 1.8446065187454224
Epoch: 9| Step: 1
Training loss: 1.7374147176742554
Validation loss: 1.837289178971764
Epoch: 9| Step: 2
Training loss: 1.9366194009780884
Validation loss: 1.8216836435331716
Epoch: 9| Step: 3
Training loss: 2.222318649291992
Validation loss: 1.8175943326607025
Epoch: 9| Step: 4
Training loss: 1.9224374294281006
Validation loss: 1.827067701079005
Epoch: 9| Step: 5
Training loss: 2.1324257850646973
Validation loss: 1.8434231161213608
Epoch: 9| Step: 6
Training loss: 2.0898427963256836
Validation loss: 1.8420545617453485
Epoch: 9| Step: 7
Training loss: 2.9570767879486084
Validation loss: 1.8197844483011918
Epoch: 9| Step: 8
Training loss: 2.0129992961883545
Validation loss: 1.8275508606176583
Epoch: 9| Step: 9
Training loss: 1.838701844215393
Validation loss: 1.8141852831668992
Epoch: 9| Step: 10
Training loss: 1.3551698923110962
Validation loss: 1.8194816824343565
Epoch: 9| Step: 11
Training loss: 1.778049111366272
Validation loss: 1.8423323854268026
Epoch: 9| Step: 12
Training loss: 1.2424814701080322
Validation loss: 1.8124515598626445
Epoch: 9| Step: 13
Training loss: 1.3217484951019287
Validation loss: 1.8141748321999749
Epoch: 9| Step: 14
Training loss: 1.5510772466659546
Validation loss: 1.814445190292468
Epoch: 9| Step: 15
Training loss: 2.05891752243042
Validation loss: 1.8255579523045382
Epoch: 9| Step: 16
Training loss: 2.4185574054718018
Validation loss: 1.8080171839796382
Epoch: 9| Step: 17
Training loss: 1.9952322244644165
Validation loss: 1.8109978806200644
Epoch: 9| Step: 18
Training loss: 2.157461643218994
Validation loss: 1.8173521285434422
Epoch: 9| Step: 19
Training loss: 1.7611181735992432
Validation loss: 1.8093286512566984
Epoch: 96| Step: 0
Training loss: 1.7212084531784058
Validation loss: 1.8234884944751109
Epoch: 9| Step: 1
Training loss: 2.0626816749572754
Validation loss: 1.8214801524182875
Epoch: 9| Step: 2
Training loss: 1.472890019416809
Validation loss: 1.8207980660225849
Epoch: 9| Step: 3
Training loss: 1.7820461988449097
Validation loss: 1.8394410901790044
Epoch: 9| Step: 4
Training loss: 1.9917895793914795
Validation loss: 1.837758102862955
Epoch: 9| Step: 5
Training loss: 1.7349159717559814
Validation loss: 1.8438826533530255
Epoch: 9| Step: 6
Training loss: 2.524951696395874
Validation loss: 1.84866847151475
Epoch: 9| Step: 7
Training loss: 1.848050594329834
Validation loss: 1.8399362212462391
Epoch: 9| Step: 8
Training loss: 1.659458875656128
Validation loss: 1.8393290660364165
Epoch: 9| Step: 9
Training loss: 1.8249146938323975
Validation loss: 1.857716679573059
Epoch: 9| Step: 10
Training loss: 1.8079702854156494
Validation loss: 1.8506986940507408
Epoch: 9| Step: 11
Training loss: 3.064502239227295
Validation loss: 1.8510675618974426
Epoch: 9| Step: 12
Training loss: 2.060033082962036
Validation loss: 1.8315513905861396
Epoch: 9| Step: 13
Training loss: 2.2801613807678223
Validation loss: 1.8436210661483325
Epoch: 9| Step: 14
Training loss: 1.4661128520965576
Validation loss: 1.854602595885023
Epoch: 9| Step: 15
Training loss: 1.5474259853363037
Validation loss: 1.8576110052547867
Epoch: 9| Step: 16
Training loss: 2.8813624382019043
Validation loss: 1.8351693470701038
Epoch: 9| Step: 17
Training loss: 1.852858304977417
Validation loss: 1.8407566170040652
Epoch: 9| Step: 18
Training loss: 1.755345106124878
Validation loss: 1.8272787461177908
Epoch: 9| Step: 19
Training loss: 1.8785854578018188
Validation loss: 1.8332889886211148
Epoch: 97| Step: 0
Training loss: 2.1605448722839355
Validation loss: 1.843196453808023
Epoch: 9| Step: 1
Training loss: 1.8092032670974731
Validation loss: 1.8378711621538342
Epoch: 9| Step: 2
Training loss: 2.1465516090393066
Validation loss: 1.8293496644754204
Epoch: 9| Step: 3
Training loss: 2.11024808883667
Validation loss: 1.8275703697753467
Epoch: 9| Step: 4
Training loss: 1.6688199043273926
Validation loss: 1.830961973547078
Epoch: 9| Step: 5
Training loss: 1.9861456155776978
Validation loss: 1.8412616227170546
Epoch: 9| Step: 6
Training loss: 2.154188394546509
Validation loss: 1.841436100520676
Epoch: 9| Step: 7
Training loss: 1.4218533039093018
Validation loss: 1.835389414279581
Epoch: 9| Step: 8
Training loss: 1.4507176876068115
Validation loss: 1.8469909403821547
Epoch: 9| Step: 9
Training loss: 1.416762113571167
Validation loss: 1.8524365090637755
Epoch: 9| Step: 10
Training loss: 1.4860273599624634
Validation loss: 1.85899964854014
Epoch: 9| Step: 11
Training loss: 2.1605706214904785
Validation loss: 1.849028649947626
Epoch: 9| Step: 12
Training loss: 2.433472156524658
Validation loss: 1.8672927566569486
Epoch: 9| Step: 13
Training loss: 1.6501808166503906
Validation loss: 1.855090823962534
Epoch: 9| Step: 14
Training loss: 2.336181640625
Validation loss: 1.855150620714366
Epoch: 9| Step: 15
Training loss: 2.351825475692749
Validation loss: 1.8642825960255356
Epoch: 9| Step: 16
Training loss: 1.9489166736602783
Validation loss: 1.8470271937281109
Epoch: 9| Step: 17
Training loss: 1.8869590759277344
Validation loss: 1.85392720150433
Epoch: 9| Step: 18
Training loss: 2.6736347675323486
Validation loss: 1.8605675663021828
Epoch: 9| Step: 19
Training loss: 2.046323299407959
Validation loss: 1.8479876672621254
Epoch: 98| Step: 0
Training loss: 1.6724045276641846
Validation loss: 1.84449760176295
Epoch: 9| Step: 1
Training loss: 1.5105037689208984
Validation loss: 1.833131347628806
Epoch: 9| Step: 2
Training loss: 1.8417664766311646
Validation loss: 1.8428659113191015
Epoch: 9| Step: 3
Training loss: 1.988853096961975
Validation loss: 1.840300445076373
Epoch: 9| Step: 4
Training loss: 1.7302806377410889
Validation loss: 1.840518391389641
Epoch: 9| Step: 5
Training loss: 1.738201379776001
Validation loss: 1.8218486532032918
Epoch: 9| Step: 6
Training loss: 1.6974260807037354
Validation loss: 1.8348120159382442
Epoch: 9| Step: 7
Training loss: 2.654573440551758
Validation loss: 1.8391818459943043
Epoch: 9| Step: 8
Training loss: 1.8311420679092407
Validation loss: 1.832373335207109
Epoch: 9| Step: 9
Training loss: 1.600710391998291
Validation loss: 1.8339442426352193
Epoch: 9| Step: 10
Training loss: 2.191678524017334
Validation loss: 1.809305515220697
Epoch: 9| Step: 11
Training loss: 2.3638124465942383
Validation loss: 1.8315111441577938
Epoch: 9| Step: 12
Training loss: 1.3164668083190918
Validation loss: 1.829800147804425
Epoch: 9| Step: 13
Training loss: 1.9837322235107422
Validation loss: 1.8323926179529093
Epoch: 9| Step: 14
Training loss: 2.097536087036133
Validation loss: 1.8307731117275978
Epoch: 9| Step: 15
Training loss: 2.409322738647461
Validation loss: 1.8432377774080784
Epoch: 9| Step: 16
Training loss: 2.13748836517334
Validation loss: 1.8315585156996472
Epoch: 9| Step: 17
Training loss: 2.738335609436035
Validation loss: 1.8297285510481691
Epoch: 9| Step: 18
Training loss: 2.154672622680664
Validation loss: 1.8273968310664883
Epoch: 9| Step: 19
Training loss: 1.642699956893921
Validation loss: 1.8265589681460703
Epoch: 99| Step: 0
Training loss: 2.207206964492798
Validation loss: 1.8189377038598917
Epoch: 9| Step: 1
Training loss: 2.232647180557251
Validation loss: 1.8220247124596465
Epoch: 9| Step: 2
Training loss: 2.480370044708252
Validation loss: 1.8240666904037806
Epoch: 9| Step: 3
Training loss: 2.4219865798950195
Validation loss: 1.8085563328626344
Epoch: 9| Step: 4
Training loss: 1.7651150226593018
Validation loss: 1.8162155846040027
Epoch: 9| Step: 5
Training loss: 1.5051711797714233
Validation loss: 1.810963923982579
Epoch: 9| Step: 6
Training loss: 2.235860824584961
Validation loss: 1.8149316328034983
Epoch: 9| Step: 7
Training loss: 1.519482135772705
Validation loss: 1.8040833524662814
Epoch: 9| Step: 8
Training loss: 1.5531651973724365
Validation loss: 1.818168926582062
Epoch: 9| Step: 9
Training loss: 1.7700886726379395
Validation loss: 1.7936784483545976
Epoch: 9| Step: 10
Training loss: 2.1462278366088867
Validation loss: 1.8258451291983075
Epoch: 9| Step: 11
Training loss: 1.9875640869140625
Validation loss: 1.8153823837101888
Epoch: 9| Step: 12
Training loss: 1.9255276918411255
Validation loss: 1.8170123726343936
Epoch: 9| Step: 13
Training loss: 1.507421612739563
Validation loss: 1.8286082744598389
Epoch: 9| Step: 14
Training loss: 2.5914487838745117
Validation loss: 1.8403827526586518
Epoch: 9| Step: 15
Training loss: 1.428025484085083
Validation loss: 1.8441394558913415
Epoch: 9| Step: 16
Training loss: 2.246023178100586
Validation loss: 1.8437348029596343
Epoch: 9| Step: 17
Training loss: 1.8026636838912964
Validation loss: 1.847494444401144
Epoch: 9| Step: 18
Training loss: 1.8603408336639404
Validation loss: 1.8373222119516606
Epoch: 9| Step: 19
Training loss: 2.2691774368286133
Validation loss: 1.8435922209307445
Epoch: 100| Step: 0
Training loss: 1.554538607597351
Validation loss: 1.8299306408106852
Epoch: 9| Step: 1
Training loss: 1.6542141437530518
Validation loss: 1.8471339932448572
Epoch: 9| Step: 2
Training loss: 1.843606948852539
Validation loss: 1.8283367963145962
Epoch: 9| Step: 3
Training loss: 1.7230920791625977
Validation loss: 1.8379938147908492
Epoch: 9| Step: 4
Training loss: 0.9387564063072205
Validation loss: 1.8360005985918662
Epoch: 9| Step: 5
Training loss: 1.6853201389312744
Validation loss: 1.8301882460820589
Epoch: 9| Step: 6
Training loss: 2.0265610218048096
Validation loss: 1.831980977984641
Epoch: 9| Step: 7
Training loss: 1.9383305311203003
Validation loss: 1.828709465136631
Epoch: 9| Step: 8
Training loss: 2.281710147857666
Validation loss: 1.8352568501191173
Epoch: 9| Step: 9
Training loss: 2.2441468238830566
Validation loss: 1.8092488539304665
Epoch: 9| Step: 10
Training loss: 1.8354967832565308
Validation loss: 1.8229985545865066
Epoch: 9| Step: 11
Training loss: 1.91385817527771
Validation loss: 1.8098640716333183
Epoch: 9| Step: 12
Training loss: 2.3025081157684326
Validation loss: 1.8116474674760008
Epoch: 9| Step: 13
Training loss: 2.138930320739746
Validation loss: 1.8120953444954302
Epoch: 9| Step: 14
Training loss: 2.0358619689941406
Validation loss: 1.8128208410825661
Epoch: 9| Step: 15
Training loss: 2.0302493572235107
Validation loss: 1.7987131120489657
Epoch: 9| Step: 16
Training loss: 2.400984525680542
Validation loss: 1.82895510659801
Epoch: 9| Step: 17
Training loss: 1.9797337055206299
Validation loss: 1.836089635066849
Epoch: 9| Step: 18
Training loss: 2.1873042583465576
Validation loss: 1.851287732021414
Epoch: 9| Step: 19
Training loss: 2.674929618835449
Validation loss: 1.8240128515435636
