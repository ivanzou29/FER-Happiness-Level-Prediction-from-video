Epoch: 1| Step: 0
Training loss: 6.374979954108342
Validation loss: 7.022254977253817

Epoch: 5| Step: 1
Training loss: 6.536142661285162
Validation loss: 7.008952909548257

Epoch: 5| Step: 2
Training loss: 6.639097940229601
Validation loss: 6.993904332062345

Epoch: 5| Step: 3
Training loss: 7.443498004071815
Validation loss: 6.981811621970229

Epoch: 5| Step: 4
Training loss: 6.843761705362422
Validation loss: 6.972096436553456

Epoch: 5| Step: 5
Training loss: 6.5986353417053385
Validation loss: 6.958280513661939

Epoch: 5| Step: 6
Training loss: 7.310888911732109
Validation loss: 6.949973397238335

Epoch: 5| Step: 7
Training loss: 7.359377591725924
Validation loss: 6.938264672920645

Epoch: 5| Step: 8
Training loss: 7.3771563464859575
Validation loss: 6.9267152349050045

Epoch: 5| Step: 9
Training loss: 7.962755050047725
Validation loss: 6.917346354107353

Epoch: 5| Step: 10
Training loss: 6.550887232669805
Validation loss: 6.9032878938828315

Epoch: 5| Step: 11
Training loss: 9.424400686945853
Validation loss: 6.888694163957775

Epoch: 2| Step: 0
Training loss: 6.854896143287213
Validation loss: 6.878039295125325

Epoch: 5| Step: 1
Training loss: 6.316338005003931
Validation loss: 6.863457104494943

Epoch: 5| Step: 2
Training loss: 7.544006181489873
Validation loss: 6.848619792582626

Epoch: 5| Step: 3
Training loss: 6.965968650394664
Validation loss: 6.8349214274632555

Epoch: 5| Step: 4
Training loss: 7.275173811786163
Validation loss: 6.819723341971363

Epoch: 5| Step: 5
Training loss: 6.623153429178245
Validation loss: 6.804109183086358

Epoch: 5| Step: 6
Training loss: 7.172389857608916
Validation loss: 6.7872194774305346

Epoch: 5| Step: 7
Training loss: 6.56281475947163
Validation loss: 6.769610117434349

Epoch: 5| Step: 8
Training loss: 6.505569419480487
Validation loss: 6.754552424540164

Epoch: 5| Step: 9
Training loss: 7.384362436510684
Validation loss: 6.738149695839902

Epoch: 5| Step: 10
Training loss: 6.984843057058496
Validation loss: 6.717131048513832

Epoch: 5| Step: 11
Training loss: 5.04515381743966
Validation loss: 6.700181375487284

Epoch: 3| Step: 0
Training loss: 6.416403860019493
Validation loss: 6.678696955653987

Epoch: 5| Step: 1
Training loss: 7.114487237313898
Validation loss: 6.664251887562179

Epoch: 5| Step: 2
Training loss: 6.7893473715765635
Validation loss: 6.642437245535901

Epoch: 5| Step: 3
Training loss: 7.252878078216982
Validation loss: 6.624739311895351

Epoch: 5| Step: 4
Training loss: 6.715470618190455
Validation loss: 6.601999795789849

Epoch: 5| Step: 5
Training loss: 7.264967103110471
Validation loss: 6.581823811719458

Epoch: 5| Step: 6
Training loss: 5.918850813493493
Validation loss: 6.557012073796811

Epoch: 5| Step: 7
Training loss: 5.95920714615552
Validation loss: 6.531788002257042

Epoch: 5| Step: 8
Training loss: 5.991414285083118
Validation loss: 6.504809324327325

Epoch: 5| Step: 9
Training loss: 6.441964684518383
Validation loss: 6.481988968837148

Epoch: 5| Step: 10
Training loss: 7.1829793230641
Validation loss: 6.450067369961861

Epoch: 5| Step: 11
Training loss: 7.462089857015908
Validation loss: 6.419844344223846

Epoch: 4| Step: 0
Training loss: 5.912366172776034
Validation loss: 6.39216334101313

Epoch: 5| Step: 1
Training loss: 6.631710756277873
Validation loss: 6.360293322842749

Epoch: 5| Step: 2
Training loss: 5.922603512040954
Validation loss: 6.319600156698493

Epoch: 5| Step: 3
Training loss: 7.097563000298968
Validation loss: 6.2789609923046426

Epoch: 5| Step: 4
Training loss: 5.983486976173924
Validation loss: 6.237881355629913

Epoch: 5| Step: 5
Training loss: 6.943237406629162
Validation loss: 6.19418215612128

Epoch: 5| Step: 6
Training loss: 7.147162518641303
Validation loss: 6.1540962621561155

Epoch: 5| Step: 7
Training loss: 5.736404600273337
Validation loss: 6.093631280247952

Epoch: 5| Step: 8
Training loss: 6.186982104272951
Validation loss: 6.049740660182104

Epoch: 5| Step: 9
Training loss: 5.894691096035125
Validation loss: 5.984828842124998

Epoch: 5| Step: 10
Training loss: 5.699936233966926
Validation loss: 5.936775993241537

Epoch: 5| Step: 11
Training loss: 3.6765052982262576
Validation loss: 5.877151122497255

Epoch: 5| Step: 0
Training loss: 5.463374520488509
Validation loss: 5.829491939926607

Epoch: 5| Step: 1
Training loss: 5.2450401855907565
Validation loss: 5.756352384846133

Epoch: 5| Step: 2
Training loss: 4.776896969730855
Validation loss: 5.687661053399879

Epoch: 5| Step: 3
Training loss: 6.06519218524001
Validation loss: 5.633689138454593

Epoch: 5| Step: 4
Training loss: 6.025893604918109
Validation loss: 5.56791925224083

Epoch: 5| Step: 5
Training loss: 5.3800530745146675
Validation loss: 5.484607238779258

Epoch: 5| Step: 6
Training loss: 5.176752193716296
Validation loss: 5.4226286160083195

Epoch: 5| Step: 7
Training loss: 5.782534894693642
Validation loss: 5.347304041623215

Epoch: 5| Step: 8
Training loss: 5.406557107482517
Validation loss: 5.256739959983934

Epoch: 5| Step: 9
Training loss: 5.604553700900661
Validation loss: 5.14844584331695

Epoch: 5| Step: 10
Training loss: 5.373598315202711
Validation loss: 5.075585380706148

Epoch: 5| Step: 11
Training loss: 6.680476413116146
Validation loss: 4.9681245022257325

Epoch: 6| Step: 0
Training loss: 5.167618304975983
Validation loss: 4.868771682514688

Epoch: 5| Step: 1
Training loss: 4.840146403975201
Validation loss: 4.7757057132797245

Epoch: 5| Step: 2
Training loss: 4.778178905434972
Validation loss: 4.649432625560244

Epoch: 5| Step: 3
Training loss: 4.40779725092076
Validation loss: 4.567631931456161

Epoch: 5| Step: 4
Training loss: 4.05429469210607
Validation loss: 4.437181353881456

Epoch: 5| Step: 5
Training loss: 4.346432961888116
Validation loss: 4.336673067035883

Epoch: 5| Step: 6
Training loss: 4.862395791944997
Validation loss: 4.212509380899883

Epoch: 5| Step: 7
Training loss: 4.363209559057415
Validation loss: 4.0691935489388165

Epoch: 5| Step: 8
Training loss: 3.291018522810297
Validation loss: 3.94482810694717

Epoch: 5| Step: 9
Training loss: 3.6431877055704964
Validation loss: 3.8195252286671475

Epoch: 5| Step: 10
Training loss: 3.915740059077736
Validation loss: 3.721197925417257

Epoch: 5| Step: 11
Training loss: 2.985382549111349
Validation loss: 3.607580815152665

Epoch: 7| Step: 0
Training loss: 2.8466354654584007
Validation loss: 3.456408359424683

Epoch: 5| Step: 1
Training loss: 3.0750017925970545
Validation loss: 3.3374020103709294

Epoch: 5| Step: 2
Training loss: 3.9337052724384622
Validation loss: 3.2601780341979407

Epoch: 5| Step: 3
Training loss: 2.3179611468214536
Validation loss: 3.141021463095952

Epoch: 5| Step: 4
Training loss: 3.3215057024225603
Validation loss: 3.07704052483171

Epoch: 5| Step: 5
Training loss: 2.6899911734283735
Validation loss: 2.955699286400869

Epoch: 5| Step: 6
Training loss: 2.820413434449486
Validation loss: 2.927804859102683

Epoch: 5| Step: 7
Training loss: 3.266604627941387
Validation loss: 2.828135467566127

Epoch: 5| Step: 8
Training loss: 3.1648227108058546
Validation loss: 2.7881166259359387

Epoch: 5| Step: 9
Training loss: 2.633878950339731
Validation loss: 2.8155462968829705

Epoch: 5| Step: 10
Training loss: 3.113419858749846
Validation loss: 2.8093179716065304

Epoch: 5| Step: 11
Training loss: 1.2064632326128835
Validation loss: 2.8333530331843053

Epoch: 8| Step: 0
Training loss: 2.28123453213399
Validation loss: 2.862022470153003

Epoch: 5| Step: 1
Training loss: 2.9452344646285367
Validation loss: 2.9013731040624626

Epoch: 5| Step: 2
Training loss: 2.622342717460825
Validation loss: 2.861735153324799

Epoch: 5| Step: 3
Training loss: 2.3816637615865077
Validation loss: 2.9087947724419347

Epoch: 5| Step: 4
Training loss: 3.3200301465423765
Validation loss: 2.965424924237488

Epoch: 5| Step: 5
Training loss: 2.84356605018679
Validation loss: 2.9803818889608116

Epoch: 5| Step: 6
Training loss: 3.190295171923216
Validation loss: 2.979218026809977

Epoch: 5| Step: 7
Training loss: 2.9110800691297167
Validation loss: 2.978427633017627

Epoch: 5| Step: 8
Training loss: 3.325904069334828
Validation loss: 2.9390495318935015

Epoch: 5| Step: 9
Training loss: 3.054545601673453
Validation loss: 2.9222897627911713

Epoch: 5| Step: 10
Training loss: 2.6703545778551896
Validation loss: 2.831839512440098

Epoch: 5| Step: 11
Training loss: 2.4595692539689913
Validation loss: 2.855182377640325

Epoch: 9| Step: 0
Training loss: 1.8594686660896083
Validation loss: 2.8343715635459

Epoch: 5| Step: 1
Training loss: 2.8246712012231674
Validation loss: 2.8107841414523795

Epoch: 5| Step: 2
Training loss: 2.737951500991836
Validation loss: 2.7979427338325813

Epoch: 5| Step: 3
Training loss: 2.147520223218133
Validation loss: 2.7569928558694277

Epoch: 5| Step: 4
Training loss: 3.3595782551156765
Validation loss: 2.848981596847668

Epoch: 5| Step: 5
Training loss: 2.6308670780151244
Validation loss: 2.8236408161142164

Epoch: 5| Step: 6
Training loss: 3.06134945802507
Validation loss: 2.767233569355671

Epoch: 5| Step: 7
Training loss: 2.423027305886841
Validation loss: 2.7949040605824576

Epoch: 5| Step: 8
Training loss: 3.1265364875073574
Validation loss: 2.764845531700547

Epoch: 5| Step: 9
Training loss: 3.3284622522969705
Validation loss: 2.7614641517358183

Epoch: 5| Step: 10
Training loss: 3.0255156085485333
Validation loss: 2.785973523945231

Epoch: 5| Step: 11
Training loss: 1.8787012444398885
Validation loss: 2.7760751064975135

Epoch: 10| Step: 0
Training loss: 2.484576235124564
Validation loss: 2.7656130673713233

Epoch: 5| Step: 1
Training loss: 2.7536495440805444
Validation loss: 2.790338753162237

Epoch: 5| Step: 2
Training loss: 2.711128426020558
Validation loss: 2.73331854620477

Epoch: 5| Step: 3
Training loss: 2.8451511159227594
Validation loss: 2.8068879508970683

Epoch: 5| Step: 4
Training loss: 3.1757737425918338
Validation loss: 2.830918535895483

Epoch: 5| Step: 5
Training loss: 1.9146420593996019
Validation loss: 2.8300241272563955

Epoch: 5| Step: 6
Training loss: 2.829862956311041
Validation loss: 2.8028933100102673

Epoch: 5| Step: 7
Training loss: 2.863930996686928
Validation loss: 2.776773815453706

Epoch: 5| Step: 8
Training loss: 2.767888667546771
Validation loss: 2.758489459038096

Epoch: 5| Step: 9
Training loss: 2.62027833537586
Validation loss: 2.7453205979151263

Epoch: 5| Step: 10
Training loss: 2.722073507680015
Validation loss: 2.7298660813835744

Epoch: 5| Step: 11
Training loss: 3.93261282243053
Validation loss: 2.7732388170024227

Epoch: 11| Step: 0
Training loss: 2.4139168210810205
Validation loss: 2.782462548669082

Epoch: 5| Step: 1
Training loss: 3.0312520449916587
Validation loss: 2.7789571469114214

Epoch: 5| Step: 2
Training loss: 2.5758855167443944
Validation loss: 2.728346942993115

Epoch: 5| Step: 3
Training loss: 2.1019597582100085
Validation loss: 2.7662492683295907

Epoch: 5| Step: 4
Training loss: 2.808564038709762
Validation loss: 2.774580137175826

Epoch: 5| Step: 5
Training loss: 2.4550192741678516
Validation loss: 2.737058844648188

Epoch: 5| Step: 6
Training loss: 3.0244627798687693
Validation loss: 2.7724699777399997

Epoch: 5| Step: 7
Training loss: 3.1018885674104006
Validation loss: 2.789791250611764

Epoch: 5| Step: 8
Training loss: 2.8975713623316834
Validation loss: 2.7396559409514727

Epoch: 5| Step: 9
Training loss: 2.9528404785019275
Validation loss: 2.777356955652904

Epoch: 5| Step: 10
Training loss: 2.8510122944149634
Validation loss: 2.7952945299958727

Epoch: 5| Step: 11
Training loss: 2.234366463598204
Validation loss: 2.775445825259154

Epoch: 12| Step: 0
Training loss: 2.8289749807179843
Validation loss: 2.7619637754269113

Epoch: 5| Step: 1
Training loss: 2.3880942918190335
Validation loss: 2.7877287574097616

Epoch: 5| Step: 2
Training loss: 2.479382759314806
Validation loss: 2.7139912206659584

Epoch: 5| Step: 3
Training loss: 3.3587467049631154
Validation loss: 2.748202289017594

Epoch: 5| Step: 4
Training loss: 2.502737358642819
Validation loss: 2.764870582027111

Epoch: 5| Step: 5
Training loss: 2.3360155787862964
Validation loss: 2.768876996080712

Epoch: 5| Step: 6
Training loss: 2.517890904827304
Validation loss: 2.7340424762352584

Epoch: 5| Step: 7
Training loss: 3.123206424991456
Validation loss: 2.7542849846172395

Epoch: 5| Step: 8
Training loss: 2.645387947462172
Validation loss: 2.743374621000261

Epoch: 5| Step: 9
Training loss: 3.1038252026115614
Validation loss: 2.751733576669472

Epoch: 5| Step: 10
Training loss: 2.5274361028999217
Validation loss: 2.758412725385539

Epoch: 5| Step: 11
Training loss: 3.3193452750218033
Validation loss: 2.7017130499260045

Epoch: 13| Step: 0
Training loss: 2.5853552955231036
Validation loss: 2.7507077917380673

Epoch: 5| Step: 1
Training loss: 2.4504425544411292
Validation loss: 2.736712479355046

Epoch: 5| Step: 2
Training loss: 3.0643673867168615
Validation loss: 2.7192169753048416

Epoch: 5| Step: 3
Training loss: 2.9081570510852495
Validation loss: 2.7749747121936004

Epoch: 5| Step: 4
Training loss: 2.865448052487413
Validation loss: 2.722661409231777

Epoch: 5| Step: 5
Training loss: 2.355873794271181
Validation loss: 2.7444048011115627

Epoch: 5| Step: 6
Training loss: 2.2422932988636126
Validation loss: 2.763126429997704

Epoch: 5| Step: 7
Training loss: 2.514941578787538
Validation loss: 2.7357200184641903

Epoch: 5| Step: 8
Training loss: 3.6589272633193626
Validation loss: 2.762161388473042

Epoch: 5| Step: 9
Training loss: 2.6295673961717583
Validation loss: 2.7099698489847377

Epoch: 5| Step: 10
Training loss: 2.6469846808577873
Validation loss: 2.7392380730138166

Epoch: 5| Step: 11
Training loss: 2.3101772293206384
Validation loss: 2.710449464312678

Epoch: 14| Step: 0
Training loss: 2.946879084109958
Validation loss: 2.74245797514267

Epoch: 5| Step: 1
Training loss: 2.6862358846244754
Validation loss: 2.7339797397310255

Epoch: 5| Step: 2
Training loss: 2.5264505166908284
Validation loss: 2.74781810655083

Epoch: 5| Step: 3
Training loss: 2.731891485167549
Validation loss: 2.7620708307695017

Epoch: 5| Step: 4
Training loss: 2.6776736507862093
Validation loss: 2.7003605070622987

Epoch: 5| Step: 5
Training loss: 2.260990216550788
Validation loss: 2.716865511259644

Epoch: 5| Step: 6
Training loss: 2.8291947675684885
Validation loss: 2.7480021429951216

Epoch: 5| Step: 7
Training loss: 2.602450932196837
Validation loss: 2.7771167653430706

Epoch: 5| Step: 8
Training loss: 2.7096558105248776
Validation loss: 2.706957714702225

Epoch: 5| Step: 9
Training loss: 2.9195823446513214
Validation loss: 2.7219195835624346

Epoch: 5| Step: 10
Training loss: 2.9810443287406834
Validation loss: 2.7798756407634033

Epoch: 5| Step: 11
Training loss: 1.6869665644961027
Validation loss: 2.7049955169513664

Epoch: 15| Step: 0
Training loss: 2.070913896842055
Validation loss: 2.747313838416168

Epoch: 5| Step: 1
Training loss: 2.555763881134813
Validation loss: 2.7315201342775928

Epoch: 5| Step: 2
Training loss: 2.4700391276731484
Validation loss: 2.7450735947494964

Epoch: 5| Step: 3
Training loss: 2.457791306391559
Validation loss: 2.7569238349396183

Epoch: 5| Step: 4
Training loss: 1.7604154853892078
Validation loss: 2.734756508506746

Epoch: 5| Step: 5
Training loss: 2.9750152331050392
Validation loss: 2.799211588055534

Epoch: 5| Step: 6
Training loss: 3.4368562962643456
Validation loss: 2.7364257388478355

Epoch: 5| Step: 7
Training loss: 2.7996746521348506
Validation loss: 2.696441789755276

Epoch: 5| Step: 8
Training loss: 2.8506316037259416
Validation loss: 2.7087378322091555

Epoch: 5| Step: 9
Training loss: 2.8629328371325165
Validation loss: 2.766453279506471

Epoch: 5| Step: 10
Training loss: 2.9073548216585117
Validation loss: 2.731518490424462

Epoch: 5| Step: 11
Training loss: 1.3241326858324816
Validation loss: 2.75799804509997

Epoch: 16| Step: 0
Training loss: 2.3471425235417365
Validation loss: 2.7199854765766083

Epoch: 5| Step: 1
Training loss: 2.9528437081846746
Validation loss: 2.7152909237629315

Epoch: 5| Step: 2
Training loss: 3.4702479246985383
Validation loss: 2.7191043929711265

Epoch: 5| Step: 3
Training loss: 2.788838438976808
Validation loss: 2.7247005871234133

Epoch: 5| Step: 4
Training loss: 2.4553731348086663
Validation loss: 2.7021822709553933

Epoch: 5| Step: 5
Training loss: 2.730492762294943
Validation loss: 2.777819700454556

Epoch: 5| Step: 6
Training loss: 1.987895935735132
Validation loss: 2.7839805186579354

Epoch: 5| Step: 7
Training loss: 2.1002793489577636
Validation loss: 2.7315135552222833

Epoch: 5| Step: 8
Training loss: 2.6714978760602515
Validation loss: 2.740878014392175

Epoch: 5| Step: 9
Training loss: 3.331389925596334
Validation loss: 2.7386413569616503

Epoch: 5| Step: 10
Training loss: 2.543896671350001
Validation loss: 2.6892840429940237

Epoch: 5| Step: 11
Training loss: 2.059661993425291
Validation loss: 2.7041296552781033

Epoch: 17| Step: 0
Training loss: 2.8920073631899896
Validation loss: 2.720000984049133

Epoch: 5| Step: 1
Training loss: 2.2728937816312764
Validation loss: 2.688978524072539

Epoch: 5| Step: 2
Training loss: 2.5456971797548826
Validation loss: 2.6913293754623973

Epoch: 5| Step: 3
Training loss: 2.884812568380743
Validation loss: 2.6911210350536496

Epoch: 5| Step: 4
Training loss: 2.8661239272887604
Validation loss: 2.6733672416130783

Epoch: 5| Step: 5
Training loss: 3.5445110492832734
Validation loss: 2.704490952280155

Epoch: 5| Step: 6
Training loss: 1.5983735878137824
Validation loss: 2.666355570637432

Epoch: 5| Step: 7
Training loss: 2.255651793073718
Validation loss: 2.7443904776539614

Epoch: 5| Step: 8
Training loss: 3.118083624275666
Validation loss: 2.739027428642762

Epoch: 5| Step: 9
Training loss: 2.9217108206088254
Validation loss: 2.6987901559892733

Epoch: 5| Step: 10
Training loss: 2.078844562519865
Validation loss: 2.657231015079333

Epoch: 5| Step: 11
Training loss: 1.9160794588707168
Validation loss: 2.714865840392038

Epoch: 18| Step: 0
Training loss: 2.8499840116888944
Validation loss: 2.6798794105844967

Epoch: 5| Step: 1
Training loss: 2.1373333648511883
Validation loss: 2.7546717957214706

Epoch: 5| Step: 2
Training loss: 2.566094366483621
Validation loss: 2.6325212349598233

Epoch: 5| Step: 3
Training loss: 3.2339825230812127
Validation loss: 2.693846269673681

Epoch: 5| Step: 4
Training loss: 2.00945740051752
Validation loss: 2.6716892743021736

Epoch: 5| Step: 5
Training loss: 3.014189857968129
Validation loss: 2.646346745777493

Epoch: 5| Step: 6
Training loss: 2.5812535579185814
Validation loss: 2.7052596342333985

Epoch: 5| Step: 7
Training loss: 3.0266821353645903
Validation loss: 2.75931918921935

Epoch: 5| Step: 8
Training loss: 2.5931912475273475
Validation loss: 2.741103476988906

Epoch: 5| Step: 9
Training loss: 2.4994793349722597
Validation loss: 2.738132249639266

Epoch: 5| Step: 10
Training loss: 2.2764963238588205
Validation loss: 2.712394403491228

Epoch: 5| Step: 11
Training loss: 3.046019135603532
Validation loss: 2.756182566255404

Epoch: 19| Step: 0
Training loss: 2.7967807178482955
Validation loss: 2.688608960966435

Epoch: 5| Step: 1
Training loss: 2.4059761188745674
Validation loss: 2.640865104338124

Epoch: 5| Step: 2
Training loss: 3.3991452937955624
Validation loss: 2.6833152867138805

Epoch: 5| Step: 3
Training loss: 2.5977794187787326
Validation loss: 2.7075695183430395

Epoch: 5| Step: 4
Training loss: 2.4042222036980356
Validation loss: 2.6916668437705753

Epoch: 5| Step: 5
Training loss: 3.3415945360829014
Validation loss: 2.6675987452517558

Epoch: 5| Step: 6
Training loss: 3.0141178772675703
Validation loss: 2.7545923194590576

Epoch: 5| Step: 7
Training loss: 2.154715724702116
Validation loss: 2.6607261416974812

Epoch: 5| Step: 8
Training loss: 2.62230489523282
Validation loss: 2.694206010672991

Epoch: 5| Step: 9
Training loss: 2.2782482098200134
Validation loss: 2.7235437968832836

Epoch: 5| Step: 10
Training loss: 2.280075502483983
Validation loss: 2.6727348899627095

Epoch: 5| Step: 11
Training loss: 2.463219157125048
Validation loss: 2.717610409016514

Epoch: 20| Step: 0
Training loss: 2.043002826705523
Validation loss: 2.691902055919548

Epoch: 5| Step: 1
Training loss: 2.7691130113832503
Validation loss: 2.7219897512079005

Epoch: 5| Step: 2
Training loss: 2.5065731420553816
Validation loss: 2.702674820886094

Epoch: 5| Step: 3
Training loss: 2.011642899055474
Validation loss: 2.673654131247359

Epoch: 5| Step: 4
Training loss: 3.4646064823284877
Validation loss: 2.663277474017724

Epoch: 5| Step: 5
Training loss: 2.9350150128424133
Validation loss: 2.7341455236146657

Epoch: 5| Step: 6
Training loss: 2.5610158390447597
Validation loss: 2.6639261406598873

Epoch: 5| Step: 7
Training loss: 2.710971095511843
Validation loss: 2.7575605275545416

Epoch: 5| Step: 8
Training loss: 2.4539231866630384
Validation loss: 2.7353821961225244

Epoch: 5| Step: 9
Training loss: 2.4155889826725963
Validation loss: 2.6791576606832472

Epoch: 5| Step: 10
Training loss: 2.6510071118294296
Validation loss: 2.704073109401879

Epoch: 5| Step: 11
Training loss: 2.6257232396290227
Validation loss: 2.6705208036613164

Epoch: 21| Step: 0
Training loss: 2.9036088653172665
Validation loss: 2.631797564715716

Epoch: 5| Step: 1
Training loss: 2.4141826908350956
Validation loss: 2.687126170632388

Epoch: 5| Step: 2
Training loss: 1.8732038796089199
Validation loss: 2.6181705697213657

Epoch: 5| Step: 3
Training loss: 2.4683465748735904
Validation loss: 2.7043894895396554

Epoch: 5| Step: 4
Training loss: 2.5939755628930334
Validation loss: 2.6531608158265683

Epoch: 5| Step: 5
Training loss: 2.8259526967208783
Validation loss: 2.726030416226133

Epoch: 5| Step: 6
Training loss: 2.6105790700929314
Validation loss: 2.710696195916849

Epoch: 5| Step: 7
Training loss: 1.8532620770091646
Validation loss: 2.77173302439884

Epoch: 5| Step: 8
Training loss: 2.6154806919920297
Validation loss: 2.7362607502453846

Epoch: 5| Step: 9
Training loss: 3.339219633982924
Validation loss: 2.739922529091809

Epoch: 5| Step: 10
Training loss: 3.0405313820457565
Validation loss: 2.6855366691626625

Epoch: 5| Step: 11
Training loss: 3.1905991690521316
Validation loss: 2.678830012373902

Epoch: 22| Step: 0
Training loss: 2.491330660190361
Validation loss: 2.7006549869324186

Epoch: 5| Step: 1
Training loss: 2.7484357893495512
Validation loss: 2.708847482491253

Epoch: 5| Step: 2
Training loss: 2.7351277214508514
Validation loss: 2.685353416179391

Epoch: 5| Step: 3
Training loss: 2.8876624519921834
Validation loss: 2.638146958846049

Epoch: 5| Step: 4
Training loss: 2.72237207579818
Validation loss: 2.689468985819906

Epoch: 5| Step: 5
Training loss: 2.684931303740273
Validation loss: 2.6783680350420096

Epoch: 5| Step: 6
Training loss: 2.7761449359248576
Validation loss: 2.7318789542844546

Epoch: 5| Step: 7
Training loss: 2.7568359375
Validation loss: 2.678820003449854

Epoch: 5| Step: 8
Training loss: 2.362750134017726
Validation loss: 2.696762848367942

Epoch: 5| Step: 9
Training loss: 2.7154262878269373
Validation loss: 2.70031142396173

Epoch: 5| Step: 10
Training loss: 2.690898254909302
Validation loss: 2.678009197175156

Epoch: 5| Step: 11
Training loss: 1.3503346240388165
Validation loss: 2.6706400763171443

Epoch: 23| Step: 0
Training loss: 2.53153349619281
Validation loss: 2.666206720045314

Epoch: 5| Step: 1
Training loss: 3.164413168984184
Validation loss: 2.688869777809444

Epoch: 5| Step: 2
Training loss: 2.8450830709601544
Validation loss: 2.6247010779859425

Epoch: 5| Step: 3
Training loss: 2.5208104870814436
Validation loss: 2.671076147663574

Epoch: 5| Step: 4
Training loss: 2.3910448291617277
Validation loss: 2.6598548587720297

Epoch: 5| Step: 5
Training loss: 2.8354717113823944
Validation loss: 2.7065227961317517

Epoch: 5| Step: 6
Training loss: 2.3390233507364835
Validation loss: 2.6730118836896173

Epoch: 5| Step: 7
Training loss: 2.277671410886399
Validation loss: 2.672625226291712

Epoch: 5| Step: 8
Training loss: 2.475427120614517
Validation loss: 2.703599946885528

Epoch: 5| Step: 9
Training loss: 2.4851642050881106
Validation loss: 2.725791756633475

Epoch: 5| Step: 10
Training loss: 2.781947102140453
Validation loss: 2.7116517656823858

Epoch: 5| Step: 11
Training loss: 3.628934895019479
Validation loss: 2.6547972577303156

Epoch: 24| Step: 0
Training loss: 2.757039423752362
Validation loss: 2.659934050942325

Epoch: 5| Step: 1
Training loss: 2.2356126465321475
Validation loss: 2.66262745171614

Epoch: 5| Step: 2
Training loss: 2.8496440129727407
Validation loss: 2.6578048306757607

Epoch: 5| Step: 3
Training loss: 2.21667878092656
Validation loss: 2.67200994243766

Epoch: 5| Step: 4
Training loss: 3.1460247023692425
Validation loss: 2.644395630372153

Epoch: 5| Step: 5
Training loss: 1.8653265326137152
Validation loss: 2.6701648846206765

Epoch: 5| Step: 6
Training loss: 2.8809095268410045
Validation loss: 2.669120234761364

Epoch: 5| Step: 7
Training loss: 2.720740806170774
Validation loss: 2.660525223083766

Epoch: 5| Step: 8
Training loss: 2.4461760047477394
Validation loss: 2.6469695600172414

Epoch: 5| Step: 9
Training loss: 2.968769274197301
Validation loss: 2.6729034764436905

Epoch: 5| Step: 10
Training loss: 2.9073520334761005
Validation loss: 2.64815133348267

Epoch: 5| Step: 11
Training loss: 2.2683152636112633
Validation loss: 2.6821424066192354

Epoch: 25| Step: 0
Training loss: 2.202090405970403
Validation loss: 2.6532367950088567

Epoch: 5| Step: 1
Training loss: 2.6279965508785286
Validation loss: 2.683461118897519

Epoch: 5| Step: 2
Training loss: 2.8734289105916004
Validation loss: 2.6776175108268356

Epoch: 5| Step: 3
Training loss: 2.587824475864486
Validation loss: 2.6823470687082756

Epoch: 5| Step: 4
Training loss: 2.408752230300227
Validation loss: 2.696831062551297

Epoch: 5| Step: 5
Training loss: 2.6377289369848684
Validation loss: 2.660523540965969

Epoch: 5| Step: 6
Training loss: 3.01034383894706
Validation loss: 2.6802815148723123

Epoch: 5| Step: 7
Training loss: 3.0626335893416106
Validation loss: 2.682727161102533

Epoch: 5| Step: 8
Training loss: 2.223222013581546
Validation loss: 2.695571949583675

Epoch: 5| Step: 9
Training loss: 2.623235654535226
Validation loss: 2.6232770798426763

Epoch: 5| Step: 10
Training loss: 2.1942730271981663
Validation loss: 2.685399524692211

Epoch: 5| Step: 11
Training loss: 3.5627996753668922
Validation loss: 2.6805021940090823

Epoch: 26| Step: 0
Training loss: 2.4474076627900185
Validation loss: 2.6678833992050794

Epoch: 5| Step: 1
Training loss: 2.245718060462217
Validation loss: 2.6238290638799153

Epoch: 5| Step: 2
Training loss: 2.9901996114692184
Validation loss: 2.611706310915463

Epoch: 5| Step: 3
Training loss: 2.471016724477786
Validation loss: 2.645366497356174

Epoch: 5| Step: 4
Training loss: 1.865455430597781
Validation loss: 2.6081490063562307

Epoch: 5| Step: 5
Training loss: 2.207571102047058
Validation loss: 2.6647638197659593

Epoch: 5| Step: 6
Training loss: 2.936700915145199
Validation loss: 2.620476272399646

Epoch: 5| Step: 7
Training loss: 3.066156812107878
Validation loss: 2.6591557447850143

Epoch: 5| Step: 8
Training loss: 2.8449597143663015
Validation loss: 2.651034590606139

Epoch: 5| Step: 9
Training loss: 3.007997343650619
Validation loss: 2.645634198141626

Epoch: 5| Step: 10
Training loss: 2.2868436403253787
Validation loss: 2.602542950196073

Epoch: 5| Step: 11
Training loss: 3.0143958240148043
Validation loss: 2.6761792520386036

Epoch: 27| Step: 0
Training loss: 2.9350980312735784
Validation loss: 2.678167870563076

Epoch: 5| Step: 1
Training loss: 2.745883721992497
Validation loss: 2.602737485992635

Epoch: 5| Step: 2
Training loss: 2.0609565508397947
Validation loss: 2.61706742727686

Epoch: 5| Step: 3
Training loss: 3.027975614502449
Validation loss: 2.638121300177867

Epoch: 5| Step: 4
Training loss: 2.560293876201212
Validation loss: 2.616123476615784

Epoch: 5| Step: 5
Training loss: 2.4080347155416306
Validation loss: 2.6410352249068954

Epoch: 5| Step: 6
Training loss: 2.5148277203990244
Validation loss: 2.697229516342188

Epoch: 5| Step: 7
Training loss: 2.3350105615413748
Validation loss: 2.6951239220444085

Epoch: 5| Step: 8
Training loss: 2.4742388007481093
Validation loss: 2.6349522548339546

Epoch: 5| Step: 9
Training loss: 2.103349571084743
Validation loss: 2.64076911939283

Epoch: 5| Step: 10
Training loss: 2.792489817710898
Validation loss: 2.6500703659851945

Epoch: 5| Step: 11
Training loss: 4.254920803458176
Validation loss: 2.681436755531416

Epoch: 28| Step: 0
Training loss: 3.111402760943704
Validation loss: 2.63753638506074

Epoch: 5| Step: 1
Training loss: 2.489591867174236
Validation loss: 2.677805819162336

Epoch: 5| Step: 2
Training loss: 2.3328737305809057
Validation loss: 2.5769416636509463

Epoch: 5| Step: 3
Training loss: 2.440700874663366
Validation loss: 2.709294219611241

Epoch: 5| Step: 4
Training loss: 2.569200362105079
Validation loss: 2.664206824397259

Epoch: 5| Step: 5
Training loss: 2.6582810658864204
Validation loss: 2.6618990163144387

Epoch: 5| Step: 6
Training loss: 2.51739079834252
Validation loss: 2.607180523506971

Epoch: 5| Step: 7
Training loss: 2.656593031331418
Validation loss: 2.7121343361805987

Epoch: 5| Step: 8
Training loss: 2.8695384685239658
Validation loss: 2.678106596062601

Epoch: 5| Step: 9
Training loss: 2.0776241530723123
Validation loss: 2.669583659875845

Epoch: 5| Step: 10
Training loss: 2.7843512914057085
Validation loss: 2.616705835913826

Epoch: 5| Step: 11
Training loss: 2.413761255918599
Validation loss: 2.6475198932172885

Epoch: 29| Step: 0
Training loss: 3.096570665358548
Validation loss: 2.6570429572027234

Epoch: 5| Step: 1
Training loss: 2.8389207685969495
Validation loss: 2.5957400986923087

Epoch: 5| Step: 2
Training loss: 2.540519132203119
Validation loss: 2.582138536372122

Epoch: 5| Step: 3
Training loss: 2.2155989716672946
Validation loss: 2.6299918938646023

Epoch: 5| Step: 4
Training loss: 3.115580438507572
Validation loss: 2.5814301276300924

Epoch: 5| Step: 5
Training loss: 2.8414887880677697
Validation loss: 2.647000285744877

Epoch: 5| Step: 6
Training loss: 2.1182290080883104
Validation loss: 2.644878017242387

Epoch: 5| Step: 7
Training loss: 2.0404604508096598
Validation loss: 2.6293761280753474

Epoch: 5| Step: 8
Training loss: 2.6507959358130067
Validation loss: 2.610826667184982

Epoch: 5| Step: 9
Training loss: 2.5120405166055484
Validation loss: 2.6114615874897225

Epoch: 5| Step: 10
Training loss: 2.1234195666366413
Validation loss: 2.6314373839881884

Epoch: 5| Step: 11
Training loss: 2.624612688828091
Validation loss: 2.6597017860678824

Epoch: 30| Step: 0
Training loss: 2.973662317690238
Validation loss: 2.64296739656957

Epoch: 5| Step: 1
Training loss: 2.7592688327294193
Validation loss: 2.6528034626436874

Epoch: 5| Step: 2
Training loss: 2.680659081848743
Validation loss: 2.663678325200153

Epoch: 5| Step: 3
Training loss: 2.3578952418345613
Validation loss: 2.6134434883912387

Epoch: 5| Step: 4
Training loss: 2.219804540054129
Validation loss: 2.6371367285712153

Epoch: 5| Step: 5
Training loss: 3.022071233963861
Validation loss: 2.7016985957333586

Epoch: 5| Step: 6
Training loss: 2.441849569125278
Validation loss: 2.6904206005203752

Epoch: 5| Step: 7
Training loss: 2.439193528521277
Validation loss: 2.706947850148609

Epoch: 5| Step: 8
Training loss: 2.364714284175251
Validation loss: 2.6619589696177792

Epoch: 5| Step: 9
Training loss: 3.238779800378055
Validation loss: 2.687761197963074

Epoch: 5| Step: 10
Training loss: 2.0656918190264073
Validation loss: 2.6616169396387104

Epoch: 5| Step: 11
Training loss: 1.162021819591021
Validation loss: 2.682558362473466

Epoch: 31| Step: 0
Training loss: 2.981376219822573
Validation loss: 2.6910664510465434

Epoch: 5| Step: 1
Training loss: 2.777960385572227
Validation loss: 2.667552008784727

Epoch: 5| Step: 2
Training loss: 2.3502396319342944
Validation loss: 2.617538629767213

Epoch: 5| Step: 3
Training loss: 2.6813143137796778
Validation loss: 2.67333047571965

Epoch: 5| Step: 4
Training loss: 3.2159383400562045
Validation loss: 2.5935354297236195

Epoch: 5| Step: 5
Training loss: 2.4562360146782
Validation loss: 2.6382244944056943

Epoch: 5| Step: 6
Training loss: 1.7445585256409706
Validation loss: 2.5538945615261155

Epoch: 5| Step: 7
Training loss: 2.49302740503237
Validation loss: 2.655175500344746

Epoch: 5| Step: 8
Training loss: 2.5904627731938126
Validation loss: 2.6390375372920216

Epoch: 5| Step: 9
Training loss: 2.3268140135546536
Validation loss: 2.671209449490032

Epoch: 5| Step: 10
Training loss: 2.5930989379014457
Validation loss: 2.6396468079383517

Epoch: 5| Step: 11
Training loss: 2.2274411258131206
Validation loss: 2.6230029123522556

Epoch: 32| Step: 0
Training loss: 2.6259092845079564
Validation loss: 2.60023738575177

Epoch: 5| Step: 1
Training loss: 2.4763123780067082
Validation loss: 2.6315093206409332

Epoch: 5| Step: 2
Training loss: 2.8468982750017617
Validation loss: 2.6317595008975023

Epoch: 5| Step: 3
Training loss: 2.7012878525467987
Validation loss: 2.5708631217524975

Epoch: 5| Step: 4
Training loss: 2.2357970294239604
Validation loss: 2.6200302210064623

Epoch: 5| Step: 5
Training loss: 2.042527568729136
Validation loss: 2.671500051413094

Epoch: 5| Step: 6
Training loss: 2.370983743393866
Validation loss: 2.634343295587229

Epoch: 5| Step: 7
Training loss: 3.0869675088302646
Validation loss: 2.568558168634908

Epoch: 5| Step: 8
Training loss: 2.011066456937704
Validation loss: 2.6518747798090354

Epoch: 5| Step: 9
Training loss: 2.4805199805548606
Validation loss: 2.6062503654607796

Epoch: 5| Step: 10
Training loss: 2.856753622517284
Validation loss: 2.6683364826974465

Epoch: 5| Step: 11
Training loss: 4.025044477702743
Validation loss: 2.64436432214401

Epoch: 33| Step: 0
Training loss: 2.850132581069746
Validation loss: 2.663608963620583

Epoch: 5| Step: 1
Training loss: 2.1350547545869234
Validation loss: 2.617605394241191

Epoch: 5| Step: 2
Training loss: 2.336323071557087
Validation loss: 2.64555224980607

Epoch: 5| Step: 3
Training loss: 3.5664422157705253
Validation loss: 2.683232371482375

Epoch: 5| Step: 4
Training loss: 2.1205802281805775
Validation loss: 2.6322720705930007

Epoch: 5| Step: 5
Training loss: 2.4039528520819538
Validation loss: 2.6500541194151896

Epoch: 5| Step: 6
Training loss: 2.7335359866528055
Validation loss: 2.6393575391614146

Epoch: 5| Step: 7
Training loss: 1.9390525135210395
Validation loss: 2.679186263440387

Epoch: 5| Step: 8
Training loss: 2.6827906666013326
Validation loss: 2.697617692227172

Epoch: 5| Step: 9
Training loss: 3.0331191759350316
Validation loss: 2.6313997963001934

Epoch: 5| Step: 10
Training loss: 2.470437354468045
Validation loss: 2.620115136311501

Epoch: 5| Step: 11
Training loss: 1.342477684048632
Validation loss: 2.645291732313003

Epoch: 34| Step: 0
Training loss: 2.4135468064869325
Validation loss: 2.6751939523504102

Epoch: 5| Step: 1
Training loss: 2.4047046008874555
Validation loss: 2.684449364398542

Epoch: 5| Step: 2
Training loss: 1.8831123334912538
Validation loss: 2.6246901321685585

Epoch: 5| Step: 3
Training loss: 2.331048550735533
Validation loss: 2.6920469210823557

Epoch: 5| Step: 4
Training loss: 2.5984934440091148
Validation loss: 2.7123202884049866

Epoch: 5| Step: 5
Training loss: 2.8846064415817527
Validation loss: 2.644082873305418

Epoch: 5| Step: 6
Training loss: 3.014256932941863
Validation loss: 2.603223821986039

Epoch: 5| Step: 7
Training loss: 2.9519735039036212
Validation loss: 2.663845329345091

Epoch: 5| Step: 8
Training loss: 2.303342886029468
Validation loss: 2.6798448025249835

Epoch: 5| Step: 9
Training loss: 2.4875543751356655
Validation loss: 2.6247752638390427

Epoch: 5| Step: 10
Training loss: 2.69767812216802
Validation loss: 2.6374400002463263

Epoch: 5| Step: 11
Training loss: 0.948775136762903
Validation loss: 2.6543617942343234

Epoch: 35| Step: 0
Training loss: 2.012428410364463
Validation loss: 2.6460423587223203

Epoch: 5| Step: 1
Training loss: 3.2212263044404295
Validation loss: 2.6150763542024866

Epoch: 5| Step: 2
Training loss: 2.3682983612048436
Validation loss: 2.638373963550628

Epoch: 5| Step: 3
Training loss: 2.850349230868919
Validation loss: 2.5978193456555836

Epoch: 5| Step: 4
Training loss: 2.6106376105897353
Validation loss: 2.583413593265757

Epoch: 5| Step: 5
Training loss: 2.1112533683140176
Validation loss: 2.6225263695047203

Epoch: 5| Step: 6
Training loss: 3.275434590398875
Validation loss: 2.6408998658572678

Epoch: 5| Step: 7
Training loss: 2.3071156270285833
Validation loss: 2.657896522630622

Epoch: 5| Step: 8
Training loss: 2.369871424635822
Validation loss: 2.674461651936314

Epoch: 5| Step: 9
Training loss: 2.598491241945324
Validation loss: 2.600799410447115

Epoch: 5| Step: 10
Training loss: 2.4381922203562545
Validation loss: 2.6133627999985674

Epoch: 5| Step: 11
Training loss: 1.8346627212849784
Validation loss: 2.6360456516470205

Epoch: 36| Step: 0
Training loss: 2.7501049888683493
Validation loss: 2.646255485142768

Epoch: 5| Step: 1
Training loss: 2.364387089544371
Validation loss: 2.6603880233736246

Epoch: 5| Step: 2
Training loss: 2.9934648222671463
Validation loss: 2.673534870436819

Epoch: 5| Step: 3
Training loss: 1.8576552829038837
Validation loss: 2.625518792975254

Epoch: 5| Step: 4
Training loss: 2.989040383049219
Validation loss: 2.676054917794326

Epoch: 5| Step: 5
Training loss: 2.896294390157535
Validation loss: 2.6395920759104943

Epoch: 5| Step: 6
Training loss: 1.4568933007438112
Validation loss: 2.661810108285641

Epoch: 5| Step: 7
Training loss: 2.6378016077943616
Validation loss: 2.671990256398342

Epoch: 5| Step: 8
Training loss: 2.3995050794194346
Validation loss: 2.656289459384213

Epoch: 5| Step: 9
Training loss: 2.8561454837299443
Validation loss: 2.6298029080394216

Epoch: 5| Step: 10
Training loss: 2.643397664429397
Validation loss: 2.6724546744342392

Epoch: 5| Step: 11
Training loss: 2.4267222472871746
Validation loss: 2.576409283414757

Epoch: 37| Step: 0
Training loss: 2.9852186678181454
Validation loss: 2.5994013687096333

Epoch: 5| Step: 1
Training loss: 2.3207528566644724
Validation loss: 2.6455235875662564

Epoch: 5| Step: 2
Training loss: 2.242746954581081
Validation loss: 2.6304237932140584

Epoch: 5| Step: 3
Training loss: 2.7937958033005117
Validation loss: 2.6192337121998674

Epoch: 5| Step: 4
Training loss: 2.6461594948768035
Validation loss: 2.559802546827441

Epoch: 5| Step: 5
Training loss: 2.1618427225897716
Validation loss: 2.613639377446504

Epoch: 5| Step: 6
Training loss: 2.580246947986094
Validation loss: 2.6078755911449587

Epoch: 5| Step: 7
Training loss: 2.92330636444469
Validation loss: 2.5681683603480403

Epoch: 5| Step: 8
Training loss: 2.801894473455569
Validation loss: 2.6492963540475847

Epoch: 5| Step: 9
Training loss: 2.195846221229715
Validation loss: 2.621631379568044

Epoch: 5| Step: 10
Training loss: 2.4475718045636317
Validation loss: 2.6042859139160996

Epoch: 5| Step: 11
Training loss: 2.1792256402617687
Validation loss: 2.561351410158434

Epoch: 38| Step: 0
Training loss: 2.68158781328869
Validation loss: 2.652952342561647

Epoch: 5| Step: 1
Training loss: 2.0694449280376284
Validation loss: 2.6507161071070273

Epoch: 5| Step: 2
Training loss: 2.744414031503311
Validation loss: 2.658545743643539

Epoch: 5| Step: 3
Training loss: 2.232595735656608
Validation loss: 2.653553532775558

Epoch: 5| Step: 4
Training loss: 2.223089353604323
Validation loss: 2.6818555841607656

Epoch: 5| Step: 5
Training loss: 2.3814177887041765
Validation loss: 2.6111731891038894

Epoch: 5| Step: 6
Training loss: 2.84720125474937
Validation loss: 2.627686083713632

Epoch: 5| Step: 7
Training loss: 2.418929345236461
Validation loss: 2.5681184450191057

Epoch: 5| Step: 8
Training loss: 2.4579047998750934
Validation loss: 2.568419512103902

Epoch: 5| Step: 9
Training loss: 3.148718582366087
Validation loss: 2.6461038707730697

Epoch: 5| Step: 10
Training loss: 2.7886206867325387
Validation loss: 2.6388558663148034

Epoch: 5| Step: 11
Training loss: 2.0697446800188444
Validation loss: 2.6003461711243743

Epoch: 39| Step: 0
Training loss: 2.6505242962676236
Validation loss: 2.6316752217797768

Epoch: 5| Step: 1
Training loss: 2.07515831768495
Validation loss: 2.6241614501003223

Epoch: 5| Step: 2
Training loss: 2.3126256753949286
Validation loss: 2.6692030338267636

Epoch: 5| Step: 3
Training loss: 2.4811633962127635
Validation loss: 2.6433240388026955

Epoch: 5| Step: 4
Training loss: 2.8789339103042817
Validation loss: 2.571654405245308

Epoch: 5| Step: 5
Training loss: 2.961888948026562
Validation loss: 2.6335284601924593

Epoch: 5| Step: 6
Training loss: 1.983322885897178
Validation loss: 2.6550353096495614

Epoch: 5| Step: 7
Training loss: 2.3357371368723614
Validation loss: 2.6048265473052856

Epoch: 5| Step: 8
Training loss: 2.502955596944516
Validation loss: 2.5944269131942406

Epoch: 5| Step: 9
Training loss: 3.4434611564562405
Validation loss: 2.6357843057179533

Epoch: 5| Step: 10
Training loss: 2.365442621212886
Validation loss: 2.6386864410231774

Epoch: 5| Step: 11
Training loss: 2.113177679488957
Validation loss: 2.6208251686656348

Epoch: 40| Step: 0
Training loss: 2.4490467357919115
Validation loss: 2.5667972392665055

Epoch: 5| Step: 1
Training loss: 3.1223678184612087
Validation loss: 2.6271086957545715

Epoch: 5| Step: 2
Training loss: 2.8296563654955613
Validation loss: 2.597821789201819

Epoch: 5| Step: 3
Training loss: 2.1508178840840073
Validation loss: 2.670368331197542

Epoch: 5| Step: 4
Training loss: 3.5218783902386357
Validation loss: 2.6117457282030587

Epoch: 5| Step: 5
Training loss: 1.799094910362007
Validation loss: 2.5544681979902903

Epoch: 5| Step: 6
Training loss: 2.2598790409835456
Validation loss: 2.6467202807548382

Epoch: 5| Step: 7
Training loss: 1.835886982973546
Validation loss: 2.571193308386871

Epoch: 5| Step: 8
Training loss: 2.1182987914231726
Validation loss: 2.578289431327858

Epoch: 5| Step: 9
Training loss: 2.4144810187248757
Validation loss: 2.6189701367142266

Epoch: 5| Step: 10
Training loss: 3.052908376858879
Validation loss: 2.6165854715295445

Epoch: 5| Step: 11
Training loss: 1.630618140373262
Validation loss: 2.6209100999086328

Epoch: 41| Step: 0
Training loss: 2.533941180521275
Validation loss: 2.5908667805503383

Epoch: 5| Step: 1
Training loss: 2.787704521853001
Validation loss: 2.5897684292511163

Epoch: 5| Step: 2
Training loss: 2.5433341846322985
Validation loss: 2.6359502430630233

Epoch: 5| Step: 3
Training loss: 2.2620638516535116
Validation loss: 2.5529054186995372

Epoch: 5| Step: 4
Training loss: 2.3979000520724387
Validation loss: 2.6432556013216746

Epoch: 5| Step: 5
Training loss: 2.196591367902261
Validation loss: 2.6371538344858205

Epoch: 5| Step: 6
Training loss: 3.049842367632666
Validation loss: 2.624832950302401

Epoch: 5| Step: 7
Training loss: 2.98476914604188
Validation loss: 2.6793043828446463

Epoch: 5| Step: 8
Training loss: 2.112552989769137
Validation loss: 2.7297496767465153

Epoch: 5| Step: 9
Training loss: 2.4633388852515865
Validation loss: 2.641619748883215

Epoch: 5| Step: 10
Training loss: 2.6194227096592604
Validation loss: 2.664302766617031

Epoch: 5| Step: 11
Training loss: 2.840618211593322
Validation loss: 2.652604275222877

Epoch: 42| Step: 0
Training loss: 2.4714338948312973
Validation loss: 2.5551139483389735

Epoch: 5| Step: 1
Training loss: 2.0982136758264276
Validation loss: 2.6441180133120437

Epoch: 5| Step: 2
Training loss: 2.9445668700895893
Validation loss: 2.599095225630947

Epoch: 5| Step: 3
Training loss: 2.5833955470151384
Validation loss: 2.5900381215737722

Epoch: 5| Step: 4
Training loss: 2.0200012958635765
Validation loss: 2.605310727903143

Epoch: 5| Step: 5
Training loss: 2.1104601294161482
Validation loss: 2.593409056258744

Epoch: 5| Step: 6
Training loss: 3.131266300364571
Validation loss: 2.6138304060687068

Epoch: 5| Step: 7
Training loss: 2.6344794817169106
Validation loss: 2.6083833557629785

Epoch: 5| Step: 8
Training loss: 2.203528509320435
Validation loss: 2.559440329078509

Epoch: 5| Step: 9
Training loss: 2.794287822253418
Validation loss: 2.5986404332820103

Epoch: 5| Step: 10
Training loss: 2.522969016412187
Validation loss: 2.610379514914415

Epoch: 5| Step: 11
Training loss: 2.2202991933511136
Validation loss: 2.6393229831619642

Epoch: 43| Step: 0
Training loss: 2.2855314028328206
Validation loss: 2.602299002716284

Epoch: 5| Step: 1
Training loss: 3.0050359419769412
Validation loss: 2.6304110886383576

Epoch: 5| Step: 2
Training loss: 1.9901178118083134
Validation loss: 2.6210860068921757

Epoch: 5| Step: 3
Training loss: 2.8337725317639357
Validation loss: 2.6883717830704517

Epoch: 5| Step: 4
Training loss: 2.6802321344873787
Validation loss: 2.6298161104046347

Epoch: 5| Step: 5
Training loss: 2.5163377024739435
Validation loss: 2.6151830674357477

Epoch: 5| Step: 6
Training loss: 2.763784367189364
Validation loss: 2.7304210158411

Epoch: 5| Step: 7
Training loss: 2.466266976871826
Validation loss: 2.660381720235468

Epoch: 5| Step: 8
Training loss: 3.0160341924049634
Validation loss: 2.6316140311918272

Epoch: 5| Step: 9
Training loss: 2.0600306438277856
Validation loss: 2.6856318419915817

Epoch: 5| Step: 10
Training loss: 2.281610538785224
Validation loss: 2.679460176662771

Epoch: 5| Step: 11
Training loss: 3.224120613085399
Validation loss: 2.64631043410333

Epoch: 44| Step: 0
Training loss: 2.9586037167486268
Validation loss: 2.6561119642107602

Epoch: 5| Step: 1
Training loss: 2.2080751903972278
Validation loss: 2.5479764643337695

Epoch: 5| Step: 2
Training loss: 2.16034298963978
Validation loss: 2.6272635842505503

Epoch: 5| Step: 3
Training loss: 2.2914419468603824
Validation loss: 2.6520890276044398

Epoch: 5| Step: 4
Training loss: 2.1003098849584085
Validation loss: 2.62991385873024

Epoch: 5| Step: 5
Training loss: 2.9065625422606605
Validation loss: 2.628881804837698

Epoch: 5| Step: 6
Training loss: 2.774429530711896
Validation loss: 2.642117949175143

Epoch: 5| Step: 7
Training loss: 2.514893988314604
Validation loss: 2.5924152440544996

Epoch: 5| Step: 8
Training loss: 2.4802747755725187
Validation loss: 2.625508535414725

Epoch: 5| Step: 9
Training loss: 2.8571104660922897
Validation loss: 2.61413865025053

Epoch: 5| Step: 10
Training loss: 2.210464480856992
Validation loss: 2.593460350256185

Epoch: 5| Step: 11
Training loss: 3.333538684877411
Validation loss: 2.637711311300286

Epoch: 45| Step: 0
Training loss: 2.4799602317697893
Validation loss: 2.5621647693035023

Epoch: 5| Step: 1
Training loss: 2.8514203597921695
Validation loss: 2.6132474934175347

Epoch: 5| Step: 2
Training loss: 2.7378167861819582
Validation loss: 2.669424472512054

Epoch: 5| Step: 3
Training loss: 2.2426964584251183
Validation loss: 2.5902239029991505

Epoch: 5| Step: 4
Training loss: 2.3781072468038578
Validation loss: 2.6186107769953963

Epoch: 5| Step: 5
Training loss: 2.6747560193751494
Validation loss: 2.621177958136833

Epoch: 5| Step: 6
Training loss: 2.8693056520039097
Validation loss: 2.590363501652119

Epoch: 5| Step: 7
Training loss: 2.848203253308261
Validation loss: 2.6765826767700793

Epoch: 5| Step: 8
Training loss: 2.122713766487615
Validation loss: 2.601359144631291

Epoch: 5| Step: 9
Training loss: 1.9383606998592364
Validation loss: 2.5715774546329127

Epoch: 5| Step: 10
Training loss: 2.784017150694537
Validation loss: 2.5807943608543233

Epoch: 5| Step: 11
Training loss: 2.5748882899080052
Validation loss: 2.6347173446480983

Epoch: 46| Step: 0
Training loss: 2.1927501345264626
Validation loss: 2.6334004448435047

Epoch: 5| Step: 1
Training loss: 2.4279085865566055
Validation loss: 2.6458770017449478

Epoch: 5| Step: 2
Training loss: 2.3734466090476434
Validation loss: 2.655518305735938

Epoch: 5| Step: 3
Training loss: 2.5739025332738334
Validation loss: 2.646285665449231

Epoch: 5| Step: 4
Training loss: 2.504232638268135
Validation loss: 2.600759502582375

Epoch: 5| Step: 5
Training loss: 2.860406741583253
Validation loss: 2.6170810317213746

Epoch: 5| Step: 6
Training loss: 1.9171883108173076
Validation loss: 2.595025928376356

Epoch: 5| Step: 7
Training loss: 2.9088116912791495
Validation loss: 2.632157331952976

Epoch: 5| Step: 8
Training loss: 2.837532876786322
Validation loss: 2.5684859598776204

Epoch: 5| Step: 9
Training loss: 2.037976088805681
Validation loss: 2.566562285922382

Epoch: 5| Step: 10
Training loss: 2.865606303346433
Validation loss: 2.5265908807636146

Epoch: 5| Step: 11
Training loss: 1.4017339459094034
Validation loss: 2.595065533950382

Epoch: 47| Step: 0
Training loss: 3.172676173159096
Validation loss: 2.6220779579851485

Epoch: 5| Step: 1
Training loss: 1.8929295011915588
Validation loss: 2.5985370376065724

Epoch: 5| Step: 2
Training loss: 2.761230166542313
Validation loss: 2.5763825934596807

Epoch: 5| Step: 3
Training loss: 2.357545357972712
Validation loss: 2.6324657887297414

Epoch: 5| Step: 4
Training loss: 2.6198461892209974
Validation loss: 2.6328491034826205

Epoch: 5| Step: 5
Training loss: 2.2379521898646257
Validation loss: 2.6039124034095846

Epoch: 5| Step: 6
Training loss: 2.222950786792296
Validation loss: 2.6206949179769086

Epoch: 5| Step: 7
Training loss: 3.0082457391414996
Validation loss: 2.6443203194444376

Epoch: 5| Step: 8
Training loss: 2.4772130069740443
Validation loss: 2.664584361372673

Epoch: 5| Step: 9
Training loss: 2.815985490794083
Validation loss: 2.6596896508770325

Epoch: 5| Step: 10
Training loss: 2.1600904678896606
Validation loss: 2.597246366205604

Epoch: 5| Step: 11
Training loss: 2.978247138257758
Validation loss: 2.668449470251039

Epoch: 48| Step: 0
Training loss: 1.8022550232820305
Validation loss: 2.6748306367861225

Epoch: 5| Step: 1
Training loss: 2.981500169666061
Validation loss: 2.669170520417235

Epoch: 5| Step: 2
Training loss: 2.337664013988615
Validation loss: 2.626509270401919

Epoch: 5| Step: 3
Training loss: 2.4858112142484394
Validation loss: 2.609987716158708

Epoch: 5| Step: 4
Training loss: 2.376816506640299
Validation loss: 2.5920360563102065

Epoch: 5| Step: 5
Training loss: 2.2809898541670965
Validation loss: 2.6387682938766077

Epoch: 5| Step: 6
Training loss: 3.1403696136640993
Validation loss: 2.5791502657529595

Epoch: 5| Step: 7
Training loss: 2.2895250081022986
Validation loss: 2.595439169355398

Epoch: 5| Step: 8
Training loss: 2.748882239935127
Validation loss: 2.5898411761808573

Epoch: 5| Step: 9
Training loss: 2.438277487368432
Validation loss: 2.597179558404121

Epoch: 5| Step: 10
Training loss: 2.513042664638954
Validation loss: 2.5803461371193546

Epoch: 5| Step: 11
Training loss: 2.2451323732291453
Validation loss: 2.558931261471352

Epoch: 49| Step: 0
Training loss: 2.57527419176692
Validation loss: 2.6136340790262405

Epoch: 5| Step: 1
Training loss: 2.173706160942894
Validation loss: 2.642140512257293

Epoch: 5| Step: 2
Training loss: 2.1135301143756053
Validation loss: 2.612042382877131

Epoch: 5| Step: 3
Training loss: 2.3798162915149277
Validation loss: 2.5533833728232884

Epoch: 5| Step: 4
Training loss: 2.593028048497862
Validation loss: 2.640257774114263

Epoch: 5| Step: 5
Training loss: 2.53236298758152
Validation loss: 2.5849183754851106

Epoch: 5| Step: 6
Training loss: 3.1823458419825146
Validation loss: 2.5874849051804616

Epoch: 5| Step: 7
Training loss: 2.189926654336462
Validation loss: 2.6208472744783693

Epoch: 5| Step: 8
Training loss: 2.6552965135823765
Validation loss: 2.618553951211445

Epoch: 5| Step: 9
Training loss: 2.239788406800689
Validation loss: 2.6001859389049504

Epoch: 5| Step: 10
Training loss: 3.0078351701154595
Validation loss: 2.6104277012057238

Epoch: 5| Step: 11
Training loss: 2.3438567073690653
Validation loss: 2.624777981285204

Epoch: 50| Step: 0
Training loss: 2.8135751152851434
Validation loss: 2.6316471822471135

Epoch: 5| Step: 1
Training loss: 2.6812410438939325
Validation loss: 2.581712546327747

Epoch: 5| Step: 2
Training loss: 2.527612120634642
Validation loss: 2.644773734173273

Epoch: 5| Step: 3
Training loss: 2.9470069119489195
Validation loss: 2.649261263978046

Epoch: 5| Step: 4
Training loss: 2.052682805162161
Validation loss: 2.631152017087413

Epoch: 5| Step: 5
Training loss: 3.1882996397602765
Validation loss: 2.6305070021359156

Epoch: 5| Step: 6
Training loss: 2.3574935788403923
Validation loss: 2.5721767355144793

Epoch: 5| Step: 7
Training loss: 2.288955321422954
Validation loss: 2.655831655582185

Epoch: 5| Step: 8
Training loss: 2.3439617824238046
Validation loss: 2.6224172655054985

Epoch: 5| Step: 9
Training loss: 1.8430062426431857
Validation loss: 2.6728559704670944

Epoch: 5| Step: 10
Training loss: 2.2518057464783783
Validation loss: 2.6103342961688023

Epoch: 5| Step: 11
Training loss: 1.2591969707350785
Validation loss: 2.5992623701105453

Epoch: 51| Step: 0
Training loss: 2.144124643937244
Validation loss: 2.603215071702447

Epoch: 5| Step: 1
Training loss: 2.8508426959670077
Validation loss: 2.6536387417554703

Epoch: 5| Step: 2
Training loss: 2.639829165826788
Validation loss: 2.6182283106424906

Epoch: 5| Step: 3
Training loss: 3.313537147388576
Validation loss: 2.6251004177141564

Epoch: 5| Step: 4
Training loss: 1.9922725285354796
Validation loss: 2.592784625338778

Epoch: 5| Step: 5
Training loss: 2.9641110767653145
Validation loss: 2.6607110466789554

Epoch: 5| Step: 6
Training loss: 2.3557093356676266
Validation loss: 2.619779307422847

Epoch: 5| Step: 7
Training loss: 2.298787780252121
Validation loss: 2.6988623641891767

Epoch: 5| Step: 8
Training loss: 2.2533580305036423
Validation loss: 2.6174782510829724

Epoch: 5| Step: 9
Training loss: 1.8830598534153926
Validation loss: 2.5770859213846626

Epoch: 5| Step: 10
Training loss: 2.5352224567626087
Validation loss: 2.6724040007827328

Epoch: 5| Step: 11
Training loss: 2.7835914956553984
Validation loss: 2.5953848600395792

Epoch: 52| Step: 0
Training loss: 2.372202178945844
Validation loss: 2.670025432581032

Epoch: 5| Step: 1
Training loss: 2.8906824054688385
Validation loss: 2.6129680078976047

Epoch: 5| Step: 2
Training loss: 2.6225928213968026
Validation loss: 2.6112999963303447

Epoch: 5| Step: 3
Training loss: 2.29012942918718
Validation loss: 2.616710023358824

Epoch: 5| Step: 4
Training loss: 2.6562533210284847
Validation loss: 2.558268837524813

Epoch: 5| Step: 5
Training loss: 2.108260927226055
Validation loss: 2.674335807714594

Epoch: 5| Step: 6
Training loss: 2.6683992678017256
Validation loss: 2.6062183779193937

Epoch: 5| Step: 7
Training loss: 2.3690599143171776
Validation loss: 2.576050896993766

Epoch: 5| Step: 8
Training loss: 3.103387483096376
Validation loss: 2.604135934012586

Epoch: 5| Step: 9
Training loss: 2.3616700788575127
Validation loss: 2.6429477667137666

Epoch: 5| Step: 10
Training loss: 2.485929374753476
Validation loss: 2.597987229909046

Epoch: 5| Step: 11
Training loss: 1.6054028128567361
Validation loss: 2.529024757073141

Epoch: 53| Step: 0
Training loss: 2.4634681889636587
Validation loss: 2.595143303972172

Epoch: 5| Step: 1
Training loss: 2.8947926762320475
Validation loss: 2.5899541264599164

Epoch: 5| Step: 2
Training loss: 2.4388929446202847
Validation loss: 2.6239430290180694

Epoch: 5| Step: 3
Training loss: 2.088958039165002
Validation loss: 2.5947328758139014

Epoch: 5| Step: 4
Training loss: 2.711471197269
Validation loss: 2.5768934911335397

Epoch: 5| Step: 5
Training loss: 2.6630871908802516
Validation loss: 2.610714775948562

Epoch: 5| Step: 6
Training loss: 2.356215021900835
Validation loss: 2.625986763378837

Epoch: 5| Step: 7
Training loss: 2.196964172029474
Validation loss: 2.615572143348769

Epoch: 5| Step: 8
Training loss: 2.845958816048047
Validation loss: 2.633971648676036

Epoch: 5| Step: 9
Training loss: 2.099083668742761
Validation loss: 2.6306438286946503

Epoch: 5| Step: 10
Training loss: 2.459561886890744
Validation loss: 2.615686489128394

Epoch: 5| Step: 11
Training loss: 2.6467351703122053
Validation loss: 2.561842551055742

Epoch: 54| Step: 0
Training loss: 2.562436731069164
Validation loss: 2.5868205150424872

Epoch: 5| Step: 1
Training loss: 2.7888643424113577
Validation loss: 2.508447024128234

Epoch: 5| Step: 2
Training loss: 2.3771627517079916
Validation loss: 2.5733327928066507

Epoch: 5| Step: 3
Training loss: 2.0955113076970107
Validation loss: 2.61366052541006

Epoch: 5| Step: 4
Training loss: 2.7741698251898965
Validation loss: 2.572718046349546

Epoch: 5| Step: 5
Training loss: 2.1753818001467953
Validation loss: 2.642020716291888

Epoch: 5| Step: 6
Training loss: 2.204069651996795
Validation loss: 2.6193941976416713

Epoch: 5| Step: 7
Training loss: 2.0821937368804213
Validation loss: 2.51406343142767

Epoch: 5| Step: 8
Training loss: 2.6775489926597538
Validation loss: 2.6435187358123704

Epoch: 5| Step: 9
Training loss: 2.7272306569062392
Validation loss: 2.6259145959910506

Epoch: 5| Step: 10
Training loss: 2.9758461718539144
Validation loss: 2.5840594107069306

Epoch: 5| Step: 11
Training loss: 3.29169639541786
Validation loss: 2.595334170574651

Epoch: 55| Step: 0
Training loss: 2.032823158840234
Validation loss: 2.598482567477967

Epoch: 5| Step: 1
Training loss: 2.4159932239576394
Validation loss: 2.5711621519865813

Epoch: 5| Step: 2
Training loss: 2.872774506708461
Validation loss: 2.5442609184850244

Epoch: 5| Step: 3
Training loss: 2.630058410198973
Validation loss: 2.6202934889235485

Epoch: 5| Step: 4
Training loss: 2.1764906543449545
Validation loss: 2.5961770801102286

Epoch: 5| Step: 5
Training loss: 3.2859100674415114
Validation loss: 2.552665944971139

Epoch: 5| Step: 6
Training loss: 2.398758062256687
Validation loss: 2.593308257974229

Epoch: 5| Step: 7
Training loss: 2.4418770053953907
Validation loss: 2.635762909370443

Epoch: 5| Step: 8
Training loss: 2.048932271952298
Validation loss: 2.59629318308529

Epoch: 5| Step: 9
Training loss: 2.194090370660804
Validation loss: 2.6015490091487647

Epoch: 5| Step: 10
Training loss: 2.8378219018584447
Validation loss: 2.6119510855770565

Epoch: 5| Step: 11
Training loss: 1.805217714573308
Validation loss: 2.6085932963644027

Epoch: 56| Step: 0
Training loss: 2.8298260541641373
Validation loss: 2.5801831824922745

Epoch: 5| Step: 1
Training loss: 3.1646077004240207
Validation loss: 2.613733226881022

Epoch: 5| Step: 2
Training loss: 1.958319873628287
Validation loss: 2.564917331352368

Epoch: 5| Step: 3
Training loss: 2.13664722497261
Validation loss: 2.659627128928557

Epoch: 5| Step: 4
Training loss: 2.2075366496481537
Validation loss: 2.6579163709882434

Epoch: 5| Step: 5
Training loss: 2.2613478704036236
Validation loss: 2.6267529908891727

Epoch: 5| Step: 6
Training loss: 2.332842457317695
Validation loss: 2.682428179973708

Epoch: 5| Step: 7
Training loss: 2.4897500677950486
Validation loss: 2.6406619315790727

Epoch: 5| Step: 8
Training loss: 2.4624636807159646
Validation loss: 2.7157131970902126

Epoch: 5| Step: 9
Training loss: 3.208178892175313
Validation loss: 2.6793331212196096

Epoch: 5| Step: 10
Training loss: 2.910218349536677
Validation loss: 2.6131879583640907

Epoch: 5| Step: 11
Training loss: 1.713351006225002
Validation loss: 2.6351423566843866

Epoch: 57| Step: 0
Training loss: 2.7860432158142348
Validation loss: 2.576144006446796

Epoch: 5| Step: 1
Training loss: 2.4193188375440124
Validation loss: 2.6061673464578936

Epoch: 5| Step: 2
Training loss: 1.7571318940630338
Validation loss: 2.564613393446774

Epoch: 5| Step: 3
Training loss: 1.9414125131548243
Validation loss: 2.643982210925928

Epoch: 5| Step: 4
Training loss: 3.0389029257491043
Validation loss: 2.638906303286954

Epoch: 5| Step: 5
Training loss: 2.4929987146195987
Validation loss: 2.641555614624172

Epoch: 5| Step: 6
Training loss: 2.2628976124768045
Validation loss: 2.5771698155202474

Epoch: 5| Step: 7
Training loss: 2.6339682920107204
Validation loss: 2.5959569626560715

Epoch: 5| Step: 8
Training loss: 2.2716217655475193
Validation loss: 2.568783522709689

Epoch: 5| Step: 9
Training loss: 3.2717729583538686
Validation loss: 2.6758342060130063

Epoch: 5| Step: 10
Training loss: 2.335925456242468
Validation loss: 2.633576558646469

Epoch: 5| Step: 11
Training loss: 3.18271472239508
Validation loss: 2.5823119487532735

Epoch: 58| Step: 0
Training loss: 2.3225012323645204
Validation loss: 2.583127459018711

Epoch: 5| Step: 1
Training loss: 2.1863454769305397
Validation loss: 2.6361048494741848

Epoch: 5| Step: 2
Training loss: 2.42294474941083
Validation loss: 2.6083602188378174

Epoch: 5| Step: 3
Training loss: 2.9603457702551865
Validation loss: 2.5689873608139293

Epoch: 5| Step: 4
Training loss: 3.1824018809977055
Validation loss: 2.6765622226754284

Epoch: 5| Step: 5
Training loss: 2.3135859027625645
Validation loss: 2.680807889636383

Epoch: 5| Step: 6
Training loss: 2.25747572555249
Validation loss: 2.6796782097687863

Epoch: 5| Step: 7
Training loss: 2.279510148113042
Validation loss: 2.6797789918574635

Epoch: 5| Step: 8
Training loss: 2.439413346759601
Validation loss: 2.6768092016338882

Epoch: 5| Step: 9
Training loss: 2.358607893778497
Validation loss: 2.569857660494325

Epoch: 5| Step: 10
Training loss: 2.6365701817229588
Validation loss: 2.636384120475928

Epoch: 5| Step: 11
Training loss: 1.7873532988630605
Validation loss: 2.611433089359601

Epoch: 59| Step: 0
Training loss: 2.774737502046136
Validation loss: 2.6241421849524222

Epoch: 5| Step: 1
Training loss: 2.991424702358047
Validation loss: 2.6423500039636796

Epoch: 5| Step: 2
Training loss: 2.4753210764995104
Validation loss: 2.577049015426238

Epoch: 5| Step: 3
Training loss: 2.4465216916274746
Validation loss: 2.653633946225861

Epoch: 5| Step: 4
Training loss: 2.5109605846281524
Validation loss: 2.662904138891239

Epoch: 5| Step: 5
Training loss: 2.440477655434695
Validation loss: 2.5554141606442413

Epoch: 5| Step: 6
Training loss: 2.1738687050485708
Validation loss: 2.617125302614777

Epoch: 5| Step: 7
Training loss: 2.3788262715542756
Validation loss: 2.575536862211939

Epoch: 5| Step: 8
Training loss: 1.9139092208835509
Validation loss: 2.548655080950144

Epoch: 5| Step: 9
Training loss: 2.857815009481539
Validation loss: 2.5950892755676342

Epoch: 5| Step: 10
Training loss: 2.5697462391533095
Validation loss: 2.616551393097854

Epoch: 5| Step: 11
Training loss: 2.4009293028604537
Validation loss: 2.577151536668632

Epoch: 60| Step: 0
Training loss: 2.6420416107597244
Validation loss: 2.5401746534514773

Epoch: 5| Step: 1
Training loss: 1.9667482038610706
Validation loss: 2.6322310548020202

Epoch: 5| Step: 2
Training loss: 2.3817001998530336
Validation loss: 2.6285655276525253

Epoch: 5| Step: 3
Training loss: 3.0909020773150178
Validation loss: 2.5774454550609587

Epoch: 5| Step: 4
Training loss: 2.4357076070284043
Validation loss: 2.607427753722842

Epoch: 5| Step: 5
Training loss: 2.824706820238216
Validation loss: 2.6106616215553213

Epoch: 5| Step: 6
Training loss: 2.1684952380141485
Validation loss: 2.6598765916628206

Epoch: 5| Step: 7
Training loss: 2.609538912621695
Validation loss: 2.6190341564654025

Epoch: 5| Step: 8
Training loss: 1.922415618532847
Validation loss: 2.5909128950198577

Epoch: 5| Step: 9
Training loss: 2.472285575864554
Validation loss: 2.6359548785607787

Epoch: 5| Step: 10
Training loss: 2.9235735357492048
Validation loss: 2.5543097548260465

Epoch: 5| Step: 11
Training loss: 2.960067903152219
Validation loss: 2.606384604413918

Epoch: 61| Step: 0
Training loss: 2.1766859601476747
Validation loss: 2.6127185529342656

Epoch: 5| Step: 1
Training loss: 1.9442911799139706
Validation loss: 2.627201886316717

Epoch: 5| Step: 2
Training loss: 2.8110692093565537
Validation loss: 2.583365702939019

Epoch: 5| Step: 3
Training loss: 3.096266522569428
Validation loss: 2.553357165833777

Epoch: 5| Step: 4
Training loss: 2.751739385357556
Validation loss: 2.6465735313722236

Epoch: 5| Step: 5
Training loss: 2.932452796497588
Validation loss: 2.5972912983766467

Epoch: 5| Step: 6
Training loss: 1.972794148374729
Validation loss: 2.579769931418134

Epoch: 5| Step: 7
Training loss: 2.6339472920119658
Validation loss: 2.5446813064194385

Epoch: 5| Step: 8
Training loss: 2.478084253118073
Validation loss: 2.612065593675268

Epoch: 5| Step: 9
Training loss: 1.93494973464854
Validation loss: 2.554057223374728

Epoch: 5| Step: 10
Training loss: 2.9615664657046166
Validation loss: 2.5936118475954824

Epoch: 5| Step: 11
Training loss: 1.703332170957603
Validation loss: 2.6047187499711977

Epoch: 62| Step: 0
Training loss: 2.7700578756517795
Validation loss: 2.5197298430014956

Epoch: 5| Step: 1
Training loss: 1.5791233794923378
Validation loss: 2.6174010308302984

Epoch: 5| Step: 2
Training loss: 2.54392441285201
Validation loss: 2.630262392577536

Epoch: 5| Step: 3
Training loss: 3.0630850719627514
Validation loss: 2.657315377149943

Epoch: 5| Step: 4
Training loss: 2.6384275423517383
Validation loss: 2.653132681354356

Epoch: 5| Step: 5
Training loss: 2.6220092084360678
Validation loss: 2.61160760343095

Epoch: 5| Step: 6
Training loss: 2.333549580317253
Validation loss: 2.6567252051937196

Epoch: 5| Step: 7
Training loss: 2.2306055671698353
Validation loss: 2.662467475328298

Epoch: 5| Step: 8
Training loss: 2.826361343370366
Validation loss: 2.672136899965491

Epoch: 5| Step: 9
Training loss: 2.081233517693216
Validation loss: 2.639093101418904

Epoch: 5| Step: 10
Training loss: 3.0103880321016425
Validation loss: 2.617652252078236

Epoch: 5| Step: 11
Training loss: 1.159396709639885
Validation loss: 2.643310482985485

Epoch: 63| Step: 0
Training loss: 2.2698828314904422
Validation loss: 2.6228724914286934

Epoch: 5| Step: 1
Training loss: 2.6402146963037163
Validation loss: 2.618508228682658

Epoch: 5| Step: 2
Training loss: 1.7820741185873257
Validation loss: 2.6399430931284513

Epoch: 5| Step: 3
Training loss: 2.198901084059496
Validation loss: 2.606261792754671

Epoch: 5| Step: 4
Training loss: 2.699027511512999
Validation loss: 2.6636566718113723

Epoch: 5| Step: 5
Training loss: 2.619980872863373
Validation loss: 2.6322317926239274

Epoch: 5| Step: 6
Training loss: 2.541238269244062
Validation loss: 2.6209482113739204

Epoch: 5| Step: 7
Training loss: 2.228211123820383
Validation loss: 2.591405728339809

Epoch: 5| Step: 8
Training loss: 2.5856886452966954
Validation loss: 2.595465341837162

Epoch: 5| Step: 9
Training loss: 2.4011376307267134
Validation loss: 2.655186705852278

Epoch: 5| Step: 10
Training loss: 2.8259709200432646
Validation loss: 2.589758555611039

Epoch: 5| Step: 11
Training loss: 3.086252394436185
Validation loss: 2.561470503362532

Epoch: 64| Step: 0
Training loss: 2.0593708460857076
Validation loss: 2.628533373269325

Epoch: 5| Step: 1
Training loss: 2.023869177529493
Validation loss: 2.570118808888357

Epoch: 5| Step: 2
Training loss: 2.6156135950785555
Validation loss: 2.5991358164474763

Epoch: 5| Step: 3
Training loss: 2.1240433054027683
Validation loss: 2.5784888309419074

Epoch: 5| Step: 4
Training loss: 2.820870130365614
Validation loss: 2.587444934013313

Epoch: 5| Step: 5
Training loss: 2.2430136617311645
Validation loss: 2.543474476222835

Epoch: 5| Step: 6
Training loss: 3.0953049268249573
Validation loss: 2.6106408945113775

Epoch: 5| Step: 7
Training loss: 2.5540727814869184
Validation loss: 2.6112568783034154

Epoch: 5| Step: 8
Training loss: 2.0486813793595435
Validation loss: 2.561135293065356

Epoch: 5| Step: 9
Training loss: 3.071607321546939
Validation loss: 2.608741831910635

Epoch: 5| Step: 10
Training loss: 2.183896721036294
Validation loss: 2.5455353925171806

Epoch: 5| Step: 11
Training loss: 0.7748058814310501
Validation loss: 2.601614146822549

Epoch: 65| Step: 0
Training loss: 2.0670168574826455
Validation loss: 2.614757434524747

Epoch: 5| Step: 1
Training loss: 2.9301038115666853
Validation loss: 2.5455535978997226

Epoch: 5| Step: 2
Training loss: 2.2477365340876503
Validation loss: 2.594721700204111

Epoch: 5| Step: 3
Training loss: 2.45994620566748
Validation loss: 2.5649848923166987

Epoch: 5| Step: 4
Training loss: 2.0968505903434984
Validation loss: 2.6342994177561936

Epoch: 5| Step: 5
Training loss: 2.4339841281558314
Validation loss: 2.6089534228612052

Epoch: 5| Step: 6
Training loss: 2.5744998297973742
Validation loss: 2.6289198082946945

Epoch: 5| Step: 7
Training loss: 2.646427708543468
Validation loss: 2.6668265351912375

Epoch: 5| Step: 8
Training loss: 2.7228924992215346
Validation loss: 2.6079995647646537

Epoch: 5| Step: 9
Training loss: 2.59332584451936
Validation loss: 2.6117281858148433

Epoch: 5| Step: 10
Training loss: 2.720980025616632
Validation loss: 2.5694635490761146

Epoch: 5| Step: 11
Training loss: 2.571524661781629
Validation loss: 2.597197543302935

Epoch: 66| Step: 0
Training loss: 2.781663756722341
Validation loss: 2.5739969245758396

Epoch: 5| Step: 1
Training loss: 2.243117933583708
Validation loss: 2.606159608555677

Epoch: 5| Step: 2
Training loss: 2.354962903518232
Validation loss: 2.5534196598779135

Epoch: 5| Step: 3
Training loss: 1.7285081076593245
Validation loss: 2.6324808513667053

Epoch: 5| Step: 4
Training loss: 2.146336419349123
Validation loss: 2.5381874102349893

Epoch: 5| Step: 5
Training loss: 2.2422715015160923
Validation loss: 2.673159344529602

Epoch: 5| Step: 6
Training loss: 2.48775305299492
Validation loss: 2.578040335449906

Epoch: 5| Step: 7
Training loss: 3.008808238690514
Validation loss: 2.6048596579064207

Epoch: 5| Step: 8
Training loss: 2.6739468043135384
Validation loss: 2.517192245753602

Epoch: 5| Step: 9
Training loss: 2.5197565495500243
Validation loss: 2.6500858702332333

Epoch: 5| Step: 10
Training loss: 2.1768444483866833
Validation loss: 2.601987038493341

Epoch: 5| Step: 11
Training loss: 3.1904042794366294
Validation loss: 2.5917873195538164

Epoch: 67| Step: 0
Training loss: 2.235395185279081
Validation loss: 2.5420251942603347

Epoch: 5| Step: 1
Training loss: 2.358135175523761
Validation loss: 2.567502496502092

Epoch: 5| Step: 2
Training loss: 2.9097406897089053
Validation loss: 2.612560182240225

Epoch: 5| Step: 3
Training loss: 2.8921059603663086
Validation loss: 2.553388041498656

Epoch: 5| Step: 4
Training loss: 2.398377557558412
Validation loss: 2.6070870288052266

Epoch: 5| Step: 5
Training loss: 2.5138036164304403
Validation loss: 2.5568921864200136

Epoch: 5| Step: 6
Training loss: 2.8433126595369025
Validation loss: 2.6367221031638595

Epoch: 5| Step: 7
Training loss: 2.3746218129262284
Validation loss: 2.553608657801801

Epoch: 5| Step: 8
Training loss: 2.902682832648639
Validation loss: 2.6290048218943225

Epoch: 5| Step: 9
Training loss: 1.6176699595946784
Validation loss: 2.5880050806610315

Epoch: 5| Step: 10
Training loss: 2.0046993121470367
Validation loss: 2.5672673445745438

Epoch: 5| Step: 11
Training loss: 2.3621992172029334
Validation loss: 2.573061866884525

Epoch: 68| Step: 0
Training loss: 2.7472043999725013
Validation loss: 2.6027833596107164

Epoch: 5| Step: 1
Training loss: 2.375998337375817
Validation loss: 2.5542607704446536

Epoch: 5| Step: 2
Training loss: 2.2309608250713255
Validation loss: 2.605061817180113

Epoch: 5| Step: 3
Training loss: 2.0562889907062094
Validation loss: 2.5600178412347216

Epoch: 5| Step: 4
Training loss: 2.815762810081261
Validation loss: 2.6246437027738674

Epoch: 5| Step: 5
Training loss: 2.6428447174457688
Validation loss: 2.6504139422461805

Epoch: 5| Step: 6
Training loss: 2.4497031868959023
Validation loss: 2.5504722466468506

Epoch: 5| Step: 7
Training loss: 2.300957509463759
Validation loss: 2.5654735602577254

Epoch: 5| Step: 8
Training loss: 2.8126163882439092
Validation loss: 2.6040219889824288

Epoch: 5| Step: 9
Training loss: 2.3339983696298536
Validation loss: 2.6347762876558325

Epoch: 5| Step: 10
Training loss: 2.195239408640611
Validation loss: 2.5829420036869686

Epoch: 5| Step: 11
Training loss: 2.513036497920468
Validation loss: 2.679717672639699

Epoch: 69| Step: 0
Training loss: 1.984809767786459
Validation loss: 2.6186131404417745

Epoch: 5| Step: 1
Training loss: 2.127875346189743
Validation loss: 2.592284803689269

Epoch: 5| Step: 2
Training loss: 2.6475225347869262
Validation loss: 2.602007462230477

Epoch: 5| Step: 3
Training loss: 2.6134722857935264
Validation loss: 2.5877994622062293

Epoch: 5| Step: 4
Training loss: 2.2520639701620166
Validation loss: 2.635074769837654

Epoch: 5| Step: 5
Training loss: 1.9405265672570915
Validation loss: 2.564616120410594

Epoch: 5| Step: 6
Training loss: 2.8677967889743448
Validation loss: 2.545442599630037

Epoch: 5| Step: 7
Training loss: 2.096366386298981
Validation loss: 2.6149888439742828

Epoch: 5| Step: 8
Training loss: 2.9816600973342275
Validation loss: 2.56931453296228

Epoch: 5| Step: 9
Training loss: 2.397721770911785
Validation loss: 2.595692263566852

Epoch: 5| Step: 10
Training loss: 2.877611384087857
Validation loss: 2.606607823923198

Epoch: 5| Step: 11
Training loss: 2.7589117782441464
Validation loss: 2.6115983182690474

Epoch: 70| Step: 0
Training loss: 2.7001352700150774
Validation loss: 2.581767512638639

Epoch: 5| Step: 1
Training loss: 1.7851501731852601
Validation loss: 2.5622197246017793

Epoch: 5| Step: 2
Training loss: 2.1198145484782827
Validation loss: 2.5663372245343203

Epoch: 5| Step: 3
Training loss: 2.3635473684749586
Validation loss: 2.634763287353987

Epoch: 5| Step: 4
Training loss: 2.367811668368663
Validation loss: 2.5561402241329354

Epoch: 5| Step: 5
Training loss: 1.69080777405431
Validation loss: 2.5618883581496483

Epoch: 5| Step: 6
Training loss: 2.1668311081130494
Validation loss: 2.5805565705438247

Epoch: 5| Step: 7
Training loss: 2.6525858121144927
Validation loss: 2.605038704142242

Epoch: 5| Step: 8
Training loss: 3.0281047430630497
Validation loss: 2.605398088495012

Epoch: 5| Step: 9
Training loss: 2.64763924150584
Validation loss: 2.5867233158041705

Epoch: 5| Step: 10
Training loss: 3.199749167863577
Validation loss: 2.6424258033852492

Epoch: 5| Step: 11
Training loss: 0.862293109405655
Validation loss: 2.5423971101065246

Epoch: 71| Step: 0
Training loss: 2.3800555179435734
Validation loss: 2.5630574279128227

Epoch: 5| Step: 1
Training loss: 2.066586924624466
Validation loss: 2.631784579897115

Epoch: 5| Step: 2
Training loss: 2.192771228120825
Validation loss: 2.6236871887946904

Epoch: 5| Step: 3
Training loss: 2.572729765452431
Validation loss: 2.676313691638194

Epoch: 5| Step: 4
Training loss: 2.197738881325696
Validation loss: 2.61646382969104

Epoch: 5| Step: 5
Training loss: 3.349180144008967
Validation loss: 2.5634911760186143

Epoch: 5| Step: 6
Training loss: 3.2104263084377407
Validation loss: 2.5998241050227597

Epoch: 5| Step: 7
Training loss: 2.4862394234656238
Validation loss: 2.5575380743976845

Epoch: 5| Step: 8
Training loss: 1.978969269662815
Validation loss: 2.58771536371574

Epoch: 5| Step: 9
Training loss: 2.16768181079023
Validation loss: 2.6460461355722797

Epoch: 5| Step: 10
Training loss: 2.4400086820166544
Validation loss: 2.6233424126495413

Epoch: 5| Step: 11
Training loss: 2.243427319289032
Validation loss: 2.64280120065941

Epoch: 72| Step: 0
Training loss: 2.637224343887003
Validation loss: 2.598381885721734

Epoch: 5| Step: 1
Training loss: 2.6798960434977843
Validation loss: 2.5717440428520364

Epoch: 5| Step: 2
Training loss: 2.857570391411228
Validation loss: 2.5924997112184496

Epoch: 5| Step: 3
Training loss: 2.413834446872436
Validation loss: 2.617529153111948

Epoch: 5| Step: 4
Training loss: 2.0206692291431465
Validation loss: 2.5583888605213607

Epoch: 5| Step: 5
Training loss: 2.1325756123096826
Validation loss: 2.5717222064068204

Epoch: 5| Step: 6
Training loss: 2.267007655786646
Validation loss: 2.579858497668506

Epoch: 5| Step: 7
Training loss: 2.441726150916465
Validation loss: 2.542373017097369

Epoch: 5| Step: 8
Training loss: 2.5655769854756065
Validation loss: 2.5994174159384227

Epoch: 5| Step: 9
Training loss: 2.1627327589777177
Validation loss: 2.567037855954

Epoch: 5| Step: 10
Training loss: 2.579946071297701
Validation loss: 2.6217960604945434

Epoch: 5| Step: 11
Training loss: 3.352039080972388
Validation loss: 2.568152504677198

Epoch: 73| Step: 0
Training loss: 2.5130755851723903
Validation loss: 2.5894760016501506

Epoch: 5| Step: 1
Training loss: 2.709868734354873
Validation loss: 2.5934459515731243

Epoch: 5| Step: 2
Training loss: 3.0812275543323877
Validation loss: 2.628243465301282

Epoch: 5| Step: 3
Training loss: 2.022852750554831
Validation loss: 2.6961650900483516

Epoch: 5| Step: 4
Training loss: 2.0877131644502898
Validation loss: 2.5795166729243237

Epoch: 5| Step: 5
Training loss: 2.75240749401175
Validation loss: 2.578405014398721

Epoch: 5| Step: 6
Training loss: 2.617684752639798
Validation loss: 2.6301070140296585

Epoch: 5| Step: 7
Training loss: 2.767933544739335
Validation loss: 2.6464283429322157

Epoch: 5| Step: 8
Training loss: 2.1382673882622947
Validation loss: 2.6393407486380793

Epoch: 5| Step: 9
Training loss: 2.1458909357234397
Validation loss: 2.693859268798654

Epoch: 5| Step: 10
Training loss: 2.182340804998192
Validation loss: 2.6775345712692205

Epoch: 5| Step: 11
Training loss: 2.525261187500017
Validation loss: 2.630852800987392

Epoch: 74| Step: 0
Training loss: 2.5466497590800277
Validation loss: 2.5685416772154332

Epoch: 5| Step: 1
Training loss: 2.0604545391781928
Validation loss: 2.6162399550486737

Epoch: 5| Step: 2
Training loss: 2.0728270033673026
Validation loss: 2.5625087071092505

Epoch: 5| Step: 3
Training loss: 2.5491361351550017
Validation loss: 2.626786815952049

Epoch: 5| Step: 4
Training loss: 3.0290695685592754
Validation loss: 2.5777955586497976

Epoch: 5| Step: 5
Training loss: 2.398338290967803
Validation loss: 2.5783153271020676

Epoch: 5| Step: 6
Training loss: 2.4267050539725323
Validation loss: 2.643035337861134

Epoch: 5| Step: 7
Training loss: 2.3597948319752997
Validation loss: 2.6164719395759977

Epoch: 5| Step: 8
Training loss: 2.2913990789301892
Validation loss: 2.5722598628793265

Epoch: 5| Step: 9
Training loss: 2.86507976507491
Validation loss: 2.6001420520221914

Epoch: 5| Step: 10
Training loss: 2.5718039038137475
Validation loss: 2.530016135282417

Epoch: 5| Step: 11
Training loss: 1.2177844991541011
Validation loss: 2.5830245461549866

Epoch: 75| Step: 0
Training loss: 1.9107902114512034
Validation loss: 2.580868992769036

Epoch: 5| Step: 1
Training loss: 2.6383912158174416
Validation loss: 2.5583544670209575

Epoch: 5| Step: 2
Training loss: 2.8028782186247696
Validation loss: 2.5824825067595456

Epoch: 5| Step: 3
Training loss: 2.6869193935875186
Validation loss: 2.5797429027034

Epoch: 5| Step: 4
Training loss: 1.8809027899527597
Validation loss: 2.5927929280632673

Epoch: 5| Step: 5
Training loss: 2.110701080568651
Validation loss: 2.5935130872879784

Epoch: 5| Step: 6
Training loss: 3.025854598460638
Validation loss: 2.5702266079698046

Epoch: 5| Step: 7
Training loss: 2.601105887633966
Validation loss: 2.617985993604298

Epoch: 5| Step: 8
Training loss: 1.8778270389872014
Validation loss: 2.592274161697691

Epoch: 5| Step: 9
Training loss: 2.14614957189016
Validation loss: 2.6298392077737227

Epoch: 5| Step: 10
Training loss: 2.683661092165883
Validation loss: 2.6351625121428923

Epoch: 5| Step: 11
Training loss: 1.5054540026684278
Validation loss: 2.6351376047765

Epoch: 76| Step: 0
Training loss: 2.5860764388361885
Validation loss: 2.6894045151043846

Epoch: 5| Step: 1
Training loss: 2.1477784411714445
Validation loss: 2.6540895577093564

Epoch: 5| Step: 2
Training loss: 2.966774694926142
Validation loss: 2.5764872464212836

Epoch: 5| Step: 3
Training loss: 3.210453043308083
Validation loss: 2.5622498653802768

Epoch: 5| Step: 4
Training loss: 2.495659588947385
Validation loss: 2.637159191126863

Epoch: 5| Step: 5
Training loss: 2.058859646905125
Validation loss: 2.626929088988357

Epoch: 5| Step: 6
Training loss: 1.8266230224815863
Validation loss: 2.631337545996864

Epoch: 5| Step: 7
Training loss: 2.3647184179318175
Validation loss: 2.608738229533415

Epoch: 5| Step: 8
Training loss: 2.4712614009210214
Validation loss: 2.667403522899029

Epoch: 5| Step: 9
Training loss: 2.097325815781889
Validation loss: 2.6902506764715968

Epoch: 5| Step: 10
Training loss: 2.582459845586169
Validation loss: 2.665271956202917

Epoch: 5| Step: 11
Training loss: 1.6373280413078208
Validation loss: 2.6215503975156915

Epoch: 77| Step: 0
Training loss: 2.054003467486314
Validation loss: 2.5805206054164667

Epoch: 5| Step: 1
Training loss: 3.022580520655358
Validation loss: 2.566645440306973

Epoch: 5| Step: 2
Training loss: 1.6795275944733787
Validation loss: 2.514732664605049

Epoch: 5| Step: 3
Training loss: 2.1225215820006045
Validation loss: 2.6102294322455695

Epoch: 5| Step: 4
Training loss: 3.16426534120262
Validation loss: 2.5548183862597025

Epoch: 5| Step: 5
Training loss: 1.964011529884757
Validation loss: 2.6295175129859185

Epoch: 5| Step: 6
Training loss: 2.5298912263187114
Validation loss: 2.541633243549486

Epoch: 5| Step: 7
Training loss: 2.5698251001239463
Validation loss: 2.605350444038933

Epoch: 5| Step: 8
Training loss: 2.2924889447560295
Validation loss: 2.59945423743808

Epoch: 5| Step: 9
Training loss: 2.6743044153835847
Validation loss: 2.6207684704972323

Epoch: 5| Step: 10
Training loss: 2.4099878780962367
Validation loss: 2.6188642605881554

Epoch: 5| Step: 11
Training loss: 2.7745756151266043
Validation loss: 2.587164269963653

Epoch: 78| Step: 0
Training loss: 2.91711053649688
Validation loss: 2.521335036949794

Epoch: 5| Step: 1
Training loss: 2.3035903646846205
Validation loss: 2.5615502628885607

Epoch: 5| Step: 2
Training loss: 2.2268886394227567
Validation loss: 2.6072083765601066

Epoch: 5| Step: 3
Training loss: 2.5180513989184603
Validation loss: 2.5634288364387854

Epoch: 5| Step: 4
Training loss: 2.708085112323085
Validation loss: 2.565395665266864

Epoch: 5| Step: 5
Training loss: 1.9748060541654726
Validation loss: 2.6143261427102145

Epoch: 5| Step: 6
Training loss: 3.2477729209294868
Validation loss: 2.6288552432806194

Epoch: 5| Step: 7
Training loss: 2.025520931161172
Validation loss: 2.5868327770180533

Epoch: 5| Step: 8
Training loss: 2.399965675426442
Validation loss: 2.638216669785021

Epoch: 5| Step: 9
Training loss: 2.252897198678022
Validation loss: 2.592517843537585

Epoch: 5| Step: 10
Training loss: 2.192194016787467
Validation loss: 2.546212246636331

Epoch: 5| Step: 11
Training loss: 2.214922652949991
Validation loss: 2.6121473793842673

Epoch: 79| Step: 0
Training loss: 2.781116782437615
Validation loss: 2.569251961557886

Epoch: 5| Step: 1
Training loss: 2.639380618899464
Validation loss: 2.5845448911301614

Epoch: 5| Step: 2
Training loss: 2.5471066796645077
Validation loss: 2.599465083152445

Epoch: 5| Step: 3
Training loss: 2.716273264884063
Validation loss: 2.617479864083718

Epoch: 5| Step: 4
Training loss: 1.8849939395797
Validation loss: 2.6524557390574

Epoch: 5| Step: 5
Training loss: 2.5784833254479342
Validation loss: 2.6764658068494205

Epoch: 5| Step: 6
Training loss: 2.4054719732249943
Validation loss: 2.5523115964260925

Epoch: 5| Step: 7
Training loss: 2.6553081862324928
Validation loss: 2.5790033789996283

Epoch: 5| Step: 8
Training loss: 2.526524217795648
Validation loss: 2.6387643183758382

Epoch: 5| Step: 9
Training loss: 2.892091121541272
Validation loss: 2.636243706754912

Epoch: 5| Step: 10
Training loss: 1.9415533059990937
Validation loss: 2.5621844539352048

Epoch: 5| Step: 11
Training loss: 1.5627933226875028
Validation loss: 2.6086928300148333

Epoch: 80| Step: 0
Training loss: 2.7664646231938437
Validation loss: 2.5572951964893313

Epoch: 5| Step: 1
Training loss: 2.308637331375334
Validation loss: 2.6288444810311424

Epoch: 5| Step: 2
Training loss: 1.887738380789409
Validation loss: 2.615536691989612

Epoch: 5| Step: 3
Training loss: 1.9631100963669266
Validation loss: 2.613553415522668

Epoch: 5| Step: 4
Training loss: 2.1545587071024714
Validation loss: 2.6213205678085045

Epoch: 5| Step: 5
Training loss: 2.315276257898963
Validation loss: 2.6201358642367443

Epoch: 5| Step: 6
Training loss: 3.020194115368553
Validation loss: 2.6184626153777235

Epoch: 5| Step: 7
Training loss: 2.819463459403859
Validation loss: 2.6715491172344374

Epoch: 5| Step: 8
Training loss: 2.7720918211488543
Validation loss: 2.6284026768458233

Epoch: 5| Step: 9
Training loss: 1.7941987383513054
Validation loss: 2.55447451746793

Epoch: 5| Step: 10
Training loss: 2.4445794807569743
Validation loss: 2.5613103562953112

Epoch: 5| Step: 11
Training loss: 2.849773357816016
Validation loss: 2.600185300875137

Epoch: 81| Step: 0
Training loss: 2.382560541558576
Validation loss: 2.589640912934697

Epoch: 5| Step: 1
Training loss: 2.566593807804709
Validation loss: 2.5989337160604773

Epoch: 5| Step: 2
Training loss: 2.0473774300615624
Validation loss: 2.5363110428381805

Epoch: 5| Step: 3
Training loss: 2.3310998945003725
Validation loss: 2.5676030659069995

Epoch: 5| Step: 4
Training loss: 2.7801410307205283
Validation loss: 2.5996745861118056

Epoch: 5| Step: 5
Training loss: 2.0537134915135096
Validation loss: 2.61879718301006

Epoch: 5| Step: 6
Training loss: 2.266924255357644
Validation loss: 2.569028237859929

Epoch: 5| Step: 7
Training loss: 2.2403462256501587
Validation loss: 2.6585727073157273

Epoch: 5| Step: 8
Training loss: 2.425531592552389
Validation loss: 2.563839943940289

Epoch: 5| Step: 9
Training loss: 2.8493940077221116
Validation loss: 2.606020471054304

Epoch: 5| Step: 10
Training loss: 2.851354638453617
Validation loss: 2.5374960542281717

Epoch: 5| Step: 11
Training loss: 1.7293766614260067
Validation loss: 2.537737926359357

Epoch: 82| Step: 0
Training loss: 2.105704044931602
Validation loss: 2.586236412082707

Epoch: 5| Step: 1
Training loss: 2.3811842060761705
Validation loss: 2.577164843007023

Epoch: 5| Step: 2
Training loss: 2.672251178516717
Validation loss: 2.6064650247913965

Epoch: 5| Step: 3
Training loss: 1.8921387972497845
Validation loss: 2.6458315317393097

Epoch: 5| Step: 4
Training loss: 1.7843583408520036
Validation loss: 2.6264781158465578

Epoch: 5| Step: 5
Training loss: 2.4642722166967266
Validation loss: 2.6784010784536294

Epoch: 5| Step: 6
Training loss: 2.1878182315955668
Validation loss: 2.604256122324233

Epoch: 5| Step: 7
Training loss: 2.9142465814532934
Validation loss: 2.6763354133672785

Epoch: 5| Step: 8
Training loss: 1.9997544137853782
Validation loss: 2.7165311733247406

Epoch: 5| Step: 9
Training loss: 2.8129762882029317
Validation loss: 2.606771979139586

Epoch: 5| Step: 10
Training loss: 3.2695757317109306
Validation loss: 2.6683873434178143

Epoch: 5| Step: 11
Training loss: 1.4780165360316782
Validation loss: 2.660077635826006

Epoch: 83| Step: 0
Training loss: 2.1740082068968336
Validation loss: 2.6407552231800753

Epoch: 5| Step: 1
Training loss: 2.7813812396342232
Validation loss: 2.6104882848240876

Epoch: 5| Step: 2
Training loss: 2.3325286794782136
Validation loss: 2.5917023730399267

Epoch: 5| Step: 3
Training loss: 2.121338550920062
Validation loss: 2.5313912850654914

Epoch: 5| Step: 4
Training loss: 2.9670238094165224
Validation loss: 2.6269467756721694

Epoch: 5| Step: 5
Training loss: 2.401157489446191
Validation loss: 2.621484434570894

Epoch: 5| Step: 6
Training loss: 2.418898198912906
Validation loss: 2.665218210728084

Epoch: 5| Step: 7
Training loss: 2.284773000547753
Validation loss: 2.6099641138717975

Epoch: 5| Step: 8
Training loss: 2.256878405525894
Validation loss: 2.556768349569708

Epoch: 5| Step: 9
Training loss: 2.3360337457636255
Validation loss: 2.5796471196539135

Epoch: 5| Step: 10
Training loss: 2.42239167639513
Validation loss: 2.577901684115483

Epoch: 5| Step: 11
Training loss: 3.141445982557734
Validation loss: 2.6143882774960043

Epoch: 84| Step: 0
Training loss: 2.3854896389878757
Validation loss: 2.5797605085602813

Epoch: 5| Step: 1
Training loss: 2.2683131614458953
Validation loss: 2.6104647213124696

Epoch: 5| Step: 2
Training loss: 1.856081698715967
Validation loss: 2.547672536907681

Epoch: 5| Step: 3
Training loss: 2.379288064918121
Validation loss: 2.5945531528478423

Epoch: 5| Step: 4
Training loss: 2.529782376032901
Validation loss: 2.6119529454039294

Epoch: 5| Step: 5
Training loss: 2.7073401072621777
Validation loss: 2.5724091602038666

Epoch: 5| Step: 6
Training loss: 2.2335020907776326
Validation loss: 2.551036309833336

Epoch: 5| Step: 7
Training loss: 2.3019885795966193
Validation loss: 2.644258478504106

Epoch: 5| Step: 8
Training loss: 2.1367724200940676
Validation loss: 2.595095402339601

Epoch: 5| Step: 9
Training loss: 3.0677044301205183
Validation loss: 2.696688778880514

Epoch: 5| Step: 10
Training loss: 2.7284841679020584
Validation loss: 2.5968506292797846

Epoch: 5| Step: 11
Training loss: 2.506303279624309
Validation loss: 2.618974479850276

Epoch: 85| Step: 0
Training loss: 1.9070676707126808
Validation loss: 2.6068902205885105

Epoch: 5| Step: 1
Training loss: 1.9843528926549054
Validation loss: 2.594006368690541

Epoch: 5| Step: 2
Training loss: 2.570151466032617
Validation loss: 2.5728397525199784

Epoch: 5| Step: 3
Training loss: 2.711845839414639
Validation loss: 2.620557731173243

Epoch: 5| Step: 4
Training loss: 2.550704043565009
Validation loss: 2.642905520213622

Epoch: 5| Step: 5
Training loss: 2.324067542022041
Validation loss: 2.6445669963454868

Epoch: 5| Step: 6
Training loss: 2.0137481231017693
Validation loss: 2.6590101860717326

Epoch: 5| Step: 7
Training loss: 2.8096323440699487
Validation loss: 2.565617037910624

Epoch: 5| Step: 8
Training loss: 2.228884693981486
Validation loss: 2.5947767469869745

Epoch: 5| Step: 9
Training loss: 3.17940225657378
Validation loss: 2.6143428924969765

Epoch: 5| Step: 10
Training loss: 2.0256907756593328
Validation loss: 2.5652215256283726

Epoch: 5| Step: 11
Training loss: 2.8194155970842667
Validation loss: 2.581032102314991

Epoch: 86| Step: 0
Training loss: 1.88828858329539
Validation loss: 2.662430835028485

Epoch: 5| Step: 1
Training loss: 2.264298465034441
Validation loss: 2.6508805101696273

Epoch: 5| Step: 2
Training loss: 2.491503104345572
Validation loss: 2.585237483214985

Epoch: 5| Step: 3
Training loss: 2.1597500465729533
Validation loss: 2.5628509978905543

Epoch: 5| Step: 4
Training loss: 3.1954714262223067
Validation loss: 2.6268243769940427

Epoch: 5| Step: 5
Training loss: 2.497280644586901
Validation loss: 2.588578622401961

Epoch: 5| Step: 6
Training loss: 2.447463774213303
Validation loss: 2.5322841800049165

Epoch: 5| Step: 7
Training loss: 2.5504453008455172
Validation loss: 2.566708280382892

Epoch: 5| Step: 8
Training loss: 2.032233601621639
Validation loss: 2.6120280523977155

Epoch: 5| Step: 9
Training loss: 2.3701328800469375
Validation loss: 2.5960348399057507

Epoch: 5| Step: 10
Training loss: 2.2295537832325687
Validation loss: 2.5855726539797077

Epoch: 5| Step: 11
Training loss: 1.7632983246172216
Validation loss: 2.592495216437561

Epoch: 87| Step: 0
Training loss: 2.3882616116530873
Validation loss: 2.642343462298739

Epoch: 5| Step: 1
Training loss: 3.0236925121076514
Validation loss: 2.5902562779007874

Epoch: 5| Step: 2
Training loss: 2.4292407836425167
Validation loss: 2.5314736718776394

Epoch: 5| Step: 3
Training loss: 1.8457961286091895
Validation loss: 2.5780519802657524

Epoch: 5| Step: 4
Training loss: 1.8183436408422382
Validation loss: 2.608133268046885

Epoch: 5| Step: 5
Training loss: 2.297895970140381
Validation loss: 2.5950607143985267

Epoch: 5| Step: 6
Training loss: 2.325391970172213
Validation loss: 2.592925423228256

Epoch: 5| Step: 7
Training loss: 2.4484782339090274
Validation loss: 2.6026862870419585

Epoch: 5| Step: 8
Training loss: 2.6629989156573988
Validation loss: 2.5939509608844866

Epoch: 5| Step: 9
Training loss: 2.9080970391266265
Validation loss: 2.605683262128573

Epoch: 5| Step: 10
Training loss: 2.2133782060892617
Validation loss: 2.6437278026674016

Epoch: 5| Step: 11
Training loss: 1.6193894585067403
Validation loss: 2.5993653490273054

Epoch: 88| Step: 0
Training loss: 2.4009624697076846
Validation loss: 2.602609303512425

Epoch: 5| Step: 1
Training loss: 2.949615653911258
Validation loss: 2.5695957510161374

Epoch: 5| Step: 2
Training loss: 2.1151382269453913
Validation loss: 2.61402953439293

Epoch: 5| Step: 3
Training loss: 2.6452858325855604
Validation loss: 2.5560700372648113

Epoch: 5| Step: 4
Training loss: 2.513411881191656
Validation loss: 2.5804385814930115

Epoch: 5| Step: 5
Training loss: 2.213883341430368
Validation loss: 2.628282148884427

Epoch: 5| Step: 6
Training loss: 2.153456274052336
Validation loss: 2.6023046257920597

Epoch: 5| Step: 7
Training loss: 2.535715379465278
Validation loss: 2.5491197285275056

Epoch: 5| Step: 8
Training loss: 1.7844880771382954
Validation loss: 2.6675775705682256

Epoch: 5| Step: 9
Training loss: 2.3217425836153227
Validation loss: 2.6175922517329346

Epoch: 5| Step: 10
Training loss: 2.2245917985203363
Validation loss: 2.670581578923087

Epoch: 5| Step: 11
Training loss: 2.2323133654184355
Validation loss: 2.592367815089136

Epoch: 89| Step: 0
Training loss: 2.2361411203880954
Validation loss: 2.5871504890039145

Epoch: 5| Step: 1
Training loss: 1.5317765712360345
Validation loss: 2.616224060367424

Epoch: 5| Step: 2
Training loss: 2.123516237933808
Validation loss: 2.5765047935561176

Epoch: 5| Step: 3
Training loss: 2.6587919750406437
Validation loss: 2.5341130967600214

Epoch: 5| Step: 4
Training loss: 2.2944859127128447
Validation loss: 2.4986603684194155

Epoch: 5| Step: 5
Training loss: 2.666413374633391
Validation loss: 2.5591058272029543

Epoch: 5| Step: 6
Training loss: 2.6456191108866967
Validation loss: 2.618371583672156

Epoch: 5| Step: 7
Training loss: 1.7025265123316762
Validation loss: 2.580613039690694

Epoch: 5| Step: 8
Training loss: 2.8257988062010786
Validation loss: 2.587091313365839

Epoch: 5| Step: 9
Training loss: 2.4753687535710727
Validation loss: 2.5760602061623508

Epoch: 5| Step: 10
Training loss: 2.8903600622885812
Validation loss: 2.546397802195288

Epoch: 5| Step: 11
Training loss: 1.5990801670573835
Validation loss: 2.559646894446234

Epoch: 90| Step: 0
Training loss: 1.9606881762058328
Validation loss: 2.568715234043208

Epoch: 5| Step: 1
Training loss: 2.181411334960117
Validation loss: 2.550269374924517

Epoch: 5| Step: 2
Training loss: 2.4261368200680566
Validation loss: 2.611210776911438

Epoch: 5| Step: 3
Training loss: 3.0612935395141054
Validation loss: 2.6202485284671657

Epoch: 5| Step: 4
Training loss: 1.897740491219856
Validation loss: 2.566379823747017

Epoch: 5| Step: 5
Training loss: 2.0158148387845336
Validation loss: 2.548364075258429

Epoch: 5| Step: 6
Training loss: 2.6539660339539206
Validation loss: 2.58490358333949

Epoch: 5| Step: 7
Training loss: 2.402182671333781
Validation loss: 2.6037270454631676

Epoch: 5| Step: 8
Training loss: 2.537960999053146
Validation loss: 2.6189487092065824

Epoch: 5| Step: 9
Training loss: 2.6641851044574563
Validation loss: 2.6013660051221077

Epoch: 5| Step: 10
Training loss: 1.9084793562458444
Validation loss: 2.653333064631188

Epoch: 5| Step: 11
Training loss: 2.979440814300222
Validation loss: 2.6296611947013053

Epoch: 91| Step: 0
Training loss: 1.8920723285479626
Validation loss: 2.61111121749765

Epoch: 5| Step: 1
Training loss: 2.468082482596491
Validation loss: 2.621427572551362

Epoch: 5| Step: 2
Training loss: 2.4191936785847457
Validation loss: 2.5715756312772227

Epoch: 5| Step: 3
Training loss: 1.7988510544565341
Validation loss: 2.593396292931865

Epoch: 5| Step: 4
Training loss: 2.0393676529476386
Validation loss: 2.6032879847457044

Epoch: 5| Step: 5
Training loss: 2.425440176114966
Validation loss: 2.619881498845542

Epoch: 5| Step: 6
Training loss: 2.176087390449102
Validation loss: 2.595494285125506

Epoch: 5| Step: 7
Training loss: 2.3875216617899735
Validation loss: 2.5661624655246835

Epoch: 5| Step: 8
Training loss: 2.2519773695369354
Validation loss: 2.57384064463345

Epoch: 5| Step: 9
Training loss: 3.294388543037624
Validation loss: 2.5943615893240426

Epoch: 5| Step: 10
Training loss: 2.1650593248657155
Validation loss: 2.5816331288117333

Epoch: 5| Step: 11
Training loss: 2.789899257085291
Validation loss: 2.5886508271337507

Epoch: 92| Step: 0
Training loss: 2.1992973462656793
Validation loss: 2.5679313931612073

Epoch: 5| Step: 1
Training loss: 2.25625609505377
Validation loss: 2.6127040512609154

Epoch: 5| Step: 2
Training loss: 2.503857211913768
Validation loss: 2.6003980006439558

Epoch: 5| Step: 3
Training loss: 2.552083312573076
Validation loss: 2.5818830785207103

Epoch: 5| Step: 4
Training loss: 2.526405691023753
Validation loss: 2.6676343835851224

Epoch: 5| Step: 5
Training loss: 2.08506888259794
Validation loss: 2.6248598742550397

Epoch: 5| Step: 6
Training loss: 2.3436277230472933
Validation loss: 2.5913669830466173

Epoch: 5| Step: 7
Training loss: 1.9601911363047682
Validation loss: 2.672210702014323

Epoch: 5| Step: 8
Training loss: 3.089229170567657
Validation loss: 2.577425482283562

Epoch: 5| Step: 9
Training loss: 2.8518265275349157
Validation loss: 2.661441785508363

Epoch: 5| Step: 10
Training loss: 1.6787267021783772
Validation loss: 2.617304354284202

Epoch: 5| Step: 11
Training loss: 2.0643311665726514
Validation loss: 2.6189401404303436

Epoch: 93| Step: 0
Training loss: 2.4837893389507983
Validation loss: 2.64031248105519

Epoch: 5| Step: 1
Training loss: 2.054573897205542
Validation loss: 2.589875245514118

Epoch: 5| Step: 2
Training loss: 2.321212131764487
Validation loss: 2.636062563024945

Epoch: 5| Step: 3
Training loss: 2.9164226066566
Validation loss: 2.6136498868351166

Epoch: 5| Step: 4
Training loss: 1.9316899955773628
Validation loss: 2.5775376855048213

Epoch: 5| Step: 5
Training loss: 1.4882220559350698
Validation loss: 2.703742131400919

Epoch: 5| Step: 6
Training loss: 2.0468544995395144
Validation loss: 2.5853744308706395

Epoch: 5| Step: 7
Training loss: 2.6316917139286367
Validation loss: 2.56704907081804

Epoch: 5| Step: 8
Training loss: 2.481692899672502
Validation loss: 2.572123638261414

Epoch: 5| Step: 9
Training loss: 2.8871468728538368
Validation loss: 2.5726628268401375

Epoch: 5| Step: 10
Training loss: 2.4156222443361344
Validation loss: 2.5859885004244694

Epoch: 5| Step: 11
Training loss: 0.9183751931201322
Validation loss: 2.6158394734342063

Epoch: 94| Step: 0
Training loss: 2.5226097993422503
Validation loss: 2.6503127294425686

Epoch: 5| Step: 1
Training loss: 2.2155741138291063
Validation loss: 2.557746793617235

Epoch: 5| Step: 2
Training loss: 2.8739197401548227
Validation loss: 2.5463668612775385

Epoch: 5| Step: 3
Training loss: 1.9815750192422101
Validation loss: 2.5450895639184683

Epoch: 5| Step: 4
Training loss: 2.7939705712551
Validation loss: 2.6068498667430124

Epoch: 5| Step: 5
Training loss: 2.2159336106515433
Validation loss: 2.5487785129907294

Epoch: 5| Step: 6
Training loss: 2.5771277146050124
Validation loss: 2.58584804706729

Epoch: 5| Step: 7
Training loss: 1.9209991568305862
Validation loss: 2.6215801896223625

Epoch: 5| Step: 8
Training loss: 2.4344022580384843
Validation loss: 2.534411557565376

Epoch: 5| Step: 9
Training loss: 2.102070346435515
Validation loss: 2.5870233351642122

Epoch: 5| Step: 10
Training loss: 2.5388440786460813
Validation loss: 2.580209059260213

Epoch: 5| Step: 11
Training loss: 3.0212160766868776
Validation loss: 2.519541290420911

Epoch: 95| Step: 0
Training loss: 2.1376474653093767
Validation loss: 2.6067773639141114

Epoch: 5| Step: 1
Training loss: 2.025609798215457
Validation loss: 2.5424905455284414

Epoch: 5| Step: 2
Training loss: 1.749391722549807
Validation loss: 2.5380920472706956

Epoch: 5| Step: 3
Training loss: 2.8322147704546428
Validation loss: 2.5963153485476695

Epoch: 5| Step: 4
Training loss: 2.722394933433425
Validation loss: 2.6028651850847417

Epoch: 5| Step: 5
Training loss: 1.9909555253599167
Validation loss: 2.5544867091544647

Epoch: 5| Step: 6
Training loss: 2.706953303548392
Validation loss: 2.619411222213048

Epoch: 5| Step: 7
Training loss: 2.2577079563950755
Validation loss: 2.588371821357047

Epoch: 5| Step: 8
Training loss: 2.8514345741318
Validation loss: 2.5541421967392677

Epoch: 5| Step: 9
Training loss: 2.714451867231055
Validation loss: 2.5394851587099323

Epoch: 5| Step: 10
Training loss: 1.8657404827113886
Validation loss: 2.5994290605313437

Epoch: 5| Step: 11
Training loss: 1.417306961021159
Validation loss: 2.547966087597085

Epoch: 96| Step: 0
Training loss: 2.526483545620815
Validation loss: 2.57032311890485

Epoch: 5| Step: 1
Training loss: 1.9611026648764895
Validation loss: 2.657590647443655

Epoch: 5| Step: 2
Training loss: 2.6111110006381972
Validation loss: 2.599976746519347

Epoch: 5| Step: 3
Training loss: 2.0342586829806644
Validation loss: 2.605559797855151

Epoch: 5| Step: 4
Training loss: 2.0804198937977105
Validation loss: 2.5851955059994802

Epoch: 5| Step: 5
Training loss: 2.437803005067496
Validation loss: 2.5674390877367044

Epoch: 5| Step: 6
Training loss: 2.3646732486876663
Validation loss: 2.587066983802935

Epoch: 5| Step: 7
Training loss: 2.8486607667573374
Validation loss: 2.545715329348429

Epoch: 5| Step: 8
Training loss: 2.2278174360597562
Validation loss: 2.6154601550673653

Epoch: 5| Step: 9
Training loss: 2.3744094515974807
Validation loss: 2.5001420457540293

Epoch: 5| Step: 10
Training loss: 2.453163584023048
Validation loss: 2.589367549915294

Epoch: 5| Step: 11
Training loss: 1.883412499015809
Validation loss: 2.534162382386498

Epoch: 97| Step: 0
Training loss: 2.405627281562514
Validation loss: 2.5924841691296803

Epoch: 5| Step: 1
Training loss: 2.502924448425311
Validation loss: 2.567337331735388

Epoch: 5| Step: 2
Training loss: 2.2251444266089333
Validation loss: 2.5941300209509173

Epoch: 5| Step: 3
Training loss: 2.664235934432018
Validation loss: 2.6554164738048716

Epoch: 5| Step: 4
Training loss: 2.450019474341398
Validation loss: 2.629143521397958

Epoch: 5| Step: 5
Training loss: 2.6638343690984225
Validation loss: 2.5173419992591044

Epoch: 5| Step: 6
Training loss: 2.1724752790407567
Validation loss: 2.5643084742629854

Epoch: 5| Step: 7
Training loss: 1.7639961493746366
Validation loss: 2.5823155283674994

Epoch: 5| Step: 8
Training loss: 2.1629148669655778
Validation loss: 2.5890653503930245

Epoch: 5| Step: 9
Training loss: 2.5102114982710613
Validation loss: 2.6474797327792596

Epoch: 5| Step: 10
Training loss: 2.1886654610159453
Validation loss: 2.5461619613513924

Epoch: 5| Step: 11
Training loss: 2.251231810026588
Validation loss: 2.5919949557194957

Epoch: 98| Step: 0
Training loss: 2.7330348627216687
Validation loss: 2.583736581759836

Epoch: 5| Step: 1
Training loss: 2.3569818953675337
Validation loss: 2.564754928335248

Epoch: 5| Step: 2
Training loss: 2.338336032132662
Validation loss: 2.6235391169625286

Epoch: 5| Step: 3
Training loss: 2.2268773977227676
Validation loss: 2.555162220437851

Epoch: 5| Step: 4
Training loss: 2.162220305067003
Validation loss: 2.5881385885958346

Epoch: 5| Step: 5
Training loss: 2.458207423547211
Validation loss: 2.6242483913590773

Epoch: 5| Step: 6
Training loss: 2.368914889834487
Validation loss: 2.582353653547851

Epoch: 5| Step: 7
Training loss: 2.6277325349622385
Validation loss: 2.5654209206030414

Epoch: 5| Step: 8
Training loss: 2.5010246084559125
Validation loss: 2.587788629021375

Epoch: 5| Step: 9
Training loss: 1.9152266718324207
Validation loss: 2.599575467632525

Epoch: 5| Step: 10
Training loss: 2.2083496477016284
Validation loss: 2.5743577733412377

Epoch: 5| Step: 11
Training loss: 1.451143944780848
Validation loss: 2.5572924811419546

Epoch: 99| Step: 0
Training loss: 2.0548463477169845
Validation loss: 2.5136193243035345

Epoch: 5| Step: 1
Training loss: 2.8116828579107636
Validation loss: 2.58032088349317

Epoch: 5| Step: 2
Training loss: 2.288777512656354
Validation loss: 2.638168554259044

Epoch: 5| Step: 3
Training loss: 2.570816129836067
Validation loss: 2.5382371235842767

Epoch: 5| Step: 4
Training loss: 2.8893964476452587
Validation loss: 2.6267606567818214

Epoch: 5| Step: 5
Training loss: 1.717808205326979
Validation loss: 2.5987399639567657

Epoch: 5| Step: 6
Training loss: 2.6858304182702164
Validation loss: 2.630797376234919

Epoch: 5| Step: 7
Training loss: 2.1720612809684883
Validation loss: 2.549615210831399

Epoch: 5| Step: 8
Training loss: 2.3347344506033196
Validation loss: 2.5927318543322184

Epoch: 5| Step: 9
Training loss: 2.231054225849116
Validation loss: 2.6014657293732735

Epoch: 5| Step: 10
Training loss: 1.9636509575686816
Validation loss: 2.506683380632613

Epoch: 5| Step: 11
Training loss: 2.7588595815102157
Validation loss: 2.636426292495027

Epoch: 100| Step: 0
Training loss: 1.9334172948604949
Validation loss: 2.5274265949835297

Epoch: 5| Step: 1
Training loss: 2.5675668632321864
Validation loss: 2.5894902612825033

Epoch: 5| Step: 2
Training loss: 2.3208157285870694
Validation loss: 2.5246677175323575

Epoch: 5| Step: 3
Training loss: 1.9142249213612665
Validation loss: 2.610186585782212

Epoch: 5| Step: 4
Training loss: 2.835617341604437
Validation loss: 2.600070235177932

Epoch: 5| Step: 5
Training loss: 2.394275645417932
Validation loss: 2.597650437121472

Epoch: 5| Step: 6
Training loss: 2.524043054821041
Validation loss: 2.5903010782063713

Epoch: 5| Step: 7
Training loss: 2.0485779179471986
Validation loss: 2.6023719070699345

Epoch: 5| Step: 8
Training loss: 2.5335366552308725
Validation loss: 2.5739315916674297

Epoch: 5| Step: 9
Training loss: 2.3984305415844704
Validation loss: 2.5720259338253517

Epoch: 5| Step: 10
Training loss: 2.401360436143417
Validation loss: 2.581527110566313

Epoch: 5| Step: 11
Training loss: 1.2818064993006844
Validation loss: 2.593911713610739

Epoch: 101| Step: 0
Training loss: 2.2708816056559926
Validation loss: 2.580790850341318

Epoch: 5| Step: 1
Training loss: 1.8517650380801836
Validation loss: 2.571560117249392

Epoch: 5| Step: 2
Training loss: 2.1016396433912803
Validation loss: 2.5427425848437974

Epoch: 5| Step: 3
Training loss: 2.7502325999986725
Validation loss: 2.6029909353549034

Epoch: 5| Step: 4
Training loss: 2.3046299814061886
Validation loss: 2.596179873407574

Epoch: 5| Step: 5
Training loss: 2.3945800378008
Validation loss: 2.580064941495778

Epoch: 5| Step: 6
Training loss: 2.4098836042859113
Validation loss: 2.5379879991168983

Epoch: 5| Step: 7
Training loss: 2.8980594193058136
Validation loss: 2.6595761884589075

Epoch: 5| Step: 8
Training loss: 1.661211033257178
Validation loss: 2.6006955983038123

Epoch: 5| Step: 9
Training loss: 2.394986132778725
Validation loss: 2.5760686669102513

Epoch: 5| Step: 10
Training loss: 2.366046492041617
Validation loss: 2.624583676793335

Epoch: 5| Step: 11
Training loss: 1.9175885789049687
Validation loss: 2.565114253971514

Epoch: 102| Step: 0
Training loss: 3.0763183558874427
Validation loss: 2.5488938012558937

Epoch: 5| Step: 1
Training loss: 2.194813193016661
Validation loss: 2.587673703105188

Epoch: 5| Step: 2
Training loss: 2.0107775217724684
Validation loss: 2.5701249236793373

Epoch: 5| Step: 3
Training loss: 2.347037590886317
Validation loss: 2.6071513289203847

Epoch: 5| Step: 4
Training loss: 2.4195034105561057
Validation loss: 2.6374518272556577

Epoch: 5| Step: 5
Training loss: 2.1487534169363536
Validation loss: 2.5891224972563287

Epoch: 5| Step: 6
Training loss: 2.5810562578327136
Validation loss: 2.6093473033234615

Epoch: 5| Step: 7
Training loss: 2.572842914795827
Validation loss: 2.6116120082606518

Epoch: 5| Step: 8
Training loss: 2.1377227488674464
Validation loss: 2.529679874992228

Epoch: 5| Step: 9
Training loss: 2.2214144973939867
Validation loss: 2.572932943429054

Epoch: 5| Step: 10
Training loss: 2.125783887901478
Validation loss: 2.5988922754173194

Epoch: 5| Step: 11
Training loss: 1.9636888389848732
Validation loss: 2.6342826232762975

Epoch: 103| Step: 0
Training loss: 2.803548597567397
Validation loss: 2.6000060503229023

Epoch: 5| Step: 1
Training loss: 2.40122768870309
Validation loss: 2.637278680570282

Epoch: 5| Step: 2
Training loss: 2.0105593405056057
Validation loss: 2.5847378816960993

Epoch: 5| Step: 3
Training loss: 2.3876030465302
Validation loss: 2.633032249086577

Epoch: 5| Step: 4
Training loss: 1.8027761667352475
Validation loss: 2.585366465511252

Epoch: 5| Step: 5
Training loss: 1.9316837626115675
Validation loss: 2.6351183180873816

Epoch: 5| Step: 6
Training loss: 2.713579369183604
Validation loss: 2.6371979190918786

Epoch: 5| Step: 7
Training loss: 2.5169463863247663
Validation loss: 2.5582187678709793

Epoch: 5| Step: 8
Training loss: 2.254965283788491
Validation loss: 2.5944061445172464

Epoch: 5| Step: 9
Training loss: 2.226395771409685
Validation loss: 2.6128312784569587

Epoch: 5| Step: 10
Training loss: 2.3910140176040686
Validation loss: 2.578297464786608

Epoch: 5| Step: 11
Training loss: 2.1222525394176004
Validation loss: 2.6218682863060856

Epoch: 104| Step: 0
Training loss: 2.6962801315894738
Validation loss: 2.6134767254915188

Epoch: 5| Step: 1
Training loss: 1.7316247252206123
Validation loss: 2.6275605285368067

Epoch: 5| Step: 2
Training loss: 2.1554319516145184
Validation loss: 2.6084083776880864

Epoch: 5| Step: 3
Training loss: 2.8183623358168353
Validation loss: 2.6114701446663746

Epoch: 5| Step: 4
Training loss: 1.679151014660504
Validation loss: 2.5719607439731007

Epoch: 5| Step: 5
Training loss: 2.2292840754407393
Validation loss: 2.59203057959065

Epoch: 5| Step: 6
Training loss: 2.2721296920631384
Validation loss: 2.6137848631572287

Epoch: 5| Step: 7
Training loss: 2.6276398962872647
Validation loss: 2.6392166700967183

Epoch: 5| Step: 8
Training loss: 2.3865181546738525
Validation loss: 2.611983459306855

Epoch: 5| Step: 9
Training loss: 2.7081039527200192
Validation loss: 2.660768473004216

Epoch: 5| Step: 10
Training loss: 2.104313407791931
Validation loss: 2.6388590247711936

Epoch: 5| Step: 11
Training loss: 1.8890375455938746
Validation loss: 2.5810909607871793

Epoch: 105| Step: 0
Training loss: 2.5575018729671957
Validation loss: 2.594631604424122

Epoch: 5| Step: 1
Training loss: 1.9716807153329725
Validation loss: 2.5596864808098054

Epoch: 5| Step: 2
Training loss: 1.8717558451892822
Validation loss: 2.61634051154068

Epoch: 5| Step: 3
Training loss: 2.612937186133256
Validation loss: 2.6515752084337967

Epoch: 5| Step: 4
Training loss: 2.182727949161056
Validation loss: 2.648963182129637

Epoch: 5| Step: 5
Training loss: 2.297957288625683
Validation loss: 2.585147441173835

Epoch: 5| Step: 6
Training loss: 2.282581724477452
Validation loss: 2.512591102238977

Epoch: 5| Step: 7
Training loss: 2.2143896535571064
Validation loss: 2.5651387239765104

Epoch: 5| Step: 8
Training loss: 2.417583971113569
Validation loss: 2.612912964161013

Epoch: 5| Step: 9
Training loss: 2.559706211666715
Validation loss: 2.6175744752754575

Epoch: 5| Step: 10
Training loss: 2.4227350492188324
Validation loss: 2.654561426088989

Epoch: 5| Step: 11
Training loss: 2.563414805803729
Validation loss: 2.566054302142243

Epoch: 106| Step: 0
Training loss: 1.9101352807514667
Validation loss: 2.5719959655471016

Epoch: 5| Step: 1
Training loss: 2.5462756241495508
Validation loss: 2.570631320508759

Epoch: 5| Step: 2
Training loss: 1.719333133610722
Validation loss: 2.5404119006504247

Epoch: 5| Step: 3
Training loss: 2.375085226838674
Validation loss: 2.592301918158101

Epoch: 5| Step: 4
Training loss: 2.561253965792697
Validation loss: 2.573620046901567

Epoch: 5| Step: 5
Training loss: 2.202112925850035
Validation loss: 2.456989811566543

Epoch: 5| Step: 6
Training loss: 2.558232638668936
Validation loss: 2.557848810751074

Epoch: 5| Step: 7
Training loss: 1.8979493443690465
Validation loss: 2.5940621391210046

Epoch: 5| Step: 8
Training loss: 2.494264699647321
Validation loss: 2.588699820821294

Epoch: 5| Step: 9
Training loss: 2.586441682374544
Validation loss: 2.5877047221270653

Epoch: 5| Step: 10
Training loss: 2.503551821090634
Validation loss: 2.518101754395664

Epoch: 5| Step: 11
Training loss: 2.4532842888110817
Validation loss: 2.5509140385116598

Epoch: 107| Step: 0
Training loss: 1.8977759193577082
Validation loss: 2.5774925689269477

Epoch: 5| Step: 1
Training loss: 2.3493064628035767
Validation loss: 2.608300221835276

Epoch: 5| Step: 2
Training loss: 1.9592491876099862
Validation loss: 2.5776526278456293

Epoch: 5| Step: 3
Training loss: 1.861652101899732
Validation loss: 2.5826354635173248

Epoch: 5| Step: 4
Training loss: 2.1609266125011
Validation loss: 2.5364027049853086

Epoch: 5| Step: 5
Training loss: 3.1727813778690974
Validation loss: 2.5577276651943888

Epoch: 5| Step: 6
Training loss: 2.163669261252427
Validation loss: 2.6014995128196854

Epoch: 5| Step: 7
Training loss: 2.587526691686095
Validation loss: 2.5472074537416467

Epoch: 5| Step: 8
Training loss: 2.1044072180497486
Validation loss: 2.612934501995456

Epoch: 5| Step: 9
Training loss: 2.0894314082841574
Validation loss: 2.59508189892265

Epoch: 5| Step: 10
Training loss: 2.5544827347099357
Validation loss: 2.614510181183822

Epoch: 5| Step: 11
Training loss: 1.9485711682806492
Validation loss: 2.55102226361058

Epoch: 108| Step: 0
Training loss: 1.955640287110953
Validation loss: 2.6197831752227425

Epoch: 5| Step: 1
Training loss: 2.56709714557548
Validation loss: 2.5512873413827113

Epoch: 5| Step: 2
Training loss: 2.540533396816136
Validation loss: 2.5199511905010237

Epoch: 5| Step: 3
Training loss: 1.9633568053577661
Validation loss: 2.589402321795573

Epoch: 5| Step: 4
Training loss: 1.9482964606123083
Validation loss: 2.566916072068861

Epoch: 5| Step: 5
Training loss: 2.0741343795370253
Validation loss: 2.5558912142018544

Epoch: 5| Step: 6
Training loss: 2.504207598901252
Validation loss: 2.5559148455261522

Epoch: 5| Step: 7
Training loss: 2.4866356311153375
Validation loss: 2.5917289627250226

Epoch: 5| Step: 8
Training loss: 1.9156034533734199
Validation loss: 2.622940477915077

Epoch: 5| Step: 9
Training loss: 2.3159728907314583
Validation loss: 2.628530058790678

Epoch: 5| Step: 10
Training loss: 2.6536750429971043
Validation loss: 2.6062671023508286

Epoch: 5| Step: 11
Training loss: 3.958335729230189
Validation loss: 2.5824645617116295

Epoch: 109| Step: 0
Training loss: 2.1268896788775207
Validation loss: 2.584095866709512

Epoch: 5| Step: 1
Training loss: 2.118787998095039
Validation loss: 2.478684576161536

Epoch: 5| Step: 2
Training loss: 3.00686067655867
Validation loss: 2.516881202612434

Epoch: 5| Step: 3
Training loss: 2.5569511440653705
Validation loss: 2.583399876896268

Epoch: 5| Step: 4
Training loss: 2.782854538888628
Validation loss: 2.5403827227960436

Epoch: 5| Step: 5
Training loss: 2.2009474361508996
Validation loss: 2.5451503445198504

Epoch: 5| Step: 6
Training loss: 1.8954441663226285
Validation loss: 2.627436748170389

Epoch: 5| Step: 7
Training loss: 2.1327198273922665
Validation loss: 2.505425942712163

Epoch: 5| Step: 8
Training loss: 2.2495424017232657
Validation loss: 2.5392870133736247

Epoch: 5| Step: 9
Training loss: 2.378741379209564
Validation loss: 2.5729343063635275

Epoch: 5| Step: 10
Training loss: 1.7544441332919813
Validation loss: 2.556648794481219

Epoch: 5| Step: 11
Training loss: 1.3581685818571179
Validation loss: 2.595564494797567

Epoch: 110| Step: 0
Training loss: 2.220136182577423
Validation loss: 2.5707246050004637

Epoch: 5| Step: 1
Training loss: 2.055820399340191
Validation loss: 2.615755625128869

Epoch: 5| Step: 2
Training loss: 2.6361853844224385
Validation loss: 2.6471550723858335

Epoch: 5| Step: 3
Training loss: 1.6733352131218755
Validation loss: 2.662886802950763

Epoch: 5| Step: 4
Training loss: 2.2697982762313296
Validation loss: 2.6573572917587285

Epoch: 5| Step: 5
Training loss: 2.3145621101054177
Validation loss: 2.5567135723947247

Epoch: 5| Step: 6
Training loss: 2.1899255656304186
Validation loss: 2.6549589572519157

Epoch: 5| Step: 7
Training loss: 3.014065828613215
Validation loss: 2.629352465582055

Epoch: 5| Step: 8
Training loss: 1.6725528091737785
Validation loss: 2.6480939936793995

Epoch: 5| Step: 9
Training loss: 2.387058165245484
Validation loss: 2.730361470674035

Epoch: 5| Step: 10
Training loss: 2.1140853846764074
Validation loss: 2.5894742944787863

Epoch: 5| Step: 11
Training loss: 3.428824835449788
Validation loss: 2.6439275761600456

Epoch: 111| Step: 0
Training loss: 2.4407970919728967
Validation loss: 2.5365259068839983

Epoch: 5| Step: 1
Training loss: 1.6105469075678736
Validation loss: 2.521673107298673

Epoch: 5| Step: 2
Training loss: 2.8937819279336767
Validation loss: 2.5311303247802726

Epoch: 5| Step: 3
Training loss: 2.1555557238959984
Validation loss: 2.5323357980874412

Epoch: 5| Step: 4
Training loss: 2.1121985858118935
Validation loss: 2.57997593952882

Epoch: 5| Step: 5
Training loss: 2.1942881301812656
Validation loss: 2.5867006380166586

Epoch: 5| Step: 6
Training loss: 1.7091076964433787
Validation loss: 2.5957845766459546

Epoch: 5| Step: 7
Training loss: 2.381914513649827
Validation loss: 2.567823141805686

Epoch: 5| Step: 8
Training loss: 2.6940433776127257
Validation loss: 2.5900056154541256

Epoch: 5| Step: 9
Training loss: 2.6312602643245464
Validation loss: 2.5188474648914987

Epoch: 5| Step: 10
Training loss: 2.5945393843323723
Validation loss: 2.567552961609895

Epoch: 5| Step: 11
Training loss: 1.146007016052286
Validation loss: 2.5643418116741965

Epoch: 112| Step: 0
Training loss: 2.648134737516808
Validation loss: 2.628109305263471

Epoch: 5| Step: 1
Training loss: 1.9062396815286498
Validation loss: 2.539065524368441

Epoch: 5| Step: 2
Training loss: 2.7567866419277585
Validation loss: 2.600560053392042

Epoch: 5| Step: 3
Training loss: 1.7711142896782976
Validation loss: 2.5991019602340115

Epoch: 5| Step: 4
Training loss: 2.560095147063449
Validation loss: 2.6536774276235215

Epoch: 5| Step: 5
Training loss: 2.283962674899853
Validation loss: 2.6961973976765883

Epoch: 5| Step: 6
Training loss: 1.8239444632650066
Validation loss: 2.6568542279424774

Epoch: 5| Step: 7
Training loss: 2.4523078869654897
Validation loss: 2.6108196812575235

Epoch: 5| Step: 8
Training loss: 2.1343704514015176
Validation loss: 2.62790525215476

Epoch: 5| Step: 9
Training loss: 2.044853435198144
Validation loss: 2.5842410205459827

Epoch: 5| Step: 10
Training loss: 2.5055566071110804
Validation loss: 2.598679710441893

Epoch: 5| Step: 11
Training loss: 1.3615916802915298
Validation loss: 2.655731700370574

Epoch: 113| Step: 0
Training loss: 2.041521832784992
Validation loss: 2.6322970201694247

Epoch: 5| Step: 1
Training loss: 2.0639844234233644
Validation loss: 2.6341743682447847

Epoch: 5| Step: 2
Training loss: 2.2296764349445684
Validation loss: 2.5524873932661936

Epoch: 5| Step: 3
Training loss: 1.8974633877002645
Validation loss: 2.550409458359822

Epoch: 5| Step: 4
Training loss: 2.038692630823699
Validation loss: 2.6345312241901033

Epoch: 5| Step: 5
Training loss: 2.607506179875396
Validation loss: 2.6047687533862582

Epoch: 5| Step: 6
Training loss: 2.040710601646905
Validation loss: 2.570891263938694

Epoch: 5| Step: 7
Training loss: 2.6402296865133508
Validation loss: 2.634291918987955

Epoch: 5| Step: 8
Training loss: 2.312222232116931
Validation loss: 2.6193081097931703

Epoch: 5| Step: 9
Training loss: 2.5862459765145305
Validation loss: 2.591999945773754

Epoch: 5| Step: 10
Training loss: 2.630577610392922
Validation loss: 2.5623479774784963

Epoch: 5| Step: 11
Training loss: 2.4848677428451547
Validation loss: 2.5857565010704833

Epoch: 114| Step: 0
Training loss: 2.308533953361844
Validation loss: 2.620973253583516

Epoch: 5| Step: 1
Training loss: 2.619118231692581
Validation loss: 2.532887419765887

Epoch: 5| Step: 2
Training loss: 2.2491863686979063
Validation loss: 2.6010085194810073

Epoch: 5| Step: 3
Training loss: 3.0185949692495857
Validation loss: 2.5400558054605757

Epoch: 5| Step: 4
Training loss: 2.0052452447309563
Validation loss: 2.5480939097500355

Epoch: 5| Step: 5
Training loss: 2.253572383066001
Validation loss: 2.6074476452719564

Epoch: 5| Step: 6
Training loss: 2.2255219822356973
Validation loss: 2.522081678162977

Epoch: 5| Step: 7
Training loss: 1.598656450864674
Validation loss: 2.583432631481298

Epoch: 5| Step: 8
Training loss: 1.7910553606423962
Validation loss: 2.563191308998853

Epoch: 5| Step: 9
Training loss: 2.432119054339738
Validation loss: 2.5472895825043356

Epoch: 5| Step: 10
Training loss: 2.1451126172217543
Validation loss: 2.5981834737049065

Epoch: 5| Step: 11
Training loss: 3.3966215346173425
Validation loss: 2.6128706027337048

Epoch: 115| Step: 0
Training loss: 2.718588637901826
Validation loss: 2.5701752831840046

Epoch: 5| Step: 1
Training loss: 2.5731461045569737
Validation loss: 2.54700455989387

Epoch: 5| Step: 2
Training loss: 2.577897310317365
Validation loss: 2.4765749990185957

Epoch: 5| Step: 3
Training loss: 2.2171152029152763
Validation loss: 2.5880929198461287

Epoch: 5| Step: 4
Training loss: 2.049140433626654
Validation loss: 2.6203470810526848

Epoch: 5| Step: 5
Training loss: 2.796920946479051
Validation loss: 2.5836053187231736

Epoch: 5| Step: 6
Training loss: 1.9047747672589024
Validation loss: 2.6264945914593274

Epoch: 5| Step: 7
Training loss: 1.8813707838857125
Validation loss: 2.5595638969308965

Epoch: 5| Step: 8
Training loss: 2.2016873911080252
Validation loss: 2.6226632639427816

Epoch: 5| Step: 9
Training loss: 2.0875931359261006
Validation loss: 2.5695875821037997

Epoch: 5| Step: 10
Training loss: 2.2892605952973444
Validation loss: 2.566725298337772

Epoch: 5| Step: 11
Training loss: 2.14970277461689
Validation loss: 2.4912012235361622

Epoch: 116| Step: 0
Training loss: 2.262570130330887
Validation loss: 2.6107657185235076

Epoch: 5| Step: 1
Training loss: 2.0535250664447333
Validation loss: 2.681147634483217

Epoch: 5| Step: 2
Training loss: 2.2176439994151655
Validation loss: 2.7388621760229124

Epoch: 5| Step: 3
Training loss: 2.4457801639771612
Validation loss: 2.633265485573572

Epoch: 5| Step: 4
Training loss: 2.6938902709975574
Validation loss: 2.73387883362289

Epoch: 5| Step: 5
Training loss: 2.0088002191140113
Validation loss: 2.756619192556056

Epoch: 5| Step: 6
Training loss: 2.390158414498697
Validation loss: 2.7148309098998946

Epoch: 5| Step: 7
Training loss: 2.9288563274077957
Validation loss: 2.6633066688101183

Epoch: 5| Step: 8
Training loss: 2.039773984992228
Validation loss: 2.690053670999492

Epoch: 5| Step: 9
Training loss: 2.168787456265953
Validation loss: 2.5949552370876763

Epoch: 5| Step: 10
Training loss: 1.9034952364181341
Validation loss: 2.5756107940751067

Epoch: 5| Step: 11
Training loss: 1.9473159462138294
Validation loss: 2.596675356808356

Epoch: 117| Step: 0
Training loss: 2.4886051847437445
Validation loss: 2.6083110421927356

Epoch: 5| Step: 1
Training loss: 1.9651959143468998
Validation loss: 2.5835207722456768

Epoch: 5| Step: 2
Training loss: 2.297212329409095
Validation loss: 2.578773062586378

Epoch: 5| Step: 3
Training loss: 2.6655348124122558
Validation loss: 2.574482442637793

Epoch: 5| Step: 4
Training loss: 1.5529833324149578
Validation loss: 2.6261751254249472

Epoch: 5| Step: 5
Training loss: 2.0842188923955316
Validation loss: 2.611027048045131

Epoch: 5| Step: 6
Training loss: 1.8664471423402664
Validation loss: 2.5519293615384204

Epoch: 5| Step: 7
Training loss: 2.238611113789199
Validation loss: 2.6039719616899837

Epoch: 5| Step: 8
Training loss: 2.570431042752253
Validation loss: 2.586715231704585

Epoch: 5| Step: 9
Training loss: 2.3357939915287513
Validation loss: 2.5383787261477937

Epoch: 5| Step: 10
Training loss: 2.553663882812183
Validation loss: 2.591308643587135

Epoch: 5| Step: 11
Training loss: 2.7347530430631153
Validation loss: 2.58221761133866

Epoch: 118| Step: 0
Training loss: 1.7149721414733428
Validation loss: 2.573518512132414

Epoch: 5| Step: 1
Training loss: 2.1662717483758307
Validation loss: 2.54990574453722

Epoch: 5| Step: 2
Training loss: 2.9920418407554155
Validation loss: 2.556197250151498

Epoch: 5| Step: 3
Training loss: 2.143442791427397
Validation loss: 2.585989462723202

Epoch: 5| Step: 4
Training loss: 2.113519284985441
Validation loss: 2.6183108903160597

Epoch: 5| Step: 5
Training loss: 2.4214238884933206
Validation loss: 2.565220660099462

Epoch: 5| Step: 6
Training loss: 2.0091261073284885
Validation loss: 2.5443140466795264

Epoch: 5| Step: 7
Training loss: 2.557975403125367
Validation loss: 2.6186520137071803

Epoch: 5| Step: 8
Training loss: 1.9389489201333991
Validation loss: 2.5237939698947316

Epoch: 5| Step: 9
Training loss: 1.7029467148164175
Validation loss: 2.6251995071405245

Epoch: 5| Step: 10
Training loss: 1.6792604125226664
Validation loss: 2.6080673428477645

Epoch: 5| Step: 11
Training loss: 3.6260488900004284
Validation loss: 2.594963287860687

Epoch: 119| Step: 0
Training loss: 2.0730840593032536
Validation loss: 2.5923228071607376

Epoch: 5| Step: 1
Training loss: 2.1918909961300574
Validation loss: 2.636789962372045

Epoch: 5| Step: 2
Training loss: 2.1725714136464647
Validation loss: 2.6057707970360307

Epoch: 5| Step: 3
Training loss: 3.1972815828385364
Validation loss: 2.5774977874746363

Epoch: 5| Step: 4
Training loss: 2.0855913768020837
Validation loss: 2.565261705598692

Epoch: 5| Step: 5
Training loss: 1.8184195568971442
Validation loss: 2.5602902871382813

Epoch: 5| Step: 6
Training loss: 2.2259566704233698
Validation loss: 2.5769546048499983

Epoch: 5| Step: 7
Training loss: 2.491583484889983
Validation loss: 2.5700304017637494

Epoch: 5| Step: 8
Training loss: 1.951195458010947
Validation loss: 2.5597559883258003

Epoch: 5| Step: 9
Training loss: 1.8932908864479296
Validation loss: 2.582153548260173

Epoch: 5| Step: 10
Training loss: 2.2676242820385757
Validation loss: 2.590127153650656

Epoch: 5| Step: 11
Training loss: 2.187901487291149
Validation loss: 2.5357294086188267

Epoch: 120| Step: 0
Training loss: 2.1208992828527644
Validation loss: 2.5744816245972104

Epoch: 5| Step: 1
Training loss: 1.8025970241343034
Validation loss: 2.494336854628207

Epoch: 5| Step: 2
Training loss: 2.1910687354974323
Validation loss: 2.526109337965363

Epoch: 5| Step: 3
Training loss: 1.842293179937139
Validation loss: 2.6253401785636648

Epoch: 5| Step: 4
Training loss: 2.5571978539522147
Validation loss: 2.6504404564157484

Epoch: 5| Step: 5
Training loss: 1.6952099043921791
Validation loss: 2.6035666588343314

Epoch: 5| Step: 6
Training loss: 3.0388894313770702
Validation loss: 2.527275638753288

Epoch: 5| Step: 7
Training loss: 1.9112183907928177
Validation loss: 2.5697725882644766

Epoch: 5| Step: 8
Training loss: 2.4555621826960845
Validation loss: 2.608140954386983

Epoch: 5| Step: 9
Training loss: 2.1120316341733094
Validation loss: 2.5693345204601585

Epoch: 5| Step: 10
Training loss: 2.6724992881609806
Validation loss: 2.532069313040213

Epoch: 5| Step: 11
Training loss: 2.081857412785614
Validation loss: 2.582778507046665

Epoch: 121| Step: 0
Training loss: 2.461760077678918
Validation loss: 2.5553425912359264

Epoch: 5| Step: 1
Training loss: 1.9691808925356415
Validation loss: 2.5938190734428983

Epoch: 5| Step: 2
Training loss: 1.923387258138435
Validation loss: 2.643179476165986

Epoch: 5| Step: 3
Training loss: 2.579556431897829
Validation loss: 2.5296345999552625

Epoch: 5| Step: 4
Training loss: 1.7963252014261126
Validation loss: 2.5829786235311474

Epoch: 5| Step: 5
Training loss: 2.0561168036178366
Validation loss: 2.5786780948941246

Epoch: 5| Step: 6
Training loss: 2.490647752148176
Validation loss: 2.549225878707983

Epoch: 5| Step: 7
Training loss: 2.75560925360455
Validation loss: 2.6143686553442786

Epoch: 5| Step: 8
Training loss: 2.134760487542423
Validation loss: 2.5809834057051413

Epoch: 5| Step: 9
Training loss: 2.0300061452237026
Validation loss: 2.5938423132650796

Epoch: 5| Step: 10
Training loss: 2.4882104405459056
Validation loss: 2.56649186733272

Epoch: 5| Step: 11
Training loss: 1.6821422294011563
Validation loss: 2.5599606267439405

Epoch: 122| Step: 0
Training loss: 2.0616771328084007
Validation loss: 2.6352640090172907

Epoch: 5| Step: 1
Training loss: 2.1235821425554557
Validation loss: 2.6174383090721554

Epoch: 5| Step: 2
Training loss: 1.893918911794247
Validation loss: 2.570422082283011

Epoch: 5| Step: 3
Training loss: 2.394554050953077
Validation loss: 2.5955672045527765

Epoch: 5| Step: 4
Training loss: 2.304650878615294
Validation loss: 2.615198953249535

Epoch: 5| Step: 5
Training loss: 2.4658605349442233
Validation loss: 2.5642165273166633

Epoch: 5| Step: 6
Training loss: 2.541931503339474
Validation loss: 2.608344085709791

Epoch: 5| Step: 7
Training loss: 2.3799379113056545
Validation loss: 2.62037993298639

Epoch: 5| Step: 8
Training loss: 2.012894429477714
Validation loss: 2.602334256490315

Epoch: 5| Step: 9
Training loss: 1.8347367925816984
Validation loss: 2.566563377428216

Epoch: 5| Step: 10
Training loss: 2.025594261475279
Validation loss: 2.6159940930899155

Epoch: 5| Step: 11
Training loss: 2.9017834539719045
Validation loss: 2.578840614954335

Epoch: 123| Step: 0
Training loss: 2.1383568100546113
Validation loss: 2.5797157273730447

Epoch: 5| Step: 1
Training loss: 1.9148337542530949
Validation loss: 2.6573911721263674

Epoch: 5| Step: 2
Training loss: 2.1710069417328555
Validation loss: 2.5792460999918605

Epoch: 5| Step: 3
Training loss: 2.7929621769754385
Validation loss: 2.6448935894873165

Epoch: 5| Step: 4
Training loss: 2.6352182145217067
Validation loss: 2.672389122277914

Epoch: 5| Step: 5
Training loss: 2.047456032789783
Validation loss: 2.598902810038141

Epoch: 5| Step: 6
Training loss: 2.1993687851241583
Validation loss: 2.6053735238078257

Epoch: 5| Step: 7
Training loss: 1.7527266105818244
Validation loss: 2.613654366140348

Epoch: 5| Step: 8
Training loss: 2.609406887933197
Validation loss: 2.6216726521312324

Epoch: 5| Step: 9
Training loss: 2.0873135374932272
Validation loss: 2.638533495651788

Epoch: 5| Step: 10
Training loss: 1.9126909596968111
Validation loss: 2.6669231169789427

Epoch: 5| Step: 11
Training loss: 1.0972870446759573
Validation loss: 2.5681955766360467

Epoch: 124| Step: 0
Training loss: 1.8676371013151518
Validation loss: 2.6150749011676053

Epoch: 5| Step: 1
Training loss: 2.42096353422589
Validation loss: 2.561533889235323

Epoch: 5| Step: 2
Training loss: 2.842543629065716
Validation loss: 2.5980197317567355

Epoch: 5| Step: 3
Training loss: 2.412196354707077
Validation loss: 2.5900536323146963

Epoch: 5| Step: 4
Training loss: 1.8528413500818137
Validation loss: 2.6338548398647212

Epoch: 5| Step: 5
Training loss: 2.1459080457797772
Validation loss: 2.6152304434942617

Epoch: 5| Step: 6
Training loss: 2.328497632819003
Validation loss: 2.644877735543914

Epoch: 5| Step: 7
Training loss: 2.0351384431202746
Validation loss: 2.5922968980278123

Epoch: 5| Step: 8
Training loss: 2.292975404590003
Validation loss: 2.5885433194457725

Epoch: 5| Step: 9
Training loss: 2.3513043537580294
Validation loss: 2.590694868758442

Epoch: 5| Step: 10
Training loss: 1.748579947742934
Validation loss: 2.5813248245564364

Epoch: 5| Step: 11
Training loss: 0.8521026857847486
Validation loss: 2.603667437702938

Epoch: 125| Step: 0
Training loss: 2.354931113659027
Validation loss: 2.4806542595005707

Epoch: 5| Step: 1
Training loss: 2.3518851936437737
Validation loss: 2.5968350022927607

Epoch: 5| Step: 2
Training loss: 2.1527084900018454
Validation loss: 2.603318348359937

Epoch: 5| Step: 3
Training loss: 2.0006386214140854
Validation loss: 2.608756881111354

Epoch: 5| Step: 4
Training loss: 1.6315762891407735
Validation loss: 2.560994834327925

Epoch: 5| Step: 5
Training loss: 2.3646338257181014
Validation loss: 2.5665402776596085

Epoch: 5| Step: 6
Training loss: 2.1308216682545438
Validation loss: 2.5647242127518477

Epoch: 5| Step: 7
Training loss: 2.2479998917562654
Validation loss: 2.573417826478697

Epoch: 5| Step: 8
Training loss: 1.9541140074097718
Validation loss: 2.622341304440682

Epoch: 5| Step: 9
Training loss: 2.675542712194865
Validation loss: 2.558444906472292

Epoch: 5| Step: 10
Training loss: 2.4843373805622666
Validation loss: 2.5885134234253204

Epoch: 5| Step: 11
Training loss: 0.9184741637656472
Validation loss: 2.5480478936559376

Epoch: 126| Step: 0
Training loss: 2.3052923928121185
Validation loss: 2.5967559019000683

Epoch: 5| Step: 1
Training loss: 2.9043374280015946
Validation loss: 2.5706844543820853

Epoch: 5| Step: 2
Training loss: 1.7732261498166428
Validation loss: 2.6478675784211245

Epoch: 5| Step: 3
Training loss: 2.4930180328671767
Validation loss: 2.6352380508587663

Epoch: 5| Step: 4
Training loss: 1.81775528228668
Validation loss: 2.6224812427743323

Epoch: 5| Step: 5
Training loss: 1.7773421402808645
Validation loss: 2.6567883002170607

Epoch: 5| Step: 6
Training loss: 1.7217500340137835
Validation loss: 2.620538610121166

Epoch: 5| Step: 7
Training loss: 1.9395469189540053
Validation loss: 2.5864714679136145

Epoch: 5| Step: 8
Training loss: 2.3652945525800986
Validation loss: 2.639450067670142

Epoch: 5| Step: 9
Training loss: 2.4495597249131826
Validation loss: 2.606350716581902

Epoch: 5| Step: 10
Training loss: 1.9135680513703561
Validation loss: 2.5779164971704605

Epoch: 5| Step: 11
Training loss: 2.3526789147409595
Validation loss: 2.6424143708272916

Epoch: 127| Step: 0
Training loss: 1.805413830729456
Validation loss: 2.564977324523736

Epoch: 5| Step: 1
Training loss: 2.016836585880956
Validation loss: 2.5846890454369733

Epoch: 5| Step: 2
Training loss: 1.7089492183883854
Validation loss: 2.5376743395348336

Epoch: 5| Step: 3
Training loss: 2.3498958118149615
Validation loss: 2.5038720900754012

Epoch: 5| Step: 4
Training loss: 2.005977281709922
Validation loss: 2.5943083774893196

Epoch: 5| Step: 5
Training loss: 1.8251603696202023
Validation loss: 2.5578715773346747

Epoch: 5| Step: 6
Training loss: 2.4621139378651398
Validation loss: 2.6471422867405137

Epoch: 5| Step: 7
Training loss: 2.3907769846755054
Validation loss: 2.5833766738783552

Epoch: 5| Step: 8
Training loss: 2.0182889146061984
Validation loss: 2.593419444610483

Epoch: 5| Step: 9
Training loss: 2.4279324488347562
Validation loss: 2.615525597674044

Epoch: 5| Step: 10
Training loss: 2.841056134666675
Validation loss: 2.616576219218488

Epoch: 5| Step: 11
Training loss: 0.5503065891154216
Validation loss: 2.5627219794045244

Epoch: 128| Step: 0
Training loss: 2.2388326288647797
Validation loss: 2.6310142314810654

Epoch: 5| Step: 1
Training loss: 2.138924584634452
Validation loss: 2.668523623702092

Epoch: 5| Step: 2
Training loss: 2.303863274557326
Validation loss: 2.5615794381368175

Epoch: 5| Step: 3
Training loss: 2.437247825684978
Validation loss: 2.621875875546382

Epoch: 5| Step: 4
Training loss: 2.07760808725498
Validation loss: 2.565327646554111

Epoch: 5| Step: 5
Training loss: 1.9490818747737442
Validation loss: 2.5303659798823914

Epoch: 5| Step: 6
Training loss: 2.02236580175959
Validation loss: 2.5712444892185062

Epoch: 5| Step: 7
Training loss: 1.563273657952384
Validation loss: 2.583688063006032

Epoch: 5| Step: 8
Training loss: 1.7696315576952295
Validation loss: 2.6527576938144053

Epoch: 5| Step: 9
Training loss: 2.8305496865476742
Validation loss: 2.5903620941977494

Epoch: 5| Step: 10
Training loss: 2.090691795479502
Validation loss: 2.628611131931214

Epoch: 5| Step: 11
Training loss: 0.589265931920349
Validation loss: 2.679088929760615

Epoch: 129| Step: 0
Training loss: 2.4332992351006695
Validation loss: 2.59117675967267

Epoch: 5| Step: 1
Training loss: 2.3179616611065033
Validation loss: 2.630187509787941

Epoch: 5| Step: 2
Training loss: 1.8904406875430624
Validation loss: 2.607097938026839

Epoch: 5| Step: 3
Training loss: 2.3636643784870173
Validation loss: 2.590393395495512

Epoch: 5| Step: 4
Training loss: 2.2695968014414545
Validation loss: 2.5348141874906305

Epoch: 5| Step: 5
Training loss: 2.1762553439877195
Validation loss: 2.545745821623008

Epoch: 5| Step: 6
Training loss: 2.0177478109609472
Validation loss: 2.573764392385805

Epoch: 5| Step: 7
Training loss: 1.9658531796417225
Validation loss: 2.594072720163967

Epoch: 5| Step: 8
Training loss: 2.0927644374296093
Validation loss: 2.581247488733383

Epoch: 5| Step: 9
Training loss: 1.7174665340622446
Validation loss: 2.5907709409608604

Epoch: 5| Step: 10
Training loss: 2.5962854884536353
Validation loss: 2.5511693537511806

Epoch: 5| Step: 11
Training loss: 0.8163579899153738
Validation loss: 2.562676202717189

Epoch: 130| Step: 0
Training loss: 1.950581718143091
Validation loss: 2.651810919791868

Epoch: 5| Step: 1
Training loss: 2.3927700417288778
Validation loss: 2.61470621638398

Epoch: 5| Step: 2
Training loss: 1.999548384221979
Validation loss: 2.652508992219736

Epoch: 5| Step: 3
Training loss: 2.039016547726643
Validation loss: 2.586799132291484

Epoch: 5| Step: 4
Training loss: 2.0599158310592656
Validation loss: 2.6129992779111393

Epoch: 5| Step: 5
Training loss: 2.721594977181233
Validation loss: 2.6123494234146496

Epoch: 5| Step: 6
Training loss: 2.1552239893299605
Validation loss: 2.645713748382067

Epoch: 5| Step: 7
Training loss: 1.965470746754491
Validation loss: 2.603413539066937

Epoch: 5| Step: 8
Training loss: 2.654305048937699
Validation loss: 2.5871327644852515

Epoch: 5| Step: 9
Training loss: 2.1247193768277572
Validation loss: 2.620459671755394

Epoch: 5| Step: 10
Training loss: 1.6710760756775571
Validation loss: 2.550413372935305

Epoch: 5| Step: 11
Training loss: 1.8078276822335424
Validation loss: 2.519156246222639

Epoch: 131| Step: 0
Training loss: 1.9932596351029908
Validation loss: 2.5645362315641536

Epoch: 5| Step: 1
Training loss: 2.465889927853939
Validation loss: 2.625461208607602

Epoch: 5| Step: 2
Training loss: 2.365140426370112
Validation loss: 2.7026881745174567

Epoch: 5| Step: 3
Training loss: 2.3037822432597945
Validation loss: 2.6251194714803336

Epoch: 5| Step: 4
Training loss: 2.3700268527413026
Validation loss: 2.651941054444023

Epoch: 5| Step: 5
Training loss: 1.7350990227576102
Validation loss: 2.5796749349588866

Epoch: 5| Step: 6
Training loss: 1.6810977427235485
Validation loss: 2.614530385508404

Epoch: 5| Step: 7
Training loss: 2.0943503586638044
Validation loss: 2.6130805173681257

Epoch: 5| Step: 8
Training loss: 2.0673719720281447
Validation loss: 2.5505094884851616

Epoch: 5| Step: 9
Training loss: 2.1612835058877087
Validation loss: 2.5752689880008317

Epoch: 5| Step: 10
Training loss: 2.667051098849306
Validation loss: 2.5514629829717173

Epoch: 5| Step: 11
Training loss: 2.0887251953259325
Validation loss: 2.6397658554947565

Epoch: 132| Step: 0
Training loss: 2.1365197906755946
Validation loss: 2.6255106731980744

Epoch: 5| Step: 1
Training loss: 3.0064150251430295
Validation loss: 2.4534897624187613

Epoch: 5| Step: 2
Training loss: 1.5879539861858882
Validation loss: 2.5774400957270642

Epoch: 5| Step: 3
Training loss: 1.8494411500765402
Validation loss: 2.6162735591094397

Epoch: 5| Step: 4
Training loss: 2.1751516311231467
Validation loss: 2.568271007879077

Epoch: 5| Step: 5
Training loss: 2.0860021916905533
Validation loss: 2.6501994165926703

Epoch: 5| Step: 6
Training loss: 1.7551585868630397
Validation loss: 2.5859907400253577

Epoch: 5| Step: 7
Training loss: 2.009740356642356
Validation loss: 2.6651585767503634

Epoch: 5| Step: 8
Training loss: 1.7379794769655699
Validation loss: 2.614191882147968

Epoch: 5| Step: 9
Training loss: 2.052080131825178
Validation loss: 2.7000482097195264

Epoch: 5| Step: 10
Training loss: 2.8167051455636383
Validation loss: 2.6084820214955293

Epoch: 5| Step: 11
Training loss: 1.328687840297007
Validation loss: 2.6115300422158705

Epoch: 133| Step: 0
Training loss: 1.6320680080015997
Validation loss: 2.658266655814178

Epoch: 5| Step: 1
Training loss: 2.553340825235051
Validation loss: 2.6055081625211316

Epoch: 5| Step: 2
Training loss: 2.121772559141203
Validation loss: 2.635488672491578

Epoch: 5| Step: 3
Training loss: 1.3083205663863984
Validation loss: 2.550160841294847

Epoch: 5| Step: 4
Training loss: 2.065341263990812
Validation loss: 2.6073134724803357

Epoch: 5| Step: 5
Training loss: 1.910135155933822
Validation loss: 2.638255427411795

Epoch: 5| Step: 6
Training loss: 2.157817989179409
Validation loss: 2.5963313995454853

Epoch: 5| Step: 7
Training loss: 2.2685836941214856
Validation loss: 2.6914348886827386

Epoch: 5| Step: 8
Training loss: 2.2215092654415987
Validation loss: 2.5412753121759923

Epoch: 5| Step: 9
Training loss: 2.654289689099912
Validation loss: 2.6101609491182085

Epoch: 5| Step: 10
Training loss: 2.0575430285936087
Validation loss: 2.568542802688562

Epoch: 5| Step: 11
Training loss: 2.3327878814031897
Validation loss: 2.6169089819140727

Epoch: 134| Step: 0
Training loss: 1.5769560610951967
Validation loss: 2.6558669618173814

Epoch: 5| Step: 1
Training loss: 2.5864367968220447
Validation loss: 2.555363720164403

Epoch: 5| Step: 2
Training loss: 2.360854739563271
Validation loss: 2.6337396892652962

Epoch: 5| Step: 3
Training loss: 1.9449883003177173
Validation loss: 2.6459183616692425

Epoch: 5| Step: 4
Training loss: 2.084292674118848
Validation loss: 2.6504875470859393

Epoch: 5| Step: 5
Training loss: 2.0025104026190865
Validation loss: 2.693738151400323

Epoch: 5| Step: 6
Training loss: 2.5407683760197965
Validation loss: 2.693814739620599

Epoch: 5| Step: 7
Training loss: 2.180475126863324
Validation loss: 2.6178035447555423

Epoch: 5| Step: 8
Training loss: 1.9949437241994519
Validation loss: 2.5665696864776653

Epoch: 5| Step: 9
Training loss: 1.6097399103470826
Validation loss: 2.588991000796478

Epoch: 5| Step: 10
Training loss: 2.482278094866223
Validation loss: 2.4995762386391966

Epoch: 5| Step: 11
Training loss: 1.328358349215551
Validation loss: 2.5717282942085244

Epoch: 135| Step: 0
Training loss: 2.3271617560859963
Validation loss: 2.5621537734497006

Epoch: 5| Step: 1
Training loss: 2.2698806257410866
Validation loss: 2.598142969333767

Epoch: 5| Step: 2
Training loss: 2.1297086271048316
Validation loss: 2.593994358915432

Epoch: 5| Step: 3
Training loss: 1.8953663666595268
Validation loss: 2.6319041095272193

Epoch: 5| Step: 4
Training loss: 2.7130908164415133
Validation loss: 2.572703328856912

Epoch: 5| Step: 5
Training loss: 1.1592716222362707
Validation loss: 2.596382157542494

Epoch: 5| Step: 6
Training loss: 1.455009632930788
Validation loss: 2.6495329730239043

Epoch: 5| Step: 7
Training loss: 1.7095049430371807
Validation loss: 2.586755728757335

Epoch: 5| Step: 8
Training loss: 2.510398695843165
Validation loss: 2.5703321763418896

Epoch: 5| Step: 9
Training loss: 2.016313184018937
Validation loss: 2.5951311693073027

Epoch: 5| Step: 10
Training loss: 2.4055844662255175
Validation loss: 2.6596362837665493

Epoch: 5| Step: 11
Training loss: 3.040298014639727
Validation loss: 2.5891629854331004

Epoch: 136| Step: 0
Training loss: 1.7355794075461
Validation loss: 2.5869293922861973

Epoch: 5| Step: 1
Training loss: 1.6655576194890078
Validation loss: 2.6349633842285174

Epoch: 5| Step: 2
Training loss: 1.4332651702434662
Validation loss: 2.6001667597367852

Epoch: 5| Step: 3
Training loss: 2.0009193691496865
Validation loss: 2.6700687400610597

Epoch: 5| Step: 4
Training loss: 2.4178273493969122
Validation loss: 2.6029845333019668

Epoch: 5| Step: 5
Training loss: 1.895334855943932
Validation loss: 2.552971270231343

Epoch: 5| Step: 6
Training loss: 2.1304237486867503
Validation loss: 2.528830129007892

Epoch: 5| Step: 7
Training loss: 2.1593172675666996
Validation loss: 2.5642843430606894

Epoch: 5| Step: 8
Training loss: 2.2933769317667054
Validation loss: 2.5845329450125085

Epoch: 5| Step: 9
Training loss: 2.7872677111810993
Validation loss: 2.596471611027158

Epoch: 5| Step: 10
Training loss: 2.3295724964475424
Validation loss: 2.583958216943492

Epoch: 5| Step: 11
Training loss: 2.14685732905016
Validation loss: 2.665879264949403

Epoch: 137| Step: 0
Training loss: 2.3770906381943373
Validation loss: 2.533927427659205

Epoch: 5| Step: 1
Training loss: 1.5578035344790826
Validation loss: 2.5911579432116647

Epoch: 5| Step: 2
Training loss: 1.8969844704828376
Validation loss: 2.562383994136085

Epoch: 5| Step: 3
Training loss: 2.0300672168596443
Validation loss: 2.570986915315335

Epoch: 5| Step: 4
Training loss: 1.9981386941077195
Validation loss: 2.552178538097187

Epoch: 5| Step: 5
Training loss: 2.3459395290298395
Validation loss: 2.6299534979517802

Epoch: 5| Step: 6
Training loss: 1.7296724920130009
Validation loss: 2.586976563834001

Epoch: 5| Step: 7
Training loss: 2.1017850736720547
Validation loss: 2.5921645968458016

Epoch: 5| Step: 8
Training loss: 1.9888551254828246
Validation loss: 2.652720181659313

Epoch: 5| Step: 9
Training loss: 2.569505280699521
Validation loss: 2.519841051399661

Epoch: 5| Step: 10
Training loss: 2.2860585575029613
Validation loss: 2.5427333041106692

Epoch: 5| Step: 11
Training loss: 2.167758031003794
Validation loss: 2.5751038044311407

Epoch: 138| Step: 0
Training loss: 1.6265777118129119
Validation loss: 2.5644165563288217

Epoch: 5| Step: 1
Training loss: 1.9593647276686657
Validation loss: 2.568088523981388

Epoch: 5| Step: 2
Training loss: 2.295316310019866
Validation loss: 2.5877938498390147

Epoch: 5| Step: 3
Training loss: 2.1835797741055427
Validation loss: 2.6214453039325774

Epoch: 5| Step: 4
Training loss: 2.07080072368324
Validation loss: 2.5961116759157465

Epoch: 5| Step: 5
Training loss: 2.4399091112687867
Validation loss: 2.5873529549832015

Epoch: 5| Step: 6
Training loss: 1.9819064066794467
Validation loss: 2.5694196207262143

Epoch: 5| Step: 7
Training loss: 1.3293897104816912
Validation loss: 2.537344052701382

Epoch: 5| Step: 8
Training loss: 2.1238117261586407
Validation loss: 2.587213053740875

Epoch: 5| Step: 9
Training loss: 2.06225746347106
Validation loss: 2.5818100034692177

Epoch: 5| Step: 10
Training loss: 2.394034254761191
Validation loss: 2.615093235939418

Epoch: 5| Step: 11
Training loss: 3.091854246743444
Validation loss: 2.536632327561872

Epoch: 139| Step: 0
Training loss: 2.1966967579580348
Validation loss: 2.6261315593795835

Epoch: 5| Step: 1
Training loss: 1.9957522941919268
Validation loss: 2.5868233338043076

Epoch: 5| Step: 2
Training loss: 2.1929662798903973
Validation loss: 2.5663708936480587

Epoch: 5| Step: 3
Training loss: 2.2346543357542292
Validation loss: 2.572556498771799

Epoch: 5| Step: 4
Training loss: 3.0004817257988803
Validation loss: 2.572480567596759

Epoch: 5| Step: 5
Training loss: 1.9140847963864005
Validation loss: 2.53270859941554

Epoch: 5| Step: 6
Training loss: 1.645241047321116
Validation loss: 2.7153670613915457

Epoch: 5| Step: 7
Training loss: 1.6897002111132848
Validation loss: 2.4748895933590997

Epoch: 5| Step: 8
Training loss: 2.2279127878621785
Validation loss: 2.5926755035353115

Epoch: 5| Step: 9
Training loss: 1.580752988967833
Validation loss: 2.5313050574135043

Epoch: 5| Step: 10
Training loss: 1.8616684945671558
Validation loss: 2.6621172077588957

Epoch: 5| Step: 11
Training loss: 2.397030793738193
Validation loss: 2.647941681728461

Epoch: 140| Step: 0
Training loss: 2.841244946134195
Validation loss: 2.530506660669738

Epoch: 5| Step: 1
Training loss: 2.1400495437876486
Validation loss: 2.5752077995636946

Epoch: 5| Step: 2
Training loss: 1.9207076582545777
Validation loss: 2.6621180473815165

Epoch: 5| Step: 3
Training loss: 2.162658787007839
Validation loss: 2.6626866275229073

Epoch: 5| Step: 4
Training loss: 1.4064258465494532
Validation loss: 2.651477790338107

Epoch: 5| Step: 5
Training loss: 2.334213794621535
Validation loss: 2.611997348852696

Epoch: 5| Step: 6
Training loss: 2.211660206355779
Validation loss: 2.6843824083775942

Epoch: 5| Step: 7
Training loss: 1.5860467882506695
Validation loss: 2.669401924201754

Epoch: 5| Step: 8
Training loss: 1.6489654707939914
Validation loss: 2.606836734793614

Epoch: 5| Step: 9
Training loss: 2.07193608949107
Validation loss: 2.553363495842372

Epoch: 5| Step: 10
Training loss: 1.993001494817178
Validation loss: 2.6014949915836065

Epoch: 5| Step: 11
Training loss: 2.9675210115481057
Validation loss: 2.6287738640125724

Epoch: 141| Step: 0
Training loss: 1.848489972463727
Validation loss: 2.5840414304770434

Epoch: 5| Step: 1
Training loss: 1.6939758093952115
Validation loss: 2.6004985012015163

Epoch: 5| Step: 2
Training loss: 2.013225220983801
Validation loss: 2.5755884350016567

Epoch: 5| Step: 3
Training loss: 2.126858963996996
Validation loss: 2.646035114739047

Epoch: 5| Step: 4
Training loss: 1.673987150705808
Validation loss: 2.646267038127411

Epoch: 5| Step: 5
Training loss: 2.4994538664340515
Validation loss: 2.5471451972909107

Epoch: 5| Step: 6
Training loss: 1.9741076276245824
Validation loss: 2.582830835251557

Epoch: 5| Step: 7
Training loss: 2.0699252936109485
Validation loss: 2.5861441269424366

Epoch: 5| Step: 8
Training loss: 1.962093544436126
Validation loss: 2.5962117435695955

Epoch: 5| Step: 9
Training loss: 2.398115503025413
Validation loss: 2.620701092920005

Epoch: 5| Step: 10
Training loss: 1.8869580103331978
Validation loss: 2.5906339066202393

Epoch: 5| Step: 11
Training loss: 1.9314937400706556
Validation loss: 2.539013913985764

Epoch: 142| Step: 0
Training loss: 2.0066635466178555
Validation loss: 2.5862292444973596

Epoch: 5| Step: 1
Training loss: 1.8764227237783515
Validation loss: 2.6602593811329096

Epoch: 5| Step: 2
Training loss: 1.9692471194476844
Validation loss: 2.723079311024626

Epoch: 5| Step: 3
Training loss: 2.303054696696134
Validation loss: 2.7175361985746775

Epoch: 5| Step: 4
Training loss: 1.6167701514377224
Validation loss: 2.859992591158067

Epoch: 5| Step: 5
Training loss: 2.0801993894376793
Validation loss: 2.812948078207474

Epoch: 5| Step: 6
Training loss: 2.5256683598123733
Validation loss: 2.835756924907932

Epoch: 5| Step: 7
Training loss: 1.7779436712879024
Validation loss: 2.701692024951684

Epoch: 5| Step: 8
Training loss: 2.704796511317082
Validation loss: 2.6787158513113902

Epoch: 5| Step: 9
Training loss: 1.8554230051926817
Validation loss: 2.627571753512116

Epoch: 5| Step: 10
Training loss: 1.711624773893994
Validation loss: 2.579357507657313

Epoch: 5| Step: 11
Training loss: 2.1166936432128125
Validation loss: 2.59381493330111

Epoch: 143| Step: 0
Training loss: 1.7505772864619444
Validation loss: 2.6273249669064813

Epoch: 5| Step: 1
Training loss: 2.7986350036139704
Validation loss: 2.5584407071455795

Epoch: 5| Step: 2
Training loss: 2.3716076163658775
Validation loss: 2.5979673882870875

Epoch: 5| Step: 3
Training loss: 1.8144634398463875
Validation loss: 2.6240535838935846

Epoch: 5| Step: 4
Training loss: 1.9799135773033347
Validation loss: 2.629580935946223

Epoch: 5| Step: 5
Training loss: 1.840255399683879
Validation loss: 2.6546373558285583

Epoch: 5| Step: 6
Training loss: 1.7204030497295326
Validation loss: 2.6451468791213943

Epoch: 5| Step: 7
Training loss: 2.297213886199222
Validation loss: 2.534553665859392

Epoch: 5| Step: 8
Training loss: 1.6275569166318642
Validation loss: 2.5199463455540845

Epoch: 5| Step: 9
Training loss: 2.4757261578878422
Validation loss: 2.627467036882852

Epoch: 5| Step: 10
Training loss: 1.7729940658272085
Validation loss: 2.57627920872398

Epoch: 5| Step: 11
Training loss: 2.430328382744528
Validation loss: 2.712972227351857

Epoch: 144| Step: 0
Training loss: 1.7700466727444923
Validation loss: 2.63873483698958

Epoch: 5| Step: 1
Training loss: 2.660433985793922
Validation loss: 2.602459005588129

Epoch: 5| Step: 2
Training loss: 2.119910034573991
Validation loss: 2.7105459100831775

Epoch: 5| Step: 3
Training loss: 2.2270581145564146
Validation loss: 2.6128182868298793

Epoch: 5| Step: 4
Training loss: 2.278128173156119
Validation loss: 2.6934636948530293

Epoch: 5| Step: 5
Training loss: 1.4027839331077432
Validation loss: 2.7050906772069823

Epoch: 5| Step: 6
Training loss: 2.0051572586754993
Validation loss: 2.59985168153195

Epoch: 5| Step: 7
Training loss: 2.072344434212134
Validation loss: 2.6358110424280707

Epoch: 5| Step: 8
Training loss: 1.852973110928218
Validation loss: 2.6528580044858643

Epoch: 5| Step: 9
Training loss: 2.182562569227125
Validation loss: 2.6709855738994936

Epoch: 5| Step: 10
Training loss: 1.9277409299296484
Validation loss: 2.586374528264364

Epoch: 5| Step: 11
Training loss: 1.242085866549081
Validation loss: 2.57078380186651

Epoch: 145| Step: 0
Training loss: 2.2518584735231104
Validation loss: 2.6717817427810693

Epoch: 5| Step: 1
Training loss: 2.16901720143414
Validation loss: 2.640052229179205

Epoch: 5| Step: 2
Training loss: 1.8577846489720429
Validation loss: 2.59066882063828

Epoch: 5| Step: 3
Training loss: 1.7708244398305129
Validation loss: 2.666851124245

Epoch: 5| Step: 4
Training loss: 2.3449395784837406
Validation loss: 2.7132957198158723

Epoch: 5| Step: 5
Training loss: 1.6298578716401735
Validation loss: 2.7298006396401027

Epoch: 5| Step: 6
Training loss: 2.845744010301694
Validation loss: 2.7163383084082824

Epoch: 5| Step: 7
Training loss: 1.7059396007306187
Validation loss: 2.697090745431785

Epoch: 5| Step: 8
Training loss: 2.0123566144011775
Validation loss: 2.7742279323295933

Epoch: 5| Step: 9
Training loss: 1.9434663522691469
Validation loss: 2.7062768752016835

Epoch: 5| Step: 10
Training loss: 1.8783473335473224
Validation loss: 2.767966430531017

Epoch: 5| Step: 11
Training loss: 1.7406190389260583
Validation loss: 2.5320798824308337

Epoch: 146| Step: 0
Training loss: 1.7267206732332163
Validation loss: 2.6407339310609035

Epoch: 5| Step: 1
Training loss: 1.921352098242733
Validation loss: 2.615385625224652

Epoch: 5| Step: 2
Training loss: 2.1150832188243776
Validation loss: 2.657534703757491

Epoch: 5| Step: 3
Training loss: 1.8478317338705976
Validation loss: 2.6107059480335053

Epoch: 5| Step: 4
Training loss: 2.1690713913645583
Validation loss: 2.6833286441343414

Epoch: 5| Step: 5
Training loss: 2.62849584042817
Validation loss: 2.622446568568727

Epoch: 5| Step: 6
Training loss: 2.1081737347332385
Validation loss: 2.6196089156905833

Epoch: 5| Step: 7
Training loss: 1.7232561169904121
Validation loss: 2.6037060838934103

Epoch: 5| Step: 8
Training loss: 1.9018707627353608
Validation loss: 2.665660643553559

Epoch: 5| Step: 9
Training loss: 1.7382477832101386
Validation loss: 2.59259470139776

Epoch: 5| Step: 10
Training loss: 1.7533530401468878
Validation loss: 2.638399066276888

Epoch: 5| Step: 11
Training loss: 2.086842772676834
Validation loss: 2.5931755716721088

Epoch: 147| Step: 0
Training loss: 2.082593086973993
Validation loss: 2.639508028067686

Epoch: 5| Step: 1
Training loss: 2.1443755991442073
Validation loss: 2.5902014284469637

Epoch: 5| Step: 2
Training loss: 1.7609741261285718
Validation loss: 2.569582115528933

Epoch: 5| Step: 3
Training loss: 1.6351000809442764
Validation loss: 2.6173066335105073

Epoch: 5| Step: 4
Training loss: 1.8936093319055762
Validation loss: 2.6700247368279824

Epoch: 5| Step: 5
Training loss: 1.7045617998668836
Validation loss: 2.665202022950454

Epoch: 5| Step: 6
Training loss: 2.061208841018179
Validation loss: 2.7205261662194777

Epoch: 5| Step: 7
Training loss: 1.9798153132221687
Validation loss: 2.686920735674712

Epoch: 5| Step: 8
Training loss: 1.9352474038713174
Validation loss: 2.6397813995665835

Epoch: 5| Step: 9
Training loss: 2.4775979557939176
Validation loss: 2.6957513719114368

Epoch: 5| Step: 10
Training loss: 1.8860141868138636
Validation loss: 2.6821079833212735

Epoch: 5| Step: 11
Training loss: 2.7120997331336065
Validation loss: 2.6504255258299874

Epoch: 148| Step: 0
Training loss: 2.0010451923625916
Validation loss: 2.584967447601026

Epoch: 5| Step: 1
Training loss: 1.736939192907218
Validation loss: 2.5513682096583867

Epoch: 5| Step: 2
Training loss: 1.4140167228918468
Validation loss: 2.6068556114737276

Epoch: 5| Step: 3
Training loss: 2.0730074634187625
Validation loss: 2.643922413584072

Epoch: 5| Step: 4
Training loss: 1.940364258675315
Validation loss: 2.610573175634492

Epoch: 5| Step: 5
Training loss: 1.39345588146678
Validation loss: 2.5831736674240267

Epoch: 5| Step: 6
Training loss: 2.075388203351507
Validation loss: 2.5433405630222254

Epoch: 5| Step: 7
Training loss: 2.060106680616919
Validation loss: 2.623651866019642

Epoch: 5| Step: 8
Training loss: 2.556692101038316
Validation loss: 2.7183847949405457

Epoch: 5| Step: 9
Training loss: 2.1192814793338473
Validation loss: 2.6821023682890783

Epoch: 5| Step: 10
Training loss: 2.3806076104452134
Validation loss: 2.6789126337048943

Epoch: 5| Step: 11
Training loss: 1.5441900514141627
Validation loss: 2.707826971744373

Epoch: 149| Step: 0
Training loss: 2.1092314494701814
Validation loss: 2.6068209409264522

Epoch: 5| Step: 1
Training loss: 2.264843088908525
Validation loss: 2.6238449711760716

Epoch: 5| Step: 2
Training loss: 1.6074849112886727
Validation loss: 2.64030761617163

Epoch: 5| Step: 3
Training loss: 1.4603761624729394
Validation loss: 2.628522420734463

Epoch: 5| Step: 4
Training loss: 2.585869088089121
Validation loss: 2.612141682420411

Epoch: 5| Step: 5
Training loss: 2.6357127891503787
Validation loss: 2.7515344962392434

Epoch: 5| Step: 6
Training loss: 1.7182383382582718
Validation loss: 2.5929387137495183

Epoch: 5| Step: 7
Training loss: 1.8691253183150685
Validation loss: 2.6092001310066797

Epoch: 5| Step: 8
Training loss: 1.7166359124005905
Validation loss: 2.54920595956739

Epoch: 5| Step: 9
Training loss: 1.85121698817583
Validation loss: 2.5164934400809873

Epoch: 5| Step: 10
Training loss: 1.7838133721432192
Validation loss: 2.6790957932914052

Epoch: 5| Step: 11
Training loss: 0.6107385979898564
Validation loss: 2.564244761818634

Epoch: 150| Step: 0
Training loss: 2.007249211362379
Validation loss: 2.621241724998402

Epoch: 5| Step: 1
Training loss: 1.904636513181707
Validation loss: 2.669483903273929

Epoch: 5| Step: 2
Training loss: 1.7041482913543002
Validation loss: 2.7401509307387997

Epoch: 5| Step: 3
Training loss: 2.0517865142194647
Validation loss: 2.71619947507903

Epoch: 5| Step: 4
Training loss: 1.6557202481628326
Validation loss: 2.767547280609252

Epoch: 5| Step: 5
Training loss: 2.187515367726432
Validation loss: 2.6806086596453937

Epoch: 5| Step: 6
Training loss: 2.178051187367386
Validation loss: 2.703815809264063

Epoch: 5| Step: 7
Training loss: 1.6956071729387279
Validation loss: 2.6564316481768064

Epoch: 5| Step: 8
Training loss: 2.1358734634723406
Validation loss: 2.665883863311451

Epoch: 5| Step: 9
Training loss: 1.5729802184076667
Validation loss: 2.6990947704116643

Epoch: 5| Step: 10
Training loss: 2.6732110146612538
Validation loss: 2.678414427000997

Epoch: 5| Step: 11
Training loss: 1.7007109305511812
Validation loss: 2.618659278433193

Epoch: 151| Step: 0
Training loss: 1.4899452498957027
Validation loss: 2.5583286332471418

Epoch: 5| Step: 1
Training loss: 1.9284499675104776
Validation loss: 2.6704374130493878

Epoch: 5| Step: 2
Training loss: 2.325978358344361
Validation loss: 2.6144247019596487

Epoch: 5| Step: 3
Training loss: 1.582208920144898
Validation loss: 2.5418523163037747

Epoch: 5| Step: 4
Training loss: 1.6635572355907764
Validation loss: 2.6164380438106765

Epoch: 5| Step: 5
Training loss: 2.50897760154241
Validation loss: 2.6200681670678234

Epoch: 5| Step: 6
Training loss: 2.3680041827474203
Validation loss: 2.5900152580199647

Epoch: 5| Step: 7
Training loss: 1.919372790530047
Validation loss: 2.6284175341073874

Epoch: 5| Step: 8
Training loss: 1.568177399107646
Validation loss: 2.6489247086811387

Epoch: 5| Step: 9
Training loss: 2.1368671484259316
Validation loss: 2.753471581896055

Epoch: 5| Step: 10
Training loss: 1.5188961319811551
Validation loss: 2.6271663309811912

Epoch: 5| Step: 11
Training loss: 2.7145431242331615
Validation loss: 2.6166214971430075

Epoch: 152| Step: 0
Training loss: 2.079845777259419
Validation loss: 2.6107745918969667

Epoch: 5| Step: 1
Training loss: 1.4360009545718875
Validation loss: 2.58853637699889

Epoch: 5| Step: 2
Training loss: 1.9520882868695453
Validation loss: 2.4690845721520436

Epoch: 5| Step: 3
Training loss: 3.011365026143246
Validation loss: 2.6505973133745067

Epoch: 5| Step: 4
Training loss: 1.6175509426814971
Validation loss: 2.5295851652398156

Epoch: 5| Step: 5
Training loss: 1.4690947432429344
Validation loss: 2.6639196333328146

Epoch: 5| Step: 6
Training loss: 1.8314783364070992
Validation loss: 2.6039494360283877

Epoch: 5| Step: 7
Training loss: 2.101855516391621
Validation loss: 2.651366404421452

Epoch: 5| Step: 8
Training loss: 1.7622298960313534
Validation loss: 2.624136370173766

Epoch: 5| Step: 9
Training loss: 1.8982595352461886
Validation loss: 2.6614100096633524

Epoch: 5| Step: 10
Training loss: 1.7432518688494414
Validation loss: 2.626929852880091

Epoch: 5| Step: 11
Training loss: 1.7681229062706805
Validation loss: 2.5863476223449084

Epoch: 153| Step: 0
Training loss: 1.9573381072972744
Validation loss: 2.558883122588895

Epoch: 5| Step: 1
Training loss: 1.8781206864039286
Validation loss: 2.6343692361656235

Epoch: 5| Step: 2
Training loss: 1.883273246391758
Validation loss: 2.7461130350447753

Epoch: 5| Step: 3
Training loss: 2.2250266684316244
Validation loss: 2.6927861670356465

Epoch: 5| Step: 4
Training loss: 1.5952645379608485
Validation loss: 2.666252543037896

Epoch: 5| Step: 5
Training loss: 2.082202782641391
Validation loss: 2.645171425593888

Epoch: 5| Step: 6
Training loss: 2.667605373943325
Validation loss: 2.5473345281513624

Epoch: 5| Step: 7
Training loss: 1.6029891196326076
Validation loss: 2.6019431552639647

Epoch: 5| Step: 8
Training loss: 1.5611487076750843
Validation loss: 2.64394103112327

Epoch: 5| Step: 9
Training loss: 2.040133023506329
Validation loss: 2.6607225088947635

Epoch: 5| Step: 10
Training loss: 1.5231890353523434
Validation loss: 2.677581511923975

Epoch: 5| Step: 11
Training loss: 1.3322415004150567
Validation loss: 2.6219641542640804

Epoch: 154| Step: 0
Training loss: 2.043110421339635
Validation loss: 2.6647792236126686

Epoch: 5| Step: 1
Training loss: 2.1228267552057063
Validation loss: 2.649144591217205

Epoch: 5| Step: 2
Training loss: 1.7578448483351656
Validation loss: 2.559208764471453

Epoch: 5| Step: 3
Training loss: 1.2874828485624215
Validation loss: 2.5806224863821265

Epoch: 5| Step: 4
Training loss: 2.0036255638049894
Validation loss: 2.613727130494907

Epoch: 5| Step: 5
Training loss: 1.7559749238519955
Validation loss: 2.6491976484491206

Epoch: 5| Step: 6
Training loss: 2.0689071779959898
Validation loss: 2.581762518198243

Epoch: 5| Step: 7
Training loss: 2.7611832807777152
Validation loss: 2.533762754076672

Epoch: 5| Step: 8
Training loss: 1.8890167205539041
Validation loss: 2.6021799418278286

Epoch: 5| Step: 9
Training loss: 1.7831132747078782
Validation loss: 2.6904009236519157

Epoch: 5| Step: 10
Training loss: 2.0592239255005764
Validation loss: 2.7162556222224605

Epoch: 5| Step: 11
Training loss: 1.2916928360451758
Validation loss: 2.833658702250708

Epoch: 155| Step: 0
Training loss: 1.380010924226949
Validation loss: 2.6825117422144924

Epoch: 5| Step: 1
Training loss: 2.001434407836862
Validation loss: 2.7131873275913665

Epoch: 5| Step: 2
Training loss: 2.067724488881477
Validation loss: 2.7101305879294504

Epoch: 5| Step: 3
Training loss: 1.9114548962914717
Validation loss: 2.730958282581363

Epoch: 5| Step: 4
Training loss: 1.5646541242504477
Validation loss: 2.6616927315549064

Epoch: 5| Step: 5
Training loss: 1.7280643887091298
Validation loss: 2.620521126594582

Epoch: 5| Step: 6
Training loss: 1.7194305459759933
Validation loss: 2.7118687125088634

Epoch: 5| Step: 7
Training loss: 2.123022056511732
Validation loss: 2.660953482555417

Epoch: 5| Step: 8
Training loss: 1.642917811120596
Validation loss: 2.647210282247337

Epoch: 5| Step: 9
Training loss: 2.312941534831476
Validation loss: 2.6197026896803326

Epoch: 5| Step: 10
Training loss: 2.656797644315305
Validation loss: 2.5461402839652503

Epoch: 5| Step: 11
Training loss: 2.1725598908872885
Validation loss: 2.620508389173061

Epoch: 156| Step: 0
Training loss: 1.5565922249768558
Validation loss: 2.5569403355892537

Epoch: 5| Step: 1
Training loss: 1.655453328397893
Validation loss: 2.579448032952004

Epoch: 5| Step: 2
Training loss: 1.8439632227823517
Validation loss: 2.717618626470988

Epoch: 5| Step: 3
Training loss: 2.020542857998692
Validation loss: 2.718816763690248

Epoch: 5| Step: 4
Training loss: 2.189427208045203
Validation loss: 2.6968341052217295

Epoch: 5| Step: 5
Training loss: 2.516583656895701
Validation loss: 2.7361525507164686

Epoch: 5| Step: 6
Training loss: 1.8086481930672422
Validation loss: 2.8612398726357835

Epoch: 5| Step: 7
Training loss: 1.8066177284233216
Validation loss: 2.7035069829689404

Epoch: 5| Step: 8
Training loss: 1.4419173494956252
Validation loss: 2.701303261416132

Epoch: 5| Step: 9
Training loss: 2.49970939854595
Validation loss: 2.6408899031420647

Epoch: 5| Step: 10
Training loss: 1.7574014818950434
Validation loss: 2.7347661528786396

Epoch: 5| Step: 11
Training loss: 1.378040203850617
Validation loss: 2.582154436967365

Epoch: 157| Step: 0
Training loss: 1.7803220506853512
Validation loss: 2.61265280807509

Epoch: 5| Step: 1
Training loss: 2.2081092024971474
Validation loss: 2.5939633231931656

Epoch: 5| Step: 2
Training loss: 1.9640061885557547
Validation loss: 2.6033777313459865

Epoch: 5| Step: 3
Training loss: 1.9617180961385994
Validation loss: 2.628235805623488

Epoch: 5| Step: 4
Training loss: 1.5995334332410143
Validation loss: 2.5743432369435184

Epoch: 5| Step: 5
Training loss: 1.8681624672260244
Validation loss: 2.6010029738092784

Epoch: 5| Step: 6
Training loss: 1.5256570932528144
Validation loss: 2.709482518944269

Epoch: 5| Step: 7
Training loss: 2.045443434636929
Validation loss: 2.6413947719598005

Epoch: 5| Step: 8
Training loss: 1.411763551187978
Validation loss: 2.6686761010545057

Epoch: 5| Step: 9
Training loss: 1.97910022289442
Validation loss: 2.5493234321221236

Epoch: 5| Step: 10
Training loss: 2.5490685126703827
Validation loss: 2.630788566620114

Epoch: 5| Step: 11
Training loss: 2.96114942451519
Validation loss: 2.7037177253727407

Epoch: 158| Step: 0
Training loss: 2.378034760897251
Validation loss: 2.6910727690640552

Epoch: 5| Step: 1
Training loss: 1.5601428753886537
Validation loss: 2.826122259773513

Epoch: 5| Step: 2
Training loss: 1.5450320584325985
Validation loss: 2.718296382229184

Epoch: 5| Step: 3
Training loss: 1.6353615753548867
Validation loss: 2.8191142191581178

Epoch: 5| Step: 4
Training loss: 1.4523327216047204
Validation loss: 2.7367480961137964

Epoch: 5| Step: 5
Training loss: 1.9886865109152545
Validation loss: 2.805509197184679

Epoch: 5| Step: 6
Training loss: 2.1644448724054794
Validation loss: 2.685060976402797

Epoch: 5| Step: 7
Training loss: 2.3051134653360843
Validation loss: 2.783232910710729

Epoch: 5| Step: 8
Training loss: 2.245099771572294
Validation loss: 2.6114051253978796

Epoch: 5| Step: 9
Training loss: 1.6379455484415297
Validation loss: 2.6935857539837635

Epoch: 5| Step: 10
Training loss: 1.8060098402614915
Validation loss: 2.585590181719477

Epoch: 5| Step: 11
Training loss: 1.1324223339741761
Validation loss: 2.6361693537510424

Epoch: 159| Step: 0
Training loss: 2.6823781021166355
Validation loss: 2.5300520624990988

Epoch: 5| Step: 1
Training loss: 1.6617290631015917
Validation loss: 2.635555585333531

Epoch: 5| Step: 2
Training loss: 1.9180221394801498
Validation loss: 2.6489168031601884

Epoch: 5| Step: 3
Training loss: 1.9882108604697082
Validation loss: 2.65772558440571

Epoch: 5| Step: 4
Training loss: 2.0981341337994355
Validation loss: 2.633391221432257

Epoch: 5| Step: 5
Training loss: 1.557830929814542
Validation loss: 2.681133765996483

Epoch: 5| Step: 6
Training loss: 1.8147218831626433
Validation loss: 2.597178231142723

Epoch: 5| Step: 7
Training loss: 1.5927185011697786
Validation loss: 2.6389464511504954

Epoch: 5| Step: 8
Training loss: 1.9192654641092284
Validation loss: 2.7061890819174352

Epoch: 5| Step: 9
Training loss: 1.3348094795665495
Validation loss: 2.675884478728793

Epoch: 5| Step: 10
Training loss: 2.15473132624879
Validation loss: 2.6495945146419424

Epoch: 5| Step: 11
Training loss: 1.24607920862401
Validation loss: 2.714512606763371

Epoch: 160| Step: 0
Training loss: 1.9684412275110377
Validation loss: 2.631129035072

Epoch: 5| Step: 1
Training loss: 2.3355202190526025
Validation loss: 2.6801356875946043

Epoch: 5| Step: 2
Training loss: 1.677515941606661
Validation loss: 2.725192912882215

Epoch: 5| Step: 3
Training loss: 2.108765464594858
Validation loss: 2.6567378362837437

Epoch: 5| Step: 4
Training loss: 1.4624053598414224
Validation loss: 2.695801426130219

Epoch: 5| Step: 5
Training loss: 1.6558059960949838
Validation loss: 2.7120030898730176

Epoch: 5| Step: 6
Training loss: 1.2699155255255465
Validation loss: 2.5983581818360415

Epoch: 5| Step: 7
Training loss: 1.9309290548258131
Validation loss: 2.724947154848012

Epoch: 5| Step: 8
Training loss: 1.663088446283156
Validation loss: 2.589070568636176

Epoch: 5| Step: 9
Training loss: 1.7734873760452718
Validation loss: 2.7018947080090046

Epoch: 5| Step: 10
Training loss: 1.5137005415632276
Validation loss: 2.6503577721100355

Epoch: 5| Step: 11
Training loss: 2.0463680192752474
Validation loss: 2.6725815699481523

Epoch: 161| Step: 0
Training loss: 1.7601722306814147
Validation loss: 2.7020663759164667

Epoch: 5| Step: 1
Training loss: 2.025520578039272
Validation loss: 2.5448080853747004

Epoch: 5| Step: 2
Training loss: 1.7854766224335148
Validation loss: 2.6516428879627356

Epoch: 5| Step: 3
Training loss: 2.450510758079602
Validation loss: 2.6381645816200527

Epoch: 5| Step: 4
Training loss: 1.8119988899732815
Validation loss: 2.6238591841112187

Epoch: 5| Step: 5
Training loss: 1.8543330200092647
Validation loss: 2.6135455360449837

Epoch: 5| Step: 6
Training loss: 1.8837913406382025
Validation loss: 2.6424385892949602

Epoch: 5| Step: 7
Training loss: 2.1711292770460457
Validation loss: 2.6428652370327708

Epoch: 5| Step: 8
Training loss: 1.4012597444928812
Validation loss: 2.674053404638293

Epoch: 5| Step: 9
Training loss: 1.5615712266471657
Validation loss: 2.6162658473004345

Epoch: 5| Step: 10
Training loss: 1.3096362160663613
Validation loss: 2.7340673982081705

Epoch: 5| Step: 11
Training loss: 1.562147482206642
Validation loss: 2.69647835842233

Epoch: 162| Step: 0
Training loss: 1.6006135687965415
Validation loss: 2.710198791879655

Epoch: 5| Step: 1
Training loss: 1.9264201561039658
Validation loss: 2.768170537653715

Epoch: 5| Step: 2
Training loss: 1.9215518090407766
Validation loss: 2.7607978929428247

Epoch: 5| Step: 3
Training loss: 2.009401872375108
Validation loss: 2.8123977289325666

Epoch: 5| Step: 4
Training loss: 1.8420696036393684
Validation loss: 2.68657737981919

Epoch: 5| Step: 5
Training loss: 1.5992281393083934
Validation loss: 2.6420734240274855

Epoch: 5| Step: 6
Training loss: 2.456320461204092
Validation loss: 2.6725708834207973

Epoch: 5| Step: 7
Training loss: 2.151076482040026
Validation loss: 2.5696625936251327

Epoch: 5| Step: 8
Training loss: 1.3078030602992938
Validation loss: 2.683407776601586

Epoch: 5| Step: 9
Training loss: 1.7694620619967598
Validation loss: 2.5865225307831046

Epoch: 5| Step: 10
Training loss: 1.5131104049388397
Validation loss: 2.638261384280148

Epoch: 5| Step: 11
Training loss: 1.1711870335739267
Validation loss: 2.6014148185289936

Epoch: 163| Step: 0
Training loss: 1.7460569510113142
Validation loss: 2.6714989804703775

Epoch: 5| Step: 1
Training loss: 1.8009763268583445
Validation loss: 2.778943602109211

Epoch: 5| Step: 2
Training loss: 1.5734629745466804
Validation loss: 2.7055453304416965

Epoch: 5| Step: 3
Training loss: 1.7768665385707318
Validation loss: 2.682554881443117

Epoch: 5| Step: 4
Training loss: 2.018358609550247
Validation loss: 2.7294294555952687

Epoch: 5| Step: 5
Training loss: 1.7071535952652732
Validation loss: 2.6546687636856516

Epoch: 5| Step: 6
Training loss: 1.9486971292915132
Validation loss: 2.621704528792455

Epoch: 5| Step: 7
Training loss: 1.9320189565474926
Validation loss: 2.681101460258554

Epoch: 5| Step: 8
Training loss: 1.3380013747215336
Validation loss: 2.705431863399493

Epoch: 5| Step: 9
Training loss: 2.3897097961255644
Validation loss: 2.57148807777827

Epoch: 5| Step: 10
Training loss: 1.652896653324967
Validation loss: 2.7400918834251202

Epoch: 5| Step: 11
Training loss: 1.985475490321766
Validation loss: 2.720831625871186

Epoch: 164| Step: 0
Training loss: 1.3335645246739323
Validation loss: 2.697446831305

Epoch: 5| Step: 1
Training loss: 1.6389453100560916
Validation loss: 2.7112673156657854

Epoch: 5| Step: 2
Training loss: 1.7741030481894486
Validation loss: 2.657974061385624

Epoch: 5| Step: 3
Training loss: 1.7401645702058
Validation loss: 2.634100175567662

Epoch: 5| Step: 4
Training loss: 2.0450575819046426
Validation loss: 2.7675328400181667

Epoch: 5| Step: 5
Training loss: 1.8929920983852389
Validation loss: 2.6543893767559528

Epoch: 5| Step: 6
Training loss: 1.600076274245869
Validation loss: 2.6846394211398836

Epoch: 5| Step: 7
Training loss: 2.346205785352009
Validation loss: 2.664351743133837

Epoch: 5| Step: 8
Training loss: 2.1847933781956854
Validation loss: 2.734390818232241

Epoch: 5| Step: 9
Training loss: 1.686076588236227
Validation loss: 2.68191042415966

Epoch: 5| Step: 10
Training loss: 1.4592775103988813
Validation loss: 2.6385102127214415

Epoch: 5| Step: 11
Training loss: 1.3060029302683929
Validation loss: 2.8216587210481565

Epoch: 165| Step: 0
Training loss: 2.461883556838223
Validation loss: 2.7096493653588083

Epoch: 5| Step: 1
Training loss: 1.7326414362655733
Validation loss: 2.6626677157332

Epoch: 5| Step: 2
Training loss: 1.5024946449425551
Validation loss: 2.6634464651694882

Epoch: 5| Step: 3
Training loss: 2.3063228688707214
Validation loss: 2.674946638567364

Epoch: 5| Step: 4
Training loss: 1.6209965320528883
Validation loss: 2.6561865630709076

Epoch: 5| Step: 5
Training loss: 1.6998431582186413
Validation loss: 2.6393452916124542

Epoch: 5| Step: 6
Training loss: 1.5013487632973777
Validation loss: 2.6398918104580753

Epoch: 5| Step: 7
Training loss: 1.489477282752638
Validation loss: 2.6508255866124504

Epoch: 5| Step: 8
Training loss: 1.5232197923868995
Validation loss: 2.582814192651162

Epoch: 5| Step: 9
Training loss: 2.4788111156599126
Validation loss: 2.689121437350442

Epoch: 5| Step: 10
Training loss: 1.4021166774342577
Validation loss: 2.749063971916829

Epoch: 5| Step: 11
Training loss: 1.6184356590447615
Validation loss: 2.6670857164820942

Epoch: 166| Step: 0
Training loss: 1.7009441166331525
Validation loss: 2.6401541927853627

Epoch: 5| Step: 1
Training loss: 1.5474100439890783
Validation loss: 2.691664898776329

Epoch: 5| Step: 2
Training loss: 1.4498781416101143
Validation loss: 2.6385818002999133

Epoch: 5| Step: 3
Training loss: 1.867468074643152
Validation loss: 2.6737571244325458

Epoch: 5| Step: 4
Training loss: 1.7342802829482316
Validation loss: 2.6397596856338255

Epoch: 5| Step: 5
Training loss: 1.6418987597433357
Validation loss: 2.636742708073784

Epoch: 5| Step: 6
Training loss: 1.8587152929599529
Validation loss: 2.679203045263351

Epoch: 5| Step: 7
Training loss: 1.548763701937874
Validation loss: 2.6651595943298965

Epoch: 5| Step: 8
Training loss: 2.1853984001664206
Validation loss: 2.750653301290754

Epoch: 5| Step: 9
Training loss: 1.611401735416163
Validation loss: 2.6876691831520745

Epoch: 5| Step: 10
Training loss: 2.4792403415877615
Validation loss: 2.693618920508449

Epoch: 5| Step: 11
Training loss: 0.9537976189820991
Validation loss: 2.621426568312676

Epoch: 167| Step: 0
Training loss: 1.924211399995161
Validation loss: 2.666167832199544

Epoch: 5| Step: 1
Training loss: 1.1743866516802093
Validation loss: 2.646554031487645

Epoch: 5| Step: 2
Training loss: 1.998224065983892
Validation loss: 2.7868811146989234

Epoch: 5| Step: 3
Training loss: 1.67674174492702
Validation loss: 2.6747949494891077

Epoch: 5| Step: 4
Training loss: 1.4156059988064515
Validation loss: 2.666212718790611

Epoch: 5| Step: 5
Training loss: 2.341367706093586
Validation loss: 2.760307566568066

Epoch: 5| Step: 6
Training loss: 1.2380022763584144
Validation loss: 2.71248858635489

Epoch: 5| Step: 7
Training loss: 1.7880652034271998
Validation loss: 2.7759668913904294

Epoch: 5| Step: 8
Training loss: 2.0143814390756
Validation loss: 2.7181603826408516

Epoch: 5| Step: 9
Training loss: 1.7158064866092435
Validation loss: 2.686531372872099

Epoch: 5| Step: 10
Training loss: 1.724975063309588
Validation loss: 2.648298085462082

Epoch: 5| Step: 11
Training loss: 2.831931234764117
Validation loss: 2.601459440036234

Epoch: 168| Step: 0
Training loss: 2.38892957618229
Validation loss: 2.6058559482700416

Epoch: 5| Step: 1
Training loss: 1.7814339659874991
Validation loss: 2.6262918010933403

Epoch: 5| Step: 2
Training loss: 1.7976035589912063
Validation loss: 2.8011707405737383

Epoch: 5| Step: 3
Training loss: 1.8457200468387642
Validation loss: 2.6403943286492826

Epoch: 5| Step: 4
Training loss: 1.478203240354215
Validation loss: 2.650003553484088

Epoch: 5| Step: 5
Training loss: 1.736923544782885
Validation loss: 2.6202664156860775

Epoch: 5| Step: 6
Training loss: 1.7805131425466227
Validation loss: 2.68759649680134

Epoch: 5| Step: 7
Training loss: 1.3702806632194158
Validation loss: 2.66582929358296

Epoch: 5| Step: 8
Training loss: 1.3481937387032148
Validation loss: 2.71232379716051

Epoch: 5| Step: 9
Training loss: 1.7722756365131114
Validation loss: 2.742332675637545

Epoch: 5| Step: 10
Training loss: 1.836309257366576
Validation loss: 2.7518113088244136

Epoch: 5| Step: 11
Training loss: 1.7046851615295315
Validation loss: 2.7093541581211316

Epoch: 169| Step: 0
Training loss: 1.7936366879497574
Validation loss: 2.6067912126037336

Epoch: 5| Step: 1
Training loss: 1.8254193882275027
Validation loss: 2.6332851555396806

Epoch: 5| Step: 2
Training loss: 1.470431886664286
Validation loss: 2.6758040898223063

Epoch: 5| Step: 3
Training loss: 1.7439879279025063
Validation loss: 2.6331750787994626

Epoch: 5| Step: 4
Training loss: 1.299291955258357
Validation loss: 2.6519575554168324

Epoch: 5| Step: 5
Training loss: 1.706388863303018
Validation loss: 2.7573740631366626

Epoch: 5| Step: 6
Training loss: 1.4221680726895605
Validation loss: 2.6931125360859864

Epoch: 5| Step: 7
Training loss: 1.6262401836782185
Validation loss: 2.6850134043415186

Epoch: 5| Step: 8
Training loss: 2.6346577593283462
Validation loss: 2.768344411427814

Epoch: 5| Step: 9
Training loss: 1.6130516498476712
Validation loss: 2.700626096571482

Epoch: 5| Step: 10
Training loss: 2.0098168725244556
Validation loss: 2.6288050480446725

Epoch: 5| Step: 11
Training loss: 1.5987255742978725
Validation loss: 2.6373886274714957

Epoch: 170| Step: 0
Training loss: 1.5384621005790857
Validation loss: 2.709391373816222

Epoch: 5| Step: 1
Training loss: 1.8154118923322637
Validation loss: 2.704042040260603

Epoch: 5| Step: 2
Training loss: 1.8567438181605629
Validation loss: 2.826198930134129

Epoch: 5| Step: 3
Training loss: 1.8157149773525976
Validation loss: 2.780298087990357

Epoch: 5| Step: 4
Training loss: 1.8204696652913759
Validation loss: 2.837565988734011

Epoch: 5| Step: 5
Training loss: 1.1551995531900234
Validation loss: 2.7364055305839705

Epoch: 5| Step: 6
Training loss: 1.8309061137639506
Validation loss: 2.7764601251909298

Epoch: 5| Step: 7
Training loss: 2.4447169934638864
Validation loss: 2.6161852041860647

Epoch: 5| Step: 8
Training loss: 1.369537034922871
Validation loss: 2.6097038846039653

Epoch: 5| Step: 9
Training loss: 1.9050070665884238
Validation loss: 2.6163606884416875

Epoch: 5| Step: 10
Training loss: 1.7508715094365899
Validation loss: 2.589306040505553

Epoch: 5| Step: 11
Training loss: 2.6747190274424977
Validation loss: 2.6384887443523124

Epoch: 171| Step: 0
Training loss: 2.312923083394099
Validation loss: 2.639554527193777

Epoch: 5| Step: 1
Training loss: 2.030276255860237
Validation loss: 2.5945522645587262

Epoch: 5| Step: 2
Training loss: 1.442247346936115
Validation loss: 2.624261873403293

Epoch: 5| Step: 3
Training loss: 1.1795265643761614
Validation loss: 2.6542172376724533

Epoch: 5| Step: 4
Training loss: 1.7775072630399888
Validation loss: 2.533225277794274

Epoch: 5| Step: 5
Training loss: 1.6421716574967267
Validation loss: 2.59543864881199

Epoch: 5| Step: 6
Training loss: 1.8337855287112146
Validation loss: 2.703821687828204

Epoch: 5| Step: 7
Training loss: 1.8771178682334935
Validation loss: 2.644692777117327

Epoch: 5| Step: 8
Training loss: 0.9986250484828004
Validation loss: 2.67203362497832

Epoch: 5| Step: 9
Training loss: 1.9778940291951204
Validation loss: 2.694256410695961

Epoch: 5| Step: 10
Training loss: 1.7583445782173812
Validation loss: 2.7504667550676967

Epoch: 5| Step: 11
Training loss: 1.4833118044258833
Validation loss: 2.6685353613429603

Epoch: 172| Step: 0
Training loss: 1.8701074345984263
Validation loss: 2.8140827635028978

Epoch: 5| Step: 1
Training loss: 2.3420137204779006
Validation loss: 2.7515370668343855

Epoch: 5| Step: 2
Training loss: 1.4591268651135492
Validation loss: 2.714093819647795

Epoch: 5| Step: 3
Training loss: 1.6609621492927094
Validation loss: 2.7127070262970143

Epoch: 5| Step: 4
Training loss: 1.6376731839217573
Validation loss: 2.6211770656057864

Epoch: 5| Step: 5
Training loss: 1.8546722951392727
Validation loss: 2.7036596956426164

Epoch: 5| Step: 6
Training loss: 2.5236599000413387
Validation loss: 2.719768709670013

Epoch: 5| Step: 7
Training loss: 1.2511508888678387
Validation loss: 2.6205030781049046

Epoch: 5| Step: 8
Training loss: 1.6875979077228778
Validation loss: 2.6955597455424

Epoch: 5| Step: 9
Training loss: 1.2591847581319011
Validation loss: 2.649739593330902

Epoch: 5| Step: 10
Training loss: 1.446749081498127
Validation loss: 2.6902134083185207

Epoch: 5| Step: 11
Training loss: 0.878975454360956
Validation loss: 2.7357204796340224

Epoch: 173| Step: 0
Training loss: 1.2403391395835501
Validation loss: 2.6373926540122414

Epoch: 5| Step: 1
Training loss: 2.080432729090512
Validation loss: 2.684073936890168

Epoch: 5| Step: 2
Training loss: 1.6288898567820183
Validation loss: 2.675484990335365

Epoch: 5| Step: 3
Training loss: 1.9251636187883994
Validation loss: 2.7092032111535014

Epoch: 5| Step: 4
Training loss: 1.879437472615266
Validation loss: 2.679939247072596

Epoch: 5| Step: 5
Training loss: 1.8287242983030825
Validation loss: 2.6711952579204477

Epoch: 5| Step: 6
Training loss: 1.6951390894083547
Validation loss: 2.678143099794537

Epoch: 5| Step: 7
Training loss: 2.039155570642951
Validation loss: 2.7402879596889904

Epoch: 5| Step: 8
Training loss: 1.2841299301196898
Validation loss: 2.656177949863199

Epoch: 5| Step: 9
Training loss: 1.6468239068750268
Validation loss: 2.675120943743044

Epoch: 5| Step: 10
Training loss: 1.3472914934647315
Validation loss: 2.715003902184859

Epoch: 5| Step: 11
Training loss: 0.7945161951189764
Validation loss: 2.727563209850201

Epoch: 174| Step: 0
Training loss: 1.4135799954680108
Validation loss: 2.6314494814731537

Epoch: 5| Step: 1
Training loss: 1.9119575603874628
Validation loss: 2.668598702018487

Epoch: 5| Step: 2
Training loss: 1.7011241533875907
Validation loss: 2.702841620760121

Epoch: 5| Step: 3
Training loss: 2.434866338269022
Validation loss: 2.635198238553617

Epoch: 5| Step: 4
Training loss: 1.7257475159345508
Validation loss: 2.626331634935215

Epoch: 5| Step: 5
Training loss: 1.535063762645172
Validation loss: 2.5632553906169653

Epoch: 5| Step: 6
Training loss: 1.4887402244778616
Validation loss: 2.583971899593087

Epoch: 5| Step: 7
Training loss: 2.104643084787362
Validation loss: 2.6774013506041165

Epoch: 5| Step: 8
Training loss: 1.7147229267212776
Validation loss: 2.6760218676860097

Epoch: 5| Step: 9
Training loss: 1.4395237650418415
Validation loss: 2.7482465514675534

Epoch: 5| Step: 10
Training loss: 1.2088311364794575
Validation loss: 2.6716945282365208

Epoch: 5| Step: 11
Training loss: 1.4652286278233895
Validation loss: 2.7212765562437755

Epoch: 175| Step: 0
Training loss: 1.3136214959826296
Validation loss: 2.676122059894606

Epoch: 5| Step: 1
Training loss: 2.1678834090748045
Validation loss: 2.761272971773068

Epoch: 5| Step: 2
Training loss: 2.660800043700878
Validation loss: 2.7740871116397554

Epoch: 5| Step: 3
Training loss: 1.1357451264203162
Validation loss: 2.7426858831274727

Epoch: 5| Step: 4
Training loss: 1.400643170301446
Validation loss: 2.7500077124689786

Epoch: 5| Step: 5
Training loss: 1.5252278298462896
Validation loss: 2.7051831203241012

Epoch: 5| Step: 6
Training loss: 1.4497947679170282
Validation loss: 2.678123195473988

Epoch: 5| Step: 7
Training loss: 1.6750104505298333
Validation loss: 2.6979348514685366

Epoch: 5| Step: 8
Training loss: 1.5531607180504439
Validation loss: 2.826939669880094

Epoch: 5| Step: 9
Training loss: 1.9275103808963352
Validation loss: 2.645058467119035

Epoch: 5| Step: 10
Training loss: 1.4474530015078544
Validation loss: 2.795643750332605

Epoch: 5| Step: 11
Training loss: 0.5340028571256005
Validation loss: 2.6340850184779163

Epoch: 176| Step: 0
Training loss: 1.8553698704121842
Validation loss: 2.6626434387528004

Epoch: 5| Step: 1
Training loss: 1.4840002289537937
Validation loss: 2.6721806825370846

Epoch: 5| Step: 2
Training loss: 1.2632085077389432
Validation loss: 2.769819057272259

Epoch: 5| Step: 3
Training loss: 1.695371846509494
Validation loss: 2.6741018440799995

Epoch: 5| Step: 4
Training loss: 1.5773466097922473
Validation loss: 2.652157308311431

Epoch: 5| Step: 5
Training loss: 1.755218626571342
Validation loss: 2.6657372260609415

Epoch: 5| Step: 6
Training loss: 1.7033632444279938
Validation loss: 2.7209735543356044

Epoch: 5| Step: 7
Training loss: 1.103312677946872
Validation loss: 2.6805598893621942

Epoch: 5| Step: 8
Training loss: 2.744539561749085
Validation loss: 2.594978868696139

Epoch: 5| Step: 9
Training loss: 1.699261754686591
Validation loss: 2.7143914118033554

Epoch: 5| Step: 10
Training loss: 1.4768865320608633
Validation loss: 2.8056613007268645

Epoch: 5| Step: 11
Training loss: 1.914239493769799
Validation loss: 2.7015107172865735

Epoch: 177| Step: 0
Training loss: 1.3981597880374141
Validation loss: 2.7943143933051093

Epoch: 5| Step: 1
Training loss: 1.7115684983066708
Validation loss: 2.7298031724754632

Epoch: 5| Step: 2
Training loss: 2.1214059842271
Validation loss: 2.7603580480625465

Epoch: 5| Step: 3
Training loss: 1.4086760045735165
Validation loss: 2.603085855630085

Epoch: 5| Step: 4
Training loss: 2.4625554654608677
Validation loss: 2.6651393917624278

Epoch: 5| Step: 5
Training loss: 1.6173197374320138
Validation loss: 2.6965012071402725

Epoch: 5| Step: 6
Training loss: 1.6147421071730348
Validation loss: 2.7020526846503135

Epoch: 5| Step: 7
Training loss: 1.3225015855141493
Validation loss: 2.577693833796686

Epoch: 5| Step: 8
Training loss: 1.94030067080214
Validation loss: 2.6657130329343013

Epoch: 5| Step: 9
Training loss: 1.4041627440506266
Validation loss: 2.6151693277624037

Epoch: 5| Step: 10
Training loss: 0.991682329508294
Validation loss: 2.8295306265654743

Epoch: 5| Step: 11
Training loss: 0.9676049140606694
Validation loss: 2.7491092503616774

Epoch: 178| Step: 0
Training loss: 1.0143697758021244
Validation loss: 2.7683718092237113

Epoch: 5| Step: 1
Training loss: 1.65867624172031
Validation loss: 2.761306688789702

Epoch: 5| Step: 2
Training loss: 1.3198111219811257
Validation loss: 2.7609656753642375

Epoch: 5| Step: 3
Training loss: 2.4736119934723977
Validation loss: 2.664520023022318

Epoch: 5| Step: 4
Training loss: 1.880768802478352
Validation loss: 2.860593313878319

Epoch: 5| Step: 5
Training loss: 1.513393371556223
Validation loss: 2.657295724309148

Epoch: 5| Step: 6
Training loss: 1.6944818527317018
Validation loss: 2.6679751469175654

Epoch: 5| Step: 7
Training loss: 1.6518564790863006
Validation loss: 2.670534645425073

Epoch: 5| Step: 8
Training loss: 1.511086659529705
Validation loss: 2.597181019538362

Epoch: 5| Step: 9
Training loss: 1.6436995988088174
Validation loss: 2.701662774299894

Epoch: 5| Step: 10
Training loss: 2.007934210387235
Validation loss: 2.7388827959682414

Epoch: 5| Step: 11
Training loss: 1.3908988597253322
Validation loss: 2.6449756220792056

Epoch: 179| Step: 0
Training loss: 1.7697697830269228
Validation loss: 2.6790975879664645

Epoch: 5| Step: 1
Training loss: 1.6600953573391453
Validation loss: 2.634622628884563

Epoch: 5| Step: 2
Training loss: 1.1978536285178558
Validation loss: 2.6969256415830185

Epoch: 5| Step: 3
Training loss: 1.4753441199057604
Validation loss: 2.649161733967918

Epoch: 5| Step: 4
Training loss: 1.2558682027598465
Validation loss: 2.7649103523676755

Epoch: 5| Step: 5
Training loss: 1.639404351411252
Validation loss: 2.73651104283232

Epoch: 5| Step: 6
Training loss: 1.6840596627519258
Validation loss: 2.7722109522576637

Epoch: 5| Step: 7
Training loss: 1.6526190345817495
Validation loss: 2.731660527322685

Epoch: 5| Step: 8
Training loss: 1.5360585441508927
Validation loss: 2.754682207021318

Epoch: 5| Step: 9
Training loss: 1.7190097265806077
Validation loss: 2.851822343945311

Epoch: 5| Step: 10
Training loss: 2.021738053036653
Validation loss: 2.718717739308446

Epoch: 5| Step: 11
Training loss: 1.0803757545462378
Validation loss: 2.765133289584495

Epoch: 180| Step: 0
Training loss: 1.613485549663454
Validation loss: 2.6796006298905843

Epoch: 5| Step: 1
Training loss: 1.455693917254311
Validation loss: 2.678515742495121

Epoch: 5| Step: 2
Training loss: 1.6867518002557145
Validation loss: 2.8188245340545754

Epoch: 5| Step: 3
Training loss: 2.3056330406108736
Validation loss: 2.7916847496490877

Epoch: 5| Step: 4
Training loss: 1.9806328278540657
Validation loss: 2.642497390149096

Epoch: 5| Step: 5
Training loss: 1.3212714691005796
Validation loss: 2.7607608988392847

Epoch: 5| Step: 6
Training loss: 1.3830401561862393
Validation loss: 2.70875500856496

Epoch: 5| Step: 7
Training loss: 1.5112301532208878
Validation loss: 2.692963607734483

Epoch: 5| Step: 8
Training loss: 2.0935467293978913
Validation loss: 2.779820789345755

Epoch: 5| Step: 9
Training loss: 1.4606912170731094
Validation loss: 2.695364946970008

Epoch: 5| Step: 10
Training loss: 1.3400548651836128
Validation loss: 2.726164569253712

Epoch: 5| Step: 11
Training loss: 2.50709956127475
Validation loss: 2.7537484775376813

Epoch: 181| Step: 0
Training loss: 1.8433798078894765
Validation loss: 2.7740052765844427

Epoch: 5| Step: 1
Training loss: 2.1086491218863745
Validation loss: 2.736643429727983

Epoch: 5| Step: 2
Training loss: 1.1040388909068772
Validation loss: 2.8026152015009886

Epoch: 5| Step: 3
Training loss: 2.253147361104744
Validation loss: 2.741932022931305

Epoch: 5| Step: 4
Training loss: 1.4584265361248723
Validation loss: 2.721827603032226

Epoch: 5| Step: 5
Training loss: 1.4691065903250766
Validation loss: 2.806507837476581

Epoch: 5| Step: 6
Training loss: 1.555450252344417
Validation loss: 2.77201612343372

Epoch: 5| Step: 7
Training loss: 1.2483157732347718
Validation loss: 2.776153549077312

Epoch: 5| Step: 8
Training loss: 1.5999589288923812
Validation loss: 2.7676976693411794

Epoch: 5| Step: 9
Training loss: 1.6209554957988055
Validation loss: 2.840389858595176

Epoch: 5| Step: 10
Training loss: 1.698227165554967
Validation loss: 2.5960966088976343

Epoch: 5| Step: 11
Training loss: 1.959669090480163
Validation loss: 2.8063370609726146

Epoch: 182| Step: 0
Training loss: 1.7082896188244683
Validation loss: 2.640168882324234

Epoch: 5| Step: 1
Training loss: 1.5872347182047268
Validation loss: 2.7011347851122673

Epoch: 5| Step: 2
Training loss: 1.7165773704908338
Validation loss: 2.736263454997262

Epoch: 5| Step: 3
Training loss: 2.0779953536127627
Validation loss: 2.691134497695732

Epoch: 5| Step: 4
Training loss: 1.1581443527259885
Validation loss: 2.6771941304316766

Epoch: 5| Step: 5
Training loss: 2.2942482596826537
Validation loss: 2.7363286042196004

Epoch: 5| Step: 6
Training loss: 1.6914806041276425
Validation loss: 2.8057595756888767

Epoch: 5| Step: 7
Training loss: 1.1490622657026603
Validation loss: 2.6954321645811157

Epoch: 5| Step: 8
Training loss: 1.4830505887416956
Validation loss: 2.71762910661375

Epoch: 5| Step: 9
Training loss: 1.7677340444007403
Validation loss: 2.667921997673463

Epoch: 5| Step: 10
Training loss: 1.7495847618107492
Validation loss: 2.755565048134341

Epoch: 5| Step: 11
Training loss: 0.7232551773392322
Validation loss: 2.761996833005761

Epoch: 183| Step: 0
Training loss: 1.3517345252840098
Validation loss: 2.711785190346792

Epoch: 5| Step: 1
Training loss: 1.9304367649418954
Validation loss: 2.7355602093580913

Epoch: 5| Step: 2
Training loss: 1.4937386165169182
Validation loss: 2.7080876214489344

Epoch: 5| Step: 3
Training loss: 1.3830820456694175
Validation loss: 2.6343189499014397

Epoch: 5| Step: 4
Training loss: 2.2761685985609033
Validation loss: 2.6213778679590565

Epoch: 5| Step: 5
Training loss: 1.2843254673820326
Validation loss: 2.6892517465085324

Epoch: 5| Step: 6
Training loss: 1.2542348650938613
Validation loss: 2.714604461882411

Epoch: 5| Step: 7
Training loss: 1.8883536069656512
Validation loss: 2.733912634131985

Epoch: 5| Step: 8
Training loss: 1.8606871775270355
Validation loss: 2.715120937184146

Epoch: 5| Step: 9
Training loss: 1.4903584399894634
Validation loss: 2.767504080654813

Epoch: 5| Step: 10
Training loss: 1.6229929633889992
Validation loss: 2.753812177778333

Epoch: 5| Step: 11
Training loss: 1.1398328355733343
Validation loss: 2.7655743524256504

Epoch: 184| Step: 0
Training loss: 1.2369796699389053
Validation loss: 2.672607481347153

Epoch: 5| Step: 1
Training loss: 1.658151362928853
Validation loss: 2.7132205931824056

Epoch: 5| Step: 2
Training loss: 1.443795144832642
Validation loss: 2.741230996183875

Epoch: 5| Step: 3
Training loss: 1.7192730194543226
Validation loss: 2.731859065116792

Epoch: 5| Step: 4
Training loss: 1.2165500641605378
Validation loss: 2.700696607783781

Epoch: 5| Step: 5
Training loss: 1.4849595374557716
Validation loss: 2.6190357647148637

Epoch: 5| Step: 6
Training loss: 1.2145540437825542
Validation loss: 2.7581980672574824

Epoch: 5| Step: 7
Training loss: 1.5130078243499567
Validation loss: 2.7783010042991205

Epoch: 5| Step: 8
Training loss: 2.2562459507110693
Validation loss: 2.7566639396910766

Epoch: 5| Step: 9
Training loss: 1.4525534213250053
Validation loss: 2.755238690897102

Epoch: 5| Step: 10
Training loss: 1.4333855168505758
Validation loss: 2.6646548719150656

Epoch: 5| Step: 11
Training loss: 2.095162783286888
Validation loss: 2.7446483572235767

Epoch: 185| Step: 0
Training loss: 1.3683589603163178
Validation loss: 2.6930868939058468

Epoch: 5| Step: 1
Training loss: 1.8716121584574597
Validation loss: 2.671608024777764

Epoch: 5| Step: 2
Training loss: 1.284229953492824
Validation loss: 2.774260181320661

Epoch: 5| Step: 3
Training loss: 1.1783762332565444
Validation loss: 2.6920100412830985

Epoch: 5| Step: 4
Training loss: 1.5936619603392677
Validation loss: 2.8217039295104955

Epoch: 5| Step: 5
Training loss: 1.2503462311938713
Validation loss: 2.7039792469557202

Epoch: 5| Step: 6
Training loss: 1.5756695974016193
Validation loss: 2.7920040500847407

Epoch: 5| Step: 7
Training loss: 1.6954882130777038
Validation loss: 2.7005164067603937

Epoch: 5| Step: 8
Training loss: 1.7970472833720672
Validation loss: 2.6506216144847468

Epoch: 5| Step: 9
Training loss: 2.1985185230022255
Validation loss: 2.696921619205363

Epoch: 5| Step: 10
Training loss: 0.9120469980741203
Validation loss: 2.732551159003152

Epoch: 5| Step: 11
Training loss: 2.6319670182744357
Validation loss: 2.886789612681066

Epoch: 186| Step: 0
Training loss: 1.2359519253550846
Validation loss: 2.836167010083252

Epoch: 5| Step: 1
Training loss: 1.305519158733019
Validation loss: 2.8914160634063006

Epoch: 5| Step: 2
Training loss: 1.4988764687725726
Validation loss: 2.9289268591287914

Epoch: 5| Step: 3
Training loss: 1.614816743120124
Validation loss: 2.8433071986443683

Epoch: 5| Step: 4
Training loss: 1.9695415419385682
Validation loss: 2.7568497801003122

Epoch: 5| Step: 5
Training loss: 2.2097340466065543
Validation loss: 2.7029420353409668

Epoch: 5| Step: 6
Training loss: 1.6901106244058381
Validation loss: 2.7898683354428484

Epoch: 5| Step: 7
Training loss: 1.3839193967875476
Validation loss: 2.821998250895201

Epoch: 5| Step: 8
Training loss: 1.703415452180786
Validation loss: 2.766176104189921

Epoch: 5| Step: 9
Training loss: 1.432039421295478
Validation loss: 2.6669195931908707

Epoch: 5| Step: 10
Training loss: 1.6578357950168454
Validation loss: 2.662927312991327

Epoch: 5| Step: 11
Training loss: 1.4213041060724747
Validation loss: 2.771735945420903

Epoch: 187| Step: 0
Training loss: 1.5193628840589106
Validation loss: 2.7612975616353777

Epoch: 5| Step: 1
Training loss: 1.3489507677413501
Validation loss: 2.6249097059251585

Epoch: 5| Step: 2
Training loss: 1.4397586824288127
Validation loss: 2.752579801097326

Epoch: 5| Step: 3
Training loss: 1.53248102957355
Validation loss: 2.8323257784223217

Epoch: 5| Step: 4
Training loss: 2.134177864320398
Validation loss: 2.8322303719509527

Epoch: 5| Step: 5
Training loss: 1.683537245508082
Validation loss: 2.8010457657490493

Epoch: 5| Step: 6
Training loss: 1.9821010987781598
Validation loss: 2.917129389070519

Epoch: 5| Step: 7
Training loss: 1.3208139584601455
Validation loss: 2.9288788590770407

Epoch: 5| Step: 8
Training loss: 1.3406976142193427
Validation loss: 2.779157665892004

Epoch: 5| Step: 9
Training loss: 1.3860247957590526
Validation loss: 2.9059574191849995

Epoch: 5| Step: 10
Training loss: 1.676358992569791
Validation loss: 2.7214434790062905

Epoch: 5| Step: 11
Training loss: 1.6983979446030344
Validation loss: 2.801363077209219

Epoch: 188| Step: 0
Training loss: 1.4288876490062703
Validation loss: 2.7134345369675374

Epoch: 5| Step: 1
Training loss: 1.7347446769372106
Validation loss: 2.6130326765335816

Epoch: 5| Step: 2
Training loss: 1.7252713031545286
Validation loss: 2.7476869233065893

Epoch: 5| Step: 3
Training loss: 2.297760254374784
Validation loss: 2.729269387348033

Epoch: 5| Step: 4
Training loss: 1.4985783515738054
Validation loss: 2.6604196359253884

Epoch: 5| Step: 5
Training loss: 1.1980192665722484
Validation loss: 2.74106728259235

Epoch: 5| Step: 6
Training loss: 1.7063295506527771
Validation loss: 2.7443232718758623

Epoch: 5| Step: 7
Training loss: 1.4778154496639222
Validation loss: 2.7274671873571728

Epoch: 5| Step: 8
Training loss: 1.6584977785681545
Validation loss: 2.793400963550266

Epoch: 5| Step: 9
Training loss: 1.1656594810806156
Validation loss: 2.6594044934380663

Epoch: 5| Step: 10
Training loss: 1.4429339658203413
Validation loss: 2.7158435965478027

Epoch: 5| Step: 11
Training loss: 1.5912592254874673
Validation loss: 2.702421078325026

Epoch: 189| Step: 0
Training loss: 1.7775471665231495
Validation loss: 2.8482639900912394

Epoch: 5| Step: 1
Training loss: 1.134528603150748
Validation loss: 2.705805293099344

Epoch: 5| Step: 2
Training loss: 1.6768666555884488
Validation loss: 2.699882639141559

Epoch: 5| Step: 3
Training loss: 2.381328383229498
Validation loss: 2.805869569741777

Epoch: 5| Step: 4
Training loss: 1.0123638909301842
Validation loss: 2.692103250919218

Epoch: 5| Step: 5
Training loss: 1.5553426464394435
Validation loss: 2.6633347704071477

Epoch: 5| Step: 6
Training loss: 1.6741293566002047
Validation loss: 2.7443233877118627

Epoch: 5| Step: 7
Training loss: 1.810623052119984
Validation loss: 2.7590382889332616

Epoch: 5| Step: 8
Training loss: 1.577184037789962
Validation loss: 2.7953603788383337

Epoch: 5| Step: 9
Training loss: 1.273243895247359
Validation loss: 2.7130757198443876

Epoch: 5| Step: 10
Training loss: 1.5143007608653243
Validation loss: 2.7608607252895907

Epoch: 5| Step: 11
Training loss: 1.038798191040632
Validation loss: 2.6812300954760153

Epoch: 190| Step: 0
Training loss: 1.4712100428208903
Validation loss: 2.828520035947709

Epoch: 5| Step: 1
Training loss: 1.502141536408621
Validation loss: 2.7532001212324952

Epoch: 5| Step: 2
Training loss: 1.730706743188273
Validation loss: 2.7551115243750446

Epoch: 5| Step: 3
Training loss: 2.1171683560452523
Validation loss: 2.7342217284342456

Epoch: 5| Step: 4
Training loss: 1.0637797334238352
Validation loss: 2.682925869059541

Epoch: 5| Step: 5
Training loss: 1.7215267293042134
Validation loss: 2.7988135263577365

Epoch: 5| Step: 6
Training loss: 1.5724190773329934
Validation loss: 2.6127763649143145

Epoch: 5| Step: 7
Training loss: 1.7437147622325126
Validation loss: 2.6976562924223497

Epoch: 5| Step: 8
Training loss: 1.6628690209664418
Validation loss: 2.6554483662625668

Epoch: 5| Step: 9
Training loss: 1.4723676403770782
Validation loss: 2.8265841907619995

Epoch: 5| Step: 10
Training loss: 1.4287793553124262
Validation loss: 2.7424802741596364

Epoch: 5| Step: 11
Training loss: 1.1121789661925758
Validation loss: 2.6907350268815846

Epoch: 191| Step: 0
Training loss: 1.2669959472675736
Validation loss: 2.725123937731043

Epoch: 5| Step: 1
Training loss: 1.5516295142938232
Validation loss: 2.7713025754587983

Epoch: 5| Step: 2
Training loss: 1.097318060964108
Validation loss: 2.709251190812092

Epoch: 5| Step: 3
Training loss: 1.35902944097004
Validation loss: 2.7382535039681435

Epoch: 5| Step: 4
Training loss: 1.478204450024552
Validation loss: 2.753580450170785

Epoch: 5| Step: 5
Training loss: 2.1795089812648314
Validation loss: 2.8370832960696775

Epoch: 5| Step: 6
Training loss: 1.7785220757058917
Validation loss: 2.742471269087866

Epoch: 5| Step: 7
Training loss: 1.392795198062198
Validation loss: 2.8603124940374083

Epoch: 5| Step: 8
Training loss: 1.40019094833905
Validation loss: 2.701905410916657

Epoch: 5| Step: 9
Training loss: 1.2448588503446862
Validation loss: 2.8292887595793834

Epoch: 5| Step: 10
Training loss: 1.2542725500399148
Validation loss: 2.701832607512349

Epoch: 5| Step: 11
Training loss: 1.560019622459245
Validation loss: 2.7495206483743244

Epoch: 192| Step: 0
Training loss: 1.119922943700168
Validation loss: 2.7584942307369547

Epoch: 5| Step: 1
Training loss: 1.4467878080588914
Validation loss: 2.6700557925375485

Epoch: 5| Step: 2
Training loss: 1.438929220482873
Validation loss: 2.6672515109842707

Epoch: 5| Step: 3
Training loss: 1.2432537181375987
Validation loss: 2.766868861165549

Epoch: 5| Step: 4
Training loss: 1.612592277547917
Validation loss: 2.7019550165568043

Epoch: 5| Step: 5
Training loss: 1.474146405230483
Validation loss: 2.7569028130299222

Epoch: 5| Step: 6
Training loss: 1.5632558901596683
Validation loss: 2.7030682236252606

Epoch: 5| Step: 7
Training loss: 1.3789575151201976
Validation loss: 2.7624096831205125

Epoch: 5| Step: 8
Training loss: 1.6871384127309053
Validation loss: 2.733637425082034

Epoch: 5| Step: 9
Training loss: 2.102130231784667
Validation loss: 2.7072245504512473

Epoch: 5| Step: 10
Training loss: 1.384236480809465
Validation loss: 2.74201015974913

Epoch: 5| Step: 11
Training loss: 0.4508250501169073
Validation loss: 2.7338141383848185

Epoch: 193| Step: 0
Training loss: 1.2886652941389778
Validation loss: 2.7602273492251412

Epoch: 5| Step: 1
Training loss: 2.126380696257723
Validation loss: 2.715717561093265

Epoch: 5| Step: 2
Training loss: 1.5626641759451154
Validation loss: 2.713799333816559

Epoch: 5| Step: 3
Training loss: 1.8774718204014054
Validation loss: 2.674342397419924

Epoch: 5| Step: 4
Training loss: 1.1884849880299124
Validation loss: 2.8493539243792934

Epoch: 5| Step: 5
Training loss: 1.0146986037511176
Validation loss: 2.678879307355253

Epoch: 5| Step: 6
Training loss: 1.520472139639541
Validation loss: 2.720143646091832

Epoch: 5| Step: 7
Training loss: 0.8959338590124184
Validation loss: 2.670533678252296

Epoch: 5| Step: 8
Training loss: 1.4376869080148482
Validation loss: 2.7056978179221947

Epoch: 5| Step: 9
Training loss: 1.4662548541861051
Validation loss: 2.73223501115922

Epoch: 5| Step: 10
Training loss: 1.4058649595615542
Validation loss: 2.7746566027306483

Epoch: 5| Step: 11
Training loss: 1.4134823784122783
Validation loss: 2.706584811037742

Epoch: 194| Step: 0
Training loss: 1.3681145712854512
Validation loss: 2.731752576788211

Epoch: 5| Step: 1
Training loss: 1.3387583348204442
Validation loss: 2.8173196610326454

Epoch: 5| Step: 2
Training loss: 1.3089379612302057
Validation loss: 2.7849384470591825

Epoch: 5| Step: 3
Training loss: 1.3685533077406702
Validation loss: 2.845762037070184

Epoch: 5| Step: 4
Training loss: 1.4143280285812128
Validation loss: 2.857457793247525

Epoch: 5| Step: 5
Training loss: 1.0601604734264967
Validation loss: 2.9523864239632465

Epoch: 5| Step: 6
Training loss: 1.483826465644927
Validation loss: 2.86830719644891

Epoch: 5| Step: 7
Training loss: 1.3940391206437694
Validation loss: 2.8619973954698277

Epoch: 5| Step: 8
Training loss: 1.821669109874505
Validation loss: 2.8038842087789266

Epoch: 5| Step: 9
Training loss: 2.2176362586922815
Validation loss: 2.8423053474453988

Epoch: 5| Step: 10
Training loss: 1.8716696089973093
Validation loss: 2.7736191596055186

Epoch: 5| Step: 11
Training loss: 0.9147964530465735
Validation loss: 2.7214680016663304

Epoch: 195| Step: 0
Training loss: 1.4281676505166254
Validation loss: 2.7674595052047466

Epoch: 5| Step: 1
Training loss: 1.4067299341750579
Validation loss: 2.676828907900747

Epoch: 5| Step: 2
Training loss: 1.0628368741218202
Validation loss: 2.774926211404215

Epoch: 5| Step: 3
Training loss: 1.1394649511540262
Validation loss: 2.778524527840948

Epoch: 5| Step: 4
Training loss: 0.8979118136092616
Validation loss: 2.7419515654962736

Epoch: 5| Step: 5
Training loss: 1.4524181656756496
Validation loss: 2.794809050807472

Epoch: 5| Step: 6
Training loss: 1.5128574863136526
Validation loss: 2.8392399561862995

Epoch: 5| Step: 7
Training loss: 2.414410019832167
Validation loss: 2.8393582222406666

Epoch: 5| Step: 8
Training loss: 1.7614378440863907
Validation loss: 2.77787605403197

Epoch: 5| Step: 9
Training loss: 1.3750775488746103
Validation loss: 2.7705367271358616

Epoch: 5| Step: 10
Training loss: 1.7551205515960338
Validation loss: 2.8415287481233475

Epoch: 5| Step: 11
Training loss: 1.3763192090641447
Validation loss: 2.741648451668274

Epoch: 196| Step: 0
Training loss: 1.238754422731328
Validation loss: 2.755833110868916

Epoch: 5| Step: 1
Training loss: 1.1642106237193166
Validation loss: 2.779454977149974

Epoch: 5| Step: 2
Training loss: 1.117338957223494
Validation loss: 2.737993835660554

Epoch: 5| Step: 3
Training loss: 1.2941676456245474
Validation loss: 2.782664143089895

Epoch: 5| Step: 4
Training loss: 1.227147734182066
Validation loss: 2.7254987024105763

Epoch: 5| Step: 5
Training loss: 2.4300525059933924
Validation loss: 2.755478664806134

Epoch: 5| Step: 6
Training loss: 1.231858307499385
Validation loss: 2.769156505517477

Epoch: 5| Step: 7
Training loss: 1.3397246549742732
Validation loss: 2.8079448015662334

Epoch: 5| Step: 8
Training loss: 1.5602547344667093
Validation loss: 2.7504149994404217

Epoch: 5| Step: 9
Training loss: 1.2279560895083423
Validation loss: 2.7755773285990486

Epoch: 5| Step: 10
Training loss: 1.809590207282366
Validation loss: 2.752949877310038

Epoch: 5| Step: 11
Training loss: 1.107945770726881
Validation loss: 2.753534806905774

Epoch: 197| Step: 0
Training loss: 1.3210652930896176
Validation loss: 2.735270293668582

Epoch: 5| Step: 1
Training loss: 1.2119400304429822
Validation loss: 2.699385384376774

Epoch: 5| Step: 2
Training loss: 1.0519656628563774
Validation loss: 2.701761232460939

Epoch: 5| Step: 3
Training loss: 1.294635493628697
Validation loss: 2.6139426465935864

Epoch: 5| Step: 4
Training loss: 1.3095486928590365
Validation loss: 2.7180465869845483

Epoch: 5| Step: 5
Training loss: 1.303749478231236
Validation loss: 2.7490536369078806

Epoch: 5| Step: 6
Training loss: 1.9823427983189479
Validation loss: 2.821824211967518

Epoch: 5| Step: 7
Training loss: 1.3289488088710308
Validation loss: 2.80242153995972

Epoch: 5| Step: 8
Training loss: 1.4774251365736564
Validation loss: 2.8717196173794335

Epoch: 5| Step: 9
Training loss: 2.0319983644328707
Validation loss: 2.7760838433235264

Epoch: 5| Step: 10
Training loss: 1.3162466342951826
Validation loss: 2.8785839875251087

Epoch: 5| Step: 11
Training loss: 1.7354567307529727
Validation loss: 2.8871328102522904

Epoch: 198| Step: 0
Training loss: 1.3954301602947141
Validation loss: 2.8598170885425422

Epoch: 5| Step: 1
Training loss: 1.3015007343268181
Validation loss: 2.8347630341375947

Epoch: 5| Step: 2
Training loss: 1.0537474222027257
Validation loss: 2.861246274920975

Epoch: 5| Step: 3
Training loss: 1.5414703433153292
Validation loss: 2.816287235279682

Epoch: 5| Step: 4
Training loss: 1.5394712573369949
Validation loss: 2.739491148704321

Epoch: 5| Step: 5
Training loss: 1.0271241856330724
Validation loss: 2.9397946147747573

Epoch: 5| Step: 6
Training loss: 1.3088722046614696
Validation loss: 2.8522912126402904

Epoch: 5| Step: 7
Training loss: 1.3333167532048906
Validation loss: 2.7448024146335865

Epoch: 5| Step: 8
Training loss: 2.277552600006129
Validation loss: 2.6560703198116684

Epoch: 5| Step: 9
Training loss: 1.8745862504312214
Validation loss: 2.807258801571626

Epoch: 5| Step: 10
Training loss: 1.5140283570903184
Validation loss: 2.7850183824655046

Epoch: 5| Step: 11
Training loss: 0.6238576940552595
Validation loss: 2.879252160666641

Epoch: 199| Step: 0
Training loss: 1.1950038935386402
Validation loss: 2.848154653183179

Epoch: 5| Step: 1
Training loss: 1.4857124326636737
Validation loss: 2.724905583586243

Epoch: 5| Step: 2
Training loss: 2.076835748678683
Validation loss: 2.8016471854248746

Epoch: 5| Step: 3
Training loss: 1.118616537306145
Validation loss: 2.7831270120486242

Epoch: 5| Step: 4
Training loss: 1.6294496210860496
Validation loss: 2.824646354162072

Epoch: 5| Step: 5
Training loss: 1.3129802914990263
Validation loss: 2.7666284569051247

Epoch: 5| Step: 6
Training loss: 1.2037398018409933
Validation loss: 2.9407062077432014

Epoch: 5| Step: 7
Training loss: 1.107983751067679
Validation loss: 2.7974094753942462

Epoch: 5| Step: 8
Training loss: 1.3637638494835544
Validation loss: 2.9085361366054543

Epoch: 5| Step: 9
Training loss: 1.2298239335373258
Validation loss: 2.7845121319214776

Epoch: 5| Step: 10
Training loss: 1.676339436647707
Validation loss: 2.8103327949079846

Epoch: 5| Step: 11
Training loss: 2.048615741904102
Validation loss: 2.861664322857868

Epoch: 200| Step: 0
Training loss: 1.1183419831496197
Validation loss: 2.8417167591106103

Epoch: 5| Step: 1
Training loss: 1.6886579284868586
Validation loss: 2.8084725754815834

Epoch: 5| Step: 2
Training loss: 1.0593798206861071
Validation loss: 2.8412513235469206

Epoch: 5| Step: 3
Training loss: 1.4451034807157606
Validation loss: 2.7820046861825283

Epoch: 5| Step: 4
Training loss: 1.3295448343235516
Validation loss: 2.758044677052891

Epoch: 5| Step: 5
Training loss: 1.0119551452413935
Validation loss: 2.836745631283987

Epoch: 5| Step: 6
Training loss: 1.4701338396970238
Validation loss: 2.800059031675995

Epoch: 5| Step: 7
Training loss: 2.14625488387337
Validation loss: 2.8207346669798317

Epoch: 5| Step: 8
Training loss: 1.25980035305209
Validation loss: 2.7343824150348213

Epoch: 5| Step: 9
Training loss: 1.6883921913790616
Validation loss: 2.7047342423826444

Epoch: 5| Step: 10
Training loss: 1.0034874068317254
Validation loss: 2.7786606940480154

Epoch: 5| Step: 11
Training loss: 1.5026422117850222
Validation loss: 2.7431118015097233

Epoch: 201| Step: 0
Training loss: 1.933369201568592
Validation loss: 2.7341087865666585

Epoch: 5| Step: 1
Training loss: 1.1950117742684625
Validation loss: 2.8142560104042067

Epoch: 5| Step: 2
Training loss: 0.9744797125358963
Validation loss: 2.761086995528855

Epoch: 5| Step: 3
Training loss: 1.4336394840606088
Validation loss: 2.8316899938073457

Epoch: 5| Step: 4
Training loss: 1.5744818001473886
Validation loss: 2.928552531484341

Epoch: 5| Step: 5
Training loss: 1.2275132788815881
Validation loss: 2.6980729272627615

Epoch: 5| Step: 6
Training loss: 1.475365532017054
Validation loss: 2.808294288258177

Epoch: 5| Step: 7
Training loss: 1.6291461283111952
Validation loss: 2.808114963799117

Epoch: 5| Step: 8
Training loss: 1.5931510547828518
Validation loss: 2.7736040253411547

Epoch: 5| Step: 9
Training loss: 1.292364157763582
Validation loss: 2.7522144865847817

Epoch: 5| Step: 10
Training loss: 1.266641938235852
Validation loss: 2.77935584357142

Epoch: 5| Step: 11
Training loss: 1.3165155472929433
Validation loss: 2.7892866267203433

Epoch: 202| Step: 0
Training loss: 1.0892459775033099
Validation loss: 2.8057263964128363

Epoch: 5| Step: 1
Training loss: 1.3084073061997672
Validation loss: 2.7593017389833228

Epoch: 5| Step: 2
Training loss: 1.2443019696450688
Validation loss: 2.8365423890285166

Epoch: 5| Step: 3
Training loss: 2.2433839589717643
Validation loss: 2.8332777099665796

Epoch: 5| Step: 4
Training loss: 1.292041780496011
Validation loss: 2.7357608698209748

Epoch: 5| Step: 5
Training loss: 1.7880303349748525
Validation loss: 2.837668907078906

Epoch: 5| Step: 6
Training loss: 1.427564702212795
Validation loss: 2.7955606913673137

Epoch: 5| Step: 7
Training loss: 1.395073109560236
Validation loss: 2.8081706245180595

Epoch: 5| Step: 8
Training loss: 1.1756676907370418
Validation loss: 2.81025684760978

Epoch: 5| Step: 9
Training loss: 1.648504174497651
Validation loss: 2.7939205157466156

Epoch: 5| Step: 10
Training loss: 0.7980794219383595
Validation loss: 2.7425342532580204

Epoch: 5| Step: 11
Training loss: 1.0209826665111226
Validation loss: 2.8985357276469794

Epoch: 203| Step: 0
Training loss: 1.3492914424325473
Validation loss: 2.768149823654332

Epoch: 5| Step: 1
Training loss: 1.44545328640215
Validation loss: 2.7358582352085827

Epoch: 5| Step: 2
Training loss: 1.3970621261026184
Validation loss: 2.8427177309295844

Epoch: 5| Step: 3
Training loss: 1.0309465135155453
Validation loss: 2.7364602375834655

Epoch: 5| Step: 4
Training loss: 1.8594252635669484
Validation loss: 2.758989286555632

Epoch: 5| Step: 5
Training loss: 0.953860827465046
Validation loss: 2.8062854967796316

Epoch: 5| Step: 6
Training loss: 1.36064689152515
Validation loss: 2.7488642337608997

Epoch: 5| Step: 7
Training loss: 1.040867378028293
Validation loss: 2.786915555620249

Epoch: 5| Step: 8
Training loss: 1.8548004553061512
Validation loss: 2.7639878235068918

Epoch: 5| Step: 9
Training loss: 1.3214404913832294
Validation loss: 2.7974237049404436

Epoch: 5| Step: 10
Training loss: 1.575290513871801
Validation loss: 2.9096550938781847

Epoch: 5| Step: 11
Training loss: 1.3310272370696357
Validation loss: 2.853648869099226

Epoch: 204| Step: 0
Training loss: 1.0217231194320615
Validation loss: 2.9195924128630817

Epoch: 5| Step: 1
Training loss: 1.1198686026232803
Validation loss: 2.7701519269283907

Epoch: 5| Step: 2
Training loss: 1.2237842463064612
Validation loss: 2.7672773156003005

Epoch: 5| Step: 3
Training loss: 1.450137194358364
Validation loss: 2.7060265045735865

Epoch: 5| Step: 4
Training loss: 1.7929905576356244
Validation loss: 2.8420541513571607

Epoch: 5| Step: 5
Training loss: 1.2683359945789812
Validation loss: 2.807981991273827

Epoch: 5| Step: 6
Training loss: 2.0312100920058
Validation loss: 2.8602889325339924

Epoch: 5| Step: 7
Training loss: 1.159182875515572
Validation loss: 2.8592033960097027

Epoch: 5| Step: 8
Training loss: 1.4135389254418567
Validation loss: 2.764440077917583

Epoch: 5| Step: 9
Training loss: 1.4064750067520664
Validation loss: 2.726789576156893

Epoch: 5| Step: 10
Training loss: 1.1597668029429697
Validation loss: 2.7079435575437154

Epoch: 5| Step: 11
Training loss: 1.9313177720310841
Validation loss: 2.8225715867349854

Epoch: 205| Step: 0
Training loss: 1.333296949168324
Validation loss: 2.8526111921458748

Epoch: 5| Step: 1
Training loss: 2.094238679707499
Validation loss: 2.746780783462735

Epoch: 5| Step: 2
Training loss: 1.2870646861166202
Validation loss: 2.657726498303244

Epoch: 5| Step: 3
Training loss: 1.1536926133751186
Validation loss: 2.716277457925154

Epoch: 5| Step: 4
Training loss: 1.387490157358811
Validation loss: 2.8057295865406218

Epoch: 5| Step: 5
Training loss: 1.2605070076505167
Validation loss: 2.8024867640695166

Epoch: 5| Step: 6
Training loss: 1.3694054188346592
Validation loss: 2.753538001580137

Epoch: 5| Step: 7
Training loss: 1.0066779204133232
Validation loss: 2.794191991589061

Epoch: 5| Step: 8
Training loss: 1.537320618128295
Validation loss: 2.771987860344901

Epoch: 5| Step: 9
Training loss: 0.9567017591389093
Validation loss: 2.7514897812190218

Epoch: 5| Step: 10
Training loss: 1.1177264960745812
Validation loss: 2.7540114073820683

Epoch: 5| Step: 11
Training loss: 2.206937696786558
Validation loss: 2.6765545658039254

Epoch: 206| Step: 0
Training loss: 2.084157920411295
Validation loss: 2.798140905308204

Epoch: 5| Step: 1
Training loss: 1.124528733198056
Validation loss: 2.729496995333655

Epoch: 5| Step: 2
Training loss: 1.2100122177673667
Validation loss: 2.77753787965121

Epoch: 5| Step: 3
Training loss: 1.198371413894306
Validation loss: 2.7947225901716117

Epoch: 5| Step: 4
Training loss: 1.0878900771079747
Validation loss: 2.8551047945971195

Epoch: 5| Step: 5
Training loss: 1.0323063035550233
Validation loss: 2.8976953829689562

Epoch: 5| Step: 6
Training loss: 1.2936031479349566
Validation loss: 2.7287075218270505

Epoch: 5| Step: 7
Training loss: 1.6088639716478075
Validation loss: 2.7984984958688486

Epoch: 5| Step: 8
Training loss: 1.5279442272642838
Validation loss: 2.7647872022207034

Epoch: 5| Step: 9
Training loss: 1.4363226007848622
Validation loss: 2.7378981934998547

Epoch: 5| Step: 10
Training loss: 1.0954869238918787
Validation loss: 2.7702403557411612

Epoch: 5| Step: 11
Training loss: 1.9935664771108783
Validation loss: 2.7406619031415924

Epoch: 207| Step: 0
Training loss: 1.3488316372124984
Validation loss: 2.8526648598487903

Epoch: 5| Step: 1
Training loss: 1.826555997055395
Validation loss: 2.73306775770326

Epoch: 5| Step: 2
Training loss: 1.3002892099140657
Validation loss: 2.9077897351258843

Epoch: 5| Step: 3
Training loss: 1.6273672760550788
Validation loss: 2.814319880109057

Epoch: 5| Step: 4
Training loss: 1.0102347901768032
Validation loss: 2.7807062917738885

Epoch: 5| Step: 5
Training loss: 0.9917800246824703
Validation loss: 2.6759978083759317

Epoch: 5| Step: 6
Training loss: 1.9683038115111142
Validation loss: 2.8778459070543367

Epoch: 5| Step: 7
Training loss: 0.9389111388941458
Validation loss: 2.7189530190854896

Epoch: 5| Step: 8
Training loss: 0.9391784901003056
Validation loss: 2.843810140232317

Epoch: 5| Step: 9
Training loss: 1.4874293975744042
Validation loss: 2.8976341121236238

Epoch: 5| Step: 10
Training loss: 0.7827555074141651
Validation loss: 2.8713760929157344

Epoch: 5| Step: 11
Training loss: 1.2568050638599473
Validation loss: 2.781654292807267

Epoch: 208| Step: 0
Training loss: 1.1742270199705915
Validation loss: 2.806937700838468

Epoch: 5| Step: 1
Training loss: 0.9532931757907673
Validation loss: 2.8531914225907298

Epoch: 5| Step: 2
Training loss: 1.0725049583836181
Validation loss: 2.981922176912443

Epoch: 5| Step: 3
Training loss: 2.0386356769366145
Validation loss: 2.7684418903675856

Epoch: 5| Step: 4
Training loss: 1.2500766253827436
Validation loss: 2.8773695710586136

Epoch: 5| Step: 5
Training loss: 0.9758266881254445
Validation loss: 2.759156714503725

Epoch: 5| Step: 6
Training loss: 1.7254159840436056
Validation loss: 2.794481567561138

Epoch: 5| Step: 7
Training loss: 1.0119738754210046
Validation loss: 2.7546720373419684

Epoch: 5| Step: 8
Training loss: 2.0939838791220313
Validation loss: 2.759341614788734

Epoch: 5| Step: 9
Training loss: 1.0263779890978355
Validation loss: 2.8033006474845643

Epoch: 5| Step: 10
Training loss: 1.245544408171158
Validation loss: 2.7579977101207445

Epoch: 5| Step: 11
Training loss: 2.4526135342728854
Validation loss: 2.805289445637651

Epoch: 209| Step: 0
Training loss: 1.486360446814094
Validation loss: 2.8547960559657466

Epoch: 5| Step: 1
Training loss: 1.43129735476851
Validation loss: 2.859271483640773

Epoch: 5| Step: 2
Training loss: 2.0109661583388547
Validation loss: 2.7811721119350636

Epoch: 5| Step: 3
Training loss: 1.100736809098089
Validation loss: 3.0215629167957907

Epoch: 5| Step: 4
Training loss: 1.4176563097368209
Validation loss: 2.9330972995583964

Epoch: 5| Step: 5
Training loss: 1.2285501205380314
Validation loss: 2.8944918740940913

Epoch: 5| Step: 6
Training loss: 1.2302796718102131
Validation loss: 2.7783187714244497

Epoch: 5| Step: 7
Training loss: 1.4261757500835381
Validation loss: 2.853073827445485

Epoch: 5| Step: 8
Training loss: 1.323456671529758
Validation loss: 2.79752787636648

Epoch: 5| Step: 9
Training loss: 1.1443655265111807
Validation loss: 2.846942398747424

Epoch: 5| Step: 10
Training loss: 1.3848120247151872
Validation loss: 2.731461420467462

Epoch: 5| Step: 11
Training loss: 0.7859806268891313
Validation loss: 2.673140161218728

Epoch: 210| Step: 0
Training loss: 1.1785869390945032
Validation loss: 2.638510980790338

Epoch: 5| Step: 1
Training loss: 1.5010869538435365
Validation loss: 2.7845665448740724

Epoch: 5| Step: 2
Training loss: 1.3036931526028253
Validation loss: 2.677944598952715

Epoch: 5| Step: 3
Training loss: 1.052609919337742
Validation loss: 2.8535228696953525

Epoch: 5| Step: 4
Training loss: 1.0889192987810494
Validation loss: 2.8946374212193633

Epoch: 5| Step: 5
Training loss: 1.4529876644086088
Validation loss: 2.7991111773739017

Epoch: 5| Step: 6
Training loss: 0.8540555525049447
Validation loss: 2.780272283398632

Epoch: 5| Step: 7
Training loss: 1.5748550227212446
Validation loss: 2.754025172197726

Epoch: 5| Step: 8
Training loss: 1.207587450387193
Validation loss: 2.796609556932044

Epoch: 5| Step: 9
Training loss: 1.924658395751863
Validation loss: 2.905040154160428

Epoch: 5| Step: 10
Training loss: 1.1480347322832292
Validation loss: 2.8897086263243046

Epoch: 5| Step: 11
Training loss: 1.8409464582938548
Validation loss: 2.8153237261036512

Epoch: 211| Step: 0
Training loss: 1.0340096511316628
Validation loss: 2.8680464196899904

Epoch: 5| Step: 1
Training loss: 1.2908299207221559
Validation loss: 2.957456564037456

Epoch: 5| Step: 2
Training loss: 1.3538735096841985
Validation loss: 2.8459870164760033

Epoch: 5| Step: 3
Training loss: 0.9144736775301118
Validation loss: 2.8155505837708796

Epoch: 5| Step: 4
Training loss: 1.0101156605696033
Validation loss: 2.878975424416413

Epoch: 5| Step: 5
Training loss: 0.919158618911369
Validation loss: 2.729587090604717

Epoch: 5| Step: 6
Training loss: 2.38678407969867
Validation loss: 2.8645608080354017

Epoch: 5| Step: 7
Training loss: 1.214532892129628
Validation loss: 2.818119182472093

Epoch: 5| Step: 8
Training loss: 1.5436672512842196
Validation loss: 2.849760641118815

Epoch: 5| Step: 9
Training loss: 1.0422521980026394
Validation loss: 2.7325241727768996

Epoch: 5| Step: 10
Training loss: 1.3995509483328465
Validation loss: 2.850106844098355

Epoch: 5| Step: 11
Training loss: 1.5643731143222224
Validation loss: 2.7405008343734356

Epoch: 212| Step: 0
Training loss: 1.1538657272341508
Validation loss: 2.843776549051179

Epoch: 5| Step: 1
Training loss: 1.1571106671594023
Validation loss: 2.944639808743317

Epoch: 5| Step: 2
Training loss: 1.18197889293989
Validation loss: 3.0785113768283456

Epoch: 5| Step: 3
Training loss: 1.698200560943076
Validation loss: 2.8877306563934617

Epoch: 5| Step: 4
Training loss: 1.1958782378127266
Validation loss: 2.8854917706976106

Epoch: 5| Step: 5
Training loss: 1.707624040066529
Validation loss: 2.9109013501780936

Epoch: 5| Step: 6
Training loss: 1.1552458862218236
Validation loss: 2.829496063618074

Epoch: 5| Step: 7
Training loss: 1.2039768126526662
Validation loss: 2.900868098456028

Epoch: 5| Step: 8
Training loss: 1.5151421475843363
Validation loss: 2.802605219932197

Epoch: 5| Step: 9
Training loss: 2.37552998301333
Validation loss: 2.8332181736505992

Epoch: 5| Step: 10
Training loss: 1.1760965222432078
Validation loss: 2.7531818997424153

Epoch: 5| Step: 11
Training loss: 1.1845559216008066
Validation loss: 2.827893850107935

Epoch: 213| Step: 0
Training loss: 0.9267522492156353
Validation loss: 2.7827764422739962

Epoch: 5| Step: 1
Training loss: 1.028356017156734
Validation loss: 2.7041097916165264

Epoch: 5| Step: 2
Training loss: 1.2604947131665314
Validation loss: 2.798052662384511

Epoch: 5| Step: 3
Training loss: 1.3205561215608959
Validation loss: 2.8123670988118414

Epoch: 5| Step: 4
Training loss: 1.4776799247646597
Validation loss: 2.823846594638873

Epoch: 5| Step: 5
Training loss: 1.3567454017798823
Validation loss: 2.8241762885300012

Epoch: 5| Step: 6
Training loss: 1.7889889364652096
Validation loss: 2.9225387397343523

Epoch: 5| Step: 7
Training loss: 2.0584434150366424
Validation loss: 2.806152131342975

Epoch: 5| Step: 8
Training loss: 0.9929358296073252
Validation loss: 2.8885253893181186

Epoch: 5| Step: 9
Training loss: 1.4253857207690879
Validation loss: 2.827627401677471

Epoch: 5| Step: 10
Training loss: 1.4649997475529477
Validation loss: 2.9264758532898942

Epoch: 5| Step: 11
Training loss: 1.0392095131951826
Validation loss: 2.761351824049083

Epoch: 214| Step: 0
Training loss: 1.589729323709654
Validation loss: 2.7666743419628843

Epoch: 5| Step: 1
Training loss: 1.9558376547992276
Validation loss: 2.770759453660968

Epoch: 5| Step: 2
Training loss: 1.299454066378784
Validation loss: 2.786133240366467

Epoch: 5| Step: 3
Training loss: 1.3270176478508187
Validation loss: 2.8015818779426436

Epoch: 5| Step: 4
Training loss: 1.2663190845800112
Validation loss: 2.828553025117334

Epoch: 5| Step: 5
Training loss: 0.8858117661911478
Validation loss: 2.8318701161112556

Epoch: 5| Step: 6
Training loss: 1.7218381708156145
Validation loss: 2.7719613386869137

Epoch: 5| Step: 7
Training loss: 1.2528411048978654
Validation loss: 2.9244355458612468

Epoch: 5| Step: 8
Training loss: 1.1586899658914351
Validation loss: 2.8229130443441837

Epoch: 5| Step: 9
Training loss: 1.3963220461952819
Validation loss: 2.9177959583330133

Epoch: 5| Step: 10
Training loss: 0.8511678498633817
Validation loss: 2.853921219558226

Epoch: 5| Step: 11
Training loss: 1.0151972530163995
Validation loss: 2.791492870718914

Epoch: 215| Step: 0
Training loss: 1.2853163877391751
Validation loss: 2.8485848910250624

Epoch: 5| Step: 1
Training loss: 1.298247931972585
Validation loss: 2.901586458610205

Epoch: 5| Step: 2
Training loss: 1.485227801642636
Validation loss: 2.82603258810379

Epoch: 5| Step: 3
Training loss: 1.095278570980187
Validation loss: 2.760338898528957

Epoch: 5| Step: 4
Training loss: 1.2314833560303646
Validation loss: 2.9506213425533696

Epoch: 5| Step: 5
Training loss: 1.0163610872032605
Validation loss: 2.716713365395272

Epoch: 5| Step: 6
Training loss: 1.847477265090327
Validation loss: 2.8649206078543292

Epoch: 5| Step: 7
Training loss: 0.880982925310196
Validation loss: 2.8896762734400614

Epoch: 5| Step: 8
Training loss: 1.1045930986657464
Validation loss: 2.772340294234289

Epoch: 5| Step: 9
Training loss: 0.7099882642689439
Validation loss: 2.735461762040347

Epoch: 5| Step: 10
Training loss: 2.062293071192069
Validation loss: 2.860102923904336

Epoch: 5| Step: 11
Training loss: 1.7264594137910254
Validation loss: 2.841489770469575

Epoch: 216| Step: 0
Training loss: 1.2263530382268746
Validation loss: 2.8757077327313674

Epoch: 5| Step: 1
Training loss: 1.150552165115824
Validation loss: 2.83779838116301

Epoch: 5| Step: 2
Training loss: 2.0400025988543544
Validation loss: 2.845631502742977

Epoch: 5| Step: 3
Training loss: 1.084589059242808
Validation loss: 2.8394644097781665

Epoch: 5| Step: 4
Training loss: 1.156968486353417
Validation loss: 2.838224940463738

Epoch: 5| Step: 5
Training loss: 1.296979187606498
Validation loss: 2.7634303190707517

Epoch: 5| Step: 6
Training loss: 1.839218195285702
Validation loss: 2.8243748791857746

Epoch: 5| Step: 7
Training loss: 1.278371927896428
Validation loss: 2.706193248368097

Epoch: 5| Step: 8
Training loss: 1.1595820280655535
Validation loss: 2.7931642441700277

Epoch: 5| Step: 9
Training loss: 1.1101239322519338
Validation loss: 2.7597194054925227

Epoch: 5| Step: 10
Training loss: 1.1126018391834167
Validation loss: 2.7657971984071295

Epoch: 5| Step: 11
Training loss: 1.3312480335489714
Validation loss: 2.734538852686967

Epoch: 217| Step: 0
Training loss: 0.982498651314312
Validation loss: 2.7369922392025123

Epoch: 5| Step: 1
Training loss: 1.199653024975533
Validation loss: 2.931888563907723

Epoch: 5| Step: 2
Training loss: 1.5607014031703144
Validation loss: 2.8659753307268874

Epoch: 5| Step: 3
Training loss: 1.2111777774785322
Validation loss: 2.8902746142852234

Epoch: 5| Step: 4
Training loss: 1.010640634051332
Validation loss: 2.796265196431384

Epoch: 5| Step: 5
Training loss: 1.4171942495166416
Validation loss: 2.718383102945654

Epoch: 5| Step: 6
Training loss: 1.1953535883205604
Validation loss: 2.7997225929113494

Epoch: 5| Step: 7
Training loss: 1.9815923449174775
Validation loss: 2.781822677831035

Epoch: 5| Step: 8
Training loss: 1.1155917635542834
Validation loss: 2.7530378807795124

Epoch: 5| Step: 9
Training loss: 0.8690110699395199
Validation loss: 2.686984415647513

Epoch: 5| Step: 10
Training loss: 1.3993422495803416
Validation loss: 2.8045979718412055

Epoch: 5| Step: 11
Training loss: 1.2518495704326829
Validation loss: 2.756056874257016

Epoch: 218| Step: 0
Training loss: 1.167876938493376
Validation loss: 2.8300002784807496

Epoch: 5| Step: 1
Training loss: 0.9539528050414868
Validation loss: 2.8023892499188

Epoch: 5| Step: 2
Training loss: 0.8305959365501918
Validation loss: 2.759541157968435

Epoch: 5| Step: 3
Training loss: 1.4131310698941104
Validation loss: 2.790831135978377

Epoch: 5| Step: 4
Training loss: 1.2523066219506587
Validation loss: 2.8427191042995985

Epoch: 5| Step: 5
Training loss: 2.0718683118985544
Validation loss: 2.7668541908386426

Epoch: 5| Step: 6
Training loss: 1.2284921422512225
Validation loss: 2.8593146347316654

Epoch: 5| Step: 7
Training loss: 1.125958352384186
Validation loss: 2.7494637443301198

Epoch: 5| Step: 8
Training loss: 1.5662599718852643
Validation loss: 2.7721988580532906

Epoch: 5| Step: 9
Training loss: 1.2655888305016858
Validation loss: 2.772109321673292

Epoch: 5| Step: 10
Training loss: 1.2333590998836255
Validation loss: 2.8339096259283

Epoch: 5| Step: 11
Training loss: 0.6826603211403518
Validation loss: 2.739981877355207

Epoch: 219| Step: 0
Training loss: 1.2982502734622707
Validation loss: 2.722344328181026

Epoch: 5| Step: 1
Training loss: 1.386005658835877
Validation loss: 2.7815951390371647

Epoch: 5| Step: 2
Training loss: 1.4712738105188983
Validation loss: 2.873678121194672

Epoch: 5| Step: 3
Training loss: 1.0861529678535278
Validation loss: 2.827761359748465

Epoch: 5| Step: 4
Training loss: 1.3284053730944154
Validation loss: 2.8532385999522627

Epoch: 5| Step: 5
Training loss: 1.3440057378090131
Validation loss: 2.788735079312901

Epoch: 5| Step: 6
Training loss: 1.1195223225612299
Validation loss: 2.859688562734748

Epoch: 5| Step: 7
Training loss: 0.4734495929394784
Validation loss: 2.751661649365725

Epoch: 5| Step: 8
Training loss: 1.4393286476506595
Validation loss: 2.818257009894724

Epoch: 5| Step: 9
Training loss: 1.680241976750179
Validation loss: 2.7625209141568177

Epoch: 5| Step: 10
Training loss: 0.6850460646796186
Validation loss: 2.9478367681200925

Epoch: 5| Step: 11
Training loss: 1.4702518170894765
Validation loss: 2.849471254685818

Epoch: 220| Step: 0
Training loss: 1.3819133184219472
Validation loss: 2.8211851170168787

Epoch: 5| Step: 1
Training loss: 0.9251894447570619
Validation loss: 2.7482830091657293

Epoch: 5| Step: 2
Training loss: 1.2732728722999245
Validation loss: 2.761343355398105

Epoch: 5| Step: 3
Training loss: 1.2910801673718533
Validation loss: 2.776518107474216

Epoch: 5| Step: 4
Training loss: 1.2022756080081594
Validation loss: 2.7667302116216526

Epoch: 5| Step: 5
Training loss: 1.060397704928579
Validation loss: 2.8666499826773766

Epoch: 5| Step: 6
Training loss: 1.192249937409847
Validation loss: 2.847822905706023

Epoch: 5| Step: 7
Training loss: 1.235936589487852
Validation loss: 2.805555494442762

Epoch: 5| Step: 8
Training loss: 1.3669706772126877
Validation loss: 2.7956779838093553

Epoch: 5| Step: 9
Training loss: 1.0333303218202905
Validation loss: 2.86291425052138

Epoch: 5| Step: 10
Training loss: 1.890139682997062
Validation loss: 2.8513350304580762

Epoch: 5| Step: 11
Training loss: 1.430519320616504
Validation loss: 2.9197082985770697

Epoch: 221| Step: 0
Training loss: 0.8986765667835069
Validation loss: 2.8354960746959947

Epoch: 5| Step: 1
Training loss: 1.870765800644866
Validation loss: 2.888342631613602

Epoch: 5| Step: 2
Training loss: 1.2554050887559718
Validation loss: 2.9268309641654833

Epoch: 5| Step: 3
Training loss: 1.175420762877216
Validation loss: 2.688564348525437

Epoch: 5| Step: 4
Training loss: 1.7062698167481531
Validation loss: 2.841847038044789

Epoch: 5| Step: 5
Training loss: 0.9725023630500856
Validation loss: 2.779631840457932

Epoch: 5| Step: 6
Training loss: 1.213619044160506
Validation loss: 2.8552212588326054

Epoch: 5| Step: 7
Training loss: 1.2173246215837272
Validation loss: 2.8118812798828943

Epoch: 5| Step: 8
Training loss: 0.9588724292436714
Validation loss: 2.8447740024636095

Epoch: 5| Step: 9
Training loss: 1.325400621200538
Validation loss: 2.7344862815374245

Epoch: 5| Step: 10
Training loss: 1.0472002805125165
Validation loss: 2.889593266747601

Epoch: 5| Step: 11
Training loss: 1.248730539393645
Validation loss: 2.8016080323217802

Epoch: 222| Step: 0
Training loss: 0.9522269661627069
Validation loss: 2.8088885609304497

Epoch: 5| Step: 1
Training loss: 1.594947514642062
Validation loss: 2.8121532332376584

Epoch: 5| Step: 2
Training loss: 1.1812943384639216
Validation loss: 2.8133025825621787

Epoch: 5| Step: 3
Training loss: 1.0311264195233
Validation loss: 2.7721949413114975

Epoch: 5| Step: 4
Training loss: 1.3329582233078137
Validation loss: 2.729681284387358

Epoch: 5| Step: 5
Training loss: 1.1347918876721035
Validation loss: 2.863018813169249

Epoch: 5| Step: 6
Training loss: 1.3099579489852875
Validation loss: 2.778912862420046

Epoch: 5| Step: 7
Training loss: 1.069287609941761
Validation loss: 2.8163301102235314

Epoch: 5| Step: 8
Training loss: 1.8693974397231405
Validation loss: 2.760107071027475

Epoch: 5| Step: 9
Training loss: 1.607008518175054
Validation loss: 2.8321770676529416

Epoch: 5| Step: 10
Training loss: 1.4910084325243653
Validation loss: 2.8213535264941503

Epoch: 5| Step: 11
Training loss: 0.4508655052845743
Validation loss: 2.7456285164892535

Epoch: 223| Step: 0
Training loss: 1.4409477517783573
Validation loss: 2.747017377245505

Epoch: 5| Step: 1
Training loss: 1.1932304050411935
Validation loss: 2.8941953792808146

Epoch: 5| Step: 2
Training loss: 1.9210229861399883
Validation loss: 2.8281959784717876

Epoch: 5| Step: 3
Training loss: 1.4492321579305216
Validation loss: 2.8359375140117438

Epoch: 5| Step: 4
Training loss: 1.3046128028912771
Validation loss: 3.017532466802258

Epoch: 5| Step: 5
Training loss: 1.0601306751964268
Validation loss: 2.89593597385724

Epoch: 5| Step: 6
Training loss: 1.0499153398261725
Validation loss: 2.8050962591229207

Epoch: 5| Step: 7
Training loss: 0.7000567140764983
Validation loss: 2.8524431514842394

Epoch: 5| Step: 8
Training loss: 0.8534901700272238
Validation loss: 2.7642080768599597

Epoch: 5| Step: 9
Training loss: 1.347735770270521
Validation loss: 2.896820381552234

Epoch: 5| Step: 10
Training loss: 1.3530707350635398
Validation loss: 2.8553774671667065

Epoch: 5| Step: 11
Training loss: 0.5797221314812437
Validation loss: 2.8750418749814197

Epoch: 224| Step: 0
Training loss: 1.2913961383587562
Validation loss: 2.898748009321728

Epoch: 5| Step: 1
Training loss: 1.3756642904394352
Validation loss: 2.832830606533509

Epoch: 5| Step: 2
Training loss: 0.831543219628467
Validation loss: 2.760947760588271

Epoch: 5| Step: 3
Training loss: 1.1005666573704993
Validation loss: 2.8847645092589453

Epoch: 5| Step: 4
Training loss: 1.2062714293162597
Validation loss: 2.8426751002159167

Epoch: 5| Step: 5
Training loss: 1.9861468117031404
Validation loss: 2.8529895225245157

Epoch: 5| Step: 6
Training loss: 1.209243327619446
Validation loss: 2.857047062712643

Epoch: 5| Step: 7
Training loss: 1.007953367812202
Validation loss: 2.898645059397637

Epoch: 5| Step: 8
Training loss: 1.1509630628072807
Validation loss: 2.8769281079356386

Epoch: 5| Step: 9
Training loss: 1.601201458685823
Validation loss: 2.823278063811491

Epoch: 5| Step: 10
Training loss: 1.0345581630103584
Validation loss: 2.8820181443979895

Epoch: 5| Step: 11
Training loss: 0.6612415534202919
Validation loss: 2.7588871131059425

Epoch: 225| Step: 0
Training loss: 1.0451718040400473
Validation loss: 2.867816377944544

Epoch: 5| Step: 1
Training loss: 1.0284377390589707
Validation loss: 2.869764439799253

Epoch: 5| Step: 2
Training loss: 0.78785560390123
Validation loss: 2.851659625067193

Epoch: 5| Step: 3
Training loss: 1.2282489917858916
Validation loss: 2.859245703853826

Epoch: 5| Step: 4
Training loss: 1.0630527068534856
Validation loss: 2.7670919224125607

Epoch: 5| Step: 5
Training loss: 1.1742611306994686
Validation loss: 2.7451517145226254

Epoch: 5| Step: 6
Training loss: 0.909858196392142
Validation loss: 2.8702078648438736

Epoch: 5| Step: 7
Training loss: 0.7507180114851711
Validation loss: 2.891753277228188

Epoch: 5| Step: 8
Training loss: 1.5549325414419297
Validation loss: 2.975609547548822

Epoch: 5| Step: 9
Training loss: 1.078024265171911
Validation loss: 2.765190086723195

Epoch: 5| Step: 10
Training loss: 1.5321124236736103
Validation loss: 2.9175771342374714

Epoch: 5| Step: 11
Training loss: 4.039805478615736
Validation loss: 2.8099595093015868

Epoch: 226| Step: 0
Training loss: 1.2874906261806538
Validation loss: 2.927658297224901

Epoch: 5| Step: 1
Training loss: 1.1714868538510057
Validation loss: 2.861748184773381

Epoch: 5| Step: 2
Training loss: 1.1560740465881774
Validation loss: 2.864593718538822

Epoch: 5| Step: 3
Training loss: 1.2726801392881388
Validation loss: 2.8887605479405627

Epoch: 5| Step: 4
Training loss: 1.561753972292276
Validation loss: 2.8687176203233578

Epoch: 5| Step: 5
Training loss: 1.8144207346871808
Validation loss: 2.956248160799192

Epoch: 5| Step: 6
Training loss: 1.1759332197457626
Validation loss: 2.856947970165347

Epoch: 5| Step: 7
Training loss: 0.753867904399458
Validation loss: 2.7057129520129894

Epoch: 5| Step: 8
Training loss: 1.0529452026107189
Validation loss: 2.8443810003926058

Epoch: 5| Step: 9
Training loss: 0.6883310583583501
Validation loss: 2.8060331844237787

Epoch: 5| Step: 10
Training loss: 1.2326997422552965
Validation loss: 2.835006876437612

Epoch: 5| Step: 11
Training loss: 0.8096310876873934
Validation loss: 2.865927865619443

Epoch: 227| Step: 0
Training loss: 1.4758747254994382
Validation loss: 2.7467891197970693

Epoch: 5| Step: 1
Training loss: 0.8186316572085525
Validation loss: 2.8820383674504053

Epoch: 5| Step: 2
Training loss: 1.0846683028579436
Validation loss: 2.8581271167154747

Epoch: 5| Step: 3
Training loss: 1.5052188842122058
Validation loss: 2.850215614678906

Epoch: 5| Step: 4
Training loss: 1.8699668724267253
Validation loss: 2.8070066032456573

Epoch: 5| Step: 5
Training loss: 1.0044227191862218
Validation loss: 2.8121199668984724

Epoch: 5| Step: 6
Training loss: 0.8780088463252884
Validation loss: 2.839191584013562

Epoch: 5| Step: 7
Training loss: 0.7929174472392723
Validation loss: 2.830600771877162

Epoch: 5| Step: 8
Training loss: 1.5619113576259092
Validation loss: 2.883147815476523

Epoch: 5| Step: 9
Training loss: 0.9482580904506123
Validation loss: 2.8817986322511473

Epoch: 5| Step: 10
Training loss: 0.9681843675273752
Validation loss: 2.944577976313878

Epoch: 5| Step: 11
Training loss: 0.9232679608393002
Validation loss: 2.842481207845588

Epoch: 228| Step: 0
Training loss: 1.3429508494304254
Validation loss: 2.8435619173277455

Epoch: 5| Step: 1
Training loss: 0.8780113581094365
Validation loss: 2.884594849611207

Epoch: 5| Step: 2
Training loss: 1.0249759671254808
Validation loss: 2.849226641994878

Epoch: 5| Step: 3
Training loss: 1.197420940935158
Validation loss: 2.811673901352076

Epoch: 5| Step: 4
Training loss: 1.2604834588799105
Validation loss: 2.756777339451719

Epoch: 5| Step: 5
Training loss: 1.0805321510011763
Validation loss: 2.729365641254173

Epoch: 5| Step: 6
Training loss: 1.313626396396979
Validation loss: 2.8574133329856997

Epoch: 5| Step: 7
Training loss: 0.9371556921353715
Validation loss: 2.830225033102982

Epoch: 5| Step: 8
Training loss: 1.3724885459241298
Validation loss: 2.830256191256662

Epoch: 5| Step: 9
Training loss: 2.037027095841063
Validation loss: 2.795600103285487

Epoch: 5| Step: 10
Training loss: 0.9904438827962778
Validation loss: 2.8573924697819653

Epoch: 5| Step: 11
Training loss: 1.3412158046604656
Validation loss: 3.007679884327881

Epoch: 229| Step: 0
Training loss: 1.2266850501389903
Validation loss: 3.0018942799671455

Epoch: 5| Step: 1
Training loss: 1.253864038059925
Validation loss: 2.879902195081037

Epoch: 5| Step: 2
Training loss: 1.2085212473708022
Validation loss: 3.00234654499486

Epoch: 5| Step: 3
Training loss: 0.9396281247905958
Validation loss: 2.974152805274335

Epoch: 5| Step: 4
Training loss: 1.0711669852319265
Validation loss: 2.824735834210595

Epoch: 5| Step: 5
Training loss: 2.0884311358217738
Validation loss: 2.8596312784993474

Epoch: 5| Step: 6
Training loss: 1.0910533905322055
Validation loss: 2.7740699476782598

Epoch: 5| Step: 7
Training loss: 1.0388303798603156
Validation loss: 2.838283696249256

Epoch: 5| Step: 8
Training loss: 1.477736475653369
Validation loss: 2.7613834715348564

Epoch: 5| Step: 9
Training loss: 0.909050986648829
Validation loss: 2.755914952046435

Epoch: 5| Step: 10
Training loss: 1.3907870937559355
Validation loss: 2.8090277253852864

Epoch: 5| Step: 11
Training loss: 0.3543310508521435
Validation loss: 2.776742232470989

Epoch: 230| Step: 0
Training loss: 0.9994017778617827
Validation loss: 2.825966204277725

Epoch: 5| Step: 1
Training loss: 0.9878922854251566
Validation loss: 2.6911406992740337

Epoch: 5| Step: 2
Training loss: 1.2117581447786427
Validation loss: 2.7996548560555334

Epoch: 5| Step: 3
Training loss: 1.2595248679825286
Validation loss: 2.9500993437122767

Epoch: 5| Step: 4
Training loss: 0.7614282689941284
Validation loss: 2.8215162784977297

Epoch: 5| Step: 5
Training loss: 1.0115503001545385
Validation loss: 3.0401766972889135

Epoch: 5| Step: 6
Training loss: 1.4339846875744517
Validation loss: 2.852164987816784

Epoch: 5| Step: 7
Training loss: 1.4254072979207804
Validation loss: 2.850834294532436

Epoch: 5| Step: 8
Training loss: 1.1843412953112806
Validation loss: 2.865770227017158

Epoch: 5| Step: 9
Training loss: 1.1473559522285126
Validation loss: 2.891938366525146

Epoch: 5| Step: 10
Training loss: 1.8168778658366296
Validation loss: 2.7921975749523726

Epoch: 5| Step: 11
Training loss: 0.46946798015725105
Validation loss: 2.824207300608789

Epoch: 231| Step: 0
Training loss: 1.2271835795690338
Validation loss: 2.8173278838499267

Epoch: 5| Step: 1
Training loss: 1.2509617920002816
Validation loss: 2.867757402788434

Epoch: 5| Step: 2
Training loss: 1.2101984537546282
Validation loss: 2.802926455482964

Epoch: 5| Step: 3
Training loss: 1.0944967173234794
Validation loss: 2.729651911502995

Epoch: 5| Step: 4
Training loss: 1.3241386726946132
Validation loss: 2.870633482424607

Epoch: 5| Step: 5
Training loss: 1.447382748455336
Validation loss: 2.8875155555834535

Epoch: 5| Step: 6
Training loss: 1.6850474160198667
Validation loss: 2.931730204210502

Epoch: 5| Step: 7
Training loss: 0.9277231316136131
Validation loss: 2.797431307970023

Epoch: 5| Step: 8
Training loss: 0.9128859030552889
Validation loss: 2.804820136402469

Epoch: 5| Step: 9
Training loss: 1.2147440486117622
Validation loss: 2.7941838535637697

Epoch: 5| Step: 10
Training loss: 1.067894536351054
Validation loss: 2.843960879964212

Epoch: 5| Step: 11
Training loss: 0.5070743771683922
Validation loss: 2.7887864069697392

Epoch: 232| Step: 0
Training loss: 1.0934795045157268
Validation loss: 2.844221173891238

Epoch: 5| Step: 1
Training loss: 1.0951595488019785
Validation loss: 2.8084738736308434

Epoch: 5| Step: 2
Training loss: 1.8580943594009158
Validation loss: 2.783430593018131

Epoch: 5| Step: 3
Training loss: 0.905104439278382
Validation loss: 2.9412244999811383

Epoch: 5| Step: 4
Training loss: 0.7980191861286565
Validation loss: 2.9190079669645463

Epoch: 5| Step: 5
Training loss: 1.019936141371253
Validation loss: 2.8854500439270714

Epoch: 5| Step: 6
Training loss: 0.9412609320584507
Validation loss: 2.8043619390197265

Epoch: 5| Step: 7
Training loss: 1.3271828395042211
Validation loss: 2.921771188751558

Epoch: 5| Step: 8
Training loss: 1.0135650284450928
Validation loss: 2.9152835984061123

Epoch: 5| Step: 9
Training loss: 0.9374409339099756
Validation loss: 2.9845069137099487

Epoch: 5| Step: 10
Training loss: 1.7161941251390367
Validation loss: 2.8407378085838664

Epoch: 5| Step: 11
Training loss: 1.114886548638261
Validation loss: 2.9355175806184106

Epoch: 233| Step: 0
Training loss: 1.0805035765490283
Validation loss: 2.859145018009098

Epoch: 5| Step: 1
Training loss: 0.9454031025998034
Validation loss: 2.9615599381474436

Epoch: 5| Step: 2
Training loss: 1.723578312258056
Validation loss: 2.8556515121592922

Epoch: 5| Step: 3
Training loss: 0.8363550159562319
Validation loss: 2.8846341918674554

Epoch: 5| Step: 4
Training loss: 1.8991137269583813
Validation loss: 2.9082140968240466

Epoch: 5| Step: 5
Training loss: 1.1891736233050416
Validation loss: 2.83223934066791

Epoch: 5| Step: 6
Training loss: 1.2619206884009755
Validation loss: 2.7409727878493193

Epoch: 5| Step: 7
Training loss: 1.1160355611214834
Validation loss: 2.824376915688149

Epoch: 5| Step: 8
Training loss: 1.2811931504453842
Validation loss: 2.8899562783877437

Epoch: 5| Step: 9
Training loss: 0.8752622551952159
Validation loss: 2.9511734368963713

Epoch: 5| Step: 10
Training loss: 1.3530157137604646
Validation loss: 2.8140890930376505

Epoch: 5| Step: 11
Training loss: 0.6012002671783041
Validation loss: 3.043933932434355

Epoch: 234| Step: 0
Training loss: 1.2536028438477433
Validation loss: 2.813543373417163

Epoch: 5| Step: 1
Training loss: 1.03799446686242
Validation loss: 2.755908261808837

Epoch: 5| Step: 2
Training loss: 1.0700339073085101
Validation loss: 2.821123452154792

Epoch: 5| Step: 3
Training loss: 0.8297443391975196
Validation loss: 2.869866210375515

Epoch: 5| Step: 4
Training loss: 1.083859988112476
Validation loss: 2.7676644178320338

Epoch: 5| Step: 5
Training loss: 1.4572802783374748
Validation loss: 2.8155263442447143

Epoch: 5| Step: 6
Training loss: 1.8228342818762624
Validation loss: 2.8427451457855897

Epoch: 5| Step: 7
Training loss: 1.3802980309855735
Validation loss: 2.702244635458388

Epoch: 5| Step: 8
Training loss: 1.0334139574551302
Validation loss: 2.844474941116461

Epoch: 5| Step: 9
Training loss: 0.9518080821970852
Validation loss: 2.922406986242258

Epoch: 5| Step: 10
Training loss: 1.2576846419087107
Validation loss: 2.894210547125446

Epoch: 5| Step: 11
Training loss: 1.5767235151019856
Validation loss: 2.903833930020119

Epoch: 235| Step: 0
Training loss: 0.9661255326241827
Validation loss: 2.940389899173947

Epoch: 5| Step: 1
Training loss: 1.575506776689188
Validation loss: 3.0184171002091578

Epoch: 5| Step: 2
Training loss: 1.2828497784828286
Validation loss: 2.8943131399411994

Epoch: 5| Step: 3
Training loss: 0.9717943593512534
Validation loss: 2.9349619810857694

Epoch: 5| Step: 4
Training loss: 1.8995304807470155
Validation loss: 2.949420644152708

Epoch: 5| Step: 5
Training loss: 0.9416334582411886
Validation loss: 2.855822779969247

Epoch: 5| Step: 6
Training loss: 1.1746447066590047
Validation loss: 2.913819017371583

Epoch: 5| Step: 7
Training loss: 0.9679687179799417
Validation loss: 2.88943095934242

Epoch: 5| Step: 8
Training loss: 0.8388364206695992
Validation loss: 2.8419541602725267

Epoch: 5| Step: 9
Training loss: 1.1862898231631278
Validation loss: 2.875104549828963

Epoch: 5| Step: 10
Training loss: 1.3301128993480993
Validation loss: 2.8399951514910113

Epoch: 5| Step: 11
Training loss: 0.7262605839678675
Validation loss: 2.927627466517725

Epoch: 236| Step: 0
Training loss: 1.0951968296591694
Validation loss: 2.8860807664493913

Epoch: 5| Step: 1
Training loss: 1.2713328562753785
Validation loss: 2.864805890309857

Epoch: 5| Step: 2
Training loss: 1.0749767056979764
Validation loss: 2.905784501290007

Epoch: 5| Step: 3
Training loss: 0.9515566194600019
Validation loss: 2.8879277610171266

Epoch: 5| Step: 4
Training loss: 0.8890913759178217
Validation loss: 2.881781834045259

Epoch: 5| Step: 5
Training loss: 1.0707693308444233
Validation loss: 2.857650772004098

Epoch: 5| Step: 6
Training loss: 1.9539767429916097
Validation loss: 2.802280186305443

Epoch: 5| Step: 7
Training loss: 1.2937404945503483
Validation loss: 2.8409931737420995

Epoch: 5| Step: 8
Training loss: 0.9601645113137206
Validation loss: 2.850955240047463

Epoch: 5| Step: 9
Training loss: 1.043546195319619
Validation loss: 2.799528834175898

Epoch: 5| Step: 10
Training loss: 1.1093107392947645
Validation loss: 2.844664112352381

Epoch: 5| Step: 11
Training loss: 0.48253262750470866
Validation loss: 2.8393195191827525

Epoch: 237| Step: 0
Training loss: 0.9832820577237764
Validation loss: 3.0005334174597444

Epoch: 5| Step: 1
Training loss: 0.6132351317346966
Validation loss: 2.9039952134941527

Epoch: 5| Step: 2
Training loss: 0.9570752814926707
Validation loss: 2.853183198678567

Epoch: 5| Step: 3
Training loss: 1.1321198549207419
Validation loss: 2.865323412689942

Epoch: 5| Step: 4
Training loss: 0.8489396184875032
Validation loss: 2.8279653191492526

Epoch: 5| Step: 5
Training loss: 1.131919666843407
Validation loss: 2.8303946982080155

Epoch: 5| Step: 6
Training loss: 1.7905284755714652
Validation loss: 2.9017489317075333

Epoch: 5| Step: 7
Training loss: 0.9499421679310984
Validation loss: 2.7907283449135574

Epoch: 5| Step: 8
Training loss: 1.3696132829016454
Validation loss: 2.860656006633686

Epoch: 5| Step: 9
Training loss: 1.120334540965655
Validation loss: 2.878716381890973

Epoch: 5| Step: 10
Training loss: 1.526712584755895
Validation loss: 2.7971834087288636

Epoch: 5| Step: 11
Training loss: 1.0763624960558824
Validation loss: 2.876550370438928

Epoch: 238| Step: 0
Training loss: 0.49229511719327285
Validation loss: 2.934027740032088

Epoch: 5| Step: 1
Training loss: 0.9438683378792543
Validation loss: 2.823758993192179

Epoch: 5| Step: 2
Training loss: 1.1093353479310535
Validation loss: 2.7476296793896955

Epoch: 5| Step: 3
Training loss: 1.161972627688341
Validation loss: 2.889996118267933

Epoch: 5| Step: 4
Training loss: 2.015823945865585
Validation loss: 2.9710537320883468

Epoch: 5| Step: 5
Training loss: 1.0716886931232696
Validation loss: 2.9142450440804177

Epoch: 5| Step: 6
Training loss: 0.9975657339115949
Validation loss: 2.7347288502210905

Epoch: 5| Step: 7
Training loss: 0.8336743888713408
Validation loss: 2.913023902504501

Epoch: 5| Step: 8
Training loss: 1.300110515151799
Validation loss: 2.8944216787695205

Epoch: 5| Step: 9
Training loss: 1.158145279107207
Validation loss: 2.836154915398388

Epoch: 5| Step: 10
Training loss: 1.302292962047954
Validation loss: 2.84284099610842

Epoch: 5| Step: 11
Training loss: 0.9797776662897085
Validation loss: 3.00476541786778

Epoch: 239| Step: 0
Training loss: 0.9718094168855833
Validation loss: 2.8872443423136334

Epoch: 5| Step: 1
Training loss: 0.9573629621841444
Validation loss: 2.8737687985254903

Epoch: 5| Step: 2
Training loss: 1.1444016210687884
Validation loss: 2.901061064257511

Epoch: 5| Step: 3
Training loss: 1.3399002463660465
Validation loss: 2.7933032744705284

Epoch: 5| Step: 4
Training loss: 2.119180002154315
Validation loss: 2.7949404392652215

Epoch: 5| Step: 5
Training loss: 1.0038867755589223
Validation loss: 2.8547454279670257

Epoch: 5| Step: 6
Training loss: 0.8142668513333691
Validation loss: 2.9045015291623786

Epoch: 5| Step: 7
Training loss: 0.7213965081046051
Validation loss: 2.8506942298064084

Epoch: 5| Step: 8
Training loss: 1.2796997367823442
Validation loss: 2.932750768728223

Epoch: 5| Step: 9
Training loss: 1.2558140961596025
Validation loss: 2.9211269923962173

Epoch: 5| Step: 10
Training loss: 0.8888497646152296
Validation loss: 2.882731008368575

Epoch: 5| Step: 11
Training loss: 2.148959564588314
Validation loss: 2.847063837582462

Epoch: 240| Step: 0
Training loss: 1.3005710924627236
Validation loss: 2.9970131979785264

Epoch: 5| Step: 1
Training loss: 1.0732389663495223
Validation loss: 2.8549723526389283

Epoch: 5| Step: 2
Training loss: 1.8977372875790386
Validation loss: 2.7920521439168606

Epoch: 5| Step: 3
Training loss: 1.086995220324721
Validation loss: 2.951609005417781

Epoch: 5| Step: 4
Training loss: 1.3439509662896763
Validation loss: 2.7543435365054014

Epoch: 5| Step: 5
Training loss: 1.3451338451113473
Validation loss: 2.805180269906725

Epoch: 5| Step: 6
Training loss: 0.8832075872228401
Validation loss: 2.7821970873693256

Epoch: 5| Step: 7
Training loss: 0.7783640008053985
Validation loss: 2.8855911671494354

Epoch: 5| Step: 8
Training loss: 1.2516359591029524
Validation loss: 2.898475417088778

Epoch: 5| Step: 9
Training loss: 0.8731735103513977
Validation loss: 2.8661630829038947

Epoch: 5| Step: 10
Training loss: 1.0227524889139659
Validation loss: 2.9080096219505736

Epoch: 5| Step: 11
Training loss: 1.2604703602769316
Validation loss: 2.8195185719429894

Epoch: 241| Step: 0
Training loss: 0.757592828117571
Validation loss: 2.8775782841457724

Epoch: 5| Step: 1
Training loss: 1.1101242544031877
Validation loss: 2.8121935465536048

Epoch: 5| Step: 2
Training loss: 1.0500545896235944
Validation loss: 2.972148262026695

Epoch: 5| Step: 3
Training loss: 1.1722650006148632
Validation loss: 2.9130040650772067

Epoch: 5| Step: 4
Training loss: 0.7482545728661634
Validation loss: 2.8664642759244376

Epoch: 5| Step: 5
Training loss: 0.9480729585571537
Validation loss: 2.900310356836165

Epoch: 5| Step: 6
Training loss: 1.4293874623798275
Validation loss: 2.8992711605130816

Epoch: 5| Step: 7
Training loss: 1.8235637134061993
Validation loss: 2.9379530516723755

Epoch: 5| Step: 8
Training loss: 1.2340488244325563
Validation loss: 2.868357919288019

Epoch: 5| Step: 9
Training loss: 1.0406057613759525
Validation loss: 2.8522288514978564

Epoch: 5| Step: 10
Training loss: 0.9845835146995977
Validation loss: 2.853056501476437

Epoch: 5| Step: 11
Training loss: 0.7465137677516805
Validation loss: 2.9997076978274047

Epoch: 242| Step: 0
Training loss: 1.8715575087463707
Validation loss: 2.8241991505837545

Epoch: 5| Step: 1
Training loss: 1.4132532153873247
Validation loss: 2.8808803130859872

Epoch: 5| Step: 2
Training loss: 1.1807402403987661
Validation loss: 2.8557724032392238

Epoch: 5| Step: 3
Training loss: 0.8891113535996104
Validation loss: 2.907956669913028

Epoch: 5| Step: 4
Training loss: 1.1583526154612467
Validation loss: 2.905869647058887

Epoch: 5| Step: 5
Training loss: 1.2912513413842353
Validation loss: 2.900816716365092

Epoch: 5| Step: 6
Training loss: 1.0778133107638828
Validation loss: 2.9396915681262783

Epoch: 5| Step: 7
Training loss: 1.483947210406322
Validation loss: 2.9374104411764375

Epoch: 5| Step: 8
Training loss: 0.7601655432200674
Validation loss: 2.921930995955383

Epoch: 5| Step: 9
Training loss: 0.7260412992442737
Validation loss: 2.9678667293779797

Epoch: 5| Step: 10
Training loss: 1.0351587259514905
Validation loss: 2.820328762609877

Epoch: 5| Step: 11
Training loss: 1.0541979748646553
Validation loss: 2.9221576887115495

Epoch: 243| Step: 0
Training loss: 0.750557017110416
Validation loss: 2.8340913457506995

Epoch: 5| Step: 1
Training loss: 1.7955422144075261
Validation loss: 2.7344348065329878

Epoch: 5| Step: 2
Training loss: 0.9274474654010308
Validation loss: 2.7846802656533294

Epoch: 5| Step: 3
Training loss: 1.0962786735342804
Validation loss: 2.788642595241356

Epoch: 5| Step: 4
Training loss: 0.9418678260130063
Validation loss: 2.8364044414550853

Epoch: 5| Step: 5
Training loss: 1.2399789622275725
Validation loss: 2.850346198721842

Epoch: 5| Step: 6
Training loss: 0.9320724414251008
Validation loss: 2.815614798100795

Epoch: 5| Step: 7
Training loss: 0.8316436007810634
Validation loss: 2.872403797036017

Epoch: 5| Step: 8
Training loss: 1.1128302480454806
Validation loss: 2.8828630727244904

Epoch: 5| Step: 9
Training loss: 0.9327882939301835
Validation loss: 2.990966248848896

Epoch: 5| Step: 10
Training loss: 1.4580195861463678
Validation loss: 2.7789383150069815

Epoch: 5| Step: 11
Training loss: 0.6431955774059718
Validation loss: 2.898020351857738

Epoch: 244| Step: 0
Training loss: 1.1424649174351877
Validation loss: 2.8353985466098983

Epoch: 5| Step: 1
Training loss: 0.7748967671088522
Validation loss: 2.788588008892161

Epoch: 5| Step: 2
Training loss: 0.9900656712550308
Validation loss: 3.0090865405283758

Epoch: 5| Step: 3
Training loss: 1.3972346924431134
Validation loss: 2.8168329011846325

Epoch: 5| Step: 4
Training loss: 0.9857433133905888
Validation loss: 2.7857890076857057

Epoch: 5| Step: 5
Training loss: 1.904415060435122
Validation loss: 2.821406665576699

Epoch: 5| Step: 6
Training loss: 1.1392908000960653
Validation loss: 2.87430340510122

Epoch: 5| Step: 7
Training loss: 1.1546969938597675
Validation loss: 2.9527064435525716

Epoch: 5| Step: 8
Training loss: 0.9017082387456643
Validation loss: 2.924997734954696

Epoch: 5| Step: 9
Training loss: 1.0725527519644242
Validation loss: 2.783413659771676

Epoch: 5| Step: 10
Training loss: 1.0623147466386331
Validation loss: 2.8297723394770826

Epoch: 5| Step: 11
Training loss: 1.7283695482502008
Validation loss: 2.748333151265777

Epoch: 245| Step: 0
Training loss: 0.7976240489710734
Validation loss: 2.8800769670177915

Epoch: 5| Step: 1
Training loss: 1.585235590709393
Validation loss: 2.867161697839817

Epoch: 5| Step: 2
Training loss: 1.1116178165170658
Validation loss: 2.72920444816665

Epoch: 5| Step: 3
Training loss: 1.4656133232383581
Validation loss: 2.9633800091534255

Epoch: 5| Step: 4
Training loss: 1.9938412253816125
Validation loss: 2.847931017045369

Epoch: 5| Step: 5
Training loss: 0.8658393484303796
Validation loss: 2.8288602733765043

Epoch: 5| Step: 6
Training loss: 1.0066682100494713
Validation loss: 2.9525229262469384

Epoch: 5| Step: 7
Training loss: 0.8770836815791825
Validation loss: 2.9768044681270522

Epoch: 5| Step: 8
Training loss: 1.2020495673891018
Validation loss: 2.9756459638122457

Epoch: 5| Step: 9
Training loss: 1.0132292440770037
Validation loss: 2.7757261710084498

Epoch: 5| Step: 10
Training loss: 0.9927002190294636
Validation loss: 2.9553845152824163

Epoch: 5| Step: 11
Training loss: 0.828944322752556
Validation loss: 2.890507516965125

Epoch: 246| Step: 0
Training loss: 0.7927866007747488
Validation loss: 2.882688779855364

Epoch: 5| Step: 1
Training loss: 0.9560355787539894
Validation loss: 2.8703045095444293

Epoch: 5| Step: 2
Training loss: 0.8000333689644477
Validation loss: 2.8262144418150155

Epoch: 5| Step: 3
Training loss: 1.1714588189207442
Validation loss: 2.887354056893546

Epoch: 5| Step: 4
Training loss: 1.2736387971322984
Validation loss: 2.7810177116687345

Epoch: 5| Step: 5
Training loss: 1.0329335082664783
Validation loss: 2.731358159074707

Epoch: 5| Step: 6
Training loss: 2.0435659436515
Validation loss: 2.7850842138875147

Epoch: 5| Step: 7
Training loss: 1.1372898934797664
Validation loss: 2.7165589858042294

Epoch: 5| Step: 8
Training loss: 1.0126798328772628
Validation loss: 2.877039545284425

Epoch: 5| Step: 9
Training loss: 0.8801933189480909
Validation loss: 2.8036922275721023

Epoch: 5| Step: 10
Training loss: 1.2168592801325275
Validation loss: 2.8199855230965354

Epoch: 5| Step: 11
Training loss: 0.6909161786706604
Validation loss: 2.9662810080753923

Epoch: 247| Step: 0
Training loss: 0.9972953579777689
Validation loss: 2.849942685270385

Epoch: 5| Step: 1
Training loss: 0.7564283097708093
Validation loss: 2.9578218700746173

Epoch: 5| Step: 2
Training loss: 1.2141273569582762
Validation loss: 2.9526266050851575

Epoch: 5| Step: 3
Training loss: 1.6788772402991188
Validation loss: 2.870806628205913

Epoch: 5| Step: 4
Training loss: 1.0126817163421025
Validation loss: 2.8241602362642744

Epoch: 5| Step: 5
Training loss: 0.961354049091261
Validation loss: 2.854625238116477

Epoch: 5| Step: 6
Training loss: 1.0290458126898738
Validation loss: 2.7634904422223174

Epoch: 5| Step: 7
Training loss: 1.0018337245536992
Validation loss: 2.8220694855465194

Epoch: 5| Step: 8
Training loss: 1.047417059097947
Validation loss: 2.9171283640330685

Epoch: 5| Step: 9
Training loss: 1.2342367939898347
Validation loss: 2.8719586096967094

Epoch: 5| Step: 10
Training loss: 1.0367019341491337
Validation loss: 2.8992154875805225

Epoch: 5| Step: 11
Training loss: 0.5300479641389751
Validation loss: 2.8411509335778344

Epoch: 248| Step: 0
Training loss: 1.0024710760914568
Validation loss: 2.859451101850307

Epoch: 5| Step: 1
Training loss: 1.0220122568884806
Validation loss: 2.8123058993860623

Epoch: 5| Step: 2
Training loss: 0.8533037564310193
Validation loss: 2.8278142607322954

Epoch: 5| Step: 3
Training loss: 1.9444272888274494
Validation loss: 2.8152371968265397

Epoch: 5| Step: 4
Training loss: 1.0516108531519537
Validation loss: 2.9005463221210883

Epoch: 5| Step: 5
Training loss: 0.9936573525192403
Validation loss: 2.8191308058242237

Epoch: 5| Step: 6
Training loss: 1.114485347160309
Validation loss: 2.8745483237134084

Epoch: 5| Step: 7
Training loss: 0.9743006031734961
Validation loss: 2.8831510715448383

Epoch: 5| Step: 8
Training loss: 1.0243205563296316
Validation loss: 2.975925143698692

Epoch: 5| Step: 9
Training loss: 0.8645916137911589
Validation loss: 2.919916278404222

Epoch: 5| Step: 10
Training loss: 1.1005338912071247
Validation loss: 2.900598072035781

Epoch: 5| Step: 11
Training loss: 2.493490900714948
Validation loss: 3.000594206084337

Epoch: 249| Step: 0
Training loss: 1.2684493399229824
Validation loss: 2.828421090715942

Epoch: 5| Step: 1
Training loss: 1.1217293349883968
Validation loss: 2.863100137225813

Epoch: 5| Step: 2
Training loss: 1.0376796842576093
Validation loss: 2.8697003674854753

Epoch: 5| Step: 3
Training loss: 1.9890654990150396
Validation loss: 2.886599643643539

Epoch: 5| Step: 4
Training loss: 1.0333891558694464
Validation loss: 2.9343854341331603

Epoch: 5| Step: 5
Training loss: 1.006938525800009
Validation loss: 2.772062919150105

Epoch: 5| Step: 6
Training loss: 0.9591306431123439
Validation loss: 2.938486090987259

Epoch: 5| Step: 7
Training loss: 1.0152753961839298
Validation loss: 2.8741268062030363

Epoch: 5| Step: 8
Training loss: 1.0119622721744943
Validation loss: 2.8198373487642994

Epoch: 5| Step: 9
Training loss: 1.4162714444293616
Validation loss: 2.9221156424094223

Epoch: 5| Step: 10
Training loss: 0.8063220856843912
Validation loss: 3.01938650846147

Epoch: 5| Step: 11
Training loss: 1.1057840713091978
Validation loss: 3.014103424891309

Epoch: 250| Step: 0
Training loss: 1.0049090293971348
Validation loss: 3.14399314051366

Epoch: 5| Step: 1
Training loss: 1.7397440381162428
Validation loss: 2.9508080720040155

Epoch: 5| Step: 2
Training loss: 0.6841778249059137
Validation loss: 2.987456310490113

Epoch: 5| Step: 3
Training loss: 0.9802281361821672
Validation loss: 2.9461422366186283

Epoch: 5| Step: 4
Training loss: 1.140369543445315
Validation loss: 2.962602494474739

Epoch: 5| Step: 5
Training loss: 1.2707025846333004
Validation loss: 2.8317437282488425

Epoch: 5| Step: 6
Training loss: 0.8547060279302456
Validation loss: 2.8136551409824895

Epoch: 5| Step: 7
Training loss: 0.997937280419436
Validation loss: 2.80083083175832

Epoch: 5| Step: 8
Training loss: 0.9106117385809758
Validation loss: 2.9345838058762332

Epoch: 5| Step: 9
Training loss: 1.092887429299435
Validation loss: 2.8467609164915677

Epoch: 5| Step: 10
Training loss: 1.1684286685598626
Validation loss: 2.9122444085705963

Epoch: 5| Step: 11
Training loss: 0.506123094782655
Validation loss: 2.894922436815478

Epoch: 251| Step: 0
Training loss: 0.9878047653904316
Validation loss: 2.78652956624947

Epoch: 5| Step: 1
Training loss: 1.9045162133297626
Validation loss: 2.833334240258764

Epoch: 5| Step: 2
Training loss: 0.8940447688019495
Validation loss: 2.8684121928234765

Epoch: 5| Step: 3
Training loss: 1.098422071801657
Validation loss: 2.7785424615758214

Epoch: 5| Step: 4
Training loss: 0.7678564988890828
Validation loss: 2.8781380631339877

Epoch: 5| Step: 5
Training loss: 0.9999044789946162
Validation loss: 2.962321093209862

Epoch: 5| Step: 6
Training loss: 0.7268334160518738
Validation loss: 3.043944379120823

Epoch: 5| Step: 7
Training loss: 1.1837615847801175
Validation loss: 2.9526214843141654

Epoch: 5| Step: 8
Training loss: 0.9604957619712065
Validation loss: 2.946707923659311

Epoch: 5| Step: 9
Training loss: 1.0188890093178529
Validation loss: 3.020862534261295

Epoch: 5| Step: 10
Training loss: 0.8240580108254126
Validation loss: 2.908479225266805

Epoch: 5| Step: 11
Training loss: 1.7180131893473234
Validation loss: 2.82293378935028

Epoch: 252| Step: 0
Training loss: 1.2468934079295713
Validation loss: 2.8143153018989007

Epoch: 5| Step: 1
Training loss: 0.7590389355786268
Validation loss: 2.8753043062071013

Epoch: 5| Step: 2
Training loss: 1.163742840803274
Validation loss: 2.805477399466586

Epoch: 5| Step: 3
Training loss: 0.9220614487202382
Validation loss: 2.8112616815207

Epoch: 5| Step: 4
Training loss: 1.9265335192206083
Validation loss: 2.835918505266119

Epoch: 5| Step: 5
Training loss: 0.9965296670332371
Validation loss: 2.9731932700974713

Epoch: 5| Step: 6
Training loss: 1.1019428218885914
Validation loss: 2.8963129048986014

Epoch: 5| Step: 7
Training loss: 0.8911549179592104
Validation loss: 2.9039726940069692

Epoch: 5| Step: 8
Training loss: 0.8269174516756078
Validation loss: 2.9648335238461723

Epoch: 5| Step: 9
Training loss: 1.3470652293247214
Validation loss: 2.963177882673883

Epoch: 5| Step: 10
Training loss: 1.0526646182245862
Validation loss: 2.8445762963881025

Epoch: 5| Step: 11
Training loss: 0.7024156383007996
Validation loss: 2.922097614124156

Epoch: 253| Step: 0
Training loss: 0.8734410567373286
Validation loss: 3.0047000849700454

Epoch: 5| Step: 1
Training loss: 0.9574173129162525
Validation loss: 2.8340030444332327

Epoch: 5| Step: 2
Training loss: 0.9921491420269797
Validation loss: 2.8213444104987495

Epoch: 5| Step: 3
Training loss: 1.0317278824014522
Validation loss: 2.873958443898255

Epoch: 5| Step: 4
Training loss: 1.6643207331773258
Validation loss: 2.8244708675483237

Epoch: 5| Step: 5
Training loss: 0.8144512954069303
Validation loss: 2.936442945903956

Epoch: 5| Step: 6
Training loss: 1.8944691441374781
Validation loss: 2.826241746103347

Epoch: 5| Step: 7
Training loss: 0.7920035891764646
Validation loss: 2.9249782674204865

Epoch: 5| Step: 8
Training loss: 0.7039429040102068
Validation loss: 2.9104619320075726

Epoch: 5| Step: 9
Training loss: 1.1970842482318473
Validation loss: 2.8803092301937756

Epoch: 5| Step: 10
Training loss: 0.5930995892306062
Validation loss: 2.967678944308404

Epoch: 5| Step: 11
Training loss: 0.6390719545966101
Validation loss: 2.918852648812193

Epoch: 254| Step: 0
Training loss: 1.2202078096661002
Validation loss: 2.9254399004152467

Epoch: 5| Step: 1
Training loss: 0.8164392492022535
Validation loss: 2.9359484829510274

Epoch: 5| Step: 2
Training loss: 1.0619169767366785
Validation loss: 2.84060462507908

Epoch: 5| Step: 3
Training loss: 0.7695537893024904
Validation loss: 2.957109108441159

Epoch: 5| Step: 4
Training loss: 1.0839896537033633
Validation loss: 2.870020462072845

Epoch: 5| Step: 5
Training loss: 1.9453599303564557
Validation loss: 3.034418688249093

Epoch: 5| Step: 6
Training loss: 0.7535471876464388
Validation loss: 2.9707735326258065

Epoch: 5| Step: 7
Training loss: 0.9830159690817162
Validation loss: 2.8932106001447346

Epoch: 5| Step: 8
Training loss: 0.9497911587598251
Validation loss: 2.8685275886408688

Epoch: 5| Step: 9
Training loss: 1.0232688823144191
Validation loss: 2.9101925465754603

Epoch: 5| Step: 10
Training loss: 0.9935218669134038
Validation loss: 2.936757189935549

Epoch: 5| Step: 11
Training loss: 0.43338091670030776
Validation loss: 2.8589926500509493

Epoch: 255| Step: 0
Training loss: 1.2369194846227922
Validation loss: 2.8236193022948206

Epoch: 5| Step: 1
Training loss: 0.78030223578446
Validation loss: 2.871590610684415

Epoch: 5| Step: 2
Training loss: 1.1689333807544242
Validation loss: 2.8477909246413193

Epoch: 5| Step: 3
Training loss: 1.1305663366582157
Validation loss: 2.8095674484922513

Epoch: 5| Step: 4
Training loss: 1.0422088483599885
Validation loss: 2.851386339154791

Epoch: 5| Step: 5
Training loss: 1.219731986749223
Validation loss: 2.9205090292843434

Epoch: 5| Step: 6
Training loss: 1.7706343221099232
Validation loss: 2.8799259479647303

Epoch: 5| Step: 7
Training loss: 0.8014484138426904
Validation loss: 2.8499144821554228

Epoch: 5| Step: 8
Training loss: 1.0422200004851738
Validation loss: 2.892561834144781

Epoch: 5| Step: 9
Training loss: 1.2388788459971396
Validation loss: 2.9918376894089973

Epoch: 5| Step: 10
Training loss: 1.0417545408695088
Validation loss: 2.914609184495878

Epoch: 5| Step: 11
Training loss: 0.9372755099773177
Validation loss: 2.9104669716532756

Epoch: 256| Step: 0
Training loss: 0.6556827500458258
Validation loss: 2.951618718691765

Epoch: 5| Step: 1
Training loss: 0.6614510968831229
Validation loss: 2.9178268520675963

Epoch: 5| Step: 2
Training loss: 0.8580084599475776
Validation loss: 2.977683706368334

Epoch: 5| Step: 3
Training loss: 1.2757030063610173
Validation loss: 2.9163978838824014

Epoch: 5| Step: 4
Training loss: 0.8808245599129924
Validation loss: 2.863154340414787

Epoch: 5| Step: 5
Training loss: 1.080830427581089
Validation loss: 2.845264932568961

Epoch: 5| Step: 6
Training loss: 1.1015786785263346
Validation loss: 2.835114337705601

Epoch: 5| Step: 7
Training loss: 0.940912615885056
Validation loss: 2.853882261478786

Epoch: 5| Step: 8
Training loss: 1.9582468243693356
Validation loss: 2.7201244964870273

Epoch: 5| Step: 9
Training loss: 0.8152665209132963
Validation loss: 2.789094445680518

Epoch: 5| Step: 10
Training loss: 1.0570113964711532
Validation loss: 2.796081526314683

Epoch: 5| Step: 11
Training loss: 1.5255151128829891
Validation loss: 2.8733037180731484

Epoch: 257| Step: 0
Training loss: 1.0430977845112932
Validation loss: 2.803139715535278

Epoch: 5| Step: 1
Training loss: 0.5944978872555214
Validation loss: 2.8068151629886486

Epoch: 5| Step: 2
Training loss: 1.6989637863224476
Validation loss: 2.8351359745329736

Epoch: 5| Step: 3
Training loss: 0.6508137469289358
Validation loss: 2.9695804538679837

Epoch: 5| Step: 4
Training loss: 1.0283603642299606
Validation loss: 2.9339683892875157

Epoch: 5| Step: 5
Training loss: 1.3093586067138547
Validation loss: 2.978152415325178

Epoch: 5| Step: 6
Training loss: 1.0031207384630991
Validation loss: 2.9452910114722046

Epoch: 5| Step: 7
Training loss: 1.1089273543578235
Validation loss: 2.9443783497114837

Epoch: 5| Step: 8
Training loss: 1.069959206293693
Validation loss: 2.829539554687752

Epoch: 5| Step: 9
Training loss: 1.173730424061641
Validation loss: 2.9278979316207203

Epoch: 5| Step: 10
Training loss: 1.0787628608900595
Validation loss: 2.842101733797762

Epoch: 5| Step: 11
Training loss: 1.3696755576390964
Validation loss: 2.916817818993857

Epoch: 258| Step: 0
Training loss: 0.8550086678517318
Validation loss: 2.8845839842489274

Epoch: 5| Step: 1
Training loss: 0.8110444529423712
Validation loss: 2.8361716055596067

Epoch: 5| Step: 2
Training loss: 1.2838713649296807
Validation loss: 2.929822421887773

Epoch: 5| Step: 3
Training loss: 0.9659161804571423
Validation loss: 2.872345766868728

Epoch: 5| Step: 4
Training loss: 0.7961063792057088
Validation loss: 2.976678230258556

Epoch: 5| Step: 5
Training loss: 0.9129050335708029
Validation loss: 2.9538465254223456

Epoch: 5| Step: 6
Training loss: 1.0161756343307164
Validation loss: 2.862714807704649

Epoch: 5| Step: 7
Training loss: 1.6888891083455082
Validation loss: 2.9450840848793662

Epoch: 5| Step: 8
Training loss: 1.366413093318564
Validation loss: 2.92528366047484

Epoch: 5| Step: 9
Training loss: 0.8799180374122788
Validation loss: 2.93917311372871

Epoch: 5| Step: 10
Training loss: 0.8154946672509626
Validation loss: 2.826491693917615

Epoch: 5| Step: 11
Training loss: 0.6497680846380216
Validation loss: 2.939723100230055

Epoch: 259| Step: 0
Training loss: 0.6866320853722824
Validation loss: 2.9361029593372496

Epoch: 5| Step: 1
Training loss: 0.7755466947904062
Validation loss: 2.805383176250056

Epoch: 5| Step: 2
Training loss: 0.9251478579629719
Validation loss: 2.899286952818824

Epoch: 5| Step: 3
Training loss: 0.7213304472143969
Validation loss: 2.883577829305126

Epoch: 5| Step: 4
Training loss: 1.9839573217846915
Validation loss: 2.742515055337787

Epoch: 5| Step: 5
Training loss: 0.8718013882753083
Validation loss: 2.80108746601954

Epoch: 5| Step: 6
Training loss: 0.8916690128212363
Validation loss: 2.9217140099004033

Epoch: 5| Step: 7
Training loss: 1.3616225418184897
Validation loss: 2.8944919290072595

Epoch: 5| Step: 8
Training loss: 0.9088856747183619
Validation loss: 2.889732408608789

Epoch: 5| Step: 9
Training loss: 0.955209734689287
Validation loss: 2.9463568032594405

Epoch: 5| Step: 10
Training loss: 0.9303086714045915
Validation loss: 2.946286149319077

Epoch: 5| Step: 11
Training loss: 1.095588773312382
Validation loss: 2.822753346681828

Epoch: 260| Step: 0
Training loss: 0.8900209352624147
Validation loss: 2.9229855220476146

Epoch: 5| Step: 1
Training loss: 0.8340170360307189
Validation loss: 2.8651353801189043

Epoch: 5| Step: 2
Training loss: 1.6551721052362713
Validation loss: 2.8554697275921095

Epoch: 5| Step: 3
Training loss: 0.8630391122236307
Validation loss: 2.91837312074492

Epoch: 5| Step: 4
Training loss: 0.9785845764597519
Validation loss: 2.968203872507739

Epoch: 5| Step: 5
Training loss: 0.8080234820216066
Validation loss: 3.008318695805903

Epoch: 5| Step: 6
Training loss: 0.9024172005752344
Validation loss: 2.8806247766524598

Epoch: 5| Step: 7
Training loss: 1.0069817364389821
Validation loss: 2.953889996647774

Epoch: 5| Step: 8
Training loss: 1.1827003960037632
Validation loss: 2.9798098861239395

Epoch: 5| Step: 9
Training loss: 0.8706264183104081
Validation loss: 2.881029551161941

Epoch: 5| Step: 10
Training loss: 1.3712776256410888
Validation loss: 2.9327374227348035

Epoch: 5| Step: 11
Training loss: 0.3484196799472692
Validation loss: 2.760486980958214

Epoch: 261| Step: 0
Training loss: 0.9342171730274468
Validation loss: 2.778267618672965

Epoch: 5| Step: 1
Training loss: 0.9296158835130894
Validation loss: 2.901022364257116

Epoch: 5| Step: 2
Training loss: 0.9573421985183429
Validation loss: 2.8679673418903904

Epoch: 5| Step: 3
Training loss: 0.766950666305737
Validation loss: 2.9460531259759026

Epoch: 5| Step: 4
Training loss: 1.110628896952218
Validation loss: 2.9385965833476013

Epoch: 5| Step: 5
Training loss: 0.7560344956465167
Validation loss: 2.8881870952293687

Epoch: 5| Step: 6
Training loss: 0.8033276521183744
Validation loss: 2.988943610823906

Epoch: 5| Step: 7
Training loss: 1.1106749426883344
Validation loss: 3.052482150366955

Epoch: 5| Step: 8
Training loss: 0.9798924549609971
Validation loss: 2.915426935389827

Epoch: 5| Step: 9
Training loss: 2.0163378970337904
Validation loss: 2.9378935300047377

Epoch: 5| Step: 10
Training loss: 0.8194272305320285
Validation loss: 2.905855531480998

Epoch: 5| Step: 11
Training loss: 1.463021653219147
Validation loss: 2.8359811287318437

Epoch: 262| Step: 0
Training loss: 0.8449761699950461
Validation loss: 2.9197480182921334

Epoch: 5| Step: 1
Training loss: 1.8672844131409994
Validation loss: 2.8252207489749788

Epoch: 5| Step: 2
Training loss: 1.029317837525214
Validation loss: 2.8381396939361334

Epoch: 5| Step: 3
Training loss: 0.8710697324717638
Validation loss: 2.8154522906703923

Epoch: 5| Step: 4
Training loss: 1.1560461019180104
Validation loss: 2.906639609661146

Epoch: 5| Step: 5
Training loss: 0.8347329347070825
Validation loss: 2.8620276523656405

Epoch: 5| Step: 6
Training loss: 1.0132075957247368
Validation loss: 2.896881326684281

Epoch: 5| Step: 7
Training loss: 0.9583573165601524
Validation loss: 2.8377208654566983

Epoch: 5| Step: 8
Training loss: 0.6260949556983132
Validation loss: 2.8711931241715396

Epoch: 5| Step: 9
Training loss: 0.8530814945739841
Validation loss: 2.9760875773579905

Epoch: 5| Step: 10
Training loss: 1.281847930577752
Validation loss: 2.9672619252365

Epoch: 5| Step: 11
Training loss: 0.417642162754742
Validation loss: 2.9288058772762464

Epoch: 263| Step: 0
Training loss: 1.002663581706012
Validation loss: 2.8759092054267423

Epoch: 5| Step: 1
Training loss: 1.8086957140660593
Validation loss: 3.0506660840207185

Epoch: 5| Step: 2
Training loss: 1.0642014512182476
Validation loss: 2.9231906213708845

Epoch: 5| Step: 3
Training loss: 1.081987290573924
Validation loss: 2.9790771422017497

Epoch: 5| Step: 4
Training loss: 0.9564178992579212
Validation loss: 2.8967905086416272

Epoch: 5| Step: 5
Training loss: 0.9703378892116947
Validation loss: 2.937121647621717

Epoch: 5| Step: 6
Training loss: 1.3001095065431627
Validation loss: 2.8613761437805842

Epoch: 5| Step: 7
Training loss: 1.156594560163866
Validation loss: 2.934366702581611

Epoch: 5| Step: 8
Training loss: 0.8142653873244078
Validation loss: 2.8190856723857074

Epoch: 5| Step: 9
Training loss: 0.8630192907239395
Validation loss: 2.8766821970875878

Epoch: 5| Step: 10
Training loss: 0.777268986005971
Validation loss: 2.9852410111835197

Epoch: 5| Step: 11
Training loss: 0.6166261703709002
Validation loss: 2.9862678543372496

Epoch: 264| Step: 0
Training loss: 0.7667387821308497
Validation loss: 2.8105968570749384

Epoch: 5| Step: 1
Training loss: 0.8630753008257607
Validation loss: 2.8838365212667054

Epoch: 5| Step: 2
Training loss: 1.3324937660686966
Validation loss: 2.833406750111175

Epoch: 5| Step: 3
Training loss: 0.7510712443615123
Validation loss: 3.007879849295015

Epoch: 5| Step: 4
Training loss: 1.05877526335317
Validation loss: 2.9631072912120837

Epoch: 5| Step: 5
Training loss: 1.6521105590475493
Validation loss: 3.035061383493367

Epoch: 5| Step: 6
Training loss: 0.7253466451579805
Validation loss: 2.8288427534529963

Epoch: 5| Step: 7
Training loss: 1.0354838878422474
Validation loss: 2.983379284453318

Epoch: 5| Step: 8
Training loss: 1.3620800421017552
Validation loss: 2.95430057748511

Epoch: 5| Step: 9
Training loss: 0.9045176226310442
Validation loss: 3.0528931677113365

Epoch: 5| Step: 10
Training loss: 0.862073960330897
Validation loss: 2.9698375015084677

Epoch: 5| Step: 11
Training loss: 0.48859514446687813
Validation loss: 2.9969017650136993

Epoch: 265| Step: 0
Training loss: 1.7609795417268808
Validation loss: 2.9569130743307888

Epoch: 5| Step: 1
Training loss: 0.7963433829842135
Validation loss: 2.8420574020744813

Epoch: 5| Step: 2
Training loss: 0.9267042363621683
Validation loss: 3.03033746177807

Epoch: 5| Step: 3
Training loss: 0.9411312350541466
Validation loss: 2.8388789906850738

Epoch: 5| Step: 4
Training loss: 0.9238336413745021
Validation loss: 2.9213869295795476

Epoch: 5| Step: 5
Training loss: 1.107136899958462
Validation loss: 2.852299334639025

Epoch: 5| Step: 6
Training loss: 0.9478738307007464
Validation loss: 2.870431092618664

Epoch: 5| Step: 7
Training loss: 0.8976927282559194
Validation loss: 2.8970427589029475

Epoch: 5| Step: 8
Training loss: 0.8423252792753297
Validation loss: 2.936444207778052

Epoch: 5| Step: 9
Training loss: 0.9023752908850192
Validation loss: 2.8433938449664384

Epoch: 5| Step: 10
Training loss: 0.9775196115424039
Validation loss: 2.921366241007555

Epoch: 5| Step: 11
Training loss: 0.6452776199778897
Validation loss: 2.865495100859301

Epoch: 266| Step: 0
Training loss: 1.6556517762221818
Validation loss: 2.8804285104394878

Epoch: 5| Step: 1
Training loss: 1.110545977613239
Validation loss: 2.868837254401675

Epoch: 5| Step: 2
Training loss: 0.9671850484838522
Validation loss: 3.0566524225074345

Epoch: 5| Step: 3
Training loss: 1.1318816997765815
Validation loss: 2.909378560586807

Epoch: 5| Step: 4
Training loss: 0.8892537653759933
Validation loss: 2.9795459236926494

Epoch: 5| Step: 5
Training loss: 0.8560620345249262
Validation loss: 3.0563301489370307

Epoch: 5| Step: 6
Training loss: 0.900337995534287
Validation loss: 2.849032327271074

Epoch: 5| Step: 7
Training loss: 0.9137127198886908
Validation loss: 2.895635774217609

Epoch: 5| Step: 8
Training loss: 0.5271366701794971
Validation loss: 3.0235715470017848

Epoch: 5| Step: 9
Training loss: 0.8558778873114663
Validation loss: 2.843306227352083

Epoch: 5| Step: 10
Training loss: 1.0575930098625808
Validation loss: 2.8768232169067267

Epoch: 5| Step: 11
Training loss: 1.854476888471978
Validation loss: 2.957491967724265

Epoch: 267| Step: 0
Training loss: 0.5458116547693636
Validation loss: 2.8702864154093506

Epoch: 5| Step: 1
Training loss: 1.0665835278615161
Validation loss: 3.020688810947255

Epoch: 5| Step: 2
Training loss: 0.7060164656258936
Validation loss: 3.0477377379240136

Epoch: 5| Step: 3
Training loss: 1.080815758357593
Validation loss: 2.975768032496963

Epoch: 5| Step: 4
Training loss: 1.7784848082126574
Validation loss: 3.001929748616219

Epoch: 5| Step: 5
Training loss: 0.8304159755930407
Validation loss: 3.02665929460643

Epoch: 5| Step: 6
Training loss: 0.8292436781220484
Validation loss: 2.9733945420156065

Epoch: 5| Step: 7
Training loss: 1.0189266238949186
Validation loss: 2.998615720381283

Epoch: 5| Step: 8
Training loss: 1.1340515726529572
Validation loss: 2.9668801693402185

Epoch: 5| Step: 9
Training loss: 0.9207221759545572
Validation loss: 2.9119337486491887

Epoch: 5| Step: 10
Training loss: 0.9159326902150661
Validation loss: 3.0175249508613917

Epoch: 5| Step: 11
Training loss: 0.6226154136907678
Validation loss: 2.8206260978797464

Epoch: 268| Step: 0
Training loss: 0.8130330024768091
Validation loss: 3.019046946940484

Epoch: 5| Step: 1
Training loss: 1.174719752716053
Validation loss: 2.9863819910001963

Epoch: 5| Step: 2
Training loss: 0.9674623299197185
Validation loss: 3.045107170504286

Epoch: 5| Step: 3
Training loss: 1.0479545151616927
Validation loss: 3.0242500954608764

Epoch: 5| Step: 4
Training loss: 0.8088433069473231
Validation loss: 2.9269036795621424

Epoch: 5| Step: 5
Training loss: 0.9960020733700662
Validation loss: 2.9448362247013784

Epoch: 5| Step: 6
Training loss: 0.6946752821533869
Validation loss: 3.041678798773273

Epoch: 5| Step: 7
Training loss: 1.2064787455084518
Validation loss: 3.0119727588743497

Epoch: 5| Step: 8
Training loss: 0.46963701564413246
Validation loss: 2.890458055778841

Epoch: 5| Step: 9
Training loss: 1.1447793216519866
Validation loss: 2.8902517026136163

Epoch: 5| Step: 10
Training loss: 1.6962517452582402
Validation loss: 3.00210887576869

Epoch: 5| Step: 11
Training loss: 0.6293065473498703
Validation loss: 2.9067524608930717

Epoch: 269| Step: 0
Training loss: 1.0550097503030758
Validation loss: 2.8844326329009835

Epoch: 5| Step: 1
Training loss: 0.8523310421731485
Validation loss: 2.8691553886281294

Epoch: 5| Step: 2
Training loss: 1.0143644286032032
Validation loss: 2.8701130374940313

Epoch: 5| Step: 3
Training loss: 0.740178007933872
Validation loss: 3.0373056362640325

Epoch: 5| Step: 4
Training loss: 0.6581449398052296
Validation loss: 2.9876549058121826

Epoch: 5| Step: 5
Training loss: 1.1428895183643666
Validation loss: 2.8791218111451737

Epoch: 5| Step: 6
Training loss: 1.6915419878685873
Validation loss: 2.9116412101365006

Epoch: 5| Step: 7
Training loss: 1.0060844095587131
Validation loss: 2.954190433731208

Epoch: 5| Step: 8
Training loss: 0.8763200135496242
Validation loss: 2.9090892909598187

Epoch: 5| Step: 9
Training loss: 1.0506849847538484
Validation loss: 2.915505025779611

Epoch: 5| Step: 10
Training loss: 0.7436518628425071
Validation loss: 2.9950039840845815

Epoch: 5| Step: 11
Training loss: 0.44950976689370936
Validation loss: 2.969708488732998

Epoch: 270| Step: 0
Training loss: 1.1290950947186802
Validation loss: 2.9435392888836427

Epoch: 5| Step: 1
Training loss: 0.9490008633934249
Validation loss: 2.908830771811769

Epoch: 5| Step: 2
Training loss: 0.7456145819985792
Validation loss: 2.8188840466279266

Epoch: 5| Step: 3
Training loss: 1.0650441060313198
Validation loss: 2.7837757418332605

Epoch: 5| Step: 4
Training loss: 1.008451333248088
Validation loss: 3.0149682306531673

Epoch: 5| Step: 5
Training loss: 0.7070447804542053
Validation loss: 2.893990658803872

Epoch: 5| Step: 6
Training loss: 0.9054575777063992
Validation loss: 2.9613915450089756

Epoch: 5| Step: 7
Training loss: 0.8645501111246767
Validation loss: 2.890058049457143

Epoch: 5| Step: 8
Training loss: 1.2535914325942312
Validation loss: 2.849936501593131

Epoch: 5| Step: 9
Training loss: 1.7100054148538084
Validation loss: 2.8787353789278054

Epoch: 5| Step: 10
Training loss: 0.8686983161756257
Validation loss: 2.9372074069404346

Epoch: 5| Step: 11
Training loss: 1.5879361191879937
Validation loss: 2.858300742046032

Epoch: 271| Step: 0
Training loss: 0.7955091401971105
Validation loss: 2.885725994032399

Epoch: 5| Step: 1
Training loss: 0.584437930956606
Validation loss: 2.9161210480745163

Epoch: 5| Step: 2
Training loss: 1.101493833309025
Validation loss: 2.9984194347002378

Epoch: 5| Step: 3
Training loss: 0.8315954365420211
Validation loss: 2.931555058642992

Epoch: 5| Step: 4
Training loss: 0.8768112645603803
Validation loss: 2.861434201996411

Epoch: 5| Step: 5
Training loss: 1.00092874552328
Validation loss: 2.7958143236922974

Epoch: 5| Step: 6
Training loss: 0.7022001754098846
Validation loss: 2.8001092186981995

Epoch: 5| Step: 7
Training loss: 1.1715095458803855
Validation loss: 2.861649666383739

Epoch: 5| Step: 8
Training loss: 0.8862961421624778
Validation loss: 2.877905196702795

Epoch: 5| Step: 9
Training loss: 0.7344676020250162
Validation loss: 2.8913756658817094

Epoch: 5| Step: 10
Training loss: 1.7845068487034332
Validation loss: 2.916706641241159

Epoch: 5| Step: 11
Training loss: 0.4375698340403003
Validation loss: 2.8662420787776686

Epoch: 272| Step: 0
Training loss: 0.8771318962866582
Validation loss: 2.9906989429597735

Epoch: 5| Step: 1
Training loss: 1.0034348386659735
Validation loss: 2.8981558259299858

Epoch: 5| Step: 2
Training loss: 0.9665059894725484
Validation loss: 2.8652835383202966

Epoch: 5| Step: 3
Training loss: 1.1623207733471939
Validation loss: 2.93223273701963

Epoch: 5| Step: 4
Training loss: 0.7610237667994183
Validation loss: 2.862176214393657

Epoch: 5| Step: 5
Training loss: 0.9218438676652795
Validation loss: 2.9630903337230747

Epoch: 5| Step: 6
Training loss: 0.6959048972952837
Validation loss: 3.0052653273671384

Epoch: 5| Step: 7
Training loss: 0.5662655885921181
Validation loss: 2.9373860878196925

Epoch: 5| Step: 8
Training loss: 1.7795456880865825
Validation loss: 2.8824866092566053

Epoch: 5| Step: 9
Training loss: 0.763928811638795
Validation loss: 2.8411858599833075

Epoch: 5| Step: 10
Training loss: 0.7468759321262816
Validation loss: 2.8650681357079173

Epoch: 5| Step: 11
Training loss: 1.0430540128567514
Validation loss: 2.922037007945418

Epoch: 273| Step: 0
Training loss: 0.7939258680977267
Validation loss: 2.8164793473280025

Epoch: 5| Step: 1
Training loss: 0.8760944061793902
Validation loss: 2.8958342687115888

Epoch: 5| Step: 2
Training loss: 0.7786731949063337
Validation loss: 2.834204211516806

Epoch: 5| Step: 3
Training loss: 1.344967800378913
Validation loss: 2.8549734730637804

Epoch: 5| Step: 4
Training loss: 1.8078547176881592
Validation loss: 2.9785712732004863

Epoch: 5| Step: 5
Training loss: 0.8205759624463819
Validation loss: 2.8023630780164197

Epoch: 5| Step: 6
Training loss: 1.0485465526005897
Validation loss: 2.9090648097875547

Epoch: 5| Step: 7
Training loss: 0.9290345407353451
Validation loss: 2.975111747160302

Epoch: 5| Step: 8
Training loss: 1.1030532813600462
Validation loss: 2.9770293649774175

Epoch: 5| Step: 9
Training loss: 0.8868616803965499
Validation loss: 2.960421400627917

Epoch: 5| Step: 10
Training loss: 0.7339355290082785
Validation loss: 2.9548379952203545

Epoch: 5| Step: 11
Training loss: 1.2443580617091938
Validation loss: 2.8793752384040787

Epoch: 274| Step: 0
Training loss: 0.992015132800165
Validation loss: 2.9760127790627027

Epoch: 5| Step: 1
Training loss: 0.5613000043755182
Validation loss: 2.985965930504609

Epoch: 5| Step: 2
Training loss: 2.0334317741119965
Validation loss: 2.884274571145497

Epoch: 5| Step: 3
Training loss: 1.0684344110168094
Validation loss: 3.0364853916085868

Epoch: 5| Step: 4
Training loss: 0.6928476298729731
Validation loss: 2.9322766912878584

Epoch: 5| Step: 5
Training loss: 0.798389939535853
Validation loss: 2.9270314260656605

Epoch: 5| Step: 6
Training loss: 0.6511534378746029
Validation loss: 2.9863762362030806

Epoch: 5| Step: 7
Training loss: 0.679979743831127
Validation loss: 3.002858287096832

Epoch: 5| Step: 8
Training loss: 0.9156824087431409
Validation loss: 2.9709229531130465

Epoch: 5| Step: 9
Training loss: 0.8005961134357634
Validation loss: 2.9050121234732744

Epoch: 5| Step: 10
Training loss: 0.5917866772065746
Validation loss: 2.9337509086086286

Epoch: 5| Step: 11
Training loss: 1.0048080727945392
Validation loss: 2.9469606626431126

Epoch: 275| Step: 0
Training loss: 0.9787245049694296
Validation loss: 2.923366866149604

Epoch: 5| Step: 1
Training loss: 0.9038643183498412
Validation loss: 2.9042799059182505

Epoch: 5| Step: 2
Training loss: 0.8156214323002333
Validation loss: 2.9822892894639907

Epoch: 5| Step: 3
Training loss: 1.084153610627838
Validation loss: 2.8753907104044423

Epoch: 5| Step: 4
Training loss: 0.7177681228544739
Validation loss: 2.9595791796963433

Epoch: 5| Step: 5
Training loss: 1.6748694582500916
Validation loss: 2.9019444234993736

Epoch: 5| Step: 6
Training loss: 0.8218606418182189
Validation loss: 2.9708226648239893

Epoch: 5| Step: 7
Training loss: 1.0192497712566164
Validation loss: 2.880094496056449

Epoch: 5| Step: 8
Training loss: 0.6094934641790414
Validation loss: 2.893783699317288

Epoch: 5| Step: 9
Training loss: 0.8486908606374136
Validation loss: 2.9465784443476393

Epoch: 5| Step: 10
Training loss: 1.00153007276295
Validation loss: 2.8958039122168664

Epoch: 5| Step: 11
Training loss: 0.4517073817951976
Validation loss: 2.7805922619878864

Epoch: 276| Step: 0
Training loss: 0.828097001088257
Validation loss: 2.8442106258155664

Epoch: 5| Step: 1
Training loss: 0.9083217092231055
Validation loss: 2.900186297308286

Epoch: 5| Step: 2
Training loss: 1.829913641867092
Validation loss: 2.9452171107865635

Epoch: 5| Step: 3
Training loss: 1.0041825919781329
Validation loss: 2.879441379344764

Epoch: 5| Step: 4
Training loss: 0.9039279523006463
Validation loss: 2.782394468383256

Epoch: 5| Step: 5
Training loss: 0.8160195781051403
Validation loss: 2.8128596429116723

Epoch: 5| Step: 6
Training loss: 0.8787200730546934
Validation loss: 2.9468634912287013

Epoch: 5| Step: 7
Training loss: 0.8737654491690493
Validation loss: 2.929646772313479

Epoch: 5| Step: 8
Training loss: 0.9528087654178204
Validation loss: 2.9126503755499202

Epoch: 5| Step: 9
Training loss: 0.7230849360624497
Validation loss: 2.941603614700541

Epoch: 5| Step: 10
Training loss: 0.7398540153717739
Validation loss: 3.0453679914329777

Epoch: 5| Step: 11
Training loss: 0.7754850930577251
Validation loss: 2.911279665469735

Epoch: 277| Step: 0
Training loss: 0.6591751663618102
Validation loss: 3.070396656762862

Epoch: 5| Step: 1
Training loss: 0.6869450193126717
Validation loss: 2.897375935489552

Epoch: 5| Step: 2
Training loss: 1.1324806516565054
Validation loss: 3.0083162125411125

Epoch: 5| Step: 3
Training loss: 1.0572312937570214
Validation loss: 3.033721198359284

Epoch: 5| Step: 4
Training loss: 0.8514907526711376
Validation loss: 2.855411422856788

Epoch: 5| Step: 5
Training loss: 1.0085012758442682
Validation loss: 2.9959485160975525

Epoch: 5| Step: 6
Training loss: 1.7641175848551565
Validation loss: 2.911170441389535

Epoch: 5| Step: 7
Training loss: 0.592005500908051
Validation loss: 2.9061266452493077

Epoch: 5| Step: 8
Training loss: 0.8489955043651232
Validation loss: 2.904969548592702

Epoch: 5| Step: 9
Training loss: 1.1023925467653055
Validation loss: 2.837814774607725

Epoch: 5| Step: 10
Training loss: 0.5630608517672101
Validation loss: 2.867576053079767

Epoch: 5| Step: 11
Training loss: 0.5860395724081389
Validation loss: 2.8915349713677245

Epoch: 278| Step: 0
Training loss: 0.8049652583165998
Validation loss: 3.054275000282825

Epoch: 5| Step: 1
Training loss: 0.6693786999255593
Validation loss: 2.9958765911928324

Epoch: 5| Step: 2
Training loss: 0.9807050199907444
Validation loss: 2.8696037214782795

Epoch: 5| Step: 3
Training loss: 0.6970496177006272
Validation loss: 2.8837745667000783

Epoch: 5| Step: 4
Training loss: 0.609873885344284
Validation loss: 2.991438538695959

Epoch: 5| Step: 5
Training loss: 0.8232030531155621
Validation loss: 3.0525447553081646

Epoch: 5| Step: 6
Training loss: 0.702050235337902
Validation loss: 2.8825773334468487

Epoch: 5| Step: 7
Training loss: 0.9180532213669685
Validation loss: 2.876405907767889

Epoch: 5| Step: 8
Training loss: 1.2103225130809023
Validation loss: 2.9604592251565283

Epoch: 5| Step: 9
Training loss: 1.7956871418701146
Validation loss: 2.8396024885718663

Epoch: 5| Step: 10
Training loss: 1.082432531320188
Validation loss: 2.898336042014822

Epoch: 5| Step: 11
Training loss: 0.4465209558808592
Validation loss: 2.8988529774670946

Epoch: 279| Step: 0
Training loss: 0.9944235168743651
Validation loss: 2.896873247378579

Epoch: 5| Step: 1
Training loss: 0.7808682462675904
Validation loss: 2.8799358616139776

Epoch: 5| Step: 2
Training loss: 0.8264317385644275
Validation loss: 2.933478605852645

Epoch: 5| Step: 3
Training loss: 0.9776111618114192
Validation loss: 2.9400091581083028

Epoch: 5| Step: 4
Training loss: 1.0772231379568418
Validation loss: 2.8272455298706376

Epoch: 5| Step: 5
Training loss: 1.5931690877723168
Validation loss: 2.9899674688279134

Epoch: 5| Step: 6
Training loss: 0.8902479009199155
Validation loss: 2.8567152768450073

Epoch: 5| Step: 7
Training loss: 0.8204587896785314
Validation loss: 2.9590493945205774

Epoch: 5| Step: 8
Training loss: 0.7892206241311264
Validation loss: 3.000769023213219

Epoch: 5| Step: 9
Training loss: 0.8074089621372724
Validation loss: 2.9582459051797563

Epoch: 5| Step: 10
Training loss: 0.8668009953446036
Validation loss: 2.953231358841448

Epoch: 5| Step: 11
Training loss: 0.7771819439893791
Validation loss: 2.9883130273396783

Epoch: 280| Step: 0
Training loss: 1.2126484258984482
Validation loss: 2.9309145006787127

Epoch: 5| Step: 1
Training loss: 0.8802152253432256
Validation loss: 2.8405880309085374

Epoch: 5| Step: 2
Training loss: 1.19580980315413
Validation loss: 2.95098243844251

Epoch: 5| Step: 3
Training loss: 0.9376528297467459
Validation loss: 2.8432885728341257

Epoch: 5| Step: 4
Training loss: 0.7386157373069308
Validation loss: 2.8891771075450023

Epoch: 5| Step: 5
Training loss: 0.8650019830890481
Validation loss: 2.9446632013590572

Epoch: 5| Step: 6
Training loss: 0.6599383925814751
Validation loss: 2.849255294711877

Epoch: 5| Step: 7
Training loss: 0.7274035026680976
Validation loss: 2.9231116250007902

Epoch: 5| Step: 8
Training loss: 0.6315466853997304
Validation loss: 2.975415840791628

Epoch: 5| Step: 9
Training loss: 0.8700814972995657
Validation loss: 2.8465793214600312

Epoch: 5| Step: 10
Training loss: 1.5843738683813142
Validation loss: 2.9745946805728374

Epoch: 5| Step: 11
Training loss: 1.0536243873383513
Validation loss: 3.0455897106388803

Epoch: 281| Step: 0
Training loss: 1.7019477765356272
Validation loss: 2.9844058902333486

Epoch: 5| Step: 1
Training loss: 0.459283739224289
Validation loss: 3.012731768502414

Epoch: 5| Step: 2
Training loss: 1.3105864426485476
Validation loss: 2.8668680281575463

Epoch: 5| Step: 3
Training loss: 1.0751565619613623
Validation loss: 3.0063198200453223

Epoch: 5| Step: 4
Training loss: 0.8862087446760609
Validation loss: 2.9553720160436456

Epoch: 5| Step: 5
Training loss: 0.9072149007025133
Validation loss: 2.9143255215629984

Epoch: 5| Step: 6
Training loss: 0.7136211675827333
Validation loss: 3.0035552839628585

Epoch: 5| Step: 7
Training loss: 0.8825997965636323
Validation loss: 2.916995235510061

Epoch: 5| Step: 8
Training loss: 0.7168465994652671
Validation loss: 2.915113370407285

Epoch: 5| Step: 9
Training loss: 0.7790524665930086
Validation loss: 2.968854882244771

Epoch: 5| Step: 10
Training loss: 0.9625633875298655
Validation loss: 2.896741712014733

Epoch: 5| Step: 11
Training loss: 0.3584219693558318
Validation loss: 2.9601437386256495

Epoch: 282| Step: 0
Training loss: 0.691206348206698
Validation loss: 2.947204373487699

Epoch: 5| Step: 1
Training loss: 0.9781658590637017
Validation loss: 2.9335359888532277

Epoch: 5| Step: 2
Training loss: 1.0233017926113472
Validation loss: 3.0091628012046474

Epoch: 5| Step: 3
Training loss: 1.0058469308620397
Validation loss: 2.9509278690324114

Epoch: 5| Step: 4
Training loss: 1.6452393083513368
Validation loss: 2.9874905140512027

Epoch: 5| Step: 5
Training loss: 0.8404800488601996
Validation loss: 2.8376970533604164

Epoch: 5| Step: 6
Training loss: 0.8531834984030848
Validation loss: 3.0488660925277498

Epoch: 5| Step: 7
Training loss: 0.9910731027164336
Validation loss: 2.8352394996488766

Epoch: 5| Step: 8
Training loss: 0.6476327429394884
Validation loss: 2.863268187364287

Epoch: 5| Step: 9
Training loss: 1.0924955531189107
Validation loss: 2.8870988697935625

Epoch: 5| Step: 10
Training loss: 0.7812887182178219
Validation loss: 2.9219324646873113

Epoch: 5| Step: 11
Training loss: 0.41324787257501355
Validation loss: 2.89756743335343

Epoch: 283| Step: 0
Training loss: 0.8217123167950712
Validation loss: 2.952508444901851

Epoch: 5| Step: 1
Training loss: 0.8954991264296402
Validation loss: 2.908961900556199

Epoch: 5| Step: 2
Training loss: 1.0702763015306103
Validation loss: 2.9208040059549605

Epoch: 5| Step: 3
Training loss: 1.1713975060726722
Validation loss: 2.9043316029890427

Epoch: 5| Step: 4
Training loss: 1.0068792117390077
Validation loss: 2.961070377317394

Epoch: 5| Step: 5
Training loss: 0.6547066159974076
Validation loss: 2.9593108984273044

Epoch: 5| Step: 6
Training loss: 0.8597152729879967
Validation loss: 2.958505616521885

Epoch: 5| Step: 7
Training loss: 1.056836742879504
Validation loss: 2.9743309800770956

Epoch: 5| Step: 8
Training loss: 1.5092875326967223
Validation loss: 2.9784010568065646

Epoch: 5| Step: 9
Training loss: 0.7480701014645417
Validation loss: 2.9459714751022608

Epoch: 5| Step: 10
Training loss: 1.0543317406717003
Validation loss: 2.970913112357448

Epoch: 5| Step: 11
Training loss: 0.9620149975795242
Validation loss: 2.9136020204532347

Epoch: 284| Step: 0
Training loss: 1.0920617834820316
Validation loss: 2.966009055922932

Epoch: 5| Step: 1
Training loss: 0.8687121074289036
Validation loss: 2.8798399937463617

Epoch: 5| Step: 2
Training loss: 1.7958123423447805
Validation loss: 2.8874889029527706

Epoch: 5| Step: 3
Training loss: 0.7327677406029799
Validation loss: 2.8508590527329294

Epoch: 5| Step: 4
Training loss: 0.9226641752337112
Validation loss: 2.96052175268673

Epoch: 5| Step: 5
Training loss: 1.0141777878221794
Validation loss: 2.8093214423138515

Epoch: 5| Step: 6
Training loss: 0.9317531557718012
Validation loss: 2.9035413948515685

Epoch: 5| Step: 7
Training loss: 0.7377063591826629
Validation loss: 2.863724202878381

Epoch: 5| Step: 8
Training loss: 0.6152805855971374
Validation loss: 2.9604466131191414

Epoch: 5| Step: 9
Training loss: 0.6801166495028066
Validation loss: 2.8793225239765525

Epoch: 5| Step: 10
Training loss: 0.892177032569637
Validation loss: 2.8472305768104937

Epoch: 5| Step: 11
Training loss: 0.20628962750204907
Validation loss: 2.936358185966482

Epoch: 285| Step: 0
Training loss: 0.9734528125519906
Validation loss: 2.894493816646768

Epoch: 5| Step: 1
Training loss: 0.8121938128517753
Validation loss: 2.933488941309841

Epoch: 5| Step: 2
Training loss: 1.063506266982136
Validation loss: 2.9404138965619766

Epoch: 5| Step: 3
Training loss: 0.6892781886707151
Validation loss: 2.9313701392187377

Epoch: 5| Step: 4
Training loss: 0.49711503762595044
Validation loss: 2.9238289846021077

Epoch: 5| Step: 5
Training loss: 0.9334506639459738
Validation loss: 2.8217803995547492

Epoch: 5| Step: 6
Training loss: 0.7190928263529629
Validation loss: 2.8882665652870934

Epoch: 5| Step: 7
Training loss: 0.6019803367172553
Validation loss: 2.9595299648972717

Epoch: 5| Step: 8
Training loss: 1.1042069421776244
Validation loss: 2.998452916850309

Epoch: 5| Step: 9
Training loss: 1.693295663517244
Validation loss: 2.953995446855492

Epoch: 5| Step: 10
Training loss: 0.7231881323631871
Validation loss: 2.876798544030834

Epoch: 5| Step: 11
Training loss: 1.3156664662837387
Validation loss: 2.811631785711368

Epoch: 286| Step: 0
Training loss: 1.1416981495509706
Validation loss: 2.947538504366552

Epoch: 5| Step: 1
Training loss: 1.7435538232851842
Validation loss: 2.975718274213368

Epoch: 5| Step: 2
Training loss: 0.907641165186557
Validation loss: 3.066677546395477

Epoch: 5| Step: 3
Training loss: 1.047047045790218
Validation loss: 2.879803233547163

Epoch: 5| Step: 4
Training loss: 0.705830476440569
Validation loss: 2.9492919306486134

Epoch: 5| Step: 5
Training loss: 0.9075864277292661
Validation loss: 2.9649369631837503

Epoch: 5| Step: 6
Training loss: 0.6049065717958491
Validation loss: 2.7594741375784824

Epoch: 5| Step: 7
Training loss: 0.7067940456333328
Validation loss: 2.855582959021562

Epoch: 5| Step: 8
Training loss: 0.6676717845378106
Validation loss: 2.8419326277880663

Epoch: 5| Step: 9
Training loss: 0.7673960074137205
Validation loss: 2.731469388948195

Epoch: 5| Step: 10
Training loss: 1.1556533098647355
Validation loss: 2.769489806331

Epoch: 5| Step: 11
Training loss: 0.33567278434815984
Validation loss: 2.950854493298451

Epoch: 287| Step: 0
Training loss: 0.8235802007438878
Validation loss: 2.8332471320185086

Epoch: 5| Step: 1
Training loss: 0.6279506887480583
Validation loss: 2.823002786953206

Epoch: 5| Step: 2
Training loss: 0.8883145127321621
Validation loss: 2.869638277351934

Epoch: 5| Step: 3
Training loss: 0.9217772997793386
Validation loss: 2.799931291250919

Epoch: 5| Step: 4
Training loss: 0.8531762327803168
Validation loss: 2.8964515799073918

Epoch: 5| Step: 5
Training loss: 1.536964962293742
Validation loss: 2.9038608260455305

Epoch: 5| Step: 6
Training loss: 0.8780019219101571
Validation loss: 3.010396912233861

Epoch: 5| Step: 7
Training loss: 0.5947423722995471
Validation loss: 2.9293209066972423

Epoch: 5| Step: 8
Training loss: 0.8857671530169249
Validation loss: 2.936461510283849

Epoch: 5| Step: 9
Training loss: 0.6024493826184911
Validation loss: 3.0074775575364376

Epoch: 5| Step: 10
Training loss: 0.969538798214457
Validation loss: 2.935357029085456

Epoch: 5| Step: 11
Training loss: 1.2512493565697782
Validation loss: 2.9055678958359272

Epoch: 288| Step: 0
Training loss: 0.7948843457409986
Validation loss: 2.9507852600248166

Epoch: 5| Step: 1
Training loss: 0.7868247831044747
Validation loss: 2.9037419712362356

Epoch: 5| Step: 2
Training loss: 1.7023949414522264
Validation loss: 2.836580996896958

Epoch: 5| Step: 3
Training loss: 1.0794149228627758
Validation loss: 2.8105269116118365

Epoch: 5| Step: 4
Training loss: 0.9750583203308494
Validation loss: 2.911168370055858

Epoch: 5| Step: 5
Training loss: 0.6806539701701468
Validation loss: 2.864336687509189

Epoch: 5| Step: 6
Training loss: 1.1612776143842534
Validation loss: 2.9889492543223266

Epoch: 5| Step: 7
Training loss: 0.9292019770346278
Validation loss: 2.992294953676946

Epoch: 5| Step: 8
Training loss: 0.6365758349333277
Validation loss: 2.992447874129909

Epoch: 5| Step: 9
Training loss: 0.47680660937299885
Validation loss: 2.9969607843128294

Epoch: 5| Step: 10
Training loss: 0.6497258176600362
Validation loss: 2.8923890307237663

Epoch: 5| Step: 11
Training loss: 0.5723733898156022
Validation loss: 2.928039490771976

Epoch: 289| Step: 0
Training loss: 0.7915798859130805
Validation loss: 2.899124502796639

Epoch: 5| Step: 1
Training loss: 0.8605478086739218
Validation loss: 2.9520304870092975

Epoch: 5| Step: 2
Training loss: 0.8656023676698849
Validation loss: 2.9108643764744775

Epoch: 5| Step: 3
Training loss: 0.8636226065466276
Validation loss: 2.849800513073193

Epoch: 5| Step: 4
Training loss: 0.9104894592957057
Validation loss: 2.8538074383362755

Epoch: 5| Step: 5
Training loss: 0.8425279173484613
Validation loss: 2.8195724784477147

Epoch: 5| Step: 6
Training loss: 1.557303523227971
Validation loss: 3.049127818563246

Epoch: 5| Step: 7
Training loss: 0.9380443899757636
Validation loss: 2.971740427857939

Epoch: 5| Step: 8
Training loss: 0.9830161813023115
Validation loss: 3.109155516170348

Epoch: 5| Step: 9
Training loss: 0.9539609276349649
Validation loss: 2.9802586892673872

Epoch: 5| Step: 10
Training loss: 0.7873250509631813
Validation loss: 2.9692824505280555

Epoch: 5| Step: 11
Training loss: 0.18116175172133123
Validation loss: 2.898964788521312

Epoch: 290| Step: 0
Training loss: 1.0692566724688992
Validation loss: 2.834184379714833

Epoch: 5| Step: 1
Training loss: 0.8951073003626983
Validation loss: 2.853191850846302

Epoch: 5| Step: 2
Training loss: 0.8372213896598408
Validation loss: 2.97458137537435

Epoch: 5| Step: 3
Training loss: 0.6604954000727236
Validation loss: 3.037565148469928

Epoch: 5| Step: 4
Training loss: 0.9297102276243904
Validation loss: 2.914360218674618

Epoch: 5| Step: 5
Training loss: 0.6043191640598685
Validation loss: 2.864619855936903

Epoch: 5| Step: 6
Training loss: 0.7981244931260473
Validation loss: 2.937821333469214

Epoch: 5| Step: 7
Training loss: 0.6927125519549949
Validation loss: 2.8827383484991302

Epoch: 5| Step: 8
Training loss: 0.65968990218874
Validation loss: 2.89101095286401

Epoch: 5| Step: 9
Training loss: 0.8041531909215428
Validation loss: 2.9162847586777403

Epoch: 5| Step: 10
Training loss: 0.6887448917483336
Validation loss: 2.9514787784924796

Epoch: 5| Step: 11
Training loss: 3.1225469498048146
Validation loss: 2.9746486388211912

Epoch: 291| Step: 0
Training loss: 0.8006184482231938
Validation loss: 3.2129043996219964

Epoch: 5| Step: 1
Training loss: 1.1781953886744498
Validation loss: 2.9763725901017155

Epoch: 5| Step: 2
Training loss: 1.7275568657664462
Validation loss: 3.09094343136068

Epoch: 5| Step: 3
Training loss: 0.9207686558329362
Validation loss: 3.1076416443019896

Epoch: 5| Step: 4
Training loss: 0.9543209389874266
Validation loss: 2.9617105379077135

Epoch: 5| Step: 5
Training loss: 0.7514852281845774
Validation loss: 2.899394560238982

Epoch: 5| Step: 6
Training loss: 0.886186751030863
Validation loss: 2.9310974288796143

Epoch: 5| Step: 7
Training loss: 0.9447471252058494
Validation loss: 2.977334560679396

Epoch: 5| Step: 8
Training loss: 0.7444225588194209
Validation loss: 2.944856380691195

Epoch: 5| Step: 9
Training loss: 0.7758592779558778
Validation loss: 2.892968404963719

Epoch: 5| Step: 10
Training loss: 0.5299442737900906
Validation loss: 2.8479876820310386

Epoch: 5| Step: 11
Training loss: 0.63114766717235
Validation loss: 2.9121184900057155

Epoch: 292| Step: 0
Training loss: 1.5584762643690029
Validation loss: 2.7638575910482017

Epoch: 5| Step: 1
Training loss: 0.8566692759762322
Validation loss: 2.9254674976701187

Epoch: 5| Step: 2
Training loss: 0.8872968494926419
Validation loss: 2.930124536765537

Epoch: 5| Step: 3
Training loss: 0.9905335465343905
Validation loss: 3.1045499038091076

Epoch: 5| Step: 4
Training loss: 0.9386648570737771
Validation loss: 3.004191328459809

Epoch: 5| Step: 5
Training loss: 0.8911696324755395
Validation loss: 2.9415967659214304

Epoch: 5| Step: 6
Training loss: 0.9192468389706265
Validation loss: 2.8983099087636313

Epoch: 5| Step: 7
Training loss: 0.8575184274589682
Validation loss: 2.9533067206661223

Epoch: 5| Step: 8
Training loss: 0.9361595107023453
Validation loss: 2.9940136117158587

Epoch: 5| Step: 9
Training loss: 0.9837307108208264
Validation loss: 2.9774736459998

Epoch: 5| Step: 10
Training loss: 0.7015407728811157
Validation loss: 2.8780458908171185

Epoch: 5| Step: 11
Training loss: 0.6340097945235936
Validation loss: 2.8810604908888844

Epoch: 293| Step: 0
Training loss: 1.101509796396849
Validation loss: 2.93361205981247

Epoch: 5| Step: 1
Training loss: 0.9194397847619996
Validation loss: 2.9448215200185914

Epoch: 5| Step: 2
Training loss: 1.7197289193357643
Validation loss: 2.936361355965875

Epoch: 5| Step: 3
Training loss: 0.7346814916081889
Validation loss: 2.980695630025472

Epoch: 5| Step: 4
Training loss: 0.7439309773524935
Validation loss: 2.9532655114010047

Epoch: 5| Step: 5
Training loss: 0.8030888501057935
Validation loss: 3.0256845172653755

Epoch: 5| Step: 6
Training loss: 0.6709522742113698
Validation loss: 3.0190100736192

Epoch: 5| Step: 7
Training loss: 0.6368853111293415
Validation loss: 3.028977112215429

Epoch: 5| Step: 8
Training loss: 0.8779159052597628
Validation loss: 3.049303935310267

Epoch: 5| Step: 9
Training loss: 0.7801668287645267
Validation loss: 2.9776980552708583

Epoch: 5| Step: 10
Training loss: 1.0039128997226265
Validation loss: 2.949922692368914

Epoch: 5| Step: 11
Training loss: 1.0149530975892882
Validation loss: 3.041071243447193

Epoch: 294| Step: 0
Training loss: 0.7950192328591789
Validation loss: 2.982808049583146

Epoch: 5| Step: 1
Training loss: 1.0967090361583856
Validation loss: 2.8360139330327554

Epoch: 5| Step: 2
Training loss: 1.3318586041834455
Validation loss: 2.8927269621924494

Epoch: 5| Step: 3
Training loss: 0.7670705344855492
Validation loss: 2.9207405295074396

Epoch: 5| Step: 4
Training loss: 0.5606806791420276
Validation loss: 2.8842197729120924

Epoch: 5| Step: 5
Training loss: 1.1603867529820724
Validation loss: 2.9531110161075147

Epoch: 5| Step: 6
Training loss: 0.7378807798246816
Validation loss: 3.002876654262606

Epoch: 5| Step: 7
Training loss: 0.8645291522104199
Validation loss: 3.001282431096124

Epoch: 5| Step: 8
Training loss: 1.5553748370204767
Validation loss: 2.9309072168007764

Epoch: 5| Step: 9
Training loss: 0.8478551886076103
Validation loss: 3.064510694213861

Epoch: 5| Step: 10
Training loss: 1.031930929848193
Validation loss: 2.920652473761848

Epoch: 5| Step: 11
Training loss: 1.1790200675893698
Validation loss: 3.0126943892235887

Epoch: 295| Step: 0
Training loss: 0.7741374692006568
Validation loss: 2.942990194454702

Epoch: 5| Step: 1
Training loss: 0.7424965064611996
Validation loss: 2.8522093191712776

Epoch: 5| Step: 2
Training loss: 0.925828280642571
Validation loss: 2.9775966406426773

Epoch: 5| Step: 3
Training loss: 0.8872995700978304
Validation loss: 2.8439102302376567

Epoch: 5| Step: 4
Training loss: 0.7396907370222114
Validation loss: 3.0333969830465364

Epoch: 5| Step: 5
Training loss: 1.2312484934841177
Validation loss: 2.9204505705438115

Epoch: 5| Step: 6
Training loss: 0.7625806187394595
Validation loss: 3.007245390962889

Epoch: 5| Step: 7
Training loss: 0.9629087620510726
Validation loss: 2.947993389834141

Epoch: 5| Step: 8
Training loss: 1.0998754907713804
Validation loss: 2.9893845891961552

Epoch: 5| Step: 9
Training loss: 0.7521629139931765
Validation loss: 2.903174920092607

Epoch: 5| Step: 10
Training loss: 0.8006512047844038
Validation loss: 2.9099925155150133

Epoch: 5| Step: 11
Training loss: 3.1969100577332994
Validation loss: 3.078175578210136

Epoch: 296| Step: 0
Training loss: 0.925561903065758
Validation loss: 3.121480290010787

Epoch: 5| Step: 1
Training loss: 1.27695536177128
Validation loss: 3.054386192349667

Epoch: 5| Step: 2
Training loss: 0.9325892259490411
Validation loss: 3.1565529957989416

Epoch: 5| Step: 3
Training loss: 1.1063779724584561
Validation loss: 3.015165511391497

Epoch: 5| Step: 4
Training loss: 1.0202046359239731
Validation loss: 3.0274086565832636

Epoch: 5| Step: 5
Training loss: 0.7946524198516982
Validation loss: 2.978757317747881

Epoch: 5| Step: 6
Training loss: 0.5921920111894516
Validation loss: 2.940285687492766

Epoch: 5| Step: 7
Training loss: 1.6092469988539089
Validation loss: 2.888666035592739

Epoch: 5| Step: 8
Training loss: 1.0354419242086026
Validation loss: 2.8362969239916267

Epoch: 5| Step: 9
Training loss: 0.8688897960348616
Validation loss: 2.954513677429494

Epoch: 5| Step: 10
Training loss: 0.8832679181498947
Validation loss: 2.994149467055405

Epoch: 5| Step: 11
Training loss: 1.1185001584471999
Validation loss: 2.867257016038239

Epoch: 297| Step: 0
Training loss: 0.8136195026305171
Validation loss: 2.950581927338965

Epoch: 5| Step: 1
Training loss: 1.552245248972521
Validation loss: 2.9087112389367

Epoch: 5| Step: 2
Training loss: 0.7613479885682765
Validation loss: 2.964269140933657

Epoch: 5| Step: 3
Training loss: 0.89264216287222
Validation loss: 2.9720451639197774

Epoch: 5| Step: 4
Training loss: 0.8304526527545698
Validation loss: 3.045690214853754

Epoch: 5| Step: 5
Training loss: 0.5878080392411723
Validation loss: 2.997067481825076

Epoch: 5| Step: 6
Training loss: 0.8376209385222222
Validation loss: 3.0594182403335

Epoch: 5| Step: 7
Training loss: 0.9384641140400971
Validation loss: 2.972924262591582

Epoch: 5| Step: 8
Training loss: 0.9251657041128799
Validation loss: 2.9061225364106136

Epoch: 5| Step: 9
Training loss: 0.5937920103770992
Validation loss: 2.8756865635305116

Epoch: 5| Step: 10
Training loss: 1.0685664504527563
Validation loss: 2.8614768448545522

Epoch: 5| Step: 11
Training loss: 0.3569876738151379
Validation loss: 2.9676525764587875

Epoch: 298| Step: 0
Training loss: 0.966798046381077
Validation loss: 2.9008860532069756

Epoch: 5| Step: 1
Training loss: 0.7305062024312089
Validation loss: 3.0257275243760327

Epoch: 5| Step: 2
Training loss: 0.921924072511272
Validation loss: 2.9094995086174777

Epoch: 5| Step: 3
Training loss: 0.7213741166607306
Validation loss: 3.026675656339624

Epoch: 5| Step: 4
Training loss: 0.6199478518951143
Validation loss: 2.923332707511229

Epoch: 5| Step: 5
Training loss: 1.4689843822711137
Validation loss: 2.902865572158911

Epoch: 5| Step: 6
Training loss: 0.6912756543288036
Validation loss: 2.9110997490432635

Epoch: 5| Step: 7
Training loss: 0.6296397131873902
Validation loss: 2.8760548397998167

Epoch: 5| Step: 8
Training loss: 0.7241730314471831
Validation loss: 3.046715854498825

Epoch: 5| Step: 9
Training loss: 1.0062104732734938
Validation loss: 2.961390585610277

Epoch: 5| Step: 10
Training loss: 1.0509630350895187
Validation loss: 2.9283561563733227

Epoch: 5| Step: 11
Training loss: 0.8483601473397184
Validation loss: 3.0125195749261535

Epoch: 299| Step: 0
Training loss: 0.7485630256655446
Validation loss: 3.0129093269325917

Epoch: 5| Step: 1
Training loss: 0.5588228782813882
Validation loss: 3.00465935905346

Epoch: 5| Step: 2
Training loss: 1.6083230589833297
Validation loss: 3.050052264292111

Epoch: 5| Step: 3
Training loss: 0.7982637981628422
Validation loss: 2.929466707174882

Epoch: 5| Step: 4
Training loss: 0.584916611458355
Validation loss: 2.906805337467449

Epoch: 5| Step: 5
Training loss: 0.7010715593499324
Validation loss: 2.9196001536917047

Epoch: 5| Step: 6
Training loss: 0.7952024072618333
Validation loss: 2.9439071722653303

Epoch: 5| Step: 7
Training loss: 0.7879530405826943
Validation loss: 2.9898064836874725

Epoch: 5| Step: 8
Training loss: 0.7704952417854267
Validation loss: 2.946789547384803

Epoch: 5| Step: 9
Training loss: 1.0185926655229465
Validation loss: 3.0100395941057587

Epoch: 5| Step: 10
Training loss: 1.2076775755537408
Validation loss: 2.9431682626721827

Epoch: 5| Step: 11
Training loss: 0.9418109957610658
Validation loss: 3.0365181923010427

Epoch: 300| Step: 0
Training loss: 0.5551366196695947
Validation loss: 2.9652778029658973

Epoch: 5| Step: 1
Training loss: 0.9293306130518112
Validation loss: 2.9605170113248156

Epoch: 5| Step: 2
Training loss: 1.521099859773016
Validation loss: 2.8939104911784517

Epoch: 5| Step: 3
Training loss: 0.6984541564593804
Validation loss: 2.942390939030491

Epoch: 5| Step: 4
Training loss: 0.662782085391735
Validation loss: 2.9434824113922415

Epoch: 5| Step: 5
Training loss: 0.8624906760554886
Validation loss: 2.9372245104773027

Epoch: 5| Step: 6
Training loss: 0.912041214350475
Validation loss: 2.879870935904754

Epoch: 5| Step: 7
Training loss: 1.0437272988780248
Validation loss: 2.945596311944697

Epoch: 5| Step: 8
Training loss: 0.6625114277987654
Validation loss: 2.8887340563894393

Epoch: 5| Step: 9
Training loss: 0.624976539171488
Validation loss: 2.9534146504925425

Epoch: 5| Step: 10
Training loss: 0.7663045708793906
Validation loss: 2.9380460867325904

Epoch: 5| Step: 11
Training loss: 0.47024642188654264
Validation loss: 2.8793657506373695

Epoch: 301| Step: 0
Training loss: 0.646928133602184
Validation loss: 2.8910833768581714

Epoch: 5| Step: 1
Training loss: 0.7598016725436904
Validation loss: 2.9500611169594055

Epoch: 5| Step: 2
Training loss: 0.4732126476280054
Validation loss: 2.9457363292544465

Epoch: 5| Step: 3
Training loss: 0.7524568926228165
Validation loss: 2.982614307403423

Epoch: 5| Step: 4
Training loss: 0.8694225068485022
Validation loss: 2.9270100952072524

Epoch: 5| Step: 5
Training loss: 0.8220089400772878
Validation loss: 2.918475943203008

Epoch: 5| Step: 6
Training loss: 0.7912542289391874
Validation loss: 2.9571547455155986

Epoch: 5| Step: 7
Training loss: 1.7347377363410004
Validation loss: 2.991445832925861

Epoch: 5| Step: 8
Training loss: 0.5935442969720397
Validation loss: 2.9654302071476657

Epoch: 5| Step: 9
Training loss: 0.9121069244417195
Validation loss: 2.976674048602216

Epoch: 5| Step: 10
Training loss: 0.6546056218261059
Validation loss: 2.98182791553925

Epoch: 5| Step: 11
Training loss: 0.6995540859030289
Validation loss: 3.0210675258400923

Epoch: 302| Step: 0
Training loss: 1.6431533949158954
Validation loss: 3.03821205981764

Epoch: 5| Step: 1
Training loss: 1.002925705646459
Validation loss: 2.9113855551879824

Epoch: 5| Step: 2
Training loss: 0.910016257853478
Validation loss: 2.940010472514732

Epoch: 5| Step: 3
Training loss: 0.6498884719755372
Validation loss: 2.907645847410526

Epoch: 5| Step: 4
Training loss: 0.8754959744372319
Validation loss: 2.891080377124444

Epoch: 5| Step: 5
Training loss: 0.8125148918547763
Validation loss: 2.9012815843106847

Epoch: 5| Step: 6
Training loss: 0.6667214063185171
Validation loss: 2.924218708282587

Epoch: 5| Step: 7
Training loss: 0.7560565306932494
Validation loss: 2.936597628005638

Epoch: 5| Step: 8
Training loss: 0.625937854921009
Validation loss: 2.9481521328185725

Epoch: 5| Step: 9
Training loss: 0.9653540431722322
Validation loss: 3.0415558838374688

Epoch: 5| Step: 10
Training loss: 0.7973316604502085
Validation loss: 2.9073650740145927

Epoch: 5| Step: 11
Training loss: 0.27600298766492115
Validation loss: 2.99782272644112

Epoch: 303| Step: 0
Training loss: 1.5916646890811053
Validation loss: 2.998659784911333

Epoch: 5| Step: 1
Training loss: 1.0362779406012157
Validation loss: 3.103985972660464

Epoch: 5| Step: 2
Training loss: 0.892498288246458
Validation loss: 3.0242701886183743

Epoch: 5| Step: 3
Training loss: 1.0181474904947798
Validation loss: 2.935101026635411

Epoch: 5| Step: 4
Training loss: 0.6192925444300328
Validation loss: 3.0517741991747553

Epoch: 5| Step: 5
Training loss: 0.8936424670852832
Validation loss: 2.929030253967692

Epoch: 5| Step: 6
Training loss: 0.9036509635552469
Validation loss: 2.908704736207416

Epoch: 5| Step: 7
Training loss: 0.8208333496313206
Validation loss: 2.823279615532607

Epoch: 5| Step: 8
Training loss: 0.7280166594490777
Validation loss: 3.0375864453566965

Epoch: 5| Step: 9
Training loss: 0.796399105310153
Validation loss: 2.842783683392341

Epoch: 5| Step: 10
Training loss: 0.7459923640364039
Validation loss: 2.8738644437442424

Epoch: 5| Step: 11
Training loss: 1.4973131593741864
Validation loss: 2.8956185828426753

Epoch: 304| Step: 0
Training loss: 0.7664292062788005
Validation loss: 2.9929794710956887

Epoch: 5| Step: 1
Training loss: 0.9838235006539513
Validation loss: 3.068047692008816

Epoch: 5| Step: 2
Training loss: 0.6829905218957995
Validation loss: 3.0259707087449885

Epoch: 5| Step: 3
Training loss: 0.6919390462851714
Validation loss: 2.9829161941518

Epoch: 5| Step: 4
Training loss: 0.814221429229293
Validation loss: 3.063134030474926

Epoch: 5| Step: 5
Training loss: 0.5619768783150351
Validation loss: 2.997811343605298

Epoch: 5| Step: 6
Training loss: 1.4952636487548674
Validation loss: 2.9415023875810675

Epoch: 5| Step: 7
Training loss: 1.0787040703323705
Validation loss: 2.874296076264016

Epoch: 5| Step: 8
Training loss: 0.9339792261815354
Validation loss: 2.8919959554610983

Epoch: 5| Step: 9
Training loss: 0.9887288403085539
Validation loss: 2.9756244873514355

Epoch: 5| Step: 10
Training loss: 0.4874716493725885
Validation loss: 2.9380127783894103

Epoch: 5| Step: 11
Training loss: 0.36888466897519095
Validation loss: 2.9164590466490257

Epoch: 305| Step: 0
Training loss: 1.4529660866094847
Validation loss: 2.9953744216273344

Epoch: 5| Step: 1
Training loss: 1.142330723248511
Validation loss: 3.0053571347972015

Epoch: 5| Step: 2
Training loss: 0.5379320814325822
Validation loss: 3.001234297355809

Epoch: 5| Step: 3
Training loss: 0.63272086998916
Validation loss: 2.9720121797923467

Epoch: 5| Step: 4
Training loss: 0.7914051745031794
Validation loss: 3.0233817181628697

Epoch: 5| Step: 5
Training loss: 0.8277158626198261
Validation loss: 3.013110171317634

Epoch: 5| Step: 6
Training loss: 0.7195267005138728
Validation loss: 2.9792155159544422

Epoch: 5| Step: 7
Training loss: 0.6012653013015217
Validation loss: 3.116285109028263

Epoch: 5| Step: 8
Training loss: 0.563040950061699
Validation loss: 2.9058000325620514

Epoch: 5| Step: 9
Training loss: 0.9784875435521179
Validation loss: 2.944388066595282

Epoch: 5| Step: 10
Training loss: 0.8859420937716757
Validation loss: 2.9429235002741803

Epoch: 5| Step: 11
Training loss: 0.7669017034108068
Validation loss: 2.938822391131671

Epoch: 306| Step: 0
Training loss: 1.4417404986459217
Validation loss: 2.928941175554956

Epoch: 5| Step: 1
Training loss: 0.7504108416302813
Validation loss: 2.9405135631898203

Epoch: 5| Step: 2
Training loss: 0.8289792674961272
Validation loss: 2.9946858340374205

Epoch: 5| Step: 3
Training loss: 0.9248212834996997
Validation loss: 2.945249868818146

Epoch: 5| Step: 4
Training loss: 0.6969719062449442
Validation loss: 2.959969448713775

Epoch: 5| Step: 5
Training loss: 0.5398080618029837
Validation loss: 2.883740951872235

Epoch: 5| Step: 6
Training loss: 0.7712794550830795
Validation loss: 3.016510186211529

Epoch: 5| Step: 7
Training loss: 0.7153888562647063
Validation loss: 2.9843598942931915

Epoch: 5| Step: 8
Training loss: 0.6004202265196009
Validation loss: 2.993354586355534

Epoch: 5| Step: 9
Training loss: 0.867469982155549
Validation loss: 3.11359090633176

Epoch: 5| Step: 10
Training loss: 0.9892276258466604
Validation loss: 2.8851552711731

Epoch: 5| Step: 11
Training loss: 0.3843008419544805
Validation loss: 2.9109342008890406

Epoch: 307| Step: 0
Training loss: 0.7281608638198966
Validation loss: 3.0697040035768937

Epoch: 5| Step: 1
Training loss: 0.8139728255129424
Validation loss: 2.987658034684332

Epoch: 5| Step: 2
Training loss: 0.8094255895526997
Validation loss: 2.949106459343036

Epoch: 5| Step: 3
Training loss: 0.7381886419110278
Validation loss: 2.889705571878239

Epoch: 5| Step: 4
Training loss: 0.9234832700691747
Validation loss: 2.925782404425291

Epoch: 5| Step: 5
Training loss: 1.505937982429701
Validation loss: 2.9145501029679033

Epoch: 5| Step: 6
Training loss: 0.8388369891201157
Validation loss: 2.946689794673136

Epoch: 5| Step: 7
Training loss: 0.801987423467605
Validation loss: 2.951624531158865

Epoch: 5| Step: 8
Training loss: 0.7257549350924213
Validation loss: 2.978125844997354

Epoch: 5| Step: 9
Training loss: 0.5137227254435619
Validation loss: 3.013806847487502

Epoch: 5| Step: 10
Training loss: 0.7171393467646787
Validation loss: 2.9663903546152324

Epoch: 5| Step: 11
Training loss: 0.7173493462412612
Validation loss: 2.98461311948204

Epoch: 308| Step: 0
Training loss: 0.6981149410796976
Validation loss: 3.027796790566862

Epoch: 5| Step: 1
Training loss: 0.8249995072681228
Validation loss: 2.9538603343151055

Epoch: 5| Step: 2
Training loss: 0.9407081073026792
Validation loss: 2.967703042383232

Epoch: 5| Step: 3
Training loss: 1.6046667764397142
Validation loss: 2.9197771085407274

Epoch: 5| Step: 4
Training loss: 0.6094397975020399
Validation loss: 2.870382740792812

Epoch: 5| Step: 5
Training loss: 0.7813637459920445
Validation loss: 2.9813719714503097

Epoch: 5| Step: 6
Training loss: 0.8468095972347996
Validation loss: 2.9082931084478982

Epoch: 5| Step: 7
Training loss: 0.6938223354328708
Validation loss: 3.01335587393051

Epoch: 5| Step: 8
Training loss: 0.8661465970370714
Validation loss: 2.907847310766092

Epoch: 5| Step: 9
Training loss: 0.892068262366381
Validation loss: 2.885645379918568

Epoch: 5| Step: 10
Training loss: 0.7274281666872489
Validation loss: 2.953160353016706

Epoch: 5| Step: 11
Training loss: 0.5991731479605489
Validation loss: 2.8811836551549663

Epoch: 309| Step: 0
Training loss: 0.7165255747754234
Validation loss: 2.963943703348241

Epoch: 5| Step: 1
Training loss: 0.688641316065304
Validation loss: 2.9898404676507244

Epoch: 5| Step: 2
Training loss: 0.7941708778064219
Validation loss: 2.9649892041726544

Epoch: 5| Step: 3
Training loss: 0.6262174907401158
Validation loss: 2.86897834126716

Epoch: 5| Step: 4
Training loss: 0.9372939837115437
Validation loss: 2.9998965510440088

Epoch: 5| Step: 5
Training loss: 1.5591986302263596
Validation loss: 2.9580291515549115

Epoch: 5| Step: 6
Training loss: 0.7382312737559488
Validation loss: 2.9743779326796713

Epoch: 5| Step: 7
Training loss: 0.943564635508422
Validation loss: 3.110145428672324

Epoch: 5| Step: 8
Training loss: 1.1071404531778
Validation loss: 2.99553695306041

Epoch: 5| Step: 9
Training loss: 0.7846203013898237
Validation loss: 2.903544958212708

Epoch: 5| Step: 10
Training loss: 0.5247991132138482
Validation loss: 2.8842231793191115

Epoch: 5| Step: 11
Training loss: 0.8192760641161828
Validation loss: 2.8835668980993154

Epoch: 310| Step: 0
Training loss: 0.9168316555374217
Validation loss: 2.9657838392312543

Epoch: 5| Step: 1
Training loss: 1.122277409205855
Validation loss: 2.924945530289152

Epoch: 5| Step: 2
Training loss: 0.7800669677425492
Validation loss: 2.8913877632095026

Epoch: 5| Step: 3
Training loss: 0.7538090776663575
Validation loss: 2.8528401303980795

Epoch: 5| Step: 4
Training loss: 1.0982383189301974
Validation loss: 3.055706055985456

Epoch: 5| Step: 5
Training loss: 0.5297733991170931
Validation loss: 2.8206373821888104

Epoch: 5| Step: 6
Training loss: 0.6154502610981061
Validation loss: 2.8054373260384

Epoch: 5| Step: 7
Training loss: 0.7584077915554954
Validation loss: 2.92795808398469

Epoch: 5| Step: 8
Training loss: 1.589727074093217
Validation loss: 3.0581102163582607

Epoch: 5| Step: 9
Training loss: 0.8026068370328259
Validation loss: 2.9642309058889933

Epoch: 5| Step: 10
Training loss: 0.7222951450783113
Validation loss: 2.8342955909380576

Epoch: 5| Step: 11
Training loss: 0.6088361069018853
Validation loss: 3.065436544792459

Epoch: 311| Step: 0
Training loss: 0.7790434384605802
Validation loss: 2.946553897050126

Epoch: 5| Step: 1
Training loss: 0.61693500230848
Validation loss: 2.8225837079484206

Epoch: 5| Step: 2
Training loss: 0.9375750829512053
Validation loss: 2.9190434524137387

Epoch: 5| Step: 3
Training loss: 0.855562039518626
Validation loss: 2.788543542474898

Epoch: 5| Step: 4
Training loss: 1.4229525161777214
Validation loss: 2.944933602999176

Epoch: 5| Step: 5
Training loss: 0.6630206068887097
Validation loss: 3.016007456797034

Epoch: 5| Step: 6
Training loss: 0.898796275277902
Validation loss: 2.928155869979737

Epoch: 5| Step: 7
Training loss: 0.7674011725377243
Validation loss: 2.88093078524776

Epoch: 5| Step: 8
Training loss: 0.8404818572514977
Validation loss: 2.9702995639808965

Epoch: 5| Step: 9
Training loss: 0.7682102308795246
Validation loss: 2.8991238243319835

Epoch: 5| Step: 10
Training loss: 0.8290694267596124
Validation loss: 2.9667145962718804

Epoch: 5| Step: 11
Training loss: 0.5029632557156765
Validation loss: 2.880271201571424

Epoch: 312| Step: 0
Training loss: 0.5813192069988712
Validation loss: 2.8743848591769723

Epoch: 5| Step: 1
Training loss: 0.7527806472215318
Validation loss: 2.9936709797729755

Epoch: 5| Step: 2
Training loss: 0.6691620412985761
Validation loss: 2.9848080265990857

Epoch: 5| Step: 3
Training loss: 0.8427336540866243
Validation loss: 2.966628836049461

Epoch: 5| Step: 4
Training loss: 0.7062584884943636
Validation loss: 2.9887993556645567

Epoch: 5| Step: 5
Training loss: 0.8300324550855595
Validation loss: 3.018050873399678

Epoch: 5| Step: 6
Training loss: 0.4491712462145182
Validation loss: 2.9110540451659874

Epoch: 5| Step: 7
Training loss: 0.820183335080684
Validation loss: 2.9729234706495165

Epoch: 5| Step: 8
Training loss: 0.793106367825735
Validation loss: 2.951079960655503

Epoch: 5| Step: 9
Training loss: 0.6551894519270657
Validation loss: 2.836420450694247

Epoch: 5| Step: 10
Training loss: 1.4972421406915277
Validation loss: 2.928617761920519

Epoch: 5| Step: 11
Training loss: 0.48809385136801636
Validation loss: 2.843019279805962

Epoch: 313| Step: 0
Training loss: 1.597147891024254
Validation loss: 2.893946061245054

Epoch: 5| Step: 1
Training loss: 0.6928878470311493
Validation loss: 2.8696609139584366

Epoch: 5| Step: 2
Training loss: 0.693015193135505
Validation loss: 2.9067319347351397

Epoch: 5| Step: 3
Training loss: 0.5862542377147955
Validation loss: 2.873278036527707

Epoch: 5| Step: 4
Training loss: 0.6878692762277808
Validation loss: 2.9170790868909053

Epoch: 5| Step: 5
Training loss: 0.8638372572617709
Validation loss: 2.8862353562393417

Epoch: 5| Step: 6
Training loss: 0.8579426011891003
Validation loss: 3.002668422508813

Epoch: 5| Step: 7
Training loss: 0.673280244420616
Validation loss: 2.930409060312444

Epoch: 5| Step: 8
Training loss: 0.8256033526231463
Validation loss: 3.009792614089064

Epoch: 5| Step: 9
Training loss: 0.830116935271482
Validation loss: 2.951188449909851

Epoch: 5| Step: 10
Training loss: 0.7247853438176606
Validation loss: 2.9836613632362847

Epoch: 5| Step: 11
Training loss: 0.9368320628806092
Validation loss: 3.0871762328591164

Epoch: 314| Step: 0
Training loss: 0.8735959163578186
Validation loss: 2.9235826608844646

Epoch: 5| Step: 1
Training loss: 0.8442139233174605
Validation loss: 2.9299708996500495

Epoch: 5| Step: 2
Training loss: 0.6952117246827638
Validation loss: 2.8909195071195053

Epoch: 5| Step: 3
Training loss: 0.5877285604051126
Validation loss: 2.9104816707122834

Epoch: 5| Step: 4
Training loss: 0.640206595767198
Validation loss: 2.8949013703762407

Epoch: 5| Step: 5
Training loss: 0.8574544774419893
Validation loss: 2.96084606999103

Epoch: 5| Step: 6
Training loss: 0.7944885872608749
Validation loss: 2.9183034368719634

Epoch: 5| Step: 7
Training loss: 1.6481779355172348
Validation loss: 2.9857397171329363

Epoch: 5| Step: 8
Training loss: 0.7089252710008203
Validation loss: 2.9411803754495427

Epoch: 5| Step: 9
Training loss: 0.7084679943062345
Validation loss: 2.856009182144323

Epoch: 5| Step: 10
Training loss: 0.9469648060527845
Validation loss: 2.9839966152975643

Epoch: 5| Step: 11
Training loss: 0.31025706269480974
Validation loss: 3.0316810203154434

Epoch: 315| Step: 0
Training loss: 0.8585650007938093
Validation loss: 3.007796924104861

Epoch: 5| Step: 1
Training loss: 0.7726988685201717
Validation loss: 2.963546200946005

Epoch: 5| Step: 2
Training loss: 0.7510183890690758
Validation loss: 3.009420429149604

Epoch: 5| Step: 3
Training loss: 0.6058385150596874
Validation loss: 2.929558696034664

Epoch: 5| Step: 4
Training loss: 0.841987039633924
Validation loss: 2.982913759676593

Epoch: 5| Step: 5
Training loss: 0.6816021490304944
Validation loss: 2.9837952428508494

Epoch: 5| Step: 6
Training loss: 1.5615577908685967
Validation loss: 2.905356926239338

Epoch: 5| Step: 7
Training loss: 0.7462825436420952
Validation loss: 3.0270743399895808

Epoch: 5| Step: 8
Training loss: 0.8560983788117471
Validation loss: 2.9355252236155587

Epoch: 5| Step: 9
Training loss: 0.8734055364830304
Validation loss: 2.984232478042383

Epoch: 5| Step: 10
Training loss: 0.5013401727118978
Validation loss: 2.9204878174618543

Epoch: 5| Step: 11
Training loss: 0.369018595068018
Validation loss: 2.9273159142853893

Epoch: 316| Step: 0
Training loss: 1.4473535920255012
Validation loss: 2.971170211879394

Epoch: 5| Step: 1
Training loss: 0.4712081985248563
Validation loss: 2.9512825050378937

Epoch: 5| Step: 2
Training loss: 0.5934005009837104
Validation loss: 2.9359071518522395

Epoch: 5| Step: 3
Training loss: 0.5707470531646541
Validation loss: 2.9498135301686896

Epoch: 5| Step: 4
Training loss: 0.4370742156450844
Validation loss: 2.970615322964872

Epoch: 5| Step: 5
Training loss: 0.7047981488295004
Validation loss: 2.9649544428423424

Epoch: 5| Step: 6
Training loss: 0.8623654094670907
Validation loss: 2.962090629214137

Epoch: 5| Step: 7
Training loss: 0.6513311785076943
Validation loss: 2.9906062670007723

Epoch: 5| Step: 8
Training loss: 0.9565749345611159
Validation loss: 3.063854242484201

Epoch: 5| Step: 9
Training loss: 0.9870251902348501
Validation loss: 2.9111026394233837

Epoch: 5| Step: 10
Training loss: 0.7375425649741313
Validation loss: 2.9680374762790174

Epoch: 5| Step: 11
Training loss: 0.6121927794870943
Validation loss: 2.8701628060191333

Epoch: 317| Step: 0
Training loss: 0.7163586017234124
Validation loss: 2.981242618111802

Epoch: 5| Step: 1
Training loss: 0.9039622402407115
Validation loss: 3.026226423251281

Epoch: 5| Step: 2
Training loss: 0.5171133581763943
Validation loss: 3.076389569042543

Epoch: 5| Step: 3
Training loss: 0.4082791015883811
Validation loss: 3.0066901652033904

Epoch: 5| Step: 4
Training loss: 0.7734292540447821
Validation loss: 2.9805771494260256

Epoch: 5| Step: 5
Training loss: 0.6835435249406443
Validation loss: 2.825756860651861

Epoch: 5| Step: 6
Training loss: 1.5572823956914237
Validation loss: 2.984092379464459

Epoch: 5| Step: 7
Training loss: 0.8157339293720395
Validation loss: 3.006899750509282

Epoch: 5| Step: 8
Training loss: 0.6685579166674269
Validation loss: 2.841777853011781

Epoch: 5| Step: 9
Training loss: 0.7772887704086909
Validation loss: 2.9899551955611754

Epoch: 5| Step: 10
Training loss: 0.5768383761731745
Validation loss: 2.9671365871149358

Epoch: 5| Step: 11
Training loss: 0.8638171435701162
Validation loss: 3.0573748307016126

Epoch: 318| Step: 0
Training loss: 0.7935900204055071
Validation loss: 2.975911066654335

Epoch: 5| Step: 1
Training loss: 0.7387876035669549
Validation loss: 2.894456997157957

Epoch: 5| Step: 2
Training loss: 0.483936680621252
Validation loss: 3.0939983146248213

Epoch: 5| Step: 3
Training loss: 0.6993508240831074
Validation loss: 3.117833554172357

Epoch: 5| Step: 4
Training loss: 1.0649663685247845
Validation loss: 2.973440046070457

Epoch: 5| Step: 5
Training loss: 0.5446509778312969
Validation loss: 3.023837474615862

Epoch: 5| Step: 6
Training loss: 0.5700855326056897
Validation loss: 2.963882233415484

Epoch: 5| Step: 7
Training loss: 0.6063975931211681
Validation loss: 3.019690209630007

Epoch: 5| Step: 8
Training loss: 1.497118168393827
Validation loss: 3.13130861875953

Epoch: 5| Step: 9
Training loss: 0.7570364606459487
Validation loss: 2.941642505197116

Epoch: 5| Step: 10
Training loss: 0.752803569279924
Validation loss: 2.962971414006508

Epoch: 5| Step: 11
Training loss: 0.46189370624617443
Validation loss: 3.028833622357284

Epoch: 319| Step: 0
Training loss: 0.7326615005145574
Validation loss: 2.9895902970307136

Epoch: 5| Step: 1
Training loss: 0.7374532183664413
Validation loss: 2.9390167926355315

Epoch: 5| Step: 2
Training loss: 0.7024658080091633
Validation loss: 3.0311217067875287

Epoch: 5| Step: 3
Training loss: 0.6719172264846512
Validation loss: 2.952851651170654

Epoch: 5| Step: 4
Training loss: 0.6227560051973434
Validation loss: 2.9991493227661135

Epoch: 5| Step: 5
Training loss: 0.44367112949776893
Validation loss: 3.001834603135176

Epoch: 5| Step: 6
Training loss: 0.652966778586306
Validation loss: 2.986568210914737

Epoch: 5| Step: 7
Training loss: 0.8107302906300282
Validation loss: 3.040838227827824

Epoch: 5| Step: 8
Training loss: 1.5787489762231162
Validation loss: 2.963492147817475

Epoch: 5| Step: 9
Training loss: 0.6206653965214163
Validation loss: 3.0053580768550185

Epoch: 5| Step: 10
Training loss: 1.0361284980360514
Validation loss: 3.0040832586433326

Epoch: 5| Step: 11
Training loss: 0.40256590404353504
Validation loss: 2.895591181412047

Epoch: 320| Step: 0
Training loss: 1.6097406508969152
Validation loss: 3.0565110476717634

Epoch: 5| Step: 1
Training loss: 0.7548669810935932
Validation loss: 3.0684339424006746

Epoch: 5| Step: 2
Training loss: 0.6536527509183969
Validation loss: 3.002958736124109

Epoch: 5| Step: 3
Training loss: 0.7917473693336602
Validation loss: 3.031472102939154

Epoch: 5| Step: 4
Training loss: 0.7027853675310154
Validation loss: 2.982903928506161

Epoch: 5| Step: 5
Training loss: 0.7834663234257883
Validation loss: 2.8945545773889645

Epoch: 5| Step: 6
Training loss: 0.7814224434318671
Validation loss: 2.999392332019133

Epoch: 5| Step: 7
Training loss: 0.5991218399005898
Validation loss: 2.937819040842562

Epoch: 5| Step: 8
Training loss: 0.5481369172978845
Validation loss: 3.010270456153605

Epoch: 5| Step: 9
Training loss: 0.6781382388040009
Validation loss: 2.8924256532929093

Epoch: 5| Step: 10
Training loss: 0.6727442552015759
Validation loss: 2.9205190432791426

Epoch: 5| Step: 11
Training loss: 0.6096170384894423
Validation loss: 2.894970042491514

Epoch: 321| Step: 0
Training loss: 0.6935910549743088
Validation loss: 3.0262741168107836

Epoch: 5| Step: 1
Training loss: 0.8378839737065733
Validation loss: 2.848812843434153

Epoch: 5| Step: 2
Training loss: 0.6217196208126147
Validation loss: 2.92222859288159

Epoch: 5| Step: 3
Training loss: 1.515851426662334
Validation loss: 2.909697245129248

Epoch: 5| Step: 4
Training loss: 0.5052971384972638
Validation loss: 3.0062251670906197

Epoch: 5| Step: 5
Training loss: 1.088078973926234
Validation loss: 3.037383042871592

Epoch: 5| Step: 6
Training loss: 0.8630114517822388
Validation loss: 3.0685960341272387

Epoch: 5| Step: 7
Training loss: 0.595335650056487
Validation loss: 3.035902770218927

Epoch: 5| Step: 8
Training loss: 0.8315679845446292
Validation loss: 2.9698815314216014

Epoch: 5| Step: 9
Training loss: 0.7708417316357299
Validation loss: 2.9039092704203733

Epoch: 5| Step: 10
Training loss: 0.5999658872920643
Validation loss: 2.9704320793556422

Epoch: 5| Step: 11
Training loss: 0.2962260305590687
Validation loss: 2.9734665029170033

Epoch: 322| Step: 0
Training loss: 1.0290624362402234
Validation loss: 2.9162328613198403

Epoch: 5| Step: 1
Training loss: 0.9133263256217186
Validation loss: 2.8644829518618824

Epoch: 5| Step: 2
Training loss: 0.6613853344222539
Validation loss: 2.918077857493987

Epoch: 5| Step: 3
Training loss: 0.639180555375094
Validation loss: 3.0075666517047486

Epoch: 5| Step: 4
Training loss: 0.48622589875337807
Validation loss: 3.0249526312432207

Epoch: 5| Step: 5
Training loss: 1.5532905782019057
Validation loss: 2.8992100977205313

Epoch: 5| Step: 6
Training loss: 0.8612258746639608
Validation loss: 2.9694618107920605

Epoch: 5| Step: 7
Training loss: 0.6294564866971313
Validation loss: 2.860055175512451

Epoch: 5| Step: 8
Training loss: 0.9991265893448886
Validation loss: 2.9309495369293597

Epoch: 5| Step: 9
Training loss: 0.7439448782513213
Validation loss: 3.0265923205317797

Epoch: 5| Step: 10
Training loss: 0.8125618030811235
Validation loss: 3.003739585932494

Epoch: 5| Step: 11
Training loss: 0.5224462774483819
Validation loss: 3.007617468517753

Epoch: 323| Step: 0
Training loss: 1.0231946118255428
Validation loss: 2.9923573969455997

Epoch: 5| Step: 1
Training loss: 0.6246435579509273
Validation loss: 3.05941292814254

Epoch: 5| Step: 2
Training loss: 1.4852846269743119
Validation loss: 2.960125905030143

Epoch: 5| Step: 3
Training loss: 0.9414497460411703
Validation loss: 2.9308860904018847

Epoch: 5| Step: 4
Training loss: 0.6315305936021767
Validation loss: 2.9888036100981896

Epoch: 5| Step: 5
Training loss: 0.7914891085691654
Validation loss: 3.014959159698884

Epoch: 5| Step: 6
Training loss: 0.5337714774748745
Validation loss: 2.9325879451527226

Epoch: 5| Step: 7
Training loss: 0.6204380917185573
Validation loss: 3.0301383952732044

Epoch: 5| Step: 8
Training loss: 0.4864075377557841
Validation loss: 2.9175970478255433

Epoch: 5| Step: 9
Training loss: 0.6878230029720662
Validation loss: 2.942531314803142

Epoch: 5| Step: 10
Training loss: 0.5531733895811137
Validation loss: 2.9944498757189453

Epoch: 5| Step: 11
Training loss: 1.1796334866922522
Validation loss: 2.9819040404748423

Epoch: 324| Step: 0
Training loss: 0.8680413312806204
Validation loss: 3.016602744738955

Epoch: 5| Step: 1
Training loss: 1.4698337858001627
Validation loss: 2.9272864408154318

Epoch: 5| Step: 2
Training loss: 0.6020903315241916
Validation loss: 2.964301058389736

Epoch: 5| Step: 3
Training loss: 0.5396777525763166
Validation loss: 3.0480461738869495

Epoch: 5| Step: 4
Training loss: 0.6538926427375662
Validation loss: 3.0623503505707603

Epoch: 5| Step: 5
Training loss: 0.8828764360619523
Validation loss: 3.043530792186263

Epoch: 5| Step: 6
Training loss: 0.77780340971794
Validation loss: 3.002638299135391

Epoch: 5| Step: 7
Training loss: 0.6739262606159313
Validation loss: 2.9968707964048584

Epoch: 5| Step: 8
Training loss: 0.807652833606286
Validation loss: 2.886418951191041

Epoch: 5| Step: 9
Training loss: 0.7440485859819215
Validation loss: 3.0045581171510607

Epoch: 5| Step: 10
Training loss: 0.757449426882728
Validation loss: 3.000865917274322

Epoch: 5| Step: 11
Training loss: 0.4756205896681878
Validation loss: 3.041038214195992

Epoch: 325| Step: 0
Training loss: 0.7594169071392057
Validation loss: 2.982987279285756

Epoch: 5| Step: 1
Training loss: 1.5277409732123077
Validation loss: 2.992711242973559

Epoch: 5| Step: 2
Training loss: 0.8634703416132149
Validation loss: 2.9642960214599814

Epoch: 5| Step: 3
Training loss: 0.9097253327805886
Validation loss: 3.057468007388977

Epoch: 5| Step: 4
Training loss: 0.6339515042906104
Validation loss: 2.926103507113068

Epoch: 5| Step: 5
Training loss: 0.7252014702356483
Validation loss: 2.987586033219438

Epoch: 5| Step: 6
Training loss: 0.6456118455120975
Validation loss: 3.0382344769459237

Epoch: 5| Step: 7
Training loss: 0.8018466468133407
Validation loss: 2.9904542124156177

Epoch: 5| Step: 8
Training loss: 0.543485656148933
Validation loss: 3.0289377392750656

Epoch: 5| Step: 9
Training loss: 0.8290401296692581
Validation loss: 3.0480606641322656

Epoch: 5| Step: 10
Training loss: 0.6480919250318379
Validation loss: 2.9396805988894594

Epoch: 5| Step: 11
Training loss: 0.44947439465986183
Validation loss: 2.9388025926356565

Epoch: 326| Step: 0
Training loss: 0.630718817863542
Validation loss: 2.9584351855640647

Epoch: 5| Step: 1
Training loss: 0.9018534860139954
Validation loss: 2.983354327369501

Epoch: 5| Step: 2
Training loss: 0.5706239398641443
Validation loss: 2.904395691166056

Epoch: 5| Step: 3
Training loss: 0.6156023408621563
Validation loss: 2.948083752636146

Epoch: 5| Step: 4
Training loss: 0.8368116069027933
Validation loss: 2.9731122710194917

Epoch: 5| Step: 5
Training loss: 0.4925623783072215
Validation loss: 3.048165753829783

Epoch: 5| Step: 6
Training loss: 1.0199508680403422
Validation loss: 2.808555139409753

Epoch: 5| Step: 7
Training loss: 0.5399996034302845
Validation loss: 2.9643160015661048

Epoch: 5| Step: 8
Training loss: 1.467529357798462
Validation loss: 3.0568674964113343

Epoch: 5| Step: 9
Training loss: 0.5872616365496992
Validation loss: 2.9687403929705525

Epoch: 5| Step: 10
Training loss: 0.7676794164862926
Validation loss: 2.9392264379071906

Epoch: 5| Step: 11
Training loss: 0.7734092553115909
Validation loss: 2.9176711952508887

Epoch: 327| Step: 0
Training loss: 0.9710341566464197
Validation loss: 2.9163106439920456

Epoch: 5| Step: 1
Training loss: 1.0703059286765084
Validation loss: 2.9349860499319647

Epoch: 5| Step: 2
Training loss: 0.8224478766555459
Validation loss: 2.8869968258003764

Epoch: 5| Step: 3
Training loss: 0.7147257556359279
Validation loss: 2.9891427221598525

Epoch: 5| Step: 4
Training loss: 0.9184685178582954
Validation loss: 2.8816079135999866

Epoch: 5| Step: 5
Training loss: 0.5589625334987686
Validation loss: 2.9710038196168314

Epoch: 5| Step: 6
Training loss: 0.3169949553175529
Validation loss: 2.897778649520666

Epoch: 5| Step: 7
Training loss: 1.423031347223048
Validation loss: 3.013561643149003

Epoch: 5| Step: 8
Training loss: 0.9790291114663715
Validation loss: 2.9551478325387044

Epoch: 5| Step: 9
Training loss: 0.6692009875790182
Validation loss: 3.0429085499885375

Epoch: 5| Step: 10
Training loss: 0.7345085834186015
Validation loss: 3.039586467405764

Epoch: 5| Step: 11
Training loss: 0.9526134118573016
Validation loss: 3.0385921280970787

Epoch: 328| Step: 0
Training loss: 0.8245799642619012
Validation loss: 3.0383444512286424

Epoch: 5| Step: 1
Training loss: 0.6506504765487048
Validation loss: 3.0388822853505575

Epoch: 5| Step: 2
Training loss: 0.4670060778330588
Validation loss: 2.852987429842181

Epoch: 5| Step: 3
Training loss: 1.491991599440256
Validation loss: 2.944780838029669

Epoch: 5| Step: 4
Training loss: 1.0126238570574753
Validation loss: 2.936964500261192

Epoch: 5| Step: 5
Training loss: 0.622199723273571
Validation loss: 3.0659864814621605

Epoch: 5| Step: 6
Training loss: 0.7703699875866145
Validation loss: 2.9218751529958755

Epoch: 5| Step: 7
Training loss: 0.4481884128336241
Validation loss: 2.9290758774543915

Epoch: 5| Step: 8
Training loss: 0.4982573868404452
Validation loss: 2.908782631390917

Epoch: 5| Step: 9
Training loss: 0.7759387483559874
Validation loss: 3.031085373645533

Epoch: 5| Step: 10
Training loss: 0.7030444204993608
Validation loss: 3.0269929481624165

Epoch: 5| Step: 11
Training loss: 0.3602367518025377
Validation loss: 2.9636621880899887

Epoch: 329| Step: 0
Training loss: 0.5212643620001277
Validation loss: 3.0130996144292332

Epoch: 5| Step: 1
Training loss: 0.4878348331605389
Validation loss: 2.9177930167040245

Epoch: 5| Step: 2
Training loss: 0.681859590616771
Validation loss: 2.9275748336852625

Epoch: 5| Step: 3
Training loss: 0.8046520188296026
Validation loss: 2.960686356790039

Epoch: 5| Step: 4
Training loss: 0.8983977599269763
Validation loss: 2.9824404962604123

Epoch: 5| Step: 5
Training loss: 0.9947217880125453
Validation loss: 3.0065484136088805

Epoch: 5| Step: 6
Training loss: 0.6733704048950264
Validation loss: 2.935863333146461

Epoch: 5| Step: 7
Training loss: 0.6502556646497031
Validation loss: 2.97493193612656

Epoch: 5| Step: 8
Training loss: 0.6494588965521216
Validation loss: 2.997916282766891

Epoch: 5| Step: 9
Training loss: 1.459147371432868
Validation loss: 2.813509078380246

Epoch: 5| Step: 10
Training loss: 0.41825468318845993
Validation loss: 3.0646168600427255

Epoch: 5| Step: 11
Training loss: 0.6478672507556973
Validation loss: 2.9929194505481993

Epoch: 330| Step: 0
Training loss: 0.890444519762869
Validation loss: 2.882988904536907

Epoch: 5| Step: 1
Training loss: 0.6835392085524052
Validation loss: 3.0222814585735382

Epoch: 5| Step: 2
Training loss: 1.4822335305768317
Validation loss: 3.041843109804961

Epoch: 5| Step: 3
Training loss: 0.8334599796062709
Validation loss: 2.954367677246298

Epoch: 5| Step: 4
Training loss: 0.8288757591859633
Validation loss: 2.9521951944070493

Epoch: 5| Step: 5
Training loss: 0.4971201933469418
Validation loss: 2.9208092301245334

Epoch: 5| Step: 6
Training loss: 0.7657888976631544
Validation loss: 2.9519951120483006

Epoch: 5| Step: 7
Training loss: 0.4907386131918604
Validation loss: 2.935814289257194

Epoch: 5| Step: 8
Training loss: 0.7998478357322863
Validation loss: 2.9728288270412477

Epoch: 5| Step: 9
Training loss: 0.7232855453907562
Validation loss: 2.9806012665373025

Epoch: 5| Step: 10
Training loss: 0.4049944365378302
Validation loss: 2.993982027601697

Epoch: 5| Step: 11
Training loss: 0.6984380700708576
Validation loss: 2.959453858584021

Epoch: 331| Step: 0
Training loss: 0.7796230159536721
Validation loss: 3.0033978187787667

Epoch: 5| Step: 1
Training loss: 0.6233353858631768
Validation loss: 2.910238397108772

Epoch: 5| Step: 2
Training loss: 0.8445505300574276
Validation loss: 2.993119707966463

Epoch: 5| Step: 3
Training loss: 0.6503096750648071
Validation loss: 2.940260580861788

Epoch: 5| Step: 4
Training loss: 0.6012622777672638
Validation loss: 3.0720356545748913

Epoch: 5| Step: 5
Training loss: 0.6600093113719238
Validation loss: 2.930575247307216

Epoch: 5| Step: 6
Training loss: 0.7878716424443493
Validation loss: 2.9738437888850613

Epoch: 5| Step: 7
Training loss: 0.7237930017586771
Validation loss: 2.9988487239963475

Epoch: 5| Step: 8
Training loss: 0.8630532356277136
Validation loss: 3.0133695057228254

Epoch: 5| Step: 9
Training loss: 1.4464426107246686
Validation loss: 3.0084836764206346

Epoch: 5| Step: 10
Training loss: 0.7780642596824052
Validation loss: 2.9935456091355976

Epoch: 5| Step: 11
Training loss: 0.8190107279879529
Validation loss: 2.945813359881237

Epoch: 332| Step: 0
Training loss: 0.6261984778432947
Validation loss: 2.92033533339455

Epoch: 5| Step: 1
Training loss: 0.7025460720905652
Validation loss: 2.960091308085421

Epoch: 5| Step: 2
Training loss: 0.955310691804332
Validation loss: 2.9507563778400754

Epoch: 5| Step: 3
Training loss: 0.5316433572243492
Validation loss: 2.9855047753787307

Epoch: 5| Step: 4
Training loss: 0.7601136339715118
Validation loss: 2.9753457366707767

Epoch: 5| Step: 5
Training loss: 0.5325859886015302
Validation loss: 2.9909350576946454

Epoch: 5| Step: 6
Training loss: 0.7137622677872791
Validation loss: 2.9074968240796557

Epoch: 5| Step: 7
Training loss: 0.7893537984554501
Validation loss: 2.9531560253686657

Epoch: 5| Step: 8
Training loss: 0.6274660335709763
Validation loss: 2.819793170796559

Epoch: 5| Step: 9
Training loss: 1.5653329725367982
Validation loss: 2.9066440697945075

Epoch: 5| Step: 10
Training loss: 0.7504052021252977
Validation loss: 2.8487612686949815

Epoch: 5| Step: 11
Training loss: 0.9388249571293558
Validation loss: 2.976381301370802

Epoch: 333| Step: 0
Training loss: 0.8666082973876227
Validation loss: 3.0700224010549046

Epoch: 5| Step: 1
Training loss: 0.6483061554032974
Validation loss: 2.934879940410774

Epoch: 5| Step: 2
Training loss: 0.7289908651321191
Validation loss: 3.0345484789082326

Epoch: 5| Step: 3
Training loss: 0.6650423562392623
Validation loss: 3.018083367544094

Epoch: 5| Step: 4
Training loss: 0.8341872171836071
Validation loss: 2.9576617819648536

Epoch: 5| Step: 5
Training loss: 0.859644240771542
Validation loss: 2.9522757578996264

Epoch: 5| Step: 6
Training loss: 1.4593338758404593
Validation loss: 2.874493485212505

Epoch: 5| Step: 7
Training loss: 0.5986743806778837
Validation loss: 2.9463130354419653

Epoch: 5| Step: 8
Training loss: 0.5840784973027416
Validation loss: 2.931539399502273

Epoch: 5| Step: 9
Training loss: 1.0406396125935964
Validation loss: 3.0929020576966266

Epoch: 5| Step: 10
Training loss: 0.6612297449092484
Validation loss: 3.068117646574864

Epoch: 5| Step: 11
Training loss: 0.5544062694001037
Validation loss: 3.05764836446015

Epoch: 334| Step: 0
Training loss: 0.6877109897411605
Validation loss: 3.015830742862204

Epoch: 5| Step: 1
Training loss: 0.6531416986694404
Validation loss: 3.0519378885673047

Epoch: 5| Step: 2
Training loss: 1.4395155666684916
Validation loss: 2.858374495297952

Epoch: 5| Step: 3
Training loss: 0.9104818653938136
Validation loss: 2.972927005984196

Epoch: 5| Step: 4
Training loss: 0.7054784383351452
Validation loss: 2.8897506491239593

Epoch: 5| Step: 5
Training loss: 0.7053777211414114
Validation loss: 2.985714317297006

Epoch: 5| Step: 6
Training loss: 0.44468125559429594
Validation loss: 2.9634249864792945

Epoch: 5| Step: 7
Training loss: 0.8311013411483437
Validation loss: 2.8376319033959696

Epoch: 5| Step: 8
Training loss: 0.7737519366805532
Validation loss: 2.9218270744976365

Epoch: 5| Step: 9
Training loss: 0.4562832180106419
Validation loss: 2.869669135651568

Epoch: 5| Step: 10
Training loss: 0.5526827730819829
Validation loss: 3.0870753142266922

Epoch: 5| Step: 11
Training loss: 0.35655112590250937
Validation loss: 2.9788856018081784

Epoch: 335| Step: 0
Training loss: 1.4800831637343301
Validation loss: 3.090919413491979

Epoch: 5| Step: 1
Training loss: 0.8631916258535677
Validation loss: 2.9927267413707903

Epoch: 5| Step: 2
Training loss: 0.6775548955629442
Validation loss: 2.964930228612687

Epoch: 5| Step: 3
Training loss: 0.8512611205821242
Validation loss: 2.945522213189383

Epoch: 5| Step: 4
Training loss: 0.647602692933165
Validation loss: 2.8719022447236693

Epoch: 5| Step: 5
Training loss: 0.6495080406625109
Validation loss: 3.004327877567368

Epoch: 5| Step: 6
Training loss: 0.5687787583175364
Validation loss: 2.9571007838403283

Epoch: 5| Step: 7
Training loss: 0.5259674762744178
Validation loss: 2.8902643545807445

Epoch: 5| Step: 8
Training loss: 0.9715234372055117
Validation loss: 2.9840374001691683

Epoch: 5| Step: 9
Training loss: 0.6285464993439545
Validation loss: 2.960559552444848

Epoch: 5| Step: 10
Training loss: 0.586056150503099
Validation loss: 2.9310558056845646

Epoch: 5| Step: 11
Training loss: 0.3193856530176457
Validation loss: 2.888678336850931

Epoch: 336| Step: 0
Training loss: 0.7349464952366231
Validation loss: 2.949446103930498

Epoch: 5| Step: 1
Training loss: 0.5616610416485365
Validation loss: 2.933898310591912

Epoch: 5| Step: 2
Training loss: 0.6376410515265531
Validation loss: 3.009209956406463

Epoch: 5| Step: 3
Training loss: 0.6418103672311251
Validation loss: 2.92665057303523

Epoch: 5| Step: 4
Training loss: 0.6116605592140371
Validation loss: 3.059386597592871

Epoch: 5| Step: 5
Training loss: 1.3688638056294815
Validation loss: 2.9776371428526596

Epoch: 5| Step: 6
Training loss: 0.9814535719490768
Validation loss: 2.970157008789325

Epoch: 5| Step: 7
Training loss: 0.6030817540135652
Validation loss: 2.9247924566676566

Epoch: 5| Step: 8
Training loss: 0.6239485479318856
Validation loss: 3.016885480839482

Epoch: 5| Step: 9
Training loss: 0.9679440868520824
Validation loss: 2.9455311910723694

Epoch: 5| Step: 10
Training loss: 0.5520116981479619
Validation loss: 3.020081575620332

Epoch: 5| Step: 11
Training loss: 1.034560582779727
Validation loss: 2.920166359216696

Epoch: 337| Step: 0
Training loss: 0.7026317349721727
Validation loss: 3.0128027436707416

Epoch: 5| Step: 1
Training loss: 0.8968577552759118
Validation loss: 2.9740438977885923

Epoch: 5| Step: 2
Training loss: 1.463745763627591
Validation loss: 2.956932471039409

Epoch: 5| Step: 3
Training loss: 0.7020241066225178
Validation loss: 3.0561871339486006

Epoch: 5| Step: 4
Training loss: 0.6932525552481749
Validation loss: 3.0247457566884575

Epoch: 5| Step: 5
Training loss: 0.8109745965311564
Validation loss: 2.930397910557945

Epoch: 5| Step: 6
Training loss: 0.5914056321900542
Validation loss: 2.95153193420125

Epoch: 5| Step: 7
Training loss: 0.8251439185756975
Validation loss: 3.0285425089264444

Epoch: 5| Step: 8
Training loss: 0.6334449057012042
Validation loss: 2.9759158068569307

Epoch: 5| Step: 9
Training loss: 0.4647092223846259
Validation loss: 2.95498965698859

Epoch: 5| Step: 10
Training loss: 0.7398771767884741
Validation loss: 3.0286496010142163

Epoch: 5| Step: 11
Training loss: 1.279061471960576
Validation loss: 3.069871115241606

Epoch: 338| Step: 0
Training loss: 0.7589657061171002
Validation loss: 3.029156148508343

Epoch: 5| Step: 1
Training loss: 0.845600853213635
Validation loss: 2.978205443527018

Epoch: 5| Step: 2
Training loss: 0.6813411546670058
Validation loss: 3.004044425838819

Epoch: 5| Step: 3
Training loss: 0.6427395742439554
Validation loss: 3.021528549874198

Epoch: 5| Step: 4
Training loss: 0.5485884119185342
Validation loss: 3.0743834642476133

Epoch: 5| Step: 5
Training loss: 0.4907181317324844
Validation loss: 3.0130599153182596

Epoch: 5| Step: 6
Training loss: 0.8653000231911372
Validation loss: 3.032598981853632

Epoch: 5| Step: 7
Training loss: 0.5830366424639951
Validation loss: 3.061749499349002

Epoch: 5| Step: 8
Training loss: 0.9181889046799843
Validation loss: 2.997893832563577

Epoch: 5| Step: 9
Training loss: 1.5006431154605842
Validation loss: 2.947549835314407

Epoch: 5| Step: 10
Training loss: 0.530105985894595
Validation loss: 3.0332116141019325

Epoch: 5| Step: 11
Training loss: 0.5658842641225056
Validation loss: 3.030301474923941

Epoch: 339| Step: 0
Training loss: 0.46930534526610385
Validation loss: 2.9666899242632447

Epoch: 5| Step: 1
Training loss: 0.5894309614197255
Validation loss: 2.9418504404058985

Epoch: 5| Step: 2
Training loss: 0.6782890270870809
Validation loss: 2.9431080954554907

Epoch: 5| Step: 3
Training loss: 0.8723284263570006
Validation loss: 2.9514886874111848

Epoch: 5| Step: 4
Training loss: 1.449260454014794
Validation loss: 2.8948292786876206

Epoch: 5| Step: 5
Training loss: 0.5716520802589722
Validation loss: 2.964701572472069

Epoch: 5| Step: 6
Training loss: 0.5742955578148154
Validation loss: 3.1078243894047533

Epoch: 5| Step: 7
Training loss: 0.6696776231187818
Validation loss: 3.0021369363224775

Epoch: 5| Step: 8
Training loss: 0.7648771876818022
Validation loss: 2.888835793143777

Epoch: 5| Step: 9
Training loss: 0.6453646271644323
Validation loss: 3.0477830919280917

Epoch: 5| Step: 10
Training loss: 0.5983235243185414
Validation loss: 2.993611752922363

Epoch: 5| Step: 11
Training loss: 0.4812038349946919
Validation loss: 3.028470731589706

Epoch: 340| Step: 0
Training loss: 0.5660172540761015
Validation loss: 2.9546436226537334

Epoch: 5| Step: 1
Training loss: 0.7407739529736074
Validation loss: 3.0439008624466473

Epoch: 5| Step: 2
Training loss: 0.4789142116364006
Validation loss: 2.9562437385401372

Epoch: 5| Step: 3
Training loss: 0.808102592163498
Validation loss: 3.037445337617382

Epoch: 5| Step: 4
Training loss: 0.637679422598259
Validation loss: 3.0135881565189964

Epoch: 5| Step: 5
Training loss: 1.5138194547512105
Validation loss: 3.0466274323917855

Epoch: 5| Step: 6
Training loss: 0.6651792224504133
Validation loss: 2.9819676207970525

Epoch: 5| Step: 7
Training loss: 0.6935854905769557
Validation loss: 3.0150164252003004

Epoch: 5| Step: 8
Training loss: 0.5657924614959324
Validation loss: 3.0766103474396687

Epoch: 5| Step: 9
Training loss: 0.7570811016096758
Validation loss: 3.0180137969955743

Epoch: 5| Step: 10
Training loss: 0.41706359752120176
Validation loss: 3.0172912099126274

Epoch: 5| Step: 11
Training loss: 0.7475552449814772
Validation loss: 2.980649796799566

Epoch: 341| Step: 0
Training loss: 0.8415514949018106
Validation loss: 3.0120445137954177

Epoch: 5| Step: 1
Training loss: 0.650068919489474
Validation loss: 2.96266608999938

Epoch: 5| Step: 2
Training loss: 0.7140576569040278
Validation loss: 3.0333474168520387

Epoch: 5| Step: 3
Training loss: 0.8492191865668978
Validation loss: 2.9619120232985616

Epoch: 5| Step: 4
Training loss: 0.5893192611987776
Validation loss: 3.0151892266482676

Epoch: 5| Step: 5
Training loss: 1.4302407950291962
Validation loss: 2.9763370688871

Epoch: 5| Step: 6
Training loss: 0.5119617554920802
Validation loss: 3.0015780020741594

Epoch: 5| Step: 7
Training loss: 0.5547338385769961
Validation loss: 3.019859743529736

Epoch: 5| Step: 8
Training loss: 0.5256049133980527
Validation loss: 3.005951346051453

Epoch: 5| Step: 9
Training loss: 0.7829815938912792
Validation loss: 2.896430493722

Epoch: 5| Step: 10
Training loss: 0.7038656360624577
Validation loss: 3.099849769325834

Epoch: 5| Step: 11
Training loss: 0.9287900038635513
Validation loss: 3.0477926681876197

Epoch: 342| Step: 0
Training loss: 0.5234357065198548
Validation loss: 3.0793845476864874

Epoch: 5| Step: 1
Training loss: 0.7241745129750251
Validation loss: 2.952407080226897

Epoch: 5| Step: 2
Training loss: 0.8052378133794956
Validation loss: 3.0638890651942234

Epoch: 5| Step: 3
Training loss: 0.995599691496771
Validation loss: 3.0891068355843494

Epoch: 5| Step: 4
Training loss: 0.8769234225334228
Validation loss: 3.0019804060421693

Epoch: 5| Step: 5
Training loss: 0.8592917315282943
Validation loss: 3.0518173464245124

Epoch: 5| Step: 6
Training loss: 1.3631219634206357
Validation loss: 3.023827566240347

Epoch: 5| Step: 7
Training loss: 0.7749301109795457
Validation loss: 2.8832256086618724

Epoch: 5| Step: 8
Training loss: 0.7515456643865788
Validation loss: 2.980126627513479

Epoch: 5| Step: 9
Training loss: 0.6713410850968846
Validation loss: 2.963657629406953

Epoch: 5| Step: 10
Training loss: 0.804755828326742
Validation loss: 2.957210671387397

Epoch: 5| Step: 11
Training loss: 0.19299208310793894
Validation loss: 3.00279045795332

Epoch: 343| Step: 0
Training loss: 0.7918254333374468
Validation loss: 3.018246899416388

Epoch: 5| Step: 1
Training loss: 0.631666771059187
Validation loss: 2.9012035253950503

Epoch: 5| Step: 2
Training loss: 0.5921903504476665
Validation loss: 2.967042940812386

Epoch: 5| Step: 3
Training loss: 0.7417602513951352
Validation loss: 2.9700692608492805

Epoch: 5| Step: 4
Training loss: 0.5808531082933772
Validation loss: 2.98129366703429

Epoch: 5| Step: 5
Training loss: 0.8157045552124544
Validation loss: 3.117671192855864

Epoch: 5| Step: 6
Training loss: 0.8397986466472502
Validation loss: 3.080782393540921

Epoch: 5| Step: 7
Training loss: 1.336338362310292
Validation loss: 3.021522365562201

Epoch: 5| Step: 8
Training loss: 0.5498688628176601
Validation loss: 3.03292570300843

Epoch: 5| Step: 9
Training loss: 0.5792124289905302
Validation loss: 2.9471729922120398

Epoch: 5| Step: 10
Training loss: 0.6316936397539071
Validation loss: 2.9610936166476334

Epoch: 5| Step: 11
Training loss: 0.3848176524040555
Validation loss: 3.051586593504167

Epoch: 344| Step: 0
Training loss: 0.877754609808881
Validation loss: 3.0451281536603707

Epoch: 5| Step: 1
Training loss: 0.5378704712748228
Validation loss: 2.951887604832382

Epoch: 5| Step: 2
Training loss: 0.748952730464714
Validation loss: 3.013682274956022

Epoch: 5| Step: 3
Training loss: 0.5503524842864768
Validation loss: 3.062775596233115

Epoch: 5| Step: 4
Training loss: 0.7352944968727481
Validation loss: 2.978500496247439

Epoch: 5| Step: 5
Training loss: 1.50767002519673
Validation loss: 2.990002258314813

Epoch: 5| Step: 6
Training loss: 0.5738962526434702
Validation loss: 2.974743565158182

Epoch: 5| Step: 7
Training loss: 0.5892252932367045
Validation loss: 2.9905310013792734

Epoch: 5| Step: 8
Training loss: 0.5556122231060333
Validation loss: 3.0475385350937847

Epoch: 5| Step: 9
Training loss: 0.8388743994228514
Validation loss: 2.938436757869614

Epoch: 5| Step: 10
Training loss: 0.8721167882002628
Validation loss: 3.0174704358618163

Epoch: 5| Step: 11
Training loss: 1.0185911440885458
Validation loss: 2.9548118456209957

Epoch: 345| Step: 0
Training loss: 0.7985153891836732
Validation loss: 2.952502136208162

Epoch: 5| Step: 1
Training loss: 0.7284030776234842
Validation loss: 2.904541545755753

Epoch: 5| Step: 2
Training loss: 0.7012166936040037
Validation loss: 3.035745063660443

Epoch: 5| Step: 3
Training loss: 0.7539699310130317
Validation loss: 2.9472490516232

Epoch: 5| Step: 4
Training loss: 0.6386713617071953
Validation loss: 2.99513112120802

Epoch: 5| Step: 5
Training loss: 0.6427068146657287
Validation loss: 3.0003279764979944

Epoch: 5| Step: 6
Training loss: 0.5169933542455313
Validation loss: 3.085909039329918

Epoch: 5| Step: 7
Training loss: 1.3942955095655618
Validation loss: 2.9715486819996086

Epoch: 5| Step: 8
Training loss: 0.6506870499263911
Validation loss: 3.030680393172455

Epoch: 5| Step: 9
Training loss: 0.7182463664392165
Validation loss: 2.985333663192962

Epoch: 5| Step: 10
Training loss: 0.7056194985025731
Validation loss: 2.990518926415492

Epoch: 5| Step: 11
Training loss: 0.7526466639222872
Validation loss: 3.0518447318351103

Epoch: 346| Step: 0
Training loss: 0.6095327515474828
Validation loss: 2.947527173375138

Epoch: 5| Step: 1
Training loss: 0.7819002116016531
Validation loss: 2.923227680450918

Epoch: 5| Step: 2
Training loss: 0.7636358540422836
Validation loss: 2.9685721662028417

Epoch: 5| Step: 3
Training loss: 0.8434393275475393
Validation loss: 2.9743330007442688

Epoch: 5| Step: 4
Training loss: 0.5733059225442205
Validation loss: 2.980458064162204

Epoch: 5| Step: 5
Training loss: 1.469990794613619
Validation loss: 2.9909262692433893

Epoch: 5| Step: 6
Training loss: 0.6146409093967335
Validation loss: 3.0363290420060363

Epoch: 5| Step: 7
Training loss: 0.9314111070997446
Validation loss: 3.0733852395606887

Epoch: 5| Step: 8
Training loss: 0.5831653120247384
Validation loss: 2.935312790969644

Epoch: 5| Step: 9
Training loss: 0.6511732095705852
Validation loss: 2.9662564999122956

Epoch: 5| Step: 10
Training loss: 0.8216655652913829
Validation loss: 2.9920440918343387

Epoch: 5| Step: 11
Training loss: 1.194003915994379
Validation loss: 3.082707490854951

Epoch: 347| Step: 0
Training loss: 0.782892484252537
Validation loss: 2.9059128719573915

Epoch: 5| Step: 1
Training loss: 1.5537953332868975
Validation loss: 3.0377068981563795

Epoch: 5| Step: 2
Training loss: 0.552128517053313
Validation loss: 2.997229598291313

Epoch: 5| Step: 3
Training loss: 0.46712246317757755
Validation loss: 2.940707518459935

Epoch: 5| Step: 4
Training loss: 0.8132600164069261
Validation loss: 2.944609844062693

Epoch: 5| Step: 5
Training loss: 0.8611353790459527
Validation loss: 2.9916381315014506

Epoch: 5| Step: 6
Training loss: 0.6011618233497874
Validation loss: 3.0340433555630564

Epoch: 5| Step: 7
Training loss: 0.62205138843922
Validation loss: 3.04607062848325

Epoch: 5| Step: 8
Training loss: 0.6176214985874646
Validation loss: 2.9745273056948593

Epoch: 5| Step: 9
Training loss: 0.6620572274976827
Validation loss: 3.1096469370459774

Epoch: 5| Step: 10
Training loss: 0.6799736735913705
Validation loss: 3.1117720094733325

Epoch: 5| Step: 11
Training loss: 0.9388053389592891
Validation loss: 3.0366570956748964

Epoch: 348| Step: 0
Training loss: 1.4027043890981414
Validation loss: 2.955993718926945

Epoch: 5| Step: 1
Training loss: 0.8015078713761707
Validation loss: 3.0057420746949113

Epoch: 5| Step: 2
Training loss: 0.7273539672527288
Validation loss: 3.0733267666718285

Epoch: 5| Step: 3
Training loss: 0.5108557259452203
Validation loss: 2.952535829523161

Epoch: 5| Step: 4
Training loss: 0.604736377406513
Validation loss: 2.962254810783177

Epoch: 5| Step: 5
Training loss: 0.6265037090468766
Validation loss: 3.008222946632044

Epoch: 5| Step: 6
Training loss: 0.7569142947088573
Validation loss: 2.9204916271655055

Epoch: 5| Step: 7
Training loss: 0.5354602256699709
Validation loss: 3.0101063127267262

Epoch: 5| Step: 8
Training loss: 0.5898804811068207
Validation loss: 2.9136122763984345

Epoch: 5| Step: 9
Training loss: 0.703628190443186
Validation loss: 3.0164124773394803

Epoch: 5| Step: 10
Training loss: 0.5362524791918091
Validation loss: 3.0897550767085775

Epoch: 5| Step: 11
Training loss: 0.9122136973284596
Validation loss: 3.006680315960129

Epoch: 349| Step: 0
Training loss: 0.8681178901331783
Validation loss: 3.0573068252308992

Epoch: 5| Step: 1
Training loss: 0.4073102393960494
Validation loss: 2.9402208240342556

Epoch: 5| Step: 2
Training loss: 0.5412273887686229
Validation loss: 2.9720880647984678

Epoch: 5| Step: 3
Training loss: 0.44086074880263904
Validation loss: 2.972806952621132

Epoch: 5| Step: 4
Training loss: 0.40931449981797385
Validation loss: 2.967578971527583

Epoch: 5| Step: 5
Training loss: 0.8294974057235757
Validation loss: 2.9709535585574463

Epoch: 5| Step: 6
Training loss: 0.56200402964644
Validation loss: 2.9347918688624945

Epoch: 5| Step: 7
Training loss: 0.8466129474669069
Validation loss: 3.06885996684314

Epoch: 5| Step: 8
Training loss: 0.6697473993895228
Validation loss: 3.016712592145937

Epoch: 5| Step: 9
Training loss: 0.6944770508634719
Validation loss: 2.974202459484605

Epoch: 5| Step: 10
Training loss: 1.5114577903545026
Validation loss: 2.935118044294111

Epoch: 5| Step: 11
Training loss: 0.3362175195811329
Validation loss: 3.004384327294637

Epoch: 350| Step: 0
Training loss: 0.6304196221592672
Validation loss: 2.952173867023059

Epoch: 5| Step: 1
Training loss: 0.5086962712290161
Validation loss: 2.950183678555355

Epoch: 5| Step: 2
Training loss: 0.6978074861407009
Validation loss: 2.9913725245253264

Epoch: 5| Step: 3
Training loss: 0.798475005580955
Validation loss: 2.88278058662428

Epoch: 5| Step: 4
Training loss: 0.3958532826098057
Validation loss: 3.0464494489531426

Epoch: 5| Step: 5
Training loss: 0.6572818364427452
Validation loss: 2.985206188671726

Epoch: 5| Step: 6
Training loss: 0.7209532595707274
Validation loss: 2.930538589620268

Epoch: 5| Step: 7
Training loss: 1.5326558102033374
Validation loss: 3.0567381984424324

Epoch: 5| Step: 8
Training loss: 0.7209776482153065
Validation loss: 3.040789932895369

Epoch: 5| Step: 9
Training loss: 0.8716334223622757
Validation loss: 3.0496366032920417

Epoch: 5| Step: 10
Training loss: 0.6539057003552168
Validation loss: 3.0347707561702086

Epoch: 5| Step: 11
Training loss: 0.2895575228287432
Validation loss: 2.973989584514189

Epoch: 351| Step: 0
Training loss: 0.45440238914688574
Validation loss: 2.9517306680936644

Epoch: 5| Step: 1
Training loss: 0.580597205343692
Validation loss: 3.0348309801246085

Epoch: 5| Step: 2
Training loss: 0.6219510333866158
Validation loss: 2.9359616384009635

Epoch: 5| Step: 3
Training loss: 1.465452347531554
Validation loss: 3.048426977856685

Epoch: 5| Step: 4
Training loss: 0.6427678347041735
Validation loss: 3.0764806134337297

Epoch: 5| Step: 5
Training loss: 0.7798893332835721
Validation loss: 2.979015707757409

Epoch: 5| Step: 6
Training loss: 0.6394155762774698
Validation loss: 3.1012570657563763

Epoch: 5| Step: 7
Training loss: 0.8121169727992051
Validation loss: 2.983716016516485

Epoch: 5| Step: 8
Training loss: 0.6194052386480826
Validation loss: 3.0230016205249433

Epoch: 5| Step: 9
Training loss: 0.7238750181124011
Validation loss: 3.0323359061739694

Epoch: 5| Step: 10
Training loss: 0.6333731298951689
Validation loss: 3.020686709473957

Epoch: 5| Step: 11
Training loss: 0.20728845633763665
Validation loss: 2.9789738437077973

Epoch: 352| Step: 0
Training loss: 0.7097172167933914
Validation loss: 3.196194114405347

Epoch: 5| Step: 1
Training loss: 0.6059590231273291
Validation loss: 2.95477765209876

Epoch: 5| Step: 2
Training loss: 0.5865544440844721
Validation loss: 3.0690243310279786

Epoch: 5| Step: 3
Training loss: 0.5906889714307564
Validation loss: 2.9468136393016606

Epoch: 5| Step: 4
Training loss: 0.49983403312394137
Validation loss: 2.9834783881546736

Epoch: 5| Step: 5
Training loss: 0.7143068225330234
Validation loss: 3.0121385122664353

Epoch: 5| Step: 6
Training loss: 0.5150705593345595
Validation loss: 2.933174916120448

Epoch: 5| Step: 7
Training loss: 0.8024215274245875
Validation loss: 3.0396000420231184

Epoch: 5| Step: 8
Training loss: 0.49052071283025334
Validation loss: 3.0071134671482724

Epoch: 5| Step: 9
Training loss: 0.7448436389920612
Validation loss: 2.9475920681571957

Epoch: 5| Step: 10
Training loss: 1.4126890477964924
Validation loss: 3.0499147201299515

Epoch: 5| Step: 11
Training loss: 0.9248414561002666
Validation loss: 2.999708025684878

Epoch: 353| Step: 0
Training loss: 0.615332919508973
Validation loss: 2.931697574666345

Epoch: 5| Step: 1
Training loss: 0.5591578802772446
Validation loss: 2.943649648938862

Epoch: 5| Step: 2
Training loss: 0.4742962153352722
Validation loss: 2.964243610742926

Epoch: 5| Step: 3
Training loss: 0.6020036046214876
Validation loss: 3.0307587687651787

Epoch: 5| Step: 4
Training loss: 0.8331250447003523
Validation loss: 2.951327915808459

Epoch: 5| Step: 5
Training loss: 0.6974912646987449
Validation loss: 2.9887131555462125

Epoch: 5| Step: 6
Training loss: 1.4868737320896561
Validation loss: 3.0664782440740295

Epoch: 5| Step: 7
Training loss: 0.6460395042959776
Validation loss: 3.104363887504061

Epoch: 5| Step: 8
Training loss: 0.6611890670306337
Validation loss: 3.0252883529369283

Epoch: 5| Step: 9
Training loss: 0.5118373413113267
Validation loss: 2.9796634084324047

Epoch: 5| Step: 10
Training loss: 0.6503633831378975
Validation loss: 3.018448859780316

Epoch: 5| Step: 11
Training loss: 0.7149408826863863
Validation loss: 2.986601436758065

Epoch: 354| Step: 0
Training loss: 0.7364094737318458
Validation loss: 2.9910184005559026

Epoch: 5| Step: 1
Training loss: 0.48031663425033827
Validation loss: 2.9944656504216534

Epoch: 5| Step: 2
Training loss: 0.5220068553715566
Validation loss: 3.045272284983206

Epoch: 5| Step: 3
Training loss: 0.6740495179844606
Validation loss: 3.0186816916625396

Epoch: 5| Step: 4
Training loss: 0.5285556572232912
Validation loss: 2.9599709673721772

Epoch: 5| Step: 5
Training loss: 0.7708361642802724
Validation loss: 3.024800692316087

Epoch: 5| Step: 6
Training loss: 1.522329543770877
Validation loss: 2.9381974488012617

Epoch: 5| Step: 7
Training loss: 0.5372286022677059
Validation loss: 3.0947789269725132

Epoch: 5| Step: 8
Training loss: 0.4099434982014518
Validation loss: 2.9442497649901944

Epoch: 5| Step: 9
Training loss: 0.6054504391762434
Validation loss: 3.101579184050892

Epoch: 5| Step: 10
Training loss: 0.5913548093165909
Validation loss: 2.9628519228790378

Epoch: 5| Step: 11
Training loss: 0.2432976015165963
Validation loss: 3.013084553819858

Epoch: 355| Step: 0
Training loss: 0.5025749955746248
Validation loss: 3.047368862198129

Epoch: 5| Step: 1
Training loss: 0.8572098941360135
Validation loss: 2.8892476933185054

Epoch: 5| Step: 2
Training loss: 0.6058794658977169
Validation loss: 3.0083988691537393

Epoch: 5| Step: 3
Training loss: 0.5958076010218223
Validation loss: 2.9689508704776797

Epoch: 5| Step: 4
Training loss: 0.6512986909233208
Validation loss: 3.0408292536465544

Epoch: 5| Step: 5
Training loss: 0.6223046357019115
Validation loss: 2.978040513464383

Epoch: 5| Step: 6
Training loss: 0.6717989235323395
Validation loss: 3.0207624602499266

Epoch: 5| Step: 7
Training loss: 0.6523555594648802
Validation loss: 2.9750241921079694

Epoch: 5| Step: 8
Training loss: 0.7476071492079339
Validation loss: 2.977311831826808

Epoch: 5| Step: 9
Training loss: 0.6510557605489438
Validation loss: 2.925219506941817

Epoch: 5| Step: 10
Training loss: 1.4323195946022462
Validation loss: 2.9864549761672237

Epoch: 5| Step: 11
Training loss: 0.4508409483731269
Validation loss: 3.0486843703284454

Epoch: 356| Step: 0
Training loss: 0.7221634292717789
Validation loss: 2.9486578839607747

Epoch: 5| Step: 1
Training loss: 0.5047186283869358
Validation loss: 3.0150129161545403

Epoch: 5| Step: 2
Training loss: 0.6464820930924725
Validation loss: 2.972762334453742

Epoch: 5| Step: 3
Training loss: 0.7728683612531576
Validation loss: 2.9916074039430174

Epoch: 5| Step: 4
Training loss: 0.6283533497319558
Validation loss: 2.935990950345039

Epoch: 5| Step: 5
Training loss: 0.5137903635267689
Validation loss: 2.9502559799999184

Epoch: 5| Step: 6
Training loss: 0.7820989192682527
Validation loss: 3.119541257935688

Epoch: 5| Step: 7
Training loss: 0.6564967735978253
Validation loss: 2.978099507932914

Epoch: 5| Step: 8
Training loss: 0.7207321119811113
Validation loss: 3.140616728485501

Epoch: 5| Step: 9
Training loss: 0.4566429966978381
Validation loss: 3.0228995568290533

Epoch: 5| Step: 10
Training loss: 1.368901818273394
Validation loss: 3.0033329737852164

Epoch: 5| Step: 11
Training loss: 0.7862195837811794
Validation loss: 2.897287985681249

Epoch: 357| Step: 0
Training loss: 0.5677826567361623
Validation loss: 2.9833643601755884

Epoch: 5| Step: 1
Training loss: 0.6291979000936826
Validation loss: 2.924449975991002

Epoch: 5| Step: 2
Training loss: 1.5463898023039195
Validation loss: 3.002116552738713

Epoch: 5| Step: 3
Training loss: 0.789523377234885
Validation loss: 2.97308249640394

Epoch: 5| Step: 4
Training loss: 0.8166305379920636
Validation loss: 2.8602012246597166

Epoch: 5| Step: 5
Training loss: 0.7067031309741014
Validation loss: 3.102960529303377

Epoch: 5| Step: 6
Training loss: 0.5556700962590493
Validation loss: 2.9878916401245665

Epoch: 5| Step: 7
Training loss: 0.6035920622483806
Validation loss: 3.0239164579257913

Epoch: 5| Step: 8
Training loss: 0.6268415975751949
Validation loss: 3.1592398384731575

Epoch: 5| Step: 9
Training loss: 0.8900118273045614
Validation loss: 2.9863320137100064

Epoch: 5| Step: 10
Training loss: 0.8018284718906552
Validation loss: 3.0950441511494127

Epoch: 5| Step: 11
Training loss: 0.6327236254412814
Validation loss: 3.1120046553372633

Epoch: 358| Step: 0
Training loss: 0.6602523553178657
Validation loss: 3.10627934015388

Epoch: 5| Step: 1
Training loss: 0.7145396768860077
Validation loss: 2.9331792275269843

Epoch: 5| Step: 2
Training loss: 0.3850642173640871
Validation loss: 2.930440627888346

Epoch: 5| Step: 3
Training loss: 0.4774573944716851
Validation loss: 3.0089952133493925

Epoch: 5| Step: 4
Training loss: 0.7266569999028514
Validation loss: 3.043867834527051

Epoch: 5| Step: 5
Training loss: 0.4570890699801485
Validation loss: 2.9483806236022514

Epoch: 5| Step: 6
Training loss: 0.6677219983595546
Validation loss: 3.0207669048021

Epoch: 5| Step: 7
Training loss: 0.8293864521193217
Validation loss: 3.0488815612476303

Epoch: 5| Step: 8
Training loss: 1.446055453312201
Validation loss: 2.936316999345246

Epoch: 5| Step: 9
Training loss: 0.6681485073639579
Validation loss: 2.95893343135679

Epoch: 5| Step: 10
Training loss: 0.7388129363385044
Validation loss: 3.0417438566960446

Epoch: 5| Step: 11
Training loss: 0.19541907263930564
Validation loss: 2.8099070587971027

Epoch: 359| Step: 0
Training loss: 0.6232072629739803
Validation loss: 2.9915939037741905

Epoch: 5| Step: 1
Training loss: 0.5502501016622794
Validation loss: 2.9874963448447582

Epoch: 5| Step: 2
Training loss: 0.6824977699355138
Validation loss: 2.9504744124008457

Epoch: 5| Step: 3
Training loss: 0.8758990233262469
Validation loss: 2.9717950864330347

Epoch: 5| Step: 4
Training loss: 0.4259464923192095
Validation loss: 3.0163930267410364

Epoch: 5| Step: 5
Training loss: 0.7578261069423132
Validation loss: 3.0865479778892992

Epoch: 5| Step: 6
Training loss: 0.9024341092136134
Validation loss: 3.0243968509442585

Epoch: 5| Step: 7
Training loss: 1.4401111936024125
Validation loss: 3.061662961791124

Epoch: 5| Step: 8
Training loss: 0.5161751499825601
Validation loss: 2.9710190651195343

Epoch: 5| Step: 9
Training loss: 0.8130305831946913
Validation loss: 3.034934331569983

Epoch: 5| Step: 10
Training loss: 0.817118028711089
Validation loss: 2.905213605334091

Epoch: 5| Step: 11
Training loss: 0.8559212728844453
Validation loss: 2.935079879653941

Epoch: 360| Step: 0
Training loss: 0.6090307485995395
Validation loss: 2.946127002319008

Epoch: 5| Step: 1
Training loss: 0.5306262112660955
Validation loss: 3.056129170651073

Epoch: 5| Step: 2
Training loss: 0.7821127895714703
Validation loss: 2.9516765668700473

Epoch: 5| Step: 3
Training loss: 0.7862812920849289
Validation loss: 2.8952167160953355

Epoch: 5| Step: 4
Training loss: 0.6965713249869444
Validation loss: 3.0225489556844356

Epoch: 5| Step: 5
Training loss: 0.5151555785573066
Validation loss: 3.049384203875632

Epoch: 5| Step: 6
Training loss: 0.7802946734731447
Validation loss: 3.062536010725097

Epoch: 5| Step: 7
Training loss: 0.5607497748562841
Validation loss: 2.9145280876858974

Epoch: 5| Step: 8
Training loss: 0.6606967451462583
Validation loss: 3.0599963827724728

Epoch: 5| Step: 9
Training loss: 1.4727399483530192
Validation loss: 3.031141207076527

Epoch: 5| Step: 10
Training loss: 0.595783941071258
Validation loss: 3.078611025707317

Epoch: 5| Step: 11
Training loss: 0.3414648350571246
Validation loss: 3.0591815888648717

Epoch: 361| Step: 0
Training loss: 0.5509544533097186
Validation loss: 2.992015322386977

Epoch: 5| Step: 1
Training loss: 0.6902915460282463
Validation loss: 3.0040244454162988

Epoch: 5| Step: 2
Training loss: 0.5588726601173053
Validation loss: 2.8781016695041357

Epoch: 5| Step: 3
Training loss: 0.6741566175207746
Validation loss: 2.909984008334376

Epoch: 5| Step: 4
Training loss: 1.437565511786329
Validation loss: 2.9433123798495755

Epoch: 5| Step: 5
Training loss: 0.8191195214663335
Validation loss: 2.975823728739432

Epoch: 5| Step: 6
Training loss: 0.5685636277906243
Validation loss: 2.902547624631557

Epoch: 5| Step: 7
Training loss: 0.5090510888925358
Validation loss: 3.0519383572896106

Epoch: 5| Step: 8
Training loss: 0.5595527899163908
Validation loss: 2.9204124047158504

Epoch: 5| Step: 9
Training loss: 0.6290080775877881
Validation loss: 3.014089980988099

Epoch: 5| Step: 10
Training loss: 0.6366337444454625
Validation loss: 3.1427463022597255

Epoch: 5| Step: 11
Training loss: 0.8456298232522508
Validation loss: 3.191787899236431

Epoch: 362| Step: 0
Training loss: 1.323737853285378
Validation loss: 3.040013709505334

Epoch: 5| Step: 1
Training loss: 0.6066985899085638
Validation loss: 2.9791277547220223

Epoch: 5| Step: 2
Training loss: 0.5674284557164189
Validation loss: 2.9346070179941948

Epoch: 5| Step: 3
Training loss: 0.45893892103720935
Validation loss: 2.9422587138434344

Epoch: 5| Step: 4
Training loss: 0.8440313223454926
Validation loss: 3.037748570861263

Epoch: 5| Step: 5
Training loss: 0.7424273053299517
Validation loss: 2.997217762438693

Epoch: 5| Step: 6
Training loss: 0.5921571849622557
Validation loss: 3.0273169370714905

Epoch: 5| Step: 7
Training loss: 0.6394876292525693
Validation loss: 3.0019609711378417

Epoch: 5| Step: 8
Training loss: 0.6101641069558427
Validation loss: 2.984439609487298

Epoch: 5| Step: 9
Training loss: 0.5937272368635234
Validation loss: 3.0372610105417053

Epoch: 5| Step: 10
Training loss: 0.672013246374478
Validation loss: 2.9608896263365647

Epoch: 5| Step: 11
Training loss: 0.7837807672718977
Validation loss: 3.017871749402693

Epoch: 363| Step: 0
Training loss: 0.6962593147161552
Validation loss: 3.01612586966295

Epoch: 5| Step: 1
Training loss: 0.7801583101324457
Validation loss: 3.0261611925813643

Epoch: 5| Step: 2
Training loss: 0.6588520959713529
Validation loss: 3.086832991777166

Epoch: 5| Step: 3
Training loss: 0.5287804706171642
Validation loss: 3.075168377316261

Epoch: 5| Step: 4
Training loss: 0.44703435124078555
Validation loss: 2.913424779197317

Epoch: 5| Step: 5
Training loss: 1.4070396325657564
Validation loss: 2.931978803016999

Epoch: 5| Step: 6
Training loss: 0.7885235749507898
Validation loss: 2.948386230184715

Epoch: 5| Step: 7
Training loss: 0.6952649646754783
Validation loss: 2.974071996001024

Epoch: 5| Step: 8
Training loss: 0.9304644759918369
Validation loss: 2.868574086089026

Epoch: 5| Step: 9
Training loss: 0.6356153698607104
Validation loss: 2.9907491595073536

Epoch: 5| Step: 10
Training loss: 0.5577863980979559
Validation loss: 3.0048539345533154

Epoch: 5| Step: 11
Training loss: 0.9733028484060195
Validation loss: 3.0118286732867388

Epoch: 364| Step: 0
Training loss: 0.545624802579549
Validation loss: 2.9959697175494546

Epoch: 5| Step: 1
Training loss: 0.6893850622540837
Validation loss: 3.030117501743976

Epoch: 5| Step: 2
Training loss: 0.8773266648814034
Validation loss: 2.976290162210836

Epoch: 5| Step: 3
Training loss: 0.5750868068351186
Validation loss: 2.9386391764277806

Epoch: 5| Step: 4
Training loss: 0.4446263632229296
Validation loss: 2.941088956122264

Epoch: 5| Step: 5
Training loss: 0.548773223194379
Validation loss: 3.063908989183172

Epoch: 5| Step: 6
Training loss: 0.6664390224971372
Validation loss: 3.0940970184472985

Epoch: 5| Step: 7
Training loss: 0.6385111008547654
Validation loss: 3.0023078154624443

Epoch: 5| Step: 8
Training loss: 1.3626447793175742
Validation loss: 2.996279658087364

Epoch: 5| Step: 9
Training loss: 0.5632317340054588
Validation loss: 2.9974319473508197

Epoch: 5| Step: 10
Training loss: 0.6284190595094215
Validation loss: 3.116622545360095

Epoch: 5| Step: 11
Training loss: 0.5644057362869195
Validation loss: 2.9746106474003917

Epoch: 365| Step: 0
Training loss: 0.5197428222314753
Validation loss: 3.0371170550839053

Epoch: 5| Step: 1
Training loss: 0.7592526152775815
Validation loss: 3.076038599104255

Epoch: 5| Step: 2
Training loss: 1.3233971311499204
Validation loss: 2.9227855168069152

Epoch: 5| Step: 3
Training loss: 0.661384793696604
Validation loss: 3.010686794072097

Epoch: 5| Step: 4
Training loss: 0.5059548954273433
Validation loss: 3.0873357703408604

Epoch: 5| Step: 5
Training loss: 0.6004887447954053
Validation loss: 3.028844711495888

Epoch: 5| Step: 6
Training loss: 0.7105557601062811
Validation loss: 3.0068078084672507

Epoch: 5| Step: 7
Training loss: 0.7152545353180004
Validation loss: 2.923033340193704

Epoch: 5| Step: 8
Training loss: 0.6952353016720378
Validation loss: 3.0855126873188845

Epoch: 5| Step: 9
Training loss: 0.5748068464357232
Validation loss: 3.0780160274677018

Epoch: 5| Step: 10
Training loss: 0.6444594140913017
Validation loss: 3.057792805546705

Epoch: 5| Step: 11
Training loss: 0.45492728029499163
Validation loss: 3.0310511638539674

Epoch: 366| Step: 0
Training loss: 0.5339952670076908
Validation loss: 3.053838288234172

Epoch: 5| Step: 1
Training loss: 0.5273455584459732
Validation loss: 3.0068234919056827

Epoch: 5| Step: 2
Training loss: 0.719175751681387
Validation loss: 2.998893858382266

Epoch: 5| Step: 3
Training loss: 0.36032067143222274
Validation loss: 3.0181670666620874

Epoch: 5| Step: 4
Training loss: 1.501426812907583
Validation loss: 2.983431089298527

Epoch: 5| Step: 5
Training loss: 0.6140493211957877
Validation loss: 3.0302834788779056

Epoch: 5| Step: 6
Training loss: 0.7191480280854098
Validation loss: 3.0177296391609443

Epoch: 5| Step: 7
Training loss: 0.689423557760568
Validation loss: 2.9719739841967168

Epoch: 5| Step: 8
Training loss: 0.6891681849598641
Validation loss: 3.105980379516308

Epoch: 5| Step: 9
Training loss: 0.775580548681032
Validation loss: 2.9151393956181075

Epoch: 5| Step: 10
Training loss: 0.6662655582364875
Validation loss: 3.1009700603288395

Epoch: 5| Step: 11
Training loss: 0.6980919309483357
Validation loss: 3.0255985964273306

Epoch: 367| Step: 0
Training loss: 0.7808486670579982
Validation loss: 2.997436338670782

Epoch: 5| Step: 1
Training loss: 0.5161871302379684
Validation loss: 3.11589744789786

Epoch: 5| Step: 2
Training loss: 1.402799187025776
Validation loss: 2.9485847280051405

Epoch: 5| Step: 3
Training loss: 0.5710251679577507
Validation loss: 2.9648853076272244

Epoch: 5| Step: 4
Training loss: 0.6595289195330669
Validation loss: 3.052329093664239

Epoch: 5| Step: 5
Training loss: 0.6034489567052824
Validation loss: 3.0176799110932535

Epoch: 5| Step: 6
Training loss: 0.5074495045200101
Validation loss: 3.003342614044883

Epoch: 5| Step: 7
Training loss: 0.5487217918914333
Validation loss: 3.084619915226699

Epoch: 5| Step: 8
Training loss: 0.6931666576501372
Validation loss: 3.0016096949073217

Epoch: 5| Step: 9
Training loss: 0.7370508830803832
Validation loss: 3.086963283488732

Epoch: 5| Step: 10
Training loss: 0.6332748043053223
Validation loss: 3.0036070318721664

Epoch: 5| Step: 11
Training loss: 0.9993562712593367
Validation loss: 3.085971265519593

Epoch: 368| Step: 0
Training loss: 1.5182954524004968
Validation loss: 3.041135731283035

Epoch: 5| Step: 1
Training loss: 0.7333226069475088
Validation loss: 2.994833063033003

Epoch: 5| Step: 2
Training loss: 0.6773649412577921
Validation loss: 2.986709863062609

Epoch: 5| Step: 3
Training loss: 0.9083522879229812
Validation loss: 2.9964650043048255

Epoch: 5| Step: 4
Training loss: 0.33806140530776263
Validation loss: 2.9909050552903635

Epoch: 5| Step: 5
Training loss: 0.5923759724177766
Validation loss: 3.0689170876081104

Epoch: 5| Step: 6
Training loss: 0.6856586332600088
Validation loss: 3.038676612498215

Epoch: 5| Step: 7
Training loss: 0.7814807551059022
Validation loss: 2.957935687101277

Epoch: 5| Step: 8
Training loss: 0.5194572740246541
Validation loss: 2.9324512076919067

Epoch: 5| Step: 9
Training loss: 0.6432258796350505
Validation loss: 3.001913973425369

Epoch: 5| Step: 10
Training loss: 0.5714469495866297
Validation loss: 3.0345237527850957

Epoch: 5| Step: 11
Training loss: 0.45179754693503943
Validation loss: 3.0162166647525384

Epoch: 369| Step: 0
Training loss: 0.5407102804229986
Validation loss: 3.063246973246941

Epoch: 5| Step: 1
Training loss: 0.6001738087916751
Validation loss: 3.069461316258439

Epoch: 5| Step: 2
Training loss: 0.46245755890125145
Validation loss: 3.0622569136906805

Epoch: 5| Step: 3
Training loss: 0.6826190648305507
Validation loss: 2.9152694432197674

Epoch: 5| Step: 4
Training loss: 0.593889747035068
Validation loss: 3.082898408376246

Epoch: 5| Step: 5
Training loss: 0.6167172439127688
Validation loss: 2.9596951779755423

Epoch: 5| Step: 6
Training loss: 0.6177626235888617
Validation loss: 3.0027272821458992

Epoch: 5| Step: 7
Training loss: 0.7394147779352537
Validation loss: 2.9963404468098718

Epoch: 5| Step: 8
Training loss: 1.346961774044347
Validation loss: 3.057000051537928

Epoch: 5| Step: 9
Training loss: 0.5925729528816236
Validation loss: 3.0570581023091985

Epoch: 5| Step: 10
Training loss: 0.6787231224667788
Validation loss: 3.109612990940775

Epoch: 5| Step: 11
Training loss: 1.1146084019108642
Validation loss: 3.083310698520643

Epoch: 370| Step: 0
Training loss: 1.5354464889935904
Validation loss: 3.0010963099089696

Epoch: 5| Step: 1
Training loss: 0.6736387346006832
Validation loss: 3.0607264907671676

Epoch: 5| Step: 2
Training loss: 0.40252418546102015
Validation loss: 2.9218850671115373

Epoch: 5| Step: 3
Training loss: 0.5619286178278928
Validation loss: 2.9648815415645533

Epoch: 5| Step: 4
Training loss: 0.6442765166007058
Validation loss: 3.035313478224424

Epoch: 5| Step: 5
Training loss: 0.6680174692690732
Validation loss: 2.9742848416931085

Epoch: 5| Step: 6
Training loss: 0.6794927252196893
Validation loss: 2.9539880248390715

Epoch: 5| Step: 7
Training loss: 0.6870169893562817
Validation loss: 2.9238100495137527

Epoch: 5| Step: 8
Training loss: 0.49199631928893056
Validation loss: 2.994235527258186

Epoch: 5| Step: 9
Training loss: 0.643585621114963
Validation loss: 3.0507278861028184

Epoch: 5| Step: 10
Training loss: 0.6020323169658205
Validation loss: 3.0782738470502875

Epoch: 5| Step: 11
Training loss: 0.561843568518915
Validation loss: 3.087903799068716

Epoch: 371| Step: 0
Training loss: 0.6697135801661779
Validation loss: 2.9286876820430345

Epoch: 5| Step: 1
Training loss: 0.6071347849173029
Validation loss: 2.989349845691605

Epoch: 5| Step: 2
Training loss: 0.7248184025997711
Validation loss: 3.0518026526653683

Epoch: 5| Step: 3
Training loss: 0.6486762652822307
Validation loss: 2.886203325824074

Epoch: 5| Step: 4
Training loss: 0.7142446540202515
Validation loss: 2.9791392122795406

Epoch: 5| Step: 5
Training loss: 0.612854584411644
Validation loss: 3.010273921226589

Epoch: 5| Step: 6
Training loss: 0.4803401185572789
Validation loss: 2.9245431824514236

Epoch: 5| Step: 7
Training loss: 1.3688679857656922
Validation loss: 3.022433667118957

Epoch: 5| Step: 8
Training loss: 0.6383982314227519
Validation loss: 2.97557371174782

Epoch: 5| Step: 9
Training loss: 0.7526227075389497
Validation loss: 3.034297463224906

Epoch: 5| Step: 10
Training loss: 0.8162646741263666
Validation loss: 3.1637535164124113

Epoch: 5| Step: 11
Training loss: 0.8779574550018207
Validation loss: 3.0175842087570146

Epoch: 372| Step: 0
Training loss: 0.6498833817625502
Validation loss: 3.0457919845087913

Epoch: 5| Step: 1
Training loss: 0.652981520594297
Validation loss: 3.060643762395059

Epoch: 5| Step: 2
Training loss: 0.5685195172884191
Validation loss: 2.9910382752251934

Epoch: 5| Step: 3
Training loss: 0.5556450222085217
Validation loss: 2.9492118616423677

Epoch: 5| Step: 4
Training loss: 0.6312427359814565
Validation loss: 2.9683539310403226

Epoch: 5| Step: 5
Training loss: 0.8449845642169764
Validation loss: 2.9569224644567655

Epoch: 5| Step: 6
Training loss: 0.7155945384109814
Validation loss: 2.982084587059239

Epoch: 5| Step: 7
Training loss: 1.5253565512159453
Validation loss: 2.966108291205306

Epoch: 5| Step: 8
Training loss: 0.504915276964895
Validation loss: 2.940805712453346

Epoch: 5| Step: 9
Training loss: 0.7867262975336388
Validation loss: 2.970398930163884

Epoch: 5| Step: 10
Training loss: 0.6248785377733477
Validation loss: 2.897965825544004

Epoch: 5| Step: 11
Training loss: 0.7052826730001444
Validation loss: 3.0149241540604033

Epoch: 373| Step: 0
Training loss: 0.6027847605206567
Validation loss: 3.044564285471065

Epoch: 5| Step: 1
Training loss: 0.6556261366987965
Validation loss: 2.9456763308411413

Epoch: 5| Step: 2
Training loss: 0.6918680620750193
Validation loss: 2.91479003115145

Epoch: 5| Step: 3
Training loss: 0.39047959482459577
Validation loss: 2.9777559439331545

Epoch: 5| Step: 4
Training loss: 0.5482381724722587
Validation loss: 2.9793614788427467

Epoch: 5| Step: 5
Training loss: 0.7250854491159955
Validation loss: 2.882142620601004

Epoch: 5| Step: 6
Training loss: 0.6757776557959084
Validation loss: 2.8593943999975138

Epoch: 5| Step: 7
Training loss: 0.5226670188535668
Validation loss: 2.90635466301706

Epoch: 5| Step: 8
Training loss: 1.4905506363399428
Validation loss: 2.8596620849851764

Epoch: 5| Step: 9
Training loss: 0.5437019392675321
Validation loss: 2.8951878594437246

Epoch: 5| Step: 10
Training loss: 0.8099618294046135
Validation loss: 2.8896416030945637

Epoch: 5| Step: 11
Training loss: 0.7390145590719815
Validation loss: 3.091033034715716

Epoch: 374| Step: 0
Training loss: 0.8860443508293802
Validation loss: 3.0226697579485693

Epoch: 5| Step: 1
Training loss: 0.8010061552975638
Validation loss: 3.0717367827377746

Epoch: 5| Step: 2
Training loss: 0.6546461624897187
Validation loss: 3.081321231619646

Epoch: 5| Step: 3
Training loss: 0.7066956455958607
Validation loss: 3.0435206084656916

Epoch: 5| Step: 4
Training loss: 1.28465177612075
Validation loss: 2.921882673583265

Epoch: 5| Step: 5
Training loss: 0.685064031643265
Validation loss: 3.0129973175177422

Epoch: 5| Step: 6
Training loss: 0.46504599715457184
Validation loss: 2.978424961398697

Epoch: 5| Step: 7
Training loss: 0.8079166618204207
Validation loss: 3.067607341500764

Epoch: 5| Step: 8
Training loss: 0.7291520843864259
Validation loss: 3.072867209903987

Epoch: 5| Step: 9
Training loss: 0.743884345350887
Validation loss: 2.983408170477125

Epoch: 5| Step: 10
Training loss: 0.8347542847223213
Validation loss: 3.0331527335686426

Epoch: 5| Step: 11
Training loss: 0.23570021450836526
Validation loss: 2.9209256083233237

Epoch: 375| Step: 0
Training loss: 0.6248870270669148
Validation loss: 2.993734333419423

Epoch: 5| Step: 1
Training loss: 0.4000299643677736
Validation loss: 2.941277689021888

Epoch: 5| Step: 2
Training loss: 0.4982694988473969
Validation loss: 3.0875269116452766

Epoch: 5| Step: 3
Training loss: 0.5225924317495505
Validation loss: 3.060362939555588

Epoch: 5| Step: 4
Training loss: 0.7044043452082825
Validation loss: 2.9650698421887487

Epoch: 5| Step: 5
Training loss: 0.6191326826771485
Validation loss: 3.051527068099587

Epoch: 5| Step: 6
Training loss: 0.7378923310098066
Validation loss: 2.9949392575370317

Epoch: 5| Step: 7
Training loss: 0.5714000626673145
Validation loss: 3.0163481937207077

Epoch: 5| Step: 8
Training loss: 0.7026358068273377
Validation loss: 3.0737577300293184

Epoch: 5| Step: 9
Training loss: 1.2906916640385697
Validation loss: 2.892718682403972

Epoch: 5| Step: 10
Training loss: 0.5174499352973634
Validation loss: 2.936069671243585

Epoch: 5| Step: 11
Training loss: 0.3722912990687085
Validation loss: 2.950903775357297

Epoch: 376| Step: 0
Training loss: 0.6047626438813972
Validation loss: 2.9550428537573734

Epoch: 5| Step: 1
Training loss: 0.6430070367401377
Validation loss: 3.04549431125187

Epoch: 5| Step: 2
Training loss: 0.9297619637552739
Validation loss: 3.0585533681828894

Epoch: 5| Step: 3
Training loss: 0.6501936972389772
Validation loss: 3.024094877315108

Epoch: 5| Step: 4
Training loss: 0.5695390551624859
Validation loss: 3.0296109182467523

Epoch: 5| Step: 5
Training loss: 0.5477493381156735
Validation loss: 2.9149785106340134

Epoch: 5| Step: 6
Training loss: 0.8055910389491788
Validation loss: 2.9621713260150453

Epoch: 5| Step: 7
Training loss: 0.5880896399364651
Validation loss: 2.945954698861973

Epoch: 5| Step: 8
Training loss: 0.5691086853742054
Validation loss: 2.858790443856007

Epoch: 5| Step: 9
Training loss: 0.616788469562913
Validation loss: 3.02339538032311

Epoch: 5| Step: 10
Training loss: 1.3300041816760415
Validation loss: 2.927190725499131

Epoch: 5| Step: 11
Training loss: 0.7756180898034265
Validation loss: 2.9122853830365565

Epoch: 377| Step: 0
Training loss: 0.5586487269523699
Validation loss: 2.9509208702053225

Epoch: 5| Step: 1
Training loss: 0.7567241758458834
Validation loss: 3.035208935241479

Epoch: 5| Step: 2
Training loss: 1.3545371600264262
Validation loss: 2.97254300664147

Epoch: 5| Step: 3
Training loss: 0.5365942964813754
Validation loss: 2.9852425078344416

Epoch: 5| Step: 4
Training loss: 0.6440784597848745
Validation loss: 2.993279898446832

Epoch: 5| Step: 5
Training loss: 0.49061398038212417
Validation loss: 3.0341751529138734

Epoch: 5| Step: 6
Training loss: 0.590274678639772
Validation loss: 2.9679147432090662

Epoch: 5| Step: 7
Training loss: 0.43699782365414147
Validation loss: 3.014939574515995

Epoch: 5| Step: 8
Training loss: 0.6105719084681059
Validation loss: 2.8952685784269567

Epoch: 5| Step: 9
Training loss: 0.48114750377527205
Validation loss: 3.0056066111409767

Epoch: 5| Step: 10
Training loss: 0.591476605562962
Validation loss: 2.7966388517454543

Epoch: 5| Step: 11
Training loss: 0.6004472525900415
Validation loss: 2.9409992684541

Epoch: 378| Step: 0
Training loss: 0.5897399356253327
Validation loss: 2.919015518761662

Epoch: 5| Step: 1
Training loss: 0.49503214329576994
Validation loss: 3.00109860053847

Epoch: 5| Step: 2
Training loss: 0.5295313354564157
Validation loss: 3.0371069806938915

Epoch: 5| Step: 3
Training loss: 0.8030798324174037
Validation loss: 3.0688041754742583

Epoch: 5| Step: 4
Training loss: 0.6310539063779719
Validation loss: 2.9553649655555367

Epoch: 5| Step: 5
Training loss: 0.5900477631276878
Validation loss: 3.008051297175035

Epoch: 5| Step: 6
Training loss: 0.5384624015819528
Validation loss: 2.9546304898651674

Epoch: 5| Step: 7
Training loss: 0.6787508726377831
Validation loss: 3.0493909669408423

Epoch: 5| Step: 8
Training loss: 1.3933065897977472
Validation loss: 2.9011670204807842

Epoch: 5| Step: 9
Training loss: 0.5701539851379154
Validation loss: 3.0336942453216085

Epoch: 5| Step: 10
Training loss: 0.5543534253383181
Validation loss: 3.013325310140101

Epoch: 5| Step: 11
Training loss: 0.8431514807092196
Validation loss: 2.959213046563861

Epoch: 379| Step: 0
Training loss: 0.7611969162922116
Validation loss: 3.1156882885136117

Epoch: 5| Step: 1
Training loss: 0.5572957249668938
Validation loss: 3.0076105553677155

Epoch: 5| Step: 2
Training loss: 0.6940880398643593
Validation loss: 2.91674753939814

Epoch: 5| Step: 3
Training loss: 0.6308848372951473
Validation loss: 2.956674622330038

Epoch: 5| Step: 4
Training loss: 0.5478551255924546
Validation loss: 2.9815000996958285

Epoch: 5| Step: 5
Training loss: 0.7743663412353564
Validation loss: 2.88022228028345

Epoch: 5| Step: 6
Training loss: 0.4889139425099845
Validation loss: 3.041682819210345

Epoch: 5| Step: 7
Training loss: 0.5782168289661478
Validation loss: 3.0291074738278896

Epoch: 5| Step: 8
Training loss: 0.8126321831799246
Validation loss: 3.0043507591450984

Epoch: 5| Step: 9
Training loss: 1.3240914972878584
Validation loss: 2.9539108307271644

Epoch: 5| Step: 10
Training loss: 0.5950681710659627
Validation loss: 3.079120833133654

Epoch: 5| Step: 11
Training loss: 0.41992262019601395
Validation loss: 3.018838863104762

Epoch: 380| Step: 0
Training loss: 0.6433581687485134
Validation loss: 2.9013885185684187

Epoch: 5| Step: 1
Training loss: 0.49120543156414254
Validation loss: 3.0121536732482066

Epoch: 5| Step: 2
Training loss: 0.626064133730228
Validation loss: 2.9837005345740715

Epoch: 5| Step: 3
Training loss: 0.838721941096284
Validation loss: 2.9557585973856844

Epoch: 5| Step: 4
Training loss: 0.45092599947956563
Validation loss: 3.0646178616813784

Epoch: 5| Step: 5
Training loss: 0.5683777534161453
Validation loss: 3.0319486514233316

Epoch: 5| Step: 6
Training loss: 0.3987728652257949
Validation loss: 2.9025682967455633

Epoch: 5| Step: 7
Training loss: 0.5247404762683272
Validation loss: 2.9724449219612583

Epoch: 5| Step: 8
Training loss: 0.5512501229180093
Validation loss: 3.020539816485287

Epoch: 5| Step: 9
Training loss: 0.6710512967165296
Validation loss: 2.9300088595993055

Epoch: 5| Step: 10
Training loss: 0.6212297686500549
Validation loss: 2.9992652993458138

Epoch: 5| Step: 11
Training loss: 2.793923210901965
Validation loss: 3.047523116602231

Epoch: 381| Step: 0
Training loss: 0.6182647671260588
Validation loss: 3.0225680347176165

Epoch: 5| Step: 1
Training loss: 0.34184079569233866
Validation loss: 3.0213997090697227

Epoch: 5| Step: 2
Training loss: 0.6746656879187384
Validation loss: 3.034633593110101

Epoch: 5| Step: 3
Training loss: 0.6663169067526206
Validation loss: 3.0488263329144885

Epoch: 5| Step: 4
Training loss: 0.7482128307823916
Validation loss: 2.965208869602942

Epoch: 5| Step: 5
Training loss: 0.5803850691228138
Validation loss: 2.9622131290582003

Epoch: 5| Step: 6
Training loss: 0.5675258751570524
Validation loss: 3.0323060316564363

Epoch: 5| Step: 7
Training loss: 0.6531352649228861
Validation loss: 3.0042196307934375

Epoch: 5| Step: 8
Training loss: 0.7409328899135548
Validation loss: 3.032530484655612

Epoch: 5| Step: 9
Training loss: 0.6390167844878274
Validation loss: 2.9735107530453218

Epoch: 5| Step: 10
Training loss: 1.2900659066005535
Validation loss: 2.99178011638382

Epoch: 5| Step: 11
Training loss: 0.40045223227321813
Validation loss: 2.9428802923861843

Epoch: 382| Step: 0
Training loss: 0.5014962518025191
Validation loss: 2.870950453938601

Epoch: 5| Step: 1
Training loss: 0.6526060433651264
Validation loss: 2.950578765883993

Epoch: 5| Step: 2
Training loss: 0.8285359856290306
Validation loss: 3.003266351120832

Epoch: 5| Step: 3
Training loss: 0.6972309178708894
Validation loss: 2.904640321107308

Epoch: 5| Step: 4
Training loss: 0.5639686221041587
Validation loss: 2.946875858003364

Epoch: 5| Step: 5
Training loss: 0.5464313887675768
Validation loss: 2.969963702345025

Epoch: 5| Step: 6
Training loss: 0.7136385821681833
Validation loss: 2.9367052991781777

Epoch: 5| Step: 7
Training loss: 1.210198897022179
Validation loss: 3.1614699209001946

Epoch: 5| Step: 8
Training loss: 0.6478732768143869
Validation loss: 2.983856981733027

Epoch: 5| Step: 9
Training loss: 0.5274780667522524
Validation loss: 3.0860928299195787

Epoch: 5| Step: 10
Training loss: 0.8730614850829405
Validation loss: 3.056351763611431

Epoch: 5| Step: 11
Training loss: 0.7374977111780889
Validation loss: 3.0876689769409933

Epoch: 383| Step: 0
Training loss: 0.7314910263220327
Validation loss: 2.992717211309946

Epoch: 5| Step: 1
Training loss: 0.5298352758370585
Validation loss: 3.051507776215361

Epoch: 5| Step: 2
Training loss: 0.5476594475885443
Validation loss: 2.9794265971575014

Epoch: 5| Step: 3
Training loss: 0.8174319964597742
Validation loss: 3.0786589144925363

Epoch: 5| Step: 4
Training loss: 0.5234665649087894
Validation loss: 2.8730646613059094

Epoch: 5| Step: 5
Training loss: 0.5896615763890736
Validation loss: 2.9757736909676353

Epoch: 5| Step: 6
Training loss: 0.6539324300577295
Validation loss: 2.9535297977528066

Epoch: 5| Step: 7
Training loss: 1.3708378914445194
Validation loss: 2.94242119640117

Epoch: 5| Step: 8
Training loss: 0.5444067704645122
Validation loss: 3.0001616798649615

Epoch: 5| Step: 9
Training loss: 0.42594108731164865
Validation loss: 2.963896873698333

Epoch: 5| Step: 10
Training loss: 0.5242326589635113
Validation loss: 3.0212595600576138

Epoch: 5| Step: 11
Training loss: 0.4907834750771446
Validation loss: 3.082354819907878

Epoch: 384| Step: 0
Training loss: 0.5863868262115483
Validation loss: 3.0281000353476633

Epoch: 5| Step: 1
Training loss: 0.5863012583433308
Validation loss: 3.121305570707354

Epoch: 5| Step: 2
Training loss: 0.6127225432639178
Validation loss: 3.0226499860943004

Epoch: 5| Step: 3
Training loss: 0.7372588490769693
Validation loss: 2.97083863854882

Epoch: 5| Step: 4
Training loss: 0.4086677425921612
Validation loss: 3.0309401645472356

Epoch: 5| Step: 5
Training loss: 1.2651563176912053
Validation loss: 3.0702454524852847

Epoch: 5| Step: 6
Training loss: 0.6389772810695523
Validation loss: 2.9795114855629476

Epoch: 5| Step: 7
Training loss: 0.6716942211285879
Validation loss: 2.9234586459736813

Epoch: 5| Step: 8
Training loss: 0.6566565934326772
Validation loss: 2.9097198398057347

Epoch: 5| Step: 9
Training loss: 0.6136751307177124
Validation loss: 2.876668939757158

Epoch: 5| Step: 10
Training loss: 0.732656619282778
Validation loss: 2.9334953823266736

Epoch: 5| Step: 11
Training loss: 0.2584646530832117
Validation loss: 3.087678854185399

Epoch: 385| Step: 0
Training loss: 0.626602383721192
Validation loss: 2.9193273000618523

Epoch: 5| Step: 1
Training loss: 0.5086576617936642
Validation loss: 3.0122414121800616

Epoch: 5| Step: 2
Training loss: 0.5598042583244328
Validation loss: 2.987230293118256

Epoch: 5| Step: 3
Training loss: 0.7369109258071868
Validation loss: 3.070485728960738

Epoch: 5| Step: 4
Training loss: 1.3635347234531205
Validation loss: 3.065539587051373

Epoch: 5| Step: 5
Training loss: 0.6194879177568636
Validation loss: 2.9119663693788134

Epoch: 5| Step: 6
Training loss: 0.5872877711608597
Validation loss: 3.0928115834344028

Epoch: 5| Step: 7
Training loss: 0.5940253472587534
Validation loss: 2.984662343384062

Epoch: 5| Step: 8
Training loss: 0.500842130296011
Validation loss: 3.0644845857579566

Epoch: 5| Step: 9
Training loss: 0.6368326190627338
Validation loss: 2.9429474601248953

Epoch: 5| Step: 10
Training loss: 0.5041135908463165
Validation loss: 2.954132577612453

Epoch: 5| Step: 11
Training loss: 0.827712406084737
Validation loss: 3.040019331722113

Epoch: 386| Step: 0
Training loss: 0.5483967181744726
Validation loss: 2.9808595900214114

Epoch: 5| Step: 1
Training loss: 0.5599152731662599
Validation loss: 2.9272595547113913

Epoch: 5| Step: 2
Training loss: 1.3502364958137447
Validation loss: 2.9882274514801295

Epoch: 5| Step: 3
Training loss: 0.621311749281246
Validation loss: 2.805635888745695

Epoch: 5| Step: 4
Training loss: 0.7944257533009501
Validation loss: 2.905701571849349

Epoch: 5| Step: 5
Training loss: 0.5059472085116694
Validation loss: 3.0065123716501936

Epoch: 5| Step: 6
Training loss: 0.7050869589804322
Validation loss: 2.983499411847612

Epoch: 5| Step: 7
Training loss: 0.4406058050262833
Validation loss: 2.939481472753155

Epoch: 5| Step: 8
Training loss: 0.4461124997449244
Validation loss: 3.0167311581590437

Epoch: 5| Step: 9
Training loss: 0.5269968940762774
Validation loss: 3.057595373835525

Epoch: 5| Step: 10
Training loss: 0.5837559843471355
Validation loss: 2.8942223511477656

Epoch: 5| Step: 11
Training loss: 0.6722606173322715
Validation loss: 2.90616330321695

Epoch: 387| Step: 0
Training loss: 0.799579071529203
Validation loss: 2.9852138725043194

Epoch: 5| Step: 1
Training loss: 0.4288032102236039
Validation loss: 2.9366720500486077

Epoch: 5| Step: 2
Training loss: 0.6887934178827055
Validation loss: 2.8597423303623946

Epoch: 5| Step: 3
Training loss: 0.6434811910475426
Validation loss: 2.8918499885506934

Epoch: 5| Step: 4
Training loss: 0.7088651110168371
Validation loss: 2.8512233654396506

Epoch: 5| Step: 5
Training loss: 1.4036880467943431
Validation loss: 3.0055703033855976

Epoch: 5| Step: 6
Training loss: 0.560309303261807
Validation loss: 2.922411286340347

Epoch: 5| Step: 7
Training loss: 0.7532422397896202
Validation loss: 2.9971845548502136

Epoch: 5| Step: 8
Training loss: 0.6361040529912684
Validation loss: 3.055050180405984

Epoch: 5| Step: 9
Training loss: 0.6499236667267655
Validation loss: 2.9591975975640223

Epoch: 5| Step: 10
Training loss: 0.645849232836843
Validation loss: 2.8946360759140752

Epoch: 5| Step: 11
Training loss: 0.43539499619810496
Validation loss: 2.9614884862841806

Epoch: 388| Step: 0
Training loss: 0.7115948750364431
Validation loss: 2.953600668568861

Epoch: 5| Step: 1
Training loss: 0.6641498732587605
Validation loss: 2.937216491410029

Epoch: 5| Step: 2
Training loss: 0.5582980460312951
Validation loss: 3.0554105873590185

Epoch: 5| Step: 3
Training loss: 0.5623369510427233
Validation loss: 2.921919246073381

Epoch: 5| Step: 4
Training loss: 0.4622874454559425
Validation loss: 2.906144283792016

Epoch: 5| Step: 5
Training loss: 1.3129371187648347
Validation loss: 2.843872141049041

Epoch: 5| Step: 6
Training loss: 0.5838551713275234
Validation loss: 2.86815719421832

Epoch: 5| Step: 7
Training loss: 0.6356155339664257
Validation loss: 2.9531970006921746

Epoch: 5| Step: 8
Training loss: 0.46281083139534746
Validation loss: 2.9235215944815183

Epoch: 5| Step: 9
Training loss: 0.8278418722734413
Validation loss: 2.8340691961927993

Epoch: 5| Step: 10
Training loss: 0.580035532405556
Validation loss: 2.900069905540176

Epoch: 5| Step: 11
Training loss: 0.7823762405197955
Validation loss: 2.944468018799303

Epoch: 389| Step: 0
Training loss: 0.6904510537905721
Validation loss: 2.942315395531177

Epoch: 5| Step: 1
Training loss: 0.7436113853471501
Validation loss: 2.9232712060038524

Epoch: 5| Step: 2
Training loss: 1.287411783029403
Validation loss: 2.930811002836247

Epoch: 5| Step: 3
Training loss: 0.5399787413863062
Validation loss: 2.9239847416914504

Epoch: 5| Step: 4
Training loss: 0.4397159892262516
Validation loss: 2.9371139462068414

Epoch: 5| Step: 5
Training loss: 0.6489278708625945
Validation loss: 2.9997159240586204

Epoch: 5| Step: 6
Training loss: 0.6087170986394213
Validation loss: 2.934995672676583

Epoch: 5| Step: 7
Training loss: 0.603254712441697
Validation loss: 2.998108250821228

Epoch: 5| Step: 8
Training loss: 0.6348175966554542
Validation loss: 3.0221336175183757

Epoch: 5| Step: 9
Training loss: 0.6966728447529151
Validation loss: 2.8670492320801624

Epoch: 5| Step: 10
Training loss: 0.5547237384402717
Validation loss: 3.054923192368243

Epoch: 5| Step: 11
Training loss: 0.20257651112506103
Validation loss: 2.998986404109137

Epoch: 390| Step: 0
Training loss: 0.44308764158989145
Validation loss: 3.0405097300526385

Epoch: 5| Step: 1
Training loss: 0.5278851026308564
Validation loss: 2.9207246253172188

Epoch: 5| Step: 2
Training loss: 1.3403880178852299
Validation loss: 2.9624410349776245

Epoch: 5| Step: 3
Training loss: 0.6803673818702459
Validation loss: 2.933437009671633

Epoch: 5| Step: 4
Training loss: 0.7889562478620071
Validation loss: 3.0150679829905576

Epoch: 5| Step: 5
Training loss: 0.7024543742978612
Validation loss: 2.910570474454808

Epoch: 5| Step: 6
Training loss: 0.6997383147950925
Validation loss: 2.9679658740977692

Epoch: 5| Step: 7
Training loss: 0.5362534795439257
Validation loss: 2.9748259590969117

Epoch: 5| Step: 8
Training loss: 0.5414490323688534
Validation loss: 3.0249005440580135

Epoch: 5| Step: 9
Training loss: 0.7052558611504895
Validation loss: 2.9232355102046848

Epoch: 5| Step: 10
Training loss: 0.6999956854619166
Validation loss: 3.017267307047165

Epoch: 5| Step: 11
Training loss: 0.29554393671053947
Validation loss: 2.869008714981777

Epoch: 391| Step: 0
Training loss: 0.5966381801521666
Validation loss: 2.8626410899310817

Epoch: 5| Step: 1
Training loss: 1.3981561644162697
Validation loss: 3.0686980217845514

Epoch: 5| Step: 2
Training loss: 0.6029120825448471
Validation loss: 3.0876245032109924

Epoch: 5| Step: 3
Training loss: 0.879698637761402
Validation loss: 2.9524066529037993

Epoch: 5| Step: 4
Training loss: 0.6396641387177185
Validation loss: 2.9538006657137417

Epoch: 5| Step: 5
Training loss: 0.5793795248223227
Validation loss: 3.1085129857666676

Epoch: 5| Step: 6
Training loss: 0.9067496205053805
Validation loss: 3.0299250469757224

Epoch: 5| Step: 7
Training loss: 0.7635156027667902
Validation loss: 3.0692318930950817

Epoch: 5| Step: 8
Training loss: 0.863763734788352
Validation loss: 2.932362273852859

Epoch: 5| Step: 9
Training loss: 0.5158040862761354
Validation loss: 3.02489260635266

Epoch: 5| Step: 10
Training loss: 0.42468319613512384
Validation loss: 2.997615121243295

Epoch: 5| Step: 11
Training loss: 0.6459469592726426
Validation loss: 2.9286960161742073

Epoch: 392| Step: 0
Training loss: 0.579580331031744
Validation loss: 2.905451429027718

Epoch: 5| Step: 1
Training loss: 0.7480046830591695
Validation loss: 2.9954402132886866

Epoch: 5| Step: 2
Training loss: 0.5612621196891071
Validation loss: 2.994364048932425

Epoch: 5| Step: 3
Training loss: 1.3077943096468208
Validation loss: 2.934872185725497

Epoch: 5| Step: 4
Training loss: 0.5968270377416789
Validation loss: 2.8933587524528757

Epoch: 5| Step: 5
Training loss: 0.7750871578551883
Validation loss: 2.962522047500014

Epoch: 5| Step: 6
Training loss: 0.5302930796657782
Validation loss: 3.0254657260741955

Epoch: 5| Step: 7
Training loss: 0.4570032094846918
Validation loss: 2.977373928696877

Epoch: 5| Step: 8
Training loss: 0.5544639996777331
Validation loss: 2.967327402816502

Epoch: 5| Step: 9
Training loss: 0.6102614435422399
Validation loss: 3.0458620849344746

Epoch: 5| Step: 10
Training loss: 0.5585839330704239
Validation loss: 2.889457731581495

Epoch: 5| Step: 11
Training loss: 0.4482383977193754
Validation loss: 2.895866600824363

Epoch: 393| Step: 0
Training loss: 0.6200349287607732
Validation loss: 2.9181453714362986

Epoch: 5| Step: 1
Training loss: 0.5649697338707375
Validation loss: 2.892913053716262

Epoch: 5| Step: 2
Training loss: 0.4798628235047416
Validation loss: 3.1057711727908166

Epoch: 5| Step: 3
Training loss: 0.5142894556935017
Validation loss: 3.071434505154337

Epoch: 5| Step: 4
Training loss: 0.5135100077013248
Validation loss: 2.8630710921937186

Epoch: 5| Step: 5
Training loss: 0.6134521586395796
Validation loss: 2.918667196886811

Epoch: 5| Step: 6
Training loss: 0.556342999045599
Validation loss: 2.9277523346448278

Epoch: 5| Step: 7
Training loss: 0.5632109916985321
Validation loss: 2.949387774139698

Epoch: 5| Step: 8
Training loss: 0.7729424713090876
Validation loss: 2.9423375979246726

Epoch: 5| Step: 9
Training loss: 1.2801812994978663
Validation loss: 3.04542285516336

Epoch: 5| Step: 10
Training loss: 0.606611588391734
Validation loss: 3.021961712834098

Epoch: 5| Step: 11
Training loss: 0.545198814543193
Validation loss: 2.9645857064154306

Epoch: 394| Step: 0
Training loss: 0.5720523267466757
Validation loss: 2.943381583018858

Epoch: 5| Step: 1
Training loss: 0.8201075706635788
Validation loss: 2.98856032321266

Epoch: 5| Step: 2
Training loss: 0.5241740155071285
Validation loss: 2.9859539668309334

Epoch: 5| Step: 3
Training loss: 0.7328287444113796
Validation loss: 3.0719928042336635

Epoch: 5| Step: 4
Training loss: 0.6678249583601782
Validation loss: 2.9686045761629796

Epoch: 5| Step: 5
Training loss: 0.42074075741286227
Validation loss: 2.9610925263121226

Epoch: 5| Step: 6
Training loss: 0.5792342704543794
Validation loss: 3.023960311465

Epoch: 5| Step: 7
Training loss: 1.2955397200684449
Validation loss: 2.984381337849809

Epoch: 5| Step: 8
Training loss: 0.47891873877018265
Validation loss: 2.963084637621066

Epoch: 5| Step: 9
Training loss: 0.6499516835961897
Validation loss: 3.0909255071640107

Epoch: 5| Step: 10
Training loss: 0.4732159225096247
Validation loss: 2.9942046057228633

Epoch: 5| Step: 11
Training loss: 0.34268680792847706
Validation loss: 2.9969071532040474

Epoch: 395| Step: 0
Training loss: 0.4467691222721609
Validation loss: 2.9686711183742753

Epoch: 5| Step: 1
Training loss: 0.6543904479570715
Validation loss: 3.035662232080928

Epoch: 5| Step: 2
Training loss: 0.7145776305420608
Validation loss: 3.083691892953966

Epoch: 5| Step: 3
Training loss: 0.5296187882319094
Validation loss: 3.1085072685202944

Epoch: 5| Step: 4
Training loss: 0.5456268781561933
Validation loss: 2.977926343981562

Epoch: 5| Step: 5
Training loss: 0.59583403602861
Validation loss: 3.025003781592157

Epoch: 5| Step: 6
Training loss: 0.5700336453897904
Validation loss: 2.9295654644450786

Epoch: 5| Step: 7
Training loss: 0.863072089493985
Validation loss: 3.0211133805176376

Epoch: 5| Step: 8
Training loss: 0.5221915718253162
Validation loss: 2.973855335280307

Epoch: 5| Step: 9
Training loss: 1.2631908603808673
Validation loss: 3.090763889016692

Epoch: 5| Step: 10
Training loss: 0.7184997620552322
Validation loss: 2.9869985682359856

Epoch: 5| Step: 11
Training loss: 0.8460132479566018
Validation loss: 3.0265332094691044

Epoch: 396| Step: 0
Training loss: 0.6369985889916235
Validation loss: 2.9777093715386123

Epoch: 5| Step: 1
Training loss: 0.8295287704215154
Validation loss: 2.9113535626189577

Epoch: 5| Step: 2
Training loss: 0.7022925217120739
Validation loss: 2.9104969141024735

Epoch: 5| Step: 3
Training loss: 1.3403057047164042
Validation loss: 3.009389386352293

Epoch: 5| Step: 4
Training loss: 0.4013559381620966
Validation loss: 2.9938203026912817

Epoch: 5| Step: 5
Training loss: 0.6040723880564374
Validation loss: 3.0407723566557108

Epoch: 5| Step: 6
Training loss: 0.5455336879079848
Validation loss: 2.9893982339283514

Epoch: 5| Step: 7
Training loss: 0.6227957240255566
Validation loss: 2.9784401972657784

Epoch: 5| Step: 8
Training loss: 0.694099267898589
Validation loss: 3.0854746314473873

Epoch: 5| Step: 9
Training loss: 0.5040638403688454
Validation loss: 3.0317695506703233

Epoch: 5| Step: 10
Training loss: 0.5257864103021519
Validation loss: 3.0226153784649332

Epoch: 5| Step: 11
Training loss: 0.87342785196998
Validation loss: 2.9421990834482683

Epoch: 397| Step: 0
Training loss: 0.5186208047042046
Validation loss: 2.9631702288651933

Epoch: 5| Step: 1
Training loss: 0.6911831080818636
Validation loss: 3.049099955882427

Epoch: 5| Step: 2
Training loss: 0.4798318937595172
Validation loss: 2.9971905175933213

Epoch: 5| Step: 3
Training loss: 0.7650592815891479
Validation loss: 3.037061645525277

Epoch: 5| Step: 4
Training loss: 1.4444470262911944
Validation loss: 2.980577609372759

Epoch: 5| Step: 5
Training loss: 0.5546001580473698
Validation loss: 2.9160823094722814

Epoch: 5| Step: 6
Training loss: 0.426361685772854
Validation loss: 3.0006281208407994

Epoch: 5| Step: 7
Training loss: 0.6124316848882119
Validation loss: 2.985778362132967

Epoch: 5| Step: 8
Training loss: 0.6429648815237964
Validation loss: 2.9702941057845345

Epoch: 5| Step: 9
Training loss: 0.41616510562250036
Validation loss: 3.0009914587751627

Epoch: 5| Step: 10
Training loss: 0.5488643159167468
Validation loss: 2.985916455279703

Epoch: 5| Step: 11
Training loss: 0.42957722375868385
Validation loss: 2.990123734274217

Epoch: 398| Step: 0
Training loss: 0.4703982303589342
Validation loss: 3.0381072389106647

Epoch: 5| Step: 1
Training loss: 1.3335148220919146
Validation loss: 3.052982202299145

Epoch: 5| Step: 2
Training loss: 0.5764253996069456
Validation loss: 3.0043543335492338

Epoch: 5| Step: 3
Training loss: 0.5537731263560619
Validation loss: 2.999575621338052

Epoch: 5| Step: 4
Training loss: 0.5514901110989417
Validation loss: 3.004672408731418

Epoch: 5| Step: 5
Training loss: 0.5498263149852306
Validation loss: 2.9121407622929936

Epoch: 5| Step: 6
Training loss: 0.4589048600817093
Validation loss: 2.9952463263768867

Epoch: 5| Step: 7
Training loss: 0.61603571460503
Validation loss: 3.0283363700243333

Epoch: 5| Step: 8
Training loss: 0.588179026482571
Validation loss: 3.0100749931783506

Epoch: 5| Step: 9
Training loss: 0.4200068543079198
Validation loss: 2.965193934276445

Epoch: 5| Step: 10
Training loss: 0.6657614124908535
Validation loss: 3.0107061528513683

Epoch: 5| Step: 11
Training loss: 0.9390982673421869
Validation loss: 3.00902676533287

Epoch: 399| Step: 0
Training loss: 0.4915027699494334
Validation loss: 2.997870901702649

Epoch: 5| Step: 1
Training loss: 0.7685197097593758
Validation loss: 2.928649175810372

Epoch: 5| Step: 2
Training loss: 0.5207943011599071
Validation loss: 2.9613723838124435

Epoch: 5| Step: 3
Training loss: 0.49926378766325497
Validation loss: 3.066451468812606

Epoch: 5| Step: 4
Training loss: 0.80419091762944
Validation loss: 3.0319110962210427

Epoch: 5| Step: 5
Training loss: 0.723125078865647
Validation loss: 3.028384817634375

Epoch: 5| Step: 6
Training loss: 0.5823958618167694
Validation loss: 2.968707924260238

Epoch: 5| Step: 7
Training loss: 1.3777875387621938
Validation loss: 2.913428864098524

Epoch: 5| Step: 8
Training loss: 0.4290326243235535
Validation loss: 3.024269032370329

Epoch: 5| Step: 9
Training loss: 0.4888386405995312
Validation loss: 3.093901961219771

Epoch: 5| Step: 10
Training loss: 0.608961649844465
Validation loss: 2.9918115012742788

Epoch: 5| Step: 11
Training loss: 0.3565269899196528
Validation loss: 2.918764736919788

Epoch: 400| Step: 0
Training loss: 0.5616840696704434
Validation loss: 2.9552362521151125

Epoch: 5| Step: 1
Training loss: 0.520142217500112
Validation loss: 2.979503110192307

Epoch: 5| Step: 2
Training loss: 1.3694410661075818
Validation loss: 2.9553047626097326

Epoch: 5| Step: 3
Training loss: 0.5413568019992421
Validation loss: 3.0048783593304416

Epoch: 5| Step: 4
Training loss: 0.5462268803502806
Validation loss: 2.982431154834139

Epoch: 5| Step: 5
Training loss: 0.6524086879913623
Validation loss: 3.0605663565912513

Epoch: 5| Step: 6
Training loss: 0.5343446075987631
Validation loss: 3.015720015101235

Epoch: 5| Step: 7
Training loss: 0.3915082482629795
Validation loss: 3.005825340800442

Epoch: 5| Step: 8
Training loss: 0.4320317563266098
Validation loss: 3.000306322432918

Epoch: 5| Step: 9
Training loss: 0.582594170468987
Validation loss: 3.0254847965643363

Epoch: 5| Step: 10
Training loss: 0.5377227887035043
Validation loss: 3.0423024582135394

Epoch: 5| Step: 11
Training loss: 0.3243119668814673
Validation loss: 3.016970121987409

Testing loss: 3.1047827104270462
