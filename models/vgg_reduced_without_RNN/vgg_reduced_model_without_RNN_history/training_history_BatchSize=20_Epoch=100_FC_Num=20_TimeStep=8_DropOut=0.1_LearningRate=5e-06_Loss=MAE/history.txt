Epoch: 1| Step: 0
Training loss: 5.290334224700928
Validation loss: 5.370316843191783

Epoch: 5| Step: 1
Training loss: 4.9596266746521
Validation loss: 5.351326743761699

Epoch: 5| Step: 2
Training loss: 5.133787155151367
Validation loss: 5.333658893903096

Epoch: 5| Step: 3
Training loss: 5.066374778747559
Validation loss: 5.314635872840881

Epoch: 5| Step: 4
Training loss: 5.10267448425293
Validation loss: 5.2907233238220215

Epoch: 5| Step: 5
Training loss: 5.793861389160156
Validation loss: 5.270606497923533

Epoch: 5| Step: 6
Training loss: 5.564245700836182
Validation loss: 5.249333163102468

Epoch: 5| Step: 7
Training loss: 5.873991012573242
Validation loss: 5.223185578982036

Epoch: 5| Step: 8
Training loss: 4.710991859436035
Validation loss: 5.2018237709999084

Epoch: 5| Step: 9
Training loss: 5.819319248199463
Validation loss: 5.1797274351119995

Epoch: 5| Step: 10
Training loss: 5.187676429748535
Validation loss: 5.1537264585494995

Epoch: 5| Step: 11
Training loss: 6.007660865783691
Validation loss: 5.125559588273366

Epoch: 2| Step: 0
Training loss: 6.252851486206055
Validation loss: 5.102153241634369

Epoch: 5| Step: 1
Training loss: 4.836359977722168
Validation loss: 5.072868665059407

Epoch: 5| Step: 2
Training loss: 5.310979843139648
Validation loss: 5.047514895598094

Epoch: 5| Step: 3
Training loss: 5.945406436920166
Validation loss: 5.022288878758748

Epoch: 5| Step: 4
Training loss: 4.899109840393066
Validation loss: 4.990805357694626

Epoch: 5| Step: 5
Training loss: 5.266634941101074
Validation loss: 4.95655745267868

Epoch: 5| Step: 6
Training loss: 5.239369869232178
Validation loss: 4.929110447565715

Epoch: 5| Step: 7
Training loss: 3.9856998920440674
Validation loss: 4.897095004717509

Epoch: 5| Step: 8
Training loss: 4.50106143951416
Validation loss: 4.862979223330815

Epoch: 5| Step: 9
Training loss: 4.043520450592041
Validation loss: 4.830087939898173

Epoch: 5| Step: 10
Training loss: 5.009281158447266
Validation loss: 4.794799546400706

Epoch: 5| Step: 11
Training loss: 4.978811740875244
Validation loss: 4.7556183735529585

Epoch: 3| Step: 0
Training loss: 4.44299840927124
Validation loss: 4.717809975147247

Epoch: 5| Step: 1
Training loss: 4.183304786682129
Validation loss: 4.678319454193115

Epoch: 5| Step: 2
Training loss: 5.665813446044922
Validation loss: 4.634825726350148

Epoch: 5| Step: 3
Training loss: 4.247655868530273
Validation loss: 4.589502394199371

Epoch: 5| Step: 4
Training loss: 4.699780464172363
Validation loss: 4.5420645872751875

Epoch: 5| Step: 5
Training loss: 4.427750587463379
Validation loss: 4.492812385161717

Epoch: 5| Step: 6
Training loss: 4.85291862487793
Validation loss: 4.446247299512227

Epoch: 5| Step: 7
Training loss: 4.70284366607666
Validation loss: 4.397246132294337

Epoch: 5| Step: 8
Training loss: 4.894546031951904
Validation loss: 4.33648145198822

Epoch: 5| Step: 9
Training loss: 3.9550743103027344
Validation loss: 4.275073279937108

Epoch: 5| Step: 10
Training loss: 4.370436191558838
Validation loss: 4.218743662039439

Epoch: 5| Step: 11
Training loss: 3.123575448989868
Validation loss: 4.1523422201474505

Epoch: 4| Step: 0
Training loss: 4.4648847579956055
Validation loss: 4.093194256226222

Epoch: 5| Step: 1
Training loss: 4.235496520996094
Validation loss: 4.0377241770426435

Epoch: 5| Step: 2
Training loss: 3.69639253616333
Validation loss: 3.9740227361520133

Epoch: 5| Step: 3
Training loss: 4.4856858253479
Validation loss: 3.909938395023346

Epoch: 5| Step: 4
Training loss: 3.806514024734497
Validation loss: 3.841206947962443

Epoch: 5| Step: 5
Training loss: 4.3454437255859375
Validation loss: 3.769801805416743

Epoch: 5| Step: 6
Training loss: 2.794882297515869
Validation loss: 3.7027409374713898

Epoch: 5| Step: 7
Training loss: 3.505356550216675
Validation loss: 3.621614803870519

Epoch: 5| Step: 8
Training loss: 3.377532958984375
Validation loss: 3.547455668449402

Epoch: 5| Step: 9
Training loss: 3.1859230995178223
Validation loss: 3.4771393537521362

Epoch: 5| Step: 10
Training loss: 4.151572227478027
Validation loss: 3.4013942877451577

Epoch: 5| Step: 11
Training loss: 4.235236167907715
Validation loss: 3.3004901806513467

Epoch: 5| Step: 0
Training loss: 2.5305328369140625
Validation loss: 3.2267944316069284

Epoch: 5| Step: 1
Training loss: 2.761465549468994
Validation loss: 3.1582382718722024

Epoch: 5| Step: 2
Training loss: 2.5953891277313232
Validation loss: 3.049641956885656

Epoch: 5| Step: 3
Training loss: 3.6835219860076904
Validation loss: 2.987303098042806

Epoch: 5| Step: 4
Training loss: 3.212134599685669
Validation loss: 2.8978357116381326

Epoch: 5| Step: 5
Training loss: 2.8246049880981445
Validation loss: 2.82685054341952

Epoch: 5| Step: 6
Training loss: 2.46431303024292
Validation loss: 2.710090219974518

Epoch: 5| Step: 7
Training loss: 2.345263719558716
Validation loss: 2.6567138731479645

Epoch: 5| Step: 8
Training loss: 2.7231552600860596
Validation loss: 2.5432253181934357

Epoch: 5| Step: 9
Training loss: 2.1841819286346436
Validation loss: 2.48448583483696

Epoch: 5| Step: 10
Training loss: 2.4323337078094482
Validation loss: 2.403022696574529

Epoch: 5| Step: 11
Training loss: 3.056715965270996
Validation loss: 2.343489110469818

Epoch: 6| Step: 0
Training loss: 1.8760883808135986
Validation loss: 2.3113874793052673

Epoch: 5| Step: 1
Training loss: 2.2654409408569336
Validation loss: 2.2548374632994332

Epoch: 5| Step: 2
Training loss: 2.3687679767608643
Validation loss: 2.1916420509417853

Epoch: 5| Step: 3
Training loss: 2.0279181003570557
Validation loss: 2.219306096434593

Epoch: 5| Step: 4
Training loss: 1.8627145290374756
Validation loss: 2.195857430497805

Epoch: 5| Step: 5
Training loss: 2.1511893272399902
Validation loss: 2.216345876455307

Epoch: 5| Step: 6
Training loss: 1.7339916229248047
Validation loss: 2.2131234208742776

Epoch: 5| Step: 7
Training loss: 2.299433469772339
Validation loss: 2.236110577980677

Epoch: 5| Step: 8
Training loss: 2.5046544075012207
Validation loss: 2.2751339177290597

Epoch: 5| Step: 9
Training loss: 2.4935784339904785
Validation loss: 2.2861237774292626

Epoch: 5| Step: 10
Training loss: 2.3576273918151855
Validation loss: 2.327509398261706

Epoch: 5| Step: 11
Training loss: 2.969487190246582
Validation loss: 2.2784204135338464

Epoch: 7| Step: 0
Training loss: 1.7284088134765625
Validation loss: 2.279305025935173

Epoch: 5| Step: 1
Training loss: 2.0455374717712402
Validation loss: 2.2600979109605155

Epoch: 5| Step: 2
Training loss: 2.437312364578247
Validation loss: 2.2304601669311523

Epoch: 5| Step: 3
Training loss: 2.3702754974365234
Validation loss: 2.232486387093862

Epoch: 5| Step: 4
Training loss: 2.6487784385681152
Validation loss: 2.2035560260216394

Epoch: 5| Step: 5
Training loss: 2.2939040660858154
Validation loss: 2.1943825085957847

Epoch: 5| Step: 6
Training loss: 2.334843873977661
Validation loss: 2.1764901876449585

Epoch: 5| Step: 7
Training loss: 2.399247646331787
Validation loss: 2.177017350991567

Epoch: 5| Step: 8
Training loss: 1.8049430847167969
Validation loss: 2.1901217798391976

Epoch: 5| Step: 9
Training loss: 1.6166274547576904
Validation loss: 2.1866658429304757

Epoch: 5| Step: 10
Training loss: 2.1918394565582275
Validation loss: 2.2136032233635583

Epoch: 5| Step: 11
Training loss: 1.1003131866455078
Validation loss: 2.194173296292623

Epoch: 8| Step: 0
Training loss: 2.0182814598083496
Validation loss: 2.183538650472959

Epoch: 5| Step: 1
Training loss: 2.4493815898895264
Validation loss: 2.223677178223928

Epoch: 5| Step: 2
Training loss: 1.8473503589630127
Validation loss: 2.2177295138438544

Epoch: 5| Step: 3
Training loss: 2.281524181365967
Validation loss: 2.218988761305809

Epoch: 5| Step: 4
Training loss: 2.674962043762207
Validation loss: 2.2174916565418243

Epoch: 5| Step: 5
Training loss: 1.8857128620147705
Validation loss: 2.223037580649058

Epoch: 5| Step: 6
Training loss: 1.535554051399231
Validation loss: 2.2446878403425217

Epoch: 5| Step: 7
Training loss: 1.9283206462860107
Validation loss: 2.2291316787401834

Epoch: 5| Step: 8
Training loss: 1.965123176574707
Validation loss: 2.222214644153913

Epoch: 5| Step: 9
Training loss: 2.360949754714966
Validation loss: 2.1978593269983926

Epoch: 5| Step: 10
Training loss: 2.4682209491729736
Validation loss: 2.1862174967924752

Epoch: 5| Step: 11
Training loss: 1.6081724166870117
Validation loss: 2.18218557536602

Epoch: 9| Step: 0
Training loss: 2.119706153869629
Validation loss: 2.1944173822800317

Epoch: 5| Step: 1
Training loss: 2.1353278160095215
Validation loss: 2.2101268817981086

Epoch: 5| Step: 2
Training loss: 1.8360722064971924
Validation loss: 2.1977129727602005

Epoch: 5| Step: 3
Training loss: 2.319455862045288
Validation loss: 2.2024938613176346

Epoch: 5| Step: 4
Training loss: 1.9356107711791992
Validation loss: 2.214584638675054

Epoch: 5| Step: 5
Training loss: 1.706825613975525
Validation loss: 2.197228570779165

Epoch: 5| Step: 6
Training loss: 1.789406418800354
Validation loss: 2.156010483702024

Epoch: 5| Step: 7
Training loss: 2.282214641571045
Validation loss: 2.168262004852295

Epoch: 5| Step: 8
Training loss: 2.1351308822631836
Validation loss: 2.18600757420063

Epoch: 5| Step: 9
Training loss: 2.236210584640503
Validation loss: 2.1700001855691275

Epoch: 5| Step: 10
Training loss: 2.503728151321411
Validation loss: 2.1840507288773856

Epoch: 5| Step: 11
Training loss: 1.958928108215332
Validation loss: 2.1702867348988852

Epoch: 10| Step: 0
Training loss: 1.8040930032730103
Validation loss: 2.1543942292531333

Epoch: 5| Step: 1
Training loss: 2.0988593101501465
Validation loss: 2.1766079515218735

Epoch: 5| Step: 2
Training loss: 1.412067174911499
Validation loss: 2.1723220696051917

Epoch: 5| Step: 3
Training loss: 2.5187325477600098
Validation loss: 2.1750680406888327

Epoch: 5| Step: 4
Training loss: 1.66768479347229
Validation loss: 2.152482748031616

Epoch: 5| Step: 5
Training loss: 2.5268616676330566
Validation loss: 2.1686267405748367

Epoch: 5| Step: 6
Training loss: 2.3575472831726074
Validation loss: 2.1433133532603583

Epoch: 5| Step: 7
Training loss: 2.398531913757324
Validation loss: 2.151179532210032

Epoch: 5| Step: 8
Training loss: 2.3884408473968506
Validation loss: 2.1520758916934333

Epoch: 5| Step: 9
Training loss: 1.919532060623169
Validation loss: 2.171774218479792

Epoch: 5| Step: 10
Training loss: 1.9645240306854248
Validation loss: 2.1532313028971353

Epoch: 5| Step: 11
Training loss: 1.683518886566162
Validation loss: 2.150096828738848

Epoch: 11| Step: 0
Training loss: 2.3459620475769043
Validation loss: 2.1714848478635154

Epoch: 5| Step: 1
Training loss: 2.4390015602111816
Validation loss: 2.150374432404836

Epoch: 5| Step: 2
Training loss: 1.277209997177124
Validation loss: 2.156548281510671

Epoch: 5| Step: 3
Training loss: 2.002000331878662
Validation loss: 2.165732358892759

Epoch: 5| Step: 4
Training loss: 2.093377113342285
Validation loss: 2.140761728088061

Epoch: 5| Step: 5
Training loss: 1.765197515487671
Validation loss: 2.1744854052861533

Epoch: 5| Step: 6
Training loss: 2.2298293113708496
Validation loss: 2.1469617585341134

Epoch: 5| Step: 7
Training loss: 1.8371527194976807
Validation loss: 2.1375646541515985

Epoch: 5| Step: 8
Training loss: 2.3246800899505615
Validation loss: 2.1570296635230384

Epoch: 5| Step: 9
Training loss: 2.0564053058624268
Validation loss: 2.1230019629001617

Epoch: 5| Step: 10
Training loss: 2.2800140380859375
Validation loss: 2.1257477601369223

Epoch: 5| Step: 11
Training loss: 2.0739402770996094
Validation loss: 2.141059711575508

Epoch: 12| Step: 0
Training loss: 2.4724631309509277
Validation loss: 2.14958718419075

Epoch: 5| Step: 1
Training loss: 2.003552198410034
Validation loss: 2.14592116077741

Epoch: 5| Step: 2
Training loss: 2.0394742488861084
Validation loss: 2.1644917527834573

Epoch: 5| Step: 3
Training loss: 2.2632389068603516
Validation loss: 2.115837901830673

Epoch: 5| Step: 4
Training loss: 1.971190094947815
Validation loss: 2.1246912429730096

Epoch: 5| Step: 5
Training loss: 1.9081093072891235
Validation loss: 2.1470391054948172

Epoch: 5| Step: 6
Training loss: 1.8594858646392822
Validation loss: 2.1522686133782067

Epoch: 5| Step: 7
Training loss: 2.069828748703003
Validation loss: 2.157282610734304

Epoch: 5| Step: 8
Training loss: 2.213928699493408
Validation loss: 2.1208096792300544

Epoch: 5| Step: 9
Training loss: 2.5036840438842773
Validation loss: 2.1411215414603553

Epoch: 5| Step: 10
Training loss: 1.37613844871521
Validation loss: 2.142570808529854

Epoch: 5| Step: 11
Training loss: 0.6572708487510681
Validation loss: 2.1326771130164466

Epoch: 13| Step: 0
Training loss: 1.813990831375122
Validation loss: 2.1424442330996194

Epoch: 5| Step: 1
Training loss: 1.867483139038086
Validation loss: 2.115233361721039

Epoch: 5| Step: 2
Training loss: 1.873836874961853
Validation loss: 2.1387862314780555

Epoch: 5| Step: 3
Training loss: 1.8851522207260132
Validation loss: 2.153740798433622

Epoch: 5| Step: 4
Training loss: 2.1719555854797363
Validation loss: 2.141309837500254

Epoch: 5| Step: 5
Training loss: 2.289032459259033
Validation loss: 2.1610244065523148

Epoch: 5| Step: 6
Training loss: 2.38281512260437
Validation loss: 2.133560925722122

Epoch: 5| Step: 7
Training loss: 1.8421179056167603
Validation loss: 2.1471519817908606

Epoch: 5| Step: 8
Training loss: 2.073136806488037
Validation loss: 2.1384775390227637

Epoch: 5| Step: 9
Training loss: 2.2849104404449463
Validation loss: 2.1355632146199546

Epoch: 5| Step: 10
Training loss: 2.158116102218628
Validation loss: 2.141765207052231

Epoch: 5| Step: 11
Training loss: 1.789069652557373
Validation loss: 2.1237821330626807

Epoch: 14| Step: 0
Training loss: 1.740627646446228
Validation loss: 2.132663289705912

Epoch: 5| Step: 1
Training loss: 1.7254431247711182
Validation loss: 2.130603457490603

Epoch: 5| Step: 2
Training loss: 1.8481544256210327
Validation loss: 2.1318173507849374

Epoch: 5| Step: 3
Training loss: 2.3983399868011475
Validation loss: 2.121564437945684

Epoch: 5| Step: 4
Training loss: 2.169829845428467
Validation loss: 2.1291468888521194

Epoch: 5| Step: 5
Training loss: 2.1187903881073
Validation loss: 2.1199546257654824

Epoch: 5| Step: 6
Training loss: 2.5409467220306396
Validation loss: 2.112194816271464

Epoch: 5| Step: 7
Training loss: 2.2812092304229736
Validation loss: 2.1393314401308694

Epoch: 5| Step: 8
Training loss: 1.9092187881469727
Validation loss: 2.1342282046874366

Epoch: 5| Step: 9
Training loss: 2.35444712638855
Validation loss: 2.1398505866527557

Epoch: 5| Step: 10
Training loss: 1.6740257740020752
Validation loss: 2.124898537993431

Epoch: 5| Step: 11
Training loss: 1.472160816192627
Validation loss: 2.1409206837415695

Epoch: 15| Step: 0
Training loss: 2.4421133995056152
Validation loss: 2.1231715629498162

Epoch: 5| Step: 1
Training loss: 2.232874631881714
Validation loss: 2.1453509777784348

Epoch: 5| Step: 2
Training loss: 2.3023898601531982
Validation loss: 2.127307956417402

Epoch: 5| Step: 3
Training loss: 1.3673365116119385
Validation loss: 2.118264213204384

Epoch: 5| Step: 4
Training loss: 2.0553107261657715
Validation loss: 2.1348196466763816

Epoch: 5| Step: 5
Training loss: 1.5061500072479248
Validation loss: 2.128293658296267

Epoch: 5| Step: 6
Training loss: 1.9948995113372803
Validation loss: 2.0870520571867623

Epoch: 5| Step: 7
Training loss: 2.2727112770080566
Validation loss: 2.1137731124957404

Epoch: 5| Step: 8
Training loss: 2.1996371746063232
Validation loss: 2.0962693144877753

Epoch: 5| Step: 9
Training loss: 2.2530579566955566
Validation loss: 2.1120988527933755

Epoch: 5| Step: 10
Training loss: 2.246980905532837
Validation loss: 2.1255050798257193

Epoch: 5| Step: 11
Training loss: 0.7927893400192261
Validation loss: 2.0939991424481073

Epoch: 16| Step: 0
Training loss: 1.8883692026138306
Validation loss: 2.0895174741744995

Epoch: 5| Step: 1
Training loss: 2.771205186843872
Validation loss: 2.1050110260645547

Epoch: 5| Step: 2
Training loss: 2.128431797027588
Validation loss: 2.1368807206551232

Epoch: 5| Step: 3
Training loss: 1.4291229248046875
Validation loss: 2.1026504238446555

Epoch: 5| Step: 4
Training loss: 1.6982555389404297
Validation loss: 2.129406447211901

Epoch: 5| Step: 5
Training loss: 2.2468502521514893
Validation loss: 2.119574402769407

Epoch: 5| Step: 6
Training loss: 2.0665340423583984
Validation loss: 2.08417572081089

Epoch: 5| Step: 7
Training loss: 2.048485279083252
Validation loss: 2.1097711324691772

Epoch: 5| Step: 8
Training loss: 1.5108261108398438
Validation loss: 2.1201635599136353

Epoch: 5| Step: 9
Training loss: 2.5205562114715576
Validation loss: 2.1072392066319785

Epoch: 5| Step: 10
Training loss: 1.9733426570892334
Validation loss: 2.1174543102582297

Epoch: 5| Step: 11
Training loss: 2.5185914039611816
Validation loss: 2.1037714878718057

Epoch: 17| Step: 0
Training loss: 2.823575496673584
Validation loss: 2.094287951787313

Epoch: 5| Step: 1
Training loss: 1.8939625024795532
Validation loss: 2.109958400328954

Epoch: 5| Step: 2
Training loss: 1.3612892627716064
Validation loss: 2.100124314427376

Epoch: 5| Step: 3
Training loss: 2.0365428924560547
Validation loss: 2.1287270238002143

Epoch: 5| Step: 4
Training loss: 1.7802512645721436
Validation loss: 2.096407557527224

Epoch: 5| Step: 5
Training loss: 1.660347580909729
Validation loss: 2.1193315287431083

Epoch: 5| Step: 6
Training loss: 2.156808614730835
Validation loss: 2.0996151864528656

Epoch: 5| Step: 7
Training loss: 2.0182666778564453
Validation loss: 2.1104991833368936

Epoch: 5| Step: 8
Training loss: 2.4621663093566895
Validation loss: 2.0849709461132684

Epoch: 5| Step: 9
Training loss: 1.9845155477523804
Validation loss: 2.0951738506555557

Epoch: 5| Step: 10
Training loss: 2.235922336578369
Validation loss: 2.110618238647779

Epoch: 5| Step: 11
Training loss: 2.191890239715576
Validation loss: 2.1096899807453156

Epoch: 18| Step: 0
Training loss: 1.6486613750457764
Validation loss: 2.1140945504109063

Epoch: 5| Step: 1
Training loss: 2.1912853717803955
Validation loss: 2.107609579960505

Epoch: 5| Step: 2
Training loss: 1.6271259784698486
Validation loss: 2.1220910946528115

Epoch: 5| Step: 3
Training loss: 1.7844536304473877
Validation loss: 2.09860527018706

Epoch: 5| Step: 4
Training loss: 1.8383861780166626
Validation loss: 2.095384975274404

Epoch: 5| Step: 5
Training loss: 2.0705068111419678
Validation loss: 2.1135691354672113

Epoch: 5| Step: 6
Training loss: 2.654356002807617
Validation loss: 2.1221410632133484

Epoch: 5| Step: 7
Training loss: 2.610379219055176
Validation loss: 2.11221814652284

Epoch: 5| Step: 8
Training loss: 1.7458473443984985
Validation loss: 2.0918363134066262

Epoch: 5| Step: 9
Training loss: 1.9073272943496704
Validation loss: 2.0813036213318505

Epoch: 5| Step: 10
Training loss: 2.2583718299865723
Validation loss: 2.0922115445137024

Epoch: 5| Step: 11
Training loss: 1.8832745552062988
Validation loss: 2.058959871530533

Epoch: 19| Step: 0
Training loss: 2.1512033939361572
Validation loss: 2.091439113020897

Epoch: 5| Step: 1
Training loss: 1.8301359415054321
Validation loss: 2.085878481467565

Epoch: 5| Step: 2
Training loss: 1.9235941171646118
Validation loss: 2.104436938961347

Epoch: 5| Step: 3
Training loss: 2.2512269020080566
Validation loss: 2.094099203745524

Epoch: 5| Step: 4
Training loss: 2.4062609672546387
Validation loss: 2.064435288310051

Epoch: 5| Step: 5
Training loss: 1.9649684429168701
Validation loss: 2.091200610001882

Epoch: 5| Step: 6
Training loss: 2.1915512084960938
Validation loss: 2.0917178789774575

Epoch: 5| Step: 7
Training loss: 1.999572515487671
Validation loss: 2.094885836044947

Epoch: 5| Step: 8
Training loss: 2.0183165073394775
Validation loss: 2.10315078496933

Epoch: 5| Step: 9
Training loss: 1.9014816284179688
Validation loss: 2.088935002684593

Epoch: 5| Step: 10
Training loss: 1.8313846588134766
Validation loss: 2.0721804797649384

Epoch: 5| Step: 11
Training loss: 0.9107739925384521
Validation loss: 2.0953295081853867

Epoch: 20| Step: 0
Training loss: 2.261892318725586
Validation loss: 2.093261187275251

Epoch: 5| Step: 1
Training loss: 2.415032148361206
Validation loss: 2.0984451274077096

Epoch: 5| Step: 2
Training loss: 2.1868793964385986
Validation loss: 2.079894483089447

Epoch: 5| Step: 3
Training loss: 1.4385075569152832
Validation loss: 2.1060026784737906

Epoch: 5| Step: 4
Training loss: 1.6055278778076172
Validation loss: 2.1213173270225525

Epoch: 5| Step: 5
Training loss: 2.2394938468933105
Validation loss: 2.0938497136036553

Epoch: 5| Step: 6
Training loss: 2.290024518966675
Validation loss: 2.091538374622663

Epoch: 5| Step: 7
Training loss: 2.1291708946228027
Validation loss: 2.08328115940094

Epoch: 5| Step: 8
Training loss: 2.05985951423645
Validation loss: 2.0837754805882773

Epoch: 5| Step: 9
Training loss: 1.9607023000717163
Validation loss: 2.0650126238663993

Epoch: 5| Step: 10
Training loss: 1.8063762187957764
Validation loss: 2.088885545730591

Epoch: 5| Step: 11
Training loss: 0.9325658679008484
Validation loss: 2.089675302306811

Epoch: 21| Step: 0
Training loss: 2.0634984970092773
Validation loss: 2.0899380495150885

Epoch: 5| Step: 1
Training loss: 2.143505573272705
Validation loss: 2.0915808180967965

Epoch: 5| Step: 2
Training loss: 1.8711246252059937
Validation loss: 2.0910813560088477

Epoch: 5| Step: 3
Training loss: 1.7231972217559814
Validation loss: 2.1057447691758475

Epoch: 5| Step: 4
Training loss: 2.364651918411255
Validation loss: 2.082918961842855

Epoch: 5| Step: 5
Training loss: 2.381307363510132
Validation loss: 2.083577315012614

Epoch: 5| Step: 6
Training loss: 1.3774573802947998
Validation loss: 2.0981787145137787

Epoch: 5| Step: 7
Training loss: 2.3082995414733887
Validation loss: 2.1059008290370307

Epoch: 5| Step: 8
Training loss: 2.2511703968048096
Validation loss: 2.0937664409478507

Epoch: 5| Step: 9
Training loss: 1.6543413400650024
Validation loss: 2.0775725742181144

Epoch: 5| Step: 10
Training loss: 2.194938898086548
Validation loss: 2.0880350271860757

Epoch: 5| Step: 11
Training loss: 1.9737648963928223
Validation loss: 2.07557142774264

Epoch: 22| Step: 0
Training loss: 1.957754135131836
Validation loss: 2.083889380097389

Epoch: 5| Step: 1
Training loss: 1.4119023084640503
Validation loss: 2.0978301664193473

Epoch: 5| Step: 2
Training loss: 1.7546437978744507
Validation loss: 2.0939232061306634

Epoch: 5| Step: 3
Training loss: 2.093693971633911
Validation loss: 2.08443055053552

Epoch: 5| Step: 4
Training loss: 1.7653268575668335
Validation loss: 2.0681574990351996

Epoch: 5| Step: 5
Training loss: 2.467893600463867
Validation loss: 2.0846840192874274

Epoch: 5| Step: 6
Training loss: 2.0955703258514404
Validation loss: 2.0670119325319924

Epoch: 5| Step: 7
Training loss: 2.3342018127441406
Validation loss: 2.0678085883458457

Epoch: 5| Step: 8
Training loss: 2.6148085594177246
Validation loss: 2.073825255036354

Epoch: 5| Step: 9
Training loss: 1.7628310918807983
Validation loss: 2.1114843636751175

Epoch: 5| Step: 10
Training loss: 2.137026071548462
Validation loss: 2.0883594999710717

Epoch: 5| Step: 11
Training loss: 1.2660856246948242
Validation loss: 2.089256932338079

Epoch: 23| Step: 0
Training loss: 1.9669910669326782
Validation loss: 2.0818087657292685

Epoch: 5| Step: 1
Training loss: 2.254079818725586
Validation loss: 2.1087771306435266

Epoch: 5| Step: 2
Training loss: 2.099238634109497
Validation loss: 2.1320275912682214

Epoch: 5| Step: 3
Training loss: 2.0729775428771973
Validation loss: 2.0723112920920053

Epoch: 5| Step: 4
Training loss: 1.7408077716827393
Validation loss: 2.0808586378892264

Epoch: 5| Step: 5
Training loss: 2.2908802032470703
Validation loss: 2.072717289129893

Epoch: 5| Step: 6
Training loss: 1.7878491878509521
Validation loss: 2.0848362048467

Epoch: 5| Step: 7
Training loss: 2.19476318359375
Validation loss: 2.04673241575559

Epoch: 5| Step: 8
Training loss: 2.0536789894104004
Validation loss: 2.089597702026367

Epoch: 5| Step: 9
Training loss: 2.0060603618621826
Validation loss: 2.114729344844818

Epoch: 5| Step: 10
Training loss: 1.9175726175308228
Validation loss: 2.070829212665558

Epoch: 5| Step: 11
Training loss: 1.4255495071411133
Validation loss: 2.038298934698105

Epoch: 24| Step: 0
Training loss: 2.1642966270446777
Validation loss: 2.097892572482427

Epoch: 5| Step: 1
Training loss: 2.090451717376709
Validation loss: 2.0795888006687164

Epoch: 5| Step: 2
Training loss: 1.9066741466522217
Validation loss: 2.088456451892853

Epoch: 5| Step: 3
Training loss: 2.207484722137451
Validation loss: 2.081173693140348

Epoch: 5| Step: 4
Training loss: 1.8194758892059326
Validation loss: 2.084298476576805

Epoch: 5| Step: 5
Training loss: 1.7872880697250366
Validation loss: 2.0445640782515206

Epoch: 5| Step: 6
Training loss: 1.9506486654281616
Validation loss: 2.0653196225563684

Epoch: 5| Step: 7
Training loss: 1.9118083715438843
Validation loss: 2.070198396841685

Epoch: 5| Step: 8
Training loss: 1.8460890054702759
Validation loss: 2.111623485883077

Epoch: 5| Step: 9
Training loss: 2.048142194747925
Validation loss: 2.0901814699172974

Epoch: 5| Step: 10
Training loss: 2.4739699363708496
Validation loss: 2.1037088533242545

Epoch: 5| Step: 11
Training loss: 1.6076092720031738
Validation loss: 2.0930526107549667

Epoch: 25| Step: 0
Training loss: 1.3027222156524658
Validation loss: 2.0756277044614158

Epoch: 5| Step: 1
Training loss: 1.924294114112854
Validation loss: 2.0853946059942245

Epoch: 5| Step: 2
Training loss: 3.175086736679077
Validation loss: 2.0896676729122796

Epoch: 5| Step: 3
Training loss: 1.6927642822265625
Validation loss: 2.090740606188774

Epoch: 5| Step: 4
Training loss: 1.7981010675430298
Validation loss: 2.119878719250361

Epoch: 5| Step: 5
Training loss: 1.7369801998138428
Validation loss: 2.1352077374855676

Epoch: 5| Step: 6
Training loss: 2.0412960052490234
Validation loss: 2.151778062184652

Epoch: 5| Step: 7
Training loss: 1.8107668161392212
Validation loss: 2.1218524475892386

Epoch: 5| Step: 8
Training loss: 1.669426679611206
Validation loss: 2.1852286209662757

Epoch: 5| Step: 9
Training loss: 2.424858808517456
Validation loss: 2.1152374297380447

Epoch: 5| Step: 10
Training loss: 2.352206230163574
Validation loss: 2.136184200644493

Epoch: 5| Step: 11
Training loss: 4.371506214141846
Validation loss: 2.130730534593264

Epoch: 26| Step: 0
Training loss: 2.0770859718322754
Validation loss: 2.108118027448654

Epoch: 5| Step: 1
Training loss: 1.715673804283142
Validation loss: 2.063668961326281

Epoch: 5| Step: 2
Training loss: 1.7840951681137085
Validation loss: 2.0815206468105316

Epoch: 5| Step: 3
Training loss: 1.9922535419464111
Validation loss: 2.0555726091066995

Epoch: 5| Step: 4
Training loss: 2.463672399520874
Validation loss: 2.0642849802970886

Epoch: 5| Step: 5
Training loss: 1.417070984840393
Validation loss: 2.0936103065808616

Epoch: 5| Step: 6
Training loss: 2.2659993171691895
Validation loss: 2.113922114173571

Epoch: 5| Step: 7
Training loss: 2.1571216583251953
Validation loss: 2.10053159793218

Epoch: 5| Step: 8
Training loss: 2.593040943145752
Validation loss: 2.1123039424419403

Epoch: 5| Step: 9
Training loss: 2.033202886581421
Validation loss: 2.113209292292595

Epoch: 5| Step: 10
Training loss: 1.9701564311981201
Validation loss: 2.08555239935716

Epoch: 5| Step: 11
Training loss: 2.1394569873809814
Validation loss: 2.106395408511162

Epoch: 27| Step: 0
Training loss: 2.1246113777160645
Validation loss: 2.0972130447626114

Epoch: 5| Step: 1
Training loss: 2.1485848426818848
Validation loss: 2.0805798520644507

Epoch: 5| Step: 2
Training loss: 1.8302253484725952
Validation loss: 2.0576843321323395

Epoch: 5| Step: 3
Training loss: 2.141292095184326
Validation loss: 2.0997838924328485

Epoch: 5| Step: 4
Training loss: 1.8398926258087158
Validation loss: 2.0723081628481546

Epoch: 5| Step: 5
Training loss: 2.1486620903015137
Validation loss: 2.0878919263680777

Epoch: 5| Step: 6
Training loss: 2.2181429862976074
Validation loss: 2.0916993767023087

Epoch: 5| Step: 7
Training loss: 1.542569875717163
Validation loss: 2.091050992409388

Epoch: 5| Step: 8
Training loss: 1.8282697200775146
Validation loss: 2.0638384024302163

Epoch: 5| Step: 9
Training loss: 1.989611268043518
Validation loss: 2.0744150380293527

Epoch: 5| Step: 10
Training loss: 2.343860149383545
Validation loss: 2.0749549170335135

Epoch: 5| Step: 11
Training loss: 2.395153760910034
Validation loss: 2.08157250781854

Epoch: 28| Step: 0
Training loss: 2.3802459239959717
Validation loss: 2.086946278810501

Epoch: 5| Step: 1
Training loss: 1.8433427810668945
Validation loss: 2.088293264309565

Epoch: 5| Step: 2
Training loss: 1.3646612167358398
Validation loss: 2.0878995607296624

Epoch: 5| Step: 3
Training loss: 1.578655481338501
Validation loss: 2.0667001008987427

Epoch: 5| Step: 4
Training loss: 2.670661449432373
Validation loss: 2.097169707218806

Epoch: 5| Step: 5
Training loss: 1.8980926275253296
Validation loss: 2.1102819045384726

Epoch: 5| Step: 6
Training loss: 2.4189116954803467
Validation loss: 2.1277542610963187

Epoch: 5| Step: 7
Training loss: 2.1302196979522705
Validation loss: 2.106751670440038

Epoch: 5| Step: 8
Training loss: 1.6367743015289307
Validation loss: 2.116995776693026

Epoch: 5| Step: 9
Training loss: 2.452085018157959
Validation loss: 2.068897992372513

Epoch: 5| Step: 10
Training loss: 2.196345329284668
Validation loss: 2.0717896123727164

Epoch: 5| Step: 11
Training loss: 1.40779709815979
Validation loss: 2.0859985103209815

Epoch: 29| Step: 0
Training loss: 1.7556064128875732
Validation loss: 2.0854566941658654

Epoch: 5| Step: 1
Training loss: 1.9448989629745483
Validation loss: 2.0801835556825004

Epoch: 5| Step: 2
Training loss: 1.9666742086410522
Validation loss: 2.0543382863203683

Epoch: 5| Step: 3
Training loss: 1.3633979558944702
Validation loss: 2.057522103190422

Epoch: 5| Step: 4
Training loss: 2.1946985721588135
Validation loss: 2.065620576341947

Epoch: 5| Step: 5
Training loss: 1.6948989629745483
Validation loss: 2.046870822707812

Epoch: 5| Step: 6
Training loss: 2.398545503616333
Validation loss: 2.0581722309192023

Epoch: 5| Step: 7
Training loss: 2.219797134399414
Validation loss: 2.079681227604548

Epoch: 5| Step: 8
Training loss: 1.4572410583496094
Validation loss: 2.094968428214391

Epoch: 5| Step: 9
Training loss: 2.287450075149536
Validation loss: 2.0631452053785324

Epoch: 5| Step: 10
Training loss: 2.58481502532959
Validation loss: 2.0511534611384072

Epoch: 5| Step: 11
Training loss: 1.9371223449707031
Validation loss: 2.072771484653155

Epoch: 30| Step: 0
Training loss: 1.7952392101287842
Validation loss: 2.0690022657314935

Epoch: 5| Step: 1
Training loss: 2.2789502143859863
Validation loss: 2.082727164030075

Epoch: 5| Step: 2
Training loss: 1.690787672996521
Validation loss: 2.07016259431839

Epoch: 5| Step: 3
Training loss: 1.7257206439971924
Validation loss: 2.092497304081917

Epoch: 5| Step: 4
Training loss: 2.2834370136260986
Validation loss: 2.11467311779658

Epoch: 5| Step: 5
Training loss: 2.1053829193115234
Validation loss: 2.1332996835311255

Epoch: 5| Step: 6
Training loss: 1.8294126987457275
Validation loss: 2.124053508043289

Epoch: 5| Step: 7
Training loss: 2.321295738220215
Validation loss: 2.1219988614320755

Epoch: 5| Step: 8
Training loss: 2.2467103004455566
Validation loss: 2.1309649298588433

Epoch: 5| Step: 9
Training loss: 1.8516525030136108
Validation loss: 2.0970559616883597

Epoch: 5| Step: 10
Training loss: 2.0479800701141357
Validation loss: 2.0797709921995797

Epoch: 5| Step: 11
Training loss: 1.0617926120758057
Validation loss: 2.0818535685539246

Epoch: 31| Step: 0
Training loss: 1.9364795684814453
Validation loss: 2.0855065087477365

Epoch: 5| Step: 1
Training loss: 2.154097080230713
Validation loss: 2.060240164399147

Epoch: 5| Step: 2
Training loss: 1.566748023033142
Validation loss: 2.081110512216886

Epoch: 5| Step: 3
Training loss: 1.719765305519104
Validation loss: 2.0665476272503533

Epoch: 5| Step: 4
Training loss: 2.2210350036621094
Validation loss: 2.1042893578608832

Epoch: 5| Step: 5
Training loss: 2.5855536460876465
Validation loss: 2.080748418966929

Epoch: 5| Step: 6
Training loss: 2.1761386394500732
Validation loss: 2.1127272099256516

Epoch: 5| Step: 7
Training loss: 2.032944917678833
Validation loss: 2.085177039106687

Epoch: 5| Step: 8
Training loss: 1.7672046422958374
Validation loss: 2.074993426601092

Epoch: 5| Step: 9
Training loss: 1.6332504749298096
Validation loss: 2.0790858765443168

Epoch: 5| Step: 10
Training loss: 2.412050485610962
Validation loss: 2.1000614364941916

Epoch: 5| Step: 11
Training loss: 2.8131279945373535
Validation loss: 2.091641719142596

Epoch: 32| Step: 0
Training loss: 1.6783998012542725
Validation loss: 2.0739292105038962

Epoch: 5| Step: 1
Training loss: 2.4941813945770264
Validation loss: 2.073568195104599

Epoch: 5| Step: 2
Training loss: 1.8568414449691772
Validation loss: 2.0557493368784585

Epoch: 5| Step: 3
Training loss: 1.535056710243225
Validation loss: 2.064682294925054

Epoch: 5| Step: 4
Training loss: 2.199486494064331
Validation loss: 2.089066927631696

Epoch: 5| Step: 5
Training loss: 2.196302890777588
Validation loss: 2.068217302362124

Epoch: 5| Step: 6
Training loss: 1.8458549976348877
Validation loss: 2.1106914828221

Epoch: 5| Step: 7
Training loss: 1.6184031963348389
Validation loss: 2.0817389438549676

Epoch: 5| Step: 8
Training loss: 2.7193045616149902
Validation loss: 2.0885429084300995

Epoch: 5| Step: 9
Training loss: 1.6979774236679077
Validation loss: 2.0759387562672296

Epoch: 5| Step: 10
Training loss: 2.036031723022461
Validation loss: 2.0743005573749542

Epoch: 5| Step: 11
Training loss: 2.2271668910980225
Validation loss: 2.1314840962489447

Epoch: 33| Step: 0
Training loss: 1.690953016281128
Validation loss: 2.0982412099838257

Epoch: 5| Step: 1
Training loss: 1.5677211284637451
Validation loss: 2.111521710952123

Epoch: 5| Step: 2
Training loss: 1.727977991104126
Validation loss: 2.1297619541486106

Epoch: 5| Step: 3
Training loss: 1.8480949401855469
Validation loss: 2.1314169466495514

Epoch: 5| Step: 4
Training loss: 2.397739887237549
Validation loss: 2.1393446872631707

Epoch: 5| Step: 5
Training loss: 2.1996676921844482
Validation loss: 2.1330265452464423

Epoch: 5| Step: 6
Training loss: 1.8603651523590088
Validation loss: 2.116788645585378

Epoch: 5| Step: 7
Training loss: 2.7927727699279785
Validation loss: 2.0752082963784537

Epoch: 5| Step: 8
Training loss: 2.313570737838745
Validation loss: 2.086941654483477

Epoch: 5| Step: 9
Training loss: 1.9156410694122314
Validation loss: 2.0922120014826455

Epoch: 5| Step: 10
Training loss: 2.171250104904175
Validation loss: 2.070669283469518

Epoch: 5| Step: 11
Training loss: 0.5415307283401489
Validation loss: 2.067614033818245

Epoch: 34| Step: 0
Training loss: 1.9070065021514893
Validation loss: 2.0576971968015036

Epoch: 5| Step: 1
Training loss: 2.364999294281006
Validation loss: 2.0832559019327164

Epoch: 5| Step: 2
Training loss: 1.6227489709854126
Validation loss: 2.0874383399883905

Epoch: 5| Step: 3
Training loss: 2.267207622528076
Validation loss: 2.0830358813206353

Epoch: 5| Step: 4
Training loss: 1.636770486831665
Validation loss: 2.0862008382876716

Epoch: 5| Step: 5
Training loss: 2.4874215126037598
Validation loss: 2.0799557318290076

Epoch: 5| Step: 6
Training loss: 2.5033373832702637
Validation loss: 2.0869569331407547

Epoch: 5| Step: 7
Training loss: 2.0975289344787598
Validation loss: 2.1074527502059937

Epoch: 5| Step: 8
Training loss: 2.190692901611328
Validation loss: 2.0786050260066986

Epoch: 5| Step: 9
Training loss: 1.668410062789917
Validation loss: 2.0886339098215103

Epoch: 5| Step: 10
Training loss: 1.2678661346435547
Validation loss: 2.1122502833604813

Epoch: 5| Step: 11
Training loss: 2.8357222080230713
Validation loss: 2.080598841110865

Epoch: 35| Step: 0
Training loss: 2.500243902206421
Validation loss: 2.0608976036310196

Epoch: 5| Step: 1
Training loss: 1.9336910247802734
Validation loss: 2.0721473147471747

Epoch: 5| Step: 2
Training loss: 2.2481865882873535
Validation loss: 2.086616630355517

Epoch: 5| Step: 3
Training loss: 1.5530160665512085
Validation loss: 2.0798383752504983

Epoch: 5| Step: 4
Training loss: 1.8642141819000244
Validation loss: 2.094322592020035

Epoch: 5| Step: 5
Training loss: 1.6969941854476929
Validation loss: 2.1199184457461038

Epoch: 5| Step: 6
Training loss: 1.7486522197723389
Validation loss: 2.090890804926554

Epoch: 5| Step: 7
Training loss: 1.8657677173614502
Validation loss: 2.1025631725788116

Epoch: 5| Step: 8
Training loss: 1.878080129623413
Validation loss: 2.1046528816223145

Epoch: 5| Step: 9
Training loss: 2.844914197921753
Validation loss: 2.1100196788708367

Epoch: 5| Step: 10
Training loss: 2.013967514038086
Validation loss: 2.1070390045642853

Epoch: 5| Step: 11
Training loss: 1.8502999544143677
Validation loss: 2.117359389861425

Epoch: 36| Step: 0
Training loss: 1.9810714721679688
Validation loss: 2.0992755542198815

Epoch: 5| Step: 1
Training loss: 1.9364368915557861
Validation loss: 2.092459256450335

Epoch: 5| Step: 2
Training loss: 2.1131722927093506
Validation loss: 2.0831282436847687

Epoch: 5| Step: 3
Training loss: 1.7645267248153687
Validation loss: 2.069689234097799

Epoch: 5| Step: 4
Training loss: 2.426321506500244
Validation loss: 2.0809000382820764

Epoch: 5| Step: 5
Training loss: 1.4790513515472412
Validation loss: 2.0506914208332696

Epoch: 5| Step: 6
Training loss: 2.373011589050293
Validation loss: 2.070406660437584

Epoch: 5| Step: 7
Training loss: 2.176088571548462
Validation loss: 2.070260008176168

Epoch: 5| Step: 8
Training loss: 2.1771881580352783
Validation loss: 2.058726335565249

Epoch: 5| Step: 9
Training loss: 1.880875587463379
Validation loss: 2.0714541574319205

Epoch: 5| Step: 10
Training loss: 1.835314154624939
Validation loss: 2.0505522241195044

Epoch: 5| Step: 11
Training loss: 1.3798221349716187
Validation loss: 2.0492416322231293

Epoch: 37| Step: 0
Training loss: 2.260221481323242
Validation loss: 2.0803631047407785

Epoch: 5| Step: 1
Training loss: 2.2316551208496094
Validation loss: 2.0630002369483313

Epoch: 5| Step: 2
Training loss: 1.8816581964492798
Validation loss: 2.0841591159502664

Epoch: 5| Step: 3
Training loss: 1.7890697717666626
Validation loss: 2.1179139812787375

Epoch: 5| Step: 4
Training loss: 1.8294795751571655
Validation loss: 2.0672989885012307

Epoch: 5| Step: 5
Training loss: 2.791018009185791
Validation loss: 2.076349357763926

Epoch: 5| Step: 6
Training loss: 1.8881711959838867
Validation loss: 2.098117619752884

Epoch: 5| Step: 7
Training loss: 1.656243085861206
Validation loss: 2.068839371204376

Epoch: 5| Step: 8
Training loss: 2.009397029876709
Validation loss: 2.053889890511831

Epoch: 5| Step: 9
Training loss: 1.9624388217926025
Validation loss: 2.072154020269712

Epoch: 5| Step: 10
Training loss: 1.6654735803604126
Validation loss: 2.0646034677823386

Epoch: 5| Step: 11
Training loss: 2.25032377243042
Validation loss: 2.065900286038717

Epoch: 38| Step: 0
Training loss: 2.4916062355041504
Validation loss: 2.046480745077133

Epoch: 5| Step: 1
Training loss: 2.041992664337158
Validation loss: 2.088544189929962

Epoch: 5| Step: 2
Training loss: 1.9591610431671143
Validation loss: 2.067472125093142

Epoch: 5| Step: 3
Training loss: 2.2958014011383057
Validation loss: 2.0775080819924674

Epoch: 5| Step: 4
Training loss: 2.1701102256774902
Validation loss: 2.082039932409922

Epoch: 5| Step: 5
Training loss: 1.1907727718353271
Validation loss: 2.081684783101082

Epoch: 5| Step: 6
Training loss: 2.4163665771484375
Validation loss: 2.058934340874354

Epoch: 5| Step: 7
Training loss: 1.7483829259872437
Validation loss: 2.063101202249527

Epoch: 5| Step: 8
Training loss: 1.63027024269104
Validation loss: 2.067281410098076

Epoch: 5| Step: 9
Training loss: 2.325295925140381
Validation loss: 2.064248025417328

Epoch: 5| Step: 10
Training loss: 1.8425556421279907
Validation loss: 2.1076415131489434

Epoch: 5| Step: 11
Training loss: 1.8383842706680298
Validation loss: 2.0353348751862845

Epoch: 39| Step: 0
Training loss: 1.5952845811843872
Validation loss: 2.03974682589372

Epoch: 5| Step: 1
Training loss: 1.8062913417816162
Validation loss: 2.0650862604379654

Epoch: 5| Step: 2
Training loss: 1.457242727279663
Validation loss: 2.0585112124681473

Epoch: 5| Step: 3
Training loss: 1.9489381313323975
Validation loss: 2.0386607199907303

Epoch: 5| Step: 4
Training loss: 2.351903200149536
Validation loss: 2.064520259698232

Epoch: 5| Step: 5
Training loss: 2.296722888946533
Validation loss: 2.0625949452320733

Epoch: 5| Step: 6
Training loss: 2.1091461181640625
Validation loss: 2.027278944849968

Epoch: 5| Step: 7
Training loss: 1.530264139175415
Validation loss: 2.0795821199814477

Epoch: 5| Step: 8
Training loss: 2.111103057861328
Validation loss: 2.061501463254293

Epoch: 5| Step: 9
Training loss: 2.174973964691162
Validation loss: 2.0565894693136215

Epoch: 5| Step: 10
Training loss: 2.17999529838562
Validation loss: 2.061705226699511

Epoch: 5| Step: 11
Training loss: 2.573453903198242
Validation loss: 2.054320121804873

Epoch: 40| Step: 0
Training loss: 1.5629560947418213
Validation loss: 2.065130348006884

Epoch: 5| Step: 1
Training loss: 1.5984357595443726
Validation loss: 2.033299759030342

Epoch: 5| Step: 2
Training loss: 2.4664273262023926
Validation loss: 2.048067182302475

Epoch: 5| Step: 3
Training loss: 1.9864089488983154
Validation loss: 2.0558012425899506

Epoch: 5| Step: 4
Training loss: 1.8955646753311157
Validation loss: 2.0577877163887024

Epoch: 5| Step: 5
Training loss: 1.6874618530273438
Validation loss: 2.0465213507413864

Epoch: 5| Step: 6
Training loss: 2.11741304397583
Validation loss: 2.0595021645228067

Epoch: 5| Step: 7
Training loss: 1.7521982192993164
Validation loss: 2.054737110932668

Epoch: 5| Step: 8
Training loss: 2.570178270339966
Validation loss: 2.0497653484344482

Epoch: 5| Step: 9
Training loss: 2.298475980758667
Validation loss: 2.0429352720578513

Epoch: 5| Step: 10
Training loss: 1.8292300701141357
Validation loss: 2.0631090303262076

Epoch: 5| Step: 11
Training loss: 1.4936999082565308
Validation loss: 2.07228713730971

Epoch: 41| Step: 0
Training loss: 1.6652631759643555
Validation loss: 2.066367819905281

Epoch: 5| Step: 1
Training loss: 2.2829201221466064
Validation loss: 2.0728568583726883

Epoch: 5| Step: 2
Training loss: 1.7853546142578125
Validation loss: 2.077681844433149

Epoch: 5| Step: 3
Training loss: 1.7649329900741577
Validation loss: 2.106067106127739

Epoch: 5| Step: 4
Training loss: 2.028449773788452
Validation loss: 2.0791616489489875

Epoch: 5| Step: 5
Training loss: 1.7545835971832275
Validation loss: 2.0779958417018256

Epoch: 5| Step: 6
Training loss: 1.9394428730010986
Validation loss: 2.107541302839915

Epoch: 5| Step: 7
Training loss: 2.1882553100585938
Validation loss: 2.063866843779882

Epoch: 5| Step: 8
Training loss: 2.185303211212158
Validation loss: 2.0841901898384094

Epoch: 5| Step: 9
Training loss: 2.6410462856292725
Validation loss: 2.0894293040037155

Epoch: 5| Step: 10
Training loss: 1.667005181312561
Validation loss: 2.092604771256447

Epoch: 5| Step: 11
Training loss: 2.628754138946533
Validation loss: 2.09215339521567

Epoch: 42| Step: 0
Training loss: 1.5918982028961182
Validation loss: 2.076899473865827

Epoch: 5| Step: 1
Training loss: 2.0130133628845215
Validation loss: 2.0510084430376687

Epoch: 5| Step: 2
Training loss: 2.0778939723968506
Validation loss: 2.0793382128079734

Epoch: 5| Step: 3
Training loss: 2.0698399543762207
Validation loss: 2.077451984087626

Epoch: 5| Step: 4
Training loss: 2.345034122467041
Validation loss: 2.0623459865649543

Epoch: 5| Step: 5
Training loss: 1.6671030521392822
Validation loss: 2.0587010929981866

Epoch: 5| Step: 6
Training loss: 1.8828754425048828
Validation loss: 2.0444611658652625

Epoch: 5| Step: 7
Training loss: 1.5669101476669312
Validation loss: 2.0940105468034744

Epoch: 5| Step: 8
Training loss: 2.2747180461883545
Validation loss: 2.053877746065458

Epoch: 5| Step: 9
Training loss: 2.5902087688446045
Validation loss: 2.081224168340365

Epoch: 5| Step: 10
Training loss: 1.6214187145233154
Validation loss: 2.068947494029999

Epoch: 5| Step: 11
Training loss: 2.474759817123413
Validation loss: 2.0729630887508392

Epoch: 43| Step: 0
Training loss: 1.6330913305282593
Validation loss: 2.089721361796061

Epoch: 5| Step: 1
Training loss: 1.8016372919082642
Validation loss: 2.0690722117821374

Epoch: 5| Step: 2
Training loss: 1.3088496923446655
Validation loss: 2.045584663748741

Epoch: 5| Step: 3
Training loss: 2.4962046146392822
Validation loss: 2.0590736170609794

Epoch: 5| Step: 4
Training loss: 1.8652398586273193
Validation loss: 2.051510567466418

Epoch: 5| Step: 5
Training loss: 1.8041560649871826
Validation loss: 2.0604799588521323

Epoch: 5| Step: 6
Training loss: 1.8802576065063477
Validation loss: 2.0581330905357995

Epoch: 5| Step: 7
Training loss: 2.012078046798706
Validation loss: 2.08630433678627

Epoch: 5| Step: 8
Training loss: 1.7575299739837646
Validation loss: 2.0574984351793923

Epoch: 5| Step: 9
Training loss: 2.472573757171631
Validation loss: 2.073605472842852

Epoch: 5| Step: 10
Training loss: 2.4201834201812744
Validation loss: 2.096860150496165

Epoch: 5| Step: 11
Training loss: 2.3823869228363037
Validation loss: 2.0762831966082254

Epoch: 44| Step: 0
Training loss: 1.422212839126587
Validation loss: 2.07160085439682

Epoch: 5| Step: 1
Training loss: 2.2005209922790527
Validation loss: 2.07798403998216

Epoch: 5| Step: 2
Training loss: 2.0498385429382324
Validation loss: 2.0816506346066794

Epoch: 5| Step: 3
Training loss: 1.4388139247894287
Validation loss: 2.089329565564791

Epoch: 5| Step: 4
Training loss: 2.0999484062194824
Validation loss: 2.076637143890063

Epoch: 5| Step: 5
Training loss: 1.6948978900909424
Validation loss: 2.0984459718068442

Epoch: 5| Step: 6
Training loss: 2.346364736557007
Validation loss: 2.0913516680399575

Epoch: 5| Step: 7
Training loss: 1.9416773319244385
Validation loss: 2.0771988530953727

Epoch: 5| Step: 8
Training loss: 1.9896001815795898
Validation loss: 2.1019620100657144

Epoch: 5| Step: 9
Training loss: 2.638340473175049
Validation loss: 2.0684566497802734

Epoch: 5| Step: 10
Training loss: 2.0127968788146973
Validation loss: 2.0747693479061127

Epoch: 5| Step: 11
Training loss: 1.1604516506195068
Validation loss: 2.066922883192698

Epoch: 45| Step: 0
Training loss: 1.864140272140503
Validation loss: 2.0348775535821915

Epoch: 5| Step: 1
Training loss: 2.481781482696533
Validation loss: 2.047035520275434

Epoch: 5| Step: 2
Training loss: 1.4106476306915283
Validation loss: 2.0492461174726486

Epoch: 5| Step: 3
Training loss: 1.982643485069275
Validation loss: 2.078301563858986

Epoch: 5| Step: 4
Training loss: 2.480276346206665
Validation loss: 2.066060319542885

Epoch: 5| Step: 5
Training loss: 1.8027044534683228
Validation loss: 2.0564320385456085

Epoch: 5| Step: 6
Training loss: 2.339479446411133
Validation loss: 2.076974853873253

Epoch: 5| Step: 7
Training loss: 1.3430100679397583
Validation loss: 2.090843061606089

Epoch: 5| Step: 8
Training loss: 1.9893569946289062
Validation loss: 2.0353020429611206

Epoch: 5| Step: 9
Training loss: 1.6709007024765015
Validation loss: 2.072001655896505

Epoch: 5| Step: 10
Training loss: 1.78883957862854
Validation loss: 2.0770126581192017

Epoch: 5| Step: 11
Training loss: 3.4591574668884277
Validation loss: 2.0881592631340027

Epoch: 46| Step: 0
Training loss: 2.463520050048828
Validation loss: 2.0748371481895447

Epoch: 5| Step: 1
Training loss: 2.241657257080078
Validation loss: 2.059981028238932

Epoch: 5| Step: 2
Training loss: 2.078723907470703
Validation loss: 2.0617113759120307

Epoch: 5| Step: 3
Training loss: 1.679990530014038
Validation loss: 2.055739934245745

Epoch: 5| Step: 4
Training loss: 2.104511260986328
Validation loss: 2.055071453253428

Epoch: 5| Step: 5
Training loss: 1.8037563562393188
Validation loss: 2.059771110614141

Epoch: 5| Step: 6
Training loss: 1.9355071783065796
Validation loss: 2.0919780085484185

Epoch: 5| Step: 7
Training loss: 2.794975519180298
Validation loss: 2.064828097820282

Epoch: 5| Step: 8
Training loss: 1.5552635192871094
Validation loss: 2.0614042033751807

Epoch: 5| Step: 9
Training loss: 1.3784196376800537
Validation loss: 2.0626812477906546

Epoch: 5| Step: 10
Training loss: 2.075321674346924
Validation loss: 2.0870893001556396

Epoch: 5| Step: 11
Training loss: 2.0583574771881104
Validation loss: 2.0276664594809213

Epoch: 47| Step: 0
Training loss: 2.0070652961730957
Validation loss: 2.0679839750130973

Epoch: 5| Step: 1
Training loss: 2.2516262531280518
Validation loss: 2.0835362374782562

Epoch: 5| Step: 2
Training loss: 2.0058939456939697
Validation loss: 2.0716703037420907

Epoch: 5| Step: 3
Training loss: 2.243903636932373
Validation loss: 2.077537397543589

Epoch: 5| Step: 4
Training loss: 1.9484474658966064
Validation loss: 2.0560682117938995

Epoch: 5| Step: 5
Training loss: 1.6038627624511719
Validation loss: 2.0557505389054618

Epoch: 5| Step: 6
Training loss: 1.551216721534729
Validation loss: 2.0641371806462607

Epoch: 5| Step: 7
Training loss: 2.351505756378174
Validation loss: 2.0774822682142258

Epoch: 5| Step: 8
Training loss: 1.7396560907363892
Validation loss: 2.0616493870814643

Epoch: 5| Step: 9
Training loss: 2.4694936275482178
Validation loss: 2.0591360181570053

Epoch: 5| Step: 10
Training loss: 1.4629662036895752
Validation loss: 2.095598811904589

Epoch: 5| Step: 11
Training loss: 1.5398094654083252
Validation loss: 2.0894081940253577

Epoch: 48| Step: 0
Training loss: 1.883784294128418
Validation loss: 2.1086507936318717

Epoch: 5| Step: 1
Training loss: 1.8518234491348267
Validation loss: 2.096814294656118

Epoch: 5| Step: 2
Training loss: 2.139857530593872
Validation loss: 2.1163813322782516

Epoch: 5| Step: 3
Training loss: 1.9260413646697998
Validation loss: 2.0886653810739517

Epoch: 5| Step: 4
Training loss: 2.1115713119506836
Validation loss: 2.1443504790465036

Epoch: 5| Step: 5
Training loss: 1.9562718868255615
Validation loss: 2.1504150281349816

Epoch: 5| Step: 6
Training loss: 2.232897996902466
Validation loss: 2.1633214553197226

Epoch: 5| Step: 7
Training loss: 2.0664191246032715
Validation loss: 2.1305160025755563

Epoch: 5| Step: 8
Training loss: 2.275564670562744
Validation loss: 2.0772068351507187

Epoch: 5| Step: 9
Training loss: 1.7964683771133423
Validation loss: 2.078446383277575

Epoch: 5| Step: 10
Training loss: 1.8743927478790283
Validation loss: 2.073892811934153

Epoch: 5| Step: 11
Training loss: 1.048917293548584
Validation loss: 2.06894684334596

Epoch: 49| Step: 0
Training loss: 2.430011749267578
Validation loss: 2.066966404517492

Epoch: 5| Step: 1
Training loss: 2.5432827472686768
Validation loss: 2.072346309820811

Epoch: 5| Step: 2
Training loss: 1.7760320901870728
Validation loss: 2.0852439304192862

Epoch: 5| Step: 3
Training loss: 1.7812143564224243
Validation loss: 2.071830615401268

Epoch: 5| Step: 4
Training loss: 1.8336702585220337
Validation loss: 2.075055812795957

Epoch: 5| Step: 5
Training loss: 1.8267333507537842
Validation loss: 2.0639229913552604

Epoch: 5| Step: 6
Training loss: 1.7280080318450928
Validation loss: 2.0519692103068032

Epoch: 5| Step: 7
Training loss: 1.6179554462432861
Validation loss: 2.069054772456487

Epoch: 5| Step: 8
Training loss: 2.1528778076171875
Validation loss: 2.064470519622167

Epoch: 5| Step: 9
Training loss: 1.9731521606445312
Validation loss: 2.0836534202098846

Epoch: 5| Step: 10
Training loss: 1.7542393207550049
Validation loss: 2.04942420621713

Epoch: 5| Step: 11
Training loss: 3.522904872894287
Validation loss: 2.0743877589702606

Epoch: 50| Step: 0
Training loss: 2.4572224617004395
Validation loss: 2.0559293776750565

Epoch: 5| Step: 1
Training loss: 1.658047080039978
Validation loss: 2.0889107088247933

Epoch: 5| Step: 2
Training loss: 1.9456660747528076
Validation loss: 2.0650722781817117

Epoch: 5| Step: 3
Training loss: 1.8550584316253662
Validation loss: 2.0869340300559998

Epoch: 5| Step: 4
Training loss: 1.971880316734314
Validation loss: 2.070138782262802

Epoch: 5| Step: 5
Training loss: 1.9850209951400757
Validation loss: 2.0581271002689996

Epoch: 5| Step: 6
Training loss: 1.5193400382995605
Validation loss: 2.032504285375277

Epoch: 5| Step: 7
Training loss: 2.0327706336975098
Validation loss: 2.0868195593357086

Epoch: 5| Step: 8
Training loss: 1.6389119625091553
Validation loss: 2.1153800090154014

Epoch: 5| Step: 9
Training loss: 2.601308822631836
Validation loss: 2.0899518777926764

Epoch: 5| Step: 10
Training loss: 2.191242218017578
Validation loss: 2.066286563873291

Epoch: 5| Step: 11
Training loss: 1.3514976501464844
Validation loss: 2.0795415739218392

Epoch: 51| Step: 0
Training loss: 1.7088901996612549
Validation loss: 2.0817072987556458

Epoch: 5| Step: 1
Training loss: 1.376105546951294
Validation loss: 2.081898162762324

Epoch: 5| Step: 2
Training loss: 2.3746120929718018
Validation loss: 2.0503629545370736

Epoch: 5| Step: 3
Training loss: 1.7581655979156494
Validation loss: 2.076211671034495

Epoch: 5| Step: 4
Training loss: 1.768967628479004
Validation loss: 2.0515032907327018

Epoch: 5| Step: 5
Training loss: 2.417595386505127
Validation loss: 2.0923949082692466

Epoch: 5| Step: 6
Training loss: 2.0953543186187744
Validation loss: 2.04458216826121

Epoch: 5| Step: 7
Training loss: 1.7502708435058594
Validation loss: 2.0638071099917092

Epoch: 5| Step: 8
Training loss: 2.24088716506958
Validation loss: 2.0711572716633477

Epoch: 5| Step: 9
Training loss: 2.227419376373291
Validation loss: 2.064929629365603

Epoch: 5| Step: 10
Training loss: 1.76277756690979
Validation loss: 2.084327811996142

Epoch: 5| Step: 11
Training loss: 1.9764857292175293
Validation loss: 2.0677456110715866

Epoch: 52| Step: 0
Training loss: 2.030715227127075
Validation loss: 2.072257017095884

Epoch: 5| Step: 1
Training loss: 2.129265308380127
Validation loss: 2.0890007267395654

Epoch: 5| Step: 2
Training loss: 1.536696195602417
Validation loss: 2.074541096885999

Epoch: 5| Step: 3
Training loss: 2.0707337856292725
Validation loss: 2.074347823858261

Epoch: 5| Step: 4
Training loss: 2.1461470127105713
Validation loss: 2.060703376928965

Epoch: 5| Step: 5
Training loss: 1.6682897806167603
Validation loss: 2.063718398412069

Epoch: 5| Step: 6
Training loss: 1.7658474445343018
Validation loss: 2.0838164488474527

Epoch: 5| Step: 7
Training loss: 1.9137065410614014
Validation loss: 2.0848960826794305

Epoch: 5| Step: 8
Training loss: 1.8104263544082642
Validation loss: 2.1065196295579276

Epoch: 5| Step: 9
Training loss: 2.311361789703369
Validation loss: 2.080982724825541

Epoch: 5| Step: 10
Training loss: 2.092331886291504
Validation loss: 2.0868103951215744

Epoch: 5| Step: 11
Training loss: 1.6145925521850586
Validation loss: 2.095993017156919

Epoch: 53| Step: 0
Training loss: 2.188812494277954
Validation loss: 2.0957893977562585

Epoch: 5| Step: 1
Training loss: 1.7038847208023071
Validation loss: 2.071114639441172

Epoch: 5| Step: 2
Training loss: 1.5908688306808472
Validation loss: 2.0874638011058173

Epoch: 5| Step: 3
Training loss: 1.7824430465698242
Validation loss: 2.0508546928564706

Epoch: 5| Step: 4
Training loss: 1.8603923320770264
Validation loss: 2.100372463464737

Epoch: 5| Step: 5
Training loss: 1.8544009923934937
Validation loss: 2.0836614022652307

Epoch: 5| Step: 6
Training loss: 1.727358102798462
Validation loss: 2.1056831975777945

Epoch: 5| Step: 7
Training loss: 1.988189697265625
Validation loss: 2.0589901208877563

Epoch: 5| Step: 8
Training loss: 2.6368298530578613
Validation loss: 2.0595942387978234

Epoch: 5| Step: 9
Training loss: 1.7333940267562866
Validation loss: 2.034596492846807

Epoch: 5| Step: 10
Training loss: 2.415996789932251
Validation loss: 2.073692634701729

Epoch: 5| Step: 11
Training loss: 1.1028339862823486
Validation loss: 2.0471104880174003

Epoch: 54| Step: 0
Training loss: 1.9602292776107788
Validation loss: 2.0604378134012222

Epoch: 5| Step: 1
Training loss: 2.164956569671631
Validation loss: 2.0499629775683084

Epoch: 5| Step: 2
Training loss: 1.7735055685043335
Validation loss: 2.046201998988787

Epoch: 5| Step: 3
Training loss: 1.6356290578842163
Validation loss: 2.0744746377070746

Epoch: 5| Step: 4
Training loss: 1.9655640125274658
Validation loss: 2.064531539877256

Epoch: 5| Step: 5
Training loss: 2.3455023765563965
Validation loss: 2.028278668721517

Epoch: 5| Step: 6
Training loss: 2.509742259979248
Validation loss: 2.0326560586690903

Epoch: 5| Step: 7
Training loss: 2.014678478240967
Validation loss: 2.0391483306884766

Epoch: 5| Step: 8
Training loss: 1.3269351720809937
Validation loss: 2.0486344496409097

Epoch: 5| Step: 9
Training loss: 1.85637629032135
Validation loss: 2.066941430171331

Epoch: 5| Step: 10
Training loss: 1.8754863739013672
Validation loss: 2.0643469790617623

Epoch: 5| Step: 11
Training loss: 2.545132637023926
Validation loss: 2.0571100960175195

Epoch: 55| Step: 0
Training loss: 1.9981155395507812
Validation loss: 2.0935677935679755

Epoch: 5| Step: 1
Training loss: 1.8559329509735107
Validation loss: 2.036293854316076

Epoch: 5| Step: 2
Training loss: 2.522538661956787
Validation loss: 2.0520139336586

Epoch: 5| Step: 3
Training loss: 1.8712444305419922
Validation loss: 2.0639070173104606

Epoch: 5| Step: 4
Training loss: 2.0937817096710205
Validation loss: 2.0836307952801385

Epoch: 5| Step: 5
Training loss: 2.057150363922119
Validation loss: 2.0635631630818048

Epoch: 5| Step: 6
Training loss: 2.431709051132202
Validation loss: 2.0553250908851624

Epoch: 5| Step: 7
Training loss: 1.4812618494033813
Validation loss: 2.0685336540142694

Epoch: 5| Step: 8
Training loss: 1.7485504150390625
Validation loss: 2.0547505219777427

Epoch: 5| Step: 9
Training loss: 1.928015947341919
Validation loss: 2.070677101612091

Epoch: 5| Step: 10
Training loss: 1.519478440284729
Validation loss: 2.0910977770884833

Epoch: 5| Step: 11
Training loss: 1.3156994581222534
Validation loss: 2.1044048418601355

Epoch: 56| Step: 0
Training loss: 2.077843189239502
Validation loss: 2.1264459987481437

Epoch: 5| Step: 1
Training loss: 2.236774206161499
Validation loss: 2.1274684170881906

Epoch: 5| Step: 2
Training loss: 1.5562278032302856
Validation loss: 2.1446749617656073

Epoch: 5| Step: 3
Training loss: 2.5505013465881348
Validation loss: 2.1477851370970407

Epoch: 5| Step: 4
Training loss: 2.1525866985321045
Validation loss: 2.113589103023211

Epoch: 5| Step: 5
Training loss: 2.466229200363159
Validation loss: 2.119044234355291

Epoch: 5| Step: 6
Training loss: 1.2738783359527588
Validation loss: 2.0802434285481772

Epoch: 5| Step: 7
Training loss: 1.3562276363372803
Validation loss: 2.088270351290703

Epoch: 5| Step: 8
Training loss: 2.604897975921631
Validation loss: 2.0941702922185264

Epoch: 5| Step: 9
Training loss: 1.859788179397583
Validation loss: 2.0761728982130685

Epoch: 5| Step: 10
Training loss: 1.8001779317855835
Validation loss: 2.0588427086671195

Epoch: 5| Step: 11
Training loss: 0.9032166004180908
Validation loss: 2.0523683031400046

Epoch: 57| Step: 0
Training loss: 2.5279698371887207
Validation loss: 2.0738358994325004

Epoch: 5| Step: 1
Training loss: 1.7417665719985962
Validation loss: 2.064465746283531

Epoch: 5| Step: 2
Training loss: 2.0392470359802246
Validation loss: 2.1065721263488135

Epoch: 5| Step: 3
Training loss: 2.0668537616729736
Validation loss: 2.062218740582466

Epoch: 5| Step: 4
Training loss: 1.6676340103149414
Validation loss: 2.0712753981351852

Epoch: 5| Step: 5
Training loss: 2.1691513061523438
Validation loss: 2.060986985762914

Epoch: 5| Step: 6
Training loss: 1.7864993810653687
Validation loss: 2.0370933214823403

Epoch: 5| Step: 7
Training loss: 1.562549114227295
Validation loss: 2.0809824963410697

Epoch: 5| Step: 8
Training loss: 2.0553083419799805
Validation loss: 2.053102577726046

Epoch: 5| Step: 9
Training loss: 1.8085237741470337
Validation loss: 2.086575056115786

Epoch: 5| Step: 10
Training loss: 1.9809057712554932
Validation loss: 2.0827234089374542

Epoch: 5| Step: 11
Training loss: 2.067797899246216
Validation loss: 2.102678954601288

Epoch: 58| Step: 0
Training loss: 1.3705335855484009
Validation loss: 2.0683128337065377

Epoch: 5| Step: 1
Training loss: 2.663923978805542
Validation loss: 2.0425413648287454

Epoch: 5| Step: 2
Training loss: 1.7863279581069946
Validation loss: 2.0910978416601815

Epoch: 5| Step: 3
Training loss: 1.7070986032485962
Validation loss: 2.0783595740795135

Epoch: 5| Step: 4
Training loss: 2.157984495162964
Validation loss: 2.0586646596590676

Epoch: 5| Step: 5
Training loss: 1.943671464920044
Validation loss: 2.075358957052231

Epoch: 5| Step: 6
Training loss: 2.472557544708252
Validation loss: 2.0755487779776254

Epoch: 5| Step: 7
Training loss: 2.160065174102783
Validation loss: 2.0677699893712997

Epoch: 5| Step: 8
Training loss: 1.2431702613830566
Validation loss: 2.080573091904322

Epoch: 5| Step: 9
Training loss: 1.8948653936386108
Validation loss: 2.069127917289734

Epoch: 5| Step: 10
Training loss: 2.070371389389038
Validation loss: 2.0761500050624213

Epoch: 5| Step: 11
Training loss: 1.660045862197876
Validation loss: 2.0342884461085

Epoch: 59| Step: 0
Training loss: 2.4273462295532227
Validation loss: 2.043167074521383

Epoch: 5| Step: 1
Training loss: 1.7067102193832397
Validation loss: 2.0400079439083734

Epoch: 5| Step: 2
Training loss: 1.6947240829467773
Validation loss: 2.0508839984734855

Epoch: 5| Step: 3
Training loss: 1.5836427211761475
Validation loss: 2.0448857049147287

Epoch: 5| Step: 4
Training loss: 1.5872116088867188
Validation loss: 2.065921907623609

Epoch: 5| Step: 5
Training loss: 2.025381565093994
Validation loss: 2.063264732559522

Epoch: 5| Step: 6
Training loss: 2.6302831172943115
Validation loss: 2.0836062133312225

Epoch: 5| Step: 7
Training loss: 2.3609249591827393
Validation loss: 2.0889594703912735

Epoch: 5| Step: 8
Training loss: 1.5752456188201904
Validation loss: 2.0864056597153344

Epoch: 5| Step: 9
Training loss: 2.1028201580047607
Validation loss: 2.099925175309181

Epoch: 5| Step: 10
Training loss: 1.9337208271026611
Validation loss: 2.07299475868543

Epoch: 5| Step: 11
Training loss: 0.8586349487304688
Validation loss: 2.0544990052779517

Epoch: 60| Step: 0
Training loss: 2.287360668182373
Validation loss: 2.071841314435005

Epoch: 5| Step: 1
Training loss: 1.824664831161499
Validation loss: 2.048894206682841

Epoch: 5| Step: 2
Training loss: 1.8274379968643188
Validation loss: 2.047081470489502

Epoch: 5| Step: 3
Training loss: 2.277557849884033
Validation loss: 2.0723378310600915

Epoch: 5| Step: 4
Training loss: 1.786303162574768
Validation loss: 2.061886598666509

Epoch: 5| Step: 5
Training loss: 1.8661582469940186
Validation loss: 2.07187083363533

Epoch: 5| Step: 6
Training loss: 2.1656575202941895
Validation loss: 2.059493839740753

Epoch: 5| Step: 7
Training loss: 1.877868413925171
Validation loss: 2.0352108776569366

Epoch: 5| Step: 8
Training loss: 1.9772498607635498
Validation loss: 2.067738691965739

Epoch: 5| Step: 9
Training loss: 2.0269317626953125
Validation loss: 2.045504262049993

Epoch: 5| Step: 10
Training loss: 1.5569099187850952
Validation loss: 2.057205617427826

Epoch: 5| Step: 11
Training loss: 1.0387855768203735
Validation loss: 2.066639890273412

Epoch: 61| Step: 0
Training loss: 2.21270489692688
Validation loss: 2.094507093230883

Epoch: 5| Step: 1
Training loss: 2.02813458442688
Validation loss: 2.07283986111482

Epoch: 5| Step: 2
Training loss: 1.985883355140686
Validation loss: 2.0603516002496085

Epoch: 5| Step: 3
Training loss: 1.8622782230377197
Validation loss: 2.0748130629460015

Epoch: 5| Step: 4
Training loss: 2.1120893955230713
Validation loss: 2.100504199663798

Epoch: 5| Step: 5
Training loss: 1.7947708368301392
Validation loss: 2.1074936042229333

Epoch: 5| Step: 6
Training loss: 2.150869846343994
Validation loss: 2.125901366273562

Epoch: 5| Step: 7
Training loss: 2.4612350463867188
Validation loss: 2.1317819158236184

Epoch: 5| Step: 8
Training loss: 1.5562471151351929
Validation loss: 2.083198830485344

Epoch: 5| Step: 9
Training loss: 1.9592050313949585
Validation loss: 2.09941195944945

Epoch: 5| Step: 10
Training loss: 1.3876010179519653
Validation loss: 2.1168706864118576

Epoch: 5| Step: 11
Training loss: 2.197300910949707
Validation loss: 2.075996453563372

Epoch: 62| Step: 0
Training loss: 2.241504430770874
Validation loss: 2.1184231688578925

Epoch: 5| Step: 1
Training loss: 2.2457528114318848
Validation loss: 2.0597591400146484

Epoch: 5| Step: 2
Training loss: 1.7941335439682007
Validation loss: 2.050598586599032

Epoch: 5| Step: 3
Training loss: 1.8746364116668701
Validation loss: 2.063968002796173

Epoch: 5| Step: 4
Training loss: 2.1863863468170166
Validation loss: 2.1008674651384354

Epoch: 5| Step: 5
Training loss: 1.688159704208374
Validation loss: 2.0635741353034973

Epoch: 5| Step: 6
Training loss: 2.1748111248016357
Validation loss: 2.093495080868403

Epoch: 5| Step: 7
Training loss: 1.3103392124176025
Validation loss: 2.0640234500169754

Epoch: 5| Step: 8
Training loss: 2.2990243434906006
Validation loss: 2.0888686825831733

Epoch: 5| Step: 9
Training loss: 1.5189049243927002
Validation loss: 2.0681933661301932

Epoch: 5| Step: 10
Training loss: 1.7582460641860962
Validation loss: 2.050992394487063

Epoch: 5| Step: 11
Training loss: 2.72216796875
Validation loss: 2.061101714769999

Epoch: 63| Step: 0
Training loss: 1.955815076828003
Validation loss: 2.053453932205836

Epoch: 5| Step: 1
Training loss: 1.8393688201904297
Validation loss: 2.0603992442289987

Epoch: 5| Step: 2
Training loss: 1.711424469947815
Validation loss: 2.076803594827652

Epoch: 5| Step: 3
Training loss: 1.893115758895874
Validation loss: 2.092493216196696

Epoch: 5| Step: 4
Training loss: 1.3409030437469482
Validation loss: 2.0647935271263123

Epoch: 5| Step: 5
Training loss: 2.1118462085723877
Validation loss: 2.0389288316170373

Epoch: 5| Step: 6
Training loss: 1.8104196786880493
Validation loss: 2.076037655274073

Epoch: 5| Step: 7
Training loss: 2.0865373611450195
Validation loss: 2.0446255803108215

Epoch: 5| Step: 8
Training loss: 1.8580787181854248
Validation loss: 2.074182947476705

Epoch: 5| Step: 9
Training loss: 2.160182237625122
Validation loss: 2.039942925175031

Epoch: 5| Step: 10
Training loss: 1.987857460975647
Validation loss: 2.0576953291893005

Epoch: 5| Step: 11
Training loss: 3.9596939086914062
Validation loss: 2.063760722676913

Epoch: 64| Step: 0
Training loss: 2.0808956623077393
Validation loss: 2.048750321070353

Epoch: 5| Step: 1
Training loss: 1.6990540027618408
Validation loss: 2.0649481117725372

Epoch: 5| Step: 2
Training loss: 1.8653602600097656
Validation loss: 2.0706440955400467

Epoch: 5| Step: 3
Training loss: 2.250972032546997
Validation loss: 2.089630867044131

Epoch: 5| Step: 4
Training loss: 1.754690408706665
Validation loss: 2.0774986942609153

Epoch: 5| Step: 5
Training loss: 1.7026698589324951
Validation loss: 2.090719978014628

Epoch: 5| Step: 6
Training loss: 1.8092867136001587
Validation loss: 2.079954355955124

Epoch: 5| Step: 7
Training loss: 2.4412834644317627
Validation loss: 2.1247672935326896

Epoch: 5| Step: 8
Training loss: 2.2911481857299805
Validation loss: 2.0771043449640274

Epoch: 5| Step: 9
Training loss: 1.323859453201294
Validation loss: 2.077439477046331

Epoch: 5| Step: 10
Training loss: 2.238039493560791
Validation loss: 2.0650022526582084

Epoch: 5| Step: 11
Training loss: 1.0813353061676025
Validation loss: 2.0989036510388055

Epoch: 65| Step: 0
Training loss: 1.5209124088287354
Validation loss: 2.0880130330721536

Epoch: 5| Step: 1
Training loss: 1.6364030838012695
Validation loss: 2.078642110029856

Epoch: 5| Step: 2
Training loss: 2.102041721343994
Validation loss: 2.0574938158194223

Epoch: 5| Step: 3
Training loss: 2.3392844200134277
Validation loss: 2.0475486367940903

Epoch: 5| Step: 4
Training loss: 1.9042984247207642
Validation loss: 2.0753221064805984

Epoch: 5| Step: 5
Training loss: 1.9420547485351562
Validation loss: 2.053240974744161

Epoch: 5| Step: 6
Training loss: 2.0378220081329346
Validation loss: 2.055118570725123

Epoch: 5| Step: 7
Training loss: 2.5024709701538086
Validation loss: 2.0794825504223504

Epoch: 5| Step: 8
Training loss: 1.544377326965332
Validation loss: 2.0594962487618127

Epoch: 5| Step: 9
Training loss: 1.6898438930511475
Validation loss: 2.048106223344803

Epoch: 5| Step: 10
Training loss: 2.254380226135254
Validation loss: 2.020143767197927

Epoch: 5| Step: 11
Training loss: 0.9755113124847412
Validation loss: 2.067447528243065

Epoch: 66| Step: 0
Training loss: 2.4964466094970703
Validation loss: 2.07942695915699

Epoch: 5| Step: 1
Training loss: 2.4472270011901855
Validation loss: 2.0858761221170425

Epoch: 5| Step: 2
Training loss: 1.6971368789672852
Validation loss: 2.097382888197899

Epoch: 5| Step: 3
Training loss: 1.1760860681533813
Validation loss: 2.0695339938004813

Epoch: 5| Step: 4
Training loss: 2.2000374794006348
Validation loss: 2.075318937500318

Epoch: 5| Step: 5
Training loss: 1.7987887859344482
Validation loss: 2.057866166035334

Epoch: 5| Step: 6
Training loss: 2.0511555671691895
Validation loss: 2.048269127806028

Epoch: 5| Step: 7
Training loss: 2.4602503776550293
Validation loss: 2.05789053440094

Epoch: 5| Step: 8
Training loss: 1.897210717201233
Validation loss: 2.0302781015634537

Epoch: 5| Step: 9
Training loss: 1.5852264165878296
Validation loss: 2.079955776532491

Epoch: 5| Step: 10
Training loss: 1.6759309768676758
Validation loss: 2.042026033004125

Epoch: 5| Step: 11
Training loss: 1.522085428237915
Validation loss: 2.0409856935342154

Epoch: 67| Step: 0
Training loss: 1.6897733211517334
Validation loss: 2.0644125044345856

Epoch: 5| Step: 1
Training loss: 1.5747684240341187
Validation loss: 2.0909768491983414

Epoch: 5| Step: 2
Training loss: 2.232513904571533
Validation loss: 2.083038037021955

Epoch: 5| Step: 3
Training loss: 1.416024088859558
Validation loss: 2.0561363051335015

Epoch: 5| Step: 4
Training loss: 1.8467366695404053
Validation loss: 2.0950496147076287

Epoch: 5| Step: 5
Training loss: 2.4162955284118652
Validation loss: 2.1179955899715424

Epoch: 5| Step: 6
Training loss: 1.687953233718872
Validation loss: 2.072386627395948

Epoch: 5| Step: 7
Training loss: 1.5500303506851196
Validation loss: 2.072212095061938

Epoch: 5| Step: 8
Training loss: 2.2214584350585938
Validation loss: 2.080796296397845

Epoch: 5| Step: 9
Training loss: 2.1172733306884766
Validation loss: 2.100183124343554

Epoch: 5| Step: 10
Training loss: 2.1263461112976074
Validation loss: 2.04508867363135

Epoch: 5| Step: 11
Training loss: 3.2347536087036133
Validation loss: 2.050799787044525

Epoch: 68| Step: 0
Training loss: 1.8475698232650757
Validation loss: 2.0534916867812476

Epoch: 5| Step: 1
Training loss: 1.8568216562271118
Validation loss: 2.04809433221817

Epoch: 5| Step: 2
Training loss: 1.9102070331573486
Validation loss: 2.049589142203331

Epoch: 5| Step: 3
Training loss: 2.4091222286224365
Validation loss: 2.0732495139042535

Epoch: 5| Step: 4
Training loss: 2.136035680770874
Validation loss: 2.0568482726812363

Epoch: 5| Step: 5
Training loss: 2.4032764434814453
Validation loss: 2.057982161641121

Epoch: 5| Step: 6
Training loss: 1.707129716873169
Validation loss: 2.056407501300176

Epoch: 5| Step: 7
Training loss: 1.719496726989746
Validation loss: 2.0377736538648605

Epoch: 5| Step: 8
Training loss: 1.326554536819458
Validation loss: 2.09569085141023

Epoch: 5| Step: 9
Training loss: 1.5415761470794678
Validation loss: 2.0806460877259574

Epoch: 5| Step: 10
Training loss: 2.177910327911377
Validation loss: 2.0992743372917175

Epoch: 5| Step: 11
Training loss: 2.5587737560272217
Validation loss: 2.0998646716276803

Epoch: 69| Step: 0
Training loss: 2.0066099166870117
Validation loss: 2.076006998618444

Epoch: 5| Step: 1
Training loss: 2.0942537784576416
Validation loss: 2.0790080428123474

Epoch: 5| Step: 2
Training loss: 1.8100112676620483
Validation loss: 2.0729396293560662

Epoch: 5| Step: 3
Training loss: 1.6151483058929443
Validation loss: 2.0710879067579904

Epoch: 5| Step: 4
Training loss: 2.071556568145752
Validation loss: 2.0816082656383514

Epoch: 5| Step: 5
Training loss: 1.2317991256713867
Validation loss: 2.0937962929407754

Epoch: 5| Step: 6
Training loss: 2.4824986457824707
Validation loss: 2.1131972819566727

Epoch: 5| Step: 7
Training loss: 1.9603331089019775
Validation loss: 2.0674540301163993

Epoch: 5| Step: 8
Training loss: 1.4204117059707642
Validation loss: 2.0738146851460137

Epoch: 5| Step: 9
Training loss: 2.167616605758667
Validation loss: 2.080207218726476

Epoch: 5| Step: 10
Training loss: 1.939662218093872
Validation loss: 2.080065389474233

Epoch: 5| Step: 11
Training loss: 3.298489809036255
Validation loss: 2.077855055530866

Epoch: 70| Step: 0
Training loss: 1.6554410457611084
Validation loss: 2.0667388339837394

Epoch: 5| Step: 1
Training loss: 1.9890697002410889
Validation loss: 2.0851804614067078

Epoch: 5| Step: 2
Training loss: 1.9936668872833252
Validation loss: 2.0574973771969476

Epoch: 5| Step: 3
Training loss: 2.2035117149353027
Validation loss: 2.051205257574717

Epoch: 5| Step: 4
Training loss: 2.190307855606079
Validation loss: 2.059966733058294

Epoch: 5| Step: 5
Training loss: 1.4430702924728394
Validation loss: 2.0380292534828186

Epoch: 5| Step: 6
Training loss: 1.8380931615829468
Validation loss: 2.0296470373868942

Epoch: 5| Step: 7
Training loss: 1.7900922298431396
Validation loss: 2.045090908805529

Epoch: 5| Step: 8
Training loss: 1.7084710597991943
Validation loss: 2.058085228006045

Epoch: 5| Step: 9
Training loss: 2.2232372760772705
Validation loss: 2.058008556564649

Epoch: 5| Step: 10
Training loss: 1.8780860900878906
Validation loss: 2.0440267622470856

Epoch: 5| Step: 11
Training loss: 3.0433614253997803
Validation loss: 2.0880336115757623

Epoch: 71| Step: 0
Training loss: 2.001020669937134
Validation loss: 2.041794707377752

Epoch: 5| Step: 1
Training loss: 1.1939727067947388
Validation loss: 2.058412512143453

Epoch: 5| Step: 2
Training loss: 1.9524482488632202
Validation loss: 2.0602675527334213

Epoch: 5| Step: 3
Training loss: 1.8776718378067017
Validation loss: 2.0667956123749414

Epoch: 5| Step: 4
Training loss: 1.632702112197876
Validation loss: 2.0319316734870276

Epoch: 5| Step: 5
Training loss: 3.091820478439331
Validation loss: 2.08368589480718

Epoch: 5| Step: 6
Training loss: 1.9747295379638672
Validation loss: 2.065783073504766

Epoch: 5| Step: 7
Training loss: 1.3771823644638062
Validation loss: 2.0474132696787515

Epoch: 5| Step: 8
Training loss: 1.5056020021438599
Validation loss: 2.070568030079206

Epoch: 5| Step: 9
Training loss: 2.2631516456604004
Validation loss: 2.046954562266668

Epoch: 5| Step: 10
Training loss: 2.4113032817840576
Validation loss: 2.0341933319965997

Epoch: 5| Step: 11
Training loss: 1.1883771419525146
Validation loss: 2.0590697526931763

Epoch: 72| Step: 0
Training loss: 2.276940107345581
Validation loss: 2.0508075406154

Epoch: 5| Step: 1
Training loss: 2.009279727935791
Validation loss: 2.0189487040042877

Epoch: 5| Step: 2
Training loss: 1.9550154209136963
Validation loss: 2.0330651899178824

Epoch: 5| Step: 3
Training loss: 1.7833030223846436
Validation loss: 2.0536409268776574

Epoch: 5| Step: 4
Training loss: 1.317090392112732
Validation loss: 2.0410232792297998

Epoch: 5| Step: 5
Training loss: 1.4635523557662964
Validation loss: 2.0275131314992905

Epoch: 5| Step: 6
Training loss: 1.671276330947876
Validation loss: 2.056382785240809

Epoch: 5| Step: 7
Training loss: 2.0449798107147217
Validation loss: 2.057549645503362

Epoch: 5| Step: 8
Training loss: 2.2664988040924072
Validation loss: 2.0806694428126016

Epoch: 5| Step: 9
Training loss: 1.9802757501602173
Validation loss: 2.116722116867701

Epoch: 5| Step: 10
Training loss: 2.326066493988037
Validation loss: 2.1014741311470666

Epoch: 5| Step: 11
Training loss: 1.1195473670959473
Validation loss: 2.0740306079387665

Epoch: 73| Step: 0
Training loss: 1.5133819580078125
Validation loss: 2.0812736799319587

Epoch: 5| Step: 1
Training loss: 1.7463878393173218
Validation loss: 2.0587278505166373

Epoch: 5| Step: 2
Training loss: 1.9714794158935547
Validation loss: 2.084078590075175

Epoch: 5| Step: 3
Training loss: 1.2628862857818604
Validation loss: 2.0863029013077417

Epoch: 5| Step: 4
Training loss: 1.8019492626190186
Validation loss: 2.0533387362957

Epoch: 5| Step: 5
Training loss: 2.4307496547698975
Validation loss: 2.0780795216560364

Epoch: 5| Step: 6
Training loss: 1.848980188369751
Validation loss: 2.076523870229721

Epoch: 5| Step: 7
Training loss: 1.9934402704238892
Validation loss: 2.063392842809359

Epoch: 5| Step: 8
Training loss: 2.1168084144592285
Validation loss: 2.0897076974312463

Epoch: 5| Step: 9
Training loss: 2.286900520324707
Validation loss: 2.054726555943489

Epoch: 5| Step: 10
Training loss: 1.9600645303726196
Validation loss: 2.0696142117182412

Epoch: 5| Step: 11
Training loss: 1.5597493648529053
Validation loss: 2.0422637114922204

Epoch: 74| Step: 0
Training loss: 1.7129402160644531
Validation loss: 2.058608909447988

Epoch: 5| Step: 1
Training loss: 1.9646638631820679
Validation loss: 2.045052647590637

Epoch: 5| Step: 2
Training loss: 1.7965482473373413
Validation loss: 2.056178003549576

Epoch: 5| Step: 3
Training loss: 2.4215312004089355
Validation loss: 2.082124710083008

Epoch: 5| Step: 4
Training loss: 1.6766729354858398
Validation loss: 2.060986260573069

Epoch: 5| Step: 5
Training loss: 2.231987953186035
Validation loss: 2.0781382769346237

Epoch: 5| Step: 6
Training loss: 1.6107324361801147
Validation loss: 2.0725511411825814

Epoch: 5| Step: 7
Training loss: 1.4099618196487427
Validation loss: 2.0731178671121597

Epoch: 5| Step: 8
Training loss: 2.15804123878479
Validation loss: 2.063240791360537

Epoch: 5| Step: 9
Training loss: 2.142221450805664
Validation loss: 2.0487418522437415

Epoch: 5| Step: 10
Training loss: 1.7282634973526
Validation loss: 2.0671782145897546

Epoch: 5| Step: 11
Training loss: 1.7686183452606201
Validation loss: 2.072593480348587

Epoch: 75| Step: 0
Training loss: 1.8644304275512695
Validation loss: 2.039222409327825

Epoch: 5| Step: 1
Training loss: 1.6498897075653076
Validation loss: 2.0667948126792908

Epoch: 5| Step: 2
Training loss: 2.0603785514831543
Validation loss: 2.0607364972432456

Epoch: 5| Step: 3
Training loss: 1.7783746719360352
Validation loss: 2.086618810892105

Epoch: 5| Step: 4
Training loss: 1.9725974798202515
Validation loss: 2.051070968310038

Epoch: 5| Step: 5
Training loss: 2.020289897918701
Validation loss: 2.090090647339821

Epoch: 5| Step: 6
Training loss: 2.4575533866882324
Validation loss: 2.100843628247579

Epoch: 5| Step: 7
Training loss: 1.363258957862854
Validation loss: 2.1143723527590432

Epoch: 5| Step: 8
Training loss: 2.0263562202453613
Validation loss: 2.0968665381272635

Epoch: 5| Step: 9
Training loss: 1.554764986038208
Validation loss: 2.1167564342419305

Epoch: 5| Step: 10
Training loss: 1.9200080633163452
Validation loss: 2.1180058966080346

Epoch: 5| Step: 11
Training loss: 1.8184518814086914
Validation loss: 2.0720934867858887

Epoch: 76| Step: 0
Training loss: 2.7067601680755615
Validation loss: 2.0979952017466226

Epoch: 5| Step: 1
Training loss: 1.8022905588150024
Validation loss: 2.0905001163482666

Epoch: 5| Step: 2
Training loss: 1.4288861751556396
Validation loss: 2.0569285502036414

Epoch: 5| Step: 3
Training loss: 2.047191619873047
Validation loss: 2.0488399813572564

Epoch: 5| Step: 4
Training loss: 1.6990867853164673
Validation loss: 2.071371724208196

Epoch: 5| Step: 5
Training loss: 1.427990198135376
Validation loss: 2.042430132627487

Epoch: 5| Step: 6
Training loss: 1.9494518041610718
Validation loss: 2.061902383963267

Epoch: 5| Step: 7
Training loss: 2.4374749660491943
Validation loss: 2.04023876786232

Epoch: 5| Step: 8
Training loss: 1.8683637380599976
Validation loss: 2.0680027504762015

Epoch: 5| Step: 9
Training loss: 2.1557517051696777
Validation loss: 2.052816172440847

Epoch: 5| Step: 10
Training loss: 1.5942919254302979
Validation loss: 2.0605579018592834

Epoch: 5| Step: 11
Training loss: 1.087342619895935
Validation loss: 2.032822370529175

Epoch: 77| Step: 0
Training loss: 1.3747574090957642
Validation loss: 2.0543106695016227

Epoch: 5| Step: 1
Training loss: 1.7582752704620361
Validation loss: 2.070745433370272

Epoch: 5| Step: 2
Training loss: 2.215559482574463
Validation loss: 2.0446670055389404

Epoch: 5| Step: 3
Training loss: 1.5678634643554688
Validation loss: 2.0957158456246057

Epoch: 5| Step: 4
Training loss: 1.5138590335845947
Validation loss: 2.0990336189667382

Epoch: 5| Step: 5
Training loss: 1.7930333614349365
Validation loss: 2.090212821960449

Epoch: 5| Step: 6
Training loss: 1.630384087562561
Validation loss: 2.0686645805835724

Epoch: 5| Step: 7
Training loss: 1.890496015548706
Validation loss: 2.0909645507733026

Epoch: 5| Step: 8
Training loss: 2.8886566162109375
Validation loss: 2.1038914173841476

Epoch: 5| Step: 9
Training loss: 2.1134486198425293
Validation loss: 2.0601891626914344

Epoch: 5| Step: 10
Training loss: 1.6491237878799438
Validation loss: 2.11428535481294

Epoch: 5| Step: 11
Training loss: 3.3491196632385254
Validation loss: 2.0881466567516327

Epoch: 78| Step: 0
Training loss: 2.331387996673584
Validation loss: 2.106418361266454

Epoch: 5| Step: 1
Training loss: 2.6000678539276123
Validation loss: 2.102429355184237

Epoch: 5| Step: 2
Training loss: 1.9038070440292358
Validation loss: 2.092913488547007

Epoch: 5| Step: 3
Training loss: 1.7040716409683228
Validation loss: 2.1067625333865485

Epoch: 5| Step: 4
Training loss: 1.8946306705474854
Validation loss: 2.06831231713295

Epoch: 5| Step: 5
Training loss: 1.789354920387268
Validation loss: 2.060283293326696

Epoch: 5| Step: 6
Training loss: 1.5830292701721191
Validation loss: 2.0731175392866135

Epoch: 5| Step: 7
Training loss: 1.428386926651001
Validation loss: 2.0688767383495965

Epoch: 5| Step: 8
Training loss: 2.045840263366699
Validation loss: 2.074816972017288

Epoch: 5| Step: 9
Training loss: 1.491483449935913
Validation loss: 2.047245144844055

Epoch: 5| Step: 10
Training loss: 2.1068687438964844
Validation loss: 2.042712852358818

Epoch: 5| Step: 11
Training loss: 2.3318417072296143
Validation loss: 2.0748933255672455

Epoch: 79| Step: 0
Training loss: 1.6368917226791382
Validation loss: 2.053958127895991

Epoch: 5| Step: 1
Training loss: 2.1110763549804688
Validation loss: 2.0381824175516763

Epoch: 5| Step: 2
Training loss: 2.2351393699645996
Validation loss: 2.0591826488574347

Epoch: 5| Step: 3
Training loss: 1.6397817134857178
Validation loss: 2.0288305332263312

Epoch: 5| Step: 4
Training loss: 1.7474205493927002
Validation loss: 2.068790982166926

Epoch: 5| Step: 5
Training loss: 1.7659410238265991
Validation loss: 2.0206746757030487

Epoch: 5| Step: 6
Training loss: 2.0198230743408203
Validation loss: 2.0779189417759576

Epoch: 5| Step: 7
Training loss: 1.648796796798706
Validation loss: 2.060605595509211

Epoch: 5| Step: 8
Training loss: 1.7230119705200195
Validation loss: 2.076939602692922

Epoch: 5| Step: 9
Training loss: 2.5531861782073975
Validation loss: 2.023969918489456

Epoch: 5| Step: 10
Training loss: 1.8387701511383057
Validation loss: 2.0607903401056924

Epoch: 5| Step: 11
Training loss: 1.8076307773590088
Validation loss: 2.0661025047302246

Epoch: 80| Step: 0
Training loss: 2.458043336868286
Validation loss: 2.0795257737239203

Epoch: 5| Step: 1
Training loss: 1.939517617225647
Validation loss: 2.068809668223063

Epoch: 5| Step: 2
Training loss: 1.8043079376220703
Validation loss: 2.107029308875402

Epoch: 5| Step: 3
Training loss: 1.9033677577972412
Validation loss: 2.0921590079863868

Epoch: 5| Step: 4
Training loss: 1.5394443273544312
Validation loss: 2.0993508795897164

Epoch: 5| Step: 5
Training loss: 1.992059350013733
Validation loss: 2.1192539085944495

Epoch: 5| Step: 6
Training loss: 1.6172815561294556
Validation loss: 2.139633759856224

Epoch: 5| Step: 7
Training loss: 1.6840131282806396
Validation loss: 2.081285680333773

Epoch: 5| Step: 8
Training loss: 2.1797266006469727
Validation loss: 2.096139907836914

Epoch: 5| Step: 9
Training loss: 2.1290478706359863
Validation loss: 2.0806143283843994

Epoch: 5| Step: 10
Training loss: 1.5531294345855713
Validation loss: 2.068083350857099

Epoch: 5| Step: 11
Training loss: 2.3639204502105713
Validation loss: 2.0841537714004517

Epoch: 81| Step: 0
Training loss: 1.6173436641693115
Validation loss: 2.0893108944098153

Epoch: 5| Step: 1
Training loss: 1.7061593532562256
Validation loss: 2.0235756188631058

Epoch: 5| Step: 2
Training loss: 1.4854471683502197
Validation loss: 2.0310198267300925

Epoch: 5| Step: 3
Training loss: 2.1492538452148438
Validation loss: 2.0556619316339493

Epoch: 5| Step: 4
Training loss: 2.1718621253967285
Validation loss: 2.073418060938517

Epoch: 5| Step: 5
Training loss: 2.044107675552368
Validation loss: 2.0546369502941766

Epoch: 5| Step: 6
Training loss: 2.2873616218566895
Validation loss: 2.0766340543826423

Epoch: 5| Step: 7
Training loss: 1.2524938583374023
Validation loss: 2.049278477827708

Epoch: 5| Step: 8
Training loss: 1.6914726495742798
Validation loss: 2.0824188788731894

Epoch: 5| Step: 9
Training loss: 2.370817184448242
Validation loss: 2.0653962095578513

Epoch: 5| Step: 10
Training loss: 1.6811206340789795
Validation loss: 2.0485673944155374

Epoch: 5| Step: 11
Training loss: 3.070162296295166
Validation loss: 2.0658214588960013

Epoch: 82| Step: 0
Training loss: 2.2252612113952637
Validation loss: 2.031691327691078

Epoch: 5| Step: 1
Training loss: 1.4438737630844116
Validation loss: 2.0446413358052573

Epoch: 5| Step: 2
Training loss: 2.1280677318573
Validation loss: 2.100384180744489

Epoch: 5| Step: 3
Training loss: 1.7841084003448486
Validation loss: 2.1197437594334283

Epoch: 5| Step: 4
Training loss: 1.9041624069213867
Validation loss: 2.085880090792974

Epoch: 5| Step: 5
Training loss: 1.8353725671768188
Validation loss: 2.072124366958936

Epoch: 5| Step: 6
Training loss: 1.9258201122283936
Validation loss: 2.104723811149597

Epoch: 5| Step: 7
Training loss: 1.5040996074676514
Validation loss: 2.1024365524450936

Epoch: 5| Step: 8
Training loss: 2.0560431480407715
Validation loss: 2.0934148828188577

Epoch: 5| Step: 9
Training loss: 2.213383913040161
Validation loss: 2.093282163143158

Epoch: 5| Step: 10
Training loss: 1.6944363117218018
Validation loss: 2.0596839686234794

Epoch: 5| Step: 11
Training loss: 1.9560514688491821
Validation loss: 2.085090825955073

Epoch: 83| Step: 0
Training loss: 2.038069248199463
Validation loss: 2.0508746206760406

Epoch: 5| Step: 1
Training loss: 1.1951122283935547
Validation loss: 2.058645819624265

Epoch: 5| Step: 2
Training loss: 1.9830926656723022
Validation loss: 2.0841606160004935

Epoch: 5| Step: 3
Training loss: 2.118328094482422
Validation loss: 2.0531657338142395

Epoch: 5| Step: 4
Training loss: 2.069260358810425
Validation loss: 2.0470205495754876

Epoch: 5| Step: 5
Training loss: 2.3663439750671387
Validation loss: 2.0550615886847177

Epoch: 5| Step: 6
Training loss: 2.1440820693969727
Validation loss: 2.075873777270317

Epoch: 5| Step: 7
Training loss: 1.9580227136611938
Validation loss: 2.0748059451580048

Epoch: 5| Step: 8
Training loss: 1.634320855140686
Validation loss: 2.070907493432363

Epoch: 5| Step: 9
Training loss: 1.4061555862426758
Validation loss: 2.0765987237294516

Epoch: 5| Step: 10
Training loss: 1.582951545715332
Validation loss: 2.0703928619623184

Epoch: 5| Step: 11
Training loss: 1.8300844430923462
Validation loss: 2.043818016846975

Epoch: 84| Step: 0
Training loss: 1.7075201272964478
Validation loss: 2.0807774662971497

Epoch: 5| Step: 1
Training loss: 1.4666017293930054
Validation loss: 2.0703694373369217

Epoch: 5| Step: 2
Training loss: 2.156141996383667
Validation loss: 2.083500236272812

Epoch: 5| Step: 3
Training loss: 1.8871104717254639
Validation loss: 2.069204201300939

Epoch: 5| Step: 4
Training loss: 1.9244415760040283
Validation loss: 2.0748376647631326

Epoch: 5| Step: 5
Training loss: 2.2207248210906982
Validation loss: 2.0794265270233154

Epoch: 5| Step: 6
Training loss: 1.8149678707122803
Validation loss: 2.0777673522631326

Epoch: 5| Step: 7
Training loss: 1.7973499298095703
Validation loss: 2.11599167684714

Epoch: 5| Step: 8
Training loss: 1.3411879539489746
Validation loss: 2.1071645468473434

Epoch: 5| Step: 9
Training loss: 2.2637248039245605
Validation loss: 2.089899172385534

Epoch: 5| Step: 10
Training loss: 1.888114333152771
Validation loss: 2.0993760426839194

Epoch: 5| Step: 11
Training loss: 1.8897699117660522
Validation loss: 2.100678637623787

Epoch: 85| Step: 0
Training loss: 1.8424482345581055
Validation loss: 2.073705703020096

Epoch: 5| Step: 1
Training loss: 2.24992036819458
Validation loss: 2.0959801028172174

Epoch: 5| Step: 2
Training loss: 1.7787830829620361
Validation loss: 2.041939467191696

Epoch: 5| Step: 3
Training loss: 1.9239095449447632
Validation loss: 2.0328225940465927

Epoch: 5| Step: 4
Training loss: 1.6048389673233032
Validation loss: 2.0479353864987693

Epoch: 5| Step: 5
Training loss: 1.4849679470062256
Validation loss: 2.0520328183968863

Epoch: 5| Step: 6
Training loss: 1.7985248565673828
Validation loss: 2.0712383488814035

Epoch: 5| Step: 7
Training loss: 1.8714520931243896
Validation loss: 2.031029909849167

Epoch: 5| Step: 8
Training loss: 2.126519203186035
Validation loss: 2.0819625854492188

Epoch: 5| Step: 9
Training loss: 1.6024566888809204
Validation loss: 2.029411827524503

Epoch: 5| Step: 10
Training loss: 2.0308852195739746
Validation loss: 2.089500625928243

Epoch: 5| Step: 11
Training loss: 2.8579165935516357
Validation loss: 2.046151210864385

Epoch: 86| Step: 0
Training loss: 1.957909345626831
Validation loss: 2.0565435141324997

Epoch: 5| Step: 1
Training loss: 1.798161268234253
Validation loss: 2.044072409470876

Epoch: 5| Step: 2
Training loss: 2.077463388442993
Validation loss: 2.058348005016645

Epoch: 5| Step: 3
Training loss: 1.6868696212768555
Validation loss: 2.045742079615593

Epoch: 5| Step: 4
Training loss: 2.259467601776123
Validation loss: 2.042944004138311

Epoch: 5| Step: 5
Training loss: 1.6658928394317627
Validation loss: 2.0390467047691345

Epoch: 5| Step: 6
Training loss: 1.8516308069229126
Validation loss: 2.053397685289383

Epoch: 5| Step: 7
Training loss: 1.6050859689712524
Validation loss: 2.0448587437470755

Epoch: 5| Step: 8
Training loss: 1.681418776512146
Validation loss: 2.076641490062078

Epoch: 5| Step: 9
Training loss: 1.6653486490249634
Validation loss: 2.058907071749369

Epoch: 5| Step: 10
Training loss: 2.247253894805908
Validation loss: 2.0669404168923697

Epoch: 5| Step: 11
Training loss: 2.5139527320861816
Validation loss: 2.072603553533554

Epoch: 87| Step: 0
Training loss: 1.9217630624771118
Validation loss: 2.073101649681727

Epoch: 5| Step: 1
Training loss: 1.8157405853271484
Validation loss: 2.0927302738030753

Epoch: 5| Step: 2
Training loss: 2.6695761680603027
Validation loss: 2.1102282206217446

Epoch: 5| Step: 3
Training loss: 1.6595239639282227
Validation loss: 2.111535911758741

Epoch: 5| Step: 4
Training loss: 1.825278639793396
Validation loss: 2.124602963527044

Epoch: 5| Step: 5
Training loss: 2.518090009689331
Validation loss: 2.048752650618553

Epoch: 5| Step: 6
Training loss: 1.453569769859314
Validation loss: 2.0792837838331857

Epoch: 5| Step: 7
Training loss: 1.777151107788086
Validation loss: 2.0530877262353897

Epoch: 5| Step: 8
Training loss: 1.489512324333191
Validation loss: 2.070185994108518

Epoch: 5| Step: 9
Training loss: 1.3904725313186646
Validation loss: 2.090990290045738

Epoch: 5| Step: 10
Training loss: 1.9115298986434937
Validation loss: 2.0620216677586236

Epoch: 5| Step: 11
Training loss: 1.154455304145813
Validation loss: 2.0520330518484116

Epoch: 88| Step: 0
Training loss: 1.8618139028549194
Validation loss: 2.077169825633367

Epoch: 5| Step: 1
Training loss: 1.9015941619873047
Validation loss: 2.032126615444819

Epoch: 5| Step: 2
Training loss: 1.5711251497268677
Validation loss: 2.069715400536855

Epoch: 5| Step: 3
Training loss: 1.8236510753631592
Validation loss: 2.084302837649981

Epoch: 5| Step: 4
Training loss: 2.297370195388794
Validation loss: 2.0557533303896585

Epoch: 5| Step: 5
Training loss: 1.6861937046051025
Validation loss: 2.0654252618551254

Epoch: 5| Step: 6
Training loss: 1.9582380056381226
Validation loss: 2.065084437529246

Epoch: 5| Step: 7
Training loss: 1.5073907375335693
Validation loss: 2.0511723160743713

Epoch: 5| Step: 8
Training loss: 1.9312702417373657
Validation loss: 2.085505415995916

Epoch: 5| Step: 9
Training loss: 1.6129226684570312
Validation loss: 2.0724103103081384

Epoch: 5| Step: 10
Training loss: 1.7463016510009766
Validation loss: 2.1090872486432395

Epoch: 5| Step: 11
Training loss: 3.400484085083008
Validation loss: 2.0645468632380166

Epoch: 89| Step: 0
Training loss: 1.980067491531372
Validation loss: 2.058154061436653

Epoch: 5| Step: 1
Training loss: 1.5316410064697266
Validation loss: 2.0684044808149338

Epoch: 5| Step: 2
Training loss: 2.094902515411377
Validation loss: 2.0745240350564322

Epoch: 5| Step: 3
Training loss: 2.251326322555542
Validation loss: 2.0856605023145676

Epoch: 5| Step: 4
Training loss: 1.6780650615692139
Validation loss: 2.070633813738823

Epoch: 5| Step: 5
Training loss: 1.8325691223144531
Validation loss: 2.065703029433886

Epoch: 5| Step: 6
Training loss: 1.2362486124038696
Validation loss: 2.067819486061732

Epoch: 5| Step: 7
Training loss: 1.5254396200180054
Validation loss: 2.040710985660553

Epoch: 5| Step: 8
Training loss: 2.154273509979248
Validation loss: 2.072375620404879

Epoch: 5| Step: 9
Training loss: 1.9169018268585205
Validation loss: 2.059473440051079

Epoch: 5| Step: 10
Training loss: 2.02807879447937
Validation loss: 2.0776923398176828

Epoch: 5| Step: 11
Training loss: 2.8109734058380127
Validation loss: 2.029475981990496

Epoch: 90| Step: 0
Training loss: 1.560430884361267
Validation loss: 2.058700998624166

Epoch: 5| Step: 1
Training loss: 2.0903477668762207
Validation loss: 2.0757443010807037

Epoch: 5| Step: 2
Training loss: 1.658774733543396
Validation loss: 2.1015692154566445

Epoch: 5| Step: 3
Training loss: 1.5630329847335815
Validation loss: 2.0743181904157004

Epoch: 5| Step: 4
Training loss: 1.3205370903015137
Validation loss: 2.0597666601339975

Epoch: 5| Step: 5
Training loss: 1.573639154434204
Validation loss: 2.060255487759908

Epoch: 5| Step: 6
Training loss: 2.544823408126831
Validation loss: 2.11520649989446

Epoch: 5| Step: 7
Training loss: 1.6389858722686768
Validation loss: 2.0989059706528983

Epoch: 5| Step: 8
Training loss: 1.9679902791976929
Validation loss: 2.079474543531736

Epoch: 5| Step: 9
Training loss: 2.4044277667999268
Validation loss: 2.087818851073583

Epoch: 5| Step: 10
Training loss: 2.04156756401062
Validation loss: 2.10289936264356

Epoch: 5| Step: 11
Training loss: 1.4220389127731323
Validation loss: 2.083924502134323

Epoch: 91| Step: 0
Training loss: 1.948815941810608
Validation loss: 2.1002162794272103

Epoch: 5| Step: 1
Training loss: 1.2250179052352905
Validation loss: 2.062046537796656

Epoch: 5| Step: 2
Training loss: 1.8345105648040771
Validation loss: 2.065734247366587

Epoch: 5| Step: 3
Training loss: 2.0665547847747803
Validation loss: 2.0233676731586456

Epoch: 5| Step: 4
Training loss: 2.068552017211914
Validation loss: 2.0441350787878036

Epoch: 5| Step: 5
Training loss: 1.7493383884429932
Validation loss: 2.0395576308170953

Epoch: 5| Step: 6
Training loss: 1.9608227014541626
Validation loss: 2.0487453043460846

Epoch: 5| Step: 7
Training loss: 1.7933858633041382
Validation loss: 2.0639211535453796

Epoch: 5| Step: 8
Training loss: 1.826723337173462
Validation loss: 2.0920536567767463

Epoch: 5| Step: 9
Training loss: 2.021031618118286
Validation loss: 2.077846089998881

Epoch: 5| Step: 10
Training loss: 1.9370033740997314
Validation loss: 2.0668006539344788

Epoch: 5| Step: 11
Training loss: 3.005866050720215
Validation loss: 2.0889872113863626

Epoch: 92| Step: 0
Training loss: 1.644687294960022
Validation loss: 2.0552516331275306

Epoch: 5| Step: 1
Training loss: 1.3089402914047241
Validation loss: 2.0369463662306466

Epoch: 5| Step: 2
Training loss: 1.9109256267547607
Validation loss: 2.053521374861399

Epoch: 5| Step: 3
Training loss: 2.095388650894165
Validation loss: 2.041634892423948

Epoch: 5| Step: 4
Training loss: 2.271944522857666
Validation loss: 2.0801654060681662

Epoch: 5| Step: 5
Training loss: 1.8116371631622314
Validation loss: 2.0649827967087426

Epoch: 5| Step: 6
Training loss: 1.997204065322876
Validation loss: 2.089321802059809

Epoch: 5| Step: 7
Training loss: 2.1737723350524902
Validation loss: 2.1092610359191895

Epoch: 5| Step: 8
Training loss: 1.7615861892700195
Validation loss: 2.1274262815713882

Epoch: 5| Step: 9
Training loss: 1.6209678649902344
Validation loss: 2.144418309132258

Epoch: 5| Step: 10
Training loss: 2.258645534515381
Validation loss: 2.1075700720151267

Epoch: 5| Step: 11
Training loss: 0.7773666381835938
Validation loss: 2.0997668653726578

Epoch: 93| Step: 0
Training loss: 1.7797046899795532
Validation loss: 2.1186579217513404

Epoch: 5| Step: 1
Training loss: 1.641528844833374
Validation loss: 2.0546754896640778

Epoch: 5| Step: 2
Training loss: 1.961551308631897
Validation loss: 2.0918706307808557

Epoch: 5| Step: 3
Training loss: 1.66677987575531
Validation loss: 2.02108525733153

Epoch: 5| Step: 4
Training loss: 1.747618317604065
Validation loss: 2.0696782767772675

Epoch: 5| Step: 5
Training loss: 1.847948431968689
Validation loss: 2.031764696041743

Epoch: 5| Step: 6
Training loss: 1.865302324295044
Validation loss: 2.044039105375608

Epoch: 5| Step: 7
Training loss: 1.8164374828338623
Validation loss: 2.0265769412120185

Epoch: 5| Step: 8
Training loss: 1.9480419158935547
Validation loss: 2.0692986796299615

Epoch: 5| Step: 9
Training loss: 1.9062188863754272
Validation loss: 2.03320042292277

Epoch: 5| Step: 10
Training loss: 1.9486076831817627
Validation loss: 2.0613520443439484

Epoch: 5| Step: 11
Training loss: 1.8756381273269653
Validation loss: 2.051267753044764

Epoch: 94| Step: 0
Training loss: 2.1582412719726562
Validation loss: 2.0401451538006463

Epoch: 5| Step: 1
Training loss: 2.4339025020599365
Validation loss: 2.0775704284509025

Epoch: 5| Step: 2
Training loss: 2.1375958919525146
Validation loss: 2.0563923368851342

Epoch: 5| Step: 3
Training loss: 1.673335313796997
Validation loss: 2.078302929798762

Epoch: 5| Step: 4
Training loss: 1.4746334552764893
Validation loss: 2.012837146719297

Epoch: 5| Step: 5
Training loss: 1.9322971105575562
Validation loss: 2.0828651189804077

Epoch: 5| Step: 6
Training loss: 1.9166473150253296
Validation loss: 2.0548143287499747

Epoch: 5| Step: 7
Training loss: 1.7992690801620483
Validation loss: 2.055384710431099

Epoch: 5| Step: 8
Training loss: 1.6265592575073242
Validation loss: 2.079279750585556

Epoch: 5| Step: 9
Training loss: 1.2675902843475342
Validation loss: 2.063296069701513

Epoch: 5| Step: 10
Training loss: 1.5794297456741333
Validation loss: 2.0639726519584656

Epoch: 5| Step: 11
Training loss: 1.827636480331421
Validation loss: 2.0917430917421975

Epoch: 95| Step: 0
Training loss: 1.6586776971817017
Validation loss: 2.064462279280027

Epoch: 5| Step: 1
Training loss: 1.6448163986206055
Validation loss: 2.0841055313746133

Epoch: 5| Step: 2
Training loss: 1.7319167852401733
Validation loss: 2.0954259584347406

Epoch: 5| Step: 3
Training loss: 2.243504762649536
Validation loss: 2.119315872589747

Epoch: 5| Step: 4
Training loss: 2.2214243412017822
Validation loss: 2.072223350405693

Epoch: 5| Step: 5
Training loss: 2.2554500102996826
Validation loss: 2.0746383418639502

Epoch: 5| Step: 6
Training loss: 1.792773962020874
Validation loss: 2.098616898059845

Epoch: 5| Step: 7
Training loss: 1.8666057586669922
Validation loss: 2.064641480644544

Epoch: 5| Step: 8
Training loss: 1.3378469944000244
Validation loss: 2.047300418217977

Epoch: 5| Step: 9
Training loss: 1.5963163375854492
Validation loss: 2.0854861785968146

Epoch: 5| Step: 10
Training loss: 1.9551315307617188
Validation loss: 2.0560053835312524

Epoch: 5| Step: 11
Training loss: 1.390397071838379
Validation loss: 2.0551202396551767

Epoch: 96| Step: 0
Training loss: 1.9033057689666748
Validation loss: 2.076629544297854

Epoch: 5| Step: 1
Training loss: 1.5640674829483032
Validation loss: 2.0590069691340127

Epoch: 5| Step: 2
Training loss: 1.9760980606079102
Validation loss: 2.0465380251407623

Epoch: 5| Step: 3
Training loss: 1.4973152875900269
Validation loss: 2.080928608775139

Epoch: 5| Step: 4
Training loss: 1.5204088687896729
Validation loss: 2.0682196418444314

Epoch: 5| Step: 5
Training loss: 1.8999474048614502
Validation loss: 2.061716298262278

Epoch: 5| Step: 6
Training loss: 1.9851620197296143
Validation loss: 2.033573637406031

Epoch: 5| Step: 7
Training loss: 2.1268727779388428
Validation loss: 2.0551617542902627

Epoch: 5| Step: 8
Training loss: 1.6778080463409424
Validation loss: 2.0511110623677573

Epoch: 5| Step: 9
Training loss: 1.826885461807251
Validation loss: 2.0744302719831467

Epoch: 5| Step: 10
Training loss: 1.7369797229766846
Validation loss: 2.048921599984169

Epoch: 5| Step: 11
Training loss: 2.974635124206543
Validation loss: 2.0670345773299537

Epoch: 97| Step: 0
Training loss: 1.2211570739746094
Validation loss: 2.1338190833727517

Epoch: 5| Step: 1
Training loss: 1.918956995010376
Validation loss: 2.0478656888008118

Epoch: 5| Step: 2
Training loss: 1.8854554891586304
Validation loss: 2.066019023458163

Epoch: 5| Step: 3
Training loss: 1.792945146560669
Validation loss: 2.052782734235128

Epoch: 5| Step: 4
Training loss: 1.6826614141464233
Validation loss: 2.0786005506912866

Epoch: 5| Step: 5
Training loss: 1.5991414785385132
Validation loss: 2.092133899529775

Epoch: 5| Step: 6
Training loss: 1.3709847927093506
Validation loss: 2.070172225435575

Epoch: 5| Step: 7
Training loss: 2.5065181255340576
Validation loss: 2.0892328967650733

Epoch: 5| Step: 8
Training loss: 2.307067632675171
Validation loss: 2.0779768377542496

Epoch: 5| Step: 9
Training loss: 1.888283133506775
Validation loss: 2.058438395460447

Epoch: 5| Step: 10
Training loss: 1.7365639209747314
Validation loss: 2.0407893309990564

Epoch: 5| Step: 11
Training loss: 1.079709768295288
Validation loss: 2.045574734608332

Epoch: 98| Step: 0
Training loss: 2.134721040725708
Validation loss: 2.065144528945287

Epoch: 5| Step: 1
Training loss: 1.835766077041626
Validation loss: 2.063374509414037

Epoch: 5| Step: 2
Training loss: 1.8603127002716064
Validation loss: 2.0822447339693704

Epoch: 5| Step: 3
Training loss: 1.7680938243865967
Validation loss: 2.0756916850805283

Epoch: 5| Step: 4
Training loss: 1.640755295753479
Validation loss: 2.040908455848694

Epoch: 5| Step: 5
Training loss: 1.436004400253296
Validation loss: 2.070651024580002

Epoch: 5| Step: 6
Training loss: 1.8418323993682861
Validation loss: 2.068844278653463

Epoch: 5| Step: 7
Training loss: 1.7788158655166626
Validation loss: 2.0586565832297006

Epoch: 5| Step: 8
Training loss: 1.7566169500350952
Validation loss: 2.055678794781367

Epoch: 5| Step: 9
Training loss: 1.9731388092041016
Validation loss: 2.065557653705279

Epoch: 5| Step: 10
Training loss: 2.1546778678894043
Validation loss: 2.0766807397206626

Epoch: 5| Step: 11
Training loss: 1.0313664674758911
Validation loss: 2.1220445235570273

Epoch: 99| Step: 0
Training loss: 1.8390613794326782
Validation loss: 2.0922650595506034

Epoch: 5| Step: 1
Training loss: 2.2220075130462646
Validation loss: 2.087648779153824

Epoch: 5| Step: 2
Training loss: 1.7418533563613892
Validation loss: 2.1172120422124863

Epoch: 5| Step: 3
Training loss: 1.5930306911468506
Validation loss: 2.1058914959430695

Epoch: 5| Step: 4
Training loss: 1.8189802169799805
Validation loss: 2.1045867701371512

Epoch: 5| Step: 5
Training loss: 1.7130237817764282
Validation loss: 2.085329239567121

Epoch: 5| Step: 6
Training loss: 1.9404557943344116
Validation loss: 2.1222445368766785

Epoch: 5| Step: 7
Training loss: 1.7492071390151978
Validation loss: 2.0798615316549935

Epoch: 5| Step: 8
Training loss: 2.0043513774871826
Validation loss: 2.0435515890518823

Epoch: 5| Step: 9
Training loss: 1.437901258468628
Validation loss: 2.041854331890742

Epoch: 5| Step: 10
Training loss: 1.7906299829483032
Validation loss: 2.0610118756691613

Epoch: 5| Step: 11
Training loss: 1.530543327331543
Validation loss: 2.030379220843315

Epoch: 100| Step: 0
Training loss: 1.5573829412460327
Validation loss: 2.062528202931086

Epoch: 5| Step: 1
Training loss: 1.7320868968963623
Validation loss: 2.076082944869995

Epoch: 5| Step: 2
Training loss: 1.1723177433013916
Validation loss: 2.114384263753891

Epoch: 5| Step: 3
Training loss: 1.5815495252609253
Validation loss: 2.123542606830597

Epoch: 5| Step: 4
Training loss: 1.707519769668579
Validation loss: 2.0918032179276147

Epoch: 5| Step: 5
Training loss: 2.298466444015503
Validation loss: 2.1075227012236915

Epoch: 5| Step: 6
Training loss: 1.9432735443115234
Validation loss: 2.1107632219791412

Epoch: 5| Step: 7
Training loss: 2.0445072650909424
Validation loss: 2.0865634232759476

Epoch: 5| Step: 8
Training loss: 1.9424991607666016
Validation loss: 2.064562494556109

Epoch: 5| Step: 9
Training loss: 2.2184624671936035
Validation loss: 2.0796477049589157

Epoch: 5| Step: 10
Training loss: 1.480263590812683
Validation loss: 2.080602223674456

Epoch: 5| Step: 11
Training loss: 2.2034058570861816
Validation loss: 2.078999583919843

Testing loss: 1.8962446682744747
