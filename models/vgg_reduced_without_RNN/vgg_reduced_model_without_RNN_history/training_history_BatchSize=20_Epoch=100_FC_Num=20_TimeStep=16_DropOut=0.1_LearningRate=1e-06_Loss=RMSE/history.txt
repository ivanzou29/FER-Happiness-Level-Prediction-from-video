Epoch: 1| Step: 0
Training loss: 3.3649292916610327
Validation loss: 2.6594092082404934
Epoch: 7| Step: 1
Training loss: 3.773669628640733
Validation loss: 2.657196147349502
Epoch: 7| Step: 2
Training loss: 2.6133168307905685
Validation loss: 2.6425603074183415
Epoch: 7| Step: 3
Training loss: 2.4962039738109603
Validation loss: 2.6559016383215406
Epoch: 7| Step: 4
Training loss: 3.5980616702466275
Validation loss: 2.648520200061151
Epoch: 7| Step: 5
Training loss: 2.7002655958303254
Validation loss: 2.6537718602376783
Epoch: 7| Step: 6
Training loss: 3.522248128708139
Validation loss: 2.638775578809667
Epoch: 7| Step: 7
Training loss: 2.66737155737356
Validation loss: 2.642029345091751
Epoch: 7| Step: 8
Training loss: 3.40729037854038
Validation loss: 2.6416015742771726
Epoch: 7| Step: 9
Training loss: 3.235860732128992
Validation loss: 2.648324136481359
Epoch: 7| Step: 10
Training loss: 2.8939083113734325
Validation loss: 2.6344221372403505
Epoch: 7| Step: 11
Training loss: 2.486426891633648
Validation loss: 2.6401435425108524
Epoch: 7| Step: 12
Training loss: 3.3092083680993154
Validation loss: 2.6094113962607848
Epoch: 7| Step: 13
Training loss: 3.656416538716842
Validation loss: 2.5988606587075136
Epoch: 7| Step: 14
Training loss: 3.3390628370214355
Validation loss: 2.6291291246719783
Epoch: 7| Step: 15
Training loss: 3.3025042308748507
Validation loss: 2.6243292690352185
Epoch: 2| Step: 0
Training loss: 3.087107607968778
Validation loss: 2.622449357181579
Epoch: 7| Step: 1
Training loss: 3.1464328489341007
Validation loss: 2.6241047444670533
Epoch: 7| Step: 2
Training loss: 3.1632458798613743
Validation loss: 2.572595795275039
Epoch: 7| Step: 3
Training loss: 2.87364015346884
Validation loss: 2.60099926759181
Epoch: 7| Step: 4
Training loss: 3.31504450542327
Validation loss: 2.606339523557255
Epoch: 7| Step: 5
Training loss: 2.889765431213496
Validation loss: 2.587552133831243
Epoch: 7| Step: 6
Training loss: 3.033246827900711
Validation loss: 2.611620832627312
Epoch: 7| Step: 7
Training loss: 3.3849518598686053
Validation loss: 2.582533084081291
Epoch: 7| Step: 8
Training loss: 2.587622793481305
Validation loss: 2.595607237076849
Epoch: 7| Step: 9
Training loss: 3.0460928671112306
Validation loss: 2.5902743706058557
Epoch: 7| Step: 10
Training loss: 3.1353238283186715
Validation loss: 2.596832591359369
Epoch: 7| Step: 11
Training loss: 3.185095534636018
Validation loss: 2.5497733348472282
Epoch: 7| Step: 12
Training loss: 3.161554392696497
Validation loss: 2.5844859122502624
Epoch: 7| Step: 13
Training loss: 2.971506545594792
Validation loss: 2.587657481821305
Epoch: 7| Step: 14
Training loss: 3.2284538876999442
Validation loss: 2.5683282494938853
Epoch: 7| Step: 15
Training loss: 3.8438996076543916
Validation loss: 2.586033067120411
Epoch: 3| Step: 0
Training loss: 2.795516382056487
Validation loss: 2.576342885114125
Epoch: 7| Step: 1
Training loss: 2.74755056707831
Validation loss: 2.5799179514365562
Epoch: 7| Step: 2
Training loss: 2.7616577141692837
Validation loss: 2.5669923586463264
Epoch: 7| Step: 3
Training loss: 2.760527573762695
Validation loss: 2.55931118230427
Epoch: 7| Step: 4
Training loss: 3.551160198339757
Validation loss: 2.5671202934845336
Epoch: 7| Step: 5
Training loss: 3.097962257308032
Validation loss: 2.5587142643256575
Epoch: 7| Step: 6
Training loss: 2.9021395255894866
Validation loss: 2.5689735852414226
Epoch: 7| Step: 7
Training loss: 3.3928274569252443
Validation loss: 2.541166936886842
Epoch: 7| Step: 8
Training loss: 3.237085063958578
Validation loss: 2.5448601152926953
Epoch: 7| Step: 9
Training loss: 3.236433912630566
Validation loss: 2.535755885473325
Epoch: 7| Step: 10
Training loss: 3.2465586415465357
Validation loss: 2.552141471500049
Epoch: 7| Step: 11
Training loss: 3.2990067807972285
Validation loss: 2.5434357784323947
Epoch: 7| Step: 12
Training loss: 3.4654452415744608
Validation loss: 2.547249592758494
Epoch: 7| Step: 13
Training loss: 3.274900705710508
Validation loss: 2.5499984525566095
Epoch: 7| Step: 14
Training loss: 2.9638731401814193
Validation loss: 2.544887715156599
Epoch: 7| Step: 15
Training loss: 2.6889471549121975
Validation loss: 2.5370360109332233
Epoch: 4| Step: 0
Training loss: 3.0126019282528507
Validation loss: 2.544347037526725
Epoch: 7| Step: 1
Training loss: 3.6463679911629243
Validation loss: 2.5404674372607725
Epoch: 7| Step: 2
Training loss: 2.845063294040174
Validation loss: 2.530982853192468
Epoch: 7| Step: 3
Training loss: 2.8240300665543523
Validation loss: 2.4832965808259737
Epoch: 7| Step: 4
Training loss: 3.448486250345685
Validation loss: 2.513684606865336
Epoch: 7| Step: 5
Training loss: 3.0372720263922175
Validation loss: 2.5081675250278432
Epoch: 7| Step: 6
Training loss: 2.726064117265339
Validation loss: 2.4877525612388793
Epoch: 7| Step: 7
Training loss: 3.1687704593517116
Validation loss: 2.5143932123699604
Epoch: 7| Step: 8
Training loss: 3.2800723914554806
Validation loss: 2.496392456491428
Epoch: 7| Step: 9
Training loss: 2.999226311418005
Validation loss: 2.51437750976587
Epoch: 7| Step: 10
Training loss: 3.2008241903354397
Validation loss: 2.515682477806048
Epoch: 7| Step: 11
Training loss: 2.4868909463996745
Validation loss: 2.5037476326047523
Epoch: 7| Step: 12
Training loss: 3.1851889516215106
Validation loss: 2.4940615400604202
Epoch: 7| Step: 13
Training loss: 3.189685745306047
Validation loss: 2.5008757945400886
Epoch: 7| Step: 14
Training loss: 2.337962315989098
Validation loss: 2.4992416628709613
Epoch: 7| Step: 15
Training loss: 3.3192906860607034
Validation loss: 2.4973964500658807
Epoch: 5| Step: 0
Training loss: 2.786808246258794
Validation loss: 2.483574108565612
Epoch: 7| Step: 1
Training loss: 3.0058969714693116
Validation loss: 2.485213797145315
Epoch: 7| Step: 2
Training loss: 3.165825246820835
Validation loss: 2.4762184338313986
Epoch: 7| Step: 3
Training loss: 2.8584695018070825
Validation loss: 2.488483616167307
Epoch: 7| Step: 4
Training loss: 3.222484903115244
Validation loss: 2.472553180506736
Epoch: 7| Step: 5
Training loss: 3.107500747840159
Validation loss: 2.45873782933134
Epoch: 7| Step: 6
Training loss: 3.396881097895142
Validation loss: 2.4640797582336575
Epoch: 7| Step: 7
Training loss: 3.1225043440483913
Validation loss: 2.4588062794350236
Epoch: 7| Step: 8
Training loss: 2.8466254148985923
Validation loss: 2.4785955734303355
Epoch: 7| Step: 9
Training loss: 2.8767676517034197
Validation loss: 2.4509780539876975
Epoch: 7| Step: 10
Training loss: 3.1320772521136844
Validation loss: 2.454480171438916
Epoch: 7| Step: 11
Training loss: 2.8785348805376114
Validation loss: 2.4537793859560777
Epoch: 7| Step: 12
Training loss: 3.261473430613629
Validation loss: 2.4378725851517817
Epoch: 7| Step: 13
Training loss: 2.869810313160176
Validation loss: 2.4623872707668886
Epoch: 7| Step: 14
Training loss: 2.73401225272435
Validation loss: 2.4214254121993237
Epoch: 7| Step: 15
Training loss: 2.904542811228773
Validation loss: 2.4434655465305184
Epoch: 6| Step: 0
Training loss: 3.675026308341805
Validation loss: 2.4295505720334107
Epoch: 7| Step: 1
Training loss: 3.4159307540200174
Validation loss: 2.441333920893664
Epoch: 7| Step: 2
Training loss: 3.39677946488026
Validation loss: 2.415605966511196
Epoch: 7| Step: 3
Training loss: 2.341818356833029
Validation loss: 2.417727791358014
Epoch: 7| Step: 4
Training loss: 2.8575879125012653
Validation loss: 2.3941083054315615
Epoch: 7| Step: 5
Training loss: 3.04144868113142
Validation loss: 2.42500151892268
Epoch: 7| Step: 6
Training loss: 2.869445410653717
Validation loss: 2.4127340019124115
Epoch: 7| Step: 7
Training loss: 2.903680957986591
Validation loss: 2.4126365638042517
Epoch: 7| Step: 8
Training loss: 2.9180498022544956
Validation loss: 2.409558369444687
Epoch: 7| Step: 9
Training loss: 2.9004813748428977
Validation loss: 2.4192665670150846
Epoch: 7| Step: 10
Training loss: 2.634548260295802
Validation loss: 2.4106460863262114
Epoch: 7| Step: 11
Training loss: 3.3087260502437377
Validation loss: 2.3996474255599023
Epoch: 7| Step: 12
Training loss: 2.555081491682444
Validation loss: 2.365536344700452
Epoch: 7| Step: 13
Training loss: 2.63777702286897
Validation loss: 2.3891593440383048
Epoch: 7| Step: 14
Training loss: 2.8772928797388526
Validation loss: 2.3619442720876216
Epoch: 7| Step: 15
Training loss: 2.8908249244629958
Validation loss: 2.381210433661159
Epoch: 7| Step: 0
Training loss: 3.4198944073265163
Validation loss: 2.370164652108918
Epoch: 7| Step: 1
Training loss: 2.7678905625676964
Validation loss: 2.376913197611479
Epoch: 7| Step: 2
Training loss: 2.9539908295361865
Validation loss: 2.386739247444457
Epoch: 7| Step: 3
Training loss: 2.5785634910603226
Validation loss: 2.361535337553659
Epoch: 7| Step: 4
Training loss: 2.8344308933858104
Validation loss: 2.374171597694812
Epoch: 7| Step: 5
Training loss: 2.929072201011821
Validation loss: 2.3540690125431323
Epoch: 7| Step: 6
Training loss: 2.79217398479587
Validation loss: 2.3443774064065166
Epoch: 7| Step: 7
Training loss: 3.361972390228857
Validation loss: 2.3619603114946637
Epoch: 7| Step: 8
Training loss: 3.057109994164171
Validation loss: 2.358792906868897
Epoch: 7| Step: 9
Training loss: 2.9679137005662395
Validation loss: 2.334891610696566
Epoch: 7| Step: 10
Training loss: 2.7587036767759825
Validation loss: 2.34574106467022
Epoch: 7| Step: 11
Training loss: 2.5980324379567583
Validation loss: 2.3187843909443204
Epoch: 7| Step: 12
Training loss: 2.6124363832165867
Validation loss: 2.34186967249148
Epoch: 7| Step: 13
Training loss: 2.9122077828044914
Validation loss: 2.3369878433647124
Epoch: 7| Step: 14
Training loss: 3.0729661495729004
Validation loss: 2.3336755439730372
Epoch: 7| Step: 15
Training loss: 2.805849987313319
Validation loss: 2.332413439330884
Epoch: 8| Step: 0
Training loss: 2.5918529881006505
Validation loss: 2.327324128044379
Epoch: 7| Step: 1
Training loss: 3.03334177735659
Validation loss: 2.3287038080528406
Epoch: 7| Step: 2
Training loss: 2.989974595539269
Validation loss: 2.292223871887231
Epoch: 7| Step: 3
Training loss: 2.5472259279716636
Validation loss: 2.2928234761092234
Epoch: 7| Step: 4
Training loss: 3.1532351759082227
Validation loss: 2.2676835560996578
Epoch: 7| Step: 5
Training loss: 3.1333416803397607
Validation loss: 2.307505456936532
Epoch: 7| Step: 6
Training loss: 3.2076625040088027
Validation loss: 2.2999432679131133
Epoch: 7| Step: 7
Training loss: 2.78833477025547
Validation loss: 2.2955918779134743
Epoch: 7| Step: 8
Training loss: 3.238832212911554
Validation loss: 2.2856414389682165
Epoch: 7| Step: 9
Training loss: 2.709164438128447
Validation loss: 2.2847745570824842
Epoch: 7| Step: 10
Training loss: 2.1452714375721866
Validation loss: 2.2712808276585266
Epoch: 7| Step: 11
Training loss: 3.005863340894476
Validation loss: 2.256055920955043
Epoch: 7| Step: 12
Training loss: 2.731361865234078
Validation loss: 2.24620740894805
Epoch: 7| Step: 13
Training loss: 2.5407634026435617
Validation loss: 2.2677534078188875
Epoch: 7| Step: 14
Training loss: 2.8428868251820116
Validation loss: 2.266919597803865
Epoch: 7| Step: 15
Training loss: 2.661498147227481
Validation loss: 2.25181919166546
Epoch: 9| Step: 0
Training loss: 2.913317383112189
Validation loss: 2.203347196702184
Epoch: 7| Step: 1
Training loss: 2.914563828776395
Validation loss: 2.2522875326358367
Epoch: 7| Step: 2
Training loss: 2.4883269540850184
Validation loss: 2.2430176509745587
Epoch: 7| Step: 3
Training loss: 2.553318788604877
Validation loss: 2.2461310926426
Epoch: 7| Step: 4
Training loss: 2.885653452791824
Validation loss: 2.2406077841180596
Epoch: 7| Step: 5
Training loss: 3.1803943495082163
Validation loss: 2.228541073014984
Epoch: 7| Step: 6
Training loss: 2.858828299533888
Validation loss: 2.221141810552751
Epoch: 7| Step: 7
Training loss: 3.156038636032732
Validation loss: 2.2119593539137536
Epoch: 7| Step: 8
Training loss: 2.533517645940616
Validation loss: 2.20305062286979
Epoch: 7| Step: 9
Training loss: 2.3701733180544386
Validation loss: 2.2191257592712725
Epoch: 7| Step: 10
Training loss: 2.8120740779924676
Validation loss: 2.2110409611362405
Epoch: 7| Step: 11
Training loss: 2.7374454370922408
Validation loss: 2.2148491271634017
Epoch: 7| Step: 12
Training loss: 2.6765016351784268
Validation loss: 2.176671147346304
Epoch: 7| Step: 13
Training loss: 2.934960424101156
Validation loss: 2.1973699404856033
Epoch: 7| Step: 14
Training loss: 2.371805250828505
Validation loss: 2.1994424544717157
Epoch: 7| Step: 15
Training loss: 2.8965711316975953
Validation loss: 2.187630193019676
Epoch: 10| Step: 0
Training loss: 2.595878003890781
Validation loss: 2.1789140138429275
Epoch: 7| Step: 1
Training loss: 3.0416606397873904
Validation loss: 2.184490826938967
Epoch: 7| Step: 2
Training loss: 2.883526142560796
Validation loss: 2.148382376821211
Epoch: 7| Step: 3
Training loss: 2.587393820238013
Validation loss: 2.1628169210067476
Epoch: 7| Step: 4
Training loss: 3.1246398718273567
Validation loss: 2.162949537683853
Epoch: 7| Step: 5
Training loss: 2.634613417293236
Validation loss: 2.1549618258081193
Epoch: 7| Step: 6
Training loss: 2.9003005299559046
Validation loss: 2.1601809877889373
Epoch: 7| Step: 7
Training loss: 2.5634795386887483
Validation loss: 2.1252058112116927
Epoch: 7| Step: 8
Training loss: 2.6877631125177737
Validation loss: 2.1550584225812464
Epoch: 7| Step: 9
Training loss: 2.5684251900134365
Validation loss: 2.142431077457018
Epoch: 7| Step: 10
Training loss: 2.958325041280238
Validation loss: 2.134653000282741
Epoch: 7| Step: 11
Training loss: 2.761629224564461
Validation loss: 2.128007667302971
Epoch: 7| Step: 12
Training loss: 2.6669056507152433
Validation loss: 2.1298721954182382
Epoch: 7| Step: 13
Training loss: 2.514511809850218
Validation loss: 2.1249182255823102
Epoch: 7| Step: 14
Training loss: 2.1085332250512487
Validation loss: 2.1130177956326954
Epoch: 7| Step: 15
Training loss: 2.523280939022666
Validation loss: 2.120341252544821
Epoch: 11| Step: 0
Training loss: 2.39064594334423
Validation loss: 2.098158948886379
Epoch: 7| Step: 1
Training loss: 2.7816928125260842
Validation loss: 2.1162372544914945
Epoch: 7| Step: 2
Training loss: 2.249385749895081
Validation loss: 2.1047142812632247
Epoch: 7| Step: 3
Training loss: 2.723807180573875
Validation loss: 2.10446168660284
Epoch: 7| Step: 4
Training loss: 2.5678533135288366
Validation loss: 2.091521310553208
Epoch: 7| Step: 5
Training loss: 3.0199304393310844
Validation loss: 2.089701097692374
Epoch: 7| Step: 6
Training loss: 2.394377810865648
Validation loss: 2.082002001836908
Epoch: 7| Step: 7
Training loss: 2.634655406504416
Validation loss: 2.093403308551115
Epoch: 7| Step: 8
Training loss: 2.9864089186462923
Validation loss: 2.0920038758195862
Epoch: 7| Step: 9
Training loss: 2.422565386414294
Validation loss: 2.057865512654934
Epoch: 7| Step: 10
Training loss: 2.2456306842633276
Validation loss: 2.073479785380399
Epoch: 7| Step: 11
Training loss: 2.888220534487448
Validation loss: 2.061477135020033
Epoch: 7| Step: 12
Training loss: 2.6345138712308045
Validation loss: 2.0499755139767215
Epoch: 7| Step: 13
Training loss: 2.6480735146093726
Validation loss: 2.066441275158824
Epoch: 7| Step: 14
Training loss: 2.9072611700682014
Validation loss: 2.0630888571147477
Epoch: 7| Step: 15
Training loss: 2.4447280136510035
Validation loss: 2.0708123819558453
Epoch: 12| Step: 0
Training loss: 2.951427476418753
Validation loss: 2.058323356298849
Epoch: 7| Step: 1
Training loss: 2.4763489640172596
Validation loss: 2.0377262725881167
Epoch: 7| Step: 2
Training loss: 2.5748749563725593
Validation loss: 2.030690907465152
Epoch: 7| Step: 3
Training loss: 2.157855445163763
Validation loss: 2.0505869456631025
Epoch: 7| Step: 4
Training loss: 2.3327248211254945
Validation loss: 2.041132078257632
Epoch: 7| Step: 5
Training loss: 2.46375106556026
Validation loss: 2.0461090114887437
Epoch: 7| Step: 6
Training loss: 2.8871044267796013
Validation loss: 2.0353094718917233
Epoch: 7| Step: 7
Training loss: 2.456093225499091
Validation loss: 2.0355838822278343
Epoch: 7| Step: 8
Training loss: 2.8632990692125433
Validation loss: 2.0355488286729466
Epoch: 7| Step: 9
Training loss: 2.490287319443306
Validation loss: 2.0456754563279693
Epoch: 7| Step: 10
Training loss: 2.839997215269631
Validation loss: 2.02456948535783
Epoch: 7| Step: 11
Training loss: 2.6927569229395396
Validation loss: 2.0355820941862617
Epoch: 7| Step: 12
Training loss: 2.5168881295721124
Validation loss: 2.0189049239874644
Epoch: 7| Step: 13
Training loss: 2.4751498167374457
Validation loss: 2.0263367526168214
Epoch: 7| Step: 14
Training loss: 2.3438787806416705
Validation loss: 2.0270654608248226
Epoch: 7| Step: 15
Training loss: 2.474469380381786
Validation loss: 2.028239788937007
Epoch: 13| Step: 0
Training loss: 2.3858173372578744
Validation loss: 2.0183366161036735
Epoch: 7| Step: 1
Training loss: 3.0345986343773927
Validation loss: 2.018999317598604
Epoch: 7| Step: 2
Training loss: 3.0431290512073663
Validation loss: 2.0117826483061263
Epoch: 7| Step: 3
Training loss: 2.929178341172577
Validation loss: 2.0079493279142704
Epoch: 7| Step: 4
Training loss: 2.3897030118346776
Validation loss: 2.0235640631412344
Epoch: 7| Step: 5
Training loss: 2.47427946449228
Validation loss: 2.017583871500771
Epoch: 7| Step: 6
Training loss: 2.5866283404404706
Validation loss: 2.0212344196416865
Epoch: 7| Step: 7
Training loss: 2.3367761235669033
Validation loss: 2.0113770249632816
Epoch: 7| Step: 8
Training loss: 2.5824805256939265
Validation loss: 1.9956026897840953
Epoch: 7| Step: 9
Training loss: 2.073138916778545
Validation loss: 2.017393252764712
Epoch: 7| Step: 10
Training loss: 2.4761833598659946
Validation loss: 2.007785856175908
Epoch: 7| Step: 11
Training loss: 2.4251314973081026
Validation loss: 2.012291352598393
Epoch: 7| Step: 12
Training loss: 2.0279447219733675
Validation loss: 2.0111289300225548
Epoch: 7| Step: 13
Training loss: 2.865578514395997
Validation loss: 2.0260896346152104
Epoch: 7| Step: 14
Training loss: 2.3870318967480366
Validation loss: 2.010252846067796
Epoch: 7| Step: 15
Training loss: 2.235425368757514
Validation loss: 1.9851978113144948
Epoch: 14| Step: 0
Training loss: 1.9659919796466705
Validation loss: 2.022778566132794
Epoch: 7| Step: 1
Training loss: 2.323238082567832
Validation loss: 2.0175183787784245
Epoch: 7| Step: 2
Training loss: 2.2584310034245023
Validation loss: 2.0093937494115526
Epoch: 7| Step: 3
Training loss: 2.494269861324809
Validation loss: 2.0022015450219195
Epoch: 7| Step: 4
Training loss: 2.448900314632484
Validation loss: 2.027476808547751
Epoch: 7| Step: 5
Training loss: 2.296985857098376
Validation loss: 2.014086896775026
Epoch: 7| Step: 6
Training loss: 2.0517947644370023
Validation loss: 2.025104197855885
Epoch: 7| Step: 7
Training loss: 2.388931572209983
Validation loss: 2.017083587788577
Epoch: 7| Step: 8
Training loss: 2.2527340066934958
Validation loss: 2.0007493250119817
Epoch: 7| Step: 9
Training loss: 2.876980141113393
Validation loss: 2.022588226410585
Epoch: 7| Step: 10
Training loss: 2.6547205392489075
Validation loss: 2.0235930800405204
Epoch: 7| Step: 11
Training loss: 2.530997840660377
Validation loss: 2.0234431590172393
Epoch: 7| Step: 12
Training loss: 2.9195222408899832
Validation loss: 2.014622493006833
Epoch: 7| Step: 13
Training loss: 3.227122999373959
Validation loss: 2.026286179095923
Epoch: 7| Step: 14
Training loss: 2.924776156736888
Validation loss: 2.0223853856494145
Epoch: 7| Step: 15
Training loss: 2.198337303757667
Validation loss: 2.0328526816659584
Epoch: 15| Step: 0
Training loss: 2.5233057891202395
Validation loss: 2.032916908837016
Epoch: 7| Step: 1
Training loss: 2.4593171128630593
Validation loss: 2.0273729727969463
Epoch: 7| Step: 2
Training loss: 2.7731025601008503
Validation loss: 2.0174143731072824
Epoch: 7| Step: 3
Training loss: 2.5873529991372988
Validation loss: 2.034665847336947
Epoch: 7| Step: 4
Training loss: 2.0622045131905886
Validation loss: 2.035690804652621
Epoch: 7| Step: 5
Training loss: 2.6464385194078504
Validation loss: 2.0320938711321515
Epoch: 7| Step: 6
Training loss: 2.3003483674308436
Validation loss: 2.029363937242878
Epoch: 7| Step: 7
Training loss: 2.035387139576371
Validation loss: 2.020264410915366
Epoch: 7| Step: 8
Training loss: 2.4802754484535416
Validation loss: 2.0341765579853766
Epoch: 7| Step: 9
Training loss: 2.5875167403854418
Validation loss: 2.0339531404988147
Epoch: 7| Step: 10
Training loss: 2.4215459784695983
Validation loss: 2.039340591739849
Epoch: 7| Step: 11
Training loss: 2.4678879210497056
Validation loss: 2.011948783062913
Epoch: 7| Step: 12
Training loss: 2.443156111180752
Validation loss: 2.039039040597527
Epoch: 7| Step: 13
Training loss: 2.4962526846896553
Validation loss: 2.0366017336714646
Epoch: 7| Step: 14
Training loss: 2.90189831525715
Validation loss: 2.0160463885749866
Epoch: 7| Step: 15
Training loss: 2.660351806264213
Validation loss: 2.0369692345338084
Epoch: 16| Step: 0
Training loss: 2.725213709159265
Validation loss: 2.030019922786297
Epoch: 7| Step: 1
Training loss: 2.2052262478621674
Validation loss: 2.034517220500577
Epoch: 7| Step: 2
Training loss: 2.143489619421021
Validation loss: 2.0212874611524887
Epoch: 7| Step: 3
Training loss: 2.454085241066896
Validation loss: 2.0424347844964275
Epoch: 7| Step: 4
Training loss: 2.2782887089937307
Validation loss: 2.0227831091752417
Epoch: 7| Step: 5
Training loss: 3.0831689704869776
Validation loss: 2.018706875973419
Epoch: 7| Step: 6
Training loss: 2.417492550007052
Validation loss: 2.0387341866100384
Epoch: 7| Step: 7
Training loss: 2.978044436346771
Validation loss: 2.033889724755188
Epoch: 7| Step: 8
Training loss: 2.870438149266102
Validation loss: 2.040008142732444
Epoch: 7| Step: 9
Training loss: 2.7294808320984725
Validation loss: 2.0363961180194354
Epoch: 7| Step: 10
Training loss: 2.7008807617781394
Validation loss: 2.0426536114238965
Epoch: 7| Step: 11
Training loss: 2.133360739869663
Validation loss: 2.0409818043676875
Epoch: 7| Step: 12
Training loss: 1.564349719950889
Validation loss: 2.0405244133430744
Epoch: 7| Step: 13
Training loss: 2.2275382062416154
Validation loss: 2.0398532599428787
Epoch: 7| Step: 14
Training loss: 2.385554902403802
Validation loss: 2.0323501438725646
Epoch: 7| Step: 15
Training loss: 2.662100956344447
Validation loss: 2.0383604534476043
Epoch: 17| Step: 0
Training loss: 2.7805177388989604
Validation loss: 2.041396716419692
Epoch: 7| Step: 1
Training loss: 3.1508236307840414
Validation loss: 2.0326406785460165
Epoch: 7| Step: 2
Training loss: 2.6650386151921115
Validation loss: 2.0412685054846342
Epoch: 7| Step: 3
Training loss: 2.019215778672464
Validation loss: 2.034704052219165
Epoch: 7| Step: 4
Training loss: 2.4724143152461586
Validation loss: 2.0438096358370315
Epoch: 7| Step: 5
Training loss: 2.437793322789578
Validation loss: 2.0296813667656246
Epoch: 7| Step: 6
Training loss: 2.6643120880896216
Validation loss: 2.0317539616465234
Epoch: 7| Step: 7
Training loss: 2.5585644902310722
Validation loss: 2.0346324401830307
Epoch: 7| Step: 8
Training loss: 2.609850628842694
Validation loss: 2.042783985127816
Epoch: 7| Step: 9
Training loss: 2.172833018705983
Validation loss: 2.0357391110279766
Epoch: 7| Step: 10
Training loss: 2.393336435154824
Validation loss: 2.0386349707605564
Epoch: 7| Step: 11
Training loss: 2.5759460489061103
Validation loss: 2.031775955851098
Epoch: 7| Step: 12
Training loss: 2.478555930000053
Validation loss: 2.039696271384161
Epoch: 7| Step: 13
Training loss: 2.6494685953773116
Validation loss: 2.031159271317127
Epoch: 7| Step: 14
Training loss: 1.9580429416463718
Validation loss: 2.025931615492809
Epoch: 7| Step: 15
Training loss: 2.1212222234270715
Validation loss: 2.031866232280355
Epoch: 18| Step: 0
Training loss: 2.4741229728659975
Validation loss: 2.0371988934646614
Epoch: 7| Step: 1
Training loss: 2.524710697181297
Validation loss: 2.021305594336472
Epoch: 7| Step: 2
Training loss: 2.0049783021509104
Validation loss: 2.047530706609415
Epoch: 7| Step: 3
Training loss: 2.379479550588982
Validation loss: 2.031818976290953
Epoch: 7| Step: 4
Training loss: 2.1201044800042363
Validation loss: 2.042958341523523
Epoch: 7| Step: 5
Training loss: 2.7541237170342345
Validation loss: 2.0314211957610406
Epoch: 7| Step: 6
Training loss: 2.681596259676025
Validation loss: 2.033168288374293
Epoch: 7| Step: 7
Training loss: 2.5619042797327896
Validation loss: 2.0406112013977498
Epoch: 7| Step: 8
Training loss: 2.599959512542053
Validation loss: 2.0146815081855554
Epoch: 7| Step: 9
Training loss: 2.7569890940841026
Validation loss: 2.0434032092432632
Epoch: 7| Step: 10
Training loss: 2.5982870841747934
Validation loss: 2.0377976290173607
Epoch: 7| Step: 11
Training loss: 2.519602598614283
Validation loss: 2.04815446161886
Epoch: 7| Step: 12
Training loss: 2.8060850948827087
Validation loss: 2.039173952922231
Epoch: 7| Step: 13
Training loss: 2.4873189697334848
Validation loss: 2.042930504200987
Epoch: 7| Step: 14
Training loss: 2.7451046808012856
Validation loss: 2.045803014134658
Epoch: 7| Step: 15
Training loss: 1.6937749544114196
Validation loss: 2.038658434059283
Epoch: 19| Step: 0
Training loss: 2.218540450395598
Validation loss: 2.037834752142875
Epoch: 7| Step: 1
Training loss: 2.058446889774536
Validation loss: 2.04348279295046
Epoch: 7| Step: 2
Training loss: 2.2322977720726875
Validation loss: 2.042138731954149
Epoch: 7| Step: 3
Training loss: 2.503087045141299
Validation loss: 2.023884625062724
Epoch: 7| Step: 4
Training loss: 2.707331388934816
Validation loss: 2.035086286525105
Epoch: 7| Step: 5
Training loss: 2.7146250684744913
Validation loss: 2.0440734528608244
Epoch: 7| Step: 6
Training loss: 2.5747982872037953
Validation loss: 2.028877679043774
Epoch: 7| Step: 7
Training loss: 2.39274134487906
Validation loss: 2.0260108761049054
Epoch: 7| Step: 8
Training loss: 2.9308279030447397
Validation loss: 2.0536345853648723
Epoch: 7| Step: 9
Training loss: 3.106336019080991
Validation loss: 2.0375523592547036
Epoch: 7| Step: 10
Training loss: 1.912340409345847
Validation loss: 2.0372753219958826
Epoch: 7| Step: 11
Training loss: 2.574218564764314
Validation loss: 2.0479451968515168
Epoch: 7| Step: 12
Training loss: 2.0087653248172095
Validation loss: 2.0452480902249794
Epoch: 7| Step: 13
Training loss: 1.52106608173146
Validation loss: 2.047257691586577
Epoch: 7| Step: 14
Training loss: 3.403076653535572
Validation loss: 2.0268021346705276
Epoch: 7| Step: 15
Training loss: 2.2879524533926827
Validation loss: 2.0316354636831475
Epoch: 20| Step: 0
Training loss: 2.6401856186664574
Validation loss: 2.047210786803641
Epoch: 7| Step: 1
Training loss: 2.740074017074917
Validation loss: 2.04111213718038
Epoch: 7| Step: 2
Training loss: 2.322402577897657
Validation loss: 2.04491244918624
Epoch: 7| Step: 3
Training loss: 3.110369652616153
Validation loss: 2.031526193025395
Epoch: 7| Step: 4
Training loss: 2.8822078742744743
Validation loss: 2.0422510506377307
Epoch: 7| Step: 5
Training loss: 1.9697550070377392
Validation loss: 2.035746107931086
Epoch: 7| Step: 6
Training loss: 2.853594998842589
Validation loss: 2.0353037439338935
Epoch: 7| Step: 7
Training loss: 2.753325618920899
Validation loss: 2.0241069100006386
Epoch: 7| Step: 8
Training loss: 2.2860192389225156
Validation loss: 2.0362955984700797
Epoch: 7| Step: 9
Training loss: 2.1613628197826977
Validation loss: 2.03831941322478
Epoch: 7| Step: 10
Training loss: 1.6938325953315725
Validation loss: 2.0421754485425927
Epoch: 7| Step: 11
Training loss: 1.6659382022876936
Validation loss: 2.0284555895992415
Epoch: 7| Step: 12
Training loss: 2.9384480022083306
Validation loss: 2.0355401916012417
Epoch: 7| Step: 13
Training loss: 3.0151222877311534
Validation loss: 2.0228870175517875
Epoch: 7| Step: 14
Training loss: 1.862192791686243
Validation loss: 2.0393517246351434
Epoch: 7| Step: 15
Training loss: 2.3068284257865486
Validation loss: 2.0186949491578168
Epoch: 21| Step: 0
Training loss: 2.527802556886428
Validation loss: 2.026939711433688
Epoch: 7| Step: 1
Training loss: 2.7229644732278344
Validation loss: 2.031610369729079
Epoch: 7| Step: 2
Training loss: 2.470387362480452
Validation loss: 2.0382350759441445
Epoch: 7| Step: 3
Training loss: 2.417353784504454
Validation loss: 2.0303049411690193
Epoch: 7| Step: 4
Training loss: 2.440545453718045
Validation loss: 2.0335899254236307
Epoch: 7| Step: 5
Training loss: 3.1288974109386696
Validation loss: 2.036811606826617
Epoch: 7| Step: 6
Training loss: 1.7537384292753753
Validation loss: 2.03313566525758
Epoch: 7| Step: 7
Training loss: 2.7019889958211927
Validation loss: 2.0295613453377883
Epoch: 7| Step: 8
Training loss: 2.3289512857704215
Validation loss: 2.03515997852976
Epoch: 7| Step: 9
Training loss: 2.5535058137921984
Validation loss: 2.0381934436996016
Epoch: 7| Step: 10
Training loss: 2.3248234835652206
Validation loss: 2.0360479011932866
Epoch: 7| Step: 11
Training loss: 2.2090014280812804
Validation loss: 2.022376829235287
Epoch: 7| Step: 12
Training loss: 2.556439000536558
Validation loss: 2.022734317711423
Epoch: 7| Step: 13
Training loss: 2.619635231600588
Validation loss: 2.0358526826474788
Epoch: 7| Step: 14
Training loss: 2.328400973150105
Validation loss: 2.0396285658554336
Epoch: 7| Step: 15
Training loss: 2.543702191177722
Validation loss: 2.0300768384072776
Epoch: 22| Step: 0
Training loss: 2.5744099061233614
Validation loss: 2.0319222984694787
Epoch: 7| Step: 1
Training loss: 2.1584366477875156
Validation loss: 2.036597305221183
Epoch: 7| Step: 2
Training loss: 1.7768191055807874
Validation loss: 2.0304412102788523
Epoch: 7| Step: 3
Training loss: 2.4240907439189274
Validation loss: 2.0350456818040796
Epoch: 7| Step: 4
Training loss: 2.24540049593519
Validation loss: 2.0240472480421254
Epoch: 7| Step: 5
Training loss: 2.4155144630398686
Validation loss: 2.038831035631235
Epoch: 7| Step: 6
Training loss: 2.386876776875136
Validation loss: 2.0293794776751035
Epoch: 7| Step: 7
Training loss: 2.1594626777393193
Validation loss: 2.0052338593782215
Epoch: 7| Step: 8
Training loss: 2.772497227274383
Validation loss: 2.053551351610635
Epoch: 7| Step: 9
Training loss: 2.5882627975308132
Validation loss: 2.0404447013047236
Epoch: 7| Step: 10
Training loss: 2.8342815009428604
Validation loss: 2.039729166578495
Epoch: 7| Step: 11
Training loss: 2.2805655510833462
Validation loss: 2.0404049754424443
Epoch: 7| Step: 12
Training loss: 2.577454635857311
Validation loss: 2.0344741544376
Epoch: 7| Step: 13
Training loss: 2.5145784653492993
Validation loss: 2.0393774046641826
Epoch: 7| Step: 14
Training loss: 3.045573734295841
Validation loss: 2.043137361830319
Epoch: 7| Step: 15
Training loss: 2.7438294801083876
Validation loss: 2.0400940775266507
Epoch: 23| Step: 0
Training loss: 2.326884201486547
Validation loss: 2.020655975769245
Epoch: 7| Step: 1
Training loss: 2.3046984656121547
Validation loss: 2.0257675464917537
Epoch: 7| Step: 2
Training loss: 2.0127282433774942
Validation loss: 2.0356070418012013
Epoch: 7| Step: 3
Training loss: 2.653600650561175
Validation loss: 2.050045251899498
Epoch: 7| Step: 4
Training loss: 2.0606724126820635
Validation loss: 2.048092596807297
Epoch: 7| Step: 5
Training loss: 3.106048952039916
Validation loss: 2.042780028101806
Epoch: 7| Step: 6
Training loss: 2.4717184641738013
Validation loss: 2.0376224779113477
Epoch: 7| Step: 7
Training loss: 2.5559618276811156
Validation loss: 2.03113612484762
Epoch: 7| Step: 8
Training loss: 2.7616805919725107
Validation loss: 2.0370954830388848
Epoch: 7| Step: 9
Training loss: 2.6040896493331247
Validation loss: 2.029777513056982
Epoch: 7| Step: 10
Training loss: 2.016056103402544
Validation loss: 2.032628418697523
Epoch: 7| Step: 11
Training loss: 2.5903963215837758
Validation loss: 2.0481832437227223
Epoch: 7| Step: 12
Training loss: 2.5529600129811785
Validation loss: 2.0318731865753947
Epoch: 7| Step: 13
Training loss: 2.615068540094288
Validation loss: 2.022769849487568
Epoch: 7| Step: 14
Training loss: 2.445767491335508
Validation loss: 2.043427770018631
Epoch: 7| Step: 15
Training loss: 2.471266417692426
Validation loss: 2.0388104238626203
Epoch: 24| Step: 0
Training loss: 2.460611279376444
Validation loss: 2.0346699492231757
Epoch: 7| Step: 1
Training loss: 3.0323232736690784
Validation loss: 2.0330766307945543
Epoch: 7| Step: 2
Training loss: 2.405312095266385
Validation loss: 2.033563807072297
Epoch: 7| Step: 3
Training loss: 1.8552871775878854
Validation loss: 2.027250884172594
Epoch: 7| Step: 4
Training loss: 2.5071775399069307
Validation loss: 2.028055617511968
Epoch: 7| Step: 5
Training loss: 2.5775829323303587
Validation loss: 2.0400420588823818
Epoch: 7| Step: 6
Training loss: 2.123176465470506
Validation loss: 2.0451331223869755
Epoch: 7| Step: 7
Training loss: 2.7197086792500027
Validation loss: 2.025056957318227
Epoch: 7| Step: 8
Training loss: 2.537763527401302
Validation loss: 2.0387737775706745
Epoch: 7| Step: 9
Training loss: 2.650341418602961
Validation loss: 2.0388106412139724
Epoch: 7| Step: 10
Training loss: 2.115077357218942
Validation loss: 2.0205606585819846
Epoch: 7| Step: 11
Training loss: 2.752093125431064
Validation loss: 2.019290115373907
Epoch: 7| Step: 12
Training loss: 2.51449502717727
Validation loss: 2.037706477202922
Epoch: 7| Step: 13
Training loss: 2.6695643913303964
Validation loss: 2.039448648492656
Epoch: 7| Step: 14
Training loss: 2.4075195134244565
Validation loss: 2.0471373672287068
Epoch: 7| Step: 15
Training loss: 2.2010802391224122
Validation loss: 2.0338996304472237
Epoch: 25| Step: 0
Training loss: 3.1839972304710726
Validation loss: 2.042883959365796
Epoch: 7| Step: 1
Training loss: 2.7369026054807297
Validation loss: 2.0383257806597115
Epoch: 7| Step: 2
Training loss: 3.0222376924318284
Validation loss: 2.0409982712330814
Epoch: 7| Step: 3
Training loss: 2.771030638895351
Validation loss: 2.037508515226206
Epoch: 7| Step: 4
Training loss: 2.3413230028395247
Validation loss: 2.012315283905392
Epoch: 7| Step: 5
Training loss: 2.4930492095252554
Validation loss: 2.030320627174825
Epoch: 7| Step: 6
Training loss: 2.6354906174809885
Validation loss: 2.0261345030761877
Epoch: 7| Step: 7
Training loss: 2.568718969895553
Validation loss: 2.0363439740066585
Epoch: 7| Step: 8
Training loss: 2.478267143184831
Validation loss: 2.0183369055821543
Epoch: 7| Step: 9
Training loss: 2.439700478320992
Validation loss: 2.027433326357466
Epoch: 7| Step: 10
Training loss: 2.3417779382444315
Validation loss: 2.012774305338586
Epoch: 7| Step: 11
Training loss: 2.2747388962364505
Validation loss: 2.0269645659810513
Epoch: 7| Step: 12
Training loss: 1.8923068171964939
Validation loss: 2.0228818483062176
Epoch: 7| Step: 13
Training loss: 2.125741380502004
Validation loss: 2.016471362957775
Epoch: 7| Step: 14
Training loss: 1.6768997123452767
Validation loss: 2.0231138259418473
Epoch: 7| Step: 15
Training loss: 2.3534710511857866
Validation loss: 2.01187229611328
Epoch: 26| Step: 0
Training loss: 2.5711568355789836
Validation loss: 2.0255537001448345
Epoch: 7| Step: 1
Training loss: 2.709604072786688
Validation loss: 2.025164298797989
Epoch: 7| Step: 2
Training loss: 1.9974627493964539
Validation loss: 2.019125935009279
Epoch: 7| Step: 3
Training loss: 2.9539248074703046
Validation loss: 2.026991270697737
Epoch: 7| Step: 4
Training loss: 2.1133663139216656
Validation loss: 2.025109786600237
Epoch: 7| Step: 5
Training loss: 1.9030988945133602
Validation loss: 2.0263959521765997
Epoch: 7| Step: 6
Training loss: 2.6497536598725198
Validation loss: 2.023470739243413
Epoch: 7| Step: 7
Training loss: 2.8210527711277917
Validation loss: 2.0286520199790767
Epoch: 7| Step: 8
Training loss: 1.9819462247842148
Validation loss: 2.0331437065039464
Epoch: 7| Step: 9
Training loss: 1.9267901085816472
Validation loss: 2.020417554621377
Epoch: 7| Step: 10
Training loss: 2.676994638915709
Validation loss: 2.024220135938326
Epoch: 7| Step: 11
Training loss: 2.7605894982315973
Validation loss: 2.0316863141769863
Epoch: 7| Step: 12
Training loss: 2.7240382535940015
Validation loss: 2.0222144851442474
Epoch: 7| Step: 13
Training loss: 2.297608135281242
Validation loss: 2.0379467748066493
Epoch: 7| Step: 14
Training loss: 2.491771029409924
Validation loss: 2.0411024062188656
Epoch: 7| Step: 15
Training loss: 2.793852552882803
Validation loss: 2.029754365451082
Epoch: 27| Step: 0
Training loss: 2.385806844415248
Validation loss: 2.0353012936970587
Epoch: 7| Step: 1
Training loss: 2.7082369762788185
Validation loss: 2.021925218690813
Epoch: 7| Step: 2
Training loss: 2.5417153921824482
Validation loss: 2.0208078241362593
Epoch: 7| Step: 3
Training loss: 2.206369486482844
Validation loss: 2.038027119414537
Epoch: 7| Step: 4
Training loss: 2.221999247278726
Validation loss: 2.036914848117564
Epoch: 7| Step: 5
Training loss: 1.8901823802528386
Validation loss: 2.0272886161953982
Epoch: 7| Step: 6
Training loss: 2.812025242047813
Validation loss: 2.030725550017102
Epoch: 7| Step: 7
Training loss: 2.539876672348913
Validation loss: 2.0332712384268765
Epoch: 7| Step: 8
Training loss: 2.615285244732574
Validation loss: 2.032848597825377
Epoch: 7| Step: 9
Training loss: 2.791775706045346
Validation loss: 2.0439150273425164
Epoch: 7| Step: 10
Training loss: 2.5867112952573983
Validation loss: 2.0430082756747727
Epoch: 7| Step: 11
Training loss: 2.3493105221866655
Validation loss: 2.0457484967157367
Epoch: 7| Step: 12
Training loss: 2.101005168314718
Validation loss: 2.038212490324741
Epoch: 7| Step: 13
Training loss: 2.4314167700989096
Validation loss: 2.0347670584101794
Epoch: 7| Step: 14
Training loss: 2.9413991170647247
Validation loss: 2.0430450528634134
Epoch: 7| Step: 15
Training loss: 2.330080171441893
Validation loss: 2.0290481548630366
Epoch: 28| Step: 0
Training loss: 2.645383080646654
Validation loss: 2.0332795165781765
Epoch: 7| Step: 1
Training loss: 2.4202101368741555
Validation loss: 2.0290382435894023
Epoch: 7| Step: 2
Training loss: 2.537009668189705
Validation loss: 2.019161968041709
Epoch: 7| Step: 3
Training loss: 2.4834051578384297
Validation loss: 2.033428704763328
Epoch: 7| Step: 4
Training loss: 2.173728316792844
Validation loss: 2.0401518840294246
Epoch: 7| Step: 5
Training loss: 2.6438421030436774
Validation loss: 2.0426133205836567
Epoch: 7| Step: 6
Training loss: 2.836103113976625
Validation loss: 2.026473907524284
Epoch: 7| Step: 7
Training loss: 2.1911420747908945
Validation loss: 2.0403407181976565
Epoch: 7| Step: 8
Training loss: 2.4919281349229077
Validation loss: 2.020807145986969
Epoch: 7| Step: 9
Training loss: 2.374416179174377
Validation loss: 2.036624453041835
Epoch: 7| Step: 10
Training loss: 2.3631155917533517
Validation loss: 2.0260704177521944
Epoch: 7| Step: 11
Training loss: 2.4191540599901438
Validation loss: 2.029598961986892
Epoch: 7| Step: 12
Training loss: 2.077250361127704
Validation loss: 2.0280606799233203
Epoch: 7| Step: 13
Training loss: 2.795344440070893
Validation loss: 2.007467521695871
Epoch: 7| Step: 14
Training loss: 1.9033624635572788
Validation loss: 2.0279385366142937
Epoch: 7| Step: 15
Training loss: 3.108914901967531
Validation loss: 2.035311055629514
Epoch: 29| Step: 0
Training loss: 2.455587135541481
Validation loss: 2.02890509698851
Epoch: 7| Step: 1
Training loss: 2.0777407412817843
Validation loss: 2.0275025295334763
Epoch: 7| Step: 2
Training loss: 2.3198387612842692
Validation loss: 2.0428556432350535
Epoch: 7| Step: 3
Training loss: 2.3017618521588967
Validation loss: 2.0348506738449545
Epoch: 7| Step: 4
Training loss: 2.650743768788488
Validation loss: 2.0372434567277877
Epoch: 7| Step: 5
Training loss: 2.578794635158974
Validation loss: 2.0286835450373055
Epoch: 7| Step: 6
Training loss: 3.080399810305962
Validation loss: 2.039341097403788
Epoch: 7| Step: 7
Training loss: 2.4515526464396764
Validation loss: 2.0363524368932335
Epoch: 7| Step: 8
Training loss: 2.116422282651413
Validation loss: 2.037919386964452
Epoch: 7| Step: 9
Training loss: 1.7307479323193373
Validation loss: 2.0015865358755494
Epoch: 7| Step: 10
Training loss: 2.675810653636346
Validation loss: 2.039742059747204
Epoch: 7| Step: 11
Training loss: 2.646681301771517
Validation loss: 2.0298924994874468
Epoch: 7| Step: 12
Training loss: 2.295324619746817
Validation loss: 2.034516067882832
Epoch: 7| Step: 13
Training loss: 3.473848050419705
Validation loss: 2.039823881392111
Epoch: 7| Step: 14
Training loss: 2.152529284447497
Validation loss: 2.0309026261593908
Epoch: 7| Step: 15
Training loss: 2.124666748843248
Validation loss: 2.0315258434993693
Epoch: 30| Step: 0
Training loss: 2.190784712994731
Validation loss: 2.0207933731239858
Epoch: 7| Step: 1
Training loss: 2.965453877953678
Validation loss: 2.039717939165904
Epoch: 7| Step: 2
Training loss: 2.3854922375653667
Validation loss: 2.039919382597141
Epoch: 7| Step: 3
Training loss: 2.6624237121255105
Validation loss: 2.0307866805545163
Epoch: 7| Step: 4
Training loss: 2.3857528804956334
Validation loss: 2.027702433353593
Epoch: 7| Step: 5
Training loss: 1.993289478174678
Validation loss: 2.028135234839874
Epoch: 7| Step: 6
Training loss: 2.957024316011107
Validation loss: 2.0362291513402133
Epoch: 7| Step: 7
Training loss: 2.469166201504438
Validation loss: 2.0302630993143467
Epoch: 7| Step: 8
Training loss: 2.6332782820085776
Validation loss: 2.01911939213307
Epoch: 7| Step: 9
Training loss: 2.0798502479344534
Validation loss: 2.0215045572344748
Epoch: 7| Step: 10
Training loss: 2.1386301811717816
Validation loss: 2.0328762491489667
Epoch: 7| Step: 11
Training loss: 2.5975079257466005
Validation loss: 2.029754150521242
Epoch: 7| Step: 12
Training loss: 2.708301328812303
Validation loss: 2.011333387887663
Epoch: 7| Step: 13
Training loss: 2.593653665615015
Validation loss: 2.0276591773226333
Epoch: 7| Step: 14
Training loss: 2.5135175513828463
Validation loss: 2.0250853524847545
Epoch: 7| Step: 15
Training loss: 2.1553648085383927
Validation loss: 2.0309880314916673
Epoch: 31| Step: 0
Training loss: 2.2080173146356796
Validation loss: 2.031406018692026
Epoch: 7| Step: 1
Training loss: 2.7036730260381105
Validation loss: 2.031984775996334
Epoch: 7| Step: 2
Training loss: 2.112719561661705
Validation loss: 2.024257360717217
Epoch: 7| Step: 3
Training loss: 2.6119303725690473
Validation loss: 2.0351234770597153
Epoch: 7| Step: 4
Training loss: 2.3631631112323386
Validation loss: 2.0286333583820704
Epoch: 7| Step: 5
Training loss: 2.4204249809631486
Validation loss: 2.00545398995422
Epoch: 7| Step: 6
Training loss: 1.6539182984170484
Validation loss: 2.020984547066953
Epoch: 7| Step: 7
Training loss: 2.5789791657344736
Validation loss: 2.0248587993752385
Epoch: 7| Step: 8
Training loss: 2.27690222305832
Validation loss: 2.0293014795347535
Epoch: 7| Step: 9
Training loss: 2.1826643765871916
Validation loss: 2.0433621395901884
Epoch: 7| Step: 10
Training loss: 2.6447892619589446
Validation loss: 2.0410492296983493
Epoch: 7| Step: 11
Training loss: 3.0272412092008927
Validation loss: 2.004587761795078
Epoch: 7| Step: 12
Training loss: 2.5924107414631683
Validation loss: 2.0401836339630717
Epoch: 7| Step: 13
Training loss: 2.4753011385427324
Validation loss: 2.0283958785751186
Epoch: 7| Step: 14
Training loss: 2.964236713733224
Validation loss: 2.01685187804651
Epoch: 7| Step: 15
Training loss: 2.4527997815748543
Validation loss: 2.0148952677641185
Epoch: 32| Step: 0
Training loss: 2.41122981417499
Validation loss: 2.0360711626765946
Epoch: 7| Step: 1
Training loss: 2.7374909875451405
Validation loss: 2.010024595300114
Epoch: 7| Step: 2
Training loss: 2.9188270378973544
Validation loss: 2.028170219866404
Epoch: 7| Step: 3
Training loss: 2.4067967772074406
Validation loss: 2.0172988554175477
Epoch: 7| Step: 4
Training loss: 2.3468685510701697
Validation loss: 2.0282873024784953
Epoch: 7| Step: 5
Training loss: 2.434025366457405
Validation loss: 2.042470162110178
Epoch: 7| Step: 6
Training loss: 2.7796601455483287
Validation loss: 1.999352487951927
Epoch: 7| Step: 7
Training loss: 2.514815206090195
Validation loss: 2.018172332049905
Epoch: 7| Step: 8
Training loss: 2.191636017366293
Validation loss: 2.0177686191902966
Epoch: 7| Step: 9
Training loss: 2.3118317128151187
Validation loss: 2.0303468511934044
Epoch: 7| Step: 10
Training loss: 2.405541749238687
Validation loss: 2.028481751647212
Epoch: 7| Step: 11
Training loss: 2.1266269065863184
Validation loss: 2.0176551953523494
Epoch: 7| Step: 12
Training loss: 2.371434999447382
Validation loss: 2.0305979572189883
Epoch: 7| Step: 13
Training loss: 2.5577089133752264
Validation loss: 2.0372029137372176
Epoch: 7| Step: 14
Training loss: 2.543388742199138
Validation loss: 2.0334967353340505
Epoch: 7| Step: 15
Training loss: 2.4824470380682775
Validation loss: 2.0152836928355895
Epoch: 33| Step: 0
Training loss: 2.1694734317711495
Validation loss: 2.0355800009972387
Epoch: 7| Step: 1
Training loss: 2.4447653648891485
Validation loss: 2.0239836229489754
Epoch: 7| Step: 2
Training loss: 2.8382881447970547
Validation loss: 2.0434741703456294
Epoch: 7| Step: 3
Training loss: 2.973325716644704
Validation loss: 2.0169272632188715
Epoch: 7| Step: 4
Training loss: 2.6728801063738934
Validation loss: 2.0070123514155
Epoch: 7| Step: 5
Training loss: 2.540268080674143
Validation loss: 2.0307206654863683
Epoch: 7| Step: 6
Training loss: 1.9470804905096855
Validation loss: 2.0243131399133265
Epoch: 7| Step: 7
Training loss: 2.5456242210636124
Validation loss: 2.033914438643453
Epoch: 7| Step: 8
Training loss: 2.553897187131413
Validation loss: 2.01750400553573
Epoch: 7| Step: 9
Training loss: 2.754586037137419
Validation loss: 2.0262743936340644
Epoch: 7| Step: 10
Training loss: 2.4206057268080157
Validation loss: 2.027263390527788
Epoch: 7| Step: 11
Training loss: 1.9005400392107794
Validation loss: 2.0082685474417343
Epoch: 7| Step: 12
Training loss: 2.6528087989187243
Validation loss: 2.0330087015219878
Epoch: 7| Step: 13
Training loss: 2.3077785646995084
Validation loss: 2.023744269381293
Epoch: 7| Step: 14
Training loss: 2.2268004173189335
Validation loss: 2.0253405024577913
Epoch: 7| Step: 15
Training loss: 2.3922116867028724
Validation loss: 2.0293331813468756
Epoch: 34| Step: 0
Training loss: 2.256987212990373
Validation loss: 2.0343222094806803
Epoch: 7| Step: 1
Training loss: 2.7979395880840805
Validation loss: 2.0315291806462334
Epoch: 7| Step: 2
Training loss: 2.3764259675363144
Validation loss: 2.03810993337191
Epoch: 7| Step: 3
Training loss: 2.68019521813582
Validation loss: 2.0299517625957133
Epoch: 7| Step: 4
Training loss: 1.9327613965666712
Validation loss: 2.0177656676568194
Epoch: 7| Step: 5
Training loss: 2.6034074719365967
Validation loss: 2.0250219945368317
Epoch: 7| Step: 6
Training loss: 2.3822764309583713
Validation loss: 2.019446823102538
Epoch: 7| Step: 7
Training loss: 2.5240347424154863
Validation loss: 2.0307897588370927
Epoch: 7| Step: 8
Training loss: 2.233905662914892
Validation loss: 2.034172847346604
Epoch: 7| Step: 9
Training loss: 2.638992978993364
Validation loss: 2.026652422582426
Epoch: 7| Step: 10
Training loss: 2.244444239755921
Validation loss: 2.0083200263454906
Epoch: 7| Step: 11
Training loss: 2.622515092629931
Validation loss: 2.025893360266668
Epoch: 7| Step: 12
Training loss: 2.3761538664000406
Validation loss: 2.0210494667437744
Epoch: 7| Step: 13
Training loss: 2.3498307755596124
Validation loss: 2.020138175286119
Epoch: 7| Step: 14
Training loss: 3.107172813960142
Validation loss: 2.0221881885006607
Epoch: 7| Step: 15
Training loss: 2.1711259826485745
Validation loss: 2.0206060927354628
Epoch: 35| Step: 0
Training loss: 2.391226300183436
Validation loss: 2.005982383044784
Epoch: 7| Step: 1
Training loss: 2.1159095426308836
Validation loss: 2.0147881021678247
Epoch: 7| Step: 2
Training loss: 2.112470827521968
Validation loss: 2.04273109046822
Epoch: 7| Step: 3
Training loss: 2.2148607579676556
Validation loss: 2.0206407545814007
Epoch: 7| Step: 4
Training loss: 2.3712924327281257
Validation loss: 2.0207535753410233
Epoch: 7| Step: 5
Training loss: 2.6185365758340504
Validation loss: 2.0271222220724137
Epoch: 7| Step: 6
Training loss: 2.6107479298302225
Validation loss: 2.021647275309031
Epoch: 7| Step: 7
Training loss: 2.6382856672282204
Validation loss: 2.002998483963829
Epoch: 7| Step: 8
Training loss: 2.683204678201663
Validation loss: 2.0186261497731532
Epoch: 7| Step: 9
Training loss: 2.565781422910016
Validation loss: 2.0296449433468218
Epoch: 7| Step: 10
Training loss: 1.8821553076572437
Validation loss: 2.0300924245875698
Epoch: 7| Step: 11
Training loss: 2.359224529394444
Validation loss: 2.0137380775147076
Epoch: 7| Step: 12
Training loss: 2.7023512774823337
Validation loss: 2.0294442735875546
Epoch: 7| Step: 13
Training loss: 2.4052508372872454
Validation loss: 2.012371680676257
Epoch: 7| Step: 14
Training loss: 2.549080858818033
Validation loss: 2.027815991691887
Epoch: 7| Step: 15
Training loss: 3.080295010842436
Validation loss: 2.0228766682312718
Epoch: 36| Step: 0
Training loss: 2.2029899393441545
Validation loss: 2.0318738750670207
Epoch: 7| Step: 1
Training loss: 2.324922137853765
Validation loss: 2.033420140354883
Epoch: 7| Step: 2
Training loss: 1.8105965188801474
Validation loss: 2.0119398158875557
Epoch: 7| Step: 3
Training loss: 2.767926826127259
Validation loss: 2.0093651181747276
Epoch: 7| Step: 4
Training loss: 2.3667770382392535
Validation loss: 2.022078831815786
Epoch: 7| Step: 5
Training loss: 2.3388299799689194
Validation loss: 2.0253425423201126
Epoch: 7| Step: 6
Training loss: 2.483522472816753
Validation loss: 2.042050568689102
Epoch: 7| Step: 7
Training loss: 2.702425827716476
Validation loss: 2.0399632210553476
Epoch: 7| Step: 8
Training loss: 2.7560381922573924
Validation loss: 2.0252582916683597
Epoch: 7| Step: 9
Training loss: 2.094474780905495
Validation loss: 2.0309600409050272
Epoch: 7| Step: 10
Training loss: 2.7990096486570293
Validation loss: 2.01886292211476
Epoch: 7| Step: 11
Training loss: 2.7196318851339436
Validation loss: 2.0392349767879754
Epoch: 7| Step: 12
Training loss: 2.6765234593062233
Validation loss: 2.027550856249478
Epoch: 7| Step: 13
Training loss: 2.5030452301230492
Validation loss: 2.0223704811304772
Epoch: 7| Step: 14
Training loss: 2.6497923499749634
Validation loss: 2.0168944832105167
Epoch: 7| Step: 15
Training loss: 2.1176067092111888
Validation loss: 2.032274973611976
Epoch: 37| Step: 0
Training loss: 2.6162938656253036
Validation loss: 2.0222291851302416
Epoch: 7| Step: 1
Training loss: 2.0517286455640464
Validation loss: 2.0308961215877015
Epoch: 7| Step: 2
Training loss: 2.978198625549118
Validation loss: 2.022219796834931
Epoch: 7| Step: 3
Training loss: 2.117157432652331
Validation loss: 2.0278774491137295
Epoch: 7| Step: 4
Training loss: 2.7637887667141605
Validation loss: 2.038240881938409
Epoch: 7| Step: 5
Training loss: 1.7455616936163278
Validation loss: 2.033492605997969
Epoch: 7| Step: 6
Training loss: 2.799553552866498
Validation loss: 2.0198298562991606
Epoch: 7| Step: 7
Training loss: 2.0930058309780937
Validation loss: 2.012976177425734
Epoch: 7| Step: 8
Training loss: 2.271720316368364
Validation loss: 2.0373473366791
Epoch: 7| Step: 9
Training loss: 2.2053265765285346
Validation loss: 2.0301833474409903
Epoch: 7| Step: 10
Training loss: 3.008343221237826
Validation loss: 2.0454912785705686
Epoch: 7| Step: 11
Training loss: 2.857892762272478
Validation loss: 2.0368199089761445
Epoch: 7| Step: 12
Training loss: 2.2888817829754267
Validation loss: 2.037899935780728
Epoch: 7| Step: 13
Training loss: 2.568508175792904
Validation loss: 2.0401724943252844
Epoch: 7| Step: 14
Training loss: 2.3264246113882874
Validation loss: 2.0332515971930296
Epoch: 7| Step: 15
Training loss: 2.4247379240015925
Validation loss: 1.9952212710880008
Epoch: 38| Step: 0
Training loss: 2.6247594814011204
Validation loss: 2.0379212458475373
Epoch: 7| Step: 1
Training loss: 2.362411364149075
Validation loss: 2.0389775954428115
Epoch: 7| Step: 2
Training loss: 2.5200421901985806
Validation loss: 2.012608376848657
Epoch: 7| Step: 3
Training loss: 2.456123414793876
Validation loss: 2.030850695763999
Epoch: 7| Step: 4
Training loss: 2.3959731572578797
Validation loss: 2.0122802435878615
Epoch: 7| Step: 5
Training loss: 2.6395360744212963
Validation loss: 2.0186734889006552
Epoch: 7| Step: 6
Training loss: 2.0364533901561117
Validation loss: 2.0183572775656717
Epoch: 7| Step: 7
Training loss: 1.6910169474983638
Validation loss: 2.033956309758768
Epoch: 7| Step: 8
Training loss: 2.839118623572432
Validation loss: 2.033380056577715
Epoch: 7| Step: 9
Training loss: 1.9968880045531525
Validation loss: 2.023252438608203
Epoch: 7| Step: 10
Training loss: 2.37950079242447
Validation loss: 2.0292384985996947
Epoch: 7| Step: 11
Training loss: 2.773836864677384
Validation loss: 2.030379834186103
Epoch: 7| Step: 12
Training loss: 2.8592205735493734
Validation loss: 2.0207798796271845
Epoch: 7| Step: 13
Training loss: 2.7975212501352864
Validation loss: 2.027984765218639
Epoch: 7| Step: 14
Training loss: 2.355041060201107
Validation loss: 2.0258904360372774
Epoch: 7| Step: 15
Training loss: 2.4849006528587085
Validation loss: 2.022523645507924
Epoch: 39| Step: 0
Training loss: 2.357975424666788
Validation loss: 2.0286637712124946
Epoch: 7| Step: 1
Training loss: 2.0809158286028726
Validation loss: 2.04040905080014
Epoch: 7| Step: 2
Training loss: 2.425786360828956
Validation loss: 2.0147265270473618
Epoch: 7| Step: 3
Training loss: 2.668930572904552
Validation loss: 2.032606106287921
Epoch: 7| Step: 4
Training loss: 2.505364860567061
Validation loss: 2.013596386846315
Epoch: 7| Step: 5
Training loss: 2.5172494891328414
Validation loss: 2.0350501382262465
Epoch: 7| Step: 6
Training loss: 2.4114879718933757
Validation loss: 2.0253531050850415
Epoch: 7| Step: 7
Training loss: 2.4531065338800393
Validation loss: 2.0311146488923715
Epoch: 7| Step: 8
Training loss: 2.6114778554212306
Validation loss: 2.020328345884511
Epoch: 7| Step: 9
Training loss: 2.0174343061564564
Validation loss: 2.0253261494695973
Epoch: 7| Step: 10
Training loss: 2.6432067168586864
Validation loss: 2.028470219727092
Epoch: 7| Step: 11
Training loss: 2.5853979925136485
Validation loss: 2.017150281456472
Epoch: 7| Step: 12
Training loss: 2.6309734679406342
Validation loss: 2.0237323996095946
Epoch: 7| Step: 13
Training loss: 2.415794368595028
Validation loss: 2.021457868857663
Epoch: 7| Step: 14
Training loss: 2.5552057796257643
Validation loss: 2.0346148314265595
Epoch: 7| Step: 15
Training loss: 2.486745794774196
Validation loss: 2.0242962369820274
Epoch: 40| Step: 0
Training loss: 3.121265468719491
Validation loss: 2.028378481536093
Epoch: 7| Step: 1
Training loss: 2.63855856674049
Validation loss: 2.0332243088492348
Epoch: 7| Step: 2
Training loss: 2.0677018890152317
Validation loss: 2.027603596031748
Epoch: 7| Step: 3
Training loss: 2.6502193432126844
Validation loss: 2.029727324386647
Epoch: 7| Step: 4
Training loss: 2.0637618164241776
Validation loss: 2.012864341380831
Epoch: 7| Step: 5
Training loss: 2.6695253626105697
Validation loss: 2.023006767316542
Epoch: 7| Step: 6
Training loss: 2.1969286851034604
Validation loss: 2.03177051724161
Epoch: 7| Step: 7
Training loss: 2.8753283769243616
Validation loss: 2.0195982107849475
Epoch: 7| Step: 8
Training loss: 2.023380823704019
Validation loss: 2.0250163963313867
Epoch: 7| Step: 9
Training loss: 2.452317317493291
Validation loss: 2.0219014557505846
Epoch: 7| Step: 10
Training loss: 2.5455648410730816
Validation loss: 2.0313149643503245
Epoch: 7| Step: 11
Training loss: 2.241828384616672
Validation loss: 2.020831321306466
Epoch: 7| Step: 12
Training loss: 2.8243182786047827
Validation loss: 2.0249528551648233
Epoch: 7| Step: 13
Training loss: 2.743776648876449
Validation loss: 2.029034911557406
Epoch: 7| Step: 14
Training loss: 2.467387052538558
Validation loss: 2.0316508725729094
Epoch: 7| Step: 15
Training loss: 1.3990398793184344
Validation loss: 2.0294953192955743
Epoch: 41| Step: 0
Training loss: 2.245480873415482
Validation loss: 2.027096026957749
Epoch: 7| Step: 1
Training loss: 2.4039055438407924
Validation loss: 2.0272281119944515
Epoch: 7| Step: 2
Training loss: 2.3915917928674486
Validation loss: 2.014263033553046
Epoch: 7| Step: 3
Training loss: 2.567146090117224
Validation loss: 2.026603752736009
Epoch: 7| Step: 4
Training loss: 2.1525691584200044
Validation loss: 2.024646702134518
Epoch: 7| Step: 5
Training loss: 2.939717693398862
Validation loss: 2.028357321993573
Epoch: 7| Step: 6
Training loss: 2.6267778643034845
Validation loss: 2.0249001344824076
Epoch: 7| Step: 7
Training loss: 1.9950753616975323
Validation loss: 2.025767491293551
Epoch: 7| Step: 8
Training loss: 2.9138978804247664
Validation loss: 2.0276998348569784
Epoch: 7| Step: 9
Training loss: 2.2929078180122846
Validation loss: 2.022882552035843
Epoch: 7| Step: 10
Training loss: 2.6565594661180625
Validation loss: 2.031813425524236
Epoch: 7| Step: 11
Training loss: 2.361093665663154
Validation loss: 2.0321671937511647
Epoch: 7| Step: 12
Training loss: 2.1504555951385274
Validation loss: 2.0078297014621724
Epoch: 7| Step: 13
Training loss: 2.6600506687357854
Validation loss: 2.037928836179899
Epoch: 7| Step: 14
Training loss: 2.372953235678238
Validation loss: 2.0161164630447366
Epoch: 7| Step: 15
Training loss: 2.469613129592807
Validation loss: 2.0206022993149935
Epoch: 42| Step: 0
Training loss: 2.2661022867414014
Validation loss: 2.031212817759455
Epoch: 7| Step: 1
Training loss: 2.4148945285045618
Validation loss: 2.0216656558686816
Epoch: 7| Step: 2
Training loss: 2.0492210629588667
Validation loss: 2.0291050732102867
Epoch: 7| Step: 3
Training loss: 2.655017521974608
Validation loss: 2.0256165637054364
Epoch: 7| Step: 4
Training loss: 2.4309204505825663
Validation loss: 2.030685213885938
Epoch: 7| Step: 5
Training loss: 2.4436825325864975
Validation loss: 2.012935092628725
Epoch: 7| Step: 6
Training loss: 2.0715915399720783
Validation loss: 2.032182190922804
Epoch: 7| Step: 7
Training loss: 2.607665272757156
Validation loss: 2.025202112152706
Epoch: 7| Step: 8
Training loss: 2.3573487530408257
Validation loss: 2.0239561228438716
Epoch: 7| Step: 9
Training loss: 2.558940555277104
Validation loss: 2.0213260779073665
Epoch: 7| Step: 10
Training loss: 2.726592142987814
Validation loss: 2.0350967814732286
Epoch: 7| Step: 11
Training loss: 2.470030633527934
Validation loss: 2.010893171193632
Epoch: 7| Step: 12
Training loss: 2.4484523322380993
Validation loss: 2.014909032100113
Epoch: 7| Step: 13
Training loss: 2.754638401401016
Validation loss: 2.015854725858339
Epoch: 7| Step: 14
Training loss: 2.5331132412554482
Validation loss: 2.0315914502024404
Epoch: 7| Step: 15
Training loss: 2.5302755104801427
Validation loss: 2.0324576125409086
Epoch: 43| Step: 0
Training loss: 2.1783712371042423
Validation loss: 2.027769019330101
Epoch: 7| Step: 1
Training loss: 2.5254932450570635
Validation loss: 2.0311760896234907
Epoch: 7| Step: 2
Training loss: 2.7567888905169076
Validation loss: 2.0258307685616512
Epoch: 7| Step: 3
Training loss: 2.4288224523303157
Validation loss: 2.0217142238565775
Epoch: 7| Step: 4
Training loss: 2.2986646673513924
Validation loss: 2.015453965962915
Epoch: 7| Step: 5
Training loss: 2.86652634816925
Validation loss: 2.0188971287260085
Epoch: 7| Step: 6
Training loss: 2.911650695087348
Validation loss: 2.028947674239791
Epoch: 7| Step: 7
Training loss: 2.8974986239439073
Validation loss: 2.027912060582053
Epoch: 7| Step: 8
Training loss: 2.7798377748538483
Validation loss: 2.0283129378934337
Epoch: 7| Step: 9
Training loss: 2.4093094239173602
Validation loss: 2.024967059821199
Epoch: 7| Step: 10
Training loss: 2.2477928568271963
Validation loss: 2.028016234746401
Epoch: 7| Step: 11
Training loss: 2.209781303977267
Validation loss: 2.020165743661433
Epoch: 7| Step: 12
Training loss: 2.0991820286391487
Validation loss: 2.0222509905027937
Epoch: 7| Step: 13
Training loss: 2.2579974986384332
Validation loss: 2.035497492079387
Epoch: 7| Step: 14
Training loss: 1.7637727862750956
Validation loss: 2.0217126542847006
Epoch: 7| Step: 15
Training loss: 2.4886666902156693
Validation loss: 2.0305263077392524
Epoch: 44| Step: 0
Training loss: 2.535785708582465
Validation loss: 2.0008823281888413
Epoch: 7| Step: 1
Training loss: 2.3173784914229625
Validation loss: 2.0240040360537663
Epoch: 7| Step: 2
Training loss: 2.5310399474597802
Validation loss: 2.018382940138487
Epoch: 7| Step: 3
Training loss: 2.9349688724251393
Validation loss: 2.0333705124694097
Epoch: 7| Step: 4
Training loss: 2.302291503976203
Validation loss: 2.0295907270106834
Epoch: 7| Step: 5
Training loss: 2.5756661451571308
Validation loss: 2.0273500689841724
Epoch: 7| Step: 6
Training loss: 2.1311024947595003
Validation loss: 2.018278919837286
Epoch: 7| Step: 7
Training loss: 2.9084098747550615
Validation loss: 2.0305725738601277
Epoch: 7| Step: 8
Training loss: 2.1639816324156103
Validation loss: 2.0300596882091138
Epoch: 7| Step: 9
Training loss: 2.2166224205171163
Validation loss: 2.0276797281122123
Epoch: 7| Step: 10
Training loss: 2.3772926307520037
Validation loss: 2.029483140047941
Epoch: 7| Step: 11
Training loss: 2.289471794746113
Validation loss: 2.0055757521606568
Epoch: 7| Step: 12
Training loss: 2.405029482749999
Validation loss: 2.010385033064632
Epoch: 7| Step: 13
Training loss: 2.63186066851205
Validation loss: 2.0141657216012203
Epoch: 7| Step: 14
Training loss: 2.3764451298269282
Validation loss: 2.0304490840404954
Epoch: 7| Step: 15
Training loss: 2.474590298429331
Validation loss: 2.0274752310686637
Epoch: 45| Step: 0
Training loss: 2.714945883167665
Validation loss: 2.025862167288952
Epoch: 7| Step: 1
Training loss: 2.4353524553390775
Validation loss: 2.030917570490807
Epoch: 7| Step: 2
Training loss: 2.855558088708027
Validation loss: 2.0388994649607146
Epoch: 7| Step: 3
Training loss: 2.5650449071451726
Validation loss: 2.0346524914528263
Epoch: 7| Step: 4
Training loss: 2.1641262885101806
Validation loss: 2.0128158183629936
Epoch: 7| Step: 5
Training loss: 1.9497793610777516
Validation loss: 2.0143996101352575
Epoch: 7| Step: 6
Training loss: 2.188564041752001
Validation loss: 2.020366306752011
Epoch: 7| Step: 7
Training loss: 2.622516729048763
Validation loss: 2.0350707274573465
Epoch: 7| Step: 8
Training loss: 2.787730008202518
Validation loss: 2.023202824580828
Epoch: 7| Step: 9
Training loss: 2.604603773944203
Validation loss: 2.0028083004814548
Epoch: 7| Step: 10
Training loss: 2.461571602644101
Validation loss: 2.0191382593421925
Epoch: 7| Step: 11
Training loss: 2.8756893824148153
Validation loss: 2.0257672324209977
Epoch: 7| Step: 12
Training loss: 2.1732267934432765
Validation loss: 2.0112331834663078
Epoch: 7| Step: 13
Training loss: 2.593605313229634
Validation loss: 2.008668489967462
Epoch: 7| Step: 14
Training loss: 1.786124136076179
Validation loss: 2.024044830208727
Epoch: 7| Step: 15
Training loss: 2.380554730496683
Validation loss: 2.009283058138718
Epoch: 46| Step: 0
Training loss: 2.7073468881640497
Validation loss: 2.0264179846806476
Epoch: 7| Step: 1
Training loss: 2.131168276654659
Validation loss: 2.036351988531015
Epoch: 7| Step: 2
Training loss: 2.2593125372941025
Validation loss: 2.021327909620131
Epoch: 7| Step: 3
Training loss: 2.0956901557002006
Validation loss: 2.0141150473781084
Epoch: 7| Step: 4
Training loss: 2.326325098431543
Validation loss: 2.0054355986568417
Epoch: 7| Step: 5
Training loss: 2.441977472237316
Validation loss: 2.0131372514926356
Epoch: 7| Step: 6
Training loss: 2.170788280388086
Validation loss: 1.9986911580012352
Epoch: 7| Step: 7
Training loss: 3.1994770397585124
Validation loss: 2.025025452938272
Epoch: 7| Step: 8
Training loss: 2.4005463614044102
Validation loss: 2.0016057888318692
Epoch: 7| Step: 9
Training loss: 2.531556475888459
Validation loss: 2.016554466833197
Epoch: 7| Step: 10
Training loss: 2.9680578127574613
Validation loss: 2.0096284315607638
Epoch: 7| Step: 11
Training loss: 2.1371486308097802
Validation loss: 2.006716335147288
Epoch: 7| Step: 12
Training loss: 2.5899589133225596
Validation loss: 2.020223198827603
Epoch: 7| Step: 13
Training loss: 2.282128778794152
Validation loss: 2.016837114220479
Epoch: 7| Step: 14
Training loss: 2.3748853555414695
Validation loss: 2.010314160047156
Epoch: 7| Step: 15
Training loss: 2.47829581173488
Validation loss: 2.017281365653769
Epoch: 47| Step: 0
Training loss: 2.3438926144761414
Validation loss: 2.0340044990893764
Epoch: 7| Step: 1
Training loss: 2.5361240696747167
Validation loss: 2.0214350038642173
Epoch: 7| Step: 2
Training loss: 2.4030102805347533
Validation loss: 2.0317827487790785
Epoch: 7| Step: 3
Training loss: 2.1910018139705
Validation loss: 2.0282424995641914
Epoch: 7| Step: 4
Training loss: 2.445434957247269
Validation loss: 2.0261909789853503
Epoch: 7| Step: 5
Training loss: 2.3941966782983806
Validation loss: 2.0297016574475797
Epoch: 7| Step: 6
Training loss: 2.79256623041883
Validation loss: 2.041554692018893
Epoch: 7| Step: 7
Training loss: 2.8642702983554145
Validation loss: 2.0234871566092614
Epoch: 7| Step: 8
Training loss: 2.4342789519610717
Validation loss: 2.0350921005023177
Epoch: 7| Step: 9
Training loss: 2.328937875046042
Validation loss: 2.0354961523986272
Epoch: 7| Step: 10
Training loss: 2.7969961299985395
Validation loss: 2.032099402248091
Epoch: 7| Step: 11
Training loss: 2.435526219871567
Validation loss: 2.014458848116003
Epoch: 7| Step: 12
Training loss: 2.518096467985792
Validation loss: 2.035266433937671
Epoch: 7| Step: 13
Training loss: 2.538696826131905
Validation loss: 2.0266744099680185
Epoch: 7| Step: 14
Training loss: 2.456378116129896
Validation loss: 2.0301064130312145
Epoch: 7| Step: 15
Training loss: 1.7060152779685502
Validation loss: 2.033951185049218
Epoch: 48| Step: 0
Training loss: 2.951189001956424
Validation loss: 2.03251127329544
Epoch: 7| Step: 1
Training loss: 1.856892057922757
Validation loss: 2.024761806121792
Epoch: 7| Step: 2
Training loss: 2.123291450738177
Validation loss: 2.0316381419558653
Epoch: 7| Step: 3
Training loss: 2.474554746246118
Validation loss: 2.028513162089508
Epoch: 7| Step: 4
Training loss: 1.9353375826946777
Validation loss: 2.016162111532039
Epoch: 7| Step: 5
Training loss: 2.481936523627894
Validation loss: 2.0119725615910635
Epoch: 7| Step: 6
Training loss: 3.325654021453548
Validation loss: 2.030206631707901
Epoch: 7| Step: 7
Training loss: 2.33090300240274
Validation loss: 2.033315279760672
Epoch: 7| Step: 8
Training loss: 2.012459331599109
Validation loss: 2.0258747643906463
Epoch: 7| Step: 9
Training loss: 2.805885675310489
Validation loss: 2.0068066784592045
Epoch: 7| Step: 10
Training loss: 2.656788670392046
Validation loss: 2.018235473953953
Epoch: 7| Step: 11
Training loss: 2.2270085473583894
Validation loss: 2.0143643148119263
Epoch: 7| Step: 12
Training loss: 2.19191840675694
Validation loss: 2.0081098774615294
Epoch: 7| Step: 13
Training loss: 2.2939775317687325
Validation loss: 2.0334429459663097
Epoch: 7| Step: 14
Training loss: 2.537615554508628
Validation loss: 2.016166744770045
Epoch: 7| Step: 15
Training loss: 2.660415972831793
Validation loss: 2.0178453815983337
Epoch: 49| Step: 0
Training loss: 2.1813886013646386
Validation loss: 2.0259494012314696
Epoch: 7| Step: 1
Training loss: 2.22909990252282
Validation loss: 2.03067479276676
Epoch: 7| Step: 2
Training loss: 2.502570261545307
Validation loss: 2.0255285867108426
Epoch: 7| Step: 3
Training loss: 2.2705648304332646
Validation loss: 1.9989851466357391
Epoch: 7| Step: 4
Training loss: 2.8067599744380827
Validation loss: 2.029961563997127
Epoch: 7| Step: 5
Training loss: 2.883071350220356
Validation loss: 2.029985025912598
Epoch: 7| Step: 6
Training loss: 2.055598648009085
Validation loss: 2.0186633293415617
Epoch: 7| Step: 7
Training loss: 2.6240831317933235
Validation loss: 2.0338118810569297
Epoch: 7| Step: 8
Training loss: 2.5742935841266026
Validation loss: 2.0167222601671853
Epoch: 7| Step: 9
Training loss: 2.230371583335332
Validation loss: 2.018954086525109
Epoch: 7| Step: 10
Training loss: 2.6388904359601044
Validation loss: 2.020673788668203
Epoch: 7| Step: 11
Training loss: 2.466341413069227
Validation loss: 2.0225490453014503
Epoch: 7| Step: 12
Training loss: 2.7873689013388376
Validation loss: 2.0184323884425304
Epoch: 7| Step: 13
Training loss: 2.3436898796000083
Validation loss: 2.0299355279287887
Epoch: 7| Step: 14
Training loss: 2.241570364527332
Validation loss: 2.021375693102325
Epoch: 7| Step: 15
Training loss: 2.2768394998133172
Validation loss: 2.023010856174642
Epoch: 50| Step: 0
Training loss: 2.738107281218081
Validation loss: 2.030690112397353
Epoch: 7| Step: 1
Training loss: 2.6191665682265186
Validation loss: 2.0279782928479277
Epoch: 7| Step: 2
Training loss: 2.337326810408066
Validation loss: 2.004300363896741
Epoch: 7| Step: 3
Training loss: 1.8466176507253962
Validation loss: 2.0101135451039824
Epoch: 7| Step: 4
Training loss: 2.3721651927555953
Validation loss: 2.0205230240940413
Epoch: 7| Step: 5
Training loss: 2.7306129079155026
Validation loss: 2.0259518485605827
Epoch: 7| Step: 6
Training loss: 2.655368524036467
Validation loss: 2.0323656630908817
Epoch: 7| Step: 7
Training loss: 2.1173381681427097
Validation loss: 2.035039168083009
Epoch: 7| Step: 8
Training loss: 2.434877794712315
Validation loss: 2.033943828689891
Epoch: 7| Step: 9
Training loss: 2.2324532734422524
Validation loss: 2.0195127839474623
Epoch: 7| Step: 10
Training loss: 2.57209757586854
Validation loss: 2.0340983630814806
Epoch: 7| Step: 11
Training loss: 2.5218757071606333
Validation loss: 2.021939567077996
Epoch: 7| Step: 12
Training loss: 2.5693587646862244
Validation loss: 2.0336987113331677
Epoch: 7| Step: 13
Training loss: 2.389009316191107
Validation loss: 2.029762369071455
Epoch: 7| Step: 14
Training loss: 2.3819388366969325
Validation loss: 2.0216786297475733
Epoch: 7| Step: 15
Training loss: 2.5498661193109555
Validation loss: 2.0201939082870775
Epoch: 51| Step: 0
Training loss: 2.775466477648142
Validation loss: 2.0313742230777048
Epoch: 7| Step: 1
Training loss: 2.1527463671399216
Validation loss: 2.013281346309546
Epoch: 7| Step: 2
Training loss: 2.501776064370535
Validation loss: 2.0185269288773733
Epoch: 7| Step: 3
Training loss: 2.307668019435908
Validation loss: 1.987008929469261
Epoch: 7| Step: 4
Training loss: 2.8428417054775217
Validation loss: 2.0192724036027294
Epoch: 7| Step: 5
Training loss: 2.5999829878617304
Validation loss: 2.025144676368701
Epoch: 7| Step: 6
Training loss: 2.2322803629347048
Validation loss: 2.0067278958376793
Epoch: 7| Step: 7
Training loss: 2.5516060726745935
Validation loss: 2.024029351224424
Epoch: 7| Step: 8
Training loss: 2.1991611832288593
Validation loss: 2.0253800234337453
Epoch: 7| Step: 9
Training loss: 2.227042698526634
Validation loss: 2.0257731470836218
Epoch: 7| Step: 10
Training loss: 3.175756775784
Validation loss: 2.0206462850082216
Epoch: 7| Step: 11
Training loss: 2.433704159407293
Validation loss: 1.9978177061580509
Epoch: 7| Step: 12
Training loss: 2.4939000096531925
Validation loss: 2.0160340192430675
Epoch: 7| Step: 13
Training loss: 1.650588453726746
Validation loss: 2.01150905698926
Epoch: 7| Step: 14
Training loss: 2.2867770193773898
Validation loss: 2.0098042812990085
Epoch: 7| Step: 15
Training loss: 2.4005284840141923
Validation loss: 1.993280951595358
Epoch: 52| Step: 0
Training loss: 2.111040602170226
Validation loss: 2.0245817959486514
Epoch: 7| Step: 1
Training loss: 3.0224894927467734
Validation loss: 2.016813804127027
Epoch: 7| Step: 2
Training loss: 2.3872744948056988
Validation loss: 2.0151756625347246
Epoch: 7| Step: 3
Training loss: 2.15618929570206
Validation loss: 2.0027563237292476
Epoch: 7| Step: 4
Training loss: 2.5189151454200793
Validation loss: 2.0254419955224936
Epoch: 7| Step: 5
Training loss: 2.388478031855178
Validation loss: 2.008312323267257
Epoch: 7| Step: 6
Training loss: 2.06563988015129
Validation loss: 2.020490241994112
Epoch: 7| Step: 7
Training loss: 2.7406774639819202
Validation loss: 2.008358479290534
Epoch: 7| Step: 8
Training loss: 2.2958934529135595
Validation loss: 2.0182980378305873
Epoch: 7| Step: 9
Training loss: 2.2891554048712743
Validation loss: 2.0222081818461426
Epoch: 7| Step: 10
Training loss: 2.627009939267132
Validation loss: 2.0185824507974206
Epoch: 7| Step: 11
Training loss: 2.5255033463459884
Validation loss: 2.024362880046535
Epoch: 7| Step: 12
Training loss: 2.552207559689136
Validation loss: 2.018235230206893
Epoch: 7| Step: 13
Training loss: 2.5608628788725114
Validation loss: 2.032173953870498
Epoch: 7| Step: 14
Training loss: 2.5046833040674654
Validation loss: 2.034293166931798
Epoch: 7| Step: 15
Training loss: 2.348359927624045
Validation loss: 2.025277546402045
Epoch: 53| Step: 0
Training loss: 2.818360305542769
Validation loss: 2.014707588486973
Epoch: 7| Step: 1
Training loss: 2.4766177583420212
Validation loss: 2.017410803676717
Epoch: 7| Step: 2
Training loss: 2.2898928857930803
Validation loss: 2.0186136372143992
Epoch: 7| Step: 3
Training loss: 2.4359485873103996
Validation loss: 2.011172725469314
Epoch: 7| Step: 4
Training loss: 2.3610466094338216
Validation loss: 2.0256369754747556
Epoch: 7| Step: 5
Training loss: 2.6767898774757684
Validation loss: 2.0164102608402614
Epoch: 7| Step: 6
Training loss: 2.544138836958866
Validation loss: 2.0153482720996667
Epoch: 7| Step: 7
Training loss: 2.4374231179657038
Validation loss: 2.0198493617875584
Epoch: 7| Step: 8
Training loss: 1.900633809132908
Validation loss: 2.0240356061209313
Epoch: 7| Step: 9
Training loss: 2.3424165111144832
Validation loss: 2.0239706828707513
Epoch: 7| Step: 10
Training loss: 2.5642774046684695
Validation loss: 2.009007245496606
Epoch: 7| Step: 11
Training loss: 2.125294496661647
Validation loss: 2.0109077326675773
Epoch: 7| Step: 12
Training loss: 2.3702271337356735
Validation loss: 2.0115206867502353
Epoch: 7| Step: 13
Training loss: 2.337066071568362
Validation loss: 2.0092080905627454
Epoch: 7| Step: 14
Training loss: 2.611411208184184
Validation loss: 2.020667927694755
Epoch: 7| Step: 15
Training loss: 2.75486273421875
Validation loss: 2.0234165516788014
Epoch: 54| Step: 0
Training loss: 2.5258216578575468
Validation loss: 2.0196701024106987
Epoch: 7| Step: 1
Training loss: 2.367880540373396
Validation loss: 2.020779909362424
Epoch: 7| Step: 2
Training loss: 2.2164852780387356
Validation loss: 1.9887606162592857
Epoch: 7| Step: 3
Training loss: 3.0327066284127375
Validation loss: 2.026094369048801
Epoch: 7| Step: 4
Training loss: 2.496702117091027
Validation loss: 2.0194299302802845
Epoch: 7| Step: 5
Training loss: 2.1976541540174526
Validation loss: 2.024413858240195
Epoch: 7| Step: 6
Training loss: 2.489393048748965
Validation loss: 1.993035642186139
Epoch: 7| Step: 7
Training loss: 2.3876442870634293
Validation loss: 2.017399777257554
Epoch: 7| Step: 8
Training loss: 2.591802762333178
Validation loss: 2.0180144028580296
Epoch: 7| Step: 9
Training loss: 2.547160594818214
Validation loss: 2.031409825003929
Epoch: 7| Step: 10
Training loss: 2.8779401257975783
Validation loss: 2.0117508854302133
Epoch: 7| Step: 11
Training loss: 2.7248135179178736
Validation loss: 2.0157132691768065
Epoch: 7| Step: 12
Training loss: 2.468488462090837
Validation loss: 2.0031370840687583
Epoch: 7| Step: 13
Training loss: 1.8915893365231513
Validation loss: 1.9953795757889359
Epoch: 7| Step: 14
Training loss: 2.3867032663994996
Validation loss: 2.0047354465141396
Epoch: 7| Step: 15
Training loss: 1.8061904923823342
Validation loss: 1.9918511786382584
Epoch: 55| Step: 0
Training loss: 2.8622775328697423
Validation loss: 2.005265693238037
Epoch: 7| Step: 1
Training loss: 2.6927511677879807
Validation loss: 2.0127620196797076
Epoch: 7| Step: 2
Training loss: 2.6156806821376732
Validation loss: 2.015039401272662
Epoch: 7| Step: 3
Training loss: 2.527411953744273
Validation loss: 2.012241248109325
Epoch: 7| Step: 4
Training loss: 3.212754971965291
Validation loss: 2.00615059627383
Epoch: 7| Step: 5
Training loss: 2.204501324098414
Validation loss: 2.011242574309785
Epoch: 7| Step: 6
Training loss: 2.159961105279065
Validation loss: 2.015661721435608
Epoch: 7| Step: 7
Training loss: 2.7070688572592894
Validation loss: 2.0103441850915775
Epoch: 7| Step: 8
Training loss: 2.3963424031207197
Validation loss: 2.0212099232875573
Epoch: 7| Step: 9
Training loss: 2.1114281728579316
Validation loss: 2.009676296238567
Epoch: 7| Step: 10
Training loss: 2.4366126768477376
Validation loss: 2.0070222178618233
Epoch: 7| Step: 11
Training loss: 2.0507517203975176
Validation loss: 2.022368859451719
Epoch: 7| Step: 12
Training loss: 1.750771488705497
Validation loss: 1.9998896792452296
Epoch: 7| Step: 13
Training loss: 2.2252746069678717
Validation loss: 2.0171213563622974
Epoch: 7| Step: 14
Training loss: 2.0767692790185306
Validation loss: 2.007555584699434
Epoch: 7| Step: 15
Training loss: 2.7663095780001647
Validation loss: 2.0242602168773227
Epoch: 56| Step: 0
Training loss: 2.622834538594782
Validation loss: 2.013699276738441
Epoch: 7| Step: 1
Training loss: 2.574303216083887
Validation loss: 2.026117486870134
Epoch: 7| Step: 2
Training loss: 2.155497322847159
Validation loss: 2.0195153052739117
Epoch: 7| Step: 3
Training loss: 2.587031383741343
Validation loss: 2.017144021990021
Epoch: 7| Step: 4
Training loss: 1.9446074039050314
Validation loss: 2.0200947940208267
Epoch: 7| Step: 5
Training loss: 2.8229233763968105
Validation loss: 2.017490762385711
Epoch: 7| Step: 6
Training loss: 2.5106214911977887
Validation loss: 2.021986034751184
Epoch: 7| Step: 7
Training loss: 2.5882881291116986
Validation loss: 2.008384214003666
Epoch: 7| Step: 8
Training loss: 2.0288158210047262
Validation loss: 2.0031741909108693
Epoch: 7| Step: 9
Training loss: 2.593630868404941
Validation loss: 1.9924352514071886
Epoch: 7| Step: 10
Training loss: 2.674638178232796
Validation loss: 2.0129665374884933
Epoch: 7| Step: 11
Training loss: 2.714573688933971
Validation loss: 2.0097993211553224
Epoch: 7| Step: 12
Training loss: 2.1058260980664696
Validation loss: 1.9981183464449979
Epoch: 7| Step: 13
Training loss: 2.56181586832717
Validation loss: 2.006827522928139
Epoch: 7| Step: 14
Training loss: 2.6457648280929527
Validation loss: 2.017849263896833
Epoch: 7| Step: 15
Training loss: 1.7366399324132493
Validation loss: 2.0085446636789666
Epoch: 57| Step: 0
Training loss: 2.5120002743058754
Validation loss: 2.003144162530723
Epoch: 7| Step: 1
Training loss: 2.451584447661576
Validation loss: 2.0264126998841983
Epoch: 7| Step: 2
Training loss: 2.422813479805754
Validation loss: 2.02581811603308
Epoch: 7| Step: 3
Training loss: 2.8229415348172875
Validation loss: 2.025035410188886
Epoch: 7| Step: 4
Training loss: 2.6016110710673295
Validation loss: 2.027493656529475
Epoch: 7| Step: 5
Training loss: 1.764345904173548
Validation loss: 2.012488399602036
Epoch: 7| Step: 6
Training loss: 2.0803215636597
Validation loss: 2.0236531802513458
Epoch: 7| Step: 7
Training loss: 2.374071642481594
Validation loss: 2.020328296442345
Epoch: 7| Step: 8
Training loss: 2.3050498548234124
Validation loss: 2.0018810146696113
Epoch: 7| Step: 9
Training loss: 2.7471518072196885
Validation loss: 2.008456324993826
Epoch: 7| Step: 10
Training loss: 2.1088536501263824
Validation loss: 2.0154993272059785
Epoch: 7| Step: 11
Training loss: 2.363341779958304
Validation loss: 2.003807638795066
Epoch: 7| Step: 12
Training loss: 2.7161588927577096
Validation loss: 2.0151589892596107
Epoch: 7| Step: 13
Training loss: 2.2869805251653
Validation loss: 2.0162296709951355
Epoch: 7| Step: 14
Training loss: 2.982688866876147
Validation loss: 2.0235860334578435
Epoch: 7| Step: 15
Training loss: 2.298848245252328
Validation loss: 2.013261513808317
Epoch: 58| Step: 0
Training loss: 2.5692075075988026
Validation loss: 2.001292119998424
Epoch: 7| Step: 1
Training loss: 2.708307138952103
Validation loss: 2.017474403140126
Epoch: 7| Step: 2
Training loss: 2.7096730562180813
Validation loss: 2.0232973550755387
Epoch: 7| Step: 3
Training loss: 2.9016575778714397
Validation loss: 1.9988972517902523
Epoch: 7| Step: 4
Training loss: 2.0486707890613185
Validation loss: 2.009899740809563
Epoch: 7| Step: 5
Training loss: 2.7609593751620407
Validation loss: 2.0081859548999734
Epoch: 7| Step: 6
Training loss: 2.1567043986648273
Validation loss: 2.018273911854505
Epoch: 7| Step: 7
Training loss: 2.063445019243941
Validation loss: 2.018066356847348
Epoch: 7| Step: 8
Training loss: 1.84298036967031
Validation loss: 2.024346400581504
Epoch: 7| Step: 9
Training loss: 2.717717292471628
Validation loss: 2.012869788998212
Epoch: 7| Step: 10
Training loss: 3.01938896288098
Validation loss: 2.027909652058681
Epoch: 7| Step: 11
Training loss: 2.016400565043686
Validation loss: 2.015252192168821
Epoch: 7| Step: 12
Training loss: 2.4198066000464618
Validation loss: 2.0208845916773517
Epoch: 7| Step: 13
Training loss: 2.5419862785959464
Validation loss: 2.013767245801132
Epoch: 7| Step: 14
Training loss: 2.3969764857087714
Validation loss: 2.0027484638998
Epoch: 7| Step: 15
Training loss: 1.793657756387475
Validation loss: 2.030193893231749
Epoch: 59| Step: 0
Training loss: 2.5017446152625404
Validation loss: 2.000641047702309
Epoch: 7| Step: 1
Training loss: 2.356513909654786
Validation loss: 2.024591119574054
Epoch: 7| Step: 2
Training loss: 2.8442721044796837
Validation loss: 2.0154216008396704
Epoch: 7| Step: 3
Training loss: 2.7505072212616795
Validation loss: 2.0161019394548005
Epoch: 7| Step: 4
Training loss: 2.398620399683398
Validation loss: 1.9878515741640412
Epoch: 7| Step: 5
Training loss: 1.798674370804093
Validation loss: 2.0237674778393235
Epoch: 7| Step: 6
Training loss: 2.35187586727324
Validation loss: 2.010593337451359
Epoch: 7| Step: 7
Training loss: 2.4046988503706905
Validation loss: 2.017374344380229
Epoch: 7| Step: 8
Training loss: 2.566207994209249
Validation loss: 1.99946462330725
Epoch: 7| Step: 9
Training loss: 2.1932345836327616
Validation loss: 2.0198544466728876
Epoch: 7| Step: 10
Training loss: 2.2285767128116714
Validation loss: 2.0041699290492594
Epoch: 7| Step: 11
Training loss: 2.570863983449713
Validation loss: 2.015464183410064
Epoch: 7| Step: 12
Training loss: 2.608196243567285
Validation loss: 2.023086513500449
Epoch: 7| Step: 13
Training loss: 2.653611432202853
Validation loss: 2.0116666928137072
Epoch: 7| Step: 14
Training loss: 2.0793167941744444
Validation loss: 2.0203275597807773
Epoch: 7| Step: 15
Training loss: 2.577132155239395
Validation loss: 2.0059535520289504
Epoch: 60| Step: 0
Training loss: 2.245287941391549
Validation loss: 2.015989488874179
Epoch: 7| Step: 1
Training loss: 3.0159948250703406
Validation loss: 2.015294934516713
Epoch: 7| Step: 2
Training loss: 2.4949623851195875
Validation loss: 2.0125397071454
Epoch: 7| Step: 3
Training loss: 2.8294024032637575
Validation loss: 2.022205642003198
Epoch: 7| Step: 4
Training loss: 2.4134767679756326
Validation loss: 2.0147149834453404
Epoch: 7| Step: 5
Training loss: 2.0581018196698078
Validation loss: 2.0174381884591015
Epoch: 7| Step: 6
Training loss: 2.3360304798005895
Validation loss: 2.017751900623772
Epoch: 7| Step: 7
Training loss: 2.3558766279188137
Validation loss: 2.019204052698172
Epoch: 7| Step: 8
Training loss: 2.1685798952083495
Validation loss: 2.014259191360268
Epoch: 7| Step: 9
Training loss: 2.4682558748230767
Validation loss: 2.022707470186198
Epoch: 7| Step: 10
Training loss: 1.797382647910807
Validation loss: 2.0375755986213053
Epoch: 7| Step: 11
Training loss: 2.346043088037591
Validation loss: 2.0206720926673487
Epoch: 7| Step: 12
Training loss: 2.4137985924719425
Validation loss: 2.028950934632132
Epoch: 7| Step: 13
Training loss: 2.0624872843032507
Validation loss: 2.028912580209652
Epoch: 7| Step: 14
Training loss: 2.8924112935093294
Validation loss: 2.022516161428341
Epoch: 7| Step: 15
Training loss: 2.8768715778921368
Validation loss: 2.013471806702411
Epoch: 61| Step: 0
Training loss: 2.5220611881695767
Validation loss: 2.0181916979975316
Epoch: 7| Step: 1
Training loss: 2.6044104398435857
Validation loss: 2.0132211801585203
Epoch: 7| Step: 2
Training loss: 2.1691039266561227
Validation loss: 2.0285717681495603
Epoch: 7| Step: 3
Training loss: 2.670726417706629
Validation loss: 2.0210114934958168
Epoch: 7| Step: 4
Training loss: 2.7178794958027175
Validation loss: 2.0150429084648143
Epoch: 7| Step: 5
Training loss: 2.709878588275829
Validation loss: 2.01352678238308
Epoch: 7| Step: 6
Training loss: 2.3615804305537353
Validation loss: 2.002968083104378
Epoch: 7| Step: 7
Training loss: 1.9814311140293408
Validation loss: 2.0255546293713156
Epoch: 7| Step: 8
Training loss: 2.737882359247715
Validation loss: 2.013357755267361
Epoch: 7| Step: 9
Training loss: 2.196303391738494
Validation loss: 2.0113431807870237
Epoch: 7| Step: 10
Training loss: 2.342136081693568
Validation loss: 2.0084597657847647
Epoch: 7| Step: 11
Training loss: 2.1988017633795716
Validation loss: 2.0287913915540985
Epoch: 7| Step: 12
Training loss: 2.2503004933076522
Validation loss: 2.017858474486712
Epoch: 7| Step: 13
Training loss: 2.55567031294015
Validation loss: 2.0156728926874283
Epoch: 7| Step: 14
Training loss: 2.441870854229968
Validation loss: 2.0112889656266866
Epoch: 7| Step: 15
Training loss: 2.5371757187366
Validation loss: 2.0181900157632375
Epoch: 62| Step: 0
Training loss: 2.595036107365185
Validation loss: 2.002660103245963
Epoch: 7| Step: 1
Training loss: 2.0409359565043306
Validation loss: 2.027785250456999
Epoch: 7| Step: 2
Training loss: 2.7739129317136597
Validation loss: 2.0157512665142914
Epoch: 7| Step: 3
Training loss: 2.4806376242034074
Validation loss: 2.0278562909498414
Epoch: 7| Step: 4
Training loss: 2.4350015600305217
Validation loss: 2.017811364558884
Epoch: 7| Step: 5
Training loss: 2.4523512476490197
Validation loss: 2.0138195375942387
Epoch: 7| Step: 6
Training loss: 2.40674793986764
Validation loss: 2.0173810672956383
Epoch: 7| Step: 7
Training loss: 2.6122202636766936
Validation loss: 2.021128474220707
Epoch: 7| Step: 8
Training loss: 2.5647677179942874
Validation loss: 2.0162945121180575
Epoch: 7| Step: 9
Training loss: 2.2531157219599196
Validation loss: 2.015614588861767
Epoch: 7| Step: 10
Training loss: 2.215787925164089
Validation loss: 2.0016887587125036
Epoch: 7| Step: 11
Training loss: 3.004699522917801
Validation loss: 2.0122895010533237
Epoch: 7| Step: 12
Training loss: 2.5381614612176366
Validation loss: 2.009656181017057
Epoch: 7| Step: 13
Training loss: 2.5560718017247694
Validation loss: 2.0104822817651518
Epoch: 7| Step: 14
Training loss: 1.8464675531333254
Validation loss: 2.0059853712298494
Epoch: 7| Step: 15
Training loss: 2.135253627104515
Validation loss: 1.9961990971730408
Epoch: 63| Step: 0
Training loss: 2.063512033644191
Validation loss: 2.013070103328324
Epoch: 7| Step: 1
Training loss: 2.22105148656287
Validation loss: 2.008368014711872
Epoch: 7| Step: 2
Training loss: 2.3183028126656318
Validation loss: 2.0015976921906584
Epoch: 7| Step: 3
Training loss: 2.8149085010679773
Validation loss: 2.019128781769735
Epoch: 7| Step: 4
Training loss: 2.753919582469943
Validation loss: 2.010370792622041
Epoch: 7| Step: 5
Training loss: 2.734071115228838
Validation loss: 2.012337299209112
Epoch: 7| Step: 6
Training loss: 1.8141562688153092
Validation loss: 2.0267384132856794
Epoch: 7| Step: 7
Training loss: 2.1320641850226734
Validation loss: 2.0057143027147903
Epoch: 7| Step: 8
Training loss: 2.6183936229379903
Validation loss: 2.022354957316059
Epoch: 7| Step: 9
Training loss: 2.698218506727427
Validation loss: 2.026023535517678
Epoch: 7| Step: 10
Training loss: 2.57774368702975
Validation loss: 2.0279965766944277
Epoch: 7| Step: 11
Training loss: 2.918820993348331
Validation loss: 2.027142406549508
Epoch: 7| Step: 12
Training loss: 1.8677659036671297
Validation loss: 2.003737017107052
Epoch: 7| Step: 13
Training loss: 2.3787735524617726
Validation loss: 2.024029154377372
Epoch: 7| Step: 14
Training loss: 2.4034496708126416
Validation loss: 2.016228418713011
Epoch: 7| Step: 15
Training loss: 2.445273012080078
Validation loss: 2.0203173068311715
Epoch: 64| Step: 0
Training loss: 2.784999591546568
Validation loss: 2.0115759759390075
Epoch: 7| Step: 1
Training loss: 2.564606521794971
Validation loss: 2.019961742768408
Epoch: 7| Step: 2
Training loss: 2.3669432460554707
Validation loss: 2.0107692883313835
Epoch: 7| Step: 3
Training loss: 2.8054687771947227
Validation loss: 2.0245342611107766
Epoch: 7| Step: 4
Training loss: 2.193160009792319
Validation loss: 2.0211222454401088
Epoch: 7| Step: 5
Training loss: 2.6528868084171866
Validation loss: 2.012323572289755
Epoch: 7| Step: 6
Training loss: 2.560355428817452
Validation loss: 2.0023705588039635
Epoch: 7| Step: 7
Training loss: 2.5304897720862853
Validation loss: 2.00449135123846
Epoch: 7| Step: 8
Training loss: 2.2482790193249085
Validation loss: 2.026161866387076
Epoch: 7| Step: 9
Training loss: 1.6716692075903392
Validation loss: 2.0144872090785113
Epoch: 7| Step: 10
Training loss: 2.2903202494280546
Validation loss: 2.0248556626159937
Epoch: 7| Step: 11
Training loss: 2.104691908845199
Validation loss: 2.014267497307157
Epoch: 7| Step: 12
Training loss: 2.348927793001181
Validation loss: 2.008494680357779
Epoch: 7| Step: 13
Training loss: 2.6911902707811954
Validation loss: 2.0142362258893884
Epoch: 7| Step: 14
Training loss: 2.3379046982267524
Validation loss: 2.0130100163426023
Epoch: 7| Step: 15
Training loss: 2.5904455622063156
Validation loss: 2.0065261360205273
Epoch: 65| Step: 0
Training loss: 2.1056870610961114
Validation loss: 1.9960760166993083
Epoch: 7| Step: 1
Training loss: 2.749376139535427
Validation loss: 2.0048678352570404
Epoch: 7| Step: 2
Training loss: 2.4424911651920085
Validation loss: 2.0033862450287714
Epoch: 7| Step: 3
Training loss: 2.653444940801208
Validation loss: 2.000077422914435
Epoch: 7| Step: 4
Training loss: 2.187376400316735
Validation loss: 2.009238651739605
Epoch: 7| Step: 5
Training loss: 2.15393229328028
Validation loss: 2.0152935496727586
Epoch: 7| Step: 6
Training loss: 2.733891384408972
Validation loss: 2.00514451482657
Epoch: 7| Step: 7
Training loss: 2.7985150520829114
Validation loss: 2.0045063593130688
Epoch: 7| Step: 8
Training loss: 2.444938948011417
Validation loss: 2.0007482910076093
Epoch: 7| Step: 9
Training loss: 2.2750386371056397
Validation loss: 2.013731256703902
Epoch: 7| Step: 10
Training loss: 2.297833819955142
Validation loss: 2.0132853540883864
Epoch: 7| Step: 11
Training loss: 2.5609798109040045
Validation loss: 2.009954465394643
Epoch: 7| Step: 12
Training loss: 2.404842807446639
Validation loss: 2.018891698837993
Epoch: 7| Step: 13
Training loss: 2.086667279658771
Validation loss: 2.01258296608507
Epoch: 7| Step: 14
Training loss: 2.563530970404759
Validation loss: 2.019380709296806
Epoch: 7| Step: 15
Training loss: 2.45026926390493
Validation loss: 2.0111332725312714
Epoch: 66| Step: 0
Training loss: 2.427653451738588
Validation loss: 2.0090354842812186
Epoch: 7| Step: 1
Training loss: 2.4029534287339116
Validation loss: 2.0204993800384368
Epoch: 7| Step: 2
Training loss: 2.7898625100006327
Validation loss: 2.006041648452518
Epoch: 7| Step: 3
Training loss: 2.239294438617822
Validation loss: 2.017968420710801
Epoch: 7| Step: 4
Training loss: 2.4721119840620416
Validation loss: 2.0164586896292174
Epoch: 7| Step: 5
Training loss: 2.7133041736744876
Validation loss: 2.0140702571654807
Epoch: 7| Step: 6
Training loss: 2.478015268982281
Validation loss: 2.0147749813844325
Epoch: 7| Step: 7
Training loss: 2.5540983588173876
Validation loss: 2.0022516001601387
Epoch: 7| Step: 8
Training loss: 2.1992584279141605
Validation loss: 2.0114941284211785
Epoch: 7| Step: 9
Training loss: 2.8654317443311923
Validation loss: 2.0171843127634075
Epoch: 7| Step: 10
Training loss: 2.2024257984284072
Validation loss: 2.011056096848152
Epoch: 7| Step: 11
Training loss: 2.2490242855784333
Validation loss: 2.009229068685969
Epoch: 7| Step: 12
Training loss: 2.3238694385287397
Validation loss: 1.994836855795249
Epoch: 7| Step: 13
Training loss: 2.0194729292987343
Validation loss: 2.0097348822417946
Epoch: 7| Step: 14
Training loss: 2.914062827266235
Validation loss: 2.0155014164741822
Epoch: 7| Step: 15
Training loss: 1.8718059673539875
Validation loss: 2.0119542067747385
Epoch: 67| Step: 0
Training loss: 1.758512637260265
Validation loss: 2.0149545292156006
Epoch: 7| Step: 1
Training loss: 2.6298523514063965
Validation loss: 2.008146270583899
Epoch: 7| Step: 2
Training loss: 2.3000018575909618
Validation loss: 1.9915323963152214
Epoch: 7| Step: 3
Training loss: 2.1485407024218506
Validation loss: 2.0052367732161476
Epoch: 7| Step: 4
Training loss: 2.3538047264734288
Validation loss: 2.014952167698336
Epoch: 7| Step: 5
Training loss: 2.186752736657832
Validation loss: 2.019567821804156
Epoch: 7| Step: 6
Training loss: 2.7971271422548822
Validation loss: 2.0150574158744927
Epoch: 7| Step: 7
Training loss: 2.0082538282979296
Validation loss: 2.0356766242136524
Epoch: 7| Step: 8
Training loss: 2.863214302060949
Validation loss: 2.0268431738449793
Epoch: 7| Step: 9
Training loss: 2.5992496508133685
Validation loss: 2.0235072309280904
Epoch: 7| Step: 10
Training loss: 2.93766005059741
Validation loss: 2.0267096591204576
Epoch: 7| Step: 11
Training loss: 1.6973729423422266
Validation loss: 2.0350327684972394
Epoch: 7| Step: 12
Training loss: 3.078734826419562
Validation loss: 2.031624788207545
Epoch: 7| Step: 13
Training loss: 2.292994952336448
Validation loss: 2.0175460058788084
Epoch: 7| Step: 14
Training loss: 2.5734434219227365
Validation loss: 2.022555378986895
Epoch: 7| Step: 15
Training loss: 2.358232638452574
Validation loss: 2.0210834151716934
Epoch: 68| Step: 0
Training loss: 2.696313467609579
Validation loss: 2.013136652643522
Epoch: 7| Step: 1
Training loss: 2.348050152680034
Validation loss: 2.017082931241426
Epoch: 7| Step: 2
Training loss: 2.5002491826804754
Validation loss: 2.0169760404295207
Epoch: 7| Step: 3
Training loss: 2.531571732784284
Validation loss: 2.0023543487157722
Epoch: 7| Step: 4
Training loss: 2.2926754089607346
Validation loss: 2.020280068080229
Epoch: 7| Step: 5
Training loss: 2.3820631506145307
Validation loss: 2.0173485281036934
Epoch: 7| Step: 6
Training loss: 2.1117704000588455
Validation loss: 2.00335521759294
Epoch: 7| Step: 7
Training loss: 2.196196897208858
Validation loss: 2.014382901010991
Epoch: 7| Step: 8
Training loss: 2.7187415813447244
Validation loss: 2.0017892093111613
Epoch: 7| Step: 9
Training loss: 2.1618151511923505
Validation loss: 2.017372967365352
Epoch: 7| Step: 10
Training loss: 2.186576539349323
Validation loss: 2.004646657860703
Epoch: 7| Step: 11
Training loss: 2.324313019195124
Validation loss: 1.998750035309783
Epoch: 7| Step: 12
Training loss: 2.4291132895448913
Validation loss: 2.0100244314374125
Epoch: 7| Step: 13
Training loss: 2.699511808835531
Validation loss: 2.0063752059837525
Epoch: 7| Step: 14
Training loss: 2.4213287721974663
Validation loss: 2.008341773978167
Epoch: 7| Step: 15
Training loss: 2.7632116790546757
Validation loss: 2.0032164738983824
Epoch: 69| Step: 0
Training loss: 2.3457805738281055
Validation loss: 2.021329636045077
Epoch: 7| Step: 1
Training loss: 2.2152146662933663
Validation loss: 2.012346359542168
Epoch: 7| Step: 2
Training loss: 2.892944395172429
Validation loss: 2.0157504872658785
Epoch: 7| Step: 3
Training loss: 2.0838525760806332
Validation loss: 2.021891198383919
Epoch: 7| Step: 4
Training loss: 2.2265117438705015
Validation loss: 1.9948757170637113
Epoch: 7| Step: 5
Training loss: 2.5524270792828054
Validation loss: 2.013826219161136
Epoch: 7| Step: 6
Training loss: 2.1348086228014793
Validation loss: 1.9945069602794854
Epoch: 7| Step: 7
Training loss: 2.7849110713437457
Validation loss: 1.9982691698272061
Epoch: 7| Step: 8
Training loss: 2.2995359616089743
Validation loss: 2.00710056631156
Epoch: 7| Step: 9
Training loss: 1.606559958033915
Validation loss: 1.9970546989448479
Epoch: 7| Step: 10
Training loss: 2.6449922641576125
Validation loss: 2.0042578294931395
Epoch: 7| Step: 11
Training loss: 2.594831953395735
Validation loss: 1.9996179712577822
Epoch: 7| Step: 12
Training loss: 2.897223452255591
Validation loss: 1.9935150111533282
Epoch: 7| Step: 13
Training loss: 2.3497835952462784
Validation loss: 1.9968854165395191
Epoch: 7| Step: 14
Training loss: 2.3846214557030874
Validation loss: 2.018130663590045
Epoch: 7| Step: 15
Training loss: 2.5657970338264726
Validation loss: 2.0127773973775844
Epoch: 70| Step: 0
Training loss: 2.2102362393426667
Validation loss: 1.9963651039412338
Epoch: 7| Step: 1
Training loss: 2.1663733308246527
Validation loss: 2.0235166214664266
Epoch: 7| Step: 2
Training loss: 2.7170011661598643
Validation loss: 2.0017294610665757
Epoch: 7| Step: 3
Training loss: 2.3765905976750643
Validation loss: 2.0123812353960138
Epoch: 7| Step: 4
Training loss: 3.010169277563945
Validation loss: 2.008182332369847
Epoch: 7| Step: 5
Training loss: 2.6538760179308647
Validation loss: 2.002378947671474
Epoch: 7| Step: 6
Training loss: 2.0709491254745864
Validation loss: 2.0146283399834166
Epoch: 7| Step: 7
Training loss: 2.467847731649022
Validation loss: 2.0095224141880044
Epoch: 7| Step: 8
Training loss: 2.0733116450918176
Validation loss: 2.003515993169043
Epoch: 7| Step: 9
Training loss: 2.779398955818151
Validation loss: 2.0151767503964777
Epoch: 7| Step: 10
Training loss: 2.790243117975505
Validation loss: 1.9948674190202653
Epoch: 7| Step: 11
Training loss: 2.635231785578017
Validation loss: 2.000549947197426
Epoch: 7| Step: 12
Training loss: 2.102100402742564
Validation loss: 2.004034655244161
Epoch: 7| Step: 13
Training loss: 2.1149370120072843
Validation loss: 2.006534160456383
Epoch: 7| Step: 14
Training loss: 2.2775576247327467
Validation loss: 2.011590037440866
Epoch: 7| Step: 15
Training loss: 2.2149315872132838
Validation loss: 2.0011480758428193
Epoch: 71| Step: 0
Training loss: 2.2012636153727736
Validation loss: 2.002165253660744
Epoch: 7| Step: 1
Training loss: 2.2821467479090165
Validation loss: 2.010848734789417
Epoch: 7| Step: 2
Training loss: 1.9406332706883314
Validation loss: 2.0081455477607597
Epoch: 7| Step: 3
Training loss: 1.5768913508295894
Validation loss: 2.024593553292765
Epoch: 7| Step: 4
Training loss: 2.263021196219734
Validation loss: 2.016829824053632
Epoch: 7| Step: 5
Training loss: 2.100984515155303
Validation loss: 2.0208612693247643
Epoch: 7| Step: 6
Training loss: 2.78980456826527
Validation loss: 2.0103112750923393
Epoch: 7| Step: 7
Training loss: 2.5328592906774055
Validation loss: 2.0284396412242627
Epoch: 7| Step: 8
Training loss: 2.728560188601275
Validation loss: 2.0292065174560703
Epoch: 7| Step: 9
Training loss: 2.8785524396733195
Validation loss: 2.029002778902814
Epoch: 7| Step: 10
Training loss: 2.20859352114514
Validation loss: 2.00785031560316
Epoch: 7| Step: 11
Training loss: 2.4957359188813295
Validation loss: 2.027386235595119
Epoch: 7| Step: 12
Training loss: 2.318845856939579
Validation loss: 2.0276616849545954
Epoch: 7| Step: 13
Training loss: 2.91458771500566
Validation loss: 2.0437701158522676
Epoch: 7| Step: 14
Training loss: 2.6446074301539055
Validation loss: 2.0302676717228314
Epoch: 7| Step: 15
Training loss: 2.7548796969142253
Validation loss: 2.027040574298291
Epoch: 72| Step: 0
Training loss: 2.19038135953151
Validation loss: 2.017235955781602
Epoch: 7| Step: 1
Training loss: 2.4412079997632135
Validation loss: 2.014022327151387
Epoch: 7| Step: 2
Training loss: 2.6427388956430096
Validation loss: 2.032771111680769
Epoch: 7| Step: 3
Training loss: 2.4661130704922343
Validation loss: 2.0162782482436516
Epoch: 7| Step: 4
Training loss: 2.967342966836984
Validation loss: 2.020527765769325
Epoch: 7| Step: 5
Training loss: 2.1947749555615728
Validation loss: 2.021898657331707
Epoch: 7| Step: 6
Training loss: 1.7640136522772527
Validation loss: 2.0002861874961884
Epoch: 7| Step: 7
Training loss: 2.4466672806734704
Validation loss: 2.0079238105728945
Epoch: 7| Step: 8
Training loss: 2.580466392116411
Validation loss: 2.017142303021194
Epoch: 7| Step: 9
Training loss: 2.2202246694890615
Validation loss: 2.001116390752131
Epoch: 7| Step: 10
Training loss: 2.7247562054410217
Validation loss: 1.992388762228777
Epoch: 7| Step: 11
Training loss: 2.734075213756033
Validation loss: 2.0049817723939833
Epoch: 7| Step: 12
Training loss: 2.7557220749207136
Validation loss: 2.0224608001303537
Epoch: 7| Step: 13
Training loss: 2.508841330287079
Validation loss: 2.001007534975932
Epoch: 7| Step: 14
Training loss: 1.6084818908127345
Validation loss: 2.011023026403183
Epoch: 7| Step: 15
Training loss: 2.2311169539248867
Validation loss: 1.9980763169332183
Epoch: 73| Step: 0
Training loss: 2.0181335689094584
Validation loss: 2.013363412943535
Epoch: 7| Step: 1
Training loss: 1.994580077527334
Validation loss: 2.0043580947713235
Epoch: 7| Step: 2
Training loss: 2.4212962781966776
Validation loss: 2.0082444075658046
Epoch: 7| Step: 3
Training loss: 2.8035001233711303
Validation loss: 2.0099704194381087
Epoch: 7| Step: 4
Training loss: 2.477925403922314
Validation loss: 1.9924484967431677
Epoch: 7| Step: 5
Training loss: 2.3985757694709813
Validation loss: 2.0113216044022995
Epoch: 7| Step: 6
Training loss: 2.287111355644691
Validation loss: 2.0067529909321147
Epoch: 7| Step: 7
Training loss: 2.4279258695469137
Validation loss: 2.0174812219981053
Epoch: 7| Step: 8
Training loss: 2.6853764150447357
Validation loss: 2.012708221242151
Epoch: 7| Step: 9
Training loss: 2.506603674536757
Validation loss: 2.0152064804408685
Epoch: 7| Step: 10
Training loss: 2.2074223804760194
Validation loss: 2.0257098063973626
Epoch: 7| Step: 11
Training loss: 2.261989438950551
Validation loss: 2.029242707083829
Epoch: 7| Step: 12
Training loss: 2.312948544277486
Validation loss: 2.0096774465632965
Epoch: 7| Step: 13
Training loss: 2.855877347380102
Validation loss: 2.011546495335064
Epoch: 7| Step: 14
Training loss: 2.7476030654250363
Validation loss: 2.0160455123602903
Epoch: 7| Step: 15
Training loss: 2.331655091790279
Validation loss: 2.018940148636134
Epoch: 74| Step: 0
Training loss: 2.363881638612049
Validation loss: 2.0114079454029565
Epoch: 7| Step: 1
Training loss: 2.319137121412841
Validation loss: 2.0177684666577744
Epoch: 7| Step: 2
Training loss: 2.49861278193429
Validation loss: 1.9980835784861364
Epoch: 7| Step: 3
Training loss: 2.3984846178825574
Validation loss: 2.000849072378267
Epoch: 7| Step: 4
Training loss: 2.5518141520222786
Validation loss: 2.005702737852885
Epoch: 7| Step: 5
Training loss: 2.848204760059327
Validation loss: 2.015852033821434
Epoch: 7| Step: 6
Training loss: 1.9129377524841602
Validation loss: 2.001649726869645
Epoch: 7| Step: 7
Training loss: 2.2720348317673116
Validation loss: 1.995372566404492
Epoch: 7| Step: 8
Training loss: 2.450671870691352
Validation loss: 2.0100449127921536
Epoch: 7| Step: 9
Training loss: 2.3594115803895406
Validation loss: 2.0075830680544806
Epoch: 7| Step: 10
Training loss: 2.436990733620954
Validation loss: 2.0075378585719
Epoch: 7| Step: 11
Training loss: 2.559160801607411
Validation loss: 1.996136455619288
Epoch: 7| Step: 12
Training loss: 2.4132040034287003
Validation loss: 2.0096308302004355
Epoch: 7| Step: 13
Training loss: 2.1756753947123495
Validation loss: 1.9993754248718283
Epoch: 7| Step: 14
Training loss: 2.7606604894283224
Validation loss: 1.9928390234750424
Epoch: 7| Step: 15
Training loss: 2.4576155266524626
Validation loss: 2.0018076268444696
Epoch: 75| Step: 0
Training loss: 2.6190670722800444
Validation loss: 2.0011606429526814
Epoch: 7| Step: 1
Training loss: 2.5074826793129485
Validation loss: 1.9884240241611313
Epoch: 7| Step: 2
Training loss: 2.316917118649777
Validation loss: 2.0096140811853265
Epoch: 7| Step: 3
Training loss: 2.7171763985282578
Validation loss: 2.0022692475133392
Epoch: 7| Step: 4
Training loss: 2.205311224808553
Validation loss: 2.0057094614926623
Epoch: 7| Step: 5
Training loss: 2.648595934604727
Validation loss: 2.003875256866988
Epoch: 7| Step: 6
Training loss: 2.400924039815629
Validation loss: 1.987833050265215
Epoch: 7| Step: 7
Training loss: 2.7165983608840505
Validation loss: 2.0002306610912246
Epoch: 7| Step: 8
Training loss: 2.1502605679548044
Validation loss: 1.9874205732805479
Epoch: 7| Step: 9
Training loss: 2.1881922035390096
Validation loss: 1.9825575738967447
Epoch: 7| Step: 10
Training loss: 2.417354573527697
Validation loss: 1.9988481027397944
Epoch: 7| Step: 11
Training loss: 2.5196133858947256
Validation loss: 1.9990972432550123
Epoch: 7| Step: 12
Training loss: 2.2020735159095426
Validation loss: 1.9929382254105341
Epoch: 7| Step: 13
Training loss: 2.404633709936127
Validation loss: 1.993374445792989
Epoch: 7| Step: 14
Training loss: 2.090891808788965
Validation loss: 1.995534577949077
Epoch: 7| Step: 15
Training loss: 2.603524233094828
Validation loss: 1.9946067809742352
Epoch: 76| Step: 0
Training loss: 2.4684249084437404
Validation loss: 1.9778317166841088
Epoch: 7| Step: 1
Training loss: 2.09943324570121
Validation loss: 1.9929140737395117
Epoch: 7| Step: 2
Training loss: 2.5120463061286356
Validation loss: 2.0039492593737864
Epoch: 7| Step: 3
Training loss: 2.1525926394138173
Validation loss: 2.0065265161729955
Epoch: 7| Step: 4
Training loss: 2.4361449167401528
Validation loss: 2.0105461905222057
Epoch: 7| Step: 5
Training loss: 2.4366260820375727
Validation loss: 1.9859275374599492
Epoch: 7| Step: 6
Training loss: 2.527531376614686
Validation loss: 2.0014493451652724
Epoch: 7| Step: 7
Training loss: 2.8679284741621704
Validation loss: 1.9985900634806864
Epoch: 7| Step: 8
Training loss: 2.7560992660307226
Validation loss: 2.0091029996733227
Epoch: 7| Step: 9
Training loss: 2.8662184239148396
Validation loss: 2.0050655657076826
Epoch: 7| Step: 10
Training loss: 2.59527616527094
Validation loss: 2.006858001985457
Epoch: 7| Step: 11
Training loss: 2.1270463851225463
Validation loss: 1.991893797696122
Epoch: 7| Step: 12
Training loss: 1.5040157922260593
Validation loss: 2.009091917887772
Epoch: 7| Step: 13
Training loss: 2.7735413437865604
Validation loss: 2.023372706125992
Epoch: 7| Step: 14
Training loss: 2.170586073175172
Validation loss: 2.0136346856771157
Epoch: 7| Step: 15
Training loss: 2.1148860570637824
Validation loss: 2.0171788269013664
Epoch: 77| Step: 0
Training loss: 2.5855615809359977
Validation loss: 2.0085794639482715
Epoch: 7| Step: 1
Training loss: 2.2548333282790263
Validation loss: 2.0148438309702543
Epoch: 7| Step: 2
Training loss: 2.7186803699214783
Validation loss: 2.017770887283256
Epoch: 7| Step: 3
Training loss: 2.7220483700604907
Validation loss: 1.993743892882892
Epoch: 7| Step: 4
Training loss: 2.177611534862253
Validation loss: 2.013401149052659
Epoch: 7| Step: 5
Training loss: 2.5509726670138124
Validation loss: 1.981238952282853
Epoch: 7| Step: 6
Training loss: 2.436290440857398
Validation loss: 2.0192117752357475
Epoch: 7| Step: 7
Training loss: 2.430531149847629
Validation loss: 2.0118601482970857
Epoch: 7| Step: 8
Training loss: 2.5028804397649633
Validation loss: 2.021784333412186
Epoch: 7| Step: 9
Training loss: 2.4019616296071384
Validation loss: 2.0086956661518363
Epoch: 7| Step: 10
Training loss: 2.5128247331127698
Validation loss: 2.017671861392826
Epoch: 7| Step: 11
Training loss: 1.9108049972147816
Validation loss: 2.014140322386003
Epoch: 7| Step: 12
Training loss: 2.5825887242721772
Validation loss: 2.021144432975263
Epoch: 7| Step: 13
Training loss: 2.1988955543142468
Validation loss: 2.009628395205695
Epoch: 7| Step: 14
Training loss: 1.972181750346437
Validation loss: 2.0257139965093858
Epoch: 7| Step: 15
Training loss: 2.6240700482287957
Validation loss: 2.017073010323415
Epoch: 78| Step: 0
Training loss: 2.356514516700339
Validation loss: 2.0107846345054523
Epoch: 7| Step: 1
Training loss: 2.6775544243133345
Validation loss: 2.022509401730818
Epoch: 7| Step: 2
Training loss: 2.164881582215214
Validation loss: 2.0354972362433044
Epoch: 7| Step: 3
Training loss: 2.38026807669711
Validation loss: 2.0173266047517693
Epoch: 7| Step: 4
Training loss: 2.0357182581583144
Validation loss: 2.014036933594481
Epoch: 7| Step: 5
Training loss: 1.7236854437122096
Validation loss: 2.017587530209352
Epoch: 7| Step: 6
Training loss: 2.1089784602679145
Validation loss: 2.021158032917206
Epoch: 7| Step: 7
Training loss: 2.831323658909208
Validation loss: 2.0199446643795693
Epoch: 7| Step: 8
Training loss: 2.269031568136977
Validation loss: 2.0146840913231454
Epoch: 7| Step: 9
Training loss: 2.195525026724782
Validation loss: 2.013390744327283
Epoch: 7| Step: 10
Training loss: 2.569313295700313
Validation loss: 2.013544737727547
Epoch: 7| Step: 11
Training loss: 2.777130333363699
Validation loss: 2.00961564128305
Epoch: 7| Step: 12
Training loss: 2.4766499115833667
Validation loss: 2.033393396411492
Epoch: 7| Step: 13
Training loss: 2.476422230692244
Validation loss: 1.9717066785806792
Epoch: 7| Step: 14
Training loss: 2.85335085456436
Validation loss: 2.0216852440295687
Epoch: 7| Step: 15
Training loss: 2.5442515710565514
Validation loss: 2.012468310032288
Epoch: 79| Step: 0
Training loss: 2.434398830233521
Validation loss: 2.0022032797418
Epoch: 7| Step: 1
Training loss: 2.3353882210797328
Validation loss: 2.007782873535486
Epoch: 7| Step: 2
Training loss: 2.7620510996650016
Validation loss: 2.0141617625134907
Epoch: 7| Step: 3
Training loss: 2.2069031264663463
Validation loss: 2.0153765187907817
Epoch: 7| Step: 4
Training loss: 2.859574107757795
Validation loss: 2.022500216464908
Epoch: 7| Step: 5
Training loss: 2.257537085818892
Validation loss: 2.004310548005237
Epoch: 7| Step: 6
Training loss: 2.5737432987224085
Validation loss: 2.0159466774329977
Epoch: 7| Step: 7
Training loss: 2.3646112403959316
Validation loss: 2.007436102614892
Epoch: 7| Step: 8
Training loss: 2.3106420115266944
Validation loss: 2.0117491266074246
Epoch: 7| Step: 9
Training loss: 2.4396096905447204
Validation loss: 1.9999620324016727
Epoch: 7| Step: 10
Training loss: 2.7646793106387273
Validation loss: 1.999511901313835
Epoch: 7| Step: 11
Training loss: 2.266662886092829
Validation loss: 2.002405623998261
Epoch: 7| Step: 12
Training loss: 2.49124902735728
Validation loss: 1.9980799566344878
Epoch: 7| Step: 13
Training loss: 2.2431099619006596
Validation loss: 2.0007217496598697
Epoch: 7| Step: 14
Training loss: 2.2055500292555306
Validation loss: 2.001314731608608
Epoch: 7| Step: 15
Training loss: 2.0614457181287853
Validation loss: 2.0104552968344023
Epoch: 80| Step: 0
Training loss: 1.6530605772333855
Validation loss: 1.9944678540740932
Epoch: 7| Step: 1
Training loss: 2.5438173814701743
Validation loss: 2.0069865956490482
Epoch: 7| Step: 2
Training loss: 1.9004662744690544
Validation loss: 2.0087030864961677
Epoch: 7| Step: 3
Training loss: 2.704716384883312
Validation loss: 2.0183592830774133
Epoch: 7| Step: 4
Training loss: 2.696156775888312
Validation loss: 2.0189458666717663
Epoch: 7| Step: 5
Training loss: 2.5125954908757286
Validation loss: 1.9956211681573244
Epoch: 7| Step: 6
Training loss: 2.1570835437397533
Validation loss: 2.0138110438662515
Epoch: 7| Step: 7
Training loss: 2.4884450909437583
Validation loss: 2.016180520720243
Epoch: 7| Step: 8
Training loss: 2.3142889165772043
Validation loss: 1.9921794309522456
Epoch: 7| Step: 9
Training loss: 2.5920436715756208
Validation loss: 2.021519049609092
Epoch: 7| Step: 10
Training loss: 1.9884582320851174
Validation loss: 2.015850679223154
Epoch: 7| Step: 11
Training loss: 2.1466032208767456
Validation loss: 2.0094263590192067
Epoch: 7| Step: 12
Training loss: 2.672475468493529
Validation loss: 2.0039997545012156
Epoch: 7| Step: 13
Training loss: 2.5624637135983606
Validation loss: 2.01772053514246
Epoch: 7| Step: 14
Training loss: 2.6223514455898185
Validation loss: 2.0172932850443157
Epoch: 7| Step: 15
Training loss: 2.848141978089568
Validation loss: 2.00658839060212
Epoch: 81| Step: 0
Training loss: 1.9848249631141406
Validation loss: 2.0099259606357283
Epoch: 7| Step: 1
Training loss: 2.1786435269434685
Validation loss: 2.023336116589266
Epoch: 7| Step: 2
Training loss: 2.374313355619904
Validation loss: 2.015208565074067
Epoch: 7| Step: 3
Training loss: 2.7957877491296785
Validation loss: 2.013408312225135
Epoch: 7| Step: 4
Training loss: 2.3714515881069778
Validation loss: 1.9995724261496077
Epoch: 7| Step: 5
Training loss: 2.530946124639487
Validation loss: 2.015947646051778
Epoch: 7| Step: 6
Training loss: 2.6472685718337035
Validation loss: 2.003159754582035
Epoch: 7| Step: 7
Training loss: 2.5918086496529824
Validation loss: 2.0034958179959617
Epoch: 7| Step: 8
Training loss: 2.5738113845093205
Validation loss: 2.009257871722392
Epoch: 7| Step: 9
Training loss: 2.1145244897130975
Validation loss: 2.0083242069059226
Epoch: 7| Step: 10
Training loss: 2.5596394273027467
Validation loss: 2.000579426709356
Epoch: 7| Step: 11
Training loss: 2.319071119750206
Validation loss: 2.012428483027705
Epoch: 7| Step: 12
Training loss: 2.5465598818308766
Validation loss: 1.998837874589737
Epoch: 7| Step: 13
Training loss: 2.518785753777283
Validation loss: 2.0096727445315024
Epoch: 7| Step: 14
Training loss: 2.314514313866786
Validation loss: 2.002770097144445
Epoch: 7| Step: 15
Training loss: 2.0765542425561225
Validation loss: 1.9994156637541287
Epoch: 82| Step: 0
Training loss: 1.8040212086574843
Validation loss: 2.001197523826198
Epoch: 7| Step: 1
Training loss: 2.282877302457618
Validation loss: 1.9955949966549238
Epoch: 7| Step: 2
Training loss: 2.5917736015051047
Validation loss: 2.0107655590063676
Epoch: 7| Step: 3
Training loss: 2.563385880092494
Validation loss: 2.0065729652068636
Epoch: 7| Step: 4
Training loss: 2.7102878462731153
Validation loss: 2.0135224786880905
Epoch: 7| Step: 5
Training loss: 2.3827649721502335
Validation loss: 2.0043063082483488
Epoch: 7| Step: 6
Training loss: 2.501828288076546
Validation loss: 1.999898573571035
Epoch: 7| Step: 7
Training loss: 2.0166081832518437
Validation loss: 2.0073343136816466
Epoch: 7| Step: 8
Training loss: 2.4763793877617677
Validation loss: 2.004193297763906
Epoch: 7| Step: 9
Training loss: 2.6171209981639674
Validation loss: 2.00431031646264
Epoch: 7| Step: 10
Training loss: 2.3704286047727123
Validation loss: 1.9979007055070594
Epoch: 7| Step: 11
Training loss: 2.6054450495841563
Validation loss: 1.9867203151636017
Epoch: 7| Step: 12
Training loss: 2.40265624952369
Validation loss: 2.0023256822342224
Epoch: 7| Step: 13
Training loss: 2.4992615562844143
Validation loss: 2.0053440081840344
Epoch: 7| Step: 14
Training loss: 2.6464496004980096
Validation loss: 1.9980283326978308
Epoch: 7| Step: 15
Training loss: 2.0524183151587714
Validation loss: 1.9977299159261301
Epoch: 83| Step: 0
Training loss: 3.0940756578226343
Validation loss: 1.992436875072118
Epoch: 7| Step: 1
Training loss: 2.290153685997309
Validation loss: 2.009628076835492
Epoch: 7| Step: 2
Training loss: 2.764758647849641
Validation loss: 2.0088406582631015
Epoch: 7| Step: 3
Training loss: 2.352936707520448
Validation loss: 1.9954466118845118
Epoch: 7| Step: 4
Training loss: 2.1159743320660587
Validation loss: 2.0081967499103324
Epoch: 7| Step: 5
Training loss: 1.9835512749420159
Validation loss: 2.012089074915378
Epoch: 7| Step: 6
Training loss: 2.443571988619962
Validation loss: 2.0019358583463815
Epoch: 7| Step: 7
Training loss: 1.9661633286529314
Validation loss: 2.0064688580647094
Epoch: 7| Step: 8
Training loss: 2.323206987471095
Validation loss: 2.010703156230583
Epoch: 7| Step: 9
Training loss: 2.7959015073769384
Validation loss: 2.006916392656602
Epoch: 7| Step: 10
Training loss: 2.5530489178344133
Validation loss: 1.981454905272588
Epoch: 7| Step: 11
Training loss: 2.1106124074174497
Validation loss: 2.007603008400834
Epoch: 7| Step: 12
Training loss: 2.153249892556013
Validation loss: 1.9995878949898578
Epoch: 7| Step: 13
Training loss: 2.4916455866539664
Validation loss: 2.0053384425118663
Epoch: 7| Step: 14
Training loss: 2.452151840493208
Validation loss: 1.9820006969527848
Epoch: 7| Step: 15
Training loss: 2.469178560940481
Validation loss: 2.0000865532479035
Epoch: 84| Step: 0
Training loss: 2.4906871907547807
Validation loss: 1.9954135916218747
Epoch: 7| Step: 1
Training loss: 2.070275533094198
Validation loss: 2.008936481924813
Epoch: 7| Step: 2
Training loss: 2.030076260003413
Validation loss: 2.009317505589599
Epoch: 7| Step: 3
Training loss: 2.2754140959089906
Validation loss: 2.014994178637806
Epoch: 7| Step: 4
Training loss: 2.1576596503569707
Validation loss: 2.008851305418468
Epoch: 7| Step: 5
Training loss: 2.6653480448518
Validation loss: 2.030778961544681
Epoch: 7| Step: 6
Training loss: 2.632817027826689
Validation loss: 1.9882390445823235
Epoch: 7| Step: 7
Training loss: 2.79914065184736
Validation loss: 2.030356722034048
Epoch: 7| Step: 8
Training loss: 2.1469446162634784
Validation loss: 2.036427664985488
Epoch: 7| Step: 9
Training loss: 2.8460829670461223
Validation loss: 2.021204227032975
Epoch: 7| Step: 10
Training loss: 2.456398984161748
Validation loss: 2.0161616090570873
Epoch: 7| Step: 11
Training loss: 2.108071270463539
Validation loss: 2.0174417589066738
Epoch: 7| Step: 12
Training loss: 2.422475235913821
Validation loss: 2.017059868619189
Epoch: 7| Step: 13
Training loss: 1.8793805766807863
Validation loss: 1.9987822505185007
Epoch: 7| Step: 14
Training loss: 2.4238431747178324
Validation loss: 1.9980084969199672
Epoch: 7| Step: 15
Training loss: 2.8710874388748664
Validation loss: 2.0018607446968066
Epoch: 85| Step: 0
Training loss: 2.5817067552692032
Validation loss: 1.9995269899088108
Epoch: 7| Step: 1
Training loss: 2.5064332205374376
Validation loss: 2.011820989885186
Epoch: 7| Step: 2
Training loss: 2.389112305605403
Validation loss: 2.0131778119880974
Epoch: 7| Step: 3
Training loss: 2.05664653722886
Validation loss: 2.0135759821891885
Epoch: 7| Step: 4
Training loss: 2.5877441364789813
Validation loss: 2.0001471624369613
Epoch: 7| Step: 5
Training loss: 2.4569463427114426
Validation loss: 2.018888288901904
Epoch: 7| Step: 6
Training loss: 2.193772614191334
Validation loss: 1.98407660159638
Epoch: 7| Step: 7
Training loss: 2.3455929440453374
Validation loss: 2.014420861040298
Epoch: 7| Step: 8
Training loss: 2.3145695266746764
Validation loss: 2.0108334761781093
Epoch: 7| Step: 9
Training loss: 2.8616917297770588
Validation loss: 2.0191772503731484
Epoch: 7| Step: 10
Training loss: 2.564137284642897
Validation loss: 1.998056273223364
Epoch: 7| Step: 11
Training loss: 1.958746487748844
Validation loss: 2.008290400323476
Epoch: 7| Step: 12
Training loss: 2.071724579242803
Validation loss: 2.0112287845129346
Epoch: 7| Step: 13
Training loss: 2.3648036120372953
Validation loss: 2.0051060432957244
Epoch: 7| Step: 14
Training loss: 2.5583015100278814
Validation loss: 2.003448473205052
Epoch: 7| Step: 15
Training loss: 2.63765364285278
Validation loss: 2.0091582567223405
Epoch: 86| Step: 0
Training loss: 2.4161555528016967
Validation loss: 1.9974338402084704
Epoch: 7| Step: 1
Training loss: 2.764622220932744
Validation loss: 1.9978943271265326
Epoch: 7| Step: 2
Training loss: 2.4460637215324876
Validation loss: 2.015142339010701
Epoch: 7| Step: 3
Training loss: 2.147167371362114
Validation loss: 1.984609494374691
Epoch: 7| Step: 4
Training loss: 2.419579285393319
Validation loss: 1.994756613186563
Epoch: 7| Step: 5
Training loss: 2.154703885155136
Validation loss: 1.9729165911242137
Epoch: 7| Step: 6
Training loss: 2.1029268395309035
Validation loss: 2.000122200415851
Epoch: 7| Step: 7
Training loss: 2.2386743756188596
Validation loss: 1.994878212138843
Epoch: 7| Step: 8
Training loss: 2.0449512556091363
Validation loss: 1.9820210852563622
Epoch: 7| Step: 9
Training loss: 2.7567271401331115
Validation loss: 1.983534152245425
Epoch: 7| Step: 10
Training loss: 2.5638675297097357
Validation loss: 1.9925566586698698
Epoch: 7| Step: 11
Training loss: 2.4016293835928297
Validation loss: 2.0065197094616183
Epoch: 7| Step: 12
Training loss: 2.3088435572001744
Validation loss: 2.002891662485869
Epoch: 7| Step: 13
Training loss: 2.566171109881734
Validation loss: 2.0094828880491193
Epoch: 7| Step: 14
Training loss: 2.269550369366002
Validation loss: 1.99288644231749
Epoch: 7| Step: 15
Training loss: 2.8779351551844057
Validation loss: 1.976807604263484
Epoch: 87| Step: 0
Training loss: 1.7585787988990587
Validation loss: 1.9898452020614859
Epoch: 7| Step: 1
Training loss: 2.653656534928945
Validation loss: 2.00006907325879
Epoch: 7| Step: 2
Training loss: 2.6531219015114598
Validation loss: 2.0077957472036503
Epoch: 7| Step: 3
Training loss: 2.2189960611935042
Validation loss: 2.004388321250012
Epoch: 7| Step: 4
Training loss: 1.979321209411819
Validation loss: 2.0017581275191967
Epoch: 7| Step: 5
Training loss: 2.409001548313706
Validation loss: 2.0049394739131388
Epoch: 7| Step: 6
Training loss: 1.852658426303298
Validation loss: 2.0128499305069436
Epoch: 7| Step: 7
Training loss: 2.494727869883886
Validation loss: 2.02675258087415
Epoch: 7| Step: 8
Training loss: 2.728044866584474
Validation loss: 2.026598720711914
Epoch: 7| Step: 9
Training loss: 2.5366825158738986
Validation loss: 2.01031940188201
Epoch: 7| Step: 10
Training loss: 2.5543487977582724
Validation loss: 2.0284595930465463
Epoch: 7| Step: 11
Training loss: 1.844145522285848
Validation loss: 2.003005732909304
Epoch: 7| Step: 12
Training loss: 2.5742516291230593
Validation loss: 2.0205709641618887
Epoch: 7| Step: 13
Training loss: 3.0174564472838514
Validation loss: 2.01655044948705
Epoch: 7| Step: 14
Training loss: 2.397327675777007
Validation loss: 2.0149420652192798
Epoch: 7| Step: 15
Training loss: 2.573794617972489
Validation loss: 2.0225672634382486
Epoch: 88| Step: 0
Training loss: 2.349369382453245
Validation loss: 2.0202864305400463
Epoch: 7| Step: 1
Training loss: 2.3234315196141826
Validation loss: 2.0105787978582366
Epoch: 7| Step: 2
Training loss: 2.502716686459557
Validation loss: 2.00844978440003
Epoch: 7| Step: 3
Training loss: 2.5210643273650124
Validation loss: 2.0115088958842877
Epoch: 7| Step: 4
Training loss: 2.5307654399723027
Validation loss: 2.005287950197735
Epoch: 7| Step: 5
Training loss: 2.1624754446763377
Validation loss: 1.990850268819206
Epoch: 7| Step: 6
Training loss: 2.2022570259743457
Validation loss: 1.998535758225158
Epoch: 7| Step: 7
Training loss: 2.6527504700414117
Validation loss: 1.9877440254888992
Epoch: 7| Step: 8
Training loss: 1.972020596359899
Validation loss: 1.9908921048436863
Epoch: 7| Step: 9
Training loss: 2.960333850694607
Validation loss: 2.006156315820652
Epoch: 7| Step: 10
Training loss: 2.5470023094139815
Validation loss: 2.00742221793178
Epoch: 7| Step: 11
Training loss: 2.389370158851902
Validation loss: 2.006533974948188
Epoch: 7| Step: 12
Training loss: 1.9961023498469344
Validation loss: 2.012012186660609
Epoch: 7| Step: 13
Training loss: 2.3901119304926293
Validation loss: 1.9927761440348568
Epoch: 7| Step: 14
Training loss: 2.345934345877923
Validation loss: 2.001598477990771
Epoch: 7| Step: 15
Training loss: 2.535145905037156
Validation loss: 1.9993821548521429
Epoch: 89| Step: 0
Training loss: 2.199875945148214
Validation loss: 1.9986190519422509
Epoch: 7| Step: 1
Training loss: 2.545146238401128
Validation loss: 1.9892724391114098
Epoch: 7| Step: 2
Training loss: 2.2459438638847766
Validation loss: 1.996399074011615
Epoch: 7| Step: 3
Training loss: 2.6534823191650134
Validation loss: 1.996880297403888
Epoch: 7| Step: 4
Training loss: 1.914154673322749
Validation loss: 2.0130414715905554
Epoch: 7| Step: 5
Training loss: 2.6935590707332366
Validation loss: 1.9939474793776293
Epoch: 7| Step: 6
Training loss: 2.481832198631549
Validation loss: 1.9877637875465393
Epoch: 7| Step: 7
Training loss: 2.4942377440468912
Validation loss: 1.9796194227059567
Epoch: 7| Step: 8
Training loss: 2.145060156132059
Validation loss: 1.9816572750215453
Epoch: 7| Step: 9
Training loss: 2.3567903015569067
Validation loss: 2.0068551056698407
Epoch: 7| Step: 10
Training loss: 2.104307969387869
Validation loss: 1.9964449379978904
Epoch: 7| Step: 11
Training loss: 2.9229497717797286
Validation loss: 1.9899887081948782
Epoch: 7| Step: 12
Training loss: 2.7437205145778747
Validation loss: 1.990600428592019
Epoch: 7| Step: 13
Training loss: 2.6253272261341074
Validation loss: 1.9955306726371211
Epoch: 7| Step: 14
Training loss: 1.952085966300478
Validation loss: 1.980501318598207
Epoch: 7| Step: 15
Training loss: 2.2460285741223163
Validation loss: 1.9946806621736617
Epoch: 90| Step: 0
Training loss: 2.352752283171613
Validation loss: 1.9991799364431622
Epoch: 7| Step: 1
Training loss: 2.9159562653557214
Validation loss: 2.000588502817493
Epoch: 7| Step: 2
Training loss: 2.48071624242051
Validation loss: 1.9946749061970108
Epoch: 7| Step: 3
Training loss: 2.1696542047723026
Validation loss: 1.9888419541727806
Epoch: 7| Step: 4
Training loss: 2.8512541303725976
Validation loss: 2.0087060737239257
Epoch: 7| Step: 5
Training loss: 2.425491880888867
Validation loss: 1.9996690306792129
Epoch: 7| Step: 6
Training loss: 2.150693949996776
Validation loss: 2.004600981694438
Epoch: 7| Step: 7
Training loss: 1.68304661049447
Validation loss: 2.0071081283987953
Epoch: 7| Step: 8
Training loss: 2.3018950533504787
Validation loss: 1.9979432575617468
Epoch: 7| Step: 9
Training loss: 2.639922279890047
Validation loss: 1.9993468910204757
Epoch: 7| Step: 10
Training loss: 2.152054949041178
Validation loss: 2.0027648832580494
Epoch: 7| Step: 11
Training loss: 2.313475119709871
Validation loss: 1.9975565858211697
Epoch: 7| Step: 12
Training loss: 2.8742651622246544
Validation loss: 2.0060169565809938
Epoch: 7| Step: 13
Training loss: 2.152435799238279
Validation loss: 2.003638838916304
Epoch: 7| Step: 14
Training loss: 2.281582115767208
Validation loss: 1.9973459861225966
Epoch: 7| Step: 15
Training loss: 2.5525314145298714
Validation loss: 2.004423037514523
Epoch: 91| Step: 0
Training loss: 2.3913932014814705
Validation loss: 2.0308791340836305
Epoch: 7| Step: 1
Training loss: 2.00935097022987
Validation loss: 2.017975701278432
Epoch: 7| Step: 2
Training loss: 1.7573747556075592
Validation loss: 2.01820437274327
Epoch: 7| Step: 3
Training loss: 2.6857684567678466
Validation loss: 2.011611023142235
Epoch: 7| Step: 4
Training loss: 2.8862168801093797
Validation loss: 1.9950712927019056
Epoch: 7| Step: 5
Training loss: 2.228808103821338
Validation loss: 2.0063425841983302
Epoch: 7| Step: 6
Training loss: 2.8240231437004915
Validation loss: 1.9999500411431266
Epoch: 7| Step: 7
Training loss: 2.4108499922727873
Validation loss: 1.9944066809677377
Epoch: 7| Step: 8
Training loss: 2.88999247460887
Validation loss: 1.9915518908744685
Epoch: 7| Step: 9
Training loss: 1.8739851430346766
Validation loss: 1.9978683232744743
Epoch: 7| Step: 10
Training loss: 2.744981955797267
Validation loss: 2.0036879675684838
Epoch: 7| Step: 11
Training loss: 2.055422111280793
Validation loss: 1.9924776412614549
Epoch: 7| Step: 12
Training loss: 2.3992985972039667
Validation loss: 2.0121757799015403
Epoch: 7| Step: 13
Training loss: 2.1261779661720346
Validation loss: 1.9858096252907451
Epoch: 7| Step: 14
Training loss: 2.5930160035427674
Validation loss: 2.0112230526772863
Epoch: 7| Step: 15
Training loss: 2.2483686255005546
Validation loss: 1.9969032716773267
Epoch: 92| Step: 0
Training loss: 2.2144139863581325
Validation loss: 2.0045071452867185
Epoch: 7| Step: 1
Training loss: 2.8791755539958896
Validation loss: 2.009059895270445
Epoch: 7| Step: 2
Training loss: 2.632983465331854
Validation loss: 2.0191013269445963
Epoch: 7| Step: 3
Training loss: 2.4343337010221355
Validation loss: 1.9911329076725466
Epoch: 7| Step: 4
Training loss: 1.8277505996613372
Validation loss: 2.0041016104023948
Epoch: 7| Step: 5
Training loss: 3.0502622898074017
Validation loss: 2.020245799732661
Epoch: 7| Step: 6
Training loss: 2.5811976762322217
Validation loss: 2.0028534001693883
Epoch: 7| Step: 7
Training loss: 2.037399841842428
Validation loss: 2.019438684671309
Epoch: 7| Step: 8
Training loss: 2.4251683638811894
Validation loss: 2.0061314196883613
Epoch: 7| Step: 9
Training loss: 2.1971934666971036
Validation loss: 2.00826533445974
Epoch: 7| Step: 10
Training loss: 1.9285562264887788
Validation loss: 2.007621256261196
Epoch: 7| Step: 11
Training loss: 2.506730366093629
Validation loss: 2.0029733798826923
Epoch: 7| Step: 12
Training loss: 2.6105691153380772
Validation loss: 2.012908969596075
Epoch: 7| Step: 13
Training loss: 2.1561394262296205
Validation loss: 1.9995387825656017
Epoch: 7| Step: 14
Training loss: 2.297191572106584
Validation loss: 2.0131486039568083
Epoch: 7| Step: 15
Training loss: 2.329871527441181
Validation loss: 2.0204146753539685
Epoch: 93| Step: 0
Training loss: 2.992969221584569
Validation loss: 2.012816988664181
Epoch: 7| Step: 1
Training loss: 2.5587692084101605
Validation loss: 2.0153607504155713
Epoch: 7| Step: 2
Training loss: 2.610516235774532
Validation loss: 2.0092473859817033
Epoch: 7| Step: 3
Training loss: 2.3607051712331764
Validation loss: 2.0010276045153996
Epoch: 7| Step: 4
Training loss: 2.0587941023382483
Validation loss: 2.0258271366787244
Epoch: 7| Step: 5
Training loss: 2.213798693525801
Validation loss: 2.019326248487571
Epoch: 7| Step: 6
Training loss: 2.3186383613794965
Validation loss: 2.020530280302267
Epoch: 7| Step: 7
Training loss: 2.6942406333667783
Validation loss: 2.0028373381505267
Epoch: 7| Step: 8
Training loss: 2.4917846162706474
Validation loss: 2.0205880252894217
Epoch: 7| Step: 9
Training loss: 2.1075512949718447
Validation loss: 2.0195833581799683
Epoch: 7| Step: 10
Training loss: 1.9979101825989436
Validation loss: 2.0168657683782274
Epoch: 7| Step: 11
Training loss: 2.3929048525318057
Validation loss: 2.024748922532706
Epoch: 7| Step: 12
Training loss: 2.5857082853119677
Validation loss: 2.017571691283579
Epoch: 7| Step: 13
Training loss: 2.4282182869487383
Validation loss: 2.0108920503769405
Epoch: 7| Step: 14
Training loss: 2.2805292741585648
Validation loss: 2.0213427565578055
Epoch: 7| Step: 15
Training loss: 2.316511335128233
Validation loss: 2.0148662400088626
Epoch: 94| Step: 0
Training loss: 1.8193190323540278
Validation loss: 2.023300572788912
Epoch: 7| Step: 1
Training loss: 2.147793427072817
Validation loss: 2.005207394254512
Epoch: 7| Step: 2
Training loss: 2.3969208833562563
Validation loss: 2.020732581759203
Epoch: 7| Step: 3
Training loss: 2.6202030857378698
Validation loss: 1.9955872286762788
Epoch: 7| Step: 4
Training loss: 2.6355965493873637
Validation loss: 2.0168599494933126
Epoch: 7| Step: 5
Training loss: 2.9203774597552092
Validation loss: 2.002449749388097
Epoch: 7| Step: 6
Training loss: 2.0585995408036437
Validation loss: 2.0103858898150437
Epoch: 7| Step: 7
Training loss: 2.4728742506400847
Validation loss: 1.9985580321038028
Epoch: 7| Step: 8
Training loss: 1.9196939886133448
Validation loss: 2.000154387053587
Epoch: 7| Step: 9
Training loss: 2.0856430474524443
Validation loss: 1.9912234078434736
Epoch: 7| Step: 10
Training loss: 2.463335110565219
Validation loss: 1.995005839035581
Epoch: 7| Step: 11
Training loss: 1.7809852938807926
Validation loss: 1.9978125330270786
Epoch: 7| Step: 12
Training loss: 2.7753874465312114
Validation loss: 2.018647939926446
Epoch: 7| Step: 13
Training loss: 2.613007809142259
Validation loss: 1.9796734931221571
Epoch: 7| Step: 14
Training loss: 2.62565368505916
Validation loss: 2.009629193758091
Epoch: 7| Step: 15
Training loss: 2.7844140560609154
Validation loss: 2.0165341023538432
Epoch: 95| Step: 0
Training loss: 2.4110949402465613
Validation loss: 1.98966289033007
Epoch: 7| Step: 1
Training loss: 2.1286909921994304
Validation loss: 2.0000725241199877
Epoch: 7| Step: 2
Training loss: 2.638580614342914
Validation loss: 1.9838225828785758
Epoch: 7| Step: 3
Training loss: 2.1060767490208216
Validation loss: 2.0055290470918847
Epoch: 7| Step: 4
Training loss: 2.5878092742225416
Validation loss: 2.0034822709114466
Epoch: 7| Step: 5
Training loss: 2.2877926998795304
Validation loss: 1.9964020469266814
Epoch: 7| Step: 6
Training loss: 2.2110496465594753
Validation loss: 2.016384776919453
Epoch: 7| Step: 7
Training loss: 2.4251802593758485
Validation loss: 2.0031979047643134
Epoch: 7| Step: 8
Training loss: 2.533562533985878
Validation loss: 2.012883892589748
Epoch: 7| Step: 9
Training loss: 2.6756720082057153
Validation loss: 2.0163501904655425
Epoch: 7| Step: 10
Training loss: 2.480634068063783
Validation loss: 1.9905945259369384
Epoch: 7| Step: 11
Training loss: 2.228268903068551
Validation loss: 2.000877112119721
Epoch: 7| Step: 12
Training loss: 2.203276500497948
Validation loss: 1.9980902186802696
Epoch: 7| Step: 13
Training loss: 2.342553914364688
Validation loss: 2.0022112177661584
Epoch: 7| Step: 14
Training loss: 2.304466935287847
Validation loss: 1.9968181784483456
Epoch: 7| Step: 15
Training loss: 2.7284584776697036
Validation loss: 2.009214035611786
Epoch: 96| Step: 0
Training loss: 2.3754995724134274
Validation loss: 2.0074336248550404
Epoch: 7| Step: 1
Training loss: 2.7620345262914925
Validation loss: 2.010997024887246
Epoch: 7| Step: 2
Training loss: 2.144151442061437
Validation loss: 1.990199325330396
Epoch: 7| Step: 3
Training loss: 1.9309433776993201
Validation loss: 1.9769170637230578
Epoch: 7| Step: 4
Training loss: 2.472512673402403
Validation loss: 1.9822721373075274
Epoch: 7| Step: 5
Training loss: 2.158628175055753
Validation loss: 1.9836314960399515
Epoch: 7| Step: 6
Training loss: 2.242768959918623
Validation loss: 2.009464545593555
Epoch: 7| Step: 7
Training loss: 2.566131809372568
Validation loss: 1.9890494247467465
Epoch: 7| Step: 8
Training loss: 2.5666178669769772
Validation loss: 1.9983551090882938
Epoch: 7| Step: 9
Training loss: 2.058151168587373
Validation loss: 2.0064523890189503
Epoch: 7| Step: 10
Training loss: 2.5061278582179
Validation loss: 2.0113827683755705
Epoch: 7| Step: 11
Training loss: 2.5562860463032893
Validation loss: 2.0033575560779466
Epoch: 7| Step: 12
Training loss: 2.5526417231655723
Validation loss: 2.0073991315280764
Epoch: 7| Step: 13
Training loss: 3.06294060476455
Validation loss: 2.0049024781030287
Epoch: 7| Step: 14
Training loss: 2.204974865586325
Validation loss: 2.005520555091971
Epoch: 7| Step: 15
Training loss: 1.9652805335838428
Validation loss: 2.013530913512754
Epoch: 97| Step: 0
Training loss: 1.85995564089967
Validation loss: 2.017928479078144
Epoch: 7| Step: 1
Training loss: 2.166076604261674
Validation loss: 2.0051113136264616
Epoch: 7| Step: 2
Training loss: 2.0813873612264358
Validation loss: 2.0191436734230597
Epoch: 7| Step: 3
Training loss: 2.425788523099503
Validation loss: 2.0098618491180336
Epoch: 7| Step: 4
Training loss: 2.342550555714668
Validation loss: 2.0101432729030684
Epoch: 7| Step: 5
Training loss: 2.3595065654930862
Validation loss: 2.0045367395882616
Epoch: 7| Step: 6
Training loss: 2.755072596955632
Validation loss: 2.0133770624363554
Epoch: 7| Step: 7
Training loss: 2.431402845898176
Validation loss: 2.018320410850491
Epoch: 7| Step: 8
Training loss: 2.699153209282529
Validation loss: 2.0022850299432657
Epoch: 7| Step: 9
Training loss: 3.037955192712639
Validation loss: 2.0105683804183028
Epoch: 7| Step: 10
Training loss: 2.252844919264335
Validation loss: 2.00722280629423
Epoch: 7| Step: 11
Training loss: 2.9416327117026495
Validation loss: 1.99729749970595
Epoch: 7| Step: 12
Training loss: 2.2795723795175866
Validation loss: 2.0001805546151843
Epoch: 7| Step: 13
Training loss: 2.0474952748003084
Validation loss: 2.002203069948994
Epoch: 7| Step: 14
Training loss: 2.0697652993316966
Validation loss: 2.0030613772516337
Epoch: 7| Step: 15
Training loss: 2.260129591003012
Validation loss: 1.9907078535268292
Epoch: 98| Step: 0
Training loss: 2.758406361730103
Validation loss: 2.0011970900600664
Epoch: 7| Step: 1
Training loss: 2.6740105554890206
Validation loss: 1.9787738269570994
Epoch: 7| Step: 2
Training loss: 2.028424101934995
Validation loss: 2.0055979445898404
Epoch: 7| Step: 3
Training loss: 2.727374374055994
Validation loss: 1.9979738154643312
Epoch: 7| Step: 4
Training loss: 2.082188240702665
Validation loss: 2.006575157946764
Epoch: 7| Step: 5
Training loss: 2.3111480678859837
Validation loss: 1.9976168583369895
Epoch: 7| Step: 6
Training loss: 2.4634342183613023
Validation loss: 1.9943084282885684
Epoch: 7| Step: 7
Training loss: 2.4140830424894575
Validation loss: 2.001305544095223
Epoch: 7| Step: 8
Training loss: 2.178418846504704
Validation loss: 1.9979509743357633
Epoch: 7| Step: 9
Training loss: 1.8360256092762135
Validation loss: 1.999951447067562
Epoch: 7| Step: 10
Training loss: 2.4362912237477685
Validation loss: 1.996375014486756
Epoch: 7| Step: 11
Training loss: 2.7745524999285234
Validation loss: 2.0035912571309185
Epoch: 7| Step: 12
Training loss: 2.5585522830311014
Validation loss: 2.0020321579943445
Epoch: 7| Step: 13
Training loss: 2.3530947740292922
Validation loss: 2.00420874538482
Epoch: 7| Step: 14
Training loss: 2.3858820920654837
Validation loss: 1.9977418185384712
Epoch: 7| Step: 15
Training loss: 2.1900682903772917
Validation loss: 1.9875058940380592
Epoch: 99| Step: 0
Training loss: 2.0981233385776625
Validation loss: 1.9931246069394364
Epoch: 7| Step: 1
Training loss: 2.4316133673798577
Validation loss: 2.0071245205590458
Epoch: 7| Step: 2
Training loss: 2.143983531276594
Validation loss: 1.9976866896340633
Epoch: 7| Step: 3
Training loss: 2.165191906535415
Validation loss: 1.9933121783990553
Epoch: 7| Step: 4
Training loss: 2.895056714176062
Validation loss: 2.011246464027132
Epoch: 7| Step: 5
Training loss: 2.486675133354084
Validation loss: 2.0029020614182285
Epoch: 7| Step: 6
Training loss: 2.512076866996602
Validation loss: 2.004944843982569
Epoch: 7| Step: 7
Training loss: 2.2947483727631917
Validation loss: 2.0078750571310726
Epoch: 7| Step: 8
Training loss: 2.0955952725917255
Validation loss: 2.0002242512128494
Epoch: 7| Step: 9
Training loss: 2.2256557826907786
Validation loss: 1.9998474960627837
Epoch: 7| Step: 10
Training loss: 2.0645571766366286
Validation loss: 1.9807093769407336
Epoch: 7| Step: 11
Training loss: 2.2339992607409176
Validation loss: 1.9980892840720668
Epoch: 7| Step: 12
Training loss: 2.9591593775600797
Validation loss: 1.996097671144865
Epoch: 7| Step: 13
Training loss: 2.3998223199240836
Validation loss: 2.0012332782936357
Epoch: 7| Step: 14
Training loss: 2.400622040881593
Validation loss: 1.9851589831357292
Epoch: 7| Step: 15
Training loss: 2.641367610365581
Validation loss: 1.9957088002827805
Epoch: 100| Step: 0
Training loss: 2.3512480769537403
Validation loss: 1.980042702096413
Epoch: 7| Step: 1
Training loss: 2.29578960490136
Validation loss: 2.004599912701204
Epoch: 7| Step: 2
Training loss: 2.4106378553273724
Validation loss: 1.9955528471437614
Epoch: 7| Step: 3
Training loss: 2.790033251656532
Validation loss: 2.0038189754182016
Epoch: 7| Step: 4
Training loss: 2.535664041739039
Validation loss: 1.9999027031616423
Epoch: 7| Step: 5
Training loss: 2.481239883825017
Validation loss: 2.0028974143713256
Epoch: 7| Step: 6
Training loss: 2.2766720548410544
Validation loss: 2.0188199765936075
Epoch: 7| Step: 7
Training loss: 2.8877260260033886
Validation loss: 2.010939151692252
Epoch: 7| Step: 8
Training loss: 2.8010138889882232
Validation loss: 2.0129035003060483
Epoch: 7| Step: 9
Training loss: 2.137865836084988
Validation loss: 2.000557446653348
Epoch: 7| Step: 10
Training loss: 2.2333938471818264
Validation loss: 2.0029310245173306
Epoch: 7| Step: 11
Training loss: 1.8405558186144606
Validation loss: 2.0113790958260296
Epoch: 7| Step: 12
Training loss: 2.388123843191027
Validation loss: 2.019016032347784
Epoch: 7| Step: 13
Training loss: 2.150169201779934
Validation loss: 2.0127732386454835
Epoch: 7| Step: 14
Training loss: 2.430644837208019
Validation loss: 2.015813219002924
Epoch: 7| Step: 15
Training loss: 2.069688119843575
Validation loss: 2.0176633045882006
