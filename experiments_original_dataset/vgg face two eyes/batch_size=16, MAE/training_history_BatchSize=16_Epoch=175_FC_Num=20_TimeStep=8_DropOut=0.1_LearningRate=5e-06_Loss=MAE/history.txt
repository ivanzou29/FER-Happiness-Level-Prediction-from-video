Epoch: 1| Step: 0
Training loss: 2.747302293777466
Validation loss: 2.3522619009017944

Epoch: 6| Step: 1
Training loss: 2.699742317199707
Validation loss: 2.3392059206962585

Epoch: 6| Step: 2
Training loss: 2.601059913635254
Validation loss: 2.3252052466074624

Epoch: 6| Step: 3
Training loss: 2.6774187088012695
Validation loss: 2.3083864053090415

Epoch: 6| Step: 4
Training loss: 2.5768938064575195
Validation loss: 2.2934858202934265

Epoch: 6| Step: 5
Training loss: 1.8393208980560303
Validation loss: 2.2820050915082297

Epoch: 6| Step: 6
Training loss: 2.580124855041504
Validation loss: 2.265744149684906

Epoch: 6| Step: 7
Training loss: 1.9145722389221191
Validation loss: 2.2516988118489585

Epoch: 6| Step: 8
Training loss: 2.023770809173584
Validation loss: 2.2365085085233054

Epoch: 6| Step: 9
Training loss: 2.7093417644500732
Validation loss: 2.2198890248934426

Epoch: 6| Step: 10
Training loss: 2.444863796234131
Validation loss: 2.2111360232035318

Epoch: 6| Step: 11
Training loss: 2.769408941268921
Validation loss: 2.1992201805114746

Epoch: 6| Step: 12
Training loss: 2.3422658443450928
Validation loss: 2.188453435897827

Epoch: 6| Step: 13
Training loss: 1.8705389499664307
Validation loss: 2.176778177420298

Epoch: 2| Step: 0
Training loss: 1.5330069065093994
Validation loss: 2.1677496631940207

Epoch: 6| Step: 1
Training loss: 2.258113384246826
Validation loss: 2.1583990852038064

Epoch: 6| Step: 2
Training loss: 2.338273286819458
Validation loss: 2.1415999929110208

Epoch: 6| Step: 3
Training loss: 2.274327039718628
Validation loss: 2.1305669148763022

Epoch: 6| Step: 4
Training loss: 2.5240864753723145
Validation loss: 2.1167960166931152

Epoch: 6| Step: 5
Training loss: 2.2959001064300537
Validation loss: 2.111309011777242

Epoch: 6| Step: 6
Training loss: 2.1612331867218018
Validation loss: 2.098179817199707

Epoch: 6| Step: 7
Training loss: 2.2436091899871826
Validation loss: 2.088168958822886

Epoch: 6| Step: 8
Training loss: 2.5684218406677246
Validation loss: 2.0815266768137612

Epoch: 6| Step: 9
Training loss: 1.519944190979004
Validation loss: 2.0746456583340964

Epoch: 6| Step: 10
Training loss: 2.365696907043457
Validation loss: 2.0702988107999167

Epoch: 6| Step: 11
Training loss: 2.4961166381835938
Validation loss: 2.063735624154409

Epoch: 6| Step: 12
Training loss: 2.6879942417144775
Validation loss: 2.0573366284370422

Epoch: 6| Step: 13
Training loss: 2.556114912033081
Validation loss: 2.0561719139417014

Epoch: 3| Step: 0
Training loss: 2.1607632637023926
Validation loss: 2.05509481827418

Epoch: 6| Step: 1
Training loss: 1.659780502319336
Validation loss: 2.0521050492922464

Epoch: 6| Step: 2
Training loss: 2.7956790924072266
Validation loss: 2.0501173933347068

Epoch: 6| Step: 3
Training loss: 2.1319057941436768
Validation loss: 2.0470517675081887

Epoch: 6| Step: 4
Training loss: 2.190641403198242
Validation loss: 2.0439891616503396

Epoch: 6| Step: 5
Training loss: 1.7766132354736328
Validation loss: 2.040666699409485

Epoch: 6| Step: 6
Training loss: 2.7062559127807617
Validation loss: 2.0473664005597434

Epoch: 6| Step: 7
Training loss: 2.2446975708007812
Validation loss: 2.0499340891838074

Epoch: 6| Step: 8
Training loss: 2.3640599250793457
Validation loss: 2.045808712641398

Epoch: 6| Step: 9
Training loss: 2.0546011924743652
Validation loss: 2.05175119638443

Epoch: 6| Step: 10
Training loss: 2.423865795135498
Validation loss: 2.051453193028768

Epoch: 6| Step: 11
Training loss: 1.778258204460144
Validation loss: 2.0530030926068625

Epoch: 6| Step: 12
Training loss: 2.0490546226501465
Validation loss: 2.057033916314443

Epoch: 6| Step: 13
Training loss: 2.3838424682617188
Validation loss: 2.0594090620676675

Epoch: 4| Step: 0
Training loss: 2.5367236137390137
Validation loss: 2.0598588784535727

Epoch: 6| Step: 1
Training loss: 2.689504861831665
Validation loss: 2.058780868848165

Epoch: 6| Step: 2
Training loss: 2.614043712615967
Validation loss: 2.0675339698791504

Epoch: 6| Step: 3
Training loss: 2.6743462085723877
Validation loss: 2.0729368925094604

Epoch: 6| Step: 4
Training loss: 1.2576632499694824
Validation loss: 2.067799190680186

Epoch: 6| Step: 5
Training loss: 2.1972122192382812
Validation loss: 2.0664793451627097

Epoch: 6| Step: 6
Training loss: 1.532891035079956
Validation loss: 2.076883296171824

Epoch: 6| Step: 7
Training loss: 2.466752290725708
Validation loss: 2.0751742919286094

Epoch: 6| Step: 8
Training loss: 2.2402491569519043
Validation loss: 2.0796488523483276

Epoch: 6| Step: 9
Training loss: 2.029019594192505
Validation loss: 2.083523432413737

Epoch: 6| Step: 10
Training loss: 2.4437355995178223
Validation loss: 2.0802937944730124

Epoch: 6| Step: 11
Training loss: 1.7690222263336182
Validation loss: 2.0849935015042624

Epoch: 6| Step: 12
Training loss: 1.8284529447555542
Validation loss: 2.080000082651774

Epoch: 6| Step: 13
Training loss: 2.0607433319091797
Validation loss: 2.0852649807929993

Epoch: 5| Step: 0
Training loss: 2.034262180328369
Validation loss: 2.087018132209778

Epoch: 6| Step: 1
Training loss: 1.9350506067276
Validation loss: 2.0942713220914206

Epoch: 6| Step: 2
Training loss: 2.7235636711120605
Validation loss: 2.093129336833954

Epoch: 6| Step: 3
Training loss: 2.1093177795410156
Validation loss: 2.0938455859820047

Epoch: 6| Step: 4
Training loss: 2.1816136837005615
Validation loss: 2.096817374229431

Epoch: 6| Step: 5
Training loss: 2.8100266456604004
Validation loss: 2.1018309394518533

Epoch: 6| Step: 6
Training loss: 1.924167513847351
Validation loss: 2.0969738960266113

Epoch: 6| Step: 7
Training loss: 2.444220542907715
Validation loss: 2.1013044317563376

Epoch: 6| Step: 8
Training loss: 1.5360602140426636
Validation loss: 2.100005030632019

Epoch: 6| Step: 9
Training loss: 1.904908299446106
Validation loss: 2.1027752161026

Epoch: 6| Step: 10
Training loss: 1.8441355228424072
Validation loss: 2.1041265527407327

Epoch: 6| Step: 11
Training loss: 2.2396998405456543
Validation loss: 2.1093324025472007

Epoch: 6| Step: 12
Training loss: 2.5476369857788086
Validation loss: 2.1101505557696023

Epoch: 6| Step: 13
Training loss: 1.8752716779708862
Validation loss: 2.1079667607943215

Epoch: 6| Step: 0
Training loss: 2.3129305839538574
Validation loss: 2.1099960605303445

Epoch: 6| Step: 1
Training loss: 1.5517473220825195
Validation loss: 2.101606289545695

Epoch: 6| Step: 2
Training loss: 1.7020615339279175
Validation loss: 2.10161554813385

Epoch: 6| Step: 3
Training loss: 2.656188726425171
Validation loss: 2.095913310845693

Epoch: 6| Step: 4
Training loss: 2.4899582862854004
Validation loss: 2.095146735509237

Epoch: 6| Step: 5
Training loss: 1.8329110145568848
Validation loss: 2.095356365044912

Epoch: 6| Step: 6
Training loss: 1.5317778587341309
Validation loss: 2.0880883932113647

Epoch: 6| Step: 7
Training loss: 2.2854065895080566
Validation loss: 2.089827756086985

Epoch: 6| Step: 8
Training loss: 1.9931187629699707
Validation loss: 2.0903987089792886

Epoch: 6| Step: 9
Training loss: 1.9501185417175293
Validation loss: 2.093739628791809

Epoch: 6| Step: 10
Training loss: 2.496615409851074
Validation loss: 2.095081011454264

Epoch: 6| Step: 11
Training loss: 2.0306813716888428
Validation loss: 2.0981225768725076

Epoch: 6| Step: 12
Training loss: 2.4656596183776855
Validation loss: 2.098708709081014

Epoch: 6| Step: 13
Training loss: 2.7878568172454834
Validation loss: 2.0975714921951294

Epoch: 7| Step: 0
Training loss: 1.9447853565216064
Validation loss: 2.0981528560320535

Epoch: 6| Step: 1
Training loss: 1.4652338027954102
Validation loss: 2.0991217891375222

Epoch: 6| Step: 2
Training loss: 2.1829488277435303
Validation loss: 2.0980995098749795

Epoch: 6| Step: 3
Training loss: 2.134127378463745
Validation loss: 2.093857983748118

Epoch: 6| Step: 4
Training loss: 2.017451763153076
Validation loss: 2.091950257619222

Epoch: 6| Step: 5
Training loss: 2.1667590141296387
Validation loss: 2.096824904282888

Epoch: 6| Step: 6
Training loss: 2.144123077392578
Validation loss: 2.09835155804952

Epoch: 6| Step: 7
Training loss: 2.6470465660095215
Validation loss: 2.0986467599868774

Epoch: 6| Step: 8
Training loss: 1.9572052955627441
Validation loss: 2.1052002708117166

Epoch: 6| Step: 9
Training loss: 1.9632694721221924
Validation loss: 2.0980170369148254

Epoch: 6| Step: 10
Training loss: 2.975884437561035
Validation loss: 2.103720545768738

Epoch: 6| Step: 11
Training loss: 1.9563710689544678
Validation loss: 2.1004408399264016

Epoch: 6| Step: 12
Training loss: 2.2018613815307617
Validation loss: 2.0972545742988586

Epoch: 6| Step: 13
Training loss: 2.1343367099761963
Validation loss: 2.0952239831288657

Epoch: 8| Step: 0
Training loss: 2.169750213623047
Validation loss: 2.097978393236796

Epoch: 6| Step: 1
Training loss: 1.9815659523010254
Validation loss: 2.086755653222402

Epoch: 6| Step: 2
Training loss: 2.0403385162353516
Validation loss: 2.0897598266601562

Epoch: 6| Step: 3
Training loss: 2.375776767730713
Validation loss: 2.0804412961006165

Epoch: 6| Step: 4
Training loss: 1.7146068811416626
Validation loss: 2.0769327878952026

Epoch: 6| Step: 5
Training loss: 1.6068897247314453
Validation loss: 2.0782100558280945

Epoch: 6| Step: 6
Training loss: 2.731086254119873
Validation loss: 2.0838346680005393

Epoch: 6| Step: 7
Training loss: 1.4747223854064941
Validation loss: 2.07549387216568

Epoch: 6| Step: 8
Training loss: 2.356743097305298
Validation loss: 2.0748278299967446

Epoch: 6| Step: 9
Training loss: 2.359071731567383
Validation loss: 2.0778605143229165

Epoch: 6| Step: 10
Training loss: 2.247243881225586
Validation loss: 2.076836903889974

Epoch: 6| Step: 11
Training loss: 2.1381630897521973
Validation loss: 2.072781503200531

Epoch: 6| Step: 12
Training loss: 1.999547004699707
Validation loss: 2.0735167860984802

Epoch: 6| Step: 13
Training loss: 2.59019136428833
Validation loss: 2.0669415990511575

Epoch: 9| Step: 0
Training loss: 2.8559675216674805
Validation loss: 2.067419727643331

Epoch: 6| Step: 1
Training loss: 2.191558599472046
Validation loss: 2.069202502568563

Epoch: 6| Step: 2
Training loss: 2.093656539916992
Validation loss: 2.0717305342356362

Epoch: 6| Step: 3
Training loss: 2.439253330230713
Validation loss: 2.054766754309336

Epoch: 6| Step: 4
Training loss: 1.847461462020874
Validation loss: 2.061595857143402

Epoch: 6| Step: 5
Training loss: 1.762125849723816
Validation loss: 2.0655889312426248

Epoch: 6| Step: 6
Training loss: 1.5320634841918945
Validation loss: 2.063677748044332

Epoch: 6| Step: 7
Training loss: 1.9364242553710938
Validation loss: 2.069275657335917

Epoch: 6| Step: 8
Training loss: 2.3172922134399414
Validation loss: 2.0687251488367715

Epoch: 6| Step: 9
Training loss: 2.187581777572632
Validation loss: 2.067038814226786

Epoch: 6| Step: 10
Training loss: 2.5361571311950684
Validation loss: 2.0744354724884033

Epoch: 6| Step: 11
Training loss: 1.9801464080810547
Validation loss: 2.0785677631696067

Epoch: 6| Step: 12
Training loss: 2.0063118934631348
Validation loss: 2.0762784481048584

Epoch: 6| Step: 13
Training loss: 2.0779240131378174
Validation loss: 2.077285905679067

Epoch: 10| Step: 0
Training loss: 2.0277819633483887
Validation loss: 2.071797549724579

Epoch: 6| Step: 1
Training loss: 2.3455703258514404
Validation loss: 2.071019689242045

Epoch: 6| Step: 2
Training loss: 1.9451810121536255
Validation loss: 2.0672216018040976

Epoch: 6| Step: 3
Training loss: 2.131087303161621
Validation loss: 2.0639412800470986

Epoch: 6| Step: 4
Training loss: 2.313537120819092
Validation loss: 2.0543057719866433

Epoch: 6| Step: 5
Training loss: 2.3459153175354004
Validation loss: 2.052026629447937

Epoch: 6| Step: 6
Training loss: 2.463204860687256
Validation loss: 2.0520957310994468

Epoch: 6| Step: 7
Training loss: 1.3770869970321655
Validation loss: 2.05126158396403

Epoch: 6| Step: 8
Training loss: 2.626723527908325
Validation loss: 2.0510782996813455

Epoch: 6| Step: 9
Training loss: 1.8719607591629028
Validation loss: 2.0499866207440696

Epoch: 6| Step: 10
Training loss: 2.285616874694824
Validation loss: 2.0499255657196045

Epoch: 6| Step: 11
Training loss: 2.141669511795044
Validation loss: 2.045966903368632

Epoch: 6| Step: 12
Training loss: 1.8435826301574707
Validation loss: 2.053893566131592

Epoch: 6| Step: 13
Training loss: 1.9169033765792847
Validation loss: 2.0510491927464805

Epoch: 11| Step: 0
Training loss: 1.4180947542190552
Validation loss: 2.056822200616201

Epoch: 6| Step: 1
Training loss: 1.6763317584991455
Validation loss: 2.063132186730703

Epoch: 6| Step: 2
Training loss: 1.6901109218597412
Validation loss: 2.0673784812291465

Epoch: 6| Step: 3
Training loss: 2.310093879699707
Validation loss: 2.071856955687205

Epoch: 6| Step: 4
Training loss: 2.8577022552490234
Validation loss: 2.0683515270551047

Epoch: 6| Step: 5
Training loss: 2.138700008392334
Validation loss: 2.0716237823168435

Epoch: 6| Step: 6
Training loss: 1.995352029800415
Validation loss: 2.0823785265286765

Epoch: 6| Step: 7
Training loss: 1.8711833953857422
Validation loss: 2.0863030354181924

Epoch: 6| Step: 8
Training loss: 2.5056064128875732
Validation loss: 2.0816952188809714

Epoch: 6| Step: 9
Training loss: 2.3407719135284424
Validation loss: 2.0770357648531594

Epoch: 6| Step: 10
Training loss: 2.4687530994415283
Validation loss: 2.0745365023612976

Epoch: 6| Step: 11
Training loss: 1.659670114517212
Validation loss: 2.0720959901809692

Epoch: 6| Step: 12
Training loss: 2.4131929874420166
Validation loss: 2.0668709874153137

Epoch: 6| Step: 13
Training loss: 2.2103233337402344
Validation loss: 2.0670508543650308

Epoch: 12| Step: 0
Training loss: 2.2533721923828125
Validation loss: 2.062443812688192

Epoch: 6| Step: 1
Training loss: 2.3426921367645264
Validation loss: 2.0591274301211038

Epoch: 6| Step: 2
Training loss: 2.2968945503234863
Validation loss: 2.0601413249969482

Epoch: 6| Step: 3
Training loss: 2.2362358570098877
Validation loss: 2.049884001413981

Epoch: 6| Step: 4
Training loss: 2.271308422088623
Validation loss: 2.0530497630437217

Epoch: 6| Step: 5
Training loss: 2.5687780380249023
Validation loss: 2.0385454893112183

Epoch: 6| Step: 6
Training loss: 2.555002212524414
Validation loss: 2.039359986782074

Epoch: 6| Step: 7
Training loss: 1.9882211685180664
Validation loss: 2.0429893136024475

Epoch: 6| Step: 8
Training loss: 2.035249710083008
Validation loss: 2.0478776494661965

Epoch: 6| Step: 9
Training loss: 1.8027151823043823
Validation loss: 2.0382418036460876

Epoch: 6| Step: 10
Training loss: 1.4395458698272705
Validation loss: 2.0395796298980713

Epoch: 6| Step: 11
Training loss: 1.9982686042785645
Validation loss: 2.0367648601531982

Epoch: 6| Step: 12
Training loss: 1.6269242763519287
Validation loss: 2.0429365237553916

Epoch: 6| Step: 13
Training loss: 1.9751390218734741
Validation loss: 2.051835854848226

Epoch: 13| Step: 0
Training loss: 2.1023359298706055
Validation loss: 2.0468347867329917

Epoch: 6| Step: 1
Training loss: 1.79403555393219
Validation loss: 2.052930156389872

Epoch: 6| Step: 2
Training loss: 2.339273452758789
Validation loss: 2.058267335096995

Epoch: 6| Step: 3
Training loss: 2.005183696746826
Validation loss: 2.0532317558924356

Epoch: 6| Step: 4
Training loss: 2.03657865524292
Validation loss: 2.062208890914917

Epoch: 6| Step: 5
Training loss: 1.7001080513000488
Validation loss: 2.0593822797139487

Epoch: 6| Step: 6
Training loss: 2.4958479404449463
Validation loss: 2.0702232718467712

Epoch: 6| Step: 7
Training loss: 1.905319094657898
Validation loss: 2.0709065000216165

Epoch: 6| Step: 8
Training loss: 1.9712038040161133
Validation loss: 2.079959273338318

Epoch: 6| Step: 9
Training loss: 2.2626495361328125
Validation loss: 2.0800744692484536

Epoch: 6| Step: 10
Training loss: 1.8966221809387207
Validation loss: 2.082567791144053

Epoch: 6| Step: 11
Training loss: 2.082721710205078
Validation loss: 2.0879672169685364

Epoch: 6| Step: 12
Training loss: 2.479769229888916
Validation loss: 2.0881476203600564

Epoch: 6| Step: 13
Training loss: 2.0898025035858154
Validation loss: 2.0844354828198752

Epoch: 14| Step: 0
Training loss: 2.504805564880371
Validation loss: 2.0806785821914673

Epoch: 6| Step: 1
Training loss: 2.3392343521118164
Validation loss: 2.073139508565267

Epoch: 6| Step: 2
Training loss: 2.038261890411377
Validation loss: 2.069848577181498

Epoch: 6| Step: 3
Training loss: 2.197693347930908
Validation loss: 2.057015041510264

Epoch: 6| Step: 4
Training loss: 2.420661211013794
Validation loss: 2.0597785313924155

Epoch: 6| Step: 5
Training loss: 2.3299953937530518
Validation loss: 2.0525154868761697

Epoch: 6| Step: 6
Training loss: 1.8061473369598389
Validation loss: 2.041577955087026

Epoch: 6| Step: 7
Training loss: 1.9829355478286743
Validation loss: 2.042462468147278

Epoch: 6| Step: 8
Training loss: 1.6819677352905273
Validation loss: 2.0395480593045554

Epoch: 6| Step: 9
Training loss: 1.9272300004959106
Validation loss: 2.0389538009961448

Epoch: 6| Step: 10
Training loss: 1.666982650756836
Validation loss: 2.036536912123362

Epoch: 6| Step: 11
Training loss: 2.2656965255737305
Validation loss: 2.0305543740590415

Epoch: 6| Step: 12
Training loss: 1.415390968322754
Validation loss: 2.029628098011017

Epoch: 6| Step: 13
Training loss: 2.341627359390259
Validation loss: 2.025816857814789

Epoch: 15| Step: 0
Training loss: 1.7773239612579346
Validation loss: 2.022884746392568

Epoch: 6| Step: 1
Training loss: 2.4290122985839844
Validation loss: 2.0251938899358115

Epoch: 6| Step: 2
Training loss: 2.1166374683380127
Validation loss: 2.021125872929891

Epoch: 6| Step: 3
Training loss: 1.61702561378479
Validation loss: 2.018337925275167

Epoch: 6| Step: 4
Training loss: 2.101954221725464
Validation loss: 2.0112787087758384

Epoch: 6| Step: 5
Training loss: 2.3631980419158936
Validation loss: 2.0191070437431335

Epoch: 6| Step: 6
Training loss: 1.6745433807373047
Validation loss: 2.022355079650879

Epoch: 6| Step: 7
Training loss: 2.542201042175293
Validation loss: 2.0205891132354736

Epoch: 6| Step: 8
Training loss: 2.109718084335327
Validation loss: 2.016669770081838

Epoch: 6| Step: 9
Training loss: 2.0044336318969727
Validation loss: 2.0246543486913047

Epoch: 6| Step: 10
Training loss: 2.4090826511383057
Validation loss: 2.0289061466852822

Epoch: 6| Step: 11
Training loss: 1.5538824796676636
Validation loss: 2.018128971258799

Epoch: 6| Step: 12
Training loss: 2.166858673095703
Validation loss: 2.033582925796509

Epoch: 6| Step: 13
Training loss: 1.9737434387207031
Validation loss: 2.0371525486310325

Epoch: 16| Step: 0
Training loss: 1.9666428565979004
Validation loss: 2.0461482405662537

Epoch: 6| Step: 1
Training loss: 2.72712779045105
Validation loss: 2.0504111647605896

Epoch: 6| Step: 2
Training loss: 2.7957005500793457
Validation loss: 2.038543085257212

Epoch: 6| Step: 3
Training loss: 1.5366913080215454
Validation loss: 2.034923334916433

Epoch: 6| Step: 4
Training loss: 2.1481337547302246
Validation loss: 2.036330501238505

Epoch: 6| Step: 5
Training loss: 2.252075672149658
Validation loss: 2.0370452205340066

Epoch: 6| Step: 6
Training loss: 1.7764670848846436
Validation loss: 2.0435806711514792

Epoch: 6| Step: 7
Training loss: 1.4626975059509277
Validation loss: 2.0456100503603616

Epoch: 6| Step: 8
Training loss: 2.5405194759368896
Validation loss: 2.042136828104655

Epoch: 6| Step: 9
Training loss: 2.037351131439209
Validation loss: 2.044792652130127

Epoch: 6| Step: 10
Training loss: 1.57956862449646
Validation loss: 2.0331507523854575

Epoch: 6| Step: 11
Training loss: 2.3231101036071777
Validation loss: 2.0342042644818625

Epoch: 6| Step: 12
Training loss: 1.5792477130889893
Validation loss: 2.03301211198171

Epoch: 6| Step: 13
Training loss: 1.9551701545715332
Validation loss: 2.023841400941213

Epoch: 17| Step: 0
Training loss: 2.902827262878418
Validation loss: 2.030165453751882

Epoch: 6| Step: 1
Training loss: 2.1373867988586426
Validation loss: 2.020393172899882

Epoch: 6| Step: 2
Training loss: 1.8807117938995361
Validation loss: 2.023690680662791

Epoch: 6| Step: 3
Training loss: 2.231353282928467
Validation loss: 2.0305518905321756

Epoch: 6| Step: 4
Training loss: 2.4586124420166016
Validation loss: 2.0240145524342856

Epoch: 6| Step: 5
Training loss: 1.910737156867981
Validation loss: 2.0194580952326455

Epoch: 6| Step: 6
Training loss: 2.271364450454712
Validation loss: 2.0272151629130044

Epoch: 6| Step: 7
Training loss: 1.8890047073364258
Validation loss: 2.02426016330719

Epoch: 6| Step: 8
Training loss: 1.5524038076400757
Validation loss: 2.0236803094546

Epoch: 6| Step: 9
Training loss: 1.6755692958831787
Validation loss: 2.021544257799784

Epoch: 6| Step: 10
Training loss: 1.688440203666687
Validation loss: 2.0229468941688538

Epoch: 6| Step: 11
Training loss: 1.8225713968276978
Validation loss: 2.022066911061605

Epoch: 6| Step: 12
Training loss: 2.484464168548584
Validation loss: 2.0277934074401855

Epoch: 6| Step: 13
Training loss: 1.4357465505599976
Validation loss: 2.021155536174774

Epoch: 18| Step: 0
Training loss: 2.641611337661743
Validation loss: 2.019695540269216

Epoch: 6| Step: 1
Training loss: 2.082653522491455
Validation loss: 2.0146912932395935

Epoch: 6| Step: 2
Training loss: 1.8472237586975098
Validation loss: 2.021519939104716

Epoch: 6| Step: 3
Training loss: 2.148372173309326
Validation loss: 2.01257461309433

Epoch: 6| Step: 4
Training loss: 2.196673631668091
Validation loss: 2.0236862301826477

Epoch: 6| Step: 5
Training loss: 2.1113829612731934
Validation loss: 2.0287452936172485

Epoch: 6| Step: 6
Training loss: 2.355086326599121
Validation loss: 2.0276676019032798

Epoch: 6| Step: 7
Training loss: 2.0495896339416504
Validation loss: 2.013562778631846

Epoch: 6| Step: 8
Training loss: 1.924482822418213
Validation loss: 2.018424371878306

Epoch: 6| Step: 9
Training loss: 1.7797398567199707
Validation loss: 2.0205286542574563

Epoch: 6| Step: 10
Training loss: 2.0649709701538086
Validation loss: 2.017871697743734

Epoch: 6| Step: 11
Training loss: 1.7022032737731934
Validation loss: 2.024848222732544

Epoch: 6| Step: 12
Training loss: 1.7666938304901123
Validation loss: 2.0220834016799927

Epoch: 6| Step: 13
Training loss: 1.4370452165603638
Validation loss: 2.0144835313161216

Epoch: 19| Step: 0
Training loss: 1.7988348007202148
Validation loss: 2.0145962238311768

Epoch: 6| Step: 1
Training loss: 1.701475739479065
Validation loss: 2.0114580591519675

Epoch: 6| Step: 2
Training loss: 2.3024697303771973
Validation loss: 2.0012978116671243

Epoch: 6| Step: 3
Training loss: 1.6680629253387451
Validation loss: 2.0106765230496726

Epoch: 6| Step: 4
Training loss: 2.1940841674804688
Validation loss: 2.0100290973981223

Epoch: 6| Step: 5
Training loss: 1.7899324893951416
Validation loss: 2.0196212331453958

Epoch: 6| Step: 6
Training loss: 2.5446057319641113
Validation loss: 2.0132601261138916

Epoch: 6| Step: 7
Training loss: 1.8160954713821411
Validation loss: 2.009749929110209

Epoch: 6| Step: 8
Training loss: 1.5379478931427002
Validation loss: 2.025067706902822

Epoch: 6| Step: 9
Training loss: 2.195336103439331
Validation loss: 2.0343835751215615

Epoch: 6| Step: 10
Training loss: 1.7700824737548828
Validation loss: 2.031856119632721

Epoch: 6| Step: 11
Training loss: 2.6622774600982666
Validation loss: 2.0330468018849692

Epoch: 6| Step: 12
Training loss: 1.7711352109909058
Validation loss: 2.035424073537191

Epoch: 6| Step: 13
Training loss: 2.195096254348755
Validation loss: 2.03102844953537

Epoch: 20| Step: 0
Training loss: 2.3175153732299805
Validation loss: 2.031645874182383

Epoch: 6| Step: 1
Training loss: 1.7769910097122192
Validation loss: 2.019491712252299

Epoch: 6| Step: 2
Training loss: 1.7410478591918945
Validation loss: 2.0129016836484275

Epoch: 6| Step: 3
Training loss: 2.099031925201416
Validation loss: 2.017804523309072

Epoch: 6| Step: 4
Training loss: 2.2702367305755615
Validation loss: 2.0167855421702066

Epoch: 6| Step: 5
Training loss: 1.3923866748809814
Validation loss: 2.0066643555959067

Epoch: 6| Step: 6
Training loss: 2.2587618827819824
Validation loss: 2.0134230653444924

Epoch: 6| Step: 7
Training loss: 1.6842072010040283
Validation loss: 2.0119280417760215

Epoch: 6| Step: 8
Training loss: 1.8397552967071533
Validation loss: 2.011970043182373

Epoch: 6| Step: 9
Training loss: 2.0847504138946533
Validation loss: 2.0153003931045532

Epoch: 6| Step: 10
Training loss: 1.9392874240875244
Validation loss: 2.0143408377965293

Epoch: 6| Step: 11
Training loss: 1.7172179222106934
Validation loss: 2.03758970896403

Epoch: 6| Step: 12
Training loss: 2.1635143756866455
Validation loss: 2.024034877618154

Epoch: 6| Step: 13
Training loss: 2.313567638397217
Validation loss: 2.0320332050323486

Epoch: 21| Step: 0
Training loss: 0.6887496113777161
Validation loss: 2.035192886988322

Epoch: 6| Step: 1
Training loss: 1.7926921844482422
Validation loss: 2.0296987493832908

Epoch: 6| Step: 2
Training loss: 1.2991509437561035
Validation loss: 2.037605365117391

Epoch: 6| Step: 3
Training loss: 2.631321668624878
Validation loss: 2.0474769671758017

Epoch: 6| Step: 4
Training loss: 1.9284619092941284
Validation loss: 2.054569582144419

Epoch: 6| Step: 5
Training loss: 1.6129525899887085
Validation loss: 2.049634039402008

Epoch: 6| Step: 6
Training loss: 2.4059906005859375
Validation loss: 2.046942949295044

Epoch: 6| Step: 7
Training loss: 1.7099264860153198
Validation loss: 2.0293941100438437

Epoch: 6| Step: 8
Training loss: 2.0504555702209473
Validation loss: 2.011286954085032

Epoch: 6| Step: 9
Training loss: 2.447977066040039
Validation loss: 2.0199272632598877

Epoch: 6| Step: 10
Training loss: 1.8375470638275146
Validation loss: 1.9994236032168071

Epoch: 6| Step: 11
Training loss: 2.105135440826416
Validation loss: 1.9983577330907185

Epoch: 6| Step: 12
Training loss: 1.8256151676177979
Validation loss: 2.000436703364054

Epoch: 6| Step: 13
Training loss: 2.941779375076294
Validation loss: 1.9972392320632935

Epoch: 22| Step: 0
Training loss: 1.5034338235855103
Validation loss: 2.000568985939026

Epoch: 6| Step: 1
Training loss: 2.281428575515747
Validation loss: 1.997287094593048

Epoch: 6| Step: 2
Training loss: 1.6526381969451904
Validation loss: 1.9913660883903503

Epoch: 6| Step: 3
Training loss: 1.6404750347137451
Validation loss: 1.9866733153661091

Epoch: 6| Step: 4
Training loss: 2.2740478515625
Validation loss: 1.9942177931467693

Epoch: 6| Step: 5
Training loss: 2.0693588256835938
Validation loss: 1.9902563691139221

Epoch: 6| Step: 6
Training loss: 2.1193997859954834
Validation loss: 1.9916449983914692

Epoch: 6| Step: 7
Training loss: 2.1444239616394043
Validation loss: 1.9895209074020386

Epoch: 6| Step: 8
Training loss: 1.3962647914886475
Validation loss: 1.9878581364949544

Epoch: 6| Step: 9
Training loss: 1.6831445693969727
Validation loss: 1.9862539172172546

Epoch: 6| Step: 10
Training loss: 2.1209845542907715
Validation loss: 1.9914302428563435

Epoch: 6| Step: 11
Training loss: 2.3393821716308594
Validation loss: 2.012893001238505

Epoch: 6| Step: 12
Training loss: 1.9851009845733643
Validation loss: 2.0123778184254966

Epoch: 6| Step: 13
Training loss: 2.127973794937134
Validation loss: 2.018431822458903

Epoch: 23| Step: 0
Training loss: 1.7883501052856445
Validation loss: 2.0254066586494446

Epoch: 6| Step: 1
Training loss: 2.077685832977295
Validation loss: 2.0150146484375

Epoch: 6| Step: 2
Training loss: 1.7113540172576904
Validation loss: 2.013930638631185

Epoch: 6| Step: 3
Training loss: 1.7129192352294922
Validation loss: 2.006195843219757

Epoch: 6| Step: 4
Training loss: 1.935898780822754
Validation loss: 2.00766529639562

Epoch: 6| Step: 5
Training loss: 1.959315538406372
Validation loss: 2.0067644317944846

Epoch: 6| Step: 6
Training loss: 2.149275064468384
Validation loss: 2.0187543630599976

Epoch: 6| Step: 7
Training loss: 1.9587268829345703
Validation loss: 2.0350243846575418

Epoch: 6| Step: 8
Training loss: 1.2655820846557617
Validation loss: 2.0486281315485635

Epoch: 6| Step: 9
Training loss: 2.021867036819458
Validation loss: 2.0478517015775046

Epoch: 6| Step: 10
Training loss: 2.148099899291992
Validation loss: 2.041934609413147

Epoch: 6| Step: 11
Training loss: 1.9621977806091309
Validation loss: 2.0480215152104697

Epoch: 6| Step: 12
Training loss: 2.3096346855163574
Validation loss: 2.0253653327624

Epoch: 6| Step: 13
Training loss: 2.32186222076416
Validation loss: 2.0305627385775247

Epoch: 24| Step: 0
Training loss: 2.1783506870269775
Validation loss: 2.01375675201416

Epoch: 6| Step: 1
Training loss: 1.9122064113616943
Validation loss: 1.9934257864952087

Epoch: 6| Step: 2
Training loss: 1.9920196533203125
Validation loss: 1.9967089891433716

Epoch: 6| Step: 3
Training loss: 1.5999174118041992
Validation loss: 1.9959489504496257

Epoch: 6| Step: 4
Training loss: 1.6391383409500122
Validation loss: 1.989333728949229

Epoch: 6| Step: 5
Training loss: 1.9514449834823608
Validation loss: 1.9918878078460693

Epoch: 6| Step: 6
Training loss: 2.071139335632324
Validation loss: 1.9914096593856812

Epoch: 6| Step: 7
Training loss: 1.8887020349502563
Validation loss: 2.002534329891205

Epoch: 6| Step: 8
Training loss: 2.0955381393432617
Validation loss: 1.992469807465871

Epoch: 6| Step: 9
Training loss: 2.3845696449279785
Validation loss: 1.992093066374461

Epoch: 6| Step: 10
Training loss: 1.8006094694137573
Validation loss: 1.994349479675293

Epoch: 6| Step: 11
Training loss: 1.6582903861999512
Validation loss: 1.984757622083028

Epoch: 6| Step: 12
Training loss: 2.1740193367004395
Validation loss: 1.9927281538645427

Epoch: 6| Step: 13
Training loss: 1.8577778339385986
Validation loss: 1.9922323822975159

Epoch: 25| Step: 0
Training loss: 1.7585253715515137
Validation loss: 2.0045108993848166

Epoch: 6| Step: 1
Training loss: 2.3225903511047363
Validation loss: 2.01581480105718

Epoch: 6| Step: 2
Training loss: 2.20210337638855
Validation loss: 2.0330860018730164

Epoch: 6| Step: 3
Training loss: 2.023352861404419
Validation loss: 2.043660879135132

Epoch: 6| Step: 4
Training loss: 2.2114012241363525
Validation loss: 2.042912264664968

Epoch: 6| Step: 5
Training loss: 1.5618882179260254
Validation loss: 2.0358407894770303

Epoch: 6| Step: 6
Training loss: 1.9991536140441895
Validation loss: 2.019291937351227

Epoch: 6| Step: 7
Training loss: 1.7554736137390137
Validation loss: 2.01389350493749

Epoch: 6| Step: 8
Training loss: 2.359261989593506
Validation loss: 1.9967596928278606

Epoch: 6| Step: 9
Training loss: 1.5366873741149902
Validation loss: 1.9936411380767822

Epoch: 6| Step: 10
Training loss: 2.0950961112976074
Validation loss: 2.000644783178965

Epoch: 6| Step: 11
Training loss: 2.4691667556762695
Validation loss: 2.003984808921814

Epoch: 6| Step: 12
Training loss: 1.314100980758667
Validation loss: 2.002398947874705

Epoch: 6| Step: 13
Training loss: 1.4531731605529785
Validation loss: 1.9969552556673686

Epoch: 26| Step: 0
Training loss: 1.730934739112854
Validation loss: 1.9896002411842346

Epoch: 6| Step: 1
Training loss: 1.798572063446045
Validation loss: 1.994625449180603

Epoch: 6| Step: 2
Training loss: 1.8672785758972168
Validation loss: 2.0027167201042175

Epoch: 6| Step: 3
Training loss: 2.0270607471466064
Validation loss: 2.0084696213404336

Epoch: 6| Step: 4
Training loss: 2.205200433731079
Validation loss: 1.996738612651825

Epoch: 6| Step: 5
Training loss: 1.8802659511566162
Validation loss: 2.004110594590505

Epoch: 6| Step: 6
Training loss: 2.6155762672424316
Validation loss: 1.9835910201072693

Epoch: 6| Step: 7
Training loss: 1.4623470306396484
Validation loss: 1.9833155473073323

Epoch: 6| Step: 8
Training loss: 1.1066257953643799
Validation loss: 1.9968022306760151

Epoch: 6| Step: 9
Training loss: 1.7689207792282104
Validation loss: 1.999627709388733

Epoch: 6| Step: 10
Training loss: 1.7992265224456787
Validation loss: 2.0184794863065085

Epoch: 6| Step: 11
Training loss: 2.087461471557617
Validation loss: 2.018914540608724

Epoch: 6| Step: 12
Training loss: 2.484337091445923
Validation loss: 2.0171849131584167

Epoch: 6| Step: 13
Training loss: 1.6710338592529297
Validation loss: 2.050604740778605

Epoch: 27| Step: 0
Training loss: 2.229602813720703
Validation loss: 2.0343233346939087

Epoch: 6| Step: 1
Training loss: 1.3305566310882568
Validation loss: 2.0307671427726746

Epoch: 6| Step: 2
Training loss: 1.6402746438980103
Validation loss: 2.0298068523406982

Epoch: 6| Step: 3
Training loss: 1.3676342964172363
Validation loss: 2.0114632646242776

Epoch: 6| Step: 4
Training loss: 2.0277931690216064
Validation loss: 1.9907400409380596

Epoch: 6| Step: 5
Training loss: 2.3559787273406982
Validation loss: 2.0078529914220176

Epoch: 6| Step: 6
Training loss: 2.0591979026794434
Validation loss: 1.9975120027860005

Epoch: 6| Step: 7
Training loss: 1.7606861591339111
Validation loss: 1.993313690026601

Epoch: 6| Step: 8
Training loss: 2.0200510025024414
Validation loss: 1.98389728864034

Epoch: 6| Step: 9
Training loss: 1.6839807033538818
Validation loss: 1.9741594791412354

Epoch: 6| Step: 10
Training loss: 2.304401397705078
Validation loss: 1.9809924165407817

Epoch: 6| Step: 11
Training loss: 1.6440999507904053
Validation loss: 1.9734161297480266

Epoch: 6| Step: 12
Training loss: 2.0475656986236572
Validation loss: 1.9676424860954285

Epoch: 6| Step: 13
Training loss: 1.6121163368225098
Validation loss: 1.9587769508361816

Epoch: 28| Step: 0
Training loss: 1.7829389572143555
Validation loss: 1.9643336931864421

Epoch: 6| Step: 1
Training loss: 2.0494189262390137
Validation loss: 1.966612954934438

Epoch: 6| Step: 2
Training loss: 2.6694252490997314
Validation loss: 1.9638645251592

Epoch: 6| Step: 3
Training loss: 1.8952131271362305
Validation loss: 1.9750611384709675

Epoch: 6| Step: 4
Training loss: 1.7724785804748535
Validation loss: 1.9792648553848267

Epoch: 6| Step: 5
Training loss: 2.1295337677001953
Validation loss: 1.9701979358990986

Epoch: 6| Step: 6
Training loss: 1.8357259035110474
Validation loss: 1.9606102108955383

Epoch: 6| Step: 7
Training loss: 1.7142232656478882
Validation loss: 1.9772778352101643

Epoch: 6| Step: 8
Training loss: 2.0130717754364014
Validation loss: 1.9878414273262024

Epoch: 6| Step: 9
Training loss: 2.0142464637756348
Validation loss: 1.9926720261573792

Epoch: 6| Step: 10
Training loss: 1.6973471641540527
Validation loss: 1.9974931478500366

Epoch: 6| Step: 11
Training loss: 1.539958119392395
Validation loss: 2.0185049970944724

Epoch: 6| Step: 12
Training loss: 1.382548451423645
Validation loss: 2.049509326616923

Epoch: 6| Step: 13
Training loss: 2.0499343872070312
Validation loss: 2.0905999342600503

Epoch: 29| Step: 0
Training loss: 2.016735076904297
Validation loss: 2.101881225903829

Epoch: 6| Step: 1
Training loss: 1.6756463050842285
Validation loss: 2.109051545461019

Epoch: 6| Step: 2
Training loss: 2.328641653060913
Validation loss: 2.108666479587555

Epoch: 6| Step: 3
Training loss: 1.7982796430587769
Validation loss: 2.0710083842277527

Epoch: 6| Step: 4
Training loss: 2.5012879371643066
Validation loss: 2.0778094132741294

Epoch: 6| Step: 5
Training loss: 1.9715352058410645
Validation loss: 2.048961102962494

Epoch: 6| Step: 6
Training loss: 1.6701076030731201
Validation loss: 2.0200902819633484

Epoch: 6| Step: 7
Training loss: 2.063406229019165
Validation loss: 1.9919042984644573

Epoch: 6| Step: 8
Training loss: 1.6526871919631958
Validation loss: 1.9827935099601746

Epoch: 6| Step: 9
Training loss: 2.4260306358337402
Validation loss: 1.9676197568575542

Epoch: 6| Step: 10
Training loss: 1.8851068019866943
Validation loss: 1.9670112133026123

Epoch: 6| Step: 11
Training loss: 1.4873826503753662
Validation loss: 1.973389705022176

Epoch: 6| Step: 12
Training loss: 1.6403270959854126
Validation loss: 1.9762755831082661

Epoch: 6| Step: 13
Training loss: 1.7038612365722656
Validation loss: 1.9827802578608196

Epoch: 30| Step: 0
Training loss: 2.227977991104126
Validation loss: 1.9828374981880188

Epoch: 6| Step: 1
Training loss: 1.9446378946304321
Validation loss: 1.9777386983235676

Epoch: 6| Step: 2
Training loss: 1.9158095121383667
Validation loss: 1.9757331609725952

Epoch: 6| Step: 3
Training loss: 2.0860018730163574
Validation loss: 1.960883657137553

Epoch: 6| Step: 4
Training loss: 1.6854093074798584
Validation loss: 1.9673250516255696

Epoch: 6| Step: 5
Training loss: 1.54058039188385
Validation loss: 1.9793978333473206

Epoch: 6| Step: 6
Training loss: 2.0329065322875977
Validation loss: 1.9965186913808186

Epoch: 6| Step: 7
Training loss: 1.3682703971862793
Validation loss: 2.006037096182505

Epoch: 6| Step: 8
Training loss: 1.2774550914764404
Validation loss: 2.0286575754483542

Epoch: 6| Step: 9
Training loss: 2.6415114402770996
Validation loss: 2.0380207101504006

Epoch: 6| Step: 10
Training loss: 1.7260249853134155
Validation loss: 2.0275860826174417

Epoch: 6| Step: 11
Training loss: 1.655622124671936
Validation loss: 2.0071410735448203

Epoch: 6| Step: 12
Training loss: 2.8339462280273438
Validation loss: 1.997253954410553

Epoch: 6| Step: 13
Training loss: 1.8727937936782837
Validation loss: 1.9718067049980164

Epoch: 31| Step: 0
Training loss: 2.2070345878601074
Validation loss: 1.9838834007581074

Epoch: 6| Step: 1
Training loss: 1.9296679496765137
Validation loss: 1.9745604793230693

Epoch: 6| Step: 2
Training loss: 1.7101354598999023
Validation loss: 1.979497532049815

Epoch: 6| Step: 3
Training loss: 1.8305203914642334
Validation loss: 1.9723169008890789

Epoch: 6| Step: 4
Training loss: 1.682469129562378
Validation loss: 1.9686895608901978

Epoch: 6| Step: 5
Training loss: 1.337364673614502
Validation loss: 1.9671981533368428

Epoch: 6| Step: 6
Training loss: 1.796778678894043
Validation loss: 1.97027983268102

Epoch: 6| Step: 7
Training loss: 1.5318971872329712
Validation loss: 1.9715494910875957

Epoch: 6| Step: 8
Training loss: 2.3181538581848145
Validation loss: 1.9769262075424194

Epoch: 6| Step: 9
Training loss: 1.9266209602355957
Validation loss: 1.9761801759401958

Epoch: 6| Step: 10
Training loss: 2.037480354309082
Validation loss: 1.9721882939338684

Epoch: 6| Step: 11
Training loss: 2.0876405239105225
Validation loss: 1.985978901386261

Epoch: 6| Step: 12
Training loss: 1.6329302787780762
Validation loss: 1.9925831158955891

Epoch: 6| Step: 13
Training loss: 1.7418931722640991
Validation loss: 1.9982646703720093

Epoch: 32| Step: 0
Training loss: 2.151200294494629
Validation loss: 1.9895732800165813

Epoch: 6| Step: 1
Training loss: 1.9247982501983643
Validation loss: 1.9851821660995483

Epoch: 6| Step: 2
Training loss: 1.6836353540420532
Validation loss: 1.9937568108240764

Epoch: 6| Step: 3
Training loss: 1.5194557905197144
Validation loss: 1.9973223606745403

Epoch: 6| Step: 4
Training loss: 1.606909990310669
Validation loss: 1.991686741511027

Epoch: 6| Step: 5
Training loss: 1.7398111820220947
Validation loss: 2.001403192679087

Epoch: 6| Step: 6
Training loss: 2.2574777603149414
Validation loss: 1.9849881331125896

Epoch: 6| Step: 7
Training loss: 2.5941314697265625
Validation loss: 1.9851663708686829

Epoch: 6| Step: 8
Training loss: 0.8991749286651611
Validation loss: 1.9654619296391804

Epoch: 6| Step: 9
Training loss: 1.3695552349090576
Validation loss: 1.962870677312215

Epoch: 6| Step: 10
Training loss: 1.6718946695327759
Validation loss: 1.961676339308421

Epoch: 6| Step: 11
Training loss: 2.0902700424194336
Validation loss: 1.9710609118143718

Epoch: 6| Step: 12
Training loss: 2.184156656265259
Validation loss: 1.9785458048184712

Epoch: 6| Step: 13
Training loss: 1.9674071073532104
Validation loss: 1.9790659546852112

Epoch: 33| Step: 0
Training loss: 1.680963158607483
Validation loss: 1.9825514157613118

Epoch: 6| Step: 1
Training loss: 2.063251256942749
Validation loss: 1.9773191412289937

Epoch: 6| Step: 2
Training loss: 1.5603723526000977
Validation loss: 1.9660494327545166

Epoch: 6| Step: 3
Training loss: 2.3252663612365723
Validation loss: 1.9757216175397236

Epoch: 6| Step: 4
Training loss: 1.772951364517212
Validation loss: 1.9775086243947346

Epoch: 6| Step: 5
Training loss: 1.7920289039611816
Validation loss: 1.9846014380455017

Epoch: 6| Step: 6
Training loss: 1.2613091468811035
Validation loss: 2.007735808690389

Epoch: 6| Step: 7
Training loss: 1.281288743019104
Validation loss: 2.016855855782827

Epoch: 6| Step: 8
Training loss: 1.9737253189086914
Validation loss: 2.0328197677930198

Epoch: 6| Step: 9
Training loss: 1.754103183746338
Validation loss: 2.058314045270284

Epoch: 6| Step: 10
Training loss: 1.9676117897033691
Validation loss: 2.0434240102767944

Epoch: 6| Step: 11
Training loss: 2.129462242126465
Validation loss: 2.0494545102119446

Epoch: 6| Step: 12
Training loss: 2.333571195602417
Validation loss: 2.0167909264564514

Epoch: 6| Step: 13
Training loss: 2.1632473468780518
Validation loss: 2.0040440559387207

Epoch: 34| Step: 0
Training loss: 1.758141279220581
Validation loss: 1.970449149608612

Epoch: 6| Step: 1
Training loss: 2.0240068435668945
Validation loss: 1.9659005602200825

Epoch: 6| Step: 2
Training loss: 1.9347975254058838
Validation loss: 1.9507689277331035

Epoch: 6| Step: 3
Training loss: 1.817540168762207
Validation loss: 1.9737908442815144

Epoch: 6| Step: 4
Training loss: 1.8657355308532715
Validation loss: 1.9813435077667236

Epoch: 6| Step: 5
Training loss: 2.5629560947418213
Validation loss: 1.9807049036026

Epoch: 6| Step: 6
Training loss: 1.6780409812927246
Validation loss: 1.9734679063161213

Epoch: 6| Step: 7
Training loss: 2.2481203079223633
Validation loss: 1.9682582815488179

Epoch: 6| Step: 8
Training loss: 2.1929728984832764
Validation loss: 1.9484519759813945

Epoch: 6| Step: 9
Training loss: 2.0802736282348633
Validation loss: 1.947899321715037

Epoch: 6| Step: 10
Training loss: 1.5379087924957275
Validation loss: 1.947027047475179

Epoch: 6| Step: 11
Training loss: 1.435827612876892
Validation loss: 1.9586652318636577

Epoch: 6| Step: 12
Training loss: 1.6738415956497192
Validation loss: 1.970397710800171

Epoch: 6| Step: 13
Training loss: 1.661825180053711
Validation loss: 1.9760597149531047

Epoch: 35| Step: 0
Training loss: 1.1671192646026611
Validation loss: 1.9771807591120403

Epoch: 6| Step: 1
Training loss: 1.940964698791504
Validation loss: 1.9869078000386555

Epoch: 6| Step: 2
Training loss: 1.6154420375823975
Validation loss: 1.9983145793279011

Epoch: 6| Step: 3
Training loss: 2.2483739852905273
Validation loss: 2.0131574074427285

Epoch: 6| Step: 4
Training loss: 1.3405691385269165
Validation loss: 2.011146048704783

Epoch: 6| Step: 5
Training loss: 1.6444056034088135
Validation loss: 1.9926035404205322

Epoch: 6| Step: 6
Training loss: 2.053982734680176
Validation loss: 1.990745524565379

Epoch: 6| Step: 7
Training loss: 1.8192806243896484
Validation loss: 1.992287774880727

Epoch: 6| Step: 8
Training loss: 1.6795063018798828
Validation loss: 1.9803783297538757

Epoch: 6| Step: 9
Training loss: 1.4103357791900635
Validation loss: 1.9721248944600422

Epoch: 6| Step: 10
Training loss: 2.518458366394043
Validation loss: 1.9707637826601665

Epoch: 6| Step: 11
Training loss: 2.330664873123169
Validation loss: 1.9611746271451314

Epoch: 6| Step: 12
Training loss: 1.430898666381836
Validation loss: 1.9477497339248657

Epoch: 6| Step: 13
Training loss: 2.0649499893188477
Validation loss: 1.9599978923797607

Epoch: 36| Step: 0
Training loss: 1.4296271800994873
Validation loss: 1.963610827922821

Epoch: 6| Step: 1
Training loss: 1.7812490463256836
Validation loss: 1.9578753312428792

Epoch: 6| Step: 2
Training loss: 1.4589614868164062
Validation loss: 1.9484010736147563

Epoch: 6| Step: 3
Training loss: 2.137112617492676
Validation loss: 1.9520938595136006

Epoch: 6| Step: 4
Training loss: 2.195962429046631
Validation loss: 1.9542361895243328

Epoch: 6| Step: 5
Training loss: 1.4344935417175293
Validation loss: 1.956315000851949

Epoch: 6| Step: 6
Training loss: 2.14445161819458
Validation loss: 1.954562524954478

Epoch: 6| Step: 7
Training loss: 1.2319153547286987
Validation loss: 1.9493908683458965

Epoch: 6| Step: 8
Training loss: 2.078646659851074
Validation loss: 1.955216924349467

Epoch: 6| Step: 9
Training loss: 1.6762146949768066
Validation loss: 1.9702272812525432

Epoch: 6| Step: 10
Training loss: 1.4364707469940186
Validation loss: 1.9769938389460247

Epoch: 6| Step: 11
Training loss: 2.306988000869751
Validation loss: 1.9638457695643108

Epoch: 6| Step: 12
Training loss: 1.6331536769866943
Validation loss: 1.9872438112894695

Epoch: 6| Step: 13
Training loss: 1.8929884433746338
Validation loss: 1.991118848323822

Epoch: 37| Step: 0
Training loss: 2.051203727722168
Validation loss: 1.9968538482983906

Epoch: 6| Step: 1
Training loss: 1.7569451332092285
Validation loss: 1.9787787795066833

Epoch: 6| Step: 2
Training loss: 1.2696845531463623
Validation loss: 1.9847509463628132

Epoch: 6| Step: 3
Training loss: 2.457176685333252
Validation loss: 1.9684167901674907

Epoch: 6| Step: 4
Training loss: 2.0541698932647705
Validation loss: 1.9695138335227966

Epoch: 6| Step: 5
Training loss: 1.6270110607147217
Validation loss: 1.9554768800735474

Epoch: 6| Step: 6
Training loss: 1.5139671564102173
Validation loss: 1.9682526191075642

Epoch: 6| Step: 7
Training loss: 1.4226841926574707
Validation loss: 1.951209803422292

Epoch: 6| Step: 8
Training loss: 2.2171201705932617
Validation loss: 1.9681113958358765

Epoch: 6| Step: 9
Training loss: 1.877002239227295
Validation loss: 1.9787642161051433

Epoch: 6| Step: 10
Training loss: 1.9209411144256592
Validation loss: 1.9695229927698772

Epoch: 6| Step: 11
Training loss: 1.7606258392333984
Validation loss: 1.986335535844167

Epoch: 6| Step: 12
Training loss: 1.5064258575439453
Validation loss: 1.986001431941986

Epoch: 6| Step: 13
Training loss: 1.7551138401031494
Validation loss: 1.9822633465131123

Epoch: 38| Step: 0
Training loss: 0.9720444083213806
Validation loss: 1.9772201776504517

Epoch: 6| Step: 1
Training loss: 1.6439357995986938
Validation loss: 1.9924060304959614

Epoch: 6| Step: 2
Training loss: 1.834184169769287
Validation loss: 1.9805195530255635

Epoch: 6| Step: 3
Training loss: 1.6923377513885498
Validation loss: 1.9597520629564922

Epoch: 6| Step: 4
Training loss: 2.1444735527038574
Validation loss: 1.9480557243029277

Epoch: 6| Step: 5
Training loss: 1.6161153316497803
Validation loss: 1.9624929626782734

Epoch: 6| Step: 6
Training loss: 1.8042035102844238
Validation loss: 1.946314811706543

Epoch: 6| Step: 7
Training loss: 1.6436002254486084
Validation loss: 1.9567174116770427

Epoch: 6| Step: 8
Training loss: 1.3442293405532837
Validation loss: 1.9752590854962666

Epoch: 6| Step: 9
Training loss: 1.7525370121002197
Validation loss: 1.9911398887634277

Epoch: 6| Step: 10
Training loss: 1.7333734035491943
Validation loss: 1.9754250446955364

Epoch: 6| Step: 11
Training loss: 2.0536813735961914
Validation loss: 1.9994130929311116

Epoch: 6| Step: 12
Training loss: 2.3303494453430176
Validation loss: 2.0073527495066323

Epoch: 6| Step: 13
Training loss: 2.065412998199463
Validation loss: 1.9924161831537883

Epoch: 39| Step: 0
Training loss: 1.63991379737854
Validation loss: 1.9981760382652283

Epoch: 6| Step: 1
Training loss: 1.9508776664733887
Validation loss: 1.9896559317906697

Epoch: 6| Step: 2
Training loss: 1.9449708461761475
Validation loss: 1.9903262456258137

Epoch: 6| Step: 3
Training loss: 1.782098650932312
Validation loss: 2.01371560494105

Epoch: 6| Step: 4
Training loss: 1.1577858924865723
Validation loss: 1.9884121417999268

Epoch: 6| Step: 5
Training loss: 1.177459716796875
Validation loss: 1.9836618304252625

Epoch: 6| Step: 6
Training loss: 1.4423139095306396
Validation loss: 1.9805610378583272

Epoch: 6| Step: 7
Training loss: 1.4169390201568604
Validation loss: 1.9679513573646545

Epoch: 6| Step: 8
Training loss: 2.046300172805786
Validation loss: 1.9660847187042236

Epoch: 6| Step: 9
Training loss: 1.794346809387207
Validation loss: 1.9634809494018555

Epoch: 6| Step: 10
Training loss: 2.217695951461792
Validation loss: 1.9636307160059612

Epoch: 6| Step: 11
Training loss: 1.690195083618164
Validation loss: 1.9645581245422363

Epoch: 6| Step: 12
Training loss: 1.6771016120910645
Validation loss: 1.9847505489985149

Epoch: 6| Step: 13
Training loss: 2.7077794075012207
Validation loss: 1.9781707525253296

Epoch: 40| Step: 0
Training loss: 1.7279020547866821
Validation loss: 1.9826828440030415

Epoch: 6| Step: 1
Training loss: 1.624753475189209
Validation loss: 2.000191112359365

Epoch: 6| Step: 2
Training loss: 1.5722708702087402
Validation loss: 1.9682226181030273

Epoch: 6| Step: 3
Training loss: 1.753151774406433
Validation loss: 1.9754006067911785

Epoch: 6| Step: 4
Training loss: 1.6423358917236328
Validation loss: 1.9844961166381836

Epoch: 6| Step: 5
Training loss: 1.8312796354293823
Validation loss: 1.9877477884292603

Epoch: 6| Step: 6
Training loss: 1.9924213886260986
Validation loss: 1.997471531232198

Epoch: 6| Step: 7
Training loss: 1.187178134918213
Validation loss: 2.0031893452008567

Epoch: 6| Step: 8
Training loss: 1.8751600980758667
Validation loss: 2.0089557568232217

Epoch: 6| Step: 9
Training loss: 1.3627783060073853
Validation loss: 2.0015962322553

Epoch: 6| Step: 10
Training loss: 1.8512637615203857
Validation loss: 2.0246253609657288

Epoch: 6| Step: 11
Training loss: 1.167151927947998
Validation loss: 2.022193948427836

Epoch: 6| Step: 12
Training loss: 2.5381603240966797
Validation loss: 1.9930829207102458

Epoch: 6| Step: 13
Training loss: 2.164652109146118
Validation loss: 1.9886671900749207

Epoch: 41| Step: 0
Training loss: 1.6249407529830933
Validation loss: 1.9707878430684407

Epoch: 6| Step: 1
Training loss: 1.8654557466506958
Validation loss: 1.9828576842943828

Epoch: 6| Step: 2
Training loss: 2.074612855911255
Validation loss: 1.9708115657170613

Epoch: 6| Step: 3
Training loss: 1.5843700170516968
Validation loss: 1.966165800889333

Epoch: 6| Step: 4
Training loss: 1.4787837266921997
Validation loss: 1.9563427170117695

Epoch: 6| Step: 5
Training loss: 1.3662030696868896
Validation loss: 1.9764591852823894

Epoch: 6| Step: 6
Training loss: 2.2841715812683105
Validation loss: 1.9819483757019043

Epoch: 6| Step: 7
Training loss: 1.8342658281326294
Validation loss: 1.9727465907732646

Epoch: 6| Step: 8
Training loss: 1.5807162523269653
Validation loss: 1.9741350611050923

Epoch: 6| Step: 9
Training loss: 1.7864601612091064
Validation loss: 1.9804091652234395

Epoch: 6| Step: 10
Training loss: 1.5666968822479248
Validation loss: 1.975506563981374

Epoch: 6| Step: 11
Training loss: 1.2689718008041382
Validation loss: 1.9606364369392395

Epoch: 6| Step: 12
Training loss: 1.7980241775512695
Validation loss: 1.964346170425415

Epoch: 6| Step: 13
Training loss: 2.2800817489624023
Validation loss: 1.9703689217567444

Epoch: 42| Step: 0
Training loss: 2.172814130783081
Validation loss: 1.965670069058736

Epoch: 6| Step: 1
Training loss: 1.7805805206298828
Validation loss: 1.973630666732788

Epoch: 6| Step: 2
Training loss: 1.4953668117523193
Validation loss: 1.977708876132965

Epoch: 6| Step: 3
Training loss: 1.7545018196105957
Validation loss: 1.969864030679067

Epoch: 6| Step: 4
Training loss: 2.1501975059509277
Validation loss: 1.9901774724324544

Epoch: 6| Step: 5
Training loss: 1.3166447877883911
Validation loss: 2.0035921732584634

Epoch: 6| Step: 6
Training loss: 1.9274013042449951
Validation loss: 2.0244102279345193

Epoch: 6| Step: 7
Training loss: 1.9881846904754639
Validation loss: 2.0252461036046348

Epoch: 6| Step: 8
Training loss: 1.3476369380950928
Validation loss: 2.015121102333069

Epoch: 6| Step: 9
Training loss: 2.17615008354187
Validation loss: 2.005048374334971

Epoch: 6| Step: 10
Training loss: 1.7014799118041992
Validation loss: 2.004602551460266

Epoch: 6| Step: 11
Training loss: 1.382256031036377
Validation loss: 1.982065757115682

Epoch: 6| Step: 12
Training loss: 1.6987982988357544
Validation loss: 1.9817273219426472

Epoch: 6| Step: 13
Training loss: 1.4150221347808838
Validation loss: 1.9646700024604797

Epoch: 43| Step: 0
Training loss: 1.3398131132125854
Validation loss: 1.985007603963216

Epoch: 6| Step: 1
Training loss: 1.3743607997894287
Validation loss: 1.9760568737983704

Epoch: 6| Step: 2
Training loss: 1.2726702690124512
Validation loss: 1.972957173983256

Epoch: 6| Step: 3
Training loss: 1.8310340642929077
Validation loss: 1.9890056649843852

Epoch: 6| Step: 4
Training loss: 1.6788443326950073
Validation loss: 1.9912450710932414

Epoch: 6| Step: 5
Training loss: 1.8088562488555908
Validation loss: 2.0126929879188538

Epoch: 6| Step: 6
Training loss: 2.6048991680145264
Validation loss: 2.0416778922080994

Epoch: 6| Step: 7
Training loss: 1.619712471961975
Validation loss: 2.060209353764852

Epoch: 6| Step: 8
Training loss: 2.100343704223633
Validation loss: 2.0968768994013467

Epoch: 6| Step: 9
Training loss: 1.9465434551239014
Validation loss: 2.056588292121887

Epoch: 6| Step: 10
Training loss: 2.0392792224884033
Validation loss: 2.0408256451288858

Epoch: 6| Step: 11
Training loss: 1.457009196281433
Validation loss: 2.0100409587224326

Epoch: 6| Step: 12
Training loss: 1.7651879787445068
Validation loss: 1.9863582849502563

Epoch: 6| Step: 13
Training loss: 1.930312991142273
Validation loss: 1.9709449609120686

Epoch: 44| Step: 0
Training loss: 1.600127935409546
Validation loss: 1.9655840198198955

Epoch: 6| Step: 1
Training loss: 2.140146255493164
Validation loss: 1.9708545207977295

Epoch: 6| Step: 2
Training loss: 2.453325033187866
Validation loss: 1.9736725489298503

Epoch: 6| Step: 3
Training loss: 1.6341185569763184
Validation loss: 1.978494127591451

Epoch: 6| Step: 4
Training loss: 2.116459846496582
Validation loss: 1.9677633047103882

Epoch: 6| Step: 5
Training loss: 1.1065163612365723
Validation loss: 1.972956160704295

Epoch: 6| Step: 6
Training loss: 0.9742720127105713
Validation loss: 1.9640806317329407

Epoch: 6| Step: 7
Training loss: 2.2532310485839844
Validation loss: 1.9617297450701396

Epoch: 6| Step: 8
Training loss: 1.606198787689209
Validation loss: 1.9958521525065105

Epoch: 6| Step: 9
Training loss: 1.6499392986297607
Validation loss: 2.0120225747426352

Epoch: 6| Step: 10
Training loss: 1.4265573024749756
Validation loss: 2.0198946396509805

Epoch: 6| Step: 11
Training loss: 1.7443416118621826
Validation loss: 2.047853628794352

Epoch: 6| Step: 12
Training loss: 1.4522711038589478
Validation loss: 2.0302946964899697

Epoch: 6| Step: 13
Training loss: 2.281785488128662
Validation loss: 2.0274258653322854

Epoch: 45| Step: 0
Training loss: 1.774843454360962
Validation loss: 2.016212284564972

Epoch: 6| Step: 1
Training loss: 1.5023808479309082
Validation loss: 1.9885790745417278

Epoch: 6| Step: 2
Training loss: 1.4719629287719727
Validation loss: 1.9766964117685955

Epoch: 6| Step: 3
Training loss: 1.7541263103485107
Validation loss: 1.974874198436737

Epoch: 6| Step: 4
Training loss: 1.5495811700820923
Validation loss: 1.9840493003527324

Epoch: 6| Step: 5
Training loss: 2.3607234954833984
Validation loss: 1.983949323495229

Epoch: 6| Step: 6
Training loss: 1.253830075263977
Validation loss: 1.987854500611623

Epoch: 6| Step: 7
Training loss: 1.7595490217208862
Validation loss: 1.9907907048861186

Epoch: 6| Step: 8
Training loss: 2.1305339336395264
Validation loss: 2.0150608817736306

Epoch: 6| Step: 9
Training loss: 1.4261062145233154
Validation loss: 2.0030465523401895

Epoch: 6| Step: 10
Training loss: 1.5591602325439453
Validation loss: 2.0475594997406006

Epoch: 6| Step: 11
Training loss: 1.7607553005218506
Validation loss: 2.0339871843655906

Epoch: 6| Step: 12
Training loss: 2.5174009799957275
Validation loss: 2.0293354789415994

Epoch: 6| Step: 13
Training loss: 1.654240369796753
Validation loss: 2.007265349229177

Epoch: 46| Step: 0
Training loss: 2.2671093940734863
Validation loss: 2.0053847829500833

Epoch: 6| Step: 1
Training loss: 1.3855552673339844
Validation loss: 1.9954887231190999

Epoch: 6| Step: 2
Training loss: 1.4069801568984985
Validation loss: 1.979285180568695

Epoch: 6| Step: 3
Training loss: 2.077988386154175
Validation loss: 1.9751404523849487

Epoch: 6| Step: 4
Training loss: 1.6612075567245483
Validation loss: 1.9802887241045635

Epoch: 6| Step: 5
Training loss: 1.4235045909881592
Validation loss: 1.9670398831367493

Epoch: 6| Step: 6
Training loss: 1.4475864171981812
Validation loss: 1.9717635711034138

Epoch: 6| Step: 7
Training loss: 1.328262209892273
Validation loss: 1.9776070713996887

Epoch: 6| Step: 8
Training loss: 1.454322338104248
Validation loss: 1.9758156538009644

Epoch: 6| Step: 9
Training loss: 1.8316543102264404
Validation loss: 1.9822383721669514

Epoch: 6| Step: 10
Training loss: 1.8462638854980469
Validation loss: 1.99531489610672

Epoch: 6| Step: 11
Training loss: 1.7917739152908325
Validation loss: 1.959795395533244

Epoch: 6| Step: 12
Training loss: 1.6285767555236816
Validation loss: 1.9841086864471436

Epoch: 6| Step: 13
Training loss: 2.1646947860717773
Validation loss: 1.9850240151087444

Epoch: 47| Step: 0
Training loss: 1.7977043390274048
Validation loss: 2.0016818046569824

Epoch: 6| Step: 1
Training loss: 1.9407920837402344
Validation loss: 2.000423530737559

Epoch: 6| Step: 2
Training loss: 1.9476423263549805
Validation loss: 1.9998899698257446

Epoch: 6| Step: 3
Training loss: 1.850571632385254
Validation loss: 2.003989577293396

Epoch: 6| Step: 4
Training loss: 1.4866080284118652
Validation loss: 1.9995241562525432

Epoch: 6| Step: 5
Training loss: 1.633431077003479
Validation loss: 1.9838634332021077

Epoch: 6| Step: 6
Training loss: 1.4727141857147217
Validation loss: 1.9717441598574321

Epoch: 6| Step: 7
Training loss: 1.5242345333099365
Validation loss: 1.9828320145606995

Epoch: 6| Step: 8
Training loss: 1.2625091075897217
Validation loss: 1.9769067565600078

Epoch: 6| Step: 9
Training loss: 1.57108736038208
Validation loss: 1.9924594362576802

Epoch: 6| Step: 10
Training loss: 1.7814350128173828
Validation loss: 1.9930231372515361

Epoch: 6| Step: 11
Training loss: 1.6004350185394287
Validation loss: 1.9892633557319641

Epoch: 6| Step: 12
Training loss: 1.7174005508422852
Validation loss: 2.0317287842432656

Epoch: 6| Step: 13
Training loss: 1.8206117153167725
Validation loss: 2.0324746966362

Epoch: 48| Step: 0
Training loss: 1.6523417234420776
Validation loss: 2.0323738058408103

Epoch: 6| Step: 1
Training loss: 1.848857045173645
Validation loss: 2.0214343865712485

Epoch: 6| Step: 2
Training loss: 1.3765361309051514
Validation loss: 1.9954243898391724

Epoch: 6| Step: 3
Training loss: 2.2824394702911377
Validation loss: 2.005801022052765

Epoch: 6| Step: 4
Training loss: 1.5140793323516846
Validation loss: 1.9890032013257344

Epoch: 6| Step: 5
Training loss: 1.0690914392471313
Validation loss: 1.9901777505874634

Epoch: 6| Step: 6
Training loss: 1.4358031749725342
Validation loss: 1.984447995821635

Epoch: 6| Step: 7
Training loss: 2.479823589324951
Validation loss: 1.9981961051623027

Epoch: 6| Step: 8
Training loss: 2.3527750968933105
Validation loss: 2.0021891593933105

Epoch: 6| Step: 9
Training loss: 1.7526090145111084
Validation loss: 1.988479753335317

Epoch: 6| Step: 10
Training loss: 1.8621622323989868
Validation loss: 1.9896788597106934

Epoch: 6| Step: 11
Training loss: 1.875520944595337
Validation loss: 1.9874134063720703

Epoch: 6| Step: 12
Training loss: 1.3712255954742432
Validation loss: 1.9999335010846455

Epoch: 6| Step: 13
Training loss: 1.3410069942474365
Validation loss: 2.0108327666918435

Epoch: 49| Step: 0
Training loss: 1.2247651815414429
Validation loss: 2.0240025321642556

Epoch: 6| Step: 1
Training loss: 2.395280122756958
Validation loss: 2.046043892701467

Epoch: 6| Step: 2
Training loss: 1.7363934516906738
Validation loss: 2.054785152276357

Epoch: 6| Step: 3
Training loss: 1.3071422576904297
Validation loss: 2.0449616511662803

Epoch: 6| Step: 4
Training loss: 1.8448610305786133
Validation loss: 2.0140926043192544

Epoch: 6| Step: 5
Training loss: 1.5395293235778809
Validation loss: 1.9974522590637207

Epoch: 6| Step: 6
Training loss: 1.0536184310913086
Validation loss: 1.9746086994806926

Epoch: 6| Step: 7
Training loss: 1.7211787700653076
Validation loss: 1.981907327969869

Epoch: 6| Step: 8
Training loss: 1.238875150680542
Validation loss: 1.9744245012601216

Epoch: 6| Step: 9
Training loss: 2.105560064315796
Validation loss: 1.9842003385225933

Epoch: 6| Step: 10
Training loss: 2.036851406097412
Validation loss: 1.988297442595164

Epoch: 6| Step: 11
Training loss: 2.274970531463623
Validation loss: 2.0010701417922974

Epoch: 6| Step: 12
Training loss: 1.6220762729644775
Validation loss: 2.0091204047203064

Epoch: 6| Step: 13
Training loss: 2.0476419925689697
Validation loss: 1.9884119431177776

Epoch: 50| Step: 0
Training loss: 2.075766086578369
Validation loss: 1.9838971694310505

Epoch: 6| Step: 1
Training loss: 1.2840352058410645
Validation loss: 1.9828621943791707

Epoch: 6| Step: 2
Training loss: 1.8708627223968506
Validation loss: 1.9806495308876038

Epoch: 6| Step: 3
Training loss: 1.8038443326950073
Validation loss: 1.9775758385658264

Epoch: 6| Step: 4
Training loss: 1.4989938735961914
Validation loss: 2.0288151701291404

Epoch: 6| Step: 5
Training loss: 1.1772358417510986
Validation loss: 2.060387214024862

Epoch: 6| Step: 6
Training loss: 1.2898437976837158
Validation loss: 2.038804590702057

Epoch: 6| Step: 7
Training loss: 1.5284826755523682
Validation loss: 2.0615885655085244

Epoch: 6| Step: 8
Training loss: 1.8919857740402222
Validation loss: 2.037625869115194

Epoch: 6| Step: 9
Training loss: 1.8522388935089111
Validation loss: 2.0179165999094644

Epoch: 6| Step: 10
Training loss: 2.3939568996429443
Validation loss: 1.9945237239201863

Epoch: 6| Step: 11
Training loss: 1.6286954879760742
Validation loss: 2.0052373011906943

Epoch: 6| Step: 12
Training loss: 1.3552531003952026
Validation loss: 1.984803557395935

Epoch: 6| Step: 13
Training loss: 2.0266175270080566
Validation loss: 1.967241644859314

Epoch: 51| Step: 0
Training loss: 1.8313173055648804
Validation loss: 1.968536913394928

Epoch: 6| Step: 1
Training loss: 1.6083080768585205
Validation loss: 1.9684770305951436

Epoch: 6| Step: 2
Training loss: 1.5589518547058105
Validation loss: 1.9572852849960327

Epoch: 6| Step: 3
Training loss: 1.576179027557373
Validation loss: 1.9518482685089111

Epoch: 6| Step: 4
Training loss: 1.9192252159118652
Validation loss: 1.953986903031667

Epoch: 6| Step: 5
Training loss: 1.046065330505371
Validation loss: 1.9593751827875774

Epoch: 6| Step: 6
Training loss: 1.9798941612243652
Validation loss: 1.9606306155522664

Epoch: 6| Step: 7
Training loss: 1.5718004703521729
Validation loss: 1.9691254297892253

Epoch: 6| Step: 8
Training loss: 1.6284270286560059
Validation loss: 1.976426601409912

Epoch: 6| Step: 9
Training loss: 1.8066473007202148
Validation loss: 2.009721040725708

Epoch: 6| Step: 10
Training loss: 1.9270743131637573
Validation loss: 2.027257740497589

Epoch: 6| Step: 11
Training loss: 1.1775808334350586
Validation loss: 2.018061856428782

Epoch: 6| Step: 12
Training loss: 2.2804059982299805
Validation loss: 2.0197887420654297

Epoch: 6| Step: 13
Training loss: 1.1977715492248535
Validation loss: 2.0349449117978415

Epoch: 52| Step: 0
Training loss: 1.7223892211914062
Validation loss: 2.0063752929369607

Epoch: 6| Step: 1
Training loss: 1.5832335948944092
Validation loss: 2.0047967433929443

Epoch: 6| Step: 2
Training loss: 1.41945219039917
Validation loss: 1.9944112499554951

Epoch: 6| Step: 3
Training loss: 1.7181204557418823
Validation loss: 1.9735432068506877

Epoch: 6| Step: 4
Training loss: 1.8938196897506714
Validation loss: 1.9681137601534526

Epoch: 6| Step: 5
Training loss: 1.9566359519958496
Validation loss: 1.9715110262235005

Epoch: 6| Step: 6
Training loss: 1.2280573844909668
Validation loss: 1.965967853864034

Epoch: 6| Step: 7
Training loss: 1.2416925430297852
Validation loss: 1.9749077558517456

Epoch: 6| Step: 8
Training loss: 1.7170625925064087
Validation loss: 1.9840582609176636

Epoch: 6| Step: 9
Training loss: 1.4795024394989014
Validation loss: 1.9999780257542927

Epoch: 6| Step: 10
Training loss: 2.029261827468872
Validation loss: 2.00775408744812

Epoch: 6| Step: 11
Training loss: 1.8041495084762573
Validation loss: 2.0049110054969788

Epoch: 6| Step: 12
Training loss: 1.7876781225204468
Validation loss: 2.0047876834869385

Epoch: 6| Step: 13
Training loss: 1.7061480283737183
Validation loss: 1.998388131459554

Epoch: 53| Step: 0
Training loss: 1.0504179000854492
Validation loss: 1.9967325925827026

Epoch: 6| Step: 1
Training loss: 1.2879161834716797
Validation loss: 1.9757455786069233

Epoch: 6| Step: 2
Training loss: 1.7112748622894287
Validation loss: 1.9810700416564941

Epoch: 6| Step: 3
Training loss: 1.7407503128051758
Validation loss: 1.9697673519452412

Epoch: 6| Step: 4
Training loss: 1.8913707733154297
Validation loss: 1.9582691391309102

Epoch: 6| Step: 5
Training loss: 1.8805456161499023
Validation loss: 1.9652559955914815

Epoch: 6| Step: 6
Training loss: 1.6804227828979492
Validation loss: 1.955916663010915

Epoch: 6| Step: 7
Training loss: 1.7558162212371826
Validation loss: 1.9555676182111104

Epoch: 6| Step: 8
Training loss: 1.6310410499572754
Validation loss: 1.952778438727061

Epoch: 6| Step: 9
Training loss: 2.2339816093444824
Validation loss: 1.9659883975982666

Epoch: 6| Step: 10
Training loss: 1.7495083808898926
Validation loss: 1.9807022213935852

Epoch: 6| Step: 11
Training loss: 1.3938478231430054
Validation loss: 2.001246531804403

Epoch: 6| Step: 12
Training loss: 0.7016522884368896
Validation loss: 1.9688688516616821

Epoch: 6| Step: 13
Training loss: 1.8597301244735718
Validation loss: 2.001830577850342

Epoch: 54| Step: 0
Training loss: 1.9005873203277588
Validation loss: 2.0091280539830527

Epoch: 6| Step: 1
Training loss: 1.7072832584381104
Validation loss: 2.0106279253959656

Epoch: 6| Step: 2
Training loss: 1.5976642370224
Validation loss: 2.011026700337728

Epoch: 6| Step: 3
Training loss: 1.7128746509552002
Validation loss: 2.0076876481374106

Epoch: 6| Step: 4
Training loss: 1.4860199689865112
Validation loss: 1.9859047134717305

Epoch: 6| Step: 5
Training loss: 1.1949405670166016
Validation loss: 1.9945645928382874

Epoch: 6| Step: 6
Training loss: 1.5763375759124756
Validation loss: 2.0125256379445395

Epoch: 6| Step: 7
Training loss: 1.352950930595398
Validation loss: 1.9841089049975078

Epoch: 6| Step: 8
Training loss: 2.240154266357422
Validation loss: 1.9826221664746602

Epoch: 6| Step: 9
Training loss: 0.9177477359771729
Validation loss: 1.9957916140556335

Epoch: 6| Step: 10
Training loss: 1.5801221132278442
Validation loss: 1.9996374249458313

Epoch: 6| Step: 11
Training loss: 1.7182948589324951
Validation loss: 1.9757208029429119

Epoch: 6| Step: 12
Training loss: 2.0607950687408447
Validation loss: 1.9963429768880208

Epoch: 6| Step: 13
Training loss: 1.065072774887085
Validation loss: 1.9817265669504802

Epoch: 55| Step: 0
Training loss: 1.6300820112228394
Validation loss: 1.9899415969848633

Epoch: 6| Step: 1
Training loss: 1.783682107925415
Validation loss: 1.9954560995101929

Epoch: 6| Step: 2
Training loss: 1.3895580768585205
Validation loss: 1.9748741785685222

Epoch: 6| Step: 3
Training loss: 1.4278820753097534
Validation loss: 1.9907325108846028

Epoch: 6| Step: 4
Training loss: 1.6023311614990234
Validation loss: 2.0079424381256104

Epoch: 6| Step: 5
Training loss: 1.2787907123565674
Validation loss: 2.0011399189631143

Epoch: 6| Step: 6
Training loss: 1.105968952178955
Validation loss: 2.0213258266448975

Epoch: 6| Step: 7
Training loss: 1.8516826629638672
Validation loss: 2.050328552722931

Epoch: 6| Step: 8
Training loss: 1.4174463748931885
Validation loss: 2.0699661572774253

Epoch: 6| Step: 9
Training loss: 2.0398647785186768
Validation loss: 2.078297038873037

Epoch: 6| Step: 10
Training loss: 1.6480252742767334
Validation loss: 2.054186205069224

Epoch: 6| Step: 11
Training loss: 2.0958611965179443
Validation loss: 2.0242557922999063

Epoch: 6| Step: 12
Training loss: 1.7902806997299194
Validation loss: 2.0145247181256614

Epoch: 6| Step: 13
Training loss: 1.4926472902297974
Validation loss: 1.9978659550348918

Epoch: 56| Step: 0
Training loss: 2.0167832374572754
Validation loss: 1.9861687819163005

Epoch: 6| Step: 1
Training loss: 0.8192107081413269
Validation loss: 1.9996906320254009

Epoch: 6| Step: 2
Training loss: 1.3015578985214233
Validation loss: 2.0138676961263022

Epoch: 6| Step: 3
Training loss: 1.872510313987732
Validation loss: 2.0062344868977866

Epoch: 6| Step: 4
Training loss: 1.4599721431732178
Validation loss: 1.989047070344289

Epoch: 6| Step: 5
Training loss: 1.965949296951294
Validation loss: 1.9979604085286458

Epoch: 6| Step: 6
Training loss: 2.334052801132202
Validation loss: 1.9873599608739216

Epoch: 6| Step: 7
Training loss: 1.2812082767486572
Validation loss: 2.006537675857544

Epoch: 6| Step: 8
Training loss: 1.7467656135559082
Validation loss: 2.0108974973360696

Epoch: 6| Step: 9
Training loss: 1.1784393787384033
Validation loss: 2.0438469449679055

Epoch: 6| Step: 10
Training loss: 2.196558952331543
Validation loss: 2.0475961764653525

Epoch: 6| Step: 11
Training loss: 1.4756265878677368
Validation loss: 2.0800214807192483

Epoch: 6| Step: 12
Training loss: 1.623647928237915
Validation loss: 2.085558513800303

Epoch: 6| Step: 13
Training loss: 0.9489587545394897
Validation loss: 2.081820249557495

Epoch: 57| Step: 0
Training loss: 1.4754976034164429
Validation loss: 2.0803547898928323

Epoch: 6| Step: 1
Training loss: 1.5668684244155884
Validation loss: 2.080295821030935

Epoch: 6| Step: 2
Training loss: 1.7190113067626953
Validation loss: 2.0277454257011414

Epoch: 6| Step: 3
Training loss: 1.284050703048706
Validation loss: 2.001993497212728

Epoch: 6| Step: 4
Training loss: 1.5334491729736328
Validation loss: 1.9977138837178547

Epoch: 6| Step: 5
Training loss: 1.211768388748169
Validation loss: 1.9714314540227253

Epoch: 6| Step: 6
Training loss: 2.14300274848938
Validation loss: 1.9738124410311382

Epoch: 6| Step: 7
Training loss: 1.8158645629882812
Validation loss: 1.9818835258483887

Epoch: 6| Step: 8
Training loss: 1.8335728645324707
Validation loss: 1.9962016741434734

Epoch: 6| Step: 9
Training loss: 2.239455223083496
Validation loss: 2.0102516412734985

Epoch: 6| Step: 10
Training loss: 1.3596240282058716
Validation loss: 2.0060184399286904

Epoch: 6| Step: 11
Training loss: 2.1846296787261963
Validation loss: 1.9820510149002075

Epoch: 6| Step: 12
Training loss: 1.1263316869735718
Validation loss: 1.9879842400550842

Epoch: 6| Step: 13
Training loss: 1.9601540565490723
Validation loss: 1.9895541469256084

Epoch: 58| Step: 0
Training loss: 1.1879665851593018
Validation loss: 2.0363751451174417

Epoch: 6| Step: 1
Training loss: 2.207426071166992
Validation loss: 2.033260405063629

Epoch: 6| Step: 2
Training loss: 1.7075614929199219
Validation loss: 2.05827260017395

Epoch: 6| Step: 3
Training loss: 1.9076976776123047
Validation loss: 2.07708348830541

Epoch: 6| Step: 4
Training loss: 1.2516248226165771
Validation loss: 2.06534880399704

Epoch: 6| Step: 5
Training loss: 1.3755428791046143
Validation loss: 2.044471581776937

Epoch: 6| Step: 6
Training loss: 1.5517504215240479
Validation loss: 2.009115139643351

Epoch: 6| Step: 7
Training loss: 2.0187463760375977
Validation loss: 1.98665189743042

Epoch: 6| Step: 8
Training loss: 1.5688285827636719
Validation loss: 1.9789921442667644

Epoch: 6| Step: 9
Training loss: 2.1195335388183594
Validation loss: 1.9815493027369182

Epoch: 6| Step: 10
Training loss: 1.7699538469314575
Validation loss: 1.9875122507413228

Epoch: 6| Step: 11
Training loss: 1.364651083946228
Validation loss: 1.9750601649284363

Epoch: 6| Step: 12
Training loss: 1.461951732635498
Validation loss: 1.9514214793841045

Epoch: 6| Step: 13
Training loss: 1.237829327583313
Validation loss: 1.979511519273122

Epoch: 59| Step: 0
Training loss: 1.323271632194519
Validation loss: 1.9779878656069438

Epoch: 6| Step: 1
Training loss: 1.6744062900543213
Validation loss: 1.9953057368596394

Epoch: 6| Step: 2
Training loss: 1.3525989055633545
Validation loss: 2.0074066321055093

Epoch: 6| Step: 3
Training loss: 1.298606514930725
Validation loss: 2.0013336737950644

Epoch: 6| Step: 4
Training loss: 1.5080673694610596
Validation loss: 2.0394843022028604

Epoch: 6| Step: 5
Training loss: 1.8491547107696533
Validation loss: 2.012419859568278

Epoch: 6| Step: 6
Training loss: 1.467707633972168
Validation loss: 2.0395333568255105

Epoch: 6| Step: 7
Training loss: 1.0636706352233887
Validation loss: 2.0125880042711892

Epoch: 6| Step: 8
Training loss: 1.7712125778198242
Validation loss: 2.008298635482788

Epoch: 6| Step: 9
Training loss: 1.2299160957336426
Validation loss: 1.9833015600840251

Epoch: 6| Step: 10
Training loss: 1.2579914331436157
Validation loss: 1.9731257557868958

Epoch: 6| Step: 11
Training loss: 2.74649715423584
Validation loss: 1.9807674686113994

Epoch: 6| Step: 12
Training loss: 1.4177149534225464
Validation loss: 1.9782405893007915

Epoch: 6| Step: 13
Training loss: 2.0181045532226562
Validation loss: 1.9757065176963806

Epoch: 60| Step: 0
Training loss: 1.9727580547332764
Validation loss: 1.9802914261817932

Epoch: 6| Step: 1
Training loss: 1.863521695137024
Validation loss: 1.9725939631462097

Epoch: 6| Step: 2
Training loss: 2.0058398246765137
Validation loss: 1.9572682778040569

Epoch: 6| Step: 3
Training loss: 1.4078445434570312
Validation loss: 1.936668872833252

Epoch: 6| Step: 4
Training loss: 1.355898380279541
Validation loss: 1.9544209043184917

Epoch: 6| Step: 5
Training loss: 1.4072729349136353
Validation loss: 1.9678321679433186

Epoch: 6| Step: 6
Training loss: 1.5635887384414673
Validation loss: 1.9876606265703838

Epoch: 6| Step: 7
Training loss: 1.4809372425079346
Validation loss: 2.009031593799591

Epoch: 6| Step: 8
Training loss: 1.357701063156128
Validation loss: 2.0116226077079773

Epoch: 6| Step: 9
Training loss: 1.994856834411621
Validation loss: 2.0044058760007224

Epoch: 6| Step: 10
Training loss: 2.04069185256958
Validation loss: 1.9722164869308472

Epoch: 6| Step: 11
Training loss: 1.5443732738494873
Validation loss: 1.9798870086669922

Epoch: 6| Step: 12
Training loss: 1.0338627099990845
Validation loss: 1.9605331619580586

Epoch: 6| Step: 13
Training loss: 1.4016002416610718
Validation loss: 1.96107679605484

Epoch: 61| Step: 0
Training loss: 1.2945435047149658
Validation loss: 1.9822758237520854

Epoch: 6| Step: 1
Training loss: 1.4228670597076416
Validation loss: 1.9883154034614563

Epoch: 6| Step: 2
Training loss: 1.8651232719421387
Validation loss: 1.9955303470293682

Epoch: 6| Step: 3
Training loss: 1.6553552150726318
Validation loss: 2.0067354639371238

Epoch: 6| Step: 4
Training loss: 1.3133801221847534
Validation loss: 2.0072968006134033

Epoch: 6| Step: 5
Training loss: 1.8237353563308716
Validation loss: 1.9976335366566975

Epoch: 6| Step: 6
Training loss: 1.3636749982833862
Validation loss: 2.0067195296287537

Epoch: 6| Step: 7
Training loss: 1.2422593832015991
Validation loss: 2.0043582916259766

Epoch: 6| Step: 8
Training loss: 1.8615747690200806
Validation loss: 2.022075613339742

Epoch: 6| Step: 9
Training loss: 1.653213620185852
Validation loss: 2.006045718987783

Epoch: 6| Step: 10
Training loss: 1.6301110982894897
Validation loss: 1.9763619899749756

Epoch: 6| Step: 11
Training loss: 1.4243260622024536
Validation loss: 1.9877557555834453

Epoch: 6| Step: 12
Training loss: 1.4634132385253906
Validation loss: 1.9671412110328674

Epoch: 6| Step: 13
Training loss: 1.4039490222930908
Validation loss: 1.9612063964207966

Epoch: 62| Step: 0
Training loss: 1.287859320640564
Validation loss: 1.9760609070460002

Epoch: 6| Step: 1
Training loss: 1.5476179122924805
Validation loss: 1.9755798975626628

Epoch: 6| Step: 2
Training loss: 1.561658501625061
Validation loss: 1.9877450068791707

Epoch: 6| Step: 3
Training loss: 1.8612533807754517
Validation loss: 1.970228413740794

Epoch: 6| Step: 4
Training loss: 1.4150898456573486
Validation loss: 1.9710139830907185

Epoch: 6| Step: 5
Training loss: 1.1801902055740356
Validation loss: 1.9877344767252605

Epoch: 6| Step: 6
Training loss: 1.987901210784912
Validation loss: 1.9969849387804668

Epoch: 6| Step: 7
Training loss: 1.6642166376113892
Validation loss: 2.010345677534739

Epoch: 6| Step: 8
Training loss: 2.3488643169403076
Validation loss: 2.0276851654052734

Epoch: 6| Step: 9
Training loss: 1.5103367567062378
Validation loss: 2.0525911450386047

Epoch: 6| Step: 10
Training loss: 1.2722511291503906
Validation loss: 2.067584733168284

Epoch: 6| Step: 11
Training loss: 1.5392918586730957
Validation loss: 2.0789509216944375

Epoch: 6| Step: 12
Training loss: 1.3508816957473755
Validation loss: 2.046985626220703

Epoch: 6| Step: 13
Training loss: 1.2979296445846558
Validation loss: 2.031449536482493

Epoch: 63| Step: 0
Training loss: 2.027780532836914
Validation loss: 2.0011380712191262

Epoch: 6| Step: 1
Training loss: 1.3098042011260986
Validation loss: 1.989813208580017

Epoch: 6| Step: 2
Training loss: 1.5968643426895142
Validation loss: 1.9810269077618916

Epoch: 6| Step: 3
Training loss: 1.140774130821228
Validation loss: 1.9791320363680522

Epoch: 6| Step: 4
Training loss: 1.2056292295455933
Validation loss: 1.9784421920776367

Epoch: 6| Step: 5
Training loss: 1.6856169700622559
Validation loss: 1.9810795585314434

Epoch: 6| Step: 6
Training loss: 1.3600637912750244
Validation loss: 1.9877723654111226

Epoch: 6| Step: 7
Training loss: 1.5289591550827026
Validation loss: 1.9976505835851033

Epoch: 6| Step: 8
Training loss: 1.2743849754333496
Validation loss: 1.9912015795707703

Epoch: 6| Step: 9
Training loss: 1.799015998840332
Validation loss: 2.0143876473108926

Epoch: 6| Step: 10
Training loss: 1.170451045036316
Validation loss: 1.9976993401845295

Epoch: 6| Step: 11
Training loss: 1.879597783088684
Validation loss: 1.9970691800117493

Epoch: 6| Step: 12
Training loss: 1.8282681703567505
Validation loss: 2.0066948731740317

Epoch: 6| Step: 13
Training loss: 1.4990507364273071
Validation loss: 1.9950788021087646

Epoch: 64| Step: 0
Training loss: 1.168604850769043
Validation loss: 2.005376160144806

Epoch: 6| Step: 1
Training loss: 1.2574710845947266
Validation loss: 2.0018184185028076

Epoch: 6| Step: 2
Training loss: 1.67036771774292
Validation loss: 1.9701322317123413

Epoch: 6| Step: 3
Training loss: 1.4261060953140259
Validation loss: 1.9772147337595622

Epoch: 6| Step: 4
Training loss: 1.2835371494293213
Validation loss: 1.9598711133003235

Epoch: 6| Step: 5
Training loss: 1.6386042833328247
Validation loss: 1.987952987353007

Epoch: 6| Step: 6
Training loss: 2.0527822971343994
Validation loss: 1.9796544909477234

Epoch: 6| Step: 7
Training loss: 1.596716284751892
Validation loss: 1.9835079511006672

Epoch: 6| Step: 8
Training loss: 1.9789257049560547
Validation loss: 2.000408867994944

Epoch: 6| Step: 9
Training loss: 1.1506693363189697
Validation loss: 1.9987947742144268

Epoch: 6| Step: 10
Training loss: 0.8822892904281616
Validation loss: 1.9981608390808105

Epoch: 6| Step: 11
Training loss: 1.3235876560211182
Validation loss: 1.994359831015269

Epoch: 6| Step: 12
Training loss: 1.50807785987854
Validation loss: 2.003782947858175

Epoch: 6| Step: 13
Training loss: 1.8410990238189697
Validation loss: 1.9782864848772685

Epoch: 65| Step: 0
Training loss: 1.4533439874649048
Validation loss: 1.994906743367513

Epoch: 6| Step: 1
Training loss: 1.356980323791504
Validation loss: 1.9990416765213013

Epoch: 6| Step: 2
Training loss: 1.3736698627471924
Validation loss: 2.0139130353927612

Epoch: 6| Step: 3
Training loss: 1.2434971332550049
Validation loss: 1.9947104255358379

Epoch: 6| Step: 4
Training loss: 1.9525253772735596
Validation loss: 1.9919455647468567

Epoch: 6| Step: 5
Training loss: 1.0264859199523926
Validation loss: 2.002088189125061

Epoch: 6| Step: 6
Training loss: 1.8957337141036987
Validation loss: 1.995870033899943

Epoch: 6| Step: 7
Training loss: 1.409557580947876
Validation loss: 1.9927472472190857

Epoch: 6| Step: 8
Training loss: 1.471846103668213
Validation loss: 1.9948075811068218

Epoch: 6| Step: 9
Training loss: 1.6511518955230713
Validation loss: 2.0076833963394165

Epoch: 6| Step: 10
Training loss: 1.6917221546173096
Validation loss: 1.992797275384267

Epoch: 6| Step: 11
Training loss: 1.4982224702835083
Validation loss: 1.9897762537002563

Epoch: 6| Step: 12
Training loss: 1.3148319721221924
Validation loss: 1.9948354760805767

Epoch: 6| Step: 13
Training loss: 1.4381722211837769
Validation loss: 1.9937334259351094

Epoch: 66| Step: 0
Training loss: 1.7489333152770996
Validation loss: 1.9936427275339763

Epoch: 6| Step: 1
Training loss: 0.7459354400634766
Validation loss: 1.9874404867490132

Epoch: 6| Step: 2
Training loss: 0.9110978245735168
Validation loss: 1.997344473997752

Epoch: 6| Step: 3
Training loss: 1.685760736465454
Validation loss: 1.9877302646636963

Epoch: 6| Step: 4
Training loss: 1.8711289167404175
Validation loss: 1.9915029406547546

Epoch: 6| Step: 5
Training loss: 1.2337167263031006
Validation loss: 2.001844346523285

Epoch: 6| Step: 6
Training loss: 1.201884388923645
Validation loss: 2.0251887241999307

Epoch: 6| Step: 7
Training loss: 1.9815608263015747
Validation loss: 2.014009634653727

Epoch: 6| Step: 8
Training loss: 1.494746446609497
Validation loss: 1.9919161200523376

Epoch: 6| Step: 9
Training loss: 1.8713661432266235
Validation loss: 1.9842037955919902

Epoch: 6| Step: 10
Training loss: 1.20547616481781
Validation loss: 1.9756890137990315

Epoch: 6| Step: 11
Training loss: 1.365403175354004
Validation loss: 1.9717058340708415

Epoch: 6| Step: 12
Training loss: 1.2182247638702393
Validation loss: 1.9941774010658264

Epoch: 6| Step: 13
Training loss: 1.869681715965271
Validation loss: 1.9932582179705303

Epoch: 67| Step: 0
Training loss: 1.4866106510162354
Validation loss: 2.00566699107488

Epoch: 6| Step: 1
Training loss: 1.708722710609436
Validation loss: 2.03904656569163

Epoch: 6| Step: 2
Training loss: 1.693275809288025
Validation loss: 2.0139920910199485

Epoch: 6| Step: 3
Training loss: 1.3496183156967163
Validation loss: 2.0057992339134216

Epoch: 6| Step: 4
Training loss: 1.0291268825531006
Validation loss: 2.0085877180099487

Epoch: 6| Step: 5
Training loss: 1.3258278369903564
Validation loss: 2.018485109011332

Epoch: 6| Step: 6
Training loss: 1.6363134384155273
Validation loss: 1.990578571955363

Epoch: 6| Step: 7
Training loss: 1.4122986793518066
Validation loss: 1.9857279459635417

Epoch: 6| Step: 8
Training loss: 1.578075647354126
Validation loss: 1.9897894064585369

Epoch: 6| Step: 9
Training loss: 1.590038537979126
Validation loss: 2.0072410901387534

Epoch: 6| Step: 10
Training loss: 1.7962076663970947
Validation loss: 1.985085626443227

Epoch: 6| Step: 11
Training loss: 1.0344449281692505
Validation loss: 2.011003235975901

Epoch: 6| Step: 12
Training loss: 1.2588865756988525
Validation loss: 1.9787700374921162

Epoch: 6| Step: 13
Training loss: 1.6161739826202393
Validation loss: 2.0229137341181436

Epoch: 68| Step: 0
Training loss: 1.3075586557388306
Validation loss: 2.0275768438975015

Epoch: 6| Step: 1
Training loss: 2.2975292205810547
Validation loss: 2.0206450819969177

Epoch: 6| Step: 2
Training loss: 1.335673213005066
Validation loss: 2.020897706349691

Epoch: 6| Step: 3
Training loss: 0.9907935857772827
Validation loss: 2.020655075709025

Epoch: 6| Step: 4
Training loss: 1.3118635416030884
Validation loss: 2.0153960386912027

Epoch: 6| Step: 5
Training loss: 1.1641936302185059
Validation loss: 1.9907085696856182

Epoch: 6| Step: 6
Training loss: 1.5540046691894531
Validation loss: 1.9758296012878418

Epoch: 6| Step: 7
Training loss: 1.6104443073272705
Validation loss: 1.9776944120724995

Epoch: 6| Step: 8
Training loss: 1.2298465967178345
Validation loss: 1.9740946690241497

Epoch: 6| Step: 9
Training loss: 0.8319085836410522
Validation loss: 1.9734811584154766

Epoch: 6| Step: 10
Training loss: 1.258779525756836
Validation loss: 1.9872312943140666

Epoch: 6| Step: 11
Training loss: 1.5475986003875732
Validation loss: 1.977600336074829

Epoch: 6| Step: 12
Training loss: 1.448620319366455
Validation loss: 1.9650529623031616

Epoch: 6| Step: 13
Training loss: 2.06815767288208
Validation loss: 1.961764633655548

Epoch: 69| Step: 0
Training loss: 1.1463403701782227
Validation loss: 1.9940547744433086

Epoch: 6| Step: 1
Training loss: 1.5850697755813599
Validation loss: 1.9846565127372742

Epoch: 6| Step: 2
Training loss: 1.7355538606643677
Validation loss: 2.0007826487223306

Epoch: 6| Step: 3
Training loss: 1.388527512550354
Validation loss: 1.9977024793624878

Epoch: 6| Step: 4
Training loss: 1.3636826276779175
Validation loss: 1.973665992418925

Epoch: 6| Step: 5
Training loss: 1.5850685834884644
Validation loss: 1.9668564796447754

Epoch: 6| Step: 6
Training loss: 1.4048595428466797
Validation loss: 1.9626703262329102

Epoch: 6| Step: 7
Training loss: 0.9976066946983337
Validation loss: 1.9728198647499084

Epoch: 6| Step: 8
Training loss: 1.6791329383850098
Validation loss: 1.983963429927826

Epoch: 6| Step: 9
Training loss: 1.7686388492584229
Validation loss: 2.001147468884786

Epoch: 6| Step: 10
Training loss: 1.463166356086731
Validation loss: 2.0026232997576394

Epoch: 6| Step: 11
Training loss: 1.6136949062347412
Validation loss: 2.0325233141581216

Epoch: 6| Step: 12
Training loss: 0.8766202926635742
Validation loss: 2.044570783774058

Epoch: 6| Step: 13
Training loss: 1.34786856174469
Validation loss: 2.0040905475616455

Epoch: 70| Step: 0
Training loss: 1.4838438034057617
Validation loss: 2.0037041306495667

Epoch: 6| Step: 1
Training loss: 1.2133617401123047
Validation loss: 2.018139123916626

Epoch: 6| Step: 2
Training loss: 1.1577726602554321
Validation loss: 1.9880848328272502

Epoch: 6| Step: 3
Training loss: 1.3197903633117676
Validation loss: 1.9975337187449138

Epoch: 6| Step: 4
Training loss: 1.8859248161315918
Validation loss: 1.9924792051315308

Epoch: 6| Step: 5
Training loss: 1.5792783498764038
Validation loss: 1.9763526916503906

Epoch: 6| Step: 6
Training loss: 1.5943500995635986
Validation loss: 1.9835488398869832

Epoch: 6| Step: 7
Training loss: 1.3723000288009644
Validation loss: 1.9963845610618591

Epoch: 6| Step: 8
Training loss: 0.7815102338790894
Validation loss: 1.9986680547396343

Epoch: 6| Step: 9
Training loss: 1.283657193183899
Validation loss: 2.001733044783274

Epoch: 6| Step: 10
Training loss: 1.5983524322509766
Validation loss: 2.002794702847799

Epoch: 6| Step: 11
Training loss: 1.3945245742797852
Validation loss: 1.9763614932696025

Epoch: 6| Step: 12
Training loss: 1.5814990997314453
Validation loss: 1.980892797311147

Epoch: 6| Step: 13
Training loss: 1.3924474716186523
Validation loss: 1.9544832507769268

Epoch: 71| Step: 0
Training loss: 1.1273318529129028
Validation loss: 1.9716350237528484

Epoch: 6| Step: 1
Training loss: 1.327454924583435
Validation loss: 1.9675450325012207

Epoch: 6| Step: 2
Training loss: 1.8667876720428467
Validation loss: 1.9587212602297466

Epoch: 6| Step: 3
Training loss: 1.1242477893829346
Validation loss: 1.989806632200877

Epoch: 6| Step: 4
Training loss: 1.0072883367538452
Validation loss: 2.0016321539878845

Epoch: 6| Step: 5
Training loss: 0.8148672580718994
Validation loss: 2.03820530573527

Epoch: 6| Step: 6
Training loss: 1.4827816486358643
Validation loss: 2.0351864099502563

Epoch: 6| Step: 7
Training loss: 1.691861867904663
Validation loss: 2.048517644405365

Epoch: 6| Step: 8
Training loss: 1.5588455200195312
Validation loss: 2.0481528838475547

Epoch: 6| Step: 9
Training loss: 1.125403881072998
Validation loss: 2.0337390104929605

Epoch: 6| Step: 10
Training loss: 1.7542564868927002
Validation loss: 1.9981442491213481

Epoch: 6| Step: 11
Training loss: 2.215087652206421
Validation loss: 1.994705617427826

Epoch: 6| Step: 12
Training loss: 1.2441872358322144
Validation loss: 1.9708172082901

Epoch: 6| Step: 13
Training loss: 1.3630338907241821
Validation loss: 2.0117448965708413

Epoch: 72| Step: 0
Training loss: 1.4951658248901367
Validation loss: 2.0125489036242166

Epoch: 6| Step: 1
Training loss: 1.2446131706237793
Validation loss: 1.983379344145457

Epoch: 6| Step: 2
Training loss: 1.5391392707824707
Validation loss: 2.0112714370091758

Epoch: 6| Step: 3
Training loss: 1.2084543704986572
Validation loss: 1.9800681471824646

Epoch: 6| Step: 4
Training loss: 2.286087989807129
Validation loss: 2.035699427127838

Epoch: 6| Step: 5
Training loss: 1.3700042963027954
Validation loss: 2.006832182407379

Epoch: 6| Step: 6
Training loss: 1.729872465133667
Validation loss: 2.0032126108805337

Epoch: 6| Step: 7
Training loss: 1.1523332595825195
Validation loss: 2.0116379261016846

Epoch: 6| Step: 8
Training loss: 0.8061503171920776
Validation loss: 2.002924919128418

Epoch: 6| Step: 9
Training loss: 1.209453821182251
Validation loss: 1.9980867902437847

Epoch: 6| Step: 10
Training loss: 1.3758548498153687
Validation loss: 1.973968466122945

Epoch: 6| Step: 11
Training loss: 1.113554835319519
Validation loss: 2.0047542651494346

Epoch: 6| Step: 12
Training loss: 1.860802173614502
Validation loss: 2.0216896533966064

Epoch: 6| Step: 13
Training loss: 1.0438809394836426
Validation loss: 2.018721282482147

Epoch: 73| Step: 0
Training loss: 1.5545188188552856
Validation loss: 2.0199058254559836

Epoch: 6| Step: 1
Training loss: 1.507497787475586
Validation loss: 2.007586717605591

Epoch: 6| Step: 2
Training loss: 2.1280264854431152
Validation loss: 1.9924559394518535

Epoch: 6| Step: 3
Training loss: 1.6014373302459717
Validation loss: 1.9956488410631816

Epoch: 6| Step: 4
Training loss: 0.9864158034324646
Validation loss: 2.0078697005907693

Epoch: 6| Step: 5
Training loss: 1.056868076324463
Validation loss: 1.988934834798177

Epoch: 6| Step: 6
Training loss: 1.3839166164398193
Validation loss: 1.9918158451716106

Epoch: 6| Step: 7
Training loss: 1.199414610862732
Validation loss: 1.9637012283007305

Epoch: 6| Step: 8
Training loss: 1.2666913270950317
Validation loss: 1.9789814750353496

Epoch: 6| Step: 9
Training loss: 1.1263617277145386
Validation loss: 1.981864054997762

Epoch: 6| Step: 10
Training loss: 1.3035765886306763
Validation loss: 1.993000825246175

Epoch: 6| Step: 11
Training loss: 0.6164063811302185
Validation loss: 1.967670162518819

Epoch: 6| Step: 12
Training loss: 1.6685607433319092
Validation loss: 1.9680018623669941

Epoch: 6| Step: 13
Training loss: 1.603886365890503
Validation loss: 1.9690051674842834

Epoch: 74| Step: 0
Training loss: 1.2305796146392822
Validation loss: 1.9610183238983154

Epoch: 6| Step: 1
Training loss: 1.6304584741592407
Validation loss: 1.987581729888916

Epoch: 6| Step: 2
Training loss: 1.4210143089294434
Validation loss: 1.9815651973088582

Epoch: 6| Step: 3
Training loss: 1.4265146255493164
Validation loss: 2.017845352490743

Epoch: 6| Step: 4
Training loss: 1.6325018405914307
Validation loss: 2.0114185412724814

Epoch: 6| Step: 5
Training loss: 2.5134401321411133
Validation loss: 2.01465767621994

Epoch: 6| Step: 6
Training loss: 1.1366324424743652
Validation loss: 1.9975890119870503

Epoch: 6| Step: 7
Training loss: 1.0195486545562744
Validation loss: 1.964907944202423

Epoch: 6| Step: 8
Training loss: 1.0371471643447876
Validation loss: 1.9619021813074748

Epoch: 6| Step: 9
Training loss: 1.3782864809036255
Validation loss: 1.955451528231303

Epoch: 6| Step: 10
Training loss: 1.0540578365325928
Validation loss: 1.965171992778778

Epoch: 6| Step: 11
Training loss: 1.4954456090927124
Validation loss: 1.967066804567973

Epoch: 6| Step: 12
Training loss: 1.1051113605499268
Validation loss: 1.970578928788503

Epoch: 6| Step: 13
Training loss: 1.0430816411972046
Validation loss: 1.9856047630310059

Epoch: 75| Step: 0
Training loss: 1.2462506294250488
Validation loss: 1.9776824315388997

Epoch: 6| Step: 1
Training loss: 1.4312779903411865
Validation loss: 1.9508383472760518

Epoch: 6| Step: 2
Training loss: 1.2806740999221802
Validation loss: 1.9684122403462727

Epoch: 6| Step: 3
Training loss: 1.365060806274414
Validation loss: 1.9749993483225505

Epoch: 6| Step: 4
Training loss: 0.9661190509796143
Validation loss: 1.9508150219917297

Epoch: 6| Step: 5
Training loss: 1.506616234779358
Validation loss: 1.9667883117993672

Epoch: 6| Step: 6
Training loss: 1.2232677936553955
Validation loss: 1.961586316426595

Epoch: 6| Step: 7
Training loss: 1.444791555404663
Validation loss: 1.9760581056276958

Epoch: 6| Step: 8
Training loss: 1.672936201095581
Validation loss: 2.0118287603060403

Epoch: 6| Step: 9
Training loss: 1.7535839080810547
Validation loss: 2.0266390840212503

Epoch: 6| Step: 10
Training loss: 1.475013256072998
Validation loss: 2.054277181625366

Epoch: 6| Step: 11
Training loss: 0.9858906269073486
Validation loss: 2.0371480782826743

Epoch: 6| Step: 12
Training loss: 1.4441696405410767
Validation loss: 2.0491177241007485

Epoch: 6| Step: 13
Training loss: 1.2934417724609375
Validation loss: 2.026284337043762

Epoch: 76| Step: 0
Training loss: 1.4752362966537476
Validation loss: 1.9933382868766785

Epoch: 6| Step: 1
Training loss: 1.2452727556228638
Validation loss: 1.9776317874590557

Epoch: 6| Step: 2
Training loss: 0.9605895280838013
Validation loss: 1.9941683014233906

Epoch: 6| Step: 3
Training loss: 1.8264052867889404
Validation loss: 1.9600919882456462

Epoch: 6| Step: 4
Training loss: 1.211024522781372
Validation loss: 1.9846978783607483

Epoch: 6| Step: 5
Training loss: 1.9333622455596924
Validation loss: 1.98536217212677

Epoch: 6| Step: 6
Training loss: 0.7923821806907654
Validation loss: 2.011864880720774

Epoch: 6| Step: 7
Training loss: 1.3872216939926147
Validation loss: 2.0404310822486877

Epoch: 6| Step: 8
Training loss: 1.698474407196045
Validation loss: 2.0696500539779663

Epoch: 6| Step: 9
Training loss: 1.7529481649398804
Validation loss: 2.0625073512395224

Epoch: 6| Step: 10
Training loss: 0.6416510343551636
Validation loss: 2.026735802491506

Epoch: 6| Step: 11
Training loss: 1.065589189529419
Validation loss: 2.000771681467692

Epoch: 6| Step: 12
Training loss: 1.4122321605682373
Validation loss: 1.9970982670783997

Epoch: 6| Step: 13
Training loss: 1.3774961233139038
Validation loss: 1.9931941032409668

Epoch: 77| Step: 0
Training loss: 1.5136067867279053
Validation loss: 1.9871269464492798

Epoch: 6| Step: 1
Training loss: 1.2331109046936035
Validation loss: 1.9559203187624614

Epoch: 6| Step: 2
Training loss: 2.18381404876709
Validation loss: 1.9661881724993389

Epoch: 6| Step: 3
Training loss: 0.6439928412437439
Validation loss: 2.0084518790245056

Epoch: 6| Step: 4
Training loss: 1.356327772140503
Validation loss: 2.0329702695210776

Epoch: 6| Step: 5
Training loss: 1.4715732336044312
Validation loss: 1.988684892654419

Epoch: 6| Step: 6
Training loss: 1.0472663640975952
Validation loss: 1.9859583377838135

Epoch: 6| Step: 7
Training loss: 1.4071016311645508
Validation loss: 1.9979209899902344

Epoch: 6| Step: 8
Training loss: 0.9754356741905212
Validation loss: 1.9607542951901753

Epoch: 6| Step: 9
Training loss: 1.1544055938720703
Validation loss: 1.9650938510894775

Epoch: 6| Step: 10
Training loss: 1.4869039058685303
Validation loss: 1.9705790281295776

Epoch: 6| Step: 11
Training loss: 1.6898435354232788
Validation loss: 1.9681981801986694

Epoch: 6| Step: 12
Training loss: 1.254671573638916
Validation loss: 1.9521300594011943

Epoch: 6| Step: 13
Training loss: 1.1830122470855713
Validation loss: 1.9777416586875916

Epoch: 78| Step: 0
Training loss: 1.0960135459899902
Validation loss: 1.9902190168698628

Epoch: 6| Step: 1
Training loss: 0.6651633977890015
Validation loss: 2.0261851946512857

Epoch: 6| Step: 2
Training loss: 1.476193904876709
Validation loss: 1.9823177456855774

Epoch: 6| Step: 3
Training loss: 1.3381364345550537
Validation loss: 1.9932377139727275

Epoch: 6| Step: 4
Training loss: 1.9915900230407715
Validation loss: 2.0097436904907227

Epoch: 6| Step: 5
Training loss: 1.5098576545715332
Validation loss: 2.0151260097821555

Epoch: 6| Step: 6
Training loss: 1.0825408697128296
Validation loss: 1.9755276242891948

Epoch: 6| Step: 7
Training loss: 1.1192857027053833
Validation loss: 1.996055245399475

Epoch: 6| Step: 8
Training loss: 1.5485756397247314
Validation loss: 1.9836401144663494

Epoch: 6| Step: 9
Training loss: 1.4514729976654053
Validation loss: 2.003199299176534

Epoch: 6| Step: 10
Training loss: 1.2368407249450684
Validation loss: 2.012976268927256

Epoch: 6| Step: 11
Training loss: 1.2841427326202393
Validation loss: 2.040055811405182

Epoch: 6| Step: 12
Training loss: 0.752263069152832
Validation loss: 2.040711760520935

Epoch: 6| Step: 13
Training loss: 1.5645331144332886
Validation loss: 2.084027965863546

Epoch: 79| Step: 0
Training loss: 1.335655927658081
Validation loss: 2.055470863978068

Epoch: 6| Step: 1
Training loss: 1.0850510597229004
Validation loss: 2.055468122164408

Epoch: 6| Step: 2
Training loss: 1.5361627340316772
Validation loss: 2.019947608311971

Epoch: 6| Step: 3
Training loss: 1.0140421390533447
Validation loss: 2.035376409689585

Epoch: 6| Step: 4
Training loss: 0.9431737661361694
Validation loss: 2.0083915988604226

Epoch: 6| Step: 5
Training loss: 1.0890192985534668
Validation loss: 2.029334624608358

Epoch: 6| Step: 6
Training loss: 1.187351942062378
Validation loss: 2.0279607574144998

Epoch: 6| Step: 7
Training loss: 1.6492398977279663
Validation loss: 2.038956582546234

Epoch: 6| Step: 8
Training loss: 1.8296737670898438
Validation loss: 2.051858901977539

Epoch: 6| Step: 9
Training loss: 1.6334645748138428
Validation loss: 2.1220847964286804

Epoch: 6| Step: 10
Training loss: 1.828969120979309
Validation loss: 2.129095176855723

Epoch: 6| Step: 11
Training loss: 1.6199933290481567
Validation loss: 2.1310661236445108

Epoch: 6| Step: 12
Training loss: 1.0858759880065918
Validation loss: 2.09723569949468

Epoch: 6| Step: 13
Training loss: 1.2188456058502197
Validation loss: 2.097477078437805

Epoch: 80| Step: 0
Training loss: 1.3664895296096802
Validation loss: 2.0398674408594766

Epoch: 6| Step: 1
Training loss: 1.1518067121505737
Validation loss: 2.032244066397349

Epoch: 6| Step: 2
Training loss: 0.8454492688179016
Validation loss: 2.01750648021698

Epoch: 6| Step: 3
Training loss: 1.016165018081665
Validation loss: 1.9969106117884319

Epoch: 6| Step: 4
Training loss: 1.2057994604110718
Validation loss: 1.9947575132052104

Epoch: 6| Step: 5
Training loss: 1.2265243530273438
Validation loss: 1.9974883794784546

Epoch: 6| Step: 6
Training loss: 1.6264830827713013
Validation loss: 1.9619693160057068

Epoch: 6| Step: 7
Training loss: 1.481194257736206
Validation loss: 1.9938516815503438

Epoch: 6| Step: 8
Training loss: 1.4543275833129883
Validation loss: 1.9468034307161968

Epoch: 6| Step: 9
Training loss: 1.094817876815796
Validation loss: 1.9889359672864277

Epoch: 6| Step: 10
Training loss: 1.5807476043701172
Validation loss: 1.9844823479652405

Epoch: 6| Step: 11
Training loss: 1.569483757019043
Validation loss: 2.0052559773127236

Epoch: 6| Step: 12
Training loss: 1.2295093536376953
Validation loss: 2.0118738611539206

Epoch: 6| Step: 13
Training loss: 0.9050078988075256
Validation loss: 1.9922014673550923

Epoch: 81| Step: 0
Training loss: 1.4140851497650146
Validation loss: 2.0137640635172525

Epoch: 6| Step: 1
Training loss: 1.019733190536499
Validation loss: 2.003086050351461

Epoch: 6| Step: 2
Training loss: 1.1925687789916992
Validation loss: 1.965861737728119

Epoch: 6| Step: 3
Training loss: 1.649377703666687
Validation loss: 1.972796102364858

Epoch: 6| Step: 4
Training loss: 0.979468584060669
Validation loss: 1.9497185548146565

Epoch: 6| Step: 5
Training loss: 1.3778074979782104
Validation loss: 1.9835414290428162

Epoch: 6| Step: 6
Training loss: 1.1714938879013062
Validation loss: 1.9549177289009094

Epoch: 6| Step: 7
Training loss: 0.7158650755882263
Validation loss: 1.9892016251881917

Epoch: 6| Step: 8
Training loss: 1.6609203815460205
Validation loss: 1.979488770167033

Epoch: 6| Step: 9
Training loss: 1.6424438953399658
Validation loss: 2.0086819330851235

Epoch: 6| Step: 10
Training loss: 1.6199562549591064
Validation loss: 2.0111635526021323

Epoch: 6| Step: 11
Training loss: 1.3546452522277832
Validation loss: 2.0069178144137063

Epoch: 6| Step: 12
Training loss: 0.8473273515701294
Validation loss: 2.001814862092336

Epoch: 6| Step: 13
Training loss: 0.8630136251449585
Validation loss: 1.9834885994593303

Epoch: 82| Step: 0
Training loss: 0.8049063682556152
Validation loss: 1.9841249386469524

Epoch: 6| Step: 1
Training loss: 0.9504395127296448
Validation loss: 2.021412948767344

Epoch: 6| Step: 2
Training loss: 1.3115661144256592
Validation loss: 1.9926610390345256

Epoch: 6| Step: 3
Training loss: 0.8924527168273926
Validation loss: 1.9943865537643433

Epoch: 6| Step: 4
Training loss: 1.695709228515625
Validation loss: 1.9950313170750935

Epoch: 6| Step: 5
Training loss: 1.3720173835754395
Validation loss: 1.9854880770047505

Epoch: 6| Step: 6
Training loss: 1.1466962099075317
Validation loss: 1.9973401824633281

Epoch: 6| Step: 7
Training loss: 1.579717755317688
Validation loss: 1.9808388153711955

Epoch: 6| Step: 8
Training loss: 1.3632760047912598
Validation loss: 1.982190450032552

Epoch: 6| Step: 9
Training loss: 1.110329270362854
Validation loss: 1.9809065262476604

Epoch: 6| Step: 10
Training loss: 1.2649617195129395
Validation loss: 2.0121670365333557

Epoch: 6| Step: 11
Training loss: 1.238661766052246
Validation loss: 2.0264503955841064

Epoch: 6| Step: 12
Training loss: 1.874229907989502
Validation loss: 2.0254526138305664

Epoch: 6| Step: 13
Training loss: 1.334817886352539
Validation loss: 1.9745901226997375

Epoch: 83| Step: 0
Training loss: 1.2411470413208008
Validation loss: 1.9433120489120483

Epoch: 6| Step: 1
Training loss: 0.7139062285423279
Validation loss: 1.9397679964701335

Epoch: 6| Step: 2
Training loss: 1.1060643196105957
Validation loss: 1.9240712722142537

Epoch: 6| Step: 3
Training loss: 0.9906703233718872
Validation loss: 1.9309620062510173

Epoch: 6| Step: 4
Training loss: 1.3674142360687256
Validation loss: 1.9394854704538982

Epoch: 6| Step: 5
Training loss: 1.6369800567626953
Validation loss: 1.9815765619277954

Epoch: 6| Step: 6
Training loss: 1.311342477798462
Validation loss: 1.9544266661008198

Epoch: 6| Step: 7
Training loss: 1.3769218921661377
Validation loss: 2.020944436391195

Epoch: 6| Step: 8
Training loss: 1.255223274230957
Validation loss: 2.0210954546928406

Epoch: 6| Step: 9
Training loss: 1.1563079357147217
Validation loss: 2.052854379018148

Epoch: 6| Step: 10
Training loss: 1.8770873546600342
Validation loss: 2.0292026003201804

Epoch: 6| Step: 11
Training loss: 1.1055517196655273
Validation loss: 2.031144400437673

Epoch: 6| Step: 12
Training loss: 1.542526125907898
Validation loss: 2.0190849701563516

Epoch: 6| Step: 13
Training loss: 0.9046836495399475
Validation loss: 1.9671509265899658

Epoch: 84| Step: 0
Training loss: 1.566864252090454
Validation loss: 1.9811689853668213

Epoch: 6| Step: 1
Training loss: 0.6830101609230042
Validation loss: 1.9970300594965618

Epoch: 6| Step: 2
Training loss: 1.2994130849838257
Validation loss: 2.045858065287272

Epoch: 6| Step: 3
Training loss: 1.5600849390029907
Validation loss: 2.027337153752645

Epoch: 6| Step: 4
Training loss: 1.0556927919387817
Validation loss: 2.0105311274528503

Epoch: 6| Step: 5
Training loss: 1.4387545585632324
Validation loss: 1.96501225233078

Epoch: 6| Step: 6
Training loss: 1.6930713653564453
Validation loss: 1.9526580572128296

Epoch: 6| Step: 7
Training loss: 1.0092501640319824
Validation loss: 1.9459555943806965

Epoch: 6| Step: 8
Training loss: 1.0383121967315674
Validation loss: 1.959332009156545

Epoch: 6| Step: 9
Training loss: 1.1626713275909424
Validation loss: 1.93394668896993

Epoch: 6| Step: 10
Training loss: 1.5478111505508423
Validation loss: 1.977099319299062

Epoch: 6| Step: 11
Training loss: 1.2937759160995483
Validation loss: 2.0067453384399414

Epoch: 6| Step: 12
Training loss: 1.7608857154846191
Validation loss: 2.0095167756080627

Epoch: 6| Step: 13
Training loss: 1.2748128175735474
Validation loss: 1.9882012208302815

Epoch: 85| Step: 0
Training loss: 1.217540979385376
Validation loss: 1.935910940170288

Epoch: 6| Step: 1
Training loss: 1.1955715417861938
Validation loss: 1.9105729858080547

Epoch: 6| Step: 2
Training loss: 1.1484884023666382
Validation loss: 1.9268254041671753

Epoch: 6| Step: 3
Training loss: 1.047179937362671
Validation loss: 1.9344821969668071

Epoch: 6| Step: 4
Training loss: 1.5831855535507202
Validation loss: 1.9343876043955486

Epoch: 6| Step: 5
Training loss: 1.373512625694275
Validation loss: 1.939852813879649

Epoch: 6| Step: 6
Training loss: 0.9912194609642029
Validation loss: 1.9499506155649822

Epoch: 6| Step: 7
Training loss: 1.0740032196044922
Validation loss: 1.9753026763598125

Epoch: 6| Step: 8
Training loss: 1.4045698642730713
Validation loss: 1.9789916475613911

Epoch: 6| Step: 9
Training loss: 1.2874869108200073
Validation loss: 1.9546845356623332

Epoch: 6| Step: 10
Training loss: 1.5060962438583374
Validation loss: 1.9459336598714192

Epoch: 6| Step: 11
Training loss: 1.1018556356430054
Validation loss: 1.9241314331690471

Epoch: 6| Step: 12
Training loss: 1.2698588371276855
Validation loss: 1.9347147742907207

Epoch: 6| Step: 13
Training loss: 1.4278637170791626
Validation loss: 1.9492329359054565

Epoch: 86| Step: 0
Training loss: 1.8700270652770996
Validation loss: 1.934091607729594

Epoch: 6| Step: 1
Training loss: 1.03550124168396
Validation loss: 1.9575429956118267

Epoch: 6| Step: 2
Training loss: 0.8361130952835083
Validation loss: 1.9326305190722148

Epoch: 6| Step: 3
Training loss: 1.2982077598571777
Validation loss: 1.9454636375109355

Epoch: 6| Step: 4
Training loss: 1.3776863813400269
Validation loss: 1.9914474487304688

Epoch: 6| Step: 5
Training loss: 1.3605259656906128
Validation loss: 1.9800390998522441

Epoch: 6| Step: 6
Training loss: 1.151138424873352
Validation loss: 1.9540264407793682

Epoch: 6| Step: 7
Training loss: 1.4677236080169678
Validation loss: 1.9691175421079

Epoch: 6| Step: 8
Training loss: 1.183428406715393
Validation loss: 1.9726865688959758

Epoch: 6| Step: 9
Training loss: 1.33364999294281
Validation loss: 1.955665687719981

Epoch: 6| Step: 10
Training loss: 1.2063138484954834
Validation loss: 1.935973624388377

Epoch: 6| Step: 11
Training loss: 1.154211401939392
Validation loss: 1.9589223464330037

Epoch: 6| Step: 12
Training loss: 0.9117527008056641
Validation loss: 1.9442542791366577

Epoch: 6| Step: 13
Training loss: 0.6045534610748291
Validation loss: 1.9736708799997966

Epoch: 87| Step: 0
Training loss: 1.1736865043640137
Validation loss: 1.9723291794459026

Epoch: 6| Step: 1
Training loss: 1.0577008724212646
Validation loss: 1.9601285854975383

Epoch: 6| Step: 2
Training loss: 1.187274694442749
Validation loss: 2.003393034140269

Epoch: 6| Step: 3
Training loss: 1.4162894487380981
Validation loss: 2.0153194069862366

Epoch: 6| Step: 4
Training loss: 1.4707636833190918
Validation loss: 2.0033867955207825

Epoch: 6| Step: 5
Training loss: 0.8778797388076782
Validation loss: 1.9745648105939229

Epoch: 6| Step: 6
Training loss: 1.1117796897888184
Validation loss: 1.934380312760671

Epoch: 6| Step: 7
Training loss: 1.5796053409576416
Validation loss: 1.9161933660507202

Epoch: 6| Step: 8
Training loss: 1.03853178024292
Validation loss: 1.909190575281779

Epoch: 6| Step: 9
Training loss: 1.3143806457519531
Validation loss: 1.927596350510915

Epoch: 6| Step: 10
Training loss: 0.9674524664878845
Validation loss: 1.9374756614367168

Epoch: 6| Step: 11
Training loss: 1.863508701324463
Validation loss: 1.9337172508239746

Epoch: 6| Step: 12
Training loss: 0.830377459526062
Validation loss: 1.934258719285329

Epoch: 6| Step: 13
Training loss: 1.0605478286743164
Validation loss: 1.982209026813507

Epoch: 88| Step: 0
Training loss: 0.9093188643455505
Validation loss: 2.018460770448049

Epoch: 6| Step: 1
Training loss: 0.8601864576339722
Validation loss: 1.9981682697931926

Epoch: 6| Step: 2
Training loss: 1.3170726299285889
Validation loss: 1.9823805491129558

Epoch: 6| Step: 3
Training loss: 1.0661636590957642
Validation loss: 1.956613540649414

Epoch: 6| Step: 4
Training loss: 1.2873749732971191
Validation loss: 1.9405924876530964

Epoch: 6| Step: 5
Training loss: 1.514988660812378
Validation loss: 1.9160991509755452

Epoch: 6| Step: 6
Training loss: 1.838017225265503
Validation loss: 1.9206027587254841

Epoch: 6| Step: 7
Training loss: 1.5514912605285645
Validation loss: 1.9054495890935261

Epoch: 6| Step: 8
Training loss: 1.0701245069503784
Validation loss: 1.9123228788375854

Epoch: 6| Step: 9
Training loss: 1.1835505962371826
Validation loss: 1.91715673605601

Epoch: 6| Step: 10
Training loss: 0.9960229396820068
Validation loss: 1.929249346256256

Epoch: 6| Step: 11
Training loss: 0.7785769701004028
Validation loss: 1.9367138942082722

Epoch: 6| Step: 12
Training loss: 1.7330023050308228
Validation loss: 1.9462052186330159

Epoch: 6| Step: 13
Training loss: 0.7075279951095581
Validation loss: 1.9241963227589924

Epoch: 89| Step: 0
Training loss: 1.2035658359527588
Validation loss: 1.9352001150449116

Epoch: 6| Step: 1
Training loss: 0.8962947726249695
Validation loss: 1.9597634474436443

Epoch: 6| Step: 2
Training loss: 1.3665698766708374
Validation loss: 1.9295249581336975

Epoch: 6| Step: 3
Training loss: 1.0167484283447266
Validation loss: 1.9368627667427063

Epoch: 6| Step: 4
Training loss: 1.7534241676330566
Validation loss: 1.9480621218681335

Epoch: 6| Step: 5
Training loss: 0.9898913502693176
Validation loss: 1.9697596629460652

Epoch: 6| Step: 6
Training loss: 1.2693065404891968
Validation loss: 1.931552251180013

Epoch: 6| Step: 7
Training loss: 0.9857558012008667
Validation loss: 1.9698305527369182

Epoch: 6| Step: 8
Training loss: 0.7360996007919312
Validation loss: 1.9745970964431763

Epoch: 6| Step: 9
Training loss: 0.9668862223625183
Validation loss: 1.9782087802886963

Epoch: 6| Step: 10
Training loss: 0.8889252543449402
Validation loss: 2.007083217302958

Epoch: 6| Step: 11
Training loss: 1.100203037261963
Validation loss: 2.042106827100118

Epoch: 6| Step: 12
Training loss: 1.6056569814682007
Validation loss: 2.065997004508972

Epoch: 6| Step: 13
Training loss: 1.3936221599578857
Validation loss: 2.082701643308004

Epoch: 90| Step: 0
Training loss: 1.0559916496276855
Validation loss: 2.034787197907766

Epoch: 6| Step: 1
Training loss: 1.4924020767211914
Validation loss: 2.020720879236857

Epoch: 6| Step: 2
Training loss: 1.3113470077514648
Validation loss: 1.9908414880434673

Epoch: 6| Step: 3
Training loss: 0.736839234828949
Validation loss: 1.9909610946973164

Epoch: 6| Step: 4
Training loss: 1.0532035827636719
Validation loss: 1.992236316204071

Epoch: 6| Step: 5
Training loss: 1.4085192680358887
Validation loss: 1.9857696692148845

Epoch: 6| Step: 6
Training loss: 1.6479265689849854
Validation loss: 1.996035397052765

Epoch: 6| Step: 7
Training loss: 1.2808265686035156
Validation loss: 1.9830593069394429

Epoch: 6| Step: 8
Training loss: 1.0065644979476929
Validation loss: 1.9584910074869792

Epoch: 6| Step: 9
Training loss: 1.432413101196289
Validation loss: 2.024559477965037

Epoch: 6| Step: 10
Training loss: 0.8675685524940491
Validation loss: 2.0693707267443338

Epoch: 6| Step: 11
Training loss: 1.2564921379089355
Validation loss: 2.0555232167243958

Epoch: 6| Step: 12
Training loss: 1.4579614400863647
Validation loss: 1.9757169683774312

Epoch: 6| Step: 13
Training loss: 0.7454577088356018
Validation loss: 1.968454122543335

Epoch: 91| Step: 0
Training loss: 1.6391537189483643
Validation loss: 1.9735225637753804

Epoch: 6| Step: 1
Training loss: 1.4078447818756104
Validation loss: 1.9655868212382

Epoch: 6| Step: 2
Training loss: 1.2146236896514893
Validation loss: 1.997623085975647

Epoch: 6| Step: 3
Training loss: 0.915086567401886
Validation loss: 1.95704847574234

Epoch: 6| Step: 4
Training loss: 0.9394410848617554
Validation loss: 1.9671996037165325

Epoch: 6| Step: 5
Training loss: 0.42286378145217896
Validation loss: 2.007078011830648

Epoch: 6| Step: 6
Training loss: 0.865960955619812
Validation loss: 1.9654292662938435

Epoch: 6| Step: 7
Training loss: 1.797298789024353
Validation loss: 1.995070258776347

Epoch: 6| Step: 8
Training loss: 1.01456880569458
Validation loss: 1.9908607403437297

Epoch: 6| Step: 9
Training loss: 1.6272881031036377
Validation loss: 2.0090484817822776

Epoch: 6| Step: 10
Training loss: 1.1468064785003662
Validation loss: 1.9578367869059246

Epoch: 6| Step: 11
Training loss: 0.9401596784591675
Validation loss: 1.9549681544303894

Epoch: 6| Step: 12
Training loss: 1.0089831352233887
Validation loss: 1.9370196262995403

Epoch: 6| Step: 13
Training loss: 0.9715068340301514
Validation loss: 1.935382088025411

Epoch: 92| Step: 0
Training loss: 0.7120802402496338
Validation loss: 1.9421254595120747

Epoch: 6| Step: 1
Training loss: 1.1059141159057617
Validation loss: 1.936574657758077

Epoch: 6| Step: 2
Training loss: 1.0060750246047974
Validation loss: 1.9406922062238057

Epoch: 6| Step: 3
Training loss: 0.9367356300354004
Validation loss: 1.9498764276504517

Epoch: 6| Step: 4
Training loss: 1.678758978843689
Validation loss: 1.9522168636322021

Epoch: 6| Step: 5
Training loss: 1.2861006259918213
Validation loss: 1.9622552990913391

Epoch: 6| Step: 6
Training loss: 0.8575652837753296
Validation loss: 1.9704739451408386

Epoch: 6| Step: 7
Training loss: 0.8948572874069214
Validation loss: 1.9762033422787983

Epoch: 6| Step: 8
Training loss: 1.391606330871582
Validation loss: 1.9577362140019734

Epoch: 6| Step: 9
Training loss: 1.3348033428192139
Validation loss: 1.9757535854975383

Epoch: 6| Step: 10
Training loss: 1.422682523727417
Validation loss: 1.9477789600690205

Epoch: 6| Step: 11
Training loss: 1.2041707038879395
Validation loss: 1.9758667548497517

Epoch: 6| Step: 12
Training loss: 1.0605440139770508
Validation loss: 1.959551453590393

Epoch: 6| Step: 13
Training loss: 1.0287286043167114
Validation loss: 2.05312047402064

Epoch: 93| Step: 0
Training loss: 1.2887146472930908
Validation loss: 2.136193116505941

Epoch: 6| Step: 1
Training loss: 1.1276508569717407
Validation loss: 2.0494137008984885

Epoch: 6| Step: 2
Training loss: 1.3351855278015137
Validation loss: 2.0287636518478394

Epoch: 6| Step: 3
Training loss: 1.1855638027191162
Validation loss: 1.9856430292129517

Epoch: 6| Step: 4
Training loss: 1.3226553201675415
Validation loss: 1.9922779202461243

Epoch: 6| Step: 5
Training loss: 1.560758352279663
Validation loss: 1.9783723553021748

Epoch: 6| Step: 6
Training loss: 1.2364362478256226
Validation loss: 1.9945481618245442

Epoch: 6| Step: 7
Training loss: 1.5487940311431885
Validation loss: 1.972802956899007

Epoch: 6| Step: 8
Training loss: 1.0029997825622559
Validation loss: 1.9665279189745586

Epoch: 6| Step: 9
Training loss: 0.7037827968597412
Validation loss: 1.969258725643158

Epoch: 6| Step: 10
Training loss: 0.5619734525680542
Validation loss: 2.023377517859141

Epoch: 6| Step: 11
Training loss: 1.1556721925735474
Validation loss: 2.079150398572286

Epoch: 6| Step: 12
Training loss: 1.467261791229248
Validation loss: 2.0711175998051963

Epoch: 6| Step: 13
Training loss: 1.334836721420288
Validation loss: 1.9943909049034119

Epoch: 94| Step: 0
Training loss: 1.306459903717041
Validation loss: 1.9437043865521748

Epoch: 6| Step: 1
Training loss: 0.927383542060852
Validation loss: 1.953048010667165

Epoch: 6| Step: 2
Training loss: 1.2436026334762573
Validation loss: 1.9597009420394897

Epoch: 6| Step: 3
Training loss: 1.868401288986206
Validation loss: 1.9688657522201538

Epoch: 6| Step: 4
Training loss: 0.9470138549804688
Validation loss: 1.9562851786613464

Epoch: 6| Step: 5
Training loss: 0.5616812705993652
Validation loss: 1.9072227478027344

Epoch: 6| Step: 6
Training loss: 0.9965502023696899
Validation loss: 1.9426787892977397

Epoch: 6| Step: 7
Training loss: 1.069585919380188
Validation loss: 1.9984851678212483

Epoch: 6| Step: 8
Training loss: 0.9643409252166748
Validation loss: 1.9610790014266968

Epoch: 6| Step: 9
Training loss: 0.9095356464385986
Validation loss: 1.9623737335205078

Epoch: 6| Step: 10
Training loss: 0.937881588935852
Validation loss: 1.9779861370722454

Epoch: 6| Step: 11
Training loss: 1.8526618480682373
Validation loss: 1.9390968879063923

Epoch: 6| Step: 12
Training loss: 1.1687933206558228
Validation loss: 1.9286579489707947

Epoch: 6| Step: 13
Training loss: 1.2078742980957031
Validation loss: 1.9519165356953938

Epoch: 95| Step: 0
Training loss: 1.279753565788269
Validation loss: 1.9679803450902302

Epoch: 6| Step: 1
Training loss: 0.8648177981376648
Validation loss: 1.9677156209945679

Epoch: 6| Step: 2
Training loss: 0.9467162489891052
Validation loss: 2.011402428150177

Epoch: 6| Step: 3
Training loss: 0.7585239410400391
Validation loss: 2.0730494459470115

Epoch: 6| Step: 4
Training loss: 1.8550043106079102
Validation loss: 2.0931203166643777

Epoch: 6| Step: 5
Training loss: 0.856665313243866
Validation loss: 2.0953438679377236

Epoch: 6| Step: 6
Training loss: 1.4979950189590454
Validation loss: 2.042675236860911

Epoch: 6| Step: 7
Training loss: 0.7854046821594238
Validation loss: 2.026020805040995

Epoch: 6| Step: 8
Training loss: 0.599165678024292
Validation loss: 1.9956244230270386

Epoch: 6| Step: 9
Training loss: 1.2419195175170898
Validation loss: 2.0126818219820657

Epoch: 6| Step: 10
Training loss: 1.4244405031204224
Validation loss: 2.0427348415056863

Epoch: 6| Step: 11
Training loss: 0.960452675819397
Validation loss: 2.0377286473910012

Epoch: 6| Step: 12
Training loss: 1.7465221881866455
Validation loss: 2.0643915136655173

Epoch: 6| Step: 13
Training loss: 0.7520170211791992
Validation loss: 2.0003575483957925

Epoch: 96| Step: 0
Training loss: 1.607474446296692
Validation loss: 1.947803537050883

Epoch: 6| Step: 1
Training loss: 1.12093186378479
Validation loss: 1.9776120980580647

Epoch: 6| Step: 2
Training loss: 1.051112413406372
Validation loss: 1.9818164110183716

Epoch: 6| Step: 3
Training loss: 0.849608302116394
Validation loss: 1.9511913458506267

Epoch: 6| Step: 4
Training loss: 1.1648759841918945
Validation loss: 1.944964865843455

Epoch: 6| Step: 5
Training loss: 1.3172216415405273
Validation loss: 1.9605305393536885

Epoch: 6| Step: 6
Training loss: 0.7858594655990601
Validation loss: 1.9534122546513875

Epoch: 6| Step: 7
Training loss: 0.9708888530731201
Validation loss: 1.9328791896502178

Epoch: 6| Step: 8
Training loss: 1.1829780340194702
Validation loss: 1.9502094388008118

Epoch: 6| Step: 9
Training loss: 1.4217114448547363
Validation loss: 1.9058350523312886

Epoch: 6| Step: 10
Training loss: 1.099833369255066
Validation loss: 1.9122469623883565

Epoch: 6| Step: 11
Training loss: 1.0228853225708008
Validation loss: 1.936322549978892

Epoch: 6| Step: 12
Training loss: 0.5873294472694397
Validation loss: 1.9168052077293396

Epoch: 6| Step: 13
Training loss: 0.8767483234405518
Validation loss: 1.923274576663971

Epoch: 97| Step: 0
Training loss: 0.5555447340011597
Validation loss: 1.9125642379124959

Epoch: 6| Step: 1
Training loss: 1.5778703689575195
Validation loss: 1.93110187848409

Epoch: 6| Step: 2
Training loss: 0.7245280742645264
Validation loss: 1.9360807339350383

Epoch: 6| Step: 3
Training loss: 0.7837780117988586
Validation loss: 1.9215373794237773

Epoch: 6| Step: 4
Training loss: 1.3787330389022827
Validation loss: 1.909077266852061

Epoch: 6| Step: 5
Training loss: 1.3016574382781982
Validation loss: 1.9100191394488018

Epoch: 6| Step: 6
Training loss: 0.6384274363517761
Validation loss: 1.9268306493759155

Epoch: 6| Step: 7
Training loss: 1.1694207191467285
Validation loss: 1.909932831923167

Epoch: 6| Step: 8
Training loss: 0.8893749713897705
Validation loss: 1.9345995783805847

Epoch: 6| Step: 9
Training loss: 1.103530764579773
Validation loss: 1.9419851303100586

Epoch: 6| Step: 10
Training loss: 1.661013126373291
Validation loss: 1.9716449578603108

Epoch: 6| Step: 11
Training loss: 1.53531014919281
Validation loss: 1.9758182366689045

Epoch: 6| Step: 12
Training loss: 1.1227082014083862
Validation loss: 1.9853148659070332

Epoch: 6| Step: 13
Training loss: 0.6125843524932861
Validation loss: 1.923778732617696

Epoch: 98| Step: 0
Training loss: 1.2130398750305176
Validation loss: 1.971192459265391

Epoch: 6| Step: 1
Training loss: 0.7347530722618103
Validation loss: 1.9408594369888306

Epoch: 6| Step: 2
Training loss: 0.6982640624046326
Validation loss: 1.9524468779563904

Epoch: 6| Step: 3
Training loss: 0.9151521921157837
Validation loss: 1.9413767059644063

Epoch: 6| Step: 4
Training loss: 0.7173907160758972
Validation loss: 1.9379351139068604

Epoch: 6| Step: 5
Training loss: 1.090623140335083
Validation loss: 1.9468834002812703

Epoch: 6| Step: 6
Training loss: 0.9710107445716858
Validation loss: 1.931134283542633

Epoch: 6| Step: 7
Training loss: 1.0774576663970947
Validation loss: 1.9540114204088848

Epoch: 6| Step: 8
Training loss: 1.2375881671905518
Validation loss: 2.0069873134295144

Epoch: 6| Step: 9
Training loss: 1.3520681858062744
Validation loss: 1.9786412119865417

Epoch: 6| Step: 10
Training loss: 1.0049748420715332
Validation loss: 1.9786279797554016

Epoch: 6| Step: 11
Training loss: 0.9310696125030518
Validation loss: 1.994247833887736

Epoch: 6| Step: 12
Training loss: 0.9670449495315552
Validation loss: 1.9472053050994873

Epoch: 6| Step: 13
Training loss: 1.405990719795227
Validation loss: 1.9584784905115764

Epoch: 99| Step: 0
Training loss: 1.0407347679138184
Validation loss: 1.9717142780621846

Epoch: 6| Step: 1
Training loss: 1.154195785522461
Validation loss: 1.9425164461135864

Epoch: 6| Step: 2
Training loss: 0.8961689472198486
Validation loss: 1.9746553699175518

Epoch: 6| Step: 3
Training loss: 0.9133594632148743
Validation loss: 1.9428374767303467

Epoch: 6| Step: 4
Training loss: 0.5445441007614136
Validation loss: 1.9511905709902446

Epoch: 6| Step: 5
Training loss: 0.8812865614891052
Validation loss: 1.931961437066396

Epoch: 6| Step: 6
Training loss: 0.7587043046951294
Validation loss: 1.941341241200765

Epoch: 6| Step: 7
Training loss: 1.475237250328064
Validation loss: 1.9700230558713276

Epoch: 6| Step: 8
Training loss: 1.2078242301940918
Validation loss: 1.961238165696462

Epoch: 6| Step: 9
Training loss: 0.9897730946540833
Validation loss: 1.9076107541720073

Epoch: 6| Step: 10
Training loss: 1.0223551988601685
Validation loss: 1.9810970624287922

Epoch: 6| Step: 11
Training loss: 1.2811534404754639
Validation loss: 1.9577075839042664

Epoch: 6| Step: 12
Training loss: 0.6135290861129761
Validation loss: 1.9497912327448528

Epoch: 6| Step: 13
Training loss: 1.3605103492736816
Validation loss: 1.949869434038798

Epoch: 100| Step: 0
Training loss: 1.387642502784729
Validation loss: 1.9418535629908245

Epoch: 6| Step: 1
Training loss: 1.2981700897216797
Validation loss: 1.9389482537905376

Epoch: 6| Step: 2
Training loss: 1.1568710803985596
Validation loss: 1.9689920544624329

Epoch: 6| Step: 3
Training loss: 0.6067986488342285
Validation loss: 1.9640801747639973

Epoch: 6| Step: 4
Training loss: 0.8159140944480896
Validation loss: 1.9519447684288025

Epoch: 6| Step: 5
Training loss: 0.9878798723220825
Validation loss: 1.933794339497884

Epoch: 6| Step: 6
Training loss: 1.1613426208496094
Validation loss: 1.9446512858072917

Epoch: 6| Step: 7
Training loss: 1.1901624202728271
Validation loss: 1.9393031398455303

Epoch: 6| Step: 8
Training loss: 1.2373206615447998
Validation loss: 1.9714900652567546

Epoch: 6| Step: 9
Training loss: 0.9347590804100037
Validation loss: 2.012227217356364

Epoch: 6| Step: 10
Training loss: 0.7294016480445862
Validation loss: 2.029090424378713

Epoch: 6| Step: 11
Training loss: 1.1020809412002563
Validation loss: 1.9315553903579712

Epoch: 6| Step: 12
Training loss: 1.3155176639556885
Validation loss: 1.9555901686350505

Epoch: 6| Step: 13
Training loss: 1.3844325542449951
Validation loss: 1.9676401019096375

Epoch: 101| Step: 0
Training loss: 1.313382863998413
Validation loss: 1.9649832447369893

Epoch: 6| Step: 1
Training loss: 1.2299336194992065
Validation loss: 1.9644164045651753

Epoch: 6| Step: 2
Training loss: 0.9088038802146912
Validation loss: 1.9269809524218242

Epoch: 6| Step: 3
Training loss: 1.2357757091522217
Validation loss: 1.934532642364502

Epoch: 6| Step: 4
Training loss: 1.092448115348816
Validation loss: 2.0251445174217224

Epoch: 6| Step: 5
Training loss: 1.7094659805297852
Validation loss: 2.068754196166992

Epoch: 6| Step: 6
Training loss: 1.362392544746399
Validation loss: 2.068761189778646

Epoch: 6| Step: 7
Training loss: 0.6797175407409668
Validation loss: 2.0066755612691245

Epoch: 6| Step: 8
Training loss: 1.1517293453216553
Validation loss: 1.968483030796051

Epoch: 6| Step: 9
Training loss: 0.995132327079773
Validation loss: 1.923441191514333

Epoch: 6| Step: 10
Training loss: 1.0309319496154785
Validation loss: 1.9789015650749207

Epoch: 6| Step: 11
Training loss: 1.6717884540557861
Validation loss: 2.02393114566803

Epoch: 6| Step: 12
Training loss: 1.646479845046997
Validation loss: 2.048663099606832

Epoch: 6| Step: 13
Training loss: 1.8635966777801514
Validation loss: 2.062502841154734

Epoch: 102| Step: 0
Training loss: 1.1650352478027344
Validation loss: 2.000133196512858

Epoch: 6| Step: 1
Training loss: 0.8194683790206909
Validation loss: 1.926664412021637

Epoch: 6| Step: 2
Training loss: 0.7460212707519531
Validation loss: 1.9039634068806965

Epoch: 6| Step: 3
Training loss: 0.987364649772644
Validation loss: 1.958296815554301

Epoch: 6| Step: 4
Training loss: 1.046532392501831
Validation loss: 2.0568143129348755

Epoch: 6| Step: 5
Training loss: 1.310978889465332
Validation loss: 2.044857442378998

Epoch: 6| Step: 6
Training loss: 0.9663593769073486
Validation loss: 2.0279328425725303

Epoch: 6| Step: 7
Training loss: 0.9898983836174011
Validation loss: 1.9721444845199585

Epoch: 6| Step: 8
Training loss: 0.8764671087265015
Validation loss: 1.9273149967193604

Epoch: 6| Step: 9
Training loss: 1.2386813163757324
Validation loss: 1.9628969430923462

Epoch: 6| Step: 10
Training loss: 1.6197302341461182
Validation loss: 1.9601078430811565

Epoch: 6| Step: 11
Training loss: 1.6666185855865479
Validation loss: 1.9970856507619221

Epoch: 6| Step: 12
Training loss: 1.427246332168579
Validation loss: 1.954400897026062

Epoch: 6| Step: 13
Training loss: 1.219933032989502
Validation loss: 1.9550660053888957

Epoch: 103| Step: 0
Training loss: 1.4506025314331055
Validation loss: 1.9480973879496257

Epoch: 6| Step: 1
Training loss: 0.6683273315429688
Validation loss: 1.9342929124832153

Epoch: 6| Step: 2
Training loss: 0.8010715246200562
Validation loss: 1.9603915015856426

Epoch: 6| Step: 3
Training loss: 1.7230498790740967
Validation loss: 1.9580941200256348

Epoch: 6| Step: 4
Training loss: 1.2866766452789307
Validation loss: 2.029216011365255

Epoch: 6| Step: 5
Training loss: 1.0234057903289795
Validation loss: 1.9829880396525066

Epoch: 6| Step: 6
Training loss: 0.7329598665237427
Validation loss: 1.9549107352892559

Epoch: 6| Step: 7
Training loss: 0.6794758439064026
Validation loss: 1.9400771260261536

Epoch: 6| Step: 8
Training loss: 1.634373426437378
Validation loss: 1.9420433441797893

Epoch: 6| Step: 9
Training loss: 0.7020716667175293
Validation loss: 1.9330835143725078

Epoch: 6| Step: 10
Training loss: 0.5849350094795227
Validation loss: 1.9672674139340718

Epoch: 6| Step: 11
Training loss: 0.8969694375991821
Validation loss: 1.9805126190185547

Epoch: 6| Step: 12
Training loss: 0.9475729465484619
Validation loss: 2.0038820703824363

Epoch: 6| Step: 13
Training loss: 1.3651758432388306
Validation loss: 2.024819294611613

Epoch: 104| Step: 0
Training loss: 1.0903936624526978
Validation loss: 2.010551651318868

Epoch: 6| Step: 1
Training loss: 1.0107330083847046
Validation loss: 1.9642595847447712

Epoch: 6| Step: 2
Training loss: 1.4680951833724976
Validation loss: 1.9660734136899312

Epoch: 6| Step: 3
Training loss: 0.6591149568557739
Validation loss: 1.9312352935473125

Epoch: 6| Step: 4
Training loss: 0.6148934364318848
Validation loss: 1.9285300572713215

Epoch: 6| Step: 5
Training loss: 0.44403061270713806
Validation loss: 1.9279236197471619

Epoch: 6| Step: 6
Training loss: 0.7319674491882324
Validation loss: 1.9255028367042542

Epoch: 6| Step: 7
Training loss: 1.4873847961425781
Validation loss: 1.947127064069112

Epoch: 6| Step: 8
Training loss: 1.1032702922821045
Validation loss: 1.9607843160629272

Epoch: 6| Step: 9
Training loss: 1.3247995376586914
Validation loss: 1.93527756134669

Epoch: 6| Step: 10
Training loss: 1.6854724884033203
Validation loss: 1.9309507012367249

Epoch: 6| Step: 11
Training loss: 0.6556366682052612
Validation loss: 1.9547054370244343

Epoch: 6| Step: 12
Training loss: 0.8561246991157532
Validation loss: 1.9267656008402507

Epoch: 6| Step: 13
Training loss: 1.0756011009216309
Validation loss: 1.9193215767542522

Epoch: 105| Step: 0
Training loss: 1.1262524127960205
Validation loss: 1.8896052440007527

Epoch: 6| Step: 1
Training loss: 0.8282973170280457
Validation loss: 1.9033119678497314

Epoch: 6| Step: 2
Training loss: 1.082785725593567
Validation loss: 1.9037244121233623

Epoch: 6| Step: 3
Training loss: 0.7493221759796143
Validation loss: 1.9308913548787434

Epoch: 6| Step: 4
Training loss: 0.7762273550033569
Validation loss: 1.907137930393219

Epoch: 6| Step: 5
Training loss: 1.1007697582244873
Validation loss: 1.9392744302749634

Epoch: 6| Step: 6
Training loss: 0.9523314833641052
Validation loss: 1.9184840718905132

Epoch: 6| Step: 7
Training loss: 0.7209359407424927
Validation loss: 1.9393698970476787

Epoch: 6| Step: 8
Training loss: 0.6656346321105957
Validation loss: 1.9436274766921997

Epoch: 6| Step: 9
Training loss: 1.0287151336669922
Validation loss: 1.9143814245859783

Epoch: 6| Step: 10
Training loss: 1.1926192045211792
Validation loss: 1.9460577567418416

Epoch: 6| Step: 11
Training loss: 0.9709280729293823
Validation loss: 1.9147994716962178

Epoch: 6| Step: 12
Training loss: 1.1755435466766357
Validation loss: 1.927064577738444

Epoch: 6| Step: 13
Training loss: 1.0328845977783203
Validation loss: 1.9582636952400208

Epoch: 106| Step: 0
Training loss: 1.029949426651001
Validation loss: 1.9484604994455974

Epoch: 6| Step: 1
Training loss: 0.6428773403167725
Validation loss: 1.9424538215001423

Epoch: 6| Step: 2
Training loss: 0.8349830508232117
Validation loss: 1.90645170211792

Epoch: 6| Step: 3
Training loss: 0.9535771608352661
Validation loss: 1.9494418501853943

Epoch: 6| Step: 4
Training loss: 1.3582358360290527
Validation loss: 1.9448782602945964

Epoch: 6| Step: 5
Training loss: 1.0224509239196777
Validation loss: 1.9556967616081238

Epoch: 6| Step: 6
Training loss: 0.9051545858383179
Validation loss: 1.9216110308965046

Epoch: 6| Step: 7
Training loss: 1.2872825860977173
Validation loss: 1.9299037059148152

Epoch: 6| Step: 8
Training loss: 0.5049431920051575
Validation loss: 1.945117433865865

Epoch: 6| Step: 9
Training loss: 0.870019793510437
Validation loss: 1.9635579983393352

Epoch: 6| Step: 10
Training loss: 1.0173922777175903
Validation loss: 1.947087029616038

Epoch: 6| Step: 11
Training loss: 1.307004690170288
Validation loss: 1.9213629166285198

Epoch: 6| Step: 12
Training loss: 0.30631986260414124
Validation loss: 1.98895263671875

Epoch: 6| Step: 13
Training loss: 1.416802167892456
Validation loss: 1.9145780007044475

Epoch: 107| Step: 0
Training loss: 0.9384200572967529
Validation loss: 1.9554738799730937

Epoch: 6| Step: 1
Training loss: 1.1986807584762573
Validation loss: 1.9652427633603413

Epoch: 6| Step: 2
Training loss: 0.5547275543212891
Validation loss: 1.9602665106455486

Epoch: 6| Step: 3
Training loss: 1.1574441194534302
Validation loss: 1.989132324854533

Epoch: 6| Step: 4
Training loss: 0.9060229063034058
Validation loss: 1.982401470343272

Epoch: 6| Step: 5
Training loss: 0.6946873664855957
Validation loss: 1.969869593779246

Epoch: 6| Step: 6
Training loss: 0.6607499122619629
Validation loss: 1.9708841840426128

Epoch: 6| Step: 7
Training loss: 0.9164360761642456
Validation loss: 1.9551918903986614

Epoch: 6| Step: 8
Training loss: 0.983025074005127
Validation loss: 1.9623901844024658

Epoch: 6| Step: 9
Training loss: 0.7109218835830688
Validation loss: 1.9620080987612407

Epoch: 6| Step: 10
Training loss: 1.0972942113876343
Validation loss: 1.9636519153912861

Epoch: 6| Step: 11
Training loss: 1.0419812202453613
Validation loss: 1.9191097021102905

Epoch: 6| Step: 12
Training loss: 0.8442957401275635
Validation loss: 1.9861911535263062

Epoch: 6| Step: 13
Training loss: 1.2312803268432617
Validation loss: 1.9827632904052734

Epoch: 108| Step: 0
Training loss: 0.9090640544891357
Validation loss: 1.9963135719299316

Epoch: 6| Step: 1
Training loss: 1.198899269104004
Validation loss: 1.9783496658007305

Epoch: 6| Step: 2
Training loss: 1.151522159576416
Validation loss: 2.000128130118052

Epoch: 6| Step: 3
Training loss: 0.5980179905891418
Validation loss: 1.9891711076100667

Epoch: 6| Step: 4
Training loss: 1.410278558731079
Validation loss: 1.9679643313090007

Epoch: 6| Step: 5
Training loss: 0.7473857402801514
Validation loss: 1.9697089791297913

Epoch: 6| Step: 6
Training loss: 1.109834909439087
Validation loss: 1.9595884283383687

Epoch: 6| Step: 7
Training loss: 1.209061861038208
Validation loss: 1.9959519505500793

Epoch: 6| Step: 8
Training loss: 1.2678545713424683
Validation loss: 1.9629027446111043

Epoch: 6| Step: 9
Training loss: 0.5225649476051331
Validation loss: 1.9833721319834392

Epoch: 6| Step: 10
Training loss: 0.6013166308403015
Validation loss: 1.9715781807899475

Epoch: 6| Step: 11
Training loss: 0.8222580552101135
Validation loss: 2.0006908774375916

Epoch: 6| Step: 12
Training loss: 0.9901010394096375
Validation loss: 1.9849943319956462

Epoch: 6| Step: 13
Training loss: 0.592948853969574
Validation loss: 2.008935530980428

Epoch: 109| Step: 0
Training loss: 0.9761074781417847
Validation loss: 1.964365561803182

Epoch: 6| Step: 1
Training loss: 0.9575977921485901
Validation loss: 1.9523810148239136

Epoch: 6| Step: 2
Training loss: 1.2048457860946655
Validation loss: 1.9589454531669617

Epoch: 6| Step: 3
Training loss: 0.5233352184295654
Validation loss: 1.9177176554997761

Epoch: 6| Step: 4
Training loss: 0.9378153681755066
Validation loss: 1.9340484738349915

Epoch: 6| Step: 5
Training loss: 1.258529782295227
Validation loss: 1.906690537929535

Epoch: 6| Step: 6
Training loss: 0.9157079458236694
Validation loss: 1.9666900634765625

Epoch: 6| Step: 7
Training loss: 0.8840878009796143
Validation loss: 1.967344303925832

Epoch: 6| Step: 8
Training loss: 1.4419124126434326
Validation loss: 1.9400984048843384

Epoch: 6| Step: 9
Training loss: 1.0397638082504272
Validation loss: 1.945539911588033

Epoch: 6| Step: 10
Training loss: 0.4392170310020447
Validation loss: 1.9509105285008748

Epoch: 6| Step: 11
Training loss: 0.8750854730606079
Validation loss: 1.8911909063657124

Epoch: 6| Step: 12
Training loss: 1.202674388885498
Validation loss: 1.9362341960271199

Epoch: 6| Step: 13
Training loss: 0.5951272249221802
Validation loss: 1.898743728796641

Epoch: 110| Step: 0
Training loss: 0.6285324692726135
Validation loss: 1.8982869982719421

Epoch: 6| Step: 1
Training loss: 0.611769437789917
Validation loss: 1.9300091067949932

Epoch: 6| Step: 2
Training loss: 1.2229881286621094
Validation loss: 2.0067047278086343

Epoch: 6| Step: 3
Training loss: 1.2838833332061768
Validation loss: 1.9852002263069153

Epoch: 6| Step: 4
Training loss: 0.6196107268333435
Validation loss: 1.9420881668726604

Epoch: 6| Step: 5
Training loss: 0.9373653531074524
Validation loss: 1.9607241948445637

Epoch: 6| Step: 6
Training loss: 1.1449453830718994
Validation loss: 1.9389684796333313

Epoch: 6| Step: 7
Training loss: 1.0753400325775146
Validation loss: 1.9376256068547566

Epoch: 6| Step: 8
Training loss: 1.2945486307144165
Validation loss: 1.926831603050232

Epoch: 6| Step: 9
Training loss: 0.9161926507949829
Validation loss: 1.940385599931081

Epoch: 6| Step: 10
Training loss: 0.6786458492279053
Validation loss: 1.9200719793637593

Epoch: 6| Step: 11
Training loss: 0.7421414852142334
Validation loss: 1.9273088375727336

Epoch: 6| Step: 12
Training loss: 1.0655676126480103
Validation loss: 1.9476026892662048

Epoch: 6| Step: 13
Training loss: 0.8258602619171143
Validation loss: 1.9219296375910442

Epoch: 111| Step: 0
Training loss: 0.6510645747184753
Validation loss: 1.9551182389259338

Epoch: 6| Step: 1
Training loss: 1.1517130136489868
Validation loss: 1.9296507636706035

Epoch: 6| Step: 2
Training loss: 0.8808077573776245
Validation loss: 1.8972058693567913

Epoch: 6| Step: 3
Training loss: 0.937644362449646
Validation loss: 1.8994221091270447

Epoch: 6| Step: 4
Training loss: 1.2642791271209717
Validation loss: 1.9143223762512207

Epoch: 6| Step: 5
Training loss: 1.2683370113372803
Validation loss: 1.879052499930064

Epoch: 6| Step: 6
Training loss: 0.7309908866882324
Validation loss: 1.892079512278239

Epoch: 6| Step: 7
Training loss: 0.7435721158981323
Validation loss: 1.9072466492652893

Epoch: 6| Step: 8
Training loss: 0.5574729442596436
Validation loss: 1.933060844739278

Epoch: 6| Step: 9
Training loss: 1.3930330276489258
Validation loss: 1.8880794246991475

Epoch: 6| Step: 10
Training loss: 0.6934387683868408
Validation loss: 1.8314029773076375

Epoch: 6| Step: 11
Training loss: 0.4319734275341034
Validation loss: 1.9148368040720622

Epoch: 6| Step: 12
Training loss: 0.7481722831726074
Validation loss: 1.9133725961049397

Epoch: 6| Step: 13
Training loss: 1.4395909309387207
Validation loss: 1.9072643717130024

Epoch: 112| Step: 0
Training loss: 1.6642019748687744
Validation loss: 1.945257802804311

Epoch: 6| Step: 1
Training loss: 0.5388044118881226
Validation loss: 1.896981139977773

Epoch: 6| Step: 2
Training loss: 0.385056734085083
Validation loss: 1.9241244792938232

Epoch: 6| Step: 3
Training loss: 0.41726595163345337
Validation loss: 1.9126630226771038

Epoch: 6| Step: 4
Training loss: 1.5578408241271973
Validation loss: 1.9647354086240132

Epoch: 6| Step: 5
Training loss: 0.7301026582717896
Validation loss: 1.938840349515279

Epoch: 6| Step: 6
Training loss: 0.7772379517555237
Validation loss: 1.9579649368921916

Epoch: 6| Step: 7
Training loss: 1.1306421756744385
Validation loss: 1.9831445217132568

Epoch: 6| Step: 8
Training loss: 0.7970768213272095
Validation loss: 1.9857694705327351

Epoch: 6| Step: 9
Training loss: 0.6402921676635742
Validation loss: 2.0055052439371743

Epoch: 6| Step: 10
Training loss: 0.9196486473083496
Validation loss: 1.941816806793213

Epoch: 6| Step: 11
Training loss: 0.8905810117721558
Validation loss: 1.9519517024358113

Epoch: 6| Step: 12
Training loss: 0.8889937400817871
Validation loss: 1.9815526008605957

Epoch: 6| Step: 13
Training loss: 1.046940565109253
Validation loss: 1.9554869731267293

Epoch: 113| Step: 0
Training loss: 0.6137251853942871
Validation loss: 1.9715477029482524

Epoch: 6| Step: 1
Training loss: 0.8471729159355164
Validation loss: 1.9845433235168457

Epoch: 6| Step: 2
Training loss: 0.834349513053894
Validation loss: 1.980865478515625

Epoch: 6| Step: 3
Training loss: 0.9376254677772522
Validation loss: 1.943553884824117

Epoch: 6| Step: 4
Training loss: 0.3718128800392151
Validation loss: 1.956651230653127

Epoch: 6| Step: 5
Training loss: 0.8836708068847656
Validation loss: 1.9795445799827576

Epoch: 6| Step: 6
Training loss: 1.7764902114868164
Validation loss: 1.9236704111099243

Epoch: 6| Step: 7
Training loss: 0.7133030891418457
Validation loss: 1.9539947509765625

Epoch: 6| Step: 8
Training loss: 0.6666533350944519
Validation loss: 1.957813024520874

Epoch: 6| Step: 9
Training loss: 0.9582781791687012
Validation loss: 1.935942570368449

Epoch: 6| Step: 10
Training loss: 1.0878450870513916
Validation loss: 1.9538986086845398

Epoch: 6| Step: 11
Training loss: 0.7707976698875427
Validation loss: 1.9631734490394592

Epoch: 6| Step: 12
Training loss: 1.0360604524612427
Validation loss: 1.9616636832555134

Epoch: 6| Step: 13
Training loss: 0.8036450147628784
Validation loss: 1.9679295420646667

Epoch: 114| Step: 0
Training loss: 0.8590993285179138
Validation loss: 1.965139885743459

Epoch: 6| Step: 1
Training loss: 0.30438679456710815
Validation loss: 1.9495091239611309

Epoch: 6| Step: 2
Training loss: 0.6274157762527466
Validation loss: 1.9095654686292012

Epoch: 6| Step: 3
Training loss: 0.995171070098877
Validation loss: 1.9225607911745708

Epoch: 6| Step: 4
Training loss: 0.7616821527481079
Validation loss: 1.8993665774663289

Epoch: 6| Step: 5
Training loss: 1.1528282165527344
Validation loss: 1.9470066825548809

Epoch: 6| Step: 6
Training loss: 0.8772504329681396
Validation loss: 1.9080166816711426

Epoch: 6| Step: 7
Training loss: 1.2465641498565674
Validation loss: 1.937294602394104

Epoch: 6| Step: 8
Training loss: 0.9242045879364014
Validation loss: 1.9419833620389302

Epoch: 6| Step: 9
Training loss: 1.30845046043396
Validation loss: 1.9856517712275188

Epoch: 6| Step: 10
Training loss: 0.7832835912704468
Validation loss: 1.9314624468485515

Epoch: 6| Step: 11
Training loss: 0.8652555346488953
Validation loss: 1.944742480913798

Epoch: 6| Step: 12
Training loss: 0.8987795114517212
Validation loss: 1.9318480292956035

Epoch: 6| Step: 13
Training loss: 1.2023767232894897
Validation loss: 1.9514254331588745

Epoch: 115| Step: 0
Training loss: 0.8597166538238525
Validation loss: 1.9486974875132244

Epoch: 6| Step: 1
Training loss: 0.6349411010742188
Validation loss: 1.9454704523086548

Epoch: 6| Step: 2
Training loss: 0.8389986753463745
Validation loss: 1.9766751925150554

Epoch: 6| Step: 3
Training loss: 1.2531498670578003
Validation loss: 1.9755125641822815

Epoch: 6| Step: 4
Training loss: 0.7313153743743896
Validation loss: 1.9933935205141704

Epoch: 6| Step: 5
Training loss: 0.9911518096923828
Validation loss: 1.9650723338127136

Epoch: 6| Step: 6
Training loss: 1.8730003833770752
Validation loss: 1.9747815132141113

Epoch: 6| Step: 7
Training loss: 0.7209116816520691
Validation loss: 1.9495112498601277

Epoch: 6| Step: 8
Training loss: 0.7859891057014465
Validation loss: 1.955777068932851

Epoch: 6| Step: 9
Training loss: 0.6396403312683105
Validation loss: 1.9256932536760967

Epoch: 6| Step: 10
Training loss: 1.1113157272338867
Validation loss: 1.9355452259381611

Epoch: 6| Step: 11
Training loss: 0.5956593751907349
Validation loss: 1.9606281717618306

Epoch: 6| Step: 12
Training loss: 0.809539258480072
Validation loss: 1.9340312083562214

Epoch: 6| Step: 13
Training loss: 0.5825503468513489
Validation loss: 1.9363070329030354

Epoch: 116| Step: 0
Training loss: 1.002793788909912
Validation loss: 1.9440052310625713

Epoch: 6| Step: 1
Training loss: 0.780319333076477
Validation loss: 1.9135983784993489

Epoch: 6| Step: 2
Training loss: 1.1014982461929321
Validation loss: 1.9112108945846558

Epoch: 6| Step: 3
Training loss: 0.9081624746322632
Validation loss: 1.9319126804669697

Epoch: 6| Step: 4
Training loss: 0.9988297820091248
Validation loss: 1.921888490517934

Epoch: 6| Step: 5
Training loss: 0.5607428550720215
Validation loss: 1.9589044253031414

Epoch: 6| Step: 6
Training loss: 0.7156221866607666
Validation loss: 1.9368985096613567

Epoch: 6| Step: 7
Training loss: 1.1472113132476807
Validation loss: 1.974078933397929

Epoch: 6| Step: 8
Training loss: 0.6686723232269287
Validation loss: 1.955056627591451

Epoch: 6| Step: 9
Training loss: 1.4592589139938354
Validation loss: 1.9310517311096191

Epoch: 6| Step: 10
Training loss: 0.6681519746780396
Validation loss: 1.9255856275558472

Epoch: 6| Step: 11
Training loss: 0.8105928897857666
Validation loss: 1.9374741911888123

Epoch: 6| Step: 12
Training loss: 0.8997985124588013
Validation loss: 1.9281054933865864

Epoch: 6| Step: 13
Training loss: 0.7158060669898987
Validation loss: 1.9654162923494976

Epoch: 117| Step: 0
Training loss: 0.6085653305053711
Validation loss: 1.9342774550120037

Epoch: 6| Step: 1
Training loss: 0.5347427129745483
Validation loss: 1.9103878736495972

Epoch: 6| Step: 2
Training loss: 1.0299228429794312
Validation loss: 1.9296464721361797

Epoch: 6| Step: 3
Training loss: 0.8511003255844116
Validation loss: 1.9477177659670513

Epoch: 6| Step: 4
Training loss: 0.9706053733825684
Validation loss: 1.9209582606951396

Epoch: 6| Step: 5
Training loss: 1.0850969552993774
Validation loss: 1.9353421131769817

Epoch: 6| Step: 6
Training loss: 0.7205122709274292
Validation loss: 1.985485017299652

Epoch: 6| Step: 7
Training loss: 0.6141462326049805
Validation loss: 1.936158577601115

Epoch: 6| Step: 8
Training loss: 0.8578914403915405
Validation loss: 1.9899173974990845

Epoch: 6| Step: 9
Training loss: 0.7566012144088745
Validation loss: 2.0000460545221963

Epoch: 6| Step: 10
Training loss: 0.9798924326896667
Validation loss: 1.9884081085522969

Epoch: 6| Step: 11
Training loss: 1.2039895057678223
Validation loss: 1.9480645954608917

Epoch: 6| Step: 12
Training loss: 1.0167161226272583
Validation loss: 1.9431272943814595

Epoch: 6| Step: 13
Training loss: 0.8793925046920776
Validation loss: 1.9458699822425842

Epoch: 118| Step: 0
Training loss: 0.531231164932251
Validation loss: 1.9481179118156433

Epoch: 6| Step: 1
Training loss: 0.8442740440368652
Validation loss: 1.9576409061749775

Epoch: 6| Step: 2
Training loss: 0.736770749092102
Validation loss: 1.970698853333791

Epoch: 6| Step: 3
Training loss: 1.184279441833496
Validation loss: 1.9966079592704773

Epoch: 6| Step: 4
Training loss: 1.1921807527542114
Validation loss: 1.9465627074241638

Epoch: 6| Step: 5
Training loss: 0.6019889712333679
Validation loss: 1.9391287763913472

Epoch: 6| Step: 6
Training loss: 1.101927399635315
Validation loss: 1.9330833355585735

Epoch: 6| Step: 7
Training loss: 0.9569092988967896
Validation loss: 1.9377877910931904

Epoch: 6| Step: 8
Training loss: 0.42229515314102173
Validation loss: 1.8991364041964214

Epoch: 6| Step: 9
Training loss: 0.7890397310256958
Validation loss: 1.9077494740486145

Epoch: 6| Step: 10
Training loss: 0.661828339099884
Validation loss: 1.9550113081932068

Epoch: 6| Step: 11
Training loss: 1.0405852794647217
Validation loss: 1.9709731340408325

Epoch: 6| Step: 12
Training loss: 1.1392903327941895
Validation loss: 1.982326825459798

Epoch: 6| Step: 13
Training loss: 1.0351685285568237
Validation loss: 1.9712287386258442

Epoch: 119| Step: 0
Training loss: 0.8522453308105469
Validation loss: 1.927966296672821

Epoch: 6| Step: 1
Training loss: 0.5445407629013062
Validation loss: 1.9722127517064412

Epoch: 6| Step: 2
Training loss: 0.5984742045402527
Validation loss: 1.9409460425376892

Epoch: 6| Step: 3
Training loss: 0.7215518355369568
Validation loss: 1.9561427632967632

Epoch: 6| Step: 4
Training loss: 1.250337839126587
Validation loss: 1.9937414526939392

Epoch: 6| Step: 5
Training loss: 0.9611921310424805
Validation loss: 1.9826924602190654

Epoch: 6| Step: 6
Training loss: 1.3955843448638916
Validation loss: 1.9932708342870076

Epoch: 6| Step: 7
Training loss: 1.1338410377502441
Validation loss: 1.9758994579315186

Epoch: 6| Step: 8
Training loss: 0.49338969588279724
Validation loss: 1.9186575611432393

Epoch: 6| Step: 9
Training loss: 0.8215302228927612
Validation loss: 1.981749991575877

Epoch: 6| Step: 10
Training loss: 0.564644455909729
Validation loss: 1.9249393939971924

Epoch: 6| Step: 11
Training loss: 0.5042621493339539
Validation loss: 1.950802981853485

Epoch: 6| Step: 12
Training loss: 1.22340726852417
Validation loss: 1.9481736620267232

Epoch: 6| Step: 13
Training loss: 0.6753559112548828
Validation loss: 1.9744146664937336

Epoch: 120| Step: 0
Training loss: 1.1147403717041016
Validation loss: 1.9848638375600178

Epoch: 6| Step: 1
Training loss: 0.553076982498169
Validation loss: 1.9923648834228516

Epoch: 6| Step: 2
Training loss: 1.3800454139709473
Validation loss: 1.999197820822398

Epoch: 6| Step: 3
Training loss: 0.7183539867401123
Validation loss: 1.9671485821406047

Epoch: 6| Step: 4
Training loss: 1.033474087715149
Validation loss: 1.9623688062032063

Epoch: 6| Step: 5
Training loss: 1.7038419246673584
Validation loss: 1.9895884195963542

Epoch: 6| Step: 6
Training loss: 0.5537915229797363
Validation loss: 1.9675320784250896

Epoch: 6| Step: 7
Training loss: 0.6023324728012085
Validation loss: 1.9575554132461548

Epoch: 6| Step: 8
Training loss: 0.5166473388671875
Validation loss: 1.9634023408095043

Epoch: 6| Step: 9
Training loss: 0.5305805206298828
Validation loss: 1.940746506055196

Epoch: 6| Step: 10
Training loss: 0.7273032665252686
Validation loss: 1.9765197038650513

Epoch: 6| Step: 11
Training loss: 0.5726118087768555
Validation loss: 1.9481344024340312

Epoch: 6| Step: 12
Training loss: 1.0200251340866089
Validation loss: 1.9669406811396282

Epoch: 6| Step: 13
Training loss: 0.7012714743614197
Validation loss: 1.9785661498705547

Epoch: 121| Step: 0
Training loss: 0.6781697273254395
Validation loss: 1.9521851738293965

Epoch: 6| Step: 1
Training loss: 0.6663966774940491
Validation loss: 1.9607450763384502

Epoch: 6| Step: 2
Training loss: 0.5845077633857727
Validation loss: 1.9371421933174133

Epoch: 6| Step: 3
Training loss: 0.7606016397476196
Validation loss: 1.9157169659932454

Epoch: 6| Step: 4
Training loss: 0.857006311416626
Validation loss: 1.958962122599284

Epoch: 6| Step: 5
Training loss: 0.5413349866867065
Validation loss: 1.9678494930267334

Epoch: 6| Step: 6
Training loss: 0.9363799691200256
Validation loss: 1.9380610982577007

Epoch: 6| Step: 7
Training loss: 0.6110315322875977
Validation loss: 1.9526482025782268

Epoch: 6| Step: 8
Training loss: 1.2945644855499268
Validation loss: 1.981802761554718

Epoch: 6| Step: 9
Training loss: 1.2555737495422363
Validation loss: 1.955073595046997

Epoch: 6| Step: 10
Training loss: 0.5829317569732666
Validation loss: 1.9442898233731587

Epoch: 6| Step: 11
Training loss: 1.055848479270935
Validation loss: 1.9835931460062664

Epoch: 6| Step: 12
Training loss: 1.047683835029602
Validation loss: 1.9130988121032715

Epoch: 6| Step: 13
Training loss: 0.7056934833526611
Validation loss: 1.9676711161931355

Epoch: 122| Step: 0
Training loss: 0.8736475706100464
Validation loss: 1.9805738131205242

Epoch: 6| Step: 1
Training loss: 1.085824728012085
Validation loss: 1.96926611661911

Epoch: 6| Step: 2
Training loss: 0.6298691630363464
Validation loss: 1.986830751101176

Epoch: 6| Step: 3
Training loss: 0.6893019080162048
Validation loss: 1.9189298748970032

Epoch: 6| Step: 4
Training loss: 0.9386342763900757
Validation loss: 1.9412871996561687

Epoch: 6| Step: 5
Training loss: 1.1317574977874756
Validation loss: 2.0156593322753906

Epoch: 6| Step: 6
Training loss: 1.0544832944869995
Validation loss: 2.0304194688796997

Epoch: 6| Step: 7
Training loss: 1.5337245464324951
Validation loss: 2.005544900894165

Epoch: 6| Step: 8
Training loss: 0.7498174905776978
Validation loss: 1.9786893526713054

Epoch: 6| Step: 9
Training loss: 0.8567299246788025
Validation loss: 1.9581134517987568

Epoch: 6| Step: 10
Training loss: 0.7632235884666443
Validation loss: 1.95538063844045

Epoch: 6| Step: 11
Training loss: 1.24994695186615
Validation loss: 1.9772835771242778

Epoch: 6| Step: 12
Training loss: 0.9664736390113831
Validation loss: 2.069131056467692

Epoch: 6| Step: 13
Training loss: 1.0450735092163086
Validation loss: 2.0217198729515076

Epoch: 123| Step: 0
Training loss: 1.0749998092651367
Validation loss: 1.9807251493136089

Epoch: 6| Step: 1
Training loss: 0.5633289813995361
Validation loss: 1.9680119752883911

Epoch: 6| Step: 2
Training loss: 0.696147620677948
Validation loss: 1.9719474911689758

Epoch: 6| Step: 3
Training loss: 0.9315621852874756
Validation loss: 1.9824784994125366

Epoch: 6| Step: 4
Training loss: 0.6995283365249634
Validation loss: 1.9585466186205547

Epoch: 6| Step: 5
Training loss: 0.9329071640968323
Validation loss: 1.9693554441134136

Epoch: 6| Step: 6
Training loss: 1.071400761604309
Validation loss: 1.993808627128601

Epoch: 6| Step: 7
Training loss: 1.222043514251709
Validation loss: 1.9747613072395325

Epoch: 6| Step: 8
Training loss: 1.2659506797790527
Validation loss: 1.9756775101025899

Epoch: 6| Step: 9
Training loss: 0.7262325286865234
Validation loss: 1.958524505297343

Epoch: 6| Step: 10
Training loss: 0.6742956638336182
Validation loss: 1.9721949696540833

Epoch: 6| Step: 11
Training loss: 1.2624036073684692
Validation loss: 1.9122519691785176

Epoch: 6| Step: 12
Training loss: 0.5353546142578125
Validation loss: 1.8982081214586894

Epoch: 6| Step: 13
Training loss: 0.7406964898109436
Validation loss: 1.9136559963226318

Epoch: 124| Step: 0
Training loss: 0.9440286159515381
Validation loss: 1.9156941572825115

Epoch: 6| Step: 1
Training loss: 0.9802559018135071
Validation loss: 1.9295055270195007

Epoch: 6| Step: 2
Training loss: 1.3240442276000977
Validation loss: 1.9439581831296284

Epoch: 6| Step: 3
Training loss: 1.6513681411743164
Validation loss: 1.9398141105969746

Epoch: 6| Step: 4
Training loss: 0.49825119972229004
Validation loss: 1.9070565303166707

Epoch: 6| Step: 5
Training loss: 0.4807637333869934
Validation loss: 1.9217341939608257

Epoch: 6| Step: 6
Training loss: 0.6605415940284729
Validation loss: 1.8988982439041138

Epoch: 6| Step: 7
Training loss: 0.6856718063354492
Validation loss: 1.9081570903460185

Epoch: 6| Step: 8
Training loss: 0.7425628900527954
Validation loss: 1.90082581837972

Epoch: 6| Step: 9
Training loss: 0.45050930976867676
Validation loss: 1.922652006149292

Epoch: 6| Step: 10
Training loss: 0.440855473279953
Validation loss: 1.9255691369374592

Epoch: 6| Step: 11
Training loss: 1.1803741455078125
Validation loss: 1.9146465063095093

Epoch: 6| Step: 12
Training loss: 0.8861769437789917
Validation loss: 1.9404941002527873

Epoch: 6| Step: 13
Training loss: 0.4375693202018738
Validation loss: 1.942474325497945

Epoch: 125| Step: 0
Training loss: 0.7523273825645447
Validation loss: 1.938504974047343

Epoch: 6| Step: 1
Training loss: 0.8841884732246399
Validation loss: 1.9123900334040325

Epoch: 6| Step: 2
Training loss: 0.8522544503211975
Validation loss: 1.9395039280255635

Epoch: 6| Step: 3
Training loss: 0.4508882462978363
Validation loss: 1.9542855223019917

Epoch: 6| Step: 4
Training loss: 0.45023807883262634
Validation loss: 1.9481502572695415

Epoch: 6| Step: 5
Training loss: 0.8792524337768555
Validation loss: 1.9523633321126301

Epoch: 6| Step: 6
Training loss: 0.886442244052887
Validation loss: 1.966402490933736

Epoch: 6| Step: 7
Training loss: 1.041235327720642
Validation loss: 1.933782418568929

Epoch: 6| Step: 8
Training loss: 0.7199475765228271
Validation loss: 1.9526811838150024

Epoch: 6| Step: 9
Training loss: 0.5497075319290161
Validation loss: 1.9789404670397441

Epoch: 6| Step: 10
Training loss: 1.1679584980010986
Validation loss: 1.9959198037783306

Epoch: 6| Step: 11
Training loss: 0.5595980882644653
Validation loss: 2.015802244345347

Epoch: 6| Step: 12
Training loss: 1.173151969909668
Validation loss: 2.005170524120331

Epoch: 6| Step: 13
Training loss: 0.8883854150772095
Validation loss: 1.9785733620325725

Epoch: 126| Step: 0
Training loss: 0.7623724937438965
Validation loss: 1.9564541776974995

Epoch: 6| Step: 1
Training loss: 1.1004102230072021
Validation loss: 1.9654958844184875

Epoch: 6| Step: 2
Training loss: 1.0710731744766235
Validation loss: 1.9510029753049214

Epoch: 6| Step: 3
Training loss: 0.6973909735679626
Validation loss: 1.983005166053772

Epoch: 6| Step: 4
Training loss: 0.6882275342941284
Validation loss: 1.955652932325999

Epoch: 6| Step: 5
Training loss: 0.4333520531654358
Validation loss: 1.9290555119514465

Epoch: 6| Step: 6
Training loss: 1.0103821754455566
Validation loss: 1.9820690751075745

Epoch: 6| Step: 7
Training loss: 1.0021573305130005
Validation loss: 1.9423480033874512

Epoch: 6| Step: 8
Training loss: 0.5909129977226257
Validation loss: 1.9441067973772685

Epoch: 6| Step: 9
Training loss: 0.49755412340164185
Validation loss: 1.9676375985145569

Epoch: 6| Step: 10
Training loss: 1.0155754089355469
Validation loss: 1.9381111065546672

Epoch: 6| Step: 11
Training loss: 0.573776125907898
Validation loss: 1.958902935187022

Epoch: 6| Step: 12
Training loss: 1.250294804573059
Validation loss: 1.93120676279068

Epoch: 6| Step: 13
Training loss: 0.6252111196517944
Validation loss: 1.9693723718325298

Epoch: 127| Step: 0
Training loss: 1.2032390832901
Validation loss: 1.9259735345840454

Epoch: 6| Step: 1
Training loss: 0.5249617099761963
Validation loss: 1.916667103767395

Epoch: 6| Step: 2
Training loss: 0.4783616065979004
Validation loss: 1.9408543109893799

Epoch: 6| Step: 3
Training loss: 0.5037412643432617
Validation loss: 1.9256529410680134

Epoch: 6| Step: 4
Training loss: 1.0434672832489014
Validation loss: 1.9557145635286968

Epoch: 6| Step: 5
Training loss: 1.1704879999160767
Validation loss: 1.930430273214976

Epoch: 6| Step: 6
Training loss: 0.587645411491394
Validation loss: 1.9582280317942302

Epoch: 6| Step: 7
Training loss: 0.7754493355751038
Validation loss: 1.9728339314460754

Epoch: 6| Step: 8
Training loss: 0.5977965593338013
Validation loss: 1.9728659788767497

Epoch: 6| Step: 9
Training loss: 0.9378594756126404
Validation loss: 2.01878821849823

Epoch: 6| Step: 10
Training loss: 0.8430254459381104
Validation loss: 1.9817443490028381

Epoch: 6| Step: 11
Training loss: 0.9116485714912415
Validation loss: 1.9626427292823792

Epoch: 6| Step: 12
Training loss: 0.9460130929946899
Validation loss: 1.9794524312019348

Epoch: 6| Step: 13
Training loss: 0.8026431798934937
Validation loss: 1.9862987796465557

Epoch: 128| Step: 0
Training loss: 0.8023161292076111
Validation loss: 2.0492968956629434

Epoch: 6| Step: 1
Training loss: 0.8968080878257751
Validation loss: 2.0267048676808677

Epoch: 6| Step: 2
Training loss: 1.4071130752563477
Validation loss: 2.0013618071873984

Epoch: 6| Step: 3
Training loss: 0.6604669690132141
Validation loss: 2.0132498741149902

Epoch: 6| Step: 4
Training loss: 1.030610203742981
Validation loss: 1.958673894405365

Epoch: 6| Step: 5
Training loss: 1.0323011875152588
Validation loss: 2.033102730909983

Epoch: 6| Step: 6
Training loss: 1.178831934928894
Validation loss: 2.0410310427347818

Epoch: 6| Step: 7
Training loss: 0.8862122297286987
Validation loss: 2.068487564722697

Epoch: 6| Step: 8
Training loss: 0.6575325727462769
Validation loss: 2.0233781933784485

Epoch: 6| Step: 9
Training loss: 0.23380614817142487
Validation loss: 1.9744975765546162

Epoch: 6| Step: 10
Training loss: 0.8459358215332031
Validation loss: 1.9534637729326885

Epoch: 6| Step: 11
Training loss: 1.1923165321350098
Validation loss: 1.9498414198557537

Epoch: 6| Step: 12
Training loss: 0.9755422472953796
Validation loss: 1.927152156829834

Epoch: 6| Step: 13
Training loss: 0.8724087476730347
Validation loss: 1.9638417760531108

Epoch: 129| Step: 0
Training loss: 0.5899343490600586
Validation loss: 1.9331426620483398

Epoch: 6| Step: 1
Training loss: 0.7051945924758911
Validation loss: 1.9496210018793743

Epoch: 6| Step: 2
Training loss: 0.7915090918540955
Validation loss: 1.9345978299776714

Epoch: 6| Step: 3
Training loss: 0.9959617257118225
Validation loss: 1.9802576899528503

Epoch: 6| Step: 4
Training loss: 1.0018057823181152
Validation loss: 1.9317304094632466

Epoch: 6| Step: 5
Training loss: 0.757382869720459
Validation loss: 1.9552234411239624

Epoch: 6| Step: 6
Training loss: 0.843269407749176
Validation loss: 1.9608253041903179

Epoch: 6| Step: 7
Training loss: 1.3722124099731445
Validation loss: 1.9279091755549114

Epoch: 6| Step: 8
Training loss: 0.8936275243759155
Validation loss: 1.9731300075848897

Epoch: 6| Step: 9
Training loss: 0.6672589182853699
Validation loss: 1.9310172994931538

Epoch: 6| Step: 10
Training loss: 1.1222760677337646
Validation loss: 1.9572555422782898

Epoch: 6| Step: 11
Training loss: 0.27945563197135925
Validation loss: 1.9797005852063496

Epoch: 6| Step: 12
Training loss: 0.460568904876709
Validation loss: 1.9424097736676533

Epoch: 6| Step: 13
Training loss: 0.4823618531227112
Validation loss: 1.981945514678955

Epoch: 130| Step: 0
Training loss: 0.774291455745697
Validation loss: 1.9549324711163838

Epoch: 6| Step: 1
Training loss: 0.6970147490501404
Validation loss: 1.9759700695673625

Epoch: 6| Step: 2
Training loss: 0.8963302373886108
Validation loss: 2.009708285331726

Epoch: 6| Step: 3
Training loss: 0.8319389820098877
Validation loss: 1.9894649585088093

Epoch: 6| Step: 4
Training loss: 0.42798757553100586
Validation loss: 1.948737621307373

Epoch: 6| Step: 5
Training loss: 0.8460217118263245
Validation loss: 1.949697474638621

Epoch: 6| Step: 6
Training loss: 0.8367323279380798
Validation loss: 1.9646686712900798

Epoch: 6| Step: 7
Training loss: 0.6042574048042297
Validation loss: 1.9659383296966553

Epoch: 6| Step: 8
Training loss: 0.9341185092926025
Validation loss: 1.9438946843147278

Epoch: 6| Step: 9
Training loss: 0.5648190379142761
Validation loss: 1.9952601393063862

Epoch: 6| Step: 10
Training loss: 0.5767943859100342
Validation loss: 2.011763075987498

Epoch: 6| Step: 11
Training loss: 0.7478516101837158
Validation loss: 1.9924717545509338

Epoch: 6| Step: 12
Training loss: 1.636551856994629
Validation loss: 1.9636650284131367

Epoch: 6| Step: 13
Training loss: 0.604719877243042
Validation loss: 1.9662804802258809

Epoch: 131| Step: 0
Training loss: 0.6679883599281311
Validation loss: 1.9499922394752502

Epoch: 6| Step: 1
Training loss: 0.7941434383392334
Validation loss: 1.9511696100234985

Epoch: 6| Step: 2
Training loss: 1.0348267555236816
Validation loss: 1.9689550797144573

Epoch: 6| Step: 3
Training loss: 0.8467217683792114
Validation loss: 1.9518121878306072

Epoch: 6| Step: 4
Training loss: 0.44352471828460693
Validation loss: 1.9565054376920064

Epoch: 6| Step: 5
Training loss: 0.8029659986495972
Validation loss: 1.9911361734072368

Epoch: 6| Step: 6
Training loss: 0.808910071849823
Validation loss: 1.9654664595921834

Epoch: 6| Step: 7
Training loss: 0.5371542572975159
Validation loss: 1.9706548651059468

Epoch: 6| Step: 8
Training loss: 0.7108354568481445
Validation loss: 1.9602797826131184

Epoch: 6| Step: 9
Training loss: 0.47937914729118347
Validation loss: 1.9685663382212322

Epoch: 6| Step: 10
Training loss: 0.704256534576416
Validation loss: 1.9632132450739543

Epoch: 6| Step: 11
Training loss: 1.0195541381835938
Validation loss: 1.9345446626345317

Epoch: 6| Step: 12
Training loss: 0.7574038505554199
Validation loss: 1.9142653544743855

Epoch: 6| Step: 13
Training loss: 1.1393334865570068
Validation loss: 1.973998447259267

Epoch: 132| Step: 0
Training loss: 0.5250481963157654
Validation loss: 1.945952832698822

Epoch: 6| Step: 1
Training loss: 0.7698333263397217
Validation loss: 1.9778206944465637

Epoch: 6| Step: 2
Training loss: 1.213052749633789
Validation loss: 1.9971375266710918

Epoch: 6| Step: 3
Training loss: 0.8223035335540771
Validation loss: 1.9646070996920268

Epoch: 6| Step: 4
Training loss: 0.5600519180297852
Validation loss: 1.9683578213055928

Epoch: 6| Step: 5
Training loss: 1.15225088596344
Validation loss: 1.9838809967041016

Epoch: 6| Step: 6
Training loss: 1.0036206245422363
Validation loss: 1.9681719541549683

Epoch: 6| Step: 7
Training loss: 0.46536314487457275
Validation loss: 1.9689049919446309

Epoch: 6| Step: 8
Training loss: 0.7133065462112427
Validation loss: 1.9473206798235576

Epoch: 6| Step: 9
Training loss: 0.6397252082824707
Validation loss: 1.9811648925145466

Epoch: 6| Step: 10
Training loss: 1.172413945198059
Validation loss: 2.003441413243612

Epoch: 6| Step: 11
Training loss: 0.5927281379699707
Validation loss: 1.9711497624715169

Epoch: 6| Step: 12
Training loss: 0.5974305868148804
Validation loss: 1.9969435930252075

Epoch: 6| Step: 13
Training loss: 0.4661429226398468
Validation loss: 1.9879941741625469

Epoch: 133| Step: 0
Training loss: 0.6275393962860107
Validation loss: 1.9716935356458027

Epoch: 6| Step: 1
Training loss: 0.4368249177932739
Validation loss: 1.9981802304585774

Epoch: 6| Step: 2
Training loss: 0.4391368329524994
Validation loss: 1.981011648972829

Epoch: 6| Step: 3
Training loss: 1.8729166984558105
Validation loss: 2.0177528460820517

Epoch: 6| Step: 4
Training loss: 1.0384559631347656
Validation loss: 1.9773475925127666

Epoch: 6| Step: 5
Training loss: 1.1848015785217285
Validation loss: 1.9980733394622803

Epoch: 6| Step: 6
Training loss: 0.5490425825119019
Validation loss: 1.9844779173533122

Epoch: 6| Step: 7
Training loss: 0.3446318507194519
Validation loss: 1.9743110537528992

Epoch: 6| Step: 8
Training loss: 0.29744887351989746
Validation loss: 1.9957157174746196

Epoch: 6| Step: 9
Training loss: 0.9610140919685364
Validation loss: 1.917328457037608

Epoch: 6| Step: 10
Training loss: 0.59160315990448
Validation loss: 1.9537124633789062

Epoch: 6| Step: 11
Training loss: 0.8230853080749512
Validation loss: 1.9549253582954407

Epoch: 6| Step: 12
Training loss: 0.6175334453582764
Validation loss: 1.9514154990514119

Epoch: 6| Step: 13
Training loss: 0.8690268993377686
Validation loss: 1.930994689464569

Epoch: 134| Step: 0
Training loss: 0.6729427576065063
Validation loss: 1.9265925486882527

Epoch: 6| Step: 1
Training loss: 0.8413926362991333
Validation loss: 1.9580880403518677

Epoch: 6| Step: 2
Training loss: 0.8322337865829468
Validation loss: 1.965049386024475

Epoch: 6| Step: 3
Training loss: 0.6684997081756592
Validation loss: 1.961682875951131

Epoch: 6| Step: 4
Training loss: 0.5987089276313782
Validation loss: 1.9177177548408508

Epoch: 6| Step: 5
Training loss: 0.7315350770950317
Validation loss: 2.0074485540390015

Epoch: 6| Step: 6
Training loss: 0.7339645624160767
Validation loss: 2.0193625489870706

Epoch: 6| Step: 7
Training loss: 1.0867483615875244
Validation loss: 2.0175886948903403

Epoch: 6| Step: 8
Training loss: 1.4544544219970703
Validation loss: 1.996625264485677

Epoch: 6| Step: 9
Training loss: 0.8920283317565918
Validation loss: 1.950018088022868

Epoch: 6| Step: 10
Training loss: 0.46435773372650146
Validation loss: 1.9761297901471455

Epoch: 6| Step: 11
Training loss: 0.7733684778213501
Validation loss: 1.9716340899467468

Epoch: 6| Step: 12
Training loss: 0.8357076644897461
Validation loss: 1.9892638127009075

Epoch: 6| Step: 13
Training loss: 0.94544517993927
Validation loss: 1.9618861079216003

Epoch: 135| Step: 0
Training loss: 0.897291898727417
Validation loss: 1.9774354696273804

Epoch: 6| Step: 1
Training loss: 0.517941951751709
Validation loss: 1.9929278294245403

Epoch: 6| Step: 2
Training loss: 0.7847495079040527
Validation loss: 2.037480572859446

Epoch: 6| Step: 3
Training loss: 0.993021547794342
Validation loss: 2.06384668747584

Epoch: 6| Step: 4
Training loss: 0.6473333835601807
Validation loss: 2.01414293050766

Epoch: 6| Step: 5
Training loss: 0.8626282215118408
Validation loss: 1.9772365093231201

Epoch: 6| Step: 6
Training loss: 0.8312963247299194
Validation loss: 1.9874472220738728

Epoch: 6| Step: 7
Training loss: 0.9669114947319031
Validation loss: 1.960921843846639

Epoch: 6| Step: 8
Training loss: 0.7862921953201294
Validation loss: 1.9567852814992268

Epoch: 6| Step: 9
Training loss: 0.34306278824806213
Validation loss: 1.9823601643244426

Epoch: 6| Step: 10
Training loss: 0.7905020713806152
Validation loss: 1.9988749027252197

Epoch: 6| Step: 11
Training loss: 1.0594737529754639
Validation loss: 2.001921455065409

Epoch: 6| Step: 12
Training loss: 0.5545706152915955
Validation loss: 2.0107732812563577

Epoch: 6| Step: 13
Training loss: 0.8607096672058105
Validation loss: 2.007317284742991

Epoch: 136| Step: 0
Training loss: 1.1798968315124512
Validation loss: 1.9992438554763794

Epoch: 6| Step: 1
Training loss: 0.83056640625
Validation loss: 1.993043581644694

Epoch: 6| Step: 2
Training loss: 1.2549254894256592
Validation loss: 1.9760006467501323

Epoch: 6| Step: 3
Training loss: 0.608432948589325
Validation loss: 2.006715714931488

Epoch: 6| Step: 4
Training loss: 0.839068591594696
Validation loss: 2.0077642798423767

Epoch: 6| Step: 5
Training loss: 0.42026132345199585
Validation loss: 1.9643574953079224

Epoch: 6| Step: 6
Training loss: 0.626764178276062
Validation loss: 1.9858577251434326

Epoch: 6| Step: 7
Training loss: 0.7131748199462891
Validation loss: 1.9970559477806091

Epoch: 6| Step: 8
Training loss: 0.94227135181427
Validation loss: 1.963199496269226

Epoch: 6| Step: 9
Training loss: 0.3564385175704956
Validation loss: 1.9418854713439941

Epoch: 6| Step: 10
Training loss: 0.4144948124885559
Validation loss: 1.9629944562911987

Epoch: 6| Step: 11
Training loss: 1.0750036239624023
Validation loss: 1.9568661451339722

Epoch: 6| Step: 12
Training loss: 1.0774861574172974
Validation loss: 1.9708394010861714

Epoch: 6| Step: 13
Training loss: 0.5372858643531799
Validation loss: 1.9503915111223857

Epoch: 137| Step: 0
Training loss: 0.6396844983100891
Validation loss: 1.9266491333643596

Epoch: 6| Step: 1
Training loss: 0.9218447804450989
Validation loss: 1.985840082168579

Epoch: 6| Step: 2
Training loss: 0.7913590669631958
Validation loss: 2.046613852183024

Epoch: 6| Step: 3
Training loss: 1.0302386283874512
Validation loss: 2.0223899682362876

Epoch: 6| Step: 4
Training loss: 0.5238603353500366
Validation loss: 1.968810796737671

Epoch: 6| Step: 5
Training loss: 0.7063388824462891
Validation loss: 1.956959863503774

Epoch: 6| Step: 6
Training loss: 1.0534577369689941
Validation loss: 1.9710410634676616

Epoch: 6| Step: 7
Training loss: 0.6572428941726685
Validation loss: 1.9340086976687114

Epoch: 6| Step: 8
Training loss: 0.4569486677646637
Validation loss: 1.9179392059644063

Epoch: 6| Step: 9
Training loss: 0.7043107748031616
Validation loss: 1.971760133902232

Epoch: 6| Step: 10
Training loss: 0.8515730500221252
Validation loss: 1.9923402468363445

Epoch: 6| Step: 11
Training loss: 1.0409376621246338
Validation loss: 2.0071372787157693

Epoch: 6| Step: 12
Training loss: 0.8069268465042114
Validation loss: 2.0109193523724875

Epoch: 6| Step: 13
Training loss: 0.7617231607437134
Validation loss: 2.0266594092051187

Epoch: 138| Step: 0
Training loss: 0.4318208396434784
Validation loss: 1.9727396368980408

Epoch: 6| Step: 1
Training loss: 0.34997284412384033
Validation loss: 1.962465524673462

Epoch: 6| Step: 2
Training loss: 0.5672812461853027
Validation loss: 1.9131086468696594

Epoch: 6| Step: 3
Training loss: 1.019133448600769
Validation loss: 1.970085124174754

Epoch: 6| Step: 4
Training loss: 0.8451757431030273
Validation loss: 1.9551103711128235

Epoch: 6| Step: 5
Training loss: 0.793739914894104
Validation loss: 1.9527857502301533

Epoch: 6| Step: 6
Training loss: 0.5019170045852661
Validation loss: 1.9431358178456624

Epoch: 6| Step: 7
Training loss: 0.6888805031776428
Validation loss: 1.9941380222638447

Epoch: 6| Step: 8
Training loss: 1.0170947313308716
Validation loss: 2.000999093055725

Epoch: 6| Step: 9
Training loss: 1.183143973350525
Validation loss: 1.9946256875991821

Epoch: 6| Step: 10
Training loss: 0.8829575777053833
Validation loss: 1.9748641848564148

Epoch: 6| Step: 11
Training loss: 0.7274649739265442
Validation loss: 1.9734057784080505

Epoch: 6| Step: 12
Training loss: 0.90211021900177
Validation loss: 1.955653687318166

Epoch: 6| Step: 13
Training loss: 0.6280695199966431
Validation loss: 1.967067023118337

Epoch: 139| Step: 0
Training loss: 0.6132150888442993
Validation loss: 1.9538085063298543

Epoch: 6| Step: 1
Training loss: 0.5686513185501099
Validation loss: 1.9332698782285054

Epoch: 6| Step: 2
Training loss: 0.47227299213409424
Validation loss: 1.9351328214009602

Epoch: 6| Step: 3
Training loss: 0.8837999105453491
Validation loss: 1.983066737651825

Epoch: 6| Step: 4
Training loss: 0.461991548538208
Validation loss: 2.0271643002827964

Epoch: 6| Step: 5
Training loss: 0.8289155960083008
Validation loss: 1.928249756495158

Epoch: 6| Step: 6
Training loss: 0.8339812755584717
Validation loss: 1.9350031812985737

Epoch: 6| Step: 7
Training loss: 0.39340972900390625
Validation loss: 1.9504515926043193

Epoch: 6| Step: 8
Training loss: 0.794255256652832
Validation loss: 1.926528513431549

Epoch: 6| Step: 9
Training loss: 0.8757768869400024
Validation loss: 1.922741452852885

Epoch: 6| Step: 10
Training loss: 0.6927353143692017
Validation loss: 1.940619985262553

Epoch: 6| Step: 11
Training loss: 0.7812426090240479
Validation loss: 1.9671585361162822

Epoch: 6| Step: 12
Training loss: 0.8003959655761719
Validation loss: 1.9618088404337566

Epoch: 6| Step: 13
Training loss: 0.5697748064994812
Validation loss: 1.947667082150777

Epoch: 140| Step: 0
Training loss: 0.5633664131164551
Validation loss: 1.9664839108784993

Epoch: 6| Step: 1
Training loss: 0.6168211698532104
Validation loss: 1.946936349074046

Epoch: 6| Step: 2
Training loss: 0.6282839775085449
Validation loss: 1.942210078239441

Epoch: 6| Step: 3
Training loss: 0.5475190281867981
Validation loss: 1.9484575390815735

Epoch: 6| Step: 4
Training loss: 0.4008122384548187
Validation loss: 1.9354718327522278

Epoch: 6| Step: 5
Training loss: 1.4437530040740967
Validation loss: 1.9535509745279949

Epoch: 6| Step: 6
Training loss: 0.3891593813896179
Validation loss: 1.9678235054016113

Epoch: 6| Step: 7
Training loss: 0.3917790651321411
Validation loss: 1.991533875465393

Epoch: 6| Step: 8
Training loss: 0.9866067171096802
Validation loss: 1.9764562646547954

Epoch: 6| Step: 9
Training loss: 0.8982015252113342
Validation loss: 1.960268755753835

Epoch: 6| Step: 10
Training loss: 0.33014458417892456
Validation loss: 1.968635102113088

Epoch: 6| Step: 11
Training loss: 0.6555375456809998
Validation loss: 1.9941024780273438

Epoch: 6| Step: 12
Training loss: 1.0003769397735596
Validation loss: 1.993062714735667

Epoch: 6| Step: 13
Training loss: 0.8539208173751831
Validation loss: 1.9861848751703899

Epoch: 141| Step: 0
Training loss: 0.8170590400695801
Validation loss: 2.0005340774854026

Epoch: 6| Step: 1
Training loss: 1.0083715915679932
Validation loss: 1.9960300922393799

Epoch: 6| Step: 2
Training loss: 0.6232897043228149
Validation loss: 2.0170386036237082

Epoch: 6| Step: 3
Training loss: 0.6907920837402344
Validation loss: 1.9887531598409016

Epoch: 6| Step: 4
Training loss: 0.5072048306465149
Validation loss: 1.999412477016449

Epoch: 6| Step: 5
Training loss: 0.5905110836029053
Validation loss: 1.9782925049463909

Epoch: 6| Step: 6
Training loss: 0.9928976893424988
Validation loss: 1.9708814024925232

Epoch: 6| Step: 7
Training loss: 0.2967670261859894
Validation loss: 1.9470447699228923

Epoch: 6| Step: 8
Training loss: 0.8548001646995544
Validation loss: 1.9441663026809692

Epoch: 6| Step: 9
Training loss: 0.48760178685188293
Validation loss: 1.9685264627138774

Epoch: 6| Step: 10
Training loss: 0.9756025075912476
Validation loss: 1.950975199540456

Epoch: 6| Step: 11
Training loss: 0.5328016877174377
Validation loss: 1.977701981862386

Epoch: 6| Step: 12
Training loss: 0.7283778190612793
Validation loss: 1.9796821077664692

Epoch: 6| Step: 13
Training loss: 0.7251203060150146
Validation loss: 1.9567389488220215

Epoch: 142| Step: 0
Training loss: 0.5341325998306274
Validation loss: 1.931087036927541

Epoch: 6| Step: 1
Training loss: 0.8713982701301575
Validation loss: 1.905275046825409

Epoch: 6| Step: 2
Training loss: 0.3848627805709839
Validation loss: 1.9407143195470173

Epoch: 6| Step: 3
Training loss: 0.25675708055496216
Validation loss: 1.922886888186137

Epoch: 6| Step: 4
Training loss: 0.6347113847732544
Validation loss: 1.9604710936546326

Epoch: 6| Step: 5
Training loss: 0.9913650155067444
Validation loss: 2.015282611052195

Epoch: 6| Step: 6
Training loss: 0.910277783870697
Validation loss: 1.9882153471310933

Epoch: 6| Step: 7
Training loss: 0.7119763493537903
Validation loss: 1.961950918038686

Epoch: 6| Step: 8
Training loss: 0.561126172542572
Validation loss: 1.951570709546407

Epoch: 6| Step: 9
Training loss: 0.8545493483543396
Validation loss: 1.9440048933029175

Epoch: 6| Step: 10
Training loss: 1.2688852548599243
Validation loss: 1.9686334530512493

Epoch: 6| Step: 11
Training loss: 0.7187991142272949
Validation loss: 1.9867788751920064

Epoch: 6| Step: 12
Training loss: 0.47325435280799866
Validation loss: 1.959457000096639

Epoch: 6| Step: 13
Training loss: 0.8293477296829224
Validation loss: 1.962797462940216

Epoch: 143| Step: 0
Training loss: 0.6994117498397827
Validation loss: 1.9577566385269165

Epoch: 6| Step: 1
Training loss: 1.0218466520309448
Validation loss: 2.007518450419108

Epoch: 6| Step: 2
Training loss: 0.8134472370147705
Validation loss: 1.974370042483012

Epoch: 6| Step: 3
Training loss: 0.9017658233642578
Validation loss: 1.9285215536753337

Epoch: 6| Step: 4
Training loss: 0.550732433795929
Validation loss: 1.9242729743321736

Epoch: 6| Step: 5
Training loss: 1.0008397102355957
Validation loss: 1.9471906026204426

Epoch: 6| Step: 6
Training loss: 0.793387234210968
Validation loss: 1.9378541906674702

Epoch: 6| Step: 7
Training loss: 0.5738084316253662
Validation loss: 1.9343834519386292

Epoch: 6| Step: 8
Training loss: 0.8640538454055786
Validation loss: 1.9033515652020772

Epoch: 6| Step: 9
Training loss: 0.3762582838535309
Validation loss: 1.9241761962572734

Epoch: 6| Step: 10
Training loss: 0.5201524496078491
Validation loss: 1.8743582169214885

Epoch: 6| Step: 11
Training loss: 0.3958558142185211
Validation loss: 1.8838174144426982

Epoch: 6| Step: 12
Training loss: 0.7368780970573425
Validation loss: 1.9420334100723267

Epoch: 6| Step: 13
Training loss: 0.4808926284313202
Validation loss: 1.9192052880922954

Epoch: 144| Step: 0
Training loss: 0.7077770233154297
Validation loss: 1.9011416832605998

Epoch: 6| Step: 1
Training loss: 1.1929683685302734
Validation loss: 1.9124039212862651

Epoch: 6| Step: 2
Training loss: 1.0008561611175537
Validation loss: 1.9319069186846416

Epoch: 6| Step: 3
Training loss: 0.989337682723999
Validation loss: 1.9653570453325908

Epoch: 6| Step: 4
Training loss: 0.6167976260185242
Validation loss: 1.9259037772814434

Epoch: 6| Step: 5
Training loss: 0.9896660447120667
Validation loss: 1.947393000125885

Epoch: 6| Step: 6
Training loss: 0.320678174495697
Validation loss: 1.9565425117810566

Epoch: 6| Step: 7
Training loss: 0.732022762298584
Validation loss: 1.9441523949305217

Epoch: 6| Step: 8
Training loss: 0.24485774338245392
Validation loss: 1.9860007961591084

Epoch: 6| Step: 9
Training loss: 0.5810230374336243
Validation loss: 1.966138740380605

Epoch: 6| Step: 10
Training loss: 0.619199275970459
Validation loss: 1.915478785832723

Epoch: 6| Step: 11
Training loss: 0.5486297607421875
Validation loss: 1.940495530764262

Epoch: 6| Step: 12
Training loss: 0.41200578212738037
Validation loss: 1.905048906803131

Epoch: 6| Step: 13
Training loss: 0.34464651346206665
Validation loss: 1.9434828758239746

Epoch: 145| Step: 0
Training loss: 0.9064908027648926
Validation loss: 1.9661555687586467

Epoch: 6| Step: 1
Training loss: 0.7343717813491821
Validation loss: 1.9416743318239849

Epoch: 6| Step: 2
Training loss: 0.6639413237571716
Validation loss: 1.9230022231737773

Epoch: 6| Step: 3
Training loss: 0.9374477863311768
Validation loss: 1.9605040351549785

Epoch: 6| Step: 4
Training loss: 0.6985479593276978
Validation loss: 1.9848928451538086

Epoch: 6| Step: 5
Training loss: 1.0943917036056519
Validation loss: 1.9923984011014302

Epoch: 6| Step: 6
Training loss: 0.8068398833274841
Validation loss: 1.995879590511322

Epoch: 6| Step: 7
Training loss: 0.7889140844345093
Validation loss: 2.0446536540985107

Epoch: 6| Step: 8
Training loss: 0.6419827938079834
Validation loss: 2.000461518764496

Epoch: 6| Step: 9
Training loss: 0.48757028579711914
Validation loss: 1.9816901882489522

Epoch: 6| Step: 10
Training loss: 0.5220848917961121
Validation loss: 1.9840874870618184

Epoch: 6| Step: 11
Training loss: 0.5792404413223267
Validation loss: 1.9869623184204102

Epoch: 6| Step: 12
Training loss: 0.21146157383918762
Validation loss: 1.9770591457684834

Epoch: 6| Step: 13
Training loss: 0.4209294319152832
Validation loss: 1.9942499001820881

Epoch: 146| Step: 0
Training loss: 0.6084061861038208
Validation loss: 2.0227419336636863

Epoch: 6| Step: 1
Training loss: 0.5267641544342041
Validation loss: 2.032289286454519

Epoch: 6| Step: 2
Training loss: 0.8580836653709412
Validation loss: 2.00991427898407

Epoch: 6| Step: 3
Training loss: 0.524652898311615
Validation loss: 1.9560959736506145

Epoch: 6| Step: 4
Training loss: 0.731526255607605
Validation loss: 1.9512144724527996

Epoch: 6| Step: 5
Training loss: 1.0314754247665405
Validation loss: 1.9163389801979065

Epoch: 6| Step: 6
Training loss: 0.8051241636276245
Validation loss: 1.9297778606414795

Epoch: 6| Step: 7
Training loss: 1.1880018711090088
Validation loss: 1.9170029163360596

Epoch: 6| Step: 8
Training loss: 0.8347969055175781
Validation loss: 1.92904394865036

Epoch: 6| Step: 9
Training loss: 0.390222430229187
Validation loss: 1.9025353988011677

Epoch: 6| Step: 10
Training loss: 0.5251657366752625
Validation loss: 1.9744563698768616

Epoch: 6| Step: 11
Training loss: 0.33623912930488586
Validation loss: 1.9646556576093037

Epoch: 6| Step: 12
Training loss: 0.5379927158355713
Validation loss: 1.9325576623280842

Epoch: 6| Step: 13
Training loss: 0.4674036502838135
Validation loss: 1.9359322985013325

Epoch: 147| Step: 0
Training loss: 0.6310656666755676
Validation loss: 1.944011390209198

Epoch: 6| Step: 1
Training loss: 0.42763006687164307
Validation loss: 1.9279803832372029

Epoch: 6| Step: 2
Training loss: 0.4595920741558075
Validation loss: 1.937803030014038

Epoch: 6| Step: 3
Training loss: 0.9571902751922607
Validation loss: 1.9569693207740784

Epoch: 6| Step: 4
Training loss: 0.7428459525108337
Validation loss: 1.9910794695218403

Epoch: 6| Step: 5
Training loss: 0.5438846349716187
Validation loss: 1.96021701892217

Epoch: 6| Step: 6
Training loss: 1.1461310386657715
Validation loss: 1.9886247913042705

Epoch: 6| Step: 7
Training loss: 0.41062015295028687
Validation loss: 1.9408868948618572

Epoch: 6| Step: 8
Training loss: 1.0008642673492432
Validation loss: 1.9344764550526936

Epoch: 6| Step: 9
Training loss: 0.5734596848487854
Validation loss: 1.9903343717257183

Epoch: 6| Step: 10
Training loss: 1.3413887023925781
Validation loss: 1.9389301935831706

Epoch: 6| Step: 11
Training loss: 0.3242412507534027
Validation loss: 1.9573045372962952

Epoch: 6| Step: 12
Training loss: 0.3557559549808502
Validation loss: 1.9687763849894206

Epoch: 6| Step: 13
Training loss: 0.6622056365013123
Validation loss: 1.975824197133382

Epoch: 148| Step: 0
Training loss: 0.8724410533905029
Validation loss: 1.9522619843482971

Epoch: 6| Step: 1
Training loss: 0.8659361600875854
Validation loss: 1.9491331577301025

Epoch: 6| Step: 2
Training loss: 0.41325610876083374
Validation loss: 1.922885000705719

Epoch: 6| Step: 3
Training loss: 0.4160965085029602
Validation loss: 1.9528589646021526

Epoch: 6| Step: 4
Training loss: 0.2904367446899414
Validation loss: 1.9709085424741108

Epoch: 6| Step: 5
Training loss: 0.6724200248718262
Validation loss: 1.9477301438649495

Epoch: 6| Step: 6
Training loss: 0.854731559753418
Validation loss: 1.959592382113139

Epoch: 6| Step: 7
Training loss: 0.5877212285995483
Validation loss: 1.9616206487019856

Epoch: 6| Step: 8
Training loss: 0.9640508890151978
Validation loss: 1.9478946924209595

Epoch: 6| Step: 9
Training loss: 0.779512882232666
Validation loss: 1.9513797958691914

Epoch: 6| Step: 10
Training loss: 0.6260284781455994
Validation loss: 1.9751864473025005

Epoch: 6| Step: 11
Training loss: 0.6912422180175781
Validation loss: 1.9863219062487285

Epoch: 6| Step: 12
Training loss: 0.6256101727485657
Validation loss: 1.9701027274131775

Epoch: 6| Step: 13
Training loss: 0.674243688583374
Validation loss: 2.0122087796529136

Epoch: 149| Step: 0
Training loss: 0.7455905675888062
Validation loss: 2.025442818800608

Epoch: 6| Step: 1
Training loss: 0.7029029130935669
Validation loss: 2.0144022901852927

Epoch: 6| Step: 2
Training loss: 0.6584731340408325
Validation loss: 1.9693444172541301

Epoch: 6| Step: 3
Training loss: 0.8258642554283142
Validation loss: 1.9546436071395874

Epoch: 6| Step: 4
Training loss: 0.8216964602470398
Validation loss: 1.9747438232103984

Epoch: 6| Step: 5
Training loss: 0.347995400428772
Validation loss: 1.9380506873130798

Epoch: 6| Step: 6
Training loss: 0.7904071807861328
Validation loss: 1.9222254951794941

Epoch: 6| Step: 7
Training loss: 0.23647429049015045
Validation loss: 1.929619312286377

Epoch: 6| Step: 8
Training loss: 0.4337170720100403
Validation loss: 1.96791277329127

Epoch: 6| Step: 9
Training loss: 0.7604018449783325
Validation loss: 1.9692252079645793

Epoch: 6| Step: 10
Training loss: 0.7068151831626892
Validation loss: 1.9326217770576477

Epoch: 6| Step: 11
Training loss: 0.4655054211616516
Validation loss: 1.9308034976323445

Epoch: 6| Step: 12
Training loss: 1.40129816532135
Validation loss: 1.9163018067677815

Epoch: 6| Step: 13
Training loss: 0.5690701007843018
Validation loss: 1.9216053287188213

Epoch: 150| Step: 0
Training loss: 0.4850017726421356
Validation loss: 1.9195308089256287

Epoch: 6| Step: 1
Training loss: 0.9446886777877808
Validation loss: 1.9181753993034363

Epoch: 6| Step: 2
Training loss: 0.45401573181152344
Validation loss: 1.926843563715617

Epoch: 6| Step: 3
Training loss: 0.6785616278648376
Validation loss: 1.9247798522313435

Epoch: 6| Step: 4
Training loss: 0.4476688802242279
Validation loss: 1.9322084585825603

Epoch: 6| Step: 5
Training loss: 0.5786648392677307
Validation loss: 1.9651793440183003

Epoch: 6| Step: 6
Training loss: 0.2256428450345993
Validation loss: 1.9178345203399658

Epoch: 6| Step: 7
Training loss: 0.5848713517189026
Validation loss: 1.9523334105809529

Epoch: 6| Step: 8
Training loss: 0.9643919467926025
Validation loss: 1.955340564250946

Epoch: 6| Step: 9
Training loss: 0.8902451395988464
Validation loss: 1.9537630478541057

Epoch: 6| Step: 10
Training loss: 0.8754397630691528
Validation loss: 1.9193898836771648

Epoch: 6| Step: 11
Training loss: 0.4523107409477234
Validation loss: 1.9465135137240093

Epoch: 6| Step: 12
Training loss: 0.5333119630813599
Validation loss: 1.9448212186495464

Epoch: 6| Step: 13
Training loss: 0.43220001459121704
Validation loss: 1.9604321519533794

Epoch: 151| Step: 0
Training loss: 0.40669962763786316
Validation loss: 1.940182904402415

Epoch: 6| Step: 1
Training loss: 0.8360787630081177
Validation loss: 1.9268749157587688

Epoch: 6| Step: 2
Training loss: 0.5276154279708862
Validation loss: 1.932331661383311

Epoch: 6| Step: 3
Training loss: 0.4996175169944763
Validation loss: 1.9878437121709187

Epoch: 6| Step: 4
Training loss: 0.6905670762062073
Validation loss: 1.9979846080144246

Epoch: 6| Step: 5
Training loss: 1.0422857999801636
Validation loss: 1.9611422419548035

Epoch: 6| Step: 6
Training loss: 0.21850384771823883
Validation loss: 1.9817518989245098

Epoch: 6| Step: 7
Training loss: 0.6748719811439514
Validation loss: 1.9384516874949138

Epoch: 6| Step: 8
Training loss: 0.6569432020187378
Validation loss: 1.9375647107760112

Epoch: 6| Step: 9
Training loss: 0.8668580055236816
Validation loss: 1.9655078450838726

Epoch: 6| Step: 10
Training loss: 0.4006427824497223
Validation loss: 1.953931450843811

Epoch: 6| Step: 11
Training loss: 0.8755208253860474
Validation loss: 1.9459845821062725

Epoch: 6| Step: 12
Training loss: 0.4696316719055176
Validation loss: 1.972500483194987

Epoch: 6| Step: 13
Training loss: 1.0037834644317627
Validation loss: 1.9739219148953755

Epoch: 152| Step: 0
Training loss: 0.5421102046966553
Validation loss: 1.9356610973676045

Epoch: 6| Step: 1
Training loss: 0.5732139348983765
Validation loss: 1.9366646806399028

Epoch: 6| Step: 2
Training loss: 0.37571412324905396
Validation loss: 1.950545330842336

Epoch: 6| Step: 3
Training loss: 0.5001323223114014
Validation loss: 1.9660518169403076

Epoch: 6| Step: 4
Training loss: 0.786780834197998
Validation loss: 1.9519532521565754

Epoch: 6| Step: 5
Training loss: 0.7332467436790466
Validation loss: 1.9725903669993083

Epoch: 6| Step: 6
Training loss: 0.5296786427497864
Validation loss: 2.001272141933441

Epoch: 6| Step: 7
Training loss: 0.6327675580978394
Validation loss: 2.0271500945091248

Epoch: 6| Step: 8
Training loss: 1.4718883037567139
Validation loss: 1.9759366313616435

Epoch: 6| Step: 9
Training loss: 0.3559328615665436
Validation loss: 1.9902917345364888

Epoch: 6| Step: 10
Training loss: 0.719436764717102
Validation loss: 1.969626506169637

Epoch: 6| Step: 11
Training loss: 0.5101561546325684
Validation loss: 1.992674708366394

Epoch: 6| Step: 12
Training loss: 1.1138173341751099
Validation loss: 1.9911101460456848

Epoch: 6| Step: 13
Training loss: 0.412796288728714
Validation loss: 1.9753466844558716

Epoch: 153| Step: 0
Training loss: 1.011340856552124
Validation loss: 2.0121684869130454

Epoch: 6| Step: 1
Training loss: 0.7403171062469482
Validation loss: 2.0070907870928445

Epoch: 6| Step: 2
Training loss: 0.8165761232376099
Validation loss: 2.0347264210383096

Epoch: 6| Step: 3
Training loss: 0.7221797704696655
Validation loss: 1.9854424198468525

Epoch: 6| Step: 4
Training loss: 0.7488484978675842
Validation loss: 1.9811065991719563

Epoch: 6| Step: 5
Training loss: 0.5031609535217285
Validation loss: 1.9919618566830952

Epoch: 6| Step: 6
Training loss: 0.4056920111179352
Validation loss: 1.9930488268534343

Epoch: 6| Step: 7
Training loss: 0.5890872478485107
Validation loss: 1.9521769881248474

Epoch: 6| Step: 8
Training loss: 0.936140775680542
Validation loss: 1.9774459997812908

Epoch: 6| Step: 9
Training loss: 0.44048887491226196
Validation loss: 1.9556927680969238

Epoch: 6| Step: 10
Training loss: 0.6657668948173523
Validation loss: 1.9620969891548157

Epoch: 6| Step: 11
Training loss: 0.6785537004470825
Validation loss: 1.9675585826237996

Epoch: 6| Step: 12
Training loss: 0.42699483036994934
Validation loss: 1.923779010772705

Epoch: 6| Step: 13
Training loss: 0.3095656633377075
Validation loss: 1.946246345837911

Epoch: 154| Step: 0
Training loss: 0.8372755646705627
Validation loss: 1.9503354827562969

Epoch: 6| Step: 1
Training loss: 0.7021044492721558
Validation loss: 1.9116851687431335

Epoch: 6| Step: 2
Training loss: 0.45721736550331116
Validation loss: 1.9239358107248943

Epoch: 6| Step: 3
Training loss: 0.2749687135219574
Validation loss: 1.9408161441485088

Epoch: 6| Step: 4
Training loss: 0.9965920448303223
Validation loss: 1.9654805064201355

Epoch: 6| Step: 5
Training loss: 1.1545416116714478
Validation loss: 1.957254985968272

Epoch: 6| Step: 6
Training loss: 0.40596070885658264
Validation loss: 1.9503447810808818

Epoch: 6| Step: 7
Training loss: 0.8976882696151733
Validation loss: 1.9438560009002686

Epoch: 6| Step: 8
Training loss: 0.5048454999923706
Validation loss: 1.9380244016647339

Epoch: 6| Step: 9
Training loss: 0.6732702851295471
Validation loss: 1.9450853268305461

Epoch: 6| Step: 10
Training loss: 0.6345614790916443
Validation loss: 1.9776710271835327

Epoch: 6| Step: 11
Training loss: 0.8564492464065552
Validation loss: 1.9691295425097148

Epoch: 6| Step: 12
Training loss: 0.7104488611221313
Validation loss: 1.9507525364557903

Epoch: 6| Step: 13
Training loss: 0.28456470370292664
Validation loss: 1.9564806620279949

Epoch: 155| Step: 0
Training loss: 0.5769578814506531
Validation loss: 1.9752172032992046

Epoch: 6| Step: 1
Training loss: 0.769333004951477
Validation loss: 2.0205054680506387

Epoch: 6| Step: 2
Training loss: 0.7658928036689758
Validation loss: 1.964167336622874

Epoch: 6| Step: 3
Training loss: 0.6360195875167847
Validation loss: 1.962729016939799

Epoch: 6| Step: 4
Training loss: 0.5996389389038086
Validation loss: 1.9660106499989827

Epoch: 6| Step: 5
Training loss: 0.8276054263114929
Validation loss: 1.9458486437797546

Epoch: 6| Step: 6
Training loss: 0.6081148386001587
Validation loss: 1.9436746040980022

Epoch: 6| Step: 7
Training loss: 0.626789391040802
Validation loss: 1.972850779692332

Epoch: 6| Step: 8
Training loss: 0.6082338094711304
Validation loss: 1.9777796069780986

Epoch: 6| Step: 9
Training loss: 0.8203012943267822
Validation loss: 2.0188827315966287

Epoch: 6| Step: 10
Training loss: 0.5136504769325256
Validation loss: 1.992584228515625

Epoch: 6| Step: 11
Training loss: 0.5958349704742432
Validation loss: 1.994102954864502

Epoch: 6| Step: 12
Training loss: 0.9269726872444153
Validation loss: 1.9966885646184285

Epoch: 6| Step: 13
Training loss: 0.8758138418197632
Validation loss: 1.9384854237238567

Epoch: 156| Step: 0
Training loss: 0.8806419372558594
Validation loss: 1.9344838658968608

Epoch: 6| Step: 1
Training loss: 0.9168269634246826
Validation loss: 1.9963244199752808

Epoch: 6| Step: 2
Training loss: 0.46038055419921875
Validation loss: 1.9462587038675945

Epoch: 6| Step: 3
Training loss: 1.1865042448043823
Validation loss: 1.9833829005559285

Epoch: 6| Step: 4
Training loss: 0.41061967611312866
Validation loss: 1.9763808846473694

Epoch: 6| Step: 5
Training loss: 0.7319308519363403
Validation loss: 1.9818302591641743

Epoch: 6| Step: 6
Training loss: 0.2851337790489197
Validation loss: 1.972102443377177

Epoch: 6| Step: 7
Training loss: 0.5755664110183716
Validation loss: 1.9937066435813904

Epoch: 6| Step: 8
Training loss: 0.43697378039360046
Validation loss: 1.9634073774019878

Epoch: 6| Step: 9
Training loss: 0.48257070779800415
Validation loss: 1.9817088445027669

Epoch: 6| Step: 10
Training loss: 0.878156304359436
Validation loss: 1.9157663186391194

Epoch: 6| Step: 11
Training loss: 0.29045265913009644
Validation loss: 1.9716955025990803

Epoch: 6| Step: 12
Training loss: 0.5968925952911377
Validation loss: 1.9262073238690693

Epoch: 6| Step: 13
Training loss: 0.65505051612854
Validation loss: 1.930734932422638

Epoch: 157| Step: 0
Training loss: 0.4348564147949219
Validation loss: 1.9525692065556843

Epoch: 6| Step: 1
Training loss: 1.1256847381591797
Validation loss: 1.9491191506385803

Epoch: 6| Step: 2
Training loss: 0.3531993329524994
Validation loss: 1.9585252205530803

Epoch: 6| Step: 3
Training loss: 0.3954766094684601
Validation loss: 1.9975374142328899

Epoch: 6| Step: 4
Training loss: 0.41135647892951965
Validation loss: 1.9656119147936504

Epoch: 6| Step: 5
Training loss: 1.4038217067718506
Validation loss: 1.9407259821891785

Epoch: 6| Step: 6
Training loss: 0.7278394103050232
Validation loss: 1.9162362416585286

Epoch: 6| Step: 7
Training loss: 0.6476960182189941
Validation loss: 1.922484298547109

Epoch: 6| Step: 8
Training loss: 0.2885977625846863
Validation loss: 1.9538741906483967

Epoch: 6| Step: 9
Training loss: 0.506777822971344
Validation loss: 1.9246176679929097

Epoch: 6| Step: 10
Training loss: 0.6176786422729492
Validation loss: 1.939205567042033

Epoch: 6| Step: 11
Training loss: 0.47761446237564087
Validation loss: 1.944621245066325

Epoch: 6| Step: 12
Training loss: 0.846348226070404
Validation loss: 1.9158729314804077

Epoch: 6| Step: 13
Training loss: 0.7507197856903076
Validation loss: 1.9167978564898174

Epoch: 158| Step: 0
Training loss: 0.6626278162002563
Validation loss: 1.9226072629292805

Epoch: 6| Step: 1
Training loss: 0.26607000827789307
Validation loss: 1.961587945620219

Epoch: 6| Step: 2
Training loss: 0.4440332055091858
Validation loss: 1.9483198126157124

Epoch: 6| Step: 3
Training loss: 1.1986663341522217
Validation loss: 1.9223496516545613

Epoch: 6| Step: 4
Training loss: 0.2988690435886383
Validation loss: 1.9581701556841533

Epoch: 6| Step: 5
Training loss: 0.7065120935440063
Validation loss: 1.9059377908706665

Epoch: 6| Step: 6
Training loss: 0.3464518189430237
Validation loss: 1.9218969345092773

Epoch: 6| Step: 7
Training loss: 0.4450712203979492
Validation loss: 1.9574022094408672

Epoch: 6| Step: 8
Training loss: 0.7192118167877197
Validation loss: 1.9059343338012695

Epoch: 6| Step: 9
Training loss: 0.8345669507980347
Validation loss: 1.9475442171096802

Epoch: 6| Step: 10
Training loss: 0.7066583633422852
Validation loss: 1.940685550371806

Epoch: 6| Step: 11
Training loss: 0.3871215581893921
Validation loss: 1.959057092666626

Epoch: 6| Step: 12
Training loss: 0.4374457597732544
Validation loss: 1.9651885628700256

Epoch: 6| Step: 13
Training loss: 0.9713810086250305
Validation loss: 1.9852450887362163

Epoch: 159| Step: 0
Training loss: 1.2658950090408325
Validation loss: 1.9899361729621887

Epoch: 6| Step: 1
Training loss: 0.8201413154602051
Validation loss: 1.9393487373987834

Epoch: 6| Step: 2
Training loss: 0.617676854133606
Validation loss: 1.9553263783454895

Epoch: 6| Step: 3
Training loss: 0.6584833264350891
Validation loss: 1.950161059697469

Epoch: 6| Step: 4
Training loss: 0.2733534574508667
Validation loss: 1.9311804970105488

Epoch: 6| Step: 5
Training loss: 0.40679997205734253
Validation loss: 1.986948589483897

Epoch: 6| Step: 6
Training loss: 0.4737280607223511
Validation loss: 1.933396339416504

Epoch: 6| Step: 7
Training loss: 0.734351634979248
Validation loss: 1.9675132234891255

Epoch: 6| Step: 8
Training loss: 0.8499716520309448
Validation loss: 1.9801712830861409

Epoch: 6| Step: 9
Training loss: 0.5367043018341064
Validation loss: 1.9596579869588215

Epoch: 6| Step: 10
Training loss: 0.9112164974212646
Validation loss: 1.984818458557129

Epoch: 6| Step: 11
Training loss: 0.5713873505592346
Validation loss: 1.944216787815094

Epoch: 6| Step: 12
Training loss: 0.3704597055912018
Validation loss: 1.941442886988322

Epoch: 6| Step: 13
Training loss: 0.36717313528060913
Validation loss: 1.9466562469800313

Epoch: 160| Step: 0
Training loss: 0.5159233808517456
Validation loss: 2.0019911726315818

Epoch: 6| Step: 1
Training loss: 0.7950725555419922
Validation loss: 2.022072752316793

Epoch: 6| Step: 2
Training loss: 0.7396366000175476
Validation loss: 1.9570943514506023

Epoch: 6| Step: 3
Training loss: 0.4762536585330963
Validation loss: 2.025282005469004

Epoch: 6| Step: 4
Training loss: 0.8589736223220825
Validation loss: 2.0175487200419107

Epoch: 6| Step: 5
Training loss: 0.6564903855323792
Validation loss: 2.006399850050608

Epoch: 6| Step: 6
Training loss: 0.722710371017456
Validation loss: 1.925018072128296

Epoch: 6| Step: 7
Training loss: 0.4276278018951416
Validation loss: 1.9924862782160442

Epoch: 6| Step: 8
Training loss: 0.5002095699310303
Validation loss: 1.9684896071751912

Epoch: 6| Step: 9
Training loss: 0.2478804737329483
Validation loss: 1.9431339502334595

Epoch: 6| Step: 10
Training loss: 1.0844810009002686
Validation loss: 1.9635570247968037

Epoch: 6| Step: 11
Training loss: 0.5746252536773682
Validation loss: 1.9814757307370503

Epoch: 6| Step: 12
Training loss: 0.453043133020401
Validation loss: 1.9775935610135396

Epoch: 6| Step: 13
Training loss: 0.5706033706665039
Validation loss: 1.9567546447118123

Epoch: 161| Step: 0
Training loss: 0.3035067915916443
Validation loss: 1.9226667284965515

Epoch: 6| Step: 1
Training loss: 0.8144834637641907
Validation loss: 1.9285257657368977

Epoch: 6| Step: 2
Training loss: 0.5193360447883606
Validation loss: 1.9285546739896138

Epoch: 6| Step: 3
Training loss: 0.34170377254486084
Validation loss: 1.9050986766815186

Epoch: 6| Step: 4
Training loss: 0.807968020439148
Validation loss: 1.9548129240671794

Epoch: 6| Step: 5
Training loss: 0.7207400798797607
Validation loss: 1.9885900020599365

Epoch: 6| Step: 6
Training loss: 0.799985408782959
Validation loss: 1.9884885152180989

Epoch: 6| Step: 7
Training loss: 0.899895429611206
Validation loss: 1.951469322045644

Epoch: 6| Step: 8
Training loss: 0.5787199139595032
Validation loss: 1.9339212973912556

Epoch: 6| Step: 9
Training loss: 0.5243632793426514
Validation loss: 1.9683338205019634

Epoch: 6| Step: 10
Training loss: 0.6922279596328735
Validation loss: 1.9502901236216228

Epoch: 6| Step: 11
Training loss: 0.25273096561431885
Validation loss: 1.9473973711331685

Epoch: 6| Step: 12
Training loss: 0.698464035987854
Validation loss: 1.9618121981620789

Epoch: 6| Step: 13
Training loss: 0.8254275918006897
Validation loss: 1.9917484720547993

Epoch: 162| Step: 0
Training loss: 0.7092189788818359
Validation loss: 1.9902987877527873

Epoch: 6| Step: 1
Training loss: 0.44976377487182617
Validation loss: 1.9676444232463837

Epoch: 6| Step: 2
Training loss: 0.7534745931625366
Validation loss: 1.9796104033788045

Epoch: 6| Step: 3
Training loss: 0.6256802678108215
Validation loss: 1.9736900329589844

Epoch: 6| Step: 4
Training loss: 0.8261792659759521
Validation loss: 1.9867482781410217

Epoch: 6| Step: 5
Training loss: 0.9361123442649841
Validation loss: 1.9784843722979228

Epoch: 6| Step: 6
Training loss: 0.4270218014717102
Validation loss: 1.9697766304016113

Epoch: 6| Step: 7
Training loss: 0.3432352542877197
Validation loss: 2.000063419342041

Epoch: 6| Step: 8
Training loss: 0.5373228788375854
Validation loss: 2.011889159679413

Epoch: 6| Step: 9
Training loss: 0.5118458271026611
Validation loss: 2.002838969230652

Epoch: 6| Step: 10
Training loss: 0.6699374318122864
Validation loss: 2.021284560362498

Epoch: 6| Step: 11
Training loss: 0.8069911599159241
Validation loss: 1.9777490297953289

Epoch: 6| Step: 12
Training loss: 1.1483250856399536
Validation loss: 1.9964827299118042

Epoch: 6| Step: 13
Training loss: 0.19283229112625122
Validation loss: 1.983030875523885

Epoch: 163| Step: 0
Training loss: 0.5825495719909668
Validation loss: 1.9768672386805217

Epoch: 6| Step: 1
Training loss: 1.0049278736114502
Validation loss: 1.9853886763254802

Epoch: 6| Step: 2
Training loss: 0.3699423372745514
Validation loss: 1.962117870648702

Epoch: 6| Step: 3
Training loss: 0.9315305948257446
Validation loss: 1.9787777463595073

Epoch: 6| Step: 4
Training loss: 0.7039792537689209
Validation loss: 1.9568729797999065

Epoch: 6| Step: 5
Training loss: 0.6621225476264954
Validation loss: 1.9395325183868408

Epoch: 6| Step: 6
Training loss: 0.5386776328086853
Validation loss: 1.9319307406743367

Epoch: 6| Step: 7
Training loss: 0.3726045489311218
Validation loss: 1.949090600013733

Epoch: 6| Step: 8
Training loss: 0.5171622633934021
Validation loss: 1.9606587489446003

Epoch: 6| Step: 9
Training loss: 0.6130192279815674
Validation loss: 1.9359822869300842

Epoch: 6| Step: 10
Training loss: 0.5235676765441895
Validation loss: 1.9602250059445698

Epoch: 6| Step: 11
Training loss: 0.5916339159011841
Validation loss: 1.9518224000930786

Epoch: 6| Step: 12
Training loss: 0.7499890327453613
Validation loss: 1.951446294784546

Epoch: 6| Step: 13
Training loss: 0.3419782519340515
Validation loss: 1.9486027558644612

Epoch: 164| Step: 0
Training loss: 0.46772855520248413
Validation loss: 1.9421147108078003

Epoch: 6| Step: 1
Training loss: 0.5794519186019897
Validation loss: 1.962870995203654

Epoch: 6| Step: 2
Training loss: 0.6003770232200623
Validation loss: 1.9606451193491619

Epoch: 6| Step: 3
Training loss: 0.5929700136184692
Validation loss: 1.9604506889979045

Epoch: 6| Step: 4
Training loss: 0.6429163217544556
Validation loss: 1.9489926099777222

Epoch: 6| Step: 5
Training loss: 0.5591358542442322
Validation loss: 1.9754937887191772

Epoch: 6| Step: 6
Training loss: 0.5221101641654968
Validation loss: 1.9850526452064514

Epoch: 6| Step: 7
Training loss: 0.5759363174438477
Validation loss: 1.9596962134043376

Epoch: 6| Step: 8
Training loss: 0.2379121482372284
Validation loss: 1.9551611344019573

Epoch: 6| Step: 9
Training loss: 0.5935579538345337
Validation loss: 1.9052441914876301

Epoch: 6| Step: 10
Training loss: 0.7220799326896667
Validation loss: 1.9299213886260986

Epoch: 6| Step: 11
Training loss: 0.9607624411582947
Validation loss: 1.9316389759381611

Epoch: 6| Step: 12
Training loss: 0.5046783685684204
Validation loss: 1.945314387480418

Epoch: 6| Step: 13
Training loss: 0.33300602436065674
Validation loss: 1.9471331636110942

Epoch: 165| Step: 0
Training loss: 0.9578653573989868
Validation loss: 1.9303555488586426

Epoch: 6| Step: 1
Training loss: 1.0209404230117798
Validation loss: 1.927372932434082

Epoch: 6| Step: 2
Training loss: 0.39056676626205444
Validation loss: 1.9575341939926147

Epoch: 6| Step: 3
Training loss: 0.3706255555152893
Validation loss: 1.9203828970591228

Epoch: 6| Step: 4
Training loss: 0.3187774419784546
Validation loss: 1.9443201224009197

Epoch: 6| Step: 5
Training loss: 0.35043323040008545
Validation loss: 1.9408942063649495

Epoch: 6| Step: 6
Training loss: 0.4241122007369995
Validation loss: 1.9289912382761638

Epoch: 6| Step: 7
Training loss: 0.6161072254180908
Validation loss: 1.952636977036794

Epoch: 6| Step: 8
Training loss: 0.7081001996994019
Validation loss: 1.9343583583831787

Epoch: 6| Step: 9
Training loss: 0.2318926304578781
Validation loss: 1.9318782289822896

Epoch: 6| Step: 10
Training loss: 0.8664014339447021
Validation loss: 1.9503963589668274

Epoch: 6| Step: 11
Training loss: 0.5665634870529175
Validation loss: 1.9496886332829793

Epoch: 6| Step: 12
Training loss: 1.194521188735962
Validation loss: 2.0097103118896484

Epoch: 6| Step: 13
Training loss: 0.47162434458732605
Validation loss: 2.021312336126963

Epoch: 166| Step: 0
Training loss: 1.0064821243286133
Validation loss: 1.9531232317288716

Epoch: 6| Step: 1
Training loss: 0.4962782859802246
Validation loss: 2.0051777561505637

Epoch: 6| Step: 2
Training loss: 0.5925973653793335
Validation loss: 1.9929712017377217

Epoch: 6| Step: 3
Training loss: 0.4467870891094208
Validation loss: 2.0074109633763633

Epoch: 6| Step: 4
Training loss: 0.4703882336616516
Validation loss: 1.98347806930542

Epoch: 6| Step: 5
Training loss: 0.5177228450775146
Validation loss: 2.040043811003367

Epoch: 6| Step: 6
Training loss: 0.6728397607803345
Validation loss: 2.004533330599467

Epoch: 6| Step: 7
Training loss: 0.6839965581893921
Validation loss: 2.0095198353131614

Epoch: 6| Step: 8
Training loss: 0.5198211669921875
Validation loss: 1.9777497053146362

Epoch: 6| Step: 9
Training loss: 0.37506452202796936
Validation loss: 2.0043683846791587

Epoch: 6| Step: 10
Training loss: 0.4337356686592102
Validation loss: 2.012661576271057

Epoch: 6| Step: 11
Training loss: 0.944862425327301
Validation loss: 2.0096245408058167

Epoch: 6| Step: 12
Training loss: 0.6872963309288025
Validation loss: 1.9891176025072734

Epoch: 6| Step: 13
Training loss: 0.2144010066986084
Validation loss: 1.9821315308411915

Epoch: 167| Step: 0
Training loss: 0.338358074426651
Validation loss: 1.984982152779897

Epoch: 6| Step: 1
Training loss: 0.6034985780715942
Validation loss: 2.0056420167287192

Epoch: 6| Step: 2
Training loss: 0.19673879444599152
Validation loss: 1.9677380720774333

Epoch: 6| Step: 3
Training loss: 0.9056606292724609
Validation loss: 1.9814149339993794

Epoch: 6| Step: 4
Training loss: 0.7394218444824219
Validation loss: 1.9701083302497864

Epoch: 6| Step: 5
Training loss: 0.44786331057548523
Validation loss: 1.960720996061961

Epoch: 6| Step: 6
Training loss: 0.6834752559661865
Validation loss: 1.9207168221473694

Epoch: 6| Step: 7
Training loss: 0.4139658808708191
Validation loss: 1.970090389251709

Epoch: 6| Step: 8
Training loss: 0.7385118007659912
Validation loss: 1.9841364026069641

Epoch: 6| Step: 9
Training loss: 0.5795526504516602
Validation loss: 1.96416970094045

Epoch: 6| Step: 10
Training loss: 0.5179241895675659
Validation loss: 1.9466927647590637

Epoch: 6| Step: 11
Training loss: 0.6706323623657227
Validation loss: 1.9438774585723877

Epoch: 6| Step: 12
Training loss: 0.8514717817306519
Validation loss: 1.9388155341148376

Epoch: 6| Step: 13
Training loss: 0.6052227020263672
Validation loss: 1.9505633314450581

Epoch: 168| Step: 0
Training loss: 0.38919931650161743
Validation loss: 1.9368553757667542

Epoch: 6| Step: 1
Training loss: 0.8445460796356201
Validation loss: 1.993727684020996

Epoch: 6| Step: 2
Training loss: 1.0504205226898193
Validation loss: 1.9574838678042095

Epoch: 6| Step: 3
Training loss: 0.543159544467926
Validation loss: 1.9770693977673848

Epoch: 6| Step: 4
Training loss: 0.32855626940727234
Validation loss: 1.9625123937924702

Epoch: 6| Step: 5
Training loss: 0.2725752592086792
Validation loss: 1.9761693477630615

Epoch: 6| Step: 6
Training loss: 0.23101478815078735
Validation loss: 1.9494394461313884

Epoch: 6| Step: 7
Training loss: 0.649502158164978
Validation loss: 1.9733505845069885

Epoch: 6| Step: 8
Training loss: 0.5779231190681458
Validation loss: 1.985210915406545

Epoch: 6| Step: 9
Training loss: 0.7394273281097412
Validation loss: 1.938325862089793

Epoch: 6| Step: 10
Training loss: 0.8044586181640625
Validation loss: 2.00217612584432

Epoch: 6| Step: 11
Training loss: 0.4165804088115692
Validation loss: 1.9615824222564697

Epoch: 6| Step: 12
Training loss: 0.4885329604148865
Validation loss: 1.945132891337077

Epoch: 6| Step: 13
Training loss: 0.42505383491516113
Validation loss: 1.9532076319058735

Epoch: 169| Step: 0
Training loss: 0.3332306146621704
Validation loss: 1.9412140846252441

Epoch: 6| Step: 1
Training loss: 0.7023351192474365
Validation loss: 1.941535214583079

Epoch: 6| Step: 2
Training loss: 0.4697916507720947
Validation loss: 1.9175507227579753

Epoch: 6| Step: 3
Training loss: 0.41985341906547546
Validation loss: 1.9229120810826619

Epoch: 6| Step: 4
Training loss: 0.7046817541122437
Validation loss: 1.9506131807963054

Epoch: 6| Step: 5
Training loss: 0.4832232594490051
Validation loss: 2.009628633658091

Epoch: 6| Step: 6
Training loss: 0.588411271572113
Validation loss: 1.9537765582402546

Epoch: 6| Step: 7
Training loss: 0.5085344910621643
Validation loss: 1.9632340868314107

Epoch: 6| Step: 8
Training loss: 0.5396036505699158
Validation loss: 1.9952356417973836

Epoch: 6| Step: 9
Training loss: 0.6668540835380554
Validation loss: 1.961401343345642

Epoch: 6| Step: 10
Training loss: 0.33836182951927185
Validation loss: 1.9326221744219463

Epoch: 6| Step: 11
Training loss: 0.7300848364830017
Validation loss: 1.9621780117352803

Epoch: 6| Step: 12
Training loss: 1.2415111064910889
Validation loss: 1.9417239824930828

Epoch: 6| Step: 13
Training loss: 0.7495622038841248
Validation loss: 1.9324562549591064

Epoch: 170| Step: 0
Training loss: 0.3030569553375244
Validation loss: 1.92071932554245

Epoch: 6| Step: 1
Training loss: 0.857654869556427
Validation loss: 1.9427254994710286

Epoch: 6| Step: 2
Training loss: 0.8210533857345581
Validation loss: 1.9416446487108867

Epoch: 6| Step: 3
Training loss: 0.40332460403442383
Validation loss: 1.9294663270314534

Epoch: 6| Step: 4
Training loss: 0.5399281978607178
Validation loss: 1.9604862531026204

Epoch: 6| Step: 5
Training loss: 0.4068329334259033
Validation loss: 1.9803082942962646

Epoch: 6| Step: 6
Training loss: 0.8276169300079346
Validation loss: 1.96187025308609

Epoch: 6| Step: 7
Training loss: 0.6078056693077087
Validation loss: 1.9523420333862305

Epoch: 6| Step: 8
Training loss: 0.9021140336990356
Validation loss: 1.9438267350196838

Epoch: 6| Step: 9
Training loss: 0.5233185887336731
Validation loss: 1.9638577302296956

Epoch: 6| Step: 10
Training loss: 0.41579070687294006
Validation loss: 1.943960189819336

Epoch: 6| Step: 11
Training loss: 0.39445608854293823
Validation loss: 1.9106106758117676

Epoch: 6| Step: 12
Training loss: 0.5051154494285583
Validation loss: 1.9416922728220622

Epoch: 6| Step: 13
Training loss: 0.44040071964263916
Validation loss: 1.9446550210316975

Epoch: 171| Step: 0
Training loss: 0.8849893808364868
Validation loss: 1.9406185746192932

Epoch: 6| Step: 1
Training loss: 0.7174867987632751
Validation loss: 1.9694047172864277

Epoch: 6| Step: 2
Training loss: 0.20520810782909393
Validation loss: 1.9519713521003723

Epoch: 6| Step: 3
Training loss: 0.4069235920906067
Validation loss: 1.9427857398986816

Epoch: 6| Step: 4
Training loss: 0.2905726432800293
Validation loss: 1.9386817812919617

Epoch: 6| Step: 5
Training loss: 0.469713419675827
Validation loss: 1.9189480741818745

Epoch: 6| Step: 6
Training loss: 0.7996113896369934
Validation loss: 1.9304665525754292

Epoch: 6| Step: 7
Training loss: 0.9968183040618896
Validation loss: 1.9096134702364604

Epoch: 6| Step: 8
Training loss: 0.38504451513290405
Validation loss: 1.9206563035647075

Epoch: 6| Step: 9
Training loss: 0.34501826763153076
Validation loss: 1.9711201985677083

Epoch: 6| Step: 10
Training loss: 0.8103749752044678
Validation loss: 1.9978531400362651

Epoch: 6| Step: 11
Training loss: 0.2848356366157532
Validation loss: 1.974674900372823

Epoch: 6| Step: 12
Training loss: 0.605018138885498
Validation loss: 1.9635309378306072

Epoch: 6| Step: 13
Training loss: 0.7617982625961304
Validation loss: 1.9644975662231445

Epoch: 172| Step: 0
Training loss: 0.8014686107635498
Validation loss: 1.9184261759122212

Epoch: 6| Step: 1
Training loss: 0.4521116614341736
Validation loss: 1.977630873521169

Epoch: 6| Step: 2
Training loss: 0.5728247165679932
Validation loss: 1.937990407148997

Epoch: 6| Step: 3
Training loss: 0.2547847032546997
Validation loss: 1.9121524095535278

Epoch: 6| Step: 4
Training loss: 0.21719574928283691
Validation loss: 1.977209786574046

Epoch: 6| Step: 5
Training loss: 0.5693778395652771
Validation loss: 1.9450971682866414

Epoch: 6| Step: 6
Training loss: 0.34672319889068604
Validation loss: 1.9041247169176738

Epoch: 6| Step: 7
Training loss: 0.6735407114028931
Validation loss: 1.9465275406837463

Epoch: 6| Step: 8
Training loss: 1.155982255935669
Validation loss: 1.9105979601542156

Epoch: 6| Step: 9
Training loss: 0.5617354512214661
Validation loss: 1.9656460881233215

Epoch: 6| Step: 10
Training loss: 0.38601118326187134
Validation loss: 1.9517109990119934

Epoch: 6| Step: 11
Training loss: 0.7129327058792114
Validation loss: 1.9444326559702556

Epoch: 6| Step: 12
Training loss: 0.4971405863761902
Validation loss: 1.9770097931226094

Epoch: 6| Step: 13
Training loss: 0.6377663016319275
Validation loss: 1.9267767866452534

Epoch: 173| Step: 0
Training loss: 0.2342357039451599
Validation loss: 1.935241937637329

Epoch: 6| Step: 1
Training loss: 0.37283581495285034
Validation loss: 1.966937005519867

Epoch: 6| Step: 2
Training loss: 0.3312661051750183
Validation loss: 1.943323791027069

Epoch: 6| Step: 3
Training loss: 1.0210036039352417
Validation loss: 1.9628274242083232

Epoch: 6| Step: 4
Training loss: 0.7035437822341919
Validation loss: 1.9671784241994221

Epoch: 6| Step: 5
Training loss: 0.2999139130115509
Validation loss: 1.9726009368896484

Epoch: 6| Step: 6
Training loss: 0.904387354850769
Validation loss: 1.966362198193868

Epoch: 6| Step: 7
Training loss: 0.4119283854961395
Validation loss: 1.9663128852844238

Epoch: 6| Step: 8
Training loss: 0.8383082747459412
Validation loss: 1.9739835262298584

Epoch: 6| Step: 9
Training loss: 0.7701022624969482
Validation loss: 1.9547324975331624

Epoch: 6| Step: 10
Training loss: 0.38135528564453125
Validation loss: 1.9629671772321065

Epoch: 6| Step: 11
Training loss: 0.5619648098945618
Validation loss: 1.9689527750015259

Epoch: 6| Step: 12
Training loss: 0.19091007113456726
Validation loss: 1.9555339813232422

Epoch: 6| Step: 13
Training loss: 0.5507597923278809
Validation loss: 1.9666706124941509

Epoch: 174| Step: 0
Training loss: 0.6786709427833557
Validation loss: 1.954428235689799

Epoch: 6| Step: 1
Training loss: 0.48667293787002563
Validation loss: 1.9587051272392273

Epoch: 6| Step: 2
Training loss: 1.2699768543243408
Validation loss: 1.9520296255747478

Epoch: 6| Step: 3
Training loss: 0.7818670272827148
Validation loss: 1.9514784216880798

Epoch: 6| Step: 4
Training loss: 0.47508540749549866
Validation loss: 1.9687774976094563

Epoch: 6| Step: 5
Training loss: 0.38772398233413696
Validation loss: 1.9757969578107197

Epoch: 6| Step: 6
Training loss: 0.23540756106376648
Validation loss: 1.9908775289853413

Epoch: 6| Step: 7
Training loss: 0.928723931312561
Validation loss: 1.9549109141031902

Epoch: 6| Step: 8
Training loss: 0.8645657896995544
Validation loss: 1.993778109550476

Epoch: 6| Step: 9
Training loss: 0.3370833396911621
Validation loss: 1.95201575756073

Epoch: 6| Step: 10
Training loss: 0.42565375566482544
Validation loss: 1.9674529631932576

Epoch: 6| Step: 11
Training loss: 0.3466450870037079
Validation loss: 1.9215129415194194

Epoch: 6| Step: 12
Training loss: 0.8900994062423706
Validation loss: 1.9446913003921509

Epoch: 6| Step: 13
Training loss: 0.29433774948120117
Validation loss: 1.949337363243103

Epoch: 175| Step: 0
Training loss: 0.5893086194992065
Validation loss: 1.9770782192548115

Epoch: 6| Step: 1
Training loss: 0.6085302829742432
Validation loss: 1.9396752913792927

Epoch: 6| Step: 2
Training loss: 0.7600692510604858
Validation loss: 1.9843073884646099

Epoch: 6| Step: 3
Training loss: 0.5638211369514465
Validation loss: 1.9451859792073567

Epoch: 6| Step: 4
Training loss: 0.33529597520828247
Validation loss: 1.9693927367528279

Epoch: 6| Step: 5
Training loss: 0.2933831214904785
Validation loss: 1.9431028962135315

Epoch: 6| Step: 6
Training loss: 0.52933669090271
Validation loss: 1.9389560023943584

Epoch: 6| Step: 7
Training loss: 0.8214818239212036
Validation loss: 1.9034220377604167

Epoch: 6| Step: 8
Training loss: 0.4532169699668884
Validation loss: 1.941754678885142

Epoch: 6| Step: 9
Training loss: 0.9606925249099731
Validation loss: 1.9451193809509277

Epoch: 6| Step: 10
Training loss: 0.7342830896377563
Validation loss: 1.9313664833704631

Epoch: 6| Step: 11
Training loss: 0.4433848559856415
Validation loss: 1.931700348854065

Epoch: 6| Step: 12
Training loss: 0.22256819903850555
Validation loss: 1.9597391883532207

Epoch: 6| Step: 13
Training loss: 0.43431878089904785
Validation loss: 1.8886446952819824

Testing loss: 1.7434824970986347
