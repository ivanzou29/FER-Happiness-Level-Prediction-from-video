Epoch: 1| Step: 0
Training loss: 5.679457664489746
Validation loss: 5.1738918622334795

Epoch: 6| Step: 1
Training loss: 4.798267364501953
Validation loss: 5.135361274083455

Epoch: 6| Step: 2
Training loss: 4.686059474945068
Validation loss: 5.0930735270182295

Epoch: 6| Step: 3
Training loss: 5.060826778411865
Validation loss: 5.055169900258382

Epoch: 6| Step: 4
Training loss: 4.777400493621826
Validation loss: 5.014429847399394

Epoch: 6| Step: 5
Training loss: 3.8800888061523438
Validation loss: 4.976540009180705

Epoch: 6| Step: 6
Training loss: 5.761868953704834
Validation loss: 4.936794360478719

Epoch: 6| Step: 7
Training loss: 5.276266098022461
Validation loss: 4.897257884343465

Epoch: 6| Step: 8
Training loss: 4.6102142333984375
Validation loss: 4.8601508140563965

Epoch: 6| Step: 9
Training loss: 5.222330093383789
Validation loss: 4.817827661832173

Epoch: 6| Step: 10
Training loss: 4.6733856201171875
Validation loss: 4.775098005930583

Epoch: 6| Step: 11
Training loss: 5.657041549682617
Validation loss: 4.73820694287618

Epoch: 6| Step: 12
Training loss: 5.461759567260742
Validation loss: 4.695500294367473

Epoch: 6| Step: 13
Training loss: 4.251628398895264
Validation loss: 4.6490029493967695

Epoch: 2| Step: 0
Training loss: 4.002305030822754
Validation loss: 4.60613997777303

Epoch: 6| Step: 1
Training loss: 4.6009111404418945
Validation loss: 4.556889375050862

Epoch: 6| Step: 2
Training loss: 3.8832156658172607
Validation loss: 4.507534583409627

Epoch: 6| Step: 3
Training loss: 4.325777530670166
Validation loss: 4.459318319956462

Epoch: 6| Step: 4
Training loss: 5.183727264404297
Validation loss: 4.404082377751668

Epoch: 6| Step: 5
Training loss: 5.197415351867676
Validation loss: 4.345418294270833

Epoch: 6| Step: 6
Training loss: 3.208181381225586
Validation loss: 4.29295567671458

Epoch: 6| Step: 7
Training loss: 4.574039936065674
Validation loss: 4.231603225072225

Epoch: 6| Step: 8
Training loss: 3.4578638076782227
Validation loss: 4.175890525182088

Epoch: 6| Step: 9
Training loss: 4.8625407218933105
Validation loss: 4.115190704663594

Epoch: 6| Step: 10
Training loss: 4.848420143127441
Validation loss: 4.053252816200256

Epoch: 6| Step: 11
Training loss: 4.456937789916992
Validation loss: 3.994042992591858

Epoch: 6| Step: 12
Training loss: 3.8044276237487793
Validation loss: 3.9346772829691568

Epoch: 6| Step: 13
Training loss: 4.442225456237793
Validation loss: 3.866860588391622

Epoch: 3| Step: 0
Training loss: 4.275687217712402
Validation loss: 3.8025839726130166

Epoch: 6| Step: 1
Training loss: 4.172708511352539
Validation loss: 3.7357792456944785

Epoch: 6| Step: 2
Training loss: 3.619511842727661
Validation loss: 3.663978099822998

Epoch: 6| Step: 3
Training loss: 3.779918670654297
Validation loss: 3.5895118713378906

Epoch: 6| Step: 4
Training loss: 3.2011804580688477
Validation loss: 3.5205229123433432

Epoch: 6| Step: 5
Training loss: 3.150111198425293
Validation loss: 3.4508628050486245

Epoch: 6| Step: 6
Training loss: 3.475761890411377
Validation loss: 3.3712626695632935

Epoch: 6| Step: 7
Training loss: 3.0934417247772217
Validation loss: 3.291554053624471

Epoch: 6| Step: 8
Training loss: 2.8961105346679688
Validation loss: 3.2004851500193277

Epoch: 6| Step: 9
Training loss: 2.819700241088867
Validation loss: 3.1389262676239014

Epoch: 6| Step: 10
Training loss: 3.9282026290893555
Validation loss: 3.0441671212514243

Epoch: 6| Step: 11
Training loss: 2.1896591186523438
Validation loss: 2.9735577503840127

Epoch: 6| Step: 12
Training loss: 3.482447385787964
Validation loss: 2.8926045497258506

Epoch: 6| Step: 13
Training loss: 3.077531337738037
Validation loss: 2.7921601931254068

Epoch: 4| Step: 0
Training loss: 2.7408275604248047
Validation loss: 2.7132471799850464

Epoch: 6| Step: 1
Training loss: 2.8374576568603516
Validation loss: 2.6038251717885337

Epoch: 6| Step: 2
Training loss: 2.696772813796997
Validation loss: 2.513905644416809

Epoch: 6| Step: 3
Training loss: 3.0296921730041504
Validation loss: 2.41825799147288

Epoch: 6| Step: 4
Training loss: 2.075685501098633
Validation loss: 2.348830461502075

Epoch: 6| Step: 5
Training loss: 1.751025915145874
Validation loss: 2.3015991846720376

Epoch: 6| Step: 6
Training loss: 2.07731556892395
Validation loss: 2.2325275937716165

Epoch: 6| Step: 7
Training loss: 1.879324197769165
Validation loss: 2.195001165072123

Epoch: 6| Step: 8
Training loss: 2.518430233001709
Validation loss: 2.1749746203422546

Epoch: 6| Step: 9
Training loss: 2.628366231918335
Validation loss: 2.1658397118250527

Epoch: 6| Step: 10
Training loss: 2.3999133110046387
Validation loss: 2.1718621452649436

Epoch: 6| Step: 11
Training loss: 2.132774591445923
Validation loss: 2.1495959758758545

Epoch: 6| Step: 12
Training loss: 2.366140842437744
Validation loss: 2.1499804854393005

Epoch: 6| Step: 13
Training loss: 1.285871982574463
Validation loss: 2.1741581757863364

Epoch: 5| Step: 0
Training loss: 2.400913953781128
Validation loss: 2.178905208905538

Epoch: 6| Step: 1
Training loss: 2.096445322036743
Validation loss: 2.215734541416168

Epoch: 6| Step: 2
Training loss: 2.34118914604187
Validation loss: 2.229516307512919

Epoch: 6| Step: 3
Training loss: 2.016491651535034
Validation loss: 2.220955510934194

Epoch: 6| Step: 4
Training loss: 1.8223636150360107
Validation loss: 2.222663243611654

Epoch: 6| Step: 5
Training loss: 2.1022911071777344
Validation loss: 2.2262728611628213

Epoch: 6| Step: 6
Training loss: 2.0318284034729004
Validation loss: 2.1822868982950845

Epoch: 6| Step: 7
Training loss: 2.8971810340881348
Validation loss: 2.174082418282827

Epoch: 6| Step: 8
Training loss: 1.3915406465530396
Validation loss: 2.134050488471985

Epoch: 6| Step: 9
Training loss: 2.597029685974121
Validation loss: 2.1306136647860208

Epoch: 6| Step: 10
Training loss: 2.5319085121154785
Validation loss: 2.1610144774119058

Epoch: 6| Step: 11
Training loss: 1.985429286956787
Validation loss: 2.135868489742279

Epoch: 6| Step: 12
Training loss: 2.0003128051757812
Validation loss: 2.1326634883880615

Epoch: 6| Step: 13
Training loss: 2.6323037147521973
Validation loss: 2.164414564768473

Epoch: 6| Step: 0
Training loss: 2.216435194015503
Validation loss: 2.1681594451268515

Epoch: 6| Step: 1
Training loss: 1.884331226348877
Validation loss: 2.1410500208536782

Epoch: 6| Step: 2
Training loss: 1.5065194368362427
Validation loss: 2.1512581507364907

Epoch: 6| Step: 3
Training loss: 1.9456868171691895
Validation loss: 2.1681278944015503

Epoch: 6| Step: 4
Training loss: 1.5491700172424316
Validation loss: 2.170440594355265

Epoch: 6| Step: 5
Training loss: 2.6105315685272217
Validation loss: 2.1723865469296775

Epoch: 6| Step: 6
Training loss: 1.9338107109069824
Validation loss: 2.1750080982844033

Epoch: 6| Step: 7
Training loss: 2.2582144737243652
Validation loss: 2.1678926746050515

Epoch: 6| Step: 8
Training loss: 2.3667986392974854
Validation loss: 2.1644933621088662

Epoch: 6| Step: 9
Training loss: 2.114772319793701
Validation loss: 2.1645724972089133

Epoch: 6| Step: 10
Training loss: 2.9626920223236084
Validation loss: 2.1490015387535095

Epoch: 6| Step: 11
Training loss: 2.855848789215088
Validation loss: 2.192314624786377

Epoch: 6| Step: 12
Training loss: 2.364388942718506
Validation loss: 2.168374180793762

Epoch: 6| Step: 13
Training loss: 1.5995914936065674
Validation loss: 2.138460397720337

Epoch: 7| Step: 0
Training loss: 2.3778347969055176
Validation loss: 2.1547951896985373

Epoch: 6| Step: 1
Training loss: 1.4921138286590576
Validation loss: 2.137957215309143

Epoch: 6| Step: 2
Training loss: 1.7383497953414917
Validation loss: 2.1390801270802817

Epoch: 6| Step: 3
Training loss: 2.241048812866211
Validation loss: 2.1503312389055886

Epoch: 6| Step: 4
Training loss: 1.9095063209533691
Validation loss: 2.1256492137908936

Epoch: 6| Step: 5
Training loss: 2.2487778663635254
Validation loss: 2.1166163881619773

Epoch: 6| Step: 6
Training loss: 1.9926981925964355
Validation loss: 2.128114104270935

Epoch: 6| Step: 7
Training loss: 1.7383055686950684
Validation loss: 2.115344742933909

Epoch: 6| Step: 8
Training loss: 2.826043128967285
Validation loss: 2.0889742374420166

Epoch: 6| Step: 9
Training loss: 2.9189910888671875
Validation loss: 2.0773291985193887

Epoch: 6| Step: 10
Training loss: 1.7169824838638306
Validation loss: 2.0917230248451233

Epoch: 6| Step: 11
Training loss: 2.067302703857422
Validation loss: 2.086490790049235

Epoch: 6| Step: 12
Training loss: 1.573583960533142
Validation loss: 2.116666555404663

Epoch: 6| Step: 13
Training loss: 2.704486846923828
Validation loss: 2.1056026617685952

Epoch: 8| Step: 0
Training loss: 2.3241124153137207
Validation loss: 2.0921348532040915

Epoch: 6| Step: 1
Training loss: 2.4309771060943604
Validation loss: 2.0988337993621826

Epoch: 6| Step: 2
Training loss: 1.7937469482421875
Validation loss: 2.109463314215342

Epoch: 6| Step: 3
Training loss: 2.793438196182251
Validation loss: 2.1116049687067666

Epoch: 6| Step: 4
Training loss: 2.1318724155426025
Validation loss: 2.0959118207295737

Epoch: 6| Step: 5
Training loss: 1.8535737991333008
Validation loss: 2.1038034558296204

Epoch: 6| Step: 6
Training loss: 2.2582430839538574
Validation loss: 2.083427627881368

Epoch: 6| Step: 7
Training loss: 1.5805919170379639
Validation loss: 2.070835212866465

Epoch: 6| Step: 8
Training loss: 1.8446991443634033
Validation loss: 2.1054049928983054

Epoch: 6| Step: 9
Training loss: 2.4700512886047363
Validation loss: 2.0953202644983926

Epoch: 6| Step: 10
Training loss: 2.062110424041748
Validation loss: 2.097815215587616

Epoch: 6| Step: 11
Training loss: 2.250706195831299
Validation loss: 2.092967669169108

Epoch: 6| Step: 12
Training loss: 1.9319576025009155
Validation loss: 2.0813194115956626

Epoch: 6| Step: 13
Training loss: 1.785247564315796
Validation loss: 2.071092446645101

Epoch: 9| Step: 0
Training loss: 2.410205841064453
Validation loss: 2.0682628750801086

Epoch: 6| Step: 1
Training loss: 2.266880750656128
Validation loss: 2.102213740348816

Epoch: 6| Step: 2
Training loss: 1.8125419616699219
Validation loss: 2.090323348840078

Epoch: 6| Step: 3
Training loss: 1.4986000061035156
Validation loss: 2.0736566384633384

Epoch: 6| Step: 4
Training loss: 2.1562511920928955
Validation loss: 2.0942612091700235

Epoch: 6| Step: 5
Training loss: 2.3825736045837402
Validation loss: 2.105947732925415

Epoch: 6| Step: 6
Training loss: 1.9745126962661743
Validation loss: 2.0841692686080933

Epoch: 6| Step: 7
Training loss: 2.2246336936950684
Validation loss: 2.0918630758921304

Epoch: 6| Step: 8
Training loss: 2.3646392822265625
Validation loss: 2.0877293745676675

Epoch: 6| Step: 9
Training loss: 1.8698238134384155
Validation loss: 2.0888009667396545

Epoch: 6| Step: 10
Training loss: 2.41165828704834
Validation loss: 2.0869461496671042

Epoch: 6| Step: 11
Training loss: 1.6973073482513428
Validation loss: 2.072563727696737

Epoch: 6| Step: 12
Training loss: 1.7595298290252686
Validation loss: 2.081100801626841

Epoch: 6| Step: 13
Training loss: 2.3358187675476074
Validation loss: 2.08128958940506

Epoch: 10| Step: 0
Training loss: 2.5957345962524414
Validation loss: 2.060032228628794

Epoch: 6| Step: 1
Training loss: 1.9430813789367676
Validation loss: 2.066187083721161

Epoch: 6| Step: 2
Training loss: 2.0062601566314697
Validation loss: 2.0638712445894876

Epoch: 6| Step: 3
Training loss: 2.2202696800231934
Validation loss: 2.0773592591285706

Epoch: 6| Step: 4
Training loss: 1.900853157043457
Validation loss: 2.072161873181661

Epoch: 6| Step: 5
Training loss: 1.43636155128479
Validation loss: 2.0848156809806824

Epoch: 6| Step: 6
Training loss: 1.7169432640075684
Validation loss: 2.0796120166778564

Epoch: 6| Step: 7
Training loss: 2.006553888320923
Validation loss: 2.069012939929962

Epoch: 6| Step: 8
Training loss: 2.0846545696258545
Validation loss: 2.059692700703939

Epoch: 6| Step: 9
Training loss: 2.6594157218933105
Validation loss: 2.0536075234413147

Epoch: 6| Step: 10
Training loss: 1.9005296230316162
Validation loss: 2.065001646677653

Epoch: 6| Step: 11
Training loss: 2.0779807567596436
Validation loss: 2.0675851504007974

Epoch: 6| Step: 12
Training loss: 2.4456751346588135
Validation loss: 2.0529973904291787

Epoch: 6| Step: 13
Training loss: 1.9129681587219238
Validation loss: 2.059530019760132

Epoch: 11| Step: 0
Training loss: 2.464492082595825
Validation loss: 2.086000382900238

Epoch: 6| Step: 1
Training loss: 1.8254828453063965
Validation loss: 2.0624187191327414

Epoch: 6| Step: 2
Training loss: 1.3730779886245728
Validation loss: 2.061256547768911

Epoch: 6| Step: 3
Training loss: 1.4721001386642456
Validation loss: 2.0534832080205283

Epoch: 6| Step: 4
Training loss: 1.964348554611206
Validation loss: 2.06433242559433

Epoch: 6| Step: 5
Training loss: 1.6554139852523804
Validation loss: 2.0336496432622275

Epoch: 6| Step: 6
Training loss: 1.642217993736267
Validation loss: 2.065608024597168

Epoch: 6| Step: 7
Training loss: 2.541325092315674
Validation loss: 2.03687592347463

Epoch: 6| Step: 8
Training loss: 2.0998713970184326
Validation loss: 2.058774471282959

Epoch: 6| Step: 9
Training loss: 2.219773292541504
Validation loss: 2.065733850002289

Epoch: 6| Step: 10
Training loss: 2.281099796295166
Validation loss: 2.0452712376912436

Epoch: 6| Step: 11
Training loss: 2.4965131282806396
Validation loss: 2.05286713441213

Epoch: 6| Step: 12
Training loss: 2.005422830581665
Validation loss: 2.057050903638204

Epoch: 6| Step: 13
Training loss: 2.5193240642547607
Validation loss: 2.0600780248641968

Epoch: 12| Step: 0
Training loss: 2.281318187713623
Validation loss: 2.0487181146939597

Epoch: 6| Step: 1
Training loss: 2.424349308013916
Validation loss: 2.0721982518831887

Epoch: 6| Step: 2
Training loss: 2.0108494758605957
Validation loss: 2.0752986073493958

Epoch: 6| Step: 3
Training loss: 1.863132357597351
Validation loss: 2.0765593846639

Epoch: 6| Step: 4
Training loss: 2.3163766860961914
Validation loss: 2.0620397528012595

Epoch: 6| Step: 5
Training loss: 2.5776453018188477
Validation loss: 2.0404045581817627

Epoch: 6| Step: 6
Training loss: 1.6619529724121094
Validation loss: 2.056254188219706

Epoch: 6| Step: 7
Training loss: 2.1591877937316895
Validation loss: 2.0761165420214334

Epoch: 6| Step: 8
Training loss: 2.193667411804199
Validation loss: 2.0445227225621543

Epoch: 6| Step: 9
Training loss: 2.3731226921081543
Validation loss: 2.057889223098755

Epoch: 6| Step: 10
Training loss: 1.849435806274414
Validation loss: 2.0631741484006247

Epoch: 6| Step: 11
Training loss: 1.4829766750335693
Validation loss: 2.062860647837321

Epoch: 6| Step: 12
Training loss: 1.807116985321045
Validation loss: 2.0506136616071067

Epoch: 6| Step: 13
Training loss: 1.6376771926879883
Validation loss: 2.038174827893575

Epoch: 13| Step: 0
Training loss: 2.1013343334198
Validation loss: 2.0466533104578652

Epoch: 6| Step: 1
Training loss: 1.682140588760376
Validation loss: 2.0401838223139444

Epoch: 6| Step: 2
Training loss: 2.7914304733276367
Validation loss: 2.0158475240071616

Epoch: 6| Step: 3
Training loss: 1.7158597707748413
Validation loss: 2.022277613480886

Epoch: 6| Step: 4
Training loss: 2.2747573852539062
Validation loss: 2.0355818470319114

Epoch: 6| Step: 5
Training loss: 2.0722389221191406
Validation loss: 2.037615497907003

Epoch: 6| Step: 6
Training loss: 2.285611152648926
Validation loss: 2.068502922852834

Epoch: 6| Step: 7
Training loss: 2.170132875442505
Validation loss: 2.042576173941294

Epoch: 6| Step: 8
Training loss: 2.6000683307647705
Validation loss: 2.028355360031128

Epoch: 6| Step: 9
Training loss: 1.6987364292144775
Validation loss: 2.037597974141439

Epoch: 6| Step: 10
Training loss: 2.2653236389160156
Validation loss: 2.045304457346598

Epoch: 6| Step: 11
Training loss: 1.492077350616455
Validation loss: 2.052976886431376

Epoch: 6| Step: 12
Training loss: 1.4664182662963867
Validation loss: 2.0472169518470764

Epoch: 6| Step: 13
Training loss: 1.766719102859497
Validation loss: 2.0470571517944336

Epoch: 14| Step: 0
Training loss: 1.8402345180511475
Validation loss: 2.038633167743683

Epoch: 6| Step: 1
Training loss: 1.6290864944458008
Validation loss: 2.0635523200035095

Epoch: 6| Step: 2
Training loss: 2.1616640090942383
Validation loss: 2.027278999487559

Epoch: 6| Step: 3
Training loss: 1.3125063180923462
Validation loss: 2.036458909511566

Epoch: 6| Step: 4
Training loss: 1.9238746166229248
Validation loss: 2.033851067225138

Epoch: 6| Step: 5
Training loss: 1.9154309034347534
Validation loss: 2.07070662577947

Epoch: 6| Step: 6
Training loss: 2.6137452125549316
Validation loss: 2.0472284158070884

Epoch: 6| Step: 7
Training loss: 2.488508939743042
Validation loss: 2.050441841284434

Epoch: 6| Step: 8
Training loss: 1.9586085081100464
Validation loss: 2.037390112876892

Epoch: 6| Step: 9
Training loss: 2.4212646484375
Validation loss: 2.022684176762899

Epoch: 6| Step: 10
Training loss: 1.7518783807754517
Validation loss: 2.0507779518763223

Epoch: 6| Step: 11
Training loss: 1.8590080738067627
Validation loss: 2.0308576623598733

Epoch: 6| Step: 12
Training loss: 1.9708688259124756
Validation loss: 2.043575565020243

Epoch: 6| Step: 13
Training loss: 2.434860944747925
Validation loss: 2.0300241510073342

Epoch: 15| Step: 0
Training loss: 1.8811285495758057
Validation loss: 2.0553629398345947

Epoch: 6| Step: 1
Training loss: 2.060230016708374
Validation loss: 2.0667316714922586

Epoch: 6| Step: 2
Training loss: 2.182608127593994
Validation loss: 2.0341831048329673

Epoch: 6| Step: 3
Training loss: 1.7098969221115112
Validation loss: 2.0662147402763367

Epoch: 6| Step: 4
Training loss: 1.8681597709655762
Validation loss: 2.0627301732699075

Epoch: 6| Step: 5
Training loss: 2.01884126663208
Validation loss: 2.0514984130859375

Epoch: 6| Step: 6
Training loss: 1.9218631982803345
Validation loss: 2.039766013622284

Epoch: 6| Step: 7
Training loss: 2.4031496047973633
Validation loss: 2.0342888236045837

Epoch: 6| Step: 8
Training loss: 2.0000534057617188
Validation loss: 2.03095551331838

Epoch: 6| Step: 9
Training loss: 2.3380188941955566
Validation loss: 2.065400183200836

Epoch: 6| Step: 10
Training loss: 1.574104905128479
Validation loss: 2.0281238357226052

Epoch: 6| Step: 11
Training loss: 1.5463757514953613
Validation loss: 2.0502333442370095

Epoch: 6| Step: 12
Training loss: 2.3539323806762695
Validation loss: 2.0438380241394043

Epoch: 6| Step: 13
Training loss: 2.6280317306518555
Validation loss: 2.0234921177228293

Epoch: 16| Step: 0
Training loss: 2.1772942543029785
Validation loss: 2.0331561962763467

Epoch: 6| Step: 1
Training loss: 1.744044303894043
Validation loss: 2.0518118937810264

Epoch: 6| Step: 2
Training loss: 1.6799708604812622
Validation loss: 2.036664287249247

Epoch: 6| Step: 3
Training loss: 2.2503767013549805
Validation loss: 2.0378703077634177

Epoch: 6| Step: 4
Training loss: 1.9530314207077026
Validation loss: 2.0130585630734763

Epoch: 6| Step: 5
Training loss: 2.0215983390808105
Validation loss: 2.050060272216797

Epoch: 6| Step: 6
Training loss: 1.808325171470642
Validation loss: 2.0182005365689597

Epoch: 6| Step: 7
Training loss: 1.91885507106781
Validation loss: 2.0363879402478537

Epoch: 6| Step: 8
Training loss: 1.5851738452911377
Validation loss: 2.0228256781895957

Epoch: 6| Step: 9
Training loss: 1.8075026273727417
Validation loss: 2.0326044956843057

Epoch: 6| Step: 10
Training loss: 2.2411932945251465
Validation loss: 2.033578634262085

Epoch: 6| Step: 11
Training loss: 2.196720838546753
Validation loss: 2.040902098019918

Epoch: 6| Step: 12
Training loss: 2.3321049213409424
Validation loss: 2.038799822330475

Epoch: 6| Step: 13
Training loss: 2.5025064945220947
Validation loss: 2.0212531089782715

Epoch: 17| Step: 0
Training loss: 2.3354685306549072
Validation loss: 2.031498074531555

Epoch: 6| Step: 1
Training loss: 2.225064754486084
Validation loss: 2.058654169241587

Epoch: 6| Step: 2
Training loss: 2.0979015827178955
Validation loss: 2.052014728387197

Epoch: 6| Step: 3
Training loss: 1.7239346504211426
Validation loss: 2.0095160802205405

Epoch: 6| Step: 4
Training loss: 2.165109157562256
Validation loss: 2.021844963232676

Epoch: 6| Step: 5
Training loss: 1.9887077808380127
Validation loss: 2.006067474683126

Epoch: 6| Step: 6
Training loss: 1.9317779541015625
Validation loss: 2.0197080175081887

Epoch: 6| Step: 7
Training loss: 1.8513377904891968
Validation loss: 2.008605718612671

Epoch: 6| Step: 8
Training loss: 1.9823635816574097
Validation loss: 2.049287259578705

Epoch: 6| Step: 9
Training loss: 1.929509162902832
Validation loss: 2.01978729168574

Epoch: 6| Step: 10
Training loss: 2.2024521827697754
Validation loss: 2.0391831000645957

Epoch: 6| Step: 11
Training loss: 1.3875367641448975
Validation loss: 2.042346100012461

Epoch: 6| Step: 12
Training loss: 2.724106550216675
Validation loss: 2.022526482741038

Epoch: 6| Step: 13
Training loss: 1.6482956409454346
Validation loss: 2.021071414152781

Epoch: 18| Step: 0
Training loss: 1.9677739143371582
Validation loss: 2.01022998491923

Epoch: 6| Step: 1
Training loss: 1.972933053970337
Validation loss: 2.027756452560425

Epoch: 6| Step: 2
Training loss: 1.9678465127944946
Validation loss: 2.0078860918680825

Epoch: 6| Step: 3
Training loss: 2.1789917945861816
Validation loss: 2.031068126360575

Epoch: 6| Step: 4
Training loss: 1.8362576961517334
Validation loss: 2.036911944548289

Epoch: 6| Step: 5
Training loss: 1.8481121063232422
Validation loss: 2.0262991388638816

Epoch: 6| Step: 6
Training loss: 2.352719306945801
Validation loss: 2.041415572166443

Epoch: 6| Step: 7
Training loss: 1.741413950920105
Validation loss: 2.023044308026632

Epoch: 6| Step: 8
Training loss: 1.7769966125488281
Validation loss: 2.0415313243865967

Epoch: 6| Step: 9
Training loss: 1.8964953422546387
Validation loss: 2.046955188115438

Epoch: 6| Step: 10
Training loss: 2.815463066101074
Validation loss: 2.0410603682200112

Epoch: 6| Step: 11
Training loss: 1.8288726806640625
Validation loss: 2.0158031781514487

Epoch: 6| Step: 12
Training loss: 2.401249647140503
Validation loss: 2.031799594561259

Epoch: 6| Step: 13
Training loss: 1.7478938102722168
Validation loss: 2.0248372753461203

Epoch: 19| Step: 0
Training loss: 1.5854723453521729
Validation loss: 2.0304391980171204

Epoch: 6| Step: 1
Training loss: 1.467210054397583
Validation loss: 2.0437512199083963

Epoch: 6| Step: 2
Training loss: 1.437314748764038
Validation loss: 2.0474681655565896

Epoch: 6| Step: 3
Training loss: 1.3366963863372803
Validation loss: 2.025437613328298

Epoch: 6| Step: 4
Training loss: 2.819340944290161
Validation loss: 2.060011386871338

Epoch: 6| Step: 5
Training loss: 2.5684146881103516
Validation loss: 2.060615281263987

Epoch: 6| Step: 6
Training loss: 1.5880789756774902
Validation loss: 2.0314584771792092

Epoch: 6| Step: 7
Training loss: 2.0791776180267334
Validation loss: 2.0324806769688926

Epoch: 6| Step: 8
Training loss: 1.917181372642517
Validation loss: 2.027682363986969

Epoch: 6| Step: 9
Training loss: 1.6958057880401611
Validation loss: 2.0063576698303223

Epoch: 6| Step: 10
Training loss: 2.0936198234558105
Validation loss: 2.0036979715029397

Epoch: 6| Step: 11
Training loss: 2.5762829780578613
Validation loss: 2.007640759150187

Epoch: 6| Step: 12
Training loss: 2.3276073932647705
Validation loss: 2.0404673417409263

Epoch: 6| Step: 13
Training loss: 2.631385326385498
Validation loss: 2.039379060268402

Epoch: 20| Step: 0
Training loss: 1.8207790851593018
Validation loss: 2.0338120261828103

Epoch: 6| Step: 1
Training loss: 1.7980246543884277
Validation loss: 2.030162195364634

Epoch: 6| Step: 2
Training loss: 2.434901475906372
Validation loss: 2.0266114274660745

Epoch: 6| Step: 3
Training loss: 1.6181604862213135
Validation loss: 2.033179004987081

Epoch: 6| Step: 4
Training loss: 2.3580832481384277
Validation loss: 2.0561228593190513

Epoch: 6| Step: 5
Training loss: 2.2643699645996094
Validation loss: 2.0332897106806436

Epoch: 6| Step: 6
Training loss: 1.5695064067840576
Validation loss: 2.043538987636566

Epoch: 6| Step: 7
Training loss: 2.2071585655212402
Validation loss: 2.0556275049845376

Epoch: 6| Step: 8
Training loss: 1.4075977802276611
Validation loss: 2.0457545121510825

Epoch: 6| Step: 9
Training loss: 2.1467702388763428
Validation loss: 2.0544511477152505

Epoch: 6| Step: 10
Training loss: 2.407085418701172
Validation loss: 2.0419373909632363

Epoch: 6| Step: 11
Training loss: 1.9910187721252441
Validation loss: 2.0294254422187805

Epoch: 6| Step: 12
Training loss: 1.92594575881958
Validation loss: 2.0187027851740518

Epoch: 6| Step: 13
Training loss: 2.0567269325256348
Validation loss: 2.031469782193502

Epoch: 21| Step: 0
Training loss: 1.8892221450805664
Validation loss: 1.99600354830424

Epoch: 6| Step: 1
Training loss: 1.6743229627609253
Validation loss: 2.0429053703943887

Epoch: 6| Step: 2
Training loss: 2.3793866634368896
Validation loss: 2.0358946323394775

Epoch: 6| Step: 3
Training loss: 2.231698989868164
Validation loss: 2.0268194874127707

Epoch: 6| Step: 4
Training loss: 1.9126794338226318
Validation loss: 2.0217483242352805

Epoch: 6| Step: 5
Training loss: 1.9626433849334717
Validation loss: 2.050756275653839

Epoch: 6| Step: 6
Training loss: 2.503232002258301
Validation loss: 2.0150490403175354

Epoch: 6| Step: 7
Training loss: 1.8337140083312988
Validation loss: 2.0344559947649636

Epoch: 6| Step: 8
Training loss: 1.5619122982025146
Validation loss: 2.0318131844202676

Epoch: 6| Step: 9
Training loss: 2.259775400161743
Validation loss: 2.0364938775698342

Epoch: 6| Step: 10
Training loss: 1.281583309173584
Validation loss: 2.031721512476603

Epoch: 6| Step: 11
Training loss: 1.8286241292953491
Validation loss: 2.0362435976664224

Epoch: 6| Step: 12
Training loss: 1.9366906881332397
Validation loss: 2.0264925360679626

Epoch: 6| Step: 13
Training loss: 2.4623188972473145
Validation loss: 2.0042394002278647

Epoch: 22| Step: 0
Training loss: 1.5849432945251465
Validation loss: 2.029379924138387

Epoch: 6| Step: 1
Training loss: 2.5103862285614014
Validation loss: 2.0152187744776406

Epoch: 6| Step: 2
Training loss: 1.368481159210205
Validation loss: 2.0482865969340005

Epoch: 6| Step: 3
Training loss: 2.2828168869018555
Validation loss: 1.9947796662648518

Epoch: 6| Step: 4
Training loss: 1.996903657913208
Validation loss: 2.0416035652160645

Epoch: 6| Step: 5
Training loss: 1.611851692199707
Validation loss: 2.0276817282040915

Epoch: 6| Step: 6
Training loss: 2.3006765842437744
Validation loss: 2.0124314030011496

Epoch: 6| Step: 7
Training loss: 2.017611026763916
Validation loss: 2.0240662693977356

Epoch: 6| Step: 8
Training loss: 2.7925055027008057
Validation loss: 2.0171837409337363

Epoch: 6| Step: 9
Training loss: 1.7884266376495361
Validation loss: 2.025657594203949

Epoch: 6| Step: 10
Training loss: 1.877152442932129
Validation loss: 2.0487909515698752

Epoch: 6| Step: 11
Training loss: 1.7844265699386597
Validation loss: 2.0169358452161155

Epoch: 6| Step: 12
Training loss: 1.9961726665496826
Validation loss: 2.028554320335388

Epoch: 6| Step: 13
Training loss: 1.8774092197418213
Validation loss: 2.03122744957606

Epoch: 23| Step: 0
Training loss: 2.5692381858825684
Validation loss: 2.0150903264681497

Epoch: 6| Step: 1
Training loss: 1.4959973096847534
Validation loss: 2.019804219404856

Epoch: 6| Step: 2
Training loss: 1.9745662212371826
Validation loss: 2.0247973601023355

Epoch: 6| Step: 3
Training loss: 2.4604358673095703
Validation loss: 2.0068389177322388

Epoch: 6| Step: 4
Training loss: 1.1042495965957642
Validation loss: 2.0180051724116006

Epoch: 6| Step: 5
Training loss: 2.3295936584472656
Validation loss: 2.033070762952169

Epoch: 6| Step: 6
Training loss: 2.1230413913726807
Validation loss: 2.0226410031318665

Epoch: 6| Step: 7
Training loss: 2.322737455368042
Validation loss: 2.0178998510042825

Epoch: 6| Step: 8
Training loss: 2.02074933052063
Validation loss: 2.00943394502004

Epoch: 6| Step: 9
Training loss: 2.2811203002929688
Validation loss: 2.026797632376353

Epoch: 6| Step: 10
Training loss: 1.3545176982879639
Validation loss: 1.9972227811813354

Epoch: 6| Step: 11
Training loss: 2.083609104156494
Validation loss: 2.002316335837046

Epoch: 6| Step: 12
Training loss: 1.8064494132995605
Validation loss: 2.0321043928464255

Epoch: 6| Step: 13
Training loss: 1.6985702514648438
Validation loss: 2.028762678305308

Epoch: 24| Step: 0
Training loss: 1.7606948614120483
Validation loss: 2.0302085677782693

Epoch: 6| Step: 1
Training loss: 2.0044963359832764
Validation loss: 2.0117205381393433

Epoch: 6| Step: 2
Training loss: 2.019918203353882
Validation loss: 2.0136488874753318

Epoch: 6| Step: 3
Training loss: 1.04854416847229
Validation loss: 2.026130517323812

Epoch: 6| Step: 4
Training loss: 2.188589096069336
Validation loss: 2.054475744565328

Epoch: 6| Step: 5
Training loss: 2.303168773651123
Validation loss: 2.0312611063321433

Epoch: 6| Step: 6
Training loss: 2.1830637454986572
Validation loss: 2.0228824615478516

Epoch: 6| Step: 7
Training loss: 2.559363842010498
Validation loss: 2.0159291426340737

Epoch: 6| Step: 8
Training loss: 1.3989044427871704
Validation loss: 2.018042723337809

Epoch: 6| Step: 9
Training loss: 2.0386509895324707
Validation loss: 2.0224161942799888

Epoch: 6| Step: 10
Training loss: 1.7445765733718872
Validation loss: 2.0341654817263284

Epoch: 6| Step: 11
Training loss: 2.123687982559204
Validation loss: 2.0355497002601624

Epoch: 6| Step: 12
Training loss: 1.8801859617233276
Validation loss: 2.017948647340139

Epoch: 6| Step: 13
Training loss: 2.4165725708007812
Validation loss: 2.006840149561564

Epoch: 25| Step: 0
Training loss: 1.3401710987091064
Validation loss: 2.020471235116323

Epoch: 6| Step: 1
Training loss: 1.8632128238677979
Validation loss: 2.014831761519114

Epoch: 6| Step: 2
Training loss: 1.907090663909912
Validation loss: 2.0283764799435935

Epoch: 6| Step: 3
Training loss: 2.4340980052948
Validation loss: 2.025371551513672

Epoch: 6| Step: 4
Training loss: 1.4993035793304443
Validation loss: 2.0027257402737937

Epoch: 6| Step: 5
Training loss: 2.062729835510254
Validation loss: 2.009475668271383

Epoch: 6| Step: 6
Training loss: 2.198575496673584
Validation loss: 2.01088680823644

Epoch: 6| Step: 7
Training loss: 2.0420784950256348
Validation loss: 2.0123405853907266

Epoch: 6| Step: 8
Training loss: 2.1377668380737305
Validation loss: 2.020728131135305

Epoch: 6| Step: 9
Training loss: 1.4846400022506714
Validation loss: 2.023924231529236

Epoch: 6| Step: 10
Training loss: 2.2945029735565186
Validation loss: 2.0254741509755454

Epoch: 6| Step: 11
Training loss: 1.4589875936508179
Validation loss: 2.013991057872772

Epoch: 6| Step: 12
Training loss: 2.1977968215942383
Validation loss: 2.0391370058059692

Epoch: 6| Step: 13
Training loss: 2.6036925315856934
Validation loss: 2.006159543991089

Epoch: 26| Step: 0
Training loss: 1.934156894683838
Validation loss: 2.0224817991256714

Epoch: 6| Step: 1
Training loss: 1.9456920623779297
Validation loss: 2.034387171268463

Epoch: 6| Step: 2
Training loss: 2.023111343383789
Validation loss: 1.9921882152557373

Epoch: 6| Step: 3
Training loss: 1.2587227821350098
Validation loss: 2.0171692768732705

Epoch: 6| Step: 4
Training loss: 1.7790464162826538
Validation loss: 2.025775988896688

Epoch: 6| Step: 5
Training loss: 2.085646152496338
Validation loss: 2.0282414754231772

Epoch: 6| Step: 6
Training loss: 2.112133026123047
Validation loss: 2.0112362702687583

Epoch: 6| Step: 7
Training loss: 2.844987392425537
Validation loss: 2.0062018831570945

Epoch: 6| Step: 8
Training loss: 1.8418067693710327
Validation loss: 2.0039645433425903

Epoch: 6| Step: 9
Training loss: 1.8680081367492676
Validation loss: 2.0070796410242715

Epoch: 6| Step: 10
Training loss: 1.7420753240585327
Validation loss: 2.009239931901296

Epoch: 6| Step: 11
Training loss: 1.600750207901001
Validation loss: 2.0053128004074097

Epoch: 6| Step: 12
Training loss: 2.473005771636963
Validation loss: 2.024209976196289

Epoch: 6| Step: 13
Training loss: 2.2208988666534424
Validation loss: 2.0177207787831626

Epoch: 27| Step: 0
Training loss: 1.6468539237976074
Validation loss: 2.010500907897949

Epoch: 6| Step: 1
Training loss: 1.747213363647461
Validation loss: 2.0106212496757507

Epoch: 6| Step: 2
Training loss: 2.191483974456787
Validation loss: 2.0109763542811074

Epoch: 6| Step: 3
Training loss: 2.226902961730957
Validation loss: 2.02523402372996

Epoch: 6| Step: 4
Training loss: 1.6612792015075684
Validation loss: 2.032315810521444

Epoch: 6| Step: 5
Training loss: 2.0407276153564453
Validation loss: 2.050370752811432

Epoch: 6| Step: 6
Training loss: 1.890268325805664
Validation loss: 2.0664166808128357

Epoch: 6| Step: 7
Training loss: 2.8903634548187256
Validation loss: 2.050405522187551

Epoch: 6| Step: 8
Training loss: 1.8944666385650635
Validation loss: 2.0698965787887573

Epoch: 6| Step: 9
Training loss: 1.920332670211792
Validation loss: 2.0662538607915244

Epoch: 6| Step: 10
Training loss: 2.174375057220459
Validation loss: 2.0570173064867654

Epoch: 6| Step: 11
Training loss: 2.0307998657226562
Validation loss: 2.036456306775411

Epoch: 6| Step: 12
Training loss: 1.6911251544952393
Validation loss: 2.0238755544026694

Epoch: 6| Step: 13
Training loss: 1.630469799041748
Validation loss: 2.011711378892263

Epoch: 28| Step: 0
Training loss: 1.349174976348877
Validation loss: 2.023449639479319

Epoch: 6| Step: 1
Training loss: 1.200850009918213
Validation loss: 2.0123784144719443

Epoch: 6| Step: 2
Training loss: 1.647712230682373
Validation loss: 2.0161396662394204

Epoch: 6| Step: 3
Training loss: 2.775933265686035
Validation loss: 1.9961042205492656

Epoch: 6| Step: 4
Training loss: 2.1197972297668457
Validation loss: 2.021663765112559

Epoch: 6| Step: 5
Training loss: 2.702026844024658
Validation loss: 2.0001588463783264

Epoch: 6| Step: 6
Training loss: 1.8670448064804077
Validation loss: 2.016295373439789

Epoch: 6| Step: 7
Training loss: 1.957176923751831
Validation loss: 2.0277199149131775

Epoch: 6| Step: 8
Training loss: 2.0854015350341797
Validation loss: 2.013666888078054

Epoch: 6| Step: 9
Training loss: 1.660827875137329
Validation loss: 2.0202535589536033

Epoch: 6| Step: 10
Training loss: 2.1328611373901367
Validation loss: 2.031245211760203

Epoch: 6| Step: 11
Training loss: 2.010982036590576
Validation loss: 2.0294729272524514

Epoch: 6| Step: 12
Training loss: 1.4014685153961182
Validation loss: 2.0343331893285117

Epoch: 6| Step: 13
Training loss: 2.556804656982422
Validation loss: 2.022234618663788

Epoch: 29| Step: 0
Training loss: 1.7207057476043701
Validation loss: 2.0168320337931314

Epoch: 6| Step: 1
Training loss: 1.1662265062332153
Validation loss: 2.0113295515378318

Epoch: 6| Step: 2
Training loss: 1.6301360130310059
Validation loss: 2.0130375226338706

Epoch: 6| Step: 3
Training loss: 3.067124605178833
Validation loss: 2.0229052901268005

Epoch: 6| Step: 4
Training loss: 1.9429316520690918
Validation loss: 2.016362210114797

Epoch: 6| Step: 5
Training loss: 1.7885782718658447
Validation loss: 2.0429134567578635

Epoch: 6| Step: 6
Training loss: 1.9530115127563477
Validation loss: 2.02279140551885

Epoch: 6| Step: 7
Training loss: 1.923870325088501
Validation loss: 2.0364298025767007

Epoch: 6| Step: 8
Training loss: 2.5223870277404785
Validation loss: 2.010080953439077

Epoch: 6| Step: 9
Training loss: 1.477068543434143
Validation loss: 2.029129763444265

Epoch: 6| Step: 10
Training loss: 1.9716652631759644
Validation loss: 2.023837665716807

Epoch: 6| Step: 11
Training loss: 1.9120738506317139
Validation loss: 2.005119740962982

Epoch: 6| Step: 12
Training loss: 1.9483294486999512
Validation loss: 2.0028537710507712

Epoch: 6| Step: 13
Training loss: 2.329124927520752
Validation loss: 2.031381924947103

Epoch: 30| Step: 0
Training loss: 2.4396092891693115
Validation loss: 2.0099581678708396

Epoch: 6| Step: 1
Training loss: 2.5364017486572266
Validation loss: 2.014647205670675

Epoch: 6| Step: 2
Training loss: 2.6647231578826904
Validation loss: 2.016393482685089

Epoch: 6| Step: 3
Training loss: 1.327054500579834
Validation loss: 2.0123957792917886

Epoch: 6| Step: 4
Training loss: 1.501495361328125
Validation loss: 2.012913703918457

Epoch: 6| Step: 5
Training loss: 1.4638428688049316
Validation loss: 2.005601644515991

Epoch: 6| Step: 6
Training loss: 1.5131876468658447
Validation loss: 2.0233915646870932

Epoch: 6| Step: 7
Training loss: 2.002610683441162
Validation loss: 2.002361317475637

Epoch: 6| Step: 8
Training loss: 2.435384511947632
Validation loss: 2.001281479994456

Epoch: 6| Step: 9
Training loss: 1.3615003824234009
Validation loss: 2.025700787703196

Epoch: 6| Step: 10
Training loss: 2.0305733680725098
Validation loss: 2.010310471057892

Epoch: 6| Step: 11
Training loss: 2.1320579051971436
Validation loss: 2.010353744029999

Epoch: 6| Step: 12
Training loss: 2.436342239379883
Validation loss: 2.0176422595977783

Epoch: 6| Step: 13
Training loss: 1.6036872863769531
Validation loss: 2.0124197403589883

Epoch: 31| Step: 0
Training loss: 2.435142755508423
Validation loss: 2.0041218996047974

Epoch: 6| Step: 1
Training loss: 2.436384677886963
Validation loss: 2.0076900720596313

Epoch: 6| Step: 2
Training loss: 1.0290392637252808
Validation loss: 2.005381186803182

Epoch: 6| Step: 3
Training loss: 1.837219476699829
Validation loss: 2.002872109413147

Epoch: 6| Step: 4
Training loss: 1.4478588104248047
Validation loss: 2.006448745727539

Epoch: 6| Step: 5
Training loss: 2.5117077827453613
Validation loss: 2.0108500520388284

Epoch: 6| Step: 6
Training loss: 1.6977285146713257
Validation loss: 2.008133848508199

Epoch: 6| Step: 7
Training loss: 1.5303642749786377
Validation loss: 2.0238704681396484

Epoch: 6| Step: 8
Training loss: 2.7190842628479004
Validation loss: 2.028893212477366

Epoch: 6| Step: 9
Training loss: 2.0973618030548096
Validation loss: 2.0253955125808716

Epoch: 6| Step: 10
Training loss: 2.2180488109588623
Validation loss: 2.00784424940745

Epoch: 6| Step: 11
Training loss: 1.193477749824524
Validation loss: 2.0091883142789206

Epoch: 6| Step: 12
Training loss: 2.343470573425293
Validation loss: 2.007115602493286

Epoch: 6| Step: 13
Training loss: 1.7923626899719238
Validation loss: 2.015918791294098

Epoch: 32| Step: 0
Training loss: 1.7481799125671387
Validation loss: 1.9948773582776387

Epoch: 6| Step: 1
Training loss: 2.8464231491088867
Validation loss: 2.019392192363739

Epoch: 6| Step: 2
Training loss: 1.5146265029907227
Validation loss: 2.0092697739601135

Epoch: 6| Step: 3
Training loss: 1.7941334247589111
Validation loss: 2.0119861165682473

Epoch: 6| Step: 4
Training loss: 1.8028920888900757
Validation loss: 2.017184555530548

Epoch: 6| Step: 5
Training loss: 2.6863503456115723
Validation loss: 2.0207884907722473

Epoch: 6| Step: 6
Training loss: 1.7967355251312256
Validation loss: 2.01307076215744

Epoch: 6| Step: 7
Training loss: 1.4486401081085205
Validation loss: 2.0072966615358987

Epoch: 6| Step: 8
Training loss: 1.5643020868301392
Validation loss: 2.013842682043711

Epoch: 6| Step: 9
Training loss: 1.6423108577728271
Validation loss: 1.9914026260375977

Epoch: 6| Step: 10
Training loss: 2.181533098220825
Validation loss: 2.002534886201223

Epoch: 6| Step: 11
Training loss: 1.382324457168579
Validation loss: 2.0094517866770425

Epoch: 6| Step: 12
Training loss: 2.2706098556518555
Validation loss: 2.0123366117477417

Epoch: 6| Step: 13
Training loss: 2.2787528038024902
Validation loss: 1.9988860090573628

Epoch: 33| Step: 0
Training loss: 1.6961207389831543
Validation loss: 2.0146548748016357

Epoch: 6| Step: 1
Training loss: 2.094280242919922
Validation loss: 2.047015686829885

Epoch: 6| Step: 2
Training loss: 1.9952718019485474
Validation loss: 2.0279765327771506

Epoch: 6| Step: 3
Training loss: 1.8379393815994263
Validation loss: 2.0559149583180747

Epoch: 6| Step: 4
Training loss: 1.4460722208023071
Validation loss: 2.070889671643575

Epoch: 6| Step: 5
Training loss: 1.9228370189666748
Validation loss: 2.036988894144694

Epoch: 6| Step: 6
Training loss: 2.227191925048828
Validation loss: 2.056747337182363

Epoch: 6| Step: 7
Training loss: 1.4937186241149902
Validation loss: 2.048362155755361

Epoch: 6| Step: 8
Training loss: 1.5713369846343994
Validation loss: 2.044426739215851

Epoch: 6| Step: 9
Training loss: 2.0210680961608887
Validation loss: 2.0646219650904336

Epoch: 6| Step: 10
Training loss: 2.402838706970215
Validation loss: 2.0221375226974487

Epoch: 6| Step: 11
Training loss: 1.8004753589630127
Validation loss: 2.004612227280935

Epoch: 6| Step: 12
Training loss: 2.6461892127990723
Validation loss: 2.017487347126007

Epoch: 6| Step: 13
Training loss: 2.098092555999756
Validation loss: 2.01638134320577

Epoch: 34| Step: 0
Training loss: 1.308663010597229
Validation loss: 2.005009174346924

Epoch: 6| Step: 1
Training loss: 2.4457015991210938
Validation loss: 2.0095689495404563

Epoch: 6| Step: 2
Training loss: 1.8647781610488892
Validation loss: 2.0096867879231772

Epoch: 6| Step: 3
Training loss: 2.164820909500122
Validation loss: 2.0240565737088523

Epoch: 6| Step: 4
Training loss: 1.93791925907135
Validation loss: 2.0191216270128884

Epoch: 6| Step: 5
Training loss: 1.522512674331665
Validation loss: 1.9916031956672668

Epoch: 6| Step: 6
Training loss: 3.0773539543151855
Validation loss: 2.003324866294861

Epoch: 6| Step: 7
Training loss: 2.095301628112793
Validation loss: 1.984424392382304

Epoch: 6| Step: 8
Training loss: 1.345409870147705
Validation loss: 2.0165653228759766

Epoch: 6| Step: 9
Training loss: 2.080197334289551
Validation loss: 2.0163188775380454

Epoch: 6| Step: 10
Training loss: 2.1359596252441406
Validation loss: 1.997531274954478

Epoch: 6| Step: 11
Training loss: 1.9886101484298706
Validation loss: 2.0220277110735574

Epoch: 6| Step: 12
Training loss: 2.3644683361053467
Validation loss: 2.0054535468419394

Epoch: 6| Step: 13
Training loss: 1.054753303527832
Validation loss: 2.0346410671869912

Epoch: 35| Step: 0
Training loss: 2.1796579360961914
Validation loss: 2.0154998699824014

Epoch: 6| Step: 1
Training loss: 1.9198565483093262
Validation loss: 1.9978941480318706

Epoch: 6| Step: 2
Training loss: 2.17985463142395
Validation loss: 2.0240822434425354

Epoch: 6| Step: 3
Training loss: 1.807551622390747
Validation loss: 2.052843153476715

Epoch: 6| Step: 4
Training loss: 1.81793212890625
Validation loss: 2.033451497554779

Epoch: 6| Step: 5
Training loss: 1.789014220237732
Validation loss: 2.0360587437947593

Epoch: 6| Step: 6
Training loss: 2.078153133392334
Validation loss: 2.0122239192326865

Epoch: 6| Step: 7
Training loss: 1.4759268760681152
Validation loss: 2.0255293448766074

Epoch: 6| Step: 8
Training loss: 2.449507474899292
Validation loss: 2.00175541639328

Epoch: 6| Step: 9
Training loss: 1.7522257566452026
Validation loss: 2.028680125872294

Epoch: 6| Step: 10
Training loss: 1.7247989177703857
Validation loss: 2.0456139047940574

Epoch: 6| Step: 11
Training loss: 2.464595317840576
Validation loss: 2.0496917565663657

Epoch: 6| Step: 12
Training loss: 2.3569579124450684
Validation loss: 2.0333667596181235

Epoch: 6| Step: 13
Training loss: 1.0679478645324707
Validation loss: 2.0193289319674173

Epoch: 36| Step: 0
Training loss: 1.2765295505523682
Validation loss: 2.0132378737131753

Epoch: 6| Step: 1
Training loss: 2.043093681335449
Validation loss: 2.02284969886144

Epoch: 6| Step: 2
Training loss: 1.4016737937927246
Validation loss: 1.9790815114974976

Epoch: 6| Step: 3
Training loss: 1.5242581367492676
Validation loss: 1.9919638832410176

Epoch: 6| Step: 4
Training loss: 1.76153564453125
Validation loss: 2.01137642065684

Epoch: 6| Step: 5
Training loss: 2.585475444793701
Validation loss: 2.019419511159261

Epoch: 6| Step: 6
Training loss: 1.8704111576080322
Validation loss: 1.990968366463979

Epoch: 6| Step: 7
Training loss: 2.7365376949310303
Validation loss: 2.002083400885264

Epoch: 6| Step: 8
Training loss: 1.9140045642852783
Validation loss: 1.9974228938420613

Epoch: 6| Step: 9
Training loss: 2.030827045440674
Validation loss: 1.9906419515609741

Epoch: 6| Step: 10
Training loss: 2.3640666007995605
Validation loss: 1.988718589146932

Epoch: 6| Step: 11
Training loss: 1.4747657775878906
Validation loss: 2.005849619706472

Epoch: 6| Step: 12
Training loss: 2.002622127532959
Validation loss: 2.004366417725881

Epoch: 6| Step: 13
Training loss: 1.775909662246704
Validation loss: 2.0024290084838867

Epoch: 37| Step: 0
Training loss: 1.9672738313674927
Validation loss: 2.0204391280810037

Epoch: 6| Step: 1
Training loss: 2.0475945472717285
Validation loss: 1.9952990611394246

Epoch: 6| Step: 2
Training loss: 1.8061466217041016
Validation loss: 2.012073536713918

Epoch: 6| Step: 3
Training loss: 1.607206106185913
Validation loss: 2.0162418683369956

Epoch: 6| Step: 4
Training loss: 2.200683355331421
Validation loss: 2.00541744629542

Epoch: 6| Step: 5
Training loss: 1.5404767990112305
Validation loss: 2.0197315414746604

Epoch: 6| Step: 6
Training loss: 1.740016222000122
Validation loss: 2.024272898832957

Epoch: 6| Step: 7
Training loss: 2.22123384475708
Validation loss: 2.036903897921244

Epoch: 6| Step: 8
Training loss: 1.2078721523284912
Validation loss: 2.007449189821879

Epoch: 6| Step: 9
Training loss: 2.7019519805908203
Validation loss: 2.011362612247467

Epoch: 6| Step: 10
Training loss: 1.9279042482376099
Validation loss: 2.0275001724561057

Epoch: 6| Step: 11
Training loss: 2.169957399368286
Validation loss: 2.0122769276301065

Epoch: 6| Step: 12
Training loss: 1.4576102495193481
Validation loss: 1.9919643799463909

Epoch: 6| Step: 13
Training loss: 2.1976733207702637
Validation loss: 1.9921025435129802

Epoch: 38| Step: 0
Training loss: 1.533179521560669
Validation loss: 2.0247023701667786

Epoch: 6| Step: 1
Training loss: 1.9580967426300049
Validation loss: 2.002791702747345

Epoch: 6| Step: 2
Training loss: 1.4983278512954712
Validation loss: 1.9994375507036846

Epoch: 6| Step: 3
Training loss: 2.284392833709717
Validation loss: 2.014629820982615

Epoch: 6| Step: 4
Training loss: 2.1617233753204346
Validation loss: 2.0072667797406516

Epoch: 6| Step: 5
Training loss: 1.687518835067749
Validation loss: 1.991687496503194

Epoch: 6| Step: 6
Training loss: 1.7408050298690796
Validation loss: 2.0308929085731506

Epoch: 6| Step: 7
Training loss: 2.061326026916504
Validation loss: 2.0193000038464866

Epoch: 6| Step: 8
Training loss: 2.7144923210144043
Validation loss: 2.0084195137023926

Epoch: 6| Step: 9
Training loss: 1.7678632736206055
Validation loss: 1.9906288385391235

Epoch: 6| Step: 10
Training loss: 1.7620322704315186
Validation loss: 2.0090978741645813

Epoch: 6| Step: 11
Training loss: 2.1786723136901855
Validation loss: 2.007756312688192

Epoch: 6| Step: 12
Training loss: 1.3829338550567627
Validation loss: 1.978426496187846

Epoch: 6| Step: 13
Training loss: 1.9440041780471802
Validation loss: 2.0045476953188577

Epoch: 39| Step: 0
Training loss: 1.9358632564544678
Validation loss: 2.009730815887451

Epoch: 6| Step: 1
Training loss: 1.815651535987854
Validation loss: 2.0061727364857993

Epoch: 6| Step: 2
Training loss: 2.073955774307251
Validation loss: 2.0069172779719033

Epoch: 6| Step: 3
Training loss: 1.7024025917053223
Validation loss: 2.016714632511139

Epoch: 6| Step: 4
Training loss: 2.229625940322876
Validation loss: 2.0100976626078286

Epoch: 6| Step: 5
Training loss: 1.9428904056549072
Validation loss: 2.016735037167867

Epoch: 6| Step: 6
Training loss: 1.6140936613082886
Validation loss: 1.9871323903401692

Epoch: 6| Step: 7
Training loss: 1.444935917854309
Validation loss: 2.001800537109375

Epoch: 6| Step: 8
Training loss: 2.176973819732666
Validation loss: 1.9994836449623108

Epoch: 6| Step: 9
Training loss: 1.9464771747589111
Validation loss: 2.0073610146840415

Epoch: 6| Step: 10
Training loss: 1.7029919624328613
Validation loss: 2.0075212121009827

Epoch: 6| Step: 11
Training loss: 2.268221616744995
Validation loss: 2.0313117106755576

Epoch: 6| Step: 12
Training loss: 1.7246493101119995
Validation loss: 2.062952140967051

Epoch: 6| Step: 13
Training loss: 1.972453236579895
Validation loss: 2.0641000469525657

Epoch: 40| Step: 0
Training loss: 1.6975126266479492
Validation loss: 2.0665910641352334

Epoch: 6| Step: 1
Training loss: 1.5457696914672852
Validation loss: 2.051180362701416

Epoch: 6| Step: 2
Training loss: 2.5456326007843018
Validation loss: 2.04226807753245

Epoch: 6| Step: 3
Training loss: 2.207242965698242
Validation loss: 2.0361489256223044

Epoch: 6| Step: 4
Training loss: 1.3217213153839111
Validation loss: 2.0361792047818503

Epoch: 6| Step: 5
Training loss: 2.691596508026123
Validation loss: 2.0074417988459268

Epoch: 6| Step: 6
Training loss: 1.6871758699417114
Validation loss: 2.0303157766660056

Epoch: 6| Step: 7
Training loss: 2.3419246673583984
Validation loss: 1.997505784034729

Epoch: 6| Step: 8
Training loss: 1.2399320602416992
Validation loss: 1.9837393561999004

Epoch: 6| Step: 9
Training loss: 2.1851208209991455
Validation loss: 1.979537347952525

Epoch: 6| Step: 10
Training loss: 1.4609637260437012
Validation loss: 2.018819590409597

Epoch: 6| Step: 11
Training loss: 1.327177882194519
Validation loss: 1.9810123244921367

Epoch: 6| Step: 12
Training loss: 2.2274701595306396
Validation loss: 2.0324036677678428

Epoch: 6| Step: 13
Training loss: 2.1443862915039062
Validation loss: 1.9847946365674336

Epoch: 41| Step: 0
Training loss: 2.068843364715576
Validation loss: 1.9845421711603801

Epoch: 6| Step: 1
Training loss: 2.4003355503082275
Validation loss: 1.9828527967135112

Epoch: 6| Step: 2
Training loss: 1.585433006286621
Validation loss: 2.016642451286316

Epoch: 6| Step: 3
Training loss: 0.9158985018730164
Validation loss: 2.034628987312317

Epoch: 6| Step: 4
Training loss: 1.967491865158081
Validation loss: 2.0034022529919944

Epoch: 6| Step: 5
Training loss: 2.3916444778442383
Validation loss: 2.0111959973971048

Epoch: 6| Step: 6
Training loss: 2.105297803878784
Validation loss: 2.019510825475057

Epoch: 6| Step: 7
Training loss: 1.7616338729858398
Validation loss: 2.0173901518185935

Epoch: 6| Step: 8
Training loss: 1.3197715282440186
Validation loss: 2.014401932557424

Epoch: 6| Step: 9
Training loss: 2.427985668182373
Validation loss: 2.006252725919088

Epoch: 6| Step: 10
Training loss: 2.0957627296447754
Validation loss: 2.0008883476257324

Epoch: 6| Step: 11
Training loss: 1.5425605773925781
Validation loss: 2.018787980079651

Epoch: 6| Step: 12
Training loss: 1.717055082321167
Validation loss: 2.0264777541160583

Epoch: 6| Step: 13
Training loss: 1.9970264434814453
Validation loss: 2.0281951427459717

Epoch: 42| Step: 0
Training loss: 1.66069495677948
Validation loss: 2.029279033342997

Epoch: 6| Step: 1
Training loss: 2.442261219024658
Validation loss: 1.9849196672439575

Epoch: 6| Step: 2
Training loss: 1.529939889907837
Validation loss: 2.0511833826700845

Epoch: 6| Step: 3
Training loss: 1.6281025409698486
Validation loss: 2.0234260161717734

Epoch: 6| Step: 4
Training loss: 1.2842211723327637
Validation loss: 2.0243634581565857

Epoch: 6| Step: 5
Training loss: 2.4392404556274414
Validation loss: 2.034467260042826

Epoch: 6| Step: 6
Training loss: 1.3065228462219238
Validation loss: 2.0356650352478027

Epoch: 6| Step: 7
Training loss: 1.7173150777816772
Validation loss: 2.0348591009775796

Epoch: 6| Step: 8
Training loss: 2.7028400897979736
Validation loss: 2.0111619035402932

Epoch: 6| Step: 9
Training loss: 1.6941211223602295
Validation loss: 2.0254480044047036

Epoch: 6| Step: 10
Training loss: 2.202366352081299
Validation loss: 2.0021859407424927

Epoch: 6| Step: 11
Training loss: 2.4328153133392334
Validation loss: 2.029167572657267

Epoch: 6| Step: 12
Training loss: 2.0241730213165283
Validation loss: 2.0123427311579385

Epoch: 6| Step: 13
Training loss: 1.426447868347168
Validation loss: 1.9920209646224976

Epoch: 43| Step: 0
Training loss: 1.5743532180786133
Validation loss: 1.9940689603487651

Epoch: 6| Step: 1
Training loss: 1.489810824394226
Validation loss: 1.9821093877156575

Epoch: 6| Step: 2
Training loss: 1.590138554573059
Validation loss: 2.007010797659556

Epoch: 6| Step: 3
Training loss: 2.0560145378112793
Validation loss: 1.9928988019625347

Epoch: 6| Step: 4
Training loss: 1.6316239833831787
Validation loss: 1.9868313074111938

Epoch: 6| Step: 5
Training loss: 2.0481016635894775
Validation loss: 1.9920241634051006

Epoch: 6| Step: 6
Training loss: 1.8247566223144531
Validation loss: 1.99176953236262

Epoch: 6| Step: 7
Training loss: 1.8400988578796387
Validation loss: 1.996295173962911

Epoch: 6| Step: 8
Training loss: 2.553729772567749
Validation loss: 2.0141777396202087

Epoch: 6| Step: 9
Training loss: 1.9782180786132812
Validation loss: 1.9916213353474934

Epoch: 6| Step: 10
Training loss: 1.7299922704696655
Validation loss: 2.002998729546865

Epoch: 6| Step: 11
Training loss: 1.8448402881622314
Validation loss: 1.9970656236012776

Epoch: 6| Step: 12
Training loss: 1.9204707145690918
Validation loss: 2.020850976308187

Epoch: 6| Step: 13
Training loss: 2.4413275718688965
Validation loss: 2.0422533750534058

Epoch: 44| Step: 0
Training loss: 1.7923425436019897
Validation loss: 2.0584644277890525

Epoch: 6| Step: 1
Training loss: 2.0358309745788574
Validation loss: 2.0553032557169595

Epoch: 6| Step: 2
Training loss: 1.8264379501342773
Validation loss: 2.049938758214315

Epoch: 6| Step: 3
Training loss: 2.76265811920166
Validation loss: 2.0535301764806113

Epoch: 6| Step: 4
Training loss: 2.045647144317627
Validation loss: 2.046218772729238

Epoch: 6| Step: 5
Training loss: 1.9636235237121582
Validation loss: 2.0464778542518616

Epoch: 6| Step: 6
Training loss: 1.743930459022522
Validation loss: 2.038667599360148

Epoch: 6| Step: 7
Training loss: 1.24744713306427
Validation loss: 2.009595255057017

Epoch: 6| Step: 8
Training loss: 1.6583302021026611
Validation loss: 2.011299967765808

Epoch: 6| Step: 9
Training loss: 1.747962236404419
Validation loss: 2.021227757136027

Epoch: 6| Step: 10
Training loss: 1.874351978302002
Validation loss: 2.0277887185414634

Epoch: 6| Step: 11
Training loss: 1.6502834558486938
Validation loss: 2.0007309913635254

Epoch: 6| Step: 12
Training loss: 2.3999266624450684
Validation loss: 1.9997124671936035

Epoch: 6| Step: 13
Training loss: 1.4887038469314575
Validation loss: 1.9872158368428547

Epoch: 45| Step: 0
Training loss: 1.4851303100585938
Validation loss: 1.9871890942255657

Epoch: 6| Step: 1
Training loss: 1.656019926071167
Validation loss: 2.032648821671804

Epoch: 6| Step: 2
Training loss: 1.8485193252563477
Validation loss: 2.016847630341848

Epoch: 6| Step: 3
Training loss: 2.077609062194824
Validation loss: 2.007596810658773

Epoch: 6| Step: 4
Training loss: 1.7114284038543701
Validation loss: 1.9740567604700725

Epoch: 6| Step: 5
Training loss: 1.4785511493682861
Validation loss: 2.0139907598495483

Epoch: 6| Step: 6
Training loss: 1.780935287475586
Validation loss: 1.997120161851247

Epoch: 6| Step: 7
Training loss: 2.135394334793091
Validation loss: 2.025235573450724

Epoch: 6| Step: 8
Training loss: 1.4152040481567383
Validation loss: 2.00737464427948

Epoch: 6| Step: 9
Training loss: 2.6710457801818848
Validation loss: 1.9865869879722595

Epoch: 6| Step: 10
Training loss: 2.363924980163574
Validation loss: 2.0162041187286377

Epoch: 6| Step: 11
Training loss: 1.4305897951126099
Validation loss: 2.015954573949178

Epoch: 6| Step: 12
Training loss: 2.203275203704834
Validation loss: 2.04373300075531

Epoch: 6| Step: 13
Training loss: 1.7867965698242188
Validation loss: 2.0273523529370627

Epoch: 46| Step: 0
Training loss: 2.0414421558380127
Validation loss: 1.9916711449623108

Epoch: 6| Step: 1
Training loss: 1.7930362224578857
Validation loss: 2.0208921233812966

Epoch: 6| Step: 2
Training loss: 1.715463638305664
Validation loss: 2.027633627255758

Epoch: 6| Step: 3
Training loss: 1.3019850254058838
Validation loss: 1.9911552667617798

Epoch: 6| Step: 4
Training loss: 1.7602417469024658
Validation loss: 1.9875750343004863

Epoch: 6| Step: 5
Training loss: 2.212083339691162
Validation loss: 2.000176787376404

Epoch: 6| Step: 6
Training loss: 2.1164586544036865
Validation loss: 1.9950424432754517

Epoch: 6| Step: 7
Training loss: 1.3282749652862549
Validation loss: 1.9696487188339233

Epoch: 6| Step: 8
Training loss: 2.134249210357666
Validation loss: 1.98445067803065

Epoch: 6| Step: 9
Training loss: 1.4136735200881958
Validation loss: 2.0264919201533

Epoch: 6| Step: 10
Training loss: 2.6363184452056885
Validation loss: 2.057530462741852

Epoch: 6| Step: 11
Training loss: 1.925357460975647
Validation loss: 2.063508172829946

Epoch: 6| Step: 12
Training loss: 1.8224031925201416
Validation loss: 2.0420907537142434

Epoch: 6| Step: 13
Training loss: 2.105748176574707
Validation loss: 2.0485356648763022

Epoch: 47| Step: 0
Training loss: 1.3277544975280762
Validation loss: 2.0365243951479592

Epoch: 6| Step: 1
Training loss: 1.254846453666687
Validation loss: 2.032888094584147

Epoch: 6| Step: 2
Training loss: 1.5619200468063354
Validation loss: 2.058674176534017

Epoch: 6| Step: 3
Training loss: 1.5669775009155273
Validation loss: 2.0466135144233704

Epoch: 6| Step: 4
Training loss: 2.374377727508545
Validation loss: 2.0561189452807107

Epoch: 6| Step: 5
Training loss: 1.3781975507736206
Validation loss: 2.0161771376927695

Epoch: 6| Step: 6
Training loss: 1.7386372089385986
Validation loss: 2.021936853726705

Epoch: 6| Step: 7
Training loss: 2.4708616733551025
Validation loss: 2.0068196058273315

Epoch: 6| Step: 8
Training loss: 2.3093276023864746
Validation loss: 1.9960291186968486

Epoch: 6| Step: 9
Training loss: 1.4793328046798706
Validation loss: 2.036426285902659

Epoch: 6| Step: 10
Training loss: 2.5756940841674805
Validation loss: 1.9838801821072896

Epoch: 6| Step: 11
Training loss: 2.074932098388672
Validation loss: 2.0160107413927713

Epoch: 6| Step: 12
Training loss: 2.107733726501465
Validation loss: 2.0081478158632913

Epoch: 6| Step: 13
Training loss: 1.5863598585128784
Validation loss: 2.0206310947736106

Epoch: 48| Step: 0
Training loss: 2.2560110092163086
Validation loss: 2.004587411880493

Epoch: 6| Step: 1
Training loss: 2.0374574661254883
Validation loss: 1.9983285268147786

Epoch: 6| Step: 2
Training loss: 1.3820910453796387
Validation loss: 2.015883723894755

Epoch: 6| Step: 3
Training loss: 1.889479637145996
Validation loss: 2.0219417015711465

Epoch: 6| Step: 4
Training loss: 1.6832823753356934
Validation loss: 1.9964067538579304

Epoch: 6| Step: 5
Training loss: 3.099024772644043
Validation loss: 1.98726890484492

Epoch: 6| Step: 6
Training loss: 1.6303297281265259
Validation loss: 2.005374292532603

Epoch: 6| Step: 7
Training loss: 1.825881004333496
Validation loss: 1.9963681896527607

Epoch: 6| Step: 8
Training loss: 1.8635188341140747
Validation loss: 1.9795875151952107

Epoch: 6| Step: 9
Training loss: 1.7838022708892822
Validation loss: 1.9794809420903523

Epoch: 6| Step: 10
Training loss: 1.9506553411483765
Validation loss: 1.9925965468088787

Epoch: 6| Step: 11
Training loss: 1.0919097661972046
Validation loss: 2.0117607911427817

Epoch: 6| Step: 12
Training loss: 1.8063725233078003
Validation loss: 2.0782082875569663

Epoch: 6| Step: 13
Training loss: 1.4402942657470703
Validation loss: 2.0478448073069253

Epoch: 49| Step: 0
Training loss: 1.9121729135513306
Validation loss: 2.0631577173868814

Epoch: 6| Step: 1
Training loss: 1.9615223407745361
Validation loss: 2.0838993191719055

Epoch: 6| Step: 2
Training loss: 1.5223711729049683
Validation loss: 2.062882681687673

Epoch: 6| Step: 3
Training loss: 1.49259614944458
Validation loss: 2.093107541402181

Epoch: 6| Step: 4
Training loss: 1.165730357170105
Validation loss: 2.105067948500315

Epoch: 6| Step: 5
Training loss: 2.1720128059387207
Validation loss: 2.087944209575653

Epoch: 6| Step: 6
Training loss: 2.1689367294311523
Validation loss: 2.0485167702039084

Epoch: 6| Step: 7
Training loss: 2.0740156173706055
Validation loss: 2.0464760859807334

Epoch: 6| Step: 8
Training loss: 1.8700127601623535
Validation loss: 1.9957938591639202

Epoch: 6| Step: 9
Training loss: 2.9068541526794434
Validation loss: 2.0138869682947793

Epoch: 6| Step: 10
Training loss: 1.7746901512145996
Validation loss: 2.0052895148595176

Epoch: 6| Step: 11
Training loss: 1.3094449043273926
Validation loss: 2.0052635073661804

Epoch: 6| Step: 12
Training loss: 2.0585949420928955
Validation loss: 2.0257763266563416

Epoch: 6| Step: 13
Training loss: 1.4904839992523193
Validation loss: 2.005304455757141

Epoch: 50| Step: 0
Training loss: 2.294243812561035
Validation loss: 1.9948010245958965

Epoch: 6| Step: 1
Training loss: 1.7184882164001465
Validation loss: 1.9959107637405396

Epoch: 6| Step: 2
Training loss: 1.6138901710510254
Validation loss: 1.9923481146494548

Epoch: 6| Step: 3
Training loss: 1.6258769035339355
Validation loss: 2.000944495201111

Epoch: 6| Step: 4
Training loss: 1.421101689338684
Validation loss: 2.015366554260254

Epoch: 6| Step: 5
Training loss: 2.3322157859802246
Validation loss: 2.008833110332489

Epoch: 6| Step: 6
Training loss: 2.4354615211486816
Validation loss: 2.0304155945777893

Epoch: 6| Step: 7
Training loss: 2.1879119873046875
Validation loss: 2.007675051689148

Epoch: 6| Step: 8
Training loss: 1.501737117767334
Validation loss: 2.0409268140792847

Epoch: 6| Step: 9
Training loss: 1.3008496761322021
Validation loss: 2.00872266292572

Epoch: 6| Step: 10
Training loss: 2.3006255626678467
Validation loss: 2.0240438977877298

Epoch: 6| Step: 11
Training loss: 1.012660264968872
Validation loss: 1.995648185412089

Epoch: 6| Step: 12
Training loss: 2.5102596282958984
Validation loss: 1.9979228973388672

Epoch: 6| Step: 13
Training loss: 1.5406352281570435
Validation loss: 2.0043480594952903

Epoch: 51| Step: 0
Training loss: 1.8192933797836304
Validation loss: 2.0187228322029114

Epoch: 6| Step: 1
Training loss: 2.0758538246154785
Validation loss: 2.0094807147979736

Epoch: 6| Step: 2
Training loss: 1.5473006963729858
Validation loss: 2.0166515906651816

Epoch: 6| Step: 3
Training loss: 1.3311872482299805
Validation loss: 2.0026283661524453

Epoch: 6| Step: 4
Training loss: 1.8156697750091553
Validation loss: 2.009623130162557

Epoch: 6| Step: 5
Training loss: 1.446974515914917
Validation loss: 1.9703787962595622

Epoch: 6| Step: 6
Training loss: 1.8914918899536133
Validation loss: 2.00516806046168

Epoch: 6| Step: 7
Training loss: 2.366197109222412
Validation loss: 1.9695699016253154

Epoch: 6| Step: 8
Training loss: 1.8712536096572876
Validation loss: 1.9873310724894206

Epoch: 6| Step: 9
Training loss: 1.9557551145553589
Validation loss: 2.0103468894958496

Epoch: 6| Step: 10
Training loss: 2.151383399963379
Validation loss: 2.0228640039761863

Epoch: 6| Step: 11
Training loss: 1.6384116411209106
Validation loss: 2.0111942291259766

Epoch: 6| Step: 12
Training loss: 1.906730055809021
Validation loss: 1.9981461962064107

Epoch: 6| Step: 13
Training loss: 1.9098767042160034
Validation loss: 2.0173365076382956

Epoch: 52| Step: 0
Training loss: 1.8436933755874634
Validation loss: 2.0254117051760354

Epoch: 6| Step: 1
Training loss: 2.329821825027466
Validation loss: 2.014062285423279

Epoch: 6| Step: 2
Training loss: 1.8807919025421143
Validation loss: 2.022985259691874

Epoch: 6| Step: 3
Training loss: 1.8134411573410034
Validation loss: 2.0529560645421348

Epoch: 6| Step: 4
Training loss: 1.7776525020599365
Validation loss: 2.0498046875

Epoch: 6| Step: 5
Training loss: 2.2028329372406006
Validation loss: 2.0407075683275857

Epoch: 6| Step: 6
Training loss: 1.6247272491455078
Validation loss: 2.0255573193232217

Epoch: 6| Step: 7
Training loss: 2.1198890209198
Validation loss: 2.05376398563385

Epoch: 6| Step: 8
Training loss: 1.844036340713501
Validation loss: 2.016707181930542

Epoch: 6| Step: 9
Training loss: 1.9079713821411133
Validation loss: 2.0211680134137473

Epoch: 6| Step: 10
Training loss: 1.828357219696045
Validation loss: 2.050807535648346

Epoch: 6| Step: 11
Training loss: 1.4387646913528442
Validation loss: 2.0194461743036904

Epoch: 6| Step: 12
Training loss: 1.1882835626602173
Validation loss: 2.0140708684921265

Epoch: 6| Step: 13
Training loss: 1.8097002506256104
Validation loss: 1.9906785488128662

Epoch: 53| Step: 0
Training loss: 1.8119583129882812
Validation loss: 2.0119815866152444

Epoch: 6| Step: 1
Training loss: 1.5671340227127075
Validation loss: 1.9997687538464863

Epoch: 6| Step: 2
Training loss: 2.2102835178375244
Validation loss: 1.9950863122940063

Epoch: 6| Step: 3
Training loss: 2.9218411445617676
Validation loss: 1.9947285453478496

Epoch: 6| Step: 4
Training loss: 1.8721015453338623
Validation loss: 1.9968405365943909

Epoch: 6| Step: 5
Training loss: 1.4073524475097656
Validation loss: 1.9800850749015808

Epoch: 6| Step: 6
Training loss: 2.1006054878234863
Validation loss: 1.9783801436424255

Epoch: 6| Step: 7
Training loss: 1.4275949001312256
Validation loss: 1.9707876443862915

Epoch: 6| Step: 8
Training loss: 1.60916268825531
Validation loss: 1.9798556764920552

Epoch: 6| Step: 9
Training loss: 1.0053074359893799
Validation loss: 1.976386268933614

Epoch: 6| Step: 10
Training loss: 1.8320105075836182
Validation loss: 2.0227343837420144

Epoch: 6| Step: 11
Training loss: 2.0175321102142334
Validation loss: 2.01271382967631

Epoch: 6| Step: 12
Training loss: 1.5592803955078125
Validation loss: 2.0736231605211892

Epoch: 6| Step: 13
Training loss: 2.03775954246521
Validation loss: 1.9889604250590007

Epoch: 54| Step: 0
Training loss: 1.6111390590667725
Validation loss: 2.043323040008545

Epoch: 6| Step: 1
Training loss: 1.2579259872436523
Validation loss: 2.022891581058502

Epoch: 6| Step: 2
Training loss: 2.076319456100464
Validation loss: 2.012377222379049

Epoch: 6| Step: 3
Training loss: 1.7831027507781982
Validation loss: 2.0352224508921304

Epoch: 6| Step: 4
Training loss: 1.8591004610061646
Validation loss: 2.02124692996343

Epoch: 6| Step: 5
Training loss: 1.1068916320800781
Validation loss: 2.0037243962287903

Epoch: 6| Step: 6
Training loss: 2.210354804992676
Validation loss: 1.9877131581306458

Epoch: 6| Step: 7
Training loss: 1.4111754894256592
Validation loss: 1.9873608946800232

Epoch: 6| Step: 8
Training loss: 2.4901652336120605
Validation loss: 2.015051861604055

Epoch: 6| Step: 9
Training loss: 2.37735652923584
Validation loss: 1.9936087131500244

Epoch: 6| Step: 10
Training loss: 1.4525628089904785
Validation loss: 2.0134990016619363

Epoch: 6| Step: 11
Training loss: 2.446305751800537
Validation loss: 1.979261616865794

Epoch: 6| Step: 12
Training loss: 1.370545506477356
Validation loss: 2.010324776172638

Epoch: 6| Step: 13
Training loss: 2.2910118103027344
Validation loss: 1.9807740052541096

Epoch: 55| Step: 0
Training loss: 1.8040804862976074
Validation loss: 2.001101493835449

Epoch: 6| Step: 1
Training loss: 1.101942777633667
Validation loss: 2.017530858516693

Epoch: 6| Step: 2
Training loss: 1.6132006645202637
Validation loss: 2.045242130756378

Epoch: 6| Step: 3
Training loss: 1.6598279476165771
Validation loss: 2.0618595282236734

Epoch: 6| Step: 4
Training loss: 2.186617612838745
Validation loss: 2.0779715180397034

Epoch: 6| Step: 5
Training loss: 1.1630711555480957
Validation loss: 2.0664144158363342

Epoch: 6| Step: 6
Training loss: 2.1150412559509277
Validation loss: 2.054241498311361

Epoch: 6| Step: 7
Training loss: 2.12963604927063
Validation loss: 2.0326574246088662

Epoch: 6| Step: 8
Training loss: 1.7177549600601196
Validation loss: 2.047147572040558

Epoch: 6| Step: 9
Training loss: 2.441603899002075
Validation loss: 2.0422097047170005

Epoch: 6| Step: 10
Training loss: 1.6714446544647217
Validation loss: 2.0483418305714927

Epoch: 6| Step: 11
Training loss: 1.5214576721191406
Validation loss: 2.0253373781840005

Epoch: 6| Step: 12
Training loss: 1.5015387535095215
Validation loss: 1.9859267473220825

Epoch: 6| Step: 13
Training loss: 2.825251579284668
Validation loss: 2.013885974884033

Epoch: 56| Step: 0
Training loss: 2.3154048919677734
Validation loss: 2.0069127678871155

Epoch: 6| Step: 1
Training loss: 1.593090534210205
Validation loss: 2.002755562464396

Epoch: 6| Step: 2
Training loss: 1.5198979377746582
Validation loss: 2.0303168892860413

Epoch: 6| Step: 3
Training loss: 1.6017301082611084
Validation loss: 2.01144673426946

Epoch: 6| Step: 4
Training loss: 1.662480354309082
Validation loss: 1.99799640973409

Epoch: 6| Step: 5
Training loss: 1.7973475456237793
Validation loss: 1.9870742360750835

Epoch: 6| Step: 6
Training loss: 1.9763041734695435
Validation loss: 2.0252734621365867

Epoch: 6| Step: 7
Training loss: 1.727515697479248
Validation loss: 1.9859410524368286

Epoch: 6| Step: 8
Training loss: 1.7968980073928833
Validation loss: 1.9484904209772747

Epoch: 6| Step: 9
Training loss: 1.875940203666687
Validation loss: 1.9971823294957478

Epoch: 6| Step: 10
Training loss: 1.7166857719421387
Validation loss: 2.016080637772878

Epoch: 6| Step: 11
Training loss: 1.6105082035064697
Validation loss: 2.0171907941500344

Epoch: 6| Step: 12
Training loss: 2.424443483352661
Validation loss: 2.011765400568644

Epoch: 6| Step: 13
Training loss: 1.3797842264175415
Validation loss: 2.013302286465963

Epoch: 57| Step: 0
Training loss: 1.6461150646209717
Validation loss: 1.9989811182022095

Epoch: 6| Step: 1
Training loss: 2.04852032661438
Validation loss: 2.048785706361135

Epoch: 6| Step: 2
Training loss: 2.034566879272461
Validation loss: 2.075199842453003

Epoch: 6| Step: 3
Training loss: 1.9558563232421875
Validation loss: 2.054015835126241

Epoch: 6| Step: 4
Training loss: 1.093063473701477
Validation loss: 2.0603119333585105

Epoch: 6| Step: 5
Training loss: 2.670524835586548
Validation loss: 2.021522045135498

Epoch: 6| Step: 6
Training loss: 1.6889570951461792
Validation loss: 2.009642740090688

Epoch: 6| Step: 7
Training loss: 1.8787188529968262
Validation loss: 1.990150233109792

Epoch: 6| Step: 8
Training loss: 1.4853951930999756
Validation loss: 1.9869062503178914

Epoch: 6| Step: 9
Training loss: 1.5823523998260498
Validation loss: 2.011643926302592

Epoch: 6| Step: 10
Training loss: 1.798783540725708
Validation loss: 1.9967225988705952

Epoch: 6| Step: 11
Training loss: 1.5793282985687256
Validation loss: 2.0076112349828086

Epoch: 6| Step: 12
Training loss: 1.7997257709503174
Validation loss: 1.980823775132497

Epoch: 6| Step: 13
Training loss: 1.6903095245361328
Validation loss: 2.0353914896647134

Epoch: 58| Step: 0
Training loss: 1.4902503490447998
Validation loss: 2.0215131839116416

Epoch: 6| Step: 1
Training loss: 2.128389835357666
Validation loss: 2.0144476890563965

Epoch: 6| Step: 2
Training loss: 1.1691789627075195
Validation loss: 2.0246378978093467

Epoch: 6| Step: 3
Training loss: 1.2974393367767334
Validation loss: 2.0589837233225503

Epoch: 6| Step: 4
Training loss: 2.386993408203125
Validation loss: 2.051157593727112

Epoch: 6| Step: 5
Training loss: 2.073086977005005
Validation loss: 2.0486650466918945

Epoch: 6| Step: 6
Training loss: 1.053116798400879
Validation loss: 1.9987101356188457

Epoch: 6| Step: 7
Training loss: 1.0369963645935059
Validation loss: 2.044627547264099

Epoch: 6| Step: 8
Training loss: 2.1354568004608154
Validation loss: 2.0380605260531106

Epoch: 6| Step: 9
Training loss: 2.6611781120300293
Validation loss: 1.9987965822219849

Epoch: 6| Step: 10
Training loss: 1.8930323123931885
Validation loss: 2.0224714477856955

Epoch: 6| Step: 11
Training loss: 1.9640154838562012
Validation loss: 1.9482425053914387

Epoch: 6| Step: 12
Training loss: 2.0022459030151367
Validation loss: 1.9797880450884502

Epoch: 6| Step: 13
Training loss: 1.987094759941101
Validation loss: 2.008304218451182

Epoch: 59| Step: 0
Training loss: 1.093727946281433
Validation loss: 1.9541881680488586

Epoch: 6| Step: 1
Training loss: 2.1755290031433105
Validation loss: 1.9686703085899353

Epoch: 6| Step: 2
Training loss: 1.7401281595230103
Validation loss: 1.981846570968628

Epoch: 6| Step: 3
Training loss: 1.5551484823226929
Validation loss: 1.996698220570882

Epoch: 6| Step: 4
Training loss: 1.7105623483657837
Validation loss: 1.9970508416493733

Epoch: 6| Step: 5
Training loss: 1.3084673881530762
Validation loss: 1.9977283279101055

Epoch: 6| Step: 6
Training loss: 1.3296172618865967
Validation loss: 2.0015486677487693

Epoch: 6| Step: 7
Training loss: 2.0942904949188232
Validation loss: 2.031280795733134

Epoch: 6| Step: 8
Training loss: 2.4688007831573486
Validation loss: 2.066656549771627

Epoch: 6| Step: 9
Training loss: 2.0074045658111572
Validation loss: 2.051538606484731

Epoch: 6| Step: 10
Training loss: 1.5919513702392578
Validation loss: 2.0668120980262756

Epoch: 6| Step: 11
Training loss: 2.2126522064208984
Validation loss: 2.0813072323799133

Epoch: 6| Step: 12
Training loss: 1.8348329067230225
Validation loss: 2.0769534707069397

Epoch: 6| Step: 13
Training loss: 1.9178920984268188
Validation loss: 2.004623075326284

Epoch: 60| Step: 0
Training loss: 1.4273533821105957
Validation loss: 2.049935499827067

Epoch: 6| Step: 1
Training loss: 1.703782081604004
Validation loss: 2.040286600589752

Epoch: 6| Step: 2
Training loss: 1.4477577209472656
Validation loss: 2.0082621773084006

Epoch: 6| Step: 3
Training loss: 1.3480017185211182
Validation loss: 2.0068596402804055

Epoch: 6| Step: 4
Training loss: 1.8063454627990723
Validation loss: 1.9880326986312866

Epoch: 6| Step: 5
Training loss: 1.493714451789856
Validation loss: 2.015126427014669

Epoch: 6| Step: 6
Training loss: 2.4565701484680176
Validation loss: 2.008343815803528

Epoch: 6| Step: 7
Training loss: 2.111677646636963
Validation loss: 1.971702218055725

Epoch: 6| Step: 8
Training loss: 2.4809389114379883
Validation loss: 1.9799946546554565

Epoch: 6| Step: 9
Training loss: 1.6233865022659302
Validation loss: 2.0006856322288513

Epoch: 6| Step: 10
Training loss: 1.408997893333435
Validation loss: 2.000718812147776

Epoch: 6| Step: 11
Training loss: 1.4968035221099854
Validation loss: 1.9717405637105305

Epoch: 6| Step: 12
Training loss: 2.0863776206970215
Validation loss: 1.967452069123586

Epoch: 6| Step: 13
Training loss: 1.8721892833709717
Validation loss: 2.055081049601237

Epoch: 61| Step: 0
Training loss: 1.5361478328704834
Validation loss: 2.0187683502833047

Epoch: 6| Step: 1
Training loss: 1.0625941753387451
Validation loss: 2.03140781323115

Epoch: 6| Step: 2
Training loss: 1.3416036367416382
Validation loss: 2.0339165131251016

Epoch: 6| Step: 3
Training loss: 1.8767125606536865
Validation loss: 2.0507887601852417

Epoch: 6| Step: 4
Training loss: 1.9675912857055664
Validation loss: 2.042931298414866

Epoch: 6| Step: 5
Training loss: 0.9406819343566895
Validation loss: 2.024559279282888

Epoch: 6| Step: 6
Training loss: 2.0518925189971924
Validation loss: 2.000564436117808

Epoch: 6| Step: 7
Training loss: 1.5636008977890015
Validation loss: 2.0012769301732383

Epoch: 6| Step: 8
Training loss: 2.514503002166748
Validation loss: 1.9994273980458577

Epoch: 6| Step: 9
Training loss: 1.7907346487045288
Validation loss: 2.0032765666643777

Epoch: 6| Step: 10
Training loss: 2.519310235977173
Validation loss: 1.9696815808614094

Epoch: 6| Step: 11
Training loss: 2.0854506492614746
Validation loss: 1.9672269821166992

Epoch: 6| Step: 12
Training loss: 1.726025104522705
Validation loss: 1.9740066925684612

Epoch: 6| Step: 13
Training loss: 1.8046560287475586
Validation loss: 1.9766504764556885

Epoch: 62| Step: 0
Training loss: 1.7124958038330078
Validation loss: 1.9686498641967773

Epoch: 6| Step: 1
Training loss: 2.1196064949035645
Validation loss: 2.0240591963132224

Epoch: 6| Step: 2
Training loss: 1.8797415494918823
Validation loss: 1.9812125364939372

Epoch: 6| Step: 3
Training loss: 1.796765685081482
Validation loss: 2.0248683293660483

Epoch: 6| Step: 4
Training loss: 1.4301948547363281
Validation loss: 2.0051026344299316

Epoch: 6| Step: 5
Training loss: 0.9028974771499634
Validation loss: 2.024991055329641

Epoch: 6| Step: 6
Training loss: 1.5921909809112549
Validation loss: 2.0468303561210632

Epoch: 6| Step: 7
Training loss: 1.776108741760254
Validation loss: 2.044980545838674

Epoch: 6| Step: 8
Training loss: 1.2018083333969116
Validation loss: 2.0902151266733804

Epoch: 6| Step: 9
Training loss: 1.9163533449172974
Validation loss: 2.093450407187144

Epoch: 6| Step: 10
Training loss: 2.015833854675293
Validation loss: 2.0726762612660727

Epoch: 6| Step: 11
Training loss: 1.7476311922073364
Validation loss: 2.0612518787384033

Epoch: 6| Step: 12
Training loss: 1.9566538333892822
Validation loss: 2.031265695889791

Epoch: 6| Step: 13
Training loss: 2.272292137145996
Validation loss: 2.079445719718933

Epoch: 63| Step: 0
Training loss: 1.1058036088943481
Validation loss: 2.032783806324005

Epoch: 6| Step: 1
Training loss: 2.0620555877685547
Validation loss: 1.9976512988408406

Epoch: 6| Step: 2
Training loss: 2.034407138824463
Validation loss: 2.0113524794578552

Epoch: 6| Step: 3
Training loss: 1.7746556997299194
Validation loss: 2.0050731698671975

Epoch: 6| Step: 4
Training loss: 2.5128495693206787
Validation loss: 2.0120588143666587

Epoch: 6| Step: 5
Training loss: 1.4750158786773682
Validation loss: 2.041029413541158

Epoch: 6| Step: 6
Training loss: 1.4352973699569702
Validation loss: 2.031797409057617

Epoch: 6| Step: 7
Training loss: 1.893909215927124
Validation loss: 2.020449082056681

Epoch: 6| Step: 8
Training loss: 1.2698547840118408
Validation loss: 1.9949585398038228

Epoch: 6| Step: 9
Training loss: 1.8601462841033936
Validation loss: 2.0103421012560525

Epoch: 6| Step: 10
Training loss: 1.8945516347885132
Validation loss: 2.030123253663381

Epoch: 6| Step: 11
Training loss: 1.425016164779663
Validation loss: 2.026962916056315

Epoch: 6| Step: 12
Training loss: 2.2358412742614746
Validation loss: 2.0095425645510354

Epoch: 6| Step: 13
Training loss: 1.3081064224243164
Validation loss: 1.9935494661331177

Epoch: 64| Step: 0
Training loss: 2.0504913330078125
Validation loss: 1.9941318035125732

Epoch: 6| Step: 1
Training loss: 1.5560965538024902
Validation loss: 2.018176555633545

Epoch: 6| Step: 2
Training loss: 1.5440890789031982
Validation loss: 2.0200578967730203

Epoch: 6| Step: 3
Training loss: 1.6475507020950317
Validation loss: 2.051730473836263

Epoch: 6| Step: 4
Training loss: 1.7930216789245605
Validation loss: 2.0743032892545066

Epoch: 6| Step: 5
Training loss: 1.3779046535491943
Validation loss: 2.0679620703061423

Epoch: 6| Step: 6
Training loss: 2.713505744934082
Validation loss: 2.0777316888173423

Epoch: 6| Step: 7
Training loss: 2.037024736404419
Validation loss: 2.0809858640034995

Epoch: 6| Step: 8
Training loss: 1.266208529472351
Validation loss: 2.059093197186788

Epoch: 6| Step: 9
Training loss: 1.545188069343567
Validation loss: 2.0343814889589944

Epoch: 6| Step: 10
Training loss: 1.915793776512146
Validation loss: 2.0050583283106485

Epoch: 6| Step: 11
Training loss: 1.0422487258911133
Validation loss: 1.9618347883224487

Epoch: 6| Step: 12
Training loss: 1.9244134426116943
Validation loss: 1.980301817258199

Epoch: 6| Step: 13
Training loss: 1.8973805904388428
Validation loss: 1.984118660291036

Epoch: 65| Step: 0
Training loss: 1.4027321338653564
Validation loss: 1.9770585695902507

Epoch: 6| Step: 1
Training loss: 1.374197006225586
Validation loss: 1.983202854792277

Epoch: 6| Step: 2
Training loss: 2.023411750793457
Validation loss: 2.0154284636179605

Epoch: 6| Step: 3
Training loss: 0.939971923828125
Validation loss: 2.039785305658976

Epoch: 6| Step: 4
Training loss: 1.3901960849761963
Validation loss: 2.0104488730430603

Epoch: 6| Step: 5
Training loss: 1.3999388217926025
Validation loss: 2.0132814844449363

Epoch: 6| Step: 6
Training loss: 1.552712321281433
Validation loss: 2.0611156622568765

Epoch: 6| Step: 7
Training loss: 1.8429253101348877
Validation loss: 2.069609781106313

Epoch: 6| Step: 8
Training loss: 2.550440788269043
Validation loss: 2.0276352365811667

Epoch: 6| Step: 9
Training loss: 2.4115443229675293
Validation loss: 2.005748450756073

Epoch: 6| Step: 10
Training loss: 1.845034122467041
Validation loss: 2.0035007198651633

Epoch: 6| Step: 11
Training loss: 2.1066832542419434
Validation loss: 2.034658948580424

Epoch: 6| Step: 12
Training loss: 1.5895912647247314
Validation loss: 1.9845434427261353

Epoch: 6| Step: 13
Training loss: 1.7722015380859375
Validation loss: 2.0032060146331787

Epoch: 66| Step: 0
Training loss: 1.2652866840362549
Validation loss: 2.0025164683659873

Epoch: 6| Step: 1
Training loss: 1.6233971118927002
Validation loss: 2.0027018785476685

Epoch: 6| Step: 2
Training loss: 2.0015740394592285
Validation loss: 1.9930951595306396

Epoch: 6| Step: 3
Training loss: 1.5402520895004272
Validation loss: 1.983967701594035

Epoch: 6| Step: 4
Training loss: 2.287008047103882
Validation loss: 1.98101011912028

Epoch: 6| Step: 5
Training loss: 1.5727334022521973
Validation loss: 1.9553414781888325

Epoch: 6| Step: 6
Training loss: 1.7289608716964722
Validation loss: 1.9662889043490093

Epoch: 6| Step: 7
Training loss: 1.6782939434051514
Validation loss: 2.030803600947062

Epoch: 6| Step: 8
Training loss: 1.4010366201400757
Validation loss: 1.9773549437522888

Epoch: 6| Step: 9
Training loss: 1.6025574207305908
Validation loss: 2.040650566418966

Epoch: 6| Step: 10
Training loss: 1.9728853702545166
Validation loss: 2.0105408430099487

Epoch: 6| Step: 11
Training loss: 1.8600423336029053
Validation loss: 2.02680895725886

Epoch: 6| Step: 12
Training loss: 1.4682406187057495
Validation loss: 2.1414636969566345

Epoch: 6| Step: 13
Training loss: 1.8742201328277588
Validation loss: 2.0931188265482583

Epoch: 67| Step: 0
Training loss: 1.9369137287139893
Validation loss: 2.096717099348704

Epoch: 6| Step: 1
Training loss: 2.051845073699951
Validation loss: 2.0893662770589194

Epoch: 6| Step: 2
Training loss: 1.3745173215866089
Validation loss: 2.068011780579885

Epoch: 6| Step: 3
Training loss: 1.434437870979309
Validation loss: 2.0380692879358926

Epoch: 6| Step: 4
Training loss: 1.5583610534667969
Validation loss: 2.0034053723017373

Epoch: 6| Step: 5
Training loss: 1.296419620513916
Validation loss: 2.011955738067627

Epoch: 6| Step: 6
Training loss: 1.6962016820907593
Validation loss: 1.9983171820640564

Epoch: 6| Step: 7
Training loss: 2.069746732711792
Validation loss: 2.0264734625816345

Epoch: 6| Step: 8
Training loss: 2.1093828678131104
Validation loss: 2.0032037496566772

Epoch: 6| Step: 9
Training loss: 1.6574846506118774
Validation loss: 1.9960038661956787

Epoch: 6| Step: 10
Training loss: 1.946892499923706
Validation loss: 1.988261838754018

Epoch: 6| Step: 11
Training loss: 2.0870473384857178
Validation loss: 1.9990071853001912

Epoch: 6| Step: 12
Training loss: 1.5573712587356567
Validation loss: 1.981257677078247

Epoch: 6| Step: 13
Training loss: 1.3015773296356201
Validation loss: 1.9693551659584045

Epoch: 68| Step: 0
Training loss: 1.482752799987793
Validation loss: 2.0131948391596475

Epoch: 6| Step: 1
Training loss: 1.4623546600341797
Validation loss: 2.014007786909739

Epoch: 6| Step: 2
Training loss: 1.9346190690994263
Validation loss: 2.0330155889193215

Epoch: 6| Step: 3
Training loss: 1.8718394041061401
Validation loss: 2.0774678786595664

Epoch: 6| Step: 4
Training loss: 1.7692137956619263
Validation loss: 2.061066746711731

Epoch: 6| Step: 5
Training loss: 1.0971940755844116
Validation loss: 2.0652013421058655

Epoch: 6| Step: 6
Training loss: 1.8737356662750244
Validation loss: 2.0748485326766968

Epoch: 6| Step: 7
Training loss: 2.15342378616333
Validation loss: 2.0354949037233987

Epoch: 6| Step: 8
Training loss: 1.3249377012252808
Validation loss: 2.00127112865448

Epoch: 6| Step: 9
Training loss: 1.7576072216033936
Validation loss: 2.008163412412008

Epoch: 6| Step: 10
Training loss: 2.1490585803985596
Validation loss: 2.0333330432573953

Epoch: 6| Step: 11
Training loss: 1.6135505437850952
Validation loss: 1.9821621775627136

Epoch: 6| Step: 12
Training loss: 1.620342493057251
Validation loss: 1.989385763804118

Epoch: 6| Step: 13
Training loss: 1.567939281463623
Validation loss: 2.00669527053833

Epoch: 69| Step: 0
Training loss: 1.5929875373840332
Validation loss: 1.9806421796480815

Epoch: 6| Step: 1
Training loss: 1.8341814279556274
Validation loss: 2.0556435187657676

Epoch: 6| Step: 2
Training loss: 1.5252902507781982
Validation loss: 2.039052963256836

Epoch: 6| Step: 3
Training loss: 1.4817569255828857
Validation loss: 2.0101590752601624

Epoch: 6| Step: 4
Training loss: 1.9918773174285889
Validation loss: 2.100939949353536

Epoch: 6| Step: 5
Training loss: 1.2132694721221924
Validation loss: 2.073665976524353

Epoch: 6| Step: 6
Training loss: 1.825570821762085
Validation loss: 2.0994912981987

Epoch: 6| Step: 7
Training loss: 1.757552146911621
Validation loss: 2.057325541973114

Epoch: 6| Step: 8
Training loss: 1.5947039127349854
Validation loss: 2.01252144575119

Epoch: 6| Step: 9
Training loss: 1.380810022354126
Validation loss: 2.0111823280652366

Epoch: 6| Step: 10
Training loss: 2.1503615379333496
Validation loss: 2.0000703732172647

Epoch: 6| Step: 11
Training loss: 2.188683032989502
Validation loss: 2.0147032737731934

Epoch: 6| Step: 12
Training loss: 1.2429044246673584
Validation loss: 2.0060351292292276

Epoch: 6| Step: 13
Training loss: 1.9841134548187256
Validation loss: 1.9692572156588237

Epoch: 70| Step: 0
Training loss: 1.248548150062561
Validation loss: 2.009692211945852

Epoch: 6| Step: 1
Training loss: 2.0243656635284424
Validation loss: 2.0097463130950928

Epoch: 6| Step: 2
Training loss: 1.7054803371429443
Validation loss: 2.0027921199798584

Epoch: 6| Step: 3
Training loss: 2.2561821937561035
Validation loss: 2.011845846970876

Epoch: 6| Step: 4
Training loss: 2.1737513542175293
Validation loss: 1.9829184810320537

Epoch: 6| Step: 5
Training loss: 1.4803036451339722
Validation loss: 2.0443832079569497

Epoch: 6| Step: 6
Training loss: 1.745084285736084
Validation loss: 2.016496260960897

Epoch: 6| Step: 7
Training loss: 1.1461501121520996
Validation loss: 2.0361826618512473

Epoch: 6| Step: 8
Training loss: 2.091596841812134
Validation loss: 2.0405697226524353

Epoch: 6| Step: 9
Training loss: 1.4383161067962646
Validation loss: 2.0236045320828757

Epoch: 6| Step: 10
Training loss: 1.5234073400497437
Validation loss: 2.051405588785807

Epoch: 6| Step: 11
Training loss: 1.0561649799346924
Validation loss: 2.1031575401624045

Epoch: 6| Step: 12
Training loss: 2.012403964996338
Validation loss: 2.1092975536982217

Epoch: 6| Step: 13
Training loss: 1.475921630859375
Validation loss: 2.098527173201243

Epoch: 71| Step: 0
Training loss: 1.6571955680847168
Validation loss: 2.0819572607676187

Epoch: 6| Step: 1
Training loss: 1.9344584941864014
Validation loss: 2.035054703553518

Epoch: 6| Step: 2
Training loss: 1.4238048791885376
Validation loss: 2.001445551713308

Epoch: 6| Step: 3
Training loss: 1.5354087352752686
Validation loss: 2.0080384016036987

Epoch: 6| Step: 4
Training loss: 1.8059942722320557
Validation loss: 2.0311985413233438

Epoch: 6| Step: 5
Training loss: 1.0219669342041016
Validation loss: 2.0047672192255654

Epoch: 6| Step: 6
Training loss: 2.279611110687256
Validation loss: 2.0113898317019143

Epoch: 6| Step: 7
Training loss: 1.7112841606140137
Validation loss: 2.0441091458002725

Epoch: 6| Step: 8
Training loss: 1.5453853607177734
Validation loss: 2.026050845781962

Epoch: 6| Step: 9
Training loss: 1.287837028503418
Validation loss: 2.0377442836761475

Epoch: 6| Step: 10
Training loss: 0.8944727182388306
Validation loss: 2.0428893168767295

Epoch: 6| Step: 11
Training loss: 2.3445870876312256
Validation loss: 2.0681432088216147

Epoch: 6| Step: 12
Training loss: 1.693724274635315
Validation loss: 2.083514153957367

Epoch: 6| Step: 13
Training loss: 1.8720026016235352
Validation loss: 2.002120574315389

Epoch: 72| Step: 0
Training loss: 1.1979364156723022
Validation loss: 2.038734714190165

Epoch: 6| Step: 1
Training loss: 1.634901762008667
Validation loss: 2.0283418893814087

Epoch: 6| Step: 2
Training loss: 1.6795129776000977
Validation loss: 2.050359030564626

Epoch: 6| Step: 3
Training loss: 2.1164724826812744
Validation loss: 1.9815074602762859

Epoch: 6| Step: 4
Training loss: 1.5256801843643188
Validation loss: 1.9856475392977397

Epoch: 6| Step: 5
Training loss: 1.8540093898773193
Validation loss: 1.9536568721135457

Epoch: 6| Step: 6
Training loss: 1.835585117340088
Validation loss: 1.9859507878621419

Epoch: 6| Step: 7
Training loss: 1.2222394943237305
Validation loss: 1.9447593490282695

Epoch: 6| Step: 8
Training loss: 1.4453296661376953
Validation loss: 2.0105095505714417

Epoch: 6| Step: 9
Training loss: 1.6089550256729126
Validation loss: 1.9899222056070964

Epoch: 6| Step: 10
Training loss: 1.3511748313903809
Validation loss: 2.0173389315605164

Epoch: 6| Step: 11
Training loss: 2.3097736835479736
Validation loss: 2.0404706398646035

Epoch: 6| Step: 12
Training loss: 1.3068830966949463
Validation loss: 2.0911149382591248

Epoch: 6| Step: 13
Training loss: 1.767021656036377
Validation loss: 2.096777617931366

Epoch: 73| Step: 0
Training loss: 1.297199010848999
Validation loss: 2.0805591344833374

Epoch: 6| Step: 1
Training loss: 1.4022417068481445
Validation loss: 2.1162507136662803

Epoch: 6| Step: 2
Training loss: 1.4934873580932617
Validation loss: 2.079903165499369

Epoch: 6| Step: 3
Training loss: 1.6664519309997559
Validation loss: 2.075117369492849

Epoch: 6| Step: 4
Training loss: 2.1151771545410156
Validation loss: 2.065852244695028

Epoch: 6| Step: 5
Training loss: 1.1421124935150146
Validation loss: 1.9938143094380696

Epoch: 6| Step: 6
Training loss: 1.482255458831787
Validation loss: 2.02973402539889

Epoch: 6| Step: 7
Training loss: 1.9471853971481323
Validation loss: 1.9954375425974529

Epoch: 6| Step: 8
Training loss: 1.6401746273040771
Validation loss: 1.9714642763137817

Epoch: 6| Step: 9
Training loss: 1.7616145610809326
Validation loss: 1.9738128582636516

Epoch: 6| Step: 10
Training loss: 2.277831554412842
Validation loss: 1.976145346959432

Epoch: 6| Step: 11
Training loss: 1.3718714714050293
Validation loss: 1.9541916052500408

Epoch: 6| Step: 12
Training loss: 1.449501395225525
Validation loss: 1.9501717686653137

Epoch: 6| Step: 13
Training loss: 1.8723244667053223
Validation loss: 1.95744655529658

Epoch: 74| Step: 0
Training loss: 1.1238738298416138
Validation loss: 1.9529868563016255

Epoch: 6| Step: 1
Training loss: 1.825095295906067
Validation loss: 1.9955557187398274

Epoch: 6| Step: 2
Training loss: 1.126903772354126
Validation loss: 2.0197254419326782

Epoch: 6| Step: 3
Training loss: 1.8692889213562012
Validation loss: 2.0354128082593284

Epoch: 6| Step: 4
Training loss: 1.6154699325561523
Validation loss: 2.0481778581937156

Epoch: 6| Step: 5
Training loss: 2.417973518371582
Validation loss: 2.0693047046661377

Epoch: 6| Step: 6
Training loss: 1.7383618354797363
Validation loss: 2.063942829767863

Epoch: 6| Step: 7
Training loss: 1.5936998128890991
Validation loss: 2.0334940950075784

Epoch: 6| Step: 8
Training loss: 1.605351448059082
Validation loss: 2.040021002292633

Epoch: 6| Step: 9
Training loss: 1.0728609561920166
Validation loss: 2.007954994837443

Epoch: 6| Step: 10
Training loss: 1.7236440181732178
Validation loss: 1.963835636774699

Epoch: 6| Step: 11
Training loss: 1.6262564659118652
Validation loss: 1.9558858474095662

Epoch: 6| Step: 12
Training loss: 2.1739280223846436
Validation loss: 1.9424741466840107

Epoch: 6| Step: 13
Training loss: 1.6302833557128906
Validation loss: 1.9766274293263753

Epoch: 75| Step: 0
Training loss: 1.7630352973937988
Validation loss: 1.9927390615145366

Epoch: 6| Step: 1
Training loss: 1.248245358467102
Validation loss: 1.961992621421814

Epoch: 6| Step: 2
Training loss: 1.422820806503296
Validation loss: 2.0075340072313943

Epoch: 6| Step: 3
Training loss: 1.285485029220581
Validation loss: 2.0368914008140564

Epoch: 6| Step: 4
Training loss: 1.8698902130126953
Validation loss: 2.0425564646720886

Epoch: 6| Step: 5
Training loss: 1.4830275774002075
Validation loss: 2.030150572458903

Epoch: 6| Step: 6
Training loss: 1.592319130897522
Validation loss: 2.036702295144399

Epoch: 6| Step: 7
Training loss: 1.7793048620224
Validation loss: 2.059078335762024

Epoch: 6| Step: 8
Training loss: 2.2664730548858643
Validation loss: 2.01101815700531

Epoch: 6| Step: 9
Training loss: 1.6099445819854736
Validation loss: 2.053022861480713

Epoch: 6| Step: 10
Training loss: 1.10746431350708
Validation loss: 1.988607943058014

Epoch: 6| Step: 11
Training loss: 1.7410223484039307
Validation loss: 1.9998785654703777

Epoch: 6| Step: 12
Training loss: 1.7406556606292725
Validation loss: 2.005838473637899

Epoch: 6| Step: 13
Training loss: 1.5106008052825928
Validation loss: 2.0448920925458274

Epoch: 76| Step: 0
Training loss: 1.8331986665725708
Validation loss: 2.016335129737854

Epoch: 6| Step: 1
Training loss: 1.1407183408737183
Validation loss: 2.001116712888082

Epoch: 6| Step: 2
Training loss: 1.2895454168319702
Validation loss: 2.04791267712911

Epoch: 6| Step: 3
Training loss: 1.195212721824646
Validation loss: 2.0234805941581726

Epoch: 6| Step: 4
Training loss: 0.7239167094230652
Validation loss: 2.0285536448160806

Epoch: 6| Step: 5
Training loss: 1.133596420288086
Validation loss: 2.0405744115511575

Epoch: 6| Step: 6
Training loss: 1.8533011674880981
Validation loss: 2.0655158360799155

Epoch: 6| Step: 7
Training loss: 1.3846536874771118
Validation loss: 1.997176726659139

Epoch: 6| Step: 8
Training loss: 2.56905198097229
Validation loss: 2.0301931301752725

Epoch: 6| Step: 9
Training loss: 2.1902592182159424
Validation loss: 2.0522287885348

Epoch: 6| Step: 10
Training loss: 2.1325619220733643
Validation loss: 2.030994256337484

Epoch: 6| Step: 11
Training loss: 1.738112211227417
Validation loss: 2.035776416460673

Epoch: 6| Step: 12
Training loss: 1.3595314025878906
Validation loss: 1.9797362486521404

Epoch: 6| Step: 13
Training loss: 1.8401886224746704
Validation loss: 1.9722703297932942

Epoch: 77| Step: 0
Training loss: 1.4522396326065063
Validation loss: 1.9807111819585164

Epoch: 6| Step: 1
Training loss: 1.9602501392364502
Validation loss: 1.9695620735486348

Epoch: 6| Step: 2
Training loss: 0.8087512254714966
Validation loss: 1.977163851261139

Epoch: 6| Step: 3
Training loss: 1.6159794330596924
Validation loss: 1.9601302941640217

Epoch: 6| Step: 4
Training loss: 1.491735816001892
Validation loss: 1.9995303551355998

Epoch: 6| Step: 5
Training loss: 1.0658341646194458
Validation loss: 2.020551343758901

Epoch: 6| Step: 6
Training loss: 2.2263784408569336
Validation loss: 1.9870344599088032

Epoch: 6| Step: 7
Training loss: 1.2021939754486084
Validation loss: 1.9928513367970784

Epoch: 6| Step: 8
Training loss: 1.205678939819336
Validation loss: 2.0240262746810913

Epoch: 6| Step: 9
Training loss: 1.9743324518203735
Validation loss: 2.022424578666687

Epoch: 6| Step: 10
Training loss: 1.4100289344787598
Validation loss: 2.0203709999720254

Epoch: 6| Step: 11
Training loss: 1.7444933652877808
Validation loss: 1.9928568005561829

Epoch: 6| Step: 12
Training loss: 1.5723960399627686
Validation loss: 2.0247439543406167

Epoch: 6| Step: 13
Training loss: 2.153337240219116
Validation loss: 2.0059659679730735

Epoch: 78| Step: 0
Training loss: 1.8891394138336182
Validation loss: 2.0111822485923767

Epoch: 6| Step: 1
Training loss: 1.8283872604370117
Validation loss: 2.017023960749308

Epoch: 6| Step: 2
Training loss: 1.2150193452835083
Validation loss: 2.009713331858317

Epoch: 6| Step: 3
Training loss: 1.4256761074066162
Validation loss: 1.9921540419260662

Epoch: 6| Step: 4
Training loss: 1.0075795650482178
Validation loss: 2.0398001869519553

Epoch: 6| Step: 5
Training loss: 1.2022967338562012
Validation loss: 2.0179866949717202

Epoch: 6| Step: 6
Training loss: 1.3396689891815186
Validation loss: 1.9903449614842732

Epoch: 6| Step: 7
Training loss: 2.022369623184204
Validation loss: 2.0346121390660605

Epoch: 6| Step: 8
Training loss: 1.7702769041061401
Validation loss: 2.11038076877594

Epoch: 6| Step: 9
Training loss: 1.1257338523864746
Validation loss: 2.0351668993631997

Epoch: 6| Step: 10
Training loss: 1.9311836957931519
Validation loss: 2.0976750453313193

Epoch: 6| Step: 11
Training loss: 2.0236997604370117
Validation loss: 2.0768058697382608

Epoch: 6| Step: 12
Training loss: 1.6941802501678467
Validation loss: 2.073068936665853

Epoch: 6| Step: 13
Training loss: 1.2228784561157227
Validation loss: 2.020532170931498

Epoch: 79| Step: 0
Training loss: 1.8895847797393799
Validation loss: 2.0265517433484397

Epoch: 6| Step: 1
Training loss: 1.6873104572296143
Validation loss: 1.937468429406484

Epoch: 6| Step: 2
Training loss: 1.774605393409729
Validation loss: 1.9620844721794128

Epoch: 6| Step: 3
Training loss: 1.523655652999878
Validation loss: 1.9737905661265056

Epoch: 6| Step: 4
Training loss: 1.5460039377212524
Validation loss: 1.9333647688229878

Epoch: 6| Step: 5
Training loss: 1.4678195714950562
Validation loss: 1.9747191468874614

Epoch: 6| Step: 6
Training loss: 1.8971688747406006
Validation loss: 1.985870599746704

Epoch: 6| Step: 7
Training loss: 1.3980236053466797
Validation loss: 1.9756745894749959

Epoch: 6| Step: 8
Training loss: 1.2518830299377441
Validation loss: 2.0284549593925476

Epoch: 6| Step: 9
Training loss: 1.4500629901885986
Validation loss: 2.0543451507886252

Epoch: 6| Step: 10
Training loss: 1.2812366485595703
Validation loss: 2.056688606739044

Epoch: 6| Step: 11
Training loss: 1.4742789268493652
Validation loss: 2.081494172414144

Epoch: 6| Step: 12
Training loss: 0.6814606785774231
Validation loss: 2.1544169584910073

Epoch: 6| Step: 13
Training loss: 2.769937038421631
Validation loss: 2.0835049947102866

Epoch: 80| Step: 0
Training loss: 1.2358531951904297
Validation loss: 2.0835169553756714

Epoch: 6| Step: 1
Training loss: 2.046833038330078
Validation loss: 1.9939057032267253

Epoch: 6| Step: 2
Training loss: 1.708890438079834
Validation loss: 2.0152820150057473

Epoch: 6| Step: 3
Training loss: 0.8726412653923035
Validation loss: 1.9735154906908672

Epoch: 6| Step: 4
Training loss: 1.4796676635742188
Validation loss: 1.9959085782368977

Epoch: 6| Step: 5
Training loss: 1.0964757204055786
Validation loss: 1.9816328485806782

Epoch: 6| Step: 6
Training loss: 1.5888378620147705
Validation loss: 1.9677122235298157

Epoch: 6| Step: 7
Training loss: 1.532457709312439
Validation loss: 1.9928322037061055

Epoch: 6| Step: 8
Training loss: 1.3747601509094238
Validation loss: 2.0030998587608337

Epoch: 6| Step: 9
Training loss: 1.4339927434921265
Validation loss: 1.977457344532013

Epoch: 6| Step: 10
Training loss: 1.173449993133545
Validation loss: 2.0195323824882507

Epoch: 6| Step: 11
Training loss: 1.6607697010040283
Validation loss: 2.039731045564016

Epoch: 6| Step: 12
Training loss: 2.0289764404296875
Validation loss: 2.0750968853632608

Epoch: 6| Step: 13
Training loss: 2.1799840927124023
Validation loss: 2.079466780026754

Epoch: 81| Step: 0
Training loss: 1.5775489807128906
Validation loss: 2.0796144604682922

Epoch: 6| Step: 1
Training loss: 1.9925907850265503
Validation loss: 2.0745893518129983

Epoch: 6| Step: 2
Training loss: 1.3474589586257935
Validation loss: 2.043170154094696

Epoch: 6| Step: 3
Training loss: 1.600771188735962
Validation loss: 2.021325091520945

Epoch: 6| Step: 4
Training loss: 1.738295078277588
Validation loss: 1.999625325202942

Epoch: 6| Step: 5
Training loss: 0.8443403840065002
Validation loss: 2.021328111489614

Epoch: 6| Step: 6
Training loss: 1.9877325296401978
Validation loss: 2.0535252690315247

Epoch: 6| Step: 7
Training loss: 1.2260944843292236
Validation loss: 1.9885546565055847

Epoch: 6| Step: 8
Training loss: 1.5137441158294678
Validation loss: 1.9828901092211406

Epoch: 6| Step: 9
Training loss: 1.3197698593139648
Validation loss: 1.9952257076899211

Epoch: 6| Step: 10
Training loss: 2.2485408782958984
Validation loss: 2.0217912197113037

Epoch: 6| Step: 11
Training loss: 0.6316224336624146
Validation loss: 2.0210224787394204

Epoch: 6| Step: 12
Training loss: 1.5458813905715942
Validation loss: 1.992217481136322

Epoch: 6| Step: 13
Training loss: 1.6418375968933105
Validation loss: 1.9759387373924255

Epoch: 82| Step: 0
Training loss: 1.2966257333755493
Validation loss: 1.9838097095489502

Epoch: 6| Step: 1
Training loss: 1.316298484802246
Validation loss: 2.0258272091547647

Epoch: 6| Step: 2
Training loss: 0.6114745140075684
Validation loss: 2.020587901274363

Epoch: 6| Step: 3
Training loss: 1.6871237754821777
Validation loss: 2.027098556359609

Epoch: 6| Step: 4
Training loss: 1.6572027206420898
Validation loss: 2.0583860079447427

Epoch: 6| Step: 5
Training loss: 2.056530714035034
Validation loss: 2.0407737493515015

Epoch: 6| Step: 6
Training loss: 1.976132869720459
Validation loss: 2.016020039717356

Epoch: 6| Step: 7
Training loss: 1.198744773864746
Validation loss: 1.9855592449506123

Epoch: 6| Step: 8
Training loss: 1.410205364227295
Validation loss: 2.0270047386487327

Epoch: 6| Step: 9
Training loss: 1.1073284149169922
Validation loss: 1.9720823168754578

Epoch: 6| Step: 10
Training loss: 1.653862714767456
Validation loss: 1.9880354404449463

Epoch: 6| Step: 11
Training loss: 1.563086748123169
Validation loss: 2.01898201306661

Epoch: 6| Step: 12
Training loss: 1.4668405055999756
Validation loss: 1.976437509059906

Epoch: 6| Step: 13
Training loss: 1.9181830883026123
Validation loss: 2.0093099077542624

Epoch: 83| Step: 0
Training loss: 1.2224030494689941
Validation loss: 2.0321199893951416

Epoch: 6| Step: 1
Training loss: 1.9071062803268433
Validation loss: 2.002369483311971

Epoch: 6| Step: 2
Training loss: 1.886313796043396
Validation loss: 2.024812122186025

Epoch: 6| Step: 3
Training loss: 2.275238037109375
Validation loss: 1.971982439359029

Epoch: 6| Step: 4
Training loss: 1.8580906391143799
Validation loss: 2.0241556763648987

Epoch: 6| Step: 5
Training loss: 1.3380405902862549
Validation loss: 2.044544498125712

Epoch: 6| Step: 6
Training loss: 0.9091233015060425
Validation loss: 2.0460649331410727

Epoch: 6| Step: 7
Training loss: 1.062765121459961
Validation loss: 2.034643570582072

Epoch: 6| Step: 8
Training loss: 1.567510962486267
Validation loss: 2.0632930199305215

Epoch: 6| Step: 9
Training loss: 1.3050541877746582
Validation loss: 2.020106852054596

Epoch: 6| Step: 10
Training loss: 1.301271677017212
Validation loss: 2.044433335463206

Epoch: 6| Step: 11
Training loss: 1.3811981678009033
Validation loss: 2.0208153327306113

Epoch: 6| Step: 12
Training loss: 1.2437775135040283
Validation loss: 1.9844071865081787

Epoch: 6| Step: 13
Training loss: 1.5377823114395142
Validation loss: 1.9813291430473328

Epoch: 84| Step: 0
Training loss: 1.114213228225708
Validation loss: 1.9728579719861348

Epoch: 6| Step: 1
Training loss: 2.512389659881592
Validation loss: 1.9923730095227559

Epoch: 6| Step: 2
Training loss: 1.601494550704956
Validation loss: 1.9706915815671284

Epoch: 6| Step: 3
Training loss: 0.9698981642723083
Validation loss: 1.978364646434784

Epoch: 6| Step: 4
Training loss: 1.48260498046875
Validation loss: 1.9549046953519185

Epoch: 6| Step: 5
Training loss: 1.0130095481872559
Validation loss: 1.97730420033137

Epoch: 6| Step: 6
Training loss: 1.7680034637451172
Validation loss: 1.9464735984802246

Epoch: 6| Step: 7
Training loss: 1.4904680252075195
Validation loss: 1.9936084747314453

Epoch: 6| Step: 8
Training loss: 1.655198574066162
Validation loss: 2.002900858720144

Epoch: 6| Step: 9
Training loss: 1.5739554166793823
Validation loss: 1.9971173008282979

Epoch: 6| Step: 10
Training loss: 1.5059938430786133
Validation loss: 2.0108123620351157

Epoch: 6| Step: 11
Training loss: 0.9956759214401245
Validation loss: 2.0245628555615744

Epoch: 6| Step: 12
Training loss: 1.377509355545044
Validation loss: 2.061169385910034

Epoch: 6| Step: 13
Training loss: 1.383010983467102
Validation loss: 2.052263617515564

Epoch: 85| Step: 0
Training loss: 1.6747957468032837
Validation loss: 2.0936636130015054

Epoch: 6| Step: 1
Training loss: 1.5967382192611694
Validation loss: 2.0195632378260293

Epoch: 6| Step: 2
Training loss: 1.463641881942749
Validation loss: 2.0209255615870156

Epoch: 6| Step: 3
Training loss: 1.340430736541748
Validation loss: 2.011531134446462

Epoch: 6| Step: 4
Training loss: 0.6840354204177856
Validation loss: 2.028925140698751

Epoch: 6| Step: 5
Training loss: 1.618605375289917
Validation loss: 1.9924895962079365

Epoch: 6| Step: 6
Training loss: 1.6426832675933838
Validation loss: 1.9566528995831807

Epoch: 6| Step: 7
Training loss: 1.6955630779266357
Validation loss: 1.9536320169766743

Epoch: 6| Step: 8
Training loss: 1.6815073490142822
Validation loss: 1.9673169056574504

Epoch: 6| Step: 9
Training loss: 1.285888910293579
Validation loss: 1.977071225643158

Epoch: 6| Step: 10
Training loss: 1.3284342288970947
Validation loss: 2.042030612627665

Epoch: 6| Step: 11
Training loss: 1.9759247303009033
Validation loss: 2.1059978008270264

Epoch: 6| Step: 12
Training loss: 1.113757610321045
Validation loss: 2.061048607031504

Epoch: 6| Step: 13
Training loss: 1.2591681480407715
Validation loss: 2.1284002661705017

Epoch: 86| Step: 0
Training loss: 2.093433380126953
Validation loss: 2.104992071787516

Epoch: 6| Step: 1
Training loss: 1.4576292037963867
Validation loss: 2.087999085585276

Epoch: 6| Step: 2
Training loss: 0.9858936667442322
Validation loss: 2.029188553492228

Epoch: 6| Step: 3
Training loss: 1.3926537036895752
Validation loss: 2.00086110830307

Epoch: 6| Step: 4
Training loss: 1.8025251626968384
Validation loss: 1.9464336435000102

Epoch: 6| Step: 5
Training loss: 1.3643423318862915
Validation loss: 1.9482871095339458

Epoch: 6| Step: 6
Training loss: 1.136763334274292
Validation loss: 1.9725298484166462

Epoch: 6| Step: 7
Training loss: 1.351402997970581
Validation loss: 1.9768787423769634

Epoch: 6| Step: 8
Training loss: 1.8159091472625732
Validation loss: 1.9786315560340881

Epoch: 6| Step: 9
Training loss: 2.2484307289123535
Validation loss: 1.9720164934794109

Epoch: 6| Step: 10
Training loss: 0.9740116596221924
Validation loss: 1.9813896020253499

Epoch: 6| Step: 11
Training loss: 1.3653724193572998
Validation loss: 1.9734422167142232

Epoch: 6| Step: 12
Training loss: 1.0542840957641602
Validation loss: 1.9818272193272908

Epoch: 6| Step: 13
Training loss: 0.8407835960388184
Validation loss: 2.0251633723576865

Epoch: 87| Step: 0
Training loss: 1.2652969360351562
Validation loss: 2.0021925568580627

Epoch: 6| Step: 1
Training loss: 2.2187557220458984
Validation loss: 2.0068785548210144

Epoch: 6| Step: 2
Training loss: 1.4074301719665527
Validation loss: 1.9940677285194397

Epoch: 6| Step: 3
Training loss: 1.1484105587005615
Validation loss: 1.9650426109631856

Epoch: 6| Step: 4
Training loss: 1.621642827987671
Validation loss: 2.0248076915740967

Epoch: 6| Step: 5
Training loss: 1.4101403951644897
Validation loss: 1.9720036188761394

Epoch: 6| Step: 6
Training loss: 1.8855122327804565
Validation loss: 1.960714856783549

Epoch: 6| Step: 7
Training loss: 1.1804155111312866
Validation loss: 1.9768800139427185

Epoch: 6| Step: 8
Training loss: 1.4913076162338257
Validation loss: 1.997284968694051

Epoch: 6| Step: 9
Training loss: 0.7458255290985107
Validation loss: 2.0467540423075357

Epoch: 6| Step: 10
Training loss: 2.2335071563720703
Validation loss: 2.0344279209772744

Epoch: 6| Step: 11
Training loss: 0.7355289459228516
Validation loss: 2.032891313234965

Epoch: 6| Step: 12
Training loss: 1.1156331300735474
Validation loss: 2.055644075075785

Epoch: 6| Step: 13
Training loss: 1.1858885288238525
Validation loss: 2.0412418047587075

Epoch: 88| Step: 0
Training loss: 1.1223785877227783
Validation loss: 2.0340014696121216

Epoch: 6| Step: 1
Training loss: 1.2524678707122803
Validation loss: 1.9764676690101624

Epoch: 6| Step: 2
Training loss: 1.642733097076416
Validation loss: 2.0258493423461914

Epoch: 6| Step: 3
Training loss: 1.097659945487976
Validation loss: 1.961411714553833

Epoch: 6| Step: 4
Training loss: 1.277242660522461
Validation loss: 1.9827172756195068

Epoch: 6| Step: 5
Training loss: 1.536458969116211
Validation loss: 2.007505794366201

Epoch: 6| Step: 6
Training loss: 1.7549662590026855
Validation loss: 2.026937246322632

Epoch: 6| Step: 7
Training loss: 1.6335645914077759
Validation loss: 1.9467819730440776

Epoch: 6| Step: 8
Training loss: 1.5646672248840332
Validation loss: 2.0131478309631348

Epoch: 6| Step: 9
Training loss: 1.5057337284088135
Validation loss: 2.003896176815033

Epoch: 6| Step: 10
Training loss: 1.7064757347106934
Validation loss: 2.019702116648356

Epoch: 6| Step: 11
Training loss: 1.3374515771865845
Validation loss: 2.0192091862360635

Epoch: 6| Step: 12
Training loss: 0.9153940081596375
Validation loss: 1.9919666051864624

Epoch: 6| Step: 13
Training loss: 1.3089488744735718
Validation loss: 2.065241058667501

Epoch: 89| Step: 0
Training loss: 1.6658039093017578
Validation loss: 2.0192648569742837

Epoch: 6| Step: 1
Training loss: 1.4262863397598267
Validation loss: 2.052053610483805

Epoch: 6| Step: 2
Training loss: 1.550278663635254
Validation loss: 2.0593568086624146

Epoch: 6| Step: 3
Training loss: 1.0498156547546387
Validation loss: 2.027416149775187

Epoch: 6| Step: 4
Training loss: 1.044103980064392
Validation loss: 2.0321192344029746

Epoch: 6| Step: 5
Training loss: 1.3995511531829834
Validation loss: 2.009639620780945

Epoch: 6| Step: 6
Training loss: 1.5619490146636963
Validation loss: 1.9602224230766296

Epoch: 6| Step: 7
Training loss: 1.604419231414795
Validation loss: 1.965724527835846

Epoch: 6| Step: 8
Training loss: 0.950918436050415
Validation loss: 1.9440497159957886

Epoch: 6| Step: 9
Training loss: 1.2366523742675781
Validation loss: 1.948966920375824

Epoch: 6| Step: 10
Training loss: 1.9420018196105957
Validation loss: 1.9857975244522095

Epoch: 6| Step: 11
Training loss: 1.2815954685211182
Validation loss: 1.9702114860216777

Epoch: 6| Step: 12
Training loss: 1.2395620346069336
Validation loss: 2.048553943634033

Epoch: 6| Step: 13
Training loss: 1.2850794792175293
Validation loss: 2.005671958128611

Epoch: 90| Step: 0
Training loss: 1.2797905206680298
Validation loss: 2.0098529855410256

Epoch: 6| Step: 1
Training loss: 1.195565938949585
Validation loss: 2.05543061097463

Epoch: 6| Step: 2
Training loss: 0.9057945013046265
Validation loss: 2.054624001185099

Epoch: 6| Step: 3
Training loss: 1.3610668182373047
Validation loss: 2.070017417271932

Epoch: 6| Step: 4
Training loss: 1.011866807937622
Validation loss: 2.065069019794464

Epoch: 6| Step: 5
Training loss: 2.0073695182800293
Validation loss: 2.0445802410443625

Epoch: 6| Step: 6
Training loss: 1.0059118270874023
Validation loss: 2.04913729429245

Epoch: 6| Step: 7
Training loss: 1.4737656116485596
Validation loss: 1.9717515110969543

Epoch: 6| Step: 8
Training loss: 1.7270854711532593
Validation loss: 1.9621981581052144

Epoch: 6| Step: 9
Training loss: 1.9613831043243408
Validation loss: 1.9167711933453877

Epoch: 6| Step: 10
Training loss: 1.7032012939453125
Validation loss: 1.9167433977127075

Epoch: 6| Step: 11
Training loss: 1.1737143993377686
Validation loss: 1.9439748922983806

Epoch: 6| Step: 12
Training loss: 1.7617683410644531
Validation loss: 1.9172664682070415

Epoch: 6| Step: 13
Training loss: 1.1861902475357056
Validation loss: 1.9186348517735798

Epoch: 91| Step: 0
Training loss: 1.3396201133728027
Validation loss: 1.9436007340749104

Epoch: 6| Step: 1
Training loss: 1.3127551078796387
Validation loss: 1.9743560353914897

Epoch: 6| Step: 2
Training loss: 1.4893758296966553
Validation loss: 2.0210616985956826

Epoch: 6| Step: 3
Training loss: 1.3888905048370361
Validation loss: 2.137811998526255

Epoch: 6| Step: 4
Training loss: 1.1249175071716309
Validation loss: 2.1394198735555015

Epoch: 6| Step: 5
Training loss: 1.291623592376709
Validation loss: 2.1412681539853415

Epoch: 6| Step: 6
Training loss: 1.8055481910705566
Validation loss: 2.1365975538889566

Epoch: 6| Step: 7
Training loss: 2.0468955039978027
Validation loss: 2.0667019287745156

Epoch: 6| Step: 8
Training loss: 1.3335562944412231
Validation loss: 1.995808184146881

Epoch: 6| Step: 9
Training loss: 1.3703372478485107
Validation loss: 1.9641988674799602

Epoch: 6| Step: 10
Training loss: 0.9376152753829956
Validation loss: 1.9125824173291524

Epoch: 6| Step: 11
Training loss: 1.3480998277664185
Validation loss: 1.9542828400929768

Epoch: 6| Step: 12
Training loss: 1.6725903749465942
Validation loss: 1.9796762267748516

Epoch: 6| Step: 13
Training loss: 1.5579113960266113
Validation loss: 1.9673454960187275

Epoch: 92| Step: 0
Training loss: 1.4677469730377197
Validation loss: 1.9357211987177532

Epoch: 6| Step: 1
Training loss: 1.3073210716247559
Validation loss: 2.01566348473231

Epoch: 6| Step: 2
Training loss: 1.2180259227752686
Validation loss: 2.023745596408844

Epoch: 6| Step: 3
Training loss: 1.8542723655700684
Validation loss: 2.0385427276293435

Epoch: 6| Step: 4
Training loss: 0.7019510269165039
Validation loss: 2.0451404253641763

Epoch: 6| Step: 5
Training loss: 1.103514552116394
Validation loss: 2.082227567831675

Epoch: 6| Step: 6
Training loss: 1.3498517274856567
Validation loss: 2.014781355857849

Epoch: 6| Step: 7
Training loss: 1.9713380336761475
Validation loss: 1.998364269733429

Epoch: 6| Step: 8
Training loss: 1.3834795951843262
Validation loss: 1.9552021622657776

Epoch: 6| Step: 9
Training loss: 1.2695326805114746
Validation loss: 2.012847344080607

Epoch: 6| Step: 10
Training loss: 0.9000146389007568
Validation loss: 1.9782933990160625

Epoch: 6| Step: 11
Training loss: 0.9117600917816162
Validation loss: 2.0151103734970093

Epoch: 6| Step: 12
Training loss: 1.8222346305847168
Validation loss: 2.0139061411221824

Epoch: 6| Step: 13
Training loss: 1.4390332698822021
Validation loss: 2.0355345408121743

Epoch: 93| Step: 0
Training loss: 1.6474852561950684
Validation loss: 1.9888915816942851

Epoch: 6| Step: 1
Training loss: 1.631559133529663
Validation loss: 1.9960890412330627

Epoch: 6| Step: 2
Training loss: 1.2584526538848877
Validation loss: 2.037100315093994

Epoch: 6| Step: 3
Training loss: 1.453387975692749
Validation loss: 1.991494079430898

Epoch: 6| Step: 4
Training loss: 0.9695358872413635
Validation loss: 1.9707558751106262

Epoch: 6| Step: 5
Training loss: 1.2390921115875244
Validation loss: 1.958973467350006

Epoch: 6| Step: 6
Training loss: 1.1231900453567505
Validation loss: 1.944970389207204

Epoch: 6| Step: 7
Training loss: 1.3133511543273926
Validation loss: 1.9648472269376118

Epoch: 6| Step: 8
Training loss: 0.6571794748306274
Validation loss: 2.0272507667541504

Epoch: 6| Step: 9
Training loss: 1.0186688899993896
Validation loss: 2.0373509724934897

Epoch: 6| Step: 10
Training loss: 1.4755089282989502
Validation loss: 1.975514789422353

Epoch: 6| Step: 11
Training loss: 1.4769175052642822
Validation loss: 2.0526960690816245

Epoch: 6| Step: 12
Training loss: 1.1220734119415283
Validation loss: 2.124445696671804

Epoch: 6| Step: 13
Training loss: 2.050499439239502
Validation loss: 2.1323636174201965

Epoch: 94| Step: 0
Training loss: 1.805445909500122
Validation loss: 2.091088672478994

Epoch: 6| Step: 1
Training loss: 1.7295418977737427
Validation loss: 2.112918277581533

Epoch: 6| Step: 2
Training loss: 1.3940119743347168
Validation loss: 2.0308069586753845

Epoch: 6| Step: 3
Training loss: 1.3374849557876587
Validation loss: 2.0119739373524985

Epoch: 6| Step: 4
Training loss: 1.15895676612854
Validation loss: 1.9497016270955403

Epoch: 6| Step: 5
Training loss: 1.3425160646438599
Validation loss: 1.9493091305096943

Epoch: 6| Step: 6
Training loss: 1.3778201341629028
Validation loss: 1.92757648229599

Epoch: 6| Step: 7
Training loss: 1.3535165786743164
Validation loss: 1.9531026085217793

Epoch: 6| Step: 8
Training loss: 1.2371411323547363
Validation loss: 2.001262684663137

Epoch: 6| Step: 9
Training loss: 1.0455281734466553
Validation loss: 2.046984871228536

Epoch: 6| Step: 10
Training loss: 0.8625800013542175
Validation loss: 2.0842724442481995

Epoch: 6| Step: 11
Training loss: 1.1132714748382568
Validation loss: 2.104212979475657

Epoch: 6| Step: 12
Training loss: 1.2264704704284668
Validation loss: 2.0605987111727395

Epoch: 6| Step: 13
Training loss: 1.7478630542755127
Validation loss: 1.974053978919983

Epoch: 95| Step: 0
Training loss: 1.077558159828186
Validation loss: 2.0619490345319114

Epoch: 6| Step: 1
Training loss: 1.5452680587768555
Validation loss: 1.9978764255841572

Epoch: 6| Step: 2
Training loss: 1.4763903617858887
Validation loss: 1.924393653869629

Epoch: 6| Step: 3
Training loss: 1.1089460849761963
Validation loss: 1.9079423745473225

Epoch: 6| Step: 4
Training loss: 1.4115180969238281
Validation loss: 1.995212157567342

Epoch: 6| Step: 5
Training loss: 1.1930005550384521
Validation loss: 1.9063121676445007

Epoch: 6| Step: 6
Training loss: 1.0361299514770508
Validation loss: 1.9747443000475566

Epoch: 6| Step: 7
Training loss: 1.1781949996948242
Validation loss: 2.0195749203364053

Epoch: 6| Step: 8
Training loss: 1.3326115608215332
Validation loss: 2.1264999310175576

Epoch: 6| Step: 9
Training loss: 1.6833820343017578
Validation loss: 2.090872506300608

Epoch: 6| Step: 10
Training loss: 0.8793895244598389
Validation loss: 2.0757819612820945

Epoch: 6| Step: 11
Training loss: 1.6273224353790283
Validation loss: 2.089015622933706

Epoch: 6| Step: 12
Training loss: 1.671860694885254
Validation loss: 2.0427195032437644

Epoch: 6| Step: 13
Training loss: 1.178830862045288
Validation loss: 1.9679001569747925

Epoch: 96| Step: 0
Training loss: 0.6203582286834717
Validation loss: 1.9720887939135234

Epoch: 6| Step: 1
Training loss: 1.7553051710128784
Validation loss: 1.9431858857472737

Epoch: 6| Step: 2
Training loss: 1.489919662475586
Validation loss: 1.9282833536465962

Epoch: 6| Step: 3
Training loss: 1.2322269678115845
Validation loss: 1.940363625685374

Epoch: 6| Step: 4
Training loss: 1.9613207578659058
Validation loss: 1.9407334526379902

Epoch: 6| Step: 5
Training loss: 1.6399805545806885
Validation loss: 1.993908405303955

Epoch: 6| Step: 6
Training loss: 0.8627965450286865
Validation loss: 1.9694874286651611

Epoch: 6| Step: 7
Training loss: 1.3686754703521729
Validation loss: 1.9690021276474

Epoch: 6| Step: 8
Training loss: 1.7794981002807617
Validation loss: 1.9917031327883403

Epoch: 6| Step: 9
Training loss: 0.8555468916893005
Validation loss: 2.0106061498324075

Epoch: 6| Step: 10
Training loss: 0.7001305818557739
Validation loss: 2.0584564208984375

Epoch: 6| Step: 11
Training loss: 1.3454325199127197
Validation loss: 2.007823646068573

Epoch: 6| Step: 12
Training loss: 1.4235625267028809
Validation loss: 2.053179085254669

Epoch: 6| Step: 13
Training loss: 0.7689751982688904
Validation loss: 2.1027894218762717

Epoch: 97| Step: 0
Training loss: 1.7882000207901
Validation loss: 2.077847123146057

Epoch: 6| Step: 1
Training loss: 1.4197834730148315
Validation loss: 2.0755812923113504

Epoch: 6| Step: 2
Training loss: 1.3039190769195557
Validation loss: 1.982149342695872

Epoch: 6| Step: 3
Training loss: 1.1473033428192139
Validation loss: 1.9712026715278625

Epoch: 6| Step: 4
Training loss: 1.0554887056350708
Validation loss: 1.947852651278178

Epoch: 6| Step: 5
Training loss: 1.2047196626663208
Validation loss: 2.001872181892395

Epoch: 6| Step: 6
Training loss: 0.8460423350334167
Validation loss: 1.9359024365743

Epoch: 6| Step: 7
Training loss: 1.0126850605010986
Validation loss: 1.9657759070396423

Epoch: 6| Step: 8
Training loss: 1.323311448097229
Validation loss: 2.0681029756863913

Epoch: 6| Step: 9
Training loss: 1.6672000885009766
Validation loss: 2.1188817222913108

Epoch: 6| Step: 10
Training loss: 1.783872365951538
Validation loss: 2.0778103272120156

Epoch: 6| Step: 11
Training loss: 0.7413386106491089
Validation loss: 2.0476850469907126

Epoch: 6| Step: 12
Training loss: 1.169821858406067
Validation loss: 2.0478709936141968

Epoch: 6| Step: 13
Training loss: 1.686019778251648
Validation loss: 1.971660594145457

Epoch: 98| Step: 0
Training loss: 1.7132513523101807
Validation loss: 2.0272905031840005

Epoch: 6| Step: 1
Training loss: 1.398113489151001
Validation loss: 1.961299439271291

Epoch: 6| Step: 2
Training loss: 1.2474884986877441
Validation loss: 1.9582999746004741

Epoch: 6| Step: 3
Training loss: 1.0737777948379517
Validation loss: 1.955698589483897

Epoch: 6| Step: 4
Training loss: 0.8797733187675476
Validation loss: 1.9518275062243144

Epoch: 6| Step: 5
Training loss: 1.543808937072754
Validation loss: 1.9521524707476299

Epoch: 6| Step: 6
Training loss: 1.0302461385726929
Validation loss: 1.999294598897298

Epoch: 6| Step: 7
Training loss: 1.1551522016525269
Validation loss: 1.9771629571914673

Epoch: 6| Step: 8
Training loss: 0.8984270691871643
Validation loss: 1.9916590452194214

Epoch: 6| Step: 9
Training loss: 1.0311702489852905
Validation loss: 2.0366679032643638

Epoch: 6| Step: 10
Training loss: 2.365138053894043
Validation loss: 2.0668883124987283

Epoch: 6| Step: 11
Training loss: 1.0170053243637085
Validation loss: 2.022712071736654

Epoch: 6| Step: 12
Training loss: 1.5612154006958008
Validation loss: 2.083442290623983

Epoch: 6| Step: 13
Training loss: 0.583149254322052
Validation loss: 2.082275688648224

Epoch: 99| Step: 0
Training loss: 1.2161693572998047
Validation loss: 1.987052361170451

Epoch: 6| Step: 1
Training loss: 1.3315386772155762
Validation loss: 2.014993170897166

Epoch: 6| Step: 2
Training loss: 0.9455603361129761
Validation loss: 1.985407551129659

Epoch: 6| Step: 3
Training loss: 1.6171666383743286
Validation loss: 1.9619378050168355

Epoch: 6| Step: 4
Training loss: 1.3153514862060547
Validation loss: 1.963298738002777

Epoch: 6| Step: 5
Training loss: 0.9098660945892334
Validation loss: 1.96273934841156

Epoch: 6| Step: 6
Training loss: 1.0991811752319336
Validation loss: 1.940894881884257

Epoch: 6| Step: 7
Training loss: 1.4449753761291504
Validation loss: 1.98715744415919

Epoch: 6| Step: 8
Training loss: 0.9660876393318176
Validation loss: 2.005190134048462

Epoch: 6| Step: 9
Training loss: 1.5293946266174316
Validation loss: 1.960192898909251

Epoch: 6| Step: 10
Training loss: 1.3989938497543335
Validation loss: 2.0207473238309226

Epoch: 6| Step: 11
Training loss: 1.0270534753799438
Validation loss: 1.909744401772817

Epoch: 6| Step: 12
Training loss: 1.650815486907959
Validation loss: 1.9659650723139446

Epoch: 6| Step: 13
Training loss: 0.8396505117416382
Validation loss: 1.9521308938662212

Epoch: 100| Step: 0
Training loss: 1.7891845703125
Validation loss: 1.9186617533365886

Epoch: 6| Step: 1
Training loss: 1.4675569534301758
Validation loss: 1.9509871403376262

Epoch: 6| Step: 2
Training loss: 1.2443952560424805
Validation loss: 1.9994584719340007

Epoch: 6| Step: 3
Training loss: 1.6119749546051025
Validation loss: 1.9696263869603474

Epoch: 6| Step: 4
Training loss: 0.7327321171760559
Validation loss: 1.9814951419830322

Epoch: 6| Step: 5
Training loss: 1.1079639196395874
Validation loss: 1.9706879059473674

Epoch: 6| Step: 6
Training loss: 2.343488931655884
Validation loss: 1.9915106296539307

Epoch: 6| Step: 7
Training loss: 1.2636773586273193
Validation loss: 1.9910523494084675

Epoch: 6| Step: 8
Training loss: 0.893221378326416
Validation loss: 1.9658706188201904

Epoch: 6| Step: 9
Training loss: 0.6796243190765381
Validation loss: 1.959357003370921

Epoch: 6| Step: 10
Training loss: 0.8386485576629639
Validation loss: 1.993740399678548

Epoch: 6| Step: 11
Training loss: 0.832793116569519
Validation loss: 2.0601329604784646

Epoch: 6| Step: 12
Training loss: 1.348078966140747
Validation loss: 2.0637329618136087

Epoch: 6| Step: 13
Training loss: 1.0187225341796875
Validation loss: 2.0759896636009216

Epoch: 101| Step: 0
Training loss: 1.2057067155838013
Validation loss: 2.093222459157308

Epoch: 6| Step: 1
Training loss: 0.9901474714279175
Validation loss: 2.0487353603045144

Epoch: 6| Step: 2
Training loss: 1.4350320100784302
Validation loss: 2.0118893583615622

Epoch: 6| Step: 3
Training loss: 1.3101842403411865
Validation loss: 2.0193702379862466

Epoch: 6| Step: 4
Training loss: 0.9868124127388
Validation loss: 1.9797736008961995

Epoch: 6| Step: 5
Training loss: 1.1467561721801758
Validation loss: 1.970360775788625

Epoch: 6| Step: 6
Training loss: 0.7925131320953369
Validation loss: 1.9505005478858948

Epoch: 6| Step: 7
Training loss: 1.6135789155960083
Validation loss: 1.9738925099372864

Epoch: 6| Step: 8
Training loss: 1.0884513854980469
Validation loss: 1.9472367763519287

Epoch: 6| Step: 9
Training loss: 1.0493165254592896
Validation loss: 1.9783902963002522

Epoch: 6| Step: 10
Training loss: 1.2799639701843262
Validation loss: 1.9904382824897766

Epoch: 6| Step: 11
Training loss: 1.2656170129776
Validation loss: 1.9401509364446003

Epoch: 6| Step: 12
Training loss: 1.4126181602478027
Validation loss: 1.9793914755185444

Epoch: 6| Step: 13
Training loss: 1.2940621376037598
Validation loss: 1.9895193378130596

Epoch: 102| Step: 0
Training loss: 1.3769608736038208
Validation loss: 1.9820717175801594

Epoch: 6| Step: 1
Training loss: 1.39537513256073
Validation loss: 2.0180124243100486

Epoch: 6| Step: 2
Training loss: 0.8934047222137451
Validation loss: 2.020148833592733

Epoch: 6| Step: 3
Training loss: 1.0972546339035034
Validation loss: 2.036854366461436

Epoch: 6| Step: 4
Training loss: 1.1574267148971558
Validation loss: 2.104259411493937

Epoch: 6| Step: 5
Training loss: 0.9234861731529236
Validation loss: 2.099099894364675

Epoch: 6| Step: 6
Training loss: 1.6948785781860352
Validation loss: 2.0557872454325357

Epoch: 6| Step: 7
Training loss: 0.9988067150115967
Validation loss: 2.041891634464264

Epoch: 6| Step: 8
Training loss: 0.7944841980934143
Validation loss: 1.9716697732607524

Epoch: 6| Step: 9
Training loss: 1.3134942054748535
Validation loss: 1.9633424679438274

Epoch: 6| Step: 10
Training loss: 1.1529268026351929
Validation loss: 1.934441367785136

Epoch: 6| Step: 11
Training loss: 1.5888773202896118
Validation loss: 1.955195128917694

Epoch: 6| Step: 12
Training loss: 1.5561245679855347
Validation loss: 1.9253170887629192

Epoch: 6| Step: 13
Training loss: 1.4649730920791626
Validation loss: 1.9467970132827759

Epoch: 103| Step: 0
Training loss: 0.8887702226638794
Validation loss: 1.923888921737671

Epoch: 6| Step: 1
Training loss: 1.9728851318359375
Validation loss: 1.9584890007972717

Epoch: 6| Step: 2
Training loss: 0.9072641134262085
Validation loss: 1.9849824508031209

Epoch: 6| Step: 3
Training loss: 1.0671685934066772
Validation loss: 2.033910393714905

Epoch: 6| Step: 4
Training loss: 1.3809006214141846
Validation loss: 2.1380483706792197

Epoch: 6| Step: 5
Training loss: 0.9483062028884888
Validation loss: 2.145094335079193

Epoch: 6| Step: 6
Training loss: 1.1350600719451904
Validation loss: 2.1357012589772544

Epoch: 6| Step: 7
Training loss: 1.2541704177856445
Validation loss: 2.130780061086019

Epoch: 6| Step: 8
Training loss: 1.2050975561141968
Validation loss: 2.0705472429593406

Epoch: 6| Step: 9
Training loss: 1.51827073097229
Validation loss: 1.998363693555196

Epoch: 6| Step: 10
Training loss: 1.013926386833191
Validation loss: 1.9760149916013081

Epoch: 6| Step: 11
Training loss: 1.3319770097732544
Validation loss: 1.959071199099223

Epoch: 6| Step: 12
Training loss: 0.8935197591781616
Validation loss: 1.9772632122039795

Epoch: 6| Step: 13
Training loss: 1.4135249853134155
Validation loss: 1.9206729928652446

Epoch: 104| Step: 0
Training loss: 1.161103367805481
Validation loss: 1.9543348749478657

Epoch: 6| Step: 1
Training loss: 1.5867522954940796
Validation loss: 1.9597875078519185

Epoch: 6| Step: 2
Training loss: 0.9216459393501282
Validation loss: 2.016747752825419

Epoch: 6| Step: 3
Training loss: 1.0720266103744507
Validation loss: 2.0070040822029114

Epoch: 6| Step: 4
Training loss: 0.5111446380615234
Validation loss: 1.9784252444903057

Epoch: 6| Step: 5
Training loss: 1.2773723602294922
Validation loss: 1.9919789830843608

Epoch: 6| Step: 6
Training loss: 1.1397209167480469
Validation loss: 1.9963909188906352

Epoch: 6| Step: 7
Training loss: 1.3799940347671509
Validation loss: 2.0051299929618835

Epoch: 6| Step: 8
Training loss: 1.2109588384628296
Validation loss: 2.020626664161682

Epoch: 6| Step: 9
Training loss: 0.8941307067871094
Validation loss: 1.999657134215037

Epoch: 6| Step: 10
Training loss: 0.9560484886169434
Validation loss: 2.053678810596466

Epoch: 6| Step: 11
Training loss: 1.2263747453689575
Validation loss: 2.039708117643992

Epoch: 6| Step: 12
Training loss: 1.5832493305206299
Validation loss: 2.0481985608736673

Epoch: 6| Step: 13
Training loss: 1.2799770832061768
Validation loss: 2.0803299148877463

Epoch: 105| Step: 0
Training loss: 0.833640456199646
Validation loss: 2.0021448135375977

Epoch: 6| Step: 1
Training loss: 1.117936134338379
Validation loss: 1.913931707541148

Epoch: 6| Step: 2
Training loss: 1.2392566204071045
Validation loss: 1.9871303240458171

Epoch: 6| Step: 3
Training loss: 0.8346485495567322
Validation loss: 1.9373088677724202

Epoch: 6| Step: 4
Training loss: 0.7304046154022217
Validation loss: 1.9381547768910725

Epoch: 6| Step: 5
Training loss: 0.9312595725059509
Validation loss: 1.9606571197509766

Epoch: 6| Step: 6
Training loss: 1.0947396755218506
Validation loss: 1.9390357335408528

Epoch: 6| Step: 7
Training loss: 1.5448294878005981
Validation loss: 2.0782474478085837

Epoch: 6| Step: 8
Training loss: 1.4155703783035278
Validation loss: 2.0623923540115356

Epoch: 6| Step: 9
Training loss: 1.2461867332458496
Validation loss: 2.0790016651153564

Epoch: 6| Step: 10
Training loss: 1.1346862316131592
Validation loss: 2.067710796991984

Epoch: 6| Step: 11
Training loss: 2.2427544593811035
Validation loss: 2.0101518630981445

Epoch: 6| Step: 12
Training loss: 0.49836796522140503
Validation loss: 2.0310650070508323

Epoch: 6| Step: 13
Training loss: 1.3486438989639282
Validation loss: 2.0212369561195374

Epoch: 106| Step: 0
Training loss: 0.614016056060791
Validation loss: 2.0109854340553284

Epoch: 6| Step: 1
Training loss: 1.188015341758728
Validation loss: 1.984440286954244

Epoch: 6| Step: 2
Training loss: 1.2468268871307373
Validation loss: 2.003662963708242

Epoch: 6| Step: 3
Training loss: 1.0905530452728271
Validation loss: 1.9327738285064697

Epoch: 6| Step: 4
Training loss: 0.9364391565322876
Validation loss: 1.9799235065778096

Epoch: 6| Step: 5
Training loss: 1.4523046016693115
Validation loss: 2.0143984953562417

Epoch: 6| Step: 6
Training loss: 1.4326658248901367
Validation loss: 1.9771823088328044

Epoch: 6| Step: 7
Training loss: 0.8710289001464844
Validation loss: 2.0129496455192566

Epoch: 6| Step: 8
Training loss: 1.1084895133972168
Validation loss: 1.999490241209666

Epoch: 6| Step: 9
Training loss: 1.2430191040039062
Validation loss: 2.059647262096405

Epoch: 6| Step: 10
Training loss: 1.6325511932373047
Validation loss: 2.0445326964060464

Epoch: 6| Step: 11
Training loss: 1.1165838241577148
Validation loss: 2.0395748615264893

Epoch: 6| Step: 12
Training loss: 0.5798200368881226
Validation loss: 2.0254565477371216

Epoch: 6| Step: 13
Training loss: 0.9804394841194153
Validation loss: 2.0490078727404275

Epoch: 107| Step: 0
Training loss: 0.5170515179634094
Validation loss: 1.9798896710077922

Epoch: 6| Step: 1
Training loss: 1.7589085102081299
Validation loss: 1.9355249603589375

Epoch: 6| Step: 2
Training loss: 1.6054389476776123
Validation loss: 1.9501296679178874

Epoch: 6| Step: 3
Training loss: 0.5627990961074829
Validation loss: 1.9101332426071167

Epoch: 6| Step: 4
Training loss: 1.5195461511611938
Validation loss: 1.9728692571322124

Epoch: 6| Step: 5
Training loss: 1.2460370063781738
Validation loss: 1.948318064212799

Epoch: 6| Step: 6
Training loss: 1.4428493976593018
Validation loss: 1.9335517287254333

Epoch: 6| Step: 7
Training loss: 1.1548783779144287
Validation loss: 1.9820748766263325

Epoch: 6| Step: 8
Training loss: 0.9037704467773438
Validation loss: 1.9531245231628418

Epoch: 6| Step: 9
Training loss: 0.8450668454170227
Validation loss: 1.9851104815800984

Epoch: 6| Step: 10
Training loss: 1.3413900136947632
Validation loss: 2.066768527030945

Epoch: 6| Step: 11
Training loss: 1.3015215396881104
Validation loss: 2.097425639629364

Epoch: 6| Step: 12
Training loss: 0.8665188550949097
Validation loss: 2.0821311275164285

Epoch: 6| Step: 13
Training loss: 0.9172840118408203
Validation loss: 2.1181965470314026

Epoch: 108| Step: 0
Training loss: 1.0050832033157349
Validation loss: 2.04729171593984

Epoch: 6| Step: 1
Training loss: 1.1123294830322266
Validation loss: 1.9917155702908833

Epoch: 6| Step: 2
Training loss: 1.403955101966858
Validation loss: 1.9454081654548645

Epoch: 6| Step: 3
Training loss: 0.8743792772293091
Validation loss: 1.9525725642840068

Epoch: 6| Step: 4
Training loss: 1.4728002548217773
Validation loss: 1.905438741048177

Epoch: 6| Step: 5
Training loss: 1.2168400287628174
Validation loss: 1.9267858465512593

Epoch: 6| Step: 6
Training loss: 0.9612992405891418
Validation loss: 1.9057858784993489

Epoch: 6| Step: 7
Training loss: 1.550457239151001
Validation loss: 1.958106239636739

Epoch: 6| Step: 8
Training loss: 0.9318807125091553
Validation loss: 1.9501005212465923

Epoch: 6| Step: 9
Training loss: 1.0097870826721191
Validation loss: 2.009494682153066

Epoch: 6| Step: 10
Training loss: 0.8752202987670898
Validation loss: 2.0762749711672464

Epoch: 6| Step: 11
Training loss: 1.569178581237793
Validation loss: 2.091223975022634

Epoch: 6| Step: 12
Training loss: 1.1943613290786743
Validation loss: 2.093099514643351

Epoch: 6| Step: 13
Training loss: 0.9442205429077148
Validation loss: 2.052922328313192

Epoch: 109| Step: 0
Training loss: 1.1179019212722778
Validation loss: 2.0936541755994162

Epoch: 6| Step: 1
Training loss: 0.7867593765258789
Validation loss: 2.0413946509361267

Epoch: 6| Step: 2
Training loss: 0.679928183555603
Validation loss: 1.9739656845728557

Epoch: 6| Step: 3
Training loss: 1.3346456289291382
Validation loss: 1.9389914870262146

Epoch: 6| Step: 4
Training loss: 1.4899330139160156
Validation loss: 1.9568955898284912

Epoch: 6| Step: 5
Training loss: 1.4481415748596191
Validation loss: 1.9860311945279439

Epoch: 6| Step: 6
Training loss: 1.6294161081314087
Validation loss: 1.9641146858533223

Epoch: 6| Step: 7
Training loss: 0.6518045663833618
Validation loss: 1.9679128925005596

Epoch: 6| Step: 8
Training loss: 1.190425157546997
Validation loss: 2.0181551774342856

Epoch: 6| Step: 9
Training loss: 1.5433712005615234
Validation loss: 2.0563958287239075

Epoch: 6| Step: 10
Training loss: 1.2942816019058228
Validation loss: 2.0946262876192727

Epoch: 6| Step: 11
Training loss: 0.6946457028388977
Validation loss: 2.1241837541262307

Epoch: 6| Step: 12
Training loss: 0.8437563180923462
Validation loss: 2.0320969025293985

Epoch: 6| Step: 13
Training loss: 1.3263509273529053
Validation loss: 2.0253174702326455

Epoch: 110| Step: 0
Training loss: 1.538193702697754
Validation loss: 1.9810617764790852

Epoch: 6| Step: 1
Training loss: 1.5876516103744507
Validation loss: 1.9556993047396343

Epoch: 6| Step: 2
Training loss: 1.0576183795928955
Validation loss: 1.957516849040985

Epoch: 6| Step: 3
Training loss: 1.0680525302886963
Validation loss: 1.9521697958310444

Epoch: 6| Step: 4
Training loss: 1.4742710590362549
Validation loss: 2.00228351354599

Epoch: 6| Step: 5
Training loss: 0.665947675704956
Validation loss: 2.0129091342290244

Epoch: 6| Step: 6
Training loss: 1.0779528617858887
Validation loss: 2.045525074005127

Epoch: 6| Step: 7
Training loss: 0.8879014253616333
Validation loss: 2.0938728054364524

Epoch: 6| Step: 8
Training loss: 0.8028024435043335
Validation loss: 2.074172337849935

Epoch: 6| Step: 9
Training loss: 1.5450308322906494
Validation loss: 2.0504862467447915

Epoch: 6| Step: 10
Training loss: 0.6385627388954163
Validation loss: 1.9970139066378276

Epoch: 6| Step: 11
Training loss: 1.2827199697494507
Validation loss: 1.9964314103126526

Epoch: 6| Step: 12
Training loss: 0.783021867275238
Validation loss: 1.9189603924751282

Epoch: 6| Step: 13
Training loss: 1.177933692932129
Validation loss: 1.961631715297699

Epoch: 111| Step: 0
Training loss: 0.9252856969833374
Validation loss: 1.9610332449277241

Epoch: 6| Step: 1
Training loss: 0.8819575309753418
Validation loss: 1.9777958989143372

Epoch: 6| Step: 2
Training loss: 0.9802706241607666
Validation loss: 1.9476368427276611

Epoch: 6| Step: 3
Training loss: 0.6841118931770325
Validation loss: 1.9443425138791401

Epoch: 6| Step: 4
Training loss: 1.7681212425231934
Validation loss: 2.0191959540049234

Epoch: 6| Step: 5
Training loss: 1.4189952611923218
Validation loss: 2.0173929731051126

Epoch: 6| Step: 6
Training loss: 0.8563467264175415
Validation loss: 2.061919113000234

Epoch: 6| Step: 7
Training loss: 1.0203485488891602
Validation loss: 2.0651323397954306

Epoch: 6| Step: 8
Training loss: 1.0130144357681274
Validation loss: 2.0091205636660256

Epoch: 6| Step: 9
Training loss: 1.5787804126739502
Validation loss: 1.9964483976364136

Epoch: 6| Step: 10
Training loss: 1.2505964040756226
Validation loss: 1.9534888466199238

Epoch: 6| Step: 11
Training loss: 1.2551594972610474
Validation loss: 1.9930382172266643

Epoch: 6| Step: 12
Training loss: 1.121629238128662
Validation loss: 2.0004642407099404

Epoch: 6| Step: 13
Training loss: 0.9070863127708435
Validation loss: 1.9655829071998596

Epoch: 112| Step: 0
Training loss: 0.975526750087738
Validation loss: 1.9986565311749775

Epoch: 6| Step: 1
Training loss: 1.1302863359451294
Validation loss: 2.0629160404205322

Epoch: 6| Step: 2
Training loss: 1.6619271039962769
Validation loss: 2.0421626766522727

Epoch: 6| Step: 3
Training loss: 1.1265687942504883
Validation loss: 2.078970491886139

Epoch: 6| Step: 4
Training loss: 1.1761550903320312
Validation loss: 2.132619043191274

Epoch: 6| Step: 5
Training loss: 0.9574411511421204
Validation loss: 2.06147700548172

Epoch: 6| Step: 6
Training loss: 0.8375253081321716
Validation loss: 2.1069827477137246

Epoch: 6| Step: 7
Training loss: 0.9214305877685547
Validation loss: 2.0876493652661643

Epoch: 6| Step: 8
Training loss: 1.0935088396072388
Validation loss: 2.067924439907074

Epoch: 6| Step: 9
Training loss: 0.60471510887146
Validation loss: 2.0081531405448914

Epoch: 6| Step: 10
Training loss: 0.9520010352134705
Validation loss: 1.936737835407257

Epoch: 6| Step: 11
Training loss: 1.162374496459961
Validation loss: 2.0014081796010337

Epoch: 6| Step: 12
Training loss: 1.3573520183563232
Validation loss: 1.9941339095433552

Epoch: 6| Step: 13
Training loss: 1.1554477214813232
Validation loss: 1.9710400899251301

Epoch: 113| Step: 0
Training loss: 0.9216225147247314
Validation loss: 1.935708224773407

Epoch: 6| Step: 1
Training loss: 1.1669591665267944
Validation loss: 2.0015596747398376

Epoch: 6| Step: 2
Training loss: 0.7259360551834106
Validation loss: 1.985390802224477

Epoch: 6| Step: 3
Training loss: 1.464807152748108
Validation loss: 2.0068712631861367

Epoch: 6| Step: 4
Training loss: 0.8013685941696167
Validation loss: 2.0149549643198648

Epoch: 6| Step: 5
Training loss: 0.6502399444580078
Validation loss: 2.0361916025479636

Epoch: 6| Step: 6
Training loss: 1.6182994842529297
Validation loss: 2.0141348838806152

Epoch: 6| Step: 7
Training loss: 0.5744368433952332
Validation loss: 1.9252408345540364

Epoch: 6| Step: 8
Training loss: 0.5926203727722168
Validation loss: 1.9521992802619934

Epoch: 6| Step: 9
Training loss: 1.6571366786956787
Validation loss: 1.989304502805074

Epoch: 6| Step: 10
Training loss: 0.7729411125183105
Validation loss: 1.9967992305755615

Epoch: 6| Step: 11
Training loss: 1.1544420719146729
Validation loss: 1.9678790867328644

Epoch: 6| Step: 12
Training loss: 1.1629817485809326
Validation loss: 1.934803585211436

Epoch: 6| Step: 13
Training loss: 1.216189980506897
Validation loss: 1.9549619754155476

Epoch: 114| Step: 0
Training loss: 0.874405562877655
Validation loss: 2.0335424343744912

Epoch: 6| Step: 1
Training loss: 0.6557765007019043
Validation loss: 2.0109970370928445

Epoch: 6| Step: 2
Training loss: 0.925044059753418
Validation loss: 2.04407145579656

Epoch: 6| Step: 3
Training loss: 1.3660143613815308
Validation loss: 2.0465120474497476

Epoch: 6| Step: 4
Training loss: 1.1492743492126465
Validation loss: 2.05011785030365

Epoch: 6| Step: 5
Training loss: 1.5227724313735962
Validation loss: 1.9524312615394592

Epoch: 6| Step: 6
Training loss: 1.4344451427459717
Validation loss: 1.9710596601168315

Epoch: 6| Step: 7
Training loss: 0.8568772077560425
Validation loss: 1.9423427780469258

Epoch: 6| Step: 8
Training loss: 0.9675021171569824
Validation loss: 1.9939866264661152

Epoch: 6| Step: 9
Training loss: 1.2545852661132812
Validation loss: 1.9661898811658223

Epoch: 6| Step: 10
Training loss: 0.9046873450279236
Validation loss: 1.9522834221522014

Epoch: 6| Step: 11
Training loss: 0.7978555560112
Validation loss: 1.9484644929567974

Epoch: 6| Step: 12
Training loss: 0.8780658841133118
Validation loss: 1.9613662560780842

Epoch: 6| Step: 13
Training loss: 1.0286874771118164
Validation loss: 1.9864819844563801

Epoch: 115| Step: 0
Training loss: 0.7200604677200317
Validation loss: 1.9751925865809123

Epoch: 6| Step: 1
Training loss: 0.8330681324005127
Validation loss: 2.0313387910525003

Epoch: 6| Step: 2
Training loss: 1.2051243782043457
Validation loss: 2.1154686411221824

Epoch: 6| Step: 3
Training loss: 1.1684973239898682
Validation loss: 2.021618366241455

Epoch: 6| Step: 4
Training loss: 1.6041805744171143
Validation loss: 2.0028240283330283

Epoch: 6| Step: 5
Training loss: 0.6121854782104492
Validation loss: 1.976069708665212

Epoch: 6| Step: 6
Training loss: 0.9559552073478699
Validation loss: 1.9639700253804524

Epoch: 6| Step: 7
Training loss: 1.4900233745574951
Validation loss: 1.955672065416972

Epoch: 6| Step: 8
Training loss: 0.9671809673309326
Validation loss: 1.9442684650421143

Epoch: 6| Step: 9
Training loss: 0.8916123509407043
Validation loss: 2.0010175506273904

Epoch: 6| Step: 10
Training loss: 1.0313469171524048
Validation loss: 1.9542592366536458

Epoch: 6| Step: 11
Training loss: 1.259164810180664
Validation loss: 1.9787914951642354

Epoch: 6| Step: 12
Training loss: 1.0119297504425049
Validation loss: 1.9834981362024944

Epoch: 6| Step: 13
Training loss: 0.958580493927002
Validation loss: 2.0072752237319946

Epoch: 116| Step: 0
Training loss: 1.638091802597046
Validation loss: 2.0399363239606223

Epoch: 6| Step: 1
Training loss: 0.9615064859390259
Validation loss: 1.980195979277293

Epoch: 6| Step: 2
Training loss: 0.7021040916442871
Validation loss: 1.9596754908561707

Epoch: 6| Step: 3
Training loss: 0.8766576051712036
Validation loss: 2.0117321411768594

Epoch: 6| Step: 4
Training loss: 1.6540876626968384
Validation loss: 1.9184150695800781

Epoch: 6| Step: 5
Training loss: 0.67027747631073
Validation loss: 1.9745347301165264

Epoch: 6| Step: 6
Training loss: 1.3796278238296509
Validation loss: 1.9533008535703023

Epoch: 6| Step: 7
Training loss: 0.7143309116363525
Validation loss: 1.9326027631759644

Epoch: 6| Step: 8
Training loss: 1.5540668964385986
Validation loss: 1.93780521551768

Epoch: 6| Step: 9
Training loss: 1.1065526008605957
Validation loss: 1.985970397790273

Epoch: 6| Step: 10
Training loss: 1.0106689929962158
Validation loss: 1.9906709392865498

Epoch: 6| Step: 11
Training loss: 0.4930973947048187
Validation loss: 2.0580647389094033

Epoch: 6| Step: 12
Training loss: 0.8303855061531067
Validation loss: 2.026502331097921

Epoch: 6| Step: 13
Training loss: 0.6673992872238159
Validation loss: 2.0569265882174173

Epoch: 117| Step: 0
Training loss: 0.8972446322441101
Validation loss: 2.048090120156606

Epoch: 6| Step: 1
Training loss: 0.5111901164054871
Validation loss: 2.06255970398585

Epoch: 6| Step: 2
Training loss: 1.2523236274719238
Validation loss: 2.0027464628219604

Epoch: 6| Step: 3
Training loss: 0.924828052520752
Validation loss: 1.9579872290293376

Epoch: 6| Step: 4
Training loss: 0.7481112480163574
Validation loss: 1.9883049726486206

Epoch: 6| Step: 5
Training loss: 1.2680848836898804
Validation loss: 1.940926730632782

Epoch: 6| Step: 6
Training loss: 1.1371073722839355
Validation loss: 1.9429137706756592

Epoch: 6| Step: 7
Training loss: 1.0220612287521362
Validation loss: 1.9412986437479656

Epoch: 6| Step: 8
Training loss: 1.1424399614334106
Validation loss: 1.9504762689272563

Epoch: 6| Step: 9
Training loss: 0.9082224369049072
Validation loss: 2.0429967443148294

Epoch: 6| Step: 10
Training loss: 0.9399411678314209
Validation loss: 2.0392983754475913

Epoch: 6| Step: 11
Training loss: 1.0527738332748413
Validation loss: 2.0528693000475564

Epoch: 6| Step: 12
Training loss: 1.3731094598770142
Validation loss: 2.0008103251457214

Epoch: 6| Step: 13
Training loss: 0.7126621007919312
Validation loss: 2.064225415388743

Epoch: 118| Step: 0
Training loss: 1.0267661809921265
Validation loss: 2.000825802485148

Epoch: 6| Step: 1
Training loss: 0.5605627298355103
Validation loss: 1.9664156834284465

Epoch: 6| Step: 2
Training loss: 1.0744168758392334
Validation loss: 1.9981395999590557

Epoch: 6| Step: 3
Training loss: 1.080259084701538
Validation loss: 2.03300150235494

Epoch: 6| Step: 4
Training loss: 1.3865079879760742
Validation loss: 2.002660652001699

Epoch: 6| Step: 5
Training loss: 1.0962425470352173
Validation loss: 2.0204389492670694

Epoch: 6| Step: 6
Training loss: 0.7965765595436096
Validation loss: 1.95898042122523

Epoch: 6| Step: 7
Training loss: 0.935844898223877
Validation loss: 2.0026137232780457

Epoch: 6| Step: 8
Training loss: 0.9834312796592712
Validation loss: 1.9796122709910076

Epoch: 6| Step: 9
Training loss: 0.3818797171115875
Validation loss: 2.0000757972399392

Epoch: 6| Step: 10
Training loss: 1.1766878366470337
Validation loss: 2.0369474490483603

Epoch: 6| Step: 11
Training loss: 1.241004228591919
Validation loss: 1.9940329591433208

Epoch: 6| Step: 12
Training loss: 1.3416199684143066
Validation loss: 1.9803892175356548

Epoch: 6| Step: 13
Training loss: 0.5229215025901794
Validation loss: 1.896184245745341

Epoch: 119| Step: 0
Training loss: 0.7553438544273376
Validation loss: 1.942684570948283

Epoch: 6| Step: 1
Training loss: 1.3235377073287964
Validation loss: 1.9931446711222331

Epoch: 6| Step: 2
Training loss: 0.7187989950180054
Validation loss: 1.959643046061198

Epoch: 6| Step: 3
Training loss: 0.9684750437736511
Validation loss: 1.9349472721417744

Epoch: 6| Step: 4
Training loss: 0.5757308602333069
Validation loss: 2.053171992301941

Epoch: 6| Step: 5
Training loss: 0.8374326229095459
Validation loss: 2.0091981093088784

Epoch: 6| Step: 6
Training loss: 0.7440571188926697
Validation loss: 1.9272813200950623

Epoch: 6| Step: 7
Training loss: 1.2072031497955322
Validation loss: 2.0152833660443625

Epoch: 6| Step: 8
Training loss: 0.7149198651313782
Validation loss: 2.0361794034639993

Epoch: 6| Step: 9
Training loss: 0.6244533061981201
Validation loss: 1.9390947421391804

Epoch: 6| Step: 10
Training loss: 1.0800378322601318
Validation loss: 1.9827339053153992

Epoch: 6| Step: 11
Training loss: 1.3813884258270264
Validation loss: 1.979885995388031

Epoch: 6| Step: 12
Training loss: 1.2739769220352173
Validation loss: 1.9488593141237895

Epoch: 6| Step: 13
Training loss: 1.2854156494140625
Validation loss: 1.963462769985199

Epoch: 120| Step: 0
Training loss: 0.6878879070281982
Validation loss: 1.963395595550537

Epoch: 6| Step: 1
Training loss: 1.1487655639648438
Validation loss: 2.015597343444824

Epoch: 6| Step: 2
Training loss: 1.0178430080413818
Validation loss: 1.9947525064150493

Epoch: 6| Step: 3
Training loss: 1.3052027225494385
Validation loss: 2.0264928142229715

Epoch: 6| Step: 4
Training loss: 0.4928658604621887
Validation loss: 1.9825722773869832

Epoch: 6| Step: 5
Training loss: 0.8411544561386108
Validation loss: 2.006812036037445

Epoch: 6| Step: 6
Training loss: 1.772587776184082
Validation loss: 2.0701884428660073

Epoch: 6| Step: 7
Training loss: 0.6194893717765808
Validation loss: 2.0563234289487204

Epoch: 6| Step: 8
Training loss: 1.364509105682373
Validation loss: 1.9884955684343975

Epoch: 6| Step: 9
Training loss: 0.6941232085227966
Validation loss: 1.9358462293942769

Epoch: 6| Step: 10
Training loss: 0.916663646697998
Validation loss: 1.949626386165619

Epoch: 6| Step: 11
Training loss: 0.908770740032196
Validation loss: 1.9470746119817097

Epoch: 6| Step: 12
Training loss: 1.0251911878585815
Validation loss: 1.947948157787323

Epoch: 6| Step: 13
Training loss: 0.4753039479255676
Validation loss: 1.937576134999593

Epoch: 121| Step: 0
Training loss: 0.9108432531356812
Validation loss: 1.9627705812454224

Epoch: 6| Step: 1
Training loss: 0.5919297933578491
Validation loss: 2.0222089886665344

Epoch: 6| Step: 2
Training loss: 1.0951766967773438
Validation loss: 2.030647406975428

Epoch: 6| Step: 3
Training loss: 0.41336116194725037
Validation loss: 2.0044246514638266

Epoch: 6| Step: 4
Training loss: 0.8326557874679565
Validation loss: 2.013144294420878

Epoch: 6| Step: 5
Training loss: 0.9190637469291687
Validation loss: 2.013691703478495

Epoch: 6| Step: 6
Training loss: 0.911545991897583
Validation loss: 2.0112536946932473

Epoch: 6| Step: 7
Training loss: 0.8595114946365356
Validation loss: 1.965288559595744

Epoch: 6| Step: 8
Training loss: 1.070124864578247
Validation loss: 1.9713153441747029

Epoch: 6| Step: 9
Training loss: 0.8949137926101685
Validation loss: 1.959662675857544

Epoch: 6| Step: 10
Training loss: 1.2757692337036133
Validation loss: 1.9390169183413188

Epoch: 6| Step: 11
Training loss: 1.2860593795776367
Validation loss: 1.9487191836039226

Epoch: 6| Step: 12
Training loss: 1.0626989603042603
Validation loss: 1.989448348681132

Epoch: 6| Step: 13
Training loss: 1.2841662168502808
Validation loss: 2.020567158857981

Epoch: 122| Step: 0
Training loss: 1.0445818901062012
Validation loss: 1.932155191898346

Epoch: 6| Step: 1
Training loss: 0.5328027606010437
Validation loss: 1.9914461771647136

Epoch: 6| Step: 2
Training loss: 0.6863114237785339
Validation loss: 2.002459625403086

Epoch: 6| Step: 3
Training loss: 0.6196491718292236
Validation loss: 2.0473814805348716

Epoch: 6| Step: 4
Training loss: 0.706153154373169
Validation loss: 2.0559638341267905

Epoch: 6| Step: 5
Training loss: 1.5296297073364258
Validation loss: 1.9760873715082805

Epoch: 6| Step: 6
Training loss: 1.3914768695831299
Validation loss: 1.9820829629898071

Epoch: 6| Step: 7
Training loss: 0.7755348682403564
Validation loss: 1.9297187328338623

Epoch: 6| Step: 8
Training loss: 1.035662293434143
Validation loss: 1.9363232056299846

Epoch: 6| Step: 9
Training loss: 0.7219110727310181
Validation loss: 1.9596031109491985

Epoch: 6| Step: 10
Training loss: 1.2953567504882812
Validation loss: 1.9477311770121257

Epoch: 6| Step: 11
Training loss: 0.6654600501060486
Validation loss: 1.920914351940155

Epoch: 6| Step: 12
Training loss: 1.3785126209259033
Validation loss: 1.9343330065409343

Epoch: 6| Step: 13
Training loss: 1.2123918533325195
Validation loss: 2.005782981713613

Epoch: 123| Step: 0
Training loss: 0.7537058591842651
Validation loss: 2.0734448631604514

Epoch: 6| Step: 1
Training loss: 1.4457917213439941
Validation loss: 2.032930076122284

Epoch: 6| Step: 2
Training loss: 1.2640268802642822
Validation loss: 2.0853355725606284

Epoch: 6| Step: 3
Training loss: 1.3285919427871704
Validation loss: 2.0947557290395102

Epoch: 6| Step: 4
Training loss: 0.7573607563972473
Validation loss: 1.98344482978185

Epoch: 6| Step: 5
Training loss: 0.6909506320953369
Validation loss: 1.9855990409851074

Epoch: 6| Step: 6
Training loss: 0.6297968029975891
Validation loss: 1.9684868653615315

Epoch: 6| Step: 7
Training loss: 1.0182257890701294
Validation loss: 1.9135151704152424

Epoch: 6| Step: 8
Training loss: 1.0756535530090332
Validation loss: 1.94207759698232

Epoch: 6| Step: 9
Training loss: 0.9162067174911499
Validation loss: 1.9895121653874714

Epoch: 6| Step: 10
Training loss: 1.0288738012313843
Validation loss: 1.9562330444653828

Epoch: 6| Step: 11
Training loss: 0.968908429145813
Validation loss: 1.943156639734904

Epoch: 6| Step: 12
Training loss: 0.7251128554344177
Validation loss: 1.9821601311365764

Epoch: 6| Step: 13
Training loss: 0.9525155425071716
Validation loss: 1.993026117483775

Epoch: 124| Step: 0
Training loss: 0.6654236316680908
Validation loss: 1.98864742120107

Epoch: 6| Step: 1
Training loss: 0.5728378295898438
Validation loss: 1.9712451696395874

Epoch: 6| Step: 2
Training loss: 0.9863384366035461
Validation loss: 1.9672216773033142

Epoch: 6| Step: 3
Training loss: 1.2864973545074463
Validation loss: 2.0267920891443887

Epoch: 6| Step: 4
Training loss: 0.8018813133239746
Validation loss: 1.8758551677068074

Epoch: 6| Step: 5
Training loss: 1.140076994895935
Validation loss: 1.9537073969841003

Epoch: 6| Step: 6
Training loss: 1.041128396987915
Validation loss: 1.9759003520011902

Epoch: 6| Step: 7
Training loss: 1.025294303894043
Validation loss: 1.9762494762738545

Epoch: 6| Step: 8
Training loss: 0.936435878276825
Validation loss: 1.9755027890205383

Epoch: 6| Step: 9
Training loss: 0.9398670792579651
Validation loss: 2.0133973558743796

Epoch: 6| Step: 10
Training loss: 1.5376875400543213
Validation loss: 2.0134915908177695

Epoch: 6| Step: 11
Training loss: 0.6972159743309021
Validation loss: 2.026077389717102

Epoch: 6| Step: 12
Training loss: 0.9334990382194519
Validation loss: 2.0233484903971353

Epoch: 6| Step: 13
Training loss: 0.7681053876876831
Validation loss: 2.0350359082221985

Epoch: 125| Step: 0
Training loss: 0.8247215151786804
Validation loss: 2.0420798659324646

Epoch: 6| Step: 1
Training loss: 0.8150341510772705
Validation loss: 1.9765994548797607

Epoch: 6| Step: 2
Training loss: 0.6694203615188599
Validation loss: 1.9803653955459595

Epoch: 6| Step: 3
Training loss: 0.8453004360198975
Validation loss: 1.940151532491048

Epoch: 6| Step: 4
Training loss: 0.9951732158660889
Validation loss: 1.9541601141293843

Epoch: 6| Step: 5
Training loss: 1.0821995735168457
Validation loss: 1.9364705681800842

Epoch: 6| Step: 6
Training loss: 1.1027677059173584
Validation loss: 1.9417742888132732

Epoch: 6| Step: 7
Training loss: 1.2230925559997559
Validation loss: 2.0562596718470254

Epoch: 6| Step: 8
Training loss: 0.924849271774292
Validation loss: 2.0199806292851767

Epoch: 6| Step: 9
Training loss: 0.9895774126052856
Validation loss: 1.9842161933581035

Epoch: 6| Step: 10
Training loss: 1.1721676588058472
Validation loss: 2.0268818140029907

Epoch: 6| Step: 11
Training loss: 0.689981997013092
Validation loss: 2.0388192733128867

Epoch: 6| Step: 12
Training loss: 0.5425201058387756
Validation loss: 2.001703461011251

Epoch: 6| Step: 13
Training loss: 0.9889916181564331
Validation loss: 1.9377705852190654

Epoch: 126| Step: 0
Training loss: 0.6462504267692566
Validation loss: 1.9141434232393901

Epoch: 6| Step: 1
Training loss: 0.8198444247245789
Validation loss: 1.92390775680542

Epoch: 6| Step: 2
Training loss: 1.07346510887146
Validation loss: 1.9739890098571777

Epoch: 6| Step: 3
Training loss: 0.9017647504806519
Validation loss: 1.955832600593567

Epoch: 6| Step: 4
Training loss: 0.6444599628448486
Validation loss: 1.9840157230695088

Epoch: 6| Step: 5
Training loss: 1.476239562034607
Validation loss: 1.9783969918886821

Epoch: 6| Step: 6
Training loss: 1.0723704099655151
Validation loss: 2.0337670842806497

Epoch: 6| Step: 7
Training loss: 0.7658505439758301
Validation loss: 2.0140130519866943

Epoch: 6| Step: 8
Training loss: 0.7617208361625671
Validation loss: 2.0114629666010537

Epoch: 6| Step: 9
Training loss: 1.0329153537750244
Validation loss: 1.978457013765971

Epoch: 6| Step: 10
Training loss: 0.644548237323761
Validation loss: 2.0427571733792624

Epoch: 6| Step: 11
Training loss: 0.8298423886299133
Validation loss: 1.9468554457028706

Epoch: 6| Step: 12
Training loss: 1.1767072677612305
Validation loss: 1.9970926543076832

Epoch: 6| Step: 13
Training loss: 0.5821459293365479
Validation loss: 2.0244097113609314

Epoch: 127| Step: 0
Training loss: 0.5493062734603882
Validation loss: 2.0108718872070312

Epoch: 6| Step: 1
Training loss: 0.5096418857574463
Validation loss: 1.9556799530982971

Epoch: 6| Step: 2
Training loss: 0.7002905607223511
Validation loss: 2.0229013164838157

Epoch: 6| Step: 3
Training loss: 0.9774502515792847
Validation loss: 2.0103408694267273

Epoch: 6| Step: 4
Training loss: 1.2115910053253174
Validation loss: 2.008800725142161

Epoch: 6| Step: 5
Training loss: 0.6968916654586792
Validation loss: 1.9778139392534893

Epoch: 6| Step: 6
Training loss: 1.1401704549789429
Validation loss: 1.9596332708994548

Epoch: 6| Step: 7
Training loss: 0.3804333209991455
Validation loss: 1.9506915012995403

Epoch: 6| Step: 8
Training loss: 1.106270670890808
Validation loss: 1.975699543952942

Epoch: 6| Step: 9
Training loss: 0.4990158677101135
Validation loss: 2.04562916358312

Epoch: 6| Step: 10
Training loss: 0.48278388381004333
Validation loss: 1.9721799890200298

Epoch: 6| Step: 11
Training loss: 1.3799288272857666
Validation loss: 1.9828875462214153

Epoch: 6| Step: 12
Training loss: 1.7443879842758179
Validation loss: 1.957013229529063

Epoch: 6| Step: 13
Training loss: 1.180699348449707
Validation loss: 2.0068071484565735

Epoch: 128| Step: 0
Training loss: 0.5867478847503662
Validation loss: 1.9747164448102315

Epoch: 6| Step: 1
Training loss: 0.854343056678772
Validation loss: 1.9521273970603943

Epoch: 6| Step: 2
Training loss: 0.576591432094574
Validation loss: 1.952032744884491

Epoch: 6| Step: 3
Training loss: 0.8549625873565674
Validation loss: 1.931136469046275

Epoch: 6| Step: 4
Training loss: 0.6959282755851746
Validation loss: 2.0047887563705444

Epoch: 6| Step: 5
Training loss: 0.9200069904327393
Validation loss: 2.016973634560903

Epoch: 6| Step: 6
Training loss: 0.5273393392562866
Validation loss: 2.0504069129625955

Epoch: 6| Step: 7
Training loss: 0.5596681237220764
Validation loss: 1.99592391649882

Epoch: 6| Step: 8
Training loss: 1.1209036111831665
Validation loss: 2.021766205628713

Epoch: 6| Step: 9
Training loss: 0.7331233024597168
Validation loss: 2.006911555926005

Epoch: 6| Step: 10
Training loss: 1.4193578958511353
Validation loss: 1.9740707675615947

Epoch: 6| Step: 11
Training loss: 1.051872730255127
Validation loss: 1.988977074623108

Epoch: 6| Step: 12
Training loss: 1.0875271558761597
Validation loss: 1.9546575546264648

Epoch: 6| Step: 13
Training loss: 1.311861515045166
Validation loss: 1.9884997407595317

Epoch: 129| Step: 0
Training loss: 0.8202782869338989
Validation loss: 1.9733124375343323

Epoch: 6| Step: 1
Training loss: 0.3974817991256714
Validation loss: 1.9926887154579163

Epoch: 6| Step: 2
Training loss: 0.8263589143753052
Validation loss: 2.0357937018076577

Epoch: 6| Step: 3
Training loss: 1.5716971158981323
Validation loss: 2.0869532227516174

Epoch: 6| Step: 4
Training loss: 0.9880892634391785
Validation loss: 2.0876821478207908

Epoch: 6| Step: 5
Training loss: 0.7447226047515869
Validation loss: 2.024730126063029

Epoch: 6| Step: 6
Training loss: 1.186605453491211
Validation loss: 2.017997900644938

Epoch: 6| Step: 7
Training loss: 1.2929751873016357
Validation loss: 1.9688214858373005

Epoch: 6| Step: 8
Training loss: 0.6758148670196533
Validation loss: 1.9365879495938618

Epoch: 6| Step: 9
Training loss: 0.6670845746994019
Validation loss: 1.9079595804214478

Epoch: 6| Step: 10
Training loss: 0.9098674058914185
Validation loss: 1.9409956733385723

Epoch: 6| Step: 11
Training loss: 1.1351548433303833
Validation loss: 1.9850986401240032

Epoch: 6| Step: 12
Training loss: 0.5901749134063721
Validation loss: 1.9912244081497192

Epoch: 6| Step: 13
Training loss: 0.8202000856399536
Validation loss: 2.041991968949636

Epoch: 130| Step: 0
Training loss: 0.8951684236526489
Validation loss: 2.0369102160135903

Epoch: 6| Step: 1
Training loss: 1.1807234287261963
Validation loss: 2.011227230230967

Epoch: 6| Step: 2
Training loss: 0.49016812443733215
Validation loss: 1.9557642141977947

Epoch: 6| Step: 3
Training loss: 0.9597249627113342
Validation loss: 1.9714735349019368

Epoch: 6| Step: 4
Training loss: 0.8848785161972046
Validation loss: 1.948565940062205

Epoch: 6| Step: 5
Training loss: 1.0652594566345215
Validation loss: 1.9426162640253704

Epoch: 6| Step: 6
Training loss: 1.1191354990005493
Validation loss: 1.9005076090494792

Epoch: 6| Step: 7
Training loss: 0.6359983086585999
Validation loss: 1.9433332284291585

Epoch: 6| Step: 8
Training loss: 0.7421278953552246
Validation loss: 1.9629909197489421

Epoch: 6| Step: 9
Training loss: 1.1804931163787842
Validation loss: 1.9652335246404011

Epoch: 6| Step: 10
Training loss: 0.5619701147079468
Validation loss: 2.04171488682429

Epoch: 6| Step: 11
Training loss: 0.7589825987815857
Validation loss: 2.0123195250829062

Epoch: 6| Step: 12
Training loss: 1.3351279497146606
Validation loss: 2.0561652382214866

Epoch: 6| Step: 13
Training loss: 0.8294325470924377
Validation loss: 2.0825748840967813

Epoch: 131| Step: 0
Training loss: 0.8560335636138916
Validation loss: 2.0333749453226724

Epoch: 6| Step: 1
Training loss: 0.6269928812980652
Validation loss: 1.9274269938468933

Epoch: 6| Step: 2
Training loss: 0.6185563802719116
Validation loss: 1.9624799688657124

Epoch: 6| Step: 3
Training loss: 0.8660780191421509
Validation loss: 1.9639884233474731

Epoch: 6| Step: 4
Training loss: 0.6667043566703796
Validation loss: 1.9758739074071248

Epoch: 6| Step: 5
Training loss: 0.8474482297897339
Validation loss: 2.008824666341146

Epoch: 6| Step: 6
Training loss: 1.2114355564117432
Validation loss: 2.032384912172953

Epoch: 6| Step: 7
Training loss: 0.655764102935791
Validation loss: 2.0305513540903726

Epoch: 6| Step: 8
Training loss: 1.0207157135009766
Validation loss: 1.9840317964553833

Epoch: 6| Step: 9
Training loss: 0.8008674383163452
Validation loss: 2.0316908756891885

Epoch: 6| Step: 10
Training loss: 0.6624077558517456
Validation loss: 1.999540627002716

Epoch: 6| Step: 11
Training loss: 0.8906214237213135
Validation loss: 1.9655391573905945

Epoch: 6| Step: 12
Training loss: 0.9706346392631531
Validation loss: 1.9139784375826518

Epoch: 6| Step: 13
Training loss: 1.346510887145996
Validation loss: 1.9701727430025737

Epoch: 132| Step: 0
Training loss: 1.4625186920166016
Validation loss: 1.9641470313072205

Epoch: 6| Step: 1
Training loss: 0.5859647989273071
Validation loss: 1.9648882150650024

Epoch: 6| Step: 2
Training loss: 0.6376087069511414
Validation loss: 2.0352211594581604

Epoch: 6| Step: 3
Training loss: 0.7237840890884399
Validation loss: 1.9838385383288066

Epoch: 6| Step: 4
Training loss: 0.7983487248420715
Validation loss: 2.0326995849609375

Epoch: 6| Step: 5
Training loss: 0.34883999824523926
Validation loss: 1.9929517110188801

Epoch: 6| Step: 6
Training loss: 0.8904919624328613
Validation loss: 1.9864364862442017

Epoch: 6| Step: 7
Training loss: 0.774015486240387
Validation loss: 2.0021494229634604

Epoch: 6| Step: 8
Training loss: 1.1873717308044434
Validation loss: 1.9915883143742878

Epoch: 6| Step: 9
Training loss: 0.7478474378585815
Validation loss: 1.982951819896698

Epoch: 6| Step: 10
Training loss: 0.672984778881073
Validation loss: 2.002260684967041

Epoch: 6| Step: 11
Training loss: 0.7258654236793518
Validation loss: 1.9500217239061992

Epoch: 6| Step: 12
Training loss: 0.8544071912765503
Validation loss: 1.994112988313039

Epoch: 6| Step: 13
Training loss: 1.4412081241607666
Validation loss: 2.001125375429789

Epoch: 133| Step: 0
Training loss: 1.028163194656372
Validation loss: 1.9941615064938862

Epoch: 6| Step: 1
Training loss: 1.5110633373260498
Validation loss: 2.0095872481664023

Epoch: 6| Step: 2
Training loss: 0.8613058924674988
Validation loss: 2.0125224391619363

Epoch: 6| Step: 3
Training loss: 0.9502518177032471
Validation loss: 1.9967065850893657

Epoch: 6| Step: 4
Training loss: 0.6508517265319824
Validation loss: 1.9939339955647786

Epoch: 6| Step: 5
Training loss: 0.555448055267334
Validation loss: 2.027006904284159

Epoch: 6| Step: 6
Training loss: 1.0041701793670654
Validation loss: 2.002041280269623

Epoch: 6| Step: 7
Training loss: 0.538644552230835
Validation loss: 2.015614946683248

Epoch: 6| Step: 8
Training loss: 0.903118371963501
Validation loss: 2.024333119392395

Epoch: 6| Step: 9
Training loss: 0.7619750499725342
Validation loss: 2.083392381668091

Epoch: 6| Step: 10
Training loss: 0.8826116323471069
Validation loss: 2.106052895387014

Epoch: 6| Step: 11
Training loss: 0.8873928785324097
Validation loss: 2.011981964111328

Epoch: 6| Step: 12
Training loss: 0.38093245029449463
Validation loss: 1.9545096556345622

Epoch: 6| Step: 13
Training loss: 1.029815673828125
Validation loss: 1.9644731084505718

Epoch: 134| Step: 0
Training loss: 0.6376940011978149
Validation loss: 1.9641712705294292

Epoch: 6| Step: 1
Training loss: 1.6515313386917114
Validation loss: 1.9440659483273823

Epoch: 6| Step: 2
Training loss: 0.9231848120689392
Validation loss: 1.9868927001953125

Epoch: 6| Step: 3
Training loss: 0.7314294576644897
Validation loss: 1.9933372934659321

Epoch: 6| Step: 4
Training loss: 0.9276682138442993
Validation loss: 2.0300739804903665

Epoch: 6| Step: 5
Training loss: 0.806041955947876
Validation loss: 2.057400902112325

Epoch: 6| Step: 6
Training loss: 0.7240904569625854
Validation loss: 2.0547288258870444

Epoch: 6| Step: 7
Training loss: 0.5318977236747742
Validation loss: 2.000202695528666

Epoch: 6| Step: 8
Training loss: 0.6839386224746704
Validation loss: 1.9843944311141968

Epoch: 6| Step: 9
Training loss: 1.0718371868133545
Validation loss: 1.9104642669359844

Epoch: 6| Step: 10
Training loss: 1.2493752241134644
Validation loss: 1.9368427594502766

Epoch: 6| Step: 11
Training loss: 0.7143826484680176
Validation loss: 1.946420947710673

Epoch: 6| Step: 12
Training loss: 0.7658030986785889
Validation loss: 1.9238866964975994

Epoch: 6| Step: 13
Training loss: 0.8666017651557922
Validation loss: 1.982052206993103

Epoch: 135| Step: 0
Training loss: 0.7070977091789246
Validation loss: 1.9761302669843037

Epoch: 6| Step: 1
Training loss: 0.8762991428375244
Validation loss: 2.0207636753718057

Epoch: 6| Step: 2
Training loss: 0.9168570041656494
Validation loss: 2.0453346570332847

Epoch: 6| Step: 3
Training loss: 0.9401845335960388
Validation loss: 2.1095210115114846

Epoch: 6| Step: 4
Training loss: 0.7911715507507324
Validation loss: 2.020398437976837

Epoch: 6| Step: 5
Training loss: 0.8605409860610962
Validation loss: 1.9458042581876118

Epoch: 6| Step: 6
Training loss: 0.5664007663726807
Validation loss: 1.9345236619313557

Epoch: 6| Step: 7
Training loss: 0.5332581400871277
Validation loss: 1.9311563372612

Epoch: 6| Step: 8
Training loss: 0.787492573261261
Validation loss: 1.9673810799916585

Epoch: 6| Step: 9
Training loss: 1.2916170358657837
Validation loss: 1.9446326891581218

Epoch: 6| Step: 10
Training loss: 0.8831413984298706
Validation loss: 1.9650152325630188

Epoch: 6| Step: 11
Training loss: 0.9726449847221375
Validation loss: 1.9437078436215718

Epoch: 6| Step: 12
Training loss: 0.7313581705093384
Validation loss: 2.0245193243026733

Epoch: 6| Step: 13
Training loss: 0.9256001710891724
Validation loss: 2.060983975728353

Epoch: 136| Step: 0
Training loss: 0.8476824760437012
Validation loss: 2.1121004025141397

Epoch: 6| Step: 1
Training loss: 0.8915181159973145
Validation loss: 2.1061675945917764

Epoch: 6| Step: 2
Training loss: 0.7937489151954651
Validation loss: 2.0501522620519004

Epoch: 6| Step: 3
Training loss: 0.9924188852310181
Validation loss: 2.051962594191233

Epoch: 6| Step: 4
Training loss: 0.7440743446350098
Validation loss: 2.058034340540568

Epoch: 6| Step: 5
Training loss: 1.1465427875518799
Validation loss: 1.9809720714886982

Epoch: 6| Step: 6
Training loss: 0.9379618167877197
Validation loss: 1.9468078017234802

Epoch: 6| Step: 7
Training loss: 1.1780987977981567
Validation loss: 1.9543641805648804

Epoch: 6| Step: 8
Training loss: 0.806540310382843
Validation loss: 1.9553531209627788

Epoch: 6| Step: 9
Training loss: 0.9245034456253052
Validation loss: 1.9031718174616497

Epoch: 6| Step: 10
Training loss: 1.2558542490005493
Validation loss: 1.9895475109418232

Epoch: 6| Step: 11
Training loss: 0.7203083634376526
Validation loss: 2.049966514110565

Epoch: 6| Step: 12
Training loss: 0.633593738079071
Validation loss: 2.0403231581052146

Epoch: 6| Step: 13
Training loss: 0.8191166520118713
Validation loss: 2.1160440842310586

Epoch: 137| Step: 0
Training loss: 0.8961387872695923
Validation loss: 2.1196886698404946

Epoch: 6| Step: 1
Training loss: 0.6863090991973877
Validation loss: 2.122681895891825

Epoch: 6| Step: 2
Training loss: 0.7026410102844238
Validation loss: 1.998644491036733

Epoch: 6| Step: 3
Training loss: 0.9704864621162415
Validation loss: 1.9826574722925823

Epoch: 6| Step: 4
Training loss: 0.917833685874939
Validation loss: 1.9622786243756611

Epoch: 6| Step: 5
Training loss: 1.4219987392425537
Validation loss: 1.9672149022420247

Epoch: 6| Step: 6
Training loss: 1.1280038356781006
Validation loss: 1.919941524664561

Epoch: 6| Step: 7
Training loss: 0.6285266876220703
Validation loss: 1.9289458791414897

Epoch: 6| Step: 8
Training loss: 0.8718012571334839
Validation loss: 1.9856542746225994

Epoch: 6| Step: 9
Training loss: 0.46421515941619873
Validation loss: 1.9647364616394043

Epoch: 6| Step: 10
Training loss: 0.9102108478546143
Validation loss: 2.057431697845459

Epoch: 6| Step: 11
Training loss: 0.5474964380264282
Validation loss: 2.056358834107717

Epoch: 6| Step: 12
Training loss: 1.362051010131836
Validation loss: 2.037472208340963

Epoch: 6| Step: 13
Training loss: 0.8590600490570068
Validation loss: 2.02143524090449

Epoch: 138| Step: 0
Training loss: 0.9690823554992676
Validation loss: 2.0329272945721946

Epoch: 6| Step: 1
Training loss: 1.0554829835891724
Validation loss: 2.0195281902949014

Epoch: 6| Step: 2
Training loss: 0.34110355377197266
Validation loss: 1.9964021841684978

Epoch: 6| Step: 3
Training loss: 0.40050986409187317
Validation loss: 2.0051339070002236

Epoch: 6| Step: 4
Training loss: 0.5556821823120117
Validation loss: 1.9694790442784627

Epoch: 6| Step: 5
Training loss: 0.8468145132064819
Validation loss: 2.0421168208122253

Epoch: 6| Step: 6
Training loss: 0.6168943643569946
Validation loss: 1.895374596118927

Epoch: 6| Step: 7
Training loss: 0.8865776062011719
Validation loss: 1.9149251381556194

Epoch: 6| Step: 8
Training loss: 0.6614872813224792
Validation loss: 1.9807116587956746

Epoch: 6| Step: 9
Training loss: 1.6288238763809204
Validation loss: 1.995065152645111

Epoch: 6| Step: 10
Training loss: 0.526670515537262
Validation loss: 2.0137699842453003

Epoch: 6| Step: 11
Training loss: 0.8226079344749451
Validation loss: 2.0946502486864724

Epoch: 6| Step: 12
Training loss: 0.67640221118927
Validation loss: 1.9823214213053386

Epoch: 6| Step: 13
Training loss: 1.1274375915527344
Validation loss: 1.966112454732259

Epoch: 139| Step: 0
Training loss: 0.7027743458747864
Validation loss: 1.9583081205685933

Epoch: 6| Step: 1
Training loss: 0.801114559173584
Validation loss: 1.932388921578725

Epoch: 6| Step: 2
Training loss: 0.6185809969902039
Validation loss: 1.95987735191981

Epoch: 6| Step: 3
Training loss: 0.8482635021209717
Validation loss: 2.0052420695622764

Epoch: 6| Step: 4
Training loss: 0.8300077319145203
Validation loss: 1.9767393668492634

Epoch: 6| Step: 5
Training loss: 0.9211400747299194
Validation loss: 2.009150425593058

Epoch: 6| Step: 6
Training loss: 0.6617878079414368
Validation loss: 2.001005987326304

Epoch: 6| Step: 7
Training loss: 0.5503690242767334
Validation loss: 1.998918890953064

Epoch: 6| Step: 8
Training loss: 0.9657706022262573
Validation loss: 1.943028748035431

Epoch: 6| Step: 9
Training loss: 1.328320860862732
Validation loss: 1.9303719003995259

Epoch: 6| Step: 10
Training loss: 0.7292807102203369
Validation loss: 1.9930885235468547

Epoch: 6| Step: 11
Training loss: 0.8593863248825073
Validation loss: 1.9729118943214417

Epoch: 6| Step: 12
Training loss: 0.40734148025512695
Validation loss: 1.9298579692840576

Epoch: 6| Step: 13
Training loss: 0.8649380803108215
Validation loss: 1.917680303255717

Epoch: 140| Step: 0
Training loss: 1.2025105953216553
Validation loss: 1.937494933605194

Epoch: 6| Step: 1
Training loss: 0.8303696513175964
Validation loss: 1.923481325308482

Epoch: 6| Step: 2
Training loss: 0.3672817349433899
Validation loss: 1.9300290544827778

Epoch: 6| Step: 3
Training loss: 0.8417352437973022
Validation loss: 1.956533432006836

Epoch: 6| Step: 4
Training loss: 0.5076800584793091
Validation loss: 1.933998664220174

Epoch: 6| Step: 5
Training loss: 0.7799587249755859
Validation loss: 2.006176511446635

Epoch: 6| Step: 6
Training loss: 0.5524083375930786
Validation loss: 2.0407150189081826

Epoch: 6| Step: 7
Training loss: 0.8227920532226562
Validation loss: 2.0753759344418845

Epoch: 6| Step: 8
Training loss: 0.5759769678115845
Validation loss: 2.055258492628733

Epoch: 6| Step: 9
Training loss: 0.9005277752876282
Validation loss: 2.041595180829366

Epoch: 6| Step: 10
Training loss: 0.6473779082298279
Validation loss: 2.0502496560414634

Epoch: 6| Step: 11
Training loss: 0.4560251235961914
Validation loss: 2.068401316801707

Epoch: 6| Step: 12
Training loss: 1.0779876708984375
Validation loss: 1.967094620068868

Epoch: 6| Step: 13
Training loss: 1.3543648719787598
Validation loss: 1.9788343906402588

Epoch: 141| Step: 0
Training loss: 0.8172955513000488
Validation loss: 1.9362146258354187

Epoch: 6| Step: 1
Training loss: 0.7799548506736755
Validation loss: 1.9791549841562908

Epoch: 6| Step: 2
Training loss: 0.7666569352149963
Validation loss: 1.9032302300135295

Epoch: 6| Step: 3
Training loss: 0.574907660484314
Validation loss: 1.909849723180135

Epoch: 6| Step: 4
Training loss: 0.9109108448028564
Validation loss: 1.9627989729245503

Epoch: 6| Step: 5
Training loss: 1.302222490310669
Validation loss: 2.0396412213643393

Epoch: 6| Step: 6
Training loss: 0.7631017565727234
Validation loss: 2.0382593472798667

Epoch: 6| Step: 7
Training loss: 0.7440769672393799
Validation loss: 2.1471986373265586

Epoch: 6| Step: 8
Training loss: 1.0651365518569946
Validation loss: 2.1533533334732056

Epoch: 6| Step: 9
Training loss: 0.8240858316421509
Validation loss: 2.1185418168703714

Epoch: 6| Step: 10
Training loss: 0.6982629299163818
Validation loss: 2.003847082455953

Epoch: 6| Step: 11
Training loss: 0.8128767013549805
Validation loss: 1.9593459169069927

Epoch: 6| Step: 12
Training loss: 0.9551816582679749
Validation loss: 1.958307921886444

Epoch: 6| Step: 13
Training loss: 0.8049721121788025
Validation loss: 1.9407315254211426

Epoch: 142| Step: 0
Training loss: 0.7374774813652039
Validation loss: 1.9815449515978496

Epoch: 6| Step: 1
Training loss: 0.3540738821029663
Validation loss: 1.9464441935221355

Epoch: 6| Step: 2
Training loss: 0.7566308975219727
Validation loss: 1.9719237685203552

Epoch: 6| Step: 3
Training loss: 0.3698422908782959
Validation loss: 2.002472917238871

Epoch: 6| Step: 4
Training loss: 0.8062102198600769
Validation loss: 2.0443843801816306

Epoch: 6| Step: 5
Training loss: 0.8518692255020142
Validation loss: 2.0886439283688865

Epoch: 6| Step: 6
Training loss: 1.0771479606628418
Validation loss: 2.007678270339966

Epoch: 6| Step: 7
Training loss: 0.9775644540786743
Validation loss: 2.079387068748474

Epoch: 6| Step: 8
Training loss: 0.4180336594581604
Validation loss: 2.018380343914032

Epoch: 6| Step: 9
Training loss: 0.7912923693656921
Validation loss: 2.0330559412638345

Epoch: 6| Step: 10
Training loss: 0.9559106826782227
Validation loss: 2.0016611417134604

Epoch: 6| Step: 11
Training loss: 0.7765576839447021
Validation loss: 1.9332237442334492

Epoch: 6| Step: 12
Training loss: 1.2335749864578247
Validation loss: 1.9446531136830647

Epoch: 6| Step: 13
Training loss: 1.0923242568969727
Validation loss: 1.9189271132151287

Epoch: 143| Step: 0
Training loss: 1.1605875492095947
Validation loss: 1.934460421403249

Epoch: 6| Step: 1
Training loss: 1.6698763370513916
Validation loss: 1.935430924097697

Epoch: 6| Step: 2
Training loss: 0.4564898610115051
Validation loss: 1.9613407055536907

Epoch: 6| Step: 3
Training loss: 0.5492518544197083
Validation loss: 1.996239185333252

Epoch: 6| Step: 4
Training loss: 0.989126443862915
Validation loss: 2.011573155721029

Epoch: 6| Step: 5
Training loss: 0.7534267902374268
Validation loss: 2.0287359257539115

Epoch: 6| Step: 6
Training loss: 0.8334296345710754
Validation loss: 2.006749431292216

Epoch: 6| Step: 7
Training loss: 0.9858376383781433
Validation loss: 2.0321454207102456

Epoch: 6| Step: 8
Training loss: 0.5016833543777466
Validation loss: 1.984202245871226

Epoch: 6| Step: 9
Training loss: 0.7618458867073059
Validation loss: 1.9591427842775981

Epoch: 6| Step: 10
Training loss: 0.6344963312149048
Validation loss: 1.9914813041687012

Epoch: 6| Step: 11
Training loss: 0.4574245810508728
Validation loss: 2.0027182896931968

Epoch: 6| Step: 12
Training loss: 0.45128893852233887
Validation loss: 2.0281051993370056

Epoch: 6| Step: 13
Training loss: 0.8264003992080688
Validation loss: 2.0500160455703735

Epoch: 144| Step: 0
Training loss: 0.6667721271514893
Validation loss: 2.023214836915334

Epoch: 6| Step: 1
Training loss: 0.7588741779327393
Validation loss: 1.965179721514384

Epoch: 6| Step: 2
Training loss: 0.7865763306617737
Validation loss: 1.9988264242808025

Epoch: 6| Step: 3
Training loss: 0.721324622631073
Validation loss: 2.0305285851160684

Epoch: 6| Step: 4
Training loss: 0.49687010049819946
Validation loss: 1.962870438893636

Epoch: 6| Step: 5
Training loss: 1.1500383615493774
Validation loss: 1.9905924797058105

Epoch: 6| Step: 6
Training loss: 1.3156044483184814
Validation loss: 1.9986343185106914

Epoch: 6| Step: 7
Training loss: 0.4953693151473999
Validation loss: 1.964306652545929

Epoch: 6| Step: 8
Training loss: 0.9454853534698486
Validation loss: 1.9662954012552898

Epoch: 6| Step: 9
Training loss: 0.7854942083358765
Validation loss: 1.9798092047373455

Epoch: 6| Step: 10
Training loss: 0.6336997747421265
Validation loss: 1.9998097618420918

Epoch: 6| Step: 11
Training loss: 0.7597529292106628
Validation loss: 1.983294407526652

Epoch: 6| Step: 12
Training loss: 0.42933744192123413
Validation loss: 1.9880420565605164

Epoch: 6| Step: 13
Training loss: 0.6645402908325195
Validation loss: 2.056333820025126

Epoch: 145| Step: 0
Training loss: 0.6185188293457031
Validation loss: 1.997058133284251

Epoch: 6| Step: 1
Training loss: 0.5415868759155273
Validation loss: 2.0155465404192605

Epoch: 6| Step: 2
Training loss: 0.849278450012207
Validation loss: 1.9576983451843262

Epoch: 6| Step: 3
Training loss: 0.7458391189575195
Validation loss: 2.0099841356277466

Epoch: 6| Step: 4
Training loss: 0.5631081461906433
Validation loss: 1.9650833209355671

Epoch: 6| Step: 5
Training loss: 0.7237733602523804
Validation loss: 1.9912703037261963

Epoch: 6| Step: 6
Training loss: 0.8067806959152222
Validation loss: 2.008964161078135

Epoch: 6| Step: 7
Training loss: 0.8118155598640442
Validation loss: 2.0793990095456443

Epoch: 6| Step: 8
Training loss: 0.28807735443115234
Validation loss: 2.0399520794550576

Epoch: 6| Step: 9
Training loss: 0.6024121046066284
Validation loss: 2.07781720161438

Epoch: 6| Step: 10
Training loss: 1.253735065460205
Validation loss: 2.0362852613131204

Epoch: 6| Step: 11
Training loss: 0.7288071513175964
Validation loss: 2.011692762374878

Epoch: 6| Step: 12
Training loss: 1.1906267404556274
Validation loss: 2.0183086593945823

Epoch: 6| Step: 13
Training loss: 0.7809566855430603
Validation loss: 2.026164690653483

Epoch: 146| Step: 0
Training loss: 0.6176402568817139
Validation loss: 2.051296353340149

Epoch: 6| Step: 1
Training loss: 0.505573034286499
Validation loss: 2.089285751183828

Epoch: 6| Step: 2
Training loss: 0.8223510980606079
Validation loss: 2.0026113589604697

Epoch: 6| Step: 3
Training loss: 0.5127677917480469
Validation loss: 2.0417622327804565

Epoch: 6| Step: 4
Training loss: 0.9186259508132935
Validation loss: 2.015228827794393

Epoch: 6| Step: 5
Training loss: 0.538066029548645
Validation loss: 1.9987518787384033

Epoch: 6| Step: 6
Training loss: 0.7193104028701782
Validation loss: 2.028049131234487

Epoch: 6| Step: 7
Training loss: 0.737953782081604
Validation loss: 2.0005972186724343

Epoch: 6| Step: 8
Training loss: 0.49193137884140015
Validation loss: 2.0202777981758118

Epoch: 6| Step: 9
Training loss: 0.6477342247962952
Validation loss: 1.988443374633789

Epoch: 6| Step: 10
Training loss: 0.606568455696106
Validation loss: 2.0084542830785117

Epoch: 6| Step: 11
Training loss: 0.898629903793335
Validation loss: 1.9922441045443218

Epoch: 6| Step: 12
Training loss: 1.2710524797439575
Validation loss: 1.9773831367492676

Epoch: 6| Step: 13
Training loss: 1.133096694946289
Validation loss: 1.970685342947642

Epoch: 147| Step: 0
Training loss: 0.8723430633544922
Validation loss: 1.975435773531596

Epoch: 6| Step: 1
Training loss: 0.31378310918807983
Validation loss: 1.9375904003779094

Epoch: 6| Step: 2
Training loss: 0.6408862471580505
Validation loss: 1.9716692368189495

Epoch: 6| Step: 3
Training loss: 1.1111409664154053
Validation loss: 1.9935719172159831

Epoch: 6| Step: 4
Training loss: 0.8650819063186646
Validation loss: 2.031027396519979

Epoch: 6| Step: 5
Training loss: 0.7965964078903198
Validation loss: 2.0242002407709756

Epoch: 6| Step: 6
Training loss: 0.5225732326507568
Validation loss: 2.0485801895459494

Epoch: 6| Step: 7
Training loss: 0.9027701616287231
Validation loss: 2.0368531545003257

Epoch: 6| Step: 8
Training loss: 0.6460540294647217
Validation loss: 2.050458550453186

Epoch: 6| Step: 9
Training loss: 0.49657395482063293
Validation loss: 2.0043757359186807

Epoch: 6| Step: 10
Training loss: 0.8970317244529724
Validation loss: 1.9848414659500122

Epoch: 6| Step: 11
Training loss: 0.7336192727088928
Validation loss: 1.960648814837138

Epoch: 6| Step: 12
Training loss: 0.8876616954803467
Validation loss: 1.9916612108548482

Epoch: 6| Step: 13
Training loss: 0.6995313167572021
Validation loss: 1.9644548495610554

Epoch: 148| Step: 0
Training loss: 0.7223802208900452
Validation loss: 1.9904617071151733

Epoch: 6| Step: 1
Training loss: 0.5240113735198975
Validation loss: 2.0002304911613464

Epoch: 6| Step: 2
Training loss: 0.8566762208938599
Validation loss: 2.001448671023051

Epoch: 6| Step: 3
Training loss: 0.5798929929733276
Validation loss: 2.0130024751027427

Epoch: 6| Step: 4
Training loss: 0.8779447078704834
Validation loss: 2.034186919530233

Epoch: 6| Step: 5
Training loss: 1.1170787811279297
Validation loss: 1.9613429109255474

Epoch: 6| Step: 6
Training loss: 0.6370717287063599
Validation loss: 2.0178142388661704

Epoch: 6| Step: 7
Training loss: 0.9891237020492554
Validation loss: 2.021548867225647

Epoch: 6| Step: 8
Training loss: 0.9345243573188782
Validation loss: 2.0103938579559326

Epoch: 6| Step: 9
Training loss: 0.601520299911499
Validation loss: 1.9737366239229839

Epoch: 6| Step: 10
Training loss: 0.5788537859916687
Validation loss: 1.9861290057500203

Epoch: 6| Step: 11
Training loss: 0.32871466875076294
Validation loss: 1.9770311911900837

Epoch: 6| Step: 12
Training loss: 0.35604268312454224
Validation loss: 2.0377583305040994

Epoch: 6| Step: 13
Training loss: 0.7407031059265137
Validation loss: 1.983860969543457

Epoch: 149| Step: 0
Training loss: 0.922936737537384
Validation loss: 2.0367743174235025

Epoch: 6| Step: 1
Training loss: 0.5588312745094299
Validation loss: 2.0370381275812783

Epoch: 6| Step: 2
Training loss: 0.7922543287277222
Validation loss: 2.0479204058647156

Epoch: 6| Step: 3
Training loss: 0.8751881122589111
Validation loss: 2.0353360573450723

Epoch: 6| Step: 4
Training loss: 0.4821470081806183
Validation loss: 2.0494945645332336

Epoch: 6| Step: 5
Training loss: 1.278076171875
Validation loss: 2.021370053291321

Epoch: 6| Step: 6
Training loss: 0.6743678450584412
Validation loss: 2.0018891096115112

Epoch: 6| Step: 7
Training loss: 0.40117043256759644
Validation loss: 2.0047987699508667

Epoch: 6| Step: 8
Training loss: 0.7047386169433594
Validation loss: 1.9639878074328105

Epoch: 6| Step: 9
Training loss: 0.4244438111782074
Validation loss: 1.9437758922576904

Epoch: 6| Step: 10
Training loss: 0.6452817320823669
Validation loss: 1.954594095547994

Epoch: 6| Step: 11
Training loss: 1.1071829795837402
Validation loss: 2.000960866610209

Epoch: 6| Step: 12
Training loss: 0.39555829763412476
Validation loss: 2.0836705366770425

Epoch: 6| Step: 13
Training loss: 0.589000403881073
Validation loss: 2.1040865977605185

Epoch: 150| Step: 0
Training loss: 1.0625801086425781
Validation loss: 2.1128892302513123

Epoch: 6| Step: 1
Training loss: 0.7704996466636658
Validation loss: 2.0470489462216697

Epoch: 6| Step: 2
Training loss: 0.7030298709869385
Validation loss: 2.0476125876108804

Epoch: 6| Step: 3
Training loss: 0.6186720132827759
Validation loss: 1.9477724234263103

Epoch: 6| Step: 4
Training loss: 1.368253231048584
Validation loss: 1.9750994642575581

Epoch: 6| Step: 5
Training loss: 1.0988624095916748
Validation loss: 1.930131435394287

Epoch: 6| Step: 6
Training loss: 0.8127784132957458
Validation loss: 1.9576999346415203

Epoch: 6| Step: 7
Training loss: 0.4815058708190918
Validation loss: 1.9565834204355876

Epoch: 6| Step: 8
Training loss: 0.3227478265762329
Validation loss: 1.9777437051137288

Epoch: 6| Step: 9
Training loss: 0.626157283782959
Validation loss: 2.066647390524546

Epoch: 6| Step: 10
Training loss: 0.7374253869056702
Validation loss: 2.0811694264411926

Epoch: 6| Step: 11
Training loss: 0.9529135227203369
Validation loss: 2.1543880701065063

Epoch: 6| Step: 12
Training loss: 0.6207350492477417
Validation loss: 2.121458371480306

Epoch: 6| Step: 13
Training loss: 0.8254444599151611
Validation loss: 2.084255655606588

Epoch: 151| Step: 0
Training loss: 1.228316068649292
Validation loss: 1.9959033727645874

Epoch: 6| Step: 1
Training loss: 1.2943921089172363
Validation loss: 1.99110343058904

Epoch: 6| Step: 2
Training loss: 0.5489199161529541
Validation loss: 1.978696048259735

Epoch: 6| Step: 3
Training loss: 0.8513330817222595
Validation loss: 2.0123605728149414

Epoch: 6| Step: 4
Training loss: 0.41359516978263855
Validation loss: 1.9652452270189922

Epoch: 6| Step: 5
Training loss: 0.5643899440765381
Validation loss: 1.935933530330658

Epoch: 6| Step: 6
Training loss: 0.4153907895088196
Validation loss: 2.0313344597816467

Epoch: 6| Step: 7
Training loss: 0.7225978970527649
Validation loss: 2.0206403136253357

Epoch: 6| Step: 8
Training loss: 0.6152182221412659
Validation loss: 2.0444416403770447

Epoch: 6| Step: 9
Training loss: 0.773900032043457
Validation loss: 2.067507346471151

Epoch: 6| Step: 10
Training loss: 0.9228070378303528
Validation loss: 2.0120121439297995

Epoch: 6| Step: 11
Training loss: 0.3060106039047241
Validation loss: 2.0771613121032715

Epoch: 6| Step: 12
Training loss: 0.7778383493423462
Validation loss: 2.0199474692344666

Epoch: 6| Step: 13
Training loss: 0.5756475925445557
Validation loss: 2.0197229186693826

Epoch: 152| Step: 0
Training loss: 0.47383201122283936
Validation loss: 1.9964022437731426

Epoch: 6| Step: 1
Training loss: 0.8367617130279541
Validation loss: 2.1040197809537253

Epoch: 6| Step: 2
Training loss: 1.075257420539856
Validation loss: 2.0764549175898233

Epoch: 6| Step: 3
Training loss: 0.48894476890563965
Validation loss: 2.018687824408213

Epoch: 6| Step: 4
Training loss: 0.46249592304229736
Validation loss: 2.046166181564331

Epoch: 6| Step: 5
Training loss: 0.996239423751831
Validation loss: 1.996777355670929

Epoch: 6| Step: 6
Training loss: 0.679007887840271
Validation loss: 1.9866763750712078

Epoch: 6| Step: 7
Training loss: 0.9504445791244507
Validation loss: 1.9761061469713848

Epoch: 6| Step: 8
Training loss: 0.6654972434043884
Validation loss: 2.0067644913991294

Epoch: 6| Step: 9
Training loss: 0.5336934328079224
Validation loss: 1.981806457042694

Epoch: 6| Step: 10
Training loss: 0.6648927330970764
Validation loss: 2.0297396183013916

Epoch: 6| Step: 11
Training loss: 0.8718195557594299
Validation loss: 2.072371164957682

Epoch: 6| Step: 12
Training loss: 0.6957656741142273
Validation loss: 2.0079047679901123

Epoch: 6| Step: 13
Training loss: 0.637082040309906
Validation loss: 2.0099241534868875

Epoch: 153| Step: 0
Training loss: 0.3721434473991394
Validation loss: 2.038177490234375

Epoch: 6| Step: 1
Training loss: 0.6522517204284668
Validation loss: 1.9587050875027974

Epoch: 6| Step: 2
Training loss: 0.5776254534721375
Validation loss: 2.0350945194562278

Epoch: 6| Step: 3
Training loss: 0.5784814953804016
Validation loss: 1.9490910172462463

Epoch: 6| Step: 4
Training loss: 0.9939220547676086
Validation loss: 1.9958361387252808

Epoch: 6| Step: 5
Training loss: 0.6336288452148438
Validation loss: 1.9903186957041423

Epoch: 6| Step: 6
Training loss: 0.7196547985076904
Validation loss: 2.017449935277303

Epoch: 6| Step: 7
Training loss: 0.9463203549385071
Validation loss: 2.0621103843053183

Epoch: 6| Step: 8
Training loss: 0.8570874929428101
Validation loss: 2.0769180059432983

Epoch: 6| Step: 9
Training loss: 0.7215756177902222
Validation loss: 2.0695098439852395

Epoch: 6| Step: 10
Training loss: 0.8607547283172607
Validation loss: 2.1303149461746216

Epoch: 6| Step: 11
Training loss: 0.8219987154006958
Validation loss: 2.007951100667318

Epoch: 6| Step: 12
Training loss: 0.7079294919967651
Validation loss: 2.047899067401886

Epoch: 6| Step: 13
Training loss: 0.6481943130493164
Validation loss: 2.036924958229065

Epoch: 154| Step: 0
Training loss: 0.954450249671936
Validation loss: 2.030100663503011

Epoch: 6| Step: 1
Training loss: 0.9045622944831848
Validation loss: 2.0166311860084534

Epoch: 6| Step: 2
Training loss: 0.17374278604984283
Validation loss: 2.0367815097173056

Epoch: 6| Step: 3
Training loss: 0.4625767171382904
Validation loss: 2.009192923704783

Epoch: 6| Step: 4
Training loss: 0.8311351537704468
Validation loss: 2.016033093134562

Epoch: 6| Step: 5
Training loss: 0.9030364751815796
Validation loss: 2.0038486321767173

Epoch: 6| Step: 6
Training loss: 0.9251594543457031
Validation loss: 2.010989010334015

Epoch: 6| Step: 7
Training loss: 0.7115648984909058
Validation loss: 2.0212607185045877

Epoch: 6| Step: 8
Training loss: 0.40647250413894653
Validation loss: 2.005241811275482

Epoch: 6| Step: 9
Training loss: 0.5486132502555847
Validation loss: 1.9971733689308167

Epoch: 6| Step: 10
Training loss: 0.7496674060821533
Validation loss: 1.9875627358754475

Epoch: 6| Step: 11
Training loss: 0.38842469453811646
Validation loss: 1.9824090003967285

Epoch: 6| Step: 12
Training loss: 0.5785613656044006
Validation loss: 1.975316087404887

Epoch: 6| Step: 13
Training loss: 1.0950372219085693
Validation loss: 2.018848240375519

Epoch: 155| Step: 0
Training loss: 0.6485306024551392
Validation loss: 2.0283201535542807

Epoch: 6| Step: 1
Training loss: 1.0316532850265503
Validation loss: 2.0172576308250427

Epoch: 6| Step: 2
Training loss: 0.3966330885887146
Validation loss: 2.0889925956726074

Epoch: 6| Step: 3
Training loss: 0.44176650047302246
Validation loss: 2.0796388387680054

Epoch: 6| Step: 4
Training loss: 0.8431522846221924
Validation loss: 1.981464107831319

Epoch: 6| Step: 5
Training loss: 1.0400629043579102
Validation loss: 1.9879188537597656

Epoch: 6| Step: 6
Training loss: 0.40093857049942017
Validation loss: 1.9338864882787068

Epoch: 6| Step: 7
Training loss: 0.6415867805480957
Validation loss: 2.000342150529226

Epoch: 6| Step: 8
Training loss: 0.44885677099227905
Validation loss: 1.9669745763142903

Epoch: 6| Step: 9
Training loss: 0.7813565731048584
Validation loss: 1.98513662815094

Epoch: 6| Step: 10
Training loss: 0.6375222206115723
Validation loss: 2.0259714325269065

Epoch: 6| Step: 11
Training loss: 0.8667234182357788
Validation loss: 2.037192980448405

Epoch: 6| Step: 12
Training loss: 0.767880916595459
Validation loss: 2.0461729764938354

Epoch: 6| Step: 13
Training loss: 0.8182013034820557
Validation loss: 2.0407221714655557

Epoch: 156| Step: 0
Training loss: 0.3265712559223175
Validation loss: 1.9765833417574565

Epoch: 6| Step: 1
Training loss: 0.6568883657455444
Validation loss: 2.04075296719869

Epoch: 6| Step: 2
Training loss: 1.051796555519104
Validation loss: 1.9289620916048686

Epoch: 6| Step: 3
Training loss: 0.4141983389854431
Validation loss: 1.965922971566518

Epoch: 6| Step: 4
Training loss: 0.734383225440979
Validation loss: 1.9366050958633423

Epoch: 6| Step: 5
Training loss: 0.6928791999816895
Validation loss: 1.9558702905972798

Epoch: 6| Step: 6
Training loss: 0.5334796905517578
Validation loss: 2.0111789107322693

Epoch: 6| Step: 7
Training loss: 0.8346191644668579
Validation loss: 1.9998124440511067

Epoch: 6| Step: 8
Training loss: 0.44892072677612305
Validation loss: 2.03390101591746

Epoch: 6| Step: 9
Training loss: 0.5528427362442017
Validation loss: 2.033906936645508

Epoch: 6| Step: 10
Training loss: 1.096555471420288
Validation loss: 2.0955217679341636

Epoch: 6| Step: 11
Training loss: 1.0471447706222534
Validation loss: 2.028357128302256

Epoch: 6| Step: 12
Training loss: 0.9311918020248413
Validation loss: 2.000236431757609

Epoch: 6| Step: 13
Training loss: 0.6929020881652832
Validation loss: 1.9922439853350322

Epoch: 157| Step: 0
Training loss: 1.0368009805679321
Validation loss: 1.991376260916392

Epoch: 6| Step: 1
Training loss: 1.2892236709594727
Validation loss: 1.9683810472488403

Epoch: 6| Step: 2
Training loss: 0.48827266693115234
Validation loss: 1.9471949140230815

Epoch: 6| Step: 3
Training loss: 0.6973096132278442
Validation loss: 1.9749058087666829

Epoch: 6| Step: 4
Training loss: 0.5894045829772949
Validation loss: 1.9878902037938435

Epoch: 6| Step: 5
Training loss: 0.37426549196243286
Validation loss: 1.9493886629740398

Epoch: 6| Step: 6
Training loss: 0.6271241903305054
Validation loss: 1.9709875384966533

Epoch: 6| Step: 7
Training loss: 0.47478318214416504
Validation loss: 2.016668220361074

Epoch: 6| Step: 8
Training loss: 0.647453784942627
Validation loss: 2.070604145526886

Epoch: 6| Step: 9
Training loss: 0.8576867580413818
Validation loss: 2.0104751189549765

Epoch: 6| Step: 10
Training loss: 0.6177637577056885
Validation loss: 2.007755478223165

Epoch: 6| Step: 11
Training loss: 0.3437628448009491
Validation loss: 1.9476006031036377

Epoch: 6| Step: 12
Training loss: 0.6959792375564575
Validation loss: 1.9965133666992188

Epoch: 6| Step: 13
Training loss: 0.6317324638366699
Validation loss: 1.9731786251068115

Epoch: 158| Step: 0
Training loss: 1.0948835611343384
Validation loss: 1.915315141280492

Epoch: 6| Step: 1
Training loss: 0.7014703750610352
Validation loss: 1.988379677136739

Epoch: 6| Step: 2
Training loss: 0.5042831897735596
Validation loss: 1.9892799059549968

Epoch: 6| Step: 3
Training loss: 0.5815708637237549
Validation loss: 2.0268676479657493

Epoch: 6| Step: 4
Training loss: 1.1928684711456299
Validation loss: 2.0975199937820435

Epoch: 6| Step: 5
Training loss: 0.6919154524803162
Validation loss: 2.050693949063619

Epoch: 6| Step: 6
Training loss: 0.381279855966568
Validation loss: 2.017548461755117

Epoch: 6| Step: 7
Training loss: 1.1561367511749268
Validation loss: 2.004244844118754

Epoch: 6| Step: 8
Training loss: 0.8125573992729187
Validation loss: 2.026936133702596

Epoch: 6| Step: 9
Training loss: 0.6577886343002319
Validation loss: 1.998174746831258

Epoch: 6| Step: 10
Training loss: 0.27108997106552124
Validation loss: 1.9631900787353516

Epoch: 6| Step: 11
Training loss: 0.7876768112182617
Validation loss: 1.9530255397160847

Epoch: 6| Step: 12
Training loss: 0.4998200237751007
Validation loss: 2.025096038977305

Epoch: 6| Step: 13
Training loss: 0.37324273586273193
Validation loss: 2.048933982849121

Epoch: 159| Step: 0
Training loss: 0.5225227475166321
Validation loss: 2.0366403261820474

Epoch: 6| Step: 1
Training loss: 0.39898955821990967
Validation loss: 2.068901697794596

Epoch: 6| Step: 2
Training loss: 0.7094353437423706
Validation loss: 2.0664831598599753

Epoch: 6| Step: 3
Training loss: 0.4840037226676941
Validation loss: 2.049237092336019

Epoch: 6| Step: 4
Training loss: 0.36657968163490295
Validation loss: 2.0319061477979026

Epoch: 6| Step: 5
Training loss: 0.48251277208328247
Validation loss: 1.9887468616167705

Epoch: 6| Step: 6
Training loss: 0.7612947821617126
Validation loss: 2.026289701461792

Epoch: 6| Step: 7
Training loss: 0.5894880294799805
Validation loss: 1.9936056733131409

Epoch: 6| Step: 8
Training loss: 0.8568571209907532
Validation loss: 1.9891691605250041

Epoch: 6| Step: 9
Training loss: 0.95061194896698
Validation loss: 2.0846750736236572

Epoch: 6| Step: 10
Training loss: 1.0291883945465088
Validation loss: 2.1120946606000266

Epoch: 6| Step: 11
Training loss: 0.5992929935455322
Validation loss: 1.9826926390329997

Epoch: 6| Step: 12
Training loss: 0.37233400344848633
Validation loss: 2.0074510971705117

Epoch: 6| Step: 13
Training loss: 0.765243649482727
Validation loss: 2.0281617641448975

Epoch: 160| Step: 0
Training loss: 0.8477818369865417
Validation loss: 2.016286631425222

Epoch: 6| Step: 1
Training loss: 0.7342445850372314
Validation loss: 2.02527646223704

Epoch: 6| Step: 2
Training loss: 0.9264044165611267
Validation loss: 2.0703657468159995

Epoch: 6| Step: 3
Training loss: 0.8558586835861206
Validation loss: 2.054678658644358

Epoch: 6| Step: 4
Training loss: 0.5199925303459167
Validation loss: 2.094790041446686

Epoch: 6| Step: 5
Training loss: 0.4726269841194153
Validation loss: 2.0211148659388223

Epoch: 6| Step: 6
Training loss: 0.7746947407722473
Validation loss: 2.0565285682678223

Epoch: 6| Step: 7
Training loss: 0.5254221558570862
Validation loss: 2.0304869214693704

Epoch: 6| Step: 8
Training loss: 0.2986242175102234
Validation loss: 2.0420506596565247

Epoch: 6| Step: 9
Training loss: 0.5442556142807007
Validation loss: 2.0034752090771994

Epoch: 6| Step: 10
Training loss: 1.1594924926757812
Validation loss: 2.0657660563786826

Epoch: 6| Step: 11
Training loss: 0.48307526111602783
Validation loss: 1.9448347489039104

Epoch: 6| Step: 12
Training loss: 0.37278473377227783
Validation loss: 1.944156289100647

Epoch: 6| Step: 13
Training loss: 0.7588489055633545
Validation loss: 1.959348479906718

Epoch: 161| Step: 0
Training loss: 0.8737220168113708
Validation loss: 1.9518467982610066

Epoch: 6| Step: 1
Training loss: 0.9366828203201294
Validation loss: 1.9894421100616455

Epoch: 6| Step: 2
Training loss: 0.560659646987915
Validation loss: 2.01538223028183

Epoch: 6| Step: 3
Training loss: 0.9086281061172485
Validation loss: 2.0337390700976052

Epoch: 6| Step: 4
Training loss: 0.5963699221611023
Validation loss: 2.0142216285069785

Epoch: 6| Step: 5
Training loss: 0.618378221988678
Validation loss: 2.069404204686483

Epoch: 6| Step: 6
Training loss: 0.6138659715652466
Validation loss: 2.056927224000295

Epoch: 6| Step: 7
Training loss: 0.9002910256385803
Validation loss: 2.0635960499445596

Epoch: 6| Step: 8
Training loss: 0.6734139323234558
Validation loss: 2.0119200547536216

Epoch: 6| Step: 9
Training loss: 0.39446181058883667
Validation loss: 1.9911108613014221

Epoch: 6| Step: 10
Training loss: 0.7405314445495605
Validation loss: 2.0281007289886475

Epoch: 6| Step: 11
Training loss: 0.427112340927124
Validation loss: 1.990027089913686

Epoch: 6| Step: 12
Training loss: 0.2730526924133301
Validation loss: 1.9979137579600017

Epoch: 6| Step: 13
Training loss: 0.9705566167831421
Validation loss: 1.974144717057546

Epoch: 162| Step: 0
Training loss: 1.0089001655578613
Validation loss: 1.9831775824228923

Epoch: 6| Step: 1
Training loss: 0.3443027138710022
Validation loss: 2.027014513810476

Epoch: 6| Step: 2
Training loss: 0.8821969032287598
Validation loss: 1.9752852320671082

Epoch: 6| Step: 3
Training loss: 0.4142531752586365
Validation loss: 2.0403345823287964

Epoch: 6| Step: 4
Training loss: 1.0449979305267334
Validation loss: 1.9872538447380066

Epoch: 6| Step: 5
Training loss: 0.6791590452194214
Validation loss: 1.9962205688158672

Epoch: 6| Step: 6
Training loss: 0.9143871068954468
Validation loss: 2.0290938218434653

Epoch: 6| Step: 7
Training loss: 0.43559885025024414
Validation loss: 1.9902702172597249

Epoch: 6| Step: 8
Training loss: 0.7362247705459595
Validation loss: 1.9171619415283203

Epoch: 6| Step: 9
Training loss: 0.6196476221084595
Validation loss: 1.9981981714566548

Epoch: 6| Step: 10
Training loss: 0.6087027788162231
Validation loss: 1.9240791002909343

Epoch: 6| Step: 11
Training loss: 0.4528593122959137
Validation loss: 1.9783588449160259

Epoch: 6| Step: 12
Training loss: 0.6571311950683594
Validation loss: 1.8966033061345418

Epoch: 6| Step: 13
Training loss: 0.5246996879577637
Validation loss: 1.9668394923210144

Epoch: 163| Step: 0
Training loss: 0.5333360433578491
Validation loss: 1.9501801530520122

Epoch: 6| Step: 1
Training loss: 0.6822820901870728
Validation loss: 2.0748232205708823

Epoch: 6| Step: 2
Training loss: 0.5546091198921204
Validation loss: 2.0721279184023538

Epoch: 6| Step: 3
Training loss: 0.6907027959823608
Validation loss: 2.0712588826815286

Epoch: 6| Step: 4
Training loss: 1.2941341400146484
Validation loss: 2.049899439016978

Epoch: 6| Step: 5
Training loss: 0.7047430276870728
Validation loss: 2.060842275619507

Epoch: 6| Step: 6
Training loss: 0.4011816084384918
Validation loss: 1.9813400506973267

Epoch: 6| Step: 7
Training loss: 0.5786725878715515
Validation loss: 1.9889232913653057

Epoch: 6| Step: 8
Training loss: 0.4757418632507324
Validation loss: 1.9588947494824727

Epoch: 6| Step: 9
Training loss: 1.0007200241088867
Validation loss: 1.995062530040741

Epoch: 6| Step: 10
Training loss: 0.995721697807312
Validation loss: 1.8804585735003154

Epoch: 6| Step: 11
Training loss: 0.7393585443496704
Validation loss: 1.9413079818089802

Epoch: 6| Step: 12
Training loss: 0.35927265882492065
Validation loss: 1.9659245212872822

Epoch: 6| Step: 13
Training loss: 0.523183286190033
Validation loss: 2.001984635988871

Epoch: 164| Step: 0
Training loss: 0.956174910068512
Validation loss: 2.0368090073267617

Epoch: 6| Step: 1
Training loss: 0.8615780472755432
Validation loss: 2.0168801744778952

Epoch: 6| Step: 2
Training loss: 0.7355599403381348
Validation loss: 2.019673228263855

Epoch: 6| Step: 3
Training loss: 0.47440534830093384
Validation loss: 2.0300646821657815

Epoch: 6| Step: 4
Training loss: 0.60552978515625
Validation loss: 2.0193331638971963

Epoch: 6| Step: 5
Training loss: 0.6661130785942078
Validation loss: 1.998994251092275

Epoch: 6| Step: 6
Training loss: 0.557939887046814
Validation loss: 1.9890148838361104

Epoch: 6| Step: 7
Training loss: 0.32493728399276733
Validation loss: 1.9780389070510864

Epoch: 6| Step: 8
Training loss: 0.7677040100097656
Validation loss: 1.9509212176005046

Epoch: 6| Step: 9
Training loss: 0.8149057626724243
Validation loss: 2.0065431197484336

Epoch: 6| Step: 10
Training loss: 0.5993728637695312
Validation loss: 2.0120590329170227

Epoch: 6| Step: 11
Training loss: 0.4838618338108063
Validation loss: 2.0098763704299927

Epoch: 6| Step: 12
Training loss: 0.5092356204986572
Validation loss: 2.0681779781977334

Epoch: 6| Step: 13
Training loss: 1.1970351934432983
Validation loss: 2.033952613671621

Epoch: 165| Step: 0
Training loss: 0.8957710266113281
Validation loss: 2.038159966468811

Epoch: 6| Step: 1
Training loss: 0.4102034568786621
Validation loss: 2.0459598898887634

Epoch: 6| Step: 2
Training loss: 0.6679904460906982
Validation loss: 2.094253440697988

Epoch: 6| Step: 3
Training loss: 0.37485986948013306
Validation loss: 2.0616350769996643

Epoch: 6| Step: 4
Training loss: 1.1406391859054565
Validation loss: 2.0846288204193115

Epoch: 6| Step: 5
Training loss: 0.8363420367240906
Validation loss: 2.0214770237604776

Epoch: 6| Step: 6
Training loss: 0.7025260329246521
Validation loss: 2.0184393723805747

Epoch: 6| Step: 7
Training loss: 0.3228852152824402
Validation loss: 1.9336321751276653

Epoch: 6| Step: 8
Training loss: 0.7320695519447327
Validation loss: 1.9789010087649028

Epoch: 6| Step: 9
Training loss: 0.4417744278907776
Validation loss: 2.008421242237091

Epoch: 6| Step: 10
Training loss: 0.6211456656455994
Validation loss: 2.0127099553743997

Epoch: 6| Step: 11
Training loss: 0.5740151405334473
Validation loss: 1.999209463596344

Epoch: 6| Step: 12
Training loss: 0.679919958114624
Validation loss: 1.9978196620941162

Epoch: 6| Step: 13
Training loss: 0.5785117149353027
Validation loss: 2.0478861331939697

Epoch: 166| Step: 0
Training loss: 0.49025875329971313
Validation loss: 2.009977320830027

Epoch: 6| Step: 1
Training loss: 0.6582703590393066
Validation loss: 1.9959506193796794

Epoch: 6| Step: 2
Training loss: 0.5978516936302185
Validation loss: 2.030539949735006

Epoch: 6| Step: 3
Training loss: 1.0488734245300293
Validation loss: 1.9729739824930828

Epoch: 6| Step: 4
Training loss: 0.46092963218688965
Validation loss: 1.9655705094337463

Epoch: 6| Step: 5
Training loss: 0.4997480511665344
Validation loss: 1.9712913831075032

Epoch: 6| Step: 6
Training loss: 0.7184017896652222
Validation loss: 1.9380281368891399

Epoch: 6| Step: 7
Training loss: 0.48874011635780334
Validation loss: 1.99850195646286

Epoch: 6| Step: 8
Training loss: 0.43569445610046387
Validation loss: 2.0326342980066934

Epoch: 6| Step: 9
Training loss: 0.6118285655975342
Validation loss: 2.008956472078959

Epoch: 6| Step: 10
Training loss: 0.7112125158309937
Validation loss: 2.020799199740092

Epoch: 6| Step: 11
Training loss: 0.5274167060852051
Validation loss: 2.011412958304087

Epoch: 6| Step: 12
Training loss: 0.7945231199264526
Validation loss: 2.061385532220205

Epoch: 6| Step: 13
Training loss: 0.8957251906394958
Validation loss: 2.0582463145256042

Epoch: 167| Step: 0
Training loss: 0.4283979535102844
Validation loss: 2.0722200075785318

Epoch: 6| Step: 1
Training loss: 0.5353251695632935
Validation loss: 2.0369865695635476

Epoch: 6| Step: 2
Training loss: 0.6021876335144043
Validation loss: 2.0039925376574197

Epoch: 6| Step: 3
Training loss: 0.3158429265022278
Validation loss: 1.9789801239967346

Epoch: 6| Step: 4
Training loss: 0.5042909979820251
Validation loss: 2.0267480413118997

Epoch: 6| Step: 5
Training loss: 0.8292077779769897
Validation loss: 1.9958571592966716

Epoch: 6| Step: 6
Training loss: 0.5821084380149841
Validation loss: 2.0353968739509583

Epoch: 6| Step: 7
Training loss: 0.5962187051773071
Validation loss: 2.0034123063087463

Epoch: 6| Step: 8
Training loss: 0.48145779967308044
Validation loss: 1.977333625157674

Epoch: 6| Step: 9
Training loss: 0.2964061200618744
Validation loss: 1.9871614972750347

Epoch: 6| Step: 10
Training loss: 1.1319401264190674
Validation loss: 2.0461021661758423

Epoch: 6| Step: 11
Training loss: 1.031132698059082
Validation loss: 2.037411650021871

Epoch: 6| Step: 12
Training loss: 0.9040963649749756
Validation loss: 2.0427523454030356

Epoch: 6| Step: 13
Training loss: 0.5043843388557434
Validation loss: 2.085378726323446

Epoch: 168| Step: 0
Training loss: 0.46972137689590454
Validation loss: 2.056138356526693

Epoch: 6| Step: 1
Training loss: 0.7344664335250854
Validation loss: 2.0184877117474875

Epoch: 6| Step: 2
Training loss: 0.5233802795410156
Validation loss: 2.001304845015208

Epoch: 6| Step: 3
Training loss: 0.6261870861053467
Validation loss: 1.9669921398162842

Epoch: 6| Step: 4
Training loss: 0.6905425786972046
Validation loss: 2.0146363178888955

Epoch: 6| Step: 5
Training loss: 0.2431410551071167
Validation loss: 2.0409366289774575

Epoch: 6| Step: 6
Training loss: 0.76494300365448
Validation loss: 2.054859717686971

Epoch: 6| Step: 7
Training loss: 0.6629181504249573
Validation loss: 1.9529312054316204

Epoch: 6| Step: 8
Training loss: 0.6314947605133057
Validation loss: 2.0306593775749207

Epoch: 6| Step: 9
Training loss: 0.577763557434082
Validation loss: 2.0446824431419373

Epoch: 6| Step: 10
Training loss: 0.4806942939758301
Validation loss: 2.0232428709665933

Epoch: 6| Step: 11
Training loss: 0.5517028570175171
Validation loss: 2.0332628091176352

Epoch: 6| Step: 12
Training loss: 0.8594045639038086
Validation loss: 1.9610232710838318

Epoch: 6| Step: 13
Training loss: 1.2596557140350342
Validation loss: 1.9742865165074666

Epoch: 169| Step: 0
Training loss: 0.6111496090888977
Validation loss: 1.9847195148468018

Epoch: 6| Step: 1
Training loss: 0.42596572637557983
Validation loss: 1.9783881505330403

Epoch: 6| Step: 2
Training loss: 0.6282485723495483
Validation loss: 1.9766509731610615

Epoch: 6| Step: 3
Training loss: 1.0130201578140259
Validation loss: 2.0796270966529846

Epoch: 6| Step: 4
Training loss: 0.4325926601886749
Validation loss: 2.0046510696411133

Epoch: 6| Step: 5
Training loss: 0.8243104219436646
Validation loss: 2.018106242020925

Epoch: 6| Step: 6
Training loss: 0.4210912585258484
Validation loss: 2.0025994380315146

Epoch: 6| Step: 7
Training loss: 0.3990410566329956
Validation loss: 2.0169153014818826

Epoch: 6| Step: 8
Training loss: 0.8556114435195923
Validation loss: 2.055212835470835

Epoch: 6| Step: 9
Training loss: 1.2507598400115967
Validation loss: 1.989638090133667

Epoch: 6| Step: 10
Training loss: 0.4414181411266327
Validation loss: 2.0304256876309714

Epoch: 6| Step: 11
Training loss: 0.32010477781295776
Validation loss: 1.9373164772987366

Epoch: 6| Step: 12
Training loss: 0.6940370798110962
Validation loss: 1.965411861737569

Epoch: 6| Step: 13
Training loss: 0.5798642635345459
Validation loss: 2.0021236340204873

Epoch: 170| Step: 0
Training loss: 0.43020766973495483
Validation loss: 2.0433218479156494

Epoch: 6| Step: 1
Training loss: 0.5966276526451111
Validation loss: 2.0777687629063926

Epoch: 6| Step: 2
Training loss: 0.5006358623504639
Validation loss: 2.077317496140798

Epoch: 6| Step: 3
Training loss: 0.7496656179428101
Validation loss: 2.0458900531133017

Epoch: 6| Step: 4
Training loss: 0.4220961332321167
Validation loss: 2.009394029776255

Epoch: 6| Step: 5
Training loss: 1.3109008073806763
Validation loss: 1.96430637439092

Epoch: 6| Step: 6
Training loss: 0.4965614378452301
Validation loss: 1.9583438038825989

Epoch: 6| Step: 7
Training loss: 0.5109893083572388
Validation loss: 1.9757798115412395

Epoch: 6| Step: 8
Training loss: 0.6719976663589478
Validation loss: 1.9786382516225178

Epoch: 6| Step: 9
Training loss: 0.3263898491859436
Validation loss: 1.979950447877248

Epoch: 6| Step: 10
Training loss: 0.6654772162437439
Validation loss: 1.9864132801691692

Epoch: 6| Step: 11
Training loss: 0.7325266599655151
Validation loss: 1.9967832962671916

Epoch: 6| Step: 12
Training loss: 0.6275284290313721
Validation loss: 2.0401406288146973

Epoch: 6| Step: 13
Training loss: 0.7400011420249939
Validation loss: 2.0686948895454407

Epoch: 171| Step: 0
Training loss: 0.49093174934387207
Validation loss: 2.085817118485769

Epoch: 6| Step: 1
Training loss: 0.5275062918663025
Validation loss: 2.0247522592544556

Epoch: 6| Step: 2
Training loss: 0.7923029065132141
Validation loss: 2.0639984409014382

Epoch: 6| Step: 3
Training loss: 0.7755104303359985
Validation loss: 2.0330093701680503

Epoch: 6| Step: 4
Training loss: 0.5181119441986084
Validation loss: 2.051409343878428

Epoch: 6| Step: 5
Training loss: 0.7828021049499512
Validation loss: 2.0007880330085754

Epoch: 6| Step: 6
Training loss: 0.6267852783203125
Validation loss: 2.0029799342155457

Epoch: 6| Step: 7
Training loss: 0.6453220844268799
Validation loss: 2.006847341855367

Epoch: 6| Step: 8
Training loss: 0.47209084033966064
Validation loss: 2.017114599545797

Epoch: 6| Step: 9
Training loss: 0.6700812578201294
Validation loss: 2.019532779852549

Epoch: 6| Step: 10
Training loss: 0.8088563680648804
Validation loss: 2.101592540740967

Epoch: 6| Step: 11
Training loss: 0.4677264094352722
Validation loss: 2.042823294798533

Epoch: 6| Step: 12
Training loss: 0.33166414499282837
Validation loss: 2.065422693888346

Epoch: 6| Step: 13
Training loss: 0.8084105253219604
Validation loss: 2.111386319001516

Epoch: 172| Step: 0
Training loss: 0.5250729918479919
Validation loss: 2.0617663860321045

Epoch: 6| Step: 1
Training loss: 0.9351115226745605
Validation loss: 2.0509130557378135

Epoch: 6| Step: 2
Training loss: 0.8882431387901306
Validation loss: 2.0319252808888755

Epoch: 6| Step: 3
Training loss: 0.5509538650512695
Validation loss: 2.0256949067115784

Epoch: 6| Step: 4
Training loss: 0.3136531114578247
Validation loss: 2.0315857529640198

Epoch: 6| Step: 5
Training loss: 0.5871169567108154
Validation loss: 1.9420865774154663

Epoch: 6| Step: 6
Training loss: 0.44596153497695923
Validation loss: 1.991600771745046

Epoch: 6| Step: 7
Training loss: 0.556357741355896
Validation loss: 2.018140892187754

Epoch: 6| Step: 8
Training loss: 0.6074002981185913
Validation loss: 2.0158178210258484

Epoch: 6| Step: 9
Training loss: 0.2416882961988449
Validation loss: 1.9820237358411152

Epoch: 6| Step: 10
Training loss: 0.7495537996292114
Validation loss: 2.0655112862586975

Epoch: 6| Step: 11
Training loss: 0.4708820879459381
Validation loss: 2.0553375085194907

Epoch: 6| Step: 12
Training loss: 0.782593309879303
Validation loss: 2.0962477922439575

Epoch: 6| Step: 13
Training loss: 0.998308539390564
Validation loss: 2.0833518306414285

Epoch: 173| Step: 0
Training loss: 0.8174363374710083
Validation loss: 2.0466858744621277

Epoch: 6| Step: 1
Training loss: 0.6718966960906982
Validation loss: 2.020469387372335

Epoch: 6| Step: 2
Training loss: 0.6266149282455444
Validation loss: 1.9618764321009319

Epoch: 6| Step: 3
Training loss: 0.34393996000289917
Validation loss: 2.0166616837183633

Epoch: 6| Step: 4
Training loss: 0.5009293556213379
Validation loss: 1.9647645751635234

Epoch: 6| Step: 5
Training loss: 0.603452205657959
Validation loss: 1.970112939675649

Epoch: 6| Step: 6
Training loss: 0.8465532064437866
Validation loss: 2.0284541050593057

Epoch: 6| Step: 7
Training loss: 0.5451663732528687
Validation loss: 2.0335601568222046

Epoch: 6| Step: 8
Training loss: 0.5209377408027649
Validation loss: 1.9937149286270142

Epoch: 6| Step: 9
Training loss: 0.6462882161140442
Validation loss: 2.067112406094869

Epoch: 6| Step: 10
Training loss: 0.3343309164047241
Validation loss: 2.0919194420178733

Epoch: 6| Step: 11
Training loss: 0.5977874398231506
Validation loss: 2.061182459195455

Epoch: 6| Step: 12
Training loss: 1.068311095237732
Validation loss: 2.049483338991801

Epoch: 6| Step: 13
Training loss: 0.6211285591125488
Validation loss: 2.0514155626296997

Epoch: 174| Step: 0
Training loss: 0.7023268342018127
Validation loss: 2.04056050380071

Epoch: 6| Step: 1
Training loss: 0.2922442853450775
Validation loss: 1.9320462346076965

Epoch: 6| Step: 2
Training loss: 0.6038520336151123
Validation loss: 1.9829676747322083

Epoch: 6| Step: 3
Training loss: 0.590322732925415
Validation loss: 1.9841583569844563

Epoch: 6| Step: 4
Training loss: 0.37674304842948914
Validation loss: 1.9681318004926045

Epoch: 6| Step: 5
Training loss: 0.8569313287734985
Validation loss: 2.0333664417266846

Epoch: 6| Step: 6
Training loss: 0.6330622434616089
Validation loss: 2.017402410507202

Epoch: 6| Step: 7
Training loss: 0.4543329179286957
Validation loss: 2.050042768319448

Epoch: 6| Step: 8
Training loss: 0.767687201499939
Validation loss: 2.0735780596733093

Epoch: 6| Step: 9
Training loss: 0.33930885791778564
Validation loss: 2.017652988433838

Epoch: 6| Step: 10
Training loss: 1.0969154834747314
Validation loss: 2.0034131606419883

Epoch: 6| Step: 11
Training loss: 0.6533129215240479
Validation loss: 2.002186397711436

Epoch: 6| Step: 12
Training loss: 0.5827765464782715
Validation loss: 1.9997142950693767

Epoch: 6| Step: 13
Training loss: 0.5406566262245178
Validation loss: 2.0097477237383523

Epoch: 175| Step: 0
Training loss: 0.47674185037612915
Validation loss: 2.0227461655934653

Epoch: 6| Step: 1
Training loss: 0.6539961099624634
Validation loss: 2.0228137572606406

Epoch: 6| Step: 2
Training loss: 0.5361723303794861
Validation loss: 2.0384361147880554

Epoch: 6| Step: 3
Training loss: 0.4882127642631531
Validation loss: 1.992449680964152

Epoch: 6| Step: 4
Training loss: 0.403717577457428
Validation loss: 1.9802576502164204

Epoch: 6| Step: 5
Training loss: 0.287373423576355
Validation loss: 2.007107456525167

Epoch: 6| Step: 6
Training loss: 0.30527931451797485
Validation loss: 1.996533473332723

Epoch: 6| Step: 7
Training loss: 0.5927955508232117
Validation loss: 1.9708295067151387

Epoch: 6| Step: 8
Training loss: 0.5021392107009888
Validation loss: 1.9738450447718303

Epoch: 6| Step: 9
Training loss: 0.8456729650497437
Validation loss: 1.9699889222780864

Epoch: 6| Step: 10
Training loss: 0.6880271434783936
Validation loss: 1.955275336901347

Epoch: 6| Step: 11
Training loss: 0.5918715000152588
Validation loss: 1.9591015179951985

Epoch: 6| Step: 12
Training loss: 1.2696715593338013
Validation loss: 2.0168068408966064

Epoch: 6| Step: 13
Training loss: 0.7303211688995361
Validation loss: 2.0545284350713096

Epoch: 176| Step: 0
Training loss: 0.3303927779197693
Validation loss: 2.0403650204340615

Epoch: 6| Step: 1
Training loss: 0.9857562780380249
Validation loss: 2.0336154103279114

Epoch: 6| Step: 2
Training loss: 0.7425732612609863
Validation loss: 2.0197715957959494

Epoch: 6| Step: 3
Training loss: 0.6844635605812073
Validation loss: 2.0103065768877664

Epoch: 6| Step: 4
Training loss: 0.91454017162323
Validation loss: 2.0331034660339355

Epoch: 6| Step: 5
Training loss: 0.6622310876846313
Validation loss: 2.0009288589159646

Epoch: 6| Step: 6
Training loss: 0.5366525650024414
Validation loss: 1.979205846786499

Epoch: 6| Step: 7
Training loss: 0.5533865690231323
Validation loss: 1.9635779062906902

Epoch: 6| Step: 8
Training loss: 0.8103917837142944
Validation loss: 2.030597746372223

Epoch: 6| Step: 9
Training loss: 0.2660773992538452
Validation loss: 2.032112956047058

Epoch: 6| Step: 10
Training loss: 0.514346718788147
Validation loss: 2.0546990831693015

Epoch: 6| Step: 11
Training loss: 0.43763095140457153
Validation loss: 2.0726357301076255

Epoch: 6| Step: 12
Training loss: 0.46200984716415405
Validation loss: 2.0874791940053306

Epoch: 6| Step: 13
Training loss: 0.7388924360275269
Validation loss: 2.0485639572143555

Epoch: 177| Step: 0
Training loss: 0.8804031014442444
Validation loss: 2.032899479071299

Epoch: 6| Step: 1
Training loss: 0.4461838901042938
Validation loss: 2.0178734262784324

Epoch: 6| Step: 2
Training loss: 0.6424195766448975
Validation loss: 2.0555428862571716

Epoch: 6| Step: 3
Training loss: 0.9403866529464722
Validation loss: 1.990188479423523

Epoch: 6| Step: 4
Training loss: 0.6297628879547119
Validation loss: 2.031034509340922

Epoch: 6| Step: 5
Training loss: 0.44950127601623535
Validation loss: 2.068102260430654

Epoch: 6| Step: 6
Training loss: 0.8160924911499023
Validation loss: 2.0288705825805664

Epoch: 6| Step: 7
Training loss: 0.6111791133880615
Validation loss: 2.040938973426819

Epoch: 6| Step: 8
Training loss: 0.3618527352809906
Validation loss: 2.068666378657023

Epoch: 6| Step: 9
Training loss: 0.6017666459083557
Validation loss: 2.082950154940287

Epoch: 6| Step: 10
Training loss: 0.41749581694602966
Validation loss: 2.042464236418406

Epoch: 6| Step: 11
Training loss: 0.43781042098999023
Validation loss: 2.073402722676595

Epoch: 6| Step: 12
Training loss: 0.4151712656021118
Validation loss: 2.0114319721857705

Epoch: 6| Step: 13
Training loss: 0.733031153678894
Validation loss: 2.042508840560913

Epoch: 178| Step: 0
Training loss: 0.775665283203125
Validation loss: 2.0129865805308023

Epoch: 6| Step: 1
Training loss: 0.5760039687156677
Validation loss: 2.015666921933492

Epoch: 6| Step: 2
Training loss: 0.35761475563049316
Validation loss: 2.036147713661194

Epoch: 6| Step: 3
Training loss: 0.5517444610595703
Validation loss: 2.0246661901474

Epoch: 6| Step: 4
Training loss: 0.4755603075027466
Validation loss: 1.9941829442977905

Epoch: 6| Step: 5
Training loss: 0.4207874834537506
Validation loss: 2.056965947151184

Epoch: 6| Step: 6
Training loss: 0.24564674496650696
Validation loss: 2.0198407570521035

Epoch: 6| Step: 7
Training loss: 0.5675187706947327
Validation loss: 2.0505279699961343

Epoch: 6| Step: 8
Training loss: 0.7769083976745605
Validation loss: 2.118096947669983

Epoch: 6| Step: 9
Training loss: 0.5519904494285583
Validation loss: 2.0572095115979514

Epoch: 6| Step: 10
Training loss: 0.5910167694091797
Validation loss: 2.0731518268585205

Epoch: 6| Step: 11
Training loss: 1.2561182975769043
Validation loss: 2.0211484829584756

Epoch: 6| Step: 12
Training loss: 0.3549932837486267
Validation loss: 1.9952086210250854

Epoch: 6| Step: 13
Training loss: 0.9997156262397766
Validation loss: 2.000777284304301

Epoch: 179| Step: 0
Training loss: 0.580245852470398
Validation loss: 2.0302591721216836

Epoch: 6| Step: 1
Training loss: 0.9794959425926208
Validation loss: 1.9880141615867615

Epoch: 6| Step: 2
Training loss: 0.3415086269378662
Validation loss: 1.9949161807696025

Epoch: 6| Step: 3
Training loss: 0.7688449621200562
Validation loss: 1.9875275293986003

Epoch: 6| Step: 4
Training loss: 0.29158496856689453
Validation loss: 2.0103184382120767

Epoch: 6| Step: 5
Training loss: 0.34497368335723877
Validation loss: 2.0020253658294678

Epoch: 6| Step: 6
Training loss: 1.0833134651184082
Validation loss: 1.994727373123169

Epoch: 6| Step: 7
Training loss: 0.5219569802284241
Validation loss: 1.9826136628786724

Epoch: 6| Step: 8
Training loss: 0.6495130658149719
Validation loss: 2.0380415519078574

Epoch: 6| Step: 9
Training loss: 0.5327732563018799
Validation loss: 1.9962157011032104

Epoch: 6| Step: 10
Training loss: 0.46501055359840393
Validation loss: 1.9687708616256714

Epoch: 6| Step: 11
Training loss: 0.3352622389793396
Validation loss: 1.9599108497301738

Epoch: 6| Step: 12
Training loss: 0.5301687717437744
Validation loss: 2.013640026251475

Epoch: 6| Step: 13
Training loss: 0.623001754283905
Validation loss: 2.040665566921234

Epoch: 180| Step: 0
Training loss: 0.5171356797218323
Validation loss: 2.0271403988202414

Epoch: 6| Step: 1
Training loss: 0.5274967551231384
Validation loss: 2.0347468058268228

Epoch: 6| Step: 2
Training loss: 1.0346349477767944
Validation loss: 2.026040573914846

Epoch: 6| Step: 3
Training loss: 0.3407798111438751
Validation loss: 2.0191784302393594

Epoch: 6| Step: 4
Training loss: 0.45727235078811646
Validation loss: 2.043963452180227

Epoch: 6| Step: 5
Training loss: 0.6586703062057495
Validation loss: 2.07942795753479

Epoch: 6| Step: 6
Training loss: 0.3497113585472107
Validation loss: 2.040258844693502

Epoch: 6| Step: 7
Training loss: 0.6677147746086121
Validation loss: 2.080237030982971

Epoch: 6| Step: 8
Training loss: 0.2639961242675781
Validation loss: 2.1056878368059793

Epoch: 6| Step: 9
Training loss: 0.31308022141456604
Validation loss: 2.007271150747935

Epoch: 6| Step: 10
Training loss: 0.918880045413971
Validation loss: 2.063981751600901

Epoch: 6| Step: 11
Training loss: 0.7993445992469788
Validation loss: 2.0113314986228943

Epoch: 6| Step: 12
Training loss: 0.6199444532394409
Validation loss: 2.0266390244166055

Epoch: 6| Step: 13
Training loss: 0.745883584022522
Validation loss: 2.024827758471171

Epoch: 181| Step: 0
Training loss: 0.7510508894920349
Validation loss: 2.0136754512786865

Epoch: 6| Step: 1
Training loss: 0.7336277961730957
Validation loss: 2.0287437041600547

Epoch: 6| Step: 2
Training loss: 0.8623247146606445
Validation loss: 2.0620510975519815

Epoch: 6| Step: 3
Training loss: 0.32406696677207947
Validation loss: 2.042625109354655

Epoch: 6| Step: 4
Training loss: 0.4517836570739746
Validation loss: 2.0863532225290933

Epoch: 6| Step: 5
Training loss: 0.539334774017334
Validation loss: 2.1380707025527954

Epoch: 6| Step: 6
Training loss: 0.8682051301002502
Validation loss: 2.0795043309529624

Epoch: 6| Step: 7
Training loss: 0.4711099863052368
Validation loss: 2.0325413743654885

Epoch: 6| Step: 8
Training loss: 0.2877824008464813
Validation loss: 2.066780130068461

Epoch: 6| Step: 9
Training loss: 1.0861868858337402
Validation loss: 1.980795979499817

Epoch: 6| Step: 10
Training loss: 0.6528562307357788
Validation loss: 1.9794793923695881

Epoch: 6| Step: 11
Training loss: 0.3014475405216217
Validation loss: 2.0223130782445273

Epoch: 6| Step: 12
Training loss: 0.4990789592266083
Validation loss: 1.9973809520403545

Epoch: 6| Step: 13
Training loss: 0.4449555575847626
Validation loss: 2.0525510708491006

Epoch: 182| Step: 0
Training loss: 0.5861966013908386
Validation loss: 2.0317960381507874

Epoch: 6| Step: 1
Training loss: 0.4599109888076782
Validation loss: 2.0166608492533364

Epoch: 6| Step: 2
Training loss: 0.5403693914413452
Validation loss: 2.089067041873932

Epoch: 6| Step: 3
Training loss: 0.6811816096305847
Validation loss: 2.0942219495773315

Epoch: 6| Step: 4
Training loss: 0.7072787284851074
Validation loss: 2.060165584087372

Epoch: 6| Step: 5
Training loss: 0.6592194437980652
Validation loss: 2.0514415303866067

Epoch: 6| Step: 6
Training loss: 0.48311927914619446
Validation loss: 2.0266933838526406

Epoch: 6| Step: 7
Training loss: 0.28301483392715454
Validation loss: 1.9692116975784302

Epoch: 6| Step: 8
Training loss: 0.6412397027015686
Validation loss: 1.978515883286794

Epoch: 6| Step: 9
Training loss: 0.946539044380188
Validation loss: 1.9883163968722026

Epoch: 6| Step: 10
Training loss: 0.7746649980545044
Validation loss: 1.9460201263427734

Epoch: 6| Step: 11
Training loss: 0.5297433733940125
Validation loss: 1.986045002937317

Epoch: 6| Step: 12
Training loss: 0.8494942784309387
Validation loss: 2.033072829246521

Epoch: 6| Step: 13
Training loss: 0.4387609362602234
Validation loss: 2.0251699090003967

Epoch: 183| Step: 0
Training loss: 0.3729359805583954
Validation loss: 2.055076618989309

Epoch: 6| Step: 1
Training loss: 0.6064801216125488
Validation loss: 2.0890588760375977

Epoch: 6| Step: 2
Training loss: 0.7470498085021973
Validation loss: 2.0758453011512756

Epoch: 6| Step: 3
Training loss: 0.34570610523223877
Validation loss: 2.1136524081230164

Epoch: 6| Step: 4
Training loss: 0.3872934579849243
Validation loss: 1.9989425142606099

Epoch: 6| Step: 5
Training loss: 0.35338470339775085
Validation loss: 2.070953905582428

Epoch: 6| Step: 6
Training loss: 0.798332929611206
Validation loss: 1.9825713833173115

Epoch: 6| Step: 7
Training loss: 0.6672993898391724
Validation loss: 2.008659998575846

Epoch: 6| Step: 8
Training loss: 0.6747226715087891
Validation loss: 2.064181605974833

Epoch: 6| Step: 9
Training loss: 0.457785964012146
Validation loss: 2.1057247718175254

Epoch: 6| Step: 10
Training loss: 0.810235857963562
Validation loss: 2.0564657052357993

Epoch: 6| Step: 11
Training loss: 0.4581400752067566
Validation loss: 2.027202049891154

Epoch: 6| Step: 12
Training loss: 0.45558619499206543
Validation loss: 2.0646615028381348

Epoch: 6| Step: 13
Training loss: 0.5404750108718872
Validation loss: 2.0554295579592385

Epoch: 184| Step: 0
Training loss: 0.3622615337371826
Validation loss: 2.0163640777269998

Epoch: 6| Step: 1
Training loss: 0.7135034799575806
Validation loss: 2.080103655656179

Epoch: 6| Step: 2
Training loss: 0.577092170715332
Validation loss: 2.0382975141207376

Epoch: 6| Step: 3
Training loss: 0.7751905918121338
Validation loss: 2.0478471517562866

Epoch: 6| Step: 4
Training loss: 0.7390566468238831
Validation loss: 2.078012228012085

Epoch: 6| Step: 5
Training loss: 0.48253658413887024
Validation loss: 2.033167024453481

Epoch: 6| Step: 6
Training loss: 0.1869516670703888
Validation loss: 1.9902539451917012

Epoch: 6| Step: 7
Training loss: 1.1085715293884277
Validation loss: 2.037081301212311

Epoch: 6| Step: 8
Training loss: 0.6809735298156738
Validation loss: 2.025447646776835

Epoch: 6| Step: 9
Training loss: 0.3415820598602295
Validation loss: 1.9923118948936462

Epoch: 6| Step: 10
Training loss: 0.5378508567810059
Validation loss: 2.074437995751699

Epoch: 6| Step: 11
Training loss: 0.43542301654815674
Validation loss: 2.0320560137430825

Epoch: 6| Step: 12
Training loss: 0.18900670111179352
Validation loss: 2.0382302006085715

Epoch: 6| Step: 13
Training loss: 0.7663281559944153
Validation loss: 2.011513670285543

Epoch: 185| Step: 0
Training loss: 0.6919381022453308
Validation loss: 2.0793777306874595

Epoch: 6| Step: 1
Training loss: 0.31421390175819397
Validation loss: 2.0252322951952615

Epoch: 6| Step: 2
Training loss: 0.3494674861431122
Validation loss: 2.03499174118042

Epoch: 6| Step: 3
Training loss: 0.9102848768234253
Validation loss: 2.0074834624926248

Epoch: 6| Step: 4
Training loss: 0.5213634967803955
Validation loss: 2.0532097021738687

Epoch: 6| Step: 5
Training loss: 0.4842427670955658
Validation loss: 2.067266265551249

Epoch: 6| Step: 6
Training loss: 1.022127389907837
Validation loss: 1.9872502088546753

Epoch: 6| Step: 7
Training loss: 0.367096483707428
Validation loss: 2.031051774819692

Epoch: 6| Step: 8
Training loss: 0.3454958200454712
Validation loss: 2.0332632064819336

Epoch: 6| Step: 9
Training loss: 0.3299596607685089
Validation loss: 2.0888297160466514

Epoch: 6| Step: 10
Training loss: 0.73322594165802
Validation loss: 2.0779664317766824

Epoch: 6| Step: 11
Training loss: 0.44597575068473816
Validation loss: 2.0274301171302795

Epoch: 6| Step: 12
Training loss: 0.4106998145580292
Validation loss: 2.0276476542154946

Epoch: 6| Step: 13
Training loss: 0.8280172348022461
Validation loss: 2.0158320665359497

Epoch: 186| Step: 0
Training loss: 0.4213618338108063
Validation loss: 2.0661545594533286

Epoch: 6| Step: 1
Training loss: 0.7511821985244751
Validation loss: 2.0605026682217917

Epoch: 6| Step: 2
Training loss: 0.26990336179733276
Validation loss: 2.0270779132843018

Epoch: 6| Step: 3
Training loss: 0.39825350046157837
Validation loss: 2.015307664871216

Epoch: 6| Step: 4
Training loss: 0.3479503393173218
Validation loss: 2.025472184022268

Epoch: 6| Step: 5
Training loss: 0.8333791494369507
Validation loss: 2.0041993459065757

Epoch: 6| Step: 6
Training loss: 0.8243535757064819
Validation loss: 1.9897762934366863

Epoch: 6| Step: 7
Training loss: 0.2315979301929474
Validation loss: 2.0305408239364624

Epoch: 6| Step: 8
Training loss: 0.5150256752967834
Validation loss: 2.0120912392934165

Epoch: 6| Step: 9
Training loss: 0.9828320741653442
Validation loss: 2.0093432466189065

Epoch: 6| Step: 10
Training loss: 0.3519126772880554
Validation loss: 2.036251405874888

Epoch: 6| Step: 11
Training loss: 0.603435218334198
Validation loss: 2.018959939479828

Epoch: 6| Step: 12
Training loss: 0.4046759307384491
Validation loss: 1.9697572588920593

Epoch: 6| Step: 13
Training loss: 0.492770791053772
Validation loss: 1.9935039083162944

Epoch: 187| Step: 0
Training loss: 0.6326554417610168
Validation loss: 2.0053638021151223

Epoch: 6| Step: 1
Training loss: 0.5722998380661011
Validation loss: 1.9959308505058289

Epoch: 6| Step: 2
Training loss: 0.49222680926322937
Validation loss: 2.013885974884033

Epoch: 6| Step: 3
Training loss: 0.6898073554039001
Validation loss: 2.0648167729377747

Epoch: 6| Step: 4
Training loss: 0.36660662293434143
Validation loss: 2.0226558645566306

Epoch: 6| Step: 5
Training loss: 0.3555269241333008
Validation loss: 2.099627753098806

Epoch: 6| Step: 6
Training loss: 0.32214048504829407
Validation loss: 2.1191792090733848

Epoch: 6| Step: 7
Training loss: 0.8485910296440125
Validation loss: 2.0874736309051514

Epoch: 6| Step: 8
Training loss: 0.2896069288253784
Validation loss: 2.072050849596659

Epoch: 6| Step: 9
Training loss: 0.4853008985519409
Validation loss: 2.09541779756546

Epoch: 6| Step: 10
Training loss: 0.5996572971343994
Validation loss: 2.0390015840530396

Epoch: 6| Step: 11
Training loss: 1.0613083839416504
Validation loss: 2.029788315296173

Epoch: 6| Step: 12
Training loss: 0.36684125661849976
Validation loss: 2.085434397061666

Epoch: 6| Step: 13
Training loss: 0.5711622834205627
Validation loss: 2.0515044728914895

Epoch: 188| Step: 0
Training loss: 0.37745586037635803
Validation loss: 2.0221500396728516

Epoch: 6| Step: 1
Training loss: 0.8110285997390747
Validation loss: 2.0586589574813843

Epoch: 6| Step: 2
Training loss: 0.3736397922039032
Validation loss: 2.1013938188552856

Epoch: 6| Step: 3
Training loss: 0.5349633693695068
Validation loss: 2.0419358015060425

Epoch: 6| Step: 4
Training loss: 0.7306309938430786
Validation loss: 2.064717868963877

Epoch: 6| Step: 5
Training loss: 0.5197980403900146
Validation loss: 2.133611043294271

Epoch: 6| Step: 6
Training loss: 0.18768508732318878
Validation loss: 2.085030674934387

Epoch: 6| Step: 7
Training loss: 0.35800302028656006
Validation loss: 2.058412512143453

Epoch: 6| Step: 8
Training loss: 0.3092629313468933
Validation loss: 2.098042368888855

Epoch: 6| Step: 9
Training loss: 0.6184360384941101
Validation loss: 2.1124576330184937

Epoch: 6| Step: 10
Training loss: 0.5926371216773987
Validation loss: 2.096600572268168

Epoch: 6| Step: 11
Training loss: 0.7932935953140259
Validation loss: 2.023818552494049

Epoch: 6| Step: 12
Training loss: 0.3345830738544464
Validation loss: 2.0575796365737915

Epoch: 6| Step: 13
Training loss: 0.8355731964111328
Validation loss: 2.011986474196116

Epoch: 189| Step: 0
Training loss: 0.6290199160575867
Validation loss: 2.02299565076828

Epoch: 6| Step: 1
Training loss: 0.5725222826004028
Validation loss: 2.053399384021759

Epoch: 6| Step: 2
Training loss: 0.16773751378059387
Validation loss: 2.048071344693502

Epoch: 6| Step: 3
Training loss: 0.8458533883094788
Validation loss: 1.999455710252126

Epoch: 6| Step: 4
Training loss: 0.3762667179107666
Validation loss: 2.039794127146403

Epoch: 6| Step: 5
Training loss: 0.6957918405532837
Validation loss: 2.0338114500045776

Epoch: 6| Step: 6
Training loss: 0.5952210426330566
Validation loss: 2.0153469244639077

Epoch: 6| Step: 7
Training loss: 0.3840762972831726
Validation loss: 2.060645798842112

Epoch: 6| Step: 8
Training loss: 0.36021357774734497
Validation loss: 2.022341330846151

Epoch: 6| Step: 9
Training loss: 0.5793975591659546
Validation loss: 2.030820588270823

Epoch: 6| Step: 10
Training loss: 0.4177384376525879
Validation loss: 2.0356625517209372

Epoch: 6| Step: 11
Training loss: 0.42551401257514954
Validation loss: 2.0188798109690347

Epoch: 6| Step: 12
Training loss: 0.7801566123962402
Validation loss: 2.0543177127838135

Epoch: 6| Step: 13
Training loss: 0.5593125224113464
Validation loss: 2.0752138098080954

Epoch: 190| Step: 0
Training loss: 0.5182335376739502
Validation loss: 2.0409608085950217

Epoch: 6| Step: 1
Training loss: 0.517447829246521
Validation loss: 2.0370707511901855

Epoch: 6| Step: 2
Training loss: 0.5289618372917175
Validation loss: 2.103856841723124

Epoch: 6| Step: 3
Training loss: 0.9214193820953369
Validation loss: 2.0587132970492044

Epoch: 6| Step: 4
Training loss: 0.4448643624782562
Validation loss: 2.0861952106157937

Epoch: 6| Step: 5
Training loss: 0.4506588876247406
Validation loss: 2.0742667516072593

Epoch: 6| Step: 6
Training loss: 0.3834492266178131
Validation loss: 2.0670507351557412

Epoch: 6| Step: 7
Training loss: 0.7493561506271362
Validation loss: 2.0659590363502502

Epoch: 6| Step: 8
Training loss: 0.7001289129257202
Validation loss: 2.047244966030121

Epoch: 6| Step: 9
Training loss: 0.8159106969833374
Validation loss: 2.092051327228546

Epoch: 6| Step: 10
Training loss: 0.3459199368953705
Validation loss: 2.025260249773661

Epoch: 6| Step: 11
Training loss: 0.5053346157073975
Validation loss: 2.091904083887736

Epoch: 6| Step: 12
Training loss: 0.520444929599762
Validation loss: 2.0885464946428933

Epoch: 6| Step: 13
Training loss: 0.6026872992515564
Validation loss: 2.0456392963727317

Epoch: 191| Step: 0
Training loss: 0.742701530456543
Validation loss: 2.0204140742619834

Epoch: 6| Step: 1
Training loss: 0.811492919921875
Validation loss: 1.9977795879046123

Epoch: 6| Step: 2
Training loss: 0.37442535161972046
Validation loss: 2.029062549273173

Epoch: 6| Step: 3
Training loss: 0.5829312801361084
Validation loss: 2.01235169172287

Epoch: 6| Step: 4
Training loss: 0.2911532521247864
Validation loss: 2.077064255873362

Epoch: 6| Step: 5
Training loss: 0.6875094175338745
Validation loss: 2.014035185178121

Epoch: 6| Step: 6
Training loss: 0.39775294065475464
Validation loss: 2.0524434049924216

Epoch: 6| Step: 7
Training loss: 0.4256190061569214
Validation loss: 2.0632868011792502

Epoch: 6| Step: 8
Training loss: 0.5647516846656799
Validation loss: 2.0649264256159463

Epoch: 6| Step: 9
Training loss: 0.2027401626110077
Validation loss: 2.087466577688853

Epoch: 6| Step: 10
Training loss: 0.38702982664108276
Validation loss: 2.011190394560496

Epoch: 6| Step: 11
Training loss: 0.3585703372955322
Validation loss: 2.0428606470425925

Epoch: 6| Step: 12
Training loss: 1.125337839126587
Validation loss: 2.034977396329244

Epoch: 6| Step: 13
Training loss: 0.33515605330467224
Validation loss: 2.049988547960917

Epoch: 192| Step: 0
Training loss: 0.30066347122192383
Validation loss: 2.108440419038137

Epoch: 6| Step: 1
Training loss: 0.37965747714042664
Validation loss: 2.0711930195490518

Epoch: 6| Step: 2
Training loss: 0.5546939373016357
Validation loss: 2.090654750665029

Epoch: 6| Step: 3
Training loss: 0.4423869848251343
Validation loss: 2.1157263914744058

Epoch: 6| Step: 4
Training loss: 0.9444969892501831
Validation loss: 2.0468508998552957

Epoch: 6| Step: 5
Training loss: 0.4659321904182434
Validation loss: 2.046155571937561

Epoch: 6| Step: 6
Training loss: 0.443684458732605
Validation loss: 2.072811722755432

Epoch: 6| Step: 7
Training loss: 0.5479432344436646
Validation loss: 2.0356494585673013

Epoch: 6| Step: 8
Training loss: 0.4596273601055145
Validation loss: 2.0656436880429587

Epoch: 6| Step: 9
Training loss: 0.4437634348869324
Validation loss: 2.0922457575798035

Epoch: 6| Step: 10
Training loss: 0.46556034684181213
Validation loss: 2.0217729409535727

Epoch: 6| Step: 11
Training loss: 0.8526095151901245
Validation loss: 2.0626227259635925

Epoch: 6| Step: 12
Training loss: 0.35866400599479675
Validation loss: 2.0668048659960427

Epoch: 6| Step: 13
Training loss: 0.2773592472076416
Validation loss: 2.0278054078420005

Epoch: 193| Step: 0
Training loss: 0.7930498123168945
Validation loss: 2.0312154293060303

Epoch: 6| Step: 1
Training loss: 0.6367932558059692
Validation loss: 2.0707489450772605

Epoch: 6| Step: 2
Training loss: 0.9821634292602539
Validation loss: 2.026669681072235

Epoch: 6| Step: 3
Training loss: 0.2594565749168396
Validation loss: 2.019618491331736

Epoch: 6| Step: 4
Training loss: 0.3265070617198944
Validation loss: 2.035656154155731

Epoch: 6| Step: 5
Training loss: 0.23469775915145874
Validation loss: 2.0308133562405906

Epoch: 6| Step: 6
Training loss: 0.4434654116630554
Validation loss: 2.015824834505717

Epoch: 6| Step: 7
Training loss: 0.6557506918907166
Validation loss: 2.0625935395558677

Epoch: 6| Step: 8
Training loss: 0.6753052473068237
Validation loss: 2.0573561588923135

Epoch: 6| Step: 9
Training loss: 0.657507061958313
Validation loss: 2.12986292441686

Epoch: 6| Step: 10
Training loss: 0.5578142404556274
Validation loss: 2.055000285307566

Epoch: 6| Step: 11
Training loss: 0.644034743309021
Validation loss: 2.033715029557546

Epoch: 6| Step: 12
Training loss: 0.4433336853981018
Validation loss: 2.0723405877749124

Epoch: 6| Step: 13
Training loss: 0.5854372978210449
Validation loss: 2.030699630578359

Epoch: 194| Step: 0
Training loss: 0.8364717960357666
Validation loss: 2.0671045184135437

Epoch: 6| Step: 1
Training loss: 0.47685855627059937
Validation loss: 1.9853069583574932

Epoch: 6| Step: 2
Training loss: 0.5766164660453796
Validation loss: 2.0354503790537515

Epoch: 6| Step: 3
Training loss: 0.821762204170227
Validation loss: 2.062471548716227

Epoch: 6| Step: 4
Training loss: 0.4026729464530945
Validation loss: 2.1133447686831155

Epoch: 6| Step: 5
Training loss: 0.6496709585189819
Validation loss: 2.112292488416036

Epoch: 6| Step: 6
Training loss: 0.7766050696372986
Validation loss: 2.1597668329874673

Epoch: 6| Step: 7
Training loss: 0.8138983249664307
Validation loss: 2.105702499548594

Epoch: 6| Step: 8
Training loss: 0.39802101254463196
Validation loss: 2.0497483015060425

Epoch: 6| Step: 9
Training loss: 0.28545695543289185
Validation loss: 2.0649102528889975

Epoch: 6| Step: 10
Training loss: 0.53619384765625
Validation loss: 2.0449461340904236

Epoch: 6| Step: 11
Training loss: 0.5313234329223633
Validation loss: 2.08065136273702

Epoch: 6| Step: 12
Training loss: 0.8921870589256287
Validation loss: 2.0780679186185202

Epoch: 6| Step: 13
Training loss: 0.4173228442668915
Validation loss: 2.0676242113113403

Epoch: 195| Step: 0
Training loss: 0.2925991415977478
Validation loss: 2.0281867384910583

Epoch: 6| Step: 1
Training loss: 0.2738250195980072
Validation loss: 2.0765515764554343

Epoch: 6| Step: 2
Training loss: 0.4255460500717163
Validation loss: 2.128478527069092

Epoch: 6| Step: 3
Training loss: 0.18169593811035156
Validation loss: 2.085859497388204

Epoch: 6| Step: 4
Training loss: 0.35627830028533936
Validation loss: 2.0482784509658813

Epoch: 6| Step: 5
Training loss: 0.4255485534667969
Validation loss: 2.091969152291616

Epoch: 6| Step: 6
Training loss: 0.46643874049186707
Validation loss: 2.055282731850942

Epoch: 6| Step: 7
Training loss: 0.8068529367446899
Validation loss: 2.0328835447629294

Epoch: 6| Step: 8
Training loss: 0.780065655708313
Validation loss: 2.054585019747416

Epoch: 6| Step: 9
Training loss: 0.7561835646629333
Validation loss: 2.0911623438199363

Epoch: 6| Step: 10
Training loss: 0.3999329209327698
Validation loss: 2.0104678869247437

Epoch: 6| Step: 11
Training loss: 0.6531116962432861
Validation loss: 2.029751161734263

Epoch: 6| Step: 12
Training loss: 0.7088674306869507
Validation loss: 2.0403218269348145

Epoch: 6| Step: 13
Training loss: 0.9167587161064148
Validation loss: 2.057503402233124

Epoch: 196| Step: 0
Training loss: 0.9902229309082031
Validation loss: 2.058581610520681

Epoch: 6| Step: 1
Training loss: 0.43000417947769165
Validation loss: 2.0226650834083557

Epoch: 6| Step: 2
Training loss: 0.65192711353302
Validation loss: 2.0472834507624307

Epoch: 6| Step: 3
Training loss: 0.23686078190803528
Validation loss: 2.083028872807821

Epoch: 6| Step: 4
Training loss: 0.44394737482070923
Validation loss: 2.0559125343958535

Epoch: 6| Step: 5
Training loss: 0.3749665319919586
Validation loss: 2.075420637925466

Epoch: 6| Step: 6
Training loss: 0.3342064619064331
Validation loss: 2.0991620620091758

Epoch: 6| Step: 7
Training loss: 0.35660701990127563
Validation loss: 2.0733651717503867

Epoch: 6| Step: 8
Training loss: 0.5211920142173767
Validation loss: 2.088123381137848

Epoch: 6| Step: 9
Training loss: 0.5568139553070068
Validation loss: 2.0388782819112143

Epoch: 6| Step: 10
Training loss: 0.5445945262908936
Validation loss: 2.076651871204376

Epoch: 6| Step: 11
Training loss: 0.6302599906921387
Validation loss: 2.0916223327318826

Epoch: 6| Step: 12
Training loss: 0.5969538688659668
Validation loss: 2.0516143242518106

Epoch: 6| Step: 13
Training loss: 0.5326389074325562
Validation loss: 2.028190036614736

Epoch: 197| Step: 0
Training loss: 0.7318471074104309
Validation loss: 2.1323713858922324

Epoch: 6| Step: 1
Training loss: 0.7345819473266602
Validation loss: 2.0566140015920005

Epoch: 6| Step: 2
Training loss: 0.48494014143943787
Validation loss: 2.0659197767575583

Epoch: 6| Step: 3
Training loss: 0.7129158973693848
Validation loss: 2.071464022000631

Epoch: 6| Step: 4
Training loss: 0.3268691599369049
Validation loss: 2.0592575073242188

Epoch: 6| Step: 5
Training loss: 0.7052568197250366
Validation loss: 2.054550210634867

Epoch: 6| Step: 6
Training loss: 0.45082521438598633
Validation loss: 1.9877687692642212

Epoch: 6| Step: 7
Training loss: 0.668655514717102
Validation loss: 2.0143511494000754

Epoch: 6| Step: 8
Training loss: 0.3688596189022064
Validation loss: 2.036473532517751

Epoch: 6| Step: 9
Training loss: 0.34850597381591797
Validation loss: 2.0400922298431396

Epoch: 6| Step: 10
Training loss: 0.42505747079849243
Validation loss: 2.0945223569869995

Epoch: 6| Step: 11
Training loss: 0.8587183952331543
Validation loss: 2.1211589177449546

Epoch: 6| Step: 12
Training loss: 0.5699170827865601
Validation loss: 2.1362462639808655

Epoch: 6| Step: 13
Training loss: 0.5888621807098389
Validation loss: 2.155441621939341

Epoch: 198| Step: 0
Training loss: 1.139312982559204
Validation loss: 2.1440057357152305

Epoch: 6| Step: 1
Training loss: 0.5444847345352173
Validation loss: 2.107727587223053

Epoch: 6| Step: 2
Training loss: 0.22179114818572998
Validation loss: 2.0510318676630654

Epoch: 6| Step: 3
Training loss: 0.476216197013855
Validation loss: 2.064888079961141

Epoch: 6| Step: 4
Training loss: 0.37948232889175415
Validation loss: 2.023523529370626

Epoch: 6| Step: 5
Training loss: 0.43256741762161255
Validation loss: 2.002484838167826

Epoch: 6| Step: 6
Training loss: 0.8091573119163513
Validation loss: 2.049543559551239

Epoch: 6| Step: 7
Training loss: 0.5992470979690552
Validation loss: 2.017241954803467

Epoch: 6| Step: 8
Training loss: 0.33406543731689453
Validation loss: 2.024774750073751

Epoch: 6| Step: 9
Training loss: 0.27010369300842285
Validation loss: 2.0403815110524497

Epoch: 6| Step: 10
Training loss: 0.36337387561798096
Validation loss: 2.0282620787620544

Epoch: 6| Step: 11
Training loss: 0.41148507595062256
Validation loss: 2.0687511960665383

Epoch: 6| Step: 12
Training loss: 0.7219088077545166
Validation loss: 2.008482654889425

Epoch: 6| Step: 13
Training loss: 1.0984340906143188
Validation loss: 2.0377993981043496

Epoch: 199| Step: 0
Training loss: 0.3715399503707886
Validation loss: 2.0600367188453674

Epoch: 6| Step: 1
Training loss: 0.5504751801490784
Validation loss: 2.0237091978391013

Epoch: 6| Step: 2
Training loss: 0.7600301504135132
Validation loss: 1.9938992857933044

Epoch: 6| Step: 3
Training loss: 0.3304799795150757
Validation loss: 1.998750905195872

Epoch: 6| Step: 4
Training loss: 0.4557499885559082
Validation loss: 2.022476851940155

Epoch: 6| Step: 5
Training loss: 0.28558382391929626
Validation loss: 2.0246384541193643

Epoch: 6| Step: 6
Training loss: 0.49817049503326416
Validation loss: 2.024141848087311

Epoch: 6| Step: 7
Training loss: 0.6786671876907349
Validation loss: 2.0698089400927224

Epoch: 6| Step: 8
Training loss: 0.6479411125183105
Validation loss: 2.0772772828737893

Epoch: 6| Step: 9
Training loss: 0.3358975648880005
Validation loss: 2.084536910057068

Epoch: 6| Step: 10
Training loss: 0.900352954864502
Validation loss: 2.0817365447680154

Epoch: 6| Step: 11
Training loss: 0.3798755407333374
Validation loss: 2.0805150071779885

Epoch: 6| Step: 12
Training loss: 0.4840356111526489
Validation loss: 2.04815936088562

Epoch: 6| Step: 13
Training loss: 0.5823510885238647
Validation loss: 2.0277310411135354

Epoch: 200| Step: 0
Training loss: 0.476640522480011
Validation loss: 2.0580879052480063

Epoch: 6| Step: 1
Training loss: 0.571622371673584
Validation loss: 2.058080712954203

Epoch: 6| Step: 2
Training loss: 0.6169657111167908
Validation loss: 2.0452978213628135

Epoch: 6| Step: 3
Training loss: 0.26341307163238525
Validation loss: 2.085010528564453

Epoch: 6| Step: 4
Training loss: 0.49538832902908325
Validation loss: 2.1088367700576782

Epoch: 6| Step: 5
Training loss: 0.4963253140449524
Validation loss: 2.107236663500468

Epoch: 6| Step: 6
Training loss: 0.5843305587768555
Validation loss: 2.1106919248898826

Epoch: 6| Step: 7
Training loss: 0.2561476230621338
Validation loss: 2.1335865259170532

Epoch: 6| Step: 8
Training loss: 0.26704633235931396
Validation loss: 2.0555866161982217

Epoch: 6| Step: 9
Training loss: 0.3169997036457062
Validation loss: 2.0710450410842896

Epoch: 6| Step: 10
Training loss: 0.8402255773544312
Validation loss: 2.0559211373329163

Epoch: 6| Step: 11
Training loss: 0.8271920680999756
Validation loss: 2.022037227948507

Epoch: 6| Step: 12
Training loss: 0.6634994149208069
Validation loss: 1.9836490352948506

Epoch: 6| Step: 13
Training loss: 0.7684508562088013
Validation loss: 1.9920556942621868

Epoch: 201| Step: 0
Training loss: 0.833389163017273
Validation loss: 2.016691426436106

Epoch: 6| Step: 1
Training loss: 1.0024847984313965
Validation loss: 2.059617201487223

Epoch: 6| Step: 2
Training loss: 1.114902138710022
Validation loss: 2.144874334335327

Epoch: 6| Step: 3
Training loss: 0.6148514747619629
Validation loss: 2.1305571794509888

Epoch: 6| Step: 4
Training loss: 0.8494385480880737
Validation loss: 2.157236893971761

Epoch: 6| Step: 5
Training loss: 0.6188193559646606
Validation loss: 2.1157700220743814

Epoch: 6| Step: 6
Training loss: 0.4345230758190155
Validation loss: 2.0465297301610312

Epoch: 6| Step: 7
Training loss: 0.477475106716156
Validation loss: 2.045673390229543

Epoch: 6| Step: 8
Training loss: 0.5091599225997925
Validation loss: 1.965548316637675

Epoch: 6| Step: 9
Training loss: 0.4637388586997986
Validation loss: 2.034618079662323

Epoch: 6| Step: 10
Training loss: 0.6573030948638916
Validation loss: 2.038180867830912

Epoch: 6| Step: 11
Training loss: 0.44595810770988464
Validation loss: 2.018166442712148

Epoch: 6| Step: 12
Training loss: 0.33472940325737
Validation loss: 2.0340820948282876

Epoch: 6| Step: 13
Training loss: 0.21942201256752014
Validation loss: 2.05010853211085

Epoch: 202| Step: 0
Training loss: 0.5471639037132263
Validation loss: 2.0997536182403564

Epoch: 6| Step: 1
Training loss: 0.39613431692123413
Validation loss: 2.096071243286133

Epoch: 6| Step: 2
Training loss: 0.6996892094612122
Validation loss: 2.125659684340159

Epoch: 6| Step: 3
Training loss: 0.6114334464073181
Validation loss: 2.1243494351704917

Epoch: 6| Step: 4
Training loss: 0.3067903518676758
Validation loss: 2.083110809326172

Epoch: 6| Step: 5
Training loss: 0.7063454985618591
Validation loss: 2.0311038295427957

Epoch: 6| Step: 6
Training loss: 0.6952346563339233
Validation loss: 2.0660059650739035

Epoch: 6| Step: 7
Training loss: 0.6891533136367798
Validation loss: 1.9764115413029988

Epoch: 6| Step: 8
Training loss: 0.4355628788471222
Validation loss: 2.0011490980784097

Epoch: 6| Step: 9
Training loss: 0.35549038648605347
Validation loss: 2.0565422574679055

Epoch: 6| Step: 10
Training loss: 0.3001279830932617
Validation loss: 2.0979817112286887

Epoch: 6| Step: 11
Training loss: 1.2655409574508667
Validation loss: 2.0845682621002197

Epoch: 6| Step: 12
Training loss: 0.4564798176288605
Validation loss: 2.0877243876457214

Epoch: 6| Step: 13
Training loss: 0.4498603940010071
Validation loss: 2.028708199659983

Epoch: 203| Step: 0
Training loss: 0.45230036973953247
Validation loss: 2.0427324374516806

Epoch: 6| Step: 1
Training loss: 0.6726455092430115
Validation loss: 2.0724201599756875

Epoch: 6| Step: 2
Training loss: 0.7218841910362244
Validation loss: 2.054359038670858

Epoch: 6| Step: 3
Training loss: 0.5851175785064697
Validation loss: 2.0100732247034707

Epoch: 6| Step: 4
Training loss: 0.213922381401062
Validation loss: 2.053876062234243

Epoch: 6| Step: 5
Training loss: 0.29208076000213623
Validation loss: 1.9852399428685505

Epoch: 6| Step: 6
Training loss: 0.35189810395240784
Validation loss: 2.029690424601237

Epoch: 6| Step: 7
Training loss: 0.5628011226654053
Validation loss: 1.9989383419354756

Epoch: 6| Step: 8
Training loss: 0.5083258152008057
Validation loss: 1.972994903723399

Epoch: 6| Step: 9
Training loss: 1.0653795003890991
Validation loss: 2.053175429503123

Epoch: 6| Step: 10
Training loss: 0.29005587100982666
Validation loss: 2.049174149831136

Epoch: 6| Step: 11
Training loss: 0.20666807889938354
Validation loss: 2.050226310888926

Epoch: 6| Step: 12
Training loss: 0.6925675272941589
Validation loss: 2.0656239986419678

Epoch: 6| Step: 13
Training loss: 0.4752961993217468
Validation loss: 2.0045771400133767

Epoch: 204| Step: 0
Training loss: 0.6951272487640381
Validation loss: 2.044660290082296

Epoch: 6| Step: 1
Training loss: 0.36674606800079346
Validation loss: 2.0229238867759705

Epoch: 6| Step: 2
Training loss: 0.3874264657497406
Validation loss: 2.0393248200416565

Epoch: 6| Step: 3
Training loss: 0.3050248622894287
Validation loss: 2.0164732933044434

Epoch: 6| Step: 4
Training loss: 0.28598523139953613
Validation loss: 2.015950401624044

Epoch: 6| Step: 5
Training loss: 0.1976323127746582
Validation loss: 2.0136324961980185

Epoch: 6| Step: 6
Training loss: 0.716637372970581
Validation loss: 2.00839626789093

Epoch: 6| Step: 7
Training loss: 0.4277666211128235
Validation loss: 1.9923798243204753

Epoch: 6| Step: 8
Training loss: 0.7653278708457947
Validation loss: 2.0314990282058716

Epoch: 6| Step: 9
Training loss: 0.8065227270126343
Validation loss: 2.0550301671028137

Epoch: 6| Step: 10
Training loss: 0.31020963191986084
Validation loss: 2.0490268071492515

Epoch: 6| Step: 11
Training loss: 0.1685577630996704
Validation loss: 2.012608269850413

Epoch: 6| Step: 12
Training loss: 0.4319469928741455
Validation loss: 2.0412716269493103

Epoch: 6| Step: 13
Training loss: 0.8378158807754517
Validation loss: 2.0933862924575806

Epoch: 205| Step: 0
Training loss: 0.7149543166160583
Validation loss: 2.0675357381502786

Epoch: 6| Step: 1
Training loss: 0.4862326979637146
Validation loss: 2.0656570196151733

Epoch: 6| Step: 2
Training loss: 0.7034125924110413
Validation loss: 2.1064182917277017

Epoch: 6| Step: 3
Training loss: 0.48328542709350586
Validation loss: 2.0858248670895896

Epoch: 6| Step: 4
Training loss: 0.43913406133651733
Validation loss: 2.031278411547343

Epoch: 6| Step: 5
Training loss: 0.5838284492492676
Validation loss: 1.9954533576965332

Epoch: 6| Step: 6
Training loss: 0.547515869140625
Validation loss: 2.0258357524871826

Epoch: 6| Step: 7
Training loss: 0.7201833724975586
Validation loss: 1.9713954329490662

Epoch: 6| Step: 8
Training loss: 0.33925965428352356
Validation loss: 1.9797648588816326

Epoch: 6| Step: 9
Training loss: 0.5473867654800415
Validation loss: 2.007612407207489

Epoch: 6| Step: 10
Training loss: 0.21824635565280914
Validation loss: 1.996255139509837

Epoch: 6| Step: 11
Training loss: 0.31968018412590027
Validation loss: 2.0213796893755593

Epoch: 6| Step: 12
Training loss: 0.5952117443084717
Validation loss: 2.0957714915275574

Epoch: 6| Step: 13
Training loss: 0.3238333463668823
Validation loss: 2.024632513523102

Epoch: 206| Step: 0
Training loss: 0.44305944442749023
Validation loss: 2.039383808771769

Epoch: 6| Step: 1
Training loss: 0.3241562247276306
Validation loss: 2.030221919218699

Epoch: 6| Step: 2
Training loss: 0.6070270538330078
Validation loss: 2.0337851643562317

Epoch: 6| Step: 3
Training loss: 0.602402925491333
Validation loss: 2.0026860435803733

Epoch: 6| Step: 4
Training loss: 0.4764459729194641
Validation loss: 2.046496053536733

Epoch: 6| Step: 5
Training loss: 0.6145954728126526
Validation loss: 2.0644248723983765

Epoch: 6| Step: 6
Training loss: 0.5651524066925049
Validation loss: 2.036711831887563

Epoch: 6| Step: 7
Training loss: 0.6485428810119629
Validation loss: 2.0546882152557373

Epoch: 6| Step: 8
Training loss: 0.7998886108398438
Validation loss: 2.0174953937530518

Epoch: 6| Step: 9
Training loss: 0.45909735560417175
Validation loss: 2.0301502346992493

Epoch: 6| Step: 10
Training loss: 0.30771583318710327
Validation loss: 2.055284261703491

Epoch: 6| Step: 11
Training loss: 0.2425660789012909
Validation loss: 2.03327606121699

Epoch: 6| Step: 12
Training loss: 0.5180211067199707
Validation loss: 2.0605955719947815

Epoch: 6| Step: 13
Training loss: 0.5976843237876892
Validation loss: 2.1621395349502563

Epoch: 207| Step: 0
Training loss: 0.28583958745002747
Validation loss: 2.090308427810669

Epoch: 6| Step: 1
Training loss: 0.36136394739151
Validation loss: 2.097764790058136

Epoch: 6| Step: 2
Training loss: 0.48308002948760986
Validation loss: 2.078053911526998

Epoch: 6| Step: 3
Training loss: 0.264263391494751
Validation loss: 2.043544511000315

Epoch: 6| Step: 4
Training loss: 0.8649932742118835
Validation loss: 2.012385447820028

Epoch: 6| Step: 5
Training loss: 0.664663553237915
Validation loss: 2.0537360509236655

Epoch: 6| Step: 6
Training loss: 0.6059122085571289
Validation loss: 2.067249317963918

Epoch: 6| Step: 7
Training loss: 0.44370102882385254
Validation loss: 2.073555648326874

Epoch: 6| Step: 8
Training loss: 0.44991248846054077
Validation loss: 2.04369193315506

Epoch: 6| Step: 9
Training loss: 0.4779786765575409
Validation loss: 2.0209252635637918

Epoch: 6| Step: 10
Training loss: 0.4715433716773987
Validation loss: 2.0734198888142905

Epoch: 6| Step: 11
Training loss: 0.545820951461792
Validation loss: 2.034502148628235

Epoch: 6| Step: 12
Training loss: 0.6405622959136963
Validation loss: 2.001068035761515

Epoch: 6| Step: 13
Training loss: 0.4018932580947876
Validation loss: 2.0485727787017822

Epoch: 208| Step: 0
Training loss: 0.26115238666534424
Validation loss: 1.983862082163493

Epoch: 6| Step: 1
Training loss: 0.2508770525455475
Validation loss: 2.0539437532424927

Epoch: 6| Step: 2
Training loss: 0.7077566385269165
Validation loss: 2.028459668159485

Epoch: 6| Step: 3
Training loss: 0.3590604364871979
Validation loss: 2.023224651813507

Epoch: 6| Step: 4
Training loss: 0.3400641083717346
Validation loss: 2.0532158414522805

Epoch: 6| Step: 5
Training loss: 0.3771284222602844
Validation loss: 2.0773425698280334

Epoch: 6| Step: 6
Training loss: 0.7524608969688416
Validation loss: 2.0285701553026834

Epoch: 6| Step: 7
Training loss: 0.3439674377441406
Validation loss: 2.05536820491155

Epoch: 6| Step: 8
Training loss: 0.3386676609516144
Validation loss: 2.0279374718666077

Epoch: 6| Step: 9
Training loss: 0.8373966217041016
Validation loss: 2.0648585160573325

Epoch: 6| Step: 10
Training loss: 0.5729007124900818
Validation loss: 2.0488516290982566

Epoch: 6| Step: 11
Training loss: 0.4439014196395874
Validation loss: 2.0317379037539163

Epoch: 6| Step: 12
Training loss: 0.9762746095657349
Validation loss: 2.011173943678538

Epoch: 6| Step: 13
Training loss: 0.34404462575912476
Validation loss: 2.0480921069780984

Epoch: 209| Step: 0
Training loss: 0.3338910937309265
Validation loss: 2.0770006577173867

Epoch: 6| Step: 1
Training loss: 0.3857487738132477
Validation loss: 2.033667425314585

Epoch: 6| Step: 2
Training loss: 0.2961052656173706
Validation loss: 2.0265448292096457

Epoch: 6| Step: 3
Training loss: 0.6439051032066345
Validation loss: 2.1172630389531455

Epoch: 6| Step: 4
Training loss: 0.25846976041793823
Validation loss: 2.0243749419848123

Epoch: 6| Step: 5
Training loss: 0.8955664038658142
Validation loss: 2.1075653235117593

Epoch: 6| Step: 6
Training loss: 0.6779751777648926
Validation loss: 2.077911992867788

Epoch: 6| Step: 7
Training loss: 0.5573563575744629
Validation loss: 2.0891273617744446

Epoch: 6| Step: 8
Training loss: 0.3172384202480316
Validation loss: 2.029461443424225

Epoch: 6| Step: 9
Training loss: 0.24968156218528748
Validation loss: 2.050406813621521

Epoch: 6| Step: 10
Training loss: 0.439899206161499
Validation loss: 2.0580082535743713

Epoch: 6| Step: 11
Training loss: 0.590197741985321
Validation loss: 2.0138295888900757

Epoch: 6| Step: 12
Training loss: 0.4779418706893921
Validation loss: 2.0296104550361633

Epoch: 6| Step: 13
Training loss: 0.4503149688243866
Validation loss: 2.044883668422699

Epoch: 210| Step: 0
Training loss: 0.6897938847541809
Validation loss: 2.0711718797683716

Epoch: 6| Step: 1
Training loss: 0.48611047863960266
Validation loss: 2.0429092049598694

Epoch: 6| Step: 2
Training loss: 0.3361142873764038
Validation loss: 2.0596863428751626

Epoch: 6| Step: 3
Training loss: 0.5234370231628418
Validation loss: 2.08056370417277

Epoch: 6| Step: 4
Training loss: 0.3290502727031708
Validation loss: 2.0121963024139404

Epoch: 6| Step: 5
Training loss: 0.25054439902305603
Validation loss: 2.0653760035832724

Epoch: 6| Step: 6
Training loss: 0.7286825180053711
Validation loss: 2.0197293758392334

Epoch: 6| Step: 7
Training loss: 0.8875381946563721
Validation loss: 2.015199581782023

Epoch: 6| Step: 8
Training loss: 0.48918628692626953
Validation loss: 2.0939742724100747

Epoch: 6| Step: 9
Training loss: 0.3959271013736725
Validation loss: 1.989884356657664

Epoch: 6| Step: 10
Training loss: 0.6593486070632935
Validation loss: 2.035719931125641

Epoch: 6| Step: 11
Training loss: 0.4377327859401703
Validation loss: 2.034750759601593

Epoch: 6| Step: 12
Training loss: 0.433741956949234
Validation loss: 2.026836375395457

Epoch: 6| Step: 13
Training loss: 0.3532797694206238
Validation loss: 2.049478987852732

Epoch: 211| Step: 0
Training loss: 0.2930726706981659
Validation loss: 2.063203990459442

Epoch: 6| Step: 1
Training loss: 0.5611761212348938
Validation loss: 2.0595386226971946

Epoch: 6| Step: 2
Training loss: 0.2790292203426361
Validation loss: 1.9880681037902832

Epoch: 6| Step: 3
Training loss: 0.37450289726257324
Validation loss: 2.0274776419003806

Epoch: 6| Step: 4
Training loss: 0.7479207515716553
Validation loss: 2.0411820809046426

Epoch: 6| Step: 5
Training loss: 0.6624630689620972
Validation loss: 2.081358253955841

Epoch: 6| Step: 6
Training loss: 0.7767312526702881
Validation loss: 2.0309003790219626

Epoch: 6| Step: 7
Training loss: 0.4646152853965759
Validation loss: 2.073355197906494

Epoch: 6| Step: 8
Training loss: 0.29871609807014465
Validation loss: 2.064619223276774

Epoch: 6| Step: 9
Training loss: 0.4034888446331024
Validation loss: 2.074005206425985

Epoch: 6| Step: 10
Training loss: 0.21975091099739075
Validation loss: 2.063625156879425

Epoch: 6| Step: 11
Training loss: 0.23341505229473114
Validation loss: 2.0722399751345315

Epoch: 6| Step: 12
Training loss: 0.5589028596878052
Validation loss: 2.1017662286758423

Epoch: 6| Step: 13
Training loss: 0.7907613515853882
Validation loss: 2.0528161923090615

Epoch: 212| Step: 0
Training loss: 0.5365458726882935
Validation loss: 2.1104679902394614

Epoch: 6| Step: 1
Training loss: 0.21672236919403076
Validation loss: 2.041787564754486

Epoch: 6| Step: 2
Training loss: 0.6192582249641418
Validation loss: 2.0446550647417703

Epoch: 6| Step: 3
Training loss: 0.3250526189804077
Validation loss: 2.0456395347913108

Epoch: 6| Step: 4
Training loss: 0.529013991355896
Validation loss: 2.0858455499013266

Epoch: 6| Step: 5
Training loss: 0.3731602430343628
Validation loss: 2.097321391105652

Epoch: 6| Step: 6
Training loss: 0.42861440777778625
Validation loss: 2.1090590159098306

Epoch: 6| Step: 7
Training loss: 0.6214830875396729
Validation loss: 2.1361743609110513

Epoch: 6| Step: 8
Training loss: 0.9209636449813843
Validation loss: 2.068426728248596

Epoch: 6| Step: 9
Training loss: 0.20715738832950592
Validation loss: 2.0258670250574746

Epoch: 6| Step: 10
Training loss: 0.651689887046814
Validation loss: 2.0636414090792337

Epoch: 6| Step: 11
Training loss: 0.38146597146987915
Validation loss: 2.0617369413375854

Epoch: 6| Step: 12
Training loss: 0.4107424020767212
Validation loss: 2.050013701121012

Epoch: 6| Step: 13
Training loss: 0.5813850164413452
Validation loss: 2.0184785525004068

Epoch: 213| Step: 0
Training loss: 0.21209153532981873
Validation loss: 2.0658209323883057

Epoch: 6| Step: 1
Training loss: 0.3434383273124695
Validation loss: 2.0667541225751243

Epoch: 6| Step: 2
Training loss: 0.7124582529067993
Validation loss: 2.065730333328247

Epoch: 6| Step: 3
Training loss: 0.5419190526008606
Validation loss: 2.0272376338640847

Epoch: 6| Step: 4
Training loss: 0.46783047914505005
Validation loss: 2.0464502374331155

Epoch: 6| Step: 5
Training loss: 0.2992890477180481
Validation loss: 2.117217242717743

Epoch: 6| Step: 6
Training loss: 0.28636300563812256
Validation loss: 2.0163290898005166

Epoch: 6| Step: 7
Training loss: 0.7427622675895691
Validation loss: 2.054412523905436

Epoch: 6| Step: 8
Training loss: 0.9151957035064697
Validation loss: 2.0481028954188027

Epoch: 6| Step: 9
Training loss: 0.584824800491333
Validation loss: 2.0107166369756064

Epoch: 6| Step: 10
Training loss: 0.4547136723995209
Validation loss: 2.0147780577341714

Epoch: 6| Step: 11
Training loss: 0.3872066140174866
Validation loss: 2.0354265769322715

Epoch: 6| Step: 12
Training loss: 0.35878539085388184
Validation loss: 2.068010846773783

Epoch: 6| Step: 13
Training loss: 0.2804907560348511
Validation loss: 2.0607284108797708

Epoch: 214| Step: 0
Training loss: 0.6588884592056274
Validation loss: 2.050359050432841

Epoch: 6| Step: 1
Training loss: 0.3941551446914673
Validation loss: 2.0679226318995156

Epoch: 6| Step: 2
Training loss: 0.6746348142623901
Validation loss: 2.1128029425938926

Epoch: 6| Step: 3
Training loss: 0.22365602850914001
Validation loss: 2.0372609893480935

Epoch: 6| Step: 4
Training loss: 0.3380083441734314
Validation loss: 2.058808167775472

Epoch: 6| Step: 5
Training loss: 0.6563209295272827
Validation loss: 2.06885157028834

Epoch: 6| Step: 6
Training loss: 0.3933122754096985
Validation loss: 2.0974700848261514

Epoch: 6| Step: 7
Training loss: 0.5816280245780945
Validation loss: 2.1016558607419333

Epoch: 6| Step: 8
Training loss: 0.21726219356060028
Validation loss: 2.10778139034907

Epoch: 6| Step: 9
Training loss: 0.5224581956863403
Validation loss: 2.0773903727531433

Epoch: 6| Step: 10
Training loss: 0.46245890855789185
Validation loss: 2.075350046157837

Epoch: 6| Step: 11
Training loss: 0.49178293347358704
Validation loss: 2.04951282342275

Epoch: 6| Step: 12
Training loss: 0.6395453810691833
Validation loss: 2.0799810886383057

Epoch: 6| Step: 13
Training loss: 0.44662219285964966
Validation loss: 2.046010216077169

Epoch: 215| Step: 0
Training loss: 0.2849540114402771
Validation loss: 2.1115761597951255

Epoch: 6| Step: 1
Training loss: 0.4802749752998352
Validation loss: 2.047849873701731

Epoch: 6| Step: 2
Training loss: 0.4810422658920288
Validation loss: 2.0743181506792703

Epoch: 6| Step: 3
Training loss: 0.2902342677116394
Validation loss: 2.054470101992289

Epoch: 6| Step: 4
Training loss: 0.5066943764686584
Validation loss: 2.0690744320551553

Epoch: 6| Step: 5
Training loss: 0.4934724271297455
Validation loss: 2.0883460640907288

Epoch: 6| Step: 6
Training loss: 0.30914026498794556
Validation loss: 2.054447869459788

Epoch: 6| Step: 7
Training loss: 0.5418326258659363
Validation loss: 2.058541496594747

Epoch: 6| Step: 8
Training loss: 0.5297489762306213
Validation loss: 2.0580517848332724

Epoch: 6| Step: 9
Training loss: 0.4430822730064392
Validation loss: 2.0104448000590005

Epoch: 6| Step: 10
Training loss: 0.94413161277771
Validation loss: 2.004031697909037

Epoch: 6| Step: 11
Training loss: 0.674649178981781
Validation loss: 2.007371485233307

Epoch: 6| Step: 12
Training loss: 0.3276293873786926
Validation loss: 2.030898869037628

Epoch: 6| Step: 13
Training loss: 0.3795098662376404
Validation loss: 2.0628837744394937

Epoch: 216| Step: 0
Training loss: 0.7989258766174316
Validation loss: 2.0374510884284973

Epoch: 6| Step: 1
Training loss: 0.6424137353897095
Validation loss: 1.9956567684809368

Epoch: 6| Step: 2
Training loss: 0.4050918221473694
Validation loss: 2.064436992009481

Epoch: 6| Step: 3
Training loss: 0.3761839270591736
Validation loss: 2.0742417772610984

Epoch: 6| Step: 4
Training loss: 0.3142763376235962
Validation loss: 2.0268328189849854

Epoch: 6| Step: 5
Training loss: 0.27113404870033264
Validation loss: 1.9622849623362224

Epoch: 6| Step: 6
Training loss: 0.41327083110809326
Validation loss: 2.0604661107063293

Epoch: 6| Step: 7
Training loss: 0.24885393679141998
Validation loss: 2.0688350200653076

Epoch: 6| Step: 8
Training loss: 0.37494397163391113
Validation loss: 2.034956912199656

Epoch: 6| Step: 9
Training loss: 0.37680697441101074
Validation loss: 2.015437146027883

Epoch: 6| Step: 10
Training loss: 0.5246993899345398
Validation loss: 2.03817480802536

Epoch: 6| Step: 11
Training loss: 0.5143842697143555
Validation loss: 2.036720593770345

Epoch: 6| Step: 12
Training loss: 0.7129489779472351
Validation loss: 2.050707161426544

Epoch: 6| Step: 13
Training loss: 0.5436260104179382
Validation loss: 2.042788883050283

Epoch: 217| Step: 0
Training loss: 0.4232846796512604
Validation loss: 2.0222450892130532

Epoch: 6| Step: 1
Training loss: 0.5927643179893494
Validation loss: 2.0496458609898887

Epoch: 6| Step: 2
Training loss: 0.26789796352386475
Validation loss: 2.0788369178771973

Epoch: 6| Step: 3
Training loss: 0.3543885052204132
Validation loss: 2.0511613686879477

Epoch: 6| Step: 4
Training loss: 0.436040997505188
Validation loss: 2.0354087750116983

Epoch: 6| Step: 5
Training loss: 1.0793840885162354
Validation loss: 2.038201073805491

Epoch: 6| Step: 6
Training loss: 0.4501667618751526
Validation loss: 2.0318786104520163

Epoch: 6| Step: 7
Training loss: 0.19402790069580078
Validation loss: 2.035078008969625

Epoch: 6| Step: 8
Training loss: 0.4473063349723816
Validation loss: 2.0268702507019043

Epoch: 6| Step: 9
Training loss: 0.7342782020568848
Validation loss: 2.034739136695862

Epoch: 6| Step: 10
Training loss: 0.42192786931991577
Validation loss: 2.001163979371389

Epoch: 6| Step: 11
Training loss: 0.2822969853878021
Validation loss: 2.0349332888921103

Epoch: 6| Step: 12
Training loss: 0.5895411968231201
Validation loss: 2.0587414304415383

Epoch: 6| Step: 13
Training loss: 0.3428126275539398
Validation loss: 2.020057499408722

Epoch: 218| Step: 0
Training loss: 0.252792626619339
Validation loss: 2.0747174620628357

Epoch: 6| Step: 1
Training loss: 0.8061962127685547
Validation loss: 2.0357103745142617

Epoch: 6| Step: 2
Training loss: 0.7563120126724243
Validation loss: 2.037180264790853

Epoch: 6| Step: 3
Training loss: 0.2720140218734741
Validation loss: 2.0526185433069863

Epoch: 6| Step: 4
Training loss: 0.528517484664917
Validation loss: 2.040700674057007

Epoch: 6| Step: 5
Training loss: 0.19434216618537903
Validation loss: 2.0748504201571145

Epoch: 6| Step: 6
Training loss: 0.32677584886550903
Validation loss: 2.107215960820516

Epoch: 6| Step: 7
Training loss: 0.4110240936279297
Validation loss: 2.1138749917348227

Epoch: 6| Step: 8
Training loss: 0.301774263381958
Validation loss: 2.070384124914805

Epoch: 6| Step: 9
Training loss: 0.48144006729125977
Validation loss: 2.062013308207194

Epoch: 6| Step: 10
Training loss: 0.49492326378822327
Validation loss: 2.053168217341105

Epoch: 6| Step: 11
Training loss: 0.2772088646888733
Validation loss: 2.0451630353927612

Epoch: 6| Step: 12
Training loss: 0.4267505407333374
Validation loss: 2.0254642367362976

Epoch: 6| Step: 13
Training loss: 0.8424803614616394
Validation loss: 2.031326731046041

Epoch: 219| Step: 0
Training loss: 0.49406948685646057
Validation loss: 2.0458476146062217

Epoch: 6| Step: 1
Training loss: 0.456143319606781
Validation loss: 1.9938685496648152

Epoch: 6| Step: 2
Training loss: 0.5366733074188232
Validation loss: 2.07683672507604

Epoch: 6| Step: 3
Training loss: 0.7546190023422241
Validation loss: 2.0786559184392295

Epoch: 6| Step: 4
Training loss: 0.17916828393936157
Validation loss: 2.0655179222424827

Epoch: 6| Step: 5
Training loss: 0.5107187032699585
Validation loss: 2.0452614426612854

Epoch: 6| Step: 6
Training loss: 0.5659660696983337
Validation loss: 2.0173075000445047

Epoch: 6| Step: 7
Training loss: 0.38500896096229553
Validation loss: 2.0591810941696167

Epoch: 6| Step: 8
Training loss: 0.38240042328834534
Validation loss: 2.088906009991964

Epoch: 6| Step: 9
Training loss: 0.473526269197464
Validation loss: 2.0335561831792197

Epoch: 6| Step: 10
Training loss: 0.35654711723327637
Validation loss: 2.0835468769073486

Epoch: 6| Step: 11
Training loss: 0.5992109179496765
Validation loss: 2.071526348590851

Epoch: 6| Step: 12
Training loss: 0.46891874074935913
Validation loss: 2.0636475483576455

Epoch: 6| Step: 13
Training loss: 0.5998483896255493
Validation loss: 2.047975560029348

Epoch: 220| Step: 0
Training loss: 1.1013352870941162
Validation loss: 2.0701244870821633

Epoch: 6| Step: 1
Training loss: 0.3877241015434265
Validation loss: 2.072756846745809

Epoch: 6| Step: 2
Training loss: 0.32682955265045166
Validation loss: 2.075936277707418

Epoch: 6| Step: 3
Training loss: 0.3554971218109131
Validation loss: 2.0834508736928306

Epoch: 6| Step: 4
Training loss: 0.43367674946784973
Validation loss: 2.0485684076944985

Epoch: 6| Step: 5
Training loss: 0.4645390808582306
Validation loss: 2.0664761463801065

Epoch: 6| Step: 6
Training loss: 0.46770307421684265
Validation loss: 2.063112497329712

Epoch: 6| Step: 7
Training loss: 0.6800742745399475
Validation loss: 2.0327266852060952

Epoch: 6| Step: 8
Training loss: 0.2964373528957367
Validation loss: 2.0460081497828164

Epoch: 6| Step: 9
Training loss: 0.48765790462493896
Validation loss: 2.0408051212628684

Epoch: 6| Step: 10
Training loss: 0.5599158406257629
Validation loss: 2.082965075969696

Epoch: 6| Step: 11
Training loss: 0.611140251159668
Validation loss: 2.090066115061442

Epoch: 6| Step: 12
Training loss: 0.45060020685195923
Validation loss: 2.0918810963630676

Epoch: 6| Step: 13
Training loss: 0.24060703814029694
Validation loss: 2.060048262278239

Epoch: 221| Step: 0
Training loss: 0.7535680532455444
Validation loss: 2.0594919323921204

Epoch: 6| Step: 1
Training loss: 0.45157015323638916
Validation loss: 2.072312831878662

Epoch: 6| Step: 2
Training loss: 0.7412612438201904
Validation loss: 2.0556503931681314

Epoch: 6| Step: 3
Training loss: 0.3456304967403412
Validation loss: 2.0596060752868652

Epoch: 6| Step: 4
Training loss: 0.436354398727417
Validation loss: 2.0307922760645547

Epoch: 6| Step: 5
Training loss: 0.4664590656757355
Validation loss: 1.9832263191541035

Epoch: 6| Step: 6
Training loss: 0.289355993270874
Validation loss: 2.0618011951446533

Epoch: 6| Step: 7
Training loss: 0.591917872428894
Validation loss: 2.056361277898153

Epoch: 6| Step: 8
Training loss: 0.6657609343528748
Validation loss: 2.183860957622528

Epoch: 6| Step: 9
Training loss: 0.6567031145095825
Validation loss: 2.127536396185557

Epoch: 6| Step: 10
Training loss: 0.507634699344635
Validation loss: 2.0985668897628784

Epoch: 6| Step: 11
Training loss: 0.8770122528076172
Validation loss: 2.0587859749794006

Epoch: 6| Step: 12
Training loss: 0.24354299902915955
Validation loss: 2.023276706536611

Epoch: 6| Step: 13
Training loss: 0.5690187215805054
Validation loss: 2.012359360853831

Epoch: 222| Step: 0
Training loss: 0.5705282688140869
Validation loss: 2.0244513551394143

Epoch: 6| Step: 1
Training loss: 0.9802834391593933
Validation loss: 2.0298452178637185

Epoch: 6| Step: 2
Training loss: 0.6600456237792969
Validation loss: 2.004541834195455

Epoch: 6| Step: 3
Training loss: 0.39340460300445557
Validation loss: 2.0013398925463357

Epoch: 6| Step: 4
Training loss: 0.6120415925979614
Validation loss: 2.0026661356290183

Epoch: 6| Step: 5
Training loss: 0.42781075835227966
Validation loss: 2.0500125090281167

Epoch: 6| Step: 6
Training loss: 0.40099677443504333
Validation loss: 2.0616987347602844

Epoch: 6| Step: 7
Training loss: 0.33837997913360596
Validation loss: 2.080941994984945

Epoch: 6| Step: 8
Training loss: 0.5434395670890808
Validation loss: 2.108728528022766

Epoch: 6| Step: 9
Training loss: 0.6129714250564575
Validation loss: 2.056702673435211

Epoch: 6| Step: 10
Training loss: 0.33969658613204956
Validation loss: 2.0972893834114075

Epoch: 6| Step: 11
Training loss: 0.5463438034057617
Validation loss: 2.0279533664385476

Epoch: 6| Step: 12
Training loss: 0.6461815237998962
Validation loss: 2.012185752391815

Epoch: 6| Step: 13
Training loss: 0.523829460144043
Validation loss: 2.0423715114593506

Epoch: 223| Step: 0
Training loss: 0.29208678007125854
Validation loss: 2.0515546202659607

Epoch: 6| Step: 1
Training loss: 0.634932279586792
Validation loss: 2.0713520447413125

Epoch: 6| Step: 2
Training loss: 0.44030827283859253
Validation loss: 2.051161607106527

Epoch: 6| Step: 3
Training loss: 0.34805765748023987
Validation loss: 2.048306326071421

Epoch: 6| Step: 4
Training loss: 0.4742065668106079
Validation loss: 2.0276597340901694

Epoch: 6| Step: 5
Training loss: 0.3949281573295593
Validation loss: 2.1019532283147178

Epoch: 6| Step: 6
Training loss: 0.3596476912498474
Validation loss: 2.0526544650395713

Epoch: 6| Step: 7
Training loss: 0.7521216869354248
Validation loss: 2.060813287893931

Epoch: 6| Step: 8
Training loss: 0.7684465646743774
Validation loss: 2.0538369019826255

Epoch: 6| Step: 9
Training loss: 0.19327306747436523
Validation loss: 2.069028635819753

Epoch: 6| Step: 10
Training loss: 0.3329505920410156
Validation loss: 2.078855812549591

Epoch: 6| Step: 11
Training loss: 0.36643949151039124
Validation loss: 2.0134525299072266

Epoch: 6| Step: 12
Training loss: 0.5906404852867126
Validation loss: 2.083035488923391

Epoch: 6| Step: 13
Training loss: 0.4925570487976074
Validation loss: 2.0752773880958557

Epoch: 224| Step: 0
Training loss: 0.37645331025123596
Validation loss: 2.032114883263906

Epoch: 6| Step: 1
Training loss: 0.7100416421890259
Validation loss: 1.9883232712745667

Epoch: 6| Step: 2
Training loss: 0.3913164436817169
Validation loss: 2.0363475481669107

Epoch: 6| Step: 3
Training loss: 0.32137390971183777
Validation loss: 2.0316811005274453

Epoch: 6| Step: 4
Training loss: 0.6477928161621094
Validation loss: 1.9954174955685933

Epoch: 6| Step: 5
Training loss: 0.41892683506011963
Validation loss: 2.0460289120674133

Epoch: 6| Step: 6
Training loss: 0.38779547810554504
Validation loss: 2.0039122700691223

Epoch: 6| Step: 7
Training loss: 0.37901198863983154
Validation loss: 2.0330395102500916

Epoch: 6| Step: 8
Training loss: 0.5520257353782654
Validation loss: 2.058365523815155

Epoch: 6| Step: 9
Training loss: 0.748921275138855
Validation loss: 2.0780195792516074

Epoch: 6| Step: 10
Training loss: 0.47490763664245605
Validation loss: 2.1039934158325195

Epoch: 6| Step: 11
Training loss: 0.4560568928718567
Validation loss: 2.0995290676752725

Epoch: 6| Step: 12
Training loss: 0.44882476329803467
Validation loss: 2.0467393596967063

Epoch: 6| Step: 13
Training loss: 0.36959612369537354
Validation loss: 2.048723896344503

Epoch: 225| Step: 0
Training loss: 0.4276697337627411
Validation loss: 2.049763838450114

Epoch: 6| Step: 1
Training loss: 0.8059101104736328
Validation loss: 2.0198057889938354

Epoch: 6| Step: 2
Training loss: 1.057027816772461
Validation loss: 2.0535390377044678

Epoch: 6| Step: 3
Training loss: 0.4275364875793457
Validation loss: 2.0624306996663413

Epoch: 6| Step: 4
Training loss: 0.22649401426315308
Validation loss: 2.041680117448171

Epoch: 6| Step: 5
Training loss: 0.3860890865325928
Validation loss: 2.0616945226987204

Epoch: 6| Step: 6
Training loss: 0.6488379836082458
Validation loss: 2.0858452320098877

Epoch: 6| Step: 7
Training loss: 0.4261878430843353
Validation loss: 2.062390466531118

Epoch: 6| Step: 8
Training loss: 0.49307703971862793
Validation loss: 2.10563458998998

Epoch: 6| Step: 9
Training loss: 0.3341870903968811
Validation loss: 2.086987475554148

Epoch: 6| Step: 10
Training loss: 0.36952513456344604
Validation loss: 2.077729423840841

Epoch: 6| Step: 11
Training loss: 0.3758445382118225
Validation loss: 2.0700798630714417

Epoch: 6| Step: 12
Training loss: 0.5680923461914062
Validation loss: 2.0401700337727866

Epoch: 6| Step: 13
Training loss: 0.44285130500793457
Validation loss: 2.057807445526123

Epoch: 226| Step: 0
Training loss: 0.5197465419769287
Validation loss: 2.0983323454856873

Epoch: 6| Step: 1
Training loss: 0.28338104486465454
Validation loss: 2.0269035498301187

Epoch: 6| Step: 2
Training loss: 0.26197344064712524
Validation loss: 2.046531895796458

Epoch: 6| Step: 3
Training loss: 0.2977353632450104
Validation loss: 2.0472463766733804

Epoch: 6| Step: 4
Training loss: 0.6492246389389038
Validation loss: 2.105443557103475

Epoch: 6| Step: 5
Training loss: 0.39203083515167236
Validation loss: 2.06387331088384

Epoch: 6| Step: 6
Training loss: 0.6656999588012695
Validation loss: 2.0338545441627502

Epoch: 6| Step: 7
Training loss: 0.24937531352043152
Validation loss: 2.0229282776514688

Epoch: 6| Step: 8
Training loss: 0.8592798709869385
Validation loss: 1.9983547727266948

Epoch: 6| Step: 9
Training loss: 0.433032751083374
Validation loss: 2.0327088038126626

Epoch: 6| Step: 10
Training loss: 0.2744486927986145
Validation loss: 2.023973286151886

Epoch: 6| Step: 11
Training loss: 0.4094967842102051
Validation loss: 2.08242921034495

Epoch: 6| Step: 12
Training loss: 0.6736404895782471
Validation loss: 2.0609301328659058

Epoch: 6| Step: 13
Training loss: 0.25851869583129883
Validation loss: 2.029820760091146

Epoch: 227| Step: 0
Training loss: 0.355093777179718
Validation loss: 2.0489349563916526

Epoch: 6| Step: 1
Training loss: 0.3184410333633423
Validation loss: 2.065440515677134

Epoch: 6| Step: 2
Training loss: 0.3611817955970764
Validation loss: 2.0421927769978843

Epoch: 6| Step: 3
Training loss: 0.5365879535675049
Validation loss: 1.9969895084698994

Epoch: 6| Step: 4
Training loss: 0.6135401129722595
Validation loss: 2.0731852451960244

Epoch: 6| Step: 5
Training loss: 0.457863986492157
Validation loss: 2.056915601094564

Epoch: 6| Step: 6
Training loss: 0.3074078857898712
Validation loss: 2.0232223073641458

Epoch: 6| Step: 7
Training loss: 0.3997828960418701
Validation loss: 2.063912491003672

Epoch: 6| Step: 8
Training loss: 0.7983993291854858
Validation loss: 2.024900734424591

Epoch: 6| Step: 9
Training loss: 0.49680250883102417
Validation loss: 2.026460369427999

Epoch: 6| Step: 10
Training loss: 0.3091576397418976
Validation loss: 2.0356414914131165

Epoch: 6| Step: 11
Training loss: 0.42719781398773193
Validation loss: 2.054133574167887

Epoch: 6| Step: 12
Training loss: 0.3316206932067871
Validation loss: 2.040457844734192

Epoch: 6| Step: 13
Training loss: 0.2809765636920929
Validation loss: 2.031408409277598

Epoch: 228| Step: 0
Training loss: 0.20455342531204224
Validation loss: 1.9925619562466939

Epoch: 6| Step: 1
Training loss: 0.2880520224571228
Validation loss: 2.0522343516349792

Epoch: 6| Step: 2
Training loss: 0.44851967692375183
Validation loss: 2.0372098485628762

Epoch: 6| Step: 3
Training loss: 0.2657342553138733
Validation loss: 2.044777969519297

Epoch: 6| Step: 4
Training loss: 0.28154948353767395
Validation loss: 2.0096868673960366

Epoch: 6| Step: 5
Training loss: 0.2945495843887329
Validation loss: 2.0446683168411255

Epoch: 6| Step: 6
Training loss: 0.9728936553001404
Validation loss: 2.040205975373586

Epoch: 6| Step: 7
Training loss: 0.4463164806365967
Validation loss: 2.01385498046875

Epoch: 6| Step: 8
Training loss: 0.4075030982494354
Validation loss: 2.0849620699882507

Epoch: 6| Step: 9
Training loss: 0.4145464599132538
Validation loss: 2.034998814264933

Epoch: 6| Step: 10
Training loss: 0.3932746946811676
Validation loss: 2.051138758659363

Epoch: 6| Step: 11
Training loss: 0.3640092611312866
Validation loss: 2.035434583822886

Epoch: 6| Step: 12
Training loss: 0.4436119794845581
Validation loss: 2.064111510912577

Epoch: 6| Step: 13
Training loss: 0.9676735401153564
Validation loss: 2.037280023097992

Epoch: 229| Step: 0
Training loss: 0.3583228886127472
Validation loss: 2.0727182428042092

Epoch: 6| Step: 1
Training loss: 0.5086594820022583
Validation loss: 2.0833849708239236

Epoch: 6| Step: 2
Training loss: 0.2935682237148285
Validation loss: 2.0509639978408813

Epoch: 6| Step: 3
Training loss: 0.272090345621109
Validation loss: 2.088227172692617

Epoch: 6| Step: 4
Training loss: 0.16469097137451172
Validation loss: 2.0369884173075357

Epoch: 6| Step: 5
Training loss: 0.730866551399231
Validation loss: 2.0464621980985007

Epoch: 6| Step: 6
Training loss: 0.47264987230300903
Validation loss: 2.095203161239624

Epoch: 6| Step: 7
Training loss: 0.4110288918018341
Validation loss: 2.107359528541565

Epoch: 6| Step: 8
Training loss: 0.31114912033081055
Validation loss: 2.0848455230394998

Epoch: 6| Step: 9
Training loss: 0.6728934049606323
Validation loss: 2.0821422338485718

Epoch: 6| Step: 10
Training loss: 0.3240346908569336
Validation loss: 2.078675369421641

Epoch: 6| Step: 11
Training loss: 0.4139419198036194
Validation loss: 2.025816480318705

Epoch: 6| Step: 12
Training loss: 0.2919433116912842
Validation loss: 2.081194818019867

Epoch: 6| Step: 13
Training loss: 0.7817425727844238
Validation loss: 2.0421242117881775

Epoch: 230| Step: 0
Training loss: 0.5190632343292236
Validation loss: 2.074638605117798

Epoch: 6| Step: 1
Training loss: 0.3202158212661743
Validation loss: 2.0511333346366882

Epoch: 6| Step: 2
Training loss: 0.26846206188201904
Validation loss: 2.058124581972758

Epoch: 6| Step: 3
Training loss: 0.39358723163604736
Validation loss: 2.0699034134546914

Epoch: 6| Step: 4
Training loss: 0.47925126552581787
Validation loss: 2.052711228529612

Epoch: 6| Step: 5
Training loss: 0.8858538866043091
Validation loss: 2.0721196929613748

Epoch: 6| Step: 6
Training loss: 0.34114524722099304
Validation loss: 2.0541417797406516

Epoch: 6| Step: 7
Training loss: 0.4073942303657532
Validation loss: 2.0287609696388245

Epoch: 6| Step: 8
Training loss: 0.20083379745483398
Validation loss: 2.094632347424825

Epoch: 6| Step: 9
Training loss: 0.5503215789794922
Validation loss: 2.093427836894989

Epoch: 6| Step: 10
Training loss: 0.4397835433483124
Validation loss: 2.0586043993631997

Epoch: 6| Step: 11
Training loss: 0.17468109726905823
Validation loss: 2.101718842983246

Epoch: 6| Step: 12
Training loss: 0.4663625955581665
Validation loss: 2.071481247742971

Epoch: 6| Step: 13
Training loss: 0.5447072982788086
Validation loss: 2.0972949266433716

Epoch: 231| Step: 0
Training loss: 0.6193095445632935
Validation loss: 2.12163915236791

Epoch: 6| Step: 1
Training loss: 0.409950852394104
Validation loss: 2.1022355953852334

Epoch: 6| Step: 2
Training loss: 0.4701533615589142
Validation loss: 2.0659123261769614

Epoch: 6| Step: 3
Training loss: 0.5675715208053589
Validation loss: 2.0178559025128684

Epoch: 6| Step: 4
Training loss: 0.5605762004852295
Validation loss: 2.042553186416626

Epoch: 6| Step: 5
Training loss: 0.39780694246292114
Validation loss: 2.069308638572693

Epoch: 6| Step: 6
Training loss: 0.23625148832798004
Validation loss: 2.0717421770095825

Epoch: 6| Step: 7
Training loss: 0.5032327175140381
Validation loss: 2.0564032395680747

Epoch: 6| Step: 8
Training loss: 0.31357064843177795
Validation loss: 2.0276723504066467

Epoch: 6| Step: 9
Training loss: 0.4015088677406311
Validation loss: 2.065799434979757

Epoch: 6| Step: 10
Training loss: 0.3874002695083618
Validation loss: 2.111654043197632

Epoch: 6| Step: 11
Training loss: 0.4942595958709717
Validation loss: 2.0782822171847024

Epoch: 6| Step: 12
Training loss: 0.5518987774848938
Validation loss: 2.0522508223851523

Epoch: 6| Step: 13
Training loss: 0.5905447006225586
Validation loss: 2.091180702050527

Epoch: 232| Step: 0
Training loss: 0.47400906682014465
Validation loss: 2.047865887482961

Epoch: 6| Step: 1
Training loss: 0.6838381290435791
Validation loss: 2.0822868744532266

Epoch: 6| Step: 2
Training loss: 0.43280547857284546
Validation loss: 2.051528811454773

Epoch: 6| Step: 3
Training loss: 0.785677969455719
Validation loss: 2.0616273880004883

Epoch: 6| Step: 4
Training loss: 0.3233385682106018
Validation loss: 2.080453375975291

Epoch: 6| Step: 5
Training loss: 0.3105187714099884
Validation loss: 2.0821094711621604

Epoch: 6| Step: 6
Training loss: 0.49280932545661926
Validation loss: 2.061954994996389

Epoch: 6| Step: 7
Training loss: 0.38470104336738586
Validation loss: 2.079658567905426

Epoch: 6| Step: 8
Training loss: 0.4850313067436218
Validation loss: 2.047146995862325

Epoch: 6| Step: 9
Training loss: 0.401897668838501
Validation loss: 2.051771879196167

Epoch: 6| Step: 10
Training loss: 0.519847571849823
Validation loss: 2.0065399209658303

Epoch: 6| Step: 11
Training loss: 0.28306224942207336
Validation loss: 2.0179773569107056

Epoch: 6| Step: 12
Training loss: 0.2903854250907898
Validation loss: 2.096976021925608

Epoch: 6| Step: 13
Training loss: 0.5027623176574707
Validation loss: 2.058236062526703

Epoch: 233| Step: 0
Training loss: 0.20664703845977783
Validation loss: 2.114747862021128

Epoch: 6| Step: 1
Training loss: 0.25203609466552734
Validation loss: 2.0627360145250955

Epoch: 6| Step: 2
Training loss: 0.8949679136276245
Validation loss: 2.036225199699402

Epoch: 6| Step: 3
Training loss: 0.31157273054122925
Validation loss: 2.0307785669962564

Epoch: 6| Step: 4
Training loss: 0.3812909722328186
Validation loss: 2.0620932976404824

Epoch: 6| Step: 5
Training loss: 0.19538599252700806
Validation loss: 2.0051198601722717

Epoch: 6| Step: 6
Training loss: 0.45279258489608765
Validation loss: 2.098080495993296

Epoch: 6| Step: 7
Training loss: 0.3393898010253906
Validation loss: 2.097240169843038

Epoch: 6| Step: 8
Training loss: 0.9443132877349854
Validation loss: 2.0594523747762046

Epoch: 6| Step: 9
Training loss: 0.5181814432144165
Validation loss: 2.0339805086453757

Epoch: 6| Step: 10
Training loss: 0.314376562833786
Validation loss: 2.046351651350657

Epoch: 6| Step: 11
Training loss: 0.2780437171459198
Validation loss: 2.105278968811035

Epoch: 6| Step: 12
Training loss: 0.38842666149139404
Validation loss: 2.055148204167684

Epoch: 6| Step: 13
Training loss: 0.33248332142829895
Validation loss: 2.045866092046102

Epoch: 234| Step: 0
Training loss: 0.23813259601593018
Validation loss: 2.099574009577433

Epoch: 6| Step: 1
Training loss: 0.3507421016693115
Validation loss: 2.0630632241566977

Epoch: 6| Step: 2
Training loss: 0.8375353217124939
Validation loss: 2.092516521612803

Epoch: 6| Step: 3
Training loss: 0.399528443813324
Validation loss: 2.0938376585642495

Epoch: 6| Step: 4
Training loss: 0.5664410591125488
Validation loss: 2.0455773075421653

Epoch: 6| Step: 5
Training loss: 0.5814646482467651
Validation loss: 2.1195281346639

Epoch: 6| Step: 6
Training loss: 0.23534733057022095
Validation loss: 2.0786324540774026

Epoch: 6| Step: 7
Training loss: 0.4402388334274292
Validation loss: 2.0690817634264627

Epoch: 6| Step: 8
Training loss: 0.3043416738510132
Validation loss: 2.058821221192678

Epoch: 6| Step: 9
Training loss: 0.2770783603191376
Validation loss: 2.035361131032308

Epoch: 6| Step: 10
Training loss: 0.35713618993759155
Validation loss: 2.0161678989728293

Epoch: 6| Step: 11
Training loss: 0.4452317953109741
Validation loss: 2.0225574374198914

Epoch: 6| Step: 12
Training loss: 0.3585090637207031
Validation loss: 2.042731205622355

Epoch: 6| Step: 13
Training loss: 0.6821624636650085
Validation loss: 2.0710957249005637

Epoch: 235| Step: 0
Training loss: 0.40335097908973694
Validation loss: 2.060893396536509

Epoch: 6| Step: 1
Training loss: 0.5961683988571167
Validation loss: 2.029393990834554

Epoch: 6| Step: 2
Training loss: 0.4326646327972412
Validation loss: 2.0501708587010703

Epoch: 6| Step: 3
Training loss: 0.457388311624527
Validation loss: 2.0560946067174277

Epoch: 6| Step: 4
Training loss: 0.5454230308532715
Validation loss: 2.1003492871920266

Epoch: 6| Step: 5
Training loss: 0.23053401708602905
Validation loss: 2.0615017414093018

Epoch: 6| Step: 6
Training loss: 0.24905693531036377
Validation loss: 2.080992341041565

Epoch: 6| Step: 7
Training loss: 0.37833601236343384
Validation loss: 2.0442054271698

Epoch: 6| Step: 8
Training loss: 0.26605507731437683
Validation loss: 2.102583189805349

Epoch: 6| Step: 9
Training loss: 0.3386949300765991
Validation loss: 2.0584957202275596

Epoch: 6| Step: 10
Training loss: 0.6260794401168823
Validation loss: 2.084079702695211

Epoch: 6| Step: 11
Training loss: 0.41622281074523926
Validation loss: 2.076542337735494

Epoch: 6| Step: 12
Training loss: 0.2822134792804718
Validation loss: 2.0682182709376016

Epoch: 6| Step: 13
Training loss: 0.18424519896507263
Validation loss: 2.1290427843729653

Epoch: 236| Step: 0
Training loss: 0.7485320568084717
Validation loss: 2.0678167740503945

Epoch: 6| Step: 1
Training loss: 0.3882625102996826
Validation loss: 2.0851005713144937

Epoch: 6| Step: 2
Training loss: 0.4605044424533844
Validation loss: 2.141084849834442

Epoch: 6| Step: 3
Training loss: 0.29773038625717163
Validation loss: 2.0619544188181558

Epoch: 6| Step: 4
Training loss: 0.4436306953430176
Validation loss: 2.0910008947054544

Epoch: 6| Step: 5
Training loss: 0.2711043953895569
Validation loss: 2.0752312342325845

Epoch: 6| Step: 6
Training loss: 0.36875104904174805
Validation loss: 2.0819473266601562

Epoch: 6| Step: 7
Training loss: 0.26995977759361267
Validation loss: 2.0517786939938865

Epoch: 6| Step: 8
Training loss: 0.2722199559211731
Validation loss: 2.086035668849945

Epoch: 6| Step: 9
Training loss: 0.5417017340660095
Validation loss: 2.0817267100016275

Epoch: 6| Step: 10
Training loss: 0.3870164453983307
Validation loss: 2.023827830950419

Epoch: 6| Step: 11
Training loss: 0.46579915285110474
Validation loss: 2.06843892733256

Epoch: 6| Step: 12
Training loss: 0.48580852150917053
Validation loss: 2.0816386540730796

Epoch: 6| Step: 13
Training loss: 0.6400284767150879
Validation loss: 2.060116708278656

Epoch: 237| Step: 0
Training loss: 0.3568514585494995
Validation loss: 2.0373267332712808

Epoch: 6| Step: 1
Training loss: 0.2578195631504059
Validation loss: 2.053011496861776

Epoch: 6| Step: 2
Training loss: 0.30981647968292236
Validation loss: 2.0374576250712075

Epoch: 6| Step: 3
Training loss: 0.2976645231246948
Validation loss: 2.0454155802726746

Epoch: 6| Step: 4
Training loss: 0.38205718994140625
Validation loss: 2.0442354877789817

Epoch: 6| Step: 5
Training loss: 0.42781952023506165
Validation loss: 2.017473121484121

Epoch: 6| Step: 6
Training loss: 0.6949355602264404
Validation loss: 2.0671048959096274

Epoch: 6| Step: 7
Training loss: 0.5534546375274658
Validation loss: 2.035910904407501

Epoch: 6| Step: 8
Training loss: 0.1944756954908371
Validation loss: 2.048735797405243

Epoch: 6| Step: 9
Training loss: 0.5089880228042603
Validation loss: 2.0320831537246704

Epoch: 6| Step: 10
Training loss: 0.7223812341690063
Validation loss: 2.0424528320630393

Epoch: 6| Step: 11
Training loss: 0.45005685091018677
Validation loss: 2.080631653467814

Epoch: 6| Step: 12
Training loss: 0.2558232843875885
Validation loss: 2.0550323128700256

Epoch: 6| Step: 13
Training loss: 0.5791340470314026
Validation loss: 2.0605740547180176

Epoch: 238| Step: 0
Training loss: 0.15402621030807495
Validation loss: 2.070611079533895

Epoch: 6| Step: 1
Training loss: 0.2968645989894867
Validation loss: 2.100855608781179

Epoch: 6| Step: 2
Training loss: 0.34276673197746277
Validation loss: 2.0888410409291587

Epoch: 6| Step: 3
Training loss: 0.45656096935272217
Validation loss: 2.080061306556066

Epoch: 6| Step: 4
Training loss: 0.6382371187210083
Validation loss: 2.055532475312551

Epoch: 6| Step: 5
Training loss: 0.3826669454574585
Validation loss: 2.061317046483358

Epoch: 6| Step: 6
Training loss: 0.24780310690402985
Validation loss: 2.040025015672048

Epoch: 6| Step: 7
Training loss: 0.2844351530075073
Validation loss: 2.065985401471456

Epoch: 6| Step: 8
Training loss: 0.9919358491897583
Validation loss: 2.065421720345815

Epoch: 6| Step: 9
Training loss: 0.5300054550170898
Validation loss: 2.0893940528233848

Epoch: 6| Step: 10
Training loss: 0.20512038469314575
Validation loss: 2.0458961725234985

Epoch: 6| Step: 11
Training loss: 0.3167634606361389
Validation loss: 2.042663057645162

Epoch: 6| Step: 12
Training loss: 0.3621531128883362
Validation loss: 2.0819976528485618

Epoch: 6| Step: 13
Training loss: 0.3921922445297241
Validation loss: 2.091147502263387

Epoch: 239| Step: 0
Training loss: 0.3091886639595032
Validation loss: 2.0801245967547097

Epoch: 6| Step: 1
Training loss: 0.22425074875354767
Validation loss: 2.049948732058207

Epoch: 6| Step: 2
Training loss: 0.5216395854949951
Validation loss: 2.110075751940409

Epoch: 6| Step: 3
Training loss: 0.32772743701934814
Validation loss: 2.1046155889829

Epoch: 6| Step: 4
Training loss: 0.36343222856521606
Validation loss: 2.0929970741271973

Epoch: 6| Step: 5
Training loss: 0.41779401898384094
Validation loss: 2.0649163921674094

Epoch: 6| Step: 6
Training loss: 0.28750181198120117
Validation loss: 2.097650686899821

Epoch: 6| Step: 7
Training loss: 0.3232543468475342
Validation loss: 2.059913694858551

Epoch: 6| Step: 8
Training loss: 0.39967355132102966
Validation loss: 2.0502344965934753

Epoch: 6| Step: 9
Training loss: 0.776199221611023
Validation loss: 2.0564366579055786

Epoch: 6| Step: 10
Training loss: 0.40740299224853516
Validation loss: 2.1150842905044556

Epoch: 6| Step: 11
Training loss: 0.23593437671661377
Validation loss: 2.0330170591672263

Epoch: 6| Step: 12
Training loss: 0.4693906605243683
Validation loss: 2.0360261599222818

Epoch: 6| Step: 13
Training loss: 0.5832995772361755
Validation loss: 2.0578529238700867

Epoch: 240| Step: 0
Training loss: 0.41071850061416626
Validation loss: 2.054371992746989

Epoch: 6| Step: 1
Training loss: 0.2738856375217438
Validation loss: 2.0821328163146973

Epoch: 6| Step: 2
Training loss: 0.6742114424705505
Validation loss: 2.0862398942311606

Epoch: 6| Step: 3
Training loss: 0.7820709943771362
Validation loss: 2.078382889429728

Epoch: 6| Step: 4
Training loss: 0.4066280722618103
Validation loss: 2.0867967208226523

Epoch: 6| Step: 5
Training loss: 0.4626510441303253
Validation loss: 2.1069056391716003

Epoch: 6| Step: 6
Training loss: 0.2625378370285034
Validation loss: 2.0668330589930215

Epoch: 6| Step: 7
Training loss: 0.39020824432373047
Validation loss: 2.0654538671175637

Epoch: 6| Step: 8
Training loss: 0.23305556178092957
Validation loss: 2.0528849959373474

Epoch: 6| Step: 9
Training loss: 0.3125579357147217
Validation loss: 2.03534730275472

Epoch: 6| Step: 10
Training loss: 0.621193528175354
Validation loss: 2.0567173957824707

Epoch: 6| Step: 11
Training loss: 0.21432313323020935
Validation loss: 2.0582071344057717

Epoch: 6| Step: 12
Training loss: 0.22658009827136993
Validation loss: 2.101669987042745

Epoch: 6| Step: 13
Training loss: 0.4570578932762146
Validation loss: 2.0440953969955444

Epoch: 241| Step: 0
Training loss: 0.5318002700805664
Validation loss: 2.094837745030721

Epoch: 6| Step: 1
Training loss: 0.33682817220687866
Validation loss: 2.090417722860972

Epoch: 6| Step: 2
Training loss: 0.34649884700775146
Validation loss: 2.059330940246582

Epoch: 6| Step: 3
Training loss: 0.36952975392341614
Validation loss: 2.0865943233172097

Epoch: 6| Step: 4
Training loss: 0.23675931990146637
Validation loss: 2.060499906539917

Epoch: 6| Step: 5
Training loss: 0.5953104496002197
Validation loss: 2.0842737952868142

Epoch: 6| Step: 6
Training loss: 0.2348318248987198
Validation loss: 2.0699467857678733

Epoch: 6| Step: 7
Training loss: 0.25352412462234497
Validation loss: 2.103573819001516

Epoch: 6| Step: 8
Training loss: 0.4711041748523712
Validation loss: 2.0851134260495505

Epoch: 6| Step: 9
Training loss: 0.7975102066993713
Validation loss: 2.144952356815338

Epoch: 6| Step: 10
Training loss: 0.46731069684028625
Validation loss: 2.0794476668039956

Epoch: 6| Step: 11
Training loss: 0.16662156581878662
Validation loss: 2.082192858060201

Epoch: 6| Step: 12
Training loss: 0.350760281085968
Validation loss: 2.0737183690071106

Epoch: 6| Step: 13
Training loss: 0.5263855457305908
Validation loss: 2.077981173992157

Epoch: 242| Step: 0
Training loss: 0.30911895632743835
Validation loss: 2.0550224582354226

Epoch: 6| Step: 1
Training loss: 0.356062114238739
Validation loss: 2.1049049894014993

Epoch: 6| Step: 2
Training loss: 0.2041122019290924
Validation loss: 2.080744206905365

Epoch: 6| Step: 3
Training loss: 0.2893325090408325
Validation loss: 2.0669981638590493

Epoch: 6| Step: 4
Training loss: 0.7057499885559082
Validation loss: 2.0699930787086487

Epoch: 6| Step: 5
Training loss: 0.18382255733013153
Validation loss: 2.078197459379832

Epoch: 6| Step: 6
Training loss: 0.19782444834709167
Validation loss: 2.078907787799835

Epoch: 6| Step: 7
Training loss: 0.7344919443130493
Validation loss: 2.080512762069702

Epoch: 6| Step: 8
Training loss: 0.45379161834716797
Validation loss: 2.0781166553497314

Epoch: 6| Step: 9
Training loss: 0.2905292510986328
Validation loss: 2.057540933291117

Epoch: 6| Step: 10
Training loss: 0.8435785174369812
Validation loss: 2.0584886272748313

Epoch: 6| Step: 11
Training loss: 0.3593619763851166
Validation loss: 2.0766515930493674

Epoch: 6| Step: 12
Training loss: 0.45066317915916443
Validation loss: 2.077804605166117

Epoch: 6| Step: 13
Training loss: 0.3636273145675659
Validation loss: 2.100067655245463

Epoch: 243| Step: 0
Training loss: 0.34055787324905396
Validation loss: 2.116400162378947

Epoch: 6| Step: 1
Training loss: 0.49141162633895874
Validation loss: 2.1098867058753967

Epoch: 6| Step: 2
Training loss: 0.32524365186691284
Validation loss: 2.0891382098197937

Epoch: 6| Step: 3
Training loss: 0.2733588218688965
Validation loss: 2.068698267141978

Epoch: 6| Step: 4
Training loss: 0.3473854660987854
Validation loss: 2.0875423351923623

Epoch: 6| Step: 5
Training loss: 0.4889472424983978
Validation loss: 2.0362399021784463

Epoch: 6| Step: 6
Training loss: 0.9083826541900635
Validation loss: 2.0607893466949463

Epoch: 6| Step: 7
Training loss: 0.7445287704467773
Validation loss: 2.0301618178685508

Epoch: 6| Step: 8
Training loss: 0.28965577483177185
Validation loss: 2.098191956679026

Epoch: 6| Step: 9
Training loss: 0.671186089515686
Validation loss: 2.125282883644104

Epoch: 6| Step: 10
Training loss: 0.4501631259918213
Validation loss: 2.143037954966227

Epoch: 6| Step: 11
Training loss: 0.3729022443294525
Validation loss: 2.144711971282959

Epoch: 6| Step: 12
Training loss: 0.3744075894355774
Validation loss: 2.1007967392603555

Epoch: 6| Step: 13
Training loss: 0.31551045179367065
Validation loss: 2.107567469278971

Epoch: 244| Step: 0
Training loss: 0.9206385016441345
Validation loss: 2.113139033317566

Epoch: 6| Step: 1
Training loss: 0.6495281457901001
Validation loss: 2.0568961103757224

Epoch: 6| Step: 2
Training loss: 0.3215222954750061
Validation loss: 2.048753261566162

Epoch: 6| Step: 3
Training loss: 0.3825792074203491
Validation loss: 2.0944934288660684

Epoch: 6| Step: 4
Training loss: 0.2778138518333435
Validation loss: 2.087542156378428

Epoch: 6| Step: 5
Training loss: 0.49848663806915283
Validation loss: 2.12395449479421

Epoch: 6| Step: 6
Training loss: 0.47303107380867004
Validation loss: 2.1165631214777627

Epoch: 6| Step: 7
Training loss: 0.4481513798236847
Validation loss: 2.1123381853103638

Epoch: 6| Step: 8
Training loss: 0.43040183186531067
Validation loss: 2.1007917126019797

Epoch: 6| Step: 9
Training loss: 0.30649811029434204
Validation loss: 2.076005458831787

Epoch: 6| Step: 10
Training loss: 0.5415425896644592
Validation loss: 2.043205459912618

Epoch: 6| Step: 11
Training loss: 0.35295939445495605
Validation loss: 2.0498230258623757

Epoch: 6| Step: 12
Training loss: 0.3485923111438751
Validation loss: 2.1062000393867493

Epoch: 6| Step: 13
Training loss: 0.5093253254890442
Validation loss: 2.0667485197385154

Epoch: 245| Step: 0
Training loss: 0.862975001335144
Validation loss: 2.060091972351074

Epoch: 6| Step: 1
Training loss: 0.573465883731842
Validation loss: 2.076775074005127

Epoch: 6| Step: 2
Training loss: 0.261408269405365
Validation loss: 2.0770921111106873

Epoch: 6| Step: 3
Training loss: 0.33013099431991577
Validation loss: 2.04792183637619

Epoch: 6| Step: 4
Training loss: 0.4365115165710449
Validation loss: 2.080438514550527

Epoch: 6| Step: 5
Training loss: 0.16046260297298431
Validation loss: 2.1073973973592124

Epoch: 6| Step: 6
Training loss: 0.27681997418403625
Validation loss: 2.0896852811177573

Epoch: 6| Step: 7
Training loss: 0.415623277425766
Validation loss: 2.0991821686426797

Epoch: 6| Step: 8
Training loss: 0.3369697630405426
Validation loss: 2.0657774607340493

Epoch: 6| Step: 9
Training loss: 0.3228219151496887
Validation loss: 2.047070324420929

Epoch: 6| Step: 10
Training loss: 0.29571712017059326
Validation loss: 2.0655941168467202

Epoch: 6| Step: 11
Training loss: 0.29992926120758057
Validation loss: 2.050177037715912

Epoch: 6| Step: 12
Training loss: 0.4775506854057312
Validation loss: 2.041644891103109

Epoch: 6| Step: 13
Training loss: 0.7902283668518066
Validation loss: 2.032663424809774

Epoch: 246| Step: 0
Training loss: 0.4865744113922119
Validation loss: 2.057218154271444

Epoch: 6| Step: 1
Training loss: 0.4867546260356903
Validation loss: 2.0719011624654136

Epoch: 6| Step: 2
Training loss: 0.40734267234802246
Validation loss: 2.071158707141876

Epoch: 6| Step: 3
Training loss: 0.5191001892089844
Validation loss: 2.0893469055493674

Epoch: 6| Step: 4
Training loss: 0.32104238867759705
Validation loss: 2.12835023800532

Epoch: 6| Step: 5
Training loss: 0.42390716075897217
Validation loss: 2.127657393614451

Epoch: 6| Step: 6
Training loss: 0.3281152844429016
Validation loss: 2.1333829164505005

Epoch: 6| Step: 7
Training loss: 0.38445714116096497
Validation loss: 2.0905180970827737

Epoch: 6| Step: 8
Training loss: 0.3629460334777832
Validation loss: 2.1162376006444297

Epoch: 6| Step: 9
Training loss: 0.784761369228363
Validation loss: 2.1099153955777488

Epoch: 6| Step: 10
Training loss: 0.4896854758262634
Validation loss: 2.094427784283956

Epoch: 6| Step: 11
Training loss: 0.3920826315879822
Validation loss: 2.091053048769633

Epoch: 6| Step: 12
Training loss: 0.5947924852371216
Validation loss: 2.1089484691619873

Epoch: 6| Step: 13
Training loss: 0.4946077764034271
Validation loss: 2.12134983142217

Epoch: 247| Step: 0
Training loss: 0.269594669342041
Validation loss: 2.1097565491994223

Epoch: 6| Step: 1
Training loss: 0.3902166783809662
Validation loss: 2.1090280214945474

Epoch: 6| Step: 2
Training loss: 0.387402206659317
Validation loss: 2.098394513130188

Epoch: 6| Step: 3
Training loss: 0.5425262451171875
Validation loss: 2.097799817721049

Epoch: 6| Step: 4
Training loss: 0.38700035214424133
Validation loss: 2.0666065216064453

Epoch: 6| Step: 5
Training loss: 0.43595921993255615
Validation loss: 2.0974727074305215

Epoch: 6| Step: 6
Training loss: 0.45699262619018555
Validation loss: 2.100696643193563

Epoch: 6| Step: 7
Training loss: 0.572624146938324
Validation loss: 2.0430983304977417

Epoch: 6| Step: 8
Training loss: 0.4173220694065094
Validation loss: 2.0652565360069275

Epoch: 6| Step: 9
Training loss: 0.4171290993690491
Validation loss: 2.046507736047109

Epoch: 6| Step: 10
Training loss: 0.23098278045654297
Validation loss: 2.0667600631713867

Epoch: 6| Step: 11
Training loss: 0.28960105776786804
Validation loss: 2.083344022432963

Epoch: 6| Step: 12
Training loss: 0.4464777112007141
Validation loss: 2.11519060532252

Epoch: 6| Step: 13
Training loss: 0.790561854839325
Validation loss: 2.1098352670669556

Epoch: 248| Step: 0
Training loss: 0.5303057432174683
Validation loss: 2.0653034249941506

Epoch: 6| Step: 1
Training loss: 0.9177414774894714
Validation loss: 2.1165552139282227

Epoch: 6| Step: 2
Training loss: 0.45537319779396057
Validation loss: 2.117112318674723

Epoch: 6| Step: 3
Training loss: 0.4063776731491089
Validation loss: 2.070399363835653

Epoch: 6| Step: 4
Training loss: 0.19822245836257935
Validation loss: 2.024005651473999

Epoch: 6| Step: 5
Training loss: 0.4343200922012329
Validation loss: 2.0781365434328714

Epoch: 6| Step: 6
Training loss: 0.21291440725326538
Validation loss: 2.045188089211782

Epoch: 6| Step: 7
Training loss: 0.5579544305801392
Validation loss: 2.0495672027269998

Epoch: 6| Step: 8
Training loss: 0.5513380169868469
Validation loss: 2.069011867046356

Epoch: 6| Step: 9
Training loss: 0.3778339624404907
Validation loss: 2.050297439098358

Epoch: 6| Step: 10
Training loss: 0.1942041516304016
Validation loss: 2.081475853919983

Epoch: 6| Step: 11
Training loss: 0.2892898917198181
Validation loss: 2.0979740023612976

Epoch: 6| Step: 12
Training loss: 0.39248108863830566
Validation loss: 2.041812558968862

Epoch: 6| Step: 13
Training loss: 0.19062800705432892
Validation loss: 2.109678486982981

Epoch: 249| Step: 0
Training loss: 0.7190807461738586
Validation loss: 2.0531013309955597

Epoch: 6| Step: 1
Training loss: 0.4293879270553589
Validation loss: 2.087799390157064

Epoch: 6| Step: 2
Training loss: 0.20351621508598328
Validation loss: 2.0852301120758057

Epoch: 6| Step: 3
Training loss: 0.47888895869255066
Validation loss: 2.055610160032908

Epoch: 6| Step: 4
Training loss: 0.2848871350288391
Validation loss: 2.0560352404912314

Epoch: 6| Step: 5
Training loss: 0.2467719316482544
Validation loss: 2.082339366277059

Epoch: 6| Step: 6
Training loss: 0.41102826595306396
Validation loss: 2.1188068787256875

Epoch: 6| Step: 7
Training loss: 0.36817729473114014
Validation loss: 2.0244081020355225

Epoch: 6| Step: 8
Training loss: 0.2119450867176056
Validation loss: 2.0568344791730246

Epoch: 6| Step: 9
Training loss: 0.2914985418319702
Validation loss: 2.050519128640493

Epoch: 6| Step: 10
Training loss: 0.3672480583190918
Validation loss: 2.1157037019729614

Epoch: 6| Step: 11
Training loss: 0.2581157088279724
Validation loss: 2.067209303379059

Epoch: 6| Step: 12
Training loss: 0.30794909596443176
Validation loss: 2.111607770125071

Epoch: 6| Step: 13
Training loss: 0.5345920920372009
Validation loss: 2.06552000840505

Epoch: 250| Step: 0
Training loss: 0.47446006536483765
Validation loss: 2.1180782318115234

Epoch: 6| Step: 1
Training loss: 0.2871142625808716
Validation loss: 2.0505460699399314

Epoch: 6| Step: 2
Training loss: 0.19660960137844086
Validation loss: 2.0184101661046348

Epoch: 6| Step: 3
Training loss: 0.30704885721206665
Validation loss: 2.086131771405538

Epoch: 6| Step: 4
Training loss: 0.32564860582351685
Validation loss: 2.1096827189127603

Epoch: 6| Step: 5
Training loss: 0.3012273609638214
Validation loss: 2.076584756374359

Epoch: 6| Step: 6
Training loss: 0.4292834997177124
Validation loss: 2.072264810403188

Epoch: 6| Step: 7
Training loss: 0.7369599938392639
Validation loss: 2.109556953112284

Epoch: 6| Step: 8
Training loss: 0.18402376770973206
Validation loss: 2.0701917012532554

Epoch: 6| Step: 9
Training loss: 0.4326140582561493
Validation loss: 2.084678808848063

Epoch: 6| Step: 10
Training loss: 0.5061241388320923
Validation loss: 2.0555218855539956

Epoch: 6| Step: 11
Training loss: 0.36896419525146484
Validation loss: 2.0749319195747375

Epoch: 6| Step: 12
Training loss: 0.3768616318702698
Validation loss: 2.147086282571157

Epoch: 6| Step: 13
Training loss: 0.4901023805141449
Validation loss: 2.11398313442866

Epoch: 251| Step: 0
Training loss: 0.39004021883010864
Validation loss: 2.0648074944814048

Epoch: 6| Step: 1
Training loss: 0.2634887993335724
Validation loss: 2.0622241298357644

Epoch: 6| Step: 2
Training loss: 0.5701775550842285
Validation loss: 2.086901585261027

Epoch: 6| Step: 3
Training loss: 0.3621829152107239
Validation loss: 2.102719326814016

Epoch: 6| Step: 4
Training loss: 0.5699642896652222
Validation loss: 2.0520623922348022

Epoch: 6| Step: 5
Training loss: 0.5699482560157776
Validation loss: 2.1008870601654053

Epoch: 6| Step: 6
Training loss: 0.7955359816551208
Validation loss: 2.0725446144739785

Epoch: 6| Step: 7
Training loss: 0.15946809947490692
Validation loss: 2.0392887194951377

Epoch: 6| Step: 8
Training loss: 0.3198125660419464
Validation loss: 2.0963757038116455

Epoch: 6| Step: 9
Training loss: 0.154550701379776
Validation loss: 2.1441356937090554

Epoch: 6| Step: 10
Training loss: 0.240399569272995
Validation loss: 2.1047853231430054

Epoch: 6| Step: 11
Training loss: 0.5658301115036011
Validation loss: 2.0974477926890054

Epoch: 6| Step: 12
Training loss: 0.26331326365470886
Validation loss: 2.091840942700704

Epoch: 6| Step: 13
Training loss: 0.34704267978668213
Validation loss: 2.1083479523658752

Epoch: 252| Step: 0
Training loss: 0.2990849018096924
Validation loss: 2.0770976146062217

Epoch: 6| Step: 1
Training loss: 0.24674271047115326
Validation loss: 2.0539790193239846

Epoch: 6| Step: 2
Training loss: 0.767298698425293
Validation loss: 2.0591344038645425

Epoch: 6| Step: 3
Training loss: 0.3984079360961914
Validation loss: 2.094258725643158

Epoch: 6| Step: 4
Training loss: 0.18019264936447144
Validation loss: 2.1136069893836975

Epoch: 6| Step: 5
Training loss: 0.26145467162132263
Validation loss: 2.068882246812185

Epoch: 6| Step: 6
Training loss: 0.26088079810142517
Validation loss: 2.0335158904393515

Epoch: 6| Step: 7
Training loss: 0.2554856538772583
Validation loss: 2.045863409837087

Epoch: 6| Step: 8
Training loss: 0.37052154541015625
Validation loss: 2.0839893420537314

Epoch: 6| Step: 9
Training loss: 0.17818258702754974
Validation loss: 2.097070892651876

Epoch: 6| Step: 10
Training loss: 0.3132683336734772
Validation loss: 2.0652554829915366

Epoch: 6| Step: 11
Training loss: 0.5306006073951721
Validation loss: 2.107835908730825

Epoch: 6| Step: 12
Training loss: 0.5687941312789917
Validation loss: 2.0872196157773337

Epoch: 6| Step: 13
Training loss: 0.5089390873908997
Validation loss: 2.1229154467582703

Epoch: 253| Step: 0
Training loss: 0.2769879698753357
Validation loss: 2.097469210624695

Epoch: 6| Step: 1
Training loss: 0.31814610958099365
Validation loss: 2.0838035146395364

Epoch: 6| Step: 2
Training loss: 0.4421720802783966
Validation loss: 2.073908587296804

Epoch: 6| Step: 3
Training loss: 0.34513404965400696
Validation loss: 2.0471965670585632

Epoch: 6| Step: 4
Training loss: 0.5378000736236572
Validation loss: 2.062806765238444

Epoch: 6| Step: 5
Training loss: 0.6031595468521118
Validation loss: 2.12645560503006

Epoch: 6| Step: 6
Training loss: 0.2537776231765747
Validation loss: 2.0637372732162476

Epoch: 6| Step: 7
Training loss: 0.5799077749252319
Validation loss: 2.081413149833679

Epoch: 6| Step: 8
Training loss: 0.35109931230545044
Validation loss: 2.0765134692192078

Epoch: 6| Step: 9
Training loss: 0.2811393439769745
Validation loss: 2.063106914361318

Epoch: 6| Step: 10
Training loss: 0.5728493928909302
Validation loss: 2.0908030072848

Epoch: 6| Step: 11
Training loss: 0.2937466502189636
Validation loss: 2.150611241658529

Epoch: 6| Step: 12
Training loss: 0.37909525632858276
Validation loss: 2.095717986424764

Epoch: 6| Step: 13
Training loss: 0.549144983291626
Validation loss: 2.1502575675646463

Epoch: 254| Step: 0
Training loss: 0.4715001583099365
Validation loss: 2.1329944133758545

Epoch: 6| Step: 1
Training loss: 0.26248615980148315
Validation loss: 2.055987298488617

Epoch: 6| Step: 2
Training loss: 0.15421664714813232
Validation loss: 2.109217127164205

Epoch: 6| Step: 3
Training loss: 0.39815229177474976
Validation loss: 2.056851585706075

Epoch: 6| Step: 4
Training loss: 0.34018629789352417
Validation loss: 2.0491885344187417

Epoch: 6| Step: 5
Training loss: 0.24973882734775543
Validation loss: 2.107189655303955

Epoch: 6| Step: 6
Training loss: 0.1692103147506714
Validation loss: 2.06360516945521

Epoch: 6| Step: 7
Training loss: 0.9105793237686157
Validation loss: 2.062757949034373

Epoch: 6| Step: 8
Training loss: 0.23438449203968048
Validation loss: 2.032044291496277

Epoch: 6| Step: 9
Training loss: 0.25389161705970764
Validation loss: 2.0874282121658325

Epoch: 6| Step: 10
Training loss: 0.29757654666900635
Validation loss: 2.048693895339966

Epoch: 6| Step: 11
Training loss: 0.3943527638912201
Validation loss: 2.051286518573761

Epoch: 6| Step: 12
Training loss: 0.3379861116409302
Validation loss: 2.090445359547933

Epoch: 6| Step: 13
Training loss: 0.6019321084022522
Validation loss: 2.091486175855001

Epoch: 255| Step: 0
Training loss: 0.45229125022888184
Validation loss: 2.094791909058889

Epoch: 6| Step: 1
Training loss: 0.25335973501205444
Validation loss: 2.082062005996704

Epoch: 6| Step: 2
Training loss: 0.5356868505477905
Validation loss: 2.0754517714182534

Epoch: 6| Step: 3
Training loss: 0.2970619201660156
Validation loss: 2.0609657168388367

Epoch: 6| Step: 4
Training loss: 0.29477590322494507
Validation loss: 2.0592698454856873

Epoch: 6| Step: 5
Training loss: 0.46258026361465454
Validation loss: 2.0532807111740112

Epoch: 6| Step: 6
Training loss: 0.5057476758956909
Validation loss: 2.0637625257174173

Epoch: 6| Step: 7
Training loss: 0.27634119987487793
Validation loss: 2.0349456667900085

Epoch: 6| Step: 8
Training loss: 0.20129036903381348
Validation loss: 2.0560895204544067

Epoch: 6| Step: 9
Training loss: 0.2942832112312317
Validation loss: 2.0780438780784607

Epoch: 6| Step: 10
Training loss: 0.3204854130744934
Validation loss: 2.0862621466318765

Epoch: 6| Step: 11
Training loss: 0.5270669460296631
Validation loss: 2.1547844807306924

Epoch: 6| Step: 12
Training loss: 0.6861838102340698
Validation loss: 2.1107120712598166

Epoch: 6| Step: 13
Training loss: 0.43713364005088806
Validation loss: 2.0662413438161216

Epoch: 256| Step: 0
Training loss: 0.43522965908050537
Validation loss: 2.092865467071533

Epoch: 6| Step: 1
Training loss: 0.30649083852767944
Validation loss: 2.108906944592794

Epoch: 6| Step: 2
Training loss: 0.2888064980506897
Validation loss: 2.0456315875053406

Epoch: 6| Step: 3
Training loss: 0.2557394504547119
Validation loss: 2.0747135082880654

Epoch: 6| Step: 4
Training loss: 0.27821800112724304
Validation loss: 2.026869237422943

Epoch: 6| Step: 5
Training loss: 0.6484174728393555
Validation loss: 2.034885744253794

Epoch: 6| Step: 6
Training loss: 0.3460858166217804
Validation loss: 2.0368118286132812

Epoch: 6| Step: 7
Training loss: 0.42568573355674744
Validation loss: 2.0583486557006836

Epoch: 6| Step: 8
Training loss: 0.6783614754676819
Validation loss: 2.0602206786473594

Epoch: 6| Step: 9
Training loss: 0.5206284523010254
Validation loss: 2.098063309987386

Epoch: 6| Step: 10
Training loss: 0.30660736560821533
Validation loss: 2.0858107010523477

Epoch: 6| Step: 11
Training loss: 0.4813121557235718
Validation loss: 2.1000040769577026

Epoch: 6| Step: 12
Training loss: 0.2277296483516693
Validation loss: 2.0980204343795776

Epoch: 6| Step: 13
Training loss: 0.5558089017868042
Validation loss: 2.0711857875188193

Epoch: 257| Step: 0
Training loss: 0.40521204471588135
Validation loss: 2.057673176129659

Epoch: 6| Step: 1
Training loss: 0.7667772769927979
Validation loss: 2.0583214362462363

Epoch: 6| Step: 2
Training loss: 0.39475303888320923
Validation loss: 2.052825371424357

Epoch: 6| Step: 3
Training loss: 0.3285866379737854
Validation loss: 2.0857346852620444

Epoch: 6| Step: 4
Training loss: 0.4285200834274292
Validation loss: 2.082226792971293

Epoch: 6| Step: 5
Training loss: 0.22273603081703186
Validation loss: 2.1197391549746194

Epoch: 6| Step: 6
Training loss: 0.37349438667297363
Validation loss: 2.0313575863838196

Epoch: 6| Step: 7
Training loss: 0.4119719862937927
Validation loss: 2.071102420488993

Epoch: 6| Step: 8
Training loss: 0.270534873008728
Validation loss: 2.0595256090164185

Epoch: 6| Step: 9
Training loss: 0.3955736756324768
Validation loss: 2.040831983089447

Epoch: 6| Step: 10
Training loss: 0.4673319160938263
Validation loss: 2.0641080141067505

Epoch: 6| Step: 11
Training loss: 0.3663421869277954
Validation loss: 2.0718653202056885

Epoch: 6| Step: 12
Training loss: 0.28851595520973206
Validation loss: 2.089381297429403

Epoch: 6| Step: 13
Training loss: 0.4053998589515686
Validation loss: 2.086070716381073

Epoch: 258| Step: 0
Training loss: 0.8876821994781494
Validation loss: 2.0824559728304544

Epoch: 6| Step: 1
Training loss: 0.2438836693763733
Validation loss: 2.0661023457845054

Epoch: 6| Step: 2
Training loss: 0.2459944486618042
Validation loss: 2.072332262992859

Epoch: 6| Step: 3
Training loss: 0.3197423219680786
Validation loss: 2.096104919910431

Epoch: 6| Step: 4
Training loss: 0.3864668309688568
Validation loss: 2.062892973423004

Epoch: 6| Step: 5
Training loss: 0.2598040997982025
Validation loss: 2.0852585236231485

Epoch: 6| Step: 6
Training loss: 0.42457854747772217
Validation loss: 2.05725105603536

Epoch: 6| Step: 7
Training loss: 0.31641438603401184
Validation loss: 2.0887593229611716

Epoch: 6| Step: 8
Training loss: 0.3136839270591736
Validation loss: 2.052199979623159

Epoch: 6| Step: 9
Training loss: 0.1365012228488922
Validation loss: 2.054341713587443

Epoch: 6| Step: 10
Training loss: 0.2936478853225708
Validation loss: 2.078579584757487

Epoch: 6| Step: 11
Training loss: 0.5205379724502563
Validation loss: 2.09967573483785

Epoch: 6| Step: 12
Training loss: 0.6736816167831421
Validation loss: 2.067401130994161

Epoch: 6| Step: 13
Training loss: 0.25741058588027954
Validation loss: 2.0943689942359924

Epoch: 259| Step: 0
Training loss: 0.6534382104873657
Validation loss: 2.1017733414967856

Epoch: 6| Step: 1
Training loss: 0.2994416058063507
Validation loss: 2.0921006997426352

Epoch: 6| Step: 2
Training loss: 0.32426735758781433
Validation loss: 2.0768757462501526

Epoch: 6| Step: 3
Training loss: 0.39827418327331543
Validation loss: 2.051616589228312

Epoch: 6| Step: 4
Training loss: 0.28556445240974426
Validation loss: 2.0939488212267556

Epoch: 6| Step: 5
Training loss: 0.6728269457817078
Validation loss: 2.1094595988591514

Epoch: 6| Step: 6
Training loss: 0.3809835612773895
Validation loss: 2.1090847849845886

Epoch: 6| Step: 7
Training loss: 0.31612712144851685
Validation loss: 2.0771422386169434

Epoch: 6| Step: 8
Training loss: 0.26707005500793457
Validation loss: 2.1304659644762673

Epoch: 6| Step: 9
Training loss: 0.4347558617591858
Validation loss: 2.092016061147054

Epoch: 6| Step: 10
Training loss: 0.3906177580356598
Validation loss: 2.1688918670018515

Epoch: 6| Step: 11
Training loss: 0.391288161277771
Validation loss: 2.148127237955729

Epoch: 6| Step: 12
Training loss: 0.4283369779586792
Validation loss: 2.1013614336649575

Epoch: 6| Step: 13
Training loss: 0.36207568645477295
Validation loss: 2.088482995827993

Epoch: 260| Step: 0
Training loss: 0.2584553360939026
Validation loss: 2.0184503396352134

Epoch: 6| Step: 1
Training loss: 0.2509830594062805
Validation loss: 2.0168238083521524

Epoch: 6| Step: 2
Training loss: 0.8832394480705261
Validation loss: 2.0583888490994773

Epoch: 6| Step: 3
Training loss: 0.5123472213745117
Validation loss: 2.0920169750849404

Epoch: 6| Step: 4
Training loss: 0.5778120756149292
Validation loss: 2.0369069576263428

Epoch: 6| Step: 5
Training loss: 0.33565425872802734
Validation loss: 2.078142007191976

Epoch: 6| Step: 6
Training loss: 0.5623066425323486
Validation loss: 2.06296569108963

Epoch: 6| Step: 7
Training loss: 0.32743367552757263
Validation loss: 2.127426783243815

Epoch: 6| Step: 8
Training loss: 0.49871498346328735
Validation loss: 2.0876153906186423

Epoch: 6| Step: 9
Training loss: 0.48302486538887024
Validation loss: 2.169133464495341

Epoch: 6| Step: 10
Training loss: 0.49636784195899963
Validation loss: 2.1214051445325217

Epoch: 6| Step: 11
Training loss: 0.3051806092262268
Validation loss: 2.104789654413859

Epoch: 6| Step: 12
Training loss: 0.4420328140258789
Validation loss: 2.023486832777659

Epoch: 6| Step: 13
Training loss: 0.4733869135379791
Validation loss: 2.108058452606201

Epoch: 261| Step: 0
Training loss: 0.45653074979782104
Validation loss: 2.068182408809662

Epoch: 6| Step: 1
Training loss: 0.7119131088256836
Validation loss: 2.0500537355740867

Epoch: 6| Step: 2
Training loss: 0.3038395047187805
Validation loss: 2.0381428003311157

Epoch: 6| Step: 3
Training loss: 0.4364984631538391
Validation loss: 2.041019876797994

Epoch: 6| Step: 4
Training loss: 0.28007227182388306
Validation loss: 2.065269192059835

Epoch: 6| Step: 5
Training loss: 0.31791698932647705
Validation loss: 2.1261717478434243

Epoch: 6| Step: 6
Training loss: 0.4498761296272278
Validation loss: 2.0483632683753967

Epoch: 6| Step: 7
Training loss: 0.21741369366645813
Validation loss: 2.064362565676371

Epoch: 6| Step: 8
Training loss: 0.2504045367240906
Validation loss: 2.105447789033254

Epoch: 6| Step: 9
Training loss: 0.42918604612350464
Validation loss: 2.083864986896515

Epoch: 6| Step: 10
Training loss: 0.5909926891326904
Validation loss: 2.1180033882459006

Epoch: 6| Step: 11
Training loss: 0.40218585729599
Validation loss: 2.0709957281748452

Epoch: 6| Step: 12
Training loss: 0.2845262289047241
Validation loss: 2.076455275217692

Epoch: 6| Step: 13
Training loss: 0.37008100748062134
Validation loss: 2.094511250654856

Epoch: 262| Step: 0
Training loss: 0.21661105751991272
Validation loss: 2.078934609889984

Epoch: 6| Step: 1
Training loss: 0.6897372603416443
Validation loss: 2.0925039052963257

Epoch: 6| Step: 2
Training loss: 0.2592609226703644
Validation loss: 2.1231047908465066

Epoch: 6| Step: 3
Training loss: 0.4385795593261719
Validation loss: 2.03338630994161

Epoch: 6| Step: 4
Training loss: 0.5124266147613525
Validation loss: 2.0510407288869223

Epoch: 6| Step: 5
Training loss: 0.19698955118656158
Validation loss: 2.0891228119532266

Epoch: 6| Step: 6
Training loss: 0.3014427125453949
Validation loss: 2.1050391594568887

Epoch: 6| Step: 7
Training loss: 0.49487820267677307
Validation loss: 2.0967153112093606

Epoch: 6| Step: 8
Training loss: 0.2971436083316803
Validation loss: 2.114804824193319

Epoch: 6| Step: 9
Training loss: 0.20127838850021362
Validation loss: 2.100257615248362

Epoch: 6| Step: 10
Training loss: 0.22694845497608185
Validation loss: 2.0674599011739097

Epoch: 6| Step: 11
Training loss: 0.2679617404937744
Validation loss: 2.0456800858179727

Epoch: 6| Step: 12
Training loss: 0.5998586416244507
Validation loss: 2.0935686230659485

Epoch: 6| Step: 13
Training loss: 0.4536011219024658
Validation loss: 2.059511442979177

Epoch: 263| Step: 0
Training loss: 0.39057058095932007
Validation loss: 2.079057812690735

Epoch: 6| Step: 1
Training loss: 0.37069812417030334
Validation loss: 2.0773420532544455

Epoch: 6| Step: 2
Training loss: 0.24990348517894745
Validation loss: 2.055601418018341

Epoch: 6| Step: 3
Training loss: 0.30374032258987427
Validation loss: 2.0969490011533103

Epoch: 6| Step: 4
Training loss: 0.7008110284805298
Validation loss: 2.062397837638855

Epoch: 6| Step: 5
Training loss: 0.2519457936286926
Validation loss: 2.116300185521444

Epoch: 6| Step: 6
Training loss: 0.56871497631073
Validation loss: 2.1174671053886414

Epoch: 6| Step: 7
Training loss: 0.2874976396560669
Validation loss: 2.07394548257192

Epoch: 6| Step: 8
Training loss: 0.42897140979766846
Validation loss: 2.0722594062487283

Epoch: 6| Step: 9
Training loss: 0.5565230846405029
Validation loss: 2.0920967062314353

Epoch: 6| Step: 10
Training loss: 0.28404244780540466
Validation loss: 2.0428656935691833

Epoch: 6| Step: 11
Training loss: 0.41719943284988403
Validation loss: 2.0243132511774697

Epoch: 6| Step: 12
Training loss: 0.2834930419921875
Validation loss: 2.047777752081553

Epoch: 6| Step: 13
Training loss: 0.38363391160964966
Validation loss: 2.1032178004582724

Epoch: 264| Step: 0
Training loss: 0.3185768127441406
Validation loss: 2.0696581999460855

Epoch: 6| Step: 1
Training loss: 0.271027147769928
Validation loss: 2.095550318559011

Epoch: 6| Step: 2
Training loss: 0.34919846057891846
Validation loss: 2.0244892636934915

Epoch: 6| Step: 3
Training loss: 0.4177713394165039
Validation loss: 2.0753449201583862

Epoch: 6| Step: 4
Training loss: 0.2591175436973572
Validation loss: 2.0736523270606995

Epoch: 6| Step: 5
Training loss: 0.3150739371776581
Validation loss: 2.0630335410435996

Epoch: 6| Step: 6
Training loss: 0.35397660732269287
Validation loss: 2.055970013141632

Epoch: 6| Step: 7
Training loss: 0.2991170883178711
Validation loss: 2.0523354212443032

Epoch: 6| Step: 8
Training loss: 0.28316646814346313
Validation loss: 2.1072741746902466

Epoch: 6| Step: 9
Training loss: 0.4071614444255829
Validation loss: 2.0825226505597434

Epoch: 6| Step: 10
Training loss: 0.7132815718650818
Validation loss: 2.0430870056152344

Epoch: 6| Step: 11
Training loss: 0.6094875931739807
Validation loss: 2.0893714427948

Epoch: 6| Step: 12
Training loss: 0.21744680404663086
Validation loss: 2.0917237599690757

Epoch: 6| Step: 13
Training loss: 0.3956558108329773
Validation loss: 2.109180529912313

Epoch: 265| Step: 0
Training loss: 0.2526434063911438
Validation loss: 2.1132832368214927

Epoch: 6| Step: 1
Training loss: 0.2289574146270752
Validation loss: 2.122119903564453

Epoch: 6| Step: 2
Training loss: 0.2702157199382782
Validation loss: 2.090997040271759

Epoch: 6| Step: 3
Training loss: 0.7094964981079102
Validation loss: 2.075960397720337

Epoch: 6| Step: 4
Training loss: 0.6240076422691345
Validation loss: 2.1208402514457703

Epoch: 6| Step: 5
Training loss: 0.321999728679657
Validation loss: 2.1077259381612143

Epoch: 6| Step: 6
Training loss: 0.6456623673439026
Validation loss: 2.0970086256663003

Epoch: 6| Step: 7
Training loss: 0.265498548746109
Validation loss: 2.1252689957618713

Epoch: 6| Step: 8
Training loss: 0.29789137840270996
Validation loss: 2.08528999487559

Epoch: 6| Step: 9
Training loss: 0.40190738439559937
Validation loss: 2.0925280849138894

Epoch: 6| Step: 10
Training loss: 0.3956751227378845
Validation loss: 2.1332329312960305

Epoch: 6| Step: 11
Training loss: 0.31521376967430115
Validation loss: 2.1348158717155457

Epoch: 6| Step: 12
Training loss: 0.23395150899887085
Validation loss: 2.137993256251017

Epoch: 6| Step: 13
Training loss: 0.3758472204208374
Validation loss: 2.135687450567881

Epoch: 266| Step: 0
Training loss: 0.47344866394996643
Validation loss: 2.082989672819773

Epoch: 6| Step: 1
Training loss: 0.6987484693527222
Validation loss: 2.123185694217682

Epoch: 6| Step: 2
Training loss: 0.4251771569252014
Validation loss: 2.061132768789927

Epoch: 6| Step: 3
Training loss: 0.4173877239227295
Validation loss: 2.0997401078542075

Epoch: 6| Step: 4
Training loss: 0.37623563408851624
Validation loss: 2.107572158177694

Epoch: 6| Step: 5
Training loss: 0.3174448609352112
Validation loss: 2.0753637750943503

Epoch: 6| Step: 6
Training loss: 0.261606901884079
Validation loss: 2.0826202630996704

Epoch: 6| Step: 7
Training loss: 0.24275049567222595
Validation loss: 2.1919376452763877

Epoch: 6| Step: 8
Training loss: 0.5077962279319763
Validation loss: 2.111550490061442

Epoch: 6| Step: 9
Training loss: 0.27324509620666504
Validation loss: 2.1317885518074036

Epoch: 6| Step: 10
Training loss: 0.3052009642124176
Validation loss: 2.1093030174573264

Epoch: 6| Step: 11
Training loss: 0.28894078731536865
Validation loss: 2.025940259297689

Epoch: 6| Step: 12
Training loss: 0.30682373046875
Validation loss: 2.1093586087226868

Epoch: 6| Step: 13
Training loss: 0.27624601125717163
Validation loss: 2.0737499793370566

Epoch: 267| Step: 0
Training loss: 0.3458218574523926
Validation loss: 2.08803129196167

Epoch: 6| Step: 1
Training loss: 0.3282695412635803
Validation loss: 2.0947230656941733

Epoch: 6| Step: 2
Training loss: 0.18359610438346863
Validation loss: 2.0852941274642944

Epoch: 6| Step: 3
Training loss: 0.30419671535491943
Validation loss: 2.1114339232444763

Epoch: 6| Step: 4
Training loss: 0.39165741205215454
Validation loss: 2.1448671221733093

Epoch: 6| Step: 5
Training loss: 0.43819066882133484
Validation loss: 2.0943830808003745

Epoch: 6| Step: 6
Training loss: 0.8122110366821289
Validation loss: 2.106927216053009

Epoch: 6| Step: 7
Training loss: 0.28072112798690796
Validation loss: 2.0713707407315574

Epoch: 6| Step: 8
Training loss: 0.2562982141971588
Validation loss: 2.0753174225489297

Epoch: 6| Step: 9
Training loss: 0.3870168924331665
Validation loss: 2.0869999527931213

Epoch: 6| Step: 10
Training loss: 0.26526713371276855
Validation loss: 2.0969185034434

Epoch: 6| Step: 11
Training loss: 0.30898404121398926
Validation loss: 2.088990350564321

Epoch: 6| Step: 12
Training loss: 0.46694257855415344
Validation loss: 2.0868658224741616

Epoch: 6| Step: 13
Training loss: 0.27788448333740234
Validation loss: 2.082608620325724

Epoch: 268| Step: 0
Training loss: 0.3447068929672241
Validation loss: 2.112091143925985

Epoch: 6| Step: 1
Training loss: 0.20085734128952026
Validation loss: 2.063585380713145

Epoch: 6| Step: 2
Training loss: 0.2510594427585602
Validation loss: 2.024009923140208

Epoch: 6| Step: 3
Training loss: 0.2977334260940552
Validation loss: 2.0975935061772666

Epoch: 6| Step: 4
Training loss: 0.2876734733581543
Validation loss: 2.091456870237986

Epoch: 6| Step: 5
Training loss: 0.41406047344207764
Validation loss: 2.1265727480252585

Epoch: 6| Step: 6
Training loss: 0.45828157663345337
Validation loss: 2.0686306158701577

Epoch: 6| Step: 7
Training loss: 0.36343637108802795
Validation loss: 2.067088862260183

Epoch: 6| Step: 8
Training loss: 0.33284154534339905
Validation loss: 2.0903250575065613

Epoch: 6| Step: 9
Training loss: 0.9089738726615906
Validation loss: 2.080551048119863

Epoch: 6| Step: 10
Training loss: 0.258033812046051
Validation loss: 2.11481249332428

Epoch: 6| Step: 11
Training loss: 0.3071545958518982
Validation loss: 2.087316373984019

Epoch: 6| Step: 12
Training loss: 0.3835080862045288
Validation loss: 2.1156887213389077

Epoch: 6| Step: 13
Training loss: 0.4042758047580719
Validation loss: 2.11189866065979

Epoch: 269| Step: 0
Training loss: 0.369441419839859
Validation loss: 2.134239455064138

Epoch: 6| Step: 1
Training loss: 0.4380704164505005
Validation loss: 2.0707470774650574

Epoch: 6| Step: 2
Training loss: 0.20217470824718475
Validation loss: 2.180676261583964

Epoch: 6| Step: 3
Training loss: 0.4069845676422119
Validation loss: 2.1119194825490317

Epoch: 6| Step: 4
Training loss: 0.21419110894203186
Validation loss: 2.115274965763092

Epoch: 6| Step: 5
Training loss: 0.2422657310962677
Validation loss: 2.139613687992096

Epoch: 6| Step: 6
Training loss: 0.28774482011795044
Validation loss: 2.102877914905548

Epoch: 6| Step: 7
Training loss: 0.1833634227514267
Validation loss: 2.1665679812431335

Epoch: 6| Step: 8
Training loss: 0.37111836671829224
Validation loss: 2.0775309403737388

Epoch: 6| Step: 9
Training loss: 0.633919894695282
Validation loss: 2.1164751847585044

Epoch: 6| Step: 10
Training loss: 0.27048662304878235
Validation loss: 2.1053637862205505

Epoch: 6| Step: 11
Training loss: 0.4501323103904724
Validation loss: 2.1183802684148154

Epoch: 6| Step: 12
Training loss: 0.2956005334854126
Validation loss: 2.091161588827769

Epoch: 6| Step: 13
Training loss: 0.6658313870429993
Validation loss: 2.103232483069102

Epoch: 270| Step: 0
Training loss: 0.6829683184623718
Validation loss: 2.0753330985705056

Epoch: 6| Step: 1
Training loss: 0.25455138087272644
Validation loss: 2.096440613269806

Epoch: 6| Step: 2
Training loss: 0.4774438142776489
Validation loss: 2.110869566599528

Epoch: 6| Step: 3
Training loss: 0.3893076777458191
Validation loss: 2.1381141940752664

Epoch: 6| Step: 4
Training loss: 0.2661530673503876
Validation loss: 2.1072272260983786

Epoch: 6| Step: 5
Training loss: 0.3883451223373413
Validation loss: 2.0811261336008706

Epoch: 6| Step: 6
Training loss: 0.2166251242160797
Validation loss: 2.098616083463033

Epoch: 6| Step: 7
Training loss: 0.38737624883651733
Validation loss: 2.095009207725525

Epoch: 6| Step: 8
Training loss: 0.27177655696868896
Validation loss: 2.1139140129089355

Epoch: 6| Step: 9
Training loss: 0.4068133234977722
Validation loss: 2.0768362085024514

Epoch: 6| Step: 10
Training loss: 0.20350250601768494
Validation loss: 2.154760241508484

Epoch: 6| Step: 11
Training loss: 0.5613163709640503
Validation loss: 2.1078151861826577

Epoch: 6| Step: 12
Training loss: 0.27603453397750854
Validation loss: 2.1024042765299478

Epoch: 6| Step: 13
Training loss: 0.3649323582649231
Validation loss: 2.1138327916463218

Epoch: 271| Step: 0
Training loss: 0.3485718071460724
Validation loss: 2.073448598384857

Epoch: 6| Step: 1
Training loss: 0.27818870544433594
Validation loss: 2.1048550804456077

Epoch: 6| Step: 2
Training loss: 0.2497299462556839
Validation loss: 2.079512119293213

Epoch: 6| Step: 3
Training loss: 0.5148642063140869
Validation loss: 2.085462729136149

Epoch: 6| Step: 4
Training loss: 0.894496738910675
Validation loss: 2.1710153023401895

Epoch: 6| Step: 5
Training loss: 0.14913910627365112
Validation loss: 2.051278313000997

Epoch: 6| Step: 6
Training loss: 0.28709661960601807
Validation loss: 2.0714714924494424

Epoch: 6| Step: 7
Training loss: 0.18415319919586182
Validation loss: 2.1118318835894265

Epoch: 6| Step: 8
Training loss: 0.4868259131908417
Validation loss: 2.076179484526316

Epoch: 6| Step: 9
Training loss: 0.22411298751831055
Validation loss: 2.058115323384603

Epoch: 6| Step: 10
Training loss: 0.40373700857162476
Validation loss: 2.1085007389386496

Epoch: 6| Step: 11
Training loss: 0.41150403022766113
Validation loss: 2.1116904616355896

Epoch: 6| Step: 12
Training loss: 0.23925425112247467
Validation loss: 2.1014914512634277

Epoch: 6| Step: 13
Training loss: 0.37885981798171997
Validation loss: 2.180321474870046

Epoch: 272| Step: 0
Training loss: 0.38642966747283936
Validation loss: 2.120391547679901

Epoch: 6| Step: 1
Training loss: 0.18158775568008423
Validation loss: 2.085452894369761

Epoch: 6| Step: 2
Training loss: 0.3085980713367462
Validation loss: 2.0906997521718345

Epoch: 6| Step: 3
Training loss: 0.17394259572029114
Validation loss: 2.049242118994395

Epoch: 6| Step: 4
Training loss: 0.39026567339897156
Validation loss: 2.0856553316116333

Epoch: 6| Step: 5
Training loss: 1.0714319944381714
Validation loss: 2.0736561020215354

Epoch: 6| Step: 6
Training loss: 0.3263612687587738
Validation loss: 2.0875871777534485

Epoch: 6| Step: 7
Training loss: 0.21614430844783783
Validation loss: 2.0393441120783486

Epoch: 6| Step: 8
Training loss: 0.38796180486679077
Validation loss: 2.1051590045293174

Epoch: 6| Step: 9
Training loss: 0.321911096572876
Validation loss: 2.064794441064199

Epoch: 6| Step: 10
Training loss: 0.36306032538414
Validation loss: 2.109740753968557

Epoch: 6| Step: 11
Training loss: 0.5178179144859314
Validation loss: 2.1341081857681274

Epoch: 6| Step: 12
Training loss: 0.25592240691185
Validation loss: 2.1073224345842996

Epoch: 6| Step: 13
Training loss: 0.1845429539680481
Validation loss: 2.078034063180288

Epoch: 273| Step: 0
Training loss: 0.30553117394447327
Validation loss: 2.0379411379496255

Epoch: 6| Step: 1
Training loss: 0.2257339507341385
Validation loss: 2.0681822896003723

Epoch: 6| Step: 2
Training loss: 0.48654234409332275
Validation loss: 2.074904481569926

Epoch: 6| Step: 3
Training loss: 0.260824978351593
Validation loss: 2.0418084065119424

Epoch: 6| Step: 4
Training loss: 0.30155283212661743
Validation loss: 2.057533919811249

Epoch: 6| Step: 5
Training loss: 0.39609673619270325
Validation loss: 2.0754899183909097

Epoch: 6| Step: 6
Training loss: 0.3616606891155243
Validation loss: 2.0855143666267395

Epoch: 6| Step: 7
Training loss: 0.49274054169654846
Validation loss: 2.133549451828003

Epoch: 6| Step: 8
Training loss: 0.4034806191921234
Validation loss: 2.090438803037008

Epoch: 6| Step: 9
Training loss: 0.21168532967567444
Validation loss: 2.120540897051493

Epoch: 6| Step: 10
Training loss: 0.4466528296470642
Validation loss: 2.0944575667381287

Epoch: 6| Step: 11
Training loss: 0.3566121459007263
Validation loss: 2.1165539026260376

Epoch: 6| Step: 12
Training loss: 0.2890198230743408
Validation loss: 2.072266777356466

Epoch: 6| Step: 13
Training loss: 0.7192990183830261
Validation loss: 2.0478604634602866

Epoch: 274| Step: 0
Training loss: 0.37928682565689087
Validation loss: 2.078276753425598

Epoch: 6| Step: 1
Training loss: 0.25086498260498047
Validation loss: 2.074388047059377

Epoch: 6| Step: 2
Training loss: 0.18863141536712646
Validation loss: 2.0777145425478616

Epoch: 6| Step: 3
Training loss: 0.14841040968894958
Validation loss: 2.0741631786028543

Epoch: 6| Step: 4
Training loss: 0.3217884302139282
Validation loss: 2.091458320617676

Epoch: 6| Step: 5
Training loss: 0.28717759251594543
Validation loss: 2.035504460334778

Epoch: 6| Step: 6
Training loss: 0.2293420135974884
Validation loss: 2.069310784339905

Epoch: 6| Step: 7
Training loss: 0.6135850548744202
Validation loss: 2.0098578135172525

Epoch: 6| Step: 8
Training loss: 0.36327260732650757
Validation loss: 1.988145649433136

Epoch: 6| Step: 9
Training loss: 0.36907538771629333
Validation loss: 2.0594695607821145

Epoch: 6| Step: 10
Training loss: 0.34794536232948303
Validation loss: 2.022077977657318

Epoch: 6| Step: 11
Training loss: 0.8180459141731262
Validation loss: 2.0691870053609214

Epoch: 6| Step: 12
Training loss: 0.26750648021698
Validation loss: 2.079043726126353

Epoch: 6| Step: 13
Training loss: 0.32767078280448914
Validation loss: 2.0558587114016214

Epoch: 275| Step: 0
Training loss: 0.5394316911697388
Validation loss: 2.045764207839966

Epoch: 6| Step: 1
Training loss: 0.24876269698143005
Validation loss: 2.061614374319712

Epoch: 6| Step: 2
Training loss: 0.31968650221824646
Validation loss: 2.104608138402303

Epoch: 6| Step: 3
Training loss: 0.23017552495002747
Validation loss: 2.0886693199475608

Epoch: 6| Step: 4
Training loss: 0.36659330129623413
Validation loss: 2.1277827620506287

Epoch: 6| Step: 5
Training loss: 0.30716484785079956
Validation loss: 2.0270268519719443

Epoch: 6| Step: 6
Training loss: 0.35873568058013916
Validation loss: 2.093156099319458

Epoch: 6| Step: 7
Training loss: 0.6911438703536987
Validation loss: 2.0927871267000833

Epoch: 6| Step: 8
Training loss: 0.29234579205513
Validation loss: 2.1079320112864175

Epoch: 6| Step: 9
Training loss: 0.42344382405281067
Validation loss: 2.052004853884379

Epoch: 6| Step: 10
Training loss: 0.27761808037757874
Validation loss: 2.0941208402315774

Epoch: 6| Step: 11
Training loss: 0.2143177092075348
Validation loss: 2.1019176642100015

Epoch: 6| Step: 12
Training loss: 0.39962780475616455
Validation loss: 2.1032880942026773

Epoch: 6| Step: 13
Training loss: 0.44719287753105164
Validation loss: 2.112209379673004

Epoch: 276| Step: 0
Training loss: 0.7309635281562805
Validation loss: 2.1237635811169944

Epoch: 6| Step: 1
Training loss: 0.2678748369216919
Validation loss: 2.086013913154602

Epoch: 6| Step: 2
Training loss: 0.3158852159976959
Validation loss: 2.078890005747477

Epoch: 6| Step: 3
Training loss: 0.1719461977481842
Validation loss: 2.0469382405281067

Epoch: 6| Step: 4
Training loss: 0.3053792119026184
Validation loss: 2.084191918373108

Epoch: 6| Step: 5
Training loss: 0.6756851673126221
Validation loss: 2.037576735019684

Epoch: 6| Step: 6
Training loss: 0.29106786847114563
Validation loss: 2.0643452405929565

Epoch: 6| Step: 7
Training loss: 0.3659829795360565
Validation loss: 2.0702131191889444

Epoch: 6| Step: 8
Training loss: 0.2521563768386841
Validation loss: 2.0403685172398887

Epoch: 6| Step: 9
Training loss: 0.31128358840942383
Validation loss: 2.0805843671162925

Epoch: 6| Step: 10
Training loss: 0.5138607025146484
Validation loss: 2.0962645411491394

Epoch: 6| Step: 11
Training loss: 0.5808531641960144
Validation loss: 2.1311128338178

Epoch: 6| Step: 12
Training loss: 0.43144065141677856
Validation loss: 2.1010215679804483

Epoch: 6| Step: 13
Training loss: 0.32595309615135193
Validation loss: 2.0904851953188577

Epoch: 277| Step: 0
Training loss: 0.1618582010269165
Validation loss: 2.054385562737783

Epoch: 6| Step: 1
Training loss: 0.30504387617111206
Validation loss: 2.0657772024472556

Epoch: 6| Step: 2
Training loss: 0.44618478417396545
Validation loss: 2.066607415676117

Epoch: 6| Step: 3
Training loss: 0.349648118019104
Validation loss: 2.013014098008474

Epoch: 6| Step: 4
Training loss: 0.5865062475204468
Validation loss: 2.049758553504944

Epoch: 6| Step: 5
Training loss: 0.34025251865386963
Validation loss: 2.0333813230196633

Epoch: 6| Step: 6
Training loss: 0.32796984910964966
Validation loss: 2.0321691433588662

Epoch: 6| Step: 7
Training loss: 0.7910879254341125
Validation loss: 2.0416723092397056

Epoch: 6| Step: 8
Training loss: 0.24543434381484985
Validation loss: 2.135551075140635

Epoch: 6| Step: 9
Training loss: 0.311393141746521
Validation loss: 2.1247459252675376

Epoch: 6| Step: 10
Training loss: 0.3565881550312042
Validation loss: 2.102565050125122

Epoch: 6| Step: 11
Training loss: 0.3117506504058838
Validation loss: 2.097852031389872

Epoch: 6| Step: 12
Training loss: 0.2169003188610077
Validation loss: 2.1129520734151206

Epoch: 6| Step: 13
Training loss: 0.47642505168914795
Validation loss: 2.073183238506317

Epoch: 278| Step: 0
Training loss: 0.3906777799129486
Validation loss: 2.063898424307505

Epoch: 6| Step: 1
Training loss: 0.23843371868133545
Validation loss: 2.075182477633158

Epoch: 6| Step: 2
Training loss: 0.363692969083786
Validation loss: 2.0611233711242676

Epoch: 6| Step: 3
Training loss: 0.28844237327575684
Validation loss: 2.1099244753519693

Epoch: 6| Step: 4
Training loss: 0.30682238936424255
Validation loss: 2.1046232183774314

Epoch: 6| Step: 5
Training loss: 0.3697633445262909
Validation loss: 2.051686863104502

Epoch: 6| Step: 6
Training loss: 0.9958893060684204
Validation loss: 2.0779224236806235

Epoch: 6| Step: 7
Training loss: 0.387713223695755
Validation loss: 2.089732825756073

Epoch: 6| Step: 8
Training loss: 0.2880309224128723
Validation loss: 2.103898604710897

Epoch: 6| Step: 9
Training loss: 0.2526078224182129
Validation loss: 2.0638764103253684

Epoch: 6| Step: 10
Training loss: 0.3759942948818207
Validation loss: 2.0784610907236734

Epoch: 6| Step: 11
Training loss: 0.48795318603515625
Validation loss: 2.0946630239486694

Epoch: 6| Step: 12
Training loss: 0.20418931543827057
Validation loss: 2.1379199226697287

Epoch: 6| Step: 13
Training loss: 0.2952589690685272
Validation loss: 2.0843639373779297

Epoch: 279| Step: 0
Training loss: 0.3056574761867523
Validation loss: 2.1032317876815796

Epoch: 6| Step: 1
Training loss: 0.2488543689250946
Validation loss: 2.1363630294799805

Epoch: 6| Step: 2
Training loss: 0.4463517963886261
Validation loss: 2.088035305341085

Epoch: 6| Step: 3
Training loss: 0.2862682342529297
Validation loss: 2.073874851067861

Epoch: 6| Step: 4
Training loss: 0.46946585178375244
Validation loss: 2.060068686803182

Epoch: 6| Step: 5
Training loss: 0.3134423792362213
Validation loss: 2.069539169470469

Epoch: 6| Step: 6
Training loss: 0.2761852443218231
Validation loss: 2.0606143474578857

Epoch: 6| Step: 7
Training loss: 0.20720168948173523
Validation loss: 2.0703070561091104

Epoch: 6| Step: 8
Training loss: 0.6532337665557861
Validation loss: 2.063904345035553

Epoch: 6| Step: 9
Training loss: 0.2582966685295105
Validation loss: 2.023230771223704

Epoch: 6| Step: 10
Training loss: 0.24040290713310242
Validation loss: 2.020369827747345

Epoch: 6| Step: 11
Training loss: 0.7537751793861389
Validation loss: 2.052847146987915

Epoch: 6| Step: 12
Training loss: 0.387305349111557
Validation loss: 2.059255301952362

Epoch: 6| Step: 13
Training loss: 0.3283769488334656
Validation loss: 2.074691335360209

Epoch: 280| Step: 0
Training loss: 0.4073895812034607
Validation loss: 2.071585774421692

Epoch: 6| Step: 1
Training loss: 0.3491007685661316
Validation loss: 2.06081360578537

Epoch: 6| Step: 2
Training loss: 0.2654290795326233
Validation loss: 2.053068220615387

Epoch: 6| Step: 3
Training loss: 0.3576156497001648
Validation loss: 2.0862318873405457

Epoch: 6| Step: 4
Training loss: 0.2987380027770996
Validation loss: 2.080070654551188

Epoch: 6| Step: 5
Training loss: 0.2438880205154419
Validation loss: 2.053932766119639

Epoch: 6| Step: 6
Training loss: 0.2663164734840393
Validation loss: 2.0427982807159424

Epoch: 6| Step: 7
Training loss: 0.19376236200332642
Validation loss: 2.0020543336868286

Epoch: 6| Step: 8
Training loss: 0.7229717969894409
Validation loss: 2.063236971696218

Epoch: 6| Step: 9
Training loss: 0.45818591117858887
Validation loss: 2.0622850259145102

Epoch: 6| Step: 10
Training loss: 0.4182170033454895
Validation loss: 2.060598095258077

Epoch: 6| Step: 11
Training loss: 0.3232651948928833
Validation loss: 2.04694273074468

Epoch: 6| Step: 12
Training loss: 0.21765924990177155
Validation loss: 2.0064334670702615

Epoch: 6| Step: 13
Training loss: 0.27819186449050903
Validation loss: 2.0885028640429177

Epoch: 281| Step: 0
Training loss: 0.27835971117019653
Validation loss: 2.086965004603068

Epoch: 6| Step: 1
Training loss: 0.3928438723087311
Validation loss: 2.085012137889862

Epoch: 6| Step: 2
Training loss: 0.42336830496788025
Validation loss: 2.091202696164449

Epoch: 6| Step: 3
Training loss: 0.4315918982028961
Validation loss: 2.0624870459238687

Epoch: 6| Step: 4
Training loss: 0.3392857611179352
Validation loss: 2.0332327683766684

Epoch: 6| Step: 5
Training loss: 0.35573872923851013
Validation loss: 2.0743650794029236

Epoch: 6| Step: 6
Training loss: 0.2913137674331665
Validation loss: 2.0672521193822226

Epoch: 6| Step: 7
Training loss: 0.6479167342185974
Validation loss: 2.064599355061849

Epoch: 6| Step: 8
Training loss: 0.42209142446517944
Validation loss: 2.091760436693827

Epoch: 6| Step: 9
Training loss: 0.4334222972393036
Validation loss: 2.041948835055033

Epoch: 6| Step: 10
Training loss: 0.25327545404434204
Validation loss: 2.0378215511639914

Epoch: 6| Step: 11
Training loss: 0.5195738077163696
Validation loss: 2.089766184488932

Epoch: 6| Step: 12
Training loss: 0.2888321876525879
Validation loss: 2.074653228123983

Epoch: 6| Step: 13
Training loss: 0.251268208026886
Validation loss: 2.072445591290792

Epoch: 282| Step: 0
Training loss: 0.34888148307800293
Validation loss: 2.0861244201660156

Epoch: 6| Step: 1
Training loss: 0.29557645320892334
Validation loss: 2.1037798126538596

Epoch: 6| Step: 2
Training loss: 0.30074554681777954
Validation loss: 2.0547233621279397

Epoch: 6| Step: 3
Training loss: 0.598372757434845
Validation loss: 2.086644411087036

Epoch: 6| Step: 4
Training loss: 0.32835811376571655
Validation loss: 2.0459446012973785

Epoch: 6| Step: 5
Training loss: 0.6647542119026184
Validation loss: 2.0359058181444802

Epoch: 6| Step: 6
Training loss: 0.33149927854537964
Validation loss: 2.0921302239100137

Epoch: 6| Step: 7
Training loss: 0.19602417945861816
Validation loss: 2.0950459241867065

Epoch: 6| Step: 8
Training loss: 0.4215610921382904
Validation loss: 2.089607377847036

Epoch: 6| Step: 9
Training loss: 0.17146939039230347
Validation loss: 2.1081034739812217

Epoch: 6| Step: 10
Training loss: 0.28701239824295044
Validation loss: 2.1684497197469077

Epoch: 6| Step: 11
Training loss: 0.2314772605895996
Validation loss: 2.103643814722697

Epoch: 6| Step: 12
Training loss: 0.49250614643096924
Validation loss: 2.1421060959498086

Epoch: 6| Step: 13
Training loss: 0.23010186851024628
Validation loss: 2.0936010678609214

Epoch: 283| Step: 0
Training loss: 0.1886088103055954
Validation loss: 2.111534337202708

Epoch: 6| Step: 1
Training loss: 0.2957955002784729
Validation loss: 2.1078613996505737

Epoch: 6| Step: 2
Training loss: 0.4032011032104492
Validation loss: 2.0819657246271768

Epoch: 6| Step: 3
Training loss: 0.7142553925514221
Validation loss: 2.094387968381246

Epoch: 6| Step: 4
Training loss: 0.20119768381118774
Validation loss: 2.122186283270518

Epoch: 6| Step: 5
Training loss: 0.3701864182949066
Validation loss: 2.0809743205706277

Epoch: 6| Step: 6
Training loss: 0.3766477108001709
Validation loss: 2.1092968583106995

Epoch: 6| Step: 7
Training loss: 0.3002311587333679
Validation loss: 2.0879089633623757

Epoch: 6| Step: 8
Training loss: 0.36146268248558044
Validation loss: 2.0886281530062356

Epoch: 6| Step: 9
Training loss: 0.30124330520629883
Validation loss: 2.086600740750631

Epoch: 6| Step: 10
Training loss: 0.471017450094223
Validation loss: 2.0218503872553506

Epoch: 6| Step: 11
Training loss: 0.26086270809173584
Validation loss: 2.0599953730901084

Epoch: 6| Step: 12
Training loss: 0.17773103713989258
Validation loss: 2.084912200768789

Epoch: 6| Step: 13
Training loss: 0.3860696852207184
Validation loss: 2.08942186832428

Epoch: 284| Step: 0
Training loss: 0.30001959204673767
Validation loss: 2.128928244113922

Epoch: 6| Step: 1
Training loss: 0.6764169931411743
Validation loss: 2.1128151019414267

Epoch: 6| Step: 2
Training loss: 0.2727743983268738
Validation loss: 2.1126914819081626

Epoch: 6| Step: 3
Training loss: 0.25712069869041443
Validation loss: 2.0599310994148254

Epoch: 6| Step: 4
Training loss: 0.2389029562473297
Validation loss: 2.063429514567057

Epoch: 6| Step: 5
Training loss: 0.26447582244873047
Validation loss: 2.042720158894857

Epoch: 6| Step: 6
Training loss: 0.5338760018348694
Validation loss: 2.1445990602175393

Epoch: 6| Step: 7
Training loss: 0.20898012816905975
Validation loss: 2.065180778503418

Epoch: 6| Step: 8
Training loss: 0.20956483483314514
Validation loss: 2.036931872367859

Epoch: 6| Step: 9
Training loss: 0.2045915573835373
Validation loss: 2.074712892373403

Epoch: 6| Step: 10
Training loss: 0.5012850761413574
Validation loss: 2.0997270345687866

Epoch: 6| Step: 11
Training loss: 0.3151726722717285
Validation loss: 2.079972724119822

Epoch: 6| Step: 12
Training loss: 0.2676805555820465
Validation loss: 2.069979985555013

Epoch: 6| Step: 13
Training loss: 0.46683114767074585
Validation loss: 2.0665282011032104

Epoch: 285| Step: 0
Training loss: 0.2734883427619934
Validation loss: 2.0638797680536904

Epoch: 6| Step: 1
Training loss: 0.27761492133140564
Validation loss: 2.075623393058777

Epoch: 6| Step: 2
Training loss: 0.22816547751426697
Validation loss: 2.073960522810618

Epoch: 6| Step: 3
Training loss: 0.30645114183425903
Validation loss: 2.076378285884857

Epoch: 6| Step: 4
Training loss: 0.2983279824256897
Validation loss: 2.0649107495943704

Epoch: 6| Step: 5
Training loss: 0.46789786219596863
Validation loss: 2.059083561102549

Epoch: 6| Step: 6
Training loss: 0.2879336476325989
Validation loss: 2.0975337823232016

Epoch: 6| Step: 7
Training loss: 0.7548980116844177
Validation loss: 2.062182446320852

Epoch: 6| Step: 8
Training loss: 0.3883829116821289
Validation loss: 2.094201982021332

Epoch: 6| Step: 9
Training loss: 0.362703412771225
Validation loss: 2.0891189575195312

Epoch: 6| Step: 10
Training loss: 0.33557409048080444
Validation loss: 2.046111802260081

Epoch: 6| Step: 11
Training loss: 0.3303728699684143
Validation loss: 2.074471354484558

Epoch: 6| Step: 12
Training loss: 0.23069505393505096
Validation loss: 2.0931236346562705

Epoch: 6| Step: 13
Training loss: 0.39913609623908997
Validation loss: 2.093231519063314

Epoch: 286| Step: 0
Training loss: 0.29117441177368164
Validation loss: 2.0463496843973794

Epoch: 6| Step: 1
Training loss: 0.26693195104599
Validation loss: 2.065047562122345

Epoch: 6| Step: 2
Training loss: 0.22856497764587402
Validation loss: 2.0852728486061096

Epoch: 6| Step: 3
Training loss: 0.2705498933792114
Validation loss: 2.0992244879404702

Epoch: 6| Step: 4
Training loss: 0.3253028094768524
Validation loss: 2.113087793191274

Epoch: 6| Step: 5
Training loss: 0.9273115396499634
Validation loss: 2.090930243333181

Epoch: 6| Step: 6
Training loss: 0.2157256305217743
Validation loss: 2.094766636689504

Epoch: 6| Step: 7
Training loss: 0.32281094789505005
Validation loss: 2.115284502506256

Epoch: 6| Step: 8
Training loss: 0.21069982647895813
Validation loss: 2.072151005268097

Epoch: 6| Step: 9
Training loss: 0.31509238481521606
Validation loss: 2.0905534625053406

Epoch: 6| Step: 10
Training loss: 0.4273231625556946
Validation loss: 2.076624353726705

Epoch: 6| Step: 11
Training loss: 0.21090714633464813
Validation loss: 2.090501129627228

Epoch: 6| Step: 12
Training loss: 0.3983522951602936
Validation loss: 2.0503801306088767

Epoch: 6| Step: 13
Training loss: 0.4186832904815674
Validation loss: 2.1072948972384133

Epoch: 287| Step: 0
Training loss: 0.3660869002342224
Validation loss: 2.1112066507339478

Epoch: 6| Step: 1
Training loss: 0.2273712158203125
Validation loss: 2.0391032497088113

Epoch: 6| Step: 2
Training loss: 0.3304433226585388
Validation loss: 2.0977010329564414

Epoch: 6| Step: 3
Training loss: 0.7919161319732666
Validation loss: 2.0710146029790244

Epoch: 6| Step: 4
Training loss: 0.26774361729621887
Validation loss: 2.055000066757202

Epoch: 6| Step: 5
Training loss: 0.38134434819221497
Validation loss: 2.10428253809611

Epoch: 6| Step: 6
Training loss: 0.23747828602790833
Validation loss: 2.090837319691976

Epoch: 6| Step: 7
Training loss: 0.2381194531917572
Validation loss: 2.0939627091089883

Epoch: 6| Step: 8
Training loss: 0.328181654214859
Validation loss: 2.0674756368001304

Epoch: 6| Step: 9
Training loss: 0.237778902053833
Validation loss: 2.0641203920046487

Epoch: 6| Step: 10
Training loss: 0.18616782128810883
Validation loss: 2.099490761756897

Epoch: 6| Step: 11
Training loss: 0.2716066241264343
Validation loss: 2.096554080645243

Epoch: 6| Step: 12
Training loss: 0.5152010321617126
Validation loss: 2.056207597255707

Epoch: 6| Step: 13
Training loss: 0.45085060596466064
Validation loss: 2.054130494594574

Epoch: 288| Step: 0
Training loss: 0.2784064710140228
Validation loss: 2.027352293332418

Epoch: 6| Step: 1
Training loss: 0.24961069226264954
Validation loss: 2.0960522095362344

Epoch: 6| Step: 2
Training loss: 0.40563130378723145
Validation loss: 2.0686620076497397

Epoch: 6| Step: 3
Training loss: 0.4062643349170685
Validation loss: 2.098409593105316

Epoch: 6| Step: 4
Training loss: 0.29379546642303467
Validation loss: 2.0895882646242776

Epoch: 6| Step: 5
Training loss: 0.23354971408843994
Validation loss: 2.0855969389279685

Epoch: 6| Step: 6
Training loss: 0.6842035055160522
Validation loss: 2.0830169121424356

Epoch: 6| Step: 7
Training loss: 0.3199923634529114
Validation loss: 2.1015247106552124

Epoch: 6| Step: 8
Training loss: 0.23657450079917908
Validation loss: 2.0572038888931274

Epoch: 6| Step: 9
Training loss: 0.19354961812496185
Validation loss: 2.0785058736801147

Epoch: 6| Step: 10
Training loss: 0.3431481719017029
Validation loss: 2.0605346163113913

Epoch: 6| Step: 11
Training loss: 0.40554869174957275
Validation loss: 2.098874092102051

Epoch: 6| Step: 12
Training loss: 0.31204742193222046
Validation loss: 2.1526501178741455

Epoch: 6| Step: 13
Training loss: 0.2638200521469116
Validation loss: 2.1335160732269287

Epoch: 289| Step: 0
Training loss: 0.6377222537994385
Validation loss: 2.1640078028043113

Epoch: 6| Step: 1
Training loss: 0.32703617215156555
Validation loss: 2.127607742945353

Epoch: 6| Step: 2
Training loss: 0.3993137776851654
Validation loss: 2.1145904858907065

Epoch: 6| Step: 3
Training loss: 0.5149767398834229
Validation loss: 2.1167486111323037

Epoch: 6| Step: 4
Training loss: 0.32920995354652405
Validation loss: 2.11391411225001

Epoch: 6| Step: 5
Training loss: 0.41981279850006104
Validation loss: 2.0612725615501404

Epoch: 6| Step: 6
Training loss: 0.3240361213684082
Validation loss: 2.0839290221532187

Epoch: 6| Step: 7
Training loss: 0.2622023820877075
Validation loss: 2.094822903474172

Epoch: 6| Step: 8
Training loss: 0.1781507134437561
Validation loss: 2.0643937389055886

Epoch: 6| Step: 9
Training loss: 0.11577478051185608
Validation loss: 2.06958415110906

Epoch: 6| Step: 10
Training loss: 0.3134477138519287
Validation loss: 2.079451064268748

Epoch: 6| Step: 11
Training loss: 0.257365345954895
Validation loss: 2.1036065022150674

Epoch: 6| Step: 12
Training loss: 0.28095853328704834
Validation loss: 2.095246354738871

Epoch: 6| Step: 13
Training loss: 0.6161186695098877
Validation loss: 2.1062700152397156

Epoch: 290| Step: 0
Training loss: 0.3172066807746887
Validation loss: 2.106942971547445

Epoch: 6| Step: 1
Training loss: 0.28077250719070435
Validation loss: 2.0628398060798645

Epoch: 6| Step: 2
Training loss: 0.1580222249031067
Validation loss: 2.0912298361460366

Epoch: 6| Step: 3
Training loss: 0.2156994342803955
Validation loss: 2.0828798611958823

Epoch: 6| Step: 4
Training loss: 0.3579466938972473
Validation loss: 2.0604423880577087

Epoch: 6| Step: 5
Training loss: 0.2251596599817276
Validation loss: 2.068109929561615

Epoch: 6| Step: 6
Training loss: 0.27165353298187256
Validation loss: 2.110566715399424

Epoch: 6| Step: 7
Training loss: 0.3095300793647766
Validation loss: 2.050086577733358

Epoch: 6| Step: 8
Training loss: 0.52638840675354
Validation loss: 2.118704636891683

Epoch: 6| Step: 9
Training loss: 0.21482327580451965
Validation loss: 2.118338922659556

Epoch: 6| Step: 10
Training loss: 0.7625759840011597
Validation loss: 2.0979623993237815

Epoch: 6| Step: 11
Training loss: 0.3980444371700287
Validation loss: 2.1209707260131836

Epoch: 6| Step: 12
Training loss: 0.1890285164117813
Validation loss: 2.0609538356463113

Epoch: 6| Step: 13
Training loss: 0.20494073629379272
Validation loss: 2.1265774369239807

Epoch: 291| Step: 0
Training loss: 0.7378228306770325
Validation loss: 2.1491327484448752

Epoch: 6| Step: 1
Training loss: 0.30024802684783936
Validation loss: 2.100093424320221

Epoch: 6| Step: 2
Training loss: 0.25478535890579224
Validation loss: 2.0437913735707602

Epoch: 6| Step: 3
Training loss: 0.32262325286865234
Validation loss: 2.107470373312632

Epoch: 6| Step: 4
Training loss: 0.22210250794887543
Validation loss: 2.1489020188649497

Epoch: 6| Step: 5
Training loss: 0.21156679093837738
Validation loss: 2.100111265977224

Epoch: 6| Step: 6
Training loss: 0.3458205461502075
Validation loss: 2.090071201324463

Epoch: 6| Step: 7
Training loss: 0.1584663987159729
Validation loss: 2.157361408074697

Epoch: 6| Step: 8
Training loss: 0.34259575605392456
Validation loss: 2.1064557433128357

Epoch: 6| Step: 9
Training loss: 0.26547330617904663
Validation loss: 2.105443557103475

Epoch: 6| Step: 10
Training loss: 0.17722970247268677
Validation loss: 2.1125165224075317

Epoch: 6| Step: 11
Training loss: 0.4561225175857544
Validation loss: 2.105611721674601

Epoch: 6| Step: 12
Training loss: 0.17540667951107025
Validation loss: 2.145965039730072

Epoch: 6| Step: 13
Training loss: 0.4162898361682892
Validation loss: 2.144536793231964

Epoch: 292| Step: 0
Training loss: 0.4884333908557892
Validation loss: 2.091423233350118

Epoch: 6| Step: 1
Training loss: 0.4324072599411011
Validation loss: 2.0645973285039267

Epoch: 6| Step: 2
Training loss: 0.2568865418434143
Validation loss: 2.0779573917388916

Epoch: 6| Step: 3
Training loss: 0.3830013871192932
Validation loss: 2.123221834500631

Epoch: 6| Step: 4
Training loss: 0.282037615776062
Validation loss: 2.083396236101786

Epoch: 6| Step: 5
Training loss: 0.20017465949058533
Validation loss: 2.0902989308039346

Epoch: 6| Step: 6
Training loss: 0.24536436796188354
Validation loss: 2.106148580710093

Epoch: 6| Step: 7
Training loss: 0.2634749412536621
Validation loss: 2.1153690020243325

Epoch: 6| Step: 8
Training loss: 0.32299602031707764
Validation loss: 2.079930901527405

Epoch: 6| Step: 9
Training loss: 0.2973026931285858
Validation loss: 2.0723663171132407

Epoch: 6| Step: 10
Training loss: 0.27860796451568604
Validation loss: 2.0823150277137756

Epoch: 6| Step: 11
Training loss: 0.7709192037582397
Validation loss: 2.0852596163749695

Epoch: 6| Step: 12
Training loss: 0.2351587861776352
Validation loss: 2.119111100832621

Epoch: 6| Step: 13
Training loss: 0.3510443866252899
Validation loss: 2.08969376484553

Epoch: 293| Step: 0
Training loss: 0.2863600254058838
Validation loss: 2.086590588092804

Epoch: 6| Step: 1
Training loss: 0.2319241762161255
Validation loss: 2.1482120354970298

Epoch: 6| Step: 2
Training loss: 0.5058108568191528
Validation loss: 2.0775851607322693

Epoch: 6| Step: 3
Training loss: 0.42772454023361206
Validation loss: 2.112220287322998

Epoch: 6| Step: 4
Training loss: 0.15676932036876678
Validation loss: 2.1214551528294883

Epoch: 6| Step: 5
Training loss: 0.22799229621887207
Validation loss: 2.022080441315969

Epoch: 6| Step: 6
Training loss: 0.7907297611236572
Validation loss: 2.0722933212916055

Epoch: 6| Step: 7
Training loss: 0.4319370985031128
Validation loss: 2.0468599001566568

Epoch: 6| Step: 8
Training loss: 0.4494478404521942
Validation loss: 2.1004282236099243

Epoch: 6| Step: 9
Training loss: 0.24844832718372345
Validation loss: 2.080340623855591

Epoch: 6| Step: 10
Training loss: 0.23632431030273438
Validation loss: 2.046882768472036

Epoch: 6| Step: 11
Training loss: 0.37246495485305786
Validation loss: 2.112167318662008

Epoch: 6| Step: 12
Training loss: 0.2237156480550766
Validation loss: 2.1016534765561423

Epoch: 6| Step: 13
Training loss: 0.3429313898086548
Validation loss: 2.1383054653803506

Epoch: 294| Step: 0
Training loss: 0.2832544445991516
Validation loss: 2.115801771481832

Epoch: 6| Step: 1
Training loss: 0.24790626764297485
Validation loss: 2.1339020331700644

Epoch: 6| Step: 2
Training loss: 0.19901323318481445
Validation loss: 2.117760638395945

Epoch: 6| Step: 3
Training loss: 0.2045426070690155
Validation loss: 2.076450685660044

Epoch: 6| Step: 4
Training loss: 0.3319012522697449
Validation loss: 2.1060610016187034

Epoch: 6| Step: 5
Training loss: 0.40907034277915955
Validation loss: 2.104786237080892

Epoch: 6| Step: 6
Training loss: 0.5089314579963684
Validation loss: 2.1546074549357095

Epoch: 6| Step: 7
Training loss: 0.5279923677444458
Validation loss: 2.0814544955889382

Epoch: 6| Step: 8
Training loss: 0.2138213813304901
Validation loss: 2.127469817797343

Epoch: 6| Step: 9
Training loss: 0.28434526920318604
Validation loss: 2.1028585036595664

Epoch: 6| Step: 10
Training loss: 0.2939491868019104
Validation loss: 2.1273440519968667

Epoch: 6| Step: 11
Training loss: 0.7603112459182739
Validation loss: 2.1356399854024253

Epoch: 6| Step: 12
Training loss: 0.20286345481872559
Validation loss: 2.1244335174560547

Epoch: 6| Step: 13
Training loss: 0.2909277677536011
Validation loss: 2.051811635494232

Epoch: 295| Step: 0
Training loss: 0.2223629355430603
Validation loss: 2.1036251982053122

Epoch: 6| Step: 1
Training loss: 0.833726167678833
Validation loss: 2.117739220460256

Epoch: 6| Step: 2
Training loss: 0.37517058849334717
Validation loss: 2.0861720641454062

Epoch: 6| Step: 3
Training loss: 0.6232410669326782
Validation loss: 2.082713484764099

Epoch: 6| Step: 4
Training loss: 0.38472628593444824
Validation loss: 2.0717331568400064

Epoch: 6| Step: 5
Training loss: 0.23369811475276947
Validation loss: 2.0735033750534058

Epoch: 6| Step: 6
Training loss: 0.32100558280944824
Validation loss: 2.101238568623861

Epoch: 6| Step: 7
Training loss: 0.3644181489944458
Validation loss: 2.13309915860494

Epoch: 6| Step: 8
Training loss: 0.5323442220687866
Validation loss: 2.1143826444943747

Epoch: 6| Step: 9
Training loss: 0.33498668670654297
Validation loss: 2.090471386909485

Epoch: 6| Step: 10
Training loss: 0.4536338448524475
Validation loss: 2.107389589150747

Epoch: 6| Step: 11
Training loss: 0.261649489402771
Validation loss: 2.0588683088620505

Epoch: 6| Step: 12
Training loss: 0.40031448006629944
Validation loss: 2.066019515196482

Epoch: 6| Step: 13
Training loss: 0.3285198211669922
Validation loss: 2.0728593667348227

Epoch: 296| Step: 0
Training loss: 0.23497894406318665
Validation loss: 2.0863108237584433

Epoch: 6| Step: 1
Training loss: 0.3765888214111328
Validation loss: 2.0552794138590493

Epoch: 6| Step: 2
Training loss: 0.3154405355453491
Validation loss: 2.114857534567515

Epoch: 6| Step: 3
Training loss: 0.2865644693374634
Validation loss: 2.07331774632136

Epoch: 6| Step: 4
Training loss: 0.6630986928939819
Validation loss: 2.0840481917063394

Epoch: 6| Step: 5
Training loss: 0.3723260760307312
Validation loss: 2.1296724875768027

Epoch: 6| Step: 6
Training loss: 0.23445653915405273
Validation loss: 2.1133603851000466

Epoch: 6| Step: 7
Training loss: 0.42555734515190125
Validation loss: 2.0901535948117576

Epoch: 6| Step: 8
Training loss: 0.21378359198570251
Validation loss: 2.0788016517957053

Epoch: 6| Step: 9
Training loss: 0.22181615233421326
Validation loss: 2.060091574986776

Epoch: 6| Step: 10
Training loss: 0.2691410183906555
Validation loss: 2.097416897614797

Epoch: 6| Step: 11
Training loss: 0.24098649621009827
Validation loss: 2.053996741771698

Epoch: 6| Step: 12
Training loss: 0.3179847002029419
Validation loss: 2.0786463220914206

Epoch: 6| Step: 13
Training loss: 0.3433097004890442
Validation loss: 2.109220882256826

Epoch: 297| Step: 0
Training loss: 0.25465959310531616
Validation loss: 2.0708941221237183

Epoch: 6| Step: 1
Training loss: 0.15682122111320496
Validation loss: 2.057595352331797

Epoch: 6| Step: 2
Training loss: 0.32263970375061035
Validation loss: 2.0836640199025473

Epoch: 6| Step: 3
Training loss: 0.6423879861831665
Validation loss: 2.0475549499193826

Epoch: 6| Step: 4
Training loss: 0.25315409898757935
Validation loss: 2.11027721563975

Epoch: 6| Step: 5
Training loss: 0.4901452958583832
Validation loss: 2.081794857978821

Epoch: 6| Step: 6
Training loss: 0.30560943484306335
Validation loss: 2.1103821794191995

Epoch: 6| Step: 7
Training loss: 0.3284865617752075
Validation loss: 2.1206169923146567

Epoch: 6| Step: 8
Training loss: 0.21289442479610443
Validation loss: 2.1115206480026245

Epoch: 6| Step: 9
Training loss: 0.27493226528167725
Validation loss: 2.1150709986686707

Epoch: 6| Step: 10
Training loss: 0.24338515102863312
Validation loss: 2.0725942850112915

Epoch: 6| Step: 11
Training loss: 0.29080212116241455
Validation loss: 2.1551976998647056

Epoch: 6| Step: 12
Training loss: 0.43527287244796753
Validation loss: 2.0989399751027427

Epoch: 6| Step: 13
Training loss: 0.2434958517551422
Validation loss: 2.090185602506002

Epoch: 298| Step: 0
Training loss: 0.3658369779586792
Validation loss: 2.0875356793403625

Epoch: 6| Step: 1
Training loss: 0.2554479241371155
Validation loss: 2.1122716466585794

Epoch: 6| Step: 2
Training loss: 0.14004065096378326
Validation loss: 2.08662748336792

Epoch: 6| Step: 3
Training loss: 0.19208666682243347
Validation loss: 2.0718528827031455

Epoch: 6| Step: 4
Training loss: 0.3991599678993225
Validation loss: 2.069428543249766

Epoch: 6| Step: 5
Training loss: 0.19233377277851105
Validation loss: 2.108950972557068

Epoch: 6| Step: 6
Training loss: 0.8117163181304932
Validation loss: 2.0797089338302612

Epoch: 6| Step: 7
Training loss: 0.3426729738712311
Validation loss: 2.0813443660736084

Epoch: 6| Step: 8
Training loss: 0.20426525175571442
Validation loss: 2.117220421632131

Epoch: 6| Step: 9
Training loss: 0.21556419134140015
Validation loss: 2.0857221285502114

Epoch: 6| Step: 10
Training loss: 0.33577072620391846
Validation loss: 2.123846093813578

Epoch: 6| Step: 11
Training loss: 0.38690465688705444
Validation loss: 2.079953193664551

Epoch: 6| Step: 12
Training loss: 0.2751406133174896
Validation loss: 2.0787814259529114

Epoch: 6| Step: 13
Training loss: 0.24853959679603577
Validation loss: 2.084379037221273

Epoch: 299| Step: 0
Training loss: 0.24390913546085358
Validation loss: 2.0888670484224954

Epoch: 6| Step: 1
Training loss: 0.3844313621520996
Validation loss: 2.0579505364100137

Epoch: 6| Step: 2
Training loss: 0.49133092164993286
Validation loss: 2.0856948494911194

Epoch: 6| Step: 3
Training loss: 0.4278664290904999
Validation loss: 2.066710611184438

Epoch: 6| Step: 4
Training loss: 0.22966423630714417
Validation loss: 2.0791815916697183

Epoch: 6| Step: 5
Training loss: 0.36840689182281494
Validation loss: 2.0959355235099792

Epoch: 6| Step: 6
Training loss: 0.22891540825366974
Validation loss: 2.0947914520899453

Epoch: 6| Step: 7
Training loss: 0.2254716455936432
Validation loss: 2.0688955982526145

Epoch: 6| Step: 8
Training loss: 0.5556731820106506
Validation loss: 2.0548832615216575

Epoch: 6| Step: 9
Training loss: 0.332236647605896
Validation loss: 2.0463778972625732

Epoch: 6| Step: 10
Training loss: 0.18297411501407623
Validation loss: 2.085287789503733

Epoch: 6| Step: 11
Training loss: 0.4089743494987488
Validation loss: 2.1007160345713296

Epoch: 6| Step: 12
Training loss: 0.2872936725616455
Validation loss: 2.0319411555926004

Epoch: 6| Step: 13
Training loss: 0.2270888090133667
Validation loss: 2.0569450656572976

Epoch: 300| Step: 0
Training loss: 0.2553129196166992
Validation loss: 2.107549786567688

Epoch: 6| Step: 1
Training loss: 0.29693931341171265
Validation loss: 2.155295252799988

Epoch: 6| Step: 2
Training loss: 0.2512691617012024
Validation loss: 2.1081876357396445

Epoch: 6| Step: 3
Training loss: 0.4433627724647522
Validation loss: 2.1386969288190207

Epoch: 6| Step: 4
Training loss: 0.47020891308784485
Validation loss: 2.051366945107778

Epoch: 6| Step: 5
Training loss: 0.6695328950881958
Validation loss: 2.094296137491862

Epoch: 6| Step: 6
Training loss: 0.2615257501602173
Validation loss: 2.005666673183441

Epoch: 6| Step: 7
Training loss: 0.4568522572517395
Validation loss: 2.0348345041275024

Epoch: 6| Step: 8
Training loss: 0.35172757506370544
Validation loss: 2.1001728574434915

Epoch: 6| Step: 9
Training loss: 0.3718717396259308
Validation loss: 2.0989376107851663

Epoch: 6| Step: 10
Training loss: 0.46363598108291626
Validation loss: 2.045978625615438

Epoch: 6| Step: 11
Training loss: 0.20994463562965393
Validation loss: 2.092344363530477

Epoch: 6| Step: 12
Training loss: 0.2532338500022888
Validation loss: 2.10681281487147

Epoch: 6| Step: 13
Training loss: 0.5040846467018127
Validation loss: 2.1311360398928323

Epoch: 301| Step: 0
Training loss: 0.3223084807395935
Validation loss: 2.1137238343556723

Epoch: 6| Step: 1
Training loss: 0.403339684009552
Validation loss: 2.068443536758423

Epoch: 6| Step: 2
Training loss: 0.22168612480163574
Validation loss: 2.0107504526774087

Epoch: 6| Step: 3
Training loss: 0.2424674779176712
Validation loss: 2.054880758126577

Epoch: 6| Step: 4
Training loss: 0.36908984184265137
Validation loss: 2.024376630783081

Epoch: 6| Step: 5
Training loss: 0.18978261947631836
Validation loss: 2.0638750394185386

Epoch: 6| Step: 6
Training loss: 0.3326570987701416
Validation loss: 2.075136204560598

Epoch: 6| Step: 7
Training loss: 0.24991092085838318
Validation loss: 2.0585145950317383

Epoch: 6| Step: 8
Training loss: 0.8209267854690552
Validation loss: 2.0839810967445374

Epoch: 6| Step: 9
Training loss: 0.45487692952156067
Validation loss: 2.1037721832593284

Epoch: 6| Step: 10
Training loss: 0.5229319334030151
Validation loss: 2.102476497491201

Epoch: 6| Step: 11
Training loss: 0.36734670400619507
Validation loss: 2.1140938997268677

Epoch: 6| Step: 12
Training loss: 0.16265113651752472
Validation loss: 2.10341876745224

Epoch: 6| Step: 13
Training loss: 0.2526529133319855
Validation loss: 2.075579285621643

Epoch: 302| Step: 0
Training loss: 0.23437896370887756
Validation loss: 2.0610727270444236

Epoch: 6| Step: 1
Training loss: 0.35914427042007446
Validation loss: 2.0497196316719055

Epoch: 6| Step: 2
Training loss: 0.43013110756874084
Validation loss: 2.09032412370046

Epoch: 6| Step: 3
Training loss: 0.3554164171218872
Validation loss: 2.0872385700543723

Epoch: 6| Step: 4
Training loss: 0.28132373094558716
Validation loss: 2.070094366868337

Epoch: 6| Step: 5
Training loss: 0.38260990381240845
Validation loss: 2.0547812779744468

Epoch: 6| Step: 6
Training loss: 0.34550732374191284
Validation loss: 2.0532108346621194

Epoch: 6| Step: 7
Training loss: 0.1533094048500061
Validation loss: 2.0843416849772134

Epoch: 6| Step: 8
Training loss: 0.20682178437709808
Validation loss: 2.081003487110138

Epoch: 6| Step: 9
Training loss: 0.3855160176753998
Validation loss: 2.1090994675954184

Epoch: 6| Step: 10
Training loss: 0.339266300201416
Validation loss: 2.0643927852312722

Epoch: 6| Step: 11
Training loss: 0.5542764067649841
Validation loss: 2.0641987919807434

Epoch: 6| Step: 12
Training loss: 0.1543111801147461
Validation loss: 2.027063727378845

Epoch: 6| Step: 13
Training loss: 0.26396453380584717
Validation loss: 2.1176674564679465

Epoch: 303| Step: 0
Training loss: 0.18073666095733643
Validation loss: 2.048873702685038

Epoch: 6| Step: 1
Training loss: 0.18285727500915527
Validation loss: 2.0697704752286277

Epoch: 6| Step: 2
Training loss: 0.9063538312911987
Validation loss: 2.076740086078644

Epoch: 6| Step: 3
Training loss: 0.3607492446899414
Validation loss: 2.0499062736829123

Epoch: 6| Step: 4
Training loss: 0.33810803294181824
Validation loss: 2.073097825050354

Epoch: 6| Step: 5
Training loss: 0.25295567512512207
Validation loss: 2.0965853333473206

Epoch: 6| Step: 6
Training loss: 0.2790369391441345
Validation loss: 2.0898738503456116

Epoch: 6| Step: 7
Training loss: 0.13484808802604675
Validation loss: 2.0364447633425393

Epoch: 6| Step: 8
Training loss: 0.38277411460876465
Validation loss: 2.0481666127840676

Epoch: 6| Step: 9
Training loss: 0.26315736770629883
Validation loss: 2.0193604032198587

Epoch: 6| Step: 10
Training loss: 0.2539803683757782
Validation loss: 2.130936781565348

Epoch: 6| Step: 11
Training loss: 0.25758370757102966
Validation loss: 2.102350115776062

Epoch: 6| Step: 12
Training loss: 0.5073185563087463
Validation loss: 2.1543028752009072

Epoch: 6| Step: 13
Training loss: 0.2613956332206726
Validation loss: 2.0851197640101113

Epoch: 304| Step: 0
Training loss: 0.8237351179122925
Validation loss: 2.0486605962117515

Epoch: 6| Step: 1
Training loss: 0.2274009734392166
Validation loss: 2.078284660975138

Epoch: 6| Step: 2
Training loss: 0.17918884754180908
Validation loss: 2.0992236733436584

Epoch: 6| Step: 3
Training loss: 0.32179543375968933
Validation loss: 2.0437527298927307

Epoch: 6| Step: 4
Training loss: 0.26809677481651306
Validation loss: 2.0058613816897073

Epoch: 6| Step: 5
Training loss: 0.2202514410018921
Validation loss: 2.063934326171875

Epoch: 6| Step: 6
Training loss: 0.26996904611587524
Validation loss: 2.0461689035097756

Epoch: 6| Step: 7
Training loss: 0.3611494302749634
Validation loss: 2.0632994771003723

Epoch: 6| Step: 8
Training loss: 0.24588808417320251
Validation loss: 2.079804023106893

Epoch: 6| Step: 9
Training loss: 0.2529251277446747
Validation loss: 2.0714218815167746

Epoch: 6| Step: 10
Training loss: 0.4901415705680847
Validation loss: 2.089500308036804

Epoch: 6| Step: 11
Training loss: 0.4277454614639282
Validation loss: 2.0869439244270325

Epoch: 6| Step: 12
Training loss: 0.4224737286567688
Validation loss: 2.0776137312253318

Epoch: 6| Step: 13
Training loss: 0.42019665241241455
Validation loss: 2.080282151699066

Epoch: 305| Step: 0
Training loss: 0.2003677785396576
Validation loss: 2.0482343832651773

Epoch: 6| Step: 1
Training loss: 0.1923537701368332
Validation loss: 2.064296245574951

Epoch: 6| Step: 2
Training loss: 0.3726724088191986
Validation loss: 2.0327135125796

Epoch: 6| Step: 3
Training loss: 0.21823547780513763
Validation loss: 2.03674578666687

Epoch: 6| Step: 4
Training loss: 0.3914605379104614
Validation loss: 2.041657308737437

Epoch: 6| Step: 5
Training loss: 0.36147749423980713
Validation loss: 2.045971234639486

Epoch: 6| Step: 6
Training loss: 0.7072903513908386
Validation loss: 2.0541058580080667

Epoch: 6| Step: 7
Training loss: 0.2363690286874771
Validation loss: 2.0836756030718484

Epoch: 6| Step: 8
Training loss: 0.38921716809272766
Validation loss: 2.1243726015090942

Epoch: 6| Step: 9
Training loss: 0.32418256998062134
Validation loss: 2.0097447633743286

Epoch: 6| Step: 10
Training loss: 0.43978381156921387
Validation loss: 2.0643831690152488

Epoch: 6| Step: 11
Training loss: 0.36530786752700806
Validation loss: 2.077351907889048

Epoch: 6| Step: 12
Training loss: 0.3192752003669739
Validation loss: 2.096808910369873

Epoch: 6| Step: 13
Training loss: 0.403361439704895
Validation loss: 2.0756230552991233

Epoch: 306| Step: 0
Training loss: 0.5315982699394226
Validation loss: 2.0876054167747498

Epoch: 6| Step: 1
Training loss: 0.3393826484680176
Validation loss: 2.073623855908712

Epoch: 6| Step: 2
Training loss: 0.29122576117515564
Validation loss: 2.0808021227518716

Epoch: 6| Step: 3
Training loss: 0.48306354880332947
Validation loss: 2.0470676819483438

Epoch: 6| Step: 4
Training loss: 0.22249677777290344
Validation loss: 2.1086280941963196

Epoch: 6| Step: 5
Training loss: 0.23715709149837494
Validation loss: 2.1203335523605347

Epoch: 6| Step: 6
Training loss: 0.41486549377441406
Validation loss: 2.095588485399882

Epoch: 6| Step: 7
Training loss: 0.5144108533859253
Validation loss: 2.122550984223684

Epoch: 6| Step: 8
Training loss: 0.38895851373672485
Validation loss: 2.06715327501297

Epoch: 6| Step: 9
Training loss: 0.3791150152683258
Validation loss: 2.071907619635264

Epoch: 6| Step: 10
Training loss: 0.2194715142250061
Validation loss: 2.129203955332438

Epoch: 6| Step: 11
Training loss: 0.1861851066350937
Validation loss: 2.083441694577535

Epoch: 6| Step: 12
Training loss: 0.23687924444675446
Validation loss: 2.047433833281199

Epoch: 6| Step: 13
Training loss: 0.7139970660209656
Validation loss: 2.0617856979370117

Epoch: 307| Step: 0
Training loss: 0.6048560738563538
Validation loss: 2.0644995967547097

Epoch: 6| Step: 1
Training loss: 0.15933987498283386
Validation loss: 2.0607334971427917

Epoch: 6| Step: 2
Training loss: 0.24335047602653503
Validation loss: 2.0860083301862082

Epoch: 6| Step: 3
Training loss: 0.2544558346271515
Validation loss: 2.053863803545634

Epoch: 6| Step: 4
Training loss: 0.308405339717865
Validation loss: 2.0941495100657144

Epoch: 6| Step: 5
Training loss: 0.18081413209438324
Validation loss: 2.038903594017029

Epoch: 6| Step: 6
Training loss: 0.22594280540943146
Validation loss: 2.02314031124115

Epoch: 6| Step: 7
Training loss: 0.2669774889945984
Validation loss: 2.050459563732147

Epoch: 6| Step: 8
Training loss: 0.3060400187969208
Validation loss: 2.0688363114992776

Epoch: 6| Step: 9
Training loss: 0.23088563978672028
Validation loss: 2.088108718395233

Epoch: 6| Step: 10
Training loss: 0.3941938877105713
Validation loss: 2.0898998181025186

Epoch: 6| Step: 11
Training loss: 0.7030050754547119
Validation loss: 2.094621459643046

Epoch: 6| Step: 12
Training loss: 0.29831662774086
Validation loss: 2.0943713386853537

Epoch: 6| Step: 13
Training loss: 0.24570614099502563
Validation loss: 2.0806304216384888

Epoch: 308| Step: 0
Training loss: 0.20845836400985718
Validation loss: 2.0648694038391113

Epoch: 6| Step: 1
Training loss: 0.5827921032905579
Validation loss: 2.048857589562734

Epoch: 6| Step: 2
Training loss: 0.16446727514266968
Validation loss: 2.0882477362950644

Epoch: 6| Step: 3
Training loss: 0.21307244896888733
Validation loss: 2.076871951421102

Epoch: 6| Step: 4
Training loss: 0.179872065782547
Validation loss: 2.1306740840276084

Epoch: 6| Step: 5
Training loss: 0.46349573135375977
Validation loss: 2.1289058128992715

Epoch: 6| Step: 6
Training loss: 0.41160884499549866
Validation loss: 2.088221629460653

Epoch: 6| Step: 7
Training loss: 0.18787840008735657
Validation loss: 2.1047505935033164

Epoch: 6| Step: 8
Training loss: 0.2847176194190979
Validation loss: 2.0674721201260886

Epoch: 6| Step: 9
Training loss: 0.4334092140197754
Validation loss: 2.059551258881887

Epoch: 6| Step: 10
Training loss: 0.2691119313240051
Validation loss: 2.071096102396647

Epoch: 6| Step: 11
Training loss: 0.21914012730121613
Validation loss: 2.0818472504615784

Epoch: 6| Step: 12
Training loss: 0.2861008644104004
Validation loss: 2.0831400752067566

Epoch: 6| Step: 13
Training loss: 0.25789159536361694
Validation loss: 2.100809951623281

Epoch: 309| Step: 0
Training loss: 0.2965984344482422
Validation loss: 2.066661854585012

Epoch: 6| Step: 1
Training loss: 0.289770245552063
Validation loss: 2.0475456515947976

Epoch: 6| Step: 2
Training loss: 0.38293296098709106
Validation loss: 2.0567176938056946

Epoch: 6| Step: 3
Training loss: 0.28844988346099854
Validation loss: 2.0695107777913413

Epoch: 6| Step: 4
Training loss: 0.4247516095638275
Validation loss: 2.104198614756266

Epoch: 6| Step: 5
Training loss: 0.19415828585624695
Validation loss: 2.0954647858937583

Epoch: 6| Step: 6
Training loss: 0.2474619746208191
Validation loss: 2.080369472503662

Epoch: 6| Step: 7
Training loss: 0.28233450651168823
Validation loss: 2.0494635701179504

Epoch: 6| Step: 8
Training loss: 0.8292393684387207
Validation loss: 2.0636303623517356

Epoch: 6| Step: 9
Training loss: 0.31359514594078064
Validation loss: 2.0996354023615518

Epoch: 6| Step: 10
Training loss: 0.23308494687080383
Validation loss: 2.0562438368797302

Epoch: 6| Step: 11
Training loss: 0.2791904807090759
Validation loss: 2.0339633027712503

Epoch: 6| Step: 12
Training loss: 0.2749198079109192
Validation loss: 2.0769287745157876

Epoch: 6| Step: 13
Training loss: 0.1740715354681015
Validation loss: 2.0695816477139792

Epoch: 310| Step: 0
Training loss: 0.2769719362258911
Validation loss: 2.1021834214528403

Epoch: 6| Step: 1
Training loss: 0.4313421845436096
Validation loss: 2.1391406257947287

Epoch: 6| Step: 2
Training loss: 0.49130088090896606
Validation loss: 2.087010681629181

Epoch: 6| Step: 3
Training loss: 0.3878338932991028
Validation loss: 2.1286955873171487

Epoch: 6| Step: 4
Training loss: 0.25715842843055725
Validation loss: 2.109171748161316

Epoch: 6| Step: 5
Training loss: 0.2491188943386078
Validation loss: 2.0627799034118652

Epoch: 6| Step: 6
Training loss: 0.23155349493026733
Validation loss: 2.052475889523824

Epoch: 6| Step: 7
Training loss: 0.16099490225315094
Validation loss: 2.0971639156341553

Epoch: 6| Step: 8
Training loss: 0.3650261163711548
Validation loss: 2.0737995505332947

Epoch: 6| Step: 9
Training loss: 0.6114771366119385
Validation loss: 2.0732260743776956

Epoch: 6| Step: 10
Training loss: 0.22908565402030945
Validation loss: 2.1132752696673074

Epoch: 6| Step: 11
Training loss: 0.2531657814979553
Validation loss: 2.091350515683492

Epoch: 6| Step: 12
Training loss: 0.3331419825553894
Validation loss: 2.046523372332255

Epoch: 6| Step: 13
Training loss: 0.23974482715129852
Validation loss: 2.1023300091425576

Epoch: 311| Step: 0
Training loss: 0.24832671880722046
Validation loss: 2.0996551513671875

Epoch: 6| Step: 1
Training loss: 0.2718544900417328
Validation loss: 2.1222512125968933

Epoch: 6| Step: 2
Training loss: 0.3649905323982239
Validation loss: 2.0870456298192344

Epoch: 6| Step: 3
Training loss: 0.2818889617919922
Validation loss: 2.073023537794749

Epoch: 6| Step: 4
Training loss: 0.22815607488155365
Validation loss: 2.0748055378595986

Epoch: 6| Step: 5
Training loss: 0.2735854983329773
Validation loss: 2.0497172474861145

Epoch: 6| Step: 6
Training loss: 0.5834600925445557
Validation loss: 2.0732773542404175

Epoch: 6| Step: 7
Training loss: 0.2866062521934509
Validation loss: 2.0373157262802124

Epoch: 6| Step: 8
Training loss: 0.39273446798324585
Validation loss: 2.1296870708465576

Epoch: 6| Step: 9
Training loss: 0.7143638730049133
Validation loss: 2.088385899861654

Epoch: 6| Step: 10
Training loss: 0.17866459488868713
Validation loss: 2.03865251938502

Epoch: 6| Step: 11
Training loss: 0.44825926423072815
Validation loss: 2.101217806339264

Epoch: 6| Step: 12
Training loss: 0.33369046449661255
Validation loss: 2.0880884726842246

Epoch: 6| Step: 13
Training loss: 0.2486785501241684
Validation loss: 2.095355530579885

Epoch: 312| Step: 0
Training loss: 0.2704778015613556
Validation loss: 2.1036940018335977

Epoch: 6| Step: 1
Training loss: 0.288646399974823
Validation loss: 2.085806131362915

Epoch: 6| Step: 2
Training loss: 0.127649188041687
Validation loss: 2.1023829181989035

Epoch: 6| Step: 3
Training loss: 0.38545945286750793
Validation loss: 2.0675785740216575

Epoch: 6| Step: 4
Training loss: 0.4153452217578888
Validation loss: 2.0540050864219666

Epoch: 6| Step: 5
Training loss: 0.30117323994636536
Validation loss: 2.071472783883413

Epoch: 6| Step: 6
Training loss: 0.3005361557006836
Validation loss: 2.0300758282343545

Epoch: 6| Step: 7
Training loss: 0.271114319562912
Validation loss: 2.0598182479540506

Epoch: 6| Step: 8
Training loss: 0.507201611995697
Validation loss: 2.078766167163849

Epoch: 6| Step: 9
Training loss: 0.8627926111221313
Validation loss: 2.0907739798227944

Epoch: 6| Step: 10
Training loss: 0.44622287154197693
Validation loss: 2.1484227577845254

Epoch: 6| Step: 11
Training loss: 0.33881640434265137
Validation loss: 2.1167914668718972

Epoch: 6| Step: 12
Training loss: 0.348673015832901
Validation loss: 2.090770939985911

Epoch: 6| Step: 13
Training loss: 0.21458032727241516
Validation loss: 2.056584099928538

Epoch: 313| Step: 0
Training loss: 0.3615615963935852
Validation loss: 2.0612577199935913

Epoch: 6| Step: 1
Training loss: 0.7138757705688477
Validation loss: 2.0735742449760437

Epoch: 6| Step: 2
Training loss: 0.33990296721458435
Validation loss: 2.065497855345408

Epoch: 6| Step: 3
Training loss: 0.35058093070983887
Validation loss: 2.0839974085489907

Epoch: 6| Step: 4
Training loss: 0.35252195596694946
Validation loss: 2.0906267960866294

Epoch: 6| Step: 5
Training loss: 0.2466617226600647
Validation loss: 2.093785564104716

Epoch: 6| Step: 6
Training loss: 0.29752659797668457
Validation loss: 2.142863949139913

Epoch: 6| Step: 7
Training loss: 0.364436537027359
Validation loss: 2.097037672996521

Epoch: 6| Step: 8
Training loss: 0.4132571220397949
Validation loss: 2.104460299015045

Epoch: 6| Step: 9
Training loss: 0.3375746011734009
Validation loss: 2.0867705742518106

Epoch: 6| Step: 10
Training loss: 0.33052152395248413
Validation loss: 2.1125304897626243

Epoch: 6| Step: 11
Training loss: 0.34470632672309875
Validation loss: 2.099562148253123

Epoch: 6| Step: 12
Training loss: 0.34097954630851746
Validation loss: 2.104997913042704

Epoch: 6| Step: 13
Training loss: 0.2663807272911072
Validation loss: 2.0849785208702087

Epoch: 314| Step: 0
Training loss: 0.6416068077087402
Validation loss: 2.0449018081029258

Epoch: 6| Step: 1
Training loss: 0.22789549827575684
Validation loss: 2.078483740488688

Epoch: 6| Step: 2
Training loss: 0.18671542406082153
Validation loss: 2.06995681921641

Epoch: 6| Step: 3
Training loss: 0.23525045812129974
Validation loss: 2.089192191759745

Epoch: 6| Step: 4
Training loss: 0.20620447397232056
Validation loss: 2.1273010770479837

Epoch: 6| Step: 5
Training loss: 0.22820770740509033
Validation loss: 2.092264195283254

Epoch: 6| Step: 6
Training loss: 0.27052175998687744
Validation loss: 2.0674587289492288

Epoch: 6| Step: 7
Training loss: 0.1652042269706726
Validation loss: 2.0725716948509216

Epoch: 6| Step: 8
Training loss: 0.14158831536769867
Validation loss: 2.0778454343477883

Epoch: 6| Step: 9
Training loss: 0.34272170066833496
Validation loss: 2.095183034737905

Epoch: 6| Step: 10
Training loss: 0.5485619306564331
Validation loss: 2.0927891929944358

Epoch: 6| Step: 11
Training loss: 0.2055453211069107
Validation loss: 2.0790597796440125

Epoch: 6| Step: 12
Training loss: 0.5582399368286133
Validation loss: 2.0499366521835327

Epoch: 6| Step: 13
Training loss: 0.34438732266426086
Validation loss: 2.0844905972480774

Epoch: 315| Step: 0
Training loss: 0.2051117718219757
Validation loss: 2.0470288395881653

Epoch: 6| Step: 1
Training loss: 0.27687910199165344
Validation loss: 2.0849860111872354

Epoch: 6| Step: 2
Training loss: 0.2532939910888672
Validation loss: 2.071343024571737

Epoch: 6| Step: 3
Training loss: 0.33464235067367554
Validation loss: 2.076945185661316

Epoch: 6| Step: 4
Training loss: 0.26063355803489685
Validation loss: 2.092002809047699

Epoch: 6| Step: 5
Training loss: 0.2333602011203766
Validation loss: 2.0891048908233643

Epoch: 6| Step: 6
Training loss: 0.33046525716781616
Validation loss: 2.104905903339386

Epoch: 6| Step: 7
Training loss: 0.5210805535316467
Validation loss: 2.107496360937754

Epoch: 6| Step: 8
Training loss: 0.6057724952697754
Validation loss: 2.1057306130727134

Epoch: 6| Step: 9
Training loss: 0.2504986524581909
Validation loss: 2.068743268648783

Epoch: 6| Step: 10
Training loss: 0.349551796913147
Validation loss: 2.0513161023457847

Epoch: 6| Step: 11
Training loss: 0.2278658151626587
Validation loss: 2.084887742996216

Epoch: 6| Step: 12
Training loss: 0.20993879437446594
Validation loss: 2.1013554533322654

Epoch: 6| Step: 13
Training loss: 0.46775883436203003
Validation loss: 2.0749314030011496

Epoch: 316| Step: 0
Training loss: 0.2848992347717285
Validation loss: 2.0721795558929443

Epoch: 6| Step: 1
Training loss: 0.3144279718399048
Validation loss: 2.0877739985783896

Epoch: 6| Step: 2
Training loss: 0.30398300290107727
Validation loss: 2.087671081225077

Epoch: 6| Step: 3
Training loss: 0.4247247874736786
Validation loss: 2.0615042050679526

Epoch: 6| Step: 4
Training loss: 0.34772050380706787
Validation loss: 2.1024760603904724

Epoch: 6| Step: 5
Training loss: 0.467385858297348
Validation loss: 2.0619763930638633

Epoch: 6| Step: 6
Training loss: 0.2353922724723816
Validation loss: 2.0652701258659363

Epoch: 6| Step: 7
Training loss: 0.1881539523601532
Validation loss: 2.0444973707199097

Epoch: 6| Step: 8
Training loss: 0.610262393951416
Validation loss: 2.0952439109484353

Epoch: 6| Step: 9
Training loss: 0.21582689881324768
Validation loss: 2.074305852254232

Epoch: 6| Step: 10
Training loss: 0.2637478709220886
Validation loss: 2.0748023986816406

Epoch: 6| Step: 11
Training loss: 0.22517703473567963
Validation loss: 2.0630311171213784

Epoch: 6| Step: 12
Training loss: 0.27032315731048584
Validation loss: 2.0653164386749268

Epoch: 6| Step: 13
Training loss: 0.2575608789920807
Validation loss: 2.0421456495920816

Epoch: 317| Step: 0
Training loss: 0.14730586111545563
Validation loss: 2.1301346023877463

Epoch: 6| Step: 1
Training loss: 0.2321634143590927
Validation loss: 2.1174828807512918

Epoch: 6| Step: 2
Training loss: 0.3485586643218994
Validation loss: 2.098022739092509

Epoch: 6| Step: 3
Training loss: 0.2698451280593872
Validation loss: 2.1495582660039267

Epoch: 6| Step: 4
Training loss: 0.2837103605270386
Validation loss: 2.078768809636434

Epoch: 6| Step: 5
Training loss: 0.4409467279911041
Validation loss: 2.1176265875498452

Epoch: 6| Step: 6
Training loss: 0.23231354355812073
Validation loss: 2.101682960987091

Epoch: 6| Step: 7
Training loss: 0.21848565340042114
Validation loss: 2.023959994316101

Epoch: 6| Step: 8
Training loss: 0.630817174911499
Validation loss: 2.018805464108785

Epoch: 6| Step: 9
Training loss: 0.4499755799770355
Validation loss: 2.0563507874806723

Epoch: 6| Step: 10
Training loss: 0.339129239320755
Validation loss: 2.0665311217308044

Epoch: 6| Step: 11
Training loss: 0.2430981695652008
Validation loss: 2.0717550913492837

Epoch: 6| Step: 12
Training loss: 0.19023948907852173
Validation loss: 2.0944201350212097

Epoch: 6| Step: 13
Training loss: 0.40555912256240845
Validation loss: 2.094776133696238

Epoch: 318| Step: 0
Training loss: 0.41916364431381226
Validation loss: 2.0730707248051963

Epoch: 6| Step: 1
Training loss: 0.42340248823165894
Validation loss: 2.080257534980774

Epoch: 6| Step: 2
Training loss: 0.4199685752391815
Validation loss: 2.047752877076467

Epoch: 6| Step: 3
Training loss: 0.2935815751552582
Validation loss: 2.0252557595570884

Epoch: 6| Step: 4
Training loss: 0.33876529335975647
Validation loss: 2.033985654513041

Epoch: 6| Step: 5
Training loss: 0.3473275601863861
Validation loss: 2.031813462575277

Epoch: 6| Step: 6
Training loss: 0.4389004707336426
Validation loss: 2.0574368437131247

Epoch: 6| Step: 7
Training loss: 0.6195398569107056
Validation loss: 2.0192232926686606

Epoch: 6| Step: 8
Training loss: 0.31751585006713867
Validation loss: 2.119515061378479

Epoch: 6| Step: 9
Training loss: 0.20924179255962372
Validation loss: 2.0732497374216714

Epoch: 6| Step: 10
Training loss: 0.2101544737815857
Validation loss: 2.087437629699707

Epoch: 6| Step: 11
Training loss: 0.4205995202064514
Validation loss: 2.042953928311666

Epoch: 6| Step: 12
Training loss: 0.21938562393188477
Validation loss: 2.089323341846466

Epoch: 6| Step: 13
Training loss: 0.29496657848358154
Validation loss: 2.063760260740916

Epoch: 319| Step: 0
Training loss: 0.37331169843673706
Validation loss: 2.0739042162895203

Epoch: 6| Step: 1
Training loss: 0.1641419231891632
Validation loss: 2.0728939374287925

Epoch: 6| Step: 2
Training loss: 0.24778039753437042
Validation loss: 2.0808145006497702

Epoch: 6| Step: 3
Training loss: 0.6858745217323303
Validation loss: 2.09863289197286

Epoch: 6| Step: 4
Training loss: 0.22350749373435974
Validation loss: 2.073501467704773

Epoch: 6| Step: 5
Training loss: 0.2044343203306198
Validation loss: 2.0994513034820557

Epoch: 6| Step: 6
Training loss: 0.3498912453651428
Validation loss: 2.090388039747874

Epoch: 6| Step: 7
Training loss: 0.37873563170433044
Validation loss: 2.081145624319712

Epoch: 6| Step: 8
Training loss: 0.28335827589035034
Validation loss: 2.071312685807546

Epoch: 6| Step: 9
Training loss: 0.28794825077056885
Validation loss: 2.086116890112559

Epoch: 6| Step: 10
Training loss: 0.42461422085762024
Validation loss: 2.0814869006474814

Epoch: 6| Step: 11
Training loss: 0.2441914677619934
Validation loss: 2.080587844053904

Epoch: 6| Step: 12
Training loss: 0.17979952692985535
Validation loss: 2.04721870024999

Epoch: 6| Step: 13
Training loss: 0.19907906651496887
Validation loss: 2.045309046904246

Epoch: 320| Step: 0
Training loss: 0.15836183726787567
Validation loss: 2.06381618976593

Epoch: 6| Step: 1
Training loss: 0.2732498049736023
Validation loss: 2.0861347913742065

Epoch: 6| Step: 2
Training loss: 0.37148022651672363
Validation loss: 2.0752257307370505

Epoch: 6| Step: 3
Training loss: 0.6533834934234619
Validation loss: 2.092302401860555

Epoch: 6| Step: 4
Training loss: 0.2949681878089905
Validation loss: 2.065788964430491

Epoch: 6| Step: 5
Training loss: 0.19995789229869843
Validation loss: 2.0758138298988342

Epoch: 6| Step: 6
Training loss: 0.2061757743358612
Validation loss: 2.0884820421536765

Epoch: 6| Step: 7
Training loss: 0.7068797945976257
Validation loss: 2.0516494512557983

Epoch: 6| Step: 8
Training loss: 0.439686119556427
Validation loss: 2.0298380255699158

Epoch: 6| Step: 9
Training loss: 0.26951366662979126
Validation loss: 2.060031513373057

Epoch: 6| Step: 10
Training loss: 0.17955932021141052
Validation loss: 2.049775322278341

Epoch: 6| Step: 11
Training loss: 0.3344818949699402
Validation loss: 2.058583160241445

Epoch: 6| Step: 12
Training loss: 0.29251158237457275
Validation loss: 2.085678438345591

Epoch: 6| Step: 13
Training loss: 0.37730923295021057
Validation loss: 2.0635733207066855

Epoch: 321| Step: 0
Training loss: 0.42918866872787476
Validation loss: 2.0630000829696655

Epoch: 6| Step: 1
Training loss: 0.5602452754974365
Validation loss: 2.0290241638819375

Epoch: 6| Step: 2
Training loss: 0.21130985021591187
Validation loss: 2.0516323844591775

Epoch: 6| Step: 3
Training loss: 0.3580641746520996
Validation loss: 2.068574289480845

Epoch: 6| Step: 4
Training loss: 0.24763423204421997
Validation loss: 2.09242707490921

Epoch: 6| Step: 5
Training loss: 0.32233959436416626
Validation loss: 2.0226901968320212

Epoch: 6| Step: 6
Training loss: 0.26723307371139526
Validation loss: 2.0539576212565103

Epoch: 6| Step: 7
Training loss: 0.24091356992721558
Validation loss: 2.0739091436068215

Epoch: 6| Step: 8
Training loss: 0.41866379976272583
Validation loss: 2.063401738802592

Epoch: 6| Step: 9
Training loss: 0.20014357566833496
Validation loss: 2.0938741167386374

Epoch: 6| Step: 10
Training loss: 0.3891066014766693
Validation loss: 2.0819486578305564

Epoch: 6| Step: 11
Training loss: 0.6519476771354675
Validation loss: 2.1045968532562256

Epoch: 6| Step: 12
Training loss: 0.24473223090171814
Validation loss: 2.0971450408299765

Epoch: 6| Step: 13
Training loss: 0.1908239871263504
Validation loss: 2.0751119454701743

Epoch: 322| Step: 0
Training loss: 0.3801901340484619
Validation loss: 2.065476397673289

Epoch: 6| Step: 1
Training loss: 0.27531152963638306
Validation loss: 2.05498868227005

Epoch: 6| Step: 2
Training loss: 0.2684555947780609
Validation loss: 2.0923377672831216

Epoch: 6| Step: 3
Training loss: 0.20163871347904205
Validation loss: 2.063252031803131

Epoch: 6| Step: 4
Training loss: 0.7751178741455078
Validation loss: 2.0627697308858237

Epoch: 6| Step: 5
Training loss: 0.28649306297302246
Validation loss: 2.0970203479131064

Epoch: 6| Step: 6
Training loss: 0.312097430229187
Validation loss: 2.113532761732737

Epoch: 6| Step: 7
Training loss: 0.37751203775405884
Validation loss: 2.1076056559880576

Epoch: 6| Step: 8
Training loss: 0.47053593397140503
Validation loss: 2.1416494051615396

Epoch: 6| Step: 9
Training loss: 0.33664318919181824
Validation loss: 2.1083863973617554

Epoch: 6| Step: 10
Training loss: 0.1903986781835556
Validation loss: 2.0712068478266397

Epoch: 6| Step: 11
Training loss: 0.2506139278411865
Validation loss: 2.091987748940786

Epoch: 6| Step: 12
Training loss: 0.27849113941192627
Validation loss: 2.0406810442606607

Epoch: 6| Step: 13
Training loss: 0.39145809412002563
Validation loss: 2.07243283589681

Epoch: 323| Step: 0
Training loss: 0.28652164340019226
Validation loss: 2.0436861316363015

Epoch: 6| Step: 1
Training loss: 0.33865171670913696
Validation loss: 2.0559361577033997

Epoch: 6| Step: 2
Training loss: 0.21167142689228058
Validation loss: 2.0919299125671387

Epoch: 6| Step: 3
Training loss: 0.2040291726589203
Validation loss: 2.092322806517283

Epoch: 6| Step: 4
Training loss: 0.23224318027496338
Validation loss: 2.0758926471074424

Epoch: 6| Step: 5
Training loss: 0.18701709806919098
Validation loss: 2.0893412431081138

Epoch: 6| Step: 6
Training loss: 0.2631540894508362
Validation loss: 2.0720651745796204

Epoch: 6| Step: 7
Training loss: 0.16969691216945648
Validation loss: 2.0888044834136963

Epoch: 6| Step: 8
Training loss: 0.6369324922561646
Validation loss: 2.1100708643595376

Epoch: 6| Step: 9
Training loss: 0.4429106116294861
Validation loss: 2.086000661055247

Epoch: 6| Step: 10
Training loss: 0.15250341594219208
Validation loss: 2.0707395474116006

Epoch: 6| Step: 11
Training loss: 0.3242751359939575
Validation loss: 2.0633555253346763

Epoch: 6| Step: 12
Training loss: 0.3995608985424042
Validation loss: 2.097395141919454

Epoch: 6| Step: 13
Training loss: 0.277710497379303
Validation loss: 2.100145777066549

Epoch: 324| Step: 0
Training loss: 0.6692728996276855
Validation loss: 2.1127624114354453

Epoch: 6| Step: 1
Training loss: 0.2584903836250305
Validation loss: 2.1762468814849854

Epoch: 6| Step: 2
Training loss: 0.35260966420173645
Validation loss: 2.1410050988197327

Epoch: 6| Step: 3
Training loss: 0.3100755214691162
Validation loss: 2.115184406439463

Epoch: 6| Step: 4
Training loss: 0.34826797246932983
Validation loss: 2.1283360520998635

Epoch: 6| Step: 5
Training loss: 0.2921256422996521
Validation loss: 2.108183224995931

Epoch: 6| Step: 6
Training loss: 0.2699957489967346
Validation loss: 2.072681804498037

Epoch: 6| Step: 7
Training loss: 0.26723966002464294
Validation loss: 2.0481573144594827

Epoch: 6| Step: 8
Training loss: 0.2867735028266907
Validation loss: 2.071058690547943

Epoch: 6| Step: 9
Training loss: 0.299477756023407
Validation loss: 2.070202966531118

Epoch: 6| Step: 10
Training loss: 0.19699150323867798
Validation loss: 2.023734927177429

Epoch: 6| Step: 11
Training loss: 0.4339721202850342
Validation loss: 2.0165554881095886

Epoch: 6| Step: 12
Training loss: 0.2762785255908966
Validation loss: 2.0858393708864846

Epoch: 6| Step: 13
Training loss: 0.22634562849998474
Validation loss: 2.04326460758845

Epoch: 325| Step: 0
Training loss: 0.2827495336532593
Validation loss: 2.112551291783651

Epoch: 6| Step: 1
Training loss: 0.3959128260612488
Validation loss: 2.0806501110394797

Epoch: 6| Step: 2
Training loss: 0.47850537300109863
Validation loss: 2.06307715177536

Epoch: 6| Step: 3
Training loss: 0.39932987093925476
Validation loss: 2.076241215070089

Epoch: 6| Step: 4
Training loss: 0.2563473880290985
Validation loss: 2.06835275888443

Epoch: 6| Step: 5
Training loss: 0.21405546367168427
Validation loss: 2.0491979718208313

Epoch: 6| Step: 6
Training loss: 0.3996252715587616
Validation loss: 2.046797235806783

Epoch: 6| Step: 7
Training loss: 0.5026192665100098
Validation loss: 2.045203765233358

Epoch: 6| Step: 8
Training loss: 0.3858039379119873
Validation loss: 2.0286104877789817

Epoch: 6| Step: 9
Training loss: 0.41327357292175293
Validation loss: 2.0095442732175193

Epoch: 6| Step: 10
Training loss: 0.5334892868995667
Validation loss: 2.067480444908142

Epoch: 6| Step: 11
Training loss: 0.2788553833961487
Validation loss: 2.049050788084666

Epoch: 6| Step: 12
Training loss: 0.7389159202575684
Validation loss: 2.0616645216941833

Epoch: 6| Step: 13
Training loss: 0.2106943130493164
Validation loss: 2.1436689694722495

Epoch: 326| Step: 0
Training loss: 0.3122735619544983
Validation loss: 2.125819504261017

Epoch: 6| Step: 1
Training loss: 0.2768256664276123
Validation loss: 2.1319855650266013

Epoch: 6| Step: 2
Training loss: 0.24638037383556366
Validation loss: 2.101295789082845

Epoch: 6| Step: 3
Training loss: 0.39505377411842346
Validation loss: 2.064388712247213

Epoch: 6| Step: 4
Training loss: 0.6341841220855713
Validation loss: 2.1141451597213745

Epoch: 6| Step: 5
Training loss: 0.2259567230939865
Validation loss: 2.06993967294693

Epoch: 6| Step: 6
Training loss: 0.298801064491272
Validation loss: 2.0845678249994912

Epoch: 6| Step: 7
Training loss: 0.31073129177093506
Validation loss: 2.102624694506327

Epoch: 6| Step: 8
Training loss: 0.4334384500980377
Validation loss: 2.066533168156942

Epoch: 6| Step: 9
Training loss: 0.19769003987312317
Validation loss: 2.0765108267466226

Epoch: 6| Step: 10
Training loss: 0.25703734159469604
Validation loss: 2.08721923828125

Epoch: 6| Step: 11
Training loss: 0.24519938230514526
Validation loss: 2.103572130203247

Epoch: 6| Step: 12
Training loss: 0.30125609040260315
Validation loss: 2.1215732296307883

Epoch: 6| Step: 13
Training loss: 0.530644416809082
Validation loss: 2.10591330130895

Epoch: 327| Step: 0
Training loss: 0.4617518186569214
Validation loss: 2.093053142229716

Epoch: 6| Step: 1
Training loss: 0.15910661220550537
Validation loss: 2.0801554322242737

Epoch: 6| Step: 2
Training loss: 0.15798832476139069
Validation loss: 2.059711277484894

Epoch: 6| Step: 3
Training loss: 0.2788717746734619
Validation loss: 2.0708967049916587

Epoch: 6| Step: 4
Training loss: 0.1927262246608734
Validation loss: 2.0467134714126587

Epoch: 6| Step: 5
Training loss: 0.2579309940338135
Validation loss: 2.095794757207235

Epoch: 6| Step: 6
Training loss: 0.18844686448574066
Validation loss: 2.084904889265696

Epoch: 6| Step: 7
Training loss: 0.23188316822052002
Validation loss: 2.083430906136831

Epoch: 6| Step: 8
Training loss: 0.25460997223854065
Validation loss: 2.0664143164952598

Epoch: 6| Step: 9
Training loss: 0.8529611229896545
Validation loss: 2.071050981680552

Epoch: 6| Step: 10
Training loss: 0.3605615496635437
Validation loss: 2.0552929043769836

Epoch: 6| Step: 11
Training loss: 0.21131590008735657
Validation loss: 2.074758211771647

Epoch: 6| Step: 12
Training loss: 0.17647914588451385
Validation loss: 2.0668968756993613

Epoch: 6| Step: 13
Training loss: 0.30349141359329224
Validation loss: 2.062132954597473

Epoch: 328| Step: 0
Training loss: 0.6435942649841309
Validation loss: 2.0569798151652017

Epoch: 6| Step: 1
Training loss: 0.2525821328163147
Validation loss: 2.092603385448456

Epoch: 6| Step: 2
Training loss: 0.33034321665763855
Validation loss: 2.0698763529459634

Epoch: 6| Step: 3
Training loss: 0.27361345291137695
Validation loss: 2.0469390948613486

Epoch: 6| Step: 4
Training loss: 0.24044033885002136
Validation loss: 2.0519103407859802

Epoch: 6| Step: 5
Training loss: 0.3120156228542328
Validation loss: 2.074744462966919

Epoch: 6| Step: 6
Training loss: 0.20608094334602356
Validation loss: 2.10002472003301

Epoch: 6| Step: 7
Training loss: 0.6139909029006958
Validation loss: 2.1111436684926352

Epoch: 6| Step: 8
Training loss: 0.16864237189292908
Validation loss: 2.098124106725057

Epoch: 6| Step: 9
Training loss: 0.2738773822784424
Validation loss: 2.081925412019094

Epoch: 6| Step: 10
Training loss: 0.29537203907966614
Validation loss: 2.0964694221814475

Epoch: 6| Step: 11
Training loss: 0.2105053961277008
Validation loss: 2.1007338960965476

Epoch: 6| Step: 12
Training loss: 0.3945062756538391
Validation loss: 2.07380743821462

Epoch: 6| Step: 13
Training loss: 0.31615129113197327
Validation loss: 2.0716853737831116

Epoch: 329| Step: 0
Training loss: 0.3323824405670166
Validation loss: 2.0952159762382507

Epoch: 6| Step: 1
Training loss: 0.30397823452949524
Validation loss: 2.088132699330648

Epoch: 6| Step: 2
Training loss: 0.19709745049476624
Validation loss: 2.099072972933451

Epoch: 6| Step: 3
Training loss: 0.3488556742668152
Validation loss: 2.052036921183268

Epoch: 6| Step: 4
Training loss: 0.19194325804710388
Validation loss: 2.1152045130729675

Epoch: 6| Step: 5
Training loss: 0.31945568323135376
Validation loss: 2.0806116859118142

Epoch: 6| Step: 6
Training loss: 0.2898588180541992
Validation loss: 2.115008771419525

Epoch: 6| Step: 7
Training loss: 0.23378188908100128
Validation loss: 2.1291226148605347

Epoch: 6| Step: 8
Training loss: 0.22012904286384583
Validation loss: 2.0547839403152466

Epoch: 6| Step: 9
Training loss: 0.6219347715377808
Validation loss: 2.059997797012329

Epoch: 6| Step: 10
Training loss: 0.460362046957016
Validation loss: 2.0434375206629434

Epoch: 6| Step: 11
Training loss: 0.3092295229434967
Validation loss: 2.105422576268514

Epoch: 6| Step: 12
Training loss: 0.6162546277046204
Validation loss: 2.0920660495758057

Epoch: 6| Step: 13
Training loss: 0.1833747774362564
Validation loss: 2.049931546052297

Epoch: 330| Step: 0
Training loss: 0.28528866171836853
Validation loss: 2.0943790475527444

Epoch: 6| Step: 1
Training loss: 0.26838308572769165
Validation loss: 2.0501550436019897

Epoch: 6| Step: 2
Training loss: 0.3471217751502991
Validation loss: 2.098595937093099

Epoch: 6| Step: 3
Training loss: 0.26991403102874756
Validation loss: 2.076608677705129

Epoch: 6| Step: 4
Training loss: 0.3275798559188843
Validation loss: 2.1202887296676636

Epoch: 6| Step: 5
Training loss: 0.2616350054740906
Validation loss: 2.085729440053304

Epoch: 6| Step: 6
Training loss: 0.22137710452079773
Validation loss: 2.113511860370636

Epoch: 6| Step: 7
Training loss: 0.37899860739707947
Validation loss: 2.038901428381602

Epoch: 6| Step: 8
Training loss: 0.4052530825138092
Validation loss: 2.0564262866973877

Epoch: 6| Step: 9
Training loss: 0.3004566729068756
Validation loss: 2.059176762898763

Epoch: 6| Step: 10
Training loss: 0.25031745433807373
Validation loss: 2.079548637072245

Epoch: 6| Step: 11
Training loss: 0.2001197338104248
Validation loss: 2.0610572894414267

Epoch: 6| Step: 12
Training loss: 0.313143253326416
Validation loss: 1.9998900890350342

Epoch: 6| Step: 13
Training loss: 0.5413286685943604
Validation loss: 2.076639552911123

Epoch: 331| Step: 0
Training loss: 0.3546002507209778
Validation loss: 2.0497136314709983

Epoch: 6| Step: 1
Training loss: 0.33431389927864075
Validation loss: 2.1100427508354187

Epoch: 6| Step: 2
Training loss: 0.2054424285888672
Validation loss: 2.1173082192738852

Epoch: 6| Step: 3
Training loss: 0.2083563655614853
Validation loss: 2.0869838992754617

Epoch: 6| Step: 4
Training loss: 0.7556842565536499
Validation loss: 2.078851799170176

Epoch: 6| Step: 5
Training loss: 0.33598050475120544
Validation loss: 2.0816579461097717

Epoch: 6| Step: 6
Training loss: 0.44836434721946716
Validation loss: 2.0846108396848044

Epoch: 6| Step: 7
Training loss: 0.28121891617774963
Validation loss: 2.1213119427363076

Epoch: 6| Step: 8
Training loss: 0.17708134651184082
Validation loss: 2.1415733297665915

Epoch: 6| Step: 9
Training loss: 0.188040629029274
Validation loss: 2.0645896593729653

Epoch: 6| Step: 10
Training loss: 0.27015596628189087
Validation loss: 2.1262290477752686

Epoch: 6| Step: 11
Training loss: 0.30582451820373535
Validation loss: 2.065546174844106

Epoch: 6| Step: 12
Training loss: 0.2382964789867401
Validation loss: 2.051160454750061

Epoch: 6| Step: 13
Training loss: 0.32196366786956787
Validation loss: 2.1130273739496865

Epoch: 332| Step: 0
Training loss: 0.176167294383049
Validation loss: 2.0471991499265036

Epoch: 6| Step: 1
Training loss: 0.16810685396194458
Validation loss: 2.064874549706777

Epoch: 6| Step: 2
Training loss: 0.21474438905715942
Validation loss: 2.052527050177256

Epoch: 6| Step: 3
Training loss: 0.30306482315063477
Validation loss: 2.0460150440533957

Epoch: 6| Step: 4
Training loss: 0.21856483817100525
Validation loss: 2.0867525339126587

Epoch: 6| Step: 5
Training loss: 0.6952129602432251
Validation loss: 2.0690229535102844

Epoch: 6| Step: 6
Training loss: 0.3481421172618866
Validation loss: 2.070428709189097

Epoch: 6| Step: 7
Training loss: 0.36439087986946106
Validation loss: 2.0732282996177673

Epoch: 6| Step: 8
Training loss: 0.20653590559959412
Validation loss: 2.1010335286458335

Epoch: 6| Step: 9
Training loss: 0.2730959355831146
Validation loss: 2.039500633875529

Epoch: 6| Step: 10
Training loss: 0.35567209124565125
Validation loss: 2.06473179658254

Epoch: 6| Step: 11
Training loss: 0.35113540291786194
Validation loss: 2.046096762021383

Epoch: 6| Step: 12
Training loss: 0.23086461424827576
Validation loss: 2.1160261233647666

Epoch: 6| Step: 13
Training loss: 0.3566136658191681
Validation loss: 2.053501824537913

Epoch: 333| Step: 0
Training loss: 0.17964354157447815
Validation loss: 2.0715319514274597

Epoch: 6| Step: 1
Training loss: 0.3179021179676056
Validation loss: 2.0756079951922097

Epoch: 6| Step: 2
Training loss: 0.24582388997077942
Validation loss: 2.0781254172325134

Epoch: 6| Step: 3
Training loss: 0.6820666790008545
Validation loss: 2.0691594084103904

Epoch: 6| Step: 4
Training loss: 0.5439856648445129
Validation loss: 2.059728264808655

Epoch: 6| Step: 5
Training loss: 0.21999412775039673
Validation loss: 2.0952916344006858

Epoch: 6| Step: 6
Training loss: 0.21782834827899933
Validation loss: 2.1062457958857217

Epoch: 6| Step: 7
Training loss: 0.12866106629371643
Validation loss: 2.1144816478093467

Epoch: 6| Step: 8
Training loss: 0.23627181351184845
Validation loss: 2.1194525758425393

Epoch: 6| Step: 9
Training loss: 0.30804550647735596
Validation loss: 2.09370627005895

Epoch: 6| Step: 10
Training loss: 0.1836417019367218
Validation loss: 2.119392772515615

Epoch: 6| Step: 11
Training loss: 0.33109697699546814
Validation loss: 2.0861195623874664

Epoch: 6| Step: 12
Training loss: 0.22036053240299225
Validation loss: 2.0823780496915183

Epoch: 6| Step: 13
Training loss: 0.2309754341840744
Validation loss: 2.1013606588045755

Epoch: 334| Step: 0
Training loss: 0.6196497678756714
Validation loss: 2.077946205933889

Epoch: 6| Step: 1
Training loss: 0.19944149255752563
Validation loss: 2.0594708919525146

Epoch: 6| Step: 2
Training loss: 0.22555968165397644
Validation loss: 2.0843932827313743

Epoch: 6| Step: 3
Training loss: 0.26494184136390686
Validation loss: 2.0816280444463096

Epoch: 6| Step: 4
Training loss: 0.24577181041240692
Validation loss: 2.0677837133407593

Epoch: 6| Step: 5
Training loss: 0.23949700593948364
Validation loss: 2.0692657232284546

Epoch: 6| Step: 6
Training loss: 0.3329067826271057
Validation loss: 2.1025171081225076

Epoch: 6| Step: 7
Training loss: 0.3142451345920563
Validation loss: 2.0396006306012473

Epoch: 6| Step: 8
Training loss: 0.20624464750289917
Validation loss: 2.098285675048828

Epoch: 6| Step: 9
Training loss: 0.19539184868335724
Validation loss: 2.0851859052975974

Epoch: 6| Step: 10
Training loss: 0.5492717027664185
Validation loss: 2.086402475833893

Epoch: 6| Step: 11
Training loss: 0.1443989872932434
Validation loss: 2.114197393258413

Epoch: 6| Step: 12
Training loss: 0.23091349005699158
Validation loss: 2.0850283900896707

Epoch: 6| Step: 13
Training loss: 0.26261991262435913
Validation loss: 2.093551218509674

Epoch: 335| Step: 0
Training loss: 0.20185771584510803
Validation loss: 2.076789299647013

Epoch: 6| Step: 1
Training loss: 0.2480783462524414
Validation loss: 2.1147137880325317

Epoch: 6| Step: 2
Training loss: 0.3021618127822876
Validation loss: 2.0622554222742715

Epoch: 6| Step: 3
Training loss: 0.18791797757148743
Validation loss: 2.0771910150845847

Epoch: 6| Step: 4
Training loss: 0.5922170877456665
Validation loss: 2.0800681908925376

Epoch: 6| Step: 5
Training loss: 0.1497117578983307
Validation loss: 2.086532235145569

Epoch: 6| Step: 6
Training loss: 0.20766781270503998
Validation loss: 2.10412460565567

Epoch: 6| Step: 7
Training loss: 0.21746551990509033
Validation loss: 2.0874493519465127

Epoch: 6| Step: 8
Training loss: 0.24280548095703125
Validation loss: 2.116578777631124

Epoch: 6| Step: 9
Training loss: 0.41112208366394043
Validation loss: 2.108527143796285

Epoch: 6| Step: 10
Training loss: 0.4229324162006378
Validation loss: 2.0951725244522095

Epoch: 6| Step: 11
Training loss: 0.23845815658569336
Validation loss: 2.0621590813001

Epoch: 6| Step: 12
Training loss: 0.342367559671402
Validation loss: 2.0714990496635437

Epoch: 6| Step: 13
Training loss: 0.2852485775947571
Validation loss: 2.060726523399353

Epoch: 336| Step: 0
Training loss: 0.22774776816368103
Validation loss: 2.0562970638275146

Epoch: 6| Step: 1
Training loss: 0.2963590919971466
Validation loss: 2.0434048175811768

Epoch: 6| Step: 2
Training loss: 0.1840466558933258
Validation loss: 2.0572993556658425

Epoch: 6| Step: 3
Training loss: 0.28810015320777893
Validation loss: 2.085094968477885

Epoch: 6| Step: 4
Training loss: 0.29800042510032654
Validation loss: 2.0861817002296448

Epoch: 6| Step: 5
Training loss: 0.1925792396068573
Validation loss: 2.1241782108942666

Epoch: 6| Step: 6
Training loss: 0.2482788860797882
Validation loss: 2.0662760933240256

Epoch: 6| Step: 7
Training loss: 0.4206363558769226
Validation loss: 2.0529936949412027

Epoch: 6| Step: 8
Training loss: 0.7094857096672058
Validation loss: 2.096689979235331

Epoch: 6| Step: 9
Training loss: 0.16485577821731567
Validation loss: 2.118375221888224

Epoch: 6| Step: 10
Training loss: 0.3198060989379883
Validation loss: 2.086183190345764

Epoch: 6| Step: 11
Training loss: 0.2112458497285843
Validation loss: 2.0835115909576416

Epoch: 6| Step: 12
Training loss: 0.18752135336399078
Validation loss: 2.0912150343259177

Epoch: 6| Step: 13
Training loss: 0.21603821218013763
Validation loss: 2.0769845445950827

Epoch: 337| Step: 0
Training loss: 0.2918403148651123
Validation loss: 2.06957354148229

Epoch: 6| Step: 1
Training loss: 0.33756789565086365
Validation loss: 2.0768338441848755

Epoch: 6| Step: 2
Training loss: 0.2390589416027069
Validation loss: 2.0821743408838906

Epoch: 6| Step: 3
Training loss: 0.14787614345550537
Validation loss: 2.08972958723704

Epoch: 6| Step: 4
Training loss: 0.1503356248140335
Validation loss: 2.064206083615621

Epoch: 6| Step: 5
Training loss: 0.7631872892379761
Validation loss: 2.056052585442861

Epoch: 6| Step: 6
Training loss: 0.1918613165616989
Validation loss: 2.0881834626197815

Epoch: 6| Step: 7
Training loss: 0.3744065761566162
Validation loss: 2.116679549217224

Epoch: 6| Step: 8
Training loss: 0.3177705407142639
Validation loss: 2.0941675106684365

Epoch: 6| Step: 9
Training loss: 0.28250500559806824
Validation loss: 2.1259776949882507

Epoch: 6| Step: 10
Training loss: 0.2846173346042633
Validation loss: 2.0875794688860574

Epoch: 6| Step: 11
Training loss: 0.16428163647651672
Validation loss: 2.0694711407025657

Epoch: 6| Step: 12
Training loss: 0.4600756764411926
Validation loss: 2.084299325942993

Epoch: 6| Step: 13
Training loss: 0.25257739424705505
Validation loss: 2.086322327454885

Epoch: 338| Step: 0
Training loss: 0.7461437582969666
Validation loss: 2.0957293709119162

Epoch: 6| Step: 1
Training loss: 0.4047265648841858
Validation loss: 2.087088863054911

Epoch: 6| Step: 2
Training loss: 0.23983769118785858
Validation loss: 2.07629664738973

Epoch: 6| Step: 3
Training loss: 0.20737701654434204
Validation loss: 2.05918554464976

Epoch: 6| Step: 4
Training loss: 0.20667466521263123
Validation loss: 2.099432726701101

Epoch: 6| Step: 5
Training loss: 0.2413373589515686
Validation loss: 2.0770403146743774

Epoch: 6| Step: 6
Training loss: 0.35439562797546387
Validation loss: 2.0558605790138245

Epoch: 6| Step: 7
Training loss: 0.26949721574783325
Validation loss: 2.075416068236033

Epoch: 6| Step: 8
Training loss: 0.2593381404876709
Validation loss: 2.073002576828003

Epoch: 6| Step: 9
Training loss: 0.2887413501739502
Validation loss: 2.057681997617086

Epoch: 6| Step: 10
Training loss: 0.21108193695545197
Validation loss: 2.055673281351725

Epoch: 6| Step: 11
Training loss: 0.23602195084095
Validation loss: 2.041767497857412

Epoch: 6| Step: 12
Training loss: 0.3301250636577606
Validation loss: 2.075249433517456

Epoch: 6| Step: 13
Training loss: 0.22960124909877777
Validation loss: 2.108312487602234

Epoch: 339| Step: 0
Training loss: 0.14037518203258514
Validation loss: 2.0789157350858054

Epoch: 6| Step: 1
Training loss: 0.35244321823120117
Validation loss: 2.1056413650512695

Epoch: 6| Step: 2
Training loss: 0.25791072845458984
Validation loss: 2.075944741566976

Epoch: 6| Step: 3
Training loss: 0.24331985414028168
Validation loss: 2.103893538316091

Epoch: 6| Step: 4
Training loss: 0.2571204900741577
Validation loss: 2.1114577849706015

Epoch: 6| Step: 5
Training loss: 0.3496563136577606
Validation loss: 2.0535444418589273

Epoch: 6| Step: 6
Training loss: 0.13724245131015778
Validation loss: 2.073728024959564

Epoch: 6| Step: 7
Training loss: 0.1703929603099823
Validation loss: 2.0468704104423523

Epoch: 6| Step: 8
Training loss: 0.2705659866333008
Validation loss: 2.1027375857035318

Epoch: 6| Step: 9
Training loss: 0.37679657340049744
Validation loss: 2.0956761638323465

Epoch: 6| Step: 10
Training loss: 0.6901473999023438
Validation loss: 2.0787317752838135

Epoch: 6| Step: 11
Training loss: 0.2989014685153961
Validation loss: 2.0768378376960754

Epoch: 6| Step: 12
Training loss: 0.17537420988082886
Validation loss: 2.090660254160563

Epoch: 6| Step: 13
Training loss: 0.2418438047170639
Validation loss: 2.07396266857783

Epoch: 340| Step: 0
Training loss: 0.19405120611190796
Validation loss: 2.0654510656992593

Epoch: 6| Step: 1
Training loss: 0.3461727499961853
Validation loss: 2.0912862420082092

Epoch: 6| Step: 2
Training loss: 0.15527822077274323
Validation loss: 2.1207236448923745

Epoch: 6| Step: 3
Training loss: 0.25529301166534424
Validation loss: 2.1062920292218528

Epoch: 6| Step: 4
Training loss: 0.19379469752311707
Validation loss: 2.0692545771598816

Epoch: 6| Step: 5
Training loss: 0.8058457374572754
Validation loss: 2.0980212688446045

Epoch: 6| Step: 6
Training loss: 0.22558054327964783
Validation loss: 2.036517163117727

Epoch: 6| Step: 7
Training loss: 0.36969679594039917
Validation loss: 2.0854584177335105

Epoch: 6| Step: 8
Training loss: 0.20407810807228088
Validation loss: 2.101025104522705

Epoch: 6| Step: 9
Training loss: 0.25372862815856934
Validation loss: 2.0620824098587036

Epoch: 6| Step: 10
Training loss: 0.22273382544517517
Validation loss: 2.0641715923945108

Epoch: 6| Step: 11
Training loss: 0.3373103737831116
Validation loss: 2.0918237368265786

Epoch: 6| Step: 12
Training loss: 0.38056251406669617
Validation loss: 2.0603923400243125

Epoch: 6| Step: 13
Training loss: 0.3811989426612854
Validation loss: 2.077632268269857

Epoch: 341| Step: 0
Training loss: 0.3889312148094177
Validation loss: 2.0315332412719727

Epoch: 6| Step: 1
Training loss: 0.2434576451778412
Validation loss: 2.052610615889231

Epoch: 6| Step: 2
Training loss: 0.5984776616096497
Validation loss: 2.038165787855784

Epoch: 6| Step: 3
Training loss: 0.2588437497615814
Validation loss: 2.1111849745114646

Epoch: 6| Step: 4
Training loss: 0.22487005591392517
Validation loss: 2.0509662429491677

Epoch: 6| Step: 5
Training loss: 0.21547818183898926
Validation loss: 2.0493796269098916

Epoch: 6| Step: 6
Training loss: 0.4162129759788513
Validation loss: 2.02181343237559

Epoch: 6| Step: 7
Training loss: 0.26183634996414185
Validation loss: 2.082188387711843

Epoch: 6| Step: 8
Training loss: 0.26499664783477783
Validation loss: 2.1121531327565513

Epoch: 6| Step: 9
Training loss: 0.2304629236459732
Validation loss: 2.084289073944092

Epoch: 6| Step: 10
Training loss: 0.2551534175872803
Validation loss: 2.063612937927246

Epoch: 6| Step: 11
Training loss: 0.2964514195919037
Validation loss: 2.047796448071798

Epoch: 6| Step: 12
Training loss: 0.2506481409072876
Validation loss: 2.0662760933240256

Epoch: 6| Step: 13
Training loss: 0.21575617790222168
Validation loss: 2.0971820751825967

Epoch: 342| Step: 0
Training loss: 0.23948930203914642
Validation loss: 2.0581323901812234

Epoch: 6| Step: 1
Training loss: 0.30478736758232117
Validation loss: 2.033944845199585

Epoch: 6| Step: 2
Training loss: 0.26533663272857666
Validation loss: 2.083951234817505

Epoch: 6| Step: 3
Training loss: 0.6279740929603577
Validation loss: 2.0884810288747153

Epoch: 6| Step: 4
Training loss: 0.19394631683826447
Validation loss: 2.1349674065907798

Epoch: 6| Step: 5
Training loss: 0.30921080708503723
Validation loss: 2.1104912956555686

Epoch: 6| Step: 6
Training loss: 0.18201684951782227
Validation loss: 2.0849898060162864

Epoch: 6| Step: 7
Training loss: 0.41882920265197754
Validation loss: 2.085803727308909

Epoch: 6| Step: 8
Training loss: 0.27256572246551514
Validation loss: 2.057737330595652

Epoch: 6| Step: 9
Training loss: 0.3491258919239044
Validation loss: 2.031450112660726

Epoch: 6| Step: 10
Training loss: 0.21105864644050598
Validation loss: 2.0815656185150146

Epoch: 6| Step: 11
Training loss: 0.33790141344070435
Validation loss: 2.0542876919110618

Epoch: 6| Step: 12
Training loss: 0.5484265685081482
Validation loss: 2.0147915283838906

Epoch: 6| Step: 13
Training loss: 0.32951241731643677
Validation loss: 2.0920937061309814

Epoch: 343| Step: 0
Training loss: 0.257722944021225
Validation loss: 2.075724800427755

Epoch: 6| Step: 1
Training loss: 0.39257335662841797
Validation loss: 2.0717904766400657

Epoch: 6| Step: 2
Training loss: 0.4799104332923889
Validation loss: 2.109800477822622

Epoch: 6| Step: 3
Training loss: 0.30974435806274414
Validation loss: 2.1125367482503257

Epoch: 6| Step: 4
Training loss: 0.7138515114784241
Validation loss: 2.108804782231649

Epoch: 6| Step: 5
Training loss: 0.21403217315673828
Validation loss: 2.062647004922231

Epoch: 6| Step: 6
Training loss: 0.24190208315849304
Validation loss: 2.06278262535731

Epoch: 6| Step: 7
Training loss: 0.4654434323310852
Validation loss: 2.0455989440282187

Epoch: 6| Step: 8
Training loss: 0.22059130668640137
Validation loss: 2.0115774273872375

Epoch: 6| Step: 9
Training loss: 0.29494035243988037
Validation loss: 2.0327325463294983

Epoch: 6| Step: 10
Training loss: 0.1735091358423233
Validation loss: 2.0757744510968528

Epoch: 6| Step: 11
Training loss: 0.30271846055984497
Validation loss: 2.0501198371251426

Epoch: 6| Step: 12
Training loss: 0.28294801712036133
Validation loss: 2.0547324419021606

Epoch: 6| Step: 13
Training loss: 0.22508563101291656
Validation loss: 2.074806888898214

Epoch: 344| Step: 0
Training loss: 0.29409295320510864
Validation loss: 2.0699684619903564

Epoch: 6| Step: 1
Training loss: 0.1549326330423355
Validation loss: 2.116476078828176

Epoch: 6| Step: 2
Training loss: 0.2567458152770996
Validation loss: 2.049022058645884

Epoch: 6| Step: 3
Training loss: 0.14666280150413513
Validation loss: 2.0664252440134683

Epoch: 6| Step: 4
Training loss: 0.3676600158214569
Validation loss: 2.0284197131792703

Epoch: 6| Step: 5
Training loss: 0.16423875093460083
Validation loss: 2.070783038934072

Epoch: 6| Step: 6
Training loss: 0.18634441494941711
Validation loss: 2.0504433711369834

Epoch: 6| Step: 7
Training loss: 0.19053012132644653
Validation loss: 2.0914689898490906

Epoch: 6| Step: 8
Training loss: 0.4010278582572937
Validation loss: 2.089800715446472

Epoch: 6| Step: 9
Training loss: 0.1832333356142044
Validation loss: 2.0489256779352822

Epoch: 6| Step: 10
Training loss: 0.3446851372718811
Validation loss: 2.0568678975105286

Epoch: 6| Step: 11
Training loss: 0.24785518646240234
Validation loss: 2.109594444433848

Epoch: 6| Step: 12
Training loss: 0.8346848487854004
Validation loss: 2.0302893916765847

Epoch: 6| Step: 13
Training loss: 0.27788692712783813
Validation loss: 2.0769037008285522

Epoch: 345| Step: 0
Training loss: 0.2533565163612366
Validation loss: 2.0783807039260864

Epoch: 6| Step: 1
Training loss: 0.23894453048706055
Validation loss: 2.0637734134991965

Epoch: 6| Step: 2
Training loss: 0.36919814348220825
Validation loss: 2.0840107798576355

Epoch: 6| Step: 3
Training loss: 0.3532230257987976
Validation loss: 2.158105035622915

Epoch: 6| Step: 4
Training loss: 0.6713079214096069
Validation loss: 2.124680459499359

Epoch: 6| Step: 5
Training loss: 0.2802967131137848
Validation loss: 2.114775796731313

Epoch: 6| Step: 6
Training loss: 0.2301446497440338
Validation loss: 2.093657394250234

Epoch: 6| Step: 7
Training loss: 0.18303444981575012
Validation loss: 2.0612833499908447

Epoch: 6| Step: 8
Training loss: 0.259117066860199
Validation loss: 2.0395755767822266

Epoch: 6| Step: 9
Training loss: 0.1789856106042862
Validation loss: 2.1014127333958945

Epoch: 6| Step: 10
Training loss: 0.36615896224975586
Validation loss: 2.0391993721326194

Epoch: 6| Step: 11
Training loss: 0.23931708931922913
Validation loss: 2.1189395586649575

Epoch: 6| Step: 12
Training loss: 0.2884795069694519
Validation loss: 2.056052267551422

Epoch: 6| Step: 13
Training loss: 0.2525528371334076
Validation loss: 2.064327915509542

Epoch: 346| Step: 0
Training loss: 0.27244508266448975
Validation loss: 2.103457192579905

Epoch: 6| Step: 1
Training loss: 0.3319310247898102
Validation loss: 2.0663496454556785

Epoch: 6| Step: 2
Training loss: 0.5567152500152588
Validation loss: 2.069171945254008

Epoch: 6| Step: 3
Training loss: 0.7053530812263489
Validation loss: 2.0862496495246887

Epoch: 6| Step: 4
Training loss: 0.15537601709365845
Validation loss: 2.0602265199025473

Epoch: 6| Step: 5
Training loss: 0.19020795822143555
Validation loss: 2.0467474261919656

Epoch: 6| Step: 6
Training loss: 0.15336108207702637
Validation loss: 2.0689902901649475

Epoch: 6| Step: 7
Training loss: 0.19452334940433502
Validation loss: 2.0769238074620566

Epoch: 6| Step: 8
Training loss: 0.3163612484931946
Validation loss: 2.0818132956822715

Epoch: 6| Step: 9
Training loss: 0.16283318400382996
Validation loss: 2.0888800024986267

Epoch: 6| Step: 10
Training loss: 0.12405170500278473
Validation loss: 2.034243961175283

Epoch: 6| Step: 11
Training loss: 0.22043105959892273
Validation loss: 2.0742708841959634

Epoch: 6| Step: 12
Training loss: 0.2728431224822998
Validation loss: 2.0866365830103555

Epoch: 6| Step: 13
Training loss: 0.3269086480140686
Validation loss: 2.0737887422243753

Epoch: 347| Step: 0
Training loss: 0.21645566821098328
Validation loss: 2.082652429739634

Epoch: 6| Step: 1
Training loss: 0.20091353356838226
Validation loss: 2.060400644938151

Epoch: 6| Step: 2
Training loss: 0.18455715477466583
Validation loss: 2.0900590817133584

Epoch: 6| Step: 3
Training loss: 0.22671042382717133
Validation loss: 2.0634328524271646

Epoch: 6| Step: 4
Training loss: 0.20803210139274597
Validation loss: 2.108452022075653

Epoch: 6| Step: 5
Training loss: 0.2523198425769806
Validation loss: 2.068735738595327

Epoch: 6| Step: 6
Training loss: 0.34699487686157227
Validation loss: 2.0926520824432373

Epoch: 6| Step: 7
Training loss: 0.2447090744972229
Validation loss: 2.085978349049886

Epoch: 6| Step: 8
Training loss: 0.3343537449836731
Validation loss: 2.0808363556861877

Epoch: 6| Step: 9
Training loss: 0.26893922686576843
Validation loss: 2.0654764572779336

Epoch: 6| Step: 10
Training loss: 0.33516812324523926
Validation loss: 2.0682652990023294

Epoch: 6| Step: 11
Training loss: 0.4024699628353119
Validation loss: 2.072786271572113

Epoch: 6| Step: 12
Training loss: 0.164358988404274
Validation loss: 2.086577574412028

Epoch: 6| Step: 13
Training loss: 0.6058511137962341
Validation loss: 2.08512681722641

Epoch: 348| Step: 0
Training loss: 0.21149805188179016
Validation loss: 2.06054425239563

Epoch: 6| Step: 1
Training loss: 0.2920759916305542
Validation loss: 2.1063243548075357

Epoch: 6| Step: 2
Training loss: 0.31681209802627563
Validation loss: 2.0927533308664956

Epoch: 6| Step: 3
Training loss: 0.2901596426963806
Validation loss: 2.105368137359619

Epoch: 6| Step: 4
Training loss: 0.3863130509853363
Validation loss: 2.1509234507878623

Epoch: 6| Step: 5
Training loss: 0.19000326097011566
Validation loss: 2.10208253065745

Epoch: 6| Step: 6
Training loss: 0.22201763093471527
Validation loss: 2.0596688191095986

Epoch: 6| Step: 7
Training loss: 0.18738853931427002
Validation loss: 2.106130143006643

Epoch: 6| Step: 8
Training loss: 0.19419853389263153
Validation loss: 2.1084563732147217

Epoch: 6| Step: 9
Training loss: 0.16840454936027527
Validation loss: 2.10241707166036

Epoch: 6| Step: 10
Training loss: 0.21046054363250732
Validation loss: 2.0687307516733804

Epoch: 6| Step: 11
Training loss: 0.3814731240272522
Validation loss: 2.1013585130373635

Epoch: 6| Step: 12
Training loss: 0.3550126850605011
Validation loss: 2.1347698171933494

Epoch: 6| Step: 13
Training loss: 0.7090312242507935
Validation loss: 2.055057942867279

Epoch: 349| Step: 0
Training loss: 0.31724172830581665
Validation loss: 2.045062800248464

Epoch: 6| Step: 1
Training loss: 0.19906070828437805
Validation loss: 2.079438050587972

Epoch: 6| Step: 2
Training loss: 0.2790623903274536
Validation loss: 2.057565450668335

Epoch: 6| Step: 3
Training loss: 0.37891530990600586
Validation loss: 2.047778844833374

Epoch: 6| Step: 4
Training loss: 0.230504110455513
Validation loss: 2.060229400793711

Epoch: 6| Step: 5
Training loss: 0.2595597505569458
Validation loss: 2.0174225767453513

Epoch: 6| Step: 6
Training loss: 0.4692547619342804
Validation loss: 2.039769411087036

Epoch: 6| Step: 7
Training loss: 0.2331894487142563
Validation loss: 2.0293944676717124

Epoch: 6| Step: 8
Training loss: 0.23572969436645508
Validation loss: 2.056303918361664

Epoch: 6| Step: 9
Training loss: 0.7740075588226318
Validation loss: 2.027243494987488

Epoch: 6| Step: 10
Training loss: 0.1220913901925087
Validation loss: 2.0635376572608948

Epoch: 6| Step: 11
Training loss: 0.2624313235282898
Validation loss: 2.0595756371816

Epoch: 6| Step: 12
Training loss: 0.19072465598583221
Validation loss: 2.096943199634552

Epoch: 6| Step: 13
Training loss: 0.24762555956840515
Validation loss: 2.0576626857121787

Epoch: 350| Step: 0
Training loss: 0.21430142223834991
Validation loss: 2.079170028368632

Epoch: 6| Step: 1
Training loss: 0.21956048905849457
Validation loss: 2.0429858962694802

Epoch: 6| Step: 2
Training loss: 0.3755332827568054
Validation loss: 2.0366095304489136

Epoch: 6| Step: 3
Training loss: 0.29012393951416016
Validation loss: 2.0425254106521606

Epoch: 6| Step: 4
Training loss: 0.21471327543258667
Validation loss: 2.0602802832921348

Epoch: 6| Step: 5
Training loss: 0.15093454718589783
Validation loss: 2.0360209544499717

Epoch: 6| Step: 6
Training loss: 0.24437759816646576
Validation loss: 2.0359867413838706

Epoch: 6| Step: 7
Training loss: 0.20085375010967255
Validation loss: 2.0856484174728394

Epoch: 6| Step: 8
Training loss: 0.6208210587501526
Validation loss: 2.0878851413726807

Epoch: 6| Step: 9
Training loss: 0.5085996985435486
Validation loss: 2.0645887653032937

Epoch: 6| Step: 10
Training loss: 0.25661611557006836
Validation loss: 2.0767300526301065

Epoch: 6| Step: 11
Training loss: 0.21725904941558838
Validation loss: 2.036714196205139

Epoch: 6| Step: 12
Training loss: 0.3588576018810272
Validation loss: 2.099722385406494

Epoch: 6| Step: 13
Training loss: 0.2802277207374573
Validation loss: 2.035870889822642

Epoch: 351| Step: 0
Training loss: 0.31667205691337585
Validation loss: 2.0717957615852356

Epoch: 6| Step: 1
Training loss: 0.3087899684906006
Validation loss: 2.1121583183606467

Epoch: 6| Step: 2
Training loss: 0.25186067819595337
Validation loss: 2.050698379675547

Epoch: 6| Step: 3
Training loss: 0.3062264919281006
Validation loss: 2.060919245084127

Epoch: 6| Step: 4
Training loss: 0.22929441928863525
Validation loss: 2.0708511670430503

Epoch: 6| Step: 5
Training loss: 0.37417733669281006
Validation loss: 2.0794403354326882

Epoch: 6| Step: 6
Training loss: 0.2099931836128235
Validation loss: 2.101164400577545

Epoch: 6| Step: 7
Training loss: 0.33951136469841003
Validation loss: 2.040852506955465

Epoch: 6| Step: 8
Training loss: 0.20047840476036072
Validation loss: 2.0805161794026694

Epoch: 6| Step: 9
Training loss: 0.8329017162322998
Validation loss: 2.0985372265179953

Epoch: 6| Step: 10
Training loss: 0.21525081992149353
Validation loss: 2.0651460886001587

Epoch: 6| Step: 11
Training loss: 0.25023430585861206
Validation loss: 2.063046375910441

Epoch: 6| Step: 12
Training loss: 0.21066434681415558
Validation loss: 2.0192965467770896

Epoch: 6| Step: 13
Training loss: 0.2696385383605957
Validation loss: 2.032148838043213

Epoch: 352| Step: 0
Training loss: 0.22938692569732666
Validation loss: 2.0444935162862143

Epoch: 6| Step: 1
Training loss: 0.20168834924697876
Validation loss: 2.078904847304026

Epoch: 6| Step: 2
Training loss: 0.25289186835289
Validation loss: 2.069829066594442

Epoch: 6| Step: 3
Training loss: 0.23020225763320923
Validation loss: 2.0633497635523477

Epoch: 6| Step: 4
Training loss: 0.21471554040908813
Validation loss: 2.0925482908884683

Epoch: 6| Step: 5
Training loss: 0.19249668717384338
Validation loss: 2.0376455386479697

Epoch: 6| Step: 6
Training loss: 0.16281758248806
Validation loss: 2.0752172668774924

Epoch: 6| Step: 7
Training loss: 0.19536444544792175
Validation loss: 2.061082899570465

Epoch: 6| Step: 8
Training loss: 0.3905017673969269
Validation loss: 2.071404755115509

Epoch: 6| Step: 9
Training loss: 0.08766207098960876
Validation loss: 2.0673291285832724

Epoch: 6| Step: 10
Training loss: 0.3569534420967102
Validation loss: 2.0756826996803284

Epoch: 6| Step: 11
Training loss: 0.14978477358818054
Validation loss: 2.0601507822672525

Epoch: 6| Step: 12
Training loss: 0.2505706548690796
Validation loss: 2.0426503817240396

Epoch: 6| Step: 13
Training loss: 0.7137255072593689
Validation loss: 2.058562616507212

Epoch: 353| Step: 0
Training loss: 0.2885599732398987
Validation loss: 2.0933075149854026

Epoch: 6| Step: 1
Training loss: 0.2630627155303955
Validation loss: 2.081181287765503

Epoch: 6| Step: 2
Training loss: 0.23913294076919556
Validation loss: 2.0953206618626914

Epoch: 6| Step: 3
Training loss: 0.37544044852256775
Validation loss: 2.0778116981188455

Epoch: 6| Step: 4
Training loss: 0.2580864727497101
Validation loss: 2.0642379323641458

Epoch: 6| Step: 5
Training loss: 0.3302507996559143
Validation loss: 2.0849146048227944

Epoch: 6| Step: 6
Training loss: 0.26915332674980164
Validation loss: 2.1005664666493735

Epoch: 6| Step: 7
Training loss: 0.23502279818058014
Validation loss: 2.0864175955454507

Epoch: 6| Step: 8
Training loss: 0.6514551043510437
Validation loss: 2.0706817309061685

Epoch: 6| Step: 9
Training loss: 0.2833414673805237
Validation loss: 2.08861380815506

Epoch: 6| Step: 10
Training loss: 0.23904508352279663
Validation loss: 2.0786240895589194

Epoch: 6| Step: 11
Training loss: 0.21076756715774536
Validation loss: 2.0462233622868857

Epoch: 6| Step: 12
Training loss: 0.24672937393188477
Validation loss: 2.0595207810401917

Epoch: 6| Step: 13
Training loss: 0.3953118324279785
Validation loss: 2.0606918931007385

Epoch: 354| Step: 0
Training loss: 0.29018160700798035
Validation loss: 2.0836766163508096

Epoch: 6| Step: 1
Training loss: 0.22893399000167847
Validation loss: 2.1089861392974854

Epoch: 6| Step: 2
Training loss: 0.2760466933250427
Validation loss: 2.0703012943267822

Epoch: 6| Step: 3
Training loss: 0.40967726707458496
Validation loss: 2.07132089138031

Epoch: 6| Step: 4
Training loss: 0.5772877931594849
Validation loss: 2.0597488284111023

Epoch: 6| Step: 5
Training loss: 0.2471577525138855
Validation loss: 2.028918464978536

Epoch: 6| Step: 6
Training loss: 0.24349069595336914
Validation loss: 2.108478566010793

Epoch: 6| Step: 7
Training loss: 0.1632559895515442
Validation loss: 2.082772692044576

Epoch: 6| Step: 8
Training loss: 0.22233328223228455
Validation loss: 2.0881385803222656

Epoch: 6| Step: 9
Training loss: 0.3274857997894287
Validation loss: 2.029847582181295

Epoch: 6| Step: 10
Training loss: 0.15999537706375122
Validation loss: 2.0484994451204934

Epoch: 6| Step: 11
Training loss: 0.2269810438156128
Validation loss: 2.0922087033589682

Epoch: 6| Step: 12
Training loss: 0.46692919731140137
Validation loss: 2.1119226018587747

Epoch: 6| Step: 13
Training loss: 0.181019127368927
Validation loss: 2.065555989742279

Epoch: 355| Step: 0
Training loss: 0.1697881817817688
Validation loss: 2.074883004029592

Epoch: 6| Step: 1
Training loss: 0.21553486585617065
Validation loss: 2.0702262918154397

Epoch: 6| Step: 2
Training loss: 0.3395814001560211
Validation loss: 2.1164519786834717

Epoch: 6| Step: 3
Training loss: 0.24689117074012756
Validation loss: 2.04818058013916

Epoch: 6| Step: 4
Training loss: 0.3412407636642456
Validation loss: 2.0970439314842224

Epoch: 6| Step: 5
Training loss: 0.5007192492485046
Validation loss: 2.0531614224116006

Epoch: 6| Step: 6
Training loss: 0.27918514609336853
Validation loss: 2.097992499669393

Epoch: 6| Step: 7
Training loss: 0.2579217553138733
Validation loss: 2.0528202652931213

Epoch: 6| Step: 8
Training loss: 0.27416473627090454
Validation loss: 2.0887930591901145

Epoch: 6| Step: 9
Training loss: 0.5766642093658447
Validation loss: 2.0661956469217935

Epoch: 6| Step: 10
Training loss: 0.24911057949066162
Validation loss: 2.0861871441205344

Epoch: 6| Step: 11
Training loss: 0.2720366418361664
Validation loss: 2.1160812377929688

Epoch: 6| Step: 12
Training loss: 0.2448028177022934
Validation loss: 2.065182149410248

Epoch: 6| Step: 13
Training loss: 0.3834899663925171
Validation loss: 2.088568111260732

Epoch: 356| Step: 0
Training loss: 0.6630314588546753
Validation loss: 2.0674312512079873

Epoch: 6| Step: 1
Training loss: 0.16683702170848846
Validation loss: 2.068094491958618

Epoch: 6| Step: 2
Training loss: 0.1945456862449646
Validation loss: 2.0650927821795144

Epoch: 6| Step: 3
Training loss: 0.3095087707042694
Validation loss: 2.0799400409062705

Epoch: 6| Step: 4
Training loss: 0.15578550100326538
Validation loss: 2.0881774624188743

Epoch: 6| Step: 5
Training loss: 0.37046176195144653
Validation loss: 2.069931964079539

Epoch: 6| Step: 6
Training loss: 0.2159247100353241
Validation loss: 2.0939583579699197

Epoch: 6| Step: 7
Training loss: 0.40780195593833923
Validation loss: 2.1165281732877097

Epoch: 6| Step: 8
Training loss: 0.16925236582756042
Validation loss: 2.1152926087379456

Epoch: 6| Step: 9
Training loss: 0.24283082783222198
Validation loss: 2.078086237112681

Epoch: 6| Step: 10
Training loss: 0.3453441262245178
Validation loss: 2.1357693672180176

Epoch: 6| Step: 11
Training loss: 0.3219437599182129
Validation loss: 2.089984714984894

Epoch: 6| Step: 12
Training loss: 0.2985683083534241
Validation loss: 2.0807453989982605

Epoch: 6| Step: 13
Training loss: 0.203434556722641
Validation loss: 2.069706678390503

Epoch: 357| Step: 0
Training loss: 0.33807817101478577
Validation loss: 2.056045730908712

Epoch: 6| Step: 1
Training loss: 0.415103018283844
Validation loss: 2.042535960674286

Epoch: 6| Step: 2
Training loss: 0.30186647176742554
Validation loss: 2.056921740372976

Epoch: 6| Step: 3
Training loss: 0.2057698667049408
Validation loss: 2.08104278643926

Epoch: 6| Step: 4
Training loss: 0.2206680327653885
Validation loss: 2.053054094314575

Epoch: 6| Step: 5
Training loss: 0.28218144178390503
Validation loss: 2.1471627950668335

Epoch: 6| Step: 6
Training loss: 0.872864305973053
Validation loss: 2.084072748819987

Epoch: 6| Step: 7
Training loss: 0.48499566316604614
Validation loss: 2.1116546193758645

Epoch: 6| Step: 8
Training loss: 0.3934271037578583
Validation loss: 2.1248450676600137

Epoch: 6| Step: 9
Training loss: 0.25472787022590637
Validation loss: 2.101891338825226

Epoch: 6| Step: 10
Training loss: 0.14505353569984436
Validation loss: 2.032413065433502

Epoch: 6| Step: 11
Training loss: 0.30675604939460754
Validation loss: 2.0551939010620117

Epoch: 6| Step: 12
Training loss: 0.2922010123729706
Validation loss: 2.047198216120402

Epoch: 6| Step: 13
Training loss: 0.27057769894599915
Validation loss: 2.0520265102386475

Epoch: 358| Step: 0
Training loss: 0.2574886679649353
Validation loss: 2.067701975504557

Epoch: 6| Step: 1
Training loss: 0.37391984462738037
Validation loss: 2.045392870903015

Epoch: 6| Step: 2
Training loss: 0.2429722100496292
Validation loss: 2.078030308087667

Epoch: 6| Step: 3
Training loss: 0.23157842457294464
Validation loss: 2.058107237021128

Epoch: 6| Step: 4
Training loss: 0.3282386362552643
Validation loss: 2.068016509215037

Epoch: 6| Step: 5
Training loss: 0.19340243935585022
Validation loss: 2.117571711540222

Epoch: 6| Step: 6
Training loss: 0.7839409112930298
Validation loss: 2.132399578889211

Epoch: 6| Step: 7
Training loss: 0.559840738773346
Validation loss: 2.110400935014089

Epoch: 6| Step: 8
Training loss: 0.3019740581512451
Validation loss: 2.0908859372138977

Epoch: 6| Step: 9
Training loss: 0.233273446559906
Validation loss: 2.0732617576917014

Epoch: 6| Step: 10
Training loss: 0.26273977756500244
Validation loss: 2.068090001742045

Epoch: 6| Step: 11
Training loss: 0.22550630569458008
Validation loss: 2.075786074002584

Epoch: 6| Step: 12
Training loss: 0.37209874391555786
Validation loss: 2.085928797721863

Epoch: 6| Step: 13
Training loss: 0.423298716545105
Validation loss: 2.1076447566350303

Epoch: 359| Step: 0
Training loss: 0.22554169595241547
Validation loss: 2.07904976606369

Epoch: 6| Step: 1
Training loss: 0.23999473452568054
Validation loss: 2.083033005396525

Epoch: 6| Step: 2
Training loss: 0.3619127571582794
Validation loss: 2.0984119971593223

Epoch: 6| Step: 3
Training loss: 0.3322761654853821
Validation loss: 2.088438173135122

Epoch: 6| Step: 4
Training loss: 0.29810890555381775
Validation loss: 2.119085709253947

Epoch: 6| Step: 5
Training loss: 0.3089215159416199
Validation loss: 2.0969455440839133

Epoch: 6| Step: 6
Training loss: 0.2523954510688782
Validation loss: 2.1286125580469766

Epoch: 6| Step: 7
Training loss: 0.3453673720359802
Validation loss: 2.09292209148407

Epoch: 6| Step: 8
Training loss: 0.22049763798713684
Validation loss: 2.1047462622324624

Epoch: 6| Step: 9
Training loss: 0.7890866994857788
Validation loss: 2.0737282832463584

Epoch: 6| Step: 10
Training loss: 0.38691896200180054
Validation loss: 2.1103252172470093

Epoch: 6| Step: 11
Training loss: 0.37322771549224854
Validation loss: 2.055091619491577

Epoch: 6| Step: 12
Training loss: 0.24714875221252441
Validation loss: 2.0962133208910623

Epoch: 6| Step: 13
Training loss: 0.18483102321624756
Validation loss: 2.119634767373403

Epoch: 360| Step: 0
Training loss: 0.16031965613365173
Validation loss: 2.1103246212005615

Epoch: 6| Step: 1
Training loss: 0.25207725167274475
Validation loss: 2.157548487186432

Epoch: 6| Step: 2
Training loss: 0.2627391219139099
Validation loss: 2.1053595542907715

Epoch: 6| Step: 3
Training loss: 0.24689415097236633
Validation loss: 2.106361965338389

Epoch: 6| Step: 4
Training loss: 0.7193926572799683
Validation loss: 2.149299701054891

Epoch: 6| Step: 5
Training loss: 0.2518051862716675
Validation loss: 2.0975226958592734

Epoch: 6| Step: 6
Training loss: 0.16604885458946228
Validation loss: 2.0890975991884866

Epoch: 6| Step: 7
Training loss: 0.22382496297359467
Validation loss: 2.0791528622309365

Epoch: 6| Step: 8
Training loss: 0.3195291757583618
Validation loss: 2.0764785011609397

Epoch: 6| Step: 9
Training loss: 0.3020951747894287
Validation loss: 2.080703695615133

Epoch: 6| Step: 10
Training loss: 0.5466695427894592
Validation loss: 2.0940208037694297

Epoch: 6| Step: 11
Training loss: 0.3560655117034912
Validation loss: 2.0340097745259604

Epoch: 6| Step: 12
Training loss: 0.15494777262210846
Validation loss: 2.1265867551167807

Epoch: 6| Step: 13
Training loss: 0.33534860610961914
Validation loss: 2.1345187425613403

Epoch: 361| Step: 0
Training loss: 0.31759899854660034
Validation loss: 2.1657657623291016

Epoch: 6| Step: 1
Training loss: 0.24938379228115082
Validation loss: 2.118703007698059

Epoch: 6| Step: 2
Training loss: 0.20662808418273926
Validation loss: 2.0904343724250793

Epoch: 6| Step: 3
Training loss: 0.492665559053421
Validation loss: 2.06832093000412

Epoch: 6| Step: 4
Training loss: 0.2571561932563782
Validation loss: 2.09391983350118

Epoch: 6| Step: 5
Training loss: 0.2900293171405792
Validation loss: 2.0634410778681436

Epoch: 6| Step: 6
Training loss: 0.5494377613067627
Validation loss: 2.121924042701721

Epoch: 6| Step: 7
Training loss: 0.4519196152687073
Validation loss: 2.0573480327924094

Epoch: 6| Step: 8
Training loss: 0.3341049551963806
Validation loss: 2.051011800765991

Epoch: 6| Step: 9
Training loss: 0.21783483028411865
Validation loss: 2.105963110923767

Epoch: 6| Step: 10
Training loss: 0.25889673829078674
Validation loss: 2.0717161893844604

Epoch: 6| Step: 11
Training loss: 0.24247616529464722
Validation loss: 2.1214288075764975

Epoch: 6| Step: 12
Training loss: 0.4436582326889038
Validation loss: 2.1242559353510537

Epoch: 6| Step: 13
Training loss: 0.45433688163757324
Validation loss: 2.131975253423055

Epoch: 362| Step: 0
Training loss: 0.1969049870967865
Validation loss: 2.0829585989316306

Epoch: 6| Step: 1
Training loss: 0.2964222729206085
Validation loss: 2.0902515649795532

Epoch: 6| Step: 2
Training loss: 0.5618119835853577
Validation loss: 2.0837378104527793

Epoch: 6| Step: 3
Training loss: 0.2216206043958664
Validation loss: 2.0691643357276917

Epoch: 6| Step: 4
Training loss: 0.2485288828611374
Validation loss: 2.1000590125719705

Epoch: 6| Step: 5
Training loss: 0.2785717248916626
Validation loss: 2.0796568393707275

Epoch: 6| Step: 6
Training loss: 0.4028725028038025
Validation loss: 2.090874751408895

Epoch: 6| Step: 7
Training loss: 0.22461475431919098
Validation loss: 2.074438909689585

Epoch: 6| Step: 8
Training loss: 0.20457711815834045
Validation loss: 2.0967270334561667

Epoch: 6| Step: 9
Training loss: 0.2440609484910965
Validation loss: 2.0834606687227883

Epoch: 6| Step: 10
Training loss: 0.18181532621383667
Validation loss: 2.082689960797628

Epoch: 6| Step: 11
Training loss: 0.6207895278930664
Validation loss: 2.07134340206782

Epoch: 6| Step: 12
Training loss: 0.20957280695438385
Validation loss: 2.0816345810890198

Epoch: 6| Step: 13
Training loss: 0.31476891040802
Validation loss: 2.11398051182429

Epoch: 363| Step: 0
Training loss: 0.20620426535606384
Validation loss: 2.125474770863851

Epoch: 6| Step: 1
Training loss: 0.19040726125240326
Validation loss: 2.1060741543769836

Epoch: 6| Step: 2
Training loss: 0.29421159625053406
Validation loss: 2.067771553993225

Epoch: 6| Step: 3
Training loss: 0.21769364178180695
Validation loss: 2.0725231568018594

Epoch: 6| Step: 4
Training loss: 0.6150570511817932
Validation loss: 2.0809576312700906

Epoch: 6| Step: 5
Training loss: 0.4427039623260498
Validation loss: 2.0804468194643655

Epoch: 6| Step: 6
Training loss: 0.3468745946884155
Validation loss: 2.0596798261006675

Epoch: 6| Step: 7
Training loss: 0.1856076419353485
Validation loss: 2.070448954900106

Epoch: 6| Step: 8
Training loss: 0.3390492796897888
Validation loss: 2.1109580198923745

Epoch: 6| Step: 9
Training loss: 0.19357368350028992
Validation loss: 2.068900386492411

Epoch: 6| Step: 10
Training loss: 0.3761051297187805
Validation loss: 2.0766815741856894

Epoch: 6| Step: 11
Training loss: 0.22535893321037292
Validation loss: 2.0529799858729043

Epoch: 6| Step: 12
Training loss: 0.2298801839351654
Validation loss: 2.0222710967063904

Epoch: 6| Step: 13
Training loss: 0.2502337694168091
Validation loss: 2.057092328866323

Epoch: 364| Step: 0
Training loss: 0.2210555374622345
Validation loss: 2.0807636976242065

Epoch: 6| Step: 1
Training loss: 0.3109862506389618
Validation loss: 2.070996721585592

Epoch: 6| Step: 2
Training loss: 0.16994234919548035
Validation loss: 2.0798741380373635

Epoch: 6| Step: 3
Training loss: 0.36188173294067383
Validation loss: 2.07125190893809

Epoch: 6| Step: 4
Training loss: 0.20861320197582245
Validation loss: 2.087571163972219

Epoch: 6| Step: 5
Training loss: 0.31471312046051025
Validation loss: 2.0950995286305747

Epoch: 6| Step: 6
Training loss: 0.3283396065235138
Validation loss: 2.0671158830324807

Epoch: 6| Step: 7
Training loss: 0.18058010935783386
Validation loss: 2.046081244945526

Epoch: 6| Step: 8
Training loss: 0.22029095888137817
Validation loss: 2.0586477518081665

Epoch: 6| Step: 9
Training loss: 0.28175923228263855
Validation loss: 2.0404696067174277

Epoch: 6| Step: 10
Training loss: 0.30837008357048035
Validation loss: 2.022732973098755

Epoch: 6| Step: 11
Training loss: 0.2315940260887146
Validation loss: 2.054930845896403

Epoch: 6| Step: 12
Training loss: 0.5790225267410278
Validation loss: 2.096317688624064

Epoch: 6| Step: 13
Training loss: 0.32782644033432007
Validation loss: 2.0904908180236816

Epoch: 365| Step: 0
Training loss: 0.27891141176223755
Validation loss: 2.070471386114756

Epoch: 6| Step: 1
Training loss: 0.21107161045074463
Validation loss: 2.118364711602529

Epoch: 6| Step: 2
Training loss: 0.6991491913795471
Validation loss: 2.098637640476227

Epoch: 6| Step: 3
Training loss: 0.21770071983337402
Validation loss: 2.0523759722709656

Epoch: 6| Step: 4
Training loss: 0.18279923498630524
Validation loss: 2.080431580543518

Epoch: 6| Step: 5
Training loss: 0.341671884059906
Validation loss: 2.0721468726793923

Epoch: 6| Step: 6
Training loss: 0.3261197805404663
Validation loss: 2.032774786154429

Epoch: 6| Step: 7
Training loss: 0.2493213713169098
Validation loss: 2.059281269709269

Epoch: 6| Step: 8
Training loss: 0.19402797520160675
Validation loss: 2.1186474164326987

Epoch: 6| Step: 9
Training loss: 0.27800434827804565
Validation loss: 2.041991710662842

Epoch: 6| Step: 10
Training loss: 0.17055341601371765
Validation loss: 2.095248560110728

Epoch: 6| Step: 11
Training loss: 0.27153491973876953
Validation loss: 2.066934585571289

Epoch: 6| Step: 12
Training loss: 0.19194824993610382
Validation loss: 2.0934431751569114

Epoch: 6| Step: 13
Training loss: 0.4093515872955322
Validation loss: 2.119540353616079

Epoch: 366| Step: 0
Training loss: 0.192016139626503
Validation loss: 2.092490633328756

Epoch: 6| Step: 1
Training loss: 0.14898453652858734
Validation loss: 2.098610440889994

Epoch: 6| Step: 2
Training loss: 0.27718448638916016
Validation loss: 2.0729175408681235

Epoch: 6| Step: 3
Training loss: 0.11351615935564041
Validation loss: 2.0724377234776816

Epoch: 6| Step: 4
Training loss: 0.2810998857021332
Validation loss: 2.0496985713640847

Epoch: 6| Step: 5
Training loss: 0.6463391184806824
Validation loss: 2.077010174592336

Epoch: 6| Step: 6
Training loss: 0.3062557876110077
Validation loss: 2.0753904978434243

Epoch: 6| Step: 7
Training loss: 0.2925352454185486
Validation loss: 2.0468597412109375

Epoch: 6| Step: 8
Training loss: 0.2051108479499817
Validation loss: 2.0867891907691956

Epoch: 6| Step: 9
Training loss: 0.24561810493469238
Validation loss: 2.0765758951505027

Epoch: 6| Step: 10
Training loss: 0.46338480710983276
Validation loss: 2.1203856666882834

Epoch: 6| Step: 11
Training loss: 0.2014438807964325
Validation loss: 2.0761475364367166

Epoch: 6| Step: 12
Training loss: 0.33700644969940186
Validation loss: 2.079707384109497

Epoch: 6| Step: 13
Training loss: 0.2590515911579132
Validation loss: 2.0628823041915894

Epoch: 367| Step: 0
Training loss: 0.1627711057662964
Validation loss: 2.0418447653452554

Epoch: 6| Step: 1
Training loss: 0.23580250144004822
Validation loss: 2.07121205329895

Epoch: 6| Step: 2
Training loss: 0.5772356986999512
Validation loss: 2.07950892051061

Epoch: 6| Step: 3
Training loss: 0.13912785053253174
Validation loss: 2.0704031189282737

Epoch: 6| Step: 4
Training loss: 0.26950380206108093
Validation loss: 2.1039814154307046

Epoch: 6| Step: 5
Training loss: 0.1498640477657318
Validation loss: 2.0680625637372336

Epoch: 6| Step: 6
Training loss: 0.2778788208961487
Validation loss: 2.0711492697397866

Epoch: 6| Step: 7
Training loss: 0.20639029145240784
Validation loss: 2.0858088533083596

Epoch: 6| Step: 8
Training loss: 0.2246692180633545
Validation loss: 2.13234676917394

Epoch: 6| Step: 9
Training loss: 0.2095862329006195
Validation loss: 2.0410268306732178

Epoch: 6| Step: 10
Training loss: 0.5148110389709473
Validation loss: 2.126211941242218

Epoch: 6| Step: 11
Training loss: 0.22233739495277405
Validation loss: 2.062419573465983

Epoch: 6| Step: 12
Training loss: 0.20261645317077637
Validation loss: 2.0656906366348267

Epoch: 6| Step: 13
Training loss: 0.40179499983787537
Validation loss: 2.0702784260114035

Epoch: 368| Step: 0
Training loss: 0.19617953896522522
Validation loss: 2.0929020841916404

Epoch: 6| Step: 1
Training loss: 0.2199403941631317
Validation loss: 2.1003835995992026

Epoch: 6| Step: 2
Training loss: 0.16754749417304993
Validation loss: 2.080911656220754

Epoch: 6| Step: 3
Training loss: 0.2217080295085907
Validation loss: 2.0627457896868386

Epoch: 6| Step: 4
Training loss: 0.7714271545410156
Validation loss: 2.062689423561096

Epoch: 6| Step: 5
Training loss: 0.2470991611480713
Validation loss: 2.06061319510142

Epoch: 6| Step: 6
Training loss: 0.357485294342041
Validation loss: 2.1037607192993164

Epoch: 6| Step: 7
Training loss: 0.2600388824939728
Validation loss: 2.060195803642273

Epoch: 6| Step: 8
Training loss: 0.4301099181175232
Validation loss: 2.080743134021759

Epoch: 6| Step: 9
Training loss: 0.2082941234111786
Validation loss: 2.1046743392944336

Epoch: 6| Step: 10
Training loss: 0.3731991946697235
Validation loss: 2.101975977420807

Epoch: 6| Step: 11
Training loss: 0.16771337389945984
Validation loss: 2.1167302330334983

Epoch: 6| Step: 12
Training loss: 0.2088862955570221
Validation loss: 2.0818682312965393

Epoch: 6| Step: 13
Training loss: 0.15721362829208374
Validation loss: 2.1045470436414084

Epoch: 369| Step: 0
Training loss: 0.5937253832817078
Validation loss: 2.1260210275650024

Epoch: 6| Step: 1
Training loss: 0.22098010778427124
Validation loss: 2.104124446709951

Epoch: 6| Step: 2
Training loss: 0.29449793696403503
Validation loss: 2.1101840138435364

Epoch: 6| Step: 3
Training loss: 0.31388378143310547
Validation loss: 2.091734151045481

Epoch: 6| Step: 4
Training loss: 0.4026358723640442
Validation loss: 2.0880849361419678

Epoch: 6| Step: 5
Training loss: 0.36478668451309204
Validation loss: 2.099872370560964

Epoch: 6| Step: 6
Training loss: 0.3006313741207123
Validation loss: 2.082801938056946

Epoch: 6| Step: 7
Training loss: 0.1812676191329956
Validation loss: 2.0803081591924033

Epoch: 6| Step: 8
Training loss: 0.17454947531223297
Validation loss: 2.084711750348409

Epoch: 6| Step: 9
Training loss: 0.2460862696170807
Validation loss: 2.0555168191591897

Epoch: 6| Step: 10
Training loss: 0.2628886103630066
Validation loss: 2.0536666909853616

Epoch: 6| Step: 11
Training loss: 0.1656741052865982
Validation loss: 2.1088553269704184

Epoch: 6| Step: 12
Training loss: 0.23063267767429352
Validation loss: 2.1342522899309793

Epoch: 6| Step: 13
Training loss: 0.1311855912208557
Validation loss: 2.088650643825531

Epoch: 370| Step: 0
Training loss: 0.1515638828277588
Validation loss: 2.0936808586120605

Epoch: 6| Step: 1
Training loss: 0.2997003197669983
Validation loss: 2.0788851579030356

Epoch: 6| Step: 2
Training loss: 0.7600271701812744
Validation loss: 2.0752573211987815

Epoch: 6| Step: 3
Training loss: 0.3084675967693329
Validation loss: 2.1126384933789573

Epoch: 6| Step: 4
Training loss: 0.2245073914527893
Validation loss: 2.1332077383995056

Epoch: 6| Step: 5
Training loss: 0.20486432313919067
Validation loss: 2.115070343017578

Epoch: 6| Step: 6
Training loss: 0.20600399374961853
Validation loss: 2.0708181659380593

Epoch: 6| Step: 7
Training loss: 0.15001089870929718
Validation loss: 2.060050149758657

Epoch: 6| Step: 8
Training loss: 0.2674592137336731
Validation loss: 2.1133243242899575

Epoch: 6| Step: 9
Training loss: 0.1777891218662262
Validation loss: 2.0377179980278015

Epoch: 6| Step: 10
Training loss: 0.33825409412384033
Validation loss: 2.0509192943573

Epoch: 6| Step: 11
Training loss: 0.267854243516922
Validation loss: 2.067746917406718

Epoch: 6| Step: 12
Training loss: 0.26210474967956543
Validation loss: 2.0379209915796914

Epoch: 6| Step: 13
Training loss: 0.369698703289032
Validation loss: 2.0378399093945823

Epoch: 371| Step: 0
Training loss: 0.39708375930786133
Validation loss: 2.08634219566981

Epoch: 6| Step: 1
Training loss: 0.23680353164672852
Validation loss: 2.1276804010073342

Epoch: 6| Step: 2
Training loss: 0.3914042115211487
Validation loss: 2.067299564679464

Epoch: 6| Step: 3
Training loss: 0.31634992361068726
Validation loss: 2.0549993316332498

Epoch: 6| Step: 4
Training loss: 0.6193040013313293
Validation loss: 2.066908836364746

Epoch: 6| Step: 5
Training loss: 0.24321341514587402
Validation loss: 2.035130341847738

Epoch: 6| Step: 6
Training loss: 0.2842949628829956
Validation loss: 2.0519115130106607

Epoch: 6| Step: 7
Training loss: 0.26236188411712646
Validation loss: 2.0455756386121116

Epoch: 6| Step: 8
Training loss: 0.3141009211540222
Validation loss: 2.0871405800183616

Epoch: 6| Step: 9
Training loss: 0.22161069512367249
Validation loss: 2.079242527484894

Epoch: 6| Step: 10
Training loss: 0.2634428143501282
Validation loss: 2.125605821609497

Epoch: 6| Step: 11
Training loss: 0.29439374804496765
Validation loss: 2.0722868839899697

Epoch: 6| Step: 12
Training loss: 0.27720779180526733
Validation loss: 2.0569744308789573

Epoch: 6| Step: 13
Training loss: 0.20703071355819702
Validation loss: 2.0875576535860696

Epoch: 372| Step: 0
Training loss: 0.21231979131698608
Validation loss: 2.062798718611399

Epoch: 6| Step: 1
Training loss: 0.43388357758522034
Validation loss: 2.0557867685953775

Epoch: 6| Step: 2
Training loss: 0.33374351263046265
Validation loss: 2.104783574740092

Epoch: 6| Step: 3
Training loss: 0.3299705684185028
Validation loss: 2.0993544459342957

Epoch: 6| Step: 4
Training loss: 0.13307856023311615
Validation loss: 2.0731426080067954

Epoch: 6| Step: 5
Training loss: 0.5884045362472534
Validation loss: 2.0927698413530984

Epoch: 6| Step: 6
Training loss: 0.17744098603725433
Validation loss: 2.1185439229011536

Epoch: 6| Step: 7
Training loss: 0.24205203354358673
Validation loss: 2.099082112312317

Epoch: 6| Step: 8
Training loss: 0.2695713937282562
Validation loss: 2.0946672757466636

Epoch: 6| Step: 9
Training loss: 0.26627665758132935
Validation loss: 2.0925820072491965

Epoch: 6| Step: 10
Training loss: 0.19646859169006348
Validation loss: 2.0625800093015036

Epoch: 6| Step: 11
Training loss: 0.09447097778320312
Validation loss: 2.123397489388784

Epoch: 6| Step: 12
Training loss: 0.32284367084503174
Validation loss: 2.1065975427627563

Epoch: 6| Step: 13
Training loss: 0.3570238947868347
Validation loss: 2.0781850020090737

Epoch: 373| Step: 0
Training loss: 0.20612746477127075
Validation loss: 2.095527231693268

Epoch: 6| Step: 1
Training loss: 0.17401956021785736
Validation loss: 2.074619948863983

Epoch: 6| Step: 2
Training loss: 0.1935136318206787
Validation loss: 2.1321274439493814

Epoch: 6| Step: 3
Training loss: 0.2509347200393677
Validation loss: 2.112587849299113

Epoch: 6| Step: 4
Training loss: 0.2770145535469055
Validation loss: 2.1058820486068726

Epoch: 6| Step: 5
Training loss: 0.35674500465393066
Validation loss: 2.0731323758761087

Epoch: 6| Step: 6
Training loss: 0.22005026042461395
Validation loss: 2.0559153159459433

Epoch: 6| Step: 7
Training loss: 0.19262441992759705
Validation loss: 2.0763575434684753

Epoch: 6| Step: 8
Training loss: 0.6706488728523254
Validation loss: 2.047209858894348

Epoch: 6| Step: 9
Training loss: 0.4962617754936218
Validation loss: 2.0461339354515076

Epoch: 6| Step: 10
Training loss: 0.2900373041629791
Validation loss: 2.029017925262451

Epoch: 6| Step: 11
Training loss: 0.45928409695625305
Validation loss: 2.040046195189158

Epoch: 6| Step: 12
Training loss: 0.26611658930778503
Validation loss: 2.0610005458196006

Epoch: 6| Step: 13
Training loss: 0.16578854620456696
Validation loss: 2.0571454564730325

Epoch: 374| Step: 0
Training loss: 0.2513570189476013
Validation loss: 2.112994054953257

Epoch: 6| Step: 1
Training loss: 0.3401780128479004
Validation loss: 2.0724802215894065

Epoch: 6| Step: 2
Training loss: 0.21596719324588776
Validation loss: 2.1088011463483176

Epoch: 6| Step: 3
Training loss: 0.18689432740211487
Validation loss: 2.085658689339956

Epoch: 6| Step: 4
Training loss: 0.6572574377059937
Validation loss: 2.02922652165095

Epoch: 6| Step: 5
Training loss: 0.1878332495689392
Validation loss: 2.0791088342666626

Epoch: 6| Step: 6
Training loss: 0.32036957144737244
Validation loss: 2.045838634173075

Epoch: 6| Step: 7
Training loss: 0.28468433022499084
Validation loss: 2.075038810571035

Epoch: 6| Step: 8
Training loss: 0.17009718716144562
Validation loss: 2.085635999838511

Epoch: 6| Step: 9
Training loss: 0.20297151803970337
Validation loss: 2.0519938270250955

Epoch: 6| Step: 10
Training loss: 0.2684192657470703
Validation loss: 2.085216144720713

Epoch: 6| Step: 11
Training loss: 0.35332557559013367
Validation loss: 2.0550100803375244

Epoch: 6| Step: 12
Training loss: 0.28396499156951904
Validation loss: 2.0543706019719443

Epoch: 6| Step: 13
Training loss: 0.23793840408325195
Validation loss: 2.0558438897132874

Epoch: 375| Step: 0
Training loss: 0.297664612531662
Validation loss: 2.0749690930048623

Epoch: 6| Step: 1
Training loss: 0.14190305769443512
Validation loss: 2.0821280479431152

Epoch: 6| Step: 2
Training loss: 0.20486624538898468
Validation loss: 2.0635456244150796

Epoch: 6| Step: 3
Training loss: 0.19291141629219055
Validation loss: 2.097652475039164

Epoch: 6| Step: 4
Training loss: 0.2699521780014038
Validation loss: 2.1305333375930786

Epoch: 6| Step: 5
Training loss: 0.3313570022583008
Validation loss: 2.06338107585907

Epoch: 6| Step: 6
Training loss: 0.22176307439804077
Validation loss: 2.047441999117533

Epoch: 6| Step: 7
Training loss: 0.3860146999359131
Validation loss: 2.0512238144874573

Epoch: 6| Step: 8
Training loss: 0.24351082742214203
Validation loss: 2.0548778573671975

Epoch: 6| Step: 9
Training loss: 0.339590847492218
Validation loss: 2.0807522336641946

Epoch: 6| Step: 10
Training loss: 0.15286113321781158
Validation loss: 2.092204431692759

Epoch: 6| Step: 11
Training loss: 0.18150761723518372
Validation loss: 2.061720331509908

Epoch: 6| Step: 12
Training loss: 0.552199125289917
Validation loss: 2.0680039723714194

Epoch: 6| Step: 13
Training loss: 0.13440042734146118
Validation loss: 2.086911221345266

Epoch: 376| Step: 0
Training loss: 0.2480572909116745
Validation loss: 2.17255429426829

Epoch: 6| Step: 1
Training loss: 0.2636358141899109
Validation loss: 2.1201513409614563

Epoch: 6| Step: 2
Training loss: 0.15825636684894562
Validation loss: 2.064257582028707

Epoch: 6| Step: 3
Training loss: 0.2607986032962799
Validation loss: 2.0514347354571023

Epoch: 6| Step: 4
Training loss: 0.195574551820755
Validation loss: 2.053683559099833

Epoch: 6| Step: 5
Training loss: 0.32692793011665344
Validation loss: 2.04837566614151

Epoch: 6| Step: 6
Training loss: 0.3716272711753845
Validation loss: 2.0621480147043862

Epoch: 6| Step: 7
Training loss: 0.5266887545585632
Validation loss: 2.074657698472341

Epoch: 6| Step: 8
Training loss: 0.18381325900554657
Validation loss: 2.1115227540334067

Epoch: 6| Step: 9
Training loss: 0.2685200572013855
Validation loss: 2.0434170166651406

Epoch: 6| Step: 10
Training loss: 0.2900580167770386
Validation loss: 2.087049146493276

Epoch: 6| Step: 11
Training loss: 0.37145280838012695
Validation loss: 2.0451377828915915

Epoch: 6| Step: 12
Training loss: 0.23506182432174683
Validation loss: 2.044258733590444

Epoch: 6| Step: 13
Training loss: 0.20590317249298096
Validation loss: 2.0579965909322104

Epoch: 377| Step: 0
Training loss: 0.23800157010555267
Validation loss: 2.0702799558639526

Epoch: 6| Step: 1
Training loss: 0.553043007850647
Validation loss: 2.090443968772888

Epoch: 6| Step: 2
Training loss: 0.1817939281463623
Validation loss: 2.0703567266464233

Epoch: 6| Step: 3
Training loss: 0.1640646755695343
Validation loss: 2.06715989112854

Epoch: 6| Step: 4
Training loss: 0.4191094934940338
Validation loss: 2.03140397866567

Epoch: 6| Step: 5
Training loss: 0.22122406959533691
Validation loss: 2.0371325413386026

Epoch: 6| Step: 6
Training loss: 0.2799937129020691
Validation loss: 2.078968902428945

Epoch: 6| Step: 7
Training loss: 0.16647791862487793
Validation loss: 2.0676825245221457

Epoch: 6| Step: 8
Training loss: 0.19894495606422424
Validation loss: 2.0870266954104104

Epoch: 6| Step: 9
Training loss: 0.2819965183734894
Validation loss: 2.0993428031603494

Epoch: 6| Step: 10
Training loss: 0.18034587800502777
Validation loss: 2.0368085503578186

Epoch: 6| Step: 11
Training loss: 0.21000617742538452
Validation loss: 2.0572397907574973

Epoch: 6| Step: 12
Training loss: 0.6196129322052002
Validation loss: 2.063092033068339

Epoch: 6| Step: 13
Training loss: 0.17640356719493866
Validation loss: 2.0937077403068542

Epoch: 378| Step: 0
Training loss: 0.24439674615859985
Validation loss: 2.130384405454

Epoch: 6| Step: 1
Training loss: 0.3124094009399414
Validation loss: 2.1282068888346353

Epoch: 6| Step: 2
Training loss: 0.19280467927455902
Validation loss: 2.118037541707357

Epoch: 6| Step: 3
Training loss: 0.5925070643424988
Validation loss: 2.0844118197758994

Epoch: 6| Step: 4
Training loss: 0.3872849643230438
Validation loss: 2.0729690392812095

Epoch: 6| Step: 5
Training loss: 0.2206721007823944
Validation loss: 2.055867930253347

Epoch: 6| Step: 6
Training loss: 0.20273897051811218
Validation loss: 2.062570949395498

Epoch: 6| Step: 7
Training loss: 0.20077958703041077
Validation loss: 2.0555531978607178

Epoch: 6| Step: 8
Training loss: 0.17257383465766907
Validation loss: 2.0521715879440308

Epoch: 6| Step: 9
Training loss: 0.18254703283309937
Validation loss: 2.0624516805013022

Epoch: 6| Step: 10
Training loss: 0.2087235450744629
Validation loss: 2.047137677669525

Epoch: 6| Step: 11
Training loss: 0.256692111492157
Validation loss: 2.074563503265381

Epoch: 6| Step: 12
Training loss: 0.2569943070411682
Validation loss: 2.060344318548838

Epoch: 6| Step: 13
Training loss: 0.38850104808807373
Validation loss: 2.083159307638804

Epoch: 379| Step: 0
Training loss: 0.15578624606132507
Validation loss: 2.067883531252543

Epoch: 6| Step: 1
Training loss: 0.4386746287345886
Validation loss: 2.101052403450012

Epoch: 6| Step: 2
Training loss: 0.2769481837749481
Validation loss: 2.0854358275731406

Epoch: 6| Step: 3
Training loss: 0.238394096493721
Validation loss: 2.106029450893402

Epoch: 6| Step: 4
Training loss: 0.19729234278202057
Validation loss: 2.1004323760668435

Epoch: 6| Step: 5
Training loss: 0.2489064633846283
Validation loss: 2.0548020005226135

Epoch: 6| Step: 6
Training loss: 0.36978790163993835
Validation loss: 2.076774795850118

Epoch: 6| Step: 7
Training loss: 0.19373515248298645
Validation loss: 2.097515881061554

Epoch: 6| Step: 8
Training loss: 0.6163586974143982
Validation loss: 2.0524392127990723

Epoch: 6| Step: 9
Training loss: 0.16930505633354187
Validation loss: 2.092016359170278

Epoch: 6| Step: 10
Training loss: 0.27811408042907715
Validation loss: 2.095001459121704

Epoch: 6| Step: 11
Training loss: 0.25829583406448364
Validation loss: 2.0594035983085632

Epoch: 6| Step: 12
Training loss: 0.33315110206604004
Validation loss: 2.0873159567515054

Epoch: 6| Step: 13
Training loss: 0.1607242226600647
Validation loss: 2.0940415064493814

Epoch: 380| Step: 0
Training loss: 0.20762167870998383
Validation loss: 2.0848934849103293

Epoch: 6| Step: 1
Training loss: 0.32792723178863525
Validation loss: 2.0786019762357077

Epoch: 6| Step: 2
Training loss: 0.22987455129623413
Validation loss: 2.0832093755404153

Epoch: 6| Step: 3
Training loss: 0.20577862858772278
Validation loss: 2.048353095849355

Epoch: 6| Step: 4
Training loss: 0.18197780847549438
Validation loss: 2.047423164049784

Epoch: 6| Step: 5
Training loss: 0.22994902729988098
Validation loss: 2.0742430488268533

Epoch: 6| Step: 6
Training loss: 0.1726379692554474
Validation loss: 2.031631906827291

Epoch: 6| Step: 7
Training loss: 0.1963546723127365
Validation loss: 2.083197375138601

Epoch: 6| Step: 8
Training loss: 0.33055058121681213
Validation loss: 2.09160848458608

Epoch: 6| Step: 9
Training loss: 0.18115846812725067
Validation loss: 2.06596831480662

Epoch: 6| Step: 10
Training loss: 0.36063796281814575
Validation loss: 2.121160566806793

Epoch: 6| Step: 11
Training loss: 0.2340240329504013
Validation loss: 2.048495610555013

Epoch: 6| Step: 12
Training loss: 0.616246223449707
Validation loss: 2.097898224989573

Epoch: 6| Step: 13
Training loss: 0.25809282064437866
Validation loss: 2.0811819434165955

Epoch: 381| Step: 0
Training loss: 0.23511821031570435
Validation loss: 2.085585912068685

Epoch: 6| Step: 1
Training loss: 0.25117775797843933
Validation loss: 2.1002024213473

Epoch: 6| Step: 2
Training loss: 0.10857947915792465
Validation loss: 2.086603124936422

Epoch: 6| Step: 3
Training loss: 0.186378613114357
Validation loss: 2.0865477124849954

Epoch: 6| Step: 4
Training loss: 0.20912842452526093
Validation loss: 2.088452637195587

Epoch: 6| Step: 5
Training loss: 0.23746192455291748
Validation loss: 2.0787032643953958

Epoch: 6| Step: 6
Training loss: 0.3545648455619812
Validation loss: 2.0488051772117615

Epoch: 6| Step: 7
Training loss: 0.16068139672279358
Validation loss: 2.081116000811259

Epoch: 6| Step: 8
Training loss: 0.24278125166893005
Validation loss: 2.06307985385259

Epoch: 6| Step: 9
Training loss: 0.40546441078186035
Validation loss: 2.0767202774683633

Epoch: 6| Step: 10
Training loss: 0.1706850379705429
Validation loss: 2.078691303730011

Epoch: 6| Step: 11
Training loss: 0.6027202606201172
Validation loss: 2.042164981365204

Epoch: 6| Step: 12
Training loss: 0.15560124814510345
Validation loss: 2.0993864933649697

Epoch: 6| Step: 13
Training loss: 0.33505892753601074
Validation loss: 2.099391500155131

Epoch: 382| Step: 0
Training loss: 0.17368830740451813
Validation loss: 2.0742681423823037

Epoch: 6| Step: 1
Training loss: 0.5650187730789185
Validation loss: 2.080565333366394

Epoch: 6| Step: 2
Training loss: 0.1652451753616333
Validation loss: 2.102594017982483

Epoch: 6| Step: 3
Training loss: 0.1525777280330658
Validation loss: 2.089720845222473

Epoch: 6| Step: 4
Training loss: 0.4022251069545746
Validation loss: 2.0956955552101135

Epoch: 6| Step: 5
Training loss: 0.2359902262687683
Validation loss: 2.059767484664917

Epoch: 6| Step: 6
Training loss: 0.23787759244441986
Validation loss: 2.0771949887275696

Epoch: 6| Step: 7
Training loss: 0.17855432629585266
Validation loss: 2.0823738972345986

Epoch: 6| Step: 8
Training loss: 0.2317049205303192
Validation loss: 2.071329434712728

Epoch: 6| Step: 9
Training loss: 0.3311435580253601
Validation loss: 2.0943965315818787

Epoch: 6| Step: 10
Training loss: 0.3189122676849365
Validation loss: 2.1068426171938577

Epoch: 6| Step: 11
Training loss: 0.2268688678741455
Validation loss: 2.060369849205017

Epoch: 6| Step: 12
Training loss: 0.3118128776550293
Validation loss: 2.0733439326286316

Epoch: 6| Step: 13
Training loss: 0.3435060679912567
Validation loss: 2.0877485076586404

Epoch: 383| Step: 0
Training loss: 0.29699742794036865
Validation loss: 2.0678194761276245

Epoch: 6| Step: 1
Training loss: 0.26795417070388794
Validation loss: 2.100931942462921

Epoch: 6| Step: 2
Training loss: 0.7536604404449463
Validation loss: 2.1056056221326194

Epoch: 6| Step: 3
Training loss: 0.37416696548461914
Validation loss: 2.0688268144925437

Epoch: 6| Step: 4
Training loss: 0.13493244349956512
Validation loss: 2.1247947414716086

Epoch: 6| Step: 5
Training loss: 0.18691284954547882
Validation loss: 2.0727434158325195

Epoch: 6| Step: 6
Training loss: 0.27025923132896423
Validation loss: 2.0532768766085305

Epoch: 6| Step: 7
Training loss: 0.3181474208831787
Validation loss: 2.0695040225982666

Epoch: 6| Step: 8
Training loss: 0.31351304054260254
Validation loss: 2.103248397509257

Epoch: 6| Step: 9
Training loss: 0.2034052461385727
Validation loss: 2.0727234880129495

Epoch: 6| Step: 10
Training loss: 0.2567790746688843
Validation loss: 2.0878685315450034

Epoch: 6| Step: 11
Training loss: 0.16061975061893463
Validation loss: 2.08205912510554

Epoch: 6| Step: 12
Training loss: 0.2281799614429474
Validation loss: 2.1026934583981833

Epoch: 6| Step: 13
Training loss: 0.3316991925239563
Validation loss: 2.1269211371739707

Epoch: 384| Step: 0
Training loss: 0.19192878901958466
Validation loss: 2.1338347792625427

Epoch: 6| Step: 1
Training loss: 0.15663409233093262
Validation loss: 2.081607004006704

Epoch: 6| Step: 2
Training loss: 0.19511646032333374
Validation loss: 2.0732571482658386

Epoch: 6| Step: 3
Training loss: 0.29911553859710693
Validation loss: 2.0890814860661826

Epoch: 6| Step: 4
Training loss: 0.20163969695568085
Validation loss: 2.059939901034037

Epoch: 6| Step: 5
Training loss: 0.1894751787185669
Validation loss: 2.0550885001818338

Epoch: 6| Step: 6
Training loss: 0.34853827953338623
Validation loss: 2.1037229100863137

Epoch: 6| Step: 7
Training loss: 0.3037419319152832
Validation loss: 2.0517843763033548

Epoch: 6| Step: 8
Training loss: 0.20940861105918884
Validation loss: 2.0909365018208823

Epoch: 6| Step: 9
Training loss: 0.3109755516052246
Validation loss: 2.099812686443329

Epoch: 6| Step: 10
Training loss: 0.2998916506767273
Validation loss: 2.1190763115882874

Epoch: 6| Step: 11
Training loss: 0.1965785175561905
Validation loss: 2.0870793660481772

Epoch: 6| Step: 12
Training loss: 0.6468803882598877
Validation loss: 2.0745428999265036

Epoch: 6| Step: 13
Training loss: 0.5148760080337524
Validation loss: 2.0877604484558105

Epoch: 385| Step: 0
Training loss: 0.19317784905433655
Validation loss: 2.1119067470232644

Epoch: 6| Step: 1
Training loss: 0.1771724820137024
Validation loss: 2.077120820681254

Epoch: 6| Step: 2
Training loss: 0.18696101009845734
Validation loss: 2.10206800699234

Epoch: 6| Step: 3
Training loss: 0.17318543791770935
Validation loss: 2.093128581841787

Epoch: 6| Step: 4
Training loss: 0.18922363221645355
Validation loss: 2.0928659041722617

Epoch: 6| Step: 5
Training loss: 0.1829899102449417
Validation loss: 2.0541493892669678

Epoch: 6| Step: 6
Training loss: 0.20879748463630676
Validation loss: 2.0609063704808555

Epoch: 6| Step: 7
Training loss: 0.4175873100757599
Validation loss: 2.0878824989000955

Epoch: 6| Step: 8
Training loss: 0.5471603870391846
Validation loss: 2.097629209359487

Epoch: 6| Step: 9
Training loss: 0.24990543723106384
Validation loss: 2.0866803725560508

Epoch: 6| Step: 10
Training loss: 0.2914994955062866
Validation loss: 2.14588330189387

Epoch: 6| Step: 11
Training loss: 0.3578963279724121
Validation loss: 2.161807398001353

Epoch: 6| Step: 12
Training loss: 0.3754504919052124
Validation loss: 2.173565665880839

Epoch: 6| Step: 13
Training loss: 0.36401844024658203
Validation loss: 2.148455798625946

Epoch: 386| Step: 0
Training loss: 0.35474100708961487
Validation loss: 2.1264732082684836

Epoch: 6| Step: 1
Training loss: 0.20493674278259277
Validation loss: 2.0927052895228067

Epoch: 6| Step: 2
Training loss: 0.2155892699956894
Validation loss: 2.0723277727762857

Epoch: 6| Step: 3
Training loss: 0.16029560565948486
Validation loss: 2.102417012055715

Epoch: 6| Step: 4
Training loss: 0.4353105425834656
Validation loss: 2.051789482434591

Epoch: 6| Step: 5
Training loss: 0.211892768740654
Validation loss: 2.106244206428528

Epoch: 6| Step: 6
Training loss: 0.17922133207321167
Validation loss: 2.073012411594391

Epoch: 6| Step: 7
Training loss: 0.22501489520072937
Validation loss: 2.0714897910753884

Epoch: 6| Step: 8
Training loss: 0.6307942867279053
Validation loss: 2.1079719265302024

Epoch: 6| Step: 9
Training loss: 0.18856854736804962
Validation loss: 2.1138648788134256

Epoch: 6| Step: 10
Training loss: 0.25179606676101685
Validation loss: 2.108365774154663

Epoch: 6| Step: 11
Training loss: 0.20627477765083313
Validation loss: 2.0766752560933432

Epoch: 6| Step: 12
Training loss: 0.21104097366333008
Validation loss: 2.085320154825846

Epoch: 6| Step: 13
Training loss: 0.40864068269729614
Validation loss: 2.046034296353658

Epoch: 387| Step: 0
Training loss: 0.30180037021636963
Validation loss: 2.070917805035909

Epoch: 6| Step: 1
Training loss: 0.3840796947479248
Validation loss: 2.061980148156484

Epoch: 6| Step: 2
Training loss: 0.26910144090652466
Validation loss: 2.0578929583231607

Epoch: 6| Step: 3
Training loss: 0.5931246876716614
Validation loss: 2.080263078212738

Epoch: 6| Step: 4
Training loss: 0.1497713178396225
Validation loss: 2.06397553284963

Epoch: 6| Step: 5
Training loss: 0.287405788898468
Validation loss: 2.0908194382985434

Epoch: 6| Step: 6
Training loss: 0.34070903062820435
Validation loss: 2.0734164714813232

Epoch: 6| Step: 7
Training loss: 0.24593400955200195
Validation loss: 2.035711109638214

Epoch: 6| Step: 8
Training loss: 0.14749789237976074
Validation loss: 2.0926540891329446

Epoch: 6| Step: 9
Training loss: 0.24485468864440918
Validation loss: 2.0626571575800576

Epoch: 6| Step: 10
Training loss: 0.27644574642181396
Validation loss: 2.050654093424479

Epoch: 6| Step: 11
Training loss: 0.12468545138835907
Validation loss: 2.0949284434318542

Epoch: 6| Step: 12
Training loss: 0.10436517745256424
Validation loss: 2.087219794591268

Epoch: 6| Step: 13
Training loss: 0.2699206471443176
Validation loss: 2.0734949111938477

Epoch: 388| Step: 0
Training loss: 0.2227923572063446
Validation loss: 2.1081627011299133

Epoch: 6| Step: 1
Training loss: 0.18578779697418213
Validation loss: 2.109441598256429

Epoch: 6| Step: 2
Training loss: 0.2572939991950989
Validation loss: 2.0824233094851174

Epoch: 6| Step: 3
Training loss: 0.20434395968914032
Validation loss: 2.094691256682078

Epoch: 6| Step: 4
Training loss: 0.11808161437511444
Validation loss: 2.074264566103617

Epoch: 6| Step: 5
Training loss: 0.7931516170501709
Validation loss: 2.0508219798405967

Epoch: 6| Step: 6
Training loss: 0.22039391100406647
Validation loss: 2.11189603805542

Epoch: 6| Step: 7
Training loss: 0.27434685826301575
Validation loss: 2.0658450921376548

Epoch: 6| Step: 8
Training loss: 0.1397133469581604
Validation loss: 2.0584426522254944

Epoch: 6| Step: 9
Training loss: 0.25474217534065247
Validation loss: 2.071898639202118

Epoch: 6| Step: 10
Training loss: 0.29005080461502075
Validation loss: 2.0960095524787903

Epoch: 6| Step: 11
Training loss: 0.27246540784835815
Validation loss: 2.0639741818110147

Epoch: 6| Step: 12
Training loss: 0.16107282042503357
Validation loss: 2.0918299555778503

Epoch: 6| Step: 13
Training loss: 0.194509357213974
Validation loss: 2.0936814546585083

Epoch: 389| Step: 0
Training loss: 0.20584070682525635
Validation loss: 2.0451663931210837

Epoch: 6| Step: 1
Training loss: 0.20599335432052612
Validation loss: 2.087241470813751

Epoch: 6| Step: 2
Training loss: 0.15468500554561615
Validation loss: 2.0689516266187034

Epoch: 6| Step: 3
Training loss: 0.6403496861457825
Validation loss: 2.1008678674697876

Epoch: 6| Step: 4
Training loss: 0.3406662940979004
Validation loss: 2.1087516148885093

Epoch: 6| Step: 5
Training loss: 0.19257359206676483
Validation loss: 2.107311407725016

Epoch: 6| Step: 6
Training loss: 0.3046482801437378
Validation loss: 2.0906766851743064

Epoch: 6| Step: 7
Training loss: 0.2811526954174042
Validation loss: 2.0696940422058105

Epoch: 6| Step: 8
Training loss: 0.2284562587738037
Validation loss: 2.0710322062174478

Epoch: 6| Step: 9
Training loss: 0.4226480722427368
Validation loss: 2.1148741443951926

Epoch: 6| Step: 10
Training loss: 0.2126050740480423
Validation loss: 2.058055102825165

Epoch: 6| Step: 11
Training loss: 0.2984497845172882
Validation loss: 2.04982860883077

Epoch: 6| Step: 12
Training loss: 0.1791118085384369
Validation loss: 2.0765925645828247

Epoch: 6| Step: 13
Training loss: 0.2087213099002838
Validation loss: 2.0688236157099404

Epoch: 390| Step: 0
Training loss: 0.14938770234584808
Validation loss: 2.0737462242444358

Epoch: 6| Step: 1
Training loss: 0.16248196363449097
Validation loss: 2.0764976342519126

Epoch: 6| Step: 2
Training loss: 0.23875850439071655
Validation loss: 2.034891347090403

Epoch: 6| Step: 3
Training loss: 0.3156135678291321
Validation loss: 2.0449111461639404

Epoch: 6| Step: 4
Training loss: 0.1816023588180542
Validation loss: 2.087705969810486

Epoch: 6| Step: 5
Training loss: 0.337074875831604
Validation loss: 2.065962473551432

Epoch: 6| Step: 6
Training loss: 0.26259204745292664
Validation loss: 2.05617622534434

Epoch: 6| Step: 7
Training loss: 0.19393642246723175
Validation loss: 2.054696242014567

Epoch: 6| Step: 8
Training loss: 0.8507022857666016
Validation loss: 2.054517388343811

Epoch: 6| Step: 9
Training loss: 0.1944928914308548
Validation loss: 2.094303250312805

Epoch: 6| Step: 10
Training loss: 0.19227862358093262
Validation loss: 2.0816046396891275

Epoch: 6| Step: 11
Training loss: 0.15024681389331818
Validation loss: 2.038817842801412

Epoch: 6| Step: 12
Training loss: 0.28998252749443054
Validation loss: 2.092072824637095

Epoch: 6| Step: 13
Training loss: 0.2406177669763565
Validation loss: 2.1119752128918967

Epoch: 391| Step: 0
Training loss: 0.362923800945282
Validation loss: 2.121547838052114

Epoch: 6| Step: 1
Training loss: 0.2114446610212326
Validation loss: 2.128576934337616

Epoch: 6| Step: 2
Training loss: 0.1861875355243683
Validation loss: 2.1229196389516196

Epoch: 6| Step: 3
Training loss: 0.13506382703781128
Validation loss: 2.109854737917582

Epoch: 6| Step: 4
Training loss: 0.20397286117076874
Validation loss: 2.106316924095154

Epoch: 6| Step: 5
Training loss: 0.6458070278167725
Validation loss: 2.070208708445231

Epoch: 6| Step: 6
Training loss: 0.23582279682159424
Validation loss: 2.0986618200937905

Epoch: 6| Step: 7
Training loss: 0.24781686067581177
Validation loss: 2.0482673247655234

Epoch: 6| Step: 8
Training loss: 0.4315680265426636
Validation loss: 2.1318158904711404

Epoch: 6| Step: 9
Training loss: 0.23010236024856567
Validation loss: 2.10856686035792

Epoch: 6| Step: 10
Training loss: 0.2930673658847809
Validation loss: 2.0728172858556113

Epoch: 6| Step: 11
Training loss: 0.2500634789466858
Validation loss: 2.05754820505778

Epoch: 6| Step: 12
Training loss: 0.25234630703926086
Validation loss: 2.0688303112983704

Epoch: 6| Step: 13
Training loss: 0.29652756452560425
Validation loss: 2.084710737069448

Epoch: 392| Step: 0
Training loss: 0.16841623187065125
Validation loss: 2.085811197757721

Epoch: 6| Step: 1
Training loss: 0.6482023596763611
Validation loss: 2.092261016368866

Epoch: 6| Step: 2
Training loss: 0.25677192211151123
Validation loss: 2.0727043549219766

Epoch: 6| Step: 3
Training loss: 0.26534056663513184
Validation loss: 2.0636045138041177

Epoch: 6| Step: 4
Training loss: 0.2560463845729828
Validation loss: 2.1185578306516013

Epoch: 6| Step: 5
Training loss: 0.21056309342384338
Validation loss: 2.090340336163839

Epoch: 6| Step: 6
Training loss: 0.17680321633815765
Validation loss: 2.0342907508214316

Epoch: 6| Step: 7
Training loss: 0.2575382590293884
Validation loss: 2.009624461332957

Epoch: 6| Step: 8
Training loss: 0.5584028363227844
Validation loss: 2.023363947868347

Epoch: 6| Step: 9
Training loss: 0.2500123977661133
Validation loss: 2.0819011330604553

Epoch: 6| Step: 10
Training loss: 0.33696335554122925
Validation loss: 2.062978227933248

Epoch: 6| Step: 11
Training loss: 0.23414166271686554
Validation loss: 2.0398890177408853

Epoch: 6| Step: 12
Training loss: 0.3314601182937622
Validation loss: 2.0602304339408875

Epoch: 6| Step: 13
Training loss: 0.2777775824069977
Validation loss: 2.1128296852111816

Epoch: 393| Step: 0
Training loss: 0.24875099956989288
Validation loss: 2.0957635243733725

Epoch: 6| Step: 1
Training loss: 0.4250582456588745
Validation loss: 2.1082564194997153

Epoch: 6| Step: 2
Training loss: 0.3508871793746948
Validation loss: 2.076750715573629

Epoch: 6| Step: 3
Training loss: 0.28263914585113525
Validation loss: 2.0860167145729065

Epoch: 6| Step: 4
Training loss: 0.21600697934627533
Validation loss: 2.066292623678843

Epoch: 6| Step: 5
Training loss: 0.4742389917373657
Validation loss: 2.0244924426078796

Epoch: 6| Step: 6
Training loss: 0.1826629340648651
Validation loss: 2.047120749950409

Epoch: 6| Step: 7
Training loss: 0.6838740110397339
Validation loss: 2.09466952085495

Epoch: 6| Step: 8
Training loss: 0.2649036645889282
Validation loss: 2.075065533320109

Epoch: 6| Step: 9
Training loss: 0.2758880853652954
Validation loss: 2.093052605787913

Epoch: 6| Step: 10
Training loss: 0.2222198247909546
Validation loss: 2.09497332572937

Epoch: 6| Step: 11
Training loss: 0.20035117864608765
Validation loss: 2.0810561577479043

Epoch: 6| Step: 12
Training loss: 0.3350740969181061
Validation loss: 2.135603884855906

Epoch: 6| Step: 13
Training loss: 0.2823438048362732
Validation loss: 2.095866004625956

Epoch: 394| Step: 0
Training loss: 0.37983348965644836
Validation loss: 2.0996557474136353

Epoch: 6| Step: 1
Training loss: 0.24066904187202454
Validation loss: 2.1137101451555886

Epoch: 6| Step: 2
Training loss: 0.34147191047668457
Validation loss: 2.048644224802653

Epoch: 6| Step: 3
Training loss: 0.28776901960372925
Validation loss: 2.0968662103017173

Epoch: 6| Step: 4
Training loss: 0.11871005594730377
Validation loss: 2.114363352457682

Epoch: 6| Step: 5
Training loss: 0.20083627104759216
Validation loss: 2.0831312934557595

Epoch: 6| Step: 6
Training loss: 0.19798950850963593
Validation loss: 2.0758641958236694

Epoch: 6| Step: 7
Training loss: 0.2501599192619324
Validation loss: 2.105901837348938

Epoch: 6| Step: 8
Training loss: 0.585129976272583
Validation loss: 2.1060446898142495

Epoch: 6| Step: 9
Training loss: 0.3949643671512604
Validation loss: 2.090890049934387

Epoch: 6| Step: 10
Training loss: 0.23258687555789948
Validation loss: 2.1088319619496665

Epoch: 6| Step: 11
Training loss: 0.22108042240142822
Validation loss: 2.074338674545288

Epoch: 6| Step: 12
Training loss: 0.23073917627334595
Validation loss: 2.069295366605123

Epoch: 6| Step: 13
Training loss: 0.29527151584625244
Validation loss: 2.056532561779022

Epoch: 395| Step: 0
Training loss: 0.2729042172431946
Validation loss: 2.024395167827606

Epoch: 6| Step: 1
Training loss: 0.4387917220592499
Validation loss: 2.0596257050832114

Epoch: 6| Step: 2
Training loss: 0.16608116030693054
Validation loss: 2.0792237718900046

Epoch: 6| Step: 3
Training loss: 0.18266509473323822
Validation loss: 2.108241558074951

Epoch: 6| Step: 4
Training loss: 0.5728575587272644
Validation loss: 2.09245628118515

Epoch: 6| Step: 5
Training loss: 0.2646794319152832
Validation loss: 2.0536125898361206

Epoch: 6| Step: 6
Training loss: 0.24252349138259888
Validation loss: 2.0544824798901877

Epoch: 6| Step: 7
Training loss: 0.2852146625518799
Validation loss: 2.086851477622986

Epoch: 6| Step: 8
Training loss: 0.42552852630615234
Validation loss: 2.102144996325175

Epoch: 6| Step: 9
Training loss: 0.16629816591739655
Validation loss: 2.07337894042333

Epoch: 6| Step: 10
Training loss: 0.15290145576000214
Validation loss: 2.0295512278874717

Epoch: 6| Step: 11
Training loss: 0.16854751110076904
Validation loss: 2.0804075400034585

Epoch: 6| Step: 12
Training loss: 0.24281099438667297
Validation loss: 2.015817324320475

Epoch: 6| Step: 13
Training loss: 0.30100029706954956
Validation loss: 2.0700881481170654

Epoch: 396| Step: 0
Training loss: 0.7335336804389954
Validation loss: 2.0551847219467163

Epoch: 6| Step: 1
Training loss: 0.2400755137205124
Validation loss: 2.061657726764679

Epoch: 6| Step: 2
Training loss: 0.22249644994735718
Validation loss: 2.02122300863266

Epoch: 6| Step: 3
Training loss: 0.16037234663963318
Validation loss: 2.0737239519755044

Epoch: 6| Step: 4
Training loss: 0.42854738235473633
Validation loss: 2.135850807030996

Epoch: 6| Step: 5
Training loss: 0.2930516004562378
Validation loss: 2.144371291001638

Epoch: 6| Step: 6
Training loss: 0.36082085967063904
Validation loss: 2.1328991055488586

Epoch: 6| Step: 7
Training loss: 0.31108152866363525
Validation loss: 2.152646025021871

Epoch: 6| Step: 8
Training loss: 0.48540857434272766
Validation loss: 2.080933690071106

Epoch: 6| Step: 9
Training loss: 0.10182955861091614
Validation loss: 2.062449832757314

Epoch: 6| Step: 10
Training loss: 0.3290455639362335
Validation loss: 2.0338290532430015

Epoch: 6| Step: 11
Training loss: 0.35687386989593506
Validation loss: 2.068754335244497

Epoch: 6| Step: 12
Training loss: 0.3679293990135193
Validation loss: 2.0637232263882956

Epoch: 6| Step: 13
Training loss: 0.2607637643814087
Validation loss: 2.0599826773007712

Epoch: 397| Step: 0
Training loss: 0.3248380124568939
Validation loss: 2.0998658339182534

Epoch: 6| Step: 1
Training loss: 0.2457398921251297
Validation loss: 2.077232241630554

Epoch: 6| Step: 2
Training loss: 0.38493284583091736
Validation loss: 2.0397796630859375

Epoch: 6| Step: 3
Training loss: 0.6445239782333374
Validation loss: 2.1573448975880942

Epoch: 6| Step: 4
Training loss: 0.2687671482563019
Validation loss: 2.155301292737325

Epoch: 6| Step: 5
Training loss: 0.21756701171398163
Validation loss: 2.112220068772634

Epoch: 6| Step: 6
Training loss: 0.2213972508907318
Validation loss: 2.092732528845469

Epoch: 6| Step: 7
Training loss: 0.2017122209072113
Validation loss: 2.082923193772634

Epoch: 6| Step: 8
Training loss: 0.25072818994522095
Validation loss: 2.0640199184417725

Epoch: 6| Step: 9
Training loss: 0.24269291758537292
Validation loss: 2.0378825267155967

Epoch: 6| Step: 10
Training loss: 0.2422894835472107
Validation loss: 2.056463340918223

Epoch: 6| Step: 11
Training loss: 0.3444330096244812
Validation loss: 2.0650225480397544

Epoch: 6| Step: 12
Training loss: 0.26634538173675537
Validation loss: 2.053811530272166

Epoch: 6| Step: 13
Training loss: 0.2492506504058838
Validation loss: 2.1102272272109985

Epoch: 398| Step: 0
Training loss: 0.19976688921451569
Validation loss: 2.049071113268534

Epoch: 6| Step: 1
Training loss: 0.24050232768058777
Validation loss: 2.0507250229517617

Epoch: 6| Step: 2
Training loss: 0.25420641899108887
Validation loss: 2.0855277379353843

Epoch: 6| Step: 3
Training loss: 0.2560209333896637
Validation loss: 2.059845248858134

Epoch: 6| Step: 4
Training loss: 0.3846242427825928
Validation loss: 2.084370732307434

Epoch: 6| Step: 5
Training loss: 0.22451408207416534
Validation loss: 2.096564749876658

Epoch: 6| Step: 6
Training loss: 0.20626585185527802
Validation loss: 2.0789965391159058

Epoch: 6| Step: 7
Training loss: 0.24212537705898285
Validation loss: 2.067971189816793

Epoch: 6| Step: 8
Training loss: 0.7979831695556641
Validation loss: 2.0880624453226724

Epoch: 6| Step: 9
Training loss: 0.24386096000671387
Validation loss: 2.0524390935897827

Epoch: 6| Step: 10
Training loss: 0.3341796100139618
Validation loss: 2.041265924771627

Epoch: 6| Step: 11
Training loss: 0.21534039080142975
Validation loss: 2.090664724508921

Epoch: 6| Step: 12
Training loss: 0.236467182636261
Validation loss: 2.0499863823254905

Epoch: 6| Step: 13
Training loss: 0.1769520491361618
Validation loss: 2.093331237634023

Epoch: 399| Step: 0
Training loss: 0.19347751140594482
Validation loss: 2.1004262963930764

Epoch: 6| Step: 1
Training loss: 0.24728456139564514
Validation loss: 2.071474631627401

Epoch: 6| Step: 2
Training loss: 0.763170599937439
Validation loss: 2.0538305044174194

Epoch: 6| Step: 3
Training loss: 0.17535161972045898
Validation loss: 2.103748917579651

Epoch: 6| Step: 4
Training loss: 0.2342243492603302
Validation loss: 2.119062582651774

Epoch: 6| Step: 5
Training loss: 0.27266064286231995
Validation loss: 2.060331126054128

Epoch: 6| Step: 6
Training loss: 0.12396089732646942
Validation loss: 2.108904222647349

Epoch: 6| Step: 7
Training loss: 0.1999835968017578
Validation loss: 2.104107220967611

Epoch: 6| Step: 8
Training loss: 0.36610737442970276
Validation loss: 2.077028274536133

Epoch: 6| Step: 9
Training loss: 0.20591336488723755
Validation loss: 2.1021483540534973

Epoch: 6| Step: 10
Training loss: 0.147678405046463
Validation loss: 2.111762583255768

Epoch: 6| Step: 11
Training loss: 0.21666598320007324
Validation loss: 2.0838948686917624

Epoch: 6| Step: 12
Training loss: 0.20485004782676697
Validation loss: 2.116766174634298

Epoch: 6| Step: 13
Training loss: 0.22269707918167114
Validation loss: 2.1290619373321533

Epoch: 400| Step: 0
Training loss: 0.36350613832473755
Validation loss: 2.0318396290143332

Epoch: 6| Step: 1
Training loss: 0.29155391454696655
Validation loss: 2.069476008415222

Epoch: 6| Step: 2
Training loss: 0.23262229561805725
Validation loss: 2.073285679022471

Epoch: 6| Step: 3
Training loss: 0.21703827381134033
Validation loss: 2.0687952836354575

Epoch: 6| Step: 4
Training loss: 0.18237096071243286
Validation loss: 2.1094427506128945

Epoch: 6| Step: 5
Training loss: 0.32155805826187134
Validation loss: 2.088692625363668

Epoch: 6| Step: 6
Training loss: 0.27361801266670227
Validation loss: 2.1338109970092773

Epoch: 6| Step: 7
Training loss: 0.29988008737564087
Validation loss: 2.1395157178243003

Epoch: 6| Step: 8
Training loss: 0.3145517110824585
Validation loss: 2.1135881344477334

Epoch: 6| Step: 9
Training loss: 0.21488089859485626
Validation loss: 2.097173829873403

Epoch: 6| Step: 10
Training loss: 0.14949187636375427
Validation loss: 2.076948344707489

Epoch: 6| Step: 11
Training loss: 0.5400709509849548
Validation loss: 2.063867171605428

Epoch: 6| Step: 12
Training loss: 0.3485143184661865
Validation loss: 2.0668633182843528

Epoch: 6| Step: 13
Training loss: 0.31703993678092957
Validation loss: 2.0502776503562927

Epoch: 401| Step: 0
Training loss: 0.3948993682861328
Validation loss: 2.091609835624695

Epoch: 6| Step: 1
Training loss: 0.3640763461589813
Validation loss: 2.0544431606928506

Epoch: 6| Step: 2
Training loss: 0.2808937728404999
Validation loss: 2.0544909834861755

Epoch: 6| Step: 3
Training loss: 0.2990742027759552
Validation loss: 2.082000970840454

Epoch: 6| Step: 4
Training loss: 0.24273435771465302
Validation loss: 2.0724594394365945

Epoch: 6| Step: 5
Training loss: 0.20510120689868927
Validation loss: 2.084222396214803

Epoch: 6| Step: 6
Training loss: 0.22638803720474243
Validation loss: 2.0580806334813437

Epoch: 6| Step: 7
Training loss: 0.21800893545150757
Validation loss: 2.064147194226583

Epoch: 6| Step: 8
Training loss: 0.24734540283679962
Validation loss: 2.0867246985435486

Epoch: 6| Step: 9
Training loss: 0.2698712944984436
Validation loss: 2.0277006228764853

Epoch: 6| Step: 10
Training loss: 0.3191014528274536
Validation loss: 2.069278617699941

Epoch: 6| Step: 11
Training loss: 0.28969836235046387
Validation loss: 2.0582287311553955

Epoch: 6| Step: 12
Training loss: 0.1826138198375702
Validation loss: 2.0636537671089172

Epoch: 6| Step: 13
Training loss: 0.6547120809555054
Validation loss: 2.0471396446228027

Epoch: 402| Step: 0
Training loss: 0.233987495303154
Validation loss: 2.0596572756767273

Epoch: 6| Step: 1
Training loss: 0.24784702062606812
Validation loss: 2.089568078517914

Epoch: 6| Step: 2
Training loss: 0.2505471408367157
Validation loss: 2.0952384074529014

Epoch: 6| Step: 3
Training loss: 0.20147788524627686
Validation loss: 2.09346612294515

Epoch: 6| Step: 4
Training loss: 0.1843598335981369
Validation loss: 2.0916948318481445

Epoch: 6| Step: 5
Training loss: 0.1664591133594513
Validation loss: 2.0839035709698996

Epoch: 6| Step: 6
Training loss: 0.8297354578971863
Validation loss: 2.087055047353109

Epoch: 6| Step: 7
Training loss: 0.23314769566059113
Validation loss: 2.055359423160553

Epoch: 6| Step: 8
Training loss: 0.14701439440250397
Validation loss: 2.0920488039652505

Epoch: 6| Step: 9
Training loss: 0.17705723643302917
Validation loss: 2.08584855000178

Epoch: 6| Step: 10
Training loss: 0.15789680182933807
Validation loss: 2.075292944908142

Epoch: 6| Step: 11
Training loss: 0.24174822866916656
Validation loss: 2.1072779099146524

Epoch: 6| Step: 12
Training loss: 0.2070728838443756
Validation loss: 2.074107050895691

Epoch: 6| Step: 13
Training loss: 0.24415135383605957
Validation loss: 2.07232528924942

Epoch: 403| Step: 0
Training loss: 0.23986509442329407
Validation loss: 2.0957064827283225

Epoch: 6| Step: 1
Training loss: 0.2374381124973297
Validation loss: 2.099266072114309

Epoch: 6| Step: 2
Training loss: 0.1579715758562088
Validation loss: 2.0966235796610513

Epoch: 6| Step: 3
Training loss: 0.2275686264038086
Validation loss: 2.0761406620343528

Epoch: 6| Step: 4
Training loss: 0.15961599349975586
Validation loss: 2.0563297669092813

Epoch: 6| Step: 5
Training loss: 0.16123183071613312
Validation loss: 2.07353542248408

Epoch: 6| Step: 6
Training loss: 0.1569283902645111
Validation loss: 2.0081560015678406

Epoch: 6| Step: 7
Training loss: 0.5436137914657593
Validation loss: 2.0719381173451743

Epoch: 6| Step: 8
Training loss: 0.17330604791641235
Validation loss: 2.0235645373662314

Epoch: 6| Step: 9
Training loss: 0.33552128076553345
Validation loss: 2.047493596871694

Epoch: 6| Step: 10
Training loss: 0.27319976687431335
Validation loss: 2.0819844404856362

Epoch: 6| Step: 11
Training loss: 0.41770505905151367
Validation loss: 2.06281179189682

Epoch: 6| Step: 12
Training loss: 0.14554186165332794
Validation loss: 2.1016567746798196

Epoch: 6| Step: 13
Training loss: 0.15039090812206268
Validation loss: 2.0436410506566367

Epoch: 404| Step: 0
Training loss: 0.2022342085838318
Validation loss: 2.0590361952781677

Epoch: 6| Step: 1
Training loss: 0.21611054241657257
Validation loss: 2.0277446508407593

Epoch: 6| Step: 2
Training loss: 0.3310966491699219
Validation loss: 2.103655974070231

Epoch: 6| Step: 3
Training loss: 0.2790106534957886
Validation loss: 2.0830425222714744

Epoch: 6| Step: 4
Training loss: 0.3946356177330017
Validation loss: 2.0650638739267984

Epoch: 6| Step: 5
Training loss: 0.18333840370178223
Validation loss: 2.0563666224479675

Epoch: 6| Step: 6
Training loss: 0.190609410405159
Validation loss: 2.058148125807444

Epoch: 6| Step: 7
Training loss: 0.27036941051483154
Validation loss: 2.0755481918652854

Epoch: 6| Step: 8
Training loss: 0.22598090767860413
Validation loss: 2.0902753472328186

Epoch: 6| Step: 9
Training loss: 0.2209356725215912
Validation loss: 2.0844909946123757

Epoch: 6| Step: 10
Training loss: 0.4940890967845917
Validation loss: 2.0525192817052207

Epoch: 6| Step: 11
Training loss: 0.28548985719680786
Validation loss: 2.0909995834032693

Epoch: 6| Step: 12
Training loss: 0.17424537241458893
Validation loss: 2.1287655035654702

Epoch: 6| Step: 13
Training loss: 0.18759530782699585
Validation loss: 2.0514503717422485

Epoch: 405| Step: 0
Training loss: 0.25771364569664
Validation loss: 2.0796542167663574

Epoch: 6| Step: 1
Training loss: 0.22456803917884827
Validation loss: 2.0781662265459695

Epoch: 6| Step: 2
Training loss: 0.2642715871334076
Validation loss: 2.070691088835398

Epoch: 6| Step: 3
Training loss: 0.23404517769813538
Validation loss: 2.1061991850535073

Epoch: 6| Step: 4
Training loss: 0.22168472409248352
Validation loss: 2.0930579900741577

Epoch: 6| Step: 5
Training loss: 0.33929112553596497
Validation loss: 2.082417925198873

Epoch: 6| Step: 6
Training loss: 0.3320987820625305
Validation loss: 2.0802623430887857

Epoch: 6| Step: 7
Training loss: 0.3321973383426666
Validation loss: 2.0800455808639526

Epoch: 6| Step: 8
Training loss: 0.1847429722547531
Validation loss: 2.0756431818008423

Epoch: 6| Step: 9
Training loss: 0.5317620635032654
Validation loss: 2.08485076824824

Epoch: 6| Step: 10
Training loss: 0.19178929924964905
Validation loss: 2.037602742513021

Epoch: 6| Step: 11
Training loss: 0.2908274233341217
Validation loss: 2.087153752644857

Epoch: 6| Step: 12
Training loss: 0.19384169578552246
Validation loss: 2.0883046785990396

Epoch: 6| Step: 13
Training loss: 0.1290566623210907
Validation loss: 2.0999640425046286

Epoch: 406| Step: 0
Training loss: 0.6111931800842285
Validation loss: 2.107313811779022

Epoch: 6| Step: 1
Training loss: 0.14498713612556458
Validation loss: 2.0537473559379578

Epoch: 6| Step: 2
Training loss: 0.3239465355873108
Validation loss: 2.0414093732833862

Epoch: 6| Step: 3
Training loss: 0.26644378900527954
Validation loss: 2.1204782327016196

Epoch: 6| Step: 4
Training loss: 0.29512134194374084
Validation loss: 2.115299622217814

Epoch: 6| Step: 5
Training loss: 0.33121955394744873
Validation loss: 2.0604169766108194

Epoch: 6| Step: 6
Training loss: 0.231521874666214
Validation loss: 2.0847527384757996

Epoch: 6| Step: 7
Training loss: 0.2139153927564621
Validation loss: 2.044891635576884

Epoch: 6| Step: 8
Training loss: 0.16211631894111633
Validation loss: 2.0380125443140664

Epoch: 6| Step: 9
Training loss: 0.17298434674739838
Validation loss: 2.07364829381307

Epoch: 6| Step: 10
Training loss: 0.11381396651268005
Validation loss: 2.0754088759422302

Epoch: 6| Step: 11
Training loss: 0.1669304370880127
Validation loss: 2.0465065439542136

Epoch: 6| Step: 12
Training loss: 0.18347010016441345
Validation loss: 2.0756125450134277

Epoch: 6| Step: 13
Training loss: 0.1972767859697342
Validation loss: 2.080395678679148

Epoch: 407| Step: 0
Training loss: 0.2439366579055786
Validation loss: 2.08144603172938

Epoch: 6| Step: 1
Training loss: 0.24907073378562927
Validation loss: 2.045565664768219

Epoch: 6| Step: 2
Training loss: 0.2668539881706238
Validation loss: 2.0625995794932046

Epoch: 6| Step: 3
Training loss: 0.18407148122787476
Validation loss: 2.048671464125315

Epoch: 6| Step: 4
Training loss: 0.5731220245361328
Validation loss: 2.1060732205708823

Epoch: 6| Step: 5
Training loss: 0.20004409551620483
Validation loss: 2.0913729468981423

Epoch: 6| Step: 6
Training loss: 0.2168407142162323
Validation loss: 2.0760529239972434

Epoch: 6| Step: 7
Training loss: 0.3283533751964569
Validation loss: 2.062157134215037

Epoch: 6| Step: 8
Training loss: 0.1983831226825714
Validation loss: 2.0516289472579956

Epoch: 6| Step: 9
Training loss: 0.22175274789333344
Validation loss: 2.091914097468058

Epoch: 6| Step: 10
Training loss: 0.2848731279373169
Validation loss: 2.099532345930735

Epoch: 6| Step: 11
Training loss: 0.23781828582286835
Validation loss: 2.077109694480896

Epoch: 6| Step: 12
Training loss: 0.25525277853012085
Validation loss: 2.1021474599838257

Epoch: 6| Step: 13
Training loss: 0.20849479734897614
Validation loss: 2.0807414849599204

Epoch: 408| Step: 0
Training loss: 0.37297892570495605
Validation loss: 2.1119726300239563

Epoch: 6| Step: 1
Training loss: 0.25135406851768494
Validation loss: 2.1612507899602256

Epoch: 6| Step: 2
Training loss: 0.26175493001937866
Validation loss: 2.1356683572133384

Epoch: 6| Step: 3
Training loss: 0.18559995293617249
Validation loss: 2.0866345961888633

Epoch: 6| Step: 4
Training loss: 0.22381097078323364
Validation loss: 2.072324971357981

Epoch: 6| Step: 5
Training loss: 0.38216978311538696
Validation loss: 2.080904165903727

Epoch: 6| Step: 6
Training loss: 0.37486082315444946
Validation loss: 2.061383287111918

Epoch: 6| Step: 7
Training loss: 0.1792294681072235
Validation loss: 2.049486597379049

Epoch: 6| Step: 8
Training loss: 0.3186887502670288
Validation loss: 2.059792220592499

Epoch: 6| Step: 9
Training loss: 0.6030035018920898
Validation loss: 2.0428242087364197

Epoch: 6| Step: 10
Training loss: 0.3509649932384491
Validation loss: 2.0614722967147827

Epoch: 6| Step: 11
Training loss: 0.16413971781730652
Validation loss: 2.0444959799448648

Epoch: 6| Step: 12
Training loss: 0.13679268956184387
Validation loss: 2.10984077056249

Epoch: 6| Step: 13
Training loss: 0.176273912191391
Validation loss: 2.0467106699943542

Epoch: 409| Step: 0
Training loss: 0.2252904325723648
Validation loss: 2.0244738856951394

Epoch: 6| Step: 1
Training loss: 0.15354077517986298
Validation loss: 2.035126348336538

Epoch: 6| Step: 2
Training loss: 0.2067142277956009
Validation loss: 2.063685357570648

Epoch: 6| Step: 3
Training loss: 0.22297200560569763
Validation loss: 2.0552815993626914

Epoch: 6| Step: 4
Training loss: 0.2411975860595703
Validation loss: 2.050719221433004

Epoch: 6| Step: 5
Training loss: 0.6312270760536194
Validation loss: 2.0830161968866983

Epoch: 6| Step: 6
Training loss: 0.19511647522449493
Validation loss: 2.0576365192731223

Epoch: 6| Step: 7
Training loss: 0.21275755763053894
Validation loss: 2.0808751781781516

Epoch: 6| Step: 8
Training loss: 0.11349558085203171
Validation loss: 2.1363232533137

Epoch: 6| Step: 9
Training loss: 0.28135648369789124
Validation loss: 2.083006501197815

Epoch: 6| Step: 10
Training loss: 0.1721215397119522
Validation loss: 2.0731645822525024

Epoch: 6| Step: 11
Training loss: 0.18815705180168152
Validation loss: 2.113853653271993

Epoch: 6| Step: 12
Training loss: 0.2209448218345642
Validation loss: 2.1333267291386924

Epoch: 6| Step: 13
Training loss: 0.3976600170135498
Validation loss: 2.083929260571798

Epoch: 410| Step: 0
Training loss: 0.2296534925699234
Validation loss: 2.1141401330629983

Epoch: 6| Step: 1
Training loss: 0.2965295910835266
Validation loss: 2.089140752951304

Epoch: 6| Step: 2
Training loss: 0.20825254917144775
Validation loss: 2.083036462465922

Epoch: 6| Step: 3
Training loss: 0.5580722093582153
Validation loss: 2.1159908771514893

Epoch: 6| Step: 4
Training loss: 0.38875335454940796
Validation loss: 2.133193572362264

Epoch: 6| Step: 5
Training loss: 0.3130018413066864
Validation loss: 2.114996055761973

Epoch: 6| Step: 6
Training loss: 0.23882947862148285
Validation loss: 2.1203365325927734

Epoch: 6| Step: 7
Training loss: 0.20725806057453156
Validation loss: 2.136414090792338

Epoch: 6| Step: 8
Training loss: 0.16245588660240173
Validation loss: 2.132531483968099

Epoch: 6| Step: 9
Training loss: 0.23083871603012085
Validation loss: 2.1175217032432556

Epoch: 6| Step: 10
Training loss: 0.16891264915466309
Validation loss: 2.0870323975880942

Epoch: 6| Step: 11
Training loss: 0.2297874242067337
Validation loss: 2.070699771245321

Epoch: 6| Step: 12
Training loss: 0.22197085618972778
Validation loss: 2.055587967236837

Epoch: 6| Step: 13
Training loss: 0.2749766707420349
Validation loss: 2.0781099597613015

Epoch: 411| Step: 0
Training loss: 0.1821989119052887
Validation loss: 2.041586478551229

Epoch: 6| Step: 1
Training loss: 0.21826940774917603
Validation loss: 2.070268670717875

Epoch: 6| Step: 2
Training loss: 0.16308461129665375
Validation loss: 2.0634849270184836

Epoch: 6| Step: 3
Training loss: 0.2963663339614868
Validation loss: 2.0599366426467896

Epoch: 6| Step: 4
Training loss: 0.31576699018478394
Validation loss: 2.0759583711624146

Epoch: 6| Step: 5
Training loss: 0.23678186535835266
Validation loss: 2.113774915536245

Epoch: 6| Step: 6
Training loss: 0.3012314438819885
Validation loss: 2.0131523609161377

Epoch: 6| Step: 7
Training loss: 0.2638983130455017
Validation loss: 2.0728746255238852

Epoch: 6| Step: 8
Training loss: 0.19442951679229736
Validation loss: 2.0899473230044046

Epoch: 6| Step: 9
Training loss: 0.3683018684387207
Validation loss: 2.0643140077590942

Epoch: 6| Step: 10
Training loss: 0.22979892790317535
Validation loss: 2.0320956707000732

Epoch: 6| Step: 11
Training loss: 0.2577762007713318
Validation loss: 2.091467340787252

Epoch: 6| Step: 12
Training loss: 0.2526012659072876
Validation loss: 2.0400322675704956

Epoch: 6| Step: 13
Training loss: 0.6422560811042786
Validation loss: 2.0518813729286194

Epoch: 412| Step: 0
Training loss: 0.23811891674995422
Validation loss: 2.067871709664663

Epoch: 6| Step: 1
Training loss: 0.28815528750419617
Validation loss: 2.0468859473864236

Epoch: 6| Step: 2
Training loss: 0.2505924105644226
Validation loss: 2.0339497129122415

Epoch: 6| Step: 3
Training loss: 0.19770431518554688
Validation loss: 2.1036102771759033

Epoch: 6| Step: 4
Training loss: 0.33950239419937134
Validation loss: 2.124315063158671

Epoch: 6| Step: 5
Training loss: 0.1611001044511795
Validation loss: 2.104020078976949

Epoch: 6| Step: 6
Training loss: 0.6083115339279175
Validation loss: 2.0941519339879355

Epoch: 6| Step: 7
Training loss: 0.23337393999099731
Validation loss: 2.0766404469807944

Epoch: 6| Step: 8
Training loss: 0.15094754099845886
Validation loss: 2.069150686264038

Epoch: 6| Step: 9
Training loss: 0.40529704093933105
Validation loss: 2.081312874952952

Epoch: 6| Step: 10
Training loss: 0.15594367682933807
Validation loss: 2.12516983350118

Epoch: 6| Step: 11
Training loss: 0.15775185823440552
Validation loss: 2.0928208033243814

Epoch: 6| Step: 12
Training loss: 0.22448405623435974
Validation loss: 2.097816983858744

Epoch: 6| Step: 13
Training loss: 0.1957419514656067
Validation loss: 2.1184112429618835

Epoch: 413| Step: 0
Training loss: 0.2246668040752411
Validation loss: 2.0948927203814187

Epoch: 6| Step: 1
Training loss: 0.19182553887367249
Validation loss: 2.0934426387151084

Epoch: 6| Step: 2
Training loss: 0.6947609186172485
Validation loss: 2.1333842873573303

Epoch: 6| Step: 3
Training loss: 0.2995849847793579
Validation loss: 2.1256654858589172

Epoch: 6| Step: 4
Training loss: 0.1711493730545044
Validation loss: 2.1822397311528525

Epoch: 6| Step: 5
Training loss: 0.18780092895030975
Validation loss: 2.1146642168362937

Epoch: 6| Step: 6
Training loss: 0.21941199898719788
Validation loss: 2.1558661460876465

Epoch: 6| Step: 7
Training loss: 0.22885416448116302
Validation loss: 2.086872100830078

Epoch: 6| Step: 8
Training loss: 0.1963280290365219
Validation loss: 2.131863613923391

Epoch: 6| Step: 9
Training loss: 0.2987971007823944
Validation loss: 2.113412876923879

Epoch: 6| Step: 10
Training loss: 0.3051508665084839
Validation loss: 2.08613383769989

Epoch: 6| Step: 11
Training loss: 0.2256838083267212
Validation loss: 2.1399521827697754

Epoch: 6| Step: 12
Training loss: 0.19947205483913422
Validation loss: 2.1147918899854026

Epoch: 6| Step: 13
Training loss: 0.2841376066207886
Validation loss: 2.0744043389956155

Epoch: 414| Step: 0
Training loss: 0.2768060266971588
Validation loss: 2.1468900442123413

Epoch: 6| Step: 1
Training loss: 0.17375195026397705
Validation loss: 2.156139353911082

Epoch: 6| Step: 2
Training loss: 0.2800811529159546
Validation loss: 2.128823240598043

Epoch: 6| Step: 3
Training loss: 0.5953842401504517
Validation loss: 2.067802309989929

Epoch: 6| Step: 4
Training loss: 0.14168061316013336
Validation loss: 2.1148919661839805

Epoch: 6| Step: 5
Training loss: 0.397176057100296
Validation loss: 2.1274216572443643

Epoch: 6| Step: 6
Training loss: 0.2555912733078003
Validation loss: 2.1041361490885415

Epoch: 6| Step: 7
Training loss: 0.19823908805847168
Validation loss: 2.0979640086491904

Epoch: 6| Step: 8
Training loss: 0.23088479042053223
Validation loss: 2.1092199881871543

Epoch: 6| Step: 9
Training loss: 0.14211973547935486
Validation loss: 2.1054133971532187

Epoch: 6| Step: 10
Training loss: 0.1641928255558014
Validation loss: 2.1280031204223633

Epoch: 6| Step: 11
Training loss: 0.19449935853481293
Validation loss: 2.121540904045105

Epoch: 6| Step: 12
Training loss: 0.14796383678913116
Validation loss: 2.104739507039388

Epoch: 6| Step: 13
Training loss: 0.19264382123947144
Validation loss: 2.0674243370691934

Epoch: 415| Step: 0
Training loss: 0.41387081146240234
Validation loss: 2.109114428361257

Epoch: 6| Step: 1
Training loss: 0.2309090495109558
Validation loss: 2.0662529865900674

Epoch: 6| Step: 2
Training loss: 0.184178426861763
Validation loss: 2.0843751629193625

Epoch: 6| Step: 3
Training loss: 0.2070559710264206
Validation loss: 2.097421944141388

Epoch: 6| Step: 4
Training loss: 0.19498804211616516
Validation loss: 2.073667883872986

Epoch: 6| Step: 5
Training loss: 0.2860780954360962
Validation loss: 2.13027822971344

Epoch: 6| Step: 6
Training loss: 0.2468489408493042
Validation loss: 2.0835277835528054

Epoch: 6| Step: 7
Training loss: 0.24300214648246765
Validation loss: 2.0769140323003135

Epoch: 6| Step: 8
Training loss: 0.5582165718078613
Validation loss: 2.124528169631958

Epoch: 6| Step: 9
Training loss: 0.20703673362731934
Validation loss: 2.0558809439341226

Epoch: 6| Step: 10
Training loss: 0.2814004421234131
Validation loss: 2.0805033445358276

Epoch: 6| Step: 11
Training loss: 0.20270970463752747
Validation loss: 2.0997727314631143

Epoch: 6| Step: 12
Training loss: 0.1952776163816452
Validation loss: 2.068760395050049

Epoch: 6| Step: 13
Training loss: 0.14957982301712036
Validation loss: 2.087333301703135

Epoch: 416| Step: 0
Training loss: 0.5254453420639038
Validation loss: 2.080025772253672

Epoch: 6| Step: 1
Training loss: 0.2964349389076233
Validation loss: 2.075907270113627

Epoch: 6| Step: 2
Training loss: 0.19040389358997345
Validation loss: 2.044244925181071

Epoch: 6| Step: 3
Training loss: 0.20792849361896515
Validation loss: 2.099697232246399

Epoch: 6| Step: 4
Training loss: 0.37765780091285706
Validation loss: 2.087184965610504

Epoch: 6| Step: 5
Training loss: 0.2877441644668579
Validation loss: 2.0736997524897256

Epoch: 6| Step: 6
Training loss: 0.2514040470123291
Validation loss: 2.0644257267316184

Epoch: 6| Step: 7
Training loss: 0.14959554374217987
Validation loss: 2.0728856921195984

Epoch: 6| Step: 8
Training loss: 0.18151673674583435
Validation loss: 2.1009637316068015

Epoch: 6| Step: 9
Training loss: 0.2238663285970688
Validation loss: 2.099111179510752

Epoch: 6| Step: 10
Training loss: 0.31427276134490967
Validation loss: 2.093494951725006

Epoch: 6| Step: 11
Training loss: 0.2281978726387024
Validation loss: 2.105825106302897

Epoch: 6| Step: 12
Training loss: 0.18463337421417236
Validation loss: 2.0961647629737854

Epoch: 6| Step: 13
Training loss: 0.2787435054779053
Validation loss: 2.06626158952713

Epoch: 417| Step: 0
Training loss: 0.17625197768211365
Validation loss: 2.07360045115153

Epoch: 6| Step: 1
Training loss: 0.30623704195022583
Validation loss: 2.0731051762898765

Epoch: 6| Step: 2
Training loss: 0.3915669918060303
Validation loss: 2.0729750792185464

Epoch: 6| Step: 3
Training loss: 0.2107984572649002
Validation loss: 2.0641029874483743

Epoch: 6| Step: 4
Training loss: 0.16572615504264832
Validation loss: 2.0648555954297385

Epoch: 6| Step: 5
Training loss: 0.15380965173244476
Validation loss: 2.126502513885498

Epoch: 6| Step: 6
Training loss: 0.2227959930896759
Validation loss: 2.101598004500071

Epoch: 6| Step: 7
Training loss: 0.18373295664787292
Validation loss: 2.1042900880177817

Epoch: 6| Step: 8
Training loss: 0.15388479828834534
Validation loss: 2.131676892439524

Epoch: 6| Step: 9
Training loss: 0.16847878694534302
Validation loss: 2.133184234301249

Epoch: 6| Step: 10
Training loss: 0.2652454376220703
Validation loss: 2.1128594080607095

Epoch: 6| Step: 11
Training loss: 0.6461108326911926
Validation loss: 2.10431299606959

Epoch: 6| Step: 12
Training loss: 0.29279905557632446
Validation loss: 2.1115167339642844

Epoch: 6| Step: 13
Training loss: 0.2411818653345108
Validation loss: 2.066231369972229

Epoch: 418| Step: 0
Training loss: 0.230364590883255
Validation loss: 2.107088108857473

Epoch: 6| Step: 1
Training loss: 0.434731125831604
Validation loss: 2.090837995211283

Epoch: 6| Step: 2
Training loss: 0.3278534710407257
Validation loss: 2.13467929760615

Epoch: 6| Step: 3
Training loss: 0.2861552834510803
Validation loss: 2.1539840698242188

Epoch: 6| Step: 4
Training loss: 0.17504477500915527
Validation loss: 2.118500828742981

Epoch: 6| Step: 5
Training loss: 0.2571406364440918
Validation loss: 2.148171822230021

Epoch: 6| Step: 6
Training loss: 0.23087573051452637
Validation loss: 2.076712667942047

Epoch: 6| Step: 7
Training loss: 0.20720073580741882
Validation loss: 2.0947791735331216

Epoch: 6| Step: 8
Training loss: 0.22565606236457825
Validation loss: 2.0751320918401084

Epoch: 6| Step: 9
Training loss: 0.6172250509262085
Validation loss: 2.05721382300059

Epoch: 6| Step: 10
Training loss: 0.27917900681495667
Validation loss: 2.0859529773394265

Epoch: 6| Step: 11
Training loss: 0.24225705862045288
Validation loss: 2.0818694829940796

Epoch: 6| Step: 12
Training loss: 0.16394557058811188
Validation loss: 2.082492709159851

Epoch: 6| Step: 13
Training loss: 0.17112578451633453
Validation loss: 2.1128710905710855

Epoch: 419| Step: 0
Training loss: 0.21575888991355896
Validation loss: 2.078103164831797

Epoch: 6| Step: 1
Training loss: 0.14899682998657227
Validation loss: 2.1152323881785073

Epoch: 6| Step: 2
Training loss: 0.19524183869361877
Validation loss: 2.0673828721046448

Epoch: 6| Step: 3
Training loss: 0.18288001418113708
Validation loss: 2.1193772157033286

Epoch: 6| Step: 4
Training loss: 0.729706883430481
Validation loss: 2.053984741369883

Epoch: 6| Step: 5
Training loss: 0.2083534300327301
Validation loss: 2.102871358394623

Epoch: 6| Step: 6
Training loss: 0.13498884439468384
Validation loss: 2.0882723132769265

Epoch: 6| Step: 7
Training loss: 0.24793796241283417
Validation loss: 2.1137654383977256

Epoch: 6| Step: 8
Training loss: 0.2675425112247467
Validation loss: 2.0919724106788635

Epoch: 6| Step: 9
Training loss: 0.353956401348114
Validation loss: 2.1062053442001343

Epoch: 6| Step: 10
Training loss: 0.2884383499622345
Validation loss: 2.083122809727987

Epoch: 6| Step: 11
Training loss: 0.25196218490600586
Validation loss: 2.0717007915178933

Epoch: 6| Step: 12
Training loss: 0.1964019387960434
Validation loss: 2.079773227373759

Epoch: 6| Step: 13
Training loss: 0.17134329676628113
Validation loss: 2.0732027093569436

Epoch: 420| Step: 0
Training loss: 0.26688152551651
Validation loss: 2.0973292787869773

Epoch: 6| Step: 1
Training loss: 0.23059652745723724
Validation loss: 2.087483803431193

Epoch: 6| Step: 2
Training loss: 0.5946929454803467
Validation loss: 2.077302893002828

Epoch: 6| Step: 3
Training loss: 0.233217254281044
Validation loss: 2.082756678263346

Epoch: 6| Step: 4
Training loss: 0.32903024554252625
Validation loss: 2.0943262378374734

Epoch: 6| Step: 5
Training loss: 0.16969209909439087
Validation loss: 2.1149279872576394

Epoch: 6| Step: 6
Training loss: 0.2500517964363098
Validation loss: 2.0817881425221763

Epoch: 6| Step: 7
Training loss: 0.20763090252876282
Validation loss: 2.0964303414026895

Epoch: 6| Step: 8
Training loss: 0.20878374576568604
Validation loss: 2.116471827030182

Epoch: 6| Step: 9
Training loss: 0.42600706219673157
Validation loss: 2.0752878983815513

Epoch: 6| Step: 10
Training loss: 0.178138867020607
Validation loss: 2.136422018210093

Epoch: 6| Step: 11
Training loss: 0.21994099020957947
Validation loss: 2.0913976232210794

Epoch: 6| Step: 12
Training loss: 0.2328384816646576
Validation loss: 2.0627192656199136

Epoch: 6| Step: 13
Training loss: 0.1742466390132904
Validation loss: 2.045532683531443

Epoch: 421| Step: 0
Training loss: 0.18694013357162476
Validation loss: 2.096974790096283

Epoch: 6| Step: 1
Training loss: 0.2802312970161438
Validation loss: 2.146280268828074

Epoch: 6| Step: 2
Training loss: 0.2442273199558258
Validation loss: 2.1243078112602234

Epoch: 6| Step: 3
Training loss: 0.19043892621994019
Validation loss: 2.12871915102005

Epoch: 6| Step: 4
Training loss: 0.5252975225448608
Validation loss: 2.0992936889330545

Epoch: 6| Step: 5
Training loss: 0.18334996700286865
Validation loss: 2.0820929606755576

Epoch: 6| Step: 6
Training loss: 0.2372872680425644
Validation loss: 2.1315501928329468

Epoch: 6| Step: 7
Training loss: 0.2057187259197235
Validation loss: 2.088394820690155

Epoch: 6| Step: 8
Training loss: 0.21840134263038635
Validation loss: 2.0956509113311768

Epoch: 6| Step: 9
Training loss: 0.2371671199798584
Validation loss: 2.128790001074473

Epoch: 6| Step: 10
Training loss: 0.1903655081987381
Validation loss: 2.109004636605581

Epoch: 6| Step: 11
Training loss: 0.17002549767494202
Validation loss: 2.120255927244822

Epoch: 6| Step: 12
Training loss: 0.31146201491355896
Validation loss: 2.1381776134173074

Epoch: 6| Step: 13
Training loss: 0.27650678157806396
Validation loss: 2.102885087331136

Epoch: 422| Step: 0
Training loss: 0.1629931777715683
Validation loss: 2.09515772263209

Epoch: 6| Step: 1
Training loss: 0.27933961153030396
Validation loss: 2.075196107228597

Epoch: 6| Step: 2
Training loss: 0.170030876994133
Validation loss: 2.0609435637791953

Epoch: 6| Step: 3
Training loss: 0.3050800561904907
Validation loss: 2.0679144263267517

Epoch: 6| Step: 4
Training loss: 0.20464570820331573
Validation loss: 2.047480662663778

Epoch: 6| Step: 5
Training loss: 0.1543794572353363
Validation loss: 2.0413687030474343

Epoch: 6| Step: 6
Training loss: 0.20759747922420502
Validation loss: 2.0843373934427896

Epoch: 6| Step: 7
Training loss: 0.22698089480400085
Validation loss: 2.0574784874916077

Epoch: 6| Step: 8
Training loss: 0.25711703300476074
Validation loss: 2.0911489923795066

Epoch: 6| Step: 9
Training loss: 0.6120216250419617
Validation loss: 2.12272838751475

Epoch: 6| Step: 10
Training loss: 0.4085329473018646
Validation loss: 2.090933322906494

Epoch: 6| Step: 11
Training loss: 0.2569565176963806
Validation loss: 2.07358580827713

Epoch: 6| Step: 12
Training loss: 0.28746744990348816
Validation loss: 2.084777037302653

Epoch: 6| Step: 13
Training loss: 0.13008025288581848
Validation loss: 2.0697593887646994

Epoch: 423| Step: 0
Training loss: 0.19028545916080475
Validation loss: 2.0721787412961326

Epoch: 6| Step: 1
Training loss: 0.18515165150165558
Validation loss: 2.076662560304006

Epoch: 6| Step: 2
Training loss: 0.34463202953338623
Validation loss: 2.0569745302200317

Epoch: 6| Step: 3
Training loss: 0.24190835654735565
Validation loss: 2.057081162929535

Epoch: 6| Step: 4
Training loss: 0.17946401238441467
Validation loss: 2.0777327617009482

Epoch: 6| Step: 5
Training loss: 0.1831178218126297
Validation loss: 2.0903446276982627

Epoch: 6| Step: 6
Training loss: 0.20022141933441162
Validation loss: 2.107414940992991

Epoch: 6| Step: 7
Training loss: 0.254925012588501
Validation loss: 2.125373899936676

Epoch: 6| Step: 8
Training loss: 0.27438288927078247
Validation loss: 2.112140337626139

Epoch: 6| Step: 9
Training loss: 0.1781182885169983
Validation loss: 2.066674768924713

Epoch: 6| Step: 10
Training loss: 0.2564467787742615
Validation loss: 2.082753916581472

Epoch: 6| Step: 11
Training loss: 0.2729208469390869
Validation loss: 2.092945694923401

Epoch: 6| Step: 12
Training loss: 0.6250869035720825
Validation loss: 2.0537995100021362

Epoch: 6| Step: 13
Training loss: 0.4743180572986603
Validation loss: 2.0286554296811423

Epoch: 424| Step: 0
Training loss: 0.2551868259906769
Validation loss: 2.0910255710283914

Epoch: 6| Step: 1
Training loss: 0.14932966232299805
Validation loss: 2.0676459471384683

Epoch: 6| Step: 2
Training loss: 0.18275371193885803
Validation loss: 2.0832776625951133

Epoch: 6| Step: 3
Training loss: 0.5907553434371948
Validation loss: 2.064774215221405

Epoch: 6| Step: 4
Training loss: 0.22736527025699615
Validation loss: 2.1031320492426553

Epoch: 6| Step: 5
Training loss: 0.18396320939064026
Validation loss: 2.1096787651379905

Epoch: 6| Step: 6
Training loss: 0.19550251960754395
Validation loss: 2.0749448935190835

Epoch: 6| Step: 7
Training loss: 0.2641047537326813
Validation loss: 2.0983296434084573

Epoch: 6| Step: 8
Training loss: 0.3098849058151245
Validation loss: 2.0967263182004294

Epoch: 6| Step: 9
Training loss: 0.2630210518836975
Validation loss: 2.075437009334564

Epoch: 6| Step: 10
Training loss: 0.2598021328449249
Validation loss: 2.0549190640449524

Epoch: 6| Step: 11
Training loss: 0.31988388299942017
Validation loss: 1.9949936668078105

Epoch: 6| Step: 12
Training loss: 0.22856879234313965
Validation loss: 2.0318040450414023

Epoch: 6| Step: 13
Training loss: 0.29409587383270264
Validation loss: 2.0947052637736

Epoch: 425| Step: 0
Training loss: 0.20255497097969055
Validation loss: 2.059613267580668

Epoch: 6| Step: 1
Training loss: 0.33306920528411865
Validation loss: 2.073417047659556

Epoch: 6| Step: 2
Training loss: 0.29833298921585083
Validation loss: 2.112749377886454

Epoch: 6| Step: 3
Training loss: 0.27836310863494873
Validation loss: 2.1359849174817405

Epoch: 6| Step: 4
Training loss: 0.16694185137748718
Validation loss: 2.0763004223505654

Epoch: 6| Step: 5
Training loss: 0.16154342889785767
Validation loss: 2.0629757046699524

Epoch: 6| Step: 6
Training loss: 0.2380870282649994
Validation loss: 2.0829831957817078

Epoch: 6| Step: 7
Training loss: 0.649138331413269
Validation loss: 2.085711737473806

Epoch: 6| Step: 8
Training loss: 0.26691722869873047
Validation loss: 2.0756459633509317

Epoch: 6| Step: 9
Training loss: 0.21820060908794403
Validation loss: 2.0902097622553506

Epoch: 6| Step: 10
Training loss: 0.14514754712581635
Validation loss: 2.0722214778264365

Epoch: 6| Step: 11
Training loss: 0.12865006923675537
Validation loss: 2.1307390133539834

Epoch: 6| Step: 12
Training loss: 0.15644465386867523
Validation loss: 2.0969069600105286

Epoch: 6| Step: 13
Training loss: 0.1763424575328827
Validation loss: 2.1161813537279763

Epoch: 426| Step: 0
Training loss: 0.39281797409057617
Validation loss: 2.1026687820752463

Epoch: 6| Step: 1
Training loss: 0.19803941249847412
Validation loss: 2.1034158070882163

Epoch: 6| Step: 2
Training loss: 0.21677494049072266
Validation loss: 2.0956010619799295

Epoch: 6| Step: 3
Training loss: 0.2904711067676544
Validation loss: 2.0864911476771035

Epoch: 6| Step: 4
Training loss: 0.19147451221942902
Validation loss: 2.0872609615325928

Epoch: 6| Step: 5
Training loss: 0.2915789484977722
Validation loss: 2.089271525541941

Epoch: 6| Step: 6
Training loss: 0.17781734466552734
Validation loss: 2.0581663250923157

Epoch: 6| Step: 7
Training loss: 0.16912642121315002
Validation loss: 2.0525749723116555

Epoch: 6| Step: 8
Training loss: 0.17631757259368896
Validation loss: 2.1136585672696433

Epoch: 6| Step: 9
Training loss: 0.2542230486869812
Validation loss: 2.072748859723409

Epoch: 6| Step: 10
Training loss: 0.2386471927165985
Validation loss: 2.0799100001653037

Epoch: 6| Step: 11
Training loss: 0.1242426335811615
Validation loss: 2.0578040281931558

Epoch: 6| Step: 12
Training loss: 0.5481811761856079
Validation loss: 2.0800403157869973

Epoch: 6| Step: 13
Training loss: 0.24526110291481018
Validation loss: 2.0737529595692954

Epoch: 427| Step: 0
Training loss: 0.22428415715694427
Validation loss: 2.0892080267270408

Epoch: 6| Step: 1
Training loss: 0.16997426748275757
Validation loss: 2.07778533299764

Epoch: 6| Step: 2
Training loss: 0.2180619239807129
Validation loss: 2.07105153799057

Epoch: 6| Step: 3
Training loss: 0.5969234108924866
Validation loss: 2.0393705566724143

Epoch: 6| Step: 4
Training loss: 0.43837684392929077
Validation loss: 2.0821088552474976

Epoch: 6| Step: 5
Training loss: 0.17829175293445587
Validation loss: 2.0833758314450583

Epoch: 6| Step: 6
Training loss: 0.16297829151153564
Validation loss: 2.0952096780141196

Epoch: 6| Step: 7
Training loss: 0.18768811225891113
Validation loss: 2.0804234743118286

Epoch: 6| Step: 8
Training loss: 0.153866708278656
Validation loss: 2.0729029178619385

Epoch: 6| Step: 9
Training loss: 0.21305318176746368
Validation loss: 2.0654967625935874

Epoch: 6| Step: 10
Training loss: 0.238864466547966
Validation loss: 2.0461612741152444

Epoch: 6| Step: 11
Training loss: 0.1601429581642151
Validation loss: 2.0163840452829995

Epoch: 6| Step: 12
Training loss: 0.22595781087875366
Validation loss: 2.1022539138793945

Epoch: 6| Step: 13
Training loss: 0.25118401646614075
Validation loss: 2.05899171034495

Epoch: 428| Step: 0
Training loss: 0.28014683723449707
Validation loss: 2.09934671719869

Epoch: 6| Step: 1
Training loss: 0.7468966841697693
Validation loss: 2.0811407367388406

Epoch: 6| Step: 2
Training loss: 0.22150394320487976
Validation loss: 2.110699931780497

Epoch: 6| Step: 3
Training loss: 0.19531606137752533
Validation loss: 2.0866215229034424

Epoch: 6| Step: 4
Training loss: 0.2070501446723938
Validation loss: 2.0632700324058533

Epoch: 6| Step: 5
Training loss: 0.18012771010398865
Validation loss: 2.048592468102773

Epoch: 6| Step: 6
Training loss: 0.23641115427017212
Validation loss: 2.04873518149058

Epoch: 6| Step: 7
Training loss: 0.30236026644706726
Validation loss: 2.0340659618377686

Epoch: 6| Step: 8
Training loss: 0.1762525737285614
Validation loss: 2.0772574146588645

Epoch: 6| Step: 9
Training loss: 0.2478277087211609
Validation loss: 2.074419379234314

Epoch: 6| Step: 10
Training loss: 0.192466139793396
Validation loss: 2.038280646006266

Epoch: 6| Step: 11
Training loss: 0.17325928807258606
Validation loss: 2.065532644589742

Epoch: 6| Step: 12
Training loss: 0.24354207515716553
Validation loss: 2.0759576757748923

Epoch: 6| Step: 13
Training loss: 0.2058573067188263
Validation loss: 2.0417428414026895

Epoch: 429| Step: 0
Training loss: 0.1718006432056427
Validation loss: 2.084819515546163

Epoch: 6| Step: 1
Training loss: 0.395358681678772
Validation loss: 2.0744071205457053

Epoch: 6| Step: 2
Training loss: 0.2516813278198242
Validation loss: 2.076866308848063

Epoch: 6| Step: 3
Training loss: 0.09812287241220474
Validation loss: 2.1011035442352295

Epoch: 6| Step: 4
Training loss: 0.3462482988834381
Validation loss: 2.0733497738838196

Epoch: 6| Step: 5
Training loss: 0.5124514102935791
Validation loss: 2.0655500888824463

Epoch: 6| Step: 6
Training loss: 0.21226030588150024
Validation loss: 2.0650896430015564

Epoch: 6| Step: 7
Training loss: 0.20146699249744415
Validation loss: 2.0691741903622947

Epoch: 6| Step: 8
Training loss: 0.20192405581474304
Validation loss: 2.0968058506647744

Epoch: 6| Step: 9
Training loss: 0.20026187598705292
Validation loss: 2.118462602297465

Epoch: 6| Step: 10
Training loss: 0.22939443588256836
Validation loss: 2.0941762924194336

Epoch: 6| Step: 11
Training loss: 0.2652754783630371
Validation loss: 2.102450172106425

Epoch: 6| Step: 12
Training loss: 0.1750451922416687
Validation loss: 2.0834415555000305

Epoch: 6| Step: 13
Training loss: 0.22428157925605774
Validation loss: 2.083176632722219

Epoch: 430| Step: 0
Training loss: 0.5313912630081177
Validation loss: 2.078863024711609

Epoch: 6| Step: 1
Training loss: 0.22790910303592682
Validation loss: 2.0834137002627053

Epoch: 6| Step: 2
Training loss: 0.224276602268219
Validation loss: 2.0710893472035727

Epoch: 6| Step: 3
Training loss: 0.24768075346946716
Validation loss: 2.102390468120575

Epoch: 6| Step: 4
Training loss: 0.2840256690979004
Validation loss: 2.0976198315620422

Epoch: 6| Step: 5
Training loss: 0.2311737835407257
Validation loss: 2.0870285431543985

Epoch: 6| Step: 6
Training loss: 0.24990728497505188
Validation loss: 2.0802385012308755

Epoch: 6| Step: 7
Training loss: 0.19138571619987488
Validation loss: 2.0861887534459433

Epoch: 6| Step: 8
Training loss: 0.35744595527648926
Validation loss: 2.0889964501063027

Epoch: 6| Step: 9
Training loss: 0.40949317812919617
Validation loss: 2.0697466333707175

Epoch: 6| Step: 10
Training loss: 0.2578294277191162
Validation loss: 2.074187954266866

Epoch: 6| Step: 11
Training loss: 0.17622321844100952
Validation loss: 2.066171566645304

Epoch: 6| Step: 12
Training loss: 0.14867717027664185
Validation loss: 2.06626429160436

Epoch: 6| Step: 13
Training loss: 0.2571715712547302
Validation loss: 2.0907889008522034

Epoch: 431| Step: 0
Training loss: 0.2828763723373413
Validation loss: 2.1332395871480307

Epoch: 6| Step: 1
Training loss: 0.267589271068573
Validation loss: 2.1408801277478537

Epoch: 6| Step: 2
Training loss: 0.3190969228744507
Validation loss: 2.1193478107452393

Epoch: 6| Step: 3
Training loss: 0.22730693221092224
Validation loss: 2.087275822957357

Epoch: 6| Step: 4
Training loss: 0.21805888414382935
Validation loss: 2.064846992492676

Epoch: 6| Step: 5
Training loss: 0.21795323491096497
Validation loss: 2.0684818625450134

Epoch: 6| Step: 6
Training loss: 0.8263227939605713
Validation loss: 2.0511898597081504

Epoch: 6| Step: 7
Training loss: 0.20932352542877197
Validation loss: 2.043207267920176

Epoch: 6| Step: 8
Training loss: 0.22260871529579163
Validation loss: 2.074118415514628

Epoch: 6| Step: 9
Training loss: 0.2824828624725342
Validation loss: 2.0411999225616455

Epoch: 6| Step: 10
Training loss: 0.2213413268327713
Validation loss: 2.0929073095321655

Epoch: 6| Step: 11
Training loss: 0.2026548981666565
Validation loss: 2.060987949371338

Epoch: 6| Step: 12
Training loss: 0.27467358112335205
Validation loss: 2.1060806711514792

Epoch: 6| Step: 13
Training loss: 0.2472245693206787
Validation loss: 2.0803785721460977

Epoch: 432| Step: 0
Training loss: 0.20736248791217804
Validation loss: 2.064791758855184

Epoch: 6| Step: 1
Training loss: 0.206672802567482
Validation loss: 2.0666969418525696

Epoch: 6| Step: 2
Training loss: 0.2010975182056427
Validation loss: 2.054335117340088

Epoch: 6| Step: 3
Training loss: 0.25158894062042236
Validation loss: 2.098053435484568

Epoch: 6| Step: 4
Training loss: 0.3349178433418274
Validation loss: 2.068745772043864

Epoch: 6| Step: 5
Training loss: 0.25120753049850464
Validation loss: 2.073285400867462

Epoch: 6| Step: 6
Training loss: 0.36159902811050415
Validation loss: 2.0769779880841575

Epoch: 6| Step: 7
Training loss: 0.30100661516189575
Validation loss: 2.0805737177530923

Epoch: 6| Step: 8
Training loss: 0.17543883621692657
Validation loss: 2.073161800702413

Epoch: 6| Step: 9
Training loss: 0.16540151834487915
Validation loss: 2.1023773749669394

Epoch: 6| Step: 10
Training loss: 0.13327914476394653
Validation loss: 2.098083217938741

Epoch: 6| Step: 11
Training loss: 0.2590292692184448
Validation loss: 2.068365454673767

Epoch: 6| Step: 12
Training loss: 0.20316804945468903
Validation loss: 2.1152002215385437

Epoch: 6| Step: 13
Training loss: 0.6161602735519409
Validation loss: 2.080414891242981

Epoch: 433| Step: 0
Training loss: 0.5176005363464355
Validation loss: 2.1064708828926086

Epoch: 6| Step: 1
Training loss: 0.27462929487228394
Validation loss: 2.060658812522888

Epoch: 6| Step: 2
Training loss: 0.2701479196548462
Validation loss: 2.0649596055348716

Epoch: 6| Step: 3
Training loss: 0.18440502882003784
Validation loss: 2.0687160094579062

Epoch: 6| Step: 4
Training loss: 0.23330986499786377
Validation loss: 2.07791934410731

Epoch: 6| Step: 5
Training loss: 0.37922078371047974
Validation loss: 2.0901697476704917

Epoch: 6| Step: 6
Training loss: 0.25883594155311584
Validation loss: 2.0717883507410684

Epoch: 6| Step: 7
Training loss: 0.2366326004266739
Validation loss: 2.0603005488713584

Epoch: 6| Step: 8
Training loss: 0.3254918158054352
Validation loss: 2.071558694044749

Epoch: 6| Step: 9
Training loss: 0.25578826665878296
Validation loss: 2.068905015786489

Epoch: 6| Step: 10
Training loss: 0.20788100361824036
Validation loss: 2.0636261701583862

Epoch: 6| Step: 11
Training loss: 0.19422142207622528
Validation loss: 2.0850685040156045

Epoch: 6| Step: 12
Training loss: 0.18142230808734894
Validation loss: 2.1066712935765586

Epoch: 6| Step: 13
Training loss: 0.19560959935188293
Validation loss: 2.077138980229696

Epoch: 434| Step: 0
Training loss: 0.5721789598464966
Validation loss: 2.066202938556671

Epoch: 6| Step: 1
Training loss: 0.2523254156112671
Validation loss: 2.088329553604126

Epoch: 6| Step: 2
Training loss: 0.1847206950187683
Validation loss: 2.101032098134359

Epoch: 6| Step: 3
Training loss: 0.18609145283699036
Validation loss: 2.0599640210469565

Epoch: 6| Step: 4
Training loss: 0.13444168865680695
Validation loss: 2.0756585399309793

Epoch: 6| Step: 5
Training loss: 0.19403165578842163
Validation loss: 2.1010244886080423

Epoch: 6| Step: 6
Training loss: 0.48684918880462646
Validation loss: 2.128693699836731

Epoch: 6| Step: 7
Training loss: 0.17127592861652374
Validation loss: 2.112469087044398

Epoch: 6| Step: 8
Training loss: 0.17907001078128815
Validation loss: 2.077151676019033

Epoch: 6| Step: 9
Training loss: 0.2535918951034546
Validation loss: 2.0992851853370667

Epoch: 6| Step: 10
Training loss: 0.28267335891723633
Validation loss: 2.058164139588674

Epoch: 6| Step: 11
Training loss: 0.19507792592048645
Validation loss: 2.0613195498784385

Epoch: 6| Step: 12
Training loss: 0.31113532185554504
Validation loss: 2.0340795119603476

Epoch: 6| Step: 13
Training loss: 0.239618718624115
Validation loss: 2.1061004201571145

Epoch: 435| Step: 0
Training loss: 0.2716101408004761
Validation loss: 2.081479807694753

Epoch: 6| Step: 1
Training loss: 0.21591269969940186
Validation loss: 2.0591690937678018

Epoch: 6| Step: 2
Training loss: 0.18841522932052612
Validation loss: 2.058886547883352

Epoch: 6| Step: 3
Training loss: 0.2812517285346985
Validation loss: 2.0959592858950296

Epoch: 6| Step: 4
Training loss: 0.6067814826965332
Validation loss: 2.1382532914479575

Epoch: 6| Step: 5
Training loss: 0.2613396644592285
Validation loss: 2.126619895299276

Epoch: 6| Step: 6
Training loss: 0.29727768898010254
Validation loss: 2.1210636496543884

Epoch: 6| Step: 7
Training loss: 0.23743414878845215
Validation loss: 2.0993736584981284

Epoch: 6| Step: 8
Training loss: 0.13716790080070496
Validation loss: 2.025526762008667

Epoch: 6| Step: 9
Training loss: 0.2953466773033142
Validation loss: 2.072920044263204

Epoch: 6| Step: 10
Training loss: 0.22881844639778137
Validation loss: 2.0945271253585815

Epoch: 6| Step: 11
Training loss: 0.24813860654830933
Validation loss: 2.0527331034342446

Epoch: 6| Step: 12
Training loss: 0.25501030683517456
Validation loss: 2.0578413804372153

Epoch: 6| Step: 13
Training loss: 0.35308629274368286
Validation loss: 2.0590747197469077

Epoch: 436| Step: 0
Training loss: 0.18472832441329956
Validation loss: 2.1003875732421875

Epoch: 6| Step: 1
Training loss: 0.2312154769897461
Validation loss: 2.084881047407786

Epoch: 6| Step: 2
Training loss: 0.19142702221870422
Validation loss: 2.101152797540029

Epoch: 6| Step: 3
Training loss: 0.17403081059455872
Validation loss: 2.0818283557891846

Epoch: 6| Step: 4
Training loss: 0.2768383324146271
Validation loss: 2.0884418288866677

Epoch: 6| Step: 5
Training loss: 0.22917808592319489
Validation loss: 2.0870235761006675

Epoch: 6| Step: 6
Training loss: 0.23762217164039612
Validation loss: 2.0744065642356873

Epoch: 6| Step: 7
Training loss: 0.19719985127449036
Validation loss: 2.049175202846527

Epoch: 6| Step: 8
Training loss: 0.22885552048683167
Validation loss: 2.046871562798818

Epoch: 6| Step: 9
Training loss: 0.2840232253074646
Validation loss: 2.0951369802157083

Epoch: 6| Step: 10
Training loss: 0.5413114428520203
Validation loss: 2.0655945340792337

Epoch: 6| Step: 11
Training loss: 0.2627571225166321
Validation loss: 2.1143760482470193

Epoch: 6| Step: 12
Training loss: 0.2170017659664154
Validation loss: 2.093905051549276

Epoch: 6| Step: 13
Training loss: 0.3382754623889923
Validation loss: 2.1178031166394553

Epoch: 437| Step: 0
Training loss: 0.21735896170139313
Validation loss: 2.0662810603777566

Epoch: 6| Step: 1
Training loss: 0.22498655319213867
Validation loss: 2.077632208665212

Epoch: 6| Step: 2
Training loss: 0.19253979623317719
Validation loss: 2.0763600865999856

Epoch: 6| Step: 3
Training loss: 0.2288123369216919
Validation loss: 2.106789767742157

Epoch: 6| Step: 4
Training loss: 0.19918547570705414
Validation loss: 2.0556427240371704

Epoch: 6| Step: 5
Training loss: 0.2607647776603699
Validation loss: 2.0915342966715493

Epoch: 6| Step: 6
Training loss: 0.16608482599258423
Validation loss: 2.0678335428237915

Epoch: 6| Step: 7
Training loss: 0.1794602870941162
Validation loss: 2.0775309006373086

Epoch: 6| Step: 8
Training loss: 0.2702375650405884
Validation loss: 2.043580691019694

Epoch: 6| Step: 9
Training loss: 0.236073300242424
Validation loss: 2.0527596275011697

Epoch: 6| Step: 10
Training loss: 0.572512149810791
Validation loss: 2.10318132241567

Epoch: 6| Step: 11
Training loss: 0.16047754883766174
Validation loss: 2.060101091861725

Epoch: 6| Step: 12
Training loss: 0.2556854486465454
Validation loss: 2.082490622997284

Epoch: 6| Step: 13
Training loss: 0.18294298648834229
Validation loss: 2.0419402519861856

Epoch: 438| Step: 0
Training loss: 0.25323328375816345
Validation loss: 2.0833136240641275

Epoch: 6| Step: 1
Training loss: 0.5289254784584045
Validation loss: 2.090055207411448

Epoch: 6| Step: 2
Training loss: 0.2484537959098816
Validation loss: 2.0450647870699563

Epoch: 6| Step: 3
Training loss: 0.22901281714439392
Validation loss: 2.08405331770579

Epoch: 6| Step: 4
Training loss: 0.2381926327943802
Validation loss: 2.0883538524309793

Epoch: 6| Step: 5
Training loss: 0.19812101125717163
Validation loss: 2.0810477336247764

Epoch: 6| Step: 6
Training loss: 0.09639434516429901
Validation loss: 2.100597321987152

Epoch: 6| Step: 7
Training loss: 0.37750405073165894
Validation loss: 2.1112857460975647

Epoch: 6| Step: 8
Training loss: 0.2134273648262024
Validation loss: 2.1001126567522683

Epoch: 6| Step: 9
Training loss: 0.257727712392807
Validation loss: 2.0876693725585938

Epoch: 6| Step: 10
Training loss: 0.17185229063034058
Validation loss: 2.099662403265635

Epoch: 6| Step: 11
Training loss: 0.1289709210395813
Validation loss: 2.103344897429148

Epoch: 6| Step: 12
Training loss: 0.26761072874069214
Validation loss: 2.1078203121821084

Epoch: 6| Step: 13
Training loss: 0.1518401950597763
Validation loss: 2.1246694525082908

Epoch: 439| Step: 0
Training loss: 0.27002739906311035
Validation loss: 2.0967505971590676

Epoch: 6| Step: 1
Training loss: 0.23237992823123932
Validation loss: 2.084348499774933

Epoch: 6| Step: 2
Training loss: 0.17833921313285828
Validation loss: 2.0761362512906394

Epoch: 6| Step: 3
Training loss: 0.1951824426651001
Validation loss: 2.0787526965141296

Epoch: 6| Step: 4
Training loss: 0.16405214369297028
Validation loss: 2.10625030597051

Epoch: 6| Step: 5
Training loss: 0.20010969042778015
Validation loss: 2.083562652269999

Epoch: 6| Step: 6
Training loss: 0.22339338064193726
Validation loss: 2.118619382381439

Epoch: 6| Step: 7
Training loss: 0.17788594961166382
Validation loss: 2.1471513708432517

Epoch: 6| Step: 8
Training loss: 0.11755841970443726
Validation loss: 2.1014490326245627

Epoch: 6| Step: 9
Training loss: 0.608764111995697
Validation loss: 2.1176917354265847

Epoch: 6| Step: 10
Training loss: 0.3156874477863312
Validation loss: 2.0842634439468384

Epoch: 6| Step: 11
Training loss: 0.2414824217557907
Validation loss: 2.086926261583964

Epoch: 6| Step: 12
Training loss: 0.1962265968322754
Validation loss: 2.097177565097809

Epoch: 6| Step: 13
Training loss: 0.18404677510261536
Validation loss: 2.0976101954778037

Epoch: 440| Step: 0
Training loss: 0.18130983412265778
Validation loss: 2.114594578742981

Epoch: 6| Step: 1
Training loss: 0.7245520949363708
Validation loss: 2.1197510162989297

Epoch: 6| Step: 2
Training loss: 0.3957943320274353
Validation loss: 2.110779563585917

Epoch: 6| Step: 3
Training loss: 0.284880667924881
Validation loss: 2.1266521215438843

Epoch: 6| Step: 4
Training loss: 0.1707441210746765
Validation loss: 2.1049437324206033

Epoch: 6| Step: 5
Training loss: 0.1819750964641571
Validation loss: 2.0865196784337363

Epoch: 6| Step: 6
Training loss: 0.20613184571266174
Validation loss: 2.1175179878870645

Epoch: 6| Step: 7
Training loss: 0.23922550678253174
Validation loss: 2.1146355271339417

Epoch: 6| Step: 8
Training loss: 0.2608785927295685
Validation loss: 2.1012026270230613

Epoch: 6| Step: 9
Training loss: 0.30099058151245117
Validation loss: 2.0711350440979004

Epoch: 6| Step: 10
Training loss: 0.1996251940727234
Validation loss: 2.0882076223691306

Epoch: 6| Step: 11
Training loss: 0.2373252958059311
Validation loss: 2.113753060499827

Epoch: 6| Step: 12
Training loss: 0.1380312740802765
Validation loss: 2.0735726952552795

Epoch: 6| Step: 13
Training loss: 0.24390530586242676
Validation loss: 2.035374323527018

Epoch: 441| Step: 0
Training loss: 0.17492926120758057
Validation loss: 2.1019596656163535

Epoch: 6| Step: 1
Training loss: 0.1909995973110199
Validation loss: 2.0364677707354226

Epoch: 6| Step: 2
Training loss: 0.24945256114006042
Validation loss: 2.0847533543904624

Epoch: 6| Step: 3
Training loss: 0.26293811202049255
Validation loss: 2.0833192269007363

Epoch: 6| Step: 4
Training loss: 0.212581604719162
Validation loss: 2.0589853525161743

Epoch: 6| Step: 5
Training loss: 0.19190558791160583
Validation loss: 2.058696726957957

Epoch: 6| Step: 6
Training loss: 0.40135765075683594
Validation loss: 2.075844943523407

Epoch: 6| Step: 7
Training loss: 0.5528038740158081
Validation loss: 2.120352586110433

Epoch: 6| Step: 8
Training loss: 0.21519672870635986
Validation loss: 2.083255708217621

Epoch: 6| Step: 9
Training loss: 0.3519439101219177
Validation loss: 2.112716535727183

Epoch: 6| Step: 10
Training loss: 0.2007802575826645
Validation loss: 2.0855278174082437

Epoch: 6| Step: 11
Training loss: 0.1592702865600586
Validation loss: 2.086782614390055

Epoch: 6| Step: 12
Training loss: 0.27544480562210083
Validation loss: 2.0986024141311646

Epoch: 6| Step: 13
Training loss: 0.19560351967811584
Validation loss: 2.0935046672821045

Epoch: 442| Step: 0
Training loss: 0.2200341820716858
Validation loss: 2.0861743291219077

Epoch: 6| Step: 1
Training loss: 0.3368660807609558
Validation loss: 2.1028326749801636

Epoch: 6| Step: 2
Training loss: 0.24378883838653564
Validation loss: 2.0887510180473328

Epoch: 6| Step: 3
Training loss: 0.1758524477481842
Validation loss: 2.0805241664250693

Epoch: 6| Step: 4
Training loss: 0.22173255681991577
Validation loss: 2.0736790100733438

Epoch: 6| Step: 5
Training loss: 0.2191845327615738
Validation loss: 2.0901265939076743

Epoch: 6| Step: 6
Training loss: 0.16151157021522522
Validation loss: 2.1121021707852683

Epoch: 6| Step: 7
Training loss: 0.11200659722089767
Validation loss: 2.079716205596924

Epoch: 6| Step: 8
Training loss: 0.727786660194397
Validation loss: 2.117497205734253

Epoch: 6| Step: 9
Training loss: 0.227630153298378
Validation loss: 2.094755550225576

Epoch: 6| Step: 10
Training loss: 0.12194743752479553
Validation loss: 2.084307690461477

Epoch: 6| Step: 11
Training loss: 0.13303205370903015
Validation loss: 2.0915887355804443

Epoch: 6| Step: 12
Training loss: 0.18509674072265625
Validation loss: 2.0540360808372498

Epoch: 6| Step: 13
Training loss: 0.3320102095603943
Validation loss: 2.074303468068441

Epoch: 443| Step: 0
Training loss: 0.18408164381980896
Validation loss: 2.082465867201487

Epoch: 6| Step: 1
Training loss: 0.20008032023906708
Validation loss: 2.082505464553833

Epoch: 6| Step: 2
Training loss: 0.165058434009552
Validation loss: 2.083211660385132

Epoch: 6| Step: 3
Training loss: 0.14310778677463531
Validation loss: 2.1064863801002502

Epoch: 6| Step: 4
Training loss: 0.32974863052368164
Validation loss: 2.1389858524004617

Epoch: 6| Step: 5
Training loss: 0.6313732266426086
Validation loss: 2.1253530184427896

Epoch: 6| Step: 6
Training loss: 0.2724751830101013
Validation loss: 2.1520575881004333

Epoch: 6| Step: 7
Training loss: 0.36020544171333313
Validation loss: 2.1596818963686624

Epoch: 6| Step: 8
Training loss: 0.4497981369495392
Validation loss: 2.0851141810417175

Epoch: 6| Step: 9
Training loss: 0.2979190945625305
Validation loss: 2.0634150902430215

Epoch: 6| Step: 10
Training loss: 0.20943033695220947
Validation loss: 2.1086376508076987

Epoch: 6| Step: 11
Training loss: 0.2736687958240509
Validation loss: 2.0941460927327475

Epoch: 6| Step: 12
Training loss: 0.2618345022201538
Validation loss: 2.0566499431928

Epoch: 6| Step: 13
Training loss: 0.18718171119689941
Validation loss: 2.058981021245321

Epoch: 444| Step: 0
Training loss: 0.2095024138689041
Validation loss: 2.0762064258257547

Epoch: 6| Step: 1
Training loss: 0.244180366396904
Validation loss: 2.0768161018689475

Epoch: 6| Step: 2
Training loss: 0.14364615082740784
Validation loss: 2.052739918231964

Epoch: 6| Step: 3
Training loss: 0.1408659815788269
Validation loss: 2.0955286423365274

Epoch: 6| Step: 4
Training loss: 0.175148606300354
Validation loss: 2.086325168609619

Epoch: 6| Step: 5
Training loss: 0.6156735420227051
Validation loss: 2.0919050176938376

Epoch: 6| Step: 6
Training loss: 0.36399006843566895
Validation loss: 2.100841442743937

Epoch: 6| Step: 7
Training loss: 0.24502208828926086
Validation loss: 2.106937825679779

Epoch: 6| Step: 8
Training loss: 0.16293618083000183
Validation loss: 2.107732574144999

Epoch: 6| Step: 9
Training loss: 0.28636598587036133
Validation loss: 2.118486762046814

Epoch: 6| Step: 10
Training loss: 0.22171816229820251
Validation loss: 2.0757171909014382

Epoch: 6| Step: 11
Training loss: 0.14782124757766724
Validation loss: 2.0931827425956726

Epoch: 6| Step: 12
Training loss: 0.23684822022914886
Validation loss: 2.0986359318097434

Epoch: 6| Step: 13
Training loss: 0.23197899758815765
Validation loss: 2.0896823008855185

Epoch: 445| Step: 0
Training loss: 0.2046908140182495
Validation loss: 2.0564115842183432

Epoch: 6| Step: 1
Training loss: 0.19249561429023743
Validation loss: 2.092819313208262

Epoch: 6| Step: 2
Training loss: 0.22298629581928253
Validation loss: 2.100128412246704

Epoch: 6| Step: 3
Training loss: 0.1546204537153244
Validation loss: 2.0996160308519998

Epoch: 6| Step: 4
Training loss: 0.1978328824043274
Validation loss: 2.1287616888682046

Epoch: 6| Step: 5
Training loss: 0.22900724411010742
Validation loss: 2.0838812987009683

Epoch: 6| Step: 6
Training loss: 0.28201764822006226
Validation loss: 2.120327889919281

Epoch: 6| Step: 7
Training loss: 0.24131062626838684
Validation loss: 2.1233924428621926

Epoch: 6| Step: 8
Training loss: 0.12721917033195496
Validation loss: 2.065059185028076

Epoch: 6| Step: 9
Training loss: 0.32419639825820923
Validation loss: 2.110497991243998

Epoch: 6| Step: 10
Training loss: 0.3035467863082886
Validation loss: 2.0375500122706094

Epoch: 6| Step: 11
Training loss: 0.2607952654361725
Validation loss: 2.0527012745539346

Epoch: 6| Step: 12
Training loss: 0.6827557682991028
Validation loss: 2.0895283818244934

Epoch: 6| Step: 13
Training loss: 0.26635944843292236
Validation loss: 2.0632572372754416

Epoch: 446| Step: 0
Training loss: 0.1885477900505066
Validation loss: 2.0646252036094666

Epoch: 6| Step: 1
Training loss: 0.21881380677223206
Validation loss: 2.109668572743734

Epoch: 6| Step: 2
Training loss: 0.616813063621521
Validation loss: 2.152218222618103

Epoch: 6| Step: 3
Training loss: 0.2861563563346863
Validation loss: 2.10967618227005

Epoch: 6| Step: 4
Training loss: 0.29531973600387573
Validation loss: 2.060142755508423

Epoch: 6| Step: 5
Training loss: 0.15244229137897491
Validation loss: 2.068873703479767

Epoch: 6| Step: 6
Training loss: 0.18412157893180847
Validation loss: 2.0687540769577026

Epoch: 6| Step: 7
Training loss: 0.24839667975902557
Validation loss: 2.1091309189796448

Epoch: 6| Step: 8
Training loss: 0.33058542013168335
Validation loss: 2.066102464993795

Epoch: 6| Step: 9
Training loss: 0.24965806305408478
Validation loss: 2.0787358482678733

Epoch: 6| Step: 10
Training loss: 0.2558925151824951
Validation loss: 2.0580772360165915

Epoch: 6| Step: 11
Training loss: 0.1920773684978485
Validation loss: 2.0896597703297934

Epoch: 6| Step: 12
Training loss: 0.3203561305999756
Validation loss: 2.100763221581777

Epoch: 6| Step: 13
Training loss: 0.21157310903072357
Validation loss: 2.0584601561228433

Epoch: 447| Step: 0
Training loss: 0.1652495265007019
Validation loss: 2.1110438108444214

Epoch: 6| Step: 1
Training loss: 0.19634024798870087
Validation loss: 2.067547778288523

Epoch: 6| Step: 2
Training loss: 0.34557148814201355
Validation loss: 2.1074521938959756

Epoch: 6| Step: 3
Training loss: 0.17657537758350372
Validation loss: 2.1062819957733154

Epoch: 6| Step: 4
Training loss: 0.2014298141002655
Validation loss: 2.075420339902242

Epoch: 6| Step: 5
Training loss: 0.275905966758728
Validation loss: 2.082397937774658

Epoch: 6| Step: 6
Training loss: 0.12557485699653625
Validation loss: 2.05519038438797

Epoch: 6| Step: 7
Training loss: 0.15484470129013062
Validation loss: 2.091920812924703

Epoch: 6| Step: 8
Training loss: 0.3151535987854004
Validation loss: 2.082473615805308

Epoch: 6| Step: 9
Training loss: 0.16562679409980774
Validation loss: 2.090396543343862

Epoch: 6| Step: 10
Training loss: 0.31510376930236816
Validation loss: 2.102861007054647

Epoch: 6| Step: 11
Training loss: 0.2235155999660492
Validation loss: 2.0935741662979126

Epoch: 6| Step: 12
Training loss: 0.7271997928619385
Validation loss: 2.0737114747365317

Epoch: 6| Step: 13
Training loss: 0.15788088738918304
Validation loss: 2.0816360314687095

Epoch: 448| Step: 0
Training loss: 0.5425419211387634
Validation loss: 2.084290782610575

Epoch: 6| Step: 1
Training loss: 0.263652503490448
Validation loss: 2.0401883125305176

Epoch: 6| Step: 2
Training loss: 0.19187571108341217
Validation loss: 2.1005655924479165

Epoch: 6| Step: 3
Training loss: 0.14243263006210327
Validation loss: 2.080632189909617

Epoch: 6| Step: 4
Training loss: 0.4285706579685211
Validation loss: 2.0400704542795816

Epoch: 6| Step: 5
Training loss: 0.20304110646247864
Validation loss: 2.0936155319213867

Epoch: 6| Step: 6
Training loss: 0.22315317392349243
Validation loss: 2.07846333583196

Epoch: 6| Step: 7
Training loss: 0.2503831386566162
Validation loss: 2.094386398792267

Epoch: 6| Step: 8
Training loss: 0.18986675143241882
Validation loss: 2.091716746489207

Epoch: 6| Step: 9
Training loss: 0.17775367200374603
Validation loss: 2.0880393981933594

Epoch: 6| Step: 10
Training loss: 0.26726651191711426
Validation loss: 2.1167606512705484

Epoch: 6| Step: 11
Training loss: 0.2276742160320282
Validation loss: 2.0923949480056763

Epoch: 6| Step: 12
Training loss: 0.20758119225502014
Validation loss: 2.078688621520996

Epoch: 6| Step: 13
Training loss: 0.21758802235126495
Validation loss: 2.112072507540385

Epoch: 449| Step: 0
Training loss: 0.21740709245204926
Validation loss: 2.1074084838231406

Epoch: 6| Step: 1
Training loss: 0.2920897603034973
Validation loss: 2.092410425345103

Epoch: 6| Step: 2
Training loss: 0.21946460008621216
Validation loss: 2.099590758482615

Epoch: 6| Step: 3
Training loss: 0.19553691148757935
Validation loss: 2.0833372672398887

Epoch: 6| Step: 4
Training loss: 0.19834545254707336
Validation loss: 2.0829692085584006

Epoch: 6| Step: 5
Training loss: 0.14897984266281128
Validation loss: 2.091433346271515

Epoch: 6| Step: 6
Training loss: 0.22148080170154572
Validation loss: 2.1136940121650696

Epoch: 6| Step: 7
Training loss: 0.6101040244102478
Validation loss: 2.128981053829193

Epoch: 6| Step: 8
Training loss: 0.19906210899353027
Validation loss: 2.06457926829656

Epoch: 6| Step: 9
Training loss: 0.27685707807540894
Validation loss: 2.0908785859743753

Epoch: 6| Step: 10
Training loss: 0.2660788893699646
Validation loss: 2.1183037161827087

Epoch: 6| Step: 11
Training loss: 0.13460063934326172
Validation loss: 2.09322452545166

Epoch: 6| Step: 12
Training loss: 0.25175777077674866
Validation loss: 2.1295878489812217

Epoch: 6| Step: 13
Training loss: 0.30802497267723083
Validation loss: 2.088157832622528

Epoch: 450| Step: 0
Training loss: 0.19425198435783386
Validation loss: 2.0469385782877603

Epoch: 6| Step: 1
Training loss: 0.1381063312292099
Validation loss: 2.0703501303990683

Epoch: 6| Step: 2
Training loss: 0.1549849808216095
Validation loss: 2.0793423652648926

Epoch: 6| Step: 3
Training loss: 0.21608909964561462
Validation loss: 2.054147640864054

Epoch: 6| Step: 4
Training loss: 0.19808000326156616
Validation loss: 2.06034779548645

Epoch: 6| Step: 5
Training loss: 0.17398178577423096
Validation loss: 2.0594683488210044

Epoch: 6| Step: 6
Training loss: 0.1698649823665619
Validation loss: 2.093279778957367

Epoch: 6| Step: 7
Training loss: 0.21780666708946228
Validation loss: 2.049841741720835

Epoch: 6| Step: 8
Training loss: 0.1712556928396225
Validation loss: 2.0601508220036826

Epoch: 6| Step: 9
Training loss: 0.1944359540939331
Validation loss: 2.0782273610432944

Epoch: 6| Step: 10
Training loss: 0.2566133439540863
Validation loss: 2.087754189968109

Epoch: 6| Step: 11
Training loss: 0.5075778365135193
Validation loss: 2.104241798321406

Epoch: 6| Step: 12
Training loss: 0.40031132102012634
Validation loss: 2.093651831150055

Epoch: 6| Step: 13
Training loss: 0.23291179537773132
Validation loss: 2.0896029671033225

Epoch: 451| Step: 0
Training loss: 0.3012983500957489
Validation loss: 2.06141197681427

Epoch: 6| Step: 1
Training loss: 0.16976308822631836
Validation loss: 2.046250899632772

Epoch: 6| Step: 2
Training loss: 0.5418217182159424
Validation loss: 2.0757469733556113

Epoch: 6| Step: 3
Training loss: 0.16765886545181274
Validation loss: 2.0653775731722512

Epoch: 6| Step: 4
Training loss: 0.1463741511106491
Validation loss: 2.1180953979492188

Epoch: 6| Step: 5
Training loss: 0.17550472915172577
Validation loss: 2.067212462425232

Epoch: 6| Step: 6
Training loss: 0.21560180187225342
Validation loss: 2.0689679781595864

Epoch: 6| Step: 7
Training loss: 0.2593173384666443
Validation loss: 2.0616965691248574

Epoch: 6| Step: 8
Training loss: 0.16195300221443176
Validation loss: 2.100070913632711

Epoch: 6| Step: 9
Training loss: 0.28435221314430237
Validation loss: 2.0702750285466514

Epoch: 6| Step: 10
Training loss: 0.2025844007730484
Validation loss: 2.0706148942311606

Epoch: 6| Step: 11
Training loss: 0.35845082998275757
Validation loss: 2.081518908341726

Epoch: 6| Step: 12
Training loss: 0.3210582733154297
Validation loss: 2.0614229639371238

Epoch: 6| Step: 13
Training loss: 0.25096502900123596
Validation loss: 2.1016714572906494

Epoch: 452| Step: 0
Training loss: 0.25008153915405273
Validation loss: 2.0632946292559304

Epoch: 6| Step: 1
Training loss: 0.5996149182319641
Validation loss: 2.1016856034596763

Epoch: 6| Step: 2
Training loss: 0.15273593366146088
Validation loss: 2.0905665953954062

Epoch: 6| Step: 3
Training loss: 0.3038254976272583
Validation loss: 2.1182878812154136

Epoch: 6| Step: 4
Training loss: 0.3150647282600403
Validation loss: 2.1669166882832847

Epoch: 6| Step: 5
Training loss: 0.16764843463897705
Validation loss: 2.093919575214386

Epoch: 6| Step: 6
Training loss: 0.20554953813552856
Validation loss: 2.066766063372294

Epoch: 6| Step: 7
Training loss: 0.21476083993911743
Validation loss: 2.097725212574005

Epoch: 6| Step: 8
Training loss: 0.1692771464586258
Validation loss: 2.1094003319740295

Epoch: 6| Step: 9
Training loss: 0.355743408203125
Validation loss: 2.067529300848643

Epoch: 6| Step: 10
Training loss: 0.4025253355503082
Validation loss: 2.0786667664845786

Epoch: 6| Step: 11
Training loss: 0.4845787286758423
Validation loss: 2.054688056310018

Epoch: 6| Step: 12
Training loss: 0.20709234476089478
Validation loss: 2.073467254638672

Epoch: 6| Step: 13
Training loss: 0.2435413897037506
Validation loss: 2.049813687801361

Epoch: 453| Step: 0
Training loss: 0.2346680462360382
Validation loss: 2.1216898361841836

Epoch: 6| Step: 1
Training loss: 0.2648622393608093
Validation loss: 2.1430022716522217

Epoch: 6| Step: 2
Training loss: 0.44939878582954407
Validation loss: 2.1027596990267434

Epoch: 6| Step: 3
Training loss: 0.28099149465560913
Validation loss: 2.1088138222694397

Epoch: 6| Step: 4
Training loss: 0.22869788110256195
Validation loss: 2.0842071374257407

Epoch: 6| Step: 5
Training loss: 0.2543073296546936
Validation loss: 2.071945091088613

Epoch: 6| Step: 6
Training loss: 0.2616690993309021
Validation loss: 2.079631586869558

Epoch: 6| Step: 7
Training loss: 0.40324926376342773
Validation loss: 2.035792430241903

Epoch: 6| Step: 8
Training loss: 0.2717371881008148
Validation loss: 2.091779967149099

Epoch: 6| Step: 9
Training loss: 0.2219272404909134
Validation loss: 2.037192622820536

Epoch: 6| Step: 10
Training loss: 0.22805197536945343
Validation loss: 2.0665722489356995

Epoch: 6| Step: 11
Training loss: 0.23494093120098114
Validation loss: 2.0695172945658364

Epoch: 6| Step: 12
Training loss: 0.28336095809936523
Validation loss: 2.1141231854756675

Epoch: 6| Step: 13
Training loss: 0.5117529630661011
Validation loss: 2.107051889101664

Epoch: 454| Step: 0
Training loss: 0.18828193843364716
Validation loss: 2.1122557322184243

Epoch: 6| Step: 1
Training loss: 0.20427104830741882
Validation loss: 2.09279727935791

Epoch: 6| Step: 2
Training loss: 0.5572705864906311
Validation loss: 2.1185741623242698

Epoch: 6| Step: 3
Training loss: 0.2744252383708954
Validation loss: 2.0607568422953286

Epoch: 6| Step: 4
Training loss: 0.3336426317691803
Validation loss: 2.0818602244059243

Epoch: 6| Step: 5
Training loss: 0.19307923316955566
Validation loss: 2.1127554972966514

Epoch: 6| Step: 6
Training loss: 0.19948947429656982
Validation loss: 2.087354759375254

Epoch: 6| Step: 7
Training loss: 0.3748619556427002
Validation loss: 2.0793383717536926

Epoch: 6| Step: 8
Training loss: 0.2696433663368225
Validation loss: 2.0662482182184854

Epoch: 6| Step: 9
Training loss: 0.24366380274295807
Validation loss: 2.102249264717102

Epoch: 6| Step: 10
Training loss: 0.28093570470809937
Validation loss: 2.0741136272748313

Epoch: 6| Step: 11
Training loss: 0.22606465220451355
Validation loss: 2.102552811304728

Epoch: 6| Step: 12
Training loss: 0.1849304586648941
Validation loss: 2.0609059929847717

Epoch: 6| Step: 13
Training loss: 0.18512164056301117
Validation loss: 2.053073783715566

Epoch: 455| Step: 0
Training loss: 0.24530529975891113
Validation loss: 2.0431199073791504

Epoch: 6| Step: 1
Training loss: 0.2865598201751709
Validation loss: 2.1058218081792197

Epoch: 6| Step: 2
Training loss: 0.1956975758075714
Validation loss: 2.0622456272443137

Epoch: 6| Step: 3
Training loss: 0.1804397702217102
Validation loss: 2.07458225886027

Epoch: 6| Step: 4
Training loss: 0.23511815071105957
Validation loss: 2.0940773487091064

Epoch: 6| Step: 5
Training loss: 0.23668290674686432
Validation loss: 2.0447724064191184

Epoch: 6| Step: 6
Training loss: 0.18349313735961914
Validation loss: 2.0296090046564736

Epoch: 6| Step: 7
Training loss: 0.19764281809329987
Validation loss: 2.0339717666308084

Epoch: 6| Step: 8
Training loss: 0.3463749885559082
Validation loss: 2.040100872516632

Epoch: 6| Step: 9
Training loss: 0.24865058064460754
Validation loss: 2.0571903586387634

Epoch: 6| Step: 10
Training loss: 0.5950577259063721
Validation loss: 2.044222414493561

Epoch: 6| Step: 11
Training loss: 0.20657381415367126
Validation loss: 2.064388076464335

Epoch: 6| Step: 12
Training loss: 0.29703861474990845
Validation loss: 2.0678152044614158

Epoch: 6| Step: 13
Training loss: 0.12461722642183304
Validation loss: 2.0830082098642984

Epoch: 456| Step: 0
Training loss: 0.37980377674102783
Validation loss: 2.140177329381307

Epoch: 6| Step: 1
Training loss: 0.3882935047149658
Validation loss: 2.07228954633077

Epoch: 6| Step: 2
Training loss: 0.1460607647895813
Validation loss: 2.0938052336374917

Epoch: 6| Step: 3
Training loss: 0.5304564833641052
Validation loss: 2.097268025080363

Epoch: 6| Step: 4
Training loss: 0.1567530333995819
Validation loss: 2.053237279256185

Epoch: 6| Step: 5
Training loss: 0.2866394817829132
Validation loss: 2.065921902656555

Epoch: 6| Step: 6
Training loss: 0.21683841943740845
Validation loss: 2.062150518099467

Epoch: 6| Step: 7
Training loss: 0.2689499258995056
Validation loss: 2.0590096712112427

Epoch: 6| Step: 8
Training loss: 0.256719708442688
Validation loss: 2.1129921476046243

Epoch: 6| Step: 9
Training loss: 0.2097662091255188
Validation loss: 2.0598480701446533

Epoch: 6| Step: 10
Training loss: 0.18193870782852173
Validation loss: 2.097038487593333

Epoch: 6| Step: 11
Training loss: 0.13285425305366516
Validation loss: 2.047314167022705

Epoch: 6| Step: 12
Training loss: 0.2448282539844513
Validation loss: 2.0800110896428428

Epoch: 6| Step: 13
Training loss: 0.2577327489852905
Validation loss: 2.088408092657725

Epoch: 457| Step: 0
Training loss: 0.1594858169555664
Validation loss: 2.0814186533292136

Epoch: 6| Step: 1
Training loss: 0.17359817028045654
Validation loss: 2.092878818511963

Epoch: 6| Step: 2
Training loss: 0.6703464984893799
Validation loss: 2.082313855489095

Epoch: 6| Step: 3
Training loss: 0.20576640963554382
Validation loss: 2.086542844772339

Epoch: 6| Step: 4
Training loss: 0.19851133227348328
Validation loss: 2.079773942629496

Epoch: 6| Step: 5
Training loss: 0.13830670714378357
Validation loss: 2.081949234008789

Epoch: 6| Step: 6
Training loss: 0.1824915111064911
Validation loss: 2.065422793229421

Epoch: 6| Step: 7
Training loss: 0.2787381410598755
Validation loss: 2.1105868816375732

Epoch: 6| Step: 8
Training loss: 0.1753491759300232
Validation loss: 2.120915651321411

Epoch: 6| Step: 9
Training loss: 0.1219078004360199
Validation loss: 2.080919603506724

Epoch: 6| Step: 10
Training loss: 0.2123842090368271
Validation loss: 2.0734293262163797

Epoch: 6| Step: 11
Training loss: 0.2061901092529297
Validation loss: 2.0910298824310303

Epoch: 6| Step: 12
Training loss: 0.15082824230194092
Validation loss: 2.0722369154294333

Epoch: 6| Step: 13
Training loss: 0.22980724275112152
Validation loss: 2.034557322661082

Epoch: 458| Step: 0
Training loss: 0.17586979269981384
Validation loss: 2.055789331595103

Epoch: 6| Step: 1
Training loss: 0.32404589653015137
Validation loss: 2.0919307271639505

Epoch: 6| Step: 2
Training loss: 0.17145660519599915
Validation loss: 2.10246209303538

Epoch: 6| Step: 3
Training loss: 0.24205991625785828
Validation loss: 2.072642683982849

Epoch: 6| Step: 4
Training loss: 0.18346598744392395
Validation loss: 2.064068694909414

Epoch: 6| Step: 5
Training loss: 0.5755575895309448
Validation loss: 2.087687691052755

Epoch: 6| Step: 6
Training loss: 0.18646101653575897
Validation loss: 2.0584358970324197

Epoch: 6| Step: 7
Training loss: 0.25298625230789185
Validation loss: 2.0988409717877707

Epoch: 6| Step: 8
Training loss: 0.2165789008140564
Validation loss: 2.089825133482615

Epoch: 6| Step: 9
Training loss: 0.17148268222808838
Validation loss: 2.079435348510742

Epoch: 6| Step: 10
Training loss: 0.30265241861343384
Validation loss: 2.07085653146108

Epoch: 6| Step: 11
Training loss: 0.17315268516540527
Validation loss: 2.0532350540161133

Epoch: 6| Step: 12
Training loss: 0.2348640114068985
Validation loss: 2.078820049762726

Epoch: 6| Step: 13
Training loss: 0.25112295150756836
Validation loss: 2.0478827754656472

Epoch: 459| Step: 0
Training loss: 0.24620160460472107
Validation loss: 2.029111464818319

Epoch: 6| Step: 1
Training loss: 0.20961645245552063
Validation loss: 2.088713506857554

Epoch: 6| Step: 2
Training loss: 0.3675955533981323
Validation loss: 2.0620603958765664

Epoch: 6| Step: 3
Training loss: 0.22938185930252075
Validation loss: 2.124492069085439

Epoch: 6| Step: 4
Training loss: 0.15368898212909698
Validation loss: 2.0971437096595764

Epoch: 6| Step: 5
Training loss: 0.2664160132408142
Validation loss: 2.1024500926335654

Epoch: 6| Step: 6
Training loss: 0.2356390655040741
Validation loss: 2.045284688472748

Epoch: 6| Step: 7
Training loss: 0.18219926953315735
Validation loss: 2.092807094256083

Epoch: 6| Step: 8
Training loss: 0.19258823990821838
Validation loss: 2.0631321469942727

Epoch: 6| Step: 9
Training loss: 0.5222851634025574
Validation loss: 2.096369425455729

Epoch: 6| Step: 10
Training loss: 0.19642005860805511
Validation loss: 2.030055602391561

Epoch: 6| Step: 11
Training loss: 0.2215055376291275
Validation loss: 2.0466907819112143

Epoch: 6| Step: 12
Training loss: 0.16342276334762573
Validation loss: 2.0597036679585776

Epoch: 6| Step: 13
Training loss: 0.209723562002182
Validation loss: 2.025925556818644

Epoch: 460| Step: 0
Training loss: 0.4415304660797119
Validation loss: 2.0615079402923584

Epoch: 6| Step: 1
Training loss: 0.14823071658611298
Validation loss: 2.076578656832377

Epoch: 6| Step: 2
Training loss: 0.16554167866706848
Validation loss: 2.0690935452779136

Epoch: 6| Step: 3
Training loss: 0.22211229801177979
Validation loss: 2.063936173915863

Epoch: 6| Step: 4
Training loss: 0.16475018858909607
Validation loss: 2.081098814805349

Epoch: 6| Step: 5
Training loss: 0.18197372555732727
Validation loss: 2.059861878554026

Epoch: 6| Step: 6
Training loss: 0.264204204082489
Validation loss: 2.0513405203819275

Epoch: 6| Step: 7
Training loss: 0.2300952672958374
Validation loss: 2.0902698238690696

Epoch: 6| Step: 8
Training loss: 0.13953723013401031
Validation loss: 2.1059648394584656

Epoch: 6| Step: 9
Training loss: 0.1579986810684204
Validation loss: 2.0675522287686667

Epoch: 6| Step: 10
Training loss: 0.5686913132667542
Validation loss: 2.089278737703959

Epoch: 6| Step: 11
Training loss: 0.18890617787837982
Validation loss: 2.134652018547058

Epoch: 6| Step: 12
Training loss: 0.20669609308242798
Validation loss: 2.1051289240519204

Epoch: 6| Step: 13
Training loss: 0.20118612051010132
Validation loss: 2.0751381119092307

Epoch: 461| Step: 0
Training loss: 0.1903418004512787
Validation loss: 2.1049309770266214

Epoch: 6| Step: 1
Training loss: 0.1754683256149292
Validation loss: 2.0787545442581177

Epoch: 6| Step: 2
Training loss: 0.2337925136089325
Validation loss: 2.095788319905599

Epoch: 6| Step: 3
Training loss: 0.23144972324371338
Validation loss: 2.068330963452657

Epoch: 6| Step: 4
Training loss: 0.1773749589920044
Validation loss: 2.0630154609680176

Epoch: 6| Step: 5
Training loss: 0.5564799308776855
Validation loss: 2.046628177165985

Epoch: 6| Step: 6
Training loss: 0.36654770374298096
Validation loss: 2.052327891190847

Epoch: 6| Step: 7
Training loss: 0.2161787450313568
Validation loss: 2.079471707344055

Epoch: 6| Step: 8
Training loss: 0.2384643703699112
Validation loss: 2.0830840468406677

Epoch: 6| Step: 9
Training loss: 0.39741772413253784
Validation loss: 2.0679306983947754

Epoch: 6| Step: 10
Training loss: 0.20717932283878326
Validation loss: 2.0595645705858865

Epoch: 6| Step: 11
Training loss: 0.17877668142318726
Validation loss: 2.052189886569977

Epoch: 6| Step: 12
Training loss: 0.1959352195262909
Validation loss: 2.056089699268341

Epoch: 6| Step: 13
Training loss: 0.1838764250278473
Validation loss: 2.048857490221659

Epoch: 462| Step: 0
Training loss: 0.18776710331439972
Validation loss: 2.0571277737617493

Epoch: 6| Step: 1
Training loss: 0.21565130352973938
Validation loss: 2.08886988957723

Epoch: 6| Step: 2
Training loss: 0.22545835375785828
Validation loss: 2.072408755620321

Epoch: 6| Step: 3
Training loss: 0.17001183331012726
Validation loss: 2.0342490871747336

Epoch: 6| Step: 4
Training loss: 0.2439301460981369
Validation loss: 2.041596790154775

Epoch: 6| Step: 5
Training loss: 0.30756688117980957
Validation loss: 2.060803453127543

Epoch: 6| Step: 6
Training loss: 0.24840688705444336
Validation loss: 2.075202763080597

Epoch: 6| Step: 7
Training loss: 0.23276731371879578
Validation loss: 2.060264984766642

Epoch: 6| Step: 8
Training loss: 0.20501363277435303
Validation loss: 2.0783641735712686

Epoch: 6| Step: 9
Training loss: 0.15058988332748413
Validation loss: 2.070916692415873

Epoch: 6| Step: 10
Training loss: 0.532500684261322
Validation loss: 2.0385401248931885

Epoch: 6| Step: 11
Training loss: 0.1891191154718399
Validation loss: 2.0515244801839194

Epoch: 6| Step: 12
Training loss: 0.33682525157928467
Validation loss: 2.023275911808014

Epoch: 6| Step: 13
Training loss: 0.17359790205955505
Validation loss: 2.035496989885966

Epoch: 463| Step: 0
Training loss: 0.20139890909194946
Validation loss: 2.0246305664380393

Epoch: 6| Step: 1
Training loss: 0.2850481867790222
Validation loss: 2.030827204386393

Epoch: 6| Step: 2
Training loss: 0.16404883563518524
Validation loss: 2.0654744307200112

Epoch: 6| Step: 3
Training loss: 0.21122205257415771
Validation loss: 2.0477083325386047

Epoch: 6| Step: 4
Training loss: 0.24351641535758972
Validation loss: 2.092245638370514

Epoch: 6| Step: 5
Training loss: 0.221369206905365
Validation loss: 2.087233563264211

Epoch: 6| Step: 6
Training loss: 0.23712047934532166
Validation loss: 2.0377859274546304

Epoch: 6| Step: 7
Training loss: 0.15157002210617065
Validation loss: 2.0538679162661233

Epoch: 6| Step: 8
Training loss: 0.20550382137298584
Validation loss: 2.0502808690071106

Epoch: 6| Step: 9
Training loss: 0.21764563024044037
Validation loss: 2.060669700304667

Epoch: 6| Step: 10
Training loss: 0.19628548622131348
Validation loss: 2.095461130142212

Epoch: 6| Step: 11
Training loss: 0.7655085921287537
Validation loss: 2.082836131254832

Epoch: 6| Step: 12
Training loss: 0.2401246875524521
Validation loss: 2.1236549814542136

Epoch: 6| Step: 13
Training loss: 0.21254542469978333
Validation loss: 2.098067065080007

Epoch: 464| Step: 0
Training loss: 0.18720491230487823
Validation loss: 2.050304333368937

Epoch: 6| Step: 1
Training loss: 0.1816233992576599
Validation loss: 2.0835055708885193

Epoch: 6| Step: 2
Training loss: 0.17557254433631897
Validation loss: 2.046732266743978

Epoch: 6| Step: 3
Training loss: 0.5264266729354858
Validation loss: 2.064323584238688

Epoch: 6| Step: 4
Training loss: 0.18625110387802124
Validation loss: 2.1280343929926553

Epoch: 6| Step: 5
Training loss: 0.18027067184448242
Validation loss: 2.126457452774048

Epoch: 6| Step: 6
Training loss: 0.213395357131958
Validation loss: 2.0610285003980002

Epoch: 6| Step: 7
Training loss: 0.2034057229757309
Validation loss: 2.091149310270945

Epoch: 6| Step: 8
Training loss: 0.25493401288986206
Validation loss: 2.0913952589035034

Epoch: 6| Step: 9
Training loss: 0.30169135332107544
Validation loss: 2.065842886765798

Epoch: 6| Step: 10
Training loss: 0.23014022409915924
Validation loss: 2.096886992454529

Epoch: 6| Step: 11
Training loss: 0.28928929567337036
Validation loss: 2.1042271057764688

Epoch: 6| Step: 12
Training loss: 0.3449907898902893
Validation loss: 2.05148716767629

Epoch: 6| Step: 13
Training loss: 0.17236948013305664
Validation loss: 2.047354499499003

Epoch: 465| Step: 0
Training loss: 0.5325160622596741
Validation loss: 2.1115947564442954

Epoch: 6| Step: 1
Training loss: 0.1891663670539856
Validation loss: 2.079718053340912

Epoch: 6| Step: 2
Training loss: 0.22183629870414734
Validation loss: 2.1169235905011496

Epoch: 6| Step: 3
Training loss: 0.22999072074890137
Validation loss: 2.0985787510871887

Epoch: 6| Step: 4
Training loss: 0.16845379769802094
Validation loss: 2.0930465857187905

Epoch: 6| Step: 5
Training loss: 0.1746736466884613
Validation loss: 2.106100161870321

Epoch: 6| Step: 6
Training loss: 0.2206248939037323
Validation loss: 2.07930318514506

Epoch: 6| Step: 7
Training loss: 0.3915691077709198
Validation loss: 2.0326765378316245

Epoch: 6| Step: 8
Training loss: 0.16650313138961792
Validation loss: 2.0810404817263284

Epoch: 6| Step: 9
Training loss: 0.18215183913707733
Validation loss: 2.0857715805371604

Epoch: 6| Step: 10
Training loss: 0.12600326538085938
Validation loss: 2.0557220180829368

Epoch: 6| Step: 11
Training loss: 0.23232431709766388
Validation loss: 2.141043245792389

Epoch: 6| Step: 12
Training loss: 0.22322534024715424
Validation loss: 2.0929433504740396

Epoch: 6| Step: 13
Training loss: 0.12374865263700485
Validation loss: 2.0696237087249756

Epoch: 466| Step: 0
Training loss: 0.2736660838127136
Validation loss: 2.067124366760254

Epoch: 6| Step: 1
Training loss: 0.22657807171344757
Validation loss: 2.1288238366444907

Epoch: 6| Step: 2
Training loss: 0.19500550627708435
Validation loss: 2.074047267436981

Epoch: 6| Step: 3
Training loss: 0.1685241460800171
Validation loss: 2.116342763106028

Epoch: 6| Step: 4
Training loss: 0.1459343433380127
Validation loss: 2.100219269593557

Epoch: 6| Step: 5
Training loss: 0.27123528718948364
Validation loss: 2.065538227558136

Epoch: 6| Step: 6
Training loss: 0.1824919581413269
Validation loss: 2.091910461584727

Epoch: 6| Step: 7
Training loss: 0.20546367764472961
Validation loss: 2.087278127670288

Epoch: 6| Step: 8
Training loss: 0.1048482358455658
Validation loss: 2.0512530406316123

Epoch: 6| Step: 9
Training loss: 0.18316508829593658
Validation loss: 2.069917917251587

Epoch: 6| Step: 10
Training loss: 0.57057124376297
Validation loss: 2.075730005900065

Epoch: 6| Step: 11
Training loss: 0.20894286036491394
Validation loss: 2.0489925940831504

Epoch: 6| Step: 12
Training loss: 0.36185944080352783
Validation loss: 2.081342418988546

Epoch: 6| Step: 13
Training loss: 0.24370284378528595
Validation loss: 2.0294747749964395

Epoch: 467| Step: 0
Training loss: 0.15672418475151062
Validation loss: 2.061713437239329

Epoch: 6| Step: 1
Training loss: 0.14223545789718628
Validation loss: 2.0681934555371604

Epoch: 6| Step: 2
Training loss: 0.24502885341644287
Validation loss: 2.05497008562088

Epoch: 6| Step: 3
Training loss: 0.16455191373825073
Validation loss: 2.0600280165672302

Epoch: 6| Step: 4
Training loss: 0.247261181473732
Validation loss: 2.0831364591916404

Epoch: 6| Step: 5
Training loss: 0.21471601724624634
Validation loss: 2.0758692224820456

Epoch: 6| Step: 6
Training loss: 0.2212500125169754
Validation loss: 2.051728387673696

Epoch: 6| Step: 7
Training loss: 0.18585717678070068
Validation loss: 2.061949868996938

Epoch: 6| Step: 8
Training loss: 0.1359739452600479
Validation loss: 2.053291936715444

Epoch: 6| Step: 9
Training loss: 0.5334253311157227
Validation loss: 2.044523020585378

Epoch: 6| Step: 10
Training loss: 0.32276856899261475
Validation loss: 2.0470240314801535

Epoch: 6| Step: 11
Training loss: 0.15744894742965698
Validation loss: 2.0951637625694275

Epoch: 6| Step: 12
Training loss: 0.3184293508529663
Validation loss: 2.0836848616600037

Epoch: 6| Step: 13
Training loss: 0.28420740365982056
Validation loss: 2.0653945207595825

Epoch: 468| Step: 0
Training loss: 0.18772107362747192
Validation loss: 2.106127460797628

Epoch: 6| Step: 1
Training loss: 0.12434729933738708
Validation loss: 2.096897433201472

Epoch: 6| Step: 2
Training loss: 0.15663635730743408
Validation loss: 2.088218708833059

Epoch: 6| Step: 3
Training loss: 0.20004120469093323
Validation loss: 2.0804509123166404

Epoch: 6| Step: 4
Training loss: 0.2167026251554489
Validation loss: 2.090281665325165

Epoch: 6| Step: 5
Training loss: 0.23290911316871643
Validation loss: 2.0778595606486

Epoch: 6| Step: 6
Training loss: 0.2365703582763672
Validation loss: 2.0713547666867576

Epoch: 6| Step: 7
Training loss: 0.5749279856681824
Validation loss: 2.102531691392263

Epoch: 6| Step: 8
Training loss: 0.19980424642562866
Validation loss: 2.0888424714406333

Epoch: 6| Step: 9
Training loss: 0.2889753580093384
Validation loss: 2.1094267765680947

Epoch: 6| Step: 10
Training loss: 0.24922652542591095
Validation loss: 2.1070359547932944

Epoch: 6| Step: 11
Training loss: 0.16050273180007935
Validation loss: 2.1251290440559387

Epoch: 6| Step: 12
Training loss: 0.16902944445610046
Validation loss: 2.076647102832794

Epoch: 6| Step: 13
Training loss: 0.3880065679550171
Validation loss: 2.070840080579122

Epoch: 469| Step: 0
Training loss: 0.17625051736831665
Validation loss: 2.0533389846483865

Epoch: 6| Step: 1
Training loss: 0.21376550197601318
Validation loss: 2.0512592792510986

Epoch: 6| Step: 2
Training loss: 0.520149290561676
Validation loss: 2.031180719534556

Epoch: 6| Step: 3
Training loss: 0.1386180818080902
Validation loss: 2.107731560866038

Epoch: 6| Step: 4
Training loss: 0.14135241508483887
Validation loss: 2.1172713239987693

Epoch: 6| Step: 5
Training loss: 0.15817880630493164
Validation loss: 2.0982964038848877

Epoch: 6| Step: 6
Training loss: 0.17714984714984894
Validation loss: 2.126280426979065

Epoch: 6| Step: 7
Training loss: 0.24283280968666077
Validation loss: 2.134975035985311

Epoch: 6| Step: 8
Training loss: 0.294904887676239
Validation loss: 2.0949490666389465

Epoch: 6| Step: 9
Training loss: 0.16908052563667297
Validation loss: 2.1261996030807495

Epoch: 6| Step: 10
Training loss: 0.13827498257160187
Validation loss: 2.0917593836784363

Epoch: 6| Step: 11
Training loss: 0.4319958984851837
Validation loss: 2.0995616912841797

Epoch: 6| Step: 12
Training loss: 0.23062416911125183
Validation loss: 2.0719418128331504

Epoch: 6| Step: 13
Training loss: 0.29150837659835815
Validation loss: 2.086798628171285

Epoch: 470| Step: 0
Training loss: 0.22324511408805847
Validation loss: 2.063174784183502

Epoch: 6| Step: 1
Training loss: 0.1457260549068451
Validation loss: 2.0881739258766174

Epoch: 6| Step: 2
Training loss: 0.20519620180130005
Validation loss: 2.1124334732691445

Epoch: 6| Step: 3
Training loss: 0.1602371335029602
Validation loss: 2.098892331123352

Epoch: 6| Step: 4
Training loss: 0.28888487815856934
Validation loss: 2.0793484250704446

Epoch: 6| Step: 5
Training loss: 0.2264123409986496
Validation loss: 2.054184873898824

Epoch: 6| Step: 6
Training loss: 0.20624573528766632
Validation loss: 2.0728654662768045

Epoch: 6| Step: 7
Training loss: 0.1756008416414261
Validation loss: 2.055945078531901

Epoch: 6| Step: 8
Training loss: 0.23412469029426575
Validation loss: 2.076314310232798

Epoch: 6| Step: 9
Training loss: 0.5107775926589966
Validation loss: 2.035313288370768

Epoch: 6| Step: 10
Training loss: 0.20830920338630676
Validation loss: 2.0627612471580505

Epoch: 6| Step: 11
Training loss: 0.6448630094528198
Validation loss: 2.0625813404719033

Epoch: 6| Step: 12
Training loss: 0.32062870264053345
Validation loss: 2.0819488763809204

Epoch: 6| Step: 13
Training loss: 0.15783478319644928
Validation loss: 2.085096995035807

Epoch: 471| Step: 0
Training loss: 0.2968367040157318
Validation loss: 2.0744571685791016

Epoch: 6| Step: 1
Training loss: 0.5830345153808594
Validation loss: 2.0850406686464944

Epoch: 6| Step: 2
Training loss: 0.2413608431816101
Validation loss: 2.0932143926620483

Epoch: 6| Step: 3
Training loss: 0.17231491208076477
Validation loss: 2.1402549544970193

Epoch: 6| Step: 4
Training loss: 0.28520065546035767
Validation loss: 2.084367275238037

Epoch: 6| Step: 5
Training loss: 0.370064914226532
Validation loss: 2.1238996187845864

Epoch: 6| Step: 6
Training loss: 0.2644285559654236
Validation loss: 2.077956477801005

Epoch: 6| Step: 7
Training loss: 0.49653491377830505
Validation loss: 2.0842034419377646

Epoch: 6| Step: 8
Training loss: 0.19282782077789307
Validation loss: 2.084798574447632

Epoch: 6| Step: 9
Training loss: 0.13969330489635468
Validation loss: 2.1027803222338357

Epoch: 6| Step: 10
Training loss: 0.22654592990875244
Validation loss: 2.0744378169377646

Epoch: 6| Step: 11
Training loss: 0.15107318758964539
Validation loss: 2.1166563828786216

Epoch: 6| Step: 12
Training loss: 0.32212209701538086
Validation loss: 2.103303909301758

Epoch: 6| Step: 13
Training loss: 0.3042435348033905
Validation loss: 2.128001352151235

Epoch: 472| Step: 0
Training loss: 0.2994548976421356
Validation loss: 2.1546971201896667

Epoch: 6| Step: 1
Training loss: 0.655910849571228
Validation loss: 2.0978491504987082

Epoch: 6| Step: 2
Training loss: 0.1382341831922531
Validation loss: 2.088087817033132

Epoch: 6| Step: 3
Training loss: 0.25121626257896423
Validation loss: 2.083028793334961

Epoch: 6| Step: 4
Training loss: 0.14778947830200195
Validation loss: 2.1047693292299905

Epoch: 6| Step: 5
Training loss: 0.203541100025177
Validation loss: 2.0521682500839233

Epoch: 6| Step: 6
Training loss: 0.213538259267807
Validation loss: 2.106803079446157

Epoch: 6| Step: 7
Training loss: 0.20734277367591858
Validation loss: 2.048264503479004

Epoch: 6| Step: 8
Training loss: 0.15725141763687134
Validation loss: 2.0575760205586753

Epoch: 6| Step: 9
Training loss: 0.13127659261226654
Validation loss: 2.0784888863563538

Epoch: 6| Step: 10
Training loss: 0.14771613478660583
Validation loss: 2.067880551020304

Epoch: 6| Step: 11
Training loss: 0.17277920246124268
Validation loss: 2.054076353708903

Epoch: 6| Step: 12
Training loss: 0.1978846788406372
Validation loss: 2.075852553049723

Epoch: 6| Step: 13
Training loss: 0.14849147200584412
Validation loss: 2.0669535199801126

Epoch: 473| Step: 0
Training loss: 0.1658417284488678
Validation loss: 2.0785821080207825

Epoch: 6| Step: 1
Training loss: 0.13010510802268982
Validation loss: 2.063979923725128

Epoch: 6| Step: 2
Training loss: 0.1544826775789261
Validation loss: 2.076780358950297

Epoch: 6| Step: 3
Training loss: 0.24023665487766266
Validation loss: 2.0688563783963523

Epoch: 6| Step: 4
Training loss: 0.14841651916503906
Validation loss: 2.061975439389547

Epoch: 6| Step: 5
Training loss: 0.12484994530677795
Validation loss: 2.0474130709966025

Epoch: 6| Step: 6
Training loss: 0.22965659201145172
Validation loss: 2.074137886365255

Epoch: 6| Step: 7
Training loss: 0.27039968967437744
Validation loss: 2.098642428716024

Epoch: 6| Step: 8
Training loss: 0.15329356491565704
Validation loss: 2.0847461024920144

Epoch: 6| Step: 9
Training loss: 0.21103554964065552
Validation loss: 2.0772990783055625

Epoch: 6| Step: 10
Training loss: 0.39473971724510193
Validation loss: 2.073337217171987

Epoch: 6| Step: 11
Training loss: 0.18360184133052826
Validation loss: 2.0833706061045327

Epoch: 6| Step: 12
Training loss: 0.2585758864879608
Validation loss: 2.090986510117849

Epoch: 6| Step: 13
Training loss: 0.6275140047073364
Validation loss: 2.1132461428642273

Epoch: 474| Step: 0
Training loss: 0.2115388810634613
Validation loss: 2.1184008518854776

Epoch: 6| Step: 1
Training loss: 0.6542266011238098
Validation loss: 2.0612014134724936

Epoch: 6| Step: 2
Training loss: 0.16409380733966827
Validation loss: 2.1056533455848694

Epoch: 6| Step: 3
Training loss: 0.27230194211006165
Validation loss: 2.1365105708440146

Epoch: 6| Step: 4
Training loss: 0.2076878696680069
Validation loss: 2.1758910616238913

Epoch: 6| Step: 5
Training loss: 0.16088038682937622
Validation loss: 2.0912341276804605

Epoch: 6| Step: 6
Training loss: 0.27572792768478394
Validation loss: 2.1133773724238076

Epoch: 6| Step: 7
Training loss: 0.20070357620716095
Validation loss: 2.0653817852338157

Epoch: 6| Step: 8
Training loss: 0.1604323834180832
Validation loss: 2.0948250691095986

Epoch: 6| Step: 9
Training loss: 0.18985486030578613
Validation loss: 2.0753045082092285

Epoch: 6| Step: 10
Training loss: 0.23938757181167603
Validation loss: 2.0450950264930725

Epoch: 6| Step: 11
Training loss: 0.2517167329788208
Validation loss: 2.0889501372973123

Epoch: 6| Step: 12
Training loss: 0.12515726685523987
Validation loss: 2.0822057723999023

Epoch: 6| Step: 13
Training loss: 0.36325347423553467
Validation loss: 2.092323064804077

Epoch: 475| Step: 0
Training loss: 0.18789702653884888
Validation loss: 2.123659690221151

Epoch: 6| Step: 1
Training loss: 0.355675607919693
Validation loss: 2.0949408213297525

Epoch: 6| Step: 2
Training loss: 0.2164228856563568
Validation loss: 2.091257890065511

Epoch: 6| Step: 3
Training loss: 0.4645189344882965
Validation loss: 2.079308350880941

Epoch: 6| Step: 4
Training loss: 0.18417447805404663
Validation loss: 2.0637951095898948

Epoch: 6| Step: 5
Training loss: 0.15289342403411865
Validation loss: 2.075567821661631

Epoch: 6| Step: 6
Training loss: 0.22946441173553467
Validation loss: 2.0614158113797507

Epoch: 6| Step: 7
Training loss: 0.14044876396656036
Validation loss: 2.0668052236239114

Epoch: 6| Step: 8
Training loss: 0.26519593596458435
Validation loss: 2.080957810084025

Epoch: 6| Step: 9
Training loss: 0.1291576325893402
Validation loss: 2.057995100816091

Epoch: 6| Step: 10
Training loss: 0.15850698947906494
Validation loss: 2.0639857848485312

Epoch: 6| Step: 11
Training loss: 0.18512552976608276
Validation loss: 2.0633502999941506

Epoch: 6| Step: 12
Training loss: 0.2235896736383438
Validation loss: 2.0507287979125977

Epoch: 6| Step: 13
Training loss: 0.15624432265758514
Validation loss: 2.0532090862592063

Epoch: 476| Step: 0
Training loss: 0.1258666217327118
Validation loss: 2.0829983750979104

Epoch: 6| Step: 1
Training loss: 0.54826420545578
Validation loss: 2.086239834626516

Epoch: 6| Step: 2
Training loss: 0.20676125586032867
Validation loss: 2.0836591521898904

Epoch: 6| Step: 3
Training loss: 0.17840014398097992
Validation loss: 2.0452714363733926

Epoch: 6| Step: 4
Training loss: 0.23611512780189514
Validation loss: 2.0644263426462808

Epoch: 6| Step: 5
Training loss: 0.13777107000350952
Validation loss: 2.0602375268936157

Epoch: 6| Step: 6
Training loss: 0.17769736051559448
Validation loss: 2.0931434830029807

Epoch: 6| Step: 7
Training loss: 0.1915721446275711
Validation loss: 2.0866382122039795

Epoch: 6| Step: 8
Training loss: 0.1311580240726471
Validation loss: 2.0599547028541565

Epoch: 6| Step: 9
Training loss: 0.23704910278320312
Validation loss: 2.075734714667002

Epoch: 6| Step: 10
Training loss: 0.17759579420089722
Validation loss: 2.0838544567426047

Epoch: 6| Step: 11
Training loss: 0.22728431224822998
Validation loss: 2.07468044757843

Epoch: 6| Step: 12
Training loss: 0.24607867002487183
Validation loss: 2.059311548868815

Epoch: 6| Step: 13
Training loss: 0.2891450822353363
Validation loss: 2.0840938289960227

Epoch: 477| Step: 0
Training loss: 0.3598581850528717
Validation loss: 2.0949612061182656

Epoch: 6| Step: 1
Training loss: 0.21237380802631378
Validation loss: 2.0875457922617593

Epoch: 6| Step: 2
Training loss: 0.5874655246734619
Validation loss: 2.090686817963918

Epoch: 6| Step: 3
Training loss: 0.2528495490550995
Validation loss: 2.1208025217056274

Epoch: 6| Step: 4
Training loss: 0.19950640201568604
Validation loss: 2.095090309778849

Epoch: 6| Step: 5
Training loss: 0.2317793220281601
Validation loss: 2.0969945987065635

Epoch: 6| Step: 6
Training loss: 0.1771124303340912
Validation loss: 2.111962914466858

Epoch: 6| Step: 7
Training loss: 0.1501196026802063
Validation loss: 2.1044368942578635

Epoch: 6| Step: 8
Training loss: 0.19690266251564026
Validation loss: 2.0716603994369507

Epoch: 6| Step: 9
Training loss: 0.18447542190551758
Validation loss: 2.083544969558716

Epoch: 6| Step: 10
Training loss: 0.17736801505088806
Validation loss: 2.0769543647766113

Epoch: 6| Step: 11
Training loss: 0.14133882522583008
Validation loss: 2.0573857625325522

Epoch: 6| Step: 12
Training loss: 0.3426065742969513
Validation loss: 2.048011859258016

Epoch: 6| Step: 13
Training loss: 0.19283506274223328
Validation loss: 2.0578878124554953

Epoch: 478| Step: 0
Training loss: 0.16479524970054626
Validation loss: 2.099453945954641

Epoch: 6| Step: 1
Training loss: 0.22055432200431824
Validation loss: 2.1062180598576865

Epoch: 6| Step: 2
Training loss: 0.30017414689064026
Validation loss: 2.097543021043142

Epoch: 6| Step: 3
Training loss: 0.19596055150032043
Validation loss: 2.0919402837753296

Epoch: 6| Step: 4
Training loss: 0.1390838921070099
Validation loss: 2.0668158531188965

Epoch: 6| Step: 5
Training loss: 0.14069443941116333
Validation loss: 2.0924229423205056

Epoch: 6| Step: 6
Training loss: 0.5432637929916382
Validation loss: 2.0741355220476785

Epoch: 6| Step: 7
Training loss: 0.15828309953212738
Validation loss: 2.0624272425969443

Epoch: 6| Step: 8
Training loss: 0.2364780455827713
Validation loss: 2.067497730255127

Epoch: 6| Step: 9
Training loss: 0.15040996670722961
Validation loss: 2.0606648127237954

Epoch: 6| Step: 10
Training loss: 0.15436813235282898
Validation loss: 2.0276883244514465

Epoch: 6| Step: 11
Training loss: 0.2161375880241394
Validation loss: 2.0394381284713745

Epoch: 6| Step: 12
Training loss: 0.21677395701408386
Validation loss: 2.129803458849589

Epoch: 6| Step: 13
Training loss: 0.38471853733062744
Validation loss: 2.0956018765767417

Epoch: 479| Step: 0
Training loss: 0.22805042564868927
Validation loss: 2.0895161827405295

Epoch: 6| Step: 1
Training loss: 0.17418697476387024
Validation loss: 2.01729824145635

Epoch: 6| Step: 2
Training loss: 0.17882004380226135
Validation loss: 2.064929723739624

Epoch: 6| Step: 3
Training loss: 0.21778114140033722
Validation loss: 2.0722127755482993

Epoch: 6| Step: 4
Training loss: 0.18427884578704834
Validation loss: 2.0437193512916565

Epoch: 6| Step: 5
Training loss: 0.22452449798583984
Validation loss: 2.090888758500417

Epoch: 6| Step: 6
Training loss: 0.5809078812599182
Validation loss: 2.0523469845453897

Epoch: 6| Step: 7
Training loss: 0.19249960780143738
Validation loss: 2.0576176246007285

Epoch: 6| Step: 8
Training loss: 0.1916409581899643
Validation loss: 2.0293338100115457

Epoch: 6| Step: 9
Training loss: 0.36466899514198303
Validation loss: 2.0517531633377075

Epoch: 6| Step: 10
Training loss: 0.1698223054409027
Validation loss: 2.108061949412028

Epoch: 6| Step: 11
Training loss: 0.17167381942272186
Validation loss: 2.0925228794415793

Epoch: 6| Step: 12
Training loss: 0.23164066672325134
Validation loss: 2.069777230421702

Epoch: 6| Step: 13
Training loss: 0.2654632329940796
Validation loss: 2.1317074298858643

Epoch: 480| Step: 0
Training loss: 0.13242554664611816
Validation loss: 2.0841922760009766

Epoch: 6| Step: 1
Training loss: 0.14219744503498077
Validation loss: 2.111965755621592

Epoch: 6| Step: 2
Training loss: 0.21073739230632782
Validation loss: 2.0791543324788413

Epoch: 6| Step: 3
Training loss: 0.2899961769580841
Validation loss: 2.074439307053884

Epoch: 6| Step: 4
Training loss: 0.21935458481311798
Validation loss: 2.123554209868113

Epoch: 6| Step: 5
Training loss: 0.3762509524822235
Validation loss: 2.0558924873669944

Epoch: 6| Step: 6
Training loss: 0.18940161168575287
Validation loss: 2.092982769012451

Epoch: 6| Step: 7
Training loss: 0.15355660021305084
Validation loss: 2.0459178686141968

Epoch: 6| Step: 8
Training loss: 0.28804099559783936
Validation loss: 2.0942207177480063

Epoch: 6| Step: 9
Training loss: 0.747718095779419
Validation loss: 2.1160192688306174

Epoch: 6| Step: 10
Training loss: 0.22096675634384155
Validation loss: 2.078685442606608

Epoch: 6| Step: 11
Training loss: 0.47386980056762695
Validation loss: 2.0866617361704507

Epoch: 6| Step: 12
Training loss: 0.21126127243041992
Validation loss: 2.061577399571737

Epoch: 6| Step: 13
Training loss: 0.18255239725112915
Validation loss: 2.0768287976582847

Epoch: 481| Step: 0
Training loss: 0.19051308929920197
Validation loss: 2.0619208415349326

Epoch: 6| Step: 1
Training loss: 0.14066588878631592
Validation loss: 2.073467711607615

Epoch: 6| Step: 2
Training loss: 0.2611525058746338
Validation loss: 2.086456755797068

Epoch: 6| Step: 3
Training loss: 0.22509810328483582
Validation loss: 2.0838331381479898

Epoch: 6| Step: 4
Training loss: 0.19776037335395813
Validation loss: 2.0679415663083396

Epoch: 6| Step: 5
Training loss: 0.17053832113742828
Validation loss: 2.083110491434733

Epoch: 6| Step: 6
Training loss: 0.34560567140579224
Validation loss: 2.090478996435801

Epoch: 6| Step: 7
Training loss: 0.12287409603595734
Validation loss: 2.0736996134122214

Epoch: 6| Step: 8
Training loss: 0.19675682485103607
Validation loss: 2.055827339490255

Epoch: 6| Step: 9
Training loss: 0.19286487996578217
Validation loss: 2.092138628164927

Epoch: 6| Step: 10
Training loss: 0.2349398285150528
Validation loss: 2.062899430592855

Epoch: 6| Step: 11
Training loss: 0.563944399356842
Validation loss: 2.111814041932424

Epoch: 6| Step: 12
Training loss: 0.2559884190559387
Validation loss: 2.121071457862854

Epoch: 6| Step: 13
Training loss: 0.27179068326950073
Validation loss: 2.079088250796

Epoch: 482| Step: 0
Training loss: 0.23409391939640045
Validation loss: 2.0674010117848716

Epoch: 6| Step: 1
Training loss: 0.1638941764831543
Validation loss: 2.0446849862734475

Epoch: 6| Step: 2
Training loss: 0.3200342655181885
Validation loss: 2.1161011854807534

Epoch: 6| Step: 3
Training loss: 0.1687246859073639
Validation loss: 2.0796035726865134

Epoch: 6| Step: 4
Training loss: 0.7449349761009216
Validation loss: 2.080376366774241

Epoch: 6| Step: 5
Training loss: 0.21538451313972473
Validation loss: 2.0914888779322305

Epoch: 6| Step: 6
Training loss: 0.18466250598430634
Validation loss: 2.0592044591903687

Epoch: 6| Step: 7
Training loss: 0.2514761686325073
Validation loss: 2.088093558947245

Epoch: 6| Step: 8
Training loss: 0.4048658609390259
Validation loss: 2.110092520713806

Epoch: 6| Step: 9
Training loss: 0.18667252361774445
Validation loss: 2.0718663930892944

Epoch: 6| Step: 10
Training loss: 0.22808042168617249
Validation loss: 2.0770144859949746

Epoch: 6| Step: 11
Training loss: 0.2012656033039093
Validation loss: 2.0714864134788513

Epoch: 6| Step: 12
Training loss: 0.26664191484451294
Validation loss: 2.0815031131108603

Epoch: 6| Step: 13
Training loss: 0.22435487806797028
Validation loss: 2.0488084157307944

Epoch: 483| Step: 0
Training loss: 0.49207574129104614
Validation loss: 2.035392165184021

Epoch: 6| Step: 1
Training loss: 0.2565614581108093
Validation loss: 2.113405466079712

Epoch: 6| Step: 2
Training loss: 0.24947519600391388
Validation loss: 2.0490628679593406

Epoch: 6| Step: 3
Training loss: 0.16082598268985748
Validation loss: 2.061199724674225

Epoch: 6| Step: 4
Training loss: 0.19889533519744873
Validation loss: 2.0476016799608865

Epoch: 6| Step: 5
Training loss: 0.24073857069015503
Validation loss: 2.080229341983795

Epoch: 6| Step: 6
Training loss: 0.197822704911232
Validation loss: 2.045468270778656

Epoch: 6| Step: 7
Training loss: 0.17035318911075592
Validation loss: 2.082010567188263

Epoch: 6| Step: 8
Training loss: 0.165153369307518
Validation loss: 2.0421223243077598

Epoch: 6| Step: 9
Training loss: 0.20775705575942993
Validation loss: 2.0595728158950806

Epoch: 6| Step: 10
Training loss: 0.538577139377594
Validation loss: 2.079151372114817

Epoch: 6| Step: 11
Training loss: 0.160539448261261
Validation loss: 2.073912183443705

Epoch: 6| Step: 12
Training loss: 0.25894254446029663
Validation loss: 2.1059542894363403

Epoch: 6| Step: 13
Training loss: 0.2080031931400299
Validation loss: 2.0749215682347617

Epoch: 484| Step: 0
Training loss: 0.1336108297109604
Validation loss: 2.060975432395935

Epoch: 6| Step: 1
Training loss: 0.23360860347747803
Validation loss: 2.088972886403402

Epoch: 6| Step: 2
Training loss: 0.16082149744033813
Validation loss: 2.0877141753832498

Epoch: 6| Step: 3
Training loss: 0.21569229662418365
Validation loss: 2.0800033609072366

Epoch: 6| Step: 4
Training loss: 0.17811442911624908
Validation loss: 2.085177004337311

Epoch: 6| Step: 5
Training loss: 0.7444992065429688
Validation loss: 2.0996944506963096

Epoch: 6| Step: 6
Training loss: 0.14087599515914917
Validation loss: 2.0766295194625854

Epoch: 6| Step: 7
Training loss: 0.2304026186466217
Validation loss: 2.063813845316569

Epoch: 6| Step: 8
Training loss: 0.12228938937187195
Validation loss: 2.0769508481025696

Epoch: 6| Step: 9
Training loss: 0.21353213489055634
Validation loss: 2.101774831612905

Epoch: 6| Step: 10
Training loss: 0.1439042091369629
Validation loss: 2.1259566942850747

Epoch: 6| Step: 11
Training loss: 0.22704166173934937
Validation loss: 2.097825845082601

Epoch: 6| Step: 12
Training loss: 0.13182878494262695
Validation loss: 2.0691517988840737

Epoch: 6| Step: 13
Training loss: 0.16835133731365204
Validation loss: 2.065847416718801

Epoch: 485| Step: 0
Training loss: 0.1208583414554596
Validation loss: 2.1057326793670654

Epoch: 6| Step: 1
Training loss: 0.11250471323728561
Validation loss: 2.0584839383761087

Epoch: 6| Step: 2
Training loss: 0.1507037878036499
Validation loss: 2.1032755772272744

Epoch: 6| Step: 3
Training loss: 0.19611525535583496
Validation loss: 2.057787239551544

Epoch: 6| Step: 4
Training loss: 0.21712931990623474
Validation loss: 2.0835782885551453

Epoch: 6| Step: 5
Training loss: 0.6447610855102539
Validation loss: 2.059394657611847

Epoch: 6| Step: 6
Training loss: 0.23638302087783813
Validation loss: 2.0630929867426553

Epoch: 6| Step: 7
Training loss: 0.20507314801216125
Validation loss: 2.092707872390747

Epoch: 6| Step: 8
Training loss: 0.1335727870464325
Validation loss: 2.1086238026618958

Epoch: 6| Step: 9
Training loss: 0.09940531849861145
Validation loss: 2.0747086803118386

Epoch: 6| Step: 10
Training loss: 0.2213098555803299
Validation loss: 2.0802319844563804

Epoch: 6| Step: 11
Training loss: 0.3120621144771576
Validation loss: 2.080913503964742

Epoch: 6| Step: 12
Training loss: 0.22104786336421967
Validation loss: 2.100839455922445

Epoch: 6| Step: 13
Training loss: 0.2388828992843628
Validation loss: 2.0618414084116616

Epoch: 486| Step: 0
Training loss: 0.19357618689537048
Validation loss: 2.055026650428772

Epoch: 6| Step: 1
Training loss: 0.1925772726535797
Validation loss: 2.0580704609553018

Epoch: 6| Step: 2
Training loss: 0.20491744577884674
Validation loss: 2.0668453772862754

Epoch: 6| Step: 3
Training loss: 0.17883722484111786
Validation loss: 2.0690471132596335

Epoch: 6| Step: 4
Training loss: 0.1869416981935501
Validation loss: 2.046527087688446

Epoch: 6| Step: 5
Training loss: 0.6172025203704834
Validation loss: 2.099688092867533

Epoch: 6| Step: 6
Training loss: 0.33225154876708984
Validation loss: 2.040740152200063

Epoch: 6| Step: 7
Training loss: 0.12047507613897324
Validation loss: 2.082014262676239

Epoch: 6| Step: 8
Training loss: 0.20049384236335754
Validation loss: 2.0910300811131797

Epoch: 6| Step: 9
Training loss: 0.18366973102092743
Validation loss: 2.0689345796902976

Epoch: 6| Step: 10
Training loss: 0.2606269121170044
Validation loss: 2.088250001271566

Epoch: 6| Step: 11
Training loss: 0.2283283770084381
Validation loss: 2.0926310618718467

Epoch: 6| Step: 12
Training loss: 0.2419300079345703
Validation loss: 2.0514289140701294

Epoch: 6| Step: 13
Training loss: 0.18709751963615417
Validation loss: 2.092806041240692

Epoch: 487| Step: 0
Training loss: 0.10643869638442993
Validation loss: 2.0723804434140525

Epoch: 6| Step: 1
Training loss: 0.15550580620765686
Validation loss: 2.059971829255422

Epoch: 6| Step: 2
Training loss: 0.2251952588558197
Validation loss: 2.07168577114741

Epoch: 6| Step: 3
Training loss: 0.567767858505249
Validation loss: 2.067534625530243

Epoch: 6| Step: 4
Training loss: 0.23671025037765503
Validation loss: 2.093333423137665

Epoch: 6| Step: 5
Training loss: 0.29154208302497864
Validation loss: 2.074869910875956

Epoch: 6| Step: 6
Training loss: 0.1907196342945099
Validation loss: 2.073473850886027

Epoch: 6| Step: 7
Training loss: 0.16165733337402344
Validation loss: 2.110790431499481

Epoch: 6| Step: 8
Training loss: 0.23334914445877075
Validation loss: 2.0576183597246804

Epoch: 6| Step: 9
Training loss: 0.14302627742290497
Validation loss: 2.094348589579264

Epoch: 6| Step: 10
Training loss: 0.21749120950698853
Validation loss: 2.026832362016042

Epoch: 6| Step: 11
Training loss: 0.45060840249061584
Validation loss: 2.04488742351532

Epoch: 6| Step: 12
Training loss: 0.262141615152359
Validation loss: 2.0724673668543496

Epoch: 6| Step: 13
Training loss: 0.2303394079208374
Validation loss: 2.0702467958132424

Epoch: 488| Step: 0
Training loss: 0.15794315934181213
Validation loss: 2.0382202863693237

Epoch: 6| Step: 1
Training loss: 0.21678629517555237
Validation loss: 2.055105964342753

Epoch: 6| Step: 2
Training loss: 0.148561030626297
Validation loss: 2.0507736007372537

Epoch: 6| Step: 3
Training loss: 0.22091516852378845
Validation loss: 2.115243752797445

Epoch: 6| Step: 4
Training loss: 0.13555178046226501
Validation loss: 2.0888513922691345

Epoch: 6| Step: 5
Training loss: 0.21086086332798004
Validation loss: 2.066079060236613

Epoch: 6| Step: 6
Training loss: 0.27946197986602783
Validation loss: 2.0521772503852844

Epoch: 6| Step: 7
Training loss: 0.25671935081481934
Validation loss: 2.040453016757965

Epoch: 6| Step: 8
Training loss: 0.14878253638744354
Validation loss: 2.0681679050127664

Epoch: 6| Step: 9
Training loss: 0.24726027250289917
Validation loss: 2.0543686747550964

Epoch: 6| Step: 10
Training loss: 0.3706433176994324
Validation loss: 2.0317907532056174

Epoch: 6| Step: 11
Training loss: 0.2207184135913849
Validation loss: 2.033017853895823

Epoch: 6| Step: 12
Training loss: 0.19217628240585327
Validation loss: 2.056123892466227

Epoch: 6| Step: 13
Training loss: 0.7229433059692383
Validation loss: 2.075723727544149

Epoch: 489| Step: 0
Training loss: 0.1948416531085968
Validation loss: 2.0554246306419373

Epoch: 6| Step: 1
Training loss: 0.2499023824930191
Validation loss: 2.097672979036967

Epoch: 6| Step: 2
Training loss: 0.4101024866104126
Validation loss: 2.1101304292678833

Epoch: 6| Step: 3
Training loss: 0.14547136425971985
Validation loss: 2.055413464705149

Epoch: 6| Step: 4
Training loss: 0.2427733689546585
Validation loss: 2.0421263774236045

Epoch: 6| Step: 5
Training loss: 0.16108223795890808
Validation loss: 2.0428755283355713

Epoch: 6| Step: 6
Training loss: 0.6492187976837158
Validation loss: 2.015755534172058

Epoch: 6| Step: 7
Training loss: 0.17463579773902893
Validation loss: 2.020709534486135

Epoch: 6| Step: 8
Training loss: 0.23884165287017822
Validation loss: 2.0470327734947205

Epoch: 6| Step: 9
Training loss: 0.12993402779102325
Validation loss: 2.077720801035563

Epoch: 6| Step: 10
Training loss: 0.1636803150177002
Validation loss: 2.027947207291921

Epoch: 6| Step: 11
Training loss: 0.25048592686653137
Validation loss: 2.1566896438598633

Epoch: 6| Step: 12
Training loss: 0.25157392024993896
Validation loss: 2.0809372464815774

Epoch: 6| Step: 13
Training loss: 0.22680401802062988
Validation loss: 2.0977665980656943

Epoch: 490| Step: 0
Training loss: 0.17929105460643768
Validation loss: 2.069074273109436

Epoch: 6| Step: 1
Training loss: 0.18972399830818176
Validation loss: 2.110736926396688

Epoch: 6| Step: 2
Training loss: 0.17598381638526917
Validation loss: 2.094429592291514

Epoch: 6| Step: 3
Training loss: 0.2984389662742615
Validation loss: 2.04638942082723

Epoch: 6| Step: 4
Training loss: 0.20962148904800415
Validation loss: 2.0597851475079856

Epoch: 6| Step: 5
Training loss: 0.2150353342294693
Validation loss: 2.064705411593119

Epoch: 6| Step: 6
Training loss: 0.19188565015792847
Validation loss: 2.0487074653307595

Epoch: 6| Step: 7
Training loss: 0.567823588848114
Validation loss: 2.0637132128079734

Epoch: 6| Step: 8
Training loss: 0.1373848021030426
Validation loss: 2.059533099333445

Epoch: 6| Step: 9
Training loss: 0.23328357934951782
Validation loss: 2.0778340895970664

Epoch: 6| Step: 10
Training loss: 0.1609451025724411
Validation loss: 2.065214157104492

Epoch: 6| Step: 11
Training loss: 0.1380908489227295
Validation loss: 2.074926515420278

Epoch: 6| Step: 12
Training loss: 0.22420042753219604
Validation loss: 2.0750624934832254

Epoch: 6| Step: 13
Training loss: 0.18214821815490723
Validation loss: 2.073967615763346

Epoch: 491| Step: 0
Training loss: 0.23496408760547638
Validation loss: 2.076502720514933

Epoch: 6| Step: 1
Training loss: 0.2254386842250824
Validation loss: 2.0841067830721536

Epoch: 6| Step: 2
Training loss: 0.17620258033275604
Validation loss: 2.0612333615620932

Epoch: 6| Step: 3
Training loss: 0.19787918031215668
Validation loss: 2.0675418774286904

Epoch: 6| Step: 4
Training loss: 0.30502307415008545
Validation loss: 2.064967393875122

Epoch: 6| Step: 5
Training loss: 0.13956356048583984
Validation loss: 2.051381210486094

Epoch: 6| Step: 6
Training loss: 0.7781693935394287
Validation loss: 2.052890102068583

Epoch: 6| Step: 7
Training loss: 0.27541792392730713
Validation loss: 2.0628904700279236

Epoch: 6| Step: 8
Training loss: 0.15933199226856232
Validation loss: 2.058500031630198

Epoch: 6| Step: 9
Training loss: 0.2311534285545349
Validation loss: 2.087038040161133

Epoch: 6| Step: 10
Training loss: 0.2718433737754822
Validation loss: 2.061961750189463

Epoch: 6| Step: 11
Training loss: 0.15212813019752502
Validation loss: 2.0882660349210105

Epoch: 6| Step: 12
Training loss: 0.11897297203540802
Validation loss: 2.076278825600942

Epoch: 6| Step: 13
Training loss: 0.24641847610473633
Validation loss: 2.0966604153315225

Epoch: 492| Step: 0
Training loss: 0.22939422726631165
Validation loss: 2.100772718588511

Epoch: 6| Step: 1
Training loss: 0.4155435562133789
Validation loss: 2.0943713585535684

Epoch: 6| Step: 2
Training loss: 0.13918301463127136
Validation loss: 2.0684706966082254

Epoch: 6| Step: 3
Training loss: 0.1300901472568512
Validation loss: 2.0744241078694663

Epoch: 6| Step: 4
Training loss: 0.1507892608642578
Validation loss: 2.0312424699465432

Epoch: 6| Step: 5
Training loss: 0.22635909914970398
Validation loss: 2.092872202396393

Epoch: 6| Step: 6
Training loss: 0.3000507950782776
Validation loss: 2.095025420188904

Epoch: 6| Step: 7
Training loss: 0.18164700269699097
Validation loss: 2.0531859596570334

Epoch: 6| Step: 8
Training loss: 0.23426228761672974
Validation loss: 2.072000583012899

Epoch: 6| Step: 9
Training loss: 0.17752939462661743
Validation loss: 2.069510579109192

Epoch: 6| Step: 10
Training loss: 0.5823066830635071
Validation loss: 2.0659001668294272

Epoch: 6| Step: 11
Training loss: 0.14612258970737457
Validation loss: 2.0532392462094626

Epoch: 6| Step: 12
Training loss: 0.1888066530227661
Validation loss: 2.1041446725527444

Epoch: 6| Step: 13
Training loss: 0.15727835893630981
Validation loss: 2.0673921505610147

Epoch: 493| Step: 0
Training loss: 0.14368563890457153
Validation loss: 2.003721276919047

Epoch: 6| Step: 1
Training loss: 0.24045979976654053
Validation loss: 2.0149608651796975

Epoch: 6| Step: 2
Training loss: 0.19267599284648895
Validation loss: 2.0673694809277854

Epoch: 6| Step: 3
Training loss: 0.2921619415283203
Validation loss: 2.0622703433036804

Epoch: 6| Step: 4
Training loss: 0.22883611917495728
Validation loss: 2.082058906555176

Epoch: 6| Step: 5
Training loss: 0.19662392139434814
Validation loss: 2.097545941670736

Epoch: 6| Step: 6
Training loss: 0.2730920910835266
Validation loss: 2.0874165296554565

Epoch: 6| Step: 7
Training loss: 0.1552596241235733
Validation loss: 2.0978585680325827

Epoch: 6| Step: 8
Training loss: 0.180278480052948
Validation loss: 2.057075003782908

Epoch: 6| Step: 9
Training loss: 0.6268416047096252
Validation loss: 2.1013251543045044

Epoch: 6| Step: 10
Training loss: 0.17686118185520172
Validation loss: 2.075310985247294

Epoch: 6| Step: 11
Training loss: 0.36685651540756226
Validation loss: 2.0285585125287375

Epoch: 6| Step: 12
Training loss: 0.1523016095161438
Validation loss: 2.0923696756362915

Epoch: 6| Step: 13
Training loss: 0.18110215663909912
Validation loss: 2.055746157964071

Epoch: 494| Step: 0
Training loss: 0.21695634722709656
Validation loss: 2.058437625567118

Epoch: 6| Step: 1
Training loss: 0.509028434753418
Validation loss: 2.053420662879944

Epoch: 6| Step: 2
Training loss: 0.15897023677825928
Validation loss: 2.1166664560635886

Epoch: 6| Step: 3
Training loss: 0.16556215286254883
Validation loss: 2.066299478212992

Epoch: 6| Step: 4
Training loss: 0.20031893253326416
Validation loss: 2.046390394369761

Epoch: 6| Step: 5
Training loss: 0.15502241253852844
Validation loss: 2.1265286803245544

Epoch: 6| Step: 6
Training loss: 0.11813052743673325
Validation loss: 2.025450885295868

Epoch: 6| Step: 7
Training loss: 0.41280803084373474
Validation loss: 2.0444934368133545

Epoch: 6| Step: 8
Training loss: 0.15359382331371307
Validation loss: 2.060740868250529

Epoch: 6| Step: 9
Training loss: 0.14071738719940186
Validation loss: 2.0824297666549683

Epoch: 6| Step: 10
Training loss: 0.23823319375514984
Validation loss: 2.044732630252838

Epoch: 6| Step: 11
Training loss: 0.190778911113739
Validation loss: 2.0260517994562783

Epoch: 6| Step: 12
Training loss: 0.21667224168777466
Validation loss: 2.0714661677678428

Epoch: 6| Step: 13
Training loss: 0.2115935981273651
Validation loss: 2.0585220654805503

Epoch: 495| Step: 0
Training loss: 0.19683673977851868
Validation loss: 2.066062112649282

Epoch: 6| Step: 1
Training loss: 0.16184385120868683
Validation loss: 2.0162674387296042

Epoch: 6| Step: 2
Training loss: 0.18580453097820282
Validation loss: 2.064047555128733

Epoch: 6| Step: 3
Training loss: 0.5484213829040527
Validation loss: 2.0622239311536155

Epoch: 6| Step: 4
Training loss: 0.1714257001876831
Validation loss: 2.0698317289352417

Epoch: 6| Step: 5
Training loss: 0.3215835690498352
Validation loss: 2.084469755490621

Epoch: 6| Step: 6
Training loss: 0.23047339916229248
Validation loss: 2.0823617378870645

Epoch: 6| Step: 7
Training loss: 0.2326413094997406
Validation loss: 2.0693059166272483

Epoch: 6| Step: 8
Training loss: 0.24830347299575806
Validation loss: 2.0548279881477356

Epoch: 6| Step: 9
Training loss: 0.17306527495384216
Validation loss: 2.068267027537028

Epoch: 6| Step: 10
Training loss: 0.1152765154838562
Validation loss: 2.0797475576400757

Epoch: 6| Step: 11
Training loss: 0.19804325699806213
Validation loss: 2.067554215590159

Epoch: 6| Step: 12
Training loss: 0.1965809464454651
Validation loss: 2.04763263463974

Epoch: 6| Step: 13
Training loss: 0.2895370423793793
Validation loss: 2.0685853958129883

Epoch: 496| Step: 0
Training loss: 0.2254370152950287
Validation loss: 2.0627287228902182

Epoch: 6| Step: 1
Training loss: 0.3793215751647949
Validation loss: 2.1013058026631675

Epoch: 6| Step: 2
Training loss: 0.21114321053028107
Validation loss: 2.066651781400045

Epoch: 6| Step: 3
Training loss: 0.21448510885238647
Validation loss: 2.0446839133898416

Epoch: 6| Step: 4
Training loss: 0.23583658039569855
Validation loss: 2.0618677934010825

Epoch: 6| Step: 5
Training loss: 0.18409571051597595
Validation loss: 2.0782023668289185

Epoch: 6| Step: 6
Training loss: 0.17943178117275238
Validation loss: 2.105335752169291

Epoch: 6| Step: 7
Training loss: 0.6070692539215088
Validation loss: 2.0812355279922485

Epoch: 6| Step: 8
Training loss: 0.2559677064418793
Validation loss: 2.062553882598877

Epoch: 6| Step: 9
Training loss: 0.2531718313694
Validation loss: 2.0808856089909873

Epoch: 6| Step: 10
Training loss: 0.21338734030723572
Validation loss: 2.080285588900248

Epoch: 6| Step: 11
Training loss: 0.16721054911613464
Validation loss: 2.0855823357899985

Epoch: 6| Step: 12
Training loss: 0.17809221148490906
Validation loss: 2.0428046186765036

Epoch: 6| Step: 13
Training loss: 0.21300463378429413
Validation loss: 2.0503491361935935

Epoch: 497| Step: 0
Training loss: 0.20562627911567688
Validation loss: 2.065812905629476

Epoch: 6| Step: 1
Training loss: 0.15301872789859772
Validation loss: 2.051703373591105

Epoch: 6| Step: 2
Training loss: 0.16432535648345947
Validation loss: 2.0632112423578897

Epoch: 6| Step: 3
Training loss: 0.17310692369937897
Validation loss: 2.051831523577372

Epoch: 6| Step: 4
Training loss: 0.23022255301475525
Validation loss: 2.1005945007006326

Epoch: 6| Step: 5
Training loss: 0.1600261628627777
Validation loss: 2.095688581466675

Epoch: 6| Step: 6
Training loss: 0.20591619610786438
Validation loss: 2.0621720353762307

Epoch: 6| Step: 7
Training loss: 0.17110784351825714
Validation loss: 2.076464295387268

Epoch: 6| Step: 8
Training loss: 0.1551167219877243
Validation loss: 2.1197375059127808

Epoch: 6| Step: 9
Training loss: 0.15499334037303925
Validation loss: 2.0658384362856546

Epoch: 6| Step: 10
Training loss: 0.44234687089920044
Validation loss: 2.08293749888738

Epoch: 6| Step: 11
Training loss: 0.5469509363174438
Validation loss: 2.073575258255005

Epoch: 6| Step: 12
Training loss: 0.2064671814441681
Validation loss: 2.108000953992208

Epoch: 6| Step: 13
Training loss: 0.19522234797477722
Validation loss: 2.1232398748397827

Epoch: 498| Step: 0
Training loss: 0.32555389404296875
Validation loss: 2.090247929096222

Epoch: 6| Step: 1
Training loss: 0.22996416687965393
Validation loss: 2.120507816473643

Epoch: 6| Step: 2
Training loss: 0.5781533718109131
Validation loss: 2.0388593673706055

Epoch: 6| Step: 3
Training loss: 0.19977900385856628
Validation loss: 2.0757946769396463

Epoch: 6| Step: 4
Training loss: 0.14240103960037231
Validation loss: 2.101945479710897

Epoch: 6| Step: 5
Training loss: 0.14153769612312317
Validation loss: 2.0751636028289795

Epoch: 6| Step: 6
Training loss: 0.14721156656742096
Validation loss: 2.0916189551353455

Epoch: 6| Step: 7
Training loss: 0.20825588703155518
Validation loss: 2.062499523162842

Epoch: 6| Step: 8
Training loss: 0.16370463371276855
Validation loss: 2.0547507405281067

Epoch: 6| Step: 9
Training loss: 0.18626482784748077
Validation loss: 2.0840993523597717

Epoch: 6| Step: 10
Training loss: 0.2518324851989746
Validation loss: 2.0979143579800925

Epoch: 6| Step: 11
Training loss: 0.14006435871124268
Validation loss: 2.079334855079651

Epoch: 6| Step: 12
Training loss: 0.40508216619491577
Validation loss: 2.1066420873006186

Epoch: 6| Step: 13
Training loss: 0.19721201062202454
Validation loss: 2.0987992684046426

Epoch: 499| Step: 0
Training loss: 0.24113152921199799
Validation loss: 2.07352614402771

Epoch: 6| Step: 1
Training loss: 0.23795713484287262
Validation loss: 2.0746047298113504

Epoch: 6| Step: 2
Training loss: 0.11619039624929428
Validation loss: 2.085460066795349

Epoch: 6| Step: 3
Training loss: 0.1395384669303894
Validation loss: 2.054641326268514

Epoch: 6| Step: 4
Training loss: 0.42934927344322205
Validation loss: 2.042236328125

Epoch: 6| Step: 5
Training loss: 0.17838600277900696
Validation loss: 2.0701916217803955

Epoch: 6| Step: 6
Training loss: 0.5769089460372925
Validation loss: 2.0729295015335083

Epoch: 6| Step: 7
Training loss: 0.14863067865371704
Validation loss: 2.1009509563446045

Epoch: 6| Step: 8
Training loss: 0.16881690919399261
Validation loss: 2.057604749997457

Epoch: 6| Step: 9
Training loss: 0.1898266226053238
Validation loss: 2.073155403137207

Epoch: 6| Step: 10
Training loss: 0.18017593026161194
Validation loss: 2.0458219051361084

Epoch: 6| Step: 11
Training loss: 0.2429715245962143
Validation loss: 2.085636854171753

Epoch: 6| Step: 12
Training loss: 0.12808869779109955
Validation loss: 2.092690865198771

Epoch: 6| Step: 13
Training loss: 0.20243722200393677
Validation loss: 2.0860758423805237

Epoch: 500| Step: 0
Training loss: 0.2641605734825134
Validation loss: 2.089876929918925

Epoch: 6| Step: 1
Training loss: 0.25524812936782837
Validation loss: 2.1037904222806296

Epoch: 6| Step: 2
Training loss: 0.2583908438682556
Validation loss: 2.108179966608683

Epoch: 6| Step: 3
Training loss: 0.49613168835639954
Validation loss: 2.1101156075795493

Epoch: 6| Step: 4
Training loss: 0.2228815108537674
Validation loss: 2.0996171633402505

Epoch: 6| Step: 5
Training loss: 0.16286028921604156
Validation loss: 2.089776853720347

Epoch: 6| Step: 6
Training loss: 0.1941060572862625
Validation loss: 2.0431690414746604

Epoch: 6| Step: 7
Training loss: 0.6023956537246704
Validation loss: 2.122225264708201

Epoch: 6| Step: 8
Training loss: 0.2730433940887451
Validation loss: 2.0785308678944907

Epoch: 6| Step: 9
Training loss: 0.3429343104362488
Validation loss: 2.0393386483192444

Epoch: 6| Step: 10
Training loss: 0.216426283121109
Validation loss: 2.0902704199155173

Epoch: 6| Step: 11
Training loss: 0.19025388360023499
Validation loss: 2.0485214392344155

Epoch: 6| Step: 12
Training loss: 0.11873787641525269
Validation loss: 2.1056881149609885

Epoch: 6| Step: 13
Training loss: 0.17734646797180176
Validation loss: 2.080090800921122

Epoch: 501| Step: 0
Training loss: 0.21549341082572937
Validation loss: 2.1385277112325034

Epoch: 6| Step: 1
Training loss: 0.20731160044670105
Validation loss: 2.097317894299825

Epoch: 6| Step: 2
Training loss: 0.27378952503204346
Validation loss: 2.125525116920471

Epoch: 6| Step: 3
Training loss: 0.20748615264892578
Validation loss: 2.092860003312429

Epoch: 6| Step: 4
Training loss: 0.1925949603319168
Validation loss: 2.0676538745562234

Epoch: 6| Step: 5
Training loss: 0.253595232963562
Validation loss: 2.081571022669474

Epoch: 6| Step: 6
Training loss: 0.6185829043388367
Validation loss: 2.089665730794271

Epoch: 6| Step: 7
Training loss: 0.22952856123447418
Validation loss: 2.046609898408254

Epoch: 6| Step: 8
Training loss: 0.20365586876869202
Validation loss: 2.041848878065745

Epoch: 6| Step: 9
Training loss: 0.15376950800418854
Validation loss: 2.097624440987905

Epoch: 6| Step: 10
Training loss: 0.32488125562667847
Validation loss: 2.07918643951416

Epoch: 6| Step: 11
Training loss: 0.2171149104833603
Validation loss: 2.0797741413116455

Epoch: 6| Step: 12
Training loss: 0.22854313254356384
Validation loss: 2.0546337167421975

Epoch: 6| Step: 13
Training loss: 0.23135386407375336
Validation loss: 2.068263669808706

Epoch: 502| Step: 0
Training loss: 0.46496233344078064
Validation loss: 2.075278639793396

Epoch: 6| Step: 1
Training loss: 0.2184167057275772
Validation loss: 2.07106876373291

Epoch: 6| Step: 2
Training loss: 0.5964333415031433
Validation loss: 2.0375723242759705

Epoch: 6| Step: 3
Training loss: 0.1825137883424759
Validation loss: 2.0405783454577127

Epoch: 6| Step: 4
Training loss: 0.17746266722679138
Validation loss: 2.0559517542521157

Epoch: 6| Step: 5
Training loss: 0.2163461297750473
Validation loss: 2.0852949221928916

Epoch: 6| Step: 6
Training loss: 0.1982227861881256
Validation loss: 2.100723067919413

Epoch: 6| Step: 7
Training loss: 0.23674212396144867
Validation loss: 2.1183084646860757

Epoch: 6| Step: 8
Training loss: 0.15042316913604736
Validation loss: 2.0933348139127097

Epoch: 6| Step: 9
Training loss: 0.14895273745059967
Validation loss: 2.0817630887031555

Epoch: 6| Step: 10
Training loss: 0.08793255686759949
Validation loss: 2.0692019859949746

Epoch: 6| Step: 11
Training loss: 0.16531914472579956
Validation loss: 2.0741593639055886

Epoch: 6| Step: 12
Training loss: 0.17131280899047852
Validation loss: 2.077403962612152

Epoch: 6| Step: 13
Training loss: 0.2628205418586731
Validation loss: 2.0713882644971213

Epoch: 503| Step: 0
Training loss: 0.25103849172592163
Validation loss: 2.075813670953115

Epoch: 6| Step: 1
Training loss: 0.17400096356868744
Validation loss: 2.0722191532452903

Epoch: 6| Step: 2
Training loss: 0.19566333293914795
Validation loss: 2.050829291343689

Epoch: 6| Step: 3
Training loss: 0.2598281800746918
Validation loss: 2.073921859264374

Epoch: 6| Step: 4
Training loss: 0.12753969430923462
Validation loss: 2.0490472316741943

Epoch: 6| Step: 5
Training loss: 0.19481141865253448
Validation loss: 2.0819960236549377

Epoch: 6| Step: 6
Training loss: 0.2728370130062103
Validation loss: 2.096930205821991

Epoch: 6| Step: 7
Training loss: 0.26290059089660645
Validation loss: 2.075055460135142

Epoch: 6| Step: 8
Training loss: 0.18731586635112762
Validation loss: 2.0422571500142417

Epoch: 6| Step: 9
Training loss: 0.5773330330848694
Validation loss: 2.0470906496047974

Epoch: 6| Step: 10
Training loss: 0.31694409251213074
Validation loss: 2.039141575495402

Epoch: 6| Step: 11
Training loss: 0.2594776153564453
Validation loss: 2.03629994392395

Epoch: 6| Step: 12
Training loss: 0.21224500238895416
Validation loss: 2.0799721280733743

Epoch: 6| Step: 13
Training loss: 0.1597594916820526
Validation loss: 2.0678630471229553

Epoch: 504| Step: 0
Training loss: 0.18096035718917847
Validation loss: 2.055130958557129

Epoch: 6| Step: 1
Training loss: 0.16559940576553345
Validation loss: 2.1176645954449973

Epoch: 6| Step: 2
Training loss: 0.21211186051368713
Validation loss: 2.0507699251174927

Epoch: 6| Step: 3
Training loss: 0.10729531943798065
Validation loss: 2.0651684204737344

Epoch: 6| Step: 4
Training loss: 0.2162473499774933
Validation loss: 2.0725660920143127

Epoch: 6| Step: 5
Training loss: 0.18846693634986877
Validation loss: 2.061899264653524

Epoch: 6| Step: 6
Training loss: 0.253147155046463
Validation loss: 2.0671796003977456

Epoch: 6| Step: 7
Training loss: 0.2099866271018982
Validation loss: 2.065325061480204

Epoch: 6| Step: 8
Training loss: 0.16981060802936554
Validation loss: 2.029538611570994

Epoch: 6| Step: 9
Training loss: 0.32328784465789795
Validation loss: 2.040144701798757

Epoch: 6| Step: 10
Training loss: 0.18415524065494537
Validation loss: 2.104801654815674

Epoch: 6| Step: 11
Training loss: 0.22329409420490265
Validation loss: 2.0921706159909568

Epoch: 6| Step: 12
Training loss: 0.5259652733802795
Validation loss: 2.096129318078359

Epoch: 6| Step: 13
Training loss: 0.16769468784332275
Validation loss: 2.0409030516942344

Epoch: 505| Step: 0
Training loss: 0.14468064904212952
Validation loss: 2.051660716533661

Epoch: 6| Step: 1
Training loss: 0.23082603514194489
Validation loss: 2.0421305100123086

Epoch: 6| Step: 2
Training loss: 0.42796364426612854
Validation loss: 2.0475733280181885

Epoch: 6| Step: 3
Training loss: 0.1723264455795288
Validation loss: 2.040893077850342

Epoch: 6| Step: 4
Training loss: 0.1931028664112091
Validation loss: 2.0718570947647095

Epoch: 6| Step: 5
Training loss: 0.22819370031356812
Validation loss: 2.061139404773712

Epoch: 6| Step: 6
Training loss: 0.26402702927589417
Validation loss: 2.0886847774187722

Epoch: 6| Step: 7
Training loss: 0.22169536352157593
Validation loss: 2.0528018871943154

Epoch: 6| Step: 8
Training loss: 0.49600404500961304
Validation loss: 2.084626317024231

Epoch: 6| Step: 9
Training loss: 0.2065163552761078
Validation loss: 2.0760095715522766

Epoch: 6| Step: 10
Training loss: 0.25182244181632996
Validation loss: 2.083638608455658

Epoch: 6| Step: 11
Training loss: 0.18751269578933716
Validation loss: 2.03365296125412

Epoch: 6| Step: 12
Training loss: 0.28062888979911804
Validation loss: 2.040015439192454

Epoch: 6| Step: 13
Training loss: 0.23467303812503815
Validation loss: 2.039997100830078

Epoch: 506| Step: 0
Training loss: 0.16487763822078705
Validation loss: 2.067692736784617

Epoch: 6| Step: 1
Training loss: 0.20081451535224915
Validation loss: 2.0579911271731057

Epoch: 6| Step: 2
Training loss: 0.22812789678573608
Validation loss: 2.0571457942326865

Epoch: 6| Step: 3
Training loss: 0.4730994701385498
Validation loss: 2.0795690218607583

Epoch: 6| Step: 4
Training loss: 0.17763856053352356
Validation loss: 2.0691778858502707

Epoch: 6| Step: 5
Training loss: 0.19803109765052795
Validation loss: 2.066735585530599

Epoch: 6| Step: 6
Training loss: 0.3621740937232971
Validation loss: 2.0717200438181558

Epoch: 6| Step: 7
Training loss: 0.13301712274551392
Validation loss: 2.0877480506896973

Epoch: 6| Step: 8
Training loss: 0.1921800673007965
Validation loss: 2.0679235458374023

Epoch: 6| Step: 9
Training loss: 0.1659880429506302
Validation loss: 2.049079159895579

Epoch: 6| Step: 10
Training loss: 0.22922295331954956
Validation loss: 2.064875582853953

Epoch: 6| Step: 11
Training loss: 0.21716667711734772
Validation loss: 2.0591898759206138

Epoch: 6| Step: 12
Training loss: 0.21380510926246643
Validation loss: 2.061521132787069

Epoch: 6| Step: 13
Training loss: 0.19815653562545776
Validation loss: 2.0511311292648315

Epoch: 507| Step: 0
Training loss: 0.3574179410934448
Validation loss: 2.0837589104970298

Epoch: 6| Step: 1
Training loss: 0.18000318109989166
Validation loss: 2.0558252731959024

Epoch: 6| Step: 2
Training loss: 0.17933890223503113
Validation loss: 2.060730973879496

Epoch: 6| Step: 3
Training loss: 0.2811519205570221
Validation loss: 2.089570681254069

Epoch: 6| Step: 4
Training loss: 0.49535316228866577
Validation loss: 2.0721011956532798

Epoch: 6| Step: 5
Training loss: 0.1899295300245285
Validation loss: 2.0285483400026956

Epoch: 6| Step: 6
Training loss: 0.14310365915298462
Validation loss: 2.0302407145500183

Epoch: 6| Step: 7
Training loss: 0.2436424195766449
Validation loss: 2.0778809785842896

Epoch: 6| Step: 8
Training loss: 0.29391658306121826
Validation loss: 2.029842992623647

Epoch: 6| Step: 9
Training loss: 0.21291621029376984
Validation loss: 2.0249292055765786

Epoch: 6| Step: 10
Training loss: 0.24660691618919373
Validation loss: 2.0312058329582214

Epoch: 6| Step: 11
Training loss: 0.1829598844051361
Validation loss: 2.0470238526662192

Epoch: 6| Step: 12
Training loss: 0.20832665264606476
Validation loss: 2.046618481477102

Epoch: 6| Step: 13
Training loss: 0.14288780093193054
Validation loss: 2.0518619219462075

Epoch: 508| Step: 0
Training loss: 0.27809929847717285
Validation loss: 2.03403373559316

Epoch: 6| Step: 1
Training loss: 0.21688182651996613
Validation loss: 2.0473023454348245

Epoch: 6| Step: 2
Training loss: 0.19189924001693726
Validation loss: 2.0360920429229736

Epoch: 6| Step: 3
Training loss: 0.1867864727973938
Validation loss: 2.016289552052816

Epoch: 6| Step: 4
Training loss: 0.2170184850692749
Validation loss: 2.0643257101376853

Epoch: 6| Step: 5
Training loss: 0.2211950123310089
Validation loss: 2.0836434165636697

Epoch: 6| Step: 6
Training loss: 0.20813244581222534
Validation loss: 2.0839179356892905

Epoch: 6| Step: 7
Training loss: 0.2766767144203186
Validation loss: 2.0967120925585427

Epoch: 6| Step: 8
Training loss: 0.5163295865058899
Validation loss: 2.076717495918274

Epoch: 6| Step: 9
Training loss: 0.24088609218597412
Validation loss: 2.084981123606364

Epoch: 6| Step: 10
Training loss: 0.6024000644683838
Validation loss: 2.07121479511261

Epoch: 6| Step: 11
Training loss: 0.17721430957317352
Validation loss: 2.057760536670685

Epoch: 6| Step: 12
Training loss: 0.20724639296531677
Validation loss: 2.079346259435018

Epoch: 6| Step: 13
Training loss: 0.2487313449382782
Validation loss: 2.05111300945282

Epoch: 509| Step: 0
Training loss: 0.1997903436422348
Validation loss: 2.048735499382019

Epoch: 6| Step: 1
Training loss: 0.18119746446609497
Validation loss: 2.0753307541211448

Epoch: 6| Step: 2
Training loss: 0.2195369452238083
Validation loss: 2.057920277118683

Epoch: 6| Step: 3
Training loss: 0.18611598014831543
Validation loss: 2.1144138177235923

Epoch: 6| Step: 4
Training loss: 0.2223127782344818
Validation loss: 2.0793702602386475

Epoch: 6| Step: 5
Training loss: 0.14215518534183502
Validation loss: 2.06125017007192

Epoch: 6| Step: 6
Training loss: 0.09645390510559082
Validation loss: 2.0628886620203652

Epoch: 6| Step: 7
Training loss: 0.14549538493156433
Validation loss: 2.023609220981598

Epoch: 6| Step: 8
Training loss: 0.10462076216936111
Validation loss: 2.0601735512415567

Epoch: 6| Step: 9
Training loss: 0.3138744831085205
Validation loss: 2.044707794984182

Epoch: 6| Step: 10
Training loss: 0.3484228849411011
Validation loss: 2.0372326572736106

Epoch: 6| Step: 11
Training loss: 0.2951843738555908
Validation loss: 2.066235105196635

Epoch: 6| Step: 12
Training loss: 0.6177145838737488
Validation loss: 2.04378871122996

Epoch: 6| Step: 13
Training loss: 0.20640695095062256
Validation loss: 2.0645304918289185

Epoch: 510| Step: 0
Training loss: 0.1191774308681488
Validation loss: 2.0926450888315835

Epoch: 6| Step: 1
Training loss: 0.23099717497825623
Validation loss: 2.080433666706085

Epoch: 6| Step: 2
Training loss: 0.21054592728614807
Validation loss: 2.025085727373759

Epoch: 6| Step: 3
Training loss: 0.15783144533634186
Validation loss: 2.0678995847702026

Epoch: 6| Step: 4
Training loss: 0.29894083738327026
Validation loss: 2.0400089820226035

Epoch: 6| Step: 5
Training loss: 0.18696092069149017
Validation loss: 2.0711897015571594

Epoch: 6| Step: 6
Training loss: 0.16164357960224152
Validation loss: 2.06035315990448

Epoch: 6| Step: 7
Training loss: 0.10496876388788223
Validation loss: 2.0524113972981772

Epoch: 6| Step: 8
Training loss: 0.37103188037872314
Validation loss: 2.0505636731783548

Epoch: 6| Step: 9
Training loss: 0.1377210021018982
Validation loss: 2.080518901348114

Epoch: 6| Step: 10
Training loss: 0.2310592532157898
Validation loss: 2.1177682876586914

Epoch: 6| Step: 11
Training loss: 0.19005432724952698
Validation loss: 2.086585978666941

Epoch: 6| Step: 12
Training loss: 0.18773521482944489
Validation loss: 2.0309637784957886

Epoch: 6| Step: 13
Training loss: 0.5410827994346619
Validation loss: 2.0568535526593528

Epoch: 511| Step: 0
Training loss: 0.18034926056861877
Validation loss: 2.0854910810788474

Epoch: 6| Step: 1
Training loss: 0.5410439372062683
Validation loss: 2.1039861043294272

Epoch: 6| Step: 2
Training loss: 0.38462328910827637
Validation loss: 2.0714945197105408

Epoch: 6| Step: 3
Training loss: 0.21509967744350433
Validation loss: 2.058629810810089

Epoch: 6| Step: 4
Training loss: 0.17516204714775085
Validation loss: 2.078794280687968

Epoch: 6| Step: 5
Training loss: 0.1536966860294342
Validation loss: 2.0795395572980246

Epoch: 6| Step: 6
Training loss: 0.14596642553806305
Validation loss: 2.0686481396357217

Epoch: 6| Step: 7
Training loss: 0.1930713951587677
Validation loss: 2.089652140935262

Epoch: 6| Step: 8
Training loss: 0.10706600546836853
Validation loss: 2.090652366479238

Epoch: 6| Step: 9
Training loss: 0.10186856985092163
Validation loss: 2.110934793949127

Epoch: 6| Step: 10
Training loss: 0.1317923218011856
Validation loss: 2.109541575113932

Epoch: 6| Step: 11
Training loss: 0.230123832821846
Validation loss: 2.0300603906313577

Epoch: 6| Step: 12
Training loss: 0.2771341800689697
Validation loss: 2.065935254096985

Epoch: 6| Step: 13
Training loss: 0.1544320285320282
Validation loss: 2.0774709383646646

Epoch: 512| Step: 0
Training loss: 0.3106671869754791
Validation loss: 2.0615281661351523

Epoch: 6| Step: 1
Training loss: 0.1805563122034073
Validation loss: 2.0508230527242026

Epoch: 6| Step: 2
Training loss: 0.16499078273773193
Validation loss: 2.043894430001577

Epoch: 6| Step: 3
Training loss: 0.13737903535366058
Validation loss: 2.0653867522875466

Epoch: 6| Step: 4
Training loss: 0.14167122542858124
Validation loss: 2.09468674659729

Epoch: 6| Step: 5
Training loss: 0.15684762597084045
Validation loss: 2.0775134563446045

Epoch: 6| Step: 6
Training loss: 0.5571430921554565
Validation loss: 2.0507272680600486

Epoch: 6| Step: 7
Training loss: 0.15095248818397522
Validation loss: 2.1053128639856973

Epoch: 6| Step: 8
Training loss: 0.12929345667362213
Validation loss: 2.0534919102986655

Epoch: 6| Step: 9
Training loss: 0.13227598369121552
Validation loss: 2.0955915252367654

Epoch: 6| Step: 10
Training loss: 0.20548924803733826
Validation loss: 2.082598110040029

Epoch: 6| Step: 11
Training loss: 0.16668017208576202
Validation loss: 2.0583185950915017

Epoch: 6| Step: 12
Training loss: 0.1504622995853424
Validation loss: 2.079963525136312

Epoch: 6| Step: 13
Training loss: 0.15471290051937103
Validation loss: 2.089607576529185

Epoch: 513| Step: 0
Training loss: 0.14941507577896118
Validation loss: 2.086447556813558

Epoch: 6| Step: 1
Training loss: 0.3828211724758148
Validation loss: 2.063109278678894

Epoch: 6| Step: 2
Training loss: 0.1552686095237732
Validation loss: 2.0928181608517966

Epoch: 6| Step: 3
Training loss: 0.22723126411437988
Validation loss: 2.0614140232404075

Epoch: 6| Step: 4
Training loss: 0.5792530179023743
Validation loss: 2.065279205640157

Epoch: 6| Step: 5
Training loss: 0.20124799013137817
Validation loss: 2.074126660823822

Epoch: 6| Step: 6
Training loss: 0.1502607762813568
Validation loss: 2.078091104825338

Epoch: 6| Step: 7
Training loss: 0.19116511940956116
Validation loss: 2.1099066138267517

Epoch: 6| Step: 8
Training loss: 0.2242240160703659
Validation loss: 2.0697816610336304

Epoch: 6| Step: 9
Training loss: 0.12737058103084564
Validation loss: 2.055032034715017

Epoch: 6| Step: 10
Training loss: 0.16969004273414612
Validation loss: 2.05224472284317

Epoch: 6| Step: 11
Training loss: 0.17531998455524445
Validation loss: 2.056197722752889

Epoch: 6| Step: 12
Training loss: 0.177829772233963
Validation loss: 2.088123142719269

Epoch: 6| Step: 13
Training loss: 0.16485485434532166
Validation loss: 2.0547304352124534

Epoch: 514| Step: 0
Training loss: 0.17290908098220825
Validation loss: 2.0839672485987344

Epoch: 6| Step: 1
Training loss: 0.19805596768856049
Validation loss: 2.049837271372477

Epoch: 6| Step: 2
Training loss: 0.18678027391433716
Validation loss: 2.0687852700551352

Epoch: 6| Step: 3
Training loss: 0.14183275401592255
Validation loss: 2.0340426166852317

Epoch: 6| Step: 4
Training loss: 0.20681598782539368
Validation loss: 2.0722725788752236

Epoch: 6| Step: 5
Training loss: 0.21229906380176544
Validation loss: 2.0149425069491067

Epoch: 6| Step: 6
Training loss: 0.1868683397769928
Validation loss: 2.0910224119822183

Epoch: 6| Step: 7
Training loss: 0.20298336446285248
Validation loss: 2.0643065174420676

Epoch: 6| Step: 8
Training loss: 0.23074239492416382
Validation loss: 2.047830104827881

Epoch: 6| Step: 9
Training loss: 0.31314241886138916
Validation loss: 2.0718427300453186

Epoch: 6| Step: 10
Training loss: 0.5765060782432556
Validation loss: 2.0520318945248923

Epoch: 6| Step: 11
Training loss: 0.16270878911018372
Validation loss: 2.0413999358812966

Epoch: 6| Step: 12
Training loss: 0.20873397588729858
Validation loss: 2.016221741835276

Epoch: 6| Step: 13
Training loss: 0.19968611001968384
Validation loss: 2.0869725942611694

Epoch: 515| Step: 0
Training loss: 0.17221227288246155
Validation loss: 2.05277285973231

Epoch: 6| Step: 1
Training loss: 0.5353608131408691
Validation loss: 2.0596783558527627

Epoch: 6| Step: 2
Training loss: 0.13487327098846436
Validation loss: 2.062422255674998

Epoch: 6| Step: 3
Training loss: 0.1780891716480255
Validation loss: 2.0570322275161743

Epoch: 6| Step: 4
Training loss: 0.4159039258956909
Validation loss: 2.081338028113047

Epoch: 6| Step: 5
Training loss: 0.3059788644313812
Validation loss: 2.0902082125345864

Epoch: 6| Step: 6
Training loss: 0.21318021416664124
Validation loss: 2.071601688861847

Epoch: 6| Step: 7
Training loss: 0.16398561000823975
Validation loss: 2.0566044449806213

Epoch: 6| Step: 8
Training loss: 0.19413253664970398
Validation loss: 2.0470520655314126

Epoch: 6| Step: 9
Training loss: 0.2817056179046631
Validation loss: 2.0490073760350547

Epoch: 6| Step: 10
Training loss: 0.2920055687427521
Validation loss: 2.0487189888954163

Epoch: 6| Step: 11
Training loss: 0.1538582295179367
Validation loss: 2.050596217314402

Epoch: 6| Step: 12
Training loss: 0.21649818122386932
Validation loss: 2.071784019470215

Epoch: 6| Step: 13
Training loss: 0.16007182002067566
Validation loss: 2.0906617840131125

Epoch: 516| Step: 0
Training loss: 0.20417124032974243
Validation loss: 2.0801570812861123

Epoch: 6| Step: 1
Training loss: 0.2281070500612259
Validation loss: 2.0804994304974875

Epoch: 6| Step: 2
Training loss: 0.33420413732528687
Validation loss: 2.1125335892041526

Epoch: 6| Step: 3
Training loss: 0.2795336842536926
Validation loss: 2.1066217025121055

Epoch: 6| Step: 4
Training loss: 0.2668575644493103
Validation loss: 2.0807438294092813

Epoch: 6| Step: 5
Training loss: 0.5715945363044739
Validation loss: 2.0321977734565735

Epoch: 6| Step: 6
Training loss: 0.23972398042678833
Validation loss: 2.0721855560938516

Epoch: 6| Step: 7
Training loss: 0.31869757175445557
Validation loss: 2.083860218524933

Epoch: 6| Step: 8
Training loss: 0.4405834376811981
Validation loss: 2.0664613246917725

Epoch: 6| Step: 9
Training loss: 0.2965865731239319
Validation loss: 2.0744786461194358

Epoch: 6| Step: 10
Training loss: 0.41371357440948486
Validation loss: 2.074911634127299

Epoch: 6| Step: 11
Training loss: 0.1697077602148056
Validation loss: 2.0675328969955444

Epoch: 6| Step: 12
Training loss: 0.17805872857570648
Validation loss: 2.0794644951820374

Epoch: 6| Step: 13
Training loss: 0.3506125807762146
Validation loss: 2.1230883598327637

Epoch: 517| Step: 0
Training loss: 0.26956671476364136
Validation loss: 2.1714527010917664

Epoch: 6| Step: 1
Training loss: 0.3138033151626587
Validation loss: 2.1020089983940125

Epoch: 6| Step: 2
Training loss: 0.30794137716293335
Validation loss: 2.122030238310496

Epoch: 6| Step: 3
Training loss: 0.6336571574211121
Validation loss: 2.0820747216542563

Epoch: 6| Step: 4
Training loss: 0.24322345852851868
Validation loss: 2.0790459911028543

Epoch: 6| Step: 5
Training loss: 0.25021979212760925
Validation loss: 2.0491504073143005

Epoch: 6| Step: 6
Training loss: 0.24040775001049042
Validation loss: 2.082271238168081

Epoch: 6| Step: 7
Training loss: 0.26050591468811035
Validation loss: 2.040636658668518

Epoch: 6| Step: 8
Training loss: 0.18409773707389832
Validation loss: 2.0583706299463906

Epoch: 6| Step: 9
Training loss: 0.17876791954040527
Validation loss: 2.0463815728823342

Epoch: 6| Step: 10
Training loss: 0.378229022026062
Validation loss: 2.0516682863235474

Epoch: 6| Step: 11
Training loss: 0.27430951595306396
Validation loss: 2.087139844894409

Epoch: 6| Step: 12
Training loss: 0.18308258056640625
Validation loss: 2.0396477580070496

Epoch: 6| Step: 13
Training loss: 0.23457594215869904
Validation loss: 2.0653608441352844

Epoch: 518| Step: 0
Training loss: 0.18109425902366638
Validation loss: 2.014144321282705

Epoch: 6| Step: 1
Training loss: 0.20370885729789734
Validation loss: 2.0432728131612143

Epoch: 6| Step: 2
Training loss: 0.224746972322464
Validation loss: 2.0778398315111795

Epoch: 6| Step: 3
Training loss: 0.17309334874153137
Validation loss: 2.0533092816670737

Epoch: 6| Step: 4
Training loss: 0.15907293558120728
Validation loss: 2.087053577105204

Epoch: 6| Step: 5
Training loss: 0.125839501619339
Validation loss: 2.042475422223409

Epoch: 6| Step: 6
Training loss: 0.19446298480033875
Validation loss: 2.0646987160046897

Epoch: 6| Step: 7
Training loss: 0.3667312264442444
Validation loss: 2.0756999055544534

Epoch: 6| Step: 8
Training loss: 0.1717902421951294
Validation loss: 2.0826719204584756

Epoch: 6| Step: 9
Training loss: 0.2404274195432663
Validation loss: 2.075676699479421

Epoch: 6| Step: 10
Training loss: 0.19660910964012146
Validation loss: 2.095832586288452

Epoch: 6| Step: 11
Training loss: 0.5890190601348877
Validation loss: 2.1132622559865317

Epoch: 6| Step: 12
Training loss: 0.12326998263597488
Validation loss: 2.0964096784591675

Epoch: 6| Step: 13
Training loss: 0.22524940967559814
Validation loss: 2.0565305352211

Epoch: 519| Step: 0
Training loss: 0.23430365324020386
Validation loss: 2.05639918645223

Epoch: 6| Step: 1
Training loss: 0.27986982464790344
Validation loss: 2.0817468563715615

Epoch: 6| Step: 2
Training loss: 0.12454184144735336
Validation loss: 2.036829352378845

Epoch: 6| Step: 3
Training loss: 0.15648508071899414
Validation loss: 2.039792279402415

Epoch: 6| Step: 4
Training loss: 0.19032089412212372
Validation loss: 2.070179839928945

Epoch: 6| Step: 5
Training loss: 0.15966519713401794
Validation loss: 2.0822916825612388

Epoch: 6| Step: 6
Training loss: 0.16559453308582306
Validation loss: 2.066612203915914

Epoch: 6| Step: 7
Training loss: 0.2524817883968353
Validation loss: 2.0751763184865317

Epoch: 6| Step: 8
Training loss: 0.3150026202201843
Validation loss: 2.072045385837555

Epoch: 6| Step: 9
Training loss: 0.2561042308807373
Validation loss: 2.0601889292399087

Epoch: 6| Step: 10
Training loss: 0.1630328744649887
Validation loss: 2.0642220775286355

Epoch: 6| Step: 11
Training loss: 0.1710611879825592
Validation loss: 2.0964582761128745

Epoch: 6| Step: 12
Training loss: 0.15943226218223572
Validation loss: 2.064914345741272

Epoch: 6| Step: 13
Training loss: 0.6087449789047241
Validation loss: 2.085146188735962

Epoch: 520| Step: 0
Training loss: 0.1770240217447281
Validation loss: 2.1118991573651633

Epoch: 6| Step: 1
Training loss: 0.1453806459903717
Validation loss: 2.0688513914744058

Epoch: 6| Step: 2
Training loss: 0.26845309138298035
Validation loss: 2.0720908641815186

Epoch: 6| Step: 3
Training loss: 0.29392701387405396
Validation loss: 2.0970014929771423

Epoch: 6| Step: 4
Training loss: 0.1719919592142105
Validation loss: 2.0476433634757996

Epoch: 6| Step: 5
Training loss: 0.2391439974308014
Validation loss: 2.1283957163492837

Epoch: 6| Step: 6
Training loss: 0.25874173641204834
Validation loss: 2.1290425260861716

Epoch: 6| Step: 7
Training loss: 0.2590779662132263
Validation loss: 2.0598361094792685

Epoch: 6| Step: 8
Training loss: 0.18938113749027252
Validation loss: 2.116274336973826

Epoch: 6| Step: 9
Training loss: 0.14224115014076233
Validation loss: 2.0879932045936584

Epoch: 6| Step: 10
Training loss: 0.147556334733963
Validation loss: 2.062666038672129

Epoch: 6| Step: 11
Training loss: 0.6681954264640808
Validation loss: 2.0898573795954385

Epoch: 6| Step: 12
Training loss: 0.1705108880996704
Validation loss: 2.0787549217542014

Epoch: 6| Step: 13
Training loss: 0.18998011946678162
Validation loss: 2.0827417373657227

Epoch: 521| Step: 0
Training loss: 0.13535836338996887
Validation loss: 2.0649652083714805

Epoch: 6| Step: 1
Training loss: 0.2028154730796814
Validation loss: 2.1050939162572226

Epoch: 6| Step: 2
Training loss: 0.16513273119926453
Validation loss: 2.0997749169667563

Epoch: 6| Step: 3
Training loss: 0.19835716485977173
Validation loss: 2.060189882914225

Epoch: 6| Step: 4
Training loss: 0.21395979821681976
Validation loss: 2.0455111861228943

Epoch: 6| Step: 5
Training loss: 0.1870398223400116
Validation loss: 2.0702738761901855

Epoch: 6| Step: 6
Training loss: 0.13159015774726868
Validation loss: 2.060411512851715

Epoch: 6| Step: 7
Training loss: 0.23866048455238342
Validation loss: 2.0938002665837607

Epoch: 6| Step: 8
Training loss: 0.1752721667289734
Validation loss: 2.047348121802012

Epoch: 6| Step: 9
Training loss: 0.19749286770820618
Validation loss: 2.0551350514094033

Epoch: 6| Step: 10
Training loss: 0.5369660258293152
Validation loss: 2.0670443971951804

Epoch: 6| Step: 11
Training loss: 0.1597779542207718
Validation loss: 2.057458976904551

Epoch: 6| Step: 12
Training loss: 0.33913832902908325
Validation loss: 2.0555940866470337

Epoch: 6| Step: 13
Training loss: 0.16884130239486694
Validation loss: 2.079843362172445

Epoch: 522| Step: 0
Training loss: 0.23718789219856262
Validation loss: 2.065556267897288

Epoch: 6| Step: 1
Training loss: 0.21979032456874847
Validation loss: 2.0832201639811196

Epoch: 6| Step: 2
Training loss: 0.23521006107330322
Validation loss: 2.090465267499288

Epoch: 6| Step: 3
Training loss: 0.48572441935539246
Validation loss: 2.0298402905464172

Epoch: 6| Step: 4
Training loss: 0.22116075456142426
Validation loss: 2.0221606890360513

Epoch: 6| Step: 5
Training loss: 0.261919230222702
Validation loss: 2.059377908706665

Epoch: 6| Step: 6
Training loss: 0.2553430199623108
Validation loss: 2.046971539656321

Epoch: 6| Step: 7
Training loss: 0.12473402917385101
Validation loss: 2.0522082249323526

Epoch: 6| Step: 8
Training loss: 0.13554154336452484
Validation loss: 2.024075508117676

Epoch: 6| Step: 9
Training loss: 0.19716015458106995
Validation loss: 2.087219774723053

Epoch: 6| Step: 10
Training loss: 0.18419304490089417
Validation loss: 2.067719499270121

Epoch: 6| Step: 11
Training loss: 0.17779478430747986
Validation loss: 2.1074465910593667

Epoch: 6| Step: 12
Training loss: 0.35873496532440186
Validation loss: 2.078059116999308

Epoch: 6| Step: 13
Training loss: 0.17540425062179565
Validation loss: 2.1085267464319863

Epoch: 523| Step: 0
Training loss: 0.20213648676872253
Validation loss: 2.0811146895090737

Epoch: 6| Step: 1
Training loss: 0.35977715253829956
Validation loss: 2.0625754396120706

Epoch: 6| Step: 2
Training loss: 0.4883859157562256
Validation loss: 2.0835677782694497

Epoch: 6| Step: 3
Training loss: 0.168015718460083
Validation loss: 2.0452250242233276

Epoch: 6| Step: 4
Training loss: 0.20897968113422394
Validation loss: 2.027473966280619

Epoch: 6| Step: 5
Training loss: 0.2021561563014984
Validation loss: 2.062436103820801

Epoch: 6| Step: 6
Training loss: 0.1648353934288025
Validation loss: 2.071110943953196

Epoch: 6| Step: 7
Training loss: 0.22135840356349945
Validation loss: 2.0870281060536704

Epoch: 6| Step: 8
Training loss: 0.18989090621471405
Validation loss: 2.0517733494440713

Epoch: 6| Step: 9
Training loss: 0.23352012038230896
Validation loss: 2.0241217613220215

Epoch: 6| Step: 10
Training loss: 0.1554797887802124
Validation loss: 2.071081360181173

Epoch: 6| Step: 11
Training loss: 0.18025553226470947
Validation loss: 2.047750413417816

Epoch: 6| Step: 12
Training loss: 0.27806907892227173
Validation loss: 2.0539453824361167

Epoch: 6| Step: 13
Training loss: 0.14848804473876953
Validation loss: 2.0549879471460977

Epoch: 524| Step: 0
Training loss: 0.19724181294441223
Validation loss: 2.0685569842656455

Epoch: 6| Step: 1
Training loss: 0.14355045557022095
Validation loss: 2.0260958671569824

Epoch: 6| Step: 2
Training loss: 0.21001212298870087
Validation loss: 2.0350165168444314

Epoch: 6| Step: 3
Training loss: 0.15840157866477966
Validation loss: 2.018734554449717

Epoch: 6| Step: 4
Training loss: 0.17879699170589447
Validation loss: 2.07463002204895

Epoch: 6| Step: 5
Training loss: 0.21206548810005188
Validation loss: 2.0512569745381675

Epoch: 6| Step: 6
Training loss: 0.15844236314296722
Validation loss: 2.057538866996765

Epoch: 6| Step: 7
Training loss: 0.15114891529083252
Validation loss: 2.064623455206553

Epoch: 6| Step: 8
Training loss: 0.22516849637031555
Validation loss: 2.0570437709490457

Epoch: 6| Step: 9
Training loss: 0.30639538168907166
Validation loss: 2.0740432739257812

Epoch: 6| Step: 10
Training loss: 0.2185257077217102
Validation loss: 2.047402083873749

Epoch: 6| Step: 11
Training loss: 0.5420796275138855
Validation loss: 2.038275162378947

Epoch: 6| Step: 12
Training loss: 0.1320195198059082
Validation loss: 2.0500122706095376

Epoch: 6| Step: 13
Training loss: 0.1831551343202591
Validation loss: 2.07606973250707

Epoch: 525| Step: 0
Training loss: 0.17092245817184448
Validation loss: 2.060732066631317

Epoch: 6| Step: 1
Training loss: 0.14596475660800934
Validation loss: 2.039615968863169

Epoch: 6| Step: 2
Training loss: 0.28889000415802
Validation loss: 2.047196924686432

Epoch: 6| Step: 3
Training loss: 0.5428183078765869
Validation loss: 2.0579673846562705

Epoch: 6| Step: 4
Training loss: 0.18519312143325806
Validation loss: 2.103178064028422

Epoch: 6| Step: 5
Training loss: 0.27869200706481934
Validation loss: 2.0738418102264404

Epoch: 6| Step: 6
Training loss: 0.17641375958919525
Validation loss: 2.0941068728764853

Epoch: 6| Step: 7
Training loss: 0.2221890091896057
Validation loss: 2.0787660678227744

Epoch: 6| Step: 8
Training loss: 0.2581073045730591
Validation loss: 2.066685895125071

Epoch: 6| Step: 9
Training loss: 0.15891015529632568
Validation loss: 2.054210146268209

Epoch: 6| Step: 10
Training loss: 0.17668388783931732
Validation loss: 2.024923324584961

Epoch: 6| Step: 11
Training loss: 0.26927074790000916
Validation loss: 2.0704676111539206

Epoch: 6| Step: 12
Training loss: 0.18034470081329346
Validation loss: 2.044505755106608

Epoch: 6| Step: 13
Training loss: 0.15044590830802917
Validation loss: 2.0299372474352517

Epoch: 526| Step: 0
Training loss: 0.20369504392147064
Validation loss: 2.0425602197647095

Epoch: 6| Step: 1
Training loss: 0.1362902820110321
Validation loss: 2.065470516681671

Epoch: 6| Step: 2
Training loss: 0.20020294189453125
Validation loss: 2.0407134691874185

Epoch: 6| Step: 3
Training loss: 0.19132961332798004
Validation loss: 2.080493072668711

Epoch: 6| Step: 4
Training loss: 0.40150684118270874
Validation loss: 2.079869270324707

Epoch: 6| Step: 5
Training loss: 0.27137094736099243
Validation loss: 2.098307967185974

Epoch: 6| Step: 6
Training loss: 0.3513021767139435
Validation loss: 2.0858588417371116

Epoch: 6| Step: 7
Training loss: 0.48709726333618164
Validation loss: 2.0414442817370095

Epoch: 6| Step: 8
Training loss: 0.190424382686615
Validation loss: 2.092165013154348

Epoch: 6| Step: 9
Training loss: 0.19195538759231567
Validation loss: 2.0433240135510764

Epoch: 6| Step: 10
Training loss: 0.2279004156589508
Validation loss: 2.0447598497072854

Epoch: 6| Step: 11
Training loss: 0.27079588174819946
Validation loss: 2.0186644991238913

Epoch: 6| Step: 12
Training loss: 0.18749363720417023
Validation loss: 2.076964557170868

Epoch: 6| Step: 13
Training loss: 0.18594564497470856
Validation loss: 2.0566842754681907

Epoch: 527| Step: 0
Training loss: 0.15330788493156433
Validation loss: 2.0982120633125305

Epoch: 6| Step: 1
Training loss: 0.24799662828445435
Validation loss: 2.10194065173467

Epoch: 6| Step: 2
Training loss: 0.18349507451057434
Validation loss: 2.095990320046743

Epoch: 6| Step: 3
Training loss: 0.3691633641719818
Validation loss: 2.107221086819967

Epoch: 6| Step: 4
Training loss: 0.19705888628959656
Validation loss: 2.053392012914022

Epoch: 6| Step: 5
Training loss: 0.13738849759101868
Validation loss: 2.0634387731552124

Epoch: 6| Step: 6
Training loss: 0.16609182953834534
Validation loss: 2.016481598218282

Epoch: 6| Step: 7
Training loss: 0.2350292205810547
Validation loss: 2.0551554958025613

Epoch: 6| Step: 8
Training loss: 0.2609268128871918
Validation loss: 2.072057565053304

Epoch: 6| Step: 9
Training loss: 0.23517411947250366
Validation loss: 2.046348830064138

Epoch: 6| Step: 10
Training loss: 0.6199076175689697
Validation loss: 2.051677644252777

Epoch: 6| Step: 11
Training loss: 0.2804256081581116
Validation loss: 2.056983550389608

Epoch: 6| Step: 12
Training loss: 0.13693548738956451
Validation loss: 2.0761327743530273

Epoch: 6| Step: 13
Training loss: 0.26780635118484497
Validation loss: 2.0772167245546975

Epoch: 528| Step: 0
Training loss: 0.5866549611091614
Validation loss: 2.085034171740214

Epoch: 6| Step: 1
Training loss: 0.14971837401390076
Validation loss: 2.0629383524258933

Epoch: 6| Step: 2
Training loss: 0.3255234360694885
Validation loss: 2.0311673482259116

Epoch: 6| Step: 3
Training loss: 0.2264004796743393
Validation loss: 2.0746546188990274

Epoch: 6| Step: 4
Training loss: 0.25412988662719727
Validation loss: 2.0484275420506797

Epoch: 6| Step: 5
Training loss: 0.18390962481498718
Validation loss: 2.0466485023498535

Epoch: 6| Step: 6
Training loss: 0.132863387465477
Validation loss: 2.0584649244944253

Epoch: 6| Step: 7
Training loss: 0.21793612837791443
Validation loss: 2.069014072418213

Epoch: 6| Step: 8
Training loss: 0.1671379655599594
Validation loss: 2.0566412607828775

Epoch: 6| Step: 9
Training loss: 0.19515159726142883
Validation loss: 2.074861307938894

Epoch: 6| Step: 10
Training loss: 0.19707292318344116
Validation loss: 2.0915008584658303

Epoch: 6| Step: 11
Training loss: 0.21319296956062317
Validation loss: 2.0839633544286094

Epoch: 6| Step: 12
Training loss: 0.20099495351314545
Validation loss: 2.0395853916803994

Epoch: 6| Step: 13
Training loss: 0.23186029493808746
Validation loss: 2.0730700691541037

Epoch: 529| Step: 0
Training loss: 0.1709672510623932
Validation loss: 2.088476002216339

Epoch: 6| Step: 1
Training loss: 0.21127614378929138
Validation loss: 2.0453243056933084

Epoch: 6| Step: 2
Training loss: 0.17935091257095337
Validation loss: 2.066994369029999

Epoch: 6| Step: 3
Training loss: 0.2675062417984009
Validation loss: 2.077279349168142

Epoch: 6| Step: 4
Training loss: 0.26630014181137085
Validation loss: 2.077741861343384

Epoch: 6| Step: 5
Training loss: 0.18002018332481384
Validation loss: 2.0671342809995017

Epoch: 6| Step: 6
Training loss: 0.2980678677558899
Validation loss: 2.0740174651145935

Epoch: 6| Step: 7
Training loss: 0.5428591370582581
Validation loss: 2.085258722305298

Epoch: 6| Step: 8
Training loss: 0.15889635682106018
Validation loss: 2.056188623110453

Epoch: 6| Step: 9
Training loss: 0.15133915841579437
Validation loss: 2.0400724609692893

Epoch: 6| Step: 10
Training loss: 0.2209118753671646
Validation loss: 2.054310401280721

Epoch: 6| Step: 11
Training loss: 0.183547243475914
Validation loss: 2.060544232527415

Epoch: 6| Step: 12
Training loss: 0.2425248920917511
Validation loss: 2.0350788633028665

Epoch: 6| Step: 13
Training loss: 0.2594916522502899
Validation loss: 2.029017170270284

Epoch: 530| Step: 0
Training loss: 0.19283832609653473
Validation loss: 2.0462591648101807

Epoch: 6| Step: 1
Training loss: 0.20534244179725647
Validation loss: 2.0271762212117515

Epoch: 6| Step: 2
Training loss: 0.34333449602127075
Validation loss: 2.0399399399757385

Epoch: 6| Step: 3
Training loss: 0.18723013997077942
Validation loss: 2.058030386765798

Epoch: 6| Step: 4
Training loss: 0.2275324910879135
Validation loss: 2.0399710536003113

Epoch: 6| Step: 5
Training loss: 0.2714586555957794
Validation loss: 2.063361922899882

Epoch: 6| Step: 6
Training loss: 0.14442536234855652
Validation loss: 2.082730750242869

Epoch: 6| Step: 7
Training loss: 0.21587829291820526
Validation loss: 2.076902985572815

Epoch: 6| Step: 8
Training loss: 0.23806171119213104
Validation loss: 2.036408464113871

Epoch: 6| Step: 9
Training loss: 0.2137702852487564
Validation loss: 2.076271732648214

Epoch: 6| Step: 10
Training loss: 0.5838209390640259
Validation loss: 2.0671525597572327

Epoch: 6| Step: 11
Training loss: 0.21499593555927277
Validation loss: 2.080773194630941

Epoch: 6| Step: 12
Training loss: 0.19354555010795593
Validation loss: 2.0750531554222107

Epoch: 6| Step: 13
Training loss: 0.25786757469177246
Validation loss: 2.076483209927877

Epoch: 531| Step: 0
Training loss: 0.1967221200466156
Validation loss: 2.0646822849909463

Epoch: 6| Step: 1
Training loss: 0.30926913022994995
Validation loss: 2.119791309038798

Epoch: 6| Step: 2
Training loss: 0.5719177722930908
Validation loss: 2.0802701314290366

Epoch: 6| Step: 3
Training loss: 0.21768459677696228
Validation loss: 2.0988264083862305

Epoch: 6| Step: 4
Training loss: 0.20287027955055237
Validation loss: 2.093750258286794

Epoch: 6| Step: 5
Training loss: 0.24803872406482697
Validation loss: 2.0537989934285483

Epoch: 6| Step: 6
Training loss: 0.17673549056053162
Validation loss: 2.0813297231992087

Epoch: 6| Step: 7
Training loss: 0.2034081518650055
Validation loss: 2.0461827516555786

Epoch: 6| Step: 8
Training loss: 0.17628361284732819
Validation loss: 2.070048908392588

Epoch: 6| Step: 9
Training loss: 0.18806925415992737
Validation loss: 2.0739072958628335

Epoch: 6| Step: 10
Training loss: 0.29936683177948
Validation loss: 2.0494531989097595

Epoch: 6| Step: 11
Training loss: 0.22509035468101501
Validation loss: 2.093856076399485

Epoch: 6| Step: 12
Training loss: 0.25014668703079224
Validation loss: 2.0959754983584085

Epoch: 6| Step: 13
Training loss: 0.2515757381916046
Validation loss: 2.0725032885869346

Epoch: 532| Step: 0
Training loss: 0.6462178230285645
Validation loss: 2.061937173207601

Epoch: 6| Step: 1
Training loss: 0.1588403284549713
Validation loss: 2.0649569431940713

Epoch: 6| Step: 2
Training loss: 0.16938923299312592
Validation loss: 2.0710524717966714

Epoch: 6| Step: 3
Training loss: 0.18201681971549988
Validation loss: 2.0499754349390664

Epoch: 6| Step: 4
Training loss: 0.20987601578235626
Validation loss: 2.038564682006836

Epoch: 6| Step: 5
Training loss: 0.2177838236093521
Validation loss: 2.040196637312571

Epoch: 6| Step: 6
Training loss: 0.399593710899353
Validation loss: 2.0520940820376077

Epoch: 6| Step: 7
Training loss: 0.25642043352127075
Validation loss: 2.0612696409225464

Epoch: 6| Step: 8
Training loss: 0.2191171497106552
Validation loss: 2.0497686664263406

Epoch: 6| Step: 9
Training loss: 0.13625049591064453
Validation loss: 2.0548267563184104

Epoch: 6| Step: 10
Training loss: 0.24836167693138123
Validation loss: 2.094580372174581

Epoch: 6| Step: 11
Training loss: 0.34762340784072876
Validation loss: 2.080607295036316

Epoch: 6| Step: 12
Training loss: 0.3176272213459015
Validation loss: 2.110704243183136

Epoch: 6| Step: 13
Training loss: 0.18216702342033386
Validation loss: 2.108453333377838

Epoch: 533| Step: 0
Training loss: 0.1713053584098816
Validation loss: 2.0629215041796365

Epoch: 6| Step: 1
Training loss: 0.22071072459220886
Validation loss: 2.049041469891866

Epoch: 6| Step: 2
Training loss: 0.18590015172958374
Validation loss: 2.0495516061782837

Epoch: 6| Step: 3
Training loss: 0.22862517833709717
Validation loss: 2.0654506285985312

Epoch: 6| Step: 4
Training loss: 0.2769414186477661
Validation loss: 2.044247269630432

Epoch: 6| Step: 5
Training loss: 0.6134013533592224
Validation loss: 2.067769984404246

Epoch: 6| Step: 6
Training loss: 0.23783256113529205
Validation loss: 2.0672004222869873

Epoch: 6| Step: 7
Training loss: 0.24225910007953644
Validation loss: 2.0725839535395303

Epoch: 6| Step: 8
Training loss: 0.3317109942436218
Validation loss: 2.1010536352793374

Epoch: 6| Step: 9
Training loss: 0.21406379342079163
Validation loss: 2.059505820274353

Epoch: 6| Step: 10
Training loss: 0.1962370127439499
Validation loss: 2.07330455382665

Epoch: 6| Step: 11
Training loss: 0.30388689041137695
Validation loss: 2.0850591460863748

Epoch: 6| Step: 12
Training loss: 0.18911965191364288
Validation loss: 2.064110537370046

Epoch: 6| Step: 13
Training loss: 0.22865545749664307
Validation loss: 2.0536359548568726

Epoch: 534| Step: 0
Training loss: 0.12307506799697876
Validation loss: 2.0375746289889016

Epoch: 6| Step: 1
Training loss: 0.14776179194450378
Validation loss: 2.0282487869262695

Epoch: 6| Step: 2
Training loss: 0.21250948309898376
Validation loss: 2.051902254422506

Epoch: 6| Step: 3
Training loss: 0.3198851943016052
Validation loss: 2.0322561860084534

Epoch: 6| Step: 4
Training loss: 0.1617201566696167
Validation loss: 2.041508754094442

Epoch: 6| Step: 5
Training loss: 0.1944282352924347
Validation loss: 2.072443942228953

Epoch: 6| Step: 6
Training loss: 0.14789626002311707
Validation loss: 2.0424073139826455

Epoch: 6| Step: 7
Training loss: 0.21277624368667603
Validation loss: 2.0981942613919577

Epoch: 6| Step: 8
Training loss: 0.17078368365764618
Validation loss: 2.0585235953330994

Epoch: 6| Step: 9
Training loss: 0.5337417125701904
Validation loss: 2.0741406281789145

Epoch: 6| Step: 10
Training loss: 0.23407065868377686
Validation loss: 2.065397262573242

Epoch: 6| Step: 11
Training loss: 0.19564113020896912
Validation loss: 2.0705453356107077

Epoch: 6| Step: 12
Training loss: 0.19126775860786438
Validation loss: 2.0872419675191245

Epoch: 6| Step: 13
Training loss: 0.18920239806175232
Validation loss: 2.088388959566752

Epoch: 535| Step: 0
Training loss: 0.19441796839237213
Validation loss: 2.0738748709360757

Epoch: 6| Step: 1
Training loss: 0.21588841080665588
Validation loss: 2.0471229553222656

Epoch: 6| Step: 2
Training loss: 0.20537002384662628
Validation loss: 2.0970292687416077

Epoch: 6| Step: 3
Training loss: 0.1534157693386078
Validation loss: 2.0673934618631997

Epoch: 6| Step: 4
Training loss: 0.09958726167678833
Validation loss: 2.070628583431244

Epoch: 6| Step: 5
Training loss: 0.11470790952444077
Validation loss: 2.0639161268870034

Epoch: 6| Step: 6
Training loss: 0.4899369776248932
Validation loss: 2.0833779772122702

Epoch: 6| Step: 7
Training loss: 0.34871405363082886
Validation loss: 2.096659302711487

Epoch: 6| Step: 8
Training loss: 0.17757219076156616
Validation loss: 2.065046032269796

Epoch: 6| Step: 9
Training loss: 0.1556243747472763
Validation loss: 2.051279127597809

Epoch: 6| Step: 10
Training loss: 0.14690345525741577
Validation loss: 2.1168888012568154

Epoch: 6| Step: 11
Training loss: 0.1767575591802597
Validation loss: 2.0916557709376016

Epoch: 6| Step: 12
Training loss: 0.14770019054412842
Validation loss: 2.097933530807495

Epoch: 6| Step: 13
Training loss: 0.1746985912322998
Validation loss: 2.0928914149602256

Epoch: 536| Step: 0
Training loss: 0.33667653799057007
Validation loss: 2.091150164604187

Epoch: 6| Step: 1
Training loss: 0.17185914516448975
Validation loss: 2.098288675149282

Epoch: 6| Step: 2
Training loss: 0.15927167236804962
Validation loss: 2.0513266921043396

Epoch: 6| Step: 3
Training loss: 0.541344165802002
Validation loss: 2.059336523214976

Epoch: 6| Step: 4
Training loss: 0.15651224553585052
Validation loss: 2.042340616385142

Epoch: 6| Step: 5
Training loss: 0.1654033362865448
Validation loss: 2.098350942134857

Epoch: 6| Step: 6
Training loss: 0.20069023966789246
Validation loss: 2.038654545942942

Epoch: 6| Step: 7
Training loss: 0.26917514204978943
Validation loss: 2.0563583175341287

Epoch: 6| Step: 8
Training loss: 0.14993919432163239
Validation loss: 2.0181082487106323

Epoch: 6| Step: 9
Training loss: 0.22610017657279968
Validation loss: 2.039970576763153

Epoch: 6| Step: 10
Training loss: 0.2032361477613449
Validation loss: 2.071201046307882

Epoch: 6| Step: 11
Training loss: 0.14139600098133087
Validation loss: 2.0699459115664163

Epoch: 6| Step: 12
Training loss: 0.19465097784996033
Validation loss: 2.039643327395121

Epoch: 6| Step: 13
Training loss: 0.14983612298965454
Validation loss: 2.061125934123993

Epoch: 537| Step: 0
Training loss: 0.13771167397499084
Validation loss: 2.073104977607727

Epoch: 6| Step: 1
Training loss: 0.229896679520607
Validation loss: 2.080530345439911

Epoch: 6| Step: 2
Training loss: 0.19743074476718903
Validation loss: 2.062475621700287

Epoch: 6| Step: 3
Training loss: 0.2256961166858673
Validation loss: 2.074887971083323

Epoch: 6| Step: 4
Training loss: 0.18703076243400574
Validation loss: 2.0742926796277366

Epoch: 6| Step: 5
Training loss: 0.17089739441871643
Validation loss: 2.0647324323654175

Epoch: 6| Step: 6
Training loss: 0.10005633533000946
Validation loss: 2.107183814048767

Epoch: 6| Step: 7
Training loss: 0.12779764831066132
Validation loss: 2.039724111557007

Epoch: 6| Step: 8
Training loss: 0.35670462250709534
Validation loss: 2.066852072874705

Epoch: 6| Step: 9
Training loss: 0.1773427128791809
Validation loss: 2.0486485958099365

Epoch: 6| Step: 10
Training loss: 0.22359858453273773
Validation loss: 2.046354293823242

Epoch: 6| Step: 11
Training loss: 0.20646685361862183
Validation loss: 2.0930635134379068

Epoch: 6| Step: 12
Training loss: 0.5390345454216003
Validation loss: 2.0881882111231485

Epoch: 6| Step: 13
Training loss: 0.2277495414018631
Validation loss: 2.076054632663727

Epoch: 538| Step: 0
Training loss: 0.2840988039970398
Validation loss: 2.081786314646403

Epoch: 6| Step: 1
Training loss: 0.20666296780109406
Validation loss: 2.0664220253626504

Epoch: 6| Step: 2
Training loss: 0.14906534552574158
Validation loss: 2.0704692602157593

Epoch: 6| Step: 3
Training loss: 0.11828996986150742
Validation loss: 2.057054797808329

Epoch: 6| Step: 4
Training loss: 0.11929833143949509
Validation loss: 2.021931211153666

Epoch: 6| Step: 5
Training loss: 0.17078262567520142
Validation loss: 2.0416023333867392

Epoch: 6| Step: 6
Training loss: 0.19916385412216187
Validation loss: 2.0600358843803406

Epoch: 6| Step: 7
Training loss: 0.1786266416311264
Validation loss: 2.0706586241722107

Epoch: 6| Step: 8
Training loss: 0.18327906727790833
Validation loss: 2.0840514103571572

Epoch: 6| Step: 9
Training loss: 0.5357711315155029
Validation loss: 2.0654114882151284

Epoch: 6| Step: 10
Training loss: 0.14997941255569458
Validation loss: 2.0663564205169678

Epoch: 6| Step: 11
Training loss: 0.2117128074169159
Validation loss: 2.0743006467819214

Epoch: 6| Step: 12
Training loss: 0.16747809946537018
Validation loss: 2.064937253793081

Epoch: 6| Step: 13
Training loss: 0.16039666533470154
Validation loss: 2.099235157171885

Epoch: 539| Step: 0
Training loss: 0.14400066435337067
Validation loss: 2.084999759991964

Epoch: 6| Step: 1
Training loss: 0.1974342316389084
Validation loss: 2.106808602809906

Epoch: 6| Step: 2
Training loss: 0.21863144636154175
Validation loss: 2.11998321612676

Epoch: 6| Step: 3
Training loss: 0.36132538318634033
Validation loss: 2.1158149242401123

Epoch: 6| Step: 4
Training loss: 0.20267519354820251
Validation loss: 2.079693913459778

Epoch: 6| Step: 5
Training loss: 0.18107269704341888
Validation loss: 2.105703274408976

Epoch: 6| Step: 6
Training loss: 0.16241851449012756
Validation loss: 2.1314661304155984

Epoch: 6| Step: 7
Training loss: 0.23368299007415771
Validation loss: 2.0603672862052917

Epoch: 6| Step: 8
Training loss: 0.2057647407054901
Validation loss: 2.104737957318624

Epoch: 6| Step: 9
Training loss: 0.532250165939331
Validation loss: 2.07152928908666

Epoch: 6| Step: 10
Training loss: 0.12298199534416199
Validation loss: 2.1197539567947388

Epoch: 6| Step: 11
Training loss: 0.18794256448745728
Validation loss: 2.0720190604527793

Epoch: 6| Step: 12
Training loss: 0.21115881204605103
Validation loss: 2.0819269021352134

Epoch: 6| Step: 13
Training loss: 0.24699100852012634
Validation loss: 2.1072448094685874

Epoch: 540| Step: 0
Training loss: 0.1800576150417328
Validation loss: 2.1122466723124185

Epoch: 6| Step: 1
Training loss: 0.23831850290298462
Validation loss: 2.1224048733711243

Epoch: 6| Step: 2
Training loss: 0.2342744767665863
Validation loss: 2.0858512123425803

Epoch: 6| Step: 3
Training loss: 0.17300046980381012
Validation loss: 2.1124340693155923

Epoch: 6| Step: 4
Training loss: 0.26417165994644165
Validation loss: 2.0908299684524536

Epoch: 6| Step: 5
Training loss: 0.21420353651046753
Validation loss: 2.142005364100138

Epoch: 6| Step: 6
Training loss: 0.1650177538394928
Validation loss: 2.09997687737147

Epoch: 6| Step: 7
Training loss: 0.19632680714130402
Validation loss: 2.0857152541478476

Epoch: 6| Step: 8
Training loss: 0.12438393384218216
Validation loss: 2.074498017628988

Epoch: 6| Step: 9
Training loss: 0.16967931389808655
Validation loss: 2.068536162376404

Epoch: 6| Step: 10
Training loss: 0.1621617078781128
Validation loss: 2.1162738601366677

Epoch: 6| Step: 11
Training loss: 0.1615125834941864
Validation loss: 2.1022605895996094

Epoch: 6| Step: 12
Training loss: 0.22482356429100037
Validation loss: 2.0603571931521096

Epoch: 6| Step: 13
Training loss: 0.5074101090431213
Validation loss: 2.090647300084432

Epoch: 541| Step: 0
Training loss: 0.21091215312480927
Validation loss: 2.0726555387179055

Epoch: 6| Step: 1
Training loss: 0.15288671851158142
Validation loss: 2.055648465951284

Epoch: 6| Step: 2
Training loss: 0.16189774870872498
Validation loss: 2.047574977080027

Epoch: 6| Step: 3
Training loss: 0.133322075009346
Validation loss: 2.057781676451365

Epoch: 6| Step: 4
Training loss: 0.13704031705856323
Validation loss: 2.054502248764038

Epoch: 6| Step: 5
Training loss: 0.22938264906406403
Validation loss: 2.0588566660881042

Epoch: 6| Step: 6
Training loss: 0.25217369198799133
Validation loss: 2.0370286107063293

Epoch: 6| Step: 7
Training loss: 0.1611999273300171
Validation loss: 2.033221443494161

Epoch: 6| Step: 8
Training loss: 0.17080840468406677
Validation loss: 2.084173639615377

Epoch: 6| Step: 9
Training loss: 0.2424974888563156
Validation loss: 2.044869124889374

Epoch: 6| Step: 10
Training loss: 0.19796980917453766
Validation loss: 2.0513325333595276

Epoch: 6| Step: 11
Training loss: 0.5212127566337585
Validation loss: 2.0433748960494995

Epoch: 6| Step: 12
Training loss: 0.3618089556694031
Validation loss: 2.0369827349980674

Epoch: 6| Step: 13
Training loss: 0.1573811024427414
Validation loss: 2.0886895259221396

Epoch: 542| Step: 0
Training loss: 0.11763980984687805
Validation loss: 2.0447850028673806

Epoch: 6| Step: 1
Training loss: 0.11879666894674301
Validation loss: 2.087331751982371

Epoch: 6| Step: 2
Training loss: 0.21937105059623718
Validation loss: 2.0290923913319907

Epoch: 6| Step: 3
Training loss: 0.15845724940299988
Validation loss: 2.021539847056071

Epoch: 6| Step: 4
Training loss: 0.21743923425674438
Validation loss: 2.062008579572042

Epoch: 6| Step: 5
Training loss: 0.2485668957233429
Validation loss: 2.0565232634544373

Epoch: 6| Step: 6
Training loss: 0.15909457206726074
Validation loss: 2.044308523337046

Epoch: 6| Step: 7
Training loss: 0.5497359037399292
Validation loss: 2.081055442492167

Epoch: 6| Step: 8
Training loss: 0.3023974299430847
Validation loss: 2.0631007750829062

Epoch: 6| Step: 9
Training loss: 0.12255018949508667
Validation loss: 2.048499047756195

Epoch: 6| Step: 10
Training loss: 0.1691766381263733
Validation loss: 2.0611602465311685

Epoch: 6| Step: 11
Training loss: 0.15585929155349731
Validation loss: 2.0347344676653543

Epoch: 6| Step: 12
Training loss: 0.18726852536201477
Validation loss: 2.044659455617269

Epoch: 6| Step: 13
Training loss: 0.2667423486709595
Validation loss: 2.0584577123324075

Epoch: 543| Step: 0
Training loss: 0.6024874448776245
Validation loss: 2.0350897510846457

Epoch: 6| Step: 1
Training loss: 0.23926876485347748
Validation loss: 2.0807141264279685

Epoch: 6| Step: 2
Training loss: 0.17219100892543793
Validation loss: 2.069759964942932

Epoch: 6| Step: 3
Training loss: 0.14871849119663239
Validation loss: 2.0983718832333884

Epoch: 6| Step: 4
Training loss: 0.2423093020915985
Validation loss: 2.118084987004598

Epoch: 6| Step: 5
Training loss: 0.24515818059444427
Validation loss: 2.0725067257881165

Epoch: 6| Step: 6
Training loss: 0.2738536596298218
Validation loss: 2.0886727372805276

Epoch: 6| Step: 7
Training loss: 0.2549818456172943
Validation loss: 2.0705565412839255

Epoch: 6| Step: 8
Training loss: 0.1859784573316574
Validation loss: 2.0622165203094482

Epoch: 6| Step: 9
Training loss: 0.26640209555625916
Validation loss: 2.082484503587087

Epoch: 6| Step: 10
Training loss: 0.29846513271331787
Validation loss: 2.062086760997772

Epoch: 6| Step: 11
Training loss: 0.21184590458869934
Validation loss: 2.073457976182302

Epoch: 6| Step: 12
Training loss: 0.18417538702487946
Validation loss: 2.065992514292399

Epoch: 6| Step: 13
Training loss: 0.21874642372131348
Validation loss: 2.0827728708585105

Epoch: 544| Step: 0
Training loss: 0.1888321191072464
Validation loss: 2.122955063978831

Epoch: 6| Step: 1
Training loss: 0.45507436990737915
Validation loss: 2.100511650244395

Epoch: 6| Step: 2
Training loss: 0.2958693504333496
Validation loss: 2.100924829641978

Epoch: 6| Step: 3
Training loss: 0.195622518658638
Validation loss: 2.1260552604993186

Epoch: 6| Step: 4
Training loss: 0.16453617811203003
Validation loss: 2.08216655254364

Epoch: 6| Step: 5
Training loss: 0.2571217715740204
Validation loss: 2.0444385608037314

Epoch: 6| Step: 6
Training loss: 0.20639701187610626
Validation loss: 2.0907710591952005

Epoch: 6| Step: 7
Training loss: 0.20842431485652924
Validation loss: 2.0680484970410666

Epoch: 6| Step: 8
Training loss: 0.11640222370624542
Validation loss: 2.043749829133352

Epoch: 6| Step: 9
Training loss: 0.20921339094638824
Validation loss: 2.0811636050542197

Epoch: 6| Step: 10
Training loss: 0.5974879264831543
Validation loss: 2.0104860067367554

Epoch: 6| Step: 11
Training loss: 0.17810621857643127
Validation loss: 2.0685055255889893

Epoch: 6| Step: 12
Training loss: 0.20097830891609192
Validation loss: 2.0718889832496643

Epoch: 6| Step: 13
Training loss: 0.20887139439582825
Validation loss: 2.0816508531570435

Epoch: 545| Step: 0
Training loss: 0.2623879015445709
Validation loss: 2.063334345817566

Epoch: 6| Step: 1
Training loss: 0.1951761394739151
Validation loss: 2.048029104868571

Epoch: 6| Step: 2
Training loss: 0.16978605091571808
Validation loss: 2.0783916314442954

Epoch: 6| Step: 3
Training loss: 0.14502465724945068
Validation loss: 2.062856137752533

Epoch: 6| Step: 4
Training loss: 0.1560807079076767
Validation loss: 2.0567266742388406

Epoch: 6| Step: 5
Training loss: 0.3540796637535095
Validation loss: 2.0922820568084717

Epoch: 6| Step: 6
Training loss: 0.16019916534423828
Validation loss: 2.061871568361918

Epoch: 6| Step: 7
Training loss: 0.0886421650648117
Validation loss: 2.0549103220303855

Epoch: 6| Step: 8
Training loss: 0.444845050573349
Validation loss: 2.066347340742747

Epoch: 6| Step: 9
Training loss: 0.35501864552497864
Validation loss: 2.0467912356058755

Epoch: 6| Step: 10
Training loss: 0.2111789584159851
Validation loss: 2.059649725755056

Epoch: 6| Step: 11
Training loss: 0.2209356725215912
Validation loss: 2.040238916873932

Epoch: 6| Step: 12
Training loss: 0.5375056862831116
Validation loss: 2.0161350766817727

Epoch: 6| Step: 13
Training loss: 0.2515980899333954
Validation loss: 2.085472067197164

Epoch: 546| Step: 0
Training loss: 0.15436184406280518
Validation loss: 2.0800769329071045

Epoch: 6| Step: 1
Training loss: 0.2509153485298157
Validation loss: 2.053963383038839

Epoch: 6| Step: 2
Training loss: 0.1800835281610489
Validation loss: 2.0602745413780212

Epoch: 6| Step: 3
Training loss: 0.12152186036109924
Validation loss: 2.088365058104197

Epoch: 6| Step: 4
Training loss: 0.1837528944015503
Validation loss: 2.035313685735067

Epoch: 6| Step: 5
Training loss: 0.2766438126564026
Validation loss: 2.0493218700091043

Epoch: 6| Step: 6
Training loss: 0.14426887035369873
Validation loss: 2.0785134633382163

Epoch: 6| Step: 7
Training loss: 0.22407229244709015
Validation loss: 2.0439774791399636

Epoch: 6| Step: 8
Training loss: 0.13684684038162231
Validation loss: 2.0952640970547995

Epoch: 6| Step: 9
Training loss: 0.2851096987724304
Validation loss: 2.0516459941864014

Epoch: 6| Step: 10
Training loss: 0.5940365791320801
Validation loss: 2.0575393239657083

Epoch: 6| Step: 11
Training loss: 0.20862969756126404
Validation loss: 2.0684133569399514

Epoch: 6| Step: 12
Training loss: 0.1849103569984436
Validation loss: 2.0652693708737693

Epoch: 6| Step: 13
Training loss: 0.1871911585330963
Validation loss: 2.047221044699351

Epoch: 547| Step: 0
Training loss: 0.6134656667709351
Validation loss: 2.10965363184611

Epoch: 6| Step: 1
Training loss: 0.1715165227651596
Validation loss: 2.102202912171682

Epoch: 6| Step: 2
Training loss: 0.20230436325073242
Validation loss: 2.1255873640378318

Epoch: 6| Step: 3
Training loss: 0.16707704961299896
Validation loss: 2.0644423166910806

Epoch: 6| Step: 4
Training loss: 0.15625980496406555
Validation loss: 2.073490937550863

Epoch: 6| Step: 5
Training loss: 0.18072259426116943
Validation loss: 2.087068756421407

Epoch: 6| Step: 6
Training loss: 0.1466238796710968
Validation loss: 2.076341966787974

Epoch: 6| Step: 7
Training loss: 0.20981302857398987
Validation loss: 2.078650176525116

Epoch: 6| Step: 8
Training loss: 0.18167473375797272
Validation loss: 2.0562421083450317

Epoch: 6| Step: 9
Training loss: 0.14851456880569458
Validation loss: 2.063373565673828

Epoch: 6| Step: 10
Training loss: 0.3914061486721039
Validation loss: 2.085296551386515

Epoch: 6| Step: 11
Training loss: 0.15007035434246063
Validation loss: 2.1051186124483743

Epoch: 6| Step: 12
Training loss: 0.1964908242225647
Validation loss: 2.0739210844039917

Epoch: 6| Step: 13
Training loss: 0.21644973754882812
Validation loss: 2.0522759755452475

Epoch: 548| Step: 0
Training loss: 0.5997405052185059
Validation loss: 2.056792438030243

Epoch: 6| Step: 1
Training loss: 0.17825132608413696
Validation loss: 2.0712006092071533

Epoch: 6| Step: 2
Training loss: 0.13739773631095886
Validation loss: 2.101473808288574

Epoch: 6| Step: 3
Training loss: 0.20700973272323608
Validation loss: 2.069248159726461

Epoch: 6| Step: 4
Training loss: 0.15707938373088837
Validation loss: 2.1061563889185586

Epoch: 6| Step: 5
Training loss: 0.16840334236621857
Validation loss: 2.0874053239822388

Epoch: 6| Step: 6
Training loss: 0.18967851996421814
Validation loss: 2.0785707434018454

Epoch: 6| Step: 7
Training loss: 0.1398749053478241
Validation loss: 2.065720876057943

Epoch: 6| Step: 8
Training loss: 0.2043592631816864
Validation loss: 2.073195695877075

Epoch: 6| Step: 9
Training loss: 0.2401392012834549
Validation loss: 2.0967246492703757

Epoch: 6| Step: 10
Training loss: 0.14638829231262207
Validation loss: 2.096105992794037

Epoch: 6| Step: 11
Training loss: 0.14656856656074524
Validation loss: 2.0707459847132363

Epoch: 6| Step: 12
Training loss: 0.16116537153720856
Validation loss: 2.094123065471649

Epoch: 6| Step: 13
Training loss: 0.28897276520729065
Validation loss: 2.070150852203369

Epoch: 549| Step: 0
Training loss: 0.21329456567764282
Validation loss: 2.0645814140637717

Epoch: 6| Step: 1
Training loss: 0.19110867381095886
Validation loss: 2.072243650754293

Epoch: 6| Step: 2
Training loss: 0.11507853865623474
Validation loss: 2.095149497191111

Epoch: 6| Step: 3
Training loss: 0.17037370800971985
Validation loss: 2.092734217643738

Epoch: 6| Step: 4
Training loss: 0.32385239005088806
Validation loss: 2.10862398147583

Epoch: 6| Step: 5
Training loss: 0.12482233345508575
Validation loss: 2.055468122164408

Epoch: 6| Step: 6
Training loss: 0.5306106805801392
Validation loss: 2.0789394974708557

Epoch: 6| Step: 7
Training loss: 0.16716916859149933
Validation loss: 2.0919370651245117

Epoch: 6| Step: 8
Training loss: 0.20546704530715942
Validation loss: 2.067390739917755

Epoch: 6| Step: 9
Training loss: 0.1116507351398468
Validation loss: 2.0466933449109397

Epoch: 6| Step: 10
Training loss: 0.16104771196842194
Validation loss: 2.067670921484629

Epoch: 6| Step: 11
Training loss: 0.17515340447425842
Validation loss: 2.0329857667287192

Epoch: 6| Step: 12
Training loss: 0.2292044311761856
Validation loss: 2.042056659857432

Epoch: 6| Step: 13
Training loss: 0.21901465952396393
Validation loss: 2.071322043736776

Epoch: 550| Step: 0
Training loss: 0.14293979108333588
Validation loss: 2.074980537096659

Epoch: 6| Step: 1
Training loss: 0.17806321382522583
Validation loss: 2.082642436027527

Epoch: 6| Step: 2
Training loss: 0.12125962972640991
Validation loss: 2.1010054548581443

Epoch: 6| Step: 3
Training loss: 0.21060669422149658
Validation loss: 2.045561114947001

Epoch: 6| Step: 4
Training loss: 0.17108696699142456
Validation loss: 2.09677783648173

Epoch: 6| Step: 5
Training loss: 0.16276490688323975
Validation loss: 2.0933459202448526

Epoch: 6| Step: 6
Training loss: 0.1700645089149475
Validation loss: 2.08638201157252

Epoch: 6| Step: 7
Training loss: 0.17579033970832825
Validation loss: 2.064984222253164

Epoch: 6| Step: 8
Training loss: 0.18193259835243225
Validation loss: 2.0658475955327353

Epoch: 6| Step: 9
Training loss: 0.6021958589553833
Validation loss: 2.054219603538513

Epoch: 6| Step: 10
Training loss: 0.30967384576797485
Validation loss: 2.044360041618347

Epoch: 6| Step: 11
Training loss: 0.1952246129512787
Validation loss: 2.099998970826467

Epoch: 6| Step: 12
Training loss: 0.2860615849494934
Validation loss: 2.0509777069091797

Epoch: 6| Step: 13
Training loss: 0.1896362602710724
Validation loss: 2.09125808874766

Testing loss: 1.9923692281297642
