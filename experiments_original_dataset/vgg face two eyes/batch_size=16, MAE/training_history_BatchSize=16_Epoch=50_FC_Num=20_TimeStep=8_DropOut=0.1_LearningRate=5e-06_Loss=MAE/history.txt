Epoch: 1| Step: 0
Training loss: 6.432917594909668
Validation loss: 5.870677550633748

Epoch: 6| Step: 1
Training loss: 6.74013614654541
Validation loss: 5.8456324736277265

Epoch: 6| Step: 2
Training loss: 6.645617961883545
Validation loss: 5.817262252171834

Epoch: 6| Step: 3
Training loss: 5.304421901702881
Validation loss: 5.7897805372873945

Epoch: 6| Step: 4
Training loss: 5.643643379211426
Validation loss: 5.762942393620809

Epoch: 6| Step: 5
Training loss: 6.232923984527588
Validation loss: 5.735819896062215

Epoch: 6| Step: 6
Training loss: 5.538524627685547
Validation loss: 5.7087375322977705

Epoch: 6| Step: 7
Training loss: 4.77100944519043
Validation loss: 5.681496620178223

Epoch: 6| Step: 8
Training loss: 4.941732883453369
Validation loss: 5.65565292040507

Epoch: 6| Step: 9
Training loss: 5.014101982116699
Validation loss: 5.630247275034587

Epoch: 6| Step: 10
Training loss: 5.7883381843566895
Validation loss: 5.60473895072937

Epoch: 6| Step: 11
Training loss: 5.466455459594727
Validation loss: 5.580689430236816

Epoch: 6| Step: 12
Training loss: 6.327366828918457
Validation loss: 5.550710995992024

Epoch: 6| Step: 13
Training loss: 5.923839569091797
Validation loss: 5.522647539774577

Epoch: 2| Step: 0
Training loss: 5.163961887359619
Validation loss: 5.494034051895142

Epoch: 6| Step: 1
Training loss: 6.290034294128418
Validation loss: 5.464094718297322

Epoch: 6| Step: 2
Training loss: 5.35774040222168
Validation loss: 5.432488044102986

Epoch: 6| Step: 3
Training loss: 5.9660491943359375
Validation loss: 5.405473073323567

Epoch: 6| Step: 4
Training loss: 5.680511951446533
Validation loss: 5.368921120961507

Epoch: 6| Step: 5
Training loss: 5.770072937011719
Validation loss: 5.332508563995361

Epoch: 6| Step: 6
Training loss: 5.170513153076172
Validation loss: 5.2974174817403155

Epoch: 6| Step: 7
Training loss: 4.210000991821289
Validation loss: 5.2649320761362715

Epoch: 6| Step: 8
Training loss: 4.702744483947754
Validation loss: 5.219054698944092

Epoch: 6| Step: 9
Training loss: 5.2137346267700195
Validation loss: 5.184735457102458

Epoch: 6| Step: 10
Training loss: 5.473203659057617
Validation loss: 5.146580934524536

Epoch: 6| Step: 11
Training loss: 6.257880210876465
Validation loss: 5.101811408996582

Epoch: 6| Step: 12
Training loss: 4.0044264793396
Validation loss: 5.059502840042114

Epoch: 6| Step: 13
Training loss: 5.497607231140137
Validation loss: 5.015987157821655

Epoch: 3| Step: 0
Training loss: 5.176184177398682
Validation loss: 4.970694541931152

Epoch: 6| Step: 1
Training loss: 5.693293571472168
Validation loss: 4.918204466501872

Epoch: 6| Step: 2
Training loss: 5.623255252838135
Validation loss: 4.869114359219869

Epoch: 6| Step: 3
Training loss: 5.291392803192139
Validation loss: 4.816950798034668

Epoch: 6| Step: 4
Training loss: 4.312130451202393
Validation loss: 4.757581869761149

Epoch: 6| Step: 5
Training loss: 5.107856273651123
Validation loss: 4.71143635114034

Epoch: 6| Step: 6
Training loss: 3.7863729000091553
Validation loss: 4.645431915918986

Epoch: 6| Step: 7
Training loss: 4.934628486633301
Validation loss: 4.586726864178975

Epoch: 6| Step: 8
Training loss: 4.942264556884766
Validation loss: 4.527498960494995

Epoch: 6| Step: 9
Training loss: 4.0070953369140625
Validation loss: 4.453603823979695

Epoch: 6| Step: 10
Training loss: 4.014556884765625
Validation loss: 4.388087193171184

Epoch: 6| Step: 11
Training loss: 3.9744112491607666
Validation loss: 4.3132851123809814

Epoch: 6| Step: 12
Training loss: 4.035865783691406
Validation loss: 4.2365197738011675

Epoch: 6| Step: 13
Training loss: 4.657715797424316
Validation loss: 4.176906744639079

Epoch: 4| Step: 0
Training loss: 4.2908525466918945
Validation loss: 4.095792174339294

Epoch: 6| Step: 1
Training loss: 4.493819236755371
Validation loss: 4.020109415054321

Epoch: 6| Step: 2
Training loss: 4.357923984527588
Validation loss: 3.938750147819519

Epoch: 6| Step: 3
Training loss: 2.9597911834716797
Validation loss: 3.8633883794148765

Epoch: 6| Step: 4
Training loss: 3.8656182289123535
Validation loss: 3.7870163122812905

Epoch: 6| Step: 5
Training loss: 3.0368361473083496
Validation loss: 3.7031357685724893

Epoch: 6| Step: 6
Training loss: 3.110628128051758
Validation loss: 3.623334209124247

Epoch: 6| Step: 7
Training loss: 3.8269917964935303
Validation loss: 3.542405923207601

Epoch: 6| Step: 8
Training loss: 3.3623414039611816
Validation loss: 3.452544172604879

Epoch: 6| Step: 9
Training loss: 3.24515962600708
Validation loss: 3.368334929148356

Epoch: 6| Step: 10
Training loss: 3.249441623687744
Validation loss: 3.2855721712112427

Epoch: 6| Step: 11
Training loss: 4.2257771492004395
Validation loss: 3.1913551092147827

Epoch: 6| Step: 12
Training loss: 3.6307590007781982
Validation loss: 3.0992002884546914

Epoch: 6| Step: 13
Training loss: 3.026365041732788
Validation loss: 3.0096636613210044

Epoch: 5| Step: 0
Training loss: 3.040222644805908
Validation loss: 2.9139403899510703

Epoch: 6| Step: 1
Training loss: 2.856593132019043
Validation loss: 2.8226065238316855

Epoch: 6| Step: 2
Training loss: 3.041694402694702
Validation loss: 2.716683586438497

Epoch: 6| Step: 3
Training loss: 2.6814756393432617
Validation loss: 2.6031653881073

Epoch: 6| Step: 4
Training loss: 2.3581156730651855
Validation loss: 2.5503841241200766

Epoch: 6| Step: 5
Training loss: 2.370436668395996
Validation loss: 2.456392546494802

Epoch: 6| Step: 6
Training loss: 2.5868866443634033
Validation loss: 2.40817662080129

Epoch: 6| Step: 7
Training loss: 2.418851137161255
Validation loss: 2.31300942103068

Epoch: 6| Step: 8
Training loss: 2.659364938735962
Validation loss: 2.2493905425071716

Epoch: 6| Step: 9
Training loss: 1.7222657203674316
Validation loss: 2.2342816591262817

Epoch: 6| Step: 10
Training loss: 1.9371647834777832
Validation loss: 2.21167520682017

Epoch: 6| Step: 11
Training loss: 2.5375382900238037
Validation loss: 2.2233700354894004

Epoch: 6| Step: 12
Training loss: 2.6379146575927734
Validation loss: 2.194214324156443

Epoch: 6| Step: 13
Training loss: 1.6080331802368164
Validation loss: 2.1747289101282754

Epoch: 6| Step: 0
Training loss: 1.7928425073623657
Validation loss: 2.1926198601722717

Epoch: 6| Step: 1
Training loss: 2.057258367538452
Validation loss: 2.1603564421335855

Epoch: 6| Step: 2
Training loss: 3.186067581176758
Validation loss: 2.1886895497639975

Epoch: 6| Step: 3
Training loss: 2.483278274536133
Validation loss: 2.208873689174652

Epoch: 6| Step: 4
Training loss: 1.6734986305236816
Validation loss: 2.178641676902771

Epoch: 6| Step: 5
Training loss: 1.9029366970062256
Validation loss: 2.1994903683662415

Epoch: 6| Step: 6
Training loss: 2.163445234298706
Validation loss: 2.20155135790507

Epoch: 6| Step: 7
Training loss: 2.0254321098327637
Validation loss: 2.1886324683825173

Epoch: 6| Step: 8
Training loss: 3.0853304862976074
Validation loss: 2.1862476666768393

Epoch: 6| Step: 9
Training loss: 2.3175668716430664
Validation loss: 2.1875866850217185

Epoch: 6| Step: 10
Training loss: 2.0751397609710693
Validation loss: 2.162405252456665

Epoch: 6| Step: 11
Training loss: 2.091279983520508
Validation loss: 2.156597991784414

Epoch: 6| Step: 12
Training loss: 2.508451461791992
Validation loss: 2.161850611368815

Epoch: 6| Step: 13
Training loss: 1.9354077577590942
Validation loss: 2.164094090461731

Epoch: 7| Step: 0
Training loss: 2.1057887077331543
Validation loss: 2.1630929708480835

Epoch: 6| Step: 1
Training loss: 1.7729370594024658
Validation loss: 2.192320704460144

Epoch: 6| Step: 2
Training loss: 2.5663387775421143
Validation loss: 2.1700233618418374

Epoch: 6| Step: 3
Training loss: 2.298142910003662
Validation loss: 2.188539683818817

Epoch: 6| Step: 4
Training loss: 1.58013117313385
Validation loss: 2.183647930622101

Epoch: 6| Step: 5
Training loss: 1.934607982635498
Validation loss: 2.1844782630602517

Epoch: 6| Step: 6
Training loss: 1.7888470888137817
Validation loss: 2.1993561387062073

Epoch: 6| Step: 7
Training loss: 2.5141477584838867
Validation loss: 2.1786340475082397

Epoch: 6| Step: 8
Training loss: 2.867614984512329
Validation loss: 2.2102967302004495

Epoch: 6| Step: 9
Training loss: 1.7911791801452637
Validation loss: 2.2082974513371787

Epoch: 6| Step: 10
Training loss: 2.226803779602051
Validation loss: 2.2214972972869873

Epoch: 6| Step: 11
Training loss: 2.428311824798584
Validation loss: 2.215066929658254

Epoch: 6| Step: 12
Training loss: 2.566913604736328
Validation loss: 2.2052022417386374

Epoch: 6| Step: 13
Training loss: 1.9915720224380493
Validation loss: 2.1891303062438965

Epoch: 8| Step: 0
Training loss: 2.2539000511169434
Validation loss: 2.161447604497274

Epoch: 6| Step: 1
Training loss: 2.5755503177642822
Validation loss: 2.1678332487742105

Epoch: 6| Step: 2
Training loss: 1.8856918811798096
Validation loss: 2.1734580596288047

Epoch: 6| Step: 3
Training loss: 2.816603899002075
Validation loss: 2.1385680635770163

Epoch: 6| Step: 4
Training loss: 2.2910728454589844
Validation loss: 2.1569613019625344

Epoch: 6| Step: 5
Training loss: 2.028778553009033
Validation loss: 2.1334846218427024

Epoch: 6| Step: 6
Training loss: 1.7579807043075562
Validation loss: 2.1236506501833596

Epoch: 6| Step: 7
Training loss: 2.365238666534424
Validation loss: 2.1229874889055886

Epoch: 6| Step: 8
Training loss: 2.7706832885742188
Validation loss: 2.1404318809509277

Epoch: 6| Step: 9
Training loss: 1.8560574054718018
Validation loss: 2.1401659647623696

Epoch: 6| Step: 10
Training loss: 1.352048397064209
Validation loss: 2.131961186726888

Epoch: 6| Step: 11
Training loss: 2.298111915588379
Validation loss: 2.1126551628112793

Epoch: 6| Step: 12
Training loss: 2.7068662643432617
Validation loss: 2.133026639620463

Epoch: 6| Step: 13
Training loss: 1.6808985471725464
Validation loss: 2.1406526366869607

Epoch: 9| Step: 0
Training loss: 1.534233808517456
Validation loss: 2.1369062662124634

Epoch: 6| Step: 1
Training loss: 1.7675695419311523
Validation loss: 2.1375914812088013

Epoch: 6| Step: 2
Training loss: 2.4143805503845215
Validation loss: 2.1334547201792398

Epoch: 6| Step: 3
Training loss: 3.024529457092285
Validation loss: 2.140270213286082

Epoch: 6| Step: 4
Training loss: 1.8983659744262695
Validation loss: 2.1432511607805886

Epoch: 6| Step: 5
Training loss: 2.262396812438965
Validation loss: 2.1394058068593345

Epoch: 6| Step: 6
Training loss: 1.7850186824798584
Validation loss: 2.149351974328359

Epoch: 6| Step: 7
Training loss: 2.2880945205688477
Validation loss: 2.141045868396759

Epoch: 6| Step: 8
Training loss: 2.358755111694336
Validation loss: 2.1367095510164895

Epoch: 6| Step: 9
Training loss: 2.110344886779785
Validation loss: 2.152422845363617

Epoch: 6| Step: 10
Training loss: 2.183269739151001
Validation loss: 2.1608813405036926

Epoch: 6| Step: 11
Training loss: 1.9053698778152466
Validation loss: 2.149509151776632

Epoch: 6| Step: 12
Training loss: 1.9977879524230957
Validation loss: 2.1277800798416138

Epoch: 6| Step: 13
Training loss: 2.6867482662200928
Validation loss: 2.135359505812327

Epoch: 10| Step: 0
Training loss: 2.0853872299194336
Validation loss: 2.128575841585795

Epoch: 6| Step: 1
Training loss: 1.8720861673355103
Validation loss: 2.119554817676544

Epoch: 6| Step: 2
Training loss: 2.2510764598846436
Validation loss: 2.133974472681681

Epoch: 6| Step: 3
Training loss: 1.7087810039520264
Validation loss: 2.1365245978037515

Epoch: 6| Step: 4
Training loss: 1.9334521293640137
Validation loss: 2.1121144692103067

Epoch: 6| Step: 5
Training loss: 1.5521701574325562
Validation loss: 2.1225513219833374

Epoch: 6| Step: 6
Training loss: 1.830386757850647
Validation loss: 2.12536484003067

Epoch: 6| Step: 7
Training loss: 2.588862895965576
Validation loss: 2.122779905796051

Epoch: 6| Step: 8
Training loss: 3.154543161392212
Validation loss: 2.1348374287287393

Epoch: 6| Step: 9
Training loss: 1.6970609426498413
Validation loss: 2.1153018275896707

Epoch: 6| Step: 10
Training loss: 1.9364581108093262
Validation loss: 2.090436259905497

Epoch: 6| Step: 11
Training loss: 1.3765466213226318
Validation loss: 2.124589204788208

Epoch: 6| Step: 12
Training loss: 2.8397626876831055
Validation loss: 2.0936673680941262

Epoch: 6| Step: 13
Training loss: 2.6869912147521973
Validation loss: 2.0991624196370444

Epoch: 11| Step: 0
Training loss: 2.1994996070861816
Validation loss: 2.111815353234609

Epoch: 6| Step: 1
Training loss: 2.096240997314453
Validation loss: 2.1075342496236167

Epoch: 6| Step: 2
Training loss: 2.4380111694335938
Validation loss: 2.101002017656962

Epoch: 6| Step: 3
Training loss: 2.3970155715942383
Validation loss: 2.1124257246653237

Epoch: 6| Step: 4
Training loss: 1.783069133758545
Validation loss: 2.091874599456787

Epoch: 6| Step: 5
Training loss: 2.5440566539764404
Validation loss: 2.1037171681722007

Epoch: 6| Step: 6
Training loss: 1.8443353176116943
Validation loss: 2.107043127218882

Epoch: 6| Step: 7
Training loss: 2.3230092525482178
Validation loss: 2.080774267514547

Epoch: 6| Step: 8
Training loss: 1.385151982307434
Validation loss: 2.101241926352183

Epoch: 6| Step: 9
Training loss: 2.009181022644043
Validation loss: 2.1159321864446006

Epoch: 6| Step: 10
Training loss: 1.9897782802581787
Validation loss: 2.1204620798428855

Epoch: 6| Step: 11
Training loss: 1.7906452417373657
Validation loss: 2.0848828057448068

Epoch: 6| Step: 12
Training loss: 1.9679961204528809
Validation loss: 2.1133969823519387

Epoch: 6| Step: 13
Training loss: 2.5702943801879883
Validation loss: 2.0917176604270935

Epoch: 12| Step: 0
Training loss: 2.0129876136779785
Validation loss: 2.1021821101506553

Epoch: 6| Step: 1
Training loss: 1.642524242401123
Validation loss: 2.079536497592926

Epoch: 6| Step: 2
Training loss: 1.7457646131515503
Validation loss: 2.0858402252197266

Epoch: 6| Step: 3
Training loss: 2.144937753677368
Validation loss: 2.090036610762278

Epoch: 6| Step: 4
Training loss: 2.4324638843536377
Validation loss: 2.065919737021128

Epoch: 6| Step: 5
Training loss: 1.7701270580291748
Validation loss: 2.0947784185409546

Epoch: 6| Step: 6
Training loss: 2.2038960456848145
Validation loss: 2.0769073963165283

Epoch: 6| Step: 7
Training loss: 2.0690417289733887
Validation loss: 2.0918742418289185

Epoch: 6| Step: 8
Training loss: 2.357619285583496
Validation loss: 2.091947873433431

Epoch: 6| Step: 9
Training loss: 2.4505128860473633
Validation loss: 2.112380882104238

Epoch: 6| Step: 10
Training loss: 1.632753610610962
Validation loss: 2.1032880942026773

Epoch: 6| Step: 11
Training loss: 2.8823037147521973
Validation loss: 2.078683157761892

Epoch: 6| Step: 12
Training loss: 2.272141933441162
Validation loss: 2.08092870314916

Epoch: 6| Step: 13
Training loss: 1.8887548446655273
Validation loss: 2.0709831913312278

Epoch: 13| Step: 0
Training loss: 1.6526644229888916
Validation loss: 2.085883915424347

Epoch: 6| Step: 1
Training loss: 1.8287590742111206
Validation loss: 2.06655885775884

Epoch: 6| Step: 2
Training loss: 2.0672357082366943
Validation loss: 2.087859789530436

Epoch: 6| Step: 3
Training loss: 2.223003387451172
Validation loss: 2.1056102911631265

Epoch: 6| Step: 4
Training loss: 2.287362813949585
Validation loss: 2.067319611708323

Epoch: 6| Step: 5
Training loss: 2.6142795085906982
Validation loss: 2.089313487211863

Epoch: 6| Step: 6
Training loss: 2.5422000885009766
Validation loss: 2.0825857122739158

Epoch: 6| Step: 7
Training loss: 2.1956281661987305
Validation loss: 2.0769722064336142

Epoch: 6| Step: 8
Training loss: 2.0883641242980957
Validation loss: 2.085846503575643

Epoch: 6| Step: 9
Training loss: 1.9934080839157104
Validation loss: 2.089884261290232

Epoch: 6| Step: 10
Training loss: 1.5362982749938965
Validation loss: 2.1020246942838035

Epoch: 6| Step: 11
Training loss: 2.291490316390991
Validation loss: 2.073142091433207

Epoch: 6| Step: 12
Training loss: 1.992087721824646
Validation loss: 2.080577770868937

Epoch: 6| Step: 13
Training loss: 1.5664207935333252
Validation loss: 2.0685218572616577

Epoch: 14| Step: 0
Training loss: 2.327543258666992
Validation loss: 2.107909003893534

Epoch: 6| Step: 1
Training loss: 2.1742684841156006
Validation loss: 2.054616947968801

Epoch: 6| Step: 2
Training loss: 2.2985267639160156
Validation loss: 2.109380384286245

Epoch: 6| Step: 3
Training loss: 2.1914520263671875
Validation loss: 2.0630836288134256

Epoch: 6| Step: 4
Training loss: 1.431790828704834
Validation loss: 2.0597116152445474

Epoch: 6| Step: 5
Training loss: 2.2529654502868652
Validation loss: 2.0823853611946106

Epoch: 6| Step: 6
Training loss: 2.2835521697998047
Validation loss: 2.0845054388046265

Epoch: 6| Step: 7
Training loss: 2.4689838886260986
Validation loss: 2.0591824054718018

Epoch: 6| Step: 8
Training loss: 2.2306435108184814
Validation loss: 2.072102348009745

Epoch: 6| Step: 9
Training loss: 1.515462040901184
Validation loss: 2.0828227599461875

Epoch: 6| Step: 10
Training loss: 2.1509737968444824
Validation loss: 2.0522069533665976

Epoch: 6| Step: 11
Training loss: 1.3136048316955566
Validation loss: 2.0794519186019897

Epoch: 6| Step: 12
Training loss: 1.6742115020751953
Validation loss: 2.0624220768610635

Epoch: 6| Step: 13
Training loss: 2.743813991546631
Validation loss: 2.098633110523224

Epoch: 15| Step: 0
Training loss: 1.943282127380371
Validation loss: 2.050644556681315

Epoch: 6| Step: 1
Training loss: 1.996098279953003
Validation loss: 2.059185286362966

Epoch: 6| Step: 2
Training loss: 2.4356229305267334
Validation loss: 2.0463999112447104

Epoch: 6| Step: 3
Training loss: 2.2071266174316406
Validation loss: 2.053237716356913

Epoch: 6| Step: 4
Training loss: 2.304255962371826
Validation loss: 2.0653052727381387

Epoch: 6| Step: 5
Training loss: 1.8966976404190063
Validation loss: 2.073312222957611

Epoch: 6| Step: 6
Training loss: 2.248574733734131
Validation loss: 2.072388231754303

Epoch: 6| Step: 7
Training loss: 1.625706434249878
Validation loss: 2.027801295121511

Epoch: 6| Step: 8
Training loss: 2.2376842498779297
Validation loss: 2.0674460927645364

Epoch: 6| Step: 9
Training loss: 2.0186116695404053
Validation loss: 2.0383711457252502

Epoch: 6| Step: 10
Training loss: 2.203566789627075
Validation loss: 2.085530718167623

Epoch: 6| Step: 11
Training loss: 2.196704864501953
Validation loss: 2.0634914437929788

Epoch: 6| Step: 12
Training loss: 1.4742722511291504
Validation loss: 2.0492993593215942

Epoch: 6| Step: 13
Training loss: 2.166309356689453
Validation loss: 2.04092546304067

Epoch: 16| Step: 0
Training loss: 1.816690444946289
Validation loss: 2.0261486570040383

Epoch: 6| Step: 1
Training loss: 2.106999158859253
Validation loss: 2.0233163237571716

Epoch: 6| Step: 2
Training loss: 2.6663436889648438
Validation loss: 2.059167524178823

Epoch: 6| Step: 3
Training loss: 2.4314918518066406
Validation loss: 2.066919287045797

Epoch: 6| Step: 4
Training loss: 1.6240142583847046
Validation loss: 2.0403018792470298

Epoch: 6| Step: 5
Training loss: 1.9278329610824585
Validation loss: 2.069543739159902

Epoch: 6| Step: 6
Training loss: 1.1724028587341309
Validation loss: 2.084254244963328

Epoch: 6| Step: 7
Training loss: 2.9857640266418457
Validation loss: 2.0339154402414956

Epoch: 6| Step: 8
Training loss: 1.5019491910934448
Validation loss: 2.063625713189443

Epoch: 6| Step: 9
Training loss: 2.806492567062378
Validation loss: 2.0674776434898376

Epoch: 6| Step: 10
Training loss: 1.7769088745117188
Validation loss: 2.0780556996663413

Epoch: 6| Step: 11
Training loss: 2.397007942199707
Validation loss: 2.0509532690048218

Epoch: 6| Step: 12
Training loss: 1.9380645751953125
Validation loss: 2.0407735109329224

Epoch: 6| Step: 13
Training loss: 1.6658154726028442
Validation loss: 2.060563584168752

Epoch: 17| Step: 0
Training loss: 1.9529316425323486
Validation loss: 2.0479223132133484

Epoch: 6| Step: 1
Training loss: 1.3171967267990112
Validation loss: 2.066427012284597

Epoch: 6| Step: 2
Training loss: 2.3519999980926514
Validation loss: 2.0574985345204673

Epoch: 6| Step: 3
Training loss: 1.6091727018356323
Validation loss: 2.0409163435300193

Epoch: 6| Step: 4
Training loss: 2.0788097381591797
Validation loss: 2.0708992083867392

Epoch: 6| Step: 5
Training loss: 1.633720874786377
Validation loss: 2.0817261139551797

Epoch: 6| Step: 6
Training loss: 2.2103843688964844
Validation loss: 2.062447210152944

Epoch: 6| Step: 7
Training loss: 2.247074842453003
Validation loss: 2.052802781263987

Epoch: 6| Step: 8
Training loss: 2.545468330383301
Validation loss: 2.046015481154124

Epoch: 6| Step: 9
Training loss: 1.5972769260406494
Validation loss: 2.067487974961599

Epoch: 6| Step: 10
Training loss: 2.3678088188171387
Validation loss: 2.033971389134725

Epoch: 6| Step: 11
Training loss: 2.287527561187744
Validation loss: 2.04958709081014

Epoch: 6| Step: 12
Training loss: 2.2919235229492188
Validation loss: 2.038522263367971

Epoch: 6| Step: 13
Training loss: 2.43580961227417
Validation loss: 2.0712988575299582

Epoch: 18| Step: 0
Training loss: 1.622917652130127
Validation loss: 2.0308659076690674

Epoch: 6| Step: 1
Training loss: 2.3760695457458496
Validation loss: 2.0491862495740256

Epoch: 6| Step: 2
Training loss: 1.9592972993850708
Validation loss: 2.071905334790548

Epoch: 6| Step: 3
Training loss: 1.750305414199829
Validation loss: 2.078846553961436

Epoch: 6| Step: 4
Training loss: 2.229261636734009
Validation loss: 2.0631394584973655

Epoch: 6| Step: 5
Training loss: 2.190746307373047
Validation loss: 2.062301456928253

Epoch: 6| Step: 6
Training loss: 2.054945230484009
Validation loss: 2.0485967000325522

Epoch: 6| Step: 7
Training loss: 1.7416568994522095
Validation loss: 2.0360654393831887

Epoch: 6| Step: 8
Training loss: 2.660097599029541
Validation loss: 2.063726623853048

Epoch: 6| Step: 9
Training loss: 1.84945809841156
Validation loss: 2.050632814566294

Epoch: 6| Step: 10
Training loss: 2.045191764831543
Validation loss: 2.040622969468435

Epoch: 6| Step: 11
Training loss: 1.7255713939666748
Validation loss: 2.0611273845036826

Epoch: 6| Step: 12
Training loss: 2.0317535400390625
Validation loss: 2.0509316325187683

Epoch: 6| Step: 13
Training loss: 2.0113792419433594
Validation loss: 2.027187089125315

Epoch: 19| Step: 0
Training loss: 2.084446668624878
Validation loss: 2.0594374338785806

Epoch: 6| Step: 1
Training loss: 2.0615289211273193
Validation loss: 2.056607166926066

Epoch: 6| Step: 2
Training loss: 2.476346254348755
Validation loss: 2.0413867632548013

Epoch: 6| Step: 3
Training loss: 1.622056245803833
Validation loss: 2.041792074839274

Epoch: 6| Step: 4
Training loss: 2.488743782043457
Validation loss: 2.0420439640680947

Epoch: 6| Step: 5
Training loss: 2.262967348098755
Validation loss: 2.0571580727895102

Epoch: 6| Step: 6
Training loss: 1.8040450811386108
Validation loss: 2.057998478412628

Epoch: 6| Step: 7
Training loss: 1.9244095087051392
Validation loss: 2.0427414178848267

Epoch: 6| Step: 8
Training loss: 2.14699125289917
Validation loss: 2.059680759906769

Epoch: 6| Step: 9
Training loss: 1.5875390768051147
Validation loss: 2.0155606667200723

Epoch: 6| Step: 10
Training loss: 1.823443055152893
Validation loss: 2.0325852036476135

Epoch: 6| Step: 11
Training loss: 2.0749497413635254
Validation loss: 2.028214375178019

Epoch: 6| Step: 12
Training loss: 1.9707984924316406
Validation loss: 2.045094986756643

Epoch: 6| Step: 13
Training loss: 1.7816604375839233
Validation loss: 2.039627810319265

Epoch: 20| Step: 0
Training loss: 0.9945363402366638
Validation loss: 2.0336782534917197

Epoch: 6| Step: 1
Training loss: 1.6332013607025146
Validation loss: 2.023139735062917

Epoch: 6| Step: 2
Training loss: 1.7867246866226196
Validation loss: 2.021970530351003

Epoch: 6| Step: 3
Training loss: 3.1554083824157715
Validation loss: 2.016649921735128

Epoch: 6| Step: 4
Training loss: 2.318981647491455
Validation loss: 2.0518064498901367

Epoch: 6| Step: 5
Training loss: 1.4864970445632935
Validation loss: 2.0385510524113974

Epoch: 6| Step: 6
Training loss: 2.3534297943115234
Validation loss: 2.0380913813908896

Epoch: 6| Step: 7
Training loss: 2.015895366668701
Validation loss: 2.0454474488894143

Epoch: 6| Step: 8
Training loss: 2.1819968223571777
Validation loss: 2.038156270980835

Epoch: 6| Step: 9
Training loss: 1.9040560722351074
Validation loss: 2.053330381711324

Epoch: 6| Step: 10
Training loss: 2.317612409591675
Validation loss: 2.05543585618337

Epoch: 6| Step: 11
Training loss: 1.640439748764038
Validation loss: 2.031514326731364

Epoch: 6| Step: 12
Training loss: 2.7190208435058594
Validation loss: 2.0482806166013083

Epoch: 6| Step: 13
Training loss: 1.8426289558410645
Validation loss: 2.0558738708496094

Epoch: 21| Step: 0
Training loss: 1.6444751024246216
Validation loss: 2.065043111642202

Epoch: 6| Step: 1
Training loss: 2.1059885025024414
Validation loss: 2.0457960963249207

Epoch: 6| Step: 2
Training loss: 2.010974645614624
Validation loss: 2.0899431109428406

Epoch: 6| Step: 3
Training loss: 2.027611255645752
Validation loss: 2.0944648583730063

Epoch: 6| Step: 4
Training loss: 2.037611484527588
Validation loss: 2.0678309003512063

Epoch: 6| Step: 5
Training loss: 2.5130112171173096
Validation loss: 2.061986207962036

Epoch: 6| Step: 6
Training loss: 1.3925225734710693
Validation loss: 2.041569252808889

Epoch: 6| Step: 7
Training loss: 2.1190383434295654
Validation loss: 2.046018600463867

Epoch: 6| Step: 8
Training loss: 2.3280906677246094
Validation loss: 2.0582781235376992

Epoch: 6| Step: 9
Training loss: 2.229921340942383
Validation loss: 2.0491130550702414

Epoch: 6| Step: 10
Training loss: 2.3624515533447266
Validation loss: 2.0722313721974692

Epoch: 6| Step: 11
Training loss: 1.6234976053237915
Validation loss: 2.0241453846295676

Epoch: 6| Step: 12
Training loss: 1.8844224214553833
Validation loss: 1.9971531629562378

Epoch: 6| Step: 13
Training loss: 1.9339529275894165
Validation loss: 2.0346631606419883

Epoch: 22| Step: 0
Training loss: 2.177518606185913
Validation loss: 2.0565266410509744

Epoch: 6| Step: 1
Training loss: 2.331911087036133
Validation loss: 2.0473807056744895

Epoch: 6| Step: 2
Training loss: 2.089566230773926
Validation loss: 2.0432180166244507

Epoch: 6| Step: 3
Training loss: 1.480191707611084
Validation loss: 2.008167584737142

Epoch: 6| Step: 4
Training loss: 2.3433852195739746
Validation loss: 2.040112336476644

Epoch: 6| Step: 5
Training loss: 2.2078657150268555
Validation loss: 2.0438263416290283

Epoch: 6| Step: 6
Training loss: 2.2757105827331543
Validation loss: 2.0291978120803833

Epoch: 6| Step: 7
Training loss: 2.0683162212371826
Validation loss: 2.036852320035299

Epoch: 6| Step: 8
Training loss: 2.2412612438201904
Validation loss: 2.0200233260790506

Epoch: 6| Step: 9
Training loss: 1.5440309047698975
Validation loss: 2.029844025770823

Epoch: 6| Step: 10
Training loss: 1.5167500972747803
Validation loss: 2.046417752901713

Epoch: 6| Step: 11
Training loss: 2.5996203422546387
Validation loss: 2.0343523422876992

Epoch: 6| Step: 12
Training loss: 2.1501567363739014
Validation loss: 2.0279724399248757

Epoch: 6| Step: 13
Training loss: 1.4047574996948242
Validation loss: 2.04673037926356

Epoch: 23| Step: 0
Training loss: 1.7794278860092163
Validation loss: 2.049860715866089

Epoch: 6| Step: 1
Training loss: 2.344377040863037
Validation loss: 2.0390379428863525

Epoch: 6| Step: 2
Training loss: 1.6346940994262695
Validation loss: 2.040350834528605

Epoch: 6| Step: 3
Training loss: 2.299196720123291
Validation loss: 2.0329424341519675

Epoch: 6| Step: 4
Training loss: 1.7675650119781494
Validation loss: 2.013995587825775

Epoch: 6| Step: 5
Training loss: 2.344956874847412
Validation loss: 2.0199443101882935

Epoch: 6| Step: 6
Training loss: 1.9201937913894653
Validation loss: 2.0426448384920755

Epoch: 6| Step: 7
Training loss: 1.9061143398284912
Validation loss: 2.048116068045298

Epoch: 6| Step: 8
Training loss: 2.779132843017578
Validation loss: 2.0611530542373657

Epoch: 6| Step: 9
Training loss: 2.061227321624756
Validation loss: 2.0564410289128623

Epoch: 6| Step: 10
Training loss: 1.9959052801132202
Validation loss: 2.0549000898996987

Epoch: 6| Step: 11
Training loss: 1.9207732677459717
Validation loss: 2.0381617546081543

Epoch: 6| Step: 12
Training loss: 1.9211561679840088
Validation loss: 2.0540395975112915

Epoch: 6| Step: 13
Training loss: 1.4343994855880737
Validation loss: 2.019565681616465

Epoch: 24| Step: 0
Training loss: 2.276442050933838
Validation loss: 2.0204780300458274

Epoch: 6| Step: 1
Training loss: 2.3750782012939453
Validation loss: 2.038902203241984

Epoch: 6| Step: 2
Training loss: 2.1662039756774902
Validation loss: 2.0291043718655906

Epoch: 6| Step: 3
Training loss: 2.5318422317504883
Validation loss: 1.9928909540176392

Epoch: 6| Step: 4
Training loss: 1.7893702983856201
Validation loss: 2.047322471936544

Epoch: 6| Step: 5
Training loss: 2.101017475128174
Validation loss: 2.010204255580902

Epoch: 6| Step: 6
Training loss: 2.123539447784424
Validation loss: 2.0128528674443564

Epoch: 6| Step: 7
Training loss: 1.8189955949783325
Validation loss: 2.000596344470978

Epoch: 6| Step: 8
Training loss: 2.001077890396118
Validation loss: 2.0490026275316873

Epoch: 6| Step: 9
Training loss: 1.4313712120056152
Validation loss: 2.030411938826243

Epoch: 6| Step: 10
Training loss: 1.9241480827331543
Validation loss: 2.051855822404226

Epoch: 6| Step: 11
Training loss: 1.7305161952972412
Validation loss: 2.0138163367907205

Epoch: 6| Step: 12
Training loss: 1.6364502906799316
Validation loss: 2.022436738014221

Epoch: 6| Step: 13
Training loss: 2.3237738609313965
Validation loss: 2.0282286604245505

Epoch: 25| Step: 0
Training loss: 2.424314260482788
Validation loss: 2.0046932697296143

Epoch: 6| Step: 1
Training loss: 2.685976982116699
Validation loss: 2.015281637509664

Epoch: 6| Step: 2
Training loss: 2.3016462326049805
Validation loss: 2.034049650033315

Epoch: 6| Step: 3
Training loss: 1.4794275760650635
Validation loss: 2.0634997884432473

Epoch: 6| Step: 4
Training loss: 1.314760684967041
Validation loss: 2.062999347845713

Epoch: 6| Step: 5
Training loss: 1.6356728076934814
Validation loss: 2.064321060975393

Epoch: 6| Step: 6
Training loss: 1.78756582736969
Validation loss: 2.0242429971694946

Epoch: 6| Step: 7
Training loss: 2.5208353996276855
Validation loss: 2.0070836742719016

Epoch: 6| Step: 8
Training loss: 1.8810009956359863
Validation loss: 2.009770711263021

Epoch: 6| Step: 9
Training loss: 1.8453267812728882
Validation loss: 2.0286832253138223

Epoch: 6| Step: 10
Training loss: 2.2379150390625
Validation loss: 2.0404723087946572

Epoch: 6| Step: 11
Training loss: 1.4431943893432617
Validation loss: 2.003858725229899

Epoch: 6| Step: 12
Training loss: 2.251966953277588
Validation loss: 2.0309045712153115

Epoch: 6| Step: 13
Training loss: 2.3111331462860107
Validation loss: 2.05509481827418

Epoch: 26| Step: 0
Training loss: 1.601050615310669
Validation loss: 2.043428897857666

Epoch: 6| Step: 1
Training loss: 1.9688317775726318
Validation loss: 2.0482085943222046

Epoch: 6| Step: 2
Training loss: 1.9491276741027832
Validation loss: 2.0354994336764016

Epoch: 6| Step: 3
Training loss: 2.0687918663024902
Validation loss: 1.9999350508054097

Epoch: 6| Step: 4
Training loss: 1.9799578189849854
Validation loss: 2.015382925669352

Epoch: 6| Step: 5
Training loss: 2.060732126235962
Validation loss: 2.0396984020868936

Epoch: 6| Step: 6
Training loss: 2.245856285095215
Validation loss: 2.0459179878234863

Epoch: 6| Step: 7
Training loss: 2.750641107559204
Validation loss: 2.0016648968060813

Epoch: 6| Step: 8
Training loss: 2.036470890045166
Validation loss: 2.0374135176340737

Epoch: 6| Step: 9
Training loss: 2.2784035205841064
Validation loss: 2.0368138551712036

Epoch: 6| Step: 10
Training loss: 1.6249315738677979
Validation loss: 2.0085358023643494

Epoch: 6| Step: 11
Training loss: 1.673856258392334
Validation loss: 2.004157026608785

Epoch: 6| Step: 12
Training loss: 2.234030246734619
Validation loss: 2.0595763127009072

Epoch: 6| Step: 13
Training loss: 1.5225404500961304
Validation loss: 2.0089138547579446

Epoch: 27| Step: 0
Training loss: 2.1056196689605713
Validation loss: 2.026289423306783

Epoch: 6| Step: 1
Training loss: 1.5823218822479248
Validation loss: 2.0035893519719443

Epoch: 6| Step: 2
Training loss: 2.347762107849121
Validation loss: 2.0084697802861533

Epoch: 6| Step: 3
Training loss: 2.022270679473877
Validation loss: 2.0479888121287027

Epoch: 6| Step: 4
Training loss: 1.6145975589752197
Validation loss: 2.0357056856155396

Epoch: 6| Step: 5
Training loss: 2.0424680709838867
Validation loss: 2.0308340390523276

Epoch: 6| Step: 6
Training loss: 2.3065199851989746
Validation loss: 2.0478488008181253

Epoch: 6| Step: 7
Training loss: 1.859238862991333
Validation loss: 2.0070143143335977

Epoch: 6| Step: 8
Training loss: 1.6067523956298828
Validation loss: 2.021956284840902

Epoch: 6| Step: 9
Training loss: 2.9484658241271973
Validation loss: 2.0046018759409585

Epoch: 6| Step: 10
Training loss: 1.9008729457855225
Validation loss: 1.999283234278361

Epoch: 6| Step: 11
Training loss: 1.603928804397583
Validation loss: 2.052612523237864

Epoch: 6| Step: 12
Training loss: 2.101499080657959
Validation loss: 2.052772263685862

Epoch: 6| Step: 13
Training loss: 1.7190719842910767
Validation loss: 2.0341317852338157

Epoch: 28| Step: 0
Training loss: 2.461160659790039
Validation loss: 2.0381394227345786

Epoch: 6| Step: 1
Training loss: 2.7053098678588867
Validation loss: 2.0405548413594565

Epoch: 6| Step: 2
Training loss: 1.6748203039169312
Validation loss: 2.0801209211349487

Epoch: 6| Step: 3
Training loss: 1.519534945487976
Validation loss: 2.029273053010305

Epoch: 6| Step: 4
Training loss: 1.9626572132110596
Validation loss: 2.060818692048391

Epoch: 6| Step: 5
Training loss: 1.9513899087905884
Validation loss: 2.025462289651235

Epoch: 6| Step: 6
Training loss: 2.2437283992767334
Validation loss: 2.0368581215540567

Epoch: 6| Step: 7
Training loss: 1.8217148780822754
Validation loss: 2.039413889249166

Epoch: 6| Step: 8
Training loss: 1.8699082136154175
Validation loss: 2.039379676183065

Epoch: 6| Step: 9
Training loss: 1.8302068710327148
Validation loss: 2.032123585542043

Epoch: 6| Step: 10
Training loss: 1.5089586973190308
Validation loss: 2.0138729413350425

Epoch: 6| Step: 11
Training loss: 2.1332321166992188
Validation loss: 2.0319047371546426

Epoch: 6| Step: 12
Training loss: 2.9814271926879883
Validation loss: 2.0221099853515625

Epoch: 6| Step: 13
Training loss: 1.5264943838119507
Validation loss: 2.0222256779670715

Epoch: 29| Step: 0
Training loss: 1.6287930011749268
Validation loss: 2.0189586083094277

Epoch: 6| Step: 1
Training loss: 2.777451515197754
Validation loss: 1.9951510429382324

Epoch: 6| Step: 2
Training loss: 2.2197465896606445
Validation loss: 2.022202471892039

Epoch: 6| Step: 3
Training loss: 1.785964012145996
Validation loss: 2.018596629301707

Epoch: 6| Step: 4
Training loss: 1.6434433460235596
Validation loss: 2.0104870597521463

Epoch: 6| Step: 5
Training loss: 1.7607625722885132
Validation loss: 2.0312389135360718

Epoch: 6| Step: 6
Training loss: 1.765964150428772
Validation loss: 2.046122213204702

Epoch: 6| Step: 7
Training loss: 2.0104520320892334
Validation loss: 2.039207637310028

Epoch: 6| Step: 8
Training loss: 1.9756265878677368
Validation loss: 2.027288496494293

Epoch: 6| Step: 9
Training loss: 2.232191562652588
Validation loss: 2.0434570908546448

Epoch: 6| Step: 10
Training loss: 1.6971986293792725
Validation loss: 2.054042160511017

Epoch: 6| Step: 11
Training loss: 2.566573143005371
Validation loss: 2.005648593107859

Epoch: 6| Step: 12
Training loss: 2.2611827850341797
Validation loss: 2.0337036649386087

Epoch: 6| Step: 13
Training loss: 1.4084815979003906
Validation loss: 2.031659960746765

Epoch: 30| Step: 0
Training loss: 1.4867867231369019
Validation loss: 2.0082023541132608

Epoch: 6| Step: 1
Training loss: 1.646174430847168
Validation loss: 2.008802135785421

Epoch: 6| Step: 2
Training loss: 2.106523036956787
Validation loss: 2.0231485764185586

Epoch: 6| Step: 3
Training loss: 1.9089961051940918
Validation loss: 2.0133369167645774

Epoch: 6| Step: 4
Training loss: 2.6222071647644043
Validation loss: 2.0326497753461203

Epoch: 6| Step: 5
Training loss: 2.096640110015869
Validation loss: 2.0199286739031472

Epoch: 6| Step: 6
Training loss: 2.3012912273406982
Validation loss: 2.0054787397384644

Epoch: 6| Step: 7
Training loss: 1.8159496784210205
Validation loss: 2.0523763497670493

Epoch: 6| Step: 8
Training loss: 2.2260100841522217
Validation loss: 2.0408804416656494

Epoch: 6| Step: 9
Training loss: 1.8451297283172607
Validation loss: 2.0098193685213723

Epoch: 6| Step: 10
Training loss: 1.7264039516448975
Validation loss: 2.0413601795832315

Epoch: 6| Step: 11
Training loss: 1.9181498289108276
Validation loss: 2.010122458140055

Epoch: 6| Step: 12
Training loss: 2.2843737602233887
Validation loss: 2.014335513114929

Epoch: 6| Step: 13
Training loss: 1.985016942024231
Validation loss: 2.0131579438845315

Epoch: 31| Step: 0
Training loss: 2.5742578506469727
Validation loss: 2.026387949784597

Epoch: 6| Step: 1
Training loss: 2.2822234630584717
Validation loss: 2.0133765935897827

Epoch: 6| Step: 2
Training loss: 1.4445936679840088
Validation loss: 2.016744633515676

Epoch: 6| Step: 3
Training loss: 1.3361082077026367
Validation loss: 2.0303366978963218

Epoch: 6| Step: 4
Training loss: 1.3878378868103027
Validation loss: 2.019653876622518

Epoch: 6| Step: 5
Training loss: 1.5182409286499023
Validation loss: 2.0355724891026816

Epoch: 6| Step: 6
Training loss: 2.107456922531128
Validation loss: 2.0448525746663413

Epoch: 6| Step: 7
Training loss: 2.011204719543457
Validation loss: 2.0515068769454956

Epoch: 6| Step: 8
Training loss: 2.0279784202575684
Validation loss: 2.0405887762705484

Epoch: 6| Step: 9
Training loss: 2.4581212997436523
Validation loss: 2.047593832015991

Epoch: 6| Step: 10
Training loss: 2.389073133468628
Validation loss: 2.02153072754542

Epoch: 6| Step: 11
Training loss: 1.6411858797073364
Validation loss: 2.024117032686869

Epoch: 6| Step: 12
Training loss: 1.7450413703918457
Validation loss: 2.0589212775230408

Epoch: 6| Step: 13
Training loss: 2.4906229972839355
Validation loss: 2.030320962270101

Epoch: 32| Step: 0
Training loss: 2.5420780181884766
Validation loss: 2.051561097304026

Epoch: 6| Step: 1
Training loss: 2.4835405349731445
Validation loss: 2.0354049603144326

Epoch: 6| Step: 2
Training loss: 1.337777018547058
Validation loss: 2.008743703365326

Epoch: 6| Step: 3
Training loss: 1.5344319343566895
Validation loss: 2.0395302375157676

Epoch: 6| Step: 4
Training loss: 2.1411967277526855
Validation loss: 2.021325667699178

Epoch: 6| Step: 5
Training loss: 2.386504650115967
Validation loss: 2.0344741344451904

Epoch: 6| Step: 6
Training loss: 2.960035800933838
Validation loss: 2.0199883580207825

Epoch: 6| Step: 7
Training loss: 1.6294301748275757
Validation loss: 2.0440075596173606

Epoch: 6| Step: 8
Training loss: 2.2026262283325195
Validation loss: 2.0306746562321982

Epoch: 6| Step: 9
Training loss: 1.1835089921951294
Validation loss: 2.0048885345458984

Epoch: 6| Step: 10
Training loss: 1.8234705924987793
Validation loss: 2.0329453547795615

Epoch: 6| Step: 11
Training loss: 1.5191336870193481
Validation loss: 2.0348570346832275

Epoch: 6| Step: 12
Training loss: 1.9684078693389893
Validation loss: 2.0121930638949075

Epoch: 6| Step: 13
Training loss: 2.003100633621216
Validation loss: 2.0256924430529275

Epoch: 33| Step: 0
Training loss: 2.431267023086548
Validation loss: 2.0431001385053

Epoch: 6| Step: 1
Training loss: 1.5455600023269653
Validation loss: 2.002035935719808

Epoch: 6| Step: 2
Training loss: 1.9201958179473877
Validation loss: 2.0334522128105164

Epoch: 6| Step: 3
Training loss: 1.1607489585876465
Validation loss: 2.046994070212046

Epoch: 6| Step: 4
Training loss: 1.7297687530517578
Validation loss: 2.0509290297826133

Epoch: 6| Step: 5
Training loss: 2.28291392326355
Validation loss: 2.0599867502848306

Epoch: 6| Step: 6
Training loss: 2.4768309593200684
Validation loss: 2.0495825012524924

Epoch: 6| Step: 7
Training loss: 1.1818212270736694
Validation loss: 2.035380939642588

Epoch: 6| Step: 8
Training loss: 1.6715677976608276
Validation loss: 2.045213599999746

Epoch: 6| Step: 9
Training loss: 2.031320571899414
Validation loss: 2.0377671321233115

Epoch: 6| Step: 10
Training loss: 2.1615657806396484
Validation loss: 2.0516982078552246

Epoch: 6| Step: 11
Training loss: 2.3491733074188232
Validation loss: 2.0102861722310386

Epoch: 6| Step: 12
Training loss: 1.925201416015625
Validation loss: 2.0315288305282593

Epoch: 6| Step: 13
Training loss: 2.5986976623535156
Validation loss: 2.0473379890124

Epoch: 34| Step: 0
Training loss: 1.5700984001159668
Validation loss: 2.035469671090444

Epoch: 6| Step: 1
Training loss: 2.9413046836853027
Validation loss: 2.018543064594269

Epoch: 6| Step: 2
Training loss: 2.6122632026672363
Validation loss: 2.022750735282898

Epoch: 6| Step: 3
Training loss: 2.172548770904541
Validation loss: 2.01650333404541

Epoch: 6| Step: 4
Training loss: 1.8176252841949463
Validation loss: 2.031319538752238

Epoch: 6| Step: 5
Training loss: 2.3855643272399902
Validation loss: 1.9866267442703247

Epoch: 6| Step: 6
Training loss: 1.7924182415008545
Validation loss: 2.0000165502230325

Epoch: 6| Step: 7
Training loss: 1.8487367630004883
Validation loss: 2.0073741475741067

Epoch: 6| Step: 8
Training loss: 2.1571109294891357
Validation loss: 2.027117689450582

Epoch: 6| Step: 9
Training loss: 1.5702770948410034
Validation loss: 1.9883921841780345

Epoch: 6| Step: 10
Training loss: 1.1386632919311523
Validation loss: 2.027299145857493

Epoch: 6| Step: 11
Training loss: 1.6476656198501587
Validation loss: 1.993532657623291

Epoch: 6| Step: 12
Training loss: 2.1493215560913086
Validation loss: 2.019099692503611

Epoch: 6| Step: 13
Training loss: 1.7168192863464355
Validation loss: 2.0019193490346274

Epoch: 35| Step: 0
Training loss: 2.1969664096832275
Validation loss: 2.007784823576609

Epoch: 6| Step: 1
Training loss: 1.489438772201538
Validation loss: 2.001638889312744

Epoch: 6| Step: 2
Training loss: 2.4381179809570312
Validation loss: 2.0645967920621238

Epoch: 6| Step: 3
Training loss: 2.196502447128296
Validation loss: 2.0402692357699075

Epoch: 6| Step: 4
Training loss: 1.690714955329895
Validation loss: 2.0618202487627664

Epoch: 6| Step: 5
Training loss: 2.5912842750549316
Validation loss: 2.0721935033798218

Epoch: 6| Step: 6
Training loss: 1.6868205070495605
Validation loss: 2.0702733198801675

Epoch: 6| Step: 7
Training loss: 1.87034010887146
Validation loss: 2.0634840726852417

Epoch: 6| Step: 8
Training loss: 1.2875274419784546
Validation loss: 2.074249188105265

Epoch: 6| Step: 9
Training loss: 1.4294089078903198
Validation loss: 2.054535706837972

Epoch: 6| Step: 10
Training loss: 1.646477460861206
Validation loss: 2.0377077062924704

Epoch: 6| Step: 11
Training loss: 2.3272316455841064
Validation loss: 2.0170063177744546

Epoch: 6| Step: 12
Training loss: 2.3871376514434814
Validation loss: 1.991238494714101

Epoch: 6| Step: 13
Training loss: 2.1464462280273438
Validation loss: 1.980487068494161

Epoch: 36| Step: 0
Training loss: 1.8356196880340576
Validation loss: 2.049906075000763

Epoch: 6| Step: 1
Training loss: 2.329664945602417
Validation loss: 1.9989280502001445

Epoch: 6| Step: 2
Training loss: 2.1987199783325195
Validation loss: 2.009604593118032

Epoch: 6| Step: 3
Training loss: 1.9893178939819336
Validation loss: 1.9962757229804993

Epoch: 6| Step: 4
Training loss: 2.3196041584014893
Validation loss: 1.991663972536723

Epoch: 6| Step: 5
Training loss: 1.9018434286117554
Validation loss: 2.020457903544108

Epoch: 6| Step: 6
Training loss: 1.9903149604797363
Validation loss: 2.0256844957669577

Epoch: 6| Step: 7
Training loss: 1.2268539667129517
Validation loss: 2.04407791296641

Epoch: 6| Step: 8
Training loss: 1.5878639221191406
Validation loss: 2.01736847559611

Epoch: 6| Step: 9
Training loss: 2.196117877960205
Validation loss: 2.0386781096458435

Epoch: 6| Step: 10
Training loss: 2.423652172088623
Validation loss: 2.0356838703155518

Epoch: 6| Step: 11
Training loss: 2.0614137649536133
Validation loss: 2.038117508093516

Epoch: 6| Step: 12
Training loss: 1.7132346630096436
Validation loss: 2.0410369435946145

Epoch: 6| Step: 13
Training loss: 2.0979881286621094
Validation loss: 2.030181805292765

Epoch: 37| Step: 0
Training loss: 1.587679386138916
Validation loss: 2.045421600341797

Epoch: 6| Step: 1
Training loss: 1.5388742685317993
Validation loss: 1.9778637886047363

Epoch: 6| Step: 2
Training loss: 1.9796104431152344
Validation loss: 2.0191185673077903

Epoch: 6| Step: 3
Training loss: 1.327444076538086
Validation loss: 2.037280519803365

Epoch: 6| Step: 4
Training loss: 2.422389030456543
Validation loss: 2.0599356492360434

Epoch: 6| Step: 5
Training loss: 2.5056986808776855
Validation loss: 2.0934910972913108

Epoch: 6| Step: 6
Training loss: 2.3220605850219727
Validation loss: 2.11127777894338

Epoch: 6| Step: 7
Training loss: 1.230615496635437
Validation loss: 2.1042008797327676

Epoch: 6| Step: 8
Training loss: 1.9734125137329102
Validation loss: 2.0893799662590027

Epoch: 6| Step: 9
Training loss: 2.198455572128296
Validation loss: 2.1243085066477456

Epoch: 6| Step: 10
Training loss: 2.195338726043701
Validation loss: 2.092513302961985

Epoch: 6| Step: 11
Training loss: 1.7368295192718506
Validation loss: 2.0753444830576577

Epoch: 6| Step: 12
Training loss: 3.1623685359954834
Validation loss: 2.067521591981252

Epoch: 6| Step: 13
Training loss: 1.9736628532409668
Validation loss: 2.0546364784240723

Epoch: 38| Step: 0
Training loss: 1.9893550872802734
Validation loss: 2.018758018811544

Epoch: 6| Step: 1
Training loss: 1.7852227687835693
Validation loss: 2.0534927447636924

Epoch: 6| Step: 2
Training loss: 1.8085548877716064
Validation loss: 2.046803096930186

Epoch: 6| Step: 3
Training loss: 2.588202953338623
Validation loss: 2.01432341337204

Epoch: 6| Step: 4
Training loss: 1.3805420398712158
Validation loss: 2.047034800052643

Epoch: 6| Step: 5
Training loss: 2.3295092582702637
Validation loss: 2.0460588137308755

Epoch: 6| Step: 6
Training loss: 2.005417585372925
Validation loss: 2.0162566900253296

Epoch: 6| Step: 7
Training loss: 2.1986663341522217
Validation loss: 2.0291758378346763

Epoch: 6| Step: 8
Training loss: 1.73233962059021
Validation loss: 2.021404206752777

Epoch: 6| Step: 9
Training loss: 1.6891347169876099
Validation loss: 2.015263855457306

Epoch: 6| Step: 10
Training loss: 1.7986841201782227
Validation loss: 2.0325037638346353

Epoch: 6| Step: 11
Training loss: 1.6515263319015503
Validation loss: 2.005815545717875

Epoch: 6| Step: 12
Training loss: 2.0826196670532227
Validation loss: 2.0552960634231567

Epoch: 6| Step: 13
Training loss: 1.96566903591156
Validation loss: 2.041175107161204

Epoch: 39| Step: 0
Training loss: 2.5774006843566895
Validation loss: 2.0102826356887817

Epoch: 6| Step: 1
Training loss: 1.7159984111785889
Validation loss: 2.028195838133494

Epoch: 6| Step: 2
Training loss: 1.9506635665893555
Validation loss: 2.00670333703359

Epoch: 6| Step: 3
Training loss: 1.634369134902954
Validation loss: 2.0359968344370523

Epoch: 6| Step: 4
Training loss: 2.250621795654297
Validation loss: 2.006238639354706

Epoch: 6| Step: 5
Training loss: 1.7889256477355957
Validation loss: 2.0455418825149536

Epoch: 6| Step: 6
Training loss: 2.0087978839874268
Validation loss: 2.016620397567749

Epoch: 6| Step: 7
Training loss: 2.06105899810791
Validation loss: 2.0230894088745117

Epoch: 6| Step: 8
Training loss: 2.176422595977783
Validation loss: 2.0471392075220742

Epoch: 6| Step: 9
Training loss: 1.868877649307251
Validation loss: 2.0161309440930686

Epoch: 6| Step: 10
Training loss: 1.746326208114624
Validation loss: 1.975821574529012

Epoch: 6| Step: 11
Training loss: 2.1671371459960938
Validation loss: 2.0071728428204856

Epoch: 6| Step: 12
Training loss: 2.239990711212158
Validation loss: 2.0343124866485596

Epoch: 6| Step: 13
Training loss: 0.9618158340454102
Validation loss: 2.035387694835663

Epoch: 40| Step: 0
Training loss: 1.6166582107543945
Validation loss: 2.0694753726323447

Epoch: 6| Step: 1
Training loss: 1.7701997756958008
Validation loss: 2.0734802881876626

Epoch: 6| Step: 2
Training loss: 2.47324538230896
Validation loss: 2.0489877462387085

Epoch: 6| Step: 3
Training loss: 2.1120879650115967
Validation loss: 2.057797431945801

Epoch: 6| Step: 4
Training loss: 2.244967460632324
Validation loss: 2.0593404372533164

Epoch: 6| Step: 5
Training loss: 1.2525389194488525
Validation loss: 2.025908668835958

Epoch: 6| Step: 6
Training loss: 1.6858184337615967
Validation loss: 2.035050412019094

Epoch: 6| Step: 7
Training loss: 1.4328444004058838
Validation loss: 2.0122567216555276

Epoch: 6| Step: 8
Training loss: 2.292872905731201
Validation loss: 2.0206775863965354

Epoch: 6| Step: 9
Training loss: 1.7612121105194092
Validation loss: 2.0572385589281716

Epoch: 6| Step: 10
Training loss: 2.3400537967681885
Validation loss: 2.0279645919799805

Epoch: 6| Step: 11
Training loss: 1.7650055885314941
Validation loss: 2.0459600687026978

Epoch: 6| Step: 12
Training loss: 1.8837575912475586
Validation loss: 2.024814327557882

Epoch: 6| Step: 13
Training loss: 2.5593667030334473
Validation loss: 2.0231298009554544

Epoch: 41| Step: 0
Training loss: 2.3257133960723877
Validation loss: 2.0007627805074057

Epoch: 6| Step: 1
Training loss: 1.1859815120697021
Validation loss: 2.0180827975273132

Epoch: 6| Step: 2
Training loss: 1.6281213760375977
Validation loss: 2.0331392685572305

Epoch: 6| Step: 3
Training loss: 1.875471591949463
Validation loss: 1.988637884457906

Epoch: 6| Step: 4
Training loss: 1.9882715940475464
Validation loss: 2.025346597035726

Epoch: 6| Step: 5
Training loss: 2.029165267944336
Validation loss: 1.9957132538159688

Epoch: 6| Step: 6
Training loss: 2.1717610359191895
Validation loss: 2.0071345369021096

Epoch: 6| Step: 7
Training loss: 2.3924379348754883
Validation loss: 1.9738954106966655

Epoch: 6| Step: 8
Training loss: 2.188298225402832
Validation loss: 2.009459356466929

Epoch: 6| Step: 9
Training loss: 2.233006000518799
Validation loss: 2.028364658355713

Epoch: 6| Step: 10
Training loss: 1.443251609802246
Validation loss: 2.0279035170873008

Epoch: 6| Step: 11
Training loss: 2.2632060050964355
Validation loss: 2.0266606410344443

Epoch: 6| Step: 12
Training loss: 1.9267282485961914
Validation loss: 2.0034107764561973

Epoch: 6| Step: 13
Training loss: 1.8505444526672363
Validation loss: 2.0398375590642295

Epoch: 42| Step: 0
Training loss: 2.6536850929260254
Validation loss: 2.023374378681183

Epoch: 6| Step: 1
Training loss: 2.0283031463623047
Validation loss: 2.015793760617574

Epoch: 6| Step: 2
Training loss: 1.8509767055511475
Validation loss: 2.035897135734558

Epoch: 6| Step: 3
Training loss: 2.5070669651031494
Validation loss: 2.0410394072532654

Epoch: 6| Step: 4
Training loss: 1.446923851966858
Validation loss: 2.034732679526011

Epoch: 6| Step: 5
Training loss: 1.7621122598648071
Validation loss: 2.0786572297414145

Epoch: 6| Step: 6
Training loss: 1.9429372549057007
Validation loss: 2.061104496320089

Epoch: 6| Step: 7
Training loss: 2.0391175746917725
Validation loss: 2.092954715092977

Epoch: 6| Step: 8
Training loss: 1.7513105869293213
Validation loss: 2.052273948987325

Epoch: 6| Step: 9
Training loss: 2.0351085662841797
Validation loss: 2.0385369459788003

Epoch: 6| Step: 10
Training loss: 1.917171597480774
Validation loss: 2.0435742139816284

Epoch: 6| Step: 11
Training loss: 1.5796785354614258
Validation loss: 2.0350927313168845

Epoch: 6| Step: 12
Training loss: 1.1318769454956055
Validation loss: 2.011591056982676

Epoch: 6| Step: 13
Training loss: 2.5360193252563477
Validation loss: 2.032434125741323

Epoch: 43| Step: 0
Training loss: 1.8504884243011475
Validation loss: 2.0018802086512246

Epoch: 6| Step: 1
Training loss: 1.931955337524414
Validation loss: 2.019842525323232

Epoch: 6| Step: 2
Training loss: 2.3062186241149902
Validation loss: 2.0104071497917175

Epoch: 6| Step: 3
Training loss: 1.4866222143173218
Validation loss: 2.027804891268412

Epoch: 6| Step: 4
Training loss: 2.1566710472106934
Validation loss: 2.011472761631012

Epoch: 6| Step: 5
Training loss: 1.5779597759246826
Validation loss: 2.024375061194102

Epoch: 6| Step: 6
Training loss: 1.9528782367706299
Validation loss: 1.9954942067464192

Epoch: 6| Step: 7
Training loss: 1.851575493812561
Validation loss: 1.9948153297106426

Epoch: 6| Step: 8
Training loss: 2.1738481521606445
Validation loss: 2.0559628208478293

Epoch: 6| Step: 9
Training loss: 2.3514156341552734
Validation loss: 2.030508736769358

Epoch: 6| Step: 10
Training loss: 1.4054303169250488
Validation loss: 2.0473395784695945

Epoch: 6| Step: 11
Training loss: 1.7108964920043945
Validation loss: 2.0293108224868774

Epoch: 6| Step: 12
Training loss: 1.9344203472137451
Validation loss: 2.037525475025177

Epoch: 6| Step: 13
Training loss: 2.2493972778320312
Validation loss: 2.0140689611434937

Epoch: 44| Step: 0
Training loss: 2.125089168548584
Validation loss: 2.0264155864715576

Epoch: 6| Step: 1
Training loss: 2.1154332160949707
Validation loss: 2.030523975690206

Epoch: 6| Step: 2
Training loss: 1.579421043395996
Validation loss: 2.001360813776652

Epoch: 6| Step: 3
Training loss: 2.0367591381073
Validation loss: 2.013122022151947

Epoch: 6| Step: 4
Training loss: 1.7114489078521729
Validation loss: 2.014041026433309

Epoch: 6| Step: 5
Training loss: 2.1929125785827637
Validation loss: 1.998492161432902

Epoch: 6| Step: 6
Training loss: 1.892689824104309
Validation loss: 2.011520286401113

Epoch: 6| Step: 7
Training loss: 1.824280858039856
Validation loss: 2.000877877076467

Epoch: 6| Step: 8
Training loss: 2.4431228637695312
Validation loss: 2.0284423828125

Epoch: 6| Step: 9
Training loss: 1.7474778890609741
Validation loss: 2.0091669162114463

Epoch: 6| Step: 10
Training loss: 2.1736180782318115
Validation loss: 1.9999126394589741

Epoch: 6| Step: 11
Training loss: 1.5166425704956055
Validation loss: 2.0105039874712625

Epoch: 6| Step: 12
Training loss: 1.7019771337509155
Validation loss: 2.035076638062795

Epoch: 6| Step: 13
Training loss: 1.8349533081054688
Validation loss: 2.0468071699142456

Epoch: 45| Step: 0
Training loss: 1.9556310176849365
Validation loss: 2.0113275051116943

Epoch: 6| Step: 1
Training loss: 1.964691400527954
Validation loss: 2.0149513880411782

Epoch: 6| Step: 2
Training loss: 1.8287206888198853
Validation loss: 2.0281295577685037

Epoch: 6| Step: 3
Training loss: 2.026278495788574
Validation loss: 2.0307055910428367

Epoch: 6| Step: 4
Training loss: 1.725722074508667
Validation loss: 2.0458738803863525

Epoch: 6| Step: 5
Training loss: 1.7797715663909912
Validation loss: 2.034055789311727

Epoch: 6| Step: 6
Training loss: 2.866206169128418
Validation loss: 2.0611295898755393

Epoch: 6| Step: 7
Training loss: 1.27744722366333
Validation loss: 2.038865307966868

Epoch: 6| Step: 8
Training loss: 2.2816851139068604
Validation loss: 2.042817314465841

Epoch: 6| Step: 9
Training loss: 1.9554295539855957
Validation loss: 2.027371605237325

Epoch: 6| Step: 10
Training loss: 1.6606322526931763
Validation loss: 2.0214802821477256

Epoch: 6| Step: 11
Training loss: 1.365271806716919
Validation loss: 2.0389190117518106

Epoch: 6| Step: 12
Training loss: 1.7937175035476685
Validation loss: 1.994851569334666

Epoch: 6| Step: 13
Training loss: 2.4043397903442383
Validation loss: 2.0294692317644754

Epoch: 46| Step: 0
Training loss: 2.0590224266052246
Validation loss: 2.0137080748875937

Epoch: 6| Step: 1
Training loss: 2.201190948486328
Validation loss: 2.01204506556193

Epoch: 6| Step: 2
Training loss: 1.9800912141799927
Validation loss: 1.9997488260269165

Epoch: 6| Step: 3
Training loss: 1.4789183139801025
Validation loss: 2.01761128505071

Epoch: 6| Step: 4
Training loss: 1.5763859748840332
Validation loss: 2.017527222633362

Epoch: 6| Step: 5
Training loss: 2.0896360874176025
Validation loss: 2.025693436463674

Epoch: 6| Step: 6
Training loss: 2.09721040725708
Validation loss: 2.0016841292381287

Epoch: 6| Step: 7
Training loss: 2.012350559234619
Validation loss: 2.0250877141952515

Epoch: 6| Step: 8
Training loss: 1.672666072845459
Validation loss: 2.001802444458008

Epoch: 6| Step: 9
Training loss: 1.5454988479614258
Validation loss: 2.0196379820505777

Epoch: 6| Step: 10
Training loss: 1.7270721197128296
Validation loss: 2.024294078350067

Epoch: 6| Step: 11
Training loss: 2.516770601272583
Validation loss: 2.024941305319468

Epoch: 6| Step: 12
Training loss: 2.0879201889038086
Validation loss: 2.0431321064631143

Epoch: 6| Step: 13
Training loss: 1.94120192527771
Validation loss: 2.0142435828844705

Epoch: 47| Step: 0
Training loss: 2.3713715076446533
Validation loss: 2.022539794445038

Epoch: 6| Step: 1
Training loss: 1.885936975479126
Validation loss: 2.022592763106028

Epoch: 6| Step: 2
Training loss: 1.822751760482788
Validation loss: 2.0130990743637085

Epoch: 6| Step: 3
Training loss: 1.8995559215545654
Validation loss: 1.979437033335368

Epoch: 6| Step: 4
Training loss: 2.410707950592041
Validation loss: 1.9976183573404949

Epoch: 6| Step: 5
Training loss: 1.4136090278625488
Validation loss: 1.9836789568265278

Epoch: 6| Step: 6
Training loss: 1.9042375087738037
Validation loss: 2.0146528482437134

Epoch: 6| Step: 7
Training loss: 1.810754418373108
Validation loss: 2.0253140131632485

Epoch: 6| Step: 8
Training loss: 1.7102344036102295
Validation loss: 2.0171850124994912

Epoch: 6| Step: 9
Training loss: 1.8762115240097046
Validation loss: 2.00058646996816

Epoch: 6| Step: 10
Training loss: 1.7393654584884644
Validation loss: 2.0483758250872293

Epoch: 6| Step: 11
Training loss: 1.4096695184707642
Validation loss: 1.9998026092847188

Epoch: 6| Step: 12
Training loss: 2.011503219604492
Validation loss: 2.043036182721456

Epoch: 6| Step: 13
Training loss: 2.1312527656555176
Validation loss: 2.0238166650136313

Epoch: 48| Step: 0
Training loss: 1.7053390741348267
Validation loss: 2.0110947291056314

Epoch: 6| Step: 1
Training loss: 1.552831768989563
Validation loss: 2.0058746933937073

Epoch: 6| Step: 2
Training loss: 1.9432613849639893
Validation loss: 2.0169025659561157

Epoch: 6| Step: 3
Training loss: 2.120434284210205
Validation loss: 2.022947291533152

Epoch: 6| Step: 4
Training loss: 2.041849136352539
Validation loss: 2.006372253100077

Epoch: 6| Step: 5
Training loss: 1.3326566219329834
Validation loss: 2.006143629550934

Epoch: 6| Step: 6
Training loss: 1.9848580360412598
Validation loss: 1.996652086575826

Epoch: 6| Step: 7
Training loss: 2.1900837421417236
Validation loss: 2.0127906600634256

Epoch: 6| Step: 8
Training loss: 2.151043176651001
Validation loss: 2.04178249835968

Epoch: 6| Step: 9
Training loss: 2.6913037300109863
Validation loss: 1.998958150545756

Epoch: 6| Step: 10
Training loss: 2.2230300903320312
Validation loss: 2.0401888887087503

Epoch: 6| Step: 11
Training loss: 1.8744151592254639
Validation loss: 1.9952637354532878

Epoch: 6| Step: 12
Training loss: 1.3351677656173706
Validation loss: 2.019819994767507

Epoch: 6| Step: 13
Training loss: 1.5625946521759033
Validation loss: 2.051536242167155

Epoch: 49| Step: 0
Training loss: 2.2632813453674316
Validation loss: 2.0072354276974997

Epoch: 6| Step: 1
Training loss: 1.8173332214355469
Validation loss: 2.03289924065272

Epoch: 6| Step: 2
Training loss: 1.7363457679748535
Validation loss: 2.046541134516398

Epoch: 6| Step: 3
Training loss: 2.6160061359405518
Validation loss: 2.0069809556007385

Epoch: 6| Step: 4
Training loss: 1.4101462364196777
Validation loss: 2.014772415161133

Epoch: 6| Step: 5
Training loss: 1.7660422325134277
Validation loss: 2.024040162563324

Epoch: 6| Step: 6
Training loss: 2.4423913955688477
Validation loss: 2.046230355898539

Epoch: 6| Step: 7
Training loss: 1.2739078998565674
Validation loss: 2.017982304096222

Epoch: 6| Step: 8
Training loss: 1.9897581338882446
Validation loss: 2.0542734066645303

Epoch: 6| Step: 9
Training loss: 1.946859359741211
Validation loss: 2.0247652530670166

Epoch: 6| Step: 10
Training loss: 2.1621885299682617
Validation loss: 2.008223374684652

Epoch: 6| Step: 11
Training loss: 1.8261168003082275
Validation loss: 2.0385440786679587

Epoch: 6| Step: 12
Training loss: 1.2146425247192383
Validation loss: 1.9797396858533223

Epoch: 6| Step: 13
Training loss: 2.178260564804077
Validation loss: 1.9811437726020813

Epoch: 50| Step: 0
Training loss: 1.7632005214691162
Validation loss: 2.0350303053855896

Epoch: 6| Step: 1
Training loss: 2.657686471939087
Validation loss: 2.00589382648468

Epoch: 6| Step: 2
Training loss: 1.5510849952697754
Validation loss: 2.014177660147349

Epoch: 6| Step: 3
Training loss: 1.8928589820861816
Validation loss: 2.045991579691569

Epoch: 6| Step: 4
Training loss: 1.6927226781845093
Validation loss: 2.0098619858423867

Epoch: 6| Step: 5
Training loss: 2.312417984008789
Validation loss: 2.032053073247274

Epoch: 6| Step: 6
Training loss: 2.01802921295166
Validation loss: 2.0145605405171714

Epoch: 6| Step: 7
Training loss: 1.5610874891281128
Validation loss: 2.0139399568239846

Epoch: 6| Step: 8
Training loss: 1.3326059579849243
Validation loss: 2.0019263426462808

Epoch: 6| Step: 9
Training loss: 1.9985686540603638
Validation loss: 2.003624419371287

Epoch: 6| Step: 10
Training loss: 2.245253324508667
Validation loss: 2.0311461885770163

Epoch: 6| Step: 11
Training loss: 1.806816577911377
Validation loss: 1.9779906074206035

Epoch: 6| Step: 12
Training loss: 1.6095352172851562
Validation loss: 2.049683431784312

Epoch: 6| Step: 13
Training loss: 2.132443428039551
Validation loss: 2.017100671927134

Testing loss: 1.806020772714409
