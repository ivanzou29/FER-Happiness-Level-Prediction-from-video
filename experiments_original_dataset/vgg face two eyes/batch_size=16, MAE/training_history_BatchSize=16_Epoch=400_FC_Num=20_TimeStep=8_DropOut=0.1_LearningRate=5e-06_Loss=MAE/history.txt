Epoch: 1| Step: 0
Training loss: 4.837273597717285
Validation loss: 4.114183147748311

Epoch: 6| Step: 1
Training loss: 4.139718532562256
Validation loss: 4.085454821586609

Epoch: 6| Step: 2
Training loss: 3.8620107173919678
Validation loss: 4.05747636159261

Epoch: 6| Step: 3
Training loss: 3.95634126663208
Validation loss: 4.031081994374593

Epoch: 6| Step: 4
Training loss: 4.321258544921875
Validation loss: 4.004938801129659

Epoch: 6| Step: 5
Training loss: 3.3925704956054688
Validation loss: 3.978819489479065

Epoch: 6| Step: 6
Training loss: 4.7520551681518555
Validation loss: 3.9541794459025064

Epoch: 6| Step: 7
Training loss: 4.030901908874512
Validation loss: 3.926668643951416

Epoch: 6| Step: 8
Training loss: 4.217625141143799
Validation loss: 3.902767221132914

Epoch: 6| Step: 9
Training loss: 4.3157782554626465
Validation loss: 3.8761574824651084

Epoch: 6| Step: 10
Training loss: 4.289286136627197
Validation loss: 3.8459454774856567

Epoch: 6| Step: 11
Training loss: 3.8101460933685303
Validation loss: 3.8199880123138428

Epoch: 6| Step: 12
Training loss: 3.166311025619507
Validation loss: 3.7942179441452026

Epoch: 6| Step: 13
Training loss: 4.205649375915527
Validation loss: 3.7688153982162476

Epoch: 2| Step: 0
Training loss: 4.040831565856934
Validation loss: 3.741392175356547

Epoch: 6| Step: 1
Training loss: 2.7776451110839844
Validation loss: 3.7130720218022666

Epoch: 6| Step: 2
Training loss: 3.565999984741211
Validation loss: 3.6807154019673667

Epoch: 6| Step: 3
Training loss: 3.3430047035217285
Validation loss: 3.652246276537577

Epoch: 6| Step: 4
Training loss: 3.541886329650879
Validation loss: 3.6247231562932334

Epoch: 6| Step: 5
Training loss: 3.7260406017303467
Validation loss: 3.5912389755249023

Epoch: 6| Step: 6
Training loss: 4.436850070953369
Validation loss: 3.560585141181946

Epoch: 6| Step: 7
Training loss: 4.055380821228027
Validation loss: 3.5299218893051147

Epoch: 6| Step: 8
Training loss: 3.2062525749206543
Validation loss: 3.4956761995951333

Epoch: 6| Step: 9
Training loss: 3.898186206817627
Validation loss: 3.460755546887716

Epoch: 6| Step: 10
Training loss: 4.357888698577881
Validation loss: 3.4224851528803506

Epoch: 6| Step: 11
Training loss: 3.1380467414855957
Validation loss: 3.382081389427185

Epoch: 6| Step: 12
Training loss: 3.091750383377075
Validation loss: 3.3403495947519937

Epoch: 6| Step: 13
Training loss: 4.245079040527344
Validation loss: 3.298082192738851

Epoch: 3| Step: 0
Training loss: 2.922740936279297
Validation loss: 3.2627986669540405

Epoch: 6| Step: 1
Training loss: 3.244302988052368
Validation loss: 3.2197428146998086

Epoch: 6| Step: 2
Training loss: 3.354898452758789
Validation loss: 3.1747825543085733

Epoch: 6| Step: 3
Training loss: 3.599717140197754
Validation loss: 3.13247541586558

Epoch: 6| Step: 4
Training loss: 3.210197925567627
Validation loss: 3.084113041559855

Epoch: 6| Step: 5
Training loss: 3.2798657417297363
Validation loss: 3.034070293108622

Epoch: 6| Step: 6
Training loss: 3.4364190101623535
Validation loss: 2.9795012871424356

Epoch: 6| Step: 7
Training loss: 3.5031826496124268
Validation loss: 2.9251538117726645

Epoch: 6| Step: 8
Training loss: 2.9978175163269043
Validation loss: 2.8789227406183877

Epoch: 6| Step: 9
Training loss: 2.6872501373291016
Validation loss: 2.8259915113449097

Epoch: 6| Step: 10
Training loss: 3.077970504760742
Validation loss: 2.7715648412704468

Epoch: 6| Step: 11
Training loss: 2.7777538299560547
Validation loss: 2.7139235138893127

Epoch: 6| Step: 12
Training loss: 2.7903733253479004
Validation loss: 2.653602719306946

Epoch: 6| Step: 13
Training loss: 2.485856056213379
Validation loss: 2.596479594707489

Epoch: 4| Step: 0
Training loss: 2.0294978618621826
Validation loss: 2.52878475189209

Epoch: 6| Step: 1
Training loss: 3.162241220474243
Validation loss: 2.4810736576716104

Epoch: 6| Step: 2
Training loss: 2.7951955795288086
Validation loss: 2.416653315226237

Epoch: 6| Step: 3
Training loss: 2.445829391479492
Validation loss: 2.3433174093564353

Epoch: 6| Step: 4
Training loss: 2.525376558303833
Validation loss: 2.2873734633127847

Epoch: 6| Step: 5
Training loss: 2.352447032928467
Validation loss: 2.2246288061141968

Epoch: 6| Step: 6
Training loss: 2.207512617111206
Validation loss: 2.1658435662587485

Epoch: 6| Step: 7
Training loss: 2.2395362854003906
Validation loss: 2.1211381753285727

Epoch: 6| Step: 8
Training loss: 2.5942189693450928
Validation loss: 2.06428595383962

Epoch: 6| Step: 9
Training loss: 1.7987703084945679
Validation loss: 2.048548857371012

Epoch: 6| Step: 10
Training loss: 2.1158485412597656
Validation loss: 2.0156701803207397

Epoch: 6| Step: 11
Training loss: 1.7112276554107666
Validation loss: 2.0098616083463035

Epoch: 6| Step: 12
Training loss: 2.338383197784424
Validation loss: 1.9805848002433777

Epoch: 6| Step: 13
Training loss: 2.322835922241211
Validation loss: 1.974957565466563

Epoch: 5| Step: 0
Training loss: 2.433896541595459
Validation loss: 1.986413876215617

Epoch: 6| Step: 1
Training loss: 1.7238255739212036
Validation loss: 1.9705400069554646

Epoch: 6| Step: 2
Training loss: 1.9711863994598389
Validation loss: 1.9903444449106853

Epoch: 6| Step: 3
Training loss: 1.79115629196167
Validation loss: 1.979413201411565

Epoch: 6| Step: 4
Training loss: 2.108283519744873
Validation loss: 1.9953559637069702

Epoch: 6| Step: 5
Training loss: 2.433136224746704
Validation loss: 1.9915940165519714

Epoch: 6| Step: 6
Training loss: 2.7808568477630615
Validation loss: 1.9835251371065776

Epoch: 6| Step: 7
Training loss: 2.517651319503784
Validation loss: 1.9977580308914185

Epoch: 6| Step: 8
Training loss: 1.8553520441055298
Validation loss: 1.9848603010177612

Epoch: 6| Step: 9
Training loss: 2.1283414363861084
Validation loss: 1.997750957806905

Epoch: 6| Step: 10
Training loss: 2.013875961303711
Validation loss: 1.9977056384086609

Epoch: 6| Step: 11
Training loss: 1.7085822820663452
Validation loss: 1.9832887649536133

Epoch: 6| Step: 12
Training loss: 1.9567334651947021
Validation loss: 1.9676989515622456

Epoch: 6| Step: 13
Training loss: 1.932516098022461
Validation loss: 1.9760874112447102

Epoch: 6| Step: 0
Training loss: 2.3445935249328613
Validation loss: 1.9737924734751384

Epoch: 6| Step: 1
Training loss: 1.8706138134002686
Validation loss: 1.9534027973810832

Epoch: 6| Step: 2
Training loss: 2.532970905303955
Validation loss: 1.9768743515014648

Epoch: 6| Step: 3
Training loss: 2.227595806121826
Validation loss: 1.9863999883333843

Epoch: 6| Step: 4
Training loss: 1.9523158073425293
Validation loss: 1.9764031767845154

Epoch: 6| Step: 5
Training loss: 2.5767242908477783
Validation loss: 1.989806334177653

Epoch: 6| Step: 6
Training loss: 1.5716663599014282
Validation loss: 1.972111165523529

Epoch: 6| Step: 7
Training loss: 2.1694576740264893
Validation loss: 1.980697472890218

Epoch: 6| Step: 8
Training loss: 1.9748520851135254
Validation loss: 1.9927672743797302

Epoch: 6| Step: 9
Training loss: 2.0815048217773438
Validation loss: 1.9768781065940857

Epoch: 6| Step: 10
Training loss: 1.7783222198486328
Validation loss: 1.9864717721939087

Epoch: 6| Step: 11
Training loss: 1.696120262145996
Validation loss: 1.9808990160624187

Epoch: 6| Step: 12
Training loss: 2.266392230987549
Validation loss: 1.9745614528656006

Epoch: 6| Step: 13
Training loss: 2.2392311096191406
Validation loss: 1.9699116746584575

Epoch: 7| Step: 0
Training loss: 1.619415283203125
Validation loss: 1.9829994837443035

Epoch: 6| Step: 1
Training loss: 1.639531135559082
Validation loss: 1.9763596852620442

Epoch: 6| Step: 2
Training loss: 2.234950542449951
Validation loss: 1.9634983539581299

Epoch: 6| Step: 3
Training loss: 2.447862386703491
Validation loss: 1.9778044025103252

Epoch: 6| Step: 4
Training loss: 1.8378450870513916
Validation loss: 1.9863563179969788

Epoch: 6| Step: 5
Training loss: 2.3275399208068848
Validation loss: 1.9935864210128784

Epoch: 6| Step: 6
Training loss: 1.7395777702331543
Validation loss: 1.9875895778338115

Epoch: 6| Step: 7
Training loss: 2.085923194885254
Validation loss: 1.9747960766156514

Epoch: 6| Step: 8
Training loss: 2.611548900604248
Validation loss: 1.971040964126587

Epoch: 6| Step: 9
Training loss: 1.668179988861084
Validation loss: 1.9810155431429546

Epoch: 6| Step: 10
Training loss: 2.214841842651367
Validation loss: 1.9691308538119

Epoch: 6| Step: 11
Training loss: 1.7087570428848267
Validation loss: 1.963744084040324

Epoch: 6| Step: 12
Training loss: 2.0144922733306885
Validation loss: 1.9807650446891785

Epoch: 6| Step: 13
Training loss: 2.92454195022583
Validation loss: 1.9527145226796467

Epoch: 8| Step: 0
Training loss: 2.051809787750244
Validation loss: 1.9731145699818928

Epoch: 6| Step: 1
Training loss: 2.4382479190826416
Validation loss: 1.966667354106903

Epoch: 6| Step: 2
Training loss: 2.3581109046936035
Validation loss: 1.961613933245341

Epoch: 6| Step: 3
Training loss: 2.3456943035125732
Validation loss: 1.959942877292633

Epoch: 6| Step: 4
Training loss: 2.2882611751556396
Validation loss: 1.9572381178538005

Epoch: 6| Step: 5
Training loss: 2.5413637161254883
Validation loss: 1.969119906425476

Epoch: 6| Step: 6
Training loss: 2.1460113525390625
Validation loss: 1.9619728922843933

Epoch: 6| Step: 7
Training loss: 1.5123379230499268
Validation loss: 1.9628598093986511

Epoch: 6| Step: 8
Training loss: 1.8685340881347656
Validation loss: 1.964453140894572

Epoch: 6| Step: 9
Training loss: 1.5789494514465332
Validation loss: 1.9687025149663289

Epoch: 6| Step: 10
Training loss: 1.481777548789978
Validation loss: 1.962420105934143

Epoch: 6| Step: 11
Training loss: 1.9791922569274902
Validation loss: 1.9629052480061848

Epoch: 6| Step: 12
Training loss: 1.5772004127502441
Validation loss: 1.9590004285176594

Epoch: 6| Step: 13
Training loss: 2.6210901737213135
Validation loss: 1.9568843642870586

Epoch: 9| Step: 0
Training loss: 1.9661668539047241
Validation loss: 1.9642778237660725

Epoch: 6| Step: 1
Training loss: 2.2328174114227295
Validation loss: 1.9555403391520183

Epoch: 6| Step: 2
Training loss: 2.4692673683166504
Validation loss: 1.963065008322398

Epoch: 6| Step: 3
Training loss: 1.821305751800537
Validation loss: 1.962601939837138

Epoch: 6| Step: 4
Training loss: 2.1137032508850098
Validation loss: 1.9610140721003215

Epoch: 6| Step: 5
Training loss: 1.6150634288787842
Validation loss: 1.973265012105306

Epoch: 6| Step: 6
Training loss: 2.0436763763427734
Validation loss: 1.9872833291689556

Epoch: 6| Step: 7
Training loss: 1.8512303829193115
Validation loss: 1.9772743980089824

Epoch: 6| Step: 8
Training loss: 1.9907703399658203
Validation loss: 1.9879088997840881

Epoch: 6| Step: 9
Training loss: 2.5279502868652344
Validation loss: 1.9911682804425557

Epoch: 6| Step: 10
Training loss: 2.1641311645507812
Validation loss: 2.0159692764282227

Epoch: 6| Step: 11
Training loss: 1.858386516571045
Validation loss: 2.0069421529769897

Epoch: 6| Step: 12
Training loss: 2.4403932094573975
Validation loss: 2.005912641684214

Epoch: 6| Step: 13
Training loss: 1.689202070236206
Validation loss: 1.982988138993581

Epoch: 10| Step: 0
Training loss: 1.7460713386535645
Validation loss: 1.9934860070546467

Epoch: 6| Step: 1
Training loss: 2.2443971633911133
Validation loss: 1.9768176078796387

Epoch: 6| Step: 2
Training loss: 2.7394328117370605
Validation loss: 1.9736133217811584

Epoch: 6| Step: 3
Training loss: 2.115186929702759
Validation loss: 1.9669257005055745

Epoch: 6| Step: 4
Training loss: 1.691375732421875
Validation loss: 1.9600298404693604

Epoch: 6| Step: 5
Training loss: 2.608370304107666
Validation loss: 1.9558457533518474

Epoch: 6| Step: 6
Training loss: 1.4216099977493286
Validation loss: 1.9542281031608582

Epoch: 6| Step: 7
Training loss: 2.2529616355895996
Validation loss: 1.9607956608136494

Epoch: 6| Step: 8
Training loss: 1.9067635536193848
Validation loss: 1.9630559881528218

Epoch: 6| Step: 9
Training loss: 2.3388898372650146
Validation loss: 1.9522295991579692

Epoch: 6| Step: 10
Training loss: 1.7646329402923584
Validation loss: 1.9527468085289001

Epoch: 6| Step: 11
Training loss: 2.307159900665283
Validation loss: 1.963117281595866

Epoch: 6| Step: 12
Training loss: 1.811611533164978
Validation loss: 1.963675578435262

Epoch: 6| Step: 13
Training loss: 1.627530813217163
Validation loss: 1.9537392656008403

Epoch: 11| Step: 0
Training loss: 1.313281774520874
Validation loss: 1.961634635925293

Epoch: 6| Step: 1
Training loss: 1.801830530166626
Validation loss: 1.9564659198125203

Epoch: 6| Step: 2
Training loss: 1.9705662727355957
Validation loss: 1.9549013177553813

Epoch: 6| Step: 3
Training loss: 2.03201961517334
Validation loss: 1.9566276868184407

Epoch: 6| Step: 4
Training loss: 1.7450281381607056
Validation loss: 1.9487685958544414

Epoch: 6| Step: 5
Training loss: 2.6851351261138916
Validation loss: 1.9510387182235718

Epoch: 6| Step: 6
Training loss: 2.2057101726531982
Validation loss: 1.9540218313535054

Epoch: 6| Step: 7
Training loss: 2.203045606613159
Validation loss: 1.9704623023668926

Epoch: 6| Step: 8
Training loss: 1.9354851245880127
Validation loss: 1.9726563493410747

Epoch: 6| Step: 9
Training loss: 1.6829547882080078
Validation loss: 1.960829774538676

Epoch: 6| Step: 10
Training loss: 2.073183059692383
Validation loss: 1.9709309935569763

Epoch: 6| Step: 11
Training loss: 2.721566677093506
Validation loss: 1.9781091213226318

Epoch: 6| Step: 12
Training loss: 2.221349000930786
Validation loss: 1.9437069296836853

Epoch: 6| Step: 13
Training loss: 2.0460643768310547
Validation loss: 1.9511691729227703

Epoch: 12| Step: 0
Training loss: 2.067420482635498
Validation loss: 1.944932798544566

Epoch: 6| Step: 1
Training loss: 2.7601466178894043
Validation loss: 1.9578592379887898

Epoch: 6| Step: 2
Training loss: 2.262439012527466
Validation loss: 1.9547734260559082

Epoch: 6| Step: 3
Training loss: 2.0160715579986572
Validation loss: 1.9660665194193523

Epoch: 6| Step: 4
Training loss: 1.8986468315124512
Validation loss: 1.953236977259318

Epoch: 6| Step: 5
Training loss: 1.866391897201538
Validation loss: 1.957046091556549

Epoch: 6| Step: 6
Training loss: 2.775623321533203
Validation loss: 1.9657107591629028

Epoch: 6| Step: 7
Training loss: 2.3943285942077637
Validation loss: 1.9481917023658752

Epoch: 6| Step: 8
Training loss: 2.021007776260376
Validation loss: 1.9632937908172607

Epoch: 6| Step: 9
Training loss: 1.7912468910217285
Validation loss: 1.9558452765146892

Epoch: 6| Step: 10
Training loss: 1.6633894443511963
Validation loss: 1.9458493789037068

Epoch: 6| Step: 11
Training loss: 1.2454097270965576
Validation loss: 1.9554727872212727

Epoch: 6| Step: 12
Training loss: 1.602644920349121
Validation loss: 1.9542800982793171

Epoch: 6| Step: 13
Training loss: 1.9314441680908203
Validation loss: 1.9483987887700398

Epoch: 13| Step: 0
Training loss: 2.526576042175293
Validation loss: 1.9487690329551697

Epoch: 6| Step: 1
Training loss: 2.3814194202423096
Validation loss: 1.9448799689610798

Epoch: 6| Step: 2
Training loss: 1.9903697967529297
Validation loss: 1.9700547655423482

Epoch: 6| Step: 3
Training loss: 1.391200065612793
Validation loss: 1.9603533546129863

Epoch: 6| Step: 4
Training loss: 1.8776363134384155
Validation loss: 1.9459261099497478

Epoch: 6| Step: 5
Training loss: 2.430105447769165
Validation loss: 1.9483871658643086

Epoch: 6| Step: 6
Training loss: 2.3173556327819824
Validation loss: 1.9441900253295898

Epoch: 6| Step: 7
Training loss: 1.2785382270812988
Validation loss: 1.9477498730023701

Epoch: 6| Step: 8
Training loss: 1.4362308979034424
Validation loss: 1.9447206060091655

Epoch: 6| Step: 9
Training loss: 2.0453426837921143
Validation loss: 1.9401570955912273

Epoch: 6| Step: 10
Training loss: 1.862602710723877
Validation loss: 1.9506968259811401

Epoch: 6| Step: 11
Training loss: 2.463304281234741
Validation loss: 1.9494880040486653

Epoch: 6| Step: 12
Training loss: 2.317215919494629
Validation loss: 1.9621225595474243

Epoch: 6| Step: 13
Training loss: 1.8856892585754395
Validation loss: 1.954010804494222

Epoch: 14| Step: 0
Training loss: 2.6803951263427734
Validation loss: 1.9599286715189617

Epoch: 6| Step: 1
Training loss: 1.6205723285675049
Validation loss: 1.9511166612307231

Epoch: 6| Step: 2
Training loss: 2.316389322280884
Validation loss: 1.9442471663157146

Epoch: 6| Step: 3
Training loss: 1.844818353652954
Validation loss: 1.9602240522702534

Epoch: 6| Step: 4
Training loss: 2.1596100330352783
Validation loss: 1.95404448111852

Epoch: 6| Step: 5
Training loss: 2.2726149559020996
Validation loss: 1.9499468803405762

Epoch: 6| Step: 6
Training loss: 1.261159896850586
Validation loss: 1.9582115014394124

Epoch: 6| Step: 7
Training loss: 1.7306050062179565
Validation loss: 1.9484538833300273

Epoch: 6| Step: 8
Training loss: 1.7236156463623047
Validation loss: 1.9497428735097249

Epoch: 6| Step: 9
Training loss: 2.384885549545288
Validation loss: 1.9389564990997314

Epoch: 6| Step: 10
Training loss: 1.7884498834609985
Validation loss: 1.9390084346135457

Epoch: 6| Step: 11
Training loss: 1.664121150970459
Validation loss: 1.9496033191680908

Epoch: 6| Step: 12
Training loss: 2.171103000640869
Validation loss: 1.9378823041915894

Epoch: 6| Step: 13
Training loss: 2.5532102584838867
Validation loss: 1.9443670908610027

Epoch: 15| Step: 0
Training loss: 2.0951170921325684
Validation loss: 1.9530097842216492

Epoch: 6| Step: 1
Training loss: 2.399336576461792
Validation loss: 1.9474951227506

Epoch: 6| Step: 2
Training loss: 1.8726239204406738
Validation loss: 1.9560607075691223

Epoch: 6| Step: 3
Training loss: 1.8240325450897217
Validation loss: 1.9478518962860107

Epoch: 6| Step: 4
Training loss: 1.7951242923736572
Validation loss: 1.9372191727161407

Epoch: 6| Step: 5
Training loss: 1.7958567142486572
Validation loss: 1.9384565552075703

Epoch: 6| Step: 6
Training loss: 2.4900131225585938
Validation loss: 1.953270395596822

Epoch: 6| Step: 7
Training loss: 2.102809429168701
Validation loss: 1.935112218062083

Epoch: 6| Step: 8
Training loss: 2.1906633377075195
Validation loss: 1.9340443015098572

Epoch: 6| Step: 9
Training loss: 2.287137746810913
Validation loss: 1.9492135246594746

Epoch: 6| Step: 10
Training loss: 2.0491013526916504
Validation loss: 1.9382595419883728

Epoch: 6| Step: 11
Training loss: 1.6968821287155151
Validation loss: 1.9544417063395183

Epoch: 6| Step: 12
Training loss: 1.9864566326141357
Validation loss: 1.9438155889511108

Epoch: 6| Step: 13
Training loss: 1.3689059019088745
Validation loss: 1.9433430631955464

Epoch: 16| Step: 0
Training loss: 1.727304220199585
Validation loss: 1.9626840353012085

Epoch: 6| Step: 1
Training loss: 1.8461196422576904
Validation loss: 1.9683791597684224

Epoch: 6| Step: 2
Training loss: 2.13572096824646
Validation loss: 1.967406193415324

Epoch: 6| Step: 3
Training loss: 1.5900211334228516
Validation loss: 1.966266353925069

Epoch: 6| Step: 4
Training loss: 1.6486552953720093
Validation loss: 1.9550288915634155

Epoch: 6| Step: 5
Training loss: 2.2476449012756348
Validation loss: 1.9592281977335613

Epoch: 6| Step: 6
Training loss: 2.321524143218994
Validation loss: 1.9703730543454487

Epoch: 6| Step: 7
Training loss: 2.0845627784729004
Validation loss: 1.9676019946734111

Epoch: 6| Step: 8
Training loss: 2.999708652496338
Validation loss: 1.965592861175537

Epoch: 6| Step: 9
Training loss: 1.5792608261108398
Validation loss: 1.959999442100525

Epoch: 6| Step: 10
Training loss: 1.9880495071411133
Validation loss: 1.9689686099688213

Epoch: 6| Step: 11
Training loss: 2.1114625930786133
Validation loss: 1.9430213570594788

Epoch: 6| Step: 12
Training loss: 1.929605484008789
Validation loss: 1.9518333872159321

Epoch: 6| Step: 13
Training loss: 1.8601045608520508
Validation loss: 1.9486571153004963

Epoch: 17| Step: 0
Training loss: 2.293720245361328
Validation loss: 1.9481837153434753

Epoch: 6| Step: 1
Training loss: 2.6223862171173096
Validation loss: 1.958145280679067

Epoch: 6| Step: 2
Training loss: 1.9579241275787354
Validation loss: 1.9612714846928914

Epoch: 6| Step: 3
Training loss: 1.8813340663909912
Validation loss: 1.9368658463160198

Epoch: 6| Step: 4
Training loss: 1.9264802932739258
Validation loss: 1.9527862668037415

Epoch: 6| Step: 5
Training loss: 2.0747053623199463
Validation loss: 1.9605453610420227

Epoch: 6| Step: 6
Training loss: 1.7073731422424316
Validation loss: 1.9714088241259258

Epoch: 6| Step: 7
Training loss: 1.9052077531814575
Validation loss: 1.970238447189331

Epoch: 6| Step: 8
Training loss: 2.380391836166382
Validation loss: 1.958713134129842

Epoch: 6| Step: 9
Training loss: 2.2707128524780273
Validation loss: 1.964041809240977

Epoch: 6| Step: 10
Training loss: 1.8983204364776611
Validation loss: 1.9694464604059856

Epoch: 6| Step: 11
Training loss: 1.9664809703826904
Validation loss: 1.9587143460909526

Epoch: 6| Step: 12
Training loss: 1.5674219131469727
Validation loss: 1.9609075983365376

Epoch: 6| Step: 13
Training loss: 2.0562903881073
Validation loss: 1.9404152234395344

Epoch: 18| Step: 0
Training loss: 2.10628080368042
Validation loss: 1.941857119401296

Epoch: 6| Step: 1
Training loss: 2.687074899673462
Validation loss: 1.948081115881602

Epoch: 6| Step: 2
Training loss: 1.073875069618225
Validation loss: 1.936351736386617

Epoch: 6| Step: 3
Training loss: 1.0430599451065063
Validation loss: 1.9332497119903564

Epoch: 6| Step: 4
Training loss: 2.298854351043701
Validation loss: 1.9588840802510579

Epoch: 6| Step: 5
Training loss: 2.761117935180664
Validation loss: 1.9629055460294087

Epoch: 6| Step: 6
Training loss: 2.709557056427002
Validation loss: 1.9545371135075886

Epoch: 6| Step: 7
Training loss: 1.391831874847412
Validation loss: 1.9623743693033855

Epoch: 6| Step: 8
Training loss: 2.3577890396118164
Validation loss: 1.9557254910469055

Epoch: 6| Step: 9
Training loss: 1.382759690284729
Validation loss: 1.935770312945048

Epoch: 6| Step: 10
Training loss: 2.8211896419525146
Validation loss: 1.949688156445821

Epoch: 6| Step: 11
Training loss: 1.9105193614959717
Validation loss: 1.954514741897583

Epoch: 6| Step: 12
Training loss: 1.1123313903808594
Validation loss: 1.9644067883491516

Epoch: 6| Step: 13
Training loss: 2.205911636352539
Validation loss: 1.9446796576182048

Epoch: 19| Step: 0
Training loss: 1.7761435508728027
Validation loss: 1.9385877847671509

Epoch: 6| Step: 1
Training loss: 1.8024502992630005
Validation loss: 1.9455854694048564

Epoch: 6| Step: 2
Training loss: 1.9381986856460571
Validation loss: 1.9389888842900593

Epoch: 6| Step: 3
Training loss: 1.7450203895568848
Validation loss: 1.9540186723073323

Epoch: 6| Step: 4
Training loss: 2.238816976547241
Validation loss: 1.9374564290046692

Epoch: 6| Step: 5
Training loss: 1.8092777729034424
Validation loss: 1.9349667032559712

Epoch: 6| Step: 6
Training loss: 1.441031575202942
Validation loss: 1.9671212832132976

Epoch: 6| Step: 7
Training loss: 2.220493793487549
Validation loss: 1.9656471212704976

Epoch: 6| Step: 8
Training loss: 1.6084277629852295
Validation loss: 1.9531097014745076

Epoch: 6| Step: 9
Training loss: 2.3118069171905518
Validation loss: 1.9654253323872883

Epoch: 6| Step: 10
Training loss: 2.3270814418792725
Validation loss: 1.953225553035736

Epoch: 6| Step: 11
Training loss: 2.2957136631011963
Validation loss: 1.9404490788777669

Epoch: 6| Step: 12
Training loss: 2.4335999488830566
Validation loss: 1.9318896134694417

Epoch: 6| Step: 13
Training loss: 1.7400829792022705
Validation loss: 1.9423361817995708

Epoch: 20| Step: 0
Training loss: 2.176393508911133
Validation loss: 1.9395371079444885

Epoch: 6| Step: 1
Training loss: 2.3102941513061523
Validation loss: 1.9457072416941326

Epoch: 6| Step: 2
Training loss: 2.045405387878418
Validation loss: 1.9518407980600994

Epoch: 6| Step: 3
Training loss: 1.6147165298461914
Validation loss: 1.9491634368896484

Epoch: 6| Step: 4
Training loss: 2.033884286880493
Validation loss: 1.9500654141108196

Epoch: 6| Step: 5
Training loss: 1.9125583171844482
Validation loss: 1.9359799027442932

Epoch: 6| Step: 6
Training loss: 2.060914993286133
Validation loss: 1.9421467383702595

Epoch: 6| Step: 7
Training loss: 1.5686308145523071
Validation loss: 1.937870939572652

Epoch: 6| Step: 8
Training loss: 2.2508978843688965
Validation loss: 1.9496900240580242

Epoch: 6| Step: 9
Training loss: 2.278735637664795
Validation loss: 1.943670630455017

Epoch: 6| Step: 10
Training loss: 1.8600267171859741
Validation loss: 1.9271480639775593

Epoch: 6| Step: 11
Training loss: 2.1518678665161133
Validation loss: 1.941344956556956

Epoch: 6| Step: 12
Training loss: 2.0502376556396484
Validation loss: 1.9464495380719502

Epoch: 6| Step: 13
Training loss: 1.6258952617645264
Validation loss: 1.9284647901852925

Epoch: 21| Step: 0
Training loss: 2.401005744934082
Validation loss: 1.9490233063697815

Epoch: 6| Step: 1
Training loss: 2.557101249694824
Validation loss: 1.959300955136617

Epoch: 6| Step: 2
Training loss: 1.576676607131958
Validation loss: 1.949207882086436

Epoch: 6| Step: 3
Training loss: 1.683179497718811
Validation loss: 1.951891799767812

Epoch: 6| Step: 4
Training loss: 2.2649612426757812
Validation loss: 1.9511309464772542

Epoch: 6| Step: 5
Training loss: 1.7015198469161987
Validation loss: 1.9478453199068706

Epoch: 6| Step: 6
Training loss: 2.276768207550049
Validation loss: 1.932307501633962

Epoch: 6| Step: 7
Training loss: 2.123579978942871
Validation loss: 1.9426854848861694

Epoch: 6| Step: 8
Training loss: 2.167405366897583
Validation loss: 1.946082313855489

Epoch: 6| Step: 9
Training loss: 1.9900102615356445
Validation loss: 1.9416855573654175

Epoch: 6| Step: 10
Training loss: 1.8214247226715088
Validation loss: 1.9441985885302226

Epoch: 6| Step: 11
Training loss: 1.5198408365249634
Validation loss: 1.9373967448870342

Epoch: 6| Step: 12
Training loss: 1.7192740440368652
Validation loss: 1.9528204401334126

Epoch: 6| Step: 13
Training loss: 1.8932288885116577
Validation loss: 1.9364084601402283

Epoch: 22| Step: 0
Training loss: 2.7076938152313232
Validation loss: 1.9500320156415303

Epoch: 6| Step: 1
Training loss: 1.7031055688858032
Validation loss: 1.942947785059611

Epoch: 6| Step: 2
Training loss: 1.9083194732666016
Validation loss: 1.9494370420773823

Epoch: 6| Step: 3
Training loss: 1.7998013496398926
Validation loss: 1.9696545998255413

Epoch: 6| Step: 4
Training loss: 1.9751019477844238
Validation loss: 1.9609510898590088

Epoch: 6| Step: 5
Training loss: 2.221648693084717
Validation loss: 1.9581498106320698

Epoch: 6| Step: 6
Training loss: 1.9663093090057373
Validation loss: 1.9457401633262634

Epoch: 6| Step: 7
Training loss: 2.172649383544922
Validation loss: 1.9484542806943257

Epoch: 6| Step: 8
Training loss: 1.5936166048049927
Validation loss: 1.94474196434021

Epoch: 6| Step: 9
Training loss: 2.0526514053344727
Validation loss: 1.9412699341773987

Epoch: 6| Step: 10
Training loss: 1.2083935737609863
Validation loss: 1.9261022011439006

Epoch: 6| Step: 11
Training loss: 1.9937772750854492
Validation loss: 1.9410930077234905

Epoch: 6| Step: 12
Training loss: 2.3455991744995117
Validation loss: 1.9496901631355286

Epoch: 6| Step: 13
Training loss: 2.0794079303741455
Validation loss: 1.9422080119450886

Epoch: 23| Step: 0
Training loss: 1.9585182666778564
Validation loss: 1.9382919271787007

Epoch: 6| Step: 1
Training loss: 1.4957435131072998
Validation loss: 1.939224123954773

Epoch: 6| Step: 2
Training loss: 2.711091995239258
Validation loss: 1.9326876004536946

Epoch: 6| Step: 3
Training loss: 2.3636422157287598
Validation loss: 1.95477561155955

Epoch: 6| Step: 4
Training loss: 1.7575311660766602
Validation loss: 1.9453633427619934

Epoch: 6| Step: 5
Training loss: 2.0744481086730957
Validation loss: 1.9464245041211445

Epoch: 6| Step: 6
Training loss: 1.6448369026184082
Validation loss: 1.934076229731242

Epoch: 6| Step: 7
Training loss: 1.9559441804885864
Validation loss: 1.944579839706421

Epoch: 6| Step: 8
Training loss: 2.108076810836792
Validation loss: 1.9379188815752666

Epoch: 6| Step: 9
Training loss: 1.6810375452041626
Validation loss: 1.9430271188418071

Epoch: 6| Step: 10
Training loss: 1.7329336404800415
Validation loss: 1.92402587334315

Epoch: 6| Step: 11
Training loss: 1.9712905883789062
Validation loss: 1.960643192132314

Epoch: 6| Step: 12
Training loss: 1.9503958225250244
Validation loss: 1.9358023206392925

Epoch: 6| Step: 13
Training loss: 2.0525763034820557
Validation loss: 1.9428384900093079

Epoch: 24| Step: 0
Training loss: 2.2579610347747803
Validation loss: 1.9552473028500874

Epoch: 6| Step: 1
Training loss: 2.8547401428222656
Validation loss: 1.938137690226237

Epoch: 6| Step: 2
Training loss: 1.799075722694397
Validation loss: 1.9462292393048604

Epoch: 6| Step: 3
Training loss: 1.8081780672073364
Validation loss: 1.9470054109891255

Epoch: 6| Step: 4
Training loss: 1.7252870798110962
Validation loss: 1.956969439983368

Epoch: 6| Step: 5
Training loss: 1.9042212963104248
Validation loss: 1.9625064134597778

Epoch: 6| Step: 6
Training loss: 2.0876193046569824
Validation loss: 1.941441814104716

Epoch: 6| Step: 7
Training loss: 1.6341588497161865
Validation loss: 1.95426744222641

Epoch: 6| Step: 8
Training loss: 2.319533348083496
Validation loss: 1.9592175881067913

Epoch: 6| Step: 9
Training loss: 1.6896833181381226
Validation loss: 1.950716455777486

Epoch: 6| Step: 10
Training loss: 1.970901608467102
Validation loss: 1.9274473587671916

Epoch: 6| Step: 11
Training loss: 1.335205078125
Validation loss: 1.9584918816884358

Epoch: 6| Step: 12
Training loss: 1.4754905700683594
Validation loss: 1.9420003096262615

Epoch: 6| Step: 13
Training loss: 2.5577969551086426
Validation loss: 1.9300932884216309

Epoch: 25| Step: 0
Training loss: 1.6794850826263428
Validation loss: 1.942019522190094

Epoch: 6| Step: 1
Training loss: 2.2922229766845703
Validation loss: 1.944563368956248

Epoch: 6| Step: 2
Training loss: 2.252756118774414
Validation loss: 1.9360182881355286

Epoch: 6| Step: 3
Training loss: 1.3209714889526367
Validation loss: 1.9409558176994324

Epoch: 6| Step: 4
Training loss: 1.7742435932159424
Validation loss: 1.9451744159062703

Epoch: 6| Step: 5
Training loss: 2.2802734375
Validation loss: 1.9396173357963562

Epoch: 6| Step: 6
Training loss: 2.23748517036438
Validation loss: 1.93860920270284

Epoch: 6| Step: 7
Training loss: 2.2103769779205322
Validation loss: 1.9356357057889302

Epoch: 6| Step: 8
Training loss: 2.3413279056549072
Validation loss: 1.9451905687650044

Epoch: 6| Step: 9
Training loss: 1.2810431718826294
Validation loss: 1.9556648135185242

Epoch: 6| Step: 10
Training loss: 2.5271759033203125
Validation loss: 1.9334576924641926

Epoch: 6| Step: 11
Training loss: 2.233722686767578
Validation loss: 1.9425510168075562

Epoch: 6| Step: 12
Training loss: 1.3892111778259277
Validation loss: 1.9338995615641277

Epoch: 6| Step: 13
Training loss: 1.6970099210739136
Validation loss: 1.9318838119506836

Epoch: 26| Step: 0
Training loss: 2.5016279220581055
Validation loss: 1.9365376631418865

Epoch: 6| Step: 1
Training loss: 2.1127543449401855
Validation loss: 1.9329403241475422

Epoch: 6| Step: 2
Training loss: 2.072810649871826
Validation loss: 1.934964160124461

Epoch: 6| Step: 3
Training loss: 1.9273338317871094
Validation loss: 1.933171570301056

Epoch: 6| Step: 4
Training loss: 1.8561522960662842
Validation loss: 1.9374592900276184

Epoch: 6| Step: 5
Training loss: 1.9835710525512695
Validation loss: 1.9382207989692688

Epoch: 6| Step: 6
Training loss: 2.020772933959961
Validation loss: 1.9466665387153625

Epoch: 6| Step: 7
Training loss: 1.913620114326477
Validation loss: 1.9512758056322734

Epoch: 6| Step: 8
Training loss: 1.3449554443359375
Validation loss: 1.9518511494000752

Epoch: 6| Step: 9
Training loss: 2.277034282684326
Validation loss: 1.9769645134607952

Epoch: 6| Step: 10
Training loss: 1.5426712036132812
Validation loss: 1.9722378849983215

Epoch: 6| Step: 11
Training loss: 1.7842576503753662
Validation loss: 1.988814075787862

Epoch: 6| Step: 12
Training loss: 2.0620617866516113
Validation loss: 1.978218913078308

Epoch: 6| Step: 13
Training loss: 2.092245101928711
Validation loss: 1.9824509620666504

Epoch: 27| Step: 0
Training loss: 2.444154739379883
Validation loss: 1.9625487128893535

Epoch: 6| Step: 1
Training loss: 1.8338227272033691
Validation loss: 1.971876323223114

Epoch: 6| Step: 2
Training loss: 1.9502967596054077
Validation loss: 1.9585902094841003

Epoch: 6| Step: 3
Training loss: 2.2327113151550293
Validation loss: 1.9435208439826965

Epoch: 6| Step: 4
Training loss: 1.67746102809906
Validation loss: 1.9628460705280304

Epoch: 6| Step: 5
Training loss: 2.3449931144714355
Validation loss: 1.9440782864888508

Epoch: 6| Step: 6
Training loss: 1.621927261352539
Validation loss: 1.947175145149231

Epoch: 6| Step: 7
Training loss: 1.6813445091247559
Validation loss: 1.9378382166226704

Epoch: 6| Step: 8
Training loss: 2.199324369430542
Validation loss: 1.921175440152486

Epoch: 6| Step: 9
Training loss: 1.230950117111206
Validation loss: 1.9254229068756104

Epoch: 6| Step: 10
Training loss: 1.7773802280426025
Validation loss: 1.9519285162289937

Epoch: 6| Step: 11
Training loss: 1.958500623703003
Validation loss: 1.9417127966880798

Epoch: 6| Step: 12
Training loss: 2.2713894844055176
Validation loss: 1.9340324799219768

Epoch: 6| Step: 13
Training loss: 1.927304744720459
Validation loss: 1.9289286931355794

Epoch: 28| Step: 0
Training loss: 2.563326835632324
Validation loss: 1.9363558491071065

Epoch: 6| Step: 1
Training loss: 1.8685277700424194
Validation loss: 1.9284712274869282

Epoch: 6| Step: 2
Training loss: 2.1885406970977783
Validation loss: 1.9270878434181213

Epoch: 6| Step: 3
Training loss: 1.822892189025879
Validation loss: 1.9324274063110352

Epoch: 6| Step: 4
Training loss: 1.2067503929138184
Validation loss: 1.9294569691022236

Epoch: 6| Step: 5
Training loss: 2.2347488403320312
Validation loss: 1.933679203192393

Epoch: 6| Step: 6
Training loss: 1.4891706705093384
Validation loss: 1.9308303395907085

Epoch: 6| Step: 7
Training loss: 1.6688889265060425
Validation loss: 1.9353095889091492

Epoch: 6| Step: 8
Training loss: 2.008396863937378
Validation loss: 1.9361270666122437

Epoch: 6| Step: 9
Training loss: 1.9908366203308105
Validation loss: 1.9335280855496724

Epoch: 6| Step: 10
Training loss: 2.4851670265197754
Validation loss: 1.9382395346959431

Epoch: 6| Step: 11
Training loss: 1.8107552528381348
Validation loss: 1.9282570282618205

Epoch: 6| Step: 12
Training loss: 2.214130401611328
Validation loss: 1.955465038617452

Epoch: 6| Step: 13
Training loss: 1.7389461994171143
Validation loss: 1.9314647912979126

Epoch: 29| Step: 0
Training loss: 1.9614410400390625
Validation loss: 1.9576174815495808

Epoch: 6| Step: 1
Training loss: 1.7663698196411133
Validation loss: 1.9511972467104595

Epoch: 6| Step: 2
Training loss: 2.126380443572998
Validation loss: 1.9747387369473774

Epoch: 6| Step: 3
Training loss: 1.7794032096862793
Validation loss: 1.973616937796275

Epoch: 6| Step: 4
Training loss: 1.7887580394744873
Validation loss: 1.9865641196568806

Epoch: 6| Step: 5
Training loss: 2.333477258682251
Validation loss: 1.992256263891856

Epoch: 6| Step: 6
Training loss: 2.3202333450317383
Validation loss: 1.986966888109843

Epoch: 6| Step: 7
Training loss: 1.740407943725586
Validation loss: 1.9654998779296875

Epoch: 6| Step: 8
Training loss: 2.0091631412506104
Validation loss: 1.9626598954200745

Epoch: 6| Step: 9
Training loss: 1.8958439826965332
Validation loss: 1.9355989495913188

Epoch: 6| Step: 10
Training loss: 2.064453601837158
Validation loss: 1.9277726610501607

Epoch: 6| Step: 11
Training loss: 1.6789721250534058
Validation loss: 1.9305229981740315

Epoch: 6| Step: 12
Training loss: 2.2522850036621094
Validation loss: 1.936619718869527

Epoch: 6| Step: 13
Training loss: 1.9061188697814941
Validation loss: 1.9279594421386719

Epoch: 30| Step: 0
Training loss: 2.1182961463928223
Validation loss: 1.9208183884620667

Epoch: 6| Step: 1
Training loss: 2.1936349868774414
Validation loss: 1.9405708114306133

Epoch: 6| Step: 2
Training loss: 1.7672853469848633
Validation loss: 1.9449560046195984

Epoch: 6| Step: 3
Training loss: 1.822849988937378
Validation loss: 1.9408823649088542

Epoch: 6| Step: 4
Training loss: 1.6436554193496704
Validation loss: 1.9287359317143757

Epoch: 6| Step: 5
Training loss: 2.3816986083984375
Validation loss: 1.924131413300832

Epoch: 6| Step: 6
Training loss: 1.5311212539672852
Validation loss: 1.9403854012489319

Epoch: 6| Step: 7
Training loss: 2.171380043029785
Validation loss: 1.9375030199686687

Epoch: 6| Step: 8
Training loss: 2.1028687953948975
Validation loss: 1.9333106478055317

Epoch: 6| Step: 9
Training loss: 2.1401097774505615
Validation loss: 1.9357791145642598

Epoch: 6| Step: 10
Training loss: 1.7155230045318604
Validation loss: 1.9324749112129211

Epoch: 6| Step: 11
Training loss: 1.9376839399337769
Validation loss: 1.9370190699895222

Epoch: 6| Step: 12
Training loss: 1.4900732040405273
Validation loss: 1.9260476728280385

Epoch: 6| Step: 13
Training loss: 2.6244583129882812
Validation loss: 1.937624414761861

Epoch: 31| Step: 0
Training loss: 1.748892068862915
Validation loss: 1.9266852537790935

Epoch: 6| Step: 1
Training loss: 2.2396979331970215
Validation loss: 1.92838450272878

Epoch: 6| Step: 2
Training loss: 2.2501659393310547
Validation loss: 1.9445358713467915

Epoch: 6| Step: 3
Training loss: 2.1362972259521484
Validation loss: 1.937913179397583

Epoch: 6| Step: 4
Training loss: 1.818620204925537
Validation loss: 1.9454384843508403

Epoch: 6| Step: 5
Training loss: 2.3218305110931396
Validation loss: 1.940547247727712

Epoch: 6| Step: 6
Training loss: 2.305448055267334
Validation loss: 1.9274378617604573

Epoch: 6| Step: 7
Training loss: 1.9952654838562012
Validation loss: 1.935308317343394

Epoch: 6| Step: 8
Training loss: 1.5658257007598877
Validation loss: 1.9387457370758057

Epoch: 6| Step: 9
Training loss: 1.8807352781295776
Validation loss: 1.9257529377937317

Epoch: 6| Step: 10
Training loss: 1.7026418447494507
Validation loss: 1.9250192244847615

Epoch: 6| Step: 11
Training loss: 1.763906717300415
Validation loss: 1.9463527003924053

Epoch: 6| Step: 12
Training loss: 1.8432729244232178
Validation loss: 1.9376010298728943

Epoch: 6| Step: 13
Training loss: 1.685494303703308
Validation loss: 1.9343276421229045

Epoch: 32| Step: 0
Training loss: 1.5705816745758057
Validation loss: 1.9559288422266643

Epoch: 6| Step: 1
Training loss: 2.052489757537842
Validation loss: 1.9468462268511455

Epoch: 6| Step: 2
Training loss: 1.648106575012207
Validation loss: 1.9533902804056804

Epoch: 6| Step: 3
Training loss: 1.792586088180542
Validation loss: 1.9627692302068074

Epoch: 6| Step: 4
Training loss: 2.261436939239502
Validation loss: 1.9717502395311992

Epoch: 6| Step: 5
Training loss: 1.6550800800323486
Validation loss: 1.960888942082723

Epoch: 6| Step: 6
Training loss: 1.4047935009002686
Validation loss: 1.9570263425509136

Epoch: 6| Step: 7
Training loss: 1.7361836433410645
Validation loss: 1.9350127975145976

Epoch: 6| Step: 8
Training loss: 2.404186725616455
Validation loss: 1.954869012037913

Epoch: 6| Step: 9
Training loss: 1.4525668621063232
Validation loss: 1.9442936380704243

Epoch: 6| Step: 10
Training loss: 2.096273422241211
Validation loss: 1.9500011801719666

Epoch: 6| Step: 11
Training loss: 2.5504612922668457
Validation loss: 1.924656371275584

Epoch: 6| Step: 12
Training loss: 2.1552391052246094
Validation loss: 1.9278584122657776

Epoch: 6| Step: 13
Training loss: 2.3543691635131836
Validation loss: 1.924740493297577

Epoch: 33| Step: 0
Training loss: 2.4735872745513916
Validation loss: 1.9260850350062053

Epoch: 6| Step: 1
Training loss: 2.855076313018799
Validation loss: 1.9133573571840923

Epoch: 6| Step: 2
Training loss: 1.9027299880981445
Validation loss: 1.9375533262888591

Epoch: 6| Step: 3
Training loss: 1.6816164255142212
Validation loss: 1.9295384486516316

Epoch: 6| Step: 4
Training loss: 1.5555403232574463
Validation loss: 1.943803648153941

Epoch: 6| Step: 5
Training loss: 2.066866636276245
Validation loss: 1.9189061323801677

Epoch: 6| Step: 6
Training loss: 2.3265788555145264
Validation loss: 1.9188047846158345

Epoch: 6| Step: 7
Training loss: 1.7148545980453491
Validation loss: 1.9311888416608174

Epoch: 6| Step: 8
Training loss: 1.366843819618225
Validation loss: 1.928419570128123

Epoch: 6| Step: 9
Training loss: 2.176003932952881
Validation loss: 1.9173677166302998

Epoch: 6| Step: 10
Training loss: 1.731231927871704
Validation loss: 1.9260759751001995

Epoch: 6| Step: 11
Training loss: 1.4912991523742676
Validation loss: 1.910957892735799

Epoch: 6| Step: 12
Training loss: 2.086872100830078
Validation loss: 1.922106146812439

Epoch: 6| Step: 13
Training loss: 1.811265230178833
Validation loss: 1.9279165863990784

Epoch: 34| Step: 0
Training loss: 2.4866929054260254
Validation loss: 1.9511134227116902

Epoch: 6| Step: 1
Training loss: 1.6079713106155396
Validation loss: 1.9650604327519734

Epoch: 6| Step: 2
Training loss: 1.9169172048568726
Validation loss: 1.9497471849123638

Epoch: 6| Step: 3
Training loss: 1.5122193098068237
Validation loss: 1.9715290069580078

Epoch: 6| Step: 4
Training loss: 1.431811809539795
Validation loss: 1.9804229935010274

Epoch: 6| Step: 5
Training loss: 1.6605863571166992
Validation loss: 1.9566832780838013

Epoch: 6| Step: 6
Training loss: 2.131442070007324
Validation loss: 1.960510790348053

Epoch: 6| Step: 7
Training loss: 2.169874668121338
Validation loss: 1.950730840365092

Epoch: 6| Step: 8
Training loss: 2.501893997192383
Validation loss: 1.9259159564971924

Epoch: 6| Step: 9
Training loss: 1.8431217670440674
Validation loss: 1.9371421138445537

Epoch: 6| Step: 10
Training loss: 1.825809121131897
Validation loss: 1.950760026772817

Epoch: 6| Step: 11
Training loss: 1.5932633876800537
Validation loss: 1.9417820970217388

Epoch: 6| Step: 12
Training loss: 1.9210195541381836
Validation loss: 1.9392767151196797

Epoch: 6| Step: 13
Training loss: 2.4875171184539795
Validation loss: 1.9221914410591125

Epoch: 35| Step: 0
Training loss: 2.2718076705932617
Validation loss: 1.927393873532613

Epoch: 6| Step: 1
Training loss: 2.209366798400879
Validation loss: 1.932492693265279

Epoch: 6| Step: 2
Training loss: 1.6687471866607666
Validation loss: 1.9219450950622559

Epoch: 6| Step: 3
Training loss: 2.1351797580718994
Validation loss: 1.9287266532580059

Epoch: 6| Step: 4
Training loss: 1.5451067686080933
Validation loss: 1.929347078005473

Epoch: 6| Step: 5
Training loss: 2.393723964691162
Validation loss: 1.9270187218983967

Epoch: 6| Step: 6
Training loss: 1.5629560947418213
Validation loss: 1.9314102530479431

Epoch: 6| Step: 7
Training loss: 2.0801312923431396
Validation loss: 1.9306817054748535

Epoch: 6| Step: 8
Training loss: 1.7373082637786865
Validation loss: 1.9386772116025288

Epoch: 6| Step: 9
Training loss: 2.146273612976074
Validation loss: 1.9279730916023254

Epoch: 6| Step: 10
Training loss: 2.3232715129852295
Validation loss: 1.919526716073354

Epoch: 6| Step: 11
Training loss: 1.57692551612854
Validation loss: 1.9312319159507751

Epoch: 6| Step: 12
Training loss: 1.9689005613327026
Validation loss: 1.9362117250760396

Epoch: 6| Step: 13
Training loss: 1.717264175415039
Validation loss: 1.9172075390815735

Epoch: 36| Step: 0
Training loss: 2.252849578857422
Validation loss: 1.92049773534139

Epoch: 6| Step: 1
Training loss: 2.19714093208313
Validation loss: 1.9383984406789143

Epoch: 6| Step: 2
Training loss: 1.8421869277954102
Validation loss: 1.935979386170705

Epoch: 6| Step: 3
Training loss: 1.9125123023986816
Validation loss: 1.922670344511668

Epoch: 6| Step: 4
Training loss: 1.5351753234863281
Validation loss: 1.9534990390141804

Epoch: 6| Step: 5
Training loss: 1.94380784034729
Validation loss: 1.949706455071767

Epoch: 6| Step: 6
Training loss: 1.4824650287628174
Validation loss: 1.9518235524495442

Epoch: 6| Step: 7
Training loss: 2.6784958839416504
Validation loss: 1.9773945212364197

Epoch: 6| Step: 8
Training loss: 2.5352797508239746
Validation loss: 1.979383409023285

Epoch: 6| Step: 9
Training loss: 1.7272589206695557
Validation loss: 1.9784277081489563

Epoch: 6| Step: 10
Training loss: 1.630021333694458
Validation loss: 1.977867881457011

Epoch: 6| Step: 11
Training loss: 1.6163737773895264
Validation loss: 1.9842540621757507

Epoch: 6| Step: 12
Training loss: 1.714460849761963
Validation loss: 1.9693485498428345

Epoch: 6| Step: 13
Training loss: 1.873073935508728
Validation loss: 1.9588265021642048

Epoch: 37| Step: 0
Training loss: 1.8552334308624268
Validation loss: 1.9352820714314778

Epoch: 6| Step: 1
Training loss: 2.4278576374053955
Validation loss: 1.9304785529772441

Epoch: 6| Step: 2
Training loss: 1.5824987888336182
Validation loss: 1.9288917382558186

Epoch: 6| Step: 3
Training loss: 2.1043481826782227
Validation loss: 1.9317636092503865

Epoch: 6| Step: 4
Training loss: 1.3701777458190918
Validation loss: 1.921726663907369

Epoch: 6| Step: 5
Training loss: 1.9831960201263428
Validation loss: 1.9245623350143433

Epoch: 6| Step: 6
Training loss: 1.75544011592865
Validation loss: 1.9472223321596782

Epoch: 6| Step: 7
Training loss: 2.599240303039551
Validation loss: 1.9316455523173015

Epoch: 6| Step: 8
Training loss: 2.5153937339782715
Validation loss: 1.9288059671719868

Epoch: 6| Step: 9
Training loss: 1.5307021141052246
Validation loss: 1.9206501642862956

Epoch: 6| Step: 10
Training loss: 1.7583502531051636
Validation loss: 1.9347471992174785

Epoch: 6| Step: 11
Training loss: 1.722098469734192
Validation loss: 1.9278359413146973

Epoch: 6| Step: 12
Training loss: 2.234525203704834
Validation loss: 1.9320638577143352

Epoch: 6| Step: 13
Training loss: 1.5634294748306274
Validation loss: 1.9316739837328594

Epoch: 38| Step: 0
Training loss: 1.6044327020645142
Validation loss: 1.935003658135732

Epoch: 6| Step: 1
Training loss: 1.8075177669525146
Validation loss: 1.9366747935612996

Epoch: 6| Step: 2
Training loss: 2.096766471862793
Validation loss: 1.92549467086792

Epoch: 6| Step: 3
Training loss: 1.8414276838302612
Validation loss: 1.9366576472918193

Epoch: 6| Step: 4
Training loss: 1.6441092491149902
Validation loss: 1.9299047986666362

Epoch: 6| Step: 5
Training loss: 1.5214660167694092
Validation loss: 1.9418432513872783

Epoch: 6| Step: 6
Training loss: 1.8060302734375
Validation loss: 1.924252212047577

Epoch: 6| Step: 7
Training loss: 1.8067936897277832
Validation loss: 1.93329918384552

Epoch: 6| Step: 8
Training loss: 1.987735629081726
Validation loss: 1.940376341342926

Epoch: 6| Step: 9
Training loss: 2.072059392929077
Validation loss: 1.9428752859433491

Epoch: 6| Step: 10
Training loss: 1.8752937316894531
Validation loss: 1.9356470704078674

Epoch: 6| Step: 11
Training loss: 3.035557270050049
Validation loss: 1.9339082638422649

Epoch: 6| Step: 12
Training loss: 1.6743513345718384
Validation loss: 1.9243468443552654

Epoch: 6| Step: 13
Training loss: 2.099726915359497
Validation loss: 1.9384618202845256

Epoch: 39| Step: 0
Training loss: 1.4427320957183838
Validation loss: 1.9326198895772297

Epoch: 6| Step: 1
Training loss: 2.0733375549316406
Validation loss: 1.9457775155703227

Epoch: 6| Step: 2
Training loss: 1.6759381294250488
Validation loss: 1.9222721656163533

Epoch: 6| Step: 3
Training loss: 1.4975459575653076
Validation loss: 1.9514836072921753

Epoch: 6| Step: 4
Training loss: 2.4110400676727295
Validation loss: 1.9368933240572612

Epoch: 6| Step: 5
Training loss: 1.9301786422729492
Validation loss: 1.943423291047414

Epoch: 6| Step: 6
Training loss: 1.8273881673812866
Validation loss: 1.9322802821795146

Epoch: 6| Step: 7
Training loss: 1.9235435724258423
Validation loss: 1.9448412855466206

Epoch: 6| Step: 8
Training loss: 1.6612542867660522
Validation loss: 1.921941061814626

Epoch: 6| Step: 9
Training loss: 2.1588640213012695
Validation loss: 1.9173155228296916

Epoch: 6| Step: 10
Training loss: 1.783473253250122
Validation loss: 1.9216317733128865

Epoch: 6| Step: 11
Training loss: 1.9517793655395508
Validation loss: 1.9170056382815044

Epoch: 6| Step: 12
Training loss: 2.461225986480713
Validation loss: 1.9157456556955974

Epoch: 6| Step: 13
Training loss: 1.7902393341064453
Validation loss: 1.908762792746226

Epoch: 40| Step: 0
Training loss: 1.8991203308105469
Validation loss: 1.9338340560595195

Epoch: 6| Step: 1
Training loss: 2.102757453918457
Validation loss: 1.928252100944519

Epoch: 6| Step: 2
Training loss: 1.719834804534912
Validation loss: 1.9189949830373128

Epoch: 6| Step: 3
Training loss: 2.5301876068115234
Validation loss: 1.9358573357264202

Epoch: 6| Step: 4
Training loss: 1.5814979076385498
Validation loss: 1.9244707425435383

Epoch: 6| Step: 5
Training loss: 2.2922308444976807
Validation loss: 1.935537338256836

Epoch: 6| Step: 6
Training loss: 1.4643610715866089
Validation loss: 1.9407938122749329

Epoch: 6| Step: 7
Training loss: 1.3507628440856934
Validation loss: 1.9581544995307922

Epoch: 6| Step: 8
Training loss: 1.6000839471817017
Validation loss: 1.954256534576416

Epoch: 6| Step: 9
Training loss: 2.7067172527313232
Validation loss: 1.94553009668986

Epoch: 6| Step: 10
Training loss: 2.1899805068969727
Validation loss: 1.9362333218256633

Epoch: 6| Step: 11
Training loss: 1.5677664279937744
Validation loss: 1.9412850538889568

Epoch: 6| Step: 12
Training loss: 1.5775859355926514
Validation loss: 1.9431355396906536

Epoch: 6| Step: 13
Training loss: 2.18743896484375
Validation loss: 1.9364168445269268

Epoch: 41| Step: 0
Training loss: 1.7003042697906494
Validation loss: 1.914187729358673

Epoch: 6| Step: 1
Training loss: 2.2187540531158447
Validation loss: 1.9245392481486003

Epoch: 6| Step: 2
Training loss: 1.863803744316101
Validation loss: 1.9222766160964966

Epoch: 6| Step: 3
Training loss: 2.187985420227051
Validation loss: 1.9298845529556274

Epoch: 6| Step: 4
Training loss: 2.207388401031494
Validation loss: 1.9201856851577759

Epoch: 6| Step: 5
Training loss: 2.517127513885498
Validation loss: 1.9388875563939412

Epoch: 6| Step: 6
Training loss: 1.419093132019043
Validation loss: 1.9316912492116292

Epoch: 6| Step: 7
Training loss: 1.5907115936279297
Validation loss: 1.9347116152445476

Epoch: 6| Step: 8
Training loss: 1.4779855012893677
Validation loss: 1.9442965586980183

Epoch: 6| Step: 9
Training loss: 2.1172268390655518
Validation loss: 1.9429848790168762

Epoch: 6| Step: 10
Training loss: 1.9150158166885376
Validation loss: 1.934818148612976

Epoch: 6| Step: 11
Training loss: 1.7447354793548584
Validation loss: 1.9258564313252766

Epoch: 6| Step: 12
Training loss: 2.1169486045837402
Validation loss: 1.9425727128982544

Epoch: 6| Step: 13
Training loss: 1.6698498725891113
Validation loss: 1.9451744357744853

Epoch: 42| Step: 0
Training loss: 2.096813678741455
Validation loss: 1.9328004916508992

Epoch: 6| Step: 1
Training loss: 1.7644574642181396
Validation loss: 1.9412226676940918

Epoch: 6| Step: 2
Training loss: 1.4041385650634766
Validation loss: 1.9266016085942586

Epoch: 6| Step: 3
Training loss: 1.391202688217163
Validation loss: 1.931490182876587

Epoch: 6| Step: 4
Training loss: 2.4264094829559326
Validation loss: 1.9255638519922893

Epoch: 6| Step: 5
Training loss: 1.715430498123169
Validation loss: 1.948866327603658

Epoch: 6| Step: 6
Training loss: 1.8067437410354614
Validation loss: 1.9398299256960552

Epoch: 6| Step: 7
Training loss: 1.8140580654144287
Validation loss: 1.9615079760551453

Epoch: 6| Step: 8
Training loss: 2.378922462463379
Validation loss: 1.956464906533559

Epoch: 6| Step: 9
Training loss: 2.1569151878356934
Validation loss: 1.9497465292612712

Epoch: 6| Step: 10
Training loss: 1.8365859985351562
Validation loss: 1.9278105894724529

Epoch: 6| Step: 11
Training loss: 1.9572114944458008
Validation loss: 1.947875718275706

Epoch: 6| Step: 12
Training loss: 1.7427672147750854
Validation loss: 1.9320460160573323

Epoch: 6| Step: 13
Training loss: 2.1022536754608154
Validation loss: 1.9285821318626404

Epoch: 43| Step: 0
Training loss: 2.347397804260254
Validation loss: 1.9170534412066143

Epoch: 6| Step: 1
Training loss: 1.7450758218765259
Validation loss: 1.930036226908366

Epoch: 6| Step: 2
Training loss: 1.7983310222625732
Validation loss: 1.9123164216677349

Epoch: 6| Step: 3
Training loss: 1.357192873954773
Validation loss: 1.946535547574361

Epoch: 6| Step: 4
Training loss: 2.2006239891052246
Validation loss: 1.9433615803718567

Epoch: 6| Step: 5
Training loss: 1.7555019855499268
Validation loss: 1.9542625546455383

Epoch: 6| Step: 6
Training loss: 1.6501061916351318
Validation loss: 1.9676848252614338

Epoch: 6| Step: 7
Training loss: 2.7448835372924805
Validation loss: 1.957094172636668

Epoch: 6| Step: 8
Training loss: 2.0331239700317383
Validation loss: 1.9550825754801433

Epoch: 6| Step: 9
Training loss: 2.301889419555664
Validation loss: 1.9461991389592488

Epoch: 6| Step: 10
Training loss: 1.584841251373291
Validation loss: 1.9302833477656047

Epoch: 6| Step: 11
Training loss: 1.7059576511383057
Validation loss: 1.9437225262324016

Epoch: 6| Step: 12
Training loss: 1.8477380275726318
Validation loss: 1.9336339433987935

Epoch: 6| Step: 13
Training loss: 1.617088794708252
Validation loss: 1.9269230564435322

Epoch: 44| Step: 0
Training loss: 1.6526587009429932
Validation loss: 1.9265244404474895

Epoch: 6| Step: 1
Training loss: 2.348088264465332
Validation loss: 1.9201197028160095

Epoch: 6| Step: 2
Training loss: 1.6039936542510986
Validation loss: 1.9159539341926575

Epoch: 6| Step: 3
Training loss: 2.1292083263397217
Validation loss: 1.9145189921061199

Epoch: 6| Step: 4
Training loss: 1.697901725769043
Validation loss: 1.9285422762235005

Epoch: 6| Step: 5
Training loss: 1.2590221166610718
Validation loss: 1.9245151281356812

Epoch: 6| Step: 6
Training loss: 2.199087619781494
Validation loss: 1.922902782758077

Epoch: 6| Step: 7
Training loss: 1.9641690254211426
Validation loss: 1.9321147402127583

Epoch: 6| Step: 8
Training loss: 2.185884714126587
Validation loss: 1.951533357302348

Epoch: 6| Step: 9
Training loss: 1.1990989446640015
Validation loss: 1.9329419334729512

Epoch: 6| Step: 10
Training loss: 2.603559732437134
Validation loss: 1.9617708921432495

Epoch: 6| Step: 11
Training loss: 1.59724760055542
Validation loss: 1.945831557114919

Epoch: 6| Step: 12
Training loss: 1.5911695957183838
Validation loss: 1.9415532946586609

Epoch: 6| Step: 13
Training loss: 2.4424967765808105
Validation loss: 1.928186575571696

Epoch: 45| Step: 0
Training loss: 2.236177921295166
Validation loss: 1.9391844669977825

Epoch: 6| Step: 1
Training loss: 2.376265525817871
Validation loss: 1.935019036134084

Epoch: 6| Step: 2
Training loss: 1.721100926399231
Validation loss: 1.9191935459772747

Epoch: 6| Step: 3
Training loss: 1.9311295747756958
Validation loss: 1.9126448233922322

Epoch: 6| Step: 4
Training loss: 1.3624651432037354
Validation loss: 1.9254759351412456

Epoch: 6| Step: 5
Training loss: 2.3516030311584473
Validation loss: 1.9348937273025513

Epoch: 6| Step: 6
Training loss: 2.2872469425201416
Validation loss: 1.9238865375518799

Epoch: 6| Step: 7
Training loss: 1.9372599124908447
Validation loss: 1.9392330249150593

Epoch: 6| Step: 8
Training loss: 1.65446138381958
Validation loss: 1.928175648053487

Epoch: 6| Step: 9
Training loss: 1.7554543018341064
Validation loss: 1.9413273135821025

Epoch: 6| Step: 10
Training loss: 1.8085997104644775
Validation loss: 1.9374891519546509

Epoch: 6| Step: 11
Training loss: 1.947932481765747
Validation loss: 1.9248955845832825

Epoch: 6| Step: 12
Training loss: 1.428420901298523
Validation loss: 1.9395570357640584

Epoch: 6| Step: 13
Training loss: 1.5246490240097046
Validation loss: 1.9347016016642253

Epoch: 46| Step: 0
Training loss: 1.9217379093170166
Validation loss: 1.9234296282132466

Epoch: 6| Step: 1
Training loss: 2.3719582557678223
Validation loss: 1.955925742785136

Epoch: 6| Step: 2
Training loss: 1.680894374847412
Validation loss: 1.9385883609453838

Epoch: 6| Step: 3
Training loss: 1.7229564189910889
Validation loss: 1.9658300677935283

Epoch: 6| Step: 4
Training loss: 1.9314590692520142
Validation loss: 1.9676631093025208

Epoch: 6| Step: 5
Training loss: 1.6256294250488281
Validation loss: 1.9575501481691997

Epoch: 6| Step: 6
Training loss: 1.7088909149169922
Validation loss: 1.9762508471806843

Epoch: 6| Step: 7
Training loss: 1.533470869064331
Validation loss: 1.9502912163734436

Epoch: 6| Step: 8
Training loss: 2.5734479427337646
Validation loss: 1.9516919453938801

Epoch: 6| Step: 9
Training loss: 1.3730816841125488
Validation loss: 1.9460724393526714

Epoch: 6| Step: 10
Training loss: 1.8351969718933105
Validation loss: 1.9379951159159343

Epoch: 6| Step: 11
Training loss: 2.5377955436706543
Validation loss: 1.9466285904248555

Epoch: 6| Step: 12
Training loss: 2.026918411254883
Validation loss: 1.9479421178499858

Epoch: 6| Step: 13
Training loss: 1.3595616817474365
Validation loss: 1.8985183437665303

Epoch: 47| Step: 0
Training loss: 2.058232069015503
Validation loss: 1.9280079205830891

Epoch: 6| Step: 1
Training loss: 2.0560367107391357
Validation loss: 1.9201433857282002

Epoch: 6| Step: 2
Training loss: 1.2774240970611572
Validation loss: 1.9210839470227559

Epoch: 6| Step: 3
Training loss: 1.6420525312423706
Validation loss: 1.9261638124783833

Epoch: 6| Step: 4
Training loss: 1.3461954593658447
Validation loss: 1.936478892962138

Epoch: 6| Step: 5
Training loss: 2.5419256687164307
Validation loss: 1.931286613146464

Epoch: 6| Step: 6
Training loss: 1.9039074182510376
Validation loss: 1.9406209985415142

Epoch: 6| Step: 7
Training loss: 1.975306749343872
Validation loss: 1.94451900323232

Epoch: 6| Step: 8
Training loss: 2.3411941528320312
Validation loss: 1.958692153294881

Epoch: 6| Step: 9
Training loss: 2.0073959827423096
Validation loss: 1.9485873778661091

Epoch: 6| Step: 10
Training loss: 2.0497372150421143
Validation loss: 1.9566583236058552

Epoch: 6| Step: 11
Training loss: 2.0290353298187256
Validation loss: 1.935534417629242

Epoch: 6| Step: 12
Training loss: 1.6288443803787231
Validation loss: 1.933071235815684

Epoch: 6| Step: 13
Training loss: 1.276658535003662
Validation loss: 1.952629307905833

Epoch: 48| Step: 0
Training loss: 1.9282147884368896
Validation loss: 1.9488449494043987

Epoch: 6| Step: 1
Training loss: 1.9013231992721558
Validation loss: 1.9193692008654277

Epoch: 6| Step: 2
Training loss: 2.13466477394104
Validation loss: 1.930714229742686

Epoch: 6| Step: 3
Training loss: 1.5188841819763184
Validation loss: 1.9099524021148682

Epoch: 6| Step: 4
Training loss: 1.39536452293396
Validation loss: 1.9387137691179912

Epoch: 6| Step: 5
Training loss: 2.056013345718384
Validation loss: 1.9227627118428547

Epoch: 6| Step: 6
Training loss: 2.479644536972046
Validation loss: 1.9265133142471313

Epoch: 6| Step: 7
Training loss: 1.9111156463623047
Validation loss: 1.9280138611793518

Epoch: 6| Step: 8
Training loss: 1.7916866540908813
Validation loss: 1.9247921705245972

Epoch: 6| Step: 9
Training loss: 2.2151148319244385
Validation loss: 1.9298557043075562

Epoch: 6| Step: 10
Training loss: 1.7330939769744873
Validation loss: 1.9415877262751262

Epoch: 6| Step: 11
Training loss: 1.8996198177337646
Validation loss: 1.9360246260960896

Epoch: 6| Step: 12
Training loss: 1.729064702987671
Validation loss: 1.940800428390503

Epoch: 6| Step: 13
Training loss: 1.8347384929656982
Validation loss: 1.931958278020223

Epoch: 49| Step: 0
Training loss: 1.348476767539978
Validation loss: 1.938953419526418

Epoch: 6| Step: 1
Training loss: 1.8314626216888428
Validation loss: 1.9394623239835103

Epoch: 6| Step: 2
Training loss: 1.9895333051681519
Validation loss: 1.9444564779599507

Epoch: 6| Step: 3
Training loss: 1.5310169458389282
Validation loss: 1.9902762373288472

Epoch: 6| Step: 4
Training loss: 2.8055622577667236
Validation loss: 1.994071125984192

Epoch: 6| Step: 5
Training loss: 2.3631319999694824
Validation loss: 2.0194894274075827

Epoch: 6| Step: 6
Training loss: 2.0133702754974365
Validation loss: 1.9995272954305012

Epoch: 6| Step: 7
Training loss: 1.637901782989502
Validation loss: 2.0024073719978333

Epoch: 6| Step: 8
Training loss: 2.0267889499664307
Validation loss: 2.0049518942832947

Epoch: 6| Step: 9
Training loss: 1.370370864868164
Validation loss: 1.9858680764834087

Epoch: 6| Step: 10
Training loss: 1.859837293624878
Validation loss: 1.9498948852221172

Epoch: 6| Step: 11
Training loss: 1.5437724590301514
Validation loss: 1.9468140800793965

Epoch: 6| Step: 12
Training loss: 2.2656233310699463
Validation loss: 1.939905087153117

Epoch: 6| Step: 13
Training loss: 1.8662240505218506
Validation loss: 1.9242665966351826

Epoch: 50| Step: 0
Training loss: 2.6599879264831543
Validation loss: 1.9234254558881123

Epoch: 6| Step: 1
Training loss: 2.1787261962890625
Validation loss: 1.9216659665107727

Epoch: 6| Step: 2
Training loss: 2.017177104949951
Validation loss: 1.9173492391904194

Epoch: 6| Step: 3
Training loss: 1.8170912265777588
Validation loss: 1.944631536801656

Epoch: 6| Step: 4
Training loss: 1.6474748849868774
Validation loss: 1.9342790444691975

Epoch: 6| Step: 5
Training loss: 2.1720895767211914
Validation loss: 1.9422025481859844

Epoch: 6| Step: 6
Training loss: 1.3508957624435425
Validation loss: 1.9392010569572449

Epoch: 6| Step: 7
Training loss: 1.5739809274673462
Validation loss: 1.9505606293678284

Epoch: 6| Step: 8
Training loss: 1.4959771633148193
Validation loss: 1.9528393348058064

Epoch: 6| Step: 9
Training loss: 2.2941927909851074
Validation loss: 1.9258023500442505

Epoch: 6| Step: 10
Training loss: 1.9170372486114502
Validation loss: 1.9313756426175435

Epoch: 6| Step: 11
Training loss: 1.6606462001800537
Validation loss: 1.911264419555664

Epoch: 6| Step: 12
Training loss: 1.9867744445800781
Validation loss: 1.9069222807884216

Epoch: 6| Step: 13
Training loss: 2.028223991394043
Validation loss: 1.9041261474291484

Epoch: 51| Step: 0
Training loss: 2.0122246742248535
Validation loss: 1.9206674098968506

Epoch: 6| Step: 1
Training loss: 2.271559238433838
Validation loss: 1.9484816392262776

Epoch: 6| Step: 2
Training loss: 1.7731530666351318
Validation loss: 1.994966983795166

Epoch: 6| Step: 3
Training loss: 1.813560962677002
Validation loss: 2.020833214124044

Epoch: 6| Step: 4
Training loss: 2.9224436283111572
Validation loss: 2.044322590033213

Epoch: 6| Step: 5
Training loss: 1.4744453430175781
Validation loss: 2.029175043106079

Epoch: 6| Step: 6
Training loss: 2.111729621887207
Validation loss: 2.011121988296509

Epoch: 6| Step: 7
Training loss: 1.6742898225784302
Validation loss: 1.9908033808072407

Epoch: 6| Step: 8
Training loss: 1.7008904218673706
Validation loss: 1.9763047297795613

Epoch: 6| Step: 9
Training loss: 2.2138288021087646
Validation loss: 1.9445584813753765

Epoch: 6| Step: 10
Training loss: 1.308809757232666
Validation loss: 1.950092852115631

Epoch: 6| Step: 11
Training loss: 1.3191642761230469
Validation loss: 1.9146993557612102

Epoch: 6| Step: 12
Training loss: 1.9741649627685547
Validation loss: 1.9262537161509197

Epoch: 6| Step: 13
Training loss: 2.213972806930542
Validation loss: 1.92665696144104

Epoch: 52| Step: 0
Training loss: 1.7215917110443115
Validation loss: 1.9295972386995952

Epoch: 6| Step: 1
Training loss: 1.7249994277954102
Validation loss: 1.9414624969164531

Epoch: 6| Step: 2
Training loss: 1.4924306869506836
Validation loss: 1.932316541671753

Epoch: 6| Step: 3
Training loss: 1.2931718826293945
Validation loss: 1.9226112167040508

Epoch: 6| Step: 4
Training loss: 2.3132431507110596
Validation loss: 1.9447484612464905

Epoch: 6| Step: 5
Training loss: 1.5180439949035645
Validation loss: 1.927394986152649

Epoch: 6| Step: 6
Training loss: 1.4302245378494263
Validation loss: 1.952371597290039

Epoch: 6| Step: 7
Training loss: 1.6531429290771484
Validation loss: 1.969218413035075

Epoch: 6| Step: 8
Training loss: 2.3507914543151855
Validation loss: 1.971388300259908

Epoch: 6| Step: 9
Training loss: 2.2073183059692383
Validation loss: 1.960944672425588

Epoch: 6| Step: 10
Training loss: 2.482172727584839
Validation loss: 1.9556897282600403

Epoch: 6| Step: 11
Training loss: 1.6624914407730103
Validation loss: 1.972183088461558

Epoch: 6| Step: 12
Training loss: 1.9188072681427002
Validation loss: 1.97317636013031

Epoch: 6| Step: 13
Training loss: 2.0287599563598633
Validation loss: 1.9441543817520142

Epoch: 53| Step: 0
Training loss: 1.7967989444732666
Validation loss: 1.9575905203819275

Epoch: 6| Step: 1
Training loss: 1.6074893474578857
Validation loss: 1.9318869709968567

Epoch: 6| Step: 2
Training loss: 1.3960044384002686
Validation loss: 1.9334354400634766

Epoch: 6| Step: 3
Training loss: 1.7294385433197021
Validation loss: 1.9235007762908936

Epoch: 6| Step: 4
Training loss: 2.127851724624634
Validation loss: 1.9205416043599446

Epoch: 6| Step: 5
Training loss: 2.670403480529785
Validation loss: 1.9167900880177815

Epoch: 6| Step: 6
Training loss: 2.423171043395996
Validation loss: 1.957301139831543

Epoch: 6| Step: 7
Training loss: 1.4546432495117188
Validation loss: 1.937703013420105

Epoch: 6| Step: 8
Training loss: 2.2388532161712646
Validation loss: 1.936537504196167

Epoch: 6| Step: 9
Training loss: 1.4070734977722168
Validation loss: 1.937594433625539

Epoch: 6| Step: 10
Training loss: 2.0659396648406982
Validation loss: 1.9414064288139343

Epoch: 6| Step: 11
Training loss: 2.0162482261657715
Validation loss: 1.9425028363863628

Epoch: 6| Step: 12
Training loss: 1.2139811515808105
Validation loss: 1.96030855178833

Epoch: 6| Step: 13
Training loss: 1.7570557594299316
Validation loss: 1.9913111329078674

Epoch: 54| Step: 0
Training loss: 2.4641480445861816
Validation loss: 1.9761577248573303

Epoch: 6| Step: 1
Training loss: 1.8600280284881592
Validation loss: 1.9571666320164998

Epoch: 6| Step: 2
Training loss: 1.426041603088379
Validation loss: 1.9676781098047893

Epoch: 6| Step: 3
Training loss: 1.5370292663574219
Validation loss: 1.9520062804222107

Epoch: 6| Step: 4
Training loss: 1.3386831283569336
Validation loss: 1.9723506967226665

Epoch: 6| Step: 5
Training loss: 1.914738655090332
Validation loss: 1.9531695246696472

Epoch: 6| Step: 6
Training loss: 1.6895421743392944
Validation loss: 1.939678470293681

Epoch: 6| Step: 7
Training loss: 1.727534532546997
Validation loss: 1.9283732175827026

Epoch: 6| Step: 8
Training loss: 1.6181937456130981
Validation loss: 1.9341697692871094

Epoch: 6| Step: 9
Training loss: 2.544726848602295
Validation loss: 1.9296337564786274

Epoch: 6| Step: 10
Training loss: 1.3879443407058716
Validation loss: 1.9367656509081523

Epoch: 6| Step: 11
Training loss: 2.0279273986816406
Validation loss: 1.9126393795013428

Epoch: 6| Step: 12
Training loss: 2.3300437927246094
Validation loss: 1.9377993543942769

Epoch: 6| Step: 13
Training loss: 1.8743438720703125
Validation loss: 1.9605331023534138

Epoch: 55| Step: 0
Training loss: 2.1507749557495117
Validation loss: 1.9691898822784424

Epoch: 6| Step: 1
Training loss: 1.676344633102417
Validation loss: 1.9621228575706482

Epoch: 6| Step: 2
Training loss: 1.4281851053237915
Validation loss: 1.9636359413464863

Epoch: 6| Step: 3
Training loss: 1.3059394359588623
Validation loss: 1.952467679977417

Epoch: 6| Step: 4
Training loss: 2.3622751235961914
Validation loss: 1.9360977013905842

Epoch: 6| Step: 5
Training loss: 2.113828420639038
Validation loss: 1.9479762315750122

Epoch: 6| Step: 6
Training loss: 1.9166853427886963
Validation loss: 1.9269501368204753

Epoch: 6| Step: 7
Training loss: 1.7922344207763672
Validation loss: 1.9357311328252156

Epoch: 6| Step: 8
Training loss: 1.4972670078277588
Validation loss: 1.9369690616925557

Epoch: 6| Step: 9
Training loss: 1.7895352840423584
Validation loss: 1.9228028655052185

Epoch: 6| Step: 10
Training loss: 1.7919220924377441
Validation loss: 1.9396712183952332

Epoch: 6| Step: 11
Training loss: 1.9948062896728516
Validation loss: 1.9432156085968018

Epoch: 6| Step: 12
Training loss: 1.234693169593811
Validation loss: 1.95400869846344

Epoch: 6| Step: 13
Training loss: 2.8323636054992676
Validation loss: 1.9652385314305623

Epoch: 56| Step: 0
Training loss: 1.4487582445144653
Validation loss: 1.956402599811554

Epoch: 6| Step: 1
Training loss: 1.9506075382232666
Validation loss: 1.955215334892273

Epoch: 6| Step: 2
Training loss: 1.6497063636779785
Validation loss: 1.9598530530929565

Epoch: 6| Step: 3
Training loss: 2.68404483795166
Validation loss: 1.9625744024912517

Epoch: 6| Step: 4
Training loss: 1.961930513381958
Validation loss: 1.9496731162071228

Epoch: 6| Step: 5
Training loss: 1.6145845651626587
Validation loss: 1.9379388093948364

Epoch: 6| Step: 6
Training loss: 1.3642972707748413
Validation loss: 1.9374735355377197

Epoch: 6| Step: 7
Training loss: 1.8892619609832764
Validation loss: 1.936326265335083

Epoch: 6| Step: 8
Training loss: 1.652366280555725
Validation loss: 1.942042887210846

Epoch: 6| Step: 9
Training loss: 1.687412977218628
Validation loss: 1.9347530206044514

Epoch: 6| Step: 10
Training loss: 2.1281967163085938
Validation loss: 1.9400108655293782

Epoch: 6| Step: 11
Training loss: 2.0504860877990723
Validation loss: 1.9461974104245503

Epoch: 6| Step: 12
Training loss: 1.5427114963531494
Validation loss: 1.9358098705609639

Epoch: 6| Step: 13
Training loss: 1.804903507232666
Validation loss: 1.9314468304316204

Epoch: 57| Step: 0
Training loss: 1.545893669128418
Validation loss: 1.9373506704966228

Epoch: 6| Step: 1
Training loss: 1.9714295864105225
Validation loss: 1.9363102515538533

Epoch: 6| Step: 2
Training loss: 2.093153715133667
Validation loss: 1.9431996941566467

Epoch: 6| Step: 3
Training loss: 1.3087661266326904
Validation loss: 1.9453139106432598

Epoch: 6| Step: 4
Training loss: 2.0555973052978516
Validation loss: 1.9246936043103535

Epoch: 6| Step: 5
Training loss: 1.7932965755462646
Validation loss: 1.9383745590845745

Epoch: 6| Step: 6
Training loss: 1.6092233657836914
Validation loss: 1.9404929081598918

Epoch: 6| Step: 7
Training loss: 2.4515349864959717
Validation loss: 1.9380398790041606

Epoch: 6| Step: 8
Training loss: 1.8549208641052246
Validation loss: 1.9471211036046345

Epoch: 6| Step: 9
Training loss: 1.446758508682251
Validation loss: 1.9400176008542378

Epoch: 6| Step: 10
Training loss: 2.146254062652588
Validation loss: 1.9488569498062134

Epoch: 6| Step: 11
Training loss: 1.5556378364562988
Validation loss: 1.948461373647054

Epoch: 6| Step: 12
Training loss: 1.8411056995391846
Validation loss: 1.938764254252116

Epoch: 6| Step: 13
Training loss: 1.6533253192901611
Validation loss: 1.94461856285731

Epoch: 58| Step: 0
Training loss: 1.7175791263580322
Validation loss: 1.9978835980097454

Epoch: 6| Step: 1
Training loss: 1.0321547985076904
Validation loss: 1.9859348336855571

Epoch: 6| Step: 2
Training loss: 1.8639897108078003
Validation loss: 2.014603575070699

Epoch: 6| Step: 3
Training loss: 1.5301356315612793
Validation loss: 2.0212281545003257

Epoch: 6| Step: 4
Training loss: 1.9422581195831299
Validation loss: 2.018794318040212

Epoch: 6| Step: 5
Training loss: 1.7989338636398315
Validation loss: 1.9989507993062336

Epoch: 6| Step: 6
Training loss: 2.5120046138763428
Validation loss: 2.013396938641866

Epoch: 6| Step: 7
Training loss: 2.045729637145996
Validation loss: 1.9869289596875508

Epoch: 6| Step: 8
Training loss: 1.6589027643203735
Validation loss: 1.9584386348724365

Epoch: 6| Step: 9
Training loss: 2.040762186050415
Validation loss: 1.9275983572006226

Epoch: 6| Step: 10
Training loss: 1.8548235893249512
Validation loss: 1.9102139075597127

Epoch: 6| Step: 11
Training loss: 1.73976731300354
Validation loss: 1.9046189586321514

Epoch: 6| Step: 12
Training loss: 1.7698789834976196
Validation loss: 1.909003774325053

Epoch: 6| Step: 13
Training loss: 2.14298415184021
Validation loss: 1.9232395887374878

Epoch: 59| Step: 0
Training loss: 1.8436912298202515
Validation loss: 1.9166828195254009

Epoch: 6| Step: 1
Training loss: 1.6953470706939697
Validation loss: 1.9291329979896545

Epoch: 6| Step: 2
Training loss: 2.228483200073242
Validation loss: 1.928787847359975

Epoch: 6| Step: 3
Training loss: 1.6437982320785522
Validation loss: 1.9259775876998901

Epoch: 6| Step: 4
Training loss: 2.1374013423919678
Validation loss: 1.9043566187222798

Epoch: 6| Step: 5
Training loss: 1.6904174089431763
Validation loss: 1.9334859649340312

Epoch: 6| Step: 6
Training loss: 1.6973962783813477
Validation loss: 1.9313915570576985

Epoch: 6| Step: 7
Training loss: 2.216414451599121
Validation loss: 1.9190065264701843

Epoch: 6| Step: 8
Training loss: 1.6695888042449951
Validation loss: 1.9211645325024922

Epoch: 6| Step: 9
Training loss: 1.0863690376281738
Validation loss: 1.9293817679087322

Epoch: 6| Step: 10
Training loss: 1.840799331665039
Validation loss: 1.9372661709785461

Epoch: 6| Step: 11
Training loss: 2.0874710083007812
Validation loss: 1.9571166634559631

Epoch: 6| Step: 12
Training loss: 1.8960199356079102
Validation loss: 1.9770539999008179

Epoch: 6| Step: 13
Training loss: 1.8258287906646729
Validation loss: 2.0019397536913552

Epoch: 60| Step: 0
Training loss: 1.569716215133667
Validation loss: 2.036065697669983

Epoch: 6| Step: 1
Training loss: 1.870539665222168
Validation loss: 2.068229933579763

Epoch: 6| Step: 2
Training loss: 1.1520357131958008
Validation loss: 2.06352291504542

Epoch: 6| Step: 3
Training loss: 2.2551345825195312
Validation loss: 2.0986038049062095

Epoch: 6| Step: 4
Training loss: 1.3153085708618164
Validation loss: 2.051604390144348

Epoch: 6| Step: 5
Training loss: 2.3112950325012207
Validation loss: 2.044351816177368

Epoch: 6| Step: 6
Training loss: 1.6856300830841064
Validation loss: 2.002541462580363

Epoch: 6| Step: 7
Training loss: 1.7747910022735596
Validation loss: 1.9884864886601765

Epoch: 6| Step: 8
Training loss: 2.152376651763916
Validation loss: 1.9807379444440205

Epoch: 6| Step: 9
Training loss: 2.0903007984161377
Validation loss: 1.9576105674107869

Epoch: 6| Step: 10
Training loss: 1.9628489017486572
Validation loss: 1.9602875113487244

Epoch: 6| Step: 11
Training loss: 2.0032122135162354
Validation loss: 1.9263167977333069

Epoch: 6| Step: 12
Training loss: 1.3411128520965576
Validation loss: 1.9272951285044353

Epoch: 6| Step: 13
Training loss: 1.6130266189575195
Validation loss: 1.9358168443044026

Epoch: 61| Step: 0
Training loss: 1.440264105796814
Validation loss: 1.9166371027628581

Epoch: 6| Step: 1
Training loss: 1.8376491069793701
Validation loss: 1.9167657693227131

Epoch: 6| Step: 2
Training loss: 2.154088020324707
Validation loss: 1.9415371616681416

Epoch: 6| Step: 3
Training loss: 2.083097219467163
Validation loss: 1.9306509097417195

Epoch: 6| Step: 4
Training loss: 2.1840672492980957
Validation loss: 1.9420880277951558

Epoch: 6| Step: 5
Training loss: 1.9746894836425781
Validation loss: 1.9344501892725627

Epoch: 6| Step: 6
Training loss: 2.0104756355285645
Validation loss: 1.9405448039372761

Epoch: 6| Step: 7
Training loss: 1.8165022134780884
Validation loss: 1.9241621891657512

Epoch: 6| Step: 8
Training loss: 2.2708568572998047
Validation loss: 1.9331650733947754

Epoch: 6| Step: 9
Training loss: 1.4462995529174805
Validation loss: 1.918298343817393

Epoch: 6| Step: 10
Training loss: 1.2804539203643799
Validation loss: 1.9341436624526978

Epoch: 6| Step: 11
Training loss: 2.1428773403167725
Validation loss: 1.9357823530832927

Epoch: 6| Step: 12
Training loss: 1.5772908926010132
Validation loss: 1.9431660175323486

Epoch: 6| Step: 13
Training loss: 1.788956642150879
Validation loss: 1.9490299224853516

Epoch: 62| Step: 0
Training loss: 1.870225191116333
Validation loss: 1.9780774116516113

Epoch: 6| Step: 1
Training loss: 1.6807444095611572
Validation loss: 1.9647029240926106

Epoch: 6| Step: 2
Training loss: 1.4135713577270508
Validation loss: 1.991300106048584

Epoch: 6| Step: 3
Training loss: 1.7210025787353516
Validation loss: 1.998281757036845

Epoch: 6| Step: 4
Training loss: 2.0023725032806396
Validation loss: 1.9912685950597127

Epoch: 6| Step: 5
Training loss: 2.006561279296875
Validation loss: 1.986494521299998

Epoch: 6| Step: 6
Training loss: 1.7472141981124878
Validation loss: 1.9806446234385173

Epoch: 6| Step: 7
Training loss: 2.4374876022338867
Validation loss: 1.968976080417633

Epoch: 6| Step: 8
Training loss: 1.5102413892745972
Validation loss: 1.9831482370694478

Epoch: 6| Step: 9
Training loss: 1.6619844436645508
Validation loss: 1.9816943208376567

Epoch: 6| Step: 10
Training loss: 1.7436175346374512
Validation loss: 1.9680571556091309

Epoch: 6| Step: 11
Training loss: 1.4894171953201294
Validation loss: 1.9638967116673787

Epoch: 6| Step: 12
Training loss: 2.4674196243286133
Validation loss: 1.9620044231414795

Epoch: 6| Step: 13
Training loss: 1.1358129978179932
Validation loss: 1.9733260869979858

Epoch: 63| Step: 0
Training loss: 1.952249526977539
Validation loss: 1.9727081457773845

Epoch: 6| Step: 1
Training loss: 1.5984866619110107
Validation loss: 1.9581412474314372

Epoch: 6| Step: 2
Training loss: 2.228912591934204
Validation loss: 1.948908309141795

Epoch: 6| Step: 3
Training loss: 1.390085220336914
Validation loss: 1.9760048985481262

Epoch: 6| Step: 4
Training loss: 2.066793918609619
Validation loss: 1.9419049620628357

Epoch: 6| Step: 5
Training loss: 1.6594066619873047
Validation loss: 1.9567107558250427

Epoch: 6| Step: 6
Training loss: 1.8659976720809937
Validation loss: 1.937887191772461

Epoch: 6| Step: 7
Training loss: 1.720808506011963
Validation loss: 1.9588382840156555

Epoch: 6| Step: 8
Training loss: 1.3404966592788696
Validation loss: 1.9734642108281453

Epoch: 6| Step: 9
Training loss: 1.3568861484527588
Validation loss: 1.9793113668759663

Epoch: 6| Step: 10
Training loss: 2.1591358184814453
Validation loss: 1.997945507367452

Epoch: 6| Step: 11
Training loss: 1.9823930263519287
Validation loss: 2.0109235644340515

Epoch: 6| Step: 12
Training loss: 1.634766697883606
Validation loss: 1.994402011235555

Epoch: 6| Step: 13
Training loss: 2.1026930809020996
Validation loss: 1.9661017457644145

Epoch: 64| Step: 0
Training loss: 2.011589288711548
Validation loss: 1.9625709652900696

Epoch: 6| Step: 1
Training loss: 1.80031418800354
Validation loss: 1.9654632210731506

Epoch: 6| Step: 2
Training loss: 1.769013524055481
Validation loss: 1.9581510821978252

Epoch: 6| Step: 3
Training loss: 1.6885164976119995
Validation loss: 1.9493958751360576

Epoch: 6| Step: 4
Training loss: 1.805114984512329
Validation loss: 1.9484485586484273

Epoch: 6| Step: 5
Training loss: 1.612351417541504
Validation loss: 1.948058267434438

Epoch: 6| Step: 6
Training loss: 2.0697054862976074
Validation loss: 1.9642361799875896

Epoch: 6| Step: 7
Training loss: 1.639970064163208
Validation loss: 1.990525444348653

Epoch: 6| Step: 8
Training loss: 1.5711842775344849
Validation loss: 1.9804633855819702

Epoch: 6| Step: 9
Training loss: 1.8375694751739502
Validation loss: 1.981074611345927

Epoch: 6| Step: 10
Training loss: 1.6999919414520264
Validation loss: 2.010447859764099

Epoch: 6| Step: 11
Training loss: 1.6041314601898193
Validation loss: 2.015362819035848

Epoch: 6| Step: 12
Training loss: 1.8004169464111328
Validation loss: 1.9877134164174397

Epoch: 6| Step: 13
Training loss: 1.9279221296310425
Validation loss: 1.965902050336202

Epoch: 65| Step: 0
Training loss: 1.583893895149231
Validation loss: 1.9490277369817097

Epoch: 6| Step: 1
Training loss: 2.626394271850586
Validation loss: 1.9209752281506856

Epoch: 6| Step: 2
Training loss: 2.056149482727051
Validation loss: 1.921801249186198

Epoch: 6| Step: 3
Training loss: 2.652937889099121
Validation loss: 1.928954044977824

Epoch: 6| Step: 4
Training loss: 1.2793956995010376
Validation loss: 1.9104048609733582

Epoch: 6| Step: 5
Training loss: 1.9035648107528687
Validation loss: 1.928335189819336

Epoch: 6| Step: 6
Training loss: 1.6965919733047485
Validation loss: 1.929122308890025

Epoch: 6| Step: 7
Training loss: 1.9252023696899414
Validation loss: 1.9252788821856182

Epoch: 6| Step: 8
Training loss: 1.1941015720367432
Validation loss: 1.9266057809193928

Epoch: 6| Step: 9
Training loss: 1.7756787538528442
Validation loss: 1.920525848865509

Epoch: 6| Step: 10
Training loss: 1.435628890991211
Validation loss: 1.9302749633789062

Epoch: 6| Step: 11
Training loss: 1.3748886585235596
Validation loss: 1.934119164943695

Epoch: 6| Step: 12
Training loss: 2.246164321899414
Validation loss: 1.9631019632021587

Epoch: 6| Step: 13
Training loss: 1.419407844543457
Validation loss: 1.9724639058113098

Epoch: 66| Step: 0
Training loss: 2.2188119888305664
Validation loss: 2.008343537648519

Epoch: 6| Step: 1
Training loss: 1.6055209636688232
Validation loss: 2.0202860236167908

Epoch: 6| Step: 2
Training loss: 2.20177960395813
Validation loss: 2.034697492917379

Epoch: 6| Step: 3
Training loss: 1.3037645816802979
Validation loss: 2.0313817858695984

Epoch: 6| Step: 4
Training loss: 1.8784825801849365
Validation loss: 2.047460675239563

Epoch: 6| Step: 5
Training loss: 1.6089345216751099
Validation loss: 2.0442503690719604

Epoch: 6| Step: 6
Training loss: 1.9601740837097168
Validation loss: 2.0308129588762918

Epoch: 6| Step: 7
Training loss: 1.3949466943740845
Validation loss: 2.0171673695246377

Epoch: 6| Step: 8
Training loss: 1.8231208324432373
Validation loss: 1.9809187253316243

Epoch: 6| Step: 9
Training loss: 1.9246324300765991
Validation loss: 1.9603208700815837

Epoch: 6| Step: 10
Training loss: 1.618646264076233
Validation loss: 1.9454941352208455

Epoch: 6| Step: 11
Training loss: 1.2886772155761719
Validation loss: 1.959967037041982

Epoch: 6| Step: 12
Training loss: 1.6823742389678955
Validation loss: 1.9603845477104187

Epoch: 6| Step: 13
Training loss: 2.2288525104522705
Validation loss: 1.9341578880945842

Epoch: 67| Step: 0
Training loss: 2.126657009124756
Validation loss: 1.9534064332644145

Epoch: 6| Step: 1
Training loss: 1.4895644187927246
Validation loss: 1.9363483389218648

Epoch: 6| Step: 2
Training loss: 1.6434574127197266
Validation loss: 1.9357910752296448

Epoch: 6| Step: 3
Training loss: 1.934465765953064
Validation loss: 1.9279327193895976

Epoch: 6| Step: 4
Training loss: 1.8151445388793945
Validation loss: 1.9343968629837036

Epoch: 6| Step: 5
Training loss: 2.239098072052002
Validation loss: 1.9298362135887146

Epoch: 6| Step: 6
Training loss: 1.3740534782409668
Validation loss: 1.951343794663747

Epoch: 6| Step: 7
Training loss: 1.8882187604904175
Validation loss: 1.9480711817741394

Epoch: 6| Step: 8
Training loss: 1.4601490497589111
Validation loss: 1.9413630565007527

Epoch: 6| Step: 9
Training loss: 2.279327392578125
Validation loss: 1.9366694887479146

Epoch: 6| Step: 10
Training loss: 1.587280511856079
Validation loss: 1.9659518996874492

Epoch: 6| Step: 11
Training loss: 1.1832382678985596
Validation loss: 1.9636916319529216

Epoch: 6| Step: 12
Training loss: 1.5821068286895752
Validation loss: 1.927075723807017

Epoch: 6| Step: 13
Training loss: 2.126461982727051
Validation loss: 1.9899524450302124

Epoch: 68| Step: 0
Training loss: 1.8740534782409668
Validation loss: 2.0096566677093506

Epoch: 6| Step: 1
Training loss: 1.6252566576004028
Validation loss: 2.0028700033823648

Epoch: 6| Step: 2
Training loss: 1.772017002105713
Validation loss: 2.039898455142975

Epoch: 6| Step: 3
Training loss: 1.8854808807373047
Validation loss: 2.0130827029546103

Epoch: 6| Step: 4
Training loss: 1.3700487613677979
Validation loss: 2.0228264133135476

Epoch: 6| Step: 5
Training loss: 2.446258306503296
Validation loss: 1.9995245734850566

Epoch: 6| Step: 6
Training loss: 2.057288646697998
Validation loss: 1.9600412249565125

Epoch: 6| Step: 7
Training loss: 1.5531394481658936
Validation loss: 1.9423486789067586

Epoch: 6| Step: 8
Training loss: 1.8248984813690186
Validation loss: 1.9308908979098003

Epoch: 6| Step: 9
Training loss: 1.8091763257980347
Validation loss: 1.9243316451708476

Epoch: 6| Step: 10
Training loss: 1.9107186794281006
Validation loss: 1.9284091393152873

Epoch: 6| Step: 11
Training loss: 1.3384921550750732
Validation loss: 1.9230011304219563

Epoch: 6| Step: 12
Training loss: 1.3119386434555054
Validation loss: 1.930589775244395

Epoch: 6| Step: 13
Training loss: 2.4193553924560547
Validation loss: 1.9375993013381958

Epoch: 69| Step: 0
Training loss: 2.0352425575256348
Validation loss: 1.940453290939331

Epoch: 6| Step: 1
Training loss: 1.3363912105560303
Validation loss: 1.9235742688179016

Epoch: 6| Step: 2
Training loss: 2.2551162242889404
Validation loss: 1.9563307364781697

Epoch: 6| Step: 3
Training loss: 1.5596497058868408
Validation loss: 1.9588501652081807

Epoch: 6| Step: 4
Training loss: 1.8519028425216675
Validation loss: 2.0065945784250894

Epoch: 6| Step: 5
Training loss: 1.5004560947418213
Validation loss: 1.9999648133913677

Epoch: 6| Step: 6
Training loss: 1.6087723970413208
Validation loss: 2.0216220219930015

Epoch: 6| Step: 7
Training loss: 1.983298420906067
Validation loss: 2.0535898009936013

Epoch: 6| Step: 8
Training loss: 2.396444797515869
Validation loss: 2.0494501193364463

Epoch: 6| Step: 9
Training loss: 2.3880696296691895
Validation loss: 2.0305301745732627

Epoch: 6| Step: 10
Training loss: 1.1651759147644043
Validation loss: 2.0063177148501077

Epoch: 6| Step: 11
Training loss: 1.4975440502166748
Validation loss: 2.002013921737671

Epoch: 6| Step: 12
Training loss: 1.4366503953933716
Validation loss: 1.9545750617980957

Epoch: 6| Step: 13
Training loss: 1.6147387027740479
Validation loss: 1.9490461548169453

Epoch: 70| Step: 0
Training loss: 2.0781264305114746
Validation loss: 1.9397583802541096

Epoch: 6| Step: 1
Training loss: 1.9263980388641357
Validation loss: 1.9301709334055583

Epoch: 6| Step: 2
Training loss: 1.9763782024383545
Validation loss: 1.9273747007052104

Epoch: 6| Step: 3
Training loss: 1.5413789749145508
Validation loss: 1.920245925585429

Epoch: 6| Step: 4
Training loss: 1.9784047603607178
Validation loss: 1.9379130800565083

Epoch: 6| Step: 5
Training loss: 1.8414223194122314
Validation loss: 1.918773074944814

Epoch: 6| Step: 6
Training loss: 1.4127401113510132
Validation loss: 1.9300426244735718

Epoch: 6| Step: 7
Training loss: 1.9749780893325806
Validation loss: 1.9257638653119404

Epoch: 6| Step: 8
Training loss: 1.82145094871521
Validation loss: 1.9318911631902058

Epoch: 6| Step: 9
Training loss: 1.1449942588806152
Validation loss: 1.9626063505808513

Epoch: 6| Step: 10
Training loss: 1.9494826793670654
Validation loss: 1.9755144516626995

Epoch: 6| Step: 11
Training loss: 1.3990684747695923
Validation loss: 1.9783970713615417

Epoch: 6| Step: 12
Training loss: 2.039412498474121
Validation loss: 1.9973966280619304

Epoch: 6| Step: 13
Training loss: 1.4448670148849487
Validation loss: 2.017046491305033

Epoch: 71| Step: 0
Training loss: 2.002143383026123
Validation loss: 1.9948957165082295

Epoch: 6| Step: 1
Training loss: 1.3896243572235107
Validation loss: 2.0066648721694946

Epoch: 6| Step: 2
Training loss: 1.90450918674469
Validation loss: 1.9868465264638264

Epoch: 6| Step: 3
Training loss: 1.3806233406066895
Validation loss: 1.9661603967348735

Epoch: 6| Step: 4
Training loss: 1.6900385618209839
Validation loss: 1.9611655672391255

Epoch: 6| Step: 5
Training loss: 2.294037103652954
Validation loss: 1.9476636052131653

Epoch: 6| Step: 6
Training loss: 1.27786386013031
Validation loss: 1.9523860414822896

Epoch: 6| Step: 7
Training loss: 2.260834217071533
Validation loss: 1.9528600772221882

Epoch: 6| Step: 8
Training loss: 2.106100559234619
Validation loss: 1.9503761132558186

Epoch: 6| Step: 9
Training loss: 1.5804203748703003
Validation loss: 1.9335943063100178

Epoch: 6| Step: 10
Training loss: 1.7019424438476562
Validation loss: 1.9567569692929585

Epoch: 6| Step: 11
Training loss: 1.241308569908142
Validation loss: 1.915456195672353

Epoch: 6| Step: 12
Training loss: 1.6954983472824097
Validation loss: 1.9564726948738098

Epoch: 6| Step: 13
Training loss: 1.5846433639526367
Validation loss: 1.9484424789746602

Epoch: 72| Step: 0
Training loss: 1.6456849575042725
Validation loss: 1.976754089196523

Epoch: 6| Step: 1
Training loss: 1.3000423908233643
Validation loss: 1.976024587949117

Epoch: 6| Step: 2
Training loss: 1.8302578926086426
Validation loss: 1.9883224368095398

Epoch: 6| Step: 3
Training loss: 1.2087604999542236
Validation loss: 1.963192105293274

Epoch: 6| Step: 4
Training loss: 2.469364881515503
Validation loss: 1.9732479552427928

Epoch: 6| Step: 5
Training loss: 1.2489137649536133
Validation loss: 1.9953387379646301

Epoch: 6| Step: 6
Training loss: 1.9121726751327515
Validation loss: 2.0001065532366433

Epoch: 6| Step: 7
Training loss: 1.6558616161346436
Validation loss: 1.9808445771535237

Epoch: 6| Step: 8
Training loss: 1.717013955116272
Validation loss: 1.9938504497210185

Epoch: 6| Step: 9
Training loss: 1.759366512298584
Validation loss: 1.997195581595103

Epoch: 6| Step: 10
Training loss: 1.4473915100097656
Validation loss: 1.9654198288917542

Epoch: 6| Step: 11
Training loss: 1.6517099142074585
Validation loss: 1.9781651496887207

Epoch: 6| Step: 12
Training loss: 1.8885178565979004
Validation loss: 1.9804149468739827

Epoch: 6| Step: 13
Training loss: 2.1534032821655273
Validation loss: 1.9609280029932659

Epoch: 73| Step: 0
Training loss: 1.4469066858291626
Validation loss: 1.9751621683438618

Epoch: 6| Step: 1
Training loss: 2.0049314498901367
Validation loss: 1.9519678751627605

Epoch: 6| Step: 2
Training loss: 1.4474976062774658
Validation loss: 1.940336803595225

Epoch: 6| Step: 3
Training loss: 1.6985092163085938
Validation loss: 1.9503559867540996

Epoch: 6| Step: 4
Training loss: 1.9334419965744019
Validation loss: 1.9414202570915222

Epoch: 6| Step: 5
Training loss: 1.556891679763794
Validation loss: 1.945208191871643

Epoch: 6| Step: 6
Training loss: 2.338132381439209
Validation loss: 1.9086403846740723

Epoch: 6| Step: 7
Training loss: 1.499497413635254
Validation loss: 1.9443534016609192

Epoch: 6| Step: 8
Training loss: 1.5462157726287842
Validation loss: 1.9406738877296448

Epoch: 6| Step: 9
Training loss: 1.5231831073760986
Validation loss: 1.9472423990567524

Epoch: 6| Step: 10
Training loss: 1.5742521286010742
Validation loss: 1.9442830681800842

Epoch: 6| Step: 11
Training loss: 1.2210699319839478
Validation loss: 1.9700470566749573

Epoch: 6| Step: 12
Training loss: 1.7893075942993164
Validation loss: 1.9447299242019653

Epoch: 6| Step: 13
Training loss: 2.266998052597046
Validation loss: 1.9566582043965657

Epoch: 74| Step: 0
Training loss: 2.1753416061401367
Validation loss: 1.962068537871043

Epoch: 6| Step: 1
Training loss: 1.6640641689300537
Validation loss: 1.9668453733126323

Epoch: 6| Step: 2
Training loss: 1.1676545143127441
Validation loss: 1.9775545001029968

Epoch: 6| Step: 3
Training loss: 1.6585675477981567
Validation loss: 1.970214605331421

Epoch: 6| Step: 4
Training loss: 1.369544267654419
Validation loss: 1.937490204970042

Epoch: 6| Step: 5
Training loss: 1.7303876876831055
Validation loss: 1.97880752881368

Epoch: 6| Step: 6
Training loss: 2.0019567012786865
Validation loss: 1.9950724442799885

Epoch: 6| Step: 7
Training loss: 1.0498884916305542
Validation loss: 1.9988938967386882

Epoch: 6| Step: 8
Training loss: 1.3537189960479736
Validation loss: 1.9926822582880657

Epoch: 6| Step: 9
Training loss: 1.6638736724853516
Validation loss: 1.9689900477727253

Epoch: 6| Step: 10
Training loss: 2.3984580039978027
Validation loss: 1.942418376604716

Epoch: 6| Step: 11
Training loss: 1.1155935525894165
Validation loss: 1.9677977760632832

Epoch: 6| Step: 12
Training loss: 2.3500123023986816
Validation loss: 1.9379105965296428

Epoch: 6| Step: 13
Training loss: 1.7753446102142334
Validation loss: 1.9423255324363708

Epoch: 75| Step: 0
Training loss: 1.8014956712722778
Validation loss: 1.9380599459012349

Epoch: 6| Step: 1
Training loss: 1.7302663326263428
Validation loss: 1.9519765774408977

Epoch: 6| Step: 2
Training loss: 1.128113031387329
Validation loss: 1.9637426535288494

Epoch: 6| Step: 3
Training loss: 1.655943512916565
Validation loss: 1.9645601511001587

Epoch: 6| Step: 4
Training loss: 1.2579820156097412
Validation loss: 1.9638223052024841

Epoch: 6| Step: 5
Training loss: 1.9382190704345703
Validation loss: 1.9832797646522522

Epoch: 6| Step: 6
Training loss: 1.5071585178375244
Validation loss: 2.0087713996569314

Epoch: 6| Step: 7
Training loss: 1.3336608409881592
Validation loss: 1.9922103484471638

Epoch: 6| Step: 8
Training loss: 1.847069263458252
Validation loss: 1.9707382520039876

Epoch: 6| Step: 9
Training loss: 1.7419788837432861
Validation loss: 1.9580739736557007

Epoch: 6| Step: 10
Training loss: 1.7663278579711914
Validation loss: 1.961254874865214

Epoch: 6| Step: 11
Training loss: 1.4630661010742188
Validation loss: 1.9315468470255535

Epoch: 6| Step: 12
Training loss: 2.1709585189819336
Validation loss: 1.9559115568796794

Epoch: 6| Step: 13
Training loss: 1.928626298904419
Validation loss: 1.945791522661845

Epoch: 76| Step: 0
Training loss: 1.812443733215332
Validation loss: 1.930213709672292

Epoch: 6| Step: 1
Training loss: 1.8506172895431519
Validation loss: 1.9719470143318176

Epoch: 6| Step: 2
Training loss: 1.7090585231781006
Validation loss: 1.9796892603238423

Epoch: 6| Step: 3
Training loss: 1.1312668323516846
Validation loss: 1.9978256225585938

Epoch: 6| Step: 4
Training loss: 2.288564682006836
Validation loss: 2.0092190305391946

Epoch: 6| Step: 5
Training loss: 1.9775526523590088
Validation loss: 2.035629471143087

Epoch: 6| Step: 6
Training loss: 1.7919977903366089
Validation loss: 2.0214311679204306

Epoch: 6| Step: 7
Training loss: 2.036076068878174
Validation loss: 2.0340439875920615

Epoch: 6| Step: 8
Training loss: 1.696340560913086
Validation loss: 1.9957833886146545

Epoch: 6| Step: 9
Training loss: 1.7879853248596191
Validation loss: 2.0007515947024026

Epoch: 6| Step: 10
Training loss: 1.612640619277954
Validation loss: 1.9866015513737996

Epoch: 6| Step: 11
Training loss: 0.9332402944564819
Validation loss: 1.952645202477773

Epoch: 6| Step: 12
Training loss: 1.5780837535858154
Validation loss: 1.9590020577112834

Epoch: 6| Step: 13
Training loss: 1.2151899337768555
Validation loss: 1.9361027677853901

Epoch: 77| Step: 0
Training loss: 1.725333333015442
Validation loss: 1.9168514410654705

Epoch: 6| Step: 1
Training loss: 1.6561708450317383
Validation loss: 1.9325847625732422

Epoch: 6| Step: 2
Training loss: 1.926073431968689
Validation loss: 1.9425699313481648

Epoch: 6| Step: 3
Training loss: 1.6010842323303223
Validation loss: 1.926070471604665

Epoch: 6| Step: 4
Training loss: 2.2078771591186523
Validation loss: 1.9436554908752441

Epoch: 6| Step: 5
Training loss: 1.5529884099960327
Validation loss: 1.939042091369629

Epoch: 6| Step: 6
Training loss: 1.7407532930374146
Validation loss: 1.9555711547533672

Epoch: 6| Step: 7
Training loss: 2.006166934967041
Validation loss: 1.9765211542447407

Epoch: 6| Step: 8
Training loss: 1.0538029670715332
Validation loss: 1.972958743572235

Epoch: 6| Step: 9
Training loss: 1.8531111478805542
Validation loss: 1.9835548400878906

Epoch: 6| Step: 10
Training loss: 1.5417919158935547
Validation loss: 2.001458764076233

Epoch: 6| Step: 11
Training loss: 1.7042027711868286
Validation loss: 1.9921551148096721

Epoch: 6| Step: 12
Training loss: 1.2752037048339844
Validation loss: 2.025742789109548

Epoch: 6| Step: 13
Training loss: 1.5614068508148193
Validation loss: 1.979097346464793

Epoch: 78| Step: 0
Training loss: 1.5846856832504272
Validation loss: 2.002943476041158

Epoch: 6| Step: 1
Training loss: 1.1352121829986572
Validation loss: 1.941474715868632

Epoch: 6| Step: 2
Training loss: 2.4083304405212402
Validation loss: 1.9638102451960247

Epoch: 6| Step: 3
Training loss: 1.8280709981918335
Validation loss: 1.9566620588302612

Epoch: 6| Step: 4
Training loss: 1.8946483135223389
Validation loss: 1.9428726037343342

Epoch: 6| Step: 5
Training loss: 1.8933578729629517
Validation loss: 1.9289937218030293

Epoch: 6| Step: 6
Training loss: 1.1948773860931396
Validation loss: 1.9366708199183147

Epoch: 6| Step: 7
Training loss: 1.1053293943405151
Validation loss: 1.9438225428263347

Epoch: 6| Step: 8
Training loss: 2.23477840423584
Validation loss: 1.9635362426439922

Epoch: 6| Step: 9
Training loss: 1.5186944007873535
Validation loss: 1.9622791012128193

Epoch: 6| Step: 10
Training loss: 1.8452457189559937
Validation loss: 1.9765409032503765

Epoch: 6| Step: 11
Training loss: 1.6305975914001465
Validation loss: 1.9987468123435974

Epoch: 6| Step: 12
Training loss: 1.2682485580444336
Validation loss: 1.9866233269373577

Epoch: 6| Step: 13
Training loss: 1.3698445558547974
Validation loss: 1.9932924509048462

Epoch: 79| Step: 0
Training loss: 1.5003582239151
Validation loss: 2.024630606174469

Epoch: 6| Step: 1
Training loss: 1.3418798446655273
Validation loss: 2.025273402531942

Epoch: 6| Step: 2
Training loss: 1.7100615501403809
Validation loss: 2.0499841372172036

Epoch: 6| Step: 3
Training loss: 1.5427577495574951
Validation loss: 2.003659665584564

Epoch: 6| Step: 4
Training loss: 1.6885974407196045
Validation loss: 2.0181131760279336

Epoch: 6| Step: 5
Training loss: 1.993006706237793
Validation loss: 1.977933684984843

Epoch: 6| Step: 6
Training loss: 1.4965996742248535
Validation loss: 1.971405843893687

Epoch: 6| Step: 7
Training loss: 1.4203417301177979
Validation loss: 1.9483899474143982

Epoch: 6| Step: 8
Training loss: 1.5264184474945068
Validation loss: 1.948817531267802

Epoch: 6| Step: 9
Training loss: 1.1852842569351196
Validation loss: 1.9598900079727173

Epoch: 6| Step: 10
Training loss: 1.7414590120315552
Validation loss: 1.9399996995925903

Epoch: 6| Step: 11
Training loss: 2.3600809574127197
Validation loss: 1.9559017022450764

Epoch: 6| Step: 12
Training loss: 1.768540382385254
Validation loss: 1.9483535885810852

Epoch: 6| Step: 13
Training loss: 1.5701764822006226
Validation loss: 1.9798179666201274

Epoch: 80| Step: 0
Training loss: 2.2344608306884766
Validation loss: 1.9972135225931804

Epoch: 6| Step: 1
Training loss: 1.4195079803466797
Validation loss: 2.0236134926478067

Epoch: 6| Step: 2
Training loss: 1.3018280267715454
Validation loss: 2.0014201402664185

Epoch: 6| Step: 3
Training loss: 1.5359301567077637
Validation loss: 2.0366437633832297

Epoch: 6| Step: 4
Training loss: 1.2494443655014038
Validation loss: 2.0380186438560486

Epoch: 6| Step: 5
Training loss: 1.8736488819122314
Validation loss: 2.0373679399490356

Epoch: 6| Step: 6
Training loss: 1.4698787927627563
Validation loss: 1.960589587688446

Epoch: 6| Step: 7
Training loss: 2.0122907161712646
Validation loss: 1.9639331301053364

Epoch: 6| Step: 8
Training loss: 1.546067476272583
Validation loss: 1.9580716292063396

Epoch: 6| Step: 9
Training loss: 1.8724079132080078
Validation loss: 1.931915561358134

Epoch: 6| Step: 10
Training loss: 1.9723243713378906
Validation loss: 1.9245088696479797

Epoch: 6| Step: 11
Training loss: 1.2520325183868408
Validation loss: 1.9853164553642273

Epoch: 6| Step: 12
Training loss: 1.6488521099090576
Validation loss: 1.956532597541809

Epoch: 6| Step: 13
Training loss: 1.5859394073486328
Validation loss: 1.926373839378357

Epoch: 81| Step: 0
Training loss: 1.3353407382965088
Validation loss: 1.962388237317403

Epoch: 6| Step: 1
Training loss: 2.221137523651123
Validation loss: 1.9572553833325703

Epoch: 6| Step: 2
Training loss: 1.5606908798217773
Validation loss: 1.9679066340128581

Epoch: 6| Step: 3
Training loss: 1.4698448181152344
Validation loss: 1.9698933959007263

Epoch: 6| Step: 4
Training loss: 1.5421161651611328
Validation loss: 1.9638150930404663

Epoch: 6| Step: 5
Training loss: 1.852475881576538
Validation loss: 1.9722435077031453

Epoch: 6| Step: 6
Training loss: 1.1003048419952393
Validation loss: 1.9781322677930195

Epoch: 6| Step: 7
Training loss: 0.9969263672828674
Validation loss: 2.0144864519437156

Epoch: 6| Step: 8
Training loss: 1.579756259918213
Validation loss: 2.0358974933624268

Epoch: 6| Step: 9
Training loss: 2.2728519439697266
Validation loss: 2.000131110350291

Epoch: 6| Step: 10
Training loss: 0.9005888104438782
Validation loss: 2.0175706148147583

Epoch: 6| Step: 11
Training loss: 1.7936384677886963
Validation loss: 2.030510445435842

Epoch: 6| Step: 12
Training loss: 1.813138484954834
Validation loss: 1.9814563592274983

Epoch: 6| Step: 13
Training loss: 1.7178231477737427
Validation loss: 2.017817974090576

Epoch: 82| Step: 0
Training loss: 2.0601205825805664
Validation loss: 1.9764422972997029

Epoch: 6| Step: 1
Training loss: 1.3189501762390137
Validation loss: 1.9349331259727478

Epoch: 6| Step: 2
Training loss: 1.2417314052581787
Validation loss: 1.9466440081596375

Epoch: 6| Step: 3
Training loss: 1.7563555240631104
Validation loss: 1.93146018187205

Epoch: 6| Step: 4
Training loss: 1.2157464027404785
Validation loss: 1.9475829601287842

Epoch: 6| Step: 5
Training loss: 1.585561990737915
Validation loss: 1.956970989704132

Epoch: 6| Step: 6
Training loss: 1.7898449897766113
Validation loss: 1.9460495511690776

Epoch: 6| Step: 7
Training loss: 1.1082289218902588
Validation loss: 2.0020132859547934

Epoch: 6| Step: 8
Training loss: 1.451743483543396
Validation loss: 1.9539299607276917

Epoch: 6| Step: 9
Training loss: 1.8061997890472412
Validation loss: 1.986635426680247

Epoch: 6| Step: 10
Training loss: 1.9874341487884521
Validation loss: 1.9642346501350403

Epoch: 6| Step: 11
Training loss: 1.0976245403289795
Validation loss: 1.9933686256408691

Epoch: 6| Step: 12
Training loss: 1.722595453262329
Validation loss: 2.017121454079946

Epoch: 6| Step: 13
Training loss: 1.951817274093628
Validation loss: 2.0466858545939126

Epoch: 83| Step: 0
Training loss: 1.9209229946136475
Validation loss: 2.00151526927948

Epoch: 6| Step: 1
Training loss: 1.3186147212982178
Validation loss: 2.0204497377077737

Epoch: 6| Step: 2
Training loss: 1.5722734928131104
Validation loss: 2.0482975045839944

Epoch: 6| Step: 3
Training loss: 1.4073576927185059
Validation loss: 2.0193985303243003

Epoch: 6| Step: 4
Training loss: 0.9213049411773682
Validation loss: 2.00919908285141

Epoch: 6| Step: 5
Training loss: 1.5272705554962158
Validation loss: 1.9968768159548442

Epoch: 6| Step: 6
Training loss: 1.706789255142212
Validation loss: 1.9696269035339355

Epoch: 6| Step: 7
Training loss: 1.7600622177124023
Validation loss: 2.012662728627523

Epoch: 6| Step: 8
Training loss: 1.7170376777648926
Validation loss: 1.9354088703791301

Epoch: 6| Step: 9
Training loss: 1.2738513946533203
Validation loss: 1.9357125163078308

Epoch: 6| Step: 10
Training loss: 2.093456745147705
Validation loss: 1.9809247454007466

Epoch: 6| Step: 11
Training loss: 2.051405906677246
Validation loss: 1.9255216121673584

Epoch: 6| Step: 12
Training loss: 1.5501307249069214
Validation loss: 1.9701521595319111

Epoch: 6| Step: 13
Training loss: 2.019120693206787
Validation loss: 1.9445248047510784

Epoch: 84| Step: 0
Training loss: 1.0032106637954712
Validation loss: 2.0152026216189065

Epoch: 6| Step: 1
Training loss: 1.8422589302062988
Validation loss: 1.9830166101455688

Epoch: 6| Step: 2
Training loss: 1.61261785030365
Validation loss: 2.027946432431539

Epoch: 6| Step: 3
Training loss: 1.5921239852905273
Validation loss: 2.0516469279925027

Epoch: 6| Step: 4
Training loss: 1.3163113594055176
Validation loss: 2.1030123631159463

Epoch: 6| Step: 5
Training loss: 1.5968133211135864
Validation loss: 2.0624107122421265

Epoch: 6| Step: 6
Training loss: 1.8563134670257568
Validation loss: 2.0305923223495483

Epoch: 6| Step: 7
Training loss: 1.238914966583252
Validation loss: 2.010709981123606

Epoch: 6| Step: 8
Training loss: 1.7095236778259277
Validation loss: 1.9890245199203491

Epoch: 6| Step: 9
Training loss: 0.9743574857711792
Validation loss: 1.9940369923909504

Epoch: 6| Step: 10
Training loss: 2.0425148010253906
Validation loss: 1.9570501446723938

Epoch: 6| Step: 11
Training loss: 1.7667646408081055
Validation loss: 1.9435141682624817

Epoch: 6| Step: 12
Training loss: 1.685366153717041
Validation loss: 1.975510875384013

Epoch: 6| Step: 13
Training loss: 2.1542043685913086
Validation loss: 1.9584989547729492

Epoch: 85| Step: 0
Training loss: 1.1532671451568604
Validation loss: 1.9703739682833354

Epoch: 6| Step: 1
Training loss: 1.487729787826538
Validation loss: 1.9735321203867595

Epoch: 6| Step: 2
Training loss: 1.944122076034546
Validation loss: 1.9651775360107422

Epoch: 6| Step: 3
Training loss: 1.6878796815872192
Validation loss: 1.9944744507471721

Epoch: 6| Step: 4
Training loss: 1.4469985961914062
Validation loss: 2.012823760509491

Epoch: 6| Step: 5
Training loss: 1.5076919794082642
Validation loss: 2.026761809984843

Epoch: 6| Step: 6
Training loss: 1.259795069694519
Validation loss: 2.0047890742619834

Epoch: 6| Step: 7
Training loss: 1.4539995193481445
Validation loss: 2.0516726771990457

Epoch: 6| Step: 8
Training loss: 1.7484276294708252
Validation loss: 2.018357296784719

Epoch: 6| Step: 9
Training loss: 1.328681230545044
Validation loss: 2.0008904337882996

Epoch: 6| Step: 10
Training loss: 1.7517826557159424
Validation loss: 1.9600649277369182

Epoch: 6| Step: 11
Training loss: 1.5837725400924683
Validation loss: 1.9443801045417786

Epoch: 6| Step: 12
Training loss: 1.346086859703064
Validation loss: 1.9593867262204487

Epoch: 6| Step: 13
Training loss: 1.8572107553482056
Validation loss: 2.0124908089637756

Epoch: 86| Step: 0
Training loss: 1.2718636989593506
Validation loss: 1.9865583380063374

Epoch: 6| Step: 1
Training loss: 1.3149998188018799
Validation loss: 1.9541467428207397

Epoch: 6| Step: 2
Training loss: 1.7012008428573608
Validation loss: 1.9587287306785583

Epoch: 6| Step: 3
Training loss: 1.418624997138977
Validation loss: 1.9848052660624187

Epoch: 6| Step: 4
Training loss: 1.801601767539978
Validation loss: 2.0000823934872947

Epoch: 6| Step: 5
Training loss: 1.1881814002990723
Validation loss: 2.013366679350535

Epoch: 6| Step: 6
Training loss: 1.9424526691436768
Validation loss: 2.0585113366444907

Epoch: 6| Step: 7
Training loss: 2.048929452896118
Validation loss: 2.0477134585380554

Epoch: 6| Step: 8
Training loss: 1.3314247131347656
Validation loss: 2.0194729765256247

Epoch: 6| Step: 9
Training loss: 1.454209566116333
Validation loss: 2.03944198290507

Epoch: 6| Step: 10
Training loss: 1.5237241983413696
Validation loss: 1.9912366072336833

Epoch: 6| Step: 11
Training loss: 1.5804979801177979
Validation loss: 1.9904174208641052

Epoch: 6| Step: 12
Training loss: 1.926076054573059
Validation loss: 1.9916218717892964

Epoch: 6| Step: 13
Training loss: 1.1675291061401367
Validation loss: 2.0045879085858664

Epoch: 87| Step: 0
Training loss: 0.9634745717048645
Validation loss: 1.9653757015864055

Epoch: 6| Step: 1
Training loss: 1.2829041481018066
Validation loss: 2.002979854742686

Epoch: 6| Step: 2
Training loss: 2.402505874633789
Validation loss: 2.007347822189331

Epoch: 6| Step: 3
Training loss: 1.5605409145355225
Validation loss: 2.0328302582105002

Epoch: 6| Step: 4
Training loss: 1.2770588397979736
Validation loss: 1.9945765336354573

Epoch: 6| Step: 5
Training loss: 1.4097944498062134
Validation loss: 2.009449621041616

Epoch: 6| Step: 6
Training loss: 1.2139370441436768
Validation loss: 2.04730761051178

Epoch: 6| Step: 7
Training loss: 2.1745028495788574
Validation loss: 2.0355936884880066

Epoch: 6| Step: 8
Training loss: 1.3049625158309937
Validation loss: 2.057038903236389

Epoch: 6| Step: 9
Training loss: 1.8264105319976807
Validation loss: 2.051741619904836

Epoch: 6| Step: 10
Training loss: 1.7486002445220947
Validation loss: 1.9617339372634888

Epoch: 6| Step: 11
Training loss: 1.1978306770324707
Validation loss: 1.972193996111552

Epoch: 6| Step: 12
Training loss: 1.8041441440582275
Validation loss: 1.955264727274577

Epoch: 6| Step: 13
Training loss: 1.220859408378601
Validation loss: 1.963521937529246

Epoch: 88| Step: 0
Training loss: 1.2887697219848633
Validation loss: 1.931559681892395

Epoch: 6| Step: 1
Training loss: 1.3667068481445312
Validation loss: 1.9498918056488037

Epoch: 6| Step: 2
Training loss: 1.955666184425354
Validation loss: 1.977325697739919

Epoch: 6| Step: 3
Training loss: 1.811056137084961
Validation loss: 1.9665825366973877

Epoch: 6| Step: 4
Training loss: 1.575846552848816
Validation loss: 1.9529441595077515

Epoch: 6| Step: 5
Training loss: 1.9301369190216064
Validation loss: 1.9541192054748535

Epoch: 6| Step: 6
Training loss: 1.2500460147857666
Validation loss: 1.9892138242721558

Epoch: 6| Step: 7
Training loss: 1.634852647781372
Validation loss: 1.9910508791605632

Epoch: 6| Step: 8
Training loss: 1.3107131719589233
Validation loss: 2.02527650197347

Epoch: 6| Step: 9
Training loss: 1.0292978286743164
Validation loss: 2.012952148914337

Epoch: 6| Step: 10
Training loss: 0.7150205373764038
Validation loss: 2.0088747342427573

Epoch: 6| Step: 11
Training loss: 1.7734915018081665
Validation loss: 2.040631433327993

Epoch: 6| Step: 12
Training loss: 1.5783979892730713
Validation loss: 2.0205126206080117

Epoch: 6| Step: 13
Training loss: 2.2359707355499268
Validation loss: 2.022681772708893

Epoch: 89| Step: 0
Training loss: 1.8381108045578003
Validation loss: 2.0210916996002197

Epoch: 6| Step: 1
Training loss: 0.8584162592887878
Validation loss: 1.9783644676208496

Epoch: 6| Step: 2
Training loss: 1.9712929725646973
Validation loss: 2.00961971282959

Epoch: 6| Step: 3
Training loss: 1.0576403141021729
Validation loss: 2.0065068999926248

Epoch: 6| Step: 4
Training loss: 1.6158368587493896
Validation loss: 1.960507869720459

Epoch: 6| Step: 5
Training loss: 1.284740924835205
Validation loss: 2.0144994060198465

Epoch: 6| Step: 6
Training loss: 1.7247408628463745
Validation loss: 2.0445846120516458

Epoch: 6| Step: 7
Training loss: 1.523852825164795
Validation loss: 1.9907967845598857

Epoch: 6| Step: 8
Training loss: 1.8097485303878784
Validation loss: 2.012209713459015

Epoch: 6| Step: 9
Training loss: 1.575691819190979
Validation loss: 2.04708594083786

Epoch: 6| Step: 10
Training loss: 1.9125003814697266
Validation loss: 2.028877000013987

Epoch: 6| Step: 11
Training loss: 0.9779921770095825
Validation loss: 1.96513432264328

Epoch: 6| Step: 12
Training loss: 1.5186097621917725
Validation loss: 1.971866250038147

Epoch: 6| Step: 13
Training loss: 1.0266897678375244
Validation loss: 1.9978504180908203

Epoch: 90| Step: 0
Training loss: 1.1820425987243652
Validation loss: 1.956675926844279

Epoch: 6| Step: 1
Training loss: 1.2141802310943604
Validation loss: 1.9947156111399333

Epoch: 6| Step: 2
Training loss: 1.2331463098526
Validation loss: 1.9997632106145222

Epoch: 6| Step: 3
Training loss: 0.7590577602386475
Validation loss: 1.9912044405937195

Epoch: 6| Step: 4
Training loss: 1.185197114944458
Validation loss: 2.0174259344736734

Epoch: 6| Step: 5
Training loss: 1.7193361520767212
Validation loss: 2.0473155776659646

Epoch: 6| Step: 6
Training loss: 1.5976053476333618
Validation loss: 2.0635487834612527

Epoch: 6| Step: 7
Training loss: 2.3912980556488037
Validation loss: 2.0639494260152182

Epoch: 6| Step: 8
Training loss: 1.9440414905548096
Validation loss: 2.0098047256469727

Epoch: 6| Step: 9
Training loss: 1.7144817113876343
Validation loss: 2.014337340990702

Epoch: 6| Step: 10
Training loss: 1.866466760635376
Validation loss: 2.0185224215189614

Epoch: 6| Step: 11
Training loss: 1.2288169860839844
Validation loss: 1.990182598431905

Epoch: 6| Step: 12
Training loss: 1.9929568767547607
Validation loss: 1.992628534634908

Epoch: 6| Step: 13
Training loss: 0.9902139902114868
Validation loss: 1.9960637092590332

Epoch: 91| Step: 0
Training loss: 1.2185423374176025
Validation loss: 1.9820089141527812

Epoch: 6| Step: 1
Training loss: 2.024592399597168
Validation loss: 1.980807900428772

Epoch: 6| Step: 2
Training loss: 1.3098584413528442
Validation loss: 2.003372053305308

Epoch: 6| Step: 3
Training loss: 1.436812162399292
Validation loss: 1.9871111909548442

Epoch: 6| Step: 4
Training loss: 1.2990890741348267
Validation loss: 2.0247637033462524

Epoch: 6| Step: 5
Training loss: 0.91123366355896
Validation loss: 2.017991046110789

Epoch: 6| Step: 6
Training loss: 1.976374864578247
Validation loss: 1.9940214951833088

Epoch: 6| Step: 7
Training loss: 1.584121823310852
Validation loss: 1.9840072790781658

Epoch: 6| Step: 8
Training loss: 1.5897650718688965
Validation loss: 1.9862064917882283

Epoch: 6| Step: 9
Training loss: 1.856420874595642
Validation loss: 2.0415982802708945

Epoch: 6| Step: 10
Training loss: 1.300818681716919
Validation loss: 2.044721762339274

Epoch: 6| Step: 11
Training loss: 0.9342939853668213
Validation loss: 2.0327526330947876

Epoch: 6| Step: 12
Training loss: 1.6552902460098267
Validation loss: 2.0678335626920066

Epoch: 6| Step: 13
Training loss: 1.3319988250732422
Validation loss: 2.0067970554033914

Epoch: 92| Step: 0
Training loss: 1.851764440536499
Validation loss: 2.0324613054593406

Epoch: 6| Step: 1
Training loss: 1.4127905368804932
Validation loss: 2.0009577671686807

Epoch: 6| Step: 2
Training loss: 2.050689935684204
Validation loss: 1.9935098091761272

Epoch: 6| Step: 3
Training loss: 1.329908847808838
Validation loss: 1.9807265003522236

Epoch: 6| Step: 4
Training loss: 1.3595905303955078
Validation loss: 1.9576619664827983

Epoch: 6| Step: 5
Training loss: 1.5013678073883057
Validation loss: 1.9427180290222168

Epoch: 6| Step: 6
Training loss: 1.4285550117492676
Validation loss: 1.9517887632052104

Epoch: 6| Step: 7
Training loss: 1.2085973024368286
Validation loss: 1.961749831835429

Epoch: 6| Step: 8
Training loss: 1.0628118515014648
Validation loss: 1.9951949715614319

Epoch: 6| Step: 9
Training loss: 1.5758638381958008
Validation loss: 1.9974136749903362

Epoch: 6| Step: 10
Training loss: 1.8017113208770752
Validation loss: 2.025105675061544

Epoch: 6| Step: 11
Training loss: 1.2625842094421387
Validation loss: 2.0036643346150718

Epoch: 6| Step: 12
Training loss: 1.094449758529663
Validation loss: 2.009602208932241

Epoch: 6| Step: 13
Training loss: 1.0843141078948975
Validation loss: 2.0202269554138184

Epoch: 93| Step: 0
Training loss: 1.408312439918518
Validation loss: 2.0012371142705283

Epoch: 6| Step: 1
Training loss: 1.5209275484085083
Validation loss: 2.027119517326355

Epoch: 6| Step: 2
Training loss: 1.4493800401687622
Validation loss: 2.0245574315389

Epoch: 6| Step: 3
Training loss: 1.4817557334899902
Validation loss: 2.0134310722351074

Epoch: 6| Step: 4
Training loss: 1.5480773448944092
Validation loss: 1.992757757504781

Epoch: 6| Step: 5
Training loss: 1.2229077816009521
Validation loss: 1.9890438516934712

Epoch: 6| Step: 6
Training loss: 1.2732601165771484
Validation loss: 1.9745342930157979

Epoch: 6| Step: 7
Training loss: 1.228763461112976
Validation loss: 1.9882214665412903

Epoch: 6| Step: 8
Training loss: 1.4286978244781494
Validation loss: 2.0110095938046775

Epoch: 6| Step: 9
Training loss: 1.8070871829986572
Validation loss: 1.9725091656049092

Epoch: 6| Step: 10
Training loss: 0.8686857223510742
Validation loss: 2.026348094145457

Epoch: 6| Step: 11
Training loss: 1.7268853187561035
Validation loss: 2.063117245833079

Epoch: 6| Step: 12
Training loss: 1.4685617685317993
Validation loss: 2.0253066619237265

Epoch: 6| Step: 13
Training loss: 1.5650668144226074
Validation loss: 2.0538369019826255

Epoch: 94| Step: 0
Training loss: 1.1135284900665283
Validation loss: 2.0298439264297485

Epoch: 6| Step: 1
Training loss: 1.3233649730682373
Validation loss: 1.999132752418518

Epoch: 6| Step: 2
Training loss: 2.407646656036377
Validation loss: 2.0198232531547546

Epoch: 6| Step: 3
Training loss: 0.8577192425727844
Validation loss: 1.997986614704132

Epoch: 6| Step: 4
Training loss: 1.7411448955535889
Validation loss: 2.0025479197502136

Epoch: 6| Step: 5
Training loss: 1.6288530826568604
Validation loss: 2.0191055734952292

Epoch: 6| Step: 6
Training loss: 1.4540762901306152
Validation loss: 2.063302298386892

Epoch: 6| Step: 7
Training loss: 1.5470960140228271
Validation loss: 2.0165268381436667

Epoch: 6| Step: 8
Training loss: 1.0497403144836426
Validation loss: 2.0422310829162598

Epoch: 6| Step: 9
Training loss: 1.4659512042999268
Validation loss: 2.002693990866343

Epoch: 6| Step: 10
Training loss: 1.5283143520355225
Validation loss: 2.025925934314728

Epoch: 6| Step: 11
Training loss: 1.0858112573623657
Validation loss: 2.0039802193641663

Epoch: 6| Step: 12
Training loss: 1.6005147695541382
Validation loss: 2.0221414963404336

Epoch: 6| Step: 13
Training loss: 0.8076111078262329
Validation loss: 2.0077687899271646

Epoch: 95| Step: 0
Training loss: 1.0303802490234375
Validation loss: 1.9779891967773438

Epoch: 6| Step: 1
Training loss: 1.5803825855255127
Validation loss: 2.004436751206716

Epoch: 6| Step: 2
Training loss: 1.1584579944610596
Validation loss: 2.0144723455111184

Epoch: 6| Step: 3
Training loss: 1.5198686122894287
Validation loss: 2.0225033362706504

Epoch: 6| Step: 4
Training loss: 1.1894876956939697
Validation loss: 2.0205605228741965

Epoch: 6| Step: 5
Training loss: 0.5890293121337891
Validation loss: 2.017610569794973

Epoch: 6| Step: 6
Training loss: 1.3521924018859863
Validation loss: 1.9943042794863384

Epoch: 6| Step: 7
Training loss: 1.8153479099273682
Validation loss: 1.9957337180773418

Epoch: 6| Step: 8
Training loss: 0.9803808927536011
Validation loss: 1.9823179642359416

Epoch: 6| Step: 9
Training loss: 1.3519978523254395
Validation loss: 1.998020629088084

Epoch: 6| Step: 10
Training loss: 2.0480504035949707
Validation loss: 1.9863061507542927

Epoch: 6| Step: 11
Training loss: 1.8396910429000854
Validation loss: 2.0189305345217385

Epoch: 6| Step: 12
Training loss: 1.066406011581421
Validation loss: 1.9758207003275554

Epoch: 6| Step: 13
Training loss: 1.7247507572174072
Validation loss: 1.979867398738861

Epoch: 96| Step: 0
Training loss: 1.377265453338623
Validation loss: 1.9729674061139424

Epoch: 6| Step: 1
Training loss: 1.3528400659561157
Validation loss: 1.9496503671010335

Epoch: 6| Step: 2
Training loss: 1.1233845949172974
Validation loss: 1.9540786345799763

Epoch: 6| Step: 3
Training loss: 2.062131404876709
Validation loss: 1.9467358589172363

Epoch: 6| Step: 4
Training loss: 1.5619661808013916
Validation loss: 2.0192439953486123

Epoch: 6| Step: 5
Training loss: 1.2582926750183105
Validation loss: 2.030884047349294

Epoch: 6| Step: 6
Training loss: 0.6824760437011719
Validation loss: 2.040433625380198

Epoch: 6| Step: 7
Training loss: 1.4725780487060547
Validation loss: 2.058974325656891

Epoch: 6| Step: 8
Training loss: 1.2638698816299438
Validation loss: 2.030083258946737

Epoch: 6| Step: 9
Training loss: 1.67207670211792
Validation loss: 2.018200715382894

Epoch: 6| Step: 10
Training loss: 1.7450965642929077
Validation loss: 2.0028084913889566

Epoch: 6| Step: 11
Training loss: 1.0351285934448242
Validation loss: 2.026310682296753

Epoch: 6| Step: 12
Training loss: 1.3471622467041016
Validation loss: 1.982631762822469

Epoch: 6| Step: 13
Training loss: 1.1400816440582275
Validation loss: 1.9721011122067769

Epoch: 97| Step: 0
Training loss: 0.8215160369873047
Validation loss: 1.9893598357836406

Epoch: 6| Step: 1
Training loss: 1.6796481609344482
Validation loss: 2.015703539053599

Epoch: 6| Step: 2
Training loss: 1.5632504224777222
Validation loss: 1.9812394380569458

Epoch: 6| Step: 3
Training loss: 1.9270082712173462
Validation loss: 2.011126240094503

Epoch: 6| Step: 4
Training loss: 1.2781509160995483
Validation loss: 2.003675421079

Epoch: 6| Step: 5
Training loss: 1.1901973485946655
Validation loss: 2.001571993033091

Epoch: 6| Step: 6
Training loss: 0.7941750288009644
Validation loss: 1.9756356080373128

Epoch: 6| Step: 7
Training loss: 1.0081111192703247
Validation loss: 2.0074430306752524

Epoch: 6| Step: 8
Training loss: 1.6691733598709106
Validation loss: 2.0861531694730124

Epoch: 6| Step: 9
Training loss: 1.7254962921142578
Validation loss: 2.074061552683512

Epoch: 6| Step: 10
Training loss: 1.0176907777786255
Validation loss: 2.0926971236864724

Epoch: 6| Step: 11
Training loss: 1.720245599746704
Validation loss: 2.068345785140991

Epoch: 6| Step: 12
Training loss: 1.3403840065002441
Validation loss: 2.041340470314026

Epoch: 6| Step: 13
Training loss: 1.115623950958252
Validation loss: 2.0288280248641968

Epoch: 98| Step: 0
Training loss: 1.4228436946868896
Validation loss: 1.98274560769399

Epoch: 6| Step: 1
Training loss: 1.510406732559204
Validation loss: 1.9899551669756572

Epoch: 6| Step: 2
Training loss: 1.452698826789856
Validation loss: 1.9574852585792542

Epoch: 6| Step: 3
Training loss: 1.0380220413208008
Validation loss: 1.9934159517288208

Epoch: 6| Step: 4
Training loss: 1.1495161056518555
Validation loss: 1.9744944175084431

Epoch: 6| Step: 5
Training loss: 1.1542084217071533
Validation loss: 1.990581472714742

Epoch: 6| Step: 6
Training loss: 1.6342746019363403
Validation loss: 1.981924017270406

Epoch: 6| Step: 7
Training loss: 1.4026681184768677
Validation loss: 1.9965188304583232

Epoch: 6| Step: 8
Training loss: 1.7643027305603027
Validation loss: 2.0287192861239114

Epoch: 6| Step: 9
Training loss: 1.2631173133850098
Validation loss: 2.065282106399536

Epoch: 6| Step: 10
Training loss: 1.5217217206954956
Validation loss: 2.0814335147539773

Epoch: 6| Step: 11
Training loss: 1.0654383897781372
Validation loss: 2.1233579317728677

Epoch: 6| Step: 12
Training loss: 1.4405766725540161
Validation loss: 2.157182236512502

Epoch: 6| Step: 13
Training loss: 0.9056258201599121
Validation loss: 2.1352455417315164

Epoch: 99| Step: 0
Training loss: 1.8267171382904053
Validation loss: 2.1931200424830117

Epoch: 6| Step: 1
Training loss: 1.4648451805114746
Validation loss: 2.1582968632380166

Epoch: 6| Step: 2
Training loss: 0.8378308415412903
Validation loss: 2.068510194619497

Epoch: 6| Step: 3
Training loss: 1.3193128108978271
Validation loss: 2.0105205376942954

Epoch: 6| Step: 4
Training loss: 1.5088932514190674
Validation loss: 1.9828025499979656

Epoch: 6| Step: 5
Training loss: 1.3827393054962158
Validation loss: 1.95105642080307

Epoch: 6| Step: 6
Training loss: 1.772813081741333
Validation loss: 1.9790210723876953

Epoch: 6| Step: 7
Training loss: 1.6113076210021973
Validation loss: 1.9678331017494202

Epoch: 6| Step: 8
Training loss: 0.8636415004730225
Validation loss: 1.9770833055178325

Epoch: 6| Step: 9
Training loss: 1.412523627281189
Validation loss: 2.0056118170420327

Epoch: 6| Step: 10
Training loss: 1.4518623352050781
Validation loss: 2.0025126139322915

Epoch: 6| Step: 11
Training loss: 1.7747247219085693
Validation loss: 2.0621618032455444

Epoch: 6| Step: 12
Training loss: 0.9455420970916748
Validation loss: 2.0560503403345742

Epoch: 6| Step: 13
Training loss: 0.7512518167495728
Validation loss: 2.145192344983419

Epoch: 100| Step: 0
Training loss: 1.7522876262664795
Validation loss: 2.115521709124247

Epoch: 6| Step: 1
Training loss: 0.9597788453102112
Validation loss: 2.0792851050694785

Epoch: 6| Step: 2
Training loss: 0.8118906617164612
Validation loss: 2.101927657922109

Epoch: 6| Step: 3
Training loss: 1.400404453277588
Validation loss: 2.0627002517382302

Epoch: 6| Step: 4
Training loss: 1.5390708446502686
Validation loss: 2.0292914708455405

Epoch: 6| Step: 5
Training loss: 1.075528621673584
Validation loss: 2.0333273808161416

Epoch: 6| Step: 6
Training loss: 1.4346439838409424
Validation loss: 2.006951630115509

Epoch: 6| Step: 7
Training loss: 2.139690399169922
Validation loss: 2.030492663383484

Epoch: 6| Step: 8
Training loss: 1.2613383531570435
Validation loss: 2.0099989573160806

Epoch: 6| Step: 9
Training loss: 1.3389520645141602
Validation loss: 1.9868930379549663

Epoch: 6| Step: 10
Training loss: 0.8258545398712158
Validation loss: 1.9707934260368347

Epoch: 6| Step: 11
Training loss: 1.5364869832992554
Validation loss: 1.9946573376655579

Epoch: 6| Step: 12
Training loss: 1.2164335250854492
Validation loss: 1.986268977324168

Epoch: 6| Step: 13
Training loss: 1.2477269172668457
Validation loss: 1.9993752241134644

Epoch: 101| Step: 0
Training loss: 0.9217896461486816
Validation loss: 2.0426899194717407

Epoch: 6| Step: 1
Training loss: 1.5195128917694092
Validation loss: 2.118053138256073

Epoch: 6| Step: 2
Training loss: 1.5504710674285889
Validation loss: 2.0714468558629355

Epoch: 6| Step: 3
Training loss: 1.0172696113586426
Validation loss: 2.0853351950645447

Epoch: 6| Step: 4
Training loss: 0.570960521697998
Validation loss: 2.0950961112976074

Epoch: 6| Step: 5
Training loss: 1.1465342044830322
Validation loss: 2.028411030769348

Epoch: 6| Step: 6
Training loss: 1.1931421756744385
Validation loss: 1.9474777777989705

Epoch: 6| Step: 7
Training loss: 1.9779062271118164
Validation loss: 1.9861080646514893

Epoch: 6| Step: 8
Training loss: 1.5056524276733398
Validation loss: 1.9581843614578247

Epoch: 6| Step: 9
Training loss: 1.421097993850708
Validation loss: 1.951701780160268

Epoch: 6| Step: 10
Training loss: 1.373236894607544
Validation loss: 1.9525188008944194

Epoch: 6| Step: 11
Training loss: 1.1442439556121826
Validation loss: 2.0026864210764566

Epoch: 6| Step: 12
Training loss: 1.3108019828796387
Validation loss: 1.984276572863261

Epoch: 6| Step: 13
Training loss: 2.311579704284668
Validation loss: 2.0179817279179892

Epoch: 102| Step: 0
Training loss: 1.5340737104415894
Validation loss: 2.051796476046244

Epoch: 6| Step: 1
Training loss: 1.7323815822601318
Validation loss: 2.081386685371399

Epoch: 6| Step: 2
Training loss: 1.3203424215316772
Validation loss: 2.1078004439671836

Epoch: 6| Step: 3
Training loss: 1.2483136653900146
Validation loss: 2.0620930194854736

Epoch: 6| Step: 4
Training loss: 1.048341989517212
Validation loss: 2.0914356311162314

Epoch: 6| Step: 5
Training loss: 1.0915547609329224
Validation loss: 2.059288581212362

Epoch: 6| Step: 6
Training loss: 1.257782220840454
Validation loss: 2.0501455267270408

Epoch: 6| Step: 7
Training loss: 0.82462477684021
Validation loss: 2.02372153600057

Epoch: 6| Step: 8
Training loss: 1.3333206176757812
Validation loss: 2.0217921336491904

Epoch: 6| Step: 9
Training loss: 1.2341194152832031
Validation loss: 2.0149568716684976

Epoch: 6| Step: 10
Training loss: 1.3460304737091064
Validation loss: 1.9769553542137146

Epoch: 6| Step: 11
Training loss: 1.2628422975540161
Validation loss: 1.980349878470103

Epoch: 6| Step: 12
Training loss: 1.247442603111267
Validation loss: 1.9629243612289429

Epoch: 6| Step: 13
Training loss: 1.1193407773971558
Validation loss: 1.979269285996755

Epoch: 103| Step: 0
Training loss: 1.0333080291748047
Validation loss: 1.9703669548034668

Epoch: 6| Step: 1
Training loss: 1.2041378021240234
Validation loss: 1.9738354881604512

Epoch: 6| Step: 2
Training loss: 0.8256839513778687
Validation loss: 2.0164125760396323

Epoch: 6| Step: 3
Training loss: 1.202991247177124
Validation loss: 2.042328417301178

Epoch: 6| Step: 4
Training loss: 1.394303798675537
Validation loss: 2.032086988290151

Epoch: 6| Step: 5
Training loss: 1.4712471961975098
Validation loss: 2.043669064839681

Epoch: 6| Step: 6
Training loss: 1.3345537185668945
Validation loss: 2.03584615389506

Epoch: 6| Step: 7
Training loss: 1.4125243425369263
Validation loss: 1.984087864557902

Epoch: 6| Step: 8
Training loss: 1.0305263996124268
Validation loss: 1.9699543317159016

Epoch: 6| Step: 9
Training loss: 1.123447060585022
Validation loss: 1.9730388919512432

Epoch: 6| Step: 10
Training loss: 1.805739402770996
Validation loss: 1.941617488861084

Epoch: 6| Step: 11
Training loss: 1.4326584339141846
Validation loss: 1.9844393332799275

Epoch: 6| Step: 12
Training loss: 1.3221348524093628
Validation loss: 1.9534364740053813

Epoch: 6| Step: 13
Training loss: 1.2491390705108643
Validation loss: 1.9827109376589458

Epoch: 104| Step: 0
Training loss: 1.0215580463409424
Validation loss: 1.9787852764129639

Epoch: 6| Step: 1
Training loss: 1.4101481437683105
Validation loss: 2.03443851073583

Epoch: 6| Step: 2
Training loss: 0.7547886371612549
Validation loss: 2.04386442899704

Epoch: 6| Step: 3
Training loss: 1.2646287679672241
Validation loss: 2.027455766995748

Epoch: 6| Step: 4
Training loss: 1.1318814754486084
Validation loss: 2.059454381465912

Epoch: 6| Step: 5
Training loss: 1.273036241531372
Validation loss: 2.0108791987101235

Epoch: 6| Step: 6
Training loss: 1.497392177581787
Validation loss: 2.0519949992497764

Epoch: 6| Step: 7
Training loss: 1.3379299640655518
Validation loss: 2.018602430820465

Epoch: 6| Step: 8
Training loss: 0.9945191144943237
Validation loss: 2.0043595830599465

Epoch: 6| Step: 9
Training loss: 1.450975775718689
Validation loss: 1.979672650496165

Epoch: 6| Step: 10
Training loss: 1.856472134590149
Validation loss: 1.9818400144577026

Epoch: 6| Step: 11
Training loss: 1.2636158466339111
Validation loss: 1.9375678499539692

Epoch: 6| Step: 12
Training loss: 0.9449357986450195
Validation loss: 1.930110216140747

Epoch: 6| Step: 13
Training loss: 1.499106764793396
Validation loss: 1.9358821113904316

Epoch: 105| Step: 0
Training loss: 1.4020832777023315
Validation loss: 1.9840846260388691

Epoch: 6| Step: 1
Training loss: 1.8690271377563477
Validation loss: 1.964051644007365

Epoch: 6| Step: 2
Training loss: 1.380319595336914
Validation loss: 2.0069688161214194

Epoch: 6| Step: 3
Training loss: 1.140207052230835
Validation loss: 2.049553632736206

Epoch: 6| Step: 4
Training loss: 1.2119542360305786
Validation loss: 2.0328266620635986

Epoch: 6| Step: 5
Training loss: 1.1971943378448486
Validation loss: 2.084761619567871

Epoch: 6| Step: 6
Training loss: 1.2894566059112549
Validation loss: 2.107836822668711

Epoch: 6| Step: 7
Training loss: 1.3883111476898193
Validation loss: 2.0762064456939697

Epoch: 6| Step: 8
Training loss: 1.1749773025512695
Validation loss: 2.0858778953552246

Epoch: 6| Step: 9
Training loss: 0.843186616897583
Validation loss: 2.0222068230311074

Epoch: 6| Step: 10
Training loss: 1.1171448230743408
Validation loss: 1.9375060002009075

Epoch: 6| Step: 11
Training loss: 1.6576905250549316
Validation loss: 1.9499004284540813

Epoch: 6| Step: 12
Training loss: 1.0844790935516357
Validation loss: 1.957209328810374

Epoch: 6| Step: 13
Training loss: 0.8870817422866821
Validation loss: 1.9201212922732036

Epoch: 106| Step: 0
Training loss: 1.6008999347686768
Validation loss: 1.9668666521708171

Epoch: 6| Step: 1
Training loss: 0.6353999376296997
Validation loss: 1.9967520038286846

Epoch: 6| Step: 2
Training loss: 0.9420902132987976
Validation loss: 2.004638155301412

Epoch: 6| Step: 3
Training loss: 0.8107924461364746
Validation loss: 2.037371277809143

Epoch: 6| Step: 4
Training loss: 1.8042991161346436
Validation loss: 2.0700507760047913

Epoch: 6| Step: 5
Training loss: 2.016587734222412
Validation loss: 2.086448609828949

Epoch: 6| Step: 6
Training loss: 0.9506264925003052
Validation loss: 2.073198119799296

Epoch: 6| Step: 7
Training loss: 0.9029957056045532
Validation loss: 2.0393680930137634

Epoch: 6| Step: 8
Training loss: 0.7672131061553955
Validation loss: 2.08046688636144

Epoch: 6| Step: 9
Training loss: 1.1124989986419678
Validation loss: 2.0140002965927124

Epoch: 6| Step: 10
Training loss: 1.011596441268921
Validation loss: 2.04735936721166

Epoch: 6| Step: 11
Training loss: 1.4573054313659668
Validation loss: 2.0165700713793435

Epoch: 6| Step: 12
Training loss: 1.437542200088501
Validation loss: 2.0132363041241965

Epoch: 6| Step: 13
Training loss: 1.4579217433929443
Validation loss: 1.9733376900355022

Epoch: 107| Step: 0
Training loss: 1.4778755903244019
Validation loss: 1.9614922801653545

Epoch: 6| Step: 1
Training loss: 1.0384581089019775
Validation loss: 1.9765227437019348

Epoch: 6| Step: 2
Training loss: 1.1193814277648926
Validation loss: 1.9913761019706726

Epoch: 6| Step: 3
Training loss: 0.7811151742935181
Validation loss: 1.9788538217544556

Epoch: 6| Step: 4
Training loss: 1.4198328256607056
Validation loss: 2.0050807197888694

Epoch: 6| Step: 5
Training loss: 1.100616693496704
Validation loss: 2.012377123037974

Epoch: 6| Step: 6
Training loss: 1.1594090461730957
Validation loss: 2.0494100054105124

Epoch: 6| Step: 7
Training loss: 1.3176639080047607
Validation loss: 2.10478138923645

Epoch: 6| Step: 8
Training loss: 1.071575403213501
Validation loss: 2.054859479268392

Epoch: 6| Step: 9
Training loss: 1.09348464012146
Validation loss: 2.098715384801229

Epoch: 6| Step: 10
Training loss: 1.005082607269287
Validation loss: 2.0664692521095276

Epoch: 6| Step: 11
Training loss: 1.4748435020446777
Validation loss: 2.0329585472742715

Epoch: 6| Step: 12
Training loss: 1.1496163606643677
Validation loss: 2.047499179840088

Epoch: 6| Step: 13
Training loss: 1.7167032957077026
Validation loss: 2.0217129985491433

Epoch: 108| Step: 0
Training loss: 1.4838041067123413
Validation loss: 1.9797539710998535

Epoch: 6| Step: 1
Training loss: 1.0705229043960571
Validation loss: 1.982125699520111

Epoch: 6| Step: 2
Training loss: 1.7602146863937378
Validation loss: 1.9965011080106099

Epoch: 6| Step: 3
Training loss: 0.8920904397964478
Validation loss: 1.9877391457557678

Epoch: 6| Step: 4
Training loss: 0.7663499116897583
Validation loss: 2.03615403175354

Epoch: 6| Step: 5
Training loss: 1.6000697612762451
Validation loss: 2.0448089440663657

Epoch: 6| Step: 6
Training loss: 1.6386176347732544
Validation loss: 2.061138848463694

Epoch: 6| Step: 7
Training loss: 0.9697526097297668
Validation loss: 2.0450299978256226

Epoch: 6| Step: 8
Training loss: 0.9318104386329651
Validation loss: 2.033904274304708

Epoch: 6| Step: 9
Training loss: 0.5356199741363525
Validation loss: 2.0095703403155007

Epoch: 6| Step: 10
Training loss: 1.1929659843444824
Validation loss: 2.0717840592066445

Epoch: 6| Step: 11
Training loss: 1.4689977169036865
Validation loss: 1.9915643731753032

Epoch: 6| Step: 12
Training loss: 1.034903883934021
Validation loss: 2.011488954226176

Epoch: 6| Step: 13
Training loss: 1.2102031707763672
Validation loss: 1.997654636700948

Epoch: 109| Step: 0
Training loss: 1.34523606300354
Validation loss: 1.9564833045005798

Epoch: 6| Step: 1
Training loss: 0.7065026164054871
Validation loss: 1.9801623026529949

Epoch: 6| Step: 2
Training loss: 1.4767746925354004
Validation loss: 2.0296643376350403

Epoch: 6| Step: 3
Training loss: 1.156739592552185
Validation loss: 2.0027594765027366

Epoch: 6| Step: 4
Training loss: 1.0786978006362915
Validation loss: 2.040724515914917

Epoch: 6| Step: 5
Training loss: 1.505159854888916
Validation loss: 2.0643057823181152

Epoch: 6| Step: 6
Training loss: 0.9287405610084534
Validation loss: 2.0391695499420166

Epoch: 6| Step: 7
Training loss: 0.9775422215461731
Validation loss: 2.009296973546346

Epoch: 6| Step: 8
Training loss: 1.8757212162017822
Validation loss: 2.040646513303121

Epoch: 6| Step: 9
Training loss: 1.1453962326049805
Validation loss: 1.9780194759368896

Epoch: 6| Step: 10
Training loss: 1.2522048950195312
Validation loss: 1.9581291476885478

Epoch: 6| Step: 11
Training loss: 0.9517720937728882
Validation loss: 2.007806440194448

Epoch: 6| Step: 12
Training loss: 1.690186858177185
Validation loss: 1.9882155458132427

Epoch: 6| Step: 13
Training loss: 0.6656506657600403
Validation loss: 2.002682367960612

Epoch: 110| Step: 0
Training loss: 0.8278301954269409
Validation loss: 2.0294062296549478

Epoch: 6| Step: 1
Training loss: 2.1423959732055664
Validation loss: 2.023206094900767

Epoch: 6| Step: 2
Training loss: 1.2907956838607788
Validation loss: 2.020074486732483

Epoch: 6| Step: 3
Training loss: 0.8739326596260071
Validation loss: 2.049481987953186

Epoch: 6| Step: 4
Training loss: 0.8394136428833008
Validation loss: 2.019846240679423

Epoch: 6| Step: 5
Training loss: 1.1569894552230835
Validation loss: 1.9891494909922283

Epoch: 6| Step: 6
Training loss: 1.1758615970611572
Validation loss: 1.9759396314620972

Epoch: 6| Step: 7
Training loss: 1.5032672882080078
Validation loss: 2.0078856348991394

Epoch: 6| Step: 8
Training loss: 1.4582746028900146
Validation loss: 1.9672235250473022

Epoch: 6| Step: 9
Training loss: 0.9872152805328369
Validation loss: 2.0037344892819724

Epoch: 6| Step: 10
Training loss: 0.660923957824707
Validation loss: 1.9983396927515666

Epoch: 6| Step: 11
Training loss: 1.2276519536972046
Validation loss: 2.0410918593406677

Epoch: 6| Step: 12
Training loss: 1.0075088739395142
Validation loss: 2.0042791763941445

Epoch: 6| Step: 13
Training loss: 1.1223080158233643
Validation loss: 2.0729757944742837

Epoch: 111| Step: 0
Training loss: 0.8873295783996582
Validation loss: 1.9910501440366108

Epoch: 6| Step: 1
Training loss: 1.7956874370574951
Validation loss: 2.0334640542666116

Epoch: 6| Step: 2
Training loss: 1.1968885660171509
Validation loss: 1.9468411008516948

Epoch: 6| Step: 3
Training loss: 0.9313784837722778
Validation loss: 2.012172738711039

Epoch: 6| Step: 4
Training loss: 1.694535493850708
Validation loss: 2.00435463587443

Epoch: 6| Step: 5
Training loss: 0.5973585844039917
Validation loss: 2.007617712020874

Epoch: 6| Step: 6
Training loss: 0.777118980884552
Validation loss: 2.0176690220832825

Epoch: 6| Step: 7
Training loss: 1.4371862411499023
Validation loss: 2.0465267499287925

Epoch: 6| Step: 8
Training loss: 1.5230753421783447
Validation loss: 2.02891206741333

Epoch: 6| Step: 9
Training loss: 0.6985468864440918
Validation loss: 2.0335079232851663

Epoch: 6| Step: 10
Training loss: 0.9807970523834229
Validation loss: 1.9894990523656209

Epoch: 6| Step: 11
Training loss: 1.5174354314804077
Validation loss: 1.96715513865153

Epoch: 6| Step: 12
Training loss: 1.0150171518325806
Validation loss: 2.0168357292811074

Epoch: 6| Step: 13
Training loss: 0.6204887628555298
Validation loss: 1.9862030744552612

Epoch: 112| Step: 0
Training loss: 1.5888434648513794
Validation loss: 1.9701120853424072

Epoch: 6| Step: 1
Training loss: 1.007971167564392
Validation loss: 1.982420285542806

Epoch: 6| Step: 2
Training loss: 1.5960413217544556
Validation loss: 1.9767134189605713

Epoch: 6| Step: 3
Training loss: 1.1278858184814453
Validation loss: 1.971137821674347

Epoch: 6| Step: 4
Training loss: 0.5926117897033691
Validation loss: 1.9822022914886475

Epoch: 6| Step: 5
Training loss: 1.3338987827301025
Validation loss: 1.9399911761283875

Epoch: 6| Step: 6
Training loss: 0.8236756324768066
Validation loss: 1.9702096581459045

Epoch: 6| Step: 7
Training loss: 1.1550487279891968
Validation loss: 1.9666477640469868

Epoch: 6| Step: 8
Training loss: 1.0588088035583496
Validation loss: 1.9686828056971233

Epoch: 6| Step: 9
Training loss: 0.6060779094696045
Validation loss: 2.032875657081604

Epoch: 6| Step: 10
Training loss: 1.2265331745147705
Validation loss: 2.0858015219370523

Epoch: 6| Step: 11
Training loss: 1.0886919498443604
Validation loss: 1.9999470512072246

Epoch: 6| Step: 12
Training loss: 1.231285572052002
Validation loss: 2.001485606034597

Epoch: 6| Step: 13
Training loss: 1.4218946695327759
Validation loss: 2.0033671855926514

Epoch: 113| Step: 0
Training loss: 0.4879092872142792
Validation loss: 1.9508923689524333

Epoch: 6| Step: 1
Training loss: 0.9011218547821045
Validation loss: 1.937661071618398

Epoch: 6| Step: 2
Training loss: 1.2761852741241455
Validation loss: 1.9814781943957012

Epoch: 6| Step: 3
Training loss: 0.9391475915908813
Validation loss: 1.9910593032836914

Epoch: 6| Step: 4
Training loss: 1.7472087144851685
Validation loss: 1.993220825990041

Epoch: 6| Step: 5
Training loss: 1.8106290102005005
Validation loss: 2.0349190831184387

Epoch: 6| Step: 6
Training loss: 0.5385904312133789
Validation loss: 2.0462146997451782

Epoch: 6| Step: 7
Training loss: 1.2901132106781006
Validation loss: 2.061916629473368

Epoch: 6| Step: 8
Training loss: 1.1485750675201416
Validation loss: 2.0482351779937744

Epoch: 6| Step: 9
Training loss: 0.8611041903495789
Validation loss: 2.0524919827779136

Epoch: 6| Step: 10
Training loss: 0.5921468734741211
Validation loss: 1.9923685789108276

Epoch: 6| Step: 11
Training loss: 1.9216557741165161
Validation loss: 1.9707233905792236

Epoch: 6| Step: 12
Training loss: 1.2611972093582153
Validation loss: 2.005983809630076

Epoch: 6| Step: 13
Training loss: 1.085336685180664
Validation loss: 1.989965597788493

Epoch: 114| Step: 0
Training loss: 1.3831883668899536
Validation loss: 1.9276149074236553

Epoch: 6| Step: 1
Training loss: 1.052473783493042
Validation loss: 2.0004818042119346

Epoch: 6| Step: 2
Training loss: 1.4243717193603516
Validation loss: 2.023938695589701

Epoch: 6| Step: 3
Training loss: 0.824600338935852
Validation loss: 2.048249622186025

Epoch: 6| Step: 4
Training loss: 0.8534038066864014
Validation loss: 2.0713427464167276

Epoch: 6| Step: 5
Training loss: 1.4334003925323486
Validation loss: 2.081017315387726

Epoch: 6| Step: 6
Training loss: 0.7707851529121399
Validation loss: 2.085432449976603

Epoch: 6| Step: 7
Training loss: 1.4163422584533691
Validation loss: 2.0592443545659385

Epoch: 6| Step: 8
Training loss: 1.1390341520309448
Validation loss: 2.0437870621681213

Epoch: 6| Step: 9
Training loss: 1.25944983959198
Validation loss: 2.0181519985198975

Epoch: 6| Step: 10
Training loss: 1.183551549911499
Validation loss: 1.9758165280024211

Epoch: 6| Step: 11
Training loss: 0.9491747617721558
Validation loss: 2.012204567591349

Epoch: 6| Step: 12
Training loss: 1.062065839767456
Validation loss: 1.9703969756762187

Epoch: 6| Step: 13
Training loss: 0.8173139095306396
Validation loss: 2.0214080810546875

Epoch: 115| Step: 0
Training loss: 0.9036967754364014
Validation loss: 1.9893792867660522

Epoch: 6| Step: 1
Training loss: 1.4928209781646729
Validation loss: 1.9629202882448833

Epoch: 6| Step: 2
Training loss: 1.0963404178619385
Validation loss: 1.9681092500686646

Epoch: 6| Step: 3
Training loss: 0.7870304584503174
Validation loss: 2.0184372862180076

Epoch: 6| Step: 4
Training loss: 1.5207403898239136
Validation loss: 1.9816397627194722

Epoch: 6| Step: 5
Training loss: 0.7605383396148682
Validation loss: 1.952366332213084

Epoch: 6| Step: 6
Training loss: 0.9907079339027405
Validation loss: 2.0228231151898703

Epoch: 6| Step: 7
Training loss: 0.9306471347808838
Validation loss: 1.9991210301717122

Epoch: 6| Step: 8
Training loss: 1.6924595832824707
Validation loss: 2.014258841673533

Epoch: 6| Step: 9
Training loss: 0.659608006477356
Validation loss: 2.023120085398356

Epoch: 6| Step: 10
Training loss: 1.6858465671539307
Validation loss: 2.04161407550176

Epoch: 6| Step: 11
Training loss: 1.0142930746078491
Validation loss: 1.9867568810780842

Epoch: 6| Step: 12
Training loss: 0.6612148284912109
Validation loss: 1.9923076430956523

Epoch: 6| Step: 13
Training loss: 0.9832412600517273
Validation loss: 1.9986716707547505

Epoch: 116| Step: 0
Training loss: 1.3863366842269897
Validation loss: 2.0329983631769815

Epoch: 6| Step: 1
Training loss: 0.7540189027786255
Validation loss: 2.0244475603103638

Epoch: 6| Step: 2
Training loss: 1.0884352922439575
Validation loss: 2.0467012524604797

Epoch: 6| Step: 3
Training loss: 0.7991197109222412
Validation loss: 1.9944463968276978

Epoch: 6| Step: 4
Training loss: 0.8014143705368042
Validation loss: 1.963671882947286

Epoch: 6| Step: 5
Training loss: 1.151270866394043
Validation loss: 1.9625061750411987

Epoch: 6| Step: 6
Training loss: 1.585485816001892
Validation loss: 1.9739385843276978

Epoch: 6| Step: 7
Training loss: 1.1404690742492676
Validation loss: 1.9399894277254741

Epoch: 6| Step: 8
Training loss: 1.170788049697876
Validation loss: 1.9345422585805256

Epoch: 6| Step: 9
Training loss: 0.949990451335907
Validation loss: 1.981432596842448

Epoch: 6| Step: 10
Training loss: 0.8068430423736572
Validation loss: 1.9947262406349182

Epoch: 6| Step: 11
Training loss: 0.7524229288101196
Validation loss: 2.0113935470581055

Epoch: 6| Step: 12
Training loss: 1.2812061309814453
Validation loss: 2.05439559618632

Epoch: 6| Step: 13
Training loss: 1.2391602993011475
Validation loss: 2.031585216522217

Epoch: 117| Step: 0
Training loss: 1.3623981475830078
Validation loss: 2.0647329092025757

Epoch: 6| Step: 1
Training loss: 0.9033631086349487
Validation loss: 1.9932927091916401

Epoch: 6| Step: 2
Training loss: 1.0648159980773926
Validation loss: 1.9737282594045003

Epoch: 6| Step: 3
Training loss: 1.2546038627624512
Validation loss: 1.9847038785616558

Epoch: 6| Step: 4
Training loss: 1.0455743074417114
Validation loss: 1.9805981516838074

Epoch: 6| Step: 5
Training loss: 1.1216646432876587
Validation loss: 1.9778749346733093

Epoch: 6| Step: 6
Training loss: 1.1470915079116821
Validation loss: 1.950892706712087

Epoch: 6| Step: 7
Training loss: 0.7823196649551392
Validation loss: 1.985136330127716

Epoch: 6| Step: 8
Training loss: 1.2501699924468994
Validation loss: 1.9720904032389324

Epoch: 6| Step: 9
Training loss: 0.6712853908538818
Validation loss: 2.010533074537913

Epoch: 6| Step: 10
Training loss: 1.6881253719329834
Validation loss: 2.0370653867721558

Epoch: 6| Step: 11
Training loss: 0.9784923195838928
Validation loss: 2.028145889441172

Epoch: 6| Step: 12
Training loss: 0.7435586452484131
Validation loss: 2.051176687081655

Epoch: 6| Step: 13
Training loss: 1.0992836952209473
Validation loss: 2.0475162267684937

Epoch: 118| Step: 0
Training loss: 1.0653297901153564
Validation loss: 2.018749713897705

Epoch: 6| Step: 1
Training loss: 0.8842807412147522
Validation loss: 1.9967151482899983

Epoch: 6| Step: 2
Training loss: 0.8872330188751221
Validation loss: 1.979228675365448

Epoch: 6| Step: 3
Training loss: 1.673150897026062
Validation loss: 1.9837465087572734

Epoch: 6| Step: 4
Training loss: 0.9185655117034912
Validation loss: 1.9751392404238384

Epoch: 6| Step: 5
Training loss: 0.7293895483016968
Validation loss: 1.9982784191767375

Epoch: 6| Step: 6
Training loss: 1.1278526782989502
Validation loss: 2.039877712726593

Epoch: 6| Step: 7
Training loss: 1.603920340538025
Validation loss: 2.028266350428263

Epoch: 6| Step: 8
Training loss: 1.195570468902588
Validation loss: 2.014051834742228

Epoch: 6| Step: 9
Training loss: 1.0914088487625122
Validation loss: 2.0043190121650696

Epoch: 6| Step: 10
Training loss: 0.8229597210884094
Validation loss: 2.032105247179667

Epoch: 6| Step: 11
Training loss: 1.279966115951538
Validation loss: 2.0196922222773233

Epoch: 6| Step: 12
Training loss: 0.6810157895088196
Validation loss: 2.01720130443573

Epoch: 6| Step: 13
Training loss: 0.5046335458755493
Validation loss: 2.0462145805358887

Epoch: 119| Step: 0
Training loss: 1.0018283128738403
Validation loss: 1.9865865111351013

Epoch: 6| Step: 1
Training loss: 0.7330248355865479
Validation loss: 2.0122291445732117

Epoch: 6| Step: 2
Training loss: 1.2184021472930908
Validation loss: 1.9847100973129272

Epoch: 6| Step: 3
Training loss: 0.9127527475357056
Validation loss: 2.0342925985654197

Epoch: 6| Step: 4
Training loss: 0.8047249913215637
Validation loss: 2.0017557541529336

Epoch: 6| Step: 5
Training loss: 1.4495596885681152
Validation loss: 2.037583907445272

Epoch: 6| Step: 6
Training loss: 0.8176851272583008
Validation loss: 1.9832704067230225

Epoch: 6| Step: 7
Training loss: 1.2301143407821655
Validation loss: 2.0003233551979065

Epoch: 6| Step: 8
Training loss: 1.1946558952331543
Validation loss: 1.9704317649205525

Epoch: 6| Step: 9
Training loss: 0.9035776257514954
Validation loss: 1.9896346728007

Epoch: 6| Step: 10
Training loss: 0.8708629012107849
Validation loss: 2.0092692971229553

Epoch: 6| Step: 11
Training loss: 0.7193547487258911
Validation loss: 2.021929601828257

Epoch: 6| Step: 12
Training loss: 1.3546922206878662
Validation loss: 2.068025767803192

Epoch: 6| Step: 13
Training loss: 1.399714469909668
Validation loss: 2.1119518677393594

Epoch: 120| Step: 0
Training loss: 1.4888460636138916
Validation loss: 2.1077428261439004

Epoch: 6| Step: 1
Training loss: 1.2252867221832275
Validation loss: 1.9942829012870789

Epoch: 6| Step: 2
Training loss: 1.360306739807129
Validation loss: 1.981642762819926

Epoch: 6| Step: 3
Training loss: 0.7030149102210999
Validation loss: 2.01098241408666

Epoch: 6| Step: 4
Training loss: 0.4407830238342285
Validation loss: 1.9722235600153606

Epoch: 6| Step: 5
Training loss: 0.6159694194793701
Validation loss: 1.9714341163635254

Epoch: 6| Step: 6
Training loss: 1.4266889095306396
Validation loss: 1.9842562278111775

Epoch: 6| Step: 7
Training loss: 1.192368745803833
Validation loss: 1.9616360664367676

Epoch: 6| Step: 8
Training loss: 0.734634518623352
Validation loss: 1.9946315089861553

Epoch: 6| Step: 9
Training loss: 1.3368030786514282
Validation loss: 2.0453951756159463

Epoch: 6| Step: 10
Training loss: 0.8048115968704224
Validation loss: 2.0021377007166543

Epoch: 6| Step: 11
Training loss: 0.8039535284042358
Validation loss: 2.0538995464642844

Epoch: 6| Step: 12
Training loss: 0.7004104852676392
Validation loss: 2.0498172442118325

Epoch: 6| Step: 13
Training loss: 1.6034603118896484
Validation loss: 2.0541190107663474

Epoch: 121| Step: 0
Training loss: 0.7143000364303589
Validation loss: 1.9861675103505452

Epoch: 6| Step: 1
Training loss: 1.163074016571045
Validation loss: 1.9788764317830403

Epoch: 6| Step: 2
Training loss: 1.3229715824127197
Validation loss: 1.9584404627482097

Epoch: 6| Step: 3
Training loss: 0.5531176328659058
Validation loss: 2.007887125015259

Epoch: 6| Step: 4
Training loss: 1.7519946098327637
Validation loss: 2.017806887626648

Epoch: 6| Step: 5
Training loss: 1.020371437072754
Validation loss: 1.9814749161402385

Epoch: 6| Step: 6
Training loss: 1.0997576713562012
Validation loss: 2.0220042069753013

Epoch: 6| Step: 7
Training loss: 0.5887753367424011
Validation loss: 2.0295859575271606

Epoch: 6| Step: 8
Training loss: 0.8554403781890869
Validation loss: 2.010927895704905

Epoch: 6| Step: 9
Training loss: 1.1829557418823242
Validation loss: 2.083469788233439

Epoch: 6| Step: 10
Training loss: 0.9960253238677979
Validation loss: 2.065271496772766

Epoch: 6| Step: 11
Training loss: 1.5765599012374878
Validation loss: 2.0499320030212402

Epoch: 6| Step: 12
Training loss: 0.9186038970947266
Validation loss: 2.071354647477468

Epoch: 6| Step: 13
Training loss: 0.7996628880500793
Validation loss: 2.007085303465525

Epoch: 122| Step: 0
Training loss: 0.9697341322898865
Validation loss: 1.9814964532852173

Epoch: 6| Step: 1
Training loss: 0.7689279317855835
Validation loss: 1.9793752431869507

Epoch: 6| Step: 2
Training loss: 0.9153400659561157
Validation loss: 2.030401329199473

Epoch: 6| Step: 3
Training loss: 0.9337648153305054
Validation loss: 2.0461453994115195

Epoch: 6| Step: 4
Training loss: 1.5456364154815674
Validation loss: 2.0468968749046326

Epoch: 6| Step: 5
Training loss: 1.9440101385116577
Validation loss: 2.040791908899943

Epoch: 6| Step: 6
Training loss: 0.8028220534324646
Validation loss: 2.0627463459968567

Epoch: 6| Step: 7
Training loss: 0.7590944766998291
Validation loss: 1.9777086178461711

Epoch: 6| Step: 8
Training loss: 0.934593677520752
Validation loss: 1.97731347878774

Epoch: 6| Step: 9
Training loss: 1.4505118131637573
Validation loss: 1.9840597907702129

Epoch: 6| Step: 10
Training loss: 0.5509090423583984
Validation loss: 1.9745753010114033

Epoch: 6| Step: 11
Training loss: 1.1215966939926147
Validation loss: 1.945192853609721

Epoch: 6| Step: 12
Training loss: 1.127387285232544
Validation loss: 1.9568229913711548

Epoch: 6| Step: 13
Training loss: 0.7063190340995789
Validation loss: 1.9822205305099487

Epoch: 123| Step: 0
Training loss: 0.6850019693374634
Validation loss: 2.021058181921641

Epoch: 6| Step: 1
Training loss: 1.7300734519958496
Validation loss: 2.0391524831453958

Epoch: 6| Step: 2
Training loss: 1.1230542659759521
Validation loss: 2.073828081289927

Epoch: 6| Step: 3
Training loss: 1.10172438621521
Validation loss: 2.0670061111450195

Epoch: 6| Step: 4
Training loss: 1.0642552375793457
Validation loss: 1.9517896175384521

Epoch: 6| Step: 5
Training loss: 1.231016993522644
Validation loss: 1.9649713238080342

Epoch: 6| Step: 6
Training loss: 1.4298713207244873
Validation loss: 1.943375865618388

Epoch: 6| Step: 7
Training loss: 0.7683508396148682
Validation loss: 1.9666159749031067

Epoch: 6| Step: 8
Training loss: 0.9696146845817566
Validation loss: 1.913034160931905

Epoch: 6| Step: 9
Training loss: 1.1598351001739502
Validation loss: 1.9405617515246074

Epoch: 6| Step: 10
Training loss: 1.0079747438430786
Validation loss: 1.956831415494283

Epoch: 6| Step: 11
Training loss: 0.7273802161216736
Validation loss: 1.9568694432576497

Epoch: 6| Step: 12
Training loss: 1.0127190351486206
Validation loss: 1.9560502568880718

Epoch: 6| Step: 13
Training loss: 0.6032231450080872
Validation loss: 1.968090573946635

Epoch: 124| Step: 0
Training loss: 1.504014253616333
Validation loss: 2.002328336238861

Epoch: 6| Step: 1
Training loss: 0.9844681024551392
Validation loss: 1.960456411043803

Epoch: 6| Step: 2
Training loss: 0.8064678907394409
Validation loss: 1.9749946196873982

Epoch: 6| Step: 3
Training loss: 1.1715408563613892
Validation loss: 1.9846636652946472

Epoch: 6| Step: 4
Training loss: 0.7443095445632935
Validation loss: 1.9802019794782002

Epoch: 6| Step: 5
Training loss: 0.9775916934013367
Validation loss: 1.997608204682668

Epoch: 6| Step: 6
Training loss: 0.7906889319419861
Validation loss: 1.9746959805488586

Epoch: 6| Step: 7
Training loss: 1.1032609939575195
Validation loss: 1.9813982446988423

Epoch: 6| Step: 8
Training loss: 0.43955859541893005
Validation loss: 2.005431512991587

Epoch: 6| Step: 9
Training loss: 1.1363630294799805
Validation loss: 2.032815376917521

Epoch: 6| Step: 10
Training loss: 0.9752508401870728
Validation loss: 1.9928644895553589

Epoch: 6| Step: 11
Training loss: 1.3115453720092773
Validation loss: 1.998012125492096

Epoch: 6| Step: 12
Training loss: 0.9288468956947327
Validation loss: 1.99067219098409

Epoch: 6| Step: 13
Training loss: 0.7630908489227295
Validation loss: 2.001127620538076

Epoch: 125| Step: 0
Training loss: 0.6768208742141724
Validation loss: 2.0253012975056968

Epoch: 6| Step: 1
Training loss: 1.3318170309066772
Validation loss: 2.0634262959162393

Epoch: 6| Step: 2
Training loss: 0.9622877836227417
Validation loss: 2.0751920541127524

Epoch: 6| Step: 3
Training loss: 0.8159536123275757
Validation loss: 2.115541954835256

Epoch: 6| Step: 4
Training loss: 1.3856205940246582
Validation loss: 2.07455712556839

Epoch: 6| Step: 5
Training loss: 1.0513923168182373
Validation loss: 2.0545307397842407

Epoch: 6| Step: 6
Training loss: 1.2690088748931885
Validation loss: 2.0472474495569863

Epoch: 6| Step: 7
Training loss: 0.9684778451919556
Validation loss: 1.9693364302317302

Epoch: 6| Step: 8
Training loss: 1.3249211311340332
Validation loss: 1.9806767702102661

Epoch: 6| Step: 9
Training loss: 1.0312483310699463
Validation loss: 1.9858296712239583

Epoch: 6| Step: 10
Training loss: 0.9420813918113708
Validation loss: 2.0014724135398865

Epoch: 6| Step: 11
Training loss: 0.9420458078384399
Validation loss: 2.0156424840291343

Epoch: 6| Step: 12
Training loss: 0.799598753452301
Validation loss: 2.0085991819699607

Epoch: 6| Step: 13
Training loss: 1.0117998123168945
Validation loss: 2.068163494269053

Epoch: 126| Step: 0
Training loss: 0.801411509513855
Validation loss: 2.0491530100504556

Epoch: 6| Step: 1
Training loss: 1.0519906282424927
Validation loss: 2.076252261797587

Epoch: 6| Step: 2
Training loss: 0.974647581577301
Validation loss: 2.0685943166414895

Epoch: 6| Step: 3
Training loss: 0.9295985102653503
Validation loss: 2.0857538978258767

Epoch: 6| Step: 4
Training loss: 0.6090038418769836
Validation loss: 2.024567802747091

Epoch: 6| Step: 5
Training loss: 0.7861237525939941
Validation loss: 1.9838017423947651

Epoch: 6| Step: 6
Training loss: 0.8983520269393921
Validation loss: 1.9582027196884155

Epoch: 6| Step: 7
Training loss: 0.7615042924880981
Validation loss: 1.969361702601115

Epoch: 6| Step: 8
Training loss: 1.0085175037384033
Validation loss: 1.9994653065999348

Epoch: 6| Step: 9
Training loss: 1.0394816398620605
Validation loss: 2.0279166301091514

Epoch: 6| Step: 10
Training loss: 1.1267621517181396
Validation loss: 2.0168375770250955

Epoch: 6| Step: 11
Training loss: 0.9787232875823975
Validation loss: 2.048072357972463

Epoch: 6| Step: 12
Training loss: 1.0022029876708984
Validation loss: 2.0080631971359253

Epoch: 6| Step: 13
Training loss: 1.5131758451461792
Validation loss: 1.9899186094601948

Epoch: 127| Step: 0
Training loss: 1.0457916259765625
Validation loss: 1.9737839301427205

Epoch: 6| Step: 1
Training loss: 0.8084638118743896
Validation loss: 1.9727569222450256

Epoch: 6| Step: 2
Training loss: 1.2108689546585083
Validation loss: 1.9714983503023784

Epoch: 6| Step: 3
Training loss: 0.7848430871963501
Validation loss: 1.956135888894399

Epoch: 6| Step: 4
Training loss: 0.51219242811203
Validation loss: 1.9998360872268677

Epoch: 6| Step: 5
Training loss: 0.7205100059509277
Validation loss: 1.9727871417999268

Epoch: 6| Step: 6
Training loss: 0.7035214304924011
Validation loss: 1.98890886704127

Epoch: 6| Step: 7
Training loss: 1.1004016399383545
Validation loss: 1.9718051354090373

Epoch: 6| Step: 8
Training loss: 0.6580758094787598
Validation loss: 2.003000577290853

Epoch: 6| Step: 9
Training loss: 1.4472180604934692
Validation loss: 1.978725830713908

Epoch: 6| Step: 10
Training loss: 0.9350871443748474
Validation loss: 2.003193219502767

Epoch: 6| Step: 11
Training loss: 1.045284390449524
Validation loss: 1.9319312572479248

Epoch: 6| Step: 12
Training loss: 0.9688596129417419
Validation loss: 1.978837251663208

Epoch: 6| Step: 13
Training loss: 1.1456921100616455
Validation loss: 1.9845566749572754

Epoch: 128| Step: 0
Training loss: 1.0743752717971802
Validation loss: 1.987876017888387

Epoch: 6| Step: 1
Training loss: 0.8123736381530762
Validation loss: 2.0091466108957925

Epoch: 6| Step: 2
Training loss: 0.862471342086792
Validation loss: 2.0029433369636536

Epoch: 6| Step: 3
Training loss: 1.230482816696167
Validation loss: 2.0697729786237082

Epoch: 6| Step: 4
Training loss: 1.199717402458191
Validation loss: 2.119823177655538

Epoch: 6| Step: 5
Training loss: 0.5977506637573242
Validation loss: 2.037740627924601

Epoch: 6| Step: 6
Training loss: 0.924048125743866
Validation loss: 2.0283131202061973

Epoch: 6| Step: 7
Training loss: 1.297785997390747
Validation loss: 2.0001757939656577

Epoch: 6| Step: 8
Training loss: 0.7382221221923828
Validation loss: 1.9972474575042725

Epoch: 6| Step: 9
Training loss: 1.1630144119262695
Validation loss: 1.9931715329488118

Epoch: 6| Step: 10
Training loss: 0.8937480449676514
Validation loss: 1.980750322341919

Epoch: 6| Step: 11
Training loss: 0.46860241889953613
Validation loss: 1.9926302035649617

Epoch: 6| Step: 12
Training loss: 1.0482122898101807
Validation loss: 2.017636299133301

Epoch: 6| Step: 13
Training loss: 0.930457353591919
Validation loss: 2.0929351449012756

Epoch: 129| Step: 0
Training loss: 0.7558417320251465
Validation loss: 2.1033249696095786

Epoch: 6| Step: 1
Training loss: 1.8002194166183472
Validation loss: 2.056255499521891

Epoch: 6| Step: 2
Training loss: 0.867955207824707
Validation loss: 2.074440519014994

Epoch: 6| Step: 3
Training loss: 0.8664543032646179
Validation loss: 2.0290955305099487

Epoch: 6| Step: 4
Training loss: 1.3519244194030762
Validation loss: 2.0449445048967996

Epoch: 6| Step: 5
Training loss: 1.1162556409835815
Validation loss: 1.9673379063606262

Epoch: 6| Step: 6
Training loss: 0.8231152296066284
Validation loss: 1.9619799455006917

Epoch: 6| Step: 7
Training loss: 1.2957106828689575
Validation loss: 1.9756866097450256

Epoch: 6| Step: 8
Training loss: 0.9406120777130127
Validation loss: 1.9515393177668254

Epoch: 6| Step: 9
Training loss: 0.524319052696228
Validation loss: 2.0151073932647705

Epoch: 6| Step: 10
Training loss: 0.8470755815505981
Validation loss: 2.0061152577400208

Epoch: 6| Step: 11
Training loss: 0.8248131275177002
Validation loss: 2.0103896260261536

Epoch: 6| Step: 12
Training loss: 0.573968231678009
Validation loss: 2.0551114281018577

Epoch: 6| Step: 13
Training loss: 0.8388141393661499
Validation loss: 2.0344669620196023

Epoch: 130| Step: 0
Training loss: 0.45511728525161743
Validation loss: 1.999674121538798

Epoch: 6| Step: 1
Training loss: 0.8490525484085083
Validation loss: 2.0034446318944297

Epoch: 6| Step: 2
Training loss: 0.600670337677002
Validation loss: 2.019234518210093

Epoch: 6| Step: 3
Training loss: 1.720029592514038
Validation loss: 2.038623789946238

Epoch: 6| Step: 4
Training loss: 0.9521636366844177
Validation loss: 1.9561973015467327

Epoch: 6| Step: 5
Training loss: 0.8190262317657471
Validation loss: 2.0212567249933877

Epoch: 6| Step: 6
Training loss: 0.9406775236129761
Validation loss: 2.0501034259796143

Epoch: 6| Step: 7
Training loss: 0.7262136340141296
Validation loss: 2.0425655444463096

Epoch: 6| Step: 8
Training loss: 1.3001816272735596
Validation loss: 1.9998374780019124

Epoch: 6| Step: 9
Training loss: 0.5352233648300171
Validation loss: 2.022603710492452

Epoch: 6| Step: 10
Training loss: 1.1554263830184937
Validation loss: 2.0278682708740234

Epoch: 6| Step: 11
Training loss: 0.6639223098754883
Validation loss: 2.064539988835653

Epoch: 6| Step: 12
Training loss: 0.7605385780334473
Validation loss: 2.03799976905187

Epoch: 6| Step: 13
Training loss: 1.439409852027893
Validation loss: 2.0076651771863303

Epoch: 131| Step: 0
Training loss: 0.9357285499572754
Validation loss: 2.0345677534739175

Epoch: 6| Step: 1
Training loss: 0.7493351697921753
Validation loss: 1.9810735980669658

Epoch: 6| Step: 2
Training loss: 1.2281241416931152
Validation loss: 1.9710095524787903

Epoch: 6| Step: 3
Training loss: 1.09473717212677
Validation loss: 2.0371482968330383

Epoch: 6| Step: 4
Training loss: 0.809471607208252
Validation loss: 2.0326953728993735

Epoch: 6| Step: 5
Training loss: 0.8416709899902344
Validation loss: 2.0217233498891196

Epoch: 6| Step: 6
Training loss: 0.8614952564239502
Validation loss: 2.0256054798762

Epoch: 6| Step: 7
Training loss: 0.4473492503166199
Validation loss: 1.9846896727879841

Epoch: 6| Step: 8
Training loss: 0.7491240501403809
Validation loss: 1.9799420436223347

Epoch: 6| Step: 9
Training loss: 0.9523105621337891
Validation loss: 1.9940577348073323

Epoch: 6| Step: 10
Training loss: 0.9358116388320923
Validation loss: 1.9858540495236714

Epoch: 6| Step: 11
Training loss: 1.3117496967315674
Validation loss: 2.009634335835775

Epoch: 6| Step: 12
Training loss: 1.3560395240783691
Validation loss: 1.9639775156974792

Epoch: 6| Step: 13
Training loss: 0.610698401927948
Validation loss: 2.0015428264935813

Epoch: 132| Step: 0
Training loss: 0.4868062734603882
Validation loss: 1.9759400486946106

Epoch: 6| Step: 1
Training loss: 0.7719534039497375
Validation loss: 2.008467177549998

Epoch: 6| Step: 2
Training loss: 0.9051920175552368
Validation loss: 2.014860192934672

Epoch: 6| Step: 3
Training loss: 1.1578822135925293
Validation loss: 2.029440144697825

Epoch: 6| Step: 4
Training loss: 0.9098769426345825
Validation loss: 2.0684571464856467

Epoch: 6| Step: 5
Training loss: 1.4661338329315186
Validation loss: 2.020914912223816

Epoch: 6| Step: 6
Training loss: 0.6489608883857727
Validation loss: 2.0065298875172934

Epoch: 6| Step: 7
Training loss: 0.5545029640197754
Validation loss: 1.9739339351654053

Epoch: 6| Step: 8
Training loss: 0.6719579100608826
Validation loss: 1.9898831248283386

Epoch: 6| Step: 9
Training loss: 1.1666247844696045
Validation loss: 1.9851609071095784

Epoch: 6| Step: 10
Training loss: 0.9655871391296387
Validation loss: 2.029519498348236

Epoch: 6| Step: 11
Training loss: 0.9325489401817322
Validation loss: 1.9839342435201008

Epoch: 6| Step: 12
Training loss: 0.7860763072967529
Validation loss: 2.021791418393453

Epoch: 6| Step: 13
Training loss: 1.3571823835372925
Validation loss: 2.0100823839505515

Epoch: 133| Step: 0
Training loss: 0.3918282091617584
Validation loss: 1.9939961830774944

Epoch: 6| Step: 1
Training loss: 1.017199158668518
Validation loss: 2.1049888134002686

Epoch: 6| Step: 2
Training loss: 0.7590113878250122
Validation loss: 2.00821989774704

Epoch: 6| Step: 3
Training loss: 1.3211370706558228
Validation loss: 2.1039841373761496

Epoch: 6| Step: 4
Training loss: 1.1013550758361816
Validation loss: 2.04566752910614

Epoch: 6| Step: 5
Training loss: 1.0029902458190918
Validation loss: 2.0115407506624856

Epoch: 6| Step: 6
Training loss: 1.3415648937225342
Validation loss: 2.007728616396586

Epoch: 6| Step: 7
Training loss: 0.75644850730896
Validation loss: 1.9542867143948872

Epoch: 6| Step: 8
Training loss: 0.641460657119751
Validation loss: 1.965740402539571

Epoch: 6| Step: 9
Training loss: 1.1628236770629883
Validation loss: 2.0033790667851767

Epoch: 6| Step: 10
Training loss: 0.8042163848876953
Validation loss: 1.9805487791697185

Epoch: 6| Step: 11
Training loss: 0.6296204924583435
Validation loss: 2.040725370248159

Epoch: 6| Step: 12
Training loss: 0.6934018135070801
Validation loss: 2.0117457707722983

Epoch: 6| Step: 13
Training loss: 0.9931244850158691
Validation loss: 2.0346221725145974

Epoch: 134| Step: 0
Training loss: 0.9325835108757019
Validation loss: 2.0051233569780984

Epoch: 6| Step: 1
Training loss: 0.45788371562957764
Validation loss: 2.010588447252909

Epoch: 6| Step: 2
Training loss: 0.7964047193527222
Validation loss: 2.0008919636408486

Epoch: 6| Step: 3
Training loss: 0.5903058648109436
Validation loss: 1.956884543100993

Epoch: 6| Step: 4
Training loss: 1.275874376296997
Validation loss: 1.9643015265464783

Epoch: 6| Step: 5
Training loss: 0.8776389360427856
Validation loss: 1.9934786160786946

Epoch: 6| Step: 6
Training loss: 1.0680363178253174
Validation loss: 1.9452999631563823

Epoch: 6| Step: 7
Training loss: 0.9625003337860107
Validation loss: 2.004492978254954

Epoch: 6| Step: 8
Training loss: 0.6309296488761902
Validation loss: 1.9645281235376995

Epoch: 6| Step: 9
Training loss: 1.234588623046875
Validation loss: 2.0022846460342407

Epoch: 6| Step: 10
Training loss: 0.9343274831771851
Validation loss: 2.017246345678965

Epoch: 6| Step: 11
Training loss: 0.8339977860450745
Validation loss: 1.9734570384025574

Epoch: 6| Step: 12
Training loss: 0.9949123859405518
Validation loss: 1.9680372675259907

Epoch: 6| Step: 13
Training loss: 0.7025611996650696
Validation loss: 1.9952283302942913

Epoch: 135| Step: 0
Training loss: 1.0457465648651123
Validation loss: 1.9878232876459758

Epoch: 6| Step: 1
Training loss: 0.8165618777275085
Validation loss: 1.9674137433369954

Epoch: 6| Step: 2
Training loss: 0.645155668258667
Validation loss: 2.002985497315725

Epoch: 6| Step: 3
Training loss: 0.7132822871208191
Validation loss: 2.004802087942759

Epoch: 6| Step: 4
Training loss: 0.6434365510940552
Validation loss: 1.9938884377479553

Epoch: 6| Step: 5
Training loss: 0.8833138346672058
Validation loss: 2.0158536632855735

Epoch: 6| Step: 6
Training loss: 0.542985737323761
Validation loss: 2.0462729136149087

Epoch: 6| Step: 7
Training loss: 0.6601039171218872
Validation loss: 2.0281113982200623

Epoch: 6| Step: 8
Training loss: 1.3536770343780518
Validation loss: 2.0580910046895347

Epoch: 6| Step: 9
Training loss: 1.2752069234848022
Validation loss: 1.9961108167966206

Epoch: 6| Step: 10
Training loss: 0.43850988149642944
Validation loss: 2.0224396785100303

Epoch: 6| Step: 11
Training loss: 0.9610109925270081
Validation loss: 1.9946661591529846

Epoch: 6| Step: 12
Training loss: 0.8526260256767273
Validation loss: 2.029125392436981

Epoch: 6| Step: 13
Training loss: 1.215120553970337
Validation loss: 1.9866745074590046

Epoch: 136| Step: 0
Training loss: 0.5032816529273987
Validation loss: 2.019631783167521

Epoch: 6| Step: 1
Training loss: 1.0850517749786377
Validation loss: 2.0195958614349365

Epoch: 6| Step: 2
Training loss: 0.966139554977417
Validation loss: 2.0347017447153726

Epoch: 6| Step: 3
Training loss: 0.9343355894088745
Validation loss: 2.044856389363607

Epoch: 6| Step: 4
Training loss: 1.0292572975158691
Validation loss: 2.036662677923838

Epoch: 6| Step: 5
Training loss: 1.1282117366790771
Validation loss: 2.0254679123560586

Epoch: 6| Step: 6
Training loss: 0.844353199005127
Validation loss: 1.991991400718689

Epoch: 6| Step: 7
Training loss: 0.6963542699813843
Validation loss: 2.0545530915260315

Epoch: 6| Step: 8
Training loss: 0.5627450942993164
Validation loss: 2.0444661378860474

Epoch: 6| Step: 9
Training loss: 0.6243410110473633
Validation loss: 2.0621179342269897

Epoch: 6| Step: 10
Training loss: 1.1866763830184937
Validation loss: 2.0441402991612754

Epoch: 6| Step: 11
Training loss: 0.821150541305542
Validation loss: 2.030726691087087

Epoch: 6| Step: 12
Training loss: 0.7460196018218994
Validation loss: 2.037130355834961

Epoch: 6| Step: 13
Training loss: 0.6124061942100525
Validation loss: 2.030218005180359

Epoch: 137| Step: 0
Training loss: 0.6957252025604248
Validation loss: 2.0066768725713096

Epoch: 6| Step: 1
Training loss: 0.7515649795532227
Validation loss: 2.024025797843933

Epoch: 6| Step: 2
Training loss: 0.9775862693786621
Validation loss: 2.00804070631663

Epoch: 6| Step: 3
Training loss: 1.0672234296798706
Validation loss: 2.0207993189493814

Epoch: 6| Step: 4
Training loss: 1.2176549434661865
Validation loss: 1.9980247219403584

Epoch: 6| Step: 5
Training loss: 0.7686961889266968
Validation loss: 1.9677173097928364

Epoch: 6| Step: 6
Training loss: 0.4942660927772522
Validation loss: 1.995891769727071

Epoch: 6| Step: 7
Training loss: 0.5430983304977417
Validation loss: 2.01477845509847

Epoch: 6| Step: 8
Training loss: 0.876966655254364
Validation loss: 2.0060637394587197

Epoch: 6| Step: 9
Training loss: 0.5936306715011597
Validation loss: 2.0368573665618896

Epoch: 6| Step: 10
Training loss: 1.0799250602722168
Validation loss: 2.0374413331349692

Epoch: 6| Step: 11
Training loss: 1.3004745244979858
Validation loss: 2.0022568106651306

Epoch: 6| Step: 12
Training loss: 0.5806117057800293
Validation loss: 2.0043460726737976

Epoch: 6| Step: 13
Training loss: 0.9315146207809448
Validation loss: 1.9490105112393696

Epoch: 138| Step: 0
Training loss: 0.6675261855125427
Validation loss: 1.9998925725619

Epoch: 6| Step: 1
Training loss: 0.523318350315094
Validation loss: 1.9573192596435547

Epoch: 6| Step: 2
Training loss: 0.9447062015533447
Validation loss: 2.0215835571289062

Epoch: 6| Step: 3
Training loss: 0.7941182255744934
Validation loss: 1.9507652123769124

Epoch: 6| Step: 4
Training loss: 0.37142398953437805
Validation loss: 2.045882225036621

Epoch: 6| Step: 5
Training loss: 0.9830723404884338
Validation loss: 2.0337162613868713

Epoch: 6| Step: 6
Training loss: 0.7168012261390686
Validation loss: 2.0732265512148538

Epoch: 6| Step: 7
Training loss: 1.3721929788589478
Validation loss: 2.014131546020508

Epoch: 6| Step: 8
Training loss: 0.8450361490249634
Validation loss: 2.0029263297716775

Epoch: 6| Step: 9
Training loss: 0.7698248624801636
Validation loss: 2.0061410466829934

Epoch: 6| Step: 10
Training loss: 0.5951443314552307
Validation loss: 2.014516909917196

Epoch: 6| Step: 11
Training loss: 1.0108873844146729
Validation loss: 2.0177412629127502

Epoch: 6| Step: 12
Training loss: 1.060973048210144
Validation loss: 2.0438233613967896

Epoch: 6| Step: 13
Training loss: 0.8132407665252686
Validation loss: 2.053940753142039

Epoch: 139| Step: 0
Training loss: 0.9360107779502869
Validation loss: 2.056355873743693

Epoch: 6| Step: 1
Training loss: 1.2137185335159302
Validation loss: 2.0438783168792725

Epoch: 6| Step: 2
Training loss: 0.9326150417327881
Validation loss: 2.051695942878723

Epoch: 6| Step: 3
Training loss: 0.9369825124740601
Validation loss: 2.029807766278585

Epoch: 6| Step: 4
Training loss: 0.8499745726585388
Validation loss: 1.9932464559872944

Epoch: 6| Step: 5
Training loss: 0.9726564884185791
Validation loss: 2.028642396132151

Epoch: 6| Step: 6
Training loss: 0.8726679682731628
Validation loss: 1.9563120404879253

Epoch: 6| Step: 7
Training loss: 0.7187491059303284
Validation loss: 2.040309250354767

Epoch: 6| Step: 8
Training loss: 1.3452283143997192
Validation loss: 1.9947292009989421

Epoch: 6| Step: 9
Training loss: 0.47961199283599854
Validation loss: 2.0343064069747925

Epoch: 6| Step: 10
Training loss: 0.9523911476135254
Validation loss: 2.0777568022410073

Epoch: 6| Step: 11
Training loss: 0.6178972721099854
Validation loss: 2.0873510241508484

Epoch: 6| Step: 12
Training loss: 0.723076581954956
Validation loss: 2.0568814873695374

Epoch: 6| Step: 13
Training loss: 0.5882483720779419
Validation loss: 2.0288160840670266

Epoch: 140| Step: 0
Training loss: 0.6223962306976318
Validation loss: 1.9555543462435405

Epoch: 6| Step: 1
Training loss: 1.0027738809585571
Validation loss: 1.9809006849924724

Epoch: 6| Step: 2
Training loss: 0.7239733338356018
Validation loss: 1.9767513275146484

Epoch: 6| Step: 3
Training loss: 1.106476068496704
Validation loss: 1.9581281145413716

Epoch: 6| Step: 4
Training loss: 0.8116737008094788
Validation loss: 1.9491660197575886

Epoch: 6| Step: 5
Training loss: 0.5183716416358948
Validation loss: 1.999500572681427

Epoch: 6| Step: 6
Training loss: 0.730267345905304
Validation loss: 2.0451536973317466

Epoch: 6| Step: 7
Training loss: 0.8241037130355835
Validation loss: 2.006454885005951

Epoch: 6| Step: 8
Training loss: 1.0547919273376465
Validation loss: 2.013562242190043

Epoch: 6| Step: 9
Training loss: 0.8852695226669312
Validation loss: 2.0339694817860923

Epoch: 6| Step: 10
Training loss: 0.6382861137390137
Validation loss: 2.059003174304962

Epoch: 6| Step: 11
Training loss: 1.040977954864502
Validation loss: 2.000930070877075

Epoch: 6| Step: 12
Training loss: 0.6214714646339417
Validation loss: 2.0023722847302756

Epoch: 6| Step: 13
Training loss: 0.9169120788574219
Validation loss: 1.9866682489713032

Epoch: 141| Step: 0
Training loss: 0.6838166117668152
Validation loss: 2.013154149055481

Epoch: 6| Step: 1
Training loss: 0.7645354866981506
Validation loss: 2.0141457517941794

Epoch: 6| Step: 2
Training loss: 1.3858749866485596
Validation loss: 1.9803430636723836

Epoch: 6| Step: 3
Training loss: 1.132918119430542
Validation loss: 1.9964371522267659

Epoch: 6| Step: 4
Training loss: 0.6191756725311279
Validation loss: 1.9940845767656963

Epoch: 6| Step: 5
Training loss: 0.7256444692611694
Validation loss: 2.050006707509359

Epoch: 6| Step: 6
Training loss: 1.0580155849456787
Validation loss: 2.0396914879480996

Epoch: 6| Step: 7
Training loss: 0.9315893650054932
Validation loss: 2.0424468914667764

Epoch: 6| Step: 8
Training loss: 0.8124169707298279
Validation loss: 2.0015594164530435

Epoch: 6| Step: 9
Training loss: 0.37078559398651123
Validation loss: 2.023215373357137

Epoch: 6| Step: 10
Training loss: 0.5523226261138916
Validation loss: 1.9726778070131938

Epoch: 6| Step: 11
Training loss: 0.8351181745529175
Validation loss: 1.9660959641138713

Epoch: 6| Step: 12
Training loss: 0.5669645667076111
Validation loss: 1.943920413653056

Epoch: 6| Step: 13
Training loss: 0.9500092267990112
Validation loss: 1.9754143754641216

Epoch: 142| Step: 0
Training loss: 0.8009942770004272
Validation loss: 1.9817977945009868

Epoch: 6| Step: 1
Training loss: 1.0941411256790161
Validation loss: 1.964761734008789

Epoch: 6| Step: 2
Training loss: 0.897880494594574
Validation loss: 2.012548247973124

Epoch: 6| Step: 3
Training loss: 0.6522707939147949
Validation loss: 2.038928190867106

Epoch: 6| Step: 4
Training loss: 1.1726641654968262
Validation loss: 2.0085704922676086

Epoch: 6| Step: 5
Training loss: 0.7996032238006592
Validation loss: 2.0062086383501687

Epoch: 6| Step: 6
Training loss: 1.1363602876663208
Validation loss: 1.9934994578361511

Epoch: 6| Step: 7
Training loss: 0.30681073665618896
Validation loss: 2.0427534778912864

Epoch: 6| Step: 8
Training loss: 0.6515467166900635
Validation loss: 1.9705362518628438

Epoch: 6| Step: 9
Training loss: 1.4591952562332153
Validation loss: 1.9848714272181194

Epoch: 6| Step: 10
Training loss: 0.8826984167098999
Validation loss: 1.9400060375531514

Epoch: 6| Step: 11
Training loss: 0.29261571168899536
Validation loss: 1.9660786787668865

Epoch: 6| Step: 12
Training loss: 0.6519194841384888
Validation loss: 2.0066367785135903

Epoch: 6| Step: 13
Training loss: 0.9225775003433228
Validation loss: 1.953115959962209

Epoch: 143| Step: 0
Training loss: 0.5126529932022095
Validation loss: 1.9960502584775288

Epoch: 6| Step: 1
Training loss: 0.4603181779384613
Validation loss: 1.979235331217448

Epoch: 6| Step: 2
Training loss: 0.9920424222946167
Validation loss: 2.0193883776664734

Epoch: 6| Step: 3
Training loss: 0.8540692329406738
Validation loss: 2.0341503620147705

Epoch: 6| Step: 4
Training loss: 0.925538182258606
Validation loss: 1.997873306274414

Epoch: 6| Step: 5
Training loss: 0.7124990224838257
Validation loss: 1.9845056732495625

Epoch: 6| Step: 6
Training loss: 0.790172815322876
Validation loss: 1.9493876099586487

Epoch: 6| Step: 7
Training loss: 0.8264256119728088
Validation loss: 1.9875526626904805

Epoch: 6| Step: 8
Training loss: 0.846846342086792
Validation loss: 1.9260382850964863

Epoch: 6| Step: 9
Training loss: 1.1991748809814453
Validation loss: 1.9668137232462566

Epoch: 6| Step: 10
Training loss: 0.7967766523361206
Validation loss: 1.9931559562683105

Epoch: 6| Step: 11
Training loss: 0.5692547559738159
Validation loss: 2.0011717081069946

Epoch: 6| Step: 12
Training loss: 0.663649320602417
Validation loss: 2.0584277908007302

Epoch: 6| Step: 13
Training loss: 1.0434727668762207
Validation loss: 2.0369577407836914

Epoch: 144| Step: 0
Training loss: 0.6482353210449219
Validation loss: 2.0437786181767783

Epoch: 6| Step: 1
Training loss: 0.8751850724220276
Validation loss: 1.9979645411173503

Epoch: 6| Step: 2
Training loss: 1.235807180404663
Validation loss: 1.9956791798273723

Epoch: 6| Step: 3
Training loss: 0.8725305795669556
Validation loss: 2.013251701990763

Epoch: 6| Step: 4
Training loss: 0.5131124258041382
Validation loss: 2.016489406426748

Epoch: 6| Step: 5
Training loss: 0.48074185848236084
Validation loss: 2.0079933404922485

Epoch: 6| Step: 6
Training loss: 0.9175721406936646
Validation loss: 2.0029064814249673

Epoch: 6| Step: 7
Training loss: 0.9380893707275391
Validation loss: 2.0109989444414773

Epoch: 6| Step: 8
Training loss: 0.38850581645965576
Validation loss: 2.0262065728505454

Epoch: 6| Step: 9
Training loss: 0.7220076322555542
Validation loss: 2.0259039203325906

Epoch: 6| Step: 10
Training loss: 0.7030822038650513
Validation loss: 2.0048953692118325

Epoch: 6| Step: 11
Training loss: 0.5408239960670471
Validation loss: 2.0597711205482483

Epoch: 6| Step: 12
Training loss: 1.2381455898284912
Validation loss: 1.932870368162791

Epoch: 6| Step: 13
Training loss: 0.9291313290596008
Validation loss: 1.9897194504737854

Epoch: 145| Step: 0
Training loss: 0.6060019135475159
Validation loss: 1.9509537021319072

Epoch: 6| Step: 1
Training loss: 0.5810930728912354
Validation loss: 2.004586100578308

Epoch: 6| Step: 2
Training loss: 0.7698908448219299
Validation loss: 1.9770610928535461

Epoch: 6| Step: 3
Training loss: 0.6674951910972595
Validation loss: 2.0540388425191245

Epoch: 6| Step: 4
Training loss: 0.6965405344963074
Validation loss: 2.0258400440216064

Epoch: 6| Step: 5
Training loss: 0.5987167358398438
Validation loss: 1.983050545056661

Epoch: 6| Step: 6
Training loss: 0.8449369072914124
Validation loss: 1.9612849553426106

Epoch: 6| Step: 7
Training loss: 0.9280174374580383
Validation loss: 1.9998912612597148

Epoch: 6| Step: 8
Training loss: 0.38685667514801025
Validation loss: 1.974437137444814

Epoch: 6| Step: 9
Training loss: 1.11299467086792
Validation loss: 2.0208662947018943

Epoch: 6| Step: 10
Training loss: 0.5439360737800598
Validation loss: 2.0247048338254294

Epoch: 6| Step: 11
Training loss: 1.1072790622711182
Validation loss: 1.990026851495107

Epoch: 6| Step: 12
Training loss: 1.0531840324401855
Validation loss: 2.026252031326294

Epoch: 6| Step: 13
Training loss: 0.8707778453826904
Validation loss: 2.0407049854596457

Epoch: 146| Step: 0
Training loss: 0.4633626341819763
Validation loss: 1.9754633506139119

Epoch: 6| Step: 1
Training loss: 1.0242254734039307
Validation loss: 1.9892693559328716

Epoch: 6| Step: 2
Training loss: 1.281217098236084
Validation loss: 1.9834989706675212

Epoch: 6| Step: 3
Training loss: 0.5479333400726318
Validation loss: 1.9904446005821228

Epoch: 6| Step: 4
Training loss: 0.9392108917236328
Validation loss: 2.001374344031016

Epoch: 6| Step: 5
Training loss: 0.8743783831596375
Validation loss: 2.048219164212545

Epoch: 6| Step: 6
Training loss: 0.7624942064285278
Validation loss: 2.0395966172218323

Epoch: 6| Step: 7
Training loss: 0.7062746286392212
Validation loss: 2.02972404162089

Epoch: 6| Step: 8
Training loss: 0.5155796408653259
Validation loss: 2.0352348685264587

Epoch: 6| Step: 9
Training loss: 0.9759159088134766
Validation loss: 2.0306628743807473

Epoch: 6| Step: 10
Training loss: 0.7196249961853027
Validation loss: 1.9617014527320862

Epoch: 6| Step: 11
Training loss: 0.5270262956619263
Validation loss: 2.016946872075399

Epoch: 6| Step: 12
Training loss: 0.6666364669799805
Validation loss: 2.031544029712677

Epoch: 6| Step: 13
Training loss: 0.7831891179084778
Validation loss: 2.010314404964447

Epoch: 147| Step: 0
Training loss: 0.6614928841590881
Validation loss: 2.013285299142202

Epoch: 6| Step: 1
Training loss: 1.1487503051757812
Validation loss: 2.04635351896286

Epoch: 6| Step: 2
Training loss: 0.650566577911377
Validation loss: 2.0261912743250527

Epoch: 6| Step: 3
Training loss: 0.5050147771835327
Validation loss: 2.0427807768185935

Epoch: 6| Step: 4
Training loss: 0.6716824769973755
Validation loss: 2.036317686239878

Epoch: 6| Step: 5
Training loss: 1.0118730068206787
Validation loss: 2.0897995233535767

Epoch: 6| Step: 6
Training loss: 0.9824816584587097
Validation loss: 2.073945681254069

Epoch: 6| Step: 7
Training loss: 0.7752402424812317
Validation loss: 1.962962547938029

Epoch: 6| Step: 8
Training loss: 1.012751817703247
Validation loss: 2.018214682737986

Epoch: 6| Step: 9
Training loss: 0.7711697816848755
Validation loss: 2.060763736565908

Epoch: 6| Step: 10
Training loss: 0.2338470220565796
Validation loss: 2.0900332927703857

Epoch: 6| Step: 11
Training loss: 0.6530539989471436
Validation loss: 2.111840387185415

Epoch: 6| Step: 12
Training loss: 1.141502022743225
Validation loss: 2.0862239599227905

Epoch: 6| Step: 13
Training loss: 0.7556014060974121
Validation loss: 2.0275519490242004

Epoch: 148| Step: 0
Training loss: 0.6089657545089722
Validation loss: 2.0450541178385415

Epoch: 6| Step: 1
Training loss: 0.5027761459350586
Validation loss: 2.0020546515782676

Epoch: 6| Step: 2
Training loss: 0.7207514047622681
Validation loss: 2.006132165590922

Epoch: 6| Step: 3
Training loss: 0.8697181344032288
Validation loss: 1.9927641948064168

Epoch: 6| Step: 4
Training loss: 0.8162855505943298
Validation loss: 1.976279377937317

Epoch: 6| Step: 5
Training loss: 0.5263835191726685
Validation loss: 2.019984404246012

Epoch: 6| Step: 6
Training loss: 0.9097402691841125
Validation loss: 2.0380102396011353

Epoch: 6| Step: 7
Training loss: 0.6291009187698364
Validation loss: 2.0262398719787598

Epoch: 6| Step: 8
Training loss: 0.5957940816879272
Validation loss: 2.0394893288612366

Epoch: 6| Step: 9
Training loss: 1.3318034410476685
Validation loss: 2.022434671719869

Epoch: 6| Step: 10
Training loss: 0.9029293060302734
Validation loss: 2.05178956190745

Epoch: 6| Step: 11
Training loss: 0.3877685070037842
Validation loss: 2.0193973382314048

Epoch: 6| Step: 12
Training loss: 1.4013032913208008
Validation loss: 2.059339682261149

Epoch: 6| Step: 13
Training loss: 0.7400655150413513
Validation loss: 2.0320560733477273

Epoch: 149| Step: 0
Training loss: 0.7043774127960205
Validation loss: 2.026155948638916

Epoch: 6| Step: 1
Training loss: 0.696768045425415
Validation loss: 2.050949056943258

Epoch: 6| Step: 2
Training loss: 0.5089779496192932
Validation loss: 2.055473029613495

Epoch: 6| Step: 3
Training loss: 0.8036699295043945
Validation loss: 2.0279070138931274

Epoch: 6| Step: 4
Training loss: 0.9347944855690002
Validation loss: 2.063598414262136

Epoch: 6| Step: 5
Training loss: 0.7473300695419312
Validation loss: 2.021179715792338

Epoch: 6| Step: 6
Training loss: 0.9693833589553833
Validation loss: 2.020363767941793

Epoch: 6| Step: 7
Training loss: 0.6020185351371765
Validation loss: 1.9937010804812114

Epoch: 6| Step: 8
Training loss: 1.0393788814544678
Validation loss: 2.0278260707855225

Epoch: 6| Step: 9
Training loss: 0.47185519337654114
Validation loss: 2.0025097330411277

Epoch: 6| Step: 10
Training loss: 0.9520140886306763
Validation loss: 2.028419852256775

Epoch: 6| Step: 11
Training loss: 0.6466535329818726
Validation loss: 2.0253682732582092

Epoch: 6| Step: 12
Training loss: 0.6998074054718018
Validation loss: 2.041516919930776

Epoch: 6| Step: 13
Training loss: 0.7142078876495361
Validation loss: 2.074871281782786

Epoch: 150| Step: 0
Training loss: 0.6382827758789062
Validation loss: 2.0568772554397583

Epoch: 6| Step: 1
Training loss: 0.6293129324913025
Validation loss: 2.011976341406504

Epoch: 6| Step: 2
Training loss: 1.1418040990829468
Validation loss: 2.0184582074483237

Epoch: 6| Step: 3
Training loss: 0.6004488468170166
Validation loss: 2.0372354388237

Epoch: 6| Step: 4
Training loss: 1.073318362236023
Validation loss: 1.9917181531588237

Epoch: 6| Step: 5
Training loss: 0.5453475713729858
Validation loss: 2.022793094317118

Epoch: 6| Step: 6
Training loss: 0.9950593113899231
Validation loss: 1.9998151063919067

Epoch: 6| Step: 7
Training loss: 0.5076858401298523
Validation loss: 1.989386300245921

Epoch: 6| Step: 8
Training loss: 0.6162788271903992
Validation loss: 2.011857330799103

Epoch: 6| Step: 9
Training loss: 0.7511489391326904
Validation loss: 2.0617584387461343

Epoch: 6| Step: 10
Training loss: 0.3903977870941162
Validation loss: 2.0648452838261924

Epoch: 6| Step: 11
Training loss: 0.5234555006027222
Validation loss: 2.058545708656311

Epoch: 6| Step: 12
Training loss: 1.659308910369873
Validation loss: 2.081187129020691

Epoch: 6| Step: 13
Training loss: 0.5911034345626831
Validation loss: 2.0516620675722756

Epoch: 151| Step: 0
Training loss: 0.6421006321907043
Validation loss: 2.024602254231771

Epoch: 6| Step: 1
Training loss: 0.7312413454055786
Validation loss: 1.9952267011006672

Epoch: 6| Step: 2
Training loss: 0.5797573924064636
Validation loss: 1.9611470500628154

Epoch: 6| Step: 3
Training loss: 1.048336386680603
Validation loss: 1.9866786003112793

Epoch: 6| Step: 4
Training loss: 0.7591946125030518
Validation loss: 1.9788506428400676

Epoch: 6| Step: 5
Training loss: 0.3124525547027588
Validation loss: 1.9932728211085002

Epoch: 6| Step: 6
Training loss: 0.9332420825958252
Validation loss: 2.0173328518867493

Epoch: 6| Step: 7
Training loss: 0.8187364935874939
Validation loss: 2.06364115079244

Epoch: 6| Step: 8
Training loss: 0.991544246673584
Validation loss: 1.963814338048299

Epoch: 6| Step: 9
Training loss: 0.5773431062698364
Validation loss: 1.948358674844106

Epoch: 6| Step: 10
Training loss: 0.9749478697776794
Validation loss: 1.95199054479599

Epoch: 6| Step: 11
Training loss: 0.7811069488525391
Validation loss: 1.9654794732729595

Epoch: 6| Step: 12
Training loss: 0.7362818717956543
Validation loss: 1.9645696878433228

Epoch: 6| Step: 13
Training loss: 0.9049545526504517
Validation loss: 1.983737011750539

Epoch: 152| Step: 0
Training loss: 0.6263667345046997
Validation loss: 2.0041556358337402

Epoch: 6| Step: 1
Training loss: 0.42257630825042725
Validation loss: 2.009947419166565

Epoch: 6| Step: 2
Training loss: 0.9920276403427124
Validation loss: 2.011673112710317

Epoch: 6| Step: 3
Training loss: 0.5157589316368103
Validation loss: 2.0099136432011924

Epoch: 6| Step: 4
Training loss: 1.4780128002166748
Validation loss: 2.029928763707479

Epoch: 6| Step: 5
Training loss: 0.6391440033912659
Validation loss: 2.0463682413101196

Epoch: 6| Step: 6
Training loss: 0.7853448390960693
Validation loss: 1.9818004965782166

Epoch: 6| Step: 7
Training loss: 0.9003872871398926
Validation loss: 1.9933231671651204

Epoch: 6| Step: 8
Training loss: 0.54534912109375
Validation loss: 1.9693552056948345

Epoch: 6| Step: 9
Training loss: 0.45622092485427856
Validation loss: 1.9575133721033733

Epoch: 6| Step: 10
Training loss: 0.8709249496459961
Validation loss: 2.016786595185598

Epoch: 6| Step: 11
Training loss: 0.8581045269966125
Validation loss: 2.0196172992388406

Epoch: 6| Step: 12
Training loss: 0.9114810824394226
Validation loss: 2.0050047834714255

Epoch: 6| Step: 13
Training loss: 0.3741382360458374
Validation loss: 2.0210840702056885

Epoch: 153| Step: 0
Training loss: 0.3485807180404663
Validation loss: 1.975773294766744

Epoch: 6| Step: 1
Training loss: 0.8546645641326904
Validation loss: 2.0060691038767495

Epoch: 6| Step: 2
Training loss: 0.7971616983413696
Validation loss: 2.0314314365386963

Epoch: 6| Step: 3
Training loss: 0.7050987482070923
Validation loss: 1.9775143265724182

Epoch: 6| Step: 4
Training loss: 1.3483130931854248
Validation loss: 1.9961995879809062

Epoch: 6| Step: 5
Training loss: 0.8422000408172607
Validation loss: 1.9858761231104534

Epoch: 6| Step: 6
Training loss: 1.0429749488830566
Validation loss: 2.031729221343994

Epoch: 6| Step: 7
Training loss: 0.5493861436843872
Validation loss: 1.9892319242159526

Epoch: 6| Step: 8
Training loss: 0.6899613738059998
Validation loss: 1.9803214073181152

Epoch: 6| Step: 9
Training loss: 0.5621069669723511
Validation loss: 1.981075644493103

Epoch: 6| Step: 10
Training loss: 0.6155371069908142
Validation loss: 2.0215093890825906

Epoch: 6| Step: 11
Training loss: 0.6506026983261108
Validation loss: 2.021074096361796

Epoch: 6| Step: 12
Training loss: 0.6238124370574951
Validation loss: 2.0292745431264243

Epoch: 6| Step: 13
Training loss: 0.566144585609436
Validation loss: 1.9514421820640564

Epoch: 154| Step: 0
Training loss: 0.37269315123558044
Validation loss: 1.97917244831721

Epoch: 6| Step: 1
Training loss: 0.9296659231185913
Validation loss: 1.9704447189966838

Epoch: 6| Step: 2
Training loss: 0.4361414611339569
Validation loss: 1.9908356070518494

Epoch: 6| Step: 3
Training loss: 0.5871084928512573
Validation loss: 1.990909218788147

Epoch: 6| Step: 4
Training loss: 0.4961392283439636
Validation loss: 2.0159225463867188

Epoch: 6| Step: 5
Training loss: 0.9226308465003967
Validation loss: 1.989294171333313

Epoch: 6| Step: 6
Training loss: 0.556367039680481
Validation loss: 2.0013708074887595

Epoch: 6| Step: 7
Training loss: 1.2605973482131958
Validation loss: 1.9550440510114033

Epoch: 6| Step: 8
Training loss: 0.8827431201934814
Validation loss: 1.9505847295125325

Epoch: 6| Step: 9
Training loss: 1.2768661975860596
Validation loss: 2.0132413307825723

Epoch: 6| Step: 10
Training loss: 0.7669119834899902
Validation loss: 1.9806492924690247

Epoch: 6| Step: 11
Training loss: 0.2560386657714844
Validation loss: 2.004574398199717

Epoch: 6| Step: 12
Training loss: 0.5844469666481018
Validation loss: 1.9834543863932292

Epoch: 6| Step: 13
Training loss: 0.4506629705429077
Validation loss: 1.9939985871315002

Epoch: 155| Step: 0
Training loss: 0.6993120908737183
Validation loss: 2.0068738063176474

Epoch: 6| Step: 1
Training loss: 0.7081953287124634
Validation loss: 2.010775605837504

Epoch: 6| Step: 2
Training loss: 0.38541197776794434
Validation loss: 2.073480208714803

Epoch: 6| Step: 3
Training loss: 0.9772858023643494
Validation loss: 2.0613213181495667

Epoch: 6| Step: 4
Training loss: 0.8077420592308044
Validation loss: 2.0232526063919067

Epoch: 6| Step: 5
Training loss: 0.646273672580719
Validation loss: 2.030219038327535

Epoch: 6| Step: 6
Training loss: 0.8033600449562073
Validation loss: 2.0147594014803567

Epoch: 6| Step: 7
Training loss: 0.5363269448280334
Validation loss: 2.0215795437494912

Epoch: 6| Step: 8
Training loss: 0.480566143989563
Validation loss: 1.9558775623639424

Epoch: 6| Step: 9
Training loss: 0.5319647192955017
Validation loss: 2.0076854626337686

Epoch: 6| Step: 10
Training loss: 0.7684500217437744
Validation loss: 2.0025465289751687

Epoch: 6| Step: 11
Training loss: 0.9169503450393677
Validation loss: 2.0166295965512595

Epoch: 6| Step: 12
Training loss: 1.0685689449310303
Validation loss: 2.0378271341323853

Epoch: 6| Step: 13
Training loss: 0.6438195705413818
Validation loss: 2.0731284618377686

Epoch: 156| Step: 0
Training loss: 0.6232650876045227
Validation loss: 2.027404268582662

Epoch: 6| Step: 1
Training loss: 0.5420575141906738
Validation loss: 2.010428786277771

Epoch: 6| Step: 2
Training loss: 0.2942223846912384
Validation loss: 1.9725253184636433

Epoch: 6| Step: 3
Training loss: 0.6958739161491394
Validation loss: 2.02547017733256

Epoch: 6| Step: 4
Training loss: 0.49752077460289
Validation loss: 2.0452389121055603

Epoch: 6| Step: 5
Training loss: 0.7164216041564941
Validation loss: 2.0123496651649475

Epoch: 6| Step: 6
Training loss: 0.8067731857299805
Validation loss: 2.0077329675356546

Epoch: 6| Step: 7
Training loss: 0.4218122959136963
Validation loss: 2.0088818470637

Epoch: 6| Step: 8
Training loss: 0.3469790816307068
Validation loss: 2.062539597352346

Epoch: 6| Step: 9
Training loss: 0.8614871501922607
Validation loss: 2.0172627170880637

Epoch: 6| Step: 10
Training loss: 1.0205161571502686
Validation loss: 2.0365783174832663

Epoch: 6| Step: 11
Training loss: 1.824486494064331
Validation loss: 2.0120871861775718

Epoch: 6| Step: 12
Training loss: 0.628013551235199
Validation loss: 2.065538247426351

Epoch: 6| Step: 13
Training loss: 0.5942981839179993
Validation loss: 2.0226162473360696

Epoch: 157| Step: 0
Training loss: 0.9970682859420776
Validation loss: 1.9840545256932576

Epoch: 6| Step: 1
Training loss: 0.6390622854232788
Validation loss: 1.9697164297103882

Epoch: 6| Step: 2
Training loss: 0.43874961137771606
Validation loss: 1.923843522866567

Epoch: 6| Step: 3
Training loss: 0.7030132412910461
Validation loss: 1.9520398775736492

Epoch: 6| Step: 4
Training loss: 1.0271601676940918
Validation loss: 1.9314563274383545

Epoch: 6| Step: 5
Training loss: 0.4153110980987549
Validation loss: 1.963476538658142

Epoch: 6| Step: 6
Training loss: 0.42844006419181824
Validation loss: 1.9740872184435527

Epoch: 6| Step: 7
Training loss: 0.9278445243835449
Validation loss: 2.017190853754679

Epoch: 6| Step: 8
Training loss: 0.6170922517776489
Validation loss: 2.0771379868189492

Epoch: 6| Step: 9
Training loss: 0.8321045637130737
Validation loss: 2.066754102706909

Epoch: 6| Step: 10
Training loss: 0.8824005126953125
Validation loss: 2.10377836227417

Epoch: 6| Step: 11
Training loss: 0.9946033954620361
Validation loss: 2.052848140398661

Epoch: 6| Step: 12
Training loss: 0.7535420656204224
Validation loss: 1.9913286368052165

Epoch: 6| Step: 13
Training loss: 0.6862702369689941
Validation loss: 1.9543921550114949

Epoch: 158| Step: 0
Training loss: 0.7332308292388916
Validation loss: 1.9774391452471416

Epoch: 6| Step: 1
Training loss: 1.1201848983764648
Validation loss: 1.9805924892425537

Epoch: 6| Step: 2
Training loss: 0.7962011098861694
Validation loss: 1.9885029196739197

Epoch: 6| Step: 3
Training loss: 0.7693370580673218
Validation loss: 2.0019476612408957

Epoch: 6| Step: 4
Training loss: 1.0298190116882324
Validation loss: 2.003942926724752

Epoch: 6| Step: 5
Training loss: 0.5533748269081116
Validation loss: 2.0094175338745117

Epoch: 6| Step: 6
Training loss: 0.7922090291976929
Validation loss: 2.020079771677653

Epoch: 6| Step: 7
Training loss: 0.6433569192886353
Validation loss: 2.0385008255640664

Epoch: 6| Step: 8
Training loss: 0.6261225938796997
Validation loss: 2.0805220007896423

Epoch: 6| Step: 9
Training loss: 0.34647107124328613
Validation loss: 2.048339307308197

Epoch: 6| Step: 10
Training loss: 0.6083796620368958
Validation loss: 2.034469485282898

Epoch: 6| Step: 11
Training loss: 1.4489855766296387
Validation loss: 2.0916878978411355

Epoch: 6| Step: 12
Training loss: 0.6683438420295715
Validation loss: 2.056873937447866

Epoch: 6| Step: 13
Training loss: 0.6006530523300171
Validation loss: 2.0226144790649414

Epoch: 159| Step: 0
Training loss: 0.8363938331604004
Validation loss: 1.956122895081838

Epoch: 6| Step: 1
Training loss: 0.7511717081069946
Validation loss: 2.0189151962598166

Epoch: 6| Step: 2
Training loss: 0.5527695417404175
Validation loss: 1.996113657951355

Epoch: 6| Step: 3
Training loss: 0.7869668006896973
Validation loss: 1.956543465455373

Epoch: 6| Step: 4
Training loss: 0.698036789894104
Validation loss: 1.973421573638916

Epoch: 6| Step: 5
Training loss: 0.5483144521713257
Validation loss: 1.969095766544342

Epoch: 6| Step: 6
Training loss: 0.8739813566207886
Validation loss: 2.0070201555887857

Epoch: 6| Step: 7
Training loss: 0.6680904626846313
Validation loss: 2.0566020806630454

Epoch: 6| Step: 8
Training loss: 0.5666480660438538
Validation loss: 2.0222312609354653

Epoch: 6| Step: 9
Training loss: 0.7820858955383301
Validation loss: 1.9809234340985615

Epoch: 6| Step: 10
Training loss: 0.366128146648407
Validation loss: 1.9816276828447978

Epoch: 6| Step: 11
Training loss: 0.9553054571151733
Validation loss: 1.9615001678466797

Epoch: 6| Step: 12
Training loss: 0.7352911233901978
Validation loss: 1.9776331583658855

Epoch: 6| Step: 13
Training loss: 0.6707176566123962
Validation loss: 2.0143551429112754

Epoch: 160| Step: 0
Training loss: 0.6349230408668518
Validation loss: 1.9869790275891621

Epoch: 6| Step: 1
Training loss: 0.42664194107055664
Validation loss: 2.019376834233602

Epoch: 6| Step: 2
Training loss: 0.6918296813964844
Validation loss: 2.062020937601725

Epoch: 6| Step: 3
Training loss: 1.6096141338348389
Validation loss: 2.0507695078849792

Epoch: 6| Step: 4
Training loss: 0.8714515566825867
Validation loss: 2.0691165725390115

Epoch: 6| Step: 5
Training loss: 0.5218095183372498
Validation loss: 2.0152517557144165

Epoch: 6| Step: 6
Training loss: 0.47393161058425903
Validation loss: 2.0277518232663474

Epoch: 6| Step: 7
Training loss: 0.6992172598838806
Validation loss: 1.9590813517570496

Epoch: 6| Step: 8
Training loss: 0.5935143232345581
Validation loss: 1.973210076491038

Epoch: 6| Step: 9
Training loss: 0.41724100708961487
Validation loss: 1.9965359965960185

Epoch: 6| Step: 10
Training loss: 0.6486828327178955
Validation loss: 1.9644960363705952

Epoch: 6| Step: 11
Training loss: 0.7563115358352661
Validation loss: 1.9738689064979553

Epoch: 6| Step: 12
Training loss: 0.813149631023407
Validation loss: 1.9851996501286824

Epoch: 6| Step: 13
Training loss: 0.6040762662887573
Validation loss: 2.062858541806539

Epoch: 161| Step: 0
Training loss: 0.3271322250366211
Validation loss: 2.0348685582478843

Epoch: 6| Step: 1
Training loss: 0.5989816784858704
Validation loss: 2.046966075897217

Epoch: 6| Step: 2
Training loss: 0.7750294208526611
Validation loss: 2.0404669046401978

Epoch: 6| Step: 3
Training loss: 1.1495622396469116
Validation loss: 2.0057325959205627

Epoch: 6| Step: 4
Training loss: 0.4290698170661926
Validation loss: 1.934751292069753

Epoch: 6| Step: 5
Training loss: 0.8451319932937622
Validation loss: 1.9764740864435832

Epoch: 6| Step: 6
Training loss: 0.8127867579460144
Validation loss: 1.978935718536377

Epoch: 6| Step: 7
Training loss: 0.47807711362838745
Validation loss: 2.032019555568695

Epoch: 6| Step: 8
Training loss: 0.7092317342758179
Validation loss: 2.0275001327196756

Epoch: 6| Step: 9
Training loss: 0.6972191333770752
Validation loss: 1.995907763640086

Epoch: 6| Step: 10
Training loss: 1.0987329483032227
Validation loss: 2.0355493426322937

Epoch: 6| Step: 11
Training loss: 0.28914839029312134
Validation loss: 2.0663192669550576

Epoch: 6| Step: 12
Training loss: 0.6294372081756592
Validation loss: 2.03571480512619

Epoch: 6| Step: 13
Training loss: 0.6116073131561279
Validation loss: 1.9924981196721394

Epoch: 162| Step: 0
Training loss: 0.34105223417282104
Validation loss: 1.9690823157628377

Epoch: 6| Step: 1
Training loss: 0.9896849989891052
Validation loss: 1.9742756684621174

Epoch: 6| Step: 2
Training loss: 0.8201475143432617
Validation loss: 2.0277229150136313

Epoch: 6| Step: 3
Training loss: 0.5481730699539185
Validation loss: 1.9858184655507405

Epoch: 6| Step: 4
Training loss: 0.8571625351905823
Validation loss: 1.9328529834747314

Epoch: 6| Step: 5
Training loss: 0.7026267051696777
Validation loss: 2.0493028362592063

Epoch: 6| Step: 6
Training loss: 0.7692121267318726
Validation loss: 2.030631502469381

Epoch: 6| Step: 7
Training loss: 0.9108240604400635
Validation loss: 2.0078100760777793

Epoch: 6| Step: 8
Training loss: 0.6631697416305542
Validation loss: 2.0148807168006897

Epoch: 6| Step: 9
Training loss: 0.5530942678451538
Validation loss: 1.984872857729594

Epoch: 6| Step: 10
Training loss: 0.41692453622817993
Validation loss: 1.9923592805862427

Epoch: 6| Step: 11
Training loss: 0.6547788977622986
Validation loss: 1.9795166452725728

Epoch: 6| Step: 12
Training loss: 0.5584511756896973
Validation loss: 1.9888235330581665

Epoch: 6| Step: 13
Training loss: 0.5471844673156738
Validation loss: 2.0372923016548157

Epoch: 163| Step: 0
Training loss: 0.5927086472511292
Validation loss: 2.0133678714434304

Epoch: 6| Step: 1
Training loss: 0.9157845377922058
Validation loss: 2.026304086049398

Epoch: 6| Step: 2
Training loss: 0.5214872360229492
Validation loss: 2.038861036300659

Epoch: 6| Step: 3
Training loss: 0.83409583568573
Validation loss: 2.0313464601834617

Epoch: 6| Step: 4
Training loss: 0.8918421268463135
Validation loss: 1.988568365573883

Epoch: 6| Step: 5
Training loss: 0.6028016805648804
Validation loss: 2.0051739613215127

Epoch: 6| Step: 6
Training loss: 0.7647586464881897
Validation loss: 2.0186891754468284

Epoch: 6| Step: 7
Training loss: 0.9202609062194824
Validation loss: 1.9962515632311504

Epoch: 6| Step: 8
Training loss: 0.7466878890991211
Validation loss: 2.0064793626467385

Epoch: 6| Step: 9
Training loss: 0.5593788623809814
Validation loss: 1.9872305591901143

Epoch: 6| Step: 10
Training loss: 0.5632644891738892
Validation loss: 2.0431026419003806

Epoch: 6| Step: 11
Training loss: 0.3759176433086395
Validation loss: 2.0227843523025513

Epoch: 6| Step: 12
Training loss: 0.6154656410217285
Validation loss: 2.087902247905731

Epoch: 6| Step: 13
Training loss: 0.4035586714744568
Validation loss: 2.074648360411326

Epoch: 164| Step: 0
Training loss: 0.8838902115821838
Validation loss: 2.0545485417048135

Epoch: 6| Step: 1
Training loss: 0.6548722982406616
Validation loss: 2.072140614191691

Epoch: 6| Step: 2
Training loss: 0.26743084192276
Validation loss: 2.0211989482243857

Epoch: 6| Step: 3
Training loss: 0.6569895148277283
Validation loss: 1.9886784354845684

Epoch: 6| Step: 4
Training loss: 0.7041343450546265
Validation loss: 1.999806543191274

Epoch: 6| Step: 5
Training loss: 0.375748872756958
Validation loss: 1.9885012308756511

Epoch: 6| Step: 6
Training loss: 0.8883042931556702
Validation loss: 2.0078729391098022

Epoch: 6| Step: 7
Training loss: 0.4946514070034027
Validation loss: 2.0561812917391458

Epoch: 6| Step: 8
Training loss: 1.3146703243255615
Validation loss: 1.994290252526601

Epoch: 6| Step: 9
Training loss: 0.34433889389038086
Validation loss: 2.1059168577194214

Epoch: 6| Step: 10
Training loss: 0.6159818172454834
Validation loss: 2.1620618104934692

Epoch: 6| Step: 11
Training loss: 0.7681431770324707
Validation loss: 2.1317479809125266

Epoch: 6| Step: 12
Training loss: 0.7600517272949219
Validation loss: 2.1608864267667136

Epoch: 6| Step: 13
Training loss: 0.9886534214019775
Validation loss: 2.1424772342046103

Epoch: 165| Step: 0
Training loss: 0.8670727014541626
Validation loss: 2.051426629225413

Epoch: 6| Step: 1
Training loss: 0.5629384517669678
Validation loss: 2.114506165186564

Epoch: 6| Step: 2
Training loss: 0.5123507380485535
Validation loss: 2.007206360499064

Epoch: 6| Step: 3
Training loss: 0.5882524847984314
Validation loss: 2.039733350276947

Epoch: 6| Step: 4
Training loss: 0.7252793908119202
Validation loss: 2.014935632546743

Epoch: 6| Step: 5
Training loss: 0.44671833515167236
Validation loss: 2.051570157210032

Epoch: 6| Step: 6
Training loss: 0.5631566047668457
Validation loss: 2.016426940759023

Epoch: 6| Step: 7
Training loss: 0.586471438407898
Validation loss: 2.056853711605072

Epoch: 6| Step: 8
Training loss: 0.8273051977157593
Validation loss: 2.0952863295873008

Epoch: 6| Step: 9
Training loss: 1.1362526416778564
Validation loss: 2.105849583943685

Epoch: 6| Step: 10
Training loss: 0.976019024848938
Validation loss: 2.056432763735453

Epoch: 6| Step: 11
Training loss: 0.7493066191673279
Validation loss: 2.0675360957781472

Epoch: 6| Step: 12
Training loss: 0.4328802227973938
Validation loss: 2.041929841041565

Epoch: 6| Step: 13
Training loss: 0.31623703241348267
Validation loss: 2.0485053261121116

Epoch: 166| Step: 0
Training loss: 0.8455853462219238
Validation loss: 2.000461141268412

Epoch: 6| Step: 1
Training loss: 0.5546847581863403
Validation loss: 1.9782004555066426

Epoch: 6| Step: 2
Training loss: 0.46148431301116943
Validation loss: 2.0106441577275596

Epoch: 6| Step: 3
Training loss: 0.49313196539878845
Validation loss: 2.0056004325548806

Epoch: 6| Step: 4
Training loss: 0.6270846128463745
Validation loss: 2.033421496550242

Epoch: 6| Step: 5
Training loss: 0.4980427324771881
Validation loss: 2.0335949261983237

Epoch: 6| Step: 6
Training loss: 0.5539954304695129
Validation loss: 2.019703964392344

Epoch: 6| Step: 7
Training loss: 0.5149505138397217
Validation loss: 2.0077532529830933

Epoch: 6| Step: 8
Training loss: 0.8955527544021606
Validation loss: 2.018088181813558

Epoch: 6| Step: 9
Training loss: 0.5170186161994934
Validation loss: 2.0090506871541343

Epoch: 6| Step: 10
Training loss: 0.8979697823524475
Validation loss: 2.0287755330403647

Epoch: 6| Step: 11
Training loss: 0.8406633734703064
Validation loss: 1.9561409155527751

Epoch: 6| Step: 12
Training loss: 0.8922944068908691
Validation loss: 1.9580273230870564

Epoch: 6| Step: 13
Training loss: 0.6218127012252808
Validation loss: 1.9913111726442974

Epoch: 167| Step: 0
Training loss: 0.6912117004394531
Validation loss: 2.0022364457448325

Epoch: 6| Step: 1
Training loss: 0.7274233102798462
Validation loss: 2.032295008500417

Epoch: 6| Step: 2
Training loss: 0.8006174564361572
Validation loss: 2.0454410513242087

Epoch: 6| Step: 3
Training loss: 0.6642894744873047
Validation loss: 2.0660558938980103

Epoch: 6| Step: 4
Training loss: 0.5974327325820923
Validation loss: 2.041584074497223

Epoch: 6| Step: 5
Training loss: 0.21820610761642456
Validation loss: 2.0172306895256042

Epoch: 6| Step: 6
Training loss: 0.47703856229782104
Validation loss: 2.017648140589396

Epoch: 6| Step: 7
Training loss: 0.7308003902435303
Validation loss: 2.013913889726003

Epoch: 6| Step: 8
Training loss: 0.607136070728302
Validation loss: 2.015824099381765

Epoch: 6| Step: 9
Training loss: 0.5569915175437927
Validation loss: 2.0300369461377463

Epoch: 6| Step: 10
Training loss: 0.5648851990699768
Validation loss: 2.0503373742103577

Epoch: 6| Step: 11
Training loss: 0.35063084959983826
Validation loss: 2.055090526739756

Epoch: 6| Step: 12
Training loss: 0.7253890037536621
Validation loss: 2.0160658955574036

Epoch: 6| Step: 13
Training loss: 0.9873846769332886
Validation loss: 1.9881909886995952

Epoch: 168| Step: 0
Training loss: 0.8629429340362549
Validation loss: 2.02380363146464

Epoch: 6| Step: 1
Training loss: 0.668138861656189
Validation loss: 2.0182597438494363

Epoch: 6| Step: 2
Training loss: 0.7404743432998657
Validation loss: 2.0189468463261924

Epoch: 6| Step: 3
Training loss: 0.5000537633895874
Validation loss: 2.0582199692726135

Epoch: 6| Step: 4
Training loss: 0.4941464364528656
Validation loss: 2.058463434378306

Epoch: 6| Step: 5
Training loss: 0.8830743432044983
Validation loss: 2.01044233640035

Epoch: 6| Step: 6
Training loss: 0.6193934082984924
Validation loss: 2.057517170906067

Epoch: 6| Step: 7
Training loss: 0.7876818180084229
Validation loss: 2.0050159891446433

Epoch: 6| Step: 8
Training loss: 0.2739119827747345
Validation loss: 2.0293253858884177

Epoch: 6| Step: 9
Training loss: 0.6660196781158447
Validation loss: 2.0378238757451377

Epoch: 6| Step: 10
Training loss: 0.35131335258483887
Validation loss: 2.0462343295415244

Epoch: 6| Step: 11
Training loss: 0.6634396314620972
Validation loss: 2.012000262737274

Epoch: 6| Step: 12
Training loss: 0.2360767126083374
Validation loss: 2.068937659263611

Epoch: 6| Step: 13
Training loss: 0.6008073687553406
Validation loss: 2.05982506275177

Epoch: 169| Step: 0
Training loss: 0.8697187900543213
Validation loss: 2.0496042172114053

Epoch: 6| Step: 1
Training loss: 0.17488591372966766
Validation loss: 2.0185864170392356

Epoch: 6| Step: 2
Training loss: 0.8333612084388733
Validation loss: 2.0642579793930054

Epoch: 6| Step: 3
Training loss: 0.4363822340965271
Validation loss: 1.982924997806549

Epoch: 6| Step: 4
Training loss: 0.6740795373916626
Validation loss: 2.021997610727946

Epoch: 6| Step: 5
Training loss: 0.9109893441200256
Validation loss: 1.9868072072664897

Epoch: 6| Step: 6
Training loss: 0.418462336063385
Validation loss: 1.9774940808614094

Epoch: 6| Step: 7
Training loss: 0.592292070388794
Validation loss: 2.0110802054405212

Epoch: 6| Step: 8
Training loss: 0.5665815472602844
Validation loss: 2.025687277317047

Epoch: 6| Step: 9
Training loss: 0.8063369989395142
Validation loss: 2.033185044924418

Epoch: 6| Step: 10
Training loss: 0.38485193252563477
Validation loss: 2.0405228535334268

Epoch: 6| Step: 11
Training loss: 0.5697774887084961
Validation loss: 2.0882012645403543

Epoch: 6| Step: 12
Training loss: 0.8460707664489746
Validation loss: 2.065121114253998

Epoch: 6| Step: 13
Training loss: 0.5425050258636475
Validation loss: 2.054938038190206

Epoch: 170| Step: 0
Training loss: 0.4652216136455536
Validation loss: 2.034698943297068

Epoch: 6| Step: 1
Training loss: 0.5099195241928101
Validation loss: 2.025453249613444

Epoch: 6| Step: 2
Training loss: 0.8804216384887695
Validation loss: 2.0181815028190613

Epoch: 6| Step: 3
Training loss: 0.517155110836029
Validation loss: 2.007645626862844

Epoch: 6| Step: 4
Training loss: 0.6336380839347839
Validation loss: 2.0750051736831665

Epoch: 6| Step: 5
Training loss: 0.24451634287834167
Validation loss: 1.9750868479410808

Epoch: 6| Step: 6
Training loss: 0.6158466339111328
Validation loss: 2.005872627099355

Epoch: 6| Step: 7
Training loss: 0.6652370691299438
Validation loss: 2.0006653467814126

Epoch: 6| Step: 8
Training loss: 0.8787118792533875
Validation loss: 2.0042192737261453

Epoch: 6| Step: 9
Training loss: 0.6073048114776611
Validation loss: 2.0007278323173523

Epoch: 6| Step: 10
Training loss: 0.5704460144042969
Validation loss: 2.029356678326925

Epoch: 6| Step: 11
Training loss: 0.4883885383605957
Validation loss: 2.0187414089838662

Epoch: 6| Step: 12
Training loss: 0.5323389768600464
Validation loss: 2.0167407194773355

Epoch: 6| Step: 13
Training loss: 0.6217941045761108
Validation loss: 1.9942214290301006

Epoch: 171| Step: 0
Training loss: 0.3665280044078827
Validation loss: 2.0280657211939492

Epoch: 6| Step: 1
Training loss: 0.3905181884765625
Validation loss: 1.996088445186615

Epoch: 6| Step: 2
Training loss: 0.7162728309631348
Validation loss: 2.020163039366404

Epoch: 6| Step: 3
Training loss: 0.6338165998458862
Validation loss: 2.0131390492121377

Epoch: 6| Step: 4
Training loss: 0.20643684267997742
Validation loss: 1.9992623527844746

Epoch: 6| Step: 5
Training loss: 0.6348036527633667
Validation loss: 2.019945740699768

Epoch: 6| Step: 6
Training loss: 0.36971092224121094
Validation loss: 2.0286346673965454

Epoch: 6| Step: 7
Training loss: 0.6720901727676392
Validation loss: 2.0407803058624268

Epoch: 6| Step: 8
Training loss: 1.239717960357666
Validation loss: 2.0512077808380127

Epoch: 6| Step: 9
Training loss: 0.6522970199584961
Validation loss: 2.0348170399665833

Epoch: 6| Step: 10
Training loss: 0.4673477113246918
Validation loss: 1.9977437257766724

Epoch: 6| Step: 11
Training loss: 0.5117665529251099
Validation loss: 2.0375699003537497

Epoch: 6| Step: 12
Training loss: 1.0636177062988281
Validation loss: 2.06269242366155

Epoch: 6| Step: 13
Training loss: 0.17688357830047607
Validation loss: 2.0770252545674643

Epoch: 172| Step: 0
Training loss: 0.7921770215034485
Validation loss: 2.114123980204264

Epoch: 6| Step: 1
Training loss: 0.5449351072311401
Validation loss: 2.094009578227997

Epoch: 6| Step: 2
Training loss: 0.7089107036590576
Validation loss: 2.019103487332662

Epoch: 6| Step: 3
Training loss: 0.6036243438720703
Validation loss: 2.0609583258628845

Epoch: 6| Step: 4
Training loss: 0.7364470958709717
Validation loss: 2.074713667233785

Epoch: 6| Step: 5
Training loss: 0.8179022669792175
Validation loss: 2.019421140352885

Epoch: 6| Step: 6
Training loss: 0.3505091071128845
Validation loss: 2.085598647594452

Epoch: 6| Step: 7
Training loss: 0.2982916235923767
Validation loss: 2.024072527885437

Epoch: 6| Step: 8
Training loss: 0.3917188346385956
Validation loss: 2.017069856325785

Epoch: 6| Step: 9
Training loss: 0.622346818447113
Validation loss: 2.0808926622072854

Epoch: 6| Step: 10
Training loss: 1.0789648294448853
Validation loss: 2.072169383366903

Epoch: 6| Step: 11
Training loss: 0.6493677496910095
Validation loss: 2.0528605580329895

Epoch: 6| Step: 12
Training loss: 0.429959774017334
Validation loss: 2.0817817052205405

Epoch: 6| Step: 13
Training loss: 0.6496485471725464
Validation loss: 2.015795270601908

Epoch: 173| Step: 0
Training loss: 0.5091707706451416
Validation loss: 2.0508002440134683

Epoch: 6| Step: 1
Training loss: 0.42643114924430847
Validation loss: 2.0796213348706565

Epoch: 6| Step: 2
Training loss: 0.43194085359573364
Validation loss: 2.0285762548446655

Epoch: 6| Step: 3
Training loss: 0.6933982372283936
Validation loss: 2.0118696292241416

Epoch: 6| Step: 4
Training loss: 1.067872166633606
Validation loss: 2.022397836049398

Epoch: 6| Step: 5
Training loss: 0.48095816373825073
Validation loss: 2.0138419469197593

Epoch: 6| Step: 6
Training loss: 0.8141776323318481
Validation loss: 2.0602737267812095

Epoch: 6| Step: 7
Training loss: 0.4332360625267029
Validation loss: 2.0327751437822976

Epoch: 6| Step: 8
Training loss: 0.3915691375732422
Validation loss: 2.0585564772288003

Epoch: 6| Step: 9
Training loss: 0.7769988775253296
Validation loss: 2.0473380088806152

Epoch: 6| Step: 10
Training loss: 0.8186754584312439
Validation loss: 2.0350460012753806

Epoch: 6| Step: 11
Training loss: 0.4859084486961365
Validation loss: 2.0214738845825195

Epoch: 6| Step: 12
Training loss: 0.5848637819290161
Validation loss: 2.0747934182484946

Epoch: 6| Step: 13
Training loss: 0.8495664596557617
Validation loss: 2.055631160736084

Epoch: 174| Step: 0
Training loss: 0.4718564450740814
Validation loss: 2.0470673640569053

Epoch: 6| Step: 1
Training loss: 0.7317487597465515
Validation loss: 2.027661840120951

Epoch: 6| Step: 2
Training loss: 0.6809900999069214
Validation loss: 2.0746018489201865

Epoch: 6| Step: 3
Training loss: 0.7087390422821045
Validation loss: 2.0866624116897583

Epoch: 6| Step: 4
Training loss: 0.7019292116165161
Validation loss: 2.1279069582621255

Epoch: 6| Step: 5
Training loss: 0.6596685647964478
Validation loss: 2.0269373257954917

Epoch: 6| Step: 6
Training loss: 0.4326428771018982
Validation loss: 2.0689547657966614

Epoch: 6| Step: 7
Training loss: 0.5485385656356812
Validation loss: 2.0218490163485208

Epoch: 6| Step: 8
Training loss: 0.722978949546814
Validation loss: 1.9959121346473694

Epoch: 6| Step: 9
Training loss: 0.9684273600578308
Validation loss: 2.0082343022028604

Epoch: 6| Step: 10
Training loss: 0.7114124298095703
Validation loss: 2.064215918382009

Epoch: 6| Step: 11
Training loss: 0.2526465654373169
Validation loss: 2.0612949331601462

Epoch: 6| Step: 12
Training loss: 0.5452786684036255
Validation loss: 2.0756776332855225

Epoch: 6| Step: 13
Training loss: 0.6184896230697632
Validation loss: 2.1370548009872437

Epoch: 175| Step: 0
Training loss: 0.8139501214027405
Validation loss: 2.1111005544662476

Epoch: 6| Step: 1
Training loss: 0.7124795913696289
Validation loss: 2.057591358820597

Epoch: 6| Step: 2
Training loss: 0.9137071967124939
Validation loss: 1.9858926335970561

Epoch: 6| Step: 3
Training loss: 0.8685840368270874
Validation loss: 2.052360415458679

Epoch: 6| Step: 4
Training loss: 0.5123136043548584
Validation loss: 2.0162429213523865

Epoch: 6| Step: 5
Training loss: 0.43336808681488037
Validation loss: 1.9833443959554036

Epoch: 6| Step: 6
Training loss: 0.747850775718689
Validation loss: 2.023212512334188

Epoch: 6| Step: 7
Training loss: 0.488171249628067
Validation loss: 2.0372851490974426

Epoch: 6| Step: 8
Training loss: 0.5426203608512878
Validation loss: 2.054783801237742

Epoch: 6| Step: 9
Training loss: 0.47640588879585266
Validation loss: 2.072266240914663

Epoch: 6| Step: 10
Training loss: 0.4683516323566437
Validation loss: 2.104836106300354

Epoch: 6| Step: 11
Training loss: 0.8387618064880371
Validation loss: 2.0472113291422525

Epoch: 6| Step: 12
Training loss: 0.751663327217102
Validation loss: 2.070532977581024

Epoch: 6| Step: 13
Training loss: 0.4965536892414093
Validation loss: 2.018275737762451

Epoch: 176| Step: 0
Training loss: 0.39687103033065796
Validation loss: 2.0391114354133606

Epoch: 6| Step: 1
Training loss: 0.5957629680633545
Validation loss: 2.0622729063034058

Epoch: 6| Step: 2
Training loss: 0.5199604630470276
Validation loss: 2.0671624739964805

Epoch: 6| Step: 3
Training loss: 0.5320123434066772
Validation loss: 2.0245076219240823

Epoch: 6| Step: 4
Training loss: 0.5575845241546631
Validation loss: 2.0409882068634033

Epoch: 6| Step: 5
Training loss: 0.6492276787757874
Validation loss: 2.055435578028361

Epoch: 6| Step: 6
Training loss: 0.51316899061203
Validation loss: 2.0816229780515036

Epoch: 6| Step: 7
Training loss: 0.5999276638031006
Validation loss: 2.0864453117052713

Epoch: 6| Step: 8
Training loss: 0.7759772539138794
Validation loss: 2.0733370383580527

Epoch: 6| Step: 9
Training loss: 0.5700103044509888
Validation loss: 2.095136562983195

Epoch: 6| Step: 10
Training loss: 0.7018950581550598
Validation loss: 2.0378974278767905

Epoch: 6| Step: 11
Training loss: 0.8607301712036133
Validation loss: 2.0110862652460733

Epoch: 6| Step: 12
Training loss: 0.2799156904220581
Validation loss: 2.0118587215741477

Epoch: 6| Step: 13
Training loss: 0.690619945526123
Validation loss: 2.0158334970474243

Epoch: 177| Step: 0
Training loss: 0.9873217940330505
Validation loss: 2.013654132684072

Epoch: 6| Step: 1
Training loss: 0.6661210060119629
Validation loss: 1.9681607286135356

Epoch: 6| Step: 2
Training loss: 0.5435758233070374
Validation loss: 2.0178016424179077

Epoch: 6| Step: 3
Training loss: 0.3019808530807495
Validation loss: 2.044834017753601

Epoch: 6| Step: 4
Training loss: 0.5322140455245972
Validation loss: 2.020721693833669

Epoch: 6| Step: 5
Training loss: 0.7710269689559937
Validation loss: 2.0591062108675637

Epoch: 6| Step: 6
Training loss: 0.5173808336257935
Validation loss: 2.0813088019688926

Epoch: 6| Step: 7
Training loss: 0.3822655975818634
Validation loss: 2.0549885034561157

Epoch: 6| Step: 8
Training loss: 0.5485348701477051
Validation loss: 2.008266270160675

Epoch: 6| Step: 9
Training loss: 0.5023168325424194
Validation loss: 2.019752820332845

Epoch: 6| Step: 10
Training loss: 0.8355531096458435
Validation loss: 2.0471539298693338

Epoch: 6| Step: 11
Training loss: 0.8568177223205566
Validation loss: 2.013581335544586

Epoch: 6| Step: 12
Training loss: 0.2860327363014221
Validation loss: 2.0178102056185403

Epoch: 6| Step: 13
Training loss: 0.473353773355484
Validation loss: 2.0470569928487143

Epoch: 178| Step: 0
Training loss: 0.675341784954071
Validation loss: 2.0197168389956155

Epoch: 6| Step: 1
Training loss: 0.266843318939209
Validation loss: 2.0354100863138833

Epoch: 6| Step: 2
Training loss: 0.5458478331565857
Validation loss: 2.032745619614919

Epoch: 6| Step: 3
Training loss: 0.27689313888549805
Validation loss: 2.0566558837890625

Epoch: 6| Step: 4
Training loss: 0.9222567081451416
Validation loss: 2.077040672302246

Epoch: 6| Step: 5
Training loss: 0.6428790092468262
Validation loss: 2.0054096976915994

Epoch: 6| Step: 6
Training loss: 1.17227303981781
Validation loss: 2.059208552042643

Epoch: 6| Step: 7
Training loss: 0.30461353063583374
Validation loss: 2.0729371706644693

Epoch: 6| Step: 8
Training loss: 0.7553214430809021
Validation loss: 2.0053303241729736

Epoch: 6| Step: 9
Training loss: 0.24244219064712524
Validation loss: 2.0220619638760886

Epoch: 6| Step: 10
Training loss: 0.33151575922966003
Validation loss: 2.0443020462989807

Epoch: 6| Step: 11
Training loss: 0.8343150019645691
Validation loss: 2.0631200075149536

Epoch: 6| Step: 12
Training loss: 0.4983493983745575
Validation loss: 2.0026877919832864

Epoch: 6| Step: 13
Training loss: 0.5366617441177368
Validation loss: 2.056368887424469

Epoch: 179| Step: 0
Training loss: 0.1779658943414688
Validation loss: 2.096900304158529

Epoch: 6| Step: 1
Training loss: 0.3233075737953186
Validation loss: 2.0731168389320374

Epoch: 6| Step: 2
Training loss: 1.0226740837097168
Validation loss: 2.123997171719869

Epoch: 6| Step: 3
Training loss: 0.4225166440010071
Validation loss: 2.0655585726102195

Epoch: 6| Step: 4
Training loss: 0.29809826612472534
Validation loss: 2.054685870806376

Epoch: 6| Step: 5
Training loss: 0.7360002994537354
Validation loss: 2.0489811499913535

Epoch: 6| Step: 6
Training loss: 0.6715527772903442
Validation loss: 2.094299872716268

Epoch: 6| Step: 7
Training loss: 0.6454498767852783
Validation loss: 1.9906923174858093

Epoch: 6| Step: 8
Training loss: 0.7449253797531128
Validation loss: 2.04427170753479

Epoch: 6| Step: 9
Training loss: 0.7587553262710571
Validation loss: 2.048999269803365

Epoch: 6| Step: 10
Training loss: 0.47727686166763306
Validation loss: 2.1058985789616904

Epoch: 6| Step: 11
Training loss: 0.9127998948097229
Validation loss: 2.04056845108668

Epoch: 6| Step: 12
Training loss: 0.21388578414916992
Validation loss: 2.0748220483462014

Epoch: 6| Step: 13
Training loss: 0.5379554033279419
Validation loss: 2.062904636065165

Epoch: 180| Step: 0
Training loss: 0.8443554639816284
Validation loss: 2.0659135778745017

Epoch: 6| Step: 1
Training loss: 0.6359719038009644
Validation loss: 2.056484321753184

Epoch: 6| Step: 2
Training loss: 0.3698296546936035
Validation loss: 2.040172755718231

Epoch: 6| Step: 3
Training loss: 0.38483375310897827
Validation loss: 2.0238998929659524

Epoch: 6| Step: 4
Training loss: 0.6231398582458496
Validation loss: 2.0188048084576926

Epoch: 6| Step: 5
Training loss: 0.6215239763259888
Validation loss: 2.036555528640747

Epoch: 6| Step: 6
Training loss: 0.27638399600982666
Validation loss: 2.062872052192688

Epoch: 6| Step: 7
Training loss: 0.48189306259155273
Validation loss: 2.065060615539551

Epoch: 6| Step: 8
Training loss: 0.6460044980049133
Validation loss: 2.07916788260142

Epoch: 6| Step: 9
Training loss: 0.323360800743103
Validation loss: 2.025839865207672

Epoch: 6| Step: 10
Training loss: 1.1699470281600952
Validation loss: 2.063861687978109

Epoch: 6| Step: 11
Training loss: 0.48009487986564636
Validation loss: 2.044273932774862

Epoch: 6| Step: 12
Training loss: 0.3495141267776489
Validation loss: 2.022802174091339

Epoch: 6| Step: 13
Training loss: 0.38090717792510986
Validation loss: 2.0489741563796997

Epoch: 181| Step: 0
Training loss: 0.6013543605804443
Validation loss: 2.0014684200286865

Epoch: 6| Step: 1
Training loss: 0.4506295919418335
Validation loss: 2.0243829091389975

Epoch: 6| Step: 2
Training loss: 0.8440112471580505
Validation loss: 1.996074656645457

Epoch: 6| Step: 3
Training loss: 0.7512805461883545
Validation loss: 2.0026986797650657

Epoch: 6| Step: 4
Training loss: 0.47397273778915405
Validation loss: 2.028272251288096

Epoch: 6| Step: 5
Training loss: 0.6722379922866821
Validation loss: 2.0453580419222512

Epoch: 6| Step: 6
Training loss: 0.9390352368354797
Validation loss: 2.0229987303415933

Epoch: 6| Step: 7
Training loss: 0.7555584907531738
Validation loss: 2.026891827583313

Epoch: 6| Step: 8
Training loss: 0.3871152400970459
Validation loss: 1.985439161459605

Epoch: 6| Step: 9
Training loss: 0.4793560802936554
Validation loss: 2.021437724431356

Epoch: 6| Step: 10
Training loss: 0.6006309986114502
Validation loss: 2.0208824078241983

Epoch: 6| Step: 11
Training loss: 0.18560822308063507
Validation loss: 2.0178662737210593

Epoch: 6| Step: 12
Training loss: 0.5824089050292969
Validation loss: 1.9540516138076782

Epoch: 6| Step: 13
Training loss: 0.32869553565979004
Validation loss: 2.0019713242848716

Epoch: 182| Step: 0
Training loss: 0.554498553276062
Validation loss: 1.972892701625824

Epoch: 6| Step: 1
Training loss: 1.221398115158081
Validation loss: 2.0316692193349204

Epoch: 6| Step: 2
Training loss: 0.4842800498008728
Validation loss: 2.0560808579126992

Epoch: 6| Step: 3
Training loss: 0.37551385164260864
Validation loss: 2.0428022344907126

Epoch: 6| Step: 4
Training loss: 0.9511659145355225
Validation loss: 2.0334018071492515

Epoch: 6| Step: 5
Training loss: 0.48814070224761963
Validation loss: 2.029950519402822

Epoch: 6| Step: 6
Training loss: 0.34363454580307007
Validation loss: 1.999713142712911

Epoch: 6| Step: 7
Training loss: 0.3026364743709564
Validation loss: 2.018798569838206

Epoch: 6| Step: 8
Training loss: 0.9411978721618652
Validation loss: 2.0073416233062744

Epoch: 6| Step: 9
Training loss: 0.4769377112388611
Validation loss: 1.9932822187741597

Epoch: 6| Step: 10
Training loss: 0.4073331654071808
Validation loss: 2.0222678979237876

Epoch: 6| Step: 11
Training loss: 0.43379849195480347
Validation loss: 2.0136672059694924

Epoch: 6| Step: 12
Training loss: 0.36821138858795166
Validation loss: 2.06585431098938

Epoch: 6| Step: 13
Training loss: 0.5076277256011963
Validation loss: 2.0741926232973733

Epoch: 183| Step: 0
Training loss: 0.4145025908946991
Validation loss: 2.061094323794047

Epoch: 6| Step: 1
Training loss: 0.7121566534042358
Validation loss: 2.0492431918780007

Epoch: 6| Step: 2
Training loss: 0.7667176723480225
Validation loss: 2.0205515225728354

Epoch: 6| Step: 3
Training loss: 0.2126142978668213
Validation loss: 1.9949889381726582

Epoch: 6| Step: 4
Training loss: 0.6007956266403198
Validation loss: 2.0359772642453513

Epoch: 6| Step: 5
Training loss: 0.7578420639038086
Validation loss: 1.9843096335728962

Epoch: 6| Step: 6
Training loss: 0.6554631590843201
Validation loss: 2.0587674180666604

Epoch: 6| Step: 7
Training loss: 0.4162065088748932
Validation loss: 2.0891175866127014

Epoch: 6| Step: 8
Training loss: 0.7922217845916748
Validation loss: 2.026516079902649

Epoch: 6| Step: 9
Training loss: 0.4272051155567169
Validation loss: 2.023042917251587

Epoch: 6| Step: 10
Training loss: 0.7000361084938049
Validation loss: 2.0289477705955505

Epoch: 6| Step: 11
Training loss: 0.24481000006198883
Validation loss: 2.0268432895342507

Epoch: 6| Step: 12
Training loss: 0.3363819718360901
Validation loss: 2.0162508289019265

Epoch: 6| Step: 13
Training loss: 0.6269639730453491
Validation loss: 2.0094613234202066

Epoch: 184| Step: 0
Training loss: 0.21865719556808472
Validation loss: 2.0583518147468567

Epoch: 6| Step: 1
Training loss: 0.828064501285553
Validation loss: 2.0313162207603455

Epoch: 6| Step: 2
Training loss: 0.2936452031135559
Validation loss: 2.0224397778511047

Epoch: 6| Step: 3
Training loss: 0.38443827629089355
Validation loss: 2.0545628666877747

Epoch: 6| Step: 4
Training loss: 0.3540498614311218
Validation loss: 2.0651312669118247

Epoch: 6| Step: 5
Training loss: 0.610008180141449
Validation loss: 2.029681166013082

Epoch: 6| Step: 6
Training loss: 0.3298220634460449
Validation loss: 2.0415597558021545

Epoch: 6| Step: 7
Training loss: 0.717147707939148
Validation loss: 2.0384756525357566

Epoch: 6| Step: 8
Training loss: 0.6114960312843323
Validation loss: 2.0686219533284507

Epoch: 6| Step: 9
Training loss: 0.609856128692627
Validation loss: 2.024130960305532

Epoch: 6| Step: 10
Training loss: 0.5374985337257385
Validation loss: 1.990750213464101

Epoch: 6| Step: 11
Training loss: 0.4512137174606323
Validation loss: 2.0833061138788858

Epoch: 6| Step: 12
Training loss: 0.22436101734638214
Validation loss: 2.022239844004313

Epoch: 6| Step: 13
Training loss: 1.1906695365905762
Validation loss: 2.007173498471578

Epoch: 185| Step: 0
Training loss: 0.3896729648113251
Validation loss: 2.004811684290568

Epoch: 6| Step: 1
Training loss: 0.7101587057113647
Validation loss: 1.9808213512102764

Epoch: 6| Step: 2
Training loss: 0.509107232093811
Validation loss: 2.0341436664263406

Epoch: 6| Step: 3
Training loss: 0.4043925702571869
Validation loss: 1.9995277722676594

Epoch: 6| Step: 4
Training loss: 0.3123791813850403
Validation loss: 2.012815237045288

Epoch: 6| Step: 5
Training loss: 0.900102436542511
Validation loss: 2.0283615589141846

Epoch: 6| Step: 6
Training loss: 0.7124013900756836
Validation loss: 2.0505464673042297

Epoch: 6| Step: 7
Training loss: 0.4088036119937897
Validation loss: 2.02044814825058

Epoch: 6| Step: 8
Training loss: 0.7253361940383911
Validation loss: 2.0171849528948465

Epoch: 6| Step: 9
Training loss: 0.5973429083824158
Validation loss: 1.9692351619402568

Epoch: 6| Step: 10
Training loss: 0.5174412727355957
Validation loss: 2.0444632371266684

Epoch: 6| Step: 11
Training loss: 0.2498835176229477
Validation loss: 1.9894091685612996

Epoch: 6| Step: 12
Training loss: 0.6154963970184326
Validation loss: 2.0493119955062866

Epoch: 6| Step: 13
Training loss: 0.2744230628013611
Validation loss: 2.009590188662211

Epoch: 186| Step: 0
Training loss: 0.4150606393814087
Validation loss: 1.9938279787699382

Epoch: 6| Step: 1
Training loss: 0.5891187787055969
Validation loss: 2.0086920658747354

Epoch: 6| Step: 2
Training loss: 0.2970496714115143
Validation loss: 2.0268423557281494

Epoch: 6| Step: 3
Training loss: 0.3848637342453003
Validation loss: 2.0278701186180115

Epoch: 6| Step: 4
Training loss: 0.267245352268219
Validation loss: 1.9972798029581706

Epoch: 6| Step: 5
Training loss: 0.6818602085113525
Validation loss: 2.0344161788622537

Epoch: 6| Step: 6
Training loss: 0.7677362561225891
Validation loss: 2.0237589677174888

Epoch: 6| Step: 7
Training loss: 0.4771064519882202
Validation loss: 1.9872771104176838

Epoch: 6| Step: 8
Training loss: 0.4333251118659973
Validation loss: 1.9991124272346497

Epoch: 6| Step: 9
Training loss: 0.6893975734710693
Validation loss: 1.96522456407547

Epoch: 6| Step: 10
Training loss: 0.3775160312652588
Validation loss: 1.9765942295392354

Epoch: 6| Step: 11
Training loss: 0.5154131054878235
Validation loss: 2.0456960598627725

Epoch: 6| Step: 12
Training loss: 0.752578616142273
Validation loss: 2.0229793190956116

Epoch: 6| Step: 13
Training loss: 0.8217495679855347
Validation loss: 2.0714465777079263

Epoch: 187| Step: 0
Training loss: 0.3600536286830902
Validation loss: 2.066327969233195

Epoch: 6| Step: 1
Training loss: 0.26095032691955566
Validation loss: 2.0307337443033853

Epoch: 6| Step: 2
Training loss: 0.3145231008529663
Validation loss: 2.0071250597635903

Epoch: 6| Step: 3
Training loss: 0.3764428496360779
Validation loss: 2.0405125617980957

Epoch: 6| Step: 4
Training loss: 0.36100757122039795
Validation loss: 2.0682392915089927

Epoch: 6| Step: 5
Training loss: 0.5006332993507385
Validation loss: 2.0296908219655356

Epoch: 6| Step: 6
Training loss: 0.9939515590667725
Validation loss: 1.9864522814750671

Epoch: 6| Step: 7
Training loss: 0.48215699195861816
Validation loss: 2.027810513973236

Epoch: 6| Step: 8
Training loss: 0.7306687831878662
Validation loss: 2.0359646876653037

Epoch: 6| Step: 9
Training loss: 0.9757721424102783
Validation loss: 1.998626748720805

Epoch: 6| Step: 10
Training loss: 0.34350675344467163
Validation loss: 2.0431218345959983

Epoch: 6| Step: 11
Training loss: 0.48020458221435547
Validation loss: 2.052598218123118

Epoch: 6| Step: 12
Training loss: 0.6420480012893677
Validation loss: 2.001033365726471

Epoch: 6| Step: 13
Training loss: 0.4055419862270355
Validation loss: 2.006162405014038

Epoch: 188| Step: 0
Training loss: 0.64042729139328
Validation loss: 2.016046186288198

Epoch: 6| Step: 1
Training loss: 0.4154295027256012
Validation loss: 2.0349190831184387

Epoch: 6| Step: 2
Training loss: 0.5447098016738892
Validation loss: 2.0535146594047546

Epoch: 6| Step: 3
Training loss: 0.5065293312072754
Validation loss: 2.049010396003723

Epoch: 6| Step: 4
Training loss: 0.5660055875778198
Validation loss: 2.0886157552401223

Epoch: 6| Step: 5
Training loss: 0.3506457805633545
Validation loss: 2.030751049518585

Epoch: 6| Step: 6
Training loss: 0.22192049026489258
Validation loss: 2.0465072194735208

Epoch: 6| Step: 7
Training loss: 0.243400439620018
Validation loss: 2.053832789262136

Epoch: 6| Step: 8
Training loss: 1.202089786529541
Validation loss: 2.0673580368359885

Epoch: 6| Step: 9
Training loss: 0.6092049479484558
Validation loss: 2.0040173729260764

Epoch: 6| Step: 10
Training loss: 0.21491876244544983
Validation loss: 2.0263578494389853

Epoch: 6| Step: 11
Training loss: 0.43176233768463135
Validation loss: 2.042578558127085

Epoch: 6| Step: 12
Training loss: 0.3784075975418091
Validation loss: 2.0591702659924827

Epoch: 6| Step: 13
Training loss: 0.397979736328125
Validation loss: 2.0262779593467712

Epoch: 189| Step: 0
Training loss: 0.4998081922531128
Validation loss: 2.013493796189626

Epoch: 6| Step: 1
Training loss: 0.5080168843269348
Validation loss: 2.0158625642458596

Epoch: 6| Step: 2
Training loss: 0.46815982460975647
Validation loss: 2.035406549771627

Epoch: 6| Step: 3
Training loss: 0.9772846102714539
Validation loss: 2.00579043229421

Epoch: 6| Step: 4
Training loss: 0.22246171534061432
Validation loss: 2.049969037373861

Epoch: 6| Step: 5
Training loss: 0.6198570728302002
Validation loss: 2.0376699765523276

Epoch: 6| Step: 6
Training loss: 0.6248483657836914
Validation loss: 2.027541716893514

Epoch: 6| Step: 7
Training loss: 0.6873293519020081
Validation loss: 2.0122614900271096

Epoch: 6| Step: 8
Training loss: 0.25749415159225464
Validation loss: 2.0985665718714395

Epoch: 6| Step: 9
Training loss: 0.4289678931236267
Validation loss: 2.016731083393097

Epoch: 6| Step: 10
Training loss: 0.256622314453125
Validation loss: 2.0545522769292197

Epoch: 6| Step: 11
Training loss: 0.42694371938705444
Validation loss: 2.0473851362864175

Epoch: 6| Step: 12
Training loss: 0.3303404450416565
Validation loss: 2.07045841217041

Epoch: 6| Step: 13
Training loss: 0.4143792986869812
Validation loss: 2.053016106287638

Epoch: 190| Step: 0
Training loss: 0.7646702527999878
Validation loss: 2.0680065949757895

Epoch: 6| Step: 1
Training loss: 0.4585265815258026
Validation loss: 2.0383700927098594

Epoch: 6| Step: 2
Training loss: 0.35140085220336914
Validation loss: 2.0254859129587808

Epoch: 6| Step: 3
Training loss: 0.5861585140228271
Validation loss: 2.0968981186548867

Epoch: 6| Step: 4
Training loss: 0.5569539070129395
Validation loss: 2.0624373157819114

Epoch: 6| Step: 5
Training loss: 0.37295636534690857
Validation loss: 2.10785178343455

Epoch: 6| Step: 6
Training loss: 0.6971392035484314
Validation loss: 2.103222211201986

Epoch: 6| Step: 7
Training loss: 0.4498225450515747
Validation loss: 2.079870323340098

Epoch: 6| Step: 8
Training loss: 0.5102884769439697
Validation loss: 2.0279095570246377

Epoch: 6| Step: 9
Training loss: 0.4226817488670349
Validation loss: 2.064818779627482

Epoch: 6| Step: 10
Training loss: 0.5503493547439575
Validation loss: 2.024313747882843

Epoch: 6| Step: 11
Training loss: 0.6972536444664001
Validation loss: 2.0377888480822244

Epoch: 6| Step: 12
Training loss: 0.4219769835472107
Validation loss: 2.0087651213010154

Epoch: 6| Step: 13
Training loss: 0.4205743670463562
Validation loss: 1.9968164960543315

Epoch: 191| Step: 0
Training loss: 0.41964513063430786
Validation loss: 2.080198645591736

Epoch: 6| Step: 1
Training loss: 0.3122396171092987
Validation loss: 2.066462755203247

Epoch: 6| Step: 2
Training loss: 0.2619979679584503
Validation loss: 2.057350834210714

Epoch: 6| Step: 3
Training loss: 1.1619011163711548
Validation loss: 2.09223073720932

Epoch: 6| Step: 4
Training loss: 0.45940229296684265
Validation loss: 2.049282411734263

Epoch: 6| Step: 5
Training loss: 0.721815824508667
Validation loss: 2.0325421492258706

Epoch: 6| Step: 6
Training loss: 0.48385316133499146
Validation loss: 2.0325072606404624

Epoch: 6| Step: 7
Training loss: 0.4855293929576874
Validation loss: 2.0758934020996094

Epoch: 6| Step: 8
Training loss: 0.7906067371368408
Validation loss: 2.014004091421763

Epoch: 6| Step: 9
Training loss: 0.5233802795410156
Validation loss: 2.116978883743286

Epoch: 6| Step: 10
Training loss: 0.6583235263824463
Validation loss: 2.0711002349853516

Epoch: 6| Step: 11
Training loss: 0.2740398049354553
Validation loss: 2.0521894693374634

Epoch: 6| Step: 12
Training loss: 0.5989993214607239
Validation loss: 2.1007914940516152

Epoch: 6| Step: 13
Training loss: 0.3215060830116272
Validation loss: 2.042683184146881

Epoch: 192| Step: 0
Training loss: 0.616471529006958
Validation loss: 2.071130096912384

Epoch: 6| Step: 1
Training loss: 0.31473618745803833
Validation loss: 2.0420052210489907

Epoch: 6| Step: 2
Training loss: 0.4604092836380005
Validation loss: 2.092408021291097

Epoch: 6| Step: 3
Training loss: 0.45348671078681946
Validation loss: 2.0795132319132485

Epoch: 6| Step: 4
Training loss: 1.096491813659668
Validation loss: 2.0860549807548523

Epoch: 6| Step: 5
Training loss: 0.33122918009757996
Validation loss: 2.0309320092201233

Epoch: 6| Step: 6
Training loss: 0.5544937252998352
Validation loss: 2.0621044437090554

Epoch: 6| Step: 7
Training loss: 0.6893370747566223
Validation loss: 2.0973084568977356

Epoch: 6| Step: 8
Training loss: 0.25795137882232666
Validation loss: 2.061807950337728

Epoch: 6| Step: 9
Training loss: 0.47319093346595764
Validation loss: 2.0366819898287454

Epoch: 6| Step: 10
Training loss: 0.2950860857963562
Validation loss: 2.0087891221046448

Epoch: 6| Step: 11
Training loss: 0.3275134265422821
Validation loss: 2.0928163131078086

Epoch: 6| Step: 12
Training loss: 0.36748206615448
Validation loss: 2.0699920654296875

Epoch: 6| Step: 13
Training loss: 0.7066762447357178
Validation loss: 2.0205448865890503

Epoch: 193| Step: 0
Training loss: 0.37434014678001404
Validation loss: 2.057626803716024

Epoch: 6| Step: 1
Training loss: 0.3819688558578491
Validation loss: 2.0579837958017984

Epoch: 6| Step: 2
Training loss: 0.19748945534229279
Validation loss: 2.051870505015055

Epoch: 6| Step: 3
Training loss: 0.9479813575744629
Validation loss: 1.9952256480852764

Epoch: 6| Step: 4
Training loss: 0.22816288471221924
Validation loss: 2.0831616123517356

Epoch: 6| Step: 5
Training loss: 0.7553228139877319
Validation loss: 1.9885087410608928

Epoch: 6| Step: 6
Training loss: 0.6284977793693542
Validation loss: 1.9877562324206035

Epoch: 6| Step: 7
Training loss: 0.24334312975406647
Validation loss: 2.0114493370056152

Epoch: 6| Step: 8
Training loss: 0.697754979133606
Validation loss: 1.9583612084388733

Epoch: 6| Step: 9
Training loss: 0.3647245764732361
Validation loss: 1.9991796215375264

Epoch: 6| Step: 10
Training loss: 0.8454806804656982
Validation loss: 2.012577931086222

Epoch: 6| Step: 11
Training loss: 0.5176335573196411
Validation loss: 2.0011897683143616

Epoch: 6| Step: 12
Training loss: 0.3365285098552704
Validation loss: 2.0403142174084983

Epoch: 6| Step: 13
Training loss: 0.22421477735042572
Validation loss: 2.063873767852783

Epoch: 194| Step: 0
Training loss: 0.2918401062488556
Validation loss: 2.068279802799225

Epoch: 6| Step: 1
Training loss: 0.4162006676197052
Validation loss: 2.018350064754486

Epoch: 6| Step: 2
Training loss: 0.4679109454154968
Validation loss: 2.068648397922516

Epoch: 6| Step: 3
Training loss: 0.30748236179351807
Validation loss: 2.0708221991856894

Epoch: 6| Step: 4
Training loss: 0.7045270204544067
Validation loss: 2.0428347984949746

Epoch: 6| Step: 5
Training loss: 0.7173939943313599
Validation loss: 2.072658101717631

Epoch: 6| Step: 6
Training loss: 0.255380779504776
Validation loss: 2.0519854029019675

Epoch: 6| Step: 7
Training loss: 0.24966925382614136
Validation loss: 2.036069711049398

Epoch: 6| Step: 8
Training loss: 0.5204277038574219
Validation loss: 1.9757416049639385

Epoch: 6| Step: 9
Training loss: 0.5535277128219604
Validation loss: 2.0247103174527488

Epoch: 6| Step: 10
Training loss: 0.6275664567947388
Validation loss: 2.026027023792267

Epoch: 6| Step: 11
Training loss: 0.4739268124103546
Validation loss: 2.0213635166486106

Epoch: 6| Step: 12
Training loss: 0.45636507868766785
Validation loss: 2.0320006807645163

Epoch: 6| Step: 13
Training loss: 0.7632944583892822
Validation loss: 2.055267870426178

Epoch: 195| Step: 0
Training loss: 0.8383891582489014
Validation loss: 2.0630212823549905

Epoch: 6| Step: 1
Training loss: 0.5776584148406982
Validation loss: 2.0666579206784568

Epoch: 6| Step: 2
Training loss: 0.7784578204154968
Validation loss: 2.114541530609131

Epoch: 6| Step: 3
Training loss: 0.3272295594215393
Validation loss: 2.0722585717837014

Epoch: 6| Step: 4
Training loss: 0.3838535249233246
Validation loss: 2.085662364959717

Epoch: 6| Step: 5
Training loss: 0.4710400104522705
Validation loss: 2.055217921733856

Epoch: 6| Step: 6
Training loss: 0.5127446055412292
Validation loss: 2.0568148295084634

Epoch: 6| Step: 7
Training loss: 0.3127760887145996
Validation loss: 2.0467520554860434

Epoch: 6| Step: 8
Training loss: 0.5930690169334412
Validation loss: 2.0328925450642905

Epoch: 6| Step: 9
Training loss: 0.5763077735900879
Validation loss: 1.9797861178716023

Epoch: 6| Step: 10
Training loss: 0.579316258430481
Validation loss: 2.0091094970703125

Epoch: 6| Step: 11
Training loss: 0.3173273801803589
Validation loss: 1.9803488453229268

Epoch: 6| Step: 12
Training loss: 0.6051097512245178
Validation loss: 2.0179967482884726

Epoch: 6| Step: 13
Training loss: 0.32035547494888306
Validation loss: 2.0205920537312827

Epoch: 196| Step: 0
Training loss: 0.36610710620880127
Validation loss: 2.0803884863853455

Epoch: 6| Step: 1
Training loss: 0.5612759590148926
Validation loss: 2.0861117442448935

Epoch: 6| Step: 2
Training loss: 0.345350056886673
Validation loss: 2.0483768781026206

Epoch: 6| Step: 3
Training loss: 0.39142417907714844
Validation loss: 2.0890127619107566

Epoch: 6| Step: 4
Training loss: 0.5202641487121582
Validation loss: 2.003090977668762

Epoch: 6| Step: 5
Training loss: 0.5989881157875061
Validation loss: 1.991147220134735

Epoch: 6| Step: 6
Training loss: 0.3565463125705719
Validation loss: 1.985972026983897

Epoch: 6| Step: 7
Training loss: 0.21981458365917206
Validation loss: 1.9969853560129802

Epoch: 6| Step: 8
Training loss: 0.3931116461753845
Validation loss: 2.006448666254679

Epoch: 6| Step: 9
Training loss: 1.2743594646453857
Validation loss: 2.0522780418395996

Epoch: 6| Step: 10
Training loss: 0.5266759395599365
Validation loss: 2.0236055652300515

Epoch: 6| Step: 11
Training loss: 0.5294442176818848
Validation loss: 2.021530111630758

Epoch: 6| Step: 12
Training loss: 0.4180143475532532
Validation loss: 2.087952713171641

Epoch: 6| Step: 13
Training loss: 0.5550312995910645
Validation loss: 2.0562294721603394

Epoch: 197| Step: 0
Training loss: 0.47742581367492676
Validation loss: 2.013630747795105

Epoch: 6| Step: 1
Training loss: 0.20734375715255737
Validation loss: 2.024009565512339

Epoch: 6| Step: 2
Training loss: 0.7539259195327759
Validation loss: 2.06733771165212

Epoch: 6| Step: 3
Training loss: 0.3698880672454834
Validation loss: 2.0503671169281006

Epoch: 6| Step: 4
Training loss: 0.7063391804695129
Validation loss: 1.9892235000928242

Epoch: 6| Step: 5
Training loss: 0.6618255972862244
Validation loss: 2.0642240246136985

Epoch: 6| Step: 6
Training loss: 0.2482249140739441
Validation loss: 2.0431045293807983

Epoch: 6| Step: 7
Training loss: 0.4838280975818634
Validation loss: 1.9844528834025066

Epoch: 6| Step: 8
Training loss: 0.7365013360977173
Validation loss: 2.0270007848739624

Epoch: 6| Step: 9
Training loss: 0.5694274306297302
Validation loss: 2.0333791772524514

Epoch: 6| Step: 10
Training loss: 0.333321750164032
Validation loss: 2.0424291690190635

Epoch: 6| Step: 11
Training loss: 0.4463058114051819
Validation loss: 2.0400867263476052

Epoch: 6| Step: 12
Training loss: 0.305833101272583
Validation loss: 2.014244019985199

Epoch: 6| Step: 13
Training loss: 0.5043729543685913
Validation loss: 2.0121895472208657

Epoch: 198| Step: 0
Training loss: 0.32301807403564453
Validation loss: 2.0234615008036294

Epoch: 6| Step: 1
Training loss: 0.3541562557220459
Validation loss: 2.050611058870951

Epoch: 6| Step: 2
Training loss: 0.33654212951660156
Validation loss: 2.003485461076101

Epoch: 6| Step: 3
Training loss: 0.5564945936203003
Validation loss: 2.070466637611389

Epoch: 6| Step: 4
Training loss: 0.2991068363189697
Validation loss: 2.002808849016825

Epoch: 6| Step: 5
Training loss: 0.3789275288581848
Validation loss: 1.9975340763727825

Epoch: 6| Step: 6
Training loss: 0.31031590700149536
Validation loss: 1.9831274151802063

Epoch: 6| Step: 7
Training loss: 0.41402000188827515
Validation loss: 2.028527537981669

Epoch: 6| Step: 8
Training loss: 0.4225653409957886
Validation loss: 2.047410170237223

Epoch: 6| Step: 9
Training loss: 1.2678724527359009
Validation loss: 2.033203125

Epoch: 6| Step: 10
Training loss: 0.7391645908355713
Validation loss: 2.0354514519373574

Epoch: 6| Step: 11
Training loss: 0.4540718197822571
Validation loss: 2.0660772919654846

Epoch: 6| Step: 12
Training loss: 0.2949468493461609
Validation loss: 2.0661736130714417

Epoch: 6| Step: 13
Training loss: 0.3860062062740326
Validation loss: 2.0235658486684165

Epoch: 199| Step: 0
Training loss: 0.3778994679450989
Validation loss: 2.0663520097732544

Epoch: 6| Step: 1
Training loss: 0.5373440980911255
Validation loss: 2.024239997069041

Epoch: 6| Step: 2
Training loss: 0.37807929515838623
Validation loss: 2.009057641029358

Epoch: 6| Step: 3
Training loss: 0.6104527711868286
Validation loss: 2.038002153237661

Epoch: 6| Step: 4
Training loss: 0.2764136493206024
Validation loss: 2.0181527137756348

Epoch: 6| Step: 5
Training loss: 0.6467113494873047
Validation loss: 2.0630940596262612

Epoch: 6| Step: 6
Training loss: 0.28664514422416687
Validation loss: 2.0746511618296304

Epoch: 6| Step: 7
Training loss: 0.5119430422782898
Validation loss: 1.9952992002169292

Epoch: 6| Step: 8
Training loss: 0.5302165150642395
Validation loss: 2.0532875259717307

Epoch: 6| Step: 9
Training loss: 0.4417228400707245
Validation loss: 2.013955990473429

Epoch: 6| Step: 10
Training loss: 0.6039770841598511
Validation loss: 2.03693280617396

Epoch: 6| Step: 11
Training loss: 0.42085719108581543
Validation loss: 2.0021750132242837

Epoch: 6| Step: 12
Training loss: 0.46198368072509766
Validation loss: 2.0643273194630942

Epoch: 6| Step: 13
Training loss: 0.4395301342010498
Validation loss: 2.038186510403951

Epoch: 200| Step: 0
Training loss: 0.3548930287361145
Validation loss: 2.012760102748871

Epoch: 6| Step: 1
Training loss: 0.6526070237159729
Validation loss: 1.9667786757151287

Epoch: 6| Step: 2
Training loss: 0.31656593084335327
Validation loss: 2.0282405416170755

Epoch: 6| Step: 3
Training loss: 0.39296218752861023
Validation loss: 2.0215096871058145

Epoch: 6| Step: 4
Training loss: 0.5821484327316284
Validation loss: 2.062782863775889

Epoch: 6| Step: 5
Training loss: 0.6728464365005493
Validation loss: 2.0460873444875083

Epoch: 6| Step: 6
Training loss: 0.7207168340682983
Validation loss: 2.1021973689397178

Epoch: 6| Step: 7
Training loss: 0.6664530038833618
Validation loss: 2.019013007481893

Epoch: 6| Step: 8
Training loss: 0.4838680624961853
Validation loss: 2.046121040980021

Epoch: 6| Step: 9
Training loss: 0.45721709728240967
Validation loss: 2.046331544717153

Epoch: 6| Step: 10
Training loss: 0.4816281199455261
Validation loss: 2.0057517488797507

Epoch: 6| Step: 11
Training loss: 0.5276802182197571
Validation loss: 2.0424808462460837

Epoch: 6| Step: 12
Training loss: 0.3291923403739929
Validation loss: 2.086605648199717

Epoch: 6| Step: 13
Training loss: 0.28492558002471924
Validation loss: 2.066457748413086

Epoch: 201| Step: 0
Training loss: 0.8371504545211792
Validation loss: 2.097347299257914

Epoch: 6| Step: 1
Training loss: 0.2272106260061264
Validation loss: 2.1059760451316833

Epoch: 6| Step: 2
Training loss: 0.7451610565185547
Validation loss: 2.1169220407803855

Epoch: 6| Step: 3
Training loss: 0.7185901403427124
Validation loss: 2.134544928868612

Epoch: 6| Step: 4
Training loss: 0.6593044996261597
Validation loss: 2.1158318320910134

Epoch: 6| Step: 5
Training loss: 0.3796871602535248
Validation loss: 2.067560871442159

Epoch: 6| Step: 6
Training loss: 0.4001445174217224
Validation loss: 2.064254621664683

Epoch: 6| Step: 7
Training loss: 0.483963280916214
Validation loss: 2.0652933716773987

Epoch: 6| Step: 8
Training loss: 0.4862058162689209
Validation loss: 2.017889757951101

Epoch: 6| Step: 9
Training loss: 0.5661517977714539
Validation loss: 2.0960146387418113

Epoch: 6| Step: 10
Training loss: 0.9990839958190918
Validation loss: 2.06137748559316

Epoch: 6| Step: 11
Training loss: 0.2828592360019684
Validation loss: 2.0481059153874717

Epoch: 6| Step: 12
Training loss: 0.4222838878631592
Validation loss: 2.0955294171969094

Epoch: 6| Step: 13
Training loss: 0.3966695964336395
Validation loss: 2.101050098737081

Epoch: 202| Step: 0
Training loss: 0.37512636184692383
Validation loss: 2.1377416253089905

Epoch: 6| Step: 1
Training loss: 0.525996208190918
Validation loss: 2.12646222114563

Epoch: 6| Step: 2
Training loss: 0.3376072347164154
Validation loss: 2.0812605222066245

Epoch: 6| Step: 3
Training loss: 0.22802473604679108
Validation loss: 2.0750945806503296

Epoch: 6| Step: 4
Training loss: 0.2165735363960266
Validation loss: 2.0032141407330832

Epoch: 6| Step: 5
Training loss: 1.0233585834503174
Validation loss: 1.9672890106836955

Epoch: 6| Step: 6
Training loss: 0.6533212065696716
Validation loss: 2.0297574599583945

Epoch: 6| Step: 7
Training loss: 0.2972921133041382
Validation loss: 1.9970131516456604

Epoch: 6| Step: 8
Training loss: 0.4553590416908264
Validation loss: 2.0497035582860312

Epoch: 6| Step: 9
Training loss: 0.5208284258842468
Validation loss: 2.030228098233541

Epoch: 6| Step: 10
Training loss: 0.5620445013046265
Validation loss: 2.1157380739847818

Epoch: 6| Step: 11
Training loss: 0.4766649007797241
Validation loss: 2.0868599812189736

Epoch: 6| Step: 12
Training loss: 0.6892885565757751
Validation loss: 2.059600512186686

Epoch: 6| Step: 13
Training loss: 0.597678542137146
Validation loss: 2.0883756279945374

Epoch: 203| Step: 0
Training loss: 0.2887815833091736
Validation loss: 2.0339805682500205

Epoch: 6| Step: 1
Training loss: 0.36752140522003174
Validation loss: 2.0353833436965942

Epoch: 6| Step: 2
Training loss: 0.4162033796310425
Validation loss: 2.065546711285909

Epoch: 6| Step: 3
Training loss: 0.33463478088378906
Validation loss: 1.989191512266795

Epoch: 6| Step: 4
Training loss: 0.7984471321105957
Validation loss: 2.0626654624938965

Epoch: 6| Step: 5
Training loss: 0.24292108416557312
Validation loss: 2.0630136926968894

Epoch: 6| Step: 6
Training loss: 0.44430750608444214
Validation loss: 2.0845580299695334

Epoch: 6| Step: 7
Training loss: 0.5216410160064697
Validation loss: 2.06336118777593

Epoch: 6| Step: 8
Training loss: 0.46308422088623047
Validation loss: 2.0555208126703897

Epoch: 6| Step: 9
Training loss: 0.66213458776474
Validation loss: 2.0715696612993875

Epoch: 6| Step: 10
Training loss: 0.5572980642318726
Validation loss: 2.0307101607322693

Epoch: 6| Step: 11
Training loss: 0.32109272480010986
Validation loss: 2.0563514629999795

Epoch: 6| Step: 12
Training loss: 0.870853066444397
Validation loss: 2.0237273971239724

Epoch: 6| Step: 13
Training loss: 0.34118539094924927
Validation loss: 2.052907089392344

Epoch: 204| Step: 0
Training loss: 0.8370490670204163
Validation loss: 2.0018479029337564

Epoch: 6| Step: 1
Training loss: 0.8754762411117554
Validation loss: 2.04483425617218

Epoch: 6| Step: 2
Training loss: 0.367133766412735
Validation loss: 2.075049797693888

Epoch: 6| Step: 3
Training loss: 0.4815822243690491
Validation loss: 2.1044551134109497

Epoch: 6| Step: 4
Training loss: 0.3388655483722687
Validation loss: 2.0546740293502808

Epoch: 6| Step: 5
Training loss: 0.5524609088897705
Validation loss: 2.111841003100077

Epoch: 6| Step: 6
Training loss: 0.45110076665878296
Validation loss: 2.101686875025431

Epoch: 6| Step: 7
Training loss: 0.535666823387146
Validation loss: 2.099068582057953

Epoch: 6| Step: 8
Training loss: 0.5393094420433044
Validation loss: 2.0496020913124084

Epoch: 6| Step: 9
Training loss: 0.3745521903038025
Validation loss: 2.0164419611295066

Epoch: 6| Step: 10
Training loss: 0.278508722782135
Validation loss: 2.0616195599238076

Epoch: 6| Step: 11
Training loss: 0.4895971417427063
Validation loss: 2.0663869380950928

Epoch: 6| Step: 12
Training loss: 0.462332546710968
Validation loss: 2.029532790184021

Epoch: 6| Step: 13
Training loss: 0.43359610438346863
Validation loss: 2.058217386404673

Epoch: 205| Step: 0
Training loss: 0.39744454622268677
Validation loss: 2.1151685317357383

Epoch: 6| Step: 1
Training loss: 0.8123332858085632
Validation loss: 2.163913448651632

Epoch: 6| Step: 2
Training loss: 0.5556595921516418
Validation loss: 2.1284621357917786

Epoch: 6| Step: 3
Training loss: 0.5548824071884155
Validation loss: 2.0718945264816284

Epoch: 6| Step: 4
Training loss: 0.4042714834213257
Validation loss: 2.058663010597229

Epoch: 6| Step: 5
Training loss: 0.3270816206932068
Validation loss: 2.0202086369196572

Epoch: 6| Step: 6
Training loss: 0.25951722264289856
Validation loss: 2.0379653175671897

Epoch: 6| Step: 7
Training loss: 1.0936408042907715
Validation loss: 2.0492401719093323

Epoch: 6| Step: 8
Training loss: 0.38937199115753174
Validation loss: 2.0239639282226562

Epoch: 6| Step: 9
Training loss: 0.4938255250453949
Validation loss: 1.9764025608698528

Epoch: 6| Step: 10
Training loss: 0.4304901957511902
Validation loss: 2.0411559343338013

Epoch: 6| Step: 11
Training loss: 0.49636566638946533
Validation loss: 2.0706297159194946

Epoch: 6| Step: 12
Training loss: 0.2501577138900757
Validation loss: 2.0474147399266562

Epoch: 6| Step: 13
Training loss: 0.5739230513572693
Validation loss: 2.0689170559247336

Epoch: 206| Step: 0
Training loss: 0.2853736877441406
Validation loss: 2.0421178738276162

Epoch: 6| Step: 1
Training loss: 0.35434502363204956
Validation loss: 2.1285497347513833

Epoch: 6| Step: 2
Training loss: 0.6178110837936401
Validation loss: 2.074721852938334

Epoch: 6| Step: 3
Training loss: 0.5611470937728882
Validation loss: 2.0302527944246926

Epoch: 6| Step: 4
Training loss: 0.6054900288581848
Validation loss: 2.035227060317993

Epoch: 6| Step: 5
Training loss: 0.4219125211238861
Validation loss: 2.0136532386144004

Epoch: 6| Step: 6
Training loss: 0.541015625
Validation loss: 1.997533122698466

Epoch: 6| Step: 7
Training loss: 0.3814452290534973
Validation loss: 2.0320881605148315

Epoch: 6| Step: 8
Training loss: 0.31811827421188354
Validation loss: 2.024446348349253

Epoch: 6| Step: 9
Training loss: 0.31715530157089233
Validation loss: 2.0487082997957864

Epoch: 6| Step: 10
Training loss: 0.7301746606826782
Validation loss: 2.1030919949213662

Epoch: 6| Step: 11
Training loss: 0.31025102734565735
Validation loss: 2.086449980735779

Epoch: 6| Step: 12
Training loss: 0.926817774772644
Validation loss: 2.0705883701642356

Epoch: 6| Step: 13
Training loss: 0.6016833186149597
Validation loss: 2.089851518472036

Epoch: 207| Step: 0
Training loss: 0.27638477087020874
Validation loss: 2.0268757939338684

Epoch: 6| Step: 1
Training loss: 0.4088190197944641
Validation loss: 2.0670798222223916

Epoch: 6| Step: 2
Training loss: 0.6415929794311523
Validation loss: 2.057040731112162

Epoch: 6| Step: 3
Training loss: 0.3842719793319702
Validation loss: 2.025334576765696

Epoch: 6| Step: 4
Training loss: 0.5832639336585999
Validation loss: 1.9982125759124756

Epoch: 6| Step: 5
Training loss: 0.5898141860961914
Validation loss: 2.034686545530955

Epoch: 6| Step: 6
Training loss: 0.24633188545703888
Validation loss: 2.0100359121958413

Epoch: 6| Step: 7
Training loss: 0.482805073261261
Validation loss: 2.036415994167328

Epoch: 6| Step: 8
Training loss: 0.3815042972564697
Validation loss: 2.070130010445913

Epoch: 6| Step: 9
Training loss: 0.4313846230506897
Validation loss: 2.0624486406644187

Epoch: 6| Step: 10
Training loss: 0.5342388153076172
Validation loss: 2.0200846989949546

Epoch: 6| Step: 11
Training loss: 0.8426330089569092
Validation loss: 2.0627551078796387

Epoch: 6| Step: 12
Training loss: 0.38557958602905273
Validation loss: 1.9832238554954529

Epoch: 6| Step: 13
Training loss: 0.5152652859687805
Validation loss: 2.033403476079305

Epoch: 208| Step: 0
Training loss: 0.4848395586013794
Validation loss: 2.056472420692444

Epoch: 6| Step: 1
Training loss: 0.29754918813705444
Validation loss: 1.9911344448725383

Epoch: 6| Step: 2
Training loss: 0.5446208715438843
Validation loss: 2.0169030825297036

Epoch: 6| Step: 3
Training loss: 0.7394877672195435
Validation loss: 2.065367877483368

Epoch: 6| Step: 4
Training loss: 0.34237921237945557
Validation loss: 2.032941222190857

Epoch: 6| Step: 5
Training loss: 0.4473552405834198
Validation loss: 2.0677895148595176

Epoch: 6| Step: 6
Training loss: 0.5111895799636841
Validation loss: 2.0519849061965942

Epoch: 6| Step: 7
Training loss: 0.2872800827026367
Validation loss: 1.9889429608980815

Epoch: 6| Step: 8
Training loss: 0.80816650390625
Validation loss: 2.0199733773867288

Epoch: 6| Step: 9
Training loss: 0.4463542103767395
Validation loss: 2.0191025932629905

Epoch: 6| Step: 10
Training loss: 0.8926748633384705
Validation loss: 1.9763424793879192

Epoch: 6| Step: 11
Training loss: 0.40699678659439087
Validation loss: 1.9722737272580464

Epoch: 6| Step: 12
Training loss: 0.22016049921512604
Validation loss: 1.9937718709309895

Epoch: 6| Step: 13
Training loss: 0.48483914136886597
Validation loss: 2.010964274406433

Epoch: 209| Step: 0
Training loss: 0.6207881569862366
Validation loss: 2.0039820671081543

Epoch: 6| Step: 1
Training loss: 0.34160536527633667
Validation loss: 2.0379406412442527

Epoch: 6| Step: 2
Training loss: 0.5177373886108398
Validation loss: 2.0309516191482544

Epoch: 6| Step: 3
Training loss: 0.6382858753204346
Validation loss: 2.0292194286982217

Epoch: 6| Step: 4
Training loss: 0.4746638536453247
Validation loss: 2.0271913607915244

Epoch: 6| Step: 5
Training loss: 0.5381841063499451
Validation loss: 2.0138250390688577

Epoch: 6| Step: 6
Training loss: 0.7707288265228271
Validation loss: 2.020170430342356

Epoch: 6| Step: 7
Training loss: 0.3445287048816681
Validation loss: 1.9695517420768738

Epoch: 6| Step: 8
Training loss: 0.6148384809494019
Validation loss: 1.9814135233561199

Epoch: 6| Step: 9
Training loss: 0.6445416212081909
Validation loss: 2.001691142717997

Epoch: 6| Step: 10
Training loss: 0.23472413420677185
Validation loss: 2.0463999112447104

Epoch: 6| Step: 11
Training loss: 0.3494341969490051
Validation loss: 2.0278716882069907

Epoch: 6| Step: 12
Training loss: 0.2698870301246643
Validation loss: 2.074101150035858

Epoch: 6| Step: 13
Training loss: 0.5268246531486511
Validation loss: 2.0510472655296326

Epoch: 210| Step: 0
Training loss: 0.5125100612640381
Validation loss: 2.060256242752075

Epoch: 6| Step: 1
Training loss: 0.5536248683929443
Validation loss: 2.018354892730713

Epoch: 6| Step: 2
Training loss: 0.36371687054634094
Validation loss: 1.9799501498540242

Epoch: 6| Step: 3
Training loss: 0.5311082005500793
Validation loss: 2.0715599854787192

Epoch: 6| Step: 4
Training loss: 0.37665045261383057
Validation loss: 2.012944142023722

Epoch: 6| Step: 5
Training loss: 0.25914624333381653
Validation loss: 1.9892996350924175

Epoch: 6| Step: 6
Training loss: 0.4905644357204437
Validation loss: 2.034252643585205

Epoch: 6| Step: 7
Training loss: 0.31493502855300903
Validation loss: 2.0309104919433594

Epoch: 6| Step: 8
Training loss: 0.7451311945915222
Validation loss: 2.0599178075790405

Epoch: 6| Step: 9
Training loss: 0.8364462852478027
Validation loss: 2.0083689093589783

Epoch: 6| Step: 10
Training loss: 0.33880937099456787
Validation loss: 2.090686837832133

Epoch: 6| Step: 11
Training loss: 0.5418887138366699
Validation loss: 2.0579304297765098

Epoch: 6| Step: 12
Training loss: 0.4333198070526123
Validation loss: 2.0736424326896667

Epoch: 6| Step: 13
Training loss: 0.32668790221214294
Validation loss: 2.01804788907369

Epoch: 211| Step: 0
Training loss: 0.40668392181396484
Validation loss: 2.0022645592689514

Epoch: 6| Step: 1
Training loss: 0.44820478558540344
Validation loss: 2.000881532828013

Epoch: 6| Step: 2
Training loss: 0.5198361873626709
Validation loss: 2.050733963648478

Epoch: 6| Step: 3
Training loss: 0.25261610746383667
Validation loss: 2.0573948423067727

Epoch: 6| Step: 4
Training loss: 0.2901708483695984
Validation loss: 2.022130807240804

Epoch: 6| Step: 5
Training loss: 0.4531879127025604
Validation loss: 2.0704853336016336

Epoch: 6| Step: 6
Training loss: 0.5580819845199585
Validation loss: 1.9769845604896545

Epoch: 6| Step: 7
Training loss: 1.035610318183899
Validation loss: 2.0197033882141113

Epoch: 6| Step: 8
Training loss: 0.40740883350372314
Validation loss: 2.0180912415186563

Epoch: 6| Step: 9
Training loss: 0.383038729429245
Validation loss: 2.032618304093679

Epoch: 6| Step: 10
Training loss: 0.18867401778697968
Validation loss: 2.0460140705108643

Epoch: 6| Step: 11
Training loss: 0.3999505043029785
Validation loss: 2.058757940928141

Epoch: 6| Step: 12
Training loss: 0.34264975786209106
Validation loss: 2.037619332472483

Epoch: 6| Step: 13
Training loss: 0.7216851711273193
Validation loss: 2.014191130797068

Epoch: 212| Step: 0
Training loss: 0.562315046787262
Validation loss: 2.0067432721455893

Epoch: 6| Step: 1
Training loss: 0.8757549524307251
Validation loss: 2.025578419367472

Epoch: 6| Step: 2
Training loss: 0.2541128396987915
Validation loss: 2.012732684612274

Epoch: 6| Step: 3
Training loss: 0.6427480578422546
Validation loss: 2.0270709792772927

Epoch: 6| Step: 4
Training loss: 0.28156375885009766
Validation loss: 2.017104685306549

Epoch: 6| Step: 5
Training loss: 0.8049682378768921
Validation loss: 2.029646913210551

Epoch: 6| Step: 6
Training loss: 0.30424562096595764
Validation loss: 2.0030853748321533

Epoch: 6| Step: 7
Training loss: 0.5682634115219116
Validation loss: 2.028127451737722

Epoch: 6| Step: 8
Training loss: 0.18719083070755005
Validation loss: 2.0093495845794678

Epoch: 6| Step: 9
Training loss: 0.521987795829773
Validation loss: 2.0469574530919394

Epoch: 6| Step: 10
Training loss: 0.4228627681732178
Validation loss: 2.044765571753184

Epoch: 6| Step: 11
Training loss: 0.3810448944568634
Validation loss: 2.038147528966268

Epoch: 6| Step: 12
Training loss: 0.23982368409633636
Validation loss: 2.026760717233022

Epoch: 6| Step: 13
Training loss: 0.3934742212295532
Validation loss: 2.038352370262146

Epoch: 213| Step: 0
Training loss: 0.5365903377532959
Validation loss: 2.0326643586158752

Epoch: 6| Step: 1
Training loss: 0.45685088634490967
Validation loss: 2.0891230503718057

Epoch: 6| Step: 2
Training loss: 0.2763723134994507
Validation loss: 2.0785233974456787

Epoch: 6| Step: 3
Training loss: 0.4433634281158447
Validation loss: 2.076567451159159

Epoch: 6| Step: 4
Training loss: 0.3382773697376251
Validation loss: 2.056769828001658

Epoch: 6| Step: 5
Training loss: 0.3244935870170593
Validation loss: 2.0949054757754006

Epoch: 6| Step: 6
Training loss: 0.6725749969482422
Validation loss: 2.0868669748306274

Epoch: 6| Step: 7
Training loss: 0.35194551944732666
Validation loss: 2.0851587057113647

Epoch: 6| Step: 8
Training loss: 0.3701375424861908
Validation loss: 2.1299296816190085

Epoch: 6| Step: 9
Training loss: 0.4943506121635437
Validation loss: 2.086424708366394

Epoch: 6| Step: 10
Training loss: 0.4704602360725403
Validation loss: 2.096199850241343

Epoch: 6| Step: 11
Training loss: 1.0023045539855957
Validation loss: 2.113496482372284

Epoch: 6| Step: 12
Training loss: 0.5004336833953857
Validation loss: 2.120269695917765

Epoch: 6| Step: 13
Training loss: 0.25633493065834045
Validation loss: 2.0579919616381326

Epoch: 214| Step: 0
Training loss: 0.44111940264701843
Validation loss: 2.0295494198799133

Epoch: 6| Step: 1
Training loss: 0.5761229991912842
Validation loss: 2.0033165415128074

Epoch: 6| Step: 2
Training loss: 0.39333078265190125
Validation loss: 2.0023597478866577

Epoch: 6| Step: 3
Training loss: 0.3144761919975281
Validation loss: 2.057926813761393

Epoch: 6| Step: 4
Training loss: 0.6443730592727661
Validation loss: 2.0271180669466653

Epoch: 6| Step: 5
Training loss: 0.37361401319503784
Validation loss: 1.994549810886383

Epoch: 6| Step: 6
Training loss: 0.6092272400856018
Validation loss: 2.0781370600064597

Epoch: 6| Step: 7
Training loss: 0.322637677192688
Validation loss: 2.037397483984629

Epoch: 6| Step: 8
Training loss: 0.8167551755905151
Validation loss: 2.067098538080851

Epoch: 6| Step: 9
Training loss: 0.3594752550125122
Validation loss: 1.9997851848602295

Epoch: 6| Step: 10
Training loss: 0.4411788880825043
Validation loss: 2.038066109021505

Epoch: 6| Step: 11
Training loss: 0.3449598550796509
Validation loss: 2.022367298603058

Epoch: 6| Step: 12
Training loss: 0.5490490198135376
Validation loss: 1.9916409651438396

Epoch: 6| Step: 13
Training loss: 0.4743127226829529
Validation loss: 2.0164231856664023

Epoch: 215| Step: 0
Training loss: 0.3170572817325592
Validation loss: 1.9983576933542888

Epoch: 6| Step: 1
Training loss: 0.4337342381477356
Validation loss: 2.0060887932777405

Epoch: 6| Step: 2
Training loss: 0.5499021410942078
Validation loss: 2.027307152748108

Epoch: 6| Step: 3
Training loss: 0.36235472559928894
Validation loss: 2.0921693444252014

Epoch: 6| Step: 4
Training loss: 0.8668643832206726
Validation loss: 2.062077601750692

Epoch: 6| Step: 5
Training loss: 0.4337214529514313
Validation loss: 2.0641042391459146

Epoch: 6| Step: 6
Training loss: 0.5369967222213745
Validation loss: 2.02749502658844

Epoch: 6| Step: 7
Training loss: 0.4642810821533203
Validation loss: 2.0150109132130942

Epoch: 6| Step: 8
Training loss: 0.7732404470443726
Validation loss: 2.032092869281769

Epoch: 6| Step: 9
Training loss: 0.45648273825645447
Validation loss: 1.9933680295944214

Epoch: 6| Step: 10
Training loss: 0.4838128089904785
Validation loss: 1.9765406250953674

Epoch: 6| Step: 11
Training loss: 0.7063244581222534
Validation loss: 1.9895717302958171

Epoch: 6| Step: 12
Training loss: 0.3093335032463074
Validation loss: 2.0479917923609414

Epoch: 6| Step: 13
Training loss: 0.2325863391160965
Validation loss: 2.060946444670359

Epoch: 216| Step: 0
Training loss: 0.31170588731765747
Validation loss: 2.0268982450167337

Epoch: 6| Step: 1
Training loss: 0.5078197717666626
Validation loss: 2.0855072935422263

Epoch: 6| Step: 2
Training loss: 0.4071594774723053
Validation loss: 1.9944697817166646

Epoch: 6| Step: 3
Training loss: 0.6098858714103699
Validation loss: 1.9767619967460632

Epoch: 6| Step: 4
Training loss: 0.2837512493133545
Validation loss: 2.085123340288798

Epoch: 6| Step: 5
Training loss: 0.3405638635158539
Validation loss: 2.0681780775388083

Epoch: 6| Step: 6
Training loss: 0.725895881652832
Validation loss: 2.030027985572815

Epoch: 6| Step: 7
Training loss: 0.27749040722846985
Validation loss: 2.0581742922465005

Epoch: 6| Step: 8
Training loss: 0.3691922426223755
Validation loss: 2.1051424940427146

Epoch: 6| Step: 9
Training loss: 0.44881922006607056
Validation loss: 2.042452891667684

Epoch: 6| Step: 10
Training loss: 0.371077299118042
Validation loss: 2.0975836515426636

Epoch: 6| Step: 11
Training loss: 0.575852632522583
Validation loss: 2.0445967515309653

Epoch: 6| Step: 12
Training loss: 0.5138383507728577
Validation loss: 2.046407322088877

Epoch: 6| Step: 13
Training loss: 0.47166121006011963
Validation loss: 2.063103755315145

Epoch: 217| Step: 0
Training loss: 0.4012238085269928
Validation loss: 2.070851763089498

Epoch: 6| Step: 1
Training loss: 0.20083078742027283
Validation loss: 2.039688150087992

Epoch: 6| Step: 2
Training loss: 0.6732100248336792
Validation loss: 2.0453386108080545

Epoch: 6| Step: 3
Training loss: 0.4522198736667633
Validation loss: 2.1301242907842

Epoch: 6| Step: 4
Training loss: 0.4822717308998108
Validation loss: 2.155910094579061

Epoch: 6| Step: 5
Training loss: 0.3449053168296814
Validation loss: 2.115315616130829

Epoch: 6| Step: 6
Training loss: 0.43721991777420044
Validation loss: 2.095591684182485

Epoch: 6| Step: 7
Training loss: 0.6458557844161987
Validation loss: 2.0685818791389465

Epoch: 6| Step: 8
Training loss: 0.42842862010002136
Validation loss: 2.0339789986610413

Epoch: 6| Step: 9
Training loss: 0.5951271057128906
Validation loss: 2.041898528734843

Epoch: 6| Step: 10
Training loss: 0.46991124749183655
Validation loss: 2.0245050390561423

Epoch: 6| Step: 11
Training loss: 0.6551405191421509
Validation loss: 2.0577737291653952

Epoch: 6| Step: 12
Training loss: 0.33985382318496704
Validation loss: 1.988135317961375

Epoch: 6| Step: 13
Training loss: 0.5001449584960938
Validation loss: 2.0600264271100364

Epoch: 218| Step: 0
Training loss: 0.40531519055366516
Validation loss: 2.056112368901571

Epoch: 6| Step: 1
Training loss: 0.26673153042793274
Validation loss: 2.029228846232096

Epoch: 6| Step: 2
Training loss: 0.1677050143480301
Validation loss: 2.0621379017829895

Epoch: 6| Step: 3
Training loss: 0.32708054780960083
Validation loss: 2.1260180473327637

Epoch: 6| Step: 4
Training loss: 0.35429471731185913
Validation loss: 2.1217902302742004

Epoch: 6| Step: 5
Training loss: 0.7736337780952454
Validation loss: 2.0550142725308738

Epoch: 6| Step: 6
Training loss: 0.48556989431381226
Validation loss: 2.067963480949402

Epoch: 6| Step: 7
Training loss: 0.5315201282501221
Validation loss: 2.060887257258097

Epoch: 6| Step: 8
Training loss: 0.3767426013946533
Validation loss: 2.039040466149648

Epoch: 6| Step: 9
Training loss: 0.6668885946273804
Validation loss: 1.9940011103947957

Epoch: 6| Step: 10
Training loss: 0.7089889049530029
Validation loss: 2.0475104451179504

Epoch: 6| Step: 11
Training loss: 0.400354266166687
Validation loss: 2.038576821486155

Epoch: 6| Step: 12
Training loss: 0.4376521706581116
Validation loss: 2.025019903977712

Epoch: 6| Step: 13
Training loss: 0.4469360411167145
Validation loss: 2.068120539188385

Epoch: 219| Step: 0
Training loss: 0.294536828994751
Validation loss: 2.015458067258199

Epoch: 6| Step: 1
Training loss: 0.694328784942627
Validation loss: 2.0271068811416626

Epoch: 6| Step: 2
Training loss: 0.32880541682243347
Validation loss: 2.0920252998669944

Epoch: 6| Step: 3
Training loss: 0.2748044729232788
Validation loss: 2.1157830357551575

Epoch: 6| Step: 4
Training loss: 0.33217281103134155
Validation loss: 2.067621886730194

Epoch: 6| Step: 5
Training loss: 0.5295181274414062
Validation loss: 2.062637527783712

Epoch: 6| Step: 6
Training loss: 0.37724214792251587
Validation loss: 2.0760701298713684

Epoch: 6| Step: 7
Training loss: 0.43518248200416565
Validation loss: 2.0663830240567527

Epoch: 6| Step: 8
Training loss: 0.7094076871871948
Validation loss: 2.03658397992452

Epoch: 6| Step: 9
Training loss: 0.5077040791511536
Validation loss: 2.0056272149086

Epoch: 6| Step: 10
Training loss: 0.4982721209526062
Validation loss: 2.0124358336130777

Epoch: 6| Step: 11
Training loss: 0.32901912927627563
Validation loss: 2.0836218992869058

Epoch: 6| Step: 12
Training loss: 0.5776770114898682
Validation loss: 2.0747002561887107

Epoch: 6| Step: 13
Training loss: 0.4385725259780884
Validation loss: 2.0430132945378623

Epoch: 220| Step: 0
Training loss: 0.5963640213012695
Validation loss: 1.987483024597168

Epoch: 6| Step: 1
Training loss: 0.3560122847557068
Validation loss: 2.034184237321218

Epoch: 6| Step: 2
Training loss: 0.6121530532836914
Validation loss: 2.0155060291290283

Epoch: 6| Step: 3
Training loss: 0.3025485873222351
Validation loss: 2.0014190077781677

Epoch: 6| Step: 4
Training loss: 0.8322115540504456
Validation loss: 1.997398018836975

Epoch: 6| Step: 5
Training loss: 0.3547426760196686
Validation loss: 1.987979233264923

Epoch: 6| Step: 6
Training loss: 0.5400601625442505
Validation loss: 2.039640168348948

Epoch: 6| Step: 7
Training loss: 0.3166228234767914
Validation loss: 2.023642341295878

Epoch: 6| Step: 8
Training loss: 0.5449684262275696
Validation loss: 2.0135173002878823

Epoch: 6| Step: 9
Training loss: 0.36298859119415283
Validation loss: 2.0437628030776978

Epoch: 6| Step: 10
Training loss: 0.3114144504070282
Validation loss: 2.015901962916056

Epoch: 6| Step: 11
Training loss: 0.32694756984710693
Validation loss: 2.0499955813090005

Epoch: 6| Step: 12
Training loss: 0.3529708981513977
Validation loss: 2.055657923221588

Epoch: 6| Step: 13
Training loss: 0.525265097618103
Validation loss: 2.026011029879252

Epoch: 221| Step: 0
Training loss: 0.2809159457683563
Validation loss: 2.0764023661613464

Epoch: 6| Step: 1
Training loss: 0.5050325393676758
Validation loss: 2.0339321891466775

Epoch: 6| Step: 2
Training loss: 0.3673384487628937
Validation loss: 1.9924117525418599

Epoch: 6| Step: 3
Training loss: 1.1693819761276245
Validation loss: 2.0527050296465554

Epoch: 6| Step: 4
Training loss: 0.47509393095970154
Validation loss: 2.0556485255559287

Epoch: 6| Step: 5
Training loss: 0.31840986013412476
Validation loss: 2.0184519489606223

Epoch: 6| Step: 6
Training loss: 0.41881316900253296
Validation loss: 2.0599492390950522

Epoch: 6| Step: 7
Training loss: 0.39134299755096436
Validation loss: 2.099969228108724

Epoch: 6| Step: 8
Training loss: 0.3088236451148987
Validation loss: 2.0899863640467324

Epoch: 6| Step: 9
Training loss: 0.28191232681274414
Validation loss: 2.1145964860916138

Epoch: 6| Step: 10
Training loss: 0.3354690372943878
Validation loss: 2.109221637248993

Epoch: 6| Step: 11
Training loss: 0.25081291794776917
Validation loss: 2.059741119543711

Epoch: 6| Step: 12
Training loss: 0.5393388271331787
Validation loss: 2.0497238636016846

Epoch: 6| Step: 13
Training loss: 0.18395423889160156
Validation loss: 2.037365893522898

Epoch: 222| Step: 0
Training loss: 0.5358941555023193
Validation loss: 2.0941620071729026

Epoch: 6| Step: 1
Training loss: 0.26955413818359375
Validation loss: 2.0359367529551187

Epoch: 6| Step: 2
Training loss: 0.4678751230239868
Validation loss: 2.041846970717112

Epoch: 6| Step: 3
Training loss: 0.4258294701576233
Validation loss: 2.0418670177459717

Epoch: 6| Step: 4
Training loss: 0.35782480239868164
Validation loss: 2.0184566974639893

Epoch: 6| Step: 5
Training loss: 0.7751816511154175
Validation loss: 2.086147904396057

Epoch: 6| Step: 6
Training loss: 0.28886231780052185
Validation loss: 2.073881685733795

Epoch: 6| Step: 7
Training loss: 0.4906717836856842
Validation loss: 2.0852920611699424

Epoch: 6| Step: 8
Training loss: 0.36308133602142334
Validation loss: 2.0583571791648865

Epoch: 6| Step: 9
Training loss: 0.4296766221523285
Validation loss: 2.0581813057263694

Epoch: 6| Step: 10
Training loss: 0.4339018762111664
Validation loss: 2.0451277097066245

Epoch: 6| Step: 11
Training loss: 0.2539430558681488
Validation loss: 2.0764337380727134

Epoch: 6| Step: 12
Training loss: 0.553707480430603
Validation loss: 2.02784393231074

Epoch: 6| Step: 13
Training loss: 0.3472592830657959
Validation loss: 2.057776073614756

Epoch: 223| Step: 0
Training loss: 0.33630284667015076
Validation loss: 2.062680979569753

Epoch: 6| Step: 1
Training loss: 0.48392632603645325
Validation loss: 2.0994182427724204

Epoch: 6| Step: 2
Training loss: 0.5971324443817139
Validation loss: 2.077025532722473

Epoch: 6| Step: 3
Training loss: 0.3865922689437866
Validation loss: 2.0585418740908303

Epoch: 6| Step: 4
Training loss: 0.39245712757110596
Validation loss: 2.0557978550593057

Epoch: 6| Step: 5
Training loss: 0.38130372762680054
Validation loss: 2.0336933732032776

Epoch: 6| Step: 6
Training loss: 0.35226142406463623
Validation loss: 2.0495583216349282

Epoch: 6| Step: 7
Training loss: 0.7875770926475525
Validation loss: 2.0967230002085366

Epoch: 6| Step: 8
Training loss: 0.36680692434310913
Validation loss: 2.0823204120000205

Epoch: 6| Step: 9
Training loss: 0.3932676315307617
Validation loss: 2.011471708615621

Epoch: 6| Step: 10
Training loss: 0.4995049238204956
Validation loss: 2.0748788913091025

Epoch: 6| Step: 11
Training loss: 0.3462677597999573
Validation loss: 2.0215318401654563

Epoch: 6| Step: 12
Training loss: 0.36079317331314087
Validation loss: 2.045625468095144

Epoch: 6| Step: 13
Training loss: 0.38117295503616333
Validation loss: 2.044362942377726

Epoch: 224| Step: 0
Training loss: 0.2988343834877014
Validation loss: 2.038373112678528

Epoch: 6| Step: 1
Training loss: 0.3208879232406616
Validation loss: 2.035265346368154

Epoch: 6| Step: 2
Training loss: 0.315199613571167
Validation loss: 2.055546283721924

Epoch: 6| Step: 3
Training loss: 0.3736899495124817
Validation loss: 2.0925088127454123

Epoch: 6| Step: 4
Training loss: 0.3396247625350952
Validation loss: 2.090964456399282

Epoch: 6| Step: 5
Training loss: 0.8513355255126953
Validation loss: 2.0686604579289756

Epoch: 6| Step: 6
Training loss: 0.4731508195400238
Validation loss: 2.0873485604921975

Epoch: 6| Step: 7
Training loss: 0.5424706935882568
Validation loss: 2.088153858979543

Epoch: 6| Step: 8
Training loss: 0.4677138924598694
Validation loss: 2.085835119088491

Epoch: 6| Step: 9
Training loss: 0.3342452645301819
Validation loss: 2.0158477425575256

Epoch: 6| Step: 10
Training loss: 0.2876717448234558
Validation loss: 2.0353947083155313

Epoch: 6| Step: 11
Training loss: 0.7055104970932007
Validation loss: 1.9941819508870442

Epoch: 6| Step: 12
Training loss: 0.4194050133228302
Validation loss: 2.0825804670651755

Epoch: 6| Step: 13
Training loss: 0.2922980785369873
Validation loss: 2.0583879947662354

Epoch: 225| Step: 0
Training loss: 0.2579425573348999
Validation loss: 1.9885712265968323

Epoch: 6| Step: 1
Training loss: 0.574964165687561
Validation loss: 2.0088005860646567

Epoch: 6| Step: 2
Training loss: 0.24923844635486603
Validation loss: 2.0271123250325522

Epoch: 6| Step: 3
Training loss: 0.21224038302898407
Validation loss: 1.9983745217323303

Epoch: 6| Step: 4
Training loss: 0.27376818656921387
Validation loss: 2.000263492266337

Epoch: 6| Step: 5
Training loss: 0.6508833169937134
Validation loss: 1.9859182238578796

Epoch: 6| Step: 6
Training loss: 0.9652165174484253
Validation loss: 1.954133152961731

Epoch: 6| Step: 7
Training loss: 0.289541095495224
Validation loss: 2.0464930534362793

Epoch: 6| Step: 8
Training loss: 0.5521044731140137
Validation loss: 2.017219881216685

Epoch: 6| Step: 9
Training loss: 0.338666707277298
Validation loss: 2.0837069948514304

Epoch: 6| Step: 10
Training loss: 0.43766504526138306
Validation loss: 2.0535482366879783

Epoch: 6| Step: 11
Training loss: 0.4426668882369995
Validation loss: 2.0940465927124023

Epoch: 6| Step: 12
Training loss: 0.597747802734375
Validation loss: 2.0549100438753762

Epoch: 6| Step: 13
Training loss: 0.6090956926345825
Validation loss: 2.078704754511515

Epoch: 226| Step: 0
Training loss: 0.9005376100540161
Validation loss: 2.0136298338572183

Epoch: 6| Step: 1
Training loss: 0.3170076608657837
Validation loss: 2.004211942354838

Epoch: 6| Step: 2
Training loss: 0.41487830877304077
Validation loss: 2.010891874631246

Epoch: 6| Step: 3
Training loss: 0.43572327494621277
Validation loss: 2.048742930094401

Epoch: 6| Step: 4
Training loss: 0.6681568622589111
Validation loss: 2.0464276472727456

Epoch: 6| Step: 5
Training loss: 0.6865270137786865
Validation loss: 2.098115166028341

Epoch: 6| Step: 6
Training loss: 0.24928778409957886
Validation loss: 2.0469192266464233

Epoch: 6| Step: 7
Training loss: 0.46437856554985046
Validation loss: 2.043168385823568

Epoch: 6| Step: 8
Training loss: 0.2874337136745453
Validation loss: 2.115936815738678

Epoch: 6| Step: 9
Training loss: 0.6572193503379822
Validation loss: 2.094225585460663

Epoch: 6| Step: 10
Training loss: 0.2600964903831482
Validation loss: 2.0766655604044595

Epoch: 6| Step: 11
Training loss: 0.42858436703681946
Validation loss: 2.083638350168864

Epoch: 6| Step: 12
Training loss: 0.35174131393432617
Validation loss: 2.087946097056071

Epoch: 6| Step: 13
Training loss: 0.18987731635570526
Validation loss: 2.0962689320246377

Epoch: 227| Step: 0
Training loss: 0.5306306481361389
Validation loss: 2.0622934301694236

Epoch: 6| Step: 1
Training loss: 0.8607558012008667
Validation loss: 2.1022872924804688

Epoch: 6| Step: 2
Training loss: 0.40963810682296753
Validation loss: 2.0562342206637063

Epoch: 6| Step: 3
Training loss: 0.2846994400024414
Validation loss: 2.057974934577942

Epoch: 6| Step: 4
Training loss: 0.14423754811286926
Validation loss: 2.0679719845453897

Epoch: 6| Step: 5
Training loss: 0.31278929114341736
Validation loss: 2.0309301018714905

Epoch: 6| Step: 6
Training loss: 0.4807760417461395
Validation loss: 2.075683037439982

Epoch: 6| Step: 7
Training loss: 0.6203711032867432
Validation loss: 2.0682965517044067

Epoch: 6| Step: 8
Training loss: 0.3847655653953552
Validation loss: 2.051593542098999

Epoch: 6| Step: 9
Training loss: 0.4026745557785034
Validation loss: 2.0730388164520264

Epoch: 6| Step: 10
Training loss: 0.5410858988761902
Validation loss: 2.031378467877706

Epoch: 6| Step: 11
Training loss: 0.38027679920196533
Validation loss: 2.087150196234385

Epoch: 6| Step: 12
Training loss: 0.3012275695800781
Validation loss: 2.05678391456604

Epoch: 6| Step: 13
Training loss: 0.549869954586029
Validation loss: 2.059218148390452

Epoch: 228| Step: 0
Training loss: 0.15504658222198486
Validation loss: 2.0264639059702554

Epoch: 6| Step: 1
Training loss: 0.3675858974456787
Validation loss: 2.0226069490114846

Epoch: 6| Step: 2
Training loss: 0.31281283497810364
Validation loss: 2.046661655108134

Epoch: 6| Step: 3
Training loss: 0.3959386646747589
Validation loss: 2.0134785970052085

Epoch: 6| Step: 4
Training loss: 0.7202209234237671
Validation loss: 2.017733653386434

Epoch: 6| Step: 5
Training loss: 0.4283205568790436
Validation loss: 2.040313204129537

Epoch: 6| Step: 6
Training loss: 0.2655990719795227
Validation loss: 1.9653027852376301

Epoch: 6| Step: 7
Training loss: 0.2975150942802429
Validation loss: 2.0754283666610718

Epoch: 6| Step: 8
Training loss: 0.4649326801300049
Validation loss: 1.9860559304555256

Epoch: 6| Step: 9
Training loss: 0.29950830340385437
Validation loss: 1.9958327412605286

Epoch: 6| Step: 10
Training loss: 0.4044755697250366
Validation loss: 2.0028687715530396

Epoch: 6| Step: 11
Training loss: 0.33987608551979065
Validation loss: 2.015435298283895

Epoch: 6| Step: 12
Training loss: 0.47958654165267944
Validation loss: 2.0339510639508567

Epoch: 6| Step: 13
Training loss: 0.47376924753189087
Validation loss: 2.0635408560434976

Epoch: 229| Step: 0
Training loss: 0.5387567281723022
Validation loss: 2.078270892302195

Epoch: 6| Step: 1
Training loss: 0.6448863744735718
Validation loss: 2.0283387700716653

Epoch: 6| Step: 2
Training loss: 0.22974039614200592
Validation loss: 2.062450567881266

Epoch: 6| Step: 3
Training loss: 0.4669347405433655
Validation loss: 2.0559838811556497

Epoch: 6| Step: 4
Training loss: 0.2807244062423706
Validation loss: 2.0875538289546967

Epoch: 6| Step: 5
Training loss: 0.23886369168758392
Validation loss: 2.0522244771321616

Epoch: 6| Step: 6
Training loss: 0.259365975856781
Validation loss: 2.0633273323376975

Epoch: 6| Step: 7
Training loss: 0.29133814573287964
Validation loss: 2.0112553040186563

Epoch: 6| Step: 8
Training loss: 0.3115154802799225
Validation loss: 2.044333815574646

Epoch: 6| Step: 9
Training loss: 0.3615194261074066
Validation loss: 2.0526795188585916

Epoch: 6| Step: 10
Training loss: 0.4541890025138855
Validation loss: 2.041467785835266

Epoch: 6| Step: 11
Training loss: 0.29451337456703186
Validation loss: 2.040562411149343

Epoch: 6| Step: 12
Training loss: 0.41862088441848755
Validation loss: 2.074282725652059

Epoch: 6| Step: 13
Training loss: 0.8234465718269348
Validation loss: 2.0495750308036804

Epoch: 230| Step: 0
Training loss: 0.493252694606781
Validation loss: 2.0923824111620584

Epoch: 6| Step: 1
Training loss: 0.1835477650165558
Validation loss: 2.082105298837026

Epoch: 6| Step: 2
Training loss: 0.2053210735321045
Validation loss: 2.0571441054344177

Epoch: 6| Step: 3
Training loss: 0.4593542218208313
Validation loss: 1.9738469521204631

Epoch: 6| Step: 4
Training loss: 0.46669942140579224
Validation loss: 2.012973189353943

Epoch: 6| Step: 5
Training loss: 0.5737981796264648
Validation loss: 2.0470804373423257

Epoch: 6| Step: 6
Training loss: 0.391741544008255
Validation loss: 2.0862472454706826

Epoch: 6| Step: 7
Training loss: 0.38188499212265015
Validation loss: 2.009062627951304

Epoch: 6| Step: 8
Training loss: 0.7268866300582886
Validation loss: 2.034329374631246

Epoch: 6| Step: 9
Training loss: 0.26120617985725403
Validation loss: 2.0376612146695456

Epoch: 6| Step: 10
Training loss: 0.3207479417324066
Validation loss: 2.0742571353912354

Epoch: 6| Step: 11
Training loss: 0.2881482243537903
Validation loss: 2.134304165840149

Epoch: 6| Step: 12
Training loss: 0.23324896395206451
Validation loss: 2.075173298517863

Epoch: 6| Step: 13
Training loss: 0.4174762964248657
Validation loss: 2.038707176844279

Epoch: 231| Step: 0
Training loss: 0.3482353091239929
Validation loss: 2.101202964782715

Epoch: 6| Step: 1
Training loss: 0.5823302268981934
Validation loss: 2.085690975189209

Epoch: 6| Step: 2
Training loss: 0.19868332147598267
Validation loss: 2.025873144467672

Epoch: 6| Step: 3
Training loss: 0.30167850852012634
Validation loss: 2.02420981725057

Epoch: 6| Step: 4
Training loss: 0.29172229766845703
Validation loss: 2.015552540620168

Epoch: 6| Step: 5
Training loss: 0.4021407663822174
Validation loss: 2.05535759528478

Epoch: 6| Step: 6
Training loss: 0.2767658531665802
Validation loss: 2.005827565987905

Epoch: 6| Step: 7
Training loss: 0.7523399591445923
Validation loss: 1.9936743378639221

Epoch: 6| Step: 8
Training loss: 0.3105008900165558
Validation loss: 2.0630085666974387

Epoch: 6| Step: 9
Training loss: 0.20233950018882751
Validation loss: 2.0147350629170737

Epoch: 6| Step: 10
Training loss: 0.6739473342895508
Validation loss: 2.044845223426819

Epoch: 6| Step: 11
Training loss: 0.3997945189476013
Validation loss: 2.043056825796763

Epoch: 6| Step: 12
Training loss: 0.325073778629303
Validation loss: 2.061131795247396

Epoch: 6| Step: 13
Training loss: 0.2750747799873352
Validation loss: 2.024384697278341

Epoch: 232| Step: 0
Training loss: 0.5280390977859497
Validation loss: 2.035461107889811

Epoch: 6| Step: 1
Training loss: 0.4988287091255188
Validation loss: 2.0287721157073975

Epoch: 6| Step: 2
Training loss: 0.2964765429496765
Validation loss: 2.0204920768737793

Epoch: 6| Step: 3
Training loss: 0.44377148151397705
Validation loss: 2.0797443191210427

Epoch: 6| Step: 4
Training loss: 0.27193236351013184
Validation loss: 2.020608345667521

Epoch: 6| Step: 5
Training loss: 0.3531840443611145
Validation loss: 2.0369759798049927

Epoch: 6| Step: 6
Training loss: 0.1853901892900467
Validation loss: 1.9869449734687805

Epoch: 6| Step: 7
Training loss: 0.9193824529647827
Validation loss: 2.034810423851013

Epoch: 6| Step: 8
Training loss: 0.2608415484428406
Validation loss: 2.0236927270889282

Epoch: 6| Step: 9
Training loss: 0.41089189052581787
Validation loss: 2.0490845441818237

Epoch: 6| Step: 10
Training loss: 0.19159191846847534
Validation loss: 2.0200992822647095

Epoch: 6| Step: 11
Training loss: 0.3523064851760864
Validation loss: 2.060542722543081

Epoch: 6| Step: 12
Training loss: 0.48496413230895996
Validation loss: 2.063479959964752

Epoch: 6| Step: 13
Training loss: 0.2709135413169861
Validation loss: 2.0655376513799033

Epoch: 233| Step: 0
Training loss: 0.27681899070739746
Validation loss: 2.023918410142263

Epoch: 6| Step: 1
Training loss: 0.8202217817306519
Validation loss: 2.0634364684422812

Epoch: 6| Step: 2
Training loss: 0.3783060908317566
Validation loss: 2.064999540646871

Epoch: 6| Step: 3
Training loss: 0.3023263216018677
Validation loss: 2.025322178999583

Epoch: 6| Step: 4
Training loss: 0.15644410252571106
Validation loss: 2.00980136791865

Epoch: 6| Step: 5
Training loss: 0.3901846408843994
Validation loss: 2.018252750237783

Epoch: 6| Step: 6
Training loss: 0.2191905677318573
Validation loss: 1.983656684557597

Epoch: 6| Step: 7
Training loss: 0.32710403203964233
Validation loss: 2.0753939350446067

Epoch: 6| Step: 8
Training loss: 0.6838424205780029
Validation loss: 2.030190428098043

Epoch: 6| Step: 9
Training loss: 0.4799761474132538
Validation loss: 1.9991035262743633

Epoch: 6| Step: 10
Training loss: 0.39981934428215027
Validation loss: 2.0730146169662476

Epoch: 6| Step: 11
Training loss: 0.31848376989364624
Validation loss: 2.03420090675354

Epoch: 6| Step: 12
Training loss: 0.2609716057777405
Validation loss: 2.0556766589482627

Epoch: 6| Step: 13
Training loss: 0.2798905372619629
Validation loss: 2.029702146848043

Epoch: 234| Step: 0
Training loss: 0.46942993998527527
Validation loss: 2.021777391433716

Epoch: 6| Step: 1
Training loss: 0.2236657440662384
Validation loss: 2.03736941019694

Epoch: 6| Step: 2
Training loss: 0.7696416974067688
Validation loss: 2.016920884450277

Epoch: 6| Step: 3
Training loss: 0.5921135544776917
Validation loss: 2.0241952339808145

Epoch: 6| Step: 4
Training loss: 0.25474295020103455
Validation loss: 1.9983881910641987

Epoch: 6| Step: 5
Training loss: 0.5247671604156494
Validation loss: 1.9838162263234456

Epoch: 6| Step: 6
Training loss: 0.31221652030944824
Validation loss: 2.0433660745620728

Epoch: 6| Step: 7
Training loss: 0.21738587319850922
Validation loss: 2.026262879371643

Epoch: 6| Step: 8
Training loss: 0.231815904378891
Validation loss: 2.0487869580586753

Epoch: 6| Step: 9
Training loss: 0.23542864620685577
Validation loss: 2.028287649154663

Epoch: 6| Step: 10
Training loss: 0.3480134606361389
Validation loss: 2.0350480675697327

Epoch: 6| Step: 11
Training loss: 0.4212171137332916
Validation loss: 2.069201111793518

Epoch: 6| Step: 12
Training loss: 0.5342073440551758
Validation loss: 2.0523418386777244

Epoch: 6| Step: 13
Training loss: 0.44449299573898315
Validation loss: 2.0604304472605386

Epoch: 235| Step: 0
Training loss: 0.1698645055294037
Validation loss: 2.067650636037191

Epoch: 6| Step: 1
Training loss: 0.5868123173713684
Validation loss: 2.025789201259613

Epoch: 6| Step: 2
Training loss: 0.46246999502182007
Validation loss: 2.0717838207880654

Epoch: 6| Step: 3
Training loss: 0.3383626639842987
Validation loss: 2.030786871910095

Epoch: 6| Step: 4
Training loss: 0.21255387365818024
Validation loss: 2.0642047127087912

Epoch: 6| Step: 5
Training loss: 0.39022982120513916
Validation loss: 2.0457075436909995

Epoch: 6| Step: 6
Training loss: 0.6333457231521606
Validation loss: 2.0542163451512656

Epoch: 6| Step: 7
Training loss: 0.25082898139953613
Validation loss: 2.0439305305480957

Epoch: 6| Step: 8
Training loss: 0.4357675313949585
Validation loss: 2.083380937576294

Epoch: 6| Step: 9
Training loss: 0.2660778760910034
Validation loss: 2.0615768233935037

Epoch: 6| Step: 10
Training loss: 0.2802921533584595
Validation loss: 2.060497760772705

Epoch: 6| Step: 11
Training loss: 0.2606612741947174
Validation loss: 2.0824467738469443

Epoch: 6| Step: 12
Training loss: 0.4089250862598419
Validation loss: 2.005604167779287

Epoch: 6| Step: 13
Training loss: 0.5964556336402893
Validation loss: 2.0313621958096824

Epoch: 236| Step: 0
Training loss: 0.2226925492286682
Validation loss: 2.0628798405329385

Epoch: 6| Step: 1
Training loss: 0.675463855266571
Validation loss: 2.018791894117991

Epoch: 6| Step: 2
Training loss: 0.28539982438087463
Validation loss: 2.0439729491869607

Epoch: 6| Step: 3
Training loss: 0.17180559039115906
Validation loss: 2.031895657380422

Epoch: 6| Step: 4
Training loss: 0.6215612888336182
Validation loss: 2.0216630498568215

Epoch: 6| Step: 5
Training loss: 0.2893657982349396
Validation loss: 2.0304575165112815

Epoch: 6| Step: 6
Training loss: 0.5140748023986816
Validation loss: 2.0297663609186807

Epoch: 6| Step: 7
Training loss: 0.41645529866218567
Validation loss: 2.043783664703369

Epoch: 6| Step: 8
Training loss: 0.21856878697872162
Validation loss: 2.0355223615964255

Epoch: 6| Step: 9
Training loss: 0.16839571297168732
Validation loss: 2.028887152671814

Epoch: 6| Step: 10
Training loss: 0.17084699869155884
Validation loss: 2.041627128918966

Epoch: 6| Step: 11
Training loss: 0.492281436920166
Validation loss: 2.0153926809628806

Epoch: 6| Step: 12
Training loss: 0.6622694730758667
Validation loss: 1.9995012680689495

Epoch: 6| Step: 13
Training loss: 0.3588007688522339
Validation loss: 2.0022794604301453

Epoch: 237| Step: 0
Training loss: 0.4325636625289917
Validation loss: 2.0211562712987265

Epoch: 6| Step: 1
Training loss: 0.2874806523323059
Validation loss: 1.9793437321980794

Epoch: 6| Step: 2
Training loss: 0.7413747310638428
Validation loss: 2.0217354695002236

Epoch: 6| Step: 3
Training loss: 0.18627914786338806
Validation loss: 2.06941556930542

Epoch: 6| Step: 4
Training loss: 0.4553740620613098
Validation loss: 2.039413789908091

Epoch: 6| Step: 5
Training loss: 0.5379423499107361
Validation loss: 2.078159670035044

Epoch: 6| Step: 6
Training loss: 0.34243839979171753
Validation loss: 2.023040235042572

Epoch: 6| Step: 7
Training loss: 0.5809518694877625
Validation loss: 2.0261579354604087

Epoch: 6| Step: 8
Training loss: 0.5304995775222778
Validation loss: 2.0260078509648642

Epoch: 6| Step: 9
Training loss: 0.39872539043426514
Validation loss: 2.0471633871396384

Epoch: 6| Step: 10
Training loss: 0.3581685423851013
Validation loss: 1.9858755469322205

Epoch: 6| Step: 11
Training loss: 0.457866370677948
Validation loss: 2.0534986654917398

Epoch: 6| Step: 12
Training loss: 0.3154267370700836
Validation loss: 2.001229246457418

Epoch: 6| Step: 13
Training loss: 0.34262698888778687
Validation loss: 2.0239928166071572

Epoch: 238| Step: 0
Training loss: 0.39156705141067505
Validation loss: 2.0289804538091025

Epoch: 6| Step: 1
Training loss: 0.4651601314544678
Validation loss: 2.0573023160298667

Epoch: 6| Step: 2
Training loss: 0.4850766956806183
Validation loss: 2.0000930428504944

Epoch: 6| Step: 3
Training loss: 0.3215624690055847
Validation loss: 2.055274029572805

Epoch: 6| Step: 4
Training loss: 0.36455392837524414
Validation loss: 2.024666210015615

Epoch: 6| Step: 5
Training loss: 0.3888850808143616
Validation loss: 2.0347417195638022

Epoch: 6| Step: 6
Training loss: 0.45919185876846313
Validation loss: 2.0777000188827515

Epoch: 6| Step: 7
Training loss: 0.31476444005966187
Validation loss: 2.028610368569692

Epoch: 6| Step: 8
Training loss: 0.6036777496337891
Validation loss: 2.048337380091349

Epoch: 6| Step: 9
Training loss: 0.2631618082523346
Validation loss: 2.039617399374644

Epoch: 6| Step: 10
Training loss: 0.6525817513465881
Validation loss: 2.053708295027415

Epoch: 6| Step: 11
Training loss: 0.24173550307750702
Validation loss: 1.9762403170267742

Epoch: 6| Step: 12
Training loss: 0.31239259243011475
Validation loss: 2.046218752861023

Epoch: 6| Step: 13
Training loss: 0.18655823171138763
Validation loss: 2.0586335261662803

Epoch: 239| Step: 0
Training loss: 0.3752560615539551
Validation loss: 2.062789479891459

Epoch: 6| Step: 1
Training loss: 0.27615663409233093
Validation loss: 2.048662543296814

Epoch: 6| Step: 2
Training loss: 0.23354844748973846
Validation loss: 2.08033549785614

Epoch: 6| Step: 3
Training loss: 0.44347262382507324
Validation loss: 2.0458648204803467

Epoch: 6| Step: 4
Training loss: 0.1735135018825531
Validation loss: 2.0652045210202536

Epoch: 6| Step: 5
Training loss: 0.6510207653045654
Validation loss: 1.9985771576563518

Epoch: 6| Step: 6
Training loss: 0.33178699016571045
Validation loss: 1.9982256094614665

Epoch: 6| Step: 7
Training loss: 0.21872739493846893
Validation loss: 2.008250812689463

Epoch: 6| Step: 8
Training loss: 0.3620157539844513
Validation loss: 2.0612862507502236

Epoch: 6| Step: 9
Training loss: 0.6651062965393066
Validation loss: 2.081986387570699

Epoch: 6| Step: 10
Training loss: 0.22921308875083923
Validation loss: 2.080830176671346

Epoch: 6| Step: 11
Training loss: 0.41899389028549194
Validation loss: 2.0585468212763467

Epoch: 6| Step: 12
Training loss: 0.470673143863678
Validation loss: 2.0712023178736367

Epoch: 6| Step: 13
Training loss: 0.39688923954963684
Validation loss: 2.0659735997517905

Epoch: 240| Step: 0
Training loss: 0.4501371383666992
Validation loss: 2.0548605918884277

Epoch: 6| Step: 1
Training loss: 0.560420036315918
Validation loss: 2.0121554136276245

Epoch: 6| Step: 2
Training loss: 0.1686781346797943
Validation loss: 2.021990120410919

Epoch: 6| Step: 3
Training loss: 0.47508811950683594
Validation loss: 1.9857850472132366

Epoch: 6| Step: 4
Training loss: 0.29267776012420654
Validation loss: 2.0270333886146545

Epoch: 6| Step: 5
Training loss: 0.34931492805480957
Validation loss: 2.0564839045206704

Epoch: 6| Step: 6
Training loss: 0.2521195411682129
Validation loss: 2.012351095676422

Epoch: 6| Step: 7
Training loss: 0.721447229385376
Validation loss: 2.0133246978123984

Epoch: 6| Step: 8
Training loss: 0.2762303054332733
Validation loss: 2.0149682760238647

Epoch: 6| Step: 9
Training loss: 0.40298187732696533
Validation loss: 2.0243597825368247

Epoch: 6| Step: 10
Training loss: 0.2988482415676117
Validation loss: 2.00458824634552

Epoch: 6| Step: 11
Training loss: 0.3527431786060333
Validation loss: 1.9939285119374592

Epoch: 6| Step: 12
Training loss: 0.35335874557495117
Validation loss: 2.0020561615626016

Epoch: 6| Step: 13
Training loss: 0.19938114285469055
Validation loss: 2.0185116132100425

Epoch: 241| Step: 0
Training loss: 0.3321085572242737
Validation loss: 2.0494601726531982

Epoch: 6| Step: 1
Training loss: 0.22384798526763916
Validation loss: 2.0052437583605447

Epoch: 6| Step: 2
Training loss: 0.21524223685264587
Validation loss: 1.9625376065572102

Epoch: 6| Step: 3
Training loss: 0.6681109666824341
Validation loss: 1.9740922649701436

Epoch: 6| Step: 4
Training loss: 0.23265832662582397
Validation loss: 1.956550141175588

Epoch: 6| Step: 5
Training loss: 0.2621578872203827
Validation loss: 2.0146981676419577

Epoch: 6| Step: 6
Training loss: 0.4647855758666992
Validation loss: 2.0505480766296387

Epoch: 6| Step: 7
Training loss: 0.5088803768157959
Validation loss: 2.0044760505358377

Epoch: 6| Step: 8
Training loss: 0.4295998811721802
Validation loss: 2.020298699537913

Epoch: 6| Step: 9
Training loss: 0.23258733749389648
Validation loss: 2.019676943620046

Epoch: 6| Step: 10
Training loss: 0.4215545654296875
Validation loss: 1.9906249443689983

Epoch: 6| Step: 11
Training loss: 0.6672540903091431
Validation loss: 2.009844104448954

Epoch: 6| Step: 12
Training loss: 0.26984840631484985
Validation loss: 1.9868237972259521

Epoch: 6| Step: 13
Training loss: 0.31909024715423584
Validation loss: 1.9822616577148438

Epoch: 242| Step: 0
Training loss: 0.24862021207809448
Validation loss: 1.9864456057548523

Epoch: 6| Step: 1
Training loss: 0.19950580596923828
Validation loss: 2.024523933728536

Epoch: 6| Step: 2
Training loss: 0.22383233904838562
Validation loss: 1.9671685099601746

Epoch: 6| Step: 3
Training loss: 0.4280833303928375
Validation loss: 2.0388152400652566

Epoch: 6| Step: 4
Training loss: 0.4177487790584564
Validation loss: 2.02236400047938

Epoch: 6| Step: 5
Training loss: 0.38793349266052246
Validation loss: 2.044774870077769

Epoch: 6| Step: 6
Training loss: 0.49846524000167847
Validation loss: 2.051958680152893

Epoch: 6| Step: 7
Training loss: 0.39386871457099915
Validation loss: 2.0438743432362876

Epoch: 6| Step: 8
Training loss: 0.2999458312988281
Validation loss: 2.0536771416664124

Epoch: 6| Step: 9
Training loss: 0.6803073883056641
Validation loss: 2.057184398174286

Epoch: 6| Step: 10
Training loss: 0.20039671659469604
Validation loss: 2.030036985874176

Epoch: 6| Step: 11
Training loss: 0.3564797043800354
Validation loss: 2.061885356903076

Epoch: 6| Step: 12
Training loss: 0.24285665154457092
Validation loss: 2.0265696247418723

Epoch: 6| Step: 13
Training loss: 0.5346990823745728
Validation loss: 2.0630696415901184

Epoch: 243| Step: 0
Training loss: 0.4592762589454651
Validation loss: 2.1104182600975037

Epoch: 6| Step: 1
Training loss: 0.2915324866771698
Validation loss: 2.0592466394106546

Epoch: 6| Step: 2
Training loss: 0.28529560565948486
Validation loss: 2.0569276412328086

Epoch: 6| Step: 3
Training loss: 0.3486303687095642
Validation loss: 2.033910890420278

Epoch: 6| Step: 4
Training loss: 0.2181631326675415
Validation loss: 2.0463106433550515

Epoch: 6| Step: 5
Training loss: 0.5831719636917114
Validation loss: 2.0781936049461365

Epoch: 6| Step: 6
Training loss: 0.49176275730133057
Validation loss: 2.0208479960759482

Epoch: 6| Step: 7
Training loss: 0.3315928876399994
Validation loss: 2.0713977217674255

Epoch: 6| Step: 8
Training loss: 0.3670573830604553
Validation loss: 2.0501123468081155

Epoch: 6| Step: 9
Training loss: 0.25909852981567383
Validation loss: 2.074747085571289

Epoch: 6| Step: 10
Training loss: 0.6939660906791687
Validation loss: 2.1208948294321694

Epoch: 6| Step: 11
Training loss: 0.3565266728401184
Validation loss: 2.0875132282574973

Epoch: 6| Step: 12
Training loss: 0.19801340997219086
Validation loss: 2.046890079975128

Epoch: 6| Step: 13
Training loss: 0.3618360459804535
Validation loss: 2.1072526772816977

Epoch: 244| Step: 0
Training loss: 0.26028960943222046
Validation loss: 2.055757979551951

Epoch: 6| Step: 1
Training loss: 0.44934776425361633
Validation loss: 2.0363409519195557

Epoch: 6| Step: 2
Training loss: 0.500403642654419
Validation loss: 2.0893666545550027

Epoch: 6| Step: 3
Training loss: 0.402983158826828
Validation loss: 2.029312868913015

Epoch: 6| Step: 4
Training loss: 0.7372386455535889
Validation loss: 2.071009933948517

Epoch: 6| Step: 5
Training loss: 0.24563166499137878
Validation loss: 2.01945569117864

Epoch: 6| Step: 6
Training loss: 0.4886583685874939
Validation loss: 2.0616923570632935

Epoch: 6| Step: 7
Training loss: 0.34334903955459595
Validation loss: 2.0570478638013205

Epoch: 6| Step: 8
Training loss: 0.4604567885398865
Validation loss: 2.0502032041549683

Epoch: 6| Step: 9
Training loss: 0.4052990674972534
Validation loss: 2.1028025348981223

Epoch: 6| Step: 10
Training loss: 0.2952636778354645
Validation loss: 2.0549131830533347

Epoch: 6| Step: 11
Training loss: 0.4970768094062805
Validation loss: 2.0607099731763205

Epoch: 6| Step: 12
Training loss: 0.2800624370574951
Validation loss: 2.0507558584213257

Epoch: 6| Step: 13
Training loss: 0.4291912615299225
Validation loss: 2.0071162382761636

Epoch: 245| Step: 0
Training loss: 0.3025554418563843
Validation loss: 1.971388816833496

Epoch: 6| Step: 1
Training loss: 0.6834467649459839
Validation loss: 1.991154670715332

Epoch: 6| Step: 2
Training loss: 0.21113601326942444
Validation loss: 1.9625306129455566

Epoch: 6| Step: 3
Training loss: 0.4595971703529358
Validation loss: 1.9618744651476543

Epoch: 6| Step: 4
Training loss: 0.17555153369903564
Validation loss: 2.0144202510515847

Epoch: 6| Step: 5
Training loss: 0.3566385805606842
Validation loss: 2.0297266046206155

Epoch: 6| Step: 6
Training loss: 0.4272724688053131
Validation loss: 2.0306797424952188

Epoch: 6| Step: 7
Training loss: 0.4948030412197113
Validation loss: 2.023121198018392

Epoch: 6| Step: 8
Training loss: 0.3131440579891205
Validation loss: 2.0144057472546897

Epoch: 6| Step: 9
Training loss: 0.4236600399017334
Validation loss: 2.010686973730723

Epoch: 6| Step: 10
Training loss: 0.36222177743911743
Validation loss: 1.9634308815002441

Epoch: 6| Step: 11
Training loss: 0.2330930233001709
Validation loss: 2.00016196568807

Epoch: 6| Step: 12
Training loss: 0.7291500568389893
Validation loss: 1.9899665315945942

Epoch: 6| Step: 13
Training loss: 0.45737242698669434
Validation loss: 1.9913825790087383

Epoch: 246| Step: 0
Training loss: 0.18326683342456818
Validation loss: 1.991172969341278

Epoch: 6| Step: 1
Training loss: 0.27521273493766785
Validation loss: 2.0002069671948752

Epoch: 6| Step: 2
Training loss: 0.46530771255493164
Validation loss: 2.054669817288717

Epoch: 6| Step: 3
Training loss: 0.2230527698993683
Validation loss: 2.0446048180262246

Epoch: 6| Step: 4
Training loss: 0.513746976852417
Validation loss: 2.0200610160827637

Epoch: 6| Step: 5
Training loss: 0.3792728781700134
Validation loss: 1.9973219434420268

Epoch: 6| Step: 6
Training loss: 0.3101080060005188
Validation loss: 1.9862504800160725

Epoch: 6| Step: 7
Training loss: 0.583737850189209
Validation loss: 2.009185711542765

Epoch: 6| Step: 8
Training loss: 0.5140568017959595
Validation loss: 1.956970751285553

Epoch: 6| Step: 9
Training loss: 0.8067771196365356
Validation loss: 2.004268785317739

Epoch: 6| Step: 10
Training loss: 0.35738345980644226
Validation loss: 1.980777104695638

Epoch: 6| Step: 11
Training loss: 0.4815595746040344
Validation loss: 1.9970803658167522

Epoch: 6| Step: 12
Training loss: 0.33102983236312866
Validation loss: 2.0048319697380066

Epoch: 6| Step: 13
Training loss: 0.41319501399993896
Validation loss: 2.053571959336599

Epoch: 247| Step: 0
Training loss: 0.5753462910652161
Validation loss: 2.0314285159111023

Epoch: 6| Step: 1
Training loss: 0.2956307828426361
Validation loss: 2.0601483384768167

Epoch: 6| Step: 2
Training loss: 0.375488817691803
Validation loss: 2.0393826564153037

Epoch: 6| Step: 3
Training loss: 0.6300126314163208
Validation loss: 2.010407865047455

Epoch: 6| Step: 4
Training loss: 0.2850702404975891
Validation loss: 2.0202166040738425

Epoch: 6| Step: 5
Training loss: 0.31900060176849365
Validation loss: 2.0186495979626975

Epoch: 6| Step: 6
Training loss: 0.3576193153858185
Validation loss: 1.9804513454437256

Epoch: 6| Step: 7
Training loss: 0.44166478514671326
Validation loss: 2.0231836438179016

Epoch: 6| Step: 8
Training loss: 0.2645096778869629
Validation loss: 1.9912967085838318

Epoch: 6| Step: 9
Training loss: 0.24104949831962585
Validation loss: 2.012600382169088

Epoch: 6| Step: 10
Training loss: 0.30971193313598633
Validation loss: 2.040629585584005

Epoch: 6| Step: 11
Training loss: 0.4200381636619568
Validation loss: 2.0062227050463357

Epoch: 6| Step: 12
Training loss: 0.9037383794784546
Validation loss: 2.0333794355392456

Epoch: 6| Step: 13
Training loss: 0.2730029225349426
Validation loss: 2.022269388039907

Epoch: 248| Step: 0
Training loss: 0.1982404589653015
Validation loss: 1.9788089195887248

Epoch: 6| Step: 1
Training loss: 0.2073015421628952
Validation loss: 2.0519238710403442

Epoch: 6| Step: 2
Training loss: 0.8418952226638794
Validation loss: 2.0568139354387918

Epoch: 6| Step: 3
Training loss: 0.6288938522338867
Validation loss: 2.023815373579661

Epoch: 6| Step: 4
Training loss: 0.2850266695022583
Validation loss: 2.0346781412760415

Epoch: 6| Step: 5
Training loss: 0.18967416882514954
Validation loss: 2.0518948833147683

Epoch: 6| Step: 6
Training loss: 0.22242800891399384
Validation loss: 2.0563749074935913

Epoch: 6| Step: 7
Training loss: 0.3077937066555023
Validation loss: 2.050530513127645

Epoch: 6| Step: 8
Training loss: 0.3778188228607178
Validation loss: 2.012331167856852

Epoch: 6| Step: 9
Training loss: 0.2404797077178955
Validation loss: 2.0178568363189697

Epoch: 6| Step: 10
Training loss: 0.38335680961608887
Validation loss: 2.0461524724960327

Epoch: 6| Step: 11
Training loss: 0.4362306296825409
Validation loss: 2.041725476582845

Epoch: 6| Step: 12
Training loss: 0.3119325041770935
Validation loss: 2.079409738381704

Epoch: 6| Step: 13
Training loss: 0.4386615455150604
Validation loss: 1.974806308746338

Epoch: 249| Step: 0
Training loss: 0.7236843109130859
Validation loss: 2.0153233210245767

Epoch: 6| Step: 1
Training loss: 0.334696888923645
Validation loss: 2.0595500071843467

Epoch: 6| Step: 2
Training loss: 0.5295313000679016
Validation loss: 2.0609933137893677

Epoch: 6| Step: 3
Training loss: 0.31459349393844604
Validation loss: 2.042060216267904

Epoch: 6| Step: 4
Training loss: 0.34495604038238525
Validation loss: 2.0618247588475547

Epoch: 6| Step: 5
Training loss: 0.2945541739463806
Validation loss: 2.005071302254995

Epoch: 6| Step: 6
Training loss: 0.5432936549186707
Validation loss: 1.9781037370363872

Epoch: 6| Step: 7
Training loss: 0.5324434041976929
Validation loss: 1.9920094013214111

Epoch: 6| Step: 8
Training loss: 0.2171037346124649
Validation loss: 1.9584941267967224

Epoch: 6| Step: 9
Training loss: 0.35292720794677734
Validation loss: 1.969508667786916

Epoch: 6| Step: 10
Training loss: 0.2510659396648407
Validation loss: 2.0217496355374656

Epoch: 6| Step: 11
Training loss: 0.5991430282592773
Validation loss: 2.041305879751841

Epoch: 6| Step: 12
Training loss: 0.3186015486717224
Validation loss: 2.0632665952046714

Epoch: 6| Step: 13
Training loss: 0.36542487144470215
Validation loss: 2.051888644695282

Epoch: 250| Step: 0
Training loss: 0.48861801624298096
Validation loss: 2.0909159978230796

Epoch: 6| Step: 1
Training loss: 0.3095279932022095
Validation loss: 2.0631908575693765

Epoch: 6| Step: 2
Training loss: 0.30921846628189087
Validation loss: 2.0705039898554483

Epoch: 6| Step: 3
Training loss: 0.45177584886550903
Validation loss: 2.017299791177114

Epoch: 6| Step: 4
Training loss: 0.16106991469860077
Validation loss: 2.0039568146069846

Epoch: 6| Step: 5
Training loss: 0.5138989686965942
Validation loss: 2.0163503686587014

Epoch: 6| Step: 6
Training loss: 0.29339364171028137
Validation loss: 2.0375418265660605

Epoch: 6| Step: 7
Training loss: 0.3710775375366211
Validation loss: 2.041432519753774

Epoch: 6| Step: 8
Training loss: 0.27816107869148254
Validation loss: 2.025757928689321

Epoch: 6| Step: 9
Training loss: 0.6624990105628967
Validation loss: 2.0730495850245156

Epoch: 6| Step: 10
Training loss: 0.316582590341568
Validation loss: 2.0699382623036704

Epoch: 6| Step: 11
Training loss: 0.48277217149734497
Validation loss: 2.0665521820386252

Epoch: 6| Step: 12
Training loss: 0.4477955102920532
Validation loss: 2.0428384939829507

Epoch: 6| Step: 13
Training loss: 0.47293031215667725
Validation loss: 2.1253896752993264

Epoch: 251| Step: 0
Training loss: 0.8874115943908691
Validation loss: 2.062886337439219

Epoch: 6| Step: 1
Training loss: 0.256061851978302
Validation loss: 2.099151094754537

Epoch: 6| Step: 2
Training loss: 0.28327277302742004
Validation loss: 2.087353607018789

Epoch: 6| Step: 3
Training loss: 0.43250566720962524
Validation loss: 2.0707596143086753

Epoch: 6| Step: 4
Training loss: 0.3650279641151428
Validation loss: 2.0384910305341086

Epoch: 6| Step: 5
Training loss: 0.2699703574180603
Validation loss: 2.1007914543151855

Epoch: 6| Step: 6
Training loss: 0.43666329979896545
Validation loss: 2.094210763772329

Epoch: 6| Step: 7
Training loss: 0.5111240148544312
Validation loss: 2.0580747723579407

Epoch: 6| Step: 8
Training loss: 0.2911422848701477
Validation loss: 2.0502530932426453

Epoch: 6| Step: 9
Training loss: 0.5817509293556213
Validation loss: 2.0689865946769714

Epoch: 6| Step: 10
Training loss: 0.2059764564037323
Validation loss: 2.0937798817952475

Epoch: 6| Step: 11
Training loss: 0.30356401205062866
Validation loss: 2.089294453461965

Epoch: 6| Step: 12
Training loss: 0.3477950990200043
Validation loss: 2.04887855052948

Epoch: 6| Step: 13
Training loss: 0.42106226086616516
Validation loss: 2.0701677799224854

Epoch: 252| Step: 0
Training loss: 0.31810206174850464
Validation loss: 1.9986725648244221

Epoch: 6| Step: 1
Training loss: 0.3049391508102417
Validation loss: 2.044178326924642

Epoch: 6| Step: 2
Training loss: 0.17211440205574036
Validation loss: 2.0075537959734597

Epoch: 6| Step: 3
Training loss: 0.28429561853408813
Validation loss: 2.0522210001945496

Epoch: 6| Step: 4
Training loss: 0.19402258098125458
Validation loss: 2.0369691451390586

Epoch: 6| Step: 5
Training loss: 0.3746943473815918
Validation loss: 2.0164294441541037

Epoch: 6| Step: 6
Training loss: 0.3432076871395111
Validation loss: 1.9870413939158122

Epoch: 6| Step: 7
Training loss: 0.42649543285369873
Validation loss: 2.029028336207072

Epoch: 6| Step: 8
Training loss: 0.36129865050315857
Validation loss: 2.061418910821279

Epoch: 6| Step: 9
Training loss: 0.3630918860435486
Validation loss: 2.075357735157013

Epoch: 6| Step: 10
Training loss: 0.2451854646205902
Validation loss: 1.9923198421796162

Epoch: 6| Step: 11
Training loss: 0.5028156042098999
Validation loss: 2.0798041621843972

Epoch: 6| Step: 12
Training loss: 0.40904223918914795
Validation loss: 2.03805410861969

Epoch: 6| Step: 13
Training loss: 0.9500196576118469
Validation loss: 2.0431321461995444

Epoch: 253| Step: 0
Training loss: 0.2963339686393738
Validation loss: 2.0665679971377053

Epoch: 6| Step: 1
Training loss: 0.2594912052154541
Validation loss: 2.0486140847206116

Epoch: 6| Step: 2
Training loss: 0.4792426526546478
Validation loss: 2.01840740442276

Epoch: 6| Step: 3
Training loss: 0.6685943007469177
Validation loss: 2.066482901573181

Epoch: 6| Step: 4
Training loss: 0.2510372996330261
Validation loss: 2.078429341316223

Epoch: 6| Step: 5
Training loss: 0.38912057876586914
Validation loss: 2.0376351475715637

Epoch: 6| Step: 6
Training loss: 0.5860544443130493
Validation loss: 2.0517351826032004

Epoch: 6| Step: 7
Training loss: 0.4964047372341156
Validation loss: 2.050020714600881

Epoch: 6| Step: 8
Training loss: 0.21811562776565552
Validation loss: 1.9936687151590984

Epoch: 6| Step: 9
Training loss: 0.34723976254463196
Validation loss: 2.0528260270754495

Epoch: 6| Step: 10
Training loss: 0.3386625647544861
Validation loss: 2.016747613747915

Epoch: 6| Step: 11
Training loss: 0.19802916049957275
Validation loss: 2.039906839529673

Epoch: 6| Step: 12
Training loss: 0.2546166479587555
Validation loss: 2.038878579934438

Epoch: 6| Step: 13
Training loss: 0.4474513828754425
Validation loss: 2.0592320760091147

Epoch: 254| Step: 0
Training loss: 0.23505616188049316
Validation loss: 2.0175325671831765

Epoch: 6| Step: 1
Training loss: 0.2745266556739807
Validation loss: 2.0373350977897644

Epoch: 6| Step: 2
Training loss: 0.2665756046772003
Validation loss: 2.0399532318115234

Epoch: 6| Step: 3
Training loss: 0.6842302083969116
Validation loss: 2.0613202253977456

Epoch: 6| Step: 4
Training loss: 0.23947802186012268
Validation loss: 2.035897970199585

Epoch: 6| Step: 5
Training loss: 0.17953908443450928
Validation loss: 2.0353795289993286

Epoch: 6| Step: 6
Training loss: 0.417330801486969
Validation loss: 2.045847733815511

Epoch: 6| Step: 7
Training loss: 0.28801584243774414
Validation loss: 1.964859147866567

Epoch: 6| Step: 8
Training loss: 0.3784569799900055
Validation loss: 2.035773754119873

Epoch: 6| Step: 9
Training loss: 0.23419201374053955
Validation loss: 1.9964478810628254

Epoch: 6| Step: 10
Training loss: 0.3014857769012451
Validation loss: 2.042606830596924

Epoch: 6| Step: 11
Training loss: 0.37894922494888306
Validation loss: 2.0358197490374246

Epoch: 6| Step: 12
Training loss: 0.36533820629119873
Validation loss: 2.020144840081533

Epoch: 6| Step: 13
Training loss: 0.7551286220550537
Validation loss: 2.0041458209355674

Epoch: 255| Step: 0
Training loss: 0.37231242656707764
Validation loss: 1.9568037788073223

Epoch: 6| Step: 1
Training loss: 0.28049248456954956
Validation loss: 1.982600708802541

Epoch: 6| Step: 2
Training loss: 0.6431800127029419
Validation loss: 2.0062180757522583

Epoch: 6| Step: 3
Training loss: 0.6402862071990967
Validation loss: 2.0293823877970376

Epoch: 6| Step: 4
Training loss: 0.30746448040008545
Validation loss: 2.038150111834208

Epoch: 6| Step: 5
Training loss: 0.2393748015165329
Validation loss: 2.0024892489115396

Epoch: 6| Step: 6
Training loss: 0.29531052708625793
Validation loss: 2.020223240057627

Epoch: 6| Step: 7
Training loss: 0.4499722123146057
Validation loss: 2.0119107365608215

Epoch: 6| Step: 8
Training loss: 0.4850728511810303
Validation loss: 2.0310055216153464

Epoch: 6| Step: 9
Training loss: 0.46766170859336853
Validation loss: 2.023548980553945

Epoch: 6| Step: 10
Training loss: 0.22936293482780457
Validation loss: 2.0322134693463645

Epoch: 6| Step: 11
Training loss: 0.40652531385421753
Validation loss: 2.034227708975474

Epoch: 6| Step: 12
Training loss: 0.19933032989501953
Validation loss: 1.9954825441042583

Epoch: 6| Step: 13
Training loss: 0.2114974856376648
Validation loss: 2.024605174859365

Epoch: 256| Step: 0
Training loss: 0.2648766040802002
Validation loss: 1.9866305987040203

Epoch: 6| Step: 1
Training loss: 0.32718443870544434
Validation loss: 2.021018465360006

Epoch: 6| Step: 2
Training loss: 0.3368666172027588
Validation loss: 2.0216610431671143

Epoch: 6| Step: 3
Training loss: 0.4438624978065491
Validation loss: 2.0256412029266357

Epoch: 6| Step: 4
Training loss: 0.4211222529411316
Validation loss: 2.0563130577405295

Epoch: 6| Step: 5
Training loss: 0.3123125731945038
Validation loss: 2.0215516090393066

Epoch: 6| Step: 6
Training loss: 0.3371031880378723
Validation loss: 2.0257155100504556

Epoch: 6| Step: 7
Training loss: 0.5884241461753845
Validation loss: 2.040103813012441

Epoch: 6| Step: 8
Training loss: 0.3601754307746887
Validation loss: 2.0071034828821817

Epoch: 6| Step: 9
Training loss: 0.285846471786499
Validation loss: 2.025420308113098

Epoch: 6| Step: 10
Training loss: 0.2927960157394409
Validation loss: 2.0684757232666016

Epoch: 6| Step: 11
Training loss: 0.3110868036746979
Validation loss: 2.0501811106999717

Epoch: 6| Step: 12
Training loss: 0.24106836318969727
Validation loss: 2.0273627440134683

Epoch: 6| Step: 13
Training loss: 0.5644007921218872
Validation loss: 2.0595909357070923

Epoch: 257| Step: 0
Training loss: 0.1654222011566162
Validation loss: 2.0225799481074014

Epoch: 6| Step: 1
Training loss: 0.4433837831020355
Validation loss: 2.027737816174825

Epoch: 6| Step: 2
Training loss: 0.37599509954452515
Validation loss: 2.053547461827596

Epoch: 6| Step: 3
Training loss: 0.30329033732414246
Validation loss: 2.0232134660085044

Epoch: 6| Step: 4
Training loss: 0.37747612595558167
Validation loss: 2.0235283573468528

Epoch: 6| Step: 5
Training loss: 0.2964114248752594
Validation loss: 2.072771151860555

Epoch: 6| Step: 6
Training loss: 0.183949276804924
Validation loss: 2.010568122069041

Epoch: 6| Step: 7
Training loss: 0.7833579778671265
Validation loss: 1.994564135869344

Epoch: 6| Step: 8
Training loss: 0.3516606390476227
Validation loss: 2.0408241748809814

Epoch: 6| Step: 9
Training loss: 0.2114415168762207
Validation loss: 2.0425761938095093

Epoch: 6| Step: 10
Training loss: 0.3969860076904297
Validation loss: 2.0286589662233987

Epoch: 6| Step: 11
Training loss: 0.27867594361305237
Validation loss: 2.006365736325582

Epoch: 6| Step: 12
Training loss: 0.22106194496154785
Validation loss: 2.015178402264913

Epoch: 6| Step: 13
Training loss: 0.5136462450027466
Validation loss: 2.017458359400431

Epoch: 258| Step: 0
Training loss: 0.37021106481552124
Validation loss: 2.0066783825556436

Epoch: 6| Step: 1
Training loss: 0.3649209439754486
Validation loss: 1.9721342325210571

Epoch: 6| Step: 2
Training loss: 0.7551361918449402
Validation loss: 2.021057665348053

Epoch: 6| Step: 3
Training loss: 0.3363646864891052
Validation loss: 2.0483230551083884

Epoch: 6| Step: 4
Training loss: 0.4551140069961548
Validation loss: 2.0394715070724487

Epoch: 6| Step: 5
Training loss: 0.5298444032669067
Validation loss: 2.057587742805481

Epoch: 6| Step: 6
Training loss: 0.45973923802375793
Validation loss: 2.073053320248922

Epoch: 6| Step: 7
Training loss: 0.26316583156585693
Validation loss: 2.0826622446378074

Epoch: 6| Step: 8
Training loss: 0.23125074803829193
Validation loss: 2.0434367855389914

Epoch: 6| Step: 9
Training loss: 0.33077025413513184
Validation loss: 2.023904800415039

Epoch: 6| Step: 10
Training loss: 0.2972494065761566
Validation loss: 2.01582940419515

Epoch: 6| Step: 11
Training loss: 0.38333284854888916
Validation loss: 2.045068601767222

Epoch: 6| Step: 12
Training loss: 0.49015361070632935
Validation loss: 2.040282686551412

Epoch: 6| Step: 13
Training loss: 0.24577254056930542
Validation loss: 2.012835363547007

Epoch: 259| Step: 0
Training loss: 0.3457449674606323
Validation loss: 2.0261704325675964

Epoch: 6| Step: 1
Training loss: 0.2295154333114624
Validation loss: 2.0187535484631858

Epoch: 6| Step: 2
Training loss: 0.29577717185020447
Validation loss: 2.0525843501091003

Epoch: 6| Step: 3
Training loss: 0.16010721027851105
Validation loss: 2.0865928332010903

Epoch: 6| Step: 4
Training loss: 0.5248558521270752
Validation loss: 2.0256802241007485

Epoch: 6| Step: 5
Training loss: 0.31297579407691956
Validation loss: 2.017819583415985

Epoch: 6| Step: 6
Training loss: 0.20483583211898804
Validation loss: 2.0209766228993735

Epoch: 6| Step: 7
Training loss: 0.36653226613998413
Validation loss: 2.015696962674459

Epoch: 6| Step: 8
Training loss: 0.5722755789756775
Validation loss: 1.9724195003509521

Epoch: 6| Step: 9
Training loss: 0.2912851870059967
Validation loss: 2.0204179088274636

Epoch: 6| Step: 10
Training loss: 0.36657804250717163
Validation loss: 2.0373695294062295

Epoch: 6| Step: 11
Training loss: 0.3777428865432739
Validation loss: 2.0400926073392234

Epoch: 6| Step: 12
Training loss: 0.5666968822479248
Validation loss: 2.0474549531936646

Epoch: 6| Step: 13
Training loss: 0.7103341817855835
Validation loss: 2.037261684735616

Epoch: 260| Step: 0
Training loss: 0.24891270697116852
Validation loss: 2.0003957748413086

Epoch: 6| Step: 1
Training loss: 0.30472737550735474
Validation loss: 2.034985899925232

Epoch: 6| Step: 2
Training loss: 0.28081050515174866
Validation loss: 2.0408698519070945

Epoch: 6| Step: 3
Training loss: 0.22021189332008362
Validation loss: 2.020084341367086

Epoch: 6| Step: 4
Training loss: 0.20435939729213715
Validation loss: 2.052421450614929

Epoch: 6| Step: 5
Training loss: 0.27171918749809265
Validation loss: 2.0559272368748984

Epoch: 6| Step: 6
Training loss: 0.19795989990234375
Validation loss: 2.0665623346964517

Epoch: 6| Step: 7
Training loss: 0.2247198075056076
Validation loss: 2.0487241546312966

Epoch: 6| Step: 8
Training loss: 0.2607957124710083
Validation loss: 2.0116958618164062

Epoch: 6| Step: 9
Training loss: 0.33915114402770996
Validation loss: 2.0414281090100608

Epoch: 6| Step: 10
Training loss: 0.26997557282447815
Validation loss: 2.0024168491363525

Epoch: 6| Step: 11
Training loss: 0.5534524917602539
Validation loss: 2.0222471157709756

Epoch: 6| Step: 12
Training loss: 0.7030398845672607
Validation loss: 2.0279197096824646

Epoch: 6| Step: 13
Training loss: 0.67635577917099
Validation loss: 1.9826399683952332

Epoch: 261| Step: 0
Training loss: 0.3566441237926483
Validation loss: 2.032664636770884

Epoch: 6| Step: 1
Training loss: 0.16883231699466705
Validation loss: 2.0398168762524924

Epoch: 6| Step: 2
Training loss: 0.5744394063949585
Validation loss: 1.9952240586280823

Epoch: 6| Step: 3
Training loss: 0.42880725860595703
Validation loss: 2.068456212679545

Epoch: 6| Step: 4
Training loss: 0.6437166333198547
Validation loss: 1.9906784097353618

Epoch: 6| Step: 5
Training loss: 0.3069496750831604
Validation loss: 2.0139158169428506

Epoch: 6| Step: 6
Training loss: 0.2668262720108032
Validation loss: 1.994974136352539

Epoch: 6| Step: 7
Training loss: 0.2748758792877197
Validation loss: 1.9861314694086711

Epoch: 6| Step: 8
Training loss: 0.24273400008678436
Validation loss: 2.0247392654418945

Epoch: 6| Step: 9
Training loss: 0.44848132133483887
Validation loss: 2.044593632221222

Epoch: 6| Step: 10
Training loss: 0.3384382426738739
Validation loss: 2.02496737241745

Epoch: 6| Step: 11
Training loss: 0.37586432695388794
Validation loss: 2.0493088960647583

Epoch: 6| Step: 12
Training loss: 0.4166654050350189
Validation loss: 2.0124367276827493

Epoch: 6| Step: 13
Training loss: 0.21787653863430023
Validation loss: 2.0500885446866355

Epoch: 262| Step: 0
Training loss: 0.5639381408691406
Validation loss: 2.0465484857559204

Epoch: 6| Step: 1
Training loss: 0.49164867401123047
Validation loss: 2.005829691886902

Epoch: 6| Step: 2
Training loss: 0.202327698469162
Validation loss: 2.0396810173988342

Epoch: 6| Step: 3
Training loss: 0.2003786265850067
Validation loss: 2.0237212578455606

Epoch: 6| Step: 4
Training loss: 0.4831134080886841
Validation loss: 2.0233127673467

Epoch: 6| Step: 5
Training loss: 0.7213571667671204
Validation loss: 2.0070599714914956

Epoch: 6| Step: 6
Training loss: 0.13804207742214203
Validation loss: 2.0469167033831277

Epoch: 6| Step: 7
Training loss: 0.41121530532836914
Validation loss: 2.0084131956100464

Epoch: 6| Step: 8
Training loss: 0.2635148763656616
Validation loss: 1.9992048144340515

Epoch: 6| Step: 9
Training loss: 0.3208813965320587
Validation loss: 2.0381385485331216

Epoch: 6| Step: 10
Training loss: 0.32218945026397705
Validation loss: 1.9943110346794128

Epoch: 6| Step: 11
Training loss: 0.30091845989227295
Validation loss: 2.000543753306071

Epoch: 6| Step: 12
Training loss: 0.3309054374694824
Validation loss: 2.02870104710261

Epoch: 6| Step: 13
Training loss: 0.21607911586761475
Validation loss: 1.9963425596555073

Epoch: 263| Step: 0
Training loss: 0.44372907280921936
Validation loss: 2.064291695753733

Epoch: 6| Step: 1
Training loss: 0.27529674768447876
Validation loss: 2.0699891448020935

Epoch: 6| Step: 2
Training loss: 0.4362041652202606
Validation loss: 2.0267478426297507

Epoch: 6| Step: 3
Training loss: 0.2724187970161438
Validation loss: 2.0040318965911865

Epoch: 6| Step: 4
Training loss: 0.5399765968322754
Validation loss: 2.04981529712677

Epoch: 6| Step: 5
Training loss: 0.6319983005523682
Validation loss: 2.015233337879181

Epoch: 6| Step: 6
Training loss: 0.3733002841472626
Validation loss: 2.0709367593129477

Epoch: 6| Step: 7
Training loss: 0.38534015417099
Validation loss: 2.0020614663759866

Epoch: 6| Step: 8
Training loss: 0.16267691552639008
Validation loss: 2.0462066928545632

Epoch: 6| Step: 9
Training loss: 0.3075687885284424
Validation loss: 2.049699048201243

Epoch: 6| Step: 10
Training loss: 0.24666044116020203
Validation loss: 2.058953841527303

Epoch: 6| Step: 11
Training loss: 0.274504691362381
Validation loss: 2.0394261479377747

Epoch: 6| Step: 12
Training loss: 0.5834380388259888
Validation loss: 2.0259071787198386

Epoch: 6| Step: 13
Training loss: 0.2625395655632019
Validation loss: 2.07881098985672

Epoch: 264| Step: 0
Training loss: 0.25418776273727417
Validation loss: 2.0335985024770102

Epoch: 6| Step: 1
Training loss: 0.3262690603733063
Validation loss: 2.046859622001648

Epoch: 6| Step: 2
Training loss: 0.5161659121513367
Validation loss: 2.0587803721427917

Epoch: 6| Step: 3
Training loss: 0.5554512143135071
Validation loss: 2.0664550264676413

Epoch: 6| Step: 4
Training loss: 0.23684516549110413
Validation loss: 2.0718445976575217

Epoch: 6| Step: 5
Training loss: 0.21090760827064514
Validation loss: 2.0263987382253013

Epoch: 6| Step: 6
Training loss: 0.2127690315246582
Validation loss: 2.0541563630104065

Epoch: 6| Step: 7
Training loss: 0.5141626596450806
Validation loss: 2.048007090886434

Epoch: 6| Step: 8
Training loss: 0.4008863568305969
Validation loss: 2.1218307415644326

Epoch: 6| Step: 9
Training loss: 0.3123742341995239
Validation loss: 2.1127436757087708

Epoch: 6| Step: 10
Training loss: 0.28736138343811035
Validation loss: 2.083847165107727

Epoch: 6| Step: 11
Training loss: 0.20444649457931519
Validation loss: 2.0703826944033303

Epoch: 6| Step: 12
Training loss: 0.21319493651390076
Validation loss: 2.092317799727122

Epoch: 6| Step: 13
Training loss: 0.6734499335289001
Validation loss: 2.037103215853373

Epoch: 265| Step: 0
Training loss: 0.20940518379211426
Validation loss: 2.0427023569742837

Epoch: 6| Step: 1
Training loss: 0.2936896085739136
Validation loss: 2.0632013082504272

Epoch: 6| Step: 2
Training loss: 0.18864333629608154
Validation loss: 2.071241637070974

Epoch: 6| Step: 3
Training loss: 0.36523908376693726
Validation loss: 2.0759423971176147

Epoch: 6| Step: 4
Training loss: 0.8425611257553101
Validation loss: 2.0655224720637

Epoch: 6| Step: 5
Training loss: 0.38584232330322266
Validation loss: 2.0718962947527566

Epoch: 6| Step: 6
Training loss: 0.45835840702056885
Validation loss: 2.045596400896708

Epoch: 6| Step: 7
Training loss: 0.24767372012138367
Validation loss: 2.074930747350057

Epoch: 6| Step: 8
Training loss: 0.36706656217575073
Validation loss: 2.02970552444458

Epoch: 6| Step: 9
Training loss: 0.26979899406433105
Validation loss: 2.060579081376394

Epoch: 6| Step: 10
Training loss: 0.448616087436676
Validation loss: 2.034447133541107

Epoch: 6| Step: 11
Training loss: 0.19876983761787415
Validation loss: 2.032009561856588

Epoch: 6| Step: 12
Training loss: 0.2579835057258606
Validation loss: 2.0359711050987244

Epoch: 6| Step: 13
Training loss: 0.2956221103668213
Validation loss: 2.057052810986837

Epoch: 266| Step: 0
Training loss: 0.22333520650863647
Validation loss: 2.0403030713399253

Epoch: 6| Step: 1
Training loss: 0.16807496547698975
Validation loss: 2.0315128366152444

Epoch: 6| Step: 2
Training loss: 0.14923180639743805
Validation loss: 2.0595267017682395

Epoch: 6| Step: 3
Training loss: 0.2479420304298401
Validation loss: 2.022742768128713

Epoch: 6| Step: 4
Training loss: 0.26709258556365967
Validation loss: 2.0452067454655967

Epoch: 6| Step: 5
Training loss: 0.20269396901130676
Validation loss: 2.0420563220977783

Epoch: 6| Step: 6
Training loss: 0.5769492983818054
Validation loss: 2.0200992822647095

Epoch: 6| Step: 7
Training loss: 0.30379045009613037
Validation loss: 2.061070422331492

Epoch: 6| Step: 8
Training loss: 0.5142852067947388
Validation loss: 2.04936550060908

Epoch: 6| Step: 9
Training loss: 0.24864619970321655
Validation loss: 2.0402307311693826

Epoch: 6| Step: 10
Training loss: 0.34767553210258484
Validation loss: 2.013052523136139

Epoch: 6| Step: 11
Training loss: 0.6993067264556885
Validation loss: 2.0337562958399453

Epoch: 6| Step: 12
Training loss: 0.21891573071479797
Validation loss: 2.015733520189921

Epoch: 6| Step: 13
Training loss: 0.398384690284729
Validation loss: 2.0423876841863

Epoch: 267| Step: 0
Training loss: 0.40488749742507935
Validation loss: 2.0224124987920127

Epoch: 6| Step: 1
Training loss: 0.2644304037094116
Validation loss: 2.0595274766286216

Epoch: 6| Step: 2
Training loss: 1.0000019073486328
Validation loss: 2.0608129103978476

Epoch: 6| Step: 3
Training loss: 0.3050820827484131
Validation loss: 2.0568390488624573

Epoch: 6| Step: 4
Training loss: 0.4449489712715149
Validation loss: 2.073368191719055

Epoch: 6| Step: 5
Training loss: 0.1593339741230011
Validation loss: 2.058706223964691

Epoch: 6| Step: 6
Training loss: 0.387892484664917
Validation loss: 2.080778201421102

Epoch: 6| Step: 7
Training loss: 0.363109290599823
Validation loss: 2.039742410182953

Epoch: 6| Step: 8
Training loss: 0.31394892930984497
Validation loss: 2.0460885564486184

Epoch: 6| Step: 9
Training loss: 0.3155437707901001
Validation loss: 2.0626816352208457

Epoch: 6| Step: 10
Training loss: 0.32426321506500244
Validation loss: 2.0541455348332724

Epoch: 6| Step: 11
Training loss: 0.2873190641403198
Validation loss: 2.0675704081853232

Epoch: 6| Step: 12
Training loss: 0.30852311849594116
Validation loss: 2.02764763434728

Epoch: 6| Step: 13
Training loss: 0.355587899684906
Validation loss: 2.0993628899256387

Epoch: 268| Step: 0
Training loss: 0.3274589776992798
Validation loss: 2.0866471330324807

Epoch: 6| Step: 1
Training loss: 0.3964088559150696
Validation loss: 2.075865944226583

Epoch: 6| Step: 2
Training loss: 0.7471071481704712
Validation loss: 2.1171231865882874

Epoch: 6| Step: 3
Training loss: 0.3980283737182617
Validation loss: 2.086910585562388

Epoch: 6| Step: 4
Training loss: 0.2515358328819275
Validation loss: 2.0815890232721963

Epoch: 6| Step: 5
Training loss: 0.7951207160949707
Validation loss: 2.038857877254486

Epoch: 6| Step: 6
Training loss: 0.30135318636894226
Validation loss: 2.0389402508735657

Epoch: 6| Step: 7
Training loss: 0.32827526330947876
Validation loss: 2.059955676396688

Epoch: 6| Step: 8
Training loss: 0.3878745436668396
Validation loss: 2.079106092453003

Epoch: 6| Step: 9
Training loss: 0.5006071925163269
Validation loss: 2.0469770431518555

Epoch: 6| Step: 10
Training loss: 0.1957964450120926
Validation loss: 2.0886924465497336

Epoch: 6| Step: 11
Training loss: 0.2441609799861908
Validation loss: 2.077353775501251

Epoch: 6| Step: 12
Training loss: 0.24378937482833862
Validation loss: 2.054936150709788

Epoch: 6| Step: 13
Training loss: 0.6713677048683167
Validation loss: 2.0776381492614746

Epoch: 269| Step: 0
Training loss: 0.3738291263580322
Validation loss: 2.0912468830744424

Epoch: 6| Step: 1
Training loss: 0.6075138449668884
Validation loss: 2.1009284257888794

Epoch: 6| Step: 2
Training loss: 0.26808255910873413
Validation loss: 2.026633163293203

Epoch: 6| Step: 3
Training loss: 0.32845139503479004
Validation loss: 2.0526612202326455

Epoch: 6| Step: 4
Training loss: 0.4061289429664612
Validation loss: 2.038219173749288

Epoch: 6| Step: 5
Training loss: 0.22891628742218018
Validation loss: 2.034470021724701

Epoch: 6| Step: 6
Training loss: 0.5756323337554932
Validation loss: 2.02342696984609

Epoch: 6| Step: 7
Training loss: 0.5031696557998657
Validation loss: 2.0442960063616433

Epoch: 6| Step: 8
Training loss: 0.36748895049095154
Validation loss: 2.0293479561805725

Epoch: 6| Step: 9
Training loss: 0.48206469416618347
Validation loss: 2.0926169554392495

Epoch: 6| Step: 10
Training loss: 0.2967183589935303
Validation loss: 2.0757089455922446

Epoch: 6| Step: 11
Training loss: 0.42252451181411743
Validation loss: 2.0380106965700784

Epoch: 6| Step: 12
Training loss: 0.4827839136123657
Validation loss: 2.054677128791809

Epoch: 6| Step: 13
Training loss: 0.2621164917945862
Validation loss: 2.0497156381607056

Epoch: 270| Step: 0
Training loss: 0.5725316405296326
Validation loss: 2.0331764221191406

Epoch: 6| Step: 1
Training loss: 0.3802105188369751
Validation loss: 2.023409068584442

Epoch: 6| Step: 2
Training loss: 0.860071063041687
Validation loss: 1.9735981424649556

Epoch: 6| Step: 3
Training loss: 0.7127816677093506
Validation loss: 1.9809059699376423

Epoch: 6| Step: 4
Training loss: 0.29334139823913574
Validation loss: 1.9876419107119243

Epoch: 6| Step: 5
Training loss: 0.24978455901145935
Validation loss: 2.0522279143333435

Epoch: 6| Step: 6
Training loss: 0.16957616806030273
Validation loss: 1.987144927183787

Epoch: 6| Step: 7
Training loss: 0.23104606568813324
Validation loss: 1.9794117013613384

Epoch: 6| Step: 8
Training loss: 0.27142980694770813
Validation loss: 2.0786699652671814

Epoch: 6| Step: 9
Training loss: 0.43319135904312134
Validation loss: 2.089228848616282

Epoch: 6| Step: 10
Training loss: 0.14532512426376343
Validation loss: 2.010161300500234

Epoch: 6| Step: 11
Training loss: 0.30728572607040405
Validation loss: 1.9880752364794414

Epoch: 6| Step: 12
Training loss: 0.42633897066116333
Validation loss: 2.0254074335098267

Epoch: 6| Step: 13
Training loss: 0.2997872829437256
Validation loss: 2.059403876463572

Epoch: 271| Step: 0
Training loss: 0.3278486728668213
Validation loss: 2.044148067633311

Epoch: 6| Step: 1
Training loss: 0.4874805808067322
Validation loss: 2.054876705010732

Epoch: 6| Step: 2
Training loss: 0.3145677447319031
Validation loss: 2.001334766546885

Epoch: 6| Step: 3
Training loss: 0.3137405216693878
Validation loss: 2.0078351497650146

Epoch: 6| Step: 4
Training loss: 0.9211752414703369
Validation loss: 2.100154459476471

Epoch: 6| Step: 5
Training loss: 0.46286076307296753
Validation loss: 2.1073745091756186

Epoch: 6| Step: 6
Training loss: 0.43057820200920105
Validation loss: 2.06820414463679

Epoch: 6| Step: 7
Training loss: 0.18750977516174316
Validation loss: 2.105640689531962

Epoch: 6| Step: 8
Training loss: 0.4718465209007263
Validation loss: 2.0286376078923545

Epoch: 6| Step: 9
Training loss: 0.40040719509124756
Validation loss: 2.066079020500183

Epoch: 6| Step: 10
Training loss: 0.2586098313331604
Validation loss: 2.0449072122573853

Epoch: 6| Step: 11
Training loss: 0.2935383915901184
Validation loss: 2.052386462688446

Epoch: 6| Step: 12
Training loss: 0.4810895323753357
Validation loss: 2.0372191270192466

Epoch: 6| Step: 13
Training loss: 0.28219014406204224
Validation loss: 2.0043207804361978

Epoch: 272| Step: 0
Training loss: 0.16358371078968048
Validation loss: 2.0641843676567078

Epoch: 6| Step: 1
Training loss: 0.4884048104286194
Validation loss: 2.077415625254313

Epoch: 6| Step: 2
Training loss: 0.3003377318382263
Validation loss: 2.0566219290097556

Epoch: 6| Step: 3
Training loss: 0.4876808822154999
Validation loss: 2.0826274752616882

Epoch: 6| Step: 4
Training loss: 0.48969918489456177
Validation loss: 2.090328494707743

Epoch: 6| Step: 5
Training loss: 0.4145238399505615
Validation loss: 2.089017371336619

Epoch: 6| Step: 6
Training loss: 0.36964625120162964
Validation loss: 2.0891740719477334

Epoch: 6| Step: 7
Training loss: 0.24109788239002228
Validation loss: 2.0127021272977195

Epoch: 6| Step: 8
Training loss: 0.28032517433166504
Validation loss: 2.0375141302744546

Epoch: 6| Step: 9
Training loss: 0.29695963859558105
Validation loss: 2.0496015747388205

Epoch: 6| Step: 10
Training loss: 0.6044174432754517
Validation loss: 2.0211458603541055

Epoch: 6| Step: 11
Training loss: 0.3621533513069153
Validation loss: 2.0593942602475486

Epoch: 6| Step: 12
Training loss: 0.2730488181114197
Validation loss: 2.0217499136924744

Epoch: 6| Step: 13
Training loss: 0.3618936538696289
Validation loss: 2.076002756754557

Epoch: 273| Step: 0
Training loss: 0.20180915296077728
Validation loss: 2.0623441338539124

Epoch: 6| Step: 1
Training loss: 0.2673567831516266
Validation loss: 2.0791030327479043

Epoch: 6| Step: 2
Training loss: 0.40813174843788147
Validation loss: 2.075231154759725

Epoch: 6| Step: 3
Training loss: 0.2754334807395935
Validation loss: 2.027589797973633

Epoch: 6| Step: 4
Training loss: 0.2941664159297943
Validation loss: 2.048051377137502

Epoch: 6| Step: 5
Training loss: 0.4056418240070343
Validation loss: 2.016447603702545

Epoch: 6| Step: 6
Training loss: 0.24684160947799683
Validation loss: 2.0121126969655356

Epoch: 6| Step: 7
Training loss: 0.37352705001831055
Validation loss: 1.9656044840812683

Epoch: 6| Step: 8
Training loss: 0.8036619424819946
Validation loss: 2.0452515284220376

Epoch: 6| Step: 9
Training loss: 0.2722947597503662
Validation loss: 2.0344448685646057

Epoch: 6| Step: 10
Training loss: 0.25913798809051514
Validation loss: 2.0482808152834573

Epoch: 6| Step: 11
Training loss: 0.2739282548427582
Validation loss: 2.02864537636439

Epoch: 6| Step: 12
Training loss: 0.34237873554229736
Validation loss: 2.0314787228902182

Epoch: 6| Step: 13
Training loss: 0.47570258378982544
Validation loss: 2.0526257356007895

Epoch: 274| Step: 0
Training loss: 0.36086851358413696
Validation loss: 2.0437799096107483

Epoch: 6| Step: 1
Training loss: 0.20212966203689575
Validation loss: 2.021483620007833

Epoch: 6| Step: 2
Training loss: 0.3158855438232422
Validation loss: 2.0563774704933167

Epoch: 6| Step: 3
Training loss: 0.3660801351070404
Validation loss: 2.0559917291005454

Epoch: 6| Step: 4
Training loss: 0.2976030111312866
Validation loss: 2.040638784567515

Epoch: 6| Step: 5
Training loss: 0.3471572995185852
Validation loss: 2.023064931233724

Epoch: 6| Step: 6
Training loss: 0.4303290843963623
Validation loss: 2.0281430880228677

Epoch: 6| Step: 7
Training loss: 0.2883788049221039
Validation loss: 2.024727543195089

Epoch: 6| Step: 8
Training loss: 0.3147185444831848
Validation loss: 2.009931266307831

Epoch: 6| Step: 9
Training loss: 0.19364897906780243
Validation loss: 2.0403610666592917

Epoch: 6| Step: 10
Training loss: 0.21106237173080444
Validation loss: 2.0383877555529275

Epoch: 6| Step: 11
Training loss: 0.8901971578598022
Validation loss: 1.99602472782135

Epoch: 6| Step: 12
Training loss: 0.24962618947029114
Validation loss: 2.0004524191220603

Epoch: 6| Step: 13
Training loss: 0.22910481691360474
Validation loss: 2.0455960830052695

Epoch: 275| Step: 0
Training loss: 0.16960792243480682
Validation loss: 2.0756282210350037

Epoch: 6| Step: 1
Training loss: 0.6632692217826843
Validation loss: 2.0177093545595803

Epoch: 6| Step: 2
Training loss: 0.28693509101867676
Validation loss: 2.017252425352732

Epoch: 6| Step: 3
Training loss: 0.6620078086853027
Validation loss: 2.031958003838857

Epoch: 6| Step: 4
Training loss: 0.16370351612567902
Validation loss: 2.0524216294288635

Epoch: 6| Step: 5
Training loss: 0.2861684560775757
Validation loss: 2.0359858870506287

Epoch: 6| Step: 6
Training loss: 0.32977649569511414
Validation loss: 2.0174215038617453

Epoch: 6| Step: 7
Training loss: 0.5139256715774536
Validation loss: 2.0325041810671487

Epoch: 6| Step: 8
Training loss: 0.22730031609535217
Validation loss: 2.005399525165558

Epoch: 6| Step: 9
Training loss: 0.25398313999176025
Validation loss: 1.9542909065882366

Epoch: 6| Step: 10
Training loss: 0.2684660851955414
Validation loss: 2.054175078868866

Epoch: 6| Step: 11
Training loss: 0.32056480646133423
Validation loss: 2.0433443784713745

Epoch: 6| Step: 12
Training loss: 0.1776251494884491
Validation loss: 2.062382539113363

Epoch: 6| Step: 13
Training loss: 0.20338961482048035
Validation loss: 2.082090357939402

Epoch: 276| Step: 0
Training loss: 0.28811752796173096
Validation loss: 2.0153415401776633

Epoch: 6| Step: 1
Training loss: 0.25525176525115967
Validation loss: 2.000928362210592

Epoch: 6| Step: 2
Training loss: 0.27610039710998535
Validation loss: 2.0262080430984497

Epoch: 6| Step: 3
Training loss: 0.666515588760376
Validation loss: 2.0160243113835654

Epoch: 6| Step: 4
Training loss: 0.4693443179130554
Validation loss: 1.9971938331921895

Epoch: 6| Step: 5
Training loss: 0.2279614359140396
Validation loss: 2.0034189224243164

Epoch: 6| Step: 6
Training loss: 0.6889009475708008
Validation loss: 2.040443738301595

Epoch: 6| Step: 7
Training loss: 0.22619348764419556
Validation loss: 2.005356550216675

Epoch: 6| Step: 8
Training loss: 0.5664390325546265
Validation loss: 2.0358361999193826

Epoch: 6| Step: 9
Training loss: 0.32926005125045776
Validation loss: 2.055794060230255

Epoch: 6| Step: 10
Training loss: 0.39872103929519653
Validation loss: 2.0718207557996116

Epoch: 6| Step: 11
Training loss: 0.2076312005519867
Validation loss: 2.0061458547910056

Epoch: 6| Step: 12
Training loss: 0.26643839478492737
Validation loss: 2.0917923847834268

Epoch: 6| Step: 13
Training loss: 0.22370828688144684
Validation loss: 2.0500530997912088

Epoch: 277| Step: 0
Training loss: 0.22307994961738586
Validation loss: 2.0226639111836753

Epoch: 6| Step: 1
Training loss: 0.2815505862236023
Validation loss: 2.047617236773173

Epoch: 6| Step: 2
Training loss: 0.34183692932128906
Validation loss: 2.047217826048533

Epoch: 6| Step: 3
Training loss: 0.36246103048324585
Validation loss: 2.0982814828554788

Epoch: 6| Step: 4
Training loss: 0.6046031713485718
Validation loss: 2.05627832810084

Epoch: 6| Step: 5
Training loss: 0.47145938873291016
Validation loss: 2.0492842396100364

Epoch: 6| Step: 6
Training loss: 0.5891408324241638
Validation loss: 2.1256642738978067

Epoch: 6| Step: 7
Training loss: 0.27886050939559937
Validation loss: 2.0917969743410745

Epoch: 6| Step: 8
Training loss: 0.4680436849594116
Validation loss: 2.0675384600957236

Epoch: 6| Step: 9
Training loss: 0.30874958634376526
Validation loss: 2.141185919443766

Epoch: 6| Step: 10
Training loss: 0.303025484085083
Validation loss: 2.06825844446818

Epoch: 6| Step: 11
Training loss: 0.30677980184555054
Validation loss: 2.0826725165049234

Epoch: 6| Step: 12
Training loss: 0.2917315661907196
Validation loss: 2.078488051891327

Epoch: 6| Step: 13
Training loss: 0.3553985059261322
Validation loss: 2.0510554711023965

Epoch: 278| Step: 0
Training loss: 0.3401026725769043
Validation loss: 2.0685076316197715

Epoch: 6| Step: 1
Training loss: 0.33012521266937256
Validation loss: 2.0341612895329795

Epoch: 6| Step: 2
Training loss: 0.6901651620864868
Validation loss: 2.029997706413269

Epoch: 6| Step: 3
Training loss: 0.23442591726779938
Validation loss: 2.0597106218338013

Epoch: 6| Step: 4
Training loss: 0.24199186265468597
Validation loss: 2.049834668636322

Epoch: 6| Step: 5
Training loss: 0.40985724329948425
Validation loss: 2.07885213692983

Epoch: 6| Step: 6
Training loss: 0.5281836986541748
Validation loss: 2.0132628083229065

Epoch: 6| Step: 7
Training loss: 0.48206597566604614
Validation loss: 2.0209717949231467

Epoch: 6| Step: 8
Training loss: 0.27374207973480225
Validation loss: 2.06752214829127

Epoch: 6| Step: 9
Training loss: 0.46483033895492554
Validation loss: 2.024539907773336

Epoch: 6| Step: 10
Training loss: 0.3187319338321686
Validation loss: 1.98106982310613

Epoch: 6| Step: 11
Training loss: 0.37278953194618225
Validation loss: 2.0082158048947654

Epoch: 6| Step: 12
Training loss: 0.367630273103714
Validation loss: 2.001620868841807

Epoch: 6| Step: 13
Training loss: 0.2663491368293762
Validation loss: 1.9473912715911865

Epoch: 279| Step: 0
Training loss: 0.7618677616119385
Validation loss: 2.008122364679972

Epoch: 6| Step: 1
Training loss: 0.24221813678741455
Validation loss: 2.013017237186432

Epoch: 6| Step: 2
Training loss: 0.21219444274902344
Validation loss: 2.027398486932119

Epoch: 6| Step: 3
Training loss: 0.3287014365196228
Validation loss: 2.0063175757726035

Epoch: 6| Step: 4
Training loss: 0.5365793108940125
Validation loss: 1.9869157473246257

Epoch: 6| Step: 5
Training loss: 0.23269709944725037
Validation loss: 2.0140865246454873

Epoch: 6| Step: 6
Training loss: 0.3037453293800354
Validation loss: 1.9872819383939107

Epoch: 6| Step: 7
Training loss: 0.33490532636642456
Validation loss: 2.024227817853292

Epoch: 6| Step: 8
Training loss: 0.23672199249267578
Validation loss: 2.0419141252835593

Epoch: 6| Step: 9
Training loss: 0.3897036910057068
Validation loss: 2.017203946908315

Epoch: 6| Step: 10
Training loss: 0.2527071237564087
Validation loss: 2.0495306253433228

Epoch: 6| Step: 11
Training loss: 0.17438244819641113
Validation loss: 2.0504604379336038

Epoch: 6| Step: 12
Training loss: 0.3917720317840576
Validation loss: 2.0446081360181174

Epoch: 6| Step: 13
Training loss: 0.34906652569770813
Validation loss: 2.031221032142639

Epoch: 280| Step: 0
Training loss: 0.24965950846672058
Validation loss: 2.0335759917894998

Epoch: 6| Step: 1
Training loss: 0.46249517798423767
Validation loss: 2.0274424950281777

Epoch: 6| Step: 2
Training loss: 0.2755482792854309
Validation loss: 2.0295651952425637

Epoch: 6| Step: 3
Training loss: 0.29206612706184387
Validation loss: 2.050403416156769

Epoch: 6| Step: 4
Training loss: 0.3476591408252716
Validation loss: 2.0513460437456765

Epoch: 6| Step: 5
Training loss: 0.2305721491575241
Validation loss: 2.0821444590886435

Epoch: 6| Step: 6
Training loss: 0.21908330917358398
Validation loss: 2.0099695126215615

Epoch: 6| Step: 7
Training loss: 0.19111573696136475
Validation loss: 2.01936944325765

Epoch: 6| Step: 8
Training loss: 0.2838912308216095
Validation loss: 2.0471635858217874

Epoch: 6| Step: 9
Training loss: 0.22476428747177124
Validation loss: 1.994337836901347

Epoch: 6| Step: 10
Training loss: 0.48868948221206665
Validation loss: 2.0676847298940024

Epoch: 6| Step: 11
Training loss: 0.31560322642326355
Validation loss: 2.05094047387441

Epoch: 6| Step: 12
Training loss: 0.6235774755477905
Validation loss: 2.0497799118359885

Epoch: 6| Step: 13
Training loss: 0.18545469641685486
Validation loss: 2.0522675116856894

Epoch: 281| Step: 0
Training loss: 0.23354984819889069
Validation loss: 2.0290295680363974

Epoch: 6| Step: 1
Training loss: 0.33074069023132324
Validation loss: 1.9718095461527507

Epoch: 6| Step: 2
Training loss: 0.26592618227005005
Validation loss: 2.0575865308443704

Epoch: 6| Step: 3
Training loss: 0.7224490642547607
Validation loss: 2.0223348339398703

Epoch: 6| Step: 4
Training loss: 0.5390777587890625
Validation loss: 2.062034328778585

Epoch: 6| Step: 5
Training loss: 0.3686490058898926
Validation loss: 2.029740790526072

Epoch: 6| Step: 6
Training loss: 0.1735273003578186
Validation loss: 2.0414530634880066

Epoch: 6| Step: 7
Training loss: 0.33112800121307373
Validation loss: 2.0479608178138733

Epoch: 6| Step: 8
Training loss: 0.47766122221946716
Validation loss: 2.0436337987581887

Epoch: 6| Step: 9
Training loss: 0.2508712410926819
Validation loss: 2.028410871823629

Epoch: 6| Step: 10
Training loss: 0.2522859573364258
Validation loss: 2.050767242908478

Epoch: 6| Step: 11
Training loss: 0.3819836378097534
Validation loss: 1.9707228342692058

Epoch: 6| Step: 12
Training loss: 0.3819875419139862
Validation loss: 2.0446294943491616

Epoch: 6| Step: 13
Training loss: 0.36377906799316406
Validation loss: 2.0323684215545654

Epoch: 282| Step: 0
Training loss: 0.2867349684238434
Validation loss: 1.9819451769193013

Epoch: 6| Step: 1
Training loss: 0.24952736496925354
Validation loss: 2.011169652144114

Epoch: 6| Step: 2
Training loss: 0.4278360605239868
Validation loss: 2.0277402798334756

Epoch: 6| Step: 3
Training loss: 0.3281111419200897
Validation loss: 2.0306163827578225

Epoch: 6| Step: 4
Training loss: 0.23824924230575562
Validation loss: 2.0756550629933677

Epoch: 6| Step: 5
Training loss: 0.3474771976470947
Validation loss: 2.035582423210144

Epoch: 6| Step: 6
Training loss: 0.5745216608047485
Validation loss: 2.008361558119456

Epoch: 6| Step: 7
Training loss: 0.2797631025314331
Validation loss: 2.00531534353892

Epoch: 6| Step: 8
Training loss: 0.21581566333770752
Validation loss: 2.0469751159350076

Epoch: 6| Step: 9
Training loss: 0.4667741060256958
Validation loss: 2.0031931400299072

Epoch: 6| Step: 10
Training loss: 0.48335057497024536
Validation loss: 2.023651878039042

Epoch: 6| Step: 11
Training loss: 0.33589810132980347
Validation loss: 2.023019234339396

Epoch: 6| Step: 12
Training loss: 0.2858436107635498
Validation loss: 2.0581672390302024

Epoch: 6| Step: 13
Training loss: 0.3654720187187195
Validation loss: 2.0590657194455466

Epoch: 283| Step: 0
Training loss: 0.12236752361059189
Validation loss: 2.040643850962321

Epoch: 6| Step: 1
Training loss: 0.22497978806495667
Validation loss: 2.0238680243492126

Epoch: 6| Step: 2
Training loss: 0.45048195123672485
Validation loss: 2.039426108201345

Epoch: 6| Step: 3
Training loss: 0.7966216802597046
Validation loss: 2.0583990812301636

Epoch: 6| Step: 4
Training loss: 0.28676992654800415
Validation loss: 2.0357800920804343

Epoch: 6| Step: 5
Training loss: 0.30722561478614807
Validation loss: 2.1094652016957602

Epoch: 6| Step: 6
Training loss: 0.28945285081863403
Validation loss: 2.114834189414978

Epoch: 6| Step: 7
Training loss: 0.45547911524772644
Validation loss: 2.0752424001693726

Epoch: 6| Step: 8
Training loss: 0.33299529552459717
Validation loss: 2.0792022943496704

Epoch: 6| Step: 9
Training loss: 0.42707785964012146
Validation loss: 2.0965810219446817

Epoch: 6| Step: 10
Training loss: 0.2895127534866333
Validation loss: 2.067464848359426

Epoch: 6| Step: 11
Training loss: 0.3826809823513031
Validation loss: 2.0705533623695374

Epoch: 6| Step: 12
Training loss: 0.1958620697259903
Validation loss: 2.015923857688904

Epoch: 6| Step: 13
Training loss: 0.30421632528305054
Validation loss: 2.0418009559313455

Epoch: 284| Step: 0
Training loss: 0.5702386498451233
Validation loss: 2.01991339524587

Epoch: 6| Step: 1
Training loss: 0.34490254521369934
Validation loss: 2.052118400732676

Epoch: 6| Step: 2
Training loss: 0.26139524579048157
Validation loss: 2.0422322750091553

Epoch: 6| Step: 3
Training loss: 0.17410936951637268
Validation loss: 2.0062668720881143

Epoch: 6| Step: 4
Training loss: 0.4825969338417053
Validation loss: 2.0500489274660745

Epoch: 6| Step: 5
Training loss: 0.20193159580230713
Validation loss: 2.0808387796084085

Epoch: 6| Step: 6
Training loss: 0.3768843412399292
Validation loss: 2.057353377342224

Epoch: 6| Step: 7
Training loss: 0.2960512936115265
Validation loss: 2.064172387123108

Epoch: 6| Step: 8
Training loss: 0.2810940742492676
Validation loss: 2.0502778689066568

Epoch: 6| Step: 9
Training loss: 0.22654394805431366
Validation loss: 1.9992266496022542

Epoch: 6| Step: 10
Training loss: 0.3342438340187073
Validation loss: 2.0812727411588035

Epoch: 6| Step: 11
Training loss: 0.21677041053771973
Validation loss: 2.0391028920809426

Epoch: 6| Step: 12
Training loss: 0.5124908685684204
Validation loss: 2.0461832880973816

Epoch: 6| Step: 13
Training loss: 0.3169349730014801
Validation loss: 2.0062724351882935

Epoch: 285| Step: 0
Training loss: 0.7716426849365234
Validation loss: 2.0295462012290955

Epoch: 6| Step: 1
Training loss: 0.24184510111808777
Validation loss: 2.0816292762756348

Epoch: 6| Step: 2
Training loss: 0.18580272793769836
Validation loss: 2.0679646531740823

Epoch: 6| Step: 3
Training loss: 0.3020440340042114
Validation loss: 2.061688542366028

Epoch: 6| Step: 4
Training loss: 0.2899880111217499
Validation loss: 2.0244476795196533

Epoch: 6| Step: 5
Training loss: 0.5781751871109009
Validation loss: 2.001842737197876

Epoch: 6| Step: 6
Training loss: 0.27252447605133057
Validation loss: 2.0644917289415994

Epoch: 6| Step: 7
Training loss: 0.24480068683624268
Validation loss: 2.0383557875951133

Epoch: 6| Step: 8
Training loss: 0.2329733818769455
Validation loss: 2.0582061211268106

Epoch: 6| Step: 9
Training loss: 0.3546408712863922
Validation loss: 2.055818716684977

Epoch: 6| Step: 10
Training loss: 0.4814698100090027
Validation loss: 2.0565674901008606

Epoch: 6| Step: 11
Training loss: 0.14954403042793274
Validation loss: 2.0602162877718606

Epoch: 6| Step: 12
Training loss: 0.28184789419174194
Validation loss: 1.9961128234863281

Epoch: 6| Step: 13
Training loss: 0.20800553262233734
Validation loss: 1.978136380513509

Epoch: 286| Step: 0
Training loss: 0.450075626373291
Validation loss: 2.0195139249165854

Epoch: 6| Step: 1
Training loss: 0.17632117867469788
Validation loss: 1.9996958176294963

Epoch: 6| Step: 2
Training loss: 0.3631032705307007
Validation loss: 2.00851047039032

Epoch: 6| Step: 3
Training loss: 0.17312198877334595
Validation loss: 2.01178240776062

Epoch: 6| Step: 4
Training loss: 0.5909655094146729
Validation loss: 2.0321819186210632

Epoch: 6| Step: 5
Training loss: 0.18359360098838806
Validation loss: 2.046427766482035

Epoch: 6| Step: 6
Training loss: 0.3105461001396179
Validation loss: 1.9918796221415203

Epoch: 6| Step: 7
Training loss: 0.2875842750072479
Validation loss: 1.969737966855367

Epoch: 6| Step: 8
Training loss: 0.22572872042655945
Validation loss: 1.999023179213206

Epoch: 6| Step: 9
Training loss: 0.7274417877197266
Validation loss: 2.0068498253822327

Epoch: 6| Step: 10
Training loss: 0.605340838432312
Validation loss: 2.0167231957117715

Epoch: 6| Step: 11
Training loss: 0.25658878684043884
Validation loss: 2.031478444735209

Epoch: 6| Step: 12
Training loss: 0.16443181037902832
Validation loss: 2.007082482179006

Epoch: 6| Step: 13
Training loss: 0.2874574065208435
Validation loss: 2.0205310185750327

Epoch: 287| Step: 0
Training loss: 0.35196834802627563
Validation loss: 2.024308164914449

Epoch: 6| Step: 1
Training loss: 0.22246047854423523
Validation loss: 2.0289136171340942

Epoch: 6| Step: 2
Training loss: 0.40988582372665405
Validation loss: 2.040285269419352

Epoch: 6| Step: 3
Training loss: 0.35875654220581055
Validation loss: 2.0478772719701133

Epoch: 6| Step: 4
Training loss: 0.51187664270401
Validation loss: 2.0482290188471475

Epoch: 6| Step: 5
Training loss: 0.2450430542230606
Validation loss: 1.996097207069397

Epoch: 6| Step: 6
Training loss: 0.4596976637840271
Validation loss: 2.031887690226237

Epoch: 6| Step: 7
Training loss: 0.3741287887096405
Validation loss: 2.021984656651815

Epoch: 6| Step: 8
Training loss: 0.41658517718315125
Validation loss: 2.0348525245984397

Epoch: 6| Step: 9
Training loss: 0.1854822337627411
Validation loss: 2.0589002768198648

Epoch: 6| Step: 10
Training loss: 0.14425288140773773
Validation loss: 2.0722972750663757

Epoch: 6| Step: 11
Training loss: 0.2158365547657013
Validation loss: 2.0509942968686423

Epoch: 6| Step: 12
Training loss: 0.3122357726097107
Validation loss: 2.0700433452924094

Epoch: 6| Step: 13
Training loss: 0.13620483875274658
Validation loss: 2.052204211552938

Epoch: 288| Step: 0
Training loss: 0.27892550826072693
Validation loss: 2.0444993376731873

Epoch: 6| Step: 1
Training loss: 0.22513610124588013
Validation loss: 2.024513383706411

Epoch: 6| Step: 2
Training loss: 0.3421318829059601
Validation loss: 2.0624593695004783

Epoch: 6| Step: 3
Training loss: 0.2691798210144043
Validation loss: 2.073062777519226

Epoch: 6| Step: 4
Training loss: 0.6257448196411133
Validation loss: 2.0109512408574424

Epoch: 6| Step: 5
Training loss: 0.23158304393291473
Validation loss: 2.0190014839172363

Epoch: 6| Step: 6
Training loss: 0.3221437335014343
Validation loss: 2.055704951286316

Epoch: 6| Step: 7
Training loss: 0.2494657039642334
Validation loss: 2.038597802321116

Epoch: 6| Step: 8
Training loss: 0.32541728019714355
Validation loss: 2.057172695795695

Epoch: 6| Step: 9
Training loss: 0.3368235230445862
Validation loss: 2.0265659292538962

Epoch: 6| Step: 10
Training loss: 0.2331710159778595
Validation loss: 2.0600139697392783

Epoch: 6| Step: 11
Training loss: 0.4469199478626251
Validation loss: 1.977169354756673

Epoch: 6| Step: 12
Training loss: 0.25292307138442993
Validation loss: 2.0051152110099792

Epoch: 6| Step: 13
Training loss: 0.4480215013027191
Validation loss: 1.999026397864024

Epoch: 289| Step: 0
Training loss: 0.24258559942245483
Validation loss: 2.0364624659220376

Epoch: 6| Step: 1
Training loss: 0.28643128275871277
Validation loss: 1.9818155566851299

Epoch: 6| Step: 2
Training loss: 0.41115322709083557
Validation loss: 2.048402786254883

Epoch: 6| Step: 3
Training loss: 0.29731664061546326
Validation loss: 2.0464347203572593

Epoch: 6| Step: 4
Training loss: 0.15507040917873383
Validation loss: 2.0194252729415894

Epoch: 6| Step: 5
Training loss: 0.27058136463165283
Validation loss: 2.059119403362274

Epoch: 6| Step: 6
Training loss: 0.2436506450176239
Validation loss: 2.0477277437845864

Epoch: 6| Step: 7
Training loss: 0.27003705501556396
Validation loss: 2.0212226112683616

Epoch: 6| Step: 8
Training loss: 0.33838868141174316
Validation loss: 2.05178572734197

Epoch: 6| Step: 9
Training loss: 0.2511535882949829
Validation loss: 2.007949948310852

Epoch: 6| Step: 10
Training loss: 0.29463115334510803
Validation loss: 2.0465735594431558

Epoch: 6| Step: 11
Training loss: 0.3969298005104065
Validation loss: 2.038761019706726

Epoch: 6| Step: 12
Training loss: 0.4007568359375
Validation loss: 2.0380104581514993

Epoch: 6| Step: 13
Training loss: 0.7694611549377441
Validation loss: 2.0621821880340576

Epoch: 290| Step: 0
Training loss: 0.39376354217529297
Validation loss: 2.025404155254364

Epoch: 6| Step: 1
Training loss: 0.40069374442100525
Validation loss: 2.045576572418213

Epoch: 6| Step: 2
Training loss: 0.2694149315357208
Validation loss: 2.0794694423675537

Epoch: 6| Step: 3
Training loss: 0.16781830787658691
Validation loss: 2.0729769269625344

Epoch: 6| Step: 4
Training loss: 0.3809223473072052
Validation loss: 2.018027742703756

Epoch: 6| Step: 5
Training loss: 0.2636409103870392
Validation loss: 2.0576531291007996

Epoch: 6| Step: 6
Training loss: 0.5546148419380188
Validation loss: 2.041478435198466

Epoch: 6| Step: 7
Training loss: 0.1692323088645935
Validation loss: 2.0500619610150657

Epoch: 6| Step: 8
Training loss: 0.4057752192020416
Validation loss: 2.01403945684433

Epoch: 6| Step: 9
Training loss: 0.3706647455692291
Validation loss: 2.103900969028473

Epoch: 6| Step: 10
Training loss: 0.20330776274204254
Validation loss: 2.040466527144114

Epoch: 6| Step: 11
Training loss: 0.1939212828874588
Validation loss: 2.058792452017466

Epoch: 6| Step: 12
Training loss: 0.26564767956733704
Validation loss: 2.0374356309572854

Epoch: 6| Step: 13
Training loss: 0.19323790073394775
Validation loss: 2.021675248940786

Epoch: 291| Step: 0
Training loss: 0.2068304419517517
Validation loss: 2.0557760993639627

Epoch: 6| Step: 1
Training loss: 0.29265648126602173
Validation loss: 2.037984867890676

Epoch: 6| Step: 2
Training loss: 0.615720272064209
Validation loss: 2.007348616917928

Epoch: 6| Step: 3
Training loss: 0.3209356367588043
Validation loss: 2.032122850418091

Epoch: 6| Step: 4
Training loss: 0.36546486616134644
Validation loss: 2.0375537673632302

Epoch: 6| Step: 5
Training loss: 0.24828733503818512
Validation loss: 2.0143836736679077

Epoch: 6| Step: 6
Training loss: 0.4269765615463257
Validation loss: 2.0422146121660867

Epoch: 6| Step: 7
Training loss: 0.3431311845779419
Validation loss: 2.0628453493118286

Epoch: 6| Step: 8
Training loss: 0.29639285802841187
Validation loss: 2.040451765060425

Epoch: 6| Step: 9
Training loss: 0.15475162863731384
Validation loss: 1.9873957832654316

Epoch: 6| Step: 10
Training loss: 0.3410840630531311
Validation loss: 2.0341994961102805

Epoch: 6| Step: 11
Training loss: 0.2452130764722824
Validation loss: 1.995690683523814

Epoch: 6| Step: 12
Training loss: 0.34925034642219543
Validation loss: 2.024425446987152

Epoch: 6| Step: 13
Training loss: 0.23468390107154846
Validation loss: 1.9710806409517925

Epoch: 292| Step: 0
Training loss: 0.2640834152698517
Validation loss: 2.0201629996299744

Epoch: 6| Step: 1
Training loss: 0.1629907637834549
Validation loss: 2.0139501492182412

Epoch: 6| Step: 2
Training loss: 0.40256214141845703
Validation loss: 1.9918563763300579

Epoch: 6| Step: 3
Training loss: 0.3553721308708191
Validation loss: 2.007549266020457

Epoch: 6| Step: 4
Training loss: 0.15526723861694336
Validation loss: 2.043022175629934

Epoch: 6| Step: 5
Training loss: 0.19285477697849274
Validation loss: 2.028491795063019

Epoch: 6| Step: 6
Training loss: 0.19547562301158905
Validation loss: 2.0599250396092734

Epoch: 6| Step: 7
Training loss: 0.24323618412017822
Validation loss: 2.0495306849479675

Epoch: 6| Step: 8
Training loss: 0.4426795542240143
Validation loss: 2.026939272880554

Epoch: 6| Step: 9
Training loss: 0.5513993501663208
Validation loss: 2.019162734349569

Epoch: 6| Step: 10
Training loss: 0.23162226378917694
Validation loss: 2.0113564928372702

Epoch: 6| Step: 11
Training loss: 0.3849523067474365
Validation loss: 2.0279300610224404

Epoch: 6| Step: 12
Training loss: 0.2545449435710907
Validation loss: 1.9707891345024109

Epoch: 6| Step: 13
Training loss: 0.3925235867500305
Validation loss: 2.008463760217031

Epoch: 293| Step: 0
Training loss: 0.5637843608856201
Validation loss: 2.0065439144770303

Epoch: 6| Step: 1
Training loss: 0.2063925862312317
Validation loss: 1.9812653462092082

Epoch: 6| Step: 2
Training loss: 0.41017985343933105
Validation loss: 2.051933308442434

Epoch: 6| Step: 3
Training loss: 0.4411519765853882
Validation loss: 2.04867293437322

Epoch: 6| Step: 4
Training loss: 0.2038709968328476
Validation loss: 2.0385244687398276

Epoch: 6| Step: 5
Training loss: 0.2383802831172943
Validation loss: 2.0178051789601645

Epoch: 6| Step: 6
Training loss: 0.3377998173236847
Validation loss: 2.0615856647491455

Epoch: 6| Step: 7
Training loss: 0.4966135025024414
Validation loss: 2.005687952041626

Epoch: 6| Step: 8
Training loss: 0.3902948200702667
Validation loss: 1.9864222407341003

Epoch: 6| Step: 9
Training loss: 0.16017229855060577
Validation loss: 1.9886725942293804

Epoch: 6| Step: 10
Training loss: 0.36142364144325256
Validation loss: 2.011178970336914

Epoch: 6| Step: 11
Training loss: 0.24614733457565308
Validation loss: 2.047200838724772

Epoch: 6| Step: 12
Training loss: 0.2441089004278183
Validation loss: 2.0110905170440674

Epoch: 6| Step: 13
Training loss: 0.2955649495124817
Validation loss: 1.9956393837928772

Epoch: 294| Step: 0
Training loss: 0.16128776967525482
Validation loss: 2.0130911668141684

Epoch: 6| Step: 1
Training loss: 0.3561829924583435
Validation loss: 2.0086233019828796

Epoch: 6| Step: 2
Training loss: 0.3443949222564697
Validation loss: 2.034316380818685

Epoch: 6| Step: 3
Training loss: 0.35734766721725464
Validation loss: 2.038105010986328

Epoch: 6| Step: 4
Training loss: 0.25358980894088745
Validation loss: 2.0374123255411782

Epoch: 6| Step: 5
Training loss: 0.27232640981674194
Validation loss: 2.0359928607940674

Epoch: 6| Step: 6
Training loss: 0.18974652886390686
Validation loss: 2.04008948802948

Epoch: 6| Step: 7
Training loss: 0.2577507197856903
Validation loss: 2.009930411974589

Epoch: 6| Step: 8
Training loss: 0.8013006448745728
Validation loss: 2.0032998919487

Epoch: 6| Step: 9
Training loss: 0.39338988065719604
Validation loss: 2.016897181669871

Epoch: 6| Step: 10
Training loss: 0.2237638384103775
Validation loss: 1.9782201449076335

Epoch: 6| Step: 11
Training loss: 0.4494941830635071
Validation loss: 1.9997208714485168

Epoch: 6| Step: 12
Training loss: 0.18807420134544373
Validation loss: 2.036258061726888

Epoch: 6| Step: 13
Training loss: 0.17124520242214203
Validation loss: 2.030524988969167

Epoch: 295| Step: 0
Training loss: 0.16425834596157074
Validation loss: 2.040958344936371

Epoch: 6| Step: 1
Training loss: 0.23293359577655792
Validation loss: 2.0277481277783713

Epoch: 6| Step: 2
Training loss: 0.24917984008789062
Validation loss: 2.015573720137278

Epoch: 6| Step: 3
Training loss: 0.29362431168556213
Validation loss: 2.0431416233380637

Epoch: 6| Step: 4
Training loss: 0.5018666982650757
Validation loss: 2.0408878326416016

Epoch: 6| Step: 5
Training loss: 0.24348662793636322
Validation loss: 2.054579496383667

Epoch: 6| Step: 6
Training loss: 0.55682373046875
Validation loss: 2.021906614303589

Epoch: 6| Step: 7
Training loss: 0.22556963562965393
Validation loss: 2.042899429798126

Epoch: 6| Step: 8
Training loss: 0.3140975832939148
Validation loss: 2.061563014984131

Epoch: 6| Step: 9
Training loss: 0.188385471701622
Validation loss: 2.0280210971832275

Epoch: 6| Step: 10
Training loss: 0.1993171125650406
Validation loss: 2.0328714648882547

Epoch: 6| Step: 11
Training loss: 0.15156696736812592
Validation loss: 2.020324925581614

Epoch: 6| Step: 12
Training loss: 0.6807208061218262
Validation loss: 2.0471282998720803

Epoch: 6| Step: 13
Training loss: 0.2499387115240097
Validation loss: 2.0157270431518555

Epoch: 296| Step: 0
Training loss: 0.45605170726776123
Validation loss: 2.01535971959432

Epoch: 6| Step: 1
Training loss: 0.29258596897125244
Validation loss: 2.003811558087667

Epoch: 6| Step: 2
Training loss: 0.3020172715187073
Validation loss: 2.035700956980387

Epoch: 6| Step: 3
Training loss: 0.29362380504608154
Validation loss: 2.025892694791158

Epoch: 6| Step: 4
Training loss: 0.29358115792274475
Validation loss: 2.027829964955648

Epoch: 6| Step: 5
Training loss: 0.6943714618682861
Validation loss: 2.005805790424347

Epoch: 6| Step: 6
Training loss: 0.22534939646720886
Validation loss: 2.04704087972641

Epoch: 6| Step: 7
Training loss: 0.2808188199996948
Validation loss: 2.001660426457723

Epoch: 6| Step: 8
Training loss: 0.30180954933166504
Validation loss: 2.009526232878367

Epoch: 6| Step: 9
Training loss: 0.3167567253112793
Validation loss: 2.03521321217219

Epoch: 6| Step: 10
Training loss: 0.16714048385620117
Validation loss: 1.9849565029144287

Epoch: 6| Step: 11
Training loss: 0.2667362093925476
Validation loss: 2.058585206667582

Epoch: 6| Step: 12
Training loss: 0.41308677196502686
Validation loss: 1.9914826154708862

Epoch: 6| Step: 13
Training loss: 0.3214109539985657
Validation loss: 2.00208447376887

Epoch: 297| Step: 0
Training loss: 0.16085706651210785
Validation loss: 2.0363643566767373

Epoch: 6| Step: 1
Training loss: 0.25839468836784363
Validation loss: 1.9814470211664836

Epoch: 6| Step: 2
Training loss: 0.11214572191238403
Validation loss: 2.048392732938131

Epoch: 6| Step: 3
Training loss: 0.24341250956058502
Validation loss: 2.045122981071472

Epoch: 6| Step: 4
Training loss: 0.2751142680644989
Validation loss: 2.000821908315023

Epoch: 6| Step: 5
Training loss: 0.1776655912399292
Validation loss: 2.0295275251070657

Epoch: 6| Step: 6
Training loss: 0.5617766380310059
Validation loss: 1.9939404527346294

Epoch: 6| Step: 7
Training loss: 0.3034345507621765
Validation loss: 2.036897599697113

Epoch: 6| Step: 8
Training loss: 0.4570644795894623
Validation loss: 2.028101086616516

Epoch: 6| Step: 9
Training loss: 0.401262104511261
Validation loss: 2.053759813308716

Epoch: 6| Step: 10
Training loss: 0.25163722038269043
Validation loss: 2.040068765481313

Epoch: 6| Step: 11
Training loss: 0.22919388115406036
Validation loss: 2.0587475101153054

Epoch: 6| Step: 12
Training loss: 0.6501206159591675
Validation loss: 2.0251572132110596

Epoch: 6| Step: 13
Training loss: 0.24723920226097107
Validation loss: 2.044189174969991

Epoch: 298| Step: 0
Training loss: 0.28466466069221497
Validation loss: 2.0071837306022644

Epoch: 6| Step: 1
Training loss: 0.24711939692497253
Validation loss: 2.0723931193351746

Epoch: 6| Step: 2
Training loss: 0.342793345451355
Validation loss: 2.039115389188131

Epoch: 6| Step: 3
Training loss: 0.19173243641853333
Validation loss: 2.029041667779287

Epoch: 6| Step: 4
Training loss: 0.328029066324234
Validation loss: 2.0458348989486694

Epoch: 6| Step: 5
Training loss: 0.33014899492263794
Validation loss: 2.0394421815872192

Epoch: 6| Step: 6
Training loss: 0.28596019744873047
Validation loss: 2.0789862275123596

Epoch: 6| Step: 7
Training loss: 0.24335184693336487
Validation loss: 2.0362016757329306

Epoch: 6| Step: 8
Training loss: 0.2466558963060379
Validation loss: 2.0431788166364035

Epoch: 6| Step: 9
Training loss: 0.3308425843715668
Validation loss: 2.082942565282186

Epoch: 6| Step: 10
Training loss: 0.5739351511001587
Validation loss: 2.0392086505889893

Epoch: 6| Step: 11
Training loss: 0.30899953842163086
Validation loss: 2.038580516974131

Epoch: 6| Step: 12
Training loss: 0.34907960891723633
Validation loss: 2.0441478292147317

Epoch: 6| Step: 13
Training loss: 0.3070918917655945
Validation loss: 2.0649353861808777

Epoch: 299| Step: 0
Training loss: 0.2353566288948059
Validation loss: 2.0615863601366677

Epoch: 6| Step: 1
Training loss: 0.4675276577472687
Validation loss: 2.0168514450391135

Epoch: 6| Step: 2
Training loss: 0.2154846489429474
Validation loss: 2.043456772963206

Epoch: 6| Step: 3
Training loss: 0.23779235780239105
Validation loss: 2.056400239467621

Epoch: 6| Step: 4
Training loss: 0.4162735939025879
Validation loss: 2.0770436724027

Epoch: 6| Step: 5
Training loss: 0.31110796332359314
Validation loss: 2.016493578751882

Epoch: 6| Step: 6
Training loss: 0.23433443903923035
Validation loss: 2.0204917987187705

Epoch: 6| Step: 7
Training loss: 0.26875442266464233
Validation loss: 2.0208728909492493

Epoch: 6| Step: 8
Training loss: 0.4760623276233673
Validation loss: 1.9867614308993022

Epoch: 6| Step: 9
Training loss: 0.21659612655639648
Validation loss: 2.0250818729400635

Epoch: 6| Step: 10
Training loss: 0.613627552986145
Validation loss: 2.0530253450075784

Epoch: 6| Step: 11
Training loss: 0.2829098105430603
Validation loss: 2.044521371523539

Epoch: 6| Step: 12
Training loss: 0.4242854416370392
Validation loss: 2.0082876284917197

Epoch: 6| Step: 13
Training loss: 0.2624291479587555
Validation loss: 2.0558316310246787

Epoch: 300| Step: 0
Training loss: 0.29344719648361206
Validation loss: 2.0661614139874778

Epoch: 6| Step: 1
Training loss: 0.4102359116077423
Validation loss: 2.045188923676809

Epoch: 6| Step: 2
Training loss: 0.2630593776702881
Validation loss: 2.0274831851323447

Epoch: 6| Step: 3
Training loss: 0.3105844259262085
Validation loss: 2.0364625453948975

Epoch: 6| Step: 4
Training loss: 0.4802949130535126
Validation loss: 2.0322431325912476

Epoch: 6| Step: 5
Training loss: 0.27186328172683716
Validation loss: 2.0154316425323486

Epoch: 6| Step: 6
Training loss: 0.2510387599468231
Validation loss: 2.055548151334127

Epoch: 6| Step: 7
Training loss: 0.1839250922203064
Validation loss: 2.0561094284057617

Epoch: 6| Step: 8
Training loss: 0.38176363706588745
Validation loss: 2.0816317995389304

Epoch: 6| Step: 9
Training loss: 0.20582148432731628
Validation loss: 2.0782700777053833

Epoch: 6| Step: 10
Training loss: 0.18804556131362915
Validation loss: 1.9981939593950908

Epoch: 6| Step: 11
Training loss: 0.16328227519989014
Validation loss: 2.0367781122525535

Epoch: 6| Step: 12
Training loss: 0.3100225627422333
Validation loss: 2.022102197011312

Epoch: 6| Step: 13
Training loss: 0.5386732816696167
Validation loss: 2.007461984952291

Epoch: 301| Step: 0
Training loss: 0.9178127646446228
Validation loss: 2.02606854836146

Epoch: 6| Step: 1
Training loss: 0.502152144908905
Validation loss: 2.0490294893582663

Epoch: 6| Step: 2
Training loss: 0.15904590487480164
Validation loss: 2.00076425075531

Epoch: 6| Step: 3
Training loss: 0.2484273910522461
Validation loss: 1.9992588758468628

Epoch: 6| Step: 4
Training loss: 0.2719572186470032
Validation loss: 2.0038743217786155

Epoch: 6| Step: 5
Training loss: 0.1365184187889099
Validation loss: 2.0327559312184653

Epoch: 6| Step: 6
Training loss: 0.20616981387138367
Validation loss: 1.9946132898330688

Epoch: 6| Step: 7
Training loss: 0.2708163261413574
Validation loss: 2.0463337699572244

Epoch: 6| Step: 8
Training loss: 0.33408576250076294
Validation loss: 2.015139857927958

Epoch: 6| Step: 9
Training loss: 0.24787378311157227
Validation loss: 2.03393946091334

Epoch: 6| Step: 10
Training loss: 0.282831072807312
Validation loss: 2.018333355585734

Epoch: 6| Step: 11
Training loss: 0.2540276050567627
Validation loss: 2.0195622046788535

Epoch: 6| Step: 12
Training loss: 0.25820547342300415
Validation loss: 2.0135493675867715

Epoch: 6| Step: 13
Training loss: 0.3116157054901123
Validation loss: 1.997583031654358

Epoch: 302| Step: 0
Training loss: 0.1405351161956787
Validation loss: 2.0223920941352844

Epoch: 6| Step: 1
Training loss: 0.2012069672346115
Validation loss: 2.0469837586085

Epoch: 6| Step: 2
Training loss: 0.3220631182193756
Validation loss: 2.068798621495565

Epoch: 6| Step: 3
Training loss: 0.2896687984466553
Validation loss: 2.02614293495814

Epoch: 6| Step: 4
Training loss: 0.24378904700279236
Validation loss: 2.0341577331225076

Epoch: 6| Step: 5
Training loss: 0.22220350801944733
Validation loss: 2.004597763220469

Epoch: 6| Step: 6
Training loss: 0.32061463594436646
Validation loss: 2.0038098096847534

Epoch: 6| Step: 7
Training loss: 0.3930045962333679
Validation loss: 2.0201232632001243

Epoch: 6| Step: 8
Training loss: 0.2250635027885437
Validation loss: 1.9926756421724956

Epoch: 6| Step: 9
Training loss: 0.1952235847711563
Validation loss: 2.024017333984375

Epoch: 6| Step: 10
Training loss: 0.5755405426025391
Validation loss: 2.083725392818451

Epoch: 6| Step: 11
Training loss: 0.5966621041297913
Validation loss: 2.054128050804138

Epoch: 6| Step: 12
Training loss: 0.21936923265457153
Validation loss: 2.0471398631731668

Epoch: 6| Step: 13
Training loss: 0.5535286664962769
Validation loss: 2.061526656150818

Epoch: 303| Step: 0
Training loss: 0.2128230631351471
Validation loss: 1.9681015213330586

Epoch: 6| Step: 1
Training loss: 0.4963832199573517
Validation loss: 2.0598896741867065

Epoch: 6| Step: 2
Training loss: 0.5289688110351562
Validation loss: 2.034122327963511

Epoch: 6| Step: 3
Training loss: 0.19971506297588348
Validation loss: 2.0275492072105408

Epoch: 6| Step: 4
Training loss: 0.270840048789978
Validation loss: 2.019204636414846

Epoch: 6| Step: 5
Training loss: 0.4460268020629883
Validation loss: 1.9997104406356812

Epoch: 6| Step: 6
Training loss: 0.19601485133171082
Validation loss: 2.0147408843040466

Epoch: 6| Step: 7
Training loss: 0.5967699885368347
Validation loss: 2.016830245653788

Epoch: 6| Step: 8
Training loss: 0.2505912184715271
Validation loss: 2.0377955238024392

Epoch: 6| Step: 9
Training loss: 0.18953187763690948
Validation loss: 2.0217546025911965

Epoch: 6| Step: 10
Training loss: 0.27625346183776855
Validation loss: 2.01386688152949

Epoch: 6| Step: 11
Training loss: 0.27660220861434937
Validation loss: 2.0271088083585105

Epoch: 6| Step: 12
Training loss: 0.25454288721084595
Validation loss: 2.0178975661595664

Epoch: 6| Step: 13
Training loss: 0.2037447988986969
Validation loss: 2.021036962668101

Epoch: 304| Step: 0
Training loss: 0.18288341164588928
Validation loss: 2.0268984834353128

Epoch: 6| Step: 1
Training loss: 0.2635917663574219
Validation loss: 2.0119791428248086

Epoch: 6| Step: 2
Training loss: 0.19879050552845
Validation loss: 2.0275230606396994

Epoch: 6| Step: 3
Training loss: 0.42669668793678284
Validation loss: 2.0389378865559897

Epoch: 6| Step: 4
Training loss: 0.3009152412414551
Validation loss: 2.0184743404388428

Epoch: 6| Step: 5
Training loss: 0.35517340898513794
Validation loss: 2.0628323356310525

Epoch: 6| Step: 6
Training loss: 0.19150345027446747
Validation loss: 2.0145957469940186

Epoch: 6| Step: 7
Training loss: 0.23484288156032562
Validation loss: 1.9897846778233845

Epoch: 6| Step: 8
Training loss: 0.27095651626586914
Validation loss: 2.0107529560724893

Epoch: 6| Step: 9
Training loss: 0.6528398990631104
Validation loss: 1.9929971893628438

Epoch: 6| Step: 10
Training loss: 0.33357590436935425
Validation loss: 2.0148439407348633

Epoch: 6| Step: 11
Training loss: 0.4260605573654175
Validation loss: 2.004474461078644

Epoch: 6| Step: 12
Training loss: 0.24203059077262878
Validation loss: 1.9934333165486653

Epoch: 6| Step: 13
Training loss: 0.2845061421394348
Validation loss: 2.0172820488611856

Epoch: 305| Step: 0
Training loss: 0.3502695560455322
Validation loss: 2.0475871165593467

Epoch: 6| Step: 1
Training loss: 0.24312689900398254
Validation loss: 2.0332871675491333

Epoch: 6| Step: 2
Training loss: 0.34862932562828064
Validation loss: 2.0236231287320456

Epoch: 6| Step: 3
Training loss: 0.16037513315677643
Validation loss: 2.025550603866577

Epoch: 6| Step: 4
Training loss: 0.30285605788230896
Validation loss: 2.0249107480049133

Epoch: 6| Step: 5
Training loss: 0.19017235934734344
Validation loss: 2.001221477985382

Epoch: 6| Step: 6
Training loss: 0.717075526714325
Validation loss: 2.0223968426386514

Epoch: 6| Step: 7
Training loss: 0.3312670588493347
Validation loss: 2.0468225876490274

Epoch: 6| Step: 8
Training loss: 0.37345629930496216
Validation loss: 2.0384016831715903

Epoch: 6| Step: 9
Training loss: 0.3669361472129822
Validation loss: 2.0674407879511514

Epoch: 6| Step: 10
Training loss: 0.28055351972579956
Validation loss: 2.0326437751452127

Epoch: 6| Step: 11
Training loss: 0.21984292566776276
Validation loss: 2.055508772532145

Epoch: 6| Step: 12
Training loss: 0.22926004230976105
Validation loss: 2.033518652121226

Epoch: 6| Step: 13
Training loss: 0.31396979093551636
Validation loss: 2.0526496171951294

Epoch: 306| Step: 0
Training loss: 0.279948353767395
Validation loss: 2.076924463113149

Epoch: 6| Step: 1
Training loss: 0.26935261487960815
Validation loss: 2.047788759072622

Epoch: 6| Step: 2
Training loss: 0.49759548902511597
Validation loss: 2.014414628346761

Epoch: 6| Step: 3
Training loss: 0.5904170870780945
Validation loss: 2.0122340520222983

Epoch: 6| Step: 4
Training loss: 0.13978150486946106
Validation loss: 2.0105339686075845

Epoch: 6| Step: 5
Training loss: 0.4316720962524414
Validation loss: 2.007177730401357

Epoch: 6| Step: 6
Training loss: 0.27304378151893616
Validation loss: 2.0095701217651367

Epoch: 6| Step: 7
Training loss: 0.21557092666625977
Validation loss: 1.9935818513234456

Epoch: 6| Step: 8
Training loss: 0.2208157777786255
Validation loss: 2.04579750696818

Epoch: 6| Step: 9
Training loss: 0.22494295239448547
Validation loss: 2.0440543492635093

Epoch: 6| Step: 10
Training loss: 0.21390599012374878
Validation loss: 2.0371487935384116

Epoch: 6| Step: 11
Training loss: 0.2998591661453247
Validation loss: 2.0394274989763894

Epoch: 6| Step: 12
Training loss: 0.338491827249527
Validation loss: 2.0508453051249185

Epoch: 6| Step: 13
Training loss: 0.3764622211456299
Validation loss: 2.025119960308075

Epoch: 307| Step: 0
Training loss: 0.37148845195770264
Validation loss: 2.0378523071606955

Epoch: 6| Step: 1
Training loss: 0.2591021955013275
Validation loss: 2.0013942321141562

Epoch: 6| Step: 2
Training loss: 0.4715283215045929
Validation loss: 2.0227210323015847

Epoch: 6| Step: 3
Training loss: 0.3188493847846985
Validation loss: 2.0271673997243247

Epoch: 6| Step: 4
Training loss: 0.22818496823310852
Validation loss: 1.976025899251302

Epoch: 6| Step: 5
Training loss: 0.2624610662460327
Validation loss: 2.0269763469696045

Epoch: 6| Step: 6
Training loss: 0.19304820895195007
Validation loss: 2.012052595615387

Epoch: 6| Step: 7
Training loss: 0.31992852687835693
Validation loss: 2.0310427149136863

Epoch: 6| Step: 8
Training loss: 0.22350072860717773
Validation loss: 2.031769553820292

Epoch: 6| Step: 9
Training loss: 0.22439056634902954
Validation loss: 2.0502907435099282

Epoch: 6| Step: 10
Training loss: 0.2981629967689514
Validation loss: 2.0375871459643045

Epoch: 6| Step: 11
Training loss: 0.4101545512676239
Validation loss: 2.0774746537208557

Epoch: 6| Step: 12
Training loss: 0.3114870488643646
Validation loss: 2.028469502925873

Epoch: 6| Step: 13
Training loss: 0.6149263381958008
Validation loss: 2.031219204266866

Epoch: 308| Step: 0
Training loss: 0.37128621339797974
Validation loss: 2.06134957075119

Epoch: 6| Step: 1
Training loss: 0.3364981710910797
Validation loss: 2.0512868364652

Epoch: 6| Step: 2
Training loss: 0.2063329815864563
Validation loss: 2.004927158355713

Epoch: 6| Step: 3
Training loss: 0.21968719363212585
Validation loss: 2.078403651714325

Epoch: 6| Step: 4
Training loss: 0.28539419174194336
Validation loss: 2.0398146708806357

Epoch: 6| Step: 5
Training loss: 0.35906079411506653
Validation loss: 2.058734973271688

Epoch: 6| Step: 6
Training loss: 0.3391004800796509
Validation loss: 2.040527323881785

Epoch: 6| Step: 7
Training loss: 0.435360312461853
Validation loss: 2.0360026558240256

Epoch: 6| Step: 8
Training loss: 0.20925888419151306
Validation loss: 1.985339085261027

Epoch: 6| Step: 9
Training loss: 0.7469674944877625
Validation loss: 2.041533589363098

Epoch: 6| Step: 10
Training loss: 0.16073502600193024
Validation loss: 2.0824197133382163

Epoch: 6| Step: 11
Training loss: 0.28989142179489136
Validation loss: 2.05135311683019

Epoch: 6| Step: 12
Training loss: 0.30284354090690613
Validation loss: 2.0405256350835166

Epoch: 6| Step: 13
Training loss: 0.20657308399677277
Validation loss: 2.0431021253267923

Epoch: 309| Step: 0
Training loss: 0.16663405299186707
Validation loss: 2.0594570438067117

Epoch: 6| Step: 1
Training loss: 0.291023850440979
Validation loss: 2.036985715230306

Epoch: 6| Step: 2
Training loss: 0.25240910053253174
Validation loss: 2.0212329824765525

Epoch: 6| Step: 3
Training loss: 0.2543110251426697
Validation loss: 2.035696804523468

Epoch: 6| Step: 4
Training loss: 0.39135444164276123
Validation loss: 2.04959503809611

Epoch: 6| Step: 5
Training loss: 0.348583459854126
Validation loss: 2.011401375134786

Epoch: 6| Step: 6
Training loss: 0.34814903140068054
Validation loss: 2.0553939739863076

Epoch: 6| Step: 7
Training loss: 0.2884790897369385
Validation loss: 2.0652061104774475

Epoch: 6| Step: 8
Training loss: 0.3252507150173187
Validation loss: 2.0445172786712646

Epoch: 6| Step: 9
Training loss: 0.256110817193985
Validation loss: 2.045747399330139

Epoch: 6| Step: 10
Training loss: 0.6084475517272949
Validation loss: 2.042900323867798

Epoch: 6| Step: 11
Training loss: 0.591734766960144
Validation loss: 2.028581122557322

Epoch: 6| Step: 12
Training loss: 0.43051135540008545
Validation loss: 2.0154898961385093

Epoch: 6| Step: 13
Training loss: 0.25579530000686646
Validation loss: 2.06703652938207

Epoch: 310| Step: 0
Training loss: 0.2522857189178467
Validation loss: 2.032650669415792

Epoch: 6| Step: 1
Training loss: 0.2954237461090088
Validation loss: 1.9951473275820415

Epoch: 6| Step: 2
Training loss: 0.2561648488044739
Validation loss: 2.055117130279541

Epoch: 6| Step: 3
Training loss: 0.4980350136756897
Validation loss: 2.0210132797559104

Epoch: 6| Step: 4
Training loss: 0.539488673210144
Validation loss: 2.0593833923339844

Epoch: 6| Step: 5
Training loss: 0.2990928888320923
Validation loss: 2.029508650302887

Epoch: 6| Step: 6
Training loss: 0.265964150428772
Validation loss: 2.0465941230456033

Epoch: 6| Step: 7
Training loss: 0.3506343960762024
Validation loss: 2.0112737019856772

Epoch: 6| Step: 8
Training loss: 0.3911520838737488
Validation loss: 2.0365583300590515

Epoch: 6| Step: 9
Training loss: 0.1331349015235901
Validation loss: 2.0319450894991555

Epoch: 6| Step: 10
Training loss: 0.25734829902648926
Validation loss: 2.0352222522099814

Epoch: 6| Step: 11
Training loss: 0.29285478591918945
Validation loss: 2.0099506775538125

Epoch: 6| Step: 12
Training loss: 0.2417895495891571
Validation loss: 1.9988826115926106

Epoch: 6| Step: 13
Training loss: 0.15500269830226898
Validation loss: 2.0625980695088706

Epoch: 311| Step: 0
Training loss: 0.17332041263580322
Validation loss: 2.027347187201182

Epoch: 6| Step: 1
Training loss: 0.3058065176010132
Validation loss: 2.061022996902466

Epoch: 6| Step: 2
Training loss: 0.21269087493419647
Validation loss: 1.9836035172144573

Epoch: 6| Step: 3
Training loss: 0.30857932567596436
Validation loss: 2.03917803366979

Epoch: 6| Step: 4
Training loss: 0.21932126581668854
Validation loss: 2.0072829922040305

Epoch: 6| Step: 5
Training loss: 0.2506091296672821
Validation loss: 2.0220468044281006

Epoch: 6| Step: 6
Training loss: 0.19595932960510254
Validation loss: 2.095182478427887

Epoch: 6| Step: 7
Training loss: 0.47806933522224426
Validation loss: 2.0109967390696206

Epoch: 6| Step: 8
Training loss: 0.6908683776855469
Validation loss: 2.083949625492096

Epoch: 6| Step: 9
Training loss: 0.28826481103897095
Validation loss: 2.004140098889669

Epoch: 6| Step: 10
Training loss: 0.193601593375206
Validation loss: 2.002384881178538

Epoch: 6| Step: 11
Training loss: 0.5749434232711792
Validation loss: 2.0244149565696716

Epoch: 6| Step: 12
Training loss: 0.19228173792362213
Validation loss: 2.014772872130076

Epoch: 6| Step: 13
Training loss: 0.24139653146266937
Validation loss: 2.026240507761637

Epoch: 312| Step: 0
Training loss: 0.25152164697647095
Validation loss: 2.0247521797815957

Epoch: 6| Step: 1
Training loss: 0.37703290581703186
Validation loss: 2.0015915433565774

Epoch: 6| Step: 2
Training loss: 0.14918148517608643
Validation loss: 2.036404609680176

Epoch: 6| Step: 3
Training loss: 0.3564736247062683
Validation loss: 2.0503889123598733

Epoch: 6| Step: 4
Training loss: 0.4291151463985443
Validation loss: 2.054676433404287

Epoch: 6| Step: 5
Training loss: 0.18080948293209076
Validation loss: 2.02663787206014

Epoch: 6| Step: 6
Training loss: 0.2102908045053482
Validation loss: 2.053650180498759

Epoch: 6| Step: 7
Training loss: 0.22674286365509033
Validation loss: 2.0238441030184426

Epoch: 6| Step: 8
Training loss: 0.4509442448616028
Validation loss: 2.0227115551630654

Epoch: 6| Step: 9
Training loss: 0.21538382768630981
Validation loss: 2.0156879226366677

Epoch: 6| Step: 10
Training loss: 0.5981941223144531
Validation loss: 2.030304233233134

Epoch: 6| Step: 11
Training loss: 0.1958426535129547
Validation loss: 2.021886467933655

Epoch: 6| Step: 12
Training loss: 0.3887321949005127
Validation loss: 2.0928199887275696

Epoch: 6| Step: 13
Training loss: 0.2632790207862854
Validation loss: 2.0023839871088662

Epoch: 313| Step: 0
Training loss: 0.21195241808891296
Validation loss: 2.0252484480539956

Epoch: 6| Step: 1
Training loss: 0.23813515901565552
Validation loss: 2.0578590830167136

Epoch: 6| Step: 2
Training loss: 0.224775493144989
Validation loss: 2.0426741242408752

Epoch: 6| Step: 3
Training loss: 0.22179630398750305
Validation loss: 2.0275381604830423

Epoch: 6| Step: 4
Training loss: 0.15613692998886108
Validation loss: 2.0260172287623086

Epoch: 6| Step: 5
Training loss: 0.1840941458940506
Validation loss: 2.004182438055674

Epoch: 6| Step: 6
Training loss: 0.6128762364387512
Validation loss: 2.0862648487091064

Epoch: 6| Step: 7
Training loss: 0.25657323002815247
Validation loss: 2.026952346165975

Epoch: 6| Step: 8
Training loss: 0.278999924659729
Validation loss: 2.0325116316477456

Epoch: 6| Step: 9
Training loss: 0.5749481916427612
Validation loss: 2.0567166606585183

Epoch: 6| Step: 10
Training loss: 0.14393186569213867
Validation loss: 2.0807860096295676

Epoch: 6| Step: 11
Training loss: 0.3417045474052429
Validation loss: 2.016437510649363

Epoch: 6| Step: 12
Training loss: 0.46465620398521423
Validation loss: 2.0535958409309387

Epoch: 6| Step: 13
Training loss: 0.22542235255241394
Validation loss: 2.0461901823679605

Epoch: 314| Step: 0
Training loss: 0.37118208408355713
Validation loss: 2.0479751229286194

Epoch: 6| Step: 1
Training loss: 0.32730919122695923
Validation loss: 2.030121147632599

Epoch: 6| Step: 2
Training loss: 0.33704137802124023
Validation loss: 2.1036049524943032

Epoch: 6| Step: 3
Training loss: 0.3053606152534485
Validation loss: 2.0624656478563943

Epoch: 6| Step: 4
Training loss: 0.6999940872192383
Validation loss: 2.0600205063819885

Epoch: 6| Step: 5
Training loss: 0.28272053599357605
Validation loss: 2.0438254674275718

Epoch: 6| Step: 6
Training loss: 0.2226669192314148
Validation loss: 2.0395462115605674

Epoch: 6| Step: 7
Training loss: 0.2137582004070282
Validation loss: 2.033691942691803

Epoch: 6| Step: 8
Training loss: 0.2693934440612793
Validation loss: 2.084484855333964

Epoch: 6| Step: 9
Training loss: 0.22673532366752625
Validation loss: 2.0261096954345703

Epoch: 6| Step: 10
Training loss: 0.3512389659881592
Validation loss: 2.017126679420471

Epoch: 6| Step: 11
Training loss: 0.23856092989444733
Validation loss: 2.038505216439565

Epoch: 6| Step: 12
Training loss: 0.42925944924354553
Validation loss: 2.029175599416097

Epoch: 6| Step: 13
Training loss: 0.5164108276367188
Validation loss: 2.0303740898768106

Epoch: 315| Step: 0
Training loss: 0.553349494934082
Validation loss: 2.061557094256083

Epoch: 6| Step: 1
Training loss: 0.30910080671310425
Validation loss: 2.0331801772117615

Epoch: 6| Step: 2
Training loss: 0.35539257526397705
Validation loss: 2.018271048863729

Epoch: 6| Step: 3
Training loss: 0.1912875473499298
Validation loss: 2.079257289568583

Epoch: 6| Step: 4
Training loss: 0.3777099549770355
Validation loss: 1.9944946765899658

Epoch: 6| Step: 5
Training loss: 0.7085524201393127
Validation loss: 2.0561519861221313

Epoch: 6| Step: 6
Training loss: 0.316734254360199
Validation loss: 2.0510263641675315

Epoch: 6| Step: 7
Training loss: 0.2569749355316162
Validation loss: 2.036286552747091

Epoch: 6| Step: 8
Training loss: 0.2838098704814911
Validation loss: 2.007152795791626

Epoch: 6| Step: 9
Training loss: 0.21583008766174316
Validation loss: 2.0172736644744873

Epoch: 6| Step: 10
Training loss: 0.29751962423324585
Validation loss: 1.98930956919988

Epoch: 6| Step: 11
Training loss: 0.26842135190963745
Validation loss: 2.0004116694132485

Epoch: 6| Step: 12
Training loss: 0.18567153811454773
Validation loss: 2.01430614789327

Epoch: 6| Step: 13
Training loss: 0.22604568302631378
Validation loss: 2.0162314971288047

Epoch: 316| Step: 0
Training loss: 0.33901894092559814
Validation loss: 1.9982099334398906

Epoch: 6| Step: 1
Training loss: 0.19231252372264862
Validation loss: 2.015722652276357

Epoch: 6| Step: 2
Training loss: 0.20161300897598267
Validation loss: 2.007756074269613

Epoch: 6| Step: 3
Training loss: 0.46562641859054565
Validation loss: 1.984360675017039

Epoch: 6| Step: 4
Training loss: 0.16971436142921448
Validation loss: 1.9975008567174275

Epoch: 6| Step: 5
Training loss: 0.1353958696126938
Validation loss: 1.9685590465863545

Epoch: 6| Step: 6
Training loss: 0.33104950189590454
Validation loss: 2.029697855313619

Epoch: 6| Step: 7
Training loss: 0.259238600730896
Validation loss: 2.0170557697614035

Epoch: 6| Step: 8
Training loss: 0.3152604103088379
Validation loss: 2.020901064078013

Epoch: 6| Step: 9
Training loss: 0.7508057355880737
Validation loss: 2.013504207134247

Epoch: 6| Step: 10
Training loss: 0.31089186668395996
Validation loss: 2.031205157438914

Epoch: 6| Step: 11
Training loss: 0.22075307369232178
Validation loss: 1.9931520819664001

Epoch: 6| Step: 12
Training loss: 0.22127637267112732
Validation loss: 1.9912429054578145

Epoch: 6| Step: 13
Training loss: 0.23842783272266388
Validation loss: 2.014080504576365

Epoch: 317| Step: 0
Training loss: 0.42378008365631104
Validation loss: 1.993846873442332

Epoch: 6| Step: 1
Training loss: 0.33370551466941833
Validation loss: 1.9892454743385315

Epoch: 6| Step: 2
Training loss: 0.26711153984069824
Validation loss: 2.0329339702924094

Epoch: 6| Step: 3
Training loss: 0.33633953332901
Validation loss: 1.9766952991485596

Epoch: 6| Step: 4
Training loss: 0.20762410759925842
Validation loss: 2.0163981517155967

Epoch: 6| Step: 5
Training loss: 0.2565303444862366
Validation loss: 2.044719099998474

Epoch: 6| Step: 6
Training loss: 0.23222193121910095
Validation loss: 2.0254300832748413

Epoch: 6| Step: 7
Training loss: 0.31222376227378845
Validation loss: 1.9881888628005981

Epoch: 6| Step: 8
Training loss: 0.2772795259952545
Validation loss: 2.024737556775411

Epoch: 6| Step: 9
Training loss: 0.22845561802387238
Validation loss: 1.9750457604726155

Epoch: 6| Step: 10
Training loss: 0.6875622868537903
Validation loss: 2.0301686724027

Epoch: 6| Step: 11
Training loss: 0.2542141079902649
Validation loss: 2.001164436340332

Epoch: 6| Step: 12
Training loss: 0.3310072422027588
Validation loss: 1.9675738612810771

Epoch: 6| Step: 13
Training loss: 0.26088574528694153
Validation loss: 1.995473285516103

Epoch: 318| Step: 0
Training loss: 0.2611445188522339
Validation loss: 2.0441672007242837

Epoch: 6| Step: 1
Training loss: 0.329435259103775
Validation loss: 2.04861185948054

Epoch: 6| Step: 2
Training loss: 0.21108433604240417
Validation loss: 2.0518906116485596

Epoch: 6| Step: 3
Training loss: 0.30221113562583923
Validation loss: 1.9925488432248433

Epoch: 6| Step: 4
Training loss: 0.3966468572616577
Validation loss: 2.013344426949819

Epoch: 6| Step: 5
Training loss: 0.3031247854232788
Validation loss: 2.0204279820124307

Epoch: 6| Step: 6
Training loss: 0.2666206657886505
Validation loss: 2.014877955118815

Epoch: 6| Step: 7
Training loss: 0.239045187830925
Validation loss: 2.012456556161245

Epoch: 6| Step: 8
Training loss: 0.7444394826889038
Validation loss: 2.053473929564158

Epoch: 6| Step: 9
Training loss: 0.3118622899055481
Validation loss: 2.037827809651693

Epoch: 6| Step: 10
Training loss: 0.17804569005966187
Validation loss: 2.0161289970080056

Epoch: 6| Step: 11
Training loss: 0.2919171452522278
Validation loss: 2.060054341952006

Epoch: 6| Step: 12
Training loss: 0.13299809396266937
Validation loss: 2.0436884562174478

Epoch: 6| Step: 13
Training loss: 0.21250185370445251
Validation loss: 2.016315519809723

Epoch: 319| Step: 0
Training loss: 0.22870689630508423
Validation loss: 2.0177443424860635

Epoch: 6| Step: 1
Training loss: 0.34585994482040405
Validation loss: 1.9968173106511433

Epoch: 6| Step: 2
Training loss: 0.2886430323123932
Validation loss: 2.0478928089141846

Epoch: 6| Step: 3
Training loss: 0.22558782994747162
Validation loss: 1.9873908559481304

Epoch: 6| Step: 4
Training loss: 0.3241743743419647
Validation loss: 2.051215410232544

Epoch: 6| Step: 5
Training loss: 0.24971842765808105
Validation loss: 2.031993865966797

Epoch: 6| Step: 6
Training loss: 0.4598747491836548
Validation loss: 2.0448627273241677

Epoch: 6| Step: 7
Training loss: 0.3408764600753784
Validation loss: 1.9948534965515137

Epoch: 6| Step: 8
Training loss: 0.16029596328735352
Validation loss: 2.076110303401947

Epoch: 6| Step: 9
Training loss: 0.2954302430152893
Validation loss: 2.0507490833600364

Epoch: 6| Step: 10
Training loss: 0.6453329920768738
Validation loss: 2.0531692504882812

Epoch: 6| Step: 11
Training loss: 0.22585177421569824
Validation loss: 2.0319600900014243

Epoch: 6| Step: 12
Training loss: 0.3049103617668152
Validation loss: 1.997786521911621

Epoch: 6| Step: 13
Training loss: 0.35950368642807007
Validation loss: 2.0360845923423767

Epoch: 320| Step: 0
Training loss: 0.1450602114200592
Validation loss: 1.9836209019025166

Epoch: 6| Step: 1
Training loss: 0.30982279777526855
Validation loss: 2.0131666461626687

Epoch: 6| Step: 2
Training loss: 0.22095395624637604
Validation loss: 2.0000811219215393

Epoch: 6| Step: 3
Training loss: 0.1836860626935959
Validation loss: 1.9935389757156372

Epoch: 6| Step: 4
Training loss: 0.29108959436416626
Validation loss: 2.014775276184082

Epoch: 6| Step: 5
Training loss: 0.2398449033498764
Validation loss: 2.02844645579656

Epoch: 6| Step: 6
Training loss: 0.45076701045036316
Validation loss: 1.9633294741312664

Epoch: 6| Step: 7
Training loss: 0.28134018182754517
Validation loss: 2.0002362728118896

Epoch: 6| Step: 8
Training loss: 0.3917582631111145
Validation loss: 2.023385922114054

Epoch: 6| Step: 9
Training loss: 0.3845874071121216
Validation loss: 1.99973460038503

Epoch: 6| Step: 10
Training loss: 0.5863964557647705
Validation loss: 2.0752678712209067

Epoch: 6| Step: 11
Training loss: 0.19070470333099365
Validation loss: 2.045348823070526

Epoch: 6| Step: 12
Training loss: 0.2011263221502304
Validation loss: 2.0479237834612527

Epoch: 6| Step: 13
Training loss: 0.23738816380500793
Validation loss: 2.02508682012558

Epoch: 321| Step: 0
Training loss: 0.18479102849960327
Validation loss: 2.050891637802124

Epoch: 6| Step: 1
Training loss: 0.1794835925102234
Validation loss: 2.0351003607114158

Epoch: 6| Step: 2
Training loss: 0.2772902846336365
Validation loss: 2.0574775536855063

Epoch: 6| Step: 3
Training loss: 0.6837470531463623
Validation loss: 2.0071903665860495

Epoch: 6| Step: 4
Training loss: 0.5168992877006531
Validation loss: 2.0669398109118142

Epoch: 6| Step: 5
Training loss: 0.19195175170898438
Validation loss: 2.050598382949829

Epoch: 6| Step: 6
Training loss: 0.19594767689704895
Validation loss: 2.041117469469706

Epoch: 6| Step: 7
Training loss: 0.3658834397792816
Validation loss: 2.069396138191223

Epoch: 6| Step: 8
Training loss: 0.3524860143661499
Validation loss: 2.0705891450246177

Epoch: 6| Step: 9
Training loss: 0.22599563002586365
Validation loss: 2.012374699115753

Epoch: 6| Step: 10
Training loss: 0.22178888320922852
Validation loss: 2.0669620434443154

Epoch: 6| Step: 11
Training loss: 0.23987291753292084
Validation loss: 2.0638829270998635

Epoch: 6| Step: 12
Training loss: 0.22658750414848328
Validation loss: 2.050028383731842

Epoch: 6| Step: 13
Training loss: 0.2988317012786865
Validation loss: 2.0260419845581055

Epoch: 322| Step: 0
Training loss: 0.2175067663192749
Validation loss: 2.024859885374705

Epoch: 6| Step: 1
Training loss: 0.25329679250717163
Validation loss: 2.0459482272466025

Epoch: 6| Step: 2
Training loss: 0.17100095748901367
Validation loss: 2.0083744724591575

Epoch: 6| Step: 3
Training loss: 0.6557574272155762
Validation loss: 2.0585997502009072

Epoch: 6| Step: 4
Training loss: 0.3418600261211395
Validation loss: 1.9683249195416768

Epoch: 6| Step: 5
Training loss: 0.3081182837486267
Validation loss: 2.008073627948761

Epoch: 6| Step: 6
Training loss: 0.3260045647621155
Validation loss: 2.024514933427175

Epoch: 6| Step: 7
Training loss: 0.4943513870239258
Validation loss: 2.005608101685842

Epoch: 6| Step: 8
Training loss: 0.17452597618103027
Validation loss: 2.0338889559110007

Epoch: 6| Step: 9
Training loss: 0.17900151014328003
Validation loss: 2.0500863591829934

Epoch: 6| Step: 10
Training loss: 0.25730660557746887
Validation loss: 2.065088629722595

Epoch: 6| Step: 11
Training loss: 0.22911903262138367
Validation loss: 2.0562047362327576

Epoch: 6| Step: 12
Training loss: 0.29557284712791443
Validation loss: 2.056732634703318

Epoch: 6| Step: 13
Training loss: 0.2368852198123932
Validation loss: 2.083777288595835

Epoch: 323| Step: 0
Training loss: 0.22569094598293304
Validation loss: 2.0837332804997764

Epoch: 6| Step: 1
Training loss: 0.175220787525177
Validation loss: 2.047885477542877

Epoch: 6| Step: 2
Training loss: 0.23640459775924683
Validation loss: 2.0178654988606772

Epoch: 6| Step: 3
Training loss: 0.2931886315345764
Validation loss: 2.0105545918146768

Epoch: 6| Step: 4
Training loss: 0.31904318928718567
Validation loss: 2.0433356364568076

Epoch: 6| Step: 5
Training loss: 0.23761655390262604
Validation loss: 2.050775686899821

Epoch: 6| Step: 6
Training loss: 0.42110639810562134
Validation loss: 2.0407127936681113

Epoch: 6| Step: 7
Training loss: 0.15111245214939117
Validation loss: 2.0310624837875366

Epoch: 6| Step: 8
Training loss: 0.3710428476333618
Validation loss: 2.0403649608294168

Epoch: 6| Step: 9
Training loss: 0.528031051158905
Validation loss: 2.0491767724355063

Epoch: 6| Step: 10
Training loss: 0.37727880477905273
Validation loss: 2.0547694166501365

Epoch: 6| Step: 11
Training loss: 0.27735602855682373
Validation loss: 2.0052177906036377

Epoch: 6| Step: 12
Training loss: 0.36398249864578247
Validation loss: 2.0391491850217185

Epoch: 6| Step: 13
Training loss: 0.1267971247434616
Validation loss: 2.020163059234619

Epoch: 324| Step: 0
Training loss: 0.2248263657093048
Validation loss: 2.0723358392715454

Epoch: 6| Step: 1
Training loss: 0.31988099217414856
Validation loss: 1.9937784473101299

Epoch: 6| Step: 2
Training loss: 0.22479180991649628
Validation loss: 2.0465394258499146

Epoch: 6| Step: 3
Training loss: 0.613190770149231
Validation loss: 2.007343510786692

Epoch: 6| Step: 4
Training loss: 0.18780681490898132
Validation loss: 2.0219003756841025

Epoch: 6| Step: 5
Training loss: 0.337361216545105
Validation loss: 2.0454314549764

Epoch: 6| Step: 6
Training loss: 0.2107188105583191
Validation loss: 2.0106163819630942

Epoch: 6| Step: 7
Training loss: 0.1371334344148636
Validation loss: 2.022352417310079

Epoch: 6| Step: 8
Training loss: 0.32924288511276245
Validation loss: 2.045847256978353

Epoch: 6| Step: 9
Training loss: 0.5089268684387207
Validation loss: 2.054516692956289

Epoch: 6| Step: 10
Training loss: 0.21858733892440796
Validation loss: 2.050577243169149

Epoch: 6| Step: 11
Training loss: 0.2400783747434616
Validation loss: 2.0286194880803428

Epoch: 6| Step: 12
Training loss: 0.31534385681152344
Validation loss: 2.0594603419303894

Epoch: 6| Step: 13
Training loss: 0.21605515480041504
Validation loss: 2.020883043607076

Epoch: 325| Step: 0
Training loss: 0.26788341999053955
Validation loss: 2.032626767953237

Epoch: 6| Step: 1
Training loss: 0.17578847706317902
Validation loss: 2.048589289188385

Epoch: 6| Step: 2
Training loss: 0.2624942660331726
Validation loss: 2.062640647093455

Epoch: 6| Step: 3
Training loss: 0.257689893245697
Validation loss: 2.0227513909339905

Epoch: 6| Step: 4
Training loss: 0.43097928166389465
Validation loss: 2.1047154863675437

Epoch: 6| Step: 5
Training loss: 0.27930235862731934
Validation loss: 2.0576082666714988

Epoch: 6| Step: 6
Training loss: 0.7788094282150269
Validation loss: 2.0316975514094033

Epoch: 6| Step: 7
Training loss: 0.2005104422569275
Validation loss: 1.9749809702237446

Epoch: 6| Step: 8
Training loss: 0.305418998003006
Validation loss: 1.9996542930603027

Epoch: 6| Step: 9
Training loss: 0.2945970594882965
Validation loss: 1.9983250896135967

Epoch: 6| Step: 10
Training loss: 0.3187280595302582
Validation loss: 2.0028469959894815

Epoch: 6| Step: 11
Training loss: 0.23102864623069763
Validation loss: 1.9864513079325359

Epoch: 6| Step: 12
Training loss: 0.23086774349212646
Validation loss: 2.0042189757029214

Epoch: 6| Step: 13
Training loss: 0.33319681882858276
Validation loss: 2.0067986647288003

Epoch: 326| Step: 0
Training loss: 0.1839079111814499
Validation loss: 1.9903119405110676

Epoch: 6| Step: 1
Training loss: 0.15793544054031372
Validation loss: 2.0297703941663108

Epoch: 6| Step: 2
Training loss: 0.2815707325935364
Validation loss: 2.047071119149526

Epoch: 6| Step: 3
Training loss: 0.6719557046890259
Validation loss: 2.052662750085195

Epoch: 6| Step: 4
Training loss: 0.23501893877983093
Validation loss: 2.0067649682362876

Epoch: 6| Step: 5
Training loss: 0.2520091235637665
Validation loss: 2.0019569794336953

Epoch: 6| Step: 6
Training loss: 0.23900297284126282
Validation loss: 2.0046685338020325

Epoch: 6| Step: 7
Training loss: 0.35308367013931274
Validation loss: 1.9866742491722107

Epoch: 6| Step: 8
Training loss: 0.2815455496311188
Validation loss: 2.0156970620155334

Epoch: 6| Step: 9
Training loss: 0.2644002437591553
Validation loss: 2.0249640345573425

Epoch: 6| Step: 10
Training loss: 0.3861735463142395
Validation loss: 2.0164207418759665

Epoch: 6| Step: 11
Training loss: 0.43664196133613586
Validation loss: 1.9590716163317363

Epoch: 6| Step: 12
Training loss: 0.29144564270973206
Validation loss: 2.02608984708786

Epoch: 6| Step: 13
Training loss: 0.4452301561832428
Validation loss: 2.0464659134546914

Epoch: 327| Step: 0
Training loss: 0.2897605299949646
Validation loss: 2.0543752908706665

Epoch: 6| Step: 1
Training loss: 0.19304636120796204
Validation loss: 2.037293275197347

Epoch: 6| Step: 2
Training loss: 0.2423851042985916
Validation loss: 2.021712521711985

Epoch: 6| Step: 3
Training loss: 0.2974986135959625
Validation loss: 2.030807395776113

Epoch: 6| Step: 4
Training loss: 0.21825724840164185
Validation loss: 2.0208853284517923

Epoch: 6| Step: 5
Training loss: 0.18412137031555176
Validation loss: 2.0459888180096946

Epoch: 6| Step: 6
Training loss: 0.22333213686943054
Validation loss: 2.043757756551107

Epoch: 6| Step: 7
Training loss: 0.29377010464668274
Validation loss: 2.0275112191836038

Epoch: 6| Step: 8
Training loss: 0.33646249771118164
Validation loss: 2.0249030590057373

Epoch: 6| Step: 9
Training loss: 0.2774779796600342
Validation loss: 2.0215893189112344

Epoch: 6| Step: 10
Training loss: 0.4605744779109955
Validation loss: 1.9920788009961445

Epoch: 6| Step: 11
Training loss: 0.5885630249977112
Validation loss: 2.012224098046621

Epoch: 6| Step: 12
Training loss: 0.2408740222454071
Validation loss: 2.0337279637654624

Epoch: 6| Step: 13
Training loss: 0.3825676143169403
Validation loss: 2.03448494275411

Epoch: 328| Step: 0
Training loss: 0.26613306999206543
Validation loss: 2.0163151621818542

Epoch: 6| Step: 1
Training loss: 0.1420823037624359
Validation loss: 1.997649888197581

Epoch: 6| Step: 2
Training loss: 0.1795920729637146
Validation loss: 2.0205702980359397

Epoch: 6| Step: 3
Training loss: 0.19794537127017975
Validation loss: 2.0186346769332886

Epoch: 6| Step: 4
Training loss: 0.22895628213882446
Validation loss: 1.9932419856389363

Epoch: 6| Step: 5
Training loss: 0.651515543460846
Validation loss: 2.031829555829366

Epoch: 6| Step: 6
Training loss: 0.2085026204586029
Validation loss: 2.0328969160715737

Epoch: 6| Step: 7
Training loss: 0.1799110770225525
Validation loss: 1.9891769289970398

Epoch: 6| Step: 8
Training loss: 0.21488410234451294
Validation loss: 1.9983688592910767

Epoch: 6| Step: 9
Training loss: 0.255572646856308
Validation loss: 2.0296703378359475

Epoch: 6| Step: 10
Training loss: 0.32083365321159363
Validation loss: 2.012330492337545

Epoch: 6| Step: 11
Training loss: 0.2127353399991989
Validation loss: 2.0132030248641968

Epoch: 6| Step: 12
Training loss: 0.5298056602478027
Validation loss: 2.022152582804362

Epoch: 6| Step: 13
Training loss: 0.31392526626586914
Validation loss: 1.982889453570048

Epoch: 329| Step: 0
Training loss: 0.36007240414619446
Validation loss: 2.0158738692601523

Epoch: 6| Step: 1
Training loss: 0.25669145584106445
Validation loss: 2.0046018759409585

Epoch: 6| Step: 2
Training loss: 0.30650588870048523
Validation loss: 1.9954577684402466

Epoch: 6| Step: 3
Training loss: 0.2143663465976715
Validation loss: 2.047206401824951

Epoch: 6| Step: 4
Training loss: 0.21455514430999756
Validation loss: 2.0431516567866006

Epoch: 6| Step: 5
Training loss: 0.23733621835708618
Validation loss: 2.0503416458765664

Epoch: 6| Step: 6
Training loss: 0.330045610666275
Validation loss: 2.0159453749656677

Epoch: 6| Step: 7
Training loss: 0.3258918523788452
Validation loss: 2.0329121947288513

Epoch: 6| Step: 8
Training loss: 0.20113308727741241
Validation loss: 2.019242584705353

Epoch: 6| Step: 9
Training loss: 0.581778883934021
Validation loss: 2.0063446164131165

Epoch: 6| Step: 10
Training loss: 0.2690122425556183
Validation loss: 2.028724511464437

Epoch: 6| Step: 11
Training loss: 0.29158973693847656
Validation loss: 1.9949286381403606

Epoch: 6| Step: 12
Training loss: 0.30533266067504883
Validation loss: 1.9873719414075215

Epoch: 6| Step: 13
Training loss: 0.44679486751556396
Validation loss: 2.0253549019495645

Epoch: 330| Step: 0
Training loss: 0.6145749092102051
Validation loss: 2.038725256919861

Epoch: 6| Step: 1
Training loss: 0.16987526416778564
Validation loss: 2.0009289582570395

Epoch: 6| Step: 2
Training loss: 0.23176389932632446
Validation loss: 2.0419286688168845

Epoch: 6| Step: 3
Training loss: 0.17010784149169922
Validation loss: 2.042497217655182

Epoch: 6| Step: 4
Training loss: 0.325922429561615
Validation loss: 2.0124112963676453

Epoch: 6| Step: 5
Training loss: 0.28548353910446167
Validation loss: 2.0389798680941262

Epoch: 6| Step: 6
Training loss: 0.27377209067344666
Validation loss: 2.016452372074127

Epoch: 6| Step: 7
Training loss: 0.21982719004154205
Validation loss: 2.0436390240987143

Epoch: 6| Step: 8
Training loss: 0.37465158104896545
Validation loss: 2.0432918071746826

Epoch: 6| Step: 9
Training loss: 0.2576840817928314
Validation loss: 2.0136247078577676

Epoch: 6| Step: 10
Training loss: 0.3239390254020691
Validation loss: 2.033610145250956

Epoch: 6| Step: 11
Training loss: 0.3949112594127655
Validation loss: 2.020665943622589

Epoch: 6| Step: 12
Training loss: 0.19310171902179718
Validation loss: 2.0277661283810935

Epoch: 6| Step: 13
Training loss: 0.2070970982313156
Validation loss: 1.9794548352559407

Epoch: 331| Step: 0
Training loss: 0.5431327819824219
Validation loss: 2.0251969695091248

Epoch: 6| Step: 1
Training loss: 0.2829689085483551
Validation loss: 2.0056945284207663

Epoch: 6| Step: 2
Training loss: 0.18653061985969543
Validation loss: 2.0236376523971558

Epoch: 6| Step: 3
Training loss: 0.22915339469909668
Validation loss: 2.0253490010897317

Epoch: 6| Step: 4
Training loss: 0.17446181178092957
Validation loss: 2.0200460155804953

Epoch: 6| Step: 5
Training loss: 0.3137054443359375
Validation loss: 2.0237817962964377

Epoch: 6| Step: 6
Training loss: 0.38736027479171753
Validation loss: 2.0273826320966086

Epoch: 6| Step: 7
Training loss: 0.23143690824508667
Validation loss: 2.0317450960477195

Epoch: 6| Step: 8
Training loss: 0.24635887145996094
Validation loss: 2.015626589457194

Epoch: 6| Step: 9
Training loss: 0.15429872274398804
Validation loss: 1.975196937719981

Epoch: 6| Step: 10
Training loss: 0.27928704023361206
Validation loss: 2.052263617515564

Epoch: 6| Step: 11
Training loss: 0.19868439435958862
Validation loss: 2.049063483874003

Epoch: 6| Step: 12
Training loss: 0.27391085028648376
Validation loss: 2.0361380577087402

Epoch: 6| Step: 13
Training loss: 0.2606007754802704
Validation loss: 2.0534260869026184

Epoch: 332| Step: 0
Training loss: 0.3577176332473755
Validation loss: 2.0012258092562356

Epoch: 6| Step: 1
Training loss: 0.2139579802751541
Validation loss: 2.029623568058014

Epoch: 6| Step: 2
Training loss: 0.32344651222229004
Validation loss: 2.043502708276113

Epoch: 6| Step: 3
Training loss: 0.19060105085372925
Validation loss: 2.0078890919685364

Epoch: 6| Step: 4
Training loss: 0.27404701709747314
Validation loss: 1.979375143845876

Epoch: 6| Step: 5
Training loss: 0.2341395616531372
Validation loss: 2.054094751675924

Epoch: 6| Step: 6
Training loss: 0.23337745666503906
Validation loss: 2.026770810286204

Epoch: 6| Step: 7
Training loss: 0.21242664754390717
Validation loss: 2.0261709888776145

Epoch: 6| Step: 8
Training loss: 0.32151204347610474
Validation loss: 2.041441023349762

Epoch: 6| Step: 9
Training loss: 0.18859006464481354
Validation loss: 2.032811681429545

Epoch: 6| Step: 10
Training loss: 0.35229983925819397
Validation loss: 2.0655516386032104

Epoch: 6| Step: 11
Training loss: 0.23843196034431458
Validation loss: 2.0347713232040405

Epoch: 6| Step: 12
Training loss: 0.42598778009414673
Validation loss: 2.0260462363560996

Epoch: 6| Step: 13
Training loss: 0.6015137434005737
Validation loss: 2.0615447759628296

Epoch: 333| Step: 0
Training loss: 0.15253129601478577
Validation loss: 2.062160611152649

Epoch: 6| Step: 1
Training loss: 0.36010557413101196
Validation loss: 2.0590943892796836

Epoch: 6| Step: 2
Training loss: 0.2525239586830139
Validation loss: 2.0907692909240723

Epoch: 6| Step: 3
Training loss: 0.3130064606666565
Validation loss: 2.0516060988108316

Epoch: 6| Step: 4
Training loss: 0.33739638328552246
Validation loss: 2.072398583094279

Epoch: 6| Step: 5
Training loss: 0.19326342642307281
Validation loss: 2.0625386238098145

Epoch: 6| Step: 6
Training loss: 0.295770525932312
Validation loss: 2.1044214169184365

Epoch: 6| Step: 7
Training loss: 0.2278464287519455
Validation loss: 2.0390055775642395

Epoch: 6| Step: 8
Training loss: 0.5534351468086243
Validation loss: 2.0325064063072205

Epoch: 6| Step: 9
Training loss: 0.36402371525764465
Validation loss: 2.0553585489590964

Epoch: 6| Step: 10
Training loss: 0.3456107974052429
Validation loss: 2.037323077519735

Epoch: 6| Step: 11
Training loss: 0.25467008352279663
Validation loss: 1.9903027812639873

Epoch: 6| Step: 12
Training loss: 0.4105161428451538
Validation loss: 2.0564615726470947

Epoch: 6| Step: 13
Training loss: 0.3185580372810364
Validation loss: 2.03902002175649

Epoch: 334| Step: 0
Training loss: 0.1877991259098053
Validation loss: 1.9820531407992046

Epoch: 6| Step: 1
Training loss: 0.18370693922042847
Validation loss: 2.0324596961339316

Epoch: 6| Step: 2
Training loss: 0.2203068733215332
Validation loss: 2.077169915040334

Epoch: 6| Step: 3
Training loss: 0.628326952457428
Validation loss: 2.0253532330195108

Epoch: 6| Step: 4
Training loss: 0.2801978290081024
Validation loss: 2.023360013961792

Epoch: 6| Step: 5
Training loss: 0.40977048873901367
Validation loss: 2.074850161870321

Epoch: 6| Step: 6
Training loss: 0.3349137008190155
Validation loss: 2.102217117945353

Epoch: 6| Step: 7
Training loss: 0.2352459579706192
Validation loss: 2.0532657305399575

Epoch: 6| Step: 8
Training loss: 0.2849522829055786
Validation loss: 2.045640150705973

Epoch: 6| Step: 9
Training loss: 0.22340409457683563
Validation loss: 2.0121123790740967

Epoch: 6| Step: 10
Training loss: 0.48263657093048096
Validation loss: 2.0286811192830405

Epoch: 6| Step: 11
Training loss: 0.263729989528656
Validation loss: 2.01803982257843

Epoch: 6| Step: 12
Training loss: 0.3133787214756012
Validation loss: 2.006850481033325

Epoch: 6| Step: 13
Training loss: 0.1534033715724945
Validation loss: 2.0149367650349936

Epoch: 335| Step: 0
Training loss: 0.25624215602874756
Validation loss: 1.9979350566864014

Epoch: 6| Step: 1
Training loss: 0.5891389846801758
Validation loss: 1.9956308404604595

Epoch: 6| Step: 2
Training loss: 0.3107271194458008
Validation loss: 2.0439053575197854

Epoch: 6| Step: 3
Training loss: 0.19521808624267578
Validation loss: 2.0308377146720886

Epoch: 6| Step: 4
Training loss: 0.1472395658493042
Validation loss: 2.054011086622874

Epoch: 6| Step: 5
Training loss: 0.28147220611572266
Validation loss: 2.0509853959083557

Epoch: 6| Step: 6
Training loss: 0.20843341946601868
Validation loss: 2.054577112197876

Epoch: 6| Step: 7
Training loss: 0.37457966804504395
Validation loss: 2.0486146410306296

Epoch: 6| Step: 8
Training loss: 0.43963882327079773
Validation loss: 2.0205384294191995

Epoch: 6| Step: 9
Training loss: 0.12166132777929306
Validation loss: 2.0491294066111245

Epoch: 6| Step: 10
Training loss: 0.23989759385585785
Validation loss: 1.9989168842633565

Epoch: 6| Step: 11
Training loss: 0.2158030867576599
Validation loss: 2.0804878870646157

Epoch: 6| Step: 12
Training loss: 0.2575107216835022
Validation loss: 2.0044953028361

Epoch: 6| Step: 13
Training loss: 0.2564547061920166
Validation loss: 2.029614726702372

Epoch: 336| Step: 0
Training loss: 0.31706929206848145
Validation loss: 2.061497926712036

Epoch: 6| Step: 1
Training loss: 0.3269738554954529
Validation loss: 1.9920937220255535

Epoch: 6| Step: 2
Training loss: 0.2587793171405792
Validation loss: 1.9820646444956462

Epoch: 6| Step: 3
Training loss: 0.16025125980377197
Validation loss: 2.0378834009170532

Epoch: 6| Step: 4
Training loss: 0.708955705165863
Validation loss: 2.0353977282842

Epoch: 6| Step: 5
Training loss: 0.39001035690307617
Validation loss: 2.008122464021047

Epoch: 6| Step: 6
Training loss: 0.18092133104801178
Validation loss: 2.0319607853889465

Epoch: 6| Step: 7
Training loss: 0.23581562936306
Validation loss: 2.008534332116445

Epoch: 6| Step: 8
Training loss: 0.16415539383888245
Validation loss: 2.028616468111674

Epoch: 6| Step: 9
Training loss: 0.20388884842395782
Validation loss: 2.0630056659380593

Epoch: 6| Step: 10
Training loss: 0.2758830785751343
Validation loss: 1.9807347456614177

Epoch: 6| Step: 11
Training loss: 0.1904805451631546
Validation loss: 2.011978507041931

Epoch: 6| Step: 12
Training loss: 0.2626323103904724
Validation loss: 2.0294225811958313

Epoch: 6| Step: 13
Training loss: 0.22722220420837402
Validation loss: 2.0214626789093018

Epoch: 337| Step: 0
Training loss: 0.20065473020076752
Validation loss: 2.046964645385742

Epoch: 6| Step: 1
Training loss: 0.3220061957836151
Validation loss: 1.9978424509366353

Epoch: 6| Step: 2
Training loss: 0.28944647312164307
Validation loss: 2.012112259864807

Epoch: 6| Step: 3
Training loss: 0.19517797231674194
Validation loss: 1.9758517344792683

Epoch: 6| Step: 4
Training loss: 0.23032666742801666
Validation loss: 2.0397930343945823

Epoch: 6| Step: 5
Training loss: 0.16268891096115112
Validation loss: 2.053053001562754

Epoch: 6| Step: 6
Training loss: 0.39321041107177734
Validation loss: 2.0381330847740173

Epoch: 6| Step: 7
Training loss: 0.6257145404815674
Validation loss: 2.0278973976771035

Epoch: 6| Step: 8
Training loss: 0.14860105514526367
Validation loss: 2.0231409867604575

Epoch: 6| Step: 9
Training loss: 0.39553216099739075
Validation loss: 1.9536363283793132

Epoch: 6| Step: 10
Training loss: 0.2435198724269867
Validation loss: 2.038165032863617

Epoch: 6| Step: 11
Training loss: 0.2754895091056824
Validation loss: 2.007731298605601

Epoch: 6| Step: 12
Training loss: 0.2773129642009735
Validation loss: 2.0105119943618774

Epoch: 6| Step: 13
Training loss: 0.3599652051925659
Validation loss: 2.0371882716814675

Epoch: 338| Step: 0
Training loss: 0.3305290937423706
Validation loss: 2.0271018346150718

Epoch: 6| Step: 1
Training loss: 0.2866131663322449
Validation loss: 2.048757274945577

Epoch: 6| Step: 2
Training loss: 0.3686370253562927
Validation loss: 2.0315328240394592

Epoch: 6| Step: 3
Training loss: 0.2679564654827118
Validation loss: 2.057097832361857

Epoch: 6| Step: 4
Training loss: 0.2182312309741974
Validation loss: 2.0400291879971824

Epoch: 6| Step: 5
Training loss: 0.6173227429389954
Validation loss: 2.028070350488027

Epoch: 6| Step: 6
Training loss: 0.2195243537425995
Validation loss: 2.03734689950943

Epoch: 6| Step: 7
Training loss: 0.19270533323287964
Validation loss: 2.006236433982849

Epoch: 6| Step: 8
Training loss: 0.3497680723667145
Validation loss: 2.009460429350535

Epoch: 6| Step: 9
Training loss: 0.23957709968090057
Validation loss: 2.0164202054341636

Epoch: 6| Step: 10
Training loss: 0.2382899820804596
Validation loss: 2.0080090363820395

Epoch: 6| Step: 11
Training loss: 0.25327879190444946
Validation loss: 2.047544697920481

Epoch: 6| Step: 12
Training loss: 0.37236154079437256
Validation loss: 2.021037538846334

Epoch: 6| Step: 13
Training loss: 0.24719169735908508
Validation loss: 2.037907361984253

Epoch: 339| Step: 0
Training loss: 0.25191181898117065
Validation loss: 2.0563791592915854

Epoch: 6| Step: 1
Training loss: 0.14450325071811676
Validation loss: 2.0084161957105002

Epoch: 6| Step: 2
Training loss: 0.33352792263031006
Validation loss: 2.0281237959861755

Epoch: 6| Step: 3
Training loss: 0.40520209074020386
Validation loss: 1.9958478013674419

Epoch: 6| Step: 4
Training loss: 0.22450491786003113
Validation loss: 2.038227399190267

Epoch: 6| Step: 5
Training loss: 0.15933027863502502
Validation loss: 2.0574797789255777

Epoch: 6| Step: 6
Training loss: 0.22837215662002563
Validation loss: 2.0221270322799683

Epoch: 6| Step: 7
Training loss: 0.19031517207622528
Validation loss: 2.022419552008311

Epoch: 6| Step: 8
Training loss: 0.1666577160358429
Validation loss: 2.0027016401290894

Epoch: 6| Step: 9
Training loss: 0.280987024307251
Validation loss: 2.0414961775143943

Epoch: 6| Step: 10
Training loss: 0.2753317356109619
Validation loss: 2.0364710291226706

Epoch: 6| Step: 11
Training loss: 0.328841894865036
Validation loss: 2.0770660837491355

Epoch: 6| Step: 12
Training loss: 0.3265173137187958
Validation loss: 2.046311616897583

Epoch: 6| Step: 13
Training loss: 0.6156840324401855
Validation loss: 1.9926298062006633

Epoch: 340| Step: 0
Training loss: 0.29770392179489136
Validation loss: 2.0647412141164145

Epoch: 6| Step: 1
Training loss: 0.3599950671195984
Validation loss: 2.051705022652944

Epoch: 6| Step: 2
Training loss: 0.45247143507003784
Validation loss: 2.0279489358266196

Epoch: 6| Step: 3
Training loss: 0.18262675404548645
Validation loss: 2.0278344551722207

Epoch: 6| Step: 4
Training loss: 0.2217358499765396
Validation loss: 2.03790549437205

Epoch: 6| Step: 5
Training loss: 0.3454864025115967
Validation loss: 2.0304739673932395

Epoch: 6| Step: 6
Training loss: 0.6349912881851196
Validation loss: 2.0370330611864724

Epoch: 6| Step: 7
Training loss: 0.37351661920547485
Validation loss: 2.0146055618921914

Epoch: 6| Step: 8
Training loss: 0.16884221136569977
Validation loss: 2.0092400312423706

Epoch: 6| Step: 9
Training loss: 0.20829154551029205
Validation loss: 1.986560881137848

Epoch: 6| Step: 10
Training loss: 0.17982926964759827
Validation loss: 1.985639750957489

Epoch: 6| Step: 11
Training loss: 0.17483985424041748
Validation loss: 2.015770216782888

Epoch: 6| Step: 12
Training loss: 0.42592087388038635
Validation loss: 2.0023807485898337

Epoch: 6| Step: 13
Training loss: 0.34039440751075745
Validation loss: 1.9922434290250142

Epoch: 341| Step: 0
Training loss: 0.26765695214271545
Validation loss: 2.02149091164271

Epoch: 6| Step: 1
Training loss: 0.26594609022140503
Validation loss: 2.0264179905255637

Epoch: 6| Step: 2
Training loss: 0.3516703248023987
Validation loss: 2.0403677423795066

Epoch: 6| Step: 3
Training loss: 0.3852686583995819
Validation loss: 2.043773829936981

Epoch: 6| Step: 4
Training loss: 0.33119308948516846
Validation loss: 2.0265254974365234

Epoch: 6| Step: 5
Training loss: 0.6591074466705322
Validation loss: 1.9917279283205669

Epoch: 6| Step: 6
Training loss: 0.3069232702255249
Validation loss: 2.0086230436960855

Epoch: 6| Step: 7
Training loss: 0.1717459261417389
Validation loss: 1.9790513515472412

Epoch: 6| Step: 8
Training loss: 0.46107733249664307
Validation loss: 1.969887653986613

Epoch: 6| Step: 9
Training loss: 0.2335655689239502
Validation loss: 1.9740943511327107

Epoch: 6| Step: 10
Training loss: 0.3405188322067261
Validation loss: 1.977619727452596

Epoch: 6| Step: 11
Training loss: 0.43224450945854187
Validation loss: 1.9885663588841755

Epoch: 6| Step: 12
Training loss: 0.18877765536308289
Validation loss: 1.978689928849538

Epoch: 6| Step: 13
Training loss: 0.36262252926826477
Validation loss: 1.999029020468394

Epoch: 342| Step: 0
Training loss: 0.20702308416366577
Validation loss: 1.9933032194773357

Epoch: 6| Step: 1
Training loss: 0.31962209939956665
Validation loss: 2.020087738831838

Epoch: 6| Step: 2
Training loss: 0.3413330316543579
Validation loss: 2.021267831325531

Epoch: 6| Step: 3
Training loss: 0.1821446716785431
Validation loss: 1.9980818629264832

Epoch: 6| Step: 4
Training loss: 0.33895713090896606
Validation loss: 2.0054685870806375

Epoch: 6| Step: 5
Training loss: 0.2193753868341446
Validation loss: 2.012300193309784

Epoch: 6| Step: 6
Training loss: 0.18847604095935822
Validation loss: 2.031932612260183

Epoch: 6| Step: 7
Training loss: 0.2348971962928772
Validation loss: 2.001089076201121

Epoch: 6| Step: 8
Training loss: 0.5516035556793213
Validation loss: 2.0563872853914895

Epoch: 6| Step: 9
Training loss: 0.1986115276813507
Validation loss: 2.028196414311727

Epoch: 6| Step: 10
Training loss: 0.16056585311889648
Validation loss: 2.0032909909884133

Epoch: 6| Step: 11
Training loss: 0.24583221971988678
Validation loss: 2.034045477708181

Epoch: 6| Step: 12
Training loss: 0.4889143109321594
Validation loss: 2.010034124056498

Epoch: 6| Step: 13
Training loss: 0.17630057036876678
Validation loss: 2.0112126072247825

Epoch: 343| Step: 0
Training loss: 0.2844555974006653
Validation loss: 2.0384118954340615

Epoch: 6| Step: 1
Training loss: 0.171338751912117
Validation loss: 2.0163846611976624

Epoch: 6| Step: 2
Training loss: 0.2366810142993927
Validation loss: 2.0420943101247153

Epoch: 6| Step: 3
Training loss: 0.3781448006629944
Validation loss: 2.0472065806388855

Epoch: 6| Step: 4
Training loss: 0.2410629838705063
Validation loss: 2.0314246813456216

Epoch: 6| Step: 5
Training loss: 0.13385459780693054
Validation loss: 2.0491944551467896

Epoch: 6| Step: 6
Training loss: 0.16755512356758118
Validation loss: 2.058426260948181

Epoch: 6| Step: 7
Training loss: 0.2615949511528015
Validation loss: 2.0065541664759317

Epoch: 6| Step: 8
Training loss: 0.3278462886810303
Validation loss: 2.023258686065674

Epoch: 6| Step: 9
Training loss: 0.36052218079566956
Validation loss: 2.010144074757894

Epoch: 6| Step: 10
Training loss: 0.23864233493804932
Validation loss: 2.020947754383087

Epoch: 6| Step: 11
Training loss: 0.27244406938552856
Validation loss: 2.0655369957288108

Epoch: 6| Step: 12
Training loss: 0.12898753583431244
Validation loss: 2.069119910399119

Epoch: 6| Step: 13
Training loss: 0.6237587928771973
Validation loss: 2.046635647614797

Epoch: 344| Step: 0
Training loss: 0.20791585743427277
Validation loss: 2.0137067437171936

Epoch: 6| Step: 1
Training loss: 0.20042341947555542
Validation loss: 2.0241302847862244

Epoch: 6| Step: 2
Training loss: 0.14930692315101624
Validation loss: 2.0121049880981445

Epoch: 6| Step: 3
Training loss: 0.28104284405708313
Validation loss: 2.063363711039225

Epoch: 6| Step: 4
Training loss: 0.1841285526752472
Validation loss: 2.045924166838328

Epoch: 6| Step: 5
Training loss: 0.2605941891670227
Validation loss: 2.0124441385269165

Epoch: 6| Step: 6
Training loss: 0.39664754271507263
Validation loss: 2.017059783140818

Epoch: 6| Step: 7
Training loss: 0.383257657289505
Validation loss: 2.0599552591641745

Epoch: 6| Step: 8
Training loss: 0.1988476663827896
Validation loss: 2.014360189437866

Epoch: 6| Step: 9
Training loss: 0.5288589000701904
Validation loss: 2.0519988934199014

Epoch: 6| Step: 10
Training loss: 0.3009963929653168
Validation loss: 1.9964628219604492

Epoch: 6| Step: 11
Training loss: 0.22957226634025574
Validation loss: 2.045358498891195

Epoch: 6| Step: 12
Training loss: 0.3116375505924225
Validation loss: 2.042560656865438

Epoch: 6| Step: 13
Training loss: 0.22832012176513672
Validation loss: 2.001064976056417

Epoch: 345| Step: 0
Training loss: 0.34733420610427856
Validation loss: 1.9799477656682332

Epoch: 6| Step: 1
Training loss: 0.20085853338241577
Validation loss: 2.0314414501190186

Epoch: 6| Step: 2
Training loss: 0.23511245846748352
Validation loss: 2.0478772123654685

Epoch: 6| Step: 3
Training loss: 0.14688032865524292
Validation loss: 2.0271916588147483

Epoch: 6| Step: 4
Training loss: 0.14648739993572235
Validation loss: 1.9986949563026428

Epoch: 6| Step: 5
Training loss: 0.31018781661987305
Validation loss: 2.0198115507761636

Epoch: 6| Step: 6
Training loss: 0.2554047107696533
Validation loss: 2.012195905049642

Epoch: 6| Step: 7
Training loss: 0.18287448585033417
Validation loss: 2.0225731134414673

Epoch: 6| Step: 8
Training loss: 0.2135794311761856
Validation loss: 2.018692413965861

Epoch: 6| Step: 9
Training loss: 0.15837928652763367
Validation loss: 2.0078657070795694

Epoch: 6| Step: 10
Training loss: 0.23292061686515808
Validation loss: 2.0184078017870584

Epoch: 6| Step: 11
Training loss: 0.38302966952323914
Validation loss: 2.028500815232595

Epoch: 6| Step: 12
Training loss: 0.30598577857017517
Validation loss: 1.9867255091667175

Epoch: 6| Step: 13
Training loss: 0.729092001914978
Validation loss: 2.016124943892161

Epoch: 346| Step: 0
Training loss: 0.2039550095796585
Validation loss: 2.0006951888402305

Epoch: 6| Step: 1
Training loss: 0.14704126119613647
Validation loss: 2.0270536740620932

Epoch: 6| Step: 2
Training loss: 0.7219079732894897
Validation loss: 2.0028746724128723

Epoch: 6| Step: 3
Training loss: 0.19970345497131348
Validation loss: 2.020216961701711

Epoch: 6| Step: 4
Training loss: 0.1962108612060547
Validation loss: 2.0229609608650208

Epoch: 6| Step: 5
Training loss: 0.28609776496887207
Validation loss: 1.9981519778569539

Epoch: 6| Step: 6
Training loss: 0.19219841063022614
Validation loss: 2.001203099886576

Epoch: 6| Step: 7
Training loss: 0.2055516391992569
Validation loss: 2.0327850381533303

Epoch: 6| Step: 8
Training loss: 0.23262950778007507
Validation loss: 2.0236449042956033

Epoch: 6| Step: 9
Training loss: 0.35236313939094543
Validation loss: 1.9798569083213806

Epoch: 6| Step: 10
Training loss: 0.17524993419647217
Validation loss: 1.9964566826820374

Epoch: 6| Step: 11
Training loss: 0.24461282789707184
Validation loss: 2.0453139543533325

Epoch: 6| Step: 12
Training loss: 0.36391371488571167
Validation loss: 1.9945259094238281

Epoch: 6| Step: 13
Training loss: 0.19988828897476196
Validation loss: 1.9996201395988464

Epoch: 347| Step: 0
Training loss: 0.14188720285892487
Validation loss: 1.991826355457306

Epoch: 6| Step: 1
Training loss: 0.22390437126159668
Validation loss: 1.9971826672554016

Epoch: 6| Step: 2
Training loss: 0.20487242937088013
Validation loss: 1.9996522665023804

Epoch: 6| Step: 3
Training loss: 0.29945361614227295
Validation loss: 1.9820814728736877

Epoch: 6| Step: 4
Training loss: 0.21441183984279633
Validation loss: 2.0139772097269693

Epoch: 6| Step: 5
Training loss: 0.2249172180891037
Validation loss: 2.002562483151754

Epoch: 6| Step: 6
Training loss: 0.15108482539653778
Validation loss: 2.006849388281504

Epoch: 6| Step: 7
Training loss: 0.2623077630996704
Validation loss: 2.0280051827430725

Epoch: 6| Step: 8
Training loss: 0.20403870940208435
Validation loss: 2.031280835469564

Epoch: 6| Step: 9
Training loss: 0.17591437697410583
Validation loss: 2.053012410799662

Epoch: 6| Step: 10
Training loss: 0.6544867753982544
Validation loss: 2.007622718811035

Epoch: 6| Step: 11
Training loss: 0.46006137132644653
Validation loss: 2.0443618496259055

Epoch: 6| Step: 12
Training loss: 0.17249420285224915
Validation loss: 2.058246910572052

Epoch: 6| Step: 13
Training loss: 0.3302519917488098
Validation loss: 2.0072356462478638

Epoch: 348| Step: 0
Training loss: 0.23086905479431152
Validation loss: 2.0142313043276467

Epoch: 6| Step: 1
Training loss: 0.2136782556772232
Validation loss: 1.9961957732836406

Epoch: 6| Step: 2
Training loss: 0.3138076663017273
Validation loss: 2.009396473566691

Epoch: 6| Step: 3
Training loss: 0.4742642343044281
Validation loss: 2.0021100441614785

Epoch: 6| Step: 4
Training loss: 0.27731287479400635
Validation loss: 2.019672671953837

Epoch: 6| Step: 5
Training loss: 0.270874559879303
Validation loss: 2.0575597683588662

Epoch: 6| Step: 6
Training loss: 0.20476415753364563
Validation loss: 2.018243451913198

Epoch: 6| Step: 7
Training loss: 0.5824232697486877
Validation loss: 2.0425833264986673

Epoch: 6| Step: 8
Training loss: 0.24424861371517181
Validation loss: 2.017046054204305

Epoch: 6| Step: 9
Training loss: 0.1941664218902588
Validation loss: 2.0236734747886658

Epoch: 6| Step: 10
Training loss: 0.25209638476371765
Validation loss: 1.9942545493443806

Epoch: 6| Step: 11
Training loss: 0.222198486328125
Validation loss: 2.0340431531270347

Epoch: 6| Step: 12
Training loss: 0.2589252293109894
Validation loss: 2.0321083267529807

Epoch: 6| Step: 13
Training loss: 0.2492474466562271
Validation loss: 2.023052434126536

Epoch: 349| Step: 0
Training loss: 0.18856219947338104
Validation loss: 2.045899232228597

Epoch: 6| Step: 1
Training loss: 0.16243210434913635
Validation loss: 2.0058496594429016

Epoch: 6| Step: 2
Training loss: 0.26643988490104675
Validation loss: 2.0187678933143616

Epoch: 6| Step: 3
Training loss: 0.1524590104818344
Validation loss: 2.0409005880355835

Epoch: 6| Step: 4
Training loss: 0.15712538361549377
Validation loss: 1.987366775671641

Epoch: 6| Step: 5
Training loss: 0.2816287577152252
Validation loss: 1.9934942722320557

Epoch: 6| Step: 6
Training loss: 0.24686557054519653
Validation loss: 1.9852363467216492

Epoch: 6| Step: 7
Training loss: 0.32671982049942017
Validation loss: 2.031594236691793

Epoch: 6| Step: 8
Training loss: 0.19619080424308777
Validation loss: 2.0327295859654746

Epoch: 6| Step: 9
Training loss: 0.42102110385894775
Validation loss: 2.0288952787717185

Epoch: 6| Step: 10
Training loss: 0.6050159335136414
Validation loss: 2.04431947072347

Epoch: 6| Step: 11
Training loss: 0.33229130506515503
Validation loss: 2.013193448384603

Epoch: 6| Step: 12
Training loss: 0.25817495584487915
Validation loss: 2.0019063552220664

Epoch: 6| Step: 13
Training loss: 0.19838987290859222
Validation loss: 2.00811767578125

Epoch: 350| Step: 0
Training loss: 0.1567818969488144
Validation loss: 1.9890562097231548

Epoch: 6| Step: 1
Training loss: 0.22517718374729156
Validation loss: 2.0192052920659385

Epoch: 6| Step: 2
Training loss: 0.33669084310531616
Validation loss: 2.014337718486786

Epoch: 6| Step: 3
Training loss: 0.37250953912734985
Validation loss: 2.0148231585820517

Epoch: 6| Step: 4
Training loss: 0.2404451221227646
Validation loss: 2.024012804031372

Epoch: 6| Step: 5
Training loss: 0.3945820927619934
Validation loss: 1.9935530026753743

Epoch: 6| Step: 6
Training loss: 0.18454991281032562
Validation loss: 1.9778083562850952

Epoch: 6| Step: 7
Training loss: 0.16920113563537598
Validation loss: 1.9647291700045268

Epoch: 6| Step: 8
Training loss: 0.39850175380706787
Validation loss: 2.0056421558062234

Epoch: 6| Step: 9
Training loss: 0.5571399927139282
Validation loss: 1.958568533261617

Epoch: 6| Step: 10
Training loss: 0.17163705825805664
Validation loss: 1.976045548915863

Epoch: 6| Step: 11
Training loss: 0.32776451110839844
Validation loss: 1.989263931910197

Epoch: 6| Step: 12
Training loss: 0.14363780617713928
Validation loss: 1.9911085764567058

Epoch: 6| Step: 13
Training loss: 0.2387102246284485
Validation loss: 1.9959132273991902

Epoch: 351| Step: 0
Training loss: 0.29913586378097534
Validation loss: 2.000140368938446

Epoch: 6| Step: 1
Training loss: 0.18896178901195526
Validation loss: 1.9893447160720825

Epoch: 6| Step: 2
Training loss: 0.15911856293678284
Validation loss: 2.0196104645729065

Epoch: 6| Step: 3
Training loss: 0.7516564130783081
Validation loss: 2.0195642709732056

Epoch: 6| Step: 4
Training loss: 0.4635061025619507
Validation loss: 2.0182261864344277

Epoch: 6| Step: 5
Training loss: 0.23600883781909943
Validation loss: 2.0206772486368814

Epoch: 6| Step: 6
Training loss: 0.21828560531139374
Validation loss: 2.011852045853933

Epoch: 6| Step: 7
Training loss: 0.20018506050109863
Validation loss: 2.0447842280069985

Epoch: 6| Step: 8
Training loss: 0.18323317170143127
Validation loss: 2.0194793343544006

Epoch: 6| Step: 9
Training loss: 0.2881263792514801
Validation loss: 2.04146009683609

Epoch: 6| Step: 10
Training loss: 0.28250548243522644
Validation loss: 2.040651818116506

Epoch: 6| Step: 11
Training loss: 0.21128007769584656
Validation loss: 2.0670113364855447

Epoch: 6| Step: 12
Training loss: 0.24026615917682648
Validation loss: 2.049241542816162

Epoch: 6| Step: 13
Training loss: 0.29089125990867615
Validation loss: 1.9938000043233235

Epoch: 352| Step: 0
Training loss: 0.2821713387966156
Validation loss: 2.025474488735199

Epoch: 6| Step: 1
Training loss: 0.3848643898963928
Validation loss: 2.0031256079673767

Epoch: 6| Step: 2
Training loss: 0.22835002839565277
Validation loss: 2.0197872320810952

Epoch: 6| Step: 3
Training loss: 0.4857221245765686
Validation loss: 2.034858008225759

Epoch: 6| Step: 4
Training loss: 0.13987410068511963
Validation loss: 2.0632632772127786

Epoch: 6| Step: 5
Training loss: 0.2514347434043884
Validation loss: 2.0373810132344565

Epoch: 6| Step: 6
Training loss: 0.24805957078933716
Validation loss: 2.031263609727224

Epoch: 6| Step: 7
Training loss: 0.2796642780303955
Validation loss: 2.0421946247418723

Epoch: 6| Step: 8
Training loss: 0.2681664526462555
Validation loss: 2.0235458612442017

Epoch: 6| Step: 9
Training loss: 0.19061502814292908
Validation loss: 2.0377705891927085

Epoch: 6| Step: 10
Training loss: 0.17106522619724274
Validation loss: 2.009336531162262

Epoch: 6| Step: 11
Training loss: 0.651542067527771
Validation loss: 2.0117717385292053

Epoch: 6| Step: 12
Training loss: 0.37062737345695496
Validation loss: 2.0199467142422995

Epoch: 6| Step: 13
Training loss: 0.3312467336654663
Validation loss: 2.0320176482200623

Epoch: 353| Step: 0
Training loss: 0.2889467477798462
Validation loss: 1.9588335951169331

Epoch: 6| Step: 1
Training loss: 0.18259119987487793
Validation loss: 1.9881357351938884

Epoch: 6| Step: 2
Training loss: 0.3015132248401642
Validation loss: 2.0034098426500955

Epoch: 6| Step: 3
Training loss: 0.27632424235343933
Validation loss: 1.964899480342865

Epoch: 6| Step: 4
Training loss: 0.25742822885513306
Validation loss: 2.0064054131507874

Epoch: 6| Step: 5
Training loss: 0.3141431212425232
Validation loss: 2.0067599018414817

Epoch: 6| Step: 6
Training loss: 0.38478145003318787
Validation loss: 2.0118651390075684

Epoch: 6| Step: 7
Training loss: 0.34850913286209106
Validation loss: 2.0145376125971475

Epoch: 6| Step: 8
Training loss: 0.22585521638393402
Validation loss: 2.039325257142385

Epoch: 6| Step: 9
Training loss: 0.6789509057998657
Validation loss: 2.010571599006653

Epoch: 6| Step: 10
Training loss: 0.25438106060028076
Validation loss: 1.963282585144043

Epoch: 6| Step: 11
Training loss: 0.18577426671981812
Validation loss: 1.9963339765866597

Epoch: 6| Step: 12
Training loss: 0.25378066301345825
Validation loss: 2.006809492905935

Epoch: 6| Step: 13
Training loss: 0.17007240653038025
Validation loss: 2.0301406383514404

Epoch: 354| Step: 0
Training loss: 0.2246972620487213
Validation loss: 2.004669427871704

Epoch: 6| Step: 1
Training loss: 0.2759280204772949
Validation loss: 2.026000459988912

Epoch: 6| Step: 2
Training loss: 0.22686335444450378
Validation loss: 2.0573604901631675

Epoch: 6| Step: 3
Training loss: 0.6180827617645264
Validation loss: 2.008474866549174

Epoch: 6| Step: 4
Training loss: 0.2532082200050354
Validation loss: 1.9937343001365662

Epoch: 6| Step: 5
Training loss: 0.45440566539764404
Validation loss: 2.013328234354655

Epoch: 6| Step: 6
Training loss: 0.2847566604614258
Validation loss: 2.0635483463605246

Epoch: 6| Step: 7
Training loss: 0.2146850824356079
Validation loss: 2.020840108394623

Epoch: 6| Step: 8
Training loss: 0.18915994465351105
Validation loss: 2.041476607322693

Epoch: 6| Step: 9
Training loss: 0.20373138785362244
Validation loss: 2.0304362376530967

Epoch: 6| Step: 10
Training loss: 0.23897182941436768
Validation loss: 2.069571097691854

Epoch: 6| Step: 11
Training loss: 0.2082921415567398
Validation loss: 2.012706478436788

Epoch: 6| Step: 12
Training loss: 0.3044334650039673
Validation loss: 1.999473472436269

Epoch: 6| Step: 13
Training loss: 0.2535642683506012
Validation loss: 2.0045692324638367

Epoch: 355| Step: 0
Training loss: 0.23942723870277405
Validation loss: 2.002251088619232

Epoch: 6| Step: 1
Training loss: 0.14591655135154724
Validation loss: 2.045495887597402

Epoch: 6| Step: 2
Training loss: 0.2190386950969696
Validation loss: 2.047833343346914

Epoch: 6| Step: 3
Training loss: 0.2062446027994156
Validation loss: 2.0099268158276877

Epoch: 6| Step: 4
Training loss: 0.2970361113548279
Validation loss: 1.9924648602803547

Epoch: 6| Step: 5
Training loss: 0.3318636417388916
Validation loss: 2.054636458555857

Epoch: 6| Step: 6
Training loss: 0.3608660399913788
Validation loss: 2.0098129908243814

Epoch: 6| Step: 7
Training loss: 0.5908719301223755
Validation loss: 1.9967535336812336

Epoch: 6| Step: 8
Training loss: 0.22253389656543732
Validation loss: 2.056660811106364

Epoch: 6| Step: 9
Training loss: 0.20348834991455078
Validation loss: 2.021787146727244

Epoch: 6| Step: 10
Training loss: 0.16536816954612732
Validation loss: 2.0377317070961

Epoch: 6| Step: 11
Training loss: 0.2431071251630783
Validation loss: 2.044484535853068

Epoch: 6| Step: 12
Training loss: 0.29481789469718933
Validation loss: 2.017618477344513

Epoch: 6| Step: 13
Training loss: 0.22081930935382843
Validation loss: 2.0264757672945657

Epoch: 356| Step: 0
Training loss: 0.28365084528923035
Validation loss: 2.0315762758255005

Epoch: 6| Step: 1
Training loss: 0.35023558139801025
Validation loss: 2.052691558996836

Epoch: 6| Step: 2
Training loss: 0.27639007568359375
Validation loss: 2.0235873659451804

Epoch: 6| Step: 3
Training loss: 0.2165176421403885
Validation loss: 2.0479141076405845

Epoch: 6| Step: 4
Training loss: 0.22407430410385132
Validation loss: 2.029773732026418

Epoch: 6| Step: 5
Training loss: 0.20902790129184723
Validation loss: 2.040337324142456

Epoch: 6| Step: 6
Training loss: 0.30556201934814453
Validation loss: 2.0523218313852944

Epoch: 6| Step: 7
Training loss: 0.23610375821590424
Validation loss: 2.0165440440177917

Epoch: 6| Step: 8
Training loss: 0.25614428520202637
Validation loss: 2.037039796511332

Epoch: 6| Step: 9
Training loss: 0.28817054629325867
Validation loss: 2.0424513816833496

Epoch: 6| Step: 10
Training loss: 0.361835777759552
Validation loss: 2.03853432337443

Epoch: 6| Step: 11
Training loss: 0.21281147003173828
Validation loss: 2.0446821252504983

Epoch: 6| Step: 12
Training loss: 0.6242303848266602
Validation loss: 2.0280693968137107

Epoch: 6| Step: 13
Training loss: 0.2768859267234802
Validation loss: 2.026662826538086

Epoch: 357| Step: 0
Training loss: 0.17958588898181915
Validation loss: 2.00096466143926

Epoch: 6| Step: 1
Training loss: 0.2974091172218323
Validation loss: 2.0151763955752053

Epoch: 6| Step: 2
Training loss: 0.20640353858470917
Validation loss: 1.9993443886439006

Epoch: 6| Step: 3
Training loss: 0.41167664527893066
Validation loss: 1.998755693435669

Epoch: 6| Step: 4
Training loss: 0.20918983221054077
Validation loss: 2.0281331141789756

Epoch: 6| Step: 5
Training loss: 0.20139263570308685
Validation loss: 2.015178143978119

Epoch: 6| Step: 6
Training loss: 0.2565199136734009
Validation loss: 1.9750113288561504

Epoch: 6| Step: 7
Training loss: 0.24758084118366241
Validation loss: 2.0205951730410256

Epoch: 6| Step: 8
Training loss: 0.5529804229736328
Validation loss: 2.0620743234952292

Epoch: 6| Step: 9
Training loss: 0.2948927879333496
Validation loss: 2.054058829943339

Epoch: 6| Step: 10
Training loss: 0.21132022142410278
Validation loss: 2.022567550341288

Epoch: 6| Step: 11
Training loss: 0.22530676424503326
Validation loss: 2.0259703596433005

Epoch: 6| Step: 12
Training loss: 0.23915039002895355
Validation loss: 2.0462045073509216

Epoch: 6| Step: 13
Training loss: 0.2900386452674866
Validation loss: 2.037646015485128

Epoch: 358| Step: 0
Training loss: 0.2514893114566803
Validation loss: 2.027551591396332

Epoch: 6| Step: 1
Training loss: 0.16306746006011963
Validation loss: 2.054058829943339

Epoch: 6| Step: 2
Training loss: 0.4179203510284424
Validation loss: 2.017466386159261

Epoch: 6| Step: 3
Training loss: 0.20936107635498047
Validation loss: 2.0384572943051658

Epoch: 6| Step: 4
Training loss: 0.15216517448425293
Validation loss: 2.0365235606829324

Epoch: 6| Step: 5
Training loss: 0.19326193630695343
Validation loss: 2.0400999585787454

Epoch: 6| Step: 6
Training loss: 0.13860386610031128
Validation loss: 2.029268483320872

Epoch: 6| Step: 7
Training loss: 0.23837773501873016
Validation loss: 2.06910240650177

Epoch: 6| Step: 8
Training loss: 0.3726396858692169
Validation loss: 2.0337689916292825

Epoch: 6| Step: 9
Training loss: 0.5262719988822937
Validation loss: 2.015095353126526

Epoch: 6| Step: 10
Training loss: 0.2438971996307373
Validation loss: 2.0127350091934204

Epoch: 6| Step: 11
Training loss: 0.2536759376525879
Validation loss: 2.053945084412893

Epoch: 6| Step: 12
Training loss: 0.32163354754447937
Validation loss: 2.0175039569536843

Epoch: 6| Step: 13
Training loss: 0.25968194007873535
Validation loss: 2.019867261250814

Epoch: 359| Step: 0
Training loss: 0.24540820717811584
Validation loss: 2.0222061475118003

Epoch: 6| Step: 1
Training loss: 0.17077484726905823
Validation loss: 2.0134639938672385

Epoch: 6| Step: 2
Training loss: 0.20297767221927643
Validation loss: 2.0017090241114297

Epoch: 6| Step: 3
Training loss: 0.32413938641548157
Validation loss: 2.0230990449587503

Epoch: 6| Step: 4
Training loss: 0.1858310103416443
Validation loss: 2.026638448238373

Epoch: 6| Step: 5
Training loss: 0.5741468071937561
Validation loss: 2.018382708231608

Epoch: 6| Step: 6
Training loss: 0.21065521240234375
Validation loss: 2.009516497453054

Epoch: 6| Step: 7
Training loss: 0.4817350506782532
Validation loss: 2.045535067717234

Epoch: 6| Step: 8
Training loss: 0.19713562726974487
Validation loss: 2.010949691136678

Epoch: 6| Step: 9
Training loss: 0.2444429248571396
Validation loss: 2.0285001595815024

Epoch: 6| Step: 10
Training loss: 0.21844442188739777
Validation loss: 2.0164488156636557

Epoch: 6| Step: 11
Training loss: 0.12773528695106506
Validation loss: 2.019688844680786

Epoch: 6| Step: 12
Training loss: 0.30897581577301025
Validation loss: 2.0212074319521585

Epoch: 6| Step: 13
Training loss: 0.21817710995674133
Validation loss: 2.011092702547709

Epoch: 360| Step: 0
Training loss: 0.25480836629867554
Validation loss: 2.0177139043807983

Epoch: 6| Step: 1
Training loss: 0.2406965047121048
Validation loss: 1.9900699456532795

Epoch: 6| Step: 2
Training loss: 0.29096364974975586
Validation loss: 1.9934047261873882

Epoch: 6| Step: 3
Training loss: 0.19526827335357666
Validation loss: 1.978366494178772

Epoch: 6| Step: 4
Training loss: 0.2914450764656067
Validation loss: 2.003272990385691

Epoch: 6| Step: 5
Training loss: 0.18918034434318542
Validation loss: 1.9957727988560994

Epoch: 6| Step: 6
Training loss: 0.19869878888130188
Validation loss: 1.9781676729520161

Epoch: 6| Step: 7
Training loss: 0.24373985826969147
Validation loss: 1.9990885456403096

Epoch: 6| Step: 8
Training loss: 0.3888884484767914
Validation loss: 1.9698072870572407

Epoch: 6| Step: 9
Training loss: 0.2712067663669586
Validation loss: 1.9926443497339885

Epoch: 6| Step: 10
Training loss: 0.22212859988212585
Validation loss: 1.9652164777119954

Epoch: 6| Step: 11
Training loss: 0.21324670314788818
Validation loss: 1.9703412055969238

Epoch: 6| Step: 12
Training loss: 0.5963693857192993
Validation loss: 2.0300654768943787

Epoch: 6| Step: 13
Training loss: 0.2417885661125183
Validation loss: 2.0264674623807273

Epoch: 361| Step: 0
Training loss: 0.17634715139865875
Validation loss: 1.992913047472636

Epoch: 6| Step: 1
Training loss: 0.17356553673744202
Validation loss: 2.0336703260739646

Epoch: 6| Step: 2
Training loss: 0.5361559987068176
Validation loss: 2.0027470191319785

Epoch: 6| Step: 3
Training loss: 0.24756401777267456
Validation loss: 2.0001969734827676

Epoch: 6| Step: 4
Training loss: 0.25531893968582153
Validation loss: 2.0019128918647766

Epoch: 6| Step: 5
Training loss: 0.21171967685222626
Validation loss: 2.0182922085126243

Epoch: 6| Step: 6
Training loss: 0.2919505536556244
Validation loss: 2.0206322272618613

Epoch: 6| Step: 7
Training loss: 0.22697101533412933
Validation loss: 2.0389147202173867

Epoch: 6| Step: 8
Training loss: 0.21575585007667542
Validation loss: 2.055388947327932

Epoch: 6| Step: 9
Training loss: 0.19668015837669373
Validation loss: 2.0213143626848855

Epoch: 6| Step: 10
Training loss: 0.21182864904403687
Validation loss: 2.040403147538503

Epoch: 6| Step: 11
Training loss: 0.34300172328948975
Validation loss: 2.027949869632721

Epoch: 6| Step: 12
Training loss: 0.20092304050922394
Validation loss: 2.0561541318893433

Epoch: 6| Step: 13
Training loss: 0.2908787727355957
Validation loss: 2.0709616343180337

Epoch: 362| Step: 0
Training loss: 0.35870835185050964
Validation loss: 2.0131283601125083

Epoch: 6| Step: 1
Training loss: 0.26528051495552063
Validation loss: 2.037354608376821

Epoch: 6| Step: 2
Training loss: 0.17663303017616272
Validation loss: 2.0543697675069175

Epoch: 6| Step: 3
Training loss: 0.56795334815979
Validation loss: 2.06032262245814

Epoch: 6| Step: 4
Training loss: 0.21352826058864594
Validation loss: 2.0483033458391824

Epoch: 6| Step: 5
Training loss: 0.36886537075042725
Validation loss: 2.08079202969869

Epoch: 6| Step: 6
Training loss: 0.31341105699539185
Validation loss: 2.0545260111490884

Epoch: 6| Step: 7
Training loss: 0.1843918263912201
Validation loss: 2.018680532773336

Epoch: 6| Step: 8
Training loss: 0.23729681968688965
Validation loss: 2.032891035079956

Epoch: 6| Step: 9
Training loss: 0.17243963479995728
Validation loss: 2.012964904308319

Epoch: 6| Step: 10
Training loss: 0.19600799679756165
Validation loss: 2.0038340091705322

Epoch: 6| Step: 11
Training loss: 0.2851903438568115
Validation loss: 1.9898179173469543

Epoch: 6| Step: 12
Training loss: 0.28196990489959717
Validation loss: 1.993150254090627

Epoch: 6| Step: 13
Training loss: 0.25320225954055786
Validation loss: 1.9874614079793294

Epoch: 363| Step: 0
Training loss: 0.20971046388149261
Validation loss: 2.0226291616757712

Epoch: 6| Step: 1
Training loss: 0.21297648549079895
Validation loss: 1.9702725013097127

Epoch: 6| Step: 2
Training loss: 0.32063010334968567
Validation loss: 1.9612270991007488

Epoch: 6| Step: 3
Training loss: 0.18741554021835327
Validation loss: 2.0480748216311135

Epoch: 6| Step: 4
Training loss: 0.25262969732284546
Validation loss: 2.0252276062965393

Epoch: 6| Step: 5
Training loss: 0.1826498657464981
Validation loss: 2.047074278195699

Epoch: 6| Step: 6
Training loss: 0.14322598278522491
Validation loss: 2.036001225312551

Epoch: 6| Step: 7
Training loss: 0.3220003843307495
Validation loss: 2.0034033258756003

Epoch: 6| Step: 8
Training loss: 0.7130960822105408
Validation loss: 2.030069629351298

Epoch: 6| Step: 9
Training loss: 0.24621087312698364
Validation loss: 2.0180057088534036

Epoch: 6| Step: 10
Training loss: 0.21012303233146667
Validation loss: 2.024212201436361

Epoch: 6| Step: 11
Training loss: 0.29823726415634155
Validation loss: 2.01418008406957

Epoch: 6| Step: 12
Training loss: 0.20905661582946777
Validation loss: 1.9707363843917847

Epoch: 6| Step: 13
Training loss: 0.14746689796447754
Validation loss: 1.9865590333938599

Epoch: 364| Step: 0
Training loss: 0.18332383036613464
Validation loss: 2.01096647977829

Epoch: 6| Step: 1
Training loss: 0.2784866690635681
Validation loss: 2.0042564868927

Epoch: 6| Step: 2
Training loss: 0.15749554336071014
Validation loss: 2.0162841081619263

Epoch: 6| Step: 3
Training loss: 0.2693679928779602
Validation loss: 2.0293966929117837

Epoch: 6| Step: 4
Training loss: 0.22519713640213013
Validation loss: 1.996412714322408

Epoch: 6| Step: 5
Training loss: 0.1566600799560547
Validation loss: 1.9868990182876587

Epoch: 6| Step: 6
Training loss: 0.17950193583965302
Validation loss: 2.01042511065801

Epoch: 6| Step: 7
Training loss: 0.20724473893642426
Validation loss: 2.0325926343599954

Epoch: 6| Step: 8
Training loss: 0.22871747612953186
Validation loss: 2.035238961378733

Epoch: 6| Step: 9
Training loss: 0.35754042863845825
Validation loss: 1.9853224158287048

Epoch: 6| Step: 10
Training loss: 0.4163030982017517
Validation loss: 2.0023242831230164

Epoch: 6| Step: 11
Training loss: 0.19527478516101837
Validation loss: 2.022430698076884

Epoch: 6| Step: 12
Training loss: 0.5880560874938965
Validation loss: 2.000127693017324

Epoch: 6| Step: 13
Training loss: 0.20565596222877502
Validation loss: 1.9970992803573608

Epoch: 365| Step: 0
Training loss: 0.21221379935741425
Validation loss: 1.9941051204999287

Epoch: 6| Step: 1
Training loss: 0.292208731174469
Validation loss: 2.03975502649943

Epoch: 6| Step: 2
Training loss: 0.2353842854499817
Validation loss: 2.016043702761332

Epoch: 6| Step: 3
Training loss: 0.19822126626968384
Validation loss: 2.0314378341039023

Epoch: 6| Step: 4
Training loss: 0.39477136731147766
Validation loss: 2.013510803381602

Epoch: 6| Step: 5
Training loss: 0.21488074958324432
Validation loss: 1.9941258827845256

Epoch: 6| Step: 6
Training loss: 0.58257657289505
Validation loss: 2.0026671290397644

Epoch: 6| Step: 7
Training loss: 0.3951854705810547
Validation loss: 2.002184212207794

Epoch: 6| Step: 8
Training loss: 0.31016674637794495
Validation loss: 1.9884077707926433

Epoch: 6| Step: 9
Training loss: 0.20531463623046875
Validation loss: 1.9923804799715679

Epoch: 6| Step: 10
Training loss: 0.300062358379364
Validation loss: 2.0239986777305603

Epoch: 6| Step: 11
Training loss: 0.18757140636444092
Validation loss: 2.0540398359298706

Epoch: 6| Step: 12
Training loss: 0.2734837830066681
Validation loss: 2.017755627632141

Epoch: 6| Step: 13
Training loss: 0.16303911805152893
Validation loss: 2.010847548643748

Epoch: 366| Step: 0
Training loss: 0.2314705103635788
Validation loss: 2.019345978895823

Epoch: 6| Step: 1
Training loss: 0.2964783310890198
Validation loss: 2.0122249523798623

Epoch: 6| Step: 2
Training loss: 0.22826334834098816
Validation loss: 2.0408514738082886

Epoch: 6| Step: 3
Training loss: 0.2018919289112091
Validation loss: 2.0186938643455505

Epoch: 6| Step: 4
Training loss: 0.18675419688224792
Validation loss: 2.0683938463528952

Epoch: 6| Step: 5
Training loss: 0.38305896520614624
Validation loss: 2.048639237880707

Epoch: 6| Step: 6
Training loss: 0.553213357925415
Validation loss: 2.0382623275121055

Epoch: 6| Step: 7
Training loss: 0.16791081428527832
Validation loss: 2.0327672759691873

Epoch: 6| Step: 8
Training loss: 0.23052939772605896
Validation loss: 2.047879159450531

Epoch: 6| Step: 9
Training loss: 0.33653023838996887
Validation loss: 2.013050079345703

Epoch: 6| Step: 10
Training loss: 0.2809668183326721
Validation loss: 2.0468904972076416

Epoch: 6| Step: 11
Training loss: 0.20509886741638184
Validation loss: 2.0161680380503335

Epoch: 6| Step: 12
Training loss: 0.2728312015533447
Validation loss: 2.03578652938207

Epoch: 6| Step: 13
Training loss: 0.33857327699661255
Validation loss: 2.017447213331858

Epoch: 367| Step: 0
Training loss: 0.278106153011322
Validation loss: 2.019589066505432

Epoch: 6| Step: 1
Training loss: 0.6645523309707642
Validation loss: 2.0031661987304688

Epoch: 6| Step: 2
Training loss: 0.15106068551540375
Validation loss: 1.990434189637502

Epoch: 6| Step: 3
Training loss: 0.17750674486160278
Validation loss: 2.0177631775538125

Epoch: 6| Step: 4
Training loss: 0.3550347089767456
Validation loss: 2.0072671373685202

Epoch: 6| Step: 5
Training loss: 0.21423742175102234
Validation loss: 2.010323405265808

Epoch: 6| Step: 6
Training loss: 0.3500458598136902
Validation loss: 2.0279051860173545

Epoch: 6| Step: 7
Training loss: 0.1415759027004242
Validation loss: 2.008078475793203

Epoch: 6| Step: 8
Training loss: 0.22395555675029755
Validation loss: 1.9893616437911987

Epoch: 6| Step: 9
Training loss: 0.20802797377109528
Validation loss: 2.0066718061765036

Epoch: 6| Step: 10
Training loss: 0.21064968407154083
Validation loss: 2.007318456967672

Epoch: 6| Step: 11
Training loss: 0.14476868510246277
Validation loss: 2.0151142875353494

Epoch: 6| Step: 12
Training loss: 0.34068185091018677
Validation loss: 2.0259222189585366

Epoch: 6| Step: 13
Training loss: 0.23851265013217926
Validation loss: 2.0126805504163108

Epoch: 368| Step: 0
Training loss: 0.195081889629364
Validation loss: 2.036607285340627

Epoch: 6| Step: 1
Training loss: 0.19278216361999512
Validation loss: 2.0018564263979592

Epoch: 6| Step: 2
Training loss: 0.6284299492835999
Validation loss: 2.007406214872996

Epoch: 6| Step: 3
Training loss: 0.37073802947998047
Validation loss: 2.0534824331601462

Epoch: 6| Step: 4
Training loss: 0.25263267755508423
Validation loss: 1.9980566501617432

Epoch: 6| Step: 5
Training loss: 0.266236811876297
Validation loss: 2.0338993072509766

Epoch: 6| Step: 6
Training loss: 0.24146483838558197
Validation loss: 1.99344797929128

Epoch: 6| Step: 7
Training loss: 0.2749451994895935
Validation loss: 1.9820089141527812

Epoch: 6| Step: 8
Training loss: 0.18487805128097534
Validation loss: 2.032872279485067

Epoch: 6| Step: 9
Training loss: 0.30241888761520386
Validation loss: 2.030176838239034

Epoch: 6| Step: 10
Training loss: 0.3919888734817505
Validation loss: 2.0522549152374268

Epoch: 6| Step: 11
Training loss: 0.22753646969795227
Validation loss: 2.0423930883407593

Epoch: 6| Step: 12
Training loss: 0.20522049069404602
Validation loss: 2.004617154598236

Epoch: 6| Step: 13
Training loss: 0.28581613302230835
Validation loss: 2.011788547039032

Epoch: 369| Step: 0
Training loss: 0.1399419605731964
Validation loss: 2.0324430068333945

Epoch: 6| Step: 1
Training loss: 0.2089877426624298
Validation loss: 2.03792272011439

Epoch: 6| Step: 2
Training loss: 0.44954678416252136
Validation loss: 2.025612771511078

Epoch: 6| Step: 3
Training loss: 0.19152577221393585
Validation loss: 2.034431755542755

Epoch: 6| Step: 4
Training loss: 0.30770304799079895
Validation loss: 2.008489191532135

Epoch: 6| Step: 5
Training loss: 0.21982210874557495
Validation loss: 2.0114765961964927

Epoch: 6| Step: 6
Training loss: 0.18299414217472076
Validation loss: 2.016975541909536

Epoch: 6| Step: 7
Training loss: 0.15499255061149597
Validation loss: 1.9752109050750732

Epoch: 6| Step: 8
Training loss: 0.30398237705230713
Validation loss: 2.019488592942556

Epoch: 6| Step: 9
Training loss: 0.6261154413223267
Validation loss: 2.02112344900767

Epoch: 6| Step: 10
Training loss: 0.22302089631557465
Validation loss: 2.0193238059679666

Epoch: 6| Step: 11
Training loss: 0.23045924305915833
Validation loss: 2.0092859466870627

Epoch: 6| Step: 12
Training loss: 0.1849120855331421
Validation loss: 2.006014962991079

Epoch: 6| Step: 13
Training loss: 0.13463199138641357
Validation loss: 2.011741360028585

Epoch: 370| Step: 0
Training loss: 0.5490862727165222
Validation loss: 1.9751657843589783

Epoch: 6| Step: 1
Training loss: 0.20562037825584412
Validation loss: 2.0052043398221335

Epoch: 6| Step: 2
Training loss: 0.18808194994926453
Validation loss: 2.011125087738037

Epoch: 6| Step: 3
Training loss: 0.3248896598815918
Validation loss: 1.9965741038322449

Epoch: 6| Step: 4
Training loss: 0.2117469757795334
Validation loss: 2.02628755569458

Epoch: 6| Step: 5
Training loss: 0.2511618733406067
Validation loss: 2.016885062058767

Epoch: 6| Step: 6
Training loss: 0.11212065815925598
Validation loss: 1.9921531478563945

Epoch: 6| Step: 7
Training loss: 0.25698378682136536
Validation loss: 2.009366512298584

Epoch: 6| Step: 8
Training loss: 0.1545363813638687
Validation loss: 2.016998906930288

Epoch: 6| Step: 9
Training loss: 0.20976875722408295
Validation loss: 2.020483454068502

Epoch: 6| Step: 10
Training loss: 0.2896711528301239
Validation loss: 1.9887554446856182

Epoch: 6| Step: 11
Training loss: 0.14527206122875214
Validation loss: 1.9947802623112996

Epoch: 6| Step: 12
Training loss: 0.2870194911956787
Validation loss: 1.9934299786885579

Epoch: 6| Step: 13
Training loss: 0.3504880368709564
Validation loss: 2.034968912601471

Epoch: 371| Step: 0
Training loss: 0.29297009110450745
Validation loss: 2.017942746480306

Epoch: 6| Step: 1
Training loss: 0.20139369368553162
Validation loss: 2.0367133220036826

Epoch: 6| Step: 2
Training loss: 0.21692515909671783
Validation loss: 2.0526411135991416

Epoch: 6| Step: 3
Training loss: 0.33112582564353943
Validation loss: 2.033560593922933

Epoch: 6| Step: 4
Training loss: 0.37440577149391174
Validation loss: 2.0453007419904075

Epoch: 6| Step: 5
Training loss: 0.2993971109390259
Validation loss: 2.0205145676930747

Epoch: 6| Step: 6
Training loss: 0.18072888255119324
Validation loss: 2.0324790875116983

Epoch: 6| Step: 7
Training loss: 0.34115806221961975
Validation loss: 2.0162197748819985

Epoch: 6| Step: 8
Training loss: 0.2472151517868042
Validation loss: 2.0169561306635537

Epoch: 6| Step: 9
Training loss: 0.49981433153152466
Validation loss: 1.999867061773936

Epoch: 6| Step: 10
Training loss: 0.18641726672649384
Validation loss: 2.0128024021784463

Epoch: 6| Step: 11
Training loss: 0.2415790855884552
Validation loss: 2.029552976290385

Epoch: 6| Step: 12
Training loss: 0.21728691458702087
Validation loss: 2.0388174057006836

Epoch: 6| Step: 13
Training loss: 0.17188602685928345
Validation loss: 2.021258592605591

Epoch: 372| Step: 0
Training loss: 0.2863304316997528
Validation loss: 2.021395186583201

Epoch: 6| Step: 1
Training loss: 0.166302889585495
Validation loss: 2.0194495916366577

Epoch: 6| Step: 2
Training loss: 0.20990726351737976
Validation loss: 1.9829294085502625

Epoch: 6| Step: 3
Training loss: 0.1479262262582779
Validation loss: 1.9998234709103901

Epoch: 6| Step: 4
Training loss: 0.17749306559562683
Validation loss: 2.0333270827929177

Epoch: 6| Step: 5
Training loss: 0.25013023614883423
Validation loss: 2.014711558818817

Epoch: 6| Step: 6
Training loss: 0.1968936175107956
Validation loss: 2.029065469900767

Epoch: 6| Step: 7
Training loss: 0.3068195581436157
Validation loss: 1.980948527654012

Epoch: 6| Step: 8
Training loss: 0.1630231738090515
Validation loss: 2.011545260747274

Epoch: 6| Step: 9
Training loss: 0.17252510786056519
Validation loss: 1.9949322740236919

Epoch: 6| Step: 10
Training loss: 0.4976001977920532
Validation loss: 2.051569481690725

Epoch: 6| Step: 11
Training loss: 0.18504440784454346
Validation loss: 1.9993532101313274

Epoch: 6| Step: 12
Training loss: 0.16801699995994568
Validation loss: 2.0367826024691262

Epoch: 6| Step: 13
Training loss: 0.5048162341117859
Validation loss: 1.9850100477536519

Epoch: 373| Step: 0
Training loss: 0.21413089334964752
Validation loss: 2.0080264608065286

Epoch: 6| Step: 1
Training loss: 0.20008090138435364
Validation loss: 1.9959400693575542

Epoch: 6| Step: 2
Training loss: 0.29384565353393555
Validation loss: 2.00509520371755

Epoch: 6| Step: 3
Training loss: 0.47301632165908813
Validation loss: 2.0323695143063865

Epoch: 6| Step: 4
Training loss: 0.31714537739753723
Validation loss: 2.0141438146432242

Epoch: 6| Step: 5
Training loss: 0.27311572432518005
Validation loss: 2.016493499279022

Epoch: 6| Step: 6
Training loss: 0.3454192280769348
Validation loss: 2.0480056206385293

Epoch: 6| Step: 7
Training loss: 0.2144612818956375
Validation loss: 2.0044336318969727

Epoch: 6| Step: 8
Training loss: 0.20892617106437683
Validation loss: 2.012385686238607

Epoch: 6| Step: 9
Training loss: 0.8499733209609985
Validation loss: 2.0167287786801658

Epoch: 6| Step: 10
Training loss: 0.14497648179531097
Validation loss: 2.049470901489258

Epoch: 6| Step: 11
Training loss: 0.43060269951820374
Validation loss: 2.0165226459503174

Epoch: 6| Step: 12
Training loss: 0.29732105135917664
Validation loss: 2.028443694114685

Epoch: 6| Step: 13
Training loss: 0.14704197645187378
Validation loss: 2.02070560057958

Epoch: 374| Step: 0
Training loss: 0.28030842542648315
Validation loss: 2.014013648033142

Epoch: 6| Step: 1
Training loss: 0.24009397625923157
Validation loss: 2.019735892613729

Epoch: 6| Step: 2
Training loss: 0.3129674196243286
Validation loss: 2.0371330976486206

Epoch: 6| Step: 3
Training loss: 0.20979313552379608
Validation loss: 2.008677581946055

Epoch: 6| Step: 4
Training loss: 0.20333746075630188
Validation loss: 2.0312005480130515

Epoch: 6| Step: 5
Training loss: 0.2555879056453705
Validation loss: 2.0339887936909995

Epoch: 6| Step: 6
Training loss: 0.23648646473884583
Validation loss: 2.0279733339945474

Epoch: 6| Step: 7
Training loss: 0.5472868084907532
Validation loss: 2.0093321005503335

Epoch: 6| Step: 8
Training loss: 0.22973018884658813
Validation loss: 2.0281265576680503

Epoch: 6| Step: 9
Training loss: 0.1844298243522644
Validation loss: 2.0629833539326987

Epoch: 6| Step: 10
Training loss: 0.27048981189727783
Validation loss: 2.0436507066090903

Epoch: 6| Step: 11
Training loss: 0.3287973701953888
Validation loss: 1.9952499469121296

Epoch: 6| Step: 12
Training loss: 0.19837409257888794
Validation loss: 1.9878012537956238

Epoch: 6| Step: 13
Training loss: 0.30556702613830566
Validation loss: 2.0295926332473755

Epoch: 375| Step: 0
Training loss: 0.16243118047714233
Validation loss: 2.0351725220680237

Epoch: 6| Step: 1
Training loss: 0.19931285083293915
Validation loss: 2.011539399623871

Epoch: 6| Step: 2
Training loss: 0.30279970169067383
Validation loss: 2.0435732007026672

Epoch: 6| Step: 3
Training loss: 0.16910392045974731
Validation loss: 2.033140162626902

Epoch: 6| Step: 4
Training loss: 0.2663651704788208
Validation loss: 2.032795508702596

Epoch: 6| Step: 5
Training loss: 0.2963756322860718
Validation loss: 2.0290340383847556

Epoch: 6| Step: 6
Training loss: 0.13788175582885742
Validation loss: 2.0452826619148254

Epoch: 6| Step: 7
Training loss: 0.17706875503063202
Validation loss: 1.954429527123769

Epoch: 6| Step: 8
Training loss: 0.2971280813217163
Validation loss: 2.001918454964956

Epoch: 6| Step: 9
Training loss: 0.21268177032470703
Validation loss: 2.0271787643432617

Epoch: 6| Step: 10
Training loss: 0.23359207808971405
Validation loss: 2.0232559045155845

Epoch: 6| Step: 11
Training loss: 0.39303767681121826
Validation loss: 2.041208585103353

Epoch: 6| Step: 12
Training loss: 0.273193895816803
Validation loss: 2.037114600340525

Epoch: 6| Step: 13
Training loss: 0.5619753003120422
Validation loss: 2.035795013109843

Epoch: 376| Step: 0
Training loss: 0.23315462470054626
Validation loss: 2.043527285257975

Epoch: 6| Step: 1
Training loss: 0.1940118372440338
Validation loss: 2.0049606959025064

Epoch: 6| Step: 2
Training loss: 0.5424413084983826
Validation loss: 2.057652731736501

Epoch: 6| Step: 3
Training loss: 0.30892443656921387
Validation loss: 2.0584560434023538

Epoch: 6| Step: 4
Training loss: 0.3322719931602478
Validation loss: 2.0256640513738

Epoch: 6| Step: 5
Training loss: 0.2099461555480957
Validation loss: 2.0797805388768515

Epoch: 6| Step: 6
Training loss: 0.14791157841682434
Validation loss: 2.029948631922404

Epoch: 6| Step: 7
Training loss: 0.22202330827713013
Validation loss: 2.0392807920773826

Epoch: 6| Step: 8
Training loss: 0.17600198090076447
Validation loss: 2.0331684748331704

Epoch: 6| Step: 9
Training loss: 0.34476688504219055
Validation loss: 2.0726306637128196

Epoch: 6| Step: 10
Training loss: 0.23899438977241516
Validation loss: 2.050043821334839

Epoch: 6| Step: 11
Training loss: 0.18362203240394592
Validation loss: 2.021519104639689

Epoch: 6| Step: 12
Training loss: 0.23743976652622223
Validation loss: 2.0813252925872803

Epoch: 6| Step: 13
Training loss: 0.241463303565979
Validation loss: 2.0493818322817483

Epoch: 377| Step: 0
Training loss: 0.25440484285354614
Validation loss: 2.043895641962687

Epoch: 6| Step: 1
Training loss: 0.2759753465652466
Validation loss: 2.038640777269999

Epoch: 6| Step: 2
Training loss: 0.5580593347549438
Validation loss: 2.0764837662378945

Epoch: 6| Step: 3
Training loss: 0.14504534006118774
Validation loss: 2.0265445907910666

Epoch: 6| Step: 4
Training loss: 0.23607441782951355
Validation loss: 2.051620662212372

Epoch: 6| Step: 5
Training loss: 0.11710117757320404
Validation loss: 2.0142612854639688

Epoch: 6| Step: 6
Training loss: 0.2329685389995575
Validation loss: 2.0212758580843606

Epoch: 6| Step: 7
Training loss: 0.2554272413253784
Validation loss: 2.0352502862612405

Epoch: 6| Step: 8
Training loss: 0.30930840969085693
Validation loss: 1.9948606689771016

Epoch: 6| Step: 9
Training loss: 0.30680370330810547
Validation loss: 2.0205180048942566

Epoch: 6| Step: 10
Training loss: 0.18747471272945404
Validation loss: 2.0378998517990112

Epoch: 6| Step: 11
Training loss: 0.26894769072532654
Validation loss: 2.0229607621828714

Epoch: 6| Step: 12
Training loss: 0.18594570457935333
Validation loss: 2.020737628142039

Epoch: 6| Step: 13
Training loss: 0.11156892776489258
Validation loss: 2.0339503288269043

Epoch: 378| Step: 0
Training loss: 0.16733060777187347
Validation loss: 2.0029428402582803

Epoch: 6| Step: 1
Training loss: 0.26853227615356445
Validation loss: 2.0273554722468057

Epoch: 6| Step: 2
Training loss: 0.26624593138694763
Validation loss: 2.00904111067454

Epoch: 6| Step: 3
Training loss: 0.2926660478115082
Validation loss: 2.0451625982920327

Epoch: 6| Step: 4
Training loss: 0.2519396245479584
Validation loss: 1.9936530590057373

Epoch: 6| Step: 5
Training loss: 0.1916571855545044
Validation loss: 1.9910040299097698

Epoch: 6| Step: 6
Training loss: 0.1996488720178604
Validation loss: 2.0287499825159707

Epoch: 6| Step: 7
Training loss: 0.2286379337310791
Validation loss: 2.0100051363309226

Epoch: 6| Step: 8
Training loss: 0.3997032046318054
Validation loss: 2.0414021809895835

Epoch: 6| Step: 9
Training loss: 0.2248375415802002
Validation loss: 2.023894945780436

Epoch: 6| Step: 10
Training loss: 0.18160566687583923
Validation loss: 2.045699497063955

Epoch: 6| Step: 11
Training loss: 0.6343623995780945
Validation loss: 2.011176427205404

Epoch: 6| Step: 12
Training loss: 0.26022669672966003
Validation loss: 2.024221122264862

Epoch: 6| Step: 13
Training loss: 0.13392387330532074
Validation loss: 2.0184364716211953

Epoch: 379| Step: 0
Training loss: 0.2059810906648636
Validation loss: 2.0349507530530295

Epoch: 6| Step: 1
Training loss: 0.1440214216709137
Validation loss: 2.0308373967806497

Epoch: 6| Step: 2
Training loss: 0.18676236271858215
Validation loss: 2.042084793249766

Epoch: 6| Step: 3
Training loss: 0.436002254486084
Validation loss: 2.024685482184092

Epoch: 6| Step: 4
Training loss: 0.1889617145061493
Validation loss: 2.0367061297098794

Epoch: 6| Step: 5
Training loss: 0.3076201379299164
Validation loss: 2.025318702061971

Epoch: 6| Step: 6
Training loss: 0.2638936936855316
Validation loss: 2.034576177597046

Epoch: 6| Step: 7
Training loss: 0.22867068648338318
Validation loss: 2.0153366923332214

Epoch: 6| Step: 8
Training loss: 0.3415086269378662
Validation loss: 2.0749041636784873

Epoch: 6| Step: 9
Training loss: 0.24789470434188843
Validation loss: 2.0203521251678467

Epoch: 6| Step: 10
Training loss: 0.592333197593689
Validation loss: 1.9777595400810242

Epoch: 6| Step: 11
Training loss: 0.17192861437797546
Validation loss: 2.007726808389028

Epoch: 6| Step: 12
Training loss: 0.20810070633888245
Validation loss: 2.0187286337216697

Epoch: 6| Step: 13
Training loss: 0.26534003019332886
Validation loss: 2.017890433470408

Epoch: 380| Step: 0
Training loss: 0.2649227976799011
Validation loss: 1.9897704323132832

Epoch: 6| Step: 1
Training loss: 0.294305682182312
Validation loss: 1.9490492542584736

Epoch: 6| Step: 2
Training loss: 0.2332184612751007
Validation loss: 1.9800452788670857

Epoch: 6| Step: 3
Training loss: 0.23129181563854218
Validation loss: 1.9916164875030518

Epoch: 6| Step: 4
Training loss: 0.2110629677772522
Validation loss: 2.0302119851112366

Epoch: 6| Step: 5
Training loss: 0.1966482251882553
Validation loss: 1.9633708000183105

Epoch: 6| Step: 6
Training loss: 0.35699009895324707
Validation loss: 2.0103026032447815

Epoch: 6| Step: 7
Training loss: 0.16963639855384827
Validation loss: 1.997140109539032

Epoch: 6| Step: 8
Training loss: 0.1439892053604126
Validation loss: 2.0159830848375955

Epoch: 6| Step: 9
Training loss: 0.1627204865217209
Validation loss: 2.0249063769976297

Epoch: 6| Step: 10
Training loss: 0.5586730241775513
Validation loss: 2.0061067938804626

Epoch: 6| Step: 11
Training loss: 0.199988454580307
Validation loss: 2.021468242009481

Epoch: 6| Step: 12
Training loss: 0.2908474802970886
Validation loss: 2.0138758619626365

Epoch: 6| Step: 13
Training loss: 0.15950746834278107
Validation loss: 2.0180736978848777

Epoch: 381| Step: 0
Training loss: 0.3235188126564026
Validation loss: 1.9836418231328328

Epoch: 6| Step: 1
Training loss: 0.34540003538131714
Validation loss: 2.0339025457700095

Epoch: 6| Step: 2
Training loss: 0.16482749581336975
Validation loss: 2.0024070739746094

Epoch: 6| Step: 3
Training loss: 0.291561484336853
Validation loss: 1.990721881389618

Epoch: 6| Step: 4
Training loss: 0.19839468598365784
Validation loss: 2.053200423717499

Epoch: 6| Step: 5
Training loss: 0.23942235112190247
Validation loss: 2.0353514353434243

Epoch: 6| Step: 6
Training loss: 0.1516331285238266
Validation loss: 2.008095860481262

Epoch: 6| Step: 7
Training loss: 0.20546308159828186
Validation loss: 2.0670520663261414

Epoch: 6| Step: 8
Training loss: 0.16821995377540588
Validation loss: 2.039966026941935

Epoch: 6| Step: 9
Training loss: 0.16749334335327148
Validation loss: 2.0295559565226235

Epoch: 6| Step: 10
Training loss: 0.22495436668395996
Validation loss: 2.03511118888855

Epoch: 6| Step: 11
Training loss: 0.20279231667518616
Validation loss: 2.025438666343689

Epoch: 6| Step: 12
Training loss: 0.16864576935768127
Validation loss: 2.00870144367218

Epoch: 6| Step: 13
Training loss: 0.8052282929420471
Validation loss: 2.013326565424601

Epoch: 382| Step: 0
Training loss: 0.24381056427955627
Validation loss: 2.0137731631596885

Epoch: 6| Step: 1
Training loss: 0.36177343130111694
Validation loss: 2.0134161909421286

Epoch: 6| Step: 2
Training loss: 0.5181264281272888
Validation loss: 2.0507145524024963

Epoch: 6| Step: 3
Training loss: 0.2428712546825409
Validation loss: 2.0150256554285684

Epoch: 6| Step: 4
Training loss: 0.225319966673851
Validation loss: 2.0584683219591775

Epoch: 6| Step: 5
Training loss: 0.16385674476623535
Validation loss: 2.093562205632528

Epoch: 6| Step: 6
Training loss: 0.3750483989715576
Validation loss: 1.9914817015329997

Epoch: 6| Step: 7
Training loss: 0.11837184429168701
Validation loss: 2.0400483210881553

Epoch: 6| Step: 8
Training loss: 0.2058311551809311
Validation loss: 2.0007808407147727

Epoch: 6| Step: 9
Training loss: 0.23972827196121216
Validation loss: 2.0289894541104636

Epoch: 6| Step: 10
Training loss: 0.16310636699199677
Validation loss: 2.039985477924347

Epoch: 6| Step: 11
Training loss: 0.18375182151794434
Validation loss: 2.0372891426086426

Epoch: 6| Step: 12
Training loss: 0.13266676664352417
Validation loss: 2.034919818242391

Epoch: 6| Step: 13
Training loss: 0.19408351182937622
Validation loss: 2.037891924381256

Epoch: 383| Step: 0
Training loss: 0.16951534152030945
Validation loss: 2.051850736141205

Epoch: 6| Step: 1
Training loss: 0.16211509704589844
Validation loss: 2.040544052918752

Epoch: 6| Step: 2
Training loss: 0.19782721996307373
Validation loss: 2.0610570311546326

Epoch: 6| Step: 3
Training loss: 0.24999640882015228
Validation loss: 2.0210247238477073

Epoch: 6| Step: 4
Training loss: 0.21316128969192505
Validation loss: 2.0359637339909873

Epoch: 6| Step: 5
Training loss: 0.16443541646003723
Validation loss: 2.0033565958340964

Epoch: 6| Step: 6
Training loss: 0.2121116816997528
Validation loss: 2.0091529488563538

Epoch: 6| Step: 7
Training loss: 0.2270456850528717
Validation loss: 2.0109935800234475

Epoch: 6| Step: 8
Training loss: 0.2008330374956131
Validation loss: 1.9811018308003743

Epoch: 6| Step: 9
Training loss: 0.6102738380432129
Validation loss: 2.0336832801500955

Epoch: 6| Step: 10
Training loss: 0.18321454524993896
Validation loss: 1.9849641919136047

Epoch: 6| Step: 11
Training loss: 0.21585199236869812
Validation loss: 1.9703182776769002

Epoch: 6| Step: 12
Training loss: 0.19614660739898682
Validation loss: 2.0221701661745706

Epoch: 6| Step: 13
Training loss: 0.4585241675376892
Validation loss: 1.9849491119384766

Epoch: 384| Step: 0
Training loss: 0.24936668574810028
Validation loss: 1.9949546655019124

Epoch: 6| Step: 1
Training loss: 0.1294715702533722
Validation loss: 1.9724706013997395

Epoch: 6| Step: 2
Training loss: 0.2719385027885437
Validation loss: 2.0316890478134155

Epoch: 6| Step: 3
Training loss: 0.39968258142471313
Validation loss: 2.0307616591453552

Epoch: 6| Step: 4
Training loss: 0.17201989889144897
Validation loss: 1.991880198319753

Epoch: 6| Step: 5
Training loss: 0.13609841465950012
Validation loss: 1.9937352140744526

Epoch: 6| Step: 6
Training loss: 0.17431902885437012
Validation loss: 2.004589339097341

Epoch: 6| Step: 7
Training loss: 0.7096287608146667
Validation loss: 1.999739368756612

Epoch: 6| Step: 8
Training loss: 0.20350494980812073
Validation loss: 1.980485737323761

Epoch: 6| Step: 9
Training loss: 0.24302078783512115
Validation loss: 1.9821291367212932

Epoch: 6| Step: 10
Training loss: 0.33965641260147095
Validation loss: 2.03408412138621

Epoch: 6| Step: 11
Training loss: 0.22719113528728485
Validation loss: 2.026207387447357

Epoch: 6| Step: 12
Training loss: 0.21860405802726746
Validation loss: 2.030775229136149

Epoch: 6| Step: 13
Training loss: 0.23141241073608398
Validation loss: 2.0290099581082663

Epoch: 385| Step: 0
Training loss: 0.2172521948814392
Validation loss: 1.9933253328005474

Epoch: 6| Step: 1
Training loss: 0.2744627594947815
Validation loss: 2.0365085005760193

Epoch: 6| Step: 2
Training loss: 0.19392459094524384
Validation loss: 2.058235685030619

Epoch: 6| Step: 3
Training loss: 0.17294801771640778
Validation loss: 2.0228375792503357

Epoch: 6| Step: 4
Training loss: 0.27775585651397705
Validation loss: 2.0311949054400125

Epoch: 6| Step: 5
Training loss: 0.616247832775116
Validation loss: 2.027877628803253

Epoch: 6| Step: 6
Training loss: 0.3644391894340515
Validation loss: 2.0101048946380615

Epoch: 6| Step: 7
Training loss: 0.18789005279541016
Validation loss: 2.0114489595095315

Epoch: 6| Step: 8
Training loss: 0.22613854706287384
Validation loss: 2.003972311814626

Epoch: 6| Step: 9
Training loss: 0.4201693534851074
Validation loss: 2.0110678474108377

Epoch: 6| Step: 10
Training loss: 0.3006649315357208
Validation loss: 2.0156488021214805

Epoch: 6| Step: 11
Training loss: 0.17097362875938416
Validation loss: 2.0323954820632935

Epoch: 6| Step: 12
Training loss: 0.19687116146087646
Validation loss: 2.0627389550209045

Epoch: 6| Step: 13
Training loss: 0.19407127797603607
Validation loss: 2.012943983078003

Epoch: 386| Step: 0
Training loss: 0.1269064098596573
Validation loss: 2.0262253681818643

Epoch: 6| Step: 1
Training loss: 0.17362210154533386
Validation loss: 2.0160664916038513

Epoch: 6| Step: 2
Training loss: 0.20605579018592834
Validation loss: 1.9937533140182495

Epoch: 6| Step: 3
Training loss: 0.2546102702617645
Validation loss: 2.0412240624427795

Epoch: 6| Step: 4
Training loss: 0.40749025344848633
Validation loss: 2.0098294218381247

Epoch: 6| Step: 5
Training loss: 0.17767871916294098
Validation loss: 2.0424537857373557

Epoch: 6| Step: 6
Training loss: 0.23170572519302368
Validation loss: 2.0470251639684043

Epoch: 6| Step: 7
Training loss: 0.1956334114074707
Validation loss: 2.009401480356852

Epoch: 6| Step: 8
Training loss: 0.13074809312820435
Validation loss: 2.0030837456385293

Epoch: 6| Step: 9
Training loss: 0.27064049243927
Validation loss: 2.0235294103622437

Epoch: 6| Step: 10
Training loss: 0.19710522890090942
Validation loss: 1.9686848918596904

Epoch: 6| Step: 11
Training loss: 0.22249522805213928
Validation loss: 2.0301605463027954

Epoch: 6| Step: 12
Training loss: 0.6359920501708984
Validation loss: 2.0565622647603354

Epoch: 6| Step: 13
Training loss: 0.17435871064662933
Validation loss: 2.010095794995626

Epoch: 387| Step: 0
Training loss: 0.1621285378932953
Validation loss: 2.0242497324943542

Epoch: 6| Step: 1
Training loss: 0.27822256088256836
Validation loss: 2.0174968441327414

Epoch: 6| Step: 2
Training loss: 0.3600634038448334
Validation loss: 2.0093413591384888

Epoch: 6| Step: 3
Training loss: 0.15500539541244507
Validation loss: 2.004344085852305

Epoch: 6| Step: 4
Training loss: 0.2891734838485718
Validation loss: 2.0064610044161477

Epoch: 6| Step: 5
Training loss: 0.5589847564697266
Validation loss: 2.0076573689778647

Epoch: 6| Step: 6
Training loss: 0.2323952317237854
Validation loss: 1.975789984067281

Epoch: 6| Step: 7
Training loss: 0.532529890537262
Validation loss: 1.9897342920303345

Epoch: 6| Step: 8
Training loss: 0.22793057560920715
Validation loss: 1.989212175210317

Epoch: 6| Step: 9
Training loss: 0.2938002347946167
Validation loss: 1.9559829235076904

Epoch: 6| Step: 10
Training loss: 0.2590796649456024
Validation loss: 1.9913057684898376

Epoch: 6| Step: 11
Training loss: 0.2768007218837738
Validation loss: 1.9755234519640605

Epoch: 6| Step: 12
Training loss: 0.16504612565040588
Validation loss: 2.0146755973498025

Epoch: 6| Step: 13
Training loss: 0.30345600843429565
Validation loss: 2.0103540619214377

Epoch: 388| Step: 0
Training loss: 0.39460039138793945
Validation loss: 2.0440447330474854

Epoch: 6| Step: 1
Training loss: 0.21218258142471313
Validation loss: 1.9813529253005981

Epoch: 6| Step: 2
Training loss: 0.1992076337337494
Validation loss: 1.9844987988471985

Epoch: 6| Step: 3
Training loss: 0.2570953965187073
Validation loss: 1.9935206174850464

Epoch: 6| Step: 4
Training loss: 0.20504266023635864
Validation loss: 2.019764721393585

Epoch: 6| Step: 5
Training loss: 0.7957873940467834
Validation loss: 2.0150504112243652

Epoch: 6| Step: 6
Training loss: 0.21864676475524902
Validation loss: 1.995066265265147

Epoch: 6| Step: 7
Training loss: 0.2594778537750244
Validation loss: 1.9758696556091309

Epoch: 6| Step: 8
Training loss: 0.210428386926651
Validation loss: 2.015743633111318

Epoch: 6| Step: 9
Training loss: 0.19391240179538727
Validation loss: 2.009651223818461

Epoch: 6| Step: 10
Training loss: 0.26570993661880493
Validation loss: 1.98838609457016

Epoch: 6| Step: 11
Training loss: 0.3382531404495239
Validation loss: 2.01543790102005

Epoch: 6| Step: 12
Training loss: 0.2309674620628357
Validation loss: 2.014128347237905

Epoch: 6| Step: 13
Training loss: 0.16204968094825745
Validation loss: 2.026477893193563

Epoch: 389| Step: 0
Training loss: 0.25816819071769714
Validation loss: 2.0132770935694375

Epoch: 6| Step: 1
Training loss: 0.29158902168273926
Validation loss: 2.0133169293403625

Epoch: 6| Step: 2
Training loss: 0.3745318353176117
Validation loss: 1.9998803734779358

Epoch: 6| Step: 3
Training loss: 0.35756081342697144
Validation loss: 1.9984908898671467

Epoch: 6| Step: 4
Training loss: 0.2320253700017929
Validation loss: 2.0360891620318093

Epoch: 6| Step: 5
Training loss: 0.2480897158384323
Validation loss: 2.0286436676979065

Epoch: 6| Step: 6
Training loss: 0.700900673866272
Validation loss: 2.0207441250483194

Epoch: 6| Step: 7
Training loss: 0.26734691858291626
Validation loss: 2.03396737575531

Epoch: 6| Step: 8
Training loss: 0.34521132707595825
Validation loss: 2.0616846084594727

Epoch: 6| Step: 9
Training loss: 0.3601798415184021
Validation loss: 2.0649399558703103

Epoch: 6| Step: 10
Training loss: 0.36503392457962036
Validation loss: 2.039336323738098

Epoch: 6| Step: 11
Training loss: 0.29420948028564453
Validation loss: 2.018054187297821

Epoch: 6| Step: 12
Training loss: 0.2469121366739273
Validation loss: 2.0105694929758706

Epoch: 6| Step: 13
Training loss: 0.1825820505619049
Validation loss: 2.0059799353281655

Epoch: 390| Step: 0
Training loss: 0.32106077671051025
Validation loss: 1.9670857588450115

Epoch: 6| Step: 1
Training loss: 0.38157108426094055
Validation loss: 2.0038782358169556

Epoch: 6| Step: 2
Training loss: 0.28736430406570435
Validation loss: 2.011319637298584

Epoch: 6| Step: 3
Training loss: 0.27811554074287415
Validation loss: 2.019754926363627

Epoch: 6| Step: 4
Training loss: 0.3589726686477661
Validation loss: 2.020388046900431

Epoch: 6| Step: 5
Training loss: 0.37093836069107056
Validation loss: 2.0256012082099915

Epoch: 6| Step: 6
Training loss: 0.29468485713005066
Validation loss: 2.015560189882914

Epoch: 6| Step: 7
Training loss: 0.1954527348279953
Validation loss: 2.0387768944104514

Epoch: 6| Step: 8
Training loss: 0.26461061835289
Validation loss: 2.031124174594879

Epoch: 6| Step: 9
Training loss: 0.2725280225276947
Validation loss: 2.0088263948758445

Epoch: 6| Step: 10
Training loss: 0.20987194776535034
Validation loss: 1.9992788632710774

Epoch: 6| Step: 11
Training loss: 0.5690760612487793
Validation loss: 2.0253181060155234

Epoch: 6| Step: 12
Training loss: 0.3675103187561035
Validation loss: 2.0139679312705994

Epoch: 6| Step: 13
Training loss: 0.4049132466316223
Validation loss: 1.986701786518097

Epoch: 391| Step: 0
Training loss: 0.21700194478034973
Validation loss: 2.037605047225952

Epoch: 6| Step: 1
Training loss: 0.17714513838291168
Validation loss: 2.0467464129130044

Epoch: 6| Step: 2
Training loss: 0.33561766147613525
Validation loss: 2.029975672562917

Epoch: 6| Step: 3
Training loss: 0.18131494522094727
Validation loss: 2.007215956846873

Epoch: 6| Step: 4
Training loss: 0.24005095660686493
Validation loss: 2.010116000970205

Epoch: 6| Step: 5
Training loss: 0.765274167060852
Validation loss: 2.0367103815078735

Epoch: 6| Step: 6
Training loss: 0.32029759883880615
Validation loss: 2.0167811711629233

Epoch: 6| Step: 7
Training loss: 0.2065354287624359
Validation loss: 2.040957430998484

Epoch: 6| Step: 8
Training loss: 0.2866964638233185
Validation loss: 2.0084707538286843

Epoch: 6| Step: 9
Training loss: 0.24355430901050568
Validation loss: 2.042171041170756

Epoch: 6| Step: 10
Training loss: 0.24835854768753052
Validation loss: 2.0302599668502808

Epoch: 6| Step: 11
Training loss: 0.30452650785446167
Validation loss: 2.0074763894081116

Epoch: 6| Step: 12
Training loss: 0.40213608741760254
Validation loss: 2.0207799673080444

Epoch: 6| Step: 13
Training loss: 0.20711857080459595
Validation loss: 1.9725130995114644

Epoch: 392| Step: 0
Training loss: 0.24577194452285767
Validation loss: 1.9959895213445027

Epoch: 6| Step: 1
Training loss: 0.23367492854595184
Validation loss: 1.9847551584243774

Epoch: 6| Step: 2
Training loss: 0.2322576344013214
Validation loss: 1.9798362851142883

Epoch: 6| Step: 3
Training loss: 0.4083344042301178
Validation loss: 2.0267497102419534

Epoch: 6| Step: 4
Training loss: 0.5431389808654785
Validation loss: 1.994638462861379

Epoch: 6| Step: 5
Training loss: 0.2848658859729767
Validation loss: 2.0195167859395347

Epoch: 6| Step: 6
Training loss: 0.25183412432670593
Validation loss: 1.99066166083018

Epoch: 6| Step: 7
Training loss: 0.21068841218948364
Validation loss: 2.0116280714670816

Epoch: 6| Step: 8
Training loss: 0.23118865489959717
Validation loss: 2.006172756354014

Epoch: 6| Step: 9
Training loss: 0.2909872531890869
Validation loss: 1.9944907824198406

Epoch: 6| Step: 10
Training loss: 0.30088651180267334
Validation loss: 1.9845050970713298

Epoch: 6| Step: 11
Training loss: 0.19902187585830688
Validation loss: 2.0022784074147544

Epoch: 6| Step: 12
Training loss: 0.2773228883743286
Validation loss: 1.9909502665201824

Epoch: 6| Step: 13
Training loss: 0.20842763781547546
Validation loss: 2.0246450503667197

Epoch: 393| Step: 0
Training loss: 0.20171505212783813
Validation loss: 2.002088963985443

Epoch: 6| Step: 1
Training loss: 0.17235736548900604
Validation loss: 2.052193502585093

Epoch: 6| Step: 2
Training loss: 0.2547515332698822
Validation loss: 2.0154335101445517

Epoch: 6| Step: 3
Training loss: 0.16924405097961426
Validation loss: 2.02381294965744

Epoch: 6| Step: 4
Training loss: 0.20235563814640045
Validation loss: 2.0317614873250327

Epoch: 6| Step: 5
Training loss: 0.39774101972579956
Validation loss: 2.0429508288701377

Epoch: 6| Step: 6
Training loss: 0.1528925597667694
Validation loss: 2.0435312191645303

Epoch: 6| Step: 7
Training loss: 0.2365548312664032
Validation loss: 2.0120460589726767

Epoch: 6| Step: 8
Training loss: 0.5258880257606506
Validation loss: 2.043086071809133

Epoch: 6| Step: 9
Training loss: 0.22183911502361298
Validation loss: 2.053893268108368

Epoch: 6| Step: 10
Training loss: 0.1845417618751526
Validation loss: 2.0344505111376443

Epoch: 6| Step: 11
Training loss: 0.16075125336647034
Validation loss: 2.061616063117981

Epoch: 6| Step: 12
Training loss: 0.2710251212120056
Validation loss: 2.025500237941742

Epoch: 6| Step: 13
Training loss: 0.1617162674665451
Validation loss: 2.037084380785624

Epoch: 394| Step: 0
Training loss: 0.21676529943943024
Validation loss: 2.0501540700594583

Epoch: 6| Step: 1
Training loss: 0.20724518597126007
Validation loss: 2.041745881239573

Epoch: 6| Step: 2
Training loss: 0.21945124864578247
Validation loss: 2.0574335853258767

Epoch: 6| Step: 3
Training loss: 0.23274460434913635
Validation loss: 1.9993477662404378

Epoch: 6| Step: 4
Training loss: 0.27895984053611755
Validation loss: 1.9902870853741963

Epoch: 6| Step: 5
Training loss: 0.262592613697052
Validation loss: 2.0215508937835693

Epoch: 6| Step: 6
Training loss: 0.3083544969558716
Validation loss: 2.0259289741516113

Epoch: 6| Step: 7
Training loss: 0.5995055437088013
Validation loss: 2.0182104309399924

Epoch: 6| Step: 8
Training loss: 0.14298106729984283
Validation loss: 2.0237470666567483

Epoch: 6| Step: 9
Training loss: 0.1995411515235901
Validation loss: 2.034699102242788

Epoch: 6| Step: 10
Training loss: 0.3443072438240051
Validation loss: 2.0014036893844604

Epoch: 6| Step: 11
Training loss: 0.17318907380104065
Validation loss: 2.0314124822616577

Epoch: 6| Step: 12
Training loss: 0.27483126521110535
Validation loss: 1.9851246078809102

Epoch: 6| Step: 13
Training loss: 0.27782678604125977
Validation loss: 1.9614523649215698

Epoch: 395| Step: 0
Training loss: 0.2519048750400543
Validation loss: 2.0223901073137918

Epoch: 6| Step: 1
Training loss: 0.26086708903312683
Validation loss: 2.012573798497518

Epoch: 6| Step: 2
Training loss: 0.1846727877855301
Validation loss: 2.0340210994084678

Epoch: 6| Step: 3
Training loss: 0.10059314221143723
Validation loss: 2.018223981062571

Epoch: 6| Step: 4
Training loss: 0.31525635719299316
Validation loss: 2.0298370718955994

Epoch: 6| Step: 5
Training loss: 0.6230539083480835
Validation loss: 2.0006993412971497

Epoch: 6| Step: 6
Training loss: 0.20208832621574402
Validation loss: 2.0415531198183694

Epoch: 6| Step: 7
Training loss: 0.09340612590312958
Validation loss: 2.017814815044403

Epoch: 6| Step: 8
Training loss: 0.13873842358589172
Validation loss: 1.995450496673584

Epoch: 6| Step: 9
Training loss: 0.35887962579727173
Validation loss: 2.0411975383758545

Epoch: 6| Step: 10
Training loss: 0.26803651452064514
Validation loss: 2.031792183717092

Epoch: 6| Step: 11
Training loss: 0.21899521350860596
Validation loss: 2.0156582395235696

Epoch: 6| Step: 12
Training loss: 0.2076345533132553
Validation loss: 2.033287008603414

Epoch: 6| Step: 13
Training loss: 0.15937060117721558
Validation loss: 2.019970655441284

Epoch: 396| Step: 0
Training loss: 0.2090970128774643
Validation loss: 2.0134418408075967

Epoch: 6| Step: 1
Training loss: 0.1566583663225174
Validation loss: 2.0720911820729575

Epoch: 6| Step: 2
Training loss: 0.31052011251449585
Validation loss: 2.034218887488047

Epoch: 6| Step: 3
Training loss: 0.16374865174293518
Validation loss: 2.0085157553354898

Epoch: 6| Step: 4
Training loss: 0.1441863477230072
Validation loss: 2.0778761506080627

Epoch: 6| Step: 5
Training loss: 0.23237285017967224
Validation loss: 2.030188043912252

Epoch: 6| Step: 6
Training loss: 0.2451930195093155
Validation loss: 2.0187645753224692

Epoch: 6| Step: 7
Training loss: 0.20307669043540955
Validation loss: 2.0229519804318747

Epoch: 6| Step: 8
Training loss: 0.20865118503570557
Validation loss: 1.9681540330251057

Epoch: 6| Step: 9
Training loss: 0.19129705429077148
Validation loss: 2.012876729170481

Epoch: 6| Step: 10
Training loss: 0.18969027698040009
Validation loss: 2.003541866938273

Epoch: 6| Step: 11
Training loss: 0.6660103797912598
Validation loss: 2.0239784121513367

Epoch: 6| Step: 12
Training loss: 0.22147473692893982
Validation loss: 2.0048014322916665

Epoch: 6| Step: 13
Training loss: 0.3028579354286194
Validation loss: 1.9825821320215862

Epoch: 397| Step: 0
Training loss: 0.1875908374786377
Validation loss: 2.028722604115804

Epoch: 6| Step: 1
Training loss: 0.247808039188385
Validation loss: 2.0556993087132773

Epoch: 6| Step: 2
Training loss: 0.17109528183937073
Validation loss: 2.0374815662701926

Epoch: 6| Step: 3
Training loss: 0.24929684400558472
Validation loss: 2.024230500062307

Epoch: 6| Step: 4
Training loss: 0.2807411551475525
Validation loss: 2.0482780933380127

Epoch: 6| Step: 5
Training loss: 0.23797188699245453
Validation loss: 1.962667981783549

Epoch: 6| Step: 6
Training loss: 0.15846532583236694
Validation loss: 2.020918687184652

Epoch: 6| Step: 7
Training loss: 0.23312531411647797
Validation loss: 2.022820770740509

Epoch: 6| Step: 8
Training loss: 0.6369364261627197
Validation loss: 1.9998875459035237

Epoch: 6| Step: 9
Training loss: 0.18478459119796753
Validation loss: 2.0271503925323486

Epoch: 6| Step: 10
Training loss: 0.20685666799545288
Validation loss: 2.0400113264719644

Epoch: 6| Step: 11
Training loss: 0.3564155697822571
Validation loss: 2.0434577663739524

Epoch: 6| Step: 12
Training loss: 0.17135503888130188
Validation loss: 2.025437613328298

Epoch: 6| Step: 13
Training loss: 0.21345849335193634
Validation loss: 2.0040537118911743

Epoch: 398| Step: 0
Training loss: 0.1978761851787567
Validation loss: 1.9939557115236919

Epoch: 6| Step: 1
Training loss: 0.2542695701122284
Validation loss: 2.0198817253112793

Epoch: 6| Step: 2
Training loss: 0.22779707610607147
Validation loss: 1.9853519598642986

Epoch: 6| Step: 3
Training loss: 0.2283424437046051
Validation loss: 1.9991615215937297

Epoch: 6| Step: 4
Training loss: 0.31237393617630005
Validation loss: 1.9971168239911397

Epoch: 6| Step: 5
Training loss: 0.31878095865249634
Validation loss: 2.04847260316213

Epoch: 6| Step: 6
Training loss: 0.20735889673233032
Validation loss: 2.060115178426107

Epoch: 6| Step: 7
Training loss: 0.17367050051689148
Validation loss: 2.0265639225641885

Epoch: 6| Step: 8
Training loss: 0.2533842921257019
Validation loss: 2.0112125873565674

Epoch: 6| Step: 9
Training loss: 0.21593044698238373
Validation loss: 2.0024072726567588

Epoch: 6| Step: 10
Training loss: 0.1972883641719818
Validation loss: 2.021114706993103

Epoch: 6| Step: 11
Training loss: 0.5863311290740967
Validation loss: 2.029928723971049

Epoch: 6| Step: 12
Training loss: 0.15283623337745667
Validation loss: 1.9828431407610576

Epoch: 6| Step: 13
Training loss: 0.1826367974281311
Validation loss: 2.0217140714327493

Epoch: 399| Step: 0
Training loss: 0.23395264148712158
Validation loss: 2.0265104373296103

Epoch: 6| Step: 1
Training loss: 0.18634092807769775
Validation loss: 2.032773514588674

Epoch: 6| Step: 2
Training loss: 0.22233891487121582
Validation loss: 2.020935614903768

Epoch: 6| Step: 3
Training loss: 0.20685157179832458
Validation loss: 2.015942335128784

Epoch: 6| Step: 4
Training loss: 0.2855875790119171
Validation loss: 2.016885201136271

Epoch: 6| Step: 5
Training loss: 0.25363224744796753
Validation loss: 1.9943772157033284

Epoch: 6| Step: 6
Training loss: 0.17073297500610352
Validation loss: 2.0085409283638

Epoch: 6| Step: 7
Training loss: 0.1982783079147339
Validation loss: 2.068696081638336

Epoch: 6| Step: 8
Training loss: 0.2346390187740326
Validation loss: 2.0283107360204062

Epoch: 6| Step: 9
Training loss: 0.2458108514547348
Validation loss: 2.00553830464681

Epoch: 6| Step: 10
Training loss: 0.5333061218261719
Validation loss: 1.9921298623085022

Epoch: 6| Step: 11
Training loss: 0.4902377724647522
Validation loss: 2.0385690132776895

Epoch: 6| Step: 12
Training loss: 0.2860683500766754
Validation loss: 2.025559941927592

Epoch: 6| Step: 13
Training loss: 0.20711186528205872
Validation loss: 2.0034146507581077

Epoch: 400| Step: 0
Training loss: 0.3027389943599701
Validation loss: 2.0231271783510842

Epoch: 6| Step: 1
Training loss: 0.35971522331237793
Validation loss: 2.023836354414622

Epoch: 6| Step: 2
Training loss: 0.1878589540719986
Validation loss: 2.0116957426071167

Epoch: 6| Step: 3
Training loss: 0.18440401554107666
Validation loss: 2.0153311491012573

Epoch: 6| Step: 4
Training loss: 0.19208261370658875
Validation loss: 2.03217351436615

Epoch: 6| Step: 5
Training loss: 0.3258088231086731
Validation loss: 2.029849370320638

Epoch: 6| Step: 6
Training loss: 0.1606355607509613
Validation loss: 2.0322429736455283

Epoch: 6| Step: 7
Training loss: 0.15083500742912292
Validation loss: 2.011006474494934

Epoch: 6| Step: 8
Training loss: 0.18327394127845764
Validation loss: 2.014821191628774

Epoch: 6| Step: 9
Training loss: 0.25961360335350037
Validation loss: 2.0112438996632895

Epoch: 6| Step: 10
Training loss: 0.22110041975975037
Validation loss: 2.0408242543538413

Epoch: 6| Step: 11
Training loss: 0.5239080190658569
Validation loss: 1.9973027507464092

Epoch: 6| Step: 12
Training loss: 0.2248454988002777
Validation loss: 2.0096994042396545

Epoch: 6| Step: 13
Training loss: 0.14554136991500854
Validation loss: 2.036315937836965

Testing loss: 1.9853412110170872
