Epoch: 1| Step: 0
Training loss: 7.186873912811279
Validation loss: 7.604517062505086

Epoch: 6| Step: 1
Training loss: 8.126229286193848
Validation loss: 7.567015012105306

Epoch: 6| Step: 2
Training loss: 8.436123847961426
Validation loss: 7.536225954691569

Epoch: 6| Step: 3
Training loss: 7.9632439613342285
Validation loss: 7.505701303482056

Epoch: 6| Step: 4
Training loss: 7.159876346588135
Validation loss: 7.4746787548065186

Epoch: 6| Step: 5
Training loss: 6.489012718200684
Validation loss: 7.443172454833984

Epoch: 6| Step: 6
Training loss: 7.036622047424316
Validation loss: 7.4105810324351

Epoch: 6| Step: 7
Training loss: 7.280284881591797
Validation loss: 7.381422519683838

Epoch: 6| Step: 8
Training loss: 7.344914436340332
Validation loss: 7.352183739344279

Epoch: 6| Step: 9
Training loss: 7.7143659591674805
Validation loss: 7.321521679560344

Epoch: 6| Step: 10
Training loss: 7.596169948577881
Validation loss: 7.287736574808757

Epoch: 6| Step: 11
Training loss: 7.115527629852295
Validation loss: 7.252919832865397

Epoch: 6| Step: 12
Training loss: 7.069988250732422
Validation loss: 7.221595446268718

Epoch: 6| Step: 13
Training loss: 7.983454704284668
Validation loss: 7.1859965324401855

Epoch: 2| Step: 0
Training loss: 8.084644317626953
Validation loss: 7.1490592161814375

Epoch: 6| Step: 1
Training loss: 7.2964091300964355
Validation loss: 7.110659599304199

Epoch: 6| Step: 2
Training loss: 7.114069938659668
Validation loss: 7.0710069338480634

Epoch: 6| Step: 3
Training loss: 7.242790699005127
Validation loss: 7.032519022623698

Epoch: 6| Step: 4
Training loss: 7.637094497680664
Validation loss: 6.992344697316487

Epoch: 6| Step: 5
Training loss: 6.4053850173950195
Validation loss: 6.94993797938029

Epoch: 6| Step: 6
Training loss: 6.828305244445801
Validation loss: 6.903970241546631

Epoch: 6| Step: 7
Training loss: 8.075778007507324
Validation loss: 6.861310958862305

Epoch: 6| Step: 8
Training loss: 6.614831447601318
Validation loss: 6.812850713729858

Epoch: 6| Step: 9
Training loss: 5.873035430908203
Validation loss: 6.761459430058797

Epoch: 6| Step: 10
Training loss: 5.353872776031494
Validation loss: 6.709294398625691

Epoch: 6| Step: 11
Training loss: 6.8962626457214355
Validation loss: 6.659240166346232

Epoch: 6| Step: 12
Training loss: 6.608752250671387
Validation loss: 6.604214509328206

Epoch: 6| Step: 13
Training loss: 6.990189552307129
Validation loss: 6.541577100753784

Epoch: 3| Step: 0
Training loss: 5.799004554748535
Validation loss: 6.483385642369588

Epoch: 6| Step: 1
Training loss: 7.084155082702637
Validation loss: 6.419275760650635

Epoch: 6| Step: 2
Training loss: 5.895720481872559
Validation loss: 6.352782249450684

Epoch: 6| Step: 3
Training loss: 6.3130669593811035
Validation loss: 6.287331740061442

Epoch: 6| Step: 4
Training loss: 5.520498275756836
Validation loss: 6.208418528238933

Epoch: 6| Step: 5
Training loss: 5.896270751953125
Validation loss: 6.140043497085571

Epoch: 6| Step: 6
Training loss: 6.20050573348999
Validation loss: 6.0645647048950195

Epoch: 6| Step: 7
Training loss: 6.846428394317627
Validation loss: 5.97045914332072

Epoch: 6| Step: 8
Training loss: 5.411313533782959
Validation loss: 5.89433232943217

Epoch: 6| Step: 9
Training loss: 5.8310627937316895
Validation loss: 5.799937009811401

Epoch: 6| Step: 10
Training loss: 6.732614517211914
Validation loss: 5.703264077504476

Epoch: 6| Step: 11
Training loss: 5.4349846839904785
Validation loss: 5.608140150705974

Epoch: 6| Step: 12
Training loss: 5.653677940368652
Validation loss: 5.508697032928467

Epoch: 6| Step: 13
Training loss: 6.074484825134277
Validation loss: 5.395361502965291

Epoch: 4| Step: 0
Training loss: 5.064953804016113
Validation loss: 5.276738325754802

Epoch: 6| Step: 1
Training loss: 4.873983860015869
Validation loss: 5.168138265609741

Epoch: 6| Step: 2
Training loss: 5.520116806030273
Validation loss: 5.03874675432841

Epoch: 6| Step: 3
Training loss: 5.907264232635498
Validation loss: 4.913183927536011

Epoch: 6| Step: 4
Training loss: 3.602757453918457
Validation loss: 4.776965061823527

Epoch: 6| Step: 5
Training loss: 4.669447898864746
Validation loss: 4.630418459574382

Epoch: 6| Step: 6
Training loss: 4.456441879272461
Validation loss: 4.489230076471965

Epoch: 6| Step: 7
Training loss: 4.72128438949585
Validation loss: 4.339464028676351

Epoch: 6| Step: 8
Training loss: 3.6543750762939453
Validation loss: 4.196013847986857

Epoch: 6| Step: 9
Training loss: 4.70095157623291
Validation loss: 4.028710563977559

Epoch: 6| Step: 10
Training loss: 3.777233600616455
Validation loss: 3.879721999168396

Epoch: 6| Step: 11
Training loss: 3.6809678077697754
Validation loss: 3.7332125902175903

Epoch: 6| Step: 12
Training loss: 3.8796260356903076
Validation loss: 3.568912625312805

Epoch: 6| Step: 13
Training loss: 4.232023239135742
Validation loss: 3.441943407058716

Epoch: 5| Step: 0
Training loss: 3.5651073455810547
Validation loss: 3.2801676988601685

Epoch: 6| Step: 1
Training loss: 3.342627763748169
Validation loss: 3.1575324138005576

Epoch: 6| Step: 2
Training loss: 3.43426513671875
Validation loss: 2.9817368189493814

Epoch: 6| Step: 3
Training loss: 2.524916648864746
Validation loss: 2.833008050918579

Epoch: 6| Step: 4
Training loss: 3.0464954376220703
Validation loss: 2.677277684211731

Epoch: 6| Step: 5
Training loss: 2.8647046089172363
Validation loss: 2.5308529138565063

Epoch: 6| Step: 6
Training loss: 1.5600755214691162
Validation loss: 2.448987285296122

Epoch: 6| Step: 7
Training loss: 2.7953073978424072
Validation loss: 2.3963995774586997

Epoch: 6| Step: 8
Training loss: 1.7833479642868042
Validation loss: 2.330784579118093

Epoch: 6| Step: 9
Training loss: 2.1022143363952637
Validation loss: 2.3127816120783486

Epoch: 6| Step: 10
Training loss: 2.9950265884399414
Validation loss: 2.2621689240137735

Epoch: 6| Step: 11
Training loss: 2.238044261932373
Validation loss: 2.2885117133458457

Epoch: 6| Step: 12
Training loss: 2.455571174621582
Validation loss: 2.268115679423014

Epoch: 6| Step: 13
Training loss: 2.9684457778930664
Validation loss: 2.2582341035207114

Epoch: 6| Step: 0
Training loss: 2.127747058868408
Validation loss: 2.3287340203921

Epoch: 6| Step: 1
Training loss: 2.619464874267578
Validation loss: 2.3150293429692588

Epoch: 6| Step: 2
Training loss: 2.023193359375
Validation loss: 2.329355776309967

Epoch: 6| Step: 3
Training loss: 2.063751697540283
Validation loss: 2.366187572479248

Epoch: 6| Step: 4
Training loss: 2.2752327919006348
Validation loss: 2.341062863667806

Epoch: 6| Step: 5
Training loss: 2.7808966636657715
Validation loss: 2.345078448454539

Epoch: 6| Step: 6
Training loss: 2.640392303466797
Validation loss: 2.3193780183792114

Epoch: 6| Step: 7
Training loss: 2.574591636657715
Validation loss: 2.290705621242523

Epoch: 6| Step: 8
Training loss: 2.892066478729248
Validation loss: 2.2962865630785623

Epoch: 6| Step: 9
Training loss: 2.103426694869995
Validation loss: 2.2932059367497764

Epoch: 6| Step: 10
Training loss: 3.0637643337249756
Validation loss: 2.2674222787221274

Epoch: 6| Step: 11
Training loss: 2.3397388458251953
Validation loss: 2.2930041352907815

Epoch: 6| Step: 12
Training loss: 2.333535671234131
Validation loss: 2.2501774628957114

Epoch: 6| Step: 13
Training loss: 2.1326770782470703
Validation loss: 2.249719500541687

Epoch: 7| Step: 0
Training loss: 2.5146484375
Validation loss: 2.252192238966624

Epoch: 6| Step: 1
Training loss: 2.3241167068481445
Validation loss: 2.2356826861699424

Epoch: 6| Step: 2
Training loss: 1.9526561498641968
Validation loss: 2.272466778755188

Epoch: 6| Step: 3
Training loss: 3.05936598777771
Validation loss: 2.2646761735280356

Epoch: 6| Step: 4
Training loss: 2.985971450805664
Validation loss: 2.2824005087216697

Epoch: 6| Step: 5
Training loss: 2.2985291481018066
Validation loss: 2.2738086183865867

Epoch: 6| Step: 6
Training loss: 3.1115119457244873
Validation loss: 2.2590168714523315

Epoch: 6| Step: 7
Training loss: 2.034850597381592
Validation loss: 2.2706828514734902

Epoch: 6| Step: 8
Training loss: 2.0689010620117188
Validation loss: 2.2708659966786704

Epoch: 6| Step: 9
Training loss: 1.3212699890136719
Validation loss: 2.2386516332626343

Epoch: 6| Step: 10
Training loss: 2.3184967041015625
Validation loss: 2.2651145458221436

Epoch: 6| Step: 11
Training loss: 2.0490036010742188
Validation loss: 2.2961570421854653

Epoch: 6| Step: 12
Training loss: 2.03247332572937
Validation loss: 2.266451120376587

Epoch: 6| Step: 13
Training loss: 2.53204345703125
Validation loss: 2.239282468954722

Epoch: 8| Step: 0
Training loss: 2.735751152038574
Validation loss: 2.2454784711201987

Epoch: 6| Step: 1
Training loss: 2.775078296661377
Validation loss: 2.258592446645101

Epoch: 6| Step: 2
Training loss: 1.988016128540039
Validation loss: 2.234840512275696

Epoch: 6| Step: 3
Training loss: 2.5173916816711426
Validation loss: 2.2611243724823

Epoch: 6| Step: 4
Training loss: 2.752150297164917
Validation loss: 2.252277930577596

Epoch: 6| Step: 5
Training loss: 2.244208574295044
Validation loss: 2.2302928368250527

Epoch: 6| Step: 6
Training loss: 1.6111857891082764
Validation loss: 2.2556843956311545

Epoch: 6| Step: 7
Training loss: 1.7538200616836548
Validation loss: 2.2283026973406472

Epoch: 6| Step: 8
Training loss: 2.977804183959961
Validation loss: 2.2110188206036887

Epoch: 6| Step: 9
Training loss: 2.593179225921631
Validation loss: 2.199920097986857

Epoch: 6| Step: 10
Training loss: 2.1934027671813965
Validation loss: 2.2351648807525635

Epoch: 6| Step: 11
Training loss: 1.7316007614135742
Validation loss: 2.191834112008413

Epoch: 6| Step: 12
Training loss: 2.530930995941162
Validation loss: 2.214109202226003

Epoch: 6| Step: 13
Training loss: 2.0867438316345215
Validation loss: 2.198178291320801

Epoch: 9| Step: 0
Training loss: 2.344555139541626
Validation loss: 2.174445112546285

Epoch: 6| Step: 1
Training loss: 2.8077898025512695
Validation loss: 2.2013399402300515

Epoch: 6| Step: 2
Training loss: 2.413761615753174
Validation loss: 2.18927401304245

Epoch: 6| Step: 3
Training loss: 2.4252407550811768
Validation loss: 2.2087575594584146

Epoch: 6| Step: 4
Training loss: 1.9649782180786133
Validation loss: 2.198795199394226

Epoch: 6| Step: 5
Training loss: 2.6775436401367188
Validation loss: 2.210293928782145

Epoch: 6| Step: 6
Training loss: 2.1195995807647705
Validation loss: 2.183347781499227

Epoch: 6| Step: 7
Training loss: 1.538787841796875
Validation loss: 2.1922401587168374

Epoch: 6| Step: 8
Training loss: 2.172276020050049
Validation loss: 2.218836029370626

Epoch: 6| Step: 9
Training loss: 2.773113489151001
Validation loss: 2.2354833682378135

Epoch: 6| Step: 10
Training loss: 1.704676628112793
Validation loss: 2.1819833517074585

Epoch: 6| Step: 11
Training loss: 2.8191299438476562
Validation loss: 2.21576193968455

Epoch: 6| Step: 12
Training loss: 1.8864870071411133
Validation loss: 2.195507287979126

Epoch: 6| Step: 13
Training loss: 2.111555576324463
Validation loss: 2.1941425800323486

Epoch: 10| Step: 0
Training loss: 2.9697251319885254
Validation loss: 2.1706418991088867

Epoch: 6| Step: 1
Training loss: 1.875531792640686
Validation loss: 2.1848367055257163

Epoch: 6| Step: 2
Training loss: 2.1535089015960693
Validation loss: 2.195591469605764

Epoch: 6| Step: 3
Training loss: 2.178374767303467
Validation loss: 2.2067331870396933

Epoch: 6| Step: 4
Training loss: 1.7737678289413452
Validation loss: 2.169122258822123

Epoch: 6| Step: 5
Training loss: 2.0063180923461914
Validation loss: 2.176165461540222

Epoch: 6| Step: 6
Training loss: 2.512265205383301
Validation loss: 2.2040021419525146

Epoch: 6| Step: 7
Training loss: 2.4366097450256348
Validation loss: 2.1922740538915

Epoch: 6| Step: 8
Training loss: 2.2148964405059814
Validation loss: 2.1770811875661216

Epoch: 6| Step: 9
Training loss: 1.7390179634094238
Validation loss: 2.213844577471415

Epoch: 6| Step: 10
Training loss: 2.151517391204834
Validation loss: 2.153921147187551

Epoch: 6| Step: 11
Training loss: 1.7971428632736206
Validation loss: 2.175052523612976

Epoch: 6| Step: 12
Training loss: 2.775225877761841
Validation loss: 2.1761308113733926

Epoch: 6| Step: 13
Training loss: 2.7132420539855957
Validation loss: 2.1697500149408975

Epoch: 11| Step: 0
Training loss: 2.2780447006225586
Validation loss: 2.146807154019674

Epoch: 6| Step: 1
Training loss: 2.715453624725342
Validation loss: 2.1287646293640137

Epoch: 6| Step: 2
Training loss: 1.639546275138855
Validation loss: 2.1464757720629373

Epoch: 6| Step: 3
Training loss: 2.1895382404327393
Validation loss: 2.1757147312164307

Epoch: 6| Step: 4
Training loss: 2.5495758056640625
Validation loss: 2.1638635396957397

Epoch: 6| Step: 5
Training loss: 2.845674991607666
Validation loss: 2.1669492522875466

Epoch: 6| Step: 6
Training loss: 1.5872461795806885
Validation loss: 2.168172856171926

Epoch: 6| Step: 7
Training loss: 2.0463719367980957
Validation loss: 2.1512728134791055

Epoch: 6| Step: 8
Training loss: 2.6478374004364014
Validation loss: 2.1668599247932434

Epoch: 6| Step: 9
Training loss: 2.6186423301696777
Validation loss: 2.16674013932546

Epoch: 6| Step: 10
Training loss: 2.3863205909729004
Validation loss: 2.143784999847412

Epoch: 6| Step: 11
Training loss: 1.9371705055236816
Validation loss: 2.1500725944836936

Epoch: 6| Step: 12
Training loss: 2.229804039001465
Validation loss: 2.1359052260716758

Epoch: 6| Step: 13
Training loss: 2.3677473068237305
Validation loss: 2.1794761419296265

Epoch: 12| Step: 0
Training loss: 1.8311283588409424
Validation loss: 2.154067059357961

Epoch: 6| Step: 1
Training loss: 2.40152645111084
Validation loss: 2.152028739452362

Epoch: 6| Step: 2
Training loss: 2.1041007041931152
Validation loss: 2.1447654366493225

Epoch: 6| Step: 3
Training loss: 2.3144454956054688
Validation loss: 2.166970173517863

Epoch: 6| Step: 4
Training loss: 2.5559425354003906
Validation loss: 2.1714455684026084

Epoch: 6| Step: 5
Training loss: 2.704594612121582
Validation loss: 2.183171331882477

Epoch: 6| Step: 6
Training loss: 1.3654916286468506
Validation loss: 2.1717217763264975

Epoch: 6| Step: 7
Training loss: 2.2401123046875
Validation loss: 2.194774031639099

Epoch: 6| Step: 8
Training loss: 2.498758316040039
Validation loss: 2.1740795771280923

Epoch: 6| Step: 9
Training loss: 2.562147378921509
Validation loss: 2.1841546297073364

Epoch: 6| Step: 10
Training loss: 2.321530342102051
Validation loss: 2.1700883309046426

Epoch: 6| Step: 11
Training loss: 2.0703091621398926
Validation loss: 2.1940701007843018

Epoch: 6| Step: 12
Training loss: 2.181776523590088
Validation loss: 2.153737564881643

Epoch: 6| Step: 13
Training loss: 2.082845687866211
Validation loss: 2.138947347799937

Epoch: 13| Step: 0
Training loss: 2.746142864227295
Validation loss: 2.1398017605145774

Epoch: 6| Step: 1
Training loss: 2.5660598278045654
Validation loss: 2.136841336886088

Epoch: 6| Step: 2
Training loss: 2.920801877975464
Validation loss: 2.1198505957921348

Epoch: 6| Step: 3
Training loss: 2.710385799407959
Validation loss: 2.120068669319153

Epoch: 6| Step: 4
Training loss: 2.511970043182373
Validation loss: 2.1323670148849487

Epoch: 6| Step: 5
Training loss: 2.0290207862854004
Validation loss: 2.121789534886678

Epoch: 6| Step: 6
Training loss: 2.0554356575012207
Validation loss: 2.135692000389099

Epoch: 6| Step: 7
Training loss: 1.8421837091445923
Validation loss: 2.11306631565094

Epoch: 6| Step: 8
Training loss: 1.738787055015564
Validation loss: 2.124191462993622

Epoch: 6| Step: 9
Training loss: 1.5692245960235596
Validation loss: 2.109563966592153

Epoch: 6| Step: 10
Training loss: 1.4845657348632812
Validation loss: 2.105545143286387

Epoch: 6| Step: 11
Training loss: 2.641716480255127
Validation loss: 2.1055950919787088

Epoch: 6| Step: 12
Training loss: 1.8877400159835815
Validation loss: 2.1108376185099282

Epoch: 6| Step: 13
Training loss: 1.6403770446777344
Validation loss: 2.116154054800669

Epoch: 14| Step: 0
Training loss: 2.165699005126953
Validation loss: 2.137246330579122

Epoch: 6| Step: 1
Training loss: 1.8650455474853516
Validation loss: 2.0991408030192056

Epoch: 6| Step: 2
Training loss: 2.212462902069092
Validation loss: 2.1051779786745706

Epoch: 6| Step: 3
Training loss: 2.2590761184692383
Validation loss: 2.14734548330307

Epoch: 6| Step: 4
Training loss: 2.251993179321289
Validation loss: 2.1244738896687827

Epoch: 6| Step: 5
Training loss: 1.6918549537658691
Validation loss: 2.128268321355184

Epoch: 6| Step: 6
Training loss: 2.6851511001586914
Validation loss: 2.110765000184377

Epoch: 6| Step: 7
Training loss: 2.6563596725463867
Validation loss: 2.1281795104344687

Epoch: 6| Step: 8
Training loss: 2.0243120193481445
Validation loss: 2.1124181747436523

Epoch: 6| Step: 9
Training loss: 1.4466432332992554
Validation loss: 2.1506757537523904

Epoch: 6| Step: 10
Training loss: 2.584606170654297
Validation loss: 2.1545897126197815

Epoch: 6| Step: 11
Training loss: 2.332620143890381
Validation loss: 2.103192687034607

Epoch: 6| Step: 12
Training loss: 2.067847728729248
Validation loss: 2.103218058745066

Epoch: 6| Step: 13
Training loss: 2.234926462173462
Validation loss: 2.1243516405423484

Epoch: 15| Step: 0
Training loss: 2.1908938884735107
Validation loss: 2.1008551915486655

Epoch: 6| Step: 1
Training loss: 1.8893475532531738
Validation loss: 2.1209882299105325

Epoch: 6| Step: 2
Training loss: 2.9721527099609375
Validation loss: 2.0871419509251914

Epoch: 6| Step: 3
Training loss: 2.260183811187744
Validation loss: 2.082949976126353

Epoch: 6| Step: 4
Training loss: 2.103487491607666
Validation loss: 2.115979174772898

Epoch: 6| Step: 5
Training loss: 1.4440312385559082
Validation loss: 2.1448830167452493

Epoch: 6| Step: 6
Training loss: 1.8415729999542236
Validation loss: 2.1043829321861267

Epoch: 6| Step: 7
Training loss: 1.9160183668136597
Validation loss: 2.0993648171424866

Epoch: 6| Step: 8
Training loss: 1.6795594692230225
Validation loss: 2.1034435828526816

Epoch: 6| Step: 9
Training loss: 1.9904944896697998
Validation loss: 2.111994425455729

Epoch: 6| Step: 10
Training loss: 2.1658544540405273
Validation loss: 2.0813311537106833

Epoch: 6| Step: 11
Training loss: 1.8471418619155884
Validation loss: 2.115454932053884

Epoch: 6| Step: 12
Training loss: 2.623046398162842
Validation loss: 2.112153788407644

Epoch: 6| Step: 13
Training loss: 2.6008682250976562
Validation loss: 2.097498377164205

Epoch: 16| Step: 0
Training loss: 2.3812379837036133
Validation loss: 2.0821407238642373

Epoch: 6| Step: 1
Training loss: 1.9286620616912842
Validation loss: 2.098164439201355

Epoch: 6| Step: 2
Training loss: 1.8930364847183228
Validation loss: 2.0927772323290506

Epoch: 6| Step: 3
Training loss: 2.2263383865356445
Validation loss: 2.0940871834754944

Epoch: 6| Step: 4
Training loss: 2.263826847076416
Validation loss: 2.095073103904724

Epoch: 6| Step: 5
Training loss: 2.0657875537872314
Validation loss: 2.1088481545448303

Epoch: 6| Step: 6
Training loss: 2.321802854537964
Validation loss: 2.1057567596435547

Epoch: 6| Step: 7
Training loss: 2.2894105911254883
Validation loss: 2.0982696612675986

Epoch: 6| Step: 8
Training loss: 1.9936257600784302
Validation loss: 2.1011326909065247

Epoch: 6| Step: 9
Training loss: 1.7586047649383545
Validation loss: 2.0972647269566855

Epoch: 6| Step: 10
Training loss: 2.2206809520721436
Validation loss: 2.0835768779118857

Epoch: 6| Step: 11
Training loss: 2.0969595909118652
Validation loss: 2.1016908486684165

Epoch: 6| Step: 12
Training loss: 2.573586940765381
Validation loss: 2.078105330467224

Epoch: 6| Step: 13
Training loss: 1.6104183197021484
Validation loss: 2.0981180667877197

Epoch: 17| Step: 0
Training loss: 2.710437059402466
Validation loss: 2.083871146043142

Epoch: 6| Step: 1
Training loss: 1.8850001096725464
Validation loss: 2.0757270455360413

Epoch: 6| Step: 2
Training loss: 2.4036343097686768
Validation loss: 2.10038161277771

Epoch: 6| Step: 3
Training loss: 2.1358628273010254
Validation loss: 2.075150728225708

Epoch: 6| Step: 4
Training loss: 2.0842771530151367
Validation loss: 2.095430870850881

Epoch: 6| Step: 5
Training loss: 2.3849048614501953
Validation loss: 2.07443376382192

Epoch: 6| Step: 6
Training loss: 1.456205129623413
Validation loss: 2.1118807593981423

Epoch: 6| Step: 7
Training loss: 2.9346351623535156
Validation loss: 2.059021234512329

Epoch: 6| Step: 8
Training loss: 1.8770852088928223
Validation loss: 2.0985239346822104

Epoch: 6| Step: 9
Training loss: 1.5655947923660278
Validation loss: 2.0790141423543296

Epoch: 6| Step: 10
Training loss: 1.7535407543182373
Validation loss: 2.0797654390335083

Epoch: 6| Step: 11
Training loss: 1.2887489795684814
Validation loss: 2.1032169262568154

Epoch: 6| Step: 12
Training loss: 2.4582536220550537
Validation loss: 2.0808510184288025

Epoch: 6| Step: 13
Training loss: 2.6223156452178955
Validation loss: 2.109180192152659

Epoch: 18| Step: 0
Training loss: 2.0732154846191406
Validation loss: 2.1071430842081704

Epoch: 6| Step: 1
Training loss: 1.8458268642425537
Validation loss: 2.0927204291025796

Epoch: 6| Step: 2
Training loss: 1.558150053024292
Validation loss: 2.1162743171056113

Epoch: 6| Step: 3
Training loss: 2.3244247436523438
Validation loss: 2.106857180595398

Epoch: 6| Step: 4
Training loss: 1.8155770301818848
Validation loss: 2.1288806398709617

Epoch: 6| Step: 5
Training loss: 1.563899278640747
Validation loss: 2.067848563194275

Epoch: 6| Step: 6
Training loss: 2.1288211345672607
Validation loss: 2.1008307337760925

Epoch: 6| Step: 7
Training loss: 2.3612191677093506
Validation loss: 2.0935394565264382

Epoch: 6| Step: 8
Training loss: 1.6241521835327148
Validation loss: 2.1145466963450112

Epoch: 6| Step: 9
Training loss: 2.0338997840881348
Validation loss: 2.078446646531423

Epoch: 6| Step: 10
Training loss: 2.7383434772491455
Validation loss: 2.1166266202926636

Epoch: 6| Step: 11
Training loss: 1.8209614753723145
Validation loss: 2.12595933675766

Epoch: 6| Step: 12
Training loss: 3.4133477210998535
Validation loss: 2.127695322036743

Epoch: 6| Step: 13
Training loss: 1.9624030590057373
Validation loss: 2.1036341389020285

Epoch: 19| Step: 0
Training loss: 1.9854114055633545
Validation loss: 2.147327403227488

Epoch: 6| Step: 1
Training loss: 1.459177017211914
Validation loss: 2.1050449212392173

Epoch: 6| Step: 2
Training loss: 2.3181493282318115
Validation loss: 2.1010541319847107

Epoch: 6| Step: 3
Training loss: 1.6424431800842285
Validation loss: 2.109824558099111

Epoch: 6| Step: 4
Training loss: 1.7225501537322998
Validation loss: 2.095443606376648

Epoch: 6| Step: 5
Training loss: 1.9792078733444214
Validation loss: 2.1227200031280518

Epoch: 6| Step: 6
Training loss: 1.4828823804855347
Validation loss: 2.061786393324534

Epoch: 6| Step: 7
Training loss: 2.5741333961486816
Validation loss: 2.1000707348187766

Epoch: 6| Step: 8
Training loss: 2.566896438598633
Validation loss: 2.055841247240702

Epoch: 6| Step: 9
Training loss: 2.088134527206421
Validation loss: 2.0732152462005615

Epoch: 6| Step: 10
Training loss: 2.436589479446411
Validation loss: 2.075608770052592

Epoch: 6| Step: 11
Training loss: 1.5413362979888916
Validation loss: 2.090625504652659

Epoch: 6| Step: 12
Training loss: 2.619168519973755
Validation loss: 2.0884010791778564

Epoch: 6| Step: 13
Training loss: 2.288412094116211
Validation loss: 2.102079172929128

Epoch: 20| Step: 0
Training loss: 2.1236214637756348
Validation loss: 2.0937406023343406

Epoch: 6| Step: 1
Training loss: 2.245504379272461
Validation loss: 2.11591104666392

Epoch: 6| Step: 2
Training loss: 2.026275634765625
Validation loss: 2.0777649680773416

Epoch: 6| Step: 3
Training loss: 1.6072970628738403
Validation loss: 2.0951042970021567

Epoch: 6| Step: 4
Training loss: 2.612199544906616
Validation loss: 2.1011735002199807

Epoch: 6| Step: 5
Training loss: 2.4175429344177246
Validation loss: 2.10450679063797

Epoch: 6| Step: 6
Training loss: 2.1520869731903076
Validation loss: 2.104963501294454

Epoch: 6| Step: 7
Training loss: 1.8029497861862183
Validation loss: 2.0773462851842246

Epoch: 6| Step: 8
Training loss: 2.6924049854278564
Validation loss: 2.0798529982566833

Epoch: 6| Step: 9
Training loss: 1.6962612867355347
Validation loss: 2.0931309858957925

Epoch: 6| Step: 10
Training loss: 1.4200387001037598
Validation loss: 2.0802540381749473

Epoch: 6| Step: 11
Training loss: 1.4807236194610596
Validation loss: 2.086474517981211

Epoch: 6| Step: 12
Training loss: 2.4522571563720703
Validation loss: 2.078904310862223

Epoch: 6| Step: 13
Training loss: 2.042964220046997
Validation loss: 2.0647852222124734

Epoch: 21| Step: 0
Training loss: 1.1920342445373535
Validation loss: 2.0943780740102134

Epoch: 6| Step: 1
Training loss: 2.409787654876709
Validation loss: 2.0742129484812417

Epoch: 6| Step: 2
Training loss: 1.519115924835205
Validation loss: 2.0969398419062295

Epoch: 6| Step: 3
Training loss: 2.412034034729004
Validation loss: 2.1083770990371704

Epoch: 6| Step: 4
Training loss: 2.74556565284729
Validation loss: 2.0471022923787436

Epoch: 6| Step: 5
Training loss: 2.6235172748565674
Validation loss: 2.11511758963267

Epoch: 6| Step: 6
Training loss: 1.9465415477752686
Validation loss: 2.0945908625920615

Epoch: 6| Step: 7
Training loss: 2.0970945358276367
Validation loss: 2.0911754171053567

Epoch: 6| Step: 8
Training loss: 2.3160743713378906
Validation loss: 2.0969329873720803

Epoch: 6| Step: 9
Training loss: 2.060392141342163
Validation loss: 2.12643301486969

Epoch: 6| Step: 10
Training loss: 2.253005266189575
Validation loss: 2.0572575330734253

Epoch: 6| Step: 11
Training loss: 1.594845175743103
Validation loss: 2.1071380376815796

Epoch: 6| Step: 12
Training loss: 1.9782906770706177
Validation loss: 2.0805782079696655

Epoch: 6| Step: 13
Training loss: 1.759848713874817
Validation loss: 2.070929169654846

Epoch: 22| Step: 0
Training loss: 2.3727033138275146
Validation loss: 2.0894373257954917

Epoch: 6| Step: 1
Training loss: 1.4901986122131348
Validation loss: 2.0887194871902466

Epoch: 6| Step: 2
Training loss: 1.7216980457305908
Validation loss: 2.045806586742401

Epoch: 6| Step: 3
Training loss: 1.7565488815307617
Validation loss: 2.0771095951398215

Epoch: 6| Step: 4
Training loss: 2.5315136909484863
Validation loss: 2.105956753094991

Epoch: 6| Step: 5
Training loss: 1.8227930068969727
Validation loss: 2.095981478691101

Epoch: 6| Step: 6
Training loss: 2.6173489093780518
Validation loss: 2.117318650086721

Epoch: 6| Step: 7
Training loss: 1.5414729118347168
Validation loss: 2.113803823788961

Epoch: 6| Step: 8
Training loss: 2.0268375873565674
Validation loss: 2.077063024044037

Epoch: 6| Step: 9
Training loss: 2.0336055755615234
Validation loss: 2.0847995281219482

Epoch: 6| Step: 10
Training loss: 1.70533287525177
Validation loss: 2.085425853729248

Epoch: 6| Step: 11
Training loss: 2.5428366661071777
Validation loss: 2.090356190999349

Epoch: 6| Step: 12
Training loss: 2.210982322692871
Validation loss: 2.059615433216095

Epoch: 6| Step: 13
Training loss: 2.1562154293060303
Validation loss: 2.100437124570211

Epoch: 23| Step: 0
Training loss: 1.4218003749847412
Validation loss: 2.09334001938502

Epoch: 6| Step: 1
Training loss: 2.706160068511963
Validation loss: 2.086801906426748

Epoch: 6| Step: 2
Training loss: 1.8976690769195557
Validation loss: 2.046426316102346

Epoch: 6| Step: 3
Training loss: 1.8904668092727661
Validation loss: 2.0509322683016458

Epoch: 6| Step: 4
Training loss: 2.0735223293304443
Validation loss: 2.0784494479497275

Epoch: 6| Step: 5
Training loss: 1.9496581554412842
Validation loss: 2.1083733240763345

Epoch: 6| Step: 6
Training loss: 2.212052822113037
Validation loss: 2.087530732154846

Epoch: 6| Step: 7
Training loss: 2.355799674987793
Validation loss: 2.062351723512014

Epoch: 6| Step: 8
Training loss: 1.635535478591919
Validation loss: 2.085626741250356

Epoch: 6| Step: 9
Training loss: 1.7131233215332031
Validation loss: 2.08102677265803

Epoch: 6| Step: 10
Training loss: 2.3628787994384766
Validation loss: 2.081920087337494

Epoch: 6| Step: 11
Training loss: 1.847327470779419
Validation loss: 2.0500794847806296

Epoch: 6| Step: 12
Training loss: 2.105924606323242
Validation loss: 2.086678663889567

Epoch: 6| Step: 13
Training loss: 2.2454142570495605
Validation loss: 2.0749785701433816

Epoch: 24| Step: 0
Training loss: 1.6375536918640137
Validation loss: 2.1096835335095725

Epoch: 6| Step: 1
Training loss: 2.2796638011932373
Validation loss: 2.1084271470705667

Epoch: 6| Step: 2
Training loss: 1.7765183448791504
Validation loss: 2.1146410504976907

Epoch: 6| Step: 3
Training loss: 1.775929570198059
Validation loss: 2.074837585290273

Epoch: 6| Step: 4
Training loss: 1.7765533924102783
Validation loss: 2.079537053902944

Epoch: 6| Step: 5
Training loss: 2.321829319000244
Validation loss: 2.1582497159639993

Epoch: 6| Step: 6
Training loss: 1.67604660987854
Validation loss: 2.0769081910451255

Epoch: 6| Step: 7
Training loss: 2.7725536823272705
Validation loss: 2.064475138982137

Epoch: 6| Step: 8
Training loss: 2.615243434906006
Validation loss: 2.0669596989949546

Epoch: 6| Step: 9
Training loss: 1.9982811212539673
Validation loss: 2.098253051439921

Epoch: 6| Step: 10
Training loss: 2.2368078231811523
Validation loss: 2.0798112750053406

Epoch: 6| Step: 11
Training loss: 2.061730146408081
Validation loss: 2.087405204772949

Epoch: 6| Step: 12
Training loss: 2.257158041000366
Validation loss: 2.090860923131307

Epoch: 6| Step: 13
Training loss: 1.710679054260254
Validation loss: 2.0650293827056885

Epoch: 25| Step: 0
Training loss: 2.0439178943634033
Validation loss: 2.114786942799886

Epoch: 6| Step: 1
Training loss: 2.029834747314453
Validation loss: 2.102289398511251

Epoch: 6| Step: 2
Training loss: 2.1115856170654297
Validation loss: 2.068218012650808

Epoch: 6| Step: 3
Training loss: 1.6292436122894287
Validation loss: 2.039872328440348

Epoch: 6| Step: 4
Training loss: 1.633366584777832
Validation loss: 2.0808370113372803

Epoch: 6| Step: 5
Training loss: 3.090017318725586
Validation loss: 2.1185177167256675

Epoch: 6| Step: 6
Training loss: 1.8998953104019165
Validation loss: 2.092488169670105

Epoch: 6| Step: 7
Training loss: 1.3956527709960938
Validation loss: 2.097774386405945

Epoch: 6| Step: 8
Training loss: 2.3263237476348877
Validation loss: 2.087506632010142

Epoch: 6| Step: 9
Training loss: 2.2163782119750977
Validation loss: 2.080076893170675

Epoch: 6| Step: 10
Training loss: 1.7600983381271362
Validation loss: 2.0383288065592446

Epoch: 6| Step: 11
Training loss: 2.398059129714966
Validation loss: 2.0716514786084494

Epoch: 6| Step: 12
Training loss: 1.9141708612442017
Validation loss: 2.0822933117548623

Epoch: 6| Step: 13
Training loss: 1.8305729627609253
Validation loss: 2.1020742456118264

Epoch: 26| Step: 0
Training loss: 2.3666417598724365
Validation loss: 2.0745218992233276

Epoch: 6| Step: 1
Training loss: 1.0360345840454102
Validation loss: 2.0607484380404153

Epoch: 6| Step: 2
Training loss: 1.9582828283309937
Validation loss: 2.108637054761251

Epoch: 6| Step: 3
Training loss: 2.0164709091186523
Validation loss: 2.041625956694285

Epoch: 6| Step: 4
Training loss: 2.2220566272735596
Validation loss: 2.0512938698132834

Epoch: 6| Step: 5
Training loss: 2.760183811187744
Validation loss: 2.091569483280182

Epoch: 6| Step: 6
Training loss: 1.6411150693893433
Validation loss: 2.061033566792806

Epoch: 6| Step: 7
Training loss: 2.5234408378601074
Validation loss: 2.1316685875256858

Epoch: 6| Step: 8
Training loss: 1.8297910690307617
Validation loss: 2.0984297593434653

Epoch: 6| Step: 9
Training loss: 2.260573148727417
Validation loss: 2.1023224592208862

Epoch: 6| Step: 10
Training loss: 1.898424506187439
Validation loss: 2.093283772468567

Epoch: 6| Step: 11
Training loss: 1.876899003982544
Validation loss: 2.0629838506380715

Epoch: 6| Step: 12
Training loss: 1.3183434009552002
Validation loss: 2.062660833199819

Epoch: 6| Step: 13
Training loss: 2.431364059448242
Validation loss: 2.0477330485979715

Epoch: 27| Step: 0
Training loss: 1.7638018131256104
Validation loss: 2.0781182249387107

Epoch: 6| Step: 1
Training loss: 1.3571714162826538
Validation loss: 2.09857439994812

Epoch: 6| Step: 2
Training loss: 2.292163133621216
Validation loss: 2.1023521622021994

Epoch: 6| Step: 3
Training loss: 2.1148557662963867
Validation loss: 2.0885153810183206

Epoch: 6| Step: 4
Training loss: 1.9649097919464111
Validation loss: 2.1119778156280518

Epoch: 6| Step: 5
Training loss: 1.9696495532989502
Validation loss: 2.1097660263379416

Epoch: 6| Step: 6
Training loss: 2.211843490600586
Validation loss: 2.058987617492676

Epoch: 6| Step: 7
Training loss: 2.2917351722717285
Validation loss: 2.1079918146133423

Epoch: 6| Step: 8
Training loss: 1.834720492362976
Validation loss: 2.0521401166915894

Epoch: 6| Step: 9
Training loss: 1.9703524112701416
Validation loss: 2.0845879515012107

Epoch: 6| Step: 10
Training loss: 2.2795650959014893
Validation loss: 2.0694782932599387

Epoch: 6| Step: 11
Training loss: 2.172147750854492
Validation loss: 2.082266688346863

Epoch: 6| Step: 12
Training loss: 1.6718891859054565
Validation loss: 2.0941332976023355

Epoch: 6| Step: 13
Training loss: 2.2383852005004883
Validation loss: 2.138176659742991

Epoch: 28| Step: 0
Training loss: 1.966475248336792
Validation loss: 2.098435699939728

Epoch: 6| Step: 1
Training loss: 2.691823720932007
Validation loss: 2.108504335085551

Epoch: 6| Step: 2
Training loss: 1.8376715183258057
Validation loss: 2.061590850353241

Epoch: 6| Step: 3
Training loss: 1.4164490699768066
Validation loss: 2.0550492207209268

Epoch: 6| Step: 4
Training loss: 1.8531062602996826
Validation loss: 2.1050791144371033

Epoch: 6| Step: 5
Training loss: 1.9177680015563965
Validation loss: 2.1188196341196694

Epoch: 6| Step: 6
Training loss: 1.7179694175720215
Validation loss: 2.0839910904566445

Epoch: 6| Step: 7
Training loss: 1.6680190563201904
Validation loss: 2.085621654987335

Epoch: 6| Step: 8
Training loss: 2.17143177986145
Validation loss: 2.1097314755121865

Epoch: 6| Step: 9
Training loss: 1.90339195728302
Validation loss: 2.0817809104919434

Epoch: 6| Step: 10
Training loss: 1.9910471439361572
Validation loss: 2.0643652280171714

Epoch: 6| Step: 11
Training loss: 2.141404628753662
Validation loss: 2.1137219270070395

Epoch: 6| Step: 12
Training loss: 2.4849886894226074
Validation loss: 2.089776794115702

Epoch: 6| Step: 13
Training loss: 2.257634162902832
Validation loss: 2.0780667662620544

Epoch: 29| Step: 0
Training loss: 2.052135467529297
Validation loss: 2.0299379030863443

Epoch: 6| Step: 1
Training loss: 1.588097095489502
Validation loss: 2.078187624613444

Epoch: 6| Step: 2
Training loss: 1.8633095026016235
Validation loss: 2.103083590666453

Epoch: 6| Step: 3
Training loss: 2.1142773628234863
Validation loss: 2.12869393825531

Epoch: 6| Step: 4
Training loss: 1.7770841121673584
Validation loss: 2.113049407800039

Epoch: 6| Step: 5
Training loss: 2.2420687675476074
Validation loss: 2.129232406616211

Epoch: 6| Step: 6
Training loss: 2.8607890605926514
Validation loss: 2.0815897782643638

Epoch: 6| Step: 7
Training loss: 1.9095680713653564
Validation loss: 2.0858561595280967

Epoch: 6| Step: 8
Training loss: 2.0244908332824707
Validation loss: 2.0655145049095154

Epoch: 6| Step: 9
Training loss: 1.8644764423370361
Validation loss: 2.089165727297465

Epoch: 6| Step: 10
Training loss: 1.910865306854248
Validation loss: 2.0845195849736533

Epoch: 6| Step: 11
Training loss: 1.778232455253601
Validation loss: 2.0868179400761924

Epoch: 6| Step: 12
Training loss: 2.277698278427124
Validation loss: 2.087526798248291

Epoch: 6| Step: 13
Training loss: 1.6416513919830322
Validation loss: 2.064310828844706

Epoch: 30| Step: 0
Training loss: 1.7896711826324463
Validation loss: 2.0907177925109863

Epoch: 6| Step: 1
Training loss: 1.9640504121780396
Validation loss: 2.1280221740404763

Epoch: 6| Step: 2
Training loss: 2.358339786529541
Validation loss: 2.0926135579744973

Epoch: 6| Step: 3
Training loss: 1.3621944189071655
Validation loss: 2.112393776575724

Epoch: 6| Step: 4
Training loss: 2.2500247955322266
Validation loss: 2.105942686398824

Epoch: 6| Step: 5
Training loss: 1.8884282112121582
Validation loss: 2.0825732151667276

Epoch: 6| Step: 6
Training loss: 2.354418992996216
Validation loss: 2.0895347197850547

Epoch: 6| Step: 7
Training loss: 1.269469976425171
Validation loss: 2.0636525750160217

Epoch: 6| Step: 8
Training loss: 1.5183981657028198
Validation loss: 2.1182984511057534

Epoch: 6| Step: 9
Training loss: 2.37079119682312
Validation loss: 2.08056902885437

Epoch: 6| Step: 10
Training loss: 1.5238540172576904
Validation loss: 2.1294414599736533

Epoch: 6| Step: 11
Training loss: 2.144166946411133
Validation loss: 2.120318055152893

Epoch: 6| Step: 12
Training loss: 2.359496593475342
Validation loss: 2.0825814803441367

Epoch: 6| Step: 13
Training loss: 2.654296398162842
Validation loss: 2.101155638694763

Epoch: 31| Step: 0
Training loss: 2.0604190826416016
Validation loss: 2.090913772583008

Epoch: 6| Step: 1
Training loss: 2.986778736114502
Validation loss: 2.1432284911473594

Epoch: 6| Step: 2
Training loss: 2.184800624847412
Validation loss: 2.106691300868988

Epoch: 6| Step: 3
Training loss: 1.174722671508789
Validation loss: 2.0998563170433044

Epoch: 6| Step: 4
Training loss: 1.8710548877716064
Validation loss: 2.1175222794214883

Epoch: 6| Step: 5
Training loss: 1.2107539176940918
Validation loss: 2.1238075494766235

Epoch: 6| Step: 6
Training loss: 2.2698559761047363
Validation loss: 2.144564966360728

Epoch: 6| Step: 7
Training loss: 1.79947030544281
Validation loss: 2.100126624107361

Epoch: 6| Step: 8
Training loss: 2.177474021911621
Validation loss: 2.0845610896746316

Epoch: 6| Step: 9
Training loss: 1.5732979774475098
Validation loss: 2.1156382163365683

Epoch: 6| Step: 10
Training loss: 2.5291457176208496
Validation loss: 2.178876280784607

Epoch: 6| Step: 11
Training loss: 2.4249863624572754
Validation loss: 2.093455215295156

Epoch: 6| Step: 12
Training loss: 2.242480516433716
Validation loss: 2.1192251642545066

Epoch: 6| Step: 13
Training loss: 1.838256597518921
Validation loss: 2.095394949118296

Epoch: 32| Step: 0
Training loss: 1.6041107177734375
Validation loss: 2.061273197333018

Epoch: 6| Step: 1
Training loss: 1.9895365238189697
Validation loss: 2.153001606464386

Epoch: 6| Step: 2
Training loss: 2.113138198852539
Validation loss: 2.1543096701304116

Epoch: 6| Step: 3
Training loss: 3.0156359672546387
Validation loss: 2.1833131313323975

Epoch: 6| Step: 4
Training loss: 1.894934058189392
Validation loss: 2.1881666580835977

Epoch: 6| Step: 5
Training loss: 2.8481972217559814
Validation loss: 2.126512130101522

Epoch: 6| Step: 6
Training loss: 1.9111511707305908
Validation loss: 2.1028051575024924

Epoch: 6| Step: 7
Training loss: 1.9661381244659424
Validation loss: 2.087396780649821

Epoch: 6| Step: 8
Training loss: 1.9195380210876465
Validation loss: 2.1018508672714233

Epoch: 6| Step: 9
Training loss: 1.6399497985839844
Validation loss: 2.08243594566981

Epoch: 6| Step: 10
Training loss: 1.9900513887405396
Validation loss: 2.0866103967030845

Epoch: 6| Step: 11
Training loss: 2.4366865158081055
Validation loss: 2.1056281526883445

Epoch: 6| Step: 12
Training loss: 1.3213832378387451
Validation loss: 2.08888041973114

Epoch: 6| Step: 13
Training loss: 1.8242487907409668
Validation loss: 2.0865010619163513

Epoch: 33| Step: 0
Training loss: 1.9124764204025269
Validation loss: 2.0810863971710205

Epoch: 6| Step: 1
Training loss: 1.802171230316162
Validation loss: 2.0850857297579446

Epoch: 6| Step: 2
Training loss: 1.7143170833587646
Validation loss: 2.1249466141064963

Epoch: 6| Step: 3
Training loss: 2.615485668182373
Validation loss: 2.0533003211021423

Epoch: 6| Step: 4
Training loss: 1.9545143842697144
Validation loss: 2.0948365132013955

Epoch: 6| Step: 5
Training loss: 1.9924170970916748
Validation loss: 2.1063448985417685

Epoch: 6| Step: 6
Training loss: 2.0629100799560547
Validation loss: 2.1528040965398154

Epoch: 6| Step: 7
Training loss: 1.3309736251831055
Validation loss: 2.0990628202756247

Epoch: 6| Step: 8
Training loss: 2.0953619480133057
Validation loss: 2.14500230550766

Epoch: 6| Step: 9
Training loss: 1.3903967142105103
Validation loss: 2.057733158270518

Epoch: 6| Step: 10
Training loss: 2.8958663940429688
Validation loss: 2.130335013071696

Epoch: 6| Step: 11
Training loss: 1.5082452297210693
Validation loss: 2.098935862382253

Epoch: 6| Step: 12
Training loss: 1.314355731010437
Validation loss: 2.124074379603068

Epoch: 6| Step: 13
Training loss: 2.8305461406707764
Validation loss: 2.091148316860199

Epoch: 34| Step: 0
Training loss: 1.4417394399642944
Validation loss: 2.0739986499150596

Epoch: 6| Step: 1
Training loss: 2.0114617347717285
Validation loss: 2.1014687220255532

Epoch: 6| Step: 2
Training loss: 2.1567859649658203
Validation loss: 2.086548070112864

Epoch: 6| Step: 3
Training loss: 1.904428482055664
Validation loss: 2.1151298880577087

Epoch: 6| Step: 4
Training loss: 2.0731310844421387
Validation loss: 2.086464444796244

Epoch: 6| Step: 5
Training loss: 1.6154227256774902
Validation loss: 2.072577397028605

Epoch: 6| Step: 6
Training loss: 2.2111668586730957
Validation loss: 2.101458430290222

Epoch: 6| Step: 7
Training loss: 1.5882222652435303
Validation loss: 2.0793747504552207

Epoch: 6| Step: 8
Training loss: 2.3588109016418457
Validation loss: 2.1361136436462402

Epoch: 6| Step: 9
Training loss: 2.0123229026794434
Validation loss: 2.108975907166799

Epoch: 6| Step: 10
Training loss: 1.861390233039856
Validation loss: 2.10599293311437

Epoch: 6| Step: 11
Training loss: 1.7191104888916016
Validation loss: 2.109785477320353

Epoch: 6| Step: 12
Training loss: 2.220731019973755
Validation loss: 2.0743867556254068

Epoch: 6| Step: 13
Training loss: 2.1143956184387207
Validation loss: 2.106283485889435

Epoch: 35| Step: 0
Training loss: 1.8844659328460693
Validation loss: 2.0677791833877563

Epoch: 6| Step: 1
Training loss: 2.83103609085083
Validation loss: 2.1111058394114175

Epoch: 6| Step: 2
Training loss: 2.2649478912353516
Validation loss: 2.0852498412132263

Epoch: 6| Step: 3
Training loss: 1.3637027740478516
Validation loss: 2.100474695364634

Epoch: 6| Step: 4
Training loss: 1.616910457611084
Validation loss: 2.092747688293457

Epoch: 6| Step: 5
Training loss: 2.409534454345703
Validation loss: 2.1029544472694397

Epoch: 6| Step: 6
Training loss: 1.4671776294708252
Validation loss: 2.0633400281270347

Epoch: 6| Step: 7
Training loss: 1.724841594696045
Validation loss: 2.0979837775230408

Epoch: 6| Step: 8
Training loss: 2.2143394947052
Validation loss: 2.111040631930033

Epoch: 6| Step: 9
Training loss: 2.0096373558044434
Validation loss: 2.0872447888056436

Epoch: 6| Step: 10
Training loss: 1.9515340328216553
Validation loss: 2.120077629884084

Epoch: 6| Step: 11
Training loss: 2.206167697906494
Validation loss: 2.1657368540763855

Epoch: 6| Step: 12
Training loss: 1.9264144897460938
Validation loss: 2.124233583609263

Epoch: 6| Step: 13
Training loss: 1.286854863166809
Validation loss: 2.0934693415959678

Epoch: 36| Step: 0
Training loss: 1.5141557455062866
Validation loss: 2.0935340325037637

Epoch: 6| Step: 1
Training loss: 1.5580201148986816
Validation loss: 2.0613842209180198

Epoch: 6| Step: 2
Training loss: 2.08273983001709
Validation loss: 2.088143308957418

Epoch: 6| Step: 3
Training loss: 2.281686782836914
Validation loss: 2.146779398123423

Epoch: 6| Step: 4
Training loss: 2.751349925994873
Validation loss: 2.091670831044515

Epoch: 6| Step: 5
Training loss: 1.62734055519104
Validation loss: 2.066452980041504

Epoch: 6| Step: 6
Training loss: 1.6291416883468628
Validation loss: 2.0993821223576865

Epoch: 6| Step: 7
Training loss: 1.8679368495941162
Validation loss: 2.0498130917549133

Epoch: 6| Step: 8
Training loss: 2.6289873123168945
Validation loss: 2.115329166253408

Epoch: 6| Step: 9
Training loss: 1.9657939672470093
Validation loss: 2.112504243850708

Epoch: 6| Step: 10
Training loss: 1.5511016845703125
Validation loss: 2.123725970586141

Epoch: 6| Step: 11
Training loss: 1.57382071018219
Validation loss: 2.1159421602884927

Epoch: 6| Step: 12
Training loss: 2.2294318675994873
Validation loss: 2.0706353783607483

Epoch: 6| Step: 13
Training loss: 1.8668991327285767
Validation loss: 2.121853510538737

Epoch: 37| Step: 0
Training loss: 1.8985822200775146
Validation loss: 2.11446475982666

Epoch: 6| Step: 1
Training loss: 1.9144237041473389
Validation loss: 2.1185110211372375

Epoch: 6| Step: 2
Training loss: 1.9246692657470703
Validation loss: 2.1085642178853354

Epoch: 6| Step: 3
Training loss: 1.1085658073425293
Validation loss: 2.0769537488619485

Epoch: 6| Step: 4
Training loss: 2.0339677333831787
Validation loss: 2.130389451980591

Epoch: 6| Step: 5
Training loss: 1.7557281255722046
Validation loss: 2.1428646246592202

Epoch: 6| Step: 6
Training loss: 2.224046468734741
Validation loss: 2.138936539491018

Epoch: 6| Step: 7
Training loss: 2.7990970611572266
Validation loss: 2.1965705951054892

Epoch: 6| Step: 8
Training loss: 1.7186779975891113
Validation loss: 2.127232809861501

Epoch: 6| Step: 9
Training loss: 2.058804988861084
Validation loss: 2.1138419111569724

Epoch: 6| Step: 10
Training loss: 2.339461326599121
Validation loss: 2.1062251329421997

Epoch: 6| Step: 11
Training loss: 1.7043664455413818
Validation loss: 2.105260888735453

Epoch: 6| Step: 12
Training loss: 2.2986531257629395
Validation loss: 2.0383469661076865

Epoch: 6| Step: 13
Training loss: 1.9522714614868164
Validation loss: 2.0902217626571655

Epoch: 38| Step: 0
Training loss: 1.970249056816101
Validation loss: 2.094582676887512

Epoch: 6| Step: 1
Training loss: 2.0579967498779297
Validation loss: 2.1088014443715415

Epoch: 6| Step: 2
Training loss: 1.7641005516052246
Validation loss: 2.131990114847819

Epoch: 6| Step: 3
Training loss: 2.530090570449829
Validation loss: 2.118622303009033

Epoch: 6| Step: 4
Training loss: 1.4157569408416748
Validation loss: 2.1158660848935447

Epoch: 6| Step: 5
Training loss: 1.9676055908203125
Validation loss: 2.1119602719942727

Epoch: 6| Step: 6
Training loss: 1.4031240940093994
Validation loss: 2.102031489213308

Epoch: 6| Step: 7
Training loss: 2.633361339569092
Validation loss: 2.136396884918213

Epoch: 6| Step: 8
Training loss: 1.965380311012268
Validation loss: 2.1377583146095276

Epoch: 6| Step: 9
Training loss: 1.810552954673767
Validation loss: 2.065306603908539

Epoch: 6| Step: 10
Training loss: 1.226194143295288
Validation loss: 2.1322689056396484

Epoch: 6| Step: 11
Training loss: 2.150796890258789
Validation loss: 2.078112999598185

Epoch: 6| Step: 12
Training loss: 2.0053932666778564
Validation loss: 2.133761445681254

Epoch: 6| Step: 13
Training loss: 2.3814444541931152
Validation loss: 2.1150975227355957

Epoch: 39| Step: 0
Training loss: 1.724073052406311
Validation loss: 2.1618855794270835

Epoch: 6| Step: 1
Training loss: 2.0884461402893066
Validation loss: 2.1421639919281006

Epoch: 6| Step: 2
Training loss: 2.5431761741638184
Validation loss: 2.1039302945137024

Epoch: 6| Step: 3
Training loss: 1.7424006462097168
Validation loss: 2.085018038749695

Epoch: 6| Step: 4
Training loss: 1.4430882930755615
Validation loss: 2.107981006304423

Epoch: 6| Step: 5
Training loss: 1.9932589530944824
Validation loss: 2.1546622117360434

Epoch: 6| Step: 6
Training loss: 1.6597305536270142
Validation loss: 2.151808420817057

Epoch: 6| Step: 7
Training loss: 1.5833474397659302
Validation loss: 2.1620004574457803

Epoch: 6| Step: 8
Training loss: 1.8512074947357178
Validation loss: 2.1534961462020874

Epoch: 6| Step: 9
Training loss: 1.947072982788086
Validation loss: 2.1173558036486306

Epoch: 6| Step: 10
Training loss: 1.7286758422851562
Validation loss: 2.130716880162557

Epoch: 6| Step: 11
Training loss: 2.4731273651123047
Validation loss: 2.1353755593299866

Epoch: 6| Step: 12
Training loss: 2.6205897331237793
Validation loss: 2.1087057987848916

Epoch: 6| Step: 13
Training loss: 1.6346595287322998
Validation loss: 2.096908748149872

Epoch: 40| Step: 0
Training loss: 2.4067978858947754
Validation loss: 2.118293305238088

Epoch: 6| Step: 1
Training loss: 1.7526814937591553
Validation loss: 2.08208300669988

Epoch: 6| Step: 2
Training loss: 2.1991724967956543
Validation loss: 2.1074124773343406

Epoch: 6| Step: 3
Training loss: 1.9689662456512451
Validation loss: 2.1136884291966758

Epoch: 6| Step: 4
Training loss: 1.8656688928604126
Validation loss: 2.093084732691447

Epoch: 6| Step: 5
Training loss: 2.0758328437805176
Validation loss: 2.1291383703549704

Epoch: 6| Step: 6
Training loss: 1.9496675729751587
Validation loss: 2.1324789921442666

Epoch: 6| Step: 7
Training loss: 1.5587315559387207
Validation loss: 2.102725704511007

Epoch: 6| Step: 8
Training loss: 1.9661602973937988
Validation loss: 2.10787041982015

Epoch: 6| Step: 9
Training loss: 2.1559557914733887
Validation loss: 2.1272725462913513

Epoch: 6| Step: 10
Training loss: 1.7354668378829956
Validation loss: 2.1105793913205466

Epoch: 6| Step: 11
Training loss: 1.8065930604934692
Validation loss: 2.1073386669158936

Epoch: 6| Step: 12
Training loss: 1.8845634460449219
Validation loss: 2.109893560409546

Epoch: 6| Step: 13
Training loss: 1.5633997917175293
Validation loss: 2.0979764660199485

Epoch: 41| Step: 0
Training loss: 1.5978264808654785
Validation loss: 2.1487234036127725

Epoch: 6| Step: 1
Training loss: 1.6433115005493164
Validation loss: 2.1388955116271973

Epoch: 6| Step: 2
Training loss: 1.8988707065582275
Validation loss: 2.108663638432821

Epoch: 6| Step: 3
Training loss: 1.7555882930755615
Validation loss: 2.131154457728068

Epoch: 6| Step: 4
Training loss: 2.477095127105713
Validation loss: 2.1157832741737366

Epoch: 6| Step: 5
Training loss: 1.6270850896835327
Validation loss: 2.135641892751058

Epoch: 6| Step: 6
Training loss: 1.8967232704162598
Validation loss: 2.0815701285998025

Epoch: 6| Step: 7
Training loss: 1.9355528354644775
Validation loss: 2.139924963315328

Epoch: 6| Step: 8
Training loss: 1.992023229598999
Validation loss: 2.171662668387095

Epoch: 6| Step: 9
Training loss: 2.083136558532715
Validation loss: 2.0829857190450034

Epoch: 6| Step: 10
Training loss: 1.914994716644287
Validation loss: 2.110063294569651

Epoch: 6| Step: 11
Training loss: 1.9484760761260986
Validation loss: 2.1379483143488565

Epoch: 6| Step: 12
Training loss: 2.227201461791992
Validation loss: 2.105983793735504

Epoch: 6| Step: 13
Training loss: 2.1623787879943848
Validation loss: 2.143442392349243

Epoch: 42| Step: 0
Training loss: 1.6703144311904907
Validation loss: 2.0885645548502603

Epoch: 6| Step: 1
Training loss: 1.7661482095718384
Validation loss: 2.10538113117218

Epoch: 6| Step: 2
Training loss: 1.4596554040908813
Validation loss: 2.1579262614250183

Epoch: 6| Step: 3
Training loss: 1.862626075744629
Validation loss: 2.149990220864614

Epoch: 6| Step: 4
Training loss: 2.7459158897399902
Validation loss: 2.1073999802271524

Epoch: 6| Step: 5
Training loss: 1.2955222129821777
Validation loss: 2.147575577100118

Epoch: 6| Step: 6
Training loss: 2.0348873138427734
Validation loss: 2.110408127307892

Epoch: 6| Step: 7
Training loss: 2.2900729179382324
Validation loss: 2.1317202051480613

Epoch: 6| Step: 8
Training loss: 2.6910507678985596
Validation loss: 2.123532791932424

Epoch: 6| Step: 9
Training loss: 1.724281668663025
Validation loss: 2.13786772886912

Epoch: 6| Step: 10
Training loss: 2.1379051208496094
Validation loss: 2.1248828768730164

Epoch: 6| Step: 11
Training loss: 1.729630470275879
Validation loss: 2.1281455556551614

Epoch: 6| Step: 12
Training loss: 1.6727685928344727
Validation loss: 2.1143781344095864

Epoch: 6| Step: 13
Training loss: 2.409475326538086
Validation loss: 2.1730554699897766

Epoch: 43| Step: 0
Training loss: 1.5505564212799072
Validation loss: 2.1159948110580444

Epoch: 6| Step: 1
Training loss: 1.701923131942749
Validation loss: 2.1066771348317466

Epoch: 6| Step: 2
Training loss: 2.1312687397003174
Validation loss: 2.1339394052823386

Epoch: 6| Step: 3
Training loss: 1.7018404006958008
Validation loss: 2.178851226965586

Epoch: 6| Step: 4
Training loss: 1.9433972835540771
Validation loss: 2.169089436531067

Epoch: 6| Step: 5
Training loss: 2.6318531036376953
Validation loss: 2.2399536768595376

Epoch: 6| Step: 6
Training loss: 1.8565524816513062
Validation loss: 2.1975513895352683

Epoch: 6| Step: 7
Training loss: 2.6579246520996094
Validation loss: 2.2394423286120095

Epoch: 6| Step: 8
Training loss: 2.396141529083252
Validation loss: 2.234160383542379

Epoch: 6| Step: 9
Training loss: 2.4475820064544678
Validation loss: 2.171908140182495

Epoch: 6| Step: 10
Training loss: 1.760522723197937
Validation loss: 2.1667074958483377

Epoch: 6| Step: 11
Training loss: 1.2951326370239258
Validation loss: 2.104689876238505

Epoch: 6| Step: 12
Training loss: 1.8812956809997559
Validation loss: 2.143278479576111

Epoch: 6| Step: 13
Training loss: 1.5568238496780396
Validation loss: 2.1516947547594705

Epoch: 44| Step: 0
Training loss: 2.1237852573394775
Validation loss: 2.101539393266042

Epoch: 6| Step: 1
Training loss: 1.929502248764038
Validation loss: 2.1437838872273765

Epoch: 6| Step: 2
Training loss: 1.6472350358963013
Validation loss: 2.093825618426005

Epoch: 6| Step: 3
Training loss: 1.3140918016433716
Validation loss: 2.1247246464093528

Epoch: 6| Step: 4
Training loss: 2.017956018447876
Validation loss: 2.108893950780233

Epoch: 6| Step: 5
Training loss: 1.7560162544250488
Validation loss: 2.106461524963379

Epoch: 6| Step: 6
Training loss: 1.9497559070587158
Validation loss: 2.0900598764419556

Epoch: 6| Step: 7
Training loss: 1.719740867614746
Validation loss: 2.0989594062169394

Epoch: 6| Step: 8
Training loss: 2.4115171432495117
Validation loss: 2.0844239592552185

Epoch: 6| Step: 9
Training loss: 2.1488120555877686
Validation loss: 2.104123890399933

Epoch: 6| Step: 10
Training loss: 1.992689847946167
Validation loss: 2.0985373655954995

Epoch: 6| Step: 11
Training loss: 2.3107104301452637
Validation loss: 2.1436615586280823

Epoch: 6| Step: 12
Training loss: 1.649288296699524
Validation loss: 2.130796710650126

Epoch: 6| Step: 13
Training loss: 1.8518786430358887
Validation loss: 2.167141536871592

Epoch: 45| Step: 0
Training loss: 1.9141029119491577
Validation loss: 2.1865921020507812

Epoch: 6| Step: 1
Training loss: 1.5755069255828857
Validation loss: 2.164184113343557

Epoch: 6| Step: 2
Training loss: 2.0011720657348633
Validation loss: 2.219175934791565

Epoch: 6| Step: 3
Training loss: 2.6023688316345215
Validation loss: 2.167411466439565

Epoch: 6| Step: 4
Training loss: 1.8627467155456543
Validation loss: 2.178134560585022

Epoch: 6| Step: 5
Training loss: 2.1624410152435303
Validation loss: 2.1809756755828857

Epoch: 6| Step: 6
Training loss: 1.915425181388855
Validation loss: 2.1348037322362265

Epoch: 6| Step: 7
Training loss: 2.581225872039795
Validation loss: 2.141283869743347

Epoch: 6| Step: 8
Training loss: 1.3744709491729736
Validation loss: 2.086390435695648

Epoch: 6| Step: 9
Training loss: 2.0003013610839844
Validation loss: 2.0961382389068604

Epoch: 6| Step: 10
Training loss: 1.7315093278884888
Validation loss: 2.0584900975227356

Epoch: 6| Step: 11
Training loss: 1.266244649887085
Validation loss: 2.1046838561693826

Epoch: 6| Step: 12
Training loss: 1.9865517616271973
Validation loss: 2.1235822439193726

Epoch: 6| Step: 13
Training loss: 2.385791301727295
Validation loss: 2.094877302646637

Epoch: 46| Step: 0
Training loss: 2.0229103565216064
Validation loss: 2.101270536581675

Epoch: 6| Step: 1
Training loss: 1.6753689050674438
Validation loss: 2.08052796125412

Epoch: 6| Step: 2
Training loss: 2.488557815551758
Validation loss: 2.162671466668447

Epoch: 6| Step: 3
Training loss: 1.6203563213348389
Validation loss: 2.090198198954264

Epoch: 6| Step: 4
Training loss: 1.5914374589920044
Validation loss: 2.1144312024116516

Epoch: 6| Step: 5
Training loss: 1.3914207220077515
Validation loss: 2.1215864022572837

Epoch: 6| Step: 6
Training loss: 2.2043001651763916
Validation loss: 2.1418586373329163

Epoch: 6| Step: 7
Training loss: 2.4510605335235596
Validation loss: 2.170994242032369

Epoch: 6| Step: 8
Training loss: 1.5311651229858398
Validation loss: 2.1317537426948547

Epoch: 6| Step: 9
Training loss: 0.9926133155822754
Validation loss: 2.158132533232371

Epoch: 6| Step: 10
Training loss: 1.685299038887024
Validation loss: 2.1420902609825134

Epoch: 6| Step: 11
Training loss: 1.8521645069122314
Validation loss: 2.040753742059072

Epoch: 6| Step: 12
Training loss: 2.4911763668060303
Validation loss: 2.107578913370768

Epoch: 6| Step: 13
Training loss: 2.573669910430908
Validation loss: 2.099760671456655

Epoch: 47| Step: 0
Training loss: 1.700681209564209
Validation loss: 2.0914390881856284

Epoch: 6| Step: 1
Training loss: 1.889951467514038
Validation loss: 2.1681877175966897

Epoch: 6| Step: 2
Training loss: 2.3477702140808105
Validation loss: 2.164438843727112

Epoch: 6| Step: 3
Training loss: 2.090179920196533
Validation loss: 2.1807895501454673

Epoch: 6| Step: 4
Training loss: 2.0292482376098633
Validation loss: 2.091141939163208

Epoch: 6| Step: 5
Training loss: 2.1665968894958496
Validation loss: 2.0651018619537354

Epoch: 6| Step: 6
Training loss: 1.9917058944702148
Validation loss: 2.1293978293736777

Epoch: 6| Step: 7
Training loss: 2.0807857513427734
Validation loss: 2.1019054452578225

Epoch: 6| Step: 8
Training loss: 1.59580659866333
Validation loss: 2.1454909443855286

Epoch: 6| Step: 9
Training loss: 1.7660073041915894
Validation loss: 2.15905225276947

Epoch: 6| Step: 10
Training loss: 1.5596561431884766
Validation loss: 2.1110063195228577

Epoch: 6| Step: 11
Training loss: 1.9665284156799316
Validation loss: 2.1471746365229287

Epoch: 6| Step: 12
Training loss: 1.8916685581207275
Validation loss: 2.1339648763338723

Epoch: 6| Step: 13
Training loss: 2.126516580581665
Validation loss: 2.1290226777394614

Epoch: 48| Step: 0
Training loss: 3.2538979053497314
Validation loss: 2.131721576054891

Epoch: 6| Step: 1
Training loss: 2.242784261703491
Validation loss: 2.1061370372772217

Epoch: 6| Step: 2
Training loss: 1.9382481575012207
Validation loss: 2.085649847984314

Epoch: 6| Step: 3
Training loss: 2.5706872940063477
Validation loss: 2.1308680971463523

Epoch: 6| Step: 4
Training loss: 1.9979288578033447
Validation loss: 2.1535282135009766

Epoch: 6| Step: 5
Training loss: 1.7757568359375
Validation loss: 2.1507898569107056

Epoch: 6| Step: 6
Training loss: 2.2397708892822266
Validation loss: 2.0886966387430825

Epoch: 6| Step: 7
Training loss: 1.693708896636963
Validation loss: 2.095758616924286

Epoch: 6| Step: 8
Training loss: 1.0049220323562622
Validation loss: 2.1131674448649087

Epoch: 6| Step: 9
Training loss: 1.332747220993042
Validation loss: 2.1268382469813027

Epoch: 6| Step: 10
Training loss: 1.973128318786621
Validation loss: 2.1257405479749045

Epoch: 6| Step: 11
Training loss: 1.517825722694397
Validation loss: 2.160138110319773

Epoch: 6| Step: 12
Training loss: 1.4310505390167236
Validation loss: 2.143378218015035

Epoch: 6| Step: 13
Training loss: 1.4895436763763428
Validation loss: 2.1135706702868142

Epoch: 49| Step: 0
Training loss: 1.6756134033203125
Validation loss: 2.1478394269943237

Epoch: 6| Step: 1
Training loss: 1.7124606370925903
Validation loss: 2.15564755598704

Epoch: 6| Step: 2
Training loss: 2.0501530170440674
Validation loss: 2.1674813628196716

Epoch: 6| Step: 3
Training loss: 1.642614483833313
Validation loss: 2.1292919317881265

Epoch: 6| Step: 4
Training loss: 1.7359592914581299
Validation loss: 2.148434042930603

Epoch: 6| Step: 5
Training loss: 2.288029193878174
Validation loss: 2.132946530977885

Epoch: 6| Step: 6
Training loss: 1.7090649604797363
Validation loss: 2.0974676807721457

Epoch: 6| Step: 7
Training loss: 1.7611944675445557
Validation loss: 2.095565835634867

Epoch: 6| Step: 8
Training loss: 2.4413414001464844
Validation loss: 2.1141717036565146

Epoch: 6| Step: 9
Training loss: 2.3786675930023193
Validation loss: 2.1560346682866416

Epoch: 6| Step: 10
Training loss: 1.8856334686279297
Validation loss: 2.0892715454101562

Epoch: 6| Step: 11
Training loss: 1.5091540813446045
Validation loss: 2.083103438218435

Epoch: 6| Step: 12
Training loss: 1.3968191146850586
Validation loss: 2.115260124206543

Epoch: 6| Step: 13
Training loss: 1.984419584274292
Validation loss: 2.105549454689026

Epoch: 50| Step: 0
Training loss: 1.7952923774719238
Validation loss: 2.106816510359446

Epoch: 6| Step: 1
Training loss: 0.9900478720664978
Validation loss: 2.151036500930786

Epoch: 6| Step: 2
Training loss: 1.537428617477417
Validation loss: 2.1272058486938477

Epoch: 6| Step: 3
Training loss: 1.8660569190979004
Validation loss: 2.0813961227734885

Epoch: 6| Step: 4
Training loss: 2.6418662071228027
Validation loss: 2.0842745105425515

Epoch: 6| Step: 5
Training loss: 1.8630151748657227
Validation loss: 2.083570679028829

Epoch: 6| Step: 6
Training loss: 2.2417359352111816
Validation loss: 2.156435271104177

Epoch: 6| Step: 7
Training loss: 2.4331629276275635
Validation loss: 2.1368378400802612

Epoch: 6| Step: 8
Training loss: 2.1059963703155518
Validation loss: 2.1276879707972207

Epoch: 6| Step: 9
Training loss: 1.577019453048706
Validation loss: 2.185190121332804

Epoch: 6| Step: 10
Training loss: 1.6853193044662476
Validation loss: 2.120821952819824

Epoch: 6| Step: 11
Training loss: 2.27441668510437
Validation loss: 2.162286122639974

Epoch: 6| Step: 12
Training loss: 1.2255514860153198
Validation loss: 2.160522202650706

Epoch: 6| Step: 13
Training loss: 2.137587070465088
Validation loss: 2.0844106475512185

Epoch: 51| Step: 0
Training loss: 2.0968081951141357
Validation loss: 2.1130889455477395

Epoch: 6| Step: 1
Training loss: 2.1283631324768066
Validation loss: 2.1081868608792624

Epoch: 6| Step: 2
Training loss: 1.6453802585601807
Validation loss: 2.145556171735128

Epoch: 6| Step: 3
Training loss: 1.8968170881271362
Validation loss: 2.107719620068868

Epoch: 6| Step: 4
Training loss: 1.783876895904541
Validation loss: 2.120974143346151

Epoch: 6| Step: 5
Training loss: 1.8270084857940674
Validation loss: 2.1459648410479226

Epoch: 6| Step: 6
Training loss: 1.9078850746154785
Validation loss: 2.158100644747416

Epoch: 6| Step: 7
Training loss: 2.2495205402374268
Validation loss: 2.1285754442214966

Epoch: 6| Step: 8
Training loss: 1.3761560916900635
Validation loss: 2.0607136885325112

Epoch: 6| Step: 9
Training loss: 1.3645257949829102
Validation loss: 2.124758164087931

Epoch: 6| Step: 10
Training loss: 2.148512601852417
Validation loss: 2.069741984208425

Epoch: 6| Step: 11
Training loss: 1.3008766174316406
Validation loss: 2.1092823346455893

Epoch: 6| Step: 12
Training loss: 2.0001368522644043
Validation loss: 2.0910438696543374

Epoch: 6| Step: 13
Training loss: 2.124074935913086
Validation loss: 2.1029600898424783

Epoch: 52| Step: 0
Training loss: 1.4053406715393066
Validation loss: 2.1077532966931662

Epoch: 6| Step: 1
Training loss: 2.0516552925109863
Validation loss: 2.131666421890259

Epoch: 6| Step: 2
Training loss: 2.2009410858154297
Validation loss: 2.131313363711039

Epoch: 6| Step: 3
Training loss: 1.6804256439208984
Validation loss: 2.1165718237559

Epoch: 6| Step: 4
Training loss: 1.5699321031570435
Validation loss: 2.139851967493693

Epoch: 6| Step: 5
Training loss: 2.4707236289978027
Validation loss: 2.160977085431417

Epoch: 6| Step: 6
Training loss: 1.439764142036438
Validation loss: 2.1618062059084573

Epoch: 6| Step: 7
Training loss: 1.1555525064468384
Validation loss: 2.188606103261312

Epoch: 6| Step: 8
Training loss: 1.7231073379516602
Validation loss: 2.116123159726461

Epoch: 6| Step: 9
Training loss: 1.9441425800323486
Validation loss: 2.137480358282725

Epoch: 6| Step: 10
Training loss: 1.5521304607391357
Validation loss: 2.1301139990488687

Epoch: 6| Step: 11
Training loss: 2.590878486633301
Validation loss: 2.1122583150863647

Epoch: 6| Step: 12
Training loss: 2.1821610927581787
Validation loss: 2.0886494318644204

Epoch: 6| Step: 13
Training loss: 2.392334461212158
Validation loss: 2.119120717048645

Epoch: 53| Step: 0
Training loss: 2.0531225204467773
Validation loss: 2.1184675296147666

Epoch: 6| Step: 1
Training loss: 2.2850024700164795
Validation loss: 2.11042457818985

Epoch: 6| Step: 2
Training loss: 2.1260807514190674
Validation loss: 2.0826848347981772

Epoch: 6| Step: 3
Training loss: 1.3138725757598877
Validation loss: 2.1291446685791016

Epoch: 6| Step: 4
Training loss: 1.4524128437042236
Validation loss: 2.1569823026657104

Epoch: 6| Step: 5
Training loss: 1.2234183549880981
Validation loss: 2.118690550327301

Epoch: 6| Step: 6
Training loss: 1.4379109144210815
Validation loss: 2.071799397468567

Epoch: 6| Step: 7
Training loss: 2.188434600830078
Validation loss: 2.1122207244237265

Epoch: 6| Step: 8
Training loss: 1.9035091400146484
Validation loss: 2.086478809515635

Epoch: 6| Step: 9
Training loss: 1.6009440422058105
Validation loss: 2.126037081082662

Epoch: 6| Step: 10
Training loss: 1.8698501586914062
Validation loss: 2.178134799003601

Epoch: 6| Step: 11
Training loss: 1.5781197547912598
Validation loss: 2.167853852113088

Epoch: 6| Step: 12
Training loss: 2.8237314224243164
Validation loss: 2.124809205532074

Epoch: 6| Step: 13
Training loss: 2.073519229888916
Validation loss: 2.1315869092941284

Epoch: 54| Step: 0
Training loss: 1.7387604713439941
Validation loss: 2.1505097349484763

Epoch: 6| Step: 1
Training loss: 2.048321008682251
Validation loss: 2.175187826156616

Epoch: 6| Step: 2
Training loss: 1.744781255722046
Validation loss: 2.1499424378077188

Epoch: 6| Step: 3
Training loss: 1.5822973251342773
Validation loss: 2.1205936074256897

Epoch: 6| Step: 4
Training loss: 1.6491525173187256
Validation loss: 2.16173388560613

Epoch: 6| Step: 5
Training loss: 1.5828781127929688
Validation loss: 2.1538174947102866

Epoch: 6| Step: 6
Training loss: 2.3833298683166504
Validation loss: 2.183898369471232

Epoch: 6| Step: 7
Training loss: 1.6262820959091187
Validation loss: 2.1269691387812295

Epoch: 6| Step: 8
Training loss: 1.772879958152771
Validation loss: 2.133198618888855

Epoch: 6| Step: 9
Training loss: 1.939679503440857
Validation loss: 2.0876850287119546

Epoch: 6| Step: 10
Training loss: 1.8836100101470947
Validation loss: 2.103713591893514

Epoch: 6| Step: 11
Training loss: 2.35197377204895
Validation loss: 2.1225059429804483

Epoch: 6| Step: 12
Training loss: 1.8565194606781006
Validation loss: 2.1405115723609924

Epoch: 6| Step: 13
Training loss: 1.870243787765503
Validation loss: 2.14275860786438

Epoch: 55| Step: 0
Training loss: 1.4681165218353271
Validation loss: 2.1311775843302407

Epoch: 6| Step: 1
Training loss: 1.9211578369140625
Validation loss: 2.161232590675354

Epoch: 6| Step: 2
Training loss: 1.634403944015503
Validation loss: 2.125588039557139

Epoch: 6| Step: 3
Training loss: 1.681565523147583
Validation loss: 2.0715742707252502

Epoch: 6| Step: 4
Training loss: 1.2781710624694824
Validation loss: 2.1512276927630105

Epoch: 6| Step: 5
Training loss: 1.782745361328125
Validation loss: 2.103134791056315

Epoch: 6| Step: 6
Training loss: 2.106100559234619
Validation loss: 2.10331396261851

Epoch: 6| Step: 7
Training loss: 2.174884080886841
Validation loss: 2.1164760986963906

Epoch: 6| Step: 8
Training loss: 1.0956165790557861
Validation loss: 2.115273177623749

Epoch: 6| Step: 9
Training loss: 1.3900964260101318
Validation loss: 2.115880231062571

Epoch: 6| Step: 10
Training loss: 1.6103591918945312
Validation loss: 2.150741755962372

Epoch: 6| Step: 11
Training loss: 2.4429409503936768
Validation loss: 2.1278775533040366

Epoch: 6| Step: 12
Training loss: 2.3270339965820312
Validation loss: 2.117506980895996

Epoch: 6| Step: 13
Training loss: 2.635789394378662
Validation loss: 2.19121253490448

Epoch: 56| Step: 0
Training loss: 1.9513192176818848
Validation loss: 2.191951334476471

Epoch: 6| Step: 1
Training loss: 2.162796974182129
Validation loss: 2.158608913421631

Epoch: 6| Step: 2
Training loss: 2.097358226776123
Validation loss: 2.186461925506592

Epoch: 6| Step: 3
Training loss: 1.6283411979675293
Validation loss: 2.1305128733317056

Epoch: 6| Step: 4
Training loss: 1.503941535949707
Validation loss: 2.19503253698349

Epoch: 6| Step: 5
Training loss: 1.7304538488388062
Validation loss: 2.183494587739309

Epoch: 6| Step: 6
Training loss: 2.0568456649780273
Validation loss: 2.141462206840515

Epoch: 6| Step: 7
Training loss: 2.1020424365997314
Validation loss: 2.123714864253998

Epoch: 6| Step: 8
Training loss: 1.6811749935150146
Validation loss: 2.118723134199778

Epoch: 6| Step: 9
Training loss: 1.966857671737671
Validation loss: 2.1242350737253823

Epoch: 6| Step: 10
Training loss: 1.4526736736297607
Validation loss: 2.1406214435895285

Epoch: 6| Step: 11
Training loss: 2.1034836769104004
Validation loss: 2.1469906767209372

Epoch: 6| Step: 12
Training loss: 2.357405185699463
Validation loss: 2.136840045452118

Epoch: 6| Step: 13
Training loss: 2.3646907806396484
Validation loss: 2.1619738340377808

Epoch: 57| Step: 0
Training loss: 1.11769700050354
Validation loss: 2.1306011080741882

Epoch: 6| Step: 1
Training loss: 1.998030662536621
Validation loss: 2.0689984361330667

Epoch: 6| Step: 2
Training loss: 1.4193296432495117
Validation loss: 2.1239131887753806

Epoch: 6| Step: 3
Training loss: 2.1206746101379395
Validation loss: 2.147728224595388

Epoch: 6| Step: 4
Training loss: 1.8338074684143066
Validation loss: 2.189127961794535

Epoch: 6| Step: 5
Training loss: 1.8701574802398682
Validation loss: 2.204357862472534

Epoch: 6| Step: 6
Training loss: 1.3167142868041992
Validation loss: 2.1531500021616616

Epoch: 6| Step: 7
Training loss: 1.4222972393035889
Validation loss: 2.182303309440613

Epoch: 6| Step: 8
Training loss: 2.2133188247680664
Validation loss: 2.2176263332366943

Epoch: 6| Step: 9
Training loss: 2.3193235397338867
Validation loss: 2.2022135257720947

Epoch: 6| Step: 10
Training loss: 2.2230634689331055
Validation loss: 2.1678611040115356

Epoch: 6| Step: 11
Training loss: 2.2510108947753906
Validation loss: 2.1860753695170083

Epoch: 6| Step: 12
Training loss: 2.3144912719726562
Validation loss: 2.1592777371406555

Epoch: 6| Step: 13
Training loss: 1.3124830722808838
Validation loss: 2.0845455527305603

Epoch: 58| Step: 0
Training loss: 1.8323975801467896
Validation loss: 2.1574127674102783

Epoch: 6| Step: 1
Training loss: 1.4617258310317993
Validation loss: 2.1365569631258645

Epoch: 6| Step: 2
Training loss: 1.4018566608428955
Validation loss: 2.1055755019187927

Epoch: 6| Step: 3
Training loss: 1.6072931289672852
Validation loss: 2.1761678655942283

Epoch: 6| Step: 4
Training loss: 1.1072978973388672
Validation loss: 2.115523040294647

Epoch: 6| Step: 5
Training loss: 1.721296787261963
Validation loss: 2.1225087443987527

Epoch: 6| Step: 6
Training loss: 1.3614948987960815
Validation loss: 2.102012654145559

Epoch: 6| Step: 7
Training loss: 1.6180734634399414
Validation loss: 2.1171459555625916

Epoch: 6| Step: 8
Training loss: 2.228541851043701
Validation loss: 2.1040226022402444

Epoch: 6| Step: 9
Training loss: 2.1464779376983643
Validation loss: 2.1934539675712585

Epoch: 6| Step: 10
Training loss: 1.5861871242523193
Validation loss: 2.1623394886652627

Epoch: 6| Step: 11
Training loss: 2.1129539012908936
Validation loss: 2.1487393577893577

Epoch: 6| Step: 12
Training loss: 2.534756898880005
Validation loss: 2.133615573247274

Epoch: 6| Step: 13
Training loss: 2.6426281929016113
Validation loss: 2.2295581897099814

Epoch: 59| Step: 0
Training loss: 2.299419403076172
Validation loss: 2.1581480701764426

Epoch: 6| Step: 1
Training loss: 2.661810874938965
Validation loss: 2.2059763272603354

Epoch: 6| Step: 2
Training loss: 2.0442442893981934
Validation loss: 2.15157014131546

Epoch: 6| Step: 3
Training loss: 1.7780592441558838
Validation loss: 2.144959568977356

Epoch: 6| Step: 4
Training loss: 1.9790245294570923
Validation loss: 2.155798355738322

Epoch: 6| Step: 5
Training loss: 1.3669772148132324
Validation loss: 2.1423688332239785

Epoch: 6| Step: 6
Training loss: 1.7750273942947388
Validation loss: 2.117996871471405

Epoch: 6| Step: 7
Training loss: 1.2995918989181519
Validation loss: 2.12396768728892

Epoch: 6| Step: 8
Training loss: 1.3395395278930664
Validation loss: 2.1302979985872903

Epoch: 6| Step: 9
Training loss: 1.891391634941101
Validation loss: 2.1191179156303406

Epoch: 6| Step: 10
Training loss: 1.8429694175720215
Validation loss: 2.107065955797831

Epoch: 6| Step: 11
Training loss: 1.5540108680725098
Validation loss: 2.064163168271383

Epoch: 6| Step: 12
Training loss: 2.2891626358032227
Validation loss: 2.1244885524113974

Epoch: 6| Step: 13
Training loss: 1.5885320901870728
Validation loss: 2.105765422185262

Epoch: 60| Step: 0
Training loss: 2.0426626205444336
Validation loss: 2.1254579623540244

Epoch: 6| Step: 1
Training loss: 2.06730055809021
Validation loss: 2.1222289005915322

Epoch: 6| Step: 2
Training loss: 1.489340901374817
Validation loss: 2.1216240723927817

Epoch: 6| Step: 3
Training loss: 2.1262497901916504
Validation loss: 2.155750016371409

Epoch: 6| Step: 4
Training loss: 1.4228651523590088
Validation loss: 2.1370152831077576

Epoch: 6| Step: 5
Training loss: 2.050584316253662
Validation loss: 2.1491912802060447

Epoch: 6| Step: 6
Training loss: 1.8322417736053467
Validation loss: 2.146635333697001

Epoch: 6| Step: 7
Training loss: 1.7909066677093506
Validation loss: 2.100070814291636

Epoch: 6| Step: 8
Training loss: 1.8159469366073608
Validation loss: 2.1238050858179727

Epoch: 6| Step: 9
Training loss: 1.0942962169647217
Validation loss: 2.0870869755744934

Epoch: 6| Step: 10
Training loss: 1.843203067779541
Validation loss: 2.126631418863932

Epoch: 6| Step: 11
Training loss: 1.3409537076950073
Validation loss: 2.092601557572683

Epoch: 6| Step: 12
Training loss: 2.3044209480285645
Validation loss: 2.1553517977396646

Epoch: 6| Step: 13
Training loss: 1.9437391757965088
Validation loss: 2.115522046883901

Epoch: 61| Step: 0
Training loss: 1.4711276292800903
Validation loss: 2.098796546459198

Epoch: 6| Step: 1
Training loss: 1.558478593826294
Validation loss: 2.1437910993893943

Epoch: 6| Step: 2
Training loss: 1.8474949598312378
Validation loss: 2.1549856861432395

Epoch: 6| Step: 3
Training loss: 1.2977787256240845
Validation loss: 2.175447722276052

Epoch: 6| Step: 4
Training loss: 1.3833582401275635
Validation loss: 2.1612441341082254

Epoch: 6| Step: 5
Training loss: 2.048121213912964
Validation loss: 2.2221599817276

Epoch: 6| Step: 6
Training loss: 2.101612091064453
Validation loss: 2.2132078409194946

Epoch: 6| Step: 7
Training loss: 2.1241512298583984
Validation loss: 2.1807458202044168

Epoch: 6| Step: 8
Training loss: 2.0687990188598633
Validation loss: 2.152199387550354

Epoch: 6| Step: 9
Training loss: 2.225363254547119
Validation loss: 2.1522157986958823

Epoch: 6| Step: 10
Training loss: 1.5074453353881836
Validation loss: 2.1270098884900412

Epoch: 6| Step: 11
Training loss: 1.5981621742248535
Validation loss: 2.1318175991376243

Epoch: 6| Step: 12
Training loss: 1.5384573936462402
Validation loss: 2.138015786806742

Epoch: 6| Step: 13
Training loss: 2.7498083114624023
Validation loss: 2.0971827308336892

Epoch: 62| Step: 0
Training loss: 1.8319631814956665
Validation loss: 2.110219419002533

Epoch: 6| Step: 1
Training loss: 1.9448086023330688
Validation loss: 2.109688639640808

Epoch: 6| Step: 2
Training loss: 1.9856057167053223
Validation loss: 2.0806684494018555

Epoch: 6| Step: 3
Training loss: 2.1847219467163086
Validation loss: 2.0972145001093545

Epoch: 6| Step: 4
Training loss: 1.365034580230713
Validation loss: 2.1248849431673684

Epoch: 6| Step: 5
Training loss: 2.267543077468872
Validation loss: 2.0933127204577127

Epoch: 6| Step: 6
Training loss: 1.9070419073104858
Validation loss: 2.13875146706899

Epoch: 6| Step: 7
Training loss: 1.9315911531448364
Validation loss: 2.0920722683270774

Epoch: 6| Step: 8
Training loss: 1.6436705589294434
Validation loss: 2.153382738431295

Epoch: 6| Step: 9
Training loss: 1.9376420974731445
Validation loss: 2.102817952632904

Epoch: 6| Step: 10
Training loss: 1.8183903694152832
Validation loss: 2.101534903049469

Epoch: 6| Step: 11
Training loss: 1.5401700735092163
Validation loss: 2.1557031075159707

Epoch: 6| Step: 12
Training loss: 1.6008071899414062
Validation loss: 2.1677591602007547

Epoch: 6| Step: 13
Training loss: 1.211450219154358
Validation loss: 2.1375442147254944

Epoch: 63| Step: 0
Training loss: 2.0055553913116455
Validation loss: 2.111480991045634

Epoch: 6| Step: 1
Training loss: 1.8325634002685547
Validation loss: 2.1699678103129068

Epoch: 6| Step: 2
Training loss: 1.3417119979858398
Validation loss: 2.1973020831743875

Epoch: 6| Step: 3
Training loss: 1.7500214576721191
Validation loss: 2.1749773621559143

Epoch: 6| Step: 4
Training loss: 1.671271562576294
Validation loss: 2.1869720220565796

Epoch: 6| Step: 5
Training loss: 1.6873170137405396
Validation loss: 2.1412849028905234

Epoch: 6| Step: 6
Training loss: 1.545827865600586
Validation loss: 2.161124030749003

Epoch: 6| Step: 7
Training loss: 2.2828736305236816
Validation loss: 2.1497705777486167

Epoch: 6| Step: 8
Training loss: 1.9443261623382568
Validation loss: 2.177968919277191

Epoch: 6| Step: 9
Training loss: 2.406795024871826
Validation loss: 2.080636958281199

Epoch: 6| Step: 10
Training loss: 2.1135129928588867
Validation loss: 2.186340649922689

Epoch: 6| Step: 11
Training loss: 1.0904664993286133
Validation loss: 2.1576350927352905

Epoch: 6| Step: 12
Training loss: 1.271113634109497
Validation loss: 2.1023906469345093

Epoch: 6| Step: 13
Training loss: 2.01409912109375
Validation loss: 2.128709375858307

Epoch: 64| Step: 0
Training loss: 1.2549457550048828
Validation loss: 2.130996902783712

Epoch: 6| Step: 1
Training loss: 1.7251513004302979
Validation loss: 2.1029211282730103

Epoch: 6| Step: 2
Training loss: 2.108604907989502
Validation loss: 2.155695080757141

Epoch: 6| Step: 3
Training loss: 1.7706023454666138
Validation loss: 2.1605434020360312

Epoch: 6| Step: 4
Training loss: 2.353776216506958
Validation loss: 2.184367855389913

Epoch: 6| Step: 5
Training loss: 1.6771162748336792
Validation loss: 2.1707975467046103

Epoch: 6| Step: 6
Training loss: 1.4064512252807617
Validation loss: 2.083186467488607

Epoch: 6| Step: 7
Training loss: 1.731359601020813
Validation loss: 2.180510322252909

Epoch: 6| Step: 8
Training loss: 1.757769227027893
Validation loss: 2.162456234296163

Epoch: 6| Step: 9
Training loss: 1.254143238067627
Validation loss: 2.138583521048228

Epoch: 6| Step: 10
Training loss: 1.6079463958740234
Validation loss: 2.148568550745646

Epoch: 6| Step: 11
Training loss: 1.5248517990112305
Validation loss: 2.1235066453615823

Epoch: 6| Step: 12
Training loss: 1.9731615781784058
Validation loss: 2.1127771536509194

Epoch: 6| Step: 13
Training loss: 2.6484932899475098
Validation loss: 2.1351141134897866

Epoch: 65| Step: 0
Training loss: 1.5635789632797241
Validation loss: 2.1344690521558127

Epoch: 6| Step: 1
Training loss: 1.3498680591583252
Validation loss: 2.1489387154579163

Epoch: 6| Step: 2
Training loss: 1.9617071151733398
Validation loss: 2.1239050229390464

Epoch: 6| Step: 3
Training loss: 2.490161418914795
Validation loss: 2.1071925163269043

Epoch: 6| Step: 4
Training loss: 0.8543387651443481
Validation loss: 2.162286420663198

Epoch: 6| Step: 5
Training loss: 1.5145947933197021
Validation loss: 2.149786591529846

Epoch: 6| Step: 6
Training loss: 2.329098701477051
Validation loss: 2.1306103666623435

Epoch: 6| Step: 7
Training loss: 2.271261692047119
Validation loss: 2.1901023983955383

Epoch: 6| Step: 8
Training loss: 2.4389498233795166
Validation loss: 2.1634228428204856

Epoch: 6| Step: 9
Training loss: 1.6403717994689941
Validation loss: 2.2193472385406494

Epoch: 6| Step: 10
Training loss: 1.8427484035491943
Validation loss: 2.18833456436793

Epoch: 6| Step: 11
Training loss: 1.3340829610824585
Validation loss: 2.1326271891593933

Epoch: 6| Step: 12
Training loss: 1.7523921728134155
Validation loss: 2.150476892789205

Epoch: 6| Step: 13
Training loss: 1.370615005493164
Validation loss: 2.152652402718862

Epoch: 66| Step: 0
Training loss: 1.8152685165405273
Validation loss: 2.139648179213206

Epoch: 6| Step: 1
Training loss: 1.6422953605651855
Validation loss: 2.166559636592865

Epoch: 6| Step: 2
Training loss: 2.0225563049316406
Validation loss: 2.128592093785604

Epoch: 6| Step: 3
Training loss: 1.4717618227005005
Validation loss: 2.118181665738424

Epoch: 6| Step: 4
Training loss: 1.9232498407363892
Validation loss: 2.1460713942845664

Epoch: 6| Step: 5
Training loss: 1.9935522079467773
Validation loss: 2.1445696155230203

Epoch: 6| Step: 6
Training loss: 1.9580546617507935
Validation loss: 2.142549753189087

Epoch: 6| Step: 7
Training loss: 0.9868866205215454
Validation loss: 2.1875028212865195

Epoch: 6| Step: 8
Training loss: 1.7659697532653809
Validation loss: 2.1475098927815757

Epoch: 6| Step: 9
Training loss: 0.9656803607940674
Validation loss: 2.164041896661123

Epoch: 6| Step: 10
Training loss: 1.9521658420562744
Validation loss: 2.142809510231018

Epoch: 6| Step: 11
Training loss: 2.1619067192077637
Validation loss: 2.2015282909075418

Epoch: 6| Step: 12
Training loss: 1.7144057750701904
Validation loss: 2.1831876238187156

Epoch: 6| Step: 13
Training loss: 2.338747501373291
Validation loss: 2.150598128636678

Epoch: 67| Step: 0
Training loss: 1.673786997795105
Validation loss: 2.1608089804649353

Epoch: 6| Step: 1
Training loss: 2.1659810543060303
Validation loss: 2.1903738379478455

Epoch: 6| Step: 2
Training loss: 1.584524154663086
Validation loss: 2.150993903477987

Epoch: 6| Step: 3
Training loss: 1.9216450452804565
Validation loss: 2.1882280111312866

Epoch: 6| Step: 4
Training loss: 1.8054680824279785
Validation loss: 2.1275623639424643

Epoch: 6| Step: 5
Training loss: 1.9085696935653687
Validation loss: 2.176200568675995

Epoch: 6| Step: 6
Training loss: 1.5412378311157227
Validation loss: 2.1446412205696106

Epoch: 6| Step: 7
Training loss: 1.2590034008026123
Validation loss: 2.1337132453918457

Epoch: 6| Step: 8
Training loss: 1.9382251501083374
Validation loss: 2.155444065729777

Epoch: 6| Step: 9
Training loss: 1.6552658081054688
Validation loss: 2.1005029877026877

Epoch: 6| Step: 10
Training loss: 1.4817683696746826
Validation loss: 2.1487401723861694

Epoch: 6| Step: 11
Training loss: 1.938981294631958
Validation loss: 2.083372930685679

Epoch: 6| Step: 12
Training loss: 2.0392279624938965
Validation loss: 2.1430987318356833

Epoch: 6| Step: 13
Training loss: 1.7881109714508057
Validation loss: 2.1310381491978965

Epoch: 68| Step: 0
Training loss: 0.6133852005004883
Validation loss: 2.148612459500631

Epoch: 6| Step: 1
Training loss: 1.9436229467391968
Validation loss: 2.152430613835653

Epoch: 6| Step: 2
Training loss: 1.437194585800171
Validation loss: 2.1551595330238342

Epoch: 6| Step: 3
Training loss: 2.0727601051330566
Validation loss: 2.179796278476715

Epoch: 6| Step: 4
Training loss: 1.7693064212799072
Validation loss: 2.2015507419904075

Epoch: 6| Step: 5
Training loss: 1.9487987756729126
Validation loss: 2.141037881374359

Epoch: 6| Step: 6
Training loss: 1.460036277770996
Validation loss: 2.159645358721415

Epoch: 6| Step: 7
Training loss: 1.1835947036743164
Validation loss: 2.130855441093445

Epoch: 6| Step: 8
Training loss: 2.6346426010131836
Validation loss: 2.1589186787605286

Epoch: 6| Step: 9
Training loss: 1.2514898777008057
Validation loss: 2.130879501501719

Epoch: 6| Step: 10
Training loss: 2.1073708534240723
Validation loss: 2.1416828632354736

Epoch: 6| Step: 11
Training loss: 2.588813304901123
Validation loss: 2.165725807348887

Epoch: 6| Step: 12
Training loss: 1.7785377502441406
Validation loss: 2.1679925322532654

Epoch: 6| Step: 13
Training loss: 1.5970730781555176
Validation loss: 2.1420339345932007

Epoch: 69| Step: 0
Training loss: 1.9249187707901
Validation loss: 2.156775176525116

Epoch: 6| Step: 1
Training loss: 1.5238581895828247
Validation loss: 2.1876742839813232

Epoch: 6| Step: 2
Training loss: 1.4249565601348877
Validation loss: 2.1465248465538025

Epoch: 6| Step: 3
Training loss: 2.096724510192871
Validation loss: 2.1182043155034385

Epoch: 6| Step: 4
Training loss: 1.4584224224090576
Validation loss: 2.097477992375692

Epoch: 6| Step: 5
Training loss: 1.5098425149917603
Validation loss: 2.0947617093722024

Epoch: 6| Step: 6
Training loss: 1.8553903102874756
Validation loss: 2.1296565731366477

Epoch: 6| Step: 7
Training loss: 1.5753815174102783
Validation loss: 2.1502854426701865

Epoch: 6| Step: 8
Training loss: 1.484452247619629
Validation loss: 2.1750769217809043

Epoch: 6| Step: 9
Training loss: 1.9997490644454956
Validation loss: 2.1932197411855063

Epoch: 6| Step: 10
Training loss: 1.9936293363571167
Validation loss: 2.1973681251207986

Epoch: 6| Step: 11
Training loss: 2.487476110458374
Validation loss: 2.196178952852885

Epoch: 6| Step: 12
Training loss: 1.6544468402862549
Validation loss: 2.1847104032834372

Epoch: 6| Step: 13
Training loss: 1.7162467241287231
Validation loss: 2.186964193979899

Epoch: 70| Step: 0
Training loss: 1.495246410369873
Validation loss: 2.1704420248667398

Epoch: 6| Step: 1
Training loss: 1.3706847429275513
Validation loss: 2.123126188913981

Epoch: 6| Step: 2
Training loss: 1.8163106441497803
Validation loss: 2.0756810903549194

Epoch: 6| Step: 3
Training loss: 1.4918057918548584
Validation loss: 2.1447346607844033

Epoch: 6| Step: 4
Training loss: 1.5717267990112305
Validation loss: 2.1246308088302612

Epoch: 6| Step: 5
Training loss: 1.82180917263031
Validation loss: 2.1062473257382712

Epoch: 6| Step: 6
Training loss: 1.4957776069641113
Validation loss: 2.128726601600647

Epoch: 6| Step: 7
Training loss: 1.8245799541473389
Validation loss: 2.1538747549057007

Epoch: 6| Step: 8
Training loss: 2.392496109008789
Validation loss: 2.133501569430033

Epoch: 6| Step: 9
Training loss: 2.07999849319458
Validation loss: 2.1754578153292337

Epoch: 6| Step: 10
Training loss: 2.1083498001098633
Validation loss: 2.1604933738708496

Epoch: 6| Step: 11
Training loss: 2.1136398315429688
Validation loss: 2.171301782131195

Epoch: 6| Step: 12
Training loss: 1.8193011283874512
Validation loss: 2.17455001672109

Epoch: 6| Step: 13
Training loss: 1.5108895301818848
Validation loss: 2.1705307563145957

Epoch: 71| Step: 0
Training loss: 1.9480528831481934
Validation loss: 2.140920797983805

Epoch: 6| Step: 1
Training loss: 1.8938508033752441
Validation loss: 2.1088680426279702

Epoch: 6| Step: 2
Training loss: 1.3957158327102661
Validation loss: 2.116693695386251

Epoch: 6| Step: 3
Training loss: 1.9766725301742554
Validation loss: 2.0878972808519998

Epoch: 6| Step: 4
Training loss: 1.666158676147461
Validation loss: 2.1514580448468528

Epoch: 6| Step: 5
Training loss: 1.930199146270752
Validation loss: 2.180919090906779

Epoch: 6| Step: 6
Training loss: 1.6259534358978271
Validation loss: 2.200169046719869

Epoch: 6| Step: 7
Training loss: 2.0722711086273193
Validation loss: 2.1223596731821694

Epoch: 6| Step: 8
Training loss: 1.7423726320266724
Validation loss: 2.16117391983668

Epoch: 6| Step: 9
Training loss: 1.7167942523956299
Validation loss: 2.110249618689219

Epoch: 6| Step: 10
Training loss: 2.0952253341674805
Validation loss: 2.107178966204325

Epoch: 6| Step: 11
Training loss: 1.764668345451355
Validation loss: 2.126521905263265

Epoch: 6| Step: 12
Training loss: 1.55033278465271
Validation loss: 2.1877615253130593

Epoch: 6| Step: 13
Training loss: 2.105924129486084
Validation loss: 2.181463062763214

Epoch: 72| Step: 0
Training loss: 2.050800323486328
Validation loss: 2.291635890801748

Epoch: 6| Step: 1
Training loss: 1.5449929237365723
Validation loss: 2.2061363458633423

Epoch: 6| Step: 2
Training loss: 1.7677150964736938
Validation loss: 2.210025986035665

Epoch: 6| Step: 3
Training loss: 0.908018946647644
Validation loss: 2.1873756845792136

Epoch: 6| Step: 4
Training loss: 2.398043632507324
Validation loss: 2.1637721061706543

Epoch: 6| Step: 5
Training loss: 1.7895985841751099
Validation loss: 2.129461963971456

Epoch: 6| Step: 6
Training loss: 1.6864917278289795
Validation loss: 2.1049245397249856

Epoch: 6| Step: 7
Training loss: 1.566981554031372
Validation loss: 2.1388410727183023

Epoch: 6| Step: 8
Training loss: 1.6812043190002441
Validation loss: 2.112546960512797

Epoch: 6| Step: 9
Training loss: 2.5259647369384766
Validation loss: 2.1326953172683716

Epoch: 6| Step: 10
Training loss: 1.9928295612335205
Validation loss: 2.0987040599187217

Epoch: 6| Step: 11
Training loss: 1.532240629196167
Validation loss: 2.136437992254893

Epoch: 6| Step: 12
Training loss: 1.7657212018966675
Validation loss: 2.1292247573534646

Epoch: 6| Step: 13
Training loss: 1.3491158485412598
Validation loss: 2.136121988296509

Epoch: 73| Step: 0
Training loss: 1.553592324256897
Validation loss: 2.1246459682782493

Epoch: 6| Step: 1
Training loss: 1.5655765533447266
Validation loss: 2.1521779696146646

Epoch: 6| Step: 2
Training loss: 1.0066804885864258
Validation loss: 2.134687383969625

Epoch: 6| Step: 3
Training loss: 1.83294677734375
Validation loss: 2.1661054690678916

Epoch: 6| Step: 4
Training loss: 1.4530611038208008
Validation loss: 2.171245733896891

Epoch: 6| Step: 5
Training loss: 1.3814936876296997
Validation loss: 2.181281089782715

Epoch: 6| Step: 6
Training loss: 2.3475794792175293
Validation loss: 2.1083682576815286

Epoch: 6| Step: 7
Training loss: 1.835310459136963
Validation loss: 2.156291445096334

Epoch: 6| Step: 8
Training loss: 1.5828754901885986
Validation loss: 2.155960440635681

Epoch: 6| Step: 9
Training loss: 1.725502610206604
Validation loss: 2.1950206756591797

Epoch: 6| Step: 10
Training loss: 1.5811110734939575
Validation loss: 2.25823050737381

Epoch: 6| Step: 11
Training loss: 1.5485217571258545
Validation loss: 2.1600130200386047

Epoch: 6| Step: 12
Training loss: 2.4871559143066406
Validation loss: 2.1479551196098328

Epoch: 6| Step: 13
Training loss: 1.9606270790100098
Validation loss: 2.1015774408976235

Epoch: 74| Step: 0
Training loss: 1.851531982421875
Validation loss: 2.1598114172617593

Epoch: 6| Step: 1
Training loss: 1.4739022254943848
Validation loss: 2.16666970650355

Epoch: 6| Step: 2
Training loss: 1.4759602546691895
Validation loss: 2.094546854496002

Epoch: 6| Step: 3
Training loss: 1.9193042516708374
Validation loss: 2.0799326499303183

Epoch: 6| Step: 4
Training loss: 1.590685248374939
Validation loss: 2.1181803743044534

Epoch: 6| Step: 5
Training loss: 1.775052547454834
Validation loss: 2.124000529448191

Epoch: 6| Step: 6
Training loss: 1.527205467224121
Validation loss: 2.143292764822642

Epoch: 6| Step: 7
Training loss: 1.978937029838562
Validation loss: 2.1111552516619363

Epoch: 6| Step: 8
Training loss: 1.626011848449707
Validation loss: 2.1191906730333963

Epoch: 6| Step: 9
Training loss: 1.738070011138916
Validation loss: 2.1124611298243203

Epoch: 6| Step: 10
Training loss: 1.2133066654205322
Validation loss: 2.102477709452311

Epoch: 6| Step: 11
Training loss: 1.8287773132324219
Validation loss: 2.1679187218348184

Epoch: 6| Step: 12
Training loss: 1.9656517505645752
Validation loss: 2.1758496363957724

Epoch: 6| Step: 13
Training loss: 1.826525330543518
Validation loss: 2.1408899625142417

Epoch: 75| Step: 0
Training loss: 1.4175479412078857
Validation loss: 2.2183311780293784

Epoch: 6| Step: 1
Training loss: 1.150874376296997
Validation loss: 2.198854943116506

Epoch: 6| Step: 2
Training loss: 2.143362522125244
Validation loss: 2.210309545199076

Epoch: 6| Step: 3
Training loss: 2.100054979324341
Validation loss: 2.176745573679606

Epoch: 6| Step: 4
Training loss: 1.4539248943328857
Validation loss: 2.1568075021107993

Epoch: 6| Step: 5
Training loss: 2.2073512077331543
Validation loss: 2.121378163496653

Epoch: 6| Step: 6
Training loss: 1.560266375541687
Validation loss: 2.1164023677508035

Epoch: 6| Step: 7
Training loss: 1.916580080986023
Validation loss: 2.1205272873242698

Epoch: 6| Step: 8
Training loss: 1.354142427444458
Validation loss: 2.117465873559316

Epoch: 6| Step: 9
Training loss: 1.2916972637176514
Validation loss: 2.1569937467575073

Epoch: 6| Step: 10
Training loss: 1.8192758560180664
Validation loss: 2.175117274125417

Epoch: 6| Step: 11
Training loss: 1.7344374656677246
Validation loss: 2.1622122526168823

Epoch: 6| Step: 12
Training loss: 2.22597336769104
Validation loss: 2.099990169207255

Epoch: 6| Step: 13
Training loss: 2.0789477825164795
Validation loss: 2.098092039426168

Epoch: 76| Step: 0
Training loss: 1.8393906354904175
Validation loss: 2.1308964490890503

Epoch: 6| Step: 1
Training loss: 1.3803181648254395
Validation loss: 2.1371036171913147

Epoch: 6| Step: 2
Training loss: 1.8780642747879028
Validation loss: 2.2011626958847046

Epoch: 6| Step: 3
Training loss: 2.079754114151001
Validation loss: 2.201389948527018

Epoch: 6| Step: 4
Training loss: 1.286273717880249
Validation loss: 2.169744332631429

Epoch: 6| Step: 5
Training loss: 1.317241907119751
Validation loss: 2.2454742391904197

Epoch: 6| Step: 6
Training loss: 2.4126508235931396
Validation loss: 2.2310479879379272

Epoch: 6| Step: 7
Training loss: 1.562359094619751
Validation loss: 2.1889206171035767

Epoch: 6| Step: 8
Training loss: 1.6352548599243164
Validation loss: 2.203376034895579

Epoch: 6| Step: 9
Training loss: 1.945403814315796
Validation loss: 2.1868937611579895

Epoch: 6| Step: 10
Training loss: 1.2655800580978394
Validation loss: 2.1646384994188943

Epoch: 6| Step: 11
Training loss: 1.861167311668396
Validation loss: 2.122970382372538

Epoch: 6| Step: 12
Training loss: 1.2983005046844482
Validation loss: 2.141221900780996

Epoch: 6| Step: 13
Training loss: 1.6792757511138916
Validation loss: 2.115716874599457

Epoch: 77| Step: 0
Training loss: 1.3343268632888794
Validation loss: 2.1098804076512656

Epoch: 6| Step: 1
Training loss: 0.9817785024642944
Validation loss: 2.1608196099599204

Epoch: 6| Step: 2
Training loss: 0.7105731964111328
Validation loss: 2.1451375484466553

Epoch: 6| Step: 3
Training loss: 2.3151698112487793
Validation loss: 2.1132906476656594

Epoch: 6| Step: 4
Training loss: 1.7387531995773315
Validation loss: 2.133224606513977

Epoch: 6| Step: 5
Training loss: 1.3189833164215088
Validation loss: 2.1424742341041565

Epoch: 6| Step: 6
Training loss: 2.0270485877990723
Validation loss: 2.1490636070569358

Epoch: 6| Step: 7
Training loss: 1.7847480773925781
Validation loss: 2.219104011853536

Epoch: 6| Step: 8
Training loss: 1.9073432683944702
Validation loss: 2.183056354522705

Epoch: 6| Step: 9
Training loss: 2.2291059494018555
Validation loss: 2.210513194402059

Epoch: 6| Step: 10
Training loss: 1.8519740104675293
Validation loss: 2.213310201962789

Epoch: 6| Step: 11
Training loss: 1.9290646314620972
Validation loss: 2.20055357615153

Epoch: 6| Step: 12
Training loss: 2.3932607173919678
Validation loss: 2.1727601488431296

Epoch: 6| Step: 13
Training loss: 1.3599019050598145
Validation loss: 2.223521669705709

Epoch: 78| Step: 0
Training loss: 1.5240509510040283
Validation loss: 2.1577210823694863

Epoch: 6| Step: 1
Training loss: 2.312302589416504
Validation loss: 2.189274867375692

Epoch: 6| Step: 2
Training loss: 1.391237497329712
Validation loss: 2.1115419268608093

Epoch: 6| Step: 3
Training loss: 1.6087478399276733
Validation loss: 2.1259730656941733

Epoch: 6| Step: 4
Training loss: 1.880937099456787
Validation loss: 2.119288901487986

Epoch: 6| Step: 5
Training loss: 1.9142889976501465
Validation loss: 2.123535613218943

Epoch: 6| Step: 6
Training loss: 1.5802454948425293
Validation loss: 2.1817249854405723

Epoch: 6| Step: 7
Training loss: 1.1247342824935913
Validation loss: 2.1177184780438743

Epoch: 6| Step: 8
Training loss: 1.947359323501587
Validation loss: 2.16247965892156

Epoch: 6| Step: 9
Training loss: 1.6389341354370117
Validation loss: 2.144952336947123

Epoch: 6| Step: 10
Training loss: 1.625741720199585
Validation loss: 2.167985439300537

Epoch: 6| Step: 11
Training loss: 1.719529151916504
Validation loss: 2.1955331563949585

Epoch: 6| Step: 12
Training loss: 1.6756494045257568
Validation loss: 2.1608973344167075

Epoch: 6| Step: 13
Training loss: 1.412408471107483
Validation loss: 2.1224801937739053

Epoch: 79| Step: 0
Training loss: 1.7337665557861328
Validation loss: 2.143902142842611

Epoch: 6| Step: 1
Training loss: 1.7227377891540527
Validation loss: 2.1134528319040933

Epoch: 6| Step: 2
Training loss: 1.7018146514892578
Validation loss: 2.1105923851331077

Epoch: 6| Step: 3
Training loss: 1.2461329698562622
Validation loss: 2.1270813743273416

Epoch: 6| Step: 4
Training loss: 1.2762318849563599
Validation loss: 2.1341756184895835

Epoch: 6| Step: 5
Training loss: 1.8663419485092163
Validation loss: 2.1455692648887634

Epoch: 6| Step: 6
Training loss: 2.0735363960266113
Validation loss: 2.149340569972992

Epoch: 6| Step: 7
Training loss: 1.47206449508667
Validation loss: 2.191909372806549

Epoch: 6| Step: 8
Training loss: 2.4152562618255615
Validation loss: 2.11673895517985

Epoch: 6| Step: 9
Training loss: 1.4914454221725464
Validation loss: 2.1294463078180947

Epoch: 6| Step: 10
Training loss: 1.732330322265625
Validation loss: 2.16853129863739

Epoch: 6| Step: 11
Training loss: 1.8276236057281494
Validation loss: 2.1798106034596763

Epoch: 6| Step: 12
Training loss: 1.223062515258789
Validation loss: 2.118349552154541

Epoch: 6| Step: 13
Training loss: 1.420656442642212
Validation loss: 2.1681995193163552

Epoch: 80| Step: 0
Training loss: 1.7577847242355347
Validation loss: 2.1339439153671265

Epoch: 6| Step: 1
Training loss: 1.7291430234909058
Validation loss: 2.1365296840667725

Epoch: 6| Step: 2
Training loss: 2.130445718765259
Validation loss: 2.139142473538717

Epoch: 6| Step: 3
Training loss: 1.193344235420227
Validation loss: 2.094991127649943

Epoch: 6| Step: 4
Training loss: 1.7898857593536377
Validation loss: 2.081979831059774

Epoch: 6| Step: 5
Training loss: 1.8767399787902832
Validation loss: 2.1280674735705056

Epoch: 6| Step: 6
Training loss: 1.4424872398376465
Validation loss: 2.137366155783335

Epoch: 6| Step: 7
Training loss: 1.4349483251571655
Validation loss: 2.129428267478943

Epoch: 6| Step: 8
Training loss: 1.8420288562774658
Validation loss: 2.1255662043889365

Epoch: 6| Step: 9
Training loss: 1.5385496616363525
Validation loss: 2.1189666191736856

Epoch: 6| Step: 10
Training loss: 1.6191256046295166
Validation loss: 2.112417737642924

Epoch: 6| Step: 11
Training loss: 2.01003360748291
Validation loss: 2.1145092447598777

Epoch: 6| Step: 12
Training loss: 1.94010329246521
Validation loss: 2.1145535906155906

Epoch: 6| Step: 13
Training loss: 1.1143221855163574
Validation loss: 2.1300569574038186

Epoch: 81| Step: 0
Training loss: 1.6744883060455322
Validation loss: 2.086305101712545

Epoch: 6| Step: 1
Training loss: 1.6040107011795044
Validation loss: 2.21741376320521

Epoch: 6| Step: 2
Training loss: 1.1416316032409668
Validation loss: 2.2123770515124

Epoch: 6| Step: 3
Training loss: 1.185671091079712
Validation loss: 2.2175370256106057

Epoch: 6| Step: 4
Training loss: 1.9270291328430176
Validation loss: 2.1627204219500222

Epoch: 6| Step: 5
Training loss: 1.6918286085128784
Validation loss: 2.183428188165029

Epoch: 6| Step: 6
Training loss: 1.738678216934204
Validation loss: 2.205055852731069

Epoch: 6| Step: 7
Training loss: 2.0988316535949707
Validation loss: 2.2169160644213357

Epoch: 6| Step: 8
Training loss: 1.3042651414871216
Validation loss: 2.183476726214091

Epoch: 6| Step: 9
Training loss: 1.2904988527297974
Validation loss: 2.171912054220835

Epoch: 6| Step: 10
Training loss: 1.4297523498535156
Validation loss: 2.1078583002090454

Epoch: 6| Step: 11
Training loss: 2.407036304473877
Validation loss: 2.111686110496521

Epoch: 6| Step: 12
Training loss: 1.3800503015518188
Validation loss: 2.1572413444519043

Epoch: 6| Step: 13
Training loss: 1.6223194599151611
Validation loss: 2.1226271192232766

Epoch: 82| Step: 0
Training loss: 1.2051024436950684
Validation loss: 2.122418979803721

Epoch: 6| Step: 1
Training loss: 1.695272445678711
Validation loss: 2.10388974348704

Epoch: 6| Step: 2
Training loss: 1.7356476783752441
Validation loss: 2.1196035544077554

Epoch: 6| Step: 3
Training loss: 1.961780071258545
Validation loss: 2.110143860181173

Epoch: 6| Step: 4
Training loss: 1.996616005897522
Validation loss: 2.14011945327123

Epoch: 6| Step: 5
Training loss: 2.0715785026550293
Validation loss: 2.1265687147776284

Epoch: 6| Step: 6
Training loss: 1.2397171258926392
Validation loss: 2.1057602365811667

Epoch: 6| Step: 7
Training loss: 1.3474504947662354
Validation loss: 2.1201749245325723

Epoch: 6| Step: 8
Training loss: 1.855444073677063
Validation loss: 2.136757771174113

Epoch: 6| Step: 9
Training loss: 1.8126788139343262
Validation loss: 2.145509878794352

Epoch: 6| Step: 10
Training loss: 1.393628716468811
Validation loss: 2.171264171600342

Epoch: 6| Step: 11
Training loss: 1.8041255474090576
Validation loss: 2.1833035548528037

Epoch: 6| Step: 12
Training loss: 1.38332998752594
Validation loss: 2.1763853828112283

Epoch: 6| Step: 13
Training loss: 1.9015339612960815
Validation loss: 2.1591387589772544

Epoch: 83| Step: 0
Training loss: 1.1914989948272705
Validation loss: 2.142185906569163

Epoch: 6| Step: 1
Training loss: 1.3609107732772827
Validation loss: 2.1200510064760842

Epoch: 6| Step: 2
Training loss: 1.9375272989273071
Validation loss: 2.1411204735438027

Epoch: 6| Step: 3
Training loss: 1.8192375898361206
Validation loss: 2.150689681371053

Epoch: 6| Step: 4
Training loss: 1.4637763500213623
Validation loss: 2.119221866130829

Epoch: 6| Step: 5
Training loss: 2.125901222229004
Validation loss: 2.127484679222107

Epoch: 6| Step: 6
Training loss: 1.3699345588684082
Validation loss: 2.130233585834503

Epoch: 6| Step: 7
Training loss: 1.549147605895996
Validation loss: 2.1419054865837097

Epoch: 6| Step: 8
Training loss: 1.7686675786972046
Validation loss: 2.1414851347605386

Epoch: 6| Step: 9
Training loss: 1.1418801546096802
Validation loss: 2.11984517176946

Epoch: 6| Step: 10
Training loss: 1.5559463500976562
Validation loss: 2.142182171344757

Epoch: 6| Step: 11
Training loss: 1.816963791847229
Validation loss: 2.1781709591547647

Epoch: 6| Step: 12
Training loss: 1.7449235916137695
Validation loss: 2.1876028378804526

Epoch: 6| Step: 13
Training loss: 2.0411062240600586
Validation loss: 2.2563258608182273

Epoch: 84| Step: 0
Training loss: 1.515339732170105
Validation loss: 2.208645006020864

Epoch: 6| Step: 1
Training loss: 1.4070942401885986
Validation loss: 2.1483171582221985

Epoch: 6| Step: 2
Training loss: 1.0905511379241943
Validation loss: 2.2064578533172607

Epoch: 6| Step: 3
Training loss: 1.3311457633972168
Validation loss: 2.2130653858184814

Epoch: 6| Step: 4
Training loss: 1.9048466682434082
Validation loss: 2.124548077583313

Epoch: 6| Step: 5
Training loss: 1.764723300933838
Validation loss: 2.1664504408836365

Epoch: 6| Step: 6
Training loss: 1.7190501689910889
Validation loss: 2.163646161556244

Epoch: 6| Step: 7
Training loss: 2.0131020545959473
Validation loss: 2.1368096470832825

Epoch: 6| Step: 8
Training loss: 1.548828125
Validation loss: 2.1573191483815513

Epoch: 6| Step: 9
Training loss: 1.4708932638168335
Validation loss: 2.1318766673405967

Epoch: 6| Step: 10
Training loss: 1.7499085664749146
Validation loss: 2.160233199596405

Epoch: 6| Step: 11
Training loss: 1.8163326978683472
Validation loss: 2.155189315478007

Epoch: 6| Step: 12
Training loss: 2.0966105461120605
Validation loss: 2.1343605717023215

Epoch: 6| Step: 13
Training loss: 1.8214282989501953
Validation loss: 2.13179475069046

Epoch: 85| Step: 0
Training loss: 1.9379281997680664
Validation loss: 2.122334619363149

Epoch: 6| Step: 1
Training loss: 1.6756916046142578
Validation loss: 2.191840946674347

Epoch: 6| Step: 2
Training loss: 1.2182337045669556
Validation loss: 2.1687334179878235

Epoch: 6| Step: 3
Training loss: 1.4774678945541382
Validation loss: 2.187672197818756

Epoch: 6| Step: 4
Training loss: 1.658469319343567
Validation loss: 2.156450867652893

Epoch: 6| Step: 5
Training loss: 1.4559656381607056
Validation loss: 2.1976489226023355

Epoch: 6| Step: 6
Training loss: 2.4085352420806885
Validation loss: 2.1532129446665444

Epoch: 6| Step: 7
Training loss: 1.243687629699707
Validation loss: 2.180032968521118

Epoch: 6| Step: 8
Training loss: 1.4107080698013306
Validation loss: 2.1754177808761597

Epoch: 6| Step: 9
Training loss: 1.1999608278274536
Validation loss: 2.163708726565043

Epoch: 6| Step: 10
Training loss: 1.5366804599761963
Validation loss: 2.078163127104441

Epoch: 6| Step: 11
Training loss: 1.6537715196609497
Validation loss: 2.125210146109263

Epoch: 6| Step: 12
Training loss: 1.845226764678955
Validation loss: 2.156096617380778

Epoch: 6| Step: 13
Training loss: 1.6906448602676392
Validation loss: 2.182701587677002

Epoch: 86| Step: 0
Training loss: 1.5118796825408936
Validation loss: 2.1623377601305642

Epoch: 6| Step: 1
Training loss: 1.4589898586273193
Validation loss: 2.165753404299418

Epoch: 6| Step: 2
Training loss: 2.604308605194092
Validation loss: 2.087501883506775

Epoch: 6| Step: 3
Training loss: 1.6229932308197021
Validation loss: 2.103542745113373

Epoch: 6| Step: 4
Training loss: 1.7476451396942139
Validation loss: 2.1608893275260925

Epoch: 6| Step: 5
Training loss: 1.8342642784118652
Validation loss: 2.1727011998494468

Epoch: 6| Step: 6
Training loss: 1.5512034893035889
Validation loss: 2.18918776512146

Epoch: 6| Step: 7
Training loss: 1.8039779663085938
Validation loss: 2.1747498512268066

Epoch: 6| Step: 8
Training loss: 1.397033929824829
Validation loss: 2.2012906273206077

Epoch: 6| Step: 9
Training loss: 1.0315009355545044
Validation loss: 2.195851186911265

Epoch: 6| Step: 10
Training loss: 1.6820026636123657
Validation loss: 2.180269738038381

Epoch: 6| Step: 11
Training loss: 1.5999141931533813
Validation loss: 2.16896915435791

Epoch: 6| Step: 12
Training loss: 1.8092349767684937
Validation loss: 2.091678261756897

Epoch: 6| Step: 13
Training loss: 1.0418986082077026
Validation loss: 2.194833815097809

Epoch: 87| Step: 0
Training loss: 2.746018886566162
Validation loss: 2.140679180622101

Epoch: 6| Step: 1
Training loss: 1.0843409299850464
Validation loss: 2.1616954803466797

Epoch: 6| Step: 2
Training loss: 1.9526174068450928
Validation loss: 2.1727124651273093

Epoch: 6| Step: 3
Training loss: 1.582289695739746
Validation loss: 2.1480968793233237

Epoch: 6| Step: 4
Training loss: 1.5108227729797363
Validation loss: 2.1250357826550803

Epoch: 6| Step: 5
Training loss: 1.4190924167633057
Validation loss: 2.1218289136886597

Epoch: 6| Step: 6
Training loss: 1.542720079421997
Validation loss: 2.1518031557401023

Epoch: 6| Step: 7
Training loss: 1.156038761138916
Validation loss: 2.141761541366577

Epoch: 6| Step: 8
Training loss: 1.8964629173278809
Validation loss: 2.1843349933624268

Epoch: 6| Step: 9
Training loss: 1.887454628944397
Validation loss: 2.1728065411249795

Epoch: 6| Step: 10
Training loss: 1.5547746419906616
Validation loss: 2.1573838591575623

Epoch: 6| Step: 11
Training loss: 1.389979362487793
Validation loss: 2.191861708958944

Epoch: 6| Step: 12
Training loss: 2.0010733604431152
Validation loss: 2.1495245893796286

Epoch: 6| Step: 13
Training loss: 1.4956402778625488
Validation loss: 2.153115669886271

Epoch: 88| Step: 0
Training loss: 1.9862135648727417
Validation loss: 2.1518345872561135

Epoch: 6| Step: 1
Training loss: 1.374159574508667
Validation loss: 2.189224203427633

Epoch: 6| Step: 2
Training loss: 1.9185869693756104
Validation loss: 2.1030914982159934

Epoch: 6| Step: 3
Training loss: 2.1538052558898926
Validation loss: 2.1743004520734153

Epoch: 6| Step: 4
Training loss: 1.4862382411956787
Validation loss: 2.1380725701649985

Epoch: 6| Step: 5
Training loss: 2.165959119796753
Validation loss: 2.12822691599528

Epoch: 6| Step: 6
Training loss: 1.4708442687988281
Validation loss: 2.1745068033536277

Epoch: 6| Step: 7
Training loss: 1.409949779510498
Validation loss: 2.147665560245514

Epoch: 6| Step: 8
Training loss: 1.267207384109497
Validation loss: 2.1334178845087686

Epoch: 6| Step: 9
Training loss: 1.1420118808746338
Validation loss: 2.1461827754974365

Epoch: 6| Step: 10
Training loss: 1.7264409065246582
Validation loss: 2.1509768764177957

Epoch: 6| Step: 11
Training loss: 1.7232853174209595
Validation loss: 2.227857788403829

Epoch: 6| Step: 12
Training loss: 0.9846212863922119
Validation loss: 2.1911802689234414

Epoch: 6| Step: 13
Training loss: 1.3755481243133545
Validation loss: 2.176180362701416

Epoch: 89| Step: 0
Training loss: 1.7043808698654175
Validation loss: 2.135863800843557

Epoch: 6| Step: 1
Training loss: 1.509876012802124
Validation loss: 2.1898621718088784

Epoch: 6| Step: 2
Training loss: 1.7229831218719482
Validation loss: 2.1527846455574036

Epoch: 6| Step: 3
Training loss: 1.9727572202682495
Validation loss: 2.1368448535601297

Epoch: 6| Step: 4
Training loss: 1.6817574501037598
Validation loss: 2.0843454798062644

Epoch: 6| Step: 5
Training loss: 0.9372459053993225
Validation loss: 2.1865397095680237

Epoch: 6| Step: 6
Training loss: 2.084636688232422
Validation loss: 2.2188830773035684

Epoch: 6| Step: 7
Training loss: 1.9860765933990479
Validation loss: 2.127081294854482

Epoch: 6| Step: 8
Training loss: 1.4141011238098145
Validation loss: 2.1538129846254983

Epoch: 6| Step: 9
Training loss: 1.144162893295288
Validation loss: 2.1824920376141868

Epoch: 6| Step: 10
Training loss: 1.3928682804107666
Validation loss: 2.192138950030009

Epoch: 6| Step: 11
Training loss: 0.5923688411712646
Validation loss: 2.1897976795832315

Epoch: 6| Step: 12
Training loss: 1.4106755256652832
Validation loss: 2.2080811659495034

Epoch: 6| Step: 13
Training loss: 2.15860652923584
Validation loss: 2.201086441675822

Epoch: 90| Step: 0
Training loss: 0.9877967834472656
Validation loss: 2.2145203351974487

Epoch: 6| Step: 1
Training loss: 1.984771490097046
Validation loss: 2.27585776646932

Epoch: 6| Step: 2
Training loss: 1.9844852685928345
Validation loss: 2.3159740567207336

Epoch: 6| Step: 3
Training loss: 1.6878876686096191
Validation loss: 2.2591825326283774

Epoch: 6| Step: 4
Training loss: 1.9326907396316528
Validation loss: 2.233948588371277

Epoch: 6| Step: 5
Training loss: 1.7821356058120728
Validation loss: 2.1806281407674155

Epoch: 6| Step: 6
Training loss: 1.0809475183486938
Validation loss: 2.2551238735516868

Epoch: 6| Step: 7
Training loss: 1.8977644443511963
Validation loss: 2.1585521896680198

Epoch: 6| Step: 8
Training loss: 1.725416898727417
Validation loss: 2.1757245659828186

Epoch: 6| Step: 9
Training loss: 1.777259349822998
Validation loss: 2.137205719947815

Epoch: 6| Step: 10
Training loss: 1.0874743461608887
Validation loss: 2.2037265300750732

Epoch: 6| Step: 11
Training loss: 1.3791269063949585
Validation loss: 2.1883322993914285

Epoch: 6| Step: 12
Training loss: 2.35630202293396
Validation loss: 2.1969878673553467

Epoch: 6| Step: 13
Training loss: 1.4073867797851562
Validation loss: 2.1135970751444497

Epoch: 91| Step: 0
Training loss: 1.3396530151367188
Validation loss: 2.141524056593577

Epoch: 6| Step: 1
Training loss: 2.117290496826172
Validation loss: 2.2210351824760437

Epoch: 6| Step: 2
Training loss: 1.7007215023040771
Validation loss: 2.202719271183014

Epoch: 6| Step: 3
Training loss: 1.6100413799285889
Validation loss: 2.2191333770751953

Epoch: 6| Step: 4
Training loss: 1.5390586853027344
Validation loss: 2.287523110707601

Epoch: 6| Step: 5
Training loss: 1.7082278728485107
Validation loss: 2.2624787092208862

Epoch: 6| Step: 6
Training loss: 1.509484052658081
Validation loss: 2.3016704320907593

Epoch: 6| Step: 7
Training loss: 1.476549744606018
Validation loss: 2.2458401918411255

Epoch: 6| Step: 8
Training loss: 1.7281560897827148
Validation loss: 2.2158740957578025

Epoch: 6| Step: 9
Training loss: 1.6563606262207031
Validation loss: 2.1948516567548118

Epoch: 6| Step: 10
Training loss: 1.0521674156188965
Validation loss: 2.1526573101679483

Epoch: 6| Step: 11
Training loss: 1.4015482664108276
Validation loss: 2.140680988629659

Epoch: 6| Step: 12
Training loss: 1.564914584159851
Validation loss: 2.157304803530375

Epoch: 6| Step: 13
Training loss: 1.6900840997695923
Validation loss: 2.124452074368795

Epoch: 92| Step: 0
Training loss: 1.9862644672393799
Validation loss: 2.164355993270874

Epoch: 6| Step: 1
Training loss: 1.7417494058609009
Validation loss: 2.184419790903727

Epoch: 6| Step: 2
Training loss: 1.609037160873413
Validation loss: 2.1754422187805176

Epoch: 6| Step: 3
Training loss: 1.1827555894851685
Validation loss: 2.1410037080446878

Epoch: 6| Step: 4
Training loss: 1.697157621383667
Validation loss: 2.172458827495575

Epoch: 6| Step: 5
Training loss: 1.142249584197998
Validation loss: 2.166483441988627

Epoch: 6| Step: 6
Training loss: 2.2369775772094727
Validation loss: 2.1506486733754477

Epoch: 6| Step: 7
Training loss: 1.443368911743164
Validation loss: 2.1674288511276245

Epoch: 6| Step: 8
Training loss: 0.7344508171081543
Validation loss: 2.1585143009821572

Epoch: 6| Step: 9
Training loss: 1.330610752105713
Validation loss: 2.20379900932312

Epoch: 6| Step: 10
Training loss: 1.5130722522735596
Validation loss: 2.2212923765182495

Epoch: 6| Step: 11
Training loss: 1.1199004650115967
Validation loss: 2.1863340735435486

Epoch: 6| Step: 12
Training loss: 1.5502231121063232
Validation loss: 2.1524757941563926

Epoch: 6| Step: 13
Training loss: 1.6114023923873901
Validation loss: 2.1432949701944985

Epoch: 93| Step: 0
Training loss: 0.8755271434783936
Validation loss: 2.179571509361267

Epoch: 6| Step: 1
Training loss: 1.7232908010482788
Validation loss: 2.2008100350697837

Epoch: 6| Step: 2
Training loss: 0.8213686943054199
Validation loss: 2.2753405968348184

Epoch: 6| Step: 3
Training loss: 1.9747954607009888
Validation loss: 2.178764581680298

Epoch: 6| Step: 4
Training loss: 1.830413818359375
Validation loss: 2.157027006149292

Epoch: 6| Step: 5
Training loss: 1.5453671216964722
Validation loss: 2.240596433480581

Epoch: 6| Step: 6
Training loss: 1.6623173952102661
Validation loss: 2.164613207181295

Epoch: 6| Step: 7
Training loss: 2.0292904376983643
Validation loss: 2.2118263641993203

Epoch: 6| Step: 8
Training loss: 1.8953793048858643
Validation loss: 2.1867125431696572

Epoch: 6| Step: 9
Training loss: 1.0506608486175537
Validation loss: 2.219411333401998

Epoch: 6| Step: 10
Training loss: 1.4119629859924316
Validation loss: 2.1755574146906533

Epoch: 6| Step: 11
Training loss: 1.318233847618103
Validation loss: 2.178025265534719

Epoch: 6| Step: 12
Training loss: 1.6068555116653442
Validation loss: 2.167625149091085

Epoch: 6| Step: 13
Training loss: 1.5007634162902832
Validation loss: 2.208150307337443

Epoch: 94| Step: 0
Training loss: 1.5201714038848877
Validation loss: 2.22355717420578

Epoch: 6| Step: 1
Training loss: 2.214904308319092
Validation loss: 2.2581138610839844

Epoch: 6| Step: 2
Training loss: 1.632254958152771
Validation loss: 2.188204805056254

Epoch: 6| Step: 3
Training loss: 1.2076337337493896
Validation loss: 2.1906850735346475

Epoch: 6| Step: 4
Training loss: 1.0726652145385742
Validation loss: 2.1650277773539224

Epoch: 6| Step: 5
Training loss: 2.143970012664795
Validation loss: 2.1737687985102334

Epoch: 6| Step: 6
Training loss: 1.1717851161956787
Validation loss: 2.2288147608439126

Epoch: 6| Step: 7
Training loss: 1.3910386562347412
Validation loss: 2.164092779159546

Epoch: 6| Step: 8
Training loss: 1.4390164613723755
Validation loss: 2.2067284981409707

Epoch: 6| Step: 9
Training loss: 1.9478535652160645
Validation loss: 2.177938540776571

Epoch: 6| Step: 10
Training loss: 1.1836920976638794
Validation loss: 2.2372164726257324

Epoch: 6| Step: 11
Training loss: 1.341304063796997
Validation loss: 2.2492371797561646

Epoch: 6| Step: 12
Training loss: 1.5642260313034058
Validation loss: 2.19982115427653

Epoch: 6| Step: 13
Training loss: 1.7288837432861328
Validation loss: 2.1550769011179605

Epoch: 95| Step: 0
Training loss: 1.656494379043579
Validation loss: 2.1000225941340127

Epoch: 6| Step: 1
Training loss: 1.0289487838745117
Validation loss: 2.203257203102112

Epoch: 6| Step: 2
Training loss: 1.3506441116333008
Validation loss: 2.11398051182429

Epoch: 6| Step: 3
Training loss: 1.7228772640228271
Validation loss: 2.1352182229359946

Epoch: 6| Step: 4
Training loss: 1.2405035495758057
Validation loss: 2.173840900262197

Epoch: 6| Step: 5
Training loss: 2.0402321815490723
Validation loss: 2.1287200848261514

Epoch: 6| Step: 6
Training loss: 1.9021077156066895
Validation loss: 2.1531065901120505

Epoch: 6| Step: 7
Training loss: 1.6177637577056885
Validation loss: 2.1828934947649636

Epoch: 6| Step: 8
Training loss: 0.9766219854354858
Validation loss: 2.138719161351522

Epoch: 6| Step: 9
Training loss: 1.6168817281723022
Validation loss: 2.1736737291018167

Epoch: 6| Step: 10
Training loss: 1.3953121900558472
Validation loss: 2.2100747426350913

Epoch: 6| Step: 11
Training loss: 1.9020487070083618
Validation loss: 2.2617027759552

Epoch: 6| Step: 12
Training loss: 1.8708524703979492
Validation loss: 2.2291290163993835

Epoch: 6| Step: 13
Training loss: 1.1275408267974854
Validation loss: 2.226783514022827

Epoch: 96| Step: 0
Training loss: 1.3432862758636475
Validation loss: 2.240616043408712

Epoch: 6| Step: 1
Training loss: 1.754530429840088
Validation loss: 2.1984355250994363

Epoch: 6| Step: 2
Training loss: 1.4750566482543945
Validation loss: 2.1715766390164695

Epoch: 6| Step: 3
Training loss: 1.1985046863555908
Validation loss: 2.1592313249905906

Epoch: 6| Step: 4
Training loss: 1.9022228717803955
Validation loss: 2.198702851931254

Epoch: 6| Step: 5
Training loss: 1.2796707153320312
Validation loss: 2.181407550970713

Epoch: 6| Step: 6
Training loss: 0.996561586856842
Validation loss: 2.1857080260912576

Epoch: 6| Step: 7
Training loss: 1.5185184478759766
Validation loss: 2.1624374787012735

Epoch: 6| Step: 8
Training loss: 1.9241420030593872
Validation loss: 2.202008088429769

Epoch: 6| Step: 9
Training loss: 1.5668261051177979
Validation loss: 2.2008259693781533

Epoch: 6| Step: 10
Training loss: 2.5134897232055664
Validation loss: 2.1896027326583862

Epoch: 6| Step: 11
Training loss: 1.4260296821594238
Validation loss: 2.1912885308265686

Epoch: 6| Step: 12
Training loss: 0.8799374103546143
Validation loss: 2.1501280466715493

Epoch: 6| Step: 13
Training loss: 0.9451001286506653
Validation loss: 2.1328415671984353

Epoch: 97| Step: 0
Training loss: 1.905925989151001
Validation loss: 2.1638798912366233

Epoch: 6| Step: 1
Training loss: 1.0055718421936035
Validation loss: 2.131616473197937

Epoch: 6| Step: 2
Training loss: 1.5866841077804565
Validation loss: 2.1652408043543496

Epoch: 6| Step: 3
Training loss: 1.488260269165039
Validation loss: 2.150080462296804

Epoch: 6| Step: 4
Training loss: 1.1583607196807861
Validation loss: 2.177869458993276

Epoch: 6| Step: 5
Training loss: 1.8587353229522705
Validation loss: 2.147367020448049

Epoch: 6| Step: 6
Training loss: 1.0344715118408203
Validation loss: 2.1930309335390725

Epoch: 6| Step: 7
Training loss: 1.3795173168182373
Validation loss: 2.205712298552195

Epoch: 6| Step: 8
Training loss: 1.6595077514648438
Validation loss: 2.24629815419515

Epoch: 6| Step: 9
Training loss: 1.5251576900482178
Validation loss: 2.1975619792938232

Epoch: 6| Step: 10
Training loss: 1.1919362545013428
Validation loss: 2.245114286740621

Epoch: 6| Step: 11
Training loss: 1.8894786834716797
Validation loss: 2.2207871079444885

Epoch: 6| Step: 12
Training loss: 1.7927881479263306
Validation loss: 2.126672367254893

Epoch: 6| Step: 13
Training loss: 1.8738856315612793
Validation loss: 2.168497641881307

Epoch: 98| Step: 0
Training loss: 1.636573076248169
Validation loss: 2.1843071381251016

Epoch: 6| Step: 1
Training loss: 1.5160706043243408
Validation loss: 2.1566397746404014

Epoch: 6| Step: 2
Training loss: 1.2116090059280396
Validation loss: 2.1050861477851868

Epoch: 6| Step: 3
Training loss: 1.3684643507003784
Validation loss: 2.1743253072102866

Epoch: 6| Step: 4
Training loss: 1.0306096076965332
Validation loss: 2.1931380232175193

Epoch: 6| Step: 5
Training loss: 1.65562105178833
Validation loss: 2.1736236214637756

Epoch: 6| Step: 6
Training loss: 1.0571274757385254
Validation loss: 2.1739243070284524

Epoch: 6| Step: 7
Training loss: 1.2141571044921875
Validation loss: 2.1819771925608316

Epoch: 6| Step: 8
Training loss: 1.1233227252960205
Validation loss: 2.153604030609131

Epoch: 6| Step: 9
Training loss: 1.4651341438293457
Validation loss: 2.222673773765564

Epoch: 6| Step: 10
Training loss: 1.7283447980880737
Validation loss: 2.17341148853302

Epoch: 6| Step: 11
Training loss: 1.4536844491958618
Validation loss: 2.215921938419342

Epoch: 6| Step: 12
Training loss: 2.67338228225708
Validation loss: 2.2430911461512246

Epoch: 6| Step: 13
Training loss: 1.4786357879638672
Validation loss: 2.234253724416097

Epoch: 99| Step: 0
Training loss: 1.416651725769043
Validation loss: 2.139613231023153

Epoch: 6| Step: 1
Training loss: 0.9199081659317017
Validation loss: 2.1967859864234924

Epoch: 6| Step: 2
Training loss: 1.342429518699646
Validation loss: 2.131951610247294

Epoch: 6| Step: 3
Training loss: 1.0897343158721924
Validation loss: 2.1623284220695496

Epoch: 6| Step: 4
Training loss: 1.2103118896484375
Validation loss: 2.198760906855265

Epoch: 6| Step: 5
Training loss: 1.3996679782867432
Validation loss: 2.1621923247973123

Epoch: 6| Step: 6
Training loss: 1.5856809616088867
Validation loss: 2.1785611708958945

Epoch: 6| Step: 7
Training loss: 1.3409805297851562
Validation loss: 2.162405033906301

Epoch: 6| Step: 8
Training loss: 1.348688006401062
Validation loss: 2.2068570454915366

Epoch: 6| Step: 9
Training loss: 1.6214103698730469
Validation loss: 2.162742773691813

Epoch: 6| Step: 10
Training loss: 1.8528993129730225
Validation loss: 2.194993793964386

Epoch: 6| Step: 11
Training loss: 1.9184296131134033
Validation loss: 2.169920007387797

Epoch: 6| Step: 12
Training loss: 2.371344566345215
Validation loss: 2.1900527079900107

Epoch: 6| Step: 13
Training loss: 0.849284291267395
Validation loss: 2.1784127354621887

Epoch: 100| Step: 0
Training loss: 1.1892060041427612
Validation loss: 2.233120838801066

Epoch: 6| Step: 1
Training loss: 1.67940354347229
Validation loss: 2.223946531613668

Epoch: 6| Step: 2
Training loss: 1.205005407333374
Validation loss: 2.2527647813161216

Epoch: 6| Step: 3
Training loss: 2.3317975997924805
Validation loss: 2.200180411338806

Epoch: 6| Step: 4
Training loss: 1.8063127994537354
Validation loss: 2.1703590552012124

Epoch: 6| Step: 5
Training loss: 1.6518220901489258
Validation loss: 2.2265625993410745

Epoch: 6| Step: 6
Training loss: 1.5065059661865234
Validation loss: 2.167533497015635

Epoch: 6| Step: 7
Training loss: 1.8187354803085327
Validation loss: 2.1610997120539346

Epoch: 6| Step: 8
Training loss: 1.3278594017028809
Validation loss: 2.178894837697347

Epoch: 6| Step: 9
Training loss: 1.2795541286468506
Validation loss: 2.164122223854065

Epoch: 6| Step: 10
Training loss: 1.3234152793884277
Validation loss: 2.172102967898051

Epoch: 6| Step: 11
Training loss: 1.192007303237915
Validation loss: 2.1745433807373047

Epoch: 6| Step: 12
Training loss: 1.0965265035629272
Validation loss: 2.2095319628715515

Epoch: 6| Step: 13
Training loss: 1.0488061904907227
Validation loss: 2.230699976285299

Epoch: 101| Step: 0
Training loss: 1.4682763814926147
Validation loss: 2.210398316383362

Epoch: 6| Step: 1
Training loss: 1.209329605102539
Validation loss: 2.226716458797455

Epoch: 6| Step: 2
Training loss: 2.169217586517334
Validation loss: 2.17470383644104

Epoch: 6| Step: 3
Training loss: 1.4526636600494385
Validation loss: 2.1753164728482566

Epoch: 6| Step: 4
Training loss: 1.2427089214324951
Validation loss: 2.1784422198931375

Epoch: 6| Step: 5
Training loss: 0.9763410091400146
Validation loss: 2.1485769748687744

Epoch: 6| Step: 6
Training loss: 1.4176913499832153
Validation loss: 2.2022071878115335

Epoch: 6| Step: 7
Training loss: 1.4057433605194092
Validation loss: 2.189211666584015

Epoch: 6| Step: 8
Training loss: 1.8056055307388306
Validation loss: 2.1639449993769326

Epoch: 6| Step: 9
Training loss: 1.787907600402832
Validation loss: 2.211640179157257

Epoch: 6| Step: 10
Training loss: 0.8992416858673096
Validation loss: 2.1585604548454285

Epoch: 6| Step: 11
Training loss: 1.451740026473999
Validation loss: 2.26133664449056

Epoch: 6| Step: 12
Training loss: 1.1937260627746582
Validation loss: 2.2559609015782676

Epoch: 6| Step: 13
Training loss: 1.5428944826126099
Validation loss: 2.2455509503682456

Epoch: 102| Step: 0
Training loss: 1.4230440855026245
Validation loss: 2.202753742535909

Epoch: 6| Step: 1
Training loss: 1.3301494121551514
Validation loss: 2.1956733663876853

Epoch: 6| Step: 2
Training loss: 1.5922050476074219
Validation loss: 2.204152444998423

Epoch: 6| Step: 3
Training loss: 1.2407394647598267
Validation loss: 2.1536174019177756

Epoch: 6| Step: 4
Training loss: 1.0426334142684937
Validation loss: 2.165580968062083

Epoch: 6| Step: 5
Training loss: 2.0657782554626465
Validation loss: 2.1492738922437034

Epoch: 6| Step: 6
Training loss: 1.6164801120758057
Validation loss: 2.1586974064509072

Epoch: 6| Step: 7
Training loss: 1.5601975917816162
Validation loss: 2.240013281504313

Epoch: 6| Step: 8
Training loss: 1.372860074043274
Validation loss: 2.1782803535461426

Epoch: 6| Step: 9
Training loss: 2.2304129600524902
Validation loss: 2.1765068769454956

Epoch: 6| Step: 10
Training loss: 0.8730734586715698
Validation loss: 2.1989511251449585

Epoch: 6| Step: 11
Training loss: 1.3095204830169678
Validation loss: 2.180825630823771

Epoch: 6| Step: 12
Training loss: 0.7310535907745361
Validation loss: 2.151598890622457

Epoch: 6| Step: 13
Training loss: 1.2600359916687012
Validation loss: 2.153962234656016

Epoch: 103| Step: 0
Training loss: 1.914788007736206
Validation loss: 2.1394501527150473

Epoch: 6| Step: 1
Training loss: 1.2285162210464478
Validation loss: 2.149535655975342

Epoch: 6| Step: 2
Training loss: 1.0929386615753174
Validation loss: 2.1916013757387796

Epoch: 6| Step: 3
Training loss: 1.8637659549713135
Validation loss: 2.1607337594032288

Epoch: 6| Step: 4
Training loss: 1.0211867094039917
Validation loss: 2.1666837533315024

Epoch: 6| Step: 5
Training loss: 1.553745150566101
Validation loss: 2.169892887274424

Epoch: 6| Step: 6
Training loss: 1.3764064311981201
Validation loss: 2.1479934652646384

Epoch: 6| Step: 7
Training loss: 1.285773515701294
Validation loss: 2.208230455716451

Epoch: 6| Step: 8
Training loss: 1.1381151676177979
Validation loss: 2.1740004618962607

Epoch: 6| Step: 9
Training loss: 1.6039713621139526
Validation loss: 2.3012893199920654

Epoch: 6| Step: 10
Training loss: 1.6058402061462402
Validation loss: 2.3355491360028586

Epoch: 6| Step: 11
Training loss: 1.699897289276123
Validation loss: 2.3197080492973328

Epoch: 6| Step: 12
Training loss: 1.5757737159729004
Validation loss: 2.314493179321289

Epoch: 6| Step: 13
Training loss: 1.0439863204956055
Validation loss: 2.2141068379084268

Epoch: 104| Step: 0
Training loss: 1.323380947113037
Validation loss: 2.2196580171585083

Epoch: 6| Step: 1
Training loss: 1.326074481010437
Validation loss: 2.232042054335276

Epoch: 6| Step: 2
Training loss: 1.5115869045257568
Validation loss: 2.2095876932144165

Epoch: 6| Step: 3
Training loss: 1.5300095081329346
Validation loss: 2.1831727425257363

Epoch: 6| Step: 4
Training loss: 1.6634293794631958
Validation loss: 2.1375921169916787

Epoch: 6| Step: 5
Training loss: 1.0045764446258545
Validation loss: 2.1369136770566306

Epoch: 6| Step: 6
Training loss: 1.6319282054901123
Validation loss: 2.18148801724116

Epoch: 6| Step: 7
Training loss: 0.9119400978088379
Validation loss: 2.218378563721975

Epoch: 6| Step: 8
Training loss: 1.3829162120819092
Validation loss: 2.19756152232488

Epoch: 6| Step: 9
Training loss: 1.3825327157974243
Validation loss: 2.1641111771265664

Epoch: 6| Step: 10
Training loss: 2.1002683639526367
Validation loss: 2.223364988962809

Epoch: 6| Step: 11
Training loss: 0.88105708360672
Validation loss: 2.2485767006874084

Epoch: 6| Step: 12
Training loss: 1.2573604583740234
Validation loss: 2.2474690278371177

Epoch: 6| Step: 13
Training loss: 1.444382667541504
Validation loss: 2.1748473048210144

Epoch: 105| Step: 0
Training loss: 1.6926374435424805
Validation loss: 2.1905989249547324

Epoch: 6| Step: 1
Training loss: 2.013744831085205
Validation loss: 2.089303970336914

Epoch: 6| Step: 2
Training loss: 1.0746304988861084
Validation loss: 2.151406943798065

Epoch: 6| Step: 3
Training loss: 1.681269645690918
Validation loss: 2.2081976532936096

Epoch: 6| Step: 4
Training loss: 1.1182633638381958
Validation loss: 2.162041445573171

Epoch: 6| Step: 5
Training loss: 1.3242723941802979
Validation loss: 2.1938189268112183

Epoch: 6| Step: 6
Training loss: 1.0576716661453247
Validation loss: 2.186678687731425

Epoch: 6| Step: 7
Training loss: 1.8985261917114258
Validation loss: 2.184734801451365

Epoch: 6| Step: 8
Training loss: 1.5192351341247559
Validation loss: 2.165486673514048

Epoch: 6| Step: 9
Training loss: 0.8353517055511475
Validation loss: 2.1957227190335593

Epoch: 6| Step: 10
Training loss: 0.9106886386871338
Validation loss: 2.211251656214396

Epoch: 6| Step: 11
Training loss: 1.3992607593536377
Validation loss: 2.238513429959615

Epoch: 6| Step: 12
Training loss: 1.080129861831665
Validation loss: 2.192757507165273

Epoch: 6| Step: 13
Training loss: 1.6011260747909546
Validation loss: 2.130321522553762

Epoch: 106| Step: 0
Training loss: 0.8734606504440308
Validation loss: 2.2320921421051025

Epoch: 6| Step: 1
Training loss: 0.9526419639587402
Validation loss: 2.195051113764445

Epoch: 6| Step: 2
Training loss: 1.2749184370040894
Validation loss: 2.2016220887502036

Epoch: 6| Step: 3
Training loss: 0.9629614949226379
Validation loss: 2.22538689772288

Epoch: 6| Step: 4
Training loss: 1.060662865638733
Validation loss: 2.162023425102234

Epoch: 6| Step: 5
Training loss: 1.666015863418579
Validation loss: 2.2094856897989907

Epoch: 6| Step: 6
Training loss: 1.7605682611465454
Validation loss: 2.1526534159978232

Epoch: 6| Step: 7
Training loss: 1.2199674844741821
Validation loss: 2.162765145301819

Epoch: 6| Step: 8
Training loss: 1.4792068004608154
Validation loss: 2.1735652685165405

Epoch: 6| Step: 9
Training loss: 1.1100701093673706
Validation loss: 2.2085724671681723

Epoch: 6| Step: 10
Training loss: 1.4599342346191406
Validation loss: 2.1965821782747903

Epoch: 6| Step: 11
Training loss: 1.558014154434204
Validation loss: 2.215560793876648

Epoch: 6| Step: 12
Training loss: 1.6714503765106201
Validation loss: 2.3128047386805215

Epoch: 6| Step: 13
Training loss: 1.795154094696045
Validation loss: 2.231465518474579

Epoch: 107| Step: 0
Training loss: 1.1366103887557983
Validation loss: 2.209987004597982

Epoch: 6| Step: 1
Training loss: 1.2925670146942139
Validation loss: 2.2374980250994363

Epoch: 6| Step: 2
Training loss: 1.355700969696045
Validation loss: 2.302550653616587

Epoch: 6| Step: 3
Training loss: 1.431330680847168
Validation loss: 2.1547455191612244

Epoch: 6| Step: 4
Training loss: 1.7077219486236572
Validation loss: 2.1404769023259482

Epoch: 6| Step: 5
Training loss: 1.5019481182098389
Validation loss: 2.1026565432548523

Epoch: 6| Step: 6
Training loss: 1.0211544036865234
Validation loss: 2.216687560081482

Epoch: 6| Step: 7
Training loss: 1.0036358833312988
Validation loss: 2.165624996026357

Epoch: 6| Step: 8
Training loss: 0.7976983785629272
Validation loss: 2.1569844683011374

Epoch: 6| Step: 9
Training loss: 0.8698410987854004
Validation loss: 2.166244943936666

Epoch: 6| Step: 10
Training loss: 1.9866636991500854
Validation loss: 2.2343914906183877

Epoch: 6| Step: 11
Training loss: 1.3972594738006592
Validation loss: 2.211470286051432

Epoch: 6| Step: 12
Training loss: 1.206690788269043
Validation loss: 2.2378323872884116

Epoch: 6| Step: 13
Training loss: 1.912050485610962
Validation loss: 2.2010426123936973

Epoch: 108| Step: 0
Training loss: 1.428022027015686
Validation loss: 2.128017326196035

Epoch: 6| Step: 1
Training loss: 1.8831475973129272
Validation loss: 2.207974910736084

Epoch: 6| Step: 2
Training loss: 1.5879542827606201
Validation loss: 2.2609229683876038

Epoch: 6| Step: 3
Training loss: 1.3092682361602783
Validation loss: 2.213535706202189

Epoch: 6| Step: 4
Training loss: 0.7556809186935425
Validation loss: 2.207623461882273

Epoch: 6| Step: 5
Training loss: 1.0682252645492554
Validation loss: 2.204561491807302

Epoch: 6| Step: 6
Training loss: 1.3382060527801514
Validation loss: 2.21828031539917

Epoch: 6| Step: 7
Training loss: 1.2074439525604248
Validation loss: 2.16122567653656

Epoch: 6| Step: 8
Training loss: 1.0458898544311523
Validation loss: 2.179266333580017

Epoch: 6| Step: 9
Training loss: 1.8893316984176636
Validation loss: 2.2147481044133506

Epoch: 6| Step: 10
Training loss: 1.6906838417053223
Validation loss: 2.148799260457357

Epoch: 6| Step: 11
Training loss: 1.5583974123001099
Validation loss: 2.158880432446798

Epoch: 6| Step: 12
Training loss: 1.264993667602539
Validation loss: 2.184656023979187

Epoch: 6| Step: 13
Training loss: 0.709552526473999
Validation loss: 2.198074460029602

Epoch: 109| Step: 0
Training loss: 1.054371953010559
Validation loss: 2.2383753458658853

Epoch: 6| Step: 1
Training loss: 1.243497371673584
Validation loss: 2.294597009817759

Epoch: 6| Step: 2
Training loss: 1.236391544342041
Validation loss: 2.2303324739138284

Epoch: 6| Step: 3
Training loss: 1.2560834884643555
Validation loss: 2.2533100048700967

Epoch: 6| Step: 4
Training loss: 1.3231840133666992
Validation loss: 2.2124328215916953

Epoch: 6| Step: 5
Training loss: 1.1970739364624023
Validation loss: 2.2212268710136414

Epoch: 6| Step: 6
Training loss: 1.7908844947814941
Validation loss: 2.1976543068885803

Epoch: 6| Step: 7
Training loss: 1.351196527481079
Validation loss: 2.2044925689697266

Epoch: 6| Step: 8
Training loss: 1.4996309280395508
Validation loss: 2.172179897626241

Epoch: 6| Step: 9
Training loss: 1.3992581367492676
Validation loss: 2.1883424520492554

Epoch: 6| Step: 10
Training loss: 1.6308035850524902
Validation loss: 2.2397781213124595

Epoch: 6| Step: 11
Training loss: 1.3138829469680786
Validation loss: 2.226483464241028

Epoch: 6| Step: 12
Training loss: 1.4846057891845703
Validation loss: 2.226868192354838

Epoch: 6| Step: 13
Training loss: 1.184516191482544
Validation loss: 2.2194309631983438

Epoch: 110| Step: 0
Training loss: 2.0801641941070557
Validation loss: 2.3785074750582376

Epoch: 6| Step: 1
Training loss: 1.5011121034622192
Validation loss: 2.3236887057622275

Epoch: 6| Step: 2
Training loss: 1.6012687683105469
Validation loss: 2.3409900665283203

Epoch: 6| Step: 3
Training loss: 1.4438414573669434
Validation loss: 2.3061394691467285

Epoch: 6| Step: 4
Training loss: 0.985481321811676
Validation loss: 2.242703159650167

Epoch: 6| Step: 5
Training loss: 1.389997959136963
Validation loss: 2.20340762535731

Epoch: 6| Step: 6
Training loss: 1.2404168844223022
Validation loss: 2.184423287709554

Epoch: 6| Step: 7
Training loss: 1.8796242475509644
Validation loss: 2.249245802561442

Epoch: 6| Step: 8
Training loss: 1.3363085985183716
Validation loss: 2.197673519452413

Epoch: 6| Step: 9
Training loss: 1.261112928390503
Validation loss: 2.1754729549090066

Epoch: 6| Step: 10
Training loss: 1.1685856580734253
Validation loss: 2.193832596143087

Epoch: 6| Step: 11
Training loss: 1.5409650802612305
Validation loss: 2.2110726038614907

Epoch: 6| Step: 12
Training loss: 0.4310572147369385
Validation loss: 2.2311141888300576

Epoch: 6| Step: 13
Training loss: 1.4156954288482666
Validation loss: 2.246303697427114

Epoch: 111| Step: 0
Training loss: 0.8922966718673706
Validation loss: 2.2338101069132485

Epoch: 6| Step: 1
Training loss: 1.7933028936386108
Validation loss: 2.245306134223938

Epoch: 6| Step: 2
Training loss: 1.1749606132507324
Validation loss: 2.2306816975275674

Epoch: 6| Step: 3
Training loss: 1.2540086507797241
Validation loss: 2.2470326026280723

Epoch: 6| Step: 4
Training loss: 1.974928379058838
Validation loss: 2.241146365801493

Epoch: 6| Step: 5
Training loss: 0.9702030420303345
Validation loss: 2.1559590697288513

Epoch: 6| Step: 6
Training loss: 1.2974169254302979
Validation loss: 2.208704113960266

Epoch: 6| Step: 7
Training loss: 1.1763243675231934
Validation loss: 2.177400290966034

Epoch: 6| Step: 8
Training loss: 1.2916783094406128
Validation loss: 2.2551756699879966

Epoch: 6| Step: 9
Training loss: 1.27951979637146
Validation loss: 2.110384523868561

Epoch: 6| Step: 10
Training loss: 1.7171281576156616
Validation loss: 2.196368952592214

Epoch: 6| Step: 11
Training loss: 1.610558271408081
Validation loss: 2.2145559390385947

Epoch: 6| Step: 12
Training loss: 1.3431341648101807
Validation loss: 2.1761297980944314

Epoch: 6| Step: 13
Training loss: 1.1184492111206055
Validation loss: 2.2444453040758767

Epoch: 112| Step: 0
Training loss: 1.109806776046753
Validation loss: 2.2505418062210083

Epoch: 6| Step: 1
Training loss: 0.5896914005279541
Validation loss: 2.2138109604517617

Epoch: 6| Step: 2
Training loss: 1.1930699348449707
Validation loss: 2.1811925172805786

Epoch: 6| Step: 3
Training loss: 1.506401538848877
Validation loss: 2.2860547304153442

Epoch: 6| Step: 4
Training loss: 1.132196307182312
Validation loss: 2.282230774561564

Epoch: 6| Step: 5
Training loss: 1.699033498764038
Validation loss: 2.215072830518087

Epoch: 6| Step: 6
Training loss: 1.784256935119629
Validation loss: 2.1715524991353354

Epoch: 6| Step: 7
Training loss: 1.2073930501937866
Validation loss: 2.1962820291519165

Epoch: 6| Step: 8
Training loss: 1.007033109664917
Validation loss: 2.1907851696014404

Epoch: 6| Step: 9
Training loss: 1.6317555904388428
Validation loss: 2.287004987398783

Epoch: 6| Step: 10
Training loss: 2.148484468460083
Validation loss: 2.225354015827179

Epoch: 6| Step: 11
Training loss: 0.9160480499267578
Validation loss: 2.20124214887619

Epoch: 6| Step: 12
Training loss: 1.2563707828521729
Validation loss: 2.2100258668263755

Epoch: 6| Step: 13
Training loss: 0.9709279537200928
Validation loss: 2.202616016070048

Epoch: 113| Step: 0
Training loss: 0.838844895362854
Validation loss: 2.2625173528989158

Epoch: 6| Step: 1
Training loss: 1.6631929874420166
Validation loss: 2.183124224344889

Epoch: 6| Step: 2
Training loss: 0.9669220447540283
Validation loss: 2.2114256024360657

Epoch: 6| Step: 3
Training loss: 0.7051056027412415
Validation loss: 2.220599095026652

Epoch: 6| Step: 4
Training loss: 1.5421617031097412
Validation loss: 2.2717409133911133

Epoch: 6| Step: 5
Training loss: 0.7428182363510132
Validation loss: 2.263012488683065

Epoch: 6| Step: 6
Training loss: 1.014641523361206
Validation loss: 2.1795186003049216

Epoch: 6| Step: 7
Training loss: 1.714449167251587
Validation loss: 2.2363921205202737

Epoch: 6| Step: 8
Training loss: 1.3180902004241943
Validation loss: 2.1476306120554605

Epoch: 6| Step: 9
Training loss: 1.7997022867202759
Validation loss: 2.1942179203033447

Epoch: 6| Step: 10
Training loss: 1.5240498781204224
Validation loss: 2.1691216627756753

Epoch: 6| Step: 11
Training loss: 0.921765148639679
Validation loss: 2.1534459988276162

Epoch: 6| Step: 12
Training loss: 1.0430209636688232
Validation loss: 2.2296713987986245

Epoch: 6| Step: 13
Training loss: 1.8163719177246094
Validation loss: 2.243775208791097

Epoch: 114| Step: 0
Training loss: 0.7909401655197144
Validation loss: 2.2717689871788025

Epoch: 6| Step: 1
Training loss: 2.409412384033203
Validation loss: 2.280111789703369

Epoch: 6| Step: 2
Training loss: 1.2902647256851196
Validation loss: 2.216751297314962

Epoch: 6| Step: 3
Training loss: 1.4594500064849854
Validation loss: 2.183618485927582

Epoch: 6| Step: 4
Training loss: 1.1987910270690918
Validation loss: 2.2201234499613443

Epoch: 6| Step: 5
Training loss: 1.490332841873169
Validation loss: 2.2347052892049155

Epoch: 6| Step: 6
Training loss: 0.7112523913383484
Validation loss: 2.201866646607717

Epoch: 6| Step: 7
Training loss: 0.7861016988754272
Validation loss: 2.1928872068723044

Epoch: 6| Step: 8
Training loss: 1.6045401096343994
Validation loss: 2.1628253857294717

Epoch: 6| Step: 9
Training loss: 1.4808545112609863
Validation loss: 2.1981950600941977

Epoch: 6| Step: 10
Training loss: 1.4644733667373657
Validation loss: 2.261238237222036

Epoch: 6| Step: 11
Training loss: 1.385697364807129
Validation loss: 2.254035154978434

Epoch: 6| Step: 12
Training loss: 0.9199744462966919
Validation loss: 2.3213411569595337

Epoch: 6| Step: 13
Training loss: 1.3031806945800781
Validation loss: 2.278754234313965

Epoch: 115| Step: 0
Training loss: 1.193766474723816
Validation loss: 2.215810855229696

Epoch: 6| Step: 1
Training loss: 0.9818100929260254
Validation loss: 2.1725125114123025

Epoch: 6| Step: 2
Training loss: 1.282862663269043
Validation loss: 2.202163298924764

Epoch: 6| Step: 3
Training loss: 1.2563047409057617
Validation loss: 2.1738120118776956

Epoch: 6| Step: 4
Training loss: 1.1622401475906372
Validation loss: 2.1719363927841187

Epoch: 6| Step: 5
Training loss: 1.9456819295883179
Validation loss: 2.1866791248321533

Epoch: 6| Step: 6
Training loss: 1.1121445894241333
Validation loss: 2.234516978263855

Epoch: 6| Step: 7
Training loss: 1.4283742904663086
Validation loss: 2.248490790526072

Epoch: 6| Step: 8
Training loss: 1.040792465209961
Validation loss: 2.2579336762428284

Epoch: 6| Step: 9
Training loss: 1.127440094947815
Validation loss: 2.158205290635427

Epoch: 6| Step: 10
Training loss: 1.2531611919403076
Validation loss: 2.2408302823702493

Epoch: 6| Step: 11
Training loss: 0.9360925555229187
Validation loss: 2.2697234551111856

Epoch: 6| Step: 12
Training loss: 1.8377830982208252
Validation loss: 2.2048149903615317

Epoch: 6| Step: 13
Training loss: 1.3042337894439697
Validation loss: 2.2365615566571555

Epoch: 116| Step: 0
Training loss: 1.2513236999511719
Validation loss: 2.277373254299164

Epoch: 6| Step: 1
Training loss: 1.2153637409210205
Validation loss: 2.2035202383995056

Epoch: 6| Step: 2
Training loss: 1.1115050315856934
Validation loss: 2.178314288457235

Epoch: 6| Step: 3
Training loss: 0.8990909457206726
Validation loss: 2.2060645818710327

Epoch: 6| Step: 4
Training loss: 1.1943280696868896
Validation loss: 2.230207920074463

Epoch: 6| Step: 5
Training loss: 1.1839722394943237
Validation loss: 2.20356277624766

Epoch: 6| Step: 6
Training loss: 1.602889060974121
Validation loss: 2.269137183825175

Epoch: 6| Step: 7
Training loss: 1.2769169807434082
Validation loss: 2.2907830476760864

Epoch: 6| Step: 8
Training loss: 1.7677185535430908
Validation loss: 2.2226165930430093

Epoch: 6| Step: 9
Training loss: 1.2698160409927368
Validation loss: 2.208017190297445

Epoch: 6| Step: 10
Training loss: 1.1439216136932373
Validation loss: 2.1595173478126526

Epoch: 6| Step: 11
Training loss: 1.447635531425476
Validation loss: 2.185117324193319

Epoch: 6| Step: 12
Training loss: 0.9291436076164246
Validation loss: 2.2792455355326333

Epoch: 6| Step: 13
Training loss: 1.3299839496612549
Validation loss: 2.211406131585439

Epoch: 117| Step: 0
Training loss: 0.6223835945129395
Validation loss: 2.2724077304204306

Epoch: 6| Step: 1
Training loss: 1.4853390455245972
Validation loss: 2.2386569579442344

Epoch: 6| Step: 2
Training loss: 1.8622325658798218
Validation loss: 2.235634724299113

Epoch: 6| Step: 3
Training loss: 1.1722865104675293
Validation loss: 2.270951231320699

Epoch: 6| Step: 4
Training loss: 0.9324617981910706
Validation loss: 2.2017359733581543

Epoch: 6| Step: 5
Training loss: 1.3617331981658936
Validation loss: 2.172574758529663

Epoch: 6| Step: 6
Training loss: 0.9436476230621338
Validation loss: 2.178841849168142

Epoch: 6| Step: 7
Training loss: 1.066955327987671
Validation loss: 2.2190134127934775

Epoch: 6| Step: 8
Training loss: 1.722970962524414
Validation loss: 2.2310220201810202

Epoch: 6| Step: 9
Training loss: 1.353432297706604
Validation loss: 2.202315946420034

Epoch: 6| Step: 10
Training loss: 0.7872993350028992
Validation loss: 2.206731915473938

Epoch: 6| Step: 11
Training loss: 0.9640486836433411
Validation loss: 2.212059736251831

Epoch: 6| Step: 12
Training loss: 1.2056760787963867
Validation loss: 2.2236214677492776

Epoch: 6| Step: 13
Training loss: 1.2479437589645386
Validation loss: 2.211541473865509

Epoch: 118| Step: 0
Training loss: 0.8253571391105652
Validation loss: 2.2086105744043985

Epoch: 6| Step: 1
Training loss: 1.5434101819992065
Validation loss: 2.2348565260569253

Epoch: 6| Step: 2
Training loss: 0.9462217092514038
Validation loss: 2.2441152532895408

Epoch: 6| Step: 3
Training loss: 2.0069656372070312
Validation loss: 2.25426838795344

Epoch: 6| Step: 4
Training loss: 1.2332545518875122
Validation loss: 2.2172059218088784

Epoch: 6| Step: 5
Training loss: 1.204984426498413
Validation loss: 2.2568269968032837

Epoch: 6| Step: 6
Training loss: 1.5028270483016968
Validation loss: 2.1879838506380715

Epoch: 6| Step: 7
Training loss: 0.9038630723953247
Validation loss: 2.220385650793711

Epoch: 6| Step: 8
Training loss: 0.8281396627426147
Validation loss: 2.2341175278027854

Epoch: 6| Step: 9
Training loss: 1.4467034339904785
Validation loss: 2.1741883556048074

Epoch: 6| Step: 10
Training loss: 1.3290115594863892
Validation loss: 2.2189637223879495

Epoch: 6| Step: 11
Training loss: 0.853714108467102
Validation loss: 2.196694850921631

Epoch: 6| Step: 12
Training loss: 1.0965466499328613
Validation loss: 2.1621715227762857

Epoch: 6| Step: 13
Training loss: 1.9387202262878418
Validation loss: 2.232671578725179

Epoch: 119| Step: 0
Training loss: 1.0145752429962158
Validation loss: 2.2721147934595742

Epoch: 6| Step: 1
Training loss: 1.0455677509307861
Validation loss: 2.3016686836878457

Epoch: 6| Step: 2
Training loss: 1.8841406106948853
Validation loss: 2.2748301227887473

Epoch: 6| Step: 3
Training loss: 1.3138220310211182
Validation loss: 2.2416937748591104

Epoch: 6| Step: 4
Training loss: 1.2599273920059204
Validation loss: 2.233750820159912

Epoch: 6| Step: 5
Training loss: 1.30401611328125
Validation loss: 2.2450761795043945

Epoch: 6| Step: 6
Training loss: 1.583993911743164
Validation loss: 2.1624567111333213

Epoch: 6| Step: 7
Training loss: 0.8491442203521729
Validation loss: 2.1301852464675903

Epoch: 6| Step: 8
Training loss: 1.0090751647949219
Validation loss: 2.198542137940725

Epoch: 6| Step: 9
Training loss: 1.2443516254425049
Validation loss: 2.1939632495244346

Epoch: 6| Step: 10
Training loss: 0.7179070711135864
Validation loss: 2.1971441904703775

Epoch: 6| Step: 11
Training loss: 1.2529280185699463
Validation loss: 2.1685710748036704

Epoch: 6| Step: 12
Training loss: 1.356809377670288
Validation loss: 2.2479803760846457

Epoch: 6| Step: 13
Training loss: 1.1091663837432861
Validation loss: 2.164184808731079

Epoch: 120| Step: 0
Training loss: 1.1308696269989014
Validation loss: 2.162826399008433

Epoch: 6| Step: 1
Training loss: 1.7821550369262695
Validation loss: 2.1727686723073325

Epoch: 6| Step: 2
Training loss: 0.7579985857009888
Validation loss: 2.236876626809438

Epoch: 6| Step: 3
Training loss: 1.5747593641281128
Validation loss: 2.172322412331899

Epoch: 6| Step: 4
Training loss: 0.9973818063735962
Validation loss: 2.1766671339670816

Epoch: 6| Step: 5
Training loss: 1.2683581113815308
Validation loss: 2.1815499464670816

Epoch: 6| Step: 6
Training loss: 0.9026458859443665
Validation loss: 2.2179240385691323

Epoch: 6| Step: 7
Training loss: 1.2511985301971436
Validation loss: 2.152805805206299

Epoch: 6| Step: 8
Training loss: 1.2860097885131836
Validation loss: 2.193727989991506

Epoch: 6| Step: 9
Training loss: 1.1130032539367676
Validation loss: 2.181529998779297

Epoch: 6| Step: 10
Training loss: 1.2904784679412842
Validation loss: 2.230380376180013

Epoch: 6| Step: 11
Training loss: 1.367781400680542
Validation loss: 2.1995655496915183

Epoch: 6| Step: 12
Training loss: 1.2018871307373047
Validation loss: 2.1552605628967285

Epoch: 6| Step: 13
Training loss: 0.884456217288971
Validation loss: 2.2379213174184165

Epoch: 121| Step: 0
Training loss: 1.3312238454818726
Validation loss: 2.2167611916859946

Epoch: 6| Step: 1
Training loss: 1.6607763767242432
Validation loss: 2.235861678918203

Epoch: 6| Step: 2
Training loss: 1.062666416168213
Validation loss: 2.24046782652537

Epoch: 6| Step: 3
Training loss: 0.9071491956710815
Validation loss: 2.2260497212409973

Epoch: 6| Step: 4
Training loss: 1.4037977457046509
Validation loss: 2.3076621492703757

Epoch: 6| Step: 5
Training loss: 0.8945130705833435
Validation loss: 2.211346387863159

Epoch: 6| Step: 6
Training loss: 1.335719347000122
Validation loss: 2.1802366574605307

Epoch: 6| Step: 7
Training loss: 1.099434494972229
Validation loss: 2.240897556145986

Epoch: 6| Step: 8
Training loss: 0.8708223104476929
Validation loss: 2.2330586115519204

Epoch: 6| Step: 9
Training loss: 1.7089428901672363
Validation loss: 2.2182602087656655

Epoch: 6| Step: 10
Training loss: 1.3095767498016357
Validation loss: 2.190739850203196

Epoch: 6| Step: 11
Training loss: 1.2898539304733276
Validation loss: 2.237433056036631

Epoch: 6| Step: 12
Training loss: 0.6330420970916748
Validation loss: 2.295543392499288

Epoch: 6| Step: 13
Training loss: 1.4156839847564697
Validation loss: 2.2286911010742188

Epoch: 122| Step: 0
Training loss: 1.1331963539123535
Validation loss: 2.2295651038487754

Epoch: 6| Step: 1
Training loss: 1.077402114868164
Validation loss: 2.204776406288147

Epoch: 6| Step: 2
Training loss: 1.0868891477584839
Validation loss: 2.2386773427327475

Epoch: 6| Step: 3
Training loss: 1.0344996452331543
Validation loss: 2.150074283281962

Epoch: 6| Step: 4
Training loss: 1.6633687019348145
Validation loss: 2.229669471581777

Epoch: 6| Step: 5
Training loss: 0.6985186338424683
Validation loss: 2.206072290738424

Epoch: 6| Step: 6
Training loss: 1.2692999839782715
Validation loss: 2.1640024185180664

Epoch: 6| Step: 7
Training loss: 0.8158761262893677
Validation loss: 2.149178167184194

Epoch: 6| Step: 8
Training loss: 0.8684744238853455
Validation loss: 2.1444484988848367

Epoch: 6| Step: 9
Training loss: 1.5071642398834229
Validation loss: 2.1531819899876914

Epoch: 6| Step: 10
Training loss: 1.6384682655334473
Validation loss: 2.2017638285954795

Epoch: 6| Step: 11
Training loss: 1.1579515933990479
Validation loss: 2.2577104965845742

Epoch: 6| Step: 12
Training loss: 0.9031226634979248
Validation loss: 2.2012551029523215

Epoch: 6| Step: 13
Training loss: 1.2965452671051025
Validation loss: 2.231706519921621

Epoch: 123| Step: 0
Training loss: 0.8722808957099915
Validation loss: 2.259433646996816

Epoch: 6| Step: 1
Training loss: 1.5454330444335938
Validation loss: 2.188942790031433

Epoch: 6| Step: 2
Training loss: 1.136257529258728
Validation loss: 2.206073443094889

Epoch: 6| Step: 3
Training loss: 1.1363670825958252
Validation loss: 2.2411036094029746

Epoch: 6| Step: 4
Training loss: 1.0770593881607056
Validation loss: 2.170965393384298

Epoch: 6| Step: 5
Training loss: 0.8585606217384338
Validation loss: 2.1565580566724143

Epoch: 6| Step: 6
Training loss: 1.501434087753296
Validation loss: 2.1969880859057107

Epoch: 6| Step: 7
Training loss: 1.1971758604049683
Validation loss: 2.11239484945933

Epoch: 6| Step: 8
Training loss: 1.1508653163909912
Validation loss: 2.2384976148605347

Epoch: 6| Step: 9
Training loss: 1.4882278442382812
Validation loss: 2.2165518601735434

Epoch: 6| Step: 10
Training loss: 1.2399814128875732
Validation loss: 2.26911723613739

Epoch: 6| Step: 11
Training loss: 1.769290566444397
Validation loss: 2.2104262113571167

Epoch: 6| Step: 12
Training loss: 1.1715238094329834
Validation loss: 2.234096050262451

Epoch: 6| Step: 13
Training loss: 0.8275750875473022
Validation loss: 2.1848570505777993

Epoch: 124| Step: 0
Training loss: 1.161799430847168
Validation loss: 2.1788421471913657

Epoch: 6| Step: 1
Training loss: 1.2248831987380981
Validation loss: 2.1364721854527793

Epoch: 6| Step: 2
Training loss: 0.8595407009124756
Validation loss: 2.132172445456187

Epoch: 6| Step: 3
Training loss: 0.9668020009994507
Validation loss: 2.222996155420939

Epoch: 6| Step: 4
Training loss: 0.9260427951812744
Validation loss: 2.2347912788391113

Epoch: 6| Step: 5
Training loss: 0.8824900388717651
Validation loss: 2.1970751682917276

Epoch: 6| Step: 6
Training loss: 1.1808744668960571
Validation loss: 2.234883745511373

Epoch: 6| Step: 7
Training loss: 1.2419793605804443
Validation loss: 2.1521008610725403

Epoch: 6| Step: 8
Training loss: 1.1380887031555176
Validation loss: 2.145804782708486

Epoch: 6| Step: 9
Training loss: 1.521010160446167
Validation loss: 2.239438792069753

Epoch: 6| Step: 10
Training loss: 1.537168025970459
Validation loss: 2.224157532056173

Epoch: 6| Step: 11
Training loss: 1.4731879234313965
Validation loss: 2.2250436345736184

Epoch: 6| Step: 12
Training loss: 1.256385087966919
Validation loss: 2.214734117190043

Epoch: 6| Step: 13
Training loss: 1.2503557205200195
Validation loss: 2.182633618513743

Epoch: 125| Step: 0
Training loss: 0.651217520236969
Validation loss: 2.139787495136261

Epoch: 6| Step: 1
Training loss: 0.8110671639442444
Validation loss: 2.186641196409861

Epoch: 6| Step: 2
Training loss: 1.075556755065918
Validation loss: 2.290771762530009

Epoch: 6| Step: 3
Training loss: 1.6868629455566406
Validation loss: 2.2345983584721885

Epoch: 6| Step: 4
Training loss: 1.5031105279922485
Validation loss: 2.2273133595784507

Epoch: 6| Step: 5
Training loss: 1.0577583312988281
Validation loss: 2.215861360232035

Epoch: 6| Step: 6
Training loss: 0.6750099658966064
Validation loss: 2.2103271484375

Epoch: 6| Step: 7
Training loss: 1.4861161708831787
Validation loss: 2.215484102567037

Epoch: 6| Step: 8
Training loss: 1.0783965587615967
Validation loss: 2.187603692213694

Epoch: 6| Step: 9
Training loss: 0.9745320677757263
Validation loss: 2.176408608754476

Epoch: 6| Step: 10
Training loss: 0.9389360547065735
Validation loss: 2.211464285850525

Epoch: 6| Step: 11
Training loss: 1.2476918697357178
Validation loss: 2.18617045879364

Epoch: 6| Step: 12
Training loss: 1.1220338344573975
Validation loss: 2.1962716380755105

Epoch: 6| Step: 13
Training loss: 1.4929516315460205
Validation loss: 2.19844514131546

Epoch: 126| Step: 0
Training loss: 1.0703526735305786
Validation loss: 2.237470885117849

Epoch: 6| Step: 1
Training loss: 1.2037690877914429
Validation loss: 2.1906495094299316

Epoch: 6| Step: 2
Training loss: 1.5790411233901978
Validation loss: 2.2022472620010376

Epoch: 6| Step: 3
Training loss: 1.0238525867462158
Validation loss: 2.248640517393748

Epoch: 6| Step: 4
Training loss: 0.9759535789489746
Validation loss: 2.1774689157803855

Epoch: 6| Step: 5
Training loss: 0.9163601398468018
Validation loss: 2.2562392552693686

Epoch: 6| Step: 6
Training loss: 0.5717403888702393
Validation loss: 2.2347331841786704

Epoch: 6| Step: 7
Training loss: 1.283212423324585
Validation loss: 2.1736622055371604

Epoch: 6| Step: 8
Training loss: 1.4765793085098267
Validation loss: 2.256910483042399

Epoch: 6| Step: 9
Training loss: 1.3061883449554443
Validation loss: 2.211663762728373

Epoch: 6| Step: 10
Training loss: 1.1937848329544067
Validation loss: 2.2557128270467124

Epoch: 6| Step: 11
Training loss: 1.1407617330551147
Validation loss: 2.2161396145820618

Epoch: 6| Step: 12
Training loss: 1.6643708944320679
Validation loss: 2.219609479109446

Epoch: 6| Step: 13
Training loss: 1.1954704523086548
Validation loss: 2.323105037212372

Epoch: 127| Step: 0
Training loss: 0.7180636525154114
Validation loss: 2.2906396190325418

Epoch: 6| Step: 1
Training loss: 0.9157545566558838
Validation loss: 2.1934523781140647

Epoch: 6| Step: 2
Training loss: 0.9856131076812744
Validation loss: 2.1712981462478638

Epoch: 6| Step: 3
Training loss: 1.1148231029510498
Validation loss: 2.1553593476613364

Epoch: 6| Step: 4
Training loss: 1.601334571838379
Validation loss: 2.2297356526056924

Epoch: 6| Step: 5
Training loss: 0.7380956411361694
Validation loss: 2.154913624127706

Epoch: 6| Step: 6
Training loss: 1.445936918258667
Validation loss: 2.2355759541193643

Epoch: 6| Step: 7
Training loss: 1.2725465297698975
Validation loss: 2.209929565588633

Epoch: 6| Step: 8
Training loss: 1.0367006063461304
Validation loss: 2.2162127693494162

Epoch: 6| Step: 9
Training loss: 1.204710841178894
Validation loss: 2.1952670017878213

Epoch: 6| Step: 10
Training loss: 1.5241276025772095
Validation loss: 2.2095903754234314

Epoch: 6| Step: 11
Training loss: 1.237975001335144
Validation loss: 2.2344100872675576

Epoch: 6| Step: 12
Training loss: 0.7523403167724609
Validation loss: 2.203141530354818

Epoch: 6| Step: 13
Training loss: 1.1316114664077759
Validation loss: 2.2570665081342063

Epoch: 128| Step: 0
Training loss: 1.242679476737976
Validation loss: 2.226767599582672

Epoch: 6| Step: 1
Training loss: 1.0268011093139648
Validation loss: 2.2123653491338096

Epoch: 6| Step: 2
Training loss: 1.537171483039856
Validation loss: 2.2448830604553223

Epoch: 6| Step: 3
Training loss: 1.008840560913086
Validation loss: 2.2252557078997293

Epoch: 6| Step: 4
Training loss: 1.2112276554107666
Validation loss: 2.2237335244814553

Epoch: 6| Step: 5
Training loss: 0.94614577293396
Validation loss: 2.2401599486668906

Epoch: 6| Step: 6
Training loss: 1.2930896282196045
Validation loss: 2.1927499969800315

Epoch: 6| Step: 7
Training loss: 0.705657422542572
Validation loss: 2.2106056809425354

Epoch: 6| Step: 8
Training loss: 1.2805113792419434
Validation loss: 2.2279831568400064

Epoch: 6| Step: 9
Training loss: 1.241199016571045
Validation loss: 2.189412852128347

Epoch: 6| Step: 10
Training loss: 1.618098258972168
Validation loss: 2.1921501755714417

Epoch: 6| Step: 11
Training loss: 1.153387427330017
Validation loss: 2.187832772731781

Epoch: 6| Step: 12
Training loss: 0.7497549653053284
Validation loss: 2.195432941118876

Epoch: 6| Step: 13
Training loss: 0.8944873213768005
Validation loss: 2.2332093516985574

Epoch: 129| Step: 0
Training loss: 1.732903003692627
Validation loss: 2.2643489440282187

Epoch: 6| Step: 1
Training loss: 1.2886470556259155
Validation loss: 2.212661027908325

Epoch: 6| Step: 2
Training loss: 0.5910406112670898
Validation loss: 2.2389904657999673

Epoch: 6| Step: 3
Training loss: 1.1031291484832764
Validation loss: 2.2620758016904197

Epoch: 6| Step: 4
Training loss: 0.9818289279937744
Validation loss: 2.1976478894551597

Epoch: 6| Step: 5
Training loss: 1.3020141124725342
Validation loss: 2.2323902448018393

Epoch: 6| Step: 6
Training loss: 1.4307019710540771
Validation loss: 2.1610198418299356

Epoch: 6| Step: 7
Training loss: 0.8454770445823669
Validation loss: 2.2075168689092

Epoch: 6| Step: 8
Training loss: 0.7850657105445862
Validation loss: 2.218949556350708

Epoch: 6| Step: 9
Training loss: 1.4582886695861816
Validation loss: 2.2232783834139505

Epoch: 6| Step: 10
Training loss: 1.1587952375411987
Validation loss: 2.1992254654566445

Epoch: 6| Step: 11
Training loss: 0.6515095829963684
Validation loss: 2.2538580894470215

Epoch: 6| Step: 12
Training loss: 0.9183794856071472
Validation loss: 2.241626520951589

Epoch: 6| Step: 13
Training loss: 1.2467501163482666
Validation loss: 2.1331071058909097

Epoch: 130| Step: 0
Training loss: 1.0368136167526245
Validation loss: 2.2282780408859253

Epoch: 6| Step: 1
Training loss: 0.680804967880249
Validation loss: 2.200135966142019

Epoch: 6| Step: 2
Training loss: 0.9883837103843689
Validation loss: 2.2799058755238852

Epoch: 6| Step: 3
Training loss: 1.7501041889190674
Validation loss: 2.2468953132629395

Epoch: 6| Step: 4
Training loss: 1.1082160472869873
Validation loss: 2.2117539048194885

Epoch: 6| Step: 5
Training loss: 1.616615653038025
Validation loss: 2.1951286594072976

Epoch: 6| Step: 6
Training loss: 1.6690874099731445
Validation loss: 2.1990185578664145

Epoch: 6| Step: 7
Training loss: 1.357231616973877
Validation loss: 2.1826819578806558

Epoch: 6| Step: 8
Training loss: 0.9169422388076782
Validation loss: 2.225809156894684

Epoch: 6| Step: 9
Training loss: 0.754020094871521
Validation loss: 2.219485640525818

Epoch: 6| Step: 10
Training loss: 0.36514174938201904
Validation loss: 2.2144901355107627

Epoch: 6| Step: 11
Training loss: 1.0118610858917236
Validation loss: 2.192083954811096

Epoch: 6| Step: 12
Training loss: 0.6093966960906982
Validation loss: 2.219714363416036

Epoch: 6| Step: 13
Training loss: 0.9281235933303833
Validation loss: 2.227505087852478

Epoch: 131| Step: 0
Training loss: 0.9163867235183716
Validation loss: 2.2027600606282554

Epoch: 6| Step: 1
Training loss: 0.7805503606796265
Validation loss: 2.208541512489319

Epoch: 6| Step: 2
Training loss: 0.7886456847190857
Validation loss: 2.241301198800405

Epoch: 6| Step: 3
Training loss: 0.7850844264030457
Validation loss: 2.1628278493881226

Epoch: 6| Step: 4
Training loss: 1.3071925640106201
Validation loss: 2.2378395398457847

Epoch: 6| Step: 5
Training loss: 1.192990779876709
Validation loss: 2.213395098845164

Epoch: 6| Step: 6
Training loss: 1.1741797924041748
Validation loss: 2.219778756300608

Epoch: 6| Step: 7
Training loss: 0.9674041867256165
Validation loss: 2.158706247806549

Epoch: 6| Step: 8
Training loss: 1.4228787422180176
Validation loss: 2.188193202018738

Epoch: 6| Step: 9
Training loss: 0.8844597339630127
Validation loss: 2.2422673106193542

Epoch: 6| Step: 10
Training loss: 1.2812271118164062
Validation loss: 2.282813628514608

Epoch: 6| Step: 11
Training loss: 1.476165533065796
Validation loss: 2.279672642548879

Epoch: 6| Step: 12
Training loss: 1.0555055141448975
Validation loss: 2.211450139681498

Epoch: 6| Step: 13
Training loss: 1.1773052215576172
Validation loss: 2.2529446283976235

Epoch: 132| Step: 0
Training loss: 0.979387104511261
Validation loss: 2.1880940198898315

Epoch: 6| Step: 1
Training loss: 1.0870639085769653
Validation loss: 2.3054543336232505

Epoch: 6| Step: 2
Training loss: 0.7232719659805298
Validation loss: 2.2026790777842202

Epoch: 6| Step: 3
Training loss: 1.2432690858840942
Validation loss: 2.1973711252212524

Epoch: 6| Step: 4
Training loss: 0.999057412147522
Validation loss: 2.2337914307912192

Epoch: 6| Step: 5
Training loss: 1.1144976615905762
Validation loss: 2.211959958076477

Epoch: 6| Step: 6
Training loss: 1.1430943012237549
Validation loss: 2.229907294114431

Epoch: 6| Step: 7
Training loss: 1.145295262336731
Validation loss: 2.2414488395055137

Epoch: 6| Step: 8
Training loss: 1.4451152086257935
Validation loss: 2.2212770779927573

Epoch: 6| Step: 9
Training loss: 1.2002516984939575
Validation loss: 2.21612141529719

Epoch: 6| Step: 10
Training loss: 0.5626485347747803
Validation loss: 2.31726610660553

Epoch: 6| Step: 11
Training loss: 1.1947791576385498
Validation loss: 2.204952895641327

Epoch: 6| Step: 12
Training loss: 1.1019213199615479
Validation loss: 2.2333485881487527

Epoch: 6| Step: 13
Training loss: 1.0953361988067627
Validation loss: 2.203266978263855

Epoch: 133| Step: 0
Training loss: 0.9601002931594849
Validation loss: 2.239016354084015

Epoch: 6| Step: 1
Training loss: 1.7193490266799927
Validation loss: 2.238971988360087

Epoch: 6| Step: 2
Training loss: 1.3014044761657715
Validation loss: 2.2133654952049255

Epoch: 6| Step: 3
Training loss: 1.0286986827850342
Validation loss: 2.2377657492955527

Epoch: 6| Step: 4
Training loss: 0.7444556355476379
Validation loss: 2.2795985539754233

Epoch: 6| Step: 5
Training loss: 0.7056440711021423
Validation loss: 2.270379602909088

Epoch: 6| Step: 6
Training loss: 0.8882781267166138
Validation loss: 2.2595462004343667

Epoch: 6| Step: 7
Training loss: 1.1598539352416992
Validation loss: 2.1917614340782166

Epoch: 6| Step: 8
Training loss: 1.0131275653839111
Validation loss: 2.170491655667623

Epoch: 6| Step: 9
Training loss: 0.7950096726417542
Validation loss: 2.2668424447377524

Epoch: 6| Step: 10
Training loss: 1.0577327013015747
Validation loss: 2.235283394654592

Epoch: 6| Step: 11
Training loss: 0.7302892208099365
Validation loss: 2.23071281115214

Epoch: 6| Step: 12
Training loss: 1.463287591934204
Validation loss: 2.1781694889068604

Epoch: 6| Step: 13
Training loss: 0.7949981689453125
Validation loss: 2.2060540517171225

Epoch: 134| Step: 0
Training loss: 1.1399872303009033
Validation loss: 2.1552451848983765

Epoch: 6| Step: 1
Training loss: 1.7050408124923706
Validation loss: 2.178112804889679

Epoch: 6| Step: 2
Training loss: 1.0024409294128418
Validation loss: 2.219412624835968

Epoch: 6| Step: 3
Training loss: 1.1618781089782715
Validation loss: 2.1503896514574685

Epoch: 6| Step: 4
Training loss: 1.2642009258270264
Validation loss: 2.261002024014791

Epoch: 6| Step: 5
Training loss: 1.0465110540390015
Validation loss: 2.3070446252822876

Epoch: 6| Step: 6
Training loss: 1.5051978826522827
Validation loss: 2.368473470211029

Epoch: 6| Step: 7
Training loss: 1.2359306812286377
Validation loss: 2.3217613299687705

Epoch: 6| Step: 8
Training loss: 0.9585824012756348
Validation loss: 2.2859888474146524

Epoch: 6| Step: 9
Training loss: 1.053518295288086
Validation loss: 2.238292117913564

Epoch: 6| Step: 10
Training loss: 0.8474746942520142
Validation loss: 2.12435774008433

Epoch: 6| Step: 11
Training loss: 1.1324630975723267
Validation loss: 2.222331623236338

Epoch: 6| Step: 12
Training loss: 0.9656729698181152
Validation loss: 2.1820583740870156

Epoch: 6| Step: 13
Training loss: 1.3369596004486084
Validation loss: 2.2989699443181357

Epoch: 135| Step: 0
Training loss: 1.2263599634170532
Validation loss: 2.235773960749308

Epoch: 6| Step: 1
Training loss: 1.3269116878509521
Validation loss: 2.1504836281140647

Epoch: 6| Step: 2
Training loss: 0.7045111656188965
Validation loss: 2.2315152287483215

Epoch: 6| Step: 3
Training loss: 0.9329938888549805
Validation loss: 2.186919649442037

Epoch: 6| Step: 4
Training loss: 1.5133976936340332
Validation loss: 2.1948503653208413

Epoch: 6| Step: 5
Training loss: 0.9946877956390381
Validation loss: 2.2195199131965637

Epoch: 6| Step: 6
Training loss: 0.8877613544464111
Validation loss: 2.2889292438824973

Epoch: 6| Step: 7
Training loss: 1.5853395462036133
Validation loss: 2.218373656272888

Epoch: 6| Step: 8
Training loss: 1.0530686378479004
Validation loss: 2.2420923511187234

Epoch: 6| Step: 9
Training loss: 1.2721883058547974
Validation loss: 2.203402320543925

Epoch: 6| Step: 10
Training loss: 1.3859727382659912
Validation loss: 2.1874422232309976

Epoch: 6| Step: 11
Training loss: 0.938774824142456
Validation loss: 2.1649609804153442

Epoch: 6| Step: 12
Training loss: 0.8935600519180298
Validation loss: 2.2369060715039573

Epoch: 6| Step: 13
Training loss: 1.061418056488037
Validation loss: 2.2383457024892173

Epoch: 136| Step: 0
Training loss: 0.5829969644546509
Validation loss: 2.223938306172689

Epoch: 6| Step: 1
Training loss: 0.7870806455612183
Validation loss: 2.1431459387143454

Epoch: 6| Step: 2
Training loss: 1.012869119644165
Validation loss: 2.256949722766876

Epoch: 6| Step: 3
Training loss: 0.9912593364715576
Validation loss: 2.252389430999756

Epoch: 6| Step: 4
Training loss: 1.2689588069915771
Validation loss: 2.2591495911280313

Epoch: 6| Step: 5
Training loss: 0.5474557876586914
Validation loss: 2.2096374233563743

Epoch: 6| Step: 6
Training loss: 1.0308506488800049
Validation loss: 2.229297955830892

Epoch: 6| Step: 7
Training loss: 0.9303934574127197
Validation loss: 2.1682685017585754

Epoch: 6| Step: 8
Training loss: 1.6345155239105225
Validation loss: 2.1703109542528787

Epoch: 6| Step: 9
Training loss: 1.0585042238235474
Validation loss: 2.1822344859441123

Epoch: 6| Step: 10
Training loss: 2.020732879638672
Validation loss: 2.181068201859792

Epoch: 6| Step: 11
Training loss: 1.1793980598449707
Validation loss: 2.1474315325419107

Epoch: 6| Step: 12
Training loss: 1.2405837774276733
Validation loss: 2.2535957296689353

Epoch: 6| Step: 13
Training loss: 1.2426761388778687
Validation loss: 2.2241090734799704

Epoch: 137| Step: 0
Training loss: 0.7852927446365356
Validation loss: 2.2591293255488076

Epoch: 6| Step: 1
Training loss: 2.029205799102783
Validation loss: 2.284538666407267

Epoch: 6| Step: 2
Training loss: 1.3158929347991943
Validation loss: 2.296343763669332

Epoch: 6| Step: 3
Training loss: 1.277819275856018
Validation loss: 2.2077683210372925

Epoch: 6| Step: 4
Training loss: 1.055918574333191
Validation loss: 2.214445193608602

Epoch: 6| Step: 5
Training loss: 1.3818261623382568
Validation loss: 2.1826221346855164

Epoch: 6| Step: 6
Training loss: 1.2194912433624268
Validation loss: 2.240587671597799

Epoch: 6| Step: 7
Training loss: 1.1264375448226929
Validation loss: 2.2418081959088645

Epoch: 6| Step: 8
Training loss: 0.9916620850563049
Validation loss: 2.232757826646169

Epoch: 6| Step: 9
Training loss: 1.2378813028335571
Validation loss: 2.214674194653829

Epoch: 6| Step: 10
Training loss: 1.113065242767334
Validation loss: 2.338679075241089

Epoch: 6| Step: 11
Training loss: 0.6910796761512756
Validation loss: 2.2547804514567056

Epoch: 6| Step: 12
Training loss: 0.768903911113739
Validation loss: 2.2331397334734597

Epoch: 6| Step: 13
Training loss: 0.6594340801239014
Validation loss: 2.245952546596527

Epoch: 138| Step: 0
Training loss: 0.9743720293045044
Validation loss: 2.2338252663612366

Epoch: 6| Step: 1
Training loss: 1.101581335067749
Validation loss: 2.2079772551854453

Epoch: 6| Step: 2
Training loss: 0.9210312962532043
Validation loss: 2.228292961915334

Epoch: 6| Step: 3
Training loss: 1.3842744827270508
Validation loss: 2.189629832903544

Epoch: 6| Step: 4
Training loss: 0.9678232669830322
Validation loss: 2.207627832889557

Epoch: 6| Step: 5
Training loss: 0.6413066983222961
Validation loss: 2.2091592152913413

Epoch: 6| Step: 6
Training loss: 0.7820404171943665
Validation loss: 2.2214800119400024

Epoch: 6| Step: 7
Training loss: 0.8202719688415527
Validation loss: 2.2349305947621665

Epoch: 6| Step: 8
Training loss: 0.8792672753334045
Validation loss: 2.3234875798225403

Epoch: 6| Step: 9
Training loss: 0.8922278881072998
Validation loss: 2.1952831943829856

Epoch: 6| Step: 10
Training loss: 1.1133136749267578
Validation loss: 2.1906734903653464

Epoch: 6| Step: 11
Training loss: 1.3904672861099243
Validation loss: 2.237680653731028

Epoch: 6| Step: 12
Training loss: 0.8680272698402405
Validation loss: 2.2305341561635337

Epoch: 6| Step: 13
Training loss: 1.4314014911651611
Validation loss: 2.319009999434153

Epoch: 139| Step: 0
Training loss: 1.0109689235687256
Validation loss: 2.2085737784703574

Epoch: 6| Step: 1
Training loss: 0.944913923740387
Validation loss: 2.1939241886138916

Epoch: 6| Step: 2
Training loss: 0.9698874950408936
Validation loss: 2.2128548622131348

Epoch: 6| Step: 3
Training loss: 1.008174180984497
Validation loss: 2.179230034351349

Epoch: 6| Step: 4
Training loss: 0.8069043159484863
Validation loss: 2.274816334247589

Epoch: 6| Step: 5
Training loss: 1.1494910717010498
Validation loss: 2.2697789072990417

Epoch: 6| Step: 6
Training loss: 1.008528709411621
Validation loss: 2.2197333574295044

Epoch: 6| Step: 7
Training loss: 0.7454484701156616
Validation loss: 2.220688005288442

Epoch: 6| Step: 8
Training loss: 0.9820849299430847
Validation loss: 2.142131805419922

Epoch: 6| Step: 9
Training loss: 2.021881341934204
Validation loss: 2.1638185183207193

Epoch: 6| Step: 10
Training loss: 0.82732093334198
Validation loss: 2.2435784339904785

Epoch: 6| Step: 11
Training loss: 0.8210490942001343
Validation loss: 2.2191808223724365

Epoch: 6| Step: 12
Training loss: 1.5809690952301025
Validation loss: 2.1961388985315957

Epoch: 6| Step: 13
Training loss: 0.6949959993362427
Validation loss: 2.1990827918052673

Epoch: 140| Step: 0
Training loss: 0.5621728301048279
Validation loss: 2.2063320676485696

Epoch: 6| Step: 1
Training loss: 0.5328433513641357
Validation loss: 2.199378569920858

Epoch: 6| Step: 2
Training loss: 0.6269501447677612
Validation loss: 2.163435916105906

Epoch: 6| Step: 3
Training loss: 0.7887710332870483
Validation loss: 2.2435474395751953

Epoch: 6| Step: 4
Training loss: 1.169556975364685
Validation loss: 2.1894482175509133

Epoch: 6| Step: 5
Training loss: 1.1589808464050293
Validation loss: 2.1813983718554177

Epoch: 6| Step: 6
Training loss: 1.0399034023284912
Validation loss: 2.2085586388905845

Epoch: 6| Step: 7
Training loss: 0.47778254747390747
Validation loss: 2.23190438747406

Epoch: 6| Step: 8
Training loss: 1.1092461347579956
Validation loss: 2.2605634133021035

Epoch: 6| Step: 9
Training loss: 1.003284215927124
Validation loss: 2.1945658326148987

Epoch: 6| Step: 10
Training loss: 1.0747168064117432
Validation loss: 2.256722569465637

Epoch: 6| Step: 11
Training loss: 1.393472671508789
Validation loss: 2.229919115702311

Epoch: 6| Step: 12
Training loss: 1.2612230777740479
Validation loss: 2.2069437503814697

Epoch: 6| Step: 13
Training loss: 1.220618724822998
Validation loss: 2.177752157052358

Epoch: 141| Step: 0
Training loss: 0.6666423678398132
Validation loss: 2.1852581103642783

Epoch: 6| Step: 1
Training loss: 1.139678955078125
Validation loss: 2.2104748487472534

Epoch: 6| Step: 2
Training loss: 0.6650806069374084
Validation loss: 2.222885489463806

Epoch: 6| Step: 3
Training loss: 1.1167480945587158
Validation loss: 2.2285639444986978

Epoch: 6| Step: 4
Training loss: 0.9256175756454468
Validation loss: 2.220662752787272

Epoch: 6| Step: 5
Training loss: 1.0391491651535034
Validation loss: 2.172237515449524

Epoch: 6| Step: 6
Training loss: 1.228955626487732
Validation loss: 2.218611001968384

Epoch: 6| Step: 7
Training loss: 0.9627985954284668
Validation loss: 2.2541735967000327

Epoch: 6| Step: 8
Training loss: 1.2536101341247559
Validation loss: 2.2605694929758706

Epoch: 6| Step: 9
Training loss: 1.0729825496673584
Validation loss: 2.275588850180308

Epoch: 6| Step: 10
Training loss: 1.2401111125946045
Validation loss: 2.4037460684776306

Epoch: 6| Step: 11
Training loss: 1.4464309215545654
Validation loss: 2.321663955847422

Epoch: 6| Step: 12
Training loss: 1.2572226524353027
Validation loss: 2.3008015950520835

Epoch: 6| Step: 13
Training loss: 0.6709802150726318
Validation loss: 2.2562379837036133

Epoch: 142| Step: 0
Training loss: 1.4569919109344482
Validation loss: 2.214617153008779

Epoch: 6| Step: 1
Training loss: 0.5752736330032349
Validation loss: 2.1865699688593545

Epoch: 6| Step: 2
Training loss: 1.504930019378662
Validation loss: 2.1662126580874124

Epoch: 6| Step: 3
Training loss: 1.2404367923736572
Validation loss: 2.214539349079132

Epoch: 6| Step: 4
Training loss: 1.0729118585586548
Validation loss: 2.11420601606369

Epoch: 6| Step: 5
Training loss: 0.7273913621902466
Validation loss: 2.264642357826233

Epoch: 6| Step: 6
Training loss: 0.4100015163421631
Validation loss: 2.2056596676508584

Epoch: 6| Step: 7
Training loss: 0.8339676856994629
Validation loss: 2.235443592071533

Epoch: 6| Step: 8
Training loss: 1.0434293746948242
Validation loss: 2.221627155939738

Epoch: 6| Step: 9
Training loss: 1.451952576637268
Validation loss: 2.233045299847921

Epoch: 6| Step: 10
Training loss: 1.2970892190933228
Validation loss: 2.212639093399048

Epoch: 6| Step: 11
Training loss: 0.7971431016921997
Validation loss: 2.174714287122091

Epoch: 6| Step: 12
Training loss: 0.9805554151535034
Validation loss: 2.254651884237925

Epoch: 6| Step: 13
Training loss: 0.7864270210266113
Validation loss: 2.1901000340779624

Epoch: 143| Step: 0
Training loss: 0.792304515838623
Validation loss: 2.2800556421279907

Epoch: 6| Step: 1
Training loss: 0.6182406544685364
Validation loss: 2.2707687616348267

Epoch: 6| Step: 2
Training loss: 1.0336339473724365
Validation loss: 2.247199376424154

Epoch: 6| Step: 3
Training loss: 0.8569310307502747
Validation loss: 2.194165209929148

Epoch: 6| Step: 4
Training loss: 0.30125194787979126
Validation loss: 2.173551062742869

Epoch: 6| Step: 5
Training loss: 1.4064147472381592
Validation loss: 2.233202497164408

Epoch: 6| Step: 6
Training loss: 1.1348216533660889
Validation loss: 2.2269678513209024

Epoch: 6| Step: 7
Training loss: 0.9035546183586121
Validation loss: 2.240053097407023

Epoch: 6| Step: 8
Training loss: 1.4115569591522217
Validation loss: 2.1351653734842935

Epoch: 6| Step: 9
Training loss: 1.397384524345398
Validation loss: 2.234471579392751

Epoch: 6| Step: 10
Training loss: 0.7937315702438354
Validation loss: 2.267867088317871

Epoch: 6| Step: 11
Training loss: 1.3416705131530762
Validation loss: 2.184902091821035

Epoch: 6| Step: 12
Training loss: 1.3155546188354492
Validation loss: 2.1204334696133933

Epoch: 6| Step: 13
Training loss: 0.5184619426727295
Validation loss: 2.244099775950114

Epoch: 144| Step: 0
Training loss: 0.879151463508606
Validation loss: 2.219106376171112

Epoch: 6| Step: 1
Training loss: 1.58903968334198
Validation loss: 2.2429827650388083

Epoch: 6| Step: 2
Training loss: 1.1152307987213135
Validation loss: 2.237108031908671

Epoch: 6| Step: 3
Training loss: 1.0216450691223145
Validation loss: 2.2550278902053833

Epoch: 6| Step: 4
Training loss: 0.8013942241668701
Validation loss: 2.204965511957804

Epoch: 6| Step: 5
Training loss: 0.7624459862709045
Validation loss: 2.254842003186544

Epoch: 6| Step: 6
Training loss: 1.027085542678833
Validation loss: 2.1884584426879883

Epoch: 6| Step: 7
Training loss: 0.5850389003753662
Validation loss: 2.1631072759628296

Epoch: 6| Step: 8
Training loss: 1.3788323402404785
Validation loss: 2.2096707820892334

Epoch: 6| Step: 9
Training loss: 0.9780175685882568
Validation loss: 2.2114864190419516

Epoch: 6| Step: 10
Training loss: 1.6662838459014893
Validation loss: 2.2514344851175943

Epoch: 6| Step: 11
Training loss: 0.7413153648376465
Validation loss: 2.203008492787679

Epoch: 6| Step: 12
Training loss: 0.8767849206924438
Validation loss: 2.2468058665593467

Epoch: 6| Step: 13
Training loss: 0.6001532673835754
Validation loss: 2.261946976184845

Epoch: 145| Step: 0
Training loss: 0.9671034812927246
Validation loss: 2.234823981920878

Epoch: 6| Step: 1
Training loss: 0.5875347852706909
Validation loss: 2.2117472688357034

Epoch: 6| Step: 2
Training loss: 1.0417481660842896
Validation loss: 2.2361029386520386

Epoch: 6| Step: 3
Training loss: 1.0580378770828247
Validation loss: 2.1728263894716897

Epoch: 6| Step: 4
Training loss: 0.5765396356582642
Validation loss: 2.2199420730272927

Epoch: 6| Step: 5
Training loss: 1.4341723918914795
Validation loss: 2.2467282017072043

Epoch: 6| Step: 6
Training loss: 1.660820722579956
Validation loss: 2.238215168317159

Epoch: 6| Step: 7
Training loss: 0.9546384811401367
Validation loss: 2.2379371722539267

Epoch: 6| Step: 8
Training loss: 0.6762794852256775
Validation loss: 2.2561870217323303

Epoch: 6| Step: 9
Training loss: 1.0982011556625366
Validation loss: 2.2292431195576987

Epoch: 6| Step: 10
Training loss: 0.8786499500274658
Validation loss: 2.2664663990338645

Epoch: 6| Step: 11
Training loss: 0.44573289155960083
Validation loss: 2.270241896311442

Epoch: 6| Step: 12
Training loss: 0.44246912002563477
Validation loss: 2.2028791109720864

Epoch: 6| Step: 13
Training loss: 1.1869680881500244
Validation loss: 2.179270644982656

Epoch: 146| Step: 0
Training loss: 0.6462031602859497
Validation loss: 2.260254462560018

Epoch: 6| Step: 1
Training loss: 0.6216215491294861
Validation loss: 2.2476683060328164

Epoch: 6| Step: 2
Training loss: 0.7888895869255066
Validation loss: 2.197889486948649

Epoch: 6| Step: 3
Training loss: 1.03749418258667
Validation loss: 2.258724808692932

Epoch: 6| Step: 4
Training loss: 1.2796142101287842
Validation loss: 2.1508803367614746

Epoch: 6| Step: 5
Training loss: 0.7038024663925171
Validation loss: 2.179515282313029

Epoch: 6| Step: 6
Training loss: 0.9925005435943604
Validation loss: 2.1986267964045205

Epoch: 6| Step: 7
Training loss: 1.0364201068878174
Validation loss: 2.2230745553970337

Epoch: 6| Step: 8
Training loss: 0.7176332473754883
Validation loss: 2.1914085944493613

Epoch: 6| Step: 9
Training loss: 1.5591553449630737
Validation loss: 2.2612703839937844

Epoch: 6| Step: 10
Training loss: 0.8079735040664673
Validation loss: 2.296559671560923

Epoch: 6| Step: 11
Training loss: 0.827985405921936
Validation loss: 2.21706094344457

Epoch: 6| Step: 12
Training loss: 1.2108185291290283
Validation loss: 2.2378034790356955

Epoch: 6| Step: 13
Training loss: 1.2111537456512451
Validation loss: 2.2249096234639487

Epoch: 147| Step: 0
Training loss: 0.643869936466217
Validation loss: 2.225979745388031

Epoch: 6| Step: 1
Training loss: 0.5593215227127075
Validation loss: 2.230436404546102

Epoch: 6| Step: 2
Training loss: 0.928777813911438
Validation loss: 2.199315905570984

Epoch: 6| Step: 3
Training loss: 0.7959234714508057
Validation loss: 2.1869855324427285

Epoch: 6| Step: 4
Training loss: 0.8380184769630432
Validation loss: 2.183192173639933

Epoch: 6| Step: 5
Training loss: 0.9143567085266113
Validation loss: 2.1662619908650718

Epoch: 6| Step: 6
Training loss: 0.8451253175735474
Validation loss: 2.2391133109728494

Epoch: 6| Step: 7
Training loss: 0.6399847865104675
Validation loss: 2.2103734016418457

Epoch: 6| Step: 8
Training loss: 1.0174280405044556
Validation loss: 2.2288030783335366

Epoch: 6| Step: 9
Training loss: 1.306309700012207
Validation loss: 2.286746382713318

Epoch: 6| Step: 10
Training loss: 1.203881025314331
Validation loss: 2.2828503449757895

Epoch: 6| Step: 11
Training loss: 1.7575793266296387
Validation loss: 2.2921056151390076

Epoch: 6| Step: 12
Training loss: 1.0895799398422241
Validation loss: 2.194853723049164

Epoch: 6| Step: 13
Training loss: 1.0896022319793701
Validation loss: 2.2128878037134805

Epoch: 148| Step: 0
Training loss: 0.8747204542160034
Validation loss: 2.1885138948758445

Epoch: 6| Step: 1
Training loss: 1.014962911605835
Validation loss: 2.2030924558639526

Epoch: 6| Step: 2
Training loss: 0.7498709559440613
Validation loss: 2.2331649462381997

Epoch: 6| Step: 3
Training loss: 0.8594497442245483
Validation loss: 2.2075559496879578

Epoch: 6| Step: 4
Training loss: 0.5570393800735474
Validation loss: 2.182001610596975

Epoch: 6| Step: 5
Training loss: 0.68462073802948
Validation loss: 2.2521299918492637

Epoch: 6| Step: 6
Training loss: 1.7018588781356812
Validation loss: 2.2372528314590454

Epoch: 6| Step: 7
Training loss: 0.9049632549285889
Validation loss: 2.2429786721865335

Epoch: 6| Step: 8
Training loss: 0.8027660846710205
Validation loss: 2.2946513096491494

Epoch: 6| Step: 9
Training loss: 0.7420870065689087
Validation loss: 2.2415104508399963

Epoch: 6| Step: 10
Training loss: 1.2240846157073975
Validation loss: 2.2426847219467163

Epoch: 6| Step: 11
Training loss: 1.34621262550354
Validation loss: 2.2350388964017234

Epoch: 6| Step: 12
Training loss: 1.362743616104126
Validation loss: 2.2832630475362143

Epoch: 6| Step: 13
Training loss: 0.7463722229003906
Validation loss: 2.2625300685564675

Epoch: 149| Step: 0
Training loss: 0.7778912782669067
Validation loss: 2.2498316764831543

Epoch: 6| Step: 1
Training loss: 1.193312406539917
Validation loss: 2.2730669577916465

Epoch: 6| Step: 2
Training loss: 1.0757131576538086
Validation loss: 2.236224631468455

Epoch: 6| Step: 3
Training loss: 0.8560386896133423
Validation loss: 2.191851556301117

Epoch: 6| Step: 4
Training loss: 0.8068305253982544
Validation loss: 2.313596725463867

Epoch: 6| Step: 5
Training loss: 1.0518969297409058
Validation loss: 2.20641295115153

Epoch: 6| Step: 6
Training loss: 0.995438277721405
Validation loss: 2.3136674761772156

Epoch: 6| Step: 7
Training loss: 0.9865827560424805
Validation loss: 2.258348802725474

Epoch: 6| Step: 8
Training loss: 0.8516337275505066
Validation loss: 2.2765576243400574

Epoch: 6| Step: 9
Training loss: 1.40447199344635
Validation loss: 2.234889249006907

Epoch: 6| Step: 10
Training loss: 1.0154461860656738
Validation loss: 2.2196967403093972

Epoch: 6| Step: 11
Training loss: 0.7719129323959351
Validation loss: 2.2233667969703674

Epoch: 6| Step: 12
Training loss: 1.1554545164108276
Validation loss: 2.204819659392039

Epoch: 6| Step: 13
Training loss: 0.46134746074676514
Validation loss: 2.239633043607076

Epoch: 150| Step: 0
Training loss: 0.7578177452087402
Validation loss: 2.2425959507624307

Epoch: 6| Step: 1
Training loss: 1.196171522140503
Validation loss: 2.287594199180603

Epoch: 6| Step: 2
Training loss: 1.48073410987854
Validation loss: 2.2268762985865274

Epoch: 6| Step: 3
Training loss: 0.9545695781707764
Validation loss: 2.2862783670425415

Epoch: 6| Step: 4
Training loss: 0.6937305331230164
Validation loss: 2.306124746799469

Epoch: 6| Step: 5
Training loss: 0.6681421995162964
Validation loss: 2.2590792576471963

Epoch: 6| Step: 6
Training loss: 0.6039096713066101
Validation loss: 2.230556090672811

Epoch: 6| Step: 7
Training loss: 0.7816568613052368
Validation loss: 2.2632636626561484

Epoch: 6| Step: 8
Training loss: 0.7119320631027222
Validation loss: 2.1850332617759705

Epoch: 6| Step: 9
Training loss: 0.9330950379371643
Validation loss: 2.2212628920873008

Epoch: 6| Step: 10
Training loss: 1.1416571140289307
Validation loss: 2.2306026220321655

Epoch: 6| Step: 11
Training loss: 1.3048548698425293
Validation loss: 2.233582536379496

Epoch: 6| Step: 12
Training loss: 0.8378849029541016
Validation loss: 2.260438779989878

Epoch: 6| Step: 13
Training loss: 0.6687324047088623
Validation loss: 2.220968325932821

Epoch: 151| Step: 0
Training loss: 0.6305047869682312
Validation loss: 2.2228150765101113

Epoch: 6| Step: 1
Training loss: 0.7815109491348267
Validation loss: 2.232732971509298

Epoch: 6| Step: 2
Training loss: 1.270792841911316
Validation loss: 2.181942323843638

Epoch: 6| Step: 3
Training loss: 0.7205363512039185
Validation loss: 2.1934958696365356

Epoch: 6| Step: 4
Training loss: 0.9733123183250427
Validation loss: 2.2514238357543945

Epoch: 6| Step: 5
Training loss: 0.5026002526283264
Validation loss: 2.171099384625753

Epoch: 6| Step: 6
Training loss: 0.5176709294319153
Validation loss: 2.2117375135421753

Epoch: 6| Step: 7
Training loss: 1.441114902496338
Validation loss: 2.173798600832621

Epoch: 6| Step: 8
Training loss: 1.044688105583191
Validation loss: 2.2023775974909463

Epoch: 6| Step: 9
Training loss: 0.6140484809875488
Validation loss: 2.204076568285624

Epoch: 6| Step: 10
Training loss: 0.9545465707778931
Validation loss: 2.2167420585950217

Epoch: 6| Step: 11
Training loss: 1.1128208637237549
Validation loss: 2.3475676774978638

Epoch: 6| Step: 12
Training loss: 0.5453522801399231
Validation loss: 2.298429489135742

Epoch: 6| Step: 13
Training loss: 1.5590510368347168
Validation loss: 2.212634106477102

Epoch: 152| Step: 0
Training loss: 1.1691316366195679
Validation loss: 2.2896377642949424

Epoch: 6| Step: 1
Training loss: 0.6958045959472656
Validation loss: 2.2705257137616477

Epoch: 6| Step: 2
Training loss: 0.7613780498504639
Validation loss: 2.2449538111686707

Epoch: 6| Step: 3
Training loss: 1.1355432271957397
Validation loss: 2.1811350186665854

Epoch: 6| Step: 4
Training loss: 0.957840621471405
Validation loss: 2.223520557085673

Epoch: 6| Step: 5
Training loss: 0.8943989276885986
Validation loss: 2.2374884486198425

Epoch: 6| Step: 6
Training loss: 1.1700859069824219
Validation loss: 2.1753573417663574

Epoch: 6| Step: 7
Training loss: 1.154625415802002
Validation loss: 2.238023062547048

Epoch: 6| Step: 8
Training loss: 1.0679140090942383
Validation loss: 2.273421049118042

Epoch: 6| Step: 9
Training loss: 0.8840774297714233
Validation loss: 2.2434085607528687

Epoch: 6| Step: 10
Training loss: 0.691981315612793
Validation loss: 2.2758194406827292

Epoch: 6| Step: 11
Training loss: 0.9905094504356384
Validation loss: 2.207379082838694

Epoch: 6| Step: 12
Training loss: 0.49826014041900635
Validation loss: 2.2118609150250754

Epoch: 6| Step: 13
Training loss: 1.4065124988555908
Validation loss: 2.1827892462412515

Epoch: 153| Step: 0
Training loss: 0.7509673237800598
Validation loss: 2.2051071921984353

Epoch: 6| Step: 1
Training loss: 1.0955866575241089
Validation loss: 2.241141219933828

Epoch: 6| Step: 2
Training loss: 1.4375908374786377
Validation loss: 2.1996506253878274

Epoch: 6| Step: 3
Training loss: 0.8910470604896545
Validation loss: 2.232024848461151

Epoch: 6| Step: 4
Training loss: 0.7308035492897034
Validation loss: 2.2204530437787375

Epoch: 6| Step: 5
Training loss: 1.0068459510803223
Validation loss: 2.207597315311432

Epoch: 6| Step: 6
Training loss: 0.7687886953353882
Validation loss: 2.2067797780036926

Epoch: 6| Step: 7
Training loss: 0.835202693939209
Validation loss: 2.248754103978475

Epoch: 6| Step: 8
Training loss: 0.8950026035308838
Validation loss: 2.220858931541443

Epoch: 6| Step: 9
Training loss: 1.1317925453186035
Validation loss: 2.2026982506116233

Epoch: 6| Step: 10
Training loss: 0.7292667031288147
Validation loss: 2.2312066356341043

Epoch: 6| Step: 11
Training loss: 1.0920770168304443
Validation loss: 2.235067824522654

Epoch: 6| Step: 12
Training loss: 0.8463029861450195
Validation loss: 2.2033241788546243

Epoch: 6| Step: 13
Training loss: 0.7316064834594727
Validation loss: 2.2130767504374185

Epoch: 154| Step: 0
Training loss: 1.2379411458969116
Validation loss: 2.181495944658915

Epoch: 6| Step: 1
Training loss: 0.5493001937866211
Validation loss: 2.2632163763046265

Epoch: 6| Step: 2
Training loss: 1.3816864490509033
Validation loss: 2.2911086479822793

Epoch: 6| Step: 3
Training loss: 1.0168745517730713
Validation loss: 2.2523545622825623

Epoch: 6| Step: 4
Training loss: 1.0839145183563232
Validation loss: 2.224662999312083

Epoch: 6| Step: 5
Training loss: 0.5092676281929016
Validation loss: 2.165557622909546

Epoch: 6| Step: 6
Training loss: 0.8545149564743042
Validation loss: 2.235992709795634

Epoch: 6| Step: 7
Training loss: 1.302791714668274
Validation loss: 2.170489470163981

Epoch: 6| Step: 8
Training loss: 1.156639575958252
Validation loss: 2.213371137777964

Epoch: 6| Step: 9
Training loss: 0.6645200848579407
Validation loss: 2.137998878955841

Epoch: 6| Step: 10
Training loss: 0.9633773565292358
Validation loss: 2.204347829023997

Epoch: 6| Step: 11
Training loss: 0.8817203044891357
Validation loss: 2.2263223528862

Epoch: 6| Step: 12
Training loss: 0.7086912989616394
Validation loss: 2.2842440803845725

Epoch: 6| Step: 13
Training loss: 0.7952057719230652
Validation loss: 2.254489779472351

Epoch: 155| Step: 0
Training loss: 0.6636967658996582
Validation loss: 2.2833454410235086

Epoch: 6| Step: 1
Training loss: 0.8114238977432251
Validation loss: 2.2976215481758118

Epoch: 6| Step: 2
Training loss: 1.1836456060409546
Validation loss: 2.192949573198954

Epoch: 6| Step: 3
Training loss: 0.730388879776001
Validation loss: 2.2284107208251953

Epoch: 6| Step: 4
Training loss: 0.7359448671340942
Validation loss: 2.1722591121991477

Epoch: 6| Step: 5
Training loss: 0.8287083506584167
Validation loss: 2.162131349245707

Epoch: 6| Step: 6
Training loss: 0.6346838474273682
Validation loss: 2.1335021257400513

Epoch: 6| Step: 7
Training loss: 1.0963869094848633
Validation loss: 2.2038063605626426

Epoch: 6| Step: 8
Training loss: 1.1125519275665283
Validation loss: 2.1969760258992515

Epoch: 6| Step: 9
Training loss: 1.2193999290466309
Validation loss: 2.2109060287475586

Epoch: 6| Step: 10
Training loss: 0.8687580227851868
Validation loss: 2.27646271387736

Epoch: 6| Step: 11
Training loss: 0.9560102224349976
Validation loss: 2.2266769409179688

Epoch: 6| Step: 12
Training loss: 1.233013391494751
Validation loss: 2.191786309083303

Epoch: 6| Step: 13
Training loss: 0.8122363090515137
Validation loss: 2.2934604485829673

Epoch: 156| Step: 0
Training loss: 0.9324163794517517
Validation loss: 2.195989191532135

Epoch: 6| Step: 1
Training loss: 0.8794692754745483
Validation loss: 2.1906237403551736

Epoch: 6| Step: 2
Training loss: 0.762816309928894
Validation loss: 2.156619906425476

Epoch: 6| Step: 3
Training loss: 1.245164394378662
Validation loss: 2.181218226750692

Epoch: 6| Step: 4
Training loss: 0.435915470123291
Validation loss: 2.2237284978230796

Epoch: 6| Step: 5
Training loss: 0.6665894389152527
Validation loss: 2.2112077275911965

Epoch: 6| Step: 6
Training loss: 0.6548153162002563
Validation loss: 2.225669582684835

Epoch: 6| Step: 7
Training loss: 0.7866924405097961
Validation loss: 2.244515538215637

Epoch: 6| Step: 8
Training loss: 0.9554306268692017
Validation loss: 2.2171390056610107

Epoch: 6| Step: 9
Training loss: 0.9778034687042236
Validation loss: 2.188344975312551

Epoch: 6| Step: 10
Training loss: 1.1807048320770264
Validation loss: 2.1956565181414285

Epoch: 6| Step: 11
Training loss: 0.8141977787017822
Validation loss: 2.2087393601735434

Epoch: 6| Step: 12
Training loss: 1.1302008628845215
Validation loss: 2.164134979248047

Epoch: 6| Step: 13
Training loss: 0.7994993329048157
Validation loss: 2.221394121646881

Epoch: 157| Step: 0
Training loss: 1.1560670137405396
Validation loss: 2.247326970100403

Epoch: 6| Step: 1
Training loss: 1.1432158946990967
Validation loss: 2.231951355934143

Epoch: 6| Step: 2
Training loss: 0.7924834489822388
Validation loss: 2.2466622591018677

Epoch: 6| Step: 3
Training loss: 0.9790062308311462
Validation loss: 2.2373997569084167

Epoch: 6| Step: 4
Training loss: 0.7145097255706787
Validation loss: 2.2729408542315164

Epoch: 6| Step: 5
Training loss: 1.1920866966247559
Validation loss: 2.2279505729675293

Epoch: 6| Step: 6
Training loss: 0.5028282403945923
Validation loss: 2.195303718249003

Epoch: 6| Step: 7
Training loss: 1.2014529705047607
Validation loss: 2.2139593760172525

Epoch: 6| Step: 8
Training loss: 1.3297322988510132
Validation loss: 2.196865737438202

Epoch: 6| Step: 9
Training loss: 0.33300626277923584
Validation loss: 2.1498249769210815

Epoch: 6| Step: 10
Training loss: 0.5557324290275574
Validation loss: 2.199000577131907

Epoch: 6| Step: 11
Training loss: 0.6456949710845947
Validation loss: 2.2292106548945108

Epoch: 6| Step: 12
Training loss: 0.6517099142074585
Validation loss: 2.2625213066736856

Epoch: 6| Step: 13
Training loss: 1.1193397045135498
Validation loss: 2.2565959890683494

Epoch: 158| Step: 0
Training loss: 1.022207260131836
Validation loss: 2.313770333925883

Epoch: 6| Step: 1
Training loss: 0.8298778533935547
Validation loss: 2.369834085305532

Epoch: 6| Step: 2
Training loss: 1.2193396091461182
Validation loss: 2.2679676612218223

Epoch: 6| Step: 3
Training loss: 0.9951725006103516
Validation loss: 2.203665018081665

Epoch: 6| Step: 4
Training loss: 1.5161386728286743
Validation loss: 2.1807509064674377

Epoch: 6| Step: 5
Training loss: 1.022096037864685
Validation loss: 2.2557294368743896

Epoch: 6| Step: 6
Training loss: 0.45107704401016235
Validation loss: 2.2282387216885886

Epoch: 6| Step: 7
Training loss: 0.9515092372894287
Validation loss: 2.191224455833435

Epoch: 6| Step: 8
Training loss: 0.7810279130935669
Validation loss: 2.2236040830612183

Epoch: 6| Step: 9
Training loss: 0.5422053337097168
Validation loss: 2.2235580484072366

Epoch: 6| Step: 10
Training loss: 0.8726730346679688
Validation loss: 2.277706027030945

Epoch: 6| Step: 11
Training loss: 1.097382664680481
Validation loss: 2.2596508661905923

Epoch: 6| Step: 12
Training loss: 0.7531622648239136
Validation loss: 2.1918194691340127

Epoch: 6| Step: 13
Training loss: 0.5695281028747559
Validation loss: 2.274079203605652

Epoch: 159| Step: 0
Training loss: 1.264375925064087
Validation loss: 2.2583007415135703

Epoch: 6| Step: 1
Training loss: 0.5409587621688843
Validation loss: 2.1982441544532776

Epoch: 6| Step: 2
Training loss: 1.026071548461914
Validation loss: 2.2602521578470864

Epoch: 6| Step: 3
Training loss: 0.6607862710952759
Validation loss: 2.2104965845743814

Epoch: 6| Step: 4
Training loss: 1.1217527389526367
Validation loss: 2.259090860684713

Epoch: 6| Step: 5
Training loss: 0.8608183860778809
Validation loss: 2.252250691254934

Epoch: 6| Step: 6
Training loss: 0.5164684653282166
Validation loss: 2.2199047207832336

Epoch: 6| Step: 7
Training loss: 0.6626627445220947
Validation loss: 2.2374371886253357

Epoch: 6| Step: 8
Training loss: 1.237901210784912
Validation loss: 2.2776437203089395

Epoch: 6| Step: 9
Training loss: 0.7526599168777466
Validation loss: 2.257694939772288

Epoch: 6| Step: 10
Training loss: 0.4587134122848511
Validation loss: 2.286185602347056

Epoch: 6| Step: 11
Training loss: 0.8995952010154724
Validation loss: 2.2011152108510337

Epoch: 6| Step: 12
Training loss: 0.7983139753341675
Validation loss: 2.2767289678255715

Epoch: 6| Step: 13
Training loss: 0.6812974214553833
Validation loss: 2.1997636953989663

Epoch: 160| Step: 0
Training loss: 0.8333923816680908
Validation loss: 2.186417579650879

Epoch: 6| Step: 1
Training loss: 1.1296350955963135
Validation loss: 2.2633354663848877

Epoch: 6| Step: 2
Training loss: 0.7533736228942871
Validation loss: 2.212448259194692

Epoch: 6| Step: 3
Training loss: 0.4543384909629822
Validation loss: 2.195026437441508

Epoch: 6| Step: 4
Training loss: 1.447126030921936
Validation loss: 2.215475598971049

Epoch: 6| Step: 5
Training loss: 0.5695556998252869
Validation loss: 2.1950743198394775

Epoch: 6| Step: 6
Training loss: 0.7715691328048706
Validation loss: 2.2236971855163574

Epoch: 6| Step: 7
Training loss: 0.5241550207138062
Validation loss: 2.2304139931996665

Epoch: 6| Step: 8
Training loss: 1.09281325340271
Validation loss: 2.218995690345764

Epoch: 6| Step: 9
Training loss: 0.7946845293045044
Validation loss: 2.261636217435201

Epoch: 6| Step: 10
Training loss: 0.874747097492218
Validation loss: 2.176343262195587

Epoch: 6| Step: 11
Training loss: 1.357346534729004
Validation loss: 2.2086204886436462

Epoch: 6| Step: 12
Training loss: 0.4927295744419098
Validation loss: 2.1857580145200095

Epoch: 6| Step: 13
Training loss: 0.6163700819015503
Validation loss: 2.2493826150894165

Epoch: 161| Step: 0
Training loss: 0.8598545789718628
Validation loss: 2.1966638565063477

Epoch: 6| Step: 1
Training loss: 0.9488833546638489
Validation loss: 2.1469882925351462

Epoch: 6| Step: 2
Training loss: 1.3661255836486816
Validation loss: 2.206003963947296

Epoch: 6| Step: 3
Training loss: 0.8098301887512207
Validation loss: 2.2243869503339133

Epoch: 6| Step: 4
Training loss: 0.5353456139564514
Validation loss: 2.241638799508413

Epoch: 6| Step: 5
Training loss: 1.0378354787826538
Validation loss: 2.2571894923845925

Epoch: 6| Step: 6
Training loss: 0.45267075300216675
Validation loss: 2.1877735455830893

Epoch: 6| Step: 7
Training loss: 0.8253124356269836
Validation loss: 2.240027666091919

Epoch: 6| Step: 8
Training loss: 0.9651050567626953
Validation loss: 2.220249136288961

Epoch: 6| Step: 9
Training loss: 0.5008689165115356
Validation loss: 2.2363879481951394

Epoch: 6| Step: 10
Training loss: 0.6828113198280334
Validation loss: 2.1949273347854614

Epoch: 6| Step: 11
Training loss: 0.7148921489715576
Validation loss: 2.205771525700887

Epoch: 6| Step: 12
Training loss: 1.229128360748291
Validation loss: 2.209965765476227

Epoch: 6| Step: 13
Training loss: 0.5892360210418701
Validation loss: 2.185085197289785

Epoch: 162| Step: 0
Training loss: 1.1335792541503906
Validation loss: 2.2025375763575235

Epoch: 6| Step: 1
Training loss: 0.9396599531173706
Validation loss: 2.1541757186253867

Epoch: 6| Step: 2
Training loss: 0.5983618497848511
Validation loss: 2.1835944652557373

Epoch: 6| Step: 3
Training loss: 0.8656772971153259
Validation loss: 2.2569762468338013

Epoch: 6| Step: 4
Training loss: 0.8446762561798096
Validation loss: 2.2367032567660012

Epoch: 6| Step: 5
Training loss: 0.8603960871696472
Validation loss: 2.2538100481033325

Epoch: 6| Step: 6
Training loss: 0.8719819784164429
Validation loss: 2.188918193181356

Epoch: 6| Step: 7
Training loss: 1.052734136581421
Validation loss: 2.224213798840841

Epoch: 6| Step: 8
Training loss: 0.7682521343231201
Validation loss: 2.2060976227124534

Epoch: 6| Step: 9
Training loss: 0.6553876399993896
Validation loss: 2.2139284213383994

Epoch: 6| Step: 10
Training loss: 0.4066038131713867
Validation loss: 2.1607149243354797

Epoch: 6| Step: 11
Training loss: 0.5471962690353394
Validation loss: 2.2092787424723306

Epoch: 6| Step: 12
Training loss: 1.0002611875534058
Validation loss: 2.261826813220978

Epoch: 6| Step: 13
Training loss: 0.8134664297103882
Validation loss: 2.1932764450709024

Epoch: 163| Step: 0
Training loss: 0.9977648258209229
Validation loss: 2.2391141057014465

Epoch: 6| Step: 1
Training loss: 0.7900712490081787
Validation loss: 2.1470780968666077

Epoch: 6| Step: 2
Training loss: 0.9544581770896912
Validation loss: 2.2370293140411377

Epoch: 6| Step: 3
Training loss: 0.6991634368896484
Validation loss: 2.2093751430511475

Epoch: 6| Step: 4
Training loss: 0.45001381635665894
Validation loss: 2.191754460334778

Epoch: 6| Step: 5
Training loss: 0.8355337977409363
Validation loss: 2.1811039646466575

Epoch: 6| Step: 6
Training loss: 0.6439169049263
Validation loss: 2.2366830110549927

Epoch: 6| Step: 7
Training loss: 0.48049911856651306
Validation loss: 2.2253124515215554

Epoch: 6| Step: 8
Training loss: 1.458799958229065
Validation loss: 2.269776185353597

Epoch: 6| Step: 9
Training loss: 0.893282949924469
Validation loss: 2.271763801574707

Epoch: 6| Step: 10
Training loss: 1.2427361011505127
Validation loss: 2.210536539554596

Epoch: 6| Step: 11
Training loss: 0.40826672315597534
Validation loss: 2.1674923102060952

Epoch: 6| Step: 12
Training loss: 0.8686673641204834
Validation loss: 2.171983242034912

Epoch: 6| Step: 13
Training loss: 0.6143167614936829
Validation loss: 2.1968089739481607

Epoch: 164| Step: 0
Training loss: 0.7447711825370789
Validation loss: 2.21978751818339

Epoch: 6| Step: 1
Training loss: 1.3325576782226562
Validation loss: 2.1459400256474814

Epoch: 6| Step: 2
Training loss: 0.926450252532959
Validation loss: 2.212035059928894

Epoch: 6| Step: 3
Training loss: 0.8002120852470398
Validation loss: 2.188054899374644

Epoch: 6| Step: 4
Training loss: 1.1134804487228394
Validation loss: 2.1801613370577493

Epoch: 6| Step: 5
Training loss: 0.7545799612998962
Validation loss: 2.1603418986002603

Epoch: 6| Step: 6
Training loss: 0.5039255023002625
Validation loss: 2.262852052847544

Epoch: 6| Step: 7
Training loss: 0.41228780150413513
Validation loss: 2.238901217778524

Epoch: 6| Step: 8
Training loss: 0.724129855632782
Validation loss: 2.147813618183136

Epoch: 6| Step: 9
Training loss: 0.41621264815330505
Validation loss: 2.2626037200291953

Epoch: 6| Step: 10
Training loss: 1.217116355895996
Validation loss: 2.211349129676819

Epoch: 6| Step: 11
Training loss: 0.85777747631073
Validation loss: 2.210611859957377

Epoch: 6| Step: 12
Training loss: 0.7900880575180054
Validation loss: 2.2811431686083474

Epoch: 6| Step: 13
Training loss: 0.6223262548446655
Validation loss: 2.258427460988363

Epoch: 165| Step: 0
Training loss: 1.4176299571990967
Validation loss: 2.2907623847325644

Epoch: 6| Step: 1
Training loss: 1.074514627456665
Validation loss: 2.229267497857412

Epoch: 6| Step: 2
Training loss: 0.4942203462123871
Validation loss: 2.1674305399258933

Epoch: 6| Step: 3
Training loss: 0.7417089939117432
Validation loss: 2.193181832631429

Epoch: 6| Step: 4
Training loss: 0.675033688545227
Validation loss: 2.1748714447021484

Epoch: 6| Step: 5
Training loss: 1.2317993640899658
Validation loss: 2.170916795730591

Epoch: 6| Step: 6
Training loss: 0.9938291907310486
Validation loss: 2.1983036200205484

Epoch: 6| Step: 7
Training loss: 0.582483172416687
Validation loss: 2.246161142985026

Epoch: 6| Step: 8
Training loss: 0.5351929664611816
Validation loss: 2.234617531299591

Epoch: 6| Step: 9
Training loss: 1.0130237340927124
Validation loss: 2.2439582347869873

Epoch: 6| Step: 10
Training loss: 1.1978747844696045
Validation loss: 2.235738734404246

Epoch: 6| Step: 11
Training loss: 0.7536308765411377
Validation loss: 2.2094990412394204

Epoch: 6| Step: 12
Training loss: 0.7754793167114258
Validation loss: 2.1829936106999717

Epoch: 6| Step: 13
Training loss: 0.5005441904067993
Validation loss: 2.2073373993237815

Epoch: 166| Step: 0
Training loss: 0.7071595191955566
Validation loss: 2.18496173620224

Epoch: 6| Step: 1
Training loss: 0.708842933177948
Validation loss: 2.2206854025522866

Epoch: 6| Step: 2
Training loss: 0.8792781233787537
Validation loss: 2.223754366238912

Epoch: 6| Step: 3
Training loss: 0.6783134341239929
Validation loss: 2.245277762413025

Epoch: 6| Step: 4
Training loss: 0.6457101702690125
Validation loss: 2.2047332922617593

Epoch: 6| Step: 5
Training loss: 0.6594578623771667
Validation loss: 2.258519470691681

Epoch: 6| Step: 6
Training loss: 1.0134844779968262
Validation loss: 2.1754688223203025

Epoch: 6| Step: 7
Training loss: 0.9135057926177979
Validation loss: 2.1757882038752236

Epoch: 6| Step: 8
Training loss: 0.6220141053199768
Validation loss: 2.2499996026357016

Epoch: 6| Step: 9
Training loss: 0.982812762260437
Validation loss: 2.2346349954605103

Epoch: 6| Step: 10
Training loss: 0.8321889638900757
Validation loss: 2.175671656926473

Epoch: 6| Step: 11
Training loss: 1.1143149137496948
Validation loss: 2.2170432011286416

Epoch: 6| Step: 12
Training loss: 0.9401110410690308
Validation loss: 2.2262422839800515

Epoch: 6| Step: 13
Training loss: 0.5820993185043335
Validation loss: 2.198167383670807

Epoch: 167| Step: 0
Training loss: 0.7614336013793945
Validation loss: 2.2073991696039834

Epoch: 6| Step: 1
Training loss: 1.06038498878479
Validation loss: 2.230454365412394

Epoch: 6| Step: 2
Training loss: 0.725171685218811
Validation loss: 2.2648439009984336

Epoch: 6| Step: 3
Training loss: 0.8848552107810974
Validation loss: 2.2502094308535256

Epoch: 6| Step: 4
Training loss: 0.8067092895507812
Validation loss: 2.2094054420789084

Epoch: 6| Step: 5
Training loss: 0.8510687947273254
Validation loss: 2.21220592657725

Epoch: 6| Step: 6
Training loss: 0.533531665802002
Validation loss: 2.183059295018514

Epoch: 6| Step: 7
Training loss: 0.6930563449859619
Validation loss: 2.2303491036097207

Epoch: 6| Step: 8
Training loss: 0.6221057176589966
Validation loss: 2.241710285345713

Epoch: 6| Step: 9
Training loss: 0.5477681159973145
Validation loss: 2.3131601015726724

Epoch: 6| Step: 10
Training loss: 1.0236486196517944
Validation loss: 2.22991414864858

Epoch: 6| Step: 11
Training loss: 1.0693433284759521
Validation loss: 2.1903778314590454

Epoch: 6| Step: 12
Training loss: 0.6534397006034851
Validation loss: 2.2352875073750815

Epoch: 6| Step: 13
Training loss: 0.8701145648956299
Validation loss: 2.186933139959971

Epoch: 168| Step: 0
Training loss: 0.7705843448638916
Validation loss: 2.232457995414734

Epoch: 6| Step: 1
Training loss: 0.8269904851913452
Validation loss: 2.232021967569987

Epoch: 6| Step: 2
Training loss: 0.6133651733398438
Validation loss: 2.2128852208455405

Epoch: 6| Step: 3
Training loss: 1.189255952835083
Validation loss: 2.24457977215449

Epoch: 6| Step: 4
Training loss: 1.4585057497024536
Validation loss: 2.185110628604889

Epoch: 6| Step: 5
Training loss: 0.9495455622673035
Validation loss: 2.2777059674263

Epoch: 6| Step: 6
Training loss: 0.6349697113037109
Validation loss: 2.26885994275411

Epoch: 6| Step: 7
Training loss: 0.6795395016670227
Validation loss: 2.20361065864563

Epoch: 6| Step: 8
Training loss: 0.6006559133529663
Validation loss: 2.19387940565745

Epoch: 6| Step: 9
Training loss: 0.5048107504844666
Validation loss: 2.242087721824646

Epoch: 6| Step: 10
Training loss: 0.6336938142776489
Validation loss: 2.235021233558655

Epoch: 6| Step: 11
Training loss: 0.7214431762695312
Validation loss: 2.2311348915100098

Epoch: 6| Step: 12
Training loss: 0.7454909086227417
Validation loss: 2.1944702863693237

Epoch: 6| Step: 13
Training loss: 0.8262902498245239
Validation loss: 2.1585299968719482

Epoch: 169| Step: 0
Training loss: 0.5627813339233398
Validation loss: 2.228474716345469

Epoch: 6| Step: 1
Training loss: 0.5419891476631165
Validation loss: 2.237333516279856

Epoch: 6| Step: 2
Training loss: 1.1420838832855225
Validation loss: 2.213869293530782

Epoch: 6| Step: 3
Training loss: 0.819468080997467
Validation loss: 2.22226482629776

Epoch: 6| Step: 4
Training loss: 0.846109926700592
Validation loss: 2.22762002547582

Epoch: 6| Step: 5
Training loss: 0.5468591451644897
Validation loss: 2.2578340570131936

Epoch: 6| Step: 6
Training loss: 0.35046422481536865
Validation loss: 2.1940720081329346

Epoch: 6| Step: 7
Training loss: 0.5429723858833313
Validation loss: 2.2237903674443564

Epoch: 6| Step: 8
Training loss: 0.7960400581359863
Validation loss: 2.2289504607518515

Epoch: 6| Step: 9
Training loss: 0.8054714202880859
Validation loss: 2.1866645415623984

Epoch: 6| Step: 10
Training loss: 1.1166789531707764
Validation loss: 2.2225189407666526

Epoch: 6| Step: 11
Training loss: 0.7090175151824951
Validation loss: 2.2566431959470115

Epoch: 6| Step: 12
Training loss: 0.6961147785186768
Validation loss: 2.2109756469726562

Epoch: 6| Step: 13
Training loss: 1.040187120437622
Validation loss: 2.235077659289042

Epoch: 170| Step: 0
Training loss: 0.5517774820327759
Validation loss: 2.1776031851768494

Epoch: 6| Step: 1
Training loss: 0.9261175394058228
Validation loss: 2.213974138100942

Epoch: 6| Step: 2
Training loss: 0.9317035675048828
Validation loss: 2.178933103879293

Epoch: 6| Step: 3
Training loss: 1.0716012716293335
Validation loss: 2.257144252459208

Epoch: 6| Step: 4
Training loss: 0.470825731754303
Validation loss: 2.2259445190429688

Epoch: 6| Step: 5
Training loss: 0.8551824688911438
Validation loss: 2.2056732972462973

Epoch: 6| Step: 6
Training loss: 0.5666996240615845
Validation loss: 2.2058184345563254

Epoch: 6| Step: 7
Training loss: 0.7923845648765564
Validation loss: 2.2569245100021362

Epoch: 6| Step: 8
Training loss: 0.7690595388412476
Validation loss: 2.1779094338417053

Epoch: 6| Step: 9
Training loss: 0.4690207242965698
Validation loss: 2.26962012052536

Epoch: 6| Step: 10
Training loss: 0.7117627859115601
Validation loss: 2.19918562968572

Epoch: 6| Step: 11
Training loss: 0.8239961862564087
Validation loss: 2.2230149706204734

Epoch: 6| Step: 12
Training loss: 0.879565954208374
Validation loss: 2.2298613588015237

Epoch: 6| Step: 13
Training loss: 0.6427999138832092
Validation loss: 2.189967473347982

Epoch: 171| Step: 0
Training loss: 0.7109412550926208
Validation loss: 2.285866300264994

Epoch: 6| Step: 1
Training loss: 0.7849031686782837
Validation loss: 2.2555824915568032

Epoch: 6| Step: 2
Training loss: 0.8209654092788696
Validation loss: 2.2330211400985718

Epoch: 6| Step: 3
Training loss: 1.2312753200531006
Validation loss: 2.1881030003229776

Epoch: 6| Step: 4
Training loss: 0.9883550405502319
Validation loss: 2.1844627459843955

Epoch: 6| Step: 5
Training loss: 1.0489791631698608
Validation loss: 2.189732392628988

Epoch: 6| Step: 6
Training loss: 1.1423895359039307
Validation loss: 2.170888364315033

Epoch: 6| Step: 7
Training loss: 0.600462794303894
Validation loss: 2.1878033876419067

Epoch: 6| Step: 8
Training loss: 0.6454987525939941
Validation loss: 2.153351664543152

Epoch: 6| Step: 9
Training loss: 0.9858485460281372
Validation loss: 2.2127156257629395

Epoch: 6| Step: 10
Training loss: 0.6906534433364868
Validation loss: 2.2340685725212097

Epoch: 6| Step: 11
Training loss: 0.48015815019607544
Validation loss: 2.182532628377279

Epoch: 6| Step: 12
Training loss: 0.4474121332168579
Validation loss: 2.202047129472097

Epoch: 6| Step: 13
Training loss: 0.6299925446510315
Validation loss: 2.2576930125554404

Epoch: 172| Step: 0
Training loss: 0.7931094765663147
Validation loss: 2.200327197710673

Epoch: 6| Step: 1
Training loss: 0.8237156867980957
Validation loss: 2.1951736013094583

Epoch: 6| Step: 2
Training loss: 0.5655596256256104
Validation loss: 2.181550363699595

Epoch: 6| Step: 3
Training loss: 0.5354043245315552
Validation loss: 2.2332253058751426

Epoch: 6| Step: 4
Training loss: 0.8106306791305542
Validation loss: 2.182217280069987

Epoch: 6| Step: 5
Training loss: 1.070591688156128
Validation loss: 2.243471880753835

Epoch: 6| Step: 6
Training loss: 0.615628719329834
Validation loss: 2.2078937689463296

Epoch: 6| Step: 7
Training loss: 1.213517427444458
Validation loss: 2.216227134068807

Epoch: 6| Step: 8
Training loss: 0.8913662433624268
Validation loss: 2.222056726614634

Epoch: 6| Step: 9
Training loss: 0.5320477485656738
Validation loss: 2.23269776503245

Epoch: 6| Step: 10
Training loss: 1.1287764310836792
Validation loss: 2.186375459035238

Epoch: 6| Step: 11
Training loss: 0.6019216775894165
Validation loss: 2.2743504842122397

Epoch: 6| Step: 12
Training loss: 0.6489920616149902
Validation loss: 2.1536558469136557

Epoch: 6| Step: 13
Training loss: 0.5156405568122864
Validation loss: 2.2740461428960166

Epoch: 173| Step: 0
Training loss: 0.9876939058303833
Validation loss: 2.2075517574946084

Epoch: 6| Step: 1
Training loss: 0.8772698640823364
Validation loss: 2.252852439880371

Epoch: 6| Step: 2
Training loss: 0.8525568842887878
Validation loss: 2.204424877961477

Epoch: 6| Step: 3
Training loss: 0.6942548155784607
Validation loss: 2.250587821006775

Epoch: 6| Step: 4
Training loss: 0.6046253442764282
Validation loss: 2.2094072500864663

Epoch: 6| Step: 5
Training loss: 0.376653790473938
Validation loss: 2.2556912899017334

Epoch: 6| Step: 6
Training loss: 0.6304152011871338
Validation loss: 2.2425060073534646

Epoch: 6| Step: 7
Training loss: 0.5779335498809814
Validation loss: 2.2955321073532104

Epoch: 6| Step: 8
Training loss: 1.087646484375
Validation loss: 2.229785760243734

Epoch: 6| Step: 9
Training loss: 0.6941184997558594
Validation loss: 2.215513745943705

Epoch: 6| Step: 10
Training loss: 1.070244550704956
Validation loss: 2.2398164669672647

Epoch: 6| Step: 11
Training loss: 0.5263396501541138
Validation loss: 2.2291341622670493

Epoch: 6| Step: 12
Training loss: 0.6800331473350525
Validation loss: 2.2056155602137246

Epoch: 6| Step: 13
Training loss: 0.5274115800857544
Validation loss: 2.245980461438497

Epoch: 174| Step: 0
Training loss: 0.7849466800689697
Validation loss: 2.236546059449514

Epoch: 6| Step: 1
Training loss: 0.6864107847213745
Validation loss: 2.2885131438573203

Epoch: 6| Step: 2
Training loss: 0.7293746471405029
Validation loss: 2.223291277885437

Epoch: 6| Step: 3
Training loss: 0.8004266023635864
Validation loss: 2.2995510697364807

Epoch: 6| Step: 4
Training loss: 0.6186845898628235
Validation loss: 2.1910352309544883

Epoch: 6| Step: 5
Training loss: 0.7374455332756042
Validation loss: 2.2676828304926553

Epoch: 6| Step: 6
Training loss: 0.7490910291671753
Validation loss: 2.227154036362966

Epoch: 6| Step: 7
Training loss: 0.7295800447463989
Validation loss: 2.2240052024523416

Epoch: 6| Step: 8
Training loss: 0.950681746006012
Validation loss: 2.230816344420115

Epoch: 6| Step: 9
Training loss: 0.7648011445999146
Validation loss: 2.241075038909912

Epoch: 6| Step: 10
Training loss: 0.4208848476409912
Validation loss: 2.2201414903004966

Epoch: 6| Step: 11
Training loss: 0.6222209930419922
Validation loss: 2.233267386754354

Epoch: 6| Step: 12
Training loss: 0.9601922631263733
Validation loss: 2.2151390314102173

Epoch: 6| Step: 13
Training loss: 0.7281895875930786
Validation loss: 2.2375821669896445

Epoch: 175| Step: 0
Training loss: 0.5941069722175598
Validation loss: 2.220580001672109

Epoch: 6| Step: 1
Training loss: 0.7434020042419434
Validation loss: 2.2200454473495483

Epoch: 6| Step: 2
Training loss: 0.8135820627212524
Validation loss: 2.1947547793388367

Epoch: 6| Step: 3
Training loss: 0.5982459783554077
Validation loss: 2.195919950803121

Epoch: 6| Step: 4
Training loss: 0.5888386368751526
Validation loss: 2.2024325927098594

Epoch: 6| Step: 5
Training loss: 0.9647673964500427
Validation loss: 2.166292111078898

Epoch: 6| Step: 6
Training loss: 1.0826431512832642
Validation loss: 2.1810231804847717

Epoch: 6| Step: 7
Training loss: 0.6278651356697083
Validation loss: 2.231497049331665

Epoch: 6| Step: 8
Training loss: 0.5455876588821411
Validation loss: 2.1639914313952127

Epoch: 6| Step: 9
Training loss: 0.46015334129333496
Validation loss: 2.159903566042582

Epoch: 6| Step: 10
Training loss: 0.8078891038894653
Validation loss: 2.227803349494934

Epoch: 6| Step: 11
Training loss: 0.6780202388763428
Validation loss: 2.164748271306356

Epoch: 6| Step: 12
Training loss: 0.9817357063293457
Validation loss: 2.1795787413915

Epoch: 6| Step: 13
Training loss: 0.7275278568267822
Validation loss: 2.2102853655815125

Epoch: 176| Step: 0
Training loss: 0.47515568137168884
Validation loss: 2.251216928164164

Epoch: 6| Step: 1
Training loss: 0.9715691804885864
Validation loss: 2.178950826327006

Epoch: 6| Step: 2
Training loss: 0.25873738527297974
Validation loss: 2.2150563398996987

Epoch: 6| Step: 3
Training loss: 0.7994266748428345
Validation loss: 2.184334913889567

Epoch: 6| Step: 4
Training loss: 1.0094844102859497
Validation loss: 2.2609041929244995

Epoch: 6| Step: 5
Training loss: 0.7372860908508301
Validation loss: 2.2017671267191568

Epoch: 6| Step: 6
Training loss: 0.7625724077224731
Validation loss: 2.2521050175031028

Epoch: 6| Step: 7
Training loss: 0.6832127571105957
Validation loss: 2.2188729643821716

Epoch: 6| Step: 8
Training loss: 0.7029610872268677
Validation loss: 2.22141033411026

Epoch: 6| Step: 9
Training loss: 0.8069273829460144
Validation loss: 2.247979382673899

Epoch: 6| Step: 10
Training loss: 1.0374243259429932
Validation loss: 2.235378881295522

Epoch: 6| Step: 11
Training loss: 0.6440070867538452
Validation loss: 2.2642023960749307

Epoch: 6| Step: 12
Training loss: 0.780969500541687
Validation loss: 2.2339973052342734

Epoch: 6| Step: 13
Training loss: 0.7021987438201904
Validation loss: 2.2572683095932007

Epoch: 177| Step: 0
Training loss: 1.3147540092468262
Validation loss: 2.2027531067530313

Epoch: 6| Step: 1
Training loss: 0.950001060962677
Validation loss: 2.2376772363980613

Epoch: 6| Step: 2
Training loss: 0.6540411114692688
Validation loss: 2.1698176860809326

Epoch: 6| Step: 3
Training loss: 0.5665983557701111
Validation loss: 2.1576594511667886

Epoch: 6| Step: 4
Training loss: 0.5335620045661926
Validation loss: 2.223965644836426

Epoch: 6| Step: 5
Training loss: 0.7142885327339172
Validation loss: 2.2164005835851035

Epoch: 6| Step: 6
Training loss: 0.7636858224868774
Validation loss: 2.2153735558191934

Epoch: 6| Step: 7
Training loss: 0.362289160490036
Validation loss: 2.225292682647705

Epoch: 6| Step: 8
Training loss: 1.0382239818572998
Validation loss: 2.243299881617228

Epoch: 6| Step: 9
Training loss: 0.5277912020683289
Validation loss: 2.232275406519572

Epoch: 6| Step: 10
Training loss: 0.8140794038772583
Validation loss: 2.2062538067499795

Epoch: 6| Step: 11
Training loss: 0.6052747368812561
Validation loss: 2.1606382528940835

Epoch: 6| Step: 12
Training loss: 0.799546480178833
Validation loss: 2.1873368422190347

Epoch: 6| Step: 13
Training loss: 0.6874650120735168
Validation loss: 2.1993871927261353

Epoch: 178| Step: 0
Training loss: 0.6214506030082703
Validation loss: 2.1965203483899436

Epoch: 6| Step: 1
Training loss: 1.2632734775543213
Validation loss: 2.2130648096402488

Epoch: 6| Step: 2
Training loss: 0.6631255149841309
Validation loss: 2.26837029059728

Epoch: 6| Step: 3
Training loss: 0.44459906220436096
Validation loss: 2.2236586213111877

Epoch: 6| Step: 4
Training loss: 0.6229239106178284
Validation loss: 2.1878622174263

Epoch: 6| Step: 5
Training loss: 0.9126990437507629
Validation loss: 2.2871695359547934

Epoch: 6| Step: 6
Training loss: 0.8452308177947998
Validation loss: 2.240441083908081

Epoch: 6| Step: 7
Training loss: 0.717338502407074
Validation loss: 2.218730608622233

Epoch: 6| Step: 8
Training loss: 0.6472342014312744
Validation loss: 2.1891307830810547

Epoch: 6| Step: 9
Training loss: 0.8175219297409058
Validation loss: 2.256978909174601

Epoch: 6| Step: 10
Training loss: 0.521325409412384
Validation loss: 2.221400558948517

Epoch: 6| Step: 11
Training loss: 1.047054648399353
Validation loss: 2.1616744796435037

Epoch: 6| Step: 12
Training loss: 0.5195272564888
Validation loss: 2.2587453722953796

Epoch: 6| Step: 13
Training loss: 0.6911953091621399
Validation loss: 2.2133758862813315

Epoch: 179| Step: 0
Training loss: 1.001845359802246
Validation loss: 2.200982610384623

Epoch: 6| Step: 1
Training loss: 0.32560470700263977
Validation loss: 2.1892604430516562

Epoch: 6| Step: 2
Training loss: 0.8199169039726257
Validation loss: 2.1867926518122354

Epoch: 6| Step: 3
Training loss: 0.6080397367477417
Validation loss: 2.2127529978752136

Epoch: 6| Step: 4
Training loss: 0.6813471913337708
Validation loss: 2.2290348013242087

Epoch: 6| Step: 5
Training loss: 0.8966434597969055
Validation loss: 2.1808831294377646

Epoch: 6| Step: 6
Training loss: 0.6031278371810913
Validation loss: 2.2190063993136087

Epoch: 6| Step: 7
Training loss: 0.9778484106063843
Validation loss: 2.2553510268529258

Epoch: 6| Step: 8
Training loss: 1.2160212993621826
Validation loss: 2.2061872482299805

Epoch: 6| Step: 9
Training loss: 0.5584032535552979
Validation loss: 2.153289715449015

Epoch: 6| Step: 10
Training loss: 0.7162377238273621
Validation loss: 2.2263293663660684

Epoch: 6| Step: 11
Training loss: 1.0262000560760498
Validation loss: 2.1976813077926636

Epoch: 6| Step: 12
Training loss: 0.5271716117858887
Validation loss: 2.229347268740336

Epoch: 6| Step: 13
Training loss: 0.34434401988983154
Validation loss: 2.237053712209066

Epoch: 180| Step: 0
Training loss: 1.632744550704956
Validation loss: 2.2049596707026162

Epoch: 6| Step: 1
Training loss: 1.0079448223114014
Validation loss: 2.1887404123942056

Epoch: 6| Step: 2
Training loss: 1.117879867553711
Validation loss: 2.218118170897166

Epoch: 6| Step: 3
Training loss: 0.8659531474113464
Validation loss: 2.236524283885956

Epoch: 6| Step: 4
Training loss: 0.2393784523010254
Validation loss: 2.272789180278778

Epoch: 6| Step: 5
Training loss: 0.8837408423423767
Validation loss: 2.2850584586461387

Epoch: 6| Step: 6
Training loss: 0.7471965551376343
Validation loss: 2.245256781578064

Epoch: 6| Step: 7
Training loss: 0.5349130630493164
Validation loss: 2.256039261817932

Epoch: 6| Step: 8
Training loss: 0.5616033673286438
Validation loss: 2.317376891771952

Epoch: 6| Step: 9
Training loss: 0.5482761859893799
Validation loss: 2.1746742129325867

Epoch: 6| Step: 10
Training loss: 0.4497395157814026
Validation loss: 2.2020880977312722

Epoch: 6| Step: 11
Training loss: 0.5269919633865356
Validation loss: 2.244386156400045

Epoch: 6| Step: 12
Training loss: 0.5240488052368164
Validation loss: 2.234013775984446

Epoch: 6| Step: 13
Training loss: 0.7348702549934387
Validation loss: 2.228306293487549

Epoch: 181| Step: 0
Training loss: 0.5660796165466309
Validation loss: 2.2342397769292197

Epoch: 6| Step: 1
Training loss: 0.8452515006065369
Validation loss: 2.2913322846094766

Epoch: 6| Step: 2
Training loss: 0.5930884480476379
Validation loss: 2.2241397897402444

Epoch: 6| Step: 3
Training loss: 0.8036637902259827
Validation loss: 2.254037002722422

Epoch: 6| Step: 4
Training loss: 0.4207894802093506
Validation loss: 2.2411028345425925

Epoch: 6| Step: 5
Training loss: 0.6587342619895935
Validation loss: 2.268777370452881

Epoch: 6| Step: 6
Training loss: 0.6858320236206055
Validation loss: 2.2602425614992776

Epoch: 6| Step: 7
Training loss: 1.3412888050079346
Validation loss: 2.218824028968811

Epoch: 6| Step: 8
Training loss: 0.40747857093811035
Validation loss: 2.2301169832547507

Epoch: 6| Step: 9
Training loss: 0.6127440333366394
Validation loss: 2.2250916163126626

Epoch: 6| Step: 10
Training loss: 0.6689164638519287
Validation loss: 2.2443977197011313

Epoch: 6| Step: 11
Training loss: 0.5796976089477539
Validation loss: 2.1974409023920694

Epoch: 6| Step: 12
Training loss: 0.9051722884178162
Validation loss: 2.2590813835461936

Epoch: 6| Step: 13
Training loss: 0.5892596244812012
Validation loss: 2.182578682899475

Epoch: 182| Step: 0
Training loss: 0.6872203350067139
Validation loss: 2.2668620546658835

Epoch: 6| Step: 1
Training loss: 0.6094405651092529
Validation loss: 2.263694405555725

Epoch: 6| Step: 2
Training loss: 0.7603413462638855
Validation loss: 2.213377674420675

Epoch: 6| Step: 3
Training loss: 0.8718475103378296
Validation loss: 2.1903573075930276

Epoch: 6| Step: 4
Training loss: 0.8669689893722534
Validation loss: 2.2124368945757547

Epoch: 6| Step: 5
Training loss: 0.6811520457267761
Validation loss: 2.1976384917894998

Epoch: 6| Step: 6
Training loss: 0.3576638698577881
Validation loss: 2.1622172196706138

Epoch: 6| Step: 7
Training loss: 0.905051589012146
Validation loss: 2.200729191303253

Epoch: 6| Step: 8
Training loss: 0.5709341764450073
Validation loss: 2.168760101000468

Epoch: 6| Step: 9
Training loss: 0.863273024559021
Validation loss: 2.1786646842956543

Epoch: 6| Step: 10
Training loss: 0.5129778385162354
Validation loss: 2.2555103500684104

Epoch: 6| Step: 11
Training loss: 0.8436840772628784
Validation loss: 2.1791470448176065

Epoch: 6| Step: 12
Training loss: 0.8282449841499329
Validation loss: 2.2242380380630493

Epoch: 6| Step: 13
Training loss: 0.4001280665397644
Validation loss: 2.2268177270889282

Epoch: 183| Step: 0
Training loss: 1.0172786712646484
Validation loss: 2.2619197567303977

Epoch: 6| Step: 1
Training loss: 0.6123102903366089
Validation loss: 2.2406222820281982

Epoch: 6| Step: 2
Training loss: 1.03678560256958
Validation loss: 2.2388828794161477

Epoch: 6| Step: 3
Training loss: 0.9747247695922852
Validation loss: 2.2184540828069053

Epoch: 6| Step: 4
Training loss: 0.7496450543403625
Validation loss: 2.1875799695650735

Epoch: 6| Step: 5
Training loss: 0.616762638092041
Validation loss: 2.261155664920807

Epoch: 6| Step: 6
Training loss: 0.7996065616607666
Validation loss: 2.216997424761454

Epoch: 6| Step: 7
Training loss: 0.477954238653183
Validation loss: 2.243735392888387

Epoch: 6| Step: 8
Training loss: 0.48286017775535583
Validation loss: 2.2322078148523965

Epoch: 6| Step: 9
Training loss: 0.7534622550010681
Validation loss: 2.3168160120646157

Epoch: 6| Step: 10
Training loss: 0.924776554107666
Validation loss: 2.278635839621226

Epoch: 6| Step: 11
Training loss: 0.7434989809989929
Validation loss: 2.2885891795158386

Epoch: 6| Step: 12
Training loss: 0.4338033199310303
Validation loss: 2.197688857714335

Epoch: 6| Step: 13
Training loss: 0.7085339426994324
Validation loss: 2.216442286968231

Epoch: 184| Step: 0
Training loss: 0.48215818405151367
Validation loss: 2.2179172237714133

Epoch: 6| Step: 1
Training loss: 1.1631617546081543
Validation loss: 2.229117969671885

Epoch: 6| Step: 2
Training loss: 0.9251198768615723
Validation loss: 2.2658883134524026

Epoch: 6| Step: 3
Training loss: 0.8065763115882874
Validation loss: 2.201397657394409

Epoch: 6| Step: 4
Training loss: 0.23120802640914917
Validation loss: 2.1719288428624473

Epoch: 6| Step: 5
Training loss: 0.6771586537361145
Validation loss: 2.2197808623313904

Epoch: 6| Step: 6
Training loss: 0.7567991018295288
Validation loss: 2.2930322686831155

Epoch: 6| Step: 7
Training loss: 1.049237847328186
Validation loss: 2.2905451456705728

Epoch: 6| Step: 8
Training loss: 0.9115567207336426
Validation loss: 2.2051493724187217

Epoch: 6| Step: 9
Training loss: 0.5023970603942871
Validation loss: 2.1856636206309

Epoch: 6| Step: 10
Training loss: 0.4747623801231384
Validation loss: 2.139825463294983

Epoch: 6| Step: 11
Training loss: 0.9707583785057068
Validation loss: 2.1720320781071982

Epoch: 6| Step: 12
Training loss: 0.7445975542068481
Validation loss: 2.156981865564982

Epoch: 6| Step: 13
Training loss: 0.5524175763130188
Validation loss: 2.167396863301595

Epoch: 185| Step: 0
Training loss: 0.5576578378677368
Validation loss: 2.2116835912068686

Epoch: 6| Step: 1
Training loss: 0.903571367263794
Validation loss: 2.229497234026591

Epoch: 6| Step: 2
Training loss: 1.1140012741088867
Validation loss: 2.2036548455556235

Epoch: 6| Step: 3
Training loss: 0.7050480842590332
Validation loss: 2.294588009516398

Epoch: 6| Step: 4
Training loss: 0.7074716091156006
Validation loss: 2.202276329199473

Epoch: 6| Step: 5
Training loss: 0.5123378038406372
Validation loss: 2.1417007446289062

Epoch: 6| Step: 6
Training loss: 0.9710538387298584
Validation loss: 2.1794264713923135

Epoch: 6| Step: 7
Training loss: 0.9449024200439453
Validation loss: 2.271246830622355

Epoch: 6| Step: 8
Training loss: 0.75811767578125
Validation loss: 2.200475732485453

Epoch: 6| Step: 9
Training loss: 0.6502494215965271
Validation loss: 2.204317649205526

Epoch: 6| Step: 10
Training loss: 1.013648509979248
Validation loss: 2.220987856388092

Epoch: 6| Step: 11
Training loss: 0.4930031895637512
Validation loss: 2.2543484767278037

Epoch: 6| Step: 12
Training loss: 0.7249218225479126
Validation loss: 2.2766112089157104

Epoch: 6| Step: 13
Training loss: 0.5752980709075928
Validation loss: 2.2515915632247925

Epoch: 186| Step: 0
Training loss: 1.389809250831604
Validation loss: 2.2932481368382773

Epoch: 6| Step: 1
Training loss: 0.5867107510566711
Validation loss: 2.291912794113159

Epoch: 6| Step: 2
Training loss: 0.6561610698699951
Validation loss: 2.223275105158488

Epoch: 6| Step: 3
Training loss: 0.8536925911903381
Validation loss: 2.2176385124524436

Epoch: 6| Step: 4
Training loss: 0.7482846975326538
Validation loss: 2.234780470530192

Epoch: 6| Step: 5
Training loss: 0.5838869214057922
Validation loss: 2.27096019188563

Epoch: 6| Step: 6
Training loss: 0.7689355611801147
Validation loss: 2.2122252186139426

Epoch: 6| Step: 7
Training loss: 0.24534820020198822
Validation loss: 2.238699277242025

Epoch: 6| Step: 8
Training loss: 0.8185263872146606
Validation loss: 2.22768505414327

Epoch: 6| Step: 9
Training loss: 0.3973407447338104
Validation loss: 2.2364599903424582

Epoch: 6| Step: 10
Training loss: 0.6429075598716736
Validation loss: 2.223365286986033

Epoch: 6| Step: 11
Training loss: 0.5687451362609863
Validation loss: 2.248367349306742

Epoch: 6| Step: 12
Training loss: 0.7208490371704102
Validation loss: 2.2312685449918113

Epoch: 6| Step: 13
Training loss: 0.6843419671058655
Validation loss: 2.23015958070755

Epoch: 187| Step: 0
Training loss: 0.46294718980789185
Validation loss: 2.1856479247411094

Epoch: 6| Step: 1
Training loss: 0.7260236740112305
Validation loss: 2.21793524424235

Epoch: 6| Step: 2
Training loss: 0.8530359268188477
Validation loss: 2.185920079549154

Epoch: 6| Step: 3
Training loss: 0.9344862699508667
Validation loss: 2.2303584218025208

Epoch: 6| Step: 4
Training loss: 0.4774627685546875
Validation loss: 2.2408743699391684

Epoch: 6| Step: 5
Training loss: 0.8156107664108276
Validation loss: 2.2098406155904136

Epoch: 6| Step: 6
Training loss: 0.7606291174888611
Validation loss: 2.1979796091715493

Epoch: 6| Step: 7
Training loss: 0.5812510251998901
Validation loss: 2.271074096361796

Epoch: 6| Step: 8
Training loss: 0.5800740718841553
Validation loss: 2.248361567656199

Epoch: 6| Step: 9
Training loss: 0.9269095063209534
Validation loss: 2.1918915510177612

Epoch: 6| Step: 10
Training loss: 0.710091233253479
Validation loss: 2.2179775635401406

Epoch: 6| Step: 11
Training loss: 0.3845241069793701
Validation loss: 2.199079076449076

Epoch: 6| Step: 12
Training loss: 0.2627842426300049
Validation loss: 2.196787436803182

Epoch: 6| Step: 13
Training loss: 0.7668458223342896
Validation loss: 2.2507674296696982

Epoch: 188| Step: 0
Training loss: 0.6425800323486328
Validation loss: 2.2359628677368164

Epoch: 6| Step: 1
Training loss: 0.42903435230255127
Validation loss: 2.2093325654665628

Epoch: 6| Step: 2
Training loss: 0.47563642263412476
Validation loss: 2.2056797544161477

Epoch: 6| Step: 3
Training loss: 0.3835263252258301
Validation loss: 2.206995944182078

Epoch: 6| Step: 4
Training loss: 0.7047355771064758
Validation loss: 2.2486576437950134

Epoch: 6| Step: 5
Training loss: 0.8496683835983276
Validation loss: 2.2574822902679443

Epoch: 6| Step: 6
Training loss: 0.803737998008728
Validation loss: 2.2128480076789856

Epoch: 6| Step: 7
Training loss: 0.3455424904823303
Validation loss: 2.179751912752787

Epoch: 6| Step: 8
Training loss: 0.5375513434410095
Validation loss: 2.18405020236969

Epoch: 6| Step: 9
Training loss: 0.49068066477775574
Validation loss: 2.2387574116388955

Epoch: 6| Step: 10
Training loss: 1.1540807485580444
Validation loss: 2.207375923792521

Epoch: 6| Step: 11
Training loss: 0.8298620581626892
Validation loss: 2.1816264589627585

Epoch: 6| Step: 12
Training loss: 0.5364066362380981
Validation loss: 2.265078862508138

Epoch: 6| Step: 13
Training loss: 0.62514728307724
Validation loss: 2.233538826306661

Epoch: 189| Step: 0
Training loss: 0.612747311592102
Validation loss: 2.296510716279348

Epoch: 6| Step: 1
Training loss: 0.4437669515609741
Validation loss: 2.2115315198898315

Epoch: 6| Step: 2
Training loss: 0.4471122622489929
Validation loss: 2.2088690201441445

Epoch: 6| Step: 3
Training loss: 0.9638327360153198
Validation loss: 2.190007964769999

Epoch: 6| Step: 4
Training loss: 0.7183658480644226
Validation loss: 2.1589790185292563

Epoch: 6| Step: 5
Training loss: 0.9548989534378052
Validation loss: 2.244461715221405

Epoch: 6| Step: 6
Training loss: 0.6391879320144653
Validation loss: 2.246035019556681

Epoch: 6| Step: 7
Training loss: 0.7774989604949951
Validation loss: 2.2235635916392007

Epoch: 6| Step: 8
Training loss: 0.40564894676208496
Validation loss: 2.2663309971491494

Epoch: 6| Step: 9
Training loss: 0.5461295247077942
Validation loss: 2.210494101047516

Epoch: 6| Step: 10
Training loss: 0.5542957186698914
Validation loss: 2.2128047545750937

Epoch: 6| Step: 11
Training loss: 0.49402204155921936
Validation loss: 2.2273033062616983

Epoch: 6| Step: 12
Training loss: 0.9272415637969971
Validation loss: 2.2054322957992554

Epoch: 6| Step: 13
Training loss: 0.7402986884117126
Validation loss: 2.2166014313697815

Epoch: 190| Step: 0
Training loss: 0.7293887138366699
Validation loss: 2.2256656289100647

Epoch: 6| Step: 1
Training loss: 0.6998223066329956
Validation loss: 2.263923247655233

Epoch: 6| Step: 2
Training loss: 0.5408362150192261
Validation loss: 2.2792442639668784

Epoch: 6| Step: 3
Training loss: 0.6674425601959229
Validation loss: 2.2334227164586387

Epoch: 6| Step: 4
Training loss: 0.36507439613342285
Validation loss: 2.232172509034475

Epoch: 6| Step: 5
Training loss: 0.8460908532142639
Validation loss: 2.223577698071798

Epoch: 6| Step: 6
Training loss: 0.5837504863739014
Validation loss: 2.2512757778167725

Epoch: 6| Step: 7
Training loss: 0.8742740154266357
Validation loss: 2.2298362255096436

Epoch: 6| Step: 8
Training loss: 0.6451399922370911
Validation loss: 2.2621060808499656

Epoch: 6| Step: 9
Training loss: 0.35641658306121826
Validation loss: 2.2597005565961203

Epoch: 6| Step: 10
Training loss: 0.99948650598526
Validation loss: 2.2626921931902566

Epoch: 6| Step: 11
Training loss: 0.9198857545852661
Validation loss: 2.2628307143847146

Epoch: 6| Step: 12
Training loss: 0.6841526031494141
Validation loss: 2.2511478861172995

Epoch: 6| Step: 13
Training loss: 0.5472507476806641
Validation loss: 2.2798542380332947

Epoch: 191| Step: 0
Training loss: 0.41549184918403625
Validation loss: 2.244876980781555

Epoch: 6| Step: 1
Training loss: 0.7413725256919861
Validation loss: 2.2458626429239907

Epoch: 6| Step: 2
Training loss: 0.6998220682144165
Validation loss: 2.2244491974512735

Epoch: 6| Step: 3
Training loss: 0.37896832823753357
Validation loss: 2.205397089322408

Epoch: 6| Step: 4
Training loss: 0.8608690500259399
Validation loss: 2.27284038066864

Epoch: 6| Step: 5
Training loss: 0.630901575088501
Validation loss: 2.1918556491533914

Epoch: 6| Step: 6
Training loss: 0.6354138851165771
Validation loss: 2.2267927726109824

Epoch: 6| Step: 7
Training loss: 0.7785837650299072
Validation loss: 2.2457876602808633

Epoch: 6| Step: 8
Training loss: 0.29345446825027466
Validation loss: 2.28400049606959

Epoch: 6| Step: 9
Training loss: 0.6961524486541748
Validation loss: 2.2402533888816833

Epoch: 6| Step: 10
Training loss: 0.582734227180481
Validation loss: 2.2821276585261026

Epoch: 6| Step: 11
Training loss: 0.7350060939788818
Validation loss: 2.2313729524612427

Epoch: 6| Step: 12
Training loss: 0.6253297924995422
Validation loss: 2.2387781739234924

Epoch: 6| Step: 13
Training loss: 0.9205850958824158
Validation loss: 2.2197163502375283

Epoch: 192| Step: 0
Training loss: 0.22585968673229218
Validation loss: 2.1925190687179565

Epoch: 6| Step: 1
Training loss: 0.5911446213722229
Validation loss: 2.2224254608154297

Epoch: 6| Step: 2
Training loss: 0.46532630920410156
Validation loss: 2.1947753032048545

Epoch: 6| Step: 3
Training loss: 0.46341219544410706
Validation loss: 2.2075692812601724

Epoch: 6| Step: 4
Training loss: 0.9719761610031128
Validation loss: 2.2016347448031106

Epoch: 6| Step: 5
Training loss: 0.8913174271583557
Validation loss: 2.1368991335233054

Epoch: 6| Step: 6
Training loss: 0.5339109301567078
Validation loss: 2.1938208738962808

Epoch: 6| Step: 7
Training loss: 0.8092656135559082
Validation loss: 2.2213696042696633

Epoch: 6| Step: 8
Training loss: 0.6805059909820557
Validation loss: 2.183412035306295

Epoch: 6| Step: 9
Training loss: 0.711971640586853
Validation loss: 2.223079482714335

Epoch: 6| Step: 10
Training loss: 0.4312553405761719
Validation loss: 2.220948040485382

Epoch: 6| Step: 11
Training loss: 0.78713059425354
Validation loss: 2.252315024534861

Epoch: 6| Step: 12
Training loss: 0.5573369264602661
Validation loss: 2.2826386292775473

Epoch: 6| Step: 13
Training loss: 0.5742784142494202
Validation loss: 2.2006276845932007

Epoch: 193| Step: 0
Training loss: 0.7263426184654236
Validation loss: 2.198824147383372

Epoch: 6| Step: 1
Training loss: 0.766219437122345
Validation loss: 2.2432036995887756

Epoch: 6| Step: 2
Training loss: 0.39620429277420044
Validation loss: 2.240494509538015

Epoch: 6| Step: 3
Training loss: 0.5745257139205933
Validation loss: 2.235658824443817

Epoch: 6| Step: 4
Training loss: 0.38324448466300964
Validation loss: 2.1888161102930703

Epoch: 6| Step: 5
Training loss: 0.6059021353721619
Validation loss: 2.213360369205475

Epoch: 6| Step: 6
Training loss: 0.9115026593208313
Validation loss: 2.207534452279409

Epoch: 6| Step: 7
Training loss: 0.5695939064025879
Validation loss: 2.267347514629364

Epoch: 6| Step: 8
Training loss: 0.47347670793533325
Validation loss: 2.2105144460995994

Epoch: 6| Step: 9
Training loss: 0.6834259629249573
Validation loss: 2.2612760861714682

Epoch: 6| Step: 10
Training loss: 0.39185822010040283
Validation loss: 2.227174003918966

Epoch: 6| Step: 11
Training loss: 0.8269690275192261
Validation loss: 2.1780362129211426

Epoch: 6| Step: 12
Training loss: 0.5488702654838562
Validation loss: 2.1993191639582315

Epoch: 6| Step: 13
Training loss: 0.7252861261367798
Validation loss: 2.2188895543416343

Epoch: 194| Step: 0
Training loss: 0.8500055074691772
Validation loss: 2.2244855562845864

Epoch: 6| Step: 1
Training loss: 0.3711532950401306
Validation loss: 2.272633115450541

Epoch: 6| Step: 2
Training loss: 0.7759871482849121
Validation loss: 2.2793060739835105

Epoch: 6| Step: 3
Training loss: 0.366019070148468
Validation loss: 2.1989901463190713

Epoch: 6| Step: 4
Training loss: 0.8589203953742981
Validation loss: 2.2174296577771506

Epoch: 6| Step: 5
Training loss: 0.6210057735443115
Validation loss: 2.256728708744049

Epoch: 6| Step: 6
Training loss: 0.5956282615661621
Validation loss: 2.2322516242663064

Epoch: 6| Step: 7
Training loss: 0.5348557233810425
Validation loss: 2.2139779329299927

Epoch: 6| Step: 8
Training loss: 0.6618885397911072
Validation loss: 2.1670565803845725

Epoch: 6| Step: 9
Training loss: 0.7314360737800598
Validation loss: 2.210012912750244

Epoch: 6| Step: 10
Training loss: 0.49118536710739136
Validation loss: 2.2414254744847617

Epoch: 6| Step: 11
Training loss: 0.6894938945770264
Validation loss: 2.1622461477915444

Epoch: 6| Step: 12
Training loss: 0.8376995325088501
Validation loss: 2.1994208097457886

Epoch: 6| Step: 13
Training loss: 0.7596240043640137
Validation loss: 2.202296415964762

Epoch: 195| Step: 0
Training loss: 0.5164366960525513
Validation loss: 2.2195199131965637

Epoch: 6| Step: 1
Training loss: 0.41033464670181274
Validation loss: 2.2334907054901123

Epoch: 6| Step: 2
Training loss: 1.1011786460876465
Validation loss: 2.2576473553975425

Epoch: 6| Step: 3
Training loss: 0.9156684875488281
Validation loss: 2.1939704616864524

Epoch: 6| Step: 4
Training loss: 0.46851134300231934
Validation loss: 2.2032631436983743

Epoch: 6| Step: 5
Training loss: 0.5233519077301025
Validation loss: 2.1942222913106284

Epoch: 6| Step: 6
Training loss: 0.6359504461288452
Validation loss: 2.1969204942385354

Epoch: 6| Step: 7
Training loss: 0.5630654692649841
Validation loss: 2.209842006365458

Epoch: 6| Step: 8
Training loss: 0.6735774874687195
Validation loss: 2.1576747496922812

Epoch: 6| Step: 9
Training loss: 0.5431164503097534
Validation loss: 2.2485475738843284

Epoch: 6| Step: 10
Training loss: 0.47104713320732117
Validation loss: 2.2094503045082092

Epoch: 6| Step: 11
Training loss: 0.7945716977119446
Validation loss: 2.153965969880422

Epoch: 6| Step: 12
Training loss: 0.6189879775047302
Validation loss: 2.219214379787445

Epoch: 6| Step: 13
Training loss: 1.0949634313583374
Validation loss: 2.2090590596199036

Epoch: 196| Step: 0
Training loss: 0.7678939700126648
Validation loss: 2.1640769044558206

Epoch: 6| Step: 1
Training loss: 0.3482220768928528
Validation loss: 2.2032423416773477

Epoch: 6| Step: 2
Training loss: 0.7277799248695374
Validation loss: 2.1979462107022605

Epoch: 6| Step: 3
Training loss: 0.8134629726409912
Validation loss: 2.2188711365063987

Epoch: 6| Step: 4
Training loss: 0.8878668546676636
Validation loss: 2.25159752368927

Epoch: 6| Step: 5
Training loss: 0.34276142716407776
Validation loss: 2.23252934217453

Epoch: 6| Step: 6
Training loss: 0.57979416847229
Validation loss: 2.1775678197542825

Epoch: 6| Step: 7
Training loss: 0.3770388662815094
Validation loss: 2.2076470454533896

Epoch: 6| Step: 8
Training loss: 0.385015606880188
Validation loss: 2.2389979362487793

Epoch: 6| Step: 9
Training loss: 0.8737832307815552
Validation loss: 2.1561787128448486

Epoch: 6| Step: 10
Training loss: 0.7677846550941467
Validation loss: 2.191917657852173

Epoch: 6| Step: 11
Training loss: 0.7553001046180725
Validation loss: 2.230006217956543

Epoch: 6| Step: 12
Training loss: 0.46513983607292175
Validation loss: 2.1905465126037598

Epoch: 6| Step: 13
Training loss: 0.3879987299442291
Validation loss: 2.206696927547455

Epoch: 197| Step: 0
Training loss: 0.2931428551673889
Validation loss: 2.218307892481486

Epoch: 6| Step: 1
Training loss: 0.8337392210960388
Validation loss: 2.2793271938959756

Epoch: 6| Step: 2
Training loss: 0.4132186472415924
Validation loss: 2.2574933767318726

Epoch: 6| Step: 3
Training loss: 0.7574869990348816
Validation loss: 2.2153764565785727

Epoch: 6| Step: 4
Training loss: 0.6662396192550659
Validation loss: 2.2469234267870584

Epoch: 6| Step: 5
Training loss: 1.099806785583496
Validation loss: 2.2332089145978293

Epoch: 6| Step: 6
Training loss: 0.5106396079063416
Validation loss: 2.178453803062439

Epoch: 6| Step: 7
Training loss: 0.7256140112876892
Validation loss: 2.2263439098993936

Epoch: 6| Step: 8
Training loss: 0.65870201587677
Validation loss: 2.1724058985710144

Epoch: 6| Step: 9
Training loss: 0.6913169622421265
Validation loss: 2.265212337176005

Epoch: 6| Step: 10
Training loss: 0.3265349268913269
Validation loss: 2.212624430656433

Epoch: 6| Step: 11
Training loss: 0.3933381736278534
Validation loss: 2.191113074620565

Epoch: 6| Step: 12
Training loss: 0.44777214527130127
Validation loss: 2.290282746156057

Epoch: 6| Step: 13
Training loss: 0.6455851793289185
Validation loss: 2.248862385749817

Epoch: 198| Step: 0
Training loss: 0.473202109336853
Validation loss: 2.1970014572143555

Epoch: 6| Step: 1
Training loss: 0.822536051273346
Validation loss: 2.165402094523112

Epoch: 6| Step: 2
Training loss: 0.45054224133491516
Validation loss: 2.212972084681193

Epoch: 6| Step: 3
Training loss: 1.0207157135009766
Validation loss: 2.193787773450216

Epoch: 6| Step: 4
Training loss: 0.470400333404541
Validation loss: 2.1500420769055686

Epoch: 6| Step: 5
Training loss: 0.6004892587661743
Validation loss: 2.2182140747706094

Epoch: 6| Step: 6
Training loss: 0.7032101154327393
Validation loss: 2.2298320531845093

Epoch: 6| Step: 7
Training loss: 0.5012850165367126
Validation loss: 2.1804139614105225

Epoch: 6| Step: 8
Training loss: 0.557633638381958
Validation loss: 2.133092443148295

Epoch: 6| Step: 9
Training loss: 0.6759177446365356
Validation loss: 2.2407147685686746

Epoch: 6| Step: 10
Training loss: 0.48876428604125977
Validation loss: 2.1840680638949075

Epoch: 6| Step: 11
Training loss: 0.8082910776138306
Validation loss: 2.219916820526123

Epoch: 6| Step: 12
Training loss: 0.20161379873752594
Validation loss: 2.1434964338938394

Epoch: 6| Step: 13
Training loss: 0.38193321228027344
Validation loss: 2.2018974224726358

Epoch: 199| Step: 0
Training loss: 0.38717663288116455
Validation loss: 2.233701308568319

Epoch: 6| Step: 1
Training loss: 0.3417337238788605
Validation loss: 2.2278995911280313

Epoch: 6| Step: 2
Training loss: 0.394045889377594
Validation loss: 2.1647828420003257

Epoch: 6| Step: 3
Training loss: 0.7415550947189331
Validation loss: 2.195937931537628

Epoch: 6| Step: 4
Training loss: 1.0148398876190186
Validation loss: 2.2250917156537375

Epoch: 6| Step: 5
Training loss: 0.6413660645484924
Validation loss: 2.2217758893966675

Epoch: 6| Step: 6
Training loss: 0.5703495740890503
Validation loss: 2.2447573145230613

Epoch: 6| Step: 7
Training loss: 0.4812069237232208
Validation loss: 2.2312989234924316

Epoch: 6| Step: 8
Training loss: 0.4803306758403778
Validation loss: 2.2088720401128135

Epoch: 6| Step: 9
Training loss: 1.0128703117370605
Validation loss: 2.2408074537913003

Epoch: 6| Step: 10
Training loss: 0.5308352112770081
Validation loss: 2.206036468346914

Epoch: 6| Step: 11
Training loss: 0.43910565972328186
Validation loss: 2.198871155579885

Epoch: 6| Step: 12
Training loss: 0.3409960865974426
Validation loss: 2.19040048122406

Epoch: 6| Step: 13
Training loss: 0.9447118043899536
Validation loss: 2.2914183537165322

Epoch: 200| Step: 0
Training loss: 0.4912976324558258
Validation loss: 2.2364852825800576

Epoch: 6| Step: 1
Training loss: 0.6879607439041138
Validation loss: 2.1995967626571655

Epoch: 6| Step: 2
Training loss: 0.48357588052749634
Validation loss: 2.2640214363733926

Epoch: 6| Step: 3
Training loss: 0.552969217300415
Validation loss: 2.1885520617167153

Epoch: 6| Step: 4
Training loss: 1.091212272644043
Validation loss: 2.2215116222699485

Epoch: 6| Step: 5
Training loss: 0.19207069277763367
Validation loss: 2.1669467886288962

Epoch: 6| Step: 6
Training loss: 0.36643871665000916
Validation loss: 2.202290157477061

Epoch: 6| Step: 7
Training loss: 0.47862231731414795
Validation loss: 2.2226192156473794

Epoch: 6| Step: 8
Training loss: 0.4660727083683014
Validation loss: 2.1345819234848022

Epoch: 6| Step: 9
Training loss: 0.5713502168655396
Validation loss: 2.22185484568278

Epoch: 6| Step: 10
Training loss: 0.8525412082672119
Validation loss: 2.194254477818807

Epoch: 6| Step: 11
Training loss: 0.4042263627052307
Validation loss: 2.1343799432118735

Epoch: 6| Step: 12
Training loss: 0.7334800362586975
Validation loss: 2.255267341931661

Epoch: 6| Step: 13
Training loss: 0.7244767546653748
Validation loss: 2.147440493106842

Epoch: 201| Step: 0
Training loss: 0.3781406283378601
Validation loss: 2.2944725155830383

Epoch: 6| Step: 1
Training loss: 0.5410016179084778
Validation loss: 2.1780176162719727

Epoch: 6| Step: 2
Training loss: 0.8433364033699036
Validation loss: 2.2487032810846963

Epoch: 6| Step: 3
Training loss: 1.4288464784622192
Validation loss: 2.2219393452008567

Epoch: 6| Step: 4
Training loss: 0.6509052515029907
Validation loss: 2.211350659529368

Epoch: 6| Step: 5
Training loss: 0.5098086595535278
Validation loss: 2.2139454086621604

Epoch: 6| Step: 6
Training loss: 0.3987096846103668
Validation loss: 2.202203015486399

Epoch: 6| Step: 7
Training loss: 0.317410409450531
Validation loss: 2.212639073530833

Epoch: 6| Step: 8
Training loss: 0.8081821203231812
Validation loss: 2.276193896929423

Epoch: 6| Step: 9
Training loss: 0.5128379464149475
Validation loss: 2.298853079477946

Epoch: 6| Step: 10
Training loss: 0.3101296126842499
Validation loss: 2.3035751382509866

Epoch: 6| Step: 11
Training loss: 0.3950454890727997
Validation loss: 2.188503702481588

Epoch: 6| Step: 12
Training loss: 0.7910105586051941
Validation loss: 2.2375592986742654

Epoch: 6| Step: 13
Training loss: 0.8175539374351501
Validation loss: 2.211830973625183

Epoch: 202| Step: 0
Training loss: 0.6784767508506775
Validation loss: 2.2556100289026895

Epoch: 6| Step: 1
Training loss: 0.4180523455142975
Validation loss: 2.254934231440226

Epoch: 6| Step: 2
Training loss: 0.4390910863876343
Validation loss: 2.255997101465861

Epoch: 6| Step: 3
Training loss: 0.591714084148407
Validation loss: 2.178793211778005

Epoch: 6| Step: 4
Training loss: 1.0470054149627686
Validation loss: 2.2435792684555054

Epoch: 6| Step: 5
Training loss: 0.3626269996166229
Validation loss: 2.2311176856358848

Epoch: 6| Step: 6
Training loss: 0.3764228820800781
Validation loss: 2.1883850693702698

Epoch: 6| Step: 7
Training loss: 0.4562992453575134
Validation loss: 2.1968546708424888

Epoch: 6| Step: 8
Training loss: 0.6738724708557129
Validation loss: 2.21840234597524

Epoch: 6| Step: 9
Training loss: 0.5968103408813477
Validation loss: 2.2140023708343506

Epoch: 6| Step: 10
Training loss: 0.5287080407142639
Validation loss: 2.173858722050985

Epoch: 6| Step: 11
Training loss: 0.7492690086364746
Validation loss: 2.1636808713277182

Epoch: 6| Step: 12
Training loss: 0.7144903540611267
Validation loss: 2.21364027261734

Epoch: 6| Step: 13
Training loss: 0.4383944272994995
Validation loss: 2.2757073640823364

Epoch: 203| Step: 0
Training loss: 0.4852917194366455
Validation loss: 2.2314899961153665

Epoch: 6| Step: 1
Training loss: 0.351930171251297
Validation loss: 2.1669238209724426

Epoch: 6| Step: 2
Training loss: 0.5396497845649719
Validation loss: 2.200785219669342

Epoch: 6| Step: 3
Training loss: 0.6053277850151062
Validation loss: 2.1812148888905845

Epoch: 6| Step: 4
Training loss: 0.7849302291870117
Validation loss: 2.209920366605123

Epoch: 6| Step: 5
Training loss: 1.218871831893921
Validation loss: 2.2069957852363586

Epoch: 6| Step: 6
Training loss: 0.4072543978691101
Validation loss: 2.2132166822751365

Epoch: 6| Step: 7
Training loss: 0.4313213527202606
Validation loss: 2.233753979206085

Epoch: 6| Step: 8
Training loss: 0.6037704944610596
Validation loss: 2.241848349571228

Epoch: 6| Step: 9
Training loss: 0.7100626230239868
Validation loss: 2.2684871753056846

Epoch: 6| Step: 10
Training loss: 0.4955386519432068
Validation loss: 2.1911126573880515

Epoch: 6| Step: 11
Training loss: 0.3096579909324646
Validation loss: 2.1963497400283813

Epoch: 6| Step: 12
Training loss: 0.3992832601070404
Validation loss: 2.169956545035044

Epoch: 6| Step: 13
Training loss: 1.261817216873169
Validation loss: 2.218288799126943

Epoch: 204| Step: 0
Training loss: 0.22106851637363434
Validation loss: 2.221876859664917

Epoch: 6| Step: 1
Training loss: 0.5419697761535645
Validation loss: 2.208755830923716

Epoch: 6| Step: 2
Training loss: 0.5269409418106079
Validation loss: 2.166818936665853

Epoch: 6| Step: 3
Training loss: 0.3987792730331421
Validation loss: 2.218673268953959

Epoch: 6| Step: 4
Training loss: 0.45970118045806885
Validation loss: 2.2321058909098306

Epoch: 6| Step: 5
Training loss: 0.8896466493606567
Validation loss: 2.2285186052322388

Epoch: 6| Step: 6
Training loss: 0.8881024122238159
Validation loss: 2.2267274856567383

Epoch: 6| Step: 7
Training loss: 1.0175940990447998
Validation loss: 2.164625426133474

Epoch: 6| Step: 8
Training loss: 0.5101974606513977
Validation loss: 2.200092395146688

Epoch: 6| Step: 9
Training loss: 0.41008371114730835
Validation loss: 2.269090255101522

Epoch: 6| Step: 10
Training loss: 0.5871886014938354
Validation loss: 2.2141236066818237

Epoch: 6| Step: 11
Training loss: 0.6206623315811157
Validation loss: 2.1972418824831643

Epoch: 6| Step: 12
Training loss: 0.4455377161502838
Validation loss: 2.2087456385294595

Epoch: 6| Step: 13
Training loss: 0.39855730533599854
Validation loss: 2.221274435520172

Epoch: 205| Step: 0
Training loss: 0.6393645405769348
Validation loss: 2.221760888894399

Epoch: 6| Step: 1
Training loss: 0.7162572145462036
Validation loss: 2.229588806629181

Epoch: 6| Step: 2
Training loss: 0.6991218328475952
Validation loss: 2.2367051243782043

Epoch: 6| Step: 3
Training loss: 0.5060699582099915
Validation loss: 2.2386720379193625

Epoch: 6| Step: 4
Training loss: 0.45188266038894653
Validation loss: 2.2334794203440347

Epoch: 6| Step: 5
Training loss: 0.4848651885986328
Validation loss: 2.226468821366628

Epoch: 6| Step: 6
Training loss: 0.6846916079521179
Validation loss: 2.241634209950765

Epoch: 6| Step: 7
Training loss: 0.42561590671539307
Validation loss: 2.2297120889027915

Epoch: 6| Step: 8
Training loss: 0.2806771397590637
Validation loss: 2.237572987874349

Epoch: 6| Step: 9
Training loss: 1.1093124151229858
Validation loss: 2.2001912593841553

Epoch: 6| Step: 10
Training loss: 0.5015014410018921
Validation loss: 2.205651342868805

Epoch: 6| Step: 11
Training loss: 0.7515367269515991
Validation loss: 2.1812045176823935

Epoch: 6| Step: 12
Training loss: 0.748254656791687
Validation loss: 2.2743566632270813

Epoch: 6| Step: 13
Training loss: 0.970893919467926
Validation loss: 2.2271676460901895

Epoch: 206| Step: 0
Training loss: 0.8570843935012817
Validation loss: 2.2402928670247397

Epoch: 6| Step: 1
Training loss: 0.6763366460800171
Validation loss: 2.21495121717453

Epoch: 6| Step: 2
Training loss: 0.5964741706848145
Validation loss: 2.2538368105888367

Epoch: 6| Step: 3
Training loss: 0.36359888315200806
Validation loss: 2.2409579952557883

Epoch: 6| Step: 4
Training loss: 0.617118239402771
Validation loss: 2.262577792008718

Epoch: 6| Step: 5
Training loss: 0.4336429536342621
Validation loss: 2.206256071726481

Epoch: 6| Step: 6
Training loss: 0.5067898035049438
Validation loss: 2.2194971243540444

Epoch: 6| Step: 7
Training loss: 0.5155386924743652
Validation loss: 2.1998388369878135

Epoch: 6| Step: 8
Training loss: 0.5434105396270752
Validation loss: 2.1935633023579917

Epoch: 6| Step: 9
Training loss: 0.42185091972351074
Validation loss: 2.15291965007782

Epoch: 6| Step: 10
Training loss: 0.39289912581443787
Validation loss: 2.1614855925242105

Epoch: 6| Step: 11
Training loss: 1.028921127319336
Validation loss: 2.2387805779774985

Epoch: 6| Step: 12
Training loss: 0.6166394948959351
Validation loss: 2.1888529459635415

Epoch: 6| Step: 13
Training loss: 0.33494216203689575
Validation loss: 2.197042385737101

Epoch: 207| Step: 0
Training loss: 0.615780234336853
Validation loss: 2.2090546091397605

Epoch: 6| Step: 1
Training loss: 0.572657585144043
Validation loss: 2.2168369690577188

Epoch: 6| Step: 2
Training loss: 0.43984389305114746
Validation loss: 2.205786148707072

Epoch: 6| Step: 3
Training loss: 1.2478241920471191
Validation loss: 2.1824121276537576

Epoch: 6| Step: 4
Training loss: 0.42118099331855774
Validation loss: 2.19913911819458

Epoch: 6| Step: 5
Training loss: 0.7551506161689758
Validation loss: 2.1689745585123696

Epoch: 6| Step: 6
Training loss: 0.668113648891449
Validation loss: 2.2396175463994346

Epoch: 6| Step: 7
Training loss: 0.2817743718624115
Validation loss: 2.2043292125066123

Epoch: 6| Step: 8
Training loss: 0.43478065729141235
Validation loss: 2.2891281644503274

Epoch: 6| Step: 9
Training loss: 0.8749952912330627
Validation loss: 2.1956563790639243

Epoch: 6| Step: 10
Training loss: 0.4722267985343933
Validation loss: 2.300030986467997

Epoch: 6| Step: 11
Training loss: 0.1561061441898346
Validation loss: 2.1980575720469155

Epoch: 6| Step: 12
Training loss: 0.3453899025917053
Validation loss: 2.185539940992991

Epoch: 6| Step: 13
Training loss: 0.352070152759552
Validation loss: 2.138933996359507

Epoch: 208| Step: 0
Training loss: 0.7057023644447327
Validation loss: 2.245507001876831

Epoch: 6| Step: 1
Training loss: 0.507267951965332
Validation loss: 2.2112526893615723

Epoch: 6| Step: 2
Training loss: 0.39593809843063354
Validation loss: 2.158300499121348

Epoch: 6| Step: 3
Training loss: 1.0673761367797852
Validation loss: 2.2418463428815207

Epoch: 6| Step: 4
Training loss: 0.5032012462615967
Validation loss: 2.230509599049886

Epoch: 6| Step: 5
Training loss: 0.8336315751075745
Validation loss: 2.288583238919576

Epoch: 6| Step: 6
Training loss: 0.9302059412002563
Validation loss: 2.3104408780733743

Epoch: 6| Step: 7
Training loss: 0.4334595203399658
Validation loss: 2.2387945453325906

Epoch: 6| Step: 8
Training loss: 0.4582805633544922
Validation loss: 2.2884331941604614

Epoch: 6| Step: 9
Training loss: 0.4151867628097534
Validation loss: 2.227328916390737

Epoch: 6| Step: 10
Training loss: 0.6411892175674438
Validation loss: 2.212259372075399

Epoch: 6| Step: 11
Training loss: 0.49025776982307434
Validation loss: 2.2201239466667175

Epoch: 6| Step: 12
Training loss: 0.34217941761016846
Validation loss: 2.222823162873586

Epoch: 6| Step: 13
Training loss: 0.6601601839065552
Validation loss: 2.180107355117798

Epoch: 209| Step: 0
Training loss: 0.38693681359291077
Validation loss: 2.207274635632833

Epoch: 6| Step: 1
Training loss: 0.5947160124778748
Validation loss: 2.270763913790385

Epoch: 6| Step: 2
Training loss: 0.5460015535354614
Validation loss: 2.252147595087687

Epoch: 6| Step: 3
Training loss: 0.420443058013916
Validation loss: 2.2286142905553183

Epoch: 6| Step: 4
Training loss: 0.4595111608505249
Validation loss: 2.2501567602157593

Epoch: 6| Step: 5
Training loss: 0.48801273107528687
Validation loss: 2.2240421772003174

Epoch: 6| Step: 6
Training loss: 0.40898361802101135
Validation loss: 2.241249938805898

Epoch: 6| Step: 7
Training loss: 0.3310753107070923
Validation loss: 2.2407721877098083

Epoch: 6| Step: 8
Training loss: 0.7756202220916748
Validation loss: 2.240933060646057

Epoch: 6| Step: 9
Training loss: 0.4765070676803589
Validation loss: 2.1670836806297302

Epoch: 6| Step: 10
Training loss: 0.41025999188423157
Validation loss: 2.1818869511286416

Epoch: 6| Step: 11
Training loss: 0.4383735656738281
Validation loss: 2.232249140739441

Epoch: 6| Step: 12
Training loss: 1.0035102367401123
Validation loss: 2.2145939469337463

Epoch: 6| Step: 13
Training loss: 0.7800697088241577
Validation loss: 2.1923811038335166

Epoch: 210| Step: 0
Training loss: 0.8381640911102295
Validation loss: 2.1581822832425437

Epoch: 6| Step: 1
Training loss: 0.39271605014801025
Validation loss: 2.198808491230011

Epoch: 6| Step: 2
Training loss: 0.5994937419891357
Validation loss: 2.217778046925863

Epoch: 6| Step: 3
Training loss: 0.542335569858551
Validation loss: 2.1960631211598716

Epoch: 6| Step: 4
Training loss: 0.7400304079055786
Validation loss: 2.1966875195503235

Epoch: 6| Step: 5
Training loss: 0.46578294038772583
Validation loss: 2.2106208403905234

Epoch: 6| Step: 6
Training loss: 0.30417779088020325
Validation loss: 2.2063498894373574

Epoch: 6| Step: 7
Training loss: 0.5428484678268433
Validation loss: 2.230643391609192

Epoch: 6| Step: 8
Training loss: 0.7484955191612244
Validation loss: 2.167859216531118

Epoch: 6| Step: 9
Training loss: 0.39233291149139404
Validation loss: 2.1699498295783997

Epoch: 6| Step: 10
Training loss: 0.53228759765625
Validation loss: 2.1772053043047586

Epoch: 6| Step: 11
Training loss: 0.5015262961387634
Validation loss: 2.177330712477366

Epoch: 6| Step: 12
Training loss: 0.9402529001235962
Validation loss: 2.22009414434433

Epoch: 6| Step: 13
Training loss: 0.37613189220428467
Validation loss: 2.210245986779531

Epoch: 211| Step: 0
Training loss: 0.28425323963165283
Validation loss: 2.195282061894735

Epoch: 6| Step: 1
Training loss: 0.34035390615463257
Validation loss: 2.189397136370341

Epoch: 6| Step: 2
Training loss: 0.5779060125350952
Validation loss: 2.233143428961436

Epoch: 6| Step: 3
Training loss: 0.8530232310295105
Validation loss: 2.2115193208058677

Epoch: 6| Step: 4
Training loss: 0.3442581295967102
Validation loss: 2.2298631072044373

Epoch: 6| Step: 5
Training loss: 0.9012910723686218
Validation loss: 2.20125017563502

Epoch: 6| Step: 6
Training loss: 0.417650043964386
Validation loss: 2.2482754786809287

Epoch: 6| Step: 7
Training loss: 0.5002707242965698
Validation loss: 2.1889188090960183

Epoch: 6| Step: 8
Training loss: 0.9573853611946106
Validation loss: 2.2537647485733032

Epoch: 6| Step: 9
Training loss: 0.4897717535495758
Validation loss: 2.193439861138662

Epoch: 6| Step: 10
Training loss: 0.638579249382019
Validation loss: 2.219943861166636

Epoch: 6| Step: 11
Training loss: 0.5233349800109863
Validation loss: 2.1548256079355874

Epoch: 6| Step: 12
Training loss: 0.7443942427635193
Validation loss: 2.1998932162920632

Epoch: 6| Step: 13
Training loss: 0.473125696182251
Validation loss: 2.2486109733581543

Epoch: 212| Step: 0
Training loss: 0.6183123588562012
Validation loss: 2.2599070072174072

Epoch: 6| Step: 1
Training loss: 0.489425390958786
Validation loss: 2.220273574193319

Epoch: 6| Step: 2
Training loss: 0.5449433922767639
Validation loss: 2.198363959789276

Epoch: 6| Step: 3
Training loss: 0.7577139735221863
Validation loss: 2.186365524927775

Epoch: 6| Step: 4
Training loss: 0.6443676948547363
Validation loss: 2.205491383870443

Epoch: 6| Step: 5
Training loss: 0.7279740571975708
Validation loss: 2.223170598347982

Epoch: 6| Step: 6
Training loss: 0.360773503780365
Validation loss: 2.2662835915883384

Epoch: 6| Step: 7
Training loss: 0.6497166156768799
Validation loss: 2.257511337598165

Epoch: 6| Step: 8
Training loss: 0.3737822473049164
Validation loss: 2.260772466659546

Epoch: 6| Step: 9
Training loss: 0.3917522430419922
Validation loss: 2.232985496520996

Epoch: 6| Step: 10
Training loss: 0.3910064101219177
Validation loss: 2.227438191572825

Epoch: 6| Step: 11
Training loss: 0.5410230159759521
Validation loss: 2.2637175917625427

Epoch: 6| Step: 12
Training loss: 0.4067445397377014
Validation loss: 2.2214326659838357

Epoch: 6| Step: 13
Training loss: 0.6449602842330933
Validation loss: 2.182827870051066

Epoch: 213| Step: 0
Training loss: 0.6357218027114868
Validation loss: 2.216429352760315

Epoch: 6| Step: 1
Training loss: 0.3347562551498413
Validation loss: 2.2215484380722046

Epoch: 6| Step: 2
Training loss: 0.6304268836975098
Validation loss: 2.190531075000763

Epoch: 6| Step: 3
Training loss: 0.4934057295322418
Validation loss: 2.1927970250447593

Epoch: 6| Step: 4
Training loss: 0.38776683807373047
Validation loss: 2.1932816902796426

Epoch: 6| Step: 5
Training loss: 0.6542742848396301
Validation loss: 2.245663106441498

Epoch: 6| Step: 6
Training loss: 0.27278128266334534
Validation loss: 2.213866412639618

Epoch: 6| Step: 7
Training loss: 0.3866409659385681
Validation loss: 2.200027028719584

Epoch: 6| Step: 8
Training loss: 0.4731014370918274
Validation loss: 2.224035859107971

Epoch: 6| Step: 9
Training loss: 0.7771062850952148
Validation loss: 2.295685072739919

Epoch: 6| Step: 10
Training loss: 1.1718511581420898
Validation loss: 2.1874921719233194

Epoch: 6| Step: 11
Training loss: 0.4290691018104553
Validation loss: 2.220029135545095

Epoch: 6| Step: 12
Training loss: 0.3229403793811798
Validation loss: 2.2080605824788413

Epoch: 6| Step: 13
Training loss: 0.6768624186515808
Validation loss: 2.225438674290975

Epoch: 214| Step: 0
Training loss: 0.6282129287719727
Validation loss: 2.193874100844065

Epoch: 6| Step: 1
Training loss: 0.33443325757980347
Validation loss: 2.2132828632990518

Epoch: 6| Step: 2
Training loss: 0.5544047951698303
Validation loss: 2.2134488622347512

Epoch: 6| Step: 3
Training loss: 0.49666276574134827
Validation loss: 2.172967493534088

Epoch: 6| Step: 4
Training loss: 0.8942577838897705
Validation loss: 2.109711249669393

Epoch: 6| Step: 5
Training loss: 0.3775195777416229
Validation loss: 2.2036131819089255

Epoch: 6| Step: 6
Training loss: 0.1888650506734848
Validation loss: 2.2007259130477905

Epoch: 6| Step: 7
Training loss: 0.4929516613483429
Validation loss: 2.242940107981364

Epoch: 6| Step: 8
Training loss: 0.29081761837005615
Validation loss: 2.195304354031881

Epoch: 6| Step: 9
Training loss: 0.2884731888771057
Validation loss: 2.1910656293233237

Epoch: 6| Step: 10
Training loss: 0.4642361104488373
Validation loss: 2.1755330165227256

Epoch: 6| Step: 11
Training loss: 1.0199410915374756
Validation loss: 2.2310033241907754

Epoch: 6| Step: 12
Training loss: 0.6838874816894531
Validation loss: 2.161205450693766

Epoch: 6| Step: 13
Training loss: 0.7249256372451782
Validation loss: 2.2182239294052124

Epoch: 215| Step: 0
Training loss: 0.8377838134765625
Validation loss: 2.173846185207367

Epoch: 6| Step: 1
Training loss: 0.620366096496582
Validation loss: 2.229294260342916

Epoch: 6| Step: 2
Training loss: 0.28940269351005554
Validation loss: 2.2373709082603455

Epoch: 6| Step: 3
Training loss: 0.6379660367965698
Validation loss: 2.1724950273831687

Epoch: 6| Step: 4
Training loss: 0.24810530245304108
Validation loss: 2.2567187349001565

Epoch: 6| Step: 5
Training loss: 0.802497148513794
Validation loss: 2.196631073951721

Epoch: 6| Step: 6
Training loss: 0.4767601490020752
Validation loss: 2.18387238184611

Epoch: 6| Step: 7
Training loss: 0.5842747688293457
Validation loss: 2.179752826690674

Epoch: 6| Step: 8
Training loss: 0.6142193675041199
Validation loss: 2.203764796257019

Epoch: 6| Step: 9
Training loss: 0.39203447103500366
Validation loss: 2.2115448713302612

Epoch: 6| Step: 10
Training loss: 0.31542399525642395
Validation loss: 2.2329494953155518

Epoch: 6| Step: 11
Training loss: 0.44838717579841614
Validation loss: 2.197597642739614

Epoch: 6| Step: 12
Training loss: 0.663722038269043
Validation loss: 2.192070464293162

Epoch: 6| Step: 13
Training loss: 0.2887497544288635
Validation loss: 2.1826391220092773

Epoch: 216| Step: 0
Training loss: 0.8455032706260681
Validation loss: 2.209110756715139

Epoch: 6| Step: 1
Training loss: 0.4099321961402893
Validation loss: 2.2034462292989097

Epoch: 6| Step: 2
Training loss: 0.8320671319961548
Validation loss: 2.252613921960195

Epoch: 6| Step: 3
Training loss: 0.5980110764503479
Validation loss: 2.156127611796061

Epoch: 6| Step: 4
Training loss: 0.44247737526893616
Validation loss: 2.209109445412954

Epoch: 6| Step: 5
Training loss: 0.3524884581565857
Validation loss: 2.212786614894867

Epoch: 6| Step: 6
Training loss: 0.35194769501686096
Validation loss: 2.1754098931948342

Epoch: 6| Step: 7
Training loss: 0.6043553352355957
Validation loss: 2.1737074653307595

Epoch: 6| Step: 8
Training loss: 0.3394168019294739
Validation loss: 2.193211317062378

Epoch: 6| Step: 9
Training loss: 0.6539515256881714
Validation loss: 2.168274760246277

Epoch: 6| Step: 10
Training loss: 0.21740016341209412
Validation loss: 2.2008703351020813

Epoch: 6| Step: 11
Training loss: 0.7709498405456543
Validation loss: 2.2107930978139243

Epoch: 6| Step: 12
Training loss: 0.5585107803344727
Validation loss: 2.2586442033449807

Epoch: 6| Step: 13
Training loss: 0.7642875909805298
Validation loss: 2.186787406603495

Epoch: 217| Step: 0
Training loss: 0.5704882144927979
Validation loss: 2.1706028381983438

Epoch: 6| Step: 1
Training loss: 0.44101089239120483
Validation loss: 2.250163475672404

Epoch: 6| Step: 2
Training loss: 0.3833777904510498
Validation loss: 2.2814983129501343

Epoch: 6| Step: 3
Training loss: 0.42792099714279175
Validation loss: 2.1910883585611978

Epoch: 6| Step: 4
Training loss: 0.530896782875061
Validation loss: 2.2351253032684326

Epoch: 6| Step: 5
Training loss: 0.2458794116973877
Validation loss: 2.169114569822947

Epoch: 6| Step: 6
Training loss: 0.7078857421875
Validation loss: 2.2158981561660767

Epoch: 6| Step: 7
Training loss: 0.2892720103263855
Validation loss: 2.231534798940023

Epoch: 6| Step: 8
Training loss: 0.8362630605697632
Validation loss: 2.233516573905945

Epoch: 6| Step: 9
Training loss: 0.3558872938156128
Validation loss: 2.2691020170847573

Epoch: 6| Step: 10
Training loss: 0.71344393491745
Validation loss: 2.2220586935679116

Epoch: 6| Step: 11
Training loss: 0.437669038772583
Validation loss: 2.2116196354230246

Epoch: 6| Step: 12
Training loss: 0.8849292397499084
Validation loss: 2.3032421271006265

Epoch: 6| Step: 13
Training loss: 0.518587589263916
Validation loss: 2.2327113350232444

Epoch: 218| Step: 0
Training loss: 0.4378783404827118
Validation loss: 2.230812648932139

Epoch: 6| Step: 1
Training loss: 0.189214825630188
Validation loss: 2.2214834690093994

Epoch: 6| Step: 2
Training loss: 0.29551541805267334
Validation loss: 2.2207213640213013

Epoch: 6| Step: 3
Training loss: 0.6094890236854553
Validation loss: 2.2074928482373557

Epoch: 6| Step: 4
Training loss: 0.4912629723548889
Validation loss: 2.259178797403971

Epoch: 6| Step: 5
Training loss: 1.0178797245025635
Validation loss: 2.2651328444480896

Epoch: 6| Step: 6
Training loss: 0.42719390988349915
Validation loss: 2.23248561223348

Epoch: 6| Step: 7
Training loss: 0.605111837387085
Validation loss: 2.2612560192743936

Epoch: 6| Step: 8
Training loss: 0.2862390875816345
Validation loss: 2.1811244090398154

Epoch: 6| Step: 9
Training loss: 0.40566325187683105
Validation loss: 2.2355469266573587

Epoch: 6| Step: 10
Training loss: 0.5274653434753418
Validation loss: 2.1981946229934692

Epoch: 6| Step: 11
Training loss: 0.5249976515769958
Validation loss: 2.175892432530721

Epoch: 6| Step: 12
Training loss: 0.37438520789146423
Validation loss: 2.2227367162704468

Epoch: 6| Step: 13
Training loss: 1.0917377471923828
Validation loss: 2.184817453225454

Epoch: 219| Step: 0
Training loss: 1.0430811643600464
Validation loss: 2.244427502155304

Epoch: 6| Step: 1
Training loss: 0.45079052448272705
Validation loss: 2.2193506757418313

Epoch: 6| Step: 2
Training loss: 0.63578200340271
Validation loss: 2.2929189006487527

Epoch: 6| Step: 3
Training loss: 0.44310617446899414
Validation loss: 2.242534557978312

Epoch: 6| Step: 4
Training loss: 0.30921274423599243
Validation loss: 2.153812030951182

Epoch: 6| Step: 5
Training loss: 0.9194349646568298
Validation loss: 2.1848432421684265

Epoch: 6| Step: 6
Training loss: 0.6683549880981445
Validation loss: 2.2301882108052573

Epoch: 6| Step: 7
Training loss: 0.4977869987487793
Validation loss: 2.223686953385671

Epoch: 6| Step: 8
Training loss: 0.539416491985321
Validation loss: 2.170470396677653

Epoch: 6| Step: 9
Training loss: 0.32886677980422974
Validation loss: 2.2733335296312966

Epoch: 6| Step: 10
Training loss: 0.7569442391395569
Validation loss: 2.269422948360443

Epoch: 6| Step: 11
Training loss: 0.574466347694397
Validation loss: 2.2398491501808167

Epoch: 6| Step: 12
Training loss: 0.5712926983833313
Validation loss: 2.2466638882954917

Epoch: 6| Step: 13
Training loss: 0.8039351105690002
Validation loss: 2.2265972892443338

Epoch: 220| Step: 0
Training loss: 0.38315361738204956
Validation loss: 2.2453991373380027

Epoch: 6| Step: 1
Training loss: 0.6763006448745728
Validation loss: 2.2277562618255615

Epoch: 6| Step: 2
Training loss: 0.5232826471328735
Validation loss: 2.279239058494568

Epoch: 6| Step: 3
Training loss: 0.37221455574035645
Validation loss: 2.2552616000175476

Epoch: 6| Step: 4
Training loss: 0.8853896260261536
Validation loss: 2.1750198006629944

Epoch: 6| Step: 5
Training loss: 0.6637454628944397
Validation loss: 2.2162819504737854

Epoch: 6| Step: 6
Training loss: 0.38177254796028137
Validation loss: 2.185024321079254

Epoch: 6| Step: 7
Training loss: 0.43883776664733887
Validation loss: 2.2027170260747275

Epoch: 6| Step: 8
Training loss: 0.4264433681964874
Validation loss: 2.170066793759664

Epoch: 6| Step: 9
Training loss: 0.8010609149932861
Validation loss: 2.2613757054011026

Epoch: 6| Step: 10
Training loss: 0.5126155018806458
Validation loss: 2.238632162412008

Epoch: 6| Step: 11
Training loss: 0.25556761026382446
Validation loss: 2.226706842581431

Epoch: 6| Step: 12
Training loss: 0.7848668098449707
Validation loss: 2.2073944409688315

Epoch: 6| Step: 13
Training loss: 0.46427828073501587
Validation loss: 2.1748773654301963

Epoch: 221| Step: 0
Training loss: 0.523924708366394
Validation loss: 2.201955556869507

Epoch: 6| Step: 1
Training loss: 0.4567277729511261
Validation loss: 2.153108994166056

Epoch: 6| Step: 2
Training loss: 0.4195253551006317
Validation loss: 2.198700428009033

Epoch: 6| Step: 3
Training loss: 0.6701204776763916
Validation loss: 2.1752756436665854

Epoch: 6| Step: 4
Training loss: 0.2805103659629822
Validation loss: 2.163371443748474

Epoch: 6| Step: 5
Training loss: 0.2423214167356491
Validation loss: 2.245861073335012

Epoch: 6| Step: 6
Training loss: 0.5069406032562256
Validation loss: 2.1720471580823264

Epoch: 6| Step: 7
Training loss: 0.5565073490142822
Validation loss: 2.219790816307068

Epoch: 6| Step: 8
Training loss: 0.6479302644729614
Validation loss: 2.180084307988485

Epoch: 6| Step: 9
Training loss: 0.7411421537399292
Validation loss: 2.2338799635569253

Epoch: 6| Step: 10
Training loss: 0.29951217770576477
Validation loss: 2.2059457898139954

Epoch: 6| Step: 11
Training loss: 0.32649949193000793
Validation loss: 2.2065308888753257

Epoch: 6| Step: 12
Training loss: 0.9410457015037537
Validation loss: 2.258608361085256

Epoch: 6| Step: 13
Training loss: 0.3819817006587982
Validation loss: 2.173196574052175

Epoch: 222| Step: 0
Training loss: 0.8473058342933655
Validation loss: 2.214284678300222

Epoch: 6| Step: 1
Training loss: 0.19614441692829132
Validation loss: 2.161247730255127

Epoch: 6| Step: 2
Training loss: 0.505587100982666
Validation loss: 2.2380046248435974

Epoch: 6| Step: 3
Training loss: 0.34544050693511963
Validation loss: 2.2199516892433167

Epoch: 6| Step: 4
Training loss: 0.5813185572624207
Validation loss: 2.209218144416809

Epoch: 6| Step: 5
Training loss: 0.38797080516815186
Validation loss: 2.2100592255592346

Epoch: 6| Step: 6
Training loss: 0.39312440156936646
Validation loss: 2.222797075907389

Epoch: 6| Step: 7
Training loss: 0.8984890580177307
Validation loss: 2.2137802243232727

Epoch: 6| Step: 8
Training loss: 0.29600948095321655
Validation loss: 2.202281673749288

Epoch: 6| Step: 9
Training loss: 0.6918062567710876
Validation loss: 2.2134276628494263

Epoch: 6| Step: 10
Training loss: 0.48961201310157776
Validation loss: 2.1887508034706116

Epoch: 6| Step: 11
Training loss: 0.4053080081939697
Validation loss: 2.2166154980659485

Epoch: 6| Step: 12
Training loss: 0.3634662926197052
Validation loss: 2.205928603808085

Epoch: 6| Step: 13
Training loss: 0.6524440050125122
Validation loss: 2.166090269883474

Epoch: 223| Step: 0
Training loss: 0.36281388998031616
Validation loss: 2.235398789246877

Epoch: 6| Step: 1
Training loss: 0.33484387397766113
Validation loss: 2.2159662445386252

Epoch: 6| Step: 2
Training loss: 0.9804419279098511
Validation loss: 2.235114018122355

Epoch: 6| Step: 3
Training loss: 0.48236382007598877
Validation loss: 2.1752023100852966

Epoch: 6| Step: 4
Training loss: 0.700239360332489
Validation loss: 2.1862793366114297

Epoch: 6| Step: 5
Training loss: 0.2340553104877472
Validation loss: 2.2797199885050454

Epoch: 6| Step: 6
Training loss: 0.44724375009536743
Validation loss: 2.2502414186795554

Epoch: 6| Step: 7
Training loss: 0.4302818477153778
Validation loss: 2.221316476662954

Epoch: 6| Step: 8
Training loss: 0.7221506834030151
Validation loss: 2.2395801544189453

Epoch: 6| Step: 9
Training loss: 0.40132084488868713
Validation loss: 2.184786001841227

Epoch: 6| Step: 10
Training loss: 0.35457712411880493
Validation loss: 2.181063175201416

Epoch: 6| Step: 11
Training loss: 0.44650089740753174
Validation loss: 2.2168880303700766

Epoch: 6| Step: 12
Training loss: 0.6682641506195068
Validation loss: 2.225211282571157

Epoch: 6| Step: 13
Training loss: 0.2984260022640228
Validation loss: 2.2169304291407266

Epoch: 224| Step: 0
Training loss: 0.40916872024536133
Validation loss: 2.2256093422571817

Epoch: 6| Step: 1
Training loss: 0.8992022275924683
Validation loss: 2.2242642641067505

Epoch: 6| Step: 2
Training loss: 0.9010384678840637
Validation loss: 2.2365775903066

Epoch: 6| Step: 3
Training loss: 0.5056352019309998
Validation loss: 2.2616538802782693

Epoch: 6| Step: 4
Training loss: 0.28547775745391846
Validation loss: 2.312132259209951

Epoch: 6| Step: 5
Training loss: 0.7621656656265259
Validation loss: 2.280030290285746

Epoch: 6| Step: 6
Training loss: 0.6145877838134766
Validation loss: 2.2648756305376687

Epoch: 6| Step: 7
Training loss: 0.4142383337020874
Validation loss: 2.2619175910949707

Epoch: 6| Step: 8
Training loss: 0.7046682834625244
Validation loss: 2.2574578722318015

Epoch: 6| Step: 9
Training loss: 0.6033917665481567
Validation loss: 2.1887144843737283

Epoch: 6| Step: 10
Training loss: 0.315204918384552
Validation loss: 2.2122092644373574

Epoch: 6| Step: 11
Training loss: 0.3773837685585022
Validation loss: 2.2313230435053506

Epoch: 6| Step: 12
Training loss: 0.4364801049232483
Validation loss: 2.2261248429616294

Epoch: 6| Step: 13
Training loss: 0.5126312375068665
Validation loss: 2.243872046470642

Epoch: 225| Step: 0
Training loss: 0.2266640067100525
Validation loss: 2.1839100122451782

Epoch: 6| Step: 1
Training loss: 0.4041174650192261
Validation loss: 2.2428691387176514

Epoch: 6| Step: 2
Training loss: 0.45503440499305725
Validation loss: 2.2311334212621055

Epoch: 6| Step: 3
Training loss: 0.5289583206176758
Validation loss: 2.2303011218706765

Epoch: 6| Step: 4
Training loss: 0.7590363025665283
Validation loss: 2.1611711780230203

Epoch: 6| Step: 5
Training loss: 0.24505318701267242
Validation loss: 2.212775468826294

Epoch: 6| Step: 6
Training loss: 0.518406331539154
Validation loss: 2.246535360813141

Epoch: 6| Step: 7
Training loss: 0.47590088844299316
Validation loss: 2.2056037982304892

Epoch: 6| Step: 8
Training loss: 0.46408870816230774
Validation loss: 2.2092041969299316

Epoch: 6| Step: 9
Training loss: 0.45618242025375366
Validation loss: 2.2205451925595603

Epoch: 6| Step: 10
Training loss: 1.0235955715179443
Validation loss: 2.2171111504236856

Epoch: 6| Step: 11
Training loss: 0.4910987913608551
Validation loss: 2.285360892613729

Epoch: 6| Step: 12
Training loss: 0.9407607316970825
Validation loss: 2.281028171380361

Epoch: 6| Step: 13
Training loss: 0.40519630908966064
Validation loss: 2.2921069065729776

Epoch: 226| Step: 0
Training loss: 0.5578818321228027
Validation loss: 2.2199761470158896

Epoch: 6| Step: 1
Training loss: 0.3435063064098358
Validation loss: 2.19259121020635

Epoch: 6| Step: 2
Training loss: 0.5836255550384521
Validation loss: 2.2206546465555825

Epoch: 6| Step: 3
Training loss: 0.6178507208824158
Validation loss: 2.2294563253720603

Epoch: 6| Step: 4
Training loss: 1.2706273794174194
Validation loss: 2.243658800919851

Epoch: 6| Step: 5
Training loss: 1.2475521564483643
Validation loss: 2.328572988510132

Epoch: 6| Step: 6
Training loss: 0.4753250479698181
Validation loss: 2.1986512343088784

Epoch: 6| Step: 7
Training loss: 0.3669779598712921
Validation loss: 2.2105209628740945

Epoch: 6| Step: 8
Training loss: 0.5312478542327881
Validation loss: 2.248530387878418

Epoch: 6| Step: 9
Training loss: 0.5131568312644958
Validation loss: 2.28608109553655

Epoch: 6| Step: 10
Training loss: 0.4670984447002411
Validation loss: 2.2425885995229087

Epoch: 6| Step: 11
Training loss: 0.36562392115592957
Validation loss: 2.2804576754570007

Epoch: 6| Step: 12
Training loss: 0.5629809498786926
Validation loss: 2.2436997095743814

Epoch: 6| Step: 13
Training loss: 0.35725414752960205
Validation loss: 2.2335656881332397

Epoch: 227| Step: 0
Training loss: 0.629319429397583
Validation loss: 2.213473081588745

Epoch: 6| Step: 1
Training loss: 0.28797799348831177
Validation loss: 2.2662247816721597

Epoch: 6| Step: 2
Training loss: 0.45732828974723816
Validation loss: 2.2016294399897256

Epoch: 6| Step: 3
Training loss: 0.3599575161933899
Validation loss: 2.148134966691335

Epoch: 6| Step: 4
Training loss: 0.5121259689331055
Validation loss: 2.1413597464561462

Epoch: 6| Step: 5
Training loss: 0.586965024471283
Validation loss: 2.2854347030321756

Epoch: 6| Step: 6
Training loss: 0.42888474464416504
Validation loss: 2.227682908376058

Epoch: 6| Step: 7
Training loss: 0.23951126635074615
Validation loss: 2.164379119873047

Epoch: 6| Step: 8
Training loss: 0.489670068025589
Validation loss: 2.2099010149637857

Epoch: 6| Step: 9
Training loss: 0.5476530194282532
Validation loss: 2.184260586897532

Epoch: 6| Step: 10
Training loss: 1.1337921619415283
Validation loss: 2.1820944348971048

Epoch: 6| Step: 11
Training loss: 0.8229467868804932
Validation loss: 2.1956775387128196

Epoch: 6| Step: 12
Training loss: 0.4369034171104431
Validation loss: 2.1834439039230347

Epoch: 6| Step: 13
Training loss: 0.16462454199790955
Validation loss: 2.144771456718445

Epoch: 228| Step: 0
Training loss: 0.49177777767181396
Validation loss: 2.1823611855506897

Epoch: 6| Step: 1
Training loss: 0.8184802532196045
Validation loss: 2.2208838065465293

Epoch: 6| Step: 2
Training loss: 0.7062962055206299
Validation loss: 2.2703977823257446

Epoch: 6| Step: 3
Training loss: 0.5310797691345215
Validation loss: 2.2592589060465493

Epoch: 6| Step: 4
Training loss: 0.4859161376953125
Validation loss: 2.233078956604004

Epoch: 6| Step: 5
Training loss: 0.31781113147735596
Validation loss: 2.1782286564509072

Epoch: 6| Step: 6
Training loss: 0.4240083396434784
Validation loss: 2.217793802420298

Epoch: 6| Step: 7
Training loss: 0.7084112167358398
Validation loss: 2.197522759437561

Epoch: 6| Step: 8
Training loss: 0.48724961280822754
Validation loss: 2.202851335207621

Epoch: 6| Step: 9
Training loss: 0.3198321759700775
Validation loss: 2.249661366144816

Epoch: 6| Step: 10
Training loss: 0.34483325481414795
Validation loss: 2.2609888911247253

Epoch: 6| Step: 11
Training loss: 0.25457996129989624
Validation loss: 2.2336387634277344

Epoch: 6| Step: 12
Training loss: 0.48111534118652344
Validation loss: 2.1679062843322754

Epoch: 6| Step: 13
Training loss: 0.8282119035720825
Validation loss: 2.160770376523336

Epoch: 229| Step: 0
Training loss: 0.3247227966785431
Validation loss: 2.2506863276163735

Epoch: 6| Step: 1
Training loss: 0.4618866443634033
Validation loss: 2.225224753220876

Epoch: 6| Step: 2
Training loss: 0.31675103306770325
Validation loss: 2.198237737019857

Epoch: 6| Step: 3
Training loss: 0.43702471256256104
Validation loss: 2.2132873137791953

Epoch: 6| Step: 4
Training loss: 0.49574142694473267
Validation loss: 2.2338902155558267

Epoch: 6| Step: 5
Training loss: 0.286681592464447
Validation loss: 2.22989821434021

Epoch: 6| Step: 6
Training loss: 0.3429790735244751
Validation loss: 2.2211684584617615

Epoch: 6| Step: 7
Training loss: 0.26493680477142334
Validation loss: 2.244469920794169

Epoch: 6| Step: 8
Training loss: 0.904972493648529
Validation loss: 2.2308505376180015

Epoch: 6| Step: 9
Training loss: 0.3824411928653717
Validation loss: 2.180808146794637

Epoch: 6| Step: 10
Training loss: 0.4420502185821533
Validation loss: 2.2148133516311646

Epoch: 6| Step: 11
Training loss: 0.5493494868278503
Validation loss: 2.2228740056355796

Epoch: 6| Step: 12
Training loss: 0.49537816643714905
Validation loss: 2.192465901374817

Epoch: 6| Step: 13
Training loss: 0.860007643699646
Validation loss: 2.1949350833892822

Epoch: 230| Step: 0
Training loss: 0.3861162066459656
Validation loss: 2.181298812230428

Epoch: 6| Step: 1
Training loss: 0.40144941210746765
Validation loss: 2.214889407157898

Epoch: 6| Step: 2
Training loss: 0.8092485666275024
Validation loss: 2.2253825465838113

Epoch: 6| Step: 3
Training loss: 1.0722392797470093
Validation loss: 2.241021712621053

Epoch: 6| Step: 4
Training loss: 0.7454873919487
Validation loss: 2.2016642491022744

Epoch: 6| Step: 5
Training loss: 0.3251323997974396
Validation loss: 2.1627958019574485

Epoch: 6| Step: 6
Training loss: 0.4759681224822998
Validation loss: 2.2124417225519815

Epoch: 6| Step: 7
Training loss: 0.6445009708404541
Validation loss: 2.2629173199335733

Epoch: 6| Step: 8
Training loss: 0.45217165350914
Validation loss: 2.239834984143575

Epoch: 6| Step: 9
Training loss: 0.34818923473358154
Validation loss: 2.2606868545214334

Epoch: 6| Step: 10
Training loss: 0.4189957082271576
Validation loss: 2.211337447166443

Epoch: 6| Step: 11
Training loss: 0.3146955370903015
Validation loss: 2.1895548899968467

Epoch: 6| Step: 12
Training loss: 0.5917627811431885
Validation loss: 2.2402448256810508

Epoch: 6| Step: 13
Training loss: 0.33657288551330566
Validation loss: 2.263421336809794

Epoch: 231| Step: 0
Training loss: 0.35632461309432983
Validation loss: 2.2128211657206216

Epoch: 6| Step: 1
Training loss: 0.498799204826355
Validation loss: 2.184725801150004

Epoch: 6| Step: 2
Training loss: 0.5185974836349487
Validation loss: 2.229865332444509

Epoch: 6| Step: 3
Training loss: 0.2168310582637787
Validation loss: 2.208672523498535

Epoch: 6| Step: 4
Training loss: 0.4372011125087738
Validation loss: 2.2223934332529702

Epoch: 6| Step: 5
Training loss: 0.44765645265579224
Validation loss: 2.2221697171529136

Epoch: 6| Step: 6
Training loss: 0.42302870750427246
Validation loss: 2.223039984703064

Epoch: 6| Step: 7
Training loss: 0.5186954140663147
Validation loss: 2.2496517499287925

Epoch: 6| Step: 8
Training loss: 0.42727774381637573
Validation loss: 2.2002012133598328

Epoch: 6| Step: 9
Training loss: 0.8356519937515259
Validation loss: 2.2303191224733987

Epoch: 6| Step: 10
Training loss: 0.8665149807929993
Validation loss: 2.2059474984804788

Epoch: 6| Step: 11
Training loss: 0.672683596611023
Validation loss: 2.209310074647268

Epoch: 6| Step: 12
Training loss: 0.363778293132782
Validation loss: 2.241985638936361

Epoch: 6| Step: 13
Training loss: 0.8460642695426941
Validation loss: 2.2165512243906655

Epoch: 232| Step: 0
Training loss: 0.3791492283344269
Validation loss: 2.161227603753408

Epoch: 6| Step: 1
Training loss: 0.8505365252494812
Validation loss: 2.2540486057599387

Epoch: 6| Step: 2
Training loss: 0.5781660676002502
Validation loss: 2.215238332748413

Epoch: 6| Step: 3
Training loss: 0.49112460017204285
Validation loss: 2.2374810377756753

Epoch: 6| Step: 4
Training loss: 0.465532124042511
Validation loss: 2.216560701529185

Epoch: 6| Step: 5
Training loss: 0.4208545982837677
Validation loss: 2.2074589927991233

Epoch: 6| Step: 6
Training loss: 0.1963028609752655
Validation loss: 2.2349199453989663

Epoch: 6| Step: 7
Training loss: 0.28311216831207275
Validation loss: 2.1729999780654907

Epoch: 6| Step: 8
Training loss: 0.4517315924167633
Validation loss: 2.182287116845449

Epoch: 6| Step: 9
Training loss: 0.5398404598236084
Validation loss: 2.205477515856425

Epoch: 6| Step: 10
Training loss: 0.27861732244491577
Validation loss: 2.183996935685476

Epoch: 6| Step: 11
Training loss: 0.6259036064147949
Validation loss: 2.235389252503713

Epoch: 6| Step: 12
Training loss: 0.3883148729801178
Validation loss: 2.2121428847312927

Epoch: 6| Step: 13
Training loss: 0.8373420834541321
Validation loss: 2.1907883683840432

Epoch: 233| Step: 0
Training loss: 0.3450213372707367
Validation loss: 2.1971251567204795

Epoch: 6| Step: 1
Training loss: 0.4019101560115814
Validation loss: 2.1948313315709433

Epoch: 6| Step: 2
Training loss: 0.37471872568130493
Validation loss: 2.2174547712008157

Epoch: 6| Step: 3
Training loss: 0.5312210321426392
Validation loss: 2.2082971334457397

Epoch: 6| Step: 4
Training loss: 0.6050629615783691
Validation loss: 2.265391985575358

Epoch: 6| Step: 5
Training loss: 0.4239637553691864
Validation loss: 2.216649909814199

Epoch: 6| Step: 6
Training loss: 0.4601120948791504
Validation loss: 2.207278331120809

Epoch: 6| Step: 7
Training loss: 0.4514462947845459
Validation loss: 2.255083600680033

Epoch: 6| Step: 8
Training loss: 0.8132175803184509
Validation loss: 2.2045798699061074

Epoch: 6| Step: 9
Training loss: 0.7419003248214722
Validation loss: 2.2310481866200766

Epoch: 6| Step: 10
Training loss: 0.41234689950942993
Validation loss: 2.188476284344991

Epoch: 6| Step: 11
Training loss: 0.3365980386734009
Validation loss: 2.1947282950083413

Epoch: 6| Step: 12
Training loss: 0.2303285151720047
Validation loss: 2.2153127193450928

Epoch: 6| Step: 13
Training loss: 0.30141472816467285
Validation loss: 2.125140964984894

Epoch: 234| Step: 0
Training loss: 0.6095167398452759
Validation loss: 2.2391132513682046

Epoch: 6| Step: 1
Training loss: 0.7691270112991333
Validation loss: 2.1941019892692566

Epoch: 6| Step: 2
Training loss: 0.48288992047309875
Validation loss: 2.2133501370747886

Epoch: 6| Step: 3
Training loss: 0.3410325348377228
Validation loss: 2.1718518336613974

Epoch: 6| Step: 4
Training loss: 0.3547098636627197
Validation loss: 2.2315987944602966

Epoch: 6| Step: 5
Training loss: 0.5388961434364319
Validation loss: 2.231963892777761

Epoch: 6| Step: 6
Training loss: 0.3404742479324341
Validation loss: 2.220131536324819

Epoch: 6| Step: 7
Training loss: 0.3648606240749359
Validation loss: 2.194223165512085

Epoch: 6| Step: 8
Training loss: 0.5247488021850586
Validation loss: 2.146580914656321

Epoch: 6| Step: 9
Training loss: 0.343342125415802
Validation loss: 2.2581380208333335

Epoch: 6| Step: 10
Training loss: 0.5769897699356079
Validation loss: 2.1787052154541016

Epoch: 6| Step: 11
Training loss: 0.27120283246040344
Validation loss: 2.2105929255485535

Epoch: 6| Step: 12
Training loss: 0.39029890298843384
Validation loss: 2.2176218827565513

Epoch: 6| Step: 13
Training loss: 0.7696890830993652
Validation loss: 2.195937156677246

Epoch: 235| Step: 0
Training loss: 0.63334059715271
Validation loss: 2.1847333908081055

Epoch: 6| Step: 1
Training loss: 0.5398612022399902
Validation loss: 2.193698604901632

Epoch: 6| Step: 2
Training loss: 0.4199264943599701
Validation loss: 2.2079192996025085

Epoch: 6| Step: 3
Training loss: 0.7416940927505493
Validation loss: 2.1877519488334656

Epoch: 6| Step: 4
Training loss: 0.36309707164764404
Validation loss: 2.216402014096578

Epoch: 6| Step: 5
Training loss: 0.4880006015300751
Validation loss: 2.2068743308385215

Epoch: 6| Step: 6
Training loss: 0.6186423301696777
Validation loss: 2.2431824604670205

Epoch: 6| Step: 7
Training loss: 0.5888697504997253
Validation loss: 2.266349732875824

Epoch: 6| Step: 8
Training loss: 0.48271000385284424
Validation loss: 2.260306159655253

Epoch: 6| Step: 9
Training loss: 0.5162888765335083
Validation loss: 2.197082002957662

Epoch: 6| Step: 10
Training loss: 0.2615779936313629
Validation loss: 2.1926711400349936

Epoch: 6| Step: 11
Training loss: 0.3828209340572357
Validation loss: 2.208993355433146

Epoch: 6| Step: 12
Training loss: 0.4215041995048523
Validation loss: 2.2225880225499473

Epoch: 6| Step: 13
Training loss: 0.5511208176612854
Validation loss: 2.236452559630076

Epoch: 236| Step: 0
Training loss: 0.292182981967926
Validation loss: 2.2221651871999106

Epoch: 6| Step: 1
Training loss: 0.3634904623031616
Validation loss: 2.283212145169576

Epoch: 6| Step: 2
Training loss: 0.4243452847003937
Validation loss: 2.3002207279205322

Epoch: 6| Step: 3
Training loss: 0.9939340353012085
Validation loss: 2.2851099173227944

Epoch: 6| Step: 4
Training loss: 0.5658021569252014
Validation loss: 2.2086119651794434

Epoch: 6| Step: 5
Training loss: 0.6977550983428955
Validation loss: 2.2451988061269126

Epoch: 6| Step: 6
Training loss: 0.5926920175552368
Validation loss: 2.2229573925336203

Epoch: 6| Step: 7
Training loss: 0.29805928468704224
Validation loss: 2.2210246324539185

Epoch: 6| Step: 8
Training loss: 0.38752055168151855
Validation loss: 2.2140936851501465

Epoch: 6| Step: 9
Training loss: 0.3754265308380127
Validation loss: 2.199460804462433

Epoch: 6| Step: 10
Training loss: 0.6087306141853333
Validation loss: 2.23741481701533

Epoch: 6| Step: 11
Training loss: 0.42641836404800415
Validation loss: 2.2057241400082908

Epoch: 6| Step: 12
Training loss: 0.30915188789367676
Validation loss: 2.2682220935821533

Epoch: 6| Step: 13
Training loss: 0.6176062226295471
Validation loss: 2.221911350886027

Epoch: 237| Step: 0
Training loss: 0.7188911437988281
Validation loss: 2.237546682357788

Epoch: 6| Step: 1
Training loss: 0.3530580401420593
Validation loss: 2.246721168359121

Epoch: 6| Step: 2
Training loss: 0.42683786153793335
Validation loss: 2.2218748331069946

Epoch: 6| Step: 3
Training loss: 0.3896152377128601
Validation loss: 2.2586550116539

Epoch: 6| Step: 4
Training loss: 0.3087571859359741
Validation loss: 2.2667284409205117

Epoch: 6| Step: 5
Training loss: 0.7746478319168091
Validation loss: 2.2530547181765237

Epoch: 6| Step: 6
Training loss: 0.23507866263389587
Validation loss: 2.203976492087046

Epoch: 6| Step: 7
Training loss: 0.5260902643203735
Validation loss: 2.223451097806295

Epoch: 6| Step: 8
Training loss: 0.454580694437027
Validation loss: 2.1936545372009277

Epoch: 6| Step: 9
Training loss: 0.19232098758220673
Validation loss: 2.264792819817861

Epoch: 6| Step: 10
Training loss: 0.6894680857658386
Validation loss: 2.1860501368840537

Epoch: 6| Step: 11
Training loss: 0.6150286197662354
Validation loss: 2.255579650402069

Epoch: 6| Step: 12
Training loss: 0.2395542860031128
Validation loss: 2.216306487719218

Epoch: 6| Step: 13
Training loss: 0.5375120043754578
Validation loss: 2.2147765159606934

Epoch: 238| Step: 0
Training loss: 0.3347691595554352
Validation loss: 2.2014353473981223

Epoch: 6| Step: 1
Training loss: 0.31295159459114075
Validation loss: 2.230005125204722

Epoch: 6| Step: 2
Training loss: 0.45809608697891235
Validation loss: 2.1593452095985413

Epoch: 6| Step: 3
Training loss: 0.32456862926483154
Validation loss: 2.2229599555333457

Epoch: 6| Step: 4
Training loss: 0.4253738224506378
Validation loss: 2.197569787502289

Epoch: 6| Step: 5
Training loss: 1.106971025466919
Validation loss: 2.158725837866465

Epoch: 6| Step: 6
Training loss: 0.3744611144065857
Validation loss: 2.1820953289667764

Epoch: 6| Step: 7
Training loss: 0.4351324141025543
Validation loss: 2.208802064259847

Epoch: 6| Step: 8
Training loss: 0.4284436106681824
Validation loss: 2.1854964097340903

Epoch: 6| Step: 9
Training loss: 0.6649072766304016
Validation loss: 2.213430325190226

Epoch: 6| Step: 10
Training loss: 0.5621951818466187
Validation loss: 2.1986761490503945

Epoch: 6| Step: 11
Training loss: 0.4570356011390686
Validation loss: 2.208650449911753

Epoch: 6| Step: 12
Training loss: 0.30975624918937683
Validation loss: 2.2214752237002053

Epoch: 6| Step: 13
Training loss: 0.48499658703804016
Validation loss: 2.2118523518244424

Epoch: 239| Step: 0
Training loss: 0.5108187198638916
Validation loss: 2.200798988342285

Epoch: 6| Step: 1
Training loss: 0.6388005614280701
Validation loss: 2.169544816017151

Epoch: 6| Step: 2
Training loss: 0.36654162406921387
Validation loss: 2.174913505713145

Epoch: 6| Step: 3
Training loss: 0.49172449111938477
Validation loss: 2.199841777483622

Epoch: 6| Step: 4
Training loss: 0.2646646499633789
Validation loss: 2.180721879005432

Epoch: 6| Step: 5
Training loss: 0.23728761076927185
Validation loss: 2.214946985244751

Epoch: 6| Step: 6
Training loss: 0.5466079711914062
Validation loss: 2.2398868004480996

Epoch: 6| Step: 7
Training loss: 0.5146487355232239
Validation loss: 2.2218656738599143

Epoch: 6| Step: 8
Training loss: 0.49450573325157166
Validation loss: 2.218311389287313

Epoch: 6| Step: 9
Training loss: 0.35660243034362793
Validation loss: 2.2292862931887307

Epoch: 6| Step: 10
Training loss: 0.6947590112686157
Validation loss: 2.177023688952128

Epoch: 6| Step: 11
Training loss: 0.39217638969421387
Validation loss: 2.224705715974172

Epoch: 6| Step: 12
Training loss: 0.3710072338581085
Validation loss: 2.182642161846161

Epoch: 6| Step: 13
Training loss: 0.7732822299003601
Validation loss: 2.1749581495920816

Epoch: 240| Step: 0
Training loss: 0.5911655426025391
Validation loss: 2.1828248103459678

Epoch: 6| Step: 1
Training loss: 0.5877257585525513
Validation loss: 2.2014304200808206

Epoch: 6| Step: 2
Training loss: 0.5691108107566833
Validation loss: 2.202411631743113

Epoch: 6| Step: 3
Training loss: 0.4152880609035492
Validation loss: 2.241815368334452

Epoch: 6| Step: 4
Training loss: 0.5001699328422546
Validation loss: 2.1904216210047402

Epoch: 6| Step: 5
Training loss: 0.4857982397079468
Validation loss: 2.209597567717234

Epoch: 6| Step: 6
Training loss: 0.7737023830413818
Validation loss: 2.23635866244634

Epoch: 6| Step: 7
Training loss: 0.6073709726333618
Validation loss: 2.1896092693010965

Epoch: 6| Step: 8
Training loss: 0.7729330062866211
Validation loss: 2.209834893544515

Epoch: 6| Step: 9
Training loss: 0.23656143248081207
Validation loss: 2.218759755293528

Epoch: 6| Step: 10
Training loss: 0.3627423644065857
Validation loss: 2.2076324423154197

Epoch: 6| Step: 11
Training loss: 0.24442903697490692
Validation loss: 2.2278665900230408

Epoch: 6| Step: 12
Training loss: 0.3504972457885742
Validation loss: 2.2081485589345298

Epoch: 6| Step: 13
Training loss: 0.6056186556816101
Validation loss: 2.229387958844503

Epoch: 241| Step: 0
Training loss: 0.9015281200408936
Validation loss: 2.2017346620559692

Epoch: 6| Step: 1
Training loss: 0.25051242113113403
Validation loss: 2.211272438367208

Epoch: 6| Step: 2
Training loss: 0.623755693435669
Validation loss: 2.2647517124811807

Epoch: 6| Step: 3
Training loss: 0.3240106999874115
Validation loss: 2.189042091369629

Epoch: 6| Step: 4
Training loss: 0.22992336750030518
Validation loss: 2.201645791530609

Epoch: 6| Step: 5
Training loss: 0.4546733796596527
Validation loss: 2.262244462966919

Epoch: 6| Step: 6
Training loss: 0.4995253384113312
Validation loss: 2.16149373849233

Epoch: 6| Step: 7
Training loss: 0.47220802307128906
Validation loss: 2.234583616256714

Epoch: 6| Step: 8
Training loss: 0.25107434391975403
Validation loss: 2.198573132356008

Epoch: 6| Step: 9
Training loss: 0.46227791905403137
Validation loss: 2.1772947708765664

Epoch: 6| Step: 10
Training loss: 0.610235333442688
Validation loss: 2.244179685910543

Epoch: 6| Step: 11
Training loss: 0.22850236296653748
Validation loss: 2.233137925465902

Epoch: 6| Step: 12
Training loss: 0.4433653950691223
Validation loss: 2.2176986932754517

Epoch: 6| Step: 13
Training loss: 0.6135892868041992
Validation loss: 2.2619388699531555

Epoch: 242| Step: 0
Training loss: 0.8554797172546387
Validation loss: 2.217044234275818

Epoch: 6| Step: 1
Training loss: 0.6602675914764404
Validation loss: 2.234272519747416

Epoch: 6| Step: 2
Training loss: 0.4913445711135864
Validation loss: 2.221481998761495

Epoch: 6| Step: 3
Training loss: 0.8778327107429504
Validation loss: 2.221650222937266

Epoch: 6| Step: 4
Training loss: 0.4220704138278961
Validation loss: 2.2204861442248025

Epoch: 6| Step: 5
Training loss: 0.5380343794822693
Validation loss: 2.2195425828297934

Epoch: 6| Step: 6
Training loss: 0.27655577659606934
Validation loss: 2.2188544273376465

Epoch: 6| Step: 7
Training loss: 0.31191253662109375
Validation loss: 2.2168493270874023

Epoch: 6| Step: 8
Training loss: 0.5518714189529419
Validation loss: 2.1659550865491233

Epoch: 6| Step: 9
Training loss: 0.3764941096305847
Validation loss: 2.226653436819712

Epoch: 6| Step: 10
Training loss: 0.3548387289047241
Validation loss: 2.2179076274236045

Epoch: 6| Step: 11
Training loss: 0.6303682327270508
Validation loss: 2.218395491441091

Epoch: 6| Step: 12
Training loss: 0.5624798536300659
Validation loss: 2.198642690976461

Epoch: 6| Step: 13
Training loss: 0.3398984670639038
Validation loss: 2.1756547490755715

Epoch: 243| Step: 0
Training loss: 0.5438470840454102
Validation loss: 2.184749186038971

Epoch: 6| Step: 1
Training loss: 0.31311720609664917
Validation loss: 2.2293525338172913

Epoch: 6| Step: 2
Training loss: 0.5965189337730408
Validation loss: 2.2817572553952536

Epoch: 6| Step: 3
Training loss: 0.2899865508079529
Validation loss: 2.231421788533529

Epoch: 6| Step: 4
Training loss: 0.3637084662914276
Validation loss: 2.269609212875366

Epoch: 6| Step: 5
Training loss: 0.7185044288635254
Validation loss: 2.219021737575531

Epoch: 6| Step: 6
Training loss: 1.0481562614440918
Validation loss: 2.2198347647984824

Epoch: 6| Step: 7
Training loss: 0.7745566368103027
Validation loss: 2.2260449131329856

Epoch: 6| Step: 8
Training loss: 0.7429195642471313
Validation loss: 2.2312337160110474

Epoch: 6| Step: 9
Training loss: 0.45492327213287354
Validation loss: 2.210614780584971

Epoch: 6| Step: 10
Training loss: 0.432304322719574
Validation loss: 2.2116959492365518

Epoch: 6| Step: 11
Training loss: 0.24298939108848572
Validation loss: 2.2265623211860657

Epoch: 6| Step: 12
Training loss: 0.28515636920928955
Validation loss: 2.2117950320243835

Epoch: 6| Step: 13
Training loss: 0.46634334325790405
Validation loss: 2.2432940204938254

Epoch: 244| Step: 0
Training loss: 0.959925651550293
Validation loss: 2.201022505760193

Epoch: 6| Step: 1
Training loss: 0.4851681590080261
Validation loss: 2.2483096718788147

Epoch: 6| Step: 2
Training loss: 0.22406722605228424
Validation loss: 2.234329183896383

Epoch: 6| Step: 3
Training loss: 0.5224869251251221
Validation loss: 2.190045873324076

Epoch: 6| Step: 4
Training loss: 0.38089361786842346
Validation loss: 2.219117601712545

Epoch: 6| Step: 5
Training loss: 0.44918277859687805
Validation loss: 2.2310214837392173

Epoch: 6| Step: 6
Training loss: 0.4032185673713684
Validation loss: 2.2238845825195312

Epoch: 6| Step: 7
Training loss: 0.46047696471214294
Validation loss: 2.2018800179163613

Epoch: 6| Step: 8
Training loss: 0.8646445274353027
Validation loss: 2.2011789679527283

Epoch: 6| Step: 9
Training loss: 0.43357279896736145
Validation loss: 2.188887278238932

Epoch: 6| Step: 10
Training loss: 0.612028181552887
Validation loss: 2.212012231349945

Epoch: 6| Step: 11
Training loss: 0.3814426064491272
Validation loss: 2.2062886357307434

Epoch: 6| Step: 12
Training loss: 0.29015737771987915
Validation loss: 2.2564244469006858

Epoch: 6| Step: 13
Training loss: 0.6498231887817383
Validation loss: 2.250155985355377

Epoch: 245| Step: 0
Training loss: 0.2870335280895233
Validation loss: 2.2109796603520713

Epoch: 6| Step: 1
Training loss: 0.29188472032546997
Validation loss: 2.2299023469289145

Epoch: 6| Step: 2
Training loss: 0.714832603931427
Validation loss: 2.238050917784373

Epoch: 6| Step: 3
Training loss: 0.485537052154541
Validation loss: 2.1957244277000427

Epoch: 6| Step: 4
Training loss: 0.38450950384140015
Validation loss: 2.2670191129048667

Epoch: 6| Step: 5
Training loss: 0.398590087890625
Validation loss: 2.2984175284703574

Epoch: 6| Step: 6
Training loss: 0.3195105493068695
Validation loss: 2.2375558416048684

Epoch: 6| Step: 7
Training loss: 0.3023252785205841
Validation loss: 2.2414456605911255

Epoch: 6| Step: 8
Training loss: 1.0942708253860474
Validation loss: 2.2110772927602134

Epoch: 6| Step: 9
Training loss: 0.42416930198669434
Validation loss: 2.2231640021006265

Epoch: 6| Step: 10
Training loss: 0.28968602418899536
Validation loss: 2.248881538709005

Epoch: 6| Step: 11
Training loss: 0.5614832639694214
Validation loss: 2.2089843352635703

Epoch: 6| Step: 12
Training loss: 0.4895605742931366
Validation loss: 2.244138936201731

Epoch: 6| Step: 13
Training loss: 0.41854652762413025
Validation loss: 2.217890202999115

Epoch: 246| Step: 0
Training loss: 0.6282022595405579
Validation loss: 2.2427353461583457

Epoch: 6| Step: 1
Training loss: 0.4034203886985779
Validation loss: 2.190804421901703

Epoch: 6| Step: 2
Training loss: 0.5745235681533813
Validation loss: 2.2702261010805764

Epoch: 6| Step: 3
Training loss: 0.2851046621799469
Validation loss: 2.2632230122884116

Epoch: 6| Step: 4
Training loss: 0.38246825337409973
Validation loss: 2.233456552028656

Epoch: 6| Step: 5
Training loss: 0.3842256963253021
Validation loss: 2.240779002507528

Epoch: 6| Step: 6
Training loss: 0.2578158378601074
Validation loss: 2.2498165369033813

Epoch: 6| Step: 7
Training loss: 0.21282705664634705
Validation loss: 2.2300260265668235

Epoch: 6| Step: 8
Training loss: 0.46359097957611084
Validation loss: 2.2354734539985657

Epoch: 6| Step: 9
Training loss: 0.5168192386627197
Validation loss: 2.2127930720647178

Epoch: 6| Step: 10
Training loss: 0.5189819931983948
Validation loss: 2.2461870114008584

Epoch: 6| Step: 11
Training loss: 0.446895956993103
Validation loss: 2.2189584573109946

Epoch: 6| Step: 12
Training loss: 0.43134579062461853
Validation loss: 2.225008487701416

Epoch: 6| Step: 13
Training loss: 0.643819272518158
Validation loss: 2.236001412073771

Epoch: 247| Step: 0
Training loss: 0.49102991819381714
Validation loss: 2.2492652535438538

Epoch: 6| Step: 1
Training loss: 0.32275518774986267
Validation loss: 2.2516139149665833

Epoch: 6| Step: 2
Training loss: 0.3839414715766907
Validation loss: 2.279066244761149

Epoch: 6| Step: 3
Training loss: 0.5777882933616638
Validation loss: 2.1987344225247702

Epoch: 6| Step: 4
Training loss: 0.2566368877887726
Validation loss: 2.2228352228800454

Epoch: 6| Step: 5
Training loss: 0.5498994588851929
Validation loss: 2.2292151848475137

Epoch: 6| Step: 6
Training loss: 0.41466641426086426
Validation loss: 2.2593555053075156

Epoch: 6| Step: 7
Training loss: 0.3088499903678894
Validation loss: 2.2452649672826133

Epoch: 6| Step: 8
Training loss: 0.34718799591064453
Validation loss: 2.2050503889719644

Epoch: 6| Step: 9
Training loss: 0.9360571503639221
Validation loss: 2.2440869212150574

Epoch: 6| Step: 10
Training loss: 0.2801906168460846
Validation loss: 2.200433313846588

Epoch: 6| Step: 11
Training loss: 0.4297495484352112
Validation loss: 2.1901320815086365

Epoch: 6| Step: 12
Training loss: 0.470013290643692
Validation loss: 2.236415227254232

Epoch: 6| Step: 13
Training loss: 0.5870860815048218
Validation loss: 2.1912047465642295

Epoch: 248| Step: 0
Training loss: 0.8032748699188232
Validation loss: 2.2108086744944253

Epoch: 6| Step: 1
Training loss: 0.5410553216934204
Validation loss: 2.2496458292007446

Epoch: 6| Step: 2
Training loss: 0.22670964896678925
Validation loss: 2.117459992567698

Epoch: 6| Step: 3
Training loss: 0.2858462333679199
Validation loss: 2.211836318174998

Epoch: 6| Step: 4
Training loss: 0.4066290855407715
Validation loss: 2.246342102686564

Epoch: 6| Step: 5
Training loss: 0.5756580233573914
Validation loss: 2.2307889461517334

Epoch: 6| Step: 6
Training loss: 0.3060407340526581
Validation loss: 2.271406610806783

Epoch: 6| Step: 7
Training loss: 0.3085171580314636
Validation loss: 2.2250053683916726

Epoch: 6| Step: 8
Training loss: 0.4108371138572693
Validation loss: 2.2275554736455283

Epoch: 6| Step: 9
Training loss: 0.37483835220336914
Validation loss: 2.249557832876841

Epoch: 6| Step: 10
Training loss: 0.16034120321273804
Validation loss: 2.234638432661692

Epoch: 6| Step: 11
Training loss: 0.6638716459274292
Validation loss: 2.246476391951243

Epoch: 6| Step: 12
Training loss: 0.6082335710525513
Validation loss: 2.213276187578837

Epoch: 6| Step: 13
Training loss: 0.6383933424949646
Validation loss: 2.2305213610331216

Epoch: 249| Step: 0
Training loss: 0.651861310005188
Validation loss: 2.2675690253575644

Epoch: 6| Step: 1
Training loss: 0.6679203510284424
Validation loss: 2.2252617875734964

Epoch: 6| Step: 2
Training loss: 0.3012472093105316
Validation loss: 2.235431750615438

Epoch: 6| Step: 3
Training loss: 0.4369155764579773
Validation loss: 2.2587092518806458

Epoch: 6| Step: 4
Training loss: 0.43572741746902466
Validation loss: 2.232874095439911

Epoch: 6| Step: 5
Training loss: 0.3808193802833557
Validation loss: 2.219772736231486

Epoch: 6| Step: 6
Training loss: 0.6274062395095825
Validation loss: 2.2491363684336343

Epoch: 6| Step: 7
Training loss: 0.41601186990737915
Validation loss: 2.26460466782252

Epoch: 6| Step: 8
Training loss: 0.6134979724884033
Validation loss: 2.232556680838267

Epoch: 6| Step: 9
Training loss: 0.5273052453994751
Validation loss: 2.208146055539449

Epoch: 6| Step: 10
Training loss: 0.21820402145385742
Validation loss: 2.2592148383458457

Epoch: 6| Step: 11
Training loss: 0.37308454513549805
Validation loss: 2.2142924666404724

Epoch: 6| Step: 12
Training loss: 0.45080170035362244
Validation loss: 2.237689733505249

Epoch: 6| Step: 13
Training loss: 0.31034529209136963
Validation loss: 2.193020145098368

Epoch: 250| Step: 0
Training loss: 0.4942190945148468
Validation loss: 2.2074036796887717

Epoch: 6| Step: 1
Training loss: 0.39560097455978394
Validation loss: 2.2124346693356833

Epoch: 6| Step: 2
Training loss: 0.3396574854850769
Validation loss: 2.2449693282445273

Epoch: 6| Step: 3
Training loss: 0.37426266074180603
Validation loss: 2.2334279219309487

Epoch: 6| Step: 4
Training loss: 0.2856653034687042
Validation loss: 2.228499174118042

Epoch: 6| Step: 5
Training loss: 0.5760016441345215
Validation loss: 2.2174330949783325

Epoch: 6| Step: 6
Training loss: 0.6937953233718872
Validation loss: 2.2446196476618447

Epoch: 6| Step: 7
Training loss: 0.23829181492328644
Validation loss: 2.2323975563049316

Epoch: 6| Step: 8
Training loss: 0.5555418729782104
Validation loss: 2.2414198517799377

Epoch: 6| Step: 9
Training loss: 0.9004957675933838
Validation loss: 2.2371726036071777

Epoch: 6| Step: 10
Training loss: 0.5398199558258057
Validation loss: 2.30529522895813

Epoch: 6| Step: 11
Training loss: 0.5992739796638489
Validation loss: 2.2430856227874756

Epoch: 6| Step: 12
Training loss: 0.26119646430015564
Validation loss: 2.2612942655881247

Epoch: 6| Step: 13
Training loss: 0.4368312954902649
Validation loss: 2.2379355430603027

Epoch: 251| Step: 0
Training loss: 0.6145220994949341
Validation loss: 2.2568249901135764

Epoch: 6| Step: 1
Training loss: 0.5911730527877808
Validation loss: 2.29839289188385

Epoch: 6| Step: 2
Training loss: 0.3620983362197876
Validation loss: 2.2909353375434875

Epoch: 6| Step: 3
Training loss: 0.33726370334625244
Validation loss: 2.2228126724561057

Epoch: 6| Step: 4
Training loss: 0.3860362768173218
Validation loss: 2.2386504213015237

Epoch: 6| Step: 5
Training loss: 0.8223651647567749
Validation loss: 2.236841599146525

Epoch: 6| Step: 6
Training loss: 0.5485121607780457
Validation loss: 2.2073448499043784

Epoch: 6| Step: 7
Training loss: 0.3086840510368347
Validation loss: 2.234437942504883

Epoch: 6| Step: 8
Training loss: 0.2855793833732605
Validation loss: 2.225742439428965

Epoch: 6| Step: 9
Training loss: 0.4701281189918518
Validation loss: 2.1961673498153687

Epoch: 6| Step: 10
Training loss: 0.9807550311088562
Validation loss: 2.2533199787139893

Epoch: 6| Step: 11
Training loss: 0.2656373381614685
Validation loss: 2.243100583553314

Epoch: 6| Step: 12
Training loss: 0.46921101212501526
Validation loss: 2.2474348743756614

Epoch: 6| Step: 13
Training loss: 0.6084144115447998
Validation loss: 2.223031202952067

Epoch: 252| Step: 0
Training loss: 0.3704853951931
Validation loss: 2.161119818687439

Epoch: 6| Step: 1
Training loss: 0.4685191512107849
Validation loss: 2.259799043337504

Epoch: 6| Step: 2
Training loss: 0.7467027902603149
Validation loss: 2.188940684000651

Epoch: 6| Step: 3
Training loss: 0.2267741709947586
Validation loss: 2.1892346143722534

Epoch: 6| Step: 4
Training loss: 0.34220731258392334
Validation loss: 2.1433101693789163

Epoch: 6| Step: 5
Training loss: 0.5084502696990967
Validation loss: 2.2548757791519165

Epoch: 6| Step: 6
Training loss: 0.4959219694137573
Validation loss: 2.239545444647471

Epoch: 6| Step: 7
Training loss: 0.29422304034233093
Validation loss: 2.2199708819389343

Epoch: 6| Step: 8
Training loss: 0.5919152498245239
Validation loss: 2.189643899599711

Epoch: 6| Step: 9
Training loss: 0.344664990901947
Validation loss: 2.1936203042666116

Epoch: 6| Step: 10
Training loss: 0.6440736055374146
Validation loss: 2.197375535964966

Epoch: 6| Step: 11
Training loss: 0.41872185468673706
Validation loss: 2.1919697523117065

Epoch: 6| Step: 12
Training loss: 0.32442334294319153
Validation loss: 2.2211419343948364

Epoch: 6| Step: 13
Training loss: 0.43158411979675293
Validation loss: 2.172285000483195

Epoch: 253| Step: 0
Training loss: 0.6397229433059692
Validation loss: 2.208488086859385

Epoch: 6| Step: 1
Training loss: 0.4263826310634613
Validation loss: 2.2103742758433023

Epoch: 6| Step: 2
Training loss: 0.5127598643302917
Validation loss: 2.2162163853645325

Epoch: 6| Step: 3
Training loss: 0.2251286506652832
Validation loss: 2.260918696721395

Epoch: 6| Step: 4
Training loss: 0.3306072950363159
Validation loss: 2.231020152568817

Epoch: 6| Step: 5
Training loss: 0.3645196557044983
Validation loss: 2.243924597899119

Epoch: 6| Step: 6
Training loss: 0.4351128339767456
Validation loss: 2.1486902038256326

Epoch: 6| Step: 7
Training loss: 0.505728006362915
Validation loss: 2.2154452006022134

Epoch: 6| Step: 8
Training loss: 0.7760767936706543
Validation loss: 2.2166590094566345

Epoch: 6| Step: 9
Training loss: 0.28709495067596436
Validation loss: 2.23489648103714

Epoch: 6| Step: 10
Training loss: 0.33028021454811096
Validation loss: 2.1889545917510986

Epoch: 6| Step: 11
Training loss: 0.9234974384307861
Validation loss: 2.2336201667785645

Epoch: 6| Step: 12
Training loss: 0.5582382082939148
Validation loss: 2.2492311000823975

Epoch: 6| Step: 13
Training loss: 0.3207814395427704
Validation loss: 2.2137664953867593

Epoch: 254| Step: 0
Training loss: 0.4856753647327423
Validation loss: 2.1775328318277993

Epoch: 6| Step: 1
Training loss: 0.4405999183654785
Validation loss: 2.1680052280426025

Epoch: 6| Step: 2
Training loss: 0.5188977718353271
Validation loss: 2.194098949432373

Epoch: 6| Step: 3
Training loss: 0.8944501876831055
Validation loss: 2.210342764854431

Epoch: 6| Step: 4
Training loss: 0.41504091024398804
Validation loss: 2.2043691277503967

Epoch: 6| Step: 5
Training loss: 0.785625159740448
Validation loss: 2.182444234689077

Epoch: 6| Step: 6
Training loss: 0.5467402338981628
Validation loss: 2.2017870346705117

Epoch: 6| Step: 7
Training loss: 0.3079073429107666
Validation loss: 2.201871375242869

Epoch: 6| Step: 8
Training loss: 0.2695232629776001
Validation loss: 2.220941722393036

Epoch: 6| Step: 9
Training loss: 0.3153887689113617
Validation loss: 2.1965641180674234

Epoch: 6| Step: 10
Training loss: 0.35091161727905273
Validation loss: 2.2063226898511252

Epoch: 6| Step: 11
Training loss: 0.3264223337173462
Validation loss: 2.2243476708730063

Epoch: 6| Step: 12
Training loss: 0.3715161383152008
Validation loss: 2.2053804993629456

Epoch: 6| Step: 13
Training loss: 0.27218204736709595
Validation loss: 2.211216688156128

Epoch: 255| Step: 0
Training loss: 0.5899794697761536
Validation loss: 2.2315940062204995

Epoch: 6| Step: 1
Training loss: 0.41363462805747986
Validation loss: 2.2044214804967246

Epoch: 6| Step: 2
Training loss: 0.35345542430877686
Validation loss: 2.199645201365153

Epoch: 6| Step: 3
Training loss: 0.7576470375061035
Validation loss: 2.2111279567082724

Epoch: 6| Step: 4
Training loss: 0.2950105369091034
Validation loss: 2.16019074122111

Epoch: 6| Step: 5
Training loss: 0.2609761357307434
Validation loss: 2.1847782929738364

Epoch: 6| Step: 6
Training loss: 0.40965813398361206
Validation loss: 2.183869699637095

Epoch: 6| Step: 7
Training loss: 0.3441621661186218
Validation loss: 2.139966130256653

Epoch: 6| Step: 8
Training loss: 0.3889312744140625
Validation loss: 2.251590689023336

Epoch: 6| Step: 9
Training loss: 0.4794486165046692
Validation loss: 2.204415579636892

Epoch: 6| Step: 10
Training loss: 0.4296577572822571
Validation loss: 2.2153052488962808

Epoch: 6| Step: 11
Training loss: 0.343067467212677
Validation loss: 2.2330243984858194

Epoch: 6| Step: 12
Training loss: 0.6254211664199829
Validation loss: 2.2721877098083496

Epoch: 6| Step: 13
Training loss: 0.38604503870010376
Validation loss: 2.2159614165623984

Epoch: 256| Step: 0
Training loss: 0.6025652885437012
Validation loss: 2.26964271068573

Epoch: 6| Step: 1
Training loss: 0.18515750765800476
Validation loss: 2.2445175647735596

Epoch: 6| Step: 2
Training loss: 0.7554250955581665
Validation loss: 2.241347928841909

Epoch: 6| Step: 3
Training loss: 0.26211708784103394
Validation loss: 2.198140263557434

Epoch: 6| Step: 4
Training loss: 0.3936356008052826
Validation loss: 2.2531866232554116

Epoch: 6| Step: 5
Training loss: 0.2249407023191452
Validation loss: 2.2571476300557456

Epoch: 6| Step: 6
Training loss: 0.5866931676864624
Validation loss: 2.2291435599327087

Epoch: 6| Step: 7
Training loss: 0.2520185112953186
Validation loss: 2.248617470264435

Epoch: 6| Step: 8
Training loss: 0.7646002769470215
Validation loss: 2.2319540977478027

Epoch: 6| Step: 9
Training loss: 0.3764006495475769
Validation loss: 2.2499677340189614

Epoch: 6| Step: 10
Training loss: 0.6928108930587769
Validation loss: 2.2187771797180176

Epoch: 6| Step: 11
Training loss: 0.4174838066101074
Validation loss: 2.2344430883725486

Epoch: 6| Step: 12
Training loss: 0.28466248512268066
Validation loss: 2.1888766487439475

Epoch: 6| Step: 13
Training loss: 0.35485127568244934
Validation loss: 2.191663364569346

Epoch: 257| Step: 0
Training loss: 0.3853444755077362
Validation loss: 2.173953036467234

Epoch: 6| Step: 1
Training loss: 0.3938447833061218
Validation loss: 2.158100446065267

Epoch: 6| Step: 2
Training loss: 0.317288339138031
Validation loss: 2.1984334786732993

Epoch: 6| Step: 3
Training loss: 0.3354489803314209
Validation loss: 2.1656283338864646

Epoch: 6| Step: 4
Training loss: 0.5900440216064453
Validation loss: 2.181329051653544

Epoch: 6| Step: 5
Training loss: 0.5373508334159851
Validation loss: 2.245766599973043

Epoch: 6| Step: 6
Training loss: 0.5792133808135986
Validation loss: 2.264084200064341

Epoch: 6| Step: 7
Training loss: 0.49744266271591187
Validation loss: 2.2754278580347695

Epoch: 6| Step: 8
Training loss: 0.3068164587020874
Validation loss: 2.2102883060773215

Epoch: 6| Step: 9
Training loss: 0.548161506652832
Validation loss: 2.2111539443333945

Epoch: 6| Step: 10
Training loss: 0.28642523288726807
Validation loss: 2.2386701901753745

Epoch: 6| Step: 11
Training loss: 0.8309661149978638
Validation loss: 2.230738401412964

Epoch: 6| Step: 12
Training loss: 0.486361026763916
Validation loss: 2.182318687438965

Epoch: 6| Step: 13
Training loss: 0.5212088823318481
Validation loss: 2.1956002712249756

Epoch: 258| Step: 0
Training loss: 0.28047505021095276
Validation loss: 2.201463540395101

Epoch: 6| Step: 1
Training loss: 0.3116493225097656
Validation loss: 2.14181649684906

Epoch: 6| Step: 2
Training loss: 0.971559464931488
Validation loss: 2.178041696548462

Epoch: 6| Step: 3
Training loss: 0.3186236619949341
Validation loss: 2.1667223970095315

Epoch: 6| Step: 4
Training loss: 0.8043060898780823
Validation loss: 2.2260618209838867

Epoch: 6| Step: 5
Training loss: 0.4904618561267853
Validation loss: 2.2107643683751426

Epoch: 6| Step: 6
Training loss: 0.40702033042907715
Validation loss: 2.224039455254873

Epoch: 6| Step: 7
Training loss: 0.32415372133255005
Validation loss: 2.2398317456245422

Epoch: 6| Step: 8
Training loss: 0.32104426622390747
Validation loss: 2.209769368171692

Epoch: 6| Step: 9
Training loss: 0.21336224675178528
Validation loss: 2.1736377676328025

Epoch: 6| Step: 10
Training loss: 0.28550636768341064
Validation loss: 2.2492935061454773

Epoch: 6| Step: 11
Training loss: 0.4654234051704407
Validation loss: 2.2232701778411865

Epoch: 6| Step: 12
Training loss: 0.599886417388916
Validation loss: 2.1790692806243896

Epoch: 6| Step: 13
Training loss: 0.5192344188690186
Validation loss: 2.2340262730916343

Epoch: 259| Step: 0
Training loss: 0.6061968803405762
Validation loss: 2.2432291507720947

Epoch: 6| Step: 1
Training loss: 0.3714640140533447
Validation loss: 2.187757949034373

Epoch: 6| Step: 2
Training loss: 0.2763581871986389
Validation loss: 2.222734351952871

Epoch: 6| Step: 3
Training loss: 0.7858404517173767
Validation loss: 2.2459857066472373

Epoch: 6| Step: 4
Training loss: 0.2509216368198395
Validation loss: 2.204972287019094

Epoch: 6| Step: 5
Training loss: 0.4209982752799988
Validation loss: 2.216061234474182

Epoch: 6| Step: 6
Training loss: 0.3709646463394165
Validation loss: 2.2031913002332053

Epoch: 6| Step: 7
Training loss: 0.5389537811279297
Validation loss: 2.2220272223154702

Epoch: 6| Step: 8
Training loss: 0.2926984131336212
Validation loss: 2.2128421862920127

Epoch: 6| Step: 9
Training loss: 0.48168620467185974
Validation loss: 2.1849729418754578

Epoch: 6| Step: 10
Training loss: 0.4974285364151001
Validation loss: 2.17996617158254

Epoch: 6| Step: 11
Training loss: 0.4542961120605469
Validation loss: 2.158656358718872

Epoch: 6| Step: 12
Training loss: 0.4370121955871582
Validation loss: 2.188618322213491

Epoch: 6| Step: 13
Training loss: 0.46970734000205994
Validation loss: 2.2351309657096863

Epoch: 260| Step: 0
Training loss: 0.9342845678329468
Validation loss: 2.242967983086904

Epoch: 6| Step: 1
Training loss: 0.3319840431213379
Validation loss: 2.233749727408091

Epoch: 6| Step: 2
Training loss: 0.3896845281124115
Validation loss: 2.1942856113115945

Epoch: 6| Step: 3
Training loss: 0.23604033887386322
Validation loss: 2.1994826594988504

Epoch: 6| Step: 4
Training loss: 0.37222927808761597
Validation loss: 2.234369218349457

Epoch: 6| Step: 5
Training loss: 0.26958924531936646
Validation loss: 2.205893854300181

Epoch: 6| Step: 6
Training loss: 0.2586110234260559
Validation loss: 2.2251309553782144

Epoch: 6| Step: 7
Training loss: 0.5827493667602539
Validation loss: 2.14079080025355

Epoch: 6| Step: 8
Training loss: 0.7334755659103394
Validation loss: 2.2096909483273826

Epoch: 6| Step: 9
Training loss: 0.33378082513809204
Validation loss: 2.22663281361262

Epoch: 6| Step: 10
Training loss: 0.5431321859359741
Validation loss: 2.2739391724268594

Epoch: 6| Step: 11
Training loss: 0.2985372543334961
Validation loss: 2.2055360078811646

Epoch: 6| Step: 12
Training loss: 0.3097965121269226
Validation loss: 2.2478133042653403

Epoch: 6| Step: 13
Training loss: 0.3584432005882263
Validation loss: 2.169386943181356

Epoch: 261| Step: 0
Training loss: 0.3674759864807129
Validation loss: 2.2120188275973

Epoch: 6| Step: 1
Training loss: 0.3660576641559601
Validation loss: 2.198020339012146

Epoch: 6| Step: 2
Training loss: 0.2417793869972229
Validation loss: 2.2659879326820374

Epoch: 6| Step: 3
Training loss: 0.261302649974823
Validation loss: 2.2167142629623413

Epoch: 6| Step: 4
Training loss: 0.3581756055355072
Validation loss: 2.1848992705345154

Epoch: 6| Step: 5
Training loss: 0.28578269481658936
Validation loss: 2.20105634133021

Epoch: 6| Step: 6
Training loss: 0.8833439946174622
Validation loss: 2.246023257573446

Epoch: 6| Step: 7
Training loss: 0.28641849756240845
Validation loss: 2.2141915758450827

Epoch: 6| Step: 8
Training loss: 0.27058443427085876
Validation loss: 2.2261693278948465

Epoch: 6| Step: 9
Training loss: 0.5572996139526367
Validation loss: 2.2207888762156167

Epoch: 6| Step: 10
Training loss: 0.3749500513076782
Validation loss: 2.2522928516070047

Epoch: 6| Step: 11
Training loss: 1.0112706422805786
Validation loss: 2.231169104576111

Epoch: 6| Step: 12
Training loss: 0.3757143020629883
Validation loss: 2.2224008639653525

Epoch: 6| Step: 13
Training loss: 0.42675545811653137
Validation loss: 2.224808911482493

Epoch: 262| Step: 0
Training loss: 0.43954142928123474
Validation loss: 2.2193987568219504

Epoch: 6| Step: 1
Training loss: 0.41247403621673584
Validation loss: 2.2229521671930947

Epoch: 6| Step: 2
Training loss: 0.7924992442131042
Validation loss: 2.2298622131347656

Epoch: 6| Step: 3
Training loss: 0.5752189755439758
Validation loss: 2.2237290938695273

Epoch: 6| Step: 4
Training loss: 0.40864455699920654
Validation loss: 2.2130034367243447

Epoch: 6| Step: 5
Training loss: 0.2725539803504944
Validation loss: 2.201267103354136

Epoch: 6| Step: 6
Training loss: 0.4283665418624878
Validation loss: 2.2555253505706787

Epoch: 6| Step: 7
Training loss: 0.24542011320590973
Validation loss: 2.2186349034309387

Epoch: 6| Step: 8
Training loss: 0.40150734782218933
Validation loss: 2.242933909098307

Epoch: 6| Step: 9
Training loss: 0.4870918095111847
Validation loss: 2.265473206837972

Epoch: 6| Step: 10
Training loss: 0.3991242051124573
Validation loss: 2.2431695461273193

Epoch: 6| Step: 11
Training loss: 0.3306097984313965
Validation loss: 2.2261590162913003

Epoch: 6| Step: 12
Training loss: 0.2311934381723404
Validation loss: 2.2059674064318338

Epoch: 6| Step: 13
Training loss: 0.4253450334072113
Validation loss: 2.2503795226415

Epoch: 263| Step: 0
Training loss: 0.28448495268821716
Validation loss: 2.238470196723938

Epoch: 6| Step: 1
Training loss: 0.2719009220600128
Validation loss: 2.2191548347473145

Epoch: 6| Step: 2
Training loss: 0.5238892436027527
Validation loss: 2.242677410443624

Epoch: 6| Step: 3
Training loss: 0.39653751254081726
Validation loss: 2.2613114515940347

Epoch: 6| Step: 4
Training loss: 0.6273193955421448
Validation loss: 2.239901880423228

Epoch: 6| Step: 5
Training loss: 0.2326311469078064
Validation loss: 2.2218865156173706

Epoch: 6| Step: 6
Training loss: 0.3941709101200104
Validation loss: 2.2213266293207803

Epoch: 6| Step: 7
Training loss: 0.6540709733963013
Validation loss: 2.200743317604065

Epoch: 6| Step: 8
Training loss: 0.5623016357421875
Validation loss: 2.2185575366020203

Epoch: 6| Step: 9
Training loss: 0.48705825209617615
Validation loss: 2.1946072975794473

Epoch: 6| Step: 10
Training loss: 0.21831658482551575
Validation loss: 2.228203554948171

Epoch: 6| Step: 11
Training loss: 0.36667945981025696
Validation loss: 2.2327988147735596

Epoch: 6| Step: 12
Training loss: 0.40094125270843506
Validation loss: 2.2194005449612937

Epoch: 6| Step: 13
Training loss: 0.2612950801849365
Validation loss: 2.2461649974187217

Epoch: 264| Step: 0
Training loss: 0.24514266848564148
Validation loss: 2.203991413116455

Epoch: 6| Step: 1
Training loss: 0.1970670223236084
Validation loss: 2.2195985118548074

Epoch: 6| Step: 2
Training loss: 1.0241745710372925
Validation loss: 2.2212260961532593

Epoch: 6| Step: 3
Training loss: 0.5568186044692993
Validation loss: 2.2235452930132547

Epoch: 6| Step: 4
Training loss: 0.42770108580589294
Validation loss: 2.273846467336019

Epoch: 6| Step: 5
Training loss: 0.37686413526535034
Validation loss: 2.1848893562952676

Epoch: 6| Step: 6
Training loss: 0.3121366500854492
Validation loss: 2.255721926689148

Epoch: 6| Step: 7
Training loss: 0.3743228316307068
Validation loss: 2.1926910678545632

Epoch: 6| Step: 8
Training loss: 0.24275703728199005
Validation loss: 2.223599116007487

Epoch: 6| Step: 9
Training loss: 0.5126744508743286
Validation loss: 2.2111430168151855

Epoch: 6| Step: 10
Training loss: 0.3821350038051605
Validation loss: 2.236386219660441

Epoch: 6| Step: 11
Training loss: 0.3837268352508545
Validation loss: 2.2097049752871194

Epoch: 6| Step: 12
Training loss: 0.506897509098053
Validation loss: 2.1751757661501565

Epoch: 6| Step: 13
Training loss: 0.22957757115364075
Validation loss: 2.214555323123932

Epoch: 265| Step: 0
Training loss: 0.31963175535202026
Validation loss: 2.216788172721863

Epoch: 6| Step: 1
Training loss: 0.4337741732597351
Validation loss: 2.2498117486635842

Epoch: 6| Step: 2
Training loss: 0.3812945783138275
Validation loss: 2.2387397289276123

Epoch: 6| Step: 3
Training loss: 0.4392426609992981
Validation loss: 2.188121179739634

Epoch: 6| Step: 4
Training loss: 0.4386005103588104
Validation loss: 2.2395581801732383

Epoch: 6| Step: 5
Training loss: 0.4036664366722107
Validation loss: 2.199686288833618

Epoch: 6| Step: 6
Training loss: 0.6223401427268982
Validation loss: 2.2628029187520347

Epoch: 6| Step: 7
Training loss: 0.5700582265853882
Validation loss: 2.2305935621261597

Epoch: 6| Step: 8
Training loss: 0.954171359539032
Validation loss: 2.230801820755005

Epoch: 6| Step: 9
Training loss: 0.36879265308380127
Validation loss: 2.2436310251553855

Epoch: 6| Step: 10
Training loss: 0.2924897372722626
Validation loss: 2.1978902419408164

Epoch: 6| Step: 11
Training loss: 0.4854036569595337
Validation loss: 2.201799511909485

Epoch: 6| Step: 12
Training loss: 0.44426482915878296
Validation loss: 2.2206379771232605

Epoch: 6| Step: 13
Training loss: 0.5227800011634827
Validation loss: 2.2429317633310952

Epoch: 266| Step: 0
Training loss: 0.6526411771774292
Validation loss: 2.2403266429901123

Epoch: 6| Step: 1
Training loss: 0.38405877351760864
Validation loss: 2.244243780771891

Epoch: 6| Step: 2
Training loss: 0.36297500133514404
Validation loss: 2.207443674405416

Epoch: 6| Step: 3
Training loss: 0.2873801589012146
Validation loss: 2.2364095052083335

Epoch: 6| Step: 4
Training loss: 0.1351906657218933
Validation loss: 2.242690145969391

Epoch: 6| Step: 5
Training loss: 0.7466655373573303
Validation loss: 2.2474177877108255

Epoch: 6| Step: 6
Training loss: 0.3872840106487274
Validation loss: 2.284324824810028

Epoch: 6| Step: 7
Training loss: 0.40293997526168823
Validation loss: 2.2538978854815164

Epoch: 6| Step: 8
Training loss: 0.5020751953125
Validation loss: 2.205838620662689

Epoch: 6| Step: 9
Training loss: 0.49484768509864807
Validation loss: 2.245142936706543

Epoch: 6| Step: 10
Training loss: 0.5208568572998047
Validation loss: 2.2563146352767944

Epoch: 6| Step: 11
Training loss: 0.3829195499420166
Validation loss: 2.1944289803504944

Epoch: 6| Step: 12
Training loss: 0.2672106623649597
Validation loss: 2.153451999028524

Epoch: 6| Step: 13
Training loss: 0.3845505714416504
Validation loss: 2.2128941218058267

Epoch: 267| Step: 0
Training loss: 0.45618605613708496
Validation loss: 2.2147205074628196

Epoch: 6| Step: 1
Training loss: 0.33726948499679565
Validation loss: 2.2264802853266397

Epoch: 6| Step: 2
Training loss: 0.24520422518253326
Validation loss: 2.252702991167704

Epoch: 6| Step: 3
Training loss: 0.32370662689208984
Validation loss: 2.253950079282125

Epoch: 6| Step: 4
Training loss: 0.29400643706321716
Validation loss: 2.199171245098114

Epoch: 6| Step: 5
Training loss: 0.38930967450141907
Validation loss: 2.238742172718048

Epoch: 6| Step: 6
Training loss: 0.8503511548042297
Validation loss: 2.226199984550476

Epoch: 6| Step: 7
Training loss: 0.3854011297225952
Validation loss: 2.258645157019297

Epoch: 6| Step: 8
Training loss: 0.5732466578483582
Validation loss: 2.260730743408203

Epoch: 6| Step: 9
Training loss: 0.8887485265731812
Validation loss: 2.203256686528524

Epoch: 6| Step: 10
Training loss: 0.3123846650123596
Validation loss: 2.2762445211410522

Epoch: 6| Step: 11
Training loss: 0.39111679792404175
Validation loss: 2.285702665646871

Epoch: 6| Step: 12
Training loss: 0.5160401463508606
Validation loss: 2.2265238960584006

Epoch: 6| Step: 13
Training loss: 0.29007357358932495
Validation loss: 2.2362207174301147

Epoch: 268| Step: 0
Training loss: 0.5607692003250122
Validation loss: 2.2234453161557517

Epoch: 6| Step: 1
Training loss: 0.23930373787879944
Validation loss: 2.201004425684611

Epoch: 6| Step: 2
Training loss: 0.28700369596481323
Validation loss: 2.25566295782725

Epoch: 6| Step: 3
Training loss: 0.306565523147583
Validation loss: 2.213370402654012

Epoch: 6| Step: 4
Training loss: 0.2458944171667099
Validation loss: 2.2198848923047385

Epoch: 6| Step: 5
Training loss: 0.5997390747070312
Validation loss: 2.1941601832707724

Epoch: 6| Step: 6
Training loss: 0.49557337164878845
Validation loss: 2.1839672923088074

Epoch: 6| Step: 7
Training loss: 0.8412128686904907
Validation loss: 2.2084414958953857

Epoch: 6| Step: 8
Training loss: 0.6070347428321838
Validation loss: 2.249677062034607

Epoch: 6| Step: 9
Training loss: 0.2547184228897095
Validation loss: 2.2233123779296875

Epoch: 6| Step: 10
Training loss: 0.21262294054031372
Validation loss: 2.2354636192321777

Epoch: 6| Step: 11
Training loss: 0.4721618592739105
Validation loss: 2.2641481757164

Epoch: 6| Step: 12
Training loss: 0.2946747839450836
Validation loss: 2.2040865619977317

Epoch: 6| Step: 13
Training loss: 0.31319013237953186
Validation loss: 2.1732335289319358

Epoch: 269| Step: 0
Training loss: 0.4377312660217285
Validation loss: 2.239799718062083

Epoch: 6| Step: 1
Training loss: 0.19987361133098602
Validation loss: 2.270558694998423

Epoch: 6| Step: 2
Training loss: 0.17962083220481873
Validation loss: 2.2338301142056785

Epoch: 6| Step: 3
Training loss: 0.4644066095352173
Validation loss: 2.207715551058451

Epoch: 6| Step: 4
Training loss: 0.2989843785762787
Validation loss: 2.2179113626480103

Epoch: 6| Step: 5
Training loss: 1.010214924812317
Validation loss: 2.249847133954366

Epoch: 6| Step: 6
Training loss: 0.358897864818573
Validation loss: 2.186241606871287

Epoch: 6| Step: 7
Training loss: 0.2831481099128723
Validation loss: 2.2406464417775473

Epoch: 6| Step: 8
Training loss: 0.5308769345283508
Validation loss: 2.187183399995168

Epoch: 6| Step: 9
Training loss: 0.2653444707393646
Validation loss: 2.2158135573069253

Epoch: 6| Step: 10
Training loss: 0.4918104410171509
Validation loss: 2.194874942302704

Epoch: 6| Step: 11
Training loss: 0.5190268754959106
Validation loss: 2.2103251218795776

Epoch: 6| Step: 12
Training loss: 0.32663601636886597
Validation loss: 2.209234674771627

Epoch: 6| Step: 13
Training loss: 0.5306395292282104
Validation loss: 2.23121041059494

Epoch: 270| Step: 0
Training loss: 0.712071418762207
Validation loss: 2.176336427529653

Epoch: 6| Step: 1
Training loss: 0.44168105721473694
Validation loss: 2.197491010030111

Epoch: 6| Step: 2
Training loss: 0.25920647382736206
Validation loss: 2.277039964993795

Epoch: 6| Step: 3
Training loss: 0.44174057245254517
Validation loss: 2.240407725175222

Epoch: 6| Step: 4
Training loss: 0.37435972690582275
Validation loss: 2.241262972354889

Epoch: 6| Step: 5
Training loss: 0.23161815106868744
Validation loss: 2.2095518708229065

Epoch: 6| Step: 6
Training loss: 0.48548781871795654
Validation loss: 2.2283074855804443

Epoch: 6| Step: 7
Training loss: 0.3308800458908081
Validation loss: 2.2299550771713257

Epoch: 6| Step: 8
Training loss: 0.2742188274860382
Validation loss: 2.2112512389818826

Epoch: 6| Step: 9
Training loss: 0.4391745924949646
Validation loss: 2.210844119389852

Epoch: 6| Step: 10
Training loss: 0.4326234757900238
Validation loss: 2.2387362122535706

Epoch: 6| Step: 11
Training loss: 0.23382562398910522
Validation loss: 2.1917786796887717

Epoch: 6| Step: 12
Training loss: 0.3289792239665985
Validation loss: 2.253309408823649

Epoch: 6| Step: 13
Training loss: 1.066204309463501
Validation loss: 2.185806632041931

Epoch: 271| Step: 0
Training loss: 0.4503861963748932
Validation loss: 2.2041387955347695

Epoch: 6| Step: 1
Training loss: 0.3851865530014038
Validation loss: 2.192502419153849

Epoch: 6| Step: 2
Training loss: 0.3692516088485718
Validation loss: 2.2477217515309653

Epoch: 6| Step: 3
Training loss: 0.31186553835868835
Validation loss: 2.1889615456263223

Epoch: 6| Step: 4
Training loss: 0.27148672938346863
Validation loss: 2.230454206466675

Epoch: 6| Step: 5
Training loss: 0.3609545826911926
Validation loss: 2.255909184614817

Epoch: 6| Step: 6
Training loss: 0.268502801656723
Validation loss: 2.2185317873954773

Epoch: 6| Step: 7
Training loss: 0.5079171657562256
Validation loss: 2.2028026382128396

Epoch: 6| Step: 8
Training loss: 0.27139219641685486
Validation loss: 2.2073992490768433

Epoch: 6| Step: 9
Training loss: 0.5348955392837524
Validation loss: 2.1761276721954346

Epoch: 6| Step: 10
Training loss: 0.16334322094917297
Validation loss: 2.2071048816045127

Epoch: 6| Step: 11
Training loss: 1.0072063207626343
Validation loss: 2.2497041622797647

Epoch: 6| Step: 12
Training loss: 0.2207885980606079
Validation loss: 2.2506956656773887

Epoch: 6| Step: 13
Training loss: 0.43838781118392944
Validation loss: 2.1812546253204346

Epoch: 272| Step: 0
Training loss: 0.2964071035385132
Validation loss: 2.145735422770182

Epoch: 6| Step: 1
Training loss: 0.51119065284729
Validation loss: 2.215738296508789

Epoch: 6| Step: 2
Training loss: 0.39959049224853516
Validation loss: 2.2322385708491006

Epoch: 6| Step: 3
Training loss: 0.7241504788398743
Validation loss: 2.199061075846354

Epoch: 6| Step: 4
Training loss: 0.4315093159675598
Validation loss: 2.230959475040436

Epoch: 6| Step: 5
Training loss: 0.27625590562820435
Validation loss: 2.2139965494473777

Epoch: 6| Step: 6
Training loss: 0.33000367879867554
Validation loss: 2.2316744128863015

Epoch: 6| Step: 7
Training loss: 0.21363909542560577
Validation loss: 2.2396833101908364

Epoch: 6| Step: 8
Training loss: 0.4383234679698944
Validation loss: 2.2204729517300925

Epoch: 6| Step: 9
Training loss: 0.4809713363647461
Validation loss: 2.1866663098335266

Epoch: 6| Step: 10
Training loss: 0.2845678925514221
Validation loss: 2.2224924763043723

Epoch: 6| Step: 11
Training loss: 0.5997761487960815
Validation loss: 2.1903815269470215

Epoch: 6| Step: 12
Training loss: 0.701400637626648
Validation loss: 2.2084399660428367

Epoch: 6| Step: 13
Training loss: 0.3649802803993225
Validation loss: 2.2307517528533936

Epoch: 273| Step: 0
Training loss: 0.44973260164260864
Validation loss: 2.1684206326802573

Epoch: 6| Step: 1
Training loss: 0.3108474612236023
Validation loss: 2.2161845763524375

Epoch: 6| Step: 2
Training loss: 0.4018159508705139
Validation loss: 2.220274885495504

Epoch: 6| Step: 3
Training loss: 0.6147576570510864
Validation loss: 2.225368936856588

Epoch: 6| Step: 4
Training loss: 0.26370668411254883
Validation loss: 2.2568747202555337

Epoch: 6| Step: 5
Training loss: 0.3334552049636841
Validation loss: 2.198629856109619

Epoch: 6| Step: 6
Training loss: 0.4670015573501587
Validation loss: 2.1909791032473245

Epoch: 6| Step: 7
Training loss: 0.26626425981521606
Validation loss: 2.255096912384033

Epoch: 6| Step: 8
Training loss: 0.8637404441833496
Validation loss: 2.170756181081136

Epoch: 6| Step: 9
Training loss: 0.5400763750076294
Validation loss: 2.2470337947209678

Epoch: 6| Step: 10
Training loss: 0.24806347489356995
Validation loss: 2.2069817781448364

Epoch: 6| Step: 11
Training loss: 0.32067322731018066
Validation loss: 2.2200177113215127

Epoch: 6| Step: 12
Training loss: 0.26813942193984985
Validation loss: 2.2131860057512918

Epoch: 6| Step: 13
Training loss: 0.34774303436279297
Validation loss: 2.1728641589482627

Epoch: 274| Step: 0
Training loss: 0.763007640838623
Validation loss: 2.2039808432261148

Epoch: 6| Step: 1
Training loss: 0.5019633769989014
Validation loss: 2.221225698788961

Epoch: 6| Step: 2
Training loss: 0.21651612222194672
Validation loss: 2.1988073786099753

Epoch: 6| Step: 3
Training loss: 0.2881360650062561
Validation loss: 2.2467998266220093

Epoch: 6| Step: 4
Training loss: 0.5298868417739868
Validation loss: 2.262750267982483

Epoch: 6| Step: 5
Training loss: 0.3803029954433441
Validation loss: 2.2158454259236655

Epoch: 6| Step: 6
Training loss: 0.2176342010498047
Validation loss: 2.2187044421831765

Epoch: 6| Step: 7
Training loss: 0.2764345407485962
Validation loss: 2.2023382782936096

Epoch: 6| Step: 8
Training loss: 0.3083649277687073
Validation loss: 2.245691935221354

Epoch: 6| Step: 9
Training loss: 0.2874908149242401
Validation loss: 2.234905481338501

Epoch: 6| Step: 10
Training loss: 0.5676952004432678
Validation loss: 2.241958975791931

Epoch: 6| Step: 11
Training loss: 0.348281592130661
Validation loss: 2.2342899243036904

Epoch: 6| Step: 12
Training loss: 0.42502361536026
Validation loss: 2.248059252897898

Epoch: 6| Step: 13
Training loss: 0.7764211893081665
Validation loss: 2.2508380015691123

Epoch: 275| Step: 0
Training loss: 0.5199608206748962
Validation loss: 2.231623729070028

Epoch: 6| Step: 1
Training loss: 0.32897377014160156
Validation loss: 2.2597737510999045

Epoch: 6| Step: 2
Training loss: 0.638276219367981
Validation loss: 2.239567736784617

Epoch: 6| Step: 3
Training loss: 0.8225876092910767
Validation loss: 2.234261473019918

Epoch: 6| Step: 4
Training loss: 0.20059140026569366
Validation loss: 2.2333472768465676

Epoch: 6| Step: 5
Training loss: 0.304657906293869
Validation loss: 2.1714847683906555

Epoch: 6| Step: 6
Training loss: 0.4623023569583893
Validation loss: 2.2161428531010947

Epoch: 6| Step: 7
Training loss: 0.5110387206077576
Validation loss: 2.188237965106964

Epoch: 6| Step: 8
Training loss: 0.5191968679428101
Validation loss: 2.225847601890564

Epoch: 6| Step: 9
Training loss: 0.38392192125320435
Validation loss: 2.204397439956665

Epoch: 6| Step: 10
Training loss: 0.4308716654777527
Validation loss: 2.2113261222839355

Epoch: 6| Step: 11
Training loss: 0.5273190140724182
Validation loss: 2.2485187649726868

Epoch: 6| Step: 12
Training loss: 0.43963074684143066
Validation loss: 2.2509364684422812

Epoch: 6| Step: 13
Training loss: 0.4275512099266052
Validation loss: 2.252217650413513

Epoch: 276| Step: 0
Training loss: 0.7085311412811279
Validation loss: 2.193459471066793

Epoch: 6| Step: 1
Training loss: 0.350262314081192
Validation loss: 2.1960150003433228

Epoch: 6| Step: 2
Training loss: 0.4297962188720703
Validation loss: 2.253481149673462

Epoch: 6| Step: 3
Training loss: 0.4006272256374359
Validation loss: 2.235467274983724

Epoch: 6| Step: 4
Training loss: 0.5182933211326599
Validation loss: 2.1746806104977927

Epoch: 6| Step: 5
Training loss: 0.24942436814308167
Validation loss: 2.170234123865763

Epoch: 6| Step: 6
Training loss: 0.45961761474609375
Validation loss: 2.238410214583079

Epoch: 6| Step: 7
Training loss: 0.7215827703475952
Validation loss: 2.2314199010531106

Epoch: 6| Step: 8
Training loss: 0.32980096340179443
Validation loss: 2.2027957240740457

Epoch: 6| Step: 9
Training loss: 0.3118760585784912
Validation loss: 2.2284171978632608

Epoch: 6| Step: 10
Training loss: 0.46254584193229675
Validation loss: 2.2379604975382485

Epoch: 6| Step: 11
Training loss: 0.6572971940040588
Validation loss: 2.2372247775395713

Epoch: 6| Step: 12
Training loss: 0.37757742404937744
Validation loss: 2.2251858512560525

Epoch: 6| Step: 13
Training loss: 0.45417001843452454
Validation loss: 2.243020514647166

Epoch: 277| Step: 0
Training loss: 0.3184482455253601
Validation loss: 2.1839244763056436

Epoch: 6| Step: 1
Training loss: 0.41257768869400024
Validation loss: 2.2507681051890054

Epoch: 6| Step: 2
Training loss: 0.20774655044078827
Validation loss: 2.21718430519104

Epoch: 6| Step: 3
Training loss: 0.49672871828079224
Validation loss: 2.247511943181356

Epoch: 6| Step: 4
Training loss: 0.32891973853111267
Validation loss: 2.239790141582489

Epoch: 6| Step: 5
Training loss: 0.34177637100219727
Validation loss: 2.218445360660553

Epoch: 6| Step: 6
Training loss: 0.6706907749176025
Validation loss: 2.159705956776937

Epoch: 6| Step: 7
Training loss: 0.32392939925193787
Validation loss: 2.186378538608551

Epoch: 6| Step: 8
Training loss: 0.3623506426811218
Validation loss: 2.204797943433126

Epoch: 6| Step: 9
Training loss: 0.38155192136764526
Validation loss: 2.218322992324829

Epoch: 6| Step: 10
Training loss: 0.27280786633491516
Validation loss: 2.217081864674886

Epoch: 6| Step: 11
Training loss: 0.24274466931819916
Validation loss: 2.2178509632746377

Epoch: 6| Step: 12
Training loss: 0.4572685658931732
Validation loss: 2.2382149696350098

Epoch: 6| Step: 13
Training loss: 0.744962215423584
Validation loss: 2.194590946038564

Epoch: 278| Step: 0
Training loss: 0.5288619995117188
Validation loss: 2.1914095679918923

Epoch: 6| Step: 1
Training loss: 0.2540108263492584
Validation loss: 2.221396803855896

Epoch: 6| Step: 2
Training loss: 0.2218896448612213
Validation loss: 2.2558432618776956

Epoch: 6| Step: 3
Training loss: 0.3189913034439087
Validation loss: 2.2421801487604776

Epoch: 6| Step: 4
Training loss: 0.588445246219635
Validation loss: 2.272516588370005

Epoch: 6| Step: 5
Training loss: 0.3403230309486389
Validation loss: 2.2312567035357156

Epoch: 6| Step: 6
Training loss: 0.2527879476547241
Validation loss: 2.2174927592277527

Epoch: 6| Step: 7
Training loss: 0.7941417694091797
Validation loss: 2.173750102519989

Epoch: 6| Step: 8
Training loss: 0.38979536294937134
Validation loss: 2.230807979901632

Epoch: 6| Step: 9
Training loss: 0.43082404136657715
Validation loss: 2.2353670597076416

Epoch: 6| Step: 10
Training loss: 0.43410569429397583
Validation loss: 2.2017575105031333

Epoch: 6| Step: 11
Training loss: 0.31371772289276123
Validation loss: 2.220667004585266

Epoch: 6| Step: 12
Training loss: 0.35346293449401855
Validation loss: 2.254640738169352

Epoch: 6| Step: 13
Training loss: 0.45468828082084656
Validation loss: 2.2819897333780923

Epoch: 279| Step: 0
Training loss: 0.6012554168701172
Validation loss: 2.221142371495565

Epoch: 6| Step: 1
Training loss: 0.37090346217155457
Validation loss: 2.2315340836842856

Epoch: 6| Step: 2
Training loss: 0.2960953116416931
Validation loss: 2.1929680506388345

Epoch: 6| Step: 3
Training loss: 0.3384957015514374
Validation loss: 2.225742757320404

Epoch: 6| Step: 4
Training loss: 0.3732220530509949
Validation loss: 2.2182887395222983

Epoch: 6| Step: 5
Training loss: 0.47403037548065186
Validation loss: 2.1690288384755454

Epoch: 6| Step: 6
Training loss: 0.5375598669052124
Validation loss: 2.1604645450909934

Epoch: 6| Step: 7
Training loss: 0.7590910792350769
Validation loss: 2.1966025034586587

Epoch: 6| Step: 8
Training loss: 0.23257635533809662
Validation loss: 2.167967657248179

Epoch: 6| Step: 9
Training loss: 0.3096652030944824
Validation loss: 2.14782722791036

Epoch: 6| Step: 10
Training loss: 0.595506489276886
Validation loss: 2.2220186392466226

Epoch: 6| Step: 11
Training loss: 0.3068240284919739
Validation loss: 2.2295451164245605

Epoch: 6| Step: 12
Training loss: 0.18416933715343475
Validation loss: 2.2277395725250244

Epoch: 6| Step: 13
Training loss: 0.4610973298549652
Validation loss: 2.204349378744761

Epoch: 280| Step: 0
Training loss: 0.5235738754272461
Validation loss: 2.1947021087010703

Epoch: 6| Step: 1
Training loss: 0.36201149225234985
Validation loss: 2.20182474454244

Epoch: 6| Step: 2
Training loss: 0.40389764308929443
Validation loss: 2.159351567427317

Epoch: 6| Step: 3
Training loss: 0.2558417320251465
Validation loss: 2.1472278237342834

Epoch: 6| Step: 4
Training loss: 0.34994760155677795
Validation loss: 2.195534348487854

Epoch: 6| Step: 5
Training loss: 0.38678184151649475
Validation loss: 2.222277899583181

Epoch: 6| Step: 6
Training loss: 0.33340442180633545
Validation loss: 2.2650625904401145

Epoch: 6| Step: 7
Training loss: 0.38024455308914185
Validation loss: 2.2330867449442544

Epoch: 6| Step: 8
Training loss: 0.2437777817249298
Validation loss: 2.2465309699376426

Epoch: 6| Step: 9
Training loss: 0.4283604323863983
Validation loss: 2.226849595705668

Epoch: 6| Step: 10
Training loss: 0.410628080368042
Validation loss: 2.2328654726346335

Epoch: 6| Step: 11
Training loss: 0.3104263246059418
Validation loss: 2.2332979242006936

Epoch: 6| Step: 12
Training loss: 0.9538968801498413
Validation loss: 2.2143288056055703

Epoch: 6| Step: 13
Training loss: 0.33373045921325684
Validation loss: 2.238234559694926

Epoch: 281| Step: 0
Training loss: 0.32690685987472534
Validation loss: 2.2040478587150574

Epoch: 6| Step: 1
Training loss: 0.2972860336303711
Validation loss: 2.22518253326416

Epoch: 6| Step: 2
Training loss: 0.3545905351638794
Validation loss: 2.2461251417795816

Epoch: 6| Step: 3
Training loss: 0.7992733120918274
Validation loss: 2.2234220703442893

Epoch: 6| Step: 4
Training loss: 0.44767293334007263
Validation loss: 2.193187733491262

Epoch: 6| Step: 5
Training loss: 0.2952232360839844
Validation loss: 2.2083879311879477

Epoch: 6| Step: 6
Training loss: 0.27420079708099365
Validation loss: 2.2148335377375283

Epoch: 6| Step: 7
Training loss: 0.6018478274345398
Validation loss: 2.26650333404541

Epoch: 6| Step: 8
Training loss: 0.23616069555282593
Validation loss: 2.1990055441856384

Epoch: 6| Step: 9
Training loss: 0.5947012901306152
Validation loss: 2.1808022260665894

Epoch: 6| Step: 10
Training loss: 0.30701249837875366
Validation loss: 2.2210679054260254

Epoch: 6| Step: 11
Training loss: 0.27520281076431274
Validation loss: 2.208408216635386

Epoch: 6| Step: 12
Training loss: 0.5900293588638306
Validation loss: 2.2288384437561035

Epoch: 6| Step: 13
Training loss: 0.23470133543014526
Validation loss: 2.1856053272883096

Epoch: 282| Step: 0
Training loss: 0.21424269676208496
Validation loss: 2.278290649255117

Epoch: 6| Step: 1
Training loss: 0.3955491781234741
Validation loss: 2.269901772340139

Epoch: 6| Step: 2
Training loss: 0.192510187625885
Validation loss: 2.2000502347946167

Epoch: 6| Step: 3
Training loss: 0.44647908210754395
Validation loss: 2.197109599908193

Epoch: 6| Step: 4
Training loss: 0.3021955192089081
Validation loss: 2.217820147673289

Epoch: 6| Step: 5
Training loss: 0.2705666124820709
Validation loss: 2.1776765982309976

Epoch: 6| Step: 6
Training loss: 0.2616899013519287
Validation loss: 2.1833075284957886

Epoch: 6| Step: 7
Training loss: 0.5933395028114319
Validation loss: 2.165759265422821

Epoch: 6| Step: 8
Training loss: 0.2676735818386078
Validation loss: 2.216676672299703

Epoch: 6| Step: 9
Training loss: 0.9869530200958252
Validation loss: 2.1792656977971396

Epoch: 6| Step: 10
Training loss: 0.2926512062549591
Validation loss: 2.173223376274109

Epoch: 6| Step: 11
Training loss: 0.21149975061416626
Validation loss: 2.176001330216726

Epoch: 6| Step: 12
Training loss: 0.37280017137527466
Validation loss: 2.1889271338780723

Epoch: 6| Step: 13
Training loss: 0.4615160822868347
Validation loss: 2.210201700528463

Epoch: 283| Step: 0
Training loss: 0.2636363208293915
Validation loss: 2.188222885131836

Epoch: 6| Step: 1
Training loss: 0.18420471251010895
Validation loss: 2.2429455518722534

Epoch: 6| Step: 2
Training loss: 0.2045874297618866
Validation loss: 2.1761473615964255

Epoch: 6| Step: 3
Training loss: 0.20529112219810486
Validation loss: 2.1766865253448486

Epoch: 6| Step: 4
Training loss: 0.28552520275115967
Validation loss: 2.210392932097117

Epoch: 6| Step: 5
Training loss: 0.4759250283241272
Validation loss: 2.2428613702456155

Epoch: 6| Step: 6
Training loss: 0.2740277647972107
Validation loss: 2.2335583368937173

Epoch: 6| Step: 7
Training loss: 0.23779553174972534
Validation loss: 2.18806262811025

Epoch: 6| Step: 8
Training loss: 0.30075597763061523
Validation loss: 2.160380760828654

Epoch: 6| Step: 9
Training loss: 0.6187774538993835
Validation loss: 2.140679041544596

Epoch: 6| Step: 10
Training loss: 0.4896310567855835
Validation loss: 2.249035656452179

Epoch: 6| Step: 11
Training loss: 0.28559669852256775
Validation loss: 2.161589582761129

Epoch: 6| Step: 12
Training loss: 0.4812023937702179
Validation loss: 2.1823577086130777

Epoch: 6| Step: 13
Training loss: 0.8305752277374268
Validation loss: 2.1743424932161965

Epoch: 284| Step: 0
Training loss: 0.1894300878047943
Validation loss: 2.2062190771102905

Epoch: 6| Step: 1
Training loss: 0.3345125615596771
Validation loss: 2.2318808833758035

Epoch: 6| Step: 2
Training loss: 1.0190609693527222
Validation loss: 2.246934652328491

Epoch: 6| Step: 3
Training loss: 0.4568188190460205
Validation loss: 2.209920028845469

Epoch: 6| Step: 4
Training loss: 0.27361059188842773
Validation loss: 2.230720261732737

Epoch: 6| Step: 5
Training loss: 0.4141559302806854
Validation loss: 2.2007147073745728

Epoch: 6| Step: 6
Training loss: 0.4308181405067444
Validation loss: 2.186607042948405

Epoch: 6| Step: 7
Training loss: 0.17416566610336304
Validation loss: 2.232061783472697

Epoch: 6| Step: 8
Training loss: 0.2550812065601349
Validation loss: 2.2302925984064736

Epoch: 6| Step: 9
Training loss: 0.3376680612564087
Validation loss: 2.1667872865994773

Epoch: 6| Step: 10
Training loss: 0.5462135076522827
Validation loss: 2.223074734210968

Epoch: 6| Step: 11
Training loss: 0.3608109652996063
Validation loss: 2.2407691876093545

Epoch: 6| Step: 12
Training loss: 0.23678377270698547
Validation loss: 2.2191280722618103

Epoch: 6| Step: 13
Training loss: 0.3530835509300232
Validation loss: 2.219461361567179

Epoch: 285| Step: 0
Training loss: 0.3779589533805847
Validation loss: 2.2421767711639404

Epoch: 6| Step: 1
Training loss: 0.4047084152698517
Validation loss: 2.2428939739863076

Epoch: 6| Step: 2
Training loss: 0.344286173582077
Validation loss: 2.2280041178067527

Epoch: 6| Step: 3
Training loss: 0.24116122722625732
Validation loss: 2.2367834051450095

Epoch: 6| Step: 4
Training loss: 0.3534333109855652
Validation loss: 2.290780266125997

Epoch: 6| Step: 5
Training loss: 0.40078869462013245
Validation loss: 2.207087755203247

Epoch: 6| Step: 6
Training loss: 0.4203950762748718
Validation loss: 2.2643636067708335

Epoch: 6| Step: 7
Training loss: 0.5886036157608032
Validation loss: 2.21294367313385

Epoch: 6| Step: 8
Training loss: 0.21628175675868988
Validation loss: 2.2482321659723916

Epoch: 6| Step: 9
Training loss: 0.9764818549156189
Validation loss: 2.222021222114563

Epoch: 6| Step: 10
Training loss: 0.5598628520965576
Validation loss: 2.2311440110206604

Epoch: 6| Step: 11
Training loss: 0.48965558409690857
Validation loss: 2.1796959042549133

Epoch: 6| Step: 12
Training loss: 0.4312523305416107
Validation loss: 2.2269458770751953

Epoch: 6| Step: 13
Training loss: 0.2481015920639038
Validation loss: 2.2569850285847983

Epoch: 286| Step: 0
Training loss: 0.29393693804740906
Validation loss: 2.187963863213857

Epoch: 6| Step: 1
Training loss: 0.3570935130119324
Validation loss: 2.2788469990094504

Epoch: 6| Step: 2
Training loss: 0.3925740718841553
Validation loss: 2.1735936204592385

Epoch: 6| Step: 3
Training loss: 0.3103090226650238
Validation loss: 2.2253918846448264

Epoch: 6| Step: 4
Training loss: 0.3205093741416931
Validation loss: 2.2071183919906616

Epoch: 6| Step: 5
Training loss: 0.5666121244430542
Validation loss: 2.2732806404431662

Epoch: 6| Step: 6
Training loss: 0.31335681676864624
Validation loss: 2.204245448112488

Epoch: 6| Step: 7
Training loss: 0.34356188774108887
Validation loss: 2.2228222489356995

Epoch: 6| Step: 8
Training loss: 0.49071210622787476
Validation loss: 2.212934454282125

Epoch: 6| Step: 9
Training loss: 0.3442092835903168
Validation loss: 2.2262067596117654

Epoch: 6| Step: 10
Training loss: 0.44243404269218445
Validation loss: 2.2263517578442893

Epoch: 6| Step: 11
Training loss: 0.3173554539680481
Validation loss: 2.2015223701794944

Epoch: 6| Step: 12
Training loss: 0.6275267601013184
Validation loss: 2.210083862145742

Epoch: 6| Step: 13
Training loss: 0.6987714171409607
Validation loss: 2.272132237752279

Epoch: 287| Step: 0
Training loss: 0.9494743943214417
Validation loss: 2.2493531306584678

Epoch: 6| Step: 1
Training loss: 0.19027426838874817
Validation loss: 2.2534092466036477

Epoch: 6| Step: 2
Training loss: 0.2736826539039612
Validation loss: 2.2060551047325134

Epoch: 6| Step: 3
Training loss: 0.2675669193267822
Validation loss: 2.2461455861727395

Epoch: 6| Step: 4
Training loss: 0.34647583961486816
Validation loss: 2.207905411720276

Epoch: 6| Step: 5
Training loss: 0.23509976267814636
Validation loss: 2.191565970579783

Epoch: 6| Step: 6
Training loss: 0.30252596735954285
Validation loss: 2.237321197986603

Epoch: 6| Step: 7
Training loss: 0.3920292854309082
Validation loss: 2.1857601006825766

Epoch: 6| Step: 8
Training loss: 0.24209165573120117
Validation loss: 2.197767893473307

Epoch: 6| Step: 9
Training loss: 0.4705919325351715
Validation loss: 2.2021230856577554

Epoch: 6| Step: 10
Training loss: 0.6355991363525391
Validation loss: 2.2112293243408203

Epoch: 6| Step: 11
Training loss: 0.5271885395050049
Validation loss: 2.1836964090665183

Epoch: 6| Step: 12
Training loss: 0.2932431697845459
Validation loss: 2.2132198214530945

Epoch: 6| Step: 13
Training loss: 0.2871531546115875
Validation loss: 2.2374870777130127

Epoch: 288| Step: 0
Training loss: 0.23127636313438416
Validation loss: 2.179705818494161

Epoch: 6| Step: 1
Training loss: 0.2486853301525116
Validation loss: 2.2099684675534568

Epoch: 6| Step: 2
Training loss: 0.3194829821586609
Validation loss: 2.2438493569691977

Epoch: 6| Step: 3
Training loss: 0.6587626934051514
Validation loss: 2.2179130713144937

Epoch: 6| Step: 4
Training loss: 0.6095256209373474
Validation loss: 2.236205299695333

Epoch: 6| Step: 5
Training loss: 0.23657628893852234
Validation loss: 2.2386995553970337

Epoch: 6| Step: 6
Training loss: 0.4009859263896942
Validation loss: 2.2077685991923013

Epoch: 6| Step: 7
Training loss: 0.5351909399032593
Validation loss: 2.295855442682902

Epoch: 6| Step: 8
Training loss: 0.29592248797416687
Validation loss: 2.216502845287323

Epoch: 6| Step: 9
Training loss: 0.3613388240337372
Validation loss: 2.199117104212443

Epoch: 6| Step: 10
Training loss: 0.3798672556877136
Validation loss: 2.200752854347229

Epoch: 6| Step: 11
Training loss: 0.4854995608329773
Validation loss: 2.22857137521108

Epoch: 6| Step: 12
Training loss: 0.8072269558906555
Validation loss: 2.2423408230145774

Epoch: 6| Step: 13
Training loss: 0.4412676990032196
Validation loss: 2.1823994517326355

Epoch: 289| Step: 0
Training loss: 0.8340173363685608
Validation loss: 2.2268980741500854

Epoch: 6| Step: 1
Training loss: 0.35536596179008484
Validation loss: 2.1749576131502786

Epoch: 6| Step: 2
Training loss: 0.3589228391647339
Validation loss: 2.232417623202006

Epoch: 6| Step: 3
Training loss: 0.317682683467865
Validation loss: 2.197707414627075

Epoch: 6| Step: 4
Training loss: 0.4144739508628845
Validation loss: 2.2036163409550986

Epoch: 6| Step: 5
Training loss: 0.3208949863910675
Validation loss: 2.2254220048586526

Epoch: 6| Step: 6
Training loss: 0.2701961100101471
Validation loss: 2.1951992511749268

Epoch: 6| Step: 7
Training loss: 0.2880069613456726
Validation loss: 2.224498152732849

Epoch: 6| Step: 8
Training loss: 0.3055686354637146
Validation loss: 2.2391079862912497

Epoch: 6| Step: 9
Training loss: 0.3573703169822693
Validation loss: 2.2393529812494912

Epoch: 6| Step: 10
Training loss: 0.41667234897613525
Validation loss: 2.2414622704188027

Epoch: 6| Step: 11
Training loss: 0.4650886058807373
Validation loss: 2.231600344181061

Epoch: 6| Step: 12
Training loss: 0.8366901874542236
Validation loss: 2.220436910788218

Epoch: 6| Step: 13
Training loss: 0.398490846157074
Validation loss: 2.2489559054374695

Epoch: 290| Step: 0
Training loss: 0.47507089376449585
Validation loss: 2.2204834620157876

Epoch: 6| Step: 1
Training loss: 0.2834843397140503
Validation loss: 2.194658319155375

Epoch: 6| Step: 2
Training loss: 0.572048544883728
Validation loss: 2.259788155555725

Epoch: 6| Step: 3
Training loss: 0.4272180199623108
Validation loss: 2.2639514605204263

Epoch: 6| Step: 4
Training loss: 0.5265082716941833
Validation loss: 2.248099207878113

Epoch: 6| Step: 5
Training loss: 0.38416844606399536
Validation loss: 2.2277214725812278

Epoch: 6| Step: 6
Training loss: 0.4130159020423889
Validation loss: 2.2364945809046426

Epoch: 6| Step: 7
Training loss: 0.32078519463539124
Validation loss: 2.183584968249003

Epoch: 6| Step: 8
Training loss: 0.43741685152053833
Validation loss: 2.203908920288086

Epoch: 6| Step: 9
Training loss: 0.534642219543457
Validation loss: 2.255197803179423

Epoch: 6| Step: 10
Training loss: 0.3857106864452362
Validation loss: 2.2159865697224936

Epoch: 6| Step: 11
Training loss: 0.6950385570526123
Validation loss: 2.235694150129954

Epoch: 6| Step: 12
Training loss: 0.3280162513256073
Validation loss: 2.264577567577362

Epoch: 6| Step: 13
Training loss: 0.3399774134159088
Validation loss: 2.2751981218655906

Epoch: 291| Step: 0
Training loss: 0.5808079242706299
Validation loss: 2.235485871632894

Epoch: 6| Step: 1
Training loss: 0.4562593102455139
Validation loss: 2.282973527908325

Epoch: 6| Step: 2
Training loss: 0.6992673873901367
Validation loss: 2.2312933206558228

Epoch: 6| Step: 3
Training loss: 0.35448622703552246
Validation loss: 2.2635446588198342

Epoch: 6| Step: 4
Training loss: 0.3139975666999817
Validation loss: 2.2524327437082925

Epoch: 6| Step: 5
Training loss: 0.43668460845947266
Validation loss: 2.2209397355715432

Epoch: 6| Step: 6
Training loss: 0.46296924352645874
Validation loss: 2.2770903507868447

Epoch: 6| Step: 7
Training loss: 0.3279670476913452
Validation loss: 2.205122093359629

Epoch: 6| Step: 8
Training loss: 0.7511045932769775
Validation loss: 2.238847633202871

Epoch: 6| Step: 9
Training loss: 0.31301891803741455
Validation loss: 2.2322517037391663

Epoch: 6| Step: 10
Training loss: 0.50971519947052
Validation loss: 2.2504014571507773

Epoch: 6| Step: 11
Training loss: 0.388993501663208
Validation loss: 2.2735971411069236

Epoch: 6| Step: 12
Training loss: 0.5438148975372314
Validation loss: 2.2270363569259644

Epoch: 6| Step: 13
Training loss: 0.4484228491783142
Validation loss: 2.2460437615712485

Epoch: 292| Step: 0
Training loss: 0.20344045758247375
Validation loss: 2.2348708510398865

Epoch: 6| Step: 1
Training loss: 0.48159608244895935
Validation loss: 2.214284837245941

Epoch: 6| Step: 2
Training loss: 0.5996623635292053
Validation loss: 2.2271750966707864

Epoch: 6| Step: 3
Training loss: 0.4051727056503296
Validation loss: 2.229180077711741

Epoch: 6| Step: 4
Training loss: 0.42725449800491333
Validation loss: 2.1916134357452393

Epoch: 6| Step: 5
Training loss: 0.18301470577716827
Validation loss: 2.2625688115755715

Epoch: 6| Step: 6
Training loss: 0.6731061339378357
Validation loss: 2.226542870203654

Epoch: 6| Step: 7
Training loss: 0.275324285030365
Validation loss: 2.196661372979482

Epoch: 6| Step: 8
Training loss: 0.472504198551178
Validation loss: 2.211414853731791

Epoch: 6| Step: 9
Training loss: 0.386177659034729
Validation loss: 2.180108686288198

Epoch: 6| Step: 10
Training loss: 0.30095338821411133
Validation loss: 2.240774949391683

Epoch: 6| Step: 11
Training loss: 0.39863860607147217
Validation loss: 2.208186407883962

Epoch: 6| Step: 12
Training loss: 0.4687541425228119
Validation loss: 2.241406520207723

Epoch: 6| Step: 13
Training loss: 0.4079161286354065
Validation loss: 2.216897169748942

Epoch: 293| Step: 0
Training loss: 0.31832098960876465
Validation loss: 2.246250053246816

Epoch: 6| Step: 1
Training loss: 0.29205119609832764
Validation loss: 2.1922184427579245

Epoch: 6| Step: 2
Training loss: 0.28592216968536377
Validation loss: 2.2713658809661865

Epoch: 6| Step: 3
Training loss: 0.16746899485588074
Validation loss: 2.205867052078247

Epoch: 6| Step: 4
Training loss: 0.24060848355293274
Validation loss: 2.2653885881106057

Epoch: 6| Step: 5
Training loss: 0.4488956332206726
Validation loss: 2.2317063013712564

Epoch: 6| Step: 6
Training loss: 0.3199412524700165
Validation loss: 2.2339779337247214

Epoch: 6| Step: 7
Training loss: 0.3453931212425232
Validation loss: 2.1916444897651672

Epoch: 6| Step: 8
Training loss: 0.42682522535324097
Validation loss: 2.227962930997213

Epoch: 6| Step: 9
Training loss: 0.32642918825149536
Validation loss: 2.264298915863037

Epoch: 6| Step: 10
Training loss: 0.7071594595909119
Validation loss: 2.2139013409614563

Epoch: 6| Step: 11
Training loss: 0.41301077604293823
Validation loss: 2.1942543188730874

Epoch: 6| Step: 12
Training loss: 0.3714390993118286
Validation loss: 2.175403972466787

Epoch: 6| Step: 13
Training loss: 0.7752817869186401
Validation loss: 2.245304445425669

Epoch: 294| Step: 0
Training loss: 0.16503426432609558
Validation loss: 2.2541988094647727

Epoch: 6| Step: 1
Training loss: 0.3990926146507263
Validation loss: 2.2529677549997964

Epoch: 6| Step: 2
Training loss: 0.23876576125621796
Validation loss: 2.2475555737813315

Epoch: 6| Step: 3
Training loss: 0.4567130208015442
Validation loss: 2.246335824330648

Epoch: 6| Step: 4
Training loss: 0.22014370560646057
Validation loss: 2.2184508244196572

Epoch: 6| Step: 5
Training loss: 0.39615294337272644
Validation loss: 2.200814445813497

Epoch: 6| Step: 6
Training loss: 0.24785301089286804
Validation loss: 2.220094859600067

Epoch: 6| Step: 7
Training loss: 0.449248343706131
Validation loss: 2.2186853885650635

Epoch: 6| Step: 8
Training loss: 0.7758998870849609
Validation loss: 2.225088278452555

Epoch: 6| Step: 9
Training loss: 0.1461608111858368
Validation loss: 2.2626585563023887

Epoch: 6| Step: 10
Training loss: 0.36608707904815674
Validation loss: 2.263358414173126

Epoch: 6| Step: 11
Training loss: 0.3413175940513611
Validation loss: 2.224665641784668

Epoch: 6| Step: 12
Training loss: 0.3528302013874054
Validation loss: 2.2263808449109397

Epoch: 6| Step: 13
Training loss: 0.6579426527023315
Validation loss: 2.206476390361786

Epoch: 295| Step: 0
Training loss: 0.17858147621154785
Validation loss: 2.2730116645495095

Epoch: 6| Step: 1
Training loss: 0.5772663354873657
Validation loss: 2.275850315888723

Epoch: 6| Step: 2
Training loss: 0.2632501721382141
Validation loss: 2.2660772800445557

Epoch: 6| Step: 3
Training loss: 0.3689619302749634
Validation loss: 2.251936952273051

Epoch: 6| Step: 4
Training loss: 0.24779778718948364
Validation loss: 2.276566525300344

Epoch: 6| Step: 5
Training loss: 0.531728982925415
Validation loss: 2.230729858080546

Epoch: 6| Step: 6
Training loss: 0.3206736743450165
Validation loss: 2.2468494176864624

Epoch: 6| Step: 7
Training loss: 0.22679436206817627
Validation loss: 2.2661147912343345

Epoch: 6| Step: 8
Training loss: 0.3546792268753052
Validation loss: 2.2428643703460693

Epoch: 6| Step: 9
Training loss: 0.3429785966873169
Validation loss: 2.2726441820462546

Epoch: 6| Step: 10
Training loss: 0.5435175895690918
Validation loss: 2.1860807140668235

Epoch: 6| Step: 11
Training loss: 0.2285355180501938
Validation loss: 2.18933097521464

Epoch: 6| Step: 12
Training loss: 0.8206859230995178
Validation loss: 2.241643210252126

Epoch: 6| Step: 13
Training loss: 0.17377787828445435
Validation loss: 2.202407439549764

Epoch: 296| Step: 0
Training loss: 0.3909231424331665
Validation loss: 2.2345380385716758

Epoch: 6| Step: 1
Training loss: 0.3853379189968109
Validation loss: 2.22760933637619

Epoch: 6| Step: 2
Training loss: 0.2070005238056183
Validation loss: 2.2847474813461304

Epoch: 6| Step: 3
Training loss: 0.280619740486145
Validation loss: 2.233713905016581

Epoch: 6| Step: 4
Training loss: 0.30053770542144775
Validation loss: 2.2540853023529053

Epoch: 6| Step: 5
Training loss: 0.4817800521850586
Validation loss: 2.299812912940979

Epoch: 6| Step: 6
Training loss: 0.5814622044563293
Validation loss: 2.2428170442581177

Epoch: 6| Step: 7
Training loss: 0.33647406101226807
Validation loss: 2.207547644774119

Epoch: 6| Step: 8
Training loss: 0.2892914414405823
Validation loss: 2.2236403624216714

Epoch: 6| Step: 9
Training loss: 0.41545113921165466
Validation loss: 2.222467919190725

Epoch: 6| Step: 10
Training loss: 0.4726252555847168
Validation loss: 2.1824413339296975

Epoch: 6| Step: 11
Training loss: 0.22459876537322998
Validation loss: 2.197510540485382

Epoch: 6| Step: 12
Training loss: 0.22118790447711945
Validation loss: 2.202884038289388

Epoch: 6| Step: 13
Training loss: 0.9057714939117432
Validation loss: 2.1732594768206277

Epoch: 297| Step: 0
Training loss: 0.22873817384243011
Validation loss: 2.2350937525431314

Epoch: 6| Step: 1
Training loss: 0.6916395425796509
Validation loss: 2.1972471872965493

Epoch: 6| Step: 2
Training loss: 0.22669143974781036
Validation loss: 2.1519065499305725

Epoch: 6| Step: 3
Training loss: 0.34194415807724
Validation loss: 2.227400283018748

Epoch: 6| Step: 4
Training loss: 0.32794928550720215
Validation loss: 2.211240569750468

Epoch: 6| Step: 5
Training loss: 0.4016382694244385
Validation loss: 2.262570242087046

Epoch: 6| Step: 6
Training loss: 0.5173807740211487
Validation loss: 2.1820050279299417

Epoch: 6| Step: 7
Training loss: 0.2910315990447998
Validation loss: 2.2747671604156494

Epoch: 6| Step: 8
Training loss: 0.6528574824333191
Validation loss: 2.281466861565908

Epoch: 6| Step: 9
Training loss: 0.23518885672092438
Validation loss: 2.2170207500457764

Epoch: 6| Step: 10
Training loss: 0.3254270553588867
Validation loss: 2.209956248601278

Epoch: 6| Step: 11
Training loss: 0.4056304693222046
Validation loss: 2.2263194918632507

Epoch: 6| Step: 12
Training loss: 0.23315200209617615
Validation loss: 2.2287232677141824

Epoch: 6| Step: 13
Training loss: 0.26650118827819824
Validation loss: 2.221092859903971

Epoch: 298| Step: 0
Training loss: 0.23976463079452515
Validation loss: 2.2203521927197776

Epoch: 6| Step: 1
Training loss: 0.5514642000198364
Validation loss: 2.2903659542401633

Epoch: 6| Step: 2
Training loss: 0.4190436899662018
Validation loss: 2.2416072487831116

Epoch: 6| Step: 3
Training loss: 0.2965363562107086
Validation loss: 2.221660772959391

Epoch: 6| Step: 4
Training loss: 0.27101805806159973
Validation loss: 2.221940596898397

Epoch: 6| Step: 5
Training loss: 0.40185871720314026
Validation loss: 2.242144505182902

Epoch: 6| Step: 6
Training loss: 0.4794383943080902
Validation loss: 2.2382935682932534

Epoch: 6| Step: 7
Training loss: 0.5962355136871338
Validation loss: 2.2252056996027627

Epoch: 6| Step: 8
Training loss: 0.6785829067230225
Validation loss: 2.2321671843528748

Epoch: 6| Step: 9
Training loss: 0.2534048557281494
Validation loss: 2.3046993414560952

Epoch: 6| Step: 10
Training loss: 0.40480518341064453
Validation loss: 2.229690968990326

Epoch: 6| Step: 11
Training loss: 0.2708406448364258
Validation loss: 2.2258413434028625

Epoch: 6| Step: 12
Training loss: 0.3245781362056732
Validation loss: 2.2882898251215615

Epoch: 6| Step: 13
Training loss: 0.39401423931121826
Validation loss: 2.2374592622121177

Epoch: 299| Step: 0
Training loss: 0.29645276069641113
Validation loss: 2.2076520323753357

Epoch: 6| Step: 1
Training loss: 0.5199490785598755
Validation loss: 2.1909597714742026

Epoch: 6| Step: 2
Training loss: 0.27770882844924927
Validation loss: 2.252284049987793

Epoch: 6| Step: 3
Training loss: 0.30151844024658203
Validation loss: 2.2143577933311462

Epoch: 6| Step: 4
Training loss: 0.436512291431427
Validation loss: 2.2205008268356323

Epoch: 6| Step: 5
Training loss: 0.29985421895980835
Validation loss: 2.23338782787323

Epoch: 6| Step: 6
Training loss: 0.45007193088531494
Validation loss: 2.236053188641866

Epoch: 6| Step: 7
Training loss: 0.7727806568145752
Validation loss: 2.247433145840963

Epoch: 6| Step: 8
Training loss: 0.4639163315296173
Validation loss: 2.2228536009788513

Epoch: 6| Step: 9
Training loss: 0.236034095287323
Validation loss: 2.2165040969848633

Epoch: 6| Step: 10
Training loss: 0.2697813808917999
Validation loss: 2.207796812057495

Epoch: 6| Step: 11
Training loss: 0.42113178968429565
Validation loss: 2.198949376742045

Epoch: 6| Step: 12
Training loss: 0.46391060948371887
Validation loss: 2.2295814156532288

Epoch: 6| Step: 13
Training loss: 0.3103654682636261
Validation loss: 2.2613229751586914

Epoch: 300| Step: 0
Training loss: 0.6399675607681274
Validation loss: 2.2231014569600425

Epoch: 6| Step: 1
Training loss: 0.8050113916397095
Validation loss: 2.219009220600128

Epoch: 6| Step: 2
Training loss: 0.2585684061050415
Validation loss: 2.185063282648722

Epoch: 6| Step: 3
Training loss: 0.29264408349990845
Validation loss: 2.202656865119934

Epoch: 6| Step: 4
Training loss: 0.4517420530319214
Validation loss: 2.2509939471880593

Epoch: 6| Step: 5
Training loss: 0.2758978605270386
Validation loss: 2.2081878582636514

Epoch: 6| Step: 6
Training loss: 0.16112002730369568
Validation loss: 2.211308399836222

Epoch: 6| Step: 7
Training loss: 0.3037896752357483
Validation loss: 2.2376831769943237

Epoch: 6| Step: 8
Training loss: 0.2856610417366028
Validation loss: 2.227689584096273

Epoch: 6| Step: 9
Training loss: 0.36419618129730225
Validation loss: 2.2590394218762717

Epoch: 6| Step: 10
Training loss: 0.48192209005355835
Validation loss: 2.2230326334635415

Epoch: 6| Step: 11
Training loss: 0.25565671920776367
Validation loss: 2.2053229014078775

Epoch: 6| Step: 12
Training loss: 0.42477521300315857
Validation loss: 2.238571027914683

Epoch: 6| Step: 13
Training loss: 0.29684239625930786
Validation loss: 2.2663307189941406

Testing loss: 2.090515092122469
