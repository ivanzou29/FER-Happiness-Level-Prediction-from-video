Epoch: 1| Step: 0
Training loss: 4.627968788146973
Validation loss: 4.16088604927063

Epoch: 6| Step: 1
Training loss: 4.2498321533203125
Validation loss: 4.13455859820048

Epoch: 6| Step: 2
Training loss: 4.504956245422363
Validation loss: 4.108320911725362

Epoch: 6| Step: 3
Training loss: 4.351836681365967
Validation loss: 4.087237199147542

Epoch: 6| Step: 4
Training loss: 4.475216388702393
Validation loss: 4.063191811243693

Epoch: 6| Step: 5
Training loss: 3.9103827476501465
Validation loss: 4.039515495300293

Epoch: 6| Step: 6
Training loss: 3.603619337081909
Validation loss: 4.016762216885884

Epoch: 6| Step: 7
Training loss: 3.8626739978790283
Validation loss: 3.993292768796285

Epoch: 6| Step: 8
Training loss: 3.0814812183380127
Validation loss: 3.970935821533203

Epoch: 6| Step: 9
Training loss: 3.14793062210083
Validation loss: 3.948481877644857

Epoch: 6| Step: 10
Training loss: 3.7938146591186523
Validation loss: 3.9264453649520874

Epoch: 6| Step: 11
Training loss: 4.733692169189453
Validation loss: 3.904189109802246

Epoch: 6| Step: 12
Training loss: 5.223594665527344
Validation loss: 3.881136894226074

Epoch: 6| Step: 13
Training loss: 4.446691036224365
Validation loss: 3.8584587574005127

Epoch: 2| Step: 0
Training loss: 3.0526692867279053
Validation loss: 3.8347808917363486

Epoch: 6| Step: 1
Training loss: 4.110437393188477
Validation loss: 3.8112173080444336

Epoch: 6| Step: 2
Training loss: 4.270614147186279
Validation loss: 3.78749414285024

Epoch: 6| Step: 3
Training loss: 3.5655012130737305
Validation loss: 3.7593324979146323

Epoch: 6| Step: 4
Training loss: 4.174149036407471
Validation loss: 3.7328943411509194

Epoch: 6| Step: 5
Training loss: 3.3148903846740723
Validation loss: 3.7055378754933677

Epoch: 6| Step: 6
Training loss: 4.901887893676758
Validation loss: 3.6763784885406494

Epoch: 6| Step: 7
Training loss: 4.868877410888672
Validation loss: 3.6479673385620117

Epoch: 6| Step: 8
Training loss: 3.8909823894500732
Validation loss: 3.6181877056757608

Epoch: 6| Step: 9
Training loss: 3.5815954208374023
Validation loss: 3.5876746575037637

Epoch: 6| Step: 10
Training loss: 3.307084083557129
Validation loss: 3.5542180935541787

Epoch: 6| Step: 11
Training loss: 4.439384460449219
Validation loss: 3.5206148624420166

Epoch: 6| Step: 12
Training loss: 2.6905570030212402
Validation loss: 3.490911920865377

Epoch: 6| Step: 13
Training loss: 3.0472302436828613
Validation loss: 3.4500914812088013

Epoch: 3| Step: 0
Training loss: 3.397644519805908
Validation loss: 3.4184670448303223

Epoch: 6| Step: 1
Training loss: 3.8271090984344482
Validation loss: 3.384469906489054

Epoch: 6| Step: 2
Training loss: 3.568603992462158
Validation loss: 3.3399418195088706

Epoch: 6| Step: 3
Training loss: 2.3103866577148438
Validation loss: 3.3044594526290894

Epoch: 6| Step: 4
Training loss: 3.1389312744140625
Validation loss: 3.265318274497986

Epoch: 6| Step: 5
Training loss: 3.4444589614868164
Validation loss: 3.2255788246790567

Epoch: 6| Step: 6
Training loss: 3.242302417755127
Validation loss: 3.1864027182261148

Epoch: 6| Step: 7
Training loss: 3.7244253158569336
Validation loss: 3.137851079305013

Epoch: 6| Step: 8
Training loss: 3.6190271377563477
Validation loss: 3.095954259236654

Epoch: 6| Step: 9
Training loss: 3.2091617584228516
Validation loss: 3.052212675412496

Epoch: 6| Step: 10
Training loss: 3.047588348388672
Validation loss: 3.0082759062449136

Epoch: 6| Step: 11
Training loss: 2.8727941513061523
Validation loss: 2.9647898276646933

Epoch: 6| Step: 12
Training loss: 3.2237563133239746
Validation loss: 2.9094873666763306

Epoch: 6| Step: 13
Training loss: 3.1363463401794434
Validation loss: 2.8634384870529175

Epoch: 4| Step: 0
Training loss: 2.86873459815979
Validation loss: 2.815502921740214

Epoch: 6| Step: 1
Training loss: 3.490757942199707
Validation loss: 2.761469999949137

Epoch: 6| Step: 2
Training loss: 1.7995851039886475
Validation loss: 2.6982662677764893

Epoch: 6| Step: 3
Training loss: 3.016828775405884
Validation loss: 2.645113945007324

Epoch: 6| Step: 4
Training loss: 2.8004043102264404
Validation loss: 2.575014273325602

Epoch: 6| Step: 5
Training loss: 2.732975959777832
Validation loss: 2.512485464413961

Epoch: 6| Step: 6
Training loss: 2.576436758041382
Validation loss: 2.432607591152191

Epoch: 6| Step: 7
Training loss: 2.2733969688415527
Validation loss: 2.3716047207514444

Epoch: 6| Step: 8
Training loss: 2.386941432952881
Validation loss: 2.308220108350118

Epoch: 6| Step: 9
Training loss: 2.6124606132507324
Validation loss: 2.2612425088882446

Epoch: 6| Step: 10
Training loss: 2.8193109035491943
Validation loss: 2.212798555692037

Epoch: 6| Step: 11
Training loss: 2.4666738510131836
Validation loss: 2.170114040374756

Epoch: 6| Step: 12
Training loss: 2.32682204246521
Validation loss: 2.1197293599446616

Epoch: 6| Step: 13
Training loss: 2.1286816596984863
Validation loss: 2.0977569222450256

Epoch: 5| Step: 0
Training loss: 2.3136582374572754
Validation loss: 2.0668684045473733

Epoch: 6| Step: 1
Training loss: 2.003986358642578
Validation loss: 2.0392072995503745

Epoch: 6| Step: 2
Training loss: 1.9672915935516357
Validation loss: 2.0262038906415305

Epoch: 6| Step: 3
Training loss: 1.8673676252365112
Validation loss: 2.0111281474431357

Epoch: 6| Step: 4
Training loss: 1.1887321472167969
Validation loss: 2.0117887258529663

Epoch: 6| Step: 5
Training loss: 2.364773750305176
Validation loss: 2.0123319029808044

Epoch: 6| Step: 6
Training loss: 1.983936071395874
Validation loss: 2.0275166034698486

Epoch: 6| Step: 7
Training loss: 1.6122673749923706
Validation loss: 2.0373743375142417

Epoch: 6| Step: 8
Training loss: 2.6248667240142822
Validation loss: 2.052941064039866

Epoch: 6| Step: 9
Training loss: 2.718047618865967
Validation loss: 2.056148032347361

Epoch: 6| Step: 10
Training loss: 2.246352434158325
Validation loss: 2.045373539129893

Epoch: 6| Step: 11
Training loss: 2.372285842895508
Validation loss: 2.041673998037974

Epoch: 6| Step: 12
Training loss: 2.445023775100708
Validation loss: 2.029733339945475

Epoch: 6| Step: 13
Training loss: 2.667560577392578
Validation loss: 2.0214390953381858

Epoch: 6| Step: 0
Training loss: 2.001753807067871
Validation loss: 2.004933019479116

Epoch: 6| Step: 1
Training loss: 1.880350947380066
Validation loss: 2.002333660920461

Epoch: 6| Step: 2
Training loss: 2.139871597290039
Validation loss: 2.010528087615967

Epoch: 6| Step: 3
Training loss: 2.431692361831665
Validation loss: 1.9966331720352173

Epoch: 6| Step: 4
Training loss: 2.3712093830108643
Validation loss: 2.002306818962097

Epoch: 6| Step: 5
Training loss: 1.9658527374267578
Validation loss: 1.9934146006902058

Epoch: 6| Step: 6
Training loss: 2.3326218128204346
Validation loss: 2.0005337397257485

Epoch: 6| Step: 7
Training loss: 2.1114749908447266
Validation loss: 2.0011926690737405

Epoch: 6| Step: 8
Training loss: 2.3545401096343994
Validation loss: 2.0042567451794944

Epoch: 6| Step: 9
Training loss: 2.2380032539367676
Validation loss: 1.9983850121498108

Epoch: 6| Step: 10
Training loss: 1.6468579769134521
Validation loss: 2.0045770009358725

Epoch: 6| Step: 11
Training loss: 2.427253246307373
Validation loss: 1.990997890631358

Epoch: 6| Step: 12
Training loss: 1.6843018531799316
Validation loss: 2.009240984916687

Epoch: 6| Step: 13
Training loss: 1.6690322160720825
Validation loss: 2.0147257844607034

Epoch: 7| Step: 0
Training loss: 1.7945271730422974
Validation loss: 2.0055431127548218

Epoch: 6| Step: 1
Training loss: 1.8467153310775757
Validation loss: 2.007019897301992

Epoch: 6| Step: 2
Training loss: 1.3904008865356445
Validation loss: 2.0148834188779197

Epoch: 6| Step: 3
Training loss: 2.0611438751220703
Validation loss: 1.9909756580988567

Epoch: 6| Step: 4
Training loss: 2.255354881286621
Validation loss: 1.9914618531862895

Epoch: 6| Step: 5
Training loss: 2.1322765350341797
Validation loss: 1.987122635046641

Epoch: 6| Step: 6
Training loss: 2.5504181385040283
Validation loss: 1.973588764667511

Epoch: 6| Step: 7
Training loss: 2.254237174987793
Validation loss: 1.9832917054494221

Epoch: 6| Step: 8
Training loss: 2.7430710792541504
Validation loss: 1.9931087692578633

Epoch: 6| Step: 9
Training loss: 2.3858463764190674
Validation loss: 1.9986655712127686

Epoch: 6| Step: 10
Training loss: 1.6511739492416382
Validation loss: 1.9958921074867249

Epoch: 6| Step: 11
Training loss: 1.934761881828308
Validation loss: 1.9907406369845073

Epoch: 6| Step: 12
Training loss: 2.021085023880005
Validation loss: 2.0086292823155723

Epoch: 6| Step: 13
Training loss: 2.372671365737915
Validation loss: 1.9756789008776348

Epoch: 8| Step: 0
Training loss: 2.607470989227295
Validation loss: 1.9861552516619365

Epoch: 6| Step: 1
Training loss: 2.0917975902557373
Validation loss: 1.9791730443636577

Epoch: 6| Step: 2
Training loss: 1.8713135719299316
Validation loss: 1.9770877559979756

Epoch: 6| Step: 3
Training loss: 2.1379621028900146
Validation loss: 1.9951866070429485

Epoch: 6| Step: 4
Training loss: 2.197801113128662
Validation loss: 1.989120622475942

Epoch: 6| Step: 5
Training loss: 1.8629541397094727
Validation loss: 1.982381006081899

Epoch: 6| Step: 6
Training loss: 1.4198315143585205
Validation loss: 1.9693866968154907

Epoch: 6| Step: 7
Training loss: 1.9357376098632812
Validation loss: 1.98798269033432

Epoch: 6| Step: 8
Training loss: 1.7088449001312256
Validation loss: 1.9801303148269653

Epoch: 6| Step: 9
Training loss: 2.169541358947754
Validation loss: 1.9823914766311646

Epoch: 6| Step: 10
Training loss: 2.6202340126037598
Validation loss: 1.9698800841967266

Epoch: 6| Step: 11
Training loss: 2.416949987411499
Validation loss: 1.988492985566457

Epoch: 6| Step: 12
Training loss: 1.9105987548828125
Validation loss: 1.9793335795402527

Epoch: 6| Step: 13
Training loss: 1.9746485948562622
Validation loss: 1.9807046055793762

Epoch: 9| Step: 0
Training loss: 2.173920154571533
Validation loss: 1.9774272044499714

Epoch: 6| Step: 1
Training loss: 1.831871747970581
Validation loss: 1.9856083393096924

Epoch: 6| Step: 2
Training loss: 2.4449238777160645
Validation loss: 1.9714207251866658

Epoch: 6| Step: 3
Training loss: 2.028618574142456
Validation loss: 1.9793565273284912

Epoch: 6| Step: 4
Training loss: 2.410277843475342
Validation loss: 1.9828029076258342

Epoch: 6| Step: 5
Training loss: 2.1772656440734863
Validation loss: 1.9839784701665242

Epoch: 6| Step: 6
Training loss: 1.722786784172058
Validation loss: 1.983867883682251

Epoch: 6| Step: 7
Training loss: 1.4436848163604736
Validation loss: 1.9728174010912578

Epoch: 6| Step: 8
Training loss: 2.948517322540283
Validation loss: 1.979586621125539

Epoch: 6| Step: 9
Training loss: 2.0671164989471436
Validation loss: 1.9765513737996419

Epoch: 6| Step: 10
Training loss: 1.3693184852600098
Validation loss: 1.9712368249893188

Epoch: 6| Step: 11
Training loss: 2.3874258995056152
Validation loss: 1.9698750774065654

Epoch: 6| Step: 12
Training loss: 1.8433952331542969
Validation loss: 1.9694077571233113

Epoch: 6| Step: 13
Training loss: 1.8941515684127808
Validation loss: 1.9678532878557842

Epoch: 10| Step: 0
Training loss: 1.8185633420944214
Validation loss: 1.9670659899711609

Epoch: 6| Step: 1
Training loss: 2.3001856803894043
Validation loss: 1.965868314107259

Epoch: 6| Step: 2
Training loss: 2.0949935913085938
Validation loss: 1.9790029128392537

Epoch: 6| Step: 3
Training loss: 1.5866388082504272
Validation loss: 1.9718692501386006

Epoch: 6| Step: 4
Training loss: 1.5306881666183472
Validation loss: 1.9789173205693562

Epoch: 6| Step: 5
Training loss: 2.1432719230651855
Validation loss: 1.9553455710411072

Epoch: 6| Step: 6
Training loss: 2.355637550354004
Validation loss: 1.976438005765279

Epoch: 6| Step: 7
Training loss: 1.4721062183380127
Validation loss: 1.9750077923138936

Epoch: 6| Step: 8
Training loss: 2.212775945663452
Validation loss: 1.9651984771092732

Epoch: 6| Step: 9
Training loss: 2.309235095977783
Validation loss: 1.9866980115572612

Epoch: 6| Step: 10
Training loss: 2.0362462997436523
Validation loss: 1.9895357886950176

Epoch: 6| Step: 11
Training loss: 2.2762436866760254
Validation loss: 1.9712124665578206

Epoch: 6| Step: 12
Training loss: 2.0164132118225098
Validation loss: 1.9828633666038513

Epoch: 6| Step: 13
Training loss: 2.5023391246795654
Validation loss: 1.967870791753133

Epoch: 11| Step: 0
Training loss: 2.5509822368621826
Validation loss: 1.985562841097514

Epoch: 6| Step: 1
Training loss: 2.442708730697632
Validation loss: 1.968489368756612

Epoch: 6| Step: 2
Training loss: 1.6383450031280518
Validation loss: 1.9630536437034607

Epoch: 6| Step: 3
Training loss: 1.8153481483459473
Validation loss: 1.9647379120190938

Epoch: 6| Step: 4
Training loss: 2.5234756469726562
Validation loss: 1.966647485891978

Epoch: 6| Step: 5
Training loss: 1.679641604423523
Validation loss: 1.9622350533803303

Epoch: 6| Step: 6
Training loss: 2.013188123703003
Validation loss: 1.9702808062235515

Epoch: 6| Step: 7
Training loss: 1.966737985610962
Validation loss: 1.9625482360521953

Epoch: 6| Step: 8
Training loss: 1.9319583177566528
Validation loss: 1.9628930687904358

Epoch: 6| Step: 9
Training loss: 2.1962809562683105
Validation loss: 1.931356926759084

Epoch: 6| Step: 10
Training loss: 2.213169813156128
Validation loss: 1.9686441818873088

Epoch: 6| Step: 11
Training loss: 2.293666124343872
Validation loss: 1.9607248107592266

Epoch: 6| Step: 12
Training loss: 1.6081550121307373
Validation loss: 1.9785990516344707

Epoch: 6| Step: 13
Training loss: 1.6855137348175049
Validation loss: 1.9515361785888672

Epoch: 12| Step: 0
Training loss: 1.7435250282287598
Validation loss: 1.9645603895187378

Epoch: 6| Step: 1
Training loss: 2.0544047355651855
Validation loss: 1.9645263353983562

Epoch: 6| Step: 2
Training loss: 2.6482625007629395
Validation loss: 1.9684686462084453

Epoch: 6| Step: 3
Training loss: 1.9561249017715454
Validation loss: 1.9571409424146016

Epoch: 6| Step: 4
Training loss: 1.6491827964782715
Validation loss: 1.9581823746363323

Epoch: 6| Step: 5
Training loss: 1.3201274871826172
Validation loss: 1.9599462350209553

Epoch: 6| Step: 6
Training loss: 2.2650091648101807
Validation loss: 1.9633894364039104

Epoch: 6| Step: 7
Training loss: 1.8780803680419922
Validation loss: 1.9545396367708843

Epoch: 6| Step: 8
Training loss: 1.6715775728225708
Validation loss: 1.9771668314933777

Epoch: 6| Step: 9
Training loss: 2.1781649589538574
Validation loss: 1.9611664215723674

Epoch: 6| Step: 10
Training loss: 2.061568260192871
Validation loss: 1.9673691391944885

Epoch: 6| Step: 11
Training loss: 2.502953290939331
Validation loss: 1.9532066980997722

Epoch: 6| Step: 12
Training loss: 1.7753621339797974
Validation loss: 1.9666375319163005

Epoch: 6| Step: 13
Training loss: 2.6146132946014404
Validation loss: 1.9604874054590862

Epoch: 13| Step: 0
Training loss: 2.1925323009490967
Validation loss: 1.9621856212615967

Epoch: 6| Step: 1
Training loss: 2.5089330673217773
Validation loss: 1.9459995031356812

Epoch: 6| Step: 2
Training loss: 1.6732416152954102
Validation loss: 1.9632484118143718

Epoch: 6| Step: 3
Training loss: 1.7440459728240967
Validation loss: 1.9657175540924072

Epoch: 6| Step: 4
Training loss: 2.213557720184326
Validation loss: 1.967037598292033

Epoch: 6| Step: 5
Training loss: 1.5888254642486572
Validation loss: 1.9569319089253743

Epoch: 6| Step: 6
Training loss: 2.2062788009643555
Validation loss: 1.954099178314209

Epoch: 6| Step: 7
Training loss: 1.5122450590133667
Validation loss: 1.9455774029095967

Epoch: 6| Step: 8
Training loss: 1.614686131477356
Validation loss: 1.959764540195465

Epoch: 6| Step: 9
Training loss: 2.2400639057159424
Validation loss: 1.9691741069157918

Epoch: 6| Step: 10
Training loss: 2.4134607315063477
Validation loss: 1.9531771739323933

Epoch: 6| Step: 11
Training loss: 2.524590253829956
Validation loss: 1.9696635603904724

Epoch: 6| Step: 12
Training loss: 1.6869289875030518
Validation loss: 1.9505951801935832

Epoch: 6| Step: 13
Training loss: 2.2358031272888184
Validation loss: 1.9578287998835247

Epoch: 14| Step: 0
Training loss: 2.362360954284668
Validation loss: 1.959615170955658

Epoch: 6| Step: 1
Training loss: 1.7931326627731323
Validation loss: 1.9653244415918987

Epoch: 6| Step: 2
Training loss: 1.6279292106628418
Validation loss: 1.9551711281140645

Epoch: 6| Step: 3
Training loss: 2.006711483001709
Validation loss: 1.9674745798110962

Epoch: 6| Step: 4
Training loss: 2.1170973777770996
Validation loss: 1.945990780989329

Epoch: 6| Step: 5
Training loss: 1.7032768726348877
Validation loss: 1.952251394589742

Epoch: 6| Step: 6
Training loss: 2.1270928382873535
Validation loss: 1.9645704825719197

Epoch: 6| Step: 7
Training loss: 1.5798622369766235
Validation loss: 1.9466404914855957

Epoch: 6| Step: 8
Training loss: 1.518380880355835
Validation loss: 1.9774151841799419

Epoch: 6| Step: 9
Training loss: 2.4721617698669434
Validation loss: 1.9677884777386982

Epoch: 6| Step: 10
Training loss: 2.5710644721984863
Validation loss: 1.9786635835965474

Epoch: 6| Step: 11
Training loss: 1.8839815855026245
Validation loss: 1.975580672423045

Epoch: 6| Step: 12
Training loss: 2.5954508781433105
Validation loss: 1.969696621100108

Epoch: 6| Step: 13
Training loss: 1.9026200771331787
Validation loss: 1.9742554227511089

Epoch: 15| Step: 0
Training loss: 1.8437297344207764
Validation loss: 1.9617335398991902

Epoch: 6| Step: 1
Training loss: 2.403960704803467
Validation loss: 1.9480895002683003

Epoch: 6| Step: 2
Training loss: 2.5252256393432617
Validation loss: 1.9519684513409932

Epoch: 6| Step: 3
Training loss: 2.1340928077697754
Validation loss: 1.9485476811726887

Epoch: 6| Step: 4
Training loss: 1.4446982145309448
Validation loss: 1.95529572168986

Epoch: 6| Step: 5
Training loss: 2.1173787117004395
Validation loss: 1.9357813596725464

Epoch: 6| Step: 6
Training loss: 2.421607494354248
Validation loss: 1.95545893907547

Epoch: 6| Step: 7
Training loss: 2.6064107418060303
Validation loss: 1.9642430146535237

Epoch: 6| Step: 8
Training loss: 1.7381399869918823
Validation loss: 1.96677561601003

Epoch: 6| Step: 9
Training loss: 1.4247902631759644
Validation loss: 1.9641645948092143

Epoch: 6| Step: 10
Training loss: 1.8950374126434326
Validation loss: 1.9680571556091309

Epoch: 6| Step: 11
Training loss: 1.6193197965621948
Validation loss: 1.9572320381800334

Epoch: 6| Step: 12
Training loss: 1.9960578680038452
Validation loss: 1.9551397760709126

Epoch: 6| Step: 13
Training loss: 2.0554563999176025
Validation loss: 1.9581902821858723

Epoch: 16| Step: 0
Training loss: 2.3886613845825195
Validation loss: 1.9446407953898113

Epoch: 6| Step: 1
Training loss: 2.3244495391845703
Validation loss: 1.9458449880282085

Epoch: 6| Step: 2
Training loss: 1.9494881629943848
Validation loss: 1.9599689245224

Epoch: 6| Step: 3
Training loss: 2.475611925125122
Validation loss: 1.965663234392802

Epoch: 6| Step: 4
Training loss: 1.7752701044082642
Validation loss: 1.9587131539980571

Epoch: 6| Step: 5
Training loss: 1.5733205080032349
Validation loss: 1.9510706464449565

Epoch: 6| Step: 6
Training loss: 1.6181081533432007
Validation loss: 1.942791223526001

Epoch: 6| Step: 7
Training loss: 2.079474449157715
Validation loss: 1.9565207958221436

Epoch: 6| Step: 8
Training loss: 2.3978443145751953
Validation loss: 1.9419464667638142

Epoch: 6| Step: 9
Training loss: 2.2758259773254395
Validation loss: 1.9424173831939697

Epoch: 6| Step: 10
Training loss: 1.5245102643966675
Validation loss: 1.9593878785769145

Epoch: 6| Step: 11
Training loss: 1.0112228393554688
Validation loss: 1.9499180316925049

Epoch: 6| Step: 12
Training loss: 2.4068479537963867
Validation loss: 1.9631930987040203

Epoch: 6| Step: 13
Training loss: 2.1382436752319336
Validation loss: 1.9600528279940288

Epoch: 17| Step: 0
Training loss: 2.032287120819092
Validation loss: 1.9548569718996684

Epoch: 6| Step: 1
Training loss: 1.4597575664520264
Validation loss: 1.9617634812990825

Epoch: 6| Step: 2
Training loss: 1.4686082601547241
Validation loss: 1.948779781659444

Epoch: 6| Step: 3
Training loss: 1.7669683694839478
Validation loss: 1.953620711962382

Epoch: 6| Step: 4
Training loss: 1.982389211654663
Validation loss: 1.9525935451189678

Epoch: 6| Step: 5
Training loss: 2.227370262145996
Validation loss: 1.9494277040163677

Epoch: 6| Step: 6
Training loss: 1.631267786026001
Validation loss: 1.954971472422282

Epoch: 6| Step: 7
Training loss: 2.566244125366211
Validation loss: 1.956985592842102

Epoch: 6| Step: 8
Training loss: 1.9133350849151611
Validation loss: 1.9556604623794556

Epoch: 6| Step: 9
Training loss: 2.43789005279541
Validation loss: 1.9489482045173645

Epoch: 6| Step: 10
Training loss: 1.998694896697998
Validation loss: 1.9500959118207295

Epoch: 6| Step: 11
Training loss: 1.9136226177215576
Validation loss: 1.9437949657440186

Epoch: 6| Step: 12
Training loss: 2.3239405155181885
Validation loss: 1.9593631625175476

Epoch: 6| Step: 13
Training loss: 2.0757529735565186
Validation loss: 1.937161882718404

Epoch: 18| Step: 0
Training loss: 2.190488815307617
Validation loss: 1.936503569285075

Epoch: 6| Step: 1
Training loss: 1.6406850814819336
Validation loss: 1.9442654450734456

Epoch: 6| Step: 2
Training loss: 1.9941136837005615
Validation loss: 1.946449915568034

Epoch: 6| Step: 3
Training loss: 1.6634235382080078
Validation loss: 1.957674245039622

Epoch: 6| Step: 4
Training loss: 3.00459885597229
Validation loss: 1.9387946724891663

Epoch: 6| Step: 5
Training loss: 1.780577301979065
Validation loss: 1.9514658053716023

Epoch: 6| Step: 6
Training loss: 1.8531184196472168
Validation loss: 1.9461867411931355

Epoch: 6| Step: 7
Training loss: 1.9084120988845825
Validation loss: 1.953328529993693

Epoch: 6| Step: 8
Training loss: 2.140636444091797
Validation loss: 1.9453261097272236

Epoch: 6| Step: 9
Training loss: 2.083613395690918
Validation loss: 1.9467304348945618

Epoch: 6| Step: 10
Training loss: 2.2749061584472656
Validation loss: 1.9588237404823303

Epoch: 6| Step: 11
Training loss: 1.8136951923370361
Validation loss: 1.956266701221466

Epoch: 6| Step: 12
Training loss: 1.8743934631347656
Validation loss: 1.9543696244557698

Epoch: 6| Step: 13
Training loss: 1.6698946952819824
Validation loss: 1.9338953693707783

Epoch: 19| Step: 0
Training loss: 2.0581929683685303
Validation loss: 1.9535850485165913

Epoch: 6| Step: 1
Training loss: 2.301331043243408
Validation loss: 1.9318109154701233

Epoch: 6| Step: 2
Training loss: 1.4444680213928223
Validation loss: 1.9433145920435588

Epoch: 6| Step: 3
Training loss: 2.3946592807769775
Validation loss: 1.9442198872566223

Epoch: 6| Step: 4
Training loss: 1.9332184791564941
Validation loss: 1.933898150920868

Epoch: 6| Step: 5
Training loss: 1.92417573928833
Validation loss: 1.946471889813741

Epoch: 6| Step: 6
Training loss: 2.0477066040039062
Validation loss: 1.946208159128825

Epoch: 6| Step: 7
Training loss: 2.3378803730010986
Validation loss: 1.9689746896425884

Epoch: 6| Step: 8
Training loss: 2.223965644836426
Validation loss: 1.9347374836603801

Epoch: 6| Step: 9
Training loss: 1.8210537433624268
Validation loss: 1.9433522621790569

Epoch: 6| Step: 10
Training loss: 1.9126203060150146
Validation loss: 1.9279365142186482

Epoch: 6| Step: 11
Training loss: 2.010953426361084
Validation loss: 1.9451677600542705

Epoch: 6| Step: 12
Training loss: 1.4340705871582031
Validation loss: 1.9547385772069295

Epoch: 6| Step: 13
Training loss: 2.059260845184326
Validation loss: 1.95952304204305

Epoch: 20| Step: 0
Training loss: 2.6555049419403076
Validation loss: 1.966990073521932

Epoch: 6| Step: 1
Training loss: 1.7633473873138428
Validation loss: 1.96843683719635

Epoch: 6| Step: 2
Training loss: 1.7588002681732178
Validation loss: 1.97301584482193

Epoch: 6| Step: 3
Training loss: 1.981547236442566
Validation loss: 1.9697062969207764

Epoch: 6| Step: 4
Training loss: 1.245462417602539
Validation loss: 1.9608338077863057

Epoch: 6| Step: 5
Training loss: 1.5736031532287598
Validation loss: 1.9558789531389873

Epoch: 6| Step: 6
Training loss: 2.230031728744507
Validation loss: 1.9581377704938252

Epoch: 6| Step: 7
Training loss: 1.6369634866714478
Validation loss: 1.9652640422185261

Epoch: 6| Step: 8
Training loss: 2.1021347045898438
Validation loss: 1.9787988861401875

Epoch: 6| Step: 9
Training loss: 2.661905288696289
Validation loss: 1.961973786354065

Epoch: 6| Step: 10
Training loss: 1.7250597476959229
Validation loss: 1.962688426176707

Epoch: 6| Step: 11
Training loss: 1.7466132640838623
Validation loss: 1.9518516063690186

Epoch: 6| Step: 12
Training loss: 2.325218915939331
Validation loss: 1.9538644750912983

Epoch: 6| Step: 13
Training loss: 2.2991650104522705
Validation loss: 1.925361653168996

Epoch: 21| Step: 0
Training loss: 2.144505500793457
Validation loss: 1.9418532450993855

Epoch: 6| Step: 1
Training loss: 1.713086485862732
Validation loss: 1.9532533089319866

Epoch: 6| Step: 2
Training loss: 2.0624141693115234
Validation loss: 1.9495510061581929

Epoch: 6| Step: 3
Training loss: 2.4674863815307617
Validation loss: 1.9387250741322835

Epoch: 6| Step: 4
Training loss: 1.6277720928192139
Validation loss: 1.9405585527420044

Epoch: 6| Step: 5
Training loss: 2.157437562942505
Validation loss: 1.9530067841211955

Epoch: 6| Step: 6
Training loss: 2.1463236808776855
Validation loss: 1.943852464358012

Epoch: 6| Step: 7
Training loss: 2.483376979827881
Validation loss: 1.937951147556305

Epoch: 6| Step: 8
Training loss: 1.4365639686584473
Validation loss: 1.9430691997210185

Epoch: 6| Step: 9
Training loss: 1.823600172996521
Validation loss: 1.946691632270813

Epoch: 6| Step: 10
Training loss: 1.8884209394454956
Validation loss: 1.9569889307022095

Epoch: 6| Step: 11
Training loss: 1.778134822845459
Validation loss: 1.937921663125356

Epoch: 6| Step: 12
Training loss: 1.739295244216919
Validation loss: 1.9425019025802612

Epoch: 6| Step: 13
Training loss: 2.3374757766723633
Validation loss: 1.9244881470998128

Epoch: 22| Step: 0
Training loss: 2.3604683876037598
Validation loss: 1.954413930575053

Epoch: 6| Step: 1
Training loss: 1.8613715171813965
Validation loss: 1.9428775310516357

Epoch: 6| Step: 2
Training loss: 1.8526922464370728
Validation loss: 1.938161591688792

Epoch: 6| Step: 3
Training loss: 2.1803815364837646
Validation loss: 1.9449332753817241

Epoch: 6| Step: 4
Training loss: 1.4609434604644775
Validation loss: 1.9474818706512451

Epoch: 6| Step: 5
Training loss: 2.1656839847564697
Validation loss: 1.9532063603401184

Epoch: 6| Step: 6
Training loss: 1.363856554031372
Validation loss: 1.9494879643122356

Epoch: 6| Step: 7
Training loss: 2.22908091545105
Validation loss: 1.945340633392334

Epoch: 6| Step: 8
Training loss: 1.9984287023544312
Validation loss: 1.947860340277354

Epoch: 6| Step: 9
Training loss: 1.4642480611801147
Validation loss: 1.9498812754948933

Epoch: 6| Step: 10
Training loss: 2.038233757019043
Validation loss: 1.9458959698677063

Epoch: 6| Step: 11
Training loss: 2.686918258666992
Validation loss: 1.9401251872380574

Epoch: 6| Step: 12
Training loss: 1.9516639709472656
Validation loss: 1.949890414873759

Epoch: 6| Step: 13
Training loss: 1.8927292823791504
Validation loss: 1.945434292157491

Epoch: 23| Step: 0
Training loss: 1.8953437805175781
Validation loss: 1.9427704215049744

Epoch: 6| Step: 1
Training loss: 1.9983108043670654
Validation loss: 1.9349610209465027

Epoch: 6| Step: 2
Training loss: 1.734877347946167
Validation loss: 1.94355175892512

Epoch: 6| Step: 3
Training loss: 2.1527204513549805
Validation loss: 1.9307226141293843

Epoch: 6| Step: 4
Training loss: 2.158735513687134
Validation loss: 1.9485462506612141

Epoch: 6| Step: 5
Training loss: 1.6732683181762695
Validation loss: 1.9425174792607625

Epoch: 6| Step: 6
Training loss: 2.2415695190429688
Validation loss: 1.9447275002797444

Epoch: 6| Step: 7
Training loss: 1.6345072984695435
Validation loss: 1.9414859414100647

Epoch: 6| Step: 8
Training loss: 2.293581008911133
Validation loss: 1.9394413828849792

Epoch: 6| Step: 9
Training loss: 1.580866813659668
Validation loss: 1.9373563329378765

Epoch: 6| Step: 10
Training loss: 2.131411075592041
Validation loss: 1.9620020985603333

Epoch: 6| Step: 11
Training loss: 1.4632807970046997
Validation loss: 1.9378306865692139

Epoch: 6| Step: 12
Training loss: 2.633387327194214
Validation loss: 1.9527847369511921

Epoch: 6| Step: 13
Training loss: 2.0216712951660156
Validation loss: 1.9677879412968953

Epoch: 24| Step: 0
Training loss: 1.4888287782669067
Validation loss: 1.9465445478757222

Epoch: 6| Step: 1
Training loss: 2.2339179515838623
Validation loss: 1.9664159218470256

Epoch: 6| Step: 2
Training loss: 1.907439947128296
Validation loss: 1.9535194635391235

Epoch: 6| Step: 3
Training loss: 1.9267991781234741
Validation loss: 1.9395675659179688

Epoch: 6| Step: 4
Training loss: 1.9402374029159546
Validation loss: 1.9464176893234253

Epoch: 6| Step: 5
Training loss: 2.3567535877227783
Validation loss: 1.9374095598856609

Epoch: 6| Step: 6
Training loss: 2.522439479827881
Validation loss: 1.9441997408866882

Epoch: 6| Step: 7
Training loss: 1.6880797147750854
Validation loss: 1.9454994599024455

Epoch: 6| Step: 8
Training loss: 1.396343469619751
Validation loss: 1.92936106522878

Epoch: 6| Step: 9
Training loss: 1.5772449970245361
Validation loss: 1.9397319356600444

Epoch: 6| Step: 10
Training loss: 1.8778034448623657
Validation loss: 1.9412731925646465

Epoch: 6| Step: 11
Training loss: 2.793536901473999
Validation loss: 1.9510301351547241

Epoch: 6| Step: 12
Training loss: 1.908682942390442
Validation loss: 1.9427698850631714

Epoch: 6| Step: 13
Training loss: 1.878319263458252
Validation loss: 1.941488007704417

Epoch: 25| Step: 0
Training loss: 1.9702539443969727
Validation loss: 1.9290377298990886

Epoch: 6| Step: 1
Training loss: 2.363382577896118
Validation loss: 1.9308724006017048

Epoch: 6| Step: 2
Training loss: 2.2898802757263184
Validation loss: 1.9436782201131184

Epoch: 6| Step: 3
Training loss: 2.0482561588287354
Validation loss: 1.9403416514396667

Epoch: 6| Step: 4
Training loss: 2.0969936847686768
Validation loss: 1.945954402287801

Epoch: 6| Step: 5
Training loss: 1.7820115089416504
Validation loss: 1.9437666932741802

Epoch: 6| Step: 6
Training loss: 2.0180437564849854
Validation loss: 1.946313480536143

Epoch: 6| Step: 7
Training loss: 1.7559969425201416
Validation loss: 1.9377905527750652

Epoch: 6| Step: 8
Training loss: 1.6627657413482666
Validation loss: 1.9467902183532715

Epoch: 6| Step: 9
Training loss: 1.9963897466659546
Validation loss: 1.9501338998476665

Epoch: 6| Step: 10
Training loss: 1.971670150756836
Validation loss: 1.9472835461298625

Epoch: 6| Step: 11
Training loss: 1.6443076133728027
Validation loss: 1.9613351623217266

Epoch: 6| Step: 12
Training loss: 1.9785733222961426
Validation loss: 1.9632132252057393

Epoch: 6| Step: 13
Training loss: 1.6785783767700195
Validation loss: 1.9687220454216003

Epoch: 26| Step: 0
Training loss: 2.023564338684082
Validation loss: 1.9691067735354106

Epoch: 6| Step: 1
Training loss: 1.8813310861587524
Validation loss: 1.9779783089955647

Epoch: 6| Step: 2
Training loss: 1.4593982696533203
Validation loss: 1.955929934978485

Epoch: 6| Step: 3
Training loss: 2.227660655975342
Validation loss: 1.9481151501337688

Epoch: 6| Step: 4
Training loss: 1.625349998474121
Validation loss: 1.948469301064809

Epoch: 6| Step: 5
Training loss: 2.2608814239501953
Validation loss: 1.9405858715375264

Epoch: 6| Step: 6
Training loss: 1.769890308380127
Validation loss: 1.934708833694458

Epoch: 6| Step: 7
Training loss: 2.721668004989624
Validation loss: 1.9425878723462422

Epoch: 6| Step: 8
Training loss: 1.5381234884262085
Validation loss: 1.9485526879628499

Epoch: 6| Step: 9
Training loss: 2.353425979614258
Validation loss: 1.9415773749351501

Epoch: 6| Step: 10
Training loss: 1.8730056285858154
Validation loss: 1.9510483940442402

Epoch: 6| Step: 11
Training loss: 2.0609066486358643
Validation loss: 1.9435190359751384

Epoch: 6| Step: 12
Training loss: 2.158541679382324
Validation loss: 1.947220464547475

Epoch: 6| Step: 13
Training loss: 1.6649240255355835
Validation loss: 1.9434977571169536

Epoch: 27| Step: 0
Training loss: 2.2096824645996094
Validation loss: 1.941551645596822

Epoch: 6| Step: 1
Training loss: 2.0647478103637695
Validation loss: 1.9593238433202107

Epoch: 6| Step: 2
Training loss: 1.758547306060791
Validation loss: 1.9361277222633362

Epoch: 6| Step: 3
Training loss: 2.2517588138580322
Validation loss: 1.9589540362358093

Epoch: 6| Step: 4
Training loss: 1.6655027866363525
Validation loss: 1.9339771668116252

Epoch: 6| Step: 5
Training loss: 1.633644700050354
Validation loss: 1.9363828500111897

Epoch: 6| Step: 6
Training loss: 2.0313196182250977
Validation loss: 1.9396271308263142

Epoch: 6| Step: 7
Training loss: 1.9298655986785889
Validation loss: 1.9614311456680298

Epoch: 6| Step: 8
Training loss: 1.3846893310546875
Validation loss: 1.935558279355367

Epoch: 6| Step: 9
Training loss: 2.1541807651519775
Validation loss: 1.9451804161071777

Epoch: 6| Step: 10
Training loss: 1.8553225994110107
Validation loss: 1.9399252931276958

Epoch: 6| Step: 11
Training loss: 2.032637596130371
Validation loss: 1.9381403128306072

Epoch: 6| Step: 12
Training loss: 1.7469818592071533
Validation loss: 1.9424968759218852

Epoch: 6| Step: 13
Training loss: 2.6132712364196777
Validation loss: 1.9441317717234294

Epoch: 28| Step: 0
Training loss: 1.6502106189727783
Validation loss: 1.9357183178265889

Epoch: 6| Step: 1
Training loss: 1.8364124298095703
Validation loss: 1.9369675517082214

Epoch: 6| Step: 2
Training loss: 1.6191647052764893
Validation loss: 1.94587242603302

Epoch: 6| Step: 3
Training loss: 2.4225265979766846
Validation loss: 1.9507248600323994

Epoch: 6| Step: 4
Training loss: 1.513245940208435
Validation loss: 1.949111799399058

Epoch: 6| Step: 5
Training loss: 2.3951375484466553
Validation loss: 1.9322267770767212

Epoch: 6| Step: 6
Training loss: 1.8243355751037598
Validation loss: 1.939706842104594

Epoch: 6| Step: 7
Training loss: 1.186516284942627
Validation loss: 1.9452025890350342

Epoch: 6| Step: 8
Training loss: 1.5540862083435059
Validation loss: 1.9612926642100017

Epoch: 6| Step: 9
Training loss: 2.9247865676879883
Validation loss: 1.9605744083722432

Epoch: 6| Step: 10
Training loss: 1.8411251306533813
Validation loss: 1.9357515573501587

Epoch: 6| Step: 11
Training loss: 1.7445297241210938
Validation loss: 1.9626497427622478

Epoch: 6| Step: 12
Training loss: 2.5446460247039795
Validation loss: 1.9472573796908061

Epoch: 6| Step: 13
Training loss: 2.2491073608398438
Validation loss: 1.9330502549807231

Epoch: 29| Step: 0
Training loss: 2.263364553451538
Validation loss: 1.9246643582979839

Epoch: 6| Step: 1
Training loss: 2.426697254180908
Validation loss: 1.944854776064555

Epoch: 6| Step: 2
Training loss: 1.8865470886230469
Validation loss: 1.9487706820170085

Epoch: 6| Step: 3
Training loss: 1.728197693824768
Validation loss: 1.94589368502299

Epoch: 6| Step: 4
Training loss: 1.4564181566238403
Validation loss: 1.938219964504242

Epoch: 6| Step: 5
Training loss: 1.921318531036377
Validation loss: 1.941084663073222

Epoch: 6| Step: 6
Training loss: 1.8417340517044067
Validation loss: 1.9405658841133118

Epoch: 6| Step: 7
Training loss: 1.6549396514892578
Validation loss: 1.9476657311121623

Epoch: 6| Step: 8
Training loss: 1.9302737712860107
Validation loss: 1.9485358595848083

Epoch: 6| Step: 9
Training loss: 1.7798975706100464
Validation loss: 1.9389545321464539

Epoch: 6| Step: 10
Training loss: 2.0936355590820312
Validation loss: 1.9519783854484558

Epoch: 6| Step: 11
Training loss: 2.693376064300537
Validation loss: 1.9437054991722107

Epoch: 6| Step: 12
Training loss: 1.7893640995025635
Validation loss: 1.9342405994733174

Epoch: 6| Step: 13
Training loss: 1.9761064052581787
Validation loss: 1.9469204743703206

Epoch: 30| Step: 0
Training loss: 1.9585621356964111
Validation loss: 1.9335341056187947

Epoch: 6| Step: 1
Training loss: 1.2832268476486206
Validation loss: 1.9594819744427998

Epoch: 6| Step: 2
Training loss: 2.3162574768066406
Validation loss: 1.9499730070432026

Epoch: 6| Step: 3
Training loss: 1.681458830833435
Validation loss: 1.9639126261075337

Epoch: 6| Step: 4
Training loss: 1.7162351608276367
Validation loss: 1.9434842665990193

Epoch: 6| Step: 5
Training loss: 2.1017284393310547
Validation loss: 1.941277007261912

Epoch: 6| Step: 6
Training loss: 2.1262285709381104
Validation loss: 1.9509242574373882

Epoch: 6| Step: 7
Training loss: 2.0227150917053223
Validation loss: 1.9322344462076824

Epoch: 6| Step: 8
Training loss: 1.506097674369812
Validation loss: 1.9360909660657246

Epoch: 6| Step: 9
Training loss: 1.6003565788269043
Validation loss: 1.9425859649976094

Epoch: 6| Step: 10
Training loss: 2.3702433109283447
Validation loss: 1.9286919037501018

Epoch: 6| Step: 11
Training loss: 2.177999258041382
Validation loss: 1.9485365748405457

Epoch: 6| Step: 12
Training loss: 2.52841854095459
Validation loss: 1.9298665920893352

Epoch: 6| Step: 13
Training loss: 1.9688453674316406
Validation loss: 1.929226775964101

Epoch: 31| Step: 0
Training loss: 1.8129220008850098
Validation loss: 1.9454900821050007

Epoch: 6| Step: 1
Training loss: 2.0035791397094727
Validation loss: 1.9536077578862507

Epoch: 6| Step: 2
Training loss: 2.844400405883789
Validation loss: 1.9352522095044453

Epoch: 6| Step: 3
Training loss: 1.5881354808807373
Validation loss: 1.947200616200765

Epoch: 6| Step: 4
Training loss: 1.7391574382781982
Validation loss: 1.941153605779012

Epoch: 6| Step: 5
Training loss: 1.981752872467041
Validation loss: 1.9292096098264058

Epoch: 6| Step: 6
Training loss: 1.4033851623535156
Validation loss: 1.9543977777163188

Epoch: 6| Step: 7
Training loss: 2.2534780502319336
Validation loss: 1.9383244514465332

Epoch: 6| Step: 8
Training loss: 1.945561170578003
Validation loss: 1.9290853540102642

Epoch: 6| Step: 9
Training loss: 1.4893593788146973
Validation loss: 1.9360704223314922

Epoch: 6| Step: 10
Training loss: 2.1534807682037354
Validation loss: 1.9541875123977661

Epoch: 6| Step: 11
Training loss: 1.8044217824935913
Validation loss: 1.9362892508506775

Epoch: 6| Step: 12
Training loss: 1.5238020420074463
Validation loss: 1.9565362731615703

Epoch: 6| Step: 13
Training loss: 2.538280487060547
Validation loss: 1.9463321566581726

Epoch: 32| Step: 0
Training loss: 1.9830801486968994
Validation loss: 1.9469212492307026

Epoch: 6| Step: 1
Training loss: 2.1588985919952393
Validation loss: 1.9426710605621338

Epoch: 6| Step: 2
Training loss: 1.5784900188446045
Validation loss: 1.957485516866048

Epoch: 6| Step: 3
Training loss: 1.999091625213623
Validation loss: 1.968054989973704

Epoch: 6| Step: 4
Training loss: 1.572462558746338
Validation loss: 1.9562360445658367

Epoch: 6| Step: 5
Training loss: 1.8675780296325684
Validation loss: 1.9717976649602253

Epoch: 6| Step: 6
Training loss: 1.278372049331665
Validation loss: 1.950809379418691

Epoch: 6| Step: 7
Training loss: 1.880328893661499
Validation loss: 1.9450539946556091

Epoch: 6| Step: 8
Training loss: 2.4388480186462402
Validation loss: 1.9405367374420166

Epoch: 6| Step: 9
Training loss: 2.4833388328552246
Validation loss: 1.9550824761390686

Epoch: 6| Step: 10
Training loss: 1.905318021774292
Validation loss: 1.9493714968363445

Epoch: 6| Step: 11
Training loss: 1.9602348804473877
Validation loss: 1.9344438513120015

Epoch: 6| Step: 12
Training loss: 1.9157217741012573
Validation loss: 1.9541244904200237

Epoch: 6| Step: 13
Training loss: 2.008333206176758
Validation loss: 1.9414013226826985

Epoch: 33| Step: 0
Training loss: 1.7858004570007324
Validation loss: 1.9374820987383525

Epoch: 6| Step: 1
Training loss: 2.2393136024475098
Validation loss: 1.9507101972897847

Epoch: 6| Step: 2
Training loss: 2.2076025009155273
Validation loss: 1.9364940524101257

Epoch: 6| Step: 3
Training loss: 2.0587925910949707
Validation loss: 1.9211469690004985

Epoch: 6| Step: 4
Training loss: 1.6078300476074219
Validation loss: 1.9490965604782104

Epoch: 6| Step: 5
Training loss: 1.8328956365585327
Validation loss: 1.9257504145304363

Epoch: 6| Step: 6
Training loss: 1.6339958906173706
Validation loss: 1.9362686276435852

Epoch: 6| Step: 7
Training loss: 1.8609015941619873
Validation loss: 1.9605106711387634

Epoch: 6| Step: 8
Training loss: 2.0761733055114746
Validation loss: 1.9594810009002686

Epoch: 6| Step: 9
Training loss: 1.480784296989441
Validation loss: 1.9651873707771301

Epoch: 6| Step: 10
Training loss: 2.4364371299743652
Validation loss: 1.978461782137553

Epoch: 6| Step: 11
Training loss: 2.025409698486328
Validation loss: 1.9666618704795837

Epoch: 6| Step: 12
Training loss: 1.8215928077697754
Validation loss: 1.9596449335416157

Epoch: 6| Step: 13
Training loss: 2.0396957397460938
Validation loss: 1.939785361289978

Epoch: 34| Step: 0
Training loss: 2.804337978363037
Validation loss: 1.930446485678355

Epoch: 6| Step: 1
Training loss: 1.7189397811889648
Validation loss: 1.9479485948880513

Epoch: 6| Step: 2
Training loss: 1.521753191947937
Validation loss: 1.9360525012016296

Epoch: 6| Step: 3
Training loss: 1.5615142583847046
Validation loss: 1.9550863305727642

Epoch: 6| Step: 4
Training loss: 2.2472424507141113
Validation loss: 1.9373618761698406

Epoch: 6| Step: 5
Training loss: 1.814764380455017
Validation loss: 1.9454317490259807

Epoch: 6| Step: 6
Training loss: 1.8509581089019775
Validation loss: 1.9478882749875386

Epoch: 6| Step: 7
Training loss: 2.024855613708496
Validation loss: 1.9416223565737407

Epoch: 6| Step: 8
Training loss: 3.0394651889801025
Validation loss: 1.9434251586596172

Epoch: 6| Step: 9
Training loss: 1.3703042268753052
Validation loss: 1.9543190399805705

Epoch: 6| Step: 10
Training loss: 1.7970820665359497
Validation loss: 1.936516006787618

Epoch: 6| Step: 11
Training loss: 1.92799711227417
Validation loss: 1.943332274754842

Epoch: 6| Step: 12
Training loss: 1.9979913234710693
Validation loss: 1.9394469857215881

Epoch: 6| Step: 13
Training loss: 1.6021324396133423
Validation loss: 1.9369511604309082

Epoch: 35| Step: 0
Training loss: 2.3270671367645264
Validation loss: 1.944205602010091

Epoch: 6| Step: 1
Training loss: 1.8337053060531616
Validation loss: 1.9492037097613018

Epoch: 6| Step: 2
Training loss: 2.2557411193847656
Validation loss: 1.9391062259674072

Epoch: 6| Step: 3
Training loss: 1.5174164772033691
Validation loss: 1.9452202717463176

Epoch: 6| Step: 4
Training loss: 1.8687326908111572
Validation loss: 1.9487443765004475

Epoch: 6| Step: 5
Training loss: 2.0653138160705566
Validation loss: 1.9599458972613018

Epoch: 6| Step: 6
Training loss: 1.7231358289718628
Validation loss: 1.9676426251729329

Epoch: 6| Step: 7
Training loss: 1.968260645866394
Validation loss: 1.9727226694424946

Epoch: 6| Step: 8
Training loss: 2.327418327331543
Validation loss: 1.9814560413360596

Epoch: 6| Step: 9
Training loss: 2.00842547416687
Validation loss: 1.9731753667195637

Epoch: 6| Step: 10
Training loss: 1.1970481872558594
Validation loss: 1.957983175913493

Epoch: 6| Step: 11
Training loss: 1.5213898420333862
Validation loss: 1.9466619491577148

Epoch: 6| Step: 12
Training loss: 2.6030194759368896
Validation loss: 1.9530436197916667

Epoch: 6| Step: 13
Training loss: 1.7050304412841797
Validation loss: 1.9437057574590046

Epoch: 36| Step: 0
Training loss: 1.8323142528533936
Validation loss: 1.9379438161849976

Epoch: 6| Step: 1
Training loss: 1.9630863666534424
Validation loss: 1.9505996505419414

Epoch: 6| Step: 2
Training loss: 2.2141759395599365
Validation loss: 1.9382760922114055

Epoch: 6| Step: 3
Training loss: 1.8597421646118164
Validation loss: 1.952165146668752

Epoch: 6| Step: 4
Training loss: 1.835233211517334
Validation loss: 1.9351992805798848

Epoch: 6| Step: 5
Training loss: 1.4294092655181885
Validation loss: 1.9235475063323975

Epoch: 6| Step: 6
Training loss: 2.1606369018554688
Validation loss: 1.9197326103846233

Epoch: 6| Step: 7
Training loss: 1.9034974575042725
Validation loss: 1.9510557850201924

Epoch: 6| Step: 8
Training loss: 2.0597896575927734
Validation loss: 1.9472050269444783

Epoch: 6| Step: 9
Training loss: 2.4364569187164307
Validation loss: 1.9333708087603252

Epoch: 6| Step: 10
Training loss: 1.9901421070098877
Validation loss: 1.9378513097763062

Epoch: 6| Step: 11
Training loss: 1.600942850112915
Validation loss: 1.9342271288235982

Epoch: 6| Step: 12
Training loss: 1.7041022777557373
Validation loss: 1.9296988646189372

Epoch: 6| Step: 13
Training loss: 1.8479409217834473
Validation loss: 1.9332429766654968

Epoch: 37| Step: 0
Training loss: 2.027874231338501
Validation loss: 1.9450197021166484

Epoch: 6| Step: 1
Training loss: 1.3991541862487793
Validation loss: 1.9423791766166687

Epoch: 6| Step: 2
Training loss: 2.4011590480804443
Validation loss: 1.9320691227912903

Epoch: 6| Step: 3
Training loss: 1.5522880554199219
Validation loss: 1.9602432648340862

Epoch: 6| Step: 4
Training loss: 1.5757557153701782
Validation loss: 1.936141312122345

Epoch: 6| Step: 5
Training loss: 2.3384861946105957
Validation loss: 1.9424391388893127

Epoch: 6| Step: 6
Training loss: 2.1230380535125732
Validation loss: 1.945327599843343

Epoch: 6| Step: 7
Training loss: 1.8054027557373047
Validation loss: 1.9404110709826152

Epoch: 6| Step: 8
Training loss: 1.6741629838943481
Validation loss: 1.941399077574412

Epoch: 6| Step: 9
Training loss: 1.7968425750732422
Validation loss: 1.9439785480499268

Epoch: 6| Step: 10
Training loss: 1.931624412536621
Validation loss: 1.93178794781367

Epoch: 6| Step: 11
Training loss: 2.1792705059051514
Validation loss: 1.951021711031596

Epoch: 6| Step: 12
Training loss: 1.866739273071289
Validation loss: 1.9262561003367107

Epoch: 6| Step: 13
Training loss: 2.0095901489257812
Validation loss: 1.9563230474789937

Epoch: 38| Step: 0
Training loss: 1.8059056997299194
Validation loss: 1.9462847113609314

Epoch: 6| Step: 1
Training loss: 1.891106367111206
Validation loss: 1.9439511895179749

Epoch: 6| Step: 2
Training loss: 1.8350496292114258
Validation loss: 1.942793369293213

Epoch: 6| Step: 3
Training loss: 1.9194831848144531
Validation loss: 1.9259131749471028

Epoch: 6| Step: 4
Training loss: 1.284865140914917
Validation loss: 1.9330912431081135

Epoch: 6| Step: 5
Training loss: 1.9068893194198608
Validation loss: 1.9352582693099976

Epoch: 6| Step: 6
Training loss: 2.068873405456543
Validation loss: 1.963398555914561

Epoch: 6| Step: 7
Training loss: 2.188732147216797
Validation loss: 1.9316911101341248

Epoch: 6| Step: 8
Training loss: 2.811922550201416
Validation loss: 1.9506850441296895

Epoch: 6| Step: 9
Training loss: 2.0317740440368652
Validation loss: 1.9550074537595112

Epoch: 6| Step: 10
Training loss: 2.104504108428955
Validation loss: 1.9672835071881611

Epoch: 6| Step: 11
Training loss: 1.1141623258590698
Validation loss: 1.9521920482317607

Epoch: 6| Step: 12
Training loss: 1.9692599773406982
Validation loss: 1.9466373523076375

Epoch: 6| Step: 13
Training loss: 1.846658706665039
Validation loss: 1.951264997323354

Epoch: 39| Step: 0
Training loss: 1.8525164127349854
Validation loss: 1.937506377696991

Epoch: 6| Step: 1
Training loss: 2.3718950748443604
Validation loss: 1.9324030081431072

Epoch: 6| Step: 2
Training loss: 1.961531400680542
Validation loss: 1.951568325360616

Epoch: 6| Step: 3
Training loss: 2.016329526901245
Validation loss: 1.9282837510108948

Epoch: 6| Step: 4
Training loss: 2.730499267578125
Validation loss: 1.9433801968892415

Epoch: 6| Step: 5
Training loss: 2.0526177883148193
Validation loss: 1.9358127117156982

Epoch: 6| Step: 6
Training loss: 1.8450554609298706
Validation loss: 1.9543943206469219

Epoch: 6| Step: 7
Training loss: 1.8405596017837524
Validation loss: 1.9359763463338215

Epoch: 6| Step: 8
Training loss: 1.5979312658309937
Validation loss: 1.9376389980316162

Epoch: 6| Step: 9
Training loss: 1.8180230855941772
Validation loss: 1.9144480625788372

Epoch: 6| Step: 10
Training loss: 1.9318610429763794
Validation loss: 1.9570411642392476

Epoch: 6| Step: 11
Training loss: 1.4677815437316895
Validation loss: 1.941601316134135

Epoch: 6| Step: 12
Training loss: 2.1268553733825684
Validation loss: 1.9457600315411885

Epoch: 6| Step: 13
Training loss: 1.1157633066177368
Validation loss: 1.9511436621348064

Epoch: 40| Step: 0
Training loss: 1.743733525276184
Validation loss: 1.9348301688830059

Epoch: 6| Step: 1
Training loss: 1.538001537322998
Validation loss: 1.9382935365041096

Epoch: 6| Step: 2
Training loss: 2.112314224243164
Validation loss: 1.9361281991004944

Epoch: 6| Step: 3
Training loss: 1.377671241760254
Validation loss: 1.9324439962704976

Epoch: 6| Step: 4
Training loss: 2.065755844116211
Validation loss: 1.9699213306109111

Epoch: 6| Step: 5
Training loss: 2.7547121047973633
Validation loss: 1.9536032478014629

Epoch: 6| Step: 6
Training loss: 1.9712214469909668
Validation loss: 1.9403650363286336

Epoch: 6| Step: 7
Training loss: 1.5134153366088867
Validation loss: 1.942182997862498

Epoch: 6| Step: 8
Training loss: 1.7292593717575073
Validation loss: 1.9526404937108357

Epoch: 6| Step: 9
Training loss: 1.9749759435653687
Validation loss: 1.9352312286694844

Epoch: 6| Step: 10
Training loss: 2.057997226715088
Validation loss: 1.9431905349095662

Epoch: 6| Step: 11
Training loss: 1.728558897972107
Validation loss: 1.9310205777486165

Epoch: 6| Step: 12
Training loss: 1.852678894996643
Validation loss: 1.9487996498743694

Epoch: 6| Step: 13
Training loss: 2.1790812015533447
Validation loss: 1.9557806849479675

Epoch: 41| Step: 0
Training loss: 1.7922656536102295
Validation loss: 1.9416154225667317

Epoch: 6| Step: 1
Training loss: 1.7085472345352173
Validation loss: 1.9325447877248128

Epoch: 6| Step: 2
Training loss: 1.8342657089233398
Validation loss: 1.9589229424794514

Epoch: 6| Step: 3
Training loss: 1.891343593597412
Validation loss: 1.9475594957669575

Epoch: 6| Step: 4
Training loss: 1.7325844764709473
Validation loss: 1.9492164651552837

Epoch: 6| Step: 5
Training loss: 2.0259222984313965
Validation loss: 1.955866316954295

Epoch: 6| Step: 6
Training loss: 1.8031890392303467
Validation loss: 1.9614299138387044

Epoch: 6| Step: 7
Training loss: 2.842653274536133
Validation loss: 1.9441632628440857

Epoch: 6| Step: 8
Training loss: 1.8447766304016113
Validation loss: 1.9341562589009602

Epoch: 6| Step: 9
Training loss: 1.9632384777069092
Validation loss: 1.9475263357162476

Epoch: 6| Step: 10
Training loss: 1.6482582092285156
Validation loss: 1.9421598315238953

Epoch: 6| Step: 11
Training loss: 2.1755828857421875
Validation loss: 1.931990106900533

Epoch: 6| Step: 12
Training loss: 1.6906466484069824
Validation loss: 1.9443720976511638

Epoch: 6| Step: 13
Training loss: 1.6777149438858032
Validation loss: 1.9467535217603047

Epoch: 42| Step: 0
Training loss: 2.1839137077331543
Validation loss: 1.9461412628491719

Epoch: 6| Step: 1
Training loss: 1.634800910949707
Validation loss: 1.9325059453646343

Epoch: 6| Step: 2
Training loss: 2.0873801708221436
Validation loss: 1.9530531764030457

Epoch: 6| Step: 3
Training loss: 1.6836028099060059
Validation loss: 1.938718279202779

Epoch: 6| Step: 4
Training loss: 2.156186580657959
Validation loss: 1.9585575262705486

Epoch: 6| Step: 5
Training loss: 1.2656108140945435
Validation loss: 1.9397000471750896

Epoch: 6| Step: 6
Training loss: 2.139080047607422
Validation loss: 1.9784905115763347

Epoch: 6| Step: 7
Training loss: 1.5402361154556274
Validation loss: 1.9802016019821167

Epoch: 6| Step: 8
Training loss: 1.910548448562622
Validation loss: 1.9439363479614258

Epoch: 6| Step: 9
Training loss: 2.0618157386779785
Validation loss: 1.93917715549469

Epoch: 6| Step: 10
Training loss: 2.244675397872925
Validation loss: 1.9297021428744

Epoch: 6| Step: 11
Training loss: 1.528901219367981
Validation loss: 1.9437540968259175

Epoch: 6| Step: 12
Training loss: 2.3341243267059326
Validation loss: 1.9587027629216511

Epoch: 6| Step: 13
Training loss: 1.7253153324127197
Validation loss: 1.9447892705599468

Epoch: 43| Step: 0
Training loss: 2.670290946960449
Validation loss: 1.9304959177970886

Epoch: 6| Step: 1
Training loss: 2.8565359115600586
Validation loss: 1.9267173409461975

Epoch: 6| Step: 2
Training loss: 1.7361772060394287
Validation loss: 1.9339786370595295

Epoch: 6| Step: 3
Training loss: 1.3281779289245605
Validation loss: 1.968747079372406

Epoch: 6| Step: 4
Training loss: 1.7827033996582031
Validation loss: 1.9393691023190816

Epoch: 6| Step: 5
Training loss: 2.0229992866516113
Validation loss: 1.9395657777786255

Epoch: 6| Step: 6
Training loss: 1.5645684003829956
Validation loss: 1.9314556519190471

Epoch: 6| Step: 7
Training loss: 2.3936758041381836
Validation loss: 1.9426353772481282

Epoch: 6| Step: 8
Training loss: 1.77327299118042
Validation loss: 1.9320947726567586

Epoch: 6| Step: 9
Training loss: 1.5741219520568848
Validation loss: 1.9487922191619873

Epoch: 6| Step: 10
Training loss: 1.5815439224243164
Validation loss: 1.9529455304145813

Epoch: 6| Step: 11
Training loss: 1.4253146648406982
Validation loss: 1.9459149440129597

Epoch: 6| Step: 12
Training loss: 2.1455657482147217
Validation loss: 1.958020846048991

Epoch: 6| Step: 13
Training loss: 1.4628021717071533
Validation loss: 1.960658589998881

Epoch: 44| Step: 0
Training loss: 2.5837254524230957
Validation loss: 1.9550844430923462

Epoch: 6| Step: 1
Training loss: 1.2598540782928467
Validation loss: 1.9488410949707031

Epoch: 6| Step: 2
Training loss: 1.8521833419799805
Validation loss: 1.9640142520268757

Epoch: 6| Step: 3
Training loss: 1.9295748472213745
Validation loss: 1.977735976378123

Epoch: 6| Step: 4
Training loss: 2.3463876247406006
Validation loss: 1.9665481646855671

Epoch: 6| Step: 5
Training loss: 2.611330986022949
Validation loss: 1.9937866926193237

Epoch: 6| Step: 6
Training loss: 2.4591622352600098
Validation loss: 1.9791030089060466

Epoch: 6| Step: 7
Training loss: 1.9768462181091309
Validation loss: 1.9621710777282715

Epoch: 6| Step: 8
Training loss: 1.2352826595306396
Validation loss: 1.9644626379013062

Epoch: 6| Step: 9
Training loss: 0.7384383678436279
Validation loss: 1.9630090991655986

Epoch: 6| Step: 10
Training loss: 2.0906596183776855
Validation loss: 1.9551736811796825

Epoch: 6| Step: 11
Training loss: 1.6116701364517212
Validation loss: 1.9292696118354797

Epoch: 6| Step: 12
Training loss: 1.8843903541564941
Validation loss: 1.924831748008728

Epoch: 6| Step: 13
Training loss: 1.753211259841919
Validation loss: 1.944554090499878

Epoch: 45| Step: 0
Training loss: 1.8461567163467407
Validation loss: 1.9422274231910706

Epoch: 6| Step: 1
Training loss: 2.2846498489379883
Validation loss: 1.9371986587842305

Epoch: 6| Step: 2
Training loss: 1.4880805015563965
Validation loss: 1.950482169787089

Epoch: 6| Step: 3
Training loss: 2.0441222190856934
Validation loss: 1.9448616703351338

Epoch: 6| Step: 4
Training loss: 2.3418774604797363
Validation loss: 1.9368401368459065

Epoch: 6| Step: 5
Training loss: 1.5744109153747559
Validation loss: 1.951015790303548

Epoch: 6| Step: 6
Training loss: 1.4164609909057617
Validation loss: 1.9525225758552551

Epoch: 6| Step: 7
Training loss: 2.188699245452881
Validation loss: 1.9480035702387493

Epoch: 6| Step: 8
Training loss: 2.263644218444824
Validation loss: 1.932599663734436

Epoch: 6| Step: 9
Training loss: 1.43929123878479
Validation loss: 1.9691073695818584

Epoch: 6| Step: 10
Training loss: 1.6790375709533691
Validation loss: 1.947109540303548

Epoch: 6| Step: 11
Training loss: 1.6328015327453613
Validation loss: 1.952333966890971

Epoch: 6| Step: 12
Training loss: 2.2774829864501953
Validation loss: 1.9406339724858601

Epoch: 6| Step: 13
Training loss: 1.8999905586242676
Validation loss: 1.9564185738563538

Epoch: 46| Step: 0
Training loss: 1.68340265750885
Validation loss: 1.9564793904622395

Epoch: 6| Step: 1
Training loss: 1.2310960292816162
Validation loss: 1.9589674870173137

Epoch: 6| Step: 2
Training loss: 2.7616257667541504
Validation loss: 1.9635995825131733

Epoch: 6| Step: 3
Training loss: 1.5431170463562012
Validation loss: 1.9704505403836567

Epoch: 6| Step: 4
Training loss: 2.174680709838867
Validation loss: 1.9798406958580017

Epoch: 6| Step: 5
Training loss: 1.5935430526733398
Validation loss: 1.9572422504425049

Epoch: 6| Step: 6
Training loss: 1.573939323425293
Validation loss: 1.9717076023419697

Epoch: 6| Step: 7
Training loss: 1.5581169128417969
Validation loss: 1.9774615565935771

Epoch: 6| Step: 8
Training loss: 2.142914056777954
Validation loss: 1.951234499613444

Epoch: 6| Step: 9
Training loss: 1.9723085165023804
Validation loss: 1.9464011192321777

Epoch: 6| Step: 10
Training loss: 1.1984963417053223
Validation loss: 1.9351205031077068

Epoch: 6| Step: 11
Training loss: 2.49405574798584
Validation loss: 1.959869643052419

Epoch: 6| Step: 12
Training loss: 1.6986231803894043
Validation loss: 1.933014730612437

Epoch: 6| Step: 13
Training loss: 2.5160603523254395
Validation loss: 1.940591832002004

Epoch: 47| Step: 0
Training loss: 1.7382869720458984
Validation loss: 1.9300684134165447

Epoch: 6| Step: 1
Training loss: 2.0400819778442383
Validation loss: 1.9397438565889995

Epoch: 6| Step: 2
Training loss: 1.5952774286270142
Validation loss: 1.9411959052085876

Epoch: 6| Step: 3
Training loss: 1.651179552078247
Validation loss: 1.945692280928294

Epoch: 6| Step: 4
Training loss: 1.8847784996032715
Validation loss: 1.960717459519704

Epoch: 6| Step: 5
Training loss: 1.5915718078613281
Validation loss: 1.9437299768129985

Epoch: 6| Step: 6
Training loss: 1.4909851551055908
Validation loss: 1.9579776326815288

Epoch: 6| Step: 7
Training loss: 2.1379191875457764
Validation loss: 1.9242702722549438

Epoch: 6| Step: 8
Training loss: 2.130551815032959
Validation loss: 1.9508350094159443

Epoch: 6| Step: 9
Training loss: 1.8916351795196533
Validation loss: 1.9722599188486736

Epoch: 6| Step: 10
Training loss: 2.3782012462615967
Validation loss: 1.962733785311381

Epoch: 6| Step: 11
Training loss: 1.6086676120758057
Validation loss: 1.9516225655873616

Epoch: 6| Step: 12
Training loss: 2.5351104736328125
Validation loss: 1.9391566514968872

Epoch: 6| Step: 13
Training loss: 1.4036160707473755
Validation loss: 1.9503489136695862

Epoch: 48| Step: 0
Training loss: 1.8492698669433594
Validation loss: 1.935141146183014

Epoch: 6| Step: 1
Training loss: 1.5383403301239014
Validation loss: 1.9429709513982136

Epoch: 6| Step: 2
Training loss: 2.0524115562438965
Validation loss: 1.9427744150161743

Epoch: 6| Step: 3
Training loss: 1.352452039718628
Validation loss: 1.940393606821696

Epoch: 6| Step: 4
Training loss: 3.1251864433288574
Validation loss: 1.9407442609469097

Epoch: 6| Step: 5
Training loss: 2.2130184173583984
Validation loss: 1.9611949920654297

Epoch: 6| Step: 6
Training loss: 2.2783288955688477
Validation loss: 1.9598666032155354

Epoch: 6| Step: 7
Training loss: 1.2430367469787598
Validation loss: 1.9660399158795674

Epoch: 6| Step: 8
Training loss: 1.2823703289031982
Validation loss: 1.9456099073092143

Epoch: 6| Step: 9
Training loss: 1.1723594665527344
Validation loss: 1.9455965956052144

Epoch: 6| Step: 10
Training loss: 1.6712825298309326
Validation loss: 1.9275181889533997

Epoch: 6| Step: 11
Training loss: 1.986707091331482
Validation loss: 1.9452883402506511

Epoch: 6| Step: 12
Training loss: 2.471653461456299
Validation loss: 1.937726656595866

Epoch: 6| Step: 13
Training loss: 1.8786072731018066
Validation loss: 1.949144462744395

Epoch: 49| Step: 0
Training loss: 2.0487678050994873
Validation loss: 1.9367700815200806

Epoch: 6| Step: 1
Training loss: 1.7800829410552979
Validation loss: 1.9580135941505432

Epoch: 6| Step: 2
Training loss: 2.043274402618408
Validation loss: 1.9406700134277344

Epoch: 6| Step: 3
Training loss: 1.6513245105743408
Validation loss: 1.9638508160909016

Epoch: 6| Step: 4
Training loss: 1.7335903644561768
Validation loss: 1.9367600480715434

Epoch: 6| Step: 5
Training loss: 1.0361422300338745
Validation loss: 1.9498020609219868

Epoch: 6| Step: 6
Training loss: 1.7211263179779053
Validation loss: 1.9688755869865417

Epoch: 6| Step: 7
Training loss: 1.6876353025436401
Validation loss: 1.9873028993606567

Epoch: 6| Step: 8
Training loss: 2.4176485538482666
Validation loss: 2.0023118058840432

Epoch: 6| Step: 9
Training loss: 1.839766263961792
Validation loss: 2.000829537709554

Epoch: 6| Step: 10
Training loss: 2.240726947784424
Validation loss: 1.9873568415641785

Epoch: 6| Step: 11
Training loss: 2.4002585411071777
Validation loss: 1.9775242805480957

Epoch: 6| Step: 12
Training loss: 1.6981096267700195
Validation loss: 1.9820229808489482

Epoch: 6| Step: 13
Training loss: 1.8846166133880615
Validation loss: 1.9680760502815247

Epoch: 50| Step: 0
Training loss: 2.244943618774414
Validation loss: 1.9633869330088298

Epoch: 6| Step: 1
Training loss: 2.228746175765991
Validation loss: 1.9574345350265503

Epoch: 6| Step: 2
Training loss: 2.204928398132324
Validation loss: 1.9461580514907837

Epoch: 6| Step: 3
Training loss: 1.7889282703399658
Validation loss: 1.9457119305928547

Epoch: 6| Step: 4
Training loss: 2.4177474975585938
Validation loss: 1.9471548199653625

Epoch: 6| Step: 5
Training loss: 1.874088168144226
Validation loss: 1.9497318665186565

Epoch: 6| Step: 6
Training loss: 1.6956493854522705
Validation loss: 1.9643121361732483

Epoch: 6| Step: 7
Training loss: 1.5589075088500977
Validation loss: 1.9710787137349446

Epoch: 6| Step: 8
Training loss: 1.579965591430664
Validation loss: 1.9415408372879028

Epoch: 6| Step: 9
Training loss: 1.7158294916152954
Validation loss: 1.9594468474388123

Epoch: 6| Step: 10
Training loss: 1.702183485031128
Validation loss: 1.954514781634013

Epoch: 6| Step: 11
Training loss: 1.5315988063812256
Validation loss: 1.9368329445521038

Epoch: 6| Step: 12
Training loss: 1.6663073301315308
Validation loss: 1.9456193844477336

Epoch: 6| Step: 13
Training loss: 2.2806715965270996
Validation loss: 1.9435208439826965

Epoch: 51| Step: 0
Training loss: 2.252963066101074
Validation loss: 1.9467521905899048

Epoch: 6| Step: 1
Training loss: 1.5418370962142944
Validation loss: 1.9547623594601948

Epoch: 6| Step: 2
Training loss: 1.9347078800201416
Validation loss: 1.9770953059196472

Epoch: 6| Step: 3
Training loss: 1.6276496648788452
Validation loss: 1.9803582827250164

Epoch: 6| Step: 4
Training loss: 2.191171884536743
Validation loss: 1.9646191199620564

Epoch: 6| Step: 5
Training loss: 2.0485782623291016
Validation loss: 1.952334463596344

Epoch: 6| Step: 6
Training loss: 1.5294897556304932
Validation loss: 1.9589826464653015

Epoch: 6| Step: 7
Training loss: 1.8023189306259155
Validation loss: 1.942883570988973

Epoch: 6| Step: 8
Training loss: 1.9308466911315918
Validation loss: 1.964313228925069

Epoch: 6| Step: 9
Training loss: 2.0286078453063965
Validation loss: 1.9680073062578838

Epoch: 6| Step: 10
Training loss: 1.6538399457931519
Validation loss: 1.9624181191126506

Epoch: 6| Step: 11
Training loss: 1.3418725728988647
Validation loss: 1.9530556400616963

Epoch: 6| Step: 12
Training loss: 2.257693290710449
Validation loss: 1.9689265092213948

Epoch: 6| Step: 13
Training loss: 1.8114217519760132
Validation loss: 1.9555272062619526

Epoch: 52| Step: 0
Training loss: 1.789113998413086
Validation loss: 1.9634280403455098

Epoch: 6| Step: 1
Training loss: 1.1915937662124634
Validation loss: 1.9556579788525899

Epoch: 6| Step: 2
Training loss: 1.8349546194076538
Validation loss: 1.964102526505788

Epoch: 6| Step: 3
Training loss: 1.3588685989379883
Validation loss: 1.9498895406723022

Epoch: 6| Step: 4
Training loss: 1.6228320598602295
Validation loss: 1.96004056930542

Epoch: 6| Step: 5
Training loss: 1.2510747909545898
Validation loss: 1.9586405555407207

Epoch: 6| Step: 6
Training loss: 1.8283429145812988
Validation loss: 1.9786638021469116

Epoch: 6| Step: 7
Training loss: 2.0194191932678223
Validation loss: 1.9656996528307598

Epoch: 6| Step: 8
Training loss: 2.2116451263427734
Validation loss: 1.981197675069173

Epoch: 6| Step: 9
Training loss: 2.1616640090942383
Validation loss: 1.9929843544960022

Epoch: 6| Step: 10
Training loss: 2.332496166229248
Validation loss: 2.0008814136187234

Epoch: 6| Step: 11
Training loss: 2.5906286239624023
Validation loss: 1.9761773745218914

Epoch: 6| Step: 12
Training loss: 1.2894119024276733
Validation loss: 1.9986900091171265

Epoch: 6| Step: 13
Training loss: 2.310214042663574
Validation loss: 1.9873398542404175

Epoch: 53| Step: 0
Training loss: 1.6896538734436035
Validation loss: 1.9745769302050273

Epoch: 6| Step: 1
Training loss: 1.1351230144500732
Validation loss: 1.968649943669637

Epoch: 6| Step: 2
Training loss: 1.7615097761154175
Validation loss: 1.9845767815907795

Epoch: 6| Step: 3
Training loss: 1.4538660049438477
Validation loss: 1.9481947620709736

Epoch: 6| Step: 4
Training loss: 2.3931546211242676
Validation loss: 1.963947316010793

Epoch: 6| Step: 5
Training loss: 2.2091996669769287
Validation loss: 1.9587553143501282

Epoch: 6| Step: 6
Training loss: 1.6191606521606445
Validation loss: 1.9543899695078533

Epoch: 6| Step: 7
Training loss: 1.7437245845794678
Validation loss: 1.9698125918706257

Epoch: 6| Step: 8
Training loss: 2.226478099822998
Validation loss: 1.93047034740448

Epoch: 6| Step: 9
Training loss: 2.1759538650512695
Validation loss: 1.9462467829386394

Epoch: 6| Step: 10
Training loss: 1.9166340827941895
Validation loss: 1.96502552429835

Epoch: 6| Step: 11
Training loss: 1.993193507194519
Validation loss: 1.9628044366836548

Epoch: 6| Step: 12
Training loss: 1.3975149393081665
Validation loss: 1.953401545683543

Epoch: 6| Step: 13
Training loss: 1.9193427562713623
Validation loss: 1.9530640443166096

Epoch: 54| Step: 0
Training loss: 1.8178404569625854
Validation loss: 1.9656955003738403

Epoch: 6| Step: 1
Training loss: 1.7244758605957031
Validation loss: 1.9925407369931538

Epoch: 6| Step: 2
Training loss: 1.7507953643798828
Validation loss: 1.9752185344696045

Epoch: 6| Step: 3
Training loss: 2.184727907180786
Validation loss: 1.9683428804079692

Epoch: 6| Step: 4
Training loss: 1.4214088916778564
Validation loss: 1.991779665152232

Epoch: 6| Step: 5
Training loss: 1.892829418182373
Validation loss: 1.9652297496795654

Epoch: 6| Step: 6
Training loss: 2.773033380508423
Validation loss: 1.9745161930720012

Epoch: 6| Step: 7
Training loss: 1.7443138360977173
Validation loss: 2.0019233028093972

Epoch: 6| Step: 8
Training loss: 1.507936954498291
Validation loss: 1.9818307956059773

Epoch: 6| Step: 9
Training loss: 1.066020131111145
Validation loss: 1.9689507484436035

Epoch: 6| Step: 10
Training loss: 1.7736339569091797
Validation loss: 1.9889904260635376

Epoch: 6| Step: 11
Training loss: 1.6750783920288086
Validation loss: 1.9626400868097942

Epoch: 6| Step: 12
Training loss: 1.679652452468872
Validation loss: 1.965060293674469

Epoch: 6| Step: 13
Training loss: 2.456850528717041
Validation loss: 1.9615893761316936

Epoch: 55| Step: 0
Training loss: 1.909116506576538
Validation loss: 1.9636317491531372

Epoch: 6| Step: 1
Training loss: 2.2276341915130615
Validation loss: 1.969340701897939

Epoch: 6| Step: 2
Training loss: 2.0167436599731445
Validation loss: 1.9665305217107136

Epoch: 6| Step: 3
Training loss: 1.4038560390472412
Validation loss: 1.9602097670237224

Epoch: 6| Step: 4
Training loss: 1.784400463104248
Validation loss: 1.9587839643160503

Epoch: 6| Step: 5
Training loss: 1.5367064476013184
Validation loss: 1.9650391340255737

Epoch: 6| Step: 6
Training loss: 1.5309386253356934
Validation loss: 1.9666020274162292

Epoch: 6| Step: 7
Training loss: 1.625551462173462
Validation loss: 1.9892614881197612

Epoch: 6| Step: 8
Training loss: 2.079420328140259
Validation loss: 1.9853212634722393

Epoch: 6| Step: 9
Training loss: 1.983994483947754
Validation loss: 1.9949532747268677

Epoch: 6| Step: 10
Training loss: 1.4713505506515503
Validation loss: 2.0014641483624778

Epoch: 6| Step: 11
Training loss: 1.9268089532852173
Validation loss: 2.005994359652201

Epoch: 6| Step: 12
Training loss: 1.8019177913665771
Validation loss: 2.033940076828003

Epoch: 6| Step: 13
Training loss: 2.105027914047241
Validation loss: 2.0233813722928367

Epoch: 56| Step: 0
Training loss: 2.4086685180664062
Validation loss: 2.0153287649154663

Epoch: 6| Step: 1
Training loss: 1.6434160470962524
Validation loss: 2.015824635823568

Epoch: 6| Step: 2
Training loss: 1.4787139892578125
Validation loss: 2.0089521606763205

Epoch: 6| Step: 3
Training loss: 1.80130934715271
Validation loss: 1.9954830209414165

Epoch: 6| Step: 4
Training loss: 1.7707585096359253
Validation loss: 1.9863712588946025

Epoch: 6| Step: 5
Training loss: 1.6016579866409302
Validation loss: 1.9812150796254475

Epoch: 6| Step: 6
Training loss: 2.1562976837158203
Validation loss: 1.9817025264104207

Epoch: 6| Step: 7
Training loss: 1.5665700435638428
Validation loss: 1.9616732597351074

Epoch: 6| Step: 8
Training loss: 1.5875561237335205
Validation loss: 1.9779810309410095

Epoch: 6| Step: 9
Training loss: 2.4381375312805176
Validation loss: 1.9403276443481445

Epoch: 6| Step: 10
Training loss: 1.8656573295593262
Validation loss: 1.9421471158663433

Epoch: 6| Step: 11
Training loss: 1.6718226671218872
Validation loss: 1.9462883273760478

Epoch: 6| Step: 12
Training loss: 2.0436809062957764
Validation loss: 1.945663829644521

Epoch: 6| Step: 13
Training loss: 1.7614374160766602
Validation loss: 1.9646055301030476

Epoch: 57| Step: 0
Training loss: 1.8325344324111938
Validation loss: 1.9574254552523296

Epoch: 6| Step: 1
Training loss: 1.6614024639129639
Validation loss: 1.9574812451998393

Epoch: 6| Step: 2
Training loss: 1.559104323387146
Validation loss: 1.9652656714121501

Epoch: 6| Step: 3
Training loss: 2.1126556396484375
Validation loss: 1.955934226512909

Epoch: 6| Step: 4
Training loss: 1.9156930446624756
Validation loss: 1.9951302806536357

Epoch: 6| Step: 5
Training loss: 1.7218854427337646
Validation loss: 1.9953601956367493

Epoch: 6| Step: 6
Training loss: 1.5348105430603027
Validation loss: 1.9858128825823467

Epoch: 6| Step: 7
Training loss: 2.176243782043457
Validation loss: 1.9871463576952617

Epoch: 6| Step: 8
Training loss: 1.963226079940796
Validation loss: 1.9957354068756104

Epoch: 6| Step: 9
Training loss: 1.6315828561782837
Validation loss: 2.002955158551534

Epoch: 6| Step: 10
Training loss: 1.8731043338775635
Validation loss: 2.0056005318959556

Epoch: 6| Step: 11
Training loss: 1.6435502767562866
Validation loss: 2.018708606561025

Epoch: 6| Step: 12
Training loss: 1.9071201086044312
Validation loss: 1.9722883303960164

Epoch: 6| Step: 13
Training loss: 1.6571736335754395
Validation loss: 1.9919468959172566

Epoch: 58| Step: 0
Training loss: 1.5729973316192627
Validation loss: 2.0008817513783774

Epoch: 6| Step: 1
Training loss: 1.8524824380874634
Validation loss: 2.010630488395691

Epoch: 6| Step: 2
Training loss: 1.855682611465454
Validation loss: 1.9600618680318196

Epoch: 6| Step: 3
Training loss: 3.144742012023926
Validation loss: 1.9712387522061665

Epoch: 6| Step: 4
Training loss: 1.6920979022979736
Validation loss: 1.9645356734593709

Epoch: 6| Step: 5
Training loss: 1.5430753231048584
Validation loss: 1.9782568216323853

Epoch: 6| Step: 6
Training loss: 1.3369488716125488
Validation loss: 1.960255761941274

Epoch: 6| Step: 7
Training loss: 0.9782899618148804
Validation loss: 1.995842953523

Epoch: 6| Step: 8
Training loss: 2.39278507232666
Validation loss: 1.9771004716555278

Epoch: 6| Step: 9
Training loss: 1.643359661102295
Validation loss: 1.9614812930425007

Epoch: 6| Step: 10
Training loss: 1.650252342224121
Validation loss: 1.9544623494148254

Epoch: 6| Step: 11
Training loss: 1.991868495941162
Validation loss: 1.9324822028477986

Epoch: 6| Step: 12
Training loss: 1.6539993286132812
Validation loss: 1.9721311330795288

Epoch: 6| Step: 13
Training loss: 1.807917594909668
Validation loss: 1.9511551260948181

Epoch: 59| Step: 0
Training loss: 1.730891466140747
Validation loss: 1.9490957061449687

Epoch: 6| Step: 1
Training loss: 2.065692901611328
Validation loss: 1.9725667635599773

Epoch: 6| Step: 2
Training loss: 1.6232807636260986
Validation loss: 1.9849563241004944

Epoch: 6| Step: 3
Training loss: 1.6702345609664917
Validation loss: 1.9676948587099712

Epoch: 6| Step: 4
Training loss: 2.3679275512695312
Validation loss: 1.9756470521291096

Epoch: 6| Step: 5
Training loss: 1.9783003330230713
Validation loss: 1.991663972536723

Epoch: 6| Step: 6
Training loss: 1.4718097448349
Validation loss: 2.0070337653160095

Epoch: 6| Step: 7
Training loss: 1.4500095844268799
Validation loss: 2.01131800810496

Epoch: 6| Step: 8
Training loss: 1.7162203788757324
Validation loss: 2.0026590824127197

Epoch: 6| Step: 9
Training loss: 1.7588801383972168
Validation loss: 1.9833160042762756

Epoch: 6| Step: 10
Training loss: 2.0076868534088135
Validation loss: 2.00914873679479

Epoch: 6| Step: 11
Training loss: 2.1031248569488525
Validation loss: 2.0011540253957114

Epoch: 6| Step: 12
Training loss: 1.7920787334442139
Validation loss: 2.0042618910471597

Epoch: 6| Step: 13
Training loss: 1.4054996967315674
Validation loss: 2.002256174882253

Epoch: 60| Step: 0
Training loss: 2.076563835144043
Validation loss: 1.97757093111674

Epoch: 6| Step: 1
Training loss: 1.5672012567520142
Validation loss: 1.9819070100784302

Epoch: 6| Step: 2
Training loss: 1.9788963794708252
Validation loss: 1.9710118770599365

Epoch: 6| Step: 3
Training loss: 2.1739068031311035
Validation loss: 1.9410721063613892

Epoch: 6| Step: 4
Training loss: 1.5566983222961426
Validation loss: 1.939993679523468

Epoch: 6| Step: 5
Training loss: 2.0889768600463867
Validation loss: 1.9576966365178425

Epoch: 6| Step: 6
Training loss: 1.659881830215454
Validation loss: 1.966046412785848

Epoch: 6| Step: 7
Training loss: 1.586176872253418
Validation loss: 1.9510780970255535

Epoch: 6| Step: 8
Training loss: 1.432668685913086
Validation loss: 1.9580626686414082

Epoch: 6| Step: 9
Training loss: 1.788157343864441
Validation loss: 1.9822383721669514

Epoch: 6| Step: 10
Training loss: 2.314659595489502
Validation loss: 1.9805338581403096

Epoch: 6| Step: 11
Training loss: 2.117313861846924
Validation loss: 1.9870645801226299

Epoch: 6| Step: 12
Training loss: 2.2499632835388184
Validation loss: 1.9947225252787273

Epoch: 6| Step: 13
Training loss: 0.8216856122016907
Validation loss: 2.0092087586720786

Epoch: 61| Step: 0
Training loss: 1.1428618431091309
Validation loss: 2.026686668395996

Epoch: 6| Step: 1
Training loss: 1.621924638748169
Validation loss: 2.0226287245750427

Epoch: 6| Step: 2
Training loss: 1.6118748188018799
Validation loss: 2.012722134590149

Epoch: 6| Step: 3
Training loss: 1.1881269216537476
Validation loss: 2.000676910082499

Epoch: 6| Step: 4
Training loss: 1.7924726009368896
Validation loss: 2.0157307386398315

Epoch: 6| Step: 5
Training loss: 2.2526025772094727
Validation loss: 2.0078322887420654

Epoch: 6| Step: 6
Training loss: 1.7140114307403564
Validation loss: 2.0104238390922546

Epoch: 6| Step: 7
Training loss: 1.4163727760314941
Validation loss: 1.9918015003204346

Epoch: 6| Step: 8
Training loss: 1.807797908782959
Validation loss: 1.9785914619763691

Epoch: 6| Step: 9
Training loss: 2.125706434249878
Validation loss: 1.9775204261144002

Epoch: 6| Step: 10
Training loss: 1.9832977056503296
Validation loss: 1.967359483242035

Epoch: 6| Step: 11
Training loss: 2.0742015838623047
Validation loss: 1.9637715419133503

Epoch: 6| Step: 12
Training loss: 2.075590133666992
Validation loss: 1.9676542282104492

Epoch: 6| Step: 13
Training loss: 2.1040759086608887
Validation loss: 1.9660309354464214

Epoch: 62| Step: 0
Training loss: 2.26709246635437
Validation loss: 1.9372824430465698

Epoch: 6| Step: 1
Training loss: 1.0198078155517578
Validation loss: 1.9675650000572205

Epoch: 6| Step: 2
Training loss: 1.6222572326660156
Validation loss: 1.9490536053975422

Epoch: 6| Step: 3
Training loss: 1.7657884359359741
Validation loss: 1.9917239944140117

Epoch: 6| Step: 4
Training loss: 1.4199013710021973
Validation loss: 1.9842033982276917

Epoch: 6| Step: 5
Training loss: 1.676563024520874
Validation loss: 1.9939042925834656

Epoch: 6| Step: 6
Training loss: 2.1088438034057617
Validation loss: 2.000041981538137

Epoch: 6| Step: 7
Training loss: 1.4691076278686523
Validation loss: 1.979997158050537

Epoch: 6| Step: 8
Training loss: 1.2011613845825195
Validation loss: 2.009412666161855

Epoch: 6| Step: 9
Training loss: 2.0882253646850586
Validation loss: 1.9828826387723286

Epoch: 6| Step: 10
Training loss: 1.658844232559204
Validation loss: 2.0185064673423767

Epoch: 6| Step: 11
Training loss: 2.165750026702881
Validation loss: 1.982652485370636

Epoch: 6| Step: 12
Training loss: 1.7545560598373413
Validation loss: 2.011458396911621

Epoch: 6| Step: 13
Training loss: 2.3165087699890137
Validation loss: 2.0366795857747397

Epoch: 63| Step: 0
Training loss: 1.4885382652282715
Validation loss: 1.993876059850057

Epoch: 6| Step: 1
Training loss: 1.8479593992233276
Validation loss: 1.9834612607955933

Epoch: 6| Step: 2
Training loss: 1.7318782806396484
Validation loss: 1.9857318997383118

Epoch: 6| Step: 3
Training loss: 1.5892809629440308
Validation loss: 1.9913058678309123

Epoch: 6| Step: 4
Training loss: 1.5455472469329834
Validation loss: 1.9670458833376567

Epoch: 6| Step: 5
Training loss: 2.4275925159454346
Validation loss: 1.9687823454538982

Epoch: 6| Step: 6
Training loss: 1.992911696434021
Validation loss: 1.9776380856831868

Epoch: 6| Step: 7
Training loss: 1.338420033454895
Validation loss: 1.9631137450536091

Epoch: 6| Step: 8
Training loss: 1.5259822607040405
Validation loss: 1.9671815832455952

Epoch: 6| Step: 9
Training loss: 1.7418007850646973
Validation loss: 1.9524362881978352

Epoch: 6| Step: 10
Training loss: 1.410279631614685
Validation loss: 1.9877217809359233

Epoch: 6| Step: 11
Training loss: 2.542083740234375
Validation loss: 2.007485290368398

Epoch: 6| Step: 12
Training loss: 1.4067084789276123
Validation loss: 2.0193100372950235

Epoch: 6| Step: 13
Training loss: 2.148007869720459
Validation loss: 1.9887184103329976

Epoch: 64| Step: 0
Training loss: 1.787153720855713
Validation loss: 2.0232082406679788

Epoch: 6| Step: 1
Training loss: 1.6599912643432617
Validation loss: 2.034897247950236

Epoch: 6| Step: 2
Training loss: 1.0896683931350708
Validation loss: 2.0637008349100747

Epoch: 6| Step: 3
Training loss: 1.913343071937561
Validation loss: 2.0651009678840637

Epoch: 6| Step: 4
Training loss: 1.6634562015533447
Validation loss: 2.0408426920572915

Epoch: 6| Step: 5
Training loss: 1.399109125137329
Validation loss: 2.04247909784317

Epoch: 6| Step: 6
Training loss: 1.6614165306091309
Validation loss: 2.0353571573893228

Epoch: 6| Step: 7
Training loss: 1.9433388710021973
Validation loss: 2.0076645612716675

Epoch: 6| Step: 8
Training loss: 2.134087085723877
Validation loss: 2.019206722577413

Epoch: 6| Step: 9
Training loss: 2.359731674194336
Validation loss: 2.0004709164301553

Epoch: 6| Step: 10
Training loss: 1.729803442955017
Validation loss: 1.9733952085177104

Epoch: 6| Step: 11
Training loss: 1.3722169399261475
Validation loss: 1.9744778474171956

Epoch: 6| Step: 12
Training loss: 1.8121846914291382
Validation loss: 1.9736279050509136

Epoch: 6| Step: 13
Training loss: 2.0882840156555176
Validation loss: 1.9638428092002869

Epoch: 65| Step: 0
Training loss: 1.8225582838058472
Validation loss: 1.9578807751337688

Epoch: 6| Step: 1
Training loss: 1.7132731676101685
Validation loss: 1.9519901474316914

Epoch: 6| Step: 2
Training loss: 1.7788928747177124
Validation loss: 1.9740563829739888

Epoch: 6| Step: 3
Training loss: 1.7905049324035645
Validation loss: 1.966207484404246

Epoch: 6| Step: 4
Training loss: 2.024442672729492
Validation loss: 1.9797651569048564

Epoch: 6| Step: 5
Training loss: 2.03374981880188
Validation loss: 1.993924081325531

Epoch: 6| Step: 6
Training loss: 1.9101524353027344
Validation loss: 1.9861360987027485

Epoch: 6| Step: 7
Training loss: 1.5566482543945312
Validation loss: 1.9901188611984253

Epoch: 6| Step: 8
Training loss: 1.1414453983306885
Validation loss: 2.009620249271393

Epoch: 6| Step: 9
Training loss: 1.7058196067810059
Validation loss: 2.011895457903544

Epoch: 6| Step: 10
Training loss: 2.188465118408203
Validation loss: 1.9971603552500408

Epoch: 6| Step: 11
Training loss: 1.3160239458084106
Validation loss: 2.0063244104385376

Epoch: 6| Step: 12
Training loss: 1.692497730255127
Validation loss: 2.0232350826263428

Epoch: 6| Step: 13
Training loss: 2.0150673389434814
Validation loss: 2.007719616095225

Epoch: 66| Step: 0
Training loss: 1.3816401958465576
Validation loss: 2.009356220563253

Epoch: 6| Step: 1
Training loss: 1.9766095876693726
Validation loss: 2.0177645683288574

Epoch: 6| Step: 2
Training loss: 2.0389018058776855
Validation loss: 2.018477976322174

Epoch: 6| Step: 3
Training loss: 1.7438734769821167
Validation loss: 2.0169418255488076

Epoch: 6| Step: 4
Training loss: 1.6569362878799438
Validation loss: 2.0061803261439004

Epoch: 6| Step: 5
Training loss: 1.4022047519683838
Validation loss: 2.0303375323613486

Epoch: 6| Step: 6
Training loss: 1.5915346145629883
Validation loss: 2.001350005467733

Epoch: 6| Step: 7
Training loss: 1.1135610342025757
Validation loss: 2.010781208674113

Epoch: 6| Step: 8
Training loss: 1.565744400024414
Validation loss: 2.0119203130404153

Epoch: 6| Step: 9
Training loss: 1.887033462524414
Validation loss: 2.0091298818588257

Epoch: 6| Step: 10
Training loss: 2.1036148071289062
Validation loss: 2.002555767695109

Epoch: 6| Step: 11
Training loss: 1.9605013132095337
Validation loss: 2.0256888469060264

Epoch: 6| Step: 12
Training loss: 1.9061405658721924
Validation loss: 2.0129966735839844

Epoch: 6| Step: 13
Training loss: 1.7333626747131348
Validation loss: 2.005392611026764

Epoch: 67| Step: 0
Training loss: 1.7993998527526855
Validation loss: 2.0088579456011453

Epoch: 6| Step: 1
Training loss: 1.3487403392791748
Validation loss: 1.9858777324358623

Epoch: 6| Step: 2
Training loss: 2.076059579849243
Validation loss: 1.9948468406995137

Epoch: 6| Step: 3
Training loss: 1.0626592636108398
Validation loss: 1.9808982213338215

Epoch: 6| Step: 4
Training loss: 1.4782536029815674
Validation loss: 2.003669281800588

Epoch: 6| Step: 5
Training loss: 1.3243663311004639
Validation loss: 1.9948342442512512

Epoch: 6| Step: 6
Training loss: 2.011941909790039
Validation loss: 2.0019366343816123

Epoch: 6| Step: 7
Training loss: 2.145012617111206
Validation loss: 2.0014039278030396

Epoch: 6| Step: 8
Training loss: 2.2208924293518066
Validation loss: 2.005086878935496

Epoch: 6| Step: 9
Training loss: 1.7544212341308594
Validation loss: 1.9882232944170635

Epoch: 6| Step: 10
Training loss: 1.6789741516113281
Validation loss: 1.9984299540519714

Epoch: 6| Step: 11
Training loss: 1.5391188859939575
Validation loss: 2.0133045315742493

Epoch: 6| Step: 12
Training loss: 1.8196349143981934
Validation loss: 2.003424564997355

Epoch: 6| Step: 13
Training loss: 1.6714237928390503
Validation loss: 2.008670767148336

Epoch: 68| Step: 0
Training loss: 1.4132238626480103
Validation loss: 2.0270360708236694

Epoch: 6| Step: 1
Training loss: 1.91875422000885
Validation loss: 2.0065933664639792

Epoch: 6| Step: 2
Training loss: 1.442784309387207
Validation loss: 2.012151777744293

Epoch: 6| Step: 3
Training loss: 2.0570430755615234
Validation loss: 2.007555584112803

Epoch: 6| Step: 4
Training loss: 1.471149206161499
Validation loss: 2.0256651043891907

Epoch: 6| Step: 5
Training loss: 1.0953418016433716
Validation loss: 2.0101828575134277

Epoch: 6| Step: 6
Training loss: 1.579567790031433
Validation loss: 2.0137998859087625

Epoch: 6| Step: 7
Training loss: 1.6446270942687988
Validation loss: 2.008093257745107

Epoch: 6| Step: 8
Training loss: 1.5420640707015991
Validation loss: 2.020805378754934

Epoch: 6| Step: 9
Training loss: 2.0610604286193848
Validation loss: 1.9958523313204448

Epoch: 6| Step: 10
Training loss: 1.3466079235076904
Validation loss: 1.9983763496081035

Epoch: 6| Step: 11
Training loss: 2.323075771331787
Validation loss: 2.00494376818339

Epoch: 6| Step: 12
Training loss: 2.0784640312194824
Validation loss: 2.0073217352231345

Epoch: 6| Step: 13
Training loss: 1.5964303016662598
Validation loss: 1.9995402495066326

Epoch: 69| Step: 0
Training loss: 2.1819894313812256
Validation loss: 2.0038350423177085

Epoch: 6| Step: 1
Training loss: 1.1603821516036987
Validation loss: 1.9918068051338196

Epoch: 6| Step: 2
Training loss: 1.3570666313171387
Validation loss: 1.9764730334281921

Epoch: 6| Step: 3
Training loss: 1.5810911655426025
Validation loss: 1.9843566417694092

Epoch: 6| Step: 4
Training loss: 1.3991162776947021
Validation loss: 2.009519636631012

Epoch: 6| Step: 5
Training loss: 2.29763126373291
Validation loss: 2.039294183254242

Epoch: 6| Step: 6
Training loss: 1.5432183742523193
Validation loss: 2.04910542567571

Epoch: 6| Step: 7
Training loss: 1.2366132736206055
Validation loss: 2.049921154975891

Epoch: 6| Step: 8
Training loss: 2.3492794036865234
Validation loss: 2.051845451196035

Epoch: 6| Step: 9
Training loss: 1.4594902992248535
Validation loss: 2.0194740692774453

Epoch: 6| Step: 10
Training loss: 1.4899685382843018
Validation loss: 2.04371839761734

Epoch: 6| Step: 11
Training loss: 1.9184194803237915
Validation loss: 2.0079579750696817

Epoch: 6| Step: 12
Training loss: 1.6045644283294678
Validation loss: 2.0128734509150186

Epoch: 6| Step: 13
Training loss: 2.1721999645233154
Validation loss: 1.9929168423016865

Epoch: 70| Step: 0
Training loss: 1.9187229871749878
Validation loss: 1.9811194936434429

Epoch: 6| Step: 1
Training loss: 1.7962971925735474
Validation loss: 1.9988098343213399

Epoch: 6| Step: 2
Training loss: 1.4987037181854248
Validation loss: 2.001747409502665

Epoch: 6| Step: 3
Training loss: 2.038700580596924
Validation loss: 2.0200770696004233

Epoch: 6| Step: 4
Training loss: 1.8780463933944702
Validation loss: 2.0340824127197266

Epoch: 6| Step: 5
Training loss: 1.7434786558151245
Validation loss: 1.9967055718104045

Epoch: 6| Step: 6
Training loss: 1.8755584955215454
Validation loss: 2.065142492453257

Epoch: 6| Step: 7
Training loss: 1.153997778892517
Validation loss: 2.056316335995992

Epoch: 6| Step: 8
Training loss: 1.2033005952835083
Validation loss: 2.0539204279581704

Epoch: 6| Step: 9
Training loss: 1.524369478225708
Validation loss: 2.064365029335022

Epoch: 6| Step: 10
Training loss: 2.1147782802581787
Validation loss: 2.0579089721043906

Epoch: 6| Step: 11
Training loss: 1.5948998928070068
Validation loss: 2.0310145219167075

Epoch: 6| Step: 12
Training loss: 1.7060514688491821
Validation loss: 2.0337785283724465

Epoch: 6| Step: 13
Training loss: 1.8133037090301514
Validation loss: 1.9945973753929138

Epoch: 71| Step: 0
Training loss: 0.9858773350715637
Validation loss: 1.9815186659495037

Epoch: 6| Step: 1
Training loss: 2.4073023796081543
Validation loss: 1.9941178560256958

Epoch: 6| Step: 2
Training loss: 1.7933940887451172
Validation loss: 1.996992329756419

Epoch: 6| Step: 3
Training loss: 1.3107593059539795
Validation loss: 1.9895047744115193

Epoch: 6| Step: 4
Training loss: 1.7454875707626343
Validation loss: 2.001246233781179

Epoch: 6| Step: 5
Training loss: 1.8693053722381592
Validation loss: 1.9922656218210857

Epoch: 6| Step: 6
Training loss: 1.487138271331787
Validation loss: 2.0028051932652793

Epoch: 6| Step: 7
Training loss: 2.049107789993286
Validation loss: 2.0173139174779258

Epoch: 6| Step: 8
Training loss: 1.6307282447814941
Validation loss: 2.0428523421287537

Epoch: 6| Step: 9
Training loss: 1.5904191732406616
Validation loss: 2.0766214728355408

Epoch: 6| Step: 10
Training loss: 1.5726763010025024
Validation loss: 2.071347177028656

Epoch: 6| Step: 11
Training loss: 1.8349862098693848
Validation loss: 2.094242433706919

Epoch: 6| Step: 12
Training loss: 1.6023051738739014
Validation loss: 2.1255014340082803

Epoch: 6| Step: 13
Training loss: 2.3121426105499268
Validation loss: 2.103239277998606

Epoch: 72| Step: 0
Training loss: 2.0781197547912598
Validation loss: 2.0992542107899985

Epoch: 6| Step: 1
Training loss: 1.691226601600647
Validation loss: 2.062089284261068

Epoch: 6| Step: 2
Training loss: 2.2988476753234863
Validation loss: 2.033300737539927

Epoch: 6| Step: 3
Training loss: 1.3763962984085083
Validation loss: 2.005427300930023

Epoch: 6| Step: 4
Training loss: 1.088111162185669
Validation loss: 2.017881174882253

Epoch: 6| Step: 5
Training loss: 2.158205032348633
Validation loss: 2.002991775671641

Epoch: 6| Step: 6
Training loss: 1.466111183166504
Validation loss: 2.0144184827804565

Epoch: 6| Step: 7
Training loss: 1.6333413124084473
Validation loss: 2.006866157054901

Epoch: 6| Step: 8
Training loss: 1.8331446647644043
Validation loss: 1.9774522185325623

Epoch: 6| Step: 9
Training loss: 1.471773624420166
Validation loss: 2.0022709568341575

Epoch: 6| Step: 10
Training loss: 1.9619864225387573
Validation loss: 2.0083271265029907

Epoch: 6| Step: 11
Training loss: 1.1593656539916992
Validation loss: 2.021615982055664

Epoch: 6| Step: 12
Training loss: 1.8057726621627808
Validation loss: 2.0201383233070374

Epoch: 6| Step: 13
Training loss: 1.6755340099334717
Validation loss: 2.0393771727879844

Epoch: 73| Step: 0
Training loss: 1.5171111822128296
Validation loss: 2.040777862071991

Epoch: 6| Step: 1
Training loss: 1.4698002338409424
Validation loss: 2.034569581349691

Epoch: 6| Step: 2
Training loss: 1.747296929359436
Validation loss: 2.0706008871396384

Epoch: 6| Step: 3
Training loss: 1.814975380897522
Validation loss: 2.0711461305618286

Epoch: 6| Step: 4
Training loss: 1.9419230222702026
Validation loss: 2.0412623484929404

Epoch: 6| Step: 5
Training loss: 1.2398262023925781
Validation loss: 2.092983663082123

Epoch: 6| Step: 6
Training loss: 1.611472249031067
Validation loss: 2.0402908325195312

Epoch: 6| Step: 7
Training loss: 2.2677464485168457
Validation loss: 2.052780270576477

Epoch: 6| Step: 8
Training loss: 1.465112328529358
Validation loss: 2.010069807370504

Epoch: 6| Step: 9
Training loss: 0.922426164150238
Validation loss: 2.0303276578585305

Epoch: 6| Step: 10
Training loss: 2.030299186706543
Validation loss: 2.012495299180349

Epoch: 6| Step: 11
Training loss: 2.2038278579711914
Validation loss: 1.9980990091959636

Epoch: 6| Step: 12
Training loss: 1.7229450941085815
Validation loss: 2.016019066174825

Epoch: 6| Step: 13
Training loss: 1.3403620719909668
Validation loss: 2.042916715145111

Epoch: 74| Step: 0
Training loss: 1.047468900680542
Validation loss: 1.9868761698404949

Epoch: 6| Step: 1
Training loss: 1.509635090827942
Validation loss: 1.9942978819211323

Epoch: 6| Step: 2
Training loss: 1.641977071762085
Validation loss: 2.0033215085665383

Epoch: 6| Step: 3
Training loss: 1.942697525024414
Validation loss: 1.987369179725647

Epoch: 6| Step: 4
Training loss: 1.2734180688858032
Validation loss: 2.00814555088679

Epoch: 6| Step: 5
Training loss: 1.6873053312301636
Validation loss: 2.0150665442148843

Epoch: 6| Step: 6
Training loss: 2.0795795917510986
Validation loss: 1.9853956699371338

Epoch: 6| Step: 7
Training loss: 1.7952412366867065
Validation loss: 2.029778261979421

Epoch: 6| Step: 8
Training loss: 1.7198724746704102
Validation loss: 2.002054810523987

Epoch: 6| Step: 9
Training loss: 1.9347344636917114
Validation loss: 2.0052457451820374

Epoch: 6| Step: 10
Training loss: 1.7836029529571533
Validation loss: 2.0257639288902283

Epoch: 6| Step: 11
Training loss: 1.3520526885986328
Validation loss: 2.0042468508084617

Epoch: 6| Step: 12
Training loss: 1.5778131484985352
Validation loss: 2.0264508724212646

Epoch: 6| Step: 13
Training loss: 1.6739535331726074
Validation loss: 2.0161094268163047

Epoch: 75| Step: 0
Training loss: 2.2980642318725586
Validation loss: 2.0419076879819236

Epoch: 6| Step: 1
Training loss: 1.140178918838501
Validation loss: 2.0681283672650657

Epoch: 6| Step: 2
Training loss: 1.7660568952560425
Validation loss: 2.0988346338272095

Epoch: 6| Step: 3
Training loss: 2.024177074432373
Validation loss: 2.0783355832099915

Epoch: 6| Step: 4
Training loss: 1.5781886577606201
Validation loss: 2.077237069606781

Epoch: 6| Step: 5
Training loss: 1.5193904638290405
Validation loss: 2.05988609790802

Epoch: 6| Step: 6
Training loss: 1.482323408126831
Validation loss: 2.07035360733668

Epoch: 6| Step: 7
Training loss: 1.6142901182174683
Validation loss: 2.0424551566441855

Epoch: 6| Step: 8
Training loss: 1.7641892433166504
Validation loss: 2.044306993484497

Epoch: 6| Step: 9
Training loss: 1.8274459838867188
Validation loss: 2.0463671882947287

Epoch: 6| Step: 10
Training loss: 1.2117396593093872
Validation loss: 2.000924368699392

Epoch: 6| Step: 11
Training loss: 1.8914779424667358
Validation loss: 2.0258124669392905

Epoch: 6| Step: 12
Training loss: 1.7352735996246338
Validation loss: 2.007412592569987

Epoch: 6| Step: 13
Training loss: 1.2571830749511719
Validation loss: 2.0286659399668374

Epoch: 76| Step: 0
Training loss: 1.5341438055038452
Validation loss: 2.0168463587760925

Epoch: 6| Step: 1
Training loss: 1.766322374343872
Validation loss: 2.0170622865358987

Epoch: 6| Step: 2
Training loss: 1.564573049545288
Validation loss: 2.009855349858602

Epoch: 6| Step: 3
Training loss: 1.3799902200698853
Validation loss: 2.0091020862261453

Epoch: 6| Step: 4
Training loss: 1.6785887479782104
Validation loss: 2.0380046168963113

Epoch: 6| Step: 5
Training loss: 1.6699721813201904
Validation loss: 2.0475876728693643

Epoch: 6| Step: 6
Training loss: 1.3999063968658447
Validation loss: 2.0676714976628623

Epoch: 6| Step: 7
Training loss: 1.7691673040390015
Validation loss: 2.06288210550944

Epoch: 6| Step: 8
Training loss: 1.1041306257247925
Validation loss: 2.066855311393738

Epoch: 6| Step: 9
Training loss: 1.7451155185699463
Validation loss: 2.021350860595703

Epoch: 6| Step: 10
Training loss: 1.7945722341537476
Validation loss: 2.0796210567156472

Epoch: 6| Step: 11
Training loss: 1.580444097518921
Validation loss: 2.0562185446421304

Epoch: 6| Step: 12
Training loss: 1.8666201829910278
Validation loss: 2.023643652598063

Epoch: 6| Step: 13
Training loss: 2.0378475189208984
Validation loss: 2.0529839992523193

Epoch: 77| Step: 0
Training loss: 1.297436237335205
Validation loss: 2.0447333455085754

Epoch: 6| Step: 1
Training loss: 1.8743232488632202
Validation loss: 2.0503352284431458

Epoch: 6| Step: 2
Training loss: 1.8328444957733154
Validation loss: 2.0430718461672464

Epoch: 6| Step: 3
Training loss: 1.3999230861663818
Validation loss: 2.0704729358355203

Epoch: 6| Step: 4
Training loss: 2.219433307647705
Validation loss: 2.03725395600001

Epoch: 6| Step: 5
Training loss: 1.9235680103302002
Validation loss: 2.0517112811406455

Epoch: 6| Step: 6
Training loss: 0.8485438823699951
Validation loss: 2.0669040083885193

Epoch: 6| Step: 7
Training loss: 1.678580641746521
Validation loss: 2.0371986031532288

Epoch: 6| Step: 8
Training loss: 1.6235308647155762
Validation loss: 2.0311518708864846

Epoch: 6| Step: 9
Training loss: 1.1586376428604126
Validation loss: 2.0168630083402

Epoch: 6| Step: 10
Training loss: 0.8000937104225159
Validation loss: 2.076667845249176

Epoch: 6| Step: 11
Training loss: 1.8097563982009888
Validation loss: 2.0364418427149453

Epoch: 6| Step: 12
Training loss: 1.8027273416519165
Validation loss: 2.052009960015615

Epoch: 6| Step: 13
Training loss: 2.180874824523926
Validation loss: 2.059369703133901

Epoch: 78| Step: 0
Training loss: 1.6237519979476929
Validation loss: 2.061598539352417

Epoch: 6| Step: 1
Training loss: 1.662429928779602
Validation loss: 2.035136580467224

Epoch: 6| Step: 2
Training loss: 1.2868742942810059
Validation loss: 2.0381491780281067

Epoch: 6| Step: 3
Training loss: 1.7709863185882568
Validation loss: 2.035840650399526

Epoch: 6| Step: 4
Training loss: 1.574310541152954
Validation loss: 2.0330227613449097

Epoch: 6| Step: 5
Training loss: 1.1316728591918945
Validation loss: 2.043110966682434

Epoch: 6| Step: 6
Training loss: 1.4824025630950928
Validation loss: 2.0635649959246316

Epoch: 6| Step: 7
Training loss: 1.7217038869857788
Validation loss: 2.0459226171175637

Epoch: 6| Step: 8
Training loss: 0.9151638150215149
Validation loss: 2.0697928269704184

Epoch: 6| Step: 9
Training loss: 1.8584280014038086
Validation loss: 2.0780970056851706

Epoch: 6| Step: 10
Training loss: 1.844879388809204
Validation loss: 2.0985448956489563

Epoch: 6| Step: 11
Training loss: 1.9903188943862915
Validation loss: 2.0975911021232605

Epoch: 6| Step: 12
Training loss: 1.5093296766281128
Validation loss: 2.1059651374816895

Epoch: 6| Step: 13
Training loss: 2.2983481884002686
Validation loss: 2.066963334878286

Epoch: 79| Step: 0
Training loss: 1.9787216186523438
Validation loss: 2.0740155776341758

Epoch: 6| Step: 1
Training loss: 1.3119252920150757
Validation loss: 2.0587320923805237

Epoch: 6| Step: 2
Training loss: 2.2810187339782715
Validation loss: 2.0443225105603537

Epoch: 6| Step: 3
Training loss: 1.1994035243988037
Validation loss: 2.0055970350901284

Epoch: 6| Step: 4
Training loss: 1.7646207809448242
Validation loss: 2.028076628843943

Epoch: 6| Step: 5
Training loss: 1.932016372680664
Validation loss: 2.0278444290161133

Epoch: 6| Step: 6
Training loss: 1.3880574703216553
Validation loss: 2.060491899649302

Epoch: 6| Step: 7
Training loss: 1.9820301532745361
Validation loss: 2.0419062773386636

Epoch: 6| Step: 8
Training loss: 1.5220001935958862
Validation loss: 2.0457816918691

Epoch: 6| Step: 9
Training loss: 1.9630199670791626
Validation loss: 2.0302610993385315

Epoch: 6| Step: 10
Training loss: 1.2824727296829224
Validation loss: 2.0361562768618264

Epoch: 6| Step: 11
Training loss: 1.911322832107544
Validation loss: 2.0287802815437317

Epoch: 6| Step: 12
Training loss: 0.8739376068115234
Validation loss: 2.070052206516266

Epoch: 6| Step: 13
Training loss: 0.9860900640487671
Validation loss: 2.062068601449331

Epoch: 80| Step: 0
Training loss: 0.8670437335968018
Validation loss: 2.0955684781074524

Epoch: 6| Step: 1
Training loss: 1.313248634338379
Validation loss: 2.07341597477595

Epoch: 6| Step: 2
Training loss: 1.665796160697937
Validation loss: 2.0872207283973694

Epoch: 6| Step: 3
Training loss: 1.8606233596801758
Validation loss: 2.121620317300161

Epoch: 6| Step: 4
Training loss: 1.7987697124481201
Validation loss: 2.0979104240735373

Epoch: 6| Step: 5
Training loss: 1.708446979522705
Validation loss: 2.1214210788408914

Epoch: 6| Step: 6
Training loss: 1.3300532102584839
Validation loss: 2.082528034845988

Epoch: 6| Step: 7
Training loss: 1.4316043853759766
Validation loss: 2.0851856470108032

Epoch: 6| Step: 8
Training loss: 1.5893096923828125
Validation loss: 2.0517885287602744

Epoch: 6| Step: 9
Training loss: 1.0746958255767822
Validation loss: 2.092926025390625

Epoch: 6| Step: 10
Training loss: 1.7985622882843018
Validation loss: 2.0331960916519165

Epoch: 6| Step: 11
Training loss: 1.9854669570922852
Validation loss: 2.038015286127726

Epoch: 6| Step: 12
Training loss: 1.3121178150177002
Validation loss: 2.0352898637453714

Epoch: 6| Step: 13
Training loss: 2.447721242904663
Validation loss: 2.0246644020080566

Epoch: 81| Step: 0
Training loss: 1.5903210639953613
Validation loss: 2.0447043975194297

Epoch: 6| Step: 1
Training loss: 1.7403950691223145
Validation loss: 2.0121044317881265

Epoch: 6| Step: 2
Training loss: 1.5702192783355713
Validation loss: 2.0358203848203025

Epoch: 6| Step: 3
Training loss: 1.2050024271011353
Validation loss: 2.0258729259173074

Epoch: 6| Step: 4
Training loss: 1.4190171957015991
Validation loss: 2.073670526345571

Epoch: 6| Step: 5
Training loss: 1.882009506225586
Validation loss: 2.032007177670797

Epoch: 6| Step: 6
Training loss: 1.912651777267456
Validation loss: 2.0593883395195007

Epoch: 6| Step: 7
Training loss: 1.4332849979400635
Validation loss: 2.0912557244300842

Epoch: 6| Step: 8
Training loss: 1.7132136821746826
Validation loss: 2.090758442878723

Epoch: 6| Step: 9
Training loss: 1.593545913696289
Validation loss: 2.0962138573328652

Epoch: 6| Step: 10
Training loss: 1.4915573596954346
Validation loss: 2.106161574522654

Epoch: 6| Step: 11
Training loss: 1.294398307800293
Validation loss: 2.1214080850283303

Epoch: 6| Step: 12
Training loss: 1.5040959119796753
Validation loss: 2.072064757347107

Epoch: 6| Step: 13
Training loss: 1.7305779457092285
Validation loss: 2.063922564188639

Epoch: 82| Step: 0
Training loss: 2.181044101715088
Validation loss: 2.083683749039968

Epoch: 6| Step: 1
Training loss: 1.6778943538665771
Validation loss: 2.067160487174988

Epoch: 6| Step: 2
Training loss: 1.2565093040466309
Validation loss: 2.027902921040853

Epoch: 6| Step: 3
Training loss: 1.570648193359375
Validation loss: 2.0550732016563416

Epoch: 6| Step: 4
Training loss: 1.7835900783538818
Validation loss: 2.03196773926417

Epoch: 6| Step: 5
Training loss: 1.3215372562408447
Validation loss: 2.050078491369883

Epoch: 6| Step: 6
Training loss: 1.281494379043579
Validation loss: 2.0368065237998962

Epoch: 6| Step: 7
Training loss: 1.6092042922973633
Validation loss: 2.0417665044466653

Epoch: 6| Step: 8
Training loss: 1.8096189498901367
Validation loss: 2.0760809977849326

Epoch: 6| Step: 9
Training loss: 1.9696944952011108
Validation loss: 2.1329338947931924

Epoch: 6| Step: 10
Training loss: 1.3248450756072998
Validation loss: 2.09816841284434

Epoch: 6| Step: 11
Training loss: 1.767941951751709
Validation loss: 2.1357354323069253

Epoch: 6| Step: 12
Training loss: 1.4017287492752075
Validation loss: 2.107048590977987

Epoch: 6| Step: 13
Training loss: 1.316572904586792
Validation loss: 2.1201807459195456

Epoch: 83| Step: 0
Training loss: 1.4601366519927979
Validation loss: 2.1147050857543945

Epoch: 6| Step: 1
Training loss: 1.273160696029663
Validation loss: 2.0531122287114463

Epoch: 6| Step: 2
Training loss: 2.034881591796875
Validation loss: 2.0802631179491677

Epoch: 6| Step: 3
Training loss: 1.5054311752319336
Validation loss: 2.0709028442700705

Epoch: 6| Step: 4
Training loss: 1.4537585973739624
Validation loss: 2.0446237921714783

Epoch: 6| Step: 5
Training loss: 1.1655964851379395
Validation loss: 2.0474734902381897

Epoch: 6| Step: 6
Training loss: 1.8394372463226318
Validation loss: 2.082930346330007

Epoch: 6| Step: 7
Training loss: 1.4328513145446777
Validation loss: 2.084548075993856

Epoch: 6| Step: 8
Training loss: 2.023402690887451
Validation loss: 2.09786049524943

Epoch: 6| Step: 9
Training loss: 0.9298925399780273
Validation loss: 2.0948464274406433

Epoch: 6| Step: 10
Training loss: 1.3509929180145264
Validation loss: 2.0813243786493936

Epoch: 6| Step: 11
Training loss: 1.3884906768798828
Validation loss: 2.0769665042559304

Epoch: 6| Step: 12
Training loss: 2.3171932697296143
Validation loss: 2.0954061150550842

Epoch: 6| Step: 13
Training loss: 1.1896672248840332
Validation loss: 2.097935676574707

Epoch: 84| Step: 0
Training loss: 1.161269187927246
Validation loss: 2.0778640309969583

Epoch: 6| Step: 1
Training loss: 1.9613754749298096
Validation loss: 2.0731290578842163

Epoch: 6| Step: 2
Training loss: 1.4697165489196777
Validation loss: 2.060432573159536

Epoch: 6| Step: 3
Training loss: 1.4723536968231201
Validation loss: 2.071150024731954

Epoch: 6| Step: 4
Training loss: 1.231978178024292
Validation loss: 2.0531916419665017

Epoch: 6| Step: 5
Training loss: 1.2725436687469482
Validation loss: 2.0613990227381387

Epoch: 6| Step: 6
Training loss: 1.7929670810699463
Validation loss: 2.06604133049647

Epoch: 6| Step: 7
Training loss: 1.2803460359573364
Validation loss: 2.0279884934425354

Epoch: 6| Step: 8
Training loss: 1.9749205112457275
Validation loss: 2.086421529452006

Epoch: 6| Step: 9
Training loss: 1.2835570573806763
Validation loss: 2.054118355115255

Epoch: 6| Step: 10
Training loss: 1.6791908740997314
Validation loss: 2.092198352018992

Epoch: 6| Step: 11
Training loss: 1.5159976482391357
Validation loss: 2.0677675207455954

Epoch: 6| Step: 12
Training loss: 0.971703052520752
Validation loss: 2.0673049688339233

Epoch: 6| Step: 13
Training loss: 1.840287208557129
Validation loss: 2.0712345441182456

Epoch: 85| Step: 0
Training loss: 2.1188158988952637
Validation loss: 2.0844656427701316

Epoch: 6| Step: 1
Training loss: 1.639592170715332
Validation loss: 2.131331483523051

Epoch: 6| Step: 2
Training loss: 1.778378963470459
Validation loss: 2.1561941107114158

Epoch: 6| Step: 3
Training loss: 1.5577778816223145
Validation loss: 2.130416512489319

Epoch: 6| Step: 4
Training loss: 1.528904676437378
Validation loss: 2.1297112305959067

Epoch: 6| Step: 5
Training loss: 0.9561007022857666
Validation loss: 2.144368509451548

Epoch: 6| Step: 6
Training loss: 1.2843129634857178
Validation loss: 2.0918404261271157

Epoch: 6| Step: 7
Training loss: 1.0890754461288452
Validation loss: 2.0754311879475913

Epoch: 6| Step: 8
Training loss: 1.9635977745056152
Validation loss: 2.085355798403422

Epoch: 6| Step: 9
Training loss: 1.3582249879837036
Validation loss: 2.0649219751358032

Epoch: 6| Step: 10
Training loss: 1.6233024597167969
Validation loss: 2.0852756897608438

Epoch: 6| Step: 11
Training loss: 1.3990683555603027
Validation loss: 2.0708386103312173

Epoch: 6| Step: 12
Training loss: 1.5053389072418213
Validation loss: 2.0589175621668496

Epoch: 6| Step: 13
Training loss: 1.3457139730453491
Validation loss: 2.0469860235850015

Epoch: 86| Step: 0
Training loss: 1.2333849668502808
Validation loss: 2.0796298384666443

Epoch: 6| Step: 1
Training loss: 1.8102673292160034
Validation loss: 2.06193600098292

Epoch: 6| Step: 2
Training loss: 1.5515140295028687
Validation loss: 2.0756025314331055

Epoch: 6| Step: 3
Training loss: 1.437997579574585
Validation loss: 2.120534896850586

Epoch: 6| Step: 4
Training loss: 1.3019802570343018
Validation loss: 2.107587377230326

Epoch: 6| Step: 5
Training loss: 1.0815579891204834
Validation loss: 2.1560794512430825

Epoch: 6| Step: 6
Training loss: 1.351934552192688
Validation loss: 2.169031004110972

Epoch: 6| Step: 7
Training loss: 1.4360888004302979
Validation loss: 2.1341708103815713

Epoch: 6| Step: 8
Training loss: 1.8269931077957153
Validation loss: 2.1059104005495706

Epoch: 6| Step: 9
Training loss: 1.391530156135559
Validation loss: 2.083669066429138

Epoch: 6| Step: 10
Training loss: 1.6735975742340088
Validation loss: 2.0886582136154175

Epoch: 6| Step: 11
Training loss: 1.2674579620361328
Validation loss: 2.057249923547109

Epoch: 6| Step: 12
Training loss: 2.310882091522217
Validation loss: 2.0719708998998008

Epoch: 6| Step: 13
Training loss: 1.5335044860839844
Validation loss: 2.042604943116506

Epoch: 87| Step: 0
Training loss: 1.5374897718429565
Validation loss: 2.0515334010124207

Epoch: 6| Step: 1
Training loss: 1.9057726860046387
Validation loss: 2.0476967692375183

Epoch: 6| Step: 2
Training loss: 1.6244449615478516
Validation loss: 2.062592069307963

Epoch: 6| Step: 3
Training loss: 1.4039208889007568
Validation loss: 2.0385868350664773

Epoch: 6| Step: 4
Training loss: 1.5701768398284912
Validation loss: 2.063927491505941

Epoch: 6| Step: 5
Training loss: 1.4509315490722656
Validation loss: 2.0434499979019165

Epoch: 6| Step: 6
Training loss: 1.492096185684204
Validation loss: 2.0783727169036865

Epoch: 6| Step: 7
Training loss: 1.6229100227355957
Validation loss: 2.0757604440053306

Epoch: 6| Step: 8
Training loss: 1.6969308853149414
Validation loss: 2.1249866088231406

Epoch: 6| Step: 9
Training loss: 1.5366618633270264
Validation loss: 2.1637999415397644

Epoch: 6| Step: 10
Training loss: 1.185604214668274
Validation loss: 2.1808964212735495

Epoch: 6| Step: 11
Training loss: 1.6123173236846924
Validation loss: 2.1627143820126853

Epoch: 6| Step: 12
Training loss: 1.5032048225402832
Validation loss: 2.197752892971039

Epoch: 6| Step: 13
Training loss: 1.4254355430603027
Validation loss: 2.169320503870646

Epoch: 88| Step: 0
Training loss: 1.0421435832977295
Validation loss: 2.111508766810099

Epoch: 6| Step: 1
Training loss: 1.683393120765686
Validation loss: 2.103107134501139

Epoch: 6| Step: 2
Training loss: 1.7647039890289307
Validation loss: 2.1044238805770874

Epoch: 6| Step: 3
Training loss: 1.0096147060394287
Validation loss: 2.0624279975891113

Epoch: 6| Step: 4
Training loss: 1.772186279296875
Validation loss: 2.0541061957677207

Epoch: 6| Step: 5
Training loss: 1.1618757247924805
Validation loss: 2.061274309953054

Epoch: 6| Step: 6
Training loss: 1.2103620767593384
Validation loss: 2.042870819568634

Epoch: 6| Step: 7
Training loss: 1.217056155204773
Validation loss: 2.0633042057355246

Epoch: 6| Step: 8
Training loss: 1.531540870666504
Validation loss: 2.066823502381643

Epoch: 6| Step: 9
Training loss: 1.8674273490905762
Validation loss: 2.101081212361654

Epoch: 6| Step: 10
Training loss: 1.9880625009536743
Validation loss: 2.0912200808525085

Epoch: 6| Step: 11
Training loss: 1.5653550624847412
Validation loss: 2.1241008241971335

Epoch: 6| Step: 12
Training loss: 1.5509395599365234
Validation loss: 2.0949416160583496

Epoch: 6| Step: 13
Training loss: 1.6376837491989136
Validation loss: 2.1187917391459146

Epoch: 89| Step: 0
Training loss: 1.9038140773773193
Validation loss: 2.152419944604238

Epoch: 6| Step: 1
Training loss: 2.306347370147705
Validation loss: 2.132752478122711

Epoch: 6| Step: 2
Training loss: 1.4737882614135742
Validation loss: 2.097811222076416

Epoch: 6| Step: 3
Training loss: 1.5082064867019653
Validation loss: 2.0865631898244223

Epoch: 6| Step: 4
Training loss: 1.6961911916732788
Validation loss: 2.058509667714437

Epoch: 6| Step: 5
Training loss: 1.176310658454895
Validation loss: 2.1248249212900796

Epoch: 6| Step: 6
Training loss: 1.7366299629211426
Validation loss: 2.040953059991201

Epoch: 6| Step: 7
Training loss: 0.9233559370040894
Validation loss: 2.097531716028849

Epoch: 6| Step: 8
Training loss: 1.2298293113708496
Validation loss: 2.0734455982844033

Epoch: 6| Step: 9
Training loss: 1.9863336086273193
Validation loss: 2.060271898905436

Epoch: 6| Step: 10
Training loss: 1.1131367683410645
Validation loss: 2.0675379435221353

Epoch: 6| Step: 11
Training loss: 1.2213467359542847
Validation loss: 2.0751761198043823

Epoch: 6| Step: 12
Training loss: 0.7364178895950317
Validation loss: 2.096182028452555

Epoch: 6| Step: 13
Training loss: 1.1332985162734985
Validation loss: 2.095116436481476

Epoch: 90| Step: 0
Training loss: 1.5479578971862793
Validation loss: 2.0574054519335427

Epoch: 6| Step: 1
Training loss: 1.496460199356079
Validation loss: 2.142066160837809

Epoch: 6| Step: 2
Training loss: 1.421785831451416
Validation loss: 2.10774827003479

Epoch: 6| Step: 3
Training loss: 1.689408779144287
Validation loss: 2.0845480958620706

Epoch: 6| Step: 4
Training loss: 1.3766779899597168
Validation loss: 2.076801061630249

Epoch: 6| Step: 5
Training loss: 1.4132351875305176
Validation loss: 2.0897676746050515

Epoch: 6| Step: 6
Training loss: 1.3314341306686401
Validation loss: 2.0913071235020957

Epoch: 6| Step: 7
Training loss: 1.3613089323043823
Validation loss: 2.065240482489268

Epoch: 6| Step: 8
Training loss: 1.2181966304779053
Validation loss: 2.0554248889287314

Epoch: 6| Step: 9
Training loss: 1.3921724557876587
Validation loss: 2.1112161676088967

Epoch: 6| Step: 10
Training loss: 0.9944390654563904
Validation loss: 2.0920542081197104

Epoch: 6| Step: 11
Training loss: 2.090009927749634
Validation loss: 2.0567785700162253

Epoch: 6| Step: 12
Training loss: 1.3244818449020386
Validation loss: 2.070108711719513

Epoch: 6| Step: 13
Training loss: 1.303660273551941
Validation loss: 2.0898770491282144

Epoch: 91| Step: 0
Training loss: 1.595608115196228
Validation loss: 2.0739034612973533

Epoch: 6| Step: 1
Training loss: 1.0428996086120605
Validation loss: 2.0656039714813232

Epoch: 6| Step: 2
Training loss: 0.8535341024398804
Validation loss: 2.0725589990615845

Epoch: 6| Step: 3
Training loss: 1.3579379320144653
Validation loss: 2.071457346280416

Epoch: 6| Step: 4
Training loss: 1.2167599201202393
Validation loss: 2.0843178431193032

Epoch: 6| Step: 5
Training loss: 1.716537594795227
Validation loss: 2.094691296418508

Epoch: 6| Step: 6
Training loss: 1.2561293840408325
Validation loss: 2.1024359464645386

Epoch: 6| Step: 7
Training loss: 2.060220718383789
Validation loss: 2.101666251818339

Epoch: 6| Step: 8
Training loss: 1.5626022815704346
Validation loss: 2.101854840914408

Epoch: 6| Step: 9
Training loss: 0.8277439475059509
Validation loss: 2.112885355949402

Epoch: 6| Step: 10
Training loss: 1.7604783773422241
Validation loss: 2.069430947303772

Epoch: 6| Step: 11
Training loss: 1.4519643783569336
Validation loss: 2.1365472078323364

Epoch: 6| Step: 12
Training loss: 1.4445265531539917
Validation loss: 2.086341460545858

Epoch: 6| Step: 13
Training loss: 1.8816121816635132
Validation loss: 2.1039156317710876

Epoch: 92| Step: 0
Training loss: 1.3529083728790283
Validation loss: 2.088753640651703

Epoch: 6| Step: 1
Training loss: 1.216252088546753
Validation loss: 2.1098448634147644

Epoch: 6| Step: 2
Training loss: 1.3341045379638672
Validation loss: 2.088924209276835

Epoch: 6| Step: 3
Training loss: 1.3419151306152344
Validation loss: 2.0862915317217507

Epoch: 6| Step: 4
Training loss: 1.2893909215927124
Validation loss: 2.0699255069096885

Epoch: 6| Step: 5
Training loss: 1.8818572759628296
Validation loss: 2.1025928457578025

Epoch: 6| Step: 6
Training loss: 1.263224482536316
Validation loss: 2.1051268180211387

Epoch: 6| Step: 7
Training loss: 1.9295122623443604
Validation loss: 2.0946761767069497

Epoch: 6| Step: 8
Training loss: 1.401947259902954
Validation loss: 2.093038340409597

Epoch: 6| Step: 9
Training loss: 1.4869558811187744
Validation loss: 2.0815046032269797

Epoch: 6| Step: 10
Training loss: 1.0358240604400635
Validation loss: 2.0639756321907043

Epoch: 6| Step: 11
Training loss: 1.33454430103302
Validation loss: 2.080945869286855

Epoch: 6| Step: 12
Training loss: 1.4451498985290527
Validation loss: 2.087015688419342

Epoch: 6| Step: 13
Training loss: 1.5292291641235352
Validation loss: 2.075438300768534

Epoch: 93| Step: 0
Training loss: 1.673292875289917
Validation loss: 2.0661470095316568

Epoch: 6| Step: 1
Training loss: 1.1585943698883057
Validation loss: 2.1319666703542075

Epoch: 6| Step: 2
Training loss: 1.3855328559875488
Validation loss: 2.127136766910553

Epoch: 6| Step: 3
Training loss: 0.7654902935028076
Validation loss: 2.142102360725403

Epoch: 6| Step: 4
Training loss: 1.5964375734329224
Validation loss: 2.1483049194018045

Epoch: 6| Step: 5
Training loss: 2.150733470916748
Validation loss: 2.1266231338183084

Epoch: 6| Step: 6
Training loss: 1.0026215314865112
Validation loss: 2.0890093644460044

Epoch: 6| Step: 7
Training loss: 1.0278980731964111
Validation loss: 2.1177521347999573

Epoch: 6| Step: 8
Training loss: 1.0666089057922363
Validation loss: 2.134460727373759

Epoch: 6| Step: 9
Training loss: 2.021912097930908
Validation loss: 2.1034828821818032

Epoch: 6| Step: 10
Training loss: 1.93977689743042
Validation loss: 2.0958615144093833

Epoch: 6| Step: 11
Training loss: 0.9689703583717346
Validation loss: 2.0770573019981384

Epoch: 6| Step: 12
Training loss: 1.310118317604065
Validation loss: 2.078991452852885

Epoch: 6| Step: 13
Training loss: 1.3509199619293213
Validation loss: 2.1027616262435913

Epoch: 94| Step: 0
Training loss: 1.2182862758636475
Validation loss: 2.076829711596171

Epoch: 6| Step: 1
Training loss: 1.712148904800415
Validation loss: 2.0840412974357605

Epoch: 6| Step: 2
Training loss: 1.2000318765640259
Validation loss: 2.0608869791030884

Epoch: 6| Step: 3
Training loss: 1.829061508178711
Validation loss: 2.088406205177307

Epoch: 6| Step: 4
Training loss: 1.8681201934814453
Validation loss: 2.05866402387619

Epoch: 6| Step: 5
Training loss: 1.828914761543274
Validation loss: 2.1123356024424234

Epoch: 6| Step: 6
Training loss: 1.0778050422668457
Validation loss: 2.1144059101740518

Epoch: 6| Step: 7
Training loss: 1.3808543682098389
Validation loss: 2.0995919704437256

Epoch: 6| Step: 8
Training loss: 0.9142308831214905
Validation loss: 2.0689921180407205

Epoch: 6| Step: 9
Training loss: 1.324939489364624
Validation loss: 2.11011532942454

Epoch: 6| Step: 10
Training loss: 1.198075532913208
Validation loss: 2.097235302130381

Epoch: 6| Step: 11
Training loss: 1.2987923622131348
Validation loss: 2.1152095993359885

Epoch: 6| Step: 12
Training loss: 1.2577269077301025
Validation loss: 2.0933377544085183

Epoch: 6| Step: 13
Training loss: 1.263036847114563
Validation loss: 2.1218379934628806

Epoch: 95| Step: 0
Training loss: 0.7446645498275757
Validation loss: 2.100380559762319

Epoch: 6| Step: 1
Training loss: 1.7797489166259766
Validation loss: 2.101153314113617

Epoch: 6| Step: 2
Training loss: 1.1682682037353516
Validation loss: 2.0751217802365622

Epoch: 6| Step: 3
Training loss: 1.4699547290802002
Validation loss: 2.1032947500546775

Epoch: 6| Step: 4
Training loss: 1.620060682296753
Validation loss: 2.1049237648646035

Epoch: 6| Step: 5
Training loss: 1.2505210638046265
Validation loss: 2.07601261138916

Epoch: 6| Step: 6
Training loss: 2.11472225189209
Validation loss: 2.1225134134292603

Epoch: 6| Step: 7
Training loss: 0.8585515022277832
Validation loss: 2.1004148920377097

Epoch: 6| Step: 8
Training loss: 1.2862361669540405
Validation loss: 2.095521708329519

Epoch: 6| Step: 9
Training loss: 1.4526180028915405
Validation loss: 2.0901909867922464

Epoch: 6| Step: 10
Training loss: 1.3105318546295166
Validation loss: 2.0946827133496604

Epoch: 6| Step: 11
Training loss: 1.428357481956482
Validation loss: 2.12140691280365

Epoch: 6| Step: 12
Training loss: 1.5671303272247314
Validation loss: 2.139444669087728

Epoch: 6| Step: 13
Training loss: 1.0429871082305908
Validation loss: 2.143498480319977

Epoch: 96| Step: 0
Training loss: 0.67769455909729
Validation loss: 2.1644509633382163

Epoch: 6| Step: 1
Training loss: 0.9677094221115112
Validation loss: 2.1379589438438416

Epoch: 6| Step: 2
Training loss: 1.3961105346679688
Validation loss: 2.1589587330818176

Epoch: 6| Step: 3
Training loss: 0.725967288017273
Validation loss: 2.113223691781362

Epoch: 6| Step: 4
Training loss: 1.2282835245132446
Validation loss: 2.0603320399920144

Epoch: 6| Step: 5
Training loss: 1.698991060256958
Validation loss: 2.0840147336324057

Epoch: 6| Step: 6
Training loss: 1.3449511528015137
Validation loss: 2.086454768975576

Epoch: 6| Step: 7
Training loss: 1.7366394996643066
Validation loss: 2.098285694917043

Epoch: 6| Step: 8
Training loss: 1.0914902687072754
Validation loss: 2.057402948538462

Epoch: 6| Step: 9
Training loss: 1.5253047943115234
Validation loss: 2.0930302143096924

Epoch: 6| Step: 10
Training loss: 1.5730222463607788
Validation loss: 2.091344137986501

Epoch: 6| Step: 11
Training loss: 1.435237169265747
Validation loss: 2.1265412966410318

Epoch: 6| Step: 12
Training loss: 2.180936336517334
Validation loss: 2.1557013392448425

Epoch: 6| Step: 13
Training loss: 2.2034409046173096
Validation loss: 2.093726893266042

Epoch: 97| Step: 0
Training loss: 1.497509241104126
Validation loss: 2.171644707520803

Epoch: 6| Step: 1
Training loss: 1.885087490081787
Validation loss: 2.1585533618927

Epoch: 6| Step: 2
Training loss: 0.9767465591430664
Validation loss: 2.108832856019338

Epoch: 6| Step: 3
Training loss: 1.5967912673950195
Validation loss: 2.1268639961878457

Epoch: 6| Step: 4
Training loss: 0.880506157875061
Validation loss: 2.1039793888727822

Epoch: 6| Step: 5
Training loss: 1.2684773206710815
Validation loss: 2.0553299387296042

Epoch: 6| Step: 6
Training loss: 1.2179337739944458
Validation loss: 2.0887682835261026

Epoch: 6| Step: 7
Training loss: 1.3923757076263428
Validation loss: 2.068612356980642

Epoch: 6| Step: 8
Training loss: 1.3373173475265503
Validation loss: 2.06878391901652

Epoch: 6| Step: 9
Training loss: 0.907537043094635
Validation loss: 2.0457502404848733

Epoch: 6| Step: 10
Training loss: 1.4403311014175415
Validation loss: 2.065360188484192

Epoch: 6| Step: 11
Training loss: 1.2209477424621582
Validation loss: 2.089272896448771

Epoch: 6| Step: 12
Training loss: 1.7150765657424927
Validation loss: 2.0754969914754233

Epoch: 6| Step: 13
Training loss: 1.6033869981765747
Validation loss: 2.1165515979131064

Epoch: 98| Step: 0
Training loss: 0.7508226633071899
Validation loss: 2.0838067531585693

Epoch: 6| Step: 1
Training loss: 1.3041456937789917
Validation loss: 2.1201890309651694

Epoch: 6| Step: 2
Training loss: 1.8767116069793701
Validation loss: 2.1216394305229187

Epoch: 6| Step: 3
Training loss: 1.7872616052627563
Validation loss: 2.086030145486196

Epoch: 6| Step: 4
Training loss: 0.9277663826942444
Validation loss: 2.077519396940867

Epoch: 6| Step: 5
Training loss: 1.1219602823257446
Validation loss: 2.096262216567993

Epoch: 6| Step: 6
Training loss: 1.0221195220947266
Validation loss: 2.0821189085642495

Epoch: 6| Step: 7
Training loss: 1.2747820615768433
Validation loss: 2.059972584247589

Epoch: 6| Step: 8
Training loss: 1.4069794416427612
Validation loss: 2.1176762183507285

Epoch: 6| Step: 9
Training loss: 1.5821787118911743
Validation loss: 2.0966996351877847

Epoch: 6| Step: 10
Training loss: 1.846859335899353
Validation loss: 2.062731663386027

Epoch: 6| Step: 11
Training loss: 1.00881826877594
Validation loss: 2.058298865954081

Epoch: 6| Step: 12
Training loss: 1.4650055170059204
Validation loss: 2.0738240281740823

Epoch: 6| Step: 13
Training loss: 0.9188916683197021
Validation loss: 2.085686981678009

Epoch: 99| Step: 0
Training loss: 1.50577712059021
Validation loss: 2.0500064293543496

Epoch: 6| Step: 1
Training loss: 1.1767512559890747
Validation loss: 2.050025542577108

Epoch: 6| Step: 2
Training loss: 1.4565753936767578
Validation loss: 2.0850661396980286

Epoch: 6| Step: 3
Training loss: 1.5086801052093506
Validation loss: 2.098562022050222

Epoch: 6| Step: 4
Training loss: 0.9014173150062561
Validation loss: 2.0950366655985513

Epoch: 6| Step: 5
Training loss: 1.0089458227157593
Validation loss: 2.092413604259491

Epoch: 6| Step: 6
Training loss: 1.271606206893921
Validation loss: 2.097096800804138

Epoch: 6| Step: 7
Training loss: 1.0922143459320068
Validation loss: 2.094833811124166

Epoch: 6| Step: 8
Training loss: 1.938449740409851
Validation loss: 2.0985710422197976

Epoch: 6| Step: 9
Training loss: 1.1143107414245605
Validation loss: 2.119199514389038

Epoch: 6| Step: 10
Training loss: 1.0102622509002686
Validation loss: 2.0185353755950928

Epoch: 6| Step: 11
Training loss: 1.7586393356323242
Validation loss: 2.095035890738169

Epoch: 6| Step: 12
Training loss: 1.6021571159362793
Validation loss: 2.103545308113098

Epoch: 6| Step: 13
Training loss: 0.8350071907043457
Validation loss: 2.0834895769755044

Epoch: 100| Step: 0
Training loss: 1.1382290124893188
Validation loss: 2.092030147711436

Epoch: 6| Step: 1
Training loss: 0.7872216701507568
Validation loss: 2.1536967754364014

Epoch: 6| Step: 2
Training loss: 1.5288904905319214
Validation loss: 2.1482679645220437

Epoch: 6| Step: 3
Training loss: 1.2626397609710693
Validation loss: 2.1516206463178

Epoch: 6| Step: 4
Training loss: 1.6107492446899414
Validation loss: 2.1134320298830667

Epoch: 6| Step: 5
Training loss: 1.2611422538757324
Validation loss: 2.1381516059239707

Epoch: 6| Step: 6
Training loss: 1.2256284952163696
Validation loss: 2.1202158530553183

Epoch: 6| Step: 7
Training loss: 0.793989896774292
Validation loss: 2.130593021710714

Epoch: 6| Step: 8
Training loss: 1.8415319919586182
Validation loss: 2.0924280683199563

Epoch: 6| Step: 9
Training loss: 1.794226884841919
Validation loss: 2.111766000588735

Epoch: 6| Step: 10
Training loss: 1.222670555114746
Validation loss: 2.1267396211624146

Epoch: 6| Step: 11
Training loss: 0.946436882019043
Validation loss: 2.1363285779953003

Epoch: 6| Step: 12
Training loss: 0.9539118409156799
Validation loss: 2.099840740362803

Epoch: 6| Step: 13
Training loss: 1.447680950164795
Validation loss: 2.1407382090886435

Epoch: 101| Step: 0
Training loss: 1.4332656860351562
Validation loss: 2.1413668990135193

Epoch: 6| Step: 1
Training loss: 1.055178165435791
Validation loss: 2.141112208366394

Epoch: 6| Step: 2
Training loss: 1.3340861797332764
Validation loss: 2.1583043138186135

Epoch: 6| Step: 3
Training loss: 1.1924571990966797
Validation loss: 2.1359088818232217

Epoch: 6| Step: 4
Training loss: 0.6396982073783875
Validation loss: 2.1022157271703086

Epoch: 6| Step: 5
Training loss: 1.1269274950027466
Validation loss: 2.081557512283325

Epoch: 6| Step: 6
Training loss: 1.4841240644454956
Validation loss: 2.07463808854421

Epoch: 6| Step: 7
Training loss: 1.6620482206344604
Validation loss: 2.0814376870791116

Epoch: 6| Step: 8
Training loss: 1.276049017906189
Validation loss: 2.070513923962911

Epoch: 6| Step: 9
Training loss: 1.2699244022369385
Validation loss: 2.0813024044036865

Epoch: 6| Step: 10
Training loss: 1.8433678150177002
Validation loss: 2.1087053219477334

Epoch: 6| Step: 11
Training loss: 1.4111744165420532
Validation loss: 2.122954467932383

Epoch: 6| Step: 12
Training loss: 1.3758536577224731
Validation loss: 2.11793851852417

Epoch: 6| Step: 13
Training loss: 1.1484519243240356
Validation loss: 2.1099801063537598

Epoch: 102| Step: 0
Training loss: 1.622195839881897
Validation loss: 2.1448448300361633

Epoch: 6| Step: 1
Training loss: 2.2183902263641357
Validation loss: 2.1131439208984375

Epoch: 6| Step: 2
Training loss: 0.6321161389350891
Validation loss: 2.1291812459627786

Epoch: 6| Step: 3
Training loss: 0.6291317939758301
Validation loss: 2.115979174772898

Epoch: 6| Step: 4
Training loss: 0.9751533269882202
Validation loss: 2.080061455567678

Epoch: 6| Step: 5
Training loss: 0.9100934267044067
Validation loss: 2.0752244790395102

Epoch: 6| Step: 6
Training loss: 1.1371077299118042
Validation loss: 2.1324990590413413

Epoch: 6| Step: 7
Training loss: 0.9076575040817261
Validation loss: 2.076570669809977

Epoch: 6| Step: 8
Training loss: 1.6796876192092896
Validation loss: 2.1040268341700235

Epoch: 6| Step: 9
Training loss: 1.3892297744750977
Validation loss: 2.03745706876119

Epoch: 6| Step: 10
Training loss: 1.5352048873901367
Validation loss: 2.0710689624150596

Epoch: 6| Step: 11
Training loss: 1.312981367111206
Validation loss: 2.1050933599472046

Epoch: 6| Step: 12
Training loss: 1.0982654094696045
Validation loss: 2.096675475438436

Epoch: 6| Step: 13
Training loss: 1.6803655624389648
Validation loss: 2.1030942797660828

Epoch: 103| Step: 0
Training loss: 1.2236106395721436
Validation loss: 2.113364656766256

Epoch: 6| Step: 1
Training loss: 0.8534418344497681
Validation loss: 2.1333232522010803

Epoch: 6| Step: 2
Training loss: 1.4169070720672607
Validation loss: 2.1207804679870605

Epoch: 6| Step: 3
Training loss: 2.037710189819336
Validation loss: 2.0998735626538596

Epoch: 6| Step: 4
Training loss: 0.9228429198265076
Validation loss: 2.0834240913391113

Epoch: 6| Step: 5
Training loss: 1.2126197814941406
Validation loss: 2.067230224609375

Epoch: 6| Step: 6
Training loss: 1.342326045036316
Validation loss: 2.0280697345733643

Epoch: 6| Step: 7
Training loss: 1.6378726959228516
Validation loss: 2.0851229429244995

Epoch: 6| Step: 8
Training loss: 1.4385849237442017
Validation loss: 2.042888323465983

Epoch: 6| Step: 9
Training loss: 1.3695192337036133
Validation loss: 2.102346658706665

Epoch: 6| Step: 10
Training loss: 0.6596816182136536
Validation loss: 2.091769814491272

Epoch: 6| Step: 11
Training loss: 0.8124198913574219
Validation loss: 2.0909913778305054

Epoch: 6| Step: 12
Training loss: 1.4932328462600708
Validation loss: 2.1668052275975547

Epoch: 6| Step: 13
Training loss: 1.2176076173782349
Validation loss: 2.158483862876892

Epoch: 104| Step: 0
Training loss: 1.161767601966858
Validation loss: 2.176314055919647

Epoch: 6| Step: 1
Training loss: 1.2001246213912964
Validation loss: 2.1983617742856345

Epoch: 6| Step: 2
Training loss: 1.778484582901001
Validation loss: 2.153719425201416

Epoch: 6| Step: 3
Training loss: 1.2536671161651611
Validation loss: 2.145421028137207

Epoch: 6| Step: 4
Training loss: 1.1754634380340576
Validation loss: 2.1031296054522195

Epoch: 6| Step: 5
Training loss: 1.3561631441116333
Validation loss: 2.085436304410299

Epoch: 6| Step: 6
Training loss: 1.148801326751709
Validation loss: 2.081481417020162

Epoch: 6| Step: 7
Training loss: 0.6862356662750244
Validation loss: 2.0700745383898416

Epoch: 6| Step: 8
Training loss: 1.2642089128494263
Validation loss: 2.100201586882273

Epoch: 6| Step: 9
Training loss: 1.3899122476577759
Validation loss: 2.0422269105911255

Epoch: 6| Step: 10
Training loss: 1.1399880647659302
Validation loss: 2.109877030054728

Epoch: 6| Step: 11
Training loss: 0.7501599788665771
Validation loss: 2.0598272681236267

Epoch: 6| Step: 12
Training loss: 1.357549786567688
Validation loss: 2.075997809569041

Epoch: 6| Step: 13
Training loss: 1.4805928468704224
Validation loss: 2.0968515078226724

Epoch: 105| Step: 0
Training loss: 1.1360669136047363
Validation loss: 2.135691483815511

Epoch: 6| Step: 1
Training loss: 1.4776700735092163
Validation loss: 2.1313854257265725

Epoch: 6| Step: 2
Training loss: 1.2933967113494873
Validation loss: 2.077451845010122

Epoch: 6| Step: 3
Training loss: 1.2333147525787354
Validation loss: 2.127473254998525

Epoch: 6| Step: 4
Training loss: 0.6100116968154907
Validation loss: 2.107257147630056

Epoch: 6| Step: 5
Training loss: 1.48445725440979
Validation loss: 2.1181236108144126

Epoch: 6| Step: 6
Training loss: 2.0533175468444824
Validation loss: 2.1004276275634766

Epoch: 6| Step: 7
Training loss: 1.3410770893096924
Validation loss: 2.1000723242759705

Epoch: 6| Step: 8
Training loss: 0.35606998205184937
Validation loss: 2.116903762022654

Epoch: 6| Step: 9
Training loss: 0.6832690238952637
Validation loss: 2.0419693986574807

Epoch: 6| Step: 10
Training loss: 1.5274561643600464
Validation loss: 2.0549462040265403

Epoch: 6| Step: 11
Training loss: 1.2202486991882324
Validation loss: 2.0700114965438843

Epoch: 6| Step: 12
Training loss: 1.3385753631591797
Validation loss: 2.058796544869741

Epoch: 6| Step: 13
Training loss: 1.4403462409973145
Validation loss: 2.1018627882003784

Epoch: 106| Step: 0
Training loss: 0.49850672483444214
Validation loss: 2.116671005884806

Epoch: 6| Step: 1
Training loss: 1.3549553155899048
Validation loss: 2.1202718019485474

Epoch: 6| Step: 2
Training loss: 1.4286760091781616
Validation loss: 2.1268974343935647

Epoch: 6| Step: 3
Training loss: 1.1878589391708374
Validation loss: 2.105283776919047

Epoch: 6| Step: 4
Training loss: 0.8372747898101807
Validation loss: 2.1434510350227356

Epoch: 6| Step: 5
Training loss: 1.2469837665557861
Validation loss: 2.0867013136545816

Epoch: 6| Step: 6
Training loss: 1.191004753112793
Validation loss: 2.085593024889628

Epoch: 6| Step: 7
Training loss: 0.8999494910240173
Validation loss: 2.06717719634374

Epoch: 6| Step: 8
Training loss: 1.4671779870986938
Validation loss: 2.0413906971613565

Epoch: 6| Step: 9
Training loss: 1.3141456842422485
Validation loss: 2.12776513894399

Epoch: 6| Step: 10
Training loss: 1.3018925189971924
Validation loss: 2.094594637552897

Epoch: 6| Step: 11
Training loss: 1.5036612749099731
Validation loss: 2.1159865061442056

Epoch: 6| Step: 12
Training loss: 1.1124532222747803
Validation loss: 2.1123868823051453

Epoch: 6| Step: 13
Training loss: 1.7115694284439087
Validation loss: 2.133264104525248

Epoch: 107| Step: 0
Training loss: 0.9697595238685608
Validation loss: 2.1375935872395835

Epoch: 6| Step: 1
Training loss: 1.9974360466003418
Validation loss: 2.148605008920034

Epoch: 6| Step: 2
Training loss: 0.5988483428955078
Validation loss: 2.151776353518168

Epoch: 6| Step: 3
Training loss: 1.2840133905410767
Validation loss: 2.1098965406417847

Epoch: 6| Step: 4
Training loss: 1.1509976387023926
Validation loss: 2.1136122941970825

Epoch: 6| Step: 5
Training loss: 1.0578482151031494
Validation loss: 2.0588369568188987

Epoch: 6| Step: 6
Training loss: 1.221555471420288
Validation loss: 2.0830306808153787

Epoch: 6| Step: 7
Training loss: 1.2975938320159912
Validation loss: 2.0813944935798645

Epoch: 6| Step: 8
Training loss: 0.9132871627807617
Validation loss: 2.1082754333813987

Epoch: 6| Step: 9
Training loss: 1.244733452796936
Validation loss: 2.108248988787333

Epoch: 6| Step: 10
Training loss: 0.7766510248184204
Validation loss: 2.0959326227506003

Epoch: 6| Step: 11
Training loss: 1.9512667655944824
Validation loss: 2.1444130539894104

Epoch: 6| Step: 12
Training loss: 1.2377245426177979
Validation loss: 2.1911616722742715

Epoch: 6| Step: 13
Training loss: 1.3457186222076416
Validation loss: 2.1776190400123596

Epoch: 108| Step: 0
Training loss: 0.9099693298339844
Validation loss: 2.1960171461105347

Epoch: 6| Step: 1
Training loss: 0.8963481187820435
Validation loss: 2.143522322177887

Epoch: 6| Step: 2
Training loss: 1.1650474071502686
Validation loss: 2.149550457795461

Epoch: 6| Step: 3
Training loss: 0.687795877456665
Validation loss: 2.138658960660299

Epoch: 6| Step: 4
Training loss: 0.7108706831932068
Validation loss: 2.1259527603785195

Epoch: 6| Step: 5
Training loss: 1.5501810312271118
Validation loss: 2.0947733918825784

Epoch: 6| Step: 6
Training loss: 1.1671279668807983
Validation loss: 2.070913076400757

Epoch: 6| Step: 7
Training loss: 1.2818306684494019
Validation loss: 2.069855550924937

Epoch: 6| Step: 8
Training loss: 2.0317296981811523
Validation loss: 2.0658682783444724

Epoch: 6| Step: 9
Training loss: 0.8454782962799072
Validation loss: 2.0794553558031716

Epoch: 6| Step: 10
Training loss: 1.7156383991241455
Validation loss: 2.1032658418019614

Epoch: 6| Step: 11
Training loss: 1.1418381929397583
Validation loss: 2.0476070046424866

Epoch: 6| Step: 12
Training loss: 0.8743927478790283
Validation loss: 2.0953787366549173

Epoch: 6| Step: 13
Training loss: 1.5136349201202393
Validation loss: 2.1179542541503906

Epoch: 109| Step: 0
Training loss: 0.9703429937362671
Validation loss: 2.1580267349878945

Epoch: 6| Step: 1
Training loss: 1.023302435874939
Validation loss: 2.1461764574050903

Epoch: 6| Step: 2
Training loss: 0.5794637799263
Validation loss: 2.1193886001904807

Epoch: 6| Step: 3
Training loss: 1.6569843292236328
Validation loss: 2.1387522220611572

Epoch: 6| Step: 4
Training loss: 0.8185813426971436
Validation loss: 2.126373569170634

Epoch: 6| Step: 5
Training loss: 1.421147108078003
Validation loss: 2.0677531560262046

Epoch: 6| Step: 6
Training loss: 1.0615925788879395
Validation loss: 2.064164658387502

Epoch: 6| Step: 7
Training loss: 1.0034579038619995
Validation loss: 2.049902359644572

Epoch: 6| Step: 8
Training loss: 1.4237133264541626
Validation loss: 2.055228670438131

Epoch: 6| Step: 9
Training loss: 1.5350524187088013
Validation loss: 2.090353508790334

Epoch: 6| Step: 10
Training loss: 0.9326233267784119
Validation loss: 2.0648600657780967

Epoch: 6| Step: 11
Training loss: 1.0049841403961182
Validation loss: 2.084518849849701

Epoch: 6| Step: 12
Training loss: 1.2196557521820068
Validation loss: 2.0725764433542886

Epoch: 6| Step: 13
Training loss: 1.8475784063339233
Validation loss: 2.0852510730425515

Epoch: 110| Step: 0
Training loss: 1.2778217792510986
Validation loss: 2.0995927453041077

Epoch: 6| Step: 1
Training loss: 0.7625123262405396
Validation loss: 2.14327742656072

Epoch: 6| Step: 2
Training loss: 1.6071345806121826
Validation loss: 2.169904331366221

Epoch: 6| Step: 3
Training loss: 1.0246151685714722
Validation loss: 2.09700608253479

Epoch: 6| Step: 4
Training loss: 0.9073269367218018
Validation loss: 2.1149152318636575

Epoch: 6| Step: 5
Training loss: 1.0857617855072021
Validation loss: 2.1244914333025613

Epoch: 6| Step: 6
Training loss: 1.3411345481872559
Validation loss: 2.026139775911967

Epoch: 6| Step: 7
Training loss: 1.0983877182006836
Validation loss: 2.0938602288564048

Epoch: 6| Step: 8
Training loss: 0.9072672724723816
Validation loss: 2.0358615716298423

Epoch: 6| Step: 9
Training loss: 1.1542596817016602
Validation loss: 2.0468732118606567

Epoch: 6| Step: 10
Training loss: 1.0592849254608154
Validation loss: 2.0637401342391968

Epoch: 6| Step: 11
Training loss: 1.1433420181274414
Validation loss: 2.1043448249499

Epoch: 6| Step: 12
Training loss: 1.653266429901123
Validation loss: 2.098071297009786

Epoch: 6| Step: 13
Training loss: 1.0017458200454712
Validation loss: 2.0658995707829795

Epoch: 111| Step: 0
Training loss: 0.7658208012580872
Validation loss: 2.139709711074829

Epoch: 6| Step: 1
Training loss: 1.0181527137756348
Validation loss: 2.117059051990509

Epoch: 6| Step: 2
Training loss: 0.7981919646263123
Validation loss: 2.10637766122818

Epoch: 6| Step: 3
Training loss: 1.610762596130371
Validation loss: 2.151583274205526

Epoch: 6| Step: 4
Training loss: 1.5300202369689941
Validation loss: 2.1354597210884094

Epoch: 6| Step: 5
Training loss: 0.979345440864563
Validation loss: 2.1136529246966043

Epoch: 6| Step: 6
Training loss: 1.3935341835021973
Validation loss: 2.1181761622428894

Epoch: 6| Step: 7
Training loss: 0.6182512640953064
Validation loss: 2.0647769570350647

Epoch: 6| Step: 8
Training loss: 1.0717889070510864
Validation loss: 2.0811832547187805

Epoch: 6| Step: 9
Training loss: 1.5289627313613892
Validation loss: 2.101971467336019

Epoch: 6| Step: 10
Training loss: 0.7448979616165161
Validation loss: 2.056531329949697

Epoch: 6| Step: 11
Training loss: 0.5535053014755249
Validation loss: 2.0628894567489624

Epoch: 6| Step: 12
Training loss: 1.4658571481704712
Validation loss: 2.1170151034990945

Epoch: 6| Step: 13
Training loss: 1.6453990936279297
Validation loss: 2.0777951876322427

Epoch: 112| Step: 0
Training loss: 1.3994965553283691
Validation loss: 2.0699885487556458

Epoch: 6| Step: 1
Training loss: 1.0637757778167725
Validation loss: 2.0829113920529685

Epoch: 6| Step: 2
Training loss: 0.8722528219223022
Validation loss: 2.1089268724123635

Epoch: 6| Step: 3
Training loss: 1.5777301788330078
Validation loss: 2.0802292029062905

Epoch: 6| Step: 4
Training loss: 0.9458463191986084
Validation loss: 2.115006764729818

Epoch: 6| Step: 5
Training loss: 0.7805027365684509
Validation loss: 2.15861048301061

Epoch: 6| Step: 6
Training loss: 1.2642180919647217
Validation loss: 2.1017999053001404

Epoch: 6| Step: 7
Training loss: 1.2417473793029785
Validation loss: 2.136965274810791

Epoch: 6| Step: 8
Training loss: 1.3299009799957275
Validation loss: 2.1122772097587585

Epoch: 6| Step: 9
Training loss: 0.7668527364730835
Validation loss: 2.1049603621164956

Epoch: 6| Step: 10
Training loss: 1.2189452648162842
Validation loss: 2.0909438729286194

Epoch: 6| Step: 11
Training loss: 0.7078748941421509
Validation loss: 2.074169178803762

Epoch: 6| Step: 12
Training loss: 1.1397373676300049
Validation loss: 2.0829259355862937

Epoch: 6| Step: 13
Training loss: 1.0309178829193115
Validation loss: 2.1015148560206094

Epoch: 113| Step: 0
Training loss: 1.192467212677002
Validation loss: 2.074229677518209

Epoch: 6| Step: 1
Training loss: 0.9716365933418274
Validation loss: 2.0983055432637534

Epoch: 6| Step: 2
Training loss: 1.313075065612793
Validation loss: 2.133301933606466

Epoch: 6| Step: 3
Training loss: 1.3220387697219849
Validation loss: 2.1425044933954873

Epoch: 6| Step: 4
Training loss: 0.9235340356826782
Validation loss: 2.111445665359497

Epoch: 6| Step: 5
Training loss: 1.2482271194458008
Validation loss: 2.077931980292002

Epoch: 6| Step: 6
Training loss: 1.3023390769958496
Validation loss: 2.0796322425206504

Epoch: 6| Step: 7
Training loss: 0.9637601375579834
Validation loss: 2.1009207566579184

Epoch: 6| Step: 8
Training loss: 0.8906035423278809
Validation loss: 2.1033283273379006

Epoch: 6| Step: 9
Training loss: 0.9846169352531433
Validation loss: 2.067671616872152

Epoch: 6| Step: 10
Training loss: 1.3185803890228271
Validation loss: 2.113636871178945

Epoch: 6| Step: 11
Training loss: 1.0804693698883057
Validation loss: 2.087175746758779

Epoch: 6| Step: 12
Training loss: 1.070679783821106
Validation loss: 2.094548225402832

Epoch: 6| Step: 13
Training loss: 0.7279430627822876
Validation loss: 2.08136252562205

Epoch: 114| Step: 0
Training loss: 1.6843016147613525
Validation loss: 2.1297068198521933

Epoch: 6| Step: 1
Training loss: 1.2718474864959717
Validation loss: 2.143779456615448

Epoch: 6| Step: 2
Training loss: 1.1191760301589966
Validation loss: 2.1142603953679404

Epoch: 6| Step: 3
Training loss: 0.8995524644851685
Validation loss: 2.124828894933065

Epoch: 6| Step: 4
Training loss: 1.0494787693023682
Validation loss: 2.1501221656799316

Epoch: 6| Step: 5
Training loss: 0.8520107269287109
Validation loss: 2.1148555278778076

Epoch: 6| Step: 6
Training loss: 1.5267910957336426
Validation loss: 2.1227185130119324

Epoch: 6| Step: 7
Training loss: 1.533199667930603
Validation loss: 2.1420013109842935

Epoch: 6| Step: 8
Training loss: 0.6468563079833984
Validation loss: 2.088274816672007

Epoch: 6| Step: 9
Training loss: 1.1595008373260498
Validation loss: 2.0708163181940713

Epoch: 6| Step: 10
Training loss: 0.8425929546356201
Validation loss: 2.084123651186625

Epoch: 6| Step: 11
Training loss: 0.8416185975074768
Validation loss: 2.0933249990145364

Epoch: 6| Step: 12
Training loss: 1.1436588764190674
Validation loss: 2.0929531852404275

Epoch: 6| Step: 13
Training loss: 0.8762900829315186
Validation loss: 2.1295172770818076

Epoch: 115| Step: 0
Training loss: 0.6896239519119263
Validation loss: 2.0986359318097434

Epoch: 6| Step: 1
Training loss: 1.087127685546875
Validation loss: 2.111349662144979

Epoch: 6| Step: 2
Training loss: 0.9223566055297852
Validation loss: 2.080833355585734

Epoch: 6| Step: 3
Training loss: 0.373980313539505
Validation loss: 2.1128366589546204

Epoch: 6| Step: 4
Training loss: 0.9489994049072266
Validation loss: 2.0836174686749778

Epoch: 6| Step: 5
Training loss: 1.333900809288025
Validation loss: 2.1403757333755493

Epoch: 6| Step: 6
Training loss: 2.3632094860076904
Validation loss: 2.0923619071642556

Epoch: 6| Step: 7
Training loss: 0.7836402654647827
Validation loss: 2.109257777531942

Epoch: 6| Step: 8
Training loss: 0.6826652884483337
Validation loss: 2.0594922304153442

Epoch: 6| Step: 9
Training loss: 1.0518581867218018
Validation loss: 2.067102054754893

Epoch: 6| Step: 10
Training loss: 0.7896928787231445
Validation loss: 2.106939693291982

Epoch: 6| Step: 11
Training loss: 1.3477237224578857
Validation loss: 2.0679021080334983

Epoch: 6| Step: 12
Training loss: 1.3821783065795898
Validation loss: 2.072378238042196

Epoch: 6| Step: 13
Training loss: 1.0824249982833862
Validation loss: 2.087436934312185

Epoch: 116| Step: 0
Training loss: 1.355205774307251
Validation loss: 2.1026604970296225

Epoch: 6| Step: 1
Training loss: 0.9724856615066528
Validation loss: 2.0855753421783447

Epoch: 6| Step: 2
Training loss: 1.630364179611206
Validation loss: 2.096644083658854

Epoch: 6| Step: 3
Training loss: 0.5686608552932739
Validation loss: 2.1346095204353333

Epoch: 6| Step: 4
Training loss: 1.2067253589630127
Validation loss: 2.134726365407308

Epoch: 6| Step: 5
Training loss: 1.1892788410186768
Validation loss: 2.0952693621317544

Epoch: 6| Step: 6
Training loss: 1.0861682891845703
Validation loss: 2.054942528406779

Epoch: 6| Step: 7
Training loss: 0.9767383337020874
Validation loss: 2.0930150747299194

Epoch: 6| Step: 8
Training loss: 1.4202640056610107
Validation loss: 2.070687711238861

Epoch: 6| Step: 9
Training loss: 0.6965823173522949
Validation loss: 2.073088049888611

Epoch: 6| Step: 10
Training loss: 0.8268687725067139
Validation loss: 2.0851014455159507

Epoch: 6| Step: 11
Training loss: 1.0543005466461182
Validation loss: 2.0850080251693726

Epoch: 6| Step: 12
Training loss: 1.2934379577636719
Validation loss: 2.07551771402359

Epoch: 6| Step: 13
Training loss: 0.8307808637619019
Validation loss: 2.084571282068888

Epoch: 117| Step: 0
Training loss: 0.6683261394500732
Validation loss: 2.11468376715978

Epoch: 6| Step: 1
Training loss: 1.2461228370666504
Validation loss: 2.101706385612488

Epoch: 6| Step: 2
Training loss: 1.0738909244537354
Validation loss: 2.147211710611979

Epoch: 6| Step: 3
Training loss: 1.3416918516159058
Validation loss: 2.07638148466746

Epoch: 6| Step: 4
Training loss: 1.2113592624664307
Validation loss: 2.0773306687672934

Epoch: 6| Step: 5
Training loss: 1.6725330352783203
Validation loss: 2.0773538947105408

Epoch: 6| Step: 6
Training loss: 1.0236257314682007
Validation loss: 2.0368361870447793

Epoch: 6| Step: 7
Training loss: 1.1636228561401367
Validation loss: 2.0742015639940896

Epoch: 6| Step: 8
Training loss: 1.0778486728668213
Validation loss: 2.0297380089759827

Epoch: 6| Step: 9
Training loss: 0.9563378095626831
Validation loss: 2.0697134733200073

Epoch: 6| Step: 10
Training loss: 1.1570136547088623
Validation loss: 2.04816081126531

Epoch: 6| Step: 11
Training loss: 1.06097412109375
Validation loss: 2.093108654022217

Epoch: 6| Step: 12
Training loss: 1.1274216175079346
Validation loss: 2.1058983405431113

Epoch: 6| Step: 13
Training loss: 0.8630931377410889
Validation loss: 2.160126586755117

Epoch: 118| Step: 0
Training loss: 0.7213938236236572
Validation loss: 2.1641202767690024

Epoch: 6| Step: 1
Training loss: 1.1327097415924072
Validation loss: 2.153713901837667

Epoch: 6| Step: 2
Training loss: 1.052406907081604
Validation loss: 2.1265393694241843

Epoch: 6| Step: 3
Training loss: 1.0609333515167236
Validation loss: 2.084576745827993

Epoch: 6| Step: 4
Training loss: 0.7906261682510376
Validation loss: 2.1084351539611816

Epoch: 6| Step: 5
Training loss: 1.454650640487671
Validation loss: 2.082331379254659

Epoch: 6| Step: 6
Training loss: 1.2590826749801636
Validation loss: 2.0365684032440186

Epoch: 6| Step: 7
Training loss: 1.1259777545928955
Validation loss: 2.07284152507782

Epoch: 6| Step: 8
Training loss: 0.8625919818878174
Validation loss: 2.073076287905375

Epoch: 6| Step: 9
Training loss: 0.895291268825531
Validation loss: 2.106474002202352

Epoch: 6| Step: 10
Training loss: 1.1959559917449951
Validation loss: 2.086070418357849

Epoch: 6| Step: 11
Training loss: 0.8649052381515503
Validation loss: 2.1656453212102256

Epoch: 6| Step: 12
Training loss: 1.4977202415466309
Validation loss: 2.12515652179718

Epoch: 6| Step: 13
Training loss: 0.9289462566375732
Validation loss: 2.1323996980985007

Epoch: 119| Step: 0
Training loss: 0.9481256008148193
Validation loss: 2.100850741068522

Epoch: 6| Step: 1
Training loss: 1.1880894899368286
Validation loss: 2.0702794194221497

Epoch: 6| Step: 2
Training loss: 0.9055258631706238
Validation loss: 2.110556662082672

Epoch: 6| Step: 3
Training loss: 0.5827272534370422
Validation loss: 2.063839832941691

Epoch: 6| Step: 4
Training loss: 0.8861699104309082
Validation loss: 2.09176238377889

Epoch: 6| Step: 5
Training loss: 0.8278235197067261
Validation loss: 2.072934071222941

Epoch: 6| Step: 6
Training loss: 1.3214129209518433
Validation loss: 2.1059542894363403

Epoch: 6| Step: 7
Training loss: 0.7094672918319702
Validation loss: 2.097996989885966

Epoch: 6| Step: 8
Training loss: 1.108873963356018
Validation loss: 2.115686376889547

Epoch: 6| Step: 9
Training loss: 1.1931612491607666
Validation loss: 2.128393232822418

Epoch: 6| Step: 10
Training loss: 1.330247402191162
Validation loss: 2.147107640902201

Epoch: 6| Step: 11
Training loss: 0.8502897620201111
Validation loss: 2.1212813456853232

Epoch: 6| Step: 12
Training loss: 1.0134395360946655
Validation loss: 2.1091994245847068

Epoch: 6| Step: 13
Training loss: 1.29659104347229
Validation loss: 2.1148579319318137

Epoch: 120| Step: 0
Training loss: 0.4827817678451538
Validation loss: 2.0798476139704385

Epoch: 6| Step: 1
Training loss: 0.6413072347640991
Validation loss: 2.1139138539632163

Epoch: 6| Step: 2
Training loss: 0.9111864566802979
Validation loss: 2.1139219204584756

Epoch: 6| Step: 3
Training loss: 1.1574575901031494
Validation loss: 2.148161788781484

Epoch: 6| Step: 4
Training loss: 1.0761487483978271
Validation loss: 2.1259716351826987

Epoch: 6| Step: 5
Training loss: 1.621759295463562
Validation loss: 2.165490428606669

Epoch: 6| Step: 6
Training loss: 1.6814329624176025
Validation loss: 2.185027301311493

Epoch: 6| Step: 7
Training loss: 0.8838605284690857
Validation loss: 2.115524649620056

Epoch: 6| Step: 8
Training loss: 1.4112861156463623
Validation loss: 2.095540245374044

Epoch: 6| Step: 9
Training loss: 0.5814141035079956
Validation loss: 2.066404620806376

Epoch: 6| Step: 10
Training loss: 1.0721508264541626
Validation loss: 2.08223428328832

Epoch: 6| Step: 11
Training loss: 1.3597296476364136
Validation loss: 2.0868133306503296

Epoch: 6| Step: 12
Training loss: 0.9554639458656311
Validation loss: 2.1254939635594687

Epoch: 6| Step: 13
Training loss: 0.7215718030929565
Validation loss: 2.1359711488087973

Epoch: 121| Step: 0
Training loss: 1.2342183589935303
Validation loss: 2.1414137283960977

Epoch: 6| Step: 1
Training loss: 1.6597986221313477
Validation loss: 2.1418824394543967

Epoch: 6| Step: 2
Training loss: 1.3221819400787354
Validation loss: 2.155335783958435

Epoch: 6| Step: 3
Training loss: 1.6663072109222412
Validation loss: 2.1214749415715537

Epoch: 6| Step: 4
Training loss: 0.3944428563117981
Validation loss: 2.086473822593689

Epoch: 6| Step: 5
Training loss: 1.0431798696517944
Validation loss: 2.0879148046175637

Epoch: 6| Step: 6
Training loss: 1.0447728633880615
Validation loss: 2.057021141052246

Epoch: 6| Step: 7
Training loss: 1.0084675550460815
Validation loss: 2.0879730582237244

Epoch: 6| Step: 8
Training loss: 1.1522408723831177
Validation loss: 2.068239390850067

Epoch: 6| Step: 9
Training loss: 0.7910454273223877
Validation loss: 2.078328808148702

Epoch: 6| Step: 10
Training loss: 0.40086835622787476
Validation loss: 2.0980483293533325

Epoch: 6| Step: 11
Training loss: 0.9464341402053833
Validation loss: 2.1315322518348694

Epoch: 6| Step: 12
Training loss: 1.3757295608520508
Validation loss: 2.1207504868507385

Epoch: 6| Step: 13
Training loss: 1.2455697059631348
Validation loss: 2.157550851504008

Epoch: 122| Step: 0
Training loss: 1.4660972356796265
Validation loss: 2.166613777478536

Epoch: 6| Step: 1
Training loss: 1.023368239402771
Validation loss: 2.195223053296407

Epoch: 6| Step: 2
Training loss: 1.035346508026123
Validation loss: 2.180666704972585

Epoch: 6| Step: 3
Training loss: 1.7472355365753174
Validation loss: 2.1377989451090493

Epoch: 6| Step: 4
Training loss: 1.1028473377227783
Validation loss: 2.0736788511276245

Epoch: 6| Step: 5
Training loss: 1.1686766147613525
Validation loss: 2.0921682715415955

Epoch: 6| Step: 6
Training loss: 0.7212941646575928
Validation loss: 2.04248309135437

Epoch: 6| Step: 7
Training loss: 0.8449158668518066
Validation loss: 2.019367198149363

Epoch: 6| Step: 8
Training loss: 0.6435885429382324
Validation loss: 2.08961151043574

Epoch: 6| Step: 9
Training loss: 0.6533033847808838
Validation loss: 2.12234228849411

Epoch: 6| Step: 10
Training loss: 0.6235858201980591
Validation loss: 2.083221356074015

Epoch: 6| Step: 11
Training loss: 0.6827035546302795
Validation loss: 2.0609042048454285

Epoch: 6| Step: 12
Training loss: 1.3272401094436646
Validation loss: 2.1179268757502236

Epoch: 6| Step: 13
Training loss: 1.257554054260254
Validation loss: 2.1298212806383767

Epoch: 123| Step: 0
Training loss: 1.1533401012420654
Validation loss: 2.121189753214518

Epoch: 6| Step: 1
Training loss: 1.2208497524261475
Validation loss: 2.1141544779141745

Epoch: 6| Step: 2
Training loss: 0.654376745223999
Validation loss: 2.10354353984197

Epoch: 6| Step: 3
Training loss: 0.6952276229858398
Validation loss: 2.0803220669428506

Epoch: 6| Step: 4
Training loss: 0.7597672939300537
Validation loss: 2.095864693323771

Epoch: 6| Step: 5
Training loss: 0.6538125872612
Validation loss: 2.1136957009633384

Epoch: 6| Step: 6
Training loss: 1.010393500328064
Validation loss: 2.096589148044586

Epoch: 6| Step: 7
Training loss: 0.9680839776992798
Validation loss: 2.117219646771749

Epoch: 6| Step: 8
Training loss: 1.3746776580810547
Validation loss: 2.079686999320984

Epoch: 6| Step: 9
Training loss: 1.8119813203811646
Validation loss: 2.0620535214742026

Epoch: 6| Step: 10
Training loss: 1.130557894706726
Validation loss: 2.0967878103256226

Epoch: 6| Step: 11
Training loss: 0.4338235855102539
Validation loss: 2.0895947217941284

Epoch: 6| Step: 12
Training loss: 0.7795895338058472
Validation loss: 2.041786770025889

Epoch: 6| Step: 13
Training loss: 0.7856459021568298
Validation loss: 2.075224538644155

Epoch: 124| Step: 0
Training loss: 0.9354922771453857
Validation loss: 2.078912099202474

Epoch: 6| Step: 1
Training loss: 0.4388032555580139
Validation loss: 2.066208998362223

Epoch: 6| Step: 2
Training loss: 1.0091580152511597
Validation loss: 2.0703737338383994

Epoch: 6| Step: 3
Training loss: 0.8163730502128601
Validation loss: 2.0494643449783325

Epoch: 6| Step: 4
Training loss: 0.7100216746330261
Validation loss: 2.037613868713379

Epoch: 6| Step: 5
Training loss: 1.2646842002868652
Validation loss: 2.0161516070365906

Epoch: 6| Step: 6
Training loss: 0.8220983147621155
Validation loss: 2.0792778730392456

Epoch: 6| Step: 7
Training loss: 0.9416649341583252
Validation loss: 2.0651485522588096

Epoch: 6| Step: 8
Training loss: 1.1801038980484009
Validation loss: 2.046410838762919

Epoch: 6| Step: 9
Training loss: 1.530456781387329
Validation loss: 2.121968905131022

Epoch: 6| Step: 10
Training loss: 0.8189587593078613
Validation loss: 2.071114102999369

Epoch: 6| Step: 11
Training loss: 1.34040105342865
Validation loss: 2.0788334012031555

Epoch: 6| Step: 12
Training loss: 0.894514799118042
Validation loss: 2.076578994592031

Epoch: 6| Step: 13
Training loss: 0.9570389986038208
Validation loss: 2.084707736968994

Epoch: 125| Step: 0
Training loss: 1.0035436153411865
Validation loss: 2.070451855659485

Epoch: 6| Step: 1
Training loss: 0.868370532989502
Validation loss: 2.086810131867727

Epoch: 6| Step: 2
Training loss: 1.119259238243103
Validation loss: 2.0195454359054565

Epoch: 6| Step: 3
Training loss: 0.4620053470134735
Validation loss: 2.0279423197110495

Epoch: 6| Step: 4
Training loss: 0.9601606130599976
Validation loss: 2.056758979956309

Epoch: 6| Step: 5
Training loss: 0.8550096750259399
Validation loss: 2.039682904879252

Epoch: 6| Step: 6
Training loss: 1.0127084255218506
Validation loss: 2.0714367628097534

Epoch: 6| Step: 7
Training loss: 0.850165069103241
Validation loss: 2.0546218156814575

Epoch: 6| Step: 8
Training loss: 0.706911563873291
Validation loss: 2.079332192738851

Epoch: 6| Step: 9
Training loss: 1.0835647583007812
Validation loss: 2.045876463254293

Epoch: 6| Step: 10
Training loss: 0.8037590384483337
Validation loss: 2.0669182737668357

Epoch: 6| Step: 11
Training loss: 0.872584879398346
Validation loss: 2.0540632009506226

Epoch: 6| Step: 12
Training loss: 1.4211547374725342
Validation loss: 2.106337626775106

Epoch: 6| Step: 13
Training loss: 1.5099873542785645
Validation loss: 2.123436530431112

Epoch: 126| Step: 0
Training loss: 0.41023457050323486
Validation loss: 2.117665449778239

Epoch: 6| Step: 1
Training loss: 1.0305964946746826
Validation loss: 2.1066433986028037

Epoch: 6| Step: 2
Training loss: 1.1234142780303955
Validation loss: 2.1441046794255576

Epoch: 6| Step: 3
Training loss: 0.886346697807312
Validation loss: 2.10452793041865

Epoch: 6| Step: 4
Training loss: 1.019740343093872
Validation loss: 2.087196429570516

Epoch: 6| Step: 5
Training loss: 1.1260327100753784
Validation loss: 2.0688186089197793

Epoch: 6| Step: 6
Training loss: 0.7080307006835938
Validation loss: 2.0619686444600425

Epoch: 6| Step: 7
Training loss: 1.0258437395095825
Validation loss: 2.081697662671407

Epoch: 6| Step: 8
Training loss: 1.3242321014404297
Validation loss: 2.0534528692563376

Epoch: 6| Step: 9
Training loss: 0.8777016997337341
Validation loss: 2.1044411261876426

Epoch: 6| Step: 10
Training loss: 1.1771727800369263
Validation loss: 2.108122964700063

Epoch: 6| Step: 11
Training loss: 1.5073869228363037
Validation loss: 2.1372734109560647

Epoch: 6| Step: 12
Training loss: 0.7406580448150635
Validation loss: 2.108935753504435

Epoch: 6| Step: 13
Training loss: 0.7150465250015259
Validation loss: 2.145431399345398

Epoch: 127| Step: 0
Training loss: 1.1762351989746094
Validation loss: 2.1287006735801697

Epoch: 6| Step: 1
Training loss: 0.8254307508468628
Validation loss: 2.106893996397654

Epoch: 6| Step: 2
Training loss: 0.4149327874183655
Validation loss: 2.0951422850290933

Epoch: 6| Step: 3
Training loss: 1.1490753889083862
Validation loss: 2.0771771470705667

Epoch: 6| Step: 4
Training loss: 0.8493132591247559
Validation loss: 2.094654619693756

Epoch: 6| Step: 5
Training loss: 0.8401045799255371
Validation loss: 2.0314842661221824

Epoch: 6| Step: 6
Training loss: 1.1293147802352905
Validation loss: 2.029090940952301

Epoch: 6| Step: 7
Training loss: 1.1709351539611816
Validation loss: 2.067571540673574

Epoch: 6| Step: 8
Training loss: 1.2017436027526855
Validation loss: 2.0747637351353965

Epoch: 6| Step: 9
Training loss: 0.8109047412872314
Validation loss: 2.082964917023977

Epoch: 6| Step: 10
Training loss: 1.415367603302002
Validation loss: 2.0743883649508157

Epoch: 6| Step: 11
Training loss: 0.7516015768051147
Validation loss: 2.06489368279775

Epoch: 6| Step: 12
Training loss: 0.517352819442749
Validation loss: 2.062049229939779

Epoch: 6| Step: 13
Training loss: 0.9316419959068298
Validation loss: 2.1036201119422913

Epoch: 128| Step: 0
Training loss: 0.7519333958625793
Validation loss: 2.1605507930119834

Epoch: 6| Step: 1
Training loss: 0.7665114402770996
Validation loss: 2.0148035685221353

Epoch: 6| Step: 2
Training loss: 1.1890459060668945
Validation loss: 2.069396515687307

Epoch: 6| Step: 3
Training loss: 0.9979708790779114
Validation loss: 2.0735651652018228

Epoch: 6| Step: 4
Training loss: 1.503260612487793
Validation loss: 2.0871634682019553

Epoch: 6| Step: 5
Training loss: 0.8591548800468445
Validation loss: 2.1001899242401123

Epoch: 6| Step: 6
Training loss: 0.6670025587081909
Validation loss: 2.1119970083236694

Epoch: 6| Step: 7
Training loss: 0.8933932781219482
Validation loss: 2.097680409749349

Epoch: 6| Step: 8
Training loss: 1.0515707731246948
Validation loss: 2.108557124932607

Epoch: 6| Step: 9
Training loss: 0.3465862274169922
Validation loss: 2.0868855118751526

Epoch: 6| Step: 10
Training loss: 1.2313021421432495
Validation loss: 2.0911006530125937

Epoch: 6| Step: 11
Training loss: 1.5535237789154053
Validation loss: 2.1303425828615823

Epoch: 6| Step: 12
Training loss: 0.8110687732696533
Validation loss: 2.1146663427352905

Epoch: 6| Step: 13
Training loss: 0.49597758054733276
Validation loss: 2.07625412940979

Epoch: 129| Step: 0
Training loss: 1.8605579137802124
Validation loss: 2.013851205507914

Epoch: 6| Step: 1
Training loss: 0.7159620523452759
Validation loss: 2.0597652991612754

Epoch: 6| Step: 2
Training loss: 0.7956249713897705
Validation loss: 2.0609193046887717

Epoch: 6| Step: 3
Training loss: 0.995930016040802
Validation loss: 2.0849948128064475

Epoch: 6| Step: 4
Training loss: 1.1754355430603027
Validation loss: 2.0991658369700112

Epoch: 6| Step: 5
Training loss: 0.8892713785171509
Validation loss: 2.1044098138809204

Epoch: 6| Step: 6
Training loss: 0.9242467880249023
Validation loss: 2.127986788749695

Epoch: 6| Step: 7
Training loss: 0.6388494968414307
Validation loss: 2.1877822081247964

Epoch: 6| Step: 8
Training loss: 0.9774371981620789
Validation loss: 2.0795156558354697

Epoch: 6| Step: 9
Training loss: 0.7961289882659912
Validation loss: 2.144489308198293

Epoch: 6| Step: 10
Training loss: 0.5365793108940125
Validation loss: 2.1502026518185935

Epoch: 6| Step: 11
Training loss: 0.5666332244873047
Validation loss: 2.0592170556386313

Epoch: 6| Step: 12
Training loss: 1.5501956939697266
Validation loss: 2.095635195573171

Epoch: 6| Step: 13
Training loss: 0.9798644781112671
Validation loss: 2.0743894378344216

Epoch: 130| Step: 0
Training loss: 0.49386537075042725
Validation loss: 2.0737777948379517

Epoch: 6| Step: 1
Training loss: 1.45876145362854
Validation loss: 2.069388826688131

Epoch: 6| Step: 2
Training loss: 1.1939332485198975
Validation loss: 2.068524797757467

Epoch: 6| Step: 3
Training loss: 0.4726465344429016
Validation loss: 2.1094236373901367

Epoch: 6| Step: 4
Training loss: 0.9968897700309753
Validation loss: 2.071660300095876

Epoch: 6| Step: 5
Training loss: 0.9829418659210205
Validation loss: 2.0697505871454873

Epoch: 6| Step: 6
Training loss: 1.0397049188613892
Validation loss: 2.093024253845215

Epoch: 6| Step: 7
Training loss: 1.4543402194976807
Validation loss: 2.076193372408549

Epoch: 6| Step: 8
Training loss: 0.982746958732605
Validation loss: 2.0280449787775674

Epoch: 6| Step: 9
Training loss: 0.6528322100639343
Validation loss: 2.0638299187024436

Epoch: 6| Step: 10
Training loss: 0.7902399301528931
Validation loss: 2.058086315790812

Epoch: 6| Step: 11
Training loss: 0.6608331799507141
Validation loss: 2.090922474861145

Epoch: 6| Step: 12
Training loss: 0.9303045272827148
Validation loss: 2.1003040870030723

Epoch: 6| Step: 13
Training loss: 0.4919258952140808
Validation loss: 2.1359923680623374

Epoch: 131| Step: 0
Training loss: 0.7086927890777588
Validation loss: 2.054452200730642

Epoch: 6| Step: 1
Training loss: 0.941731333732605
Validation loss: 2.0381247202555337

Epoch: 6| Step: 2
Training loss: 1.2963546514511108
Validation loss: 2.0720930099487305

Epoch: 6| Step: 3
Training loss: 0.8739066123962402
Validation loss: 2.0867896676063538

Epoch: 6| Step: 4
Training loss: 1.0833637714385986
Validation loss: 2.0566644867261252

Epoch: 6| Step: 5
Training loss: 0.4449521601200104
Validation loss: 2.0706729888916016

Epoch: 6| Step: 6
Training loss: 0.9082266688346863
Validation loss: 2.0715068777402244

Epoch: 6| Step: 7
Training loss: 0.5480132102966309
Validation loss: 2.0870282451311746

Epoch: 6| Step: 8
Training loss: 1.033552646636963
Validation loss: 2.0965354442596436

Epoch: 6| Step: 9
Training loss: 0.9478980302810669
Validation loss: 2.1566368341445923

Epoch: 6| Step: 10
Training loss: 0.8373324871063232
Validation loss: 2.092010716597239

Epoch: 6| Step: 11
Training loss: 1.0912740230560303
Validation loss: 2.1530180970827737

Epoch: 6| Step: 12
Training loss: 1.3904688358306885
Validation loss: 2.133449912071228

Epoch: 6| Step: 13
Training loss: 1.363201379776001
Validation loss: 2.1322563687960305

Epoch: 132| Step: 0
Training loss: 0.7884366512298584
Validation loss: 2.0745848615964255

Epoch: 6| Step: 1
Training loss: 1.1935844421386719
Validation loss: 2.0967191259066262

Epoch: 6| Step: 2
Training loss: 0.8276664614677429
Validation loss: 2.058635731538137

Epoch: 6| Step: 3
Training loss: 1.1639063358306885
Validation loss: 2.023721754550934

Epoch: 6| Step: 4
Training loss: 1.1149061918258667
Validation loss: 2.0329267581303916

Epoch: 6| Step: 5
Training loss: 0.7957326769828796
Validation loss: 2.049993932247162

Epoch: 6| Step: 6
Training loss: 0.7740252017974854
Validation loss: 2.0195698936780295

Epoch: 6| Step: 7
Training loss: 0.8903660774230957
Validation loss: 2.060872972011566

Epoch: 6| Step: 8
Training loss: 0.6214879155158997
Validation loss: 2.1037448048591614

Epoch: 6| Step: 9
Training loss: 0.8754767179489136
Validation loss: 2.127301573753357

Epoch: 6| Step: 10
Training loss: 0.9137066602706909
Validation loss: 2.077264130115509

Epoch: 6| Step: 11
Training loss: 0.6539284586906433
Validation loss: 2.0776173869768777

Epoch: 6| Step: 12
Training loss: 0.6185268759727478
Validation loss: 2.0373298128445945

Epoch: 6| Step: 13
Training loss: 0.9988646507263184
Validation loss: 2.0906749963760376

Epoch: 133| Step: 0
Training loss: 0.6749423742294312
Validation loss: 2.0504613320032754

Epoch: 6| Step: 1
Training loss: 1.2150107622146606
Validation loss: 2.075054327646891

Epoch: 6| Step: 2
Training loss: 0.762021005153656
Validation loss: 2.1223302682240806

Epoch: 6| Step: 3
Training loss: 0.9177684783935547
Validation loss: 2.085894604523977

Epoch: 6| Step: 4
Training loss: 0.6912737488746643
Validation loss: 2.1189971764882407

Epoch: 6| Step: 5
Training loss: 0.9373846054077148
Validation loss: 2.0283268292744956

Epoch: 6| Step: 6
Training loss: 0.6746529936790466
Validation loss: 2.0707446734110513

Epoch: 6| Step: 7
Training loss: 1.3896270990371704
Validation loss: 2.021250903606415

Epoch: 6| Step: 8
Training loss: 1.0294253826141357
Validation loss: 2.0058799584706626

Epoch: 6| Step: 9
Training loss: 1.0051625967025757
Validation loss: 2.0606693228085837

Epoch: 6| Step: 10
Training loss: 0.9521290063858032
Validation loss: 2.0668066342671714

Epoch: 6| Step: 11
Training loss: 0.8044949173927307
Validation loss: 2.091591397921244

Epoch: 6| Step: 12
Training loss: 1.0033941268920898
Validation loss: 2.0693644086519876

Epoch: 6| Step: 13
Training loss: 0.5800902843475342
Validation loss: 2.1002654433250427

Epoch: 134| Step: 0
Training loss: 0.40657082200050354
Validation loss: 2.1019153793652854

Epoch: 6| Step: 1
Training loss: 0.5663086771965027
Validation loss: 2.0725281635920205

Epoch: 6| Step: 2
Training loss: 1.7219557762145996
Validation loss: 2.1288886864980063

Epoch: 6| Step: 3
Training loss: 1.298999309539795
Validation loss: 2.111305594444275

Epoch: 6| Step: 4
Training loss: 0.8889368176460266
Validation loss: 2.0772165656089783

Epoch: 6| Step: 5
Training loss: 0.7550575733184814
Validation loss: 2.054107666015625

Epoch: 6| Step: 6
Training loss: 0.3895397186279297
Validation loss: 2.051683863004049

Epoch: 6| Step: 7
Training loss: 1.2276089191436768
Validation loss: 2.056161363919576

Epoch: 6| Step: 8
Training loss: 1.3095319271087646
Validation loss: 2.0653404792149863

Epoch: 6| Step: 9
Training loss: 0.712591290473938
Validation loss: 2.0691759983698526

Epoch: 6| Step: 10
Training loss: 0.4801490306854248
Validation loss: 2.047252277533213

Epoch: 6| Step: 11
Training loss: 0.9531995058059692
Validation loss: 2.0846250653266907

Epoch: 6| Step: 12
Training loss: 1.1920993328094482
Validation loss: 2.054403781890869

Epoch: 6| Step: 13
Training loss: 0.6085118651390076
Validation loss: 2.073910435040792

Epoch: 135| Step: 0
Training loss: 0.9050710797309875
Validation loss: 2.081755439440409

Epoch: 6| Step: 1
Training loss: 1.1955506801605225
Validation loss: 2.0852535367012024

Epoch: 6| Step: 2
Training loss: 0.4847877025604248
Validation loss: 2.0870460669199624

Epoch: 6| Step: 3
Training loss: 0.7294410467147827
Validation loss: 2.0528820355733237

Epoch: 6| Step: 4
Training loss: 0.6426440477371216
Validation loss: 2.0732884804407754

Epoch: 6| Step: 5
Training loss: 1.0687898397445679
Validation loss: 2.1123449206352234

Epoch: 6| Step: 6
Training loss: 0.7437350749969482
Validation loss: 2.047151585419973

Epoch: 6| Step: 7
Training loss: 1.3674731254577637
Validation loss: 2.052144169807434

Epoch: 6| Step: 8
Training loss: 1.123487949371338
Validation loss: 2.068618913491567

Epoch: 6| Step: 9
Training loss: 0.687942385673523
Validation loss: 2.1203764279683432

Epoch: 6| Step: 10
Training loss: 0.6868323683738708
Validation loss: 2.1432961424191794

Epoch: 6| Step: 11
Training loss: 1.141182541847229
Validation loss: 2.08137708902359

Epoch: 6| Step: 12
Training loss: 0.7472183704376221
Validation loss: 2.0692689418792725

Epoch: 6| Step: 13
Training loss: 0.8784927129745483
Validation loss: 2.126574476559957

Epoch: 136| Step: 0
Training loss: 1.0511441230773926
Validation loss: 2.059458096822103

Epoch: 6| Step: 1
Training loss: 0.4395890533924103
Validation loss: 2.073421756426493

Epoch: 6| Step: 2
Training loss: 0.5366795659065247
Validation loss: 2.079761246840159

Epoch: 6| Step: 3
Training loss: 0.6961789131164551
Validation loss: 2.048568367958069

Epoch: 6| Step: 4
Training loss: 0.6467118263244629
Validation loss: 2.10810915629069

Epoch: 6| Step: 5
Training loss: 0.5872492790222168
Validation loss: 2.0365801652272544

Epoch: 6| Step: 6
Training loss: 1.356088638305664
Validation loss: 2.0780095060666404

Epoch: 6| Step: 7
Training loss: 1.0533175468444824
Validation loss: 2.034743587176005

Epoch: 6| Step: 8
Training loss: 1.0061213970184326
Validation loss: 2.0951855580012

Epoch: 6| Step: 9
Training loss: 1.2705070972442627
Validation loss: 2.0763551195462546

Epoch: 6| Step: 10
Training loss: 0.9034096598625183
Validation loss: 2.0599319338798523

Epoch: 6| Step: 11
Training loss: 0.8069373965263367
Validation loss: 2.065981845060984

Epoch: 6| Step: 12
Training loss: 1.2455263137817383
Validation loss: 2.117349704106649

Epoch: 6| Step: 13
Training loss: 0.5775901079177856
Validation loss: 2.1197393933931985

Epoch: 137| Step: 0
Training loss: 0.8003414869308472
Validation loss: 2.0810439189275107

Epoch: 6| Step: 1
Training loss: 0.5143908262252808
Validation loss: 2.089610517024994

Epoch: 6| Step: 2
Training loss: 0.5686696767807007
Validation loss: 2.1168027917544046

Epoch: 6| Step: 3
Training loss: 0.71979820728302
Validation loss: 2.0490078926086426

Epoch: 6| Step: 4
Training loss: 0.8807834982872009
Validation loss: 2.0781261920928955

Epoch: 6| Step: 5
Training loss: 0.9337357878684998
Validation loss: 2.062700887521108

Epoch: 6| Step: 6
Training loss: 0.3726174831390381
Validation loss: 2.052041788895925

Epoch: 6| Step: 7
Training loss: 0.8253757357597351
Validation loss: 2.0699883500734964

Epoch: 6| Step: 8
Training loss: 0.37347376346588135
Validation loss: 2.0607335964838662

Epoch: 6| Step: 9
Training loss: 0.8001337051391602
Validation loss: 2.0525954961776733

Epoch: 6| Step: 10
Training loss: 1.5958120822906494
Validation loss: 2.082910418510437

Epoch: 6| Step: 11
Training loss: 1.5935602188110352
Validation loss: 2.048098623752594

Epoch: 6| Step: 12
Training loss: 0.7669737339019775
Validation loss: 2.0877143939336142

Epoch: 6| Step: 13
Training loss: 1.0975761413574219
Validation loss: 2.064683258533478

Epoch: 138| Step: 0
Training loss: 0.5988044142723083
Validation loss: 2.041750172773997

Epoch: 6| Step: 1
Training loss: 1.094310998916626
Validation loss: 2.0715097387631736

Epoch: 6| Step: 2
Training loss: 1.0169212818145752
Validation loss: 2.0508618156115213

Epoch: 6| Step: 3
Training loss: 0.6813937425613403
Validation loss: 2.0401770869890847

Epoch: 6| Step: 4
Training loss: 0.6863523721694946
Validation loss: 2.0502270460128784

Epoch: 6| Step: 5
Training loss: 0.7500324249267578
Validation loss: 2.067442317803701

Epoch: 6| Step: 6
Training loss: 0.5116553902626038
Validation loss: 2.0836291511853537

Epoch: 6| Step: 7
Training loss: 1.0256068706512451
Validation loss: 2.0697986483573914

Epoch: 6| Step: 8
Training loss: 1.0277163982391357
Validation loss: 2.0856303771336875

Epoch: 6| Step: 9
Training loss: 1.7387850284576416
Validation loss: 2.0673943161964417

Epoch: 6| Step: 10
Training loss: 0.5716031789779663
Validation loss: 2.0594046314557395

Epoch: 6| Step: 11
Training loss: 0.6150708198547363
Validation loss: 2.058785061041514

Epoch: 6| Step: 12
Training loss: 0.6138864755630493
Validation loss: 1.9911762873331706

Epoch: 6| Step: 13
Training loss: 0.8460494875907898
Validation loss: 2.0743658542633057

Epoch: 139| Step: 0
Training loss: 0.47739046812057495
Validation loss: 2.01953125

Epoch: 6| Step: 1
Training loss: 0.8448671698570251
Validation loss: 2.0642146865526834

Epoch: 6| Step: 2
Training loss: 0.7018380761146545
Validation loss: 2.0596932967503867

Epoch: 6| Step: 3
Training loss: 0.6694002151489258
Validation loss: 2.05210288365682

Epoch: 6| Step: 4
Training loss: 0.83855140209198
Validation loss: 2.056934634844462

Epoch: 6| Step: 5
Training loss: 1.1073930263519287
Validation loss: 2.084906538327535

Epoch: 6| Step: 6
Training loss: 0.8891208171844482
Validation loss: 2.057192583878835

Epoch: 6| Step: 7
Training loss: 0.8905085325241089
Validation loss: 2.0544922749201455

Epoch: 6| Step: 8
Training loss: 0.9449344277381897
Validation loss: 2.0527217785517373

Epoch: 6| Step: 9
Training loss: 0.722324550151825
Validation loss: 2.076149880886078

Epoch: 6| Step: 10
Training loss: 0.5843682289123535
Validation loss: 1.9977767666180928

Epoch: 6| Step: 11
Training loss: 1.4569532871246338
Validation loss: 2.0716588695844016

Epoch: 6| Step: 12
Training loss: 0.7315220832824707
Validation loss: 2.1251426935195923

Epoch: 6| Step: 13
Training loss: 0.8767483830451965
Validation loss: 2.089855909347534

Epoch: 140| Step: 0
Training loss: 1.036679983139038
Validation loss: 2.045383711655935

Epoch: 6| Step: 1
Training loss: 0.9509789943695068
Validation loss: 2.116150359312693

Epoch: 6| Step: 2
Training loss: 0.8282376527786255
Validation loss: 2.087100386619568

Epoch: 6| Step: 3
Training loss: 0.8939225673675537
Validation loss: 2.077255149682363

Epoch: 6| Step: 4
Training loss: 0.9737728238105774
Validation loss: 2.061343570550283

Epoch: 6| Step: 5
Training loss: 0.7085967063903809
Validation loss: 2.081152558326721

Epoch: 6| Step: 6
Training loss: 0.6240552663803101
Validation loss: 2.03266708056132

Epoch: 6| Step: 7
Training loss: 0.6597315669059753
Validation loss: 2.0511124531428018

Epoch: 6| Step: 8
Training loss: 0.5400087237358093
Validation loss: 2.110429306825002

Epoch: 6| Step: 9
Training loss: 0.9085262417793274
Validation loss: 2.0731669068336487

Epoch: 6| Step: 10
Training loss: 0.7330839037895203
Validation loss: 2.0778122345606485

Epoch: 6| Step: 11
Training loss: 0.46200302243232727
Validation loss: 2.082592328389486

Epoch: 6| Step: 12
Training loss: 0.8132709264755249
Validation loss: 2.088793913523356

Epoch: 6| Step: 13
Training loss: 1.1754281520843506
Validation loss: 2.1116435726483664

Epoch: 141| Step: 0
Training loss: 0.8092260360717773
Validation loss: 2.080192267894745

Epoch: 6| Step: 1
Training loss: 0.8505764007568359
Validation loss: 2.048748036225637

Epoch: 6| Step: 2
Training loss: 0.9151965975761414
Validation loss: 2.0968281825383506

Epoch: 6| Step: 3
Training loss: 0.796998918056488
Validation loss: 2.0682926774024963

Epoch: 6| Step: 4
Training loss: 0.6874982118606567
Validation loss: 2.037022372086843

Epoch: 6| Step: 5
Training loss: 1.1157140731811523
Validation loss: 2.036381562550863

Epoch: 6| Step: 6
Training loss: 0.9900232553482056
Validation loss: 2.037355601787567

Epoch: 6| Step: 7
Training loss: 0.6473947763442993
Validation loss: 2.048030436038971

Epoch: 6| Step: 8
Training loss: 0.2531331777572632
Validation loss: 2.13260946671168

Epoch: 6| Step: 9
Training loss: 0.3823525309562683
Validation loss: 2.051010171572367

Epoch: 6| Step: 10
Training loss: 0.8053627610206604
Validation loss: 2.105030655860901

Epoch: 6| Step: 11
Training loss: 1.4576984643936157
Validation loss: 2.083631177743276

Epoch: 6| Step: 12
Training loss: 0.6740831136703491
Validation loss: 2.109382967154185

Epoch: 6| Step: 13
Training loss: 1.0979843139648438
Validation loss: 2.0595924456914267

Epoch: 142| Step: 0
Training loss: 0.6142398715019226
Validation loss: 2.0862056612968445

Epoch: 6| Step: 1
Training loss: 1.3003332614898682
Validation loss: 2.0682456692059836

Epoch: 6| Step: 2
Training loss: 0.6928293108940125
Validation loss: 2.0595732927322388

Epoch: 6| Step: 3
Training loss: 0.8390693068504333
Validation loss: 2.1093775033950806

Epoch: 6| Step: 4
Training loss: 0.4387197196483612
Validation loss: 2.0953174034754434

Epoch: 6| Step: 5
Training loss: 0.5812828540802002
Validation loss: 2.135467310746511

Epoch: 6| Step: 6
Training loss: 0.9364144802093506
Validation loss: 2.0779706637064614

Epoch: 6| Step: 7
Training loss: 1.3777917623519897
Validation loss: 2.06973930199941

Epoch: 6| Step: 8
Training loss: 0.6108728647232056
Validation loss: 2.075922886530558

Epoch: 6| Step: 9
Training loss: 0.6791960000991821
Validation loss: 2.1000525752703347

Epoch: 6| Step: 10
Training loss: 0.649199366569519
Validation loss: 2.0244805018107095

Epoch: 6| Step: 11
Training loss: 0.8255070447921753
Validation loss: 2.046814958254496

Epoch: 6| Step: 12
Training loss: 1.0391405820846558
Validation loss: 2.064249654610952

Epoch: 6| Step: 13
Training loss: 0.8096423745155334
Validation loss: 2.046145478884379

Epoch: 143| Step: 0
Training loss: 0.9690128564834595
Validation loss: 2.05170077085495

Epoch: 6| Step: 1
Training loss: 0.37874412536621094
Validation loss: 2.0479758580525718

Epoch: 6| Step: 2
Training loss: 0.7886139750480652
Validation loss: 2.058938960234324

Epoch: 6| Step: 3
Training loss: 0.910042405128479
Validation loss: 2.0626022815704346

Epoch: 6| Step: 4
Training loss: 0.8774795532226562
Validation loss: 2.0816570123036704

Epoch: 6| Step: 5
Training loss: 0.6237835884094238
Validation loss: 2.0903209249178567

Epoch: 6| Step: 6
Training loss: 0.6221833825111389
Validation loss: 2.0883174339930215

Epoch: 6| Step: 7
Training loss: 1.206251859664917
Validation loss: 2.0258271296819053

Epoch: 6| Step: 8
Training loss: 0.5463470220565796
Validation loss: 2.1235735217730203

Epoch: 6| Step: 9
Training loss: 1.0779691934585571
Validation loss: 2.050817350546519

Epoch: 6| Step: 10
Training loss: 0.4196019172668457
Validation loss: 2.004843990008036

Epoch: 6| Step: 11
Training loss: 0.6072697043418884
Validation loss: 2.0624449451764426

Epoch: 6| Step: 12
Training loss: 1.1096410751342773
Validation loss: 2.095562676588694

Epoch: 6| Step: 13
Training loss: 0.8471009731292725
Validation loss: 2.106617828210195

Epoch: 144| Step: 0
Training loss: 0.8831766843795776
Validation loss: 2.1268073320388794

Epoch: 6| Step: 1
Training loss: 0.4425041675567627
Validation loss: 2.073059598604838

Epoch: 6| Step: 2
Training loss: 1.1711194515228271
Validation loss: 2.0468843976656594

Epoch: 6| Step: 3
Training loss: 1.175498604774475
Validation loss: 2.057831803957621

Epoch: 6| Step: 4
Training loss: 0.855408251285553
Validation loss: 2.0614993969599404

Epoch: 6| Step: 5
Training loss: 1.05001962184906
Validation loss: 2.0750316381454468

Epoch: 6| Step: 6
Training loss: 1.0331709384918213
Validation loss: 2.0224032203356423

Epoch: 6| Step: 7
Training loss: 0.400510311126709
Validation loss: 2.0571601192156472

Epoch: 6| Step: 8
Training loss: 0.9414339661598206
Validation loss: 2.0436692237854004

Epoch: 6| Step: 9
Training loss: 0.5138914585113525
Validation loss: 2.103594263394674

Epoch: 6| Step: 10
Training loss: 0.5709641575813293
Validation loss: 2.102779666582743

Epoch: 6| Step: 11
Training loss: 0.8321508765220642
Validation loss: 2.1055280764897666

Epoch: 6| Step: 12
Training loss: 0.5796200037002563
Validation loss: 2.095519701639811

Epoch: 6| Step: 13
Training loss: 1.066669225692749
Validation loss: 2.0800928473472595

Epoch: 145| Step: 0
Training loss: 0.4511667490005493
Validation loss: 2.068146824836731

Epoch: 6| Step: 1
Training loss: 0.8153494596481323
Validation loss: 2.033656438191732

Epoch: 6| Step: 2
Training loss: 0.6023181080818176
Validation loss: 2.094815214474996

Epoch: 6| Step: 3
Training loss: 0.7913957238197327
Validation loss: 2.071212033430735

Epoch: 6| Step: 4
Training loss: 1.1613268852233887
Validation loss: 2.0202342669169107

Epoch: 6| Step: 5
Training loss: 0.47237157821655273
Validation loss: 2.0587905248006186

Epoch: 6| Step: 6
Training loss: 0.8912698030471802
Validation loss: 2.050859014193217

Epoch: 6| Step: 7
Training loss: 0.8148284554481506
Validation loss: 2.0367496411005654

Epoch: 6| Step: 8
Training loss: 0.908981442451477
Validation loss: 2.034258484840393

Epoch: 6| Step: 9
Training loss: 0.7807462811470032
Validation loss: 2.04049022992452

Epoch: 6| Step: 10
Training loss: 0.9462445378303528
Validation loss: 2.0944822231928506

Epoch: 6| Step: 11
Training loss: 0.7338677048683167
Validation loss: 2.0622633894284568

Epoch: 6| Step: 12
Training loss: 0.7031450867652893
Validation loss: 2.060346325238546

Epoch: 6| Step: 13
Training loss: 1.0765225887298584
Validation loss: 2.060382823149363

Epoch: 146| Step: 0
Training loss: 0.9293113350868225
Validation loss: 2.0840878089269004

Epoch: 6| Step: 1
Training loss: 1.036155104637146
Validation loss: 2.097550948460897

Epoch: 6| Step: 2
Training loss: 1.0043814182281494
Validation loss: 2.059203088283539

Epoch: 6| Step: 3
Training loss: 1.0068422555923462
Validation loss: 2.03268963098526

Epoch: 6| Step: 4
Training loss: 1.0809130668640137
Validation loss: 2.047208627065023

Epoch: 6| Step: 5
Training loss: 0.4301151633262634
Validation loss: 2.0257670680681863

Epoch: 6| Step: 6
Training loss: 0.7482563257217407
Validation loss: 2.032774289449056

Epoch: 6| Step: 7
Training loss: 1.027086853981018
Validation loss: 2.026099681854248

Epoch: 6| Step: 8
Training loss: 0.7380645275115967
Validation loss: 2.053890287876129

Epoch: 6| Step: 9
Training loss: 0.6956117153167725
Validation loss: 2.028820017973582

Epoch: 6| Step: 10
Training loss: 0.7602686285972595
Validation loss: 2.0513158440589905

Epoch: 6| Step: 11
Training loss: 0.5143475532531738
Validation loss: 2.079697072505951

Epoch: 6| Step: 12
Training loss: 0.4025385081768036
Validation loss: 2.0775336821873984

Epoch: 6| Step: 13
Training loss: 0.7535766363143921
Validation loss: 2.044767757256826

Epoch: 147| Step: 0
Training loss: 0.5578119158744812
Validation loss: 2.064631183942159

Epoch: 6| Step: 1
Training loss: 0.7597203254699707
Validation loss: 2.06135360399882

Epoch: 6| Step: 2
Training loss: 0.8021851181983948
Validation loss: 2.067837655544281

Epoch: 6| Step: 3
Training loss: 1.1057127714157104
Validation loss: 2.0475815733273826

Epoch: 6| Step: 4
Training loss: 0.5945672988891602
Validation loss: 2.0550925930341086

Epoch: 6| Step: 5
Training loss: 0.4472385346889496
Validation loss: 2.0368574062983194

Epoch: 6| Step: 6
Training loss: 1.1538465023040771
Validation loss: 2.092246433099111

Epoch: 6| Step: 7
Training loss: 0.6053814888000488
Validation loss: 2.1037243405977883

Epoch: 6| Step: 8
Training loss: 0.9588905572891235
Validation loss: 2.090662936369578

Epoch: 6| Step: 9
Training loss: 0.8828812837600708
Validation loss: 2.0620524684588113

Epoch: 6| Step: 10
Training loss: 1.2787926197052002
Validation loss: 2.090591331322988

Epoch: 6| Step: 11
Training loss: 0.45542818307876587
Validation loss: 2.0835676391919455

Epoch: 6| Step: 12
Training loss: 0.7203734517097473
Validation loss: 2.0626622438430786

Epoch: 6| Step: 13
Training loss: 0.7557018399238586
Validation loss: 2.0733734170595803

Epoch: 148| Step: 0
Training loss: 0.8122315406799316
Validation loss: 2.0205039381980896

Epoch: 6| Step: 1
Training loss: 0.9039009213447571
Validation loss: 2.039874792098999

Epoch: 6| Step: 2
Training loss: 0.5118885636329651
Validation loss: 2.059205869833628

Epoch: 6| Step: 3
Training loss: 0.803748607635498
Validation loss: 2.058011790116628

Epoch: 6| Step: 4
Training loss: 0.6826448440551758
Validation loss: 2.0721853574117026

Epoch: 6| Step: 5
Training loss: 1.0655633211135864
Validation loss: 2.0720011989275613

Epoch: 6| Step: 6
Training loss: 1.142602801322937
Validation loss: 2.039900004863739

Epoch: 6| Step: 7
Training loss: 0.7622151374816895
Validation loss: 2.069590131441752

Epoch: 6| Step: 8
Training loss: 0.5797621011734009
Validation loss: 2.0474654833475747

Epoch: 6| Step: 9
Training loss: 0.4759129285812378
Validation loss: 2.04838361342748

Epoch: 6| Step: 10
Training loss: 0.9012067317962646
Validation loss: 2.0302446484565735

Epoch: 6| Step: 11
Training loss: 1.0609840154647827
Validation loss: 2.028662403424581

Epoch: 6| Step: 12
Training loss: 0.3494286835193634
Validation loss: 2.068102240562439

Epoch: 6| Step: 13
Training loss: 0.6579603552818298
Validation loss: 1.9925007025400798

Epoch: 149| Step: 0
Training loss: 1.0730922222137451
Validation loss: 2.0548508365948996

Epoch: 6| Step: 1
Training loss: 0.885746955871582
Validation loss: 2.0307449102401733

Epoch: 6| Step: 2
Training loss: 0.6847215890884399
Validation loss: 2.018831113974253

Epoch: 6| Step: 3
Training loss: 0.5462747812271118
Validation loss: 1.9866141279538472

Epoch: 6| Step: 4
Training loss: 0.5132097601890564
Validation loss: 2.0660813450813293

Epoch: 6| Step: 5
Training loss: 1.3211174011230469
Validation loss: 2.058213690916697

Epoch: 6| Step: 6
Training loss: 0.5217745304107666
Validation loss: 2.0115854342778525

Epoch: 6| Step: 7
Training loss: 0.7662009000778198
Validation loss: 2.061425427595774

Epoch: 6| Step: 8
Training loss: 0.7996986508369446
Validation loss: 2.0478105346361795

Epoch: 6| Step: 9
Training loss: 0.6095637083053589
Validation loss: 2.03052818775177

Epoch: 6| Step: 10
Training loss: 0.6140055656433105
Validation loss: 2.0059916377067566

Epoch: 6| Step: 11
Training loss: 0.7594397068023682
Validation loss: 2.0216079552968345

Epoch: 6| Step: 12
Training loss: 0.5962068438529968
Validation loss: 2.0112885236740112

Epoch: 6| Step: 13
Training loss: 0.9037834405899048
Validation loss: 2.0799805720647178

Epoch: 150| Step: 0
Training loss: 0.9995481967926025
Validation loss: 2.0502978563308716

Epoch: 6| Step: 1
Training loss: 1.0148743391036987
Validation loss: 2.040371040503184

Epoch: 6| Step: 2
Training loss: 1.3185324668884277
Validation loss: 2.040119151274363

Epoch: 6| Step: 3
Training loss: 0.6625077724456787
Validation loss: 2.036012132962545

Epoch: 6| Step: 4
Training loss: 0.826352059841156
Validation loss: 1.9903422594070435

Epoch: 6| Step: 5
Training loss: 0.3290861248970032
Validation loss: 2.037699361642202

Epoch: 6| Step: 6
Training loss: 0.7640273571014404
Validation loss: 2.033664127190908

Epoch: 6| Step: 7
Training loss: 0.7783069014549255
Validation loss: 2.0625747640927634

Epoch: 6| Step: 8
Training loss: 0.7840927243232727
Validation loss: 2.066057006518046

Epoch: 6| Step: 9
Training loss: 0.9694019556045532
Validation loss: 2.0339465339978537

Epoch: 6| Step: 10
Training loss: 0.7922161817550659
Validation loss: 2.0458815892537436

Epoch: 6| Step: 11
Training loss: 0.4951573312282562
Validation loss: 2.072826067606608

Epoch: 6| Step: 12
Training loss: 0.28788697719573975
Validation loss: 2.1068050861358643

Epoch: 6| Step: 13
Training loss: 0.5802646279335022
Validation loss: 2.095487872759501

Epoch: 151| Step: 0
Training loss: 0.9318004846572876
Validation loss: 2.081083873907725

Epoch: 6| Step: 1
Training loss: 0.19693337380886078
Validation loss: 2.047762095928192

Epoch: 6| Step: 2
Training loss: 0.8471587896347046
Validation loss: 2.0183306535085044

Epoch: 6| Step: 3
Training loss: 0.6219202876091003
Validation loss: 2.0762279828389487

Epoch: 6| Step: 4
Training loss: 0.9719216227531433
Validation loss: 2.0276940862337747

Epoch: 6| Step: 5
Training loss: 1.1945075988769531
Validation loss: 2.0144834419091544

Epoch: 6| Step: 6
Training loss: 0.850793182849884
Validation loss: 2.041519045829773

Epoch: 6| Step: 7
Training loss: 0.8761075735092163
Validation loss: 2.0419196089108786

Epoch: 6| Step: 8
Training loss: 0.4987383782863617
Validation loss: 2.1388424237569175

Epoch: 6| Step: 9
Training loss: 0.8324803709983826
Validation loss: 2.04673304160436

Epoch: 6| Step: 10
Training loss: 0.5061610341072083
Validation loss: 2.0492767691612244

Epoch: 6| Step: 11
Training loss: 0.7965519428253174
Validation loss: 2.070396443208059

Epoch: 6| Step: 12
Training loss: 0.7773036956787109
Validation loss: 2.0914321541786194

Epoch: 6| Step: 13
Training loss: 0.6832783222198486
Validation loss: 2.0900335709253945

Epoch: 152| Step: 0
Training loss: 0.5215232372283936
Validation loss: 2.06848806142807

Epoch: 6| Step: 1
Training loss: 0.6610711216926575
Validation loss: 2.102066238721212

Epoch: 6| Step: 2
Training loss: 1.0141936540603638
Validation loss: 2.1196241974830627

Epoch: 6| Step: 3
Training loss: 0.944097638130188
Validation loss: 2.043275852998098

Epoch: 6| Step: 4
Training loss: 0.8433711528778076
Validation loss: 2.083069642384847

Epoch: 6| Step: 5
Training loss: 0.6142143607139587
Validation loss: 2.0494688947995505

Epoch: 6| Step: 6
Training loss: 0.7595421671867371
Validation loss: 2.05850080649058

Epoch: 6| Step: 7
Training loss: 1.1819334030151367
Validation loss: 2.022340714931488

Epoch: 6| Step: 8
Training loss: 0.6324997544288635
Validation loss: 2.0587063233057656

Epoch: 6| Step: 9
Training loss: 0.7946630716323853
Validation loss: 2.0501041611035666

Epoch: 6| Step: 10
Training loss: 0.2904345989227295
Validation loss: 2.0089546044667563

Epoch: 6| Step: 11
Training loss: 0.7243040204048157
Validation loss: 2.077430486679077

Epoch: 6| Step: 12
Training loss: 0.6213045716285706
Validation loss: 2.1043594678243003

Epoch: 6| Step: 13
Training loss: 0.6865906715393066
Validation loss: 2.083757698535919

Epoch: 153| Step: 0
Training loss: 0.9293633699417114
Validation loss: 2.047801454861959

Epoch: 6| Step: 1
Training loss: 0.9673014283180237
Validation loss: 2.0777320663134256

Epoch: 6| Step: 2
Training loss: 0.6146599054336548
Validation loss: 2.0483671029408774

Epoch: 6| Step: 3
Training loss: 1.191986083984375
Validation loss: 2.0613245765368142

Epoch: 6| Step: 4
Training loss: 0.7937723398208618
Validation loss: 2.021072487036387

Epoch: 6| Step: 5
Training loss: 0.3900669515132904
Validation loss: 2.0160255829493203

Epoch: 6| Step: 6
Training loss: 0.5098754167556763
Validation loss: 2.0855579574902854

Epoch: 6| Step: 7
Training loss: 1.1227302551269531
Validation loss: 2.0318973660469055

Epoch: 6| Step: 8
Training loss: 1.1070550680160522
Validation loss: 2.0403268535931907

Epoch: 6| Step: 9
Training loss: 0.776614785194397
Validation loss: 2.029804309209188

Epoch: 6| Step: 10
Training loss: 0.4912520945072174
Validation loss: 2.0528409282366433

Epoch: 6| Step: 11
Training loss: 0.699039876461029
Validation loss: 2.068291743596395

Epoch: 6| Step: 12
Training loss: 0.5507806539535522
Validation loss: 2.0544021129608154

Epoch: 6| Step: 13
Training loss: 0.5209020972251892
Validation loss: 2.0805307626724243

Epoch: 154| Step: 0
Training loss: 1.1965045928955078
Validation loss: 2.0971335570017495

Epoch: 6| Step: 1
Training loss: 0.4780224859714508
Validation loss: 2.1080897450447083

Epoch: 6| Step: 2
Training loss: 0.8663515448570251
Validation loss: 2.072295844554901

Epoch: 6| Step: 3
Training loss: 0.7339446544647217
Validation loss: 2.119600077470144

Epoch: 6| Step: 4
Training loss: 0.6637909412384033
Validation loss: 2.0574327309926352

Epoch: 6| Step: 5
Training loss: 0.9643097519874573
Validation loss: 2.0671552220980325

Epoch: 6| Step: 6
Training loss: 0.5061382055282593
Validation loss: 2.0467066566149392

Epoch: 6| Step: 7
Training loss: 0.4095960259437561
Validation loss: 2.0560503005981445

Epoch: 6| Step: 8
Training loss: 0.5749317407608032
Validation loss: 2.054427762826284

Epoch: 6| Step: 9
Training loss: 0.96966552734375
Validation loss: 2.0578913489977517

Epoch: 6| Step: 10
Training loss: 0.7723518013954163
Validation loss: 2.0324689944585166

Epoch: 6| Step: 11
Training loss: 0.9335263967514038
Validation loss: 2.0498595237731934

Epoch: 6| Step: 12
Training loss: 0.37857457995414734
Validation loss: 2.0734466115633645

Epoch: 6| Step: 13
Training loss: 0.5968229174613953
Validation loss: 2.001320997873942

Epoch: 155| Step: 0
Training loss: 0.24649004638195038
Validation loss: 2.0884206096331277

Epoch: 6| Step: 1
Training loss: 0.8290313482284546
Validation loss: 2.006219506263733

Epoch: 6| Step: 2
Training loss: 0.5230879187583923
Validation loss: 2.057828446229299

Epoch: 6| Step: 3
Training loss: 0.3887665271759033
Validation loss: 2.0455612937609353

Epoch: 6| Step: 4
Training loss: 0.9002317190170288
Validation loss: 2.097076416015625

Epoch: 6| Step: 5
Training loss: 0.799910306930542
Validation loss: 2.0398202339808145

Epoch: 6| Step: 6
Training loss: 0.4751192629337311
Validation loss: 2.0676439801851907

Epoch: 6| Step: 7
Training loss: 0.9397474527359009
Validation loss: 2.0501584808031716

Epoch: 6| Step: 8
Training loss: 0.9904356002807617
Validation loss: 2.0893278320630393

Epoch: 6| Step: 9
Training loss: 0.5254340171813965
Validation loss: 2.0905160705248513

Epoch: 6| Step: 10
Training loss: 0.587593674659729
Validation loss: 2.075082004070282

Epoch: 6| Step: 11
Training loss: 1.3106629848480225
Validation loss: 2.0691334009170532

Epoch: 6| Step: 12
Training loss: 0.35128021240234375
Validation loss: 2.080000857512156

Epoch: 6| Step: 13
Training loss: 0.9241663217544556
Validation loss: 2.060317079226176

Epoch: 156| Step: 0
Training loss: 0.6322168111801147
Validation loss: 2.0728487571080527

Epoch: 6| Step: 1
Training loss: 0.4419776499271393
Validation loss: 2.0704526901245117

Epoch: 6| Step: 2
Training loss: 0.6441774368286133
Validation loss: 2.061497151851654

Epoch: 6| Step: 3
Training loss: 0.46000421047210693
Validation loss: 2.055930475393931

Epoch: 6| Step: 4
Training loss: 1.019913673400879
Validation loss: 2.0477906465530396

Epoch: 6| Step: 5
Training loss: 0.7401101589202881
Validation loss: 2.056219478448232

Epoch: 6| Step: 6
Training loss: 0.8968483209609985
Validation loss: 2.059030016263326

Epoch: 6| Step: 7
Training loss: 0.6506055593490601
Validation loss: 2.0939088066418967

Epoch: 6| Step: 8
Training loss: 1.0736392736434937
Validation loss: 2.107202390829722

Epoch: 6| Step: 9
Training loss: 0.9928205609321594
Validation loss: 2.0234147906303406

Epoch: 6| Step: 10
Training loss: 0.6490322947502136
Validation loss: 2.07182914018631

Epoch: 6| Step: 11
Training loss: 0.7585797309875488
Validation loss: 2.060643414656321

Epoch: 6| Step: 12
Training loss: 0.8312407732009888
Validation loss: 2.0491042335828147

Epoch: 6| Step: 13
Training loss: 0.540658712387085
Validation loss: 2.0493545134862265

Epoch: 157| Step: 0
Training loss: 0.6066758632659912
Validation loss: 2.0596654415130615

Epoch: 6| Step: 1
Training loss: 0.8933449983596802
Validation loss: 2.0643433332443237

Epoch: 6| Step: 2
Training loss: 0.7875317335128784
Validation loss: 2.052229344844818

Epoch: 6| Step: 3
Training loss: 0.5914657115936279
Validation loss: 2.0678165555000305

Epoch: 6| Step: 4
Training loss: 0.6810590624809265
Validation loss: 2.0599876642227173

Epoch: 6| Step: 5
Training loss: 0.4279605746269226
Validation loss: 2.0559932589530945

Epoch: 6| Step: 6
Training loss: 1.0693066120147705
Validation loss: 2.071373999118805

Epoch: 6| Step: 7
Training loss: 0.5922106504440308
Validation loss: 2.0251749555269876

Epoch: 6| Step: 8
Training loss: 0.421314001083374
Validation loss: 2.017803351084391

Epoch: 6| Step: 9
Training loss: 0.5861499905586243
Validation loss: 2.0646713376045227

Epoch: 6| Step: 10
Training loss: 0.6038683652877808
Validation loss: 2.0511235992113748

Epoch: 6| Step: 11
Training loss: 0.7458791732788086
Validation loss: 2.0658057729403176

Epoch: 6| Step: 12
Training loss: 0.9892193078994751
Validation loss: 2.0304637948671975

Epoch: 6| Step: 13
Training loss: 0.8888677358627319
Validation loss: 2.0345506072044373

Epoch: 158| Step: 0
Training loss: 1.0080429315567017
Validation loss: 2.0077525774637857

Epoch: 6| Step: 1
Training loss: 1.284960150718689
Validation loss: 2.0211851994196572

Epoch: 6| Step: 2
Training loss: 0.3740396797657013
Validation loss: 2.0524098873138428

Epoch: 6| Step: 3
Training loss: 0.5754232406616211
Validation loss: 2.0078047712643943

Epoch: 6| Step: 4
Training loss: 0.6747877597808838
Validation loss: 2.037744661172231

Epoch: 6| Step: 5
Training loss: 0.33646929264068604
Validation loss: 2.029198189576467

Epoch: 6| Step: 6
Training loss: 0.3717275857925415
Validation loss: 1.9997308850288391

Epoch: 6| Step: 7
Training loss: 0.9114251136779785
Validation loss: 1.9929351806640625

Epoch: 6| Step: 8
Training loss: 0.7223470211029053
Validation loss: 2.0563629269599915

Epoch: 6| Step: 9
Training loss: 0.8574782609939575
Validation loss: 2.0307428439458213

Epoch: 6| Step: 10
Training loss: 0.9020978212356567
Validation loss: 2.0010604858398438

Epoch: 6| Step: 11
Training loss: 0.7244919538497925
Validation loss: 2.052473505338033

Epoch: 6| Step: 12
Training loss: 0.6719924807548523
Validation loss: 2.0453463991483054

Epoch: 6| Step: 13
Training loss: 0.4246562123298645
Validation loss: 2.034015417098999

Epoch: 159| Step: 0
Training loss: 0.7196089029312134
Validation loss: 2.1118938326835632

Epoch: 6| Step: 1
Training loss: 0.7222485542297363
Validation loss: 2.0321751832962036

Epoch: 6| Step: 2
Training loss: 1.1154710054397583
Validation loss: 2.0914947787920632

Epoch: 6| Step: 3
Training loss: 0.3643929362297058
Validation loss: 2.048893610636393

Epoch: 6| Step: 4
Training loss: 0.6590638756752014
Validation loss: 2.012291431427002

Epoch: 6| Step: 5
Training loss: 0.7486027479171753
Validation loss: 2.010072668393453

Epoch: 6| Step: 6
Training loss: 0.5625957250595093
Validation loss: 2.079397678375244

Epoch: 6| Step: 7
Training loss: 0.689058244228363
Validation loss: 2.0664859414100647

Epoch: 6| Step: 8
Training loss: 0.7637646794319153
Validation loss: 2.0924775997797647

Epoch: 6| Step: 9
Training loss: 0.6699942350387573
Validation loss: 2.058332165082296

Epoch: 6| Step: 10
Training loss: 0.7576836943626404
Validation loss: 2.0826481580734253

Epoch: 6| Step: 11
Training loss: 0.9537591934204102
Validation loss: 2.1212875048319497

Epoch: 6| Step: 12
Training loss: 0.18769018352031708
Validation loss: 2.0881502429644265

Epoch: 6| Step: 13
Training loss: 0.5706123113632202
Validation loss: 2.04881759484609

Epoch: 160| Step: 0
Training loss: 0.7234774827957153
Validation loss: 2.044716715812683

Epoch: 6| Step: 1
Training loss: 0.5839839577674866
Validation loss: 2.0695187052090964

Epoch: 6| Step: 2
Training loss: 0.5995482802391052
Validation loss: 2.0120779474576316

Epoch: 6| Step: 3
Training loss: 0.6769543886184692
Validation loss: 2.0608776013056436

Epoch: 6| Step: 4
Training loss: 1.090788722038269
Validation loss: 2.1013907194137573

Epoch: 6| Step: 5
Training loss: 0.863278865814209
Validation loss: 2.0924028555552163

Epoch: 6| Step: 6
Training loss: 0.5981515645980835
Validation loss: 2.07138991355896

Epoch: 6| Step: 7
Training loss: 0.7834568619728088
Validation loss: 2.091205815474192

Epoch: 6| Step: 8
Training loss: 0.9400550127029419
Validation loss: 2.0349509716033936

Epoch: 6| Step: 9
Training loss: 0.49372026324272156
Validation loss: 1.9935152928034465

Epoch: 6| Step: 10
Training loss: 0.9835678339004517
Validation loss: 2.029889404773712

Epoch: 6| Step: 11
Training loss: 0.5698225498199463
Validation loss: 1.994184176127116

Epoch: 6| Step: 12
Training loss: 0.7165029048919678
Validation loss: 2.0315135717391968

Epoch: 6| Step: 13
Training loss: 0.48093676567077637
Validation loss: 2.031465689341227

Epoch: 161| Step: 0
Training loss: 0.6992601156234741
Validation loss: 2.0304617285728455

Epoch: 6| Step: 1
Training loss: 0.7869317531585693
Validation loss: 1.9978266557057698

Epoch: 6| Step: 2
Training loss: 0.29289501905441284
Validation loss: 2.053723851839701

Epoch: 6| Step: 3
Training loss: 0.5144566297531128
Validation loss: 2.0288817087809243

Epoch: 6| Step: 4
Training loss: 0.9783111214637756
Validation loss: 2.031398812929789

Epoch: 6| Step: 5
Training loss: 0.7674108147621155
Validation loss: 2.0750699241956077

Epoch: 6| Step: 6
Training loss: 0.5433810949325562
Validation loss: 2.007046103477478

Epoch: 6| Step: 7
Training loss: 0.6398729681968689
Validation loss: 2.0123433669408164

Epoch: 6| Step: 8
Training loss: 0.5794966220855713
Validation loss: 1.9917518695195515

Epoch: 6| Step: 9
Training loss: 1.138892412185669
Validation loss: 1.9838940898577373

Epoch: 6| Step: 10
Training loss: 0.7018934488296509
Validation loss: 2.043907721837362

Epoch: 6| Step: 11
Training loss: 0.35000717639923096
Validation loss: 2.045096516609192

Epoch: 6| Step: 12
Training loss: 1.3756616115570068
Validation loss: 2.0879741509755454

Epoch: 6| Step: 13
Training loss: 0.761695384979248
Validation loss: 2.070932388305664

Epoch: 162| Step: 0
Training loss: 0.47564250230789185
Validation loss: 2.0650525093078613

Epoch: 6| Step: 1
Training loss: 0.6051934361457825
Validation loss: 2.046936492125193

Epoch: 6| Step: 2
Training loss: 0.5797032117843628
Validation loss: 2.035748779773712

Epoch: 6| Step: 3
Training loss: 0.7350133657455444
Validation loss: 2.0356716314951577

Epoch: 6| Step: 4
Training loss: 0.7804602980613708
Validation loss: 2.065632998943329

Epoch: 6| Step: 5
Training loss: 1.4651421308517456
Validation loss: 2.0675467252731323

Epoch: 6| Step: 6
Training loss: 1.2063424587249756
Validation loss: 2.057568351427714

Epoch: 6| Step: 7
Training loss: 0.5786516070365906
Validation loss: 2.069716493288676

Epoch: 6| Step: 8
Training loss: 0.48196613788604736
Validation loss: 2.037045955657959

Epoch: 6| Step: 9
Training loss: 0.5522575974464417
Validation loss: 2.0696990887324014

Epoch: 6| Step: 10
Training loss: 0.5015288591384888
Validation loss: 2.0358938177426658

Epoch: 6| Step: 11
Training loss: 1.0184595584869385
Validation loss: 2.0515692432721457

Epoch: 6| Step: 12
Training loss: 1.1481986045837402
Validation loss: 2.084397534529368

Epoch: 6| Step: 13
Training loss: 0.7687594890594482
Validation loss: 2.0253430207570395

Epoch: 163| Step: 0
Training loss: 0.5350932478904724
Validation loss: 2.0708588560422263

Epoch: 6| Step: 1
Training loss: 0.7117406725883484
Validation loss: 2.064953863620758

Epoch: 6| Step: 2
Training loss: 0.9784601330757141
Validation loss: 2.001106381416321

Epoch: 6| Step: 3
Training loss: 0.8529991507530212
Validation loss: 2.0091373523076377

Epoch: 6| Step: 4
Training loss: 0.6853708624839783
Validation loss: 2.0613433718681335

Epoch: 6| Step: 5
Training loss: 0.32821962237358093
Validation loss: 2.0392441550890603

Epoch: 6| Step: 6
Training loss: 0.8275918960571289
Validation loss: 2.05790909131368

Epoch: 6| Step: 7
Training loss: 1.0120971202850342
Validation loss: 2.064325451850891

Epoch: 6| Step: 8
Training loss: 0.8392488956451416
Validation loss: 2.128565033276876

Epoch: 6| Step: 9
Training loss: 1.0096882581710815
Validation loss: 2.1405458052953086

Epoch: 6| Step: 10
Training loss: 1.070623517036438
Validation loss: 2.0853760639826455

Epoch: 6| Step: 11
Training loss: 0.42117345333099365
Validation loss: 2.0821573535601297

Epoch: 6| Step: 12
Training loss: 0.4400271475315094
Validation loss: 2.03018985191981

Epoch: 6| Step: 13
Training loss: 0.3712453246116638
Validation loss: 2.0242934823036194

Epoch: 164| Step: 0
Training loss: 0.7440423965454102
Validation loss: 2.03766922156016

Epoch: 6| Step: 1
Training loss: 0.6793471574783325
Validation loss: 2.0188278953234353

Epoch: 6| Step: 2
Training loss: 1.0271010398864746
Validation loss: 2.024834632873535

Epoch: 6| Step: 3
Training loss: 1.146912932395935
Validation loss: 2.059927999973297

Epoch: 6| Step: 4
Training loss: 0.6050133109092712
Validation loss: 2.0404401421546936

Epoch: 6| Step: 5
Training loss: 0.7649127244949341
Validation loss: 2.064502557118734

Epoch: 6| Step: 6
Training loss: 1.0760135650634766
Validation loss: 2.0821401278177896

Epoch: 6| Step: 7
Training loss: 0.6068531274795532
Validation loss: 2.0806033412615457

Epoch: 6| Step: 8
Training loss: 0.9420593976974487
Validation loss: 2.050295114517212

Epoch: 6| Step: 9
Training loss: 0.43898412585258484
Validation loss: 2.0412365992863974

Epoch: 6| Step: 10
Training loss: 1.1511423587799072
Validation loss: 2.012117644151052

Epoch: 6| Step: 11
Training loss: 0.636471152305603
Validation loss: 2.0502715706825256

Epoch: 6| Step: 12
Training loss: 0.568576455116272
Validation loss: 2.055168370405833

Epoch: 6| Step: 13
Training loss: 0.7007721066474915
Validation loss: 2.0081193844477334

Epoch: 165| Step: 0
Training loss: 0.4350895285606384
Validation loss: 2.059459308783213

Epoch: 6| Step: 1
Training loss: 0.6629873514175415
Validation loss: 2.0020411809285483

Epoch: 6| Step: 2
Training loss: 0.4548638164997101
Validation loss: 2.0607223312060037

Epoch: 6| Step: 3
Training loss: 0.7923827171325684
Validation loss: 2.0916857719421387

Epoch: 6| Step: 4
Training loss: 0.7461198568344116
Validation loss: 2.0433930158615112

Epoch: 6| Step: 5
Training loss: 0.5058135986328125
Validation loss: 2.081363797187805

Epoch: 6| Step: 6
Training loss: 0.575296938419342
Validation loss: 2.0754311879475913

Epoch: 6| Step: 7
Training loss: 0.5866751670837402
Validation loss: 2.0801624854405723

Epoch: 6| Step: 8
Training loss: 0.7037920951843262
Validation loss: 2.0124436219533286

Epoch: 6| Step: 9
Training loss: 0.8448747396469116
Validation loss: 2.069683333237966

Epoch: 6| Step: 10
Training loss: 0.6392704248428345
Validation loss: 2.0418155590693154

Epoch: 6| Step: 11
Training loss: 1.0599703788757324
Validation loss: 2.059615890185038

Epoch: 6| Step: 12
Training loss: 0.6136003732681274
Validation loss: 1.9702039162317913

Epoch: 6| Step: 13
Training loss: 1.030688762664795
Validation loss: 2.041753570238749

Epoch: 166| Step: 0
Training loss: 0.8470602035522461
Validation loss: 2.055706818898519

Epoch: 6| Step: 1
Training loss: 0.6152227520942688
Validation loss: 2.070191582043966

Epoch: 6| Step: 2
Training loss: 0.7630811929702759
Validation loss: 2.083046038945516

Epoch: 6| Step: 3
Training loss: 0.6468027830123901
Validation loss: 2.08063534895579

Epoch: 6| Step: 4
Training loss: 0.3133998215198517
Validation loss: 2.047011355559031

Epoch: 6| Step: 5
Training loss: 0.9777839779853821
Validation loss: 2.0298725962638855

Epoch: 6| Step: 6
Training loss: 0.6080547571182251
Validation loss: 2.0353448192278543

Epoch: 6| Step: 7
Training loss: 0.8340176939964294
Validation loss: 2.0389126539230347

Epoch: 6| Step: 8
Training loss: 0.31310147047042847
Validation loss: 2.039586047331492

Epoch: 6| Step: 9
Training loss: 0.5010441541671753
Validation loss: 2.0298750003178916

Epoch: 6| Step: 10
Training loss: 0.4668528139591217
Validation loss: 2.0184566974639893

Epoch: 6| Step: 11
Training loss: 1.0810335874557495
Validation loss: 1.9968740940093994

Epoch: 6| Step: 12
Training loss: 0.6352067589759827
Validation loss: 2.0433140993118286

Epoch: 6| Step: 13
Training loss: 0.69883131980896
Validation loss: 1.9961944818496704

Epoch: 167| Step: 0
Training loss: 0.20469655096530914
Validation loss: 2.025202135245005

Epoch: 6| Step: 1
Training loss: 0.6959466934204102
Validation loss: 2.062171200911204

Epoch: 6| Step: 2
Training loss: 0.5328389406204224
Validation loss: 2.0322168668111167

Epoch: 6| Step: 3
Training loss: 0.5708080530166626
Validation loss: 2.0494216283162436

Epoch: 6| Step: 4
Training loss: 0.5023808479309082
Validation loss: 2.044060448805491

Epoch: 6| Step: 5
Training loss: 0.8339237570762634
Validation loss: 2.023961067199707

Epoch: 6| Step: 6
Training loss: 0.6753807067871094
Validation loss: 2.030514717102051

Epoch: 6| Step: 7
Training loss: 0.8268965482711792
Validation loss: 2.005296508471171

Epoch: 6| Step: 8
Training loss: 0.7011967897415161
Validation loss: 1.9936448733011882

Epoch: 6| Step: 9
Training loss: 0.937271237373352
Validation loss: 2.0398119489351907

Epoch: 6| Step: 10
Training loss: 0.8576276302337646
Validation loss: 2.0233383973439536

Epoch: 6| Step: 11
Training loss: 0.5095750093460083
Validation loss: 1.9951549172401428

Epoch: 6| Step: 12
Training loss: 0.6067795157432556
Validation loss: 2.0110827684402466

Epoch: 6| Step: 13
Training loss: 0.8106675744056702
Validation loss: 2.0794962843259177

Epoch: 168| Step: 0
Training loss: 0.672126293182373
Validation loss: 2.0309594869613647

Epoch: 6| Step: 1
Training loss: 0.7818827629089355
Validation loss: 2.0799394845962524

Epoch: 6| Step: 2
Training loss: 0.9312429428100586
Validation loss: 2.0935662587483725

Epoch: 6| Step: 3
Training loss: 0.40355318784713745
Validation loss: 2.0512136816978455

Epoch: 6| Step: 4
Training loss: 0.7517419457435608
Validation loss: 2.0291678508122764

Epoch: 6| Step: 5
Training loss: 0.7054921388626099
Validation loss: 2.012720823287964

Epoch: 6| Step: 6
Training loss: 0.4003417491912842
Validation loss: 2.0087032516797385

Epoch: 6| Step: 7
Training loss: 0.8942141532897949
Validation loss: 2.0412463744481406

Epoch: 6| Step: 8
Training loss: 0.5572143793106079
Validation loss: 2.055909355481466

Epoch: 6| Step: 9
Training loss: 0.6703722476959229
Validation loss: 2.050929546356201

Epoch: 6| Step: 10
Training loss: 0.4432060718536377
Validation loss: 2.0407749017079673

Epoch: 6| Step: 11
Training loss: 0.26605498790740967
Validation loss: 2.0375494360923767

Epoch: 6| Step: 12
Training loss: 1.5388593673706055
Validation loss: 2.0338209867477417

Epoch: 6| Step: 13
Training loss: 0.5083131790161133
Validation loss: 2.0635725061098733

Epoch: 169| Step: 0
Training loss: 0.5563957095146179
Validation loss: 2.086658477783203

Epoch: 6| Step: 1
Training loss: 0.8038548231124878
Validation loss: 2.0501530965169272

Epoch: 6| Step: 2
Training loss: 0.6420510411262512
Validation loss: 2.0664997498194375

Epoch: 6| Step: 3
Training loss: 0.6873034834861755
Validation loss: 2.0413346886634827

Epoch: 6| Step: 4
Training loss: 0.9464160203933716
Validation loss: 2.0422549645105996

Epoch: 6| Step: 5
Training loss: 0.5732367634773254
Validation loss: 2.0500189065933228

Epoch: 6| Step: 6
Training loss: 0.6023962497711182
Validation loss: 2.0886067748069763

Epoch: 6| Step: 7
Training loss: 0.7492549419403076
Validation loss: 2.0856273571650186

Epoch: 6| Step: 8
Training loss: 0.5168744921684265
Validation loss: 2.0229640007019043

Epoch: 6| Step: 9
Training loss: 0.6033347249031067
Validation loss: 2.010047177473704

Epoch: 6| Step: 10
Training loss: 0.7953543663024902
Validation loss: 2.007845143477122

Epoch: 6| Step: 11
Training loss: 0.48298802971839905
Validation loss: 2.036790192127228

Epoch: 6| Step: 12
Training loss: 1.2281920909881592
Validation loss: 2.0398975809415183

Epoch: 6| Step: 13
Training loss: 0.31326496601104736
Validation loss: 2.0205652912457785

Epoch: 170| Step: 0
Training loss: 0.4262443482875824
Validation loss: 2.0559082428614297

Epoch: 6| Step: 1
Training loss: 0.47469472885131836
Validation loss: 2.032976190249125

Epoch: 6| Step: 2
Training loss: 0.6537124514579773
Validation loss: 2.0271023313204446

Epoch: 6| Step: 3
Training loss: 0.6584799885749817
Validation loss: 2.0584020614624023

Epoch: 6| Step: 4
Training loss: 0.550042986869812
Validation loss: 2.061145623524984

Epoch: 6| Step: 5
Training loss: 0.7110713124275208
Validation loss: 2.0454587936401367

Epoch: 6| Step: 6
Training loss: 1.0574679374694824
Validation loss: 2.03428320089976

Epoch: 6| Step: 7
Training loss: 0.45306748151779175
Validation loss: 2.0482042034467063

Epoch: 6| Step: 8
Training loss: 0.9164084196090698
Validation loss: 2.0242937008539834

Epoch: 6| Step: 9
Training loss: 0.4939928650856018
Validation loss: 2.024303356806437

Epoch: 6| Step: 10
Training loss: 0.596867024898529
Validation loss: 2.070469697316488

Epoch: 6| Step: 11
Training loss: 0.9539899230003357
Validation loss: 2.0440024534861245

Epoch: 6| Step: 12
Training loss: 0.6232154369354248
Validation loss: 2.0595894853274026

Epoch: 6| Step: 13
Training loss: 0.4119686484336853
Validation loss: 2.0534512400627136

Epoch: 171| Step: 0
Training loss: 0.707183837890625
Validation loss: 2.074421207110087

Epoch: 6| Step: 1
Training loss: 0.39940154552459717
Validation loss: 2.027450978755951

Epoch: 6| Step: 2
Training loss: 0.6657167077064514
Validation loss: 2.070732752482096

Epoch: 6| Step: 3
Training loss: 0.3340843617916107
Validation loss: 2.1225770711898804

Epoch: 6| Step: 4
Training loss: 0.5072544813156128
Validation loss: 2.1202160318692527

Epoch: 6| Step: 5
Training loss: 0.5376262664794922
Validation loss: 2.0835277239481607

Epoch: 6| Step: 6
Training loss: 0.36840522289276123
Validation loss: 2.1068563063939414

Epoch: 6| Step: 7
Training loss: 1.1170179843902588
Validation loss: 2.086877783139547

Epoch: 6| Step: 8
Training loss: 1.1236538887023926
Validation loss: 2.0518323183059692

Epoch: 6| Step: 9
Training loss: 0.527983546257019
Validation loss: 2.059152364730835

Epoch: 6| Step: 10
Training loss: 0.9522078037261963
Validation loss: 2.029723902543386

Epoch: 6| Step: 11
Training loss: 0.7035949230194092
Validation loss: 2.060844043890635

Epoch: 6| Step: 12
Training loss: 0.5057895183563232
Validation loss: 2.0600290298461914

Epoch: 6| Step: 13
Training loss: 0.5961109399795532
Validation loss: 2.0564792354901633

Epoch: 172| Step: 0
Training loss: 0.5483145117759705
Validation loss: 2.0616963704427085

Epoch: 6| Step: 1
Training loss: 1.0202653408050537
Validation loss: 2.0776271422704062

Epoch: 6| Step: 2
Training loss: 0.2592819333076477
Validation loss: 2.0721927881240845

Epoch: 6| Step: 3
Training loss: 0.42034608125686646
Validation loss: 2.05892946322759

Epoch: 6| Step: 4
Training loss: 0.7804062366485596
Validation loss: 2.036675532658895

Epoch: 6| Step: 5
Training loss: 0.4558926224708557
Validation loss: 2.1119571924209595

Epoch: 6| Step: 6
Training loss: 0.38028043508529663
Validation loss: 2.0844231247901917

Epoch: 6| Step: 7
Training loss: 0.9329971075057983
Validation loss: 2.0574718713760376

Epoch: 6| Step: 8
Training loss: 0.5911053419113159
Validation loss: 2.0473508834838867

Epoch: 6| Step: 9
Training loss: 0.526703953742981
Validation loss: 2.046936790148417

Epoch: 6| Step: 10
Training loss: 1.1178590059280396
Validation loss: 2.0551757216453552

Epoch: 6| Step: 11
Training loss: 0.4078044891357422
Validation loss: 2.061375459035238

Epoch: 6| Step: 12
Training loss: 0.4768978953361511
Validation loss: 2.0434943238894143

Epoch: 6| Step: 13
Training loss: 0.8184798955917358
Validation loss: 2.097803513209025

Epoch: 173| Step: 0
Training loss: 0.8726246356964111
Validation loss: 2.0383938352266946

Epoch: 6| Step: 1
Training loss: 0.36012086272239685
Validation loss: 2.0781079729398093

Epoch: 6| Step: 2
Training loss: 0.6823341846466064
Validation loss: 2.0851604541142783

Epoch: 6| Step: 3
Training loss: 0.8717591166496277
Validation loss: 2.0557036797205606

Epoch: 6| Step: 4
Training loss: 0.33487388491630554
Validation loss: 2.046095093091329

Epoch: 6| Step: 5
Training loss: 0.3371535837650299
Validation loss: 2.0551557739575705

Epoch: 6| Step: 6
Training loss: 0.7201226353645325
Validation loss: 2.0820117394129434

Epoch: 6| Step: 7
Training loss: 0.5356162786483765
Validation loss: 2.0273534655570984

Epoch: 6| Step: 8
Training loss: 0.523098886013031
Validation loss: 2.053966244061788

Epoch: 6| Step: 9
Training loss: 0.8800320029258728
Validation loss: 2.0036896665891013

Epoch: 6| Step: 10
Training loss: 0.6362302303314209
Validation loss: 2.0138429005940757

Epoch: 6| Step: 11
Training loss: 0.5834677815437317
Validation loss: 2.064367115497589

Epoch: 6| Step: 12
Training loss: 0.7532186508178711
Validation loss: 2.0428370038668313

Epoch: 6| Step: 13
Training loss: 0.7741568088531494
Validation loss: 2.066125472386678

Epoch: 174| Step: 0
Training loss: 0.6590925455093384
Validation loss: 2.039169172445933

Epoch: 6| Step: 1
Training loss: 0.3061408996582031
Validation loss: 2.0321380496025085

Epoch: 6| Step: 2
Training loss: 0.4305664896965027
Validation loss: 2.0376219352086387

Epoch: 6| Step: 3
Training loss: 0.5310264229774475
Validation loss: 2.089824676513672

Epoch: 6| Step: 4
Training loss: 0.789251446723938
Validation loss: 2.013498326142629

Epoch: 6| Step: 5
Training loss: 1.106699824333191
Validation loss: 2.029606580734253

Epoch: 6| Step: 6
Training loss: 0.4122980833053589
Validation loss: 2.0481781363487244

Epoch: 6| Step: 7
Training loss: 0.5734684467315674
Validation loss: 2.0884289542833963

Epoch: 6| Step: 8
Training loss: 0.770600438117981
Validation loss: 2.039664347966512

Epoch: 6| Step: 9
Training loss: 0.6480539441108704
Validation loss: 2.0930498043696084

Epoch: 6| Step: 10
Training loss: 0.7175818681716919
Validation loss: 2.045247197151184

Epoch: 6| Step: 11
Training loss: 0.4333551526069641
Validation loss: 2.0707772175470986

Epoch: 6| Step: 12
Training loss: 0.7950313687324524
Validation loss: 2.041162649790446

Epoch: 6| Step: 13
Training loss: 0.48015066981315613
Validation loss: 2.03389181693395

Epoch: 175| Step: 0
Training loss: 0.506752610206604
Validation loss: 1.9840352535247803

Epoch: 6| Step: 1
Training loss: 0.5278438925743103
Validation loss: 2.012829343477885

Epoch: 6| Step: 2
Training loss: 0.9228500127792358
Validation loss: 2.0400827527046204

Epoch: 6| Step: 3
Training loss: 0.48344936966896057
Validation loss: 2.061088720957438

Epoch: 6| Step: 4
Training loss: 1.0544501543045044
Validation loss: 1.9869351585706074

Epoch: 6| Step: 5
Training loss: 0.4700304865837097
Validation loss: 2.055436670780182

Epoch: 6| Step: 6
Training loss: 0.9060371518135071
Validation loss: 2.0278311173121133

Epoch: 6| Step: 7
Training loss: 0.7314945459365845
Validation loss: 2.033216873804728

Epoch: 6| Step: 8
Training loss: 0.5054677128791809
Validation loss: 2.0187195936838784

Epoch: 6| Step: 9
Training loss: 0.4738048017024994
Validation loss: 2.0318360726038613

Epoch: 6| Step: 10
Training loss: 0.4307197630405426
Validation loss: 2.033207893371582

Epoch: 6| Step: 11
Training loss: 0.6843305230140686
Validation loss: 2.0307923555374146

Epoch: 6| Step: 12
Training loss: 0.21065792441368103
Validation loss: 2.046019673347473

Epoch: 6| Step: 13
Training loss: 0.9327640533447266
Validation loss: 2.0796213150024414

Epoch: 176| Step: 0
Training loss: 0.6736479997634888
Validation loss: 2.0200491348902383

Epoch: 6| Step: 1
Training loss: 0.6331861019134521
Validation loss: 2.0505831440289817

Epoch: 6| Step: 2
Training loss: 0.3227290213108063
Validation loss: 2.0069074034690857

Epoch: 6| Step: 3
Training loss: 0.3825649619102478
Validation loss: 2.011933187643687

Epoch: 6| Step: 4
Training loss: 0.732917070388794
Validation loss: 2.0440611640612283

Epoch: 6| Step: 5
Training loss: 1.2512941360473633
Validation loss: 2.099199950695038

Epoch: 6| Step: 6
Training loss: 0.48326969146728516
Validation loss: 2.0805068810780845

Epoch: 6| Step: 7
Training loss: 0.9222360849380493
Validation loss: 2.065714339415232

Epoch: 6| Step: 8
Training loss: 0.4925394654273987
Validation loss: 2.070405205090841

Epoch: 6| Step: 9
Training loss: 0.5713271498680115
Validation loss: 2.0212467312812805

Epoch: 6| Step: 10
Training loss: 0.39925044775009155
Validation loss: 2.084436615308126

Epoch: 6| Step: 11
Training loss: 0.9189277291297913
Validation loss: 2.0172037283579507

Epoch: 6| Step: 12
Training loss: 0.5407936573028564
Validation loss: 2.0145325859387717

Epoch: 6| Step: 13
Training loss: 0.5117473602294922
Validation loss: 2.0284364024798074

Epoch: 177| Step: 0
Training loss: 0.4572877287864685
Validation loss: 1.9834928909937541

Epoch: 6| Step: 1
Training loss: 0.7623922824859619
Validation loss: 1.99318132797877

Epoch: 6| Step: 2
Training loss: 0.7154804468154907
Validation loss: 2.0393188198407493

Epoch: 6| Step: 3
Training loss: 0.35475170612335205
Validation loss: 2.045161505540212

Epoch: 6| Step: 4
Training loss: 0.7250331044197083
Validation loss: 2.0108463366826377

Epoch: 6| Step: 5
Training loss: 0.7322605848312378
Validation loss: 2.0407580137252808

Epoch: 6| Step: 6
Training loss: 1.0297799110412598
Validation loss: 2.0137676199277244

Epoch: 6| Step: 7
Training loss: 0.3410055637359619
Validation loss: 2.045582969983419

Epoch: 6| Step: 8
Training loss: 0.20167291164398193
Validation loss: 2.0249269207318625

Epoch: 6| Step: 9
Training loss: 0.729529619216919
Validation loss: 2.069996953010559

Epoch: 6| Step: 10
Training loss: 0.6223156452178955
Validation loss: 2.0689578453699746

Epoch: 6| Step: 11
Training loss: 0.6074873208999634
Validation loss: 1.967909534772237

Epoch: 6| Step: 12
Training loss: 0.28954705595970154
Validation loss: 2.020536780357361

Epoch: 6| Step: 13
Training loss: 1.0013277530670166
Validation loss: 2.015813668568929

Epoch: 178| Step: 0
Training loss: 0.610146164894104
Validation loss: 2.0387287934621177

Epoch: 6| Step: 1
Training loss: 0.4641135036945343
Validation loss: 2.0395649870236716

Epoch: 6| Step: 2
Training loss: 0.8116351962089539
Validation loss: 2.034019331137339

Epoch: 6| Step: 3
Training loss: 0.5497386455535889
Validation loss: 2.0518309473991394

Epoch: 6| Step: 4
Training loss: 0.5123180150985718
Validation loss: 2.0762940446535745

Epoch: 6| Step: 5
Training loss: 0.7514239549636841
Validation loss: 2.0247252583503723

Epoch: 6| Step: 6
Training loss: 0.43044817447662354
Validation loss: 2.070082128047943

Epoch: 6| Step: 7
Training loss: 0.7951611280441284
Validation loss: 2.0529529253641763

Epoch: 6| Step: 8
Training loss: 0.5995863080024719
Validation loss: 2.0521481037139893

Epoch: 6| Step: 9
Training loss: 0.6923996210098267
Validation loss: 2.0322667558987937

Epoch: 6| Step: 10
Training loss: 0.3938926160335541
Validation loss: 2.0278796553611755

Epoch: 6| Step: 11
Training loss: 0.798139214515686
Validation loss: 2.0389248927434287

Epoch: 6| Step: 12
Training loss: 0.7476059198379517
Validation loss: 2.024233023325602

Epoch: 6| Step: 13
Training loss: 0.5020259618759155
Validation loss: 1.9977916479110718

Epoch: 179| Step: 0
Training loss: 0.9137598276138306
Validation loss: 2.0471449891726174

Epoch: 6| Step: 1
Training loss: 0.6994197368621826
Validation loss: 2.0785993933677673

Epoch: 6| Step: 2
Training loss: 0.6984149217605591
Validation loss: 2.0190387964248657

Epoch: 6| Step: 3
Training loss: 0.5201952457427979
Validation loss: 2.0716267228126526

Epoch: 6| Step: 4
Training loss: 0.37630438804626465
Validation loss: 2.029100934664408

Epoch: 6| Step: 5
Training loss: 0.7293564677238464
Validation loss: 2.052028020222982

Epoch: 6| Step: 6
Training loss: 0.5659416913986206
Validation loss: 1.981250246365865

Epoch: 6| Step: 7
Training loss: 0.5475664734840393
Validation loss: 1.9893998702367146

Epoch: 6| Step: 8
Training loss: 0.5894423723220825
Validation loss: 2.0206909775733948

Epoch: 6| Step: 9
Training loss: 0.9577972292900085
Validation loss: 2.0008644262949624

Epoch: 6| Step: 10
Training loss: 0.590031623840332
Validation loss: 2.0181185007095337

Epoch: 6| Step: 11
Training loss: 0.3561486601829529
Validation loss: 2.0430177450180054

Epoch: 6| Step: 12
Training loss: 0.6233302354812622
Validation loss: 2.0950145920117698

Epoch: 6| Step: 13
Training loss: 0.5481147766113281
Validation loss: 2.1099236011505127

Epoch: 180| Step: 0
Training loss: 0.4734821319580078
Validation loss: 2.1005386312802634

Epoch: 6| Step: 1
Training loss: 0.766907274723053
Validation loss: 2.1240923404693604

Epoch: 6| Step: 2
Training loss: 0.639284074306488
Validation loss: 2.0923920472462973

Epoch: 6| Step: 3
Training loss: 0.825209379196167
Validation loss: 2.0386610428492227

Epoch: 6| Step: 4
Training loss: 0.6649974584579468
Validation loss: 2.05404140551885

Epoch: 6| Step: 5
Training loss: 1.2315635681152344
Validation loss: 2.023823320865631

Epoch: 6| Step: 6
Training loss: 0.5428838133811951
Validation loss: 2.013216972351074

Epoch: 6| Step: 7
Training loss: 0.5787756443023682
Validation loss: 2.0621041655540466

Epoch: 6| Step: 8
Training loss: 0.6700639724731445
Validation loss: 2.0433338483174643

Epoch: 6| Step: 9
Training loss: 0.9230930209159851
Validation loss: 2.025667051474253

Epoch: 6| Step: 10
Training loss: 0.40922415256500244
Validation loss: 2.043953776359558

Epoch: 6| Step: 11
Training loss: 0.5148205161094666
Validation loss: 2.05936868985494

Epoch: 6| Step: 12
Training loss: 0.566365122795105
Validation loss: 2.0208788315455117

Epoch: 6| Step: 13
Training loss: 0.4755738377571106
Validation loss: 2.0600748658180237

Epoch: 181| Step: 0
Training loss: 0.7586973309516907
Validation loss: 2.0897274812062583

Epoch: 6| Step: 1
Training loss: 0.688349187374115
Validation loss: 2.0613186955451965

Epoch: 6| Step: 2
Training loss: 0.7462680339813232
Validation loss: 2.041724681854248

Epoch: 6| Step: 3
Training loss: 0.44623270630836487
Validation loss: 2.0883155465126038

Epoch: 6| Step: 4
Training loss: 0.7232381105422974
Validation loss: 2.047063668568929

Epoch: 6| Step: 5
Training loss: 0.8709267377853394
Validation loss: 2.0362831950187683

Epoch: 6| Step: 6
Training loss: 0.4965522885322571
Validation loss: 2.062846859296163

Epoch: 6| Step: 7
Training loss: 0.6510580778121948
Validation loss: 2.0304554104804993

Epoch: 6| Step: 8
Training loss: 0.4915000796318054
Validation loss: 2.039393504460653

Epoch: 6| Step: 9
Training loss: 0.4696577191352844
Validation loss: 2.0685247580210366

Epoch: 6| Step: 10
Training loss: 0.6273750066757202
Validation loss: 2.024444897969564

Epoch: 6| Step: 11
Training loss: 0.3559492230415344
Validation loss: 1.996167242527008

Epoch: 6| Step: 12
Training loss: 0.5262537002563477
Validation loss: 2.041286528110504

Epoch: 6| Step: 13
Training loss: 0.5212575793266296
Validation loss: 2.0860588550567627

Epoch: 182| Step: 0
Training loss: 0.49521514773368835
Validation loss: 2.0178888042767844

Epoch: 6| Step: 1
Training loss: 1.0943050384521484
Validation loss: 2.056013762950897

Epoch: 6| Step: 2
Training loss: 0.533907413482666
Validation loss: 2.0895137588183084

Epoch: 6| Step: 3
Training loss: 1.0041799545288086
Validation loss: 2.047378877798716

Epoch: 6| Step: 4
Training loss: 0.5608108043670654
Validation loss: 1.9879817565282185

Epoch: 6| Step: 5
Training loss: 0.5582492351531982
Validation loss: 1.9976606369018555

Epoch: 6| Step: 6
Training loss: 0.7709025144577026
Validation loss: 2.0416061083475747

Epoch: 6| Step: 7
Training loss: 0.3026794195175171
Validation loss: 2.0188000202178955

Epoch: 6| Step: 8
Training loss: 0.5251668691635132
Validation loss: 2.0144196351369223

Epoch: 6| Step: 9
Training loss: 0.4625515937805176
Validation loss: 1.9991457064946492

Epoch: 6| Step: 10
Training loss: 0.4351420998573303
Validation loss: 2.019043962160746

Epoch: 6| Step: 11
Training loss: 0.5124478340148926
Validation loss: 2.0207500060399375

Epoch: 6| Step: 12
Training loss: 0.605130672454834
Validation loss: 2.029293179512024

Epoch: 6| Step: 13
Training loss: 0.5383313894271851
Validation loss: 2.0175751050313315

Epoch: 183| Step: 0
Training loss: 0.5530750155448914
Validation loss: 2.0319471955299377

Epoch: 6| Step: 1
Training loss: 1.1589620113372803
Validation loss: 2.0322435895601907

Epoch: 6| Step: 2
Training loss: 0.5037314891815186
Validation loss: 2.0134897430737815

Epoch: 6| Step: 3
Training loss: 0.32653722167015076
Validation loss: 2.0361385146776834

Epoch: 6| Step: 4
Training loss: 0.5547610521316528
Validation loss: 2.0355089902877808

Epoch: 6| Step: 5
Training loss: 0.5439722537994385
Validation loss: 1.9906362295150757

Epoch: 6| Step: 6
Training loss: 0.37259307503700256
Validation loss: 2.032720446586609

Epoch: 6| Step: 7
Training loss: 0.7821009755134583
Validation loss: 2.057480792204539

Epoch: 6| Step: 8
Training loss: 0.6896177530288696
Validation loss: 2.0476630330085754

Epoch: 6| Step: 9
Training loss: 0.43067485094070435
Validation loss: 2.0339404940605164

Epoch: 6| Step: 10
Training loss: 0.5431758165359497
Validation loss: 2.05780961116155

Epoch: 6| Step: 11
Training loss: 0.7213442325592041
Validation loss: 2.0431775649388633

Epoch: 6| Step: 12
Training loss: 0.38585662841796875
Validation loss: 2.0283467372258506

Epoch: 6| Step: 13
Training loss: 0.769624650478363
Validation loss: 2.0318026145299277

Epoch: 184| Step: 0
Training loss: 0.8072361946105957
Validation loss: 2.0261189937591553

Epoch: 6| Step: 1
Training loss: 0.4665714502334595
Validation loss: 2.0569284160931907

Epoch: 6| Step: 2
Training loss: 0.7031826972961426
Validation loss: 2.037688374519348

Epoch: 6| Step: 3
Training loss: 0.31700795888900757
Validation loss: 2.101648271083832

Epoch: 6| Step: 4
Training loss: 0.5564888715744019
Validation loss: 2.0198148488998413

Epoch: 6| Step: 5
Training loss: 0.31615984439849854
Validation loss: 2.0228054920832315

Epoch: 6| Step: 6
Training loss: 0.76835697889328
Validation loss: 2.039155066013336

Epoch: 6| Step: 7
Training loss: 0.3387641906738281
Validation loss: 2.0598013599713645

Epoch: 6| Step: 8
Training loss: 0.5796875953674316
Validation loss: 2.069024682044983

Epoch: 6| Step: 9
Training loss: 0.350570946931839
Validation loss: 2.0332034627596536

Epoch: 6| Step: 10
Training loss: 0.8110541105270386
Validation loss: 2.0750612616539

Epoch: 6| Step: 11
Training loss: 0.5551502704620361
Validation loss: 2.0199719071388245

Epoch: 6| Step: 12
Training loss: 0.5376264452934265
Validation loss: 2.0470224817593894

Epoch: 6| Step: 13
Training loss: 0.9612997770309448
Validation loss: 2.02812127272288

Epoch: 185| Step: 0
Training loss: 0.8379942774772644
Validation loss: 2.052379091580709

Epoch: 6| Step: 1
Training loss: 0.38932502269744873
Validation loss: 2.041089038054148

Epoch: 6| Step: 2
Training loss: 0.3370014727115631
Validation loss: 2.051255702972412

Epoch: 6| Step: 3
Training loss: 0.2796952426433563
Validation loss: 2.006689170996348

Epoch: 6| Step: 4
Training loss: 0.34251654148101807
Validation loss: 2.01678337653478

Epoch: 6| Step: 5
Training loss: 0.7749489545822144
Validation loss: 2.065521240234375

Epoch: 6| Step: 6
Training loss: 0.7184485197067261
Validation loss: 2.084055244922638

Epoch: 6| Step: 7
Training loss: 0.5570323467254639
Validation loss: 2.037571589152018

Epoch: 6| Step: 8
Training loss: 0.8006246089935303
Validation loss: 2.014576733112335

Epoch: 6| Step: 9
Training loss: 0.5503746271133423
Validation loss: 2.0279316504796348

Epoch: 6| Step: 10
Training loss: 0.6793646812438965
Validation loss: 2.017810106277466

Epoch: 6| Step: 11
Training loss: 0.5963594913482666
Validation loss: 2.047547221183777

Epoch: 6| Step: 12
Training loss: 0.9161355495452881
Validation loss: 2.0203866163889566

Epoch: 6| Step: 13
Training loss: 0.28540411591529846
Validation loss: 2.005187670389811

Epoch: 186| Step: 0
Training loss: 0.46901774406433105
Validation loss: 2.0250269571940103

Epoch: 6| Step: 1
Training loss: 0.28754571080207825
Validation loss: 2.010491967201233

Epoch: 6| Step: 2
Training loss: 0.44582629203796387
Validation loss: 2.03637957572937

Epoch: 6| Step: 3
Training loss: 0.5326815843582153
Validation loss: 2.0025628805160522

Epoch: 6| Step: 4
Training loss: 0.5302598476409912
Validation loss: 1.9911413391431172

Epoch: 6| Step: 5
Training loss: 0.918269157409668
Validation loss: 2.0416433612505593

Epoch: 6| Step: 6
Training loss: 0.3613109588623047
Validation loss: 2.0787112514177957

Epoch: 6| Step: 7
Training loss: 0.49413883686065674
Validation loss: 2.0236931244532266

Epoch: 6| Step: 8
Training loss: 0.7301562428474426
Validation loss: 2.0184539953867593

Epoch: 6| Step: 9
Training loss: 0.4509160816669464
Validation loss: 2.0048731168111167

Epoch: 6| Step: 10
Training loss: 0.5243223905563354
Validation loss: 2.0542287627855935

Epoch: 6| Step: 11
Training loss: 0.4662999212741852
Validation loss: 2.0125933090845742

Epoch: 6| Step: 12
Training loss: 1.225374460220337
Validation loss: 2.0185723304748535

Epoch: 6| Step: 13
Training loss: 0.49817854166030884
Validation loss: 1.967298448085785

Epoch: 187| Step: 0
Training loss: 0.673440158367157
Validation loss: 2.0299320618311563

Epoch: 6| Step: 1
Training loss: 0.5356703400611877
Validation loss: 2.008286456267039

Epoch: 6| Step: 2
Training loss: 0.7339493632316589
Validation loss: 2.0421312053998313

Epoch: 6| Step: 3
Training loss: 0.5486367344856262
Validation loss: 2.0207252502441406

Epoch: 6| Step: 4
Training loss: 0.6262524724006653
Validation loss: 2.0826887687047324

Epoch: 6| Step: 5
Training loss: 0.8150163888931274
Validation loss: 2.005201578140259

Epoch: 6| Step: 6
Training loss: 0.30570560693740845
Validation loss: 2.0520416696866355

Epoch: 6| Step: 7
Training loss: 0.570237934589386
Validation loss: 2.0322222312291465

Epoch: 6| Step: 8
Training loss: 0.3215785026550293
Validation loss: 2.0287985603014627

Epoch: 6| Step: 9
Training loss: 0.829846978187561
Validation loss: 2.0517868995666504

Epoch: 6| Step: 10
Training loss: 0.35035720467567444
Validation loss: 2.0235544045766196

Epoch: 6| Step: 11
Training loss: 0.5111135244369507
Validation loss: 2.085765520731608

Epoch: 6| Step: 12
Training loss: 0.497742235660553
Validation loss: 2.088444471359253

Epoch: 6| Step: 13
Training loss: 0.5252565145492554
Validation loss: 2.075900693734487

Epoch: 188| Step: 0
Training loss: 0.6106431484222412
Validation loss: 2.011100649833679

Epoch: 6| Step: 1
Training loss: 0.6745358109474182
Validation loss: 2.0130743384361267

Epoch: 6| Step: 2
Training loss: 0.7400047183036804
Validation loss: 2.0421576698621116

Epoch: 6| Step: 3
Training loss: 0.8071858286857605
Validation loss: 1.9827953775723774

Epoch: 6| Step: 4
Training loss: 0.3183969259262085
Validation loss: 2.0042978326479592

Epoch: 6| Step: 5
Training loss: 0.6197500228881836
Validation loss: 2.030782997608185

Epoch: 6| Step: 6
Training loss: 0.5721901059150696
Validation loss: 2.0463640491167703

Epoch: 6| Step: 7
Training loss: 0.2797777056694031
Validation loss: 2.0638787150382996

Epoch: 6| Step: 8
Training loss: 0.7862924933433533
Validation loss: 2.043941875298818

Epoch: 6| Step: 9
Training loss: 0.6997623443603516
Validation loss: 2.0978822310765586

Epoch: 6| Step: 10
Training loss: 0.43135806918144226
Validation loss: 2.058434804280599

Epoch: 6| Step: 11
Training loss: 0.47309327125549316
Validation loss: 2.029748499393463

Epoch: 6| Step: 12
Training loss: 0.6558136343955994
Validation loss: 2.047442078590393

Epoch: 6| Step: 13
Training loss: 0.816584050655365
Validation loss: 2.0375879406929016

Epoch: 189| Step: 0
Training loss: 0.49942708015441895
Validation loss: 2.0433756510416665

Epoch: 6| Step: 1
Training loss: 0.7661872506141663
Validation loss: 2.0412800709406533

Epoch: 6| Step: 2
Training loss: 0.660179853439331
Validation loss: 2.086260517438253

Epoch: 6| Step: 3
Training loss: 0.2952122986316681
Validation loss: 2.0556856393814087

Epoch: 6| Step: 4
Training loss: 0.5318633317947388
Validation loss: 2.0439567963282266

Epoch: 6| Step: 5
Training loss: 0.2624206244945526
Validation loss: 2.039962728818258

Epoch: 6| Step: 6
Training loss: 0.8468573689460754
Validation loss: 2.0397984385490417

Epoch: 6| Step: 7
Training loss: 0.4615095853805542
Validation loss: 1.9986591537793477

Epoch: 6| Step: 8
Training loss: 0.5317785739898682
Validation loss: 2.0449813405672708

Epoch: 6| Step: 9
Training loss: 0.4383503198623657
Validation loss: 2.0198346376419067

Epoch: 6| Step: 10
Training loss: 0.27062690258026123
Validation loss: 2.035772184530894

Epoch: 6| Step: 11
Training loss: 0.47671791911125183
Validation loss: 2.0415502190589905

Epoch: 6| Step: 12
Training loss: 0.8907268047332764
Validation loss: 2.083031396071116

Epoch: 6| Step: 13
Training loss: 0.9152745008468628
Validation loss: 2.0590323209762573

Epoch: 190| Step: 0
Training loss: 0.8025888800621033
Validation loss: 2.0517277121543884

Epoch: 6| Step: 1
Training loss: 0.48114681243896484
Validation loss: 2.046495000521342

Epoch: 6| Step: 2
Training loss: 0.4540925920009613
Validation loss: 2.0140611131985984

Epoch: 6| Step: 3
Training loss: 0.27409079670906067
Validation loss: 2.0637092192967734

Epoch: 6| Step: 4
Training loss: 0.7659491300582886
Validation loss: 2.0543548862139382

Epoch: 6| Step: 5
Training loss: 0.6523700952529907
Validation loss: 2.015350619951884

Epoch: 6| Step: 6
Training loss: 0.27887654304504395
Validation loss: 2.0328545570373535

Epoch: 6| Step: 7
Training loss: 0.3360249400138855
Validation loss: 2.044271926085154

Epoch: 6| Step: 8
Training loss: 0.31113898754119873
Validation loss: 2.0179739395777383

Epoch: 6| Step: 9
Training loss: 0.9268670678138733
Validation loss: 2.06403777996699

Epoch: 6| Step: 10
Training loss: 0.8120594024658203
Validation loss: 2.0034074584643045

Epoch: 6| Step: 11
Training loss: 0.7685220241546631
Validation loss: 2.0334972739219666

Epoch: 6| Step: 12
Training loss: 0.52153480052948
Validation loss: 2.034329613049825

Epoch: 6| Step: 13
Training loss: 0.42717355489730835
Validation loss: 2.0166032910346985

Epoch: 191| Step: 0
Training loss: 0.6041199564933777
Validation loss: 2.0229434172312417

Epoch: 6| Step: 1
Training loss: 0.4723244309425354
Validation loss: 2.031492451826731

Epoch: 6| Step: 2
Training loss: 0.2909546494483948
Validation loss: 2.0647870302200317

Epoch: 6| Step: 3
Training loss: 0.582460343837738
Validation loss: 2.033770442008972

Epoch: 6| Step: 4
Training loss: 0.6370337009429932
Validation loss: 2.024133324623108

Epoch: 6| Step: 5
Training loss: 0.86871737241745
Validation loss: 2.082625925540924

Epoch: 6| Step: 6
Training loss: 0.5588637590408325
Validation loss: 2.0317976474761963

Epoch: 6| Step: 7
Training loss: 0.40858104825019836
Validation loss: 1.9746423761049907

Epoch: 6| Step: 8
Training loss: 0.6847929954528809
Validation loss: 2.011760334173838

Epoch: 6| Step: 9
Training loss: 0.7520480751991272
Validation loss: 1.9748922785123189

Epoch: 6| Step: 10
Training loss: 0.6903977394104004
Validation loss: 2.0324522058169046

Epoch: 6| Step: 11
Training loss: 0.4815918803215027
Validation loss: 2.035954713821411

Epoch: 6| Step: 12
Training loss: 0.5532511472702026
Validation loss: 2.0227298537890115

Epoch: 6| Step: 13
Training loss: 0.4846274256706238
Validation loss: 1.9907171130180359

Epoch: 192| Step: 0
Training loss: 0.4137876331806183
Validation loss: 2.0564709305763245

Epoch: 6| Step: 1
Training loss: 0.48767855763435364
Validation loss: 2.058880031108856

Epoch: 6| Step: 2
Training loss: 0.6787763237953186
Validation loss: 2.023543039957682

Epoch: 6| Step: 3
Training loss: 0.37496840953826904
Validation loss: 1.9942660729090373

Epoch: 6| Step: 4
Training loss: 0.8482359647750854
Validation loss: 2.034337103366852

Epoch: 6| Step: 5
Training loss: 0.5267406105995178
Validation loss: 2.005283077557882

Epoch: 6| Step: 6
Training loss: 0.9272836446762085
Validation loss: 2.0195942322413125

Epoch: 6| Step: 7
Training loss: 0.6271982192993164
Validation loss: 2.03741455078125

Epoch: 6| Step: 8
Training loss: 0.7167924642562866
Validation loss: 2.0601439476013184

Epoch: 6| Step: 9
Training loss: 0.7396889925003052
Validation loss: 2.0316280921300254

Epoch: 6| Step: 10
Training loss: 0.2768222987651825
Validation loss: 2.068099637826284

Epoch: 6| Step: 11
Training loss: 0.49490103125572205
Validation loss: 2.096892476081848

Epoch: 6| Step: 12
Training loss: 0.8030916452407837
Validation loss: 2.111923654874166

Epoch: 6| Step: 13
Training loss: 0.4372691810131073
Validation loss: 2.1196332573890686

Epoch: 193| Step: 0
Training loss: 0.547309398651123
Validation loss: 2.061066150665283

Epoch: 6| Step: 1
Training loss: 0.27497923374176025
Validation loss: 2.035463829835256

Epoch: 6| Step: 2
Training loss: 0.4969886541366577
Validation loss: 2.0287707845369973

Epoch: 6| Step: 3
Training loss: 0.7105261087417603
Validation loss: 2.022616962591807

Epoch: 6| Step: 4
Training loss: 0.4829239249229431
Validation loss: 1.993570605913798

Epoch: 6| Step: 5
Training loss: 0.6025099754333496
Validation loss: 2.0262109438578286

Epoch: 6| Step: 6
Training loss: 0.7269799709320068
Validation loss: 2.0705869595209756

Epoch: 6| Step: 7
Training loss: 0.7500275373458862
Validation loss: 2.059946676095327

Epoch: 6| Step: 8
Training loss: 0.6481641530990601
Validation loss: 2.120098094145457

Epoch: 6| Step: 9
Training loss: 0.6319945454597473
Validation loss: 2.0826656818389893

Epoch: 6| Step: 10
Training loss: 0.7621314525604248
Validation loss: 2.1008951663970947

Epoch: 6| Step: 11
Training loss: 0.785359799861908
Validation loss: 2.023744304974874

Epoch: 6| Step: 12
Training loss: 0.7049599885940552
Validation loss: 2.0710665782292685

Epoch: 6| Step: 13
Training loss: 0.4801669120788574
Validation loss: 2.0680299003918967

Epoch: 194| Step: 0
Training loss: 0.8033478260040283
Validation loss: 2.025479733943939

Epoch: 6| Step: 1
Training loss: 0.255607932806015
Validation loss: 2.0194725394248962

Epoch: 6| Step: 2
Training loss: 1.0440161228179932
Validation loss: 2.0042903224627175

Epoch: 6| Step: 3
Training loss: 0.6240792274475098
Validation loss: 2.006171147028605

Epoch: 6| Step: 4
Training loss: 0.4432520866394043
Validation loss: 2.027875065803528

Epoch: 6| Step: 5
Training loss: 0.5734110474586487
Validation loss: 2.0567438999811807

Epoch: 6| Step: 6
Training loss: 0.5730319023132324
Validation loss: 2.0201313694318137

Epoch: 6| Step: 7
Training loss: 0.51734459400177
Validation loss: 2.0032862424850464

Epoch: 6| Step: 8
Training loss: 0.5760802030563354
Validation loss: 2.0421383380889893

Epoch: 6| Step: 9
Training loss: 0.4155358374118805
Validation loss: 2.056231657663981

Epoch: 6| Step: 10
Training loss: 0.2619592547416687
Validation loss: 2.04539688428243

Epoch: 6| Step: 11
Training loss: 0.6306002736091614
Validation loss: 2.0445772210756936

Epoch: 6| Step: 12
Training loss: 0.5259668231010437
Validation loss: 2.047602812449137

Epoch: 6| Step: 13
Training loss: 0.49731284379959106
Validation loss: 2.006271322568258

Epoch: 195| Step: 0
Training loss: 0.7272053956985474
Validation loss: 2.0083322525024414

Epoch: 6| Step: 1
Training loss: 0.44726449251174927
Validation loss: 2.009998063246409

Epoch: 6| Step: 2
Training loss: 0.6317282915115356
Validation loss: 1.947437326113383

Epoch: 6| Step: 3
Training loss: 0.5920571088790894
Validation loss: 1.9974993864695232

Epoch: 6| Step: 4
Training loss: 0.7517843246459961
Validation loss: 2.0336350202560425

Epoch: 6| Step: 5
Training loss: 0.4748063385486603
Validation loss: 1.9852563738822937

Epoch: 6| Step: 6
Training loss: 0.96856290102005
Validation loss: 2.016058166821798

Epoch: 6| Step: 7
Training loss: 0.27425605058670044
Validation loss: 2.033897658189138

Epoch: 6| Step: 8
Training loss: 0.6567391753196716
Validation loss: 1.9727722605069478

Epoch: 6| Step: 9
Training loss: 0.4820743501186371
Validation loss: 2.0470173756281533

Epoch: 6| Step: 10
Training loss: 0.42007583379745483
Validation loss: 2.0246583819389343

Epoch: 6| Step: 11
Training loss: 0.40147465467453003
Validation loss: 2.0125548044840493

Epoch: 6| Step: 12
Training loss: 0.3803977072238922
Validation loss: 2.0412673950195312

Epoch: 6| Step: 13
Training loss: 0.5864794254302979
Validation loss: 2.0227773984273276

Epoch: 196| Step: 0
Training loss: 0.5305377244949341
Validation loss: 1.9987068176269531

Epoch: 6| Step: 1
Training loss: 0.5731703042984009
Validation loss: 2.0330963929494223

Epoch: 6| Step: 2
Training loss: 0.39382585883140564
Validation loss: 1.997818926970164

Epoch: 6| Step: 3
Training loss: 0.2609955668449402
Validation loss: 2.025088369846344

Epoch: 6| Step: 4
Training loss: 0.2646830677986145
Validation loss: 1.9964275360107422

Epoch: 6| Step: 5
Training loss: 0.8573171496391296
Validation loss: 2.037619113922119

Epoch: 6| Step: 6
Training loss: 0.331914484500885
Validation loss: 2.012522498766581

Epoch: 6| Step: 7
Training loss: 0.8287806510925293
Validation loss: 2.0432928999265036

Epoch: 6| Step: 8
Training loss: 0.8408039808273315
Validation loss: 1.9845292369524639

Epoch: 6| Step: 9
Training loss: 0.3494911789894104
Validation loss: 2.0346823930740356

Epoch: 6| Step: 10
Training loss: 0.40648889541625977
Validation loss: 1.9816235303878784

Epoch: 6| Step: 11
Training loss: 0.5497710704803467
Validation loss: 2.0817741751670837

Epoch: 6| Step: 12
Training loss: 0.4640413522720337
Validation loss: 2.0327661633491516

Epoch: 6| Step: 13
Training loss: 0.6854864358901978
Validation loss: 2.0741899410883584

Epoch: 197| Step: 0
Training loss: 0.36530062556266785
Validation loss: 2.066276033719381

Epoch: 6| Step: 1
Training loss: 0.6728639602661133
Validation loss: 2.0640251636505127

Epoch: 6| Step: 2
Training loss: 0.5383234024047852
Validation loss: 2.0174513260523477

Epoch: 6| Step: 3
Training loss: 0.39880800247192383
Validation loss: 2.058946112791697

Epoch: 6| Step: 4
Training loss: 0.4657309055328369
Validation loss: 2.0294434229532876

Epoch: 6| Step: 5
Training loss: 0.6971961855888367
Validation loss: 2.0454049905141196

Epoch: 6| Step: 6
Training loss: 0.3835737109184265
Validation loss: 2.048765023549398

Epoch: 6| Step: 7
Training loss: 0.49714961647987366
Validation loss: 2.065757393836975

Epoch: 6| Step: 8
Training loss: 0.2629845142364502
Validation loss: 2.068470279375712

Epoch: 6| Step: 9
Training loss: 0.4465514123439789
Validation loss: 2.085907200972239

Epoch: 6| Step: 10
Training loss: 0.8510892391204834
Validation loss: 2.0435754458109536

Epoch: 6| Step: 11
Training loss: 0.9093878269195557
Validation loss: 2.009587744871775

Epoch: 6| Step: 12
Training loss: 0.531627357006073
Validation loss: 2.0101778507232666

Epoch: 6| Step: 13
Training loss: 0.6544495820999146
Validation loss: 2.05434517065684

Epoch: 198| Step: 0
Training loss: 0.4309025704860687
Validation loss: 2.001867731412252

Epoch: 6| Step: 1
Training loss: 0.27374595403671265
Validation loss: 2.0262383619944253

Epoch: 6| Step: 2
Training loss: 0.5658900737762451
Validation loss: 2.054109533627828

Epoch: 6| Step: 3
Training loss: 0.7671505212783813
Validation loss: 2.042192836602529

Epoch: 6| Step: 4
Training loss: 0.912142276763916
Validation loss: 2.0487209359804788

Epoch: 6| Step: 5
Training loss: 0.860747218132019
Validation loss: 2.0674596230189004

Epoch: 6| Step: 6
Training loss: 0.2714868187904358
Validation loss: 2.0632294019063315

Epoch: 6| Step: 7
Training loss: 0.37441879510879517
Validation loss: 2.0604456067085266

Epoch: 6| Step: 8
Training loss: 0.40717005729675293
Validation loss: 1.9968770146369934

Epoch: 6| Step: 9
Training loss: 0.5207390785217285
Validation loss: 2.0070722699165344

Epoch: 6| Step: 10
Training loss: 0.472307026386261
Validation loss: 2.0384103655815125

Epoch: 6| Step: 11
Training loss: 0.2712746262550354
Validation loss: 1.987332244714101

Epoch: 6| Step: 12
Training loss: 0.4837300479412079
Validation loss: 2.047697981198629

Epoch: 6| Step: 13
Training loss: 0.8184647560119629
Validation loss: 2.048791289329529

Epoch: 199| Step: 0
Training loss: 0.4073276221752167
Validation loss: 2.0358355244000754

Epoch: 6| Step: 1
Training loss: 1.0113444328308105
Validation loss: 2.0382613142331443

Epoch: 6| Step: 2
Training loss: 0.553386390209198
Validation loss: 2.049941341082255

Epoch: 6| Step: 3
Training loss: 0.5595461130142212
Validation loss: 2.0536224246025085

Epoch: 6| Step: 4
Training loss: 0.4476519823074341
Validation loss: 2.0448774894078574

Epoch: 6| Step: 5
Training loss: 0.5293745994567871
Validation loss: 2.049183448155721

Epoch: 6| Step: 6
Training loss: 0.5104221105575562
Validation loss: 2.0641674399375916

Epoch: 6| Step: 7
Training loss: 0.6905651688575745
Validation loss: 2.0510833263397217

Epoch: 6| Step: 8
Training loss: 0.3186553418636322
Validation loss: 2.020068426926931

Epoch: 6| Step: 9
Training loss: 0.3498304486274719
Validation loss: 2.086476484934489

Epoch: 6| Step: 10
Training loss: 0.22921663522720337
Validation loss: 2.0128252704938254

Epoch: 6| Step: 11
Training loss: 0.4407827854156494
Validation loss: 2.05082372824351

Epoch: 6| Step: 12
Training loss: 0.48696333169937134
Validation loss: 2.0372407833735147

Epoch: 6| Step: 13
Training loss: 0.7004355192184448
Validation loss: 2.050507664680481

Epoch: 200| Step: 0
Training loss: 0.7040877342224121
Validation loss: 2.079480608304342

Epoch: 6| Step: 1
Training loss: 0.602249026298523
Validation loss: 2.0519361893335977

Epoch: 6| Step: 2
Training loss: 0.4974575936794281
Validation loss: 1.9838529030481975

Epoch: 6| Step: 3
Training loss: 0.46862223744392395
Validation loss: 2.066492756207784

Epoch: 6| Step: 4
Training loss: 0.7701516151428223
Validation loss: 1.9970823526382446

Epoch: 6| Step: 5
Training loss: 0.4413006007671356
Validation loss: 1.9618401527404785

Epoch: 6| Step: 6
Training loss: 0.5780287981033325
Validation loss: 2.0469746589660645

Epoch: 6| Step: 7
Training loss: 0.544560432434082
Validation loss: 2.0312244097391763

Epoch: 6| Step: 8
Training loss: 0.43637049198150635
Validation loss: 2.045746922492981

Epoch: 6| Step: 9
Training loss: 0.595359206199646
Validation loss: 2.059942086537679

Epoch: 6| Step: 10
Training loss: 0.4324938654899597
Validation loss: 2.068954328695933

Epoch: 6| Step: 11
Training loss: 0.6096010208129883
Validation loss: 2.085770308971405

Epoch: 6| Step: 12
Training loss: 0.352927029132843
Validation loss: 2.0608932177225747

Epoch: 6| Step: 13
Training loss: 0.3340269923210144
Validation loss: 2.070954918861389

Epoch: 201| Step: 0
Training loss: 0.2320242077112198
Validation loss: 2.0008562008539834

Epoch: 6| Step: 1
Training loss: 0.4270554780960083
Validation loss: 2.0542914668718972

Epoch: 6| Step: 2
Training loss: 0.43091434240341187
Validation loss: 2.0631392002105713

Epoch: 6| Step: 3
Training loss: 0.9180831909179688
Validation loss: 2.07548588514328

Epoch: 6| Step: 4
Training loss: 0.42789268493652344
Validation loss: 2.043174088001251

Epoch: 6| Step: 5
Training loss: 0.6300796270370483
Validation loss: 2.022999405860901

Epoch: 6| Step: 6
Training loss: 0.4729596972465515
Validation loss: 2.047197620073954

Epoch: 6| Step: 7
Training loss: 0.4715195596218109
Validation loss: 2.010057290395101

Epoch: 6| Step: 8
Training loss: 0.6234011054039001
Validation loss: 2.0248741706212363

Epoch: 6| Step: 9
Training loss: 0.47892236709594727
Validation loss: 2.018170336882273

Epoch: 6| Step: 10
Training loss: 0.48298531770706177
Validation loss: 2.0153425534566245

Epoch: 6| Step: 11
Training loss: 0.683037519454956
Validation loss: 2.0582976738611856

Epoch: 6| Step: 12
Training loss: 0.42088210582733154
Validation loss: 2.049381752808889

Epoch: 6| Step: 13
Training loss: 0.43574291467666626
Validation loss: 1.9925982356071472

Epoch: 202| Step: 0
Training loss: 0.33362215757369995
Validation loss: 2.0619290868441262

Epoch: 6| Step: 1
Training loss: 0.4533628821372986
Validation loss: 2.0450857679049173

Epoch: 6| Step: 2
Training loss: 0.5386364459991455
Validation loss: 2.0453809102376304

Epoch: 6| Step: 3
Training loss: 0.42431920766830444
Validation loss: 1.986754556496938

Epoch: 6| Step: 4
Training loss: 0.5934048295021057
Validation loss: 2.0590948263804116

Epoch: 6| Step: 5
Training loss: 0.252109169960022
Validation loss: 2.051166832447052

Epoch: 6| Step: 6
Training loss: 0.2765176296234131
Validation loss: 2.0548741618792215

Epoch: 6| Step: 7
Training loss: 0.6479619741439819
Validation loss: 1.9858644008636475

Epoch: 6| Step: 8
Training loss: 0.4682215750217438
Validation loss: 2.0202582279841104

Epoch: 6| Step: 9
Training loss: 0.850753664970398
Validation loss: 2.0301500360171

Epoch: 6| Step: 10
Training loss: 0.6740905046463013
Validation loss: 1.9863690336545308

Epoch: 6| Step: 11
Training loss: 0.46677741408348083
Validation loss: 1.9991557399431865

Epoch: 6| Step: 12
Training loss: 0.5652393102645874
Validation loss: 2.0134832660357156

Epoch: 6| Step: 13
Training loss: 0.5464837551116943
Validation loss: 2.0070848862330117

Epoch: 203| Step: 0
Training loss: 1.1299608945846558
Validation loss: 2.045443614323934

Epoch: 6| Step: 1
Training loss: 0.37579309940338135
Validation loss: 2.0342791279157004

Epoch: 6| Step: 2
Training loss: 0.33850520849227905
Validation loss: 2.035351832707723

Epoch: 6| Step: 3
Training loss: 0.6106202602386475
Validation loss: 2.0453834931055703

Epoch: 6| Step: 4
Training loss: 0.5981707572937012
Validation loss: 2.0428683757781982

Epoch: 6| Step: 5
Training loss: 0.4245552718639374
Validation loss: 2.009757916132609

Epoch: 6| Step: 6
Training loss: 0.6929113864898682
Validation loss: 1.9427196582158406

Epoch: 6| Step: 7
Training loss: 0.9241002798080444
Validation loss: 2.0422824223836265

Epoch: 6| Step: 8
Training loss: 0.41866379976272583
Validation loss: 1.9982147415479024

Epoch: 6| Step: 9
Training loss: 0.7656553983688354
Validation loss: 2.0052186250686646

Epoch: 6| Step: 10
Training loss: 0.1881682425737381
Validation loss: 2.0074734886487327

Epoch: 6| Step: 11
Training loss: 0.301807701587677
Validation loss: 2.0180963277816772

Epoch: 6| Step: 12
Training loss: 0.38845598697662354
Validation loss: 2.011232237021128

Epoch: 6| Step: 13
Training loss: 0.34955811500549316
Validation loss: 2.0286482771237693

Epoch: 204| Step: 0
Training loss: 0.37772834300994873
Validation loss: 2.0570520162582397

Epoch: 6| Step: 1
Training loss: 0.3598323464393616
Validation loss: 2.0441247622172036

Epoch: 6| Step: 2
Training loss: 0.8390809893608093
Validation loss: 2.0101915200551352

Epoch: 6| Step: 3
Training loss: 0.758776843547821
Validation loss: 2.000932276248932

Epoch: 6| Step: 4
Training loss: 0.810491681098938
Validation loss: 1.9878771503766377

Epoch: 6| Step: 5
Training loss: 0.8242722749710083
Validation loss: 2.0311055779457092

Epoch: 6| Step: 6
Training loss: 0.7414581179618835
Validation loss: 2.0448531905810037

Epoch: 6| Step: 7
Training loss: 0.3235226571559906
Validation loss: 2.0152607560157776

Epoch: 6| Step: 8
Training loss: 0.35811543464660645
Validation loss: 2.033616761366526

Epoch: 6| Step: 9
Training loss: 0.525836169719696
Validation loss: 2.073576112588247

Epoch: 6| Step: 10
Training loss: 0.45991435647010803
Validation loss: 2.069577991962433

Epoch: 6| Step: 11
Training loss: 0.6011537909507751
Validation loss: 2.0439408222834268

Epoch: 6| Step: 12
Training loss: 0.20681685209274292
Validation loss: 2.091564158598582

Epoch: 6| Step: 13
Training loss: 0.4380505383014679
Validation loss: 2.041151742140452

Epoch: 205| Step: 0
Training loss: 0.5406166315078735
Validation loss: 2.0238967339197793

Epoch: 6| Step: 1
Training loss: 0.24212776124477386
Validation loss: 2.024512688318888

Epoch: 6| Step: 2
Training loss: 0.48328572511672974
Validation loss: 2.013533135255178

Epoch: 6| Step: 3
Training loss: 0.6480092406272888
Validation loss: 2.023194889227549

Epoch: 6| Step: 4
Training loss: 0.4839879274368286
Validation loss: 1.9904548327128093

Epoch: 6| Step: 5
Training loss: 0.6196101307868958
Validation loss: 2.056262989838918

Epoch: 6| Step: 6
Training loss: 0.2750281095504761
Validation loss: 2.0218307773272195

Epoch: 6| Step: 7
Training loss: 0.8108338117599487
Validation loss: 2.0537596344947815

Epoch: 6| Step: 8
Training loss: 0.9809778332710266
Validation loss: 2.0327733755111694

Epoch: 6| Step: 9
Training loss: 0.3400944471359253
Validation loss: 2.004377086957296

Epoch: 6| Step: 10
Training loss: 0.5822705030441284
Validation loss: 1.9965412815411885

Epoch: 6| Step: 11
Training loss: 0.39342355728149414
Validation loss: 2.1042389074961343

Epoch: 6| Step: 12
Training loss: 0.4371132552623749
Validation loss: 2.0117851893107095

Epoch: 6| Step: 13
Training loss: 0.42323821783065796
Validation loss: 2.0141441226005554

Epoch: 206| Step: 0
Training loss: 0.21485458314418793
Validation loss: 2.0019174019495645

Epoch: 6| Step: 1
Training loss: 0.7809184789657593
Validation loss: 2.0673042933146157

Epoch: 6| Step: 2
Training loss: 0.49639615416526794
Validation loss: 2.0345520973205566

Epoch: 6| Step: 3
Training loss: 0.8691729307174683
Validation loss: 2.030284881591797

Epoch: 6| Step: 4
Training loss: 0.501095175743103
Validation loss: 2.009973188241323

Epoch: 6| Step: 5
Training loss: 0.6904195547103882
Validation loss: 2.0058401028315225

Epoch: 6| Step: 6
Training loss: 0.26722684502601624
Validation loss: 2.0477007627487183

Epoch: 6| Step: 7
Training loss: 0.29758307337760925
Validation loss: 2.0154088934262595

Epoch: 6| Step: 8
Training loss: 0.41910165548324585
Validation loss: 2.0254894892374673

Epoch: 6| Step: 9
Training loss: 0.45621517300605774
Validation loss: 2.0453575452168784

Epoch: 6| Step: 10
Training loss: 0.4859991669654846
Validation loss: 2.005184054374695

Epoch: 6| Step: 11
Training loss: 0.6733989715576172
Validation loss: 2.035654366016388

Epoch: 6| Step: 12
Training loss: 0.5309107303619385
Validation loss: 2.030326763788859

Epoch: 6| Step: 13
Training loss: 0.496750146150589
Validation loss: 2.02117927869161

Epoch: 207| Step: 0
Training loss: 0.5281850099563599
Validation loss: 1.9984643459320068

Epoch: 6| Step: 1
Training loss: 0.4158641993999481
Validation loss: 1.9816249012947083

Epoch: 6| Step: 2
Training loss: 0.23159022629261017
Validation loss: 1.990247944990794

Epoch: 6| Step: 3
Training loss: 0.3424868583679199
Validation loss: 2.001767377058665

Epoch: 6| Step: 4
Training loss: 0.6083555221557617
Validation loss: 2.00460547208786

Epoch: 6| Step: 5
Training loss: 0.5348759293556213
Validation loss: 2.033167759577433

Epoch: 6| Step: 6
Training loss: 0.509253203868866
Validation loss: 1.999098499615987

Epoch: 6| Step: 7
Training loss: 0.6680585145950317
Validation loss: 2.019924283027649

Epoch: 6| Step: 8
Training loss: 0.3929774761199951
Validation loss: 2.0140228271484375

Epoch: 6| Step: 9
Training loss: 0.3958738446235657
Validation loss: 2.0369452039400735

Epoch: 6| Step: 10
Training loss: 0.7478452920913696
Validation loss: 2.0161985556284585

Epoch: 6| Step: 11
Training loss: 0.4150596261024475
Validation loss: 2.009057641029358

Epoch: 6| Step: 12
Training loss: 0.7365627884864807
Validation loss: 1.979427735010783

Epoch: 6| Step: 13
Training loss: 0.6965134739875793
Validation loss: 2.0286749601364136

Epoch: 208| Step: 0
Training loss: 0.5836529731750488
Validation loss: 2.0505639910697937

Epoch: 6| Step: 1
Training loss: 0.26171523332595825
Validation loss: 2.0078227519989014

Epoch: 6| Step: 2
Training loss: 0.5389828681945801
Validation loss: 2.0191414753595986

Epoch: 6| Step: 3
Training loss: 0.5040804147720337
Validation loss: 2.0687987009684243

Epoch: 6| Step: 4
Training loss: 0.5689395666122437
Validation loss: 2.0548597971598306

Epoch: 6| Step: 5
Training loss: 0.5730631351470947
Validation loss: 2.0075818300247192

Epoch: 6| Step: 6
Training loss: 0.28896164894104004
Validation loss: 2.0985692739486694

Epoch: 6| Step: 7
Training loss: 0.5024659037590027
Validation loss: 2.0256791710853577

Epoch: 6| Step: 8
Training loss: 0.3741638660430908
Validation loss: 2.047065019607544

Epoch: 6| Step: 9
Training loss: 0.5116616487503052
Validation loss: 2.0146265625953674

Epoch: 6| Step: 10
Training loss: 0.38355523347854614
Validation loss: 2.0000731348991394

Epoch: 6| Step: 11
Training loss: 0.634141206741333
Validation loss: 2.056233028570811

Epoch: 6| Step: 12
Training loss: 0.35211920738220215
Validation loss: 2.057800531387329

Epoch: 6| Step: 13
Training loss: 0.786880612373352
Validation loss: 2.00606906414032

Epoch: 209| Step: 0
Training loss: 0.4135892391204834
Validation loss: 2.027089615662893

Epoch: 6| Step: 1
Training loss: 0.6909774541854858
Validation loss: 2.1312788327534995

Epoch: 6| Step: 2
Training loss: 0.7851748466491699
Validation loss: 2.054414610068003

Epoch: 6| Step: 3
Training loss: 0.3681347966194153
Validation loss: 2.080768585205078

Epoch: 6| Step: 4
Training loss: 0.40268397331237793
Validation loss: 2.104694684346517

Epoch: 6| Step: 5
Training loss: 0.5387537479400635
Validation loss: 1.994548221429189

Epoch: 6| Step: 6
Training loss: 0.6786674857139587
Validation loss: 2.062743663787842

Epoch: 6| Step: 7
Training loss: 0.23286394774913788
Validation loss: 2.0230981906255088

Epoch: 6| Step: 8
Training loss: 0.2773534059524536
Validation loss: 2.067288259665171

Epoch: 6| Step: 9
Training loss: 0.4673142433166504
Validation loss: 2.0585983991622925

Epoch: 6| Step: 10
Training loss: 0.2299124300479889
Validation loss: 2.0602641701698303

Epoch: 6| Step: 11
Training loss: 0.6243441104888916
Validation loss: 1.9998961885770161

Epoch: 6| Step: 12
Training loss: 0.713686466217041
Validation loss: 1.990489423274994

Epoch: 6| Step: 13
Training loss: 0.551196277141571
Validation loss: 2.05866676568985

Epoch: 210| Step: 0
Training loss: 0.5060403943061829
Validation loss: 2.102349321047465

Epoch: 6| Step: 1
Training loss: 0.540902853012085
Validation loss: 2.0564058025678

Epoch: 6| Step: 2
Training loss: 0.6336749792098999
Validation loss: 2.0272309382756553

Epoch: 6| Step: 3
Training loss: 0.5282169580459595
Validation loss: 2.0222317377726235

Epoch: 6| Step: 4
Training loss: 0.5312172770500183
Validation loss: 2.0712600549062095

Epoch: 6| Step: 5
Training loss: 0.5650595426559448
Validation loss: 2.0766365925470986

Epoch: 6| Step: 6
Training loss: 0.5196492671966553
Validation loss: 2.032733897368113

Epoch: 6| Step: 7
Training loss: 0.46374207735061646
Validation loss: 2.0310510993003845

Epoch: 6| Step: 8
Training loss: 0.34245535731315613
Validation loss: 2.025983194510142

Epoch: 6| Step: 9
Training loss: 0.3360784649848938
Validation loss: 2.020542840162913

Epoch: 6| Step: 10
Training loss: 0.5486589670181274
Validation loss: 2.0213828682899475

Epoch: 6| Step: 11
Training loss: 0.24620017409324646
Validation loss: 2.0575839281082153

Epoch: 6| Step: 12
Training loss: 0.6167250275611877
Validation loss: 2.0682944854100547

Epoch: 6| Step: 13
Training loss: 0.414835661649704
Validation loss: 2.03706818819046

Epoch: 211| Step: 0
Training loss: 0.4093021750450134
Validation loss: 2.039602259794871

Epoch: 6| Step: 1
Training loss: 0.3726695477962494
Validation loss: 2.03231414159139

Epoch: 6| Step: 2
Training loss: 0.6686729788780212
Validation loss: 2.028019924958547

Epoch: 6| Step: 3
Training loss: 0.20918646454811096
Validation loss: 2.0110873579978943

Epoch: 6| Step: 4
Training loss: 0.5026131868362427
Validation loss: 2.0249284903208413

Epoch: 6| Step: 5
Training loss: 0.510421633720398
Validation loss: 1.978546400864919

Epoch: 6| Step: 6
Training loss: 0.4383876919746399
Validation loss: 2.0398149887720742

Epoch: 6| Step: 7
Training loss: 0.645010769367218
Validation loss: 2.030348320802053

Epoch: 6| Step: 8
Training loss: 1.1091465950012207
Validation loss: 2.048068881034851

Epoch: 6| Step: 9
Training loss: 0.3482547700405121
Validation loss: 2.051332414150238

Epoch: 6| Step: 10
Training loss: 0.3714424669742584
Validation loss: 2.0410794019699097

Epoch: 6| Step: 11
Training loss: 0.5971431136131287
Validation loss: 2.0380165576934814

Epoch: 6| Step: 12
Training loss: 0.7140820026397705
Validation loss: 2.0320757627487183

Epoch: 6| Step: 13
Training loss: 0.3549874722957611
Validation loss: 2.046708067258199

Epoch: 212| Step: 0
Training loss: 0.8196449279785156
Validation loss: 2.044914404551188

Epoch: 6| Step: 1
Training loss: 0.6448574066162109
Validation loss: 2.0923839608828225

Epoch: 6| Step: 2
Training loss: 0.580722451210022
Validation loss: 1.9525947173436482

Epoch: 6| Step: 3
Training loss: 0.5904958248138428
Validation loss: 2.033499320348104

Epoch: 6| Step: 4
Training loss: 0.3875617980957031
Validation loss: 2.047746260960897

Epoch: 6| Step: 5
Training loss: 0.3935234546661377
Validation loss: 2.061972498893738

Epoch: 6| Step: 6
Training loss: 0.2798945903778076
Validation loss: 2.0353511373202005

Epoch: 6| Step: 7
Training loss: 0.4939398765563965
Validation loss: 2.0517667134602866

Epoch: 6| Step: 8
Training loss: 0.36996185779571533
Validation loss: 2.0528214971224465

Epoch: 6| Step: 9
Training loss: 0.9866883754730225
Validation loss: 2.0562057296435037

Epoch: 6| Step: 10
Training loss: 0.5751229524612427
Validation loss: 2.037143051624298

Epoch: 6| Step: 11
Training loss: 0.36471986770629883
Validation loss: 2.085487643877665

Epoch: 6| Step: 12
Training loss: 0.23575498163700104
Validation loss: 2.0322837432225547

Epoch: 6| Step: 13
Training loss: 0.2869480550289154
Validation loss: 1.9998683333396912

Epoch: 213| Step: 0
Training loss: 0.5551273822784424
Validation loss: 2.015765070915222

Epoch: 6| Step: 1
Training loss: 0.4846253991127014
Validation loss: 2.0475544134775796

Epoch: 6| Step: 2
Training loss: 0.34750574827194214
Validation loss: 2.0700008074442544

Epoch: 6| Step: 3
Training loss: 0.5374698638916016
Validation loss: 2.115072766939799

Epoch: 6| Step: 4
Training loss: 0.3219551146030426
Validation loss: 2.095476984977722

Epoch: 6| Step: 5
Training loss: 0.688946008682251
Validation loss: 2.0949021180470786

Epoch: 6| Step: 6
Training loss: 0.4937627911567688
Validation loss: 2.043881436189016

Epoch: 6| Step: 7
Training loss: 0.25984662771224976
Validation loss: 2.05166765054067

Epoch: 6| Step: 8
Training loss: 0.34204423427581787
Validation loss: 2.0404901107152305

Epoch: 6| Step: 9
Training loss: 0.642114520072937
Validation loss: 2.024824341138204

Epoch: 6| Step: 10
Training loss: 0.6689397096633911
Validation loss: 2.064749558766683

Epoch: 6| Step: 11
Training loss: 1.1187992095947266
Validation loss: 2.016406456629435

Epoch: 6| Step: 12
Training loss: 0.29446929693222046
Validation loss: 2.0380898316701255

Epoch: 6| Step: 13
Training loss: 0.4353436827659607
Validation loss: 2.0413475831349692

Epoch: 214| Step: 0
Training loss: 0.5794492363929749
Validation loss: 2.000903149445852

Epoch: 6| Step: 1
Training loss: 0.9176477789878845
Validation loss: 2.0371369123458862

Epoch: 6| Step: 2
Training loss: 0.35865622758865356
Validation loss: 2.028814514478048

Epoch: 6| Step: 3
Training loss: 0.3853224515914917
Validation loss: 2.0510136087735495

Epoch: 6| Step: 4
Training loss: 0.28443974256515503
Validation loss: 2.0467150807380676

Epoch: 6| Step: 5
Training loss: 0.39148858189582825
Validation loss: 2.0753005146980286

Epoch: 6| Step: 6
Training loss: 0.46033430099487305
Validation loss: 2.0443870027860007

Epoch: 6| Step: 7
Training loss: 0.2907940745353699
Validation loss: 2.0519297122955322

Epoch: 6| Step: 8
Training loss: 0.48891258239746094
Validation loss: 2.008249501387278

Epoch: 6| Step: 9
Training loss: 0.6053234934806824
Validation loss: 2.0771596233050027

Epoch: 6| Step: 10
Training loss: 0.4190780520439148
Validation loss: 2.0528255303700766

Epoch: 6| Step: 11
Training loss: 0.37804603576660156
Validation loss: 2.055409014225006

Epoch: 6| Step: 12
Training loss: 0.39646464586257935
Validation loss: 2.064694901307424

Epoch: 6| Step: 13
Training loss: 0.5291628837585449
Validation loss: 2.0136140982309976

Epoch: 215| Step: 0
Training loss: 0.248856782913208
Validation loss: 1.9861493110656738

Epoch: 6| Step: 1
Training loss: 0.65423184633255
Validation loss: 2.0486265222231546

Epoch: 6| Step: 2
Training loss: 0.2689601182937622
Validation loss: 1.991074562072754

Epoch: 6| Step: 3
Training loss: 0.39198440313339233
Validation loss: 2.0224440892537436

Epoch: 6| Step: 4
Training loss: 0.21928521990776062
Validation loss: 1.9983468254407246

Epoch: 6| Step: 5
Training loss: 0.5621367692947388
Validation loss: 2.04069717725118

Epoch: 6| Step: 6
Training loss: 0.31611889600753784
Validation loss: 2.0312508742014566

Epoch: 6| Step: 7
Training loss: 0.35014742612838745
Validation loss: 2.0831324259440103

Epoch: 6| Step: 8
Training loss: 0.8803242444992065
Validation loss: 2.0536476174990335

Epoch: 6| Step: 9
Training loss: 0.7341641783714294
Validation loss: 2.1042098800341287

Epoch: 6| Step: 10
Training loss: 0.22520364820957184
Validation loss: 2.0150382121404014

Epoch: 6| Step: 11
Training loss: 0.4974508285522461
Validation loss: 2.1161916851997375

Epoch: 6| Step: 12
Training loss: 0.4947085976600647
Validation loss: 2.0894830226898193

Epoch: 6| Step: 13
Training loss: 0.45870348811149597
Validation loss: 2.0360297163327536

Epoch: 216| Step: 0
Training loss: 0.2648668885231018
Validation loss: 2.0823811491330466

Epoch: 6| Step: 1
Training loss: 0.4909256398677826
Validation loss: 2.061860203742981

Epoch: 6| Step: 2
Training loss: 0.5036439895629883
Validation loss: 2.0724196434020996

Epoch: 6| Step: 3
Training loss: 0.5408253073692322
Validation loss: 2.0253958900769553

Epoch: 6| Step: 4
Training loss: 0.45357322692871094
Validation loss: 2.0549177726109824

Epoch: 6| Step: 5
Training loss: 0.21072375774383545
Validation loss: 2.0408872763315835

Epoch: 6| Step: 6
Training loss: 0.5411043167114258
Validation loss: 2.0488531589508057

Epoch: 6| Step: 7
Training loss: 0.24618493020534515
Validation loss: 2.0287353793780007

Epoch: 6| Step: 8
Training loss: 0.6713911294937134
Validation loss: 2.0353441635767617

Epoch: 6| Step: 9
Training loss: 0.26376014947891235
Validation loss: 2.0525214274724326

Epoch: 6| Step: 10
Training loss: 0.6437015533447266
Validation loss: 2.009665787220001

Epoch: 6| Step: 11
Training loss: 0.8278168439865112
Validation loss: 2.0059192379315696

Epoch: 6| Step: 12
Training loss: 0.395846962928772
Validation loss: 2.017059008280436

Epoch: 6| Step: 13
Training loss: 0.5527422428131104
Validation loss: 2.023434658845266

Epoch: 217| Step: 0
Training loss: 0.4591735005378723
Validation loss: 2.001090089480082

Epoch: 6| Step: 1
Training loss: 0.369751513004303
Validation loss: 1.997011959552765

Epoch: 6| Step: 2
Training loss: 0.38706743717193604
Validation loss: 2.06184188524882

Epoch: 6| Step: 3
Training loss: 0.17703917622566223
Validation loss: 2.0722069144248962

Epoch: 6| Step: 4
Training loss: 0.5260752439498901
Validation loss: 2.0669442812601724

Epoch: 6| Step: 5
Training loss: 0.9424316883087158
Validation loss: 2.0292487144470215

Epoch: 6| Step: 6
Training loss: 0.5010455846786499
Validation loss: 2.042892336845398

Epoch: 6| Step: 7
Training loss: 0.49492546916007996
Validation loss: 1.996472140153249

Epoch: 6| Step: 8
Training loss: 0.44729578495025635
Validation loss: 2.017595370610555

Epoch: 6| Step: 9
Training loss: 0.4531930685043335
Validation loss: 2.0753829876581826

Epoch: 6| Step: 10
Training loss: 0.5844987630844116
Validation loss: 2.0678253173828125

Epoch: 6| Step: 11
Training loss: 0.2865500748157501
Validation loss: 2.043915947278341

Epoch: 6| Step: 12
Training loss: 0.1940925419330597
Validation loss: 2.0725820461908975

Epoch: 6| Step: 13
Training loss: 0.497623473405838
Validation loss: 2.067414164543152

Epoch: 218| Step: 0
Training loss: 0.5992040038108826
Validation loss: 2.042738119761149

Epoch: 6| Step: 1
Training loss: 0.634712815284729
Validation loss: 2.063802977403005

Epoch: 6| Step: 2
Training loss: 0.22742724418640137
Validation loss: 2.01467764377594

Epoch: 6| Step: 3
Training loss: 0.23531794548034668
Validation loss: 2.047293742497762

Epoch: 6| Step: 4
Training loss: 0.5033541321754456
Validation loss: 2.0482351183891296

Epoch: 6| Step: 5
Training loss: 0.46140801906585693
Validation loss: 2.0066998402277627

Epoch: 6| Step: 6
Training loss: 0.3259715437889099
Validation loss: 2.009181876977285

Epoch: 6| Step: 7
Training loss: 0.3200078010559082
Validation loss: 2.0482426285743713

Epoch: 6| Step: 8
Training loss: 0.46761053800582886
Validation loss: 2.01674218972524

Epoch: 6| Step: 9
Training loss: 0.5319966077804565
Validation loss: 2.0449910958607993

Epoch: 6| Step: 10
Training loss: 0.8362903594970703
Validation loss: 1.9998003840446472

Epoch: 6| Step: 11
Training loss: 0.38237088918685913
Validation loss: 2.0574896335601807

Epoch: 6| Step: 12
Training loss: 0.43881040811538696
Validation loss: 2.0321331222852073

Epoch: 6| Step: 13
Training loss: 0.35933917760849
Validation loss: 2.025838315486908

Epoch: 219| Step: 0
Training loss: 0.6715517640113831
Validation loss: 2.048934578895569

Epoch: 6| Step: 1
Training loss: 0.8624257445335388
Validation loss: 2.0387184619903564

Epoch: 6| Step: 2
Training loss: 0.29631298780441284
Validation loss: 2.0695294737815857

Epoch: 6| Step: 3
Training loss: 0.49410122632980347
Validation loss: 2.006922662258148

Epoch: 6| Step: 4
Training loss: 0.3528851568698883
Validation loss: 2.0596701304117837

Epoch: 6| Step: 5
Training loss: 0.484468549489975
Validation loss: 2.0254456400871277

Epoch: 6| Step: 6
Training loss: 0.46342718601226807
Validation loss: 2.029516657193502

Epoch: 6| Step: 7
Training loss: 0.225835382938385
Validation loss: 2.0955965320269265

Epoch: 6| Step: 8
Training loss: 0.45618167519569397
Validation loss: 2.068027436733246

Epoch: 6| Step: 9
Training loss: 0.4020187556743622
Validation loss: 2.0319860378901162

Epoch: 6| Step: 10
Training loss: 0.27603620290756226
Validation loss: 2.1044162114461265

Epoch: 6| Step: 11
Training loss: 0.4956636428833008
Validation loss: 2.024065057436625

Epoch: 6| Step: 12
Training loss: 0.5520747303962708
Validation loss: 2.0729278326034546

Epoch: 6| Step: 13
Training loss: 0.6649523377418518
Validation loss: 2.05647744735082

Epoch: 220| Step: 0
Training loss: 0.4013032615184784
Validation loss: 2.001014828681946

Epoch: 6| Step: 1
Training loss: 0.7256518602371216
Validation loss: 2.0382195313771567

Epoch: 6| Step: 2
Training loss: 0.4124619960784912
Validation loss: 2.053248484929403

Epoch: 6| Step: 3
Training loss: 0.3195992112159729
Validation loss: 2.0338725447654724

Epoch: 6| Step: 4
Training loss: 0.5776054263114929
Validation loss: 2.0522600015004477

Epoch: 6| Step: 5
Training loss: 0.41298994421958923
Validation loss: 2.038267811139425

Epoch: 6| Step: 6
Training loss: 0.3048352897167206
Validation loss: 2.0739344159762063

Epoch: 6| Step: 7
Training loss: 0.19379815459251404
Validation loss: 2.0121268033981323

Epoch: 6| Step: 8
Training loss: 0.30521783232688904
Validation loss: 2.0758009950319924

Epoch: 6| Step: 9
Training loss: 0.5137187242507935
Validation loss: 2.0358442664146423

Epoch: 6| Step: 10
Training loss: 0.336138516664505
Validation loss: 2.0652209719022117

Epoch: 6| Step: 11
Training loss: 0.6774759292602539
Validation loss: 2.046256641546885

Epoch: 6| Step: 12
Training loss: 0.3505409359931946
Validation loss: 2.007140040397644

Epoch: 6| Step: 13
Training loss: 0.676652193069458
Validation loss: 2.074399729569753

Epoch: 221| Step: 0
Training loss: 0.380529522895813
Validation loss: 2.0647419691085815

Epoch: 6| Step: 1
Training loss: 0.18442672491073608
Validation loss: 2.063097139199575

Epoch: 6| Step: 2
Training loss: 0.5368658304214478
Validation loss: 2.016846021016439

Epoch: 6| Step: 3
Training loss: 0.3888079524040222
Validation loss: 2.0397666692733765

Epoch: 6| Step: 4
Training loss: 0.4754968285560608
Validation loss: 2.0289089679718018

Epoch: 6| Step: 5
Training loss: 0.375003844499588
Validation loss: 2.0292710860570273

Epoch: 6| Step: 6
Training loss: 0.8186274766921997
Validation loss: 2.022575775782267

Epoch: 6| Step: 7
Training loss: 0.45096635818481445
Validation loss: 1.994825800259908

Epoch: 6| Step: 8
Training loss: 0.23036466538906097
Validation loss: 2.0405733386675515

Epoch: 6| Step: 9
Training loss: 0.32017403841018677
Validation loss: 2.000249981880188

Epoch: 6| Step: 10
Training loss: 0.5082031488418579
Validation loss: 2.0120439728101096

Epoch: 6| Step: 11
Training loss: 0.559726357460022
Validation loss: 1.9913645386695862

Epoch: 6| Step: 12
Training loss: 0.55573970079422
Validation loss: 2.0243594447771707

Epoch: 6| Step: 13
Training loss: 0.17773157358169556
Validation loss: 2.049496610959371

Epoch: 222| Step: 0
Training loss: 0.6901168823242188
Validation loss: 1.9757835467656453

Epoch: 6| Step: 1
Training loss: 0.38244956731796265
Validation loss: 2.0282004674275718

Epoch: 6| Step: 2
Training loss: 0.37896502017974854
Validation loss: 2.0304418007532754

Epoch: 6| Step: 3
Training loss: 0.3866925835609436
Validation loss: 2.030574858188629

Epoch: 6| Step: 4
Training loss: 0.6464372277259827
Validation loss: 2.050054132938385

Epoch: 6| Step: 5
Training loss: 0.6415138244628906
Validation loss: 2.0195926427841187

Epoch: 6| Step: 6
Training loss: 0.48041921854019165
Validation loss: 2.0400975942611694

Epoch: 6| Step: 7
Training loss: 0.5171595811843872
Validation loss: 2.0184314250946045

Epoch: 6| Step: 8
Training loss: 0.25352922081947327
Validation loss: 2.0347413221995034

Epoch: 6| Step: 9
Training loss: 0.5735656023025513
Validation loss: 2.00729368130366

Epoch: 6| Step: 10
Training loss: 0.33093732595443726
Validation loss: 2.0028308232625327

Epoch: 6| Step: 11
Training loss: 0.5025628209114075
Validation loss: 2.0656553506851196

Epoch: 6| Step: 12
Training loss: 0.21921631693840027
Validation loss: 2.061804632345835

Epoch: 6| Step: 13
Training loss: 0.3008752167224884
Validation loss: 2.0655394196510315

Epoch: 223| Step: 0
Training loss: 0.4612736105918884
Validation loss: 2.0927855173746743

Epoch: 6| Step: 1
Training loss: 0.822780430316925
Validation loss: 2.084018091360728

Epoch: 6| Step: 2
Training loss: 0.2780865430831909
Validation loss: 2.063250780105591

Epoch: 6| Step: 3
Training loss: 0.431347131729126
Validation loss: 2.0424196124076843

Epoch: 6| Step: 4
Training loss: 0.3149947226047516
Validation loss: 2.014872054258982

Epoch: 6| Step: 5
Training loss: 0.6832606196403503
Validation loss: 2.0271663268407187

Epoch: 6| Step: 6
Training loss: 0.5855847001075745
Validation loss: 2.0424967606862388

Epoch: 6| Step: 7
Training loss: 0.5206326246261597
Validation loss: 2.0369215408960977

Epoch: 6| Step: 8
Training loss: 0.3379179835319519
Validation loss: 2.0034366051355996

Epoch: 6| Step: 9
Training loss: 0.2940778434276581
Validation loss: 2.0659188429514566

Epoch: 6| Step: 10
Training loss: 0.49469828605651855
Validation loss: 2.0529664754867554

Epoch: 6| Step: 11
Training loss: 0.5646347999572754
Validation loss: 2.0968977014223733

Epoch: 6| Step: 12
Training loss: 0.7469761967658997
Validation loss: 2.082825462023417

Epoch: 6| Step: 13
Training loss: 0.4163348972797394
Validation loss: 2.0500693718592324

Epoch: 224| Step: 0
Training loss: 0.3737117350101471
Validation loss: 2.065394699573517

Epoch: 6| Step: 1
Training loss: 0.7777233123779297
Validation loss: 2.015653053919474

Epoch: 6| Step: 2
Training loss: 0.3320593237876892
Validation loss: 2.054081618785858

Epoch: 6| Step: 3
Training loss: 0.288568913936615
Validation loss: 2.030020515124003

Epoch: 6| Step: 4
Training loss: 0.6766963601112366
Validation loss: 2.0546021262804666

Epoch: 6| Step: 5
Training loss: 0.39268821477890015
Validation loss: 2.0225117007891336

Epoch: 6| Step: 6
Training loss: 0.5181878805160522
Validation loss: 2.0768330494562783

Epoch: 6| Step: 7
Training loss: 0.3701963722705841
Validation loss: 2.0416237910588584

Epoch: 6| Step: 8
Training loss: 0.2852715849876404
Validation loss: 2.051790416240692

Epoch: 6| Step: 9
Training loss: 0.32699286937713623
Validation loss: 2.0376386046409607

Epoch: 6| Step: 10
Training loss: 0.8114935159683228
Validation loss: 2.0513036251068115

Epoch: 6| Step: 11
Training loss: 0.44155654311180115
Validation loss: 2.0273700952529907

Epoch: 6| Step: 12
Training loss: 0.5520601272583008
Validation loss: 2.062824785709381

Epoch: 6| Step: 13
Training loss: 0.4500649571418762
Validation loss: 2.0167892376581826

Epoch: 225| Step: 0
Training loss: 0.31127792596817017
Validation loss: 2.026945332686106

Epoch: 6| Step: 1
Training loss: 0.646286129951477
Validation loss: 2.045891841252645

Epoch: 6| Step: 2
Training loss: 0.43935441970825195
Validation loss: 2.0870657364527383

Epoch: 6| Step: 3
Training loss: 0.4370894730091095
Validation loss: 2.028445283571879

Epoch: 6| Step: 4
Training loss: 0.27241814136505127
Validation loss: 2.055592159430186

Epoch: 6| Step: 5
Training loss: 0.34410956501960754
Validation loss: 2.0687090158462524

Epoch: 6| Step: 6
Training loss: 0.3447999060153961
Validation loss: 2.044761379559835

Epoch: 6| Step: 7
Training loss: 0.3717295527458191
Validation loss: 2.0021426677703857

Epoch: 6| Step: 8
Training loss: 0.31615298986434937
Validation loss: 2.054775834083557

Epoch: 6| Step: 9
Training loss: 0.9247573018074036
Validation loss: 2.029491364955902

Epoch: 6| Step: 10
Training loss: 0.6858590245246887
Validation loss: 2.0110103487968445

Epoch: 6| Step: 11
Training loss: 0.6110409498214722
Validation loss: 2.040905157725016

Epoch: 6| Step: 12
Training loss: 0.306224524974823
Validation loss: 2.0985719362894693

Epoch: 6| Step: 13
Training loss: 0.2898843288421631
Validation loss: 2.0659180680910745

Epoch: 226| Step: 0
Training loss: 0.09967981278896332
Validation loss: 2.095185478528341

Epoch: 6| Step: 1
Training loss: 0.4400765895843506
Validation loss: 2.0183808406194053

Epoch: 6| Step: 2
Training loss: 0.42927324771881104
Validation loss: 2.0597896178563437

Epoch: 6| Step: 3
Training loss: 0.6264638900756836
Validation loss: 2.0105830430984497

Epoch: 6| Step: 4
Training loss: 0.5428394079208374
Validation loss: 2.0184172987937927

Epoch: 6| Step: 5
Training loss: 0.407378613948822
Validation loss: 2.0224314530690513

Epoch: 6| Step: 6
Training loss: 0.24451935291290283
Validation loss: 2.0670011043548584

Epoch: 6| Step: 7
Training loss: 0.31497567892074585
Validation loss: 2.026282091935476

Epoch: 6| Step: 8
Training loss: 0.5005161762237549
Validation loss: 2.056714951992035

Epoch: 6| Step: 9
Training loss: 0.9403142333030701
Validation loss: 1.9967962900797527

Epoch: 6| Step: 10
Training loss: 0.44274386763572693
Validation loss: 2.0671459833780923

Epoch: 6| Step: 11
Training loss: 0.24438878893852234
Validation loss: 2.065233031908671

Epoch: 6| Step: 12
Training loss: 0.5057180523872375
Validation loss: 2.08280477921168

Epoch: 6| Step: 13
Training loss: 0.40347379446029663
Validation loss: 2.053489625453949

Epoch: 227| Step: 0
Training loss: 0.3168267011642456
Validation loss: 2.077556292215983

Epoch: 6| Step: 1
Training loss: 0.14242957532405853
Validation loss: 2.0002577900886536

Epoch: 6| Step: 2
Training loss: 0.4168722629547119
Validation loss: 2.026480972766876

Epoch: 6| Step: 3
Training loss: 0.7959083318710327
Validation loss: 2.0489693681399026

Epoch: 6| Step: 4
Training loss: 0.6830301284790039
Validation loss: 2.0319918195406594

Epoch: 6| Step: 5
Training loss: 0.278757244348526
Validation loss: 2.01956699291865

Epoch: 6| Step: 6
Training loss: 0.517263650894165
Validation loss: 2.0172203381856284

Epoch: 6| Step: 7
Training loss: 0.5691360235214233
Validation loss: 2.0578210155169168

Epoch: 6| Step: 8
Training loss: 0.34592121839523315
Validation loss: 2.0817023714383445

Epoch: 6| Step: 9
Training loss: 0.684500515460968
Validation loss: 2.1038706302642822

Epoch: 6| Step: 10
Training loss: 0.5942486524581909
Validation loss: 2.037367105484009

Epoch: 6| Step: 11
Training loss: 0.4144420623779297
Validation loss: 2.0404465595881143

Epoch: 6| Step: 12
Training loss: 0.4005080461502075
Validation loss: 2.0137113332748413

Epoch: 6| Step: 13
Training loss: 0.2501448094844818
Validation loss: 1.9877719084421794

Epoch: 228| Step: 0
Training loss: 0.35889703035354614
Validation loss: 2.024409751097361

Epoch: 6| Step: 1
Training loss: 0.200239360332489
Validation loss: 2.00657457113266

Epoch: 6| Step: 2
Training loss: 0.35362547636032104
Validation loss: 2.025953710079193

Epoch: 6| Step: 3
Training loss: 0.3201529383659363
Validation loss: 2.0758748849232993

Epoch: 6| Step: 4
Training loss: 0.8200110197067261
Validation loss: 2.0488566160202026

Epoch: 6| Step: 5
Training loss: 0.43846815824508667
Validation loss: 2.027035713195801

Epoch: 6| Step: 6
Training loss: 0.4625142514705658
Validation loss: 2.036034405231476

Epoch: 6| Step: 7
Training loss: 0.6703080534934998
Validation loss: 1.995001991589864

Epoch: 6| Step: 8
Training loss: 0.4157208800315857
Validation loss: 2.0253307024637857

Epoch: 6| Step: 9
Training loss: 0.4484069347381592
Validation loss: 2.078380604585012

Epoch: 6| Step: 10
Training loss: 0.6340230703353882
Validation loss: 2.0236805081367493

Epoch: 6| Step: 11
Training loss: 0.48560628294944763
Validation loss: 2.0254149436950684

Epoch: 6| Step: 12
Training loss: 0.5902420878410339
Validation loss: 2.0531462033589682

Epoch: 6| Step: 13
Training loss: 0.2675435543060303
Validation loss: 2.051189204057058

Epoch: 229| Step: 0
Training loss: 0.20639602839946747
Validation loss: 2.02749502658844

Epoch: 6| Step: 1
Training loss: 0.7867312431335449
Validation loss: 2.111058513323466

Epoch: 6| Step: 2
Training loss: 0.30885645747184753
Validation loss: 2.109067181746165

Epoch: 6| Step: 3
Training loss: 0.6359719634056091
Validation loss: 2.092104732990265

Epoch: 6| Step: 4
Training loss: 0.1763613224029541
Validation loss: 2.0192328095436096

Epoch: 6| Step: 5
Training loss: 0.34867599606513977
Validation loss: 2.0405863324801126

Epoch: 6| Step: 6
Training loss: 0.5782338976860046
Validation loss: 2.0428624351819358

Epoch: 6| Step: 7
Training loss: 0.25638771057128906
Validation loss: 2.0143401424090066

Epoch: 6| Step: 8
Training loss: 0.5300893187522888
Validation loss: 2.0484391848246255

Epoch: 6| Step: 9
Training loss: 0.26825571060180664
Validation loss: 2.0171706279118857

Epoch: 6| Step: 10
Training loss: 0.4784320294857025
Validation loss: 2.053183456261953

Epoch: 6| Step: 11
Training loss: 0.5113212466239929
Validation loss: 2.042565107345581

Epoch: 6| Step: 12
Training loss: 0.6900374889373779
Validation loss: 2.081635514895121

Epoch: 6| Step: 13
Training loss: 0.8349897861480713
Validation loss: 2.0282464027404785

Epoch: 230| Step: 0
Training loss: 0.7009817361831665
Validation loss: 2.0453247825304666

Epoch: 6| Step: 1
Training loss: 0.2561444640159607
Validation loss: 2.060475925604502

Epoch: 6| Step: 2
Training loss: 0.4493689239025116
Validation loss: 2.0609885454177856

Epoch: 6| Step: 3
Training loss: 0.40236496925354004
Validation loss: 2.0171314080556235

Epoch: 6| Step: 4
Training loss: 0.40258079767227173
Validation loss: 2.017485817273458

Epoch: 6| Step: 5
Training loss: 0.6103504300117493
Validation loss: 2.060451626777649

Epoch: 6| Step: 6
Training loss: 0.45744839310646057
Validation loss: 2.038384954134623

Epoch: 6| Step: 7
Training loss: 0.9734066128730774
Validation loss: 2.0376547972361245

Epoch: 6| Step: 8
Training loss: 0.4526556730270386
Validation loss: 2.0323070883750916

Epoch: 6| Step: 9
Training loss: 0.31437987089157104
Validation loss: 2.0496003230412803

Epoch: 6| Step: 10
Training loss: 0.4182782471179962
Validation loss: 2.006330450375875

Epoch: 6| Step: 11
Training loss: 0.6201399564743042
Validation loss: 1.9916166265805562

Epoch: 6| Step: 12
Training loss: 0.4624193608760834
Validation loss: 1.9806061387062073

Epoch: 6| Step: 13
Training loss: 0.40861445665359497
Validation loss: 2.02405713001887

Epoch: 231| Step: 0
Training loss: 0.5674713850021362
Validation loss: 2.0171403884887695

Epoch: 6| Step: 1
Training loss: 0.3881435990333557
Validation loss: 2.0472636024157205

Epoch: 6| Step: 2
Training loss: 0.18070870637893677
Validation loss: 2.0094098647435508

Epoch: 6| Step: 3
Training loss: 0.6053717136383057
Validation loss: 2.0979100465774536

Epoch: 6| Step: 4
Training loss: 0.49578535556793213
Validation loss: 2.0258127450942993

Epoch: 6| Step: 5
Training loss: 0.5550481081008911
Validation loss: 2.0356446703275046

Epoch: 6| Step: 6
Training loss: 0.2341887354850769
Validation loss: 2.0561850865681968

Epoch: 6| Step: 7
Training loss: 0.3409339487552643
Validation loss: 2.0478336016337075

Epoch: 6| Step: 8
Training loss: 0.5483589768409729
Validation loss: 2.0424700578053794

Epoch: 6| Step: 9
Training loss: 0.29769545793533325
Validation loss: 2.0226317246754966

Epoch: 6| Step: 10
Training loss: 0.5099517703056335
Validation loss: 1.9998887379964192

Epoch: 6| Step: 11
Training loss: 0.29775047302246094
Validation loss: 2.037393550078074

Epoch: 6| Step: 12
Training loss: 0.3273769021034241
Validation loss: 2.0374896128972373

Epoch: 6| Step: 13
Training loss: 0.6083177924156189
Validation loss: 2.059386650721232

Epoch: 232| Step: 0
Training loss: 0.5933606624603271
Validation loss: 2.028749148050944

Epoch: 6| Step: 1
Training loss: 0.39700019359588623
Validation loss: 2.0354607502619424

Epoch: 6| Step: 2
Training loss: 0.6416155099868774
Validation loss: 2.0623997847239175

Epoch: 6| Step: 3
Training loss: 0.3481905460357666
Validation loss: 2.0257150133450827

Epoch: 6| Step: 4
Training loss: 0.2655293643474579
Validation loss: 2.027607023715973

Epoch: 6| Step: 5
Training loss: 0.9047536849975586
Validation loss: 2.0169204473495483

Epoch: 6| Step: 6
Training loss: 0.5060698986053467
Validation loss: 2.0250617265701294

Epoch: 6| Step: 7
Training loss: 0.22792702913284302
Validation loss: 1.9973455667495728

Epoch: 6| Step: 8
Training loss: 0.21467943489551544
Validation loss: 2.0461986462275186

Epoch: 6| Step: 9
Training loss: 0.27459287643432617
Validation loss: 2.040489415327708

Epoch: 6| Step: 10
Training loss: 0.5286788940429688
Validation loss: 2.0342683593432107

Epoch: 6| Step: 11
Training loss: 0.21549561619758606
Validation loss: 2.0599429408709207

Epoch: 6| Step: 12
Training loss: 0.470074325799942
Validation loss: 2.0393332640329995

Epoch: 6| Step: 13
Training loss: 0.3631124496459961
Validation loss: 2.0207611521085105

Epoch: 233| Step: 0
Training loss: 0.33312416076660156
Validation loss: 2.1020118792851767

Epoch: 6| Step: 1
Training loss: 0.6199566721916199
Validation loss: 2.0469919443130493

Epoch: 6| Step: 2
Training loss: 0.7917220592498779
Validation loss: 2.0618473490079245

Epoch: 6| Step: 3
Training loss: 0.21754446625709534
Validation loss: 2.055613915125529

Epoch: 6| Step: 4
Training loss: 0.40716540813446045
Validation loss: 2.0395453373591104

Epoch: 6| Step: 5
Training loss: 0.38373202085494995
Validation loss: 2.050378362337748

Epoch: 6| Step: 6
Training loss: 0.5197052359580994
Validation loss: 2.0493022799491882

Epoch: 6| Step: 7
Training loss: 0.3837888538837433
Validation loss: 2.114925742149353

Epoch: 6| Step: 8
Training loss: 0.19388486444950104
Validation loss: 2.036444624265035

Epoch: 6| Step: 9
Training loss: 0.19462621212005615
Validation loss: 2.061022639274597

Epoch: 6| Step: 10
Training loss: 0.47214269638061523
Validation loss: 2.09203040599823

Epoch: 6| Step: 11
Training loss: 0.4108610451221466
Validation loss: 2.07040137052536

Epoch: 6| Step: 12
Training loss: 0.43479788303375244
Validation loss: 2.0532603661219277

Epoch: 6| Step: 13
Training loss: 0.6251804828643799
Validation loss: 2.0782654086748757

Epoch: 234| Step: 0
Training loss: 0.3994702100753784
Validation loss: 2.0661686261494956

Epoch: 6| Step: 1
Training loss: 0.2964893877506256
Validation loss: 2.0939761797587075

Epoch: 6| Step: 2
Training loss: 0.26361972093582153
Validation loss: 2.0488527417182922

Epoch: 6| Step: 3
Training loss: 0.43204912543296814
Validation loss: 1.9952515165011089

Epoch: 6| Step: 4
Training loss: 0.6316829919815063
Validation loss: 2.006506323814392

Epoch: 6| Step: 5
Training loss: 0.7984705567359924
Validation loss: 2.015942394733429

Epoch: 6| Step: 6
Training loss: 0.46694010496139526
Validation loss: 2.0078678925832114

Epoch: 6| Step: 7
Training loss: 0.14595434069633484
Validation loss: 1.996479074160258

Epoch: 6| Step: 8
Training loss: 0.5139895677566528
Validation loss: 1.9927414655685425

Epoch: 6| Step: 9
Training loss: 0.20934432744979858
Validation loss: 2.003336330254873

Epoch: 6| Step: 10
Training loss: 0.8403722047805786
Validation loss: 2.0628817677497864

Epoch: 6| Step: 11
Training loss: 0.3734777569770813
Validation loss: 2.0403945247332254

Epoch: 6| Step: 12
Training loss: 0.48389872908592224
Validation loss: 2.049698273340861

Epoch: 6| Step: 13
Training loss: 0.5290380120277405
Validation loss: 2.0260688066482544

Epoch: 235| Step: 0
Training loss: 0.18008098006248474
Validation loss: 2.0178199410438538

Epoch: 6| Step: 1
Training loss: 0.37768468260765076
Validation loss: 1.9970146020253499

Epoch: 6| Step: 2
Training loss: 0.4612387418746948
Validation loss: 2.0170395175615945

Epoch: 6| Step: 3
Training loss: 0.30585765838623047
Validation loss: 2.0213439067204795

Epoch: 6| Step: 4
Training loss: 0.4795568883419037
Validation loss: 2.024798274040222

Epoch: 6| Step: 5
Training loss: 0.32282355427742004
Validation loss: 2.0213123559951782

Epoch: 6| Step: 6
Training loss: 0.18120531737804413
Validation loss: 2.014484385649363

Epoch: 6| Step: 7
Training loss: 0.5517135262489319
Validation loss: 2.028990884621938

Epoch: 6| Step: 8
Training loss: 0.35615700483322144
Validation loss: 1.9990254640579224

Epoch: 6| Step: 9
Training loss: 0.5481026768684387
Validation loss: 2.03387451171875

Epoch: 6| Step: 10
Training loss: 0.4436858892440796
Validation loss: 1.98987744251887

Epoch: 6| Step: 11
Training loss: 0.7561652660369873
Validation loss: 2.013590415318807

Epoch: 6| Step: 12
Training loss: 0.39459577202796936
Validation loss: 2.028533120950063

Epoch: 6| Step: 13
Training loss: 0.5013270378112793
Validation loss: 2.076521098613739

Epoch: 236| Step: 0
Training loss: 0.23495163023471832
Validation loss: 2.034937798976898

Epoch: 6| Step: 1
Training loss: 0.6375756859779358
Validation loss: 2.0368035634358725

Epoch: 6| Step: 2
Training loss: 0.2611904442310333
Validation loss: 2.0450479785601297

Epoch: 6| Step: 3
Training loss: 0.4582011103630066
Validation loss: 2.0120186805725098

Epoch: 6| Step: 4
Training loss: 0.3782382607460022
Validation loss: 2.029013713200887

Epoch: 6| Step: 5
Training loss: 0.5404910445213318
Validation loss: 2.071145216623942

Epoch: 6| Step: 6
Training loss: 0.40628302097320557
Validation loss: 2.0282975832621255

Epoch: 6| Step: 7
Training loss: 0.5715223550796509
Validation loss: 2.0579967300097146

Epoch: 6| Step: 8
Training loss: 0.3445526361465454
Validation loss: 1.9981292883555095

Epoch: 6| Step: 9
Training loss: 0.30116134881973267
Validation loss: 2.011421859264374

Epoch: 6| Step: 10
Training loss: 0.6315900683403015
Validation loss: 2.030312935511271

Epoch: 6| Step: 11
Training loss: 0.5984876751899719
Validation loss: 2.0410176714261374

Epoch: 6| Step: 12
Training loss: 0.3376848101615906
Validation loss: 2.033283750216166

Epoch: 6| Step: 13
Training loss: 0.3202780485153198
Validation loss: 2.0355659325917563

Epoch: 237| Step: 0
Training loss: 0.6470818519592285
Validation loss: 2.0011647939682007

Epoch: 6| Step: 1
Training loss: 0.501477062702179
Validation loss: 2.0249938567479453

Epoch: 6| Step: 2
Training loss: 0.4564118981361389
Validation loss: 2.0476683974266052

Epoch: 6| Step: 3
Training loss: 0.2713336646556854
Validation loss: 2.0363216400146484

Epoch: 6| Step: 4
Training loss: 0.7703657150268555
Validation loss: 2.0315634409586587

Epoch: 6| Step: 5
Training loss: 0.4175325632095337
Validation loss: 2.0217161774635315

Epoch: 6| Step: 6
Training loss: 0.7006193399429321
Validation loss: 2.0660082499186196

Epoch: 6| Step: 7
Training loss: 0.31036657094955444
Validation loss: 2.0146801471710205

Epoch: 6| Step: 8
Training loss: 0.1997465342283249
Validation loss: 1.9961822231610615

Epoch: 6| Step: 9
Training loss: 0.46977558732032776
Validation loss: 2.0102378328641257

Epoch: 6| Step: 10
Training loss: 0.2328730970621109
Validation loss: 2.017732481161753

Epoch: 6| Step: 11
Training loss: 0.39913105964660645
Validation loss: 2.0213228861490884

Epoch: 6| Step: 12
Training loss: 0.2652028799057007
Validation loss: 2.028013010819753

Epoch: 6| Step: 13
Training loss: 0.304889976978302
Validation loss: 2.0480135083198547

Epoch: 238| Step: 0
Training loss: 0.5263004302978516
Validation loss: 1.9926488200823467

Epoch: 6| Step: 1
Training loss: 0.35510629415512085
Validation loss: 1.9926798939704895

Epoch: 6| Step: 2
Training loss: 0.35475751757621765
Validation loss: 2.044318457444509

Epoch: 6| Step: 3
Training loss: 0.2739667594432831
Validation loss: 2.054461399714152

Epoch: 6| Step: 4
Training loss: 0.676395833492279
Validation loss: 2.105368971824646

Epoch: 6| Step: 5
Training loss: 0.6006941795349121
Validation loss: 2.0584583481152854

Epoch: 6| Step: 6
Training loss: 0.31825369596481323
Validation loss: 2.101143995920817

Epoch: 6| Step: 7
Training loss: 0.5097372531890869
Validation loss: 2.0209919015566506

Epoch: 6| Step: 8
Training loss: 0.17708124220371246
Validation loss: 2.075203537940979

Epoch: 6| Step: 9
Training loss: 0.3773733079433441
Validation loss: 2.044308284918467

Epoch: 6| Step: 10
Training loss: 0.30256277322769165
Validation loss: 2.0611531933148703

Epoch: 6| Step: 11
Training loss: 0.554388165473938
Validation loss: 2.0129501024881997

Epoch: 6| Step: 12
Training loss: 0.40434324741363525
Validation loss: 2.0306710402170816

Epoch: 6| Step: 13
Training loss: 0.5963419675827026
Validation loss: 2.0455932219823203

Epoch: 239| Step: 0
Training loss: 0.303371399641037
Validation loss: 1.9901784261067708

Epoch: 6| Step: 1
Training loss: 0.23592282831668854
Validation loss: 2.0421913862228394

Epoch: 6| Step: 2
Training loss: 0.3364189565181732
Validation loss: 2.0240944822629294

Epoch: 6| Step: 3
Training loss: 0.23306767642498016
Validation loss: 2.056975861390432

Epoch: 6| Step: 4
Training loss: 0.8751213550567627
Validation loss: 2.0756325920422873

Epoch: 6| Step: 5
Training loss: 0.5517853498458862
Validation loss: 2.119764804840088

Epoch: 6| Step: 6
Training loss: 0.30391424894332886
Validation loss: 2.0560277700424194

Epoch: 6| Step: 7
Training loss: 0.41802436113357544
Validation loss: 2.070933679739634

Epoch: 6| Step: 8
Training loss: 0.4227222800254822
Validation loss: 2.0305123726526895

Epoch: 6| Step: 9
Training loss: 0.5344683527946472
Validation loss: 2.0147679249445596

Epoch: 6| Step: 10
Training loss: 0.7077603936195374
Validation loss: 2.003090798854828

Epoch: 6| Step: 11
Training loss: 0.7379471659660339
Validation loss: 2.002313216527303

Epoch: 6| Step: 12
Training loss: 0.47323471307754517
Validation loss: 2.0414514541625977

Epoch: 6| Step: 13
Training loss: 0.35431545972824097
Validation loss: 2.0105849504470825

Epoch: 240| Step: 0
Training loss: 0.28313249349594116
Validation loss: 1.9921036958694458

Epoch: 6| Step: 1
Training loss: 0.7836049795150757
Validation loss: 2.0355769197146096

Epoch: 6| Step: 2
Training loss: 0.3234431743621826
Validation loss: 2.030457556247711

Epoch: 6| Step: 3
Training loss: 0.6807680726051331
Validation loss: 2.055330832799276

Epoch: 6| Step: 4
Training loss: 0.4137570858001709
Validation loss: 2.069410721460978

Epoch: 6| Step: 5
Training loss: 0.3696928918361664
Validation loss: 2.080021858215332

Epoch: 6| Step: 6
Training loss: 0.3498970568180084
Validation loss: 2.0184311668078103

Epoch: 6| Step: 7
Training loss: 0.34551694989204407
Validation loss: 2.055892765522003

Epoch: 6| Step: 8
Training loss: 0.6273357272148132
Validation loss: 1.9965919057528179

Epoch: 6| Step: 9
Training loss: 0.4563900828361511
Validation loss: 2.017764091491699

Epoch: 6| Step: 10
Training loss: 0.4707636833190918
Validation loss: 2.0052554607391357

Epoch: 6| Step: 11
Training loss: 0.4591986835002899
Validation loss: 2.0148719549179077

Epoch: 6| Step: 12
Training loss: 0.3365241587162018
Validation loss: 1.956440011660258

Epoch: 6| Step: 13
Training loss: 0.1852278858423233
Validation loss: 1.99869970480601

Epoch: 241| Step: 0
Training loss: 0.3138716220855713
Validation loss: 2.04244734843572

Epoch: 6| Step: 1
Training loss: 0.5311809182167053
Validation loss: 2.0832931200663247

Epoch: 6| Step: 2
Training loss: 0.3516826629638672
Validation loss: 2.062043786048889

Epoch: 6| Step: 3
Training loss: 0.3705599904060364
Validation loss: 2.049032131830851

Epoch: 6| Step: 4
Training loss: 0.16019967198371887
Validation loss: 2.0205273230870566

Epoch: 6| Step: 5
Training loss: 0.4093778133392334
Validation loss: 2.005407730738322

Epoch: 6| Step: 6
Training loss: 0.33132877945899963
Validation loss: 2.0232976277669272

Epoch: 6| Step: 7
Training loss: 0.6640292406082153
Validation loss: 1.9958398540814717

Epoch: 6| Step: 8
Training loss: 0.6079373359680176
Validation loss: 2.0210788249969482

Epoch: 6| Step: 9
Training loss: 0.34346073865890503
Validation loss: 2.0127989053726196

Epoch: 6| Step: 10
Training loss: 0.5457845330238342
Validation loss: 2.0471640626589456

Epoch: 6| Step: 11
Training loss: 0.39756107330322266
Validation loss: 2.007844110329946

Epoch: 6| Step: 12
Training loss: 0.9373406171798706
Validation loss: 2.02278600136439

Epoch: 6| Step: 13
Training loss: 0.5627259612083435
Validation loss: 2.0651480158170066

Epoch: 242| Step: 0
Training loss: 0.32970619201660156
Validation loss: 2.0514938831329346

Epoch: 6| Step: 1
Training loss: 0.9660183191299438
Validation loss: 2.06274143854777

Epoch: 6| Step: 2
Training loss: 0.3686284124851227
Validation loss: 2.0784934560457864

Epoch: 6| Step: 3
Training loss: 0.4302498698234558
Validation loss: 2.0138702392578125

Epoch: 6| Step: 4
Training loss: 0.2315688580274582
Validation loss: 2.0142943064371743

Epoch: 6| Step: 5
Training loss: 0.5839263200759888
Validation loss: 2.0265833735466003

Epoch: 6| Step: 6
Training loss: 0.6560425162315369
Validation loss: 2.0354883472124734

Epoch: 6| Step: 7
Training loss: 0.23476512730121613
Validation loss: 2.0503571033477783

Epoch: 6| Step: 8
Training loss: 0.23803788423538208
Validation loss: 2.0544614593187966

Epoch: 6| Step: 9
Training loss: 0.543230414390564
Validation loss: 2.0579626162846885

Epoch: 6| Step: 10
Training loss: 0.22944048047065735
Validation loss: 2.0398979584376016

Epoch: 6| Step: 11
Training loss: 0.4438846707344055
Validation loss: 2.0145599047342935

Epoch: 6| Step: 12
Training loss: 0.3474048972129822
Validation loss: 2.0320923924446106

Epoch: 6| Step: 13
Training loss: 0.2892914414405823
Validation loss: 2.001654545466105

Epoch: 243| Step: 0
Training loss: 0.261053204536438
Validation loss: 2.0478127002716064

Epoch: 6| Step: 1
Training loss: 0.5032030344009399
Validation loss: 2.0591880877812705

Epoch: 6| Step: 2
Training loss: 0.570906400680542
Validation loss: 1.9689499735832214

Epoch: 6| Step: 3
Training loss: 0.40995216369628906
Validation loss: 1.982753872871399

Epoch: 6| Step: 4
Training loss: 0.7852924466133118
Validation loss: 2.026346524556478

Epoch: 6| Step: 5
Training loss: 0.31904053688049316
Validation loss: 2.0702141920725503

Epoch: 6| Step: 6
Training loss: 0.30998295545578003
Validation loss: 2.0272021094957986

Epoch: 6| Step: 7
Training loss: 0.5400466918945312
Validation loss: 2.0283480485280356

Epoch: 6| Step: 8
Training loss: 0.19791370630264282
Validation loss: 2.020966649055481

Epoch: 6| Step: 9
Training loss: 0.29143741726875305
Validation loss: 2.094058632850647

Epoch: 6| Step: 10
Training loss: 0.8547447323799133
Validation loss: 2.0543501377105713

Epoch: 6| Step: 11
Training loss: 0.43552929162979126
Validation loss: 2.028433839480082

Epoch: 6| Step: 12
Training loss: 0.365414559841156
Validation loss: 2.014820873737335

Epoch: 6| Step: 13
Training loss: 0.44816893339157104
Validation loss: 2.0204448898633323

Epoch: 244| Step: 0
Training loss: 0.5403838753700256
Validation loss: 2.009727676709493

Epoch: 6| Step: 1
Training loss: 0.4484826624393463
Validation loss: 2.022025763988495

Epoch: 6| Step: 2
Training loss: 0.7868359684944153
Validation loss: 2.057390590508779

Epoch: 6| Step: 3
Training loss: 0.36893314123153687
Validation loss: 2.0916319290796914

Epoch: 6| Step: 4
Training loss: 0.3517031669616699
Validation loss: 2.047233601411184

Epoch: 6| Step: 5
Training loss: 0.4145604372024536
Validation loss: 2.047164718310038

Epoch: 6| Step: 6
Training loss: 0.6127791404724121
Validation loss: 2.012608051300049

Epoch: 6| Step: 7
Training loss: 0.42276784777641296
Validation loss: 2.057279904683431

Epoch: 6| Step: 8
Training loss: 0.2960484027862549
Validation loss: 1.9895776510238647

Epoch: 6| Step: 9
Training loss: 0.25163447856903076
Validation loss: 2.0242981712023416

Epoch: 6| Step: 10
Training loss: 0.2901153564453125
Validation loss: 1.982968270778656

Epoch: 6| Step: 11
Training loss: 0.40466028451919556
Validation loss: 2.0459747910499573

Epoch: 6| Step: 12
Training loss: 0.44357675313949585
Validation loss: 2.011919399102529

Epoch: 6| Step: 13
Training loss: 0.30239272117614746
Validation loss: 2.0326107939084372

Epoch: 245| Step: 0
Training loss: 0.23753173649311066
Validation loss: 2.056873142719269

Epoch: 6| Step: 1
Training loss: 0.28091371059417725
Validation loss: 2.081395149230957

Epoch: 6| Step: 2
Training loss: 0.4715103805065155
Validation loss: 2.0371846556663513

Epoch: 6| Step: 3
Training loss: 0.3430733382701874
Validation loss: 2.004308561484019

Epoch: 6| Step: 4
Training loss: 0.3847206234931946
Validation loss: 2.051501433054606

Epoch: 6| Step: 5
Training loss: 0.5126010179519653
Validation loss: 2.027251124382019

Epoch: 6| Step: 6
Training loss: 0.504037618637085
Validation loss: 2.0722911755243936

Epoch: 6| Step: 7
Training loss: 0.512276291847229
Validation loss: 1.977563162644704

Epoch: 6| Step: 8
Training loss: 0.1976492702960968
Validation loss: 2.05551811059316

Epoch: 6| Step: 9
Training loss: 0.3859085738658905
Validation loss: 2.049641748269399

Epoch: 6| Step: 10
Training loss: 0.4675077795982361
Validation loss: 2.0025550921758017

Epoch: 6| Step: 11
Training loss: 0.2940105199813843
Validation loss: 2.0321207642555237

Epoch: 6| Step: 12
Training loss: 0.37630170583724976
Validation loss: 2.0475634932518005

Epoch: 6| Step: 13
Training loss: 0.6645880937576294
Validation loss: 2.008882462978363

Epoch: 246| Step: 0
Training loss: 0.28498876094818115
Validation loss: 2.0276639660199485

Epoch: 6| Step: 1
Training loss: 0.31355249881744385
Validation loss: 2.019151528676351

Epoch: 6| Step: 2
Training loss: 0.29966557025909424
Validation loss: 2.009999851385752

Epoch: 6| Step: 3
Training loss: 0.3226671516895294
Validation loss: 2.0609149734179177

Epoch: 6| Step: 4
Training loss: 0.49935150146484375
Validation loss: 1.9939831296602886

Epoch: 6| Step: 5
Training loss: 0.4055487811565399
Validation loss: 2.026319940884908

Epoch: 6| Step: 6
Training loss: 0.392529159784317
Validation loss: 2.0325199365615845

Epoch: 6| Step: 7
Training loss: 0.5051546096801758
Validation loss: 2.059937298297882

Epoch: 6| Step: 8
Training loss: 0.414699912071228
Validation loss: 2.013576169808706

Epoch: 6| Step: 9
Training loss: 0.8745298385620117
Validation loss: 2.000262955824534

Epoch: 6| Step: 10
Training loss: 0.4334101676940918
Validation loss: 2.066819171110789

Epoch: 6| Step: 11
Training loss: 0.3396073877811432
Validation loss: 1.982014238834381

Epoch: 6| Step: 12
Training loss: 0.41080689430236816
Validation loss: 1.9928533434867859

Epoch: 6| Step: 13
Training loss: 0.23151835799217224
Validation loss: 1.9993300835291545

Epoch: 247| Step: 0
Training loss: 0.3335448205471039
Validation loss: 2.0253350536028543

Epoch: 6| Step: 1
Training loss: 0.5069198608398438
Validation loss: 1.9967864155769348

Epoch: 6| Step: 2
Training loss: 0.6430901288986206
Validation loss: 2.010684311389923

Epoch: 6| Step: 3
Training loss: 0.3724867105484009
Validation loss: 2.0872199734052024

Epoch: 6| Step: 4
Training loss: 0.19144795835018158
Validation loss: 2.0251394708951316

Epoch: 6| Step: 5
Training loss: 0.436468243598938
Validation loss: 2.0431302189826965

Epoch: 6| Step: 6
Training loss: 0.21408939361572266
Validation loss: 2.0361451506614685

Epoch: 6| Step: 7
Training loss: 0.37848857045173645
Validation loss: 2.046424229939779

Epoch: 6| Step: 8
Training loss: 0.35542362928390503
Validation loss: 2.0149402419726052

Epoch: 6| Step: 9
Training loss: 0.531851589679718
Validation loss: 2.047429700692495

Epoch: 6| Step: 10
Training loss: 0.42735910415649414
Validation loss: 1.984448492527008

Epoch: 6| Step: 11
Training loss: 0.6365557312965393
Validation loss: 2.025326410929362

Epoch: 6| Step: 12
Training loss: 0.3387938141822815
Validation loss: 2.0295729637145996

Epoch: 6| Step: 13
Training loss: 0.24500247836112976
Validation loss: 2.0217910210291543

Epoch: 248| Step: 0
Training loss: 0.1932748258113861
Validation loss: 2.04421995083491

Epoch: 6| Step: 1
Training loss: 0.1855635941028595
Validation loss: 2.069571614265442

Epoch: 6| Step: 2
Training loss: 0.2720201909542084
Validation loss: 2.053273379802704

Epoch: 6| Step: 3
Training loss: 0.21811041235923767
Validation loss: 2.0413355231285095

Epoch: 6| Step: 4
Training loss: 0.6100055575370789
Validation loss: 2.0674245357513428

Epoch: 6| Step: 5
Training loss: 0.6965340971946716
Validation loss: 2.0472713907559714

Epoch: 6| Step: 6
Training loss: 0.8267592191696167
Validation loss: 1.9925890167554219

Epoch: 6| Step: 7
Training loss: 0.5524121522903442
Validation loss: 2.0821500619252524

Epoch: 6| Step: 8
Training loss: 0.2722936272621155
Validation loss: 2.0635756055514016

Epoch: 6| Step: 9
Training loss: 0.19669079780578613
Validation loss: 2.0298466285069785

Epoch: 6| Step: 10
Training loss: 0.24171961843967438
Validation loss: 1.9925278425216675

Epoch: 6| Step: 11
Training loss: 0.4913206398487091
Validation loss: 2.0273653467496238

Epoch: 6| Step: 12
Training loss: 0.3965626358985901
Validation loss: 2.055352826913198

Epoch: 6| Step: 13
Training loss: 0.3080747127532959
Validation loss: 2.073065916697184

Epoch: 249| Step: 0
Training loss: 0.5473202466964722
Validation loss: 2.0151207447052

Epoch: 6| Step: 1
Training loss: 0.18549197912216187
Validation loss: 2.0387155016263327

Epoch: 6| Step: 2
Training loss: 0.49813321232795715
Validation loss: 2.042149821917216

Epoch: 6| Step: 3
Training loss: 0.3288530707359314
Validation loss: 2.0460129976272583

Epoch: 6| Step: 4
Training loss: 0.4282487630844116
Validation loss: 2.060675541559855

Epoch: 6| Step: 5
Training loss: 0.3167502284049988
Validation loss: 2.019961337248484

Epoch: 6| Step: 6
Training loss: 0.2907145321369171
Validation loss: 2.03709344069163

Epoch: 6| Step: 7
Training loss: 0.5040113925933838
Validation loss: 2.0526195565859475

Epoch: 6| Step: 8
Training loss: 0.9796305298805237
Validation loss: 2.0250034729639688

Epoch: 6| Step: 9
Training loss: 0.23349601030349731
Validation loss: 2.0058586994806924

Epoch: 6| Step: 10
Training loss: 0.2776951193809509
Validation loss: 2.033966283003489

Epoch: 6| Step: 11
Training loss: 0.2897223234176636
Validation loss: 2.0353480180104575

Epoch: 6| Step: 12
Training loss: 0.28346917033195496
Validation loss: 2.043609937032064

Epoch: 6| Step: 13
Training loss: 0.29694825410842896
Validation loss: 2.110491693019867

Epoch: 250| Step: 0
Training loss: 0.47944653034210205
Validation loss: 2.070866068204244

Epoch: 6| Step: 1
Training loss: 0.36424875259399414
Validation loss: 2.0072370568911233

Epoch: 6| Step: 2
Training loss: 0.2635759711265564
Validation loss: 2.0134559075037637

Epoch: 6| Step: 3
Training loss: 0.2773180603981018
Validation loss: 2.052550514539083

Epoch: 6| Step: 4
Training loss: 0.2350829839706421
Validation loss: 2.041984577973684

Epoch: 6| Step: 5
Training loss: 0.17008262872695923
Validation loss: 2.0268829663594565

Epoch: 6| Step: 6
Training loss: 0.6269821524620056
Validation loss: 2.044804493586222

Epoch: 6| Step: 7
Training loss: 0.5020430088043213
Validation loss: 2.038447141647339

Epoch: 6| Step: 8
Training loss: 0.9106042385101318
Validation loss: 2.0488959550857544

Epoch: 6| Step: 9
Training loss: 0.3326881229877472
Validation loss: 2.0511229832967124

Epoch: 6| Step: 10
Training loss: 0.47148966789245605
Validation loss: 2.070919473965963

Epoch: 6| Step: 11
Training loss: 0.3469882905483246
Validation loss: 2.063671370347341

Epoch: 6| Step: 12
Training loss: 0.347395658493042
Validation loss: 2.006140410900116

Epoch: 6| Step: 13
Training loss: 0.4913958013057709
Validation loss: 2.041310946146647

Testing loss: 1.9554917151979405
