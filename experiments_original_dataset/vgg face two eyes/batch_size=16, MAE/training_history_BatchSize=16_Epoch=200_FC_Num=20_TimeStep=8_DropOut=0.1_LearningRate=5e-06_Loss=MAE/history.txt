Epoch: 1| Step: 0
Training loss: 6.861627101898193
Validation loss: 6.714250644048055

Epoch: 6| Step: 1
Training loss: 6.743219375610352
Validation loss: 6.683331489562988

Epoch: 6| Step: 2
Training loss: 7.334781646728516
Validation loss: 6.652490456899007

Epoch: 6| Step: 3
Training loss: 6.50953483581543
Validation loss: 6.621193965276082

Epoch: 6| Step: 4
Training loss: 6.941101551055908
Validation loss: 6.589800755182902

Epoch: 6| Step: 5
Training loss: 6.873186111450195
Validation loss: 6.55756688117981

Epoch: 6| Step: 6
Training loss: 7.343324184417725
Validation loss: 6.530688762664795

Epoch: 6| Step: 7
Training loss: 6.836723804473877
Validation loss: 6.500949700673421

Epoch: 6| Step: 8
Training loss: 6.480570316314697
Validation loss: 6.469792445500691

Epoch: 6| Step: 9
Training loss: 6.191841125488281
Validation loss: 6.43923298517863

Epoch: 6| Step: 10
Training loss: 6.0997772216796875
Validation loss: 6.407926162083943

Epoch: 6| Step: 11
Training loss: 6.623773574829102
Validation loss: 6.3769785563151045

Epoch: 6| Step: 12
Training loss: 5.058011531829834
Validation loss: 6.342865387598674

Epoch: 6| Step: 13
Training loss: 6.32082462310791
Validation loss: 6.307563463846843

Epoch: 2| Step: 0
Training loss: 7.6267194747924805
Validation loss: 6.271298170089722

Epoch: 6| Step: 1
Training loss: 6.567531585693359
Validation loss: 6.2364879449208575

Epoch: 6| Step: 2
Training loss: 6.041109561920166
Validation loss: 6.195394357045491

Epoch: 6| Step: 3
Training loss: 6.966080665588379
Validation loss: 6.158495664596558

Epoch: 6| Step: 4
Training loss: 6.267397403717041
Validation loss: 6.114276488622029

Epoch: 6| Step: 5
Training loss: 6.568220615386963
Validation loss: 6.075724442799886

Epoch: 6| Step: 6
Training loss: 4.68548059463501
Validation loss: 6.02990476290385

Epoch: 6| Step: 7
Training loss: 6.254563331604004
Validation loss: 5.981439590454102

Epoch: 6| Step: 8
Training loss: 6.599468231201172
Validation loss: 5.930200576782227

Epoch: 6| Step: 9
Training loss: 5.900586128234863
Validation loss: 5.8772655328114825

Epoch: 6| Step: 10
Training loss: 6.44547176361084
Validation loss: 5.820976098378499

Epoch: 6| Step: 11
Training loss: 4.944685459136963
Validation loss: 5.762120962142944

Epoch: 6| Step: 12
Training loss: 5.867850303649902
Validation loss: 5.697382211685181

Epoch: 6| Step: 13
Training loss: 4.082785606384277
Validation loss: 5.640276908874512

Epoch: 3| Step: 0
Training loss: 4.478846073150635
Validation loss: 5.568433364232381

Epoch: 6| Step: 1
Training loss: 6.081642150878906
Validation loss: 5.499759117762248

Epoch: 6| Step: 2
Training loss: 6.074806213378906
Validation loss: 5.420824368794759

Epoch: 6| Step: 3
Training loss: 6.419285297393799
Validation loss: 5.343875090281169

Epoch: 6| Step: 4
Training loss: 5.298836708068848
Validation loss: 5.260767300923665

Epoch: 6| Step: 5
Training loss: 5.497916221618652
Validation loss: 5.177801291147868

Epoch: 6| Step: 6
Training loss: 6.041162490844727
Validation loss: 5.091781457265218

Epoch: 6| Step: 7
Training loss: 5.545449733734131
Validation loss: 4.991738756497701

Epoch: 6| Step: 8
Training loss: 4.854924201965332
Validation loss: 4.8980090618133545

Epoch: 6| Step: 9
Training loss: 4.851495742797852
Validation loss: 4.792402982711792

Epoch: 6| Step: 10
Training loss: 4.798790454864502
Validation loss: 4.6821292241414385

Epoch: 6| Step: 11
Training loss: 4.076593399047852
Validation loss: 4.5705790519714355

Epoch: 6| Step: 12
Training loss: 3.8130507469177246
Validation loss: 4.461091121037801

Epoch: 6| Step: 13
Training loss: 3.0365748405456543
Validation loss: 4.327232162157695

Epoch: 4| Step: 0
Training loss: 4.335738658905029
Validation loss: 4.19996440410614

Epoch: 6| Step: 1
Training loss: 4.437221527099609
Validation loss: 4.077842275301616

Epoch: 6| Step: 2
Training loss: 4.33921480178833
Validation loss: 3.941893219947815

Epoch: 6| Step: 3
Training loss: 2.725639820098877
Validation loss: 3.806804895401001

Epoch: 6| Step: 4
Training loss: 4.366927623748779
Validation loss: 3.694780786832174

Epoch: 6| Step: 5
Training loss: 3.7151100635528564
Validation loss: 3.5531288782755532

Epoch: 6| Step: 6
Training loss: 2.748762369155884
Validation loss: 3.4281070629755654

Epoch: 6| Step: 7
Training loss: 3.9385883808135986
Validation loss: 3.291283885637919

Epoch: 6| Step: 8
Training loss: 2.094068765640259
Validation loss: 3.1466033458709717

Epoch: 6| Step: 9
Training loss: 2.8312652111053467
Validation loss: 3.012046734491984

Epoch: 6| Step: 10
Training loss: 3.184990167617798
Validation loss: 2.8650006850560508

Epoch: 6| Step: 11
Training loss: 2.2554287910461426
Validation loss: 2.736139456431071

Epoch: 6| Step: 12
Training loss: 2.8861002922058105
Validation loss: 2.6302808125813804

Epoch: 6| Step: 13
Training loss: 3.1326262950897217
Validation loss: 2.5421714584032693

Epoch: 5| Step: 0
Training loss: 2.545966863632202
Validation loss: 2.4562973578770957

Epoch: 6| Step: 1
Training loss: 3.466280460357666
Validation loss: 2.4103984435399375

Epoch: 6| Step: 2
Training loss: 1.6303942203521729
Validation loss: 2.354390303293864

Epoch: 6| Step: 3
Training loss: 2.567303419113159
Validation loss: 2.369040389855703

Epoch: 6| Step: 4
Training loss: 2.1744871139526367
Validation loss: 2.3267699480056763

Epoch: 6| Step: 5
Training loss: 2.4358506202697754
Validation loss: 2.3316871325174966

Epoch: 6| Step: 6
Training loss: 2.096498489379883
Validation loss: 2.335887928803762

Epoch: 6| Step: 7
Training loss: 2.5925068855285645
Validation loss: 2.3389466206232705

Epoch: 6| Step: 8
Training loss: 2.1909375190734863
Validation loss: 2.345237612724304

Epoch: 6| Step: 9
Training loss: 2.0243678092956543
Validation loss: 2.3455522855122886

Epoch: 6| Step: 10
Training loss: 1.9558987617492676
Validation loss: 2.36898144086202

Epoch: 6| Step: 11
Training loss: 1.935161828994751
Validation loss: 2.3428212304910025

Epoch: 6| Step: 12
Training loss: 2.010676145553589
Validation loss: 2.3354315161705017

Epoch: 6| Step: 13
Training loss: 2.4376397132873535
Validation loss: 2.3473132451375327

Epoch: 6| Step: 0
Training loss: 2.2125096321105957
Validation loss: 2.369218091169993

Epoch: 6| Step: 1
Training loss: 1.4188119173049927
Validation loss: 2.3512443701426187

Epoch: 6| Step: 2
Training loss: 2.244443655014038
Validation loss: 2.331891973813375

Epoch: 6| Step: 3
Training loss: 1.896106481552124
Validation loss: 2.3453737099965415

Epoch: 6| Step: 4
Training loss: 2.178966760635376
Validation loss: 2.321523149808248

Epoch: 6| Step: 5
Training loss: 2.2576770782470703
Validation loss: 2.336327870686849

Epoch: 6| Step: 6
Training loss: 1.8491179943084717
Validation loss: 2.305517872174581

Epoch: 6| Step: 7
Training loss: 2.7201390266418457
Validation loss: 2.289298892021179

Epoch: 6| Step: 8
Training loss: 2.5569872856140137
Validation loss: 2.295132040977478

Epoch: 6| Step: 9
Training loss: 2.693685531616211
Validation loss: 2.2749467293421426

Epoch: 6| Step: 10
Training loss: 1.7410528659820557
Validation loss: 2.28377366065979

Epoch: 6| Step: 11
Training loss: 3.310248374938965
Validation loss: 2.2715609073638916

Epoch: 6| Step: 12
Training loss: 2.198268413543701
Validation loss: 2.2774792909622192

Epoch: 6| Step: 13
Training loss: 2.054105281829834
Validation loss: 2.280094623565674

Epoch: 7| Step: 0
Training loss: 2.5475168228149414
Validation loss: 2.2911903063456216

Epoch: 6| Step: 1
Training loss: 3.1281704902648926
Validation loss: 2.2876590887705484

Epoch: 6| Step: 2
Training loss: 1.558240532875061
Validation loss: 2.2910226384798684

Epoch: 6| Step: 3
Training loss: 1.5340254306793213
Validation loss: 2.295572280883789

Epoch: 6| Step: 4
Training loss: 2.0150861740112305
Validation loss: 2.2919240991274514

Epoch: 6| Step: 5
Training loss: 2.483992576599121
Validation loss: 2.3020313580830893

Epoch: 6| Step: 6
Training loss: 2.2986788749694824
Validation loss: 2.3132239977518716

Epoch: 6| Step: 7
Training loss: 2.2216601371765137
Validation loss: 2.2870337764422097

Epoch: 6| Step: 8
Training loss: 2.175136089324951
Validation loss: 2.273542582988739

Epoch: 6| Step: 9
Training loss: 2.303788661956787
Validation loss: 2.267268260320028

Epoch: 6| Step: 10
Training loss: 2.932668685913086
Validation loss: 2.26700230439504

Epoch: 6| Step: 11
Training loss: 1.5875155925750732
Validation loss: 2.2479259967803955

Epoch: 6| Step: 12
Training loss: 1.9091005325317383
Validation loss: 2.268268863360087

Epoch: 6| Step: 13
Training loss: 2.3709828853607178
Validation loss: 2.248535950978597

Epoch: 8| Step: 0
Training loss: 1.5245215892791748
Validation loss: 2.2338271141052246

Epoch: 6| Step: 1
Training loss: 2.1158273220062256
Validation loss: 2.2340643405914307

Epoch: 6| Step: 2
Training loss: 3.1891415119171143
Validation loss: 2.1986723939577737

Epoch: 6| Step: 3
Training loss: 2.340974807739258
Validation loss: 2.2402544816335044

Epoch: 6| Step: 4
Training loss: 2.6869773864746094
Validation loss: 2.217641750971476

Epoch: 6| Step: 5
Training loss: 1.9728437662124634
Validation loss: 2.258270263671875

Epoch: 6| Step: 6
Training loss: 2.8922572135925293
Validation loss: 2.2271352211634317

Epoch: 6| Step: 7
Training loss: 1.4846030473709106
Validation loss: 2.1893065770467124

Epoch: 6| Step: 8
Training loss: 2.0437989234924316
Validation loss: 2.2467612624168396

Epoch: 6| Step: 9
Training loss: 2.122318744659424
Validation loss: 2.2146382331848145

Epoch: 6| Step: 10
Training loss: 1.8204002380371094
Validation loss: 2.236993889013926

Epoch: 6| Step: 11
Training loss: 2.125255584716797
Validation loss: 2.2062419056892395

Epoch: 6| Step: 12
Training loss: 1.584923505783081
Validation loss: 2.2294887701670327

Epoch: 6| Step: 13
Training loss: 2.299848794937134
Validation loss: 2.2122889161109924

Epoch: 9| Step: 0
Training loss: 1.0764933824539185
Validation loss: 2.2125346263249717

Epoch: 6| Step: 1
Training loss: 2.112593650817871
Validation loss: 2.1812657912572226

Epoch: 6| Step: 2
Training loss: 2.878282070159912
Validation loss: 2.1867456436157227

Epoch: 6| Step: 3
Training loss: 2.073930263519287
Validation loss: 2.2195776104927063

Epoch: 6| Step: 4
Training loss: 1.4822869300842285
Validation loss: 2.195131540298462

Epoch: 6| Step: 5
Training loss: 2.6114730834960938
Validation loss: 2.2189273834228516

Epoch: 6| Step: 6
Training loss: 2.161478042602539
Validation loss: 2.1795387268066406

Epoch: 6| Step: 7
Training loss: 2.372926712036133
Validation loss: 2.1921752293904624

Epoch: 6| Step: 8
Training loss: 2.390249729156494
Validation loss: 2.219915529092153

Epoch: 6| Step: 9
Training loss: 2.0324151515960693
Validation loss: 2.204683244228363

Epoch: 6| Step: 10
Training loss: 1.4789358377456665
Validation loss: 2.211455980936686

Epoch: 6| Step: 11
Training loss: 2.4421896934509277
Validation loss: 2.2141554951667786

Epoch: 6| Step: 12
Training loss: 2.603447198867798
Validation loss: 2.2191999355951944

Epoch: 6| Step: 13
Training loss: 2.3153233528137207
Validation loss: 2.227463483810425

Epoch: 10| Step: 0
Training loss: 2.089413642883301
Validation loss: 2.208640535672506

Epoch: 6| Step: 1
Training loss: 2.8382515907287598
Validation loss: 2.201754570007324

Epoch: 6| Step: 2
Training loss: 2.2851009368896484
Validation loss: 2.203149437904358

Epoch: 6| Step: 3
Training loss: 2.3032069206237793
Validation loss: 2.1764031251271567

Epoch: 6| Step: 4
Training loss: 1.6436939239501953
Validation loss: 2.2193467020988464

Epoch: 6| Step: 5
Training loss: 1.9381067752838135
Validation loss: 2.1688158909479776

Epoch: 6| Step: 6
Training loss: 2.9844396114349365
Validation loss: 2.195188522338867

Epoch: 6| Step: 7
Training loss: 2.205409526824951
Validation loss: 2.2013522585233054

Epoch: 6| Step: 8
Training loss: 1.328727126121521
Validation loss: 2.213609536488851

Epoch: 6| Step: 9
Training loss: 1.962613821029663
Validation loss: 2.202816963195801

Epoch: 6| Step: 10
Training loss: 2.6668100357055664
Validation loss: 2.2396523356437683

Epoch: 6| Step: 11
Training loss: 2.5357301235198975
Validation loss: 2.208171546459198

Epoch: 6| Step: 12
Training loss: 1.2628118991851807
Validation loss: 2.18247389793396

Epoch: 6| Step: 13
Training loss: 1.6494600772857666
Validation loss: 2.1823684573173523

Epoch: 11| Step: 0
Training loss: 2.286815881729126
Validation loss: 2.2008469700813293

Epoch: 6| Step: 1
Training loss: 2.2510643005371094
Validation loss: 2.1730812788009644

Epoch: 6| Step: 2
Training loss: 1.7988693714141846
Validation loss: 2.1988555192947388

Epoch: 6| Step: 3
Training loss: 1.951287865638733
Validation loss: 2.1772368351618447

Epoch: 6| Step: 4
Training loss: 2.135434627532959
Validation loss: 2.183754881223043

Epoch: 6| Step: 5
Training loss: 2.27925443649292
Validation loss: 2.162804881731669

Epoch: 6| Step: 6
Training loss: 2.2359683513641357
Validation loss: 2.180590192476908

Epoch: 6| Step: 7
Training loss: 1.6802208423614502
Validation loss: 2.169974207878113

Epoch: 6| Step: 8
Training loss: 2.2798337936401367
Validation loss: 2.164694686730703

Epoch: 6| Step: 9
Training loss: 1.9018768072128296
Validation loss: 2.1925870776176453

Epoch: 6| Step: 10
Training loss: 1.606257677078247
Validation loss: 2.173200090726217

Epoch: 6| Step: 11
Training loss: 1.886929988861084
Validation loss: 2.1799181501070657

Epoch: 6| Step: 12
Training loss: 3.1457812786102295
Validation loss: 2.190623641014099

Epoch: 6| Step: 13
Training loss: 1.7732138633728027
Validation loss: 2.190663675467173

Epoch: 12| Step: 0
Training loss: 1.5458784103393555
Validation loss: 2.170175830523173

Epoch: 6| Step: 1
Training loss: 1.1633493900299072
Validation loss: 2.172420918941498

Epoch: 6| Step: 2
Training loss: 2.2321665287017822
Validation loss: 2.141917069753011

Epoch: 6| Step: 3
Training loss: 2.4610214233398438
Validation loss: 2.2010186314582825

Epoch: 6| Step: 4
Training loss: 1.1608928442001343
Validation loss: 2.1764671405156455

Epoch: 6| Step: 5
Training loss: 1.6577526330947876
Validation loss: 2.2034462094306946

Epoch: 6| Step: 6
Training loss: 1.6698578596115112
Validation loss: 2.2111147244771323

Epoch: 6| Step: 7
Training loss: 1.854539394378662
Validation loss: 2.1863596638043723

Epoch: 6| Step: 8
Training loss: 2.48809552192688
Validation loss: 2.1938323974609375

Epoch: 6| Step: 9
Training loss: 2.3704309463500977
Validation loss: 2.197142541408539

Epoch: 6| Step: 10
Training loss: 2.5029985904693604
Validation loss: 2.171821713447571

Epoch: 6| Step: 11
Training loss: 1.9746730327606201
Validation loss: 2.1726842721303306

Epoch: 6| Step: 12
Training loss: 2.4147562980651855
Validation loss: 2.16724956035614

Epoch: 6| Step: 13
Training loss: 3.3782262802124023
Validation loss: 2.159766932328542

Epoch: 13| Step: 0
Training loss: 2.450774669647217
Validation loss: 2.1686158577601113

Epoch: 6| Step: 1
Training loss: 1.673628807067871
Validation loss: 2.1879266103108725

Epoch: 6| Step: 2
Training loss: 1.3412481546401978
Validation loss: 2.2292036612828574

Epoch: 6| Step: 3
Training loss: 2.5231621265411377
Validation loss: 2.154150446256002

Epoch: 6| Step: 4
Training loss: 2.212965488433838
Validation loss: 2.1987672448158264

Epoch: 6| Step: 5
Training loss: 2.2288360595703125
Validation loss: 2.2229976256688437

Epoch: 6| Step: 6
Training loss: 1.5188281536102295
Validation loss: 2.1809140046437583

Epoch: 6| Step: 7
Training loss: 2.3196566104888916
Validation loss: 2.170890212059021

Epoch: 6| Step: 8
Training loss: 2.3247056007385254
Validation loss: 2.1778137485186257

Epoch: 6| Step: 9
Training loss: 2.7205111980438232
Validation loss: 2.179893732070923

Epoch: 6| Step: 10
Training loss: 1.9640060663223267
Validation loss: 2.1700191100438437

Epoch: 6| Step: 11
Training loss: 1.813178539276123
Validation loss: 2.141035238901774

Epoch: 6| Step: 12
Training loss: 1.938217043876648
Validation loss: 2.1896052161852517

Epoch: 6| Step: 13
Training loss: 1.845770239830017
Validation loss: 2.163471241792043

Epoch: 14| Step: 0
Training loss: 1.3566752672195435
Validation loss: 2.152712027231852

Epoch: 6| Step: 1
Training loss: 3.1878015995025635
Validation loss: 2.2036906083424888

Epoch: 6| Step: 2
Training loss: 1.304934024810791
Validation loss: 2.183056116104126

Epoch: 6| Step: 3
Training loss: 2.004143714904785
Validation loss: 2.206101179122925

Epoch: 6| Step: 4
Training loss: 2.0294442176818848
Validation loss: 2.2045556902885437

Epoch: 6| Step: 5
Training loss: 2.367927074432373
Validation loss: 2.1967169841130576

Epoch: 6| Step: 6
Training loss: 2.2902421951293945
Validation loss: 2.1815326809883118

Epoch: 6| Step: 7
Training loss: 2.928581714630127
Validation loss: 2.1836960713068643

Epoch: 6| Step: 8
Training loss: 2.1428284645080566
Validation loss: 2.156982640425364

Epoch: 6| Step: 9
Training loss: 1.781214952468872
Validation loss: 2.187841773033142

Epoch: 6| Step: 10
Training loss: 2.034857749938965
Validation loss: 2.1938443183898926

Epoch: 6| Step: 11
Training loss: 2.02394437789917
Validation loss: 2.1769150694211326

Epoch: 6| Step: 12
Training loss: 1.3671176433563232
Validation loss: 2.188803732395172

Epoch: 6| Step: 13
Training loss: 1.8859080076217651
Validation loss: 2.184578994909922

Epoch: 15| Step: 0
Training loss: 1.6938291788101196
Validation loss: 2.1669721206029258

Epoch: 6| Step: 1
Training loss: 2.0394322872161865
Validation loss: 2.1944631934165955

Epoch: 6| Step: 2
Training loss: 2.660602569580078
Validation loss: 2.1504560907681785

Epoch: 6| Step: 3
Training loss: 2.076630115509033
Validation loss: 2.2054590384165444

Epoch: 6| Step: 4
Training loss: 2.961386203765869
Validation loss: 2.166222035884857

Epoch: 6| Step: 5
Training loss: 2.0716733932495117
Validation loss: 2.1888989408810935

Epoch: 6| Step: 6
Training loss: 0.9386675357818604
Validation loss: 2.1588820815086365

Epoch: 6| Step: 7
Training loss: 1.9190301895141602
Validation loss: 2.198538303375244

Epoch: 6| Step: 8
Training loss: 1.619652271270752
Validation loss: 2.2026183207829795

Epoch: 6| Step: 9
Training loss: 2.0394630432128906
Validation loss: 2.1923081080118814

Epoch: 6| Step: 10
Training loss: 1.8483625650405884
Validation loss: 2.159096360206604

Epoch: 6| Step: 11
Training loss: 1.802699089050293
Validation loss: 2.141276021798452

Epoch: 6| Step: 12
Training loss: 2.5910749435424805
Validation loss: 2.135814666748047

Epoch: 6| Step: 13
Training loss: 1.7954530715942383
Validation loss: 2.1882291038831077

Epoch: 16| Step: 0
Training loss: 1.991248369216919
Validation loss: 2.2128756443659463

Epoch: 6| Step: 1
Training loss: 1.898141622543335
Validation loss: 2.1860708395640054

Epoch: 6| Step: 2
Training loss: 1.985219955444336
Validation loss: 2.1779475609461465

Epoch: 6| Step: 3
Training loss: 1.9519027471542358
Validation loss: 2.203856408596039

Epoch: 6| Step: 4
Training loss: 1.6264610290527344
Validation loss: 2.173820734024048

Epoch: 6| Step: 5
Training loss: 2.5373096466064453
Validation loss: 2.201761305332184

Epoch: 6| Step: 6
Training loss: 2.5028269290924072
Validation loss: 2.165643294652303

Epoch: 6| Step: 7
Training loss: 2.116492748260498
Validation loss: 2.1896491646766663

Epoch: 6| Step: 8
Training loss: 2.294473648071289
Validation loss: 2.1709673404693604

Epoch: 6| Step: 9
Training loss: 1.9993348121643066
Validation loss: 2.182657778263092

Epoch: 6| Step: 10
Training loss: 1.9274649620056152
Validation loss: 2.192004839579264

Epoch: 6| Step: 11
Training loss: 1.5419347286224365
Validation loss: 2.178178389867147

Epoch: 6| Step: 12
Training loss: 2.075683116912842
Validation loss: 2.1813491582870483

Epoch: 6| Step: 13
Training loss: 2.1203691959381104
Validation loss: 2.17007839679718

Epoch: 17| Step: 0
Training loss: 1.9747264385223389
Validation loss: 2.206313451131185

Epoch: 6| Step: 1
Training loss: 2.475101947784424
Validation loss: 2.187638839085897

Epoch: 6| Step: 2
Training loss: 2.04384183883667
Validation loss: 2.1840585470199585

Epoch: 6| Step: 3
Training loss: 2.0192863941192627
Validation loss: 2.1841716965039573

Epoch: 6| Step: 4
Training loss: 1.6728720664978027
Validation loss: 2.184032956759135

Epoch: 6| Step: 5
Training loss: 2.2503609657287598
Validation loss: 2.1846346060434976

Epoch: 6| Step: 6
Training loss: 2.12684965133667
Validation loss: 2.1456743478775024

Epoch: 6| Step: 7
Training loss: 2.232292413711548
Validation loss: 2.158030907313029

Epoch: 6| Step: 8
Training loss: 1.459277868270874
Validation loss: 2.174405872821808

Epoch: 6| Step: 9
Training loss: 2.0974221229553223
Validation loss: 2.2119147181510925

Epoch: 6| Step: 10
Training loss: 1.9248310327529907
Validation loss: 2.169977605342865

Epoch: 6| Step: 11
Training loss: 1.7086701393127441
Validation loss: 2.1980411609013877

Epoch: 6| Step: 12
Training loss: 1.579052448272705
Validation loss: 2.196688731511434

Epoch: 6| Step: 13
Training loss: 2.543041706085205
Validation loss: 2.1859828432401023

Epoch: 18| Step: 0
Training loss: 1.962662696838379
Validation loss: 2.190912584463755

Epoch: 6| Step: 1
Training loss: 1.8920128345489502
Validation loss: 2.177547017733256

Epoch: 6| Step: 2
Training loss: 2.037825584411621
Validation loss: 2.181111435095469

Epoch: 6| Step: 3
Training loss: 2.0229666233062744
Validation loss: 2.180663804213206

Epoch: 6| Step: 4
Training loss: 2.7154107093811035
Validation loss: 2.1972203652064004

Epoch: 6| Step: 5
Training loss: 1.229341983795166
Validation loss: 2.1851205825805664

Epoch: 6| Step: 6
Training loss: 2.049607753753662
Validation loss: 2.1552704175313315

Epoch: 6| Step: 7
Training loss: 1.782779335975647
Validation loss: 2.195001006126404

Epoch: 6| Step: 8
Training loss: 1.691061019897461
Validation loss: 2.198450724283854

Epoch: 6| Step: 9
Training loss: 1.4445865154266357
Validation loss: 2.196867207686106

Epoch: 6| Step: 10
Training loss: 2.3473048210144043
Validation loss: 2.196023861567179

Epoch: 6| Step: 11
Training loss: 2.328845262527466
Validation loss: 2.1726513703664145

Epoch: 6| Step: 12
Training loss: 2.326249122619629
Validation loss: 2.130606492360433

Epoch: 6| Step: 13
Training loss: 1.7285301685333252
Validation loss: 2.204665939013163

Epoch: 19| Step: 0
Training loss: 2.2571990489959717
Validation loss: 2.1636757055918374

Epoch: 6| Step: 1
Training loss: 1.8341193199157715
Validation loss: 2.1965649922688804

Epoch: 6| Step: 2
Training loss: 1.884050726890564
Validation loss: 2.1868785619735718

Epoch: 6| Step: 3
Training loss: 1.7298853397369385
Validation loss: 2.175517996152242

Epoch: 6| Step: 4
Training loss: 2.2978973388671875
Validation loss: 2.212549110253652

Epoch: 6| Step: 5
Training loss: 1.1532179117202759
Validation loss: 2.2200791438420615

Epoch: 6| Step: 6
Training loss: 2.5254242420196533
Validation loss: 2.177194595336914

Epoch: 6| Step: 7
Training loss: 1.4589083194732666
Validation loss: 2.1951723098754883

Epoch: 6| Step: 8
Training loss: 1.8032528162002563
Validation loss: 2.2190062204996743

Epoch: 6| Step: 9
Training loss: 2.227478504180908
Validation loss: 2.174070735772451

Epoch: 6| Step: 10
Training loss: 2.288093090057373
Validation loss: 2.193173805872599

Epoch: 6| Step: 11
Training loss: 1.5474789142608643
Validation loss: 2.203395982583364

Epoch: 6| Step: 12
Training loss: 2.2644412517547607
Validation loss: 2.2236708402633667

Epoch: 6| Step: 13
Training loss: 2.147273063659668
Validation loss: 2.2068751056989035

Epoch: 20| Step: 0
Training loss: 2.296147346496582
Validation loss: 2.212509791056315

Epoch: 6| Step: 1
Training loss: 2.349362373352051
Validation loss: 2.2033826311429343

Epoch: 6| Step: 2
Training loss: 1.7175428867340088
Validation loss: 2.171584407488505

Epoch: 6| Step: 3
Training loss: 1.532120704650879
Validation loss: 2.178000052769979

Epoch: 6| Step: 4
Training loss: 1.52046799659729
Validation loss: 2.157390534877777

Epoch: 6| Step: 5
Training loss: 1.5517091751098633
Validation loss: 2.178020715713501

Epoch: 6| Step: 6
Training loss: 2.0119948387145996
Validation loss: 2.2158416112264

Epoch: 6| Step: 7
Training loss: 1.8618066310882568
Validation loss: 2.2453577717145285

Epoch: 6| Step: 8
Training loss: 2.7805821895599365
Validation loss: 2.2116780281066895

Epoch: 6| Step: 9
Training loss: 2.5986456871032715
Validation loss: 2.2153486013412476

Epoch: 6| Step: 10
Training loss: 2.6710329055786133
Validation loss: 2.137995719909668

Epoch: 6| Step: 11
Training loss: 1.3972251415252686
Validation loss: 2.1926618814468384

Epoch: 6| Step: 12
Training loss: 2.144289255142212
Validation loss: 2.168339808781942

Epoch: 6| Step: 13
Training loss: 1.7940177917480469
Validation loss: 2.1970836917559304

Epoch: 21| Step: 0
Training loss: 2.7220449447631836
Validation loss: 2.161360800266266

Epoch: 6| Step: 1
Training loss: 1.7453720569610596
Validation loss: 2.1933189630508423

Epoch: 6| Step: 2
Training loss: 1.9532039165496826
Validation loss: 2.1969460447629294

Epoch: 6| Step: 3
Training loss: 2.1172680854797363
Validation loss: 2.2248817880948386

Epoch: 6| Step: 4
Training loss: 1.970857858657837
Validation loss: 2.167401055494944

Epoch: 6| Step: 5
Training loss: 1.5212152004241943
Validation loss: 2.2107759515444436

Epoch: 6| Step: 6
Training loss: 2.7410409450531006
Validation loss: 2.2358933885892234

Epoch: 6| Step: 7
Training loss: 2.01933217048645
Validation loss: 2.217841943105062

Epoch: 6| Step: 8
Training loss: 1.9345608949661255
Validation loss: 2.1888062953948975

Epoch: 6| Step: 9
Training loss: 1.8086066246032715
Validation loss: 2.2202325463294983

Epoch: 6| Step: 10
Training loss: 2.3525705337524414
Validation loss: 2.206489304701487

Epoch: 6| Step: 11
Training loss: 1.6978273391723633
Validation loss: 2.1759453217188516

Epoch: 6| Step: 12
Training loss: 1.8066493272781372
Validation loss: 2.2039632201194763

Epoch: 6| Step: 13
Training loss: 2.0682895183563232
Validation loss: 2.203424572944641

Epoch: 22| Step: 0
Training loss: 1.5184602737426758
Validation loss: 2.1681870222091675

Epoch: 6| Step: 1
Training loss: 1.6561269760131836
Validation loss: 2.2054389317830405

Epoch: 6| Step: 2
Training loss: 1.0939254760742188
Validation loss: 2.2028642098108926

Epoch: 6| Step: 3
Training loss: 2.599940776824951
Validation loss: 2.1850253542264304

Epoch: 6| Step: 4
Training loss: 2.231884479522705
Validation loss: 2.2240092555681863

Epoch: 6| Step: 5
Training loss: 2.6030473709106445
Validation loss: 2.2510242263476052

Epoch: 6| Step: 6
Training loss: 2.5426249504089355
Validation loss: 2.2288166085879006

Epoch: 6| Step: 7
Training loss: 1.4809825420379639
Validation loss: 2.2704067826271057

Epoch: 6| Step: 8
Training loss: 1.8857195377349854
Validation loss: 2.2070640921592712

Epoch: 6| Step: 9
Training loss: 1.1997427940368652
Validation loss: 2.186428884665171

Epoch: 6| Step: 10
Training loss: 2.190742015838623
Validation loss: 2.2221932212511697

Epoch: 6| Step: 11
Training loss: 3.206679105758667
Validation loss: 2.2088324427604675

Epoch: 6| Step: 12
Training loss: 1.3018271923065186
Validation loss: 2.260088642438253

Epoch: 6| Step: 13
Training loss: 2.01374888420105
Validation loss: 2.21769909063975

Epoch: 23| Step: 0
Training loss: 1.965425968170166
Validation loss: 2.176279524962107

Epoch: 6| Step: 1
Training loss: 1.976712703704834
Validation loss: 2.205958147843679

Epoch: 6| Step: 2
Training loss: 1.914318323135376
Validation loss: 2.20427405834198

Epoch: 6| Step: 3
Training loss: 2.027129650115967
Validation loss: 2.1979464888572693

Epoch: 6| Step: 4
Training loss: 2.241644859313965
Validation loss: 2.1760059197743735

Epoch: 6| Step: 5
Training loss: 2.39093017578125
Validation loss: 2.1910405357678733

Epoch: 6| Step: 6
Training loss: 2.329033374786377
Validation loss: 2.2054083943367004

Epoch: 6| Step: 7
Training loss: 2.2119712829589844
Validation loss: 2.1939651568730674

Epoch: 6| Step: 8
Training loss: 1.2701753377914429
Validation loss: 2.1864274740219116

Epoch: 6| Step: 9
Training loss: 1.910283088684082
Validation loss: 2.177351176738739

Epoch: 6| Step: 10
Training loss: 2.1497952938079834
Validation loss: 2.1944645047187805

Epoch: 6| Step: 11
Training loss: 1.9713289737701416
Validation loss: 2.208473285039266

Epoch: 6| Step: 12
Training loss: 1.9909542798995972
Validation loss: 2.1842204332351685

Epoch: 6| Step: 13
Training loss: 1.3806380033493042
Validation loss: 2.226342419783274

Epoch: 24| Step: 0
Training loss: 1.8784462213516235
Validation loss: 2.2014242013295493

Epoch: 6| Step: 1
Training loss: 1.8101458549499512
Validation loss: 2.286007881164551

Epoch: 6| Step: 2
Training loss: 2.4442169666290283
Validation loss: 2.2417975664138794

Epoch: 6| Step: 3
Training loss: 2.2869153022766113
Validation loss: 2.281744639078776

Epoch: 6| Step: 4
Training loss: 1.1465944051742554
Validation loss: 2.2455513079961142

Epoch: 6| Step: 5
Training loss: 1.9981484413146973
Validation loss: 2.217704971631368

Epoch: 6| Step: 6
Training loss: 1.8856022357940674
Validation loss: 2.190817634264628

Epoch: 6| Step: 7
Training loss: 1.9530470371246338
Validation loss: 2.1583215395609536

Epoch: 6| Step: 8
Training loss: 1.7433829307556152
Validation loss: 2.1646206180254617

Epoch: 6| Step: 9
Training loss: 2.2684948444366455
Validation loss: 2.1666312217712402

Epoch: 6| Step: 10
Training loss: 2.0643320083618164
Validation loss: 2.195715328057607

Epoch: 6| Step: 11
Training loss: 1.7770507335662842
Validation loss: 2.194572627544403

Epoch: 6| Step: 12
Training loss: 2.1455960273742676
Validation loss: 2.1940208673477173

Epoch: 6| Step: 13
Training loss: 2.161308526992798
Validation loss: 2.1942376693089805

Epoch: 25| Step: 0
Training loss: 1.7653292417526245
Validation loss: 2.1985726157824197

Epoch: 6| Step: 1
Training loss: 2.2475085258483887
Validation loss: 2.2033872405687966

Epoch: 6| Step: 2
Training loss: 1.582921028137207
Validation loss: 2.1566412647565207

Epoch: 6| Step: 3
Training loss: 1.702174425125122
Validation loss: 2.1414124568303428

Epoch: 6| Step: 4
Training loss: 2.117241859436035
Validation loss: 2.1795227328936257

Epoch: 6| Step: 5
Training loss: 2.487438678741455
Validation loss: 2.225241184234619

Epoch: 6| Step: 6
Training loss: 1.730712652206421
Validation loss: 2.185582717259725

Epoch: 6| Step: 7
Training loss: 2.2207181453704834
Validation loss: 2.1659650007883706

Epoch: 6| Step: 8
Training loss: 1.548971176147461
Validation loss: 2.1862436135609946

Epoch: 6| Step: 9
Training loss: 1.712416172027588
Validation loss: 2.189761459827423

Epoch: 6| Step: 10
Training loss: 1.958723545074463
Validation loss: 2.197008430957794

Epoch: 6| Step: 11
Training loss: 1.456791639328003
Validation loss: 2.21038426955541

Epoch: 6| Step: 12
Training loss: 2.294616222381592
Validation loss: 2.2306655248006186

Epoch: 6| Step: 13
Training loss: 2.226851463317871
Validation loss: 2.2527081966400146

Epoch: 26| Step: 0
Training loss: 1.5675394535064697
Validation loss: 2.229704221089681

Epoch: 6| Step: 1
Training loss: 1.666191816329956
Validation loss: 2.234536131223043

Epoch: 6| Step: 2
Training loss: 1.3587418794631958
Validation loss: 2.195102055867513

Epoch: 6| Step: 3
Training loss: 1.6850178241729736
Validation loss: 2.1588109135627747

Epoch: 6| Step: 4
Training loss: 2.115952253341675
Validation loss: 2.184911032517751

Epoch: 6| Step: 5
Training loss: 2.145540475845337
Validation loss: 2.1837509274482727

Epoch: 6| Step: 6
Training loss: 1.9347665309906006
Validation loss: 2.1883580684661865

Epoch: 6| Step: 7
Training loss: 1.815805435180664
Validation loss: 2.233195881048838

Epoch: 6| Step: 8
Training loss: 1.8879914283752441
Validation loss: 2.17865788936615

Epoch: 6| Step: 9
Training loss: 1.4550402164459229
Validation loss: 2.206422964731852

Epoch: 6| Step: 10
Training loss: 2.0039610862731934
Validation loss: 2.2228836019833884

Epoch: 6| Step: 11
Training loss: 2.5821030139923096
Validation loss: 2.2293482422828674

Epoch: 6| Step: 12
Training loss: 2.1901051998138428
Validation loss: 2.2486441930135093

Epoch: 6| Step: 13
Training loss: 2.9329795837402344
Validation loss: 2.2006359696388245

Epoch: 27| Step: 0
Training loss: 1.7665464878082275
Validation loss: 2.190367261568705

Epoch: 6| Step: 1
Training loss: 1.360733985900879
Validation loss: 2.186358869075775

Epoch: 6| Step: 2
Training loss: 2.141951084136963
Validation loss: 2.1827831268310547

Epoch: 6| Step: 3
Training loss: 1.9098821878433228
Validation loss: 2.2113794883092246

Epoch: 6| Step: 4
Training loss: 2.4285173416137695
Validation loss: 2.2120250264803567

Epoch: 6| Step: 5
Training loss: 1.6437175273895264
Validation loss: 2.191297471523285

Epoch: 6| Step: 6
Training loss: 2.583001136779785
Validation loss: 2.2067392269770303

Epoch: 6| Step: 7
Training loss: 1.4906615018844604
Validation loss: 2.205681006113688

Epoch: 6| Step: 8
Training loss: 1.503613829612732
Validation loss: 2.2206033865610757

Epoch: 6| Step: 9
Training loss: 2.2713398933410645
Validation loss: 2.2499693433443704

Epoch: 6| Step: 10
Training loss: 1.9505178928375244
Validation loss: 2.2203306953112283

Epoch: 6| Step: 11
Training loss: 2.293325662612915
Validation loss: 2.171610256036123

Epoch: 6| Step: 12
Training loss: 1.8838921785354614
Validation loss: 2.2594949205716452

Epoch: 6| Step: 13
Training loss: 2.118004322052002
Validation loss: 2.239153424898783

Epoch: 28| Step: 0
Training loss: 1.8379864692687988
Validation loss: 2.1678682764371238

Epoch: 6| Step: 1
Training loss: 2.1131508350372314
Validation loss: 2.1891891161600747

Epoch: 6| Step: 2
Training loss: 2.2457070350646973
Validation loss: 2.1731255054473877

Epoch: 6| Step: 3
Training loss: 1.6012024879455566
Validation loss: 2.1266851822535195

Epoch: 6| Step: 4
Training loss: 2.061765193939209
Validation loss: 2.2042415340741477

Epoch: 6| Step: 5
Training loss: 1.6858882904052734
Validation loss: 2.1551249424616494

Epoch: 6| Step: 6
Training loss: 2.260186195373535
Validation loss: 2.1975773771603904

Epoch: 6| Step: 7
Training loss: 1.4619582891464233
Validation loss: 2.200416366259257

Epoch: 6| Step: 8
Training loss: 1.7041229009628296
Validation loss: 2.1425691843032837

Epoch: 6| Step: 9
Training loss: 2.0739965438842773
Validation loss: 2.212991416454315

Epoch: 6| Step: 10
Training loss: 1.8453997373580933
Validation loss: 2.189268469810486

Epoch: 6| Step: 11
Training loss: 1.628208875656128
Validation loss: 2.1829197804133096

Epoch: 6| Step: 12
Training loss: 1.6492884159088135
Validation loss: 2.18852166334788

Epoch: 6| Step: 13
Training loss: 2.2773959636688232
Validation loss: 2.2000800172487893

Epoch: 29| Step: 0
Training loss: 1.8980257511138916
Validation loss: 2.237792710463206

Epoch: 6| Step: 1
Training loss: 1.5889499187469482
Validation loss: 2.2244950334231057

Epoch: 6| Step: 2
Training loss: 1.5308732986450195
Validation loss: 2.224813381830851

Epoch: 6| Step: 3
Training loss: 1.200847864151001
Validation loss: 2.2455037236213684

Epoch: 6| Step: 4
Training loss: 2.4801061153411865
Validation loss: 2.251689314842224

Epoch: 6| Step: 5
Training loss: 1.9275130033493042
Validation loss: 2.235869288444519

Epoch: 6| Step: 6
Training loss: 2.335378646850586
Validation loss: 2.1963746349016824

Epoch: 6| Step: 7
Training loss: 2.553386688232422
Validation loss: 2.239858031272888

Epoch: 6| Step: 8
Training loss: 1.6767466068267822
Validation loss: 2.216151237487793

Epoch: 6| Step: 9
Training loss: 2.091776132583618
Validation loss: 2.1580155293146768

Epoch: 6| Step: 10
Training loss: 2.1651525497436523
Validation loss: 2.1852641701698303

Epoch: 6| Step: 11
Training loss: 1.356550931930542
Validation loss: 2.2023494640986123

Epoch: 6| Step: 12
Training loss: 1.9068483114242554
Validation loss: 2.123352587223053

Epoch: 6| Step: 13
Training loss: 2.1491241455078125
Validation loss: 2.215050756931305

Epoch: 30| Step: 0
Training loss: 2.060140609741211
Validation loss: 2.161834259827932

Epoch: 6| Step: 1
Training loss: 1.7796640396118164
Validation loss: 2.1660672624905906

Epoch: 6| Step: 2
Training loss: 1.528449535369873
Validation loss: 2.235135078430176

Epoch: 6| Step: 3
Training loss: 2.124103546142578
Validation loss: 2.163130780061086

Epoch: 6| Step: 4
Training loss: 2.130056619644165
Validation loss: 2.2270697951316833

Epoch: 6| Step: 5
Training loss: 1.4327471256256104
Validation loss: 2.181240499019623

Epoch: 6| Step: 6
Training loss: 1.8236773014068604
Validation loss: 2.2441651026407876

Epoch: 6| Step: 7
Training loss: 1.347463846206665
Validation loss: 2.2419259945551553

Epoch: 6| Step: 8
Training loss: 2.4092183113098145
Validation loss: 2.231114665667216

Epoch: 6| Step: 9
Training loss: 2.1320018768310547
Validation loss: 2.2992426554361978

Epoch: 6| Step: 10
Training loss: 2.6953630447387695
Validation loss: 2.2144223054250083

Epoch: 6| Step: 11
Training loss: 1.9215375185012817
Validation loss: 2.2068973779678345

Epoch: 6| Step: 12
Training loss: 1.9130533933639526
Validation loss: 2.2109427054723105

Epoch: 6| Step: 13
Training loss: 2.149660587310791
Validation loss: 2.2550175388654075

Epoch: 31| Step: 0
Training loss: 2.109109878540039
Validation loss: 2.21257483959198

Epoch: 6| Step: 1
Training loss: 2.3676109313964844
Validation loss: 2.2531703313191733

Epoch: 6| Step: 2
Training loss: 2.6107709407806396
Validation loss: 2.175114850203196

Epoch: 6| Step: 3
Training loss: 1.8762567043304443
Validation loss: 2.1479790409406028

Epoch: 6| Step: 4
Training loss: 1.7398983240127563
Validation loss: 2.1555720567703247

Epoch: 6| Step: 5
Training loss: 1.7612454891204834
Validation loss: 2.2034253080685935

Epoch: 6| Step: 6
Training loss: 1.9752237796783447
Validation loss: 2.2299471298853555

Epoch: 6| Step: 7
Training loss: 2.343280792236328
Validation loss: 2.192952275276184

Epoch: 6| Step: 8
Training loss: 1.558390498161316
Validation loss: 2.174191435178121

Epoch: 6| Step: 9
Training loss: 2.0779781341552734
Validation loss: 2.232464551925659

Epoch: 6| Step: 10
Training loss: 1.8233819007873535
Validation loss: 2.1800530751546225

Epoch: 6| Step: 11
Training loss: 1.607464075088501
Validation loss: 2.1988979975382485

Epoch: 6| Step: 12
Training loss: 1.645117998123169
Validation loss: 2.16740882396698

Epoch: 6| Step: 13
Training loss: 1.5496470928192139
Validation loss: 2.177183210849762

Epoch: 32| Step: 0
Training loss: 2.4467761516571045
Validation loss: 2.186393439769745

Epoch: 6| Step: 1
Training loss: 2.1029372215270996
Validation loss: 2.182351231575012

Epoch: 6| Step: 2
Training loss: 2.1846375465393066
Validation loss: 2.1887079874674478

Epoch: 6| Step: 3
Training loss: 1.4520094394683838
Validation loss: 2.204755107561747

Epoch: 6| Step: 4
Training loss: 1.8692989349365234
Validation loss: 2.2030115922292075

Epoch: 6| Step: 5
Training loss: 1.6759624481201172
Validation loss: 2.2240293423334756

Epoch: 6| Step: 6
Training loss: 1.5467562675476074
Validation loss: 2.207417825857798

Epoch: 6| Step: 7
Training loss: 1.3951306343078613
Validation loss: 2.216130495071411

Epoch: 6| Step: 8
Training loss: 2.139681816101074
Validation loss: 2.1650823752085366

Epoch: 6| Step: 9
Training loss: 1.5415282249450684
Validation loss: 2.214582105477651

Epoch: 6| Step: 10
Training loss: 2.2126002311706543
Validation loss: 2.218050797780355

Epoch: 6| Step: 11
Training loss: 1.6917352676391602
Validation loss: 2.263324777285258

Epoch: 6| Step: 12
Training loss: 2.252080202102661
Validation loss: 2.2780959208806357

Epoch: 6| Step: 13
Training loss: 1.7672734260559082
Validation loss: 2.238446911176046

Epoch: 33| Step: 0
Training loss: 2.0051071643829346
Validation loss: 2.231271723906199

Epoch: 6| Step: 1
Training loss: 1.3458573818206787
Validation loss: 2.165862282117208

Epoch: 6| Step: 2
Training loss: 1.8340688943862915
Validation loss: 2.173200170199076

Epoch: 6| Step: 3
Training loss: 2.137477159500122
Validation loss: 2.1989403565724692

Epoch: 6| Step: 4
Training loss: 2.3056368827819824
Validation loss: 2.2181639472643533

Epoch: 6| Step: 5
Training loss: 2.069337844848633
Validation loss: 2.205163757006327

Epoch: 6| Step: 6
Training loss: 1.7678543329238892
Validation loss: 2.2510100603103638

Epoch: 6| Step: 7
Training loss: 1.6448132991790771
Validation loss: 2.204656938711802

Epoch: 6| Step: 8
Training loss: 1.1976532936096191
Validation loss: 2.2241265376408896

Epoch: 6| Step: 9
Training loss: 1.8590154647827148
Validation loss: 2.188007632891337

Epoch: 6| Step: 10
Training loss: 1.83095121383667
Validation loss: 2.1668533285458884

Epoch: 6| Step: 11
Training loss: 1.676070213317871
Validation loss: 2.227540910243988

Epoch: 6| Step: 12
Training loss: 1.4390528202056885
Validation loss: 2.2008623282114663

Epoch: 6| Step: 13
Training loss: 3.020496368408203
Validation loss: 2.138647476832072

Epoch: 34| Step: 0
Training loss: 1.6525529623031616
Validation loss: 2.1933078368504844

Epoch: 6| Step: 1
Training loss: 1.9704701900482178
Validation loss: 2.2228278716405234

Epoch: 6| Step: 2
Training loss: 1.2548543214797974
Validation loss: 2.2294859091440835

Epoch: 6| Step: 3
Training loss: 2.23390531539917
Validation loss: 2.16398294766744

Epoch: 6| Step: 4
Training loss: 1.4862067699432373
Validation loss: 2.147382438182831

Epoch: 6| Step: 5
Training loss: 1.9228005409240723
Validation loss: 2.2013747692108154

Epoch: 6| Step: 6
Training loss: 1.4077757596969604
Validation loss: 2.215968688329061

Epoch: 6| Step: 7
Training loss: 1.1436991691589355
Validation loss: 2.201760768890381

Epoch: 6| Step: 8
Training loss: 2.6352975368499756
Validation loss: 2.177836815516154

Epoch: 6| Step: 9
Training loss: 2.5060174465179443
Validation loss: 2.253844916820526

Epoch: 6| Step: 10
Training loss: 2.2093286514282227
Validation loss: 2.238824268182119

Epoch: 6| Step: 11
Training loss: 2.145793914794922
Validation loss: 2.245261470476786

Epoch: 6| Step: 12
Training loss: 1.8311738967895508
Validation loss: 2.1792219082514444

Epoch: 6| Step: 13
Training loss: 1.5949757099151611
Validation loss: 2.1750599344571433

Epoch: 35| Step: 0
Training loss: 2.0110397338867188
Validation loss: 2.2121483087539673

Epoch: 6| Step: 1
Training loss: 1.4940106868743896
Validation loss: 2.216319719950358

Epoch: 6| Step: 2
Training loss: 1.7047255039215088
Validation loss: 2.1826496918996177

Epoch: 6| Step: 3
Training loss: 2.4287543296813965
Validation loss: 2.2387213110923767

Epoch: 6| Step: 4
Training loss: 2.222100257873535
Validation loss: 2.220426062742869

Epoch: 6| Step: 5
Training loss: 2.286597967147827
Validation loss: 2.2587833404541016

Epoch: 6| Step: 6
Training loss: 1.2528173923492432
Validation loss: 2.248340646425883

Epoch: 6| Step: 7
Training loss: 2.3325884342193604
Validation loss: 2.21614662806193

Epoch: 6| Step: 8
Training loss: 1.2616605758666992
Validation loss: 2.21699595451355

Epoch: 6| Step: 9
Training loss: 1.6737284660339355
Validation loss: 2.1748637358347573

Epoch: 6| Step: 10
Training loss: 2.178915500640869
Validation loss: 2.143782099088033

Epoch: 6| Step: 11
Training loss: 2.12253475189209
Validation loss: 2.2104543447494507

Epoch: 6| Step: 12
Training loss: 1.7272560596466064
Validation loss: 2.2187205950419107

Epoch: 6| Step: 13
Training loss: 1.2879866361618042
Validation loss: 2.2385651667912803

Epoch: 36| Step: 0
Training loss: 2.088038444519043
Validation loss: 2.1817718545595803

Epoch: 6| Step: 1
Training loss: 1.6133606433868408
Validation loss: 2.1888463695844016

Epoch: 6| Step: 2
Training loss: 1.6290814876556396
Validation loss: 2.1889023184776306

Epoch: 6| Step: 3
Training loss: 1.7054888010025024
Validation loss: 2.2151355346043906

Epoch: 6| Step: 4
Training loss: 2.35123872756958
Validation loss: 2.1713435848553977

Epoch: 6| Step: 5
Training loss: 1.9306105375289917
Validation loss: 2.1961869597434998

Epoch: 6| Step: 6
Training loss: 1.588050127029419
Validation loss: 2.26235024134318

Epoch: 6| Step: 7
Training loss: 1.187178373336792
Validation loss: 2.2283268769582114

Epoch: 6| Step: 8
Training loss: 2.366182565689087
Validation loss: 2.219925045967102

Epoch: 6| Step: 9
Training loss: 2.749971866607666
Validation loss: 2.235201418399811

Epoch: 6| Step: 10
Training loss: 1.8466389179229736
Validation loss: 2.202144225438436

Epoch: 6| Step: 11
Training loss: 2.045056104660034
Validation loss: 2.18682324886322

Epoch: 6| Step: 12
Training loss: 2.15161395072937
Validation loss: 2.1636949380238852

Epoch: 6| Step: 13
Training loss: 1.2713299989700317
Validation loss: 2.2318798700968423

Epoch: 37| Step: 0
Training loss: 1.586557149887085
Validation loss: 2.211966951688131

Epoch: 6| Step: 1
Training loss: 2.1082863807678223
Validation loss: 2.2044758399327598

Epoch: 6| Step: 2
Training loss: 2.5287740230560303
Validation loss: 2.2312251130739846

Epoch: 6| Step: 3
Training loss: 1.3571429252624512
Validation loss: 2.266326685746511

Epoch: 6| Step: 4
Training loss: 1.5522809028625488
Validation loss: 2.2308202187220254

Epoch: 6| Step: 5
Training loss: 1.525536060333252
Validation loss: 2.1868195136388144

Epoch: 6| Step: 6
Training loss: 2.126675605773926
Validation loss: 2.1874420642852783

Epoch: 6| Step: 7
Training loss: 2.1184802055358887
Validation loss: 2.2087085247039795

Epoch: 6| Step: 8
Training loss: 1.9136854410171509
Validation loss: 2.2155925035476685

Epoch: 6| Step: 9
Training loss: 1.617844581604004
Validation loss: 2.2074532906214395

Epoch: 6| Step: 10
Training loss: 1.743776798248291
Validation loss: 2.1657535235087075

Epoch: 6| Step: 11
Training loss: 1.9558641910552979
Validation loss: 2.260895927747091

Epoch: 6| Step: 12
Training loss: 2.464553117752075
Validation loss: 2.2319502035776773

Epoch: 6| Step: 13
Training loss: 1.3603723049163818
Validation loss: 2.2128015955289206

Epoch: 38| Step: 0
Training loss: 1.5011920928955078
Validation loss: 2.2258983651796975

Epoch: 6| Step: 1
Training loss: 1.5035572052001953
Validation loss: 2.235531528790792

Epoch: 6| Step: 2
Training loss: 1.2189956903457642
Validation loss: 2.2540560563405356

Epoch: 6| Step: 3
Training loss: 2.3436999320983887
Validation loss: 2.2234418988227844

Epoch: 6| Step: 4
Training loss: 1.7876503467559814
Validation loss: 2.2600207328796387

Epoch: 6| Step: 5
Training loss: 2.1682112216949463
Validation loss: 2.175895651181539

Epoch: 6| Step: 6
Training loss: 2.1761701107025146
Validation loss: 2.2423393527666726

Epoch: 6| Step: 7
Training loss: 2.066537618637085
Validation loss: 2.245885133743286

Epoch: 6| Step: 8
Training loss: 2.0558834075927734
Validation loss: 2.1928173104921975

Epoch: 6| Step: 9
Training loss: 1.9468276500701904
Validation loss: 2.2241594990094504

Epoch: 6| Step: 10
Training loss: 1.8458704948425293
Validation loss: 2.2134929100672402

Epoch: 6| Step: 11
Training loss: 1.763158917427063
Validation loss: 2.2278000911076865

Epoch: 6| Step: 12
Training loss: 1.4998419284820557
Validation loss: 2.224502603212992

Epoch: 6| Step: 13
Training loss: 1.733195424079895
Validation loss: 2.297103921572367

Epoch: 39| Step: 0
Training loss: 1.810370922088623
Validation loss: 2.199209729830424

Epoch: 6| Step: 1
Training loss: 1.9715516567230225
Validation loss: 2.2113630175590515

Epoch: 6| Step: 2
Training loss: 1.5000641345977783
Validation loss: 2.258746027946472

Epoch: 6| Step: 3
Training loss: 1.742795467376709
Validation loss: 2.272412419319153

Epoch: 6| Step: 4
Training loss: 2.0070247650146484
Validation loss: 2.2275056640307107

Epoch: 6| Step: 5
Training loss: 2.0642473697662354
Validation loss: 2.2213106950124106

Epoch: 6| Step: 6
Training loss: 1.4819626808166504
Validation loss: 2.1680278380711875

Epoch: 6| Step: 7
Training loss: 1.6784909963607788
Validation loss: 2.187124947706858

Epoch: 6| Step: 8
Training loss: 1.8743897676467896
Validation loss: 2.265075365702311

Epoch: 6| Step: 9
Training loss: 1.8075313568115234
Validation loss: 2.2847655415534973

Epoch: 6| Step: 10
Training loss: 2.401768445968628
Validation loss: 2.327938497066498

Epoch: 6| Step: 11
Training loss: 2.0501320362091064
Validation loss: 2.291591544946035

Epoch: 6| Step: 12
Training loss: 1.8908636569976807
Validation loss: 2.24390701452891

Epoch: 6| Step: 13
Training loss: 1.9645087718963623
Validation loss: 2.1998260617256165

Epoch: 40| Step: 0
Training loss: 1.6408545970916748
Validation loss: 2.173415700594584

Epoch: 6| Step: 1
Training loss: 1.373415470123291
Validation loss: 2.232699453830719

Epoch: 6| Step: 2
Training loss: 1.5737355947494507
Validation loss: 2.171137730280558

Epoch: 6| Step: 3
Training loss: 1.7258394956588745
Validation loss: 2.2078738808631897

Epoch: 6| Step: 4
Training loss: 2.1636714935302734
Validation loss: 2.181317170461019

Epoch: 6| Step: 5
Training loss: 2.63920259475708
Validation loss: 2.2195940812428794

Epoch: 6| Step: 6
Training loss: 1.6347103118896484
Validation loss: 2.217176596323649

Epoch: 6| Step: 7
Training loss: 2.3155884742736816
Validation loss: 2.189076522986094

Epoch: 6| Step: 8
Training loss: 1.57328462600708
Validation loss: 2.229467193285624

Epoch: 6| Step: 9
Training loss: 2.022188425064087
Validation loss: 2.1833773454030356

Epoch: 6| Step: 10
Training loss: 2.307964324951172
Validation loss: 2.256066699822744

Epoch: 6| Step: 11
Training loss: 1.2499152421951294
Validation loss: 2.1933783690134683

Epoch: 6| Step: 12
Training loss: 2.062514543533325
Validation loss: 2.176979045073191

Epoch: 6| Step: 13
Training loss: 1.6814136505126953
Validation loss: 2.2242738405863443

Epoch: 41| Step: 0
Training loss: 1.6972601413726807
Validation loss: 2.2056643962860107

Epoch: 6| Step: 1
Training loss: 2.3066940307617188
Validation loss: 2.1650648514429727

Epoch: 6| Step: 2
Training loss: 1.4891105890274048
Validation loss: 2.215186595916748

Epoch: 6| Step: 3
Training loss: 1.80521559715271
Validation loss: 2.2308619022369385

Epoch: 6| Step: 4
Training loss: 1.004525899887085
Validation loss: 2.23513925075531

Epoch: 6| Step: 5
Training loss: 1.9356169700622559
Validation loss: 2.148449977238973

Epoch: 6| Step: 6
Training loss: 1.8152475357055664
Validation loss: 2.171357810497284

Epoch: 6| Step: 7
Training loss: 1.698108196258545
Validation loss: 2.2022631764411926

Epoch: 6| Step: 8
Training loss: 1.2758089303970337
Validation loss: 2.2523632645606995

Epoch: 6| Step: 9
Training loss: 2.7114946842193604
Validation loss: 2.182551324367523

Epoch: 6| Step: 10
Training loss: 1.8702387809753418
Validation loss: 2.220134913921356

Epoch: 6| Step: 11
Training loss: 2.0919277667999268
Validation loss: 2.1488602558771768

Epoch: 6| Step: 12
Training loss: 1.6581212282180786
Validation loss: 2.1787595550219216

Epoch: 6| Step: 13
Training loss: 1.7346826791763306
Validation loss: 2.1782420873641968

Epoch: 42| Step: 0
Training loss: 1.5464057922363281
Validation loss: 2.1753713885943093

Epoch: 6| Step: 1
Training loss: 1.7016026973724365
Validation loss: 2.257981240749359

Epoch: 6| Step: 2
Training loss: 1.4779093265533447
Validation loss: 2.2074830333391824

Epoch: 6| Step: 3
Training loss: 1.427599549293518
Validation loss: 2.2352406779925027

Epoch: 6| Step: 4
Training loss: 1.5407130718231201
Validation loss: 2.257951041062673

Epoch: 6| Step: 5
Training loss: 2.036375045776367
Validation loss: 2.233664790789286

Epoch: 6| Step: 6
Training loss: 2.141036033630371
Validation loss: 2.2225622733434043

Epoch: 6| Step: 7
Training loss: 1.7392957210540771
Validation loss: 2.255896011988322

Epoch: 6| Step: 8
Training loss: 2.086376190185547
Validation loss: 2.23641437292099

Epoch: 6| Step: 9
Training loss: 1.36137855052948
Validation loss: 2.2461072405179343

Epoch: 6| Step: 10
Training loss: 2.2626121044158936
Validation loss: 2.2493347922960916

Epoch: 6| Step: 11
Training loss: 2.524528980255127
Validation loss: 2.2680419087409973

Epoch: 6| Step: 12
Training loss: 2.016662836074829
Validation loss: 2.1838584542274475

Epoch: 6| Step: 13
Training loss: 1.2081525325775146
Validation loss: 2.238352874914805

Epoch: 43| Step: 0
Training loss: 2.316967487335205
Validation loss: 2.271802842617035

Epoch: 6| Step: 1
Training loss: 1.9760515689849854
Validation loss: 2.3029870788256326

Epoch: 6| Step: 2
Training loss: 1.6844428777694702
Validation loss: 2.3394909699757895

Epoch: 6| Step: 3
Training loss: 2.570572853088379
Validation loss: 2.247802436351776

Epoch: 6| Step: 4
Training loss: 1.2434369325637817
Validation loss: 2.239791134993235

Epoch: 6| Step: 5
Training loss: 1.6271204948425293
Validation loss: 2.191942552725474

Epoch: 6| Step: 6
Training loss: 1.9551748037338257
Validation loss: 2.2289669712384543

Epoch: 6| Step: 7
Training loss: 1.7048028707504272
Validation loss: 2.207406977812449

Epoch: 6| Step: 8
Training loss: 1.498986005783081
Validation loss: 2.2672214905420938

Epoch: 6| Step: 9
Training loss: 2.1169464588165283
Validation loss: 2.2518433928489685

Epoch: 6| Step: 10
Training loss: 1.6616623401641846
Validation loss: 2.314560373624166

Epoch: 6| Step: 11
Training loss: 1.8617888689041138
Validation loss: 2.2732146978378296

Epoch: 6| Step: 12
Training loss: 1.866651177406311
Validation loss: 2.303133249282837

Epoch: 6| Step: 13
Training loss: 2.4642117023468018
Validation loss: 2.2557976444562278

Epoch: 44| Step: 0
Training loss: 1.1014933586120605
Validation loss: 2.276348372300466

Epoch: 6| Step: 1
Training loss: 1.7717840671539307
Validation loss: 2.2120962738990784

Epoch: 6| Step: 2
Training loss: 2.441659688949585
Validation loss: 2.2395633459091187

Epoch: 6| Step: 3
Training loss: 2.056993007659912
Validation loss: 2.207102656364441

Epoch: 6| Step: 4
Training loss: 1.4414129257202148
Validation loss: 2.307461758454641

Epoch: 6| Step: 5
Training loss: 2.104888916015625
Validation loss: 2.252268215020498

Epoch: 6| Step: 6
Training loss: 1.23842191696167
Validation loss: 2.2140328884124756

Epoch: 6| Step: 7
Training loss: 1.5044853687286377
Validation loss: 2.224200745423635

Epoch: 6| Step: 8
Training loss: 1.853165626525879
Validation loss: 2.210321386655172

Epoch: 6| Step: 9
Training loss: 2.572000503540039
Validation loss: 2.166636129220327

Epoch: 6| Step: 10
Training loss: 1.7700750827789307
Validation loss: 2.301833192507426

Epoch: 6| Step: 11
Training loss: 2.622145891189575
Validation loss: 2.2043974002202353

Epoch: 6| Step: 12
Training loss: 1.7369939088821411
Validation loss: 2.2247705856959024

Epoch: 6| Step: 13
Training loss: 1.5778207778930664
Validation loss: 2.269663135210673

Epoch: 45| Step: 0
Training loss: 2.1477296352386475
Validation loss: 2.2305040756861367

Epoch: 6| Step: 1
Training loss: 1.3291757106781006
Validation loss: 2.293984532356262

Epoch: 6| Step: 2
Training loss: 2.096477508544922
Validation loss: 2.3118120630582175

Epoch: 6| Step: 3
Training loss: 2.017368793487549
Validation loss: 2.284913659095764

Epoch: 6| Step: 4
Training loss: 2.445005416870117
Validation loss: 2.23292084534963

Epoch: 6| Step: 5
Training loss: 1.5976603031158447
Validation loss: 2.2912343740463257

Epoch: 6| Step: 6
Training loss: 1.6273713111877441
Validation loss: 2.2788435419400535

Epoch: 6| Step: 7
Training loss: 1.937760353088379
Validation loss: 2.23788321018219

Epoch: 6| Step: 8
Training loss: 1.582240343093872
Validation loss: 2.238814572493235

Epoch: 6| Step: 9
Training loss: 1.6162049770355225
Validation loss: 2.2037364641825357

Epoch: 6| Step: 10
Training loss: 1.4357725381851196
Validation loss: 2.196499307950338

Epoch: 6| Step: 11
Training loss: 1.6317170858383179
Validation loss: 2.2447280883789062

Epoch: 6| Step: 12
Training loss: 1.777827262878418
Validation loss: 2.18000320593516

Epoch: 6| Step: 13
Training loss: 1.7867385149002075
Validation loss: 2.1647632916768393

Epoch: 46| Step: 0
Training loss: 2.4595770835876465
Validation loss: 2.220723589261373

Epoch: 6| Step: 1
Training loss: 1.6841793060302734
Validation loss: 2.2040807207425437

Epoch: 6| Step: 2
Training loss: 2.317007303237915
Validation loss: 2.1560112635294595

Epoch: 6| Step: 3
Training loss: 2.1385326385498047
Validation loss: 2.2220075130462646

Epoch: 6| Step: 4
Training loss: 1.1127865314483643
Validation loss: 2.192384680112203

Epoch: 6| Step: 5
Training loss: 1.7320044040679932
Validation loss: 2.215056916077932

Epoch: 6| Step: 6
Training loss: 2.077986717224121
Validation loss: 2.19507489601771

Epoch: 6| Step: 7
Training loss: 1.7646046876907349
Validation loss: 2.203223387400309

Epoch: 6| Step: 8
Training loss: 1.939507246017456
Validation loss: 2.251916527748108

Epoch: 6| Step: 9
Training loss: 1.6834839582443237
Validation loss: 2.2346673806508384

Epoch: 6| Step: 10
Training loss: 1.8591278791427612
Validation loss: 2.178773502508799

Epoch: 6| Step: 11
Training loss: 1.6736443042755127
Validation loss: 2.1529486179351807

Epoch: 6| Step: 12
Training loss: 1.5873332023620605
Validation loss: 2.218300779660543

Epoch: 6| Step: 13
Training loss: 1.0619045495986938
Validation loss: 2.2038103143374124

Epoch: 47| Step: 0
Training loss: 2.0392391681671143
Validation loss: 2.2463568846384683

Epoch: 6| Step: 1
Training loss: 1.5554877519607544
Validation loss: 2.2273566325505576

Epoch: 6| Step: 2
Training loss: 1.5933997631072998
Validation loss: 2.288353602091471

Epoch: 6| Step: 3
Training loss: 1.281052589416504
Validation loss: 2.2235769232114158

Epoch: 6| Step: 4
Training loss: 1.2397702932357788
Validation loss: 2.190954327583313

Epoch: 6| Step: 5
Training loss: 1.1172360181808472
Validation loss: 2.3352602124214172

Epoch: 6| Step: 6
Training loss: 2.268726348876953
Validation loss: 2.261182427406311

Epoch: 6| Step: 7
Training loss: 2.407602071762085
Validation loss: 2.320537726084391

Epoch: 6| Step: 8
Training loss: 0.8130990862846375
Validation loss: 2.2615267038345337

Epoch: 6| Step: 9
Training loss: 1.8808660507202148
Validation loss: 2.204655965169271

Epoch: 6| Step: 10
Training loss: 2.2603702545166016
Validation loss: 2.2788010239601135

Epoch: 6| Step: 11
Training loss: 2.1299288272857666
Validation loss: 2.257197598616282

Epoch: 6| Step: 12
Training loss: 1.7195016145706177
Validation loss: 2.27108363310496

Epoch: 6| Step: 13
Training loss: 2.749182939529419
Validation loss: 2.3157850901285806

Epoch: 48| Step: 0
Training loss: 1.1235488653182983
Validation loss: 2.2251581947008767

Epoch: 6| Step: 1
Training loss: 2.073852300643921
Validation loss: 2.2231446901957193

Epoch: 6| Step: 2
Training loss: 1.7839657068252563
Validation loss: 2.2627358039220176

Epoch: 6| Step: 3
Training loss: 1.373368263244629
Validation loss: 2.205094575881958

Epoch: 6| Step: 4
Training loss: 1.9010213613510132
Validation loss: 2.2522599697113037

Epoch: 6| Step: 5
Training loss: 1.731221318244934
Validation loss: 2.227542519569397

Epoch: 6| Step: 6
Training loss: 2.0872411727905273
Validation loss: 2.244099815686544

Epoch: 6| Step: 7
Training loss: 1.4567945003509521
Validation loss: 2.2448801596959433

Epoch: 6| Step: 8
Training loss: 1.415560007095337
Validation loss: 2.2099978725115457

Epoch: 6| Step: 9
Training loss: 1.101058006286621
Validation loss: 2.190114974975586

Epoch: 6| Step: 10
Training loss: 1.7410396337509155
Validation loss: 2.2121899326642356

Epoch: 6| Step: 11
Training loss: 2.371615409851074
Validation loss: 2.2820330460866294

Epoch: 6| Step: 12
Training loss: 2.128000259399414
Validation loss: 2.2505714893341064

Epoch: 6| Step: 13
Training loss: 2.4737396240234375
Validation loss: 2.2500553528467813

Epoch: 49| Step: 0
Training loss: 1.3221217393875122
Validation loss: 2.260496139526367

Epoch: 6| Step: 1
Training loss: 2.172806739807129
Validation loss: 2.2636690934499106

Epoch: 6| Step: 2
Training loss: 1.1130554676055908
Validation loss: 2.2668240070343018

Epoch: 6| Step: 3
Training loss: 2.0017096996307373
Validation loss: 2.2459787329037986

Epoch: 6| Step: 4
Training loss: 1.873677372932434
Validation loss: 2.346057673295339

Epoch: 6| Step: 5
Training loss: 2.357377290725708
Validation loss: 2.2445470293362937

Epoch: 6| Step: 6
Training loss: 2.070413589477539
Validation loss: 2.3233020504315696

Epoch: 6| Step: 7
Training loss: 1.3687570095062256
Validation loss: 2.290210207303365

Epoch: 6| Step: 8
Training loss: 1.328477144241333
Validation loss: 2.2476454178492227

Epoch: 6| Step: 9
Training loss: 2.0848984718322754
Validation loss: 2.2291667262713113

Epoch: 6| Step: 10
Training loss: 1.4158644676208496
Validation loss: 2.224784334500631

Epoch: 6| Step: 11
Training loss: 1.6996393203735352
Validation loss: 2.2389347155888877

Epoch: 6| Step: 12
Training loss: 2.170036792755127
Validation loss: 2.2320422927538552

Epoch: 6| Step: 13
Training loss: 1.9369744062423706
Validation loss: 2.2529044349988303

Epoch: 50| Step: 0
Training loss: 1.726418375968933
Validation loss: 2.2731812397638955

Epoch: 6| Step: 1
Training loss: 1.7271932363510132
Validation loss: 2.291391452153524

Epoch: 6| Step: 2
Training loss: 1.6688082218170166
Validation loss: 2.2649342020352683

Epoch: 6| Step: 3
Training loss: 1.6006555557250977
Validation loss: 2.274066607157389

Epoch: 6| Step: 4
Training loss: 1.8572022914886475
Validation loss: 2.2706752816836038

Epoch: 6| Step: 5
Training loss: 2.5085361003875732
Validation loss: 2.1695321997006736

Epoch: 6| Step: 6
Training loss: 2.7222743034362793
Validation loss: 2.178280750910441

Epoch: 6| Step: 7
Training loss: 1.5949820280075073
Validation loss: 2.361655076344808

Epoch: 6| Step: 8
Training loss: 1.5841848850250244
Validation loss: 2.2143837213516235

Epoch: 6| Step: 9
Training loss: 1.7284915447235107
Validation loss: 2.321585694948832

Epoch: 6| Step: 10
Training loss: 1.3476274013519287
Validation loss: 2.277693589528402

Epoch: 6| Step: 11
Training loss: 2.067563772201538
Validation loss: 2.2990779081980386

Epoch: 6| Step: 12
Training loss: 1.75825834274292
Validation loss: 2.222731669743856

Epoch: 6| Step: 13
Training loss: 1.636671543121338
Validation loss: 2.292216499646505

Epoch: 51| Step: 0
Training loss: 1.6166632175445557
Validation loss: 2.177526116371155

Epoch: 6| Step: 1
Training loss: 1.4350017309188843
Validation loss: 2.2238796949386597

Epoch: 6| Step: 2
Training loss: 1.9880077838897705
Validation loss: 2.1886667013168335

Epoch: 6| Step: 3
Training loss: 1.2432539463043213
Validation loss: 2.188775638739268

Epoch: 6| Step: 4
Training loss: 1.7542692422866821
Validation loss: 2.2541839480400085

Epoch: 6| Step: 5
Training loss: 1.7348448038101196
Validation loss: 2.1670424143473306

Epoch: 6| Step: 6
Training loss: 1.8647675514221191
Validation loss: 2.239910622437795

Epoch: 6| Step: 7
Training loss: 1.5528770685195923
Validation loss: 2.163864334424337

Epoch: 6| Step: 8
Training loss: 2.0475707054138184
Validation loss: 2.2195512652397156

Epoch: 6| Step: 9
Training loss: 1.7283180952072144
Validation loss: 2.1895747979482016

Epoch: 6| Step: 10
Training loss: 1.8418104648590088
Validation loss: 2.2879269123077393

Epoch: 6| Step: 11
Training loss: 1.9987757205963135
Validation loss: 2.282395601272583

Epoch: 6| Step: 12
Training loss: 1.7297017574310303
Validation loss: 2.3328611850738525

Epoch: 6| Step: 13
Training loss: 1.6066138744354248
Validation loss: 2.2732539971669516

Epoch: 52| Step: 0
Training loss: 1.6987091302871704
Validation loss: 2.3220303853352866

Epoch: 6| Step: 1
Training loss: 1.6903127431869507
Validation loss: 2.2512896259625754

Epoch: 6| Step: 2
Training loss: 2.3745758533477783
Validation loss: 2.244659423828125

Epoch: 6| Step: 3
Training loss: 2.1476621627807617
Validation loss: 2.307458221912384

Epoch: 6| Step: 4
Training loss: 1.5696959495544434
Validation loss: 2.29268878698349

Epoch: 6| Step: 5
Training loss: 2.258284091949463
Validation loss: 2.2282972733179727

Epoch: 6| Step: 6
Training loss: 1.4245846271514893
Validation loss: 2.254307587941488

Epoch: 6| Step: 7
Training loss: 1.9845985174179077
Validation loss: 2.277949591477712

Epoch: 6| Step: 8
Training loss: 1.4104020595550537
Validation loss: 2.2521918217341104

Epoch: 6| Step: 9
Training loss: 1.2101690769195557
Validation loss: 2.2147105932235718

Epoch: 6| Step: 10
Training loss: 1.6399909257888794
Validation loss: 2.281224846839905

Epoch: 6| Step: 11
Training loss: 1.3134785890579224
Validation loss: 2.2063724199930825

Epoch: 6| Step: 12
Training loss: 1.797131061553955
Validation loss: 2.325203816095988

Epoch: 6| Step: 13
Training loss: 1.574254035949707
Validation loss: 2.255678137143453

Epoch: 53| Step: 0
Training loss: 1.8084371089935303
Validation loss: 2.254606604576111

Epoch: 6| Step: 1
Training loss: 1.8415687084197998
Validation loss: 2.288870374361674

Epoch: 6| Step: 2
Training loss: 2.1754565238952637
Validation loss: 2.2404271562894187

Epoch: 6| Step: 3
Training loss: 1.809830665588379
Validation loss: 2.246484657128652

Epoch: 6| Step: 4
Training loss: 1.080581545829773
Validation loss: 2.2669745683670044

Epoch: 6| Step: 5
Training loss: 1.1886413097381592
Validation loss: 2.2659913102785745

Epoch: 6| Step: 6
Training loss: 2.4111812114715576
Validation loss: 2.224605659643809

Epoch: 6| Step: 7
Training loss: 1.930776834487915
Validation loss: 2.303171992301941

Epoch: 6| Step: 8
Training loss: 2.099052906036377
Validation loss: 2.242037296295166

Epoch: 6| Step: 9
Training loss: 1.4830641746520996
Validation loss: 2.3051846623420715

Epoch: 6| Step: 10
Training loss: 1.5967612266540527
Validation loss: 2.2662964860598245

Epoch: 6| Step: 11
Training loss: 1.723970890045166
Validation loss: 2.286631226539612

Epoch: 6| Step: 12
Training loss: 1.6396117210388184
Validation loss: 2.333665589491526

Epoch: 6| Step: 13
Training loss: 1.653429627418518
Validation loss: 2.286659916241964

Epoch: 54| Step: 0
Training loss: 1.4424209594726562
Validation loss: 2.264125386873881

Epoch: 6| Step: 1
Training loss: 1.6185188293457031
Validation loss: 2.3231915632883706

Epoch: 6| Step: 2
Training loss: 2.0524325370788574
Validation loss: 2.250374674797058

Epoch: 6| Step: 3
Training loss: 1.9755356311798096
Validation loss: 2.2667831579844155

Epoch: 6| Step: 4
Training loss: 1.7083110809326172
Validation loss: 2.24516761302948

Epoch: 6| Step: 5
Training loss: 1.9419057369232178
Validation loss: 2.2324046889940896

Epoch: 6| Step: 6
Training loss: 1.489506483078003
Validation loss: 2.1829002499580383

Epoch: 6| Step: 7
Training loss: 2.2395355701446533
Validation loss: 2.2023093899091086

Epoch: 6| Step: 8
Training loss: 1.5037362575531006
Validation loss: 2.3198973337809243

Epoch: 6| Step: 9
Training loss: 1.982057809829712
Validation loss: 2.308231234550476

Epoch: 6| Step: 10
Training loss: 1.7819993495941162
Validation loss: 2.3312155405680337

Epoch: 6| Step: 11
Training loss: 1.609983205795288
Validation loss: 2.2660707036654153

Epoch: 6| Step: 12
Training loss: 1.6997272968292236
Validation loss: 2.1792587836583457

Epoch: 6| Step: 13
Training loss: 2.150423288345337
Validation loss: 2.2259479562441506

Epoch: 55| Step: 0
Training loss: 1.4294713735580444
Validation loss: 2.2390595277150473

Epoch: 6| Step: 1
Training loss: 1.6532758474349976
Validation loss: 2.2312666972478232

Epoch: 6| Step: 2
Training loss: 2.0145604610443115
Validation loss: 2.3631473779678345

Epoch: 6| Step: 3
Training loss: 1.459536075592041
Validation loss: 2.3720197677612305

Epoch: 6| Step: 4
Training loss: 2.8106579780578613
Validation loss: 2.376287798086802

Epoch: 6| Step: 5
Training loss: 1.4313281774520874
Validation loss: 2.4119266271591187

Epoch: 6| Step: 6
Training loss: 2.200076103210449
Validation loss: 2.429381271203359

Epoch: 6| Step: 7
Training loss: 2.210671901702881
Validation loss: 2.3421883980433145

Epoch: 6| Step: 8
Training loss: 1.716507077217102
Validation loss: 2.384571691354116

Epoch: 6| Step: 9
Training loss: 2.073361873626709
Validation loss: 2.3235370914141336

Epoch: 6| Step: 10
Training loss: 1.767293930053711
Validation loss: 2.2350680828094482

Epoch: 6| Step: 11
Training loss: 1.908676266670227
Validation loss: 2.170522073904673

Epoch: 6| Step: 12
Training loss: 1.0683224201202393
Validation loss: 2.2482799291610718

Epoch: 6| Step: 13
Training loss: 1.4730167388916016
Validation loss: 2.2187347213427224

Epoch: 56| Step: 0
Training loss: 2.301144599914551
Validation loss: 2.2641656597455344

Epoch: 6| Step: 1
Training loss: 1.8242700099945068
Validation loss: 2.2799216906229653

Epoch: 6| Step: 2
Training loss: 1.6212457418441772
Validation loss: 2.266947567462921

Epoch: 6| Step: 3
Training loss: 2.184410333633423
Validation loss: 2.213556965192159

Epoch: 6| Step: 4
Training loss: 1.5969921350479126
Validation loss: 2.2258947491645813

Epoch: 6| Step: 5
Training loss: 1.9442903995513916
Validation loss: 2.2098713715871177

Epoch: 6| Step: 6
Training loss: 1.4429641962051392
Validation loss: 2.227264682451884

Epoch: 6| Step: 7
Training loss: 1.5993824005126953
Validation loss: 2.173463523387909

Epoch: 6| Step: 8
Training loss: 1.7293524742126465
Validation loss: 2.2573335766792297

Epoch: 6| Step: 9
Training loss: 1.2806546688079834
Validation loss: 2.264171520868937

Epoch: 6| Step: 10
Training loss: 1.305027961730957
Validation loss: 2.313559075196584

Epoch: 6| Step: 11
Training loss: 1.628582239151001
Validation loss: 2.31381885210673

Epoch: 6| Step: 12
Training loss: 2.536590576171875
Validation loss: 2.34691313902537

Epoch: 6| Step: 13
Training loss: 2.008633613586426
Validation loss: 2.2739147742589316

Epoch: 57| Step: 0
Training loss: 1.2378504276275635
Validation loss: 2.283414681752523

Epoch: 6| Step: 1
Training loss: 2.3702192306518555
Validation loss: 2.163728713989258

Epoch: 6| Step: 2
Training loss: 1.7211987972259521
Validation loss: 2.2178697188695273

Epoch: 6| Step: 3
Training loss: 1.4629006385803223
Validation loss: 2.2576944629351297

Epoch: 6| Step: 4
Training loss: 1.3843899965286255
Validation loss: 2.166635493437449

Epoch: 6| Step: 5
Training loss: 1.9445888996124268
Validation loss: 2.190179149309794

Epoch: 6| Step: 6
Training loss: 2.396193265914917
Validation loss: 2.248432000478109

Epoch: 6| Step: 7
Training loss: 2.1681838035583496
Validation loss: 2.218710780143738

Epoch: 6| Step: 8
Training loss: 1.8461171388626099
Validation loss: 2.1797295808792114

Epoch: 6| Step: 9
Training loss: 1.081920862197876
Validation loss: 2.2316868702570596

Epoch: 6| Step: 10
Training loss: 1.4769761562347412
Validation loss: 2.199404259522756

Epoch: 6| Step: 11
Training loss: 1.6740734577178955
Validation loss: 2.242631415526072

Epoch: 6| Step: 12
Training loss: 1.404567837715149
Validation loss: 2.2730745474497476

Epoch: 6| Step: 13
Training loss: 1.9204245805740356
Validation loss: 2.220871110757192

Epoch: 58| Step: 0
Training loss: 1.2863199710845947
Validation loss: 2.2035361925760903

Epoch: 6| Step: 1
Training loss: 1.4700915813446045
Validation loss: 2.192775011062622

Epoch: 6| Step: 2
Training loss: 2.156766414642334
Validation loss: 2.225378851095835

Epoch: 6| Step: 3
Training loss: 1.1334223747253418
Validation loss: 2.28038881222407

Epoch: 6| Step: 4
Training loss: 1.8588457107543945
Validation loss: 2.23183274269104

Epoch: 6| Step: 5
Training loss: 1.6533303260803223
Validation loss: 2.3184802532196045

Epoch: 6| Step: 6
Training loss: 2.229552745819092
Validation loss: 2.265863021214803

Epoch: 6| Step: 7
Training loss: 2.1604716777801514
Validation loss: 2.2386117776234946

Epoch: 6| Step: 8
Training loss: 1.2388572692871094
Validation loss: 2.231842279434204

Epoch: 6| Step: 9
Training loss: 1.5014500617980957
Validation loss: 2.2535397013028464

Epoch: 6| Step: 10
Training loss: 2.2015540599823
Validation loss: 2.194933076699575

Epoch: 6| Step: 11
Training loss: 1.5274765491485596
Validation loss: 2.1780943870544434

Epoch: 6| Step: 12
Training loss: 1.7119152545928955
Validation loss: 2.2291892369588218

Epoch: 6| Step: 13
Training loss: 2.101006031036377
Validation loss: 2.236097276210785

Epoch: 59| Step: 0
Training loss: 1.0284419059753418
Validation loss: 2.237107833226522

Epoch: 6| Step: 1
Training loss: 1.5421514511108398
Validation loss: 2.154078722000122

Epoch: 6| Step: 2
Training loss: 2.161958694458008
Validation loss: 2.2101919054985046

Epoch: 6| Step: 3
Training loss: 1.563955545425415
Validation loss: 2.180301090081533

Epoch: 6| Step: 4
Training loss: 1.6145691871643066
Validation loss: 2.229007442792257

Epoch: 6| Step: 5
Training loss: 2.495375156402588
Validation loss: 2.2237252394358316

Epoch: 6| Step: 6
Training loss: 2.0469541549682617
Validation loss: 2.215778172016144

Epoch: 6| Step: 7
Training loss: 2.1329593658447266
Validation loss: 2.229988674322764

Epoch: 6| Step: 8
Training loss: 1.7144341468811035
Validation loss: 2.219490647315979

Epoch: 6| Step: 9
Training loss: 1.6925184726715088
Validation loss: 2.2163995107014975

Epoch: 6| Step: 10
Training loss: 1.9294226169586182
Validation loss: 2.1956469416618347

Epoch: 6| Step: 11
Training loss: 1.046951413154602
Validation loss: 2.2787832816441855

Epoch: 6| Step: 12
Training loss: 1.5020815134048462
Validation loss: 2.260256032148997

Epoch: 6| Step: 13
Training loss: 1.8565053939819336
Validation loss: 2.248930513858795

Epoch: 60| Step: 0
Training loss: 1.2889608144760132
Validation loss: 2.2269968390464783

Epoch: 6| Step: 1
Training loss: 1.8106086254119873
Validation loss: 2.2584398786226907

Epoch: 6| Step: 2
Training loss: 1.4741626977920532
Validation loss: 2.218170404434204

Epoch: 6| Step: 3
Training loss: 0.9130764603614807
Validation loss: 2.2285365660985312

Epoch: 6| Step: 4
Training loss: 1.7197905778884888
Validation loss: 2.334503173828125

Epoch: 6| Step: 5
Training loss: 1.6719342470169067
Validation loss: 2.2854318022727966

Epoch: 6| Step: 6
Training loss: 1.8039062023162842
Validation loss: 2.2472116351127625

Epoch: 6| Step: 7
Training loss: 2.141103744506836
Validation loss: 2.2358059088389077

Epoch: 6| Step: 8
Training loss: 2.258666515350342
Validation loss: 2.2225073973337808

Epoch: 6| Step: 9
Training loss: 1.5437438488006592
Validation loss: 2.2994438012441

Epoch: 6| Step: 10
Training loss: 2.195596218109131
Validation loss: 2.3168220122655234

Epoch: 6| Step: 11
Training loss: 1.4758970737457275
Validation loss: 2.3006081183751426

Epoch: 6| Step: 12
Training loss: 2.0056076049804688
Validation loss: 2.2940420707066855

Epoch: 6| Step: 13
Training loss: 1.5896637439727783
Validation loss: 2.2863648732503257

Epoch: 61| Step: 0
Training loss: 1.6113399267196655
Validation loss: 2.2787384192148843

Epoch: 6| Step: 1
Training loss: 1.1666886806488037
Validation loss: 2.2244083285331726

Epoch: 6| Step: 2
Training loss: 1.7325570583343506
Validation loss: 2.178067445755005

Epoch: 6| Step: 3
Training loss: 1.6637701988220215
Validation loss: 2.2337610920270285

Epoch: 6| Step: 4
Training loss: 1.4504945278167725
Validation loss: 2.2466931343078613

Epoch: 6| Step: 5
Training loss: 1.2120468616485596
Validation loss: 2.2496111392974854

Epoch: 6| Step: 6
Training loss: 1.8923832178115845
Validation loss: 2.222037414709727

Epoch: 6| Step: 7
Training loss: 1.9809037446975708
Validation loss: 2.279276410738627

Epoch: 6| Step: 8
Training loss: 2.555361747741699
Validation loss: 2.220749298731486

Epoch: 6| Step: 9
Training loss: 2.281160593032837
Validation loss: 2.2381792465845742

Epoch: 6| Step: 10
Training loss: 1.6576776504516602
Validation loss: 2.3080243865648904

Epoch: 6| Step: 11
Training loss: 1.436903953552246
Validation loss: 2.241175413131714

Epoch: 6| Step: 12
Training loss: 1.3145036697387695
Validation loss: 2.2622644503911338

Epoch: 6| Step: 13
Training loss: 1.7516677379608154
Validation loss: 2.2378384669621787

Epoch: 62| Step: 0
Training loss: 0.6855090856552124
Validation loss: 2.2571788231531777

Epoch: 6| Step: 1
Training loss: 1.5448365211486816
Validation loss: 2.2399543722470603

Epoch: 6| Step: 2
Training loss: 1.7110559940338135
Validation loss: 2.2049620350201926

Epoch: 6| Step: 3
Training loss: 1.5466828346252441
Validation loss: 2.2137802640597024

Epoch: 6| Step: 4
Training loss: 1.8627851009368896
Validation loss: 2.231609284877777

Epoch: 6| Step: 5
Training loss: 1.9252680540084839
Validation loss: 2.1809562842051187

Epoch: 6| Step: 6
Training loss: 1.7308480739593506
Validation loss: 2.257559816042582

Epoch: 6| Step: 7
Training loss: 3.3306267261505127
Validation loss: 2.2795979181925454

Epoch: 6| Step: 8
Training loss: 1.4493873119354248
Validation loss: 2.2796825567881265

Epoch: 6| Step: 9
Training loss: 2.2044341564178467
Validation loss: 2.294285515944163

Epoch: 6| Step: 10
Training loss: 1.9218273162841797
Validation loss: 2.350541432698568

Epoch: 6| Step: 11
Training loss: 1.795440435409546
Validation loss: 2.3580246766408286

Epoch: 6| Step: 12
Training loss: 1.9361892938613892
Validation loss: 2.3250362873077393

Epoch: 6| Step: 13
Training loss: 1.104709267616272
Validation loss: 2.1939661105473838

Epoch: 63| Step: 0
Training loss: 1.7552261352539062
Validation loss: 2.2411869963010154

Epoch: 6| Step: 1
Training loss: 1.8350476026535034
Validation loss: 2.2355628410975137

Epoch: 6| Step: 2
Training loss: 1.6025586128234863
Validation loss: 2.242082337538401

Epoch: 6| Step: 3
Training loss: 1.5636060237884521
Validation loss: 2.175699313481649

Epoch: 6| Step: 4
Training loss: 1.4508450031280518
Validation loss: 2.2550183534622192

Epoch: 6| Step: 5
Training loss: 1.2225761413574219
Validation loss: 2.229853332042694

Epoch: 6| Step: 6
Training loss: 1.6060858964920044
Validation loss: 2.2466130455334983

Epoch: 6| Step: 7
Training loss: 2.472538709640503
Validation loss: 2.1722070972124734

Epoch: 6| Step: 8
Training loss: 1.6275606155395508
Validation loss: 2.187405506769816

Epoch: 6| Step: 9
Training loss: 1.9734792709350586
Validation loss: 2.2371977965037027

Epoch: 6| Step: 10
Training loss: 1.3932355642318726
Validation loss: 2.2324192126592

Epoch: 6| Step: 11
Training loss: 1.0927181243896484
Validation loss: 2.266063610712687

Epoch: 6| Step: 12
Training loss: 2.0429892539978027
Validation loss: 2.211536784966787

Epoch: 6| Step: 13
Training loss: 2.239858627319336
Validation loss: 2.2012619376182556

Epoch: 64| Step: 0
Training loss: 1.6257638931274414
Validation loss: 2.2686673998832703

Epoch: 6| Step: 1
Training loss: 1.1835464239120483
Validation loss: 2.2117691040039062

Epoch: 6| Step: 2
Training loss: 1.9004244804382324
Validation loss: 2.2127461433410645

Epoch: 6| Step: 3
Training loss: 1.9771597385406494
Validation loss: 2.337742646535238

Epoch: 6| Step: 4
Training loss: 2.008336067199707
Validation loss: 2.234886884689331

Epoch: 6| Step: 5
Training loss: 1.551684856414795
Validation loss: 2.2988868753115335

Epoch: 6| Step: 6
Training loss: 1.6573467254638672
Validation loss: 2.269236385822296

Epoch: 6| Step: 7
Training loss: 2.035813093185425
Validation loss: 2.254498024781545

Epoch: 6| Step: 8
Training loss: 1.3736358880996704
Validation loss: 2.284128467241923

Epoch: 6| Step: 9
Training loss: 1.5748920440673828
Validation loss: 2.2504815459251404

Epoch: 6| Step: 10
Training loss: 1.3487099409103394
Validation loss: 2.2011983593304953

Epoch: 6| Step: 11
Training loss: 1.1905333995819092
Validation loss: 2.1687025229136148

Epoch: 6| Step: 12
Training loss: 1.5613144636154175
Validation loss: 2.1912362774213157

Epoch: 6| Step: 13
Training loss: 1.9558303356170654
Validation loss: 2.223634660243988

Epoch: 65| Step: 0
Training loss: 1.3797006607055664
Validation loss: 2.1881655057271323

Epoch: 6| Step: 1
Training loss: 1.6692267656326294
Validation loss: 2.225296060244242

Epoch: 6| Step: 2
Training loss: 1.8501324653625488
Validation loss: 2.2065216700236

Epoch: 6| Step: 3
Training loss: 1.0237120389938354
Validation loss: 2.2118611335754395

Epoch: 6| Step: 4
Training loss: 1.6437361240386963
Validation loss: 2.229997396469116

Epoch: 6| Step: 5
Training loss: 1.8147469758987427
Validation loss: 2.2418272693951926

Epoch: 6| Step: 6
Training loss: 1.8523536920547485
Validation loss: 2.2883543372154236

Epoch: 6| Step: 7
Training loss: 1.5987037420272827
Validation loss: 2.3092899719874063

Epoch: 6| Step: 8
Training loss: 1.2355303764343262
Validation loss: 2.3388899167378745

Epoch: 6| Step: 9
Training loss: 2.712113857269287
Validation loss: 2.3168214360872903

Epoch: 6| Step: 10
Training loss: 1.4446794986724854
Validation loss: 2.2284209529558816

Epoch: 6| Step: 11
Training loss: 1.339226484298706
Validation loss: 2.278286019961039

Epoch: 6| Step: 12
Training loss: 1.5298932790756226
Validation loss: 2.2140490412712097

Epoch: 6| Step: 13
Training loss: 2.047545909881592
Validation loss: 2.201891283194224

Epoch: 66| Step: 0
Training loss: 1.0196187496185303
Validation loss: 2.2390403151512146

Epoch: 6| Step: 1
Training loss: 1.7966110706329346
Validation loss: 2.248098929723104

Epoch: 6| Step: 2
Training loss: 2.211453676223755
Validation loss: 2.1570312778155007

Epoch: 6| Step: 3
Training loss: 1.0830849409103394
Validation loss: 2.2447389364242554

Epoch: 6| Step: 4
Training loss: 1.9226782321929932
Validation loss: 2.2631532748540244

Epoch: 6| Step: 5
Training loss: 1.7788269519805908
Validation loss: 2.2711827953656516

Epoch: 6| Step: 6
Training loss: 1.8002195358276367
Validation loss: 2.1935903827349343

Epoch: 6| Step: 7
Training loss: 1.7091361284255981
Validation loss: 2.22712242603302

Epoch: 6| Step: 8
Training loss: 1.5332252979278564
Validation loss: 2.1610567371050515

Epoch: 6| Step: 9
Training loss: 1.3377046585083008
Validation loss: 2.2710450291633606

Epoch: 6| Step: 10
Training loss: 1.8348026275634766
Validation loss: 2.2725154161453247

Epoch: 6| Step: 11
Training loss: 1.8433171510696411
Validation loss: 2.3451178471247354

Epoch: 6| Step: 12
Training loss: 1.9140766859054565
Validation loss: 2.359733780225118

Epoch: 6| Step: 13
Training loss: 1.4898431301116943
Validation loss: 2.3708966771761575

Epoch: 67| Step: 0
Training loss: 1.1616445779800415
Validation loss: 2.408626616001129

Epoch: 6| Step: 1
Training loss: 1.7379310131072998
Validation loss: 2.3712831139564514

Epoch: 6| Step: 2
Training loss: 2.3799490928649902
Validation loss: 2.327425539493561

Epoch: 6| Step: 3
Training loss: 1.8430395126342773
Validation loss: 2.3057639400164285

Epoch: 6| Step: 4
Training loss: 1.0094947814941406
Validation loss: 2.249480108420054

Epoch: 6| Step: 5
Training loss: 2.541140079498291
Validation loss: 2.1798112392425537

Epoch: 6| Step: 6
Training loss: 1.527734398841858
Validation loss: 2.1856366395950317

Epoch: 6| Step: 7
Training loss: 2.3301877975463867
Validation loss: 2.2878399093945823

Epoch: 6| Step: 8
Training loss: 1.4361493587493896
Validation loss: 2.3163930773735046

Epoch: 6| Step: 9
Training loss: 1.4676904678344727
Validation loss: 2.2322123050689697

Epoch: 6| Step: 10
Training loss: 1.7518789768218994
Validation loss: 2.344513237476349

Epoch: 6| Step: 11
Training loss: 1.1196377277374268
Validation loss: 2.261307636896769

Epoch: 6| Step: 12
Training loss: 2.3308627605438232
Validation loss: 2.228317399819692

Epoch: 6| Step: 13
Training loss: 1.2001454830169678
Validation loss: 2.2807342807451882

Epoch: 68| Step: 0
Training loss: 2.3166487216949463
Validation loss: 2.2552661299705505

Epoch: 6| Step: 1
Training loss: 2.224844455718994
Validation loss: 2.307669480641683

Epoch: 6| Step: 2
Training loss: 1.528113603591919
Validation loss: 2.268303712209066

Epoch: 6| Step: 3
Training loss: 1.1588869094848633
Validation loss: 2.2613062262535095

Epoch: 6| Step: 4
Training loss: 1.2397596836090088
Validation loss: 2.2816709677378335

Epoch: 6| Step: 5
Training loss: 2.0239570140838623
Validation loss: 2.2813982566197715

Epoch: 6| Step: 6
Training loss: 1.384443759918213
Validation loss: 2.228604177633921

Epoch: 6| Step: 7
Training loss: 1.51124107837677
Validation loss: 2.255849758783976

Epoch: 6| Step: 8
Training loss: 1.05721914768219
Validation loss: 2.1827339132626853

Epoch: 6| Step: 9
Training loss: 1.3300657272338867
Validation loss: 2.171231726805369

Epoch: 6| Step: 10
Training loss: 1.2518975734710693
Validation loss: 2.16083953777949

Epoch: 6| Step: 11
Training loss: 2.1297426223754883
Validation loss: 2.17002139488856

Epoch: 6| Step: 12
Training loss: 1.559312343597412
Validation loss: 2.1571316719055176

Epoch: 6| Step: 13
Training loss: 1.7252304553985596
Validation loss: 2.276396155357361

Epoch: 69| Step: 0
Training loss: 1.4109236001968384
Validation loss: 2.145307461420695

Epoch: 6| Step: 1
Training loss: 2.0067172050476074
Validation loss: 2.2154407302538552

Epoch: 6| Step: 2
Training loss: 1.826180100440979
Validation loss: 2.233812391757965

Epoch: 6| Step: 3
Training loss: 1.3541442155838013
Validation loss: 2.244090418020884

Epoch: 6| Step: 4
Training loss: 2.3916990756988525
Validation loss: 2.210811734199524

Epoch: 6| Step: 5
Training loss: 0.9817546606063843
Validation loss: 2.225905199845632

Epoch: 6| Step: 6
Training loss: 2.1297812461853027
Validation loss: 2.2449245055516562

Epoch: 6| Step: 7
Training loss: 1.0062581300735474
Validation loss: 2.1480454802513123

Epoch: 6| Step: 8
Training loss: 1.1105546951293945
Validation loss: 2.248369256655375

Epoch: 6| Step: 9
Training loss: 1.6741920709609985
Validation loss: 2.266736626625061

Epoch: 6| Step: 10
Training loss: 1.6705093383789062
Validation loss: 2.257184306780497

Epoch: 6| Step: 11
Training loss: 1.7795988321304321
Validation loss: 2.288302938143412

Epoch: 6| Step: 12
Training loss: 1.6490436792373657
Validation loss: 2.316810210545858

Epoch: 6| Step: 13
Training loss: 1.350294828414917
Validation loss: 2.2025907039642334

Epoch: 70| Step: 0
Training loss: 1.9208879470825195
Validation loss: 2.240884224573771

Epoch: 6| Step: 1
Training loss: 1.3179495334625244
Validation loss: 2.189701199531555

Epoch: 6| Step: 2
Training loss: 1.3730103969573975
Validation loss: 2.204343597094218

Epoch: 6| Step: 3
Training loss: 2.0173773765563965
Validation loss: 2.189041872819265

Epoch: 6| Step: 4
Training loss: 1.4183979034423828
Validation loss: 2.1905943155288696

Epoch: 6| Step: 5
Training loss: 1.4949164390563965
Validation loss: 2.233492990334829

Epoch: 6| Step: 6
Training loss: 1.307631492614746
Validation loss: 2.2410576542218528

Epoch: 6| Step: 7
Training loss: 1.5497792959213257
Validation loss: 2.205594619115194

Epoch: 6| Step: 8
Training loss: 1.6164729595184326
Validation loss: 2.1962496042251587

Epoch: 6| Step: 9
Training loss: 1.2450932264328003
Validation loss: 2.2280853589375815

Epoch: 6| Step: 10
Training loss: 2.0198850631713867
Validation loss: 2.261361320813497

Epoch: 6| Step: 11
Training loss: 1.7216999530792236
Validation loss: 2.2461366852124534

Epoch: 6| Step: 12
Training loss: 1.4445332288742065
Validation loss: 2.2626483837763467

Epoch: 6| Step: 13
Training loss: 2.1350879669189453
Validation loss: 2.2368826468785605

Epoch: 71| Step: 0
Training loss: 1.5648797750473022
Validation loss: 2.2547998627026877

Epoch: 6| Step: 1
Training loss: 2.341740131378174
Validation loss: 2.17365155617396

Epoch: 6| Step: 2
Training loss: 1.862921953201294
Validation loss: 2.1743669509887695

Epoch: 6| Step: 3
Training loss: 1.1038402318954468
Validation loss: 2.208888073762258

Epoch: 6| Step: 4
Training loss: 1.3744852542877197
Validation loss: 2.2363848884900412

Epoch: 6| Step: 5
Training loss: 1.1367725133895874
Validation loss: 2.224197745323181

Epoch: 6| Step: 6
Training loss: 1.5013036727905273
Validation loss: 2.27858297030131

Epoch: 6| Step: 7
Training loss: 1.8934321403503418
Validation loss: 2.2760688066482544

Epoch: 6| Step: 8
Training loss: 1.6259620189666748
Validation loss: 2.303768754005432

Epoch: 6| Step: 9
Training loss: 1.5437707901000977
Validation loss: 2.265958587328593

Epoch: 6| Step: 10
Training loss: 1.1284719705581665
Validation loss: 2.2373188734054565

Epoch: 6| Step: 11
Training loss: 1.4780079126358032
Validation loss: 2.2163711190223694

Epoch: 6| Step: 12
Training loss: 1.8922595977783203
Validation loss: 2.2376910050710044

Epoch: 6| Step: 13
Training loss: 2.221301555633545
Validation loss: 2.26764182249705

Epoch: 72| Step: 0
Training loss: 1.0710009336471558
Validation loss: 2.2322062452634177

Epoch: 6| Step: 1
Training loss: 1.4462597370147705
Validation loss: 2.2466036478678384

Epoch: 6| Step: 2
Training loss: 1.4109046459197998
Validation loss: 2.2311017314592996

Epoch: 6| Step: 3
Training loss: 1.7650189399719238
Validation loss: 2.2148077487945557

Epoch: 6| Step: 4
Training loss: 1.891085147857666
Validation loss: 2.2040218909581504

Epoch: 6| Step: 5
Training loss: 1.0547363758087158
Validation loss: 2.27355694770813

Epoch: 6| Step: 6
Training loss: 1.6377158164978027
Validation loss: 2.251432478427887

Epoch: 6| Step: 7
Training loss: 1.6841306686401367
Validation loss: 2.1995214223861694

Epoch: 6| Step: 8
Training loss: 2.0994937419891357
Validation loss: 2.2446240981419883

Epoch: 6| Step: 9
Training loss: 1.8531839847564697
Validation loss: 2.2458469470342

Epoch: 6| Step: 10
Training loss: 1.3759702444076538
Validation loss: 2.161269207795461

Epoch: 6| Step: 11
Training loss: 1.7298142910003662
Validation loss: 2.2526395320892334

Epoch: 6| Step: 12
Training loss: 1.5575135946273804
Validation loss: 2.1777204275131226

Epoch: 6| Step: 13
Training loss: 1.3478939533233643
Validation loss: 2.2949727177619934

Epoch: 73| Step: 0
Training loss: 1.751457691192627
Validation loss: 2.2727344234784446

Epoch: 6| Step: 1
Training loss: 1.4273631572723389
Validation loss: 2.2691356341044107

Epoch: 6| Step: 2
Training loss: 1.0425827503204346
Validation loss: 2.2094042698542276

Epoch: 6| Step: 3
Training loss: 1.7789876461029053
Validation loss: 2.199287394682566

Epoch: 6| Step: 4
Training loss: 1.5412299633026123
Validation loss: 2.1998831828435264

Epoch: 6| Step: 5
Training loss: 1.1791949272155762
Validation loss: 2.215754528840383

Epoch: 6| Step: 6
Training loss: 1.277942419052124
Validation loss: 2.206586023171743

Epoch: 6| Step: 7
Training loss: 1.7942532300949097
Validation loss: 2.2280852794647217

Epoch: 6| Step: 8
Training loss: 1.710864543914795
Validation loss: 2.2339158256848655

Epoch: 6| Step: 9
Training loss: 1.6135625839233398
Validation loss: 2.232155899206797

Epoch: 6| Step: 10
Training loss: 1.199247121810913
Validation loss: 2.241563101609548

Epoch: 6| Step: 11
Training loss: 1.5635883808135986
Validation loss: 2.2722829977671304

Epoch: 6| Step: 12
Training loss: 1.8815419673919678
Validation loss: 2.31510059038798

Epoch: 6| Step: 13
Training loss: 2.065659761428833
Validation loss: 2.2429035305976868

Epoch: 74| Step: 0
Training loss: 1.2493896484375
Validation loss: 2.2582739194234214

Epoch: 6| Step: 1
Training loss: 1.9858283996582031
Validation loss: 2.305738111337026

Epoch: 6| Step: 2
Training loss: 2.2181766033172607
Validation loss: 2.2656341989835105

Epoch: 6| Step: 3
Training loss: 1.7312464714050293
Validation loss: 2.217613101005554

Epoch: 6| Step: 4
Training loss: 1.5810933113098145
Validation loss: 2.2467581033706665

Epoch: 6| Step: 5
Training loss: 1.6480798721313477
Validation loss: 2.2780717809995017

Epoch: 6| Step: 6
Training loss: 1.4365307092666626
Validation loss: 2.314229965209961

Epoch: 6| Step: 7
Training loss: 0.8197457194328308
Validation loss: 2.281627655029297

Epoch: 6| Step: 8
Training loss: 1.883582353591919
Validation loss: 2.2671576539675393

Epoch: 6| Step: 9
Training loss: 1.38899564743042
Validation loss: 2.2314209938049316

Epoch: 6| Step: 10
Training loss: 1.3202921152114868
Validation loss: 2.2897136211395264

Epoch: 6| Step: 11
Training loss: 1.4933295249938965
Validation loss: 2.2032554546991983

Epoch: 6| Step: 12
Training loss: 1.1002392768859863
Validation loss: 2.1424394051233926

Epoch: 6| Step: 13
Training loss: 1.4290783405303955
Validation loss: 2.1776973406473794

Epoch: 75| Step: 0
Training loss: 1.718813180923462
Validation loss: 2.2120087146759033

Epoch: 6| Step: 1
Training loss: 1.2920610904693604
Validation loss: 2.1634459495544434

Epoch: 6| Step: 2
Training loss: 1.4524219036102295
Validation loss: 2.2379721800486245

Epoch: 6| Step: 3
Training loss: 1.5179872512817383
Validation loss: 2.190606196721395

Epoch: 6| Step: 4
Training loss: 2.088144302368164
Validation loss: 2.2092658480008445

Epoch: 6| Step: 5
Training loss: 1.461585521697998
Validation loss: 2.275844673315684

Epoch: 6| Step: 6
Training loss: 1.7184443473815918
Validation loss: 2.219252069791158

Epoch: 6| Step: 7
Training loss: 2.1241455078125
Validation loss: 2.2894477049509683

Epoch: 6| Step: 8
Training loss: 1.9672499895095825
Validation loss: 2.2878971298535666

Epoch: 6| Step: 9
Training loss: 1.7124158143997192
Validation loss: 2.3242045640945435

Epoch: 6| Step: 10
Training loss: 1.4573488235473633
Validation loss: 2.279671609401703

Epoch: 6| Step: 11
Training loss: 1.153346061706543
Validation loss: 2.2059521079063416

Epoch: 6| Step: 12
Training loss: 1.483406901359558
Validation loss: 2.2653679847717285

Epoch: 6| Step: 13
Training loss: 1.3220937252044678
Validation loss: 2.307646095752716

Epoch: 76| Step: 0
Training loss: 1.322528600692749
Validation loss: 2.2352710366249084

Epoch: 6| Step: 1
Training loss: 1.2404577732086182
Validation loss: 2.1445855696996055

Epoch: 6| Step: 2
Training loss: 1.95932137966156
Validation loss: 2.2295702695846558

Epoch: 6| Step: 3
Training loss: 1.8141002655029297
Validation loss: 2.256246785322825

Epoch: 6| Step: 4
Training loss: 1.8604841232299805
Validation loss: 2.2424745559692383

Epoch: 6| Step: 5
Training loss: 1.2382690906524658
Validation loss: 2.2688329815864563

Epoch: 6| Step: 6
Training loss: 1.59488844871521
Validation loss: 2.129235784212748

Epoch: 6| Step: 7
Training loss: 1.5473003387451172
Validation loss: 2.17538720369339

Epoch: 6| Step: 8
Training loss: 1.6211222410202026
Validation loss: 2.2806920409202576

Epoch: 6| Step: 9
Training loss: 1.435866117477417
Validation loss: 2.2367430528004966

Epoch: 6| Step: 10
Training loss: 1.5389807224273682
Validation loss: 2.2039578954378762

Epoch: 6| Step: 11
Training loss: 1.0627554655075073
Validation loss: 2.3364203770955405

Epoch: 6| Step: 12
Training loss: 1.2122914791107178
Validation loss: 2.305703043937683

Epoch: 6| Step: 13
Training loss: 1.8280876874923706
Validation loss: 2.1952550411224365

Epoch: 77| Step: 0
Training loss: 1.4601882696151733
Validation loss: 2.2796199321746826

Epoch: 6| Step: 1
Training loss: 1.799411654472351
Validation loss: 2.338862160841624

Epoch: 6| Step: 2
Training loss: 1.295311689376831
Validation loss: 2.2983421683311462

Epoch: 6| Step: 3
Training loss: 0.6487544775009155
Validation loss: 2.2836978832880654

Epoch: 6| Step: 4
Training loss: 1.330183744430542
Validation loss: 2.2813796003659568

Epoch: 6| Step: 5
Training loss: 1.6917519569396973
Validation loss: 2.240422487258911

Epoch: 6| Step: 6
Training loss: 1.6487973928451538
Validation loss: 2.202708601951599

Epoch: 6| Step: 7
Training loss: 1.7731053829193115
Validation loss: 2.2554330825805664

Epoch: 6| Step: 8
Training loss: 1.393798828125
Validation loss: 2.251152594884237

Epoch: 6| Step: 9
Training loss: 1.3817737102508545
Validation loss: 2.258523921171824

Epoch: 6| Step: 10
Training loss: 1.8079358339309692
Validation loss: 2.230269650618235

Epoch: 6| Step: 11
Training loss: 1.367844820022583
Validation loss: 2.231360693772634

Epoch: 6| Step: 12
Training loss: 1.564793586730957
Validation loss: 2.1858044068018594

Epoch: 6| Step: 13
Training loss: 2.287752628326416
Validation loss: 2.244302213191986

Epoch: 78| Step: 0
Training loss: 1.8365486860275269
Validation loss: 2.2337693770726523

Epoch: 6| Step: 1
Training loss: 2.1089067459106445
Validation loss: 2.302686591943105

Epoch: 6| Step: 2
Training loss: 1.9946835041046143
Validation loss: 2.2207810481389365

Epoch: 6| Step: 3
Training loss: 1.7244830131530762
Validation loss: 2.257341146469116

Epoch: 6| Step: 4
Training loss: 1.6111533641815186
Validation loss: 2.313237468401591

Epoch: 6| Step: 5
Training loss: 1.6019461154937744
Validation loss: 2.25963294506073

Epoch: 6| Step: 6
Training loss: 1.5147740840911865
Validation loss: 2.2289989391962686

Epoch: 6| Step: 7
Training loss: 0.9026778340339661
Validation loss: 2.2213567097981772

Epoch: 6| Step: 8
Training loss: 1.3658581972122192
Validation loss: 2.1949559847513833

Epoch: 6| Step: 9
Training loss: 1.0582354068756104
Validation loss: 2.2341453234354653

Epoch: 6| Step: 10
Training loss: 1.1109442710876465
Validation loss: 2.265439053376516

Epoch: 6| Step: 11
Training loss: 1.5466108322143555
Validation loss: 2.203465461730957

Epoch: 6| Step: 12
Training loss: 1.4754496812820435
Validation loss: 2.263033072153727

Epoch: 6| Step: 13
Training loss: 1.3575172424316406
Validation loss: 2.259891470273336

Epoch: 79| Step: 0
Training loss: 1.557215690612793
Validation loss: 2.274840851624807

Epoch: 6| Step: 1
Training loss: 1.3761719465255737
Validation loss: 2.28131095568339

Epoch: 6| Step: 2
Training loss: 1.3917045593261719
Validation loss: 2.2494146625200906

Epoch: 6| Step: 3
Training loss: 1.2121739387512207
Validation loss: 2.2892761826515198

Epoch: 6| Step: 4
Training loss: 1.0425658226013184
Validation loss: 2.2441320617993674

Epoch: 6| Step: 5
Training loss: 1.3945560455322266
Validation loss: 2.2376507918039956

Epoch: 6| Step: 6
Training loss: 1.689406156539917
Validation loss: 2.23165100812912

Epoch: 6| Step: 7
Training loss: 1.5870280265808105
Validation loss: 2.2686046957969666

Epoch: 6| Step: 8
Training loss: 1.7896674871444702
Validation loss: 2.2143208583196006

Epoch: 6| Step: 9
Training loss: 1.5959019660949707
Validation loss: 2.2281506657600403

Epoch: 6| Step: 10
Training loss: 2.0032646656036377
Validation loss: 2.2913675705591836

Epoch: 6| Step: 11
Training loss: 1.8370215892791748
Validation loss: 2.3261192043622336

Epoch: 6| Step: 12
Training loss: 1.5124984979629517
Validation loss: 2.3140440781911216

Epoch: 6| Step: 13
Training loss: 2.1715121269226074
Validation loss: 2.3074973225593567

Epoch: 80| Step: 0
Training loss: 1.6312968730926514
Validation loss: 2.3258272210756936

Epoch: 6| Step: 1
Training loss: 1.4318795204162598
Validation loss: 2.3827732602755227

Epoch: 6| Step: 2
Training loss: 1.457883358001709
Validation loss: 2.2350480953852334

Epoch: 6| Step: 3
Training loss: 0.9215574264526367
Validation loss: 2.254082679748535

Epoch: 6| Step: 4
Training loss: 1.3814284801483154
Validation loss: 2.1807971000671387

Epoch: 6| Step: 5
Training loss: 1.2773674726486206
Validation loss: 2.25767449537913

Epoch: 6| Step: 6
Training loss: 1.8328081369400024
Validation loss: 2.258976936340332

Epoch: 6| Step: 7
Training loss: 1.7303351163864136
Validation loss: 2.170845846335093

Epoch: 6| Step: 8
Training loss: 1.4681823253631592
Validation loss: 2.2393869360287986

Epoch: 6| Step: 9
Training loss: 1.6146268844604492
Validation loss: 2.211979250113169

Epoch: 6| Step: 10
Training loss: 1.9708400964736938
Validation loss: 2.229324162006378

Epoch: 6| Step: 11
Training loss: 1.2456824779510498
Validation loss: 2.2591782808303833

Epoch: 6| Step: 12
Training loss: 1.4493885040283203
Validation loss: 2.217212160428365

Epoch: 6| Step: 13
Training loss: 1.321066975593567
Validation loss: 2.212767998377482

Epoch: 81| Step: 0
Training loss: 1.709718942642212
Validation loss: 2.2342727184295654

Epoch: 6| Step: 1
Training loss: 1.8953230381011963
Validation loss: 2.2453688780466714

Epoch: 6| Step: 2
Training loss: 1.2062417268753052
Validation loss: 2.2367419600486755

Epoch: 6| Step: 3
Training loss: 0.6445962190628052
Validation loss: 2.2389624317487082

Epoch: 6| Step: 4
Training loss: 2.0068416595458984
Validation loss: 2.2206416924794516

Epoch: 6| Step: 5
Training loss: 1.4327223300933838
Validation loss: 2.213026483853658

Epoch: 6| Step: 6
Training loss: 1.7218819856643677
Validation loss: 2.275405983130137

Epoch: 6| Step: 7
Training loss: 1.495314121246338
Validation loss: 2.1857545971870422

Epoch: 6| Step: 8
Training loss: 1.654246211051941
Validation loss: 2.2202252944310508

Epoch: 6| Step: 9
Training loss: 1.1532217264175415
Validation loss: 2.240068554878235

Epoch: 6| Step: 10
Training loss: 1.6223751306533813
Validation loss: 2.2332634131113687

Epoch: 6| Step: 11
Training loss: 1.0945844650268555
Validation loss: 2.272077997525533

Epoch: 6| Step: 12
Training loss: 1.648564338684082
Validation loss: 2.2832235296567283

Epoch: 6| Step: 13
Training loss: 1.1679439544677734
Validation loss: 2.2467265327771506

Epoch: 82| Step: 0
Training loss: 1.2409389019012451
Validation loss: 2.2960670391718545

Epoch: 6| Step: 1
Training loss: 0.9424576163291931
Validation loss: 2.264578878879547

Epoch: 6| Step: 2
Training loss: 1.765576720237732
Validation loss: 2.2165343364079795

Epoch: 6| Step: 3
Training loss: 1.7437875270843506
Validation loss: 2.1737770636876426

Epoch: 6| Step: 4
Training loss: 1.2900173664093018
Validation loss: 2.3178929686546326

Epoch: 6| Step: 5
Training loss: 1.9166779518127441
Validation loss: 2.2548809250195823

Epoch: 6| Step: 6
Training loss: 1.5919749736785889
Validation loss: 2.2582794427871704

Epoch: 6| Step: 7
Training loss: 1.285768747329712
Validation loss: 2.212913990020752

Epoch: 6| Step: 8
Training loss: 1.7460107803344727
Validation loss: 2.2689292629559836

Epoch: 6| Step: 9
Training loss: 1.1744309663772583
Validation loss: 2.211162507534027

Epoch: 6| Step: 10
Training loss: 1.403774380683899
Validation loss: 2.235103984673818

Epoch: 6| Step: 11
Training loss: 1.0650091171264648
Validation loss: 2.3555442889531455

Epoch: 6| Step: 12
Training loss: 1.5808556079864502
Validation loss: 2.4242649475733438

Epoch: 6| Step: 13
Training loss: 2.407945394515991
Validation loss: 2.500744183858236

Epoch: 83| Step: 0
Training loss: 1.3318994045257568
Validation loss: 2.45440407594045

Epoch: 6| Step: 1
Training loss: 1.5082638263702393
Validation loss: 2.3473665714263916

Epoch: 6| Step: 2
Training loss: 1.7375426292419434
Validation loss: 2.309285581111908

Epoch: 6| Step: 3
Training loss: 1.6785838603973389
Validation loss: 2.2197846174240112

Epoch: 6| Step: 4
Training loss: 1.0988669395446777
Validation loss: 2.2686593333880105

Epoch: 6| Step: 5
Training loss: 1.2379286289215088
Validation loss: 2.242366909980774

Epoch: 6| Step: 6
Training loss: 1.4919154644012451
Validation loss: 2.262024243672689

Epoch: 6| Step: 7
Training loss: 1.3353781700134277
Validation loss: 2.192064662774404

Epoch: 6| Step: 8
Training loss: 0.8979732394218445
Validation loss: 2.1949763695398965

Epoch: 6| Step: 9
Training loss: 2.2473437786102295
Validation loss: 2.27653561035792

Epoch: 6| Step: 10
Training loss: 1.3355597257614136
Validation loss: 2.1860978603363037

Epoch: 6| Step: 11
Training loss: 1.1471014022827148
Validation loss: 2.296316842238108

Epoch: 6| Step: 12
Training loss: 2.672333240509033
Validation loss: 2.3346365292867026

Epoch: 6| Step: 13
Training loss: 2.0891785621643066
Validation loss: 2.4681198596954346

Epoch: 84| Step: 0
Training loss: 1.7416249513626099
Validation loss: 2.357990086078644

Epoch: 6| Step: 1
Training loss: 2.5338149070739746
Validation loss: 2.3987130920092263

Epoch: 6| Step: 2
Training loss: 1.4559082984924316
Validation loss: 2.316311498483022

Epoch: 6| Step: 3
Training loss: 1.373105525970459
Validation loss: 2.2481152216593423

Epoch: 6| Step: 4
Training loss: 0.9617429375648499
Validation loss: 2.1867016553878784

Epoch: 6| Step: 5
Training loss: 2.166478157043457
Validation loss: 2.2018602887789407

Epoch: 6| Step: 6
Training loss: 1.3051730394363403
Validation loss: 2.182218611240387

Epoch: 6| Step: 7
Training loss: 2.206998109817505
Validation loss: 2.185742656389872

Epoch: 6| Step: 8
Training loss: 1.4628167152404785
Validation loss: 2.235089361667633

Epoch: 6| Step: 9
Training loss: 1.8901605606079102
Validation loss: 2.1992194851239524

Epoch: 6| Step: 10
Training loss: 1.9558063745498657
Validation loss: 2.1673959692319236

Epoch: 6| Step: 11
Training loss: 1.769742488861084
Validation loss: 2.195065498352051

Epoch: 6| Step: 12
Training loss: 1.0993084907531738
Validation loss: 2.142865300178528

Epoch: 6| Step: 13
Training loss: 0.8679254651069641
Validation loss: 2.2008198499679565

Epoch: 85| Step: 0
Training loss: 0.9310387372970581
Validation loss: 2.269661068916321

Epoch: 6| Step: 1
Training loss: 1.4323351383209229
Validation loss: 2.2601237098375955

Epoch: 6| Step: 2
Training loss: 1.63137948513031
Validation loss: 2.3540833393732705

Epoch: 6| Step: 3
Training loss: 1.7077763080596924
Validation loss: 2.380683104197184

Epoch: 6| Step: 4
Training loss: 1.8851945400238037
Validation loss: 2.258789877096812

Epoch: 6| Step: 5
Training loss: 1.4499714374542236
Validation loss: 2.2108433842658997

Epoch: 6| Step: 6
Training loss: 1.4465460777282715
Validation loss: 2.21499240398407

Epoch: 6| Step: 7
Training loss: 1.2421112060546875
Validation loss: 2.0862287481625876

Epoch: 6| Step: 8
Training loss: 1.5135111808776855
Validation loss: 2.1573158303896585

Epoch: 6| Step: 9
Training loss: 1.1680901050567627
Validation loss: 2.1675866842269897

Epoch: 6| Step: 10
Training loss: 1.878063440322876
Validation loss: 2.181179324785868

Epoch: 6| Step: 11
Training loss: 1.9458094835281372
Validation loss: 2.193185865879059

Epoch: 6| Step: 12
Training loss: 1.5187612771987915
Validation loss: 2.1618734995524087

Epoch: 6| Step: 13
Training loss: 1.9969749450683594
Validation loss: 2.15619424978892

Epoch: 86| Step: 0
Training loss: 1.4136065244674683
Validation loss: 2.286050875981649

Epoch: 6| Step: 1
Training loss: 1.5696300268173218
Validation loss: 2.1933937867482505

Epoch: 6| Step: 2
Training loss: 1.7071459293365479
Validation loss: 2.1787999471028647

Epoch: 6| Step: 3
Training loss: 1.3157763481140137
Validation loss: 2.245168685913086

Epoch: 6| Step: 4
Training loss: 1.2259330749511719
Validation loss: 2.307087163130442

Epoch: 6| Step: 5
Training loss: 1.5697877407073975
Validation loss: 2.2484524647394815

Epoch: 6| Step: 6
Training loss: 1.4553272724151611
Validation loss: 2.213991940021515

Epoch: 6| Step: 7
Training loss: 1.7172328233718872
Validation loss: 2.249547759691874

Epoch: 6| Step: 8
Training loss: 1.6566511392593384
Validation loss: 2.2357184886932373

Epoch: 6| Step: 9
Training loss: 1.389020562171936
Validation loss: 2.164937754472097

Epoch: 6| Step: 10
Training loss: 1.3638832569122314
Validation loss: 2.132163127263387

Epoch: 6| Step: 11
Training loss: 1.976679801940918
Validation loss: 2.1101112961769104

Epoch: 6| Step: 12
Training loss: 1.2281279563903809
Validation loss: 2.1520583629608154

Epoch: 6| Step: 13
Training loss: 1.4233672618865967
Validation loss: 2.1259605884552

Epoch: 87| Step: 0
Training loss: 1.6160759925842285
Validation loss: 2.169822653134664

Epoch: 6| Step: 1
Training loss: 0.6068378686904907
Validation loss: 2.2385391195615134

Epoch: 6| Step: 2
Training loss: 2.232797145843506
Validation loss: 2.15667062997818

Epoch: 6| Step: 3
Training loss: 1.1824545860290527
Validation loss: 2.134572684764862

Epoch: 6| Step: 4
Training loss: 1.2344999313354492
Validation loss: 2.1325578093528748

Epoch: 6| Step: 5
Training loss: 0.9931113123893738
Validation loss: 2.123538394769033

Epoch: 6| Step: 6
Training loss: 1.498871922492981
Validation loss: 2.212611516316732

Epoch: 6| Step: 7
Training loss: 1.4531500339508057
Validation loss: 2.246157685915629

Epoch: 6| Step: 8
Training loss: 1.4145445823669434
Validation loss: 2.2677900791168213

Epoch: 6| Step: 9
Training loss: 1.3383314609527588
Validation loss: 2.234935939311981

Epoch: 6| Step: 10
Training loss: 1.2233545780181885
Validation loss: 2.2257598837216697

Epoch: 6| Step: 11
Training loss: 1.9805766344070435
Validation loss: 2.170997460683187

Epoch: 6| Step: 12
Training loss: 1.7133030891418457
Validation loss: 2.1907841761906943

Epoch: 6| Step: 13
Training loss: 1.903272271156311
Validation loss: 2.1959277590115867

Epoch: 88| Step: 0
Training loss: 1.3563575744628906
Validation loss: 2.1362207531929016

Epoch: 6| Step: 1
Training loss: 1.5638655424118042
Validation loss: 2.125056425730387

Epoch: 6| Step: 2
Training loss: 1.0005073547363281
Validation loss: 2.1655807892481485

Epoch: 6| Step: 3
Training loss: 1.4092347621917725
Validation loss: 2.1231038769086203

Epoch: 6| Step: 4
Training loss: 1.4494946002960205
Validation loss: 2.1917948126792908

Epoch: 6| Step: 5
Training loss: 1.4581124782562256
Validation loss: 2.1782612800598145

Epoch: 6| Step: 6
Training loss: 1.366323709487915
Validation loss: 2.179553270339966

Epoch: 6| Step: 7
Training loss: 1.7075966596603394
Validation loss: 2.1396474043528237

Epoch: 6| Step: 8
Training loss: 1.2993316650390625
Validation loss: 2.1735297242800393

Epoch: 6| Step: 9
Training loss: 1.327528715133667
Validation loss: 2.2076669335365295

Epoch: 6| Step: 10
Training loss: 1.5032964944839478
Validation loss: 2.294524868329366

Epoch: 6| Step: 11
Training loss: 1.7835662364959717
Validation loss: 2.1814644734064736

Epoch: 6| Step: 12
Training loss: 1.5045051574707031
Validation loss: 2.1606199741363525

Epoch: 6| Step: 13
Training loss: 0.9099180698394775
Validation loss: 2.2041174173355103

Epoch: 89| Step: 0
Training loss: 1.2214994430541992
Validation loss: 2.1329117019971213

Epoch: 6| Step: 1
Training loss: 0.9715684652328491
Validation loss: 2.160212457180023

Epoch: 6| Step: 2
Training loss: 1.8232203722000122
Validation loss: 2.172297418117523

Epoch: 6| Step: 3
Training loss: 1.0026909112930298
Validation loss: 2.188144564628601

Epoch: 6| Step: 4
Training loss: 1.634636402130127
Validation loss: 2.186169465382894

Epoch: 6| Step: 5
Training loss: 2.0116493701934814
Validation loss: 2.177359938621521

Epoch: 6| Step: 6
Training loss: 1.367182731628418
Validation loss: 2.165643811225891

Epoch: 6| Step: 7
Training loss: 1.1783638000488281
Validation loss: 2.1512699921925864

Epoch: 6| Step: 8
Training loss: 1.3659331798553467
Validation loss: 2.1643468141555786

Epoch: 6| Step: 9
Training loss: 1.241929292678833
Validation loss: 2.214476784070333

Epoch: 6| Step: 10
Training loss: 1.1887586116790771
Validation loss: 2.098233779271444

Epoch: 6| Step: 11
Training loss: 1.1517236232757568
Validation loss: 2.147522807121277

Epoch: 6| Step: 12
Training loss: 1.4016095399856567
Validation loss: 2.2044445077578225

Epoch: 6| Step: 13
Training loss: 1.6679354906082153
Validation loss: 2.1982871294021606

Epoch: 90| Step: 0
Training loss: 1.6236865520477295
Validation loss: 2.237996975580851

Epoch: 6| Step: 1
Training loss: 0.9158322811126709
Validation loss: 2.1580089728037515

Epoch: 6| Step: 2
Training loss: 1.5174311399459839
Validation loss: 2.1951645414034524

Epoch: 6| Step: 3
Training loss: 1.1106785535812378
Validation loss: 2.165181815624237

Epoch: 6| Step: 4
Training loss: 1.5030829906463623
Validation loss: 2.134424408276876

Epoch: 6| Step: 5
Training loss: 1.7357940673828125
Validation loss: 2.1384598215421042

Epoch: 6| Step: 6
Training loss: 1.6552810668945312
Validation loss: 2.1884449124336243

Epoch: 6| Step: 7
Training loss: 1.4298232793807983
Validation loss: 2.099330723285675

Epoch: 6| Step: 8
Training loss: 1.2255233526229858
Validation loss: 2.1706529458363852

Epoch: 6| Step: 9
Training loss: 0.7742236852645874
Validation loss: 2.2318626840909324

Epoch: 6| Step: 10
Training loss: 2.2940967082977295
Validation loss: 2.2575454910596213

Epoch: 6| Step: 11
Training loss: 1.4504730701446533
Validation loss: 2.288658857345581

Epoch: 6| Step: 12
Training loss: 1.674534797668457
Validation loss: 2.3262815475463867

Epoch: 6| Step: 13
Training loss: 1.622512936592102
Validation loss: 2.2544169624646506

Epoch: 91| Step: 0
Training loss: 1.219929814338684
Validation loss: 2.302908937136332

Epoch: 6| Step: 1
Training loss: 1.7149429321289062
Validation loss: 2.212401270866394

Epoch: 6| Step: 2
Training loss: 2.1316077709198
Validation loss: 2.1558316946029663

Epoch: 6| Step: 3
Training loss: 1.0248351097106934
Validation loss: 2.214113156000773

Epoch: 6| Step: 4
Training loss: 1.8371853828430176
Validation loss: 2.2107372283935547

Epoch: 6| Step: 5
Training loss: 1.7174984216690063
Validation loss: 2.186545650164286

Epoch: 6| Step: 6
Training loss: 0.8870464563369751
Validation loss: 2.1655618151028952

Epoch: 6| Step: 7
Training loss: 1.4772257804870605
Validation loss: 2.1416382590929666

Epoch: 6| Step: 8
Training loss: 1.303215742111206
Validation loss: 2.220521072546641

Epoch: 6| Step: 9
Training loss: 1.7062633037567139
Validation loss: 2.2286199927330017

Epoch: 6| Step: 10
Training loss: 0.9033904075622559
Validation loss: 2.2477473616600037

Epoch: 6| Step: 11
Training loss: 0.9301410913467407
Validation loss: 2.2569878697395325

Epoch: 6| Step: 12
Training loss: 1.2544114589691162
Validation loss: 2.2993407448132834

Epoch: 6| Step: 13
Training loss: 1.8396285772323608
Validation loss: 2.155501067638397

Epoch: 92| Step: 0
Training loss: 1.7251591682434082
Validation loss: 2.1260732213656106

Epoch: 6| Step: 1
Training loss: 1.4637809991836548
Validation loss: 2.0847672820091248

Epoch: 6| Step: 2
Training loss: 1.2595505714416504
Validation loss: 2.1349483927090964

Epoch: 6| Step: 3
Training loss: 1.0242793560028076
Validation loss: 2.1553389628728232

Epoch: 6| Step: 4
Training loss: 1.6343413591384888
Validation loss: 2.1307541926701865

Epoch: 6| Step: 5
Training loss: 0.8578981757164001
Validation loss: 2.137558897336324

Epoch: 6| Step: 6
Training loss: 1.4607505798339844
Validation loss: 2.142514705657959

Epoch: 6| Step: 7
Training loss: 1.3722516298294067
Validation loss: 2.265207747618357

Epoch: 6| Step: 8
Training loss: 1.2904235124588013
Validation loss: 2.3090660174687705

Epoch: 6| Step: 9
Training loss: 1.5879082679748535
Validation loss: 2.3082212607065835

Epoch: 6| Step: 10
Training loss: 1.5424588918685913
Validation loss: 2.3711885611216226

Epoch: 6| Step: 11
Training loss: 1.8748910427093506
Validation loss: 2.347196559111277

Epoch: 6| Step: 12
Training loss: 1.4258027076721191
Validation loss: 2.235698680082957

Epoch: 6| Step: 13
Training loss: 1.5141732692718506
Validation loss: 2.1807509660720825

Epoch: 93| Step: 0
Training loss: 1.2493038177490234
Validation loss: 2.2117146849632263

Epoch: 6| Step: 1
Training loss: 1.966169834136963
Validation loss: 2.201047937075297

Epoch: 6| Step: 2
Training loss: 1.437546968460083
Validation loss: 2.210281570752462

Epoch: 6| Step: 3
Training loss: 1.6016697883605957
Validation loss: 2.18104080359141

Epoch: 6| Step: 4
Training loss: 1.7348995208740234
Validation loss: 2.1349643071492515

Epoch: 6| Step: 5
Training loss: 1.0530774593353271
Validation loss: 2.172319173812866

Epoch: 6| Step: 6
Training loss: 1.357919692993164
Validation loss: 2.181192378203074

Epoch: 6| Step: 7
Training loss: 1.457554578781128
Validation loss: 2.152442534764608

Epoch: 6| Step: 8
Training loss: 0.8574599027633667
Validation loss: 2.1630394061406455

Epoch: 6| Step: 9
Training loss: 0.9523693919181824
Validation loss: 2.2272180914878845

Epoch: 6| Step: 10
Training loss: 1.5508208274841309
Validation loss: 2.266505241394043

Epoch: 6| Step: 11
Training loss: 1.7559044361114502
Validation loss: 2.292050917943319

Epoch: 6| Step: 12
Training loss: 1.552422046661377
Validation loss: 2.3877059618631997

Epoch: 6| Step: 13
Training loss: 1.313234567642212
Validation loss: 2.3975311120351157

Epoch: 94| Step: 0
Training loss: 1.9836467504501343
Validation loss: 2.344805816809336

Epoch: 6| Step: 1
Training loss: 1.3276252746582031
Validation loss: 2.2815203865369162

Epoch: 6| Step: 2
Training loss: 1.1839872598648071
Validation loss: 2.1284724473953247

Epoch: 6| Step: 3
Training loss: 0.9846136569976807
Validation loss: 2.1351566712061563

Epoch: 6| Step: 4
Training loss: 1.7500269412994385
Validation loss: 2.141729414463043

Epoch: 6| Step: 5
Training loss: 1.3846983909606934
Validation loss: 2.181626001993815

Epoch: 6| Step: 6
Training loss: 1.421562671661377
Validation loss: 2.1215055187543235

Epoch: 6| Step: 7
Training loss: 1.1447842121124268
Validation loss: 2.1018711924552917

Epoch: 6| Step: 8
Training loss: 1.201833724975586
Validation loss: 2.1766037543614707

Epoch: 6| Step: 9
Training loss: 1.6219077110290527
Validation loss: 2.1695686976114907

Epoch: 6| Step: 10
Training loss: 1.1089433431625366
Validation loss: 2.13116854429245

Epoch: 6| Step: 11
Training loss: 1.9738352298736572
Validation loss: 2.134862939516703

Epoch: 6| Step: 12
Training loss: 1.6014270782470703
Validation loss: 2.1270121335983276

Epoch: 6| Step: 13
Training loss: 1.0294004678726196
Validation loss: 2.1950313647588096

Epoch: 95| Step: 0
Training loss: 1.1538116931915283
Validation loss: 2.167778491973877

Epoch: 6| Step: 1
Training loss: 1.197996973991394
Validation loss: 2.224688172340393

Epoch: 6| Step: 2
Training loss: 1.2102878093719482
Validation loss: 2.143978238105774

Epoch: 6| Step: 3
Training loss: 1.047819972038269
Validation loss: 2.1908803979555764

Epoch: 6| Step: 4
Training loss: 1.074318528175354
Validation loss: 2.129678805669149

Epoch: 6| Step: 5
Training loss: 1.2490565776824951
Validation loss: 2.2444658279418945

Epoch: 6| Step: 6
Training loss: 1.655408501625061
Validation loss: 2.17558616399765

Epoch: 6| Step: 7
Training loss: 1.5595781803131104
Validation loss: 2.2315738797187805

Epoch: 6| Step: 8
Training loss: 1.4682419300079346
Validation loss: 2.204511026541392

Epoch: 6| Step: 9
Training loss: 1.2534432411193848
Validation loss: 2.2026562889417014

Epoch: 6| Step: 10
Training loss: 1.2690136432647705
Validation loss: 2.2653724749883017

Epoch: 6| Step: 11
Training loss: 0.9044362902641296
Validation loss: 2.184683322906494

Epoch: 6| Step: 12
Training loss: 1.7383641004562378
Validation loss: 2.1786850889523826

Epoch: 6| Step: 13
Training loss: 1.5194547176361084
Validation loss: 2.154627819856008

Epoch: 96| Step: 0
Training loss: 0.906428337097168
Validation loss: 2.1645566821098328

Epoch: 6| Step: 1
Training loss: 0.7846691608428955
Validation loss: 2.1901209553082785

Epoch: 6| Step: 2
Training loss: 0.9121310710906982
Validation loss: 2.1902432243029275

Epoch: 6| Step: 3
Training loss: 1.1249834299087524
Validation loss: 2.1908461848894754

Epoch: 6| Step: 4
Training loss: 1.2544411420822144
Validation loss: 2.1553195913632712

Epoch: 6| Step: 5
Training loss: 0.7852727174758911
Validation loss: 2.2408305207888284

Epoch: 6| Step: 6
Training loss: 1.4125254154205322
Validation loss: 2.1492592295010886

Epoch: 6| Step: 7
Training loss: 0.9032288789749146
Validation loss: 2.2114989360173545

Epoch: 6| Step: 8
Training loss: 1.6479520797729492
Validation loss: 2.2175204356511435

Epoch: 6| Step: 9
Training loss: 1.833845615386963
Validation loss: 2.179626146952311

Epoch: 6| Step: 10
Training loss: 1.4115283489227295
Validation loss: 2.18216472864151

Epoch: 6| Step: 11
Training loss: 1.3758686780929565
Validation loss: 2.1476319829622903

Epoch: 6| Step: 12
Training loss: 1.8793272972106934
Validation loss: 2.111881693204244

Epoch: 6| Step: 13
Training loss: 1.7663638591766357
Validation loss: 2.170447508494059

Epoch: 97| Step: 0
Training loss: 1.5502185821533203
Validation loss: 2.1710696617762246

Epoch: 6| Step: 1
Training loss: 0.5539803504943848
Validation loss: 2.1316628058751426

Epoch: 6| Step: 2
Training loss: 1.2150459289550781
Validation loss: 2.237647294998169

Epoch: 6| Step: 3
Training loss: 1.344760537147522
Validation loss: 2.1941484610239663

Epoch: 6| Step: 4
Training loss: 1.2656203508377075
Validation loss: 2.1802178621292114

Epoch: 6| Step: 5
Training loss: 1.0959863662719727
Validation loss: 2.0857006510098777

Epoch: 6| Step: 6
Training loss: 1.7196093797683716
Validation loss: 2.1378201047579446

Epoch: 6| Step: 7
Training loss: 1.216405987739563
Validation loss: 2.0858062903086343

Epoch: 6| Step: 8
Training loss: 1.0500328540802002
Validation loss: 2.161924143632253

Epoch: 6| Step: 9
Training loss: 1.7415108680725098
Validation loss: 2.210109750429789

Epoch: 6| Step: 10
Training loss: 1.869179368019104
Validation loss: 2.1886137326558432

Epoch: 6| Step: 11
Training loss: 0.6807816028594971
Validation loss: 2.2213589946428933

Epoch: 6| Step: 12
Training loss: 1.2950152158737183
Validation loss: 2.277480979760488

Epoch: 6| Step: 13
Training loss: 1.2063932418823242
Validation loss: 2.19239342212677

Epoch: 98| Step: 0
Training loss: 1.2665399312973022
Validation loss: 2.205063581466675

Epoch: 6| Step: 1
Training loss: 1.7372708320617676
Validation loss: 2.1660199562708535

Epoch: 6| Step: 2
Training loss: 0.9335004091262817
Validation loss: 2.2306406696637473

Epoch: 6| Step: 3
Training loss: 1.4635188579559326
Validation loss: 2.2338724533716836

Epoch: 6| Step: 4
Training loss: 1.1503249406814575
Validation loss: 2.1682982047398887

Epoch: 6| Step: 5
Training loss: 1.28578782081604
Validation loss: 2.1802457173665366

Epoch: 6| Step: 6
Training loss: 1.1600055694580078
Validation loss: 2.162287712097168

Epoch: 6| Step: 7
Training loss: 1.0193135738372803
Validation loss: 2.173597435156504

Epoch: 6| Step: 8
Training loss: 1.2923357486724854
Validation loss: 2.2283209959665933

Epoch: 6| Step: 9
Training loss: 0.8391380906105042
Validation loss: 2.148672044277191

Epoch: 6| Step: 10
Training loss: 1.8967536687850952
Validation loss: 2.2772722840309143

Epoch: 6| Step: 11
Training loss: 1.1114921569824219
Validation loss: 2.257477561632792

Epoch: 6| Step: 12
Training loss: 1.8872679471969604
Validation loss: 2.253740111986796

Epoch: 6| Step: 13
Training loss: 1.414151906967163
Validation loss: 2.15929784377416

Epoch: 99| Step: 0
Training loss: 1.3276276588439941
Validation loss: 2.1751669446627298

Epoch: 6| Step: 1
Training loss: 1.7131670713424683
Validation loss: 2.0787469347318015

Epoch: 6| Step: 2
Training loss: 1.669741153717041
Validation loss: 2.137582262357076

Epoch: 6| Step: 3
Training loss: 1.783384084701538
Validation loss: 2.1775904496510825

Epoch: 6| Step: 4
Training loss: 1.444807767868042
Validation loss: 2.1560529271761575

Epoch: 6| Step: 5
Training loss: 1.16765558719635
Validation loss: 2.1272191206614175

Epoch: 6| Step: 6
Training loss: 1.0704673528671265
Validation loss: 2.1497687498728433

Epoch: 6| Step: 7
Training loss: 0.9554651379585266
Validation loss: 2.205592413743337

Epoch: 6| Step: 8
Training loss: 1.459295630455017
Validation loss: 2.2023141781489053

Epoch: 6| Step: 9
Training loss: 0.8929678201675415
Validation loss: 2.2480936447779336

Epoch: 6| Step: 10
Training loss: 1.3028820753097534
Validation loss: 2.241336146990458

Epoch: 6| Step: 11
Training loss: 1.2838904857635498
Validation loss: 2.282527208328247

Epoch: 6| Step: 12
Training loss: 1.322213053703308
Validation loss: 2.2088107665379844

Epoch: 6| Step: 13
Training loss: 1.279033899307251
Validation loss: 2.092575788497925

Epoch: 100| Step: 0
Training loss: 1.7085041999816895
Validation loss: 2.1360065738360086

Epoch: 6| Step: 1
Training loss: 1.7913167476654053
Validation loss: 2.0996269583702087

Epoch: 6| Step: 2
Training loss: 0.8942335247993469
Validation loss: 2.119742751121521

Epoch: 6| Step: 3
Training loss: 1.1330673694610596
Validation loss: 2.1765312949816384

Epoch: 6| Step: 4
Training loss: 0.8658552169799805
Validation loss: 2.1903531153996787

Epoch: 6| Step: 5
Training loss: 0.812559962272644
Validation loss: 2.191772758960724

Epoch: 6| Step: 6
Training loss: 1.4695804119110107
Validation loss: 2.2332722544670105

Epoch: 6| Step: 7
Training loss: 1.1036241054534912
Validation loss: 2.132519861062368

Epoch: 6| Step: 8
Training loss: 1.5225622653961182
Validation loss: 2.1333762407302856

Epoch: 6| Step: 9
Training loss: 1.4733517169952393
Validation loss: 2.118048071861267

Epoch: 6| Step: 10
Training loss: 1.5209481716156006
Validation loss: 2.119460165500641

Epoch: 6| Step: 11
Training loss: 1.0812501907348633
Validation loss: 2.1418864329655967

Epoch: 6| Step: 12
Training loss: 1.4781887531280518
Validation loss: 2.182746191819509

Epoch: 6| Step: 13
Training loss: 1.079647183418274
Validation loss: 2.146760861078898

Epoch: 101| Step: 0
Training loss: 1.2615433931350708
Validation loss: 2.1387339433034263

Epoch: 6| Step: 1
Training loss: 1.2566108703613281
Validation loss: 2.1750271717707315

Epoch: 6| Step: 2
Training loss: 1.0638234615325928
Validation loss: 2.188036342461904

Epoch: 6| Step: 3
Training loss: 0.6714923977851868
Validation loss: 2.183129290739695

Epoch: 6| Step: 4
Training loss: 1.827176570892334
Validation loss: 2.2270498275756836

Epoch: 6| Step: 5
Training loss: 1.0919467210769653
Validation loss: 2.302311281363169

Epoch: 6| Step: 6
Training loss: 1.647986888885498
Validation loss: 2.1811129252115884

Epoch: 6| Step: 7
Training loss: 1.1624360084533691
Validation loss: 2.1198165814081826

Epoch: 6| Step: 8
Training loss: 0.983733057975769
Validation loss: 2.154010554154714

Epoch: 6| Step: 9
Training loss: 1.4953975677490234
Validation loss: 2.1638119220733643

Epoch: 6| Step: 10
Training loss: 1.636198878288269
Validation loss: 2.1887228886286416

Epoch: 6| Step: 11
Training loss: 1.1656243801116943
Validation loss: 2.0897828539212546

Epoch: 6| Step: 12
Training loss: 1.758011817932129
Validation loss: 2.1428781946500144

Epoch: 6| Step: 13
Training loss: 0.9759124517440796
Validation loss: 2.169923265775045

Epoch: 102| Step: 0
Training loss: 1.6444673538208008
Validation loss: 2.1158185601234436

Epoch: 6| Step: 1
Training loss: 1.5483953952789307
Validation loss: 2.095870614051819

Epoch: 6| Step: 2
Training loss: 1.4731441736221313
Validation loss: 2.132689674695333

Epoch: 6| Step: 3
Training loss: 1.4302029609680176
Validation loss: 2.1587414940198264

Epoch: 6| Step: 4
Training loss: 1.3910882472991943
Validation loss: 2.1615201830863953

Epoch: 6| Step: 5
Training loss: 0.8748605251312256
Validation loss: 2.1527555783589682

Epoch: 6| Step: 6
Training loss: 1.179518699645996
Validation loss: 2.2538413604100547

Epoch: 6| Step: 7
Training loss: 0.5124229788780212
Validation loss: 2.1578701734542847

Epoch: 6| Step: 8
Training loss: 1.5301486253738403
Validation loss: 2.1758100986480713

Epoch: 6| Step: 9
Training loss: 1.037731409072876
Validation loss: 2.1808412075042725

Epoch: 6| Step: 10
Training loss: 1.2493886947631836
Validation loss: 2.160211761792501

Epoch: 6| Step: 11
Training loss: 1.303670883178711
Validation loss: 2.0930219491322837

Epoch: 6| Step: 12
Training loss: 0.8443785905838013
Validation loss: 2.173535148302714

Epoch: 6| Step: 13
Training loss: 1.2886528968811035
Validation loss: 2.165989716847738

Epoch: 103| Step: 0
Training loss: 0.5061137676239014
Validation loss: 2.195736567179362

Epoch: 6| Step: 1
Training loss: 1.4064524173736572
Validation loss: 2.166099766890208

Epoch: 6| Step: 2
Training loss: 0.9638928771018982
Validation loss: 2.228035807609558

Epoch: 6| Step: 3
Training loss: 1.904374122619629
Validation loss: 2.193235615889231

Epoch: 6| Step: 4
Training loss: 1.1165417432785034
Validation loss: 2.1955908139546714

Epoch: 6| Step: 5
Training loss: 1.1093719005584717
Validation loss: 2.151864310105642

Epoch: 6| Step: 6
Training loss: 1.415584683418274
Validation loss: 2.1076110204060874

Epoch: 6| Step: 7
Training loss: 1.2132519483566284
Validation loss: 2.091330409049988

Epoch: 6| Step: 8
Training loss: 1.2281162738800049
Validation loss: 2.131807108720144

Epoch: 6| Step: 9
Training loss: 1.038317084312439
Validation loss: 2.138167997201284

Epoch: 6| Step: 10
Training loss: 1.0597774982452393
Validation loss: 2.124056319395701

Epoch: 6| Step: 11
Training loss: 1.1686475276947021
Validation loss: 2.2605964740117392

Epoch: 6| Step: 12
Training loss: 1.3569610118865967
Validation loss: 2.2665632565816245

Epoch: 6| Step: 13
Training loss: 1.752724289894104
Validation loss: 2.2299670577049255

Epoch: 104| Step: 0
Training loss: 0.8642081022262573
Validation loss: 2.2432137727737427

Epoch: 6| Step: 1
Training loss: 1.9365308284759521
Validation loss: 2.273170789082845

Epoch: 6| Step: 2
Training loss: 1.5494059324264526
Validation loss: 2.173648158709208

Epoch: 6| Step: 3
Training loss: 0.918891191482544
Validation loss: 2.1691413521766663

Epoch: 6| Step: 4
Training loss: 1.0958441495895386
Validation loss: 2.1438458363215127

Epoch: 6| Step: 5
Training loss: 1.4945704936981201
Validation loss: 2.1733256181081138

Epoch: 6| Step: 6
Training loss: 1.4128663539886475
Validation loss: 2.1559616923332214

Epoch: 6| Step: 7
Training loss: 1.0042511224746704
Validation loss: 2.150370240211487

Epoch: 6| Step: 8
Training loss: 1.5140225887298584
Validation loss: 2.161482115586599

Epoch: 6| Step: 9
Training loss: 1.110799789428711
Validation loss: 2.1944573124249778

Epoch: 6| Step: 10
Training loss: 0.9887529611587524
Validation loss: 2.175070285797119

Epoch: 6| Step: 11
Training loss: 1.1159818172454834
Validation loss: 2.2097554008165994

Epoch: 6| Step: 12
Training loss: 0.838222861289978
Validation loss: 2.2152491013209024

Epoch: 6| Step: 13
Training loss: 1.8376425504684448
Validation loss: 2.2445363998413086

Epoch: 105| Step: 0
Training loss: 1.6082394123077393
Validation loss: 2.244518498579661

Epoch: 6| Step: 1
Training loss: 1.3366305828094482
Validation loss: 2.1621378660202026

Epoch: 6| Step: 2
Training loss: 1.1687593460083008
Validation loss: 2.233951508998871

Epoch: 6| Step: 3
Training loss: 1.3393486738204956
Validation loss: 2.211801528930664

Epoch: 6| Step: 4
Training loss: 1.1924448013305664
Validation loss: 2.1789466540018716

Epoch: 6| Step: 5
Training loss: 0.9348345994949341
Validation loss: 2.1942147612571716

Epoch: 6| Step: 6
Training loss: 1.2533925771713257
Validation loss: 2.1405852834383645

Epoch: 6| Step: 7
Training loss: 1.1476566791534424
Validation loss: 2.1942983071009317

Epoch: 6| Step: 8
Training loss: 1.489936351776123
Validation loss: 2.113596737384796

Epoch: 6| Step: 9
Training loss: 0.870618462562561
Validation loss: 2.132575750350952

Epoch: 6| Step: 10
Training loss: 0.7922236919403076
Validation loss: 2.183403789997101

Epoch: 6| Step: 11
Training loss: 1.5539326667785645
Validation loss: 2.2238468726476035

Epoch: 6| Step: 12
Training loss: 1.3601410388946533
Validation loss: 2.2092310190200806

Epoch: 6| Step: 13
Training loss: 1.4397222995758057
Validation loss: 2.2260634899139404

Epoch: 106| Step: 0
Training loss: 0.8495738506317139
Validation loss: 2.2181238333384194

Epoch: 6| Step: 1
Training loss: 1.0971204042434692
Validation loss: 2.1834970911343894

Epoch: 6| Step: 2
Training loss: 1.54746413230896
Validation loss: 2.2017396092414856

Epoch: 6| Step: 3
Training loss: 1.1671979427337646
Validation loss: 2.1104790369669595

Epoch: 6| Step: 4
Training loss: 1.0249416828155518
Validation loss: 2.150855302810669

Epoch: 6| Step: 5
Training loss: 0.7525468468666077
Validation loss: 2.2176386515299478

Epoch: 6| Step: 6
Training loss: 1.0937062501907349
Validation loss: 2.2075524727503457

Epoch: 6| Step: 7
Training loss: 1.0468984842300415
Validation loss: 2.2177057464917502

Epoch: 6| Step: 8
Training loss: 1.2025527954101562
Validation loss: 2.187727212905884

Epoch: 6| Step: 9
Training loss: 1.1348867416381836
Validation loss: 2.2411403258641562

Epoch: 6| Step: 10
Training loss: 1.8748475313186646
Validation loss: 2.2223697900772095

Epoch: 6| Step: 11
Training loss: 1.3726919889450073
Validation loss: 2.1970221201578775

Epoch: 6| Step: 12
Training loss: 0.9773712158203125
Validation loss: 2.195152521133423

Epoch: 6| Step: 13
Training loss: 1.3513519763946533
Validation loss: 2.142684737841288

Epoch: 107| Step: 0
Training loss: 1.3520827293395996
Validation loss: 2.118630309899648

Epoch: 6| Step: 1
Training loss: 0.811179518699646
Validation loss: 2.137412667274475

Epoch: 6| Step: 2
Training loss: 1.527308702468872
Validation loss: 2.167943517367045

Epoch: 6| Step: 3
Training loss: 1.423175573348999
Validation loss: 2.142083525657654

Epoch: 6| Step: 4
Training loss: 1.3159115314483643
Validation loss: 2.15038138628006

Epoch: 6| Step: 5
Training loss: 1.1490073204040527
Validation loss: 2.2281207839647927

Epoch: 6| Step: 6
Training loss: 1.2480080127716064
Validation loss: 2.256507237752279

Epoch: 6| Step: 7
Training loss: 1.2014172077178955
Validation loss: 2.240724523862203

Epoch: 6| Step: 8
Training loss: 1.4491603374481201
Validation loss: 2.2061376571655273

Epoch: 6| Step: 9
Training loss: 0.9376577734947205
Validation loss: 2.2241862217585244

Epoch: 6| Step: 10
Training loss: 1.1688826084136963
Validation loss: 2.166385213534037

Epoch: 6| Step: 11
Training loss: 1.0587067604064941
Validation loss: 2.1459816495577493

Epoch: 6| Step: 12
Training loss: 0.7663929462432861
Validation loss: 2.144524256388346

Epoch: 6| Step: 13
Training loss: 1.6488990783691406
Validation loss: 2.161461293697357

Epoch: 108| Step: 0
Training loss: 1.1605136394500732
Validation loss: 2.086196462313334

Epoch: 6| Step: 1
Training loss: 1.408576250076294
Validation loss: 2.136076251665751

Epoch: 6| Step: 2
Training loss: 1.0324742794036865
Validation loss: 2.19105726480484

Epoch: 6| Step: 3
Training loss: 0.9287075400352478
Validation loss: 2.2345876892407737

Epoch: 6| Step: 4
Training loss: 1.3716802597045898
Validation loss: 2.130981723467509

Epoch: 6| Step: 5
Training loss: 0.7887520790100098
Validation loss: 2.17869500319163

Epoch: 6| Step: 6
Training loss: 1.187595009803772
Validation loss: 2.1234318216641745

Epoch: 6| Step: 7
Training loss: 1.4224858283996582
Validation loss: 2.1489813923835754

Epoch: 6| Step: 8
Training loss: 1.0955809354782104
Validation loss: 2.162864029407501

Epoch: 6| Step: 9
Training loss: 0.9082181453704834
Validation loss: 2.1644126176834106

Epoch: 6| Step: 10
Training loss: 1.1947970390319824
Validation loss: 2.2560009558995566

Epoch: 6| Step: 11
Training loss: 1.4998235702514648
Validation loss: 2.3430325587590537

Epoch: 6| Step: 12
Training loss: 1.2143186330795288
Validation loss: 2.3006280064582825

Epoch: 6| Step: 13
Training loss: 1.4184871912002563
Validation loss: 2.3076465725898743

Epoch: 109| Step: 0
Training loss: 1.66098952293396
Validation loss: 2.301992098490397

Epoch: 6| Step: 1
Training loss: 1.4062421321868896
Validation loss: 2.283922473589579

Epoch: 6| Step: 2
Training loss: 1.4365746974945068
Validation loss: 2.2200514674186707

Epoch: 6| Step: 3
Training loss: 0.7321324348449707
Validation loss: 2.1610422333081565

Epoch: 6| Step: 4
Training loss: 1.0179466009140015
Validation loss: 2.227340817451477

Epoch: 6| Step: 5
Training loss: 1.2166486978530884
Validation loss: 2.2388203938802085

Epoch: 6| Step: 6
Training loss: 1.611310601234436
Validation loss: 2.2060453693072

Epoch: 6| Step: 7
Training loss: 1.213973045349121
Validation loss: 2.1910868088404336

Epoch: 6| Step: 8
Training loss: 1.8539944887161255
Validation loss: 2.1103569666544595

Epoch: 6| Step: 9
Training loss: 0.7543842196464539
Validation loss: 2.2651564478874207

Epoch: 6| Step: 10
Training loss: 1.3298356533050537
Validation loss: 2.2758870919545493

Epoch: 6| Step: 11
Training loss: 0.8446580171585083
Validation loss: 2.3153109153111777

Epoch: 6| Step: 12
Training loss: 1.5332448482513428
Validation loss: 2.2552066246668496

Epoch: 6| Step: 13
Training loss: 0.9169095754623413
Validation loss: 2.2130165894826255

Epoch: 110| Step: 0
Training loss: 1.1090757846832275
Validation loss: 2.2115363279978433

Epoch: 6| Step: 1
Training loss: 1.6282895803451538
Validation loss: 2.2108621994654336

Epoch: 6| Step: 2
Training loss: 1.1732134819030762
Validation loss: 2.2179139455159507

Epoch: 6| Step: 3
Training loss: 1.1330605745315552
Validation loss: 2.2161817153294883

Epoch: 6| Step: 4
Training loss: 1.8161168098449707
Validation loss: 2.1512820521990457

Epoch: 6| Step: 5
Training loss: 0.8620520830154419
Validation loss: 2.153514583905538

Epoch: 6| Step: 6
Training loss: 1.368736982345581
Validation loss: 2.2313805421193442

Epoch: 6| Step: 7
Training loss: 0.9927879571914673
Validation loss: 2.1993164817492166

Epoch: 6| Step: 8
Training loss: 1.6221165657043457
Validation loss: 2.2038418650627136

Epoch: 6| Step: 9
Training loss: 1.2096374034881592
Validation loss: 2.2861762046813965

Epoch: 6| Step: 10
Training loss: 0.5287668704986572
Validation loss: 2.1588436365127563

Epoch: 6| Step: 11
Training loss: 1.0609978437423706
Validation loss: 2.1542232235272727

Epoch: 6| Step: 12
Training loss: 1.0429874658584595
Validation loss: 2.156161884466807

Epoch: 6| Step: 13
Training loss: 0.9967293739318848
Validation loss: 2.1921840707461038

Epoch: 111| Step: 0
Training loss: 0.7054595947265625
Validation loss: 2.1629796028137207

Epoch: 6| Step: 1
Training loss: 0.5313450694084167
Validation loss: 2.1970783472061157

Epoch: 6| Step: 2
Training loss: 0.9784539937973022
Validation loss: 2.1817320187886557

Epoch: 6| Step: 3
Training loss: 1.1344389915466309
Validation loss: 2.1510932644208274

Epoch: 6| Step: 4
Training loss: 0.7213732600212097
Validation loss: 2.1045825481414795

Epoch: 6| Step: 5
Training loss: 1.4545365571975708
Validation loss: 2.195313553015391

Epoch: 6| Step: 6
Training loss: 1.2749667167663574
Validation loss: 2.158808489640554

Epoch: 6| Step: 7
Training loss: 1.6245582103729248
Validation loss: 2.178482194741567

Epoch: 6| Step: 8
Training loss: 1.4528664350509644
Validation loss: 2.1816627979278564

Epoch: 6| Step: 9
Training loss: 1.0412163734436035
Validation loss: 2.1820987661679587

Epoch: 6| Step: 10
Training loss: 1.3669019937515259
Validation loss: 2.241145610809326

Epoch: 6| Step: 11
Training loss: 1.510610818862915
Validation loss: 2.2575329144795737

Epoch: 6| Step: 12
Training loss: 1.1663761138916016
Validation loss: 2.240247825781504

Epoch: 6| Step: 13
Training loss: 1.387600064277649
Validation loss: 2.1838403145472207

Epoch: 112| Step: 0
Training loss: 0.5464873313903809
Validation loss: 2.1676217516263327

Epoch: 6| Step: 1
Training loss: 0.902910053730011
Validation loss: 2.1489331126213074

Epoch: 6| Step: 2
Training loss: 1.7011971473693848
Validation loss: 2.1808934807777405

Epoch: 6| Step: 3
Training loss: 1.2546690702438354
Validation loss: 2.1516045928001404

Epoch: 6| Step: 4
Training loss: 1.0346386432647705
Validation loss: 2.168696562449137

Epoch: 6| Step: 5
Training loss: 1.0490221977233887
Validation loss: 2.15911211570104

Epoch: 6| Step: 6
Training loss: 0.6833099722862244
Validation loss: 2.1488016843795776

Epoch: 6| Step: 7
Training loss: 1.2083489894866943
Validation loss: 2.169815103212992

Epoch: 6| Step: 8
Training loss: 1.3981434106826782
Validation loss: 2.175516923268636

Epoch: 6| Step: 9
Training loss: 1.4323382377624512
Validation loss: 2.21218870083491

Epoch: 6| Step: 10
Training loss: 1.5243772268295288
Validation loss: 2.2643335858980813

Epoch: 6| Step: 11
Training loss: 1.3338433504104614
Validation loss: 2.214881738026937

Epoch: 6| Step: 12
Training loss: 1.0065280199050903
Validation loss: 2.1960823138554892

Epoch: 6| Step: 13
Training loss: 0.9774417877197266
Validation loss: 2.1696561574935913

Epoch: 113| Step: 0
Training loss: 0.6818364858627319
Validation loss: 2.1321327090263367

Epoch: 6| Step: 1
Training loss: 1.4675147533416748
Validation loss: 2.1714048186937966

Epoch: 6| Step: 2
Training loss: 1.318236231803894
Validation loss: 2.274197995662689

Epoch: 6| Step: 3
Training loss: 0.8190898299217224
Validation loss: 2.2137378056844077

Epoch: 6| Step: 4
Training loss: 0.9529005289077759
Validation loss: 2.214293956756592

Epoch: 6| Step: 5
Training loss: 0.9978048801422119
Validation loss: 2.218442380428314

Epoch: 6| Step: 6
Training loss: 1.557375431060791
Validation loss: 2.1568130056063333

Epoch: 6| Step: 7
Training loss: 1.5863897800445557
Validation loss: 2.236216108004252

Epoch: 6| Step: 8
Training loss: 1.4369142055511475
Validation loss: 2.1728911797205606

Epoch: 6| Step: 9
Training loss: 0.8654048442840576
Validation loss: 2.148925761381785

Epoch: 6| Step: 10
Training loss: 0.7917401194572449
Validation loss: 2.2209307154019675

Epoch: 6| Step: 11
Training loss: 1.1640225648880005
Validation loss: 2.176672716935476

Epoch: 6| Step: 12
Training loss: 0.9080376029014587
Validation loss: 2.2149529258410134

Epoch: 6| Step: 13
Training loss: 1.3777025938034058
Validation loss: 2.18696391582489

Epoch: 114| Step: 0
Training loss: 0.573839545249939
Validation loss: 2.2694221138954163

Epoch: 6| Step: 1
Training loss: 1.0436265468597412
Validation loss: 2.1594200929005942

Epoch: 6| Step: 2
Training loss: 1.14714515209198
Validation loss: 2.1699251731236777

Epoch: 6| Step: 3
Training loss: 0.8161996603012085
Validation loss: 2.18535985549291

Epoch: 6| Step: 4
Training loss: 1.023185133934021
Validation loss: 2.223287502924601

Epoch: 6| Step: 5
Training loss: 1.664130449295044
Validation loss: 2.115835746129354

Epoch: 6| Step: 6
Training loss: 0.7892464399337769
Validation loss: 2.1296538710594177

Epoch: 6| Step: 7
Training loss: 0.8900049924850464
Validation loss: 2.1682478388150535

Epoch: 6| Step: 8
Training loss: 1.2299556732177734
Validation loss: 2.177412430445353

Epoch: 6| Step: 9
Training loss: 2.258460521697998
Validation loss: 2.197004497051239

Epoch: 6| Step: 10
Training loss: 1.0075221061706543
Validation loss: 2.24882048368454

Epoch: 6| Step: 11
Training loss: 0.9504901766777039
Validation loss: 2.2770384748776755

Epoch: 6| Step: 12
Training loss: 1.2101366519927979
Validation loss: 2.2667564948399863

Epoch: 6| Step: 13
Training loss: 1.0317051410675049
Validation loss: 2.254318277041117

Epoch: 115| Step: 0
Training loss: 1.0277059078216553
Validation loss: 2.308734953403473

Epoch: 6| Step: 1
Training loss: 1.2381222248077393
Validation loss: 2.1580613255500793

Epoch: 6| Step: 2
Training loss: 0.9098584651947021
Validation loss: 2.2299319307009378

Epoch: 6| Step: 3
Training loss: 1.3129498958587646
Validation loss: 2.2015215158462524

Epoch: 6| Step: 4
Training loss: 0.7303776144981384
Validation loss: 2.238477110862732

Epoch: 6| Step: 5
Training loss: 1.078831672668457
Validation loss: 2.203753093878428

Epoch: 6| Step: 6
Training loss: 1.3530023097991943
Validation loss: 2.184202174345652

Epoch: 6| Step: 7
Training loss: 1.1212435960769653
Validation loss: 2.1322340766588845

Epoch: 6| Step: 8
Training loss: 1.4762396812438965
Validation loss: 2.2487391034762063

Epoch: 6| Step: 9
Training loss: 1.441521167755127
Validation loss: 2.307568828264872

Epoch: 6| Step: 10
Training loss: 1.2302768230438232
Validation loss: 2.2719399134318032

Epoch: 6| Step: 11
Training loss: 0.6662811636924744
Validation loss: 2.300687630971273

Epoch: 6| Step: 12
Training loss: 0.9912676215171814
Validation loss: 2.201610783735911

Epoch: 6| Step: 13
Training loss: 1.0192848443984985
Validation loss: 2.1816961765289307

Epoch: 116| Step: 0
Training loss: 1.0767985582351685
Validation loss: 2.1711838841438293

Epoch: 6| Step: 1
Training loss: 1.2945011854171753
Validation loss: 2.1008347471555076

Epoch: 6| Step: 2
Training loss: 1.096060872077942
Validation loss: 2.1960385839144387

Epoch: 6| Step: 3
Training loss: 0.7323712706565857
Validation loss: 2.176350732644399

Epoch: 6| Step: 4
Training loss: 1.292073130607605
Validation loss: 2.192697445551554

Epoch: 6| Step: 5
Training loss: 1.6624839305877686
Validation loss: 2.216005186239878

Epoch: 6| Step: 6
Training loss: 0.6389493942260742
Validation loss: 2.1128286520640054

Epoch: 6| Step: 7
Training loss: 0.8537936210632324
Validation loss: 2.2232430378595986

Epoch: 6| Step: 8
Training loss: 1.040994644165039
Validation loss: 2.1872560580571494

Epoch: 6| Step: 9
Training loss: 1.2091718912124634
Validation loss: 2.2224958737691245

Epoch: 6| Step: 10
Training loss: 1.2579448223114014
Validation loss: 2.1990525921185813

Epoch: 6| Step: 11
Training loss: 1.1177469491958618
Validation loss: 2.23168816169103

Epoch: 6| Step: 12
Training loss: 0.9318917393684387
Validation loss: 2.195072809855143

Epoch: 6| Step: 13
Training loss: 1.372598648071289
Validation loss: 2.190802752971649

Epoch: 117| Step: 0
Training loss: 0.6250362396240234
Validation loss: 2.1139634450276694

Epoch: 6| Step: 1
Training loss: 0.9546800255775452
Validation loss: 2.1696141560872397

Epoch: 6| Step: 2
Training loss: 1.2598167657852173
Validation loss: 2.290933887163798

Epoch: 6| Step: 3
Training loss: 1.5457983016967773
Validation loss: 2.2761894265810647

Epoch: 6| Step: 4
Training loss: 1.2729098796844482
Validation loss: 2.2638418674468994

Epoch: 6| Step: 5
Training loss: 1.4845919609069824
Validation loss: 2.24607123931249

Epoch: 6| Step: 6
Training loss: 0.7382550239562988
Validation loss: 2.2173142234484353

Epoch: 6| Step: 7
Training loss: 1.1175984144210815
Validation loss: 2.2164472937583923

Epoch: 6| Step: 8
Training loss: 1.5566763877868652
Validation loss: 2.2238081296284995

Epoch: 6| Step: 9
Training loss: 0.7176038026809692
Validation loss: 2.121954361597697

Epoch: 6| Step: 10
Training loss: 0.4850394129753113
Validation loss: 2.1388044555981955

Epoch: 6| Step: 11
Training loss: 1.1546423435211182
Validation loss: 2.2219152649243674

Epoch: 6| Step: 12
Training loss: 1.0874648094177246
Validation loss: 2.2456509272257485

Epoch: 6| Step: 13
Training loss: 1.3449475765228271
Validation loss: 2.162984013557434

Epoch: 118| Step: 0
Training loss: 1.1470624208450317
Validation loss: 2.2323322693506875

Epoch: 6| Step: 1
Training loss: 1.2133097648620605
Validation loss: 2.2339521447817483

Epoch: 6| Step: 2
Training loss: 1.3679150342941284
Validation loss: 2.1181785464286804

Epoch: 6| Step: 3
Training loss: 0.5788305997848511
Validation loss: 2.170160174369812

Epoch: 6| Step: 4
Training loss: 0.6189519762992859
Validation loss: 2.1981302897135415

Epoch: 6| Step: 5
Training loss: 1.3596396446228027
Validation loss: 2.2972801129023233

Epoch: 6| Step: 6
Training loss: 1.3786373138427734
Validation loss: 2.2431641817092896

Epoch: 6| Step: 7
Training loss: 1.6223747730255127
Validation loss: 2.219094733397166

Epoch: 6| Step: 8
Training loss: 1.3876689672470093
Validation loss: 2.2308119336764016

Epoch: 6| Step: 9
Training loss: 0.7219333648681641
Validation loss: 2.238944888114929

Epoch: 6| Step: 10
Training loss: 1.2647205591201782
Validation loss: 2.1856570641199746

Epoch: 6| Step: 11
Training loss: 0.6663165092468262
Validation loss: 2.190894623597463

Epoch: 6| Step: 12
Training loss: 1.170086145401001
Validation loss: 2.145117779572805

Epoch: 6| Step: 13
Training loss: 1.0820903778076172
Validation loss: 2.173209011554718

Epoch: 119| Step: 0
Training loss: 0.808584988117218
Validation loss: 2.12736847003301

Epoch: 6| Step: 1
Training loss: 1.357393503189087
Validation loss: 2.1908676425615945

Epoch: 6| Step: 2
Training loss: 0.806073009967804
Validation loss: 2.212222456932068

Epoch: 6| Step: 3
Training loss: 0.957943320274353
Validation loss: 2.19541068871816

Epoch: 6| Step: 4
Training loss: 0.820151150226593
Validation loss: 2.149080495039622

Epoch: 6| Step: 5
Training loss: 0.7504804730415344
Validation loss: 2.174937665462494

Epoch: 6| Step: 6
Training loss: 1.2432239055633545
Validation loss: 2.192815065383911

Epoch: 6| Step: 7
Training loss: 1.6456105709075928
Validation loss: 2.2645787994066873

Epoch: 6| Step: 8
Training loss: 1.3223224878311157
Validation loss: 2.2771873474121094

Epoch: 6| Step: 9
Training loss: 0.8531824946403503
Validation loss: 2.3037402431170144

Epoch: 6| Step: 10
Training loss: 1.4092960357666016
Validation loss: 2.2124744256337485

Epoch: 6| Step: 11
Training loss: 1.1069037914276123
Validation loss: 2.2167398929595947

Epoch: 6| Step: 12
Training loss: 0.601431131362915
Validation loss: 2.1388791600863137

Epoch: 6| Step: 13
Training loss: 1.6012648344039917
Validation loss: 2.1560331185658774

Epoch: 120| Step: 0
Training loss: 1.3546488285064697
Validation loss: 2.1614160736401877

Epoch: 6| Step: 1
Training loss: 0.9066181778907776
Validation loss: 2.2249592940012612

Epoch: 6| Step: 2
Training loss: 1.2249575853347778
Validation loss: 2.20329882701238

Epoch: 6| Step: 3
Training loss: 0.8803701400756836
Validation loss: 2.1904998222986856

Epoch: 6| Step: 4
Training loss: 0.3860577642917633
Validation loss: 2.229922115802765

Epoch: 6| Step: 5
Training loss: 1.0770454406738281
Validation loss: 2.257654388745626

Epoch: 6| Step: 6
Training loss: 1.1722886562347412
Validation loss: 2.233383278052012

Epoch: 6| Step: 7
Training loss: 1.1529920101165771
Validation loss: 2.2147538463274636

Epoch: 6| Step: 8
Training loss: 0.9150615930557251
Validation loss: 2.22920960187912

Epoch: 6| Step: 9
Training loss: 1.1980806589126587
Validation loss: 2.230273127555847

Epoch: 6| Step: 10
Training loss: 0.7623022794723511
Validation loss: 2.2104220390319824

Epoch: 6| Step: 11
Training loss: 1.103214979171753
Validation loss: 2.186607380708059

Epoch: 6| Step: 12
Training loss: 0.7629366517066956
Validation loss: 2.218929171562195

Epoch: 6| Step: 13
Training loss: 1.205427646636963
Validation loss: 2.206070681413015

Epoch: 121| Step: 0
Training loss: 0.747894287109375
Validation loss: 2.205038626988729

Epoch: 6| Step: 1
Training loss: 1.167358160018921
Validation loss: 2.199743310610453

Epoch: 6| Step: 2
Training loss: 1.1576101779937744
Validation loss: 2.200670063495636

Epoch: 6| Step: 3
Training loss: 0.7613450288772583
Validation loss: 2.2133674025535583

Epoch: 6| Step: 4
Training loss: 1.206467866897583
Validation loss: 2.2645748058954873

Epoch: 6| Step: 5
Training loss: 1.3194117546081543
Validation loss: 2.2613341410954795

Epoch: 6| Step: 6
Training loss: 0.5288394689559937
Validation loss: 2.2522191206614175

Epoch: 6| Step: 7
Training loss: 0.6977419853210449
Validation loss: 2.1952246030171714

Epoch: 6| Step: 8
Training loss: 1.0461664199829102
Validation loss: 2.1838444471359253

Epoch: 6| Step: 9
Training loss: 0.9869873523712158
Validation loss: 2.1510222951571145

Epoch: 6| Step: 10
Training loss: 1.8106979131698608
Validation loss: 2.2157430251439414

Epoch: 6| Step: 11
Training loss: 1.363244652748108
Validation loss: 2.2097432812054953

Epoch: 6| Step: 12
Training loss: 0.772161602973938
Validation loss: 2.194076200326284

Epoch: 6| Step: 13
Training loss: 1.130491018295288
Validation loss: 2.167264004548391

Epoch: 122| Step: 0
Training loss: 0.5037602782249451
Validation loss: 2.182113607724508

Epoch: 6| Step: 1
Training loss: 0.872886598110199
Validation loss: 2.2026926279067993

Epoch: 6| Step: 2
Training loss: 1.1579902172088623
Validation loss: 2.229661206404368

Epoch: 6| Step: 3
Training loss: 1.8155399560928345
Validation loss: 2.206031084060669

Epoch: 6| Step: 4
Training loss: 1.1756572723388672
Validation loss: 2.2084339261054993

Epoch: 6| Step: 5
Training loss: 1.3916987180709839
Validation loss: 2.188702325026194

Epoch: 6| Step: 6
Training loss: 1.451383352279663
Validation loss: 2.2420931657155356

Epoch: 6| Step: 7
Training loss: 0.8690641522407532
Validation loss: 2.1732198198636374

Epoch: 6| Step: 8
Training loss: 0.8552437424659729
Validation loss: 2.1767638524373374

Epoch: 6| Step: 9
Training loss: 0.6728858947753906
Validation loss: 2.219707210858663

Epoch: 6| Step: 10
Training loss: 0.6332680583000183
Validation loss: 2.213312864303589

Epoch: 6| Step: 11
Training loss: 0.8473168611526489
Validation loss: 2.2357171177864075

Epoch: 6| Step: 12
Training loss: 0.7468932867050171
Validation loss: 2.2346264521280923

Epoch: 6| Step: 13
Training loss: 1.0248867273330688
Validation loss: 2.2628562847773233

Epoch: 123| Step: 0
Training loss: 1.0736827850341797
Validation loss: 2.141980508963267

Epoch: 6| Step: 1
Training loss: 1.310523509979248
Validation loss: 2.2031280994415283

Epoch: 6| Step: 2
Training loss: 0.6181840896606445
Validation loss: 2.2143171032269797

Epoch: 6| Step: 3
Training loss: 1.1486018896102905
Validation loss: 2.1626792748769126

Epoch: 6| Step: 4
Training loss: 1.2494149208068848
Validation loss: 2.2025516430536904

Epoch: 6| Step: 5
Training loss: 0.9193642735481262
Validation loss: 2.2909345626831055

Epoch: 6| Step: 6
Training loss: 0.80107581615448
Validation loss: 2.173254668712616

Epoch: 6| Step: 7
Training loss: 0.8205960392951965
Validation loss: 2.195964733759562

Epoch: 6| Step: 8
Training loss: 1.5408233404159546
Validation loss: 2.200212597846985

Epoch: 6| Step: 9
Training loss: 1.4179024696350098
Validation loss: 2.2139634490013123

Epoch: 6| Step: 10
Training loss: 0.6603567600250244
Validation loss: 2.197605927785238

Epoch: 6| Step: 11
Training loss: 0.8823453187942505
Validation loss: 2.2387154499689736

Epoch: 6| Step: 12
Training loss: 0.7383204698562622
Validation loss: 2.1357415119806924

Epoch: 6| Step: 13
Training loss: 0.4931102395057678
Validation loss: 2.1952218214670816

Epoch: 124| Step: 0
Training loss: 1.1781667470932007
Validation loss: 2.2398786147435508

Epoch: 6| Step: 1
Training loss: 0.9507176280021667
Validation loss: 2.17542556921641

Epoch: 6| Step: 2
Training loss: 1.1430134773254395
Validation loss: 2.2552172938982644

Epoch: 6| Step: 3
Training loss: 0.6904937028884888
Validation loss: 2.1583839058876038

Epoch: 6| Step: 4
Training loss: 1.0742523670196533
Validation loss: 2.2064666748046875

Epoch: 6| Step: 5
Training loss: 1.1531038284301758
Validation loss: 2.25061305363973

Epoch: 6| Step: 6
Training loss: 0.9645137786865234
Validation loss: 2.340152124563853

Epoch: 6| Step: 7
Training loss: 1.9410829544067383
Validation loss: 2.3165069023768106

Epoch: 6| Step: 8
Training loss: 0.8384535908699036
Validation loss: 2.303868611653646

Epoch: 6| Step: 9
Training loss: 1.1434601545333862
Validation loss: 2.2264582316080728

Epoch: 6| Step: 10
Training loss: 0.8859293460845947
Validation loss: 2.240540564060211

Epoch: 6| Step: 11
Training loss: 1.0493334531784058
Validation loss: 2.217503607273102

Epoch: 6| Step: 12
Training loss: 1.1563035249710083
Validation loss: 2.197986900806427

Epoch: 6| Step: 13
Training loss: 1.3202943801879883
Validation loss: 2.2389419873555503

Epoch: 125| Step: 0
Training loss: 1.1945865154266357
Validation loss: 2.1700661977132163

Epoch: 6| Step: 1
Training loss: 1.0907037258148193
Validation loss: 2.2124561071395874

Epoch: 6| Step: 2
Training loss: 1.239931344985962
Validation loss: 2.1582659085591636

Epoch: 6| Step: 3
Training loss: 1.0461862087249756
Validation loss: 2.1547765930493674

Epoch: 6| Step: 4
Training loss: 0.7004934549331665
Validation loss: 2.2027247548103333

Epoch: 6| Step: 5
Training loss: 1.2296147346496582
Validation loss: 2.210962235927582

Epoch: 6| Step: 6
Training loss: 1.1220250129699707
Validation loss: 2.2773714661598206

Epoch: 6| Step: 7
Training loss: 0.7893604040145874
Validation loss: 2.2311078906059265

Epoch: 6| Step: 8
Training loss: 0.7486200928688049
Validation loss: 2.1901328961054483

Epoch: 6| Step: 9
Training loss: 1.1232959032058716
Validation loss: 2.1948949495951333

Epoch: 6| Step: 10
Training loss: 0.8070155382156372
Validation loss: 2.2252007722854614

Epoch: 6| Step: 11
Training loss: 1.4867274761199951
Validation loss: 2.2319724758466086

Epoch: 6| Step: 12
Training loss: 1.3151534795761108
Validation loss: 2.218411405881246

Epoch: 6| Step: 13
Training loss: 1.0891200304031372
Validation loss: 2.168957988421122

Epoch: 126| Step: 0
Training loss: 0.9059146642684937
Validation loss: 2.153229037920634

Epoch: 6| Step: 1
Training loss: 0.7201653122901917
Validation loss: 2.172506312529246

Epoch: 6| Step: 2
Training loss: 0.6528319716453552
Validation loss: 2.164652943611145

Epoch: 6| Step: 3
Training loss: 1.1888549327850342
Validation loss: 2.2574377059936523

Epoch: 6| Step: 4
Training loss: 1.4149235486984253
Validation loss: 2.260144511858622

Epoch: 6| Step: 5
Training loss: 0.851507306098938
Validation loss: 2.2828922867774963

Epoch: 6| Step: 6
Training loss: 1.7991573810577393
Validation loss: 2.279608170191447

Epoch: 6| Step: 7
Training loss: 0.9449546933174133
Validation loss: 2.2298885782559714

Epoch: 6| Step: 8
Training loss: 0.7913796901702881
Validation loss: 2.179286479949951

Epoch: 6| Step: 9
Training loss: 0.6964300870895386
Validation loss: 2.1817781726519265

Epoch: 6| Step: 10
Training loss: 1.2148151397705078
Validation loss: 2.2111233671506247

Epoch: 6| Step: 11
Training loss: 1.3214714527130127
Validation loss: 2.1927740573883057

Epoch: 6| Step: 12
Training loss: 0.8117661476135254
Validation loss: 2.171951154867808

Epoch: 6| Step: 13
Training loss: 1.1897997856140137
Validation loss: 2.20059472322464

Epoch: 127| Step: 0
Training loss: 0.7280697822570801
Validation loss: 2.208395838737488

Epoch: 6| Step: 1
Training loss: 1.0124778747558594
Validation loss: 2.263313670953115

Epoch: 6| Step: 2
Training loss: 1.2988955974578857
Validation loss: 2.2309639851252236

Epoch: 6| Step: 3
Training loss: 1.4180724620819092
Validation loss: 2.2902517120043435

Epoch: 6| Step: 4
Training loss: 0.9842222332954407
Validation loss: 2.1951762437820435

Epoch: 6| Step: 5
Training loss: 0.9373855590820312
Validation loss: 2.213391820589701

Epoch: 6| Step: 6
Training loss: 0.9228986501693726
Validation loss: 2.2260632713635764

Epoch: 6| Step: 7
Training loss: 1.1170611381530762
Validation loss: 2.272280752658844

Epoch: 6| Step: 8
Training loss: 1.206109642982483
Validation loss: 2.2538208762804666

Epoch: 6| Step: 9
Training loss: 0.9166398644447327
Validation loss: 2.26830393075943

Epoch: 6| Step: 10
Training loss: 0.6818492412567139
Validation loss: 2.2062422831853232

Epoch: 6| Step: 11
Training loss: 0.6852584481239319
Validation loss: 2.149890343348185

Epoch: 6| Step: 12
Training loss: 0.7478450536727905
Validation loss: 2.20042622089386

Epoch: 6| Step: 13
Training loss: 1.0197523832321167
Validation loss: 2.2477863828341165

Epoch: 128| Step: 0
Training loss: 0.9107053875923157
Validation loss: 2.2273040413856506

Epoch: 6| Step: 1
Training loss: 1.0743145942687988
Validation loss: 2.2497783104578652

Epoch: 6| Step: 2
Training loss: 0.6908446550369263
Validation loss: 2.2669533491134644

Epoch: 6| Step: 3
Training loss: 1.2020461559295654
Validation loss: 2.2556621432304382

Epoch: 6| Step: 4
Training loss: 0.9400869011878967
Validation loss: 2.2022891839345298

Epoch: 6| Step: 5
Training loss: 1.0371381044387817
Validation loss: 2.167368253072103

Epoch: 6| Step: 6
Training loss: 0.8637622594833374
Validation loss: 2.171128511428833

Epoch: 6| Step: 7
Training loss: 0.5368791222572327
Validation loss: 2.2481356461842856

Epoch: 6| Step: 8
Training loss: 1.448972463607788
Validation loss: 2.165073355038961

Epoch: 6| Step: 9
Training loss: 0.942061185836792
Validation loss: 2.1587750713030496

Epoch: 6| Step: 10
Training loss: 0.7359684705734253
Validation loss: 2.196382542451223

Epoch: 6| Step: 11
Training loss: 0.9312597513198853
Validation loss: 2.2223280668258667

Epoch: 6| Step: 12
Training loss: 0.999554455280304
Validation loss: 2.204316794872284

Epoch: 6| Step: 13
Training loss: 1.388270378112793
Validation loss: 2.212611416975657

Epoch: 129| Step: 0
Training loss: 1.0825730562210083
Validation loss: 2.2054595351219177

Epoch: 6| Step: 1
Training loss: 0.9544488787651062
Validation loss: 2.2224955757459006

Epoch: 6| Step: 2
Training loss: 0.6492923498153687
Validation loss: 2.2217690149943032

Epoch: 6| Step: 3
Training loss: 0.8259775638580322
Validation loss: 2.18943057457606

Epoch: 6| Step: 4
Training loss: 1.1431851387023926
Validation loss: 2.2569833199183145

Epoch: 6| Step: 5
Training loss: 1.2209326028823853
Validation loss: 2.2007750074068704

Epoch: 6| Step: 6
Training loss: 0.5726727247238159
Validation loss: 2.3068429629007974

Epoch: 6| Step: 7
Training loss: 1.2722342014312744
Validation loss: 2.235360046227773

Epoch: 6| Step: 8
Training loss: 1.0529500246047974
Validation loss: 2.2693464954694114

Epoch: 6| Step: 9
Training loss: 0.45725029706954956
Validation loss: 2.2681739727656045

Epoch: 6| Step: 10
Training loss: 1.4206950664520264
Validation loss: 2.289710362752279

Epoch: 6| Step: 11
Training loss: 1.0344700813293457
Validation loss: 2.234378218650818

Epoch: 6| Step: 12
Training loss: 0.7972468137741089
Validation loss: 2.2518282334009805

Epoch: 6| Step: 13
Training loss: 0.9888057708740234
Validation loss: 2.253762642542521

Epoch: 130| Step: 0
Training loss: 0.7892643213272095
Validation loss: 2.2206785877545676

Epoch: 6| Step: 1
Training loss: 1.2317488193511963
Validation loss: 2.23254531621933

Epoch: 6| Step: 2
Training loss: 0.8300493955612183
Validation loss: 2.1736775239308677

Epoch: 6| Step: 3
Training loss: 1.1843544244766235
Validation loss: 2.2225049336751304

Epoch: 6| Step: 4
Training loss: 0.8175001740455627
Validation loss: 2.2420838276545205

Epoch: 6| Step: 5
Training loss: 0.633968710899353
Validation loss: 2.2901986241340637

Epoch: 6| Step: 6
Training loss: 0.9882453083992004
Validation loss: 2.3143357038497925

Epoch: 6| Step: 7
Training loss: 0.973323404788971
Validation loss: 2.2130474050839744

Epoch: 6| Step: 8
Training loss: 1.2723469734191895
Validation loss: 2.215577721595764

Epoch: 6| Step: 9
Training loss: 0.8216840624809265
Validation loss: 2.2573405106862388

Epoch: 6| Step: 10
Training loss: 0.5483717322349548
Validation loss: 2.248099764188131

Epoch: 6| Step: 11
Training loss: 2.0242936611175537
Validation loss: 2.227945605913798

Epoch: 6| Step: 12
Training loss: 0.8813194036483765
Validation loss: 2.188372850418091

Epoch: 6| Step: 13
Training loss: 0.65447998046875
Validation loss: 2.190226058165232

Epoch: 131| Step: 0
Training loss: 1.132949948310852
Validation loss: 2.2444024085998535

Epoch: 6| Step: 1
Training loss: 0.6155427694320679
Validation loss: 2.207741061846415

Epoch: 6| Step: 2
Training loss: 0.5681290626525879
Validation loss: 2.308268189430237

Epoch: 6| Step: 3
Training loss: 0.7796628475189209
Validation loss: 2.2581434845924377

Epoch: 6| Step: 4
Training loss: 1.47791588306427
Validation loss: 2.2818168799082437

Epoch: 6| Step: 5
Training loss: 1.3689756393432617
Validation loss: 2.199516793092092

Epoch: 6| Step: 6
Training loss: 0.8918834924697876
Validation loss: 2.2274558941523233

Epoch: 6| Step: 7
Training loss: 0.5882306098937988
Validation loss: 2.2443633476893106

Epoch: 6| Step: 8
Training loss: 0.45759856700897217
Validation loss: 2.276665965716044

Epoch: 6| Step: 9
Training loss: 1.0857056379318237
Validation loss: 2.1734830935796103

Epoch: 6| Step: 10
Training loss: 1.1747255325317383
Validation loss: 2.195176343123118

Epoch: 6| Step: 11
Training loss: 1.2287808656692505
Validation loss: 2.2772454420725503

Epoch: 6| Step: 12
Training loss: 1.0109766721725464
Validation loss: 2.2023953994115195

Epoch: 6| Step: 13
Training loss: 0.8674798607826233
Validation loss: 2.1966157952944436

Epoch: 132| Step: 0
Training loss: 0.9571276307106018
Validation loss: 2.181475043296814

Epoch: 6| Step: 1
Training loss: 1.2322049140930176
Validation loss: 2.22342582543691

Epoch: 6| Step: 2
Training loss: 0.8975337743759155
Validation loss: 2.204600671927134

Epoch: 6| Step: 3
Training loss: 0.6984719038009644
Validation loss: 2.3063095609347024

Epoch: 6| Step: 4
Training loss: 1.2852444648742676
Validation loss: 2.2259834011395774

Epoch: 6| Step: 5
Training loss: 0.3403589129447937
Validation loss: 2.226271867752075

Epoch: 6| Step: 6
Training loss: 1.233154058456421
Validation loss: 2.1665745973587036

Epoch: 6| Step: 7
Training loss: 0.8000540733337402
Validation loss: 2.218973239262899

Epoch: 6| Step: 8
Training loss: 0.9436826705932617
Validation loss: 2.252816677093506

Epoch: 6| Step: 9
Training loss: 1.328026533126831
Validation loss: 2.2553388277689614

Epoch: 6| Step: 10
Training loss: 0.532275378704071
Validation loss: 2.246003826459249

Epoch: 6| Step: 11
Training loss: 1.1694471836090088
Validation loss: 2.2427371541659036

Epoch: 6| Step: 12
Training loss: 0.5949388146400452
Validation loss: 2.3066824078559875

Epoch: 6| Step: 13
Training loss: 0.48310062289237976
Validation loss: 2.2852186957995095

Epoch: 133| Step: 0
Training loss: 1.4078768491744995
Validation loss: 2.199453353881836

Epoch: 6| Step: 1
Training loss: 0.9403964281082153
Validation loss: 2.276485025882721

Epoch: 6| Step: 2
Training loss: 0.833025336265564
Validation loss: 2.340061585108439

Epoch: 6| Step: 3
Training loss: 0.8414648175239563
Validation loss: 2.2662760416666665

Epoch: 6| Step: 4
Training loss: 0.7169049978256226
Validation loss: 2.25150332848231

Epoch: 6| Step: 5
Training loss: 0.3832061290740967
Validation loss: 2.24993360042572

Epoch: 6| Step: 6
Training loss: 1.1249620914459229
Validation loss: 2.2186319629351297

Epoch: 6| Step: 7
Training loss: 0.9591655135154724
Validation loss: 2.21081813176473

Epoch: 6| Step: 8
Training loss: 1.4948679208755493
Validation loss: 2.263046701749166

Epoch: 6| Step: 9
Training loss: 0.38954734802246094
Validation loss: 2.2263373136520386

Epoch: 6| Step: 10
Training loss: 1.036402940750122
Validation loss: 2.253085494041443

Epoch: 6| Step: 11
Training loss: 0.8270728588104248
Validation loss: 2.2417596578598022

Epoch: 6| Step: 12
Training loss: 0.9341989755630493
Validation loss: 2.3027325868606567

Epoch: 6| Step: 13
Training loss: 0.8823670148849487
Validation loss: 2.2911228934923806

Epoch: 134| Step: 0
Training loss: 0.5731723308563232
Validation loss: 2.294679840405782

Epoch: 6| Step: 1
Training loss: 1.0687764883041382
Validation loss: 2.2694074710210166

Epoch: 6| Step: 2
Training loss: 0.6396030783653259
Validation loss: 2.3066659569740295

Epoch: 6| Step: 3
Training loss: 1.3028128147125244
Validation loss: 2.2946702043215432

Epoch: 6| Step: 4
Training loss: 0.8192317485809326
Validation loss: 2.2647632360458374

Epoch: 6| Step: 5
Training loss: 1.0099071264266968
Validation loss: 2.2728652159372964

Epoch: 6| Step: 6
Training loss: 0.7600791454315186
Validation loss: 2.262054999669393

Epoch: 6| Step: 7
Training loss: 1.0165050029754639
Validation loss: 2.206843098004659

Epoch: 6| Step: 8
Training loss: 1.0516977310180664
Validation loss: 2.2832255363464355

Epoch: 6| Step: 9
Training loss: 0.9316799640655518
Validation loss: 2.215272545814514

Epoch: 6| Step: 10
Training loss: 1.3463243246078491
Validation loss: 2.3298114935557046

Epoch: 6| Step: 11
Training loss: 1.0152089595794678
Validation loss: 2.25606107711792

Epoch: 6| Step: 12
Training loss: 0.7748283743858337
Validation loss: 2.2656323313713074

Epoch: 6| Step: 13
Training loss: 1.075985074043274
Validation loss: 2.309103786945343

Epoch: 135| Step: 0
Training loss: 1.2697652578353882
Validation loss: 2.344699482123057

Epoch: 6| Step: 1
Training loss: 0.9870202541351318
Validation loss: 2.3312344948450723

Epoch: 6| Step: 2
Training loss: 0.67046719789505
Validation loss: 2.249982496102651

Epoch: 6| Step: 3
Training loss: 0.5361780524253845
Validation loss: 2.2640228271484375

Epoch: 6| Step: 4
Training loss: 1.4443585872650146
Validation loss: 2.2343952854474387

Epoch: 6| Step: 5
Training loss: 0.8893824815750122
Validation loss: 2.1775786677996316

Epoch: 6| Step: 6
Training loss: 1.2044153213500977
Validation loss: 2.246923267841339

Epoch: 6| Step: 7
Training loss: 0.8434392213821411
Validation loss: 2.25688636302948

Epoch: 6| Step: 8
Training loss: 0.3077208399772644
Validation loss: 2.287192682425181

Epoch: 6| Step: 9
Training loss: 0.9657150506973267
Validation loss: 2.219219466050466

Epoch: 6| Step: 10
Training loss: 1.0718014240264893
Validation loss: 2.2348360617955527

Epoch: 6| Step: 11
Training loss: 0.9768845438957214
Validation loss: 2.3048328161239624

Epoch: 6| Step: 12
Training loss: 0.9102806448936462
Validation loss: 2.290326476097107

Epoch: 6| Step: 13
Training loss: 1.0750396251678467
Validation loss: 2.3285715182622275

Epoch: 136| Step: 0
Training loss: 0.669552206993103
Validation loss: 2.312313457330068

Epoch: 6| Step: 1
Training loss: 1.300723910331726
Validation loss: 2.340714395046234

Epoch: 6| Step: 2
Training loss: 0.46621155738830566
Validation loss: 2.267864485581716

Epoch: 6| Step: 3
Training loss: 0.8374752402305603
Validation loss: 2.2293102145195007

Epoch: 6| Step: 4
Training loss: 0.9186614751815796
Validation loss: 2.235936383406321

Epoch: 6| Step: 5
Training loss: 1.079160213470459
Validation loss: 2.2537896434466043

Epoch: 6| Step: 6
Training loss: 0.832552969455719
Validation loss: 2.1996227304140725

Epoch: 6| Step: 7
Training loss: 0.7324910163879395
Validation loss: 2.2482646306355796

Epoch: 6| Step: 8
Training loss: 1.1080964803695679
Validation loss: 2.149643301963806

Epoch: 6| Step: 9
Training loss: 1.111436367034912
Validation loss: 2.1696247458457947

Epoch: 6| Step: 10
Training loss: 0.7400983572006226
Validation loss: 2.1753891507784524

Epoch: 6| Step: 11
Training loss: 1.759519338607788
Validation loss: 2.25305829445521

Epoch: 6| Step: 12
Training loss: 0.6596809029579163
Validation loss: 2.320524573326111

Epoch: 6| Step: 13
Training loss: 1.184105396270752
Validation loss: 2.316735247770945

Epoch: 137| Step: 0
Training loss: 0.6041634678840637
Validation loss: 2.2408856749534607

Epoch: 6| Step: 1
Training loss: 1.2528806924819946
Validation loss: 2.2753453453381858

Epoch: 6| Step: 2
Training loss: 0.7721876502037048
Validation loss: 2.2257045110066733

Epoch: 6| Step: 3
Training loss: 0.8678988814353943
Validation loss: 2.2318304777145386

Epoch: 6| Step: 4
Training loss: 1.1019752025604248
Validation loss: 2.2040053009986877

Epoch: 6| Step: 5
Training loss: 0.9251406192779541
Validation loss: 2.2458972732226052

Epoch: 6| Step: 6
Training loss: 1.0790338516235352
Validation loss: 2.2655027707417807

Epoch: 6| Step: 7
Training loss: 0.9108632802963257
Validation loss: 2.241965353488922

Epoch: 6| Step: 8
Training loss: 0.9737421870231628
Validation loss: 2.2010086377461753

Epoch: 6| Step: 9
Training loss: 0.8748929500579834
Validation loss: 2.1838082671165466

Epoch: 6| Step: 10
Training loss: 0.9108342528343201
Validation loss: 2.2497377395629883

Epoch: 6| Step: 11
Training loss: 1.268505573272705
Validation loss: 2.331220726172129

Epoch: 6| Step: 12
Training loss: 0.7522608637809753
Validation loss: 2.2421942353248596

Epoch: 6| Step: 13
Training loss: 1.1382615566253662
Validation loss: 2.2652450601259866

Epoch: 138| Step: 0
Training loss: 0.841635525226593
Validation loss: 2.2706514795621238

Epoch: 6| Step: 1
Training loss: 1.0848873853683472
Validation loss: 2.243539273738861

Epoch: 6| Step: 2
Training loss: 1.1277985572814941
Validation loss: 2.2271331946055093

Epoch: 6| Step: 3
Training loss: 0.9039619565010071
Validation loss: 2.246640423933665

Epoch: 6| Step: 4
Training loss: 0.8788805603981018
Validation loss: 2.22552357117335

Epoch: 6| Step: 5
Training loss: 0.8400003910064697
Validation loss: 2.2408921122550964

Epoch: 6| Step: 6
Training loss: 0.9425379633903503
Validation loss: 2.23682032028834

Epoch: 6| Step: 7
Training loss: 0.5303784608840942
Validation loss: 2.281380812327067

Epoch: 6| Step: 8
Training loss: 0.6487683057785034
Validation loss: 2.289038062095642

Epoch: 6| Step: 9
Training loss: 0.79610276222229
Validation loss: 2.3039904832839966

Epoch: 6| Step: 10
Training loss: 1.045219898223877
Validation loss: 2.2572215795516968

Epoch: 6| Step: 11
Training loss: 0.9620506763458252
Validation loss: 2.272241751352946

Epoch: 6| Step: 12
Training loss: 0.8461806178092957
Validation loss: 2.2795717318852744

Epoch: 6| Step: 13
Training loss: 1.1408571004867554
Validation loss: 2.2498605449994407

Epoch: 139| Step: 0
Training loss: 0.7553535103797913
Validation loss: 2.2236803571383157

Epoch: 6| Step: 1
Training loss: 1.232596755027771
Validation loss: 2.2494738698005676

Epoch: 6| Step: 2
Training loss: 0.8599551916122437
Validation loss: 2.213955064614614

Epoch: 6| Step: 3
Training loss: 0.6942770481109619
Validation loss: 2.1774502992630005

Epoch: 6| Step: 4
Training loss: 0.7012674808502197
Validation loss: 2.2258348067601523

Epoch: 6| Step: 5
Training loss: 1.079445481300354
Validation loss: 2.1997488339742026

Epoch: 6| Step: 6
Training loss: 0.532599687576294
Validation loss: 2.231663783391317

Epoch: 6| Step: 7
Training loss: 1.1596579551696777
Validation loss: 2.415258208910624

Epoch: 6| Step: 8
Training loss: 0.8028562068939209
Validation loss: 2.3482433557510376

Epoch: 6| Step: 9
Training loss: 1.2717493772506714
Validation loss: 2.3644255797068277

Epoch: 6| Step: 10
Training loss: 1.2174404859542847
Validation loss: 2.2440873185793557

Epoch: 6| Step: 11
Training loss: 0.9747058153152466
Validation loss: 2.287199318408966

Epoch: 6| Step: 12
Training loss: 1.011659860610962
Validation loss: 2.2643317182858786

Epoch: 6| Step: 13
Training loss: 1.2049791812896729
Validation loss: 2.209089914957682

Epoch: 140| Step: 0
Training loss: 1.1332250833511353
Validation loss: 2.2440117398897805

Epoch: 6| Step: 1
Training loss: 1.1781138181686401
Validation loss: 2.2028955221176147

Epoch: 6| Step: 2
Training loss: 0.7463958263397217
Validation loss: 2.175319790840149

Epoch: 6| Step: 3
Training loss: 0.9813746213912964
Validation loss: 2.228790283203125

Epoch: 6| Step: 4
Training loss: 0.6461165547370911
Validation loss: 2.2712615728378296

Epoch: 6| Step: 5
Training loss: 1.2642788887023926
Validation loss: 2.2232198119163513

Epoch: 6| Step: 6
Training loss: 0.8235141038894653
Validation loss: 2.2655718127886453

Epoch: 6| Step: 7
Training loss: 0.5933866500854492
Validation loss: 2.2375593980153403

Epoch: 6| Step: 8
Training loss: 0.7413690686225891
Validation loss: 2.213391641775767

Epoch: 6| Step: 9
Training loss: 1.1521577835083008
Validation loss: 2.2389275232950845

Epoch: 6| Step: 10
Training loss: 1.9319185018539429
Validation loss: 2.2433300018310547

Epoch: 6| Step: 11
Training loss: 0.7144014835357666
Validation loss: 2.235845406850179

Epoch: 6| Step: 12
Training loss: 0.8478338122367859
Validation loss: 2.2441815932591758

Epoch: 6| Step: 13
Training loss: 0.46609926223754883
Validation loss: 2.1837801535924277

Epoch: 141| Step: 0
Training loss: 0.5826165080070496
Validation loss: 2.1942410667737327

Epoch: 6| Step: 1
Training loss: 0.7015262246131897
Validation loss: 2.2629797657330832

Epoch: 6| Step: 2
Training loss: 1.3819615840911865
Validation loss: 2.288581927617391

Epoch: 6| Step: 3
Training loss: 1.0734288692474365
Validation loss: 2.1572771668434143

Epoch: 6| Step: 4
Training loss: 0.6139587163925171
Validation loss: 2.2883184353510537

Epoch: 6| Step: 5
Training loss: 1.1043182611465454
Validation loss: 2.192480504512787

Epoch: 6| Step: 6
Training loss: 1.012990117073059
Validation loss: 2.2627323865890503

Epoch: 6| Step: 7
Training loss: 0.8229467868804932
Validation loss: 2.2742761373519897

Epoch: 6| Step: 8
Training loss: 0.6868141889572144
Validation loss: 2.2516443530718484

Epoch: 6| Step: 9
Training loss: 0.8870335817337036
Validation loss: 2.2293236454327903

Epoch: 6| Step: 10
Training loss: 0.735283613204956
Validation loss: 2.2673128843307495

Epoch: 6| Step: 11
Training loss: 0.9802943468093872
Validation loss: 2.2585686643918357

Epoch: 6| Step: 12
Training loss: 0.762076735496521
Validation loss: 2.2516273856163025

Epoch: 6| Step: 13
Training loss: 0.7381681203842163
Validation loss: 2.3095925052960715

Epoch: 142| Step: 0
Training loss: 0.8017463088035583
Validation loss: 2.2512064576148987

Epoch: 6| Step: 1
Training loss: 0.8533725142478943
Validation loss: 2.2851308981577554

Epoch: 6| Step: 2
Training loss: 0.7235047817230225
Validation loss: 2.2995065450668335

Epoch: 6| Step: 3
Training loss: 0.8216872215270996
Validation loss: 2.2833460569381714

Epoch: 6| Step: 4
Training loss: 0.5872478485107422
Validation loss: 2.237043082714081

Epoch: 6| Step: 5
Training loss: 0.9170130491256714
Validation loss: 2.242247720559438

Epoch: 6| Step: 6
Training loss: 1.0676264762878418
Validation loss: 2.265069365501404

Epoch: 6| Step: 7
Training loss: 1.4530696868896484
Validation loss: 2.244835674762726

Epoch: 6| Step: 8
Training loss: 0.5698900818824768
Validation loss: 2.329843540986379

Epoch: 6| Step: 9
Training loss: 0.6339811682701111
Validation loss: 2.3351027965545654

Epoch: 6| Step: 10
Training loss: 0.7058945894241333
Validation loss: 2.2875324289004006

Epoch: 6| Step: 11
Training loss: 1.0471186637878418
Validation loss: 2.355780045191447

Epoch: 6| Step: 12
Training loss: 0.8893452882766724
Validation loss: 2.26553746064504

Epoch: 6| Step: 13
Training loss: 1.024192214012146
Validation loss: 2.2694602012634277

Epoch: 143| Step: 0
Training loss: 0.9015504121780396
Validation loss: 2.212906757990519

Epoch: 6| Step: 1
Training loss: 0.8477429151535034
Validation loss: 2.2426337401072183

Epoch: 6| Step: 2
Training loss: 1.443924903869629
Validation loss: 2.276655117670695

Epoch: 6| Step: 3
Training loss: 0.5913770198822021
Validation loss: 2.2680720885594687

Epoch: 6| Step: 4
Training loss: 0.6603717803955078
Validation loss: 2.297421455383301

Epoch: 6| Step: 5
Training loss: 0.661418616771698
Validation loss: 2.278428792953491

Epoch: 6| Step: 6
Training loss: 1.1689025163650513
Validation loss: 2.2707020044326782

Epoch: 6| Step: 7
Training loss: 0.8575186729431152
Validation loss: 2.3113975524902344

Epoch: 6| Step: 8
Training loss: 0.840105414390564
Validation loss: 2.309637268384298

Epoch: 6| Step: 9
Training loss: 0.6906875967979431
Validation loss: 2.209973772366842

Epoch: 6| Step: 10
Training loss: 0.6463618874549866
Validation loss: 2.244961063067118

Epoch: 6| Step: 11
Training loss: 1.1771049499511719
Validation loss: 2.2237326900164285

Epoch: 6| Step: 12
Training loss: 0.6089838743209839
Validation loss: 2.2676346699396768

Epoch: 6| Step: 13
Training loss: 0.7980910539627075
Validation loss: 2.256125013033549

Epoch: 144| Step: 0
Training loss: 0.6677231192588806
Validation loss: 2.330370465914408

Epoch: 6| Step: 1
Training loss: 1.7530783414840698
Validation loss: 2.204291125138601

Epoch: 6| Step: 2
Training loss: 1.352721095085144
Validation loss: 2.370736241340637

Epoch: 6| Step: 3
Training loss: 0.617919921875
Validation loss: 2.2941593329111734

Epoch: 6| Step: 4
Training loss: 1.1768162250518799
Validation loss: 2.3323378364245095

Epoch: 6| Step: 5
Training loss: 1.1110327243804932
Validation loss: 2.2233474055926004

Epoch: 6| Step: 6
Training loss: 0.5934973955154419
Validation loss: 2.2358057697614035

Epoch: 6| Step: 7
Training loss: 0.8173785209655762
Validation loss: 2.3064362605412803

Epoch: 6| Step: 8
Training loss: 1.2026039361953735
Validation loss: 2.285200297832489

Epoch: 6| Step: 9
Training loss: 0.7812480926513672
Validation loss: 2.2521031896273294

Epoch: 6| Step: 10
Training loss: 0.6432150602340698
Validation loss: 2.3083181977272034

Epoch: 6| Step: 11
Training loss: 0.6372455358505249
Validation loss: 2.2705288529396057

Epoch: 6| Step: 12
Training loss: 0.8429359197616577
Validation loss: 2.3388835986455283

Epoch: 6| Step: 13
Training loss: 0.9693569540977478
Validation loss: 2.2000519235928855

Epoch: 145| Step: 0
Training loss: 1.6776490211486816
Validation loss: 2.2466391126314798

Epoch: 6| Step: 1
Training loss: 0.7976922392845154
Validation loss: 2.2747260133425393

Epoch: 6| Step: 2
Training loss: 0.5812773108482361
Validation loss: 2.3185327847798667

Epoch: 6| Step: 3
Training loss: 0.6272192597389221
Validation loss: 2.264380077521006

Epoch: 6| Step: 4
Training loss: 0.5613601207733154
Validation loss: 2.255017717679342

Epoch: 6| Step: 5
Training loss: 0.7816254496574402
Validation loss: 2.3265715837478638

Epoch: 6| Step: 6
Training loss: 0.6537848711013794
Validation loss: 2.3073973258336387

Epoch: 6| Step: 7
Training loss: 0.5113874673843384
Validation loss: 2.288501799106598

Epoch: 6| Step: 8
Training loss: 0.8168260455131531
Validation loss: 2.278467059135437

Epoch: 6| Step: 9
Training loss: 0.6976099610328674
Validation loss: 2.3507248361905417

Epoch: 6| Step: 10
Training loss: 1.2254855632781982
Validation loss: 2.2993993759155273

Epoch: 6| Step: 11
Training loss: 0.9616235494613647
Validation loss: 2.26369039217631

Epoch: 6| Step: 12
Training loss: 0.7345131635665894
Validation loss: 2.3011927405993142

Epoch: 6| Step: 13
Training loss: 1.091249704360962
Validation loss: 2.3362410068511963

Epoch: 146| Step: 0
Training loss: 0.460909366607666
Validation loss: 2.2418471773465476

Epoch: 6| Step: 1
Training loss: 1.1023598909378052
Validation loss: 2.331063429514567

Epoch: 6| Step: 2
Training loss: 0.93453449010849
Validation loss: 2.2757843335469565

Epoch: 6| Step: 3
Training loss: 0.7878899574279785
Validation loss: 2.3073017398516336

Epoch: 6| Step: 4
Training loss: 0.8248074054718018
Validation loss: 2.2906428575515747

Epoch: 6| Step: 5
Training loss: 0.6451187133789062
Validation loss: 2.2779030402501426

Epoch: 6| Step: 6
Training loss: 0.8618255853652954
Validation loss: 2.2381400068600974

Epoch: 6| Step: 7
Training loss: 1.0375392436981201
Validation loss: 2.222955644130707

Epoch: 6| Step: 8
Training loss: 0.9907824397087097
Validation loss: 2.321482221285502

Epoch: 6| Step: 9
Training loss: 0.47229480743408203
Validation loss: 2.284713923931122

Epoch: 6| Step: 10
Training loss: 0.5677032470703125
Validation loss: 2.24787974357605

Epoch: 6| Step: 11
Training loss: 0.8195928335189819
Validation loss: 2.256406048933665

Epoch: 6| Step: 12
Training loss: 0.9377992153167725
Validation loss: 2.3522823452949524

Epoch: 6| Step: 13
Training loss: 1.2288713455200195
Validation loss: 2.2909794052441916

Epoch: 147| Step: 0
Training loss: 1.1562020778656006
Validation loss: 2.306582033634186

Epoch: 6| Step: 1
Training loss: 1.0151586532592773
Validation loss: 2.2472567558288574

Epoch: 6| Step: 2
Training loss: 1.0344529151916504
Validation loss: 2.2470479607582092

Epoch: 6| Step: 3
Training loss: 0.8345223665237427
Validation loss: 2.256475329399109

Epoch: 6| Step: 4
Training loss: 0.4897416830062866
Validation loss: 2.224305252234141

Epoch: 6| Step: 5
Training loss: 0.9354981184005737
Validation loss: 2.216682950655619

Epoch: 6| Step: 6
Training loss: 0.696306049823761
Validation loss: 2.169905205567678

Epoch: 6| Step: 7
Training loss: 1.102886438369751
Validation loss: 2.202293654282888

Epoch: 6| Step: 8
Training loss: 0.7033491134643555
Validation loss: 2.2684562603632608

Epoch: 6| Step: 9
Training loss: 0.4494839608669281
Validation loss: 2.249894440174103

Epoch: 6| Step: 10
Training loss: 0.46307411789894104
Validation loss: 2.229201396306356

Epoch: 6| Step: 11
Training loss: 0.8314746022224426
Validation loss: 2.2274468342463174

Epoch: 6| Step: 12
Training loss: 1.609193205833435
Validation loss: 2.233999749024709

Epoch: 6| Step: 13
Training loss: 0.7956587076187134
Validation loss: 2.2533422112464905

Epoch: 148| Step: 0
Training loss: 0.7533495426177979
Validation loss: 2.2043625116348267

Epoch: 6| Step: 1
Training loss: 0.9023212194442749
Validation loss: 2.180669645468394

Epoch: 6| Step: 2
Training loss: 0.9332340955734253
Validation loss: 2.2752113739649453

Epoch: 6| Step: 3
Training loss: 1.0191545486450195
Validation loss: 2.2180510759353638

Epoch: 6| Step: 4
Training loss: 0.74431312084198
Validation loss: 2.192612032095591

Epoch: 6| Step: 5
Training loss: 1.219910979270935
Validation loss: 2.2268349528312683

Epoch: 6| Step: 6
Training loss: 1.1347708702087402
Validation loss: 2.2944048047065735

Epoch: 6| Step: 7
Training loss: 0.5794040560722351
Validation loss: 2.286964217821757

Epoch: 6| Step: 8
Training loss: 0.49289220571517944
Validation loss: 2.3274213870366416

Epoch: 6| Step: 9
Training loss: 0.8994169235229492
Validation loss: 2.2466204166412354

Epoch: 6| Step: 10
Training loss: 0.8011147975921631
Validation loss: 2.2488749424616494

Epoch: 6| Step: 11
Training loss: 0.5974145531654358
Validation loss: 2.24095485607783

Epoch: 6| Step: 12
Training loss: 0.5119444727897644
Validation loss: 2.2890206972757974

Epoch: 6| Step: 13
Training loss: 1.0274957418441772
Validation loss: 2.2075889507929483

Epoch: 149| Step: 0
Training loss: 1.1852543354034424
Validation loss: 2.2399251461029053

Epoch: 6| Step: 1
Training loss: 0.7269259691238403
Validation loss: 2.2264848152796426

Epoch: 6| Step: 2
Training loss: 0.8999860286712646
Validation loss: 2.1973642110824585

Epoch: 6| Step: 3
Training loss: 1.0251166820526123
Validation loss: 2.2469768126805625

Epoch: 6| Step: 4
Training loss: 0.7174955606460571
Validation loss: 2.224010149637858

Epoch: 6| Step: 5
Training loss: 0.8009008765220642
Validation loss: 2.2275687058766684

Epoch: 6| Step: 6
Training loss: 0.620484471321106
Validation loss: 2.239397088686625

Epoch: 6| Step: 7
Training loss: 0.5540655851364136
Validation loss: 2.230174720287323

Epoch: 6| Step: 8
Training loss: 0.7467430830001831
Validation loss: 2.250872770945231

Epoch: 6| Step: 9
Training loss: 0.7771353125572205
Validation loss: 2.3575290640195212

Epoch: 6| Step: 10
Training loss: 0.938068687915802
Validation loss: 2.34367706378301

Epoch: 6| Step: 11
Training loss: 0.9763581156730652
Validation loss: 2.3149729569753013

Epoch: 6| Step: 12
Training loss: 1.010453701019287
Validation loss: 2.29540220896403

Epoch: 6| Step: 13
Training loss: 0.9547983407974243
Validation loss: 2.264990746974945

Epoch: 150| Step: 0
Training loss: 1.2175538539886475
Validation loss: 2.3051116863886514

Epoch: 6| Step: 1
Training loss: 0.570751965045929
Validation loss: 2.1921788851420083

Epoch: 6| Step: 2
Training loss: 0.8946172595024109
Validation loss: 2.2227118810017905

Epoch: 6| Step: 3
Training loss: 0.6067583560943604
Validation loss: 2.2113507986068726

Epoch: 6| Step: 4
Training loss: 0.7815531492233276
Validation loss: 2.237680892149607

Epoch: 6| Step: 5
Training loss: 1.1006760597229004
Validation loss: 2.2760401169459024

Epoch: 6| Step: 6
Training loss: 0.6361300945281982
Validation loss: 2.2698779900868735

Epoch: 6| Step: 7
Training loss: 1.1721901893615723
Validation loss: 2.2710970044136047

Epoch: 6| Step: 8
Training loss: 1.3780561685562134
Validation loss: 2.2974688013394675

Epoch: 6| Step: 9
Training loss: 0.7795426845550537
Validation loss: 2.297736406326294

Epoch: 6| Step: 10
Training loss: 0.5305729508399963
Validation loss: 2.287048896153768

Epoch: 6| Step: 11
Training loss: 0.8492595553398132
Validation loss: 2.2399390935897827

Epoch: 6| Step: 12
Training loss: 0.7880943417549133
Validation loss: 2.231083313624064

Epoch: 6| Step: 13
Training loss: 0.7574949860572815
Validation loss: 2.179337799549103

Epoch: 151| Step: 0
Training loss: 0.9818427562713623
Validation loss: 2.2841972708702087

Epoch: 6| Step: 1
Training loss: 0.8465142250061035
Validation loss: 2.2257392009099326

Epoch: 6| Step: 2
Training loss: 0.7958376407623291
Validation loss: 2.2631245056788125

Epoch: 6| Step: 3
Training loss: 1.2107164859771729
Validation loss: 2.3017959197362265

Epoch: 6| Step: 4
Training loss: 0.835769534111023
Validation loss: 2.2384454806645713

Epoch: 6| Step: 5
Training loss: 0.7750225067138672
Validation loss: 2.2739484707514444

Epoch: 6| Step: 6
Training loss: 0.6684829592704773
Validation loss: 2.334952414035797

Epoch: 6| Step: 7
Training loss: 0.4195913076400757
Validation loss: 2.290984094142914

Epoch: 6| Step: 8
Training loss: 0.8189263343811035
Validation loss: 2.273443261782328

Epoch: 6| Step: 9
Training loss: 0.8272119760513306
Validation loss: 2.201319913069407

Epoch: 6| Step: 10
Training loss: 0.6837314367294312
Validation loss: 2.2552268902460733

Epoch: 6| Step: 11
Training loss: 0.566177487373352
Validation loss: 2.2517892320950827

Epoch: 6| Step: 12
Training loss: 1.3498440980911255
Validation loss: 2.230348606904348

Epoch: 6| Step: 13
Training loss: 0.47095948457717896
Validation loss: 2.233849048614502

Epoch: 152| Step: 0
Training loss: 0.7654235363006592
Validation loss: 2.239531616369883

Epoch: 6| Step: 1
Training loss: 0.5603792667388916
Validation loss: 2.2164836327234902

Epoch: 6| Step: 2
Training loss: 0.6745847463607788
Validation loss: 2.210282544294993

Epoch: 6| Step: 3
Training loss: 0.5161299109458923
Validation loss: 2.229959229628245

Epoch: 6| Step: 4
Training loss: 0.8907760977745056
Validation loss: 2.2913248936335244

Epoch: 6| Step: 5
Training loss: 0.8783409595489502
Validation loss: 2.3082125186920166

Epoch: 6| Step: 6
Training loss: 0.5528106093406677
Validation loss: 2.280028223991394

Epoch: 6| Step: 7
Training loss: 0.5519812107086182
Validation loss: 2.234031081199646

Epoch: 6| Step: 8
Training loss: 1.0013898611068726
Validation loss: 2.2206016182899475

Epoch: 6| Step: 9
Training loss: 0.7255234122276306
Validation loss: 2.26137775182724

Epoch: 6| Step: 10
Training loss: 0.8466057777404785
Validation loss: 2.178077518939972

Epoch: 6| Step: 11
Training loss: 0.8868333101272583
Validation loss: 2.2104934453964233

Epoch: 6| Step: 12
Training loss: 0.8916082978248596
Validation loss: 2.181791663169861

Epoch: 6| Step: 13
Training loss: 1.1423332691192627
Validation loss: 2.2267836133639016

Epoch: 153| Step: 0
Training loss: 0.8906505703926086
Validation loss: 2.2828991611798606

Epoch: 6| Step: 1
Training loss: 0.29042088985443115
Validation loss: 2.273793717225393

Epoch: 6| Step: 2
Training loss: 0.6410361528396606
Validation loss: 2.2397029201189675

Epoch: 6| Step: 3
Training loss: 1.0550018548965454
Validation loss: 2.2551735043525696

Epoch: 6| Step: 4
Training loss: 0.4632680416107178
Validation loss: 2.2760225931803384

Epoch: 6| Step: 5
Training loss: 0.4493786692619324
Validation loss: 2.2575256625811257

Epoch: 6| Step: 6
Training loss: 0.7972359657287598
Validation loss: 2.2106738487879434

Epoch: 6| Step: 7
Training loss: 0.8104847073554993
Validation loss: 2.2598372300465903

Epoch: 6| Step: 8
Training loss: 1.0014376640319824
Validation loss: 2.2572768926620483

Epoch: 6| Step: 9
Training loss: 0.7862801551818848
Validation loss: 2.2719355821609497

Epoch: 6| Step: 10
Training loss: 0.8726627826690674
Validation loss: 2.3342490593592324

Epoch: 6| Step: 11
Training loss: 1.0759316682815552
Validation loss: 2.277182718118032

Epoch: 6| Step: 12
Training loss: 0.798149585723877
Validation loss: 2.313740889231364

Epoch: 6| Step: 13
Training loss: 0.9252673387527466
Validation loss: 2.319009999434153

Epoch: 154| Step: 0
Training loss: 0.6546028852462769
Validation loss: 2.330082337061564

Epoch: 6| Step: 1
Training loss: 0.9099790453910828
Validation loss: 2.4089391430219016

Epoch: 6| Step: 2
Training loss: 1.2848570346832275
Validation loss: 2.347087025642395

Epoch: 6| Step: 3
Training loss: 0.5228544473648071
Validation loss: 2.367673476537069

Epoch: 6| Step: 4
Training loss: 0.39344948530197144
Validation loss: 2.3338698347409568

Epoch: 6| Step: 5
Training loss: 0.7816179990768433
Validation loss: 2.277340888977051

Epoch: 6| Step: 6
Training loss: 0.7282154560089111
Validation loss: 2.2595170736312866

Epoch: 6| Step: 7
Training loss: 0.8838599920272827
Validation loss: 2.2868891954421997

Epoch: 6| Step: 8
Training loss: 0.4803238809108734
Validation loss: 2.3441048860549927

Epoch: 6| Step: 9
Training loss: 1.0302507877349854
Validation loss: 2.203875700632731

Epoch: 6| Step: 10
Training loss: 1.008474349975586
Validation loss: 2.306532839934031

Epoch: 6| Step: 11
Training loss: 0.4179638624191284
Validation loss: 2.27062459786733

Epoch: 6| Step: 12
Training loss: 0.698029637336731
Validation loss: 2.3197506268819175

Epoch: 6| Step: 13
Training loss: 1.0751187801361084
Validation loss: 2.3069002628326416

Epoch: 155| Step: 0
Training loss: 0.5116851329803467
Validation loss: 2.3442062934239707

Epoch: 6| Step: 1
Training loss: 1.1776868104934692
Validation loss: 2.3699572483698526

Epoch: 6| Step: 2
Training loss: 1.0858066082000732
Validation loss: 2.4055974086125693

Epoch: 6| Step: 3
Training loss: 0.4903988242149353
Validation loss: 2.2644667625427246

Epoch: 6| Step: 4
Training loss: 0.5529792308807373
Validation loss: 2.336518704891205

Epoch: 6| Step: 5
Training loss: 0.6633028984069824
Validation loss: 2.22349218527476

Epoch: 6| Step: 6
Training loss: 1.0862582921981812
Validation loss: 2.232416331768036

Epoch: 6| Step: 7
Training loss: 0.6273167133331299
Validation loss: 2.303180913130442

Epoch: 6| Step: 8
Training loss: 1.2481372356414795
Validation loss: 2.2593170007069907

Epoch: 6| Step: 9
Training loss: 0.4518406391143799
Validation loss: 2.288859268029531

Epoch: 6| Step: 10
Training loss: 0.835591197013855
Validation loss: 2.2791879574457803

Epoch: 6| Step: 11
Training loss: 0.8654239177703857
Validation loss: 2.376336912314097

Epoch: 6| Step: 12
Training loss: 0.6893583536148071
Validation loss: 2.291585842768351

Epoch: 6| Step: 13
Training loss: 1.2042102813720703
Validation loss: 2.3136202096939087

Epoch: 156| Step: 0
Training loss: 0.7045416235923767
Validation loss: 2.2672938903172812

Epoch: 6| Step: 1
Training loss: 1.1666637659072876
Validation loss: 2.235853672027588

Epoch: 6| Step: 2
Training loss: 1.2457329034805298
Validation loss: 2.218428830305735

Epoch: 6| Step: 3
Training loss: 0.8707375526428223
Validation loss: 2.2910437186559043

Epoch: 6| Step: 4
Training loss: 0.7313547134399414
Validation loss: 2.204242765903473

Epoch: 6| Step: 5
Training loss: 0.9365246295928955
Validation loss: 2.218390186627706

Epoch: 6| Step: 6
Training loss: 0.5952857732772827
Validation loss: 2.2845521569252014

Epoch: 6| Step: 7
Training loss: 1.1504712104797363
Validation loss: 2.2830539544423423

Epoch: 6| Step: 8
Training loss: 0.38358908891677856
Validation loss: 2.2476308345794678

Epoch: 6| Step: 9
Training loss: 0.5456272959709167
Validation loss: 2.297610064347585

Epoch: 6| Step: 10
Training loss: 0.79181969165802
Validation loss: 2.288045366605123

Epoch: 6| Step: 11
Training loss: 0.6374064683914185
Validation loss: 2.3120118379592896

Epoch: 6| Step: 12
Training loss: 0.6677478551864624
Validation loss: 2.288880626360575

Epoch: 6| Step: 13
Training loss: 0.8078075647354126
Validation loss: 2.2687851389249167

Epoch: 157| Step: 0
Training loss: 0.43861183524131775
Validation loss: 2.2690731088320413

Epoch: 6| Step: 1
Training loss: 0.9935813546180725
Validation loss: 2.238541603088379

Epoch: 6| Step: 2
Training loss: 0.9128934741020203
Validation loss: 2.2454493045806885

Epoch: 6| Step: 3
Training loss: 0.7999021410942078
Validation loss: 2.2820361852645874

Epoch: 6| Step: 4
Training loss: 0.5799195170402527
Validation loss: 2.3091959158579507

Epoch: 6| Step: 5
Training loss: 0.6524412631988525
Validation loss: 2.271733045578003

Epoch: 6| Step: 6
Training loss: 0.5576338768005371
Validation loss: 2.286803980668386

Epoch: 6| Step: 7
Training loss: 0.9202062487602234
Validation loss: 2.3741907278696694

Epoch: 6| Step: 8
Training loss: 0.917001485824585
Validation loss: 2.216004490852356

Epoch: 6| Step: 9
Training loss: 0.810578465461731
Validation loss: 2.2834240595499673

Epoch: 6| Step: 10
Training loss: 1.0343564748764038
Validation loss: 2.3411367734273276

Epoch: 6| Step: 11
Training loss: 0.5457022190093994
Validation loss: 2.313645084698995

Epoch: 6| Step: 12
Training loss: 1.029172420501709
Validation loss: 2.2324002981185913

Epoch: 6| Step: 13
Training loss: 0.5124096870422363
Validation loss: 2.2170571088790894

Epoch: 158| Step: 0
Training loss: 0.8281359672546387
Validation loss: 2.228879968325297

Epoch: 6| Step: 1
Training loss: 1.0034273862838745
Validation loss: 2.3003265062967935

Epoch: 6| Step: 2
Training loss: 0.37857335805892944
Validation loss: 2.2390305399894714

Epoch: 6| Step: 3
Training loss: 0.7666134834289551
Validation loss: 2.345848321914673

Epoch: 6| Step: 4
Training loss: 0.7242181301116943
Validation loss: 2.2986775239308677

Epoch: 6| Step: 5
Training loss: 0.43042975664138794
Validation loss: 2.2980730136235556

Epoch: 6| Step: 6
Training loss: 0.9414082765579224
Validation loss: 2.2922998666763306

Epoch: 6| Step: 7
Training loss: 0.9398789405822754
Validation loss: 2.2164785663286843

Epoch: 6| Step: 8
Training loss: 1.1061596870422363
Validation loss: 2.3160808285077414

Epoch: 6| Step: 9
Training loss: 0.860163688659668
Validation loss: 2.2634944717089334

Epoch: 6| Step: 10
Training loss: 0.7693576812744141
Validation loss: 2.249132215976715

Epoch: 6| Step: 11
Training loss: 0.9922066330909729
Validation loss: 2.3045830726623535

Epoch: 6| Step: 12
Training loss: 1.070694923400879
Validation loss: 2.294976552327474

Epoch: 6| Step: 13
Training loss: 0.6364170908927917
Validation loss: 2.259876092274984

Epoch: 159| Step: 0
Training loss: 0.7579752206802368
Validation loss: 2.290497839450836

Epoch: 6| Step: 1
Training loss: 0.6237002611160278
Validation loss: 2.3331231673558555

Epoch: 6| Step: 2
Training loss: 1.0756263732910156
Validation loss: 2.437558094660441

Epoch: 6| Step: 3
Training loss: 0.7480106949806213
Validation loss: 2.415200432141622

Epoch: 6| Step: 4
Training loss: 0.6366683840751648
Validation loss: 2.3665749629338584

Epoch: 6| Step: 5
Training loss: 0.993759036064148
Validation loss: 2.2814355293909707

Epoch: 6| Step: 6
Training loss: 1.089229941368103
Validation loss: 2.246342142422994

Epoch: 6| Step: 7
Training loss: 0.950001060962677
Validation loss: 2.2702079017957053

Epoch: 6| Step: 8
Training loss: 0.7145277261734009
Validation loss: 2.2662153244018555

Epoch: 6| Step: 9
Training loss: 0.7905192971229553
Validation loss: 2.33051598072052

Epoch: 6| Step: 10
Training loss: 0.8513756394386292
Validation loss: 2.24966291586558

Epoch: 6| Step: 11
Training loss: 0.34133484959602356
Validation loss: 2.298401395479838

Epoch: 6| Step: 12
Training loss: 1.4912242889404297
Validation loss: 2.308580160140991

Epoch: 6| Step: 13
Training loss: 0.5766773223876953
Validation loss: 2.2958278258641562

Epoch: 160| Step: 0
Training loss: 0.6131271123886108
Validation loss: 2.3601334492365518

Epoch: 6| Step: 1
Training loss: 0.9028260111808777
Validation loss: 2.366291801134745

Epoch: 6| Step: 2
Training loss: 0.8064941167831421
Validation loss: 2.369706670443217

Epoch: 6| Step: 3
Training loss: 0.8064704537391663
Validation loss: 2.2927738428115845

Epoch: 6| Step: 4
Training loss: 0.9245113134384155
Validation loss: 2.2901071111361184

Epoch: 6| Step: 5
Training loss: 0.4094259738922119
Validation loss: 2.3037676016489663

Epoch: 6| Step: 6
Training loss: 0.9328486919403076
Validation loss: 2.2266260981559753

Epoch: 6| Step: 7
Training loss: 0.9331860542297363
Validation loss: 2.2520576119422913

Epoch: 6| Step: 8
Training loss: 0.7088696956634521
Validation loss: 2.240469058354696

Epoch: 6| Step: 9
Training loss: 0.8020566701889038
Validation loss: 2.263299902280172

Epoch: 6| Step: 10
Training loss: 0.639681339263916
Validation loss: 2.2860297163327536

Epoch: 6| Step: 11
Training loss: 0.560169517993927
Validation loss: 2.2779478828112283

Epoch: 6| Step: 12
Training loss: 0.5403326749801636
Validation loss: 2.249660829703013

Epoch: 6| Step: 13
Training loss: 0.7653201818466187
Validation loss: 2.2111517985661826

Epoch: 161| Step: 0
Training loss: 0.9609639644622803
Validation loss: 2.2037679155667624

Epoch: 6| Step: 1
Training loss: 1.1813851594924927
Validation loss: 2.2498406171798706

Epoch: 6| Step: 2
Training loss: 0.9736894965171814
Validation loss: 2.1979496677716575

Epoch: 6| Step: 3
Training loss: 0.7704355716705322
Validation loss: 2.20440403620402

Epoch: 6| Step: 4
Training loss: 0.5815361738204956
Validation loss: 2.244872272014618

Epoch: 6| Step: 5
Training loss: 0.8552794456481934
Validation loss: 2.2460418542226157

Epoch: 6| Step: 6
Training loss: 0.7292225956916809
Validation loss: 2.3321105440457663

Epoch: 6| Step: 7
Training loss: 0.635375440120697
Validation loss: 2.428733547528585

Epoch: 6| Step: 8
Training loss: 1.0194299221038818
Validation loss: 2.4612468481063843

Epoch: 6| Step: 9
Training loss: 0.8622178435325623
Validation loss: 2.3514956633249917

Epoch: 6| Step: 10
Training loss: 0.9005050659179688
Validation loss: 2.326045354207357

Epoch: 6| Step: 11
Training loss: 0.7848125696182251
Validation loss: 2.2741958498954773

Epoch: 6| Step: 12
Training loss: 0.8530671000480652
Validation loss: 2.231226841608683

Epoch: 6| Step: 13
Training loss: 0.8693441152572632
Validation loss: 2.3693418900171914

Epoch: 162| Step: 0
Training loss: 0.8095318078994751
Validation loss: 2.296482781569163

Epoch: 6| Step: 1
Training loss: 1.0643969774246216
Validation loss: 2.231393655141195

Epoch: 6| Step: 2
Training loss: 1.258291244506836
Validation loss: 2.256224513053894

Epoch: 6| Step: 3
Training loss: 0.5659792423248291
Validation loss: 2.267350693543752

Epoch: 6| Step: 4
Training loss: 0.6309775710105896
Validation loss: 2.258133133252462

Epoch: 6| Step: 5
Training loss: 0.5487845540046692
Validation loss: 2.3514504035313926

Epoch: 6| Step: 6
Training loss: 0.6651716232299805
Validation loss: 2.3658125400543213

Epoch: 6| Step: 7
Training loss: 0.8858609795570374
Validation loss: 2.3764837185541787

Epoch: 6| Step: 8
Training loss: 0.6935266256332397
Validation loss: 2.3360009590784707

Epoch: 6| Step: 9
Training loss: 0.7503707408905029
Validation loss: 2.3015650510787964

Epoch: 6| Step: 10
Training loss: 0.99305260181427
Validation loss: 2.3133420745531716

Epoch: 6| Step: 11
Training loss: 0.888948917388916
Validation loss: 2.3261303106943765

Epoch: 6| Step: 12
Training loss: 0.891861081123352
Validation loss: 2.238806108633677

Epoch: 6| Step: 13
Training loss: 0.720500111579895
Validation loss: 2.2958866556485495

Epoch: 163| Step: 0
Training loss: 0.6860254406929016
Validation loss: 2.2934677998224893

Epoch: 6| Step: 1
Training loss: 0.7360230088233948
Validation loss: 2.2503507137298584

Epoch: 6| Step: 2
Training loss: 0.57655930519104
Validation loss: 2.2542672753334045

Epoch: 6| Step: 3
Training loss: 0.9940364360809326
Validation loss: 2.254818916320801

Epoch: 6| Step: 4
Training loss: 0.6333569288253784
Validation loss: 2.2686974803606668

Epoch: 6| Step: 5
Training loss: 0.5929495096206665
Validation loss: 2.29168834288915

Epoch: 6| Step: 6
Training loss: 1.0185744762420654
Validation loss: 2.3263536294301352

Epoch: 6| Step: 7
Training loss: 0.5797526836395264
Validation loss: 2.2553245425224304

Epoch: 6| Step: 8
Training loss: 0.8321685791015625
Validation loss: 2.3332303961118064

Epoch: 6| Step: 9
Training loss: 0.4549391269683838
Validation loss: 2.359915296236674

Epoch: 6| Step: 10
Training loss: 0.49805957078933716
Validation loss: 2.311067004998525

Epoch: 6| Step: 11
Training loss: 0.818196177482605
Validation loss: 2.289060970147451

Epoch: 6| Step: 12
Training loss: 0.9304647445678711
Validation loss: 2.285222868124644

Epoch: 6| Step: 13
Training loss: 0.7469656467437744
Validation loss: 2.251848896344503

Epoch: 164| Step: 0
Training loss: 1.1838713884353638
Validation loss: 2.251780867576599

Epoch: 6| Step: 1
Training loss: 0.8165681958198547
Validation loss: 2.2755834261576333

Epoch: 6| Step: 2
Training loss: 0.42910879850387573
Validation loss: 2.2592849334081015

Epoch: 6| Step: 3
Training loss: 0.4809480905532837
Validation loss: 2.322620987892151

Epoch: 6| Step: 4
Training loss: 0.661479115486145
Validation loss: 2.262506286303202

Epoch: 6| Step: 5
Training loss: 0.8394724726676941
Validation loss: 2.3074115912119546

Epoch: 6| Step: 6
Training loss: 0.7011294364929199
Validation loss: 2.3373942573865256

Epoch: 6| Step: 7
Training loss: 1.3816461563110352
Validation loss: 2.3423575361569724

Epoch: 6| Step: 8
Training loss: 0.6310672163963318
Validation loss: 2.2755792140960693

Epoch: 6| Step: 9
Training loss: 0.5769954919815063
Validation loss: 2.2212522427241006

Epoch: 6| Step: 10
Training loss: 0.7751328945159912
Validation loss: 2.2369930942853293

Epoch: 6| Step: 11
Training loss: 0.625603437423706
Validation loss: 2.2724751631418862

Epoch: 6| Step: 12
Training loss: 0.4385327696800232
Validation loss: 2.2343912521998086

Epoch: 6| Step: 13
Training loss: 1.0126385688781738
Validation loss: 2.2577486435572305

Epoch: 165| Step: 0
Training loss: 0.6283915042877197
Validation loss: 2.2554609179496765

Epoch: 6| Step: 1
Training loss: 0.6219720244407654
Validation loss: 2.312210281689962

Epoch: 6| Step: 2
Training loss: 1.0615370273590088
Validation loss: 2.2740172147750854

Epoch: 6| Step: 3
Training loss: 0.9918050765991211
Validation loss: 2.2780321637789407

Epoch: 6| Step: 4
Training loss: 0.7602553963661194
Validation loss: 2.2369927962621055

Epoch: 6| Step: 5
Training loss: 0.7612954378128052
Validation loss: 2.283250411351522

Epoch: 6| Step: 6
Training loss: 0.6714585423469543
Validation loss: 2.28037691116333

Epoch: 6| Step: 7
Training loss: 0.7641347050666809
Validation loss: 2.3173905412356057

Epoch: 6| Step: 8
Training loss: 0.7437098026275635
Validation loss: 2.215371310710907

Epoch: 6| Step: 9
Training loss: 0.4087895154953003
Validation loss: 2.284063378969828

Epoch: 6| Step: 10
Training loss: 0.76533043384552
Validation loss: 2.17139462629954

Epoch: 6| Step: 11
Training loss: 0.49618110060691833
Validation loss: 2.1833600799242654

Epoch: 6| Step: 12
Training loss: 0.3228810429573059
Validation loss: 2.246191660563151

Epoch: 6| Step: 13
Training loss: 0.9897110462188721
Validation loss: 2.2751502792040506

Epoch: 166| Step: 0
Training loss: 0.7889206409454346
Validation loss: 2.3230316638946533

Epoch: 6| Step: 1
Training loss: 0.9799226522445679
Validation loss: 2.242452601591746

Epoch: 6| Step: 2
Training loss: 0.6203514337539673
Validation loss: 2.2439411282539368

Epoch: 6| Step: 3
Training loss: 0.5277470946311951
Validation loss: 2.2132579684257507

Epoch: 6| Step: 4
Training loss: 0.7389907836914062
Validation loss: 2.1726825634638467

Epoch: 6| Step: 5
Training loss: 0.6049988865852356
Validation loss: 2.190337300300598

Epoch: 6| Step: 6
Training loss: 1.0894203186035156
Validation loss: 2.2311619321505227

Epoch: 6| Step: 7
Training loss: 0.4294295012950897
Validation loss: 2.2681044737497964

Epoch: 6| Step: 8
Training loss: 0.8670296669006348
Validation loss: 2.28591126203537

Epoch: 6| Step: 9
Training loss: 0.4594154357910156
Validation loss: 2.28370201587677

Epoch: 6| Step: 10
Training loss: 0.4879974126815796
Validation loss: 2.313155730565389

Epoch: 6| Step: 11
Training loss: 0.670161247253418
Validation loss: 2.3241259654363

Epoch: 6| Step: 12
Training loss: 0.8751518726348877
Validation loss: 2.3360984524091086

Epoch: 6| Step: 13
Training loss: 0.8688987493515015
Validation loss: 2.363858977953593

Epoch: 167| Step: 0
Training loss: 0.5963059663772583
Validation loss: 2.2336514989535012

Epoch: 6| Step: 1
Training loss: 0.7574172019958496
Validation loss: 2.2821816007296243

Epoch: 6| Step: 2
Training loss: 0.8400589823722839
Validation loss: 2.3148544828097024

Epoch: 6| Step: 3
Training loss: 0.5425148010253906
Validation loss: 2.226801812648773

Epoch: 6| Step: 4
Training loss: 0.45778149366378784
Validation loss: 2.2428038716316223

Epoch: 6| Step: 5
Training loss: 0.5807838439941406
Validation loss: 2.255267918109894

Epoch: 6| Step: 6
Training loss: 0.7296602129936218
Validation loss: 2.2833701173464456

Epoch: 6| Step: 7
Training loss: 0.3666442632675171
Validation loss: 2.2957684795061746

Epoch: 6| Step: 8
Training loss: 0.7282683253288269
Validation loss: 2.312233626842499

Epoch: 6| Step: 9
Training loss: 1.218142032623291
Validation loss: 2.310494621594747

Epoch: 6| Step: 10
Training loss: 0.4446571469306946
Validation loss: 2.2723487615585327

Epoch: 6| Step: 11
Training loss: 0.5910511016845703
Validation loss: 2.256819009780884

Epoch: 6| Step: 12
Training loss: 0.8045331239700317
Validation loss: 2.26436976591746

Epoch: 6| Step: 13
Training loss: 1.1470072269439697
Validation loss: 2.252527892589569

Epoch: 168| Step: 0
Training loss: 0.6485161781311035
Validation loss: 2.2723134954770408

Epoch: 6| Step: 1
Training loss: 0.7257501482963562
Validation loss: 2.256807486216227

Epoch: 6| Step: 2
Training loss: 0.7563749551773071
Validation loss: 2.286607086658478

Epoch: 6| Step: 3
Training loss: 0.5942931771278381
Validation loss: 2.2819992899894714

Epoch: 6| Step: 4
Training loss: 0.8074264526367188
Validation loss: 2.3558847904205322

Epoch: 6| Step: 5
Training loss: 0.8366393446922302
Validation loss: 2.3224291801452637

Epoch: 6| Step: 6
Training loss: 0.7914330959320068
Validation loss: 2.2770943641662598

Epoch: 6| Step: 7
Training loss: 0.814527153968811
Validation loss: 2.332939108212789

Epoch: 6| Step: 8
Training loss: 0.5658756494522095
Validation loss: 2.333047012488047

Epoch: 6| Step: 9
Training loss: 0.6341975331306458
Validation loss: 2.192317565282186

Epoch: 6| Step: 10
Training loss: 0.8034523129463196
Validation loss: 2.2304856975873313

Epoch: 6| Step: 11
Training loss: 0.3391522765159607
Validation loss: 2.2465009490648904

Epoch: 6| Step: 12
Training loss: 0.7176026105880737
Validation loss: 2.339512308438619

Epoch: 6| Step: 13
Training loss: 0.6675708293914795
Validation loss: 2.273614823818207

Epoch: 169| Step: 0
Training loss: 0.6203823089599609
Validation loss: 2.267422914505005

Epoch: 6| Step: 1
Training loss: 1.1779768466949463
Validation loss: 2.282000462214152

Epoch: 6| Step: 2
Training loss: 0.8631299734115601
Validation loss: 2.32904181877772

Epoch: 6| Step: 3
Training loss: 0.470381498336792
Validation loss: 2.35368941227595

Epoch: 6| Step: 4
Training loss: 0.3459538221359253
Validation loss: 2.306103070576986

Epoch: 6| Step: 5
Training loss: 0.6230776309967041
Validation loss: 2.266077240308126

Epoch: 6| Step: 6
Training loss: 0.7491238117218018
Validation loss: 2.2920747796694436

Epoch: 6| Step: 7
Training loss: 0.7200387716293335
Validation loss: 2.3182417949040732

Epoch: 6| Step: 8
Training loss: 0.6827901601791382
Validation loss: 2.3068790435791016

Epoch: 6| Step: 9
Training loss: 0.5024257302284241
Validation loss: 2.290064970652262

Epoch: 6| Step: 10
Training loss: 0.888454794883728
Validation loss: 2.320751965045929

Epoch: 6| Step: 11
Training loss: 0.46716511249542236
Validation loss: 2.3363014856974282

Epoch: 6| Step: 12
Training loss: 0.7801094055175781
Validation loss: 2.387997289498647

Epoch: 6| Step: 13
Training loss: 0.7566049695014954
Validation loss: 2.365649859110514

Epoch: 170| Step: 0
Training loss: 0.5934996604919434
Validation loss: 2.3578693866729736

Epoch: 6| Step: 1
Training loss: 0.4642886817455292
Validation loss: 2.271060307820638

Epoch: 6| Step: 2
Training loss: 0.6090176701545715
Validation loss: 2.3534796039263406

Epoch: 6| Step: 3
Training loss: 0.6109744906425476
Validation loss: 2.2675166924794516

Epoch: 6| Step: 4
Training loss: 1.15657639503479
Validation loss: 2.2794645031293235

Epoch: 6| Step: 5
Training loss: 0.5141068696975708
Validation loss: 2.3051447669665017

Epoch: 6| Step: 6
Training loss: 0.29806238412857056
Validation loss: 2.3122822841008506

Epoch: 6| Step: 7
Training loss: 0.8165549039840698
Validation loss: 2.335505962371826

Epoch: 6| Step: 8
Training loss: 0.7391680479049683
Validation loss: 2.3042428890864053

Epoch: 6| Step: 9
Training loss: 0.48438596725463867
Validation loss: 2.3467147747675576

Epoch: 6| Step: 10
Training loss: 1.1052608489990234
Validation loss: 2.371118942896525

Epoch: 6| Step: 11
Training loss: 0.9063487648963928
Validation loss: 2.4261048634847007

Epoch: 6| Step: 12
Training loss: 0.42449110746383667
Validation loss: 2.333096146583557

Epoch: 6| Step: 13
Training loss: 1.065531611442566
Validation loss: 2.3201128244400024

Epoch: 171| Step: 0
Training loss: 0.6863698959350586
Validation loss: 2.2502328554789224

Epoch: 6| Step: 1
Training loss: 0.6553429365158081
Validation loss: 2.313103715578715

Epoch: 6| Step: 2
Training loss: 0.6967577934265137
Validation loss: 2.261029918988546

Epoch: 6| Step: 3
Training loss: 0.5625154972076416
Validation loss: 2.277531464894613

Epoch: 6| Step: 4
Training loss: 1.017921805381775
Validation loss: 2.243256628513336

Epoch: 6| Step: 5
Training loss: 0.5979960560798645
Validation loss: 2.2337393760681152

Epoch: 6| Step: 6
Training loss: 0.7610840201377869
Validation loss: 2.275822083155314

Epoch: 6| Step: 7
Training loss: 0.9211596250534058
Validation loss: 2.370636761188507

Epoch: 6| Step: 8
Training loss: 0.5165651440620422
Validation loss: 2.331271529197693

Epoch: 6| Step: 9
Training loss: 1.0015766620635986
Validation loss: 2.314728637536367

Epoch: 6| Step: 10
Training loss: 0.8260325789451599
Validation loss: 2.3105276425679526

Epoch: 6| Step: 11
Training loss: 0.5635886192321777
Validation loss: 2.3013548056284585

Epoch: 6| Step: 12
Training loss: 0.7510293126106262
Validation loss: 2.229778210322062

Epoch: 6| Step: 13
Training loss: 0.7947993278503418
Validation loss: 2.245028634866079

Epoch: 172| Step: 0
Training loss: 0.6790058612823486
Validation loss: 2.248623490333557

Epoch: 6| Step: 1
Training loss: 0.5342814922332764
Validation loss: 2.2660178939501443

Epoch: 6| Step: 2
Training loss: 1.3095439672470093
Validation loss: 2.2414084672927856

Epoch: 6| Step: 3
Training loss: 0.5093783140182495
Validation loss: 2.3492207129796348

Epoch: 6| Step: 4
Training loss: 0.8256020545959473
Validation loss: 2.41766365369161

Epoch: 6| Step: 5
Training loss: 0.8212170600891113
Validation loss: 2.3321029345194497

Epoch: 6| Step: 6
Training loss: 0.6040035486221313
Validation loss: 2.388854960600535

Epoch: 6| Step: 7
Training loss: 0.7900598645210266
Validation loss: 2.3365459044774375

Epoch: 6| Step: 8
Training loss: 0.41862326860427856
Validation loss: 2.351080338160197

Epoch: 6| Step: 9
Training loss: 0.9095082879066467
Validation loss: 2.336293657620748

Epoch: 6| Step: 10
Training loss: 0.45234841108322144
Validation loss: 2.3106038570404053

Epoch: 6| Step: 11
Training loss: 0.609348475933075
Validation loss: 2.2808961073557534

Epoch: 6| Step: 12
Training loss: 1.03299880027771
Validation loss: 2.280228575070699

Epoch: 6| Step: 13
Training loss: 0.9871767163276672
Validation loss: 2.345933675765991

Epoch: 173| Step: 0
Training loss: 0.942328929901123
Validation loss: 2.29970113436381

Epoch: 6| Step: 1
Training loss: 0.5950745344161987
Validation loss: 2.2967641750971475

Epoch: 6| Step: 2
Training loss: 0.697175145149231
Validation loss: 2.357617815335592

Epoch: 6| Step: 3
Training loss: 1.0071396827697754
Validation loss: 2.3098777532577515

Epoch: 6| Step: 4
Training loss: 0.3319380283355713
Validation loss: 2.3216567834218345

Epoch: 6| Step: 5
Training loss: 0.7513119578361511
Validation loss: 2.417874018351237

Epoch: 6| Step: 6
Training loss: 0.7880226969718933
Validation loss: 2.370045006275177

Epoch: 6| Step: 7
Training loss: 0.7383773922920227
Validation loss: 2.360645055770874

Epoch: 6| Step: 8
Training loss: 0.44145315885543823
Validation loss: 2.3269313176472983

Epoch: 6| Step: 9
Training loss: 0.6586517095565796
Validation loss: 2.331378142038981

Epoch: 6| Step: 10
Training loss: 0.7103170156478882
Validation loss: 2.311572770277659

Epoch: 6| Step: 11
Training loss: 0.6623208522796631
Validation loss: 2.333168009916941

Epoch: 6| Step: 12
Training loss: 0.6589323878288269
Validation loss: 2.3583658933639526

Epoch: 6| Step: 13
Training loss: 0.97865229845047
Validation loss: 2.3109466632207236

Epoch: 174| Step: 0
Training loss: 0.7643691301345825
Validation loss: 2.2887866497039795

Epoch: 6| Step: 1
Training loss: 0.6501508355140686
Validation loss: 2.3227572043736777

Epoch: 6| Step: 2
Training loss: 0.3997455835342407
Validation loss: 2.3279207150141397

Epoch: 6| Step: 3
Training loss: 0.5334806442260742
Validation loss: 2.3572091857592263

Epoch: 6| Step: 4
Training loss: 0.622404932975769
Validation loss: 2.3251424431800842

Epoch: 6| Step: 5
Training loss: 0.42544111609458923
Validation loss: 2.3526280323664346

Epoch: 6| Step: 6
Training loss: 0.6596215963363647
Validation loss: 2.3433926502863565

Epoch: 6| Step: 7
Training loss: 0.39589694142341614
Validation loss: 2.3228892882665

Epoch: 6| Step: 8
Training loss: 0.859863817691803
Validation loss: 2.2799323995908103

Epoch: 6| Step: 9
Training loss: 0.8478307723999023
Validation loss: 2.320927063624064

Epoch: 6| Step: 10
Training loss: 0.6084703803062439
Validation loss: 2.295861542224884

Epoch: 6| Step: 11
Training loss: 1.0961500406265259
Validation loss: 2.321062763532003

Epoch: 6| Step: 12
Training loss: 0.9538003206253052
Validation loss: 2.3151297171910605

Epoch: 6| Step: 13
Training loss: 0.4594975411891937
Validation loss: 2.337135354677836

Epoch: 175| Step: 0
Training loss: 0.9236294031143188
Validation loss: 2.3474560181299844

Epoch: 6| Step: 1
Training loss: 0.4903317093849182
Validation loss: 2.2999515930811563

Epoch: 6| Step: 2
Training loss: 0.423175185918808
Validation loss: 2.264672120412191

Epoch: 6| Step: 3
Training loss: 0.8093878030776978
Validation loss: 2.3421166936556497

Epoch: 6| Step: 4
Training loss: 0.7405439615249634
Validation loss: 2.319811920324961

Epoch: 6| Step: 5
Training loss: 0.4967830777168274
Validation loss: 2.308088779449463

Epoch: 6| Step: 6
Training loss: 0.6902220845222473
Validation loss: 2.2832300662994385

Epoch: 6| Step: 7
Training loss: 0.9543023705482483
Validation loss: 2.2769744197527566

Epoch: 6| Step: 8
Training loss: 0.32801884412765503
Validation loss: 2.2914355595906577

Epoch: 6| Step: 9
Training loss: 0.5473620891571045
Validation loss: 2.305678963661194

Epoch: 6| Step: 10
Training loss: 0.8873957395553589
Validation loss: 2.2665939331054688

Epoch: 6| Step: 11
Training loss: 0.6812260150909424
Validation loss: 2.332582195599874

Epoch: 6| Step: 12
Training loss: 0.5519912242889404
Validation loss: 2.2996150652567544

Epoch: 6| Step: 13
Training loss: 0.49997785687446594
Validation loss: 2.3730803529421487

Epoch: 176| Step: 0
Training loss: 0.4904717206954956
Validation loss: 2.382007638613383

Epoch: 6| Step: 1
Training loss: 1.0182693004608154
Validation loss: 2.3540781140327454

Epoch: 6| Step: 2
Training loss: 0.4046165645122528
Validation loss: 2.3037286599477134

Epoch: 6| Step: 3
Training loss: 0.43778496980667114
Validation loss: 2.23867130279541

Epoch: 6| Step: 4
Training loss: 0.5765280723571777
Validation loss: 2.32584818204244

Epoch: 6| Step: 5
Training loss: 0.37017709016799927
Validation loss: 2.2716482480367026

Epoch: 6| Step: 6
Training loss: 1.0302882194519043
Validation loss: 2.2883366545041404

Epoch: 6| Step: 7
Training loss: 0.49272122979164124
Validation loss: 2.311701496442159

Epoch: 6| Step: 8
Training loss: 0.9228571653366089
Validation loss: 2.3044976194699607

Epoch: 6| Step: 9
Training loss: 0.9409797787666321
Validation loss: 2.312714954217275

Epoch: 6| Step: 10
Training loss: 0.6351909041404724
Validation loss: 2.3214222391446433

Epoch: 6| Step: 11
Training loss: 0.5615071058273315
Validation loss: 2.3001641829808555

Epoch: 6| Step: 12
Training loss: 0.5637078285217285
Validation loss: 2.2145896355311074

Epoch: 6| Step: 13
Training loss: 0.5599972009658813
Validation loss: 2.307254950205485

Epoch: 177| Step: 0
Training loss: 0.9030309915542603
Validation loss: 2.2610562443733215

Epoch: 6| Step: 1
Training loss: 0.30865249037742615
Validation loss: 2.3218945264816284

Epoch: 6| Step: 2
Training loss: 0.5275332927703857
Validation loss: 2.314351956049601

Epoch: 6| Step: 3
Training loss: 0.48641636967658997
Validation loss: 2.313422958056132

Epoch: 6| Step: 4
Training loss: 0.5330071449279785
Validation loss: 2.294877608617147

Epoch: 6| Step: 5
Training loss: 0.7661217451095581
Validation loss: 2.3469018936157227

Epoch: 6| Step: 6
Training loss: 0.6533641815185547
Validation loss: 2.3558253049850464

Epoch: 6| Step: 7
Training loss: 0.35763612389564514
Validation loss: 2.2846800883611045

Epoch: 6| Step: 8
Training loss: 1.2213642597198486
Validation loss: 2.288557688395182

Epoch: 6| Step: 9
Training loss: 0.3994078040122986
Validation loss: 2.3087081909179688

Epoch: 6| Step: 10
Training loss: 0.8077670335769653
Validation loss: 2.319730202356974

Epoch: 6| Step: 11
Training loss: 0.527023196220398
Validation loss: 2.2989176313082376

Epoch: 6| Step: 12
Training loss: 0.7891622185707092
Validation loss: 2.303203582763672

Epoch: 6| Step: 13
Training loss: 0.45148196816444397
Validation loss: 2.306087613105774

Epoch: 178| Step: 0
Training loss: 0.6050903797149658
Validation loss: 2.309635281562805

Epoch: 6| Step: 1
Training loss: 0.5811182260513306
Validation loss: 2.3317702611287436

Epoch: 6| Step: 2
Training loss: 0.692844808101654
Validation loss: 2.385542352994283

Epoch: 6| Step: 3
Training loss: 0.519568681716919
Validation loss: 2.3818443616231284

Epoch: 6| Step: 4
Training loss: 0.6302639245986938
Validation loss: 2.341781218846639

Epoch: 6| Step: 5
Training loss: 0.5199009776115417
Validation loss: 2.303530295689901

Epoch: 6| Step: 6
Training loss: 0.5421268939971924
Validation loss: 2.3121697902679443

Epoch: 6| Step: 7
Training loss: 0.4288995862007141
Validation loss: 2.3100609381993613

Epoch: 6| Step: 8
Training loss: 0.3763347268104553
Validation loss: 2.3202404975891113

Epoch: 6| Step: 9
Training loss: 0.8923934698104858
Validation loss: 2.2848529616991677

Epoch: 6| Step: 10
Training loss: 0.5085754990577698
Validation loss: 2.3071818153063455

Epoch: 6| Step: 11
Training loss: 1.4815481901168823
Validation loss: 2.3130085865656533

Epoch: 6| Step: 12
Training loss: 0.8135247230529785
Validation loss: 2.3712422450383506

Epoch: 6| Step: 13
Training loss: 0.4511377811431885
Validation loss: 2.2948886354764304

Epoch: 179| Step: 0
Training loss: 0.6091610789299011
Validation loss: 2.320129156112671

Epoch: 6| Step: 1
Training loss: 0.7190916538238525
Validation loss: 2.3814886808395386

Epoch: 6| Step: 2
Training loss: 0.5778375864028931
Validation loss: 2.3568968971570334

Epoch: 6| Step: 3
Training loss: 0.3723609447479248
Validation loss: 2.320225159327189

Epoch: 6| Step: 4
Training loss: 0.4909810721874237
Validation loss: 2.3199477195739746

Epoch: 6| Step: 5
Training loss: 0.5783578157424927
Validation loss: 2.329785466194153

Epoch: 6| Step: 6
Training loss: 0.5647808909416199
Validation loss: 2.3007322947184243

Epoch: 6| Step: 7
Training loss: 0.5451774597167969
Validation loss: 2.344901164372762

Epoch: 6| Step: 8
Training loss: 0.8047024011611938
Validation loss: 2.2694824735323587

Epoch: 6| Step: 9
Training loss: 0.6109678745269775
Validation loss: 2.300032635529836

Epoch: 6| Step: 10
Training loss: 0.7908302545547485
Validation loss: 2.282264987627665

Epoch: 6| Step: 11
Training loss: 0.6901432871818542
Validation loss: 2.360683540503184

Epoch: 6| Step: 12
Training loss: 1.0778981447219849
Validation loss: 2.357583542664846

Epoch: 6| Step: 13
Training loss: 0.7305155992507935
Validation loss: 2.317500352859497

Epoch: 180| Step: 0
Training loss: 0.9119623303413391
Validation loss: 2.3195205330848694

Epoch: 6| Step: 1
Training loss: 0.4477355182170868
Validation loss: 2.3215872844060264

Epoch: 6| Step: 2
Training loss: 0.47437387704849243
Validation loss: 2.2871089975039163

Epoch: 6| Step: 3
Training loss: 0.5427354574203491
Validation loss: 2.32099848985672

Epoch: 6| Step: 4
Training loss: 0.5920346975326538
Validation loss: 2.3010065158208213

Epoch: 6| Step: 5
Training loss: 0.5293576717376709
Validation loss: 2.277547001838684

Epoch: 6| Step: 6
Training loss: 1.0124768018722534
Validation loss: 2.2252339522043862

Epoch: 6| Step: 7
Training loss: 0.35139045119285583
Validation loss: 2.3316690921783447

Epoch: 6| Step: 8
Training loss: 1.1089355945587158
Validation loss: 2.39992223183314

Epoch: 6| Step: 9
Training loss: 0.855205774307251
Validation loss: 2.3405712644259133

Epoch: 6| Step: 10
Training loss: 0.39095935225486755
Validation loss: 2.397178848584493

Epoch: 6| Step: 11
Training loss: 0.5891159772872925
Validation loss: 2.247428059577942

Epoch: 6| Step: 12
Training loss: 0.35394713282585144
Validation loss: 2.3646801908810935

Epoch: 6| Step: 13
Training loss: 0.8159850835800171
Validation loss: 2.3519547382990518

Epoch: 181| Step: 0
Training loss: 0.7409511804580688
Validation loss: 2.369380474090576

Epoch: 6| Step: 1
Training loss: 0.36601659655570984
Validation loss: 2.335285405317942

Epoch: 6| Step: 2
Training loss: 0.418445885181427
Validation loss: 2.3573516805966697

Epoch: 6| Step: 3
Training loss: 0.8963519930839539
Validation loss: 2.315739115079244

Epoch: 6| Step: 4
Training loss: 0.4832853674888611
Validation loss: 2.365196486314138

Epoch: 6| Step: 5
Training loss: 0.8914766311645508
Validation loss: 2.3094069560368857

Epoch: 6| Step: 6
Training loss: 0.5195167064666748
Validation loss: 2.2730170289675393

Epoch: 6| Step: 7
Training loss: 0.8337863087654114
Validation loss: 2.35715788602829

Epoch: 6| Step: 8
Training loss: 0.6281704902648926
Validation loss: 2.3387156327565513

Epoch: 6| Step: 9
Training loss: 0.5824283957481384
Validation loss: 2.378805081049601

Epoch: 6| Step: 10
Training loss: 0.7785248160362244
Validation loss: 2.4147987564404807

Epoch: 6| Step: 11
Training loss: 0.5204352140426636
Validation loss: 2.378547271092733

Epoch: 6| Step: 12
Training loss: 0.8311782479286194
Validation loss: 2.2894341945648193

Epoch: 6| Step: 13
Training loss: 0.6156331300735474
Validation loss: 2.3276827335357666

Epoch: 182| Step: 0
Training loss: 0.7467331886291504
Validation loss: 2.321357846260071

Epoch: 6| Step: 1
Training loss: 0.7073658108711243
Validation loss: 2.3225643237431846

Epoch: 6| Step: 2
Training loss: 0.5594050288200378
Validation loss: 2.304691970348358

Epoch: 6| Step: 3
Training loss: 0.328377902507782
Validation loss: 2.3033786018689475

Epoch: 6| Step: 4
Training loss: 0.8431717157363892
Validation loss: 2.379592756430308

Epoch: 6| Step: 5
Training loss: 1.09562087059021
Validation loss: 2.3700220783551535

Epoch: 6| Step: 6
Training loss: 0.6738238334655762
Validation loss: 2.3861899971961975

Epoch: 6| Step: 7
Training loss: 0.9009624719619751
Validation loss: 2.4158407052357993

Epoch: 6| Step: 8
Training loss: 0.47732314467430115
Validation loss: 2.317668934663137

Epoch: 6| Step: 9
Training loss: 0.6534948945045471
Validation loss: 2.2728046774864197

Epoch: 6| Step: 10
Training loss: 0.7075347900390625
Validation loss: 2.3015538454055786

Epoch: 6| Step: 11
Training loss: 0.9173586964607239
Validation loss: 2.337503353754679

Epoch: 6| Step: 12
Training loss: 0.37660664319992065
Validation loss: 2.341901878515879

Epoch: 6| Step: 13
Training loss: 0.8416553735733032
Validation loss: 2.248852570851644

Epoch: 183| Step: 0
Training loss: 0.5999874472618103
Validation loss: 2.350769797960917

Epoch: 6| Step: 1
Training loss: 0.6102942228317261
Validation loss: 2.355299711227417

Epoch: 6| Step: 2
Training loss: 0.6028735041618347
Validation loss: 2.3337294658025107

Epoch: 6| Step: 3
Training loss: 0.6922227740287781
Validation loss: 2.335113207499186

Epoch: 6| Step: 4
Training loss: 0.951749324798584
Validation loss: 2.3371222813924155

Epoch: 6| Step: 5
Training loss: 0.7046138048171997
Validation loss: 2.3531919519106546

Epoch: 6| Step: 6
Training loss: 0.4604230225086212
Validation loss: 2.279583195845286

Epoch: 6| Step: 7
Training loss: 0.45191147923469543
Validation loss: 2.3542998234430947

Epoch: 6| Step: 8
Training loss: 0.6390506029129028
Validation loss: 2.32166850566864

Epoch: 6| Step: 9
Training loss: 0.7152125835418701
Validation loss: 2.3920623461405435

Epoch: 6| Step: 10
Training loss: 0.38897714018821716
Validation loss: 2.400912086168925

Epoch: 6| Step: 11
Training loss: 0.5951244831085205
Validation loss: 2.3765906492869058

Epoch: 6| Step: 12
Training loss: 0.7033311128616333
Validation loss: 2.348735829194387

Epoch: 6| Step: 13
Training loss: 0.3049665093421936
Validation loss: 2.31677653392156

Epoch: 184| Step: 0
Training loss: 0.6682236790657043
Validation loss: 2.295602003733317

Epoch: 6| Step: 1
Training loss: 0.2868052124977112
Validation loss: 2.332832932472229

Epoch: 6| Step: 2
Training loss: 0.8804280161857605
Validation loss: 2.3287073373794556

Epoch: 6| Step: 3
Training loss: 0.7475067377090454
Validation loss: 2.3364176750183105

Epoch: 6| Step: 4
Training loss: 0.37288641929626465
Validation loss: 2.324990391731262

Epoch: 6| Step: 5
Training loss: 0.622578501701355
Validation loss: 2.3529648780822754

Epoch: 6| Step: 6
Training loss: 0.5672537088394165
Validation loss: 2.3543673157691956

Epoch: 6| Step: 7
Training loss: 0.6100219488143921
Validation loss: 2.348516265551249

Epoch: 6| Step: 8
Training loss: 0.38432061672210693
Validation loss: 2.3224948247273765

Epoch: 6| Step: 9
Training loss: 0.6018372774124146
Validation loss: 2.3010244965553284

Epoch: 6| Step: 10
Training loss: 1.175266146659851
Validation loss: 2.306306560834249

Epoch: 6| Step: 11
Training loss: 0.4171910285949707
Validation loss: 2.317124923070272

Epoch: 6| Step: 12
Training loss: 0.4601425528526306
Validation loss: 2.3334906101226807

Epoch: 6| Step: 13
Training loss: 0.5936902761459351
Validation loss: 2.2995644013086953

Epoch: 185| Step: 0
Training loss: 0.5591379404067993
Validation loss: 2.3266607522964478

Epoch: 6| Step: 1
Training loss: 0.5123915672302246
Validation loss: 2.3405380646387735

Epoch: 6| Step: 2
Training loss: 0.8545955419540405
Validation loss: 2.3072879910469055

Epoch: 6| Step: 3
Training loss: 0.6537516713142395
Validation loss: 2.2807878057161965

Epoch: 6| Step: 4
Training loss: 0.5032335519790649
Validation loss: 2.249820113182068

Epoch: 6| Step: 5
Training loss: 0.3522564768791199
Validation loss: 2.255360186100006

Epoch: 6| Step: 6
Training loss: 0.6887842416763306
Validation loss: 2.2759429613749185

Epoch: 6| Step: 7
Training loss: 0.5732429623603821
Validation loss: 2.341677745183309

Epoch: 6| Step: 8
Training loss: 0.3923812508583069
Validation loss: 2.299060026804606

Epoch: 6| Step: 9
Training loss: 0.3650814890861511
Validation loss: 2.3403252363204956

Epoch: 6| Step: 10
Training loss: 1.157411813735962
Validation loss: 2.2766231894493103

Epoch: 6| Step: 11
Training loss: 0.5846850872039795
Validation loss: 2.279671053091685

Epoch: 6| Step: 12
Training loss: 0.7761858701705933
Validation loss: 2.313506563504537

Epoch: 6| Step: 13
Training loss: 0.7219217419624329
Validation loss: 2.338476518789927

Epoch: 186| Step: 0
Training loss: 0.9775266647338867
Validation loss: 2.3092335859934487

Epoch: 6| Step: 1
Training loss: 0.6281256675720215
Validation loss: 2.256164034207662

Epoch: 6| Step: 2
Training loss: 0.4392954707145691
Validation loss: 2.2940379977226257

Epoch: 6| Step: 3
Training loss: 0.39379337430000305
Validation loss: 2.2212511897087097

Epoch: 6| Step: 4
Training loss: 0.37402456998825073
Validation loss: 2.276046554247538

Epoch: 6| Step: 5
Training loss: 0.6778203248977661
Validation loss: 2.2214956084887185

Epoch: 6| Step: 6
Training loss: 0.4947013258934021
Validation loss: 2.244675358136495

Epoch: 6| Step: 7
Training loss: 1.0883792638778687
Validation loss: 2.293947219848633

Epoch: 6| Step: 8
Training loss: 0.5231879353523254
Validation loss: 2.3238388498624167

Epoch: 6| Step: 9
Training loss: 0.43231824040412903
Validation loss: 2.344298799832662

Epoch: 6| Step: 10
Training loss: 0.3434962034225464
Validation loss: 2.3674159248669944

Epoch: 6| Step: 11
Training loss: 0.48682430386543274
Validation loss: 2.3274443546930947

Epoch: 6| Step: 12
Training loss: 0.596855878829956
Validation loss: 2.2937470277150473

Epoch: 6| Step: 13
Training loss: 0.8429836630821228
Validation loss: 2.295468052228292

Epoch: 187| Step: 0
Training loss: 0.625451922416687
Validation loss: 2.398139158884684

Epoch: 6| Step: 1
Training loss: 0.31115323305130005
Validation loss: 2.2760951121648154

Epoch: 6| Step: 2
Training loss: 0.6366555690765381
Validation loss: 2.261331478754679

Epoch: 6| Step: 3
Training loss: 0.9246221780776978
Validation loss: 2.3104721705118814

Epoch: 6| Step: 4
Training loss: 0.6705165505409241
Validation loss: 2.2649677793184915

Epoch: 6| Step: 5
Training loss: 0.3422718644142151
Validation loss: 2.3376150727272034

Epoch: 6| Step: 6
Training loss: 0.5803332328796387
Validation loss: 2.319350858529409

Epoch: 6| Step: 7
Training loss: 0.4808313846588135
Validation loss: 2.321363707383474

Epoch: 6| Step: 8
Training loss: 0.7300875186920166
Validation loss: 2.3433826764424643

Epoch: 6| Step: 9
Training loss: 0.26407015323638916
Validation loss: 2.329412857691447

Epoch: 6| Step: 10
Training loss: 0.634548544883728
Validation loss: 2.3525832891464233

Epoch: 6| Step: 11
Training loss: 0.7419732809066772
Validation loss: 2.347362677256266

Epoch: 6| Step: 12
Training loss: 0.7285994291305542
Validation loss: 2.341331958770752

Epoch: 6| Step: 13
Training loss: 0.46878281235694885
Validation loss: 2.3004425764083862

Epoch: 188| Step: 0
Training loss: 0.7032203674316406
Validation loss: 2.3744680086771646

Epoch: 6| Step: 1
Training loss: 0.7610258460044861
Validation loss: 2.395885705947876

Epoch: 6| Step: 2
Training loss: 0.486379474401474
Validation loss: 2.312524437904358

Epoch: 6| Step: 3
Training loss: 0.4546554386615753
Validation loss: 2.3609702984491983

Epoch: 6| Step: 4
Training loss: 0.6202693581581116
Validation loss: 2.3646238247553506

Epoch: 6| Step: 5
Training loss: 0.37259262800216675
Validation loss: 2.360045293966929

Epoch: 6| Step: 6
Training loss: 0.3910262882709503
Validation loss: 2.3029064337412515

Epoch: 6| Step: 7
Training loss: 1.0081465244293213
Validation loss: 2.331908663113912

Epoch: 6| Step: 8
Training loss: 0.5226184725761414
Validation loss: 2.320275624593099

Epoch: 6| Step: 9
Training loss: 0.5059264898300171
Validation loss: 2.34994904200236

Epoch: 6| Step: 10
Training loss: 0.7118971347808838
Validation loss: 2.3343385656674704

Epoch: 6| Step: 11
Training loss: 0.5087737441062927
Validation loss: 2.2912164330482483

Epoch: 6| Step: 12
Training loss: 0.8046500086784363
Validation loss: 2.3335119485855103

Epoch: 6| Step: 13
Training loss: 0.7226574420928955
Validation loss: 2.289034108320872

Epoch: 189| Step: 0
Training loss: 0.5036643743515015
Validation loss: 2.29398904244105

Epoch: 6| Step: 1
Training loss: 0.37809842824935913
Validation loss: 2.2412694493929544

Epoch: 6| Step: 2
Training loss: 0.8527576923370361
Validation loss: 2.3068894147872925

Epoch: 6| Step: 3
Training loss: 0.5017687082290649
Validation loss: 2.3138557076454163

Epoch: 6| Step: 4
Training loss: 0.3902430236339569
Validation loss: 2.319829265276591

Epoch: 6| Step: 5
Training loss: 0.522807776927948
Validation loss: 2.2511657079060874

Epoch: 6| Step: 6
Training loss: 0.6293303370475769
Validation loss: 2.293821652730306

Epoch: 6| Step: 7
Training loss: 0.4377598464488983
Validation loss: 2.3312915166219077

Epoch: 6| Step: 8
Training loss: 0.8715627789497375
Validation loss: 2.3282841046651206

Epoch: 6| Step: 9
Training loss: 0.40156862139701843
Validation loss: 2.343802511692047

Epoch: 6| Step: 10
Training loss: 0.19333800673484802
Validation loss: 2.311163385709127

Epoch: 6| Step: 11
Training loss: 0.44284868240356445
Validation loss: 2.3151628971099854

Epoch: 6| Step: 12
Training loss: 0.955737292766571
Validation loss: 2.20919938882192

Epoch: 6| Step: 13
Training loss: 0.7344486117362976
Validation loss: 2.2939940889676413

Epoch: 190| Step: 0
Training loss: 0.3791177272796631
Validation loss: 2.2914886275927224

Epoch: 6| Step: 1
Training loss: 0.23440031707286835
Validation loss: 2.299515108267466

Epoch: 6| Step: 2
Training loss: 0.5138125419616699
Validation loss: 2.242460608482361

Epoch: 6| Step: 3
Training loss: 0.43890857696533203
Validation loss: 2.2647328774134317

Epoch: 6| Step: 4
Training loss: 0.47849053144454956
Validation loss: 2.304110606511434

Epoch: 6| Step: 5
Training loss: 0.5381323099136353
Validation loss: 2.278461138407389

Epoch: 6| Step: 6
Training loss: 0.4621836245059967
Validation loss: 2.3128275275230408

Epoch: 6| Step: 7
Training loss: 0.6981756687164307
Validation loss: 2.266954859097799

Epoch: 6| Step: 8
Training loss: 0.6776164770126343
Validation loss: 2.3534136613210044

Epoch: 6| Step: 9
Training loss: 0.5689132809638977
Validation loss: 2.320585548877716

Epoch: 6| Step: 10
Training loss: 0.566879391670227
Validation loss: 2.306946277618408

Epoch: 6| Step: 11
Training loss: 0.4382157325744629
Validation loss: 2.3130228519439697

Epoch: 6| Step: 12
Training loss: 0.6440884470939636
Validation loss: 2.30570650100708

Epoch: 6| Step: 13
Training loss: 1.3117783069610596
Validation loss: 2.346499224503835

Epoch: 191| Step: 0
Training loss: 0.8022068738937378
Validation loss: 2.364893893400828

Epoch: 6| Step: 1
Training loss: 0.3746364116668701
Validation loss: 2.3661125103632608

Epoch: 6| Step: 2
Training loss: 0.42379942536354065
Validation loss: 2.354873855908712

Epoch: 6| Step: 3
Training loss: 0.5592273473739624
Validation loss: 2.3182944655418396

Epoch: 6| Step: 4
Training loss: 0.6729820966720581
Validation loss: 2.314122517903646

Epoch: 6| Step: 5
Training loss: 0.7794981002807617
Validation loss: 2.32215682665507

Epoch: 6| Step: 6
Training loss: 0.8496099710464478
Validation loss: 2.2695598800977073

Epoch: 6| Step: 7
Training loss: 0.5147535800933838
Validation loss: 2.2910691301027932

Epoch: 6| Step: 8
Training loss: 0.4524482488632202
Validation loss: 2.2911709348360696

Epoch: 6| Step: 9
Training loss: 0.67122882604599
Validation loss: 2.3616398572921753

Epoch: 6| Step: 10
Training loss: 0.5495483875274658
Validation loss: 2.3109204371770224

Epoch: 6| Step: 11
Training loss: 0.5119744539260864
Validation loss: 2.321909487247467

Epoch: 6| Step: 12
Training loss: 1.026139259338379
Validation loss: 2.3678415218989053

Epoch: 6| Step: 13
Training loss: 0.6362670660018921
Validation loss: 2.37861301501592

Epoch: 192| Step: 0
Training loss: 0.8746023774147034
Validation loss: 2.2734866738319397

Epoch: 6| Step: 1
Training loss: 0.4517841041088104
Validation loss: 2.3355075120925903

Epoch: 6| Step: 2
Training loss: 0.4809994697570801
Validation loss: 2.333953062693278

Epoch: 6| Step: 3
Training loss: 0.4554077386856079
Validation loss: 2.345492899417877

Epoch: 6| Step: 4
Training loss: 0.7122382521629333
Validation loss: 2.3091224233309426

Epoch: 6| Step: 5
Training loss: 1.2203335762023926
Validation loss: 2.3870970209439597

Epoch: 6| Step: 6
Training loss: 0.6689015626907349
Validation loss: 2.407958507537842

Epoch: 6| Step: 7
Training loss: 0.549882173538208
Validation loss: 2.315750002861023

Epoch: 6| Step: 8
Training loss: 0.461823433637619
Validation loss: 2.349222699801127

Epoch: 6| Step: 9
Training loss: 0.37418103218078613
Validation loss: 2.226683259010315

Epoch: 6| Step: 10
Training loss: 0.5499364137649536
Validation loss: 2.3092985351880393

Epoch: 6| Step: 11
Training loss: 0.3432183861732483
Validation loss: 2.3020774523417153

Epoch: 6| Step: 12
Training loss: 0.4896935820579529
Validation loss: 2.2640279730161033

Epoch: 6| Step: 13
Training loss: 0.5826667547225952
Validation loss: 2.3278254667917886

Epoch: 193| Step: 0
Training loss: 0.3647095263004303
Validation loss: 2.376617153485616

Epoch: 6| Step: 1
Training loss: 0.531531572341919
Validation loss: 2.3620170950889587

Epoch: 6| Step: 2
Training loss: 0.47902387380599976
Validation loss: 2.3099336425463357

Epoch: 6| Step: 3
Training loss: 0.480988085269928
Validation loss: 2.327750245730082

Epoch: 6| Step: 4
Training loss: 0.7521235942840576
Validation loss: 2.2998032371203103

Epoch: 6| Step: 5
Training loss: 0.7051610350608826
Validation loss: 2.2942023475964866

Epoch: 6| Step: 6
Training loss: 0.7919822931289673
Validation loss: 2.2802681922912598

Epoch: 6| Step: 7
Training loss: 0.6331997513771057
Validation loss: 2.267715414365133

Epoch: 6| Step: 8
Training loss: 0.7322616577148438
Validation loss: 2.3281818628311157

Epoch: 6| Step: 9
Training loss: 0.33944323658943176
Validation loss: 2.338716367880503

Epoch: 6| Step: 10
Training loss: 0.37407585978507996
Validation loss: 2.3520191311836243

Epoch: 6| Step: 11
Training loss: 0.4845474362373352
Validation loss: 2.316056191921234

Epoch: 6| Step: 12
Training loss: 0.5483537912368774
Validation loss: 2.39765598376592

Epoch: 6| Step: 13
Training loss: 0.8004425764083862
Validation loss: 2.2432393034299216

Epoch: 194| Step: 0
Training loss: 0.5082495808601379
Validation loss: 2.335536996523539

Epoch: 6| Step: 1
Training loss: 0.6348564028739929
Validation loss: 2.260250965754191

Epoch: 6| Step: 2
Training loss: 0.574808657169342
Validation loss: 2.3486621181170144

Epoch: 6| Step: 3
Training loss: 0.5283414125442505
Validation loss: 2.3032437761624656

Epoch: 6| Step: 4
Training loss: 0.6872149109840393
Validation loss: 2.370214025179545

Epoch: 6| Step: 5
Training loss: 0.5646010637283325
Validation loss: 2.3204243580500283

Epoch: 6| Step: 6
Training loss: 0.7663902044296265
Validation loss: 2.3504387935002646

Epoch: 6| Step: 7
Training loss: 0.550594687461853
Validation loss: 2.383137027422587

Epoch: 6| Step: 8
Training loss: 0.8170523643493652
Validation loss: 2.3049333095550537

Epoch: 6| Step: 9
Training loss: 0.29674673080444336
Validation loss: 2.2529013752937317

Epoch: 6| Step: 10
Training loss: 0.4332611858844757
Validation loss: 2.3812451362609863

Epoch: 6| Step: 11
Training loss: 0.46506184339523315
Validation loss: 2.3024952014287314

Epoch: 6| Step: 12
Training loss: 0.6391196250915527
Validation loss: 2.3368791341781616

Epoch: 6| Step: 13
Training loss: 0.5903826355934143
Validation loss: 2.3512203693389893

Epoch: 195| Step: 0
Training loss: 1.1971055269241333
Validation loss: 2.340637445449829

Epoch: 6| Step: 1
Training loss: 0.6058545708656311
Validation loss: 2.4231637517611184

Epoch: 6| Step: 2
Training loss: 0.39953434467315674
Validation loss: 2.3154700795809426

Epoch: 6| Step: 3
Training loss: 0.43613260984420776
Validation loss: 2.3579617738723755

Epoch: 6| Step: 4
Training loss: 0.819108784198761
Validation loss: 2.2745697498321533

Epoch: 6| Step: 5
Training loss: 0.3142126202583313
Validation loss: 2.321077346801758

Epoch: 6| Step: 6
Training loss: 0.4796672463417053
Validation loss: 2.340753118197123

Epoch: 6| Step: 7
Training loss: 0.5171444416046143
Validation loss: 2.263928314050039

Epoch: 6| Step: 8
Training loss: 0.3619653284549713
Validation loss: 2.3216033776601157

Epoch: 6| Step: 9
Training loss: 0.5698922872543335
Validation loss: 2.3112208048502603

Epoch: 6| Step: 10
Training loss: 0.29810062050819397
Validation loss: 2.31374184290568

Epoch: 6| Step: 11
Training loss: 0.4444564878940582
Validation loss: 2.276735464731852

Epoch: 6| Step: 12
Training loss: 0.8828372359275818
Validation loss: 2.2582003672917685

Epoch: 6| Step: 13
Training loss: 0.5523596405982971
Validation loss: 2.3347630898157754

Epoch: 196| Step: 0
Training loss: 0.6127623319625854
Validation loss: 2.281442860762278

Epoch: 6| Step: 1
Training loss: 0.559775710105896
Validation loss: 2.3080244263013205

Epoch: 6| Step: 2
Training loss: 0.7655906081199646
Validation loss: 2.203146477540334

Epoch: 6| Step: 3
Training loss: 0.47296106815338135
Validation loss: 2.292071978251139

Epoch: 6| Step: 4
Training loss: 0.45029497146606445
Validation loss: 2.2490445574124656

Epoch: 6| Step: 5
Training loss: 0.8997460603713989
Validation loss: 2.370028078556061

Epoch: 6| Step: 6
Training loss: 0.9751516580581665
Validation loss: 2.3565077582995095

Epoch: 6| Step: 7
Training loss: 0.7950336933135986
Validation loss: 2.4062341849009194

Epoch: 6| Step: 8
Training loss: 0.8077555298805237
Validation loss: 2.343230346838633

Epoch: 6| Step: 9
Training loss: 0.8153984546661377
Validation loss: 2.3626033465067544

Epoch: 6| Step: 10
Training loss: 0.5764003992080688
Validation loss: 2.2761112650235495

Epoch: 6| Step: 11
Training loss: 0.5764434337615967
Validation loss: 2.255224605401357

Epoch: 6| Step: 12
Training loss: 0.6872470378875732
Validation loss: 2.2556837995847068

Epoch: 6| Step: 13
Training loss: 0.5540736317634583
Validation loss: 2.265812397003174

Epoch: 197| Step: 0
Training loss: 0.8397799730300903
Validation loss: 2.331818183263143

Epoch: 6| Step: 1
Training loss: 0.49251025915145874
Validation loss: 2.272264063358307

Epoch: 6| Step: 2
Training loss: 0.4136123061180115
Validation loss: 2.23025914033254

Epoch: 6| Step: 3
Training loss: 0.3687663674354553
Validation loss: 2.286020358403524

Epoch: 6| Step: 4
Training loss: 0.7808798551559448
Validation loss: 2.3130481441815696

Epoch: 6| Step: 5
Training loss: 0.7383894920349121
Validation loss: 2.3155978322029114

Epoch: 6| Step: 6
Training loss: 0.5738755464553833
Validation loss: 2.3529399236043296

Epoch: 6| Step: 7
Training loss: 0.5160543322563171
Validation loss: 2.250602920850118

Epoch: 6| Step: 8
Training loss: 0.4224998354911804
Validation loss: 2.2894139885902405

Epoch: 6| Step: 9
Training loss: 0.6078584790229797
Validation loss: 2.3072258830070496

Epoch: 6| Step: 10
Training loss: 0.1981266736984253
Validation loss: 2.2859962582588196

Epoch: 6| Step: 11
Training loss: 0.5692916512489319
Validation loss: 2.2923113107681274

Epoch: 6| Step: 12
Training loss: 0.6625064611434937
Validation loss: 2.289103309313456

Epoch: 6| Step: 13
Training loss: 0.6518453359603882
Validation loss: 2.2330488761266074

Epoch: 198| Step: 0
Training loss: 0.4000359773635864
Validation loss: 2.275637169679006

Epoch: 6| Step: 1
Training loss: 0.46165168285369873
Validation loss: 2.315771142641703

Epoch: 6| Step: 2
Training loss: 0.533053994178772
Validation loss: 2.3333948651949563

Epoch: 6| Step: 3
Training loss: 0.7122259140014648
Validation loss: 2.396900256474813

Epoch: 6| Step: 4
Training loss: 0.6706704497337341
Validation loss: 2.373377819856008

Epoch: 6| Step: 5
Training loss: 0.7074298858642578
Validation loss: 2.2681641976038613

Epoch: 6| Step: 6
Training loss: 0.4737117290496826
Validation loss: 2.3211121757825217

Epoch: 6| Step: 7
Training loss: 0.35339444875717163
Validation loss: 2.2308868964513144

Epoch: 6| Step: 8
Training loss: 0.43893277645111084
Validation loss: 2.2213810284932456

Epoch: 6| Step: 9
Training loss: 0.7195475101470947
Validation loss: 2.2614145477612815

Epoch: 6| Step: 10
Training loss: 0.6205679178237915
Validation loss: 2.2871444821357727

Epoch: 6| Step: 11
Training loss: 0.7087632417678833
Validation loss: 2.3261936704317727

Epoch: 6| Step: 12
Training loss: 0.47473692893981934
Validation loss: 2.364042599995931

Epoch: 6| Step: 13
Training loss: 0.708911657333374
Validation loss: 2.3545729716618857

Epoch: 199| Step: 0
Training loss: 0.6276154518127441
Validation loss: 2.3301952282587686

Epoch: 6| Step: 1
Training loss: 0.6893999576568604
Validation loss: 2.372135599454244

Epoch: 6| Step: 2
Training loss: 0.6272473931312561
Validation loss: 2.326443394025167

Epoch: 6| Step: 3
Training loss: 0.6399575471878052
Validation loss: 2.2352154652277627

Epoch: 6| Step: 4
Training loss: 0.627261757850647
Validation loss: 2.3106398781140647

Epoch: 6| Step: 5
Training loss: 0.49167630076408386
Validation loss: 2.342617173989614

Epoch: 6| Step: 6
Training loss: 0.4910878539085388
Validation loss: 2.349403520425161

Epoch: 6| Step: 7
Training loss: 0.7077127695083618
Validation loss: 2.3422680695851645

Epoch: 6| Step: 8
Training loss: 0.7382165193557739
Validation loss: 2.3487453858057656

Epoch: 6| Step: 9
Training loss: 0.3900829255580902
Validation loss: 2.3378480871518454

Epoch: 6| Step: 10
Training loss: 0.47715434432029724
Validation loss: 2.2810258269309998

Epoch: 6| Step: 11
Training loss: 0.9722693562507629
Validation loss: 2.3017553091049194

Epoch: 6| Step: 12
Training loss: 0.4514145255088806
Validation loss: 2.38917483886083

Epoch: 6| Step: 13
Training loss: 0.5253909826278687
Validation loss: 2.380434195200602

Epoch: 200| Step: 0
Training loss: 0.6168132424354553
Validation loss: 2.329679230848948

Epoch: 6| Step: 1
Training loss: 0.7183321118354797
Validation loss: 2.410233457883199

Epoch: 6| Step: 2
Training loss: 0.6456941366195679
Validation loss: 2.4140472610791526

Epoch: 6| Step: 3
Training loss: 0.593690037727356
Validation loss: 2.349043885866801

Epoch: 6| Step: 4
Training loss: 0.5496407151222229
Validation loss: 2.385119398434957

Epoch: 6| Step: 5
Training loss: 0.6663445234298706
Validation loss: 2.360652049382528

Epoch: 6| Step: 6
Training loss: 0.5172991752624512
Validation loss: 2.3566938440004983

Epoch: 6| Step: 7
Training loss: 0.31441164016723633
Validation loss: 2.355307181676229

Epoch: 6| Step: 8
Training loss: 0.5856667757034302
Validation loss: 2.298749009768168

Epoch: 6| Step: 9
Training loss: 0.3927077353000641
Validation loss: 2.3713276187578836

Epoch: 6| Step: 10
Training loss: 1.0201635360717773
Validation loss: 2.305502971013387

Epoch: 6| Step: 11
Training loss: 0.4459660053253174
Validation loss: 2.3416443467140198

Epoch: 6| Step: 12
Training loss: 0.37209761142730713
Validation loss: 2.3043323953946433

Epoch: 6| Step: 13
Training loss: 0.6477169990539551
Validation loss: 2.2924692630767822

Testing loss: 2.1746780366348704
