Epoch: 1| Step: 0
Training loss: 3.635173797607422
Validation loss: 4.09276282787323

Epoch: 6| Step: 1
Training loss: 4.075385093688965
Validation loss: 4.0619577169418335

Epoch: 6| Step: 2
Training loss: 4.389688491821289
Validation loss: 4.031930208206177

Epoch: 6| Step: 3
Training loss: 4.407379627227783
Validation loss: 4.006121873855591

Epoch: 6| Step: 4
Training loss: 3.6286990642547607
Validation loss: 3.979917128880819

Epoch: 6| Step: 5
Training loss: 3.6215200424194336
Validation loss: 3.95030144850413

Epoch: 6| Step: 6
Training loss: 4.86179256439209
Validation loss: 3.921414057413737

Epoch: 6| Step: 7
Training loss: 4.835148334503174
Validation loss: 3.894071022669474

Epoch: 6| Step: 8
Training loss: 3.684209108352661
Validation loss: 3.867446859677633

Epoch: 6| Step: 9
Training loss: 4.024812698364258
Validation loss: 3.8416865269343057

Epoch: 6| Step: 10
Training loss: 3.152581214904785
Validation loss: 3.814749002456665

Epoch: 6| Step: 11
Training loss: 5.2550048828125
Validation loss: 3.7878944476445517

Epoch: 6| Step: 12
Training loss: 2.949568271636963
Validation loss: 3.7608906428019204

Epoch: 6| Step: 13
Training loss: 4.3166608810424805
Validation loss: 3.7332021792729697

Epoch: 2| Step: 0
Training loss: 3.4846434593200684
Validation loss: 3.7054689725240073

Epoch: 6| Step: 1
Training loss: 3.613157272338867
Validation loss: 3.67531418800354

Epoch: 6| Step: 2
Training loss: 3.545513391494751
Validation loss: 3.6512948274612427

Epoch: 6| Step: 3
Training loss: 3.9209203720092773
Validation loss: 3.620960275332133

Epoch: 6| Step: 4
Training loss: 2.3743598461151123
Validation loss: 3.591790517171224

Epoch: 6| Step: 5
Training loss: 4.045196533203125
Validation loss: 3.560556928316752

Epoch: 6| Step: 6
Training loss: 4.204506874084473
Validation loss: 3.530317942301432

Epoch: 6| Step: 7
Training loss: 3.5275373458862305
Validation loss: 3.4991649389266968

Epoch: 6| Step: 8
Training loss: 3.8563854694366455
Validation loss: 3.466221888860067

Epoch: 6| Step: 9
Training loss: 4.147199630737305
Validation loss: 3.4333749612172446

Epoch: 6| Step: 10
Training loss: 3.8960156440734863
Validation loss: 3.3949188788731894

Epoch: 6| Step: 11
Training loss: 3.319793701171875
Validation loss: 3.3549105723698935

Epoch: 6| Step: 12
Training loss: 3.334615468978882
Validation loss: 3.316519776980082

Epoch: 6| Step: 13
Training loss: 3.7007813453674316
Validation loss: 3.2826799949010215

Epoch: 3| Step: 0
Training loss: 2.932183265686035
Validation loss: 3.2407685915629068

Epoch: 6| Step: 1
Training loss: 3.9550819396972656
Validation loss: 3.1951167980829873

Epoch: 6| Step: 2
Training loss: 3.3875255584716797
Validation loss: 3.154449979464213

Epoch: 6| Step: 3
Training loss: 3.2468674182891846
Validation loss: 3.101129492123922

Epoch: 6| Step: 4
Training loss: 3.369809627532959
Validation loss: 3.0564478635787964

Epoch: 6| Step: 5
Training loss: 3.5154073238372803
Validation loss: 3.0095078547795615

Epoch: 6| Step: 6
Training loss: 2.6096138954162598
Validation loss: 2.9604912598927817

Epoch: 6| Step: 7
Training loss: 2.935972213745117
Validation loss: 2.9154792626698813

Epoch: 6| Step: 8
Training loss: 3.4622926712036133
Validation loss: 2.8656092087427774

Epoch: 6| Step: 9
Training loss: 3.0421690940856934
Validation loss: 2.8196718295415244

Epoch: 6| Step: 10
Training loss: 3.33793306350708
Validation loss: 2.772221008936564

Epoch: 6| Step: 11
Training loss: 2.484222888946533
Validation loss: 2.70856503645579

Epoch: 6| Step: 12
Training loss: 2.546154499053955
Validation loss: 2.6573944091796875

Epoch: 6| Step: 13
Training loss: 2.255096912384033
Validation loss: 2.6028585036595664

Epoch: 4| Step: 0
Training loss: 2.0373330116271973
Validation loss: 2.5581265687942505

Epoch: 6| Step: 1
Training loss: 2.433248519897461
Validation loss: 2.508973797162374

Epoch: 6| Step: 2
Training loss: 2.8949201107025146
Validation loss: 2.4476979970932007

Epoch: 6| Step: 3
Training loss: 2.8294646739959717
Validation loss: 2.3952680428822837

Epoch: 6| Step: 4
Training loss: 2.8179068565368652
Validation loss: 2.3400894006093345

Epoch: 6| Step: 5
Training loss: 2.356128215789795
Validation loss: 2.2880269289016724

Epoch: 6| Step: 6
Training loss: 2.2401773929595947
Validation loss: 2.2232803304990134

Epoch: 6| Step: 7
Training loss: 1.7063456773757935
Validation loss: 2.1878697077433267

Epoch: 6| Step: 8
Training loss: 2.802926540374756
Validation loss: 2.153024137020111

Epoch: 6| Step: 9
Training loss: 1.1761548519134521
Validation loss: 2.1060155034065247

Epoch: 6| Step: 10
Training loss: 2.2878191471099854
Validation loss: 2.0724648038546243

Epoch: 6| Step: 11
Training loss: 3.043416976928711
Validation loss: 2.0561844309171042

Epoch: 6| Step: 12
Training loss: 2.5286245346069336
Validation loss: 2.039746801058451

Epoch: 6| Step: 13
Training loss: 2.3376612663269043
Validation loss: 2.0319305658340454

Epoch: 5| Step: 0
Training loss: 1.7421051263809204
Validation loss: 2.0118841330210366

Epoch: 6| Step: 1
Training loss: 1.5318297147750854
Validation loss: 2.0157318115234375

Epoch: 6| Step: 2
Training loss: 2.3922996520996094
Validation loss: 2.0217153628667197

Epoch: 6| Step: 3
Training loss: 2.6498143672943115
Validation loss: 2.027634600798289

Epoch: 6| Step: 4
Training loss: 2.1377615928649902
Validation loss: 2.018744647502899

Epoch: 6| Step: 5
Training loss: 2.354310989379883
Validation loss: 2.0272570649782815

Epoch: 6| Step: 6
Training loss: 2.5890274047851562
Validation loss: 2.0275601347287497

Epoch: 6| Step: 7
Training loss: 3.073971748352051
Validation loss: 2.015173614025116

Epoch: 6| Step: 8
Training loss: 1.5302560329437256
Validation loss: 2.0263752341270447

Epoch: 6| Step: 9
Training loss: 2.213061809539795
Validation loss: 2.026001234849294

Epoch: 6| Step: 10
Training loss: 1.7913576364517212
Validation loss: 2.0167694091796875

Epoch: 6| Step: 11
Training loss: 1.8496654033660889
Validation loss: 2.006734848022461

Epoch: 6| Step: 12
Training loss: 1.3753931522369385
Validation loss: 2.0108590523401895

Epoch: 6| Step: 13
Training loss: 2.3297996520996094
Validation loss: 2.016206661860148

Epoch: 6| Step: 0
Training loss: 2.289302349090576
Validation loss: 1.9996925195058186

Epoch: 6| Step: 1
Training loss: 2.322504758834839
Validation loss: 2.002624034881592

Epoch: 6| Step: 2
Training loss: 1.8366930484771729
Validation loss: 2.0109547773996987

Epoch: 6| Step: 3
Training loss: 2.2005982398986816
Validation loss: 2.010070025920868

Epoch: 6| Step: 4
Training loss: 1.953575611114502
Validation loss: 2.0072813828786216

Epoch: 6| Step: 5
Training loss: 1.5371952056884766
Validation loss: 2.0130945642789206

Epoch: 6| Step: 6
Training loss: 1.9940276145935059
Validation loss: 2.001502056916555

Epoch: 6| Step: 7
Training loss: 2.239114761352539
Validation loss: 2.0024988055229187

Epoch: 6| Step: 8
Training loss: 2.3515195846557617
Validation loss: 2.0039751728375754

Epoch: 6| Step: 9
Training loss: 2.448275089263916
Validation loss: 2.016680439313253

Epoch: 6| Step: 10
Training loss: 2.1453800201416016
Validation loss: 2.0050192872683206

Epoch: 6| Step: 11
Training loss: 2.0005898475646973
Validation loss: 2.005965212980906

Epoch: 6| Step: 12
Training loss: 2.622708559036255
Validation loss: 1.9984842538833618

Epoch: 6| Step: 13
Training loss: 1.3208988904953003
Validation loss: 1.9991900324821472

Epoch: 7| Step: 0
Training loss: 1.7728418111801147
Validation loss: 1.9923635522524517

Epoch: 6| Step: 1
Training loss: 2.069204092025757
Validation loss: 1.9882116715113323

Epoch: 6| Step: 2
Training loss: 1.575271487236023
Validation loss: 1.9998852809270222

Epoch: 6| Step: 3
Training loss: 1.8779690265655518
Validation loss: 1.9907160600026448

Epoch: 6| Step: 4
Training loss: 2.6786458492279053
Validation loss: 2.007346034049988

Epoch: 6| Step: 5
Training loss: 2.564546585083008
Validation loss: 1.9859327673912048

Epoch: 6| Step: 6
Training loss: 2.142152786254883
Validation loss: 2.0042412082354226

Epoch: 6| Step: 7
Training loss: 2.159069776535034
Validation loss: 1.9951966206232707

Epoch: 6| Step: 8
Training loss: 1.4093570709228516
Validation loss: 1.9965973099072774

Epoch: 6| Step: 9
Training loss: 1.5723273754119873
Validation loss: 1.995937466621399

Epoch: 6| Step: 10
Training loss: 1.8636999130249023
Validation loss: 2.0091115633646646

Epoch: 6| Step: 11
Training loss: 2.2868456840515137
Validation loss: 1.9946767687797546

Epoch: 6| Step: 12
Training loss: 2.5718541145324707
Validation loss: 2.0069368879000344

Epoch: 6| Step: 13
Training loss: 2.5711734294891357
Validation loss: 1.9806465705235798

Epoch: 8| Step: 0
Training loss: 1.5249769687652588
Validation loss: 1.9930407603581746

Epoch: 6| Step: 1
Training loss: 2.5725245475769043
Validation loss: 1.992270549138387

Epoch: 6| Step: 2
Training loss: 1.8448851108551025
Validation loss: 1.9944004615147908

Epoch: 6| Step: 3
Training loss: 1.8636102676391602
Validation loss: 1.997760832309723

Epoch: 6| Step: 4
Training loss: 1.9346519708633423
Validation loss: 1.9929412206013997

Epoch: 6| Step: 5
Training loss: 1.8667881488800049
Validation loss: 1.9877442916234334

Epoch: 6| Step: 6
Training loss: 2.5274789333343506
Validation loss: 1.9841594497362773

Epoch: 6| Step: 7
Training loss: 1.9578180313110352
Validation loss: 1.9808686176935832

Epoch: 6| Step: 8
Training loss: 1.8744475841522217
Validation loss: 1.9821537733078003

Epoch: 6| Step: 9
Training loss: 2.7231650352478027
Validation loss: 1.9897347489992778

Epoch: 6| Step: 10
Training loss: 2.2568087577819824
Validation loss: 1.9913710753122966

Epoch: 6| Step: 11
Training loss: 2.029731512069702
Validation loss: 1.9808523257573445

Epoch: 6| Step: 12
Training loss: 2.094395160675049
Validation loss: 1.9746840198834736

Epoch: 6| Step: 13
Training loss: 1.8703694343566895
Validation loss: 2.005165616671244

Epoch: 9| Step: 0
Training loss: 2.848874807357788
Validation loss: 1.9891945322354634

Epoch: 6| Step: 1
Training loss: 1.508237361907959
Validation loss: 1.9906402826309204

Epoch: 6| Step: 2
Training loss: 1.515791893005371
Validation loss: 1.9946438471476238

Epoch: 6| Step: 3
Training loss: 2.248931884765625
Validation loss: 1.9859379132588704

Epoch: 6| Step: 4
Training loss: 2.256687641143799
Validation loss: 1.9912587602933247

Epoch: 6| Step: 5
Training loss: 2.2903738021850586
Validation loss: 1.9946407477060955

Epoch: 6| Step: 6
Training loss: 2.4045190811157227
Validation loss: 1.9967759648958843

Epoch: 6| Step: 7
Training loss: 2.1563022136688232
Validation loss: 1.9842542012532551

Epoch: 6| Step: 8
Training loss: 2.2728052139282227
Validation loss: 1.988276223341624

Epoch: 6| Step: 9
Training loss: 1.3524107933044434
Validation loss: 1.9818021059036255

Epoch: 6| Step: 10
Training loss: 2.0707902908325195
Validation loss: 1.9922765294710796

Epoch: 6| Step: 11
Training loss: 1.8800780773162842
Validation loss: 1.9871709148089092

Epoch: 6| Step: 12
Training loss: 2.244323253631592
Validation loss: 1.9970240394274394

Epoch: 6| Step: 13
Training loss: 1.8964838981628418
Validation loss: 1.985655426979065

Epoch: 10| Step: 0
Training loss: 1.6583898067474365
Validation loss: 1.9792607029279072

Epoch: 6| Step: 1
Training loss: 2.293334484100342
Validation loss: 1.991180419921875

Epoch: 6| Step: 2
Training loss: 1.520677089691162
Validation loss: 1.996864914894104

Epoch: 6| Step: 3
Training loss: 2.2272934913635254
Validation loss: 1.9933618505795796

Epoch: 6| Step: 4
Training loss: 1.5777878761291504
Validation loss: 2.014709750811259

Epoch: 6| Step: 5
Training loss: 1.502816915512085
Validation loss: 2.004780431588491

Epoch: 6| Step: 6
Training loss: 2.166837692260742
Validation loss: 2.0121611754099527

Epoch: 6| Step: 7
Training loss: 2.068145513534546
Validation loss: 2.004684786001841

Epoch: 6| Step: 8
Training loss: 2.4712791442871094
Validation loss: 2.0135947664578757

Epoch: 6| Step: 9
Training loss: 3.072676658630371
Validation loss: 2.0148017406463623

Epoch: 6| Step: 10
Training loss: 1.919105052947998
Validation loss: 2.0057517488797507

Epoch: 6| Step: 11
Training loss: 1.2920522689819336
Validation loss: 1.9959231813748677

Epoch: 6| Step: 12
Training loss: 3.024271011352539
Validation loss: 2.000431537628174

Epoch: 6| Step: 13
Training loss: 2.029937267303467
Validation loss: 1.9881514310836792

Epoch: 11| Step: 0
Training loss: 2.5243659019470215
Validation loss: 1.981059968471527

Epoch: 6| Step: 1
Training loss: 1.5568379163742065
Validation loss: 1.9826327959696453

Epoch: 6| Step: 2
Training loss: 3.049124002456665
Validation loss: 1.979141354560852

Epoch: 6| Step: 3
Training loss: 2.2557854652404785
Validation loss: 1.9859731197357178

Epoch: 6| Step: 4
Training loss: 1.859466791152954
Validation loss: 1.980702777703603

Epoch: 6| Step: 5
Training loss: 2.1483702659606934
Validation loss: 1.9722975691159566

Epoch: 6| Step: 6
Training loss: 1.6237504482269287
Validation loss: 1.9813494284947712

Epoch: 6| Step: 7
Training loss: 2.5824270248413086
Validation loss: 1.9789676268895466

Epoch: 6| Step: 8
Training loss: 2.0750420093536377
Validation loss: 1.9804044763247173

Epoch: 6| Step: 9
Training loss: 1.7437955141067505
Validation loss: 1.9799431165059407

Epoch: 6| Step: 10
Training loss: 1.936600923538208
Validation loss: 1.9859309395154316

Epoch: 6| Step: 11
Training loss: 1.796190857887268
Validation loss: 1.9872994422912598

Epoch: 6| Step: 12
Training loss: 1.9276673793792725
Validation loss: 1.9782170255978901

Epoch: 6| Step: 13
Training loss: 1.5549569129943848
Validation loss: 1.9789124329884846

Epoch: 12| Step: 0
Training loss: 1.3137526512145996
Validation loss: 1.9701003829638164

Epoch: 6| Step: 1
Training loss: 2.37489652633667
Validation loss: 1.9709704120953877

Epoch: 6| Step: 2
Training loss: 1.1772915124893188
Validation loss: 1.9618226687113445

Epoch: 6| Step: 3
Training loss: 2.466876983642578
Validation loss: 1.9725053310394287

Epoch: 6| Step: 4
Training loss: 1.5932691097259521
Validation loss: 1.9823022484779358

Epoch: 6| Step: 5
Training loss: 2.667072296142578
Validation loss: 1.9820698300997417

Epoch: 6| Step: 6
Training loss: 2.52933931350708
Validation loss: 2.002699871857961

Epoch: 6| Step: 7
Training loss: 2.4248578548431396
Validation loss: 1.996003766854604

Epoch: 6| Step: 8
Training loss: 1.8754231929779053
Validation loss: 1.9999415874481201

Epoch: 6| Step: 9
Training loss: 1.8767778873443604
Validation loss: 1.996581455071767

Epoch: 6| Step: 10
Training loss: 2.5103132724761963
Validation loss: 2.000602662563324

Epoch: 6| Step: 11
Training loss: 2.264260768890381
Validation loss: 2.008082369963328

Epoch: 6| Step: 12
Training loss: 1.3219273090362549
Validation loss: 1.9992462396621704

Epoch: 6| Step: 13
Training loss: 2.05340838432312
Validation loss: 2.0009218653043113

Epoch: 13| Step: 0
Training loss: 2.2743563652038574
Validation loss: 1.9799368778864543

Epoch: 6| Step: 1
Training loss: 1.596431851387024
Validation loss: 1.9962218801180522

Epoch: 6| Step: 2
Training loss: 2.0450351238250732
Validation loss: 1.971282184123993

Epoch: 6| Step: 3
Training loss: 1.6067001819610596
Validation loss: 1.9697166681289673

Epoch: 6| Step: 4
Training loss: 1.7576663494110107
Validation loss: 1.9800100723902385

Epoch: 6| Step: 5
Training loss: 2.493216037750244
Validation loss: 1.9732638200124104

Epoch: 6| Step: 6
Training loss: 1.7078759670257568
Validation loss: 1.985378623008728

Epoch: 6| Step: 7
Training loss: 2.771958589553833
Validation loss: 1.9722113410631816

Epoch: 6| Step: 8
Training loss: 1.8671835660934448
Validation loss: 1.988452672958374

Epoch: 6| Step: 9
Training loss: 2.2643473148345947
Validation loss: 1.9749679168065388

Epoch: 6| Step: 10
Training loss: 1.9102505445480347
Validation loss: 1.9567420681317647

Epoch: 6| Step: 11
Training loss: 2.5862393379211426
Validation loss: 1.9869017601013184

Epoch: 6| Step: 12
Training loss: 1.8195205926895142
Validation loss: 1.9753289818763733

Epoch: 6| Step: 13
Training loss: 1.7725389003753662
Validation loss: 1.9747487703959148

Epoch: 14| Step: 0
Training loss: 2.273258686065674
Validation loss: 1.9715929826100667

Epoch: 6| Step: 1
Training loss: 1.551580548286438
Validation loss: 1.9763790170351665

Epoch: 6| Step: 2
Training loss: 2.0483484268188477
Validation loss: 1.9782913128534954

Epoch: 6| Step: 3
Training loss: 1.5620622634887695
Validation loss: 1.9592555960019429

Epoch: 6| Step: 4
Training loss: 2.0897274017333984
Validation loss: 1.9660687843958538

Epoch: 6| Step: 5
Training loss: 1.515348196029663
Validation loss: 1.9701447486877441

Epoch: 6| Step: 6
Training loss: 2.331437110900879
Validation loss: 1.9746803243954976

Epoch: 6| Step: 7
Training loss: 2.6391496658325195
Validation loss: 1.9801498254140217

Epoch: 6| Step: 8
Training loss: 2.2485384941101074
Validation loss: 1.9722940921783447

Epoch: 6| Step: 9
Training loss: 2.4556615352630615
Validation loss: 1.9928756753603618

Epoch: 6| Step: 10
Training loss: 2.28267765045166
Validation loss: 1.9763002792994182

Epoch: 6| Step: 11
Training loss: 1.4978681802749634
Validation loss: 1.9765517512957256

Epoch: 6| Step: 12
Training loss: 2.3236641883850098
Validation loss: 1.9979353348414104

Epoch: 6| Step: 13
Training loss: 1.6408990621566772
Validation loss: 1.9938082098960876

Epoch: 15| Step: 0
Training loss: 2.265104293823242
Validation loss: 2.004688819249471

Epoch: 6| Step: 1
Training loss: 1.4552645683288574
Validation loss: 2.0048698584238687

Epoch: 6| Step: 2
Training loss: 2.1330771446228027
Validation loss: 1.9887447158495586

Epoch: 6| Step: 3
Training loss: 1.6566693782806396
Validation loss: 1.981311837832133

Epoch: 6| Step: 4
Training loss: 1.2305445671081543
Validation loss: 1.9939998785654705

Epoch: 6| Step: 5
Training loss: 2.061812162399292
Validation loss: 1.976724088191986

Epoch: 6| Step: 6
Training loss: 2.0566277503967285
Validation loss: 1.984650472799937

Epoch: 6| Step: 7
Training loss: 1.900165319442749
Validation loss: 1.965613067150116

Epoch: 6| Step: 8
Training loss: 2.142021656036377
Validation loss: 1.9671179056167603

Epoch: 6| Step: 9
Training loss: 1.9592633247375488
Validation loss: 1.9752609928448994

Epoch: 6| Step: 10
Training loss: 2.021009683609009
Validation loss: 1.984929124514262

Epoch: 6| Step: 11
Training loss: 2.341437816619873
Validation loss: 1.9902473886807759

Epoch: 6| Step: 12
Training loss: 2.9570703506469727
Validation loss: 1.985463798046112

Epoch: 6| Step: 13
Training loss: 2.0966920852661133
Validation loss: 1.973628560702006

Epoch: 16| Step: 0
Training loss: 1.8075206279754639
Validation loss: 1.9756679932276409

Epoch: 6| Step: 1
Training loss: 2.3876545429229736
Validation loss: 1.9817943374315898

Epoch: 6| Step: 2
Training loss: 1.6276962757110596
Validation loss: 1.9819969932238262

Epoch: 6| Step: 3
Training loss: 1.763267159461975
Validation loss: 1.970119595527649

Epoch: 6| Step: 4
Training loss: 1.9601588249206543
Validation loss: 1.9814768433570862

Epoch: 6| Step: 5
Training loss: 1.53107488155365
Validation loss: 1.9622971216837566

Epoch: 6| Step: 6
Training loss: 2.4958229064941406
Validation loss: 1.9733558694521587

Epoch: 6| Step: 7
Training loss: 1.5317363739013672
Validation loss: 1.9633899927139282

Epoch: 6| Step: 8
Training loss: 2.2869763374328613
Validation loss: 1.9701786835988362

Epoch: 6| Step: 9
Training loss: 1.8956998586654663
Validation loss: 1.9659478863080342

Epoch: 6| Step: 10
Training loss: 2.689667224884033
Validation loss: 1.969981074333191

Epoch: 6| Step: 11
Training loss: 2.0846312046051025
Validation loss: 1.9825945099194844

Epoch: 6| Step: 12
Training loss: 2.0466017723083496
Validation loss: 1.9859071572621663

Epoch: 6| Step: 13
Training loss: 2.0764057636260986
Validation loss: 1.987386961778005

Epoch: 17| Step: 0
Training loss: 2.0418756008148193
Validation loss: 1.9935393333435059

Epoch: 6| Step: 1
Training loss: 2.730790853500366
Validation loss: 1.9892300367355347

Epoch: 6| Step: 2
Training loss: 1.9559476375579834
Validation loss: 1.9911104242006938

Epoch: 6| Step: 3
Training loss: 1.2575984001159668
Validation loss: 1.9800453186035156

Epoch: 6| Step: 4
Training loss: 2.1466591358184814
Validation loss: 1.9761789242426555

Epoch: 6| Step: 5
Training loss: 1.9705853462219238
Validation loss: 1.96393879254659

Epoch: 6| Step: 6
Training loss: 1.8356542587280273
Validation loss: 1.9884646733601887

Epoch: 6| Step: 7
Training loss: 2.5608181953430176
Validation loss: 1.967675010363261

Epoch: 6| Step: 8
Training loss: 1.3438955545425415
Validation loss: 1.970682680606842

Epoch: 6| Step: 9
Training loss: 1.9058725833892822
Validation loss: 1.9915703137715657

Epoch: 6| Step: 10
Training loss: 2.0664443969726562
Validation loss: 1.9888521432876587

Epoch: 6| Step: 11
Training loss: 2.2037651538848877
Validation loss: 1.9918523629506428

Epoch: 6| Step: 12
Training loss: 1.7185876369476318
Validation loss: 1.9836541414260864

Epoch: 6| Step: 13
Training loss: 2.3714489936828613
Validation loss: 1.9818817973136902

Epoch: 18| Step: 0
Training loss: 1.6866282224655151
Validation loss: 1.9789716800053914

Epoch: 6| Step: 1
Training loss: 2.0428898334503174
Validation loss: 1.9771254460016887

Epoch: 6| Step: 2
Training loss: 1.943080186843872
Validation loss: 1.9665921926498413

Epoch: 6| Step: 3
Training loss: 1.9803372621536255
Validation loss: 1.9595755338668823

Epoch: 6| Step: 4
Training loss: 2.255514621734619
Validation loss: 1.9721130927403767

Epoch: 6| Step: 5
Training loss: 1.7239201068878174
Validation loss: 1.9748644828796387

Epoch: 6| Step: 6
Training loss: 2.338823080062866
Validation loss: 1.979079246520996

Epoch: 6| Step: 7
Training loss: 2.3919858932495117
Validation loss: 1.9719491799672444

Epoch: 6| Step: 8
Training loss: 1.2862669229507446
Validation loss: 1.9709962606430054

Epoch: 6| Step: 9
Training loss: 1.8812825679779053
Validation loss: 1.9675389130910237

Epoch: 6| Step: 10
Training loss: 1.9527056217193604
Validation loss: 1.9750303427378337

Epoch: 6| Step: 11
Training loss: 2.8925185203552246
Validation loss: 1.9792940219243367

Epoch: 6| Step: 12
Training loss: 1.654935598373413
Validation loss: 1.9604193369547527

Epoch: 6| Step: 13
Training loss: 1.898953914642334
Validation loss: 1.9875956575075786

Epoch: 19| Step: 0
Training loss: 1.8090319633483887
Validation loss: 1.975731333096822

Epoch: 6| Step: 1
Training loss: 2.222458839416504
Validation loss: 1.9559657176335652

Epoch: 6| Step: 2
Training loss: 1.3088269233703613
Validation loss: 1.9777716398239136

Epoch: 6| Step: 3
Training loss: 2.2784626483917236
Validation loss: 1.9723652998606365

Epoch: 6| Step: 4
Training loss: 1.7467070817947388
Validation loss: 1.9790748755137126

Epoch: 6| Step: 5
Training loss: 1.9441068172454834
Validation loss: 1.9732667406400044

Epoch: 6| Step: 6
Training loss: 1.8287826776504517
Validation loss: 1.9806437889734905

Epoch: 6| Step: 7
Training loss: 1.891711711883545
Validation loss: 1.96380482117335

Epoch: 6| Step: 8
Training loss: 1.8777891397476196
Validation loss: 1.9892413417498271

Epoch: 6| Step: 9
Training loss: 1.9965852499008179
Validation loss: 1.97590833902359

Epoch: 6| Step: 10
Training loss: 1.6171188354492188
Validation loss: 1.9915151000022888

Epoch: 6| Step: 11
Training loss: 2.748868942260742
Validation loss: 1.9866331815719604

Epoch: 6| Step: 12
Training loss: 3.089606761932373
Validation loss: 1.9877198735872905

Epoch: 6| Step: 13
Training loss: 1.606332540512085
Validation loss: 1.9805342157681782

Epoch: 20| Step: 0
Training loss: 1.7809183597564697
Validation loss: 1.982931653658549

Epoch: 6| Step: 1
Training loss: 2.594766616821289
Validation loss: 1.9779478112856548

Epoch: 6| Step: 2
Training loss: 2.130915403366089
Validation loss: 1.977835774421692

Epoch: 6| Step: 3
Training loss: 1.9952995777130127
Validation loss: 1.9558340311050415

Epoch: 6| Step: 4
Training loss: 1.9655530452728271
Validation loss: 1.9596387147903442

Epoch: 6| Step: 5
Training loss: 1.31613028049469
Validation loss: 1.9667539199193318

Epoch: 6| Step: 6
Training loss: 1.9735796451568604
Validation loss: 1.9591456055641174

Epoch: 6| Step: 7
Training loss: 1.943131685256958
Validation loss: 1.9498447974522908

Epoch: 6| Step: 8
Training loss: 2.1081085205078125
Validation loss: 1.9648145039876301

Epoch: 6| Step: 9
Training loss: 2.0722622871398926
Validation loss: 1.9431687792142232

Epoch: 6| Step: 10
Training loss: 1.7704119682312012
Validation loss: 1.9546975096066792

Epoch: 6| Step: 11
Training loss: 2.0163331031799316
Validation loss: 1.944793939590454

Epoch: 6| Step: 12
Training loss: 2.1636109352111816
Validation loss: 1.9523629943529766

Epoch: 6| Step: 13
Training loss: 1.9809823036193848
Validation loss: 1.9565067092577617

Epoch: 21| Step: 0
Training loss: 1.672468662261963
Validation loss: 1.9620392521222432

Epoch: 6| Step: 1
Training loss: 2.43841552734375
Validation loss: 1.9633902311325073

Epoch: 6| Step: 2
Training loss: 2.0859436988830566
Validation loss: 1.96048903465271

Epoch: 6| Step: 3
Training loss: 2.2155277729034424
Validation loss: 1.9671178261439006

Epoch: 6| Step: 4
Training loss: 2.0947556495666504
Validation loss: 1.9808694918950398

Epoch: 6| Step: 5
Training loss: 1.7906036376953125
Validation loss: 1.9776313304901123

Epoch: 6| Step: 6
Training loss: 1.9215420484542847
Validation loss: 1.9786423842112224

Epoch: 6| Step: 7
Training loss: 1.4275305271148682
Validation loss: 1.9879899422327678

Epoch: 6| Step: 8
Training loss: 1.6675257682800293
Validation loss: 1.9901559154192607

Epoch: 6| Step: 9
Training loss: 1.8387181758880615
Validation loss: 1.9781158566474915

Epoch: 6| Step: 10
Training loss: 2.336794376373291
Validation loss: 1.9791826804478962

Epoch: 6| Step: 11
Training loss: 1.7169543504714966
Validation loss: 1.9775007565816243

Epoch: 6| Step: 12
Training loss: 2.47501802444458
Validation loss: 1.97498885790507

Epoch: 6| Step: 13
Training loss: 2.219362735748291
Validation loss: 1.9981017708778381

Epoch: 22| Step: 0
Training loss: 2.1706438064575195
Validation loss: 1.9780452251434326

Epoch: 6| Step: 1
Training loss: 1.5191339254379272
Validation loss: 1.9716382424036663

Epoch: 6| Step: 2
Training loss: 1.7717795372009277
Validation loss: 1.963517924149831

Epoch: 6| Step: 3
Training loss: 1.5150729417800903
Validation loss: 1.9475804169972737

Epoch: 6| Step: 4
Training loss: 2.0899949073791504
Validation loss: 1.9669547478357952

Epoch: 6| Step: 5
Training loss: 2.273420572280884
Validation loss: 1.9678683678309123

Epoch: 6| Step: 6
Training loss: 1.7625902891159058
Validation loss: 1.9593251943588257

Epoch: 6| Step: 7
Training loss: 2.744189977645874
Validation loss: 1.9630357424418132

Epoch: 6| Step: 8
Training loss: 1.658134937286377
Validation loss: 1.9588374694188435

Epoch: 6| Step: 9
Training loss: 1.527397632598877
Validation loss: 1.9565745790799458

Epoch: 6| Step: 10
Training loss: 2.3831796646118164
Validation loss: 1.9610762198766072

Epoch: 6| Step: 11
Training loss: 2.04944109916687
Validation loss: 1.9591148098309834

Epoch: 6| Step: 12
Training loss: 2.1486785411834717
Validation loss: 1.9647743900616963

Epoch: 6| Step: 13
Training loss: 2.036604642868042
Validation loss: 1.974126895268758

Epoch: 23| Step: 0
Training loss: 1.3994016647338867
Validation loss: 1.9668637712796528

Epoch: 6| Step: 1
Training loss: 1.5861594676971436
Validation loss: 1.9647027850151062

Epoch: 6| Step: 2
Training loss: 2.220411777496338
Validation loss: 1.978610873222351

Epoch: 6| Step: 3
Training loss: 2.7426013946533203
Validation loss: 1.960580050945282

Epoch: 6| Step: 4
Training loss: 1.2002856731414795
Validation loss: 1.967454155286153

Epoch: 6| Step: 5
Training loss: 1.8919914960861206
Validation loss: 1.96677162249883

Epoch: 6| Step: 6
Training loss: 2.1063475608825684
Validation loss: 1.9596601128578186

Epoch: 6| Step: 7
Training loss: 1.4681007862091064
Validation loss: 1.9771079023679097

Epoch: 6| Step: 8
Training loss: 2.5078463554382324
Validation loss: 1.9753709435462952

Epoch: 6| Step: 9
Training loss: 1.4500842094421387
Validation loss: 1.9566665887832642

Epoch: 6| Step: 10
Training loss: 2.351285457611084
Validation loss: 1.9495486219724019

Epoch: 6| Step: 11
Training loss: 1.9763951301574707
Validation loss: 1.944161335627238

Epoch: 6| Step: 12
Training loss: 2.6900248527526855
Validation loss: 1.9564743041992188

Epoch: 6| Step: 13
Training loss: 2.0142877101898193
Validation loss: 1.9483278195063274

Epoch: 24| Step: 0
Training loss: 2.3898229598999023
Validation loss: 1.966313640276591

Epoch: 6| Step: 1
Training loss: 1.3478057384490967
Validation loss: 1.968607505162557

Epoch: 6| Step: 2
Training loss: 1.8521521091461182
Validation loss: 1.972772200902303

Epoch: 6| Step: 3
Training loss: 2.163247585296631
Validation loss: 1.9783660769462585

Epoch: 6| Step: 4
Training loss: 1.6718354225158691
Validation loss: 1.9811236262321472

Epoch: 6| Step: 5
Training loss: 1.9873218536376953
Validation loss: 1.9812299807866414

Epoch: 6| Step: 6
Training loss: 2.538813591003418
Validation loss: 1.9950485626856487

Epoch: 6| Step: 7
Training loss: 1.7070565223693848
Validation loss: 2.002790093421936

Epoch: 6| Step: 8
Training loss: 1.832794427871704
Validation loss: 2.0055662790934243

Epoch: 6| Step: 9
Training loss: 2.2672500610351562
Validation loss: 2.0066001613934836

Epoch: 6| Step: 10
Training loss: 1.5623679161071777
Validation loss: 2.0068442821502686

Epoch: 6| Step: 11
Training loss: 2.679832935333252
Validation loss: 1.9927512804667156

Epoch: 6| Step: 12
Training loss: 1.9012911319732666
Validation loss: 1.9749263525009155

Epoch: 6| Step: 13
Training loss: 1.944347620010376
Validation loss: 1.9582471251487732

Epoch: 25| Step: 0
Training loss: 2.2770915031433105
Validation loss: 1.9511874516805012

Epoch: 6| Step: 1
Training loss: 1.9900568723678589
Validation loss: 1.9591316382090251

Epoch: 6| Step: 2
Training loss: 2.1263527870178223
Validation loss: 1.9611403942108154

Epoch: 6| Step: 3
Training loss: 1.6599771976470947
Validation loss: 1.9648183981577556

Epoch: 6| Step: 4
Training loss: 1.7046236991882324
Validation loss: 1.9612908363342285

Epoch: 6| Step: 5
Training loss: 1.4889144897460938
Validation loss: 1.9598803917566936

Epoch: 6| Step: 6
Training loss: 2.091885566711426
Validation loss: 1.961379865805308

Epoch: 6| Step: 7
Training loss: 1.7290911674499512
Validation loss: 1.9627776741981506

Epoch: 6| Step: 8
Training loss: 2.191324472427368
Validation loss: 1.9510769645373027

Epoch: 6| Step: 9
Training loss: 2.203054904937744
Validation loss: 1.951184054215749

Epoch: 6| Step: 10
Training loss: 2.849377155303955
Validation loss: 1.967862864335378

Epoch: 6| Step: 11
Training loss: 1.7953312397003174
Validation loss: 1.960111916065216

Epoch: 6| Step: 12
Training loss: 2.037353277206421
Validation loss: 1.9569321672121684

Epoch: 6| Step: 13
Training loss: 1.7016830444335938
Validation loss: 1.95618603626887

Epoch: 26| Step: 0
Training loss: 2.1670684814453125
Validation loss: 1.9472884337107341

Epoch: 6| Step: 1
Training loss: 1.9395952224731445
Validation loss: 1.9720396995544434

Epoch: 6| Step: 2
Training loss: 1.6628787517547607
Validation loss: 1.9550183216730754

Epoch: 6| Step: 3
Training loss: 1.9325755834579468
Validation loss: 1.9676003058751423

Epoch: 6| Step: 4
Training loss: 1.8375244140625
Validation loss: 1.9629504283269246

Epoch: 6| Step: 5
Training loss: 2.263563632965088
Validation loss: 1.96187029282252

Epoch: 6| Step: 6
Training loss: 1.5310640335083008
Validation loss: 1.9585083723068237

Epoch: 6| Step: 7
Training loss: 1.869636058807373
Validation loss: 1.9687593380610149

Epoch: 6| Step: 8
Training loss: 2.3961141109466553
Validation loss: 1.953585426012675

Epoch: 6| Step: 9
Training loss: 2.1101605892181396
Validation loss: 1.9666975736618042

Epoch: 6| Step: 10
Training loss: 1.5242588520050049
Validation loss: 1.965382953484853

Epoch: 6| Step: 11
Training loss: 1.997322678565979
Validation loss: 1.964342991511027

Epoch: 6| Step: 12
Training loss: 2.0622353553771973
Validation loss: 1.9628734985987346

Epoch: 6| Step: 13
Training loss: 2.2639291286468506
Validation loss: 1.9499908089637756

Epoch: 27| Step: 0
Training loss: 1.7674663066864014
Validation loss: 1.958221395810445

Epoch: 6| Step: 1
Training loss: 2.0120978355407715
Validation loss: 1.9617971777915955

Epoch: 6| Step: 2
Training loss: 1.6156835556030273
Validation loss: 1.96201890707016

Epoch: 6| Step: 3
Training loss: 1.6995644569396973
Validation loss: 1.9589355786641438

Epoch: 6| Step: 4
Training loss: 2.4028372764587402
Validation loss: 1.9726398785909016

Epoch: 6| Step: 5
Training loss: 2.2955162525177
Validation loss: 1.967680295308431

Epoch: 6| Step: 6
Training loss: 1.6237525939941406
Validation loss: 1.976349135239919

Epoch: 6| Step: 7
Training loss: 2.476907968521118
Validation loss: 1.9811131556828816

Epoch: 6| Step: 8
Training loss: 1.8215670585632324
Validation loss: 1.9780407349268596

Epoch: 6| Step: 9
Training loss: 2.0140604972839355
Validation loss: 1.9604735175768535

Epoch: 6| Step: 10
Training loss: 2.0492446422576904
Validation loss: 1.9742695689201355

Epoch: 6| Step: 11
Training loss: 2.04412579536438
Validation loss: 1.9530157645543416

Epoch: 6| Step: 12
Training loss: 1.403722882270813
Validation loss: 1.967596709728241

Epoch: 6| Step: 13
Training loss: 2.2650442123413086
Validation loss: 1.9812976916631062

Epoch: 28| Step: 0
Training loss: 1.4240939617156982
Validation loss: 1.9511260986328125

Epoch: 6| Step: 1
Training loss: 1.6727898120880127
Validation loss: 1.9579725861549377

Epoch: 6| Step: 2
Training loss: 2.362609386444092
Validation loss: 1.9661749005317688

Epoch: 6| Step: 3
Training loss: 1.6331608295440674
Validation loss: 1.9649264415105183

Epoch: 6| Step: 4
Training loss: 1.6632016897201538
Validation loss: 1.9480247497558594

Epoch: 6| Step: 5
Training loss: 2.181536912918091
Validation loss: 1.943353792031606

Epoch: 6| Step: 6
Training loss: 1.7271747589111328
Validation loss: 1.9570921262105305

Epoch: 6| Step: 7
Training loss: 2.1269123554229736
Validation loss: 1.965216338634491

Epoch: 6| Step: 8
Training loss: 2.3516175746917725
Validation loss: 1.9690702358881633

Epoch: 6| Step: 9
Training loss: 1.8074734210968018
Validation loss: 1.949531575043996

Epoch: 6| Step: 10
Training loss: 1.9864299297332764
Validation loss: 1.9552379846572876

Epoch: 6| Step: 11
Training loss: 2.212611198425293
Validation loss: 1.9620864788691204

Epoch: 6| Step: 12
Training loss: 1.8419110774993896
Validation loss: 1.948696235815684

Epoch: 6| Step: 13
Training loss: 2.352970600128174
Validation loss: 1.955849329630534

Epoch: 29| Step: 0
Training loss: 1.6090617179870605
Validation loss: 1.9530222018559773

Epoch: 6| Step: 1
Training loss: 1.6483936309814453
Validation loss: 1.9537696242332458

Epoch: 6| Step: 2
Training loss: 1.6621899604797363
Validation loss: 1.9612855315208435

Epoch: 6| Step: 3
Training loss: 1.7898415327072144
Validation loss: 1.944307029247284

Epoch: 6| Step: 4
Training loss: 1.9007389545440674
Validation loss: 1.9504730304082234

Epoch: 6| Step: 5
Training loss: 1.9524632692337036
Validation loss: 1.9491509000460308

Epoch: 6| Step: 6
Training loss: 1.8477420806884766
Validation loss: 1.9526864091555278

Epoch: 6| Step: 7
Training loss: 1.839914321899414
Validation loss: 1.967525800069173

Epoch: 6| Step: 8
Training loss: 2.319976329803467
Validation loss: 1.9460417032241821

Epoch: 6| Step: 9
Training loss: 1.9586873054504395
Validation loss: 1.9521678884824116

Epoch: 6| Step: 10
Training loss: 1.779416799545288
Validation loss: 1.9531297882397969

Epoch: 6| Step: 11
Training loss: 2.135932207107544
Validation loss: 1.9521913329760234

Epoch: 6| Step: 12
Training loss: 2.8878936767578125
Validation loss: 1.9680031339327495

Epoch: 6| Step: 13
Training loss: 1.978593111038208
Validation loss: 1.9600757360458374

Epoch: 30| Step: 0
Training loss: 1.4896230697631836
Validation loss: 1.962814708550771

Epoch: 6| Step: 1
Training loss: 2.043820858001709
Validation loss: 1.9517536759376526

Epoch: 6| Step: 2
Training loss: 2.048640489578247
Validation loss: 1.960033694903056

Epoch: 6| Step: 3
Training loss: 2.524916172027588
Validation loss: 1.9580999215443928

Epoch: 6| Step: 4
Training loss: 1.6294641494750977
Validation loss: 1.9586734175682068

Epoch: 6| Step: 5
Training loss: 2.4459612369537354
Validation loss: 1.95203830798467

Epoch: 6| Step: 6
Training loss: 1.9860926866531372
Validation loss: 1.9559366901715596

Epoch: 6| Step: 7
Training loss: 1.8402713537216187
Validation loss: 1.9438174962997437

Epoch: 6| Step: 8
Training loss: 2.363395929336548
Validation loss: 1.9522482951482136

Epoch: 6| Step: 9
Training loss: 1.7678872346878052
Validation loss: 1.9503921270370483

Epoch: 6| Step: 10
Training loss: 2.275007724761963
Validation loss: 1.9563783208529155

Epoch: 6| Step: 11
Training loss: 1.2092790603637695
Validation loss: 1.9676060477892559

Epoch: 6| Step: 12
Training loss: 1.7166475057601929
Validation loss: 1.9571706453959148

Epoch: 6| Step: 13
Training loss: 1.886751651763916
Validation loss: 1.947453459103902

Epoch: 31| Step: 0
Training loss: 1.7659701108932495
Validation loss: 1.958881934483846

Epoch: 6| Step: 1
Training loss: 1.746374487876892
Validation loss: 1.9672550956408184

Epoch: 6| Step: 2
Training loss: 1.749182105064392
Validation loss: 1.9824984669685364

Epoch: 6| Step: 3
Training loss: 1.9182112216949463
Validation loss: 1.9809114535649617

Epoch: 6| Step: 4
Training loss: 1.4471038579940796
Validation loss: 1.973474144935608

Epoch: 6| Step: 5
Training loss: 2.179476499557495
Validation loss: 1.9725119471549988

Epoch: 6| Step: 6
Training loss: 2.6065175533294678
Validation loss: 1.961383839448293

Epoch: 6| Step: 7
Training loss: 2.273728370666504
Validation loss: 1.9618907769521077

Epoch: 6| Step: 8
Training loss: 2.0591912269592285
Validation loss: 1.9505337476730347

Epoch: 6| Step: 9
Training loss: 2.025050640106201
Validation loss: 1.9574334422747295

Epoch: 6| Step: 10
Training loss: 1.9389599561691284
Validation loss: 1.9536254008611043

Epoch: 6| Step: 11
Training loss: 1.7744243144989014
Validation loss: 1.9587205648422241

Epoch: 6| Step: 12
Training loss: 1.7891461849212646
Validation loss: 1.9642816384633381

Epoch: 6| Step: 13
Training loss: 2.0056214332580566
Validation loss: 1.9672926863034566

Epoch: 32| Step: 0
Training loss: 2.6748204231262207
Validation loss: 1.9585707187652588

Epoch: 6| Step: 1
Training loss: 1.9056878089904785
Validation loss: 1.9603984157244365

Epoch: 6| Step: 2
Training loss: 1.6599705219268799
Validation loss: 1.9409185647964478

Epoch: 6| Step: 3
Training loss: 1.8381322622299194
Validation loss: 1.9416827758153279

Epoch: 6| Step: 4
Training loss: 1.8591015338897705
Validation loss: 1.9525106350580852

Epoch: 6| Step: 5
Training loss: 1.5190176963806152
Validation loss: 1.940423051516215

Epoch: 6| Step: 6
Training loss: 1.3231984376907349
Validation loss: 1.9535437027613323

Epoch: 6| Step: 7
Training loss: 1.6351252794265747
Validation loss: 1.9346479177474976

Epoch: 6| Step: 8
Training loss: 2.385897636413574
Validation loss: 1.9500362674395244

Epoch: 6| Step: 9
Training loss: 2.094724655151367
Validation loss: 1.9647422432899475

Epoch: 6| Step: 10
Training loss: 2.6170334815979004
Validation loss: 1.9552675286928813

Epoch: 6| Step: 11
Training loss: 1.3687541484832764
Validation loss: 1.95970485607783

Epoch: 6| Step: 12
Training loss: 2.1906752586364746
Validation loss: 1.9701760411262512

Epoch: 6| Step: 13
Training loss: 2.0930323600769043
Validation loss: 1.9903544982274373

Epoch: 33| Step: 0
Training loss: 1.4899003505706787
Validation loss: 1.9807186325391133

Epoch: 6| Step: 1
Training loss: 1.9735645055770874
Validation loss: 1.951043466726939

Epoch: 6| Step: 2
Training loss: 1.772539734840393
Validation loss: 1.9845804174741108

Epoch: 6| Step: 3
Training loss: 1.607069492340088
Validation loss: 1.9605974952379863

Epoch: 6| Step: 4
Training loss: 2.505734443664551
Validation loss: 1.955691635608673

Epoch: 6| Step: 5
Training loss: 1.6740628480911255
Validation loss: 1.9505045413970947

Epoch: 6| Step: 6
Training loss: 1.5979571342468262
Validation loss: 1.9508651892344158

Epoch: 6| Step: 7
Training loss: 2.2659912109375
Validation loss: 1.9617457191149394

Epoch: 6| Step: 8
Training loss: 1.5136865377426147
Validation loss: 1.964136819044749

Epoch: 6| Step: 9
Training loss: 2.2028768062591553
Validation loss: 1.95661195119222

Epoch: 6| Step: 10
Training loss: 2.3885245323181152
Validation loss: 1.95796138048172

Epoch: 6| Step: 11
Training loss: 2.2081832885742188
Validation loss: 1.9494341015815735

Epoch: 6| Step: 12
Training loss: 1.974643349647522
Validation loss: 1.9563101728757222

Epoch: 6| Step: 13
Training loss: 1.7584199905395508
Validation loss: 1.9421064654986064

Epoch: 34| Step: 0
Training loss: 1.5474286079406738
Validation loss: 1.9427395462989807

Epoch: 6| Step: 1
Training loss: 2.032615900039673
Validation loss: 1.9614800413449605

Epoch: 6| Step: 2
Training loss: 1.7677468061447144
Validation loss: 1.9431023001670837

Epoch: 6| Step: 3
Training loss: 1.7818903923034668
Validation loss: 1.9563120603561401

Epoch: 6| Step: 4
Training loss: 2.4692959785461426
Validation loss: 1.9445204536120098

Epoch: 6| Step: 5
Training loss: 1.6376588344573975
Validation loss: 1.9627352356910706

Epoch: 6| Step: 6
Training loss: 2.0092175006866455
Validation loss: 1.966020445028941

Epoch: 6| Step: 7
Training loss: 2.2650327682495117
Validation loss: 1.974974234898885

Epoch: 6| Step: 8
Training loss: 1.9464468955993652
Validation loss: 1.987534503142039

Epoch: 6| Step: 9
Training loss: 1.6152384281158447
Validation loss: 1.9759457906087239

Epoch: 6| Step: 10
Training loss: 2.04166579246521
Validation loss: 1.997315247853597

Epoch: 6| Step: 11
Training loss: 2.183727979660034
Validation loss: 1.9748623768488567

Epoch: 6| Step: 12
Training loss: 1.5590236186981201
Validation loss: 1.957422415415446

Epoch: 6| Step: 13
Training loss: 2.5134453773498535
Validation loss: 1.9651264945665996

Epoch: 35| Step: 0
Training loss: 1.8170928955078125
Validation loss: 1.9533933798472087

Epoch: 6| Step: 1
Training loss: 1.3180925846099854
Validation loss: 1.9541732668876648

Epoch: 6| Step: 2
Training loss: 2.3413991928100586
Validation loss: 1.94837619860967

Epoch: 6| Step: 3
Training loss: 2.033506393432617
Validation loss: 1.9689984520276387

Epoch: 6| Step: 4
Training loss: 2.1384387016296387
Validation loss: 1.959921956062317

Epoch: 6| Step: 5
Training loss: 2.139209270477295
Validation loss: 1.9488144914309184

Epoch: 6| Step: 6
Training loss: 1.7139817476272583
Validation loss: 1.9447699189186096

Epoch: 6| Step: 7
Training loss: 1.6141796112060547
Validation loss: 1.9563360611597698

Epoch: 6| Step: 8
Training loss: 1.8690862655639648
Validation loss: 1.949371834595998

Epoch: 6| Step: 9
Training loss: 2.2719411849975586
Validation loss: 1.9593824744224548

Epoch: 6| Step: 10
Training loss: 1.6601990461349487
Validation loss: 1.9569031794865925

Epoch: 6| Step: 11
Training loss: 1.8288822174072266
Validation loss: 1.9571742018063862

Epoch: 6| Step: 12
Training loss: 2.0614728927612305
Validation loss: 1.948830823103587

Epoch: 6| Step: 13
Training loss: 2.4445652961730957
Validation loss: 1.9386619130770366

Epoch: 36| Step: 0
Training loss: 1.4129289388656616
Validation loss: 1.9499994317690532

Epoch: 6| Step: 1
Training loss: 2.4035348892211914
Validation loss: 1.9594186743100483

Epoch: 6| Step: 2
Training loss: 2.086812734603882
Validation loss: 1.977380136648814

Epoch: 6| Step: 3
Training loss: 2.6463310718536377
Validation loss: 1.9772952596346538

Epoch: 6| Step: 4
Training loss: 1.868886947631836
Validation loss: 1.986167887846629

Epoch: 6| Step: 5
Training loss: 1.6116431951522827
Validation loss: 2.0009225606918335

Epoch: 6| Step: 6
Training loss: 2.2075846195220947
Validation loss: 2.0078315138816833

Epoch: 6| Step: 7
Training loss: 1.4939916133880615
Validation loss: 1.9935983816782634

Epoch: 6| Step: 8
Training loss: 1.9595310688018799
Validation loss: 2.0075231790542603

Epoch: 6| Step: 9
Training loss: 1.9019966125488281
Validation loss: 1.9868138432502747

Epoch: 6| Step: 10
Training loss: 1.767724871635437
Validation loss: 1.9911327163378398

Epoch: 6| Step: 11
Training loss: 2.054637908935547
Validation loss: 1.963646908601125

Epoch: 6| Step: 12
Training loss: 1.8262158632278442
Validation loss: 1.9731018940607707

Epoch: 6| Step: 13
Training loss: 1.8418328762054443
Validation loss: 1.9675347407658894

Epoch: 37| Step: 0
Training loss: 2.003840446472168
Validation loss: 1.9420712788899739

Epoch: 6| Step: 1
Training loss: 1.87123703956604
Validation loss: 1.9518134991327922

Epoch: 6| Step: 2
Training loss: 1.925938367843628
Validation loss: 1.9548578063646953

Epoch: 6| Step: 3
Training loss: 2.0550851821899414
Validation loss: 1.9476293921470642

Epoch: 6| Step: 4
Training loss: 1.9379627704620361
Validation loss: 1.9502716859181721

Epoch: 6| Step: 5
Training loss: 2.1409292221069336
Validation loss: 1.9489856561024983

Epoch: 6| Step: 6
Training loss: 1.8858203887939453
Validation loss: 1.9486859440803528

Epoch: 6| Step: 7
Training loss: 1.108988881111145
Validation loss: 1.9300488233566284

Epoch: 6| Step: 8
Training loss: 1.8233329057693481
Validation loss: 1.955411970615387

Epoch: 6| Step: 9
Training loss: 2.3436009883880615
Validation loss: 1.9432958960533142

Epoch: 6| Step: 10
Training loss: 2.557137966156006
Validation loss: 1.9542073408762615

Epoch: 6| Step: 11
Training loss: 1.5273544788360596
Validation loss: 1.9500555396080017

Epoch: 6| Step: 12
Training loss: 1.5194551944732666
Validation loss: 1.9458921949068706

Epoch: 6| Step: 13
Training loss: 2.1485254764556885
Validation loss: 1.9347411592801411

Epoch: 38| Step: 0
Training loss: 1.9394724369049072
Validation loss: 1.9562246600786846

Epoch: 6| Step: 1
Training loss: 2.0310263633728027
Validation loss: 1.949060062567393

Epoch: 6| Step: 2
Training loss: 1.5253782272338867
Validation loss: 1.9476469159126282

Epoch: 6| Step: 3
Training loss: 1.8078001737594604
Validation loss: 1.949373443921407

Epoch: 6| Step: 4
Training loss: 2.063666820526123
Validation loss: 1.9531936446825664

Epoch: 6| Step: 5
Training loss: 1.835740327835083
Validation loss: 1.9459381302197774

Epoch: 6| Step: 6
Training loss: 1.7953965663909912
Validation loss: 1.9622753461201985

Epoch: 6| Step: 7
Training loss: 2.2630739212036133
Validation loss: 1.9664101004600525

Epoch: 6| Step: 8
Training loss: 1.513512134552002
Validation loss: 1.9685086210568745

Epoch: 6| Step: 9
Training loss: 1.7842137813568115
Validation loss: 1.955337127049764

Epoch: 6| Step: 10
Training loss: 1.9368516206741333
Validation loss: 1.9281102418899536

Epoch: 6| Step: 11
Training loss: 1.7969114780426025
Validation loss: 1.936212380727132

Epoch: 6| Step: 12
Training loss: 2.377629041671753
Validation loss: 1.953776776790619

Epoch: 6| Step: 13
Training loss: 1.9489357471466064
Validation loss: 1.940131425857544

Epoch: 39| Step: 0
Training loss: 1.8520179986953735
Validation loss: 1.967867414156596

Epoch: 6| Step: 1
Training loss: 2.0407614707946777
Validation loss: 1.9675244291623433

Epoch: 6| Step: 2
Training loss: 2.2811927795410156
Validation loss: 1.9525476892789204

Epoch: 6| Step: 3
Training loss: 1.5163958072662354
Validation loss: 1.9732034802436829

Epoch: 6| Step: 4
Training loss: 2.1295270919799805
Validation loss: 1.968715528647105

Epoch: 6| Step: 5
Training loss: 1.6661944389343262
Validation loss: 1.9781825542449951

Epoch: 6| Step: 6
Training loss: 1.74338960647583
Validation loss: 1.9562209844589233

Epoch: 6| Step: 7
Training loss: 1.4585914611816406
Validation loss: 1.9626426498095195

Epoch: 6| Step: 8
Training loss: 1.5447689294815063
Validation loss: 1.961342493693034

Epoch: 6| Step: 9
Training loss: 2.0194613933563232
Validation loss: 1.9508376717567444

Epoch: 6| Step: 10
Training loss: 2.0224781036376953
Validation loss: 1.977782408396403

Epoch: 6| Step: 11
Training loss: 1.6337649822235107
Validation loss: 1.960456669330597

Epoch: 6| Step: 12
Training loss: 2.5182266235351562
Validation loss: 1.9586786031723022

Epoch: 6| Step: 13
Training loss: 1.9812064170837402
Validation loss: 1.9431941509246826

Epoch: 40| Step: 0
Training loss: 1.9122411012649536
Validation loss: 1.9365771611531575

Epoch: 6| Step: 1
Training loss: 1.659936547279358
Validation loss: 1.949882556994756

Epoch: 6| Step: 2
Training loss: 1.5726110935211182
Validation loss: 1.9474323391914368

Epoch: 6| Step: 3
Training loss: 2.4705893993377686
Validation loss: 1.9371483723322551

Epoch: 6| Step: 4
Training loss: 1.518943428993225
Validation loss: 1.953331212202708

Epoch: 6| Step: 5
Training loss: 2.3069911003112793
Validation loss: 1.9587297042210896

Epoch: 6| Step: 6
Training loss: 1.9871066808700562
Validation loss: 1.9427685737609863

Epoch: 6| Step: 7
Training loss: 1.3044531345367432
Validation loss: 1.9424138069152832

Epoch: 6| Step: 8
Training loss: 2.1856260299682617
Validation loss: 1.9577386379241943

Epoch: 6| Step: 9
Training loss: 1.8558292388916016
Validation loss: 1.9548464020093281

Epoch: 6| Step: 10
Training loss: 2.2069787979125977
Validation loss: 1.948043445746104

Epoch: 6| Step: 11
Training loss: 2.1129252910614014
Validation loss: 1.9442711075146992

Epoch: 6| Step: 12
Training loss: 1.6892459392547607
Validation loss: 1.9465637008349101

Epoch: 6| Step: 13
Training loss: 1.7313480377197266
Validation loss: 1.9595508972803752

Epoch: 41| Step: 0
Training loss: 1.6350703239440918
Validation loss: 1.9683553377787273

Epoch: 6| Step: 1
Training loss: 1.8417705297470093
Validation loss: 1.981037159760793

Epoch: 6| Step: 2
Training loss: 1.765351414680481
Validation loss: 1.9687303304672241

Epoch: 6| Step: 3
Training loss: 1.4088035821914673
Validation loss: 1.9577273925145466

Epoch: 6| Step: 4
Training loss: 1.5123502016067505
Validation loss: 1.9784893095493317

Epoch: 6| Step: 5
Training loss: 2.1691861152648926
Validation loss: 1.9987926483154297

Epoch: 6| Step: 6
Training loss: 1.947148084640503
Validation loss: 1.9770262042681377

Epoch: 6| Step: 7
Training loss: 2.2352893352508545
Validation loss: 1.980552037556966

Epoch: 6| Step: 8
Training loss: 2.690314292907715
Validation loss: 1.9365827639897664

Epoch: 6| Step: 9
Training loss: 1.5439293384552002
Validation loss: 1.9662425518035889

Epoch: 6| Step: 10
Training loss: 2.317049980163574
Validation loss: 1.9550708929697673

Epoch: 6| Step: 11
Training loss: 2.0701303482055664
Validation loss: 1.9518318176269531

Epoch: 6| Step: 12
Training loss: 1.7515625953674316
Validation loss: 1.926987111568451

Epoch: 6| Step: 13
Training loss: 1.7838035821914673
Validation loss: 1.940673589706421

Epoch: 42| Step: 0
Training loss: 1.955924153327942
Validation loss: 1.9410193959871929

Epoch: 6| Step: 1
Training loss: 2.0948307514190674
Validation loss: 1.936076581478119

Epoch: 6| Step: 2
Training loss: 2.235232353210449
Validation loss: 1.939129074414571

Epoch: 6| Step: 3
Training loss: 1.420788288116455
Validation loss: 1.9403454462687175

Epoch: 6| Step: 4
Training loss: 2.0907554626464844
Validation loss: 1.9394798874855042

Epoch: 6| Step: 5
Training loss: 1.3432374000549316
Validation loss: 1.9306410352389018

Epoch: 6| Step: 6
Training loss: 1.8881847858428955
Validation loss: 1.9557527899742126

Epoch: 6| Step: 7
Training loss: 2.151796817779541
Validation loss: 1.9356218973795574

Epoch: 6| Step: 8
Training loss: 1.985211730003357
Validation loss: 1.9462477763493855

Epoch: 6| Step: 9
Training loss: 1.338745355606079
Validation loss: 1.9429466525713603

Epoch: 6| Step: 10
Training loss: 2.3134331703186035
Validation loss: 1.970698356628418

Epoch: 6| Step: 11
Training loss: 2.0974457263946533
Validation loss: 1.9632289012273152

Epoch: 6| Step: 12
Training loss: 1.9675688743591309
Validation loss: 1.954215904076894

Epoch: 6| Step: 13
Training loss: 1.5346901416778564
Validation loss: 1.9679657022158306

Epoch: 43| Step: 0
Training loss: 2.1108436584472656
Validation loss: 1.9899988373120625

Epoch: 6| Step: 1
Training loss: 1.4050445556640625
Validation loss: 1.97419406970342

Epoch: 6| Step: 2
Training loss: 1.9901057481765747
Validation loss: 1.9833197395006816

Epoch: 6| Step: 3
Training loss: 1.6269443035125732
Validation loss: 1.9783581296602886

Epoch: 6| Step: 4
Training loss: 1.2468210458755493
Validation loss: 1.9790388147036235

Epoch: 6| Step: 5
Training loss: 1.9316682815551758
Validation loss: 1.9692503809928894

Epoch: 6| Step: 6
Training loss: 2.1721396446228027
Validation loss: 1.9569034973780315

Epoch: 6| Step: 7
Training loss: 1.5713450908660889
Validation loss: 1.9405242999394734

Epoch: 6| Step: 8
Training loss: 1.7457168102264404
Validation loss: 1.9442718029022217

Epoch: 6| Step: 9
Training loss: 1.9645495414733887
Validation loss: 1.949153184890747

Epoch: 6| Step: 10
Training loss: 2.33282470703125
Validation loss: 1.9516056974728901

Epoch: 6| Step: 11
Training loss: 1.7193504571914673
Validation loss: 1.9610145092010498

Epoch: 6| Step: 12
Training loss: 2.170048713684082
Validation loss: 1.956142544746399

Epoch: 6| Step: 13
Training loss: 2.108764171600342
Validation loss: 1.9393305381139119

Epoch: 44| Step: 0
Training loss: 1.5576626062393188
Validation loss: 1.9456700881322224

Epoch: 6| Step: 1
Training loss: 2.4308664798736572
Validation loss: 1.938934286435445

Epoch: 6| Step: 2
Training loss: 1.855776309967041
Validation loss: 1.9525538682937622

Epoch: 6| Step: 3
Training loss: 1.9791665077209473
Validation loss: 1.9636227091153462

Epoch: 6| Step: 4
Training loss: 2.054650068283081
Validation loss: 1.9428279399871826

Epoch: 6| Step: 5
Training loss: 1.8228743076324463
Validation loss: 1.9543416897455852

Epoch: 6| Step: 6
Training loss: 2.259688377380371
Validation loss: 1.946963946024577

Epoch: 6| Step: 7
Training loss: 1.6775712966918945
Validation loss: 1.9580382704734802

Epoch: 6| Step: 8
Training loss: 2.3080286979675293
Validation loss: 1.9486591418584187

Epoch: 6| Step: 9
Training loss: 1.483295202255249
Validation loss: 1.9395313660303752

Epoch: 6| Step: 10
Training loss: 1.379370927810669
Validation loss: 1.9648921688397725

Epoch: 6| Step: 11
Training loss: 1.917598009109497
Validation loss: 1.9529207944869995

Epoch: 6| Step: 12
Training loss: 2.029021978378296
Validation loss: 1.9596967101097107

Epoch: 6| Step: 13
Training loss: 1.3370118141174316
Validation loss: 1.9577550689379375

Epoch: 45| Step: 0
Training loss: 1.9355345964431763
Validation loss: 1.934911807378133

Epoch: 6| Step: 1
Training loss: 2.01796555519104
Validation loss: 1.9805138508478801

Epoch: 6| Step: 2
Training loss: 2.466310501098633
Validation loss: 1.9817726016044617

Epoch: 6| Step: 3
Training loss: 2.145228862762451
Validation loss: 2.00421412785848

Epoch: 6| Step: 4
Training loss: 1.173436164855957
Validation loss: 1.9742135405540466

Epoch: 6| Step: 5
Training loss: 1.6395018100738525
Validation loss: 1.9694984356562297

Epoch: 6| Step: 6
Training loss: 2.611313819885254
Validation loss: 1.984957993030548

Epoch: 6| Step: 7
Training loss: 1.4195032119750977
Validation loss: 1.98975270986557

Epoch: 6| Step: 8
Training loss: 2.283383846282959
Validation loss: 1.9940434296925862

Epoch: 6| Step: 9
Training loss: 1.478299856185913
Validation loss: 1.9632800022761028

Epoch: 6| Step: 10
Training loss: 1.3829295635223389
Validation loss: 1.9598341584205627

Epoch: 6| Step: 11
Training loss: 2.068354845046997
Validation loss: 1.9650040864944458

Epoch: 6| Step: 12
Training loss: 1.7488534450531006
Validation loss: 1.975182036558787

Epoch: 6| Step: 13
Training loss: 1.8677551746368408
Validation loss: 1.9556046923001607

Epoch: 46| Step: 0
Training loss: 1.8749350309371948
Validation loss: 1.9296374320983887

Epoch: 6| Step: 1
Training loss: 2.115466594696045
Validation loss: 1.9481499195098877

Epoch: 6| Step: 2
Training loss: 1.488543152809143
Validation loss: 1.9449024597803752

Epoch: 6| Step: 3
Training loss: 1.6375632286071777
Validation loss: 1.9368821382522583

Epoch: 6| Step: 4
Training loss: 2.003049612045288
Validation loss: 1.9567049741744995

Epoch: 6| Step: 5
Training loss: 2.0039801597595215
Validation loss: 1.9493983387947083

Epoch: 6| Step: 6
Training loss: 1.868318796157837
Validation loss: 1.9543087482452393

Epoch: 6| Step: 7
Training loss: 1.907432198524475
Validation loss: 1.939263919989268

Epoch: 6| Step: 8
Training loss: 1.5689992904663086
Validation loss: 1.9395034909248352

Epoch: 6| Step: 9
Training loss: 1.7959572076797485
Validation loss: 1.9456607103347778

Epoch: 6| Step: 10
Training loss: 1.4895063638687134
Validation loss: 1.9303986430168152

Epoch: 6| Step: 11
Training loss: 2.143913745880127
Validation loss: 1.95866455634435

Epoch: 6| Step: 12
Training loss: 1.8430511951446533
Validation loss: 1.9643937746683757

Epoch: 6| Step: 13
Training loss: 2.0798497200012207
Validation loss: 2.000096023082733

Epoch: 47| Step: 0
Training loss: 1.7427384853363037
Validation loss: 2.0023282965024314

Epoch: 6| Step: 1
Training loss: 2.011059284210205
Validation loss: 2.017323990662893

Epoch: 6| Step: 2
Training loss: 1.865799903869629
Validation loss: 2.0292674899101257

Epoch: 6| Step: 3
Training loss: 1.9690425395965576
Validation loss: 2.04919962088267

Epoch: 6| Step: 4
Training loss: 2.1756937503814697
Validation loss: 2.044651210308075

Epoch: 6| Step: 5
Training loss: 1.2035424709320068
Validation loss: 2.019825061162313

Epoch: 6| Step: 6
Training loss: 1.859792947769165
Validation loss: 1.9894502758979797

Epoch: 6| Step: 7
Training loss: 2.056619167327881
Validation loss: 1.98580002784729

Epoch: 6| Step: 8
Training loss: 2.310316562652588
Validation loss: 1.9766605099042256

Epoch: 6| Step: 9
Training loss: 2.0836524963378906
Validation loss: 1.95984947681427

Epoch: 6| Step: 10
Training loss: 1.7622292041778564
Validation loss: 1.9513969818751018

Epoch: 6| Step: 11
Training loss: 1.3468806743621826
Validation loss: 1.9526518980662029

Epoch: 6| Step: 12
Training loss: 2.0667927265167236
Validation loss: 1.9586367805798848

Epoch: 6| Step: 13
Training loss: 1.688015103340149
Validation loss: 1.9427015980084736

Epoch: 48| Step: 0
Training loss: 1.4331403970718384
Validation loss: 1.9443325002988179

Epoch: 6| Step: 1
Training loss: 1.67242431640625
Validation loss: 1.9465425610542297

Epoch: 6| Step: 2
Training loss: 1.4921088218688965
Validation loss: 1.9501891533533733

Epoch: 6| Step: 3
Training loss: 1.5978889465332031
Validation loss: 1.9707277218500774

Epoch: 6| Step: 4
Training loss: 1.7402387857437134
Validation loss: 1.979368011156718

Epoch: 6| Step: 5
Training loss: 1.3211616277694702
Validation loss: 1.9591207305590312

Epoch: 6| Step: 6
Training loss: 2.435919761657715
Validation loss: 1.9845407803853352

Epoch: 6| Step: 7
Training loss: 2.7180004119873047
Validation loss: 1.981619397799174

Epoch: 6| Step: 8
Training loss: 1.5549061298370361
Validation loss: 1.994013786315918

Epoch: 6| Step: 9
Training loss: 2.0721068382263184
Validation loss: 1.9808661341667175

Epoch: 6| Step: 10
Training loss: 2.289478302001953
Validation loss: 1.9864608248074849

Epoch: 6| Step: 11
Training loss: 1.7021005153656006
Validation loss: 1.9787135521570842

Epoch: 6| Step: 12
Training loss: 2.007845878601074
Validation loss: 1.97096053759257

Epoch: 6| Step: 13
Training loss: 1.8138078451156616
Validation loss: 1.9393848776817322

Epoch: 49| Step: 0
Training loss: 2.514632225036621
Validation loss: 1.9388859272003174

Epoch: 6| Step: 1
Training loss: 2.0877866744995117
Validation loss: 1.9584665099779766

Epoch: 6| Step: 2
Training loss: 2.139633893966675
Validation loss: 1.9470909039179485

Epoch: 6| Step: 3
Training loss: 1.4640763998031616
Validation loss: 1.9576239784558613

Epoch: 6| Step: 4
Training loss: 2.1523804664611816
Validation loss: 1.931151549021403

Epoch: 6| Step: 5
Training loss: 1.8816015720367432
Validation loss: 1.9578991333643596

Epoch: 6| Step: 6
Training loss: 1.900253176689148
Validation loss: 1.9319980939229329

Epoch: 6| Step: 7
Training loss: 1.4447662830352783
Validation loss: 1.9413014849026997

Epoch: 6| Step: 8
Training loss: 2.151988983154297
Validation loss: 1.9447895487149556

Epoch: 6| Step: 9
Training loss: 1.3071200847625732
Validation loss: 1.942205289999644

Epoch: 6| Step: 10
Training loss: 1.4750480651855469
Validation loss: 1.9601728320121765

Epoch: 6| Step: 11
Training loss: 1.7694271802902222
Validation loss: 1.9623295664787292

Epoch: 6| Step: 12
Training loss: 1.849628210067749
Validation loss: 1.9509428938229878

Epoch: 6| Step: 13
Training loss: 1.480609655380249
Validation loss: 1.958998401959737

Epoch: 50| Step: 0
Training loss: 1.0374763011932373
Validation loss: 1.967374563217163

Epoch: 6| Step: 1
Training loss: 1.8039593696594238
Validation loss: 1.9607747197151184

Epoch: 6| Step: 2
Training loss: 1.9708291292190552
Validation loss: 2.0096223950386047

Epoch: 6| Step: 3
Training loss: 2.323422908782959
Validation loss: 1.9830408294995625

Epoch: 6| Step: 4
Training loss: 1.6066360473632812
Validation loss: 2.0050758918126426

Epoch: 6| Step: 5
Training loss: 1.8491675853729248
Validation loss: 1.9907982349395752

Epoch: 6| Step: 6
Training loss: 2.2194581031799316
Validation loss: 1.9598532915115356

Epoch: 6| Step: 7
Training loss: 1.856441617012024
Validation loss: 1.989993651707967

Epoch: 6| Step: 8
Training loss: 2.2245092391967773
Validation loss: 1.9726887941360474

Epoch: 6| Step: 9
Training loss: 1.4428822994232178
Validation loss: 1.9642121990521748

Epoch: 6| Step: 10
Training loss: 1.3408281803131104
Validation loss: 1.9554418921470642

Epoch: 6| Step: 11
Training loss: 1.9578198194503784
Validation loss: 1.9602493246396382

Epoch: 6| Step: 12
Training loss: 1.9358181953430176
Validation loss: 1.9795621832211812

Epoch: 6| Step: 13
Training loss: 1.7804503440856934
Validation loss: 1.9535577098528545

Epoch: 51| Step: 0
Training loss: 1.1744227409362793
Validation loss: 1.9812246759732564

Epoch: 6| Step: 1
Training loss: 1.7042897939682007
Validation loss: 1.9544822573661804

Epoch: 6| Step: 2
Training loss: 1.4717800617218018
Validation loss: 1.949958066145579

Epoch: 6| Step: 3
Training loss: 1.9037437438964844
Validation loss: 1.9408937493960063

Epoch: 6| Step: 4
Training loss: 1.960280418395996
Validation loss: 1.9665642976760864

Epoch: 6| Step: 5
Training loss: 2.7483184337615967
Validation loss: 1.9358327388763428

Epoch: 6| Step: 6
Training loss: 1.859449863433838
Validation loss: 1.9616669217745464

Epoch: 6| Step: 7
Training loss: 1.398514986038208
Validation loss: 1.9363480806350708

Epoch: 6| Step: 8
Training loss: 1.5349171161651611
Validation loss: 1.9675735632578533

Epoch: 6| Step: 9
Training loss: 1.9981266260147095
Validation loss: 1.9684378902117412

Epoch: 6| Step: 10
Training loss: 2.508151054382324
Validation loss: 1.9725028276443481

Epoch: 6| Step: 11
Training loss: 1.8710131645202637
Validation loss: 1.986957887808482

Epoch: 6| Step: 12
Training loss: 1.6551778316497803
Validation loss: 1.9664788842201233

Epoch: 6| Step: 13
Training loss: 1.6181659698486328
Validation loss: 2.007526695728302

Epoch: 52| Step: 0
Training loss: 2.0499002933502197
Validation loss: 1.9959400494893391

Epoch: 6| Step: 1
Training loss: 1.4463603496551514
Validation loss: 1.9777113397916157

Epoch: 6| Step: 2
Training loss: 2.257809638977051
Validation loss: 1.9925954540570576

Epoch: 6| Step: 3
Training loss: 1.7008061408996582
Validation loss: 2.0128084818522134

Epoch: 6| Step: 4
Training loss: 1.8150590658187866
Validation loss: 2.017008384068807

Epoch: 6| Step: 5
Training loss: 1.953126072883606
Validation loss: 2.0100112160046897

Epoch: 6| Step: 6
Training loss: 1.7998417615890503
Validation loss: 2.0052894949913025

Epoch: 6| Step: 7
Training loss: 1.28290855884552
Validation loss: 1.9775912165641785

Epoch: 6| Step: 8
Training loss: 1.5395640134811401
Validation loss: 1.9716636141141255

Epoch: 6| Step: 9
Training loss: 1.9833521842956543
Validation loss: 1.9602792263031006

Epoch: 6| Step: 10
Training loss: 1.937361717224121
Validation loss: 1.9532396793365479

Epoch: 6| Step: 11
Training loss: 2.1534056663513184
Validation loss: 1.9631283283233643

Epoch: 6| Step: 12
Training loss: 1.5227857828140259
Validation loss: 1.9516112605730693

Epoch: 6| Step: 13
Training loss: 2.0283517837524414
Validation loss: 1.939253846804301

Epoch: 53| Step: 0
Training loss: 2.1375064849853516
Validation loss: 1.9572683771451314

Epoch: 6| Step: 1
Training loss: 1.689339518547058
Validation loss: 1.9598687291145325

Epoch: 6| Step: 2
Training loss: 1.2257790565490723
Validation loss: 1.954887052377065

Epoch: 6| Step: 3
Training loss: 1.700681209564209
Validation loss: 1.9779466191927593

Epoch: 6| Step: 4
Training loss: 1.5145628452301025
Validation loss: 1.9398971796035767

Epoch: 6| Step: 5
Training loss: 2.2105088233947754
Validation loss: 1.9695562322934468

Epoch: 6| Step: 6
Training loss: 1.4879987239837646
Validation loss: 1.987058202425639

Epoch: 6| Step: 7
Training loss: 2.2768630981445312
Validation loss: 1.975463628768921

Epoch: 6| Step: 8
Training loss: 1.5786545276641846
Validation loss: 1.9798778494199116

Epoch: 6| Step: 9
Training loss: 1.3565707206726074
Validation loss: 1.9909940163294475

Epoch: 6| Step: 10
Training loss: 1.8243000507354736
Validation loss: 1.9593004782994587

Epoch: 6| Step: 11
Training loss: 1.4325742721557617
Validation loss: 1.9649789333343506

Epoch: 6| Step: 12
Training loss: 2.7059340476989746
Validation loss: 1.9672012329101562

Epoch: 6| Step: 13
Training loss: 1.9358702898025513
Validation loss: 1.956649661064148

Epoch: 54| Step: 0
Training loss: 2.070035934448242
Validation loss: 1.9736160238583882

Epoch: 6| Step: 1
Training loss: 2.261406660079956
Validation loss: 1.9755205710728962

Epoch: 6| Step: 2
Training loss: 1.20082426071167
Validation loss: 1.9466821153958638

Epoch: 6| Step: 3
Training loss: 1.482387900352478
Validation loss: 1.9615169167518616

Epoch: 6| Step: 4
Training loss: 1.485783576965332
Validation loss: 1.9847647945086162

Epoch: 6| Step: 5
Training loss: 1.5596020221710205
Validation loss: 1.976426084836324

Epoch: 6| Step: 6
Training loss: 1.9173920154571533
Validation loss: 2.005634884039561

Epoch: 6| Step: 7
Training loss: 2.3327949047088623
Validation loss: 2.0065747698148093

Epoch: 6| Step: 8
Training loss: 1.8625123500823975
Validation loss: 2.0331256985664368

Epoch: 6| Step: 9
Training loss: 2.852919578552246
Validation loss: 2.0182299415270486

Epoch: 6| Step: 10
Training loss: 1.195317029953003
Validation loss: 2.0129360953966775

Epoch: 6| Step: 11
Training loss: 1.9291263818740845
Validation loss: 1.9713690479596455

Epoch: 6| Step: 12
Training loss: 1.810150146484375
Validation loss: 1.9904206196467082

Epoch: 6| Step: 13
Training loss: 1.2775111198425293
Validation loss: 1.959921697775523

Epoch: 55| Step: 0
Training loss: 1.969472050666809
Validation loss: 1.9837819536526997

Epoch: 6| Step: 1
Training loss: 1.5005484819412231
Validation loss: 1.9342849055926006

Epoch: 6| Step: 2
Training loss: 2.1662545204162598
Validation loss: 1.9840627511342366

Epoch: 6| Step: 3
Training loss: 2.090677499771118
Validation loss: 1.96646914879481

Epoch: 6| Step: 4
Training loss: 1.556703805923462
Validation loss: 1.9919012387593586

Epoch: 6| Step: 5
Training loss: 1.9826918840408325
Validation loss: 1.9772407213846843

Epoch: 6| Step: 6
Training loss: 1.7825077772140503
Validation loss: 1.9927939176559448

Epoch: 6| Step: 7
Training loss: 1.320266604423523
Validation loss: 2.0136606097221375

Epoch: 6| Step: 8
Training loss: 1.9807320833206177
Validation loss: 2.010333756605784

Epoch: 6| Step: 9
Training loss: 1.825223445892334
Validation loss: 2.026360293229421

Epoch: 6| Step: 10
Training loss: 1.2050666809082031
Validation loss: 2.0119574268658957

Epoch: 6| Step: 11
Training loss: 1.9396508932113647
Validation loss: 2.003913720448812

Epoch: 6| Step: 12
Training loss: 2.0099711418151855
Validation loss: 1.9978049000104268

Epoch: 6| Step: 13
Training loss: 1.5947401523590088
Validation loss: 1.9537927110989888

Epoch: 56| Step: 0
Training loss: 1.4959278106689453
Validation loss: 1.961625834306081

Epoch: 6| Step: 1
Training loss: 1.7074930667877197
Validation loss: 1.9565803408622742

Epoch: 6| Step: 2
Training loss: 1.4217159748077393
Validation loss: 1.9596961736679077

Epoch: 6| Step: 3
Training loss: 1.8338618278503418
Validation loss: 1.9712955951690674

Epoch: 6| Step: 4
Training loss: 1.9584767818450928
Validation loss: 1.9681459267934163

Epoch: 6| Step: 5
Training loss: 2.0386338233947754
Validation loss: 1.964919626712799

Epoch: 6| Step: 6
Training loss: 1.662105917930603
Validation loss: 1.975069284439087

Epoch: 6| Step: 7
Training loss: 1.679215669631958
Validation loss: 1.9530272682507832

Epoch: 6| Step: 8
Training loss: 2.3164608478546143
Validation loss: 2.0051837166150412

Epoch: 6| Step: 9
Training loss: 2.3116226196289062
Validation loss: 1.972716212272644

Epoch: 6| Step: 10
Training loss: 1.9173263311386108
Validation loss: 1.996601402759552

Epoch: 6| Step: 11
Training loss: 1.7864973545074463
Validation loss: 1.970397174358368

Epoch: 6| Step: 12
Training loss: 1.347649335861206
Validation loss: 1.9618377288182576

Epoch: 6| Step: 13
Training loss: 1.344459056854248
Validation loss: 1.9952916105588276

Epoch: 57| Step: 0
Training loss: 1.6425137519836426
Validation loss: 1.978083610534668

Epoch: 6| Step: 1
Training loss: 1.8041120767593384
Validation loss: 1.9833370447158813

Epoch: 6| Step: 2
Training loss: 2.035489797592163
Validation loss: 1.9607495466868083

Epoch: 6| Step: 3
Training loss: 1.775424838066101
Validation loss: 1.9635195136070251

Epoch: 6| Step: 4
Training loss: 1.236917495727539
Validation loss: 1.9719636638959248

Epoch: 6| Step: 5
Training loss: 2.119163990020752
Validation loss: 1.9621578653653462

Epoch: 6| Step: 6
Training loss: 1.829926609992981
Validation loss: 1.9461215337117512

Epoch: 6| Step: 7
Training loss: 1.7909572124481201
Validation loss: 1.9465017120043437

Epoch: 6| Step: 8
Training loss: 2.0166494846343994
Validation loss: 1.9597606857617695

Epoch: 6| Step: 9
Training loss: 2.066882371902466
Validation loss: 1.958318253358205

Epoch: 6| Step: 10
Training loss: 1.7724127769470215
Validation loss: 1.9714968800544739

Epoch: 6| Step: 11
Training loss: 1.5393152236938477
Validation loss: 1.9951861500740051

Epoch: 6| Step: 12
Training loss: 1.6169028282165527
Validation loss: 2.0146411458651223

Epoch: 6| Step: 13
Training loss: 1.5069119930267334
Validation loss: 2.0145121415456138

Epoch: 58| Step: 0
Training loss: 1.2155141830444336
Validation loss: 2.02168607711792

Epoch: 6| Step: 1
Training loss: 1.7297675609588623
Validation loss: 2.023573935031891

Epoch: 6| Step: 2
Training loss: 0.8199847936630249
Validation loss: 2.0231841603914895

Epoch: 6| Step: 3
Training loss: 2.010629177093506
Validation loss: 2.019876937071482

Epoch: 6| Step: 4
Training loss: 2.273869037628174
Validation loss: 2.0118438005447388

Epoch: 6| Step: 5
Training loss: 1.897461175918579
Validation loss: 2.0455509424209595

Epoch: 6| Step: 6
Training loss: 2.0133581161499023
Validation loss: 2.0271714528401694

Epoch: 6| Step: 7
Training loss: 2.107412815093994
Validation loss: 2.0067325433095298

Epoch: 6| Step: 8
Training loss: 1.7892794609069824
Validation loss: 1.9846161007881165

Epoch: 6| Step: 9
Training loss: 1.859085202217102
Validation loss: 1.9706539909044902

Epoch: 6| Step: 10
Training loss: 1.6447150707244873
Validation loss: 1.9547340671221416

Epoch: 6| Step: 11
Training loss: 1.5030732154846191
Validation loss: 1.9849507610003154

Epoch: 6| Step: 12
Training loss: 1.8128210306167603
Validation loss: 1.9688695073127747

Epoch: 6| Step: 13
Training loss: 1.6825878620147705
Validation loss: 1.970147728919983

Epoch: 59| Step: 0
Training loss: 1.6921770572662354
Validation loss: 1.9706257979075115

Epoch: 6| Step: 1
Training loss: 2.238682270050049
Validation loss: 1.953192452589671

Epoch: 6| Step: 2
Training loss: 1.422768473625183
Validation loss: 1.97333558400472

Epoch: 6| Step: 3
Training loss: 1.4962363243103027
Validation loss: 1.966618041197459

Epoch: 6| Step: 4
Training loss: 1.2632662057876587
Validation loss: 1.9895952939987183

Epoch: 6| Step: 5
Training loss: 1.478887915611267
Validation loss: 1.97612859805425

Epoch: 6| Step: 6
Training loss: 1.0688531398773193
Validation loss: 2.0094638069470725

Epoch: 6| Step: 7
Training loss: 2.2872605323791504
Validation loss: 2.033546268939972

Epoch: 6| Step: 8
Training loss: 2.4173831939697266
Validation loss: 2.027136663595835

Epoch: 6| Step: 9
Training loss: 2.3486647605895996
Validation loss: 2.0244879523913064

Epoch: 6| Step: 10
Training loss: 2.2339463233947754
Validation loss: 2.011707325776418

Epoch: 6| Step: 11
Training loss: 2.138749122619629
Validation loss: 1.9923879106839497

Epoch: 6| Step: 12
Training loss: 1.319463849067688
Validation loss: 1.992489218711853

Epoch: 6| Step: 13
Training loss: 1.4077460765838623
Validation loss: 1.971019188563029

Epoch: 60| Step: 0
Training loss: 1.541948676109314
Validation loss: 1.9717315634091694

Epoch: 6| Step: 1
Training loss: 2.1368801593780518
Validation loss: 1.967233697573344

Epoch: 6| Step: 2
Training loss: 1.6283127069473267
Validation loss: 1.9457838535308838

Epoch: 6| Step: 3
Training loss: 1.7272417545318604
Validation loss: 1.9771805604298909

Epoch: 6| Step: 4
Training loss: 1.6341524124145508
Validation loss: 1.9228070378303528

Epoch: 6| Step: 5
Training loss: 1.5114079713821411
Validation loss: 1.948687195777893

Epoch: 6| Step: 6
Training loss: 1.606309413909912
Validation loss: 1.959556758403778

Epoch: 6| Step: 7
Training loss: 1.7638429403305054
Validation loss: 1.939257522424062

Epoch: 6| Step: 8
Training loss: 1.120120882987976
Validation loss: 1.9905471404393513

Epoch: 6| Step: 9
Training loss: 1.9098005294799805
Validation loss: 1.9967581431070964

Epoch: 6| Step: 10
Training loss: 2.358755111694336
Validation loss: 2.024150272210439

Epoch: 6| Step: 11
Training loss: 2.28847336769104
Validation loss: 2.0394633412361145

Epoch: 6| Step: 12
Training loss: 1.5910131931304932
Validation loss: 1.9945099353790283

Epoch: 6| Step: 13
Training loss: 1.4035050868988037
Validation loss: 2.013998727003733

Epoch: 61| Step: 0
Training loss: 1.9564374685287476
Validation loss: 2.026557962099711

Epoch: 6| Step: 1
Training loss: 1.35310697555542
Validation loss: 2.041517456372579

Epoch: 6| Step: 2
Training loss: 1.645598292350769
Validation loss: 2.0265544056892395

Epoch: 6| Step: 3
Training loss: 1.6688008308410645
Validation loss: 2.039057751496633

Epoch: 6| Step: 4
Training loss: 1.1782355308532715
Validation loss: 2.0056196451187134

Epoch: 6| Step: 5
Training loss: 2.21091628074646
Validation loss: 2.0039211312929788

Epoch: 6| Step: 6
Training loss: 1.1344425678253174
Validation loss: 1.99373064438502

Epoch: 6| Step: 7
Training loss: 1.4126343727111816
Validation loss: 2.028391440709432

Epoch: 6| Step: 8
Training loss: 2.018167018890381
Validation loss: 2.0208874146143594

Epoch: 6| Step: 9
Training loss: 1.0412518978118896
Validation loss: 1.9885010719299316

Epoch: 6| Step: 10
Training loss: 1.940585970878601
Validation loss: 2.008558531602224

Epoch: 6| Step: 11
Training loss: 2.0446949005126953
Validation loss: 2.001534362634023

Epoch: 6| Step: 12
Training loss: 2.2666096687316895
Validation loss: 2.008654793103536

Epoch: 6| Step: 13
Training loss: 2.0667059421539307
Validation loss: 1.979977508385976

Epoch: 62| Step: 0
Training loss: 1.70491623878479
Validation loss: 2.005155324935913

Epoch: 6| Step: 1
Training loss: 1.7706727981567383
Validation loss: 1.9839476346969604

Epoch: 6| Step: 2
Training loss: 1.5828826427459717
Validation loss: 1.9748429854710896

Epoch: 6| Step: 3
Training loss: 1.5227822065353394
Validation loss: 1.9939545790354412

Epoch: 6| Step: 4
Training loss: 1.7464747428894043
Validation loss: 1.94932226339976

Epoch: 6| Step: 5
Training loss: 1.1336594820022583
Validation loss: 1.975313385327657

Epoch: 6| Step: 6
Training loss: 1.8769408464431763
Validation loss: 1.9980021913846333

Epoch: 6| Step: 7
Training loss: 1.3482325077056885
Validation loss: 2.0132710337638855

Epoch: 6| Step: 8
Training loss: 1.8487757444381714
Validation loss: 1.9986784259478252

Epoch: 6| Step: 9
Training loss: 2.058560609817505
Validation loss: 1.9947657982508342

Epoch: 6| Step: 10
Training loss: 1.7690725326538086
Validation loss: 2.0233434438705444

Epoch: 6| Step: 11
Training loss: 1.7496814727783203
Validation loss: 1.9827623168627422

Epoch: 6| Step: 12
Training loss: 1.986353874206543
Validation loss: 1.9717738628387451

Epoch: 6| Step: 13
Training loss: 1.7030234336853027
Validation loss: 1.999929666519165

Epoch: 63| Step: 0
Training loss: 0.9901809096336365
Validation loss: 2.0092782179514566

Epoch: 6| Step: 1
Training loss: 1.4079914093017578
Validation loss: 1.9979032278060913

Epoch: 6| Step: 2
Training loss: 1.5760929584503174
Validation loss: 1.9682738780975342

Epoch: 6| Step: 3
Training loss: 1.4129244089126587
Validation loss: 1.95444522301356

Epoch: 6| Step: 4
Training loss: 1.6964792013168335
Validation loss: 1.98927108446757

Epoch: 6| Step: 5
Training loss: 2.2517852783203125
Validation loss: 2.0026718179384866

Epoch: 6| Step: 6
Training loss: 1.3241357803344727
Validation loss: 1.9854474266370137

Epoch: 6| Step: 7
Training loss: 1.1677584648132324
Validation loss: 1.998112181822459

Epoch: 6| Step: 8
Training loss: 1.6875841617584229
Validation loss: 2.0151246984799704

Epoch: 6| Step: 9
Training loss: 1.9470188617706299
Validation loss: 1.9761710564295452

Epoch: 6| Step: 10
Training loss: 1.147886037826538
Validation loss: 2.0052406787872314

Epoch: 6| Step: 11
Training loss: 1.8331682682037354
Validation loss: 2.0199497739473977

Epoch: 6| Step: 12
Training loss: 2.4853949546813965
Validation loss: 2.009946127732595

Epoch: 6| Step: 13
Training loss: 2.70104718208313
Validation loss: 2.015409509340922

Epoch: 64| Step: 0
Training loss: 1.469616174697876
Validation loss: 2.039909323056539

Epoch: 6| Step: 1
Training loss: 1.4038597345352173
Validation loss: 2.0320121943950653

Epoch: 6| Step: 2
Training loss: 1.7352523803710938
Validation loss: 2.0300219456354776

Epoch: 6| Step: 3
Training loss: 1.5638020038604736
Validation loss: 2.018104155858358

Epoch: 6| Step: 4
Training loss: 1.5005232095718384
Validation loss: 2.017295698324839

Epoch: 6| Step: 5
Training loss: 1.9685449600219727
Validation loss: 2.0133098562558494

Epoch: 6| Step: 6
Training loss: 1.4518980979919434
Validation loss: 2.0175348122914634

Epoch: 6| Step: 7
Training loss: 1.4759596586227417
Validation loss: 2.000441829363505

Epoch: 6| Step: 8
Training loss: 1.5612719058990479
Validation loss: 1.9725119670232136

Epoch: 6| Step: 9
Training loss: 1.4706865549087524
Validation loss: 1.9728149970372517

Epoch: 6| Step: 10
Training loss: 1.894453525543213
Validation loss: 1.9880658189455669

Epoch: 6| Step: 11
Training loss: 1.8738349676132202
Validation loss: 1.9525250395139058

Epoch: 6| Step: 12
Training loss: 1.5724599361419678
Validation loss: 1.9725032448768616

Epoch: 6| Step: 13
Training loss: 2.5618016719818115
Validation loss: 1.9840093851089478

Epoch: 65| Step: 0
Training loss: 1.6382977962493896
Validation loss: 1.9938814838727315

Epoch: 6| Step: 1
Training loss: 1.9165081977844238
Validation loss: 1.9881981015205383

Epoch: 6| Step: 2
Training loss: 1.8107272386550903
Validation loss: 2.0531007051467896

Epoch: 6| Step: 3
Training loss: 1.7090396881103516
Validation loss: 2.0700510541598

Epoch: 6| Step: 4
Training loss: 1.9114501476287842
Validation loss: 2.0527304808298745

Epoch: 6| Step: 5
Training loss: 1.9469764232635498
Validation loss: 2.074798107147217

Epoch: 6| Step: 6
Training loss: 1.6709096431732178
Validation loss: 2.096861104170481

Epoch: 6| Step: 7
Training loss: 2.301236867904663
Validation loss: 2.0801385839780173

Epoch: 6| Step: 8
Training loss: 1.5685075521469116
Validation loss: 2.046390255292257

Epoch: 6| Step: 9
Training loss: 1.7016963958740234
Validation loss: 2.0236926476160684

Epoch: 6| Step: 10
Training loss: 1.4142050743103027
Validation loss: 2.0187445680300393

Epoch: 6| Step: 11
Training loss: 1.9584875106811523
Validation loss: 1.9932430585225422

Epoch: 6| Step: 12
Training loss: 1.790280818939209
Validation loss: 1.95456196864446

Epoch: 6| Step: 13
Training loss: 1.164062738418579
Validation loss: 1.9819243947664897

Epoch: 66| Step: 0
Training loss: 1.680107593536377
Validation loss: 1.9490204056104024

Epoch: 6| Step: 1
Training loss: 1.5621049404144287
Validation loss: 1.985405961672465

Epoch: 6| Step: 2
Training loss: 1.397994875907898
Validation loss: 1.9496557712554932

Epoch: 6| Step: 3
Training loss: 1.7569782733917236
Validation loss: 1.9745437304178874

Epoch: 6| Step: 4
Training loss: 2.718508720397949
Validation loss: 1.9767852624257405

Epoch: 6| Step: 5
Training loss: 1.4979819059371948
Validation loss: 2.0157474080721536

Epoch: 6| Step: 6
Training loss: 0.9906311631202698
Validation loss: 1.966652552286784

Epoch: 6| Step: 7
Training loss: 1.662998080253601
Validation loss: 2.006515920162201

Epoch: 6| Step: 8
Training loss: 1.7067570686340332
Validation loss: 2.025600870450338

Epoch: 6| Step: 9
Training loss: 1.9450479745864868
Validation loss: 2.0397979815800986

Epoch: 6| Step: 10
Training loss: 1.8551652431488037
Validation loss: 2.032168924808502

Epoch: 6| Step: 11
Training loss: 1.2970609664916992
Validation loss: 1.9794878562291462

Epoch: 6| Step: 12
Training loss: 1.7644258737564087
Validation loss: 2.0308963656425476

Epoch: 6| Step: 13
Training loss: 1.412027359008789
Validation loss: 2.041929006576538

Epoch: 67| Step: 0
Training loss: 2.174137592315674
Validation loss: 2.042805552482605

Epoch: 6| Step: 1
Training loss: 1.2449595928192139
Validation loss: 2.015901724497477

Epoch: 6| Step: 2
Training loss: 1.762738585472107
Validation loss: 2.0015831788380942

Epoch: 6| Step: 3
Training loss: 1.643311858177185
Validation loss: 2.019973715146383

Epoch: 6| Step: 4
Training loss: 1.5277717113494873
Validation loss: 2.0448155999183655

Epoch: 6| Step: 5
Training loss: 1.4208381175994873
Validation loss: 2.0456878741582236

Epoch: 6| Step: 6
Training loss: 1.885043740272522
Validation loss: 2.0112514098485312

Epoch: 6| Step: 7
Training loss: 1.8919131755828857
Validation loss: 2.004483163356781

Epoch: 6| Step: 8
Training loss: 0.706360936164856
Validation loss: 1.9914498925209045

Epoch: 6| Step: 9
Training loss: 1.4649125337600708
Validation loss: 2.000221391518911

Epoch: 6| Step: 10
Training loss: 1.4958442449569702
Validation loss: 1.9738604227701824

Epoch: 6| Step: 11
Training loss: 1.5215964317321777
Validation loss: 1.9883308211962383

Epoch: 6| Step: 12
Training loss: 2.10201096534729
Validation loss: 1.973256528377533

Epoch: 6| Step: 13
Training loss: 1.9478156566619873
Validation loss: 2.0126179258028665

Epoch: 68| Step: 0
Training loss: 1.5547082424163818
Validation loss: 1.9871991674105327

Epoch: 6| Step: 1
Training loss: 1.7411508560180664
Validation loss: 2.036371966203054

Epoch: 6| Step: 2
Training loss: 1.351059079170227
Validation loss: 1.993682364622752

Epoch: 6| Step: 3
Training loss: 0.8989076018333435
Validation loss: 2.0320882002512612

Epoch: 6| Step: 4
Training loss: 1.39725661277771
Validation loss: 2.049158294995626

Epoch: 6| Step: 5
Training loss: 1.1709015369415283
Validation loss: 2.0123950441678367

Epoch: 6| Step: 6
Training loss: 1.0139429569244385
Validation loss: 2.0489628314971924

Epoch: 6| Step: 7
Training loss: 1.9900922775268555
Validation loss: 2.0292126337687173

Epoch: 6| Step: 8
Training loss: 2.2965900897979736
Validation loss: 2.022345185279846

Epoch: 6| Step: 9
Training loss: 1.9482637643814087
Validation loss: 2.0494866967201233

Epoch: 6| Step: 10
Training loss: 1.8912795782089233
Validation loss: 2.014300843079885

Epoch: 6| Step: 11
Training loss: 1.5858736038208008
Validation loss: 2.0690518816312156

Epoch: 6| Step: 12
Training loss: 1.9160133600234985
Validation loss: 2.0625351866086326

Epoch: 6| Step: 13
Training loss: 1.971976637840271
Validation loss: 2.0528913338979087

Epoch: 69| Step: 0
Training loss: 1.5785024166107178
Validation loss: 2.018838961919149

Epoch: 6| Step: 1
Training loss: 1.6351723670959473
Validation loss: 1.97759614388148

Epoch: 6| Step: 2
Training loss: 2.1231346130371094
Validation loss: 1.98247226079305

Epoch: 6| Step: 3
Training loss: 1.5926872491836548
Validation loss: 1.9939724405606587

Epoch: 6| Step: 4
Training loss: 1.6407008171081543
Validation loss: 1.969603180885315

Epoch: 6| Step: 5
Training loss: 1.7608096599578857
Validation loss: 1.988607128461202

Epoch: 6| Step: 6
Training loss: 1.601145625114441
Validation loss: 1.9708581765492756

Epoch: 6| Step: 7
Training loss: 1.9826080799102783
Validation loss: 2.000135660171509

Epoch: 6| Step: 8
Training loss: 1.9735138416290283
Validation loss: 2.027882138888041

Epoch: 6| Step: 9
Training loss: 1.3690011501312256
Validation loss: 2.043883224328359

Epoch: 6| Step: 10
Training loss: 0.8833577036857605
Validation loss: 2.046558380126953

Epoch: 6| Step: 11
Training loss: 1.2522313594818115
Validation loss: 2.0415740609169006

Epoch: 6| Step: 12
Training loss: 1.8547730445861816
Validation loss: 2.05520753065745

Epoch: 6| Step: 13
Training loss: 1.7505474090576172
Validation loss: 2.061187823613485

Epoch: 70| Step: 0
Training loss: 1.8731091022491455
Validation loss: 2.0385936498641968

Epoch: 6| Step: 1
Training loss: 1.8912534713745117
Validation loss: 2.027165671189626

Epoch: 6| Step: 2
Training loss: 1.4030877351760864
Validation loss: 2.03579835096995

Epoch: 6| Step: 3
Training loss: 1.5802850723266602
Validation loss: 2.0633711218833923

Epoch: 6| Step: 4
Training loss: 1.3267804384231567
Validation loss: 2.0323106249173484

Epoch: 6| Step: 5
Training loss: 2.2651710510253906
Validation loss: 2.038765549659729

Epoch: 6| Step: 6
Training loss: 1.4838534593582153
Validation loss: 1.9968847235043843

Epoch: 6| Step: 7
Training loss: 1.557403564453125
Validation loss: 1.9704749186833699

Epoch: 6| Step: 8
Training loss: 1.5423529148101807
Validation loss: 2.0238829851150513

Epoch: 6| Step: 9
Training loss: 1.5039722919464111
Validation loss: 2.00036484003067

Epoch: 6| Step: 10
Training loss: 1.1276535987854004
Validation loss: 2.0027907490730286

Epoch: 6| Step: 11
Training loss: 1.3799550533294678
Validation loss: 1.9924191037813823

Epoch: 6| Step: 12
Training loss: 1.3930225372314453
Validation loss: 2.0025420586268106

Epoch: 6| Step: 13
Training loss: 1.949172019958496
Validation loss: 2.022835393746694

Epoch: 71| Step: 0
Training loss: 2.2379086017608643
Validation loss: 2.0034420688947043

Epoch: 6| Step: 1
Training loss: 1.9871999025344849
Validation loss: 2.015597939491272

Epoch: 6| Step: 2
Training loss: 1.157015323638916
Validation loss: 2.011388679345449

Epoch: 6| Step: 3
Training loss: 1.2908490896224976
Validation loss: 2.003648797671

Epoch: 6| Step: 4
Training loss: 1.266584873199463
Validation loss: 2.020734667778015

Epoch: 6| Step: 5
Training loss: 1.2023859024047852
Validation loss: 1.9866254925727844

Epoch: 6| Step: 6
Training loss: 1.6468560695648193
Validation loss: 2.0294037461280823

Epoch: 6| Step: 7
Training loss: 0.9574452042579651
Validation loss: 2.042678713798523

Epoch: 6| Step: 8
Training loss: 1.4323747158050537
Validation loss: 2.0148585041364035

Epoch: 6| Step: 9
Training loss: 1.7761144638061523
Validation loss: 2.035031874974569

Epoch: 6| Step: 10
Training loss: 2.0992865562438965
Validation loss: 2.062013546625773

Epoch: 6| Step: 11
Training loss: 1.8154182434082031
Validation loss: 2.007761538028717

Epoch: 6| Step: 12
Training loss: 1.5904617309570312
Validation loss: 2.0220627387364707

Epoch: 6| Step: 13
Training loss: 1.3321747779846191
Validation loss: 2.0134120186169944

Epoch: 72| Step: 0
Training loss: 1.302863359451294
Validation loss: 2.0541388988494873

Epoch: 6| Step: 1
Training loss: 1.1792441606521606
Validation loss: 2.076201935609182

Epoch: 6| Step: 2
Training loss: 1.2992702722549438
Validation loss: 2.0555924574534097

Epoch: 6| Step: 3
Training loss: 2.0729098320007324
Validation loss: 2.108011861642202

Epoch: 6| Step: 4
Training loss: 1.6741514205932617
Validation loss: 2.0972485740979514

Epoch: 6| Step: 5
Training loss: 1.5402271747589111
Validation loss: 2.077850659688314

Epoch: 6| Step: 6
Training loss: 1.4506897926330566
Validation loss: 2.062431355317434

Epoch: 6| Step: 7
Training loss: 1.3702750205993652
Validation loss: 2.0529486536979675

Epoch: 6| Step: 8
Training loss: 1.5878360271453857
Validation loss: 2.0038209358851113

Epoch: 6| Step: 9
Training loss: 1.7682992219924927
Validation loss: 2.020141343275706

Epoch: 6| Step: 10
Training loss: 1.5485961437225342
Validation loss: 2.0127437512079873

Epoch: 6| Step: 11
Training loss: 1.3192371129989624
Validation loss: 1.9965079228083293

Epoch: 6| Step: 12
Training loss: 1.9573436975479126
Validation loss: 2.0185837348302207

Epoch: 6| Step: 13
Training loss: 1.5590057373046875
Validation loss: 1.9949159224828084

Epoch: 73| Step: 0
Training loss: 1.23610258102417
Validation loss: 1.9668134053548176

Epoch: 6| Step: 1
Training loss: 1.641768455505371
Validation loss: 2.0162681341171265

Epoch: 6| Step: 2
Training loss: 1.283913016319275
Validation loss: 2.009695072968801

Epoch: 6| Step: 3
Training loss: 0.8964462280273438
Validation loss: 1.9984500408172607

Epoch: 6| Step: 4
Training loss: 1.8184025287628174
Validation loss: 1.9786258737246196

Epoch: 6| Step: 5
Training loss: 1.300041913986206
Validation loss: 2.013717313607534

Epoch: 6| Step: 6
Training loss: 0.9568368792533875
Validation loss: 2.034091075261434

Epoch: 6| Step: 7
Training loss: 1.82877516746521
Validation loss: 2.007094224294027

Epoch: 6| Step: 8
Training loss: 1.938053846359253
Validation loss: 2.0533742705980935

Epoch: 6| Step: 9
Training loss: 1.9977238178253174
Validation loss: 2.1018460988998413

Epoch: 6| Step: 10
Training loss: 1.5735104084014893
Validation loss: 2.021654645601908

Epoch: 6| Step: 11
Training loss: 1.3456205129623413
Validation loss: 2.06340883175532

Epoch: 6| Step: 12
Training loss: 1.5991151332855225
Validation loss: 2.054861009120941

Epoch: 6| Step: 13
Training loss: 2.2889766693115234
Validation loss: 2.0107096433639526

Epoch: 74| Step: 0
Training loss: 1.6645926237106323
Validation loss: 2.045306086540222

Epoch: 6| Step: 1
Training loss: 1.2205963134765625
Validation loss: 2.0234581430753074

Epoch: 6| Step: 2
Training loss: 1.4641895294189453
Validation loss: 2.046076695124308

Epoch: 6| Step: 3
Training loss: 1.788017749786377
Validation loss: 2.041749735673269

Epoch: 6| Step: 4
Training loss: 1.6507328748703003
Validation loss: 2.030880888303121

Epoch: 6| Step: 5
Training loss: 1.5924564599990845
Validation loss: 2.0101567109425864

Epoch: 6| Step: 6
Training loss: 1.502654790878296
Validation loss: 2.033785422643026

Epoch: 6| Step: 7
Training loss: 1.1410666704177856
Validation loss: 2.02708367506663

Epoch: 6| Step: 8
Training loss: 1.347369909286499
Validation loss: 2.0194009145100913

Epoch: 6| Step: 9
Training loss: 1.7734100818634033
Validation loss: 2.0696723262468972

Epoch: 6| Step: 10
Training loss: 1.9108171463012695
Validation loss: 2.0329171617825827

Epoch: 6| Step: 11
Training loss: 1.491844654083252
Validation loss: 2.06955349445343

Epoch: 6| Step: 12
Training loss: 1.2339648008346558
Validation loss: 2.0598581433296204

Epoch: 6| Step: 13
Training loss: 1.2937573194503784
Validation loss: 2.072699228922526

Epoch: 75| Step: 0
Training loss: 0.9989008903503418
Validation loss: 2.069847345352173

Epoch: 6| Step: 1
Training loss: 1.7484606504440308
Validation loss: 2.0121458570162454

Epoch: 6| Step: 2
Training loss: 1.9789772033691406
Validation loss: 2.05719127257665

Epoch: 6| Step: 3
Training loss: 0.9042583703994751
Validation loss: 2.025523920853933

Epoch: 6| Step: 4
Training loss: 1.7491307258605957
Validation loss: 2.0298789143562317

Epoch: 6| Step: 5
Training loss: 1.6252193450927734
Validation loss: 2.053334335486094

Epoch: 6| Step: 6
Training loss: 1.31031334400177
Validation loss: 2.0163715879122415

Epoch: 6| Step: 7
Training loss: 1.650575041770935
Validation loss: 2.019945800304413

Epoch: 6| Step: 8
Training loss: 2.148746967315674
Validation loss: 2.0258074402809143

Epoch: 6| Step: 9
Training loss: 1.1797764301300049
Validation loss: 2.007855554421743

Epoch: 6| Step: 10
Training loss: 0.9514651298522949
Validation loss: 2.003154158592224

Epoch: 6| Step: 11
Training loss: 1.493725061416626
Validation loss: 2.000994841257731

Epoch: 6| Step: 12
Training loss: 1.8091135025024414
Validation loss: 2.019407033920288

Epoch: 6| Step: 13
Training loss: 1.3900425434112549
Validation loss: 2.012546638647715

Epoch: 76| Step: 0
Training loss: 2.3235831260681152
Validation loss: 2.003103236357371

Epoch: 6| Step: 1
Training loss: 1.5983943939208984
Validation loss: 2.0253310600916543

Epoch: 6| Step: 2
Training loss: 0.915662944316864
Validation loss: 1.9971216519673665

Epoch: 6| Step: 3
Training loss: 1.3129398822784424
Validation loss: 1.9988115628560383

Epoch: 6| Step: 4
Training loss: 1.387887716293335
Validation loss: 2.0239326556523642

Epoch: 6| Step: 5
Training loss: 1.110733985900879
Validation loss: 2.0163792967796326

Epoch: 6| Step: 6
Training loss: 1.982912302017212
Validation loss: 2.044838269551595

Epoch: 6| Step: 7
Training loss: 1.3437891006469727
Validation loss: 2.104541818300883

Epoch: 6| Step: 8
Training loss: 1.965291142463684
Validation loss: 2.122977375984192

Epoch: 6| Step: 9
Training loss: 1.8385653495788574
Validation loss: 2.1588363448778787

Epoch: 6| Step: 10
Training loss: 1.2693274021148682
Validation loss: 2.169890304406484

Epoch: 6| Step: 11
Training loss: 1.7765328884124756
Validation loss: 2.126925786336263

Epoch: 6| Step: 12
Training loss: 1.64434814453125
Validation loss: 2.096964180469513

Epoch: 6| Step: 13
Training loss: 0.832988977432251
Validation loss: 2.055102825164795

Epoch: 77| Step: 0
Training loss: 1.2141014337539673
Validation loss: 2.0505432883898416

Epoch: 6| Step: 1
Training loss: 0.9585819840431213
Validation loss: 2.0826809207598367

Epoch: 6| Step: 2
Training loss: 1.5196585655212402
Validation loss: 2.021217385927836

Epoch: 6| Step: 3
Training loss: 1.4537752866744995
Validation loss: 2.0407582918802896

Epoch: 6| Step: 4
Training loss: 1.2416982650756836
Validation loss: 2.024341563383738

Epoch: 6| Step: 5
Training loss: 1.1018123626708984
Validation loss: 2.013307730356852

Epoch: 6| Step: 6
Training loss: 1.644577980041504
Validation loss: 2.0337292551994324

Epoch: 6| Step: 7
Training loss: 1.219689130783081
Validation loss: 2.0341004133224487

Epoch: 6| Step: 8
Training loss: 1.1572513580322266
Validation loss: 1.999661962191264

Epoch: 6| Step: 9
Training loss: 1.7114315032958984
Validation loss: 1.982809583346049

Epoch: 6| Step: 10
Training loss: 2.3564605712890625
Validation loss: 2.0040226777394614

Epoch: 6| Step: 11
Training loss: 1.6959311962127686
Validation loss: 2.019072949886322

Epoch: 6| Step: 12
Training loss: 1.6137115955352783
Validation loss: 2.0215937892595925

Epoch: 6| Step: 13
Training loss: 1.9092100858688354
Validation loss: 2.058992564678192

Epoch: 78| Step: 0
Training loss: 1.397312045097351
Validation loss: 2.0362526774406433

Epoch: 6| Step: 1
Training loss: 1.408699631690979
Validation loss: 2.052069385846456

Epoch: 6| Step: 2
Training loss: 1.5887359380722046
Validation loss: 2.027295549710592

Epoch: 6| Step: 3
Training loss: 1.3075931072235107
Validation loss: 1.9969537059466045

Epoch: 6| Step: 4
Training loss: 1.3379437923431396
Validation loss: 2.0748112400372825

Epoch: 6| Step: 5
Training loss: 1.3217964172363281
Validation loss: 2.053162395954132

Epoch: 6| Step: 6
Training loss: 1.23356294631958
Validation loss: 2.0422745744387307

Epoch: 6| Step: 7
Training loss: 1.778859257698059
Validation loss: 2.047003706296285

Epoch: 6| Step: 8
Training loss: 1.7969342470169067
Validation loss: 2.0058556397755942

Epoch: 6| Step: 9
Training loss: 1.261401891708374
Validation loss: 2.04125322898229

Epoch: 6| Step: 10
Training loss: 1.2103781700134277
Validation loss: 2.0084662238756814

Epoch: 6| Step: 11
Training loss: 2.3978922367095947
Validation loss: 2.032521069049835

Epoch: 6| Step: 12
Training loss: 1.39946711063385
Validation loss: 1.9870295921961467

Epoch: 6| Step: 13
Training loss: 1.1843390464782715
Validation loss: 1.9834423462549846

Epoch: 79| Step: 0
Training loss: 1.3723279237747192
Validation loss: 2.034444729487101

Epoch: 6| Step: 1
Training loss: 0.9178411960601807
Validation loss: 2.0730133851369223

Epoch: 6| Step: 2
Training loss: 1.577161192893982
Validation loss: 2.0768377582232156

Epoch: 6| Step: 3
Training loss: 1.4101331233978271
Validation loss: 2.1036996444066367

Epoch: 6| Step: 4
Training loss: 1.8154826164245605
Validation loss: 2.1293675104777017

Epoch: 6| Step: 5
Training loss: 1.7256914377212524
Validation loss: 2.085637887318929

Epoch: 6| Step: 6
Training loss: 1.2128986120224
Validation loss: 2.0478751063346863

Epoch: 6| Step: 7
Training loss: 1.651460886001587
Validation loss: 2.064565042654673

Epoch: 6| Step: 8
Training loss: 1.0881903171539307
Validation loss: 2.0591996709505715

Epoch: 6| Step: 9
Training loss: 1.0551142692565918
Validation loss: 2.060312290986379

Epoch: 6| Step: 10
Training loss: 1.3949869871139526
Validation loss: 2.0524590810139975

Epoch: 6| Step: 11
Training loss: 1.1537115573883057
Validation loss: 2.0749355355898538

Epoch: 6| Step: 12
Training loss: 2.3319597244262695
Validation loss: 2.0247899889945984

Epoch: 6| Step: 13
Training loss: 1.7522249221801758
Validation loss: 2.0194764733314514

Epoch: 80| Step: 0
Training loss: 1.4005073308944702
Validation loss: 2.0451422135035195

Epoch: 6| Step: 1
Training loss: 1.16794753074646
Validation loss: 2.059342364470164

Epoch: 6| Step: 2
Training loss: 1.5516421794891357
Validation loss: 2.065989891688029

Epoch: 6| Step: 3
Training loss: 1.0543376207351685
Validation loss: 2.0640885829925537

Epoch: 6| Step: 4
Training loss: 1.5730054378509521
Validation loss: 1.9986401398976643

Epoch: 6| Step: 5
Training loss: 1.6534361839294434
Validation loss: 2.0231257478396096

Epoch: 6| Step: 6
Training loss: 1.5242383480072021
Validation loss: 2.051886041959127

Epoch: 6| Step: 7
Training loss: 1.5342650413513184
Validation loss: 2.0428976019223533

Epoch: 6| Step: 8
Training loss: 1.73348069190979
Validation loss: 2.0279407898585

Epoch: 6| Step: 9
Training loss: 1.5594613552093506
Validation loss: 2.0657289822896323

Epoch: 6| Step: 10
Training loss: 0.9519332051277161
Validation loss: 2.061641256014506

Epoch: 6| Step: 11
Training loss: 1.584301471710205
Validation loss: 2.0638280709584556

Epoch: 6| Step: 12
Training loss: 1.627638578414917
Validation loss: 2.0499969323476157

Epoch: 6| Step: 13
Training loss: 1.3922946453094482
Validation loss: 2.0647565921147666

Epoch: 81| Step: 0
Training loss: 1.449939250946045
Validation loss: 2.0857112805048623

Epoch: 6| Step: 1
Training loss: 1.6150124073028564
Validation loss: 2.082906504472097

Epoch: 6| Step: 2
Training loss: 1.699405550956726
Validation loss: 2.031232158342997

Epoch: 6| Step: 3
Training loss: 2.303187847137451
Validation loss: 2.0458566347757974

Epoch: 6| Step: 4
Training loss: 1.583428144454956
Validation loss: 2.036545972029368

Epoch: 6| Step: 5
Training loss: 1.1545484066009521
Validation loss: 2.042657991250356

Epoch: 6| Step: 6
Training loss: 1.6999449729919434
Validation loss: 2.02331135670344

Epoch: 6| Step: 7
Training loss: 1.3687493801116943
Validation loss: 1.9858440558115642

Epoch: 6| Step: 8
Training loss: 0.7992398142814636
Validation loss: 2.037861982981364

Epoch: 6| Step: 9
Training loss: 1.3359434604644775
Validation loss: 2.0303234656651816

Epoch: 6| Step: 10
Training loss: 1.2204217910766602
Validation loss: 2.014902909596761

Epoch: 6| Step: 11
Training loss: 1.6004002094268799
Validation loss: 2.0532698035240173

Epoch: 6| Step: 12
Training loss: 1.298710823059082
Validation loss: 2.029929200808207

Epoch: 6| Step: 13
Training loss: 1.1234843730926514
Validation loss: 2.0384112199147544

Epoch: 82| Step: 0
Training loss: 1.6403383016586304
Validation loss: 2.013159453868866

Epoch: 6| Step: 1
Training loss: 1.9205904006958008
Validation loss: 2.0535398721694946

Epoch: 6| Step: 2
Training loss: 1.3064556121826172
Validation loss: 2.041257123152415

Epoch: 6| Step: 3
Training loss: 0.9890100955963135
Validation loss: 2.033509055773417

Epoch: 6| Step: 4
Training loss: 0.9952629208564758
Validation loss: 2.0551376342773438

Epoch: 6| Step: 5
Training loss: 1.5884501934051514
Validation loss: 2.0662955244382224

Epoch: 6| Step: 6
Training loss: 1.7309141159057617
Validation loss: 2.0469917257626853

Epoch: 6| Step: 7
Training loss: 1.948991060256958
Validation loss: 2.044343868891398

Epoch: 6| Step: 8
Training loss: 1.2234411239624023
Validation loss: 2.0736717581748962

Epoch: 6| Step: 9
Training loss: 1.2648773193359375
Validation loss: 2.0894670685132346

Epoch: 6| Step: 10
Training loss: 1.596934199333191
Validation loss: 2.1030924916267395

Epoch: 6| Step: 11
Training loss: 1.2005887031555176
Validation loss: 2.06386931737264

Epoch: 6| Step: 12
Training loss: 1.2844460010528564
Validation loss: 2.0477568904558816

Epoch: 6| Step: 13
Training loss: 1.0346344709396362
Validation loss: 2.0479395389556885

Epoch: 83| Step: 0
Training loss: 0.9494818449020386
Validation loss: 2.0283028284708657

Epoch: 6| Step: 1
Training loss: 1.579728126525879
Validation loss: 2.038585642973582

Epoch: 6| Step: 2
Training loss: 0.815912663936615
Validation loss: 2.0092782974243164

Epoch: 6| Step: 3
Training loss: 1.2379980087280273
Validation loss: 2.0296244422594705

Epoch: 6| Step: 4
Training loss: 1.4248278141021729
Validation loss: 2.0537400046984353

Epoch: 6| Step: 5
Training loss: 1.730792760848999
Validation loss: 2.0519466598828635

Epoch: 6| Step: 6
Training loss: 1.0867688655853271
Validation loss: 2.0419052640597024

Epoch: 6| Step: 7
Training loss: 1.2923251390457153
Validation loss: 2.0474261244138083

Epoch: 6| Step: 8
Training loss: 1.1545612812042236
Validation loss: 2.0844544569651284

Epoch: 6| Step: 9
Training loss: 1.9262688159942627
Validation loss: 2.084744115670522

Epoch: 6| Step: 10
Training loss: 1.4838380813598633
Validation loss: 2.0656028985977173

Epoch: 6| Step: 11
Training loss: 1.790159821510315
Validation loss: 2.063278079032898

Epoch: 6| Step: 12
Training loss: 1.2796874046325684
Validation loss: 2.061009665330251

Epoch: 6| Step: 13
Training loss: 1.5823585987091064
Validation loss: 2.025740106900533

Epoch: 84| Step: 0
Training loss: 1.8883028030395508
Validation loss: 2.027649442354838

Epoch: 6| Step: 1
Training loss: 1.1660234928131104
Validation loss: 2.0390974481900535

Epoch: 6| Step: 2
Training loss: 1.5309267044067383
Validation loss: 2.017434616883596

Epoch: 6| Step: 3
Training loss: 1.8432761430740356
Validation loss: 1.99788498878479

Epoch: 6| Step: 4
Training loss: 1.395573377609253
Validation loss: 1.9796823660532634

Epoch: 6| Step: 5
Training loss: 1.4074807167053223
Validation loss: 1.9917994340260823

Epoch: 6| Step: 6
Training loss: 1.352178931236267
Validation loss: 2.036427120367686

Epoch: 6| Step: 7
Training loss: 0.676496684551239
Validation loss: 2.0507457852363586

Epoch: 6| Step: 8
Training loss: 1.4352607727050781
Validation loss: 2.056656320889791

Epoch: 6| Step: 9
Training loss: 0.9244643449783325
Validation loss: 2.0565222104390464

Epoch: 6| Step: 10
Training loss: 1.2454140186309814
Validation loss: 2.0845028360684714

Epoch: 6| Step: 11
Training loss: 1.4162139892578125
Validation loss: 2.0928879578908286

Epoch: 6| Step: 12
Training loss: 1.6268796920776367
Validation loss: 2.026959220568339

Epoch: 6| Step: 13
Training loss: 1.8368943929672241
Validation loss: 2.0499698321024575

Epoch: 85| Step: 0
Training loss: 2.1066198348999023
Validation loss: 2.0166800816853843

Epoch: 6| Step: 1
Training loss: 1.3819475173950195
Validation loss: 2.042889714241028

Epoch: 6| Step: 2
Training loss: 1.1986660957336426
Validation loss: 2.0299052596092224

Epoch: 6| Step: 3
Training loss: 1.5697801113128662
Validation loss: 2.026670674482981

Epoch: 6| Step: 4
Training loss: 1.1074331998825073
Validation loss: 2.0390914479891458

Epoch: 6| Step: 5
Training loss: 1.2172389030456543
Validation loss: 2.0890384912490845

Epoch: 6| Step: 6
Training loss: 1.0445160865783691
Validation loss: 2.046809415022532

Epoch: 6| Step: 7
Training loss: 1.472740888595581
Validation loss: 2.0703711907068887

Epoch: 6| Step: 8
Training loss: 1.3779414892196655
Validation loss: 2.0682666301727295

Epoch: 6| Step: 9
Training loss: 1.0008139610290527
Validation loss: 2.043913185596466

Epoch: 6| Step: 10
Training loss: 1.8410016298294067
Validation loss: 2.095972200234731

Epoch: 6| Step: 11
Training loss: 1.985743522644043
Validation loss: 2.0541063149770102

Epoch: 6| Step: 12
Training loss: 0.7980640530586243
Validation loss: 2.0367623567581177

Epoch: 6| Step: 13
Training loss: 1.5434105396270752
Validation loss: 1.9964816371599834

Epoch: 86| Step: 0
Training loss: 1.1987510919570923
Validation loss: 1.9861337343851726

Epoch: 6| Step: 1
Training loss: 1.171957015991211
Validation loss: 2.0344597895940146

Epoch: 6| Step: 2
Training loss: 1.0050535202026367
Validation loss: 2.0368701616923013

Epoch: 6| Step: 3
Training loss: 1.4162585735321045
Validation loss: 2.01468018690745

Epoch: 6| Step: 4
Training loss: 1.4461886882781982
Validation loss: 2.054204245408376

Epoch: 6| Step: 5
Training loss: 1.4827210903167725
Validation loss: 2.0391487081845603

Epoch: 6| Step: 6
Training loss: 1.2087231874465942
Validation loss: 2.102799912293752

Epoch: 6| Step: 7
Training loss: 1.8372957706451416
Validation loss: 2.069873829682668

Epoch: 6| Step: 8
Training loss: 1.0867559909820557
Validation loss: 2.0783207217852273

Epoch: 6| Step: 9
Training loss: 0.8861427307128906
Validation loss: 2.0617952744166055

Epoch: 6| Step: 10
Training loss: 1.4291640520095825
Validation loss: 2.083678940931956

Epoch: 6| Step: 11
Training loss: 1.7402838468551636
Validation loss: 2.029701073964437

Epoch: 6| Step: 12
Training loss: 1.2936644554138184
Validation loss: 2.037199079990387

Epoch: 6| Step: 13
Training loss: 1.6495469808578491
Validation loss: 1.9934739867846172

Epoch: 87| Step: 0
Training loss: 1.4417972564697266
Validation loss: 2.008636156717936

Epoch: 6| Step: 1
Training loss: 1.2283246517181396
Validation loss: 1.9800707300504048

Epoch: 6| Step: 2
Training loss: 1.1024227142333984
Validation loss: 1.9895035028457642

Epoch: 6| Step: 3
Training loss: 1.8447498083114624
Validation loss: 2.0055161913235984

Epoch: 6| Step: 4
Training loss: 1.4814780950546265
Validation loss: 2.007142722606659

Epoch: 6| Step: 5
Training loss: 1.6468536853790283
Validation loss: 2.0159427523612976

Epoch: 6| Step: 6
Training loss: 1.6795873641967773
Validation loss: 2.022004226843516

Epoch: 6| Step: 7
Training loss: 1.093991994857788
Validation loss: 2.0744526386260986

Epoch: 6| Step: 8
Training loss: 1.4198497533798218
Validation loss: 2.0476105411847434

Epoch: 6| Step: 9
Training loss: 0.939356803894043
Validation loss: 2.0544150869051614

Epoch: 6| Step: 10
Training loss: 1.593013048171997
Validation loss: 2.119052986303965

Epoch: 6| Step: 11
Training loss: 0.9888981580734253
Validation loss: 2.1151602466901145

Epoch: 6| Step: 12
Training loss: 1.7401018142700195
Validation loss: 2.0943719943364463

Epoch: 6| Step: 13
Training loss: 1.0810775756835938
Validation loss: 2.0788238644599915

Epoch: 88| Step: 0
Training loss: 1.3021758794784546
Validation loss: 2.048779288927714

Epoch: 6| Step: 1
Training loss: 1.3251574039459229
Validation loss: 2.03706427415212

Epoch: 6| Step: 2
Training loss: 1.9705166816711426
Validation loss: 2.0557586352030435

Epoch: 6| Step: 3
Training loss: 1.2340891361236572
Validation loss: 2.0035570859909058

Epoch: 6| Step: 4
Training loss: 1.4331097602844238
Validation loss: 2.0591149727503457

Epoch: 6| Step: 5
Training loss: 1.3816485404968262
Validation loss: 2.0412678917249045

Epoch: 6| Step: 6
Training loss: 1.2669410705566406
Validation loss: 2.018939952055613

Epoch: 6| Step: 7
Training loss: 1.0251410007476807
Validation loss: 2.0118500192960105

Epoch: 6| Step: 8
Training loss: 1.3381952047348022
Validation loss: 2.015490452448527

Epoch: 6| Step: 9
Training loss: 1.185719609260559
Validation loss: 2.01412425438563

Epoch: 6| Step: 10
Training loss: 1.2314975261688232
Validation loss: 2.0229829947153726

Epoch: 6| Step: 11
Training loss: 0.6610450744628906
Validation loss: 2.0249801675478616

Epoch: 6| Step: 12
Training loss: 1.285231113433838
Validation loss: 2.0208112001419067

Epoch: 6| Step: 13
Training loss: 1.7123699188232422
Validation loss: 2.000741442044576

Epoch: 89| Step: 0
Training loss: 0.8402915000915527
Validation loss: 2.0106825033823648

Epoch: 6| Step: 1
Training loss: 0.6855481266975403
Validation loss: 2.059438467025757

Epoch: 6| Step: 2
Training loss: 2.3534467220306396
Validation loss: 2.0899882713953652

Epoch: 6| Step: 3
Training loss: 0.9973276257514954
Validation loss: 2.094188710053762

Epoch: 6| Step: 4
Training loss: 1.113417387008667
Validation loss: 2.0770832101504006

Epoch: 6| Step: 5
Training loss: 1.5523544549942017
Validation loss: 2.0442829926808677

Epoch: 6| Step: 6
Training loss: 1.5546023845672607
Validation loss: 2.0343502163887024

Epoch: 6| Step: 7
Training loss: 1.010405421257019
Validation loss: 2.0290326873461404

Epoch: 6| Step: 8
Training loss: 0.8829484581947327
Validation loss: 2.0186749498049417

Epoch: 6| Step: 9
Training loss: 1.372085690498352
Validation loss: 1.9968254566192627

Epoch: 6| Step: 10
Training loss: 1.462562084197998
Validation loss: 1.9967974026997883

Epoch: 6| Step: 11
Training loss: 1.4449903964996338
Validation loss: 2.0001064340273538

Epoch: 6| Step: 12
Training loss: 1.325094223022461
Validation loss: 1.9445198774337769

Epoch: 6| Step: 13
Training loss: 1.6654975414276123
Validation loss: 2.015997052192688

Epoch: 90| Step: 0
Training loss: 1.4707891941070557
Validation loss: 2.038468619187673

Epoch: 6| Step: 1
Training loss: 1.4873017072677612
Validation loss: 2.0548333128293357

Epoch: 6| Step: 2
Training loss: 1.3253697156906128
Validation loss: 2.096318085988363

Epoch: 6| Step: 3
Training loss: 0.9871361255645752
Validation loss: 2.061170240243276

Epoch: 6| Step: 4
Training loss: 1.1983126401901245
Validation loss: 2.0400419433911643

Epoch: 6| Step: 5
Training loss: 1.240356206893921
Validation loss: 2.05275289217631

Epoch: 6| Step: 6
Training loss: 1.3953443765640259
Validation loss: 2.055789570013682

Epoch: 6| Step: 7
Training loss: 1.1952388286590576
Validation loss: 2.026606023311615

Epoch: 6| Step: 8
Training loss: 1.074358344078064
Validation loss: 2.018099784851074

Epoch: 6| Step: 9
Training loss: 1.4495811462402344
Validation loss: 1.981411079565684

Epoch: 6| Step: 10
Training loss: 1.4791513681411743
Validation loss: 2.006725331147512

Epoch: 6| Step: 11
Training loss: 0.758403480052948
Validation loss: 1.9995680054028828

Epoch: 6| Step: 12
Training loss: 1.3958117961883545
Validation loss: 2.014308591683706

Epoch: 6| Step: 13
Training loss: 1.7480182647705078
Validation loss: 2.0222952564557395

Epoch: 91| Step: 0
Training loss: 1.3956934213638306
Validation loss: 2.026865382989248

Epoch: 6| Step: 1
Training loss: 0.9417421817779541
Validation loss: 1.990007797876994

Epoch: 6| Step: 2
Training loss: 1.3670544624328613
Validation loss: 2.027919511000315

Epoch: 6| Step: 3
Training loss: 1.0264217853546143
Validation loss: 2.0125165383021035

Epoch: 6| Step: 4
Training loss: 1.5801997184753418
Validation loss: 2.0805882016817727

Epoch: 6| Step: 5
Training loss: 1.3063466548919678
Validation loss: 2.0143392086029053

Epoch: 6| Step: 6
Training loss: 1.7442526817321777
Validation loss: 2.0724715987841287

Epoch: 6| Step: 7
Training loss: 1.672488808631897
Validation loss: 1.99311097462972

Epoch: 6| Step: 8
Training loss: 1.2905468940734863
Validation loss: 1.964744210243225

Epoch: 6| Step: 9
Training loss: 0.8256968855857849
Validation loss: 2.0286248127619424

Epoch: 6| Step: 10
Training loss: 0.9491268396377563
Validation loss: 2.015466491381327

Epoch: 6| Step: 11
Training loss: 1.6659417152404785
Validation loss: 2.020349065462748

Epoch: 6| Step: 12
Training loss: 0.8076213598251343
Validation loss: 2.0164414445559182

Epoch: 6| Step: 13
Training loss: 1.6803187131881714
Validation loss: 1.9990636507670085

Epoch: 92| Step: 0
Training loss: 1.2084097862243652
Validation loss: 2.0131835341453552

Epoch: 6| Step: 1
Training loss: 1.3465936183929443
Validation loss: 1.986950119336446

Epoch: 6| Step: 2
Training loss: 1.5202281475067139
Validation loss: 2.010627726713816

Epoch: 6| Step: 3
Training loss: 0.7769843935966492
Validation loss: 2.0084698597590127

Epoch: 6| Step: 4
Training loss: 0.9090570211410522
Validation loss: 2.0371501048405967

Epoch: 6| Step: 5
Training loss: 1.3552685976028442
Validation loss: 1.9833014011383057

Epoch: 6| Step: 6
Training loss: 1.2642438411712646
Validation loss: 2.041752656300863

Epoch: 6| Step: 7
Training loss: 1.0148481130599976
Validation loss: 2.0233609875043235

Epoch: 6| Step: 8
Training loss: 1.2249544858932495
Validation loss: 2.0052415331204734

Epoch: 6| Step: 9
Training loss: 1.0180766582489014
Validation loss: 2.03760035832723

Epoch: 6| Step: 10
Training loss: 1.573922872543335
Validation loss: 2.0522201458613076

Epoch: 6| Step: 11
Training loss: 1.560309648513794
Validation loss: 2.0583512584368386

Epoch: 6| Step: 12
Training loss: 1.284825325012207
Validation loss: 2.0034997860590615

Epoch: 6| Step: 13
Training loss: 1.5876944065093994
Validation loss: 2.018288274606069

Epoch: 93| Step: 0
Training loss: 0.7449071407318115
Validation loss: 2.0266082088152566

Epoch: 6| Step: 1
Training loss: 1.9472112655639648
Validation loss: 2.0354872941970825

Epoch: 6| Step: 2
Training loss: 1.2150219678878784
Validation loss: 2.0126160383224487

Epoch: 6| Step: 3
Training loss: 1.138420820236206
Validation loss: 2.0228383541107178

Epoch: 6| Step: 4
Training loss: 1.3071224689483643
Validation loss: 2.006951550642649

Epoch: 6| Step: 5
Training loss: 1.5829755067825317
Validation loss: 2.022712747255961

Epoch: 6| Step: 6
Training loss: 1.175093650817871
Validation loss: 2.029969056447347

Epoch: 6| Step: 7
Training loss: 1.5648305416107178
Validation loss: 2.0260977745056152

Epoch: 6| Step: 8
Training loss: 1.1594136953353882
Validation loss: 2.04426771402359

Epoch: 6| Step: 9
Training loss: 1.5191243886947632
Validation loss: 2.0365298986434937

Epoch: 6| Step: 10
Training loss: 0.7251169681549072
Validation loss: 2.0090829332669577

Epoch: 6| Step: 11
Training loss: 1.0404562950134277
Validation loss: 2.0298124154408774

Epoch: 6| Step: 12
Training loss: 1.5101771354675293
Validation loss: 2.0103201071421304

Epoch: 6| Step: 13
Training loss: 0.8802191019058228
Validation loss: 2.036316156387329

Epoch: 94| Step: 0
Training loss: 1.0961995124816895
Validation loss: 1.958194116751353

Epoch: 6| Step: 1
Training loss: 1.2311424016952515
Validation loss: 2.0331037044525146

Epoch: 6| Step: 2
Training loss: 1.118459701538086
Validation loss: 1.9877627889315288

Epoch: 6| Step: 3
Training loss: 0.955506443977356
Validation loss: 1.977952818075816

Epoch: 6| Step: 4
Training loss: 2.1604790687561035
Validation loss: 2.0275710225105286

Epoch: 6| Step: 5
Training loss: 1.5442595481872559
Validation loss: 2.0179651578267417

Epoch: 6| Step: 6
Training loss: 1.0853407382965088
Validation loss: 2.022702674070994

Epoch: 6| Step: 7
Training loss: 0.9486830234527588
Validation loss: 2.0332475701967874

Epoch: 6| Step: 8
Training loss: 0.8910961747169495
Validation loss: 2.0650379061698914

Epoch: 6| Step: 9
Training loss: 0.9759849309921265
Validation loss: 2.000759700934092

Epoch: 6| Step: 10
Training loss: 1.5686109066009521
Validation loss: 2.0952748457590737

Epoch: 6| Step: 11
Training loss: 1.4544610977172852
Validation loss: 2.0727418859799704

Epoch: 6| Step: 12
Training loss: 1.27531898021698
Validation loss: 2.0543532371520996

Epoch: 6| Step: 13
Training loss: 1.0684492588043213
Validation loss: 2.057283620039622

Epoch: 95| Step: 0
Training loss: 1.528367042541504
Validation loss: 1.9958457152048747

Epoch: 6| Step: 1
Training loss: 1.4635577201843262
Validation loss: 2.013322194417318

Epoch: 6| Step: 2
Training loss: 1.2012524604797363
Validation loss: 1.9811161359151204

Epoch: 6| Step: 3
Training loss: 1.2337062358856201
Validation loss: 2.0077391862869263

Epoch: 6| Step: 4
Training loss: 1.026389241218567
Validation loss: 1.9772227207819622

Epoch: 6| Step: 5
Training loss: 1.2759184837341309
Validation loss: 2.0225993196169534

Epoch: 6| Step: 6
Training loss: 0.937507152557373
Validation loss: 2.060097257296244

Epoch: 6| Step: 7
Training loss: 1.9536588191986084
Validation loss: 2.073876917362213

Epoch: 6| Step: 8
Training loss: 0.9037488698959351
Validation loss: 2.0579653779665628

Epoch: 6| Step: 9
Training loss: 1.1245672702789307
Validation loss: 2.042212883631388

Epoch: 6| Step: 10
Training loss: 1.3660237789154053
Validation loss: 1.9992527763048809

Epoch: 6| Step: 11
Training loss: 1.1716322898864746
Validation loss: 2.027552346388499

Epoch: 6| Step: 12
Training loss: 0.9378187656402588
Validation loss: 2.0333179235458374

Epoch: 6| Step: 13
Training loss: 1.292427897453308
Validation loss: 2.0426542162895203

Epoch: 96| Step: 0
Training loss: 1.2202568054199219
Validation loss: 2.0205175479253135

Epoch: 6| Step: 1
Training loss: 1.4776101112365723
Validation loss: 2.048851470152537

Epoch: 6| Step: 2
Training loss: 1.457876443862915
Validation loss: 2.0230161945025125

Epoch: 6| Step: 3
Training loss: 0.9637414216995239
Validation loss: 2.010096549987793

Epoch: 6| Step: 4
Training loss: 1.311630129814148
Validation loss: 2.030778229236603

Epoch: 6| Step: 5
Training loss: 0.9471355676651001
Validation loss: 1.9988626440366108

Epoch: 6| Step: 6
Training loss: 1.3298313617706299
Validation loss: 2.0128737489382424

Epoch: 6| Step: 7
Training loss: 1.7973434925079346
Validation loss: 1.9859346747398376

Epoch: 6| Step: 8
Training loss: 1.414669156074524
Validation loss: 2.021399279435476

Epoch: 6| Step: 9
Training loss: 0.7650419473648071
Validation loss: 1.9782767097155254

Epoch: 6| Step: 10
Training loss: 0.8231256604194641
Validation loss: 2.053249716758728

Epoch: 6| Step: 11
Training loss: 1.1604269742965698
Validation loss: 2.0401540795962014

Epoch: 6| Step: 12
Training loss: 0.999186635017395
Validation loss: 2.051024933656057

Epoch: 6| Step: 13
Training loss: 1.6462342739105225
Validation loss: 2.0460991859436035

Epoch: 97| Step: 0
Training loss: 1.0903725624084473
Validation loss: 2.0266366004943848

Epoch: 6| Step: 1
Training loss: 1.3461741209030151
Validation loss: 1.9964570601781209

Epoch: 6| Step: 2
Training loss: 0.9335156679153442
Validation loss: 1.9877630869547527

Epoch: 6| Step: 3
Training loss: 1.110152244567871
Validation loss: 1.9918402632077534

Epoch: 6| Step: 4
Training loss: 1.133621335029602
Validation loss: 2.031655192375183

Epoch: 6| Step: 5
Training loss: 1.213226079940796
Validation loss: 1.9769219954808552

Epoch: 6| Step: 6
Training loss: 0.9021671414375305
Validation loss: 2.0048643946647644

Epoch: 6| Step: 7
Training loss: 1.2490445375442505
Validation loss: 2.0386687914530435

Epoch: 6| Step: 8
Training loss: 1.826320767402649
Validation loss: 2.0174394051233926

Epoch: 6| Step: 9
Training loss: 0.9499284625053406
Validation loss: 2.0486451586087546

Epoch: 6| Step: 10
Training loss: 0.9816255569458008
Validation loss: 2.04178923368454

Epoch: 6| Step: 11
Training loss: 1.229148030281067
Validation loss: 2.0344074964523315

Epoch: 6| Step: 12
Training loss: 1.405295968055725
Validation loss: 2.0066997011502585

Epoch: 6| Step: 13
Training loss: 1.0255370140075684
Validation loss: 2.0201474825541177

Epoch: 98| Step: 0
Training loss: 0.6771579384803772
Validation loss: 2.0913984378178916

Epoch: 6| Step: 1
Training loss: 1.2196133136749268
Validation loss: 2.0094322760899863

Epoch: 6| Step: 2
Training loss: 1.1698102951049805
Validation loss: 2.0232166846593223

Epoch: 6| Step: 3
Training loss: 0.975472092628479
Validation loss: 1.9341802994410198

Epoch: 6| Step: 4
Training loss: 1.0006141662597656
Validation loss: 1.983589728673299

Epoch: 6| Step: 5
Training loss: 1.0714011192321777
Validation loss: 1.972604791323344

Epoch: 6| Step: 6
Training loss: 1.1900339126586914
Validation loss: 2.011764387289683

Epoch: 6| Step: 7
Training loss: 1.531083106994629
Validation loss: 1.9983293016751607

Epoch: 6| Step: 8
Training loss: 1.1647374629974365
Validation loss: 1.9859283963839214

Epoch: 6| Step: 9
Training loss: 2.0329017639160156
Validation loss: 2.0088187058766684

Epoch: 6| Step: 10
Training loss: 1.4789313077926636
Validation loss: 1.9831270774205525

Epoch: 6| Step: 11
Training loss: 0.9268878698348999
Validation loss: 1.9985904097557068

Epoch: 6| Step: 12
Training loss: 0.8276687264442444
Validation loss: 1.9968797365824382

Epoch: 6| Step: 13
Training loss: 1.3960096836090088
Validation loss: 1.9698918461799622

Epoch: 99| Step: 0
Training loss: 1.409893274307251
Validation loss: 2.01224821805954

Epoch: 6| Step: 1
Training loss: 0.7573001384735107
Validation loss: 2.04863174756368

Epoch: 6| Step: 2
Training loss: 1.364446759223938
Validation loss: 1.9674671093622844

Epoch: 6| Step: 3
Training loss: 0.9547172784805298
Validation loss: 2.004834314187368

Epoch: 6| Step: 4
Training loss: 0.7787542343139648
Validation loss: 2.0130274097124734

Epoch: 6| Step: 5
Training loss: 1.0694866180419922
Validation loss: 1.9998316963513691

Epoch: 6| Step: 6
Training loss: 1.2167131900787354
Validation loss: 1.956519623597463

Epoch: 6| Step: 7
Training loss: 1.331350564956665
Validation loss: 1.969287892182668

Epoch: 6| Step: 8
Training loss: 1.6552989482879639
Validation loss: 2.0362829764684043

Epoch: 6| Step: 9
Training loss: 1.2357831001281738
Validation loss: 2.000668485959371

Epoch: 6| Step: 10
Training loss: 1.3548495769500732
Validation loss: 2.0181361635526023

Epoch: 6| Step: 11
Training loss: 1.0993214845657349
Validation loss: 2.1005985736846924

Epoch: 6| Step: 12
Training loss: 0.8880680203437805
Validation loss: 2.0056391755739846

Epoch: 6| Step: 13
Training loss: 1.1952338218688965
Validation loss: 1.94684894879659

Epoch: 100| Step: 0
Training loss: 0.9254571199417114
Validation loss: 2.049425741036733

Epoch: 6| Step: 1
Training loss: 1.4843730926513672
Validation loss: 1.9439284205436707

Epoch: 6| Step: 2
Training loss: 1.1312730312347412
Validation loss: 2.003986040751139

Epoch: 6| Step: 3
Training loss: 0.8289455771446228
Validation loss: 1.9631636540095012

Epoch: 6| Step: 4
Training loss: 1.5925592184066772
Validation loss: 1.966246525446574

Epoch: 6| Step: 5
Training loss: 1.0622544288635254
Validation loss: 1.991518457730611

Epoch: 6| Step: 6
Training loss: 1.5750218629837036
Validation loss: 2.0525591174761453

Epoch: 6| Step: 7
Training loss: 1.4151026010513306
Validation loss: 2.132427473862966

Epoch: 6| Step: 8
Training loss: 0.6438012719154358
Validation loss: 2.1267244617144265

Epoch: 6| Step: 9
Training loss: 1.0476728677749634
Validation loss: 2.0893471439679465

Epoch: 6| Step: 10
Training loss: 1.370383381843567
Validation loss: 2.028476357460022

Epoch: 6| Step: 11
Training loss: 1.7830328941345215
Validation loss: 1.9663939277331035

Epoch: 6| Step: 12
Training loss: 1.2731678485870361
Validation loss: 1.9802902539571126

Epoch: 6| Step: 13
Training loss: 1.3596009016036987
Validation loss: 1.959851582845052

Epoch: 101| Step: 0
Training loss: 1.1498688459396362
Validation loss: 1.987780789534251

Epoch: 6| Step: 1
Training loss: 0.9128788113594055
Validation loss: 1.9491858283678691

Epoch: 6| Step: 2
Training loss: 1.3106954097747803
Validation loss: 1.9225746393203735

Epoch: 6| Step: 3
Training loss: 1.0228270292282104
Validation loss: 1.9726622700691223

Epoch: 6| Step: 4
Training loss: 1.7555909156799316
Validation loss: 1.9448418219884236

Epoch: 6| Step: 5
Training loss: 1.7213094234466553
Validation loss: 1.9759445786476135

Epoch: 6| Step: 6
Training loss: 1.0378491878509521
Validation loss: 2.009894371032715

Epoch: 6| Step: 7
Training loss: 1.0367978811264038
Validation loss: 2.0076703230539956

Epoch: 6| Step: 8
Training loss: 1.101373314857483
Validation loss: 2.0470154682795205

Epoch: 6| Step: 9
Training loss: 1.6223955154418945
Validation loss: 2.020252545674642

Epoch: 6| Step: 10
Training loss: 0.9287707805633545
Validation loss: 1.988017996152242

Epoch: 6| Step: 11
Training loss: 0.9803420305252075
Validation loss: 1.9824780027071636

Epoch: 6| Step: 12
Training loss: 0.9127450585365295
Validation loss: 1.943366825580597

Epoch: 6| Step: 13
Training loss: 0.541401207447052
Validation loss: 1.9616834322611492

Epoch: 102| Step: 0
Training loss: 1.4953792095184326
Validation loss: 2.023702243963877

Epoch: 6| Step: 1
Training loss: 1.5337480306625366
Validation loss: 1.9658148884773254

Epoch: 6| Step: 2
Training loss: 1.3906676769256592
Validation loss: 2.008174022038778

Epoch: 6| Step: 3
Training loss: 0.7991437911987305
Validation loss: 1.988569438457489

Epoch: 6| Step: 4
Training loss: 0.838701069355011
Validation loss: 2.0027949015299478

Epoch: 6| Step: 5
Training loss: 0.9666731357574463
Validation loss: 1.9701001445452373

Epoch: 6| Step: 6
Training loss: 0.8470127582550049
Validation loss: 2.040823002656301

Epoch: 6| Step: 7
Training loss: 1.8645989894866943
Validation loss: 2.087399125099182

Epoch: 6| Step: 8
Training loss: 1.2137641906738281
Validation loss: 2.0466320315996804

Epoch: 6| Step: 9
Training loss: 1.0089863538742065
Validation loss: 2.002219100793203

Epoch: 6| Step: 10
Training loss: 0.8770132064819336
Validation loss: 2.0091803471247354

Epoch: 6| Step: 11
Training loss: 0.6552948951721191
Validation loss: 1.9899062315622966

Epoch: 6| Step: 12
Training loss: 1.5728477239608765
Validation loss: 2.0311195651690164

Epoch: 6| Step: 13
Training loss: 1.0365090370178223
Validation loss: 2.009793202082316

Epoch: 103| Step: 0
Training loss: 1.1139487028121948
Validation loss: 1.9535493850708008

Epoch: 6| Step: 1
Training loss: 1.3115568161010742
Validation loss: 2.0182402531305947

Epoch: 6| Step: 2
Training loss: 1.4441022872924805
Validation loss: 2.025201598803202

Epoch: 6| Step: 3
Training loss: 1.4922678470611572
Validation loss: 2.0217886567115784

Epoch: 6| Step: 4
Training loss: 0.8683357238769531
Validation loss: 2.025322596232096

Epoch: 6| Step: 5
Training loss: 0.5397403240203857
Validation loss: 2.002703368663788

Epoch: 6| Step: 6
Training loss: 0.8657791018486023
Validation loss: 1.9694538513819377

Epoch: 6| Step: 7
Training loss: 0.8145478367805481
Validation loss: 1.9532055656115215

Epoch: 6| Step: 8
Training loss: 1.203009843826294
Validation loss: 1.9427536328633626

Epoch: 6| Step: 9
Training loss: 1.6759092807769775
Validation loss: 1.9935040871302288

Epoch: 6| Step: 10
Training loss: 1.3041346073150635
Validation loss: 2.022873878479004

Epoch: 6| Step: 11
Training loss: 1.0195581912994385
Validation loss: 1.9660287698109944

Epoch: 6| Step: 12
Training loss: 1.1838277578353882
Validation loss: 1.962810715039571

Epoch: 6| Step: 13
Training loss: 0.9688318967819214
Validation loss: 1.9776646693547566

Epoch: 104| Step: 0
Training loss: 0.840046763420105
Validation loss: 1.9697770078976948

Epoch: 6| Step: 1
Training loss: 1.05623459815979
Validation loss: 1.9978957573572795

Epoch: 6| Step: 2
Training loss: 0.9837897419929504
Validation loss: 2.018115977446238

Epoch: 6| Step: 3
Training loss: 1.8060798645019531
Validation loss: 1.9821425477663677

Epoch: 6| Step: 4
Training loss: 0.9790735840797424
Validation loss: 1.9782416621843975

Epoch: 6| Step: 5
Training loss: 0.9703942537307739
Validation loss: 2.001804212729136

Epoch: 6| Step: 6
Training loss: 1.3382632732391357
Validation loss: 1.9533133109410603

Epoch: 6| Step: 7
Training loss: 1.539060354232788
Validation loss: 1.985548158486684

Epoch: 6| Step: 8
Training loss: 1.6201763153076172
Validation loss: 2.0247649947802224

Epoch: 6| Step: 9
Training loss: 0.5981963276863098
Validation loss: 1.9521100123723347

Epoch: 6| Step: 10
Training loss: 0.5697663426399231
Validation loss: 1.9651314218839009

Epoch: 6| Step: 11
Training loss: 1.080725073814392
Validation loss: 2.0000672340393066

Epoch: 6| Step: 12
Training loss: 1.1822457313537598
Validation loss: 2.024859627087911

Epoch: 6| Step: 13
Training loss: 0.9731921553611755
Validation loss: 2.005439023176829

Epoch: 105| Step: 0
Training loss: 1.0636266469955444
Validation loss: 1.966827968756358

Epoch: 6| Step: 1
Training loss: 0.5809696912765503
Validation loss: 2.024334172407786

Epoch: 6| Step: 2
Training loss: 1.0051482915878296
Validation loss: 2.002512276172638

Epoch: 6| Step: 3
Training loss: 1.4435827732086182
Validation loss: 1.9995633562405903

Epoch: 6| Step: 4
Training loss: 0.6834712028503418
Validation loss: 1.9657445748647053

Epoch: 6| Step: 5
Training loss: 0.7368050217628479
Validation loss: 1.9629680911699932

Epoch: 6| Step: 6
Training loss: 1.042425274848938
Validation loss: 1.96447358528773

Epoch: 6| Step: 7
Training loss: 1.5005838871002197
Validation loss: 1.9469545086224873

Epoch: 6| Step: 8
Training loss: 1.012213945388794
Validation loss: 1.9655967752138774

Epoch: 6| Step: 9
Training loss: 1.1112143993377686
Validation loss: 1.9806504050890605

Epoch: 6| Step: 10
Training loss: 1.4176766872406006
Validation loss: 1.9664443532625835

Epoch: 6| Step: 11
Training loss: 1.6105413436889648
Validation loss: 1.992067774136861

Epoch: 6| Step: 12
Training loss: 1.0818438529968262
Validation loss: 1.9790148933728535

Epoch: 6| Step: 13
Training loss: 1.1135308742523193
Validation loss: 1.9365959366162617

Epoch: 106| Step: 0
Training loss: 0.5673922300338745
Validation loss: 1.9282449682553608

Epoch: 6| Step: 1
Training loss: 1.6228103637695312
Validation loss: 2.007339278856913

Epoch: 6| Step: 2
Training loss: 1.2863502502441406
Validation loss: 1.9213761289914448

Epoch: 6| Step: 3
Training loss: 0.7455288171768188
Validation loss: 2.002266764640808

Epoch: 6| Step: 4
Training loss: 0.76401287317276
Validation loss: 1.9755703608194988

Epoch: 6| Step: 5
Training loss: 1.479900598526001
Validation loss: 1.923306902249654

Epoch: 6| Step: 6
Training loss: 0.8283195495605469
Validation loss: 1.9935209552447002

Epoch: 6| Step: 7
Training loss: 1.3301371335983276
Validation loss: 1.9395915468533833

Epoch: 6| Step: 8
Training loss: 0.6796829104423523
Validation loss: 2.0275044043858848

Epoch: 6| Step: 9
Training loss: 1.4764678478240967
Validation loss: 1.9785061677296956

Epoch: 6| Step: 10
Training loss: 1.2798805236816406
Validation loss: 2.0724761486053467

Epoch: 6| Step: 11
Training loss: 1.1255239248275757
Validation loss: 2.0599833329518638

Epoch: 6| Step: 12
Training loss: 1.218315601348877
Validation loss: 2.008005360762278

Epoch: 6| Step: 13
Training loss: 1.2407855987548828
Validation loss: 2.027076005935669

Epoch: 107| Step: 0
Training loss: 0.7823816537857056
Validation loss: 1.9914543430010478

Epoch: 6| Step: 1
Training loss: 1.188354253768921
Validation loss: 1.9955691893895466

Epoch: 6| Step: 2
Training loss: 1.518019676208496
Validation loss: 1.9566013018290203

Epoch: 6| Step: 3
Training loss: 0.7422341108322144
Validation loss: 1.9654364585876465

Epoch: 6| Step: 4
Training loss: 1.3536094427108765
Validation loss: 1.9960904121398926

Epoch: 6| Step: 5
Training loss: 1.1628285646438599
Validation loss: 1.9632637898127239

Epoch: 6| Step: 6
Training loss: 0.9860097169876099
Validation loss: 2.004223565260569

Epoch: 6| Step: 7
Training loss: 0.9879657626152039
Validation loss: 1.9634097417195637

Epoch: 6| Step: 8
Training loss: 0.832869827747345
Validation loss: 1.9352539579073589

Epoch: 6| Step: 9
Training loss: 1.0527710914611816
Validation loss: 1.9828302065531414

Epoch: 6| Step: 10
Training loss: 0.8247780799865723
Validation loss: 2.002278129259745

Epoch: 6| Step: 11
Training loss: 1.6554653644561768
Validation loss: 1.9387681484222412

Epoch: 6| Step: 12
Training loss: 1.1069362163543701
Validation loss: 1.9712692896525066

Epoch: 6| Step: 13
Training loss: 0.9133476614952087
Validation loss: 1.990137775739034

Epoch: 108| Step: 0
Training loss: 0.8438761234283447
Validation loss: 1.9438962936401367

Epoch: 6| Step: 1
Training loss: 1.202155590057373
Validation loss: 2.000907520453135

Epoch: 6| Step: 2
Training loss: 1.0014374256134033
Validation loss: 2.0160542130470276

Epoch: 6| Step: 3
Training loss: 1.261772871017456
Validation loss: 1.98690527677536

Epoch: 6| Step: 4
Training loss: 0.8541352152824402
Validation loss: 1.9304057161013286

Epoch: 6| Step: 5
Training loss: 1.8617393970489502
Validation loss: 1.9154004057248433

Epoch: 6| Step: 6
Training loss: 1.1668212413787842
Validation loss: 1.9605882167816162

Epoch: 6| Step: 7
Training loss: 0.9979708790779114
Validation loss: 1.950363556543986

Epoch: 6| Step: 8
Training loss: 0.7699742913246155
Validation loss: 1.9349306623140972

Epoch: 6| Step: 9
Training loss: 0.9439699053764343
Validation loss: 1.9295313755671184

Epoch: 6| Step: 10
Training loss: 1.0541753768920898
Validation loss: 1.9854216972986858

Epoch: 6| Step: 11
Training loss: 1.004408597946167
Validation loss: 1.9680561621983845

Epoch: 6| Step: 12
Training loss: 0.851056694984436
Validation loss: 1.9223439296086628

Epoch: 6| Step: 13
Training loss: 0.6647887229919434
Validation loss: 1.9408891797065735

Epoch: 109| Step: 0
Training loss: 1.0363723039627075
Validation loss: 1.916832943757375

Epoch: 6| Step: 1
Training loss: 1.3002398014068604
Validation loss: 1.9483723044395447

Epoch: 6| Step: 2
Training loss: 0.8067288398742676
Validation loss: 1.9727559288342793

Epoch: 6| Step: 3
Training loss: 1.3290594816207886
Validation loss: 1.9834309220314026

Epoch: 6| Step: 4
Training loss: 1.3771686553955078
Validation loss: 2.0365607341130576

Epoch: 6| Step: 5
Training loss: 0.6911088824272156
Validation loss: 2.0216758251190186

Epoch: 6| Step: 6
Training loss: 0.9483901262283325
Validation loss: 1.9775023460388184

Epoch: 6| Step: 7
Training loss: 0.6145588755607605
Validation loss: 1.9505533973375957

Epoch: 6| Step: 8
Training loss: 0.858539879322052
Validation loss: 1.916751464207967

Epoch: 6| Step: 9
Training loss: 1.125221848487854
Validation loss: 1.9481223026911418

Epoch: 6| Step: 10
Training loss: 0.7590506672859192
Validation loss: 1.9385543664296467

Epoch: 6| Step: 11
Training loss: 1.1658198833465576
Validation loss: 1.9000379641850789

Epoch: 6| Step: 12
Training loss: 1.559462547302246
Validation loss: 1.9461361567179363

Epoch: 6| Step: 13
Training loss: 1.3914613723754883
Validation loss: 1.9730684558550518

Epoch: 110| Step: 0
Training loss: 1.1895332336425781
Validation loss: 1.9795284469922383

Epoch: 6| Step: 1
Training loss: 1.0478873252868652
Validation loss: 2.0128423968950906

Epoch: 6| Step: 2
Training loss: 1.0720250606536865
Validation loss: 1.9931763013203938

Epoch: 6| Step: 3
Training loss: 1.2894680500030518
Validation loss: 2.114499509334564

Epoch: 6| Step: 4
Training loss: 1.034328579902649
Validation loss: 2.02598104874293

Epoch: 6| Step: 5
Training loss: 1.0458810329437256
Validation loss: 2.0230804483095803

Epoch: 6| Step: 6
Training loss: 0.7968336343765259
Validation loss: 1.9396441181500752

Epoch: 6| Step: 7
Training loss: 0.8110318183898926
Validation loss: 1.972256342569987

Epoch: 6| Step: 8
Training loss: 1.298406720161438
Validation loss: 1.9857169389724731

Epoch: 6| Step: 9
Training loss: 1.340799331665039
Validation loss: 1.9480575521787007

Epoch: 6| Step: 10
Training loss: 1.2268691062927246
Validation loss: 1.9533819754918416

Epoch: 6| Step: 11
Training loss: 0.7344532012939453
Validation loss: 1.9299777150154114

Epoch: 6| Step: 12
Training loss: 1.0533615350723267
Validation loss: 1.948811650276184

Epoch: 6| Step: 13
Training loss: 1.769313097000122
Validation loss: 2.010857860247294

Epoch: 111| Step: 0
Training loss: 1.0355801582336426
Validation loss: 2.0537059903144836

Epoch: 6| Step: 1
Training loss: 0.8052063584327698
Validation loss: 2.099483847618103

Epoch: 6| Step: 2
Training loss: 1.3176788091659546
Validation loss: 2.101665496826172

Epoch: 6| Step: 3
Training loss: 1.5287373065948486
Validation loss: 2.0048256317774453

Epoch: 6| Step: 4
Training loss: 1.1413655281066895
Validation loss: 1.9727548559506733

Epoch: 6| Step: 5
Training loss: 1.672437071800232
Validation loss: 1.9941241939862568

Epoch: 6| Step: 6
Training loss: 0.9245768785476685
Validation loss: 1.9627327521642048

Epoch: 6| Step: 7
Training loss: 1.3075817823410034
Validation loss: 1.966894268989563

Epoch: 6| Step: 8
Training loss: 0.7458066344261169
Validation loss: 1.9756085872650146

Epoch: 6| Step: 9
Training loss: 0.8033514022827148
Validation loss: 1.9505159656206768

Epoch: 6| Step: 10
Training loss: 0.6619526147842407
Validation loss: 1.909050464630127

Epoch: 6| Step: 11
Training loss: 1.018531322479248
Validation loss: 1.9733806053797405

Epoch: 6| Step: 12
Training loss: 1.0875407457351685
Validation loss: 2.0216586192448935

Epoch: 6| Step: 13
Training loss: 0.954162061214447
Validation loss: 2.0270217458407083

Epoch: 112| Step: 0
Training loss: 0.9547876119613647
Validation loss: 2.0373697876930237

Epoch: 6| Step: 1
Training loss: 0.992858350276947
Validation loss: 2.063595453898112

Epoch: 6| Step: 2
Training loss: 1.2225922346115112
Validation loss: 2.090236485004425

Epoch: 6| Step: 3
Training loss: 0.8872727751731873
Validation loss: 2.0595891873041787

Epoch: 6| Step: 4
Training loss: 0.7000317573547363
Validation loss: 2.015118678410848

Epoch: 6| Step: 5
Training loss: 0.9643282890319824
Validation loss: 1.940136690934499

Epoch: 6| Step: 6
Training loss: 0.7751293182373047
Validation loss: 1.9494826594988506

Epoch: 6| Step: 7
Training loss: 1.6184358596801758
Validation loss: 1.9048688213030498

Epoch: 6| Step: 8
Training loss: 0.9526861310005188
Validation loss: 1.939594566822052

Epoch: 6| Step: 9
Training loss: 1.1063425540924072
Validation loss: 1.9132337371508281

Epoch: 6| Step: 10
Training loss: 1.2772164344787598
Validation loss: 1.986691455046336

Epoch: 6| Step: 11
Training loss: 0.9819021821022034
Validation loss: 1.9459919134775798

Epoch: 6| Step: 12
Training loss: 0.9732704162597656
Validation loss: 1.9914497534434001

Epoch: 6| Step: 13
Training loss: 1.3051526546478271
Validation loss: 2.0299778978029885

Epoch: 113| Step: 0
Training loss: 1.4436445236206055
Validation loss: 2.031141221523285

Epoch: 6| Step: 1
Training loss: 0.9851702451705933
Validation loss: 2.000837524731954

Epoch: 6| Step: 2
Training loss: 1.2382268905639648
Validation loss: 2.015673339366913

Epoch: 6| Step: 3
Training loss: 0.7868640422821045
Validation loss: 2.0110536019007363

Epoch: 6| Step: 4
Training loss: 1.248349905014038
Validation loss: 1.928091009457906

Epoch: 6| Step: 5
Training loss: 1.2578206062316895
Validation loss: 1.9427141149838765

Epoch: 6| Step: 6
Training loss: 0.6963309645652771
Validation loss: 1.9539744853973389

Epoch: 6| Step: 7
Training loss: 1.6191455125808716
Validation loss: 1.9377244710922241

Epoch: 6| Step: 8
Training loss: 0.8036247491836548
Validation loss: 1.994465430577596

Epoch: 6| Step: 9
Training loss: 0.8681657314300537
Validation loss: 1.9959624807039897

Epoch: 6| Step: 10
Training loss: 1.1030704975128174
Validation loss: 2.0206012527147927

Epoch: 6| Step: 11
Training loss: 1.0014504194259644
Validation loss: 2.041878660519918

Epoch: 6| Step: 12
Training loss: 1.157716989517212
Validation loss: 2.0243166287740073

Epoch: 6| Step: 13
Training loss: 0.7291266918182373
Validation loss: 2.006251335144043

Epoch: 114| Step: 0
Training loss: 0.627214252948761
Validation loss: 2.0229950745900473

Epoch: 6| Step: 1
Training loss: 1.2674479484558105
Validation loss: 1.9523393313090007

Epoch: 6| Step: 2
Training loss: 1.2302498817443848
Validation loss: 1.9884900848070781

Epoch: 6| Step: 3
Training loss: 0.7677258253097534
Validation loss: 1.9822821418444316

Epoch: 6| Step: 4
Training loss: 1.0552979707717896
Validation loss: 1.9815328121185303

Epoch: 6| Step: 5
Training loss: 0.9298432469367981
Validation loss: 1.9598174889882405

Epoch: 6| Step: 6
Training loss: 0.7233469486236572
Validation loss: 1.9639793634414673

Epoch: 6| Step: 7
Training loss: 1.304914116859436
Validation loss: 1.9860608577728271

Epoch: 6| Step: 8
Training loss: 0.8910014629364014
Validation loss: 1.9956560134887695

Epoch: 6| Step: 9
Training loss: 1.0577472448349
Validation loss: 2.0049181381861367

Epoch: 6| Step: 10
Training loss: 1.4398114681243896
Validation loss: 1.972459852695465

Epoch: 6| Step: 11
Training loss: 1.2402679920196533
Validation loss: 1.9502266645431519

Epoch: 6| Step: 12
Training loss: 1.2133474349975586
Validation loss: 1.961604615052541

Epoch: 6| Step: 13
Training loss: 0.6266721487045288
Validation loss: 1.9927753806114197

Epoch: 115| Step: 0
Training loss: 1.3535652160644531
Validation loss: 1.9624994198481243

Epoch: 6| Step: 1
Training loss: 0.6723443269729614
Validation loss: 1.9636727968851726

Epoch: 6| Step: 2
Training loss: 0.6342045068740845
Validation loss: 2.0125754674275718

Epoch: 6| Step: 3
Training loss: 1.338285207748413
Validation loss: 1.9340731104214985

Epoch: 6| Step: 4
Training loss: 0.8874544501304626
Validation loss: 1.9251383145650227

Epoch: 6| Step: 5
Training loss: 1.1733686923980713
Validation loss: 1.944678803284963

Epoch: 6| Step: 6
Training loss: 1.1792871952056885
Validation loss: 1.9894936482111614

Epoch: 6| Step: 7
Training loss: 1.244908332824707
Validation loss: 1.9973831971486409

Epoch: 6| Step: 8
Training loss: 1.047525405883789
Validation loss: 1.9465544025103252

Epoch: 6| Step: 9
Training loss: 0.9551424980163574
Validation loss: 1.9570169846216838

Epoch: 6| Step: 10
Training loss: 1.063818097114563
Validation loss: 1.9758616089820862

Epoch: 6| Step: 11
Training loss: 0.6214693188667297
Validation loss: 1.9703195691108704

Epoch: 6| Step: 12
Training loss: 1.0833775997161865
Validation loss: 1.9656500816345215

Epoch: 6| Step: 13
Training loss: 0.7556642889976501
Validation loss: 1.9908549785614014

Epoch: 116| Step: 0
Training loss: 0.7723983526229858
Validation loss: 1.9702492157618205

Epoch: 6| Step: 1
Training loss: 0.8609330058097839
Validation loss: 1.959170937538147

Epoch: 6| Step: 2
Training loss: 1.068992018699646
Validation loss: 1.9777269959449768

Epoch: 6| Step: 3
Training loss: 0.8921517729759216
Validation loss: 1.9311878085136414

Epoch: 6| Step: 4
Training loss: 1.212198257446289
Validation loss: 1.9925699432690938

Epoch: 6| Step: 5
Training loss: 0.7608975172042847
Validation loss: 1.9709998766581218

Epoch: 6| Step: 6
Training loss: 1.1648203134536743
Validation loss: 1.9814276893933613

Epoch: 6| Step: 7
Training loss: 0.49085360765457153
Validation loss: 1.9837636351585388

Epoch: 6| Step: 8
Training loss: 1.0347390174865723
Validation loss: 1.9972188075383503

Epoch: 6| Step: 9
Training loss: 1.3181167840957642
Validation loss: 1.9708531697591145

Epoch: 6| Step: 10
Training loss: 1.3030667304992676
Validation loss: 2.009133537610372

Epoch: 6| Step: 11
Training loss: 0.6314813494682312
Validation loss: 1.965790073076884

Epoch: 6| Step: 12
Training loss: 0.8003941178321838
Validation loss: 2.0262975295384726

Epoch: 6| Step: 13
Training loss: 0.9810571670532227
Validation loss: 1.9887601335843403

Epoch: 117| Step: 0
Training loss: 0.8965672254562378
Validation loss: 2.0053836504618325

Epoch: 6| Step: 1
Training loss: 1.1579335927963257
Validation loss: 1.9684468706448872

Epoch: 6| Step: 2
Training loss: 0.8165329694747925
Validation loss: 1.9813823501269023

Epoch: 6| Step: 3
Training loss: 1.5571212768554688
Validation loss: 2.0081135034561157

Epoch: 6| Step: 4
Training loss: 0.8541136980056763
Validation loss: 1.950701912244161

Epoch: 6| Step: 5
Training loss: 0.6234675049781799
Validation loss: 1.9673046668370564

Epoch: 6| Step: 6
Training loss: 1.1448771953582764
Validation loss: 1.9552609125773113

Epoch: 6| Step: 7
Training loss: 0.65122389793396
Validation loss: 1.966609279314677

Epoch: 6| Step: 8
Training loss: 0.6654508709907532
Validation loss: 2.0188578764597573

Epoch: 6| Step: 9
Training loss: 1.1174042224884033
Validation loss: 1.9925955335299175

Epoch: 6| Step: 10
Training loss: 0.7685727477073669
Validation loss: 2.0249088207880654

Epoch: 6| Step: 11
Training loss: 0.6850401163101196
Validation loss: 1.9643659989039104

Epoch: 6| Step: 12
Training loss: 1.5523512363433838
Validation loss: 1.9988332788149517

Epoch: 6| Step: 13
Training loss: 0.9521731734275818
Validation loss: 1.98466557264328

Epoch: 118| Step: 0
Training loss: 1.4581737518310547
Validation loss: 1.9520207444826763

Epoch: 6| Step: 1
Training loss: 0.6775723099708557
Validation loss: 1.968211015065511

Epoch: 6| Step: 2
Training loss: 1.087224006652832
Validation loss: 1.9832656184832256

Epoch: 6| Step: 3
Training loss: 0.6858820915222168
Validation loss: 1.9130232532819111

Epoch: 6| Step: 4
Training loss: 0.7483607530593872
Validation loss: 1.9842175443967183

Epoch: 6| Step: 5
Training loss: 0.7982426881790161
Validation loss: 2.0117770036061606

Epoch: 6| Step: 6
Training loss: 1.2388123273849487
Validation loss: 1.98347411553065

Epoch: 6| Step: 7
Training loss: 0.5839736461639404
Validation loss: 2.0260836283365884

Epoch: 6| Step: 8
Training loss: 1.3123712539672852
Validation loss: 2.002149283885956

Epoch: 6| Step: 9
Training loss: 1.0729258060455322
Validation loss: 1.9596405029296875

Epoch: 6| Step: 10
Training loss: 1.027012825012207
Validation loss: 2.002540707588196

Epoch: 6| Step: 11
Training loss: 1.3939062356948853
Validation loss: 1.9775322874387105

Epoch: 6| Step: 12
Training loss: 0.6330178380012512
Validation loss: 1.9548814694086711

Epoch: 6| Step: 13
Training loss: 1.1518809795379639
Validation loss: 1.9799667199452717

Epoch: 119| Step: 0
Training loss: 1.1622073650360107
Validation loss: 1.9549927711486816

Epoch: 6| Step: 1
Training loss: 1.1647236347198486
Validation loss: 1.971993625164032

Epoch: 6| Step: 2
Training loss: 0.9103531241416931
Validation loss: 1.981509804725647

Epoch: 6| Step: 3
Training loss: 0.7800993919372559
Validation loss: 2.002477685610453

Epoch: 6| Step: 4
Training loss: 1.2515422105789185
Validation loss: 2.0104292035102844

Epoch: 6| Step: 5
Training loss: 0.6682409048080444
Validation loss: 1.9847106734911601

Epoch: 6| Step: 6
Training loss: 1.1329371929168701
Validation loss: 1.9821583032608032

Epoch: 6| Step: 7
Training loss: 0.8953342437744141
Validation loss: 1.9666000207265217

Epoch: 6| Step: 8
Training loss: 0.7749266624450684
Validation loss: 1.9880079627037048

Epoch: 6| Step: 9
Training loss: 1.1308424472808838
Validation loss: 1.9892931580543518

Epoch: 6| Step: 10
Training loss: 1.02558171749115
Validation loss: 1.9616888165473938

Epoch: 6| Step: 11
Training loss: 0.8982825875282288
Validation loss: 1.9571274121602376

Epoch: 6| Step: 12
Training loss: 0.7732428312301636
Validation loss: 2.0313315987586975

Epoch: 6| Step: 13
Training loss: 0.8775620460510254
Validation loss: 1.9889862934748332

Epoch: 120| Step: 0
Training loss: 1.5755137205123901
Validation loss: 2.0490150650342307

Epoch: 6| Step: 1
Training loss: 0.44149261713027954
Validation loss: 2.062810798486074

Epoch: 6| Step: 2
Training loss: 0.8139656186103821
Validation loss: 2.016586641470591

Epoch: 6| Step: 3
Training loss: 0.4976942241191864
Validation loss: 1.9523154497146606

Epoch: 6| Step: 4
Training loss: 0.8959499001502991
Validation loss: 1.9504040479660034

Epoch: 6| Step: 5
Training loss: 0.8097748756408691
Validation loss: 1.949957549571991

Epoch: 6| Step: 6
Training loss: 1.2632869482040405
Validation loss: 1.9909319877624512

Epoch: 6| Step: 7
Training loss: 1.5503857135772705
Validation loss: 1.9666293859481812

Epoch: 6| Step: 8
Training loss: 1.0563244819641113
Validation loss: 1.9534434080123901

Epoch: 6| Step: 9
Training loss: 1.0189878940582275
Validation loss: 1.97346427043279

Epoch: 6| Step: 10
Training loss: 0.8181757926940918
Validation loss: 1.9721369743347168

Epoch: 6| Step: 11
Training loss: 1.004475712776184
Validation loss: 1.983587344487508

Epoch: 6| Step: 12
Training loss: 0.8401336073875427
Validation loss: 2.029328008492788

Epoch: 6| Step: 13
Training loss: 0.8531980514526367
Validation loss: 1.9878594279289246

Epoch: 121| Step: 0
Training loss: 1.314352035522461
Validation loss: 1.9800212979316711

Epoch: 6| Step: 1
Training loss: 0.766189455986023
Validation loss: 1.959648847579956

Epoch: 6| Step: 2
Training loss: 1.6024861335754395
Validation loss: 1.958213249842326

Epoch: 6| Step: 3
Training loss: 0.783393383026123
Validation loss: 1.9963964621225994

Epoch: 6| Step: 4
Training loss: 1.1306931972503662
Validation loss: 1.9265553951263428

Epoch: 6| Step: 5
Training loss: 0.7497406005859375
Validation loss: 1.9812331199645996

Epoch: 6| Step: 6
Training loss: 0.6560162901878357
Validation loss: 1.9325853784879048

Epoch: 6| Step: 7
Training loss: 0.7672886848449707
Validation loss: 1.9300458828608196

Epoch: 6| Step: 8
Training loss: 0.7898377180099487
Validation loss: 1.9841192563374836

Epoch: 6| Step: 9
Training loss: 1.0118412971496582
Validation loss: 1.9652883609135945

Epoch: 6| Step: 10
Training loss: 0.8373095989227295
Validation loss: 1.9634981950124104

Epoch: 6| Step: 11
Training loss: 0.44447189569473267
Validation loss: 1.984761118888855

Epoch: 6| Step: 12
Training loss: 1.504256010055542
Validation loss: 1.962061842282613

Epoch: 6| Step: 13
Training loss: 0.7644587159156799
Validation loss: 1.9682534138361614

Epoch: 122| Step: 0
Training loss: 0.7703352570533752
Validation loss: 1.9884243210156758

Epoch: 6| Step: 1
Training loss: 0.7869366407394409
Validation loss: 1.9638391335805256

Epoch: 6| Step: 2
Training loss: 1.1649049520492554
Validation loss: 2.0104651053746543

Epoch: 6| Step: 3
Training loss: 1.3827824592590332
Validation loss: 1.9612107078234355

Epoch: 6| Step: 4
Training loss: 0.9856740236282349
Validation loss: 2.0041516423225403

Epoch: 6| Step: 5
Training loss: 0.9232366681098938
Validation loss: 1.987030307451884

Epoch: 6| Step: 6
Training loss: 0.7218995690345764
Validation loss: 1.9757152398427327

Epoch: 6| Step: 7
Training loss: 0.7743617296218872
Validation loss: 2.001946965853373

Epoch: 6| Step: 8
Training loss: 0.8777843713760376
Validation loss: 1.9527292450269063

Epoch: 6| Step: 9
Training loss: 1.2925596237182617
Validation loss: 1.9509677290916443

Epoch: 6| Step: 10
Training loss: 0.8783191442489624
Validation loss: 2.0246459245681763

Epoch: 6| Step: 11
Training loss: 1.071818232536316
Validation loss: 2.0176807244618735

Epoch: 6| Step: 12
Training loss: 0.9767416715621948
Validation loss: 2.0086241165796914

Epoch: 6| Step: 13
Training loss: 0.8899174928665161
Validation loss: 1.9615049759546916

Epoch: 123| Step: 0
Training loss: 0.9763232469558716
Validation loss: 1.9933411478996277

Epoch: 6| Step: 1
Training loss: 1.1677180528640747
Validation loss: 1.983585814634959

Epoch: 6| Step: 2
Training loss: 0.7668730020523071
Validation loss: 2.0109833677609763

Epoch: 6| Step: 3
Training loss: 1.0035135746002197
Validation loss: 2.0168176690737405

Epoch: 6| Step: 4
Training loss: 0.8489968776702881
Validation loss: 1.9772923390070598

Epoch: 6| Step: 5
Training loss: 0.779305100440979
Validation loss: 1.9745013912518818

Epoch: 6| Step: 6
Training loss: 0.9649635553359985
Validation loss: 1.992257575194041

Epoch: 6| Step: 7
Training loss: 1.0463639497756958
Validation loss: 2.0165483355522156

Epoch: 6| Step: 8
Training loss: 0.8561294078826904
Validation loss: 1.951123595237732

Epoch: 6| Step: 9
Training loss: 0.7633384466171265
Validation loss: 1.9541167219479878

Epoch: 6| Step: 10
Training loss: 0.8840087652206421
Validation loss: 1.9612278540929158

Epoch: 6| Step: 11
Training loss: 0.6475365161895752
Validation loss: 1.9813334544499714

Epoch: 6| Step: 12
Training loss: 0.9217196702957153
Validation loss: 1.9876219232877095

Epoch: 6| Step: 13
Training loss: 1.0315954685211182
Validation loss: 2.0209388931592307

Epoch: 124| Step: 0
Training loss: 0.6953766345977783
Validation loss: 1.9960779150327046

Epoch: 6| Step: 1
Training loss: 0.8394961357116699
Validation loss: 1.9905371864636738

Epoch: 6| Step: 2
Training loss: 1.0149662494659424
Validation loss: 2.012807031472524

Epoch: 6| Step: 3
Training loss: 0.7254193425178528
Validation loss: 2.020228842894236

Epoch: 6| Step: 4
Training loss: 0.6851704716682434
Validation loss: 1.9750699996948242

Epoch: 6| Step: 5
Training loss: 0.8795440196990967
Validation loss: 1.9826419552167256

Epoch: 6| Step: 6
Training loss: 0.5029596090316772
Validation loss: 1.9512015382448833

Epoch: 6| Step: 7
Training loss: 0.9095326066017151
Validation loss: 1.9965195457140605

Epoch: 6| Step: 8
Training loss: 0.49737784266471863
Validation loss: 1.9476224581400554

Epoch: 6| Step: 9
Training loss: 1.0931684970855713
Validation loss: 1.9781238238016765

Epoch: 6| Step: 10
Training loss: 1.1507830619812012
Validation loss: 1.952847182750702

Epoch: 6| Step: 11
Training loss: 0.600834846496582
Validation loss: 1.9683587153752644

Epoch: 6| Step: 12
Training loss: 1.5730186700820923
Validation loss: 1.956128458182017

Epoch: 6| Step: 13
Training loss: 1.0140858888626099
Validation loss: 2.002893626689911

Epoch: 125| Step: 0
Training loss: 0.7120609283447266
Validation loss: 1.9483580787976582

Epoch: 6| Step: 1
Training loss: 0.6219448447227478
Validation loss: 1.9954952994982402

Epoch: 6| Step: 2
Training loss: 0.8281381130218506
Validation loss: 1.9811225533485413

Epoch: 6| Step: 3
Training loss: 1.4185118675231934
Validation loss: 1.972995936870575

Epoch: 6| Step: 4
Training loss: 0.697689414024353
Validation loss: 1.9913276036580403

Epoch: 6| Step: 5
Training loss: 0.7725345492362976
Validation loss: 2.0180253187815347

Epoch: 6| Step: 6
Training loss: 0.8712528944015503
Validation loss: 2.0014851291974387

Epoch: 6| Step: 7
Training loss: 0.6887054443359375
Validation loss: 1.9629840056101482

Epoch: 6| Step: 8
Training loss: 0.5685945749282837
Validation loss: 2.021171530087789

Epoch: 6| Step: 9
Training loss: 1.2377331256866455
Validation loss: 1.997611939907074

Epoch: 6| Step: 10
Training loss: 0.6500129699707031
Validation loss: 1.9882461428642273

Epoch: 6| Step: 11
Training loss: 0.7059113383293152
Validation loss: 1.9522666136423747

Epoch: 6| Step: 12
Training loss: 1.478560447692871
Validation loss: 1.9768488208452861

Epoch: 6| Step: 13
Training loss: 1.218433141708374
Validation loss: 1.9366899927457173

Epoch: 126| Step: 0
Training loss: 0.8060562014579773
Validation loss: 1.9266158143679302

Epoch: 6| Step: 1
Training loss: 1.1205432415008545
Validation loss: 1.9431692759195964

Epoch: 6| Step: 2
Training loss: 0.48697417974472046
Validation loss: 2.022072652975718

Epoch: 6| Step: 3
Training loss: 0.44156795740127563
Validation loss: 1.980390687783559

Epoch: 6| Step: 4
Training loss: 1.2756807804107666
Validation loss: 1.9818606774012248

Epoch: 6| Step: 5
Training loss: 1.0738742351531982
Validation loss: 1.984597643216451

Epoch: 6| Step: 6
Training loss: 0.6972169876098633
Validation loss: 1.9370691974957783

Epoch: 6| Step: 7
Training loss: 0.9581820964813232
Validation loss: 1.9930473963419597

Epoch: 6| Step: 8
Training loss: 1.704807996749878
Validation loss: 1.9565414587656658

Epoch: 6| Step: 9
Training loss: 0.8777661919593811
Validation loss: 1.9727136492729187

Epoch: 6| Step: 10
Training loss: 0.6449275016784668
Validation loss: 1.9648488362630208

Epoch: 6| Step: 11
Training loss: 0.5307117700576782
Validation loss: 1.9508337775866191

Epoch: 6| Step: 12
Training loss: 1.1056691408157349
Validation loss: 1.988994300365448

Epoch: 6| Step: 13
Training loss: 0.8234337568283081
Validation loss: 1.9727227091789246

Epoch: 127| Step: 0
Training loss: 0.7210453748703003
Validation loss: 1.9872393210728962

Epoch: 6| Step: 1
Training loss: 1.1824681758880615
Validation loss: 1.9827908078829448

Epoch: 6| Step: 2
Training loss: 0.6836061477661133
Validation loss: 1.957790493965149

Epoch: 6| Step: 3
Training loss: 1.1064622402191162
Validation loss: 1.9590936303138733

Epoch: 6| Step: 4
Training loss: 1.0777071714401245
Validation loss: 1.9777226050694783

Epoch: 6| Step: 5
Training loss: 0.6127737760543823
Validation loss: 1.9642860889434814

Epoch: 6| Step: 6
Training loss: 0.7374178767204285
Validation loss: 1.957376221815745

Epoch: 6| Step: 7
Training loss: 1.1846096515655518
Validation loss: 1.9450652798016865

Epoch: 6| Step: 8
Training loss: 0.7003542184829712
Validation loss: 1.9728163480758667

Epoch: 6| Step: 9
Training loss: 0.65788334608078
Validation loss: 1.8894198338190715

Epoch: 6| Step: 10
Training loss: 0.6294654011726379
Validation loss: 1.9423012534777324

Epoch: 6| Step: 11
Training loss: 1.1050797700881958
Validation loss: 1.9340094129244487

Epoch: 6| Step: 12
Training loss: 0.5083026885986328
Validation loss: 1.964147925376892

Epoch: 6| Step: 13
Training loss: 1.392116904258728
Validation loss: 1.9660451610883076

Epoch: 128| Step: 0
Training loss: 0.9893089532852173
Validation loss: 1.9464927315711975

Epoch: 6| Step: 1
Training loss: 0.43992555141448975
Validation loss: 2.0022157629330954

Epoch: 6| Step: 2
Training loss: 0.503534197807312
Validation loss: 1.9515570203463237

Epoch: 6| Step: 3
Training loss: 0.6929946541786194
Validation loss: 1.9486191471417744

Epoch: 6| Step: 4
Training loss: 1.0865004062652588
Validation loss: 1.9907712539037068

Epoch: 6| Step: 5
Training loss: 0.7709507942199707
Validation loss: 1.9714305400848389

Epoch: 6| Step: 6
Training loss: 0.9329408407211304
Validation loss: 1.977179229259491

Epoch: 6| Step: 7
Training loss: 0.6541378498077393
Validation loss: 2.0145623286565146

Epoch: 6| Step: 8
Training loss: 0.7749390006065369
Validation loss: 1.987933874130249

Epoch: 6| Step: 9
Training loss: 0.9780706167221069
Validation loss: 1.9618561665217082

Epoch: 6| Step: 10
Training loss: 0.718859076499939
Validation loss: 2.0116992394129434

Epoch: 6| Step: 11
Training loss: 1.1719187498092651
Validation loss: 1.955392340819041

Epoch: 6| Step: 12
Training loss: 0.8885130286216736
Validation loss: 1.981200635433197

Epoch: 6| Step: 13
Training loss: 1.3880938291549683
Validation loss: 2.0139335989952087

Epoch: 129| Step: 0
Training loss: 0.6380991339683533
Validation loss: 2.0238455533981323

Epoch: 6| Step: 1
Training loss: 0.5534787178039551
Validation loss: 2.021272381146749

Epoch: 6| Step: 2
Training loss: 1.484277367591858
Validation loss: 2.0088099241256714

Epoch: 6| Step: 3
Training loss: 0.6632834672927856
Validation loss: 2.0107246239980063

Epoch: 6| Step: 4
Training loss: 0.698096513748169
Validation loss: 2.0163137714068093

Epoch: 6| Step: 5
Training loss: 0.764920711517334
Validation loss: 1.9709709882736206

Epoch: 6| Step: 6
Training loss: 0.8608540296554565
Validation loss: 1.9269906282424927

Epoch: 6| Step: 7
Training loss: 0.7264412641525269
Validation loss: 1.927913208802541

Epoch: 6| Step: 8
Training loss: 1.244312047958374
Validation loss: 1.9754944046338399

Epoch: 6| Step: 9
Training loss: 0.9194574356079102
Validation loss: 1.9562668800354004

Epoch: 6| Step: 10
Training loss: 1.0974735021591187
Validation loss: 1.9910765886306763

Epoch: 6| Step: 11
Training loss: 1.0522394180297852
Validation loss: 1.978568474451701

Epoch: 6| Step: 12
Training loss: 0.7406308650970459
Validation loss: 2.02500057220459

Epoch: 6| Step: 13
Training loss: 0.5339149236679077
Validation loss: 1.9877869288126628

Epoch: 130| Step: 0
Training loss: 0.8340005874633789
Validation loss: 1.9501388470331829

Epoch: 6| Step: 1
Training loss: 1.328045129776001
Validation loss: 1.9574885964393616

Epoch: 6| Step: 2
Training loss: 0.5701096653938293
Validation loss: 1.9560248851776123

Epoch: 6| Step: 3
Training loss: 0.8576914072036743
Validation loss: 1.9401116768519084

Epoch: 6| Step: 4
Training loss: 0.7614588737487793
Validation loss: 1.9649478594462078

Epoch: 6| Step: 5
Training loss: 1.0076113939285278
Validation loss: 1.9500252207120259

Epoch: 6| Step: 6
Training loss: 0.9280996918678284
Validation loss: 1.9606925050417583

Epoch: 6| Step: 7
Training loss: 0.7517067193984985
Validation loss: 1.8852449456850688

Epoch: 6| Step: 8
Training loss: 0.7033066153526306
Validation loss: 1.9733768304189045

Epoch: 6| Step: 9
Training loss: 0.7904842495918274
Validation loss: 2.002895633379618

Epoch: 6| Step: 10
Training loss: 1.022788405418396
Validation loss: 1.9822833736737568

Epoch: 6| Step: 11
Training loss: 0.8465151786804199
Validation loss: 1.9479910532633464

Epoch: 6| Step: 12
Training loss: 0.9543393850326538
Validation loss: 1.9754949808120728

Epoch: 6| Step: 13
Training loss: 0.4951211214065552
Validation loss: 1.9941117962201436

Epoch: 131| Step: 0
Training loss: 0.9283812642097473
Validation loss: 1.928790291150411

Epoch: 6| Step: 1
Training loss: 0.9258050322532654
Validation loss: 1.9825582106908162

Epoch: 6| Step: 2
Training loss: 1.1120641231536865
Validation loss: 1.951587935288747

Epoch: 6| Step: 3
Training loss: 0.48331883549690247
Validation loss: 1.9726471503575642

Epoch: 6| Step: 4
Training loss: 0.9671819806098938
Validation loss: 1.9839069843292236

Epoch: 6| Step: 5
Training loss: 1.0304296016693115
Validation loss: 1.9734520713488262

Epoch: 6| Step: 6
Training loss: 0.363743394613266
Validation loss: 1.985093394915263

Epoch: 6| Step: 7
Training loss: 0.672347366809845
Validation loss: 2.0217451055844626

Epoch: 6| Step: 8
Training loss: 0.5822067856788635
Validation loss: 2.0144787629445395

Epoch: 6| Step: 9
Training loss: 1.235241174697876
Validation loss: 2.0580917994181314

Epoch: 6| Step: 10
Training loss: 0.7108784317970276
Validation loss: 1.9954847296079

Epoch: 6| Step: 11
Training loss: 0.8004063963890076
Validation loss: 2.0073512196540833

Epoch: 6| Step: 12
Training loss: 0.7364798784255981
Validation loss: 1.924660046895345

Epoch: 6| Step: 13
Training loss: 1.3262436389923096
Validation loss: 1.9480124910672505

Epoch: 132| Step: 0
Training loss: 1.250899314880371
Validation loss: 1.9576570987701416

Epoch: 6| Step: 1
Training loss: 0.9733182787895203
Validation loss: 1.9606284101804097

Epoch: 6| Step: 2
Training loss: 0.9899029731750488
Validation loss: 1.995157539844513

Epoch: 6| Step: 3
Training loss: 1.0874738693237305
Validation loss: 1.977819800376892

Epoch: 6| Step: 4
Training loss: 0.4735080599784851
Validation loss: 2.0010785261789956

Epoch: 6| Step: 5
Training loss: 0.9935187101364136
Validation loss: 1.975327690442403

Epoch: 6| Step: 6
Training loss: 0.8016653060913086
Validation loss: 2.0306825637817383

Epoch: 6| Step: 7
Training loss: 0.48644763231277466
Validation loss: 1.9753851890563965

Epoch: 6| Step: 8
Training loss: 0.49194061756134033
Validation loss: 1.9894508520762126

Epoch: 6| Step: 9
Training loss: 0.5538934469223022
Validation loss: 1.9906228979428608

Epoch: 6| Step: 10
Training loss: 1.0129673480987549
Validation loss: 1.9948871930440266

Epoch: 6| Step: 11
Training loss: 0.8485985994338989
Validation loss: 1.9841561317443848

Epoch: 6| Step: 12
Training loss: 0.8890383243560791
Validation loss: 1.9851148923238118

Epoch: 6| Step: 13
Training loss: 0.9147491455078125
Validation loss: 1.9896713097890217

Epoch: 133| Step: 0
Training loss: 0.5173488855361938
Validation loss: 1.9417173663775127

Epoch: 6| Step: 1
Training loss: 0.4507349729537964
Validation loss: 1.966811736424764

Epoch: 6| Step: 2
Training loss: 0.6122000217437744
Validation loss: 2.002123494942983

Epoch: 6| Step: 3
Training loss: 0.8128659725189209
Validation loss: 2.0244088768959045

Epoch: 6| Step: 4
Training loss: 0.9484524726867676
Validation loss: 2.0212013522783914

Epoch: 6| Step: 5
Training loss: 1.134639024734497
Validation loss: 2.014124810695648

Epoch: 6| Step: 6
Training loss: 1.173405647277832
Validation loss: 2.0009867548942566

Epoch: 6| Step: 7
Training loss: 1.086409568786621
Validation loss: 1.950805087884267

Epoch: 6| Step: 8
Training loss: 0.9525855779647827
Validation loss: 1.9548998872439067

Epoch: 6| Step: 9
Training loss: 0.6659439206123352
Validation loss: 1.94877823193868

Epoch: 6| Step: 10
Training loss: 0.7294024229049683
Validation loss: 1.9635043342908223

Epoch: 6| Step: 11
Training loss: 1.1426304578781128
Validation loss: 2.0230142076810202

Epoch: 6| Step: 12
Training loss: 0.5739401578903198
Validation loss: 1.9378395875295003

Epoch: 6| Step: 13
Training loss: 0.5888731479644775
Validation loss: 1.9618638157844543

Epoch: 134| Step: 0
Training loss: 1.1555140018463135
Validation loss: 2.001447916030884

Epoch: 6| Step: 1
Training loss: 0.6295117139816284
Validation loss: 2.0553497870763144

Epoch: 6| Step: 2
Training loss: 1.0211176872253418
Validation loss: 2.023581643899282

Epoch: 6| Step: 3
Training loss: 0.7949070930480957
Validation loss: 2.01749982436498

Epoch: 6| Step: 4
Training loss: 1.0038297176361084
Validation loss: 1.9855037728945415

Epoch: 6| Step: 5
Training loss: 0.5310865640640259
Validation loss: 1.9713058074315388

Epoch: 6| Step: 6
Training loss: 0.9378200769424438
Validation loss: 1.963396151860555

Epoch: 6| Step: 7
Training loss: 0.8967525959014893
Validation loss: 1.9466976126035054

Epoch: 6| Step: 8
Training loss: 1.254655361175537
Validation loss: 1.9769564270973206

Epoch: 6| Step: 9
Training loss: 0.8396701216697693
Validation loss: 1.9530111749966939

Epoch: 6| Step: 10
Training loss: 0.6117985844612122
Validation loss: 1.9498935341835022

Epoch: 6| Step: 11
Training loss: 0.4476332366466522
Validation loss: 1.9910320242245991

Epoch: 6| Step: 12
Training loss: 0.5062046051025391
Validation loss: 1.9670992294947307

Epoch: 6| Step: 13
Training loss: 0.793009340763092
Validation loss: 2.0137197375297546

Epoch: 135| Step: 0
Training loss: 0.9195166826248169
Validation loss: 2.046083688735962

Epoch: 6| Step: 1
Training loss: 0.5785895586013794
Validation loss: 1.9913364450136821

Epoch: 6| Step: 2
Training loss: 0.7358503937721252
Validation loss: 2.0135629375775657

Epoch: 6| Step: 3
Training loss: 0.8760091662406921
Validation loss: 2.0129545529683432

Epoch: 6| Step: 4
Training loss: 0.4858960509300232
Validation loss: 1.9673571387926738

Epoch: 6| Step: 5
Training loss: 0.8924151062965393
Validation loss: 1.9428929090499878

Epoch: 6| Step: 6
Training loss: 1.1424145698547363
Validation loss: 1.976802388827006

Epoch: 6| Step: 7
Training loss: 0.922724723815918
Validation loss: 1.9635414282480876

Epoch: 6| Step: 8
Training loss: 1.3376158475875854
Validation loss: 1.9805513819058735

Epoch: 6| Step: 9
Training loss: 0.6971585750579834
Validation loss: 1.9831331173578899

Epoch: 6| Step: 10
Training loss: 0.7906702756881714
Validation loss: 1.9581797122955322

Epoch: 6| Step: 11
Training loss: 0.511745810508728
Validation loss: 1.9878368973731995

Epoch: 6| Step: 12
Training loss: 0.6254077553749084
Validation loss: 1.9882164398829143

Epoch: 6| Step: 13
Training loss: 0.9542522430419922
Validation loss: 1.9788446227709453

Epoch: 136| Step: 0
Training loss: 0.4941386282444
Validation loss: 1.9874796470006306

Epoch: 6| Step: 1
Training loss: 0.6034420728683472
Validation loss: 2.0164952476819358

Epoch: 6| Step: 2
Training loss: 1.063507080078125
Validation loss: 1.9676146109898884

Epoch: 6| Step: 3
Training loss: 1.0866906642913818
Validation loss: 2.0124309261639914

Epoch: 6| Step: 4
Training loss: 0.49975770711898804
Validation loss: 1.9655257662137349

Epoch: 6| Step: 5
Training loss: 0.6409103274345398
Validation loss: 1.9761896928151448

Epoch: 6| Step: 6
Training loss: 1.3500745296478271
Validation loss: 1.927148699760437

Epoch: 6| Step: 7
Training loss: 1.16150963306427
Validation loss: 1.9772549867630005

Epoch: 6| Step: 8
Training loss: 0.7855252027511597
Validation loss: 1.9530346194903057

Epoch: 6| Step: 9
Training loss: 0.6547656059265137
Validation loss: 1.9612553119659424

Epoch: 6| Step: 10
Training loss: 0.8193049430847168
Validation loss: 1.9703815976778667

Epoch: 6| Step: 11
Training loss: 0.8026005029678345
Validation loss: 1.9817174871762593

Epoch: 6| Step: 12
Training loss: 0.59339439868927
Validation loss: 2.0150694449742637

Epoch: 6| Step: 13
Training loss: 0.46835294365882874
Validation loss: 1.9521979093551636

Epoch: 137| Step: 0
Training loss: 0.5219321846961975
Validation loss: 1.9713170329729717

Epoch: 6| Step: 1
Training loss: 0.5693924427032471
Validation loss: 1.977791965007782

Epoch: 6| Step: 2
Training loss: 0.7195757627487183
Validation loss: 1.9479825099309285

Epoch: 6| Step: 3
Training loss: 0.5915642976760864
Validation loss: 1.9728113412857056

Epoch: 6| Step: 4
Training loss: 0.7382282018661499
Validation loss: 1.9661523501078289

Epoch: 6| Step: 5
Training loss: 0.9240957498550415
Validation loss: 1.9629823366800945

Epoch: 6| Step: 6
Training loss: 0.9634988307952881
Validation loss: 1.958343545595805

Epoch: 6| Step: 7
Training loss: 0.618303656578064
Validation loss: 1.9605707327524822

Epoch: 6| Step: 8
Training loss: 0.35665640234947205
Validation loss: 2.0108832915623984

Epoch: 6| Step: 9
Training loss: 0.6260734796524048
Validation loss: 2.051222562789917

Epoch: 6| Step: 10
Training loss: 1.019777774810791
Validation loss: 2.018545389175415

Epoch: 6| Step: 11
Training loss: 0.9968266487121582
Validation loss: 2.0058524012565613

Epoch: 6| Step: 12
Training loss: 0.7871050834655762
Validation loss: 1.9542761445045471

Epoch: 6| Step: 13
Training loss: 1.2805657386779785
Validation loss: 1.9693221648534138

Epoch: 138| Step: 0
Training loss: 0.5564192533493042
Validation loss: 1.9463963111241658

Epoch: 6| Step: 1
Training loss: 0.6591017842292786
Validation loss: 2.0175826946894326

Epoch: 6| Step: 2
Training loss: 0.8239331841468811
Validation loss: 1.9585213263829548

Epoch: 6| Step: 3
Training loss: 0.5407260656356812
Validation loss: 1.9798776904741924

Epoch: 6| Step: 4
Training loss: 0.881619930267334
Validation loss: 2.038728932539622

Epoch: 6| Step: 5
Training loss: 0.6692877411842346
Validation loss: 2.0315396984418235

Epoch: 6| Step: 6
Training loss: 0.7420841455459595
Validation loss: 2.004469335079193

Epoch: 6| Step: 7
Training loss: 1.1583162546157837
Validation loss: 2.049979309240977

Epoch: 6| Step: 8
Training loss: 1.2148489952087402
Validation loss: 2.0263256827990213

Epoch: 6| Step: 9
Training loss: 0.6797340512275696
Validation loss: 2.0075043439865112

Epoch: 6| Step: 10
Training loss: 0.5669403076171875
Validation loss: 2.026124199231466

Epoch: 6| Step: 11
Training loss: 0.8676248788833618
Validation loss: 1.9632378021876018

Epoch: 6| Step: 12
Training loss: 0.8455554246902466
Validation loss: 1.9822815259297688

Epoch: 6| Step: 13
Training loss: 0.9655486941337585
Validation loss: 2.0543938080469766

Epoch: 139| Step: 0
Training loss: 0.6078392863273621
Validation loss: 2.0041257540384927

Epoch: 6| Step: 1
Training loss: 1.16610586643219
Validation loss: 2.057747224966685

Epoch: 6| Step: 2
Training loss: 0.7072591781616211
Validation loss: 2.048371950785319

Epoch: 6| Step: 3
Training loss: 0.6403709053993225
Validation loss: 1.9923988580703735

Epoch: 6| Step: 4
Training loss: 0.845759928226471
Validation loss: 2.0103445251782737

Epoch: 6| Step: 5
Training loss: 0.5462040901184082
Validation loss: 1.9938693443934123

Epoch: 6| Step: 6
Training loss: 0.7413548827171326
Validation loss: 1.9776623447736104

Epoch: 6| Step: 7
Training loss: 0.7297319173812866
Validation loss: 1.9721944332122803

Epoch: 6| Step: 8
Training loss: 0.8591374158859253
Validation loss: 1.9656269152959187

Epoch: 6| Step: 9
Training loss: 0.5055645108222961
Validation loss: 1.9591401815414429

Epoch: 6| Step: 10
Training loss: 0.9561868906021118
Validation loss: 1.971842348575592

Epoch: 6| Step: 11
Training loss: 0.6349618434906006
Validation loss: 1.9957334597905476

Epoch: 6| Step: 12
Training loss: 1.0458247661590576
Validation loss: 2.011851489543915

Epoch: 6| Step: 13
Training loss: 0.9156992435455322
Validation loss: 2.032299300034841

Epoch: 140| Step: 0
Training loss: 0.5357308387756348
Validation loss: 2.009379426638285

Epoch: 6| Step: 1
Training loss: 0.5261563062667847
Validation loss: 1.9700812697410583

Epoch: 6| Step: 2
Training loss: 1.0959298610687256
Validation loss: 1.9780011177062988

Epoch: 6| Step: 3
Training loss: 0.9036086797714233
Validation loss: 1.9856989979743958

Epoch: 6| Step: 4
Training loss: 0.5894502401351929
Validation loss: 2.000452935695648

Epoch: 6| Step: 5
Training loss: 1.453357219696045
Validation loss: 1.9822514653205872

Epoch: 6| Step: 6
Training loss: 0.761142909526825
Validation loss: 1.9809261759122212

Epoch: 6| Step: 7
Training loss: 0.3631671071052551
Validation loss: 1.9947364330291748

Epoch: 6| Step: 8
Training loss: 0.46033206582069397
Validation loss: 2.0110181967417398

Epoch: 6| Step: 9
Training loss: 0.7361747622489929
Validation loss: 2.0015737811724343

Epoch: 6| Step: 10
Training loss: 0.6698616743087769
Validation loss: 1.9606544375419617

Epoch: 6| Step: 11
Training loss: 0.6476682424545288
Validation loss: 2.019148369630178

Epoch: 6| Step: 12
Training loss: 0.5036526322364807
Validation loss: 2.0197731653849282

Epoch: 6| Step: 13
Training loss: 1.299888014793396
Validation loss: 2.0069512526194253

Epoch: 141| Step: 0
Training loss: 1.294424295425415
Validation loss: 2.0206415255864463

Epoch: 6| Step: 1
Training loss: 0.5426220893859863
Validation loss: 2.010551412900289

Epoch: 6| Step: 2
Training loss: 0.5710090398788452
Validation loss: 1.9999235073725383

Epoch: 6| Step: 3
Training loss: 0.8066147565841675
Validation loss: 2.010937253634135

Epoch: 6| Step: 4
Training loss: 0.7421965003013611
Validation loss: 2.0224868655204773

Epoch: 6| Step: 5
Training loss: 0.5135508179664612
Validation loss: 1.970532496770223

Epoch: 6| Step: 6
Training loss: 0.5925162434577942
Validation loss: 2.0019856691360474

Epoch: 6| Step: 7
Training loss: 0.6627586483955383
Validation loss: 2.063954929510752

Epoch: 6| Step: 8
Training loss: 1.2361927032470703
Validation loss: 2.006561756134033

Epoch: 6| Step: 9
Training loss: 0.4924153685569763
Validation loss: 1.9952138662338257

Epoch: 6| Step: 10
Training loss: 0.520228385925293
Validation loss: 1.9831371704737346

Epoch: 6| Step: 11
Training loss: 0.47760531306266785
Validation loss: 1.9957944353421528

Epoch: 6| Step: 12
Training loss: 0.7580500841140747
Validation loss: 1.9966768026351929

Epoch: 6| Step: 13
Training loss: 0.6973148584365845
Validation loss: 1.9778464833895366

Epoch: 142| Step: 0
Training loss: 0.8282893896102905
Validation loss: 1.9863524238268535

Epoch: 6| Step: 1
Training loss: 0.7007806301116943
Validation loss: 1.9836650888125102

Epoch: 6| Step: 2
Training loss: 0.659718930721283
Validation loss: 1.9430790742238362

Epoch: 6| Step: 3
Training loss: 0.6521165370941162
Validation loss: 1.969934066136678

Epoch: 6| Step: 4
Training loss: 0.6505641341209412
Validation loss: 1.962629536787669

Epoch: 6| Step: 5
Training loss: 0.7715057134628296
Validation loss: 2.0044734477996826

Epoch: 6| Step: 6
Training loss: 1.2973852157592773
Validation loss: 1.961085855960846

Epoch: 6| Step: 7
Training loss: 0.8558131456375122
Validation loss: 1.9957306583722432

Epoch: 6| Step: 8
Training loss: 0.5759191513061523
Validation loss: 1.9584145744641621

Epoch: 6| Step: 9
Training loss: 0.7531367540359497
Validation loss: 1.9874529441197712

Epoch: 6| Step: 10
Training loss: 0.6459031105041504
Validation loss: 2.02521018187205

Epoch: 6| Step: 11
Training loss: 0.2621666491031647
Validation loss: 1.9965897401173909

Epoch: 6| Step: 12
Training loss: 0.9881038665771484
Validation loss: 1.9992652734120686

Epoch: 6| Step: 13
Training loss: 0.5496610999107361
Validation loss: 1.9976135691006978

Epoch: 143| Step: 0
Training loss: 0.7821068167686462
Validation loss: 1.986788769563039

Epoch: 6| Step: 1
Training loss: 0.7979741096496582
Validation loss: 1.9839267134666443

Epoch: 6| Step: 2
Training loss: 0.5539756417274475
Validation loss: 1.9636656840642293

Epoch: 6| Step: 3
Training loss: 0.5247007608413696
Validation loss: 1.9937609036763508

Epoch: 6| Step: 4
Training loss: 0.4767957925796509
Validation loss: 2.002643088499705

Epoch: 6| Step: 5
Training loss: 0.792148232460022
Validation loss: 2.010191857814789

Epoch: 6| Step: 6
Training loss: 0.9877973794937134
Validation loss: 1.9980046153068542

Epoch: 6| Step: 7
Training loss: 0.6027380228042603
Validation loss: 2.0139609575271606

Epoch: 6| Step: 8
Training loss: 0.999234139919281
Validation loss: 1.9789220889409382

Epoch: 6| Step: 9
Training loss: 0.5883299112319946
Validation loss: 2.0131511092185974

Epoch: 6| Step: 10
Training loss: 0.4618145525455475
Validation loss: 1.9892237385114033

Epoch: 6| Step: 11
Training loss: 0.7261361479759216
Validation loss: 1.9787464340527852

Epoch: 6| Step: 12
Training loss: 0.6936486959457397
Validation loss: 2.014738897482554

Epoch: 6| Step: 13
Training loss: 1.3768962621688843
Validation loss: 1.9583284656206768

Epoch: 144| Step: 0
Training loss: 0.6873031854629517
Validation loss: 1.9656978050867717

Epoch: 6| Step: 1
Training loss: 0.6673299074172974
Validation loss: 1.9930563767751057

Epoch: 6| Step: 2
Training loss: 0.7255954742431641
Validation loss: 1.991791307926178

Epoch: 6| Step: 3
Training loss: 0.5184758901596069
Validation loss: 1.9713693857192993

Epoch: 6| Step: 4
Training loss: 0.745663046836853
Validation loss: 2.0306427478790283

Epoch: 6| Step: 5
Training loss: 0.4770095646381378
Validation loss: 1.9915410876274109

Epoch: 6| Step: 6
Training loss: 0.637170672416687
Validation loss: 1.9670876661936443

Epoch: 6| Step: 7
Training loss: 0.9368093013763428
Validation loss: 1.9613197445869446

Epoch: 6| Step: 8
Training loss: 1.0856528282165527
Validation loss: 1.980235715707143

Epoch: 6| Step: 9
Training loss: 0.9221457839012146
Validation loss: 1.9784043431282043

Epoch: 6| Step: 10
Training loss: 1.1764718294143677
Validation loss: 1.9819869200388591

Epoch: 6| Step: 11
Training loss: 0.3492916226387024
Validation loss: 1.9471451838811238

Epoch: 6| Step: 12
Training loss: 0.5607498288154602
Validation loss: 1.9786877234776814

Epoch: 6| Step: 13
Training loss: 0.8349817991256714
Validation loss: 2.0203129649162292

Epoch: 145| Step: 0
Training loss: 0.5742802619934082
Validation loss: 2.026861310005188

Epoch: 6| Step: 1
Training loss: 1.0804781913757324
Validation loss: 2.0310086607933044

Epoch: 6| Step: 2
Training loss: 0.4964752197265625
Validation loss: 1.9356543620427449

Epoch: 6| Step: 3
Training loss: 0.31040847301483154
Validation loss: 2.0150314768155417

Epoch: 6| Step: 4
Training loss: 0.71451735496521
Validation loss: 2.001953919728597

Epoch: 6| Step: 5
Training loss: 0.6786829829216003
Validation loss: 1.9498387575149536

Epoch: 6| Step: 6
Training loss: 0.9589576125144958
Validation loss: 1.9320751229921977

Epoch: 6| Step: 7
Training loss: 0.9318053126335144
Validation loss: 1.936409095923106

Epoch: 6| Step: 8
Training loss: 0.8916994333267212
Validation loss: 1.9541836579640706

Epoch: 6| Step: 9
Training loss: 0.8005391359329224
Validation loss: 1.9548223614692688

Epoch: 6| Step: 10
Training loss: 1.0868076086044312
Validation loss: 2.0124908685684204

Epoch: 6| Step: 11
Training loss: 0.8967983722686768
Validation loss: 2.033716142177582

Epoch: 6| Step: 12
Training loss: 0.8173203468322754
Validation loss: 2.0162701408068338

Epoch: 6| Step: 13
Training loss: 0.7554882764816284
Validation loss: 1.9681921601295471

Epoch: 146| Step: 0
Training loss: 1.1638084650039673
Validation loss: 2.033804734547933

Epoch: 6| Step: 1
Training loss: 0.8310065269470215
Validation loss: 2.0160681207974753

Epoch: 6| Step: 2
Training loss: 0.6111211776733398
Validation loss: 2.035476485888163

Epoch: 6| Step: 3
Training loss: 0.6066979765892029
Validation loss: 1.9827146132787068

Epoch: 6| Step: 4
Training loss: 0.9144760370254517
Validation loss: 1.9728942314783733

Epoch: 6| Step: 5
Training loss: 0.8715350031852722
Validation loss: 2.011598308881124

Epoch: 6| Step: 6
Training loss: 1.0443737506866455
Validation loss: 1.9519111315409343

Epoch: 6| Step: 7
Training loss: 0.4624316692352295
Validation loss: 1.9810379147529602

Epoch: 6| Step: 8
Training loss: 0.4549313187599182
Validation loss: 1.966241717338562

Epoch: 6| Step: 9
Training loss: 0.8436702489852905
Validation loss: 2.0070297718048096

Epoch: 6| Step: 10
Training loss: 0.3247891962528229
Validation loss: 2.0019070704778037

Epoch: 6| Step: 11
Training loss: 1.0372236967086792
Validation loss: 1.974413553873698

Epoch: 6| Step: 12
Training loss: 0.6744370460510254
Validation loss: 2.018413245677948

Epoch: 6| Step: 13
Training loss: 0.8195662498474121
Validation loss: 1.959648331006368

Epoch: 147| Step: 0
Training loss: 0.7599169015884399
Validation loss: 2.010863204797109

Epoch: 6| Step: 1
Training loss: 0.8509721159934998
Validation loss: 1.9679279327392578

Epoch: 6| Step: 2
Training loss: 0.709435224533081
Validation loss: 1.9818053642908733

Epoch: 6| Step: 3
Training loss: 0.9633303284645081
Validation loss: 1.9726811051368713

Epoch: 6| Step: 4
Training loss: 0.5455859303474426
Validation loss: 2.0149372220039368

Epoch: 6| Step: 5
Training loss: 0.7135269045829773
Validation loss: 1.978488067785899

Epoch: 6| Step: 6
Training loss: 0.4819347858428955
Validation loss: 1.990717629591624

Epoch: 6| Step: 7
Training loss: 0.6309267282485962
Validation loss: 1.9847145676612854

Epoch: 6| Step: 8
Training loss: 0.5187309384346008
Validation loss: 1.9940530856450398

Epoch: 6| Step: 9
Training loss: 1.052201747894287
Validation loss: 2.0127620697021484

Epoch: 6| Step: 10
Training loss: 0.49494776129722595
Validation loss: 2.035493473211924

Epoch: 6| Step: 11
Training loss: 0.7858277559280396
Validation loss: 1.996998945871989

Epoch: 6| Step: 12
Training loss: 1.1077502965927124
Validation loss: 1.996192475159963

Epoch: 6| Step: 13
Training loss: 0.8565002083778381
Validation loss: 1.9992460409800212

Epoch: 148| Step: 0
Training loss: 0.3925497233867645
Validation loss: 1.9668514529863994

Epoch: 6| Step: 1
Training loss: 0.6578069925308228
Validation loss: 2.0479758977890015

Epoch: 6| Step: 2
Training loss: 1.036993145942688
Validation loss: 2.0332956115404763

Epoch: 6| Step: 3
Training loss: 0.7903450131416321
Validation loss: 2.0244569182395935

Epoch: 6| Step: 4
Training loss: 0.6199301481246948
Validation loss: 2.020747641722361

Epoch: 6| Step: 5
Training loss: 0.4523019790649414
Validation loss: 1.9917691548665364

Epoch: 6| Step: 6
Training loss: 0.6644811630249023
Validation loss: 1.957956353823344

Epoch: 6| Step: 7
Training loss: 0.8014804720878601
Validation loss: 1.9662034312884014

Epoch: 6| Step: 8
Training loss: 0.8082337975502014
Validation loss: 1.9665737946828206

Epoch: 6| Step: 9
Training loss: 0.7651435732841492
Validation loss: 1.9721195896466572

Epoch: 6| Step: 10
Training loss: 0.5605437755584717
Validation loss: 1.972301423549652

Epoch: 6| Step: 11
Training loss: 0.6272381544113159
Validation loss: 1.9645447929700215

Epoch: 6| Step: 12
Training loss: 0.46875959634780884
Validation loss: 1.9725655714670818

Epoch: 6| Step: 13
Training loss: 1.364929437637329
Validation loss: 1.955320914586385

Epoch: 149| Step: 0
Training loss: 0.5421990156173706
Validation loss: 1.947799265384674

Epoch: 6| Step: 1
Training loss: 0.8661414384841919
Validation loss: 1.9877444704373677

Epoch: 6| Step: 2
Training loss: 0.3218647241592407
Validation loss: 2.001675228277842

Epoch: 6| Step: 3
Training loss: 0.8572151064872742
Validation loss: 1.9421366651852925

Epoch: 6| Step: 4
Training loss: 0.4696154296398163
Validation loss: 1.9719430009524028

Epoch: 6| Step: 5
Training loss: 0.5128780007362366
Validation loss: 1.9976082841555278

Epoch: 6| Step: 6
Training loss: 0.36418652534484863
Validation loss: 1.962346076965332

Epoch: 6| Step: 7
Training loss: 0.8166614770889282
Validation loss: 2.0101306239763894

Epoch: 6| Step: 8
Training loss: 1.0824558734893799
Validation loss: 2.0089457829793296

Epoch: 6| Step: 9
Training loss: 0.63498854637146
Validation loss: 2.0048086245854697

Epoch: 6| Step: 10
Training loss: 0.7545119524002075
Validation loss: 1.9870736002922058

Epoch: 6| Step: 11
Training loss: 0.7421362400054932
Validation loss: 1.9688863356908162

Epoch: 6| Step: 12
Training loss: 0.9801111221313477
Validation loss: 2.037010888258616

Epoch: 6| Step: 13
Training loss: 0.44869464635849
Validation loss: 2.001637279987335

Epoch: 150| Step: 0
Training loss: 0.9628458619117737
Validation loss: 1.9536274472872417

Epoch: 6| Step: 1
Training loss: 1.2903327941894531
Validation loss: 1.9322340885798137

Epoch: 6| Step: 2
Training loss: 0.5017023086547852
Validation loss: 2.000841716925303

Epoch: 6| Step: 3
Training loss: 0.5269529819488525
Validation loss: 2.0301281213760376

Epoch: 6| Step: 4
Training loss: 0.405093789100647
Validation loss: 1.954318384329478

Epoch: 6| Step: 5
Training loss: 0.7950975894927979
Validation loss: 1.9824753403663635

Epoch: 6| Step: 6
Training loss: 1.0874884128570557
Validation loss: 2.010812302430471

Epoch: 6| Step: 7
Training loss: 0.4714875817298889
Validation loss: 2.025474429130554

Epoch: 6| Step: 8
Training loss: 0.6866970062255859
Validation loss: 2.0131505330403647

Epoch: 6| Step: 9
Training loss: 0.3378644287586212
Validation loss: 1.9837445815404255

Epoch: 6| Step: 10
Training loss: 0.7133236527442932
Validation loss: 1.9744536677996318

Epoch: 6| Step: 11
Training loss: 0.7426233887672424
Validation loss: 1.973001738389333

Epoch: 6| Step: 12
Training loss: 0.5685243606567383
Validation loss: 1.9938373168309529

Epoch: 6| Step: 13
Training loss: 0.5953792929649353
Validation loss: 1.9953408439954121

Epoch: 151| Step: 0
Training loss: 1.0741045475006104
Validation loss: 1.9824315309524536

Epoch: 6| Step: 1
Training loss: 0.5408122539520264
Validation loss: 1.955470860004425

Epoch: 6| Step: 2
Training loss: 0.7289955615997314
Validation loss: 1.9622747699419658

Epoch: 6| Step: 3
Training loss: 0.8771188855171204
Validation loss: 1.9749402801195781

Epoch: 6| Step: 4
Training loss: 0.6654368042945862
Validation loss: 1.999210516611735

Epoch: 6| Step: 5
Training loss: 0.5044834613800049
Validation loss: 1.964927573998769

Epoch: 6| Step: 6
Training loss: 0.7636777758598328
Validation loss: 2.02400932709376

Epoch: 6| Step: 7
Training loss: 0.4062667489051819
Validation loss: 1.9994807442029316

Epoch: 6| Step: 8
Training loss: 0.43996578454971313
Validation loss: 2.013032555580139

Epoch: 6| Step: 9
Training loss: 0.9292541742324829
Validation loss: 1.9584202766418457

Epoch: 6| Step: 10
Training loss: 0.634023904800415
Validation loss: 2.0320938428243003

Epoch: 6| Step: 11
Training loss: 0.7213824391365051
Validation loss: 1.9973291357358296

Epoch: 6| Step: 12
Training loss: 0.632300853729248
Validation loss: 1.9281189640363057

Epoch: 6| Step: 13
Training loss: 0.849553108215332
Validation loss: 1.975381076335907

Epoch: 152| Step: 0
Training loss: 0.6404658555984497
Validation loss: 1.9460722208023071

Epoch: 6| Step: 1
Training loss: 0.6342750191688538
Validation loss: 1.9220972657203674

Epoch: 6| Step: 2
Training loss: 0.818544864654541
Validation loss: 1.973075270652771

Epoch: 6| Step: 3
Training loss: 1.4035179615020752
Validation loss: 1.975906531016032

Epoch: 6| Step: 4
Training loss: 0.875221848487854
Validation loss: 1.9767218033472698

Epoch: 6| Step: 5
Training loss: 0.5134204626083374
Validation loss: 1.9444738229115803

Epoch: 6| Step: 6
Training loss: 0.4130644202232361
Validation loss: 1.9717019995053608

Epoch: 6| Step: 7
Training loss: 0.5285182595252991
Validation loss: 1.989577054977417

Epoch: 6| Step: 8
Training loss: 0.5983220338821411
Validation loss: 1.9878987669944763

Epoch: 6| Step: 9
Training loss: 0.3828567564487457
Validation loss: 1.9528084993362427

Epoch: 6| Step: 10
Training loss: 0.5951114296913147
Validation loss: 2.017700990041097

Epoch: 6| Step: 11
Training loss: 0.5425140857696533
Validation loss: 1.971467137336731

Epoch: 6| Step: 12
Training loss: 0.5786545872688293
Validation loss: 1.9956921537717183

Epoch: 6| Step: 13
Training loss: 0.7367454767227173
Validation loss: 2.0228786865870156

Epoch: 153| Step: 0
Training loss: 0.7400790452957153
Validation loss: 1.9494107961654663

Epoch: 6| Step: 1
Training loss: 0.38818687200546265
Validation loss: 1.959168255329132

Epoch: 6| Step: 2
Training loss: 0.7249305248260498
Validation loss: 1.9530386924743652

Epoch: 6| Step: 3
Training loss: 0.6336634159088135
Validation loss: 1.965501109759013

Epoch: 6| Step: 4
Training loss: 0.9976626634597778
Validation loss: 2.009395122528076

Epoch: 6| Step: 5
Training loss: 0.792610228061676
Validation loss: 1.9308826327323914

Epoch: 6| Step: 6
Training loss: 0.5061768889427185
Validation loss: 1.9365034500757854

Epoch: 6| Step: 7
Training loss: 1.0437946319580078
Validation loss: 1.9335174361864726

Epoch: 6| Step: 8
Training loss: 0.5801446437835693
Validation loss: 1.9875752528508503

Epoch: 6| Step: 9
Training loss: 0.6459146738052368
Validation loss: 1.943590799967448

Epoch: 6| Step: 10
Training loss: 0.5558833479881287
Validation loss: 1.974065939585368

Epoch: 6| Step: 11
Training loss: 0.4892526865005493
Validation loss: 2.0026100277900696

Epoch: 6| Step: 12
Training loss: 0.7741250991821289
Validation loss: 1.9499977231025696

Epoch: 6| Step: 13
Training loss: 0.3099381923675537
Validation loss: 1.9637020826339722

Epoch: 154| Step: 0
Training loss: 1.0384480953216553
Validation loss: 1.995124916235606

Epoch: 6| Step: 1
Training loss: 0.6776341199874878
Validation loss: 1.9666357636451721

Epoch: 6| Step: 2
Training loss: 0.7036684155464172
Validation loss: 2.0048763950665793

Epoch: 6| Step: 3
Training loss: 0.6578567028045654
Validation loss: 2.056025187174479

Epoch: 6| Step: 4
Training loss: 0.7423219680786133
Validation loss: 1.9722894032796223

Epoch: 6| Step: 5
Training loss: 0.39826613664627075
Validation loss: 1.9837820927302043

Epoch: 6| Step: 6
Training loss: 1.1046509742736816
Validation loss: 1.9356127381324768

Epoch: 6| Step: 7
Training loss: 0.6180351376533508
Validation loss: 2.009996712207794

Epoch: 6| Step: 8
Training loss: 0.6487118601799011
Validation loss: 1.9696879982948303

Epoch: 6| Step: 9
Training loss: 0.6142136454582214
Validation loss: 1.9975077112515767

Epoch: 6| Step: 10
Training loss: 0.45470523834228516
Validation loss: 1.955355703830719

Epoch: 6| Step: 11
Training loss: 0.8359659910202026
Validation loss: 1.9555838505427043

Epoch: 6| Step: 12
Training loss: 0.5296046733856201
Validation loss: 1.9826873143513997

Epoch: 6| Step: 13
Training loss: 0.4712457060813904
Validation loss: 1.9601855079332988

Epoch: 155| Step: 0
Training loss: 0.24746468663215637
Validation loss: 1.9258997440338135

Epoch: 6| Step: 1
Training loss: 0.5066392421722412
Validation loss: 1.9821605285008748

Epoch: 6| Step: 2
Training loss: 0.5308924317359924
Validation loss: 1.9914409319559734

Epoch: 6| Step: 3
Training loss: 0.820641040802002
Validation loss: 2.0113632877667746

Epoch: 6| Step: 4
Training loss: 0.6705551743507385
Validation loss: 1.9491668542226155

Epoch: 6| Step: 5
Training loss: 0.4832012951374054
Validation loss: 1.9797289371490479

Epoch: 6| Step: 6
Training loss: 0.3888358473777771
Validation loss: 2.003732442855835

Epoch: 6| Step: 7
Training loss: 1.0659852027893066
Validation loss: 2.0431949893633523

Epoch: 6| Step: 8
Training loss: 0.41107916831970215
Validation loss: 1.9623314340909321

Epoch: 6| Step: 9
Training loss: 1.3998677730560303
Validation loss: 1.9877154032389324

Epoch: 6| Step: 10
Training loss: 0.8629041910171509
Validation loss: 1.9501712918281555

Epoch: 6| Step: 11
Training loss: 0.4354919493198395
Validation loss: 1.9454630812009175

Epoch: 6| Step: 12
Training loss: 0.9626622200012207
Validation loss: 1.9516633749008179

Epoch: 6| Step: 13
Training loss: 0.9999032616615295
Validation loss: 1.9839100241661072

Epoch: 156| Step: 0
Training loss: 0.42706921696662903
Validation loss: 1.9639782905578613

Epoch: 6| Step: 1
Training loss: 0.5108012557029724
Validation loss: 1.9828061660130818

Epoch: 6| Step: 2
Training loss: 0.7478564977645874
Validation loss: 1.9785595138867695

Epoch: 6| Step: 3
Training loss: 0.7078928351402283
Validation loss: 2.061520218849182

Epoch: 6| Step: 4
Training loss: 0.6839357018470764
Validation loss: 1.9995880325635274

Epoch: 6| Step: 5
Training loss: 1.1098918914794922
Validation loss: 2.0884645779927573

Epoch: 6| Step: 6
Training loss: 0.9556486010551453
Validation loss: 2.0174489418665567

Epoch: 6| Step: 7
Training loss: 0.49903398752212524
Validation loss: 2.0011685490608215

Epoch: 6| Step: 8
Training loss: 0.2951631546020508
Validation loss: 2.0386640429496765

Epoch: 6| Step: 9
Training loss: 0.8770953416824341
Validation loss: 1.9545719623565674

Epoch: 6| Step: 10
Training loss: 0.6398149728775024
Validation loss: 1.9895734985669453

Epoch: 6| Step: 11
Training loss: 0.5787732601165771
Validation loss: 1.9998901685078938

Epoch: 6| Step: 12
Training loss: 1.2453460693359375
Validation loss: 2.0117608110109964

Epoch: 6| Step: 13
Training loss: 0.6132795810699463
Validation loss: 1.9637805223464966

Epoch: 157| Step: 0
Training loss: 0.6701647043228149
Validation loss: 2.05064723889033

Epoch: 6| Step: 1
Training loss: 0.4861217141151428
Validation loss: 1.9673733313878377

Epoch: 6| Step: 2
Training loss: 0.7047974467277527
Validation loss: 1.96345059076945

Epoch: 6| Step: 3
Training loss: 0.5828121900558472
Validation loss: 1.9813490907351177

Epoch: 6| Step: 4
Training loss: 0.4415382146835327
Validation loss: 1.9812049667040508

Epoch: 6| Step: 5
Training loss: 0.8397243022918701
Validation loss: 1.9955307245254517

Epoch: 6| Step: 6
Training loss: 0.7949473261833191
Validation loss: 1.9776124556859334

Epoch: 6| Step: 7
Training loss: 0.8446238040924072
Validation loss: 1.9779808521270752

Epoch: 6| Step: 8
Training loss: 0.5827488899230957
Validation loss: 1.9908040761947632

Epoch: 6| Step: 9
Training loss: 1.0971688032150269
Validation loss: 2.0001307328542075

Epoch: 6| Step: 10
Training loss: 0.8607810735702515
Validation loss: 2.004459003607432

Epoch: 6| Step: 11
Training loss: 0.7566162943840027
Validation loss: 2.012735923131307

Epoch: 6| Step: 12
Training loss: 0.6566063165664673
Validation loss: 1.9758338729540508

Epoch: 6| Step: 13
Training loss: 0.4380831718444824
Validation loss: 1.9737655321757

Epoch: 158| Step: 0
Training loss: 0.7338366508483887
Validation loss: 1.9728175004323323

Epoch: 6| Step: 1
Training loss: 0.7070132493972778
Validation loss: 1.9477447271347046

Epoch: 6| Step: 2
Training loss: 0.9167345762252808
Validation loss: 1.9341601133346558

Epoch: 6| Step: 3
Training loss: 0.5390018224716187
Validation loss: 1.9324481288592021

Epoch: 6| Step: 4
Training loss: 0.661888599395752
Validation loss: 1.9873217344284058

Epoch: 6| Step: 5
Training loss: 0.8420203924179077
Validation loss: 1.9604968825976055

Epoch: 6| Step: 6
Training loss: 0.42513877153396606
Validation loss: 1.9766160647074382

Epoch: 6| Step: 7
Training loss: 0.5057516098022461
Validation loss: 1.9845065871874492

Epoch: 6| Step: 8
Training loss: 0.5894031524658203
Validation loss: 2.039047420024872

Epoch: 6| Step: 9
Training loss: 0.910351574420929
Validation loss: 2.0307560563087463

Epoch: 6| Step: 10
Training loss: 0.4126771092414856
Validation loss: 2.0228051940600076

Epoch: 6| Step: 11
Training loss: 0.8163034319877625
Validation loss: 1.9656851490338643

Epoch: 6| Step: 12
Training loss: 0.7031323909759521
Validation loss: 2.021999736626943

Epoch: 6| Step: 13
Training loss: 0.5451709032058716
Validation loss: 1.95848149061203

Epoch: 159| Step: 0
Training loss: 0.790611982345581
Validation loss: 1.9377604325612385

Epoch: 6| Step: 1
Training loss: 0.8357483148574829
Validation loss: 1.9555790424346924

Epoch: 6| Step: 2
Training loss: 0.4390747547149658
Validation loss: 1.9837804039319356

Epoch: 6| Step: 3
Training loss: 0.6718326807022095
Validation loss: 1.9582093954086304

Epoch: 6| Step: 4
Training loss: 0.6670284867286682
Validation loss: 1.9585355122884114

Epoch: 6| Step: 5
Training loss: 0.7345693111419678
Validation loss: 2.0430752436319985

Epoch: 6| Step: 6
Training loss: 0.6659422516822815
Validation loss: 2.0135064919789634

Epoch: 6| Step: 7
Training loss: 0.6723198890686035
Validation loss: 1.9876098036766052

Epoch: 6| Step: 8
Training loss: 1.4968492984771729
Validation loss: 1.952740987141927

Epoch: 6| Step: 9
Training loss: 1.0418338775634766
Validation loss: 1.9478161732355754

Epoch: 6| Step: 10
Training loss: 0.2461691051721573
Validation loss: 1.9878246386845906

Epoch: 6| Step: 11
Training loss: 0.5417913198471069
Validation loss: 1.99241308371226

Epoch: 6| Step: 12
Training loss: 0.44879359006881714
Validation loss: 1.920337975025177

Epoch: 6| Step: 13
Training loss: 0.4377673864364624
Validation loss: 1.9368407328923543

Epoch: 160| Step: 0
Training loss: 0.6732367277145386
Validation loss: 1.9346047639846802

Epoch: 6| Step: 1
Training loss: 0.9517742395401001
Validation loss: 1.9378629128138225

Epoch: 6| Step: 2
Training loss: 0.4176466166973114
Validation loss: 1.9772566358248393

Epoch: 6| Step: 3
Training loss: 0.2611209750175476
Validation loss: 2.004827698071798

Epoch: 6| Step: 4
Training loss: 0.6718034744262695
Validation loss: 1.9293404817581177

Epoch: 6| Step: 5
Training loss: 0.7254238128662109
Validation loss: 2.0124245087305703

Epoch: 6| Step: 6
Training loss: 1.0303611755371094
Validation loss: 1.9843069712320964

Epoch: 6| Step: 7
Training loss: 1.051945447921753
Validation loss: 1.91996435324351

Epoch: 6| Step: 8
Training loss: 0.6307269334793091
Validation loss: 1.9542720119158428

Epoch: 6| Step: 9
Training loss: 0.5303465127944946
Validation loss: 1.9336507320404053

Epoch: 6| Step: 10
Training loss: 0.760017454624176
Validation loss: 1.9580887754758198

Epoch: 6| Step: 11
Training loss: 0.9430065155029297
Validation loss: 1.9584616820017497

Epoch: 6| Step: 12
Training loss: 0.5347325801849365
Validation loss: 1.9644112586975098

Epoch: 6| Step: 13
Training loss: 0.5330297946929932
Validation loss: 1.9603217244148254

Epoch: 161| Step: 0
Training loss: 0.5489518642425537
Validation loss: 1.9665528337160747

Epoch: 6| Step: 1
Training loss: 0.7932232022285461
Validation loss: 2.0200047890345254

Epoch: 6| Step: 2
Training loss: 0.9346498250961304
Validation loss: 2.034088353315989

Epoch: 6| Step: 3
Training loss: 0.9065171480178833
Validation loss: 2.0277745127677917

Epoch: 6| Step: 4
Training loss: 0.28600239753723145
Validation loss: 2.005091667175293

Epoch: 6| Step: 5
Training loss: 0.3491394519805908
Validation loss: 1.9748862187067668

Epoch: 6| Step: 6
Training loss: 0.6214237809181213
Validation loss: 1.9798118670781453

Epoch: 6| Step: 7
Training loss: 0.5721477270126343
Validation loss: 2.0097831090291343

Epoch: 6| Step: 8
Training loss: 0.5449547171592712
Validation loss: 1.9555534919102986

Epoch: 6| Step: 9
Training loss: 0.8131203651428223
Validation loss: 1.9614954988161724

Epoch: 6| Step: 10
Training loss: 0.5219535827636719
Validation loss: 2.005377689997355

Epoch: 6| Step: 11
Training loss: 0.5840367078781128
Validation loss: 1.9978971878687541

Epoch: 6| Step: 12
Training loss: 0.8904479742050171
Validation loss: 2.0139093001683555

Epoch: 6| Step: 13
Training loss: 1.1584177017211914
Validation loss: 2.0078444878260293

Epoch: 162| Step: 0
Training loss: 1.033102035522461
Validation loss: 2.0361605485280356

Epoch: 6| Step: 1
Training loss: 0.5364431142807007
Validation loss: 1.9786437551180522

Epoch: 6| Step: 2
Training loss: 0.35480815172195435
Validation loss: 2.002850075562795

Epoch: 6| Step: 3
Training loss: 0.7106332182884216
Validation loss: 1.9391327897707622

Epoch: 6| Step: 4
Training loss: 0.8299412727355957
Validation loss: 1.9564847548802693

Epoch: 6| Step: 5
Training loss: 0.5497360229492188
Validation loss: 1.9848988056182861

Epoch: 6| Step: 6
Training loss: 0.6329988837242126
Validation loss: 1.9162541627883911

Epoch: 6| Step: 7
Training loss: 1.1445351839065552
Validation loss: 1.9545278350512187

Epoch: 6| Step: 8
Training loss: 0.5976518392562866
Validation loss: 1.9625678062438965

Epoch: 6| Step: 9
Training loss: 0.486710786819458
Validation loss: 1.9895726044972737

Epoch: 6| Step: 10
Training loss: 0.4847917854785919
Validation loss: 1.9958275357882183

Epoch: 6| Step: 11
Training loss: 1.184906005859375
Validation loss: 2.0309900442759194

Epoch: 6| Step: 12
Training loss: 0.3721156418323517
Validation loss: 2.04673703511556

Epoch: 6| Step: 13
Training loss: 0.7163247466087341
Validation loss: 2.0160027941068015

Epoch: 163| Step: 0
Training loss: 0.7389686107635498
Validation loss: 2.021198332309723

Epoch: 6| Step: 1
Training loss: 0.4520114064216614
Validation loss: 1.9609062274297078

Epoch: 6| Step: 2
Training loss: 0.7251150608062744
Validation loss: 1.9706595540046692

Epoch: 6| Step: 3
Training loss: 0.7606728076934814
Validation loss: 1.9640109539031982

Epoch: 6| Step: 4
Training loss: 0.4784810543060303
Validation loss: 1.9909628033638

Epoch: 6| Step: 5
Training loss: 0.28801482915878296
Validation loss: 1.99362450838089

Epoch: 6| Step: 6
Training loss: 0.7282854318618774
Validation loss: 1.9896055062611897

Epoch: 6| Step: 7
Training loss: 0.41313016414642334
Validation loss: 2.019650677839915

Epoch: 6| Step: 8
Training loss: 0.46058550477027893
Validation loss: 1.949584384759267

Epoch: 6| Step: 9
Training loss: 0.6493110656738281
Validation loss: 1.983829935391744

Epoch: 6| Step: 10
Training loss: 0.9289636015892029
Validation loss: 1.9351292649904888

Epoch: 6| Step: 11
Training loss: 0.6500153541564941
Validation loss: 1.9432515700658162

Epoch: 6| Step: 12
Training loss: 0.8768149614334106
Validation loss: 1.9932560722033184

Epoch: 6| Step: 13
Training loss: 0.49338915944099426
Validation loss: 1.98104989528656

Epoch: 164| Step: 0
Training loss: 0.6157185435295105
Validation loss: 1.9502889315287273

Epoch: 6| Step: 1
Training loss: 0.4720136821269989
Validation loss: 1.9618760347366333

Epoch: 6| Step: 2
Training loss: 0.8471753597259521
Validation loss: 1.9576842586199443

Epoch: 6| Step: 3
Training loss: 0.6065500378608704
Validation loss: 1.9806039532025654

Epoch: 6| Step: 4
Training loss: 0.589242696762085
Validation loss: 1.955701212088267

Epoch: 6| Step: 5
Training loss: 0.5684231519699097
Validation loss: 1.9569169282913208

Epoch: 6| Step: 6
Training loss: 0.8795363903045654
Validation loss: 1.9132452011108398

Epoch: 6| Step: 7
Training loss: 0.5413025617599487
Validation loss: 1.9381609956423442

Epoch: 6| Step: 8
Training loss: 1.023613452911377
Validation loss: 1.9004829128583272

Epoch: 6| Step: 9
Training loss: 0.3443963825702667
Validation loss: 1.9491050640741985

Epoch: 6| Step: 10
Training loss: 0.6698808073997498
Validation loss: 1.9310978253682454

Epoch: 6| Step: 11
Training loss: 0.5320079326629639
Validation loss: 1.9537234902381897

Epoch: 6| Step: 12
Training loss: 0.6276971101760864
Validation loss: 1.9737520217895508

Epoch: 6| Step: 13
Training loss: 0.35835468769073486
Validation loss: 1.9493220647176106

Epoch: 165| Step: 0
Training loss: 0.6549210548400879
Validation loss: 2.0011285543441772

Epoch: 6| Step: 1
Training loss: 0.2669384479522705
Validation loss: 1.9733370542526245

Epoch: 6| Step: 2
Training loss: 0.9638432264328003
Validation loss: 1.9885759154955547

Epoch: 6| Step: 3
Training loss: 0.7084384560585022
Validation loss: 2.0002474586168923

Epoch: 6| Step: 4
Training loss: 0.5063340067863464
Validation loss: 1.9785454869270325

Epoch: 6| Step: 5
Training loss: 0.594353437423706
Validation loss: 1.9812204639116924

Epoch: 6| Step: 6
Training loss: 0.5464107990264893
Validation loss: 1.9899680217107136

Epoch: 6| Step: 7
Training loss: 0.7565944194793701
Validation loss: 1.9463366667429607

Epoch: 6| Step: 8
Training loss: 0.8851770758628845
Validation loss: 1.930046558380127

Epoch: 6| Step: 9
Training loss: 0.7978769540786743
Validation loss: 1.9667574564615886

Epoch: 6| Step: 10
Training loss: 0.478899747133255
Validation loss: 1.9473678469657898

Epoch: 6| Step: 11
Training loss: 0.31846630573272705
Validation loss: 1.992409626642863

Epoch: 6| Step: 12
Training loss: 0.6557265520095825
Validation loss: 1.9896865685780842

Epoch: 6| Step: 13
Training loss: 0.4104575514793396
Validation loss: 1.9933120409647624

Epoch: 166| Step: 0
Training loss: 0.15871648490428925
Validation loss: 1.9672649105389912

Epoch: 6| Step: 1
Training loss: 0.7191619873046875
Validation loss: 1.9608010450998943

Epoch: 6| Step: 2
Training loss: 0.3307229280471802
Validation loss: 1.98600568373998

Epoch: 6| Step: 3
Training loss: 1.2610533237457275
Validation loss: 1.9836963017781575

Epoch: 6| Step: 4
Training loss: 0.6437289714813232
Validation loss: 1.9650050401687622

Epoch: 6| Step: 5
Training loss: 0.739692211151123
Validation loss: 1.9371141990025837

Epoch: 6| Step: 6
Training loss: 0.9226636290550232
Validation loss: 1.9649330178896587

Epoch: 6| Step: 7
Training loss: 0.6927584409713745
Validation loss: 1.9400229056676228

Epoch: 6| Step: 8
Training loss: 0.6314806938171387
Validation loss: 1.974139412244161

Epoch: 6| Step: 9
Training loss: 0.5019267797470093
Validation loss: 1.960443655649821

Epoch: 6| Step: 10
Training loss: 0.8189477920532227
Validation loss: 1.968296746412913

Epoch: 6| Step: 11
Training loss: 0.4424470365047455
Validation loss: 1.993960698445638

Epoch: 6| Step: 12
Training loss: 0.3285786509513855
Validation loss: 1.9710501432418823

Epoch: 6| Step: 13
Training loss: 0.4041594862937927
Validation loss: 2.0280697544415793

Epoch: 167| Step: 0
Training loss: 0.49947884678840637
Validation loss: 1.9566328922907512

Epoch: 6| Step: 1
Training loss: 0.852954626083374
Validation loss: 1.9658260146776836

Epoch: 6| Step: 2
Training loss: 0.503741979598999
Validation loss: 1.9526370962460835

Epoch: 6| Step: 3
Training loss: 0.5777847170829773
Validation loss: 1.9631345470746357

Epoch: 6| Step: 4
Training loss: 0.4172513484954834
Validation loss: 1.9873155156771343

Epoch: 6| Step: 5
Training loss: 0.7173576354980469
Validation loss: 1.9976040919621785

Epoch: 6| Step: 6
Training loss: 0.5228463411331177
Validation loss: 2.0032325784365335

Epoch: 6| Step: 7
Training loss: 0.45916837453842163
Validation loss: 2.031914790471395

Epoch: 6| Step: 8
Training loss: 0.4768334925174713
Validation loss: 2.0061940352121987

Epoch: 6| Step: 9
Training loss: 0.5929509401321411
Validation loss: 1.9682514071464539

Epoch: 6| Step: 10
Training loss: 0.9607999324798584
Validation loss: 1.9452552596728008

Epoch: 6| Step: 11
Training loss: 0.5078718066215515
Validation loss: 1.989061673482259

Epoch: 6| Step: 12
Training loss: 0.645126461982727
Validation loss: 1.9678473671277363

Epoch: 6| Step: 13
Training loss: 0.8424344062805176
Validation loss: 1.9190902908643086

Epoch: 168| Step: 0
Training loss: 0.5628263354301453
Validation loss: 1.9821651975313823

Epoch: 6| Step: 1
Training loss: 0.7292442917823792
Validation loss: 1.935085693995158

Epoch: 6| Step: 2
Training loss: 0.4531455636024475
Validation loss: 1.9597395261128743

Epoch: 6| Step: 3
Training loss: 0.24925515055656433
Validation loss: 1.9723316828409831

Epoch: 6| Step: 4
Training loss: 0.6916757822036743
Validation loss: 1.9806570013364155

Epoch: 6| Step: 5
Training loss: 1.0058895349502563
Validation loss: 2.0098288456598916

Epoch: 6| Step: 6
Training loss: 0.6806082129478455
Validation loss: 1.9736221035321553

Epoch: 6| Step: 7
Training loss: 0.3096567988395691
Validation loss: 1.991593062877655

Epoch: 6| Step: 8
Training loss: 0.43332821130752563
Validation loss: 2.000319023927053

Epoch: 6| Step: 9
Training loss: 1.030382752418518
Validation loss: 2.0404353539148965

Epoch: 6| Step: 10
Training loss: 0.2791687250137329
Validation loss: 1.963694413503011

Epoch: 6| Step: 11
Training loss: 0.4342043101787567
Validation loss: 1.977062702178955

Epoch: 6| Step: 12
Training loss: 0.36085373163223267
Validation loss: 2.0259939630826316

Epoch: 6| Step: 13
Training loss: 0.7148122787475586
Validation loss: 2.0159775813420615

Epoch: 169| Step: 0
Training loss: 0.3834669888019562
Validation loss: 2.019871175289154

Epoch: 6| Step: 1
Training loss: 0.42052096128463745
Validation loss: 1.9809638659159343

Epoch: 6| Step: 2
Training loss: 0.5642639398574829
Validation loss: 1.9611213405927022

Epoch: 6| Step: 3
Training loss: 0.9607311487197876
Validation loss: 1.9442981680234273

Epoch: 6| Step: 4
Training loss: 0.8386422395706177
Validation loss: 1.9547458092371623

Epoch: 6| Step: 5
Training loss: 0.3976513147354126
Validation loss: 1.9756584962209065

Epoch: 6| Step: 6
Training loss: 1.0127383470535278
Validation loss: 1.964542071024577

Epoch: 6| Step: 7
Training loss: 0.5514307022094727
Validation loss: 1.960804005463918

Epoch: 6| Step: 8
Training loss: 0.43672844767570496
Validation loss: 1.9926700194676716

Epoch: 6| Step: 9
Training loss: 0.3514825701713562
Validation loss: 2.0209474166234336

Epoch: 6| Step: 10
Training loss: 0.6526410579681396
Validation loss: 2.029132922490438

Epoch: 6| Step: 11
Training loss: 0.7163902521133423
Validation loss: 2.0169228315353394

Epoch: 6| Step: 12
Training loss: 0.44984036684036255
Validation loss: 1.9754867752393086

Epoch: 6| Step: 13
Training loss: 0.561460018157959
Validation loss: 1.9480016628901164

Epoch: 170| Step: 0
Training loss: 0.548912763595581
Validation loss: 2.005180597305298

Epoch: 6| Step: 1
Training loss: 0.4105398654937744
Validation loss: 1.961516002813975

Epoch: 6| Step: 2
Training loss: 0.4047721028327942
Validation loss: 1.993805170059204

Epoch: 6| Step: 3
Training loss: 0.7442193031311035
Validation loss: 2.0328906774520874

Epoch: 6| Step: 4
Training loss: 0.8636852502822876
Validation loss: 1.9666595458984375

Epoch: 6| Step: 5
Training loss: 0.41825011372566223
Validation loss: 2.006275196870168

Epoch: 6| Step: 6
Training loss: 0.404089093208313
Validation loss: 2.0328195095062256

Epoch: 6| Step: 7
Training loss: 0.7860395312309265
Validation loss: 2.022077818711599

Epoch: 6| Step: 8
Training loss: 1.0205119848251343
Validation loss: 1.9793461163838704

Epoch: 6| Step: 9
Training loss: 0.4062167704105377
Validation loss: 1.9998380343119304

Epoch: 6| Step: 10
Training loss: 0.4316336214542389
Validation loss: 2.01063464085261

Epoch: 6| Step: 11
Training loss: 0.6694839596748352
Validation loss: 1.9868210752805073

Epoch: 6| Step: 12
Training loss: 0.6532374620437622
Validation loss: 1.9658066630363464

Epoch: 6| Step: 13
Training loss: 0.34358179569244385
Validation loss: 1.9710372686386108

Epoch: 171| Step: 0
Training loss: 0.8866572380065918
Validation loss: 1.966483970483144

Epoch: 6| Step: 1
Training loss: 0.7582622766494751
Validation loss: 1.9702879389127095

Epoch: 6| Step: 2
Training loss: 0.45928478240966797
Validation loss: 2.0180105765660605

Epoch: 6| Step: 3
Training loss: 0.3850802183151245
Validation loss: 1.9725716908772786

Epoch: 6| Step: 4
Training loss: 0.805000901222229
Validation loss: 1.987689197063446

Epoch: 6| Step: 5
Training loss: 0.48214221000671387
Validation loss: 1.9730405410130818

Epoch: 6| Step: 6
Training loss: 0.7217528820037842
Validation loss: 1.9907243053118389

Epoch: 6| Step: 7
Training loss: 0.46537092328071594
Validation loss: 1.937311331431071

Epoch: 6| Step: 8
Training loss: 0.5619396567344666
Validation loss: 1.9250852664311726

Epoch: 6| Step: 9
Training loss: 0.39765268564224243
Validation loss: 1.9527643124262493

Epoch: 6| Step: 10
Training loss: 0.6951605081558228
Validation loss: 1.9601225852966309

Epoch: 6| Step: 11
Training loss: 0.38464829325675964
Validation loss: 1.9715921481450398

Epoch: 6| Step: 12
Training loss: 0.460407018661499
Validation loss: 1.9554299513498943

Epoch: 6| Step: 13
Training loss: 0.7168015241622925
Validation loss: 1.9376962383588154

Epoch: 172| Step: 0
Training loss: 0.37527087330818176
Validation loss: 1.9788738091786702

Epoch: 6| Step: 1
Training loss: 0.6674793362617493
Validation loss: 2.0005622506141663

Epoch: 6| Step: 2
Training loss: 0.6483792662620544
Validation loss: 2.0124101638793945

Epoch: 6| Step: 3
Training loss: 0.43003278970718384
Validation loss: 1.9670774737993877

Epoch: 6| Step: 4
Training loss: 0.5941522121429443
Validation loss: 1.957046906153361

Epoch: 6| Step: 5
Training loss: 0.7114211916923523
Validation loss: 1.935438831647237

Epoch: 6| Step: 6
Training loss: 0.3748203217983246
Validation loss: 2.023867428302765

Epoch: 6| Step: 7
Training loss: 1.0481525659561157
Validation loss: 1.9749124844868977

Epoch: 6| Step: 8
Training loss: 0.3428885340690613
Validation loss: 1.9488199949264526

Epoch: 6| Step: 9
Training loss: 0.42529672384262085
Validation loss: 2.0109541614850364

Epoch: 6| Step: 10
Training loss: 0.6915776133537292
Validation loss: 2.001466929912567

Epoch: 6| Step: 11
Training loss: 0.38754281401634216
Validation loss: 1.9659137924512227

Epoch: 6| Step: 12
Training loss: 0.888687014579773
Validation loss: 2.0772083401679993

Epoch: 6| Step: 13
Training loss: 0.8681889772415161
Validation loss: 2.0528440872828164

Epoch: 173| Step: 0
Training loss: 0.616504430770874
Validation loss: 2.054357568422953

Epoch: 6| Step: 1
Training loss: 0.5620740056037903
Validation loss: 1.9742794036865234

Epoch: 6| Step: 2
Training loss: 0.24968957901000977
Validation loss: 2.029788851737976

Epoch: 6| Step: 3
Training loss: 0.8865213990211487
Validation loss: 1.993322491645813

Epoch: 6| Step: 4
Training loss: 0.5533282160758972
Validation loss: 1.9641135533650715

Epoch: 6| Step: 5
Training loss: 0.7856015563011169
Validation loss: 1.9455737272898357

Epoch: 6| Step: 6
Training loss: 0.45152831077575684
Validation loss: 1.965351363023122

Epoch: 6| Step: 7
Training loss: 0.533771276473999
Validation loss: 1.9874274929364522

Epoch: 6| Step: 8
Training loss: 0.42916059494018555
Validation loss: 2.0256365537643433

Epoch: 6| Step: 9
Training loss: 0.7277297377586365
Validation loss: 2.0058128237724304

Epoch: 6| Step: 10
Training loss: 0.4540126323699951
Validation loss: 2.0227847695350647

Epoch: 6| Step: 11
Training loss: 0.592212438583374
Validation loss: 1.9944485823313396

Epoch: 6| Step: 12
Training loss: 0.6718602776527405
Validation loss: 2.016285260518392

Epoch: 6| Step: 13
Training loss: 0.9397374391555786
Validation loss: 2.029393752415975

Epoch: 174| Step: 0
Training loss: 0.565287709236145
Validation loss: 1.9735334714253743

Epoch: 6| Step: 1
Training loss: 0.6683217883110046
Validation loss: 1.9635921716690063

Epoch: 6| Step: 2
Training loss: 0.45199766755104065
Validation loss: 1.9599103728930156

Epoch: 6| Step: 3
Training loss: 0.4072553515434265
Validation loss: 1.9352401693662007

Epoch: 6| Step: 4
Training loss: 0.6397005319595337
Validation loss: 1.951672613620758

Epoch: 6| Step: 5
Training loss: 0.44590064883232117
Validation loss: 1.9941267172495525

Epoch: 6| Step: 6
Training loss: 0.5698295831680298
Validation loss: 2.009179095427195

Epoch: 6| Step: 7
Training loss: 0.7465910911560059
Validation loss: 1.9849396546681721

Epoch: 6| Step: 8
Training loss: 0.9098969101905823
Validation loss: 1.9711759090423584

Epoch: 6| Step: 9
Training loss: 0.5395094752311707
Validation loss: 1.935869614283244

Epoch: 6| Step: 10
Training loss: 0.49998587369918823
Validation loss: 1.9259944955507915

Epoch: 6| Step: 11
Training loss: 0.8843489289283752
Validation loss: 1.9879177014033

Epoch: 6| Step: 12
Training loss: 0.4818432927131653
Validation loss: 1.950980265935262

Epoch: 6| Step: 13
Training loss: 0.7119121551513672
Validation loss: 1.9470030864079793

Epoch: 175| Step: 0
Training loss: 0.8549936413764954
Validation loss: 1.9512918591499329

Epoch: 6| Step: 1
Training loss: 0.6377208828926086
Validation loss: 1.9806538224220276

Epoch: 6| Step: 2
Training loss: 0.6199512481689453
Validation loss: 2.018757780392965

Epoch: 6| Step: 3
Training loss: 0.27236589789390564
Validation loss: 1.9808663129806519

Epoch: 6| Step: 4
Training loss: 0.653432309627533
Validation loss: 1.9568375945091248

Epoch: 6| Step: 5
Training loss: 0.4746306538581848
Validation loss: 1.9854151805241902

Epoch: 6| Step: 6
Training loss: 0.7123538255691528
Validation loss: 1.9537137746810913

Epoch: 6| Step: 7
Training loss: 0.5808310508728027
Validation loss: 1.9434687495231628

Epoch: 6| Step: 8
Training loss: 0.5265540480613708
Validation loss: 1.9620135227839153

Epoch: 6| Step: 9
Training loss: 0.317091166973114
Validation loss: 1.909004847208659

Epoch: 6| Step: 10
Training loss: 0.5747836828231812
Validation loss: 1.9555110732714336

Epoch: 6| Step: 11
Training loss: 0.756161093711853
Validation loss: 2.019169886906942

Epoch: 6| Step: 12
Training loss: 0.6121523380279541
Validation loss: 1.9585322936375935

Epoch: 6| Step: 13
Training loss: 0.7213033437728882
Validation loss: 2.0488206148147583

Epoch: 176| Step: 0
Training loss: 0.32571345567703247
Validation loss: 1.9735607504844666

Epoch: 6| Step: 1
Training loss: 0.5318682193756104
Validation loss: 1.9867947498957317

Epoch: 6| Step: 2
Training loss: 0.34060418605804443
Validation loss: 2.007559299468994

Epoch: 6| Step: 3
Training loss: 0.9724608659744263
Validation loss: 2.0284794171651206

Epoch: 6| Step: 4
Training loss: 0.8608111143112183
Validation loss: 1.9420400261878967

Epoch: 6| Step: 5
Training loss: 0.5601977705955505
Validation loss: 2.0032909711201987

Epoch: 6| Step: 6
Training loss: 0.47862398624420166
Validation loss: 1.9366146127382915

Epoch: 6| Step: 7
Training loss: 0.7230092287063599
Validation loss: 1.9761793613433838

Epoch: 6| Step: 8
Training loss: 0.5062347650527954
Validation loss: 1.968982736269633

Epoch: 6| Step: 9
Training loss: 0.6459132432937622
Validation loss: 1.9675594369570415

Epoch: 6| Step: 10
Training loss: 0.7458784580230713
Validation loss: 1.9742342432339985

Epoch: 6| Step: 11
Training loss: 0.5583305954933167
Validation loss: 1.95197461048762

Epoch: 6| Step: 12
Training loss: 0.8363356590270996
Validation loss: 2.012603978315989

Epoch: 6| Step: 13
Training loss: 0.3650413453578949
Validation loss: 1.965995450814565

Epoch: 177| Step: 0
Training loss: 0.4067263901233673
Validation loss: 1.9629360437393188

Epoch: 6| Step: 1
Training loss: 0.6873019933700562
Validation loss: 1.9622787435849507

Epoch: 6| Step: 2
Training loss: 0.6171016693115234
Validation loss: 2.000289479891459

Epoch: 6| Step: 3
Training loss: 0.2631152272224426
Validation loss: 1.9608655373255413

Epoch: 6| Step: 4
Training loss: 0.64348965883255
Validation loss: 1.958701988061269

Epoch: 6| Step: 5
Training loss: 0.6781439781188965
Validation loss: 1.9774457613627117

Epoch: 6| Step: 6
Training loss: 0.8598580360412598
Validation loss: 1.957492729028066

Epoch: 6| Step: 7
Training loss: 0.4605560302734375
Validation loss: 1.9595189491907756

Epoch: 6| Step: 8
Training loss: 0.36539024114608765
Validation loss: 1.9242276350657146

Epoch: 6| Step: 9
Training loss: 0.6036879420280457
Validation loss: 1.9663824836413066

Epoch: 6| Step: 10
Training loss: 0.37702447175979614
Validation loss: 1.9667312900225322

Epoch: 6| Step: 11
Training loss: 0.3047565817832947
Validation loss: 1.973776678244273

Epoch: 6| Step: 12
Training loss: 0.9579736590385437
Validation loss: 1.969352384408315

Epoch: 6| Step: 13
Training loss: 0.5666144490242004
Validation loss: 2.0023598670959473

Epoch: 178| Step: 0
Training loss: 0.16152282059192657
Validation loss: 1.9624724785486858

Epoch: 6| Step: 1
Training loss: 0.8061711192131042
Validation loss: 1.9875975847244263

Epoch: 6| Step: 2
Training loss: 0.5955837965011597
Validation loss: 1.9829048713048298

Epoch: 6| Step: 3
Training loss: 0.3648185729980469
Validation loss: 2.001284122467041

Epoch: 6| Step: 4
Training loss: 0.9548929929733276
Validation loss: 1.970037817955017

Epoch: 6| Step: 5
Training loss: 0.42803943157196045
Validation loss: 1.9909508228302002

Epoch: 6| Step: 6
Training loss: 0.4752538800239563
Validation loss: 1.9618208607037861

Epoch: 6| Step: 7
Training loss: 0.7584718465805054
Validation loss: 2.0099198818206787

Epoch: 6| Step: 8
Training loss: 0.5254503488540649
Validation loss: 1.984982669353485

Epoch: 6| Step: 9
Training loss: 0.4180193245410919
Validation loss: 1.9873406291007996

Epoch: 6| Step: 10
Training loss: 0.5868157148361206
Validation loss: 2.011902093887329

Epoch: 6| Step: 11
Training loss: 0.4714621305465698
Validation loss: 1.970578412214915

Epoch: 6| Step: 12
Training loss: 0.44099634885787964
Validation loss: 1.9632332722345989

Epoch: 6| Step: 13
Training loss: 0.4185907244682312
Validation loss: 1.9616459806760151

Epoch: 179| Step: 0
Training loss: 0.42966949939727783
Validation loss: 2.036973754564921

Epoch: 6| Step: 1
Training loss: 0.4369128942489624
Validation loss: 2.0054046710332236

Epoch: 6| Step: 2
Training loss: 0.766537070274353
Validation loss: 1.9792788624763489

Epoch: 6| Step: 3
Training loss: 0.5251250863075256
Validation loss: 2.0116825103759766

Epoch: 6| Step: 4
Training loss: 0.8454627990722656
Validation loss: 2.0128527084986367

Epoch: 6| Step: 5
Training loss: 0.7025423049926758
Validation loss: 2.012498060862223

Epoch: 6| Step: 6
Training loss: 0.5442124605178833
Validation loss: 1.975545605023702

Epoch: 6| Step: 7
Training loss: 0.34578579664230347
Validation loss: 2.0341190298398337

Epoch: 6| Step: 8
Training loss: 0.22633999586105347
Validation loss: 1.9808038870493572

Epoch: 6| Step: 9
Training loss: 0.30018848180770874
Validation loss: 1.9686022996902466

Epoch: 6| Step: 10
Training loss: 0.6838939189910889
Validation loss: 1.9618971745173137

Epoch: 6| Step: 11
Training loss: 0.42534247040748596
Validation loss: 1.9896479646364849

Epoch: 6| Step: 12
Training loss: 0.36210089921951294
Validation loss: 1.987471918265025

Epoch: 6| Step: 13
Training loss: 0.7595888376235962
Validation loss: 1.991987943649292

Epoch: 180| Step: 0
Training loss: 0.9018282890319824
Validation loss: 1.9821778933207195

Epoch: 6| Step: 1
Training loss: 0.7254794836044312
Validation loss: 1.9909782409667969

Epoch: 6| Step: 2
Training loss: 0.40331438183784485
Validation loss: 2.0024584333101907

Epoch: 6| Step: 3
Training loss: 0.47145965695381165
Validation loss: 2.058316648006439

Epoch: 6| Step: 4
Training loss: 0.7243660688400269
Validation loss: 1.996371865272522

Epoch: 6| Step: 5
Training loss: 0.4256468415260315
Validation loss: 1.998805820941925

Epoch: 6| Step: 6
Training loss: 0.9280967712402344
Validation loss: 1.9487494627634685

Epoch: 6| Step: 7
Training loss: 0.26755672693252563
Validation loss: 1.9358006914456685

Epoch: 6| Step: 8
Training loss: 0.5845715999603271
Validation loss: 1.9687682588895161

Epoch: 6| Step: 9
Training loss: 0.40052682161331177
Validation loss: 2.0054816603660583

Epoch: 6| Step: 10
Training loss: 0.45355844497680664
Validation loss: 1.9634865522384644

Epoch: 6| Step: 11
Training loss: 0.47777703404426575
Validation loss: 1.961938997109731

Epoch: 6| Step: 12
Training loss: 0.32650309801101685
Validation loss: 1.946410636107127

Epoch: 6| Step: 13
Training loss: 0.26506245136260986
Validation loss: 1.9624434908231099

Epoch: 181| Step: 0
Training loss: 0.5762863159179688
Validation loss: 1.9950106143951416

Epoch: 6| Step: 1
Training loss: 0.6229448318481445
Validation loss: 1.9584529797236125

Epoch: 6| Step: 2
Training loss: 0.4340277314186096
Validation loss: 1.9285766084988911

Epoch: 6| Step: 3
Training loss: 0.4743015766143799
Validation loss: 2.017322301864624

Epoch: 6| Step: 4
Training loss: 0.35324859619140625
Validation loss: 1.9450562198956807

Epoch: 6| Step: 5
Training loss: 0.35545802116394043
Validation loss: 1.9497948288917542

Epoch: 6| Step: 6
Training loss: 0.6360562443733215
Validation loss: 1.9827044010162354

Epoch: 6| Step: 7
Training loss: 0.6097704172134399
Validation loss: 1.953573723634084

Epoch: 6| Step: 8
Training loss: 0.7235373854637146
Validation loss: 1.9906817475954692

Epoch: 6| Step: 9
Training loss: 0.3435582220554352
Validation loss: 2.0052502751350403

Epoch: 6| Step: 10
Training loss: 0.8970857858657837
Validation loss: 1.9715093771616619

Epoch: 6| Step: 11
Training loss: 0.5040134191513062
Validation loss: 1.9872202277183533

Epoch: 6| Step: 12
Training loss: 0.44991517066955566
Validation loss: 2.0057301918665567

Epoch: 6| Step: 13
Training loss: 0.502984344959259
Validation loss: 1.944011648495992

Epoch: 182| Step: 0
Training loss: 0.6497092247009277
Validation loss: 2.0180800755818686

Epoch: 6| Step: 1
Training loss: 0.3010062575340271
Validation loss: 1.9495479663213093

Epoch: 6| Step: 2
Training loss: 0.5388782620429993
Validation loss: 2.0178213119506836

Epoch: 6| Step: 3
Training loss: 0.25997841358184814
Validation loss: 1.9654751618703206

Epoch: 6| Step: 4
Training loss: 0.4053446650505066
Validation loss: 1.985079566637675

Epoch: 6| Step: 5
Training loss: 1.288095235824585
Validation loss: 1.9836185971895854

Epoch: 6| Step: 6
Training loss: 0.5259560346603394
Validation loss: 1.9835765560468037

Epoch: 6| Step: 7
Training loss: 0.8030118942260742
Validation loss: 2.0072235465049744

Epoch: 6| Step: 8
Training loss: 0.2086920589208603
Validation loss: 1.9868016640345256

Epoch: 6| Step: 9
Training loss: 0.7143034934997559
Validation loss: 1.9853917161623638

Epoch: 6| Step: 10
Training loss: 0.4614548087120056
Validation loss: 1.9709267218907673

Epoch: 6| Step: 11
Training loss: 0.6993652582168579
Validation loss: 1.9515650272369385

Epoch: 6| Step: 12
Training loss: 0.5749784708023071
Validation loss: 1.9826749761899312

Epoch: 6| Step: 13
Training loss: 0.625253438949585
Validation loss: 1.9707661668459575

Epoch: 183| Step: 0
Training loss: 0.3329121768474579
Validation loss: 1.9320154984792073

Epoch: 6| Step: 1
Training loss: 0.30442869663238525
Validation loss: 2.0009944637616477

Epoch: 6| Step: 2
Training loss: 0.44738301634788513
Validation loss: 1.9803429047266643

Epoch: 6| Step: 3
Training loss: 0.28918522596359253
Validation loss: 1.991573731104533

Epoch: 6| Step: 4
Training loss: 1.0900572538375854
Validation loss: 1.9757517377535503

Epoch: 6| Step: 5
Training loss: 1.1324288845062256
Validation loss: 2.030993421872457

Epoch: 6| Step: 6
Training loss: 0.49007177352905273
Validation loss: 2.0049312512079873

Epoch: 6| Step: 7
Training loss: 0.6957005262374878
Validation loss: 2.04483300447464

Epoch: 6| Step: 8
Training loss: 0.3072270154953003
Validation loss: 1.9768896102905273

Epoch: 6| Step: 9
Training loss: 0.26004618406295776
Validation loss: 1.9624765515327454

Epoch: 6| Step: 10
Training loss: 0.16449874639511108
Validation loss: 1.9824341734250386

Epoch: 6| Step: 11
Training loss: 0.41565343737602234
Validation loss: 1.9498473207155864

Epoch: 6| Step: 12
Training loss: 0.5319428443908691
Validation loss: 2.0016376972198486

Epoch: 6| Step: 13
Training loss: 0.9956109523773193
Validation loss: 1.991226355234782

Epoch: 184| Step: 0
Training loss: 0.5849420428276062
Validation loss: 2.0111791094144187

Epoch: 6| Step: 1
Training loss: 0.8738412261009216
Validation loss: 1.9843679269154866

Epoch: 6| Step: 2
Training loss: 0.31212905049324036
Validation loss: 2.036876400311788

Epoch: 6| Step: 3
Training loss: 0.6855005621910095
Validation loss: 1.9690799117088318

Epoch: 6| Step: 4
Training loss: 0.19175991415977478
Validation loss: 2.023528059323629

Epoch: 6| Step: 5
Training loss: 0.7304191589355469
Validation loss: 1.999931315581004

Epoch: 6| Step: 6
Training loss: 0.29926374554634094
Validation loss: 1.9681238730748494

Epoch: 6| Step: 7
Training loss: 0.6446207761764526
Validation loss: 1.9882432023684184

Epoch: 6| Step: 8
Training loss: 0.4584980607032776
Validation loss: 1.9249362150828044

Epoch: 6| Step: 9
Training loss: 0.955282986164093
Validation loss: 1.9901447892189026

Epoch: 6| Step: 10
Training loss: 0.2795588970184326
Validation loss: 2.0064974228541055

Epoch: 6| Step: 11
Training loss: 0.6684800386428833
Validation loss: 1.9593612353007

Epoch: 6| Step: 12
Training loss: 0.3549194633960724
Validation loss: 2.0255903601646423

Epoch: 6| Step: 13
Training loss: 0.25176650285720825
Validation loss: 1.9839860598246257

Epoch: 185| Step: 0
Training loss: 0.3899122178554535
Validation loss: 1.9240589340527852

Epoch: 6| Step: 1
Training loss: 0.8981533050537109
Validation loss: 1.9749948382377625

Epoch: 6| Step: 2
Training loss: 0.4553152024745941
Validation loss: 1.941511611143748

Epoch: 6| Step: 3
Training loss: 0.38881105184555054
Validation loss: 1.941975514094035

Epoch: 6| Step: 4
Training loss: 0.7843308448791504
Validation loss: 1.9312227765719097

Epoch: 6| Step: 5
Training loss: 0.5788977146148682
Validation loss: 1.953350265820821

Epoch: 6| Step: 6
Training loss: 0.1746080070734024
Validation loss: 1.966512421766917

Epoch: 6| Step: 7
Training loss: 0.6896233558654785
Validation loss: 1.9960177739461262

Epoch: 6| Step: 8
Training loss: 0.38796600699424744
Validation loss: 1.9722461899121602

Epoch: 6| Step: 9
Training loss: 0.654503583908081
Validation loss: 1.98449311653773

Epoch: 6| Step: 10
Training loss: 0.35388123989105225
Validation loss: 1.9126882354418437

Epoch: 6| Step: 11
Training loss: 0.5057902336120605
Validation loss: 1.977269450823466

Epoch: 6| Step: 12
Training loss: 0.39058974385261536
Validation loss: 1.972500205039978

Epoch: 6| Step: 13
Training loss: 0.5445868968963623
Validation loss: 1.946999688943227

Epoch: 186| Step: 0
Training loss: 0.44731301069259644
Validation loss: 1.9771737456321716

Epoch: 6| Step: 1
Training loss: 0.6190517544746399
Validation loss: 1.9984248876571655

Epoch: 6| Step: 2
Training loss: 0.3198715150356293
Validation loss: 1.9918983181317647

Epoch: 6| Step: 3
Training loss: 0.26491212844848633
Validation loss: 1.9582102100054424

Epoch: 6| Step: 4
Training loss: 0.4512398838996887
Validation loss: 1.967205246289571

Epoch: 6| Step: 5
Training loss: 0.5939974784851074
Validation loss: 1.979351242383321

Epoch: 6| Step: 6
Training loss: 0.6619017124176025
Validation loss: 1.9758957227071126

Epoch: 6| Step: 7
Training loss: 0.409230500459671
Validation loss: 2.005320648352305

Epoch: 6| Step: 8
Training loss: 0.5529056787490845
Validation loss: 1.9716860453287761

Epoch: 6| Step: 9
Training loss: 0.8851571083068848
Validation loss: 1.9692271153132122

Epoch: 6| Step: 10
Training loss: 0.4128986895084381
Validation loss: 1.9658827980359395

Epoch: 6| Step: 11
Training loss: 0.7127008438110352
Validation loss: 1.9812769691149394

Epoch: 6| Step: 12
Training loss: 0.882337212562561
Validation loss: 2.011968731880188

Epoch: 6| Step: 13
Training loss: 0.3897707760334015
Validation loss: 2.0240110556284585

Epoch: 187| Step: 0
Training loss: 0.5681749582290649
Validation loss: 2.0674331386884055

Epoch: 6| Step: 1
Training loss: 0.42107000946998596
Validation loss: 1.9986042380332947

Epoch: 6| Step: 2
Training loss: 0.49852055311203003
Validation loss: 1.9857061107953389

Epoch: 6| Step: 3
Training loss: 0.38186734914779663
Validation loss: 1.9490996996561687

Epoch: 6| Step: 4
Training loss: 0.49407267570495605
Validation loss: 1.9792665243148804

Epoch: 6| Step: 5
Training loss: 0.7069560885429382
Validation loss: 1.9787447651227315

Epoch: 6| Step: 6
Training loss: 0.5248691439628601
Validation loss: 1.9733835458755493

Epoch: 6| Step: 7
Training loss: 0.7359617948532104
Validation loss: 1.944943944613139

Epoch: 6| Step: 8
Training loss: 0.39753198623657227
Validation loss: 1.948091189066569

Epoch: 6| Step: 9
Training loss: 0.34764671325683594
Validation loss: 1.9525009393692017

Epoch: 6| Step: 10
Training loss: 0.5559771060943604
Validation loss: 1.9852436184883118

Epoch: 6| Step: 11
Training loss: 1.111527442932129
Validation loss: 1.9988848964373271

Epoch: 6| Step: 12
Training loss: 1.0750994682312012
Validation loss: 1.9816529552141826

Epoch: 6| Step: 13
Training loss: 0.4572015106678009
Validation loss: 1.9842711488405864

Epoch: 188| Step: 0
Training loss: 0.46064233779907227
Validation loss: 2.0193422039349875

Epoch: 6| Step: 1
Training loss: 0.46117085218429565
Validation loss: 2.0055335760116577

Epoch: 6| Step: 2
Training loss: 0.4320110082626343
Validation loss: 2.0025500456492105

Epoch: 6| Step: 3
Training loss: 0.394386887550354
Validation loss: 1.9979966680208843

Epoch: 6| Step: 4
Training loss: 1.0490379333496094
Validation loss: 1.980788270632426

Epoch: 6| Step: 5
Training loss: 0.48694169521331787
Validation loss: 1.9507520198822021

Epoch: 6| Step: 6
Training loss: 0.8173186779022217
Validation loss: 1.9605310360590618

Epoch: 6| Step: 7
Training loss: 0.5700176954269409
Validation loss: 2.0167770385742188

Epoch: 6| Step: 8
Training loss: 0.49110913276672363
Validation loss: 1.9841605027516682

Epoch: 6| Step: 9
Training loss: 0.49395129084587097
Validation loss: 2.022576868534088

Epoch: 6| Step: 10
Training loss: 0.3170569837093353
Validation loss: 2.0010856986045837

Epoch: 6| Step: 11
Training loss: 0.21863625943660736
Validation loss: 1.970746099948883

Epoch: 6| Step: 12
Training loss: 0.6836774349212646
Validation loss: 1.9829509456952412

Epoch: 6| Step: 13
Training loss: 0.390805721282959
Validation loss: 1.9547047813733418

Epoch: 189| Step: 0
Training loss: 0.3873574137687683
Validation loss: 2.0020358761151633

Epoch: 6| Step: 1
Training loss: 0.2464778572320938
Validation loss: 1.9714647730191548

Epoch: 6| Step: 2
Training loss: 0.46883442997932434
Validation loss: 1.9558973511060078

Epoch: 6| Step: 3
Training loss: 0.5509560108184814
Validation loss: 1.951724886894226

Epoch: 6| Step: 4
Training loss: 0.6384515762329102
Validation loss: 1.9639240304629009

Epoch: 6| Step: 5
Training loss: 0.6055960655212402
Validation loss: 1.9642081260681152

Epoch: 6| Step: 6
Training loss: 0.6491965055465698
Validation loss: 1.9418918291727703

Epoch: 6| Step: 7
Training loss: 0.7572782635688782
Validation loss: 1.9938923517862956

Epoch: 6| Step: 8
Training loss: 0.34386146068573
Validation loss: 2.0098737875620523

Epoch: 6| Step: 9
Training loss: 0.34312883019447327
Validation loss: 1.9643756945927937

Epoch: 6| Step: 10
Training loss: 0.29770177602767944
Validation loss: 2.022597928841909

Epoch: 6| Step: 11
Training loss: 0.6849840879440308
Validation loss: 1.9846242268880208

Epoch: 6| Step: 12
Training loss: 0.5152943134307861
Validation loss: 1.9613242546717327

Epoch: 6| Step: 13
Training loss: 0.8875209093093872
Validation loss: 1.9870096445083618

Epoch: 190| Step: 0
Training loss: 0.25011271238327026
Validation loss: 1.9549418091773987

Epoch: 6| Step: 1
Training loss: 0.5197374820709229
Validation loss: 1.9351356426874797

Epoch: 6| Step: 2
Training loss: 0.4052174985408783
Validation loss: 1.9546679258346558

Epoch: 6| Step: 3
Training loss: 0.6347724795341492
Validation loss: 1.9761922558148701

Epoch: 6| Step: 4
Training loss: 0.5386789441108704
Validation loss: 1.9346380631128948

Epoch: 6| Step: 5
Training loss: 0.604789137840271
Validation loss: 1.9944688081741333

Epoch: 6| Step: 6
Training loss: 0.40067189931869507
Validation loss: 1.9671015342076619

Epoch: 6| Step: 7
Training loss: 0.23567256331443787
Validation loss: 1.9529829621315002

Epoch: 6| Step: 8
Training loss: 0.9148650169372559
Validation loss: 1.9463592171669006

Epoch: 6| Step: 9
Training loss: 0.38572752475738525
Validation loss: 1.9526850581169128

Epoch: 6| Step: 10
Training loss: 0.7969710826873779
Validation loss: 2.0063976844151816

Epoch: 6| Step: 11
Training loss: 0.4106341004371643
Validation loss: 1.9812124967575073

Epoch: 6| Step: 12
Training loss: 0.5253024101257324
Validation loss: 1.9312581817309062

Epoch: 6| Step: 13
Training loss: 0.42866063117980957
Validation loss: 2.0239988565444946

Epoch: 191| Step: 0
Training loss: 0.706240177154541
Validation loss: 1.9431579907735188

Epoch: 6| Step: 1
Training loss: 0.5944845676422119
Validation loss: 1.9675966898600261

Epoch: 6| Step: 2
Training loss: 0.23192274570465088
Validation loss: 1.923713505268097

Epoch: 6| Step: 3
Training loss: 0.2613150179386139
Validation loss: 2.004694163799286

Epoch: 6| Step: 4
Training loss: 0.3125620484352112
Validation loss: 1.9798985918362935

Epoch: 6| Step: 5
Training loss: 0.4047562777996063
Validation loss: 1.9449943900108337

Epoch: 6| Step: 6
Training loss: 0.4296363294124603
Validation loss: 1.9879345496495564

Epoch: 6| Step: 7
Training loss: 1.0675387382507324
Validation loss: 2.031154235204061

Epoch: 6| Step: 8
Training loss: 0.5269713401794434
Validation loss: 2.045389175415039

Epoch: 6| Step: 9
Training loss: 0.6030678749084473
Validation loss: 2.0192102789878845

Epoch: 6| Step: 10
Training loss: 0.4849926829338074
Validation loss: 1.9891287088394165

Epoch: 6| Step: 11
Training loss: 0.612004816532135
Validation loss: 1.9706110556920369

Epoch: 6| Step: 12
Training loss: 0.6650566458702087
Validation loss: 2.0122711857159934

Epoch: 6| Step: 13
Training loss: 0.7812737822532654
Validation loss: 1.9871698220570881

Epoch: 192| Step: 0
Training loss: 0.2870739698410034
Validation loss: 1.9510328372319539

Epoch: 6| Step: 1
Training loss: 0.3746163249015808
Validation loss: 1.9735368291536968

Epoch: 6| Step: 2
Training loss: 0.4496140480041504
Validation loss: 1.9596197605133057

Epoch: 6| Step: 3
Training loss: 0.7912745475769043
Validation loss: 1.9505244096120198

Epoch: 6| Step: 4
Training loss: 0.3509555459022522
Validation loss: 1.9830269018809001

Epoch: 6| Step: 5
Training loss: 0.5714606046676636
Validation loss: 1.951785643895467

Epoch: 6| Step: 6
Training loss: 0.46640709042549133
Validation loss: 1.9921933611234028

Epoch: 6| Step: 7
Training loss: 0.585693895816803
Validation loss: 1.9197302063306172

Epoch: 6| Step: 8
Training loss: 0.2960472106933594
Validation loss: 1.9453829526901245

Epoch: 6| Step: 9
Training loss: 0.43274128437042236
Validation loss: 1.946682870388031

Epoch: 6| Step: 10
Training loss: 0.32652637362480164
Validation loss: 1.9592647949854534

Epoch: 6| Step: 11
Training loss: 0.7946655750274658
Validation loss: 1.991756280263265

Epoch: 6| Step: 12
Training loss: 1.0566099882125854
Validation loss: 1.9211507836977642

Epoch: 6| Step: 13
Training loss: 0.646406888961792
Validation loss: 1.91185595591863

Epoch: 193| Step: 0
Training loss: 0.37284570932388306
Validation loss: 1.9850669304529827

Epoch: 6| Step: 1
Training loss: 0.2938127815723419
Validation loss: 1.989422619342804

Epoch: 6| Step: 2
Training loss: 0.3626866042613983
Validation loss: 1.9910711844762166

Epoch: 6| Step: 3
Training loss: 0.6618736386299133
Validation loss: 1.9529560804367065

Epoch: 6| Step: 4
Training loss: 0.4345797002315521
Validation loss: 1.9984420537948608

Epoch: 6| Step: 5
Training loss: 0.5828540325164795
Validation loss: 1.9825159509976704

Epoch: 6| Step: 6
Training loss: 0.8975543975830078
Validation loss: 1.9709772268931072

Epoch: 6| Step: 7
Training loss: 0.9190613031387329
Validation loss: 1.9659371972084045

Epoch: 6| Step: 8
Training loss: 0.426127552986145
Validation loss: 1.939069668451945

Epoch: 6| Step: 9
Training loss: 0.46297991275787354
Validation loss: 1.9962843457857768

Epoch: 6| Step: 10
Training loss: 0.4489620327949524
Validation loss: 1.9522432287534077

Epoch: 6| Step: 11
Training loss: 0.43635308742523193
Validation loss: 1.9772590796152751

Epoch: 6| Step: 12
Training loss: 0.3869207501411438
Validation loss: 1.9182281295458476

Epoch: 6| Step: 13
Training loss: 0.4360465109348297
Validation loss: 1.9669322768847148

Epoch: 194| Step: 0
Training loss: 0.289822518825531
Validation loss: 1.97047758102417

Epoch: 6| Step: 1
Training loss: 0.35708558559417725
Validation loss: 1.9756786624590557

Epoch: 6| Step: 2
Training loss: 0.9192366600036621
Validation loss: 1.938908298810323

Epoch: 6| Step: 3
Training loss: 0.2546302080154419
Validation loss: 1.9673246145248413

Epoch: 6| Step: 4
Training loss: 0.583491325378418
Validation loss: 1.9666118621826172

Epoch: 6| Step: 5
Training loss: 0.5529696941375732
Validation loss: 1.9384093880653381

Epoch: 6| Step: 6
Training loss: 0.3745673894882202
Validation loss: 2.0022564927736917

Epoch: 6| Step: 7
Training loss: 0.5087076425552368
Validation loss: 2.0019798477490744

Epoch: 6| Step: 8
Training loss: 0.7893195152282715
Validation loss: 2.0368801156679788

Epoch: 6| Step: 9
Training loss: 0.23607008159160614
Validation loss: 1.9590513507525127

Epoch: 6| Step: 10
Training loss: 0.2851027250289917
Validation loss: 2.020772556463877

Epoch: 6| Step: 11
Training loss: 0.3008396625518799
Validation loss: 1.9795334736506145

Epoch: 6| Step: 12
Training loss: 0.6683979034423828
Validation loss: 1.984144667784373

Epoch: 6| Step: 13
Training loss: 0.8174365758895874
Validation loss: 1.947475016117096

Epoch: 195| Step: 0
Training loss: 0.38384246826171875
Validation loss: 1.932740032672882

Epoch: 6| Step: 1
Training loss: 0.49388664960861206
Validation loss: 2.0217233498891196

Epoch: 6| Step: 2
Training loss: 0.25944268703460693
Validation loss: 1.9382362365722656

Epoch: 6| Step: 3
Training loss: 0.6911013126373291
Validation loss: 1.9491276144981384

Epoch: 6| Step: 4
Training loss: 0.19899742305278778
Validation loss: 1.9747185707092285

Epoch: 6| Step: 5
Training loss: 0.5210056304931641
Validation loss: 1.9688358902931213

Epoch: 6| Step: 6
Training loss: 0.9296281337738037
Validation loss: 2.008434772491455

Epoch: 6| Step: 7
Training loss: 0.9141428470611572
Validation loss: 1.9820157289505005

Epoch: 6| Step: 8
Training loss: 0.47887372970581055
Validation loss: 1.9523555835088093

Epoch: 6| Step: 9
Training loss: 0.4417341351509094
Validation loss: 1.9635410110155742

Epoch: 6| Step: 10
Training loss: 0.3388449549674988
Validation loss: 1.9166321754455566

Epoch: 6| Step: 11
Training loss: 0.5921737551689148
Validation loss: 1.956479251384735

Epoch: 6| Step: 12
Training loss: 0.2830599546432495
Validation loss: 1.954498867193858

Epoch: 6| Step: 13
Training loss: 0.5825754404067993
Validation loss: 2.027483423550924

Epoch: 196| Step: 0
Training loss: 0.8645436763763428
Validation loss: 1.9677258332570393

Epoch: 6| Step: 1
Training loss: 0.39799410104751587
Validation loss: 1.9860749046007793

Epoch: 6| Step: 2
Training loss: 0.4549221396446228
Validation loss: 1.9718103210131328

Epoch: 6| Step: 3
Training loss: 0.21429243683815002
Validation loss: 1.9237720767656963

Epoch: 6| Step: 4
Training loss: 0.8330546021461487
Validation loss: 1.9730265537897747

Epoch: 6| Step: 5
Training loss: 0.4825582504272461
Validation loss: 1.9556647936503093

Epoch: 6| Step: 6
Training loss: 0.5186434984207153
Validation loss: 1.9691032369931538

Epoch: 6| Step: 7
Training loss: 0.6633551716804504
Validation loss: 1.9400760332743328

Epoch: 6| Step: 8
Training loss: 0.4931873083114624
Validation loss: 1.9502689639727275

Epoch: 6| Step: 9
Training loss: 0.3606123924255371
Validation loss: 1.9551614324251811

Epoch: 6| Step: 10
Training loss: 0.4482501149177551
Validation loss: 1.9848142663637798

Epoch: 6| Step: 11
Training loss: 0.5254138708114624
Validation loss: 1.9877905050913494

Epoch: 6| Step: 12
Training loss: 0.721054196357727
Validation loss: 2.014504392941793

Epoch: 6| Step: 13
Training loss: 0.533851146697998
Validation loss: 1.9901256759961445

Epoch: 197| Step: 0
Training loss: 0.6487677693367004
Validation loss: 2.029609461625417

Epoch: 6| Step: 1
Training loss: 0.4236820340156555
Validation loss: 1.9732850392659504

Epoch: 6| Step: 2
Training loss: 0.7025597095489502
Validation loss: 1.9713107546170552

Epoch: 6| Step: 3
Training loss: 1.0446864366531372
Validation loss: 1.9240004022916157

Epoch: 6| Step: 4
Training loss: 0.42965060472488403
Validation loss: 1.944438914457957

Epoch: 6| Step: 5
Training loss: 0.4235285222530365
Validation loss: 1.9670966863632202

Epoch: 6| Step: 6
Training loss: 0.5747711062431335
Validation loss: 1.970142384370168

Epoch: 6| Step: 7
Training loss: 0.33487042784690857
Validation loss: 1.9076544046401978

Epoch: 6| Step: 8
Training loss: 0.33216822147369385
Validation loss: 1.931865930557251

Epoch: 6| Step: 9
Training loss: 0.5519845485687256
Validation loss: 1.9908039967219036

Epoch: 6| Step: 10
Training loss: 0.6354609727859497
Validation loss: 2.0190807580947876

Epoch: 6| Step: 11
Training loss: 0.5315039157867432
Validation loss: 1.9847108125686646

Epoch: 6| Step: 12
Training loss: 0.7349361181259155
Validation loss: 1.9534127910931904

Epoch: 6| Step: 13
Training loss: 0.44249963760375977
Validation loss: 1.9827263355255127

Epoch: 198| Step: 0
Training loss: 0.4488356113433838
Validation loss: 1.9447739720344543

Epoch: 6| Step: 1
Training loss: 0.287161648273468
Validation loss: 1.9387359619140625

Epoch: 6| Step: 2
Training loss: 0.49670881032943726
Validation loss: 1.9090213576952617

Epoch: 6| Step: 3
Training loss: 0.30043795704841614
Validation loss: 1.9123591184616089

Epoch: 6| Step: 4
Training loss: 0.39158809185028076
Validation loss: 1.9163087606430054

Epoch: 6| Step: 5
Training loss: 0.4015273451805115
Validation loss: 1.940709392229716

Epoch: 6| Step: 6
Training loss: 0.7433980703353882
Validation loss: 1.9496799508730571

Epoch: 6| Step: 7
Training loss: 0.7813458442687988
Validation loss: 1.9820180535316467

Epoch: 6| Step: 8
Training loss: 0.5664209127426147
Validation loss: 1.9285255273183186

Epoch: 6| Step: 9
Training loss: 0.26661914587020874
Validation loss: 1.9806726972262065

Epoch: 6| Step: 10
Training loss: 0.8814746141433716
Validation loss: 1.9915795922279358

Epoch: 6| Step: 11
Training loss: 0.6652028560638428
Validation loss: 1.9595218102137248

Epoch: 6| Step: 12
Training loss: 0.5843139290809631
Validation loss: 1.965630034605662

Epoch: 6| Step: 13
Training loss: 0.5262112617492676
Validation loss: 1.9077497124671936

Epoch: 199| Step: 0
Training loss: 0.7003583908081055
Validation loss: 1.9567813475926716

Epoch: 6| Step: 1
Training loss: 0.6259850263595581
Validation loss: 2.002793848514557

Epoch: 6| Step: 2
Training loss: 0.32016721367836
Validation loss: 1.9087527791659038

Epoch: 6| Step: 3
Training loss: 0.535233199596405
Validation loss: 1.9195804794629414

Epoch: 6| Step: 4
Training loss: 0.5777838230133057
Validation loss: 1.9294442931811016

Epoch: 6| Step: 5
Training loss: 0.39151445031166077
Validation loss: 1.9805882771809895

Epoch: 6| Step: 6
Training loss: 0.6898720264434814
Validation loss: 1.983742892742157

Epoch: 6| Step: 7
Training loss: 0.6035585403442383
Validation loss: 1.9616536696751912

Epoch: 6| Step: 8
Training loss: 0.5843625664710999
Validation loss: 1.9785828391710918

Epoch: 6| Step: 9
Training loss: 0.44506940245628357
Validation loss: 1.9721381266911824

Epoch: 6| Step: 10
Training loss: 0.13717707991600037
Validation loss: 1.9679678082466125

Epoch: 6| Step: 11
Training loss: 0.3980357348918915
Validation loss: 1.9367741743723552

Epoch: 6| Step: 12
Training loss: 0.6492869257926941
Validation loss: 1.9740998148918152

Epoch: 6| Step: 13
Training loss: 0.31506988406181335
Validation loss: 1.9449775417645772

Epoch: 200| Step: 0
Training loss: 0.3267362713813782
Validation loss: 1.953737735748291

Epoch: 6| Step: 1
Training loss: 0.1779557168483734
Validation loss: 1.9794803659121196

Epoch: 6| Step: 2
Training loss: 0.5092951655387878
Validation loss: 2.0024057030677795

Epoch: 6| Step: 3
Training loss: 0.3105894923210144
Validation loss: 1.9769280751546223

Epoch: 6| Step: 4
Training loss: 0.5551576614379883
Validation loss: 2.030078132947286

Epoch: 6| Step: 5
Training loss: 0.5254626274108887
Validation loss: 1.9879079659779866

Epoch: 6| Step: 6
Training loss: 0.63780677318573
Validation loss: 1.988122820854187

Epoch: 6| Step: 7
Training loss: 0.38631540536880493
Validation loss: 1.96119225025177

Epoch: 6| Step: 8
Training loss: 0.46791231632232666
Validation loss: 1.9948866764704387

Epoch: 6| Step: 9
Training loss: 0.40160447359085083
Validation loss: 1.9571632345517476

Epoch: 6| Step: 10
Training loss: 0.7556686401367188
Validation loss: 2.0057648022969565

Epoch: 6| Step: 11
Training loss: 0.47664692997932434
Validation loss: 2.0091670751571655

Epoch: 6| Step: 12
Training loss: 0.48836469650268555
Validation loss: 1.968350887298584

Epoch: 6| Step: 13
Training loss: 0.443636417388916
Validation loss: 1.9701282183329265

Epoch: 201| Step: 0
Training loss: 0.3583998382091522
Validation loss: 1.963366985321045

Epoch: 6| Step: 1
Training loss: 0.3382660150527954
Validation loss: 1.9653724431991577

Epoch: 6| Step: 2
Training loss: 0.5911612510681152
Validation loss: 1.9925087690353394

Epoch: 6| Step: 3
Training loss: 0.47819069027900696
Validation loss: 2.007853329181671

Epoch: 6| Step: 4
Training loss: 0.37944430112838745
Validation loss: 1.955400029818217

Epoch: 6| Step: 5
Training loss: 0.7721763849258423
Validation loss: 1.9944146076838176

Epoch: 6| Step: 6
Training loss: 0.20861032605171204
Validation loss: 1.9454621076583862

Epoch: 6| Step: 7
Training loss: 0.2790411114692688
Validation loss: 1.962534526983897

Epoch: 6| Step: 8
Training loss: 0.5362645983695984
Validation loss: 1.9666029214859009

Epoch: 6| Step: 9
Training loss: 0.6458451747894287
Validation loss: 1.9974408149719238

Epoch: 6| Step: 10
Training loss: 0.45941877365112305
Validation loss: 1.9771700302759807

Epoch: 6| Step: 11
Training loss: 0.44592612981796265
Validation loss: 1.991481860478719

Epoch: 6| Step: 12
Training loss: 0.7508302927017212
Validation loss: 1.9833224614461262

Epoch: 6| Step: 13
Training loss: 0.7607616186141968
Validation loss: 1.996102472146352

Epoch: 202| Step: 0
Training loss: 0.4251311123371124
Validation loss: 2.0207818945248923

Epoch: 6| Step: 1
Training loss: 0.3893953561782837
Validation loss: 2.010928233464559

Epoch: 6| Step: 2
Training loss: 0.2087484747171402
Validation loss: 1.9695777694384258

Epoch: 6| Step: 3
Training loss: 0.5648479461669922
Validation loss: 2.0080811182657876

Epoch: 6| Step: 4
Training loss: 0.70668625831604
Validation loss: 1.9946784774462383

Epoch: 6| Step: 5
Training loss: 0.7704426646232605
Validation loss: 1.9827414552370708

Epoch: 6| Step: 6
Training loss: 0.4271239936351776
Validation loss: 2.01889435450236

Epoch: 6| Step: 7
Training loss: 0.4656476378440857
Validation loss: 1.950216035048167

Epoch: 6| Step: 8
Training loss: 0.5872007608413696
Validation loss: 1.96577121814092

Epoch: 6| Step: 9
Training loss: 0.4104335606098175
Validation loss: 1.960038959980011

Epoch: 6| Step: 10
Training loss: 0.34588855504989624
Validation loss: 2.0148171385129294

Epoch: 6| Step: 11
Training loss: 0.5578732490539551
Validation loss: 1.9812981685002644

Epoch: 6| Step: 12
Training loss: 0.3069608807563782
Validation loss: 1.983317454655965

Epoch: 6| Step: 13
Training loss: 0.26244547963142395
Validation loss: 1.9584866960843403

Epoch: 203| Step: 0
Training loss: 0.3885682225227356
Validation loss: 1.9914761781692505

Epoch: 6| Step: 1
Training loss: 0.31392669677734375
Validation loss: 1.9821621378262837

Epoch: 6| Step: 2
Training loss: 0.2904391288757324
Validation loss: 1.9771886070569356

Epoch: 6| Step: 3
Training loss: 0.8198422193527222
Validation loss: 1.9777738451957703

Epoch: 6| Step: 4
Training loss: 0.22201770544052124
Validation loss: 1.9726507663726807

Epoch: 6| Step: 5
Training loss: 0.41959133744239807
Validation loss: 1.9764720797538757

Epoch: 6| Step: 6
Training loss: 0.2703445255756378
Validation loss: 1.9611295461654663

Epoch: 6| Step: 7
Training loss: 0.3612087368965149
Validation loss: 1.9397016167640686

Epoch: 6| Step: 8
Training loss: 0.633595883846283
Validation loss: 1.9584822257359822

Epoch: 6| Step: 9
Training loss: 0.7034545540809631
Validation loss: 1.965813656648

Epoch: 6| Step: 10
Training loss: 0.5819301605224609
Validation loss: 1.9513816237449646

Epoch: 6| Step: 11
Training loss: 0.6016317009925842
Validation loss: 1.9359137415885925

Epoch: 6| Step: 12
Training loss: 0.6480051279067993
Validation loss: 1.946645478407542

Epoch: 6| Step: 13
Training loss: 0.23865680396556854
Validation loss: 1.9779975612958272

Epoch: 204| Step: 0
Training loss: 0.4074721932411194
Validation loss: 1.9156009356180828

Epoch: 6| Step: 1
Training loss: 0.46859991550445557
Validation loss: 1.9783596793810527

Epoch: 6| Step: 2
Training loss: 0.34826210141181946
Validation loss: 1.9959071278572083

Epoch: 6| Step: 3
Training loss: 0.49212583899497986
Validation loss: 1.9748948216438293

Epoch: 6| Step: 4
Training loss: 0.28938353061676025
Validation loss: 2.0008912086486816

Epoch: 6| Step: 5
Training loss: 0.4562980532646179
Validation loss: 1.976144830385844

Epoch: 6| Step: 6
Training loss: 0.5566897392272949
Validation loss: 1.966532309850057

Epoch: 6| Step: 7
Training loss: 0.5578911304473877
Validation loss: 2.016699035962423

Epoch: 6| Step: 8
Training loss: 0.35301950573921204
Validation loss: 1.9852879643440247

Epoch: 6| Step: 9
Training loss: 0.7618433833122253
Validation loss: 1.9768900672594707

Epoch: 6| Step: 10
Training loss: 0.4083593487739563
Validation loss: 1.9755494395891826

Epoch: 6| Step: 11
Training loss: 0.6673145294189453
Validation loss: 2.0230302015940347

Epoch: 6| Step: 12
Training loss: 0.6781792640686035
Validation loss: 1.941430687904358

Epoch: 6| Step: 13
Training loss: 0.3085489869117737
Validation loss: 1.9960259795188904

Epoch: 205| Step: 0
Training loss: 0.40537792444229126
Validation loss: 2.033415377140045

Epoch: 6| Step: 1
Training loss: 0.6732421517372131
Validation loss: 2.018474022547404

Epoch: 6| Step: 2
Training loss: 0.44925588369369507
Validation loss: 2.004810174306234

Epoch: 6| Step: 3
Training loss: 0.8407405614852905
Validation loss: 1.9838001330693562

Epoch: 6| Step: 4
Training loss: 0.42093443870544434
Validation loss: 1.964856465657552

Epoch: 6| Step: 5
Training loss: 0.42198729515075684
Validation loss: 1.9639901121457417

Epoch: 6| Step: 6
Training loss: 0.22163936495780945
Validation loss: 1.996843934059143

Epoch: 6| Step: 7
Training loss: 0.5059614777565002
Validation loss: 2.0121175050735474

Epoch: 6| Step: 8
Training loss: 0.23564159870147705
Validation loss: 1.9916317065556843

Epoch: 6| Step: 9
Training loss: 0.42548325657844543
Validation loss: 1.993762771288554

Epoch: 6| Step: 10
Training loss: 0.3994988799095154
Validation loss: 2.0065176685651145

Epoch: 6| Step: 11
Training loss: 0.22455191612243652
Validation loss: 1.9992294708887737

Epoch: 6| Step: 12
Training loss: 0.6416671276092529
Validation loss: 1.9577021598815918

Epoch: 6| Step: 13
Training loss: 0.5362759828567505
Validation loss: 1.991453230381012

Epoch: 206| Step: 0
Training loss: 0.7700684666633606
Validation loss: 1.9879956642786663

Epoch: 6| Step: 1
Training loss: 0.5621925592422485
Validation loss: 1.9796665906906128

Epoch: 6| Step: 2
Training loss: 0.321612685918808
Validation loss: 1.9632757306098938

Epoch: 6| Step: 3
Training loss: 0.7507131099700928
Validation loss: 1.972401221593221

Epoch: 6| Step: 4
Training loss: 0.4722602367401123
Validation loss: 1.9580583572387695

Epoch: 6| Step: 5
Training loss: 0.5438219904899597
Validation loss: 1.9594149986902873

Epoch: 6| Step: 6
Training loss: 0.32694879174232483
Validation loss: 2.0101019541422525

Epoch: 6| Step: 7
Training loss: 0.5983390808105469
Validation loss: 1.9893648028373718

Epoch: 6| Step: 8
Training loss: 0.5119681358337402
Validation loss: 1.949890951315562

Epoch: 6| Step: 9
Training loss: 0.528752326965332
Validation loss: 1.979299525419871

Epoch: 6| Step: 10
Training loss: 0.267233669757843
Validation loss: 1.966371516386668

Epoch: 6| Step: 11
Training loss: 0.38256099820137024
Validation loss: 1.9332166910171509

Epoch: 6| Step: 12
Training loss: 0.37357044219970703
Validation loss: 1.9649389584859211

Epoch: 6| Step: 13
Training loss: 0.3082072138786316
Validation loss: 2.008378803730011

Epoch: 207| Step: 0
Training loss: 0.31421345472335815
Validation loss: 1.9933589696884155

Epoch: 6| Step: 1
Training loss: 0.4412163496017456
Validation loss: 2.0140417416890464

Epoch: 6| Step: 2
Training loss: 0.7952615022659302
Validation loss: 1.9384860793749492

Epoch: 6| Step: 3
Training loss: 0.29469460248947144
Validation loss: 1.9820103446642559

Epoch: 6| Step: 4
Training loss: 0.30937737226486206
Validation loss: 2.0227643052736917

Epoch: 6| Step: 5
Training loss: 0.49984684586524963
Validation loss: 1.9932672381401062

Epoch: 6| Step: 6
Training loss: 0.46765315532684326
Validation loss: 1.9485164086023967

Epoch: 6| Step: 7
Training loss: 0.5600683689117432
Validation loss: 1.9809621969858806

Epoch: 6| Step: 8
Training loss: 0.6061744093894958
Validation loss: 1.969113051891327

Epoch: 6| Step: 9
Training loss: 0.27311864495277405
Validation loss: 1.9750977158546448

Epoch: 6| Step: 10
Training loss: 0.4371319115161896
Validation loss: 1.97435196240743

Epoch: 6| Step: 11
Training loss: 0.8810323476791382
Validation loss: 1.99540376663208

Epoch: 6| Step: 12
Training loss: 0.4098875820636749
Validation loss: 1.9669378399848938

Epoch: 6| Step: 13
Training loss: 0.2955847978591919
Validation loss: 1.9680579900741577

Epoch: 208| Step: 0
Training loss: 0.570172131061554
Validation loss: 1.991233229637146

Epoch: 6| Step: 1
Training loss: 0.3141847252845764
Validation loss: 1.957030177116394

Epoch: 6| Step: 2
Training loss: 0.8174996376037598
Validation loss: 1.9693431456883748

Epoch: 6| Step: 3
Training loss: 0.28994154930114746
Validation loss: 1.9787666002909343

Epoch: 6| Step: 4
Training loss: 0.3289494514465332
Validation loss: 1.9799916942914326

Epoch: 6| Step: 5
Training loss: 0.38158100843429565
Validation loss: 1.9588939746220906

Epoch: 6| Step: 6
Training loss: 0.36895471811294556
Validation loss: 1.9426165421803792

Epoch: 6| Step: 7
Training loss: 0.5424709320068359
Validation loss: 2.0140929023424783

Epoch: 6| Step: 8
Training loss: 0.6852657794952393
Validation loss: 2.0304178396860757

Epoch: 6| Step: 9
Training loss: 0.1720917671918869
Validation loss: 1.9651819070180256

Epoch: 6| Step: 10
Training loss: 0.3624039590358734
Validation loss: 1.99496062596639

Epoch: 6| Step: 11
Training loss: 0.4856280982494354
Validation loss: 2.0120608806610107

Epoch: 6| Step: 12
Training loss: 0.7430457472801208
Validation loss: 1.9858426849047344

Epoch: 6| Step: 13
Training loss: 0.26158085465431213
Validation loss: 1.923069675763448

Epoch: 209| Step: 0
Training loss: 0.48403918743133545
Validation loss: 1.9872562885284424

Epoch: 6| Step: 1
Training loss: 0.18274427950382233
Validation loss: 1.9839352369308472

Epoch: 6| Step: 2
Training loss: 0.39084741473197937
Validation loss: 1.9287585417429607

Epoch: 6| Step: 3
Training loss: 0.2663898169994354
Validation loss: 1.9452175498008728

Epoch: 6| Step: 4
Training loss: 0.6013115644454956
Validation loss: 1.957426905632019

Epoch: 6| Step: 5
Training loss: 0.48679548501968384
Validation loss: 1.9615634481112163

Epoch: 6| Step: 6
Training loss: 0.6743065118789673
Validation loss: 1.9746214151382446

Epoch: 6| Step: 7
Training loss: 0.4224066138267517
Validation loss: 2.000125527381897

Epoch: 6| Step: 8
Training loss: 0.5845694541931152
Validation loss: 1.9787205457687378

Epoch: 6| Step: 9
Training loss: 0.4657851457595825
Validation loss: 2.0042821764945984

Epoch: 6| Step: 10
Training loss: 0.6262792348861694
Validation loss: 1.9487131635348003

Epoch: 6| Step: 11
Training loss: 0.21815083920955658
Validation loss: 1.9542047778765361

Epoch: 6| Step: 12
Training loss: 0.44326117634773254
Validation loss: 2.005616625150045

Epoch: 6| Step: 13
Training loss: 0.37023913860321045
Validation loss: 1.9355222781499226

Epoch: 210| Step: 0
Training loss: 0.5043839812278748
Validation loss: 1.9402564764022827

Epoch: 6| Step: 1
Training loss: 0.5703644156455994
Validation loss: 2.0010618766148887

Epoch: 6| Step: 2
Training loss: 0.23331771790981293
Validation loss: 1.961613913377126

Epoch: 6| Step: 3
Training loss: 0.8715853691101074
Validation loss: 1.949188510576884

Epoch: 6| Step: 4
Training loss: 0.3803238868713379
Validation loss: 1.9628780086835225

Epoch: 6| Step: 5
Training loss: 0.5179754495620728
Validation loss: 1.979552149772644

Epoch: 6| Step: 6
Training loss: 0.7539744973182678
Validation loss: 1.9966491063435872

Epoch: 6| Step: 7
Training loss: 0.5037102699279785
Validation loss: 1.9965364535649617

Epoch: 6| Step: 8
Training loss: 0.2360163927078247
Validation loss: 2.0184720555941262

Epoch: 6| Step: 9
Training loss: 0.2810126543045044
Validation loss: 2.017968793710073

Epoch: 6| Step: 10
Training loss: 0.5281295776367188
Validation loss: 1.990630606810252

Epoch: 6| Step: 11
Training loss: 0.33760660886764526
Validation loss: 2.013529578844706

Epoch: 6| Step: 12
Training loss: 0.31195172667503357
Validation loss: 1.9794140259424846

Epoch: 6| Step: 13
Training loss: 0.6410033106803894
Validation loss: 1.9880388379096985

Epoch: 211| Step: 0
Training loss: 0.39281052350997925
Validation loss: 1.9506978193918865

Epoch: 6| Step: 1
Training loss: 0.18978483974933624
Validation loss: 1.9922219514846802

Epoch: 6| Step: 2
Training loss: 0.32272273302078247
Validation loss: 2.0048863093058267

Epoch: 6| Step: 3
Training loss: 0.25281715393066406
Validation loss: 1.958682159582774

Epoch: 6| Step: 4
Training loss: 0.32309192419052124
Validation loss: 1.9614701469739277

Epoch: 6| Step: 5
Training loss: 0.5891976952552795
Validation loss: 1.9600686232248943

Epoch: 6| Step: 6
Training loss: 0.5288691520690918
Validation loss: 1.9779396255811055

Epoch: 6| Step: 7
Training loss: 0.4886780381202698
Validation loss: 1.9982693791389465

Epoch: 6| Step: 8
Training loss: 0.5701198577880859
Validation loss: 1.8979636430740356

Epoch: 6| Step: 9
Training loss: 0.3240181803703308
Validation loss: 1.9532549778620403

Epoch: 6| Step: 10
Training loss: 0.2986465096473694
Validation loss: 2.05526065826416

Epoch: 6| Step: 11
Training loss: 0.806566059589386
Validation loss: 1.9598858952522278

Epoch: 6| Step: 12
Training loss: 0.31449204683303833
Validation loss: 1.9628072778383892

Epoch: 6| Step: 13
Training loss: 0.604987621307373
Validation loss: 2.003464142481486

Epoch: 212| Step: 0
Training loss: 0.4020649790763855
Validation loss: 1.9591117699940999

Epoch: 6| Step: 1
Training loss: 0.5580614805221558
Validation loss: 1.939859131971995

Epoch: 6| Step: 2
Training loss: 0.3679814338684082
Validation loss: 1.9611812432607014

Epoch: 6| Step: 3
Training loss: 0.34587612748146057
Validation loss: 1.976615885893504

Epoch: 6| Step: 4
Training loss: 0.5143481492996216
Validation loss: 1.9795073866844177

Epoch: 6| Step: 5
Training loss: 0.19466395676136017
Validation loss: 1.967997133731842

Epoch: 6| Step: 6
Training loss: 0.518324613571167
Validation loss: 1.9952995777130127

Epoch: 6| Step: 7
Training loss: 0.39959126710891724
Validation loss: 2.006850322087606

Epoch: 6| Step: 8
Training loss: 0.3262377977371216
Validation loss: 1.9920037587483723

Epoch: 6| Step: 9
Training loss: 1.0103205442428589
Validation loss: 1.949018696943919

Epoch: 6| Step: 10
Training loss: 0.3008773922920227
Validation loss: 1.9903751015663147

Epoch: 6| Step: 11
Training loss: 0.2764987647533417
Validation loss: 1.9685099323590596

Epoch: 6| Step: 12
Training loss: 0.3820422887802124
Validation loss: 2.000581681728363

Epoch: 6| Step: 13
Training loss: 0.640964150428772
Validation loss: 1.992022415002187

Epoch: 213| Step: 0
Training loss: 0.28540539741516113
Validation loss: 2.00663169225057

Epoch: 6| Step: 1
Training loss: 0.6319795846939087
Validation loss: 1.9744252761205037

Epoch: 6| Step: 2
Training loss: 0.5734535455703735
Validation loss: 2.0014674266179404

Epoch: 6| Step: 3
Training loss: 0.3639317750930786
Validation loss: 1.9923345843950908

Epoch: 6| Step: 4
Training loss: 0.20491614937782288
Validation loss: 2.002803862094879

Epoch: 6| Step: 5
Training loss: 0.41181015968322754
Validation loss: 1.936024824778239

Epoch: 6| Step: 6
Training loss: 0.27071279287338257
Validation loss: 1.9996410409609477

Epoch: 6| Step: 7
Training loss: 0.6139332056045532
Validation loss: 1.9601915280024211

Epoch: 6| Step: 8
Training loss: 0.8473426103591919
Validation loss: 1.9839990139007568

Epoch: 6| Step: 9
Training loss: 0.6594143509864807
Validation loss: 1.9671368598937988

Epoch: 6| Step: 10
Training loss: 0.42079246044158936
Validation loss: 1.9410126209259033

Epoch: 6| Step: 11
Training loss: 0.3743225336074829
Validation loss: 1.900459090868632

Epoch: 6| Step: 12
Training loss: 0.2742384374141693
Validation loss: 1.9510364135106404

Epoch: 6| Step: 13
Training loss: 0.45385754108428955
Validation loss: 1.9552597403526306

Epoch: 214| Step: 0
Training loss: 0.4144824147224426
Validation loss: 1.9670894344647725

Epoch: 6| Step: 1
Training loss: 0.36150503158569336
Validation loss: 1.9722660382588704

Epoch: 6| Step: 2
Training loss: 0.559812068939209
Validation loss: 1.9512252807617188

Epoch: 6| Step: 3
Training loss: 0.5068498253822327
Validation loss: 1.9385693470637004

Epoch: 6| Step: 4
Training loss: 0.2519875764846802
Validation loss: 1.9812056024869282

Epoch: 6| Step: 5
Training loss: 0.26068565249443054
Validation loss: 2.0101430217425027

Epoch: 6| Step: 6
Training loss: 1.100598931312561
Validation loss: 1.9615050951639812

Epoch: 6| Step: 7
Training loss: 0.3374355435371399
Validation loss: 1.999584138393402

Epoch: 6| Step: 8
Training loss: 0.24184834957122803
Validation loss: 1.9726418852806091

Epoch: 6| Step: 9
Training loss: 0.39446520805358887
Validation loss: 1.9413569966952007

Epoch: 6| Step: 10
Training loss: 0.5020474195480347
Validation loss: 1.9514384667078655

Epoch: 6| Step: 11
Training loss: 0.48640382289886475
Validation loss: 1.9965461095174153

Epoch: 6| Step: 12
Training loss: 0.36611607670783997
Validation loss: 2.028057634830475

Epoch: 6| Step: 13
Training loss: 0.18415354192256927
Validation loss: 1.9486844539642334

Epoch: 215| Step: 0
Training loss: 0.3024540841579437
Validation loss: 1.9343643188476562

Epoch: 6| Step: 1
Training loss: 0.6654335260391235
Validation loss: 1.9753710428873699

Epoch: 6| Step: 2
Training loss: 0.37367427349090576
Validation loss: 1.9234822789827983

Epoch: 6| Step: 3
Training loss: 0.2583310008049011
Validation loss: 1.996623436609904

Epoch: 6| Step: 4
Training loss: 0.4616038203239441
Validation loss: 1.9449714024861653

Epoch: 6| Step: 5
Training loss: 0.3698239028453827
Validation loss: 1.979342023531596

Epoch: 6| Step: 6
Training loss: 0.6423971652984619
Validation loss: 1.9967918992042542

Epoch: 6| Step: 7
Training loss: 0.2616286277770996
Validation loss: 1.9292977253595989

Epoch: 6| Step: 8
Training loss: 0.4564599394798279
Validation loss: 1.9349910616874695

Epoch: 6| Step: 9
Training loss: 0.2685391306877136
Validation loss: 1.9716010093688965

Epoch: 6| Step: 10
Training loss: 0.4097462296485901
Validation loss: 1.9549774527549744

Epoch: 6| Step: 11
Training loss: 0.7079839706420898
Validation loss: 2.020482122898102

Epoch: 6| Step: 12
Training loss: 0.507960319519043
Validation loss: 1.9617232084274292

Epoch: 6| Step: 13
Training loss: 0.45356592535972595
Validation loss: 1.943074385325114

Epoch: 216| Step: 0
Training loss: 0.5871442556381226
Validation loss: 1.9458297888437908

Epoch: 6| Step: 1
Training loss: 0.3396613299846649
Validation loss: 1.95545361439387

Epoch: 6| Step: 2
Training loss: 0.5518255233764648
Validation loss: 1.9691058993339539

Epoch: 6| Step: 3
Training loss: 0.514991283416748
Validation loss: 1.947856108347575

Epoch: 6| Step: 4
Training loss: 0.37264877557754517
Validation loss: 1.9464990893999736

Epoch: 6| Step: 5
Training loss: 0.5135531425476074
Validation loss: 1.9519810279210408

Epoch: 6| Step: 6
Training loss: 0.37554076313972473
Validation loss: 1.9399671355883281

Epoch: 6| Step: 7
Training loss: 0.9921743869781494
Validation loss: 1.9499741593996684

Epoch: 6| Step: 8
Training loss: 0.4042946696281433
Validation loss: 1.9252895712852478

Epoch: 6| Step: 9
Training loss: 0.30078625679016113
Validation loss: 1.9471243222554524

Epoch: 6| Step: 10
Training loss: 0.24068200588226318
Validation loss: 1.9556373953819275

Epoch: 6| Step: 11
Training loss: 0.3350765109062195
Validation loss: 1.946633795897166

Epoch: 6| Step: 12
Training loss: 0.26525652408599854
Validation loss: 1.9606918692588806

Epoch: 6| Step: 13
Training loss: 0.7889812588691711
Validation loss: 1.9490175048510234

Epoch: 217| Step: 0
Training loss: 0.39760875701904297
Validation loss: 1.9891863266626995

Epoch: 6| Step: 1
Training loss: 0.2041734904050827
Validation loss: 1.9799607793490093

Epoch: 6| Step: 2
Training loss: 0.2369837909936905
Validation loss: 1.947393576304118

Epoch: 6| Step: 3
Training loss: 0.5596919059753418
Validation loss: 1.9897647500038147

Epoch: 6| Step: 4
Training loss: 0.21869707107543945
Validation loss: 1.980451265970866

Epoch: 6| Step: 5
Training loss: 0.3545624613761902
Validation loss: 1.9766895174980164

Epoch: 6| Step: 6
Training loss: 0.24127979576587677
Validation loss: 1.9514874617258708

Epoch: 6| Step: 7
Training loss: 0.5621724128723145
Validation loss: 1.9920551578203838

Epoch: 6| Step: 8
Training loss: 0.8030729293823242
Validation loss: 1.954760193824768

Epoch: 6| Step: 9
Training loss: 0.5433433055877686
Validation loss: 1.9746482968330383

Epoch: 6| Step: 10
Training loss: 0.47003814578056335
Validation loss: 1.9922597606976826

Epoch: 6| Step: 11
Training loss: 0.6753866672515869
Validation loss: 1.9479011098543804

Epoch: 6| Step: 12
Training loss: 0.5216859579086304
Validation loss: 1.9348525007565816

Epoch: 6| Step: 13
Training loss: 0.2558457851409912
Validation loss: 1.9634713331858318

Epoch: 218| Step: 0
Training loss: 0.4016892910003662
Validation loss: 1.9812510808308919

Epoch: 6| Step: 1
Training loss: 0.26516661047935486
Validation loss: 1.9482055306434631

Epoch: 6| Step: 2
Training loss: 0.2580513656139374
Validation loss: 1.9963739116986592

Epoch: 6| Step: 3
Training loss: 0.19769544899463654
Validation loss: 2.0074513951937356

Epoch: 6| Step: 4
Training loss: 0.7598419189453125
Validation loss: 1.9747668306032817

Epoch: 6| Step: 5
Training loss: 0.5633337497711182
Validation loss: 1.9653265476226807

Epoch: 6| Step: 6
Training loss: 0.37494537234306335
Validation loss: 1.9170632759730022

Epoch: 6| Step: 7
Training loss: 0.20904380083084106
Validation loss: 2.0293368101119995

Epoch: 6| Step: 8
Training loss: 0.30417948961257935
Validation loss: 1.9747191866238911

Epoch: 6| Step: 9
Training loss: 0.9636294841766357
Validation loss: 1.9611738721529643

Epoch: 6| Step: 10
Training loss: 0.43059396743774414
Validation loss: 1.9168463746706645

Epoch: 6| Step: 11
Training loss: 0.4395636022090912
Validation loss: 1.9932554761568706

Epoch: 6| Step: 12
Training loss: 0.4580329656600952
Validation loss: 1.9861149787902832

Epoch: 6| Step: 13
Training loss: 0.5071815252304077
Validation loss: 1.998449683189392

Epoch: 219| Step: 0
Training loss: 0.6964963674545288
Validation loss: 1.9292345643043518

Epoch: 6| Step: 1
Training loss: 0.41676247119903564
Validation loss: 1.9833426475524902

Epoch: 6| Step: 2
Training loss: 0.3009401261806488
Validation loss: 1.9641937812169392

Epoch: 6| Step: 3
Training loss: 0.30056509375572205
Validation loss: 1.9740657806396484

Epoch: 6| Step: 4
Training loss: 0.5426372289657593
Validation loss: 1.9776244163513184

Epoch: 6| Step: 5
Training loss: 0.9899956583976746
Validation loss: 1.960765500863393

Epoch: 6| Step: 6
Training loss: 0.43723064661026
Validation loss: 2.0007266998291016

Epoch: 6| Step: 7
Training loss: 0.4130633771419525
Validation loss: 2.041927615801493

Epoch: 6| Step: 8
Training loss: 0.4706522524356842
Validation loss: 1.9619125326474507

Epoch: 6| Step: 9
Training loss: 0.31098228693008423
Validation loss: 1.965729554494222

Epoch: 6| Step: 10
Training loss: 0.2873874306678772
Validation loss: 1.9428128004074097

Epoch: 6| Step: 11
Training loss: 0.40353161096572876
Validation loss: 1.9287012020746868

Epoch: 6| Step: 12
Training loss: 0.5691195130348206
Validation loss: 1.9966627359390259

Epoch: 6| Step: 13
Training loss: 0.5656970739364624
Validation loss: 1.937739113966624

Epoch: 220| Step: 0
Training loss: 0.4658626914024353
Validation loss: 1.9745899438858032

Epoch: 6| Step: 1
Training loss: 0.3599773645401001
Validation loss: 1.979736049969991

Epoch: 6| Step: 2
Training loss: 0.47651219367980957
Validation loss: 1.9551793138186138

Epoch: 6| Step: 3
Training loss: 0.3294779658317566
Validation loss: 1.9700597325960796

Epoch: 6| Step: 4
Training loss: 0.42882096767425537
Validation loss: 2.0071365435918174

Epoch: 6| Step: 5
Training loss: 0.5034102201461792
Validation loss: 2.0060632030169168

Epoch: 6| Step: 6
Training loss: 0.46263986825942993
Validation loss: 1.9998267690340679

Epoch: 6| Step: 7
Training loss: 0.5621457099914551
Validation loss: 1.962507466475169

Epoch: 6| Step: 8
Training loss: 0.2702825665473938
Validation loss: 1.990525205930074

Epoch: 6| Step: 9
Training loss: 0.4447330832481384
Validation loss: 1.9711825052897136

Epoch: 6| Step: 10
Training loss: 0.3714136481285095
Validation loss: 1.996502935886383

Epoch: 6| Step: 11
Training loss: 0.5458781719207764
Validation loss: 1.9842658042907715

Epoch: 6| Step: 12
Training loss: 0.30904948711395264
Validation loss: 1.984719415505727

Epoch: 6| Step: 13
Training loss: 0.25901028513908386
Validation loss: 1.9794493118921916

Epoch: 221| Step: 0
Training loss: 0.43872547149658203
Validation loss: 1.9668815732002258

Epoch: 6| Step: 1
Training loss: 0.25430092215538025
Validation loss: 1.97145676612854

Epoch: 6| Step: 2
Training loss: 0.19911445677280426
Validation loss: 1.9505608876546223

Epoch: 6| Step: 3
Training loss: 0.5368829369544983
Validation loss: 2.0272098183631897

Epoch: 6| Step: 4
Training loss: 0.3095361590385437
Validation loss: 1.9477580587069194

Epoch: 6| Step: 5
Training loss: 0.2728780210018158
Validation loss: 2.004457732041677

Epoch: 6| Step: 6
Training loss: 0.6590501070022583
Validation loss: 1.990090012550354

Epoch: 6| Step: 7
Training loss: 0.2147832214832306
Validation loss: 1.9822936455408733

Epoch: 6| Step: 8
Training loss: 0.4719359278678894
Validation loss: 1.9376938541730244

Epoch: 6| Step: 9
Training loss: 0.4774183928966522
Validation loss: 1.97064475218455

Epoch: 6| Step: 10
Training loss: 0.4983396530151367
Validation loss: 1.9646204710006714

Epoch: 6| Step: 11
Training loss: 0.6030465364456177
Validation loss: 1.986631989479065

Epoch: 6| Step: 12
Training loss: 0.45986348390579224
Validation loss: 1.9912263751029968

Epoch: 6| Step: 13
Training loss: 0.40987569093704224
Validation loss: 1.9515809416770935

Epoch: 222| Step: 0
Training loss: 0.25217851996421814
Validation loss: 1.9835575819015503

Epoch: 6| Step: 1
Training loss: 0.23436769843101501
Validation loss: 1.9696988463401794

Epoch: 6| Step: 2
Training loss: 0.5856768488883972
Validation loss: 2.0146660606066384

Epoch: 6| Step: 3
Training loss: 0.4663284420967102
Validation loss: 2.0088505943616233

Epoch: 6| Step: 4
Training loss: 0.3266337513923645
Validation loss: 1.9375106493632

Epoch: 6| Step: 5
Training loss: 0.3711792230606079
Validation loss: 2.005405823389689

Epoch: 6| Step: 6
Training loss: 0.34336644411087036
Validation loss: 1.9822361866633098

Epoch: 6| Step: 7
Training loss: 0.34712398052215576
Validation loss: 1.9954613049825032

Epoch: 6| Step: 8
Training loss: 0.4408470392227173
Validation loss: 1.9823726812998455

Epoch: 6| Step: 9
Training loss: 0.5463478565216064
Validation loss: 2.0288782715797424

Epoch: 6| Step: 10
Training loss: 0.616685152053833
Validation loss: 1.9771340886751811

Epoch: 6| Step: 11
Training loss: 0.879694938659668
Validation loss: 2.015781660874685

Epoch: 6| Step: 12
Training loss: 0.3290955424308777
Validation loss: 1.9563207825024922

Epoch: 6| Step: 13
Training loss: 0.521266520023346
Validation loss: 1.963416616121928

Epoch: 223| Step: 0
Training loss: 0.4886762201786041
Validation loss: 2.005060295263926

Epoch: 6| Step: 1
Training loss: 0.2062888741493225
Validation loss: 1.9843263824780781

Epoch: 6| Step: 2
Training loss: 0.22642111778259277
Validation loss: 1.9819008310635884

Epoch: 6| Step: 3
Training loss: 0.7934820055961609
Validation loss: 2.00047500928243

Epoch: 6| Step: 4
Training loss: 0.3665260672569275
Validation loss: 1.990695019563039

Epoch: 6| Step: 5
Training loss: 0.5372631549835205
Validation loss: 1.9690947930018108

Epoch: 6| Step: 6
Training loss: 0.46329665184020996
Validation loss: 1.9710972706476848

Epoch: 6| Step: 7
Training loss: 0.5328075289726257
Validation loss: 1.9739567240079243

Epoch: 6| Step: 8
Training loss: 0.5060922503471375
Validation loss: 1.969111482302348

Epoch: 6| Step: 9
Training loss: 0.3948977589607239
Validation loss: 2.012725035349528

Epoch: 6| Step: 10
Training loss: 0.4551798701286316
Validation loss: 1.9609130422274272

Epoch: 6| Step: 11
Training loss: 0.358873188495636
Validation loss: 2.022085169951121

Epoch: 6| Step: 12
Training loss: 0.2649320960044861
Validation loss: 1.9794689019521077

Epoch: 6| Step: 13
Training loss: 0.4313552975654602
Validation loss: 2.020433525244395

Epoch: 224| Step: 0
Training loss: 0.25326645374298096
Validation loss: 1.9494014382362366

Epoch: 6| Step: 1
Training loss: 0.6521053314208984
Validation loss: 1.9863041838010151

Epoch: 6| Step: 2
Training loss: 0.48219555616378784
Validation loss: 1.959345281124115

Epoch: 6| Step: 3
Training loss: 0.5495837330818176
Validation loss: 1.988340934117635

Epoch: 6| Step: 4
Training loss: 0.22878175973892212
Validation loss: 1.9957812229792278

Epoch: 6| Step: 5
Training loss: 0.5330739617347717
Validation loss: 1.9909770290056865

Epoch: 6| Step: 6
Training loss: 0.3460521101951599
Validation loss: 1.963759958744049

Epoch: 6| Step: 7
Training loss: 0.6387406587600708
Validation loss: 1.9948848684628804

Epoch: 6| Step: 8
Training loss: 0.2412472665309906
Validation loss: 1.9628443519274394

Epoch: 6| Step: 9
Training loss: 0.4471411108970642
Validation loss: 1.9578416347503662

Epoch: 6| Step: 10
Training loss: 0.29152682423591614
Validation loss: 1.9819990595181782

Epoch: 6| Step: 11
Training loss: 0.460638165473938
Validation loss: 1.989428162574768

Epoch: 6| Step: 12
Training loss: 0.6337858438491821
Validation loss: 1.946437915166219

Epoch: 6| Step: 13
Training loss: 0.38465529680252075
Validation loss: 1.9919933478037517

Epoch: 225| Step: 0
Training loss: 0.3088458478450775
Validation loss: 1.910439670085907

Epoch: 6| Step: 1
Training loss: 0.3549259305000305
Validation loss: 1.9955535332361858

Epoch: 6| Step: 2
Training loss: 0.30431753396987915
Validation loss: 1.990537981192271

Epoch: 6| Step: 3
Training loss: 0.395353227853775
Validation loss: 2.030901829401652

Epoch: 6| Step: 4
Training loss: 0.6626675128936768
Validation loss: 1.9739742477734883

Epoch: 6| Step: 5
Training loss: 0.26087576150894165
Validation loss: 1.9454281727472942

Epoch: 6| Step: 6
Training loss: 0.5407184362411499
Validation loss: 1.9745477835337322

Epoch: 6| Step: 7
Training loss: 0.1711842119693756
Validation loss: 1.9632584849993389

Epoch: 6| Step: 8
Training loss: 0.3544141352176666
Validation loss: 1.9833197991053264

Epoch: 6| Step: 9
Training loss: 0.6418253183364868
Validation loss: 1.9593495925267537

Epoch: 6| Step: 10
Training loss: 0.5756536722183228
Validation loss: 1.9463338653246562

Epoch: 6| Step: 11
Training loss: 0.5779568552970886
Validation loss: 1.9496099352836609

Epoch: 6| Step: 12
Training loss: 0.31389349699020386
Validation loss: 1.905939241250356

Epoch: 6| Step: 13
Training loss: 0.5035851001739502
Validation loss: 1.9772765239079793

Epoch: 226| Step: 0
Training loss: 0.24474751949310303
Validation loss: 1.9990199605623882

Epoch: 6| Step: 1
Training loss: 0.7737741470336914
Validation loss: 1.986336092154185

Epoch: 6| Step: 2
Training loss: 0.35275998711586
Validation loss: 2.0088866154352822

Epoch: 6| Step: 3
Training loss: 0.3070796728134155
Validation loss: 2.0001942912737527

Epoch: 6| Step: 4
Training loss: 0.46826016902923584
Validation loss: 1.9748613635698955

Epoch: 6| Step: 5
Training loss: 0.39091795682907104
Validation loss: 1.9131423632303874

Epoch: 6| Step: 6
Training loss: 0.24287378787994385
Validation loss: 1.9926597078641255

Epoch: 6| Step: 7
Training loss: 0.4606173038482666
Validation loss: 1.93207981189092

Epoch: 6| Step: 8
Training loss: 0.545928418636322
Validation loss: 1.945105214913686

Epoch: 6| Step: 9
Training loss: 0.3037357032299042
Validation loss: 1.9796323974927266

Epoch: 6| Step: 10
Training loss: 0.30622029304504395
Validation loss: 1.998181899388631

Epoch: 6| Step: 11
Training loss: 0.3708966374397278
Validation loss: 1.9671060840288799

Epoch: 6| Step: 12
Training loss: 0.6964302659034729
Validation loss: 1.9445277253786724

Epoch: 6| Step: 13
Training loss: 0.5624717473983765
Validation loss: 1.942011574904124

Epoch: 227| Step: 0
Training loss: 0.627759575843811
Validation loss: 2.017433683077494

Epoch: 6| Step: 1
Training loss: 0.22532548010349274
Validation loss: 1.9720072944959004

Epoch: 6| Step: 2
Training loss: 0.37382954359054565
Validation loss: 2.0073895851771035

Epoch: 6| Step: 3
Training loss: 0.32513427734375
Validation loss: 1.9812097152074177

Epoch: 6| Step: 4
Training loss: 0.24643133580684662
Validation loss: 1.9387049674987793

Epoch: 6| Step: 5
Training loss: 0.7458097338676453
Validation loss: 2.0068902571996055

Epoch: 6| Step: 6
Training loss: 0.22665925323963165
Validation loss: 1.9608902335166931

Epoch: 6| Step: 7
Training loss: 0.49279719591140747
Validation loss: 2.0109758377075195

Epoch: 6| Step: 8
Training loss: 0.3930559754371643
Validation loss: 2.0186033248901367

Epoch: 6| Step: 9
Training loss: 0.36207592487335205
Validation loss: 1.9501718680063884

Epoch: 6| Step: 10
Training loss: 0.6062349081039429
Validation loss: 1.9572686553001404

Epoch: 6| Step: 11
Training loss: 0.5849837064743042
Validation loss: 1.9836867849032085

Epoch: 6| Step: 12
Training loss: 0.3071553707122803
Validation loss: 1.9676376581192017

Epoch: 6| Step: 13
Training loss: 0.2871781587600708
Validation loss: 1.9734402696291606

Epoch: 228| Step: 0
Training loss: 0.2837373614311218
Validation loss: 1.9628734985987346

Epoch: 6| Step: 1
Training loss: 0.21274979412555695
Validation loss: 1.9669319192568462

Epoch: 6| Step: 2
Training loss: 0.2516457736492157
Validation loss: 1.9883673389752705

Epoch: 6| Step: 3
Training loss: 0.31690722703933716
Validation loss: 1.9983293811480205

Epoch: 6| Step: 4
Training loss: 0.31442588567733765
Validation loss: 1.9863736629486084

Epoch: 6| Step: 5
Training loss: 0.6102261543273926
Validation loss: 2.0017173886299133

Epoch: 6| Step: 6
Training loss: 0.3551552891731262
Validation loss: 1.946433961391449

Epoch: 6| Step: 7
Training loss: 0.655358612537384
Validation loss: 1.9594744046529133

Epoch: 6| Step: 8
Training loss: 0.24948732554912567
Validation loss: 2.0033273498217263

Epoch: 6| Step: 9
Training loss: 0.5981600284576416
Validation loss: 2.002444783846537

Epoch: 6| Step: 10
Training loss: 0.5162960290908813
Validation loss: 1.9471824765205383

Epoch: 6| Step: 11
Training loss: 0.518307089805603
Validation loss: 1.9561546246210735

Epoch: 6| Step: 12
Training loss: 0.5125632286071777
Validation loss: 2.013601859410604

Epoch: 6| Step: 13
Training loss: 0.4036722183227539
Validation loss: 1.948409656683604

Epoch: 229| Step: 0
Training loss: 0.49686121940612793
Validation loss: 1.9326403141021729

Epoch: 6| Step: 1
Training loss: 0.28826427459716797
Validation loss: 2.0191597143809

Epoch: 6| Step: 2
Training loss: 0.8877968788146973
Validation loss: 1.9778265953063965

Epoch: 6| Step: 3
Training loss: 0.4615352153778076
Validation loss: 1.9471656878789265

Epoch: 6| Step: 4
Training loss: 0.5673373341560364
Validation loss: 2.0201287070910134

Epoch: 6| Step: 5
Training loss: 0.26261579990386963
Validation loss: 1.988398551940918

Epoch: 6| Step: 6
Training loss: 0.5449811220169067
Validation loss: 1.9300544063250225

Epoch: 6| Step: 7
Training loss: 0.5128464698791504
Validation loss: 1.9721043308575947

Epoch: 6| Step: 8
Training loss: 0.459199458360672
Validation loss: 1.9713445504506428

Epoch: 6| Step: 9
Training loss: 0.39975255727767944
Validation loss: 1.9524035056432087

Epoch: 6| Step: 10
Training loss: 0.3381223678588867
Validation loss: 1.988295555114746

Epoch: 6| Step: 11
Training loss: 0.18444018065929413
Validation loss: 1.948911984761556

Epoch: 6| Step: 12
Training loss: 0.48519381880760193
Validation loss: 1.9328135251998901

Epoch: 6| Step: 13
Training loss: 0.2899634838104248
Validation loss: 1.9695844848950703

Epoch: 230| Step: 0
Training loss: 0.316067099571228
Validation loss: 1.9092212915420532

Epoch: 6| Step: 1
Training loss: 0.29381072521209717
Validation loss: 1.9665887753168743

Epoch: 6| Step: 2
Training loss: 0.9864087104797363
Validation loss: 1.9764182567596436

Epoch: 6| Step: 3
Training loss: 0.27986636757850647
Validation loss: 1.959271788597107

Epoch: 6| Step: 4
Training loss: 0.5302006006240845
Validation loss: 1.9070360660552979

Epoch: 6| Step: 5
Training loss: 0.4664260745048523
Validation loss: 1.9655349651972454

Epoch: 6| Step: 6
Training loss: 0.312791645526886
Validation loss: 1.9526087641716003

Epoch: 6| Step: 7
Training loss: 0.21836835145950317
Validation loss: 1.9649252692858379

Epoch: 6| Step: 8
Training loss: 0.5573267936706543
Validation loss: 2.002142310142517

Epoch: 6| Step: 9
Training loss: 0.38188520073890686
Validation loss: 1.9824535648028057

Epoch: 6| Step: 10
Training loss: 0.36168503761291504
Validation loss: 1.9751060009002686

Epoch: 6| Step: 11
Training loss: 0.2860015630722046
Validation loss: 1.9887405633926392

Epoch: 6| Step: 12
Training loss: 0.21344923973083496
Validation loss: 1.9553604920705159

Epoch: 6| Step: 13
Training loss: 0.49554067850112915
Validation loss: 1.960765302181244

Epoch: 231| Step: 0
Training loss: 0.9940119981765747
Validation loss: 1.951366662979126

Epoch: 6| Step: 1
Training loss: 0.2556028962135315
Validation loss: 1.9877116084098816

Epoch: 6| Step: 2
Training loss: 0.17754876613616943
Validation loss: 1.971614142258962

Epoch: 6| Step: 3
Training loss: 0.3143192529678345
Validation loss: 1.986442506313324

Epoch: 6| Step: 4
Training loss: 0.4683338403701782
Validation loss: 1.9841570655504863

Epoch: 6| Step: 5
Training loss: 0.36083951592445374
Validation loss: 1.9449437856674194

Epoch: 6| Step: 6
Training loss: 0.27318018674850464
Validation loss: 1.9084341526031494

Epoch: 6| Step: 7
Training loss: 0.2479110062122345
Validation loss: 2.015897035598755

Epoch: 6| Step: 8
Training loss: 0.4450418949127197
Validation loss: 2.0036030809084573

Epoch: 6| Step: 9
Training loss: 0.5774593949317932
Validation loss: 2.009902815024058

Epoch: 6| Step: 10
Training loss: 0.44341397285461426
Validation loss: 1.962521235148112

Epoch: 6| Step: 11
Training loss: 0.2305999994277954
Validation loss: 2.001764496167501

Epoch: 6| Step: 12
Training loss: 0.3947920799255371
Validation loss: 1.9933131734530132

Epoch: 6| Step: 13
Training loss: 0.35562288761138916
Validation loss: 2.002148230870565

Epoch: 232| Step: 0
Training loss: 0.4010694622993469
Validation loss: 1.987333079179128

Epoch: 6| Step: 1
Training loss: 0.2109047770500183
Validation loss: 1.9440859357515972

Epoch: 6| Step: 2
Training loss: 0.6796510219573975
Validation loss: 1.952068269252777

Epoch: 6| Step: 3
Training loss: 0.5454421043395996
Validation loss: 1.9541943470637004

Epoch: 6| Step: 4
Training loss: 0.39338362216949463
Validation loss: 1.935257335503896

Epoch: 6| Step: 5
Training loss: 0.38744503259658813
Validation loss: 1.9545672337214153

Epoch: 6| Step: 6
Training loss: 0.3024708926677704
Validation loss: 1.9775879780451457

Epoch: 6| Step: 7
Training loss: 0.2728819251060486
Validation loss: 1.9925894538561504

Epoch: 6| Step: 8
Training loss: 0.6717191338539124
Validation loss: 1.9137492577234905

Epoch: 6| Step: 9
Training loss: 0.3251994848251343
Validation loss: 1.968045969804128

Epoch: 6| Step: 10
Training loss: 0.2396649718284607
Validation loss: 1.9745834271113079

Epoch: 6| Step: 11
Training loss: 0.4526555836200714
Validation loss: 1.932719886302948

Epoch: 6| Step: 12
Training loss: 0.32716405391693115
Validation loss: 1.9665288130442302

Epoch: 6| Step: 13
Training loss: 0.5216095447540283
Validation loss: 1.9732738137245178

Epoch: 233| Step: 0
Training loss: 0.22714996337890625
Validation loss: 1.9811159769694011

Epoch: 6| Step: 1
Training loss: 0.6313363313674927
Validation loss: 1.9807441631952922

Epoch: 6| Step: 2
Training loss: 0.3010650873184204
Validation loss: 1.9528181751569111

Epoch: 6| Step: 3
Training loss: 0.4556260108947754
Validation loss: 1.935651183128357

Epoch: 6| Step: 4
Training loss: 0.44541028141975403
Validation loss: 1.9314266443252563

Epoch: 6| Step: 5
Training loss: 0.46329736709594727
Validation loss: 2.001367211341858

Epoch: 6| Step: 6
Training loss: 0.4409187436103821
Validation loss: 1.9399215181668599

Epoch: 6| Step: 7
Training loss: 0.6517443060874939
Validation loss: 1.952434500058492

Epoch: 6| Step: 8
Training loss: 0.2591286599636078
Validation loss: 1.991441011428833

Epoch: 6| Step: 9
Training loss: 0.21425500512123108
Validation loss: 1.976915180683136

Epoch: 6| Step: 10
Training loss: 0.4390444755554199
Validation loss: 1.9887883067131042

Epoch: 6| Step: 11
Training loss: 0.31204092502593994
Validation loss: 1.9857072432835896

Epoch: 6| Step: 12
Training loss: 0.5141382217407227
Validation loss: 1.9569010138511658

Epoch: 6| Step: 13
Training loss: 0.3833189010620117
Validation loss: 2.0082723100980124

Epoch: 234| Step: 0
Training loss: 0.4244270324707031
Validation loss: 1.9972907106081645

Epoch: 6| Step: 1
Training loss: 0.47978702187538147
Validation loss: 1.9537317156791687

Epoch: 6| Step: 2
Training loss: 0.20978094637393951
Validation loss: 1.9490807056427002

Epoch: 6| Step: 3
Training loss: 0.34666287899017334
Validation loss: 1.9724902311960857

Epoch: 6| Step: 4
Training loss: 0.8057469129562378
Validation loss: 1.9379644989967346

Epoch: 6| Step: 5
Training loss: 0.39259108901023865
Validation loss: 1.986902376015981

Epoch: 6| Step: 6
Training loss: 0.2811294198036194
Validation loss: 1.997697611649831

Epoch: 6| Step: 7
Training loss: 0.6094093918800354
Validation loss: 1.959344784418742

Epoch: 6| Step: 8
Training loss: 0.5283676385879517
Validation loss: 1.9803777535756428

Epoch: 6| Step: 9
Training loss: 0.5638580918312073
Validation loss: 2.024849772453308

Epoch: 6| Step: 10
Training loss: 0.23441854119300842
Validation loss: 1.9873488545417786

Epoch: 6| Step: 11
Training loss: 0.4436103403568268
Validation loss: 1.9618846972783406

Epoch: 6| Step: 12
Training loss: 0.47497493028640747
Validation loss: 2.0029207865397134

Epoch: 6| Step: 13
Training loss: 0.6058919429779053
Validation loss: 1.9713410933812459

Epoch: 235| Step: 0
Training loss: 0.5251039266586304
Validation loss: 1.972473919391632

Epoch: 6| Step: 1
Training loss: 0.33772823214530945
Validation loss: 1.9904730319976807

Epoch: 6| Step: 2
Training loss: 0.35742682218551636
Validation loss: 1.9881641666094463

Epoch: 6| Step: 3
Training loss: 0.42430105805397034
Validation loss: 2.0098419984181723

Epoch: 6| Step: 4
Training loss: 0.42845210433006287
Validation loss: 2.0025877356529236

Epoch: 6| Step: 5
Training loss: 0.25107914209365845
Validation loss: 2.008786420027415

Epoch: 6| Step: 6
Training loss: 0.30356109142303467
Validation loss: 2.0353532433509827

Epoch: 6| Step: 7
Training loss: 0.3027992248535156
Validation loss: 1.9960678219795227

Epoch: 6| Step: 8
Training loss: 0.37918010354042053
Validation loss: 2.0143754482269287

Epoch: 6| Step: 9
Training loss: 0.7718756198883057
Validation loss: 1.9710923631985982

Epoch: 6| Step: 10
Training loss: 0.44685545563697815
Validation loss: 1.9941310087839763

Epoch: 6| Step: 11
Training loss: 0.44558632373809814
Validation loss: 2.010586698849996

Epoch: 6| Step: 12
Training loss: 0.37843558192253113
Validation loss: 1.9962756236394246

Epoch: 6| Step: 13
Training loss: 0.5047386884689331
Validation loss: 1.9575690428415935

Epoch: 236| Step: 0
Training loss: 0.22086992859840393
Validation loss: 2.02076784769694

Epoch: 6| Step: 1
Training loss: 0.24734316766262054
Validation loss: 1.9656169215838115

Epoch: 6| Step: 2
Training loss: 0.4632720351219177
Validation loss: 1.9204677939414978

Epoch: 6| Step: 3
Training loss: 0.5460282564163208
Validation loss: 1.9674291213353474

Epoch: 6| Step: 4
Training loss: 0.3847346305847168
Validation loss: 1.9424800872802734

Epoch: 6| Step: 5
Training loss: 0.6274552345275879
Validation loss: 1.9218437671661377

Epoch: 6| Step: 6
Training loss: 0.32922929525375366
Validation loss: 1.9873181184132893

Epoch: 6| Step: 7
Training loss: 0.43800657987594604
Validation loss: 1.991767942905426

Epoch: 6| Step: 8
Training loss: 0.3473302721977234
Validation loss: 1.9894441962242126

Epoch: 6| Step: 9
Training loss: 0.5408747792243958
Validation loss: 1.9827341039975483

Epoch: 6| Step: 10
Training loss: 0.3221634328365326
Validation loss: 1.9549606442451477

Epoch: 6| Step: 11
Training loss: 0.2806313633918762
Validation loss: 1.9822152157624562

Epoch: 6| Step: 12
Training loss: 0.45073258876800537
Validation loss: 1.9718796014785767

Epoch: 6| Step: 13
Training loss: 0.3497662842273712
Validation loss: 1.930179238319397

Epoch: 237| Step: 0
Training loss: 0.6624836921691895
Validation loss: 1.9727653066317241

Epoch: 6| Step: 1
Training loss: 0.5627058744430542
Validation loss: 1.9638828039169312

Epoch: 6| Step: 2
Training loss: 0.38102829456329346
Validation loss: 1.9617092609405518

Epoch: 6| Step: 3
Training loss: 0.2961960732936859
Validation loss: 1.967481017112732

Epoch: 6| Step: 4
Training loss: 0.2233828753232956
Validation loss: 1.9355697631835938

Epoch: 6| Step: 5
Training loss: 0.2794208526611328
Validation loss: 1.9793792366981506

Epoch: 6| Step: 6
Training loss: 0.20373693108558655
Validation loss: 1.9549764394760132

Epoch: 6| Step: 7
Training loss: 0.17869171500205994
Validation loss: 1.9320711692174275

Epoch: 6| Step: 8
Training loss: 0.5516756772994995
Validation loss: 1.9795986612637837

Epoch: 6| Step: 9
Training loss: 0.5204702615737915
Validation loss: 1.9830945332845051

Epoch: 6| Step: 10
Training loss: 0.1813238561153412
Validation loss: 1.957276185353597

Epoch: 6| Step: 11
Training loss: 0.5755077600479126
Validation loss: 1.9745975335439045

Epoch: 6| Step: 12
Training loss: 0.23788341879844666
Validation loss: 1.990834653377533

Epoch: 6| Step: 13
Training loss: 0.6201576590538025
Validation loss: 1.997219701608022

Epoch: 238| Step: 0
Training loss: 0.5662273168563843
Validation loss: 2.006095846494039

Epoch: 6| Step: 1
Training loss: 0.3923951983451843
Validation loss: 2.025495946407318

Epoch: 6| Step: 2
Training loss: 0.3246726989746094
Validation loss: 2.0216908057530723

Epoch: 6| Step: 3
Training loss: 0.4999772310256958
Validation loss: 2.012373924255371

Epoch: 6| Step: 4
Training loss: 0.2786788046360016
Validation loss: 1.9590216080347698

Epoch: 6| Step: 5
Training loss: 0.5373501777648926
Validation loss: 1.9875797629356384

Epoch: 6| Step: 6
Training loss: 0.3951622247695923
Validation loss: 1.958966076374054

Epoch: 6| Step: 7
Training loss: 0.4097089171409607
Validation loss: 2.015845795472463

Epoch: 6| Step: 8
Training loss: 0.1766359508037567
Validation loss: 1.9777388175328572

Epoch: 6| Step: 9
Training loss: 0.63711017370224
Validation loss: 1.9732330640157063

Epoch: 6| Step: 10
Training loss: 0.4005371332168579
Validation loss: 1.9883031050364177

Epoch: 6| Step: 11
Training loss: 0.35415148735046387
Validation loss: 1.994103193283081

Epoch: 6| Step: 12
Training loss: 0.4398665726184845
Validation loss: 1.9632790486017864

Epoch: 6| Step: 13
Training loss: 0.31466084718704224
Validation loss: 1.9429575403531392

Epoch: 239| Step: 0
Training loss: 0.44976872205734253
Validation loss: 1.9682308038075764

Epoch: 6| Step: 1
Training loss: 0.18924760818481445
Validation loss: 1.9969401756922405

Epoch: 6| Step: 2
Training loss: 0.23966962099075317
Validation loss: 1.9663786093393962

Epoch: 6| Step: 3
Training loss: 0.7040199041366577
Validation loss: 1.9507671395937602

Epoch: 6| Step: 4
Training loss: 0.4466857612133026
Validation loss: 2.0037295619646707

Epoch: 6| Step: 5
Training loss: 0.24472247064113617
Validation loss: 1.9913613398869832

Epoch: 6| Step: 6
Training loss: 0.27943408489227295
Validation loss: 1.965108871459961

Epoch: 6| Step: 7
Training loss: 0.4679543375968933
Validation loss: 1.9795027176539104

Epoch: 6| Step: 8
Training loss: 0.19955846667289734
Validation loss: 1.9928032358487446

Epoch: 6| Step: 9
Training loss: 0.6936562061309814
Validation loss: 1.9590087135632832

Epoch: 6| Step: 10
Training loss: 0.4521278440952301
Validation loss: 1.9861566027005513

Epoch: 6| Step: 11
Training loss: 0.3693842589855194
Validation loss: 1.9879658023516338

Epoch: 6| Step: 12
Training loss: 0.26941460371017456
Validation loss: 2.0339329838752747

Epoch: 6| Step: 13
Training loss: 0.539031982421875
Validation loss: 1.968824525674184

Epoch: 240| Step: 0
Training loss: 0.7407932281494141
Validation loss: 1.9875058929125469

Epoch: 6| Step: 1
Training loss: 0.27160295844078064
Validation loss: 1.986872911453247

Epoch: 6| Step: 2
Training loss: 0.2049790769815445
Validation loss: 1.9497727553049724

Epoch: 6| Step: 3
Training loss: 0.2816132605075836
Validation loss: 1.9632418354352315

Epoch: 6| Step: 4
Training loss: 0.45052677392959595
Validation loss: 1.979489028453827

Epoch: 6| Step: 5
Training loss: 0.37009260058403015
Validation loss: 2.0019137461980185

Epoch: 6| Step: 6
Training loss: 0.20088952779769897
Validation loss: 1.9899731278419495

Epoch: 6| Step: 7
Training loss: 0.2626277804374695
Validation loss: 1.9977090160051982

Epoch: 6| Step: 8
Training loss: 0.34199219942092896
Validation loss: 1.976339856783549

Epoch: 6| Step: 9
Training loss: 0.13397343456745148
Validation loss: 2.0036858320236206

Epoch: 6| Step: 10
Training loss: 0.8178167343139648
Validation loss: 2.002102533976237

Epoch: 6| Step: 11
Training loss: 0.3789384961128235
Validation loss: 1.9873391191164653

Epoch: 6| Step: 12
Training loss: 0.4212474524974823
Validation loss: 1.981418530146281

Epoch: 6| Step: 13
Training loss: 0.66571044921875
Validation loss: 1.975491225719452

Epoch: 241| Step: 0
Training loss: 0.2744108736515045
Validation loss: 1.9589618841807048

Epoch: 6| Step: 1
Training loss: 0.46862077713012695
Validation loss: 1.9555954535802205

Epoch: 6| Step: 2
Training loss: 0.585793137550354
Validation loss: 1.9913757840792339

Epoch: 6| Step: 3
Training loss: 0.3914995491504669
Validation loss: 2.0032132466634116

Epoch: 6| Step: 4
Training loss: 0.5492905974388123
Validation loss: 1.9698894023895264

Epoch: 6| Step: 5
Training loss: 0.21634140610694885
Validation loss: 2.026320497194926

Epoch: 6| Step: 6
Training loss: 0.34015074372291565
Validation loss: 1.9465121229489644

Epoch: 6| Step: 7
Training loss: 0.34547239542007446
Validation loss: 1.9670698841412861

Epoch: 6| Step: 8
Training loss: 0.2532973885536194
Validation loss: 1.9869110584259033

Epoch: 6| Step: 9
Training loss: 0.38934439420700073
Validation loss: 1.99109282096227

Epoch: 6| Step: 10
Training loss: 0.28040874004364014
Validation loss: 1.9573618372281392

Epoch: 6| Step: 11
Training loss: 0.8798143863677979
Validation loss: 1.978736142317454

Epoch: 6| Step: 12
Training loss: 0.40298378467559814
Validation loss: 2.008033037185669

Epoch: 6| Step: 13
Training loss: 0.11538160592317581
Validation loss: 1.9819979866345723

Epoch: 242| Step: 0
Training loss: 0.32269740104675293
Validation loss: 1.990763783454895

Epoch: 6| Step: 1
Training loss: 0.2546403110027313
Validation loss: 2.000485281149546

Epoch: 6| Step: 2
Training loss: 0.289259672164917
Validation loss: 1.9907851417859395

Epoch: 6| Step: 3
Training loss: 0.7837158441543579
Validation loss: 1.9772076805432637

Epoch: 6| Step: 4
Training loss: 0.29256951808929443
Validation loss: 1.9652650753657024

Epoch: 6| Step: 5
Training loss: 0.4967915713787079
Validation loss: 1.9632290800412495

Epoch: 6| Step: 6
Training loss: 0.3301839530467987
Validation loss: 1.9885551730791728

Epoch: 6| Step: 7
Training loss: 0.9437747001647949
Validation loss: 1.9861159523328145

Epoch: 6| Step: 8
Training loss: 0.33646607398986816
Validation loss: 1.952715555826823

Epoch: 6| Step: 9
Training loss: 0.43938130140304565
Validation loss: 1.9887832800547283

Epoch: 6| Step: 10
Training loss: 0.24096281826496124
Validation loss: 1.9598292311032612

Epoch: 6| Step: 11
Training loss: 0.3297579884529114
Validation loss: 1.9597237904866536

Epoch: 6| Step: 12
Training loss: 0.349744975566864
Validation loss: 1.9453185002009075

Epoch: 6| Step: 13
Training loss: 0.2876804769039154
Validation loss: 2.0275093714396157

Epoch: 243| Step: 0
Training loss: 0.17728939652442932
Validation loss: 1.9633681774139404

Epoch: 6| Step: 1
Training loss: 0.44918906688690186
Validation loss: 1.9369009931882222

Epoch: 6| Step: 2
Training loss: 0.4667629301548004
Validation loss: 1.9710372686386108

Epoch: 6| Step: 3
Training loss: 0.5942333936691284
Validation loss: 1.9816443522771199

Epoch: 6| Step: 4
Training loss: 0.2432618886232376
Validation loss: 1.9858685930569966

Epoch: 6| Step: 5
Training loss: 0.24503761529922485
Validation loss: 1.983891228834788

Epoch: 6| Step: 6
Training loss: 0.2413320094347
Validation loss: 1.9492544333140056

Epoch: 6| Step: 7
Training loss: 0.2565782964229584
Validation loss: 1.9860781232515972

Epoch: 6| Step: 8
Training loss: 0.17659488320350647
Validation loss: 1.9594268997510274

Epoch: 6| Step: 9
Training loss: 0.4597494900226593
Validation loss: 1.9496055245399475

Epoch: 6| Step: 10
Training loss: 0.48069608211517334
Validation loss: 1.9829604029655457

Epoch: 6| Step: 11
Training loss: 0.3512847423553467
Validation loss: 2.018028676509857

Epoch: 6| Step: 12
Training loss: 0.44463756680488586
Validation loss: 1.9835943579673767

Epoch: 6| Step: 13
Training loss: 0.7945591807365417
Validation loss: 1.9885649879773457

Epoch: 244| Step: 0
Training loss: 0.4510084092617035
Validation loss: 1.930252214272817

Epoch: 6| Step: 1
Training loss: 0.2529568672180176
Validation loss: 1.9835530320803325

Epoch: 6| Step: 2
Training loss: 0.34458836913108826
Validation loss: 1.9583095113436382

Epoch: 6| Step: 3
Training loss: 0.3260784149169922
Validation loss: 1.9763368964195251

Epoch: 6| Step: 4
Training loss: 0.3322567045688629
Validation loss: 1.9674571355183919

Epoch: 6| Step: 5
Training loss: 0.3503792881965637
Validation loss: 1.9736116727193196

Epoch: 6| Step: 6
Training loss: 0.5281786918640137
Validation loss: 1.985054075717926

Epoch: 6| Step: 7
Training loss: 0.22519618272781372
Validation loss: 1.9418018062909443

Epoch: 6| Step: 8
Training loss: 0.5267314314842224
Validation loss: 1.9357128341992695

Epoch: 6| Step: 9
Training loss: 0.6547057032585144
Validation loss: 1.9927763144175212

Epoch: 6| Step: 10
Training loss: 0.4344353973865509
Validation loss: 1.9407178163528442

Epoch: 6| Step: 11
Training loss: 0.28655314445495605
Validation loss: 1.9457621177037556

Epoch: 6| Step: 12
Training loss: 0.3950929045677185
Validation loss: 1.9398450255393982

Epoch: 6| Step: 13
Training loss: 0.35796812176704407
Validation loss: 1.951448380947113

Epoch: 245| Step: 0
Training loss: 0.19981080293655396
Validation loss: 1.9487685759862263

Epoch: 6| Step: 1
Training loss: 0.40471506118774414
Validation loss: 1.9456385572751362

Epoch: 6| Step: 2
Training loss: 0.3567776083946228
Validation loss: 1.9399203856786091

Epoch: 6| Step: 3
Training loss: 0.6951149702072144
Validation loss: 1.9850255250930786

Epoch: 6| Step: 4
Training loss: 0.2622367739677429
Validation loss: 1.9828930695851643

Epoch: 6| Step: 5
Training loss: 0.31980544328689575
Validation loss: 1.9296574195226033

Epoch: 6| Step: 6
Training loss: 0.3549775779247284
Validation loss: 1.9585886001586914

Epoch: 6| Step: 7
Training loss: 0.3073052167892456
Validation loss: 1.9377777775128682

Epoch: 6| Step: 8
Training loss: 0.16115327179431915
Validation loss: 1.9475411574045818

Epoch: 6| Step: 9
Training loss: 0.4139913320541382
Validation loss: 1.9649739265441895

Epoch: 6| Step: 10
Training loss: 0.4010502099990845
Validation loss: 2.0371057391166687

Epoch: 6| Step: 11
Training loss: 0.3071866035461426
Validation loss: 1.947617510954539

Epoch: 6| Step: 12
Training loss: 0.48669421672821045
Validation loss: 1.974596122900645

Epoch: 6| Step: 13
Training loss: 0.4916818141937256
Validation loss: 1.9824260870615642

Epoch: 246| Step: 0
Training loss: 0.20464792847633362
Validation loss: 2.0073492924372354

Epoch: 6| Step: 1
Training loss: 0.3126124143600464
Validation loss: 1.9598721663157146

Epoch: 6| Step: 2
Training loss: 0.4285001754760742
Validation loss: 1.9410828948020935

Epoch: 6| Step: 3
Training loss: 0.42600739002227783
Validation loss: 1.9486514528592427

Epoch: 6| Step: 4
Training loss: 0.46858057379722595
Validation loss: 1.9461161692937214

Epoch: 6| Step: 5
Training loss: 0.18740318715572357
Validation loss: 1.9769479632377625

Epoch: 6| Step: 6
Training loss: 0.26963189244270325
Validation loss: 1.9885251720746357

Epoch: 6| Step: 7
Training loss: 0.2910323143005371
Validation loss: 1.9646676381429036

Epoch: 6| Step: 8
Training loss: 0.6889145970344543
Validation loss: 1.99387522538503

Epoch: 6| Step: 9
Training loss: 0.2383001446723938
Validation loss: 1.9806481798489888

Epoch: 6| Step: 10
Training loss: 0.40763795375823975
Validation loss: 2.014946003754934

Epoch: 6| Step: 11
Training loss: 0.6434902548789978
Validation loss: 1.9852897723515828

Epoch: 6| Step: 12
Training loss: 0.5470194816589355
Validation loss: 1.9606282313664753

Epoch: 6| Step: 13
Training loss: 0.36090904474258423
Validation loss: 2.0165584286053977

Epoch: 247| Step: 0
Training loss: 0.226240336894989
Validation loss: 1.9668855667114258

Epoch: 6| Step: 1
Training loss: 0.34635812044143677
Validation loss: 1.9856719970703125

Epoch: 6| Step: 2
Training loss: 0.424530029296875
Validation loss: 1.9854634006818135

Epoch: 6| Step: 3
Training loss: 0.34976211190223694
Validation loss: 1.9858574469884236

Epoch: 6| Step: 4
Training loss: 0.22618988156318665
Validation loss: 1.9877818028132122

Epoch: 6| Step: 5
Training loss: 0.428693026304245
Validation loss: 2.004966457684835

Epoch: 6| Step: 6
Training loss: 0.3837556540966034
Validation loss: 1.9858230749766033

Epoch: 6| Step: 7
Training loss: 0.48696208000183105
Validation loss: 1.998954137166341

Epoch: 6| Step: 8
Training loss: 0.46266552805900574
Validation loss: 1.9585386514663696

Epoch: 6| Step: 9
Training loss: 0.381009966135025
Validation loss: 1.9572000900904338

Epoch: 6| Step: 10
Training loss: 0.2675285041332245
Validation loss: 1.9794569810231526

Epoch: 6| Step: 11
Training loss: 0.3184736371040344
Validation loss: 1.9664840896924336

Epoch: 6| Step: 12
Training loss: 0.6859070062637329
Validation loss: 1.941697319348653

Epoch: 6| Step: 13
Training loss: 0.1845686137676239
Validation loss: 1.952121635278066

Epoch: 248| Step: 0
Training loss: 0.5459154844284058
Validation loss: 1.9464480479558308

Epoch: 6| Step: 1
Training loss: 0.1759858876466751
Validation loss: 1.9891570607821147

Epoch: 6| Step: 2
Training loss: 0.6650615930557251
Validation loss: 1.988434096177419

Epoch: 6| Step: 3
Training loss: 0.6618783473968506
Validation loss: 2.006590167681376

Epoch: 6| Step: 4
Training loss: 0.2983325123786926
Validation loss: 1.9831146200497944

Epoch: 6| Step: 5
Training loss: 0.15801885724067688
Validation loss: 1.925044576327006

Epoch: 6| Step: 6
Training loss: 0.5354208946228027
Validation loss: 1.9428621133168538

Epoch: 6| Step: 7
Training loss: 0.3121771216392517
Validation loss: 1.962498962879181

Epoch: 6| Step: 8
Training loss: 0.4178236424922943
Validation loss: 1.9521126747131348

Epoch: 6| Step: 9
Training loss: 0.20102834701538086
Validation loss: 1.9905340472857158

Epoch: 6| Step: 10
Training loss: 0.4532017111778259
Validation loss: 1.9543951749801636

Epoch: 6| Step: 11
Training loss: 0.3150792717933655
Validation loss: 1.9729480346043904

Epoch: 6| Step: 12
Training loss: 0.3101371228694916
Validation loss: 2.005068222681681

Epoch: 6| Step: 13
Training loss: 0.5737966895103455
Validation loss: 1.9522732098897297

Epoch: 249| Step: 0
Training loss: 0.4563939869403839
Validation loss: 1.9921039938926697

Epoch: 6| Step: 1
Training loss: 0.49170905351638794
Validation loss: 1.9882109959920247

Epoch: 6| Step: 2
Training loss: 0.3251449465751648
Validation loss: 1.9844062129656475

Epoch: 6| Step: 3
Training loss: 0.3046933710575104
Validation loss: 1.994551380475362

Epoch: 6| Step: 4
Training loss: 0.5157337784767151
Validation loss: 1.9914310574531555

Epoch: 6| Step: 5
Training loss: 0.20994621515274048
Validation loss: 1.9879554311434429

Epoch: 6| Step: 6
Training loss: 0.45666635036468506
Validation loss: 1.968816081682841

Epoch: 6| Step: 7
Training loss: 0.4457961320877075
Validation loss: 1.9818644722302754

Epoch: 6| Step: 8
Training loss: 0.7116845846176147
Validation loss: 1.9674752553304036

Epoch: 6| Step: 9
Training loss: 0.6016103029251099
Validation loss: 2.0031539599100747

Epoch: 6| Step: 10
Training loss: 0.28443023562431335
Validation loss: 1.9762483437856038

Epoch: 6| Step: 11
Training loss: 0.21918949484825134
Validation loss: 1.9878609776496887

Epoch: 6| Step: 12
Training loss: 0.29070326685905457
Validation loss: 1.994107226530711

Epoch: 6| Step: 13
Training loss: 0.20551569759845734
Validation loss: 2.0258894761403403

Epoch: 250| Step: 0
Training loss: 0.43046480417251587
Validation loss: 1.9894989331563313

Epoch: 6| Step: 1
Training loss: 0.5967754125595093
Validation loss: 2.0022199551264444

Epoch: 6| Step: 2
Training loss: 0.3870495557785034
Validation loss: 2.024411598841349

Epoch: 6| Step: 3
Training loss: 0.17044523358345032
Validation loss: 1.98533034324646

Epoch: 6| Step: 4
Training loss: 0.6338871717453003
Validation loss: 2.0205057859420776

Epoch: 6| Step: 5
Training loss: 0.6657942533493042
Validation loss: 1.9447657068570454

Epoch: 6| Step: 6
Training loss: 0.3625762462615967
Validation loss: 1.9856755534807842

Epoch: 6| Step: 7
Training loss: 0.3564549684524536
Validation loss: 1.9409151673316956

Epoch: 6| Step: 8
Training loss: 0.2363654226064682
Validation loss: 2.018612007300059

Epoch: 6| Step: 9
Training loss: 0.18623298406600952
Validation loss: 1.949022610982259

Epoch: 6| Step: 10
Training loss: 0.30967891216278076
Validation loss: 1.9722371498743694

Epoch: 6| Step: 11
Training loss: 0.5013888478279114
Validation loss: 1.9779504537582397

Epoch: 6| Step: 12
Training loss: 0.5321843028068542
Validation loss: 1.9605572024981182

Epoch: 6| Step: 13
Training loss: 0.30827364325523376
Validation loss: 1.9298145373662312

Epoch: 251| Step: 0
Training loss: 0.3809022307395935
Validation loss: 1.906001627445221

Epoch: 6| Step: 1
Training loss: 0.5236606597900391
Validation loss: 1.9204995036125183

Epoch: 6| Step: 2
Training loss: 0.4444393515586853
Validation loss: 1.9844431479771931

Epoch: 6| Step: 3
Training loss: 0.16929250955581665
Validation loss: 1.9890189965565999

Epoch: 6| Step: 4
Training loss: 0.32225653529167175
Validation loss: 1.9427602291107178

Epoch: 6| Step: 5
Training loss: 0.25615188479423523
Validation loss: 1.9644095102945964

Epoch: 6| Step: 6
Training loss: 0.19604015350341797
Validation loss: 1.959254761536916

Epoch: 6| Step: 7
Training loss: 0.47471997141838074
Validation loss: 1.9420308868090312

Epoch: 6| Step: 8
Training loss: 0.8014216423034668
Validation loss: 1.9576798280080159

Epoch: 6| Step: 9
Training loss: 0.3648042678833008
Validation loss: 1.921809156735738

Epoch: 6| Step: 10
Training loss: 0.45691391825675964
Validation loss: 1.9903789162635803

Epoch: 6| Step: 11
Training loss: 0.3359822928905487
Validation loss: 1.9428316752115886

Epoch: 6| Step: 12
Training loss: 0.3953876495361328
Validation loss: 1.9495990475018818

Epoch: 6| Step: 13
Training loss: 0.2687685787677765
Validation loss: 1.9967018564542134

Epoch: 252| Step: 0
Training loss: 0.2460450977087021
Validation loss: 1.9791508118311565

Epoch: 6| Step: 1
Training loss: 0.3412504196166992
Validation loss: 1.9916221896807353

Epoch: 6| Step: 2
Training loss: 0.26273152232170105
Validation loss: 1.9794047673543294

Epoch: 6| Step: 3
Training loss: 0.5994943976402283
Validation loss: 1.987715244293213

Epoch: 6| Step: 4
Training loss: 0.40258553624153137
Validation loss: 1.9492486715316772

Epoch: 6| Step: 5
Training loss: 0.14678436517715454
Validation loss: 1.9763153195381165

Epoch: 6| Step: 6
Training loss: 0.5760968923568726
Validation loss: 1.961692790190379

Epoch: 6| Step: 7
Training loss: 0.25635987520217896
Validation loss: 1.9894937872886658

Epoch: 6| Step: 8
Training loss: 0.36077672243118286
Validation loss: 1.970711310704549

Epoch: 6| Step: 9
Training loss: 0.2693272829055786
Validation loss: 1.94753630956014

Epoch: 6| Step: 10
Training loss: 0.39737963676452637
Validation loss: 1.9489630460739136

Epoch: 6| Step: 11
Training loss: 0.3309023678302765
Validation loss: 2.0231436491012573

Epoch: 6| Step: 12
Training loss: 0.7471259236335754
Validation loss: 2.016240378220876

Epoch: 6| Step: 13
Training loss: 0.3759194612503052
Validation loss: 1.9066133896509807

Epoch: 253| Step: 0
Training loss: 0.21615135669708252
Validation loss: 1.9834625124931335

Epoch: 6| Step: 1
Training loss: 0.2744622528553009
Validation loss: 1.9661752382914226

Epoch: 6| Step: 2
Training loss: 0.4139869213104248
Validation loss: 1.9675430059432983

Epoch: 6| Step: 3
Training loss: 0.30535879731178284
Validation loss: 1.9544055263201396

Epoch: 6| Step: 4
Training loss: 0.32292526960372925
Validation loss: 1.967691163221995

Epoch: 6| Step: 5
Training loss: 0.6141315698623657
Validation loss: 1.989560862382253

Epoch: 6| Step: 6
Training loss: 0.5729799270629883
Validation loss: 1.9841119448343914

Epoch: 6| Step: 7
Training loss: 0.3325611352920532
Validation loss: 2.0006016890207925

Epoch: 6| Step: 8
Training loss: 0.2673105299472809
Validation loss: 1.9788614710172017

Epoch: 6| Step: 9
Training loss: 0.4746590256690979
Validation loss: 1.9639833966890972

Epoch: 6| Step: 10
Training loss: 0.2029186487197876
Validation loss: 1.9561795790990193

Epoch: 6| Step: 11
Training loss: 0.4644022583961487
Validation loss: 1.9400851527849834

Epoch: 6| Step: 12
Training loss: 0.2561739385128021
Validation loss: 1.9113249778747559

Epoch: 6| Step: 13
Training loss: 0.5512807369232178
Validation loss: 1.9655664761861165

Epoch: 254| Step: 0
Training loss: 0.7078896164894104
Validation loss: 1.960513671239217

Epoch: 6| Step: 1
Training loss: 0.23277589678764343
Validation loss: 1.9922316273053486

Epoch: 6| Step: 2
Training loss: 0.42101389169692993
Validation loss: 1.9622901678085327

Epoch: 6| Step: 3
Training loss: 0.2262720763683319
Validation loss: 1.9649751583735149

Epoch: 6| Step: 4
Training loss: 0.3474768102169037
Validation loss: 1.997033675511678

Epoch: 6| Step: 5
Training loss: 0.18331806361675262
Validation loss: 1.9442705114682515

Epoch: 6| Step: 6
Training loss: 0.5082728266716003
Validation loss: 1.993761956691742

Epoch: 6| Step: 7
Training loss: 0.45384955406188965
Validation loss: 1.99286021788915

Epoch: 6| Step: 8
Training loss: 0.4333343207836151
Validation loss: 1.947492202123006

Epoch: 6| Step: 9
Training loss: 0.3811870813369751
Validation loss: 1.9462528626124065

Epoch: 6| Step: 10
Training loss: 0.4356321692466736
Validation loss: 1.9740859866142273

Epoch: 6| Step: 11
Training loss: 0.2194647192955017
Validation loss: 2.0089016954104104

Epoch: 6| Step: 12
Training loss: 0.23120847344398499
Validation loss: 1.9835265278816223

Epoch: 6| Step: 13
Training loss: 0.2568565607070923
Validation loss: 1.959077517191569

Epoch: 255| Step: 0
Training loss: 0.2698171138763428
Validation loss: 1.9768992066383362

Epoch: 6| Step: 1
Training loss: 0.4597577452659607
Validation loss: 1.9688705205917358

Epoch: 6| Step: 2
Training loss: 0.40351229906082153
Validation loss: 1.9565870761871338

Epoch: 6| Step: 3
Training loss: 0.28776270151138306
Validation loss: 1.987050433953603

Epoch: 6| Step: 4
Training loss: 0.3301295340061188
Validation loss: 2.001185099283854

Epoch: 6| Step: 5
Training loss: 0.2727886438369751
Validation loss: 1.9929280281066895

Epoch: 6| Step: 6
Training loss: 0.40632331371307373
Validation loss: 1.9646192789077759

Epoch: 6| Step: 7
Training loss: 0.2675932049751282
Validation loss: 1.9538213809331257

Epoch: 6| Step: 8
Training loss: 0.3739151060581207
Validation loss: 1.9282508889834087

Epoch: 6| Step: 9
Training loss: 0.3439270257949829
Validation loss: 1.9468298554420471

Epoch: 6| Step: 10
Training loss: 0.2883412837982178
Validation loss: 1.9450496435165405

Epoch: 6| Step: 11
Training loss: 0.39348936080932617
Validation loss: 1.9447340567906697

Epoch: 6| Step: 12
Training loss: 1.0935323238372803
Validation loss: 1.9474027156829834

Epoch: 6| Step: 13
Training loss: 0.21847756206989288
Validation loss: 2.0032090743382773

Epoch: 256| Step: 0
Training loss: 0.3364248275756836
Validation loss: 1.9991848667462666

Epoch: 6| Step: 1
Training loss: 0.4256400465965271
Validation loss: 1.944846471150716

Epoch: 6| Step: 2
Training loss: 0.38903623819351196
Validation loss: 1.9626274108886719

Epoch: 6| Step: 3
Training loss: 0.29189562797546387
Validation loss: 1.9799172083536785

Epoch: 6| Step: 4
Training loss: 0.37508609890937805
Validation loss: 1.9598823984464009

Epoch: 6| Step: 5
Training loss: 0.5945407152175903
Validation loss: 1.9373479286829631

Epoch: 6| Step: 6
Training loss: 0.3563441336154938
Validation loss: 1.9647074540456135

Epoch: 6| Step: 7
Training loss: 0.2399546205997467
Validation loss: 1.9549048940340679

Epoch: 6| Step: 8
Training loss: 0.4578753709793091
Validation loss: 1.9391385912895203

Epoch: 6| Step: 9
Training loss: 0.21822607517242432
Validation loss: 1.9859336813290913

Epoch: 6| Step: 10
Training loss: 0.3921341598033905
Validation loss: 1.9495622515678406

Epoch: 6| Step: 11
Training loss: 0.5733855962753296
Validation loss: 2.0075380404790244

Epoch: 6| Step: 12
Training loss: 0.39717304706573486
Validation loss: 1.9942753314971924

Epoch: 6| Step: 13
Training loss: 0.332420289516449
Validation loss: 1.9439629515012105

Epoch: 257| Step: 0
Training loss: 0.4379660487174988
Validation loss: 1.9501318732897441

Epoch: 6| Step: 1
Training loss: 0.4801042973995209
Validation loss: 1.9186289111773174

Epoch: 6| Step: 2
Training loss: 0.8198244571685791
Validation loss: 1.919776161511739

Epoch: 6| Step: 3
Training loss: 0.8156099319458008
Validation loss: 1.9782155950864155

Epoch: 6| Step: 4
Training loss: 0.22362247109413147
Validation loss: 1.9773133198420207

Epoch: 6| Step: 5
Training loss: 0.32463812828063965
Validation loss: 1.9544795751571655

Epoch: 6| Step: 6
Training loss: 0.25301480293273926
Validation loss: 1.9559473196665447

Epoch: 6| Step: 7
Training loss: 0.4214165210723877
Validation loss: 2.034335513909658

Epoch: 6| Step: 8
Training loss: 0.5274276733398438
Validation loss: 2.001199642817179

Epoch: 6| Step: 9
Training loss: 0.5042049288749695
Validation loss: 1.9992409149805705

Epoch: 6| Step: 10
Training loss: 0.424272358417511
Validation loss: 1.9644697705904643

Epoch: 6| Step: 11
Training loss: 0.32825952768325806
Validation loss: 2.0014756321907043

Epoch: 6| Step: 12
Training loss: 0.2935219407081604
Validation loss: 1.9946965376536052

Epoch: 6| Step: 13
Training loss: 0.4014195203781128
Validation loss: 1.9970653454462688

Epoch: 258| Step: 0
Training loss: 1.1913777589797974
Validation loss: 1.9734766284624736

Epoch: 6| Step: 1
Training loss: 0.7040032744407654
Validation loss: 1.9513156215349834

Epoch: 6| Step: 2
Training loss: 0.35577264428138733
Validation loss: 1.9615998069445293

Epoch: 6| Step: 3
Training loss: 0.19325058162212372
Validation loss: 1.9487636089324951

Epoch: 6| Step: 4
Training loss: 0.28911077976226807
Validation loss: 1.9660374919573467

Epoch: 6| Step: 5
Training loss: 0.39325082302093506
Validation loss: 1.9264604449272156

Epoch: 6| Step: 6
Training loss: 0.4868597388267517
Validation loss: 1.9895698229471843

Epoch: 6| Step: 7
Training loss: 0.4420105814933777
Validation loss: 1.946217119693756

Epoch: 6| Step: 8
Training loss: 0.49446967244148254
Validation loss: 1.9773478507995605

Epoch: 6| Step: 9
Training loss: 0.5602784156799316
Validation loss: 1.9690944751103718

Epoch: 6| Step: 10
Training loss: 0.23357440531253815
Validation loss: 1.9935869574546814

Epoch: 6| Step: 11
Training loss: 0.3742621839046478
Validation loss: 1.9629049897193909

Epoch: 6| Step: 12
Training loss: 0.5624443292617798
Validation loss: 1.9554760654767354

Epoch: 6| Step: 13
Training loss: 0.3511299788951874
Validation loss: 1.9636527101198833

Epoch: 259| Step: 0
Training loss: 0.323688268661499
Validation loss: 1.957868218421936

Epoch: 6| Step: 1
Training loss: 0.239328533411026
Validation loss: 1.9679781397183735

Epoch: 6| Step: 2
Training loss: 0.5141797065734863
Validation loss: 1.9868921836217244

Epoch: 6| Step: 3
Training loss: 0.62603360414505
Validation loss: 1.98289289077123

Epoch: 6| Step: 4
Training loss: 0.3143235445022583
Validation loss: 2.006524662176768

Epoch: 6| Step: 5
Training loss: 0.41941338777542114
Validation loss: 1.9434866905212402

Epoch: 6| Step: 6
Training loss: 0.5171546936035156
Validation loss: 1.9709149201711018

Epoch: 6| Step: 7
Training loss: 0.2100675404071808
Validation loss: 1.9825769265492756

Epoch: 6| Step: 8
Training loss: 0.34535306692123413
Validation loss: 1.938322941462199

Epoch: 6| Step: 9
Training loss: 0.4493725001811981
Validation loss: 1.964350938796997

Epoch: 6| Step: 10
Training loss: 0.2101442813873291
Validation loss: 1.976541539033254

Epoch: 6| Step: 11
Training loss: 0.2792067527770996
Validation loss: 1.9508928656578064

Epoch: 6| Step: 12
Training loss: 0.4378514587879181
Validation loss: 1.9591899911562602

Epoch: 6| Step: 13
Training loss: 0.4675282835960388
Validation loss: 1.960143228371938

Epoch: 260| Step: 0
Training loss: 0.34944263100624084
Validation loss: 1.9673011302947998

Epoch: 6| Step: 1
Training loss: 0.42172297835350037
Validation loss: 1.9901316563288372

Epoch: 6| Step: 2
Training loss: 0.11793989688158035
Validation loss: 1.9579599698384602

Epoch: 6| Step: 3
Training loss: 0.3947943449020386
Validation loss: 1.9550513625144958

Epoch: 6| Step: 4
Training loss: 0.4583497941493988
Validation loss: 1.9688130418459575

Epoch: 6| Step: 5
Training loss: 0.20801380276679993
Validation loss: 1.9571073055267334

Epoch: 6| Step: 6
Training loss: 0.3277031183242798
Validation loss: 1.9829519192377727

Epoch: 6| Step: 7
Training loss: 0.27295762300491333
Validation loss: 1.9836072325706482

Epoch: 6| Step: 8
Training loss: 0.1319785714149475
Validation loss: 1.9459501504898071

Epoch: 6| Step: 9
Training loss: 0.7448403239250183
Validation loss: 1.9721909165382385

Epoch: 6| Step: 10
Training loss: 0.3453541398048401
Validation loss: 1.9544070959091187

Epoch: 6| Step: 11
Training loss: 0.5510500073432922
Validation loss: 2.017542004585266

Epoch: 6| Step: 12
Training loss: 0.37929147481918335
Validation loss: 2.00245201587677

Epoch: 6| Step: 13
Training loss: 0.5680920481681824
Validation loss: 1.9536874294281006

Epoch: 261| Step: 0
Training loss: 0.4864012598991394
Validation loss: 1.9681993126869202

Epoch: 6| Step: 1
Training loss: 0.4196228086948395
Validation loss: 2.0046902894973755

Epoch: 6| Step: 2
Training loss: 0.22903484106063843
Validation loss: 1.983956019083659

Epoch: 6| Step: 3
Training loss: 0.5118454694747925
Validation loss: 2.0054847399393716

Epoch: 6| Step: 4
Training loss: 0.5249011516571045
Validation loss: 1.919769525527954

Epoch: 6| Step: 5
Training loss: 0.2609472870826721
Validation loss: 1.9616260727246602

Epoch: 6| Step: 6
Training loss: 0.5524030923843384
Validation loss: 1.956789255142212

Epoch: 6| Step: 7
Training loss: 0.2393450140953064
Validation loss: 1.9541311264038086

Epoch: 6| Step: 8
Training loss: 0.8219077587127686
Validation loss: 1.9629177848498027

Epoch: 6| Step: 9
Training loss: 0.30099761486053467
Validation loss: 1.9852342804272969

Epoch: 6| Step: 10
Training loss: 0.2173077017068863
Validation loss: 1.9292442202568054

Epoch: 6| Step: 11
Training loss: 0.18741969764232635
Validation loss: 1.9684843222300212

Epoch: 6| Step: 12
Training loss: 0.36316776275634766
Validation loss: 1.962240219116211

Epoch: 6| Step: 13
Training loss: 0.1457602083683014
Validation loss: 2.0181153416633606

Epoch: 262| Step: 0
Training loss: 0.650579035282135
Validation loss: 1.9841049313545227

Epoch: 6| Step: 1
Training loss: 0.20002391934394836
Validation loss: 1.9465690056482952

Epoch: 6| Step: 2
Training loss: 0.5726508498191833
Validation loss: 1.973341425259908

Epoch: 6| Step: 3
Training loss: 0.3371787667274475
Validation loss: 1.9939485788345337

Epoch: 6| Step: 4
Training loss: 0.310524046421051
Validation loss: 1.9745204250017803

Epoch: 6| Step: 5
Training loss: 0.3031168580055237
Validation loss: 1.9880078434944153

Epoch: 6| Step: 6
Training loss: 0.3654975891113281
Validation loss: 2.024926702181498

Epoch: 6| Step: 7
Training loss: 0.28939446806907654
Validation loss: 1.984232246875763

Epoch: 6| Step: 8
Training loss: 0.29608017206192017
Validation loss: 1.9516719579696655

Epoch: 6| Step: 9
Training loss: 0.4006998538970947
Validation loss: 2.027510166168213

Epoch: 6| Step: 10
Training loss: 0.4997571110725403
Validation loss: 1.9346728722254436

Epoch: 6| Step: 11
Training loss: 0.411795973777771
Validation loss: 1.952038566271464

Epoch: 6| Step: 12
Training loss: 0.41536349058151245
Validation loss: 2.00247053305308

Epoch: 6| Step: 13
Training loss: 0.26224786043167114
Validation loss: 1.95444522301356

Epoch: 263| Step: 0
Training loss: 0.44912463426589966
Validation loss: 1.9459577401479085

Epoch: 6| Step: 1
Training loss: 0.27508971095085144
Validation loss: 1.9574328263600667

Epoch: 6| Step: 2
Training loss: 0.28466954827308655
Validation loss: 1.963697910308838

Epoch: 6| Step: 3
Training loss: 0.36354130506515503
Validation loss: 1.9371823072433472

Epoch: 6| Step: 4
Training loss: 0.44514864683151245
Validation loss: 1.9480209350585938

Epoch: 6| Step: 5
Training loss: 0.5037941336631775
Validation loss: 1.9605000217755635

Epoch: 6| Step: 6
Training loss: 0.4582913815975189
Validation loss: 1.9585073788960774

Epoch: 6| Step: 7
Training loss: 0.44879332184791565
Validation loss: 1.9210231304168701

Epoch: 6| Step: 8
Training loss: 0.27586546540260315
Validation loss: 1.9266518751780193

Epoch: 6| Step: 9
Training loss: 0.4082132577896118
Validation loss: 1.957340121269226

Epoch: 6| Step: 10
Training loss: 0.410453736782074
Validation loss: 1.9421813090642293

Epoch: 6| Step: 11
Training loss: 0.7084211111068726
Validation loss: 1.9592672387758892

Epoch: 6| Step: 12
Training loss: 0.4971058964729309
Validation loss: 1.976816753546397

Epoch: 6| Step: 13
Training loss: 0.36415553092956543
Validation loss: 1.9148672819137573

Epoch: 264| Step: 0
Training loss: 0.35268980264663696
Validation loss: 1.9596582452456157

Epoch: 6| Step: 1
Training loss: 0.839745044708252
Validation loss: 1.940129816532135

Epoch: 6| Step: 2
Training loss: 0.350960910320282
Validation loss: 1.9670920570691426

Epoch: 6| Step: 3
Training loss: 0.4288094639778137
Validation loss: 1.952260156472524

Epoch: 6| Step: 4
Training loss: 0.46940553188323975
Validation loss: 1.9206655820210774

Epoch: 6| Step: 5
Training loss: 0.17109955847263336
Validation loss: 1.9561436971028645

Epoch: 6| Step: 6
Training loss: 0.6115976572036743
Validation loss: 1.9781134525934856

Epoch: 6| Step: 7
Training loss: 0.4140653908252716
Validation loss: 1.9366467197736104

Epoch: 6| Step: 8
Training loss: 0.3927046060562134
Validation loss: 1.9904879728953044

Epoch: 6| Step: 9
Training loss: 0.38598155975341797
Validation loss: 1.9724838534990947

Epoch: 6| Step: 10
Training loss: 0.3412665128707886
Validation loss: 1.9935483535130818

Epoch: 6| Step: 11
Training loss: 0.3369329571723938
Validation loss: 1.9495267073313396

Epoch: 6| Step: 12
Training loss: 0.3318027853965759
Validation loss: 1.973588724931081

Epoch: 6| Step: 13
Training loss: 0.17774054408073425
Validation loss: 1.9743103981018066

Epoch: 265| Step: 0
Training loss: 0.3188764452934265
Validation loss: 1.9791241089502971

Epoch: 6| Step: 1
Training loss: 0.4455219805240631
Validation loss: 1.9609538714090984

Epoch: 6| Step: 2
Training loss: 0.6246572136878967
Validation loss: 1.9744633237520854

Epoch: 6| Step: 3
Training loss: 0.3375592827796936
Validation loss: 1.9365580081939697

Epoch: 6| Step: 4
Training loss: 0.33474427461624146
Validation loss: 1.9806996583938599

Epoch: 6| Step: 5
Training loss: 0.3616534471511841
Validation loss: 1.9785012404123943

Epoch: 6| Step: 6
Training loss: 0.15531215071678162
Validation loss: 1.98329093058904

Epoch: 6| Step: 7
Training loss: 0.6736766695976257
Validation loss: 1.9686914086341858

Epoch: 6| Step: 8
Training loss: 0.7193148732185364
Validation loss: 1.9823035597801208

Epoch: 6| Step: 9
Training loss: 0.1841375082731247
Validation loss: 1.9844992955525715

Epoch: 6| Step: 10
Training loss: 0.27678707242012024
Validation loss: 1.9654528896013896

Epoch: 6| Step: 11
Training loss: 0.30874013900756836
Validation loss: 1.9487345417340596

Epoch: 6| Step: 12
Training loss: 0.2683650553226471
Validation loss: 1.9581877986590068

Epoch: 6| Step: 13
Training loss: 0.2016383558511734
Validation loss: 1.9860775073369343

Epoch: 266| Step: 0
Training loss: 0.39617639780044556
Validation loss: 1.9658974806467693

Epoch: 6| Step: 1
Training loss: 0.19561068713665009
Validation loss: 1.967938979466756

Epoch: 6| Step: 2
Training loss: 0.26731812953948975
Validation loss: 2.0113808314005532

Epoch: 6| Step: 3
Training loss: 0.3553495705127716
Validation loss: 1.9697683652242024

Epoch: 6| Step: 4
Training loss: 0.17589840292930603
Validation loss: 2.007094085216522

Epoch: 6| Step: 5
Training loss: 0.46317604184150696
Validation loss: 1.9591694076855977

Epoch: 6| Step: 6
Training loss: 0.8560839295387268
Validation loss: 1.9849942525227864

Epoch: 6| Step: 7
Training loss: 0.46582362055778503
Validation loss: 1.9864099025726318

Epoch: 6| Step: 8
Training loss: 0.30337101221084595
Validation loss: 1.9765585859616597

Epoch: 6| Step: 9
Training loss: 0.35099953413009644
Validation loss: 1.9622199734052022

Epoch: 6| Step: 10
Training loss: 0.4813862144947052
Validation loss: 1.972741703192393

Epoch: 6| Step: 11
Training loss: 0.2225736677646637
Validation loss: 1.9639526009559631

Epoch: 6| Step: 12
Training loss: 0.2439761757850647
Validation loss: 1.9759042660395305

Epoch: 6| Step: 13
Training loss: 0.41510769724845886
Validation loss: 1.9750596682230632

Epoch: 267| Step: 0
Training loss: 0.3512738347053528
Validation loss: 1.9677606026331584

Epoch: 6| Step: 1
Training loss: 0.5858415365219116
Validation loss: 1.9494430621465046

Epoch: 6| Step: 2
Training loss: 0.768353283405304
Validation loss: 1.9550743500391643

Epoch: 6| Step: 3
Training loss: 0.34280043840408325
Validation loss: 1.9724413553873699

Epoch: 6| Step: 4
Training loss: 0.40050703287124634
Validation loss: 1.936539649963379

Epoch: 6| Step: 5
Training loss: 0.2953723073005676
Validation loss: 1.9280263781547546

Epoch: 6| Step: 6
Training loss: 0.41217732429504395
Validation loss: 1.952331304550171

Epoch: 6| Step: 7
Training loss: 0.21572554111480713
Validation loss: 1.966831107934316

Epoch: 6| Step: 8
Training loss: 0.7855311036109924
Validation loss: 1.9030648867289226

Epoch: 6| Step: 9
Training loss: 0.17955444753170013
Validation loss: 1.9508045315742493

Epoch: 6| Step: 10
Training loss: 0.2828229069709778
Validation loss: 1.9758554100990295

Epoch: 6| Step: 11
Training loss: 0.263006329536438
Validation loss: 1.9828797578811646

Epoch: 6| Step: 12
Training loss: 0.16301725804805756
Validation loss: 1.9469116926193237

Epoch: 6| Step: 13
Training loss: 0.26427263021469116
Validation loss: 1.9731014569600422

Epoch: 268| Step: 0
Training loss: 0.23063015937805176
Validation loss: 1.9722495675086975

Epoch: 6| Step: 1
Training loss: 0.20857325196266174
Validation loss: 1.9933366378148396

Epoch: 6| Step: 2
Training loss: 0.7602696418762207
Validation loss: 2.00098047653834

Epoch: 6| Step: 3
Training loss: 0.4271290898323059
Validation loss: 1.9913674394289653

Epoch: 6| Step: 4
Training loss: 0.4391302466392517
Validation loss: 1.9765422940254211

Epoch: 6| Step: 5
Training loss: 0.2752693295478821
Validation loss: 1.9513981938362122

Epoch: 6| Step: 6
Training loss: 0.39844706654548645
Validation loss: 1.9805516401926677

Epoch: 6| Step: 7
Training loss: 0.24254682660102844
Validation loss: 1.970300277074178

Epoch: 6| Step: 8
Training loss: 0.39374756813049316
Validation loss: 1.986853539943695

Epoch: 6| Step: 9
Training loss: 0.2952326536178589
Validation loss: 2.0003549257914224

Epoch: 6| Step: 10
Training loss: 0.32246166467666626
Validation loss: 1.9942151308059692

Epoch: 6| Step: 11
Training loss: 0.1985560953617096
Validation loss: 1.9768009583155315

Epoch: 6| Step: 12
Training loss: 0.31147441267967224
Validation loss: 1.982659598191579

Epoch: 6| Step: 13
Training loss: 0.3564554750919342
Validation loss: 1.9968112508455913

Epoch: 269| Step: 0
Training loss: 0.43844467401504517
Validation loss: 1.9511548280715942

Epoch: 6| Step: 1
Training loss: 0.1676042526960373
Validation loss: 1.9811129967371623

Epoch: 6| Step: 2
Training loss: 0.22698071599006653
Validation loss: 1.9666903416315715

Epoch: 6| Step: 3
Training loss: 0.4130358099937439
Validation loss: 1.913597563902537

Epoch: 6| Step: 4
Training loss: 0.47291600704193115
Validation loss: 1.9799543817838032

Epoch: 6| Step: 5
Training loss: 0.26770123839378357
Validation loss: 1.956941028436025

Epoch: 6| Step: 6
Training loss: 0.21270421147346497
Validation loss: 1.973001480102539

Epoch: 6| Step: 7
Training loss: 0.21802984178066254
Validation loss: 1.960177739461263

Epoch: 6| Step: 8
Training loss: 0.6096165180206299
Validation loss: 1.9553022782007854

Epoch: 6| Step: 9
Training loss: 0.5173118710517883
Validation loss: 1.928771475950877

Epoch: 6| Step: 10
Training loss: 0.4479568600654602
Validation loss: 1.9728459119796753

Epoch: 6| Step: 11
Training loss: 0.37717899680137634
Validation loss: 1.9849768280982971

Epoch: 6| Step: 12
Training loss: 0.4138462543487549
Validation loss: 1.953048288822174

Epoch: 6| Step: 13
Training loss: 0.21659736335277557
Validation loss: 1.9682610034942627

Epoch: 270| Step: 0
Training loss: 0.17093634605407715
Validation loss: 1.9616990486780803

Epoch: 6| Step: 1
Training loss: 0.19048985838890076
Validation loss: 1.9606972138086955

Epoch: 6| Step: 2
Training loss: 0.37506887316703796
Validation loss: 1.969861110051473

Epoch: 6| Step: 3
Training loss: 0.28931400179862976
Validation loss: 1.9536019563674927

Epoch: 6| Step: 4
Training loss: 0.6793851852416992
Validation loss: 1.9657085537910461

Epoch: 6| Step: 5
Training loss: 0.21300041675567627
Validation loss: 1.965079168478648

Epoch: 6| Step: 6
Training loss: 0.6998434066772461
Validation loss: 1.9694564938545227

Epoch: 6| Step: 7
Training loss: 0.347133994102478
Validation loss: 1.9558689594268799

Epoch: 6| Step: 8
Training loss: 0.26222217082977295
Validation loss: 2.0031855503718057

Epoch: 6| Step: 9
Training loss: 0.31306183338165283
Validation loss: 1.9623161554336548

Epoch: 6| Step: 10
Training loss: 0.2603883445262909
Validation loss: 1.970389723777771

Epoch: 6| Step: 11
Training loss: 0.3383135497570038
Validation loss: 1.9491211970647175

Epoch: 6| Step: 12
Training loss: 0.4496385157108307
Validation loss: 1.963157852490743

Epoch: 6| Step: 13
Training loss: 0.3052886128425598
Validation loss: 1.9777917663256328

Epoch: 271| Step: 0
Training loss: 0.49159669876098633
Validation loss: 1.953380048274994

Epoch: 6| Step: 1
Training loss: 0.2246200442314148
Validation loss: 1.9904394348462422

Epoch: 6| Step: 2
Training loss: 0.5842736959457397
Validation loss: 1.987599531809489

Epoch: 6| Step: 3
Training loss: 0.3052886128425598
Validation loss: 1.9895172516504924

Epoch: 6| Step: 4
Training loss: 0.5890044569969177
Validation loss: 2.000750422477722

Epoch: 6| Step: 5
Training loss: 0.30008000135421753
Validation loss: 2.012370685736338

Epoch: 6| Step: 6
Training loss: 0.25837165117263794
Validation loss: 1.9630237619082134

Epoch: 6| Step: 7
Training loss: 0.2756960093975067
Validation loss: 1.983955939610799

Epoch: 6| Step: 8
Training loss: 0.2817615270614624
Validation loss: 2.0081206560134888

Epoch: 6| Step: 9
Training loss: 0.36744165420532227
Validation loss: 1.9594141244888306

Epoch: 6| Step: 10
Training loss: 0.4285202622413635
Validation loss: 1.9691299200057983

Epoch: 6| Step: 11
Training loss: 0.3316948413848877
Validation loss: 1.9901131987571716

Epoch: 6| Step: 12
Training loss: 0.6592431664466858
Validation loss: 1.9670414527257283

Epoch: 6| Step: 13
Training loss: 0.20353937149047852
Validation loss: 1.9278197685877483

Epoch: 272| Step: 0
Training loss: 0.34384018182754517
Validation loss: 1.9514461755752563

Epoch: 6| Step: 1
Training loss: 0.3226163387298584
Validation loss: 1.9665791193644206

Epoch: 6| Step: 2
Training loss: 0.3346552848815918
Validation loss: 1.96377299229304

Epoch: 6| Step: 3
Training loss: 0.332278311252594
Validation loss: 2.002402106920878

Epoch: 6| Step: 4
Training loss: 0.19470292329788208
Validation loss: 1.9467339317003887

Epoch: 6| Step: 5
Training loss: 0.46274009346961975
Validation loss: 1.9596208532651265

Epoch: 6| Step: 6
Training loss: 0.16923347115516663
Validation loss: 1.9806952476501465

Epoch: 6| Step: 7
Training loss: 0.2900424599647522
Validation loss: 1.9488694469134014

Epoch: 6| Step: 8
Training loss: 0.2400655448436737
Validation loss: 1.99154531955719

Epoch: 6| Step: 9
Training loss: 0.3794478476047516
Validation loss: 1.9304745594660442

Epoch: 6| Step: 10
Training loss: 0.5294932723045349
Validation loss: 1.9286176959673564

Epoch: 6| Step: 11
Training loss: 0.44359707832336426
Validation loss: 1.9368840257326763

Epoch: 6| Step: 12
Training loss: 0.5484552979469299
Validation loss: 1.9559292197227478

Epoch: 6| Step: 13
Training loss: 0.6610047817230225
Validation loss: 1.9500043789545696

Epoch: 273| Step: 0
Training loss: 0.4510118067264557
Validation loss: 2.000138282775879

Epoch: 6| Step: 1
Training loss: 0.17829301953315735
Validation loss: 1.9672734538714092

Epoch: 6| Step: 2
Training loss: 0.44363582134246826
Validation loss: 1.9667268594106038

Epoch: 6| Step: 3
Training loss: 0.26888298988342285
Validation loss: 1.9450087149937947

Epoch: 6| Step: 4
Training loss: 0.5285683274269104
Validation loss: 2.001341720422109

Epoch: 6| Step: 5
Training loss: 0.2719026207923889
Validation loss: 1.9870784481366475

Epoch: 6| Step: 6
Training loss: 0.33678489923477173
Validation loss: 1.9796533584594727

Epoch: 6| Step: 7
Training loss: 0.27939605712890625
Validation loss: 1.9746918280919392

Epoch: 6| Step: 8
Training loss: 0.2853517234325409
Validation loss: 1.9737667441368103

Epoch: 6| Step: 9
Training loss: 0.39748114347457886
Validation loss: 1.9885935584704082

Epoch: 6| Step: 10
Training loss: 0.5850825309753418
Validation loss: 1.9903445442517598

Epoch: 6| Step: 11
Training loss: 0.4065935015678406
Validation loss: 2.01565553744634

Epoch: 6| Step: 12
Training loss: 0.5427467823028564
Validation loss: 1.9439695874849956

Epoch: 6| Step: 13
Training loss: 0.19623900949954987
Validation loss: 1.9715055028597515

Epoch: 274| Step: 0
Training loss: 0.5932904481887817
Validation loss: 1.9882750113805134

Epoch: 6| Step: 1
Training loss: 0.29339101910591125
Validation loss: 1.9611324866612752

Epoch: 6| Step: 2
Training loss: 0.23569847643375397
Validation loss: 1.9586970408757527

Epoch: 6| Step: 3
Training loss: 0.18146075308322906
Validation loss: 1.9657059907913208

Epoch: 6| Step: 4
Training loss: 0.7197073698043823
Validation loss: 1.988016168276469

Epoch: 6| Step: 5
Training loss: 0.25852423906326294
Validation loss: 1.9466525514920552

Epoch: 6| Step: 6
Training loss: 0.3189277946949005
Validation loss: 1.9867014487584431

Epoch: 6| Step: 7
Training loss: 0.14252176880836487
Validation loss: 2.0169675946235657

Epoch: 6| Step: 8
Training loss: 0.3287374973297119
Validation loss: 1.9794406294822693

Epoch: 6| Step: 9
Training loss: 0.1908000409603119
Validation loss: 2.0150301257769265

Epoch: 6| Step: 10
Training loss: 0.5679260492324829
Validation loss: 1.964486539363861

Epoch: 6| Step: 11
Training loss: 0.2979072332382202
Validation loss: 2.000200569629669

Epoch: 6| Step: 12
Training loss: 0.3341435492038727
Validation loss: 1.9397032459576924

Epoch: 6| Step: 13
Training loss: 0.4322274625301361
Validation loss: 1.954568088054657

Epoch: 275| Step: 0
Training loss: 0.26685988903045654
Validation loss: 1.9513825178146362

Epoch: 6| Step: 1
Training loss: 0.2794817090034485
Validation loss: 1.992006500562032

Epoch: 6| Step: 2
Training loss: 0.26882511377334595
Validation loss: 1.9743890364964802

Epoch: 6| Step: 3
Training loss: 0.3675764203071594
Validation loss: 1.9680033723513286

Epoch: 6| Step: 4
Training loss: 0.4690433442592621
Validation loss: 1.9628567894299824

Epoch: 6| Step: 5
Training loss: 0.672887921333313
Validation loss: 1.9654865662256877

Epoch: 6| Step: 6
Training loss: 0.25654834508895874
Validation loss: 1.9753485918045044

Epoch: 6| Step: 7
Training loss: 0.2694321870803833
Validation loss: 1.9919604659080505

Epoch: 6| Step: 8
Training loss: 0.5324174165725708
Validation loss: 1.9516491095225017

Epoch: 6| Step: 9
Training loss: 0.351012259721756
Validation loss: 1.9553050994873047

Epoch: 6| Step: 10
Training loss: 0.20431968569755554
Validation loss: 1.9530398050944011

Epoch: 6| Step: 11
Training loss: 0.23824653029441833
Validation loss: 1.9763871431350708

Epoch: 6| Step: 12
Training loss: 0.24797917902469635
Validation loss: 1.9812778234481812

Epoch: 6| Step: 13
Training loss: 0.5033518671989441
Validation loss: 1.96577783425649

Epoch: 276| Step: 0
Training loss: 0.8854374289512634
Validation loss: 1.9572604695955913

Epoch: 6| Step: 1
Training loss: 0.33399584889411926
Validation loss: 2.021815021832784

Epoch: 6| Step: 2
Training loss: 0.5070525407791138
Validation loss: 1.94647083679835

Epoch: 6| Step: 3
Training loss: 0.14187060296535492
Validation loss: 1.9500625332196553

Epoch: 6| Step: 4
Training loss: 0.1676684021949768
Validation loss: 1.9699281851450603

Epoch: 6| Step: 5
Training loss: 0.30875423550605774
Validation loss: 1.9869239528973897

Epoch: 6| Step: 6
Training loss: 0.30559012293815613
Validation loss: 1.9641972780227661

Epoch: 6| Step: 7
Training loss: 0.3550150394439697
Validation loss: 1.9614702264467876

Epoch: 6| Step: 8
Training loss: 0.3134170174598694
Validation loss: 2.006852706273397

Epoch: 6| Step: 9
Training loss: 0.29152679443359375
Validation loss: 1.9906957546869914

Epoch: 6| Step: 10
Training loss: 0.20522980391979218
Validation loss: 1.9889668424924214

Epoch: 6| Step: 11
Training loss: 0.4189598560333252
Validation loss: 1.9535391132036846

Epoch: 6| Step: 12
Training loss: 0.1822490245103836
Validation loss: 2.010058502356211

Epoch: 6| Step: 13
Training loss: 0.3136007785797119
Validation loss: 1.985422670841217

Epoch: 277| Step: 0
Training loss: 0.40738898515701294
Validation loss: 1.9688877662022908

Epoch: 6| Step: 1
Training loss: 0.41598817706108093
Validation loss: 1.9772025148073833

Epoch: 6| Step: 2
Training loss: 0.2379549741744995
Validation loss: 1.9988836844762166

Epoch: 6| Step: 3
Training loss: 0.25997820496559143
Validation loss: 1.9853278795878093

Epoch: 6| Step: 4
Training loss: 0.5509123802185059
Validation loss: 1.9786054094632466

Epoch: 6| Step: 5
Training loss: 0.21554088592529297
Validation loss: 1.9922821323076885

Epoch: 6| Step: 6
Training loss: 0.48639222979545593
Validation loss: 1.9921083251635234

Epoch: 6| Step: 7
Training loss: 0.1977095901966095
Validation loss: 1.9483399192492168

Epoch: 6| Step: 8
Training loss: 0.2875699996948242
Validation loss: 2.0363760391871133

Epoch: 6| Step: 9
Training loss: 0.4328436255455017
Validation loss: 1.9863870938618977

Epoch: 6| Step: 10
Training loss: 0.3232095539569855
Validation loss: 1.994464119275411

Epoch: 6| Step: 11
Training loss: 0.7787700891494751
Validation loss: 2.0040000279744468

Epoch: 6| Step: 12
Training loss: 0.21086075901985168
Validation loss: 1.9702334801355998

Epoch: 6| Step: 13
Training loss: 0.23839738965034485
Validation loss: 1.989859660466512

Epoch: 278| Step: 0
Training loss: 0.30339673161506653
Validation loss: 1.959310273329417

Epoch: 6| Step: 1
Training loss: 0.2883071303367615
Validation loss: 1.9863351186116536

Epoch: 6| Step: 2
Training loss: 0.2461281269788742
Validation loss: 1.969943344593048

Epoch: 6| Step: 3
Training loss: 0.20084607601165771
Validation loss: 1.9826222658157349

Epoch: 6| Step: 4
Training loss: 0.2649453580379486
Validation loss: 1.960213541984558

Epoch: 6| Step: 5
Training loss: 0.27187222242355347
Validation loss: 1.9808831612269084

Epoch: 6| Step: 6
Training loss: 0.3013008236885071
Validation loss: 2.016030232111613

Epoch: 6| Step: 7
Training loss: 0.438218891620636
Validation loss: 1.9667578339576721

Epoch: 6| Step: 8
Training loss: 0.6854761242866516
Validation loss: 2.004608988761902

Epoch: 6| Step: 9
Training loss: 0.16201722621917725
Validation loss: 1.9473933378855388

Epoch: 6| Step: 10
Training loss: 0.24874350428581238
Validation loss: 1.9431697130203247

Epoch: 6| Step: 11
Training loss: 0.3178693652153015
Validation loss: 1.9760339458783467

Epoch: 6| Step: 12
Training loss: 0.666884183883667
Validation loss: 1.9626245697339375

Epoch: 6| Step: 13
Training loss: 0.28089413046836853
Validation loss: 1.973215381304423

Epoch: 279| Step: 0
Training loss: 0.2271062582731247
Validation loss: 1.9351370334625244

Epoch: 6| Step: 1
Training loss: 0.46337950229644775
Validation loss: 1.9502496321996052

Epoch: 6| Step: 2
Training loss: 0.5118074417114258
Validation loss: 1.9630759159723918

Epoch: 6| Step: 3
Training loss: 0.3739447593688965
Validation loss: 1.979820986588796

Epoch: 6| Step: 4
Training loss: 0.19796723127365112
Validation loss: 1.9834612409273784

Epoch: 6| Step: 5
Training loss: 0.3715919256210327
Validation loss: 1.9750592907269795

Epoch: 6| Step: 6
Training loss: 0.3268733620643616
Validation loss: 1.9867257277170818

Epoch: 6| Step: 7
Training loss: 0.4447025656700134
Validation loss: 1.9811587929725647

Epoch: 6| Step: 8
Training loss: 0.3310598134994507
Validation loss: 1.9952977299690247

Epoch: 6| Step: 9
Training loss: 0.32799312472343445
Validation loss: 1.9930546085039775

Epoch: 6| Step: 10
Training loss: 0.24577075242996216
Validation loss: 1.960488537947337

Epoch: 6| Step: 11
Training loss: 0.2913197875022888
Validation loss: 1.992337961991628

Epoch: 6| Step: 12
Training loss: 0.2452039122581482
Validation loss: 1.9360594948132832

Epoch: 6| Step: 13
Training loss: 0.647668182849884
Validation loss: 1.97230197985967

Epoch: 280| Step: 0
Training loss: 0.24628837406635284
Validation loss: 1.9565634727478027

Epoch: 6| Step: 1
Training loss: 0.4957105815410614
Validation loss: 1.987001895904541

Epoch: 6| Step: 2
Training loss: 0.3305151164531708
Validation loss: 1.9697364171346028

Epoch: 6| Step: 3
Training loss: 0.32397598028182983
Validation loss: 1.9490911960601807

Epoch: 6| Step: 4
Training loss: 0.7832242846488953
Validation loss: 1.957428018252055

Epoch: 6| Step: 5
Training loss: 0.21428900957107544
Validation loss: 1.9576042493184407

Epoch: 6| Step: 6
Training loss: 0.26169657707214355
Validation loss: 1.9907718300819397

Epoch: 6| Step: 7
Training loss: 0.31552642583847046
Validation loss: 1.9734995365142822

Epoch: 6| Step: 8
Training loss: 0.4141818583011627
Validation loss: 1.9579002459843953

Epoch: 6| Step: 9
Training loss: 0.48476269841194153
Validation loss: 1.9779291152954102

Epoch: 6| Step: 10
Training loss: 0.33208519220352173
Validation loss: 1.946462631225586

Epoch: 6| Step: 11
Training loss: 0.4441365599632263
Validation loss: 1.983908216158549

Epoch: 6| Step: 12
Training loss: 0.30272284150123596
Validation loss: 1.9741722345352173

Epoch: 6| Step: 13
Training loss: 0.36230599880218506
Validation loss: 1.9637632171312969

Epoch: 281| Step: 0
Training loss: 0.7235441207885742
Validation loss: 1.971005658308665

Epoch: 6| Step: 1
Training loss: 0.31336650252342224
Validation loss: 1.9638762474060059

Epoch: 6| Step: 2
Training loss: 0.45781266689300537
Validation loss: 1.9696853359540303

Epoch: 6| Step: 3
Training loss: 0.32827305793762207
Validation loss: 1.9371193647384644

Epoch: 6| Step: 4
Training loss: 0.20763567090034485
Validation loss: 2.0074944694836936

Epoch: 6| Step: 5
Training loss: 0.3079242408275604
Validation loss: 1.9364762504895527

Epoch: 6| Step: 6
Training loss: 0.4495234489440918
Validation loss: 1.986150582631429

Epoch: 6| Step: 7
Training loss: 0.5211091041564941
Validation loss: 1.9691483577092488

Epoch: 6| Step: 8
Training loss: 0.34225982427597046
Validation loss: 1.9623947143554688

Epoch: 6| Step: 9
Training loss: 0.36800235509872437
Validation loss: 1.9973978797594707

Epoch: 6| Step: 10
Training loss: 0.1342325508594513
Validation loss: 1.9567501346270244

Epoch: 6| Step: 11
Training loss: 0.1582401692867279
Validation loss: 1.966273804505666

Epoch: 6| Step: 12
Training loss: 0.5033562779426575
Validation loss: 1.9719386100769043

Epoch: 6| Step: 13
Training loss: 0.5331994891166687
Validation loss: 1.9768618146578472

Epoch: 282| Step: 0
Training loss: 1.039843201637268
Validation loss: 1.9439695874849956

Epoch: 6| Step: 1
Training loss: 0.36795806884765625
Validation loss: 1.955489456653595

Epoch: 6| Step: 2
Training loss: 0.23058073222637177
Validation loss: 2.0005027651786804

Epoch: 6| Step: 3
Training loss: 0.3613153398036957
Validation loss: 1.9444442391395569

Epoch: 6| Step: 4
Training loss: 0.484818696975708
Validation loss: 1.9608592788378398

Epoch: 6| Step: 5
Training loss: 0.33510181307792664
Validation loss: 1.997627039750417

Epoch: 6| Step: 6
Training loss: 0.27562886476516724
Validation loss: 1.977457622687022

Epoch: 6| Step: 7
Training loss: 0.37811434268951416
Validation loss: 1.9904311299324036

Epoch: 6| Step: 8
Training loss: 0.40911349654197693
Validation loss: 2.0331488450368247

Epoch: 6| Step: 9
Training loss: 0.3973480761051178
Validation loss: 1.9718840718269348

Epoch: 6| Step: 10
Training loss: 0.2426902949810028
Validation loss: 1.966438353061676

Epoch: 6| Step: 11
Training loss: 0.26424092054367065
Validation loss: 2.006293257077535

Epoch: 6| Step: 12
Training loss: 0.21941658854484558
Validation loss: 1.9753832817077637

Epoch: 6| Step: 13
Training loss: 0.31459012627601624
Validation loss: 1.9793288509051006

Epoch: 283| Step: 0
Training loss: 0.18928152322769165
Validation loss: 2.006839712460836

Epoch: 6| Step: 1
Training loss: 0.31977522373199463
Validation loss: 1.9827860395113628

Epoch: 6| Step: 2
Training loss: 0.20200781524181366
Validation loss: 1.96143505970637

Epoch: 6| Step: 3
Training loss: 0.4947810471057892
Validation loss: 1.9723397890726726

Epoch: 6| Step: 4
Training loss: 0.592982828617096
Validation loss: 2.0017414887746177

Epoch: 6| Step: 5
Training loss: 0.5098782777786255
Validation loss: 1.9575338164965312

Epoch: 6| Step: 6
Training loss: 0.44145745038986206
Validation loss: 2.0144062638282776

Epoch: 6| Step: 7
Training loss: 0.2600211501121521
Validation loss: 1.9748008052508037

Epoch: 6| Step: 8
Training loss: 0.20913928747177124
Validation loss: 1.9895066221555073

Epoch: 6| Step: 9
Training loss: 0.4428563714027405
Validation loss: 1.9487595955530803

Epoch: 6| Step: 10
Training loss: 0.2455790936946869
Validation loss: 1.9632946252822876

Epoch: 6| Step: 11
Training loss: 0.29820147156715393
Validation loss: 1.9653780261675518

Epoch: 6| Step: 12
Training loss: 0.2850535213947296
Validation loss: 1.9651185274124146

Epoch: 6| Step: 13
Training loss: 0.17175263166427612
Validation loss: 2.0034857193628945

Epoch: 284| Step: 0
Training loss: 0.2596639394760132
Validation loss: 1.9768171509106953

Epoch: 6| Step: 1
Training loss: 0.5691965818405151
Validation loss: 2.0071017344792685

Epoch: 6| Step: 2
Training loss: 0.30640709400177
Validation loss: 1.9339337746302288

Epoch: 6| Step: 3
Training loss: 0.36996936798095703
Validation loss: 1.9912482500076294

Epoch: 6| Step: 4
Training loss: 0.38456130027770996
Validation loss: 1.9998486836751301

Epoch: 6| Step: 5
Training loss: 0.3344818353652954
Validation loss: 1.932516614596049

Epoch: 6| Step: 6
Training loss: 0.24562376737594604
Validation loss: 1.9821599125862122

Epoch: 6| Step: 7
Training loss: 0.3172118365764618
Validation loss: 1.9883719682693481

Epoch: 6| Step: 8
Training loss: 0.18422645330429077
Validation loss: 2.0139562487602234

Epoch: 6| Step: 9
Training loss: 0.4482022821903229
Validation loss: 1.9840965867042542

Epoch: 6| Step: 10
Training loss: 0.5026078224182129
Validation loss: 1.9879894256591797

Epoch: 6| Step: 11
Training loss: 0.21588988602161407
Validation loss: 2.028899669647217

Epoch: 6| Step: 12
Training loss: 0.4484201967716217
Validation loss: 1.9781879583994548

Epoch: 6| Step: 13
Training loss: 0.3196565508842468
Validation loss: 1.9533166488011677

Epoch: 285| Step: 0
Training loss: 0.8020130395889282
Validation loss: 1.9392624696095784

Epoch: 6| Step: 1
Training loss: 0.12900137901306152
Validation loss: 1.9696510434150696

Epoch: 6| Step: 2
Training loss: 0.3099571764469147
Validation loss: 1.9445107181866963

Epoch: 6| Step: 3
Training loss: 0.3895253539085388
Validation loss: 1.9761743545532227

Epoch: 6| Step: 4
Training loss: 0.39999014139175415
Validation loss: 2.0175856153170266

Epoch: 6| Step: 5
Training loss: 0.30529868602752686
Validation loss: 2.0031267205874124

Epoch: 6| Step: 6
Training loss: 0.22318202257156372
Validation loss: 1.9595866203308105

Epoch: 6| Step: 7
Training loss: 0.3650217354297638
Validation loss: 2.0154261589050293

Epoch: 6| Step: 8
Training loss: 0.4004799723625183
Validation loss: 1.9775886336962383

Epoch: 6| Step: 9
Training loss: 0.24053378403186798
Validation loss: 1.9755346576372783

Epoch: 6| Step: 10
Training loss: 0.42823752760887146
Validation loss: 1.986902157465617

Epoch: 6| Step: 11
Training loss: 0.22918125987052917
Validation loss: 1.9644625981648762

Epoch: 6| Step: 12
Training loss: 0.3519464433193207
Validation loss: 1.990335484345754

Epoch: 6| Step: 13
Training loss: 0.1268884539604187
Validation loss: 1.9663368264834087

Epoch: 286| Step: 0
Training loss: 0.3768753409385681
Validation loss: 1.9809940258661907

Epoch: 6| Step: 1
Training loss: 0.40755757689476013
Validation loss: 2.0072256326675415

Epoch: 6| Step: 2
Training loss: 0.2457507848739624
Validation loss: 1.9657843311627705

Epoch: 6| Step: 3
Training loss: 0.26036232709884644
Validation loss: 1.966800610224406

Epoch: 6| Step: 4
Training loss: 0.31069785356521606
Validation loss: 1.973781446615855

Epoch: 6| Step: 5
Training loss: 0.19160355627536774
Validation loss: 1.9680948654810588

Epoch: 6| Step: 6
Training loss: 0.3999324142932892
Validation loss: 1.9781569838523865

Epoch: 6| Step: 7
Training loss: 0.8199945092201233
Validation loss: 1.988740622997284

Epoch: 6| Step: 8
Training loss: 0.31968867778778076
Validation loss: 1.9465693434079487

Epoch: 6| Step: 9
Training loss: 0.39197736978530884
Validation loss: 1.9690395792325337

Epoch: 6| Step: 10
Training loss: 0.21412967145442963
Validation loss: 1.9494070410728455

Epoch: 6| Step: 11
Training loss: 0.34394392371177673
Validation loss: 1.9504874348640442

Epoch: 6| Step: 12
Training loss: 0.28963702917099
Validation loss: 1.975188970565796

Epoch: 6| Step: 13
Training loss: 0.21678099036216736
Validation loss: 1.9587941567103069

Epoch: 287| Step: 0
Training loss: 0.7602002024650574
Validation loss: 1.9647685885429382

Epoch: 6| Step: 1
Training loss: 0.30928564071655273
Validation loss: 1.9800235827763875

Epoch: 6| Step: 2
Training loss: 0.39750099182128906
Validation loss: 1.91961274544398

Epoch: 6| Step: 3
Training loss: 0.18586763739585876
Validation loss: 1.9908571044603984

Epoch: 6| Step: 4
Training loss: 0.3987869620323181
Validation loss: 1.9570237596829732

Epoch: 6| Step: 5
Training loss: 0.35545670986175537
Validation loss: 1.9478070735931396

Epoch: 6| Step: 6
Training loss: 0.2768492102622986
Validation loss: 1.9392423629760742

Epoch: 6| Step: 7
Training loss: 0.29483842849731445
Validation loss: 1.9643115003903706

Epoch: 6| Step: 8
Training loss: 0.31269872188568115
Validation loss: 1.9670635263125102

Epoch: 6| Step: 9
Training loss: 0.2848120629787445
Validation loss: 1.9363490740458171

Epoch: 6| Step: 10
Training loss: 0.28298041224479675
Validation loss: 1.9261090954144795

Epoch: 6| Step: 11
Training loss: 0.30192506313323975
Validation loss: 1.9871743122736614

Epoch: 6| Step: 12
Training loss: 0.2889028489589691
Validation loss: 1.9611120621363323

Epoch: 6| Step: 13
Training loss: 0.21988385915756226
Validation loss: 1.9623690247535706

Epoch: 288| Step: 0
Training loss: 0.2830405831336975
Validation loss: 1.933553695678711

Epoch: 6| Step: 1
Training loss: 0.1979791522026062
Validation loss: 1.9935202797253926

Epoch: 6| Step: 2
Training loss: 0.3744658827781677
Validation loss: 1.9885459740956624

Epoch: 6| Step: 3
Training loss: 0.6466203927993774
Validation loss: 1.979109287261963

Epoch: 6| Step: 4
Training loss: 0.27161937952041626
Validation loss: 1.9665173490842183

Epoch: 6| Step: 5
Training loss: 0.19895203411579132
Validation loss: 2.001128852367401

Epoch: 6| Step: 6
Training loss: 0.3500429391860962
Validation loss: 1.9662572145462036

Epoch: 6| Step: 7
Training loss: 0.2986711859703064
Validation loss: 1.9599040150642395

Epoch: 6| Step: 8
Training loss: 0.6616479754447937
Validation loss: 1.9667173624038696

Epoch: 6| Step: 9
Training loss: 0.3210451900959015
Validation loss: 1.9908759792645772

Epoch: 6| Step: 10
Training loss: 0.4576888680458069
Validation loss: 1.9740220308303833

Epoch: 6| Step: 11
Training loss: 0.28268682956695557
Validation loss: 1.9948572119077046

Epoch: 6| Step: 12
Training loss: 0.36885571479797363
Validation loss: 1.9832666516304016

Epoch: 6| Step: 13
Training loss: 0.28582656383514404
Validation loss: 2.0044698317845664

Epoch: 289| Step: 0
Training loss: 0.34213656187057495
Validation loss: 2.053203264872233

Epoch: 6| Step: 1
Training loss: 0.6430166959762573
Validation loss: 2.0021496415138245

Epoch: 6| Step: 2
Training loss: 0.4077005386352539
Validation loss: 1.9822700222333272

Epoch: 6| Step: 3
Training loss: 0.2605655789375305
Validation loss: 1.9943901499112446

Epoch: 6| Step: 4
Training loss: 0.26054447889328003
Validation loss: 1.9689050316810608

Epoch: 6| Step: 5
Training loss: 0.5618166327476501
Validation loss: 1.9875651001930237

Epoch: 6| Step: 6
Training loss: 0.3602161407470703
Validation loss: 2.0023684899012246

Epoch: 6| Step: 7
Training loss: 0.2634009122848511
Validation loss: 1.9850865205128987

Epoch: 6| Step: 8
Training loss: 0.32930225133895874
Validation loss: 1.972922960917155

Epoch: 6| Step: 9
Training loss: 0.5004479289054871
Validation loss: 2.024399995803833

Epoch: 6| Step: 10
Training loss: 0.23791931569576263
Validation loss: 2.01094255844752

Epoch: 6| Step: 11
Training loss: 0.2865898013114929
Validation loss: 1.9960652589797974

Epoch: 6| Step: 12
Training loss: 0.4094098210334778
Validation loss: 1.9820866386095684

Epoch: 6| Step: 13
Training loss: 0.27030664682388306
Validation loss: 2.0706316033999124

Epoch: 290| Step: 0
Training loss: 0.3561086058616638
Validation loss: 1.9791701436042786

Epoch: 6| Step: 1
Training loss: 0.2277010679244995
Validation loss: 1.9740815957387288

Epoch: 6| Step: 2
Training loss: 0.19796958565711975
Validation loss: 1.9903887907663982

Epoch: 6| Step: 3
Training loss: 0.22055354714393616
Validation loss: 1.986112912495931

Epoch: 6| Step: 4
Training loss: 0.29588595032691956
Validation loss: 1.9896884163220723

Epoch: 6| Step: 5
Training loss: 0.4069787263870239
Validation loss: 2.000063975652059

Epoch: 6| Step: 6
Training loss: 0.3217101991176605
Validation loss: 1.9835558931032817

Epoch: 6| Step: 7
Training loss: 0.9755228757858276
Validation loss: 1.9919889569282532

Epoch: 6| Step: 8
Training loss: 0.2734740972518921
Validation loss: 2.0271059473355613

Epoch: 6| Step: 9
Training loss: 0.2602745294570923
Validation loss: 1.976529061794281

Epoch: 6| Step: 10
Training loss: 0.2217567265033722
Validation loss: 1.9709721803665161

Epoch: 6| Step: 11
Training loss: 0.2753220796585083
Validation loss: 1.981234351793925

Epoch: 6| Step: 12
Training loss: 0.39613887667655945
Validation loss: 1.9317456881205242

Epoch: 6| Step: 13
Training loss: 0.4969024658203125
Validation loss: 1.9517707824707031

Epoch: 291| Step: 0
Training loss: 0.23613247275352478
Validation loss: 1.944732387860616

Epoch: 6| Step: 1
Training loss: 0.23416393995285034
Validation loss: 2.0116347074508667

Epoch: 6| Step: 2
Training loss: 0.4032871127128601
Validation loss: 1.971659243106842

Epoch: 6| Step: 3
Training loss: 0.2164156436920166
Validation loss: 1.9713421662648518

Epoch: 6| Step: 4
Training loss: 0.36714255809783936
Validation loss: 1.9964954853057861

Epoch: 6| Step: 5
Training loss: 0.34820470213890076
Validation loss: 1.9846468965212505

Epoch: 6| Step: 6
Training loss: 0.6406639814376831
Validation loss: 1.9727931420008342

Epoch: 6| Step: 7
Training loss: 0.39151275157928467
Validation loss: 1.9467955629030864

Epoch: 6| Step: 8
Training loss: 0.48985791206359863
Validation loss: 1.9684146444002788

Epoch: 6| Step: 9
Training loss: 0.35957279801368713
Validation loss: 1.978752076625824

Epoch: 6| Step: 10
Training loss: 0.23237018287181854
Validation loss: 1.9670930703481038

Epoch: 6| Step: 11
Training loss: 0.199143186211586
Validation loss: 1.9817055662473042

Epoch: 6| Step: 12
Training loss: 0.3865097165107727
Validation loss: 1.9712451100349426

Epoch: 6| Step: 13
Training loss: 0.2304844856262207
Validation loss: 1.9837698539098103

Epoch: 292| Step: 0
Training loss: 0.5773899555206299
Validation loss: 1.9985297123591106

Epoch: 6| Step: 1
Training loss: 0.3952280879020691
Validation loss: 1.9572375218073528

Epoch: 6| Step: 2
Training loss: 0.3594653606414795
Validation loss: 2.0050485531489053

Epoch: 6| Step: 3
Training loss: 0.28458327054977417
Validation loss: 1.9663052161534627

Epoch: 6| Step: 4
Training loss: 0.35734519362449646
Validation loss: 2.0354347229003906

Epoch: 6| Step: 5
Training loss: 0.2501198649406433
Validation loss: 1.96977702776591

Epoch: 6| Step: 6
Training loss: 0.43791812658309937
Validation loss: 2.010888457298279

Epoch: 6| Step: 7
Training loss: 0.21005389094352722
Validation loss: 1.9527701338132222

Epoch: 6| Step: 8
Training loss: 0.33173853158950806
Validation loss: 1.9845197598139446

Epoch: 6| Step: 9
Training loss: 0.3875489830970764
Validation loss: 1.992253800233205

Epoch: 6| Step: 10
Training loss: 0.28141501545906067
Validation loss: 1.9766681989034016

Epoch: 6| Step: 11
Training loss: 0.2135499268770218
Validation loss: 1.9435293674468994

Epoch: 6| Step: 12
Training loss: 0.3577907681465149
Validation loss: 1.9391490817070007

Epoch: 6| Step: 13
Training loss: 0.20494763553142548
Validation loss: 2.0118265748023987

Epoch: 293| Step: 0
Training loss: 0.35004276037216187
Validation loss: 1.95208074649175

Epoch: 6| Step: 1
Training loss: 0.354428768157959
Validation loss: 1.9633343021074932

Epoch: 6| Step: 2
Training loss: 0.371135950088501
Validation loss: 1.9843645691871643

Epoch: 6| Step: 3
Training loss: 0.4444701075553894
Validation loss: 2.0232516328493753

Epoch: 6| Step: 4
Training loss: 0.20593923330307007
Validation loss: 1.9933147430419922

Epoch: 6| Step: 5
Training loss: 0.5630391240119934
Validation loss: 1.999651590983073

Epoch: 6| Step: 6
Training loss: 0.11172617971897125
Validation loss: 1.9522311290105183

Epoch: 6| Step: 7
Training loss: 0.23633314669132233
Validation loss: 2.0101821621259055

Epoch: 6| Step: 8
Training loss: 0.33951520919799805
Validation loss: 1.9623219172159831

Epoch: 6| Step: 9
Training loss: 0.32756873965263367
Validation loss: 2.0099451541900635

Epoch: 6| Step: 10
Training loss: 0.340457022190094
Validation loss: 1.974863330523173

Epoch: 6| Step: 11
Training loss: 0.3343520164489746
Validation loss: 1.97935817639033

Epoch: 6| Step: 12
Training loss: 0.19438281655311584
Validation loss: 1.980804165204366

Epoch: 6| Step: 13
Training loss: 0.3823660612106323
Validation loss: 1.9754973649978638

Epoch: 294| Step: 0
Training loss: 0.2604407072067261
Validation loss: 1.9954841136932373

Epoch: 6| Step: 1
Training loss: 0.4269517660140991
Validation loss: 1.9890591104825337

Epoch: 6| Step: 2
Training loss: 0.20461507141590118
Validation loss: 1.9992056886355083

Epoch: 6| Step: 3
Training loss: 0.5770144462585449
Validation loss: 1.9869274497032166

Epoch: 6| Step: 4
Training loss: 0.21564428508281708
Validation loss: 2.0043492118517556

Epoch: 6| Step: 5
Training loss: 0.20262372493743896
Validation loss: 1.9400448203086853

Epoch: 6| Step: 6
Training loss: 0.4374600648880005
Validation loss: 1.9832576115926106

Epoch: 6| Step: 7
Training loss: 0.2881249785423279
Validation loss: 1.980779508749644

Epoch: 6| Step: 8
Training loss: 0.33111849427223206
Validation loss: 1.9953781962394714

Epoch: 6| Step: 9
Training loss: 0.25311458110809326
Validation loss: 1.9520117044448853

Epoch: 6| Step: 10
Training loss: 0.3892955183982849
Validation loss: 1.9886488517125447

Epoch: 6| Step: 11
Training loss: 0.319134920835495
Validation loss: 1.9825738469759624

Epoch: 6| Step: 12
Training loss: 0.5469481945037842
Validation loss: 1.9761608242988586

Epoch: 6| Step: 13
Training loss: 0.2546771168708801
Validation loss: 1.9836541811625164

Epoch: 295| Step: 0
Training loss: 0.2543788552284241
Validation loss: 1.9509670734405518

Epoch: 6| Step: 1
Training loss: 0.15784329175949097
Validation loss: 1.9507165948549907

Epoch: 6| Step: 2
Training loss: 0.39549776911735535
Validation loss: 1.990815023581187

Epoch: 6| Step: 3
Training loss: 0.6344361901283264
Validation loss: 1.9776594440142314

Epoch: 6| Step: 4
Training loss: 0.27393531799316406
Validation loss: 1.97723788022995

Epoch: 6| Step: 5
Training loss: 0.31974026560783386
Validation loss: 2.0003625750541687

Epoch: 6| Step: 6
Training loss: 0.2629988193511963
Validation loss: 1.9696082671483357

Epoch: 6| Step: 7
Training loss: 0.29328805208206177
Validation loss: 1.9124406377474468

Epoch: 6| Step: 8
Training loss: 0.9061200022697449
Validation loss: 2.0072214802106223

Epoch: 6| Step: 9
Training loss: 0.27410733699798584
Validation loss: 1.958325445652008

Epoch: 6| Step: 10
Training loss: 0.18355634808540344
Validation loss: 1.9958011309305828

Epoch: 6| Step: 11
Training loss: 0.18827931582927704
Validation loss: 1.9260025819142659

Epoch: 6| Step: 12
Training loss: 0.4460137188434601
Validation loss: 1.9771071871121724

Epoch: 6| Step: 13
Training loss: 0.3254489004611969
Validation loss: 1.9819403489430745

Epoch: 296| Step: 0
Training loss: 0.46852511167526245
Validation loss: 1.970684826374054

Epoch: 6| Step: 1
Training loss: 0.2856816351413727
Validation loss: 1.9416988889376323

Epoch: 6| Step: 2
Training loss: 0.15750931203365326
Validation loss: 1.9805786609649658

Epoch: 6| Step: 3
Training loss: 0.256448894739151
Validation loss: 2.0145086447397866

Epoch: 6| Step: 4
Training loss: 0.7206449508666992
Validation loss: 1.994486927986145

Epoch: 6| Step: 5
Training loss: 0.323186993598938
Validation loss: 2.0070080359776816

Epoch: 6| Step: 6
Training loss: 0.2869173586368561
Validation loss: 1.998601992925008

Epoch: 6| Step: 7
Training loss: 0.32070398330688477
Validation loss: 1.9967466394106548

Epoch: 6| Step: 8
Training loss: 0.35062557458877563
Validation loss: 1.9752032955487568

Epoch: 6| Step: 9
Training loss: 0.5184317827224731
Validation loss: 1.9636866847674053

Epoch: 6| Step: 10
Training loss: 0.2703820466995239
Validation loss: 1.9356094598770142

Epoch: 6| Step: 11
Training loss: 0.14773643016815186
Validation loss: 1.9817888140678406

Epoch: 6| Step: 12
Training loss: 0.40684938430786133
Validation loss: 1.9777116775512695

Epoch: 6| Step: 13
Training loss: 0.24757060408592224
Validation loss: 1.9331844051678975

Epoch: 297| Step: 0
Training loss: 0.31165891885757446
Validation loss: 1.9739104111989338

Epoch: 6| Step: 1
Training loss: 0.27417147159576416
Validation loss: 1.9680453340212505

Epoch: 6| Step: 2
Training loss: 0.32927262783050537
Validation loss: 2.0247833331425986

Epoch: 6| Step: 3
Training loss: 0.31175553798675537
Validation loss: 1.9642256100972493

Epoch: 6| Step: 4
Training loss: 0.44205525517463684
Validation loss: 2.016723334789276

Epoch: 6| Step: 5
Training loss: 0.25965723395347595
Validation loss: 1.984752853711446

Epoch: 6| Step: 6
Training loss: 0.6559276580810547
Validation loss: 1.983275016148885

Epoch: 6| Step: 7
Training loss: 0.3592692017555237
Validation loss: 1.9704067707061768

Epoch: 6| Step: 8
Training loss: 0.4340251684188843
Validation loss: 2.0144752264022827

Epoch: 6| Step: 9
Training loss: 0.5099809765815735
Validation loss: 2.0130927562713623

Epoch: 6| Step: 10
Training loss: 0.2568907141685486
Validation loss: 2.007260779539744

Epoch: 6| Step: 11
Training loss: 0.3995944857597351
Validation loss: 1.9720409909884136

Epoch: 6| Step: 12
Training loss: 0.27457714080810547
Validation loss: 1.9767348766326904

Epoch: 6| Step: 13
Training loss: 0.25340479612350464
Validation loss: 1.9858240882555644

Epoch: 298| Step: 0
Training loss: 0.3162142336368561
Validation loss: 1.982443928718567

Epoch: 6| Step: 1
Training loss: 0.5663334131240845
Validation loss: 1.9733647108078003

Epoch: 6| Step: 2
Training loss: 0.3461548686027527
Validation loss: 1.9857078393300374

Epoch: 6| Step: 3
Training loss: 0.2741268277168274
Validation loss: 2.0216266910235086

Epoch: 6| Step: 4
Training loss: 0.22491943836212158
Validation loss: 1.9372557600339253

Epoch: 6| Step: 5
Training loss: 0.256109356880188
Validation loss: 1.9965575337409973

Epoch: 6| Step: 6
Training loss: 0.24520479142665863
Validation loss: 1.9387340148289998

Epoch: 6| Step: 7
Training loss: 0.6136646270751953
Validation loss: 1.960942010084788

Epoch: 6| Step: 8
Training loss: 0.22974203526973724
Validation loss: 1.9883591334025066

Epoch: 6| Step: 9
Training loss: 0.2623181939125061
Validation loss: 1.9721858898798625

Epoch: 6| Step: 10
Training loss: 0.3038305342197418
Validation loss: 1.9334579507509868

Epoch: 6| Step: 11
Training loss: 0.32018959522247314
Validation loss: 1.9791902303695679

Epoch: 6| Step: 12
Training loss: 0.2315085232257843
Validation loss: 2.0018340945243835

Epoch: 6| Step: 13
Training loss: 0.3493400514125824
Validation loss: 1.9556170503298442

Epoch: 299| Step: 0
Training loss: 0.6502677202224731
Validation loss: 1.9873921275138855

Epoch: 6| Step: 1
Training loss: 0.23137733340263367
Validation loss: 1.9730330506960552

Epoch: 6| Step: 2
Training loss: 0.3367253839969635
Validation loss: 1.9315646489461262

Epoch: 6| Step: 3
Training loss: 0.15987631678581238
Validation loss: 1.940029005209605

Epoch: 6| Step: 4
Training loss: 0.47067368030548096
Validation loss: 1.9520878394444783

Epoch: 6| Step: 5
Training loss: 0.4904855489730835
Validation loss: 1.9652894536654155

Epoch: 6| Step: 6
Training loss: 0.41334348917007446
Validation loss: 1.9455499251683552

Epoch: 6| Step: 7
Training loss: 0.1866784244775772
Validation loss: 1.9723415970802307

Epoch: 6| Step: 8
Training loss: 0.31006553769111633
Validation loss: 1.969721833864848

Epoch: 6| Step: 9
Training loss: 0.2989180088043213
Validation loss: 1.9604536890983582

Epoch: 6| Step: 10
Training loss: 0.2739095091819763
Validation loss: 1.9467117389043171

Epoch: 6| Step: 11
Training loss: 0.18982522189617157
Validation loss: 1.9839616020520527

Epoch: 6| Step: 12
Training loss: 0.3575051724910736
Validation loss: 1.9610334833463032

Epoch: 6| Step: 13
Training loss: 0.31211477518081665
Validation loss: 1.988974928855896

Epoch: 300| Step: 0
Training loss: 0.24835917353630066
Validation loss: 1.9893139402071636

Epoch: 6| Step: 1
Training loss: 0.2742545008659363
Validation loss: 1.9775577187538147

Epoch: 6| Step: 2
Training loss: 0.2847123444080353
Validation loss: 1.9388004342714946

Epoch: 6| Step: 3
Training loss: 0.23403838276863098
Validation loss: 1.9721138874689739

Epoch: 6| Step: 4
Training loss: 0.2295336127281189
Validation loss: 1.9573713541030884

Epoch: 6| Step: 5
Training loss: 0.2095787078142166
Validation loss: 1.980534017086029

Epoch: 6| Step: 6
Training loss: 0.37745946645736694
Validation loss: 1.9715701738993328

Epoch: 6| Step: 7
Training loss: 0.3623240292072296
Validation loss: 1.9413071672121684

Epoch: 6| Step: 8
Training loss: 0.6476129293441772
Validation loss: 1.9929969708124797

Epoch: 6| Step: 9
Training loss: 0.3670938313007355
Validation loss: 2.001842498779297

Epoch: 6| Step: 10
Training loss: 0.3185173273086548
Validation loss: 1.9913179278373718

Epoch: 6| Step: 11
Training loss: 0.6458711624145508
Validation loss: 1.9986317952473958

Epoch: 6| Step: 12
Training loss: 0.2885048985481262
Validation loss: 1.963369607925415

Epoch: 6| Step: 13
Training loss: 0.389524906873703
Validation loss: 1.9563469290733337

Epoch: 301| Step: 0
Training loss: 0.22568722069263458
Validation loss: 1.9818809827168782

Epoch: 6| Step: 1
Training loss: 0.2413266897201538
Validation loss: 1.9648135900497437

Epoch: 6| Step: 2
Training loss: 0.29233723878860474
Validation loss: 1.9413433074951172

Epoch: 6| Step: 3
Training loss: 0.24816539883613586
Validation loss: 1.9654224713643391

Epoch: 6| Step: 4
Training loss: 0.33605706691741943
Validation loss: 1.9829017718633015

Epoch: 6| Step: 5
Training loss: 0.5652145147323608
Validation loss: 1.94515722990036

Epoch: 6| Step: 6
Training loss: 0.35014182329177856
Validation loss: 1.9871199329694111

Epoch: 6| Step: 7
Training loss: 0.24250805377960205
Validation loss: 1.917190432548523

Epoch: 6| Step: 8
Training loss: 0.22068198025226593
Validation loss: 1.9752638737360637

Epoch: 6| Step: 9
Training loss: 0.2816181778907776
Validation loss: 2.0215946634610495

Epoch: 6| Step: 10
Training loss: 0.4630403518676758
Validation loss: 1.986834168434143

Epoch: 6| Step: 11
Training loss: 0.6152562499046326
Validation loss: 1.9583082993825276

Epoch: 6| Step: 12
Training loss: 0.2020288109779358
Validation loss: 1.9716222087542217

Epoch: 6| Step: 13
Training loss: 0.2798924446105957
Validation loss: 2.0166539748509726

Epoch: 302| Step: 0
Training loss: 0.14828307926654816
Validation loss: 1.9819968342781067

Epoch: 6| Step: 1
Training loss: 0.32047125697135925
Validation loss: 1.993126372496287

Epoch: 6| Step: 2
Training loss: 0.33529937267303467
Validation loss: 1.9813302556673686

Epoch: 6| Step: 3
Training loss: 0.35022011399269104
Validation loss: 1.9789663155873616

Epoch: 6| Step: 4
Training loss: 0.29203516244888306
Validation loss: 2.004616399606069

Epoch: 6| Step: 5
Training loss: 0.7782169580459595
Validation loss: 1.9746631582578023

Epoch: 6| Step: 6
Training loss: 0.2870338559150696
Validation loss: 1.9918031692504883

Epoch: 6| Step: 7
Training loss: 0.19646519422531128
Validation loss: 1.9669042627016704

Epoch: 6| Step: 8
Training loss: 0.46231138706207275
Validation loss: 1.9859854181607564

Epoch: 6| Step: 9
Training loss: 0.30126431584358215
Validation loss: 1.974376638730367

Epoch: 6| Step: 10
Training loss: 0.20089422166347504
Validation loss: 1.9290405909220378

Epoch: 6| Step: 11
Training loss: 0.24847504496574402
Validation loss: 1.9608667691548665

Epoch: 6| Step: 12
Training loss: 0.3787915110588074
Validation loss: 1.9675282835960388

Epoch: 6| Step: 13
Training loss: 0.32591766119003296
Validation loss: 1.968174119790395

Epoch: 303| Step: 0
Training loss: 0.3893546164035797
Validation loss: 1.9865305225054424

Epoch: 6| Step: 1
Training loss: 0.39844560623168945
Validation loss: 1.9958209991455078

Epoch: 6| Step: 2
Training loss: 0.1841752529144287
Validation loss: 1.9641292889912922

Epoch: 6| Step: 3
Training loss: 0.403942346572876
Validation loss: 1.995243509610494

Epoch: 6| Step: 4
Training loss: 0.38030388951301575
Validation loss: 1.9756368199984233

Epoch: 6| Step: 5
Training loss: 0.18114067614078522
Validation loss: 1.9764249324798584

Epoch: 6| Step: 6
Training loss: 0.2845674157142639
Validation loss: 2.006538172562917

Epoch: 6| Step: 7
Training loss: 0.3932749330997467
Validation loss: 1.9802203178405762

Epoch: 6| Step: 8
Training loss: 0.3867547810077667
Validation loss: 1.9538380702336628

Epoch: 6| Step: 9
Training loss: 0.7253321409225464
Validation loss: 1.9500680565834045

Epoch: 6| Step: 10
Training loss: 0.22493836283683777
Validation loss: 1.9883702198664348

Epoch: 6| Step: 11
Training loss: 0.24616098403930664
Validation loss: 1.9826549291610718

Epoch: 6| Step: 12
Training loss: 0.2388818860054016
Validation loss: 1.998644193013509

Epoch: 6| Step: 13
Training loss: 0.2615402936935425
Validation loss: 2.0089285175005593

Epoch: 304| Step: 0
Training loss: 0.4760027825832367
Validation loss: 2.01611328125

Epoch: 6| Step: 1
Training loss: 0.16858699917793274
Validation loss: 1.9974431196848552

Epoch: 6| Step: 2
Training loss: 0.24102547764778137
Validation loss: 1.9636800289154053

Epoch: 6| Step: 3
Training loss: 0.22852621972560883
Validation loss: 1.9867725173632305

Epoch: 6| Step: 4
Training loss: 0.3337005376815796
Validation loss: 1.962843080361684

Epoch: 6| Step: 5
Training loss: 0.35936760902404785
Validation loss: 2.0073176423708596

Epoch: 6| Step: 6
Training loss: 0.5609779953956604
Validation loss: 2.0117059548695884

Epoch: 6| Step: 7
Training loss: 0.15249425172805786
Validation loss: 1.941732148329417

Epoch: 6| Step: 8
Training loss: 0.24251487851142883
Validation loss: 1.973016659418742

Epoch: 6| Step: 9
Training loss: 0.3373761475086212
Validation loss: 1.9791962603727977

Epoch: 6| Step: 10
Training loss: 0.18580438196659088
Validation loss: 1.960614760716756

Epoch: 6| Step: 11
Training loss: 0.28499656915664673
Validation loss: 1.9905161261558533

Epoch: 6| Step: 12
Training loss: 0.41221463680267334
Validation loss: 1.9631357590357463

Epoch: 6| Step: 13
Training loss: 0.2079041600227356
Validation loss: 2.0080231626828513

Epoch: 305| Step: 0
Training loss: 0.6794437170028687
Validation loss: 1.9971446792284648

Epoch: 6| Step: 1
Training loss: 0.28965479135513306
Validation loss: 1.9788063565889995

Epoch: 6| Step: 2
Training loss: 0.5551550388336182
Validation loss: 1.9991765817006428

Epoch: 6| Step: 3
Training loss: 0.20358511805534363
Validation loss: 1.975587526957194

Epoch: 6| Step: 4
Training loss: 0.16406750679016113
Validation loss: 1.9861697554588318

Epoch: 6| Step: 5
Training loss: 0.3870258331298828
Validation loss: 1.9811447858810425

Epoch: 6| Step: 6
Training loss: 0.24018681049346924
Validation loss: 1.999499003092448

Epoch: 6| Step: 7
Training loss: 0.22085672616958618
Validation loss: 1.9833938678105671

Epoch: 6| Step: 8
Training loss: 0.19978979229927063
Validation loss: 1.9438137809435527

Epoch: 6| Step: 9
Training loss: 0.26296043395996094
Validation loss: 1.9991233547528584

Epoch: 6| Step: 10
Training loss: 0.22834491729736328
Validation loss: 2.000697433948517

Epoch: 6| Step: 11
Training loss: 0.23273232579231262
Validation loss: 1.9607756932576497

Epoch: 6| Step: 12
Training loss: 0.41613924503326416
Validation loss: 2.0020876129468284

Epoch: 6| Step: 13
Training loss: 0.4430975615978241
Validation loss: 1.9904224673906963

Epoch: 306| Step: 0
Training loss: 0.39463600516319275
Validation loss: 1.9974606831868489

Epoch: 6| Step: 1
Training loss: 0.3861192464828491
Validation loss: 2.0367698868115744

Epoch: 6| Step: 2
Training loss: 0.4279395341873169
Validation loss: 2.0379814306894937

Epoch: 6| Step: 3
Training loss: 0.5333009958267212
Validation loss: 2.03343003988266

Epoch: 6| Step: 4
Training loss: 0.30501091480255127
Validation loss: 2.013093948364258

Epoch: 6| Step: 5
Training loss: 0.45621389150619507
Validation loss: 1.983155091603597

Epoch: 6| Step: 6
Training loss: 0.45901352167129517
Validation loss: 1.9966115554173787

Epoch: 6| Step: 7
Training loss: 0.8261849880218506
Validation loss: 2.000246206919352

Epoch: 6| Step: 8
Training loss: 0.3345344662666321
Validation loss: 1.9773736000061035

Epoch: 6| Step: 9
Training loss: 0.2452370971441269
Validation loss: 2.031451721986135

Epoch: 6| Step: 10
Training loss: 0.1989174634218216
Validation loss: 2.058613101641337

Epoch: 6| Step: 11
Training loss: 0.3751351833343506
Validation loss: 1.9867634773254395

Epoch: 6| Step: 12
Training loss: 0.322488009929657
Validation loss: 1.9645482699076335

Epoch: 6| Step: 13
Training loss: 0.26067355275154114
Validation loss: 2.013278623421987

Epoch: 307| Step: 0
Training loss: 0.19610008597373962
Validation loss: 1.9539272983868916

Epoch: 6| Step: 1
Training loss: 0.3231430947780609
Validation loss: 1.9632045825322468

Epoch: 6| Step: 2
Training loss: 0.4118213951587677
Validation loss: 1.9789726535479228

Epoch: 6| Step: 3
Training loss: 0.19944778084754944
Validation loss: 1.9968219995498657

Epoch: 6| Step: 4
Training loss: 0.5527647137641907
Validation loss: 1.9642808834711711

Epoch: 6| Step: 5
Training loss: 0.20730054378509521
Validation loss: 1.9985972046852112

Epoch: 6| Step: 6
Training loss: 0.5775397419929504
Validation loss: 1.9409014383951824

Epoch: 6| Step: 7
Training loss: 0.21895577013492584
Validation loss: 1.9925832947095234

Epoch: 6| Step: 8
Training loss: 0.2608635723590851
Validation loss: 1.9967214663823445

Epoch: 6| Step: 9
Training loss: 0.31833380460739136
Validation loss: 1.9759957790374756

Epoch: 6| Step: 10
Training loss: 0.35963132977485657
Validation loss: 1.9819214940071106

Epoch: 6| Step: 11
Training loss: 0.2447211891412735
Validation loss: 2.0196922421455383

Epoch: 6| Step: 12
Training loss: 0.27785375714302063
Validation loss: 1.9693662921587627

Epoch: 6| Step: 13
Training loss: 0.541145920753479
Validation loss: 1.9926641583442688

Epoch: 308| Step: 0
Training loss: 0.5895100831985474
Validation loss: 1.9601416786511738

Epoch: 6| Step: 1
Training loss: 0.344235897064209
Validation loss: 1.9874348839124043

Epoch: 6| Step: 2
Training loss: 0.19922731816768646
Validation loss: 1.9686080416043599

Epoch: 6| Step: 3
Training loss: 0.320659339427948
Validation loss: 1.953005810578664

Epoch: 6| Step: 4
Training loss: 0.2155764102935791
Validation loss: 1.9721698363622029

Epoch: 6| Step: 5
Training loss: 0.31463494896888733
Validation loss: 1.9711787899335225

Epoch: 6| Step: 6
Training loss: 0.3475182056427002
Validation loss: 1.9648630420366924

Epoch: 6| Step: 7
Training loss: 0.4657838046550751
Validation loss: 2.011370221773783

Epoch: 6| Step: 8
Training loss: 0.21252942085266113
Validation loss: 2.0278552571932473

Epoch: 6| Step: 9
Training loss: 0.29667580127716064
Validation loss: 1.9483673771222432

Epoch: 6| Step: 10
Training loss: 0.3479151725769043
Validation loss: 1.963270644346873

Epoch: 6| Step: 11
Training loss: 0.2150190770626068
Validation loss: 1.995291809240977

Epoch: 6| Step: 12
Training loss: 0.1903834342956543
Validation loss: 1.9720606406529744

Epoch: 6| Step: 13
Training loss: 0.4579962491989136
Validation loss: 1.9746841192245483

Epoch: 309| Step: 0
Training loss: 0.1780683398246765
Validation loss: 1.9339221517244976

Epoch: 6| Step: 1
Training loss: 0.285706102848053
Validation loss: 1.9366806149482727

Epoch: 6| Step: 2
Training loss: 0.2844310402870178
Validation loss: 1.986438810825348

Epoch: 6| Step: 3
Training loss: 0.4422686696052551
Validation loss: 1.971793254216512

Epoch: 6| Step: 4
Training loss: 0.23920181393623352
Validation loss: 1.946262796719869

Epoch: 6| Step: 5
Training loss: 0.8932416439056396
Validation loss: 1.9343188802401226

Epoch: 6| Step: 6
Training loss: 0.34389591217041016
Validation loss: 1.9736786882082622

Epoch: 6| Step: 7
Training loss: 0.38146156072616577
Validation loss: 1.9689195950826008

Epoch: 6| Step: 8
Training loss: 0.32363462448120117
Validation loss: 1.9562085270881653

Epoch: 6| Step: 9
Training loss: 0.33085697889328003
Validation loss: 1.976313591003418

Epoch: 6| Step: 10
Training loss: 0.32166898250579834
Validation loss: 1.946849803129832

Epoch: 6| Step: 11
Training loss: 0.3204638361930847
Validation loss: 1.9823916951815288

Epoch: 6| Step: 12
Training loss: 0.2708348035812378
Validation loss: 1.968704601128896

Epoch: 6| Step: 13
Training loss: 0.41232815384864807
Validation loss: 1.972397228082021

Epoch: 310| Step: 0
Training loss: 0.4111052453517914
Validation loss: 1.9595935742060344

Epoch: 6| Step: 1
Training loss: 0.374539315700531
Validation loss: 1.9708941380182903

Epoch: 6| Step: 2
Training loss: 0.18585342168807983
Validation loss: 1.97362353404363

Epoch: 6| Step: 3
Training loss: 0.24295032024383545
Validation loss: 1.9524642030398052

Epoch: 6| Step: 4
Training loss: 0.18573588132858276
Validation loss: 1.974130908648173

Epoch: 6| Step: 5
Training loss: 0.19761160016059875
Validation loss: 1.9832191665967305

Epoch: 6| Step: 6
Training loss: 0.36744022369384766
Validation loss: 1.9493163625399272

Epoch: 6| Step: 7
Training loss: 0.25692218542099
Validation loss: 1.958866278330485

Epoch: 6| Step: 8
Training loss: 0.1631380021572113
Validation loss: 1.9340557058652241

Epoch: 6| Step: 9
Training loss: 0.6962737441062927
Validation loss: 1.9732787410418193

Epoch: 6| Step: 10
Training loss: 0.3700534403324127
Validation loss: 1.9590024749437969

Epoch: 6| Step: 11
Training loss: 0.314261794090271
Validation loss: 1.944216748078664

Epoch: 6| Step: 12
Training loss: 0.4371221661567688
Validation loss: 1.9839544296264648

Epoch: 6| Step: 13
Training loss: 0.638398289680481
Validation loss: 1.9605719049771626

Epoch: 311| Step: 0
Training loss: 0.256764680147171
Validation loss: 1.9554132024447124

Epoch: 6| Step: 1
Training loss: 0.3623926043510437
Validation loss: 1.9488588968912761

Epoch: 6| Step: 2
Training loss: 0.2467387169599533
Validation loss: 1.9738065600395203

Epoch: 6| Step: 3
Training loss: 0.5857632160186768
Validation loss: 1.9773588180541992

Epoch: 6| Step: 4
Training loss: 0.3308662474155426
Validation loss: 1.974248508612315

Epoch: 6| Step: 5
Training loss: 0.2782674729824066
Validation loss: 1.9342340032259624

Epoch: 6| Step: 6
Training loss: 0.34089162945747375
Validation loss: 1.9876492023468018

Epoch: 6| Step: 7
Training loss: 0.24932006001472473
Validation loss: 2.007916510105133

Epoch: 6| Step: 8
Training loss: 0.2750457525253296
Validation loss: 1.9769708911577861

Epoch: 6| Step: 9
Training loss: 0.16283804178237915
Validation loss: 2.0057496428489685

Epoch: 6| Step: 10
Training loss: 0.3546183109283447
Validation loss: 1.9362363417943318

Epoch: 6| Step: 11
Training loss: 0.274048388004303
Validation loss: 2.0073735316594443

Epoch: 6| Step: 12
Training loss: 0.228855162858963
Validation loss: 1.9668315052986145

Epoch: 6| Step: 13
Training loss: 0.31952404975891113
Validation loss: 2.0049301584561667

Epoch: 312| Step: 0
Training loss: 0.15796886384487152
Validation loss: 1.9382378061612446

Epoch: 6| Step: 1
Training loss: 0.3964627683162689
Validation loss: 1.9860018491744995

Epoch: 6| Step: 2
Training loss: 0.1821102648973465
Validation loss: 1.9791826605796814

Epoch: 6| Step: 3
Training loss: 0.4928506016731262
Validation loss: 1.9916618665059407

Epoch: 6| Step: 4
Training loss: 0.22272846102714539
Validation loss: 1.9918179114659627

Epoch: 6| Step: 5
Training loss: 0.2614702582359314
Validation loss: 1.980555772781372

Epoch: 6| Step: 6
Training loss: 0.19921550154685974
Validation loss: 1.9808394114176433

Epoch: 6| Step: 7
Training loss: 0.22059330344200134
Validation loss: 1.9968152244885762

Epoch: 6| Step: 8
Training loss: 0.7313195466995239
Validation loss: 1.9648791948954265

Epoch: 6| Step: 9
Training loss: 0.2677808403968811
Validation loss: 1.9532692829767864

Epoch: 6| Step: 10
Training loss: 0.37648677825927734
Validation loss: 1.936954915523529

Epoch: 6| Step: 11
Training loss: 0.4062735438346863
Validation loss: 1.9708231687545776

Epoch: 6| Step: 12
Training loss: 0.2463303506374359
Validation loss: 1.9586991270383198

Epoch: 6| Step: 13
Training loss: 0.3631536364555359
Validation loss: 1.9859341780344646

Epoch: 313| Step: 0
Training loss: 0.31475740671157837
Validation loss: 1.9489061832427979

Epoch: 6| Step: 1
Training loss: 0.22383345663547516
Validation loss: 1.9450777967770894

Epoch: 6| Step: 2
Training loss: 0.19728900492191315
Validation loss: 1.9721180597941081

Epoch: 6| Step: 3
Training loss: 0.24327512085437775
Validation loss: 1.9520628452301025

Epoch: 6| Step: 4
Training loss: 0.2398403286933899
Validation loss: 2.0052809516588845

Epoch: 6| Step: 5
Training loss: 0.28951719403266907
Validation loss: 1.9448457558949788

Epoch: 6| Step: 6
Training loss: 0.6524895429611206
Validation loss: 1.9386711517969768

Epoch: 6| Step: 7
Training loss: 0.28395846486091614
Validation loss: 1.9333181778589885

Epoch: 6| Step: 8
Training loss: 0.17133405804634094
Validation loss: 1.9528791705767314

Epoch: 6| Step: 9
Training loss: 0.22084814310073853
Validation loss: 1.9610502123832703

Epoch: 6| Step: 10
Training loss: 0.33191415667533875
Validation loss: 1.9933627645174663

Epoch: 6| Step: 11
Training loss: 0.23154105246067047
Validation loss: 1.9667007525761921

Epoch: 6| Step: 12
Training loss: 0.2185409963130951
Validation loss: 1.994791865348816

Epoch: 6| Step: 13
Training loss: 0.3544578552246094
Validation loss: 2.0121591289838157

Epoch: 314| Step: 0
Training loss: 0.549486517906189
Validation loss: 1.9939461946487427

Epoch: 6| Step: 1
Training loss: 0.31801092624664307
Validation loss: 1.9625944097836812

Epoch: 6| Step: 2
Training loss: 0.24182140827178955
Validation loss: 1.9883038600285847

Epoch: 6| Step: 3
Training loss: 0.36792096495628357
Validation loss: 1.9956983923912048

Epoch: 6| Step: 4
Training loss: 0.26967769861221313
Validation loss: 1.9788140257199605

Epoch: 6| Step: 5
Training loss: 0.5639935731887817
Validation loss: 1.9584202567736309

Epoch: 6| Step: 6
Training loss: 0.2701040506362915
Validation loss: 1.9756948153177898

Epoch: 6| Step: 7
Training loss: 0.1569633185863495
Validation loss: 1.9993991057078044

Epoch: 6| Step: 8
Training loss: 0.3056071400642395
Validation loss: 2.000336468219757

Epoch: 6| Step: 9
Training loss: 0.23111771047115326
Validation loss: 1.9747017820676167

Epoch: 6| Step: 10
Training loss: 0.362740159034729
Validation loss: 2.015340050061544

Epoch: 6| Step: 11
Training loss: 0.31043320894241333
Validation loss: 1.9787122011184692

Epoch: 6| Step: 12
Training loss: 0.3940731883049011
Validation loss: 2.0227176348368325

Epoch: 6| Step: 13
Training loss: 0.23409903049468994
Validation loss: 1.9812400142351787

Epoch: 315| Step: 0
Training loss: 0.37768614292144775
Validation loss: 2.0050200819969177

Epoch: 6| Step: 1
Training loss: 0.35509538650512695
Validation loss: 1.9925244847933452

Epoch: 6| Step: 2
Training loss: 0.25246864557266235
Validation loss: 1.9729365905125935

Epoch: 6| Step: 3
Training loss: 0.41102802753448486
Validation loss: 1.9587694605191548

Epoch: 6| Step: 4
Training loss: 0.48971831798553467
Validation loss: 1.987785538037618

Epoch: 6| Step: 5
Training loss: 0.25382769107818604
Validation loss: 1.9726129174232483

Epoch: 6| Step: 6
Training loss: 0.2604769766330719
Validation loss: 1.9591623346010845

Epoch: 6| Step: 7
Training loss: 0.1790749728679657
Validation loss: 2.0146467288335166

Epoch: 6| Step: 8
Training loss: 0.21680128574371338
Validation loss: 1.9770684639612834

Epoch: 6| Step: 9
Training loss: 0.5601525902748108
Validation loss: 1.9753189086914062

Epoch: 6| Step: 10
Training loss: 0.23788322508335114
Validation loss: 1.9543801148732503

Epoch: 6| Step: 11
Training loss: 0.2755414843559265
Validation loss: 1.9536991318066914

Epoch: 6| Step: 12
Training loss: 0.19735029339790344
Validation loss: 1.965207000573476

Epoch: 6| Step: 13
Training loss: 0.30269551277160645
Validation loss: 1.9694357514381409

Epoch: 316| Step: 0
Training loss: 0.4020017385482788
Validation loss: 1.9362616340319316

Epoch: 6| Step: 1
Training loss: 0.2611355781555176
Validation loss: 1.9763187170028687

Epoch: 6| Step: 2
Training loss: 0.4046468138694763
Validation loss: 1.972967227300008

Epoch: 6| Step: 3
Training loss: 0.2889793813228607
Validation loss: 1.9765280882517497

Epoch: 6| Step: 4
Training loss: 0.5957726836204529
Validation loss: 1.9513836900393169

Epoch: 6| Step: 5
Training loss: 0.2674083411693573
Validation loss: 1.9678495327631633

Epoch: 6| Step: 6
Training loss: 0.25421303510665894
Validation loss: 2.0004576643308005

Epoch: 6| Step: 7
Training loss: 0.2892245650291443
Validation loss: 1.976635992527008

Epoch: 6| Step: 8
Training loss: 0.4418041706085205
Validation loss: 1.9860299626986186

Epoch: 6| Step: 9
Training loss: 0.19168144464492798
Validation loss: 1.9465405941009521

Epoch: 6| Step: 10
Training loss: 0.25033536553382874
Validation loss: 1.9527111848195393

Epoch: 6| Step: 11
Training loss: 0.17230331897735596
Validation loss: 1.974932034810384

Epoch: 6| Step: 12
Training loss: 0.3306264579296112
Validation loss: 1.9516068696975708

Epoch: 6| Step: 13
Training loss: 0.29516172409057617
Validation loss: 1.9635027050971985

Epoch: 317| Step: 0
Training loss: 0.1533663123846054
Validation loss: 2.0038960774739585

Epoch: 6| Step: 1
Training loss: 0.27244505286216736
Validation loss: 1.960720717906952

Epoch: 6| Step: 2
Training loss: 0.36776337027549744
Validation loss: 1.9709336558977764

Epoch: 6| Step: 3
Training loss: 0.21375754475593567
Validation loss: 1.9163286884625752

Epoch: 6| Step: 4
Training loss: 0.1636086106300354
Validation loss: 1.9231014053026836

Epoch: 6| Step: 5
Training loss: 0.22836993634700775
Validation loss: 1.9575312733650208

Epoch: 6| Step: 6
Training loss: 0.6123572587966919
Validation loss: 1.993911604086558

Epoch: 6| Step: 7
Training loss: 0.3309839367866516
Validation loss: 1.945200244585673

Epoch: 6| Step: 8
Training loss: 0.317200243473053
Validation loss: 1.9474730690320332

Epoch: 6| Step: 9
Training loss: 0.27636563777923584
Validation loss: 2.00897216796875

Epoch: 6| Step: 10
Training loss: 0.8268598914146423
Validation loss: 1.9646878043810527

Epoch: 6| Step: 11
Training loss: 0.24121132493019104
Validation loss: 1.9666424791018169

Epoch: 6| Step: 12
Training loss: 0.3869776725769043
Validation loss: 1.9601409037907918

Epoch: 6| Step: 13
Training loss: 0.4239690899848938
Validation loss: 1.9656370282173157

Epoch: 318| Step: 0
Training loss: 0.3529922664165497
Validation loss: 2.0009796818097434

Epoch: 6| Step: 1
Training loss: 0.3464091122150421
Validation loss: 1.9862059752146404

Epoch: 6| Step: 2
Training loss: 0.24471698701381683
Validation loss: 1.9253673553466797

Epoch: 6| Step: 3
Training loss: 0.17823117971420288
Validation loss: 1.9685428539911907

Epoch: 6| Step: 4
Training loss: 0.28785449266433716
Validation loss: 1.9662947257359822

Epoch: 6| Step: 5
Training loss: 0.22898711264133453
Validation loss: 1.9388145605723064

Epoch: 6| Step: 6
Training loss: 0.5540000796318054
Validation loss: 2.010620892047882

Epoch: 6| Step: 7
Training loss: 0.16734111309051514
Validation loss: 1.9922792315483093

Epoch: 6| Step: 8
Training loss: 0.328205943107605
Validation loss: 2.007015347480774

Epoch: 6| Step: 9
Training loss: 0.38332265615463257
Validation loss: 1.9767286777496338

Epoch: 6| Step: 10
Training loss: 0.23148217797279358
Validation loss: 1.9824021259943645

Epoch: 6| Step: 11
Training loss: 0.8024922013282776
Validation loss: 1.960317850112915

Epoch: 6| Step: 12
Training loss: 0.1568918228149414
Validation loss: 1.975409468015035

Epoch: 6| Step: 13
Training loss: 0.20241592824459076
Validation loss: 1.9472280144691467

Epoch: 319| Step: 0
Training loss: 0.2302931696176529
Validation loss: 1.9623141686121623

Epoch: 6| Step: 1
Training loss: 0.2909318804740906
Validation loss: 1.9635624090830486

Epoch: 6| Step: 2
Training loss: 0.32565563917160034
Validation loss: 1.9641744097073872

Epoch: 6| Step: 3
Training loss: 0.3183848261833191
Validation loss: 1.9978802998860676

Epoch: 6| Step: 4
Training loss: 0.27157092094421387
Validation loss: 2.0084546407063804

Epoch: 6| Step: 5
Training loss: 0.12367553263902664
Validation loss: 1.9879152377446492

Epoch: 6| Step: 6
Training loss: 0.4459642171859741
Validation loss: 1.9877190391222637

Epoch: 6| Step: 7
Training loss: 0.15492479503154755
Validation loss: 1.9707918564478557

Epoch: 6| Step: 8
Training loss: 0.19917577505111694
Validation loss: 2.0101144313812256

Epoch: 6| Step: 9
Training loss: 0.3990989923477173
Validation loss: 1.9658409754435222

Epoch: 6| Step: 10
Training loss: 0.5803020000457764
Validation loss: 1.972847580909729

Epoch: 6| Step: 11
Training loss: 0.17094457149505615
Validation loss: 2.011351704597473

Epoch: 6| Step: 12
Training loss: 0.2190982550382614
Validation loss: 2.0083345572153726

Epoch: 6| Step: 13
Training loss: 0.2831913232803345
Validation loss: 2.0043890277544656

Epoch: 320| Step: 0
Training loss: 0.18288719654083252
Validation loss: 2.0243050257364907

Epoch: 6| Step: 1
Training loss: 0.3078592121601105
Validation loss: 2.014217515786489

Epoch: 6| Step: 2
Training loss: 0.24274353682994843
Validation loss: 1.9869377215703328

Epoch: 6| Step: 3
Training loss: 0.25596126914024353
Validation loss: 1.9876221021016438

Epoch: 6| Step: 4
Training loss: 0.25340592861175537
Validation loss: 2.040345291296641

Epoch: 6| Step: 5
Training loss: 0.3522951006889343
Validation loss: 2.000247518221537

Epoch: 6| Step: 6
Training loss: 0.19359344244003296
Validation loss: 2.023531357447306

Epoch: 6| Step: 7
Training loss: 0.28272712230682373
Validation loss: 1.981825351715088

Epoch: 6| Step: 8
Training loss: 0.5199395418167114
Validation loss: 1.971817394097646

Epoch: 6| Step: 9
Training loss: 0.275818794965744
Validation loss: 1.993962566057841

Epoch: 6| Step: 10
Training loss: 0.5780256390571594
Validation loss: 2.021032392978668

Epoch: 6| Step: 11
Training loss: 0.18444351851940155
Validation loss: 1.9638614455858867

Epoch: 6| Step: 12
Training loss: 0.23587439954280853
Validation loss: 1.9723012049992878

Epoch: 6| Step: 13
Training loss: 0.1918799877166748
Validation loss: 1.970599114894867

Epoch: 321| Step: 0
Training loss: 0.3318634331226349
Validation loss: 1.98420383532842

Epoch: 6| Step: 1
Training loss: 0.30324071645736694
Validation loss: 1.9746992985407512

Epoch: 6| Step: 2
Training loss: 0.21569550037384033
Validation loss: 1.9924944043159485

Epoch: 6| Step: 3
Training loss: 0.1840323507785797
Validation loss: 1.995776116847992

Epoch: 6| Step: 4
Training loss: 0.48531487584114075
Validation loss: 2.006760895252228

Epoch: 6| Step: 5
Training loss: 0.23219427466392517
Validation loss: 1.9851571718851726

Epoch: 6| Step: 6
Training loss: 0.2506176233291626
Validation loss: 1.961389700571696

Epoch: 6| Step: 7
Training loss: 0.27487629652023315
Validation loss: 1.9860447645187378

Epoch: 6| Step: 8
Training loss: 0.2898785471916199
Validation loss: 2.0020610888799033

Epoch: 6| Step: 9
Training loss: 0.241353377699852
Validation loss: 1.954556902249654

Epoch: 6| Step: 10
Training loss: 0.6967887282371521
Validation loss: 1.9912492632865906

Epoch: 6| Step: 11
Training loss: 0.2718730866909027
Validation loss: 1.993143876393636

Epoch: 6| Step: 12
Training loss: 0.3249647617340088
Validation loss: 1.999696950117747

Epoch: 6| Step: 13
Training loss: 0.20941047370433807
Validation loss: 1.98960942029953

Epoch: 322| Step: 0
Training loss: 0.2684594690799713
Validation loss: 1.9835737546284993

Epoch: 6| Step: 1
Training loss: 0.20812276005744934
Validation loss: 1.9640563130378723

Epoch: 6| Step: 2
Training loss: 0.19957993924617767
Validation loss: 1.9778250058492024

Epoch: 6| Step: 3
Training loss: 0.18886014819145203
Validation loss: 2.0186564524968467

Epoch: 6| Step: 4
Training loss: 0.27434173226356506
Validation loss: 2.0198232332865396

Epoch: 6| Step: 5
Training loss: 0.2646409869194031
Validation loss: 2.0188706318537393

Epoch: 6| Step: 6
Training loss: 0.21886321902275085
Validation loss: 2.0020405054092407

Epoch: 6| Step: 7
Training loss: 0.25757503509521484
Validation loss: 2.0042041142781577

Epoch: 6| Step: 8
Training loss: 0.3637676239013672
Validation loss: 2.0353964964548745

Epoch: 6| Step: 9
Training loss: 0.573066771030426
Validation loss: 1.9953144987424214

Epoch: 6| Step: 10
Training loss: 0.2260741889476776
Validation loss: 1.9836631218592327

Epoch: 6| Step: 11
Training loss: 0.22749382257461548
Validation loss: 1.9573964675267537

Epoch: 6| Step: 12
Training loss: 0.4204102158546448
Validation loss: 1.9766382773717244

Epoch: 6| Step: 13
Training loss: 0.5260663032531738
Validation loss: 1.9978491862614949

Epoch: 323| Step: 0
Training loss: 0.18004608154296875
Validation loss: 1.9529870748519897

Epoch: 6| Step: 1
Training loss: 0.370735228061676
Validation loss: 1.9845551252365112

Epoch: 6| Step: 2
Training loss: 0.20753753185272217
Validation loss: 1.9827235738436382

Epoch: 6| Step: 3
Training loss: 0.47777217626571655
Validation loss: 1.9530062079429626

Epoch: 6| Step: 4
Training loss: 0.34554627537727356
Validation loss: 1.9912981192270915

Epoch: 6| Step: 5
Training loss: 0.4335254430770874
Validation loss: 1.9682500163714092

Epoch: 6| Step: 6
Training loss: 0.3201184868812561
Validation loss: 1.9900372823079426

Epoch: 6| Step: 7
Training loss: 0.21218687295913696
Validation loss: 2.019571681817373

Epoch: 6| Step: 8
Training loss: 0.5386559963226318
Validation loss: 2.012660006682078

Epoch: 6| Step: 9
Training loss: 0.10657232999801636
Validation loss: 1.9922548333803813

Epoch: 6| Step: 10
Training loss: 0.29896610975265503
Validation loss: 1.9777797261873882

Epoch: 6| Step: 11
Training loss: 0.4012707769870758
Validation loss: 2.027712603410085

Epoch: 6| Step: 12
Training loss: 0.1823146939277649
Validation loss: 1.932696561018626

Epoch: 6| Step: 13
Training loss: 0.14926335215568542
Validation loss: 1.9589508374532063

Epoch: 324| Step: 0
Training loss: 0.18254294991493225
Validation loss: 1.9603885809580486

Epoch: 6| Step: 1
Training loss: 0.3290334939956665
Validation loss: 1.9619325002034504

Epoch: 6| Step: 2
Training loss: 0.5163047909736633
Validation loss: 1.9885916709899902

Epoch: 6| Step: 3
Training loss: 0.28487807512283325
Validation loss: 1.9999530911445618

Epoch: 6| Step: 4
Training loss: 0.24908597767353058
Validation loss: 1.9878727197647095

Epoch: 6| Step: 5
Training loss: 0.2795332670211792
Validation loss: 1.965282102425893

Epoch: 6| Step: 6
Training loss: 0.31479138135910034
Validation loss: 1.9769394596417744

Epoch: 6| Step: 7
Training loss: 0.3082209825515747
Validation loss: 1.9503739873568218

Epoch: 6| Step: 8
Training loss: 0.34208714962005615
Validation loss: 1.9955826203028362

Epoch: 6| Step: 9
Training loss: 0.3094768822193146
Validation loss: 1.9602798819541931

Epoch: 6| Step: 10
Training loss: 0.15473857522010803
Validation loss: 1.9318888982137044

Epoch: 6| Step: 11
Training loss: 0.3424052596092224
Validation loss: 1.9890902439753215

Epoch: 6| Step: 12
Training loss: 0.34461262822151184
Validation loss: 1.9757366180419922

Epoch: 6| Step: 13
Training loss: 0.32542136311531067
Validation loss: 1.9963837464650471

Epoch: 325| Step: 0
Training loss: 0.1278797686100006
Validation loss: 1.9735741416613262

Epoch: 6| Step: 1
Training loss: 0.2571052312850952
Validation loss: 1.9806907176971436

Epoch: 6| Step: 2
Training loss: 0.2817199230194092
Validation loss: 1.953766127427419

Epoch: 6| Step: 3
Training loss: 0.47434496879577637
Validation loss: 1.9476681749025981

Epoch: 6| Step: 4
Training loss: 0.5968973636627197
Validation loss: 1.9687781929969788

Epoch: 6| Step: 5
Training loss: 0.2903509736061096
Validation loss: 1.9524774352709453

Epoch: 6| Step: 6
Training loss: 0.17110762000083923
Validation loss: 1.961237112681071

Epoch: 6| Step: 7
Training loss: 0.3805946707725525
Validation loss: 1.952989121278127

Epoch: 6| Step: 8
Training loss: 0.15379022061824799
Validation loss: 1.9880694548288982

Epoch: 6| Step: 9
Training loss: 0.21854168176651
Validation loss: 1.9755539894104004

Epoch: 6| Step: 10
Training loss: 0.23428556323051453
Validation loss: 1.961640199025472

Epoch: 6| Step: 11
Training loss: 0.12730011343955994
Validation loss: 1.9972453514734905

Epoch: 6| Step: 12
Training loss: 0.27374356985092163
Validation loss: 1.9773508310317993

Epoch: 6| Step: 13
Training loss: 0.2881343960762024
Validation loss: 1.999394913514455

Epoch: 326| Step: 0
Training loss: 0.27587103843688965
Validation loss: 2.0102197925249734

Epoch: 6| Step: 1
Training loss: 0.3320610523223877
Validation loss: 1.977493683497111

Epoch: 6| Step: 2
Training loss: 0.28254714608192444
Validation loss: 1.9860904216766357

Epoch: 6| Step: 3
Training loss: 0.7966524362564087
Validation loss: 2.007000744342804

Epoch: 6| Step: 4
Training loss: 0.18618206679821014
Validation loss: 1.99500572681427

Epoch: 6| Step: 5
Training loss: 0.20072317123413086
Validation loss: 2.0047351320584617

Epoch: 6| Step: 6
Training loss: 0.2661529779434204
Validation loss: 1.9712339043617249

Epoch: 6| Step: 7
Training loss: 0.32994991540908813
Validation loss: 1.996768017609914

Epoch: 6| Step: 8
Training loss: 0.212449848651886
Validation loss: 1.9578436215718586

Epoch: 6| Step: 9
Training loss: 0.3034859895706177
Validation loss: 2.0060816407203674

Epoch: 6| Step: 10
Training loss: 0.21334746479988098
Validation loss: 2.0241949359575906

Epoch: 6| Step: 11
Training loss: 0.25877973437309265
Validation loss: 1.9940312306086223

Epoch: 6| Step: 12
Training loss: 0.34113821387290955
Validation loss: 2.0101249615351358

Epoch: 6| Step: 13
Training loss: 0.23154254257678986
Validation loss: 1.9783100088437398

Epoch: 327| Step: 0
Training loss: 0.2742321789264679
Validation loss: 2.001692076524099

Epoch: 6| Step: 1
Training loss: 0.34863144159317017
Validation loss: 1.988300879796346

Epoch: 6| Step: 2
Training loss: 0.3732801079750061
Validation loss: 1.9540087183316548

Epoch: 6| Step: 3
Training loss: 0.24964949488639832
Validation loss: 1.9849855105082195

Epoch: 6| Step: 4
Training loss: 0.2325107753276825
Validation loss: 1.9890273213386536

Epoch: 6| Step: 5
Training loss: 0.18750447034835815
Validation loss: 1.9805476665496826

Epoch: 6| Step: 6
Training loss: 0.22575174272060394
Validation loss: 1.9457965890566509

Epoch: 6| Step: 7
Training loss: 0.30547016859054565
Validation loss: 1.991281270980835

Epoch: 6| Step: 8
Training loss: 0.45766717195510864
Validation loss: 1.9824647108713787

Epoch: 6| Step: 9
Training loss: 0.2054387331008911
Validation loss: 2.0244078437487283

Epoch: 6| Step: 10
Training loss: 0.5281729698181152
Validation loss: 1.9777052005132039

Epoch: 6| Step: 11
Training loss: 0.3574504852294922
Validation loss: 1.9866876800855

Epoch: 6| Step: 12
Training loss: 0.29066455364227295
Validation loss: 2.024571696917216

Epoch: 6| Step: 13
Training loss: 0.21146875619888306
Validation loss: 2.0016942620277405

Epoch: 328| Step: 0
Training loss: 0.26285919547080994
Validation loss: 1.9820613265037537

Epoch: 6| Step: 1
Training loss: 0.2901480793952942
Validation loss: 1.9897331794102986

Epoch: 6| Step: 2
Training loss: 0.4021753668785095
Validation loss: 1.9910983840624492

Epoch: 6| Step: 3
Training loss: 0.2824224531650543
Validation loss: 1.9734668731689453

Epoch: 6| Step: 4
Training loss: 0.396414190530777
Validation loss: 2.0134679476420083

Epoch: 6| Step: 5
Training loss: 0.29420942068099976
Validation loss: 1.9620981812477112

Epoch: 6| Step: 6
Training loss: 0.2657536268234253
Validation loss: 2.0352739691734314

Epoch: 6| Step: 7
Training loss: 0.19411814212799072
Validation loss: 1.973525842030843

Epoch: 6| Step: 8
Training loss: 0.4047190546989441
Validation loss: 1.9678519368171692

Epoch: 6| Step: 9
Training loss: 0.21687698364257812
Validation loss: 2.0076350967089334

Epoch: 6| Step: 10
Training loss: 0.273578017950058
Validation loss: 2.0247954527537027

Epoch: 6| Step: 11
Training loss: 0.31996849179267883
Validation loss: 2.016712804635366

Epoch: 6| Step: 12
Training loss: 0.6358773112297058
Validation loss: 1.9583614269892375

Epoch: 6| Step: 13
Training loss: 0.2599431872367859
Validation loss: 1.9462811748186748

Epoch: 329| Step: 0
Training loss: 0.22036026418209076
Validation loss: 1.997097651163737

Epoch: 6| Step: 1
Training loss: 0.5244672894477844
Validation loss: 1.9546366731325786

Epoch: 6| Step: 2
Training loss: 0.4414359927177429
Validation loss: 1.9812037348747253

Epoch: 6| Step: 3
Training loss: 0.23199403285980225
Validation loss: 1.9863025943438213

Epoch: 6| Step: 4
Training loss: 0.1915396898984909
Validation loss: 1.9758433103561401

Epoch: 6| Step: 5
Training loss: 0.6677713990211487
Validation loss: 1.9974667231241863

Epoch: 6| Step: 6
Training loss: 0.2773382365703583
Validation loss: 2.0032638907432556

Epoch: 6| Step: 7
Training loss: 0.4053412079811096
Validation loss: 2.0165756742159524

Epoch: 6| Step: 8
Training loss: 0.2875783443450928
Validation loss: 1.9767756462097168

Epoch: 6| Step: 9
Training loss: 0.22566597163677216
Validation loss: 1.9993726809819539

Epoch: 6| Step: 10
Training loss: 0.18652905523777008
Validation loss: 2.0002050399780273

Epoch: 6| Step: 11
Training loss: 0.2689964175224304
Validation loss: 1.9945348501205444

Epoch: 6| Step: 12
Training loss: 0.2084619700908661
Validation loss: 1.9764227469762166

Epoch: 6| Step: 13
Training loss: 0.2856316566467285
Validation loss: 1.978022575378418

Epoch: 330| Step: 0
Training loss: 0.7481750249862671
Validation loss: 1.9598829746246338

Epoch: 6| Step: 1
Training loss: 0.23329989612102509
Validation loss: 1.9765777786572774

Epoch: 6| Step: 2
Training loss: 0.3184078335762024
Validation loss: 2.0042022665341697

Epoch: 6| Step: 3
Training loss: 0.18198534846305847
Validation loss: 1.9645466804504395

Epoch: 6| Step: 4
Training loss: 0.20604366064071655
Validation loss: 1.9633267720540364

Epoch: 6| Step: 5
Training loss: 0.16064044833183289
Validation loss: 1.9685052037239075

Epoch: 6| Step: 6
Training loss: 0.1270933896303177
Validation loss: 1.9872756004333496

Epoch: 6| Step: 7
Training loss: 0.24837300181388855
Validation loss: 1.9493898550669353

Epoch: 6| Step: 8
Training loss: 0.1634579598903656
Validation loss: 1.9698858658472698

Epoch: 6| Step: 9
Training loss: 0.3281351327896118
Validation loss: 2.0049596031506858

Epoch: 6| Step: 10
Training loss: 0.3830472230911255
Validation loss: 1.9345451593399048

Epoch: 6| Step: 11
Training loss: 0.1115814670920372
Validation loss: 1.953577737013499

Epoch: 6| Step: 12
Training loss: 0.19370651245117188
Validation loss: 1.9780556956926982

Epoch: 6| Step: 13
Training loss: 0.33214008808135986
Validation loss: 2.007290561993917

Epoch: 331| Step: 0
Training loss: 0.1716262400150299
Validation loss: 1.9625635544459026

Epoch: 6| Step: 1
Training loss: 0.29783135652542114
Validation loss: 1.9930495222409566

Epoch: 6| Step: 2
Training loss: 0.7109256982803345
Validation loss: 1.9439707398414612

Epoch: 6| Step: 3
Training loss: 0.26074591279029846
Validation loss: 1.9729924599329631

Epoch: 6| Step: 4
Training loss: 0.23657885193824768
Validation loss: 1.950829029083252

Epoch: 6| Step: 5
Training loss: 0.2001495063304901
Validation loss: 1.9546846548716228

Epoch: 6| Step: 6
Training loss: 0.19401876628398895
Validation loss: 1.9961117307345073

Epoch: 6| Step: 7
Training loss: 0.22623547911643982
Validation loss: 1.9987518986066182

Epoch: 6| Step: 8
Training loss: 0.2525395452976227
Validation loss: 1.9649170835812886

Epoch: 6| Step: 9
Training loss: 0.3229749798774719
Validation loss: 1.944042404492696

Epoch: 6| Step: 10
Training loss: 0.2639886736869812
Validation loss: 2.0132723251978555

Epoch: 6| Step: 11
Training loss: 0.2048041671514511
Validation loss: 1.9630156755447388

Epoch: 6| Step: 12
Training loss: 0.2317919135093689
Validation loss: 1.9562692244847615

Epoch: 6| Step: 13
Training loss: 0.4671868085861206
Validation loss: 1.9559649229049683

Epoch: 332| Step: 0
Training loss: 0.21261908113956451
Validation loss: 1.9617511828740437

Epoch: 6| Step: 1
Training loss: 0.3811236619949341
Validation loss: 2.0213375886281333

Epoch: 6| Step: 2
Training loss: 0.20400682091712952
Validation loss: 1.9571804006894429

Epoch: 6| Step: 3
Training loss: 0.2945432960987091
Validation loss: 1.9812740882237752

Epoch: 6| Step: 4
Training loss: 0.2916072607040405
Validation loss: 1.978712260723114

Epoch: 6| Step: 5
Training loss: 0.28604817390441895
Validation loss: 1.95933332045873

Epoch: 6| Step: 6
Training loss: 0.39588481187820435
Validation loss: 1.9352344473203023

Epoch: 6| Step: 7
Training loss: 0.3388555645942688
Validation loss: 1.960482617219289

Epoch: 6| Step: 8
Training loss: 0.3084395229816437
Validation loss: 1.9822083115577698

Epoch: 6| Step: 9
Training loss: 0.27463942766189575
Validation loss: 1.9838009874025981

Epoch: 6| Step: 10
Training loss: 0.20490220189094543
Validation loss: 1.9606736699740093

Epoch: 6| Step: 11
Training loss: 0.28882816433906555
Validation loss: 1.9916084011395772

Epoch: 6| Step: 12
Training loss: 0.6621159315109253
Validation loss: 1.9635076920191448

Epoch: 6| Step: 13
Training loss: 0.2937595844268799
Validation loss: 1.9523620804150899

Epoch: 333| Step: 0
Training loss: 0.2625434696674347
Validation loss: 2.0271584391593933

Epoch: 6| Step: 1
Training loss: 0.23801781237125397
Validation loss: 1.9537671407063801

Epoch: 6| Step: 2
Training loss: 0.2901517152786255
Validation loss: 2.022459864616394

Epoch: 6| Step: 3
Training loss: 0.2386835366487503
Validation loss: 1.9934067328770955

Epoch: 6| Step: 4
Training loss: 0.26279252767562866
Validation loss: 2.0200626055399575

Epoch: 6| Step: 5
Training loss: 0.22436828911304474
Validation loss: 1.9820503791173298

Epoch: 6| Step: 6
Training loss: 0.40514999628067017
Validation loss: 1.9605425397555034

Epoch: 6| Step: 7
Training loss: 0.2945858836174011
Validation loss: 1.9736162622769673

Epoch: 6| Step: 8
Training loss: 0.18683671951293945
Validation loss: 1.9861913919448853

Epoch: 6| Step: 9
Training loss: 0.23255585134029388
Validation loss: 2.0046656727790833

Epoch: 6| Step: 10
Training loss: 0.43773701786994934
Validation loss: 1.9708256324132283

Epoch: 6| Step: 11
Training loss: 0.25990980863571167
Validation loss: 1.9821572502454121

Epoch: 6| Step: 12
Training loss: 0.609647274017334
Validation loss: 1.9705181916554768

Epoch: 6| Step: 13
Training loss: 0.18083086609840393
Validation loss: 1.9785145322481792

Epoch: 334| Step: 0
Training loss: 0.3686186671257019
Validation loss: 1.955561339855194

Epoch: 6| Step: 1
Training loss: 0.2575894296169281
Validation loss: 1.9808652599652607

Epoch: 6| Step: 2
Training loss: 0.2548976242542267
Validation loss: 1.9727219343185425

Epoch: 6| Step: 3
Training loss: 0.29957666993141174
Validation loss: 1.9638555844624836

Epoch: 6| Step: 4
Training loss: 0.27671000361442566
Validation loss: 1.980748971303304

Epoch: 6| Step: 5
Training loss: 0.22336241602897644
Validation loss: 1.9923572738965352

Epoch: 6| Step: 6
Training loss: 0.34582582116127014
Validation loss: 1.9341768026351929

Epoch: 6| Step: 7
Training loss: 0.28848376870155334
Validation loss: 1.9497240980466206

Epoch: 6| Step: 8
Training loss: 0.1410152018070221
Validation loss: 1.9754118124643962

Epoch: 6| Step: 9
Training loss: 0.2238205522298813
Validation loss: 1.989948332309723

Epoch: 6| Step: 10
Training loss: 0.20906130969524384
Validation loss: 1.9786311189333599

Epoch: 6| Step: 11
Training loss: 0.6874480247497559
Validation loss: 1.9663522442181904

Epoch: 6| Step: 12
Training loss: 0.25360190868377686
Validation loss: 1.999847690264384

Epoch: 6| Step: 13
Training loss: 0.29660627245903015
Validation loss: 1.9590537548065186

Epoch: 335| Step: 0
Training loss: 0.21852488815784454
Validation loss: 1.9495447874069214

Epoch: 6| Step: 1
Training loss: 0.24141478538513184
Validation loss: 1.9809625546137493

Epoch: 6| Step: 2
Training loss: 0.35089606046676636
Validation loss: 1.9993350903193157

Epoch: 6| Step: 3
Training loss: 0.2506566643714905
Validation loss: 1.97269211212794

Epoch: 6| Step: 4
Training loss: 0.26507285237312317
Validation loss: 1.980044682820638

Epoch: 6| Step: 5
Training loss: 0.21032163500785828
Validation loss: 1.9911520679791768

Epoch: 6| Step: 6
Training loss: 0.31970882415771484
Validation loss: 1.9978084564208984

Epoch: 6| Step: 7
Training loss: 0.19559021294116974
Validation loss: 1.9826398293177288

Epoch: 6| Step: 8
Training loss: 0.2425798624753952
Validation loss: 1.9712436596552532

Epoch: 6| Step: 9
Training loss: 0.41833966970443726
Validation loss: 2.0055800875027976

Epoch: 6| Step: 10
Training loss: 0.5636240839958191
Validation loss: 1.9916563630104065

Epoch: 6| Step: 11
Training loss: 0.24377229809761047
Validation loss: 1.9621261954307556

Epoch: 6| Step: 12
Training loss: 0.19169281423091888
Validation loss: 1.9700884222984314

Epoch: 6| Step: 13
Training loss: 0.3644499182701111
Validation loss: 1.9806771477063496

Epoch: 336| Step: 0
Training loss: 0.18688790500164032
Validation loss: 2.014057775338491

Epoch: 6| Step: 1
Training loss: 0.24082088470458984
Validation loss: 1.9779396653175354

Epoch: 6| Step: 2
Training loss: 0.5555994510650635
Validation loss: 1.9837168256441753

Epoch: 6| Step: 3
Training loss: 0.18283921480178833
Validation loss: 1.9582929015159607

Epoch: 6| Step: 4
Training loss: 0.2776774764060974
Validation loss: 1.9797178904215496

Epoch: 6| Step: 5
Training loss: 0.3256409764289856
Validation loss: 1.9703702131907146

Epoch: 6| Step: 6
Training loss: 0.32638001441955566
Validation loss: 1.9920234481493633

Epoch: 6| Step: 7
Training loss: 0.4496828317642212
Validation loss: 2.0023364623387656

Epoch: 6| Step: 8
Training loss: 0.20880019664764404
Validation loss: 2.005384147167206

Epoch: 6| Step: 9
Training loss: 0.21044883131980896
Validation loss: 1.9614227612813313

Epoch: 6| Step: 10
Training loss: 0.3473181426525116
Validation loss: 1.9730665286382039

Epoch: 6| Step: 11
Training loss: 0.3234816789627075
Validation loss: 1.9664488633473713

Epoch: 6| Step: 12
Training loss: 0.2570236027240753
Validation loss: 1.963623543580373

Epoch: 6| Step: 13
Training loss: 0.201877161860466
Validation loss: 2.007172783215841

Epoch: 337| Step: 0
Training loss: 0.35369038581848145
Validation loss: 1.994507094224294

Epoch: 6| Step: 1
Training loss: 0.5671131014823914
Validation loss: 1.9915958046913147

Epoch: 6| Step: 2
Training loss: 0.2684394419193268
Validation loss: 1.9551305770874023

Epoch: 6| Step: 3
Training loss: 0.13300511240959167
Validation loss: 1.958082675933838

Epoch: 6| Step: 4
Training loss: 0.263679176568985
Validation loss: 1.9943235913912456

Epoch: 6| Step: 5
Training loss: 0.1845177263021469
Validation loss: 1.997710943222046

Epoch: 6| Step: 6
Training loss: 0.2418368011713028
Validation loss: 1.99622776110967

Epoch: 6| Step: 7
Training loss: 0.35232996940612793
Validation loss: 1.9853996634483337

Epoch: 6| Step: 8
Training loss: 0.32444363832473755
Validation loss: 1.9926347931226094

Epoch: 6| Step: 9
Training loss: 0.22879114747047424
Validation loss: 2.029975732167562

Epoch: 6| Step: 10
Training loss: 0.3554023504257202
Validation loss: 1.975488801797231

Epoch: 6| Step: 11
Training loss: 0.22547771036624908
Validation loss: 1.9810688296953838

Epoch: 6| Step: 12
Training loss: 0.4331916570663452
Validation loss: 1.956584870815277

Epoch: 6| Step: 13
Training loss: 0.19251447916030884
Validation loss: 1.993846853574117

Epoch: 338| Step: 0
Training loss: 0.19812780618667603
Validation loss: 1.9514057040214539

Epoch: 6| Step: 1
Training loss: 0.29683616757392883
Validation loss: 1.9551593661308289

Epoch: 6| Step: 2
Training loss: 0.33422115445137024
Validation loss: 1.9817257126172383

Epoch: 6| Step: 3
Training loss: 0.42027735710144043
Validation loss: 1.988232672214508

Epoch: 6| Step: 4
Training loss: 0.2435828149318695
Validation loss: 1.973761220773061

Epoch: 6| Step: 5
Training loss: 0.25114575028419495
Validation loss: 1.9843554894129436

Epoch: 6| Step: 6
Training loss: 0.16340172290802002
Validation loss: 2.0131359497706094

Epoch: 6| Step: 7
Training loss: 0.2605034112930298
Validation loss: 1.9729991555213928

Epoch: 6| Step: 8
Training loss: 0.16792365908622742
Validation loss: 2.001655419667562

Epoch: 6| Step: 9
Training loss: 0.21696743369102478
Validation loss: 1.9971509178479512

Epoch: 6| Step: 10
Training loss: 0.475837767124176
Validation loss: 1.9502045512199402

Epoch: 6| Step: 11
Training loss: 0.4828733801841736
Validation loss: 1.994095245997111

Epoch: 6| Step: 12
Training loss: 0.6338034272193909
Validation loss: 1.9718661506970723

Epoch: 6| Step: 13
Training loss: 0.1993517279624939
Validation loss: 1.9716719786326091

Epoch: 339| Step: 0
Training loss: 0.2033906877040863
Validation loss: 2.0019919077555337

Epoch: 6| Step: 1
Training loss: 0.38063207268714905
Validation loss: 1.9727265040079753

Epoch: 6| Step: 2
Training loss: 0.3425320088863373
Validation loss: 1.9923618237177532

Epoch: 6| Step: 3
Training loss: 0.27667200565338135
Validation loss: 1.9599693218866985

Epoch: 6| Step: 4
Training loss: 0.2308303713798523
Validation loss: 1.9886463085810344

Epoch: 6| Step: 5
Training loss: 0.16400755941867828
Validation loss: 1.9429857929547627

Epoch: 6| Step: 6
Training loss: 0.22904688119888306
Validation loss: 1.9751450419425964

Epoch: 6| Step: 7
Training loss: 0.29736337065696716
Validation loss: 1.9625945885976155

Epoch: 6| Step: 8
Training loss: 0.3667549192905426
Validation loss: 1.9263423085212708

Epoch: 6| Step: 9
Training loss: 0.1286422610282898
Validation loss: 1.990962823232015

Epoch: 6| Step: 10
Training loss: 0.6150922179222107
Validation loss: 1.9615319569905598

Epoch: 6| Step: 11
Training loss: 0.261684775352478
Validation loss: 1.977298418680827

Epoch: 6| Step: 12
Training loss: 0.17361122369766235
Validation loss: 1.9508032600084941

Epoch: 6| Step: 13
Training loss: 0.2270132303237915
Validation loss: 1.9509097337722778

Epoch: 340| Step: 0
Training loss: 0.2761155366897583
Validation loss: 1.9796588222185771

Epoch: 6| Step: 1
Training loss: 0.3267711102962494
Validation loss: 1.9527340531349182

Epoch: 6| Step: 2
Training loss: 0.24290712177753448
Validation loss: 1.959731936454773

Epoch: 6| Step: 3
Training loss: 0.2176414281129837
Validation loss: 1.9886142214139302

Epoch: 6| Step: 4
Training loss: 0.15664136409759521
Validation loss: 1.9782002170880635

Epoch: 6| Step: 5
Training loss: 0.2487768828868866
Validation loss: 1.9630599617958069

Epoch: 6| Step: 6
Training loss: 0.41300344467163086
Validation loss: 1.9735430479049683

Epoch: 6| Step: 7
Training loss: 0.20140594244003296
Validation loss: 1.9933435718218486

Epoch: 6| Step: 8
Training loss: 0.2643822133541107
Validation loss: 2.0057434837023416

Epoch: 6| Step: 9
Training loss: 0.18549318611621857
Validation loss: 1.9673529863357544

Epoch: 6| Step: 10
Training loss: 0.5653619170188904
Validation loss: 1.9897125164667766

Epoch: 6| Step: 11
Training loss: 0.5814679265022278
Validation loss: 1.9963432550430298

Epoch: 6| Step: 12
Training loss: 0.18382178246974945
Validation loss: 1.975141704082489

Epoch: 6| Step: 13
Training loss: 0.33624541759490967
Validation loss: 1.9899035493532817

Epoch: 341| Step: 0
Training loss: 0.32821792364120483
Validation loss: 1.9812984863917034

Epoch: 6| Step: 1
Training loss: 0.32451826333999634
Validation loss: 1.9537246028582256

Epoch: 6| Step: 2
Training loss: 0.25323253870010376
Validation loss: 1.986230154832204

Epoch: 6| Step: 3
Training loss: 0.340143084526062
Validation loss: 1.9970485369364421

Epoch: 6| Step: 4
Training loss: 0.27313923835754395
Validation loss: 1.9926013151804607

Epoch: 6| Step: 5
Training loss: 0.6340753436088562
Validation loss: 1.9847941398620605

Epoch: 6| Step: 6
Training loss: 0.24320274591445923
Validation loss: 1.970473011334737

Epoch: 6| Step: 7
Training loss: 0.2015996277332306
Validation loss: 1.9987064003944397

Epoch: 6| Step: 8
Training loss: 0.2109605222940445
Validation loss: 2.0112969080607095

Epoch: 6| Step: 9
Training loss: 0.24960216879844666
Validation loss: 1.9911469022432964

Epoch: 6| Step: 10
Training loss: 0.20880673825740814
Validation loss: 2.0126819809277854

Epoch: 6| Step: 11
Training loss: 0.3134598135948181
Validation loss: 1.9665581583976746

Epoch: 6| Step: 12
Training loss: 0.3233727216720581
Validation loss: 1.9893328944842021

Epoch: 6| Step: 13
Training loss: 0.37074291706085205
Validation loss: 1.9655317068099976

Epoch: 342| Step: 0
Training loss: 0.25890663266181946
Validation loss: 2.003949781258901

Epoch: 6| Step: 1
Training loss: 0.23720180988311768
Validation loss: 2.0196548104286194

Epoch: 6| Step: 2
Training loss: 0.36922332644462585
Validation loss: 1.9867420395215352

Epoch: 6| Step: 3
Training loss: 0.21187818050384521
Validation loss: 1.9883835911750793

Epoch: 6| Step: 4
Training loss: 0.31964001059532166
Validation loss: 2.0062793691953025

Epoch: 6| Step: 5
Training loss: 0.23689591884613037
Validation loss: 1.9410473306973774

Epoch: 6| Step: 6
Training loss: 0.35658448934555054
Validation loss: 1.9712320963541667

Epoch: 6| Step: 7
Training loss: 0.24777939915657043
Validation loss: 1.9758809407552083

Epoch: 6| Step: 8
Training loss: 0.34520816802978516
Validation loss: 1.9439485669136047

Epoch: 6| Step: 9
Training loss: 0.2301756739616394
Validation loss: 1.9842158357302349

Epoch: 6| Step: 10
Training loss: 0.3166537880897522
Validation loss: 2.0377058585484824

Epoch: 6| Step: 11
Training loss: 0.30170124769210815
Validation loss: 1.9681167403856914

Epoch: 6| Step: 12
Training loss: 0.6562877893447876
Validation loss: 1.961681028207143

Epoch: 6| Step: 13
Training loss: 0.200819730758667
Validation loss: 1.9881566564242046

Epoch: 343| Step: 0
Training loss: 0.22673434019088745
Validation loss: 1.955611785252889

Epoch: 6| Step: 1
Training loss: 0.3379894495010376
Validation loss: 1.9892909328142803

Epoch: 6| Step: 2
Training loss: 0.24791011214256287
Validation loss: 1.929302453994751

Epoch: 6| Step: 3
Training loss: 0.2781994342803955
Validation loss: 1.9600546558698018

Epoch: 6| Step: 4
Training loss: 0.24812273681163788
Validation loss: 1.9765417178471882

Epoch: 6| Step: 5
Training loss: 0.3003832697868347
Validation loss: 1.9642901221911113

Epoch: 6| Step: 6
Training loss: 0.34790369868278503
Validation loss: 1.9860618114471436

Epoch: 6| Step: 7
Training loss: 0.32916438579559326
Validation loss: 1.9900256792704265

Epoch: 6| Step: 8
Training loss: 0.25369590520858765
Validation loss: 2.0086082220077515

Epoch: 6| Step: 9
Training loss: 0.1853514015674591
Validation loss: 1.9833041628201802

Epoch: 6| Step: 10
Training loss: 0.16873690485954285
Validation loss: 1.9838319818178813

Epoch: 6| Step: 11
Training loss: 0.4084778130054474
Validation loss: 1.9781283537546794

Epoch: 6| Step: 12
Training loss: 0.21154652535915375
Validation loss: 1.9625394344329834

Epoch: 6| Step: 13
Training loss: 0.5704210996627808
Validation loss: 1.977740486462911

Epoch: 344| Step: 0
Training loss: 0.32454103231430054
Validation loss: 1.9937109351158142

Epoch: 6| Step: 1
Training loss: 0.24311792850494385
Validation loss: 1.9728112022082012

Epoch: 6| Step: 2
Training loss: 0.3277577757835388
Validation loss: 2.0114980737368264

Epoch: 6| Step: 3
Training loss: 0.20281767845153809
Validation loss: 1.9997135202089946

Epoch: 6| Step: 4
Training loss: 0.2643350064754486
Validation loss: 2.0026017824808755

Epoch: 6| Step: 5
Training loss: 0.15412627160549164
Validation loss: 2.023707469304403

Epoch: 6| Step: 6
Training loss: 0.3823518753051758
Validation loss: 1.9726136724154155

Epoch: 6| Step: 7
Training loss: 0.5579829812049866
Validation loss: 2.0128879944483438

Epoch: 6| Step: 8
Training loss: 0.2787737250328064
Validation loss: 1.9973943829536438

Epoch: 6| Step: 9
Training loss: 0.2319943904876709
Validation loss: 2.0100727478663125

Epoch: 6| Step: 10
Training loss: 0.3177674412727356
Validation loss: 2.010822912057241

Epoch: 6| Step: 11
Training loss: 0.14989542961120605
Validation loss: 1.9961959719657898

Epoch: 6| Step: 12
Training loss: 0.23876835405826569
Validation loss: 1.9656845728556316

Epoch: 6| Step: 13
Training loss: 0.22616709768772125
Validation loss: 1.975593388080597

Epoch: 345| Step: 0
Training loss: 0.24301579594612122
Validation loss: 2.0096654891967773

Epoch: 6| Step: 1
Training loss: 0.21814507246017456
Validation loss: 1.9773856004079182

Epoch: 6| Step: 2
Training loss: 0.31078454852104187
Validation loss: 2.0003506342569985

Epoch: 6| Step: 3
Training loss: 0.38487592339515686
Validation loss: 1.9896695415178935

Epoch: 6| Step: 4
Training loss: 0.27804887294769287
Validation loss: 2.0152642329533896

Epoch: 6| Step: 5
Training loss: 0.15207211673259735
Validation loss: 2.034087896347046

Epoch: 6| Step: 6
Training loss: 0.2936892807483673
Validation loss: 2.0213563640912375

Epoch: 6| Step: 7
Training loss: 0.3639020323753357
Validation loss: 2.0110254883766174

Epoch: 6| Step: 8
Training loss: 0.2833130657672882
Validation loss: 2.0158013304074607

Epoch: 6| Step: 9
Training loss: 0.16673199832439423
Validation loss: 1.9890015920003254

Epoch: 6| Step: 10
Training loss: 0.13682103157043457
Validation loss: 2.038442234198252

Epoch: 6| Step: 11
Training loss: 0.19292575120925903
Validation loss: 1.961433231830597

Epoch: 6| Step: 12
Training loss: 0.16460111737251282
Validation loss: 1.9929360349973042

Epoch: 6| Step: 13
Training loss: 0.6366304159164429
Validation loss: 2.013247807820638

Epoch: 346| Step: 0
Training loss: 0.22548288106918335
Validation loss: 1.9907657106717427

Epoch: 6| Step: 1
Training loss: 0.24273398518562317
Validation loss: 1.985716700553894

Epoch: 6| Step: 2
Training loss: 0.32915669679641724
Validation loss: 1.9806326627731323

Epoch: 6| Step: 3
Training loss: 0.308315634727478
Validation loss: 1.980288823445638

Epoch: 6| Step: 4
Training loss: 0.1300552636384964
Validation loss: 2.0184590816497803

Epoch: 6| Step: 5
Training loss: 0.6183445453643799
Validation loss: 1.9685612519582112

Epoch: 6| Step: 6
Training loss: 0.15804988145828247
Validation loss: 1.9476500948270161

Epoch: 6| Step: 7
Training loss: 0.2911965250968933
Validation loss: 2.02215176820755

Epoch: 6| Step: 8
Training loss: 0.2207203209400177
Validation loss: 1.9977166652679443

Epoch: 6| Step: 9
Training loss: 0.22086331248283386
Validation loss: 2.0116087992986045

Epoch: 6| Step: 10
Training loss: 0.42407554388046265
Validation loss: 1.9700690309206645

Epoch: 6| Step: 11
Training loss: 0.2729506194591522
Validation loss: 1.9958537022272747

Epoch: 6| Step: 12
Training loss: 0.4059411883354187
Validation loss: 1.9592683513959248

Epoch: 6| Step: 13
Training loss: 0.3103756308555603
Validation loss: 1.9907965858777363

Epoch: 347| Step: 0
Training loss: 0.2150069922208786
Validation loss: 1.9263258576393127

Epoch: 6| Step: 1
Training loss: 0.2902996838092804
Validation loss: 1.9855890274047852

Epoch: 6| Step: 2
Training loss: 0.19501447677612305
Validation loss: 1.9917350610097249

Epoch: 6| Step: 3
Training loss: 0.31991147994995117
Validation loss: 2.00760026772817

Epoch: 6| Step: 4
Training loss: 0.2903022766113281
Validation loss: 1.9987697005271912

Epoch: 6| Step: 5
Training loss: 0.22549746930599213
Validation loss: 1.9961979389190674

Epoch: 6| Step: 6
Training loss: 0.3165617883205414
Validation loss: 2.0184749563535056

Epoch: 6| Step: 7
Training loss: 0.24249161779880524
Validation loss: 2.033159057299296

Epoch: 6| Step: 8
Training loss: 0.291320264339447
Validation loss: 1.9820033311843872

Epoch: 6| Step: 9
Training loss: 0.2966141104698181
Validation loss: 2.0110392371813455

Epoch: 6| Step: 10
Training loss: 0.268555223941803
Validation loss: 1.9961943626403809

Epoch: 6| Step: 11
Training loss: 0.5466499328613281
Validation loss: 2.029991944630941

Epoch: 6| Step: 12
Training loss: 0.20295493304729462
Validation loss: 2.041439473628998

Epoch: 6| Step: 13
Training loss: 0.39875704050064087
Validation loss: 1.9658651947975159

Epoch: 348| Step: 0
Training loss: 0.15176981687545776
Validation loss: 1.977391521135966

Epoch: 6| Step: 1
Training loss: 0.2445920705795288
Validation loss: 2.0083069602648416

Epoch: 6| Step: 2
Training loss: 0.6020939946174622
Validation loss: 2.013524313767751

Epoch: 6| Step: 3
Training loss: 0.22571270167827606
Validation loss: 2.016101360321045

Epoch: 6| Step: 4
Training loss: 0.25157594680786133
Validation loss: 1.9661558469136555

Epoch: 6| Step: 5
Training loss: 0.35303205251693726
Validation loss: 1.9687769214312236

Epoch: 6| Step: 6
Training loss: 0.3059847950935364
Validation loss: 1.9941870371500652

Epoch: 6| Step: 7
Training loss: 0.26930347084999084
Validation loss: 1.9875888029734294

Epoch: 6| Step: 8
Training loss: 0.24869774281978607
Validation loss: 2.017861306667328

Epoch: 6| Step: 9
Training loss: 0.3541751801967621
Validation loss: 1.9972812136014302

Epoch: 6| Step: 10
Training loss: 0.25032758712768555
Validation loss: 1.9847084482510884

Epoch: 6| Step: 11
Training loss: 0.1922995150089264
Validation loss: 1.97926265001297

Epoch: 6| Step: 12
Training loss: 0.22019335627555847
Validation loss: 1.979817529519399

Epoch: 6| Step: 13
Training loss: 0.2531297206878662
Validation loss: 1.9869415362675984

Epoch: 349| Step: 0
Training loss: 0.3667435944080353
Validation loss: 2.001213471094767

Epoch: 6| Step: 1
Training loss: 0.2090684324502945
Validation loss: 1.9927765528361003

Epoch: 6| Step: 2
Training loss: 0.22891105711460114
Validation loss: 1.9543474515279133

Epoch: 6| Step: 3
Training loss: 0.5885202884674072
Validation loss: 1.9722605347633362

Epoch: 6| Step: 4
Training loss: 0.18353530764579773
Validation loss: 1.9938016931215923

Epoch: 6| Step: 5
Training loss: 0.1971849948167801
Validation loss: 1.9434377551078796

Epoch: 6| Step: 6
Training loss: 0.2889520525932312
Validation loss: 1.9838811953862507

Epoch: 6| Step: 7
Training loss: 0.3260270357131958
Validation loss: 1.9954325954119365

Epoch: 6| Step: 8
Training loss: 0.24016396701335907
Validation loss: 2.004880686601003

Epoch: 6| Step: 9
Training loss: 0.2577090263366699
Validation loss: 2.000989536444346

Epoch: 6| Step: 10
Training loss: 0.41454023122787476
Validation loss: 1.9772650003433228

Epoch: 6| Step: 11
Training loss: 0.37071168422698975
Validation loss: 1.9782501260439556

Epoch: 6| Step: 12
Training loss: 0.28773653507232666
Validation loss: 2.0067694981892905

Epoch: 6| Step: 13
Training loss: 0.17432180047035217
Validation loss: 1.99177082379659

Epoch: 350| Step: 0
Training loss: 0.3057664632797241
Validation loss: 1.9913084308306377

Epoch: 6| Step: 1
Training loss: 0.2235899418592453
Validation loss: 1.9868934949239094

Epoch: 6| Step: 2
Training loss: 0.24123692512512207
Validation loss: 1.9768390258153279

Epoch: 6| Step: 3
Training loss: 0.5064818859100342
Validation loss: 2.012286901473999

Epoch: 6| Step: 4
Training loss: 0.318648099899292
Validation loss: 2.006291608015696

Epoch: 6| Step: 5
Training loss: 0.2721330523490906
Validation loss: 1.9981784224510193

Epoch: 6| Step: 6
Training loss: 0.1884179711341858
Validation loss: 1.9884510238965352

Epoch: 6| Step: 7
Training loss: 0.14623160660266876
Validation loss: 1.961062749226888

Epoch: 6| Step: 8
Training loss: 0.3032730221748352
Validation loss: 1.9878482818603516

Epoch: 6| Step: 9
Training loss: 0.1347714364528656
Validation loss: 1.9607651034990947

Epoch: 6| Step: 10
Training loss: 0.2759612798690796
Validation loss: 2.003365159034729

Epoch: 6| Step: 11
Training loss: 0.268158882856369
Validation loss: 1.959423025449117

Epoch: 6| Step: 12
Training loss: 0.4156530797481537
Validation loss: 1.933680276075999

Epoch: 6| Step: 13
Training loss: 0.21750858426094055
Validation loss: 1.9703331589698792

Epoch: 351| Step: 0
Training loss: 0.2965957224369049
Validation loss: 1.9864624937375386

Epoch: 6| Step: 1
Training loss: 0.3417734205722809
Validation loss: 2.0066625475883484

Epoch: 6| Step: 2
Training loss: 0.2660219967365265
Validation loss: 1.959536075592041

Epoch: 6| Step: 3
Training loss: 0.31776392459869385
Validation loss: 1.9412352840105693

Epoch: 6| Step: 4
Training loss: 0.2250451147556305
Validation loss: 1.9746171832084656

Epoch: 6| Step: 5
Training loss: 0.1812918484210968
Validation loss: 1.9792030453681946

Epoch: 6| Step: 6
Training loss: 0.3044469952583313
Validation loss: 1.9684285918871562

Epoch: 6| Step: 7
Training loss: 0.2645883560180664
Validation loss: 1.9659150838851929

Epoch: 6| Step: 8
Training loss: 0.24243086576461792
Validation loss: 1.9807026783625286

Epoch: 6| Step: 9
Training loss: 0.26545196771621704
Validation loss: 1.968452513217926

Epoch: 6| Step: 10
Training loss: 0.1957889348268509
Validation loss: 1.9851320783297222

Epoch: 6| Step: 11
Training loss: 0.6263186931610107
Validation loss: 1.98858376344045

Epoch: 6| Step: 12
Training loss: 0.22403010725975037
Validation loss: 1.9947561025619507

Epoch: 6| Step: 13
Training loss: 0.4697493314743042
Validation loss: 2.0293425718943277

Epoch: 352| Step: 0
Training loss: 0.15536528825759888
Validation loss: 2.0104071696599326

Epoch: 6| Step: 1
Training loss: 0.2565770447254181
Validation loss: 2.0115312933921814

Epoch: 6| Step: 2
Training loss: 0.14708667993545532
Validation loss: 2.0076168974240622

Epoch: 6| Step: 3
Training loss: 0.27292346954345703
Validation loss: 1.9940407673517864

Epoch: 6| Step: 4
Training loss: 0.2344636619091034
Validation loss: 2.000742733478546

Epoch: 6| Step: 5
Training loss: 0.24033670127391815
Validation loss: 2.018891135851542

Epoch: 6| Step: 6
Training loss: 0.3299522399902344
Validation loss: 2.0014151334762573

Epoch: 6| Step: 7
Training loss: 0.48829203844070435
Validation loss: 2.003291587034861

Epoch: 6| Step: 8
Training loss: 0.3374136686325073
Validation loss: 1.9830116629600525

Epoch: 6| Step: 9
Training loss: 0.5596301555633545
Validation loss: 2.0204310218493142

Epoch: 6| Step: 10
Training loss: 0.31100964546203613
Validation loss: 1.9741000533103943

Epoch: 6| Step: 11
Training loss: 0.2649766206741333
Validation loss: 2.0036203066507974

Epoch: 6| Step: 12
Training loss: 0.14814697206020355
Validation loss: 1.9901045560836792

Epoch: 6| Step: 13
Training loss: 0.1788238137960434
Validation loss: 1.9937422076861064

Epoch: 353| Step: 0
Training loss: 0.210943341255188
Validation loss: 1.9987508654594421

Epoch: 6| Step: 1
Training loss: 0.3949829936027527
Validation loss: 1.9765613476435344

Epoch: 6| Step: 2
Training loss: 0.2796415090560913
Validation loss: 1.999295671780904

Epoch: 6| Step: 3
Training loss: 0.2514253556728363
Validation loss: 1.9923746188481648

Epoch: 6| Step: 4
Training loss: 0.20962125062942505
Validation loss: 2.003376543521881

Epoch: 6| Step: 5
Training loss: 0.1934681236743927
Validation loss: 1.9834679961204529

Epoch: 6| Step: 6
Training loss: 0.20143818855285645
Validation loss: 2.0349094470342

Epoch: 6| Step: 7
Training loss: 0.24205327033996582
Validation loss: 1.9859851002693176

Epoch: 6| Step: 8
Training loss: 0.22206252813339233
Validation loss: 1.9851155678431194

Epoch: 6| Step: 9
Training loss: 0.1887124478816986
Validation loss: 1.96663502852122

Epoch: 6| Step: 10
Training loss: 0.2360764741897583
Validation loss: 1.9715163509051006

Epoch: 6| Step: 11
Training loss: 0.32480180263519287
Validation loss: 1.9571850498517354

Epoch: 6| Step: 12
Training loss: 0.6071774959564209
Validation loss: 1.9599798917770386

Epoch: 6| Step: 13
Training loss: 0.19594210386276245
Validation loss: 1.993726631005605

Epoch: 354| Step: 0
Training loss: 0.39285486936569214
Validation loss: 1.9829605221748352

Epoch: 6| Step: 1
Training loss: 0.4025645852088928
Validation loss: 2.0202932159105935

Epoch: 6| Step: 2
Training loss: 0.30635198950767517
Validation loss: 1.9825178384780884

Epoch: 6| Step: 3
Training loss: 0.2452055811882019
Validation loss: 2.006012479464213

Epoch: 6| Step: 4
Training loss: 0.49520888924598694
Validation loss: 1.9910669326782227

Epoch: 6| Step: 5
Training loss: 0.30556946992874146
Validation loss: 1.994707504908244

Epoch: 6| Step: 6
Training loss: 0.23643282055854797
Validation loss: 2.0015547275543213

Epoch: 6| Step: 7
Training loss: 0.29019683599472046
Validation loss: 1.9935914675394695

Epoch: 6| Step: 8
Training loss: 0.2246549427509308
Validation loss: 1.9809890985488892

Epoch: 6| Step: 9
Training loss: 0.2565006613731384
Validation loss: 1.9874258041381836

Epoch: 6| Step: 10
Training loss: 0.1780097335577011
Validation loss: 1.9998796780904133

Epoch: 6| Step: 11
Training loss: 0.1899905651807785
Validation loss: 1.963747541109721

Epoch: 6| Step: 12
Training loss: 0.2007310837507248
Validation loss: 2.019882082939148

Epoch: 6| Step: 13
Training loss: 0.24031797051429749
Validation loss: 1.985666533311208

Epoch: 355| Step: 0
Training loss: 0.4541921615600586
Validation loss: 1.9762659668922424

Epoch: 6| Step: 1
Training loss: 0.24561062455177307
Validation loss: 1.9694304466247559

Epoch: 6| Step: 2
Training loss: 0.23234979808330536
Validation loss: 1.9538206060727437

Epoch: 6| Step: 3
Training loss: 0.31579896807670593
Validation loss: 1.9591317176818848

Epoch: 6| Step: 4
Training loss: 0.26747798919677734
Validation loss: 1.9761501550674438

Epoch: 6| Step: 5
Training loss: 0.20022708177566528
Validation loss: 1.9924730857213337

Epoch: 6| Step: 6
Training loss: 0.2070394903421402
Validation loss: 1.9350640376408894

Epoch: 6| Step: 7
Training loss: 0.5523935556411743
Validation loss: 1.9591945211092632

Epoch: 6| Step: 8
Training loss: 0.19055844843387604
Validation loss: 1.9743737777074177

Epoch: 6| Step: 9
Training loss: 0.2534150779247284
Validation loss: 2.0154186487197876

Epoch: 6| Step: 10
Training loss: 0.19142299890518188
Validation loss: 2.000885804494222

Epoch: 6| Step: 11
Training loss: 0.1968989074230194
Validation loss: 1.9633570909500122

Epoch: 6| Step: 12
Training loss: 0.32062190771102905
Validation loss: 1.970824162165324

Epoch: 6| Step: 13
Training loss: 0.3346170485019684
Validation loss: 2.0238245526949563

Epoch: 356| Step: 0
Training loss: 0.15008902549743652
Validation loss: 1.984798749287923

Epoch: 6| Step: 1
Training loss: 0.18650221824645996
Validation loss: 1.996299425760905

Epoch: 6| Step: 2
Training loss: 0.21514514088630676
Validation loss: 2.0075860222180686

Epoch: 6| Step: 3
Training loss: 0.22554218769073486
Validation loss: 1.9910847743352253

Epoch: 6| Step: 4
Training loss: 0.20792582631111145
Validation loss: 1.951567530632019

Epoch: 6| Step: 5
Training loss: 0.24668407440185547
Validation loss: 1.9624477624893188

Epoch: 6| Step: 6
Training loss: 0.34668171405792236
Validation loss: 1.9634439746538799

Epoch: 6| Step: 7
Training loss: 0.2203172743320465
Validation loss: 1.994536538918813

Epoch: 6| Step: 8
Training loss: 0.19699901342391968
Validation loss: 1.995766540368398

Epoch: 6| Step: 9
Training loss: 0.3176003694534302
Validation loss: 1.9927191336949666

Epoch: 6| Step: 10
Training loss: 0.42270737886428833
Validation loss: 1.9708640178044636

Epoch: 6| Step: 11
Training loss: 0.2367730438709259
Validation loss: 2.0258729656537375

Epoch: 6| Step: 12
Training loss: 0.20767393708229065
Validation loss: 2.0014081597328186

Epoch: 6| Step: 13
Training loss: 0.5748193860054016
Validation loss: 1.995652476946513

Epoch: 357| Step: 0
Training loss: 0.21704792976379395
Validation loss: 1.9943718512852986

Epoch: 6| Step: 1
Training loss: 0.1564142107963562
Validation loss: 2.028355280558268

Epoch: 6| Step: 2
Training loss: 0.21919026970863342
Validation loss: 1.9824039936065674

Epoch: 6| Step: 3
Training loss: 0.27087754011154175
Validation loss: 1.9779827793439229

Epoch: 6| Step: 4
Training loss: 0.3932898938655853
Validation loss: 2.0134330590566

Epoch: 6| Step: 5
Training loss: 0.14675310254096985
Validation loss: 2.0080081025759378

Epoch: 6| Step: 6
Training loss: 0.22941002249717712
Validation loss: 2.0177141626675925

Epoch: 6| Step: 7
Training loss: 0.2253371775150299
Validation loss: 1.9908153414726257

Epoch: 6| Step: 8
Training loss: 0.23065240681171417
Validation loss: 1.9850388566652934

Epoch: 6| Step: 9
Training loss: 0.27652835845947266
Validation loss: 2.0188777446746826

Epoch: 6| Step: 10
Training loss: 0.19562378525733948
Validation loss: 1.9853088061014812

Epoch: 6| Step: 11
Training loss: 0.27933207154273987
Validation loss: 1.9849673708279927

Epoch: 6| Step: 12
Training loss: 0.23846033215522766
Validation loss: 2.001171886920929

Epoch: 6| Step: 13
Training loss: 0.5924336910247803
Validation loss: 2.039125363032023

Epoch: 358| Step: 0
Training loss: 0.1737491637468338
Validation loss: 1.9693869352340698

Epoch: 6| Step: 1
Training loss: 0.2823784351348877
Validation loss: 2.0203380584716797

Epoch: 6| Step: 2
Training loss: 0.16922518610954285
Validation loss: 1.9935206572214763

Epoch: 6| Step: 3
Training loss: 0.19781488180160522
Validation loss: 1.9987247387568157

Epoch: 6| Step: 4
Training loss: 0.3666723966598511
Validation loss: 1.9789344867070515

Epoch: 6| Step: 5
Training loss: 0.19223952293395996
Validation loss: 1.9497654438018799

Epoch: 6| Step: 6
Training loss: 0.2427377849817276
Validation loss: 1.9602015217145283

Epoch: 6| Step: 7
Training loss: 0.3192298412322998
Validation loss: 1.9992693066596985

Epoch: 6| Step: 8
Training loss: 0.30942922830581665
Validation loss: 1.9901174306869507

Epoch: 6| Step: 9
Training loss: 0.5698868632316589
Validation loss: 1.9636026819547017

Epoch: 6| Step: 10
Training loss: 0.27224379777908325
Validation loss: 2.0275309085845947

Epoch: 6| Step: 11
Training loss: 0.2766997218132019
Validation loss: 1.9753659168879192

Epoch: 6| Step: 12
Training loss: 0.17691001296043396
Validation loss: 1.9727047284444172

Epoch: 6| Step: 13
Training loss: 0.39202895760536194
Validation loss: 1.9790552457173665

Epoch: 359| Step: 0
Training loss: 0.4022042751312256
Validation loss: 1.9566597143809001

Epoch: 6| Step: 1
Training loss: 0.17895129323005676
Validation loss: 1.9614166021347046

Epoch: 6| Step: 2
Training loss: 0.26247453689575195
Validation loss: 1.9996659954388936

Epoch: 6| Step: 3
Training loss: 0.26941025257110596
Validation loss: 2.012656033039093

Epoch: 6| Step: 4
Training loss: 0.21865954995155334
Validation loss: 1.9623871048291524

Epoch: 6| Step: 5
Training loss: 0.21942146122455597
Validation loss: 1.965555747350057

Epoch: 6| Step: 6
Training loss: 0.6159380674362183
Validation loss: 1.9573052724202473

Epoch: 6| Step: 7
Training loss: 0.1938464343547821
Validation loss: 1.9908704161643982

Epoch: 6| Step: 8
Training loss: 0.20677810907363892
Validation loss: 1.9756056269009907

Epoch: 6| Step: 9
Training loss: 0.293876588344574
Validation loss: 2.0151756405830383

Epoch: 6| Step: 10
Training loss: 0.30586472153663635
Validation loss: 1.997231125831604

Epoch: 6| Step: 11
Training loss: 0.32276201248168945
Validation loss: 1.9469390710194905

Epoch: 6| Step: 12
Training loss: 0.2538256049156189
Validation loss: 1.979131857554118

Epoch: 6| Step: 13
Training loss: 0.13804003596305847
Validation loss: 2.0280372301737466

Epoch: 360| Step: 0
Training loss: 0.3655809164047241
Validation loss: 2.012590448061625

Epoch: 6| Step: 1
Training loss: 0.28385138511657715
Validation loss: 1.966992974281311

Epoch: 6| Step: 2
Training loss: 0.22848352789878845
Validation loss: 1.9659955700238545

Epoch: 6| Step: 3
Training loss: 0.2695384621620178
Validation loss: 2.037892520427704

Epoch: 6| Step: 4
Training loss: 0.5282020568847656
Validation loss: 1.9933314522107441

Epoch: 6| Step: 5
Training loss: 0.1603560447692871
Validation loss: 2.002131541570028

Epoch: 6| Step: 6
Training loss: 0.1028558611869812
Validation loss: 2.013615449269613

Epoch: 6| Step: 7
Training loss: 0.2030002474784851
Validation loss: 1.9996507962544758

Epoch: 6| Step: 8
Training loss: 0.28356999158859253
Validation loss: 2.0233622392018638

Epoch: 6| Step: 9
Training loss: 0.18791183829307556
Validation loss: 2.031021694342295

Epoch: 6| Step: 10
Training loss: 0.17574837803840637
Validation loss: 2.0035221378008523

Epoch: 6| Step: 11
Training loss: 0.31509995460510254
Validation loss: 2.001116613547007

Epoch: 6| Step: 12
Training loss: 0.2543458342552185
Validation loss: 1.9795616467793782

Epoch: 6| Step: 13
Training loss: 0.3233652114868164
Validation loss: 1.9579485456148784

Epoch: 361| Step: 0
Training loss: 0.5214210748672485
Validation loss: 2.0532634258270264

Epoch: 6| Step: 1
Training loss: 0.20405209064483643
Validation loss: 1.9951265255610149

Epoch: 6| Step: 2
Training loss: 0.2030559778213501
Validation loss: 1.968133568763733

Epoch: 6| Step: 3
Training loss: 0.21066482365131378
Validation loss: 1.986630658308665

Epoch: 6| Step: 4
Training loss: 0.29221805930137634
Validation loss: 2.0390395323435464

Epoch: 6| Step: 5
Training loss: 0.17957361042499542
Validation loss: 1.9618796706199646

Epoch: 6| Step: 6
Training loss: 0.1405813843011856
Validation loss: 1.9994978706041973

Epoch: 6| Step: 7
Training loss: 0.19783209264278412
Validation loss: 1.9955528577168782

Epoch: 6| Step: 8
Training loss: 0.559593915939331
Validation loss: 1.9885538617769878

Epoch: 6| Step: 9
Training loss: 0.23491430282592773
Validation loss: 1.9795022408167522

Epoch: 6| Step: 10
Training loss: 0.27440589666366577
Validation loss: 1.9984353184700012

Epoch: 6| Step: 11
Training loss: 0.32481086254119873
Validation loss: 1.962918996810913

Epoch: 6| Step: 12
Training loss: 0.2567898631095886
Validation loss: 2.0056315263112388

Epoch: 6| Step: 13
Training loss: 0.2891732454299927
Validation loss: 1.9880731503168743

Epoch: 362| Step: 0
Training loss: 0.2800239324569702
Validation loss: 1.9538435339927673

Epoch: 6| Step: 1
Training loss: 0.1987486481666565
Validation loss: 1.9712803562482197

Epoch: 6| Step: 2
Training loss: 0.17852210998535156
Validation loss: 1.9645344614982605

Epoch: 6| Step: 3
Training loss: 0.621577262878418
Validation loss: 1.978507161140442

Epoch: 6| Step: 4
Training loss: 0.3479597270488739
Validation loss: 1.9845754702885945

Epoch: 6| Step: 5
Training loss: 0.33008480072021484
Validation loss: 2.0130478143692017

Epoch: 6| Step: 6
Training loss: 0.28635868430137634
Validation loss: 1.9762478272120159

Epoch: 6| Step: 7
Training loss: 0.2113618552684784
Validation loss: 1.9736384749412537

Epoch: 6| Step: 8
Training loss: 0.2760891616344452
Validation loss: 1.991170068581899

Epoch: 6| Step: 9
Training loss: 0.42221328616142273
Validation loss: 1.9660546779632568

Epoch: 6| Step: 10
Training loss: 0.3285122811794281
Validation loss: 1.9958263436953227

Epoch: 6| Step: 11
Training loss: 0.20425419509410858
Validation loss: 1.98577876885732

Epoch: 6| Step: 12
Training loss: 0.1449960470199585
Validation loss: 1.9807870388031006

Epoch: 6| Step: 13
Training loss: 0.2845827341079712
Validation loss: 1.9906329313913982

Epoch: 363| Step: 0
Training loss: 0.33482417464256287
Validation loss: 2.0212472677230835

Epoch: 6| Step: 1
Training loss: 0.4684693217277527
Validation loss: 2.0078357458114624

Epoch: 6| Step: 2
Training loss: 0.20499616861343384
Validation loss: 2.041171073913574

Epoch: 6| Step: 3
Training loss: 0.6007818579673767
Validation loss: 2.036479969819387

Epoch: 6| Step: 4
Training loss: 0.2767341732978821
Validation loss: 2.047780474026998

Epoch: 6| Step: 5
Training loss: 0.24530768394470215
Validation loss: 2.007729093233744

Epoch: 6| Step: 6
Training loss: 0.20237170159816742
Validation loss: 2.0000468095143638

Epoch: 6| Step: 7
Training loss: 0.2821251153945923
Validation loss: 2.0015812317530313

Epoch: 6| Step: 8
Training loss: 0.25547540187835693
Validation loss: 1.987945278485616

Epoch: 6| Step: 9
Training loss: 0.16707393527030945
Validation loss: 1.95987468957901

Epoch: 6| Step: 10
Training loss: 0.26820725202560425
Validation loss: 1.9951242208480835

Epoch: 6| Step: 11
Training loss: 0.11986523866653442
Validation loss: 1.988665779431661

Epoch: 6| Step: 12
Training loss: 0.17401540279388428
Validation loss: 1.9709115624427795

Epoch: 6| Step: 13
Training loss: 0.3103182017803192
Validation loss: 1.988145112991333

Epoch: 364| Step: 0
Training loss: 0.19942322373390198
Validation loss: 2.0133601427078247

Epoch: 6| Step: 1
Training loss: 0.19904285669326782
Validation loss: 1.9654714465141296

Epoch: 6| Step: 2
Training loss: 0.22725743055343628
Validation loss: 1.9389331738154094

Epoch: 6| Step: 3
Training loss: 0.299138605594635
Validation loss: 1.9975251356760662

Epoch: 6| Step: 4
Training loss: 0.39915043115615845
Validation loss: 1.9590344826380413

Epoch: 6| Step: 5
Training loss: 0.25503987073898315
Validation loss: 2.0086689790089927

Epoch: 6| Step: 6
Training loss: 0.1714707463979721
Validation loss: 2.004812757174174

Epoch: 6| Step: 7
Training loss: 0.22681765258312225
Validation loss: 1.96425861120224

Epoch: 6| Step: 8
Training loss: 0.20503100752830505
Validation loss: 2.0027523040771484

Epoch: 6| Step: 9
Training loss: 0.11661840230226517
Validation loss: 2.0041646162668862

Epoch: 6| Step: 10
Training loss: 0.6074153184890747
Validation loss: 1.9750539263089497

Epoch: 6| Step: 11
Training loss: 0.2763507664203644
Validation loss: 1.9674618641535442

Epoch: 6| Step: 12
Training loss: 0.24476498365402222
Validation loss: 1.9974480470021565

Epoch: 6| Step: 13
Training loss: 0.216887965798378
Validation loss: 2.000968257586161

Epoch: 365| Step: 0
Training loss: 0.18686166405677795
Validation loss: 1.964830497900645

Epoch: 6| Step: 1
Training loss: 0.3614393174648285
Validation loss: 1.9792949159940083

Epoch: 6| Step: 2
Training loss: 0.24815987050533295
Validation loss: 2.018000066280365

Epoch: 6| Step: 3
Training loss: 0.20370514690876007
Validation loss: 2.027181386947632

Epoch: 6| Step: 4
Training loss: 0.40980371832847595
Validation loss: 1.97530464331309

Epoch: 6| Step: 5
Training loss: 0.2110237330198288
Validation loss: 1.97915385166804

Epoch: 6| Step: 6
Training loss: 0.6120879054069519
Validation loss: 1.996280590693156

Epoch: 6| Step: 7
Training loss: 0.305481493473053
Validation loss: 2.044818878173828

Epoch: 6| Step: 8
Training loss: 0.2443164587020874
Validation loss: 1.9861802061398823

Epoch: 6| Step: 9
Training loss: 0.15679152309894562
Validation loss: 1.966396192709605

Epoch: 6| Step: 10
Training loss: 0.28467559814453125
Validation loss: 1.9859681725502014

Epoch: 6| Step: 11
Training loss: 0.1289084106683731
Validation loss: 2.0043166677157083

Epoch: 6| Step: 12
Training loss: 0.2832415699958801
Validation loss: 1.9870529174804688

Epoch: 6| Step: 13
Training loss: 0.17565195262432098
Validation loss: 1.9970503449440002

Epoch: 366| Step: 0
Training loss: 0.26495617628097534
Validation loss: 1.9759564399719238

Epoch: 6| Step: 1
Training loss: 0.22906498610973358
Validation loss: 2.0158295234044394

Epoch: 6| Step: 2
Training loss: 0.22132568061351776
Validation loss: 1.975101073582967

Epoch: 6| Step: 3
Training loss: 0.3401796817779541
Validation loss: 1.9676769177118938

Epoch: 6| Step: 4
Training loss: 0.2929050326347351
Validation loss: 1.9998186429341633

Epoch: 6| Step: 5
Training loss: 0.39165595173835754
Validation loss: 1.9887423714001973

Epoch: 6| Step: 6
Training loss: 0.1664901077747345
Validation loss: 1.9487602710723877

Epoch: 6| Step: 7
Training loss: 0.17696893215179443
Validation loss: 2.016439934571584

Epoch: 6| Step: 8
Training loss: 0.29206815361976624
Validation loss: 1.9962951143582661

Epoch: 6| Step: 9
Training loss: 0.21982696652412415
Validation loss: 2.004457632700602

Epoch: 6| Step: 10
Training loss: 0.2730872631072998
Validation loss: 1.9988227486610413

Epoch: 6| Step: 11
Training loss: 0.2651979327201843
Validation loss: 1.9999967614809673

Epoch: 6| Step: 12
Training loss: 0.6446118950843811
Validation loss: 1.9772011439005535

Epoch: 6| Step: 13
Training loss: 0.2633725106716156
Validation loss: 1.998811662197113

Epoch: 367| Step: 0
Training loss: 0.5544351935386658
Validation loss: 1.9877057075500488

Epoch: 6| Step: 1
Training loss: 0.23426009714603424
Validation loss: 2.0009889801343284

Epoch: 6| Step: 2
Training loss: 0.32169264554977417
Validation loss: 2.023259480794271

Epoch: 6| Step: 3
Training loss: 0.3646959066390991
Validation loss: 2.00576784213384

Epoch: 6| Step: 4
Training loss: 0.3858913481235504
Validation loss: 1.9826325972874959

Epoch: 6| Step: 5
Training loss: 0.2199767678976059
Validation loss: 2.0372294187545776

Epoch: 6| Step: 6
Training loss: 0.22407492995262146
Validation loss: 1.9635266065597534

Epoch: 6| Step: 7
Training loss: 0.1619405448436737
Validation loss: 1.9876947005589802

Epoch: 6| Step: 8
Training loss: 0.18338358402252197
Validation loss: 1.994928002357483

Epoch: 6| Step: 9
Training loss: 0.3300684690475464
Validation loss: 2.008924384911855

Epoch: 6| Step: 10
Training loss: 0.19830332696437836
Validation loss: 1.993794043858846

Epoch: 6| Step: 11
Training loss: 0.23292101919651031
Validation loss: 1.9614540139834087

Epoch: 6| Step: 12
Training loss: 0.2315208613872528
Validation loss: 1.9639924764633179

Epoch: 6| Step: 13
Training loss: 0.23325693607330322
Validation loss: 2.0196682016054788

Epoch: 368| Step: 0
Training loss: 0.16450700163841248
Validation loss: 1.9710893630981445

Epoch: 6| Step: 1
Training loss: 0.19850309193134308
Validation loss: 1.9867316683133442

Epoch: 6| Step: 2
Training loss: 0.1793312281370163
Validation loss: 1.9807228644688923

Epoch: 6| Step: 3
Training loss: 0.24942150712013245
Validation loss: 2.0343740383783975

Epoch: 6| Step: 4
Training loss: 0.31727030873298645
Validation loss: 2.0059231519699097

Epoch: 6| Step: 5
Training loss: 0.33113083243370056
Validation loss: 1.9500251412391663

Epoch: 6| Step: 6
Training loss: 0.20494407415390015
Validation loss: 1.9999188979466755

Epoch: 6| Step: 7
Training loss: 0.26522302627563477
Validation loss: 1.9975552956263225

Epoch: 6| Step: 8
Training loss: 0.6634090542793274
Validation loss: 1.9956673979759216

Epoch: 6| Step: 9
Training loss: 0.3459833562374115
Validation loss: 1.9818022052447002

Epoch: 6| Step: 10
Training loss: 0.3070988059043884
Validation loss: 1.9777663747469585

Epoch: 6| Step: 11
Training loss: 0.32756638526916504
Validation loss: 2.006707032521566

Epoch: 6| Step: 12
Training loss: 0.139302596449852
Validation loss: 2.017132878303528

Epoch: 6| Step: 13
Training loss: 0.19206473231315613
Validation loss: 2.0058388710021973

Epoch: 369| Step: 0
Training loss: 0.3190595209598541
Validation loss: 1.9875750541687012

Epoch: 6| Step: 1
Training loss: 0.3818356394767761
Validation loss: 1.9992823998133342

Epoch: 6| Step: 2
Training loss: 0.14826849102973938
Validation loss: 1.9519574244817097

Epoch: 6| Step: 3
Training loss: 0.16374081373214722
Validation loss: 2.0041680137316384

Epoch: 6| Step: 4
Training loss: 0.5813825726509094
Validation loss: 1.9961690704027812

Epoch: 6| Step: 5
Training loss: 0.188747376203537
Validation loss: 2.0222949385643005

Epoch: 6| Step: 6
Training loss: 0.1555553674697876
Validation loss: 2.0344175895055137

Epoch: 6| Step: 7
Training loss: 0.27643081545829773
Validation loss: 1.9850938717524211

Epoch: 6| Step: 8
Training loss: 0.217445507645607
Validation loss: 1.9713637630144756

Epoch: 6| Step: 9
Training loss: 0.2062993347644806
Validation loss: 1.9830581744511921

Epoch: 6| Step: 10
Training loss: 0.1868688464164734
Validation loss: 2.0071616570154824

Epoch: 6| Step: 11
Training loss: 0.15347599983215332
Validation loss: 1.980886181195577

Epoch: 6| Step: 12
Training loss: 0.3203035295009613
Validation loss: 1.976153055826823

Epoch: 6| Step: 13
Training loss: 0.3953205645084381
Validation loss: 1.968787709871928

Epoch: 370| Step: 0
Training loss: 0.28567060828208923
Validation loss: 2.0142844319343567

Epoch: 6| Step: 1
Training loss: 0.19207146763801575
Validation loss: 1.9856074055035908

Epoch: 6| Step: 2
Training loss: 0.23717784881591797
Validation loss: 2.0111491680145264

Epoch: 6| Step: 3
Training loss: 0.5181461572647095
Validation loss: 2.0055560072263083

Epoch: 6| Step: 4
Training loss: 0.24582260847091675
Validation loss: 2.0193230907122293

Epoch: 6| Step: 5
Training loss: 0.3686367869377136
Validation loss: 2.0015180508295694

Epoch: 6| Step: 6
Training loss: 0.17614349722862244
Validation loss: 1.9887923796971638

Epoch: 6| Step: 7
Training loss: 0.4079856872558594
Validation loss: 1.9456996122996013

Epoch: 6| Step: 8
Training loss: 0.13880476355552673
Validation loss: 1.9850229024887085

Epoch: 6| Step: 9
Training loss: 0.5897033214569092
Validation loss: 1.9918091495831807

Epoch: 6| Step: 10
Training loss: 0.34264060854911804
Validation loss: 2.0001055002212524

Epoch: 6| Step: 11
Training loss: 0.40311214327812195
Validation loss: 1.988781213760376

Epoch: 6| Step: 12
Training loss: 0.46353262662887573
Validation loss: 1.995854636033376

Epoch: 6| Step: 13
Training loss: 0.21530681848526
Validation loss: 1.9497878352801006

Epoch: 371| Step: 0
Training loss: 0.22267913818359375
Validation loss: 1.9761238892873128

Epoch: 6| Step: 1
Training loss: 0.33659598231315613
Validation loss: 1.9745281140009563

Epoch: 6| Step: 2
Training loss: 0.24842469394207
Validation loss: 1.9952495098114014

Epoch: 6| Step: 3
Training loss: 0.3021836280822754
Validation loss: 1.9691718618075054

Epoch: 6| Step: 4
Training loss: 0.4532056748867035
Validation loss: 1.999171495437622

Epoch: 6| Step: 5
Training loss: 0.35016873478889465
Validation loss: 1.9963230888048809

Epoch: 6| Step: 6
Training loss: 0.27264559268951416
Validation loss: 1.9997711976369221

Epoch: 6| Step: 7
Training loss: 0.38073277473449707
Validation loss: 1.9849623441696167

Epoch: 6| Step: 8
Training loss: 0.4686076045036316
Validation loss: 1.9819396535555522

Epoch: 6| Step: 9
Training loss: 0.2329631894826889
Validation loss: 1.9735462069511414

Epoch: 6| Step: 10
Training loss: 0.11327015608549118
Validation loss: 1.9381992816925049

Epoch: 6| Step: 11
Training loss: 0.2684769630432129
Validation loss: 1.975269079208374

Epoch: 6| Step: 12
Training loss: 0.5013513565063477
Validation loss: 1.9982354640960693

Epoch: 6| Step: 13
Training loss: 0.2143716961145401
Validation loss: 2.026910940806071

Epoch: 372| Step: 0
Training loss: 0.4279276132583618
Validation loss: 1.9902218381563823

Epoch: 6| Step: 1
Training loss: 0.22610624134540558
Validation loss: 2.006578783194224

Epoch: 6| Step: 2
Training loss: 0.1907854974269867
Validation loss: 1.9607378840446472

Epoch: 6| Step: 3
Training loss: 0.18609662353992462
Validation loss: 2.0147369106610618

Epoch: 6| Step: 4
Training loss: 0.2506958246231079
Validation loss: 1.9881807168324788

Epoch: 6| Step: 5
Training loss: 0.22593620419502258
Validation loss: 1.974066138267517

Epoch: 6| Step: 6
Training loss: 0.5549179315567017
Validation loss: 1.9620058337847393

Epoch: 6| Step: 7
Training loss: 0.33919474482536316
Validation loss: 1.9808305303255718

Epoch: 6| Step: 8
Training loss: 0.17936845123767853
Validation loss: 1.9690518577893574

Epoch: 6| Step: 9
Training loss: 0.15628384053707123
Validation loss: 2.020168741544088

Epoch: 6| Step: 10
Training loss: 0.1930062174797058
Validation loss: 1.9983203609784443

Epoch: 6| Step: 11
Training loss: 0.16600055992603302
Validation loss: 1.9964260061581929

Epoch: 6| Step: 12
Training loss: 0.2997593283653259
Validation loss: 1.997198184331258

Epoch: 6| Step: 13
Training loss: 0.23565155267715454
Validation loss: 1.9991117715835571

Epoch: 373| Step: 0
Training loss: 0.1845189779996872
Validation loss: 1.9643911719322205

Epoch: 6| Step: 1
Training loss: 0.19561214745044708
Validation loss: 1.9538601239522297

Epoch: 6| Step: 2
Training loss: 0.17765849828720093
Validation loss: 1.9533866842587788

Epoch: 6| Step: 3
Training loss: 0.3709888458251953
Validation loss: 1.9895981152852376

Epoch: 6| Step: 4
Training loss: 0.4162520170211792
Validation loss: 1.984375814596812

Epoch: 6| Step: 5
Training loss: 0.23151108622550964
Validation loss: 1.9878686269124348

Epoch: 6| Step: 6
Training loss: 0.15945112705230713
Validation loss: 2.0201679468154907

Epoch: 6| Step: 7
Training loss: 0.15230494737625122
Validation loss: 1.985027015209198

Epoch: 6| Step: 8
Training loss: 0.17165371775627136
Validation loss: 1.984412133693695

Epoch: 6| Step: 9
Training loss: 0.3504694104194641
Validation loss: 1.9859737356503804

Epoch: 6| Step: 10
Training loss: 0.2644723653793335
Validation loss: 2.006291468938192

Epoch: 6| Step: 11
Training loss: 0.6239471435546875
Validation loss: 1.9872760375340779

Epoch: 6| Step: 12
Training loss: 0.20002463459968567
Validation loss: 1.9764071702957153

Epoch: 6| Step: 13
Training loss: 0.25424158573150635
Validation loss: 1.9731403787930806

Epoch: 374| Step: 0
Training loss: 0.23143863677978516
Validation loss: 1.9977719982465107

Epoch: 6| Step: 1
Training loss: 0.3510804772377014
Validation loss: 2.019376834233602

Epoch: 6| Step: 2
Training loss: 0.2773582637310028
Validation loss: 1.9699236750602722

Epoch: 6| Step: 3
Training loss: 0.25546467304229736
Validation loss: 2.0212369362513223

Epoch: 6| Step: 4
Training loss: 0.131479412317276
Validation loss: 1.9370061953862507

Epoch: 6| Step: 5
Training loss: 0.4335649013519287
Validation loss: 2.024020810921987

Epoch: 6| Step: 6
Training loss: 0.2804412543773651
Validation loss: 2.0256951451301575

Epoch: 6| Step: 7
Training loss: 0.30880093574523926
Validation loss: 1.9868127703666687

Epoch: 6| Step: 8
Training loss: 0.14425209164619446
Validation loss: 1.963219165802002

Epoch: 6| Step: 9
Training loss: 0.3696669936180115
Validation loss: 1.982362727324168

Epoch: 6| Step: 10
Training loss: 0.16610608994960785
Validation loss: 1.9922423958778381

Epoch: 6| Step: 11
Training loss: 0.147138774394989
Validation loss: 1.9996941288312275

Epoch: 6| Step: 12
Training loss: 0.5416046977043152
Validation loss: 1.991097907225291

Epoch: 6| Step: 13
Training loss: 0.333041250705719
Validation loss: 1.9712395270665486

Epoch: 375| Step: 0
Training loss: 0.1970839500427246
Validation loss: 1.9514578978220622

Epoch: 6| Step: 1
Training loss: 0.21316973865032196
Validation loss: 1.9729165236155193

Epoch: 6| Step: 2
Training loss: 0.33228251338005066
Validation loss: 2.0121198892593384

Epoch: 6| Step: 3
Training loss: 0.26893240213394165
Validation loss: 1.9883300463358562

Epoch: 6| Step: 4
Training loss: 0.38227880001068115
Validation loss: 1.9620626370112102

Epoch: 6| Step: 5
Training loss: 0.4042065441608429
Validation loss: 1.9559923807779949

Epoch: 6| Step: 6
Training loss: 0.15941019356250763
Validation loss: 1.944707214832306

Epoch: 6| Step: 7
Training loss: 0.3950055241584778
Validation loss: 1.9618146618207295

Epoch: 6| Step: 8
Training loss: 0.6244586706161499
Validation loss: 1.9570945501327515

Epoch: 6| Step: 9
Training loss: 0.16549959778785706
Validation loss: 1.9898208181063335

Epoch: 6| Step: 10
Training loss: 0.23725539445877075
Validation loss: 1.9531919757525127

Epoch: 6| Step: 11
Training loss: 0.13833776116371155
Validation loss: 1.9866296648979187

Epoch: 6| Step: 12
Training loss: 0.22350892424583435
Validation loss: 2.002744177977244

Epoch: 6| Step: 13
Training loss: 0.1402951329946518
Validation loss: 1.9750560720761616

Epoch: 376| Step: 0
Training loss: 0.14773479104042053
Validation loss: 1.9677911202112834

Epoch: 6| Step: 1
Training loss: 0.1221054196357727
Validation loss: 2.0129323999087014

Epoch: 6| Step: 2
Training loss: 0.2097516506910324
Validation loss: 1.9688413540522258

Epoch: 6| Step: 3
Training loss: 0.27639952301979065
Validation loss: 1.9787225524584453

Epoch: 6| Step: 4
Training loss: 0.5373847484588623
Validation loss: 2.0094122091929116

Epoch: 6| Step: 5
Training loss: 0.2279164046049118
Validation loss: 2.0001511176427207

Epoch: 6| Step: 6
Training loss: 0.1950150430202484
Validation loss: 1.9781833291053772

Epoch: 6| Step: 7
Training loss: 0.14561253786087036
Validation loss: 1.9528724749883015

Epoch: 6| Step: 8
Training loss: 0.2640216052532196
Validation loss: 1.9951144655545552

Epoch: 6| Step: 9
Training loss: 0.31815028190612793
Validation loss: 1.9612526496251423

Epoch: 6| Step: 10
Training loss: 0.26208704710006714
Validation loss: 2.0132925311724343

Epoch: 6| Step: 11
Training loss: 0.4683511555194855
Validation loss: 1.9724273284276326

Epoch: 6| Step: 12
Training loss: 0.20265857875347137
Validation loss: 1.9503473838170369

Epoch: 6| Step: 13
Training loss: 0.4052813649177551
Validation loss: 1.9622549811999004

Epoch: 377| Step: 0
Training loss: 0.226950541138649
Validation loss: 1.947936475276947

Epoch: 6| Step: 1
Training loss: 0.3756943345069885
Validation loss: 1.94089541832606

Epoch: 6| Step: 2
Training loss: 0.2653654217720032
Validation loss: 1.982930878798167

Epoch: 6| Step: 3
Training loss: 0.6222726106643677
Validation loss: 1.988756497701009

Epoch: 6| Step: 4
Training loss: 0.19656723737716675
Validation loss: 1.9696749448776245

Epoch: 6| Step: 5
Training loss: 0.2366296499967575
Validation loss: 1.9736038446426392

Epoch: 6| Step: 6
Training loss: 0.19536562263965607
Validation loss: 1.9725443522135417

Epoch: 6| Step: 7
Training loss: 0.27852892875671387
Validation loss: 1.9769988457361858

Epoch: 6| Step: 8
Training loss: 0.14227628707885742
Validation loss: 2.0032838582992554

Epoch: 6| Step: 9
Training loss: 0.20200639963150024
Validation loss: 1.970370928446452

Epoch: 6| Step: 10
Training loss: 0.18747246265411377
Validation loss: 1.9819088180859883

Epoch: 6| Step: 11
Training loss: 0.1675812304019928
Validation loss: 2.0088289380073547

Epoch: 6| Step: 12
Training loss: 0.16880866885185242
Validation loss: 1.9705410202344258

Epoch: 6| Step: 13
Training loss: 0.197895348072052
Validation loss: 1.9687498807907104

Epoch: 378| Step: 0
Training loss: 0.17124320566654205
Validation loss: 1.9947980841000874

Epoch: 6| Step: 1
Training loss: 0.3361806571483612
Validation loss: 1.9612274765968323

Epoch: 6| Step: 2
Training loss: 0.26653432846069336
Validation loss: 1.9669237732887268

Epoch: 6| Step: 3
Training loss: 0.23784515261650085
Validation loss: 1.972688376903534

Epoch: 6| Step: 4
Training loss: 0.18902750313282013
Validation loss: 1.9992598692576091

Epoch: 6| Step: 5
Training loss: 0.2369225025177002
Validation loss: 1.9713844060897827

Epoch: 6| Step: 6
Training loss: 0.1726762056350708
Validation loss: 1.9809078772862752

Epoch: 6| Step: 7
Training loss: 0.16647282242774963
Validation loss: 1.988875408967336

Epoch: 6| Step: 8
Training loss: 0.26592573523521423
Validation loss: 1.9587286909421284

Epoch: 6| Step: 9
Training loss: 0.2572827935218811
Validation loss: 1.9802776376406352

Epoch: 6| Step: 10
Training loss: 0.16991253197193146
Validation loss: 1.9705397486686707

Epoch: 6| Step: 11
Training loss: 0.2654806971549988
Validation loss: 1.9783252676328023

Epoch: 6| Step: 12
Training loss: 0.12934911251068115
Validation loss: 1.9942856232325237

Epoch: 6| Step: 13
Training loss: 0.6515282392501831
Validation loss: 1.9776662985483806

Epoch: 379| Step: 0
Training loss: 0.1674318015575409
Validation loss: 1.9550644159317017

Epoch: 6| Step: 1
Training loss: 0.1950235515832901
Validation loss: 1.98185533285141

Epoch: 6| Step: 2
Training loss: 0.1881660521030426
Validation loss: 1.9733102718989055

Epoch: 6| Step: 3
Training loss: 0.28557661175727844
Validation loss: 1.9619924227396648

Epoch: 6| Step: 4
Training loss: 0.1886790692806244
Validation loss: 1.9650218685468037

Epoch: 6| Step: 5
Training loss: 0.13785003125667572
Validation loss: 1.9985813697179158

Epoch: 6| Step: 6
Training loss: 0.14366787672042847
Validation loss: 1.9939159154891968

Epoch: 6| Step: 7
Training loss: 0.2227780520915985
Validation loss: 2.0030640363693237

Epoch: 6| Step: 8
Training loss: 0.42727798223495483
Validation loss: 1.9860894878705342

Epoch: 6| Step: 9
Training loss: 0.2487400770187378
Validation loss: 1.9572582840919495

Epoch: 6| Step: 10
Training loss: 0.28386569023132324
Validation loss: 1.965220868587494

Epoch: 6| Step: 11
Training loss: 0.2760903835296631
Validation loss: 1.965558389822642

Epoch: 6| Step: 12
Training loss: 0.3021409511566162
Validation loss: 1.9704485138257344

Epoch: 6| Step: 13
Training loss: 0.6567040085792542
Validation loss: 1.9929402470588684

Epoch: 380| Step: 0
Training loss: 0.1608194261789322
Validation loss: 1.9698464671770732

Epoch: 6| Step: 1
Training loss: 0.3227664828300476
Validation loss: 1.9986868302027385

Epoch: 6| Step: 2
Training loss: 0.21144524216651917
Validation loss: 2.0022041400273642

Epoch: 6| Step: 3
Training loss: 0.5744174718856812
Validation loss: 1.9598467151323955

Epoch: 6| Step: 4
Training loss: 0.1992073655128479
Validation loss: 2.0080392956733704

Epoch: 6| Step: 5
Training loss: 0.17748385667800903
Validation loss: 1.9931101004282634

Epoch: 6| Step: 6
Training loss: 0.2734817862510681
Validation loss: 1.966080665588379

Epoch: 6| Step: 7
Training loss: 0.2753893733024597
Validation loss: 1.960339347521464

Epoch: 6| Step: 8
Training loss: 0.19365155696868896
Validation loss: 1.9549739758173625

Epoch: 6| Step: 9
Training loss: 0.3454524874687195
Validation loss: 1.9642346302668254

Epoch: 6| Step: 10
Training loss: 0.3776640295982361
Validation loss: 2.011759599049886

Epoch: 6| Step: 11
Training loss: 0.3736828565597534
Validation loss: 1.9811580777168274

Epoch: 6| Step: 12
Training loss: 0.38778582215309143
Validation loss: 1.9577781955401103

Epoch: 6| Step: 13
Training loss: 0.32247284054756165
Validation loss: 1.9610240459442139

Epoch: 381| Step: 0
Training loss: 0.1459793746471405
Validation loss: 1.9634325504302979

Epoch: 6| Step: 1
Training loss: 0.2921890616416931
Validation loss: 1.952170471350352

Epoch: 6| Step: 2
Training loss: 0.6912317276000977
Validation loss: 1.9488136370976765

Epoch: 6| Step: 3
Training loss: 0.2650008201599121
Validation loss: 1.9504291613896687

Epoch: 6| Step: 4
Training loss: 0.19712787866592407
Validation loss: 1.9625626007715862

Epoch: 6| Step: 5
Training loss: 0.2677810490131378
Validation loss: 1.958220382531484

Epoch: 6| Step: 6
Training loss: 0.2728309631347656
Validation loss: 1.9552363952000935

Epoch: 6| Step: 7
Training loss: 0.3717302680015564
Validation loss: 1.9374752442042034

Epoch: 6| Step: 8
Training loss: 0.2154686450958252
Validation loss: 1.9702562093734741

Epoch: 6| Step: 9
Training loss: 0.17423002421855927
Validation loss: 1.9839595953623455

Epoch: 6| Step: 10
Training loss: 0.164741650223732
Validation loss: 1.9817240635553997

Epoch: 6| Step: 11
Training loss: 0.2354467362165451
Validation loss: 1.9716641306877136

Epoch: 6| Step: 12
Training loss: 0.20751574635505676
Validation loss: 1.981457273165385

Epoch: 6| Step: 13
Training loss: 0.18495683372020721
Validation loss: 1.9717038869857788

Epoch: 382| Step: 0
Training loss: 0.28043925762176514
Validation loss: 1.973870575428009

Epoch: 6| Step: 1
Training loss: 0.6630216240882874
Validation loss: 1.9712132811546326

Epoch: 6| Step: 2
Training loss: 0.18087290227413177
Validation loss: 1.9845630129178364

Epoch: 6| Step: 3
Training loss: 0.23093575239181519
Validation loss: 1.965894877910614

Epoch: 6| Step: 4
Training loss: 0.16691644489765167
Validation loss: 2.0407491525014243

Epoch: 6| Step: 5
Training loss: 0.18020519614219666
Validation loss: 1.9905096292495728

Epoch: 6| Step: 6
Training loss: 0.20686274766921997
Validation loss: 1.9837201436360676

Epoch: 6| Step: 7
Training loss: 0.4441160261631012
Validation loss: 1.9718474348386128

Epoch: 6| Step: 8
Training loss: 0.1611095666885376
Validation loss: 1.9697347680727642

Epoch: 6| Step: 9
Training loss: 0.31907856464385986
Validation loss: 2.014129122098287

Epoch: 6| Step: 10
Training loss: 0.20454037189483643
Validation loss: 1.9815780321757

Epoch: 6| Step: 11
Training loss: 0.16115045547485352
Validation loss: 1.9878194530804951

Epoch: 6| Step: 12
Training loss: 0.26399487257003784
Validation loss: 1.9722306728363037

Epoch: 6| Step: 13
Training loss: 0.24566899240016937
Validation loss: 1.9411296049753826

Epoch: 383| Step: 0
Training loss: 0.2509631812572479
Validation loss: 1.9943856795628865

Epoch: 6| Step: 1
Training loss: 0.34041449427604675
Validation loss: 1.9619521101315816

Epoch: 6| Step: 2
Training loss: 0.30851027369499207
Validation loss: 1.9486830234527588

Epoch: 6| Step: 3
Training loss: 0.19843408465385437
Validation loss: 1.9403675397237141

Epoch: 6| Step: 4
Training loss: 0.2544252872467041
Validation loss: 1.9769934217135112

Epoch: 6| Step: 5
Training loss: 0.26729655265808105
Validation loss: 1.9573842684427898

Epoch: 6| Step: 6
Training loss: 0.17972443997859955
Validation loss: 1.966573973496755

Epoch: 6| Step: 7
Training loss: 0.20714613795280457
Validation loss: 1.965707262357076

Epoch: 6| Step: 8
Training loss: 0.39085331559181213
Validation loss: 1.9806851744651794

Epoch: 6| Step: 9
Training loss: 0.21060529351234436
Validation loss: 1.9661926627159119

Epoch: 6| Step: 10
Training loss: 0.31312987208366394
Validation loss: 1.9384363492329915

Epoch: 6| Step: 11
Training loss: 0.5538371801376343
Validation loss: 1.964176893234253

Epoch: 6| Step: 12
Training loss: 0.366851806640625
Validation loss: 1.9592333038647969

Epoch: 6| Step: 13
Training loss: 0.13617536425590515
Validation loss: 2.0126604636510215

Epoch: 384| Step: 0
Training loss: 0.15136311948299408
Validation loss: 1.9447320501009624

Epoch: 6| Step: 1
Training loss: 0.17563004791736603
Validation loss: 1.9798910021781921

Epoch: 6| Step: 2
Training loss: 0.26418250799179077
Validation loss: 1.978129466374715

Epoch: 6| Step: 3
Training loss: 0.4340558648109436
Validation loss: 2.0123141209284463

Epoch: 6| Step: 4
Training loss: 0.21444213390350342
Validation loss: 1.974586268266042

Epoch: 6| Step: 5
Training loss: 0.2774307429790497
Validation loss: 1.9715047876040142

Epoch: 6| Step: 6
Training loss: 0.17430007457733154
Validation loss: 1.9539108475049336

Epoch: 6| Step: 7
Training loss: 0.18661560118198395
Validation loss: 1.9881123900413513

Epoch: 6| Step: 8
Training loss: 0.19686247408390045
Validation loss: 2.021161695321401

Epoch: 6| Step: 9
Training loss: 0.17150753736495972
Validation loss: 1.9797728459040325

Epoch: 6| Step: 10
Training loss: 0.20421284437179565
Validation loss: 2.0166955391565957

Epoch: 6| Step: 11
Training loss: 0.2213057279586792
Validation loss: 1.9873897631963093

Epoch: 6| Step: 12
Training loss: 0.19397741556167603
Validation loss: 1.9959414998690288

Epoch: 6| Step: 13
Training loss: 0.6109867095947266
Validation loss: 1.9737530152002971

Epoch: 385| Step: 0
Training loss: 0.2709242105484009
Validation loss: 1.9734606941541035

Epoch: 6| Step: 1
Training loss: 0.20113566517829895
Validation loss: 1.980065941810608

Epoch: 6| Step: 2
Training loss: 0.23703286051750183
Validation loss: 1.9987802108128865

Epoch: 6| Step: 3
Training loss: 0.2366834431886673
Validation loss: 1.9854615728060405

Epoch: 6| Step: 4
Training loss: 0.12343166768550873
Validation loss: 1.975242793560028

Epoch: 6| Step: 5
Training loss: 0.17227056622505188
Validation loss: 1.9934932986895244

Epoch: 6| Step: 6
Training loss: 0.22077062726020813
Validation loss: 1.997810145219167

Epoch: 6| Step: 7
Training loss: 0.3025926947593689
Validation loss: 1.9518083532651265

Epoch: 6| Step: 8
Training loss: 0.3274928629398346
Validation loss: 2.0034805734952292

Epoch: 6| Step: 9
Training loss: 0.22877803444862366
Validation loss: 1.9789387782414753

Epoch: 6| Step: 10
Training loss: 0.18291105329990387
Validation loss: 1.9600140849749248

Epoch: 6| Step: 11
Training loss: 0.2347281277179718
Validation loss: 1.9845702449480693

Epoch: 6| Step: 12
Training loss: 0.2748773694038391
Validation loss: 1.9533792734146118

Epoch: 6| Step: 13
Training loss: 0.6401492953300476
Validation loss: 1.9050128658612568

Epoch: 386| Step: 0
Training loss: 0.18836863338947296
Validation loss: 1.9886349439620972

Epoch: 6| Step: 1
Training loss: 0.2949017882347107
Validation loss: 1.9624765117963154

Epoch: 6| Step: 2
Training loss: 0.18907901644706726
Validation loss: 1.9868038694063823

Epoch: 6| Step: 3
Training loss: 0.5823667049407959
Validation loss: 1.939848283926646

Epoch: 6| Step: 4
Training loss: 0.26804566383361816
Validation loss: 1.9920802513758342

Epoch: 6| Step: 5
Training loss: 0.12812766432762146
Validation loss: 1.9691681663195293

Epoch: 6| Step: 6
Training loss: 0.19924646615982056
Validation loss: 1.983777681986491

Epoch: 6| Step: 7
Training loss: 0.19821295142173767
Validation loss: 1.9598442912101746

Epoch: 6| Step: 8
Training loss: 0.21957360208034515
Validation loss: 1.973513623078664

Epoch: 6| Step: 9
Training loss: 0.3105650544166565
Validation loss: 1.959054132302602

Epoch: 6| Step: 10
Training loss: 0.23907262086868286
Validation loss: 1.9799813628196716

Epoch: 6| Step: 11
Training loss: 0.20061953365802765
Validation loss: 1.9508199493090312

Epoch: 6| Step: 12
Training loss: 0.40158703923225403
Validation loss: 1.9830825726191204

Epoch: 6| Step: 13
Training loss: 0.40057164430618286
Validation loss: 1.9962016940116882

Epoch: 387| Step: 0
Training loss: 0.47664332389831543
Validation loss: 1.9658283789952595

Epoch: 6| Step: 1
Training loss: 0.300228476524353
Validation loss: 1.9286238352457683

Epoch: 6| Step: 2
Training loss: 0.23216822743415833
Validation loss: 1.9790388743082683

Epoch: 6| Step: 3
Training loss: 0.35534584522247314
Validation loss: 2.0054054458936057

Epoch: 6| Step: 4
Training loss: 0.24746601283550262
Validation loss: 1.9908134738604228

Epoch: 6| Step: 5
Training loss: 0.2559221386909485
Validation loss: 2.0025813579559326

Epoch: 6| Step: 6
Training loss: 0.4235827326774597
Validation loss: 1.9835392236709595

Epoch: 6| Step: 7
Training loss: 0.1290501058101654
Validation loss: 1.9815410772959392

Epoch: 6| Step: 8
Training loss: 0.16066044569015503
Validation loss: 1.9757874210675557

Epoch: 6| Step: 9
Training loss: 0.28392088413238525
Validation loss: 1.9952130715052288

Epoch: 6| Step: 10
Training loss: 0.35415464639663696
Validation loss: 2.0080746014912925

Epoch: 6| Step: 11
Training loss: 0.31109851598739624
Validation loss: 2.001597980658213

Epoch: 6| Step: 12
Training loss: 0.1673753708600998
Validation loss: 1.9827765226364136

Epoch: 6| Step: 13
Training loss: 0.18128696084022522
Validation loss: 2.012985348701477

Epoch: 388| Step: 0
Training loss: 0.20970304310321808
Validation loss: 1.9872039556503296

Epoch: 6| Step: 1
Training loss: 0.6491468548774719
Validation loss: 2.0079744458198547

Epoch: 6| Step: 2
Training loss: 0.2578500807285309
Validation loss: 1.9898929993311565

Epoch: 6| Step: 3
Training loss: 0.2094714343547821
Validation loss: 1.9588854710261028

Epoch: 6| Step: 4
Training loss: 0.11948524415493011
Validation loss: 1.9892443418502808

Epoch: 6| Step: 5
Training loss: 0.21112602949142456
Validation loss: 2.0120978554089866

Epoch: 6| Step: 6
Training loss: 0.27096208930015564
Validation loss: 1.9906748334566753

Epoch: 6| Step: 7
Training loss: 0.24553072452545166
Validation loss: 2.018448770046234

Epoch: 6| Step: 8
Training loss: 0.2540320158004761
Validation loss: 1.9882863362630208

Epoch: 6| Step: 9
Training loss: 0.3220149278640747
Validation loss: 2.0041584571202598

Epoch: 6| Step: 10
Training loss: 0.16472265124320984
Validation loss: 1.944750984509786

Epoch: 6| Step: 11
Training loss: 0.18969221413135529
Validation loss: 1.9782119194666545

Epoch: 6| Step: 12
Training loss: 0.4010280966758728
Validation loss: 2.0069721341133118

Epoch: 6| Step: 13
Training loss: 0.30310502648353577
Validation loss: 1.995452066262563

Epoch: 389| Step: 0
Training loss: 0.6685437560081482
Validation loss: 1.9517061312993367

Epoch: 6| Step: 1
Training loss: 0.11727522313594818
Validation loss: 1.9636959433555603

Epoch: 6| Step: 2
Training loss: 0.33901655673980713
Validation loss: 1.953396737575531

Epoch: 6| Step: 3
Training loss: 0.20526503026485443
Validation loss: 1.9624281128247578

Epoch: 6| Step: 4
Training loss: 0.18433602154254913
Validation loss: 1.9483861525853474

Epoch: 6| Step: 5
Training loss: 0.22804796695709229
Validation loss: 1.9416159788767497

Epoch: 6| Step: 6
Training loss: 0.2702505588531494
Validation loss: 1.9375806252161663

Epoch: 6| Step: 7
Training loss: 0.2971299886703491
Validation loss: 1.9714081486066182

Epoch: 6| Step: 8
Training loss: 0.18861564993858337
Validation loss: 1.925199290116628

Epoch: 6| Step: 9
Training loss: 0.4273860454559326
Validation loss: 1.9968112309773762

Epoch: 6| Step: 10
Training loss: 0.31599611043930054
Validation loss: 1.9602541327476501

Epoch: 6| Step: 11
Training loss: 0.2939198613166809
Validation loss: 1.9894655346870422

Epoch: 6| Step: 12
Training loss: 0.26774072647094727
Validation loss: 1.9476299285888672

Epoch: 6| Step: 13
Training loss: 0.26912468671798706
Validation loss: 1.9540445804595947

Epoch: 390| Step: 0
Training loss: 0.225282222032547
Validation loss: 1.9477163553237915

Epoch: 6| Step: 1
Training loss: 0.21091872453689575
Validation loss: 1.9690826336542766

Epoch: 6| Step: 2
Training loss: 0.6432239413261414
Validation loss: 1.9681777556737263

Epoch: 6| Step: 3
Training loss: 0.23950506746768951
Validation loss: 1.9537819027900696

Epoch: 6| Step: 4
Training loss: 0.38449960947036743
Validation loss: 1.9611445267995198

Epoch: 6| Step: 5
Training loss: 0.13878001272678375
Validation loss: 1.9698593616485596

Epoch: 6| Step: 6
Training loss: 0.21484850347042084
Validation loss: 1.9882907271385193

Epoch: 6| Step: 7
Training loss: 0.29075807332992554
Validation loss: 1.999701698621114

Epoch: 6| Step: 8
Training loss: 0.24221175909042358
Validation loss: 1.9565566778182983

Epoch: 6| Step: 9
Training loss: 0.1852138340473175
Validation loss: 1.9884098966916401

Epoch: 6| Step: 10
Training loss: 0.16960948705673218
Validation loss: 1.9648413856824238

Epoch: 6| Step: 11
Training loss: 0.23053114116191864
Validation loss: 1.9877907236417134

Epoch: 6| Step: 12
Training loss: 0.28405410051345825
Validation loss: 1.976080099741618

Epoch: 6| Step: 13
Training loss: 0.2543793320655823
Validation loss: 1.9395387768745422

Epoch: 391| Step: 0
Training loss: 0.20335298776626587
Validation loss: 1.9874626596768696

Epoch: 6| Step: 1
Training loss: 0.19034773111343384
Validation loss: 1.9440629879633586

Epoch: 6| Step: 2
Training loss: 0.19290432333946228
Validation loss: 1.9811931649843852

Epoch: 6| Step: 3
Training loss: 0.2603040635585785
Validation loss: 2.009205996990204

Epoch: 6| Step: 4
Training loss: 0.32904452085494995
Validation loss: 2.011763115723928

Epoch: 6| Step: 5
Training loss: 0.34299618005752563
Validation loss: 2.0221269528071084

Epoch: 6| Step: 6
Training loss: 0.3038345277309418
Validation loss: 1.9838372071584065

Epoch: 6| Step: 7
Training loss: 0.21337522566318512
Validation loss: 2.027711828549703

Epoch: 6| Step: 8
Training loss: 0.2812730669975281
Validation loss: 2.0355656147003174

Epoch: 6| Step: 9
Training loss: 0.2887580990791321
Validation loss: 1.9983694156010945

Epoch: 6| Step: 10
Training loss: 0.21928837895393372
Validation loss: 1.9839435418446858

Epoch: 6| Step: 11
Training loss: 0.20955054461956024
Validation loss: 1.9625672896703084

Epoch: 6| Step: 12
Training loss: 0.5249521136283875
Validation loss: 2.0034592151641846

Epoch: 6| Step: 13
Training loss: 0.20473827421665192
Validation loss: 1.9415723880132039

Epoch: 392| Step: 0
Training loss: 0.217133030295372
Validation loss: 1.989016870657603

Epoch: 6| Step: 1
Training loss: 0.17806607484817505
Validation loss: 1.9878318508466084

Epoch: 6| Step: 2
Training loss: 0.312227338552475
Validation loss: 1.9834075570106506

Epoch: 6| Step: 3
Training loss: 0.5197190642356873
Validation loss: 2.0137452483177185

Epoch: 6| Step: 4
Training loss: 0.2782488167285919
Validation loss: 1.985196630160014

Epoch: 6| Step: 5
Training loss: 0.24597734212875366
Validation loss: 1.9802269736925762

Epoch: 6| Step: 6
Training loss: 0.2771058678627014
Validation loss: 1.989187518755595

Epoch: 6| Step: 7
Training loss: 0.20352937281131744
Validation loss: 1.9660454193751018

Epoch: 6| Step: 8
Training loss: 0.5296377539634705
Validation loss: 2.037558595339457

Epoch: 6| Step: 9
Training loss: 0.2853585481643677
Validation loss: 1.9884563088417053

Epoch: 6| Step: 10
Training loss: 0.17044326663017273
Validation loss: 1.980647325515747

Epoch: 6| Step: 11
Training loss: 0.20233319699764252
Validation loss: 1.9733596444129944

Epoch: 6| Step: 12
Training loss: 0.21714812517166138
Validation loss: 1.9725863138834636

Epoch: 6| Step: 13
Training loss: 0.2306002527475357
Validation loss: 1.9842259486516316

Epoch: 393| Step: 0
Training loss: 0.19823768734931946
Validation loss: 1.965882917245229

Epoch: 6| Step: 1
Training loss: 0.2591053247451782
Validation loss: 2.0003146529197693

Epoch: 6| Step: 2
Training loss: 0.23027852177619934
Validation loss: 1.9614510138829548

Epoch: 6| Step: 3
Training loss: 0.2543288767337799
Validation loss: 1.9447078108787537

Epoch: 6| Step: 4
Training loss: 0.13655732572078705
Validation loss: 1.9546358982721965

Epoch: 6| Step: 5
Training loss: 0.25654640793800354
Validation loss: 1.9561030268669128

Epoch: 6| Step: 6
Training loss: 0.2890867590904236
Validation loss: 1.9605202078819275

Epoch: 6| Step: 7
Training loss: 0.14881503582000732
Validation loss: 1.9484346508979797

Epoch: 6| Step: 8
Training loss: 0.5297753810882568
Validation loss: 1.9821608265240986

Epoch: 6| Step: 9
Training loss: 0.2529336214065552
Validation loss: 1.9668173591295879

Epoch: 6| Step: 10
Training loss: 0.16622810065746307
Validation loss: 1.974173943201701

Epoch: 6| Step: 11
Training loss: 0.3295232057571411
Validation loss: 1.9578831593195598

Epoch: 6| Step: 12
Training loss: 0.2473243921995163
Validation loss: 1.9878092209498088

Epoch: 6| Step: 13
Training loss: 0.15634825825691223
Validation loss: 1.9743928114573162

Epoch: 394| Step: 0
Training loss: 0.29898160696029663
Validation loss: 1.9884355664253235

Epoch: 6| Step: 1
Training loss: 0.22482901811599731
Validation loss: 1.9799491167068481

Epoch: 6| Step: 2
Training loss: 0.23730231821537018
Validation loss: 1.9854140679041545

Epoch: 6| Step: 3
Training loss: 0.14589737355709076
Validation loss: 2.0000223318735757

Epoch: 6| Step: 4
Training loss: 0.23310089111328125
Validation loss: 1.999261478583018

Epoch: 6| Step: 5
Training loss: 0.1963469237089157
Validation loss: 1.9902193148930867

Epoch: 6| Step: 6
Training loss: 0.28515154123306274
Validation loss: 2.0130658547083535

Epoch: 6| Step: 7
Training loss: 0.24686813354492188
Validation loss: 2.001606523990631

Epoch: 6| Step: 8
Training loss: 0.2857906222343445
Validation loss: 1.9950279593467712

Epoch: 6| Step: 9
Training loss: 0.23225446045398712
Validation loss: 1.976942817370097

Epoch: 6| Step: 10
Training loss: 0.6746260523796082
Validation loss: 1.995289941628774

Epoch: 6| Step: 11
Training loss: 0.24667206406593323
Validation loss: 2.020211716492971

Epoch: 6| Step: 12
Training loss: 0.23982295393943787
Validation loss: 2.0278200507164

Epoch: 6| Step: 13
Training loss: 0.40561017394065857
Validation loss: 1.9977037111918132

Epoch: 395| Step: 0
Training loss: 0.4205663800239563
Validation loss: 2.015706201394399

Epoch: 6| Step: 1
Training loss: 0.2840009331703186
Validation loss: 1.972094436486562

Epoch: 6| Step: 2
Training loss: 0.14799131453037262
Validation loss: 2.0207919677098594

Epoch: 6| Step: 3
Training loss: 0.3046727776527405
Validation loss: 1.974394718805949

Epoch: 6| Step: 4
Training loss: 0.2631877660751343
Validation loss: 2.0015799403190613

Epoch: 6| Step: 5
Training loss: 0.37073689699172974
Validation loss: 2.0200315713882446

Epoch: 6| Step: 6
Training loss: 0.5798401236534119
Validation loss: 2.007558822631836

Epoch: 6| Step: 7
Training loss: 0.22317729890346527
Validation loss: 1.99639093875885

Epoch: 6| Step: 8
Training loss: 0.28139472007751465
Validation loss: 1.9840256174405415

Epoch: 6| Step: 9
Training loss: 0.17698785662651062
Validation loss: 1.9496907790501912

Epoch: 6| Step: 10
Training loss: 0.1624780297279358
Validation loss: 1.9952340920766194

Epoch: 6| Step: 11
Training loss: 0.11808836460113525
Validation loss: 1.9605822761853535

Epoch: 6| Step: 12
Training loss: 0.16203728318214417
Validation loss: 1.9705520272254944

Epoch: 6| Step: 13
Training loss: 0.2388586699962616
Validation loss: 2.004193206628164

Epoch: 396| Step: 0
Training loss: 0.17560982704162598
Validation loss: 1.9917525450388591

Epoch: 6| Step: 1
Training loss: 0.282379686832428
Validation loss: 1.9308182001113892

Epoch: 6| Step: 2
Training loss: 0.2862341105937958
Validation loss: 1.992022732893626

Epoch: 6| Step: 3
Training loss: 0.16788071393966675
Validation loss: 1.9374402562777202

Epoch: 6| Step: 4
Training loss: 0.613154411315918
Validation loss: 1.9617542028427124

Epoch: 6| Step: 5
Training loss: 0.16070958971977234
Validation loss: 1.9424084623654683

Epoch: 6| Step: 6
Training loss: 0.22581186890602112
Validation loss: 1.9628830750783284

Epoch: 6| Step: 7
Training loss: 0.12024769186973572
Validation loss: 1.9597498575846355

Epoch: 6| Step: 8
Training loss: 0.18688251078128815
Validation loss: 1.9693979024887085

Epoch: 6| Step: 9
Training loss: 0.21240007877349854
Validation loss: 1.9593604604403179

Epoch: 6| Step: 10
Training loss: 0.15471802651882172
Validation loss: 1.9591402610143025

Epoch: 6| Step: 11
Training loss: 0.12507250905036926
Validation loss: 2.0104878147443137

Epoch: 6| Step: 12
Training loss: 0.2845349907875061
Validation loss: 1.9570327798525493

Epoch: 6| Step: 13
Training loss: 0.2590719759464264
Validation loss: 1.9906148314476013

Epoch: 397| Step: 0
Training loss: 0.24207989871501923
Validation loss: 2.0016221602757773

Epoch: 6| Step: 1
Training loss: 0.24639949202537537
Validation loss: 1.9516201814015706

Epoch: 6| Step: 2
Training loss: 0.20564520359039307
Validation loss: 2.0355019172032676

Epoch: 6| Step: 3
Training loss: 0.18407514691352844
Validation loss: 1.973811189333598

Epoch: 6| Step: 4
Training loss: 0.570702075958252
Validation loss: 1.9987461964289348

Epoch: 6| Step: 5
Training loss: 0.195326030254364
Validation loss: 2.022209723790487

Epoch: 6| Step: 6
Training loss: 0.2681550681591034
Validation loss: 1.9903356035550435

Epoch: 6| Step: 7
Training loss: 0.15837806463241577
Validation loss: 2.0205005606015525

Epoch: 6| Step: 8
Training loss: 0.2486094832420349
Validation loss: 1.974525272846222

Epoch: 6| Step: 9
Training loss: 0.3657068610191345
Validation loss: 1.9954472780227661

Epoch: 6| Step: 10
Training loss: 0.21809831261634827
Validation loss: 2.0087977846463523

Epoch: 6| Step: 11
Training loss: 0.3059845566749573
Validation loss: 1.9757805466651917

Epoch: 6| Step: 12
Training loss: 0.2419748604297638
Validation loss: 1.9679760138193767

Epoch: 6| Step: 13
Training loss: 0.27387017011642456
Validation loss: 2.0028789242108664

Epoch: 398| Step: 0
Training loss: 0.21589815616607666
Validation loss: 1.9761908054351807

Epoch: 6| Step: 1
Training loss: 0.1496974527835846
Validation loss: 2.0010778506596885

Epoch: 6| Step: 2
Training loss: 0.13175725936889648
Validation loss: 1.989339570204417

Epoch: 6| Step: 3
Training loss: 0.1668749451637268
Validation loss: 1.9818597833315532

Epoch: 6| Step: 4
Training loss: 0.21012413501739502
Validation loss: 1.9766842524210613

Epoch: 6| Step: 5
Training loss: 0.18262124061584473
Validation loss: 1.9949337442715962

Epoch: 6| Step: 6
Training loss: 0.29490119218826294
Validation loss: 1.9958654244740803

Epoch: 6| Step: 7
Training loss: 0.1703883856534958
Validation loss: 1.9566175937652588

Epoch: 6| Step: 8
Training loss: 0.20856791734695435
Validation loss: 1.998949448267619

Epoch: 6| Step: 9
Training loss: 0.3254421353340149
Validation loss: 2.0169462164243064

Epoch: 6| Step: 10
Training loss: 0.20749405026435852
Validation loss: 1.9988972345987956

Epoch: 6| Step: 11
Training loss: 0.12328051030635834
Validation loss: 1.9860636989275615

Epoch: 6| Step: 12
Training loss: 0.5017544627189636
Validation loss: 1.9596749544143677

Epoch: 6| Step: 13
Training loss: 0.3327215909957886
Validation loss: 2.008539001146952

Epoch: 399| Step: 0
Training loss: 0.1801440715789795
Validation loss: 1.984221875667572

Epoch: 6| Step: 1
Training loss: 0.25688955187797546
Validation loss: 2.0044132272402444

Epoch: 6| Step: 2
Training loss: 0.20084448158740997
Validation loss: 1.9726192553838093

Epoch: 6| Step: 3
Training loss: 0.22649595141410828
Validation loss: 1.9713976979255676

Epoch: 6| Step: 4
Training loss: 0.23290899395942688
Validation loss: 1.9778077801068623

Epoch: 6| Step: 5
Training loss: 0.1506761759519577
Validation loss: 2.0039657155672708

Epoch: 6| Step: 6
Training loss: 0.20557674765586853
Validation loss: 1.9993348519007366

Epoch: 6| Step: 7
Training loss: 0.20545229315757751
Validation loss: 2.016133745511373

Epoch: 6| Step: 8
Training loss: 0.1157216802239418
Validation loss: 2.0052578846613565

Epoch: 6| Step: 9
Training loss: 0.12225120514631271
Validation loss: 1.9850483338038127

Epoch: 6| Step: 10
Training loss: 0.5264943242073059
Validation loss: 2.016142725944519

Epoch: 6| Step: 11
Training loss: 0.2294197976589203
Validation loss: 2.003911256790161

Epoch: 6| Step: 12
Training loss: 0.35030287504196167
Validation loss: 2.0278839071591697

Epoch: 6| Step: 13
Training loss: 0.2649248540401459
Validation loss: 1.9882171750068665

Epoch: 400| Step: 0
Training loss: 0.20331645011901855
Validation loss: 2.0132059256235757

Epoch: 6| Step: 1
Training loss: 0.19277851283550262
Validation loss: 1.9663002888361614

Epoch: 6| Step: 2
Training loss: 0.5531592965126038
Validation loss: 1.9929893612861633

Epoch: 6| Step: 3
Training loss: 0.20085430145263672
Validation loss: 1.984212855497996

Epoch: 6| Step: 4
Training loss: 0.15391290187835693
Validation loss: 1.9657166401545207

Epoch: 6| Step: 5
Training loss: 0.20403175055980682
Validation loss: 1.9904170831044514

Epoch: 6| Step: 6
Training loss: 0.2933506369590759
Validation loss: 1.9710636734962463

Epoch: 6| Step: 7
Training loss: 0.1798531711101532
Validation loss: 1.9778287013371785

Epoch: 6| Step: 8
Training loss: 0.29732927680015564
Validation loss: 2.002397656440735

Epoch: 6| Step: 9
Training loss: 0.1421763300895691
Validation loss: 1.9921097159385681

Epoch: 6| Step: 10
Training loss: 0.21309100091457367
Validation loss: 1.9979496995608013

Epoch: 6| Step: 11
Training loss: 0.3785454034805298
Validation loss: 2.0149295727411904

Epoch: 6| Step: 12
Training loss: 0.20292019844055176
Validation loss: 2.0065171321233115

Epoch: 6| Step: 13
Training loss: 0.16574351489543915
Validation loss: 1.974977970123291

Epoch: 401| Step: 0
Training loss: 0.17878764867782593
Validation loss: 1.9750222365061443

Epoch: 6| Step: 1
Training loss: 0.13489186763763428
Validation loss: 1.9979293942451477

Epoch: 6| Step: 2
Training loss: 0.45303332805633545
Validation loss: 1.9557164907455444

Epoch: 6| Step: 3
Training loss: 0.17648813128471375
Validation loss: 1.9874492088953655

Epoch: 6| Step: 4
Training loss: 0.25634798407554626
Validation loss: 1.9766235947608948

Epoch: 6| Step: 5
Training loss: 0.2202351987361908
Validation loss: 1.9973862171173096

Epoch: 6| Step: 6
Training loss: 0.26741278171539307
Validation loss: 1.9921943346659343

Epoch: 6| Step: 7
Training loss: 0.3182377815246582
Validation loss: 2.0007898012797036

Epoch: 6| Step: 8
Training loss: 0.12545442581176758
Validation loss: 2.031509002049764

Epoch: 6| Step: 9
Training loss: 0.19163557887077332
Validation loss: 2.01227205991745

Epoch: 6| Step: 10
Training loss: 0.1786268949508667
Validation loss: 1.9564103881518047

Epoch: 6| Step: 11
Training loss: 0.1905495971441269
Validation loss: 1.9480418960253398

Epoch: 6| Step: 12
Training loss: 0.3655945360660553
Validation loss: 1.9838408827781677

Epoch: 6| Step: 13
Training loss: 0.16043764352798462
Validation loss: 1.9879636367162068

Epoch: 402| Step: 0
Training loss: 0.1391018033027649
Validation loss: 1.9956626494725545

Epoch: 6| Step: 1
Training loss: 0.14889205992221832
Validation loss: 1.9968784650166829

Epoch: 6| Step: 2
Training loss: 0.30767691135406494
Validation loss: 1.994564712047577

Epoch: 6| Step: 3
Training loss: 0.3419031798839569
Validation loss: 1.954858918984731

Epoch: 6| Step: 4
Training loss: 0.31616291403770447
Validation loss: 1.9615991512934368

Epoch: 6| Step: 5
Training loss: 0.2780839204788208
Validation loss: 1.9376362760861714

Epoch: 6| Step: 6
Training loss: 0.1368996798992157
Validation loss: 1.978327711423238

Epoch: 6| Step: 7
Training loss: 0.6736924648284912
Validation loss: 1.9853342374165852

Epoch: 6| Step: 8
Training loss: 0.2506009042263031
Validation loss: 2.0190035899480185

Epoch: 6| Step: 9
Training loss: 0.19180366396903992
Validation loss: 1.9410751263300579

Epoch: 6| Step: 10
Training loss: 0.14475546777248383
Validation loss: 2.0044556657473245

Epoch: 6| Step: 11
Training loss: 0.17434638738632202
Validation loss: 1.959108869234721

Epoch: 6| Step: 12
Training loss: 0.16089577972888947
Validation loss: 1.962131639321645

Epoch: 6| Step: 13
Training loss: 0.3503006100654602
Validation loss: 1.9285807609558105

Epoch: 403| Step: 0
Training loss: 0.24744156002998352
Validation loss: 1.962754527727763

Epoch: 6| Step: 1
Training loss: 0.31070929765701294
Validation loss: 1.9486491680145264

Epoch: 6| Step: 2
Training loss: 0.13863347470760345
Validation loss: 1.991255243619283

Epoch: 6| Step: 3
Training loss: 0.1493762731552124
Validation loss: 1.934066375096639

Epoch: 6| Step: 4
Training loss: 0.306135356426239
Validation loss: 1.9593560695648193

Epoch: 6| Step: 5
Training loss: 0.16945955157279968
Validation loss: 1.996344765027364

Epoch: 6| Step: 6
Training loss: 0.17357665300369263
Validation loss: 1.9818979501724243

Epoch: 6| Step: 7
Training loss: 0.17935189604759216
Validation loss: 1.969241996606191

Epoch: 6| Step: 8
Training loss: 0.33066171407699585
Validation loss: 2.003134469191233

Epoch: 6| Step: 9
Training loss: 0.20405063033103943
Validation loss: 2.0178120930989585

Epoch: 6| Step: 10
Training loss: 0.17434784770011902
Validation loss: 1.9954800605773926

Epoch: 6| Step: 11
Training loss: 0.5304871797561646
Validation loss: 2.0041933258374534

Epoch: 6| Step: 12
Training loss: 0.20454876124858856
Validation loss: 1.9907076756159465

Epoch: 6| Step: 13
Training loss: 0.25597670674324036
Validation loss: 1.965984086195628

Epoch: 404| Step: 0
Training loss: 0.1856500655412674
Validation loss: 1.9743082125981648

Epoch: 6| Step: 1
Training loss: 0.19917167723178864
Validation loss: 1.9986090858777363

Epoch: 6| Step: 2
Training loss: 0.30468088388442993
Validation loss: 2.0049415032068887

Epoch: 6| Step: 3
Training loss: 0.22556988894939423
Validation loss: 2.014052927494049

Epoch: 6| Step: 4
Training loss: 0.28773435950279236
Validation loss: 1.9826873143513997

Epoch: 6| Step: 5
Training loss: 0.1265161633491516
Validation loss: 1.9855136275291443

Epoch: 6| Step: 6
Training loss: 0.19920767843723297
Validation loss: 2.006907065709432

Epoch: 6| Step: 7
Training loss: 0.2637762725353241
Validation loss: 2.000443696975708

Epoch: 6| Step: 8
Training loss: 0.30617913603782654
Validation loss: 1.9754047393798828

Epoch: 6| Step: 9
Training loss: 0.5747934579849243
Validation loss: 1.97884202003479

Epoch: 6| Step: 10
Training loss: 0.33601340651512146
Validation loss: 1.9909326434135437

Epoch: 6| Step: 11
Training loss: 0.19761289656162262
Validation loss: 1.9758174220720928

Epoch: 6| Step: 12
Training loss: 0.12323755025863647
Validation loss: 1.973894437154134

Epoch: 6| Step: 13
Training loss: 0.18184347450733185
Validation loss: 1.9923951824506123

Epoch: 405| Step: 0
Training loss: 0.1967426836490631
Validation loss: 1.9705656170845032

Epoch: 6| Step: 1
Training loss: 0.26951199769973755
Validation loss: 1.9548126260439556

Epoch: 6| Step: 2
Training loss: 0.5750161409378052
Validation loss: 1.9995752374331157

Epoch: 6| Step: 3
Training loss: 0.18756702542304993
Validation loss: 1.994026283423106

Epoch: 6| Step: 4
Training loss: 0.29061397910118103
Validation loss: 1.9984877705574036

Epoch: 6| Step: 5
Training loss: 0.15630200505256653
Validation loss: 1.9658054908116658

Epoch: 6| Step: 6
Training loss: 0.2600870132446289
Validation loss: 1.9981335798899333

Epoch: 6| Step: 7
Training loss: 0.25102078914642334
Validation loss: 1.9516228834788005

Epoch: 6| Step: 8
Training loss: 0.18792107701301575
Validation loss: 1.9723201394081116

Epoch: 6| Step: 9
Training loss: 0.18008583784103394
Validation loss: 2.000239829222361

Epoch: 6| Step: 10
Training loss: 0.2694913446903229
Validation loss: 1.9840256174405415

Epoch: 6| Step: 11
Training loss: 0.15369543433189392
Validation loss: 1.9747101664543152

Epoch: 6| Step: 12
Training loss: 0.17337097227573395
Validation loss: 1.9661069711049397

Epoch: 6| Step: 13
Training loss: 0.3148907423019409
Validation loss: 2.0042781631151834

Epoch: 406| Step: 0
Training loss: 0.13375592231750488
Validation loss: 1.9897685647010803

Epoch: 6| Step: 1
Training loss: 0.5785053968429565
Validation loss: 2.0204495390256247

Epoch: 6| Step: 2
Training loss: 0.30719634890556335
Validation loss: 1.94040580590566

Epoch: 6| Step: 3
Training loss: 0.26855841279029846
Validation loss: 1.9830622275670369

Epoch: 6| Step: 4
Training loss: 0.23822921514511108
Validation loss: 2.0042444268862405

Epoch: 6| Step: 5
Training loss: 0.12706023454666138
Validation loss: 1.9797348777453105

Epoch: 6| Step: 6
Training loss: 0.17152374982833862
Validation loss: 1.9992668827374775

Epoch: 6| Step: 7
Training loss: 0.21814218163490295
Validation loss: 1.972766677538554

Epoch: 6| Step: 8
Training loss: 0.24184995889663696
Validation loss: 2.0087859431902566

Epoch: 6| Step: 9
Training loss: 0.11632280796766281
Validation loss: 2.0037701527277627

Epoch: 6| Step: 10
Training loss: 0.2240656018257141
Validation loss: 2.0355787873268127

Epoch: 6| Step: 11
Training loss: 0.2445444017648697
Validation loss: 1.9858051141103108

Epoch: 6| Step: 12
Training loss: 0.19143041968345642
Validation loss: 1.9867323438326518

Epoch: 6| Step: 13
Training loss: 0.36760374903678894
Validation loss: 1.9701263308525085

Epoch: 407| Step: 0
Training loss: 0.18286702036857605
Validation loss: 2.0025583704312644

Epoch: 6| Step: 1
Training loss: 0.2177506387233734
Validation loss: 1.9976007739702861

Epoch: 6| Step: 2
Training loss: 0.32578516006469727
Validation loss: 1.993923266728719

Epoch: 6| Step: 3
Training loss: 0.32410478591918945
Validation loss: 1.994778335094452

Epoch: 6| Step: 4
Training loss: 0.1821158081293106
Validation loss: 1.993670145670573

Epoch: 6| Step: 5
Training loss: 0.2169770896434784
Validation loss: 1.9833829402923584

Epoch: 6| Step: 6
Training loss: 0.21979720890522003
Validation loss: 1.9891425371170044

Epoch: 6| Step: 7
Training loss: 0.20943057537078857
Validation loss: 2.0033689936002097

Epoch: 6| Step: 8
Training loss: 0.5314899682998657
Validation loss: 1.9751997192700703

Epoch: 6| Step: 9
Training loss: 0.27567481994628906
Validation loss: 2.0151758591334024

Epoch: 6| Step: 10
Training loss: 0.18710674345493317
Validation loss: 2.0358519156773887

Epoch: 6| Step: 11
Training loss: 0.1764092743396759
Validation loss: 2.0013325413068137

Epoch: 6| Step: 12
Training loss: 0.2397816777229309
Validation loss: 1.9825491905212402

Epoch: 6| Step: 13
Training loss: 0.1529882550239563
Validation loss: 2.0005035996437073

Epoch: 408| Step: 0
Training loss: 0.13790486752986908
Validation loss: 2.0262430707613626

Epoch: 6| Step: 1
Training loss: 0.11584105342626572
Validation loss: 1.9826297760009766

Epoch: 6| Step: 2
Training loss: 0.21540889143943787
Validation loss: 1.995849351088206

Epoch: 6| Step: 3
Training loss: 0.2466271072626114
Validation loss: 1.9769870241483052

Epoch: 6| Step: 4
Training loss: 0.18010005354881287
Validation loss: 1.9765343070030212

Epoch: 6| Step: 5
Training loss: 0.17597249150276184
Validation loss: 2.018752872943878

Epoch: 6| Step: 6
Training loss: 0.3641033470630646
Validation loss: 1.9933488965034485

Epoch: 6| Step: 7
Training loss: 0.2529771327972412
Validation loss: 1.98622727394104

Epoch: 6| Step: 8
Training loss: 0.17218363285064697
Validation loss: 1.9655164281527202

Epoch: 6| Step: 9
Training loss: 0.4508916139602661
Validation loss: 1.9987327655156453

Epoch: 6| Step: 10
Training loss: 0.1711532473564148
Validation loss: 1.976279616355896

Epoch: 6| Step: 11
Training loss: 0.33467260003089905
Validation loss: 1.9817142883936565

Epoch: 6| Step: 12
Training loss: 0.18127095699310303
Validation loss: 1.9799515803654988

Epoch: 6| Step: 13
Training loss: 0.218952476978302
Validation loss: 1.9937561353047688

Epoch: 409| Step: 0
Training loss: 0.2709677219390869
Validation loss: 2.003557562828064

Epoch: 6| Step: 1
Training loss: 0.23097720742225647
Validation loss: 1.9896408518155415

Epoch: 6| Step: 2
Training loss: 0.3484576344490051
Validation loss: 2.004040002822876

Epoch: 6| Step: 3
Training loss: 0.18673574924468994
Validation loss: 1.9606706698735554

Epoch: 6| Step: 4
Training loss: 0.21480965614318848
Validation loss: 1.9716248909632366

Epoch: 6| Step: 5
Training loss: 0.09223684668540955
Validation loss: 1.9658090472221375

Epoch: 6| Step: 6
Training loss: 0.22662706673145294
Validation loss: 2.00257416566213

Epoch: 6| Step: 7
Training loss: 0.13020086288452148
Validation loss: 1.9911467830340068

Epoch: 6| Step: 8
Training loss: 0.26903635263442993
Validation loss: 2.0124342242876687

Epoch: 6| Step: 9
Training loss: 0.19668596982955933
Validation loss: 1.9984302719434102

Epoch: 6| Step: 10
Training loss: 0.18125125765800476
Validation loss: 2.0109253327051797

Epoch: 6| Step: 11
Training loss: 0.18595004081726074
Validation loss: 2.025065541267395

Epoch: 6| Step: 12
Training loss: 0.5925663709640503
Validation loss: 2.0163867274920144

Epoch: 6| Step: 13
Training loss: 0.32962238788604736
Validation loss: 2.0000071128209433

Epoch: 410| Step: 0
Training loss: 0.28560033440589905
Validation loss: 1.9742164214452107

Epoch: 6| Step: 1
Training loss: 0.5552533864974976
Validation loss: 1.9966787695884705

Epoch: 6| Step: 2
Training loss: 0.22979357838630676
Validation loss: 1.9964889883995056

Epoch: 6| Step: 3
Training loss: 0.24412056803703308
Validation loss: 2.007799526055654

Epoch: 6| Step: 4
Training loss: 0.17493638396263123
Validation loss: 2.0076509515444436

Epoch: 6| Step: 5
Training loss: 0.30212798714637756
Validation loss: 2.01312647263209

Epoch: 6| Step: 6
Training loss: 0.27421170473098755
Validation loss: 1.9722803632418315

Epoch: 6| Step: 7
Training loss: 0.29334667325019836
Validation loss: 1.9940499067306519

Epoch: 6| Step: 8
Training loss: 0.14658591151237488
Validation loss: 2.0022643009821572

Epoch: 6| Step: 9
Training loss: 0.1456906646490097
Validation loss: 1.9663676023483276

Epoch: 6| Step: 10
Training loss: 0.17835305631160736
Validation loss: 1.9791916608810425

Epoch: 6| Step: 11
Training loss: 0.26176387071609497
Validation loss: 2.0272492170333862

Epoch: 6| Step: 12
Training loss: 0.2760887145996094
Validation loss: 1.978383978207906

Epoch: 6| Step: 13
Training loss: 0.18458685278892517
Validation loss: 2.01219634215037

Epoch: 411| Step: 0
Training loss: 0.18690861761569977
Validation loss: 1.9714320699373882

Epoch: 6| Step: 1
Training loss: 0.1849890947341919
Validation loss: 1.9837963978449504

Epoch: 6| Step: 2
Training loss: 0.37229734659194946
Validation loss: 1.9810935258865356

Epoch: 6| Step: 3
Training loss: 0.35269302129745483
Validation loss: 1.9913017352422078

Epoch: 6| Step: 4
Training loss: 0.2508923411369324
Validation loss: 1.9686507781346638

Epoch: 6| Step: 5
Training loss: 0.16332335770130157
Validation loss: 1.9715230067571003

Epoch: 6| Step: 6
Training loss: 0.17729559540748596
Validation loss: 2.0124417344729104

Epoch: 6| Step: 7
Training loss: 0.17211738228797913
Validation loss: 2.00406285127004

Epoch: 6| Step: 8
Training loss: 0.6370896100997925
Validation loss: 1.9846799770991008

Epoch: 6| Step: 9
Training loss: 0.3030160665512085
Validation loss: 1.968384861946106

Epoch: 6| Step: 10
Training loss: 0.23030485212802887
Validation loss: 1.9736229181289673

Epoch: 6| Step: 11
Training loss: 0.1729053556919098
Validation loss: 1.950687865416209

Epoch: 6| Step: 12
Training loss: 0.3720010817050934
Validation loss: 1.955062707265218

Epoch: 6| Step: 13
Training loss: 0.2858249247074127
Validation loss: 1.9802406231562297

Epoch: 412| Step: 0
Training loss: 0.333474725484848
Validation loss: 1.9967848459879558

Epoch: 6| Step: 1
Training loss: 0.19086341559886932
Validation loss: 1.9637295802434285

Epoch: 6| Step: 2
Training loss: 0.15679287910461426
Validation loss: 1.9751078287760417

Epoch: 6| Step: 3
Training loss: 0.17496246099472046
Validation loss: 1.9661078651746113

Epoch: 6| Step: 4
Training loss: 0.20619544386863708
Validation loss: 1.9551731944084167

Epoch: 6| Step: 5
Training loss: 0.25600922107696533
Validation loss: 1.9880640506744385

Epoch: 6| Step: 6
Training loss: 0.1614367812871933
Validation loss: 1.9962408542633057

Epoch: 6| Step: 7
Training loss: 0.6008089780807495
Validation loss: 1.9811535477638245

Epoch: 6| Step: 8
Training loss: 0.25869446992874146
Validation loss: 1.975422700246175

Epoch: 6| Step: 9
Training loss: 0.20162945985794067
Validation loss: 1.9722558657328289

Epoch: 6| Step: 10
Training loss: 0.1740587204694748
Validation loss: 1.9926716089248657

Epoch: 6| Step: 11
Training loss: 0.275861918926239
Validation loss: 1.9688557585080464

Epoch: 6| Step: 12
Training loss: 0.16246920824050903
Validation loss: 1.960158367951711

Epoch: 6| Step: 13
Training loss: 0.15623465180397034
Validation loss: 1.966755171616872

Epoch: 413| Step: 0
Training loss: 0.3284233510494232
Validation loss: 1.97537761926651

Epoch: 6| Step: 1
Training loss: 0.14678040146827698
Validation loss: 1.997493048508962

Epoch: 6| Step: 2
Training loss: 0.15124918520450592
Validation loss: 1.9565608302752178

Epoch: 6| Step: 3
Training loss: 0.1604885458946228
Validation loss: 2.0081074237823486

Epoch: 6| Step: 4
Training loss: 0.19375614821910858
Validation loss: 1.9720761179924011

Epoch: 6| Step: 5
Training loss: 0.23043188452720642
Validation loss: 1.965661843617757

Epoch: 6| Step: 6
Training loss: 0.13147014379501343
Validation loss: 2.00494247674942

Epoch: 6| Step: 7
Training loss: 0.15570977330207825
Validation loss: 1.9684744675954182

Epoch: 6| Step: 8
Training loss: 0.19843502342700958
Validation loss: 2.0068878332773843

Epoch: 6| Step: 9
Training loss: 0.610296905040741
Validation loss: 2.0199844439824424

Epoch: 6| Step: 10
Training loss: 0.22419306635856628
Validation loss: 1.9942384163538616

Epoch: 6| Step: 11
Training loss: 0.17686206102371216
Validation loss: 2.0229124426841736

Epoch: 6| Step: 12
Training loss: 0.18377737700939178
Validation loss: 1.9987511038780212

Epoch: 6| Step: 13
Training loss: 0.2645542621612549
Validation loss: 1.9889551599820454

Epoch: 414| Step: 0
Training loss: 0.176799014210701
Validation loss: 1.9833486874898274

Epoch: 6| Step: 1
Training loss: 0.2705891728401184
Validation loss: 1.9496855934460957

Epoch: 6| Step: 2
Training loss: 0.15649959444999695
Validation loss: 2.0111591617266336

Epoch: 6| Step: 3
Training loss: 0.19803079962730408
Validation loss: 2.018020828564962

Epoch: 6| Step: 4
Training loss: 0.12680350244045258
Validation loss: 1.971872349580129

Epoch: 6| Step: 5
Training loss: 0.2646699547767639
Validation loss: 2.0337459643681846

Epoch: 6| Step: 6
Training loss: 0.13194797933101654
Validation loss: 1.993949552377065

Epoch: 6| Step: 7
Training loss: 0.19033282995224
Validation loss: 2.0140199065208435

Epoch: 6| Step: 8
Training loss: 0.18278253078460693
Validation loss: 1.9929766654968262

Epoch: 6| Step: 9
Training loss: 0.1817663311958313
Validation loss: 1.9915292660395305

Epoch: 6| Step: 10
Training loss: 0.18937763571739197
Validation loss: 2.0033315221468606

Epoch: 6| Step: 11
Training loss: 0.41104498505592346
Validation loss: 1.9996098081270854

Epoch: 6| Step: 12
Training loss: 0.3379528522491455
Validation loss: 2.00012614329656

Epoch: 6| Step: 13
Training loss: 0.6804384589195251
Validation loss: 1.9739527304967244

Epoch: 415| Step: 0
Training loss: 0.18937969207763672
Validation loss: 1.970658540725708

Epoch: 6| Step: 1
Training loss: 0.6772687435150146
Validation loss: 2.008223017056783

Epoch: 6| Step: 2
Training loss: 0.1314607858657837
Validation loss: 1.9738780458768208

Epoch: 6| Step: 3
Training loss: 0.1516331434249878
Validation loss: 1.9886796077092488

Epoch: 6| Step: 4
Training loss: 0.2912662923336029
Validation loss: 2.0043325821558633

Epoch: 6| Step: 5
Training loss: 0.20652517676353455
Validation loss: 2.002437710762024

Epoch: 6| Step: 6
Training loss: 0.31933271884918213
Validation loss: 2.0301711161931357

Epoch: 6| Step: 7
Training loss: 0.31141138076782227
Validation loss: 2.0356272061665854

Epoch: 6| Step: 8
Training loss: 0.32447221875190735
Validation loss: 1.977694610754649

Epoch: 6| Step: 9
Training loss: 0.20996639132499695
Validation loss: 2.000832994778951

Epoch: 6| Step: 10
Training loss: 0.23255473375320435
Validation loss: 1.9933178027470906

Epoch: 6| Step: 11
Training loss: 0.3243228793144226
Validation loss: 1.9439337054888408

Epoch: 6| Step: 12
Training loss: 0.29717397689819336
Validation loss: 1.958970030148824

Epoch: 6| Step: 13
Training loss: 0.18469183146953583
Validation loss: 1.9675408601760864

Epoch: 416| Step: 0
Training loss: 0.24385769665241241
Validation loss: 2.0015136003494263

Epoch: 6| Step: 1
Training loss: 0.308543860912323
Validation loss: 2.010373036066691

Epoch: 6| Step: 2
Training loss: 0.5583350658416748
Validation loss: 1.9891559481620789

Epoch: 6| Step: 3
Training loss: 0.26902681589126587
Validation loss: 2.0281253655751548

Epoch: 6| Step: 4
Training loss: 0.32520145177841187
Validation loss: 2.003360311190287

Epoch: 6| Step: 5
Training loss: 0.2202175110578537
Validation loss: 2.013169546922048

Epoch: 6| Step: 6
Training loss: 0.10923794656991959
Validation loss: 2.039981265862783

Epoch: 6| Step: 7
Training loss: 0.2856564223766327
Validation loss: 2.000543236732483

Epoch: 6| Step: 8
Training loss: 0.24212095141410828
Validation loss: 2.0115949312845864

Epoch: 6| Step: 9
Training loss: 0.2181183397769928
Validation loss: 1.9916783372561138

Epoch: 6| Step: 10
Training loss: 0.19650080800056458
Validation loss: 2.010920524597168

Epoch: 6| Step: 11
Training loss: 0.15875695645809174
Validation loss: 1.9713587760925293

Epoch: 6| Step: 12
Training loss: 0.2535093426704407
Validation loss: 1.9661344289779663

Epoch: 6| Step: 13
Training loss: 0.17071011662483215
Validation loss: 1.9865900079409282

Epoch: 417| Step: 0
Training loss: 0.6234772801399231
Validation loss: 1.9828443725903828

Epoch: 6| Step: 1
Training loss: 0.15315140783786774
Validation loss: 1.991642713546753

Epoch: 6| Step: 2
Training loss: 0.3133213520050049
Validation loss: 1.9868537187576294

Epoch: 6| Step: 3
Training loss: 0.2556358277797699
Validation loss: 1.9594353040059407

Epoch: 6| Step: 4
Training loss: 0.1959265172481537
Validation loss: 1.9776565432548523

Epoch: 6| Step: 5
Training loss: 0.16137200593948364
Validation loss: 1.951619823773702

Epoch: 6| Step: 6
Training loss: 0.2548491954803467
Validation loss: 1.9599770903587341

Epoch: 6| Step: 7
Training loss: 0.1741517037153244
Validation loss: 1.95045801003774

Epoch: 6| Step: 8
Training loss: 0.28747472167015076
Validation loss: 1.9831373294194539

Epoch: 6| Step: 9
Training loss: 0.17829787731170654
Validation loss: 1.9717714190483093

Epoch: 6| Step: 10
Training loss: 0.1956377625465393
Validation loss: 1.941754142443339

Epoch: 6| Step: 11
Training loss: 0.24202805757522583
Validation loss: 1.9733419219652812

Epoch: 6| Step: 12
Training loss: 0.15745650231838226
Validation loss: 1.9761808315912883

Epoch: 6| Step: 13
Training loss: 0.18746919929981232
Validation loss: 2.0137160817782083

Epoch: 418| Step: 0
Training loss: 0.19116660952568054
Validation loss: 1.9833770791689556

Epoch: 6| Step: 1
Training loss: 0.3514935374259949
Validation loss: 1.95681498448054

Epoch: 6| Step: 2
Training loss: 0.20774444937705994
Validation loss: 1.973752240339915

Epoch: 6| Step: 3
Training loss: 0.21671080589294434
Validation loss: 2.0032156904538474

Epoch: 6| Step: 4
Training loss: 0.13413351774215698
Validation loss: 1.976655383904775

Epoch: 6| Step: 5
Training loss: 0.34327971935272217
Validation loss: 2.0034655729929605

Epoch: 6| Step: 6
Training loss: 0.5370740294456482
Validation loss: 1.9840370814005535

Epoch: 6| Step: 7
Training loss: 0.1371850222349167
Validation loss: 1.984234352906545

Epoch: 6| Step: 8
Training loss: 0.30019232630729675
Validation loss: 1.9742395083109539

Epoch: 6| Step: 9
Training loss: 0.20582769811153412
Validation loss: 1.9695857763290405

Epoch: 6| Step: 10
Training loss: 0.11258862912654877
Validation loss: 1.976434051990509

Epoch: 6| Step: 11
Training loss: 0.1244402676820755
Validation loss: 1.9691219925880432

Epoch: 6| Step: 12
Training loss: 0.2478027045726776
Validation loss: 1.977335274219513

Epoch: 6| Step: 13
Training loss: 0.24125313758850098
Validation loss: 1.994552214940389

Epoch: 419| Step: 0
Training loss: 0.2378736138343811
Validation loss: 1.9953178763389587

Epoch: 6| Step: 1
Training loss: 0.271480530500412
Validation loss: 2.008920113245646

Epoch: 6| Step: 2
Training loss: 0.17715688049793243
Validation loss: 1.9670230746269226

Epoch: 6| Step: 3
Training loss: 0.12974494695663452
Validation loss: 1.9509199062983196

Epoch: 6| Step: 4
Training loss: 0.31513696908950806
Validation loss: 1.9809519251187642

Epoch: 6| Step: 5
Training loss: 0.3438533544540405
Validation loss: 1.9746014475822449

Epoch: 6| Step: 6
Training loss: 0.34282243251800537
Validation loss: 1.9983076453208923

Epoch: 6| Step: 7
Training loss: 0.31240031123161316
Validation loss: 1.952807327111562

Epoch: 6| Step: 8
Training loss: 0.21277396380901337
Validation loss: 1.9908486207326253

Epoch: 6| Step: 9
Training loss: 0.17539182305335999
Validation loss: 1.963320295015971

Epoch: 6| Step: 10
Training loss: 0.5510758757591248
Validation loss: 1.990440050760905

Epoch: 6| Step: 11
Training loss: 0.26098164916038513
Validation loss: 2.012088656425476

Epoch: 6| Step: 12
Training loss: 0.33533957600593567
Validation loss: 1.9810266097386677

Epoch: 6| Step: 13
Training loss: 0.2994507849216461
Validation loss: 1.9871266881624858

Epoch: 420| Step: 0
Training loss: 0.1733945906162262
Validation loss: 1.9651024142901103

Epoch: 6| Step: 1
Training loss: 0.1558815836906433
Validation loss: 1.9610225756963093

Epoch: 6| Step: 2
Training loss: 0.22850793600082397
Validation loss: 1.9945830504099529

Epoch: 6| Step: 3
Training loss: 0.1722029745578766
Validation loss: 2.0033083160718284

Epoch: 6| Step: 4
Training loss: 0.11743360757827759
Validation loss: 1.9990812540054321

Epoch: 6| Step: 5
Training loss: 0.16694368422031403
Validation loss: 1.9514717658360798

Epoch: 6| Step: 6
Training loss: 0.2426244020462036
Validation loss: 1.960697094599406

Epoch: 6| Step: 7
Training loss: 0.2757691740989685
Validation loss: 1.9887976447741191

Epoch: 6| Step: 8
Training loss: 0.27085572481155396
Validation loss: 1.9855196873346965

Epoch: 6| Step: 9
Training loss: 0.1499747335910797
Validation loss: 1.9806491533915203

Epoch: 6| Step: 10
Training loss: 0.5176241993904114
Validation loss: 1.9778594175974529

Epoch: 6| Step: 11
Training loss: 0.17504087090492249
Validation loss: 1.9323323369026184

Epoch: 6| Step: 12
Training loss: 0.2684609889984131
Validation loss: 1.9571633736292522

Epoch: 6| Step: 13
Training loss: 0.21997639536857605
Validation loss: 2.0009125669797263

Epoch: 421| Step: 0
Training loss: 0.19300958514213562
Validation loss: 1.9602372646331787

Epoch: 6| Step: 1
Training loss: 0.17948341369628906
Validation loss: 1.986519734064738

Epoch: 6| Step: 2
Training loss: 0.6026522517204285
Validation loss: 1.9565008680025737

Epoch: 6| Step: 3
Training loss: 0.19027619063854218
Validation loss: 1.979321579138438

Epoch: 6| Step: 4
Training loss: 0.22093026340007782
Validation loss: 1.95195867617925

Epoch: 6| Step: 5
Training loss: 0.18775832653045654
Validation loss: 1.983772297700246

Epoch: 6| Step: 6
Training loss: 0.20582544803619385
Validation loss: 2.0011767745018005

Epoch: 6| Step: 7
Training loss: 0.1430349051952362
Validation loss: 2.016119142373403

Epoch: 6| Step: 8
Training loss: 0.13603922724723816
Validation loss: 1.939913233121236

Epoch: 6| Step: 9
Training loss: 0.18017351627349854
Validation loss: 2.0054710308710733

Epoch: 6| Step: 10
Training loss: 0.2142314463853836
Validation loss: 1.9977792700131733

Epoch: 6| Step: 11
Training loss: 0.2455771267414093
Validation loss: 1.94813734292984

Epoch: 6| Step: 12
Training loss: 0.3337319493293762
Validation loss: 1.9791030883789062

Epoch: 6| Step: 13
Training loss: 0.20260019600391388
Validation loss: 2.0011895497639975

Epoch: 422| Step: 0
Training loss: 0.186512291431427
Validation loss: 1.9833807746569316

Epoch: 6| Step: 1
Training loss: 0.183434396982193
Validation loss: 2.0082477728525796

Epoch: 6| Step: 2
Training loss: 0.20465371012687683
Validation loss: 2.0017954111099243

Epoch: 6| Step: 3
Training loss: 0.42305988073349
Validation loss: 1.9770033955574036

Epoch: 6| Step: 4
Training loss: 0.20100827515125275
Validation loss: 1.9864602088928223

Epoch: 6| Step: 5
Training loss: 0.14318807423114777
Validation loss: 1.9812788367271423

Epoch: 6| Step: 6
Training loss: 0.33524441719055176
Validation loss: 2.0058160026868186

Epoch: 6| Step: 7
Training loss: 0.15898844599723816
Validation loss: 1.96468190352122

Epoch: 6| Step: 8
Training loss: 0.21135662496089935
Validation loss: 1.9847518006960552

Epoch: 6| Step: 9
Training loss: 0.16071853041648865
Validation loss: 1.9488537907600403

Epoch: 6| Step: 10
Training loss: 0.19734862446784973
Validation loss: 1.9846385320027669

Epoch: 6| Step: 11
Training loss: 0.17553135752677917
Validation loss: 1.9764992793401082

Epoch: 6| Step: 12
Training loss: 0.25545063614845276
Validation loss: 1.9884552756945293

Epoch: 6| Step: 13
Training loss: 0.46176016330718994
Validation loss: 1.9770598808924358

Epoch: 423| Step: 0
Training loss: 0.270191490650177
Validation loss: 1.992305318514506

Epoch: 6| Step: 1
Training loss: 0.1801651269197464
Validation loss: 1.9629698991775513

Epoch: 6| Step: 2
Training loss: 0.23889505863189697
Validation loss: 1.9674106637636821

Epoch: 6| Step: 3
Training loss: 0.21227705478668213
Validation loss: 1.9972122311592102

Epoch: 6| Step: 4
Training loss: 0.2301916480064392
Validation loss: 1.9384804765383403

Epoch: 6| Step: 5
Training loss: 0.15796712040901184
Validation loss: 1.9761765201886494

Epoch: 6| Step: 6
Training loss: 0.19611167907714844
Validation loss: 1.9734495878219604

Epoch: 6| Step: 7
Training loss: 0.17757537961006165
Validation loss: 1.9922989805539448

Epoch: 6| Step: 8
Training loss: 0.5339938998222351
Validation loss: 1.967537800470988

Epoch: 6| Step: 9
Training loss: 0.29491496086120605
Validation loss: 1.9848506649335225

Epoch: 6| Step: 10
Training loss: 0.1800968497991562
Validation loss: 1.9678869247436523

Epoch: 6| Step: 11
Training loss: 0.17020843923091888
Validation loss: 1.969503660996755

Epoch: 6| Step: 12
Training loss: 0.24898448586463928
Validation loss: 2.007228950659434

Epoch: 6| Step: 13
Training loss: 0.20742832124233246
Validation loss: 2.0031659801801047

Epoch: 424| Step: 0
Training loss: 0.18639028072357178
Validation loss: 1.9932219783465068

Epoch: 6| Step: 1
Training loss: 0.22092066705226898
Validation loss: 2.0174362659454346

Epoch: 6| Step: 2
Training loss: 0.1983599215745926
Validation loss: 1.971105694770813

Epoch: 6| Step: 3
Training loss: 0.22483545541763306
Validation loss: 1.9682794411977131

Epoch: 6| Step: 4
Training loss: 0.18116651475429535
Validation loss: 1.9720397591590881

Epoch: 6| Step: 5
Training loss: 0.24777336418628693
Validation loss: 1.9713867902755737

Epoch: 6| Step: 6
Training loss: 0.14531463384628296
Validation loss: 1.9632567763328552

Epoch: 6| Step: 7
Training loss: 0.14445871114730835
Validation loss: 1.9717394709587097

Epoch: 6| Step: 8
Training loss: 0.16042715311050415
Validation loss: 1.9994683464368184

Epoch: 6| Step: 9
Training loss: 0.6169055104255676
Validation loss: 1.9804166158040364

Epoch: 6| Step: 10
Training loss: 0.17626941204071045
Validation loss: 1.9911597569783528

Epoch: 6| Step: 11
Training loss: 0.3410102128982544
Validation loss: 1.9913565715154011

Epoch: 6| Step: 12
Training loss: 0.29992935061454773
Validation loss: 2.011403242746989

Epoch: 6| Step: 13
Training loss: 0.17127551138401031
Validation loss: 1.9850674867630005

Epoch: 425| Step: 0
Training loss: 0.2540230453014374
Validation loss: 1.9617343544960022

Epoch: 6| Step: 1
Training loss: 0.6341854929924011
Validation loss: 1.9969435731569927

Epoch: 6| Step: 2
Training loss: 0.2667737305164337
Validation loss: 1.9777587453524272

Epoch: 6| Step: 3
Training loss: 0.24019639194011688
Validation loss: 1.988014817237854

Epoch: 6| Step: 4
Training loss: 0.13759520649909973
Validation loss: 1.9766420125961304

Epoch: 6| Step: 5
Training loss: 0.3476850390434265
Validation loss: 1.970464328924815

Epoch: 6| Step: 6
Training loss: 0.15541282296180725
Validation loss: 1.9719815850257874

Epoch: 6| Step: 7
Training loss: 0.2062523066997528
Validation loss: 2.0184958775838218

Epoch: 6| Step: 8
Training loss: 0.19840210676193237
Validation loss: 1.9914247194925945

Epoch: 6| Step: 9
Training loss: 0.19386327266693115
Validation loss: 1.9466184377670288

Epoch: 6| Step: 10
Training loss: 0.14608119428157806
Validation loss: 1.9678231477737427

Epoch: 6| Step: 11
Training loss: 0.22364401817321777
Validation loss: 1.9680139621098836

Epoch: 6| Step: 12
Training loss: 0.1655561774969101
Validation loss: 1.9582441647847493

Epoch: 6| Step: 13
Training loss: 0.28381961584091187
Validation loss: 1.998469352722168

Epoch: 426| Step: 0
Training loss: 0.19225049018859863
Validation loss: 1.9642043312390645

Epoch: 6| Step: 1
Training loss: 0.2669795751571655
Validation loss: 1.957317054271698

Epoch: 6| Step: 2
Training loss: 0.3399503231048584
Validation loss: 1.9651094476381938

Epoch: 6| Step: 3
Training loss: 0.276462197303772
Validation loss: 1.978399137655894

Epoch: 6| Step: 4
Training loss: 0.15049584209918976
Validation loss: 1.9872291286786397

Epoch: 6| Step: 5
Training loss: 0.18449130654335022
Validation loss: 1.9417801300684612

Epoch: 6| Step: 6
Training loss: 0.22156041860580444
Validation loss: 1.9611641963322957

Epoch: 6| Step: 7
Training loss: 0.16665810346603394
Validation loss: 1.9748717149098713

Epoch: 6| Step: 8
Training loss: 0.21068927645683289
Validation loss: 1.9742997487386067

Epoch: 6| Step: 9
Training loss: 0.5205045938491821
Validation loss: 2.0005539655685425

Epoch: 6| Step: 10
Training loss: 0.41250044107437134
Validation loss: 1.9401025176048279

Epoch: 6| Step: 11
Training loss: 0.22063452005386353
Validation loss: 1.9676873882611592

Epoch: 6| Step: 12
Training loss: 0.17441575229167938
Validation loss: 1.9735913276672363

Epoch: 6| Step: 13
Training loss: 0.1289132833480835
Validation loss: 1.966440498828888

Epoch: 427| Step: 0
Training loss: 0.35899823904037476
Validation loss: 1.964700738588969

Epoch: 6| Step: 1
Training loss: 0.1669623851776123
Validation loss: 1.991757074991862

Epoch: 6| Step: 2
Training loss: 0.4991685152053833
Validation loss: 1.918663779894511

Epoch: 6| Step: 3
Training loss: 0.24251529574394226
Validation loss: 1.9731934666633606

Epoch: 6| Step: 4
Training loss: 0.1579028069972992
Validation loss: 2.001491904258728

Epoch: 6| Step: 5
Training loss: 0.18264815211296082
Validation loss: 1.9596928159395854

Epoch: 6| Step: 6
Training loss: 0.2744683623313904
Validation loss: 1.986434280872345

Epoch: 6| Step: 7
Training loss: 0.1671559363603592
Validation loss: 1.97840283314387

Epoch: 6| Step: 8
Training loss: 0.25439462065696716
Validation loss: 1.9707384904225667

Epoch: 6| Step: 9
Training loss: 0.1737174689769745
Validation loss: 1.970572789510091

Epoch: 6| Step: 10
Training loss: 0.1703919768333435
Validation loss: 1.9630329410235088

Epoch: 6| Step: 11
Training loss: 0.2654985785484314
Validation loss: 1.9898017644882202

Epoch: 6| Step: 12
Training loss: 0.2246442437171936
Validation loss: 1.9708774487177532

Epoch: 6| Step: 13
Training loss: 0.2207944542169571
Validation loss: 2.00508713722229

Epoch: 428| Step: 0
Training loss: 0.240550234913826
Validation loss: 2.00053075949351

Epoch: 6| Step: 1
Training loss: 0.2094191014766693
Validation loss: 1.9791441162427266

Epoch: 6| Step: 2
Training loss: 0.1692030131816864
Validation loss: 2.0102545619010925

Epoch: 6| Step: 3
Training loss: 0.17169609665870667
Validation loss: 1.96938556432724

Epoch: 6| Step: 4
Training loss: 0.20196056365966797
Validation loss: 1.9439568122227986

Epoch: 6| Step: 5
Training loss: 0.18279236555099487
Validation loss: 2.008413771788279

Epoch: 6| Step: 6
Training loss: 0.16109220683574677
Validation loss: 1.988899032274882

Epoch: 6| Step: 7
Training loss: 0.1710268259048462
Validation loss: 1.9892874757448833

Epoch: 6| Step: 8
Training loss: 0.2416602075099945
Validation loss: 1.950835406780243

Epoch: 6| Step: 9
Training loss: 0.14832934737205505
Validation loss: 1.9770037333170574

Epoch: 6| Step: 10
Training loss: 0.18999427556991577
Validation loss: 2.0041325092315674

Epoch: 6| Step: 11
Training loss: 0.30825382471084595
Validation loss: 2.0128541191418967

Epoch: 6| Step: 12
Training loss: 0.562233030796051
Validation loss: 2.021542509396871

Epoch: 6| Step: 13
Training loss: 0.1758027821779251
Validation loss: 1.969581405321757

Epoch: 429| Step: 0
Training loss: 0.25656038522720337
Validation loss: 2.0280928214391074

Epoch: 6| Step: 1
Training loss: 0.16536621749401093
Validation loss: 1.9778858224550884

Epoch: 6| Step: 2
Training loss: 0.49681079387664795
Validation loss: 1.98058025042216

Epoch: 6| Step: 3
Training loss: 0.24250346422195435
Validation loss: 2.0083453257878623

Epoch: 6| Step: 4
Training loss: 0.2072819173336029
Validation loss: 2.0331405202547708

Epoch: 6| Step: 5
Training loss: 0.17641910910606384
Validation loss: 1.9911253253618877

Epoch: 6| Step: 6
Training loss: 0.22160181403160095
Validation loss: 2.0032928387324014

Epoch: 6| Step: 7
Training loss: 0.23788410425186157
Validation loss: 2.015490194161733

Epoch: 6| Step: 8
Training loss: 0.16110356152057648
Validation loss: 1.996089021364848

Epoch: 6| Step: 9
Training loss: 0.23026281595230103
Validation loss: 1.9533946911493938

Epoch: 6| Step: 10
Training loss: 0.17513316869735718
Validation loss: 1.983888308207194

Epoch: 6| Step: 11
Training loss: 0.2152474820613861
Validation loss: 2.00377748409907

Epoch: 6| Step: 12
Training loss: 0.3506661057472229
Validation loss: 1.976397971312205

Epoch: 6| Step: 13
Training loss: 0.24556154012680054
Validation loss: 2.0099453131357827

Epoch: 430| Step: 0
Training loss: 0.2303469479084015
Validation loss: 2.0109394192695618

Epoch: 6| Step: 1
Training loss: 0.22545695304870605
Validation loss: 1.9908036986986797

Epoch: 6| Step: 2
Training loss: 0.15909217298030853
Validation loss: 1.9948850870132446

Epoch: 6| Step: 3
Training loss: 0.307455837726593
Validation loss: 1.9850529630978901

Epoch: 6| Step: 4
Training loss: 0.27188897132873535
Validation loss: 1.9699250062306721

Epoch: 6| Step: 5
Training loss: 0.28148627281188965
Validation loss: 1.9627204537391663

Epoch: 6| Step: 6
Training loss: 0.3401167690753937
Validation loss: 2.0021642446517944

Epoch: 6| Step: 7
Training loss: 0.20217987895011902
Validation loss: 1.9905499815940857

Epoch: 6| Step: 8
Training loss: 0.22049756348133087
Validation loss: 1.9721725185712178

Epoch: 6| Step: 9
Training loss: 0.6298744678497314
Validation loss: 1.9819220701853435

Epoch: 6| Step: 10
Training loss: 0.1907862424850464
Validation loss: 1.938885470231374

Epoch: 6| Step: 11
Training loss: 0.2696978449821472
Validation loss: 1.9821774164835613

Epoch: 6| Step: 12
Training loss: 0.27534615993499756
Validation loss: 1.9644242922465007

Epoch: 6| Step: 13
Training loss: 0.3435138463973999
Validation loss: 1.9428723653157551

Epoch: 431| Step: 0
Training loss: 0.46016544103622437
Validation loss: 1.9784905513127644

Epoch: 6| Step: 1
Training loss: 0.2585955858230591
Validation loss: 1.9785690903663635

Epoch: 6| Step: 2
Training loss: 0.16468851268291473
Validation loss: 1.9662546118100483

Epoch: 6| Step: 3
Training loss: 0.22635972499847412
Validation loss: 1.9688912630081177

Epoch: 6| Step: 4
Training loss: 0.2850678265094757
Validation loss: 1.9252625306447346

Epoch: 6| Step: 5
Training loss: 0.2007039189338684
Validation loss: 1.953380326430003

Epoch: 6| Step: 6
Training loss: 0.18366174399852753
Validation loss: 1.9428053895632427

Epoch: 6| Step: 7
Training loss: 0.16330870985984802
Validation loss: 1.94780033826828

Epoch: 6| Step: 8
Training loss: 0.5257260203361511
Validation loss: 1.9617332816123962

Epoch: 6| Step: 9
Training loss: 0.14782704412937164
Validation loss: 1.9127121170361836

Epoch: 6| Step: 10
Training loss: 0.171023428440094
Validation loss: 1.9909198085467021

Epoch: 6| Step: 11
Training loss: 0.18926939368247986
Validation loss: 1.9796964724858601

Epoch: 6| Step: 12
Training loss: 0.21947622299194336
Validation loss: 1.9101150035858154

Epoch: 6| Step: 13
Training loss: 0.19233649969100952
Validation loss: 1.9488874673843384

Epoch: 432| Step: 0
Training loss: 0.3587215542793274
Validation loss: 1.9491521120071411

Epoch: 6| Step: 1
Training loss: 0.20237712562084198
Validation loss: 1.934451401233673

Epoch: 6| Step: 2
Training loss: 0.14637255668640137
Validation loss: 1.9505280653635662

Epoch: 6| Step: 3
Training loss: 0.24272438883781433
Validation loss: 1.9559523860613506

Epoch: 6| Step: 4
Training loss: 0.15977352857589722
Validation loss: 1.9721866250038147

Epoch: 6| Step: 5
Training loss: 0.1378699392080307
Validation loss: 1.9561938444773357

Epoch: 6| Step: 6
Training loss: 0.15649858117103577
Validation loss: 1.938486377398173

Epoch: 6| Step: 7
Training loss: 0.262286514043808
Validation loss: 1.9537092447280884

Epoch: 6| Step: 8
Training loss: 0.5255670547485352
Validation loss: 1.9550431966781616

Epoch: 6| Step: 9
Training loss: 0.14621195197105408
Validation loss: 1.9281947016716003

Epoch: 6| Step: 10
Training loss: 0.2206956297159195
Validation loss: 1.9663742184638977

Epoch: 6| Step: 11
Training loss: 0.15344540774822235
Validation loss: 1.9717939297358196

Epoch: 6| Step: 12
Training loss: 0.22650209069252014
Validation loss: 1.9650402863820393

Epoch: 6| Step: 13
Training loss: 0.22126352787017822
Validation loss: 1.9650777379671733

Epoch: 433| Step: 0
Training loss: 0.1876223385334015
Validation loss: 2.0030201276143393

Epoch: 6| Step: 1
Training loss: 0.27362698316574097
Validation loss: 1.958040436108907

Epoch: 6| Step: 2
Training loss: 0.32846856117248535
Validation loss: 1.9619726538658142

Epoch: 6| Step: 3
Training loss: 0.20754259824752808
Validation loss: 1.9717755715052288

Epoch: 6| Step: 4
Training loss: 0.18053984642028809
Validation loss: 1.959564785162608

Epoch: 6| Step: 5
Training loss: 0.2397962212562561
Validation loss: 1.960608979066213

Epoch: 6| Step: 6
Training loss: 0.1393422782421112
Validation loss: 1.9886490901311238

Epoch: 6| Step: 7
Training loss: 0.181741863489151
Validation loss: 1.9735903938611348

Epoch: 6| Step: 8
Training loss: 0.15969744324684143
Validation loss: 1.9632787903149922

Epoch: 6| Step: 9
Training loss: 0.22402168810367584
Validation loss: 1.9917435844739277

Epoch: 6| Step: 10
Training loss: 0.5674484968185425
Validation loss: 2.003383000691732

Epoch: 6| Step: 11
Training loss: 0.26233282685279846
Validation loss: 2.013218025366465

Epoch: 6| Step: 12
Training loss: 0.24880839884281158
Validation loss: 1.9969510634740193

Epoch: 6| Step: 13
Training loss: 0.316148042678833
Validation loss: 1.9706695477167766

Epoch: 434| Step: 0
Training loss: 0.3778230547904968
Validation loss: 1.988340934117635

Epoch: 6| Step: 1
Training loss: 0.16117946803569794
Validation loss: 1.9741075833638508

Epoch: 6| Step: 2
Training loss: 0.36896243691444397
Validation loss: 1.9387398560841878

Epoch: 6| Step: 3
Training loss: 0.3885713815689087
Validation loss: 1.987571398417155

Epoch: 6| Step: 4
Training loss: 0.19845238327980042
Validation loss: 1.9943620363871257

Epoch: 6| Step: 5
Training loss: 0.4634554386138916
Validation loss: 1.96124134461085

Epoch: 6| Step: 6
Training loss: 0.21240009367465973
Validation loss: 1.971702794233958

Epoch: 6| Step: 7
Training loss: 0.22243273258209229
Validation loss: 2.0213392972946167

Epoch: 6| Step: 8
Training loss: 0.16544507443904877
Validation loss: 1.9876528978347778

Epoch: 6| Step: 9
Training loss: 0.2944659888744354
Validation loss: 2.022967755794525

Epoch: 6| Step: 10
Training loss: 0.21565695106983185
Validation loss: 1.9894551237424214

Epoch: 6| Step: 11
Training loss: 0.2317454069852829
Validation loss: 2.0251667499542236

Epoch: 6| Step: 12
Training loss: 0.17210836708545685
Validation loss: 2.001884380976359

Epoch: 6| Step: 13
Training loss: 0.2028931975364685
Validation loss: 1.976794958114624

Epoch: 435| Step: 0
Training loss: 0.17154598236083984
Validation loss: 2.002777934074402

Epoch: 6| Step: 1
Training loss: 0.3439304828643799
Validation loss: 2.0055265029271445

Epoch: 6| Step: 2
Training loss: 0.15357056260108948
Validation loss: 2.011599878470103

Epoch: 6| Step: 3
Training loss: 0.29637956619262695
Validation loss: 1.9761716922124226

Epoch: 6| Step: 4
Training loss: 0.17236879467964172
Validation loss: 1.9817011555035908

Epoch: 6| Step: 5
Training loss: 0.17575165629386902
Validation loss: 1.9976799885431926

Epoch: 6| Step: 6
Training loss: 0.5101978778839111
Validation loss: 1.9648051460584004

Epoch: 6| Step: 7
Training loss: 0.2567605972290039
Validation loss: 1.9782187541325886

Epoch: 6| Step: 8
Training loss: 0.12828020751476288
Validation loss: 1.9699627955754597

Epoch: 6| Step: 9
Training loss: 0.2583913505077362
Validation loss: 1.9703150788942974

Epoch: 6| Step: 10
Training loss: 0.21480393409729004
Validation loss: 1.996160586675008

Epoch: 6| Step: 11
Training loss: 0.2128751575946808
Validation loss: 1.9754992127418518

Epoch: 6| Step: 12
Training loss: 0.11869726330041885
Validation loss: 1.9805347522099812

Epoch: 6| Step: 13
Training loss: 0.10329815745353699
Validation loss: 1.9681034882863362

Epoch: 436| Step: 0
Training loss: 0.30785906314849854
Validation loss: 1.9784526824951172

Epoch: 6| Step: 1
Training loss: 0.2328866422176361
Validation loss: 2.01756751537323

Epoch: 6| Step: 2
Training loss: 0.19637253880500793
Validation loss: 2.0077250401178994

Epoch: 6| Step: 3
Training loss: 0.1988602876663208
Validation loss: 1.9444982210795085

Epoch: 6| Step: 4
Training loss: 0.21578900516033173
Validation loss: 1.9801087975502014

Epoch: 6| Step: 5
Training loss: 0.28587350249290466
Validation loss: 1.9574300050735474

Epoch: 6| Step: 6
Training loss: 0.5874342322349548
Validation loss: 1.990584174791972

Epoch: 6| Step: 7
Training loss: 0.2651383578777313
Validation loss: 1.9791925350824993

Epoch: 6| Step: 8
Training loss: 0.18609914183616638
Validation loss: 1.9651349782943726

Epoch: 6| Step: 9
Training loss: 0.25166767835617065
Validation loss: 2.0059803326924643

Epoch: 6| Step: 10
Training loss: 0.252729594707489
Validation loss: 1.971574107805888

Epoch: 6| Step: 11
Training loss: 0.18079301714897156
Validation loss: 1.9850105841954548

Epoch: 6| Step: 12
Training loss: 0.3467904329299927
Validation loss: 1.9787520964940388

Epoch: 6| Step: 13
Training loss: 0.19950830936431885
Validation loss: 1.96687912940979

Epoch: 437| Step: 0
Training loss: 0.20127719640731812
Validation loss: 1.965851863225301

Epoch: 6| Step: 1
Training loss: 0.1769014596939087
Validation loss: 1.9369577368100483

Epoch: 6| Step: 2
Training loss: 0.2897346615791321
Validation loss: 1.9477103352546692

Epoch: 6| Step: 3
Training loss: 0.21706433594226837
Validation loss: 1.996401846408844

Epoch: 6| Step: 4
Training loss: 0.21690258383750916
Validation loss: 1.9818981289863586

Epoch: 6| Step: 5
Training loss: 0.2200724482536316
Validation loss: 1.9756593505541484

Epoch: 6| Step: 6
Training loss: 0.15651914477348328
Validation loss: 2.016899267832438

Epoch: 6| Step: 7
Training loss: 0.16871151328086853
Validation loss: 1.9808376828829448

Epoch: 6| Step: 8
Training loss: 0.2792436480522156
Validation loss: 1.9875160058339436

Epoch: 6| Step: 9
Training loss: 0.18404793739318848
Validation loss: 1.9876754681269329

Epoch: 6| Step: 10
Training loss: 0.2876889705657959
Validation loss: 1.997019092241923

Epoch: 6| Step: 11
Training loss: 0.22213149070739746
Validation loss: 2.002889712651571

Epoch: 6| Step: 12
Training loss: 0.2083418369293213
Validation loss: 2.0106881856918335

Epoch: 6| Step: 13
Training loss: 0.541808545589447
Validation loss: 1.9828960696856182

Epoch: 438| Step: 0
Training loss: 0.21911507844924927
Validation loss: 1.9562719464302063

Epoch: 6| Step: 1
Training loss: 0.15133818984031677
Validation loss: 1.9525047938028972

Epoch: 6| Step: 2
Training loss: 0.17217786610126495
Validation loss: 2.015313446521759

Epoch: 6| Step: 3
Training loss: 0.13846281170845032
Validation loss: 2.004503091176351

Epoch: 6| Step: 4
Training loss: 0.23894402384757996
Validation loss: 2.020641247431437

Epoch: 6| Step: 5
Training loss: 0.22527560591697693
Validation loss: 1.9751400152842205

Epoch: 6| Step: 6
Training loss: 0.2145949900150299
Validation loss: 1.9560209115346272

Epoch: 6| Step: 7
Training loss: 0.27231472730636597
Validation loss: 1.9932917555173237

Epoch: 6| Step: 8
Training loss: 0.7410727739334106
Validation loss: 1.9467227458953857

Epoch: 6| Step: 9
Training loss: 0.29280608892440796
Validation loss: 1.9737205108006795

Epoch: 6| Step: 10
Training loss: 0.2370385080575943
Validation loss: 2.008001983165741

Epoch: 6| Step: 11
Training loss: 0.269711971282959
Validation loss: 1.9867331981658936

Epoch: 6| Step: 12
Training loss: 0.19009962677955627
Validation loss: 2.0169759591420493

Epoch: 6| Step: 13
Training loss: 0.2267913818359375
Validation loss: 2.005774716536204

Epoch: 439| Step: 0
Training loss: 0.18326273560523987
Validation loss: 2.0125258962313333

Epoch: 6| Step: 1
Training loss: 0.2262982875108719
Validation loss: 1.988942265510559

Epoch: 6| Step: 2
Training loss: 0.18493923544883728
Validation loss: 1.9900422890981038

Epoch: 6| Step: 3
Training loss: 0.3615303039550781
Validation loss: 1.984221637248993

Epoch: 6| Step: 4
Training loss: 0.31378787755966187
Validation loss: 1.9755240082740784

Epoch: 6| Step: 5
Training loss: 0.16770127415657043
Validation loss: 1.9527589877446492

Epoch: 6| Step: 6
Training loss: 0.2577754259109497
Validation loss: 1.9592203696568806

Epoch: 6| Step: 7
Training loss: 0.2618938982486725
Validation loss: 2.046855350335439

Epoch: 6| Step: 8
Training loss: 0.686508059501648
Validation loss: 1.95844304561615

Epoch: 6| Step: 9
Training loss: 0.34793931245803833
Validation loss: 1.9799198905626934

Epoch: 6| Step: 10
Training loss: 0.2742616832256317
Validation loss: 2.0037249326705933

Epoch: 6| Step: 11
Training loss: 0.28333956003189087
Validation loss: 1.9869256814320881

Epoch: 6| Step: 12
Training loss: 0.22110415995121002
Validation loss: 1.9913628896077473

Epoch: 6| Step: 13
Training loss: 0.19120128452777863
Validation loss: 1.9866653680801392

Epoch: 440| Step: 0
Training loss: 0.16466888785362244
Validation loss: 1.978879193464915

Epoch: 6| Step: 1
Training loss: 0.3105930984020233
Validation loss: 1.9933391213417053

Epoch: 6| Step: 2
Training loss: 0.18140378594398499
Validation loss: 1.979820708433787

Epoch: 6| Step: 3
Training loss: 0.20085862278938293
Validation loss: 1.9747215906778972

Epoch: 6| Step: 4
Training loss: 0.24976742267608643
Validation loss: 2.009289542833964

Epoch: 6| Step: 5
Training loss: 0.5523644685745239
Validation loss: 1.982248584429423

Epoch: 6| Step: 6
Training loss: 0.22890260815620422
Validation loss: 1.9752075672149658

Epoch: 6| Step: 7
Training loss: 0.18583741784095764
Validation loss: 1.970142384370168

Epoch: 6| Step: 8
Training loss: 0.24133363366127014
Validation loss: 1.9871429800987244

Epoch: 6| Step: 9
Training loss: 0.22509515285491943
Validation loss: 1.9835707147916157

Epoch: 6| Step: 10
Training loss: 0.18559913337230682
Validation loss: 2.010524352391561

Epoch: 6| Step: 11
Training loss: 0.19592514634132385
Validation loss: 1.955548067887624

Epoch: 6| Step: 12
Training loss: 0.19857719540596008
Validation loss: 2.0412315130233765

Epoch: 6| Step: 13
Training loss: 0.1913662850856781
Validation loss: 2.008055051167806

Epoch: 441| Step: 0
Training loss: 0.1951233446598053
Validation loss: 2.007315178712209

Epoch: 6| Step: 1
Training loss: 0.2402714192867279
Validation loss: 2.0285011728604636

Epoch: 6| Step: 2
Training loss: 0.35711032152175903
Validation loss: 2.0070301493008933

Epoch: 6| Step: 3
Training loss: 0.16806405782699585
Validation loss: 2.02616020043691

Epoch: 6| Step: 4
Training loss: 0.21568170189857483
Validation loss: 1.9716495871543884

Epoch: 6| Step: 5
Training loss: 0.18189182877540588
Validation loss: 2.009972095489502

Epoch: 6| Step: 6
Training loss: 0.257426381111145
Validation loss: 2.0167155265808105

Epoch: 6| Step: 7
Training loss: 0.18506406247615814
Validation loss: 2.025478800137838

Epoch: 6| Step: 8
Training loss: 0.245988667011261
Validation loss: 1.9951240420341492

Epoch: 6| Step: 9
Training loss: 0.14310482144355774
Validation loss: 1.9698967536290486

Epoch: 6| Step: 10
Training loss: 0.5610845685005188
Validation loss: 1.9550465146700542

Epoch: 6| Step: 11
Training loss: 0.1651507318019867
Validation loss: 1.9669418732325237

Epoch: 6| Step: 12
Training loss: 0.20676448941230774
Validation loss: 1.999339799086253

Epoch: 6| Step: 13
Training loss: 0.2053353190422058
Validation loss: 1.982053279876709

Epoch: 442| Step: 0
Training loss: 0.2035304605960846
Validation loss: 2.000954508781433

Epoch: 6| Step: 1
Training loss: 0.25113365054130554
Validation loss: 2.001996119817098

Epoch: 6| Step: 2
Training loss: 0.558957576751709
Validation loss: 1.9867561260859172

Epoch: 6| Step: 3
Training loss: 0.23086272180080414
Validation loss: 2.0082491437594094

Epoch: 6| Step: 4
Training loss: 0.19429588317871094
Validation loss: 2.007249434789022

Epoch: 6| Step: 5
Training loss: 0.18271823227405548
Validation loss: 1.9855427940686543

Epoch: 6| Step: 6
Training loss: 0.1974256932735443
Validation loss: 1.9859617749849956

Epoch: 6| Step: 7
Training loss: 0.1669575273990631
Validation loss: 1.9623319904009502

Epoch: 6| Step: 8
Training loss: 0.20093552768230438
Validation loss: 2.018109977245331

Epoch: 6| Step: 9
Training loss: 0.2982334494590759
Validation loss: 1.9824441075325012

Epoch: 6| Step: 10
Training loss: 0.20558395981788635
Validation loss: 1.9951759378115337

Epoch: 6| Step: 11
Training loss: 0.20051684975624084
Validation loss: 1.9613311688105266

Epoch: 6| Step: 12
Training loss: 0.262134313583374
Validation loss: 1.974053184191386

Epoch: 6| Step: 13
Training loss: 0.21703170239925385
Validation loss: 1.9956557552019756

Epoch: 443| Step: 0
Training loss: 0.7567587494850159
Validation loss: 1.9459391236305237

Epoch: 6| Step: 1
Training loss: 0.19574478268623352
Validation loss: 1.987464725971222

Epoch: 6| Step: 2
Training loss: 0.1779681295156479
Validation loss: 1.9577930172284443

Epoch: 6| Step: 3
Training loss: 0.18517455458641052
Validation loss: 1.9805288116137187

Epoch: 6| Step: 4
Training loss: 0.14929337799549103
Validation loss: 1.9876595934232075

Epoch: 6| Step: 5
Training loss: 0.21125344932079315
Validation loss: 1.953256328900655

Epoch: 6| Step: 6
Training loss: 0.158991277217865
Validation loss: 1.9374786218007405

Epoch: 6| Step: 7
Training loss: 0.16494372487068176
Validation loss: 1.9626547892888386

Epoch: 6| Step: 8
Training loss: 0.14255836606025696
Validation loss: 1.9533479611078899

Epoch: 6| Step: 9
Training loss: 0.13057219982147217
Validation loss: 1.9632400075594585

Epoch: 6| Step: 10
Training loss: 0.20257233083248138
Validation loss: 1.99415922164917

Epoch: 6| Step: 11
Training loss: 0.21133962273597717
Validation loss: 1.9922220905621846

Epoch: 6| Step: 12
Training loss: 0.19047437608242035
Validation loss: 1.9876028696695964

Epoch: 6| Step: 13
Training loss: 0.18745161592960358
Validation loss: 1.9979823231697083

Epoch: 444| Step: 0
Training loss: 0.28019317984580994
Validation loss: 2.00650684038798

Epoch: 6| Step: 1
Training loss: 0.19298632442951202
Validation loss: 1.9857634504636128

Epoch: 6| Step: 2
Training loss: 0.3503342270851135
Validation loss: 2.0071257948875427

Epoch: 6| Step: 3
Training loss: 0.23154257237911224
Validation loss: 2.035287837187449

Epoch: 6| Step: 4
Training loss: 0.13014185428619385
Validation loss: 2.0331104000409446

Epoch: 6| Step: 5
Training loss: 0.16689544916152954
Validation loss: 1.9963147044181824

Epoch: 6| Step: 6
Training loss: 0.19525350630283356
Validation loss: 1.9803759654362996

Epoch: 6| Step: 7
Training loss: 0.21817930042743683
Validation loss: 1.9674055377642314

Epoch: 6| Step: 8
Training loss: 0.25562387704849243
Validation loss: 1.9591762224833171

Epoch: 6| Step: 9
Training loss: 0.1937406063079834
Validation loss: 1.9866177241007488

Epoch: 6| Step: 10
Training loss: 0.49089813232421875
Validation loss: 2.0138391057650247

Epoch: 6| Step: 11
Training loss: 0.2118249088525772
Validation loss: 1.9941660563151042

Epoch: 6| Step: 12
Training loss: 0.1493355631828308
Validation loss: 2.008885165055593

Epoch: 6| Step: 13
Training loss: 0.12468789517879486
Validation loss: 1.979706843694051

Epoch: 445| Step: 0
Training loss: 0.22087642550468445
Validation loss: 1.974157452583313

Epoch: 6| Step: 1
Training loss: 0.2264474630355835
Validation loss: 1.9902852376302083

Epoch: 6| Step: 2
Training loss: 0.19892460107803345
Validation loss: 2.005632837613424

Epoch: 6| Step: 3
Training loss: 0.16913703083992004
Validation loss: 1.9988406697909038

Epoch: 6| Step: 4
Training loss: 0.21257284283638
Validation loss: 1.9874159495035808

Epoch: 6| Step: 5
Training loss: 0.24471372365951538
Validation loss: 1.963912347952525

Epoch: 6| Step: 6
Training loss: 0.2514606714248657
Validation loss: 1.9711198210716248

Epoch: 6| Step: 7
Training loss: 0.5108171105384827
Validation loss: 1.9708325266838074

Epoch: 6| Step: 8
Training loss: 0.21162791550159454
Validation loss: 2.0172911087671914

Epoch: 6| Step: 9
Training loss: 0.19709432125091553
Validation loss: 1.9954244494438171

Epoch: 6| Step: 10
Training loss: 0.25612741708755493
Validation loss: 2.0254117449124656

Epoch: 6| Step: 11
Training loss: 0.2024577111005783
Validation loss: 1.9760393102963765

Epoch: 6| Step: 12
Training loss: 0.2229699194431305
Validation loss: 1.969177782535553

Epoch: 6| Step: 13
Training loss: 0.2733052968978882
Validation loss: 1.9598344961802165

Epoch: 446| Step: 0
Training loss: 0.20879164338111877
Validation loss: 1.986797034740448

Epoch: 6| Step: 1
Training loss: 0.2265789955854416
Validation loss: 1.9865604440371196

Epoch: 6| Step: 2
Training loss: 0.21100762486457825
Validation loss: 1.9936579863230388

Epoch: 6| Step: 3
Training loss: 0.19352030754089355
Validation loss: 1.9892835021018982

Epoch: 6| Step: 4
Training loss: 0.1974431872367859
Validation loss: 1.9993617534637451

Epoch: 6| Step: 5
Training loss: 0.1161419153213501
Validation loss: 1.9849783976872761

Epoch: 6| Step: 6
Training loss: 0.19649721682071686
Validation loss: 1.997222125530243

Epoch: 6| Step: 7
Training loss: 0.17138531804084778
Validation loss: 1.971097707748413

Epoch: 6| Step: 8
Training loss: 0.1436791568994522
Validation loss: 1.980629324913025

Epoch: 6| Step: 9
Training loss: 0.1707649677991867
Validation loss: 2.0092283487319946

Epoch: 6| Step: 10
Training loss: 0.2824362516403198
Validation loss: 2.0061935981114707

Epoch: 6| Step: 11
Training loss: 0.25800251960754395
Validation loss: 1.9541428486506145

Epoch: 6| Step: 12
Training loss: 0.21620208024978638
Validation loss: 1.999798874060313

Epoch: 6| Step: 13
Training loss: 0.5842809677124023
Validation loss: 1.971440851688385

Epoch: 447| Step: 0
Training loss: 0.5626133680343628
Validation loss: 2.002317468325297

Epoch: 6| Step: 1
Training loss: 0.1905626654624939
Validation loss: 1.9610234498977661

Epoch: 6| Step: 2
Training loss: 0.1602090448141098
Validation loss: 1.996972680091858

Epoch: 6| Step: 3
Training loss: 0.29995593428611755
Validation loss: 1.9762885570526123

Epoch: 6| Step: 4
Training loss: 0.20994693040847778
Validation loss: 1.9708887736002605

Epoch: 6| Step: 5
Training loss: 0.23784610629081726
Validation loss: 2.016903837521871

Epoch: 6| Step: 6
Training loss: 0.3131384253501892
Validation loss: 1.9775950113932292

Epoch: 6| Step: 7
Training loss: 0.17182810604572296
Validation loss: 1.9636462728182476

Epoch: 6| Step: 8
Training loss: 0.20569093525409698
Validation loss: 2.0037693977355957

Epoch: 6| Step: 9
Training loss: 0.13950413465499878
Validation loss: 1.984346091747284

Epoch: 6| Step: 10
Training loss: 0.20256301760673523
Validation loss: 2.0054526726404824

Epoch: 6| Step: 11
Training loss: 0.18044427037239075
Validation loss: 1.9744563897450764

Epoch: 6| Step: 12
Training loss: 0.25460219383239746
Validation loss: 1.9904201825459797

Epoch: 6| Step: 13
Training loss: 0.23601381480693817
Validation loss: 2.003102481365204

Epoch: 448| Step: 0
Training loss: 0.6391657590866089
Validation loss: 2.0079745054244995

Epoch: 6| Step: 1
Training loss: 0.23559191823005676
Validation loss: 1.9974137544631958

Epoch: 6| Step: 2
Training loss: 0.20180529356002808
Validation loss: 2.0180885990460715

Epoch: 6| Step: 3
Training loss: 0.2622361183166504
Validation loss: 2.021113077799479

Epoch: 6| Step: 4
Training loss: 0.2586226165294647
Validation loss: 2.0310844580332437

Epoch: 6| Step: 5
Training loss: 0.12374600768089294
Validation loss: 2.0196230014165244

Epoch: 6| Step: 6
Training loss: 0.17207089066505432
Validation loss: 2.016730864842733

Epoch: 6| Step: 7
Training loss: 0.24254515767097473
Validation loss: 1.9882257382074993

Epoch: 6| Step: 8
Training loss: 0.3091955780982971
Validation loss: 1.9804689685503643

Epoch: 6| Step: 9
Training loss: 0.16818451881408691
Validation loss: 2.0153006513913474

Epoch: 6| Step: 10
Training loss: 0.1686827540397644
Validation loss: 1.993872086207072

Epoch: 6| Step: 11
Training loss: 0.21723656356334686
Validation loss: 1.9875310063362122

Epoch: 6| Step: 12
Training loss: 0.274196982383728
Validation loss: 1.9879912336667378

Epoch: 6| Step: 13
Training loss: 0.23307986557483673
Validation loss: 2.0164466500282288

Epoch: 449| Step: 0
Training loss: 0.31998011469841003
Validation loss: 2.028512636820475

Epoch: 6| Step: 1
Training loss: 0.5254366397857666
Validation loss: 1.9564099113146465

Epoch: 6| Step: 2
Training loss: 0.14497461915016174
Validation loss: 1.9577954411506653

Epoch: 6| Step: 3
Training loss: 0.187841534614563
Validation loss: 2.0141084790229797

Epoch: 6| Step: 4
Training loss: 0.20725035667419434
Validation loss: 2.0072747270266214

Epoch: 6| Step: 5
Training loss: 0.23503930866718292
Validation loss: 1.9717384576797485

Epoch: 6| Step: 6
Training loss: 0.2823178470134735
Validation loss: 1.9646801749865215

Epoch: 6| Step: 7
Training loss: 0.15755489468574524
Validation loss: 1.9618530869483948

Epoch: 6| Step: 8
Training loss: 0.16143058240413666
Validation loss: 1.9832919239997864

Epoch: 6| Step: 9
Training loss: 0.14297588169574738
Validation loss: 2.0061461130777993

Epoch: 6| Step: 10
Training loss: 0.22691437602043152
Validation loss: 2.0274581909179688

Epoch: 6| Step: 11
Training loss: 0.15426841378211975
Validation loss: 2.0184744397799173

Epoch: 6| Step: 12
Training loss: 0.217897430062294
Validation loss: 1.9866340160369873

Epoch: 6| Step: 13
Training loss: 0.19997090101242065
Validation loss: 2.0287012656529746

Epoch: 450| Step: 0
Training loss: 0.25701427459716797
Validation loss: 2.0058394273122153

Epoch: 6| Step: 1
Training loss: 0.21628330647945404
Validation loss: 1.9941694537798564

Epoch: 6| Step: 2
Training loss: 0.17487455904483795
Validation loss: 1.990260660648346

Epoch: 6| Step: 3
Training loss: 0.2564466893672943
Validation loss: 1.9905134240786235

Epoch: 6| Step: 4
Training loss: 0.15142858028411865
Validation loss: 1.9950539867083232

Epoch: 6| Step: 5
Training loss: 0.14997175335884094
Validation loss: 1.998880128065745

Epoch: 6| Step: 6
Training loss: 0.17647810280323029
Validation loss: 1.980605661869049

Epoch: 6| Step: 7
Training loss: 0.5180697441101074
Validation loss: 1.9923606713612874

Epoch: 6| Step: 8
Training loss: 0.16264361143112183
Validation loss: 1.9652893940607707

Epoch: 6| Step: 9
Training loss: 0.18592163920402527
Validation loss: 1.994674801826477

Epoch: 6| Step: 10
Training loss: 0.31600329279899597
Validation loss: 1.9704827070236206

Epoch: 6| Step: 11
Training loss: 0.14713115990161896
Validation loss: 1.9918387929598491

Epoch: 6| Step: 12
Training loss: 0.14428427815437317
Validation loss: 1.990952769915263

Epoch: 6| Step: 13
Training loss: 0.18073809146881104
Validation loss: 1.9869727889696758

Epoch: 451| Step: 0
Training loss: 0.20170444250106812
Validation loss: 1.9664660692214966

Epoch: 6| Step: 1
Training loss: 0.19549915194511414
Validation loss: 2.0177390972773233

Epoch: 6| Step: 2
Training loss: 0.26634347438812256
Validation loss: 1.973572353521983

Epoch: 6| Step: 3
Training loss: 0.1354566216468811
Validation loss: 1.9787697990735371

Epoch: 6| Step: 4
Training loss: 0.35534733533859253
Validation loss: 2.0032710234324136

Epoch: 6| Step: 5
Training loss: 0.2673173248767853
Validation loss: 1.9979528387387593

Epoch: 6| Step: 6
Training loss: 0.13467222452163696
Validation loss: 2.003425637880961

Epoch: 6| Step: 7
Training loss: 0.12553834915161133
Validation loss: 2.0015076796213784

Epoch: 6| Step: 8
Training loss: 0.1829693615436554
Validation loss: 1.9783099293708801

Epoch: 6| Step: 9
Training loss: 0.1620447337627411
Validation loss: 1.9909793337186177

Epoch: 6| Step: 10
Training loss: 0.22334390878677368
Validation loss: 1.9747567971547444

Epoch: 6| Step: 11
Training loss: 0.5246184468269348
Validation loss: 2.017658293247223

Epoch: 6| Step: 12
Training loss: 0.21311575174331665
Validation loss: 2.0063246885935464

Epoch: 6| Step: 13
Training loss: 0.17187117040157318
Validation loss: 2.010586678981781

Epoch: 452| Step: 0
Training loss: 0.5430085062980652
Validation loss: 1.9757217566172283

Epoch: 6| Step: 1
Training loss: 0.18077009916305542
Validation loss: 1.9918239116668701

Epoch: 6| Step: 2
Training loss: 0.22930951416492462
Validation loss: 2.004971444606781

Epoch: 6| Step: 3
Training loss: 0.21020998060703278
Validation loss: 2.0048506259918213

Epoch: 6| Step: 4
Training loss: 0.21236887574195862
Validation loss: 2.0067274967829385

Epoch: 6| Step: 5
Training loss: 0.23377785086631775
Validation loss: 2.027669688065847

Epoch: 6| Step: 6
Training loss: 0.18762657046318054
Validation loss: 2.0134109059969583

Epoch: 6| Step: 7
Training loss: 0.19010275602340698
Validation loss: 2.0139487584431968

Epoch: 6| Step: 8
Training loss: 0.31445252895355225
Validation loss: 1.9960741798082988

Epoch: 6| Step: 9
Training loss: 0.25142568349838257
Validation loss: 1.9962637225786846

Epoch: 6| Step: 10
Training loss: 0.2220366895198822
Validation loss: 2.0053782860438027

Epoch: 6| Step: 11
Training loss: 0.15974286198616028
Validation loss: 1.9932152231534321

Epoch: 6| Step: 12
Training loss: 0.22071486711502075
Validation loss: 1.9834338227907817

Epoch: 6| Step: 13
Training loss: 0.18456004559993744
Validation loss: 1.9874421159426372

Epoch: 453| Step: 0
Training loss: 0.2165830433368683
Validation loss: 1.986110766728719

Epoch: 6| Step: 1
Training loss: 0.2216283679008484
Validation loss: 1.9625293811162312

Epoch: 6| Step: 2
Training loss: 0.28800684213638306
Validation loss: 2.0095970233281455

Epoch: 6| Step: 3
Training loss: 0.2308158576488495
Validation loss: 1.9790389935175579

Epoch: 6| Step: 4
Training loss: 0.1625373363494873
Validation loss: 2.0134077270825705

Epoch: 6| Step: 5
Training loss: 0.1769321858882904
Validation loss: 1.9652806123097737

Epoch: 6| Step: 6
Training loss: 0.6059606075286865
Validation loss: 1.9989227056503296

Epoch: 6| Step: 7
Training loss: 0.16869938373565674
Validation loss: 1.9941561222076416

Epoch: 6| Step: 8
Training loss: 0.1983342170715332
Validation loss: 1.9768374959627788

Epoch: 6| Step: 9
Training loss: 0.31640350818634033
Validation loss: 2.0128258069356284

Epoch: 6| Step: 10
Training loss: 0.22050875425338745
Validation loss: 1.9928234616915386

Epoch: 6| Step: 11
Training loss: 0.16737808287143707
Validation loss: 1.9884189367294312

Epoch: 6| Step: 12
Training loss: 0.2799554467201233
Validation loss: 1.9743043184280396

Epoch: 6| Step: 13
Training loss: 0.11623905599117279
Validation loss: 2.0124253630638123

Epoch: 454| Step: 0
Training loss: 0.1953888237476349
Validation loss: 2.0008426507314048

Epoch: 6| Step: 1
Training loss: 0.30203577876091003
Validation loss: 2.0153364141782126

Epoch: 6| Step: 2
Training loss: 0.21490761637687683
Validation loss: 1.9888600707054138

Epoch: 6| Step: 3
Training loss: 0.21886686980724335
Validation loss: 2.0070077578226724

Epoch: 6| Step: 4
Training loss: 0.16041496396064758
Validation loss: 2.008661687374115

Epoch: 6| Step: 5
Training loss: 0.11730075627565384
Validation loss: 2.0017985105514526

Epoch: 6| Step: 6
Training loss: 0.13465094566345215
Validation loss: 1.9896577994028728

Epoch: 6| Step: 7
Training loss: 0.14680558443069458
Validation loss: 1.9896707932154338

Epoch: 6| Step: 8
Training loss: 0.5928447246551514
Validation loss: 1.993831733862559

Epoch: 6| Step: 9
Training loss: 0.24819740653038025
Validation loss: 1.9874248504638672

Epoch: 6| Step: 10
Training loss: 0.27574461698532104
Validation loss: 1.9722556074460347

Epoch: 6| Step: 11
Training loss: 0.17671728134155273
Validation loss: 1.9596185088157654

Epoch: 6| Step: 12
Training loss: 0.26045283675193787
Validation loss: 2.0227851470311484

Epoch: 6| Step: 13
Training loss: 0.20245292782783508
Validation loss: 2.0150528947512307

Epoch: 455| Step: 0
Training loss: 0.2229260355234146
Validation loss: 1.984421193599701

Epoch: 6| Step: 1
Training loss: 0.23375852406024933
Validation loss: 1.9625295797983806

Epoch: 6| Step: 2
Training loss: 0.19253215193748474
Validation loss: 1.9688105185826619

Epoch: 6| Step: 3
Training loss: 0.17717541754245758
Validation loss: 1.976820965607961

Epoch: 6| Step: 4
Training loss: 0.21880531311035156
Validation loss: 2.011935551961263

Epoch: 6| Step: 5
Training loss: 0.1562713086605072
Validation loss: 1.973450779914856

Epoch: 6| Step: 6
Training loss: 0.1876869797706604
Validation loss: 1.9472451210021973

Epoch: 6| Step: 7
Training loss: 0.164560467004776
Validation loss: 2.0171539783477783

Epoch: 6| Step: 8
Training loss: 0.130291149020195
Validation loss: 1.946480135122935

Epoch: 6| Step: 9
Training loss: 0.5436879396438599
Validation loss: 1.9752732714017232

Epoch: 6| Step: 10
Training loss: 0.1765744388103485
Validation loss: 2.0014052788416543

Epoch: 6| Step: 11
Training loss: 0.18237438797950745
Validation loss: 1.9941124320030212

Epoch: 6| Step: 12
Training loss: 0.20120196044445038
Validation loss: 1.9731854796409607

Epoch: 6| Step: 13
Training loss: 0.1188264861702919
Validation loss: 1.9780719478925068

Epoch: 456| Step: 0
Training loss: 0.1376098394393921
Validation loss: 2.0014703273773193

Epoch: 6| Step: 1
Training loss: 0.1467994749546051
Validation loss: 2.0100151896476746

Epoch: 6| Step: 2
Training loss: 0.3601588010787964
Validation loss: 1.9951915343602498

Epoch: 6| Step: 3
Training loss: 0.11604821681976318
Validation loss: 1.9974405368169148

Epoch: 6| Step: 4
Training loss: 0.16518555581569672
Validation loss: 1.9972523252169292

Epoch: 6| Step: 5
Training loss: 0.13942894339561462
Validation loss: 1.97780046860377

Epoch: 6| Step: 6
Training loss: 0.2187924087047577
Validation loss: 1.9963475863138835

Epoch: 6| Step: 7
Training loss: 0.29316163063049316
Validation loss: 1.9950352708498638

Epoch: 6| Step: 8
Training loss: 0.2700042724609375
Validation loss: 1.9765237768491108

Epoch: 6| Step: 9
Training loss: 0.2223297655582428
Validation loss: 2.0094894568125405

Epoch: 6| Step: 10
Training loss: 0.12422358989715576
Validation loss: 1.9818345109621684

Epoch: 6| Step: 11
Training loss: 0.5377693176269531
Validation loss: 1.9898466070493062

Epoch: 6| Step: 12
Training loss: 0.15345263481140137
Validation loss: 1.9671356081962585

Epoch: 6| Step: 13
Training loss: 0.17388111352920532
Validation loss: 1.98325115442276

Epoch: 457| Step: 0
Training loss: 0.1851876825094223
Validation loss: 2.0254281560579934

Epoch: 6| Step: 1
Training loss: 0.2359631359577179
Validation loss: 1.9797418316205342

Epoch: 6| Step: 2
Training loss: 0.2454097718000412
Validation loss: 1.9635149041811626

Epoch: 6| Step: 3
Training loss: 0.5309630632400513
Validation loss: 2.0169061422348022

Epoch: 6| Step: 4
Training loss: 0.23418062925338745
Validation loss: 1.968272070089976

Epoch: 6| Step: 5
Training loss: 0.16590841114521027
Validation loss: 1.9802654186884563

Epoch: 6| Step: 6
Training loss: 0.2124144583940506
Validation loss: 1.9740233023961384

Epoch: 6| Step: 7
Training loss: 0.34037625789642334
Validation loss: 1.981396734714508

Epoch: 6| Step: 8
Training loss: 0.21943622827529907
Validation loss: 1.9796342849731445

Epoch: 6| Step: 9
Training loss: 0.21036992967128754
Validation loss: 2.0263537764549255

Epoch: 6| Step: 10
Training loss: 0.16384415328502655
Validation loss: 2.01836363474528

Epoch: 6| Step: 11
Training loss: 0.18515095114707947
Validation loss: 1.9999662637710571

Epoch: 6| Step: 12
Training loss: 0.1919209063053131
Validation loss: 1.9855821927388508

Epoch: 6| Step: 13
Training loss: 0.20392419397830963
Validation loss: 1.9967369437217712

Epoch: 458| Step: 0
Training loss: 0.297211229801178
Validation loss: 1.9776721994082134

Epoch: 6| Step: 1
Training loss: 0.2123761624097824
Validation loss: 2.0201640327771506

Epoch: 6| Step: 2
Training loss: 0.20601017773151398
Validation loss: 2.012497087319692

Epoch: 6| Step: 3
Training loss: 0.23894356191158295
Validation loss: 1.9857949415842693

Epoch: 6| Step: 4
Training loss: 0.2523907423019409
Validation loss: 1.9931110938390095

Epoch: 6| Step: 5
Training loss: 0.49311789870262146
Validation loss: 2.0046873887379966

Epoch: 6| Step: 6
Training loss: 0.24452100694179535
Validation loss: 2.0206530491511026

Epoch: 6| Step: 7
Training loss: 0.25631284713745117
Validation loss: 1.9678162733713787

Epoch: 6| Step: 8
Training loss: 0.23235470056533813
Validation loss: 1.9970744649569194

Epoch: 6| Step: 9
Training loss: 0.22093573212623596
Validation loss: 2.0546741088231406

Epoch: 6| Step: 10
Training loss: 0.20894627273082733
Validation loss: 1.9840731819470723

Epoch: 6| Step: 11
Training loss: 0.15666544437408447
Validation loss: 1.969763974348704

Epoch: 6| Step: 12
Training loss: 0.20468106865882874
Validation loss: 1.9906217654546101

Epoch: 6| Step: 13
Training loss: 0.15492910146713257
Validation loss: 1.982029139995575

Epoch: 459| Step: 0
Training loss: 0.12256774306297302
Validation loss: 2.026926358540853

Epoch: 6| Step: 1
Training loss: 0.2358969748020172
Validation loss: 2.0216288765271506

Epoch: 6| Step: 2
Training loss: 0.26336032152175903
Validation loss: 1.977725088596344

Epoch: 6| Step: 3
Training loss: 0.20483183860778809
Validation loss: 1.9667200644810994

Epoch: 6| Step: 4
Training loss: 0.24928778409957886
Validation loss: 1.9495257933934529

Epoch: 6| Step: 5
Training loss: 0.5186075568199158
Validation loss: 1.9581051071484883

Epoch: 6| Step: 6
Training loss: 0.17878279089927673
Validation loss: 1.9760888020197551

Epoch: 6| Step: 7
Training loss: 0.2538175582885742
Validation loss: 1.9681853254636128

Epoch: 6| Step: 8
Training loss: 0.22469396889209747
Validation loss: 2.032919704914093

Epoch: 6| Step: 9
Training loss: 0.2613218426704407
Validation loss: 2.0042589704195657

Epoch: 6| Step: 10
Training loss: 0.21243560314178467
Validation loss: 1.9702662626902263

Epoch: 6| Step: 11
Training loss: 0.2159414142370224
Validation loss: 2.0300846695899963

Epoch: 6| Step: 12
Training loss: 0.28570395708084106
Validation loss: 2.010116179784139

Epoch: 6| Step: 13
Training loss: 0.22569352388381958
Validation loss: 2.0068742434183755

Epoch: 460| Step: 0
Training loss: 0.18823185563087463
Validation loss: 2.0376092990239463

Epoch: 6| Step: 1
Training loss: 0.20792660117149353
Validation loss: 1.9821176330248516

Epoch: 6| Step: 2
Training loss: 0.3369346857070923
Validation loss: 2.0069253047307334

Epoch: 6| Step: 3
Training loss: 0.1646491438150406
Validation loss: 1.9841272433598836

Epoch: 6| Step: 4
Training loss: 0.13897868990898132
Validation loss: 2.005134423573812

Epoch: 6| Step: 5
Training loss: 0.275743305683136
Validation loss: 2.0047181646029153

Epoch: 6| Step: 6
Training loss: 0.6748402714729309
Validation loss: 2.0073777238527932

Epoch: 6| Step: 7
Training loss: 0.25915291905403137
Validation loss: 2.0029754439989724

Epoch: 6| Step: 8
Training loss: 0.2316707968711853
Validation loss: 2.0014179348945618

Epoch: 6| Step: 9
Training loss: 0.1829833984375
Validation loss: 1.9818796714146931

Epoch: 6| Step: 10
Training loss: 0.1797505021095276
Validation loss: 1.96945321559906

Epoch: 6| Step: 11
Training loss: 0.19897441565990448
Validation loss: 1.9751101732254028

Epoch: 6| Step: 12
Training loss: 0.2585693597793579
Validation loss: 1.9870029886563618

Epoch: 6| Step: 13
Training loss: 0.24587512016296387
Validation loss: 1.9929697513580322

Epoch: 461| Step: 0
Training loss: 0.21608708798885345
Validation loss: 1.9745615720748901

Epoch: 6| Step: 1
Training loss: 0.30428990721702576
Validation loss: 1.995747943719228

Epoch: 6| Step: 2
Training loss: 0.4647769629955292
Validation loss: 2.018509864807129

Epoch: 6| Step: 3
Training loss: 0.126693993806839
Validation loss: 1.991866668065389

Epoch: 6| Step: 4
Training loss: 0.32614070177078247
Validation loss: 1.9857664306958516

Epoch: 6| Step: 5
Training loss: 0.3490231931209564
Validation loss: 1.9887559215227764

Epoch: 6| Step: 6
Training loss: 0.37908247113227844
Validation loss: 2.0016358693440757

Epoch: 6| Step: 7
Training loss: 0.17332670092582703
Validation loss: 1.9837561051050823

Epoch: 6| Step: 8
Training loss: 0.20631319284439087
Validation loss: 1.9649459918340046

Epoch: 6| Step: 9
Training loss: 0.19759541749954224
Validation loss: 1.9682636658350627

Epoch: 6| Step: 10
Training loss: 0.29286229610443115
Validation loss: 1.9823310772577922

Epoch: 6| Step: 11
Training loss: 0.27670055627822876
Validation loss: 1.9663764039675395

Epoch: 6| Step: 12
Training loss: 0.21533264219760895
Validation loss: 1.977079172929128

Epoch: 6| Step: 13
Training loss: 0.20177628099918365
Validation loss: 1.9739621082941692

Epoch: 462| Step: 0
Training loss: 0.126953125
Validation loss: 1.9764284491539001

Epoch: 6| Step: 1
Training loss: 0.21562467515468597
Validation loss: 2.016716202100118

Epoch: 6| Step: 2
Training loss: 0.15792354941368103
Validation loss: 1.9913994868596394

Epoch: 6| Step: 3
Training loss: 0.147138312458992
Validation loss: 1.9702290296554565

Epoch: 6| Step: 4
Training loss: 0.1587568074464798
Validation loss: 1.9721173246701558

Epoch: 6| Step: 5
Training loss: 0.16137395799160004
Validation loss: 1.944600800673167

Epoch: 6| Step: 6
Training loss: 0.6985852718353271
Validation loss: 1.9877383907636006

Epoch: 6| Step: 7
Training loss: 0.17645594477653503
Validation loss: 2.010808845361074

Epoch: 6| Step: 8
Training loss: 0.3886324167251587
Validation loss: 1.9831698536872864

Epoch: 6| Step: 9
Training loss: 0.231521874666214
Validation loss: 1.9734920660654705

Epoch: 6| Step: 10
Training loss: 0.1887311041355133
Validation loss: 1.9877882997194927

Epoch: 6| Step: 11
Training loss: 0.23198288679122925
Validation loss: 1.9955411354700725

Epoch: 6| Step: 12
Training loss: 0.21084219217300415
Validation loss: 2.027864237626394

Epoch: 6| Step: 13
Training loss: 0.12915365397930145
Validation loss: 1.989087740580241

Epoch: 463| Step: 0
Training loss: 0.17513126134872437
Validation loss: 1.985727310180664

Epoch: 6| Step: 1
Training loss: 0.5901477932929993
Validation loss: 1.988406280676524

Epoch: 6| Step: 2
Training loss: 0.20494362711906433
Validation loss: 1.9534923036893208

Epoch: 6| Step: 3
Training loss: 0.18476974964141846
Validation loss: 1.9622116883595784

Epoch: 6| Step: 4
Training loss: 0.14608383178710938
Validation loss: 1.9480714797973633

Epoch: 6| Step: 5
Training loss: 0.20823612809181213
Validation loss: 1.979743222395579

Epoch: 6| Step: 6
Training loss: 0.20360374450683594
Validation loss: 1.9795064727465312

Epoch: 6| Step: 7
Training loss: 0.30473265051841736
Validation loss: 1.9737928708394368

Epoch: 6| Step: 8
Training loss: 0.1336211860179901
Validation loss: 1.9437068700790405

Epoch: 6| Step: 9
Training loss: 0.3320678174495697
Validation loss: 1.9740310509999592

Epoch: 6| Step: 10
Training loss: 0.21226663887500763
Validation loss: 1.9658764600753784

Epoch: 6| Step: 11
Training loss: 0.16204223036766052
Validation loss: 1.9593805472056072

Epoch: 6| Step: 12
Training loss: 0.2295977622270584
Validation loss: 1.9643561840057373

Epoch: 6| Step: 13
Training loss: 0.17265905439853668
Validation loss: 1.95715993642807

Epoch: 464| Step: 0
Training loss: 0.1733892410993576
Validation loss: 1.9827685356140137

Epoch: 6| Step: 1
Training loss: 0.3374194800853729
Validation loss: 1.9708526929219563

Epoch: 6| Step: 2
Training loss: 0.3152179718017578
Validation loss: 1.9774977763493855

Epoch: 6| Step: 3
Training loss: 0.16566991806030273
Validation loss: 1.9642725984255474

Epoch: 6| Step: 4
Training loss: 0.14112111926078796
Validation loss: 1.9737423261006672

Epoch: 6| Step: 5
Training loss: 0.18298321962356567
Validation loss: 1.9504051407178242

Epoch: 6| Step: 6
Training loss: 0.1223624050617218
Validation loss: 1.9740233222643535

Epoch: 6| Step: 7
Training loss: 0.16796399652957916
Validation loss: 1.964860161145528

Epoch: 6| Step: 8
Training loss: 0.22895151376724243
Validation loss: 1.9768072764078777

Epoch: 6| Step: 9
Training loss: 0.24587297439575195
Validation loss: 1.978838046391805

Epoch: 6| Step: 10
Training loss: 0.17045535147190094
Validation loss: 2.00071652730306

Epoch: 6| Step: 11
Training loss: 0.20420652627944946
Validation loss: 2.0068966150283813

Epoch: 6| Step: 12
Training loss: 0.5528040528297424
Validation loss: 1.936386247475942

Epoch: 6| Step: 13
Training loss: 0.131231427192688
Validation loss: 2.0100991129875183

Epoch: 465| Step: 0
Training loss: 0.17458464205265045
Validation loss: 1.9873786171277363

Epoch: 6| Step: 1
Training loss: 0.09939394891262054
Validation loss: 1.965021789073944

Epoch: 6| Step: 2
Training loss: 0.16740655899047852
Validation loss: 1.969067911307017

Epoch: 6| Step: 3
Training loss: 0.24295388162136078
Validation loss: 1.9909070332845051

Epoch: 6| Step: 4
Training loss: 0.157864511013031
Validation loss: 2.0352627635002136

Epoch: 6| Step: 5
Training loss: 0.30865177512168884
Validation loss: 2.0247329672177634

Epoch: 6| Step: 6
Training loss: 0.2754148840904236
Validation loss: 2.001339058081309

Epoch: 6| Step: 7
Training loss: 0.5580730438232422
Validation loss: 1.978924036026001

Epoch: 6| Step: 8
Training loss: 0.21648477017879486
Validation loss: 1.9623972177505493

Epoch: 6| Step: 9
Training loss: 0.24035711586475372
Validation loss: 1.988106330235799

Epoch: 6| Step: 10
Training loss: 0.1842433214187622
Validation loss: 1.9874537984530132

Epoch: 6| Step: 11
Training loss: 0.21225064992904663
Validation loss: 2.0050309697786965

Epoch: 6| Step: 12
Training loss: 0.3046758770942688
Validation loss: 1.967506508032481

Epoch: 6| Step: 13
Training loss: 0.24305357038974762
Validation loss: 1.9813543160756428

Epoch: 466| Step: 0
Training loss: 0.1693844497203827
Validation loss: 1.971510926882426

Epoch: 6| Step: 1
Training loss: 0.29475265741348267
Validation loss: 1.9787819385528564

Epoch: 6| Step: 2
Training loss: 0.5904624462127686
Validation loss: 1.998165786266327

Epoch: 6| Step: 3
Training loss: 0.2753356099128723
Validation loss: 1.9921923677126567

Epoch: 6| Step: 4
Training loss: 0.17969344556331635
Validation loss: 1.987912615140279

Epoch: 6| Step: 5
Training loss: 0.1373002827167511
Validation loss: 1.9686419367790222

Epoch: 6| Step: 6
Training loss: 0.1496494859457016
Validation loss: 2.011818289756775

Epoch: 6| Step: 7
Training loss: 0.2141953408718109
Validation loss: 1.9764550924301147

Epoch: 6| Step: 8
Training loss: 0.35823237895965576
Validation loss: 1.9970407088597615

Epoch: 6| Step: 9
Training loss: 0.1577950417995453
Validation loss: 1.9517440398534138

Epoch: 6| Step: 10
Training loss: 0.198956698179245
Validation loss: 1.9709943532943726

Epoch: 6| Step: 11
Training loss: 0.1702224612236023
Validation loss: 1.9719433387120564

Epoch: 6| Step: 12
Training loss: 0.18082371354103088
Validation loss: 1.9672152002652485

Epoch: 6| Step: 13
Training loss: 0.18796807527542114
Validation loss: 1.981200933456421

Epoch: 467| Step: 0
Training loss: 0.16174070537090302
Validation loss: 1.9602976242701213

Epoch: 6| Step: 1
Training loss: 0.07973837852478027
Validation loss: 1.9730307658513386

Epoch: 6| Step: 2
Training loss: 0.1549684703350067
Validation loss: 1.9617716670036316

Epoch: 6| Step: 3
Training loss: 0.1248200535774231
Validation loss: 1.9458599885304768

Epoch: 6| Step: 4
Training loss: 0.19352148473262787
Validation loss: 1.9895436763763428

Epoch: 6| Step: 5
Training loss: 0.19735021889209747
Validation loss: 2.0047226349512735

Epoch: 6| Step: 6
Training loss: 0.20984816551208496
Validation loss: 1.95494145154953

Epoch: 6| Step: 7
Training loss: 0.31399667263031006
Validation loss: 1.9622083902359009

Epoch: 6| Step: 8
Training loss: 0.18480800092220306
Validation loss: 1.9713457226753235

Epoch: 6| Step: 9
Training loss: 0.4638407528400421
Validation loss: 1.9859479268391926

Epoch: 6| Step: 10
Training loss: 0.2044259011745453
Validation loss: 1.980981449286143

Epoch: 6| Step: 11
Training loss: 0.12373201549053192
Validation loss: 1.973043441772461

Epoch: 6| Step: 12
Training loss: 0.18997254967689514
Validation loss: 1.9867378274599712

Epoch: 6| Step: 13
Training loss: 0.1887722760438919
Validation loss: 1.9667588869730632

Epoch: 468| Step: 0
Training loss: 0.1415371298789978
Validation loss: 1.9591729442278545

Epoch: 6| Step: 1
Training loss: 0.1397043764591217
Validation loss: 2.0019206206003823

Epoch: 6| Step: 2
Training loss: 0.28508561849594116
Validation loss: 1.9938741723696392

Epoch: 6| Step: 3
Training loss: 0.22389182448387146
Validation loss: 1.9698477983474731

Epoch: 6| Step: 4
Training loss: 0.18087340891361237
Validation loss: 1.987304965655009

Epoch: 6| Step: 5
Training loss: 0.2222398817539215
Validation loss: 1.9716802438100178

Epoch: 6| Step: 6
Training loss: 0.20746494829654694
Validation loss: 1.963760534922282

Epoch: 6| Step: 7
Training loss: 0.13994178175926208
Validation loss: 2.013103485107422

Epoch: 6| Step: 8
Training loss: 0.2543637156486511
Validation loss: 1.9672711690266926

Epoch: 6| Step: 9
Training loss: 0.16192540526390076
Validation loss: 2.0175681710243225

Epoch: 6| Step: 10
Training loss: 0.5056298971176147
Validation loss: 1.9831088781356812

Epoch: 6| Step: 11
Training loss: 0.15179947018623352
Validation loss: 1.9684376120567322

Epoch: 6| Step: 12
Training loss: 0.148470938205719
Validation loss: 1.9743727048238118

Epoch: 6| Step: 13
Training loss: 0.20007860660552979
Validation loss: 1.9538652499516804

Epoch: 469| Step: 0
Training loss: 0.14950771629810333
Validation loss: 1.958734651406606

Epoch: 6| Step: 1
Training loss: 0.12271330505609512
Validation loss: 1.997076193491618

Epoch: 6| Step: 2
Training loss: 0.22083225846290588
Validation loss: 1.980120321114858

Epoch: 6| Step: 3
Training loss: 0.17074193060398102
Validation loss: 1.9571653604507446

Epoch: 6| Step: 4
Training loss: 0.13768942654132843
Validation loss: 1.9902992844581604

Epoch: 6| Step: 5
Training loss: 0.13552004098892212
Validation loss: 1.9738494157791138

Epoch: 6| Step: 6
Training loss: 0.14800533652305603
Validation loss: 1.9707629879315693

Epoch: 6| Step: 7
Training loss: 0.547247052192688
Validation loss: 1.9936706225077312

Epoch: 6| Step: 8
Training loss: 0.16379618644714355
Validation loss: 1.983969549338023

Epoch: 6| Step: 9
Training loss: 0.13627681136131287
Validation loss: 1.977868417898814

Epoch: 6| Step: 10
Training loss: 0.11446451395750046
Validation loss: 2.008985916773478

Epoch: 6| Step: 11
Training loss: 0.2971622943878174
Validation loss: 1.9827165802319844

Epoch: 6| Step: 12
Training loss: 0.26700127124786377
Validation loss: 1.9679147402445476

Epoch: 6| Step: 13
Training loss: 0.12894505262374878
Validation loss: 2.008808732032776

Epoch: 470| Step: 0
Training loss: 0.19113481044769287
Validation loss: 1.965065876642863

Epoch: 6| Step: 1
Training loss: 0.2784772515296936
Validation loss: 1.976107915242513

Epoch: 6| Step: 2
Training loss: 0.15817764401435852
Validation loss: 1.9602627952893574

Epoch: 6| Step: 3
Training loss: 0.18804337084293365
Validation loss: 1.9755522012710571

Epoch: 6| Step: 4
Training loss: 0.2207755148410797
Validation loss: 1.9576916893323262

Epoch: 6| Step: 5
Training loss: 0.15813888609409332
Validation loss: 1.9900929133097331

Epoch: 6| Step: 6
Training loss: 0.13679371774196625
Validation loss: 1.9563959240913391

Epoch: 6| Step: 7
Training loss: 0.5666476488113403
Validation loss: 1.9726523359616597

Epoch: 6| Step: 8
Training loss: 0.23154526948928833
Validation loss: 1.9773873289426167

Epoch: 6| Step: 9
Training loss: 0.2765890657901764
Validation loss: 1.9830714861551921

Epoch: 6| Step: 10
Training loss: 0.17999732494354248
Validation loss: 1.9549688299496968

Epoch: 6| Step: 11
Training loss: 0.15110668540000916
Validation loss: 1.9564627011617024

Epoch: 6| Step: 12
Training loss: 0.20081669092178345
Validation loss: 1.9545726974805195

Epoch: 6| Step: 13
Training loss: 0.23215538263320923
Validation loss: 1.9760889410972595

Epoch: 471| Step: 0
Training loss: 0.17475058138370514
Validation loss: 1.989362398783366

Epoch: 6| Step: 1
Training loss: 0.17628487944602966
Validation loss: 1.9528926809628804

Epoch: 6| Step: 2
Training loss: 0.18036366999149323
Validation loss: 1.988633652528127

Epoch: 6| Step: 3
Training loss: 0.27838289737701416
Validation loss: 1.9485588868459065

Epoch: 6| Step: 4
Training loss: 0.22837817668914795
Validation loss: 1.9890110095342

Epoch: 6| Step: 5
Training loss: 0.15958282351493835
Validation loss: 2.0237104098002114

Epoch: 6| Step: 6
Training loss: 0.2745693325996399
Validation loss: 1.9920110702514648

Epoch: 6| Step: 7
Training loss: 0.21262964606285095
Validation loss: 1.9920510649681091

Epoch: 6| Step: 8
Training loss: 0.1884596049785614
Validation loss: 1.9755252997080486

Epoch: 6| Step: 9
Training loss: 0.1990637481212616
Validation loss: 2.028671224912008

Epoch: 6| Step: 10
Training loss: 0.16434267163276672
Validation loss: 1.9610721866289775

Epoch: 6| Step: 11
Training loss: 0.48837313055992126
Validation loss: 1.9865319728851318

Epoch: 6| Step: 12
Training loss: 0.12584584951400757
Validation loss: 1.9713608026504517

Epoch: 6| Step: 13
Training loss: 0.19202283024787903
Validation loss: 1.9854765733083088

Epoch: 472| Step: 0
Training loss: 0.21791476011276245
Validation loss: 1.9912402828534443

Epoch: 6| Step: 1
Training loss: 0.3210333585739136
Validation loss: 1.9705257813135784

Epoch: 6| Step: 2
Training loss: 0.11615421622991562
Validation loss: 1.9732387860616047

Epoch: 6| Step: 3
Training loss: 0.18320566415786743
Validation loss: 2.006619870662689

Epoch: 6| Step: 4
Training loss: 0.1937067210674286
Validation loss: 1.9777984221776326

Epoch: 6| Step: 5
Training loss: 0.22813209891319275
Validation loss: 1.9935879111289978

Epoch: 6| Step: 6
Training loss: 0.2144496589899063
Validation loss: 2.0090736945470176

Epoch: 6| Step: 7
Training loss: 0.15653632581233978
Validation loss: 1.9669270714124043

Epoch: 6| Step: 8
Training loss: 0.5021345615386963
Validation loss: 1.986159324645996

Epoch: 6| Step: 9
Training loss: 0.22099103033542633
Validation loss: 1.9943338831265767

Epoch: 6| Step: 10
Training loss: 0.1739194691181183
Validation loss: 2.0051989952723184

Epoch: 6| Step: 11
Training loss: 0.24417150020599365
Validation loss: 1.9957459966341655

Epoch: 6| Step: 12
Training loss: 0.19700002670288086
Validation loss: 1.9813022216161091

Epoch: 6| Step: 13
Training loss: 0.13757430016994476
Validation loss: 1.9889521996180217

Epoch: 473| Step: 0
Training loss: 0.20555004477500916
Validation loss: 1.9952758153279622

Epoch: 6| Step: 1
Training loss: 0.25174087285995483
Validation loss: 1.9868826866149902

Epoch: 6| Step: 2
Training loss: 0.13769838213920593
Validation loss: 2.01545379559199

Epoch: 6| Step: 3
Training loss: 0.17664353549480438
Validation loss: 2.0129119157791138

Epoch: 6| Step: 4
Training loss: 0.14167308807373047
Validation loss: 1.9945051471392314

Epoch: 6| Step: 5
Training loss: 0.17573338747024536
Validation loss: 1.9949007431666057

Epoch: 6| Step: 6
Training loss: 0.18877342343330383
Validation loss: 2.0011204282442727

Epoch: 6| Step: 7
Training loss: 0.11128261685371399
Validation loss: 2.028762916723887

Epoch: 6| Step: 8
Training loss: 0.1261460781097412
Validation loss: 1.9837495883305867

Epoch: 6| Step: 9
Training loss: 0.1900324523448944
Validation loss: 1.9849320848782857

Epoch: 6| Step: 10
Training loss: 0.2120070904493332
Validation loss: 2.0172561009724936

Epoch: 6| Step: 11
Training loss: 0.25020042061805725
Validation loss: 2.009618580341339

Epoch: 6| Step: 12
Training loss: 0.25768399238586426
Validation loss: 2.049380362033844

Epoch: 6| Step: 13
Training loss: 0.5315489172935486
Validation loss: 2.0256656408309937

Epoch: 474| Step: 0
Training loss: 0.2392374575138092
Validation loss: 2.0190235575040183

Epoch: 6| Step: 1
Training loss: 0.20703113079071045
Validation loss: 2.0212777058283486

Epoch: 6| Step: 2
Training loss: 0.31967538595199585
Validation loss: 2.010183016459147

Epoch: 6| Step: 3
Training loss: 0.2055557370185852
Validation loss: 1.9851096868515015

Epoch: 6| Step: 4
Training loss: 0.15437908470630646
Validation loss: 1.999497612317403

Epoch: 6| Step: 5
Training loss: 0.22609616816043854
Validation loss: 2.0010369618733725

Epoch: 6| Step: 6
Training loss: 0.1576516032218933
Validation loss: 1.9712757468223572

Epoch: 6| Step: 7
Training loss: 0.11259385943412781
Validation loss: 1.9969511826833088

Epoch: 6| Step: 8
Training loss: 0.25733956694602966
Validation loss: 2.002339462439219

Epoch: 6| Step: 9
Training loss: 0.507914662361145
Validation loss: 2.007011910279592

Epoch: 6| Step: 10
Training loss: 0.28982606530189514
Validation loss: 2.003865202267965

Epoch: 6| Step: 11
Training loss: 0.14186038076877594
Validation loss: 1.9959262013435364

Epoch: 6| Step: 12
Training loss: 0.1940607875585556
Validation loss: 2.0043232639630637

Epoch: 6| Step: 13
Training loss: 0.14096884429454803
Validation loss: 2.0122092167536416

Epoch: 475| Step: 0
Training loss: 0.13591693341732025
Validation loss: 2.003620425860087

Epoch: 6| Step: 1
Training loss: 0.14266641438007355
Validation loss: 1.9943533937136333

Epoch: 6| Step: 2
Training loss: 0.21263070404529572
Validation loss: 1.9889005422592163

Epoch: 6| Step: 3
Training loss: 0.30081140995025635
Validation loss: 1.983783761660258

Epoch: 6| Step: 4
Training loss: 0.11891196668148041
Validation loss: 1.9705856442451477

Epoch: 6| Step: 5
Training loss: 0.15657661855220795
Validation loss: 1.9848620096842449

Epoch: 6| Step: 6
Training loss: 0.31878170371055603
Validation loss: 1.989716072877248

Epoch: 6| Step: 7
Training loss: 0.18960964679718018
Validation loss: 1.9557818174362183

Epoch: 6| Step: 8
Training loss: 0.5361142158508301
Validation loss: 1.986052413781484

Epoch: 6| Step: 9
Training loss: 0.18605463206768036
Validation loss: 1.9785291353861492

Epoch: 6| Step: 10
Training loss: 0.2794935703277588
Validation loss: 1.993345856666565

Epoch: 6| Step: 11
Training loss: 0.2521386742591858
Validation loss: 1.993134359518687

Epoch: 6| Step: 12
Training loss: 0.23708349466323853
Validation loss: 1.98965851465861

Epoch: 6| Step: 13
Training loss: 0.18696071207523346
Validation loss: 1.9970910747845967

Epoch: 476| Step: 0
Training loss: 0.15773576498031616
Validation loss: 2.0316812793413797

Epoch: 6| Step: 1
Training loss: 0.18845073878765106
Validation loss: 2.0106657346089682

Epoch: 6| Step: 2
Training loss: 0.5732048749923706
Validation loss: 1.9725789427757263

Epoch: 6| Step: 3
Training loss: 0.1604926586151123
Validation loss: 2.008000075817108

Epoch: 6| Step: 4
Training loss: 0.19935013353824615
Validation loss: 2.0124666690826416

Epoch: 6| Step: 5
Training loss: 0.16265147924423218
Validation loss: 1.99673988421758

Epoch: 6| Step: 6
Training loss: 0.19968628883361816
Validation loss: 2.0164734919865928

Epoch: 6| Step: 7
Training loss: 0.18038409948349
Validation loss: 1.9997201561927795

Epoch: 6| Step: 8
Training loss: 0.33068305253982544
Validation loss: 1.979757825533549

Epoch: 6| Step: 9
Training loss: 0.15274792909622192
Validation loss: 1.9712010423342388

Epoch: 6| Step: 10
Training loss: 0.1823030412197113
Validation loss: 2.0154521663983664

Epoch: 6| Step: 11
Training loss: 0.19461169838905334
Validation loss: 1.9918836951255798

Epoch: 6| Step: 12
Training loss: 0.25135040283203125
Validation loss: 1.9892240564028423

Epoch: 6| Step: 13
Training loss: 0.20209550857543945
Validation loss: 1.965391218662262

Epoch: 477| Step: 0
Training loss: 0.1696934849023819
Validation loss: 1.9897421995798747

Epoch: 6| Step: 1
Training loss: 0.1300998032093048
Validation loss: 1.9969567656517029

Epoch: 6| Step: 2
Training loss: 0.2549569010734558
Validation loss: 2.0046581824620566

Epoch: 6| Step: 3
Training loss: 0.3766774535179138
Validation loss: 2.0114983916282654

Epoch: 6| Step: 4
Training loss: 0.24141855537891388
Validation loss: 2.0240302681922913

Epoch: 6| Step: 5
Training loss: 0.23856815695762634
Validation loss: 1.9748106797536213

Epoch: 6| Step: 6
Training loss: 0.18514977395534515
Validation loss: 1.9835062821706135

Epoch: 6| Step: 7
Training loss: 0.15546256303787231
Validation loss: 1.9791677395502727

Epoch: 6| Step: 8
Training loss: 0.15847137570381165
Validation loss: 1.9653859933217366

Epoch: 6| Step: 9
Training loss: 0.5173317193984985
Validation loss: 1.9609232544898987

Epoch: 6| Step: 10
Training loss: 0.1913345605134964
Validation loss: 1.9922094543774922

Epoch: 6| Step: 11
Training loss: 0.20423436164855957
Validation loss: 1.9612523516019185

Epoch: 6| Step: 12
Training loss: 0.18209999799728394
Validation loss: 1.9890509843826294

Epoch: 6| Step: 13
Training loss: 0.20474721491336823
Validation loss: 1.9989207983016968

Epoch: 478| Step: 0
Training loss: 0.5230603218078613
Validation loss: 1.9827290177345276

Epoch: 6| Step: 1
Training loss: 0.32985198497772217
Validation loss: 1.9991533756256104

Epoch: 6| Step: 2
Training loss: 0.13125574588775635
Validation loss: 1.9891523718833923

Epoch: 6| Step: 3
Training loss: 0.2489067018032074
Validation loss: 1.9974586168924968

Epoch: 6| Step: 4
Training loss: 0.17638283967971802
Validation loss: 1.9732006192207336

Epoch: 6| Step: 5
Training loss: 0.158857524394989
Validation loss: 2.013304849465688

Epoch: 6| Step: 6
Training loss: 0.18961785733699799
Validation loss: 1.9933999975522358

Epoch: 6| Step: 7
Training loss: 0.24982723593711853
Validation loss: 1.9524299105008442

Epoch: 6| Step: 8
Training loss: 0.22882217168807983
Validation loss: 1.9849347472190857

Epoch: 6| Step: 9
Training loss: 0.3967403173446655
Validation loss: 1.979586899280548

Epoch: 6| Step: 10
Training loss: 0.18522986769676208
Validation loss: 1.9637365142504375

Epoch: 6| Step: 11
Training loss: 0.22518587112426758
Validation loss: 1.9680577715237935

Epoch: 6| Step: 12
Training loss: 0.12497223168611526
Validation loss: 1.9669860204060872

Epoch: 6| Step: 13
Training loss: 0.17793980240821838
Validation loss: 2.016550878683726

Epoch: 479| Step: 0
Training loss: 0.15965121984481812
Validation loss: 1.9931703607241313

Epoch: 6| Step: 1
Training loss: 0.22370144724845886
Validation loss: 2.0080446600914

Epoch: 6| Step: 2
Training loss: 0.10501541942358017
Validation loss: 1.9948650002479553

Epoch: 6| Step: 3
Training loss: 0.1843283474445343
Validation loss: 1.9737083911895752

Epoch: 6| Step: 4
Training loss: 0.15966802835464478
Validation loss: 1.9716237584749858

Epoch: 6| Step: 5
Training loss: 0.15774649381637573
Validation loss: 1.9467839201291401

Epoch: 6| Step: 6
Training loss: 0.18339753150939941
Validation loss: 1.9949069619178772

Epoch: 6| Step: 7
Training loss: 0.18035224080085754
Validation loss: 1.9843048850695293

Epoch: 6| Step: 8
Training loss: 0.1949881911277771
Validation loss: 1.9497080445289612

Epoch: 6| Step: 9
Training loss: 0.5334630012512207
Validation loss: 1.9716297388076782

Epoch: 6| Step: 10
Training loss: 0.20167654752731323
Validation loss: 1.9508815010388691

Epoch: 6| Step: 11
Training loss: 0.24055694043636322
Validation loss: 1.9689315954844158

Epoch: 6| Step: 12
Training loss: 0.1674092561006546
Validation loss: 1.9748796423276265

Epoch: 6| Step: 13
Training loss: 0.3540646433830261
Validation loss: 2.011986553668976

Epoch: 480| Step: 0
Training loss: 0.1963469386100769
Validation loss: 1.9891056021054585

Epoch: 6| Step: 1
Training loss: 0.23526105284690857
Validation loss: 1.9797312219937642

Epoch: 6| Step: 2
Training loss: 0.17371411621570587
Validation loss: 1.968511442343394

Epoch: 6| Step: 3
Training loss: 0.23393969237804413
Validation loss: 1.967743992805481

Epoch: 6| Step: 4
Training loss: 0.24623703956604004
Validation loss: 1.9439597129821777

Epoch: 6| Step: 5
Training loss: 0.16142599284648895
Validation loss: 1.9595867196718852

Epoch: 6| Step: 6
Training loss: 0.28351420164108276
Validation loss: 2.0073962410291037

Epoch: 6| Step: 7
Training loss: 0.1819828450679779
Validation loss: 2.012139916419983

Epoch: 6| Step: 8
Training loss: 0.24394455552101135
Validation loss: 1.9933536648750305

Epoch: 6| Step: 9
Training loss: 0.11885896325111389
Validation loss: 1.9852049549420674

Epoch: 6| Step: 10
Training loss: 0.6015047430992126
Validation loss: 1.9968091249465942

Epoch: 6| Step: 11
Training loss: 0.3387144207954407
Validation loss: 2.026031215985616

Epoch: 6| Step: 12
Training loss: 0.28488272428512573
Validation loss: 2.0399869481722512

Epoch: 6| Step: 13
Training loss: 0.27758869528770447
Validation loss: 1.9969339768091838

Epoch: 481| Step: 0
Training loss: 0.19832684099674225
Validation loss: 1.990887721379598

Epoch: 6| Step: 1
Training loss: 0.23061762750148773
Validation loss: 2.0149588584899902

Epoch: 6| Step: 2
Training loss: 0.21211911737918854
Validation loss: 1.9965685208638508

Epoch: 6| Step: 3
Training loss: 0.49306708574295044
Validation loss: 1.9929637710253398

Epoch: 6| Step: 4
Training loss: 0.28407344222068787
Validation loss: 1.993573506673177

Epoch: 6| Step: 5
Training loss: 0.2544383704662323
Validation loss: 1.9935725927352905

Epoch: 6| Step: 6
Training loss: 0.32603609561920166
Validation loss: 1.9942409594853718

Epoch: 6| Step: 7
Training loss: 0.25834059715270996
Validation loss: 1.9656656384468079

Epoch: 6| Step: 8
Training loss: 0.2092171311378479
Validation loss: 1.9963468114535015

Epoch: 6| Step: 9
Training loss: 0.3307949900627136
Validation loss: 2.0385466615358987

Epoch: 6| Step: 10
Training loss: 0.2295142114162445
Validation loss: 1.9835505684216816

Epoch: 6| Step: 11
Training loss: 0.14973393082618713
Validation loss: 2.0100335081418357

Epoch: 6| Step: 12
Training loss: 0.11111574620008469
Validation loss: 1.992876450220744

Epoch: 6| Step: 13
Training loss: 0.20487776398658752
Validation loss: 2.0141589045524597

Epoch: 482| Step: 0
Training loss: 0.2804081439971924
Validation loss: 1.982505440711975

Epoch: 6| Step: 1
Training loss: 0.17230281233787537
Validation loss: 1.9946133891741435

Epoch: 6| Step: 2
Training loss: 0.14244121313095093
Validation loss: 2.042523284753164

Epoch: 6| Step: 3
Training loss: 0.2036479413509369
Validation loss: 1.97150719165802

Epoch: 6| Step: 4
Training loss: 0.23457694053649902
Validation loss: 1.9612589875857036

Epoch: 6| Step: 5
Training loss: 0.17251750826835632
Validation loss: 1.9837482770284016

Epoch: 6| Step: 6
Training loss: 0.19249221682548523
Validation loss: 2.000093857447306

Epoch: 6| Step: 7
Training loss: 0.13923349976539612
Validation loss: 1.9836417237917583

Epoch: 6| Step: 8
Training loss: 0.15576371550559998
Validation loss: 1.965424398581187

Epoch: 6| Step: 9
Training loss: 0.5611768364906311
Validation loss: 1.9907339215278625

Epoch: 6| Step: 10
Training loss: 0.23310130834579468
Validation loss: 1.9517892400423686

Epoch: 6| Step: 11
Training loss: 0.18799439072608948
Validation loss: 1.9854187568028767

Epoch: 6| Step: 12
Training loss: 0.1850995421409607
Validation loss: 1.957790195941925

Epoch: 6| Step: 13
Training loss: 0.18303793668746948
Validation loss: 1.9651109178860982

Epoch: 483| Step: 0
Training loss: 0.17536808550357819
Validation loss: 1.9846649169921875

Epoch: 6| Step: 1
Training loss: 0.1828349083662033
Validation loss: 1.965194582939148

Epoch: 6| Step: 2
Training loss: 0.1990678310394287
Validation loss: 1.9908695618311565

Epoch: 6| Step: 3
Training loss: 0.1922520399093628
Validation loss: 1.996531089146932

Epoch: 6| Step: 4
Training loss: 0.16344045102596283
Validation loss: 1.9857763449350994

Epoch: 6| Step: 5
Training loss: 0.18479415774345398
Validation loss: 1.961117684841156

Epoch: 6| Step: 6
Training loss: 0.24233588576316833
Validation loss: 2.00972048441569

Epoch: 6| Step: 7
Training loss: 0.2519289255142212
Validation loss: 2.018070916334788

Epoch: 6| Step: 8
Training loss: 0.5542471408843994
Validation loss: 1.9681613047917683

Epoch: 6| Step: 9
Training loss: 0.1390790492296219
Validation loss: 1.995004653930664

Epoch: 6| Step: 10
Training loss: 0.1517292559146881
Validation loss: 1.97111980120341

Epoch: 6| Step: 11
Training loss: 0.30088740587234497
Validation loss: 1.9965193271636963

Epoch: 6| Step: 12
Training loss: 0.23774974048137665
Validation loss: 2.004301369190216

Epoch: 6| Step: 13
Training loss: 0.20575664937496185
Validation loss: 2.0269481539726257

Epoch: 484| Step: 0
Training loss: 0.1804841011762619
Validation loss: 1.9573622941970825

Epoch: 6| Step: 1
Training loss: 0.1632506400346756
Validation loss: 2.0198788046836853

Epoch: 6| Step: 2
Training loss: 0.26451945304870605
Validation loss: 1.9550216794013977

Epoch: 6| Step: 3
Training loss: 0.2518957853317261
Validation loss: 2.0352168877919516

Epoch: 6| Step: 4
Training loss: 0.18589884042739868
Validation loss: 2.0078882972399392

Epoch: 6| Step: 5
Training loss: 0.17361554503440857
Validation loss: 1.996447463830312

Epoch: 6| Step: 6
Training loss: 0.5502845048904419
Validation loss: 1.977628231048584

Epoch: 6| Step: 7
Training loss: 0.19787690043449402
Validation loss: 2.0018420616785684

Epoch: 6| Step: 8
Training loss: 0.2084333598613739
Validation loss: 1.98899640639623

Epoch: 6| Step: 9
Training loss: 0.17091837525367737
Validation loss: 1.9813026189804077

Epoch: 6| Step: 10
Training loss: 0.19747456908226013
Validation loss: 1.9910846948623657

Epoch: 6| Step: 11
Training loss: 0.17931625247001648
Validation loss: 2.0265894532203674

Epoch: 6| Step: 12
Training loss: 0.14372092485427856
Validation loss: 1.996306836605072

Epoch: 6| Step: 13
Training loss: 0.18189673125743866
Validation loss: 1.9944489002227783

Epoch: 485| Step: 0
Training loss: 0.5775277614593506
Validation loss: 1.9665316144625347

Epoch: 6| Step: 1
Training loss: 0.14983431994915009
Validation loss: 2.0063689152399697

Epoch: 6| Step: 2
Training loss: 0.12730011343955994
Validation loss: 2.0320827960968018

Epoch: 6| Step: 3
Training loss: 0.1942291557788849
Validation loss: 1.9848506848017375

Epoch: 6| Step: 4
Training loss: 0.16172285377979279
Validation loss: 2.0185609658559165

Epoch: 6| Step: 5
Training loss: 0.15991196036338806
Validation loss: 2.0135775009791055

Epoch: 6| Step: 6
Training loss: 0.17601576447486877
Validation loss: 2.003636658191681

Epoch: 6| Step: 7
Training loss: 0.23235675692558289
Validation loss: 1.996972958246867

Epoch: 6| Step: 8
Training loss: 0.16500335931777954
Validation loss: 2.0250337719917297

Epoch: 6| Step: 9
Training loss: 0.10975239425897598
Validation loss: 2.0156721274058023

Epoch: 6| Step: 10
Training loss: 0.1820119023323059
Validation loss: 1.9909093379974365

Epoch: 6| Step: 11
Training loss: 0.1746278703212738
Validation loss: 1.978646417458852

Epoch: 6| Step: 12
Training loss: 0.1799156665802002
Validation loss: 2.0263668100039163

Epoch: 6| Step: 13
Training loss: 0.3113117516040802
Validation loss: 1.9954949816068013

Epoch: 486| Step: 0
Training loss: 0.15105877816677094
Validation loss: 1.987610359986623

Epoch: 6| Step: 1
Training loss: 0.2287561297416687
Validation loss: 1.9811811248461406

Epoch: 6| Step: 2
Training loss: 0.1858147382736206
Validation loss: 2.003364900747935

Epoch: 6| Step: 3
Training loss: 0.5149691104888916
Validation loss: 1.971847911675771

Epoch: 6| Step: 4
Training loss: 0.182633638381958
Validation loss: 1.9989693959554036

Epoch: 6| Step: 5
Training loss: 0.22259974479675293
Validation loss: 1.9919225970904033

Epoch: 6| Step: 6
Training loss: 0.3744627833366394
Validation loss: 2.0139388839403787

Epoch: 6| Step: 7
Training loss: 0.17460840940475464
Validation loss: 1.9873225291570027

Epoch: 6| Step: 8
Training loss: 0.144021138548851
Validation loss: 1.9913344581921895

Epoch: 6| Step: 9
Training loss: 0.1559363156557083
Validation loss: 1.981666624546051

Epoch: 6| Step: 10
Training loss: 0.23380085825920105
Validation loss: 2.000654677549998

Epoch: 6| Step: 11
Training loss: 0.1813584864139557
Validation loss: 2.000046968460083

Epoch: 6| Step: 12
Training loss: 0.12706461548805237
Validation loss: 1.9940929611523945

Epoch: 6| Step: 13
Training loss: 0.17023462057113647
Validation loss: 2.0187405347824097

Epoch: 487| Step: 0
Training loss: 0.17288729548454285
Validation loss: 1.9748949805895488

Epoch: 6| Step: 1
Training loss: 0.15549792349338531
Validation loss: 2.015429377555847

Epoch: 6| Step: 2
Training loss: 0.12975037097930908
Validation loss: 1.9936806162198384

Epoch: 6| Step: 3
Training loss: 0.17337530851364136
Validation loss: 1.9895906647046406

Epoch: 6| Step: 4
Training loss: 0.15073904395103455
Validation loss: 2.006122052669525

Epoch: 6| Step: 5
Training loss: 0.19825784862041473
Validation loss: 1.9535374442736309

Epoch: 6| Step: 6
Training loss: 0.12388961017131805
Validation loss: 1.9614543517430623

Epoch: 6| Step: 7
Training loss: 0.24518150091171265
Validation loss: 2.0163751443227134

Epoch: 6| Step: 8
Training loss: 0.16105230152606964
Validation loss: 2.017937878767649

Epoch: 6| Step: 9
Training loss: 0.5470724105834961
Validation loss: 1.9882906079292297

Epoch: 6| Step: 10
Training loss: 0.10383391380310059
Validation loss: 1.9677609999974568

Epoch: 6| Step: 11
Training loss: 0.2200630009174347
Validation loss: 1.9926395217577617

Epoch: 6| Step: 12
Training loss: 0.15598265826702118
Validation loss: 1.982054054737091

Epoch: 6| Step: 13
Training loss: 0.3028715252876282
Validation loss: 1.958701252937317

Epoch: 488| Step: 0
Training loss: 0.16761386394500732
Validation loss: 1.9921911557515461

Epoch: 6| Step: 1
Training loss: 0.5793308615684509
Validation loss: 1.9631362756093342

Epoch: 6| Step: 2
Training loss: 0.17707301676273346
Validation loss: 1.9963258306185405

Epoch: 6| Step: 3
Training loss: 0.16990360617637634
Validation loss: 1.9794403910636902

Epoch: 6| Step: 4
Training loss: 0.22526568174362183
Validation loss: 1.9840888977050781

Epoch: 6| Step: 5
Training loss: 0.1060173287987709
Validation loss: 1.9749640623728435

Epoch: 6| Step: 6
Training loss: 0.1511206328868866
Validation loss: 1.9500426451365154

Epoch: 6| Step: 7
Training loss: 0.19630464911460876
Validation loss: 1.9863810936609905

Epoch: 6| Step: 8
Training loss: 0.17455250024795532
Validation loss: 1.999731461207072

Epoch: 6| Step: 9
Training loss: 0.1623188555240631
Validation loss: 1.9806316296259563

Epoch: 6| Step: 10
Training loss: 0.1308300495147705
Validation loss: 1.9920470317204793

Epoch: 6| Step: 11
Training loss: 0.25519174337387085
Validation loss: 1.9891495108604431

Epoch: 6| Step: 12
Training loss: 0.21841707825660706
Validation loss: 1.980607310930888

Epoch: 6| Step: 13
Training loss: 0.13354912400245667
Validation loss: 1.9773473540941875

Epoch: 489| Step: 0
Training loss: 0.21924728155136108
Validation loss: 1.9767247041066487

Epoch: 6| Step: 1
Training loss: 0.22898048162460327
Validation loss: 1.9931964476903279

Epoch: 6| Step: 2
Training loss: 0.3162275552749634
Validation loss: 2.0012786587079368

Epoch: 6| Step: 3
Training loss: 0.1446911245584488
Validation loss: 1.947593371073405

Epoch: 6| Step: 4
Training loss: 0.21690742671489716
Validation loss: 1.943331281344096

Epoch: 6| Step: 5
Training loss: 0.19687587022781372
Validation loss: 1.9775099555651348

Epoch: 6| Step: 6
Training loss: 0.5109697580337524
Validation loss: 2.0173650781313577

Epoch: 6| Step: 7
Training loss: 0.28679996728897095
Validation loss: 1.9631090362866719

Epoch: 6| Step: 8
Training loss: 0.2177911251783371
Validation loss: 1.989280144373576

Epoch: 6| Step: 9
Training loss: 0.17420904338359833
Validation loss: 1.97020822763443

Epoch: 6| Step: 10
Training loss: 0.16965800523757935
Validation loss: 2.0045694510142007

Epoch: 6| Step: 11
Training loss: 0.1351211667060852
Validation loss: 1.990743100643158

Epoch: 6| Step: 12
Training loss: 0.151068776845932
Validation loss: 1.9831560254096985

Epoch: 6| Step: 13
Training loss: 0.20346865057945251
Validation loss: 1.976812223593394

Epoch: 490| Step: 0
Training loss: 0.21620792150497437
Validation loss: 1.9976146419843037

Epoch: 6| Step: 1
Training loss: 0.2723480463027954
Validation loss: 1.9663647611935933

Epoch: 6| Step: 2
Training loss: 0.24792513251304626
Validation loss: 1.9812456369400024

Epoch: 6| Step: 3
Training loss: 0.2209809422492981
Validation loss: 2.0256024996439614

Epoch: 6| Step: 4
Training loss: 0.17034879326820374
Validation loss: 1.9765842358271282

Epoch: 6| Step: 5
Training loss: 0.14256858825683594
Validation loss: 1.9694275458653767

Epoch: 6| Step: 6
Training loss: 0.1903294324874878
Validation loss: 1.9909457365671794

Epoch: 6| Step: 7
Training loss: 0.2569127082824707
Validation loss: 1.978303054968516

Epoch: 6| Step: 8
Training loss: 0.19528210163116455
Validation loss: 1.9880759318669636

Epoch: 6| Step: 9
Training loss: 0.17696398496627808
Validation loss: 1.9980543653170268

Epoch: 6| Step: 10
Training loss: 0.5530410408973694
Validation loss: 1.9719538887341816

Epoch: 6| Step: 11
Training loss: 0.20481696724891663
Validation loss: 1.9676371812820435

Epoch: 6| Step: 12
Training loss: 0.16154837608337402
Validation loss: 1.9609672625859578

Epoch: 6| Step: 13
Training loss: 0.09533292800188065
Validation loss: 1.9974454243977864

Epoch: 491| Step: 0
Training loss: 0.16289031505584717
Validation loss: 1.9742904305458069

Epoch: 6| Step: 1
Training loss: 0.307110071182251
Validation loss: 1.9642082452774048

Epoch: 6| Step: 2
Training loss: 0.283017098903656
Validation loss: 1.989676793416341

Epoch: 6| Step: 3
Training loss: 0.14094647765159607
Validation loss: 1.9755627910296123

Epoch: 6| Step: 4
Training loss: 0.13518711924552917
Validation loss: 1.9943607052167256

Epoch: 6| Step: 5
Training loss: 0.21430939435958862
Validation loss: 2.017285625139872

Epoch: 6| Step: 6
Training loss: 0.2143106460571289
Validation loss: 1.9848055442174275

Epoch: 6| Step: 7
Training loss: 0.19098427891731262
Validation loss: 1.9603687922159831

Epoch: 6| Step: 8
Training loss: 0.16120874881744385
Validation loss: 2.0267913738886514

Epoch: 6| Step: 9
Training loss: 0.5378899574279785
Validation loss: 2.0023725430170694

Epoch: 6| Step: 10
Training loss: 0.20964393019676208
Validation loss: 1.970097839832306

Epoch: 6| Step: 11
Training loss: 0.16296663880348206
Validation loss: 1.997617483139038

Epoch: 6| Step: 12
Training loss: 0.17311468720436096
Validation loss: 1.9691526691118877

Epoch: 6| Step: 13
Training loss: 0.2013058066368103
Validation loss: 1.962290108203888

Epoch: 492| Step: 0
Training loss: 0.1644725501537323
Validation loss: 1.9607605338096619

Epoch: 6| Step: 1
Training loss: 0.2656877636909485
Validation loss: 1.9450921217600505

Epoch: 6| Step: 2
Training loss: 0.18122169375419617
Validation loss: 1.9661397337913513

Epoch: 6| Step: 3
Training loss: 0.18477730453014374
Validation loss: 1.9840097427368164

Epoch: 6| Step: 4
Training loss: 0.23488816618919373
Validation loss: 1.9845445950826008

Epoch: 6| Step: 5
Training loss: 0.12373609095811844
Validation loss: 1.9657058715820312

Epoch: 6| Step: 6
Training loss: 0.1319379210472107
Validation loss: 1.9865519603093464

Epoch: 6| Step: 7
Training loss: 0.49822646379470825
Validation loss: 2.0062668124834695

Epoch: 6| Step: 8
Training loss: 0.1030716747045517
Validation loss: 1.9858173529307048

Epoch: 6| Step: 9
Training loss: 0.18135350942611694
Validation loss: 2.011879563331604

Epoch: 6| Step: 10
Training loss: 0.15039458870887756
Validation loss: 1.9775791962941487

Epoch: 6| Step: 11
Training loss: 0.1733776330947876
Validation loss: 1.963266412417094

Epoch: 6| Step: 12
Training loss: 0.24114194512367249
Validation loss: 1.9999306003252666

Epoch: 6| Step: 13
Training loss: 0.2608638107776642
Validation loss: 1.9856917063395183

Epoch: 493| Step: 0
Training loss: 0.1557365357875824
Validation loss: 1.9892058372497559

Epoch: 6| Step: 1
Training loss: 0.6426566243171692
Validation loss: 1.9664595127105713

Epoch: 6| Step: 2
Training loss: 0.2550033926963806
Validation loss: 1.9966682593027751

Epoch: 6| Step: 3
Training loss: 0.17250195145606995
Validation loss: 2.0054873625437417

Epoch: 6| Step: 4
Training loss: 0.18118137121200562
Validation loss: 1.9822137951850891

Epoch: 6| Step: 5
Training loss: 0.11286162585020065
Validation loss: 1.9866134126981099

Epoch: 6| Step: 6
Training loss: 0.2127688229084015
Validation loss: 1.9821072022120159

Epoch: 6| Step: 7
Training loss: 0.17370182275772095
Validation loss: 1.98406587044398

Epoch: 6| Step: 8
Training loss: 0.20728716254234314
Validation loss: 1.9881966511408489

Epoch: 6| Step: 9
Training loss: 0.15683196485042572
Validation loss: 2.002214193344116

Epoch: 6| Step: 10
Training loss: 0.1918163150548935
Validation loss: 2.0127469897270203

Epoch: 6| Step: 11
Training loss: 0.21183614432811737
Validation loss: 2.003047287464142

Epoch: 6| Step: 12
Training loss: 0.18376997113227844
Validation loss: 2.0144441723823547

Epoch: 6| Step: 13
Training loss: 0.14228513836860657
Validation loss: 1.990855058034261

Epoch: 494| Step: 0
Training loss: 0.22207169234752655
Validation loss: 2.006568173567454

Epoch: 6| Step: 1
Training loss: 0.15544354915618896
Validation loss: 2.0330856442451477

Epoch: 6| Step: 2
Training loss: 0.1981481909751892
Validation loss: 1.9912203947703044

Epoch: 6| Step: 3
Training loss: 0.5266835689544678
Validation loss: 2.009666403134664

Epoch: 6| Step: 4
Training loss: 0.2167619913816452
Validation loss: 1.9821394483248393

Epoch: 6| Step: 5
Training loss: 0.17042745649814606
Validation loss: 2.0075575709342957

Epoch: 6| Step: 6
Training loss: 0.31757980585098267
Validation loss: 1.9637117981910706

Epoch: 6| Step: 7
Training loss: 0.21989798545837402
Validation loss: 1.998669723669688

Epoch: 6| Step: 8
Training loss: 0.15075808763504028
Validation loss: 2.001805086930593

Epoch: 6| Step: 9
Training loss: 0.14682237803936005
Validation loss: 2.013672351837158

Epoch: 6| Step: 10
Training loss: 0.1622350811958313
Validation loss: 2.0234029491742453

Epoch: 6| Step: 11
Training loss: 0.19197025895118713
Validation loss: 1.99420032898585

Epoch: 6| Step: 12
Training loss: 0.17242580652236938
Validation loss: 2.0071495175361633

Epoch: 6| Step: 13
Training loss: 0.14502324163913727
Validation loss: 1.9930286606152852

Epoch: 495| Step: 0
Training loss: 0.2512078881263733
Validation loss: 1.9888400038083394

Epoch: 6| Step: 1
Training loss: 0.1346951127052307
Validation loss: 1.9834895730018616

Epoch: 6| Step: 2
Training loss: 0.17474189400672913
Validation loss: 1.9666586518287659

Epoch: 6| Step: 3
Training loss: 0.15472346544265747
Validation loss: 1.982752005259196

Epoch: 6| Step: 4
Training loss: 0.17365768551826477
Validation loss: 1.980562428633372

Epoch: 6| Step: 5
Training loss: 0.17281927168369293
Validation loss: 1.9978177746136982

Epoch: 6| Step: 6
Training loss: 0.19017933309078217
Validation loss: 1.9859082102775574

Epoch: 6| Step: 7
Training loss: 0.18015898764133453
Validation loss: 2.0122568209966025

Epoch: 6| Step: 8
Training loss: 0.1912626475095749
Validation loss: 2.026994526386261

Epoch: 6| Step: 9
Training loss: 0.26759806275367737
Validation loss: 1.997900903224945

Epoch: 6| Step: 10
Training loss: 0.2519366145133972
Validation loss: 1.9972782929738362

Epoch: 6| Step: 11
Training loss: 0.2540966272354126
Validation loss: 1.9860129753748577

Epoch: 6| Step: 12
Training loss: 0.5702733397483826
Validation loss: 2.010782798131307

Epoch: 6| Step: 13
Training loss: 0.15810462832450867
Validation loss: 1.9783356587092082

Epoch: 496| Step: 0
Training loss: 0.14620614051818848
Validation loss: 1.995936910311381

Epoch: 6| Step: 1
Training loss: 0.12012264132499695
Validation loss: 1.946659783522288

Epoch: 6| Step: 2
Training loss: 0.17058685421943665
Validation loss: 1.9657188852628071

Epoch: 6| Step: 3
Training loss: 0.15878954529762268
Validation loss: 2.012212951978048

Epoch: 6| Step: 4
Training loss: 0.19073981046676636
Validation loss: 1.9986843665440877

Epoch: 6| Step: 5
Training loss: 0.14127884805202484
Validation loss: 2.0101242462793985

Epoch: 6| Step: 6
Training loss: 0.29883819818496704
Validation loss: 2.007604936758677

Epoch: 6| Step: 7
Training loss: 0.14525102078914642
Validation loss: 2.00599871079127

Epoch: 6| Step: 8
Training loss: 0.4955677390098572
Validation loss: 1.9845947821935017

Epoch: 6| Step: 9
Training loss: 0.20011946558952332
Validation loss: 2.010245442390442

Epoch: 6| Step: 10
Training loss: 0.22889184951782227
Validation loss: 2.0049715638160706

Epoch: 6| Step: 11
Training loss: 0.3054705858230591
Validation loss: 1.9930725693702698

Epoch: 6| Step: 12
Training loss: 0.23248830437660217
Validation loss: 1.9938919345537822

Epoch: 6| Step: 13
Training loss: 0.25274670124053955
Validation loss: 1.991122563680013

Epoch: 497| Step: 0
Training loss: 0.1426195204257965
Validation loss: 2.02229634920756

Epoch: 6| Step: 1
Training loss: 0.21281951665878296
Validation loss: 1.9808323582013447

Epoch: 6| Step: 2
Training loss: 0.33725211024284363
Validation loss: 2.0021942853927612

Epoch: 6| Step: 3
Training loss: 0.3745812177658081
Validation loss: 1.9898935953776042

Epoch: 6| Step: 4
Training loss: 0.2980632185935974
Validation loss: 1.9981783827145894

Epoch: 6| Step: 5
Training loss: 0.7009034156799316
Validation loss: 2.018751402695974

Epoch: 6| Step: 6
Training loss: 0.16039913892745972
Validation loss: 2.016760249932607

Epoch: 6| Step: 7
Training loss: 0.22145432233810425
Validation loss: 2.0011289914449057

Epoch: 6| Step: 8
Training loss: 0.30106034874916077
Validation loss: 1.9971177379290264

Epoch: 6| Step: 9
Training loss: 0.3092058300971985
Validation loss: 1.980009098847707

Epoch: 6| Step: 10
Training loss: 0.23041430115699768
Validation loss: 1.9961393276850383

Epoch: 6| Step: 11
Training loss: 0.20015960931777954
Validation loss: 2.004280686378479

Epoch: 6| Step: 12
Training loss: 0.1819385290145874
Validation loss: 2.023408889770508

Epoch: 6| Step: 13
Training loss: 0.1500084400177002
Validation loss: 2.030087927977244

Epoch: 498| Step: 0
Training loss: 0.29853177070617676
Validation loss: 1.9924647808074951

Epoch: 6| Step: 1
Training loss: 0.15516413748264313
Validation loss: 1.9864378174146016

Epoch: 6| Step: 2
Training loss: 0.1854691356420517
Validation loss: 2.0132213632265725

Epoch: 6| Step: 3
Training loss: 0.14176028966903687
Validation loss: 1.9806103507677715

Epoch: 6| Step: 4
Training loss: 0.15803810954093933
Validation loss: 2.0079715847969055

Epoch: 6| Step: 5
Training loss: 0.20364178717136383
Validation loss: 1.9761807521184285

Epoch: 6| Step: 6
Training loss: 0.19040045142173767
Validation loss: 1.9654585123062134

Epoch: 6| Step: 7
Training loss: 0.5344657301902771
Validation loss: 2.022386074066162

Epoch: 6| Step: 8
Training loss: 0.1351962834596634
Validation loss: 1.9815794428189595

Epoch: 6| Step: 9
Training loss: 0.1919628530740738
Validation loss: 1.996983011563619

Epoch: 6| Step: 10
Training loss: 0.23239505290985107
Validation loss: 1.96857355038325

Epoch: 6| Step: 11
Training loss: 0.2100638449192047
Validation loss: 1.9795290033022563

Epoch: 6| Step: 12
Training loss: 0.2275231033563614
Validation loss: 1.9938054084777832

Epoch: 6| Step: 13
Training loss: 0.18241965770721436
Validation loss: 2.0220076640446982

Epoch: 499| Step: 0
Training loss: 0.2127673327922821
Validation loss: 2.0225025614102683

Epoch: 6| Step: 1
Training loss: 0.17836666107177734
Validation loss: 1.9875150124231975

Epoch: 6| Step: 2
Training loss: 0.18394212424755096
Validation loss: 1.9887564579645793

Epoch: 6| Step: 3
Training loss: 0.2795359492301941
Validation loss: 1.9783275723457336

Epoch: 6| Step: 4
Training loss: 0.1714143455028534
Validation loss: 1.993565599123637

Epoch: 6| Step: 5
Training loss: 0.2503628134727478
Validation loss: 2.0178439219792685

Epoch: 6| Step: 6
Training loss: 0.33148065209388733
Validation loss: 1.961475094159444

Epoch: 6| Step: 7
Training loss: 0.2386268675327301
Validation loss: 1.9599201083183289

Epoch: 6| Step: 8
Training loss: 0.1565401256084442
Validation loss: 1.9935976266860962

Epoch: 6| Step: 9
Training loss: 0.16822344064712524
Validation loss: 1.9567049543062847

Epoch: 6| Step: 10
Training loss: 0.17727985978126526
Validation loss: 1.997630774974823

Epoch: 6| Step: 11
Training loss: 0.4650545120239258
Validation loss: 1.9847335815429688

Epoch: 6| Step: 12
Training loss: 0.15404655039310455
Validation loss: 1.9933377305666606

Epoch: 6| Step: 13
Training loss: 0.22811725735664368
Validation loss: 1.9811055262883503

Epoch: 500| Step: 0
Training loss: 0.17415910959243774
Validation loss: 1.966759165128072

Epoch: 6| Step: 1
Training loss: 0.1651798039674759
Validation loss: 1.9908002813657124

Epoch: 6| Step: 2
Training loss: 0.21831956505775452
Validation loss: 1.9882094860076904

Epoch: 6| Step: 3
Training loss: 0.20502537488937378
Validation loss: 1.9554463426272075

Epoch: 6| Step: 4
Training loss: 0.13610951602458954
Validation loss: 2.0191994508107505

Epoch: 6| Step: 5
Training loss: 0.16781796514987946
Validation loss: 1.9866536060969036

Epoch: 6| Step: 6
Training loss: 0.24251438677310944
Validation loss: 1.9781655470530193

Epoch: 6| Step: 7
Training loss: 0.13351136445999146
Validation loss: 2.001365900039673

Epoch: 6| Step: 8
Training loss: 0.12742462754249573
Validation loss: 1.9854175845781963

Epoch: 6| Step: 9
Training loss: 0.17326658964157104
Validation loss: 2.0126978754997253

Epoch: 6| Step: 10
Training loss: 0.22314438223838806
Validation loss: 1.9818421006202698

Epoch: 6| Step: 11
Training loss: 0.5669097900390625
Validation loss: 1.9917886853218079

Epoch: 6| Step: 12
Training loss: 0.2504442036151886
Validation loss: 2.0127346913019815

Epoch: 6| Step: 13
Training loss: 0.3284497857093811
Validation loss: 2.0192258755366006

Testing loss: 1.9252333023565278
