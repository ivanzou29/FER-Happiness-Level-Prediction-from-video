Epoch: 1| Step: 0
Training loss: 5.7834062576293945
Validation loss: 5.387058973312378

Epoch: 6| Step: 1
Training loss: 4.958207607269287
Validation loss: 5.3554738362630205

Epoch: 6| Step: 2
Training loss: 5.857359886169434
Validation loss: 5.320658604303996

Epoch: 6| Step: 3
Training loss: 5.988889694213867
Validation loss: 5.288873672485352

Epoch: 6| Step: 4
Training loss: 4.90998649597168
Validation loss: 5.261549949645996

Epoch: 6| Step: 5
Training loss: 6.02987813949585
Validation loss: 5.231101592381795

Epoch: 6| Step: 6
Training loss: 5.608447551727295
Validation loss: 5.198856512705485

Epoch: 6| Step: 7
Training loss: 5.205144882202148
Validation loss: 5.168880383173625

Epoch: 6| Step: 8
Training loss: 4.310518741607666
Validation loss: 5.139217853546143

Epoch: 6| Step: 9
Training loss: 5.850628852844238
Validation loss: 5.106830358505249

Epoch: 6| Step: 10
Training loss: 5.2764387130737305
Validation loss: 5.080383539199829

Epoch: 6| Step: 11
Training loss: 5.007936000823975
Validation loss: 5.0475484530131025

Epoch: 6| Step: 12
Training loss: 5.491098880767822
Validation loss: 5.015678485234578

Epoch: 6| Step: 13
Training loss: 3.3275718688964844
Validation loss: 4.9842744668324785

Epoch: 2| Step: 0
Training loss: 3.784371852874756
Validation loss: 4.951741139094035

Epoch: 6| Step: 1
Training loss: 4.165524005889893
Validation loss: 4.920663118362427

Epoch: 6| Step: 2
Training loss: 5.469125747680664
Validation loss: 4.885426759719849

Epoch: 6| Step: 3
Training loss: 4.433170795440674
Validation loss: 4.850374142328898

Epoch: 6| Step: 4
Training loss: 4.345824718475342
Validation loss: 4.8132344881693525

Epoch: 6| Step: 5
Training loss: 4.252756595611572
Validation loss: 4.775960127512614

Epoch: 6| Step: 6
Training loss: 4.935916900634766
Validation loss: 4.737916707992554

Epoch: 6| Step: 7
Training loss: 6.140285491943359
Validation loss: 4.699227650960286

Epoch: 6| Step: 8
Training loss: 5.544335842132568
Validation loss: 4.652908603350322

Epoch: 6| Step: 9
Training loss: 4.827118396759033
Validation loss: 4.6098255316416425

Epoch: 6| Step: 10
Training loss: 5.188906669616699
Validation loss: 4.565736095110576

Epoch: 6| Step: 11
Training loss: 4.607405662536621
Validation loss: 4.515992085138957

Epoch: 6| Step: 12
Training loss: 4.143033981323242
Validation loss: 4.4593691031138105

Epoch: 6| Step: 13
Training loss: 4.981725692749023
Validation loss: 4.405616839726766

Epoch: 3| Step: 0
Training loss: 4.352431297302246
Validation loss: 4.355797449747722

Epoch: 6| Step: 1
Training loss: 4.778535842895508
Validation loss: 4.288654963175456

Epoch: 6| Step: 2
Training loss: 4.04030704498291
Validation loss: 4.228375792503357

Epoch: 6| Step: 3
Training loss: 4.256289958953857
Validation loss: 4.165585160255432

Epoch: 6| Step: 4
Training loss: 4.603326797485352
Validation loss: 4.097447594006856

Epoch: 6| Step: 5
Training loss: 4.152478218078613
Validation loss: 4.0319691101710005

Epoch: 6| Step: 6
Training loss: 4.604790687561035
Validation loss: 3.9704421758651733

Epoch: 6| Step: 7
Training loss: 3.8057823181152344
Validation loss: 3.8974475065867105

Epoch: 6| Step: 8
Training loss: 4.497725009918213
Validation loss: 3.822657068570455

Epoch: 6| Step: 9
Training loss: 3.521909475326538
Validation loss: 3.7517876625061035

Epoch: 6| Step: 10
Training loss: 3.176572322845459
Validation loss: 3.678151766459147

Epoch: 6| Step: 11
Training loss: 3.5902328491210938
Validation loss: 3.5994816223780313

Epoch: 6| Step: 12
Training loss: 3.8495547771453857
Validation loss: 3.5205277601877847

Epoch: 6| Step: 13
Training loss: 3.1820905208587646
Validation loss: 3.445485234260559

Epoch: 4| Step: 0
Training loss: 3.4429521560668945
Validation loss: 3.3626001278559365

Epoch: 6| Step: 1
Training loss: 2.9100472927093506
Validation loss: 3.2808074951171875

Epoch: 6| Step: 2
Training loss: 3.094527244567871
Validation loss: 3.191020409266154

Epoch: 6| Step: 3
Training loss: 3.5850863456726074
Validation loss: 3.1092966000239053

Epoch: 6| Step: 4
Training loss: 2.8566131591796875
Validation loss: 3.0356609423955283

Epoch: 6| Step: 5
Training loss: 3.301936626434326
Validation loss: 2.938325881958008

Epoch: 6| Step: 6
Training loss: 3.4609413146972656
Validation loss: 2.8537203470865884

Epoch: 6| Step: 7
Training loss: 3.0221312046051025
Validation loss: 2.750628630320231

Epoch: 6| Step: 8
Training loss: 2.880308151245117
Validation loss: 2.673018534978231

Epoch: 6| Step: 9
Training loss: 1.8153059482574463
Validation loss: 2.5676307479540506

Epoch: 6| Step: 10
Training loss: 2.4293947219848633
Validation loss: 2.48306538661321

Epoch: 6| Step: 11
Training loss: 2.010868787765503
Validation loss: 2.4032488266626992

Epoch: 6| Step: 12
Training loss: 2.603543758392334
Validation loss: 2.3306864500045776

Epoch: 6| Step: 13
Training loss: 2.794908046722412
Validation loss: 2.2772284746170044

Epoch: 5| Step: 0
Training loss: 3.0197010040283203
Validation loss: 2.216907024383545

Epoch: 6| Step: 1
Training loss: 1.7559996843338013
Validation loss: 2.171713729699453

Epoch: 6| Step: 2
Training loss: 2.2748866081237793
Validation loss: 2.1417317390441895

Epoch: 6| Step: 3
Training loss: 2.0761964321136475
Validation loss: 2.1287601590156555

Epoch: 6| Step: 4
Training loss: 2.099771738052368
Validation loss: 2.1223385334014893

Epoch: 6| Step: 5
Training loss: 1.9883885383605957
Validation loss: 2.1169080336888633

Epoch: 6| Step: 6
Training loss: 1.650985836982727
Validation loss: 2.1039514740308127

Epoch: 6| Step: 7
Training loss: 2.070523262023926
Validation loss: 2.1033064126968384

Epoch: 6| Step: 8
Training loss: 2.599003553390503
Validation loss: 2.1250252723693848

Epoch: 6| Step: 9
Training loss: 2.0990712642669678
Validation loss: 2.1099525888760886

Epoch: 6| Step: 10
Training loss: 1.765812873840332
Validation loss: 2.1082421143849692

Epoch: 6| Step: 11
Training loss: 2.7185163497924805
Validation loss: 2.131448268890381

Epoch: 6| Step: 12
Training loss: 2.3226184844970703
Validation loss: 2.126655320326487

Epoch: 6| Step: 13
Training loss: 2.179091453552246
Validation loss: 2.1015917857488

Epoch: 6| Step: 0
Training loss: 2.8143630027770996
Validation loss: 2.1247603793938956

Epoch: 6| Step: 1
Training loss: 2.8376641273498535
Validation loss: 2.1179194847742715

Epoch: 6| Step: 2
Training loss: 2.1250059604644775
Validation loss: 2.077909231185913

Epoch: 6| Step: 3
Training loss: 1.6880640983581543
Validation loss: 2.0832883715629578

Epoch: 6| Step: 4
Training loss: 1.7947372198104858
Validation loss: 2.091354727745056

Epoch: 6| Step: 5
Training loss: 1.7219066619873047
Validation loss: 2.0977933009465537

Epoch: 6| Step: 6
Training loss: 2.2980265617370605
Validation loss: 2.080873986085256

Epoch: 6| Step: 7
Training loss: 1.8918142318725586
Validation loss: 2.1017327904701233

Epoch: 6| Step: 8
Training loss: 2.1186065673828125
Validation loss: 2.1081157326698303

Epoch: 6| Step: 9
Training loss: 1.8421204090118408
Validation loss: 2.1139960090319314

Epoch: 6| Step: 10
Training loss: 2.5348734855651855
Validation loss: 2.1235267519950867

Epoch: 6| Step: 11
Training loss: 2.537836790084839
Validation loss: 2.1216898759206138

Epoch: 6| Step: 12
Training loss: 1.735915184020996
Validation loss: 2.111271838347117

Epoch: 6| Step: 13
Training loss: 2.3259687423706055
Validation loss: 2.116820732752482

Epoch: 7| Step: 0
Training loss: 2.2796125411987305
Validation loss: 2.1006380120913186

Epoch: 6| Step: 1
Training loss: 2.6037654876708984
Validation loss: 2.1097951531410217

Epoch: 6| Step: 2
Training loss: 2.0938315391540527
Validation loss: 2.1206897695859275

Epoch: 6| Step: 3
Training loss: 1.2515387535095215
Validation loss: 2.0932923754056296

Epoch: 6| Step: 4
Training loss: 1.5684442520141602
Validation loss: 2.109013557434082

Epoch: 6| Step: 5
Training loss: 2.644228935241699
Validation loss: 2.087670306364695

Epoch: 6| Step: 6
Training loss: 2.206902265548706
Validation loss: 2.0711536208788552

Epoch: 6| Step: 7
Training loss: 2.684215545654297
Validation loss: 2.0955095887184143

Epoch: 6| Step: 8
Training loss: 1.9065032005310059
Validation loss: 2.0675008296966553

Epoch: 6| Step: 9
Training loss: 1.7920842170715332
Validation loss: 2.0640612045923867

Epoch: 6| Step: 10
Training loss: 2.598937511444092
Validation loss: 2.0889907081921897

Epoch: 6| Step: 11
Training loss: 2.07607364654541
Validation loss: 2.083363870779673

Epoch: 6| Step: 12
Training loss: 1.9073822498321533
Validation loss: 2.0743608872095742

Epoch: 6| Step: 13
Training loss: 1.8685786724090576
Validation loss: 2.0788917740186057

Epoch: 8| Step: 0
Training loss: 2.1386733055114746
Validation loss: 2.087724963823954

Epoch: 6| Step: 1
Training loss: 2.424058437347412
Validation loss: 2.095291574796041

Epoch: 6| Step: 2
Training loss: 1.8300352096557617
Validation loss: 2.065943419933319

Epoch: 6| Step: 3
Training loss: 1.6445481777191162
Validation loss: 2.0753972927729287

Epoch: 6| Step: 4
Training loss: 2.4575750827789307
Validation loss: 2.0766441027323403

Epoch: 6| Step: 5
Training loss: 2.0697498321533203
Validation loss: 2.0968194206555686

Epoch: 6| Step: 6
Training loss: 2.2852070331573486
Validation loss: 2.0662721594174704

Epoch: 6| Step: 7
Training loss: 2.2206711769104004
Validation loss: 2.0849966009457908

Epoch: 6| Step: 8
Training loss: 1.7297046184539795
Validation loss: 2.076511879762014

Epoch: 6| Step: 9
Training loss: 2.1355767250061035
Validation loss: 2.0709429383277893

Epoch: 6| Step: 10
Training loss: 2.8373923301696777
Validation loss: 2.063962201277415

Epoch: 6| Step: 11
Training loss: 1.4286468029022217
Validation loss: 2.0697536865870156

Epoch: 6| Step: 12
Training loss: 1.8907513618469238
Validation loss: 2.0783742467562356

Epoch: 6| Step: 13
Training loss: 2.327925205230713
Validation loss: 2.0800769130388894

Epoch: 9| Step: 0
Training loss: 2.2085680961608887
Validation loss: 2.0698679288228354

Epoch: 6| Step: 1
Training loss: 1.9139591455459595
Validation loss: 2.0794412096341452

Epoch: 6| Step: 2
Training loss: 2.6532702445983887
Validation loss: 2.0628576080004373

Epoch: 6| Step: 3
Training loss: 2.1958322525024414
Validation loss: 2.0864336093266806

Epoch: 6| Step: 4
Training loss: 2.0713558197021484
Validation loss: 2.0859262545903525

Epoch: 6| Step: 5
Training loss: 1.5116665363311768
Validation loss: 2.0870652993520102

Epoch: 6| Step: 6
Training loss: 2.040255069732666
Validation loss: 2.0725305477778115

Epoch: 6| Step: 7
Training loss: 2.4259166717529297
Validation loss: 2.067852954069773

Epoch: 6| Step: 8
Training loss: 1.7614755630493164
Validation loss: 2.0715459187825522

Epoch: 6| Step: 9
Training loss: 2.110517740249634
Validation loss: 2.0994048714637756

Epoch: 6| Step: 10
Training loss: 1.7198376655578613
Validation loss: 2.079940676689148

Epoch: 6| Step: 11
Training loss: 2.472052812576294
Validation loss: 2.0705281297365823

Epoch: 6| Step: 12
Training loss: 2.660529851913452
Validation loss: 2.082771440347036

Epoch: 6| Step: 13
Training loss: 1.4749336242675781
Validation loss: 2.0776530106862388

Epoch: 10| Step: 0
Training loss: 1.7578928470611572
Validation loss: 2.072584331035614

Epoch: 6| Step: 1
Training loss: 1.9816670417785645
Validation loss: 2.0745450854301453

Epoch: 6| Step: 2
Training loss: 2.220411539077759
Validation loss: 2.052120248476664

Epoch: 6| Step: 3
Training loss: 2.175269365310669
Validation loss: 2.0413522322972617

Epoch: 6| Step: 4
Training loss: 2.572046995162964
Validation loss: 2.0498432318369546

Epoch: 6| Step: 5
Training loss: 2.0904581546783447
Validation loss: 2.0533340175946555

Epoch: 6| Step: 6
Training loss: 2.331238269805908
Validation loss: 2.062511384487152

Epoch: 6| Step: 7
Training loss: 2.054286003112793
Validation loss: 2.0491177638371787

Epoch: 6| Step: 8
Training loss: 1.7934006452560425
Validation loss: 2.0659976402918496

Epoch: 6| Step: 9
Training loss: 1.9565058946609497
Validation loss: 2.058726946512858

Epoch: 6| Step: 10
Training loss: 2.2533376216888428
Validation loss: 2.067278484503428

Epoch: 6| Step: 11
Training loss: 1.7770171165466309
Validation loss: 2.05983829498291

Epoch: 6| Step: 12
Training loss: 1.8135014772415161
Validation loss: 2.0537987550099692

Epoch: 6| Step: 13
Training loss: 2.2595133781433105
Validation loss: 2.0570252339045205

Epoch: 11| Step: 0
Training loss: 1.95030677318573
Validation loss: 2.0522406697273254

Epoch: 6| Step: 1
Training loss: 2.113058090209961
Validation loss: 2.0475829044977822

Epoch: 6| Step: 2
Training loss: 2.4950995445251465
Validation loss: 2.0582892298698425

Epoch: 6| Step: 3
Training loss: 1.2668750286102295
Validation loss: 2.035184403260549

Epoch: 6| Step: 4
Training loss: 2.5038230419158936
Validation loss: 2.0459196170171103

Epoch: 6| Step: 5
Training loss: 2.0639796257019043
Validation loss: 2.05214657386144

Epoch: 6| Step: 6
Training loss: 2.4660723209381104
Validation loss: 2.0593918561935425

Epoch: 6| Step: 7
Training loss: 1.6674785614013672
Validation loss: 2.055201252301534

Epoch: 6| Step: 8
Training loss: 1.917011022567749
Validation loss: 2.0497647325197854

Epoch: 6| Step: 9
Training loss: 2.6151514053344727
Validation loss: 2.03472900390625

Epoch: 6| Step: 10
Training loss: 1.8131024837493896
Validation loss: 2.0556302070617676

Epoch: 6| Step: 11
Training loss: 1.7522106170654297
Validation loss: 2.0421481132507324

Epoch: 6| Step: 12
Training loss: 2.1995110511779785
Validation loss: 2.029095391432444

Epoch: 6| Step: 13
Training loss: 2.028904676437378
Validation loss: 2.051076054573059

Epoch: 12| Step: 0
Training loss: 1.6336373090744019
Validation loss: 2.044469694296519

Epoch: 6| Step: 1
Training loss: 2.592693328857422
Validation loss: 2.059992551803589

Epoch: 6| Step: 2
Training loss: 2.2233657836914062
Validation loss: 2.0594679911931357

Epoch: 6| Step: 3
Training loss: 2.4015629291534424
Validation loss: 2.064333697160085

Epoch: 6| Step: 4
Training loss: 2.272806167602539
Validation loss: 2.041628102461497

Epoch: 6| Step: 5
Training loss: 1.9185280799865723
Validation loss: 2.03767983118693

Epoch: 6| Step: 6
Training loss: 1.9450191259384155
Validation loss: 2.047743042310079

Epoch: 6| Step: 7
Training loss: 2.0340309143066406
Validation loss: 2.048722982406616

Epoch: 6| Step: 8
Training loss: 1.9300310611724854
Validation loss: 2.048481742540995

Epoch: 6| Step: 9
Training loss: 1.6312390565872192
Validation loss: 2.026720345020294

Epoch: 6| Step: 10
Training loss: 2.0105504989624023
Validation loss: 2.0448628465334573

Epoch: 6| Step: 11
Training loss: 2.0016746520996094
Validation loss: 2.060020645459493

Epoch: 6| Step: 12
Training loss: 1.709141731262207
Validation loss: 2.0535603761672974

Epoch: 6| Step: 13
Training loss: 2.501919746398926
Validation loss: 2.0425326228141785

Epoch: 13| Step: 0
Training loss: 2.0053229331970215
Validation loss: 2.0566704869270325

Epoch: 6| Step: 1
Training loss: 2.6950645446777344
Validation loss: 2.074322203795115

Epoch: 6| Step: 2
Training loss: 1.642951250076294
Validation loss: 2.054135799407959

Epoch: 6| Step: 3
Training loss: 1.9001595973968506
Validation loss: 2.0278757015864053

Epoch: 6| Step: 4
Training loss: 2.5098085403442383
Validation loss: 2.0552377502123513

Epoch: 6| Step: 5
Training loss: 2.00329327583313
Validation loss: 2.057517131169637

Epoch: 6| Step: 6
Training loss: 2.2011449337005615
Validation loss: 2.0605531533559165

Epoch: 6| Step: 7
Training loss: 1.8897426128387451
Validation loss: 2.0448360443115234

Epoch: 6| Step: 8
Training loss: 1.6592808961868286
Validation loss: 2.0465441942214966

Epoch: 6| Step: 9
Training loss: 1.7402994632720947
Validation loss: 2.018249968687693

Epoch: 6| Step: 10
Training loss: 2.2107815742492676
Validation loss: 2.0605210661888123

Epoch: 6| Step: 11
Training loss: 2.488694190979004
Validation loss: 2.0527374943097434

Epoch: 6| Step: 12
Training loss: 2.1267967224121094
Validation loss: 2.0451091527938843

Epoch: 6| Step: 13
Training loss: 1.6472344398498535
Validation loss: 2.0631449222564697

Epoch: 14| Step: 0
Training loss: 2.7135658264160156
Validation loss: 2.0613438288370767

Epoch: 6| Step: 1
Training loss: 2.1524596214294434
Validation loss: 2.03406153122584

Epoch: 6| Step: 2
Training loss: 1.8829071521759033
Validation loss: 2.036876996358236

Epoch: 6| Step: 3
Training loss: 1.3966479301452637
Validation loss: 2.056615889072418

Epoch: 6| Step: 4
Training loss: 1.6291284561157227
Validation loss: 2.045962631702423

Epoch: 6| Step: 5
Training loss: 2.611173391342163
Validation loss: 2.0638031164805093

Epoch: 6| Step: 6
Training loss: 1.9448051452636719
Validation loss: 2.0625274578730264

Epoch: 6| Step: 7
Training loss: 2.776759624481201
Validation loss: 2.0212860902150473

Epoch: 6| Step: 8
Training loss: 1.7032877206802368
Validation loss: 2.02861754099528

Epoch: 6| Step: 9
Training loss: 2.3258047103881836
Validation loss: 2.0709176659584045

Epoch: 6| Step: 10
Training loss: 1.8798699378967285
Validation loss: 2.0448511838912964

Epoch: 6| Step: 11
Training loss: 2.0299720764160156
Validation loss: 2.0356796979904175

Epoch: 6| Step: 12
Training loss: 1.9445915222167969
Validation loss: 2.033460279305776

Epoch: 6| Step: 13
Training loss: 1.793157696723938
Validation loss: 2.0301671624183655

Epoch: 15| Step: 0
Training loss: 2.158134937286377
Validation loss: 2.0251054962476096

Epoch: 6| Step: 1
Training loss: 1.972265362739563
Validation loss: 2.0138487617174783

Epoch: 6| Step: 2
Training loss: 2.332592725753784
Validation loss: 2.038114090760549

Epoch: 6| Step: 3
Training loss: 2.087761402130127
Validation loss: 2.0268655816713967

Epoch: 6| Step: 4
Training loss: 1.8663125038146973
Validation loss: 2.0632669727007547

Epoch: 6| Step: 5
Training loss: 2.186774492263794
Validation loss: 2.0247507294019065

Epoch: 6| Step: 6
Training loss: 2.0625553131103516
Validation loss: 2.0450850327809653

Epoch: 6| Step: 7
Training loss: 1.9757015705108643
Validation loss: 2.0496820410092673

Epoch: 6| Step: 8
Training loss: 2.5492818355560303
Validation loss: 2.039243241151174

Epoch: 6| Step: 9
Training loss: 1.6867291927337646
Validation loss: 2.0353763500849404

Epoch: 6| Step: 10
Training loss: 1.897858738899231
Validation loss: 2.0337429642677307

Epoch: 6| Step: 11
Training loss: 1.767420768737793
Validation loss: 2.0267180800437927

Epoch: 6| Step: 12
Training loss: 1.6693732738494873
Validation loss: 2.025017499923706

Epoch: 6| Step: 13
Training loss: 2.2215683460235596
Validation loss: 2.048217236995697

Epoch: 16| Step: 0
Training loss: 2.0286245346069336
Validation loss: 2.0696473717689514

Epoch: 6| Step: 1
Training loss: 2.547867774963379
Validation loss: 2.03207528591156

Epoch: 6| Step: 2
Training loss: 2.3992886543273926
Validation loss: 2.0419869422912598

Epoch: 6| Step: 3
Training loss: 1.5490761995315552
Validation loss: 2.0158270398775735

Epoch: 6| Step: 4
Training loss: 1.9486395120620728
Validation loss: 2.041097402572632

Epoch: 6| Step: 5
Training loss: 1.6496094465255737
Validation loss: 2.048955718676249

Epoch: 6| Step: 6
Training loss: 2.4302802085876465
Validation loss: 2.013475795586904

Epoch: 6| Step: 7
Training loss: 1.403029441833496
Validation loss: 2.039393663406372

Epoch: 6| Step: 8
Training loss: 2.180668354034424
Validation loss: 2.0485987861951194

Epoch: 6| Step: 9
Training loss: 1.6586101055145264
Validation loss: 2.0319769382476807

Epoch: 6| Step: 10
Training loss: 1.609526515007019
Validation loss: 2.0325742959976196

Epoch: 6| Step: 11
Training loss: 1.777754545211792
Validation loss: 2.0552350282669067

Epoch: 6| Step: 12
Training loss: 2.6335792541503906
Validation loss: 2.032250622908274

Epoch: 6| Step: 13
Training loss: 2.459423780441284
Validation loss: 2.0574742356936135

Epoch: 17| Step: 0
Training loss: 1.5866177082061768
Validation loss: 2.013547162214915

Epoch: 6| Step: 1
Training loss: 1.9153352975845337
Validation loss: 2.052502393722534

Epoch: 6| Step: 2
Training loss: 1.7766671180725098
Validation loss: 2.0406583547592163

Epoch: 6| Step: 3
Training loss: 1.3189759254455566
Validation loss: 2.0453765392303467

Epoch: 6| Step: 4
Training loss: 2.6534032821655273
Validation loss: 2.0300920009613037

Epoch: 6| Step: 5
Training loss: 1.7888920307159424
Validation loss: 2.0443399945894876

Epoch: 6| Step: 6
Training loss: 1.8785276412963867
Validation loss: 2.0482654571533203

Epoch: 6| Step: 7
Training loss: 2.6463510990142822
Validation loss: 2.0250210563341775

Epoch: 6| Step: 8
Training loss: 2.042466402053833
Validation loss: 2.015977402528127

Epoch: 6| Step: 9
Training loss: 2.206364870071411
Validation loss: 2.0306599338849387

Epoch: 6| Step: 10
Training loss: 2.310365676879883
Validation loss: 2.0305676460266113

Epoch: 6| Step: 11
Training loss: 2.137299060821533
Validation loss: 2.0553346077601113

Epoch: 6| Step: 12
Training loss: 2.3297557830810547
Validation loss: 2.0623690684636435

Epoch: 6| Step: 13
Training loss: 1.798758625984192
Validation loss: 2.049840291341146

Epoch: 18| Step: 0
Training loss: 2.267241954803467
Validation loss: 2.01865287621816

Epoch: 6| Step: 1
Training loss: 1.911575436592102
Validation loss: 2.042749007542928

Epoch: 6| Step: 2
Training loss: 2.2946648597717285
Validation loss: 2.0388194918632507

Epoch: 6| Step: 3
Training loss: 1.6651452779769897
Validation loss: 2.02488120396932

Epoch: 6| Step: 4
Training loss: 2.341951847076416
Validation loss: 2.02413272857666

Epoch: 6| Step: 5
Training loss: 2.3088388442993164
Validation loss: 2.0437047680219016

Epoch: 6| Step: 6
Training loss: 1.8910250663757324
Validation loss: 2.0216302474339805

Epoch: 6| Step: 7
Training loss: 1.8703230619430542
Validation loss: 2.0107542276382446

Epoch: 6| Step: 8
Training loss: 2.2553088665008545
Validation loss: 2.0544903675715127

Epoch: 6| Step: 9
Training loss: 1.20229971408844
Validation loss: 2.021631439526876

Epoch: 6| Step: 10
Training loss: 2.073373794555664
Validation loss: 2.056165258089701

Epoch: 6| Step: 11
Training loss: 1.997694492340088
Validation loss: 2.0457456906636557

Epoch: 6| Step: 12
Training loss: 2.581012487411499
Validation loss: 2.025851627190908

Epoch: 6| Step: 13
Training loss: 1.1021230220794678
Validation loss: 2.0315247774124146

Epoch: 19| Step: 0
Training loss: 2.3171823024749756
Validation loss: 2.045532683531443

Epoch: 6| Step: 1
Training loss: 1.6299587488174438
Validation loss: 2.0266062021255493

Epoch: 6| Step: 2
Training loss: 1.6802937984466553
Validation loss: 2.0475598772366843

Epoch: 6| Step: 3
Training loss: 1.7708945274353027
Validation loss: 2.0491178035736084

Epoch: 6| Step: 4
Training loss: 2.6094260215759277
Validation loss: 2.045560379823049

Epoch: 6| Step: 5
Training loss: 2.5513265132904053
Validation loss: 2.0366398890813193

Epoch: 6| Step: 6
Training loss: 1.6623620986938477
Validation loss: 2.0328267415364585

Epoch: 6| Step: 7
Training loss: 2.191985845565796
Validation loss: 2.035184144973755

Epoch: 6| Step: 8
Training loss: 1.9103245735168457
Validation loss: 2.0433027744293213

Epoch: 6| Step: 9
Training loss: 2.6395773887634277
Validation loss: 2.0520200530687966

Epoch: 6| Step: 10
Training loss: 1.4830691814422607
Validation loss: 2.051202634970347

Epoch: 6| Step: 11
Training loss: 1.5339282751083374
Validation loss: 2.0416572292645774

Epoch: 6| Step: 12
Training loss: 1.6359269618988037
Validation loss: 2.0479003389676413

Epoch: 6| Step: 13
Training loss: 2.2989325523376465
Validation loss: 2.086625953515371

Epoch: 20| Step: 0
Training loss: 2.6069459915161133
Validation loss: 2.0738380948702493

Epoch: 6| Step: 1
Training loss: 1.5114917755126953
Validation loss: 2.0544581413269043

Epoch: 6| Step: 2
Training loss: 1.817710280418396
Validation loss: 2.045080284277598

Epoch: 6| Step: 3
Training loss: 1.933349609375
Validation loss: 2.024358252684275

Epoch: 6| Step: 4
Training loss: 2.030453681945801
Validation loss: 2.0460508863131204

Epoch: 6| Step: 5
Training loss: 1.8935472965240479
Validation loss: 2.0544290939966836

Epoch: 6| Step: 6
Training loss: 2.071519374847412
Validation loss: 2.0376697182655334

Epoch: 6| Step: 7
Training loss: 1.4230122566223145
Validation loss: 2.0459894935290017

Epoch: 6| Step: 8
Training loss: 1.8318367004394531
Validation loss: 2.03179136912028

Epoch: 6| Step: 9
Training loss: 2.798771858215332
Validation loss: 2.058331290880839

Epoch: 6| Step: 10
Training loss: 2.2067337036132812
Validation loss: 2.0384335120519004

Epoch: 6| Step: 11
Training loss: 1.8729541301727295
Validation loss: 2.0094180504480996

Epoch: 6| Step: 12
Training loss: 2.526865005493164
Validation loss: 2.05194882551829

Epoch: 6| Step: 13
Training loss: 1.341381549835205
Validation loss: 2.04884539047877

Epoch: 21| Step: 0
Training loss: 2.382068395614624
Validation loss: 2.020324230194092

Epoch: 6| Step: 1
Training loss: 1.8656312227249146
Validation loss: 2.045161783695221

Epoch: 6| Step: 2
Training loss: 1.4356365203857422
Validation loss: 2.0435418287913003

Epoch: 6| Step: 3
Training loss: 2.237811803817749
Validation loss: 2.027115444342295

Epoch: 6| Step: 4
Training loss: 1.8678902387619019
Validation loss: 2.0349967877070108

Epoch: 6| Step: 5
Training loss: 2.5154614448547363
Validation loss: 2.05139430363973

Epoch: 6| Step: 6
Training loss: 1.6061406135559082
Validation loss: 2.0090975364049277

Epoch: 6| Step: 7
Training loss: 1.6725828647613525
Validation loss: 2.0294474363327026

Epoch: 6| Step: 8
Training loss: 1.837504506111145
Validation loss: 2.0477086504300437

Epoch: 6| Step: 9
Training loss: 2.0935444831848145
Validation loss: 2.0472729802131653

Epoch: 6| Step: 10
Training loss: 2.231379747390747
Validation loss: 2.0333006183306375

Epoch: 6| Step: 11
Training loss: 1.5397984981536865
Validation loss: 2.0214980244636536

Epoch: 6| Step: 12
Training loss: 2.215165376663208
Validation loss: 2.0088133215904236

Epoch: 6| Step: 13
Training loss: 2.3033287525177
Validation loss: 2.045044461886088

Epoch: 22| Step: 0
Training loss: 2.3370602130889893
Validation loss: 2.013440032800039

Epoch: 6| Step: 1
Training loss: 1.867959976196289
Validation loss: 2.0420045256614685

Epoch: 6| Step: 2
Training loss: 1.6791690587997437
Validation loss: 2.027899225552877

Epoch: 6| Step: 3
Training loss: 2.0943024158477783
Validation loss: 2.048873543739319

Epoch: 6| Step: 4
Training loss: 1.4726641178131104
Validation loss: 2.0272045532862344

Epoch: 6| Step: 5
Training loss: 2.2773756980895996
Validation loss: 2.0428108970324197

Epoch: 6| Step: 6
Training loss: 1.7922778129577637
Validation loss: 2.0399226546287537

Epoch: 6| Step: 7
Training loss: 1.748013973236084
Validation loss: 2.0540596644083657

Epoch: 6| Step: 8
Training loss: 1.7865333557128906
Validation loss: 2.0494854052861533

Epoch: 6| Step: 9
Training loss: 1.742441177368164
Validation loss: 2.0109726786613464

Epoch: 6| Step: 10
Training loss: 2.254014015197754
Validation loss: 2.0290281176567078

Epoch: 6| Step: 11
Training loss: 2.024646282196045
Validation loss: 2.0131717324256897

Epoch: 6| Step: 12
Training loss: 2.235807180404663
Validation loss: 2.02794740597407

Epoch: 6| Step: 13
Training loss: 2.1990199089050293
Validation loss: 2.023157755533854

Epoch: 23| Step: 0
Training loss: 2.2471814155578613
Validation loss: 2.039463778336843

Epoch: 6| Step: 1
Training loss: 2.4491162300109863
Validation loss: 2.02153887351354

Epoch: 6| Step: 2
Training loss: 1.3922311067581177
Validation loss: 2.0457240541776023

Epoch: 6| Step: 3
Training loss: 1.5328593254089355
Validation loss: 2.043494383494059

Epoch: 6| Step: 4
Training loss: 1.7527132034301758
Validation loss: 2.023003617922465

Epoch: 6| Step: 5
Training loss: 1.2362375259399414
Validation loss: 2.0364500085512796

Epoch: 6| Step: 6
Training loss: 2.188046932220459
Validation loss: 2.033146063486735

Epoch: 6| Step: 7
Training loss: 1.5927876234054565
Validation loss: 2.0442964235941568

Epoch: 6| Step: 8
Training loss: 1.6507965326309204
Validation loss: 2.032546957333883

Epoch: 6| Step: 9
Training loss: 2.451183795928955
Validation loss: 2.0388294458389282

Epoch: 6| Step: 10
Training loss: 1.990783929824829
Validation loss: 2.0396714409192405

Epoch: 6| Step: 11
Training loss: 2.4554805755615234
Validation loss: 2.04741370677948

Epoch: 6| Step: 12
Training loss: 2.4842631816864014
Validation loss: 2.049617350101471

Epoch: 6| Step: 13
Training loss: 2.031215190887451
Validation loss: 2.0250606338183084

Epoch: 24| Step: 0
Training loss: 1.623082160949707
Validation loss: 2.0088868737220764

Epoch: 6| Step: 1
Training loss: 1.615262746810913
Validation loss: 2.0364354252815247

Epoch: 6| Step: 2
Training loss: 1.9802109003067017
Validation loss: 2.0249802072842917

Epoch: 6| Step: 3
Training loss: 2.6332831382751465
Validation loss: 2.0512092113494873

Epoch: 6| Step: 4
Training loss: 2.061302661895752
Validation loss: 2.0526581009229026

Epoch: 6| Step: 5
Training loss: 1.4595005512237549
Validation loss: 2.035358111063639

Epoch: 6| Step: 6
Training loss: 1.6101237535476685
Validation loss: 2.0422529180844626

Epoch: 6| Step: 7
Training loss: 1.9704370498657227
Validation loss: 2.060045003890991

Epoch: 6| Step: 8
Training loss: 2.129828453063965
Validation loss: 2.0295403599739075

Epoch: 6| Step: 9
Training loss: 2.316497325897217
Validation loss: 2.050356308619181

Epoch: 6| Step: 10
Training loss: 2.236823320388794
Validation loss: 2.044300595919291

Epoch: 6| Step: 11
Training loss: 1.8875492811203003
Validation loss: 2.0413342316945395

Epoch: 6| Step: 12
Training loss: 1.5957579612731934
Validation loss: 2.050193270047506

Epoch: 6| Step: 13
Training loss: 2.624915599822998
Validation loss: 2.0514100392659507

Epoch: 25| Step: 0
Training loss: 1.729076623916626
Validation loss: 2.049427072207133

Epoch: 6| Step: 1
Training loss: 1.7172073125839233
Validation loss: 2.032447954018911

Epoch: 6| Step: 2
Training loss: 1.7300666570663452
Validation loss: 2.02625564734141

Epoch: 6| Step: 3
Training loss: 2.2650980949401855
Validation loss: 2.041050910949707

Epoch: 6| Step: 4
Training loss: 1.6619137525558472
Validation loss: 2.0321173469225564

Epoch: 6| Step: 5
Training loss: 2.2120461463928223
Validation loss: 2.0114026069641113

Epoch: 6| Step: 6
Training loss: 2.151477813720703
Validation loss: 2.030863622824351

Epoch: 6| Step: 7
Training loss: 2.4994187355041504
Validation loss: 2.0485671162605286

Epoch: 6| Step: 8
Training loss: 1.9691298007965088
Validation loss: 2.0293777783711753

Epoch: 6| Step: 9
Training loss: 1.644882321357727
Validation loss: 2.036350886027018

Epoch: 6| Step: 10
Training loss: 2.2161591053009033
Validation loss: 2.0194708903630576

Epoch: 6| Step: 11
Training loss: 1.8122793436050415
Validation loss: 2.02002223332723

Epoch: 6| Step: 12
Training loss: 1.9525349140167236
Validation loss: 2.0401156743367515

Epoch: 6| Step: 13
Training loss: 2.075009822845459
Validation loss: 2.0297412276268005

Epoch: 26| Step: 0
Training loss: 1.8367750644683838
Validation loss: 2.040965259075165

Epoch: 6| Step: 1
Training loss: 2.1340415477752686
Validation loss: 2.045157233874003

Epoch: 6| Step: 2
Training loss: 1.9535377025604248
Validation loss: 2.0250224272410073

Epoch: 6| Step: 3
Training loss: 2.25838565826416
Validation loss: 2.0620469649632773

Epoch: 6| Step: 4
Training loss: 1.8291369676589966
Validation loss: 2.0461676319440207

Epoch: 6| Step: 5
Training loss: 2.428910732269287
Validation loss: 2.070645531018575

Epoch: 6| Step: 6
Training loss: 1.9387328624725342
Validation loss: 2.0791029930114746

Epoch: 6| Step: 7
Training loss: 1.8048721551895142
Validation loss: 2.049117922782898

Epoch: 6| Step: 8
Training loss: 1.94101881980896
Validation loss: 2.0598686933517456

Epoch: 6| Step: 9
Training loss: 1.8551676273345947
Validation loss: 2.054621398448944

Epoch: 6| Step: 10
Training loss: 1.8652410507202148
Validation loss: 2.056051254272461

Epoch: 6| Step: 11
Training loss: 2.144534111022949
Validation loss: 2.027901550134023

Epoch: 6| Step: 12
Training loss: 1.2753955125808716
Validation loss: 2.0096539656321206

Epoch: 6| Step: 13
Training loss: 2.0109434127807617
Validation loss: 2.0413620273272195

Epoch: 27| Step: 0
Training loss: 1.3990485668182373
Validation loss: 2.062199572722117

Epoch: 6| Step: 1
Training loss: 3.18927001953125
Validation loss: 2.024917185306549

Epoch: 6| Step: 2
Training loss: 1.4970629215240479
Validation loss: 2.0565566023190818

Epoch: 6| Step: 3
Training loss: 1.9460610151290894
Validation loss: 2.0406866669654846

Epoch: 6| Step: 4
Training loss: 1.731879472732544
Validation loss: 2.0784735480944314

Epoch: 6| Step: 5
Training loss: 2.0073750019073486
Validation loss: 2.068747103214264

Epoch: 6| Step: 6
Training loss: 1.5886235237121582
Validation loss: 2.0797961155573526

Epoch: 6| Step: 7
Training loss: 1.7087757587432861
Validation loss: 2.060785790284475

Epoch: 6| Step: 8
Training loss: 2.363335371017456
Validation loss: 2.0422616998354592

Epoch: 6| Step: 9
Training loss: 1.5628823041915894
Validation loss: 2.0292604764302573

Epoch: 6| Step: 10
Training loss: 2.2120232582092285
Validation loss: 2.008547385533651

Epoch: 6| Step: 11
Training loss: 2.5280814170837402
Validation loss: 2.059301018714905

Epoch: 6| Step: 12
Training loss: 1.9910180568695068
Validation loss: 2.0314363638559976

Epoch: 6| Step: 13
Training loss: 2.289029836654663
Validation loss: 2.028205136458079

Epoch: 28| Step: 0
Training loss: 2.2715506553649902
Validation loss: 2.0570110281308494

Epoch: 6| Step: 1
Training loss: 2.1737356185913086
Validation loss: 2.068501094977061

Epoch: 6| Step: 2
Training loss: 1.959287405014038
Validation loss: 2.075616399447123

Epoch: 6| Step: 3
Training loss: 1.6792194843292236
Validation loss: 2.0235546827316284

Epoch: 6| Step: 4
Training loss: 1.627117395401001
Validation loss: 2.0590862234433494

Epoch: 6| Step: 5
Training loss: 1.6302070617675781
Validation loss: 2.015209992726644

Epoch: 6| Step: 6
Training loss: 1.667520523071289
Validation loss: 2.041311244169871

Epoch: 6| Step: 7
Training loss: 2.326381206512451
Validation loss: 2.068917393684387

Epoch: 6| Step: 8
Training loss: 1.7707715034484863
Validation loss: 2.032087028026581

Epoch: 6| Step: 9
Training loss: 1.5171515941619873
Validation loss: 2.033866902192434

Epoch: 6| Step: 10
Training loss: 2.1113121509552
Validation loss: 2.0055812199910483

Epoch: 6| Step: 11
Training loss: 1.9209389686584473
Validation loss: 2.056589881579081

Epoch: 6| Step: 12
Training loss: 2.033578872680664
Validation loss: 2.0168922344843545

Epoch: 6| Step: 13
Training loss: 2.5438990592956543
Validation loss: 2.0486960411071777

Epoch: 29| Step: 0
Training loss: 2.2220826148986816
Validation loss: 2.0623461604118347

Epoch: 6| Step: 1
Training loss: 2.3712401390075684
Validation loss: 2.0276055335998535

Epoch: 6| Step: 2
Training loss: 1.4306163787841797
Validation loss: 2.0559224287668862

Epoch: 6| Step: 3
Training loss: 2.2799391746520996
Validation loss: 2.053201953570048

Epoch: 6| Step: 4
Training loss: 2.3295936584472656
Validation loss: 2.04993865887324

Epoch: 6| Step: 5
Training loss: 1.5624312162399292
Validation loss: 2.0798531770706177

Epoch: 6| Step: 6
Training loss: 2.0245823860168457
Validation loss: 2.0528512994448342

Epoch: 6| Step: 7
Training loss: 1.4768292903900146
Validation loss: 2.046327074368795

Epoch: 6| Step: 8
Training loss: 1.5334796905517578
Validation loss: 2.0395765701929727

Epoch: 6| Step: 9
Training loss: 2.213590145111084
Validation loss: 2.084798594315847

Epoch: 6| Step: 10
Training loss: 2.011354923248291
Validation loss: 2.031314571698507

Epoch: 6| Step: 11
Training loss: 1.8891267776489258
Validation loss: 2.048203786214193

Epoch: 6| Step: 12
Training loss: 1.7673232555389404
Validation loss: 2.0311522086461387

Epoch: 6| Step: 13
Training loss: 2.595675468444824
Validation loss: 2.0540923277537027

Epoch: 30| Step: 0
Training loss: 1.5017476081848145
Validation loss: 2.024861454963684

Epoch: 6| Step: 1
Training loss: 2.412212371826172
Validation loss: 2.0294891198476157

Epoch: 6| Step: 2
Training loss: 1.4984657764434814
Validation loss: 2.056992848714193

Epoch: 6| Step: 3
Training loss: 1.8033664226531982
Validation loss: 2.07095734278361

Epoch: 6| Step: 4
Training loss: 2.1147713661193848
Validation loss: 2.058952589829763

Epoch: 6| Step: 5
Training loss: 2.396350145339966
Validation loss: 2.0590573946634927

Epoch: 6| Step: 6
Training loss: 1.7635011672973633
Validation loss: 2.078024665514628

Epoch: 6| Step: 7
Training loss: 2.227050304412842
Validation loss: 2.036843498547872

Epoch: 6| Step: 8
Training loss: 2.1583621501922607
Validation loss: 2.028232991695404

Epoch: 6| Step: 9
Training loss: 1.355090618133545
Validation loss: 2.041321794191996

Epoch: 6| Step: 10
Training loss: 2.3376059532165527
Validation loss: 2.02158123254776

Epoch: 6| Step: 11
Training loss: 1.9463082551956177
Validation loss: 2.050811767578125

Epoch: 6| Step: 12
Training loss: 2.0141634941101074
Validation loss: 2.0412168900171914

Epoch: 6| Step: 13
Training loss: 2.177915573120117
Validation loss: 2.036541700363159

Epoch: 31| Step: 0
Training loss: 2.18742036819458
Validation loss: 2.056702216466268

Epoch: 6| Step: 1
Training loss: 1.3352229595184326
Validation loss: 2.004233996073405

Epoch: 6| Step: 2
Training loss: 1.9562451839447021
Validation loss: 2.021999398867289

Epoch: 6| Step: 3
Training loss: 1.6924856901168823
Validation loss: 2.0771140654881797

Epoch: 6| Step: 4
Training loss: 1.713410496711731
Validation loss: 2.004344165325165

Epoch: 6| Step: 5
Training loss: 1.6090872287750244
Validation loss: 2.0123249093691506

Epoch: 6| Step: 6
Training loss: 2.2761802673339844
Validation loss: 2.0487526655197144

Epoch: 6| Step: 7
Training loss: 1.3950178623199463
Validation loss: 2.0127544601758323

Epoch: 6| Step: 8
Training loss: 2.0481245517730713
Validation loss: 2.0370779434839883

Epoch: 6| Step: 9
Training loss: 2.4539361000061035
Validation loss: 2.004676580429077

Epoch: 6| Step: 10
Training loss: 2.5074944496154785
Validation loss: 2.034343183040619

Epoch: 6| Step: 11
Training loss: 1.2553293704986572
Validation loss: 2.040785630544027

Epoch: 6| Step: 12
Training loss: 1.7512092590332031
Validation loss: 2.0726211865743003

Epoch: 6| Step: 13
Training loss: 2.4214396476745605
Validation loss: 2.058366318543752

Epoch: 32| Step: 0
Training loss: 1.6607093811035156
Validation loss: 2.054980715115865

Epoch: 6| Step: 1
Training loss: 1.8628475666046143
Validation loss: 2.024868667125702

Epoch: 6| Step: 2
Training loss: 1.9239290952682495
Validation loss: 2.0267521937688193

Epoch: 6| Step: 3
Training loss: 1.6308091878890991
Validation loss: 2.0704390009244285

Epoch: 6| Step: 4
Training loss: 1.7613002061843872
Validation loss: 2.0392685731252036

Epoch: 6| Step: 5
Training loss: 1.5276505947113037
Validation loss: 2.045791824658712

Epoch: 6| Step: 6
Training loss: 2.3767213821411133
Validation loss: 2.0278839468955994

Epoch: 6| Step: 7
Training loss: 2.1345279216766357
Validation loss: 2.0653964082400003

Epoch: 6| Step: 8
Training loss: 1.828614354133606
Validation loss: 2.0559388995170593

Epoch: 6| Step: 9
Training loss: 2.4514143466949463
Validation loss: 2.0317636330922446

Epoch: 6| Step: 10
Training loss: 1.5370699167251587
Validation loss: 2.0427885254224143

Epoch: 6| Step: 11
Training loss: 1.4949288368225098
Validation loss: 2.036092003186544

Epoch: 6| Step: 12
Training loss: 2.3523001670837402
Validation loss: 2.054922421773275

Epoch: 6| Step: 13
Training loss: 2.3075013160705566
Validation loss: 2.061395009358724

Epoch: 33| Step: 0
Training loss: 1.506897211074829
Validation loss: 2.0308614571889243

Epoch: 6| Step: 1
Training loss: 2.6208577156066895
Validation loss: 2.0493550896644592

Epoch: 6| Step: 2
Training loss: 1.850059986114502
Validation loss: 2.0182013511657715

Epoch: 6| Step: 3
Training loss: 2.0980606079101562
Validation loss: 2.039283891518911

Epoch: 6| Step: 4
Training loss: 1.888214349746704
Validation loss: 2.047989308834076

Epoch: 6| Step: 5
Training loss: 2.026660919189453
Validation loss: 2.0304412841796875

Epoch: 6| Step: 6
Training loss: 1.8111010789871216
Validation loss: 2.060786187648773

Epoch: 6| Step: 7
Training loss: 1.5131096839904785
Validation loss: 1.9975432356198628

Epoch: 6| Step: 8
Training loss: 1.689623236656189
Validation loss: 2.0492759346961975

Epoch: 6| Step: 9
Training loss: 2.061431884765625
Validation loss: 2.060203234354655

Epoch: 6| Step: 10
Training loss: 1.5205695629119873
Validation loss: 2.0266977548599243

Epoch: 6| Step: 11
Training loss: 2.395655632019043
Validation loss: 2.0422861576080322

Epoch: 6| Step: 12
Training loss: 1.8870866298675537
Validation loss: 2.056923429171244

Epoch: 6| Step: 13
Training loss: 2.376370906829834
Validation loss: 2.034463087717692

Epoch: 34| Step: 0
Training loss: 2.112487554550171
Validation loss: 2.040907879670461

Epoch: 6| Step: 1
Training loss: 2.093717098236084
Validation loss: 2.054804503917694

Epoch: 6| Step: 2
Training loss: 1.9727486371994019
Validation loss: 2.0804816087086997

Epoch: 6| Step: 3
Training loss: 2.0341243743896484
Validation loss: 2.0460424025853476

Epoch: 6| Step: 4
Training loss: 2.0499467849731445
Validation loss: 2.0202446977297464

Epoch: 6| Step: 5
Training loss: 1.5494341850280762
Validation loss: 2.054460128148397

Epoch: 6| Step: 6
Training loss: 1.9792563915252686
Validation loss: 2.0604854027430215

Epoch: 6| Step: 7
Training loss: 1.658884048461914
Validation loss: 2.0106555620829263

Epoch: 6| Step: 8
Training loss: 2.3098721504211426
Validation loss: 2.0213381250699363

Epoch: 6| Step: 9
Training loss: 2.0966668128967285
Validation loss: 2.0246117313702903

Epoch: 6| Step: 10
Training loss: 1.2661018371582031
Validation loss: 2.0463908314704895

Epoch: 6| Step: 11
Training loss: 1.611287236213684
Validation loss: 2.0640063087145486

Epoch: 6| Step: 12
Training loss: 2.25032377243042
Validation loss: 2.048034429550171

Epoch: 6| Step: 13
Training loss: 1.5401687622070312
Validation loss: 2.039247473080953

Epoch: 35| Step: 0
Training loss: 1.998435378074646
Validation loss: 2.0223513642946878

Epoch: 6| Step: 1
Training loss: 2.363407611846924
Validation loss: 2.0343504548072815

Epoch: 6| Step: 2
Training loss: 1.0498126745224
Validation loss: 2.0275798042615256

Epoch: 6| Step: 3
Training loss: 1.96903657913208
Validation loss: 2.0414742827415466

Epoch: 6| Step: 4
Training loss: 1.6915795803070068
Validation loss: 2.0525037050247192

Epoch: 6| Step: 5
Training loss: 2.412001609802246
Validation loss: 2.053690731525421

Epoch: 6| Step: 6
Training loss: 1.2553268671035767
Validation loss: 2.044520139694214

Epoch: 6| Step: 7
Training loss: 2.1603665351867676
Validation loss: 2.0447808504104614

Epoch: 6| Step: 8
Training loss: 1.235274314880371
Validation loss: 2.07515941063563

Epoch: 6| Step: 9
Training loss: 2.031024217605591
Validation loss: 2.0559906562169394

Epoch: 6| Step: 10
Training loss: 2.0451745986938477
Validation loss: 2.03958797454834

Epoch: 6| Step: 11
Training loss: 2.2513375282287598
Validation loss: 2.0448108315467834

Epoch: 6| Step: 12
Training loss: 2.5460622310638428
Validation loss: 2.0154231786727905

Epoch: 6| Step: 13
Training loss: 1.9314253330230713
Validation loss: 2.0210653146107993

Epoch: 36| Step: 0
Training loss: 2.0124311447143555
Validation loss: 2.024227023124695

Epoch: 6| Step: 1
Training loss: 1.9791606664657593
Validation loss: 2.0283385713895163

Epoch: 6| Step: 2
Training loss: 1.7889552116394043
Validation loss: 2.035005271434784

Epoch: 6| Step: 3
Training loss: 1.6194965839385986
Validation loss: 2.027213195959727

Epoch: 6| Step: 4
Training loss: 1.7929108142852783
Validation loss: 2.043248693148295

Epoch: 6| Step: 5
Training loss: 1.399648666381836
Validation loss: 2.0674912134806314

Epoch: 6| Step: 6
Training loss: 2.6207680702209473
Validation loss: 2.023224393526713

Epoch: 6| Step: 7
Training loss: 1.5733933448791504
Validation loss: 2.0386359890302024

Epoch: 6| Step: 8
Training loss: 2.0228142738342285
Validation loss: 2.032473166783651

Epoch: 6| Step: 9
Training loss: 1.949065089225769
Validation loss: 2.062756657600403

Epoch: 6| Step: 10
Training loss: 2.047849655151367
Validation loss: 2.056650161743164

Epoch: 6| Step: 11
Training loss: 1.931147575378418
Validation loss: 1.9938847819964092

Epoch: 6| Step: 12
Training loss: 1.9286580085754395
Validation loss: 2.0619113047917685

Epoch: 6| Step: 13
Training loss: 1.8244071006774902
Validation loss: 2.044061621030172

Epoch: 37| Step: 0
Training loss: 2.4578347206115723
Validation loss: 2.046744247277578

Epoch: 6| Step: 1
Training loss: 2.465557098388672
Validation loss: 2.0274887482325235

Epoch: 6| Step: 2
Training loss: 1.8031437397003174
Validation loss: 2.0445600946744285

Epoch: 6| Step: 3
Training loss: 1.946640133857727
Validation loss: 2.0437584122021994

Epoch: 6| Step: 4
Training loss: 2.0135738849639893
Validation loss: 2.0199332435925803

Epoch: 6| Step: 5
Training loss: 1.7974625825881958
Validation loss: 2.0534887313842773

Epoch: 6| Step: 6
Training loss: 1.3782203197479248
Validation loss: 2.0231754382451377

Epoch: 6| Step: 7
Training loss: 1.6325404644012451
Validation loss: 2.0401804049809775

Epoch: 6| Step: 8
Training loss: 2.348867654800415
Validation loss: 2.079322636127472

Epoch: 6| Step: 9
Training loss: 1.9059991836547852
Validation loss: 2.0347497264544168

Epoch: 6| Step: 10
Training loss: 1.791562557220459
Validation loss: 2.0550857186317444

Epoch: 6| Step: 11
Training loss: 1.8033623695373535
Validation loss: 2.0338926116625466

Epoch: 6| Step: 12
Training loss: 1.5791829824447632
Validation loss: 2.042985419432322

Epoch: 6| Step: 13
Training loss: 1.5642280578613281
Validation loss: 2.0807689229647317

Epoch: 38| Step: 0
Training loss: 1.9533661603927612
Validation loss: 2.0389602184295654

Epoch: 6| Step: 1
Training loss: 2.150930404663086
Validation loss: 2.0342034697532654

Epoch: 6| Step: 2
Training loss: 2.4128637313842773
Validation loss: 2.020922819773356

Epoch: 6| Step: 3
Training loss: 1.101184606552124
Validation loss: 2.0277294913927713

Epoch: 6| Step: 4
Training loss: 1.8352973461151123
Validation loss: 2.015935798486074

Epoch: 6| Step: 5
Training loss: 2.1243693828582764
Validation loss: 2.0626211563746133

Epoch: 6| Step: 6
Training loss: 1.7651830911636353
Validation loss: 2.0366594592730203

Epoch: 6| Step: 7
Training loss: 1.3865532875061035
Validation loss: 2.0817110538482666

Epoch: 6| Step: 8
Training loss: 2.170487403869629
Validation loss: 2.0507439573605857

Epoch: 6| Step: 9
Training loss: 1.541039228439331
Validation loss: 2.045888821283976

Epoch: 6| Step: 10
Training loss: 2.230760097503662
Validation loss: 2.0485676924387612

Epoch: 6| Step: 11
Training loss: 2.195713520050049
Validation loss: 2.089887181917826

Epoch: 6| Step: 12
Training loss: 2.214944362640381
Validation loss: 2.04000594218572

Epoch: 6| Step: 13
Training loss: 1.4293081760406494
Validation loss: 2.026761551698049

Epoch: 39| Step: 0
Training loss: 2.3571839332580566
Validation loss: 2.0186685919761658

Epoch: 6| Step: 1
Training loss: 1.6911722421646118
Validation loss: 2.017932673295339

Epoch: 6| Step: 2
Training loss: 1.4119665622711182
Validation loss: 2.062095661958059

Epoch: 6| Step: 3
Training loss: 1.4437947273254395
Validation loss: 2.0897583961486816

Epoch: 6| Step: 4
Training loss: 2.356412887573242
Validation loss: 2.0925270915031433

Epoch: 6| Step: 5
Training loss: 1.5908722877502441
Validation loss: 2.025556723276774

Epoch: 6| Step: 6
Training loss: 1.5575802326202393
Validation loss: 2.0350810289382935

Epoch: 6| Step: 7
Training loss: 1.8101617097854614
Validation loss: 2.0819991628328958

Epoch: 6| Step: 8
Training loss: 2.1171560287475586
Validation loss: 2.060672660668691

Epoch: 6| Step: 9
Training loss: 2.235590934753418
Validation loss: 2.0373608072598777

Epoch: 6| Step: 10
Training loss: 1.4810068607330322
Validation loss: 2.0676002899805703

Epoch: 6| Step: 11
Training loss: 2.0022411346435547
Validation loss: 2.048134724299113

Epoch: 6| Step: 12
Training loss: 2.7270774841308594
Validation loss: 2.0750654339790344

Epoch: 6| Step: 13
Training loss: 1.6402146816253662
Validation loss: 2.0498558282852173

Epoch: 40| Step: 0
Training loss: 1.477671504020691
Validation loss: 2.0533233086268106

Epoch: 6| Step: 1
Training loss: 1.5502339601516724
Validation loss: 2.056069254875183

Epoch: 6| Step: 2
Training loss: 1.583282470703125
Validation loss: 2.0526265303293862

Epoch: 6| Step: 3
Training loss: 1.8073267936706543
Validation loss: 2.0501253406206765

Epoch: 6| Step: 4
Training loss: 2.7998247146606445
Validation loss: 2.053094188372294

Epoch: 6| Step: 5
Training loss: 1.9726110696792603
Validation loss: 2.04636679093043

Epoch: 6| Step: 6
Training loss: 2.0172362327575684
Validation loss: 2.0923483769098916

Epoch: 6| Step: 7
Training loss: 2.029695987701416
Validation loss: 2.038806676864624

Epoch: 6| Step: 8
Training loss: 1.7920722961425781
Validation loss: 2.035025636355082

Epoch: 6| Step: 9
Training loss: 1.470329999923706
Validation loss: 2.0270286003748574

Epoch: 6| Step: 10
Training loss: 1.576298713684082
Validation loss: 2.043193598588308

Epoch: 6| Step: 11
Training loss: 2.2928578853607178
Validation loss: 2.049184878667196

Epoch: 6| Step: 12
Training loss: 2.1070849895477295
Validation loss: 2.035211662451426

Epoch: 6| Step: 13
Training loss: 1.6814216375350952
Validation loss: 2.091034551461538

Epoch: 41| Step: 0
Training loss: 2.6005351543426514
Validation loss: 2.0387988289197287

Epoch: 6| Step: 1
Training loss: 2.2318849563598633
Validation loss: 2.0384610295295715

Epoch: 6| Step: 2
Training loss: 1.5334656238555908
Validation loss: 2.037774662176768

Epoch: 6| Step: 3
Training loss: 1.667588233947754
Validation loss: 2.0651703675587973

Epoch: 6| Step: 4
Training loss: 1.629770040512085
Validation loss: 2.0640132824579873

Epoch: 6| Step: 5
Training loss: 1.7887195348739624
Validation loss: 2.0485288898150125

Epoch: 6| Step: 6
Training loss: 2.3250620365142822
Validation loss: 2.09319007396698

Epoch: 6| Step: 7
Training loss: 2.0503978729248047
Validation loss: 2.0187729795773826

Epoch: 6| Step: 8
Training loss: 1.244067907333374
Validation loss: 2.037689963976542

Epoch: 6| Step: 9
Training loss: 1.8568611145019531
Validation loss: 2.068184713522593

Epoch: 6| Step: 10
Training loss: 1.6392743587493896
Validation loss: 2.079352001349131

Epoch: 6| Step: 11
Training loss: 2.256218194961548
Validation loss: 2.026759386062622

Epoch: 6| Step: 12
Training loss: 2.0123696327209473
Validation loss: 2.0768641432126365

Epoch: 6| Step: 13
Training loss: 1.8216756582260132
Validation loss: 2.067876855532328

Epoch: 42| Step: 0
Training loss: 1.6354337930679321
Validation loss: 2.062185784180959

Epoch: 6| Step: 1
Training loss: 1.9412908554077148
Validation loss: 2.066031793753306

Epoch: 6| Step: 2
Training loss: 1.5893232822418213
Validation loss: 2.0816352168718972

Epoch: 6| Step: 3
Training loss: 1.6440508365631104
Validation loss: 2.059055666128794

Epoch: 6| Step: 4
Training loss: 1.980332851409912
Validation loss: 2.0636916756629944

Epoch: 6| Step: 5
Training loss: 1.678858995437622
Validation loss: 2.0239925185839334

Epoch: 6| Step: 6
Training loss: 2.297748327255249
Validation loss: 2.0356172720591226

Epoch: 6| Step: 7
Training loss: 1.7253434658050537
Validation loss: 2.070965747038523

Epoch: 6| Step: 8
Training loss: 1.6606261730194092
Validation loss: 2.051571031411489

Epoch: 6| Step: 9
Training loss: 2.36013126373291
Validation loss: 2.0619457761446633

Epoch: 6| Step: 10
Training loss: 2.0927419662475586
Validation loss: 2.03789754708608

Epoch: 6| Step: 11
Training loss: 1.6591122150421143
Validation loss: 2.064220388730367

Epoch: 6| Step: 12
Training loss: 2.2447855472564697
Validation loss: 2.0700572729110718

Epoch: 6| Step: 13
Training loss: 1.6680164337158203
Validation loss: 2.0632907152175903

Epoch: 43| Step: 0
Training loss: 1.8627020120620728
Validation loss: 2.0542309482892356

Epoch: 6| Step: 1
Training loss: 1.8796050548553467
Validation loss: 2.0668399333953857

Epoch: 6| Step: 2
Training loss: 1.5700173377990723
Validation loss: 2.054221272468567

Epoch: 6| Step: 3
Training loss: 1.8789772987365723
Validation loss: 2.0541249910990396

Epoch: 6| Step: 4
Training loss: 2.6469593048095703
Validation loss: 2.0305379231770835

Epoch: 6| Step: 5
Training loss: 1.679582953453064
Validation loss: 2.1075580517450967

Epoch: 6| Step: 6
Training loss: 1.8269989490509033
Validation loss: 2.044692099094391

Epoch: 6| Step: 7
Training loss: 1.2867342233657837
Validation loss: 2.0842236479123435

Epoch: 6| Step: 8
Training loss: 2.058725118637085
Validation loss: 2.044453283150991

Epoch: 6| Step: 9
Training loss: 1.3635520935058594
Validation loss: 2.0448819398880005

Epoch: 6| Step: 10
Training loss: 1.6346832513809204
Validation loss: 2.0414701104164124

Epoch: 6| Step: 11
Training loss: 1.7463982105255127
Validation loss: 2.008712867895762

Epoch: 6| Step: 12
Training loss: 1.7914698123931885
Validation loss: 2.0717804034550986

Epoch: 6| Step: 13
Training loss: 2.851224184036255
Validation loss: 2.062510927518209

Epoch: 44| Step: 0
Training loss: 2.5737695693969727
Validation loss: 2.0202152927716575

Epoch: 6| Step: 1
Training loss: 1.8730015754699707
Validation loss: 2.025664130846659

Epoch: 6| Step: 2
Training loss: 1.7391765117645264
Validation loss: 2.0746436715126038

Epoch: 6| Step: 3
Training loss: 1.2936680316925049
Validation loss: 2.0443155765533447

Epoch: 6| Step: 4
Training loss: 1.649533987045288
Validation loss: 2.03534471988678

Epoch: 6| Step: 5
Training loss: 2.0965676307678223
Validation loss: 2.0608269373575845

Epoch: 6| Step: 6
Training loss: 1.3411505222320557
Validation loss: 2.066851337750753

Epoch: 6| Step: 7
Training loss: 1.860185980796814
Validation loss: 2.0691164135932922

Epoch: 6| Step: 8
Training loss: 1.6068023443222046
Validation loss: 2.0561898946762085

Epoch: 6| Step: 9
Training loss: 1.0381708145141602
Validation loss: 2.0573250452677407

Epoch: 6| Step: 10
Training loss: 1.7580764293670654
Validation loss: 2.089388132095337

Epoch: 6| Step: 11
Training loss: 2.7025551795959473
Validation loss: 2.064736306667328

Epoch: 6| Step: 12
Training loss: 2.076043128967285
Validation loss: 2.0397293965021768

Epoch: 6| Step: 13
Training loss: 2.262995958328247
Validation loss: 2.0561394492785134

Epoch: 45| Step: 0
Training loss: 1.9838508367538452
Validation loss: 2.043010095755259

Epoch: 6| Step: 1
Training loss: 1.707963466644287
Validation loss: 2.099821627140045

Epoch: 6| Step: 2
Training loss: 2.112321376800537
Validation loss: 2.0706881086031594

Epoch: 6| Step: 3
Training loss: 2.6407175064086914
Validation loss: 2.0845174392064414

Epoch: 6| Step: 4
Training loss: 1.8152520656585693
Validation loss: 2.0701289772987366

Epoch: 6| Step: 5
Training loss: 1.7018225193023682
Validation loss: 2.0319248835245767

Epoch: 6| Step: 6
Training loss: 1.7438603639602661
Validation loss: 2.054802656173706

Epoch: 6| Step: 7
Training loss: 1.7409073114395142
Validation loss: 2.0038403272628784

Epoch: 6| Step: 8
Training loss: 1.2060976028442383
Validation loss: 2.0299707849820456

Epoch: 6| Step: 9
Training loss: 2.487689971923828
Validation loss: 2.0649626652399697

Epoch: 6| Step: 10
Training loss: 1.586667537689209
Validation loss: 2.0923097332318625

Epoch: 6| Step: 11
Training loss: 2.349147319793701
Validation loss: 2.0700710217158

Epoch: 6| Step: 12
Training loss: 1.6046779155731201
Validation loss: 2.0611491998036704

Epoch: 6| Step: 13
Training loss: 1.4902021884918213
Validation loss: 2.0609224239985147

Epoch: 46| Step: 0
Training loss: 1.7549045085906982
Validation loss: 2.033619999885559

Epoch: 6| Step: 1
Training loss: 1.3281596899032593
Validation loss: 2.073462108771006

Epoch: 6| Step: 2
Training loss: 2.005568504333496
Validation loss: 2.0973896781603494

Epoch: 6| Step: 3
Training loss: 1.1227444410324097
Validation loss: 2.0683660308519998

Epoch: 6| Step: 4
Training loss: 1.8135547637939453
Validation loss: 2.0717599391937256

Epoch: 6| Step: 5
Training loss: 1.3881306648254395
Validation loss: 2.0490988294283548

Epoch: 6| Step: 6
Training loss: 1.8181734085083008
Validation loss: 2.012237270673116

Epoch: 6| Step: 7
Training loss: 2.0114102363586426
Validation loss: 2.0984093944231668

Epoch: 6| Step: 8
Training loss: 2.127229690551758
Validation loss: 2.0474859476089478

Epoch: 6| Step: 9
Training loss: 1.8548649549484253
Validation loss: 2.071723520755768

Epoch: 6| Step: 10
Training loss: 1.7886133193969727
Validation loss: 2.0298726757367453

Epoch: 6| Step: 11
Training loss: 2.0974416732788086
Validation loss: 2.042091687520345

Epoch: 6| Step: 12
Training loss: 1.7043843269348145
Validation loss: 2.038593908150991

Epoch: 6| Step: 13
Training loss: 2.911421775817871
Validation loss: 2.058503826459249

Epoch: 47| Step: 0
Training loss: 1.9381256103515625
Validation loss: 2.057188312212626

Epoch: 6| Step: 1
Training loss: 1.830506682395935
Validation loss: 2.0385436415672302

Epoch: 6| Step: 2
Training loss: 1.0615592002868652
Validation loss: 2.0465479095776877

Epoch: 6| Step: 3
Training loss: 1.663211464881897
Validation loss: 2.034688492616018

Epoch: 6| Step: 4
Training loss: 1.6671613454818726
Validation loss: 2.0117286245028176

Epoch: 6| Step: 5
Training loss: 1.5951775312423706
Validation loss: 2.0505409638086953

Epoch: 6| Step: 6
Training loss: 2.5137953758239746
Validation loss: 2.028978705406189

Epoch: 6| Step: 7
Training loss: 1.5966745615005493
Validation loss: 2.0824352304140725

Epoch: 6| Step: 8
Training loss: 2.2406249046325684
Validation loss: 2.0223130583763123

Epoch: 6| Step: 9
Training loss: 1.7095987796783447
Validation loss: 2.0669962565104165

Epoch: 6| Step: 10
Training loss: 2.1594271659851074
Validation loss: 2.030746897061666

Epoch: 6| Step: 11
Training loss: 2.3048899173736572
Validation loss: 2.0691948731740317

Epoch: 6| Step: 12
Training loss: 2.1355528831481934
Validation loss: 2.074440916379293

Epoch: 6| Step: 13
Training loss: 1.7117477655410767
Validation loss: 2.0538583596547446

Epoch: 48| Step: 0
Training loss: 2.185272216796875
Validation loss: 2.0504504839579263

Epoch: 6| Step: 1
Training loss: 1.2427021265029907
Validation loss: 2.042602320512136

Epoch: 6| Step: 2
Training loss: 1.1966466903686523
Validation loss: 2.0430258313814798

Epoch: 6| Step: 3
Training loss: 1.6700745820999146
Validation loss: 2.011807998021444

Epoch: 6| Step: 4
Training loss: 2.3302736282348633
Validation loss: 2.0371775031089783

Epoch: 6| Step: 5
Training loss: 1.7263115644454956
Validation loss: 2.070072114467621

Epoch: 6| Step: 6
Training loss: 2.1774120330810547
Validation loss: 2.015432874361674

Epoch: 6| Step: 7
Training loss: 2.192643642425537
Validation loss: 2.065479576587677

Epoch: 6| Step: 8
Training loss: 2.38301944732666
Validation loss: 2.099253515402476

Epoch: 6| Step: 9
Training loss: 1.115073323249817
Validation loss: 2.02973473072052

Epoch: 6| Step: 10
Training loss: 2.169790744781494
Validation loss: 2.0460595885912576

Epoch: 6| Step: 11
Training loss: 2.370649814605713
Validation loss: 2.0578344265619912

Epoch: 6| Step: 12
Training loss: 1.2174040079116821
Validation loss: 2.059442400932312

Epoch: 6| Step: 13
Training loss: 1.7874770164489746
Validation loss: 1.9989417592684429

Epoch: 49| Step: 0
Training loss: 1.559552550315857
Validation loss: 2.0495407382647195

Epoch: 6| Step: 1
Training loss: 2.32546329498291
Validation loss: 2.055905838807424

Epoch: 6| Step: 2
Training loss: 1.928794503211975
Validation loss: 2.0415191650390625

Epoch: 6| Step: 3
Training loss: 2.222592353820801
Validation loss: 2.062764823436737

Epoch: 6| Step: 4
Training loss: 2.3749899864196777
Validation loss: 2.059054712454478

Epoch: 6| Step: 5
Training loss: 1.8791253566741943
Validation loss: 2.051745891571045

Epoch: 6| Step: 6
Training loss: 1.8771368265151978
Validation loss: 2.022090276082357

Epoch: 6| Step: 7
Training loss: 1.6216591596603394
Validation loss: 2.0106800397237143

Epoch: 6| Step: 8
Training loss: 2.4830899238586426
Validation loss: 2.0481264193852744

Epoch: 6| Step: 9
Training loss: 2.162841320037842
Validation loss: 2.0666704177856445

Epoch: 6| Step: 10
Training loss: 1.2949497699737549
Validation loss: 2.085600733757019

Epoch: 6| Step: 11
Training loss: 1.1443580389022827
Validation loss: 2.0458398262659707

Epoch: 6| Step: 12
Training loss: 1.2267730236053467
Validation loss: 2.07740048567454

Epoch: 6| Step: 13
Training loss: 1.3985515832901
Validation loss: 2.0708558758099875

Epoch: 50| Step: 0
Training loss: 1.461578607559204
Validation loss: 2.1019395192464194

Epoch: 6| Step: 1
Training loss: 1.5789260864257812
Validation loss: 2.060163915157318

Epoch: 6| Step: 2
Training loss: 2.3078155517578125
Validation loss: 2.0614925424257913

Epoch: 6| Step: 3
Training loss: 1.6212539672851562
Validation loss: 1.998695433139801

Epoch: 6| Step: 4
Training loss: 1.712101697921753
Validation loss: 2.06446365515391

Epoch: 6| Step: 5
Training loss: 1.179876685142517
Validation loss: 2.0784674286842346

Epoch: 6| Step: 6
Training loss: 1.813997507095337
Validation loss: 2.064666827519735

Epoch: 6| Step: 7
Training loss: 1.54750657081604
Validation loss: 2.106045424938202

Epoch: 6| Step: 8
Training loss: 1.9269887208938599
Validation loss: 2.094831923643748

Epoch: 6| Step: 9
Training loss: 1.8842731714248657
Validation loss: 2.1158968408902488

Epoch: 6| Step: 10
Training loss: 1.7578486204147339
Validation loss: 2.0497549772262573

Epoch: 6| Step: 11
Training loss: 2.5804362297058105
Validation loss: 2.085330684979757

Epoch: 6| Step: 12
Training loss: 2.1706197261810303
Validation loss: 2.053715964158376

Epoch: 6| Step: 13
Training loss: 2.199481248855591
Validation loss: 2.0320401787757874

Epoch: 51| Step: 0
Training loss: 1.869978666305542
Validation loss: 2.040104627609253

Epoch: 6| Step: 1
Training loss: 1.5737884044647217
Validation loss: 2.066939731438955

Epoch: 6| Step: 2
Training loss: 1.181061029434204
Validation loss: 2.0503578583399453

Epoch: 6| Step: 3
Training loss: 2.1599984169006348
Validation loss: 2.0552011926968894

Epoch: 6| Step: 4
Training loss: 1.9004628658294678
Validation loss: 2.0718568364779153

Epoch: 6| Step: 5
Training loss: 1.6138956546783447
Validation loss: 2.028192679087321

Epoch: 6| Step: 6
Training loss: 1.6001888513565063
Validation loss: 2.0551087657610574

Epoch: 6| Step: 7
Training loss: 1.9026883840560913
Validation loss: 1.9853944977124531

Epoch: 6| Step: 8
Training loss: 1.970453143119812
Validation loss: 2.084106425444285

Epoch: 6| Step: 9
Training loss: 2.209148406982422
Validation loss: 2.0473138093948364

Epoch: 6| Step: 10
Training loss: 2.29774808883667
Validation loss: 2.0494116147359214

Epoch: 6| Step: 11
Training loss: 2.384613275527954
Validation loss: 2.042089581489563

Epoch: 6| Step: 12
Training loss: 1.2469744682312012
Validation loss: 2.1077866156895957

Epoch: 6| Step: 13
Training loss: 2.0619330406188965
Validation loss: 2.029032548268636

Epoch: 52| Step: 0
Training loss: 1.8105133771896362
Validation loss: 2.171586016813914

Epoch: 6| Step: 1
Training loss: 1.2704873085021973
Validation loss: 2.086235264937083

Epoch: 6| Step: 2
Training loss: 2.1863083839416504
Validation loss: 2.0612340370814004

Epoch: 6| Step: 3
Training loss: 2.1789050102233887
Validation loss: 2.094229817390442

Epoch: 6| Step: 4
Training loss: 2.378777027130127
Validation loss: 2.0706390341122947

Epoch: 6| Step: 5
Training loss: 1.5425148010253906
Validation loss: 2.1061716278394065

Epoch: 6| Step: 6
Training loss: 2.1037709712982178
Validation loss: 2.065142552057902

Epoch: 6| Step: 7
Training loss: 1.628240942955017
Validation loss: 2.062802731990814

Epoch: 6| Step: 8
Training loss: 1.0617706775665283
Validation loss: 2.060252765814463

Epoch: 6| Step: 9
Training loss: 1.923589825630188
Validation loss: 2.0956098635991416

Epoch: 6| Step: 10
Training loss: 1.802958607673645
Validation loss: 2.080965439478556

Epoch: 6| Step: 11
Training loss: 1.9403659105300903
Validation loss: 2.0805425445238748

Epoch: 6| Step: 12
Training loss: 1.745821237564087
Validation loss: 1.979236940542857

Epoch: 6| Step: 13
Training loss: 1.5941355228424072
Validation loss: 2.034312347571055

Epoch: 53| Step: 0
Training loss: 1.829659104347229
Validation loss: 2.0529765685399375

Epoch: 6| Step: 1
Training loss: 2.1191256046295166
Validation loss: 2.0541992584864297

Epoch: 6| Step: 2
Training loss: 1.705431580543518
Validation loss: 2.055126110712687

Epoch: 6| Step: 3
Training loss: 1.4355101585388184
Validation loss: 2.048409581184387

Epoch: 6| Step: 4
Training loss: 1.855494737625122
Validation loss: 2.0703518191973367

Epoch: 6| Step: 5
Training loss: 1.5922213792800903
Validation loss: 2.0575432578722634

Epoch: 6| Step: 6
Training loss: 1.905522108078003
Validation loss: 2.0265219807624817

Epoch: 6| Step: 7
Training loss: 2.423271417617798
Validation loss: 2.083439350128174

Epoch: 6| Step: 8
Training loss: 2.1955318450927734
Validation loss: 2.0989736914634705

Epoch: 6| Step: 9
Training loss: 2.325899600982666
Validation loss: 2.1215673685073853

Epoch: 6| Step: 10
Training loss: 1.9939684867858887
Validation loss: 2.1209169824918113

Epoch: 6| Step: 11
Training loss: 2.0456957817077637
Validation loss: 2.1141921877861023

Epoch: 6| Step: 12
Training loss: 1.3117413520812988
Validation loss: 2.0672412713368735

Epoch: 6| Step: 13
Training loss: 1.7897084951400757
Validation loss: 2.057486613591512

Epoch: 54| Step: 0
Training loss: 1.2136130332946777
Validation loss: 2.0965778827667236

Epoch: 6| Step: 1
Training loss: 1.8152152299880981
Validation loss: 2.075877547264099

Epoch: 6| Step: 2
Training loss: 1.428218126296997
Validation loss: 2.0451783537864685

Epoch: 6| Step: 3
Training loss: 1.9351531267166138
Validation loss: 2.0854168931643167

Epoch: 6| Step: 4
Training loss: 1.7963494062423706
Validation loss: 1.9977168043454487

Epoch: 6| Step: 5
Training loss: 1.781196117401123
Validation loss: 2.0692835450172424

Epoch: 6| Step: 6
Training loss: 2.334528923034668
Validation loss: 2.0697343349456787

Epoch: 6| Step: 7
Training loss: 1.5998680591583252
Validation loss: 2.0375239054361978

Epoch: 6| Step: 8
Training loss: 1.4073097705841064
Validation loss: 2.0567060510317483

Epoch: 6| Step: 9
Training loss: 2.4361188411712646
Validation loss: 2.0682213306427

Epoch: 6| Step: 10
Training loss: 2.1952993869781494
Validation loss: 2.025853455066681

Epoch: 6| Step: 11
Training loss: 2.380452871322632
Validation loss: 2.0584137241045632

Epoch: 6| Step: 12
Training loss: 1.7908525466918945
Validation loss: 2.082941710948944

Epoch: 6| Step: 13
Training loss: 1.2007311582565308
Validation loss: 2.0640413959821067

Epoch: 55| Step: 0
Training loss: 1.5643941164016724
Validation loss: 2.0500859022140503

Epoch: 6| Step: 1
Training loss: 2.0410356521606445
Validation loss: 2.0556631286938987

Epoch: 6| Step: 2
Training loss: 1.6703457832336426
Validation loss: 2.023792028427124

Epoch: 6| Step: 3
Training loss: 1.1411292552947998
Validation loss: 2.053159713745117

Epoch: 6| Step: 4
Training loss: 2.2725818157196045
Validation loss: 2.075713634490967

Epoch: 6| Step: 5
Training loss: 1.8764084577560425
Validation loss: 2.061281681060791

Epoch: 6| Step: 6
Training loss: 1.5557010173797607
Validation loss: 2.046038031578064

Epoch: 6| Step: 7
Training loss: 1.4891822338104248
Validation loss: 2.0668681859970093

Epoch: 6| Step: 8
Training loss: 2.173793315887451
Validation loss: 2.061905801296234

Epoch: 6| Step: 9
Training loss: 1.8208755254745483
Validation loss: 2.0729386607805886

Epoch: 6| Step: 10
Training loss: 2.446104049682617
Validation loss: 2.1017061869303384

Epoch: 6| Step: 11
Training loss: 1.723899483680725
Validation loss: 2.0557161569595337

Epoch: 6| Step: 12
Training loss: 1.8659652471542358
Validation loss: 2.111167033513387

Epoch: 6| Step: 13
Training loss: 1.8173009157180786
Validation loss: 2.07742706934611

Epoch: 56| Step: 0
Training loss: 1.459431767463684
Validation loss: 2.077592611312866

Epoch: 6| Step: 1
Training loss: 1.7522990703582764
Validation loss: 2.065883000691732

Epoch: 6| Step: 2
Training loss: 1.6592321395874023
Validation loss: 2.0289814869562783

Epoch: 6| Step: 3
Training loss: 1.786943793296814
Validation loss: 2.059032221635183

Epoch: 6| Step: 4
Training loss: 2.236703872680664
Validation loss: 2.0479589700698853

Epoch: 6| Step: 5
Training loss: 1.5105077028274536
Validation loss: 2.075753132502238

Epoch: 6| Step: 6
Training loss: 1.1189566850662231
Validation loss: 2.0305909713109336

Epoch: 6| Step: 7
Training loss: 1.5082584619522095
Validation loss: 2.054921348889669

Epoch: 6| Step: 8
Training loss: 1.9948418140411377
Validation loss: 2.0531545678774514

Epoch: 6| Step: 9
Training loss: 2.347982406616211
Validation loss: 2.0376408298810325

Epoch: 6| Step: 10
Training loss: 1.8742101192474365
Validation loss: 2.0667213598887124

Epoch: 6| Step: 11
Training loss: 1.800689935684204
Validation loss: 2.0634926160176597

Epoch: 6| Step: 12
Training loss: 1.82413649559021
Validation loss: 2.0568665067354837

Epoch: 6| Step: 13
Training loss: 2.12724232673645
Validation loss: 2.0374918580055237

Epoch: 57| Step: 0
Training loss: 1.3146710395812988
Validation loss: 2.061560074488322

Epoch: 6| Step: 1
Training loss: 2.206023931503296
Validation loss: 2.055391252040863

Epoch: 6| Step: 2
Training loss: 1.5559062957763672
Validation loss: 2.0172044038772583

Epoch: 6| Step: 3
Training loss: 2.377917766571045
Validation loss: 2.048165420691172

Epoch: 6| Step: 4
Training loss: 1.2439229488372803
Validation loss: 2.0753902196884155

Epoch: 6| Step: 5
Training loss: 1.6501716375350952
Validation loss: 2.0492109855016074

Epoch: 6| Step: 6
Training loss: 1.5099611282348633
Validation loss: 2.0469210346539817

Epoch: 6| Step: 7
Training loss: 1.5556519031524658
Validation loss: 2.057383179664612

Epoch: 6| Step: 8
Training loss: 2.6422414779663086
Validation loss: 2.0225663781166077

Epoch: 6| Step: 9
Training loss: 1.6663150787353516
Validation loss: 2.020508050918579

Epoch: 6| Step: 10
Training loss: 1.5589303970336914
Validation loss: 2.077583154042562

Epoch: 6| Step: 11
Training loss: 1.8027122020721436
Validation loss: 2.084057033061981

Epoch: 6| Step: 12
Training loss: 1.6106743812561035
Validation loss: 2.070785880088806

Epoch: 6| Step: 13
Training loss: 2.589886426925659
Validation loss: 2.0518025358517966

Epoch: 58| Step: 0
Training loss: 1.5427371263504028
Validation loss: 2.0555582841237388

Epoch: 6| Step: 1
Training loss: 1.8705477714538574
Validation loss: 2.07929935057958

Epoch: 6| Step: 2
Training loss: 2.1076877117156982
Validation loss: 2.035999119281769

Epoch: 6| Step: 3
Training loss: 2.0608510971069336
Validation loss: 2.095945656299591

Epoch: 6| Step: 4
Training loss: 1.1845500469207764
Validation loss: 2.0970728000005088

Epoch: 6| Step: 5
Training loss: 1.8988265991210938
Validation loss: 2.0756057699521384

Epoch: 6| Step: 6
Training loss: 1.4738919734954834
Validation loss: 2.055185377597809

Epoch: 6| Step: 7
Training loss: 2.0512053966522217
Validation loss: 2.0434838930765786

Epoch: 6| Step: 8
Training loss: 1.813584804534912
Validation loss: 2.0590585271517434

Epoch: 6| Step: 9
Training loss: 0.864210307598114
Validation loss: 2.046124736467997

Epoch: 6| Step: 10
Training loss: 1.9703526496887207
Validation loss: 2.065271735191345

Epoch: 6| Step: 11
Training loss: 2.123943328857422
Validation loss: 1.9991533756256104

Epoch: 6| Step: 12
Training loss: 2.3765015602111816
Validation loss: 2.030346632003784

Epoch: 6| Step: 13
Training loss: 2.1180686950683594
Validation loss: 2.052432576815287

Epoch: 59| Step: 0
Training loss: 2.0617499351501465
Validation loss: 2.0580525000890098

Epoch: 6| Step: 1
Training loss: 2.2104101181030273
Validation loss: 2.012508730093638

Epoch: 6| Step: 2
Training loss: 1.1920076608657837
Validation loss: 2.0468446612358093

Epoch: 6| Step: 3
Training loss: 1.8860137462615967
Validation loss: 2.0417436957359314

Epoch: 6| Step: 4
Training loss: 1.6973932981491089
Validation loss: 2.0575371583302817

Epoch: 6| Step: 5
Training loss: 2.008408546447754
Validation loss: 2.081367333730062

Epoch: 6| Step: 6
Training loss: 1.5637993812561035
Validation loss: 2.0801106691360474

Epoch: 6| Step: 7
Training loss: 0.9158294796943665
Validation loss: 2.0737502376238504

Epoch: 6| Step: 8
Training loss: 1.3320788145065308
Validation loss: 2.1043709913889566

Epoch: 6| Step: 9
Training loss: 2.581300735473633
Validation loss: 2.0408585468928018

Epoch: 6| Step: 10
Training loss: 1.7643494606018066
Validation loss: 2.0756524006525674

Epoch: 6| Step: 11
Training loss: 1.5983805656433105
Validation loss: 2.0338141322135925

Epoch: 6| Step: 12
Training loss: 1.5526697635650635
Validation loss: 2.0823413530985513

Epoch: 6| Step: 13
Training loss: 2.2393674850463867
Validation loss: 2.0345460772514343

Epoch: 60| Step: 0
Training loss: 2.1692075729370117
Validation loss: 2.06381756067276

Epoch: 6| Step: 1
Training loss: 1.8010938167572021
Validation loss: 2.1009403268496194

Epoch: 6| Step: 2
Training loss: 1.3486143350601196
Validation loss: 2.082624316215515

Epoch: 6| Step: 3
Training loss: 2.1826119422912598
Validation loss: 2.0537293950716653

Epoch: 6| Step: 4
Training loss: 1.870956540107727
Validation loss: 2.0823206702868142

Epoch: 6| Step: 5
Training loss: 2.0559399127960205
Validation loss: 2.0737592776616416

Epoch: 6| Step: 6
Training loss: 1.751194715499878
Validation loss: 2.076327602068583

Epoch: 6| Step: 7
Training loss: 2.084076404571533
Validation loss: 2.0747861663500466

Epoch: 6| Step: 8
Training loss: 1.5538630485534668
Validation loss: 2.0266648729642234

Epoch: 6| Step: 9
Training loss: 1.980078101158142
Validation loss: 2.048642953236898

Epoch: 6| Step: 10
Training loss: 1.7441904544830322
Validation loss: 2.069147308667501

Epoch: 6| Step: 11
Training loss: 1.7217824459075928
Validation loss: 2.031367282072703

Epoch: 6| Step: 12
Training loss: 1.3100879192352295
Validation loss: 2.0383551319440207

Epoch: 6| Step: 13
Training loss: 1.6543471813201904
Validation loss: 2.0717748204867044

Epoch: 61| Step: 0
Training loss: 1.7012403011322021
Validation loss: 2.0621264378229776

Epoch: 6| Step: 1
Training loss: 2.0944089889526367
Validation loss: 2.0596967538197837

Epoch: 6| Step: 2
Training loss: 1.981453537940979
Validation loss: 2.0579923590024314

Epoch: 6| Step: 3
Training loss: 1.3745911121368408
Validation loss: 2.0636969804763794

Epoch: 6| Step: 4
Training loss: 2.1107311248779297
Validation loss: 2.0552395383516946

Epoch: 6| Step: 5
Training loss: 1.3109405040740967
Validation loss: 2.055146813392639

Epoch: 6| Step: 6
Training loss: 1.788426160812378
Validation loss: 2.072444260120392

Epoch: 6| Step: 7
Training loss: 1.3584365844726562
Validation loss: 2.0679978132247925

Epoch: 6| Step: 8
Training loss: 1.444146752357483
Validation loss: 2.0694146354993186

Epoch: 6| Step: 9
Training loss: 2.961202621459961
Validation loss: 2.0639238158861795

Epoch: 6| Step: 10
Training loss: 1.768196702003479
Validation loss: 2.042142331600189

Epoch: 6| Step: 11
Training loss: 1.8298721313476562
Validation loss: 2.082233428955078

Epoch: 6| Step: 12
Training loss: 1.5138111114501953
Validation loss: 2.0991440216700235

Epoch: 6| Step: 13
Training loss: 1.3657079935073853
Validation loss: 2.0404202143351235

Epoch: 62| Step: 0
Training loss: 1.9299392700195312
Validation loss: 2.064315378665924

Epoch: 6| Step: 1
Training loss: 1.3377082347869873
Validation loss: 2.0224886536598206

Epoch: 6| Step: 2
Training loss: 2.25791597366333
Validation loss: 2.0870763858159385

Epoch: 6| Step: 3
Training loss: 2.496894359588623
Validation loss: 2.1065341234207153

Epoch: 6| Step: 4
Training loss: 1.8634843826293945
Validation loss: 2.0512467424074807

Epoch: 6| Step: 5
Training loss: 1.763081431388855
Validation loss: 2.033506453037262

Epoch: 6| Step: 6
Training loss: 2.0324666500091553
Validation loss: 2.0702202916145325

Epoch: 6| Step: 7
Training loss: 1.4732167720794678
Validation loss: 2.050673246383667

Epoch: 6| Step: 8
Training loss: 1.7699973583221436
Validation loss: 2.0703043142954507

Epoch: 6| Step: 9
Training loss: 1.5420002937316895
Validation loss: 2.0638798077901206

Epoch: 6| Step: 10
Training loss: 1.554789662361145
Validation loss: 2.094106912612915

Epoch: 6| Step: 11
Training loss: 1.5208399295806885
Validation loss: 2.060817837715149

Epoch: 6| Step: 12
Training loss: 0.9343516826629639
Validation loss: 2.0977203249931335

Epoch: 6| Step: 13
Training loss: 2.035463809967041
Validation loss: 2.0591375827789307

Epoch: 63| Step: 0
Training loss: 1.733079195022583
Validation loss: 2.0839805603027344

Epoch: 6| Step: 1
Training loss: 1.3649872541427612
Validation loss: 2.053700884183248

Epoch: 6| Step: 2
Training loss: 1.53621244430542
Validation loss: 2.0612414280573526

Epoch: 6| Step: 3
Training loss: 1.6289485692977905
Validation loss: 2.0407610535621643

Epoch: 6| Step: 4
Training loss: 1.756152629852295
Validation loss: 2.075734774271647

Epoch: 6| Step: 5
Training loss: 1.573742151260376
Validation loss: 2.0558433334032693

Epoch: 6| Step: 6
Training loss: 1.5380921363830566
Validation loss: 2.04395725329717

Epoch: 6| Step: 7
Training loss: 1.3740884065628052
Validation loss: 2.067891856034597

Epoch: 6| Step: 8
Training loss: 2.235579490661621
Validation loss: 2.0533899664878845

Epoch: 6| Step: 9
Training loss: 2.868337631225586
Validation loss: 2.0224496722221375

Epoch: 6| Step: 10
Training loss: 1.9611369371414185
Validation loss: 2.0219878554344177

Epoch: 6| Step: 11
Training loss: 2.0958261489868164
Validation loss: 2.056988020737966

Epoch: 6| Step: 12
Training loss: 1.711548089981079
Validation loss: 2.070311745007833

Epoch: 6| Step: 13
Training loss: 1.347692847251892
Validation loss: 2.0565057396888733

Epoch: 64| Step: 0
Training loss: 2.6095032691955566
Validation loss: 2.0670747558275857

Epoch: 6| Step: 1
Training loss: 1.3688654899597168
Validation loss: 2.0695984760920205

Epoch: 6| Step: 2
Training loss: 1.7859644889831543
Validation loss: 2.0716326236724854

Epoch: 6| Step: 3
Training loss: 1.369511365890503
Validation loss: 2.090767284234365

Epoch: 6| Step: 4
Training loss: 1.479163646697998
Validation loss: 2.0408833424250283

Epoch: 6| Step: 5
Training loss: 2.337766647338867
Validation loss: 2.0636982520421348

Epoch: 6| Step: 6
Training loss: 1.7057470083236694
Validation loss: 2.076511005560557

Epoch: 6| Step: 7
Training loss: 2.234492540359497
Validation loss: 2.054082771142324

Epoch: 6| Step: 8
Training loss: 1.6346665620803833
Validation loss: 2.0883285204569497

Epoch: 6| Step: 9
Training loss: 1.7590830326080322
Validation loss: 2.0151996413866677

Epoch: 6| Step: 10
Training loss: 2.0233898162841797
Validation loss: 2.071558733781179

Epoch: 6| Step: 11
Training loss: 0.9129728078842163
Validation loss: 2.0568612813949585

Epoch: 6| Step: 12
Training loss: 1.3652278184890747
Validation loss: 2.0674094359079995

Epoch: 6| Step: 13
Training loss: 1.7146449089050293
Validation loss: 2.089230000972748

Epoch: 65| Step: 0
Training loss: 1.3736045360565186
Validation loss: 2.0858529011408486

Epoch: 6| Step: 1
Training loss: 2.1462559700012207
Validation loss: 2.078010002772013

Epoch: 6| Step: 2
Training loss: 1.6799310445785522
Validation loss: 2.1041218638420105

Epoch: 6| Step: 3
Training loss: 1.338371753692627
Validation loss: 2.102982779343923

Epoch: 6| Step: 4
Training loss: 2.0101773738861084
Validation loss: 2.090640127658844

Epoch: 6| Step: 5
Training loss: 1.918730616569519
Validation loss: 2.068255921204885

Epoch: 6| Step: 6
Training loss: 1.7043460607528687
Validation loss: 2.071669061978658

Epoch: 6| Step: 7
Training loss: 1.4378548860549927
Validation loss: 2.0311755736668906

Epoch: 6| Step: 8
Training loss: 1.5508031845092773
Validation loss: 2.0196030338605246

Epoch: 6| Step: 9
Training loss: 2.177948474884033
Validation loss: 2.0444783171017966

Epoch: 6| Step: 10
Training loss: 1.7868748903274536
Validation loss: 2.0726015170415244

Epoch: 6| Step: 11
Training loss: 1.6212635040283203
Validation loss: 2.064079244931539

Epoch: 6| Step: 12
Training loss: 1.839582085609436
Validation loss: 2.090331474939982

Epoch: 6| Step: 13
Training loss: 2.022477388381958
Validation loss: 2.0849562883377075

Epoch: 66| Step: 0
Training loss: 1.6386048793792725
Validation loss: 2.0546693404515586

Epoch: 6| Step: 1
Training loss: 1.5706000328063965
Validation loss: 2.0555164416631064

Epoch: 6| Step: 2
Training loss: 2.117330312728882
Validation loss: 2.0408066511154175

Epoch: 6| Step: 3
Training loss: 1.5506304502487183
Validation loss: 2.0500469406445823

Epoch: 6| Step: 4
Training loss: 2.658583402633667
Validation loss: 2.060158610343933

Epoch: 6| Step: 5
Training loss: 1.9023863077163696
Validation loss: 2.1157276233037314

Epoch: 6| Step: 6
Training loss: 1.6507229804992676
Validation loss: 2.1065089106559753

Epoch: 6| Step: 7
Training loss: 2.1626391410827637
Validation loss: 2.087133765220642

Epoch: 6| Step: 8
Training loss: 1.5019989013671875
Validation loss: 2.0853710770606995

Epoch: 6| Step: 9
Training loss: 0.8411701917648315
Validation loss: 2.08243860801061

Epoch: 6| Step: 10
Training loss: 1.5779221057891846
Validation loss: 2.049627741177877

Epoch: 6| Step: 11
Training loss: 1.4982848167419434
Validation loss: 2.067541261514028

Epoch: 6| Step: 12
Training loss: 2.023345470428467
Validation loss: 2.0336151917775473

Epoch: 6| Step: 13
Training loss: 1.7598375082015991
Validation loss: 2.034031649430593

Epoch: 67| Step: 0
Training loss: 2.0443406105041504
Validation loss: 2.035110672314962

Epoch: 6| Step: 1
Training loss: 1.3786358833312988
Validation loss: 2.041567107041677

Epoch: 6| Step: 2
Training loss: 1.8960175514221191
Validation loss: 2.0651757518450418

Epoch: 6| Step: 3
Training loss: 1.0712863206863403
Validation loss: 2.0125915010770163

Epoch: 6| Step: 4
Training loss: 1.1648577451705933
Validation loss: 2.037526329358419

Epoch: 6| Step: 5
Training loss: 1.495750904083252
Validation loss: 2.0422075589497886

Epoch: 6| Step: 6
Training loss: 1.46211838722229
Validation loss: 2.054414172967275

Epoch: 6| Step: 7
Training loss: 2.161050796508789
Validation loss: 2.0846826632817588

Epoch: 6| Step: 8
Training loss: 2.0618064403533936
Validation loss: 2.0487716794013977

Epoch: 6| Step: 9
Training loss: 1.7752337455749512
Validation loss: 2.047426998615265

Epoch: 6| Step: 10
Training loss: 1.6556949615478516
Validation loss: 2.0720750292142234

Epoch: 6| Step: 11
Training loss: 2.1660804748535156
Validation loss: 2.0802970131238303

Epoch: 6| Step: 12
Training loss: 1.9637428522109985
Validation loss: 2.0648731191953025

Epoch: 6| Step: 13
Training loss: 1.8068033456802368
Validation loss: 2.0694467425346375

Epoch: 68| Step: 0
Training loss: 2.0683860778808594
Validation loss: 2.048162559668223

Epoch: 6| Step: 1
Training loss: 2.0915846824645996
Validation loss: 2.0350977977116904

Epoch: 6| Step: 2
Training loss: 1.3765013217926025
Validation loss: 2.0648555358250937

Epoch: 6| Step: 3
Training loss: 1.7333165407180786
Validation loss: 2.05325847864151

Epoch: 6| Step: 4
Training loss: 0.9913479089736938
Validation loss: 2.016284247239431

Epoch: 6| Step: 5
Training loss: 1.6452298164367676
Validation loss: 2.061015566190084

Epoch: 6| Step: 6
Training loss: 1.8920950889587402
Validation loss: 2.085396190484365

Epoch: 6| Step: 7
Training loss: 1.8005837202072144
Validation loss: 2.0629673997561135

Epoch: 6| Step: 8
Training loss: 1.9194927215576172
Validation loss: 2.029204030831655

Epoch: 6| Step: 9
Training loss: 1.75130033493042
Validation loss: 2.0548338492711387

Epoch: 6| Step: 10
Training loss: 1.5617883205413818
Validation loss: 2.0804778337478638

Epoch: 6| Step: 11
Training loss: 1.834930181503296
Validation loss: 2.047243078549703

Epoch: 6| Step: 12
Training loss: 1.8323419094085693
Validation loss: 2.050160904725393

Epoch: 6| Step: 13
Training loss: 1.1541032791137695
Validation loss: 2.043278376261393

Epoch: 69| Step: 0
Training loss: 2.1506729125976562
Validation loss: 2.106048027674357

Epoch: 6| Step: 1
Training loss: 1.5373094081878662
Validation loss: 2.074753999710083

Epoch: 6| Step: 2
Training loss: 1.721612572669983
Validation loss: 2.0783263444900513

Epoch: 6| Step: 3
Training loss: 1.8341431617736816
Validation loss: 2.095689833164215

Epoch: 6| Step: 4
Training loss: 1.172485589981079
Validation loss: 2.066249668598175

Epoch: 6| Step: 5
Training loss: 2.0859668254852295
Validation loss: 2.0578360557556152

Epoch: 6| Step: 6
Training loss: 1.8155527114868164
Validation loss: 2.0899274746576944

Epoch: 6| Step: 7
Training loss: 1.5697035789489746
Validation loss: 2.0245121320088706

Epoch: 6| Step: 8
Training loss: 1.5797832012176514
Validation loss: 2.0532556970914206

Epoch: 6| Step: 9
Training loss: 2.0310254096984863
Validation loss: 2.0578505794207254

Epoch: 6| Step: 10
Training loss: 1.5952696800231934
Validation loss: 2.082936962445577

Epoch: 6| Step: 11
Training loss: 1.0669124126434326
Validation loss: 2.0447934667269387

Epoch: 6| Step: 12
Training loss: 1.4479613304138184
Validation loss: 2.0996395349502563

Epoch: 6| Step: 13
Training loss: 2.1879055500030518
Validation loss: 2.0922321677207947

Epoch: 70| Step: 0
Training loss: 2.078949451446533
Validation loss: 2.0892643133799234

Epoch: 6| Step: 1
Training loss: 1.708687663078308
Validation loss: 2.078712304433187

Epoch: 6| Step: 2
Training loss: 1.7865488529205322
Validation loss: 2.0564120411872864

Epoch: 6| Step: 3
Training loss: 1.5024480819702148
Validation loss: 2.0614772836367288

Epoch: 6| Step: 4
Training loss: 1.5701576471328735
Validation loss: 2.1057382424672446

Epoch: 6| Step: 5
Training loss: 1.5092129707336426
Validation loss: 2.0616000493367515

Epoch: 6| Step: 6
Training loss: 1.5311293601989746
Validation loss: 2.0831867456436157

Epoch: 6| Step: 7
Training loss: 1.719404697418213
Validation loss: 2.020189086596171

Epoch: 6| Step: 8
Training loss: 1.6687073707580566
Validation loss: 2.026122589906057

Epoch: 6| Step: 9
Training loss: 2.0739593505859375
Validation loss: 2.0319082736968994

Epoch: 6| Step: 10
Training loss: 1.4303277730941772
Validation loss: 2.0679033398628235

Epoch: 6| Step: 11
Training loss: 1.3897349834442139
Validation loss: 2.103424688180288

Epoch: 6| Step: 12
Training loss: 2.073823928833008
Validation loss: 2.0548909107844033

Epoch: 6| Step: 13
Training loss: 1.4577081203460693
Validation loss: 2.0404140750567117

Epoch: 71| Step: 0
Training loss: 1.516053318977356
Validation loss: 2.092033803462982

Epoch: 6| Step: 1
Training loss: 1.57377290725708
Validation loss: 2.1073146065076194

Epoch: 6| Step: 2
Training loss: 1.083260416984558
Validation loss: 2.056186238924662

Epoch: 6| Step: 3
Training loss: 2.000368118286133
Validation loss: 2.0585111379623413

Epoch: 6| Step: 4
Training loss: 2.046215057373047
Validation loss: 2.0365702708562217

Epoch: 6| Step: 5
Training loss: 1.6387633085250854
Validation loss: 2.0748149156570435

Epoch: 6| Step: 6
Training loss: 1.8658437728881836
Validation loss: 2.1283615628878274

Epoch: 6| Step: 7
Training loss: 1.2496892213821411
Validation loss: 2.0709282954533896

Epoch: 6| Step: 8
Training loss: 2.1927151679992676
Validation loss: 2.0496124029159546

Epoch: 6| Step: 9
Training loss: 1.9872915744781494
Validation loss: 2.0714244842529297

Epoch: 6| Step: 10
Training loss: 1.4195520877838135
Validation loss: 2.1133042573928833

Epoch: 6| Step: 11
Training loss: 2.0434470176696777
Validation loss: 2.049289643764496

Epoch: 6| Step: 12
Training loss: 1.1477069854736328
Validation loss: 2.0510169665018716

Epoch: 6| Step: 13
Training loss: 1.5435099601745605
Validation loss: 2.0567646622657776

Epoch: 72| Step: 0
Training loss: 1.4989635944366455
Validation loss: 2.0621339678764343

Epoch: 6| Step: 1
Training loss: 1.5980985164642334
Validation loss: 2.0953120589256287

Epoch: 6| Step: 2
Training loss: 1.3934650421142578
Validation loss: 2.036942720413208

Epoch: 6| Step: 3
Training loss: 1.8392428159713745
Validation loss: 2.072647968928019

Epoch: 6| Step: 4
Training loss: 1.8659206628799438
Validation loss: 2.077368120352427

Epoch: 6| Step: 5
Training loss: 1.791860818862915
Validation loss: 2.061352709929148

Epoch: 6| Step: 6
Training loss: 2.0177977085113525
Validation loss: 2.0816542506217957

Epoch: 6| Step: 7
Training loss: 1.662898063659668
Validation loss: 2.057948807875315

Epoch: 6| Step: 8
Training loss: 1.6570155620574951
Validation loss: 2.0166767040888467

Epoch: 6| Step: 9
Training loss: 1.1432334184646606
Validation loss: 2.0857720176378884

Epoch: 6| Step: 10
Training loss: 1.2908167839050293
Validation loss: 2.0427972873051963

Epoch: 6| Step: 11
Training loss: 2.0798845291137695
Validation loss: 2.028359810511271

Epoch: 6| Step: 12
Training loss: 1.8348699808120728
Validation loss: 2.1005011399586997

Epoch: 6| Step: 13
Training loss: 1.2217128276824951
Validation loss: 2.059685488541921

Epoch: 73| Step: 0
Training loss: 1.7162343263626099
Validation loss: 2.0588572025299072

Epoch: 6| Step: 1
Training loss: 1.5054192543029785
Validation loss: 2.051632046699524

Epoch: 6| Step: 2
Training loss: 1.4716269969940186
Validation loss: 2.0659475922584534

Epoch: 6| Step: 3
Training loss: 1.3393993377685547
Validation loss: 2.0748507380485535

Epoch: 6| Step: 4
Training loss: 1.7070775032043457
Validation loss: 2.0748365918795266

Epoch: 6| Step: 5
Training loss: 2.356400489807129
Validation loss: 2.077385405699412

Epoch: 6| Step: 6
Training loss: 1.96400785446167
Validation loss: 2.0933894316355386

Epoch: 6| Step: 7
Training loss: 1.0322504043579102
Validation loss: 2.0842736760775247

Epoch: 6| Step: 8
Training loss: 1.799988031387329
Validation loss: 2.0752603809038797

Epoch: 6| Step: 9
Training loss: 1.9425867795944214
Validation loss: 2.044480284055074

Epoch: 6| Step: 10
Training loss: 2.1683952808380127
Validation loss: 2.074957311153412

Epoch: 6| Step: 11
Training loss: 1.5760947465896606
Validation loss: 2.084757447242737

Epoch: 6| Step: 12
Training loss: 1.4591898918151855
Validation loss: 2.0908475716908774

Epoch: 6| Step: 13
Training loss: 1.4327657222747803
Validation loss: 2.0610488653182983

Epoch: 74| Step: 0
Training loss: 2.0124502182006836
Validation loss: 2.073246697584788

Epoch: 6| Step: 1
Training loss: 2.34785795211792
Validation loss: 2.0989971359570823

Epoch: 6| Step: 2
Training loss: 1.5256346464157104
Validation loss: 2.0621965328852334

Epoch: 6| Step: 3
Training loss: 1.797749400138855
Validation loss: 2.0771523118019104

Epoch: 6| Step: 4
Training loss: 1.35009765625
Validation loss: 2.072256068388621

Epoch: 6| Step: 5
Training loss: 1.523495078086853
Validation loss: 2.042214651902517

Epoch: 6| Step: 6
Training loss: 1.7152135372161865
Validation loss: 2.038204252719879

Epoch: 6| Step: 7
Training loss: 1.5853794813156128
Validation loss: 2.050094207127889

Epoch: 6| Step: 8
Training loss: 1.9464468955993652
Validation loss: 2.1037548383076987

Epoch: 6| Step: 9
Training loss: 1.9113045930862427
Validation loss: 2.09059468905131

Epoch: 6| Step: 10
Training loss: 1.2848620414733887
Validation loss: 2.0999648372332254

Epoch: 6| Step: 11
Training loss: 1.4017847776412964
Validation loss: 2.154234230518341

Epoch: 6| Step: 12
Training loss: 1.8976585865020752
Validation loss: 2.0920832554499307

Epoch: 6| Step: 13
Training loss: 1.3637683391571045
Validation loss: 2.0707192023595176

Epoch: 75| Step: 0
Training loss: 1.0967192649841309
Validation loss: 2.097518881162008

Epoch: 6| Step: 1
Training loss: 2.04441237449646
Validation loss: 2.080417593320211

Epoch: 6| Step: 2
Training loss: 1.7072033882141113
Validation loss: 2.065501113732656

Epoch: 6| Step: 3
Training loss: 2.0017659664154053
Validation loss: 2.0566741625467935

Epoch: 6| Step: 4
Training loss: 1.6150763034820557
Validation loss: 2.0400628050168357

Epoch: 6| Step: 5
Training loss: 1.6702332496643066
Validation loss: 2.078666547934214

Epoch: 6| Step: 6
Training loss: 1.479835033416748
Validation loss: 2.049125909805298

Epoch: 6| Step: 7
Training loss: 1.6841442584991455
Validation loss: 2.0332668821016946

Epoch: 6| Step: 8
Training loss: 1.7834584712982178
Validation loss: 2.086464583873749

Epoch: 6| Step: 9
Training loss: 2.1011056900024414
Validation loss: 2.0096665819485984

Epoch: 6| Step: 10
Training loss: 1.8952851295471191
Validation loss: 2.0140245159467063

Epoch: 6| Step: 11
Training loss: 1.8477447032928467
Validation loss: 2.044910113016764

Epoch: 6| Step: 12
Training loss: 1.1823163032531738
Validation loss: 2.0797621409098306

Epoch: 6| Step: 13
Training loss: 1.3314266204833984
Validation loss: 2.077978273232778

Epoch: 76| Step: 0
Training loss: 1.8903541564941406
Validation loss: 2.0644095738728843

Epoch: 6| Step: 1
Training loss: 1.475640892982483
Validation loss: 2.0874399145444236

Epoch: 6| Step: 2
Training loss: 1.9246165752410889
Validation loss: 2.111348569393158

Epoch: 6| Step: 3
Training loss: 1.6465575695037842
Validation loss: 2.09698748588562

Epoch: 6| Step: 4
Training loss: 1.741645336151123
Validation loss: 2.124893307685852

Epoch: 6| Step: 5
Training loss: 1.749914288520813
Validation loss: 2.1117363572120667

Epoch: 6| Step: 6
Training loss: 2.168929100036621
Validation loss: 2.0847801168759665

Epoch: 6| Step: 7
Training loss: 1.396669626235962
Validation loss: 2.05220627784729

Epoch: 6| Step: 8
Training loss: 1.586496114730835
Validation loss: 2.035528302192688

Epoch: 6| Step: 9
Training loss: 1.4501984119415283
Validation loss: 2.0974172353744507

Epoch: 6| Step: 10
Training loss: 1.8421598672866821
Validation loss: 2.093498249848684

Epoch: 6| Step: 11
Training loss: 1.160620927810669
Validation loss: 2.09434445699056

Epoch: 6| Step: 12
Training loss: 1.4242695569992065
Validation loss: 2.1024160186449685

Epoch: 6| Step: 13
Training loss: 1.8139843940734863
Validation loss: 2.018010139465332

Epoch: 77| Step: 0
Training loss: 1.4653749465942383
Validation loss: 2.076461990674337

Epoch: 6| Step: 1
Training loss: 1.5279216766357422
Validation loss: 2.0536144375801086

Epoch: 6| Step: 2
Training loss: 2.0109097957611084
Validation loss: 2.056350588798523

Epoch: 6| Step: 3
Training loss: 2.326768398284912
Validation loss: 2.0543574889500937

Epoch: 6| Step: 4
Training loss: 1.6554267406463623
Validation loss: 2.071736911932627

Epoch: 6| Step: 5
Training loss: 1.3869044780731201
Validation loss: 2.061273455619812

Epoch: 6| Step: 6
Training loss: 1.6557979583740234
Validation loss: 2.0433210929234824

Epoch: 6| Step: 7
Training loss: 1.8261018991470337
Validation loss: 2.049768884976705

Epoch: 6| Step: 8
Training loss: 1.6787461042404175
Validation loss: 2.0530981024106345

Epoch: 6| Step: 9
Training loss: 1.2366104125976562
Validation loss: 2.019305864969889

Epoch: 6| Step: 10
Training loss: 1.9691376686096191
Validation loss: 2.071097413698832

Epoch: 6| Step: 11
Training loss: 1.2836644649505615
Validation loss: 2.0917880137761435

Epoch: 6| Step: 12
Training loss: 2.08950138092041
Validation loss: 2.094864845275879

Epoch: 6| Step: 13
Training loss: 1.0340313911437988
Validation loss: 2.0819496313730874

Epoch: 78| Step: 0
Training loss: 1.8727548122406006
Validation loss: 2.08694597085317

Epoch: 6| Step: 1
Training loss: 1.8579585552215576
Validation loss: 2.0641336838404336

Epoch: 6| Step: 2
Training loss: 1.2833256721496582
Validation loss: 2.056467056274414

Epoch: 6| Step: 3
Training loss: 1.557100534439087
Validation loss: 2.0778041879336038

Epoch: 6| Step: 4
Training loss: 1.4336034059524536
Validation loss: 2.055654009183248

Epoch: 6| Step: 5
Training loss: 1.3819299936294556
Validation loss: 2.0229692657788596

Epoch: 6| Step: 6
Training loss: 1.3953461647033691
Validation loss: 2.0514239072799683

Epoch: 6| Step: 7
Training loss: 2.5404396057128906
Validation loss: 2.0475578705469766

Epoch: 6| Step: 8
Training loss: 1.9476358890533447
Validation loss: 2.0490123430887857

Epoch: 6| Step: 9
Training loss: 1.599552035331726
Validation loss: 2.00769050916036

Epoch: 6| Step: 10
Training loss: 1.4889013767242432
Validation loss: 2.0682045817375183

Epoch: 6| Step: 11
Training loss: 1.7357388734817505
Validation loss: 2.0597092509269714

Epoch: 6| Step: 12
Training loss: 1.617361307144165
Validation loss: 2.044533908367157

Epoch: 6| Step: 13
Training loss: 1.1574865579605103
Validation loss: 2.074229975541433

Epoch: 79| Step: 0
Training loss: 1.948045253753662
Validation loss: 2.125091274579366

Epoch: 6| Step: 1
Training loss: 1.467127799987793
Validation loss: 2.0893874764442444

Epoch: 6| Step: 2
Training loss: 1.8699053525924683
Validation loss: 2.0524616638819375

Epoch: 6| Step: 3
Training loss: 1.3119431734085083
Validation loss: 2.085684816042582

Epoch: 6| Step: 4
Training loss: 1.3307149410247803
Validation loss: 2.0835235118865967

Epoch: 6| Step: 5
Training loss: 1.8400949239730835
Validation loss: 2.095020870367686

Epoch: 6| Step: 6
Training loss: 1.334542155265808
Validation loss: 2.0512632528940835

Epoch: 6| Step: 7
Training loss: 2.4508275985717773
Validation loss: 2.0591928958892822

Epoch: 6| Step: 8
Training loss: 1.2435578107833862
Validation loss: 2.054213205973307

Epoch: 6| Step: 9
Training loss: 0.9966466426849365
Validation loss: 2.0677637259165444

Epoch: 6| Step: 10
Training loss: 1.9113417863845825
Validation loss: 2.038445512453715

Epoch: 6| Step: 11
Training loss: 1.7287286520004272
Validation loss: 2.0228888988494873

Epoch: 6| Step: 12
Training loss: 1.6484824419021606
Validation loss: 2.048219402631124

Epoch: 6| Step: 13
Training loss: 1.437462568283081
Validation loss: 2.0357934633890786

Epoch: 80| Step: 0
Training loss: 1.6674282550811768
Validation loss: 2.0563121835390725

Epoch: 6| Step: 1
Training loss: 1.818474292755127
Validation loss: 2.053334136803945

Epoch: 6| Step: 2
Training loss: 1.8936033248901367
Validation loss: 2.021130839983622

Epoch: 6| Step: 3
Training loss: 1.7138392925262451
Validation loss: 2.0580628911654153

Epoch: 6| Step: 4
Training loss: 1.6671597957611084
Validation loss: 2.0768872499465942

Epoch: 6| Step: 5
Training loss: 1.551369547843933
Validation loss: 2.0644536217053733

Epoch: 6| Step: 6
Training loss: 1.273246169090271
Validation loss: 2.0883724093437195

Epoch: 6| Step: 7
Training loss: 1.729527473449707
Validation loss: 2.094483653704325

Epoch: 6| Step: 8
Training loss: 1.13398015499115
Validation loss: 2.0923728346824646

Epoch: 6| Step: 9
Training loss: 1.5547552108764648
Validation loss: 2.1346263885498047

Epoch: 6| Step: 10
Training loss: 1.4175022840499878
Validation loss: 2.071902056535085

Epoch: 6| Step: 11
Training loss: 1.425486445426941
Validation loss: 2.119978944460551

Epoch: 6| Step: 12
Training loss: 1.6348321437835693
Validation loss: 2.110243042310079

Epoch: 6| Step: 13
Training loss: 2.0843844413757324
Validation loss: 2.050934632619222

Epoch: 81| Step: 0
Training loss: 1.2787508964538574
Validation loss: 2.069253067175547

Epoch: 6| Step: 1
Training loss: 1.5279860496520996
Validation loss: 2.048668464024862

Epoch: 6| Step: 2
Training loss: 1.1555206775665283
Validation loss: 2.071604589621226

Epoch: 6| Step: 3
Training loss: 1.829763650894165
Validation loss: 2.0219019254048667

Epoch: 6| Step: 4
Training loss: 1.6193263530731201
Validation loss: 2.0470934907595315

Epoch: 6| Step: 5
Training loss: 1.9066517353057861
Validation loss: 2.003264009952545

Epoch: 6| Step: 6
Training loss: 1.439920425415039
Validation loss: 2.0502018332481384

Epoch: 6| Step: 7
Training loss: 1.9223566055297852
Validation loss: 2.079915146032969

Epoch: 6| Step: 8
Training loss: 1.2872289419174194
Validation loss: 2.078940729300181

Epoch: 6| Step: 9
Training loss: 1.3060022592544556
Validation loss: 2.0987432400385537

Epoch: 6| Step: 10
Training loss: 1.5339019298553467
Validation loss: 2.0471524794896445

Epoch: 6| Step: 11
Training loss: 1.9040355682373047
Validation loss: 2.1165731549263

Epoch: 6| Step: 12
Training loss: 1.8808118104934692
Validation loss: 2.1021855076154075

Epoch: 6| Step: 13
Training loss: 1.9085471630096436
Validation loss: 2.0422722697257996

Epoch: 82| Step: 0
Training loss: 1.2803974151611328
Validation loss: 2.092812736829122

Epoch: 6| Step: 1
Training loss: 1.8713020086288452
Validation loss: 2.055530369281769

Epoch: 6| Step: 2
Training loss: 2.1628007888793945
Validation loss: 2.062303105990092

Epoch: 6| Step: 3
Training loss: 1.9799268245697021
Validation loss: 2.0496605038642883

Epoch: 6| Step: 4
Training loss: 1.397071361541748
Validation loss: 2.04841019709905

Epoch: 6| Step: 5
Training loss: 1.439831018447876
Validation loss: 2.0471824208895364

Epoch: 6| Step: 6
Training loss: 2.124054431915283
Validation loss: 2.046573261419932

Epoch: 6| Step: 7
Training loss: 1.379009485244751
Validation loss: 2.094143271446228

Epoch: 6| Step: 8
Training loss: 1.6874725818634033
Validation loss: 2.077054182688395

Epoch: 6| Step: 9
Training loss: 1.3386893272399902
Validation loss: 2.088492691516876

Epoch: 6| Step: 10
Training loss: 1.6455835103988647
Validation loss: 2.047564685344696

Epoch: 6| Step: 11
Training loss: 1.5412640571594238
Validation loss: 2.093900283177694

Epoch: 6| Step: 12
Training loss: 1.5972472429275513
Validation loss: 2.0778353412946067

Epoch: 6| Step: 13
Training loss: 1.0557916164398193
Validation loss: 2.075654923915863

Epoch: 83| Step: 0
Training loss: 1.7120747566223145
Validation loss: 2.1050044099489846

Epoch: 6| Step: 1
Training loss: 1.9508206844329834
Validation loss: 2.0622998476028442

Epoch: 6| Step: 2
Training loss: 2.178536891937256
Validation loss: 2.0683340032895408

Epoch: 6| Step: 3
Training loss: 0.8017327189445496
Validation loss: 2.1317585706710815

Epoch: 6| Step: 4
Training loss: 1.2941097021102905
Validation loss: 2.0960680842399597

Epoch: 6| Step: 5
Training loss: 1.6813170909881592
Validation loss: 2.0536677638689675

Epoch: 6| Step: 6
Training loss: 2.301626205444336
Validation loss: 2.066964606444041

Epoch: 6| Step: 7
Training loss: 1.3705120086669922
Validation loss: 2.0294760862986245

Epoch: 6| Step: 8
Training loss: 1.6790542602539062
Validation loss: 2.0750229557355246

Epoch: 6| Step: 9
Training loss: 1.6268459558486938
Validation loss: 2.0534939567248025

Epoch: 6| Step: 10
Training loss: 1.4332835674285889
Validation loss: 2.022540112336477

Epoch: 6| Step: 11
Training loss: 1.0612492561340332
Validation loss: 2.0545180638631186

Epoch: 6| Step: 12
Training loss: 1.2700395584106445
Validation loss: 2.0335715413093567

Epoch: 6| Step: 13
Training loss: 1.1686623096466064
Validation loss: 2.099620262781779

Epoch: 84| Step: 0
Training loss: 1.4463880062103271
Validation loss: 2.043189783891042

Epoch: 6| Step: 1
Training loss: 1.3057547807693481
Validation loss: 2.0566652615865073

Epoch: 6| Step: 2
Training loss: 1.2214341163635254
Validation loss: 2.0687540968259177

Epoch: 6| Step: 3
Training loss: 1.4574964046478271
Validation loss: 2.045615077018738

Epoch: 6| Step: 4
Training loss: 1.4213752746582031
Validation loss: 2.0911338329315186

Epoch: 6| Step: 5
Training loss: 1.8610763549804688
Validation loss: 2.09386553366979

Epoch: 6| Step: 6
Training loss: 1.3714255094528198
Validation loss: 2.0917267004648843

Epoch: 6| Step: 7
Training loss: 1.4895936250686646
Validation loss: 2.075404167175293

Epoch: 6| Step: 8
Training loss: 1.3684941530227661
Validation loss: 2.1065123279889426

Epoch: 6| Step: 9
Training loss: 1.712205410003662
Validation loss: 2.0770194927851358

Epoch: 6| Step: 10
Training loss: 1.841366171836853
Validation loss: 2.1440953612327576

Epoch: 6| Step: 11
Training loss: 1.5406792163848877
Validation loss: 2.0929015080134072

Epoch: 6| Step: 12
Training loss: 1.426985263824463
Validation loss: 2.072304626305898

Epoch: 6| Step: 13
Training loss: 1.908732533454895
Validation loss: 2.0688756505648294

Epoch: 85| Step: 0
Training loss: 1.714242696762085
Validation loss: 2.0721912384033203

Epoch: 6| Step: 1
Training loss: 1.1756784915924072
Validation loss: 2.064823349316915

Epoch: 6| Step: 2
Training loss: 1.721466064453125
Validation loss: 2.0145067969957986

Epoch: 6| Step: 3
Training loss: 1.2747983932495117
Validation loss: 2.062169293562571

Epoch: 6| Step: 4
Training loss: 1.1891840696334839
Validation loss: 2.035446345806122

Epoch: 6| Step: 5
Training loss: 1.1661460399627686
Validation loss: 2.0566670298576355

Epoch: 6| Step: 6
Training loss: 1.8561630249023438
Validation loss: 2.0507156451543174

Epoch: 6| Step: 7
Training loss: 1.5213382244110107
Validation loss: 2.081722537676493

Epoch: 6| Step: 8
Training loss: 2.285167694091797
Validation loss: 2.071629524230957

Epoch: 6| Step: 9
Training loss: 1.174407720565796
Validation loss: 2.09234086672465

Epoch: 6| Step: 10
Training loss: 1.7343130111694336
Validation loss: 2.0797097086906433

Epoch: 6| Step: 11
Training loss: 1.321728229522705
Validation loss: 2.062264700730642

Epoch: 6| Step: 12
Training loss: 1.5320974588394165
Validation loss: 2.025521238644918

Epoch: 6| Step: 13
Training loss: 1.4597684144973755
Validation loss: 2.0366777578989663

Epoch: 86| Step: 0
Training loss: 1.9943580627441406
Validation loss: 2.0466482837994895

Epoch: 6| Step: 1
Training loss: 1.5151371955871582
Validation loss: 2.02705987294515

Epoch: 6| Step: 2
Training loss: 1.6473026275634766
Validation loss: 2.0585736632347107

Epoch: 6| Step: 3
Training loss: 1.197754144668579
Validation loss: 2.0226972301801047

Epoch: 6| Step: 4
Training loss: 1.415050745010376
Validation loss: 2.0779176155726113

Epoch: 6| Step: 5
Training loss: 1.142106056213379
Validation loss: 2.0246739784876504

Epoch: 6| Step: 6
Training loss: 2.2853035926818848
Validation loss: 2.0274940927823386

Epoch: 6| Step: 7
Training loss: 1.7137928009033203
Validation loss: 2.05021341641744

Epoch: 6| Step: 8
Training loss: 1.3460078239440918
Validation loss: 2.0425131718317666

Epoch: 6| Step: 9
Training loss: 1.0216535329818726
Validation loss: 2.029301663239797

Epoch: 6| Step: 10
Training loss: 1.6130220890045166
Validation loss: 2.056991219520569

Epoch: 6| Step: 11
Training loss: 1.679452896118164
Validation loss: 2.0743802388509116

Epoch: 6| Step: 12
Training loss: 1.4174004793167114
Validation loss: 2.083303173383077

Epoch: 6| Step: 13
Training loss: 1.6337964534759521
Validation loss: 2.100119888782501

Epoch: 87| Step: 0
Training loss: 1.5109968185424805
Validation loss: 2.0296600659688315

Epoch: 6| Step: 1
Training loss: 1.853866696357727
Validation loss: 2.0207914312680564

Epoch: 6| Step: 2
Training loss: 1.150205373764038
Validation loss: 2.0526145497957864

Epoch: 6| Step: 3
Training loss: 1.4052571058273315
Validation loss: 2.042360305786133

Epoch: 6| Step: 4
Training loss: 1.4788222312927246
Validation loss: 2.0631313721338906

Epoch: 6| Step: 5
Training loss: 1.295261025428772
Validation loss: 2.05182945728302

Epoch: 6| Step: 6
Training loss: 1.2204666137695312
Validation loss: 2.040307362874349

Epoch: 6| Step: 7
Training loss: 1.8972246646881104
Validation loss: 2.0700361728668213

Epoch: 6| Step: 8
Training loss: 2.0355887413024902
Validation loss: 2.0493152340253196

Epoch: 6| Step: 9
Training loss: 1.492935299873352
Validation loss: 2.081656515598297

Epoch: 6| Step: 10
Training loss: 1.3224310874938965
Validation loss: 2.0382741888364158

Epoch: 6| Step: 11
Training loss: 1.5510177612304688
Validation loss: 2.070380210876465

Epoch: 6| Step: 12
Training loss: 1.5224024057388306
Validation loss: 2.1234779755274453

Epoch: 6| Step: 13
Training loss: 1.3298546075820923
Validation loss: 2.0936905344327292

Epoch: 88| Step: 0
Training loss: 1.4339897632598877
Validation loss: 2.079890767733256

Epoch: 6| Step: 1
Training loss: 1.1195197105407715
Validation loss: 2.075408716996511

Epoch: 6| Step: 2
Training loss: 1.3333852291107178
Validation loss: 2.058385749657949

Epoch: 6| Step: 3
Training loss: 2.670186758041382
Validation loss: 2.082487960656484

Epoch: 6| Step: 4
Training loss: 1.3293735980987549
Validation loss: 2.052516539891561

Epoch: 6| Step: 5
Training loss: 1.0930728912353516
Validation loss: 2.0544817248980203

Epoch: 6| Step: 6
Training loss: 1.314668893814087
Validation loss: 2.0584266781806946

Epoch: 6| Step: 7
Training loss: 1.6731882095336914
Validation loss: 2.0277613004048667

Epoch: 6| Step: 8
Training loss: 1.4807405471801758
Validation loss: 2.057512640953064

Epoch: 6| Step: 9
Training loss: 1.5572724342346191
Validation loss: 2.008034408092499

Epoch: 6| Step: 10
Training loss: 1.5279982089996338
Validation loss: 2.0370367566744485

Epoch: 6| Step: 11
Training loss: 1.3241863250732422
Validation loss: 2.02426815032959

Epoch: 6| Step: 12
Training loss: 1.455286979675293
Validation loss: 2.0669949452082315

Epoch: 6| Step: 13
Training loss: 1.698695182800293
Validation loss: 2.059190293153127

Epoch: 89| Step: 0
Training loss: 2.2161874771118164
Validation loss: 2.147239367167155

Epoch: 6| Step: 1
Training loss: 1.2653580904006958
Validation loss: 2.0630082885424295

Epoch: 6| Step: 2
Training loss: 1.8850231170654297
Validation loss: 2.0832869013150535

Epoch: 6| Step: 3
Training loss: 1.4283692836761475
Validation loss: 2.093576709429423

Epoch: 6| Step: 4
Training loss: 1.4090514183044434
Validation loss: 2.0492839018503823

Epoch: 6| Step: 5
Training loss: 0.9079323410987854
Validation loss: 2.0934788386027017

Epoch: 6| Step: 6
Training loss: 1.5850117206573486
Validation loss: 2.0710217555363974

Epoch: 6| Step: 7
Training loss: 1.2491191625595093
Validation loss: 2.027448813120524

Epoch: 6| Step: 8
Training loss: 1.1318694353103638
Validation loss: 2.0422043601671853

Epoch: 6| Step: 9
Training loss: 1.5537190437316895
Validation loss: 2.0612047712008157

Epoch: 6| Step: 10
Training loss: 1.4312288761138916
Validation loss: 2.040250599384308

Epoch: 6| Step: 11
Training loss: 1.7804062366485596
Validation loss: 2.047125736872355

Epoch: 6| Step: 12
Training loss: 1.876656413078308
Validation loss: 2.0041321516036987

Epoch: 6| Step: 13
Training loss: 1.7841652631759644
Validation loss: 2.020550489425659

Epoch: 90| Step: 0
Training loss: 1.6044056415557861
Validation loss: 2.110088884830475

Epoch: 6| Step: 1
Training loss: 1.6412887573242188
Validation loss: 2.1381113131841025

Epoch: 6| Step: 2
Training loss: 1.198857307434082
Validation loss: 2.0966891050338745

Epoch: 6| Step: 3
Training loss: 1.5069901943206787
Validation loss: 2.034929891427358

Epoch: 6| Step: 4
Training loss: 1.3008191585540771
Validation loss: 2.0993537505467734

Epoch: 6| Step: 5
Training loss: 1.9783565998077393
Validation loss: 2.033770183722178

Epoch: 6| Step: 6
Training loss: 1.8483766317367554
Validation loss: 2.0584211349487305

Epoch: 6| Step: 7
Training loss: 1.7194514274597168
Validation loss: 2.085018197695414

Epoch: 6| Step: 8
Training loss: 1.2882301807403564
Validation loss: 2.029993931452433

Epoch: 6| Step: 9
Training loss: 1.053846836090088
Validation loss: 1.9994512001673381

Epoch: 6| Step: 10
Training loss: 2.0875353813171387
Validation loss: 2.0402449568112693

Epoch: 6| Step: 11
Training loss: 1.3941256999969482
Validation loss: 2.0141244928042092

Epoch: 6| Step: 12
Training loss: 1.5820109844207764
Validation loss: 2.0514749884605408

Epoch: 6| Step: 13
Training loss: 0.5025374293327332
Validation loss: 2.0309154391288757

Epoch: 91| Step: 0
Training loss: 1.1878914833068848
Validation loss: 2.039107362429301

Epoch: 6| Step: 1
Training loss: 1.1471142768859863
Validation loss: 2.035647749900818

Epoch: 6| Step: 2
Training loss: 1.393646240234375
Validation loss: 2.0754856069882712

Epoch: 6| Step: 3
Training loss: 1.7419066429138184
Validation loss: 2.0175733963648477

Epoch: 6| Step: 4
Training loss: 1.6803510189056396
Validation loss: 2.0947314500808716

Epoch: 6| Step: 5
Training loss: 1.3328009843826294
Validation loss: 2.034760276476542

Epoch: 6| Step: 6
Training loss: 1.6425873041152954
Validation loss: 2.0713233153025308

Epoch: 6| Step: 7
Training loss: 1.1924593448638916
Validation loss: 2.0592698454856873

Epoch: 6| Step: 8
Training loss: 1.3519237041473389
Validation loss: 2.013745387395223

Epoch: 6| Step: 9
Training loss: 1.5693849325180054
Validation loss: 2.06254510084788

Epoch: 6| Step: 10
Training loss: 0.8970340490341187
Validation loss: 2.0498050252596536

Epoch: 6| Step: 11
Training loss: 1.931260108947754
Validation loss: 2.0378809769948325

Epoch: 6| Step: 12
Training loss: 1.4854953289031982
Validation loss: 2.0706831216812134

Epoch: 6| Step: 13
Training loss: 1.9548033475875854
Validation loss: 2.026172657807668

Epoch: 92| Step: 0
Training loss: 0.924691379070282
Validation loss: 2.0387642979621887

Epoch: 6| Step: 1
Training loss: 0.9263280034065247
Validation loss: 2.066821297009786

Epoch: 6| Step: 2
Training loss: 1.1131031513214111
Validation loss: 2.0205148458480835

Epoch: 6| Step: 3
Training loss: 1.8198773860931396
Validation loss: 2.079204022884369

Epoch: 6| Step: 4
Training loss: 1.749371886253357
Validation loss: 2.048646569252014

Epoch: 6| Step: 5
Training loss: 2.0584921836853027
Validation loss: 2.0521242221196494

Epoch: 6| Step: 6
Training loss: 1.1297534704208374
Validation loss: 2.0244078238805137

Epoch: 6| Step: 7
Training loss: 1.992172122001648
Validation loss: 2.0415196816126504

Epoch: 6| Step: 8
Training loss: 1.2559643983840942
Validation loss: 2.0108841260274253

Epoch: 6| Step: 9
Training loss: 1.5525470972061157
Validation loss: 2.0359795292218528

Epoch: 6| Step: 10
Training loss: 1.4563860893249512
Validation loss: 2.006168564160665

Epoch: 6| Step: 11
Training loss: 1.502644658088684
Validation loss: 2.0515122214953103

Epoch: 6| Step: 12
Training loss: 1.4335088729858398
Validation loss: 2.0559096336364746

Epoch: 6| Step: 13
Training loss: 1.4221386909484863
Validation loss: 2.0216978391011557

Epoch: 93| Step: 0
Training loss: 1.0975205898284912
Validation loss: 2.056625545024872

Epoch: 6| Step: 1
Training loss: 1.5072498321533203
Validation loss: 2.1004982789357505

Epoch: 6| Step: 2
Training loss: 1.542454481124878
Validation loss: 2.09214053551356

Epoch: 6| Step: 3
Training loss: 1.3031712770462036
Validation loss: 2.1092745661735535

Epoch: 6| Step: 4
Training loss: 1.3894919157028198
Validation loss: 2.093762199083964

Epoch: 6| Step: 5
Training loss: 1.3793888092041016
Validation loss: 2.077414870262146

Epoch: 6| Step: 6
Training loss: 1.7867472171783447
Validation loss: 2.0797450145085654

Epoch: 6| Step: 7
Training loss: 1.19782555103302
Validation loss: 2.041665474573771

Epoch: 6| Step: 8
Training loss: 1.2733972072601318
Validation loss: 2.033955136934916

Epoch: 6| Step: 9
Training loss: 1.3160102367401123
Validation loss: 2.019645313421885

Epoch: 6| Step: 10
Training loss: 1.1235110759735107
Validation loss: 2.010269025961558

Epoch: 6| Step: 11
Training loss: 1.7660410404205322
Validation loss: 2.027341067790985

Epoch: 6| Step: 12
Training loss: 1.16023588180542
Validation loss: 2.0013277530670166

Epoch: 6| Step: 13
Training loss: 1.7829586267471313
Validation loss: 2.0573034286499023

Epoch: 94| Step: 0
Training loss: 1.9867942333221436
Validation loss: 2.004129628340403

Epoch: 6| Step: 1
Training loss: 1.65181565284729
Validation loss: 2.0553839802742004

Epoch: 6| Step: 2
Training loss: 1.595585584640503
Validation loss: 2.0935922463734946

Epoch: 6| Step: 3
Training loss: 1.2421214580535889
Validation loss: 2.0996886690457663

Epoch: 6| Step: 4
Training loss: 1.1921741962432861
Validation loss: 2.049685994784037

Epoch: 6| Step: 5
Training loss: 0.9632238149642944
Validation loss: 2.0955333709716797

Epoch: 6| Step: 6
Training loss: 1.460763692855835
Validation loss: 2.034158170223236

Epoch: 6| Step: 7
Training loss: 0.9704219698905945
Validation loss: 2.016817629337311

Epoch: 6| Step: 8
Training loss: 1.676264762878418
Validation loss: 2.009209990501404

Epoch: 6| Step: 9
Training loss: 1.5533502101898193
Validation loss: 2.0430185198783875

Epoch: 6| Step: 10
Training loss: 0.9565455913543701
Validation loss: 2.055682281653086

Epoch: 6| Step: 11
Training loss: 2.4025490283966064
Validation loss: 2.037934501965841

Epoch: 6| Step: 12
Training loss: 1.1516339778900146
Validation loss: 2.055140654246012

Epoch: 6| Step: 13
Training loss: 1.2104320526123047
Validation loss: 2.0727099974950156

Epoch: 95| Step: 0
Training loss: 1.2046319246292114
Validation loss: 2.1054870088895163

Epoch: 6| Step: 1
Training loss: 1.5619899034500122
Validation loss: 2.0755761663118997

Epoch: 6| Step: 2
Training loss: 0.8062055110931396
Validation loss: 2.076520582040151

Epoch: 6| Step: 3
Training loss: 0.8185094594955444
Validation loss: 2.1081800858179727

Epoch: 6| Step: 4
Training loss: 1.914347767829895
Validation loss: 2.02961058417956

Epoch: 6| Step: 5
Training loss: 0.7382058501243591
Validation loss: 2.076685925324758

Epoch: 6| Step: 6
Training loss: 1.258667230606079
Validation loss: 1.9934500853220622

Epoch: 6| Step: 7
Training loss: 1.4383798837661743
Validation loss: 2.0839776396751404

Epoch: 6| Step: 8
Training loss: 1.9944720268249512
Validation loss: 2.0111846725145974

Epoch: 6| Step: 9
Training loss: 1.8676297664642334
Validation loss: 2.0459782481193542

Epoch: 6| Step: 10
Training loss: 1.8369429111480713
Validation loss: 2.0371020237604776

Epoch: 6| Step: 11
Training loss: 1.1979604959487915
Validation loss: 1.982362985610962

Epoch: 6| Step: 12
Training loss: 1.2429801225662231
Validation loss: 2.0146015882492065

Epoch: 6| Step: 13
Training loss: 1.4862858057022095
Validation loss: 2.0201453963915506

Epoch: 96| Step: 0
Training loss: 1.5774580240249634
Validation loss: 2.036996285120646

Epoch: 6| Step: 1
Training loss: 1.5940523147583008
Validation loss: 2.0651143391927085

Epoch: 6| Step: 2
Training loss: 1.4391329288482666
Validation loss: 2.072903652985891

Epoch: 6| Step: 3
Training loss: 1.9889440536499023
Validation loss: 2.0916702349980674

Epoch: 6| Step: 4
Training loss: 1.287078857421875
Validation loss: 2.117649575074514

Epoch: 6| Step: 5
Training loss: 1.7478183507919312
Validation loss: 2.0395031571388245

Epoch: 6| Step: 6
Training loss: 0.9799453616142273
Validation loss: 2.065234661102295

Epoch: 6| Step: 7
Training loss: 1.7993888854980469
Validation loss: 2.0419569611549377

Epoch: 6| Step: 8
Training loss: 1.3690040111541748
Validation loss: 2.0152018666267395

Epoch: 6| Step: 9
Training loss: 0.9125170707702637
Validation loss: 2.0056991577148438

Epoch: 6| Step: 10
Training loss: 1.0859365463256836
Validation loss: 2.004979908466339

Epoch: 6| Step: 11
Training loss: 1.2226402759552002
Validation loss: 1.9703625043233235

Epoch: 6| Step: 12
Training loss: 1.2141838073730469
Validation loss: 2.0209288199742637

Epoch: 6| Step: 13
Training loss: 1.6072945594787598
Validation loss: 2.0241087277730307

Epoch: 97| Step: 0
Training loss: 0.996922492980957
Validation loss: 1.9843951265017192

Epoch: 6| Step: 1
Training loss: 0.9059954285621643
Validation loss: 2.0406631032625833

Epoch: 6| Step: 2
Training loss: 1.5497949123382568
Validation loss: 1.9825951059659321

Epoch: 6| Step: 3
Training loss: 1.0457472801208496
Validation loss: 1.9900803764661152

Epoch: 6| Step: 4
Training loss: 1.9319733381271362
Validation loss: 1.993395725886027

Epoch: 6| Step: 5
Training loss: 1.1623258590698242
Validation loss: 2.035428980986277

Epoch: 6| Step: 6
Training loss: 1.1842660903930664
Validation loss: 2.028343756993612

Epoch: 6| Step: 7
Training loss: 1.5183210372924805
Validation loss: 2.035973827044169

Epoch: 6| Step: 8
Training loss: 2.402040958404541
Validation loss: 2.098975876967112

Epoch: 6| Step: 9
Training loss: 1.6317152976989746
Validation loss: 2.0471534729003906

Epoch: 6| Step: 10
Training loss: 1.5325961112976074
Validation loss: 2.1499414443969727

Epoch: 6| Step: 11
Training loss: 1.472043514251709
Validation loss: 2.073403278986613

Epoch: 6| Step: 12
Training loss: 1.1231210231781006
Validation loss: 2.049729903539022

Epoch: 6| Step: 13
Training loss: 1.6031405925750732
Validation loss: 2.0124135613441467

Epoch: 98| Step: 0
Training loss: 2.046412706375122
Validation loss: 2.0156760811805725

Epoch: 6| Step: 1
Training loss: 1.3784716129302979
Validation loss: 2.065791209538778

Epoch: 6| Step: 2
Training loss: 1.3190323114395142
Validation loss: 2.0400845408439636

Epoch: 6| Step: 3
Training loss: 1.4922223091125488
Validation loss: 1.9938717484474182

Epoch: 6| Step: 4
Training loss: 1.1336549520492554
Validation loss: 2.01342511177063

Epoch: 6| Step: 5
Training loss: 1.1896166801452637
Validation loss: 2.082049528757731

Epoch: 6| Step: 6
Training loss: 1.201622724533081
Validation loss: 2.030139664808909

Epoch: 6| Step: 7
Training loss: 1.323539137840271
Validation loss: 2.0339052279790244

Epoch: 6| Step: 8
Training loss: 1.2172390222549438
Validation loss: 2.0429040789604187

Epoch: 6| Step: 9
Training loss: 1.5812731981277466
Validation loss: 2.1064210534095764

Epoch: 6| Step: 10
Training loss: 1.329704999923706
Validation loss: 2.1235190629959106

Epoch: 6| Step: 11
Training loss: 0.5771833658218384
Validation loss: 2.0970163345336914

Epoch: 6| Step: 12
Training loss: 1.864302635192871
Validation loss: 2.1156781911849976

Epoch: 6| Step: 13
Training loss: 1.713890552520752
Validation loss: 2.086938043435415

Epoch: 99| Step: 0
Training loss: 1.0345792770385742
Validation loss: 2.0636285543441772

Epoch: 6| Step: 1
Training loss: 1.139047384262085
Validation loss: 2.0667553742726645

Epoch: 6| Step: 2
Training loss: 1.2983289957046509
Validation loss: 2.0381035606066384

Epoch: 6| Step: 3
Training loss: 1.6720808744430542
Validation loss: 2.022277315457662

Epoch: 6| Step: 4
Training loss: 1.966889500617981
Validation loss: 2.0328226884206138

Epoch: 6| Step: 5
Training loss: 1.6392936706542969
Validation loss: 2.0083194375038147

Epoch: 6| Step: 6
Training loss: 1.405733346939087
Validation loss: 2.038514196872711

Epoch: 6| Step: 7
Training loss: 1.0142465829849243
Validation loss: 2.0250320037206015

Epoch: 6| Step: 8
Training loss: 1.6316633224487305
Validation loss: 2.0163268049558005

Epoch: 6| Step: 9
Training loss: 1.0617986917495728
Validation loss: 2.054404139518738

Epoch: 6| Step: 10
Training loss: 1.3318015336990356
Validation loss: 2.0135603547096252

Epoch: 6| Step: 11
Training loss: 1.1561199426651
Validation loss: 1.9705971678098042

Epoch: 6| Step: 12
Training loss: 1.4003193378448486
Validation loss: 2.0217893520991006

Epoch: 6| Step: 13
Training loss: 1.3823933601379395
Validation loss: 2.0758066972096763

Epoch: 100| Step: 0
Training loss: 1.2983320951461792
Validation loss: 2.103283445040385

Epoch: 6| Step: 1
Training loss: 2.199162721633911
Validation loss: 2.072495182355245

Epoch: 6| Step: 2
Training loss: 1.4088263511657715
Validation loss: 2.0161608854929605

Epoch: 6| Step: 3
Training loss: 1.5943613052368164
Validation loss: 2.0365670323371887

Epoch: 6| Step: 4
Training loss: 1.3893046379089355
Validation loss: 2.0178422331809998

Epoch: 6| Step: 5
Training loss: 0.8927490711212158
Validation loss: 2.049106319745382

Epoch: 6| Step: 6
Training loss: 1.5307707786560059
Validation loss: 2.093281308809916

Epoch: 6| Step: 7
Training loss: 1.142943263053894
Validation loss: 2.0460126797358194

Epoch: 6| Step: 8
Training loss: 1.2550969123840332
Validation loss: 2.0548253854115806

Epoch: 6| Step: 9
Training loss: 0.9697278738021851
Validation loss: 2.008694052696228

Epoch: 6| Step: 10
Training loss: 1.4630603790283203
Validation loss: 1.9966526627540588

Epoch: 6| Step: 11
Training loss: 1.1423239707946777
Validation loss: 2.0974135398864746

Epoch: 6| Step: 12
Training loss: 1.0744402408599854
Validation loss: 2.0453761418660483

Epoch: 6| Step: 13
Training loss: 1.7699381113052368
Validation loss: 2.050858438014984

Epoch: 101| Step: 0
Training loss: 1.9284298419952393
Validation loss: 2.0902349948883057

Epoch: 6| Step: 1
Training loss: 1.2803125381469727
Validation loss: 2.1026150981585183

Epoch: 6| Step: 2
Training loss: 1.375856637954712
Validation loss: 2.0906415581703186

Epoch: 6| Step: 3
Training loss: 1.6520419120788574
Validation loss: 2.039648433526357

Epoch: 6| Step: 4
Training loss: 1.1080098152160645
Validation loss: 2.1137879888216653

Epoch: 6| Step: 5
Training loss: 1.4350496530532837
Validation loss: 2.028718332449595

Epoch: 6| Step: 6
Training loss: 0.8675439357757568
Validation loss: 2.0650100111961365

Epoch: 6| Step: 7
Training loss: 1.2643985748291016
Validation loss: 2.0440550247828164

Epoch: 6| Step: 8
Training loss: 1.633126139640808
Validation loss: 2.1012363831202188

Epoch: 6| Step: 9
Training loss: 1.468983769416809
Validation loss: 2.1223280231157937

Epoch: 6| Step: 10
Training loss: 1.1704686880111694
Validation loss: 2.0662473241488137

Epoch: 6| Step: 11
Training loss: 1.1400336027145386
Validation loss: 2.0850837230682373

Epoch: 6| Step: 12
Training loss: 1.6926625967025757
Validation loss: 2.1679744124412537

Epoch: 6| Step: 13
Training loss: 1.3766040802001953
Validation loss: 2.1009664138158164

Epoch: 102| Step: 0
Training loss: 1.2980265617370605
Validation loss: 2.0308581391970315

Epoch: 6| Step: 1
Training loss: 1.600143313407898
Validation loss: 2.025163451830546

Epoch: 6| Step: 2
Training loss: 1.0035312175750732
Validation loss: 2.0036141077677407

Epoch: 6| Step: 3
Training loss: 1.311947226524353
Validation loss: 2.0609141985575357

Epoch: 6| Step: 4
Training loss: 1.6278852224349976
Validation loss: 2.0269296964009604

Epoch: 6| Step: 5
Training loss: 1.317502737045288
Validation loss: 1.9989803433418274

Epoch: 6| Step: 6
Training loss: 1.2852160930633545
Validation loss: 2.004934827486674

Epoch: 6| Step: 7
Training loss: 1.4186336994171143
Validation loss: 1.9730747938156128

Epoch: 6| Step: 8
Training loss: 0.8106577396392822
Validation loss: 2.0327013532320657

Epoch: 6| Step: 9
Training loss: 1.532008171081543
Validation loss: 2.0443208416303

Epoch: 6| Step: 10
Training loss: 2.146285057067871
Validation loss: 2.032036244869232

Epoch: 6| Step: 11
Training loss: 1.4626376628875732
Validation loss: 2.076663831869761

Epoch: 6| Step: 12
Training loss: 1.1468243598937988
Validation loss: 2.0715694030125937

Epoch: 6| Step: 13
Training loss: 1.5412437915802002
Validation loss: 2.0709360241889954

Epoch: 103| Step: 0
Training loss: 1.4050859212875366
Validation loss: 2.07326602935791

Epoch: 6| Step: 1
Training loss: 1.3941633701324463
Validation loss: 2.0778371890385947

Epoch: 6| Step: 2
Training loss: 0.7191258668899536
Validation loss: 2.0578125516573587

Epoch: 6| Step: 3
Training loss: 1.5336283445358276
Validation loss: 2.0179926554361978

Epoch: 6| Step: 4
Training loss: 1.7365703582763672
Validation loss: 2.0801050066947937

Epoch: 6| Step: 5
Training loss: 1.08522629737854
Validation loss: 2.0387362837791443

Epoch: 6| Step: 6
Training loss: 1.5262573957443237
Validation loss: 2.0541339914004006

Epoch: 6| Step: 7
Training loss: 0.7915194034576416
Validation loss: 2.0177382429440818

Epoch: 6| Step: 8
Training loss: 1.293814778327942
Validation loss: 2.0153530836105347

Epoch: 6| Step: 9
Training loss: 1.1513471603393555
Validation loss: 2.0568180282910666

Epoch: 6| Step: 10
Training loss: 1.6217494010925293
Validation loss: 2.0604236920674643

Epoch: 6| Step: 11
Training loss: 1.0836081504821777
Validation loss: 1.991433044274648

Epoch: 6| Step: 12
Training loss: 1.2499253749847412
Validation loss: 2.0146875778834024

Epoch: 6| Step: 13
Training loss: 1.3817871809005737
Validation loss: 2.07329789797465

Epoch: 104| Step: 0
Training loss: 2.138897657394409
Validation loss: 2.017234126726786

Epoch: 6| Step: 1
Training loss: 0.97981196641922
Validation loss: 1.9766751329104106

Epoch: 6| Step: 2
Training loss: 1.8496403694152832
Validation loss: 2.023704926172892

Epoch: 6| Step: 3
Training loss: 1.1902633905410767
Validation loss: 1.950395107269287

Epoch: 6| Step: 4
Training loss: 1.6543279886245728
Validation loss: 1.9789640307426453

Epoch: 6| Step: 5
Training loss: 1.1571807861328125
Validation loss: 2.0023494362831116

Epoch: 6| Step: 6
Training loss: 1.621649980545044
Validation loss: 1.993078351020813

Epoch: 6| Step: 7
Training loss: 0.9113276600837708
Validation loss: 2.0161136587460837

Epoch: 6| Step: 8
Training loss: 0.8264824748039246
Validation loss: 2.0193652908007302

Epoch: 6| Step: 9
Training loss: 1.3382409811019897
Validation loss: 2.028304954369863

Epoch: 6| Step: 10
Training loss: 1.1455180644989014
Validation loss: 2.0835238695144653

Epoch: 6| Step: 11
Training loss: 0.904639482498169
Validation loss: 2.1127432386080423

Epoch: 6| Step: 12
Training loss: 1.2287142276763916
Validation loss: 2.0844261050224304

Epoch: 6| Step: 13
Training loss: 0.971096396446228
Validation loss: 2.051837980747223

Epoch: 105| Step: 0
Training loss: 1.2036898136138916
Validation loss: 2.0247422456741333

Epoch: 6| Step: 1
Training loss: 1.2051911354064941
Validation loss: 2.035963257153829

Epoch: 6| Step: 2
Training loss: 1.2835373878479004
Validation loss: 2.0266206860542297

Epoch: 6| Step: 3
Training loss: 1.1779636144638062
Validation loss: 2.0091686646143594

Epoch: 6| Step: 4
Training loss: 1.0314385890960693
Validation loss: 1.97020024061203

Epoch: 6| Step: 5
Training loss: 1.105731725692749
Validation loss: 1.994611660639445

Epoch: 6| Step: 6
Training loss: 1.5231587886810303
Validation loss: 1.9614140391349792

Epoch: 6| Step: 7
Training loss: 2.282622814178467
Validation loss: 2.05501127243042

Epoch: 6| Step: 8
Training loss: 1.1268399953842163
Validation loss: 2.008290449778239

Epoch: 6| Step: 9
Training loss: 1.0828760862350464
Validation loss: 2.099179665247599

Epoch: 6| Step: 10
Training loss: 1.4247081279754639
Validation loss: 2.102757751941681

Epoch: 6| Step: 11
Training loss: 0.8923516273498535
Validation loss: 2.1124380230903625

Epoch: 6| Step: 12
Training loss: 1.518972396850586
Validation loss: 2.099742611249288

Epoch: 6| Step: 13
Training loss: 1.0838217735290527
Validation loss: 2.028924842675527

Epoch: 106| Step: 0
Training loss: 1.3125208616256714
Validation loss: 2.0092448393503823

Epoch: 6| Step: 1
Training loss: 1.9415031671524048
Validation loss: 2.047067880630493

Epoch: 6| Step: 2
Training loss: 1.0255590677261353
Validation loss: 2.010461131731669

Epoch: 6| Step: 3
Training loss: 1.0734293460845947
Validation loss: 1.9814512133598328

Epoch: 6| Step: 4
Training loss: 1.1078534126281738
Validation loss: 1.9817484219868977

Epoch: 6| Step: 5
Training loss: 1.6345493793487549
Validation loss: 2.0679423014322915

Epoch: 6| Step: 6
Training loss: 1.3929023742675781
Validation loss: 1.953007419904073

Epoch: 6| Step: 7
Training loss: 1.2921971082687378
Validation loss: 1.9878386855125427

Epoch: 6| Step: 8
Training loss: 1.178539752960205
Validation loss: 2.0990121563275657

Epoch: 6| Step: 9
Training loss: 1.007190227508545
Validation loss: 2.037593205769857

Epoch: 6| Step: 10
Training loss: 1.3799350261688232
Validation loss: 2.000875155131022

Epoch: 6| Step: 11
Training loss: 1.2392865419387817
Validation loss: 2.045044223467509

Epoch: 6| Step: 12
Training loss: 0.9287175536155701
Validation loss: 2.0178242524464927

Epoch: 6| Step: 13
Training loss: 1.1245745420455933
Validation loss: 2.0425785183906555

Epoch: 107| Step: 0
Training loss: 1.2914495468139648
Validation loss: 2.0284298857053122

Epoch: 6| Step: 1
Training loss: 0.9967753887176514
Validation loss: 2.0170170664787292

Epoch: 6| Step: 2
Training loss: 1.6241978406906128
Validation loss: 2.0224889516830444

Epoch: 6| Step: 3
Training loss: 1.2667720317840576
Validation loss: 2.0755961537361145

Epoch: 6| Step: 4
Training loss: 0.9493069052696228
Validation loss: 2.0438717007637024

Epoch: 6| Step: 5
Training loss: 1.026663064956665
Validation loss: 2.014048139254252

Epoch: 6| Step: 6
Training loss: 1.0782859325408936
Validation loss: 2.0638948877652488

Epoch: 6| Step: 7
Training loss: 2.042149066925049
Validation loss: 2.0815088351567588

Epoch: 6| Step: 8
Training loss: 1.6679713726043701
Validation loss: 2.0069894591967263

Epoch: 6| Step: 9
Training loss: 1.4188697338104248
Validation loss: 2.0284700989723206

Epoch: 6| Step: 10
Training loss: 0.9943864345550537
Validation loss: 2.018414874871572

Epoch: 6| Step: 11
Training loss: 1.2151075601577759
Validation loss: 1.979005217552185

Epoch: 6| Step: 12
Training loss: 1.0141148567199707
Validation loss: 1.9746724565823872

Epoch: 6| Step: 13
Training loss: 1.0513123273849487
Validation loss: 2.0380528966585794

Epoch: 108| Step: 0
Training loss: 1.1756722927093506
Validation loss: 2.050831933816274

Epoch: 6| Step: 1
Training loss: 0.8331432938575745
Validation loss: 2.050225555896759

Epoch: 6| Step: 2
Training loss: 1.9724187850952148
Validation loss: 2.0651592214902244

Epoch: 6| Step: 3
Training loss: 1.4466629028320312
Validation loss: 2.0720650355021157

Epoch: 6| Step: 4
Training loss: 1.3182553052902222
Validation loss: 2.050801396369934

Epoch: 6| Step: 5
Training loss: 1.102658987045288
Validation loss: 2.109493394692739

Epoch: 6| Step: 6
Training loss: 0.6669042706489563
Validation loss: 2.060330351193746

Epoch: 6| Step: 7
Training loss: 1.240506887435913
Validation loss: 2.0446966091791787

Epoch: 6| Step: 8
Training loss: 1.1321024894714355
Validation loss: 2.0178905725479126

Epoch: 6| Step: 9
Training loss: 0.7108796834945679
Validation loss: 2.0295011599858603

Epoch: 6| Step: 10
Training loss: 1.4964063167572021
Validation loss: 2.0306859612464905

Epoch: 6| Step: 11
Training loss: 1.2478671073913574
Validation loss: 2.018710811932882

Epoch: 6| Step: 12
Training loss: 1.2488830089569092
Validation loss: 2.01319811741511

Epoch: 6| Step: 13
Training loss: 1.483384370803833
Validation loss: 1.9860887726147969

Epoch: 109| Step: 0
Training loss: 1.2051732540130615
Validation loss: 2.02128142118454

Epoch: 6| Step: 1
Training loss: 1.194270133972168
Validation loss: 1.9889413714408875

Epoch: 6| Step: 2
Training loss: 0.988778829574585
Validation loss: 2.010114292303721

Epoch: 6| Step: 3
Training loss: 1.1955461502075195
Validation loss: 2.0608052810033164

Epoch: 6| Step: 4
Training loss: 2.154170513153076
Validation loss: 2.014726181825002

Epoch: 6| Step: 5
Training loss: 1.0184857845306396
Validation loss: 2.0344247619311013

Epoch: 6| Step: 6
Training loss: 1.4650641679763794
Validation loss: 2.0118066867192588

Epoch: 6| Step: 7
Training loss: 0.8713878393173218
Validation loss: 2.023040016492208

Epoch: 6| Step: 8
Training loss: 1.092564582824707
Validation loss: 2.0630662043889365

Epoch: 6| Step: 9
Training loss: 1.8582347631454468
Validation loss: 2.0122158527374268

Epoch: 6| Step: 10
Training loss: 0.5402117967605591
Validation loss: 2.0370362997055054

Epoch: 6| Step: 11
Training loss: 1.296137809753418
Validation loss: 1.989445408185323

Epoch: 6| Step: 12
Training loss: 0.75052410364151
Validation loss: 2.0220696926116943

Epoch: 6| Step: 13
Training loss: 1.1771330833435059
Validation loss: 2.0069595177968345

Epoch: 110| Step: 0
Training loss: 1.061174988746643
Validation loss: 2.0271255373954773

Epoch: 6| Step: 1
Training loss: 0.8707534670829773
Validation loss: 2.0694508155186973

Epoch: 6| Step: 2
Training loss: 1.3243690729141235
Validation loss: 2.012872596581777

Epoch: 6| Step: 3
Training loss: 1.2858058214187622
Validation loss: 2.0420442819595337

Epoch: 6| Step: 4
Training loss: 0.9764518141746521
Validation loss: 1.9899830222129822

Epoch: 6| Step: 5
Training loss: 1.479369878768921
Validation loss: 1.985287566979726

Epoch: 6| Step: 6
Training loss: 1.4449646472930908
Validation loss: 1.9783754746119182

Epoch: 6| Step: 7
Training loss: 0.8982946872711182
Validation loss: 2.04726642370224

Epoch: 6| Step: 8
Training loss: 2.1498942375183105
Validation loss: 2.0416600902875266

Epoch: 6| Step: 9
Training loss: 0.7274267077445984
Validation loss: 2.060937821865082

Epoch: 6| Step: 10
Training loss: 1.0962929725646973
Validation loss: 1.9952591458956401

Epoch: 6| Step: 11
Training loss: 1.1261723041534424
Validation loss: 2.0178418358167014

Epoch: 6| Step: 12
Training loss: 1.6042909622192383
Validation loss: 2.0188740293184915

Epoch: 6| Step: 13
Training loss: 0.8534371852874756
Validation loss: 1.9976054032643635

Epoch: 111| Step: 0
Training loss: 0.6851193904876709
Validation loss: 2.02350244919459

Epoch: 6| Step: 1
Training loss: 1.2061538696289062
Validation loss: 1.9872535665829976

Epoch: 6| Step: 2
Training loss: 1.708005666732788
Validation loss: 2.0370340943336487

Epoch: 6| Step: 3
Training loss: 1.3074485063552856
Validation loss: 2.0092562437057495

Epoch: 6| Step: 4
Training loss: 1.0983575582504272
Validation loss: 2.0460896690686545

Epoch: 6| Step: 5
Training loss: 0.9962608218193054
Validation loss: 2.0561704635620117

Epoch: 6| Step: 6
Training loss: 0.9994359016418457
Validation loss: 2.0368304451306662

Epoch: 6| Step: 7
Training loss: 1.1936893463134766
Validation loss: 2.0156553785006204

Epoch: 6| Step: 8
Training loss: 0.6080528497695923
Validation loss: 2.04613995552063

Epoch: 6| Step: 9
Training loss: 1.1268219947814941
Validation loss: 2.0791070063908896

Epoch: 6| Step: 10
Training loss: 1.2186646461486816
Validation loss: 2.050643781820933

Epoch: 6| Step: 11
Training loss: 1.3068019151687622
Validation loss: 2.043851455052694

Epoch: 6| Step: 12
Training loss: 1.5548471212387085
Validation loss: 2.0044772624969482

Epoch: 6| Step: 13
Training loss: 0.7518092393875122
Validation loss: 2.0742961168289185

Epoch: 112| Step: 0
Training loss: 1.2001949548721313
Validation loss: 1.980653961499532

Epoch: 6| Step: 1
Training loss: 1.2676289081573486
Validation loss: 2.019172410170237

Epoch: 6| Step: 2
Training loss: 0.9610924124717712
Validation loss: 2.0389254689216614

Epoch: 6| Step: 3
Training loss: 1.3678951263427734
Validation loss: 2.0035915970802307

Epoch: 6| Step: 4
Training loss: 1.5698087215423584
Validation loss: 2.0113983154296875

Epoch: 6| Step: 5
Training loss: 1.3661314249038696
Validation loss: 2.071450352668762

Epoch: 6| Step: 6
Training loss: 1.634589433670044
Validation loss: 1.9811897079149883

Epoch: 6| Step: 7
Training loss: 1.0167834758758545
Validation loss: 2.065809110800425

Epoch: 6| Step: 8
Training loss: 0.8232574462890625
Validation loss: 1.9665199319521587

Epoch: 6| Step: 9
Training loss: 1.0561485290527344
Validation loss: 2.063046157360077

Epoch: 6| Step: 10
Training loss: 0.9767976999282837
Validation loss: 2.0535614689191184

Epoch: 6| Step: 11
Training loss: 0.7664076685905457
Validation loss: 2.009208540121714

Epoch: 6| Step: 12
Training loss: 1.224752426147461
Validation loss: 2.0330609679222107

Epoch: 6| Step: 13
Training loss: 0.9681335687637329
Validation loss: 2.05945094426473

Epoch: 113| Step: 0
Training loss: 1.3640307188034058
Validation loss: 1.9795691967010498

Epoch: 6| Step: 1
Training loss: 0.9402773976325989
Validation loss: 2.0110051234563193

Epoch: 6| Step: 2
Training loss: 1.052530288696289
Validation loss: 1.995500385761261

Epoch: 6| Step: 3
Training loss: 1.8424072265625
Validation loss: 2.0096160570780435

Epoch: 6| Step: 4
Training loss: 0.7304592132568359
Validation loss: 2.007485588391622

Epoch: 6| Step: 5
Training loss: 0.9853569269180298
Validation loss: 2.024923324584961

Epoch: 6| Step: 6
Training loss: 1.5417743921279907
Validation loss: 1.9681575695673625

Epoch: 6| Step: 7
Training loss: 1.337066888809204
Validation loss: 1.975292980670929

Epoch: 6| Step: 8
Training loss: 1.0084102153778076
Validation loss: 1.9990192453066509

Epoch: 6| Step: 9
Training loss: 1.3468139171600342
Validation loss: 1.973488728205363

Epoch: 6| Step: 10
Training loss: 0.9261559247970581
Validation loss: 2.07170969247818

Epoch: 6| Step: 11
Training loss: 1.0210038423538208
Validation loss: 1.9939978122711182

Epoch: 6| Step: 12
Training loss: 0.7443491220474243
Validation loss: 1.981972336769104

Epoch: 6| Step: 13
Training loss: 0.8804865479469299
Validation loss: 2.0302902857462564

Epoch: 114| Step: 0
Training loss: 0.6728619337081909
Validation loss: 2.0215102434158325

Epoch: 6| Step: 1
Training loss: 1.2178773880004883
Validation loss: 2.052579720815023

Epoch: 6| Step: 2
Training loss: 1.4417991638183594
Validation loss: 2.0093665520350137

Epoch: 6| Step: 3
Training loss: 0.72715824842453
Validation loss: 1.9680384397506714

Epoch: 6| Step: 4
Training loss: 0.744189977645874
Validation loss: 2.0225069522857666

Epoch: 6| Step: 5
Training loss: 0.8831861019134521
Validation loss: 1.9919636050860088

Epoch: 6| Step: 6
Training loss: 1.3060195446014404
Validation loss: 2.061401128768921

Epoch: 6| Step: 7
Training loss: 0.7605783939361572
Validation loss: 2.016615410645803

Epoch: 6| Step: 8
Training loss: 1.4131908416748047
Validation loss: 2.0383643309275308

Epoch: 6| Step: 9
Training loss: 1.7826452255249023
Validation loss: 2.038293480873108

Epoch: 6| Step: 10
Training loss: 1.2916368246078491
Validation loss: 2.0352710286776223

Epoch: 6| Step: 11
Training loss: 0.5690606832504272
Validation loss: 1.9972155888875325

Epoch: 6| Step: 12
Training loss: 1.2492785453796387
Validation loss: 1.9736329118410747

Epoch: 6| Step: 13
Training loss: 0.9161774516105652
Validation loss: 2.032788793245951

Epoch: 115| Step: 0
Training loss: 0.4418526589870453
Validation loss: 2.0093377431233725

Epoch: 6| Step: 1
Training loss: 0.9029854536056519
Validation loss: 2.01989092429479

Epoch: 6| Step: 2
Training loss: 1.5326136350631714
Validation loss: 2.0163819591204324

Epoch: 6| Step: 3
Training loss: 1.0687799453735352
Validation loss: 2.0361276467641196

Epoch: 6| Step: 4
Training loss: 0.5307639837265015
Validation loss: 1.9984240531921387

Epoch: 6| Step: 5
Training loss: 1.5439680814743042
Validation loss: 2.0704153776168823

Epoch: 6| Step: 6
Training loss: 1.5759212970733643
Validation loss: 2.0178232192993164

Epoch: 6| Step: 7
Training loss: 1.1840325593948364
Validation loss: 2.0320460200309753

Epoch: 6| Step: 8
Training loss: 0.6628158688545227
Validation loss: 2.019662300745646

Epoch: 6| Step: 9
Training loss: 1.181678056716919
Validation loss: 1.989266852537791

Epoch: 6| Step: 10
Training loss: 1.0064382553100586
Validation loss: 2.014128108819326

Epoch: 6| Step: 11
Training loss: 1.6242830753326416
Validation loss: 2.0231876571973166

Epoch: 6| Step: 12
Training loss: 1.1023054122924805
Validation loss: 1.933981994787852

Epoch: 6| Step: 13
Training loss: 1.1315557956695557
Validation loss: 2.012374758720398

Epoch: 116| Step: 0
Training loss: 1.0392632484436035
Validation loss: 1.9982112844785054

Epoch: 6| Step: 1
Training loss: 0.9683074355125427
Validation loss: 2.0325236717859902

Epoch: 6| Step: 2
Training loss: 1.0888843536376953
Validation loss: 2.00455234448115

Epoch: 6| Step: 3
Training loss: 1.0570504665374756
Validation loss: 1.9695218006769817

Epoch: 6| Step: 4
Training loss: 1.057082176208496
Validation loss: 2.0254383285840354

Epoch: 6| Step: 5
Training loss: 1.610823392868042
Validation loss: 1.9986983338991802

Epoch: 6| Step: 6
Training loss: 1.078595519065857
Validation loss: 1.9430046280225117

Epoch: 6| Step: 7
Training loss: 1.0553354024887085
Validation loss: 2.002526422341665

Epoch: 6| Step: 8
Training loss: 1.5106961727142334
Validation loss: 2.061133782068888

Epoch: 6| Step: 9
Training loss: 1.059643268585205
Validation loss: 2.022294759750366

Epoch: 6| Step: 10
Training loss: 1.0026626586914062
Validation loss: 2.0203229784965515

Epoch: 6| Step: 11
Training loss: 0.8098800182342529
Validation loss: 2.01533575852712

Epoch: 6| Step: 12
Training loss: 1.1842241287231445
Validation loss: 2.023354927698771

Epoch: 6| Step: 13
Training loss: 0.48461368680000305
Validation loss: 1.98515917857488

Epoch: 117| Step: 0
Training loss: 0.8862770795822144
Validation loss: 1.9840811491012573

Epoch: 6| Step: 1
Training loss: 1.5705288648605347
Validation loss: 2.0126881202061973

Epoch: 6| Step: 2
Training loss: 0.8813243508338928
Validation loss: 2.0122750202814736

Epoch: 6| Step: 3
Training loss: 1.0407681465148926
Validation loss: 2.047864635785421

Epoch: 6| Step: 4
Training loss: 0.986639142036438
Validation loss: 2.082970360914866

Epoch: 6| Step: 5
Training loss: 1.0400303602218628
Validation loss: 2.0136223435401917

Epoch: 6| Step: 6
Training loss: 1.3304288387298584
Validation loss: 2.073553184668223

Epoch: 6| Step: 7
Training loss: 1.338730812072754
Validation loss: 2.052622139453888

Epoch: 6| Step: 8
Training loss: 1.0433290004730225
Validation loss: 2.024592101573944

Epoch: 6| Step: 9
Training loss: 0.9122899770736694
Validation loss: 1.9788118799527485

Epoch: 6| Step: 10
Training loss: 1.064819574356079
Validation loss: 2.056005597114563

Epoch: 6| Step: 11
Training loss: 1.2526676654815674
Validation loss: 2.0641636848449707

Epoch: 6| Step: 12
Training loss: 0.9676593542098999
Validation loss: 1.9959048231442769

Epoch: 6| Step: 13
Training loss: 0.8804339170455933
Validation loss: 2.025614559650421

Epoch: 118| Step: 0
Training loss: 0.7798675298690796
Validation loss: 2.03619913260142

Epoch: 6| Step: 1
Training loss: 0.47359952330589294
Validation loss: 2.0643909772237143

Epoch: 6| Step: 2
Training loss: 0.8179423809051514
Validation loss: 2.0675191283226013

Epoch: 6| Step: 3
Training loss: 0.8337628841400146
Validation loss: 2.0689532359441123

Epoch: 6| Step: 4
Training loss: 1.7343260049819946
Validation loss: 2.0530056754748025

Epoch: 6| Step: 5
Training loss: 1.4789648056030273
Validation loss: 2.039271910985311

Epoch: 6| Step: 6
Training loss: 1.9383230209350586
Validation loss: 2.028928200403849

Epoch: 6| Step: 7
Training loss: 0.9414421916007996
Validation loss: 1.9886888265609741

Epoch: 6| Step: 8
Training loss: 1.067853331565857
Validation loss: 1.9851412971814473

Epoch: 6| Step: 9
Training loss: 0.8663520812988281
Validation loss: 2.0202275117238364

Epoch: 6| Step: 10
Training loss: 0.8769336938858032
Validation loss: 2.0169085264205933

Epoch: 6| Step: 11
Training loss: 1.299293041229248
Validation loss: 2.0487258434295654

Epoch: 6| Step: 12
Training loss: 1.542743444442749
Validation loss: 2.0120790004730225

Epoch: 6| Step: 13
Training loss: 0.6601207256317139
Validation loss: 1.9936194618542988

Epoch: 119| Step: 0
Training loss: 0.595871090888977
Validation loss: 2.011086324850718

Epoch: 6| Step: 1
Training loss: 0.712516188621521
Validation loss: 2.0778463085492453

Epoch: 6| Step: 2
Training loss: 1.583585262298584
Validation loss: 2.0622403025627136

Epoch: 6| Step: 3
Training loss: 1.0620660781860352
Validation loss: 1.9922685225804646

Epoch: 6| Step: 4
Training loss: 0.9765530824661255
Validation loss: 1.9981880982716878

Epoch: 6| Step: 5
Training loss: 1.3363628387451172
Validation loss: 1.9613800843556721

Epoch: 6| Step: 6
Training loss: 0.5469347238540649
Validation loss: 2.010892411073049

Epoch: 6| Step: 7
Training loss: 1.0442694425582886
Validation loss: 1.9930580457051594

Epoch: 6| Step: 8
Training loss: 1.5321511030197144
Validation loss: 1.9843199650446575

Epoch: 6| Step: 9
Training loss: 1.1129399538040161
Validation loss: 1.9729466438293457

Epoch: 6| Step: 10
Training loss: 1.035745620727539
Validation loss: 1.973867952823639

Epoch: 6| Step: 11
Training loss: 0.6831016540527344
Validation loss: 2.024476190408071

Epoch: 6| Step: 12
Training loss: 0.9891479015350342
Validation loss: 2.0192614595095315

Epoch: 6| Step: 13
Training loss: 1.3221240043640137
Validation loss: 1.975926399230957

Epoch: 120| Step: 0
Training loss: 1.0367470979690552
Validation loss: 2.025193194548289

Epoch: 6| Step: 1
Training loss: 1.1026216745376587
Validation loss: 2.041561186313629

Epoch: 6| Step: 2
Training loss: 0.6710085868835449
Validation loss: 2.001828610897064

Epoch: 6| Step: 3
Training loss: 1.0136487483978271
Validation loss: 1.9969129363695781

Epoch: 6| Step: 4
Training loss: 0.9989641904830933
Validation loss: 2.0249929428100586

Epoch: 6| Step: 5
Training loss: 1.0688376426696777
Validation loss: 1.9530794223149617

Epoch: 6| Step: 6
Training loss: 1.039643406867981
Validation loss: 1.9800262451171875

Epoch: 6| Step: 7
Training loss: 1.211637258529663
Validation loss: 2.041352609793345

Epoch: 6| Step: 8
Training loss: 0.9583889842033386
Validation loss: 1.978937824567159

Epoch: 6| Step: 9
Training loss: 1.171910047531128
Validation loss: 1.9517586628595989

Epoch: 6| Step: 10
Training loss: 1.2033777236938477
Validation loss: 2.017723004023234

Epoch: 6| Step: 11
Training loss: 1.0101336240768433
Validation loss: 2.0163702170054116

Epoch: 6| Step: 12
Training loss: 1.2583415508270264
Validation loss: 1.9878286719322205

Epoch: 6| Step: 13
Training loss: 0.8038967847824097
Validation loss: 1.9538894891738892

Epoch: 121| Step: 0
Training loss: 0.8071171641349792
Validation loss: 1.9761375387509663

Epoch: 6| Step: 1
Training loss: 0.7556617259979248
Validation loss: 1.960666835308075

Epoch: 6| Step: 2
Training loss: 1.3136181831359863
Validation loss: 1.9801737070083618

Epoch: 6| Step: 3
Training loss: 1.0658513307571411
Validation loss: 1.9933210810025532

Epoch: 6| Step: 4
Training loss: 1.4144542217254639
Validation loss: 2.0309146642684937

Epoch: 6| Step: 5
Training loss: 1.1401619911193848
Validation loss: 1.9713149666786194

Epoch: 6| Step: 6
Training loss: 0.5489641427993774
Validation loss: 1.9970142046610515

Epoch: 6| Step: 7
Training loss: 0.9149772524833679
Validation loss: 1.926077703634898

Epoch: 6| Step: 8
Training loss: 1.1901906728744507
Validation loss: 2.012861907482147

Epoch: 6| Step: 9
Training loss: 0.7615370750427246
Validation loss: 1.988093376159668

Epoch: 6| Step: 10
Training loss: 0.7952477931976318
Validation loss: 2.026793897151947

Epoch: 6| Step: 11
Training loss: 1.1040875911712646
Validation loss: 2.003303567568461

Epoch: 6| Step: 12
Training loss: 1.0677974224090576
Validation loss: 1.9809631903966267

Epoch: 6| Step: 13
Training loss: 1.0322835445404053
Validation loss: 2.00375097990036

Epoch: 122| Step: 0
Training loss: 1.188859224319458
Validation loss: 1.9671454032262166

Epoch: 6| Step: 1
Training loss: 0.7817564010620117
Validation loss: 1.9857651392618816

Epoch: 6| Step: 2
Training loss: 1.1260604858398438
Validation loss: 2.0371985832850137

Epoch: 6| Step: 3
Training loss: 0.7571296691894531
Validation loss: 2.000464995702108

Epoch: 6| Step: 4
Training loss: 0.8086389303207397
Validation loss: 1.9802122910817463

Epoch: 6| Step: 5
Training loss: 0.9466774463653564
Validation loss: 2.059713304042816

Epoch: 6| Step: 6
Training loss: 1.0149667263031006
Validation loss: 2.0117610494295755

Epoch: 6| Step: 7
Training loss: 0.8333196640014648
Validation loss: 1.9447421431541443

Epoch: 6| Step: 8
Training loss: 0.7654179334640503
Validation loss: 1.983285089333852

Epoch: 6| Step: 9
Training loss: 1.3326882123947144
Validation loss: 1.9583190480868022

Epoch: 6| Step: 10
Training loss: 1.089451789855957
Validation loss: 2.012558877468109

Epoch: 6| Step: 11
Training loss: 0.9768329858779907
Validation loss: 2.001146654287974

Epoch: 6| Step: 12
Training loss: 1.6234627962112427
Validation loss: 1.9908036788304646

Epoch: 6| Step: 13
Training loss: 0.9300767779350281
Validation loss: 2.0360778172810874

Epoch: 123| Step: 0
Training loss: 2.0267114639282227
Validation loss: 1.983968993028005

Epoch: 6| Step: 1
Training loss: 1.1434913873672485
Validation loss: 2.034627377986908

Epoch: 6| Step: 2
Training loss: 1.0602353811264038
Validation loss: 1.9782399733861287

Epoch: 6| Step: 3
Training loss: 1.2759824991226196
Validation loss: 1.948490063349406

Epoch: 6| Step: 4
Training loss: 1.009438395500183
Validation loss: 1.982332666714986

Epoch: 6| Step: 5
Training loss: 0.9935311675071716
Validation loss: 1.9695738156636555

Epoch: 6| Step: 6
Training loss: 0.9758655428886414
Validation loss: 2.0029165744781494

Epoch: 6| Step: 7
Training loss: 0.9597324728965759
Validation loss: 1.9967721104621887

Epoch: 6| Step: 8
Training loss: 0.7091227769851685
Validation loss: 1.9886756738026936

Epoch: 6| Step: 9
Training loss: 1.0080738067626953
Validation loss: 1.9877529541651409

Epoch: 6| Step: 10
Training loss: 1.1763739585876465
Validation loss: 1.9947824478149414

Epoch: 6| Step: 11
Training loss: 0.5658212900161743
Validation loss: 1.9536274075508118

Epoch: 6| Step: 12
Training loss: 0.7278525829315186
Validation loss: 1.9694705208142598

Epoch: 6| Step: 13
Training loss: 0.774870753288269
Validation loss: 1.9832441806793213

Epoch: 124| Step: 0
Training loss: 0.7551093697547913
Validation loss: 2.0442320505777993

Epoch: 6| Step: 1
Training loss: 0.8864535689353943
Validation loss: 1.9919844071070354

Epoch: 6| Step: 2
Training loss: 1.0714335441589355
Validation loss: 2.0026161670684814

Epoch: 6| Step: 3
Training loss: 1.1468288898468018
Validation loss: 2.0216610630353293

Epoch: 6| Step: 4
Training loss: 0.8574094176292419
Validation loss: 2.006080210208893

Epoch: 6| Step: 5
Training loss: 1.0481531620025635
Validation loss: 1.9505970080693562

Epoch: 6| Step: 6
Training loss: 1.505981683731079
Validation loss: 1.986068844795227

Epoch: 6| Step: 7
Training loss: 1.2527809143066406
Validation loss: 2.0079442461331687

Epoch: 6| Step: 8
Training loss: 1.0063238143920898
Validation loss: 2.001529256502787

Epoch: 6| Step: 9
Training loss: 0.7114155888557434
Validation loss: 1.9920159180959065

Epoch: 6| Step: 10
Training loss: 1.1616039276123047
Validation loss: 1.953475534915924

Epoch: 6| Step: 11
Training loss: 0.9168106317520142
Validation loss: 1.9562735358874004

Epoch: 6| Step: 12
Training loss: 0.5487052202224731
Validation loss: 1.9568423827489216

Epoch: 6| Step: 13
Training loss: 0.8809483051300049
Validation loss: 1.977272351582845

Epoch: 125| Step: 0
Training loss: 0.7540246248245239
Validation loss: 1.9772561192512512

Epoch: 6| Step: 1
Training loss: 1.2727036476135254
Validation loss: 1.992689351240794

Epoch: 6| Step: 2
Training loss: 0.6982503533363342
Validation loss: 1.984845479329427

Epoch: 6| Step: 3
Training loss: 0.6060647964477539
Validation loss: 2.0054202874501548

Epoch: 6| Step: 4
Training loss: 0.7693778276443481
Validation loss: 1.9974894722302754

Epoch: 6| Step: 5
Training loss: 1.037438988685608
Validation loss: 2.00655206044515

Epoch: 6| Step: 6
Training loss: 1.0348289012908936
Validation loss: 2.009990096092224

Epoch: 6| Step: 7
Training loss: 1.6080758571624756
Validation loss: 2.0418827335039773

Epoch: 6| Step: 8
Training loss: 0.6380503177642822
Validation loss: 2.021526445945104

Epoch: 6| Step: 9
Training loss: 1.200732707977295
Validation loss: 1.9614604115486145

Epoch: 6| Step: 10
Training loss: 1.1770238876342773
Validation loss: 2.066045423348745

Epoch: 6| Step: 11
Training loss: 0.974937915802002
Validation loss: 2.0000338554382324

Epoch: 6| Step: 12
Training loss: 1.3133797645568848
Validation loss: 1.9936545689900715

Epoch: 6| Step: 13
Training loss: 1.0968196392059326
Validation loss: 2.0011507471402488

Epoch: 126| Step: 0
Training loss: 1.2315762042999268
Validation loss: 2.028876801331838

Epoch: 6| Step: 1
Training loss: 0.9715303182601929
Validation loss: 1.9959363341331482

Epoch: 6| Step: 2
Training loss: 0.574388861656189
Validation loss: 1.949972649415334

Epoch: 6| Step: 3
Training loss: 0.8713134527206421
Validation loss: 2.0142956574757895

Epoch: 6| Step: 4
Training loss: 1.6281299591064453
Validation loss: 1.9944257537523906

Epoch: 6| Step: 5
Training loss: 0.8339510560035706
Validation loss: 2.0583357413609824

Epoch: 6| Step: 6
Training loss: 0.873233437538147
Validation loss: 1.9875202775001526

Epoch: 6| Step: 7
Training loss: 0.8516035079956055
Validation loss: 1.9559914072354634

Epoch: 6| Step: 8
Training loss: 1.5281383991241455
Validation loss: 2.0447561740875244

Epoch: 6| Step: 9
Training loss: 0.43629759550094604
Validation loss: 1.9480338493982952

Epoch: 6| Step: 10
Training loss: 0.8224939107894897
Validation loss: 1.9985311230023701

Epoch: 6| Step: 11
Training loss: 0.45084235072135925
Validation loss: 1.9654072324434917

Epoch: 6| Step: 12
Training loss: 1.0560036897659302
Validation loss: 2.0058443943659463

Epoch: 6| Step: 13
Training loss: 1.2654037475585938
Validation loss: 1.9727484583854675

Epoch: 127| Step: 0
Training loss: 0.7327505350112915
Validation loss: 1.9737916588783264

Epoch: 6| Step: 1
Training loss: 1.29270601272583
Validation loss: 1.95758984486262

Epoch: 6| Step: 2
Training loss: 1.154332160949707
Validation loss: 1.9995088179906209

Epoch: 6| Step: 3
Training loss: 1.3591420650482178
Validation loss: 1.9740154941876729

Epoch: 6| Step: 4
Training loss: 0.6486520171165466
Validation loss: 2.001178046067556

Epoch: 6| Step: 5
Training loss: 1.0871913433074951
Validation loss: 1.9459122021993

Epoch: 6| Step: 6
Training loss: 0.874525785446167
Validation loss: 1.981084167957306

Epoch: 6| Step: 7
Training loss: 1.2765161991119385
Validation loss: 2.022705932458242

Epoch: 6| Step: 8
Training loss: 0.9797461032867432
Validation loss: 2.0245492855707803

Epoch: 6| Step: 9
Training loss: 0.48681285977363586
Validation loss: 2.053041617075602

Epoch: 6| Step: 10
Training loss: 0.8862935304641724
Validation loss: 1.939503788948059

Epoch: 6| Step: 11
Training loss: 0.574432909488678
Validation loss: 2.010853389898936

Epoch: 6| Step: 12
Training loss: 0.8460391759872437
Validation loss: 2.0542611877123513

Epoch: 6| Step: 13
Training loss: 0.8268889784812927
Validation loss: 1.9877484639485676

Epoch: 128| Step: 0
Training loss: 0.858154296875
Validation loss: 1.9806971152623494

Epoch: 6| Step: 1
Training loss: 0.803348183631897
Validation loss: 1.9849136869112651

Epoch: 6| Step: 2
Training loss: 1.3345668315887451
Validation loss: 2.021036922931671

Epoch: 6| Step: 3
Training loss: 1.2877269983291626
Validation loss: 1.9526941974957783

Epoch: 6| Step: 4
Training loss: 1.2885754108428955
Validation loss: 2.020141859849294

Epoch: 6| Step: 5
Training loss: 1.3585553169250488
Validation loss: 1.9818397363026936

Epoch: 6| Step: 6
Training loss: 0.9488829374313354
Validation loss: 2.0147798458735147

Epoch: 6| Step: 7
Training loss: 0.3509265184402466
Validation loss: 1.981804092725118

Epoch: 6| Step: 8
Training loss: 0.8373439908027649
Validation loss: 2.025529940923055

Epoch: 6| Step: 9
Training loss: 0.5198451280593872
Validation loss: 1.984221080938975

Epoch: 6| Step: 10
Training loss: 1.168128252029419
Validation loss: 2.0345356464385986

Epoch: 6| Step: 11
Training loss: 0.6628463268280029
Validation loss: 2.062299688657125

Epoch: 6| Step: 12
Training loss: 0.6956567764282227
Validation loss: 1.9937397837638855

Epoch: 6| Step: 13
Training loss: 0.7723084092140198
Validation loss: 1.9896545608838399

Epoch: 129| Step: 0
Training loss: 0.6977256536483765
Validation loss: 2.0062901178995767

Epoch: 6| Step: 1
Training loss: 1.147451639175415
Validation loss: 1.9541414777437847

Epoch: 6| Step: 2
Training loss: 0.9857404232025146
Validation loss: 1.9618348876635234

Epoch: 6| Step: 3
Training loss: 0.8886289000511169
Validation loss: 1.9741185307502747

Epoch: 6| Step: 4
Training loss: 1.011976957321167
Validation loss: 1.961757481098175

Epoch: 6| Step: 5
Training loss: 1.1484534740447998
Validation loss: 1.9737449288368225

Epoch: 6| Step: 6
Training loss: 0.7015361785888672
Validation loss: 1.9947617252667744

Epoch: 6| Step: 7
Training loss: 0.5072685480117798
Validation loss: 2.001099626223246

Epoch: 6| Step: 8
Training loss: 0.9392169713973999
Validation loss: 1.9967595140139263

Epoch: 6| Step: 9
Training loss: 1.341062068939209
Validation loss: 1.9761582811673482

Epoch: 6| Step: 10
Training loss: 0.9132576584815979
Validation loss: 1.9182721376419067

Epoch: 6| Step: 11
Training loss: 1.0328201055526733
Validation loss: 1.9719703197479248

Epoch: 6| Step: 12
Training loss: 0.7850639820098877
Validation loss: 2.017470677693685

Epoch: 6| Step: 13
Training loss: 0.7274628281593323
Validation loss: 1.9521950284639995

Epoch: 130| Step: 0
Training loss: 0.8216215372085571
Validation loss: 1.960161606470744

Epoch: 6| Step: 1
Training loss: 1.0730491876602173
Validation loss: 1.98658021291097

Epoch: 6| Step: 2
Training loss: 0.663535475730896
Validation loss: 2.0628105799357095

Epoch: 6| Step: 3
Training loss: 0.8788642287254333
Validation loss: 1.9836568236351013

Epoch: 6| Step: 4
Training loss: 1.0466724634170532
Validation loss: 1.9145130316416423

Epoch: 6| Step: 5
Training loss: 0.8076733350753784
Validation loss: 1.9311703244845073

Epoch: 6| Step: 6
Training loss: 0.8951849937438965
Validation loss: 2.002510209878286

Epoch: 6| Step: 7
Training loss: 0.7959330081939697
Validation loss: 2.0310475627581277

Epoch: 6| Step: 8
Training loss: 1.14080011844635
Validation loss: 2.0511028170585632

Epoch: 6| Step: 9
Training loss: 1.1011897325515747
Validation loss: 2.014233112335205

Epoch: 6| Step: 10
Training loss: 0.8150471448898315
Validation loss: 2.00905833641688

Epoch: 6| Step: 11
Training loss: 1.1539125442504883
Validation loss: 2.028598507245382

Epoch: 6| Step: 12
Training loss: 1.2867481708526611
Validation loss: 1.9535642266273499

Epoch: 6| Step: 13
Training loss: 1.2845368385314941
Validation loss: 1.9635204076766968

Epoch: 131| Step: 0
Training loss: 1.6726841926574707
Validation loss: 1.979766050974528

Epoch: 6| Step: 1
Training loss: 0.8943296670913696
Validation loss: 1.978749930858612

Epoch: 6| Step: 2
Training loss: 0.6787425875663757
Validation loss: 1.9883480469385784

Epoch: 6| Step: 3
Training loss: 1.5540435314178467
Validation loss: 1.9551788568496704

Epoch: 6| Step: 4
Training loss: 0.7625299096107483
Validation loss: 1.9440565903981526

Epoch: 6| Step: 5
Training loss: 0.8039216995239258
Validation loss: 2.02412478129069

Epoch: 6| Step: 6
Training loss: 0.5781601667404175
Validation loss: 1.9582029779752095

Epoch: 6| Step: 7
Training loss: 0.8627276420593262
Validation loss: 2.007592717806498

Epoch: 6| Step: 8
Training loss: 0.7005826234817505
Validation loss: 2.0185795426368713

Epoch: 6| Step: 9
Training loss: 0.5373184084892273
Validation loss: 1.9958509405454

Epoch: 6| Step: 10
Training loss: 0.842082142829895
Validation loss: 1.9453078905741374

Epoch: 6| Step: 11
Training loss: 1.276823878288269
Validation loss: 1.998432457447052

Epoch: 6| Step: 12
Training loss: 1.1998648643493652
Validation loss: 1.9704576929410298

Epoch: 6| Step: 13
Training loss: 1.1070650815963745
Validation loss: 1.9648178021113079

Epoch: 132| Step: 0
Training loss: 0.6301543116569519
Validation loss: 1.9404571056365967

Epoch: 6| Step: 1
Training loss: 1.299513816833496
Validation loss: 1.9541073242823284

Epoch: 6| Step: 2
Training loss: 0.7379105687141418
Validation loss: 2.0129936138788858

Epoch: 6| Step: 3
Training loss: 1.006455659866333
Validation loss: 1.9889674385388691

Epoch: 6| Step: 4
Training loss: 0.917322039604187
Validation loss: 1.9913535912831624

Epoch: 6| Step: 5
Training loss: 1.2471842765808105
Validation loss: 1.9891539017359416

Epoch: 6| Step: 6
Training loss: 0.8166847229003906
Validation loss: 1.9488226572672527

Epoch: 6| Step: 7
Training loss: 1.2371585369110107
Validation loss: 2.0238030552864075

Epoch: 6| Step: 8
Training loss: 0.6502339243888855
Validation loss: 1.9359195828437805

Epoch: 6| Step: 9
Training loss: 1.254387617111206
Validation loss: 1.9605717460314434

Epoch: 6| Step: 10
Training loss: 0.867857813835144
Validation loss: 1.9717735648155212

Epoch: 6| Step: 11
Training loss: 0.5152835845947266
Validation loss: 1.988896369934082

Epoch: 6| Step: 12
Training loss: 1.2251572608947754
Validation loss: 1.9591584006945293

Epoch: 6| Step: 13
Training loss: 0.8102236986160278
Validation loss: 1.9509246746699016

Epoch: 133| Step: 0
Training loss: 1.1549904346466064
Validation loss: 1.9693273305892944

Epoch: 6| Step: 1
Training loss: 0.7507210969924927
Validation loss: 1.9316898385683696

Epoch: 6| Step: 2
Training loss: 0.6307564973831177
Validation loss: 1.921112835407257

Epoch: 6| Step: 3
Training loss: 1.0968173742294312
Validation loss: 1.9727009137471516

Epoch: 6| Step: 4
Training loss: 0.9721496105194092
Validation loss: 1.9493582646052043

Epoch: 6| Step: 5
Training loss: 0.5955469012260437
Validation loss: 2.0004793405532837

Epoch: 6| Step: 6
Training loss: 0.8508177399635315
Validation loss: 1.9701944788297017

Epoch: 6| Step: 7
Training loss: 0.7842283844947815
Validation loss: 1.9668227036794026

Epoch: 6| Step: 8
Training loss: 0.9334181547164917
Validation loss: 2.028033892313639

Epoch: 6| Step: 9
Training loss: 0.7229554057121277
Validation loss: 2.012112816174825

Epoch: 6| Step: 10
Training loss: 1.3120875358581543
Validation loss: 1.9660820364952087

Epoch: 6| Step: 11
Training loss: 1.117544174194336
Validation loss: 1.9831692576408386

Epoch: 6| Step: 12
Training loss: 0.3239671587944031
Validation loss: 2.008512318134308

Epoch: 6| Step: 13
Training loss: 0.9370179772377014
Validation loss: 1.9789344867070515

Epoch: 134| Step: 0
Training loss: 1.2200531959533691
Validation loss: 1.9588992595672607

Epoch: 6| Step: 1
Training loss: 0.4025413393974304
Validation loss: 1.9482589761416118

Epoch: 6| Step: 2
Training loss: 0.6170105934143066
Validation loss: 1.9475279649098713

Epoch: 6| Step: 3
Training loss: 1.1296885013580322
Validation loss: 1.939544439315796

Epoch: 6| Step: 4
Training loss: 1.0213127136230469
Validation loss: 1.975168804327647

Epoch: 6| Step: 5
Training loss: 0.6414487957954407
Validation loss: 1.9743804732958476

Epoch: 6| Step: 6
Training loss: 0.9246172904968262
Validation loss: 1.9876715143521626

Epoch: 6| Step: 7
Training loss: 0.6294487714767456
Validation loss: 1.9873332182566326

Epoch: 6| Step: 8
Training loss: 1.274397611618042
Validation loss: 1.9584143956502278

Epoch: 6| Step: 9
Training loss: 1.0443391799926758
Validation loss: 1.9941743612289429

Epoch: 6| Step: 10
Training loss: 0.8021997213363647
Validation loss: 1.9703932603200276

Epoch: 6| Step: 11
Training loss: 0.6990665197372437
Validation loss: 1.9479058782259624

Epoch: 6| Step: 12
Training loss: 0.7699829936027527
Validation loss: 2.001875718434652

Epoch: 6| Step: 13
Training loss: 0.7267547249794006
Validation loss: 1.993294358253479

Epoch: 135| Step: 0
Training loss: 1.0374864339828491
Validation loss: 1.9602761069933574

Epoch: 6| Step: 1
Training loss: 1.4849580526351929
Validation loss: 1.9317405422528584

Epoch: 6| Step: 2
Training loss: 1.1469638347625732
Validation loss: 1.9664720296859741

Epoch: 6| Step: 3
Training loss: 0.707595944404602
Validation loss: 2.002053380012512

Epoch: 6| Step: 4
Training loss: 0.5668549537658691
Validation loss: 1.9346149961153667

Epoch: 6| Step: 5
Training loss: 0.6974925994873047
Validation loss: 1.9917571942011516

Epoch: 6| Step: 6
Training loss: 0.8839685320854187
Validation loss: 1.9910214344660442

Epoch: 6| Step: 7
Training loss: 0.6542156934738159
Validation loss: 1.9495225350062053

Epoch: 6| Step: 8
Training loss: 0.6622727513313293
Validation loss: 1.9437082012494404

Epoch: 6| Step: 9
Training loss: 0.9803608059883118
Validation loss: 2.009481052557627

Epoch: 6| Step: 10
Training loss: 1.351667881011963
Validation loss: 1.9414666295051575

Epoch: 6| Step: 11
Training loss: 1.05307936668396
Validation loss: 1.9418804446856182

Epoch: 6| Step: 12
Training loss: 0.48877403140068054
Validation loss: 1.9327820738156636

Epoch: 6| Step: 13
Training loss: 0.4577716886997223
Validation loss: 1.954188386599223

Epoch: 136| Step: 0
Training loss: 0.6020416617393494
Validation loss: 1.9411506652832031

Epoch: 6| Step: 1
Training loss: 1.0532174110412598
Validation loss: 1.947352369626363

Epoch: 6| Step: 2
Training loss: 0.5463979244232178
Validation loss: 1.9539569020271301

Epoch: 6| Step: 3
Training loss: 1.1641308069229126
Validation loss: 1.9277830123901367

Epoch: 6| Step: 4
Training loss: 0.7364717125892639
Validation loss: 1.9556613365809123

Epoch: 6| Step: 5
Training loss: 0.72565758228302
Validation loss: 1.9725798964500427

Epoch: 6| Step: 6
Training loss: 0.7784600257873535
Validation loss: 1.9705349604288738

Epoch: 6| Step: 7
Training loss: 0.8303064107894897
Validation loss: 1.9295990268389385

Epoch: 6| Step: 8
Training loss: 1.5135173797607422
Validation loss: 1.96425195535024

Epoch: 6| Step: 9
Training loss: 0.8202741742134094
Validation loss: 1.970395823319753

Epoch: 6| Step: 10
Training loss: 1.1855714321136475
Validation loss: 1.9475247462590535

Epoch: 6| Step: 11
Training loss: 0.572719931602478
Validation loss: 1.9644285241762798

Epoch: 6| Step: 12
Training loss: 0.6903467774391174
Validation loss: 1.9522252480189006

Epoch: 6| Step: 13
Training loss: 0.6570539474487305
Validation loss: 1.9523239533106487

Epoch: 137| Step: 0
Training loss: 1.1457552909851074
Validation loss: 1.9890533288319905

Epoch: 6| Step: 1
Training loss: 1.0277868509292603
Validation loss: 1.9838860829671223

Epoch: 6| Step: 2
Training loss: 1.02017343044281
Validation loss: 1.9551264643669128

Epoch: 6| Step: 3
Training loss: 0.48350828886032104
Validation loss: 1.9878716468811035

Epoch: 6| Step: 4
Training loss: 1.0779284238815308
Validation loss: 1.9718170166015625

Epoch: 6| Step: 5
Training loss: 0.6716705560684204
Validation loss: 1.9204660058021545

Epoch: 6| Step: 6
Training loss: 0.6690085530281067
Validation loss: 1.9326553146044414

Epoch: 6| Step: 7
Training loss: 1.4562106132507324
Validation loss: 1.9134736855824788

Epoch: 6| Step: 8
Training loss: 1.3632781505584717
Validation loss: 1.9415037631988525

Epoch: 6| Step: 9
Training loss: 0.9134036302566528
Validation loss: 1.9635283748308818

Epoch: 6| Step: 10
Training loss: 0.6397953033447266
Validation loss: 1.949701984723409

Epoch: 6| Step: 11
Training loss: 0.47640785574913025
Validation loss: 1.9204765955607097

Epoch: 6| Step: 12
Training loss: 0.7624973654747009
Validation loss: 1.963447908560435

Epoch: 6| Step: 13
Training loss: 1.054196834564209
Validation loss: 1.931918442249298

Epoch: 138| Step: 0
Training loss: 1.506324052810669
Validation loss: 1.9220800002415974

Epoch: 6| Step: 1
Training loss: 0.7598730325698853
Validation loss: 1.9442979097366333

Epoch: 6| Step: 2
Training loss: 0.49983471632003784
Validation loss: 1.965459406375885

Epoch: 6| Step: 3
Training loss: 0.48429369926452637
Validation loss: 1.9732285340627034

Epoch: 6| Step: 4
Training loss: 0.9076803922653198
Validation loss: 1.9545620481173198

Epoch: 6| Step: 5
Training loss: 0.7435609102249146
Validation loss: 1.9438226421674092

Epoch: 6| Step: 6
Training loss: 0.683992862701416
Validation loss: 2.0022376577059426

Epoch: 6| Step: 7
Training loss: 1.2641303539276123
Validation loss: 1.9115121761957805

Epoch: 6| Step: 8
Training loss: 0.599780261516571
Validation loss: 2.0001126329104104

Epoch: 6| Step: 9
Training loss: 0.4466645121574402
Validation loss: 1.9837782581647236

Epoch: 6| Step: 10
Training loss: 0.881379246711731
Validation loss: 1.934875746568044

Epoch: 6| Step: 11
Training loss: 0.8470829725265503
Validation loss: 1.94417405128479

Epoch: 6| Step: 12
Training loss: 1.2399625778198242
Validation loss: 1.9687046806017559

Epoch: 6| Step: 13
Training loss: 0.8545480966567993
Validation loss: 1.9256818095842998

Epoch: 139| Step: 0
Training loss: 0.43940508365631104
Validation loss: 1.9324968854586284

Epoch: 6| Step: 1
Training loss: 0.9550955295562744
Validation loss: 1.9290069937705994

Epoch: 6| Step: 2
Training loss: 0.5495021343231201
Validation loss: 1.8949392437934875

Epoch: 6| Step: 3
Training loss: 0.5399990677833557
Validation loss: 2.025433083375295

Epoch: 6| Step: 4
Training loss: 0.9719852805137634
Validation loss: 1.921765108903249

Epoch: 6| Step: 5
Training loss: 0.7705975770950317
Validation loss: 1.9389669100443523

Epoch: 6| Step: 6
Training loss: 0.7006688117980957
Validation loss: 1.95053897301356

Epoch: 6| Step: 7
Training loss: 1.5750148296356201
Validation loss: 1.9424151976903279

Epoch: 6| Step: 8
Training loss: 1.158333420753479
Validation loss: 1.9533504446347554

Epoch: 6| Step: 9
Training loss: 0.5759226083755493
Validation loss: 1.9069093664487202

Epoch: 6| Step: 10
Training loss: 0.8761802315711975
Validation loss: 1.9779244860013325

Epoch: 6| Step: 11
Training loss: 0.8238914608955383
Validation loss: 1.965886612733205

Epoch: 6| Step: 12
Training loss: 0.8369503021240234
Validation loss: 1.9538848201433818

Epoch: 6| Step: 13
Training loss: 0.8575893640518188
Validation loss: 1.9658146699269612

Epoch: 140| Step: 0
Training loss: 0.5852419137954712
Validation loss: 1.9225049217542012

Epoch: 6| Step: 1
Training loss: 1.1863062381744385
Validation loss: 1.961004912853241

Epoch: 6| Step: 2
Training loss: 0.6748248338699341
Validation loss: 1.9514652291933696

Epoch: 6| Step: 3
Training loss: 0.455617755651474
Validation loss: 1.9411853750546773

Epoch: 6| Step: 4
Training loss: 0.5029278993606567
Validation loss: 1.9646584192911785

Epoch: 6| Step: 5
Training loss: 0.5922541618347168
Validation loss: 1.9153066078821819

Epoch: 6| Step: 6
Training loss: 1.0879077911376953
Validation loss: 1.9305179715156555

Epoch: 6| Step: 7
Training loss: 0.947324812412262
Validation loss: 1.9284789562225342

Epoch: 6| Step: 8
Training loss: 0.8921669721603394
Validation loss: 1.9704797267913818

Epoch: 6| Step: 9
Training loss: 0.9971835613250732
Validation loss: 1.9860274195671082

Epoch: 6| Step: 10
Training loss: 0.7142313718795776
Validation loss: 1.9058707753817241

Epoch: 6| Step: 11
Training loss: 0.5519915819168091
Validation loss: 1.9556458791097004

Epoch: 6| Step: 12
Training loss: 1.2214123010635376
Validation loss: 1.9403800964355469

Epoch: 6| Step: 13
Training loss: 1.103072166442871
Validation loss: 1.9228170315424602

Epoch: 141| Step: 0
Training loss: 0.6890761852264404
Validation loss: 1.9231439630190532

Epoch: 6| Step: 1
Training loss: 0.8292199373245239
Validation loss: 1.9750361442565918

Epoch: 6| Step: 2
Training loss: 1.1844290494918823
Validation loss: 1.9301435351371765

Epoch: 6| Step: 3
Training loss: 0.9960297346115112
Validation loss: 1.898380974928538

Epoch: 6| Step: 4
Training loss: 0.5380121469497681
Validation loss: 1.9166474143664043

Epoch: 6| Step: 5
Training loss: 0.5743222236633301
Validation loss: 1.8966057499249775

Epoch: 6| Step: 6
Training loss: 0.9998742341995239
Validation loss: 1.9756226936976116

Epoch: 6| Step: 7
Training loss: 0.6225904226303101
Validation loss: 1.9078718622525532

Epoch: 6| Step: 8
Training loss: 0.5683979988098145
Validation loss: 1.8977748950322468

Epoch: 6| Step: 9
Training loss: 0.7844563722610474
Validation loss: 1.924432357152303

Epoch: 6| Step: 10
Training loss: 0.45012199878692627
Validation loss: 1.9288243651390076

Epoch: 6| Step: 11
Training loss: 0.877321720123291
Validation loss: 1.9967926740646362

Epoch: 6| Step: 12
Training loss: 0.9305598139762878
Validation loss: 1.92088383436203

Epoch: 6| Step: 13
Training loss: 1.0778125524520874
Validation loss: 1.9658946593602498

Epoch: 142| Step: 0
Training loss: 1.133358359336853
Validation loss: 1.9114360411961873

Epoch: 6| Step: 1
Training loss: 0.5290741920471191
Validation loss: 1.9923498431841533

Epoch: 6| Step: 2
Training loss: 0.8396986126899719
Validation loss: 1.9307798345883687

Epoch: 6| Step: 3
Training loss: 0.9745402336120605
Validation loss: 1.9488864342371623

Epoch: 6| Step: 4
Training loss: 0.973343014717102
Validation loss: 1.9682693282763164

Epoch: 6| Step: 5
Training loss: 1.0235035419464111
Validation loss: 1.884670078754425

Epoch: 6| Step: 6
Training loss: 0.775597095489502
Validation loss: 1.9438016613324482

Epoch: 6| Step: 7
Training loss: 0.630775511264801
Validation loss: 1.9117185076077778

Epoch: 6| Step: 8
Training loss: 0.9938639998435974
Validation loss: 1.951375404993693

Epoch: 6| Step: 9
Training loss: 0.671334445476532
Validation loss: 1.9009277025858562

Epoch: 6| Step: 10
Training loss: 0.8831080198287964
Validation loss: 1.93068261941274

Epoch: 6| Step: 11
Training loss: 0.7185461521148682
Validation loss: 1.9538923899332683

Epoch: 6| Step: 12
Training loss: 0.6665325164794922
Validation loss: 1.9761702020963032

Epoch: 6| Step: 13
Training loss: 0.7280182242393494
Validation loss: 1.9404616157213848

Epoch: 143| Step: 0
Training loss: 0.678511917591095
Validation loss: 1.9211040536562602

Epoch: 6| Step: 1
Training loss: 0.9760568737983704
Validation loss: 1.9508630832036336

Epoch: 6| Step: 2
Training loss: 1.0720553398132324
Validation loss: 1.9218605756759644

Epoch: 6| Step: 3
Training loss: 0.6083359718322754
Validation loss: 1.943122665087382

Epoch: 6| Step: 4
Training loss: 0.38131123781204224
Validation loss: 1.9569079677263896

Epoch: 6| Step: 5
Training loss: 0.5773348808288574
Validation loss: 1.8955820798873901

Epoch: 6| Step: 6
Training loss: 1.016526699066162
Validation loss: 1.9321144819259644

Epoch: 6| Step: 7
Training loss: 0.7356376647949219
Validation loss: 1.9778599739074707

Epoch: 6| Step: 8
Training loss: 0.8805376887321472
Validation loss: 1.988214870293935

Epoch: 6| Step: 9
Training loss: 0.9456926584243774
Validation loss: 1.9680436253547668

Epoch: 6| Step: 10
Training loss: 0.9128546714782715
Validation loss: 1.99180006980896

Epoch: 6| Step: 11
Training loss: 0.9202303886413574
Validation loss: 1.9699423511823018

Epoch: 6| Step: 12
Training loss: 0.9339443445205688
Validation loss: 1.930613895257314

Epoch: 6| Step: 13
Training loss: 0.45368692278862
Validation loss: 1.9847001830736797

Epoch: 144| Step: 0
Training loss: 0.4652911424636841
Validation loss: 1.9199097553888957

Epoch: 6| Step: 1
Training loss: 0.8130213022232056
Validation loss: 1.9815724690755208

Epoch: 6| Step: 2
Training loss: 0.5957335233688354
Validation loss: 1.9983679056167603

Epoch: 6| Step: 3
Training loss: 0.8537596464157104
Validation loss: 1.9401494065920513

Epoch: 6| Step: 4
Training loss: 1.234919786453247
Validation loss: 1.937515914440155

Epoch: 6| Step: 5
Training loss: 1.0402475595474243
Validation loss: 1.9035476446151733

Epoch: 6| Step: 6
Training loss: 0.49347805976867676
Validation loss: 1.9729624390602112

Epoch: 6| Step: 7
Training loss: 0.9864258766174316
Validation loss: 1.95809272925059

Epoch: 6| Step: 8
Training loss: 0.996048629283905
Validation loss: 1.9523276289304097

Epoch: 6| Step: 9
Training loss: 0.26794493198394775
Validation loss: 2.0170940160751343

Epoch: 6| Step: 10
Training loss: 0.4977834224700928
Validation loss: 1.9286672075589497

Epoch: 6| Step: 11
Training loss: 0.590948760509491
Validation loss: 1.9553399483362834

Epoch: 6| Step: 12
Training loss: 0.4209952652454376
Validation loss: 1.940507213274638

Epoch: 6| Step: 13
Training loss: 1.3252854347229004
Validation loss: 1.9401057958602905

Epoch: 145| Step: 0
Training loss: 0.8093255162239075
Validation loss: 1.9481321374575298

Epoch: 6| Step: 1
Training loss: 0.4172700047492981
Validation loss: 1.9735784729321797

Epoch: 6| Step: 2
Training loss: 0.955369234085083
Validation loss: 1.9609108765920003

Epoch: 6| Step: 3
Training loss: 1.0813120603561401
Validation loss: 1.9875245491663616

Epoch: 6| Step: 4
Training loss: 0.5803853869438171
Validation loss: 1.9390883048375447

Epoch: 6| Step: 5
Training loss: 0.4899798631668091
Validation loss: 1.9651092688242595

Epoch: 6| Step: 6
Training loss: 0.6596853137016296
Validation loss: 1.9248154362042744

Epoch: 6| Step: 7
Training loss: 0.9878163933753967
Validation loss: 1.9486383597056072

Epoch: 6| Step: 8
Training loss: 1.2269198894500732
Validation loss: 1.9616056680679321

Epoch: 6| Step: 9
Training loss: 0.6160998344421387
Validation loss: 1.9523909489313762

Epoch: 6| Step: 10
Training loss: 1.090354561805725
Validation loss: 2.013726810614268

Epoch: 6| Step: 11
Training loss: 0.7631845474243164
Validation loss: 1.95412282148997

Epoch: 6| Step: 12
Training loss: 0.8682880401611328
Validation loss: 1.9512632091840107

Epoch: 6| Step: 13
Training loss: 0.5755103230476379
Validation loss: 1.95149032274882

Epoch: 146| Step: 0
Training loss: 0.2572828233242035
Validation loss: 1.965599497159322

Epoch: 6| Step: 1
Training loss: 0.7483125925064087
Validation loss: 1.9408023754755657

Epoch: 6| Step: 2
Training loss: 0.3447457551956177
Validation loss: 2.008436401685079

Epoch: 6| Step: 3
Training loss: 0.9525041580200195
Validation loss: 1.947433094183604

Epoch: 6| Step: 4
Training loss: 0.8766327500343323
Validation loss: 1.9706753889719646

Epoch: 6| Step: 5
Training loss: 0.8893756866455078
Validation loss: 1.985974649588267

Epoch: 6| Step: 6
Training loss: 0.7146735191345215
Validation loss: 1.9761913021405537

Epoch: 6| Step: 7
Training loss: 0.8688816428184509
Validation loss: 1.9514328837394714

Epoch: 6| Step: 8
Training loss: 0.5751023888587952
Validation loss: 1.9161504904429119

Epoch: 6| Step: 9
Training loss: 1.128239631652832
Validation loss: 1.9141287803649902

Epoch: 6| Step: 10
Training loss: 0.5748748183250427
Validation loss: 1.9670855402946472

Epoch: 6| Step: 11
Training loss: 1.3714674711227417
Validation loss: 1.9508045713106792

Epoch: 6| Step: 12
Training loss: 0.5978444814682007
Validation loss: 1.962605595588684

Epoch: 6| Step: 13
Training loss: 0.9134265184402466
Validation loss: 1.9529825448989868

Epoch: 147| Step: 0
Training loss: 0.8193104863166809
Validation loss: 2.0199999610582986

Epoch: 6| Step: 1
Training loss: 0.6182421445846558
Validation loss: 1.9678991436958313

Epoch: 6| Step: 2
Training loss: 0.6521827578544617
Validation loss: 1.9566932916641235

Epoch: 6| Step: 3
Training loss: 0.7013062238693237
Validation loss: 1.9565770030021667

Epoch: 6| Step: 4
Training loss: 0.7024810314178467
Validation loss: 1.9492857257525127

Epoch: 6| Step: 5
Training loss: 0.5732642412185669
Validation loss: 1.9983185331026714

Epoch: 6| Step: 6
Training loss: 0.5227535963058472
Validation loss: 1.9302688042322795

Epoch: 6| Step: 7
Training loss: 0.6108553409576416
Validation loss: 1.9259725213050842

Epoch: 6| Step: 8
Training loss: 0.4914306402206421
Validation loss: 1.9345192313194275

Epoch: 6| Step: 9
Training loss: 0.5269975662231445
Validation loss: 1.9698709050814311

Epoch: 6| Step: 10
Training loss: 0.714066743850708
Validation loss: 1.9018917481104534

Epoch: 6| Step: 11
Training loss: 1.260028600692749
Validation loss: 1.9337061444918315

Epoch: 6| Step: 12
Training loss: 1.4190834760665894
Validation loss: 2.002409736315409

Epoch: 6| Step: 13
Training loss: 1.241711974143982
Validation loss: 1.9745072722434998

Epoch: 148| Step: 0
Training loss: 1.2013866901397705
Validation loss: 1.932217538356781

Epoch: 6| Step: 1
Training loss: 0.501194417476654
Validation loss: 1.9241904417673747

Epoch: 6| Step: 2
Training loss: 0.633182168006897
Validation loss: 1.9837037920951843

Epoch: 6| Step: 3
Training loss: 0.7351568937301636
Validation loss: 1.9454084038734436

Epoch: 6| Step: 4
Training loss: 1.2769792079925537
Validation loss: 1.9791953166325886

Epoch: 6| Step: 5
Training loss: 0.6399476528167725
Validation loss: 1.9304489096005757

Epoch: 6| Step: 6
Training loss: 0.5182399749755859
Validation loss: 1.8804723421732585

Epoch: 6| Step: 7
Training loss: 0.6478985548019409
Validation loss: 1.9591772556304932

Epoch: 6| Step: 8
Training loss: 0.5199271440505981
Validation loss: 1.9712059895197551

Epoch: 6| Step: 9
Training loss: 0.7669796347618103
Validation loss: 1.9683838089307149

Epoch: 6| Step: 10
Training loss: 1.180950403213501
Validation loss: 1.968282401561737

Epoch: 6| Step: 11
Training loss: 0.2828827500343323
Validation loss: 1.9498018225034077

Epoch: 6| Step: 12
Training loss: 0.7798595428466797
Validation loss: 1.9439829190572102

Epoch: 6| Step: 13
Training loss: 0.8426361083984375
Validation loss: 1.9372742772102356

Epoch: 149| Step: 0
Training loss: 0.4603571891784668
Validation loss: 1.9822980165481567

Epoch: 6| Step: 1
Training loss: 1.482666015625
Validation loss: 1.9940045475959778

Epoch: 6| Step: 2
Training loss: 0.38881343603134155
Validation loss: 1.982625404993693

Epoch: 6| Step: 3
Training loss: 0.32587575912475586
Validation loss: 1.97950941324234

Epoch: 6| Step: 4
Training loss: 0.5072159767150879
Validation loss: 1.8745944897333782

Epoch: 6| Step: 5
Training loss: 0.4128309488296509
Validation loss: 1.9441030820210774

Epoch: 6| Step: 6
Training loss: 0.8552795052528381
Validation loss: 2.0247216622034707

Epoch: 6| Step: 7
Training loss: 0.9989645481109619
Validation loss: 1.9629279772440593

Epoch: 6| Step: 8
Training loss: 0.8084959983825684
Validation loss: 2.010202944278717

Epoch: 6| Step: 9
Training loss: 0.375529944896698
Validation loss: 1.9792345960934956

Epoch: 6| Step: 10
Training loss: 0.8276935815811157
Validation loss: 1.9319232106208801

Epoch: 6| Step: 11
Training loss: 0.9907687902450562
Validation loss: 1.949901024500529

Epoch: 6| Step: 12
Training loss: 0.9836046695709229
Validation loss: 2.002593676249186

Epoch: 6| Step: 13
Training loss: 1.0950400829315186
Validation loss: 1.9369053641955059

Epoch: 150| Step: 0
Training loss: 0.6225956082344055
Validation loss: 1.9099839131037395

Epoch: 6| Step: 1
Training loss: 0.3540937900543213
Validation loss: 1.9383164246877034

Epoch: 6| Step: 2
Training loss: 0.8261935710906982
Validation loss: 1.9530710577964783

Epoch: 6| Step: 3
Training loss: 0.8586243391036987
Validation loss: 1.9350768327713013

Epoch: 6| Step: 4
Training loss: 1.1994621753692627
Validation loss: 1.960794488588969

Epoch: 6| Step: 5
Training loss: 1.0669550895690918
Validation loss: 1.9847117066383362

Epoch: 6| Step: 6
Training loss: 0.8328691720962524
Validation loss: 1.9604693253835042

Epoch: 6| Step: 7
Training loss: 0.6521473526954651
Validation loss: 1.8962760368982952

Epoch: 6| Step: 8
Training loss: 0.6185770034790039
Validation loss: 1.9096620480219524

Epoch: 6| Step: 9
Training loss: 0.7279114723205566
Validation loss: 1.9306547443072002

Epoch: 6| Step: 10
Training loss: 0.6376074552536011
Validation loss: 1.932188868522644

Epoch: 6| Step: 11
Training loss: 0.7639675140380859
Validation loss: 1.980405827363332

Epoch: 6| Step: 12
Training loss: 0.74908047914505
Validation loss: 1.9541778167088826

Epoch: 6| Step: 13
Training loss: 0.4819234013557434
Validation loss: 1.9414374232292175

Epoch: 151| Step: 0
Training loss: 0.917088508605957
Validation loss: 2.0157392024993896

Epoch: 6| Step: 1
Training loss: 0.38109123706817627
Validation loss: 1.9269194602966309

Epoch: 6| Step: 2
Training loss: 0.5601168274879456
Validation loss: 1.9578054547309875

Epoch: 6| Step: 3
Training loss: 0.6314716339111328
Validation loss: 2.003946602344513

Epoch: 6| Step: 4
Training loss: 0.7644385099411011
Validation loss: 1.9915572206179302

Epoch: 6| Step: 5
Training loss: 1.0007365942001343
Validation loss: 1.9498797456423442

Epoch: 6| Step: 6
Training loss: 0.7865087985992432
Validation loss: 1.9090539614359539

Epoch: 6| Step: 7
Training loss: 1.033737301826477
Validation loss: 1.9721988042195637

Epoch: 6| Step: 8
Training loss: 1.1125693321228027
Validation loss: 1.9263252814610798

Epoch: 6| Step: 9
Training loss: 0.8311089277267456
Validation loss: 1.938384970029195

Epoch: 6| Step: 10
Training loss: 0.6330105066299438
Validation loss: 1.9441933234532673

Epoch: 6| Step: 11
Training loss: 0.7286521196365356
Validation loss: 1.9802283644676208

Epoch: 6| Step: 12
Training loss: 0.5710704922676086
Validation loss: 1.9150206446647644

Epoch: 6| Step: 13
Training loss: 0.4465930759906769
Validation loss: 1.93523770570755

Epoch: 152| Step: 0
Training loss: 1.3928985595703125
Validation loss: 1.924777885278066

Epoch: 6| Step: 1
Training loss: 0.9869210720062256
Validation loss: 1.905910054842631

Epoch: 6| Step: 2
Training loss: 0.7076509594917297
Validation loss: 1.9534443418184917

Epoch: 6| Step: 3
Training loss: 0.8177329897880554
Validation loss: 1.9690090616544087

Epoch: 6| Step: 4
Training loss: 0.5920760035514832
Validation loss: 1.9446317553520203

Epoch: 6| Step: 5
Training loss: 0.6560271978378296
Validation loss: 1.978046953678131

Epoch: 6| Step: 6
Training loss: 0.6794336438179016
Validation loss: 1.9479480783144634

Epoch: 6| Step: 7
Training loss: 0.670830249786377
Validation loss: 1.9211427966753643

Epoch: 6| Step: 8
Training loss: 0.5785662531852722
Validation loss: 1.954924762248993

Epoch: 6| Step: 9
Training loss: 0.8398107886314392
Validation loss: 1.9561401804288228

Epoch: 6| Step: 10
Training loss: 0.6210801601409912
Validation loss: 1.9132848779360454

Epoch: 6| Step: 11
Training loss: 0.7173007726669312
Validation loss: 1.8993071715037029

Epoch: 6| Step: 12
Training loss: 0.6275891065597534
Validation loss: 1.950569709142049

Epoch: 6| Step: 13
Training loss: 0.3300210237503052
Validation loss: 1.9616560737291973

Epoch: 153| Step: 0
Training loss: 0.515573263168335
Validation loss: 1.9613976279894512

Epoch: 6| Step: 1
Training loss: 0.8028318881988525
Validation loss: 1.965000053246816

Epoch: 6| Step: 2
Training loss: 0.6629000306129456
Validation loss: 1.9350359439849854

Epoch: 6| Step: 3
Training loss: 0.4418908953666687
Validation loss: 1.955176293849945

Epoch: 6| Step: 4
Training loss: 1.053547739982605
Validation loss: 1.8956621885299683

Epoch: 6| Step: 5
Training loss: 0.6832972764968872
Validation loss: 2.0205253958702087

Epoch: 6| Step: 6
Training loss: 0.6065205931663513
Validation loss: 1.9536024332046509

Epoch: 6| Step: 7
Training loss: 0.3514624238014221
Validation loss: 1.897965172926585

Epoch: 6| Step: 8
Training loss: 1.5238502025604248
Validation loss: 1.9572147727012634

Epoch: 6| Step: 9
Training loss: 1.052793264389038
Validation loss: 1.9631142616271973

Epoch: 6| Step: 10
Training loss: 0.37404441833496094
Validation loss: 1.9849499861399333

Epoch: 6| Step: 11
Training loss: 0.920081615447998
Validation loss: 1.9151320854822795

Epoch: 6| Step: 12
Training loss: 0.6735808849334717
Validation loss: 1.9256779154141743

Epoch: 6| Step: 13
Training loss: 0.7239766716957092
Validation loss: 1.9400021036465962

Epoch: 154| Step: 0
Training loss: 0.5795624256134033
Validation loss: 1.9370872974395752

Epoch: 6| Step: 1
Training loss: 0.8512470722198486
Validation loss: 1.96629931529363

Epoch: 6| Step: 2
Training loss: 0.5341472625732422
Validation loss: 1.9690237840016682

Epoch: 6| Step: 3
Training loss: 0.7243006825447083
Validation loss: 1.9228280981381733

Epoch: 6| Step: 4
Training loss: 0.6634227633476257
Validation loss: 1.981039027372996

Epoch: 6| Step: 5
Training loss: 1.211617112159729
Validation loss: 1.9519166747728984

Epoch: 6| Step: 6
Training loss: 0.406885027885437
Validation loss: 1.9036972920099895

Epoch: 6| Step: 7
Training loss: 0.4058755040168762
Validation loss: 1.9754650791486104

Epoch: 6| Step: 8
Training loss: 0.5886130332946777
Validation loss: 1.9453099370002747

Epoch: 6| Step: 9
Training loss: 0.8069710731506348
Validation loss: 1.9385401209195454

Epoch: 6| Step: 10
Training loss: 0.7516943216323853
Validation loss: 1.918907145659129

Epoch: 6| Step: 11
Training loss: 0.9356099963188171
Validation loss: 1.9306466976801555

Epoch: 6| Step: 12
Training loss: 0.8295236825942993
Validation loss: 1.9749420881271362

Epoch: 6| Step: 13
Training loss: 1.0827805995941162
Validation loss: 1.944456696510315

Epoch: 155| Step: 0
Training loss: 0.44166746735572815
Validation loss: 1.9637516140937805

Epoch: 6| Step: 1
Training loss: 1.0125584602355957
Validation loss: 1.9524754285812378

Epoch: 6| Step: 2
Training loss: 0.7821807861328125
Validation loss: 1.9725354711214702

Epoch: 6| Step: 3
Training loss: 0.47147342562675476
Validation loss: 1.923007845878601

Epoch: 6| Step: 4
Training loss: 0.6734941005706787
Validation loss: 1.8995340466499329

Epoch: 6| Step: 5
Training loss: 1.858174204826355
Validation loss: 1.9520345330238342

Epoch: 6| Step: 6
Training loss: 0.37492215633392334
Validation loss: 1.899566153685252

Epoch: 6| Step: 7
Training loss: 0.4944615364074707
Validation loss: 1.981731613477071

Epoch: 6| Step: 8
Training loss: 0.7962560057640076
Validation loss: 1.9505663514137268

Epoch: 6| Step: 9
Training loss: 0.5530973076820374
Validation loss: 1.9601178169250488

Epoch: 6| Step: 10
Training loss: 0.637931764125824
Validation loss: 1.9155642986297607

Epoch: 6| Step: 11
Training loss: 0.9067198038101196
Validation loss: 1.9680436650911968

Epoch: 6| Step: 12
Training loss: 0.6029588580131531
Validation loss: 1.949164887269338

Epoch: 6| Step: 13
Training loss: 0.5847560167312622
Validation loss: 1.9522052804629009

Epoch: 156| Step: 0
Training loss: 0.5470937490463257
Validation loss: 1.8884055813153584

Epoch: 6| Step: 1
Training loss: 0.37940841913223267
Validation loss: 1.9348310033480327

Epoch: 6| Step: 2
Training loss: 0.7400299906730652
Validation loss: 1.980060617129008

Epoch: 6| Step: 3
Training loss: 0.8401378393173218
Validation loss: 1.9233047564824421

Epoch: 6| Step: 4
Training loss: 0.8621276021003723
Validation loss: 1.8897765080134075

Epoch: 6| Step: 5
Training loss: 0.7934680581092834
Validation loss: 1.936483343442281

Epoch: 6| Step: 6
Training loss: 0.2868507504463196
Validation loss: 1.9287469585736592

Epoch: 6| Step: 7
Training loss: 0.20392251014709473
Validation loss: 1.9515270392100017

Epoch: 6| Step: 8
Training loss: 0.8541340231895447
Validation loss: 1.9287079175313313

Epoch: 6| Step: 9
Training loss: 0.4560704231262207
Validation loss: 1.9173179070154827

Epoch: 6| Step: 10
Training loss: 0.829369306564331
Validation loss: 1.88874747355779

Epoch: 6| Step: 11
Training loss: 0.586776614189148
Validation loss: 1.957400957743327

Epoch: 6| Step: 12
Training loss: 0.7393923401832581
Validation loss: 1.95009841521581

Epoch: 6| Step: 13
Training loss: 1.267143964767456
Validation loss: 1.9276413122812908

Epoch: 157| Step: 0
Training loss: 0.8279527425765991
Validation loss: 1.9518715143203735

Epoch: 6| Step: 1
Training loss: 0.6844922304153442
Validation loss: 1.959765632947286

Epoch: 6| Step: 2
Training loss: 0.9781204462051392
Validation loss: 2.0114235877990723

Epoch: 6| Step: 3
Training loss: 0.6425085663795471
Validation loss: 1.9382074077924092

Epoch: 6| Step: 4
Training loss: 1.1730753183364868
Validation loss: 1.9704097906748455

Epoch: 6| Step: 5
Training loss: 0.44629353284835815
Validation loss: 1.9341419339179993

Epoch: 6| Step: 6
Training loss: 1.0473898649215698
Validation loss: 1.9991667866706848

Epoch: 6| Step: 7
Training loss: 0.43631505966186523
Validation loss: 1.953117827574412

Epoch: 6| Step: 8
Training loss: 0.6663373112678528
Validation loss: 1.9868403275807698

Epoch: 6| Step: 9
Training loss: 0.5314895510673523
Validation loss: 1.9459225336710613

Epoch: 6| Step: 10
Training loss: 0.4154467284679413
Validation loss: 1.997131605943044

Epoch: 6| Step: 11
Training loss: 0.6211695075035095
Validation loss: 1.975687285264333

Epoch: 6| Step: 12
Training loss: 1.1385892629623413
Validation loss: 1.9391677578290303

Epoch: 6| Step: 13
Training loss: 0.4385046362876892
Validation loss: 1.9304373661677043

Epoch: 158| Step: 0
Training loss: 0.5824339389801025
Validation loss: 1.8986414074897766

Epoch: 6| Step: 1
Training loss: 0.46357959508895874
Validation loss: 1.9315547148386638

Epoch: 6| Step: 2
Training loss: 0.6066561341285706
Validation loss: 1.906355579694112

Epoch: 6| Step: 3
Training loss: 0.8434889912605286
Validation loss: 1.9161707560221355

Epoch: 6| Step: 4
Training loss: 0.5667406320571899
Validation loss: 1.91441414753596

Epoch: 6| Step: 5
Training loss: 0.5295168161392212
Validation loss: 1.9198031226793926

Epoch: 6| Step: 6
Training loss: 0.7255988121032715
Validation loss: 1.9562162359555562

Epoch: 6| Step: 7
Training loss: 1.563269853591919
Validation loss: 1.9535191853841145

Epoch: 6| Step: 8
Training loss: 0.704400897026062
Validation loss: 1.9482949773470561

Epoch: 6| Step: 9
Training loss: 0.4109378159046173
Validation loss: 1.946638027826945

Epoch: 6| Step: 10
Training loss: 0.6620302796363831
Validation loss: 1.9345932205518086

Epoch: 6| Step: 11
Training loss: 0.9361502528190613
Validation loss: 1.9659100373586018

Epoch: 6| Step: 12
Training loss: 0.8287177085876465
Validation loss: 1.917345662911733

Epoch: 6| Step: 13
Training loss: 0.6972095966339111
Validation loss: 1.9346633156140645

Epoch: 159| Step: 0
Training loss: 0.6133618950843811
Validation loss: 1.8991308609644573

Epoch: 6| Step: 1
Training loss: 0.48190003633499146
Validation loss: 1.9042762120564778

Epoch: 6| Step: 2
Training loss: 0.4956500232219696
Validation loss: 1.9321317474047344

Epoch: 6| Step: 3
Training loss: 0.5159254670143127
Validation loss: 1.92441725730896

Epoch: 6| Step: 4
Training loss: 0.6400188207626343
Validation loss: 1.9986396829287212

Epoch: 6| Step: 5
Training loss: 0.8726373314857483
Validation loss: 1.9677022298177083

Epoch: 6| Step: 6
Training loss: 0.7203811407089233
Validation loss: 1.9560410579045613

Epoch: 6| Step: 7
Training loss: 0.8824973702430725
Validation loss: 1.967999279499054

Epoch: 6| Step: 8
Training loss: 0.6122315526008606
Validation loss: 1.9385902881622314

Epoch: 6| Step: 9
Training loss: 0.22722464799880981
Validation loss: 1.9100136955579121

Epoch: 6| Step: 10
Training loss: 1.2558238506317139
Validation loss: 1.9230644901593525

Epoch: 6| Step: 11
Training loss: 0.5302454829216003
Validation loss: 1.945699433485667

Epoch: 6| Step: 12
Training loss: 0.860710620880127
Validation loss: 1.9601064125696819

Epoch: 6| Step: 13
Training loss: 0.751899003982544
Validation loss: 1.9337597489356995

Epoch: 160| Step: 0
Training loss: 0.6646769046783447
Validation loss: 1.9372714360555012

Epoch: 6| Step: 1
Training loss: 0.7811824083328247
Validation loss: 1.906504253546397

Epoch: 6| Step: 2
Training loss: 0.9902365803718567
Validation loss: 1.917190949122111

Epoch: 6| Step: 3
Training loss: 0.6118904948234558
Validation loss: 1.908909837404887

Epoch: 6| Step: 4
Training loss: 0.6428854465484619
Validation loss: 1.9392961462338765

Epoch: 6| Step: 5
Training loss: 0.6809454560279846
Validation loss: 1.9508426189422607

Epoch: 6| Step: 6
Training loss: 0.4887363314628601
Validation loss: 1.9421437978744507

Epoch: 6| Step: 7
Training loss: 1.0971860885620117
Validation loss: 1.9288315773010254

Epoch: 6| Step: 8
Training loss: 0.9237896203994751
Validation loss: 1.8973774512608845

Epoch: 6| Step: 9
Training loss: 1.0547746419906616
Validation loss: 1.972655196984609

Epoch: 6| Step: 10
Training loss: 0.7299458384513855
Validation loss: 1.9711631536483765

Epoch: 6| Step: 11
Training loss: 0.40497201681137085
Validation loss: 2.00131618976593

Epoch: 6| Step: 12
Training loss: 1.256226658821106
Validation loss: 1.9422887166341145

Epoch: 6| Step: 13
Training loss: 0.4894363284111023
Validation loss: 1.959499756495158

Epoch: 161| Step: 0
Training loss: 0.7263392210006714
Validation loss: 1.9521586894989014

Epoch: 6| Step: 1
Training loss: 0.8400740027427673
Validation loss: 1.9213553667068481

Epoch: 6| Step: 2
Training loss: 1.2272111177444458
Validation loss: 1.9796891609827678

Epoch: 6| Step: 3
Training loss: 1.0392014980316162
Validation loss: 1.9851358731587727

Epoch: 6| Step: 4
Training loss: 0.5873192548751831
Validation loss: 1.9371773600578308

Epoch: 6| Step: 5
Training loss: 0.2836040258407593
Validation loss: 1.914997637271881

Epoch: 6| Step: 6
Training loss: 0.5620269775390625
Validation loss: 1.9941703875859578

Epoch: 6| Step: 7
Training loss: 1.0261743068695068
Validation loss: 1.9071461757024128

Epoch: 6| Step: 8
Training loss: 0.5275664329528809
Validation loss: 1.8729806741078694

Epoch: 6| Step: 9
Training loss: 0.6902855038642883
Validation loss: 1.9896632432937622

Epoch: 6| Step: 10
Training loss: 0.6350845694541931
Validation loss: 1.9262609481811523

Epoch: 6| Step: 11
Training loss: 0.51273512840271
Validation loss: 1.8916972676912944

Epoch: 6| Step: 12
Training loss: 0.8067804574966431
Validation loss: 1.8943986296653748

Epoch: 6| Step: 13
Training loss: 0.6754981279373169
Validation loss: 1.9250021775563557

Epoch: 162| Step: 0
Training loss: 0.4568411707878113
Validation loss: 1.9145768284797668

Epoch: 6| Step: 1
Training loss: 0.28647923469543457
Validation loss: 1.9503053426742554

Epoch: 6| Step: 2
Training loss: 0.6945207118988037
Validation loss: 1.9052894512812297

Epoch: 6| Step: 3
Training loss: 0.3608148992061615
Validation loss: 2.00875993569692

Epoch: 6| Step: 4
Training loss: 1.0739127397537231
Validation loss: 1.937411944071452

Epoch: 6| Step: 5
Training loss: 0.8130578994750977
Validation loss: 1.9326391816139221

Epoch: 6| Step: 6
Training loss: 0.921289324760437
Validation loss: 1.9433638254801433

Epoch: 6| Step: 7
Training loss: 1.0285441875457764
Validation loss: 1.9342703620592754

Epoch: 6| Step: 8
Training loss: 0.49464893341064453
Validation loss: 1.917489508787791

Epoch: 6| Step: 9
Training loss: 0.6206701397895813
Validation loss: 1.9104146758715312

Epoch: 6| Step: 10
Training loss: 0.9311065077781677
Validation loss: 1.9225685000419617

Epoch: 6| Step: 11
Training loss: 0.6267920732498169
Validation loss: 1.9637504021326702

Epoch: 6| Step: 12
Training loss: 0.6791567206382751
Validation loss: 1.9064290523529053

Epoch: 6| Step: 13
Training loss: 0.3486475646495819
Validation loss: 1.9276479880015056

Epoch: 163| Step: 0
Training loss: 0.4474780559539795
Validation loss: 1.9493420124053955

Epoch: 6| Step: 1
Training loss: 0.53465735912323
Validation loss: 1.9421455264091492

Epoch: 6| Step: 2
Training loss: 1.3009426593780518
Validation loss: 1.8931806683540344

Epoch: 6| Step: 3
Training loss: 0.4125405550003052
Validation loss: 1.8933574557304382

Epoch: 6| Step: 4
Training loss: 0.5473759174346924
Validation loss: 1.9055304328600566

Epoch: 6| Step: 5
Training loss: 0.838495135307312
Validation loss: 1.8654296199480693

Epoch: 6| Step: 6
Training loss: 0.3581523299217224
Validation loss: 1.8898540337880452

Epoch: 6| Step: 7
Training loss: 0.4688184857368469
Validation loss: 1.896437128384908

Epoch: 6| Step: 8
Training loss: 0.7305264472961426
Validation loss: 1.878819723924001

Epoch: 6| Step: 9
Training loss: 0.788642406463623
Validation loss: 1.949461539586385

Epoch: 6| Step: 10
Training loss: 0.5873278379440308
Validation loss: 1.8920588890711467

Epoch: 6| Step: 11
Training loss: 0.7572440505027771
Validation loss: 1.9780031045277913

Epoch: 6| Step: 12
Training loss: 0.7922053933143616
Validation loss: 1.9360425273577373

Epoch: 6| Step: 13
Training loss: 0.4855945110321045
Validation loss: 1.958993375301361

Epoch: 164| Step: 0
Training loss: 0.4929226040840149
Validation loss: 1.8800925612449646

Epoch: 6| Step: 1
Training loss: 0.5517873167991638
Validation loss: 1.8849886457125347

Epoch: 6| Step: 2
Training loss: 0.4375416934490204
Validation loss: 1.9191786249478657

Epoch: 6| Step: 3
Training loss: 0.7970318794250488
Validation loss: 1.8423384825388591

Epoch: 6| Step: 4
Training loss: 0.9917603731155396
Validation loss: 1.9001529812812805

Epoch: 6| Step: 5
Training loss: 0.44807618856430054
Validation loss: 1.9290356636047363

Epoch: 6| Step: 6
Training loss: 0.7995868921279907
Validation loss: 1.9443911512692769

Epoch: 6| Step: 7
Training loss: 0.9123905897140503
Validation loss: 1.944203794002533

Epoch: 6| Step: 8
Training loss: 0.9036399722099304
Validation loss: 1.9525768955548604

Epoch: 6| Step: 9
Training loss: 0.6003690958023071
Validation loss: 1.9596152504285176

Epoch: 6| Step: 10
Training loss: 0.2860599756240845
Validation loss: 1.9434371987978618

Epoch: 6| Step: 11
Training loss: 0.4645445942878723
Validation loss: 1.9315250317255657

Epoch: 6| Step: 12
Training loss: 0.975746750831604
Validation loss: 1.9375443657239277

Epoch: 6| Step: 13
Training loss: 0.5674891471862793
Validation loss: 1.9191078146298726

Epoch: 165| Step: 0
Training loss: 0.87633216381073
Validation loss: 1.9280949036280315

Epoch: 6| Step: 1
Training loss: 0.72564697265625
Validation loss: 1.9467659791310628

Epoch: 6| Step: 2
Training loss: 0.5834200382232666
Validation loss: 1.9182689189910889

Epoch: 6| Step: 3
Training loss: 0.566663920879364
Validation loss: 1.8933617273966472

Epoch: 6| Step: 4
Training loss: 0.6897545456886292
Validation loss: 1.9179550210634868

Epoch: 6| Step: 5
Training loss: 0.8914051651954651
Validation loss: 1.9291965564092

Epoch: 6| Step: 6
Training loss: 0.7111660242080688
Validation loss: 1.8903287649154663

Epoch: 6| Step: 7
Training loss: 0.8784300684928894
Validation loss: 1.8916334708531697

Epoch: 6| Step: 8
Training loss: 0.6843663454055786
Validation loss: 1.940398375193278

Epoch: 6| Step: 9
Training loss: 0.8131637573242188
Validation loss: 1.9144273797671

Epoch: 6| Step: 10
Training loss: 0.5460143685340881
Validation loss: 1.9471869071324666

Epoch: 6| Step: 11
Training loss: 0.5038752555847168
Validation loss: 1.9003329873085022

Epoch: 6| Step: 12
Training loss: 0.3004043698310852
Validation loss: 1.8674885034561157

Epoch: 6| Step: 13
Training loss: 0.43829789757728577
Validation loss: 1.873644729455312

Epoch: 166| Step: 0
Training loss: 0.7217682600021362
Validation loss: 1.924418568611145

Epoch: 6| Step: 1
Training loss: 0.4981285035610199
Validation loss: 1.94848636786143

Epoch: 6| Step: 2
Training loss: 1.0131011009216309
Validation loss: 1.896366834640503

Epoch: 6| Step: 3
Training loss: 1.1017329692840576
Validation loss: 1.8667470415433247

Epoch: 6| Step: 4
Training loss: 0.2790871560573578
Validation loss: 1.9544817805290222

Epoch: 6| Step: 5
Training loss: 0.34985291957855225
Validation loss: 1.884421944618225

Epoch: 6| Step: 6
Training loss: 0.3936898112297058
Validation loss: 1.9310354590415955

Epoch: 6| Step: 7
Training loss: 0.8626629114151001
Validation loss: 1.9056414564450581

Epoch: 6| Step: 8
Training loss: 0.588422417640686
Validation loss: 1.9423388640085857

Epoch: 6| Step: 9
Training loss: 0.7381329536437988
Validation loss: 1.877158761024475

Epoch: 6| Step: 10
Training loss: 0.6172373294830322
Validation loss: 1.9130365053812664

Epoch: 6| Step: 11
Training loss: 0.5703229308128357
Validation loss: 1.954191009203593

Epoch: 6| Step: 12
Training loss: 0.4139689803123474
Validation loss: 1.926658848921458

Epoch: 6| Step: 13
Training loss: 0.7664435505867004
Validation loss: 1.941581666469574

Epoch: 167| Step: 0
Training loss: 0.430629163980484
Validation loss: 1.9087217450141907

Epoch: 6| Step: 1
Training loss: 0.9302533864974976
Validation loss: 1.9243009487787883

Epoch: 6| Step: 2
Training loss: 0.8215619921684265
Validation loss: 1.8689272205034893

Epoch: 6| Step: 3
Training loss: 0.5786230564117432
Validation loss: 1.9153067370255787

Epoch: 6| Step: 4
Training loss: 0.7635912299156189
Validation loss: 1.9284573992093403

Epoch: 6| Step: 5
Training loss: 1.0286824703216553
Validation loss: 1.8890137275060017

Epoch: 6| Step: 6
Training loss: 0.4493710994720459
Validation loss: 1.8751728137334187

Epoch: 6| Step: 7
Training loss: 0.723486065864563
Validation loss: 1.952110270659129

Epoch: 6| Step: 8
Training loss: 0.5602208971977234
Validation loss: 1.9485553701718648

Epoch: 6| Step: 9
Training loss: 0.2677192687988281
Validation loss: 1.9330236117045085

Epoch: 6| Step: 10
Training loss: 0.8302258849143982
Validation loss: 1.9516870180765789

Epoch: 6| Step: 11
Training loss: 0.5665968060493469
Validation loss: 1.9365183512369792

Epoch: 6| Step: 12
Training loss: 0.9741929173469543
Validation loss: 1.8599334955215454

Epoch: 6| Step: 13
Training loss: 0.4189315140247345
Validation loss: 1.9623660445213318

Epoch: 168| Step: 0
Training loss: 0.6155429482460022
Validation loss: 1.956888496875763

Epoch: 6| Step: 1
Training loss: 0.6662020683288574
Validation loss: 1.9195537368456523

Epoch: 6| Step: 2
Training loss: 0.6524189710617065
Validation loss: 1.9288060665130615

Epoch: 6| Step: 3
Training loss: 0.5771748423576355
Validation loss: 1.9374974767367046

Epoch: 6| Step: 4
Training loss: 0.49058273434638977
Validation loss: 1.929929494857788

Epoch: 6| Step: 5
Training loss: 0.7617256045341492
Validation loss: 1.922409435113271

Epoch: 6| Step: 6
Training loss: 0.44606584310531616
Validation loss: 1.9713946382204692

Epoch: 6| Step: 7
Training loss: 0.4910568594932556
Validation loss: 1.9412638346354167

Epoch: 6| Step: 8
Training loss: 1.0355188846588135
Validation loss: 1.9190611044565837

Epoch: 6| Step: 9
Training loss: 0.32748091220855713
Validation loss: 1.867474099000295

Epoch: 6| Step: 10
Training loss: 0.8914684057235718
Validation loss: 1.905870834986369

Epoch: 6| Step: 11
Training loss: 0.7992299795150757
Validation loss: 1.9405535658200581

Epoch: 6| Step: 12
Training loss: 0.6925522089004517
Validation loss: 1.943703869978587

Epoch: 6| Step: 13
Training loss: 0.3802019953727722
Validation loss: 1.945235292116801

Epoch: 169| Step: 0
Training loss: 0.5388460159301758
Validation loss: 1.9327019453048706

Epoch: 6| Step: 1
Training loss: 0.9215430021286011
Validation loss: 1.8776526252428691

Epoch: 6| Step: 2
Training loss: 0.8890639543533325
Validation loss: 1.9013781746228535

Epoch: 6| Step: 3
Training loss: 0.6061345338821411
Validation loss: 1.9395196835199993

Epoch: 6| Step: 4
Training loss: 1.0374897718429565
Validation loss: 1.8553523023923237

Epoch: 6| Step: 5
Training loss: 0.38133344054222107
Validation loss: 1.899183710416158

Epoch: 6| Step: 6
Training loss: 0.5943365097045898
Validation loss: 1.9090711275736492

Epoch: 6| Step: 7
Training loss: 0.736294150352478
Validation loss: 1.9243511358896892

Epoch: 6| Step: 8
Training loss: 0.3510974645614624
Validation loss: 1.9275973439216614

Epoch: 6| Step: 9
Training loss: 0.741919994354248
Validation loss: 1.9223846395810444

Epoch: 6| Step: 10
Training loss: 0.5825784206390381
Validation loss: 1.8818154335021973

Epoch: 6| Step: 11
Training loss: 0.5324831008911133
Validation loss: 1.9518163800239563

Epoch: 6| Step: 12
Training loss: 0.5804556608200073
Validation loss: 1.9206824898719788

Epoch: 6| Step: 13
Training loss: 0.6247330904006958
Validation loss: 1.9420047402381897

Epoch: 170| Step: 0
Training loss: 0.2469714879989624
Validation loss: 1.9556126197179158

Epoch: 6| Step: 1
Training loss: 0.7410688400268555
Validation loss: 1.890277902285258

Epoch: 6| Step: 2
Training loss: 0.615877628326416
Validation loss: 1.8636006116867065

Epoch: 6| Step: 3
Training loss: 0.6886957883834839
Validation loss: 1.9319722255071003

Epoch: 6| Step: 4
Training loss: 0.788367748260498
Validation loss: 1.9085200031598408

Epoch: 6| Step: 5
Training loss: 0.8036081194877625
Validation loss: 1.932668685913086

Epoch: 6| Step: 6
Training loss: 0.8622594475746155
Validation loss: 1.9182204206784566

Epoch: 6| Step: 7
Training loss: 0.38602763414382935
Validation loss: 1.8664124210675557

Epoch: 6| Step: 8
Training loss: 0.6865727305412292
Validation loss: 1.8828245202700298

Epoch: 6| Step: 9
Training loss: 0.46527260541915894
Validation loss: 1.9368186593055725

Epoch: 6| Step: 10
Training loss: 0.7715402841567993
Validation loss: 1.9012713432312012

Epoch: 6| Step: 11
Training loss: 0.34173184633255005
Validation loss: 1.9040501117706299

Epoch: 6| Step: 12
Training loss: 0.579838216304779
Validation loss: 1.89691827694575

Epoch: 6| Step: 13
Training loss: 0.6854308247566223
Validation loss: 1.9125230709711711

Epoch: 171| Step: 0
Training loss: 0.44047874212265015
Validation loss: 1.8665930032730103

Epoch: 6| Step: 1
Training loss: 1.0150779485702515
Validation loss: 1.8977622787157695

Epoch: 6| Step: 2
Training loss: 0.6412239670753479
Validation loss: 1.9091083407402039

Epoch: 6| Step: 3
Training loss: 0.35778334736824036
Validation loss: 1.8684768279393513

Epoch: 6| Step: 4
Training loss: 0.42616143822669983
Validation loss: 1.8990647792816162

Epoch: 6| Step: 5
Training loss: 0.665573239326477
Validation loss: 1.882750431696574

Epoch: 6| Step: 6
Training loss: 0.42594534158706665
Validation loss: 1.8792628447214763

Epoch: 6| Step: 7
Training loss: 0.8530858755111694
Validation loss: 1.8762530883153279

Epoch: 6| Step: 8
Training loss: 1.1732783317565918
Validation loss: 1.9185765782992046

Epoch: 6| Step: 9
Training loss: 0.5106319189071655
Validation loss: 1.9032967686653137

Epoch: 6| Step: 10
Training loss: 0.5088990330696106
Validation loss: 1.9266802072525024

Epoch: 6| Step: 11
Training loss: 0.2666139602661133
Validation loss: 1.8640172084172566

Epoch: 6| Step: 12
Training loss: 0.7565535306930542
Validation loss: 1.8807049989700317

Epoch: 6| Step: 13
Training loss: 0.7658576965332031
Validation loss: 1.9414755702018738

Epoch: 172| Step: 0
Training loss: 0.6489436030387878
Validation loss: 1.8987412651379902

Epoch: 6| Step: 1
Training loss: 0.3253489136695862
Validation loss: 1.889552116394043

Epoch: 6| Step: 2
Training loss: 0.41446930170059204
Validation loss: 1.8882454832394917

Epoch: 6| Step: 3
Training loss: 0.5588150024414062
Validation loss: 1.9338243405024211

Epoch: 6| Step: 4
Training loss: 0.3940385580062866
Validation loss: 1.9244499802589417

Epoch: 6| Step: 5
Training loss: 0.7005977034568787
Validation loss: 1.9313864509264629

Epoch: 6| Step: 6
Training loss: 0.3855050802230835
Validation loss: 1.8973456819852192

Epoch: 6| Step: 7
Training loss: 0.5152194499969482
Validation loss: 1.903699815273285

Epoch: 6| Step: 8
Training loss: 0.7466005682945251
Validation loss: 1.8943057854970295

Epoch: 6| Step: 9
Training loss: 0.7362479567527771
Validation loss: 1.9241935809453328

Epoch: 6| Step: 10
Training loss: 0.5930267572402954
Validation loss: 1.9088602264722188

Epoch: 6| Step: 11
Training loss: 1.2118695974349976
Validation loss: 1.8857139348983765

Epoch: 6| Step: 12
Training loss: 0.542788028717041
Validation loss: 1.9267238179842632

Epoch: 6| Step: 13
Training loss: 0.9109645485877991
Validation loss: 1.9234694838523865

Epoch: 173| Step: 0
Training loss: 0.8350319862365723
Validation loss: 1.8979010383288066

Epoch: 6| Step: 1
Training loss: 1.4000887870788574
Validation loss: 1.9049006700515747

Epoch: 6| Step: 2
Training loss: 0.570409893989563
Validation loss: 1.9391880631446838

Epoch: 6| Step: 3
Training loss: 0.39765846729278564
Validation loss: 1.881834884484609

Epoch: 6| Step: 4
Training loss: 0.3847275972366333
Validation loss: 1.8923326929410298

Epoch: 6| Step: 5
Training loss: 0.47248080372810364
Validation loss: 1.9481144547462463

Epoch: 6| Step: 6
Training loss: 0.31427136063575745
Validation loss: 1.9374633034070332

Epoch: 6| Step: 7
Training loss: 0.8481329679489136
Validation loss: 1.8760397831598918

Epoch: 6| Step: 8
Training loss: 0.8980815410614014
Validation loss: 1.867024838924408

Epoch: 6| Step: 9
Training loss: 0.3303954601287842
Validation loss: 1.8661243319511414

Epoch: 6| Step: 10
Training loss: 0.48697173595428467
Validation loss: 1.9292560617129009

Epoch: 6| Step: 11
Training loss: 0.7295858860015869
Validation loss: 1.8861529032389324

Epoch: 6| Step: 12
Training loss: 0.5166768431663513
Validation loss: 1.8911505937576294

Epoch: 6| Step: 13
Training loss: 0.6531347036361694
Validation loss: 1.8998013138771057

Epoch: 174| Step: 0
Training loss: 0.7581310272216797
Validation loss: 1.8971022764841716

Epoch: 6| Step: 1
Training loss: 0.26562654972076416
Validation loss: 1.9387273987134297

Epoch: 6| Step: 2
Training loss: 1.1298127174377441
Validation loss: 1.9196045994758606

Epoch: 6| Step: 3
Training loss: 0.7558665871620178
Validation loss: 1.9622565706570942

Epoch: 6| Step: 4
Training loss: 0.6553612947463989
Validation loss: 1.9577849706013997

Epoch: 6| Step: 5
Training loss: 0.6484649181365967
Validation loss: 1.936095158259074

Epoch: 6| Step: 6
Training loss: 0.6385910511016846
Validation loss: 1.9199204842249553

Epoch: 6| Step: 7
Training loss: 1.0326032638549805
Validation loss: 1.881212333838145

Epoch: 6| Step: 8
Training loss: 0.4478311538696289
Validation loss: 1.9444535970687866

Epoch: 6| Step: 9
Training loss: 1.0660793781280518
Validation loss: 1.916534423828125

Epoch: 6| Step: 10
Training loss: 0.46996089816093445
Validation loss: 1.880066454410553

Epoch: 6| Step: 11
Training loss: 0.6189749240875244
Validation loss: 1.9501320123672485

Epoch: 6| Step: 12
Training loss: 0.5143327713012695
Validation loss: 1.9271807273228962

Epoch: 6| Step: 13
Training loss: 0.9187161326408386
Validation loss: 1.8974655667940776

Epoch: 175| Step: 0
Training loss: 0.48169058561325073
Validation loss: 1.9417026440302532

Epoch: 6| Step: 1
Training loss: 1.4286243915557861
Validation loss: 1.9491364359855652

Epoch: 6| Step: 2
Training loss: 0.7068487405776978
Validation loss: 1.9258885383605957

Epoch: 6| Step: 3
Training loss: 0.780702531337738
Validation loss: 1.9270092447598774

Epoch: 6| Step: 4
Training loss: 0.5789787769317627
Validation loss: 1.9032879670461018

Epoch: 6| Step: 5
Training loss: 0.3950662910938263
Validation loss: 1.8993226488431294

Epoch: 6| Step: 6
Training loss: 0.6446151733398438
Validation loss: 1.8982998132705688

Epoch: 6| Step: 7
Training loss: 0.5442086458206177
Validation loss: 1.8567846218744914

Epoch: 6| Step: 8
Training loss: 0.32045412063598633
Validation loss: 1.8907225529352825

Epoch: 6| Step: 9
Training loss: 0.7916466593742371
Validation loss: 1.9186301032702129

Epoch: 6| Step: 10
Training loss: 0.8655256032943726
Validation loss: 1.919481337070465

Epoch: 6| Step: 11
Training loss: 0.2629661560058594
Validation loss: 1.8680985967318218

Epoch: 6| Step: 12
Training loss: 0.3010031580924988
Validation loss: 1.887719730536143

Epoch: 6| Step: 13
Training loss: 0.7697250843048096
Validation loss: 1.9058117469151814

Epoch: 176| Step: 0
Training loss: 0.4049646258354187
Validation loss: 1.9291199247042339

Epoch: 6| Step: 1
Training loss: 0.5478149652481079
Validation loss: 1.8911484281222026

Epoch: 6| Step: 2
Training loss: 0.48806965351104736
Validation loss: 1.8904072046279907

Epoch: 6| Step: 3
Training loss: 0.554897665977478
Validation loss: 1.897542655467987

Epoch: 6| Step: 4
Training loss: 0.5856561660766602
Validation loss: 1.921426514784495

Epoch: 6| Step: 5
Training loss: 0.7458369731903076
Validation loss: 1.906385898590088

Epoch: 6| Step: 6
Training loss: 0.6571271419525146
Validation loss: 1.876644988854726

Epoch: 6| Step: 7
Training loss: 0.7353673577308655
Validation loss: 1.9328291416168213

Epoch: 6| Step: 8
Training loss: 0.6882188320159912
Validation loss: 1.8971733848253887

Epoch: 6| Step: 9
Training loss: 0.9774205684661865
Validation loss: 1.9248934189478557

Epoch: 6| Step: 10
Training loss: 0.3664954900741577
Validation loss: 1.9432962735493977

Epoch: 6| Step: 11
Training loss: 0.7204933166503906
Validation loss: 1.8597470323244731

Epoch: 6| Step: 12
Training loss: 0.4974439740180969
Validation loss: 1.8977840542793274

Epoch: 6| Step: 13
Training loss: 0.4734349846839905
Validation loss: 1.8888338009516399

Epoch: 177| Step: 0
Training loss: 0.5646345019340515
Validation loss: 1.926718016465505

Epoch: 6| Step: 1
Training loss: 0.6253927946090698
Validation loss: 1.9267521500587463

Epoch: 6| Step: 2
Training loss: 0.8322731852531433
Validation loss: 1.8706809679667156

Epoch: 6| Step: 3
Training loss: 0.8373358249664307
Validation loss: 1.9326213598251343

Epoch: 6| Step: 4
Training loss: 0.603541374206543
Validation loss: 1.9178576072057087

Epoch: 6| Step: 5
Training loss: 1.0614922046661377
Validation loss: 1.9453617731730144

Epoch: 6| Step: 6
Training loss: 0.4948146939277649
Validation loss: 1.9184165994326274

Epoch: 6| Step: 7
Training loss: 0.6169309616088867
Validation loss: 1.935167094071706

Epoch: 6| Step: 8
Training loss: 0.43803662061691284
Validation loss: 1.9240422646204631

Epoch: 6| Step: 9
Training loss: 0.7014599442481995
Validation loss: 1.9352331558863323

Epoch: 6| Step: 10
Training loss: 0.5382215976715088
Validation loss: 1.9552868008613586

Epoch: 6| Step: 11
Training loss: 0.7394328117370605
Validation loss: 1.9595929185549419

Epoch: 6| Step: 12
Training loss: 0.5815498232841492
Validation loss: 1.9471805890401204

Epoch: 6| Step: 13
Training loss: 0.7195467948913574
Validation loss: 1.958690921465556

Epoch: 178| Step: 0
Training loss: 0.6015582084655762
Validation loss: 1.9200647075970967

Epoch: 6| Step: 1
Training loss: 0.6242667436599731
Validation loss: 1.9385360876719158

Epoch: 6| Step: 2
Training loss: 0.7771711945533752
Validation loss: 1.8999182780583699

Epoch: 6| Step: 3
Training loss: 0.653285026550293
Validation loss: 1.923703134059906

Epoch: 6| Step: 4
Training loss: 0.6426648497581482
Validation loss: 1.9390310645103455

Epoch: 6| Step: 5
Training loss: 0.8176944255828857
Validation loss: 1.892511288324992

Epoch: 6| Step: 6
Training loss: 0.8114097714424133
Validation loss: 1.9196149706840515

Epoch: 6| Step: 7
Training loss: 0.4543519616127014
Validation loss: 1.9183608492215474

Epoch: 6| Step: 8
Training loss: 0.6792929768562317
Validation loss: 1.8636213541030884

Epoch: 6| Step: 9
Training loss: 0.6774476170539856
Validation loss: 1.9456419348716736

Epoch: 6| Step: 10
Training loss: 0.5704313516616821
Validation loss: 1.9268746574719746

Epoch: 6| Step: 11
Training loss: 0.7731652855873108
Validation loss: 1.8961180448532104

Epoch: 6| Step: 12
Training loss: 0.4753226041793823
Validation loss: 1.9156225721041362

Epoch: 6| Step: 13
Training loss: 0.5225644111633301
Validation loss: 1.9127878745396931

Epoch: 179| Step: 0
Training loss: 0.9542141556739807
Validation loss: 1.9109145601590474

Epoch: 6| Step: 1
Training loss: 0.739963948726654
Validation loss: 1.9450407822926838

Epoch: 6| Step: 2
Training loss: 0.8895782232284546
Validation loss: 1.9135989546775818

Epoch: 6| Step: 3
Training loss: 0.7530572414398193
Validation loss: 1.899421234925588

Epoch: 6| Step: 4
Training loss: 0.6530351638793945
Validation loss: 1.9348355333010356

Epoch: 6| Step: 5
Training loss: 0.47383344173431396
Validation loss: 1.8550321062405903

Epoch: 6| Step: 6
Training loss: 0.8299418687820435
Validation loss: 1.8798919121424358

Epoch: 6| Step: 7
Training loss: 0.6207724809646606
Validation loss: 1.8882280985514324

Epoch: 6| Step: 8
Training loss: 0.8030900955200195
Validation loss: 1.8919515212376912

Epoch: 6| Step: 9
Training loss: 0.41904473304748535
Validation loss: 1.8931774497032166

Epoch: 6| Step: 10
Training loss: 0.480019748210907
Validation loss: 1.8973762392997742

Epoch: 6| Step: 11
Training loss: 0.32343536615371704
Validation loss: 1.896143118540446

Epoch: 6| Step: 12
Training loss: 0.3853748142719269
Validation loss: 1.92362113793691

Epoch: 6| Step: 13
Training loss: 0.6688036918640137
Validation loss: 1.901595155398051

Epoch: 180| Step: 0
Training loss: 0.3325147032737732
Validation loss: 1.8856260379155476

Epoch: 6| Step: 1
Training loss: 0.5034061670303345
Validation loss: 1.8807191252708435

Epoch: 6| Step: 2
Training loss: 0.37565651535987854
Validation loss: 1.8390221397082012

Epoch: 6| Step: 3
Training loss: 0.8209143280982971
Validation loss: 1.855647087097168

Epoch: 6| Step: 4
Training loss: 0.3735131025314331
Validation loss: 1.926930844783783

Epoch: 6| Step: 5
Training loss: 0.6940879225730896
Validation loss: 1.9283482631047566

Epoch: 6| Step: 6
Training loss: 0.577480673789978
Validation loss: 1.9321633179982503

Epoch: 6| Step: 7
Training loss: 0.6804488897323608
Validation loss: 1.854467550913493

Epoch: 6| Step: 8
Training loss: 0.48892053961753845
Validation loss: 1.8923241297403972

Epoch: 6| Step: 9
Training loss: 0.429162859916687
Validation loss: 1.9289503892262776

Epoch: 6| Step: 10
Training loss: 0.563319206237793
Validation loss: 1.9036037921905518

Epoch: 6| Step: 11
Training loss: 1.1388986110687256
Validation loss: 1.8953142960866292

Epoch: 6| Step: 12
Training loss: 0.8724599480628967
Validation loss: 1.8774489561716716

Epoch: 6| Step: 13
Training loss: 0.4480438232421875
Validation loss: 1.9257717529932659

Epoch: 181| Step: 0
Training loss: 0.3993326425552368
Validation loss: 1.8758273323376973

Epoch: 6| Step: 1
Training loss: 0.4944743514060974
Validation loss: 1.8890652060508728

Epoch: 6| Step: 2
Training loss: 0.5684607028961182
Validation loss: 1.9052275617917378

Epoch: 6| Step: 3
Training loss: 0.5104684829711914
Validation loss: 1.8655088146527607

Epoch: 6| Step: 4
Training loss: 0.6016083359718323
Validation loss: 1.8838437994321187

Epoch: 6| Step: 5
Training loss: 0.5211246013641357
Validation loss: 1.9077085852622986

Epoch: 6| Step: 6
Training loss: 0.8658041954040527
Validation loss: 1.930003782113393

Epoch: 6| Step: 7
Training loss: 0.5679590702056885
Validation loss: 1.953351358572642

Epoch: 6| Step: 8
Training loss: 0.463535338640213
Validation loss: 1.9500980178515117

Epoch: 6| Step: 9
Training loss: 0.569756031036377
Validation loss: 1.885905126730601

Epoch: 6| Step: 10
Training loss: 1.0841294527053833
Validation loss: 1.9344486594200134

Epoch: 6| Step: 11
Training loss: 0.49297764897346497
Validation loss: 1.9596966902414958

Epoch: 6| Step: 12
Training loss: 0.7804690599441528
Validation loss: 1.9221460024515789

Epoch: 6| Step: 13
Training loss: 0.45819318294525146
Validation loss: 1.8839037815729778

Epoch: 182| Step: 0
Training loss: 1.267746925354004
Validation loss: 1.902305245399475

Epoch: 6| Step: 1
Training loss: 0.4303674101829529
Validation loss: 1.8768699169158936

Epoch: 6| Step: 2
Training loss: 0.21260657906532288
Validation loss: 1.8687674601872761

Epoch: 6| Step: 3
Training loss: 0.3853690028190613
Validation loss: 1.9095502694447835

Epoch: 6| Step: 4
Training loss: 0.8247872591018677
Validation loss: 1.929660479227702

Epoch: 6| Step: 5
Training loss: 0.5785085558891296
Validation loss: 1.8741312225659688

Epoch: 6| Step: 6
Training loss: 0.4827881157398224
Validation loss: 1.9283214211463928

Epoch: 6| Step: 7
Training loss: 0.7578821778297424
Validation loss: 1.8672382632891338

Epoch: 6| Step: 8
Training loss: 0.3476012051105499
Validation loss: 1.9491706887880962

Epoch: 6| Step: 9
Training loss: 0.5576480627059937
Validation loss: 1.8297264973322551

Epoch: 6| Step: 10
Training loss: 0.3765120506286621
Validation loss: 1.9218761324882507

Epoch: 6| Step: 11
Training loss: 0.7581683397293091
Validation loss: 1.8493376970291138

Epoch: 6| Step: 12
Training loss: 0.38710248470306396
Validation loss: 1.9124728043874104

Epoch: 6| Step: 13
Training loss: 0.5326600074768066
Validation loss: 1.8861955801645915

Epoch: 183| Step: 0
Training loss: 0.8719968795776367
Validation loss: 1.8915147185325623

Epoch: 6| Step: 1
Training loss: 0.7872259616851807
Validation loss: 1.8813755710919697

Epoch: 6| Step: 2
Training loss: 0.8735280632972717
Validation loss: 1.918271501859029

Epoch: 6| Step: 3
Training loss: 0.5246979594230652
Validation loss: 1.902718424797058

Epoch: 6| Step: 4
Training loss: 0.4042919874191284
Validation loss: 1.8476439714431763

Epoch: 6| Step: 5
Training loss: 0.5426808595657349
Validation loss: 1.8753172755241394

Epoch: 6| Step: 6
Training loss: 0.7952562570571899
Validation loss: 1.863485872745514

Epoch: 6| Step: 7
Training loss: 0.6555721163749695
Validation loss: 1.8968355854352315

Epoch: 6| Step: 8
Training loss: 0.29651597142219543
Validation loss: 1.9454603791236877

Epoch: 6| Step: 9
Training loss: 0.33976954221725464
Validation loss: 1.8923116127649944

Epoch: 6| Step: 10
Training loss: 0.4706411361694336
Validation loss: 1.9493193626403809

Epoch: 6| Step: 11
Training loss: 0.5940039157867432
Validation loss: 1.9428109725316365

Epoch: 6| Step: 12
Training loss: 0.2858288884162903
Validation loss: 1.9090133309364319

Epoch: 6| Step: 13
Training loss: 0.6346128582954407
Validation loss: 1.9752825101216633

Epoch: 184| Step: 0
Training loss: 0.5997150540351868
Validation loss: 1.876645068327586

Epoch: 6| Step: 1
Training loss: 0.5286122560501099
Validation loss: 1.899678389231364

Epoch: 6| Step: 2
Training loss: 0.23707541823387146
Validation loss: 1.8582037687301636

Epoch: 6| Step: 3
Training loss: 0.3872275948524475
Validation loss: 1.89140917857488

Epoch: 6| Step: 4
Training loss: 0.3968465328216553
Validation loss: 1.8909664352734883

Epoch: 6| Step: 5
Training loss: 0.6447878479957581
Validation loss: 1.8793165683746338

Epoch: 6| Step: 6
Training loss: 0.40167856216430664
Validation loss: 1.8882933259010315

Epoch: 6| Step: 7
Training loss: 0.9948710799217224
Validation loss: 1.8927928407986958

Epoch: 6| Step: 8
Training loss: 1.3186115026474
Validation loss: 1.893891195456187

Epoch: 6| Step: 9
Training loss: 0.5394407510757446
Validation loss: 1.9030671119689941

Epoch: 6| Step: 10
Training loss: 0.5919771194458008
Validation loss: 1.9482427835464478

Epoch: 6| Step: 11
Training loss: 0.45124906301498413
Validation loss: 1.8721368312835693

Epoch: 6| Step: 12
Training loss: 0.6552618741989136
Validation loss: 1.9493178129196167

Epoch: 6| Step: 13
Training loss: 0.2584063410758972
Validation loss: 1.927485982577006

Epoch: 185| Step: 0
Training loss: 0.6874665021896362
Validation loss: 1.8878479599952698

Epoch: 6| Step: 1
Training loss: 1.0519665479660034
Validation loss: 1.919421672821045

Epoch: 6| Step: 2
Training loss: 0.5684574842453003
Validation loss: 1.8824745814005535

Epoch: 6| Step: 3
Training loss: 0.6259036660194397
Validation loss: 1.8635650674502056

Epoch: 6| Step: 4
Training loss: 0.48231545090675354
Validation loss: 1.910804808139801

Epoch: 6| Step: 5
Training loss: 0.41998234391212463
Validation loss: 1.9058810869852703

Epoch: 6| Step: 6
Training loss: 0.516034722328186
Validation loss: 1.9097906549771626

Epoch: 6| Step: 7
Training loss: 0.40672820806503296
Validation loss: 1.8921681642532349

Epoch: 6| Step: 8
Training loss: 0.6914306879043579
Validation loss: 1.8477153778076172

Epoch: 6| Step: 9
Training loss: 0.5853570699691772
Validation loss: 1.9010097583134968

Epoch: 6| Step: 10
Training loss: 0.7424788475036621
Validation loss: 1.873917023340861

Epoch: 6| Step: 11
Training loss: 0.44067251682281494
Validation loss: 1.915834367275238

Epoch: 6| Step: 12
Training loss: 0.6439228057861328
Validation loss: 1.888266146183014

Epoch: 6| Step: 13
Training loss: 0.2914183735847473
Validation loss: 1.8939783374468486

Epoch: 186| Step: 0
Training loss: 0.546419084072113
Validation loss: 1.908919632434845

Epoch: 6| Step: 1
Training loss: 0.672698974609375
Validation loss: 1.8865469892819722

Epoch: 6| Step: 2
Training loss: 0.3863299489021301
Validation loss: 1.8852049311002095

Epoch: 6| Step: 3
Training loss: 0.5344884395599365
Validation loss: 1.8956588904062908

Epoch: 6| Step: 4
Training loss: 0.6436209678649902
Validation loss: 1.845815618832906

Epoch: 6| Step: 5
Training loss: 1.0069903135299683
Validation loss: 1.85111403465271

Epoch: 6| Step: 6
Training loss: 0.5028935670852661
Validation loss: 1.925250510374705

Epoch: 6| Step: 7
Training loss: 0.7379398345947266
Validation loss: 1.9154260158538818

Epoch: 6| Step: 8
Training loss: 0.6647359132766724
Validation loss: 1.8551522294680278

Epoch: 6| Step: 9
Training loss: 0.5549881458282471
Validation loss: 1.8781448403994243

Epoch: 6| Step: 10
Training loss: 0.37963446974754333
Validation loss: 1.8771373629570007

Epoch: 6| Step: 11
Training loss: 0.42521095275878906
Validation loss: 1.8903213143348694

Epoch: 6| Step: 12
Training loss: 0.48228752613067627
Validation loss: 1.9223686059315999

Epoch: 6| Step: 13
Training loss: 0.7241895198822021
Validation loss: 1.9007460077603657

Epoch: 187| Step: 0
Training loss: 0.8588396906852722
Validation loss: 1.8732874592145283

Epoch: 6| Step: 1
Training loss: 0.6508966684341431
Validation loss: 1.90376216173172

Epoch: 6| Step: 2
Training loss: 0.5447268486022949
Validation loss: 1.8959052364031475

Epoch: 6| Step: 3
Training loss: 0.40644362568855286
Validation loss: 1.8825188279151917

Epoch: 6| Step: 4
Training loss: 0.616421639919281
Validation loss: 1.8881211082140605

Epoch: 6| Step: 5
Training loss: 0.7930529117584229
Validation loss: 1.8769720594088237

Epoch: 6| Step: 6
Training loss: 0.9755083322525024
Validation loss: 1.9014119505882263

Epoch: 6| Step: 7
Training loss: 0.30135148763656616
Validation loss: 1.874516765276591

Epoch: 6| Step: 8
Training loss: 0.30937427282333374
Validation loss: 1.8893202543258667

Epoch: 6| Step: 9
Training loss: 0.25238874554634094
Validation loss: 1.9008357922236125

Epoch: 6| Step: 10
Training loss: 0.28910964727401733
Validation loss: 1.9006511569023132

Epoch: 6| Step: 11
Training loss: 0.3485899269580841
Validation loss: 1.9298975268999736

Epoch: 6| Step: 12
Training loss: 0.5446047782897949
Validation loss: 1.8810835878054302

Epoch: 6| Step: 13
Training loss: 0.8581066131591797
Validation loss: 1.9393206636110942

Epoch: 188| Step: 0
Training loss: 0.7748205065727234
Validation loss: 1.8818093538284302

Epoch: 6| Step: 1
Training loss: 0.35967832803726196
Validation loss: 1.9198599656422932

Epoch: 6| Step: 2
Training loss: 0.915715217590332
Validation loss: 1.902410089969635

Epoch: 6| Step: 3
Training loss: 0.9787170886993408
Validation loss: 1.9302334586779277

Epoch: 6| Step: 4
Training loss: 0.6733438968658447
Validation loss: 1.9258768955866497

Epoch: 6| Step: 5
Training loss: 0.5275890827178955
Validation loss: 1.9348588983217876

Epoch: 6| Step: 6
Training loss: 0.34680378437042236
Validation loss: 1.908426841100057

Epoch: 6| Step: 7
Training loss: 0.6863669753074646
Validation loss: 1.8846083879470825

Epoch: 6| Step: 8
Training loss: 0.4038037657737732
Validation loss: 1.9118252595265706

Epoch: 6| Step: 9
Training loss: 0.32210367918014526
Validation loss: 1.901142140229543

Epoch: 6| Step: 10
Training loss: 0.6810595393180847
Validation loss: 1.9235935012499492

Epoch: 6| Step: 11
Training loss: 0.6829595565795898
Validation loss: 1.930904467900594

Epoch: 6| Step: 12
Training loss: 0.43285658955574036
Validation loss: 1.965711812178294

Epoch: 6| Step: 13
Training loss: 0.5503442287445068
Validation loss: 1.9131333629290264

Epoch: 189| Step: 0
Training loss: 0.4150097370147705
Validation loss: 1.9054892857869465

Epoch: 6| Step: 1
Training loss: 0.5638118982315063
Validation loss: 1.9394052823384602

Epoch: 6| Step: 2
Training loss: 0.31880664825439453
Validation loss: 1.885835349559784

Epoch: 6| Step: 3
Training loss: 0.9396572709083557
Validation loss: 1.8801206350326538

Epoch: 6| Step: 4
Training loss: 0.44692733883857727
Validation loss: 1.943263053894043

Epoch: 6| Step: 5
Training loss: 0.4865371286869049
Validation loss: 1.8841463724772136

Epoch: 6| Step: 6
Training loss: 0.6975618600845337
Validation loss: 1.9253877997398376

Epoch: 6| Step: 7
Training loss: 0.5851663947105408
Validation loss: 1.90736319621404

Epoch: 6| Step: 8
Training loss: 0.4149901866912842
Validation loss: 1.8948182264963787

Epoch: 6| Step: 9
Training loss: 0.5367415547370911
Validation loss: 1.8881067037582397

Epoch: 6| Step: 10
Training loss: 0.7033807039260864
Validation loss: 1.8934146960576375

Epoch: 6| Step: 11
Training loss: 0.3723003566265106
Validation loss: 1.924958844979604

Epoch: 6| Step: 12
Training loss: 0.6905676126480103
Validation loss: 1.9147942066192627

Epoch: 6| Step: 13
Training loss: 0.631588876247406
Validation loss: 1.9414552648862202

Epoch: 190| Step: 0
Training loss: 0.7539408206939697
Validation loss: 1.9114591479301453

Epoch: 6| Step: 1
Training loss: 0.49583619832992554
Validation loss: 1.9120606780052185

Epoch: 6| Step: 2
Training loss: 0.35329896211624146
Validation loss: 1.894890010356903

Epoch: 6| Step: 3
Training loss: 0.518164873123169
Validation loss: 1.8672312299410503

Epoch: 6| Step: 4
Training loss: 0.3151782751083374
Validation loss: 1.9313687284787495

Epoch: 6| Step: 5
Training loss: 0.7928634881973267
Validation loss: 1.898432691891988

Epoch: 6| Step: 6
Training loss: 0.8314743638038635
Validation loss: 1.8690401514371235

Epoch: 6| Step: 7
Training loss: 0.5946360230445862
Validation loss: 1.8769955039024353

Epoch: 6| Step: 8
Training loss: 0.40017005801200867
Validation loss: 1.9092385172843933

Epoch: 6| Step: 9
Training loss: 0.3795619010925293
Validation loss: 1.9369777639706929

Epoch: 6| Step: 10
Training loss: 0.3462445139884949
Validation loss: 1.9069432218869526

Epoch: 6| Step: 11
Training loss: 0.41187500953674316
Validation loss: 1.9305761655171711

Epoch: 6| Step: 12
Training loss: 0.5776038765907288
Validation loss: 1.902743677298228

Epoch: 6| Step: 13
Training loss: 0.561165452003479
Validation loss: 1.8253188927968342

Epoch: 191| Step: 0
Training loss: 0.47950026392936707
Validation loss: 1.9274198810259502

Epoch: 6| Step: 1
Training loss: 0.41770055890083313
Validation loss: 1.8615070780118306

Epoch: 6| Step: 2
Training loss: 0.5407306551933289
Validation loss: 1.893533746401469

Epoch: 6| Step: 3
Training loss: 0.6795852780342102
Validation loss: 1.877375642458598

Epoch: 6| Step: 4
Training loss: 0.5524499416351318
Validation loss: 1.8530789613723755

Epoch: 6| Step: 5
Training loss: 0.8950038552284241
Validation loss: 1.9052940805753071

Epoch: 6| Step: 6
Training loss: 0.616005003452301
Validation loss: 1.941888431708018

Epoch: 6| Step: 7
Training loss: 0.3410986363887787
Validation loss: 1.883134365081787

Epoch: 6| Step: 8
Training loss: 0.841545820236206
Validation loss: 1.871781826019287

Epoch: 6| Step: 9
Training loss: 0.7390024065971375
Validation loss: 1.896562894185384

Epoch: 6| Step: 10
Training loss: 0.32897210121154785
Validation loss: 1.9026854832967122

Epoch: 6| Step: 11
Training loss: 0.3793666362762451
Validation loss: 1.9297990202903748

Epoch: 6| Step: 12
Training loss: 0.28831911087036133
Validation loss: 1.878001073996226

Epoch: 6| Step: 13
Training loss: 0.3430348038673401
Validation loss: 1.901647965113322

Epoch: 192| Step: 0
Training loss: 0.6977088451385498
Validation loss: 1.8463868002096813

Epoch: 6| Step: 1
Training loss: 0.3607121407985687
Validation loss: 1.870574414730072

Epoch: 6| Step: 2
Training loss: 0.8421298861503601
Validation loss: 1.9045004844665527

Epoch: 6| Step: 3
Training loss: 0.6514434218406677
Validation loss: 1.9361160000165303

Epoch: 6| Step: 4
Training loss: 0.7962214350700378
Validation loss: 1.9448220133781433

Epoch: 6| Step: 5
Training loss: 0.38127052783966064
Validation loss: 1.8642487525939941

Epoch: 6| Step: 6
Training loss: 0.4322458505630493
Validation loss: 1.9198827544848125

Epoch: 6| Step: 7
Training loss: 0.35429179668426514
Validation loss: 1.9246789614359539

Epoch: 6| Step: 8
Training loss: 0.3792129158973694
Validation loss: 1.907047947247823

Epoch: 6| Step: 9
Training loss: 0.5775333046913147
Validation loss: 1.9132529298464458

Epoch: 6| Step: 10
Training loss: 0.33699142932891846
Validation loss: 1.8903677066167195

Epoch: 6| Step: 11
Training loss: 0.765201210975647
Validation loss: 1.8529220422108967

Epoch: 6| Step: 12
Training loss: 0.2947979271411896
Validation loss: 1.8751191695531209

Epoch: 6| Step: 13
Training loss: 0.41054484248161316
Validation loss: 1.8622271418571472

Epoch: 193| Step: 0
Training loss: 0.6860754489898682
Validation loss: 1.8590685725212097

Epoch: 6| Step: 1
Training loss: 0.622074544429779
Validation loss: 1.9069583415985107

Epoch: 6| Step: 2
Training loss: 0.5026850700378418
Validation loss: 1.8966533342997234

Epoch: 6| Step: 3
Training loss: 0.6513712406158447
Validation loss: 1.8611499468485515

Epoch: 6| Step: 4
Training loss: 0.5421396493911743
Validation loss: 1.8990341623624165

Epoch: 6| Step: 5
Training loss: 0.33149921894073486
Validation loss: 1.8260957797368367

Epoch: 6| Step: 6
Training loss: 0.34380143880844116
Validation loss: 1.9321641723314922

Epoch: 6| Step: 7
Training loss: 0.4814146161079407
Validation loss: 1.8830766081809998

Epoch: 6| Step: 8
Training loss: 0.3692857623100281
Validation loss: 1.896450698375702

Epoch: 6| Step: 9
Training loss: 0.5996330976486206
Validation loss: 1.8778746128082275

Epoch: 6| Step: 10
Training loss: 0.7095378637313843
Validation loss: 1.8586830099423726

Epoch: 6| Step: 11
Training loss: 0.4845391511917114
Validation loss: 1.867443561553955

Epoch: 6| Step: 12
Training loss: 0.6162722110748291
Validation loss: 1.9076597690582275

Epoch: 6| Step: 13
Training loss: 0.5449056625366211
Validation loss: 1.958597977956136

Epoch: 194| Step: 0
Training loss: 0.34101778268814087
Validation loss: 1.918713629245758

Epoch: 6| Step: 1
Training loss: 0.36713504791259766
Validation loss: 1.9114688436190288

Epoch: 6| Step: 2
Training loss: 0.3151780962944031
Validation loss: 1.896868646144867

Epoch: 6| Step: 3
Training loss: 0.7040823698043823
Validation loss: 1.9168099562327068

Epoch: 6| Step: 4
Training loss: 0.8654008507728577
Validation loss: 1.9111896554629009

Epoch: 6| Step: 5
Training loss: 0.672730565071106
Validation loss: 1.9335952798525493

Epoch: 6| Step: 6
Training loss: 0.4303027391433716
Validation loss: 1.8943399389584858

Epoch: 6| Step: 7
Training loss: 0.42364439368247986
Validation loss: 1.8936919768651326

Epoch: 6| Step: 8
Training loss: 0.5428495407104492
Validation loss: 1.8937478065490723

Epoch: 6| Step: 9
Training loss: 0.4938667416572571
Validation loss: 1.889939824740092

Epoch: 6| Step: 10
Training loss: 0.7319384813308716
Validation loss: 1.9089542031288147

Epoch: 6| Step: 11
Training loss: 1.0774492025375366
Validation loss: 1.8625118533770244

Epoch: 6| Step: 12
Training loss: 0.3238685131072998
Validation loss: 1.8939441839853923

Epoch: 6| Step: 13
Training loss: 0.6363011598587036
Validation loss: 1.8825397094090779

Epoch: 195| Step: 0
Training loss: 0.36849531531333923
Validation loss: 1.832708438237508

Epoch: 6| Step: 1
Training loss: 0.7172735929489136
Validation loss: 1.9053653081258137

Epoch: 6| Step: 2
Training loss: 0.46377047896385193
Validation loss: 1.9247061212857564

Epoch: 6| Step: 3
Training loss: 0.3613731861114502
Validation loss: 1.8899727662404378

Epoch: 6| Step: 4
Training loss: 0.3652076721191406
Validation loss: 1.9027060667673747

Epoch: 6| Step: 5
Training loss: 0.6297652125358582
Validation loss: 1.834128777186076

Epoch: 6| Step: 6
Training loss: 0.5963781476020813
Validation loss: 1.853863000869751

Epoch: 6| Step: 7
Training loss: 0.3977155089378357
Validation loss: 1.8515230019887288

Epoch: 6| Step: 8
Training loss: 0.49073368310928345
Validation loss: 1.9173753658930461

Epoch: 6| Step: 9
Training loss: 0.7020778656005859
Validation loss: 1.8650069038073223

Epoch: 6| Step: 10
Training loss: 0.3795364797115326
Validation loss: 1.9022117455800374

Epoch: 6| Step: 11
Training loss: 0.7566487789154053
Validation loss: 1.9232350587844849

Epoch: 6| Step: 12
Training loss: 0.29302021861076355
Validation loss: 1.9241185585657756

Epoch: 6| Step: 13
Training loss: 0.724651575088501
Validation loss: 1.8931230902671814

Epoch: 196| Step: 0
Training loss: 0.47169744968414307
Validation loss: 1.8941261967023213

Epoch: 6| Step: 1
Training loss: 0.8059147596359253
Validation loss: 1.893794059753418

Epoch: 6| Step: 2
Training loss: 0.6457481980323792
Validation loss: 1.878025472164154

Epoch: 6| Step: 3
Training loss: 0.6051079034805298
Validation loss: 1.8983368476231892

Epoch: 6| Step: 4
Training loss: 0.4046728014945984
Validation loss: 1.912842333316803

Epoch: 6| Step: 5
Training loss: 0.3043160140514374
Validation loss: 1.8536963661511738

Epoch: 6| Step: 6
Training loss: 0.8098649978637695
Validation loss: 1.9007776975631714

Epoch: 6| Step: 7
Training loss: 0.2901131808757782
Validation loss: 1.8833306630452473

Epoch: 6| Step: 8
Training loss: 0.6652443408966064
Validation loss: 1.888352632522583

Epoch: 6| Step: 9
Training loss: 0.6194607019424438
Validation loss: 1.8781181573867798

Epoch: 6| Step: 10
Training loss: 0.40912550687789917
Validation loss: 1.9180171092351277

Epoch: 6| Step: 11
Training loss: 0.41645094752311707
Validation loss: 1.8576962351799011

Epoch: 6| Step: 12
Training loss: 0.2957870364189148
Validation loss: 1.8713191548983257

Epoch: 6| Step: 13
Training loss: 0.7760589718818665
Validation loss: 1.9325855573018391

Epoch: 197| Step: 0
Training loss: 0.4908735454082489
Validation loss: 1.860357662041982

Epoch: 6| Step: 1
Training loss: 0.4102470874786377
Validation loss: 1.866345723470052

Epoch: 6| Step: 2
Training loss: 0.8481029868125916
Validation loss: 1.8964411815007527

Epoch: 6| Step: 3
Training loss: 0.5493996143341064
Validation loss: 1.8919034798940022

Epoch: 6| Step: 4
Training loss: 0.47442787885665894
Validation loss: 1.8958802024523418

Epoch: 6| Step: 5
Training loss: 0.23575015366077423
Validation loss: 1.9410577813784282

Epoch: 6| Step: 6
Training loss: 0.6567198634147644
Validation loss: 1.935826043287913

Epoch: 6| Step: 7
Training loss: 0.3270755112171173
Validation loss: 1.9004331231117249

Epoch: 6| Step: 8
Training loss: 0.6445464491844177
Validation loss: 1.9027513066927593

Epoch: 6| Step: 9
Training loss: 0.3727444112300873
Validation loss: 1.9429146250089009

Epoch: 6| Step: 10
Training loss: 0.6086006164550781
Validation loss: 1.8794851700464885

Epoch: 6| Step: 11
Training loss: 0.6458835005760193
Validation loss: 1.889601707458496

Epoch: 6| Step: 12
Training loss: 0.48082923889160156
Validation loss: 1.877203146616618

Epoch: 6| Step: 13
Training loss: 0.3796502649784088
Validation loss: 1.8881173729896545

Epoch: 198| Step: 0
Training loss: 0.5744442939758301
Validation loss: 1.908694605032603

Epoch: 6| Step: 1
Training loss: 0.8288821578025818
Validation loss: 1.885217308998108

Epoch: 6| Step: 2
Training loss: 0.2191455066204071
Validation loss: 1.9266446232795715

Epoch: 6| Step: 3
Training loss: 0.4001275897026062
Validation loss: 1.906990687052409

Epoch: 6| Step: 4
Training loss: 0.42330044507980347
Validation loss: 1.8933430314064026

Epoch: 6| Step: 5
Training loss: 0.8469047546386719
Validation loss: 1.9517773389816284

Epoch: 6| Step: 6
Training loss: 0.6221389770507812
Validation loss: 1.8962000807126362

Epoch: 6| Step: 7
Training loss: 1.154494047164917
Validation loss: 1.86753910779953

Epoch: 6| Step: 8
Training loss: 0.3391530215740204
Validation loss: 1.9021613597869873

Epoch: 6| Step: 9
Training loss: 0.41869038343429565
Validation loss: 1.881548245747884

Epoch: 6| Step: 10
Training loss: 0.3229502737522125
Validation loss: 1.8839465181032817

Epoch: 6| Step: 11
Training loss: 0.4312503933906555
Validation loss: 1.8989461660385132

Epoch: 6| Step: 12
Training loss: 0.4675130844116211
Validation loss: 1.8642946283022563

Epoch: 6| Step: 13
Training loss: 0.33942943811416626
Validation loss: 1.913664201895396

Epoch: 199| Step: 0
Training loss: 0.4061797261238098
Validation loss: 1.913022776444753

Epoch: 6| Step: 1
Training loss: 1.0095901489257812
Validation loss: 1.8985593517621357

Epoch: 6| Step: 2
Training loss: 0.25368165969848633
Validation loss: 1.9296751618385315

Epoch: 6| Step: 3
Training loss: 0.775748074054718
Validation loss: 1.9248505433400471

Epoch: 6| Step: 4
Training loss: 0.4734206795692444
Validation loss: 1.8967755635579426

Epoch: 6| Step: 5
Training loss: 0.620047926902771
Validation loss: 1.9055513540903728

Epoch: 6| Step: 6
Training loss: 0.6798788905143738
Validation loss: 1.8641950686772664

Epoch: 6| Step: 7
Training loss: 0.531105101108551
Validation loss: 1.9012107650438945

Epoch: 6| Step: 8
Training loss: 0.49624910950660706
Validation loss: 1.943368911743164

Epoch: 6| Step: 9
Training loss: 0.33370381593704224
Validation loss: 1.9247724413871765

Epoch: 6| Step: 10
Training loss: 0.3526290953159332
Validation loss: 1.8758055567741394

Epoch: 6| Step: 11
Training loss: 0.43469807505607605
Validation loss: 1.8696964780489604

Epoch: 6| Step: 12
Training loss: 0.5112914443016052
Validation loss: 1.9662425716718037

Epoch: 6| Step: 13
Training loss: 0.5515358448028564
Validation loss: 1.9108373920122783

Epoch: 200| Step: 0
Training loss: 0.24185407161712646
Validation loss: 1.8865010937054951

Epoch: 6| Step: 1
Training loss: 0.3721865713596344
Validation loss: 1.8575172225634258

Epoch: 6| Step: 2
Training loss: 0.6074377298355103
Validation loss: 1.9331570466359456

Epoch: 6| Step: 3
Training loss: 0.29024311900138855
Validation loss: 1.8547470370928447

Epoch: 6| Step: 4
Training loss: 0.38884198665618896
Validation loss: 1.9206949472427368

Epoch: 6| Step: 5
Training loss: 0.31041038036346436
Validation loss: 1.8845062255859375

Epoch: 6| Step: 6
Training loss: 0.5889972448348999
Validation loss: 1.9132004578908284

Epoch: 6| Step: 7
Training loss: 0.7452114224433899
Validation loss: 1.9113503098487854

Epoch: 6| Step: 8
Training loss: 0.9259139895439148
Validation loss: 1.9291775623957317

Epoch: 6| Step: 9
Training loss: 0.4021878242492676
Validation loss: 1.920557181040446

Epoch: 6| Step: 10
Training loss: 0.45425039529800415
Validation loss: 1.9601611097653706

Epoch: 6| Step: 11
Training loss: 0.6176989078521729
Validation loss: 1.950174371401469

Epoch: 6| Step: 12
Training loss: 0.6656627058982849
Validation loss: 1.8863234519958496

Epoch: 6| Step: 13
Training loss: 0.590462327003479
Validation loss: 1.9485527276992798

Epoch: 201| Step: 0
Training loss: 0.46527349948883057
Validation loss: 1.8956172466278076

Epoch: 6| Step: 1
Training loss: 0.38644278049468994
Validation loss: 1.9202311038970947

Epoch: 6| Step: 2
Training loss: 0.18828696012496948
Validation loss: 1.8977250655492146

Epoch: 6| Step: 3
Training loss: 0.45573800802230835
Validation loss: 1.8931395411491394

Epoch: 6| Step: 4
Training loss: 0.8878604173660278
Validation loss: 1.837203045686086

Epoch: 6| Step: 5
Training loss: 0.508741021156311
Validation loss: 1.8765811324119568

Epoch: 6| Step: 6
Training loss: 0.31920626759529114
Validation loss: 1.8840735753377278

Epoch: 6| Step: 7
Training loss: 0.7022768259048462
Validation loss: 1.857636829217275

Epoch: 6| Step: 8
Training loss: 0.2533276379108429
Validation loss: 1.8859588503837585

Epoch: 6| Step: 9
Training loss: 0.2157089114189148
Validation loss: 1.8989475965499878

Epoch: 6| Step: 10
Training loss: 0.5355610847473145
Validation loss: 1.879399836063385

Epoch: 6| Step: 11
Training loss: 0.631610095500946
Validation loss: 1.817690670490265

Epoch: 6| Step: 12
Training loss: 0.581785261631012
Validation loss: 1.882850746313731

Epoch: 6| Step: 13
Training loss: 0.7013094425201416
Validation loss: 1.8784611423810322

Epoch: 202| Step: 0
Training loss: 0.21337249875068665
Validation loss: 1.8466943899790447

Epoch: 6| Step: 1
Training loss: 0.6879370808601379
Validation loss: 1.9176095128059387

Epoch: 6| Step: 2
Training loss: 0.8503386974334717
Validation loss: 1.947906732559204

Epoch: 6| Step: 3
Training loss: 0.5298106670379639
Validation loss: 1.8922797044118245

Epoch: 6| Step: 4
Training loss: 0.6013833284378052
Validation loss: 1.906064510345459

Epoch: 6| Step: 5
Training loss: 0.8090486526489258
Validation loss: 1.9068967898686726

Epoch: 6| Step: 6
Training loss: 0.4365922808647156
Validation loss: 1.9214061697324116

Epoch: 6| Step: 7
Training loss: 0.25817182660102844
Validation loss: 1.9014410575230916

Epoch: 6| Step: 8
Training loss: 0.7695295810699463
Validation loss: 1.8751839796702068

Epoch: 6| Step: 9
Training loss: 0.403664231300354
Validation loss: 1.8771134813626607

Epoch: 6| Step: 10
Training loss: 0.46808362007141113
Validation loss: 1.846289058526357

Epoch: 6| Step: 11
Training loss: 0.6117125749588013
Validation loss: 1.8823005358378093

Epoch: 6| Step: 12
Training loss: 0.41443872451782227
Validation loss: 1.8880140980084736

Epoch: 6| Step: 13
Training loss: 0.6296874284744263
Validation loss: 1.873140772183736

Epoch: 203| Step: 0
Training loss: 0.3998250663280487
Validation loss: 1.9369208812713623

Epoch: 6| Step: 1
Training loss: 0.7036119699478149
Validation loss: 1.858183761437734

Epoch: 6| Step: 2
Training loss: 0.4605315923690796
Validation loss: 1.8983775575955708

Epoch: 6| Step: 3
Training loss: 0.17159992456436157
Validation loss: 1.9006362756093342

Epoch: 6| Step: 4
Training loss: 0.39478573203086853
Validation loss: 1.8751792907714844

Epoch: 6| Step: 5
Training loss: 0.5768948793411255
Validation loss: 1.9520609776178997

Epoch: 6| Step: 6
Training loss: 0.44561272859573364
Validation loss: 1.94195556640625

Epoch: 6| Step: 7
Training loss: 0.5058135390281677
Validation loss: 1.9557533264160156

Epoch: 6| Step: 8
Training loss: 0.9461613893508911
Validation loss: 1.825674831867218

Epoch: 6| Step: 9
Training loss: 0.5788114666938782
Validation loss: 1.908171832561493

Epoch: 6| Step: 10
Training loss: 0.37304162979125977
Validation loss: 1.9082512855529785

Epoch: 6| Step: 11
Training loss: 0.3147014081478119
Validation loss: 1.9204935630162556

Epoch: 6| Step: 12
Training loss: 1.0068027973175049
Validation loss: 1.9405825932820637

Epoch: 6| Step: 13
Training loss: 0.3947306275367737
Validation loss: 1.928731640179952

Epoch: 204| Step: 0
Training loss: 0.8550419211387634
Validation loss: 1.956620494524638

Epoch: 6| Step: 1
Training loss: 0.8116406202316284
Validation loss: 1.8661483526229858

Epoch: 6| Step: 2
Training loss: 0.16058731079101562
Validation loss: 1.8946524659792583

Epoch: 6| Step: 3
Training loss: 0.4478304982185364
Validation loss: 1.8675483862559001

Epoch: 6| Step: 4
Training loss: 0.8128308057785034
Validation loss: 1.896957516670227

Epoch: 6| Step: 5
Training loss: 0.8363124132156372
Validation loss: 1.8908969163894653

Epoch: 6| Step: 6
Training loss: 0.46980828046798706
Validation loss: 1.8562135497728984

Epoch: 6| Step: 7
Training loss: 0.47714921832084656
Validation loss: 1.8978636463483174

Epoch: 6| Step: 8
Training loss: 0.5439980626106262
Validation loss: 1.9048975507418315

Epoch: 6| Step: 9
Training loss: 0.5502625107765198
Validation loss: 1.8926830689112346

Epoch: 6| Step: 10
Training loss: 0.5402055978775024
Validation loss: 1.8948973218599956

Epoch: 6| Step: 11
Training loss: 0.4080940783023834
Validation loss: 1.8795316020647685

Epoch: 6| Step: 12
Training loss: 0.3021663725376129
Validation loss: 1.9091363350550334

Epoch: 6| Step: 13
Training loss: 0.48694074153900146
Validation loss: 1.8874692519505818

Epoch: 205| Step: 0
Training loss: 0.33437931537628174
Validation loss: 1.9650225043296814

Epoch: 6| Step: 1
Training loss: 0.9105600118637085
Validation loss: 1.9088067015012105

Epoch: 6| Step: 2
Training loss: 0.5590395927429199
Validation loss: 1.8862733840942383

Epoch: 6| Step: 3
Training loss: 0.5373220443725586
Validation loss: 1.8828848401705425

Epoch: 6| Step: 4
Training loss: 0.3498515188694
Validation loss: 1.8926158944765727

Epoch: 6| Step: 5
Training loss: 0.4665984511375427
Validation loss: 1.9006508787473042

Epoch: 6| Step: 6
Training loss: 0.415801465511322
Validation loss: 1.9136264125506084

Epoch: 6| Step: 7
Training loss: 0.4925040006637573
Validation loss: 1.8774073521296184

Epoch: 6| Step: 8
Training loss: 0.7575225830078125
Validation loss: 1.9141446948051453

Epoch: 6| Step: 9
Training loss: 0.47968968749046326
Validation loss: 1.9090176622072856

Epoch: 6| Step: 10
Training loss: 0.3215346336364746
Validation loss: 1.8457758625348408

Epoch: 6| Step: 11
Training loss: 0.8784418702125549
Validation loss: 1.929746190706889

Epoch: 6| Step: 12
Training loss: 0.38355714082717896
Validation loss: 1.9071602026621501

Epoch: 6| Step: 13
Training loss: 0.3112674951553345
Validation loss: 1.8442965348561604

Epoch: 206| Step: 0
Training loss: 0.49747562408447266
Validation loss: 1.9325124621391296

Epoch: 6| Step: 1
Training loss: 0.760577917098999
Validation loss: 1.8958959182103474

Epoch: 6| Step: 2
Training loss: 0.3060271739959717
Validation loss: 1.8652785817782085

Epoch: 6| Step: 3
Training loss: 0.23983711004257202
Validation loss: 1.8614687124888103

Epoch: 6| Step: 4
Training loss: 0.5670945644378662
Validation loss: 1.8606485724449158

Epoch: 6| Step: 5
Training loss: 0.20894569158554077
Validation loss: 1.8505073587099712

Epoch: 6| Step: 6
Training loss: 0.31251150369644165
Validation loss: 1.8640886743863423

Epoch: 6| Step: 7
Training loss: 0.4215747117996216
Validation loss: 1.896094302336375

Epoch: 6| Step: 8
Training loss: 0.4226835370063782
Validation loss: 1.8621724446614583

Epoch: 6| Step: 9
Training loss: 1.0759217739105225
Validation loss: 1.9138740301132202

Epoch: 6| Step: 10
Training loss: 0.24908167123794556
Validation loss: 1.8681671619415283

Epoch: 6| Step: 11
Training loss: 0.3821101486682892
Validation loss: 1.887006938457489

Epoch: 6| Step: 12
Training loss: 0.7120116949081421
Validation loss: 1.8707178433736165

Epoch: 6| Step: 13
Training loss: 0.7109487056732178
Validation loss: 1.866655747095744

Epoch: 207| Step: 0
Training loss: 0.2858934998512268
Validation loss: 1.877617339293162

Epoch: 6| Step: 1
Training loss: 0.8628121614456177
Validation loss: 1.8964483539263408

Epoch: 6| Step: 2
Training loss: 0.49741607904434204
Validation loss: 1.9305294156074524

Epoch: 6| Step: 3
Training loss: 0.2680678963661194
Validation loss: 1.9059050877888997

Epoch: 6| Step: 4
Training loss: 0.35563361644744873
Validation loss: 1.9216249585151672

Epoch: 6| Step: 5
Training loss: 0.4863819479942322
Validation loss: 1.8873204986254375

Epoch: 6| Step: 6
Training loss: 0.9601294994354248
Validation loss: 1.9414007067680359

Epoch: 6| Step: 7
Training loss: 0.5675641298294067
Validation loss: 1.902316153049469

Epoch: 6| Step: 8
Training loss: 0.44412297010421753
Validation loss: 1.9084336360295613

Epoch: 6| Step: 9
Training loss: 0.47464343905448914
Validation loss: 1.9200180768966675

Epoch: 6| Step: 10
Training loss: 0.26498502492904663
Validation loss: 1.888108452161153

Epoch: 6| Step: 11
Training loss: 0.3975032567977905
Validation loss: 1.9183704058329265

Epoch: 6| Step: 12
Training loss: 0.6614201664924622
Validation loss: 1.9180134534835815

Epoch: 6| Step: 13
Training loss: 0.45530247688293457
Validation loss: 1.9181175629297893

Epoch: 208| Step: 0
Training loss: 0.5832951068878174
Validation loss: 1.9305286606152852

Epoch: 6| Step: 1
Training loss: 0.7488022446632385
Validation loss: 1.8642164667447407

Epoch: 6| Step: 2
Training loss: 0.35627853870391846
Validation loss: 1.8732244769732158

Epoch: 6| Step: 3
Training loss: 0.46776875853538513
Validation loss: 1.881365954875946

Epoch: 6| Step: 4
Training loss: 0.2657397389411926
Validation loss: 1.889204700787862

Epoch: 6| Step: 5
Training loss: 0.681655764579773
Validation loss: 1.9384033878644307

Epoch: 6| Step: 6
Training loss: 0.42981499433517456
Validation loss: 1.902906874815623

Epoch: 6| Step: 7
Training loss: 0.32022470235824585
Validation loss: 1.9338352282842

Epoch: 6| Step: 8
Training loss: 0.8459557890892029
Validation loss: 1.8786161541938782

Epoch: 6| Step: 9
Training loss: 0.43617936968803406
Validation loss: 1.9302236040433247

Epoch: 6| Step: 10
Training loss: 0.41613519191741943
Validation loss: 1.9081884026527405

Epoch: 6| Step: 11
Training loss: 0.5376710295677185
Validation loss: 1.8610055049260457

Epoch: 6| Step: 12
Training loss: 0.4065483808517456
Validation loss: 1.9016027450561523

Epoch: 6| Step: 13
Training loss: 0.43910932540893555
Validation loss: 1.868743320306142

Epoch: 209| Step: 0
Training loss: 0.9910537004470825
Validation loss: 1.9184020558993022

Epoch: 6| Step: 1
Training loss: 0.18697698414325714
Validation loss: 1.8978320757548015

Epoch: 6| Step: 2
Training loss: 0.5047743320465088
Validation loss: 1.9257099231084187

Epoch: 6| Step: 3
Training loss: 0.4676869511604309
Validation loss: 1.9197685321172078

Epoch: 6| Step: 4
Training loss: 0.6155662536621094
Validation loss: 1.912794788678487

Epoch: 6| Step: 5
Training loss: 0.19547691941261292
Validation loss: 1.842494249343872

Epoch: 6| Step: 6
Training loss: 0.6169874668121338
Validation loss: 1.8706205288569133

Epoch: 6| Step: 7
Training loss: 0.6378072500228882
Validation loss: 1.879713237285614

Epoch: 6| Step: 8
Training loss: 0.2922815680503845
Validation loss: 1.8951146205266316

Epoch: 6| Step: 9
Training loss: 0.23951545357704163
Validation loss: 1.9054793516794841

Epoch: 6| Step: 10
Training loss: 0.2916734218597412
Validation loss: 1.8583138982454936

Epoch: 6| Step: 11
Training loss: 0.43911346793174744
Validation loss: 1.8863980372746785

Epoch: 6| Step: 12
Training loss: 0.5520327091217041
Validation loss: 1.8933684627215068

Epoch: 6| Step: 13
Training loss: 0.3991488814353943
Validation loss: 1.8428749640782673

Epoch: 210| Step: 0
Training loss: 0.687067985534668
Validation loss: 1.8528957565625508

Epoch: 6| Step: 1
Training loss: 0.3973221778869629
Validation loss: 1.8489649097124736

Epoch: 6| Step: 2
Training loss: 0.6753886938095093
Validation loss: 1.89452330271403

Epoch: 6| Step: 3
Training loss: 0.501076340675354
Validation loss: 1.8816682895024617

Epoch: 6| Step: 4
Training loss: 0.5224543213844299
Validation loss: 1.8913365403811138

Epoch: 6| Step: 5
Training loss: 0.6098002195358276
Validation loss: 1.8409405152002971

Epoch: 6| Step: 6
Training loss: 0.2828376591205597
Validation loss: 1.8894580801328023

Epoch: 6| Step: 7
Training loss: 0.5568590760231018
Validation loss: 1.8611843784650166

Epoch: 6| Step: 8
Training loss: 0.3639281690120697
Validation loss: 1.861716349919637

Epoch: 6| Step: 9
Training loss: 0.45791879296302795
Validation loss: 1.8983882665634155

Epoch: 6| Step: 10
Training loss: 0.32615429162979126
Validation loss: 1.8839664061864216

Epoch: 6| Step: 11
Training loss: 0.3238345980644226
Validation loss: 1.9126951098442078

Epoch: 6| Step: 12
Training loss: 0.5815114974975586
Validation loss: 1.8604933023452759

Epoch: 6| Step: 13
Training loss: 0.5564186573028564
Validation loss: 1.8848305344581604

Epoch: 211| Step: 0
Training loss: 0.6852397322654724
Validation loss: 1.8943393031756084

Epoch: 6| Step: 1
Training loss: 0.6633473634719849
Validation loss: 1.9123405416806538

Epoch: 6| Step: 2
Training loss: 0.7785780429840088
Validation loss: 1.9290864864985149

Epoch: 6| Step: 3
Training loss: 0.5032538771629333
Validation loss: 1.899764319260915

Epoch: 6| Step: 4
Training loss: 0.43934541940689087
Validation loss: 1.8869640032450359

Epoch: 6| Step: 5
Training loss: 0.47252246737480164
Validation loss: 1.9039298295974731

Epoch: 6| Step: 6
Training loss: 0.4113418161869049
Validation loss: 1.8892524441083272

Epoch: 6| Step: 7
Training loss: 0.33138778805732727
Validation loss: 1.8981949090957642

Epoch: 6| Step: 8
Training loss: 0.5830228924751282
Validation loss: 1.9295960863431294

Epoch: 6| Step: 9
Training loss: 0.48299962282180786
Validation loss: 1.8292175928751628

Epoch: 6| Step: 10
Training loss: 0.3407962918281555
Validation loss: 1.91029953956604

Epoch: 6| Step: 11
Training loss: 0.5132169723510742
Validation loss: 1.9276116689046223

Epoch: 6| Step: 12
Training loss: 0.2346266210079193
Validation loss: 1.9328668713569641

Epoch: 6| Step: 13
Training loss: 0.3646194338798523
Validation loss: 1.9023221532503765

Epoch: 212| Step: 0
Training loss: 0.3846302032470703
Validation loss: 1.8798803289731343

Epoch: 6| Step: 1
Training loss: 0.4494878649711609
Validation loss: 1.935744841893514

Epoch: 6| Step: 2
Training loss: 0.37531009316444397
Validation loss: 1.9167550802230835

Epoch: 6| Step: 3
Training loss: 0.5780370831489563
Validation loss: 1.913222074508667

Epoch: 6| Step: 4
Training loss: 0.309059202671051
Validation loss: 1.8834535280863445

Epoch: 6| Step: 5
Training loss: 0.21878638863563538
Validation loss: 1.9000796675682068

Epoch: 6| Step: 6
Training loss: 0.5641056299209595
Validation loss: 1.9076533516248066

Epoch: 6| Step: 7
Training loss: 0.6454792618751526
Validation loss: 1.8696186741193135

Epoch: 6| Step: 8
Training loss: 0.7528643608093262
Validation loss: 1.8759861787160237

Epoch: 6| Step: 9
Training loss: 0.4438457787036896
Validation loss: 1.940182050069173

Epoch: 6| Step: 10
Training loss: 0.4326572120189667
Validation loss: 1.8927822907765706

Epoch: 6| Step: 11
Training loss: 0.5973636507987976
Validation loss: 1.8966115514437358

Epoch: 6| Step: 12
Training loss: 0.25420939922332764
Validation loss: 1.8534959157307942

Epoch: 6| Step: 13
Training loss: 0.41261163353919983
Validation loss: 1.860412855943044

Epoch: 213| Step: 0
Training loss: 0.5337396264076233
Validation loss: 1.8758615851402283

Epoch: 6| Step: 1
Training loss: 0.3514787256717682
Validation loss: 1.8866317669550579

Epoch: 6| Step: 2
Training loss: 0.6320945620536804
Validation loss: 1.8946339289347331

Epoch: 6| Step: 3
Training loss: 0.3120844066143036
Validation loss: 1.8902008533477783

Epoch: 6| Step: 4
Training loss: 0.29184648394584656
Validation loss: 1.8969348470369976

Epoch: 6| Step: 5
Training loss: 0.30541539192199707
Validation loss: 1.874847372372945

Epoch: 6| Step: 6
Training loss: 0.6057784557342529
Validation loss: 1.8483227292696636

Epoch: 6| Step: 7
Training loss: 0.7951783537864685
Validation loss: 1.9006700317064922

Epoch: 6| Step: 8
Training loss: 0.48968687653541565
Validation loss: 1.828888734181722

Epoch: 6| Step: 9
Training loss: 0.2563045024871826
Validation loss: 1.9038394292195637

Epoch: 6| Step: 10
Training loss: 0.23809319734573364
Validation loss: 1.9142900904019673

Epoch: 6| Step: 11
Training loss: 0.3728446662425995
Validation loss: 1.9115079641342163

Epoch: 6| Step: 12
Training loss: 0.6567974090576172
Validation loss: 1.8895036578178406

Epoch: 6| Step: 13
Training loss: 0.2825360894203186
Validation loss: 1.9330133597056072

Epoch: 214| Step: 0
Training loss: 0.2688312530517578
Validation loss: 1.9195621013641357

Epoch: 6| Step: 1
Training loss: 0.4738149046897888
Validation loss: 1.9044416546821594

Epoch: 6| Step: 2
Training loss: 0.3358987867832184
Validation loss: 1.8999433120091755

Epoch: 6| Step: 3
Training loss: 0.3969215154647827
Validation loss: 1.9097023804982503

Epoch: 6| Step: 4
Training loss: 0.466640830039978
Validation loss: 1.8822195728619893

Epoch: 6| Step: 5
Training loss: 0.9185957312583923
Validation loss: 1.8949618736902873

Epoch: 6| Step: 6
Training loss: 0.5624616146087646
Validation loss: 1.8998496532440186

Epoch: 6| Step: 7
Training loss: 0.29737135767936707
Validation loss: 1.8974585731824238

Epoch: 6| Step: 8
Training loss: 0.6120167374610901
Validation loss: 1.909065584341685

Epoch: 6| Step: 9
Training loss: 0.5410709381103516
Validation loss: 1.8929502566655476

Epoch: 6| Step: 10
Training loss: 0.38106346130371094
Validation loss: 1.8645427028338115

Epoch: 6| Step: 11
Training loss: 0.39566147327423096
Validation loss: 1.9067827661832173

Epoch: 6| Step: 12
Training loss: 0.6067494750022888
Validation loss: 1.9171280264854431

Epoch: 6| Step: 13
Training loss: 0.4641570448875427
Validation loss: 1.913346568743388

Epoch: 215| Step: 0
Training loss: 0.49187907576560974
Validation loss: 1.8954006830851238

Epoch: 6| Step: 1
Training loss: 0.32686740159988403
Validation loss: 1.9393332203229268

Epoch: 6| Step: 2
Training loss: 0.5199960470199585
Validation loss: 1.92678968111674

Epoch: 6| Step: 3
Training loss: 0.6541804075241089
Validation loss: 1.9172935287157695

Epoch: 6| Step: 4
Training loss: 0.4493166208267212
Validation loss: 1.9225093722343445

Epoch: 6| Step: 5
Training loss: 0.472548246383667
Validation loss: 1.8783594965934753

Epoch: 6| Step: 6
Training loss: 0.24261000752449036
Validation loss: 1.926351527372996

Epoch: 6| Step: 7
Training loss: 0.765550971031189
Validation loss: 1.831994314988454

Epoch: 6| Step: 8
Training loss: 0.6025940179824829
Validation loss: 1.899721384048462

Epoch: 6| Step: 9
Training loss: 0.42912182211875916
Validation loss: 1.9482211470603943

Epoch: 6| Step: 10
Training loss: 0.3673584759235382
Validation loss: 1.8983582655588787

Epoch: 6| Step: 11
Training loss: 0.30379337072372437
Validation loss: 1.903542399406433

Epoch: 6| Step: 12
Training loss: 0.32305291295051575
Validation loss: 1.8635011911392212

Epoch: 6| Step: 13
Training loss: 0.4306403696537018
Validation loss: 1.9004934827486675

Epoch: 216| Step: 0
Training loss: 0.5693287253379822
Validation loss: 1.9141672650973003

Epoch: 6| Step: 1
Training loss: 0.3038215637207031
Validation loss: 1.9156284928321838

Epoch: 6| Step: 2
Training loss: 0.5465602278709412
Validation loss: 1.9300453265508015

Epoch: 6| Step: 3
Training loss: 0.5755630731582642
Validation loss: 1.8556552926699321

Epoch: 6| Step: 4
Training loss: 0.38715797662734985
Validation loss: 1.9082964062690735

Epoch: 6| Step: 5
Training loss: 0.7005860805511475
Validation loss: 1.9885425964991252

Epoch: 6| Step: 6
Training loss: 0.25403791666030884
Validation loss: 1.8528616229693096

Epoch: 6| Step: 7
Training loss: 0.5455129146575928
Validation loss: 1.9141757885615032

Epoch: 6| Step: 8
Training loss: 0.5418215990066528
Validation loss: 1.9108947118123372

Epoch: 6| Step: 9
Training loss: 0.37893182039260864
Validation loss: 1.9630677103996277

Epoch: 6| Step: 10
Training loss: 0.641749918460846
Validation loss: 1.9035541415214539

Epoch: 6| Step: 11
Training loss: 0.3907371163368225
Validation loss: 1.8423333366711934

Epoch: 6| Step: 12
Training loss: 0.2401474416255951
Validation loss: 1.897270659605662

Epoch: 6| Step: 13
Training loss: 0.6231502890586853
Validation loss: 1.9139233032862346

Epoch: 217| Step: 0
Training loss: 0.6632475852966309
Validation loss: 1.8820278644561768

Epoch: 6| Step: 1
Training loss: 0.6560029983520508
Validation loss: 1.8898234168688457

Epoch: 6| Step: 2
Training loss: 0.4375969469547272
Validation loss: 1.9027008016904194

Epoch: 6| Step: 3
Training loss: 0.308096706867218
Validation loss: 1.9081904490788777

Epoch: 6| Step: 4
Training loss: 0.3814300298690796
Validation loss: 1.9317384958267212

Epoch: 6| Step: 5
Training loss: 0.6103376150131226
Validation loss: 1.9101690451304119

Epoch: 6| Step: 6
Training loss: 0.29219409823417664
Validation loss: 1.9631241361300151

Epoch: 6| Step: 7
Training loss: 0.38358360528945923
Validation loss: 1.912822703520457

Epoch: 6| Step: 8
Training loss: 0.3010566532611847
Validation loss: 1.9560747543970745

Epoch: 6| Step: 9
Training loss: 0.3336697518825531
Validation loss: 1.910462458928426

Epoch: 6| Step: 10
Training loss: 0.8012689352035522
Validation loss: 1.8822507659594219

Epoch: 6| Step: 11
Training loss: 0.5087121725082397
Validation loss: 1.862637460231781

Epoch: 6| Step: 12
Training loss: 0.5444374084472656
Validation loss: 1.9157772064208984

Epoch: 6| Step: 13
Training loss: 0.4250994920730591
Validation loss: 1.9103195071220398

Epoch: 218| Step: 0
Training loss: 0.38364848494529724
Validation loss: 1.905698537826538

Epoch: 6| Step: 1
Training loss: 0.3943771421909332
Validation loss: 1.882745047410329

Epoch: 6| Step: 2
Training loss: 0.42908328771591187
Validation loss: 1.915714681148529

Epoch: 6| Step: 3
Training loss: 0.4565400183200836
Validation loss: 1.90434730052948

Epoch: 6| Step: 4
Training loss: 0.6441541910171509
Validation loss: 1.8997084299723308

Epoch: 6| Step: 5
Training loss: 0.5480396747589111
Validation loss: 1.89383202791214

Epoch: 6| Step: 6
Training loss: 0.2676793336868286
Validation loss: 1.9018686215082805

Epoch: 6| Step: 7
Training loss: 0.512649416923523
Validation loss: 1.8784990509351094

Epoch: 6| Step: 8
Training loss: 0.4366638660430908
Validation loss: 1.8776047229766846

Epoch: 6| Step: 9
Training loss: 0.7370775938034058
Validation loss: 1.8626322944959004

Epoch: 6| Step: 10
Training loss: 0.30474287271499634
Validation loss: 1.8722609281539917

Epoch: 6| Step: 11
Training loss: 0.22983504831790924
Validation loss: 1.8610318501790364

Epoch: 6| Step: 12
Training loss: 0.36357611417770386
Validation loss: 1.914328932762146

Epoch: 6| Step: 13
Training loss: 0.7551230192184448
Validation loss: 1.8836565415064495

Epoch: 219| Step: 0
Training loss: 0.44953659176826477
Validation loss: 1.8990700840950012

Epoch: 6| Step: 1
Training loss: 0.36156314611434937
Validation loss: 1.8844420711199443

Epoch: 6| Step: 2
Training loss: 0.38740479946136475
Validation loss: 1.8441185156504314

Epoch: 6| Step: 3
Training loss: 0.3590485453605652
Validation loss: 1.8802165985107422

Epoch: 6| Step: 4
Training loss: 0.26979607343673706
Validation loss: 1.8506555755933125

Epoch: 6| Step: 5
Training loss: 0.38668733835220337
Validation loss: 1.8593849142392476

Epoch: 6| Step: 6
Training loss: 0.30884653329849243
Validation loss: 1.8968843420346577

Epoch: 6| Step: 7
Training loss: 0.19289010763168335
Validation loss: 1.889293869336446

Epoch: 6| Step: 8
Training loss: 0.509283185005188
Validation loss: 1.9052716294924419

Epoch: 6| Step: 9
Training loss: 1.1905699968338013
Validation loss: 1.870755175749461

Epoch: 6| Step: 10
Training loss: 0.4065900444984436
Validation loss: 1.8924103577931721

Epoch: 6| Step: 11
Training loss: 0.4449364244937897
Validation loss: 1.8915706475575764

Epoch: 6| Step: 12
Training loss: 0.4833458662033081
Validation loss: 1.8687865336736043

Epoch: 6| Step: 13
Training loss: 0.5501525402069092
Validation loss: 1.8645480871200562

Epoch: 220| Step: 0
Training loss: 0.3576720654964447
Validation loss: 1.902535120646159

Epoch: 6| Step: 1
Training loss: 0.5712342262268066
Validation loss: 1.883477548758189

Epoch: 6| Step: 2
Training loss: 0.5198367834091187
Validation loss: 1.8603348930676777

Epoch: 6| Step: 3
Training loss: 0.6429893970489502
Validation loss: 1.8831215500831604

Epoch: 6| Step: 4
Training loss: 0.339691162109375
Validation loss: 1.9068337480227153

Epoch: 6| Step: 5
Training loss: 0.7436769604682922
Validation loss: 1.8469104568163555

Epoch: 6| Step: 6
Training loss: 0.29999667406082153
Validation loss: 1.8181896408398945

Epoch: 6| Step: 7
Training loss: 0.21416059136390686
Validation loss: 1.8704070250193279

Epoch: 6| Step: 8
Training loss: 0.46875524520874023
Validation loss: 1.8997971614201863

Epoch: 6| Step: 9
Training loss: 0.6726073026657104
Validation loss: 1.8895792762438457

Epoch: 6| Step: 10
Training loss: 0.5010625123977661
Validation loss: 1.8766415119171143

Epoch: 6| Step: 11
Training loss: 0.5807258486747742
Validation loss: 1.906464159488678

Epoch: 6| Step: 12
Training loss: 0.38522449135780334
Validation loss: 1.9188216924667358

Epoch: 6| Step: 13
Training loss: 0.33757269382476807
Validation loss: 1.9044901728630066

Epoch: 221| Step: 0
Training loss: 0.46449872851371765
Validation loss: 1.8973948955535889

Epoch: 6| Step: 1
Training loss: 0.438279390335083
Validation loss: 1.851077417532603

Epoch: 6| Step: 2
Training loss: 0.6617542505264282
Validation loss: 1.8824681242307026

Epoch: 6| Step: 3
Training loss: 0.2951623499393463
Validation loss: 1.89773827791214

Epoch: 6| Step: 4
Training loss: 0.4216741919517517
Validation loss: 1.870737910270691

Epoch: 6| Step: 5
Training loss: 0.6191814541816711
Validation loss: 1.872795859972636

Epoch: 6| Step: 6
Training loss: 0.25587207078933716
Validation loss: 1.912308156490326

Epoch: 6| Step: 7
Training loss: 1.0309371948242188
Validation loss: 1.8973259329795837

Epoch: 6| Step: 8
Training loss: 0.08528854697942734
Validation loss: 1.9330732425053914

Epoch: 6| Step: 9
Training loss: 0.32196444272994995
Validation loss: 1.9319162368774414

Epoch: 6| Step: 10
Training loss: 0.4744056761264801
Validation loss: 1.8972266912460327

Epoch: 6| Step: 11
Training loss: 0.5160308480262756
Validation loss: 1.8877784609794617

Epoch: 6| Step: 12
Training loss: 0.5930237770080566
Validation loss: 1.9072216947873433

Epoch: 6| Step: 13
Training loss: 0.18392513692378998
Validation loss: 1.8340924382209778

Epoch: 222| Step: 0
Training loss: 0.5887095928192139
Validation loss: 1.9105362097422283

Epoch: 6| Step: 1
Training loss: 0.5167144536972046
Validation loss: 1.8468359311421711

Epoch: 6| Step: 2
Training loss: 0.3970811367034912
Validation loss: 1.8692206541697185

Epoch: 6| Step: 3
Training loss: 0.22948205471038818
Validation loss: 1.8950486381848652

Epoch: 6| Step: 4
Training loss: 0.35761916637420654
Validation loss: 1.8601584235827129

Epoch: 6| Step: 5
Training loss: 0.5826643705368042
Validation loss: 1.897584577401479

Epoch: 6| Step: 6
Training loss: 0.8820863366127014
Validation loss: 1.889161765575409

Epoch: 6| Step: 7
Training loss: 0.2985471487045288
Validation loss: 1.9237421154975891

Epoch: 6| Step: 8
Training loss: 0.47611868381500244
Validation loss: 1.880643645922343

Epoch: 6| Step: 9
Training loss: 0.2592984735965729
Validation loss: 1.8515042662620544

Epoch: 6| Step: 10
Training loss: 0.48380130529403687
Validation loss: 1.9064085284868877

Epoch: 6| Step: 11
Training loss: 0.4800088405609131
Validation loss: 1.860714892546336

Epoch: 6| Step: 12
Training loss: 0.18388377130031586
Validation loss: 1.9017560482025146

Epoch: 6| Step: 13
Training loss: 0.5812481641769409
Validation loss: 1.8801465233167012

Epoch: 223| Step: 0
Training loss: 0.5436059236526489
Validation loss: 1.9528344472249348

Epoch: 6| Step: 1
Training loss: 0.5638375878334045
Validation loss: 1.875126341978709

Epoch: 6| Step: 2
Training loss: 0.3239192068576813
Validation loss: 1.8551843365033467

Epoch: 6| Step: 3
Training loss: 0.3115888833999634
Validation loss: 1.8554082314173381

Epoch: 6| Step: 4
Training loss: 0.33140215277671814
Validation loss: 1.8958859046300252

Epoch: 6| Step: 5
Training loss: 0.5559442043304443
Validation loss: 1.8604111075401306

Epoch: 6| Step: 6
Training loss: 0.8714685440063477
Validation loss: 1.8510267933209736

Epoch: 6| Step: 7
Training loss: 0.724215567111969
Validation loss: 1.8817275365193684

Epoch: 6| Step: 8
Training loss: 0.3860173225402832
Validation loss: 1.8684989213943481

Epoch: 6| Step: 9
Training loss: 0.5094122886657715
Validation loss: 1.850191871325175

Epoch: 6| Step: 10
Training loss: 0.9673919677734375
Validation loss: 1.858628511428833

Epoch: 6| Step: 11
Training loss: 0.37802284955978394
Validation loss: 1.8553009231885274

Epoch: 6| Step: 12
Training loss: 0.4835578501224518
Validation loss: 1.88872629404068

Epoch: 6| Step: 13
Training loss: 0.3901252746582031
Validation loss: 1.9024085601170857

Epoch: 224| Step: 0
Training loss: 0.3388906717300415
Validation loss: 1.890960415204366

Epoch: 6| Step: 1
Training loss: 0.27332887053489685
Validation loss: 1.9237185716629028

Epoch: 6| Step: 2
Training loss: 0.6736992597579956
Validation loss: 1.8521710236867268

Epoch: 6| Step: 3
Training loss: 0.6387609243392944
Validation loss: 1.8692095478375752

Epoch: 6| Step: 4
Training loss: 0.34893447160720825
Validation loss: 1.9002265334129333

Epoch: 6| Step: 5
Training loss: 0.4420350193977356
Validation loss: 1.8945050438245137

Epoch: 6| Step: 6
Training loss: 0.6675798296928406
Validation loss: 1.8745054999987285

Epoch: 6| Step: 7
Training loss: 0.3101385831832886
Validation loss: 1.8753891587257385

Epoch: 6| Step: 8
Training loss: 0.5530985593795776
Validation loss: 1.8607685764630635

Epoch: 6| Step: 9
Training loss: 0.2732009291648865
Validation loss: 1.9280126889546711

Epoch: 6| Step: 10
Training loss: 0.5481180548667908
Validation loss: 1.8586799105008442

Epoch: 6| Step: 11
Training loss: 0.22891977429389954
Validation loss: 1.8944043318430583

Epoch: 6| Step: 12
Training loss: 0.42860668897628784
Validation loss: 1.9388923645019531

Epoch: 6| Step: 13
Training loss: 0.4596646726131439
Validation loss: 1.8875481287638347

Epoch: 225| Step: 0
Training loss: 0.525174617767334
Validation loss: 1.86050683259964

Epoch: 6| Step: 1
Training loss: 0.3344627022743225
Validation loss: 1.873049219449361

Epoch: 6| Step: 2
Training loss: 0.4167943298816681
Validation loss: 1.8713112076123555

Epoch: 6| Step: 3
Training loss: 0.3408294916152954
Validation loss: 1.8477466901143391

Epoch: 6| Step: 4
Training loss: 0.30723923444747925
Validation loss: 1.879773497581482

Epoch: 6| Step: 5
Training loss: 0.5344387292861938
Validation loss: 1.8913774092992146

Epoch: 6| Step: 6
Training loss: 0.47457993030548096
Validation loss: 1.869466761747996

Epoch: 6| Step: 7
Training loss: 0.2998393476009369
Validation loss: 1.9128194053967793

Epoch: 6| Step: 8
Training loss: 0.22133825719356537
Validation loss: 1.859435220559438

Epoch: 6| Step: 9
Training loss: 0.3777795732021332
Validation loss: 1.8641610344250996

Epoch: 6| Step: 10
Training loss: 0.21910221874713898
Validation loss: 1.9204672972361247

Epoch: 6| Step: 11
Training loss: 0.5624599456787109
Validation loss: 1.8980006178220112

Epoch: 6| Step: 12
Training loss: 0.34956279397010803
Validation loss: 1.9431121548016865

Epoch: 6| Step: 13
Training loss: 0.7799303531646729
Validation loss: 1.9166970451672871

Epoch: 226| Step: 0
Training loss: 0.45074212551116943
Validation loss: 1.9702816009521484

Epoch: 6| Step: 1
Training loss: 0.499809205532074
Validation loss: 1.9187878568967183

Epoch: 6| Step: 2
Training loss: 0.41458094120025635
Validation loss: 1.9392486214637756

Epoch: 6| Step: 3
Training loss: 0.46198469400405884
Validation loss: 1.9232478539148967

Epoch: 6| Step: 4
Training loss: 0.29406410455703735
Validation loss: 1.8705134590466816

Epoch: 6| Step: 5
Training loss: 0.3039584159851074
Validation loss: 1.9224672714869182

Epoch: 6| Step: 6
Training loss: 0.43549278378486633
Validation loss: 1.8875110149383545

Epoch: 6| Step: 7
Training loss: 0.5665075182914734
Validation loss: 1.9069499572118123

Epoch: 6| Step: 8
Training loss: 1.0885963439941406
Validation loss: 1.8741669257481892

Epoch: 6| Step: 9
Training loss: 0.6104480028152466
Validation loss: 1.8728386759757996

Epoch: 6| Step: 10
Training loss: 0.3976336121559143
Validation loss: 1.9515763719876607

Epoch: 6| Step: 11
Training loss: 0.3383297920227051
Validation loss: 1.8868330717086792

Epoch: 6| Step: 12
Training loss: 0.2920917272567749
Validation loss: 1.916252593199412

Epoch: 6| Step: 13
Training loss: 0.3288560211658478
Validation loss: 1.9220324158668518

Epoch: 227| Step: 0
Training loss: 0.3902314603328705
Validation loss: 1.8760937650998433

Epoch: 6| Step: 1
Training loss: 0.5414198637008667
Validation loss: 1.8494858344395955

Epoch: 6| Step: 2
Training loss: 0.19408100843429565
Validation loss: 1.8794800440470378

Epoch: 6| Step: 3
Training loss: 0.503531813621521
Validation loss: 1.8778058687845867

Epoch: 6| Step: 4
Training loss: 0.3258863687515259
Validation loss: 1.8874894976615906

Epoch: 6| Step: 5
Training loss: 0.20061556994915009
Validation loss: 1.9024832844734192

Epoch: 6| Step: 6
Training loss: 0.3130454421043396
Validation loss: 1.9104997316996257

Epoch: 6| Step: 7
Training loss: 0.39295443892478943
Validation loss: 1.8551068305969238

Epoch: 6| Step: 8
Training loss: 0.2672492563724518
Validation loss: 1.8600043455759685

Epoch: 6| Step: 9
Training loss: 0.6120214462280273
Validation loss: 1.8854084014892578

Epoch: 6| Step: 10
Training loss: 0.6042789220809937
Validation loss: 1.8947036663691204

Epoch: 6| Step: 11
Training loss: 0.6767526865005493
Validation loss: 1.8943164745966594

Epoch: 6| Step: 12
Training loss: 0.42779192328453064
Validation loss: 1.8717880447705586

Epoch: 6| Step: 13
Training loss: 0.3864128291606903
Validation loss: 1.8788277904192607

Epoch: 228| Step: 0
Training loss: 0.3680092692375183
Validation loss: 1.8841331601142883

Epoch: 6| Step: 1
Training loss: 0.28782057762145996
Validation loss: 1.949193278948466

Epoch: 6| Step: 2
Training loss: 0.27510058879852295
Validation loss: 1.8739949862162273

Epoch: 6| Step: 3
Training loss: 0.23925656080245972
Validation loss: 1.8676173686981201

Epoch: 6| Step: 4
Training loss: 0.5218315124511719
Validation loss: 1.9119741121927898

Epoch: 6| Step: 5
Training loss: 0.8021940588951111
Validation loss: 1.890215535958608

Epoch: 6| Step: 6
Training loss: 0.49404752254486084
Validation loss: 1.8643455505371094

Epoch: 6| Step: 7
Training loss: 0.8307201862335205
Validation loss: 1.944366176923116

Epoch: 6| Step: 8
Training loss: 0.6939412951469421
Validation loss: 1.896656334400177

Epoch: 6| Step: 9
Training loss: 0.34546977281570435
Validation loss: 1.9449165264765422

Epoch: 6| Step: 10
Training loss: 0.380843847990036
Validation loss: 1.8969908356666565

Epoch: 6| Step: 11
Training loss: 0.4011693000793457
Validation loss: 1.9138936201731365

Epoch: 6| Step: 12
Training loss: 0.21460312604904175
Validation loss: 1.8893632491429646

Epoch: 6| Step: 13
Training loss: 0.22385065257549286
Validation loss: 1.9285895029703777

Epoch: 229| Step: 0
Training loss: 0.32029879093170166
Validation loss: 1.9112937251726787

Epoch: 6| Step: 1
Training loss: 0.4132140278816223
Validation loss: 1.9199028809865315

Epoch: 6| Step: 2
Training loss: 0.577721893787384
Validation loss: 1.8664208054542542

Epoch: 6| Step: 3
Training loss: 0.7765196561813354
Validation loss: 1.9598883390426636

Epoch: 6| Step: 4
Training loss: 0.40646761655807495
Validation loss: 1.9442415634791057

Epoch: 6| Step: 5
Training loss: 0.4593607783317566
Validation loss: 1.9067489902178447

Epoch: 6| Step: 6
Training loss: 0.36062371730804443
Validation loss: 1.9023908376693726

Epoch: 6| Step: 7
Training loss: 0.5887131094932556
Validation loss: 1.8974289099375408

Epoch: 6| Step: 8
Training loss: 0.26354819536209106
Validation loss: 1.9300209085146587

Epoch: 6| Step: 9
Training loss: 0.27059727907180786
Validation loss: 1.9442493915557861

Epoch: 6| Step: 10
Training loss: 0.3492048382759094
Validation loss: 1.8876692056655884

Epoch: 6| Step: 11
Training loss: 0.4802068769931793
Validation loss: 1.9148735801378887

Epoch: 6| Step: 12
Training loss: 0.17560721933841705
Validation loss: 1.9299903114636738

Epoch: 6| Step: 13
Training loss: 0.6748788356781006
Validation loss: 1.9493346214294434

Epoch: 230| Step: 0
Training loss: 0.4004928171634674
Validation loss: 1.8922126094500225

Epoch: 6| Step: 1
Training loss: 0.5738188028335571
Validation loss: 1.8598936994870503

Epoch: 6| Step: 2
Training loss: 0.6792547106742859
Validation loss: 1.8803562919298809

Epoch: 6| Step: 3
Training loss: 0.35367679595947266
Validation loss: 1.9355592528978984

Epoch: 6| Step: 4
Training loss: 0.2885197401046753
Validation loss: 1.9256967107454936

Epoch: 6| Step: 5
Training loss: 0.3940221071243286
Validation loss: 1.8827214042345684

Epoch: 6| Step: 6
Training loss: 0.30148419737815857
Validation loss: 1.8931841552257538

Epoch: 6| Step: 7
Training loss: 0.5342469811439514
Validation loss: 1.927898069222768

Epoch: 6| Step: 8
Training loss: 0.828859806060791
Validation loss: 1.8795141180356343

Epoch: 6| Step: 9
Training loss: 0.31859350204467773
Validation loss: 1.8797436157862346

Epoch: 6| Step: 10
Training loss: 0.34838998317718506
Validation loss: 1.8965694506963093

Epoch: 6| Step: 11
Training loss: 0.5482596755027771
Validation loss: 1.939619501431783

Epoch: 6| Step: 12
Training loss: 0.45918482542037964
Validation loss: 1.8876511653264363

Epoch: 6| Step: 13
Training loss: 0.43863123655319214
Validation loss: 1.9006386001904805

Epoch: 231| Step: 0
Training loss: 0.2652393579483032
Validation loss: 1.9299860795338948

Epoch: 6| Step: 1
Training loss: 0.6115658283233643
Validation loss: 1.896564245223999

Epoch: 6| Step: 2
Training loss: 0.30456721782684326
Validation loss: 1.8576431373755138

Epoch: 6| Step: 3
Training loss: 0.871428370475769
Validation loss: 1.8972718516985576

Epoch: 6| Step: 4
Training loss: 0.8743118047714233
Validation loss: 1.912339945634206

Epoch: 6| Step: 5
Training loss: 0.3572860658168793
Validation loss: 1.9249142011006672

Epoch: 6| Step: 6
Training loss: 0.5770242214202881
Validation loss: 1.8781453967094421

Epoch: 6| Step: 7
Training loss: 0.44995689392089844
Validation loss: 1.8867275317509968

Epoch: 6| Step: 8
Training loss: 0.3505680561065674
Validation loss: 1.9476694067319233

Epoch: 6| Step: 9
Training loss: 0.5461543202400208
Validation loss: 1.8757408261299133

Epoch: 6| Step: 10
Training loss: 0.35413244366645813
Validation loss: 1.9468568563461304

Epoch: 6| Step: 11
Training loss: 0.5113406181335449
Validation loss: 1.8949501514434814

Epoch: 6| Step: 12
Training loss: 0.5185696482658386
Validation loss: 1.9228334426879883

Epoch: 6| Step: 13
Training loss: 0.30914467573165894
Validation loss: 1.8968137105305989

Epoch: 232| Step: 0
Training loss: 0.5057552456855774
Validation loss: 1.9136412342389424

Epoch: 6| Step: 1
Training loss: 0.5405087471008301
Validation loss: 1.8974297841389973

Epoch: 6| Step: 2
Training loss: 0.2604826092720032
Validation loss: 1.87226406733195

Epoch: 6| Step: 3
Training loss: 0.6466984748840332
Validation loss: 1.8911094268163045

Epoch: 6| Step: 4
Training loss: 0.2638803720474243
Validation loss: 1.8750399549802144

Epoch: 6| Step: 5
Training loss: 0.5184731483459473
Validation loss: 1.8802406589190166

Epoch: 6| Step: 6
Training loss: 0.5875193476676941
Validation loss: 1.905788242816925

Epoch: 6| Step: 7
Training loss: 0.4062501788139343
Validation loss: 1.9117233355840046

Epoch: 6| Step: 8
Training loss: 0.8053933382034302
Validation loss: 1.885653555393219

Epoch: 6| Step: 9
Training loss: 0.3181185722351074
Validation loss: 1.9012931386629741

Epoch: 6| Step: 10
Training loss: 0.35488811135292053
Validation loss: 1.8978437781333923

Epoch: 6| Step: 11
Training loss: 0.31005918979644775
Validation loss: 1.8630727926890056

Epoch: 6| Step: 12
Training loss: 0.3280920684337616
Validation loss: 1.8702481786410015

Epoch: 6| Step: 13
Training loss: 0.7892426252365112
Validation loss: 1.8933495084444683

Epoch: 233| Step: 0
Training loss: 0.5767610669136047
Validation loss: 1.900134563446045

Epoch: 6| Step: 1
Training loss: 0.4055154025554657
Validation loss: 1.8561025659243267

Epoch: 6| Step: 2
Training loss: 0.23304781317710876
Validation loss: 1.9399441878000896

Epoch: 6| Step: 3
Training loss: 0.49425214529037476
Validation loss: 1.8702643911043804

Epoch: 6| Step: 4
Training loss: 0.475449800491333
Validation loss: 1.864537000656128

Epoch: 6| Step: 5
Training loss: 0.22205471992492676
Validation loss: 1.8801451921463013

Epoch: 6| Step: 6
Training loss: 0.38634082674980164
Validation loss: 1.8903601964314778

Epoch: 6| Step: 7
Training loss: 0.20341837406158447
Validation loss: 1.8632519245147705

Epoch: 6| Step: 8
Training loss: 0.28250551223754883
Validation loss: 1.8686590393384297

Epoch: 6| Step: 9
Training loss: 0.5607402920722961
Validation loss: 1.877769112586975

Epoch: 6| Step: 10
Training loss: 0.39861053228378296
Validation loss: 1.8872438470522563

Epoch: 6| Step: 11
Training loss: 0.8268882036209106
Validation loss: 1.8685813347498577

Epoch: 6| Step: 12
Training loss: 0.4018644094467163
Validation loss: 1.8853954474131267

Epoch: 6| Step: 13
Training loss: 0.514567494392395
Validation loss: 1.9245609045028687

Epoch: 234| Step: 0
Training loss: 0.6010208129882812
Validation loss: 1.9237240155537922

Epoch: 6| Step: 1
Training loss: 0.2609562277793884
Validation loss: 1.9134994347890217

Epoch: 6| Step: 2
Training loss: 0.42120373249053955
Validation loss: 1.870004653930664

Epoch: 6| Step: 3
Training loss: 0.46286842226982117
Validation loss: 1.8869104385375977

Epoch: 6| Step: 4
Training loss: 0.4708101153373718
Validation loss: 1.8693300882975261

Epoch: 6| Step: 5
Training loss: 0.44620245695114136
Validation loss: 1.9516061743100483

Epoch: 6| Step: 6
Training loss: 0.4151499271392822
Validation loss: 1.9322495659192402

Epoch: 6| Step: 7
Training loss: 0.2818833589553833
Validation loss: 1.9295786023139954

Epoch: 6| Step: 8
Training loss: 0.633150041103363
Validation loss: 1.9221959710121155

Epoch: 6| Step: 9
Training loss: 0.3772279918193817
Validation loss: 1.8755897084871929

Epoch: 6| Step: 10
Training loss: 0.6833485960960388
Validation loss: 1.9130066235860188

Epoch: 6| Step: 11
Training loss: 0.4775477349758148
Validation loss: 1.8915077845255535

Epoch: 6| Step: 12
Training loss: 0.38385629653930664
Validation loss: 1.9330965081850688

Epoch: 6| Step: 13
Training loss: 0.40537235140800476
Validation loss: 1.8870237270991008

Epoch: 235| Step: 0
Training loss: 0.41518130898475647
Validation loss: 1.8667384783426921

Epoch: 6| Step: 1
Training loss: 0.3381634056568146
Validation loss: 1.9086826244990032

Epoch: 6| Step: 2
Training loss: 0.4520047605037689
Validation loss: 1.8555044134457905

Epoch: 6| Step: 3
Training loss: 0.3964270055294037
Validation loss: 1.8830899198849995

Epoch: 6| Step: 4
Training loss: 0.6975346803665161
Validation loss: 1.8943412105242412

Epoch: 6| Step: 5
Training loss: 0.5761421322822571
Validation loss: 1.8365765611330669

Epoch: 6| Step: 6
Training loss: 0.4792722463607788
Validation loss: 1.8580412864685059

Epoch: 6| Step: 7
Training loss: 0.45090073347091675
Validation loss: 1.8576558828353882

Epoch: 6| Step: 8
Training loss: 0.3402671813964844
Validation loss: 1.8856588006019592

Epoch: 6| Step: 9
Training loss: 0.7579187154769897
Validation loss: 1.8577302694320679

Epoch: 6| Step: 10
Training loss: 0.33316662907600403
Validation loss: 1.884029487768809

Epoch: 6| Step: 11
Training loss: 0.615804135799408
Validation loss: 1.9293922384579976

Epoch: 6| Step: 12
Training loss: 0.27797821164131165
Validation loss: 1.849553922812144

Epoch: 6| Step: 13
Training loss: 0.26564860343933105
Validation loss: 1.8792829116185505

Epoch: 236| Step: 0
Training loss: 0.48275500535964966
Validation loss: 1.86855544646581

Epoch: 6| Step: 1
Training loss: 0.4147251844406128
Validation loss: 1.9001058141390483

Epoch: 6| Step: 2
Training loss: 0.23753878474235535
Validation loss: 1.8702941139539082

Epoch: 6| Step: 3
Training loss: 0.33232617378234863
Validation loss: 1.8728710015614827

Epoch: 6| Step: 4
Training loss: 0.2429136335849762
Validation loss: 1.901203493277232

Epoch: 6| Step: 5
Training loss: 0.32536303997039795
Validation loss: 1.9101850191752117

Epoch: 6| Step: 6
Training loss: 0.7890187501907349
Validation loss: 1.9271271228790283

Epoch: 6| Step: 7
Training loss: 0.5038686394691467
Validation loss: 1.9086593588193257

Epoch: 6| Step: 8
Training loss: 0.6401309370994568
Validation loss: 1.8888003826141357

Epoch: 6| Step: 9
Training loss: 0.31487423181533813
Validation loss: 1.8975318471590679

Epoch: 6| Step: 10
Training loss: 0.23629814386367798
Validation loss: 1.8449705044428508

Epoch: 6| Step: 11
Training loss: 0.3755299150943756
Validation loss: 1.941831906636556

Epoch: 6| Step: 12
Training loss: 0.687568724155426
Validation loss: 1.9079015254974365

Epoch: 6| Step: 13
Training loss: 0.4949910342693329
Validation loss: 1.837579031785329

Epoch: 237| Step: 0
Training loss: 0.3090229630470276
Validation loss: 1.9442745645840962

Epoch: 6| Step: 1
Training loss: 0.4391719698905945
Validation loss: 1.934590220451355

Epoch: 6| Step: 2
Training loss: 0.35008615255355835
Validation loss: 1.923306663831075

Epoch: 6| Step: 3
Training loss: 0.855300784111023
Validation loss: 1.8578230738639832

Epoch: 6| Step: 4
Training loss: 0.3146016299724579
Validation loss: 1.898443082968394

Epoch: 6| Step: 5
Training loss: 0.488359659910202
Validation loss: 1.919221043586731

Epoch: 6| Step: 6
Training loss: 0.33316272497177124
Validation loss: 1.8921032150586445

Epoch: 6| Step: 7
Training loss: 0.1701192706823349
Validation loss: 1.8954610427220662

Epoch: 6| Step: 8
Training loss: 0.43054133653640747
Validation loss: 1.8955710331598918

Epoch: 6| Step: 9
Training loss: 0.32369887828826904
Validation loss: 1.8509876728057861

Epoch: 6| Step: 10
Training loss: 0.31378984451293945
Validation loss: 1.911774754524231

Epoch: 6| Step: 11
Training loss: 0.34795066714286804
Validation loss: 1.8770304322242737

Epoch: 6| Step: 12
Training loss: 0.5655408501625061
Validation loss: 1.8641212185223897

Epoch: 6| Step: 13
Training loss: 0.6427408456802368
Validation loss: 1.9121917883555095

Epoch: 238| Step: 0
Training loss: 0.33643341064453125
Validation loss: 1.8454371293385823

Epoch: 6| Step: 1
Training loss: 0.48404359817504883
Validation loss: 1.8537486791610718

Epoch: 6| Step: 2
Training loss: 0.6292524337768555
Validation loss: 1.8931264877319336

Epoch: 6| Step: 3
Training loss: 0.24769921600818634
Validation loss: 1.9479119181632996

Epoch: 6| Step: 4
Training loss: 0.2586323320865631
Validation loss: 1.9091484546661377

Epoch: 6| Step: 5
Training loss: 0.2241518497467041
Validation loss: 1.8594030141830444

Epoch: 6| Step: 6
Training loss: 0.28687670826911926
Validation loss: 1.9144002596537273

Epoch: 6| Step: 7
Training loss: 0.5289256572723389
Validation loss: 1.880409797032674

Epoch: 6| Step: 8
Training loss: 0.401363343000412
Validation loss: 1.8895032405853271

Epoch: 6| Step: 9
Training loss: 0.7000299096107483
Validation loss: 1.909075399239858

Epoch: 6| Step: 10
Training loss: 0.22492390871047974
Validation loss: 1.9194028774897258

Epoch: 6| Step: 11
Training loss: 0.5978084802627563
Validation loss: 1.8933881719907124

Epoch: 6| Step: 12
Training loss: 0.4827938675880432
Validation loss: 1.9208482106526692

Epoch: 6| Step: 13
Training loss: 0.380587637424469
Validation loss: 1.90668781598409

Epoch: 239| Step: 0
Training loss: 0.3109826147556305
Validation loss: 1.8629254897435505

Epoch: 6| Step: 1
Training loss: 0.3935586214065552
Validation loss: 1.883100966612498

Epoch: 6| Step: 2
Training loss: 0.408366322517395
Validation loss: 1.8613446354866028

Epoch: 6| Step: 3
Training loss: 0.37281545996665955
Validation loss: 1.8716915647188823

Epoch: 6| Step: 4
Training loss: 0.4675881266593933
Validation loss: 1.8603950540224712

Epoch: 6| Step: 5
Training loss: 0.35657572746276855
Validation loss: 1.9234387278556824

Epoch: 6| Step: 6
Training loss: 0.4390193819999695
Validation loss: 1.8913061221440632

Epoch: 6| Step: 7
Training loss: 0.29116690158843994
Validation loss: 1.8842311302820842

Epoch: 6| Step: 8
Training loss: 0.557083249092102
Validation loss: 1.879173457622528

Epoch: 6| Step: 9
Training loss: 0.7606282234191895
Validation loss: 1.9166219830513

Epoch: 6| Step: 10
Training loss: 0.30242958664894104
Validation loss: 1.8997403184572856

Epoch: 6| Step: 11
Training loss: 0.23603253066539764
Validation loss: 1.844134509563446

Epoch: 6| Step: 12
Training loss: 0.4471375644207001
Validation loss: 1.8629355827967327

Epoch: 6| Step: 13
Training loss: 0.2669074535369873
Validation loss: 1.8555890719095867

Epoch: 240| Step: 0
Training loss: 0.38152340054512024
Validation loss: 1.871430516242981

Epoch: 6| Step: 1
Training loss: 0.4184874892234802
Validation loss: 1.8756176630655925

Epoch: 6| Step: 2
Training loss: 0.5011875033378601
Validation loss: 1.8436503211657207

Epoch: 6| Step: 3
Training loss: 0.296224445104599
Validation loss: 1.8749092817306519

Epoch: 6| Step: 4
Training loss: 0.3790343999862671
Validation loss: 1.8464898665746052

Epoch: 6| Step: 5
Training loss: 0.41421565413475037
Validation loss: 1.8467331329981487

Epoch: 6| Step: 6
Training loss: 0.3466026186943054
Validation loss: 1.9070195158322651

Epoch: 6| Step: 7
Training loss: 0.4231318235397339
Validation loss: 1.8264243404070537

Epoch: 6| Step: 8
Training loss: 0.5739111304283142
Validation loss: 1.8328071633974712

Epoch: 6| Step: 9
Training loss: 0.8333532810211182
Validation loss: 1.82180259625117

Epoch: 6| Step: 10
Training loss: 0.2674824595451355
Validation loss: 1.882039984067281

Epoch: 6| Step: 11
Training loss: 0.19175508618354797
Validation loss: 1.9112321734428406

Epoch: 6| Step: 12
Training loss: 0.43422263860702515
Validation loss: 1.8724033832550049

Epoch: 6| Step: 13
Training loss: 0.5620778203010559
Validation loss: 1.9099782903989155

Epoch: 241| Step: 0
Training loss: 0.45959559082984924
Validation loss: 1.8709213336308796

Epoch: 6| Step: 1
Training loss: 0.3893831670284271
Validation loss: 1.8698376615842183

Epoch: 6| Step: 2
Training loss: 0.5820663571357727
Validation loss: 1.8948976794878643

Epoch: 6| Step: 3
Training loss: 0.2920790910720825
Validation loss: 1.8813169399897258

Epoch: 6| Step: 4
Training loss: 0.6966434717178345
Validation loss: 1.8763530850410461

Epoch: 6| Step: 5
Training loss: 0.283846914768219
Validation loss: 1.8735796610514324

Epoch: 6| Step: 6
Training loss: 0.6785997748374939
Validation loss: 1.8698582649230957

Epoch: 6| Step: 7
Training loss: 0.24869853258132935
Validation loss: 1.8641949693361919

Epoch: 6| Step: 8
Training loss: 0.6199535727500916
Validation loss: 1.866125504175822

Epoch: 6| Step: 9
Training loss: 0.38082998991012573
Validation loss: 1.8957594434420268

Epoch: 6| Step: 10
Training loss: 0.4860953986644745
Validation loss: 1.8909187118212383

Epoch: 6| Step: 11
Training loss: 0.40568631887435913
Validation loss: 1.886686126391093

Epoch: 6| Step: 12
Training loss: 0.47836020588874817
Validation loss: 1.87112291653951

Epoch: 6| Step: 13
Training loss: 0.23815201222896576
Validation loss: 1.8885839581489563

Epoch: 242| Step: 0
Training loss: 0.6901470422744751
Validation loss: 1.8716303904851277

Epoch: 6| Step: 1
Training loss: 0.7476706504821777
Validation loss: 1.8577558596928914

Epoch: 6| Step: 2
Training loss: 0.3711419105529785
Validation loss: 1.9185135960578918

Epoch: 6| Step: 3
Training loss: 0.2785305976867676
Validation loss: 1.8987374901771545

Epoch: 6| Step: 4
Training loss: 0.23740169405937195
Validation loss: 1.8566495577494304

Epoch: 6| Step: 5
Training loss: 0.3058875799179077
Validation loss: 1.906890372435252

Epoch: 6| Step: 6
Training loss: 0.23050734400749207
Validation loss: 1.8717495401700337

Epoch: 6| Step: 7
Training loss: 0.4251711964607239
Validation loss: 1.889835278193156

Epoch: 6| Step: 8
Training loss: 0.4798808693885803
Validation loss: 1.9091672698656719

Epoch: 6| Step: 9
Training loss: 0.4484903812408447
Validation loss: 1.8817784786224365

Epoch: 6| Step: 10
Training loss: 0.3817344307899475
Validation loss: 1.9089512427647908

Epoch: 6| Step: 11
Training loss: 0.29725009202957153
Validation loss: 1.9444340864817302

Epoch: 6| Step: 12
Training loss: 0.845531702041626
Validation loss: 1.9381149411201477

Epoch: 6| Step: 13
Training loss: 0.4169706106185913
Validation loss: 1.8993228673934937

Epoch: 243| Step: 0
Training loss: 0.46164119243621826
Validation loss: 1.9421351949373882

Epoch: 6| Step: 1
Training loss: 0.45789438486099243
Validation loss: 1.8880802989006042

Epoch: 6| Step: 2
Training loss: 0.8335080146789551
Validation loss: 1.8865631024042766

Epoch: 6| Step: 3
Training loss: 0.22406719624996185
Validation loss: 1.8609308799107869

Epoch: 6| Step: 4
Training loss: 0.49258631467819214
Validation loss: 1.9003364443778992

Epoch: 6| Step: 5
Training loss: 0.5367180109024048
Validation loss: 1.888429840405782

Epoch: 6| Step: 6
Training loss: 0.3008999526500702
Validation loss: 1.8902534643809001

Epoch: 6| Step: 7
Training loss: 0.32948270440101624
Validation loss: 1.8585727612177532

Epoch: 6| Step: 8
Training loss: 0.301716148853302
Validation loss: 1.8708055814107258

Epoch: 6| Step: 9
Training loss: 0.44063377380371094
Validation loss: 1.8946864604949951

Epoch: 6| Step: 10
Training loss: 0.2276347577571869
Validation loss: 1.9059844215710957

Epoch: 6| Step: 11
Training loss: 0.42428311705589294
Validation loss: 1.9109175006548564

Epoch: 6| Step: 12
Training loss: 0.16298584640026093
Validation loss: 1.8643298546473186

Epoch: 6| Step: 13
Training loss: 0.2858180105686188
Validation loss: 1.8658539454142253

Epoch: 244| Step: 0
Training loss: 0.5292884111404419
Validation loss: 1.855977992216746

Epoch: 6| Step: 1
Training loss: 0.23696821928024292
Validation loss: 1.8732868432998657

Epoch: 6| Step: 2
Training loss: 0.39472126960754395
Validation loss: 1.9246837496757507

Epoch: 6| Step: 3
Training loss: 0.4231714904308319
Validation loss: 1.8812633554140727

Epoch: 6| Step: 4
Training loss: 0.4282534718513489
Validation loss: 1.8906707167625427

Epoch: 6| Step: 5
Training loss: 0.370874285697937
Validation loss: 1.870774745941162

Epoch: 6| Step: 6
Training loss: 0.41758057475090027
Validation loss: 1.8376737833023071

Epoch: 6| Step: 7
Training loss: 0.2900696396827698
Validation loss: 1.9148148496945698

Epoch: 6| Step: 8
Training loss: 0.6830726265907288
Validation loss: 1.896177629629771

Epoch: 6| Step: 9
Training loss: 0.3558385968208313
Validation loss: 1.8551028768221538

Epoch: 6| Step: 10
Training loss: 0.30059558153152466
Validation loss: 1.840929885705312

Epoch: 6| Step: 11
Training loss: 0.4069366157054901
Validation loss: 1.8368835647900899

Epoch: 6| Step: 12
Training loss: 0.3331162929534912
Validation loss: 1.8426943222681682

Epoch: 6| Step: 13
Training loss: 0.5080846548080444
Validation loss: 1.864667574564616

Epoch: 245| Step: 0
Training loss: 0.640983521938324
Validation loss: 1.8470780452092488

Epoch: 6| Step: 1
Training loss: 0.25109410285949707
Validation loss: 1.8378547032674153

Epoch: 6| Step: 2
Training loss: 0.2778628170490265
Validation loss: 1.861965497334798

Epoch: 6| Step: 3
Training loss: 0.5080088973045349
Validation loss: 1.8625232776006062

Epoch: 6| Step: 4
Training loss: 0.481575071811676
Validation loss: 1.8496060570081074

Epoch: 6| Step: 5
Training loss: 0.28590595722198486
Validation loss: 1.8683952887852986

Epoch: 6| Step: 6
Training loss: 0.37626051902770996
Validation loss: 1.85395348072052

Epoch: 6| Step: 7
Training loss: 0.3349658250808716
Validation loss: 1.8941889603932698

Epoch: 6| Step: 8
Training loss: 0.39908480644226074
Validation loss: 1.8447882930437725

Epoch: 6| Step: 9
Training loss: 0.2122989296913147
Validation loss: 1.8741953174273174

Epoch: 6| Step: 10
Training loss: 0.5105834603309631
Validation loss: 1.864795168240865

Epoch: 6| Step: 11
Training loss: 0.8452907800674438
Validation loss: 1.823005735874176

Epoch: 6| Step: 12
Training loss: 0.29289668798446655
Validation loss: 1.859350045522054

Epoch: 6| Step: 13
Training loss: 0.5828434228897095
Validation loss: 1.8673375050226848

Epoch: 246| Step: 0
Training loss: 0.24725885689258575
Validation loss: 1.8637679020563762

Epoch: 6| Step: 1
Training loss: 0.3792247474193573
Validation loss: 1.879745324452718

Epoch: 6| Step: 2
Training loss: 0.43029770255088806
Validation loss: 1.8593377272288005

Epoch: 6| Step: 3
Training loss: 0.2923831641674042
Validation loss: 1.85830161968867

Epoch: 6| Step: 4
Training loss: 0.43034428358078003
Validation loss: 1.9163909355799358

Epoch: 6| Step: 5
Training loss: 0.49162086844444275
Validation loss: 1.8990178505579631

Epoch: 6| Step: 6
Training loss: 0.40085792541503906
Validation loss: 1.8778336842854817

Epoch: 6| Step: 7
Training loss: 0.46657687425613403
Validation loss: 1.8635541399319966

Epoch: 6| Step: 8
Training loss: 0.5912543535232544
Validation loss: 1.9362274408340454

Epoch: 6| Step: 9
Training loss: 0.3820877969264984
Validation loss: 1.8593987822532654

Epoch: 6| Step: 10
Training loss: 0.6035172939300537
Validation loss: 1.9123757084210713

Epoch: 6| Step: 11
Training loss: 0.26796796917915344
Validation loss: 1.8446702361106873

Epoch: 6| Step: 12
Training loss: 0.4450991153717041
Validation loss: 1.8812302947044373

Epoch: 6| Step: 13
Training loss: 0.1334337294101715
Validation loss: 1.9041067361831665

Epoch: 247| Step: 0
Training loss: 0.4770793616771698
Validation loss: 1.8836994171142578

Epoch: 6| Step: 1
Training loss: 0.27123573422431946
Validation loss: 1.8270443081855774

Epoch: 6| Step: 2
Training loss: 0.37790489196777344
Validation loss: 1.9119486212730408

Epoch: 6| Step: 3
Training loss: 0.5764262676239014
Validation loss: 1.9043781757354736

Epoch: 6| Step: 4
Training loss: 0.9995982050895691
Validation loss: 1.8643634915351868

Epoch: 6| Step: 5
Training loss: 0.27608537673950195
Validation loss: 1.9298696517944336

Epoch: 6| Step: 6
Training loss: 0.3225690722465515
Validation loss: 1.8876588741938274

Epoch: 6| Step: 7
Training loss: 0.38866013288497925
Validation loss: 1.8737753828366597

Epoch: 6| Step: 8
Training loss: 0.2710754871368408
Validation loss: 1.8591917951901753

Epoch: 6| Step: 9
Training loss: 0.4473772644996643
Validation loss: 1.8961507678031921

Epoch: 6| Step: 10
Training loss: 0.3053920865058899
Validation loss: 1.8545258243878682

Epoch: 6| Step: 11
Training loss: 0.2726876139640808
Validation loss: 1.893326501051585

Epoch: 6| Step: 12
Training loss: 0.3988657593727112
Validation loss: 1.8712883392969768

Epoch: 6| Step: 13
Training loss: 0.25919148325920105
Validation loss: 1.8801418542861938

Epoch: 248| Step: 0
Training loss: 0.4348341226577759
Validation loss: 1.8770024577776592

Epoch: 6| Step: 1
Training loss: 0.5340346097946167
Validation loss: 1.8620700637499492

Epoch: 6| Step: 2
Training loss: 0.633772611618042
Validation loss: 1.8439392844835918

Epoch: 6| Step: 3
Training loss: 0.4330637454986572
Validation loss: 1.8740380803744

Epoch: 6| Step: 4
Training loss: 0.6052443981170654
Validation loss: 1.8758275111516316

Epoch: 6| Step: 5
Training loss: 0.4466736912727356
Validation loss: 1.8548507889111836

Epoch: 6| Step: 6
Training loss: 0.4680343270301819
Validation loss: 1.926832656065623

Epoch: 6| Step: 7
Training loss: 0.5977741479873657
Validation loss: 1.831944465637207

Epoch: 6| Step: 8
Training loss: 0.3367382287979126
Validation loss: 1.850921372572581

Epoch: 6| Step: 9
Training loss: 0.3136110007762909
Validation loss: 1.819806694984436

Epoch: 6| Step: 10
Training loss: 0.2523680627346039
Validation loss: 1.8890578150749207

Epoch: 6| Step: 11
Training loss: 0.4747363030910492
Validation loss: 1.8721035321553547

Epoch: 6| Step: 12
Training loss: 0.4316903054714203
Validation loss: 1.9028515021006267

Epoch: 6| Step: 13
Training loss: 0.3287712335586548
Validation loss: 1.887630025545756

Epoch: 249| Step: 0
Training loss: 0.8542385101318359
Validation loss: 1.9088023900985718

Epoch: 6| Step: 1
Training loss: 0.33117929100990295
Validation loss: 1.881663739681244

Epoch: 6| Step: 2
Training loss: 0.26938509941101074
Validation loss: 1.8269979357719421

Epoch: 6| Step: 3
Training loss: 0.4176349639892578
Validation loss: 1.855507532755534

Epoch: 6| Step: 4
Training loss: 0.5427443981170654
Validation loss: 1.883620798587799

Epoch: 6| Step: 5
Training loss: 0.5785019993782043
Validation loss: 1.8949059049288433

Epoch: 6| Step: 6
Training loss: 0.3253670036792755
Validation loss: 1.8884559472401936

Epoch: 6| Step: 7
Training loss: 0.2989707589149475
Validation loss: 1.8626381953557332

Epoch: 6| Step: 8
Training loss: 0.2690500020980835
Validation loss: 1.8872486352920532

Epoch: 6| Step: 9
Training loss: 0.6959207057952881
Validation loss: 1.89565642674764

Epoch: 6| Step: 10
Training loss: 0.616545557975769
Validation loss: 1.8993030587832134

Epoch: 6| Step: 11
Training loss: 0.41460609436035156
Validation loss: 1.9051360487937927

Epoch: 6| Step: 12
Training loss: 0.5428619384765625
Validation loss: 1.8781266411145527

Epoch: 6| Step: 13
Training loss: 0.31517550349235535
Validation loss: 1.8705643216768901

Epoch: 250| Step: 0
Training loss: 0.28741559386253357
Validation loss: 1.8538670341173809

Epoch: 6| Step: 1
Training loss: 0.35839229822158813
Validation loss: 1.876445432504018

Epoch: 6| Step: 2
Training loss: 0.6936594843864441
Validation loss: 1.8171712160110474

Epoch: 6| Step: 3
Training loss: 0.2139083296060562
Validation loss: 1.902429421742757

Epoch: 6| Step: 4
Training loss: 0.2937272787094116
Validation loss: 1.8628130157788594

Epoch: 6| Step: 5
Training loss: 0.2247125506401062
Validation loss: 1.904604732990265

Epoch: 6| Step: 6
Training loss: 0.368324875831604
Validation loss: 1.9048841794331868

Epoch: 6| Step: 7
Training loss: 0.6016174554824829
Validation loss: 1.9009604454040527

Epoch: 6| Step: 8
Training loss: 0.11835983395576477
Validation loss: 1.9250466426213582

Epoch: 6| Step: 9
Training loss: 0.3876152038574219
Validation loss: 1.8710091312726338

Epoch: 6| Step: 10
Training loss: 0.4886024594306946
Validation loss: 1.8641186356544495

Epoch: 6| Step: 11
Training loss: 0.5295684933662415
Validation loss: 1.889111320177714

Epoch: 6| Step: 12
Training loss: 0.523352861404419
Validation loss: 1.8459640542666118

Epoch: 6| Step: 13
Training loss: 0.377521812915802
Validation loss: 1.8828413287798564

Epoch: 251| Step: 0
Training loss: 0.23169253766536713
Validation loss: 1.9236022432645161

Epoch: 6| Step: 1
Training loss: 0.384465754032135
Validation loss: 1.9128232796986897

Epoch: 6| Step: 2
Training loss: 0.2127918303012848
Validation loss: 1.9298474589983623

Epoch: 6| Step: 3
Training loss: 0.3728811740875244
Validation loss: 1.893792490164439

Epoch: 6| Step: 4
Training loss: 0.30289340019226074
Validation loss: 1.8792619903882344

Epoch: 6| Step: 5
Training loss: 0.4325805902481079
Validation loss: 1.8435401916503906

Epoch: 6| Step: 6
Training loss: 0.3006444275379181
Validation loss: 1.8934717377026875

Epoch: 6| Step: 7
Training loss: 0.6720849871635437
Validation loss: 1.9191178878148396

Epoch: 6| Step: 8
Training loss: 0.20974572002887726
Validation loss: 1.9302192727724712

Epoch: 6| Step: 9
Training loss: 0.44376975297927856
Validation loss: 1.8749393224716187

Epoch: 6| Step: 10
Training loss: 1.0150630474090576
Validation loss: 1.9035149415334065

Epoch: 6| Step: 11
Training loss: 0.2576388716697693
Validation loss: 1.897561490535736

Epoch: 6| Step: 12
Training loss: 0.26017361879348755
Validation loss: 1.9103536208470662

Epoch: 6| Step: 13
Training loss: 0.3626512289047241
Validation loss: 1.8928609093030293

Epoch: 252| Step: 0
Training loss: 0.5274143815040588
Validation loss: 1.8833568096160889

Epoch: 6| Step: 1
Training loss: 0.17907357215881348
Validation loss: 1.914042552312215

Epoch: 6| Step: 2
Training loss: 0.5830478668212891
Validation loss: 1.8948286573092143

Epoch: 6| Step: 3
Training loss: 0.3298584222793579
Validation loss: 1.8591675957043965

Epoch: 6| Step: 4
Training loss: 0.6390348672866821
Validation loss: 1.914349655310313

Epoch: 6| Step: 5
Training loss: 0.2579357624053955
Validation loss: 1.8829394578933716

Epoch: 6| Step: 6
Training loss: 0.3058033585548401
Validation loss: 1.9405187368392944

Epoch: 6| Step: 7
Training loss: 0.21466217935085297
Validation loss: 1.8904676238695781

Epoch: 6| Step: 8
Training loss: 0.34072816371917725
Validation loss: 1.8327222267786663

Epoch: 6| Step: 9
Training loss: 0.7692660093307495
Validation loss: 1.90642116467158

Epoch: 6| Step: 10
Training loss: 0.33046600222587585
Validation loss: 1.8682721257209778

Epoch: 6| Step: 11
Training loss: 0.3064206540584564
Validation loss: 1.87654314438502

Epoch: 6| Step: 12
Training loss: 0.3882826566696167
Validation loss: 1.900015910466512

Epoch: 6| Step: 13
Training loss: 0.3817387819290161
Validation loss: 1.8674296935399373

Epoch: 253| Step: 0
Training loss: 0.345808207988739
Validation loss: 1.898899495601654

Epoch: 6| Step: 1
Training loss: 0.6565009355545044
Validation loss: 1.8776251475016277

Epoch: 6| Step: 2
Training loss: 0.21547111868858337
Validation loss: 1.8781711260477703

Epoch: 6| Step: 3
Training loss: 0.4170340895652771
Validation loss: 1.890796383221944

Epoch: 6| Step: 4
Training loss: 0.18616147339344025
Validation loss: 1.869108259677887

Epoch: 6| Step: 5
Training loss: 0.3955398201942444
Validation loss: 1.8869176308314006

Epoch: 6| Step: 6
Training loss: 0.48241686820983887
Validation loss: 1.8783904910087585

Epoch: 6| Step: 7
Training loss: 0.662592887878418
Validation loss: 1.934920350710551

Epoch: 6| Step: 8
Training loss: 0.3505777418613434
Validation loss: 1.9152117570241292

Epoch: 6| Step: 9
Training loss: 0.33572420477867126
Validation loss: 1.8904908299446106

Epoch: 6| Step: 10
Training loss: 0.3339962363243103
Validation loss: 1.9275426864624023

Epoch: 6| Step: 11
Training loss: 0.27031558752059937
Validation loss: 1.9214434226353962

Epoch: 6| Step: 12
Training loss: 0.36398017406463623
Validation loss: 1.8770616451899211

Epoch: 6| Step: 13
Training loss: 0.3702625036239624
Validation loss: 1.9318108359972637

Epoch: 254| Step: 0
Training loss: 0.23815184831619263
Validation loss: 1.9144669771194458

Epoch: 6| Step: 1
Training loss: 0.44813936948776245
Validation loss: 1.917704184850057

Epoch: 6| Step: 2
Training loss: 0.5391058325767517
Validation loss: 1.8670707941055298

Epoch: 6| Step: 3
Training loss: 0.5270786285400391
Validation loss: 1.8741458654403687

Epoch: 6| Step: 4
Training loss: 0.5039407014846802
Validation loss: 1.8477943936983745

Epoch: 6| Step: 5
Training loss: 0.24795520305633545
Validation loss: 1.876882294813792

Epoch: 6| Step: 6
Training loss: 0.31259167194366455
Validation loss: 1.8747929135958354

Epoch: 6| Step: 7
Training loss: 0.3515269458293915
Validation loss: 1.8584568699200947

Epoch: 6| Step: 8
Training loss: 0.8276554942131042
Validation loss: 1.8794549306233723

Epoch: 6| Step: 9
Training loss: 0.24841037392616272
Validation loss: 1.8473770221074421

Epoch: 6| Step: 10
Training loss: 0.31444674730300903
Validation loss: 1.8542921940485637

Epoch: 6| Step: 11
Training loss: 0.14318746328353882
Validation loss: 1.8692458271980286

Epoch: 6| Step: 12
Training loss: 0.4701645076274872
Validation loss: 1.8431058128674824

Epoch: 6| Step: 13
Training loss: 0.21640238165855408
Validation loss: 1.8683757185935974

Epoch: 255| Step: 0
Training loss: 0.2201351672410965
Validation loss: 1.8941268126169841

Epoch: 6| Step: 1
Training loss: 0.2769317626953125
Validation loss: 1.871763249238332

Epoch: 6| Step: 2
Training loss: 0.3906082808971405
Validation loss: 1.8726942737897236

Epoch: 6| Step: 3
Training loss: 0.24052514135837555
Validation loss: 1.8821827173233032

Epoch: 6| Step: 4
Training loss: 0.21632522344589233
Validation loss: 1.8737378120422363

Epoch: 6| Step: 5
Training loss: 0.27055948972702026
Validation loss: 1.8796396255493164

Epoch: 6| Step: 6
Training loss: 0.4454176723957062
Validation loss: 1.8789654175440471

Epoch: 6| Step: 7
Training loss: 0.17671293020248413
Validation loss: 1.8518246412277222

Epoch: 6| Step: 8
Training loss: 0.4122915267944336
Validation loss: 1.9311636090278625

Epoch: 6| Step: 9
Training loss: 0.24476315081119537
Validation loss: 1.8858572045962017

Epoch: 6| Step: 10
Training loss: 0.41180723905563354
Validation loss: 1.9072465499242146

Epoch: 6| Step: 11
Training loss: 1.2787258625030518
Validation loss: 1.9160735805829365

Epoch: 6| Step: 12
Training loss: 0.34147679805755615
Validation loss: 1.8961246609687805

Epoch: 6| Step: 13
Training loss: 0.48801517486572266
Validation loss: 1.9085323214530945

Epoch: 256| Step: 0
Training loss: 0.3707702159881592
Validation loss: 1.9121782581011455

Epoch: 6| Step: 1
Training loss: 0.5186299681663513
Validation loss: 1.8414981762568157

Epoch: 6| Step: 2
Training loss: 0.369798481464386
Validation loss: 1.8889687061309814

Epoch: 6| Step: 3
Training loss: 0.4653884172439575
Validation loss: 1.9387235442797344

Epoch: 6| Step: 4
Training loss: 0.6138761043548584
Validation loss: 1.9325600067774455

Epoch: 6| Step: 5
Training loss: 0.5442468523979187
Validation loss: 1.941820740699768

Epoch: 6| Step: 6
Training loss: 0.18882572650909424
Validation loss: 1.936743716398875

Epoch: 6| Step: 7
Training loss: 0.3432226777076721
Validation loss: 1.9550021886825562

Epoch: 6| Step: 8
Training loss: 0.3015861213207245
Validation loss: 1.903007487456004

Epoch: 6| Step: 9
Training loss: 0.3083914518356323
Validation loss: 1.9105071822802226

Epoch: 6| Step: 10
Training loss: 0.2977009117603302
Validation loss: 1.927561601003011

Epoch: 6| Step: 11
Training loss: 0.3472026586532593
Validation loss: 1.9113202492396038

Epoch: 6| Step: 12
Training loss: 0.4568585753440857
Validation loss: 1.9109537998835247

Epoch: 6| Step: 13
Training loss: 0.2977052330970764
Validation loss: 1.868708610534668

Epoch: 257| Step: 0
Training loss: 0.3576994240283966
Validation loss: 1.840528964996338

Epoch: 6| Step: 1
Training loss: 0.3169569671154022
Validation loss: 1.8918349345525105

Epoch: 6| Step: 2
Training loss: 0.28719571232795715
Validation loss: 1.899807333946228

Epoch: 6| Step: 3
Training loss: 0.23142069578170776
Validation loss: 1.8934043049812317

Epoch: 6| Step: 4
Training loss: 0.2986512780189514
Validation loss: 1.8594932357470195

Epoch: 6| Step: 5
Training loss: 0.34347301721572876
Validation loss: 1.912557025750478

Epoch: 6| Step: 6
Training loss: 0.4881645143032074
Validation loss: 1.9517988165219624

Epoch: 6| Step: 7
Training loss: 0.2744355797767639
Validation loss: 1.9335816502571106

Epoch: 6| Step: 8
Training loss: 0.618567943572998
Validation loss: 1.9444119930267334

Epoch: 6| Step: 9
Training loss: 0.4625754654407501
Validation loss: 1.9057515462239583

Epoch: 6| Step: 10
Training loss: 0.5340158939361572
Validation loss: 1.87197740872701

Epoch: 6| Step: 11
Training loss: 0.34985870122909546
Validation loss: 1.9236199259757996

Epoch: 6| Step: 12
Training loss: 0.6637443900108337
Validation loss: 1.8922505577405293

Epoch: 6| Step: 13
Training loss: 0.8923794627189636
Validation loss: 1.9099723895390828

Epoch: 258| Step: 0
Training loss: 0.8123430609703064
Validation loss: 1.8584549029668171

Epoch: 6| Step: 1
Training loss: 0.33484596014022827
Validation loss: 1.8382795453071594

Epoch: 6| Step: 2
Training loss: 0.3683748245239258
Validation loss: 1.843483825524648

Epoch: 6| Step: 3
Training loss: 0.30036109685897827
Validation loss: 1.9250216086705525

Epoch: 6| Step: 4
Training loss: 0.311448335647583
Validation loss: 1.9064137538274128

Epoch: 6| Step: 5
Training loss: 0.6942146420478821
Validation loss: 1.9042266408602397

Epoch: 6| Step: 6
Training loss: 0.31987082958221436
Validation loss: 1.898493806521098

Epoch: 6| Step: 7
Training loss: 0.2445685863494873
Validation loss: 1.8859823147455852

Epoch: 6| Step: 8
Training loss: 0.45174604654312134
Validation loss: 1.918448527654012

Epoch: 6| Step: 9
Training loss: 0.25875192880630493
Validation loss: 1.9368710319201152

Epoch: 6| Step: 10
Training loss: 0.3305240273475647
Validation loss: 1.8776941100756328

Epoch: 6| Step: 11
Training loss: 0.2420537769794464
Validation loss: 1.9256922006607056

Epoch: 6| Step: 12
Training loss: 0.30185288190841675
Validation loss: 1.8814419507980347

Epoch: 6| Step: 13
Training loss: 0.44113415479660034
Validation loss: 1.9182425340016682

Epoch: 259| Step: 0
Training loss: 0.32161563634872437
Validation loss: 1.9024304151535034

Epoch: 6| Step: 1
Training loss: 0.393219530582428
Validation loss: 1.8719897468884785

Epoch: 6| Step: 2
Training loss: 0.2587103843688965
Validation loss: 1.9300119876861572

Epoch: 6| Step: 3
Training loss: 0.32324469089508057
Validation loss: 1.936468243598938

Epoch: 6| Step: 4
Training loss: 0.5219569802284241
Validation loss: 1.9112956722577412

Epoch: 6| Step: 5
Training loss: 0.3768308758735657
Validation loss: 1.89219997326533

Epoch: 6| Step: 6
Training loss: 0.37891870737075806
Validation loss: 1.8998697996139526

Epoch: 6| Step: 7
Training loss: 0.46488964557647705
Validation loss: 1.9058236082394917

Epoch: 6| Step: 8
Training loss: 0.2368244230747223
Validation loss: 1.9015310804049175

Epoch: 6| Step: 9
Training loss: 0.2747943699359894
Validation loss: 1.9031201601028442

Epoch: 6| Step: 10
Training loss: 0.6177958250045776
Validation loss: 1.903938074906667

Epoch: 6| Step: 11
Training loss: 0.3947371542453766
Validation loss: 1.8870631257692974

Epoch: 6| Step: 12
Training loss: 0.5401923656463623
Validation loss: 1.8673810760180156

Epoch: 6| Step: 13
Training loss: 0.5689237117767334
Validation loss: 1.927357792854309

Epoch: 260| Step: 0
Training loss: 0.45811060070991516
Validation loss: 1.8832370241483052

Epoch: 6| Step: 1
Training loss: 0.6977526545524597
Validation loss: 1.8469905257225037

Epoch: 6| Step: 2
Training loss: 0.2556284964084625
Validation loss: 1.9292838374773662

Epoch: 6| Step: 3
Training loss: 0.31486842036247253
Validation loss: 1.8721109628677368

Epoch: 6| Step: 4
Training loss: 0.2981905937194824
Validation loss: 1.8935043215751648

Epoch: 6| Step: 5
Training loss: 0.5339590311050415
Validation loss: 1.9125311175982158

Epoch: 6| Step: 6
Training loss: 0.25635141134262085
Validation loss: 1.9071921308835347

Epoch: 6| Step: 7
Training loss: 0.26835381984710693
Validation loss: 1.9238139986991882

Epoch: 6| Step: 8
Training loss: 0.24106837809085846
Validation loss: 1.9455714225769043

Epoch: 6| Step: 9
Training loss: 0.5545938611030579
Validation loss: 1.8894022305806477

Epoch: 6| Step: 10
Training loss: 0.5589836239814758
Validation loss: 1.861643135547638

Epoch: 6| Step: 11
Training loss: 0.20585109293460846
Validation loss: 1.9013948837916057

Epoch: 6| Step: 12
Training loss: 0.34499430656433105
Validation loss: 1.8909206589063008

Epoch: 6| Step: 13
Training loss: 0.2068343311548233
Validation loss: 1.8734306693077087

Epoch: 261| Step: 0
Training loss: 0.24324443936347961
Validation loss: 1.820939878622691

Epoch: 6| Step: 1
Training loss: 0.3204337954521179
Validation loss: 1.869300623734792

Epoch: 6| Step: 2
Training loss: 0.27377626299858093
Validation loss: 1.878946324189504

Epoch: 6| Step: 3
Training loss: 0.22192168235778809
Validation loss: 1.908051331837972

Epoch: 6| Step: 4
Training loss: 0.16895446181297302
Validation loss: 1.9315357605616252

Epoch: 6| Step: 5
Training loss: 0.494418203830719
Validation loss: 1.864758312702179

Epoch: 6| Step: 6
Training loss: 0.35634058713912964
Validation loss: 1.848275065422058

Epoch: 6| Step: 7
Training loss: 0.32604992389678955
Validation loss: 1.8719020287195842

Epoch: 6| Step: 8
Training loss: 0.2520468533039093
Validation loss: 1.9020943840344746

Epoch: 6| Step: 9
Training loss: 0.7455431222915649
Validation loss: 1.9166621168454487

Epoch: 6| Step: 10
Training loss: 0.4312818944454193
Validation loss: 1.8994380633036296

Epoch: 6| Step: 11
Training loss: 0.2652500569820404
Validation loss: 1.8583220640818279

Epoch: 6| Step: 12
Training loss: 0.3474023938179016
Validation loss: 1.8725472887357075

Epoch: 6| Step: 13
Training loss: 0.6903051137924194
Validation loss: 1.8827060063680012

Epoch: 262| Step: 0
Training loss: 0.19446246325969696
Validation loss: 1.8862943450609844

Epoch: 6| Step: 1
Training loss: 0.46905064582824707
Validation loss: 1.9060371120770772

Epoch: 6| Step: 2
Training loss: 0.2275933027267456
Validation loss: 1.9025988976160686

Epoch: 6| Step: 3
Training loss: 0.49816426634788513
Validation loss: 1.8471845984458923

Epoch: 6| Step: 4
Training loss: 0.2601282000541687
Validation loss: 1.880381961663564

Epoch: 6| Step: 5
Training loss: 0.4251629114151001
Validation loss: 1.8440553347269695

Epoch: 6| Step: 6
Training loss: 0.34178128838539124
Validation loss: 1.8541065454483032

Epoch: 6| Step: 7
Training loss: 0.4669964909553528
Validation loss: 1.8625979622205098

Epoch: 6| Step: 8
Training loss: 0.17943035066127777
Validation loss: 1.895760715007782

Epoch: 6| Step: 9
Training loss: 0.3576353192329407
Validation loss: 1.8820896744728088

Epoch: 6| Step: 10
Training loss: 0.33946359157562256
Validation loss: 1.8865893483161926

Epoch: 6| Step: 11
Training loss: 0.2488909810781479
Validation loss: 1.882995069026947

Epoch: 6| Step: 12
Training loss: 0.5207441449165344
Validation loss: 1.880671997865041

Epoch: 6| Step: 13
Training loss: 0.663887619972229
Validation loss: 1.8681727647781372

Epoch: 263| Step: 0
Training loss: 0.31018346548080444
Validation loss: 1.8495301405588787

Epoch: 6| Step: 1
Training loss: 0.27587902545928955
Validation loss: 1.8534866571426392

Epoch: 6| Step: 2
Training loss: 0.28572481870651245
Validation loss: 1.8743551174799602

Epoch: 6| Step: 3
Training loss: 0.3088146150112152
Validation loss: 1.867970069249471

Epoch: 6| Step: 4
Training loss: 0.41791313886642456
Validation loss: 1.8951817353566487

Epoch: 6| Step: 5
Training loss: 0.3136797249317169
Validation loss: 1.8689870238304138

Epoch: 6| Step: 6
Training loss: 0.39610713720321655
Validation loss: 1.9225228826204936

Epoch: 6| Step: 7
Training loss: 0.49737852811813354
Validation loss: 1.8788057565689087

Epoch: 6| Step: 8
Training loss: 0.388303279876709
Validation loss: 1.8945533633232117

Epoch: 6| Step: 9
Training loss: 0.3890804052352905
Validation loss: 1.9016385873158772

Epoch: 6| Step: 10
Training loss: 0.49644845724105835
Validation loss: 1.9233726064364116

Epoch: 6| Step: 11
Training loss: 0.28631502389907837
Validation loss: 1.882615089416504

Epoch: 6| Step: 12
Training loss: 0.5205101370811462
Validation loss: 1.8969616095225017

Epoch: 6| Step: 13
Training loss: 0.8001599311828613
Validation loss: 1.9539276758829753

Epoch: 264| Step: 0
Training loss: 0.23306810855865479
Validation loss: 1.9392742315928142

Epoch: 6| Step: 1
Training loss: 0.3962668776512146
Validation loss: 1.8856330911318462

Epoch: 6| Step: 2
Training loss: 0.3454481065273285
Validation loss: 1.9075879057248433

Epoch: 6| Step: 3
Training loss: 0.7922843098640442
Validation loss: 1.915750503540039

Epoch: 6| Step: 4
Training loss: 0.36703044176101685
Validation loss: 1.9383588830629985

Epoch: 6| Step: 5
Training loss: 0.34642064571380615
Validation loss: 1.9173311591148376

Epoch: 6| Step: 6
Training loss: 0.4174436628818512
Validation loss: 1.8840000828107197

Epoch: 6| Step: 7
Training loss: 0.41638457775115967
Validation loss: 1.8818426926930745

Epoch: 6| Step: 8
Training loss: 0.2945459187030792
Validation loss: 1.9041715661684673

Epoch: 6| Step: 9
Training loss: 0.21035291254520416
Validation loss: 1.861206591129303

Epoch: 6| Step: 10
Training loss: 0.42527058720588684
Validation loss: 1.891574740409851

Epoch: 6| Step: 11
Training loss: 0.2849729061126709
Validation loss: 1.8853709697723389

Epoch: 6| Step: 12
Training loss: 0.3149488568305969
Validation loss: 1.9337428013483684

Epoch: 6| Step: 13
Training loss: 0.3421436846256256
Validation loss: 1.8832507133483887

Epoch: 265| Step: 0
Training loss: 0.6152325868606567
Validation loss: 1.9390851060549419

Epoch: 6| Step: 1
Training loss: 0.3767380714416504
Validation loss: 1.9145610729853313

Epoch: 6| Step: 2
Training loss: 0.3896353244781494
Validation loss: 1.9224776029586792

Epoch: 6| Step: 3
Training loss: 0.2244018018245697
Validation loss: 1.8782143195470173

Epoch: 6| Step: 4
Training loss: 0.3240252137184143
Validation loss: 1.9520942568778992

Epoch: 6| Step: 5
Training loss: 0.3358902335166931
Validation loss: 1.9139544367790222

Epoch: 6| Step: 6
Training loss: 0.2854011654853821
Validation loss: 1.9278965989748638

Epoch: 6| Step: 7
Training loss: 0.6123050451278687
Validation loss: 1.912800172964732

Epoch: 6| Step: 8
Training loss: 0.36993831396102905
Validation loss: 1.8552318215370178

Epoch: 6| Step: 9
Training loss: 0.35768866539001465
Validation loss: 1.9208174347877502

Epoch: 6| Step: 10
Training loss: 0.2346017211675644
Validation loss: 1.9050979018211365

Epoch: 6| Step: 11
Training loss: 0.8053486943244934
Validation loss: 1.8712070385615032

Epoch: 6| Step: 12
Training loss: 0.3423357903957367
Validation loss: 1.924634615580241

Epoch: 6| Step: 13
Training loss: 0.517956018447876
Validation loss: 1.8689480026563008

Epoch: 266| Step: 0
Training loss: 0.22907763719558716
Validation loss: 1.9052347739537556

Epoch: 6| Step: 1
Training loss: 0.3248080313205719
Validation loss: 1.8613903323809307

Epoch: 6| Step: 2
Training loss: 0.225741907954216
Validation loss: 1.9024913311004639

Epoch: 6| Step: 3
Training loss: 0.2579500377178192
Validation loss: 1.8928213119506836

Epoch: 6| Step: 4
Training loss: 0.49508917331695557
Validation loss: 1.8713674743970234

Epoch: 6| Step: 5
Training loss: 0.28106415271759033
Validation loss: 1.9480330348014832

Epoch: 6| Step: 6
Training loss: 0.9582459926605225
Validation loss: 1.8553065260251362

Epoch: 6| Step: 7
Training loss: 0.17018233239650726
Validation loss: 1.8804574608802795

Epoch: 6| Step: 8
Training loss: 0.3013528883457184
Validation loss: 1.9006425539652507

Epoch: 6| Step: 9
Training loss: 0.17343290150165558
Validation loss: 1.9219995141029358

Epoch: 6| Step: 10
Training loss: 0.3828023374080658
Validation loss: 1.9072956244150798

Epoch: 6| Step: 11
Training loss: 0.3679094910621643
Validation loss: 1.8701797127723694

Epoch: 6| Step: 12
Training loss: 0.45714929699897766
Validation loss: 1.8909940520922344

Epoch: 6| Step: 13
Training loss: 0.7441525459289551
Validation loss: 1.884714682896932

Epoch: 267| Step: 0
Training loss: 0.8251481652259827
Validation loss: 1.9057020942370098

Epoch: 6| Step: 1
Training loss: 0.3013579845428467
Validation loss: 1.8734010457992554

Epoch: 6| Step: 2
Training loss: 0.21613438427448273
Validation loss: 1.9025858640670776

Epoch: 6| Step: 3
Training loss: 0.5566096901893616
Validation loss: 1.9162750840187073

Epoch: 6| Step: 4
Training loss: 0.26985812187194824
Validation loss: 1.876417915026347

Epoch: 6| Step: 5
Training loss: 0.3883742094039917
Validation loss: 1.8618250290552776

Epoch: 6| Step: 6
Training loss: 0.38466906547546387
Validation loss: 1.8987553715705872

Epoch: 6| Step: 7
Training loss: 0.5981569290161133
Validation loss: 1.8325053453445435

Epoch: 6| Step: 8
Training loss: 0.42233365774154663
Validation loss: 1.8828002214431763

Epoch: 6| Step: 9
Training loss: 0.47780054807662964
Validation loss: 1.915239115556081

Epoch: 6| Step: 10
Training loss: 0.2588047683238983
Validation loss: 1.8916451533635457

Epoch: 6| Step: 11
Training loss: 0.2014557272195816
Validation loss: 1.8965213497479756

Epoch: 6| Step: 12
Training loss: 0.1907673478126526
Validation loss: 1.8853050072987874

Epoch: 6| Step: 13
Training loss: 0.2829660177230835
Validation loss: 1.8552164634068806

Epoch: 268| Step: 0
Training loss: 0.24929121136665344
Validation loss: 1.9048280914624531

Epoch: 6| Step: 1
Training loss: 0.7859593629837036
Validation loss: 1.8763524889945984

Epoch: 6| Step: 2
Training loss: 0.6060084104537964
Validation loss: 1.9027282396952312

Epoch: 6| Step: 3
Training loss: 0.23138052225112915
Validation loss: 1.8650246461232503

Epoch: 6| Step: 4
Training loss: 0.3749842643737793
Validation loss: 1.852129379908244

Epoch: 6| Step: 5
Training loss: 0.3175727128982544
Validation loss: 1.8986433347066243

Epoch: 6| Step: 6
Training loss: 0.25272276997566223
Validation loss: 1.8822695811589558

Epoch: 6| Step: 7
Training loss: 0.5179499387741089
Validation loss: 1.895075301329295

Epoch: 6| Step: 8
Training loss: 0.16501948237419128
Validation loss: 1.8638160824775696

Epoch: 6| Step: 9
Training loss: 0.3084791600704193
Validation loss: 1.8838417728741963

Epoch: 6| Step: 10
Training loss: 0.46485060453414917
Validation loss: 1.8367422223091125

Epoch: 6| Step: 11
Training loss: 0.2391943484544754
Validation loss: 1.867035726706187

Epoch: 6| Step: 12
Training loss: 0.4605129361152649
Validation loss: 1.8968229293823242

Epoch: 6| Step: 13
Training loss: 0.303946316242218
Validation loss: 1.922459324200948

Epoch: 269| Step: 0
Training loss: 0.3080631196498871
Validation loss: 1.8977469205856323

Epoch: 6| Step: 1
Training loss: 0.5129711627960205
Validation loss: 1.9088435967763264

Epoch: 6| Step: 2
Training loss: 0.5184728503227234
Validation loss: 1.853205959002177

Epoch: 6| Step: 3
Training loss: 0.34687334299087524
Validation loss: 1.8841302394866943

Epoch: 6| Step: 4
Training loss: 0.4108238220214844
Validation loss: 1.8437232573827107

Epoch: 6| Step: 5
Training loss: 0.2908293604850769
Validation loss: 1.9287450909614563

Epoch: 6| Step: 6
Training loss: 0.2983302175998688
Validation loss: 1.893967092037201

Epoch: 6| Step: 7
Training loss: 0.337999165058136
Validation loss: 1.8557341893513997

Epoch: 6| Step: 8
Training loss: 0.2972760498523712
Validation loss: 1.8939561645189922

Epoch: 6| Step: 9
Training loss: 0.28371402621269226
Validation loss: 1.8764030536015828

Epoch: 6| Step: 10
Training loss: 0.2962046265602112
Validation loss: 1.8928644458452861

Epoch: 6| Step: 11
Training loss: 0.6357405185699463
Validation loss: 1.8965922792752583

Epoch: 6| Step: 12
Training loss: 0.6175864934921265
Validation loss: 1.8634889125823975

Epoch: 6| Step: 13
Training loss: 0.17762228846549988
Validation loss: 1.8584266304969788

Epoch: 270| Step: 0
Training loss: 0.2200222611427307
Validation loss: 1.8861228426297505

Epoch: 6| Step: 1
Training loss: 0.49903810024261475
Validation loss: 1.8850699265797932

Epoch: 6| Step: 2
Training loss: 0.33072417974472046
Validation loss: 1.9136889576911926

Epoch: 6| Step: 3
Training loss: 0.4649685025215149
Validation loss: 1.8893731236457825

Epoch: 6| Step: 4
Training loss: 0.2217884361743927
Validation loss: 1.848903238773346

Epoch: 6| Step: 5
Training loss: 0.415549099445343
Validation loss: 1.903978168964386

Epoch: 6| Step: 6
Training loss: 0.4642863869667053
Validation loss: 1.901633898417155

Epoch: 6| Step: 7
Training loss: 0.25248539447784424
Validation loss: 1.8579861720403035

Epoch: 6| Step: 8
Training loss: 0.38803330063819885
Validation loss: 1.9201855460802715

Epoch: 6| Step: 9
Training loss: 0.22798359394073486
Validation loss: 1.8605189124743144

Epoch: 6| Step: 10
Training loss: 0.4520573019981384
Validation loss: 1.919744610786438

Epoch: 6| Step: 11
Training loss: 0.7579354047775269
Validation loss: 1.9087936282157898

Epoch: 6| Step: 12
Training loss: 0.2698054611682892
Validation loss: 1.9017608563105266

Epoch: 6| Step: 13
Training loss: 0.364463746547699
Validation loss: 1.8909449378649394

Epoch: 271| Step: 0
Training loss: 0.4869997501373291
Validation loss: 1.8777227401733398

Epoch: 6| Step: 1
Training loss: 0.30937087535858154
Validation loss: 1.9034346143404643

Epoch: 6| Step: 2
Training loss: 0.18448606133460999
Validation loss: 1.841155429681142

Epoch: 6| Step: 3
Training loss: 0.2859661877155304
Validation loss: 1.8785712917645772

Epoch: 6| Step: 4
Training loss: 0.29829642176628113
Validation loss: 1.8502516150474548

Epoch: 6| Step: 5
Training loss: 0.20481356978416443
Validation loss: 1.889973560969035

Epoch: 6| Step: 6
Training loss: 0.2880578637123108
Validation loss: 1.8844828208287556

Epoch: 6| Step: 7
Training loss: 0.9066684246063232
Validation loss: 1.9019490877787273

Epoch: 6| Step: 8
Training loss: 0.3281458616256714
Validation loss: 1.862442632516225

Epoch: 6| Step: 9
Training loss: 0.3029325306415558
Validation loss: 1.894180953502655

Epoch: 6| Step: 10
Training loss: 0.5129309296607971
Validation loss: 1.8896301984786987

Epoch: 6| Step: 11
Training loss: 0.39158010482788086
Validation loss: 1.8921441435813904

Epoch: 6| Step: 12
Training loss: 0.3887022137641907
Validation loss: 1.921658456325531

Epoch: 6| Step: 13
Training loss: 0.23965463042259216
Validation loss: 1.8749571442604065

Epoch: 272| Step: 0
Training loss: 0.2932503819465637
Validation loss: 1.8957480986913045

Epoch: 6| Step: 1
Training loss: 0.16556459665298462
Validation loss: 1.8772953947385151

Epoch: 6| Step: 2
Training loss: 0.39741718769073486
Validation loss: 1.8781109849611919

Epoch: 6| Step: 3
Training loss: 0.2716485261917114
Validation loss: 1.835391898949941

Epoch: 6| Step: 4
Training loss: 0.19309301674365997
Validation loss: 1.8444305857022603

Epoch: 6| Step: 5
Training loss: 0.4124765396118164
Validation loss: 1.8926547567049663

Epoch: 6| Step: 6
Training loss: 0.2729339003562927
Validation loss: 1.8582830627759297

Epoch: 6| Step: 7
Training loss: 0.3193361461162567
Validation loss: 1.8768873016039531

Epoch: 6| Step: 8
Training loss: 0.8002493381500244
Validation loss: 1.9048990607261658

Epoch: 6| Step: 9
Training loss: 0.6873528361320496
Validation loss: 1.8914617896080017

Epoch: 6| Step: 10
Training loss: 0.2994231581687927
Validation loss: 1.8834592898686726

Epoch: 6| Step: 11
Training loss: 0.16494593024253845
Validation loss: 1.8978402018547058

Epoch: 6| Step: 12
Training loss: 0.1872575879096985
Validation loss: 1.8634961048762004

Epoch: 6| Step: 13
Training loss: 0.221384197473526
Validation loss: 1.9169941941897075

Epoch: 273| Step: 0
Training loss: 0.24526268243789673
Validation loss: 1.8838013410568237

Epoch: 6| Step: 1
Training loss: 0.28267985582351685
Validation loss: 1.9023010730743408

Epoch: 6| Step: 2
Training loss: 0.25417500734329224
Validation loss: 1.9191595315933228

Epoch: 6| Step: 3
Training loss: 0.19805988669395447
Validation loss: 1.9300995469093323

Epoch: 6| Step: 4
Training loss: 0.35001248121261597
Validation loss: 1.9235389629999797

Epoch: 6| Step: 5
Training loss: 0.4200662672519684
Validation loss: 1.8992225726445515

Epoch: 6| Step: 6
Training loss: 0.27066361904144287
Validation loss: 1.8791073362032573

Epoch: 6| Step: 7
Training loss: 0.2768230736255646
Validation loss: 1.9109508792559307

Epoch: 6| Step: 8
Training loss: 0.9002372026443481
Validation loss: 1.9344535668690999

Epoch: 6| Step: 9
Training loss: 0.45227915048599243
Validation loss: 1.8839731613794963

Epoch: 6| Step: 10
Training loss: 0.43493878841400146
Validation loss: 1.9066734910011292

Epoch: 6| Step: 11
Training loss: 0.17444172501564026
Validation loss: 1.9017362594604492

Epoch: 6| Step: 12
Training loss: 0.49583280086517334
Validation loss: 1.90372633934021

Epoch: 6| Step: 13
Training loss: 0.23648251593112946
Validation loss: 1.9360239505767822

Epoch: 274| Step: 0
Training loss: 0.30128777027130127
Validation loss: 1.8909344673156738

Epoch: 6| Step: 1
Training loss: 0.7308253645896912
Validation loss: 1.9150215983390808

Epoch: 6| Step: 2
Training loss: 0.21163952350616455
Validation loss: 1.8976723154385884

Epoch: 6| Step: 3
Training loss: 0.5464746952056885
Validation loss: 1.885212282339732

Epoch: 6| Step: 4
Training loss: 0.3733498156070709
Validation loss: 1.9038657148679097

Epoch: 6| Step: 5
Training loss: 0.21308106184005737
Validation loss: 1.8994009693463643

Epoch: 6| Step: 6
Training loss: 0.45282480120658875
Validation loss: 1.9149930874506633

Epoch: 6| Step: 7
Training loss: 0.1962837278842926
Validation loss: 1.9166149695714314

Epoch: 6| Step: 8
Training loss: 0.28564155101776123
Validation loss: 1.8880426287651062

Epoch: 6| Step: 9
Training loss: 0.3552435040473938
Validation loss: 1.8940317432085674

Epoch: 6| Step: 10
Training loss: 0.18211506307125092
Validation loss: 1.8940903941790264

Epoch: 6| Step: 11
Training loss: 0.1487313061952591
Validation loss: 1.8941396872202556

Epoch: 6| Step: 12
Training loss: 0.6467716097831726
Validation loss: 1.9155667026837666

Epoch: 6| Step: 13
Training loss: 0.3456636667251587
Validation loss: 1.8997478882471721

Epoch: 275| Step: 0
Training loss: 0.36816543340682983
Validation loss: 1.896583576997121

Epoch: 6| Step: 1
Training loss: 0.39221954345703125
Validation loss: 1.8931665619214375

Epoch: 6| Step: 2
Training loss: 0.22780048847198486
Validation loss: 1.862238347530365

Epoch: 6| Step: 3
Training loss: 0.3460530638694763
Validation loss: 1.9353920221328735

Epoch: 6| Step: 4
Training loss: 0.38399893045425415
Validation loss: 1.9212677677472432

Epoch: 6| Step: 5
Training loss: 0.3418865203857422
Validation loss: 1.8947962721188862

Epoch: 6| Step: 6
Training loss: 0.20694077014923096
Validation loss: 1.9228567083676655

Epoch: 6| Step: 7
Training loss: 0.2419443428516388
Validation loss: 1.8883389631907146

Epoch: 6| Step: 8
Training loss: 0.44116848707199097
Validation loss: 1.914549171924591

Epoch: 6| Step: 9
Training loss: 0.24960382282733917
Validation loss: 1.9311190843582153

Epoch: 6| Step: 10
Training loss: 0.7891799211502075
Validation loss: 1.886778434117635

Epoch: 6| Step: 11
Training loss: 0.46101558208465576
Validation loss: 1.9175268014272053

Epoch: 6| Step: 12
Training loss: 0.37787917256355286
Validation loss: 1.9033475120862324

Epoch: 6| Step: 13
Training loss: 0.33908960223197937
Validation loss: 1.9096797307332356

Epoch: 276| Step: 0
Training loss: 0.1375628411769867
Validation loss: 1.8445632656415303

Epoch: 6| Step: 1
Training loss: 0.36349886655807495
Validation loss: 1.8815851012865703

Epoch: 6| Step: 2
Training loss: 0.17357103526592255
Validation loss: 1.8993940750757854

Epoch: 6| Step: 3
Training loss: 0.39598414301872253
Validation loss: 1.8803563117980957

Epoch: 6| Step: 4
Training loss: 0.3587539792060852
Validation loss: 1.9431681831677754

Epoch: 6| Step: 5
Training loss: 0.3145604133605957
Validation loss: 1.8690001368522644

Epoch: 6| Step: 6
Training loss: 0.2705146372318268
Validation loss: 1.9004868865013123

Epoch: 6| Step: 7
Training loss: 0.7451291084289551
Validation loss: 1.8747859597206116

Epoch: 6| Step: 8
Training loss: 0.3436200022697449
Validation loss: 1.8883331418037415

Epoch: 6| Step: 9
Training loss: 0.25945085287094116
Validation loss: 1.8854771256446838

Epoch: 6| Step: 10
Training loss: 0.22315461933612823
Validation loss: 1.9136603871981304

Epoch: 6| Step: 11
Training loss: 0.5340694189071655
Validation loss: 1.8714497486750286

Epoch: 6| Step: 12
Training loss: 0.42080384492874146
Validation loss: 1.8536891142527263

Epoch: 6| Step: 13
Training loss: 0.3840552568435669
Validation loss: 1.9040533701578777

Epoch: 277| Step: 0
Training loss: 0.2687879800796509
Validation loss: 1.9069956541061401

Epoch: 6| Step: 1
Training loss: 0.2452404499053955
Validation loss: 1.9439735213915508

Epoch: 6| Step: 2
Training loss: 0.17257586121559143
Validation loss: 1.8738160729408264

Epoch: 6| Step: 3
Training loss: 0.1903066337108612
Validation loss: 1.8685125311215718

Epoch: 6| Step: 4
Training loss: 0.6337095499038696
Validation loss: 1.8796438177426655

Epoch: 6| Step: 5
Training loss: 0.5122150182723999
Validation loss: 1.8887344400087993

Epoch: 6| Step: 6
Training loss: 0.4415474832057953
Validation loss: 1.9168277978897095

Epoch: 6| Step: 7
Training loss: 0.45843827724456787
Validation loss: 1.916519542535146

Epoch: 6| Step: 8
Training loss: 0.15118589997291565
Validation loss: 1.8798869848251343

Epoch: 6| Step: 9
Training loss: 0.40583673119544983
Validation loss: 1.885932187239329

Epoch: 6| Step: 10
Training loss: 0.3026447594165802
Validation loss: 1.9007731874783833

Epoch: 6| Step: 11
Training loss: 0.3799428343772888
Validation loss: 1.9070021708806355

Epoch: 6| Step: 12
Training loss: 0.324451744556427
Validation loss: 1.8745434284210205

Epoch: 6| Step: 13
Training loss: 0.33242833614349365
Validation loss: 1.8696240186691284

Epoch: 278| Step: 0
Training loss: 0.37925493717193604
Validation loss: 1.8690119981765747

Epoch: 6| Step: 1
Training loss: 0.21586795151233673
Validation loss: 1.8860676685969036

Epoch: 6| Step: 2
Training loss: 0.2389097511768341
Validation loss: 1.844187597433726

Epoch: 6| Step: 3
Training loss: 0.3604947328567505
Validation loss: 1.8989630738894145

Epoch: 6| Step: 4
Training loss: 0.2572767734527588
Validation loss: 1.8807012438774109

Epoch: 6| Step: 5
Training loss: 0.1910504400730133
Validation loss: 1.8916930953661601

Epoch: 6| Step: 6
Training loss: 0.6894822120666504
Validation loss: 1.8531920711199443

Epoch: 6| Step: 7
Training loss: 0.37007638812065125
Validation loss: 1.8886620004971821

Epoch: 6| Step: 8
Training loss: 0.3121752142906189
Validation loss: 1.8548524975776672

Epoch: 6| Step: 9
Training loss: 0.3432735502719879
Validation loss: 1.855133314927419

Epoch: 6| Step: 10
Training loss: 0.3562619686126709
Validation loss: 1.9285317460695903

Epoch: 6| Step: 11
Training loss: 0.27016061544418335
Validation loss: 1.922197659810384

Epoch: 6| Step: 12
Training loss: 0.45226120948791504
Validation loss: 1.9076271653175354

Epoch: 6| Step: 13
Training loss: 0.21924424171447754
Validation loss: 1.9113502701123555

Epoch: 279| Step: 0
Training loss: 0.22879943251609802
Validation loss: 1.8922564188639324

Epoch: 6| Step: 1
Training loss: 0.2269066572189331
Validation loss: 1.8588025569915771

Epoch: 6| Step: 2
Training loss: 0.314925879240036
Validation loss: 1.8479966521263123

Epoch: 6| Step: 3
Training loss: 0.3527737855911255
Validation loss: 1.8897876938184102

Epoch: 6| Step: 4
Training loss: 0.5184791684150696
Validation loss: 1.8684439659118652

Epoch: 6| Step: 5
Training loss: 0.2992329001426697
Validation loss: 1.9340288241704304

Epoch: 6| Step: 6
Training loss: 0.744383692741394
Validation loss: 1.8616831700007122

Epoch: 6| Step: 7
Training loss: 0.35105055570602417
Validation loss: 1.8739941914876301

Epoch: 6| Step: 8
Training loss: 0.2647101879119873
Validation loss: 1.848753531773885

Epoch: 6| Step: 9
Training loss: 0.299538254737854
Validation loss: 1.9260555505752563

Epoch: 6| Step: 10
Training loss: 0.22220994532108307
Validation loss: 1.9091241161028545

Epoch: 6| Step: 11
Training loss: 0.6868168711662292
Validation loss: 1.8754886587460835

Epoch: 6| Step: 12
Training loss: 0.23498445749282837
Validation loss: 1.876310408115387

Epoch: 6| Step: 13
Training loss: 0.30935871601104736
Validation loss: 1.8438028295834858

Epoch: 280| Step: 0
Training loss: 0.3960525393486023
Validation loss: 1.8681112329165142

Epoch: 6| Step: 1
Training loss: 0.29984647035598755
Validation loss: 1.8724041779836018

Epoch: 6| Step: 2
Training loss: 0.17493928968906403
Validation loss: 1.8795801202456157

Epoch: 6| Step: 3
Training loss: 0.28415507078170776
Validation loss: 1.8886499404907227

Epoch: 6| Step: 4
Training loss: 0.2854767441749573
Validation loss: 1.8764939904212952

Epoch: 6| Step: 5
Training loss: 0.3103320896625519
Validation loss: 1.860093931357066

Epoch: 6| Step: 6
Training loss: 0.40203166007995605
Validation loss: 1.9133824507395427

Epoch: 6| Step: 7
Training loss: 0.22601598501205444
Validation loss: 1.8673944274584453

Epoch: 6| Step: 8
Training loss: 0.812066376209259
Validation loss: 1.885250727335612

Epoch: 6| Step: 9
Training loss: 0.24323183298110962
Validation loss: 1.8836467663447063

Epoch: 6| Step: 10
Training loss: 0.3613147735595703
Validation loss: 1.864162266254425

Epoch: 6| Step: 11
Training loss: 0.33020779490470886
Validation loss: 1.903421143690745

Epoch: 6| Step: 12
Training loss: 0.23017320036888123
Validation loss: 1.9221309622128804

Epoch: 6| Step: 13
Training loss: 0.5465460419654846
Validation loss: 1.881582776705424

Epoch: 281| Step: 0
Training loss: 0.43899038434028625
Validation loss: 1.8996466596921284

Epoch: 6| Step: 1
Training loss: 0.3755474090576172
Validation loss: 1.885905126730601

Epoch: 6| Step: 2
Training loss: 0.785713791847229
Validation loss: 1.890975574652354

Epoch: 6| Step: 3
Training loss: 0.4237813353538513
Validation loss: 1.9006085594495137

Epoch: 6| Step: 4
Training loss: 0.3008023500442505
Validation loss: 1.8883506258328755

Epoch: 6| Step: 5
Training loss: 0.4441315531730652
Validation loss: 1.8883882562319438

Epoch: 6| Step: 6
Training loss: 0.516168475151062
Validation loss: 1.8567930261294048

Epoch: 6| Step: 7
Training loss: 0.27942711114883423
Validation loss: 1.9240618348121643

Epoch: 6| Step: 8
Training loss: 0.18441514670848846
Validation loss: 1.8880355954170227

Epoch: 6| Step: 9
Training loss: 0.3207552433013916
Validation loss: 1.873623291651408

Epoch: 6| Step: 10
Training loss: 0.40856024622917175
Validation loss: 1.8682254155476887

Epoch: 6| Step: 11
Training loss: 0.22902825474739075
Validation loss: 1.857130229473114

Epoch: 6| Step: 12
Training loss: 0.29943180084228516
Validation loss: 1.8933098713556926

Epoch: 6| Step: 13
Training loss: 0.38175714015960693
Validation loss: 1.8841509222984314

Epoch: 282| Step: 0
Training loss: 0.8319838643074036
Validation loss: 1.8652525941530864

Epoch: 6| Step: 1
Training loss: 0.30500277876853943
Validation loss: 1.8997724652290344

Epoch: 6| Step: 2
Training loss: 0.34203410148620605
Validation loss: 1.8595125675201416

Epoch: 6| Step: 3
Training loss: 0.31756359338760376
Validation loss: 1.8531922896703084

Epoch: 6| Step: 4
Training loss: 0.4164695739746094
Validation loss: 1.8897762497266133

Epoch: 6| Step: 5
Training loss: 0.24020421504974365
Validation loss: 1.8775506814320881

Epoch: 6| Step: 6
Training loss: 0.33155953884124756
Validation loss: 1.905701756477356

Epoch: 6| Step: 7
Training loss: 0.38821402192115784
Validation loss: 1.8574675917625427

Epoch: 6| Step: 8
Training loss: 0.21781492233276367
Validation loss: 1.8973008394241333

Epoch: 6| Step: 9
Training loss: 0.32092732191085815
Validation loss: 1.8395654559135437

Epoch: 6| Step: 10
Training loss: 0.25960573554039
Validation loss: 1.8287267486254375

Epoch: 6| Step: 11
Training loss: 0.3509427309036255
Validation loss: 1.8644323348999023

Epoch: 6| Step: 12
Training loss: 0.5434015989303589
Validation loss: 1.8496756951014202

Epoch: 6| Step: 13
Training loss: 0.2641361355781555
Validation loss: 1.87080321709315

Epoch: 283| Step: 0
Training loss: 0.505780816078186
Validation loss: 1.8756142059961955

Epoch: 6| Step: 1
Training loss: 0.31611210107803345
Validation loss: 1.8765874703725178

Epoch: 6| Step: 2
Training loss: 0.3084709048271179
Validation loss: 1.8719275792439778

Epoch: 6| Step: 3
Training loss: 0.19699522852897644
Validation loss: 1.9163166284561157

Epoch: 6| Step: 4
Training loss: 0.30989110469818115
Validation loss: 1.9059160153071086

Epoch: 6| Step: 5
Training loss: 0.35519176721572876
Validation loss: 1.860439419746399

Epoch: 6| Step: 6
Training loss: 0.31415945291519165
Validation loss: 1.8859809239705403

Epoch: 6| Step: 7
Training loss: 0.6669288873672485
Validation loss: 1.888773242632548

Epoch: 6| Step: 8
Training loss: 0.44057974219322205
Validation loss: 1.915621817111969

Epoch: 6| Step: 9
Training loss: 0.13518080115318298
Validation loss: 1.886820415655772

Epoch: 6| Step: 10
Training loss: 0.31995415687561035
Validation loss: 1.891798694928487

Epoch: 6| Step: 11
Training loss: 0.43525606393814087
Validation loss: 1.8793572783470154

Epoch: 6| Step: 12
Training loss: 0.300898015499115
Validation loss: 1.9272799491882324

Epoch: 6| Step: 13
Training loss: 0.25384628772735596
Validation loss: 1.8818325797716777

Epoch: 284| Step: 0
Training loss: 0.3891341984272003
Validation loss: 1.9033318956693013

Epoch: 6| Step: 1
Training loss: 0.45580559968948364
Validation loss: 1.9166938463846843

Epoch: 6| Step: 2
Training loss: 0.14329808950424194
Validation loss: 1.8860193093617756

Epoch: 6| Step: 3
Training loss: 0.38139021396636963
Validation loss: 1.9098287224769592

Epoch: 6| Step: 4
Training loss: 0.3219224214553833
Validation loss: 1.9220235149065654

Epoch: 6| Step: 5
Training loss: 0.16257233917713165
Validation loss: 1.8716021378835042

Epoch: 6| Step: 6
Training loss: 0.481628954410553
Validation loss: 1.8840504089991252

Epoch: 6| Step: 7
Training loss: 0.27186867594718933
Validation loss: 1.9471646149953206

Epoch: 6| Step: 8
Training loss: 0.35301053524017334
Validation loss: 1.9003734191258748

Epoch: 6| Step: 9
Training loss: 0.6657223701477051
Validation loss: 1.8708258668581645

Epoch: 6| Step: 10
Training loss: 0.2699652910232544
Validation loss: 1.8936032851537068

Epoch: 6| Step: 11
Training loss: 0.23835408687591553
Validation loss: 1.8785061836242676

Epoch: 6| Step: 12
Training loss: 0.3966558277606964
Validation loss: 1.8666589856147766

Epoch: 6| Step: 13
Training loss: 0.21761614084243774
Validation loss: 1.9030679265658061

Epoch: 285| Step: 0
Training loss: 0.390261173248291
Validation loss: 1.8974138696988423

Epoch: 6| Step: 1
Training loss: 0.2555440366268158
Validation loss: 1.8577637672424316

Epoch: 6| Step: 2
Training loss: 0.4119039475917816
Validation loss: 1.9164201219876607

Epoch: 6| Step: 3
Training loss: 0.23225194215774536
Validation loss: 1.8912474115689595

Epoch: 6| Step: 4
Training loss: 0.22839833796024323
Validation loss: 1.9155876239140828

Epoch: 6| Step: 5
Training loss: 1.0761523246765137
Validation loss: 1.8750802079836528

Epoch: 6| Step: 6
Training loss: 0.35023170709609985
Validation loss: 1.8823930223782857

Epoch: 6| Step: 7
Training loss: 0.19740572571754456
Validation loss: 1.8474844892819722

Epoch: 6| Step: 8
Training loss: 0.3365454077720642
Validation loss: 1.8691096703211467

Epoch: 6| Step: 9
Training loss: 0.25509172677993774
Validation loss: 1.9247449040412903

Epoch: 6| Step: 10
Training loss: 0.42254117131233215
Validation loss: 1.8540897170702617

Epoch: 6| Step: 11
Training loss: 0.2071838676929474
Validation loss: 1.941077450911204

Epoch: 6| Step: 12
Training loss: 0.2917115092277527
Validation loss: 1.8957631190617878

Epoch: 6| Step: 13
Training loss: 0.2532273530960083
Validation loss: 1.8743916749954224

Epoch: 286| Step: 0
Training loss: 0.24691130220890045
Validation loss: 1.8693910837173462

Epoch: 6| Step: 1
Training loss: 0.2651960253715515
Validation loss: 1.8730096022288005

Epoch: 6| Step: 2
Training loss: 0.41929200291633606
Validation loss: 1.8774937987327576

Epoch: 6| Step: 3
Training loss: 0.23879025876522064
Validation loss: 1.8987380464871724

Epoch: 6| Step: 4
Training loss: 0.18116062879562378
Validation loss: 1.9073917468388875

Epoch: 6| Step: 5
Training loss: 0.2675821781158447
Validation loss: 1.9109461704889934

Epoch: 6| Step: 6
Training loss: 0.758144736289978
Validation loss: 1.8681204716364543

Epoch: 6| Step: 7
Training loss: 0.452872097492218
Validation loss: 1.8949730197588603

Epoch: 6| Step: 8
Training loss: 0.4393065273761749
Validation loss: 1.8498980800310771

Epoch: 6| Step: 9
Training loss: 0.17613030970096588
Validation loss: 1.8720362186431885

Epoch: 6| Step: 10
Training loss: 0.43312084674835205
Validation loss: 1.8426024119059246

Epoch: 6| Step: 11
Training loss: 0.2691229581832886
Validation loss: 1.8725087841351826

Epoch: 6| Step: 12
Training loss: 0.4138373136520386
Validation loss: 1.8695835669835408

Epoch: 6| Step: 13
Training loss: 0.498882919549942
Validation loss: 1.8606635133425395

Epoch: 287| Step: 0
Training loss: 0.3208891749382019
Validation loss: 1.882718602816264

Epoch: 6| Step: 1
Training loss: 0.2968600392341614
Validation loss: 1.9099283615748088

Epoch: 6| Step: 2
Training loss: 0.6729357838630676
Validation loss: 1.8977222839991252

Epoch: 6| Step: 3
Training loss: 0.3324252665042877
Validation loss: 1.855203131834666

Epoch: 6| Step: 4
Training loss: 0.2605745494365692
Validation loss: 1.872922917207082

Epoch: 6| Step: 5
Training loss: 0.3965775668621063
Validation loss: 1.8854206800460815

Epoch: 6| Step: 6
Training loss: 0.2068939507007599
Validation loss: 1.8571487665176392

Epoch: 6| Step: 7
Training loss: 0.3533971905708313
Validation loss: 1.8432066837946575

Epoch: 6| Step: 8
Training loss: 0.4353486895561218
Validation loss: 1.83135320742925

Epoch: 6| Step: 9
Training loss: 0.45537492632865906
Validation loss: 1.8892994324366252

Epoch: 6| Step: 10
Training loss: 0.4562987685203552
Validation loss: 1.8672159910202026

Epoch: 6| Step: 11
Training loss: 0.2752739489078522
Validation loss: 1.8423533042271931

Epoch: 6| Step: 12
Training loss: 0.3604861795902252
Validation loss: 1.9216052889823914

Epoch: 6| Step: 13
Training loss: 0.3703899681568146
Validation loss: 1.8547132015228271

Epoch: 288| Step: 0
Training loss: 0.41302019357681274
Validation loss: 1.885566254456838

Epoch: 6| Step: 1
Training loss: 0.22674879431724548
Validation loss: 1.891423265139262

Epoch: 6| Step: 2
Training loss: 0.3955265283584595
Validation loss: 1.862330953280131

Epoch: 6| Step: 3
Training loss: 0.7634806632995605
Validation loss: 1.858182390530904

Epoch: 6| Step: 4
Training loss: 0.30726397037506104
Validation loss: 1.879516104857127

Epoch: 6| Step: 5
Training loss: 0.2746608853340149
Validation loss: 1.8200825055440266

Epoch: 6| Step: 6
Training loss: 0.24619269371032715
Validation loss: 1.8396770358085632

Epoch: 6| Step: 7
Training loss: 0.4655234217643738
Validation loss: 1.8679532806078594

Epoch: 6| Step: 8
Training loss: 0.24209503829479218
Validation loss: 1.8562373121579487

Epoch: 6| Step: 9
Training loss: 0.44465357065200806
Validation loss: 1.8600483139355977

Epoch: 6| Step: 10
Training loss: 0.4325064718723297
Validation loss: 1.8829941948254902

Epoch: 6| Step: 11
Training loss: 0.24793188273906708
Validation loss: 1.8638616402943928

Epoch: 6| Step: 12
Training loss: 0.1515112966299057
Validation loss: 1.871626337369283

Epoch: 6| Step: 13
Training loss: 0.32615989446640015
Validation loss: 1.8959240118662517

Epoch: 289| Step: 0
Training loss: 0.2966839373111725
Validation loss: 1.8674707611401875

Epoch: 6| Step: 1
Training loss: 0.33994248509407043
Validation loss: 1.860215425491333

Epoch: 6| Step: 2
Training loss: 0.24365252256393433
Validation loss: 1.890350063641866

Epoch: 6| Step: 3
Training loss: 0.26958149671554565
Validation loss: 1.9021386504173279

Epoch: 6| Step: 4
Training loss: 0.3005036413669586
Validation loss: 1.8699058890342712

Epoch: 6| Step: 5
Training loss: 0.8299731016159058
Validation loss: 1.851063867410024

Epoch: 6| Step: 6
Training loss: 0.2438768744468689
Validation loss: 1.9033345778783162

Epoch: 6| Step: 7
Training loss: 0.3212626576423645
Validation loss: 1.862879753112793

Epoch: 6| Step: 8
Training loss: 0.353174090385437
Validation loss: 1.880035142103831

Epoch: 6| Step: 9
Training loss: 0.36921441555023193
Validation loss: 1.8560824394226074

Epoch: 6| Step: 10
Training loss: 0.3142818808555603
Validation loss: 1.9007543921470642

Epoch: 6| Step: 11
Training loss: 0.3030318021774292
Validation loss: 1.8796815474828084

Epoch: 6| Step: 12
Training loss: 0.2100057303905487
Validation loss: 1.9559938510258992

Epoch: 6| Step: 13
Training loss: 0.4451138973236084
Validation loss: 1.8815609415372212

Epoch: 290| Step: 0
Training loss: 0.8032773733139038
Validation loss: 1.888215184211731

Epoch: 6| Step: 1
Training loss: 0.2934245467185974
Validation loss: 1.8774662812550862

Epoch: 6| Step: 2
Training loss: 0.2479756474494934
Validation loss: 1.9065276980400085

Epoch: 6| Step: 3
Training loss: 0.3455885946750641
Validation loss: 1.8652018109957378

Epoch: 6| Step: 4
Training loss: 0.20437058806419373
Validation loss: 1.863957663377126

Epoch: 6| Step: 5
Training loss: 0.4782026708126068
Validation loss: 1.8841402331988018

Epoch: 6| Step: 6
Training loss: 0.1908683180809021
Validation loss: 1.8588788906733196

Epoch: 6| Step: 7
Training loss: 0.3542570471763611
Validation loss: 1.831573764483134

Epoch: 6| Step: 8
Training loss: 0.2589837908744812
Validation loss: 1.8587033152580261

Epoch: 6| Step: 9
Training loss: 0.4074475169181824
Validation loss: 1.8745094537734985

Epoch: 6| Step: 10
Training loss: 0.40208983421325684
Validation loss: 1.9232804775238037

Epoch: 6| Step: 11
Training loss: 0.3137960433959961
Validation loss: 1.8326623439788818

Epoch: 6| Step: 12
Training loss: 0.22045324742794037
Validation loss: 1.8798405130704243

Epoch: 6| Step: 13
Training loss: 0.24144163727760315
Validation loss: 1.8539817134539287

Epoch: 291| Step: 0
Training loss: 0.3036138117313385
Validation loss: 1.8926359216372173

Epoch: 6| Step: 1
Training loss: 0.3090723752975464
Validation loss: 1.8871016105016072

Epoch: 6| Step: 2
Training loss: 0.3849952220916748
Validation loss: 1.8791345953941345

Epoch: 6| Step: 3
Training loss: 0.30480724573135376
Validation loss: 1.8868494232495625

Epoch: 6| Step: 4
Training loss: 0.18477588891983032
Validation loss: 1.8597497940063477

Epoch: 6| Step: 5
Training loss: 0.33063822984695435
Validation loss: 1.867160717646281

Epoch: 6| Step: 6
Training loss: 0.30384260416030884
Validation loss: 1.8977442979812622

Epoch: 6| Step: 7
Training loss: 0.18303433060646057
Validation loss: 1.8665848970413208

Epoch: 6| Step: 8
Training loss: 0.931941032409668
Validation loss: 1.8885065118471782

Epoch: 6| Step: 9
Training loss: 0.20081904530525208
Validation loss: 1.8322697480519612

Epoch: 6| Step: 10
Training loss: 0.2935516834259033
Validation loss: 1.8721667726834614

Epoch: 6| Step: 11
Training loss: 0.34337788820266724
Validation loss: 1.8697372277577717

Epoch: 6| Step: 12
Training loss: 0.4843454957008362
Validation loss: 1.8964378039042156

Epoch: 6| Step: 13
Training loss: 0.2760162055492401
Validation loss: 1.9301891128222148

Epoch: 292| Step: 0
Training loss: 0.1725919246673584
Validation loss: 1.8874006271362305

Epoch: 6| Step: 1
Training loss: 0.39948296546936035
Validation loss: 1.8501648505528767

Epoch: 6| Step: 2
Training loss: 0.3562321960926056
Validation loss: 1.8154213627179463

Epoch: 6| Step: 3
Training loss: 0.3835371136665344
Validation loss: 1.8784404198328655

Epoch: 6| Step: 4
Training loss: 0.36091798543930054
Validation loss: 1.876765509446462

Epoch: 6| Step: 5
Training loss: 0.2049221396446228
Validation loss: 1.8858500321706135

Epoch: 6| Step: 6
Training loss: 0.36311405897140503
Validation loss: 1.877564291159312

Epoch: 6| Step: 7
Training loss: 0.31875908374786377
Validation loss: 1.8566962877909343

Epoch: 6| Step: 8
Training loss: 0.40515071153640747
Validation loss: 1.8918301065762837

Epoch: 6| Step: 9
Training loss: 0.30088725686073303
Validation loss: 1.8728424708048503

Epoch: 6| Step: 10
Training loss: 0.3040054738521576
Validation loss: 1.8645393053690593

Epoch: 6| Step: 11
Training loss: 0.25234806537628174
Validation loss: 1.886194884777069

Epoch: 6| Step: 12
Training loss: 0.6389034986495972
Validation loss: 1.8870383302370708

Epoch: 6| Step: 13
Training loss: 0.5622409582138062
Validation loss: 1.8671573996543884

Epoch: 293| Step: 0
Training loss: 0.7087523937225342
Validation loss: 1.8701058427492778

Epoch: 6| Step: 1
Training loss: 0.35315975546836853
Validation loss: 1.9006210565567017

Epoch: 6| Step: 2
Training loss: 0.22383412718772888
Validation loss: 1.851592739423116

Epoch: 6| Step: 3
Training loss: 0.34815526008605957
Validation loss: 1.8646303017934163

Epoch: 6| Step: 4
Training loss: 0.2270464301109314
Validation loss: 1.8868033488591511

Epoch: 6| Step: 5
Training loss: 0.4089754819869995
Validation loss: 1.8605434497197468

Epoch: 6| Step: 6
Training loss: 0.5324122309684753
Validation loss: 1.8399855494499207

Epoch: 6| Step: 7
Training loss: 0.4863574504852295
Validation loss: 1.8570358554522197

Epoch: 6| Step: 8
Training loss: 0.20563289523124695
Validation loss: 1.8435303171475728

Epoch: 6| Step: 9
Training loss: 0.5738527774810791
Validation loss: 1.867533028125763

Epoch: 6| Step: 10
Training loss: 0.19225764274597168
Validation loss: 1.8538833657900493

Epoch: 6| Step: 11
Training loss: 0.23588839173316956
Validation loss: 1.8760754068692524

Epoch: 6| Step: 12
Training loss: 0.27883344888687134
Validation loss: 1.8748250007629395

Epoch: 6| Step: 13
Training loss: 0.19729991257190704
Validation loss: 1.8509199817975361

Epoch: 294| Step: 0
Training loss: 0.18174122273921967
Validation loss: 1.8947721521059673

Epoch: 6| Step: 1
Training loss: 0.5591606497764587
Validation loss: 1.879680335521698

Epoch: 6| Step: 2
Training loss: 0.27852821350097656
Validation loss: 1.8707170685132344

Epoch: 6| Step: 3
Training loss: 0.43429121375083923
Validation loss: 1.845699389775594

Epoch: 6| Step: 4
Training loss: 0.2784355878829956
Validation loss: 1.8794260223706563

Epoch: 6| Step: 5
Training loss: 0.21043279767036438
Validation loss: 1.884226123491923

Epoch: 6| Step: 6
Training loss: 0.33652347326278687
Validation loss: 1.877904236316681

Epoch: 6| Step: 7
Training loss: 0.23771312832832336
Validation loss: 1.8829363584518433

Epoch: 6| Step: 8
Training loss: 0.31348663568496704
Validation loss: 1.8825809558232625

Epoch: 6| Step: 9
Training loss: 0.8688318133354187
Validation loss: 1.866959035396576

Epoch: 6| Step: 10
Training loss: 0.20599496364593506
Validation loss: 1.9024009704589844

Epoch: 6| Step: 11
Training loss: 0.4464907646179199
Validation loss: 1.8651677370071411

Epoch: 6| Step: 12
Training loss: 0.3527683615684509
Validation loss: 1.8295331001281738

Epoch: 6| Step: 13
Training loss: 0.30588483810424805
Validation loss: 1.8619447350502014

Epoch: 295| Step: 0
Training loss: 0.3389466404914856
Validation loss: 1.8851027290026348

Epoch: 6| Step: 1
Training loss: 0.26349082589149475
Validation loss: 1.8327033718427022

Epoch: 6| Step: 2
Training loss: 0.24571028351783752
Validation loss: 1.857999583085378

Epoch: 6| Step: 3
Training loss: 0.614626407623291
Validation loss: 1.8573330442110698

Epoch: 6| Step: 4
Training loss: 0.2476268708705902
Validation loss: 1.8654598593711853

Epoch: 6| Step: 5
Training loss: 0.24089866876602173
Validation loss: 1.8487741152445476

Epoch: 6| Step: 6
Training loss: 0.23097030818462372
Validation loss: 1.8564460277557373

Epoch: 6| Step: 7
Training loss: 0.45327675342559814
Validation loss: 1.8695259094238281

Epoch: 6| Step: 8
Training loss: 0.37345150113105774
Validation loss: 1.8467386563618977

Epoch: 6| Step: 9
Training loss: 0.2995012104511261
Validation loss: 1.9252398014068604

Epoch: 6| Step: 10
Training loss: 0.21666868031024933
Validation loss: 1.8435325622558594

Epoch: 6| Step: 11
Training loss: 0.2100047767162323
Validation loss: 1.8633632063865662

Epoch: 6| Step: 12
Training loss: 0.36690855026245117
Validation loss: 1.8616916338602703

Epoch: 6| Step: 13
Training loss: 0.5349674224853516
Validation loss: 1.8461432854334514

Epoch: 296| Step: 0
Training loss: 0.3114958107471466
Validation loss: 1.886517345905304

Epoch: 6| Step: 1
Training loss: 0.6377683281898499
Validation loss: 1.876435101032257

Epoch: 6| Step: 2
Training loss: 0.36462730169296265
Validation loss: 1.855203886826833

Epoch: 6| Step: 3
Training loss: 0.26630938053131104
Validation loss: 1.886828621228536

Epoch: 6| Step: 4
Training loss: 0.32407239079475403
Validation loss: 1.8381269176801045

Epoch: 6| Step: 5
Training loss: 0.3843759000301361
Validation loss: 1.8670141299565632

Epoch: 6| Step: 6
Training loss: 0.4952816367149353
Validation loss: 1.8357825477917988

Epoch: 6| Step: 7
Training loss: 0.5510911345481873
Validation loss: 1.8427436749140422

Epoch: 6| Step: 8
Training loss: 0.2367667406797409
Validation loss: 1.884634792804718

Epoch: 6| Step: 9
Training loss: 0.2590528130531311
Validation loss: 1.8543047308921814

Epoch: 6| Step: 10
Training loss: 0.19796323776245117
Validation loss: 1.8803796768188477

Epoch: 6| Step: 11
Training loss: 0.23380115628242493
Validation loss: 1.8557146986325581

Epoch: 6| Step: 12
Training loss: 0.29274511337280273
Validation loss: 1.8893478910128276

Epoch: 6| Step: 13
Training loss: 0.4524655342102051
Validation loss: 1.8727264801661174

Epoch: 297| Step: 0
Training loss: 0.20988568663597107
Validation loss: 1.9121795296669006

Epoch: 6| Step: 1
Training loss: 0.29955190420150757
Validation loss: 1.8340114156405132

Epoch: 6| Step: 2
Training loss: 0.5120624303817749
Validation loss: 1.8541925350824993

Epoch: 6| Step: 3
Training loss: 0.36291635036468506
Validation loss: 1.8410735527674358

Epoch: 6| Step: 4
Training loss: 0.19223642349243164
Validation loss: 1.887868881225586

Epoch: 6| Step: 5
Training loss: 0.16621127724647522
Validation loss: 1.8815884788831074

Epoch: 6| Step: 6
Training loss: 0.6447882652282715
Validation loss: 1.8560364643732707

Epoch: 6| Step: 7
Training loss: 0.45242273807525635
Validation loss: 1.8586000601450603

Epoch: 6| Step: 8
Training loss: 0.4505268633365631
Validation loss: 1.8804186185201008

Epoch: 6| Step: 9
Training loss: 0.17937293648719788
Validation loss: 1.8857941230138142

Epoch: 6| Step: 10
Training loss: 0.17090165615081787
Validation loss: 1.8530031045277913

Epoch: 6| Step: 11
Training loss: 0.5981965065002441
Validation loss: 1.881515085697174

Epoch: 6| Step: 12
Training loss: 0.3100806474685669
Validation loss: 1.8816901246706645

Epoch: 6| Step: 13
Training loss: 0.3497258722782135
Validation loss: 1.8870555957158406

Epoch: 298| Step: 0
Training loss: 0.5812849998474121
Validation loss: 1.8619553844134014

Epoch: 6| Step: 1
Training loss: 0.3683013617992401
Validation loss: 1.8685836394627888

Epoch: 6| Step: 2
Training loss: 0.33175545930862427
Validation loss: 1.840982476870219

Epoch: 6| Step: 3
Training loss: 0.3318359851837158
Validation loss: 1.9089508652687073

Epoch: 6| Step: 4
Training loss: 0.38590455055236816
Validation loss: 1.8665116429328918

Epoch: 6| Step: 5
Training loss: 0.37272217869758606
Validation loss: 1.9029947519302368

Epoch: 6| Step: 6
Training loss: 0.25663819909095764
Validation loss: 1.9152499636014302

Epoch: 6| Step: 7
Training loss: 0.36327165365219116
Validation loss: 1.8798896074295044

Epoch: 6| Step: 8
Training loss: 0.408109575510025
Validation loss: 1.9001744190851848

Epoch: 6| Step: 9
Training loss: 0.3267189860343933
Validation loss: 1.8596189816792805

Epoch: 6| Step: 10
Training loss: 0.6704042553901672
Validation loss: 1.8847756385803223

Epoch: 6| Step: 11
Training loss: 0.18606911599636078
Validation loss: 1.8784899512926738

Epoch: 6| Step: 12
Training loss: 0.23729056119918823
Validation loss: 1.8610112071037292

Epoch: 6| Step: 13
Training loss: 0.29496195912361145
Validation loss: 1.9017771482467651

Epoch: 299| Step: 0
Training loss: 0.41742444038391113
Validation loss: 1.8433956901232402

Epoch: 6| Step: 1
Training loss: 0.2608725428581238
Validation loss: 1.8812703490257263

Epoch: 6| Step: 2
Training loss: 0.21732430160045624
Validation loss: 1.864681879679362

Epoch: 6| Step: 3
Training loss: 0.26006585359573364
Validation loss: 1.8756792147954304

Epoch: 6| Step: 4
Training loss: 0.3247155547142029
Validation loss: 1.8927442232767742

Epoch: 6| Step: 5
Training loss: 0.3379429578781128
Validation loss: 1.872202177842458

Epoch: 6| Step: 6
Training loss: 0.2896566390991211
Validation loss: 1.8949948350588481

Epoch: 6| Step: 7
Training loss: 0.3013848662376404
Validation loss: 1.8763761917750041

Epoch: 6| Step: 8
Training loss: 0.2078450471162796
Validation loss: 1.8612634142239888

Epoch: 6| Step: 9
Training loss: 0.6806085109710693
Validation loss: 1.8677701155344646

Epoch: 6| Step: 10
Training loss: 0.4468589425086975
Validation loss: 1.8651662468910217

Epoch: 6| Step: 11
Training loss: 0.1885640174150467
Validation loss: 1.7981107234954834

Epoch: 6| Step: 12
Training loss: 0.32641759514808655
Validation loss: 1.8510242700576782

Epoch: 6| Step: 13
Training loss: 0.4497346878051758
Validation loss: 1.8767095804214478

Epoch: 300| Step: 0
Training loss: 0.3253210783004761
Validation loss: 1.861525575319926

Epoch: 6| Step: 1
Training loss: 0.33652836084365845
Validation loss: 1.8568240404129028

Epoch: 6| Step: 2
Training loss: 0.1750638484954834
Validation loss: 1.891987641652425

Epoch: 6| Step: 3
Training loss: 0.182818204164505
Validation loss: 1.8455475370089214

Epoch: 6| Step: 4
Training loss: 0.21047881245613098
Validation loss: 1.8891691366831462

Epoch: 6| Step: 5
Training loss: 0.41966402530670166
Validation loss: 1.8627778887748718

Epoch: 6| Step: 6
Training loss: 0.3052188754081726
Validation loss: 1.8973714113235474

Epoch: 6| Step: 7
Training loss: 0.207269549369812
Validation loss: 1.8611233234405518

Epoch: 6| Step: 8
Training loss: 0.6552450656890869
Validation loss: 1.889773686726888

Epoch: 6| Step: 9
Training loss: 0.23235441744327545
Validation loss: 1.8338160713513691

Epoch: 6| Step: 10
Training loss: 0.22072654962539673
Validation loss: 1.879858672618866

Epoch: 6| Step: 11
Training loss: 0.2531614303588867
Validation loss: 1.8682847420374553

Epoch: 6| Step: 12
Training loss: 0.33666056394577026
Validation loss: 1.871619462966919

Epoch: 6| Step: 13
Training loss: 0.4951373040676117
Validation loss: 1.8173256317774455

Epoch: 301| Step: 0
Training loss: 0.670956552028656
Validation loss: 1.8632045984268188

Epoch: 6| Step: 1
Training loss: 0.5456854104995728
Validation loss: 1.880483329296112

Epoch: 6| Step: 2
Training loss: 0.2790650725364685
Validation loss: 1.9247941772143047

Epoch: 6| Step: 3
Training loss: 0.46995848417282104
Validation loss: 1.907034655412038

Epoch: 6| Step: 4
Training loss: 0.502754271030426
Validation loss: 1.8714536825815837

Epoch: 6| Step: 5
Training loss: 0.3176727890968323
Validation loss: 1.8776172598203023

Epoch: 6| Step: 6
Training loss: 0.21604269742965698
Validation loss: 1.9228990872701008

Epoch: 6| Step: 7
Training loss: 0.24674981832504272
Validation loss: 1.8995489478111267

Epoch: 6| Step: 8
Training loss: 0.3298325836658478
Validation loss: 1.8808411558469136

Epoch: 6| Step: 9
Training loss: 0.3472699522972107
Validation loss: 1.873494267463684

Epoch: 6| Step: 10
Training loss: 0.20654544234275818
Validation loss: 1.872334361076355

Epoch: 6| Step: 11
Training loss: 0.33895444869995117
Validation loss: 1.8862162629763286

Epoch: 6| Step: 12
Training loss: 0.3281458914279938
Validation loss: 1.8946531613667805

Epoch: 6| Step: 13
Training loss: 0.4126037359237671
Validation loss: 1.9086268345514934

Epoch: 302| Step: 0
Training loss: 0.20784014463424683
Validation loss: 1.8635359207789104

Epoch: 6| Step: 1
Training loss: 0.2613145112991333
Validation loss: 1.877108911673228

Epoch: 6| Step: 2
Training loss: 0.44934433698654175
Validation loss: 1.8901694814364116

Epoch: 6| Step: 3
Training loss: 0.33835265040397644
Validation loss: 1.8991887768109639

Epoch: 6| Step: 4
Training loss: 0.25793635845184326
Validation loss: 1.8856410185496013

Epoch: 6| Step: 5
Training loss: 0.3101043403148651
Validation loss: 1.8985261917114258

Epoch: 6| Step: 6
Training loss: 0.481000155210495
Validation loss: 1.8948161999384563

Epoch: 6| Step: 7
Training loss: 0.28428590297698975
Validation loss: 1.9076728820800781

Epoch: 6| Step: 8
Training loss: 0.5237082242965698
Validation loss: 1.8549089034398396

Epoch: 6| Step: 9
Training loss: 0.23399285972118378
Validation loss: 1.8586926857630413

Epoch: 6| Step: 10
Training loss: 0.35579773783683777
Validation loss: 1.8751859664916992

Epoch: 6| Step: 11
Training loss: 0.29466745257377625
Validation loss: 1.8585890928904216

Epoch: 6| Step: 12
Training loss: 0.34976574778556824
Validation loss: 1.869127372900645

Epoch: 6| Step: 13
Training loss: 0.8244282603263855
Validation loss: 1.8827409346898396

Epoch: 303| Step: 0
Training loss: 0.18757519125938416
Validation loss: 1.8316590189933777

Epoch: 6| Step: 1
Training loss: 0.261854887008667
Validation loss: 1.8479456901550293

Epoch: 6| Step: 2
Training loss: 0.35126981139183044
Validation loss: 1.843092640240987

Epoch: 6| Step: 3
Training loss: 0.18517611920833588
Validation loss: 1.8433989882469177

Epoch: 6| Step: 4
Training loss: 0.44242292642593384
Validation loss: 1.8391759594281514

Epoch: 6| Step: 5
Training loss: 0.3890495002269745
Validation loss: 1.8311686317125957

Epoch: 6| Step: 6
Training loss: 0.32091477513313293
Validation loss: 1.8298092285792034

Epoch: 6| Step: 7
Training loss: 0.5874754190444946
Validation loss: 1.8535357117652893

Epoch: 6| Step: 8
Training loss: 0.18848156929016113
Validation loss: 1.890688995520274

Epoch: 6| Step: 9
Training loss: 0.3722537159919739
Validation loss: 1.8553115924199421

Epoch: 6| Step: 10
Training loss: 0.39674293994903564
Validation loss: 1.8852909207344055

Epoch: 6| Step: 11
Training loss: 0.17361828684806824
Validation loss: 1.8416466116905212

Epoch: 6| Step: 12
Training loss: 0.7267448902130127
Validation loss: 1.921698808670044

Epoch: 6| Step: 13
Training loss: 0.20572037994861603
Validation loss: 1.8735231757164001

Epoch: 304| Step: 0
Training loss: 0.11760523915290833
Validation loss: 1.9385263919830322

Epoch: 6| Step: 1
Training loss: 0.5910567045211792
Validation loss: 1.8980043331782024

Epoch: 6| Step: 2
Training loss: 0.3381008505821228
Validation loss: 1.8905001680056255

Epoch: 6| Step: 3
Training loss: 0.42834559082984924
Validation loss: 1.8910688161849976

Epoch: 6| Step: 4
Training loss: 0.249325230717659
Validation loss: 1.8923193017641704

Epoch: 6| Step: 5
Training loss: 0.31365063786506653
Validation loss: 1.846764047940572

Epoch: 6| Step: 6
Training loss: 0.20828527212142944
Validation loss: 1.8694794376691182

Epoch: 6| Step: 7
Training loss: 0.31572723388671875
Validation loss: 1.8757110834121704

Epoch: 6| Step: 8
Training loss: 0.20485089719295502
Validation loss: 1.8397878011067708

Epoch: 6| Step: 9
Training loss: 0.2766681909561157
Validation loss: 1.893758734067281

Epoch: 6| Step: 10
Training loss: 0.16033929586410522
Validation loss: 1.86078941822052

Epoch: 6| Step: 11
Training loss: 0.4486384987831116
Validation loss: 1.9009376168251038

Epoch: 6| Step: 12
Training loss: 0.2878773808479309
Validation loss: 1.8502653042475383

Epoch: 6| Step: 13
Training loss: 0.4297669231891632
Validation loss: 1.874188522497813

Epoch: 305| Step: 0
Training loss: 0.2999887764453888
Validation loss: 1.8809600869814556

Epoch: 6| Step: 1
Training loss: 0.2300044149160385
Validation loss: 1.8494489789009094

Epoch: 6| Step: 2
Training loss: 0.22898343205451965
Validation loss: 1.8864678144454956

Epoch: 6| Step: 3
Training loss: 0.35612308979034424
Validation loss: 1.8724613984425862

Epoch: 6| Step: 4
Training loss: 0.5175721049308777
Validation loss: 1.869816243648529

Epoch: 6| Step: 5
Training loss: 0.37884798645973206
Validation loss: 1.8591022094090779

Epoch: 6| Step: 6
Training loss: 0.5461934804916382
Validation loss: 1.8357322414716084

Epoch: 6| Step: 7
Training loss: 0.6795017719268799
Validation loss: 1.840894083182017

Epoch: 6| Step: 8
Training loss: 0.15014222264289856
Validation loss: 1.869530737400055

Epoch: 6| Step: 9
Training loss: 0.3088664412498474
Validation loss: 1.8950145443280537

Epoch: 6| Step: 10
Training loss: 0.21883589029312134
Validation loss: 1.8777649799982707

Epoch: 6| Step: 11
Training loss: 0.26290395855903625
Validation loss: 1.871904194355011

Epoch: 6| Step: 12
Training loss: 0.13809537887573242
Validation loss: 1.891553779443105

Epoch: 6| Step: 13
Training loss: 0.2860007882118225
Validation loss: 1.8899222612380981

Epoch: 306| Step: 0
Training loss: 0.3095625340938568
Validation loss: 1.861799160639445

Epoch: 6| Step: 1
Training loss: 0.34836703538894653
Validation loss: 1.8890305161476135

Epoch: 6| Step: 2
Training loss: 0.3213350772857666
Validation loss: 1.8705248435338337

Epoch: 6| Step: 3
Training loss: 0.3404799997806549
Validation loss: 1.900314172108968

Epoch: 6| Step: 4
Training loss: 0.5495815873146057
Validation loss: 1.8606441617012024

Epoch: 6| Step: 5
Training loss: 0.32431548833847046
Validation loss: 1.8847851355870564

Epoch: 6| Step: 6
Training loss: 0.2766924500465393
Validation loss: 1.916215181350708

Epoch: 6| Step: 7
Training loss: 0.3890994191169739
Validation loss: 1.8782672484715779

Epoch: 6| Step: 8
Training loss: 0.16174820065498352
Validation loss: 1.8825307885805767

Epoch: 6| Step: 9
Training loss: 0.3695969581604004
Validation loss: 1.8893666466077168

Epoch: 6| Step: 10
Training loss: 0.23529867827892303
Validation loss: 1.886943022410075

Epoch: 6| Step: 11
Training loss: 0.29271265864372253
Validation loss: 1.8722342054049175

Epoch: 6| Step: 12
Training loss: 0.5754029750823975
Validation loss: 1.8654917279879253

Epoch: 6| Step: 13
Training loss: 0.2731274962425232
Validation loss: 1.8887771765391033

Epoch: 307| Step: 0
Training loss: 0.14219380915164948
Validation loss: 1.9045565327008565

Epoch: 6| Step: 1
Training loss: 0.37076765298843384
Validation loss: 1.9070223967234294

Epoch: 6| Step: 2
Training loss: 0.2225818634033203
Validation loss: 1.8886643846829732

Epoch: 6| Step: 3
Training loss: 0.21895509958267212
Validation loss: 1.8977207740147908

Epoch: 6| Step: 4
Training loss: 0.28201422095298767
Validation loss: 1.8842774828275044

Epoch: 6| Step: 5
Training loss: 0.2889457643032074
Validation loss: 1.8688463966051738

Epoch: 6| Step: 6
Training loss: 0.42493051290512085
Validation loss: 1.862319032351176

Epoch: 6| Step: 7
Training loss: 0.47592902183532715
Validation loss: 1.9059455196062725

Epoch: 6| Step: 8
Training loss: 0.19410312175750732
Validation loss: 1.8615097006162007

Epoch: 6| Step: 9
Training loss: 0.34858983755111694
Validation loss: 1.8871365984280903

Epoch: 6| Step: 10
Training loss: 0.6980758905410767
Validation loss: 1.8812381426493328

Epoch: 6| Step: 11
Training loss: 0.3341602683067322
Validation loss: 1.8769497871398926

Epoch: 6| Step: 12
Training loss: 0.34053218364715576
Validation loss: 1.8472482562065125

Epoch: 6| Step: 13
Training loss: 0.4889088273048401
Validation loss: 1.872649371623993

Epoch: 308| Step: 0
Training loss: 0.17081567645072937
Validation loss: 1.9091152548789978

Epoch: 6| Step: 1
Training loss: 0.2865009307861328
Validation loss: 1.8765764435132344

Epoch: 6| Step: 2
Training loss: 0.3139246106147766
Validation loss: 1.8729477723439534

Epoch: 6| Step: 3
Training loss: 0.415596067905426
Validation loss: 1.8489320476849873

Epoch: 6| Step: 4
Training loss: 0.610532283782959
Validation loss: 1.865858832995097

Epoch: 6| Step: 5
Training loss: 0.24879273772239685
Validation loss: 1.8580024441083272

Epoch: 6| Step: 6
Training loss: 0.25168389081954956
Validation loss: 1.8733020226160686

Epoch: 6| Step: 7
Training loss: 0.20044846832752228
Validation loss: 1.8899352153142293

Epoch: 6| Step: 8
Training loss: 0.19698932766914368
Validation loss: 1.859475274880727

Epoch: 6| Step: 9
Training loss: 0.44349533319473267
Validation loss: 1.8868921200434368

Epoch: 6| Step: 10
Training loss: 0.2505565285682678
Validation loss: 1.8770789702733357

Epoch: 6| Step: 11
Training loss: 0.3589126765727997
Validation loss: 1.8651915987332661

Epoch: 6| Step: 12
Training loss: 0.21259641647338867
Validation loss: 1.8350026806195576

Epoch: 6| Step: 13
Training loss: 0.6442282199859619
Validation loss: 1.878639777501424

Epoch: 309| Step: 0
Training loss: 0.29388099908828735
Validation loss: 1.8704707821210225

Epoch: 6| Step: 1
Training loss: 0.5711863040924072
Validation loss: 1.902816077073415

Epoch: 6| Step: 2
Training loss: 0.282464861869812
Validation loss: 1.873830219109853

Epoch: 6| Step: 3
Training loss: 0.2839895486831665
Validation loss: 1.873969296614329

Epoch: 6| Step: 4
Training loss: 0.30513083934783936
Validation loss: 1.878030240535736

Epoch: 6| Step: 5
Training loss: 0.5154110193252563
Validation loss: 1.876767635345459

Epoch: 6| Step: 6
Training loss: 0.2985336184501648
Validation loss: 1.9100271860758464

Epoch: 6| Step: 7
Training loss: 0.26495361328125
Validation loss: 1.879349668820699

Epoch: 6| Step: 8
Training loss: 0.21414928138256073
Validation loss: 1.9042301972707112

Epoch: 6| Step: 9
Training loss: 0.23180927336215973
Validation loss: 1.8832051157951355

Epoch: 6| Step: 10
Training loss: 0.2634926438331604
Validation loss: 1.911237359046936

Epoch: 6| Step: 11
Training loss: 0.7805803418159485
Validation loss: 1.8601277470588684

Epoch: 6| Step: 12
Training loss: 0.24031996726989746
Validation loss: 1.9157905379931133

Epoch: 6| Step: 13
Training loss: 0.24259710311889648
Validation loss: 1.8662377794583638

Epoch: 310| Step: 0
Training loss: 0.21382249891757965
Validation loss: 1.8610888123512268

Epoch: 6| Step: 1
Training loss: 0.19905488193035126
Validation loss: 1.858418305714925

Epoch: 6| Step: 2
Training loss: 0.45311659574508667
Validation loss: 1.833967924118042

Epoch: 6| Step: 3
Training loss: 0.24256587028503418
Validation loss: 1.8532922665278118

Epoch: 6| Step: 4
Training loss: 0.3107779920101166
Validation loss: 1.8826844890912373

Epoch: 6| Step: 5
Training loss: 0.34408584237098694
Validation loss: 1.8994417389233906

Epoch: 6| Step: 6
Training loss: 0.5970891714096069
Validation loss: 1.9219930171966553

Epoch: 6| Step: 7
Training loss: 0.3958778977394104
Validation loss: 1.8459444244702656

Epoch: 6| Step: 8
Training loss: 0.42155754566192627
Validation loss: 1.828671634197235

Epoch: 6| Step: 9
Training loss: 0.4245809018611908
Validation loss: 1.8799065748850505

Epoch: 6| Step: 10
Training loss: 0.49221736192703247
Validation loss: 1.8954961895942688

Epoch: 6| Step: 11
Training loss: 0.36022061109542847
Validation loss: 1.8828929265340169

Epoch: 6| Step: 12
Training loss: 0.2598457932472229
Validation loss: 1.8054815729459126

Epoch: 6| Step: 13
Training loss: 0.17778794467449188
Validation loss: 1.8820142547289531

Epoch: 311| Step: 0
Training loss: 0.42267924547195435
Validation loss: 1.9031424323717754

Epoch: 6| Step: 1
Training loss: 0.3711119592189789
Validation loss: 1.8994813561439514

Epoch: 6| Step: 2
Training loss: 0.3451199233531952
Validation loss: 1.8532094955444336

Epoch: 6| Step: 3
Training loss: 0.2782879173755646
Validation loss: 1.8767098188400269

Epoch: 6| Step: 4
Training loss: 0.4225040376186371
Validation loss: 1.8406711220741272

Epoch: 6| Step: 5
Training loss: 0.24037665128707886
Validation loss: 1.8686728080113728

Epoch: 6| Step: 6
Training loss: 0.14451727271080017
Validation loss: 1.8582258820533752

Epoch: 6| Step: 7
Training loss: 0.48110660910606384
Validation loss: 1.878594160079956

Epoch: 6| Step: 8
Training loss: 0.20385505259037018
Validation loss: 1.8961420853932698

Epoch: 6| Step: 9
Training loss: 0.17117491364479065
Validation loss: 1.8476058840751648

Epoch: 6| Step: 10
Training loss: 0.23769539594650269
Validation loss: 1.899543007214864

Epoch: 6| Step: 11
Training loss: 0.743654191493988
Validation loss: 1.8749448855717976

Epoch: 6| Step: 12
Training loss: 0.2619030177593231
Validation loss: 1.8955942193667095

Epoch: 6| Step: 13
Training loss: 0.14817580580711365
Validation loss: 1.8430418570836384

Epoch: 312| Step: 0
Training loss: 0.3927912712097168
Validation loss: 1.8820700248082478

Epoch: 6| Step: 1
Training loss: 0.37232863903045654
Validation loss: 1.9031443397204082

Epoch: 6| Step: 2
Training loss: 0.622227668762207
Validation loss: 1.8600305914878845

Epoch: 6| Step: 3
Training loss: 0.4009779095649719
Validation loss: 1.8377474745114644

Epoch: 6| Step: 4
Training loss: 0.23431041836738586
Validation loss: 1.8825374841690063

Epoch: 6| Step: 5
Training loss: 0.19090276956558228
Validation loss: 1.8960312604904175

Epoch: 6| Step: 6
Training loss: 0.21343836188316345
Validation loss: 1.8763950268427532

Epoch: 6| Step: 7
Training loss: 0.22630557417869568
Validation loss: 1.8661086161931355

Epoch: 6| Step: 8
Training loss: 0.27789539098739624
Validation loss: 1.883908708890279

Epoch: 6| Step: 9
Training loss: 0.2143213152885437
Validation loss: 1.8908369938532512

Epoch: 6| Step: 10
Training loss: 0.2602643668651581
Validation loss: 1.9231579701105754

Epoch: 6| Step: 11
Training loss: 0.28510403633117676
Validation loss: 1.87349929412206

Epoch: 6| Step: 12
Training loss: 0.4689866900444031
Validation loss: 1.8804400165875752

Epoch: 6| Step: 13
Training loss: 0.4109892249107361
Validation loss: 1.873221516609192

Epoch: 313| Step: 0
Training loss: 0.3217129707336426
Validation loss: 1.872675100962321

Epoch: 6| Step: 1
Training loss: 0.39521652460098267
Validation loss: 1.8677960832913716

Epoch: 6| Step: 2
Training loss: 0.7496248483657837
Validation loss: 1.889551043510437

Epoch: 6| Step: 3
Training loss: 0.31988775730133057
Validation loss: 1.838093340396881

Epoch: 6| Step: 4
Training loss: 0.23423580825328827
Validation loss: 1.8369079232215881

Epoch: 6| Step: 5
Training loss: 0.29832595586776733
Validation loss: 1.9134100675582886

Epoch: 6| Step: 6
Training loss: 0.4526822566986084
Validation loss: 1.8706209460894268

Epoch: 6| Step: 7
Training loss: 0.27644699811935425
Validation loss: 1.8495593468348186

Epoch: 6| Step: 8
Training loss: 0.17935502529144287
Validation loss: 1.8728362520535786

Epoch: 6| Step: 9
Training loss: 0.5039089918136597
Validation loss: 1.869689146677653

Epoch: 6| Step: 10
Training loss: 0.3470457196235657
Validation loss: 1.911735514799754

Epoch: 6| Step: 11
Training loss: 0.3128596842288971
Validation loss: 1.8414235909779866

Epoch: 6| Step: 12
Training loss: 0.417641818523407
Validation loss: 1.8612892031669617

Epoch: 6| Step: 13
Training loss: 0.27375733852386475
Validation loss: 1.8759549856185913

Epoch: 314| Step: 0
Training loss: 0.6226509213447571
Validation loss: 1.8623556693394978

Epoch: 6| Step: 1
Training loss: 0.2817023992538452
Validation loss: 1.8475295503934224

Epoch: 6| Step: 2
Training loss: 0.20549148321151733
Validation loss: 1.8791749477386475

Epoch: 6| Step: 3
Training loss: 0.15937887132167816
Validation loss: 1.9067317843437195

Epoch: 6| Step: 4
Training loss: 0.24132457375526428
Validation loss: 1.8686555624008179

Epoch: 6| Step: 5
Training loss: 0.2815042734146118
Validation loss: 1.8732967575391133

Epoch: 6| Step: 6
Training loss: 0.278648316860199
Validation loss: 1.859621524810791

Epoch: 6| Step: 7
Training loss: 0.2541971206665039
Validation loss: 1.8370565176010132

Epoch: 6| Step: 8
Training loss: 0.4435681998729706
Validation loss: 1.878323455651601

Epoch: 6| Step: 9
Training loss: 0.42309415340423584
Validation loss: 1.9090815385182698

Epoch: 6| Step: 10
Training loss: 0.27280503511428833
Validation loss: 1.8367193738619487

Epoch: 6| Step: 11
Training loss: 0.30850568413734436
Validation loss: 1.8754924337069194

Epoch: 6| Step: 12
Training loss: 0.38150227069854736
Validation loss: 1.893234650293986

Epoch: 6| Step: 13
Training loss: 0.22964423894882202
Validation loss: 1.9146465460459392

Epoch: 315| Step: 0
Training loss: 0.26804253458976746
Validation loss: 1.8679428299268086

Epoch: 6| Step: 1
Training loss: 0.5635628700256348
Validation loss: 1.8493055701255798

Epoch: 6| Step: 2
Training loss: 0.324881911277771
Validation loss: 1.8869501153628032

Epoch: 6| Step: 3
Training loss: 0.42806893587112427
Validation loss: 1.8753164807955425

Epoch: 6| Step: 4
Training loss: 0.2762717306613922
Validation loss: 1.9212169845898945

Epoch: 6| Step: 5
Training loss: 0.7510735988616943
Validation loss: 1.8704496423403423

Epoch: 6| Step: 6
Training loss: 0.2984973192214966
Validation loss: 1.9219065109888713

Epoch: 6| Step: 7
Training loss: 0.3509344756603241
Validation loss: 1.8790199756622314

Epoch: 6| Step: 8
Training loss: 0.3055458068847656
Validation loss: 1.8600093126296997

Epoch: 6| Step: 9
Training loss: 0.3086053431034088
Validation loss: 1.9060466090838115

Epoch: 6| Step: 10
Training loss: 0.30499541759490967
Validation loss: 1.8955539266268413

Epoch: 6| Step: 11
Training loss: 0.23907342553138733
Validation loss: 1.8691961367925007

Epoch: 6| Step: 12
Training loss: 0.2609248757362366
Validation loss: 1.8673014243443806

Epoch: 6| Step: 13
Training loss: 0.3219020962715149
Validation loss: 1.8770258625348408

Epoch: 316| Step: 0
Training loss: 0.40303874015808105
Validation loss: 1.878685454527537

Epoch: 6| Step: 1
Training loss: 0.3704214096069336
Validation loss: 1.917803446451823

Epoch: 6| Step: 2
Training loss: 0.425543874502182
Validation loss: 1.8665799101193745

Epoch: 6| Step: 3
Training loss: 0.24922220408916473
Validation loss: 1.880572517712911

Epoch: 6| Step: 4
Training loss: 0.29553866386413574
Validation loss: 1.8838215867678325

Epoch: 6| Step: 5
Training loss: 0.6387735605239868
Validation loss: 1.8460238774617512

Epoch: 6| Step: 6
Training loss: 0.4318923354148865
Validation loss: 1.8329726060231526

Epoch: 6| Step: 7
Training loss: 0.2588842213153839
Validation loss: 1.8634282350540161

Epoch: 6| Step: 8
Training loss: 0.29247769713401794
Validation loss: 1.870331088701884

Epoch: 6| Step: 9
Training loss: 0.2740546464920044
Validation loss: 1.8450219631195068

Epoch: 6| Step: 10
Training loss: 0.24676388502120972
Validation loss: 1.8729460040728252

Epoch: 6| Step: 11
Training loss: 0.20288361608982086
Validation loss: 1.8457558552424114

Epoch: 6| Step: 12
Training loss: 0.30924737453460693
Validation loss: 1.8718223770459492

Epoch: 6| Step: 13
Training loss: 0.35701870918273926
Validation loss: 1.8736979961395264

Epoch: 317| Step: 0
Training loss: 0.7524668574333191
Validation loss: 1.886669635772705

Epoch: 6| Step: 1
Training loss: 0.15341274440288544
Validation loss: 1.891817569732666

Epoch: 6| Step: 2
Training loss: 0.4583623707294464
Validation loss: 1.9003891348838806

Epoch: 6| Step: 3
Training loss: 0.32521411776542664
Validation loss: 1.8866737484931946

Epoch: 6| Step: 4
Training loss: 0.36272233724594116
Validation loss: 1.8628685077031453

Epoch: 6| Step: 5
Training loss: 0.24041077494621277
Validation loss: 1.8801659941673279

Epoch: 6| Step: 6
Training loss: 0.34416699409484863
Validation loss: 1.9212919473648071

Epoch: 6| Step: 7
Training loss: 0.2862621247768402
Validation loss: 1.9351534247398376

Epoch: 6| Step: 8
Training loss: 0.23154112696647644
Validation loss: 1.8719627261161804

Epoch: 6| Step: 9
Training loss: 0.32382217049598694
Validation loss: 1.9275872906049092

Epoch: 6| Step: 10
Training loss: 0.23708097636699677
Validation loss: 1.884326736132304

Epoch: 6| Step: 11
Training loss: 0.24326112866401672
Validation loss: 1.9342474142710369

Epoch: 6| Step: 12
Training loss: 0.2322891354560852
Validation loss: 1.8944487770398457

Epoch: 6| Step: 13
Training loss: 0.16046997904777527
Validation loss: 1.8542692462603252

Epoch: 318| Step: 0
Training loss: 0.3451341688632965
Validation loss: 1.8848195870717366

Epoch: 6| Step: 1
Training loss: 0.23216262459754944
Validation loss: 1.8428491751352947

Epoch: 6| Step: 2
Training loss: 0.25261616706848145
Validation loss: 1.9044722119967143

Epoch: 6| Step: 3
Training loss: 0.24570226669311523
Validation loss: 1.8580879370371501

Epoch: 6| Step: 4
Training loss: 0.8329766988754272
Validation loss: 1.8982835412025452

Epoch: 6| Step: 5
Training loss: 0.1990671008825302
Validation loss: 1.8998865286509197

Epoch: 6| Step: 6
Training loss: 0.29931744933128357
Validation loss: 1.8792847196261089

Epoch: 6| Step: 7
Training loss: 0.48687219619750977
Validation loss: 1.8622008164723713

Epoch: 6| Step: 8
Training loss: 0.3041456639766693
Validation loss: 1.864781419436137

Epoch: 6| Step: 9
Training loss: 0.3022249937057495
Validation loss: 1.843171238899231

Epoch: 6| Step: 10
Training loss: 0.4441107213497162
Validation loss: 1.862324337164561

Epoch: 6| Step: 11
Training loss: 0.16543640196323395
Validation loss: 1.8659298022588093

Epoch: 6| Step: 12
Training loss: 0.2295617312192917
Validation loss: 1.8644852836926777

Epoch: 6| Step: 13
Training loss: 0.2623223066329956
Validation loss: 1.874283254146576

Epoch: 319| Step: 0
Training loss: 0.24995002150535583
Validation loss: 1.868389070034027

Epoch: 6| Step: 1
Training loss: 0.3998556435108185
Validation loss: 1.8929419318834941

Epoch: 6| Step: 2
Training loss: 0.1684877574443817
Validation loss: 1.861342430114746

Epoch: 6| Step: 3
Training loss: 0.5081649422645569
Validation loss: 1.8658645153045654

Epoch: 6| Step: 4
Training loss: 0.2037455439567566
Validation loss: 1.8879867593447368

Epoch: 6| Step: 5
Training loss: 0.7624884843826294
Validation loss: 1.8356151978174846

Epoch: 6| Step: 6
Training loss: 0.20531721413135529
Validation loss: 1.8471808433532715

Epoch: 6| Step: 7
Training loss: 0.48555850982666016
Validation loss: 1.837956925233205

Epoch: 6| Step: 8
Training loss: 0.27348434925079346
Validation loss: 1.8649380405743916

Epoch: 6| Step: 9
Training loss: 0.24381577968597412
Validation loss: 1.8519718249638875

Epoch: 6| Step: 10
Training loss: 0.2584528923034668
Validation loss: 1.8858317534128826

Epoch: 6| Step: 11
Training loss: 0.3002772033214569
Validation loss: 1.8900457223256428

Epoch: 6| Step: 12
Training loss: 0.2377515435218811
Validation loss: 1.874369204044342

Epoch: 6| Step: 13
Training loss: 0.263672411441803
Validation loss: 1.8630926211675007

Epoch: 320| Step: 0
Training loss: 0.21629272401332855
Validation loss: 1.8813880681991577

Epoch: 6| Step: 1
Training loss: 0.159076526761055
Validation loss: 1.8717052141825359

Epoch: 6| Step: 2
Training loss: 0.20335638523101807
Validation loss: 1.8590242266654968

Epoch: 6| Step: 3
Training loss: 0.2001180350780487
Validation loss: 1.848409394423167

Epoch: 6| Step: 4
Training loss: 0.2998681664466858
Validation loss: 1.836613138516744

Epoch: 6| Step: 5
Training loss: 0.2648913264274597
Validation loss: 1.8616888125737507

Epoch: 6| Step: 6
Training loss: 0.42496904730796814
Validation loss: 1.8931371569633484

Epoch: 6| Step: 7
Training loss: 0.35008347034454346
Validation loss: 1.8463188012440999

Epoch: 6| Step: 8
Training loss: 0.5996633172035217
Validation loss: 1.842199405034383

Epoch: 6| Step: 9
Training loss: 0.5970276594161987
Validation loss: 1.854604184627533

Epoch: 6| Step: 10
Training loss: 0.2053447663784027
Validation loss: 1.8936781485875447

Epoch: 6| Step: 11
Training loss: 0.3984515070915222
Validation loss: 1.863364815711975

Epoch: 6| Step: 12
Training loss: 0.21390408277511597
Validation loss: 1.8838132222493489

Epoch: 6| Step: 13
Training loss: 0.24806617200374603
Validation loss: 1.8905938069025676

Epoch: 321| Step: 0
Training loss: 0.2872511148452759
Validation loss: 1.893809159596761

Epoch: 6| Step: 1
Training loss: 0.6653040647506714
Validation loss: 1.8528277079264324

Epoch: 6| Step: 2
Training loss: 0.21321821212768555
Validation loss: 1.9042957623799641

Epoch: 6| Step: 3
Training loss: 0.29628729820251465
Validation loss: 1.889462947845459

Epoch: 6| Step: 4
Training loss: 0.18709340691566467
Validation loss: 1.8932737509409587

Epoch: 6| Step: 5
Training loss: 0.40618449449539185
Validation loss: 1.8858523567517598

Epoch: 6| Step: 6
Training loss: 0.15354618430137634
Validation loss: 1.8870586355527241

Epoch: 6| Step: 7
Training loss: 0.32590728998184204
Validation loss: 1.91339244445165

Epoch: 6| Step: 8
Training loss: 0.43744513392448425
Validation loss: 1.8927856882413228

Epoch: 6| Step: 9
Training loss: 0.37553665041923523
Validation loss: 1.8862883647282918

Epoch: 6| Step: 10
Training loss: 0.24739684164524078
Validation loss: 1.915785809357961

Epoch: 6| Step: 11
Training loss: 0.33779412508010864
Validation loss: 1.8728137413660686

Epoch: 6| Step: 12
Training loss: 0.3323618769645691
Validation loss: 1.8993311325709026

Epoch: 6| Step: 13
Training loss: 0.39332157373428345
Validation loss: 1.8995917042096455

Epoch: 322| Step: 0
Training loss: 0.244723379611969
Validation loss: 1.8774235645929973

Epoch: 6| Step: 1
Training loss: 0.4368990361690521
Validation loss: 1.8698735237121582

Epoch: 6| Step: 2
Training loss: 0.32919397950172424
Validation loss: 1.896362026532491

Epoch: 6| Step: 3
Training loss: 0.32053709030151367
Validation loss: 1.8782267371813457

Epoch: 6| Step: 4
Training loss: 0.21596580743789673
Validation loss: 1.9006207585334778

Epoch: 6| Step: 5
Training loss: 0.226334810256958
Validation loss: 1.9037569363911946

Epoch: 6| Step: 6
Training loss: 0.19236646592617035
Validation loss: 1.8703674872716267

Epoch: 6| Step: 7
Training loss: 0.23006440699100494
Validation loss: 1.8664218386014302

Epoch: 6| Step: 8
Training loss: 0.20420938730239868
Validation loss: 1.9303563435872395

Epoch: 6| Step: 9
Training loss: 0.32955193519592285
Validation loss: 1.915394922097524

Epoch: 6| Step: 10
Training loss: 0.24792304635047913
Validation loss: 1.8573264877001445

Epoch: 6| Step: 11
Training loss: 0.1973997801542282
Validation loss: 1.932268460591634

Epoch: 6| Step: 12
Training loss: 0.5991257429122925
Validation loss: 1.882619599501292

Epoch: 6| Step: 13
Training loss: 0.5824093818664551
Validation loss: 1.8965581854184468

Epoch: 323| Step: 0
Training loss: 0.2366352081298828
Validation loss: 1.9160202542940776

Epoch: 6| Step: 1
Training loss: 0.6184430718421936
Validation loss: 1.8925387859344482

Epoch: 6| Step: 2
Training loss: 0.39935302734375
Validation loss: 1.9011926452318828

Epoch: 6| Step: 3
Training loss: 0.18927550315856934
Validation loss: 1.9412662188212078

Epoch: 6| Step: 4
Training loss: 0.21666240692138672
Validation loss: 1.8983647624651592

Epoch: 6| Step: 5
Training loss: 0.20683130621910095
Validation loss: 1.913117269674937

Epoch: 6| Step: 6
Training loss: 0.23599976301193237
Validation loss: 1.906374196211497

Epoch: 6| Step: 7
Training loss: 0.3205816149711609
Validation loss: 1.8963321447372437

Epoch: 6| Step: 8
Training loss: 0.6785318851470947
Validation loss: 1.8906567494074504

Epoch: 6| Step: 9
Training loss: 0.1718219667673111
Validation loss: 1.856857419013977

Epoch: 6| Step: 10
Training loss: 0.3447011709213257
Validation loss: 1.895990292231242

Epoch: 6| Step: 11
Training loss: 0.16668735444545746
Validation loss: 1.8758568167686462

Epoch: 6| Step: 12
Training loss: 0.16467733681201935
Validation loss: 1.8542923132578533

Epoch: 6| Step: 13
Training loss: 0.5134092569351196
Validation loss: 1.922881503899892

Epoch: 324| Step: 0
Training loss: 0.3361133933067322
Validation loss: 1.8773880004882812

Epoch: 6| Step: 1
Training loss: 0.19417676329612732
Validation loss: 1.8662343819936116

Epoch: 6| Step: 2
Training loss: 0.26339036226272583
Validation loss: 1.9097683032353718

Epoch: 6| Step: 3
Training loss: 0.16487613320350647
Validation loss: 1.906443218390147

Epoch: 6| Step: 4
Training loss: 0.28535062074661255
Validation loss: 1.886653999487559

Epoch: 6| Step: 5
Training loss: 0.22637619078159332
Validation loss: 1.887367069721222

Epoch: 6| Step: 6
Training loss: 0.18791545927524567
Validation loss: 1.882981816927592

Epoch: 6| Step: 7
Training loss: 0.28430357575416565
Validation loss: 1.8635161519050598

Epoch: 6| Step: 8
Training loss: 0.24785210192203522
Validation loss: 1.9085870782534282

Epoch: 6| Step: 9
Training loss: 0.38137951493263245
Validation loss: 1.8750744064648945

Epoch: 6| Step: 10
Training loss: 0.1852491796016693
Validation loss: 1.872912844022115

Epoch: 6| Step: 11
Training loss: 0.3369993567466736
Validation loss: 1.862625281016032

Epoch: 6| Step: 12
Training loss: 0.6091558933258057
Validation loss: 1.8477519353230794

Epoch: 6| Step: 13
Training loss: 0.3798573613166809
Validation loss: 1.8671814600626628

Epoch: 325| Step: 0
Training loss: 0.5937270522117615
Validation loss: 1.8923337856928508

Epoch: 6| Step: 1
Training loss: 0.3360373377799988
Validation loss: 1.8550682067871094

Epoch: 6| Step: 2
Training loss: 0.3054397702217102
Validation loss: 1.8892475167910259

Epoch: 6| Step: 3
Training loss: 0.32769060134887695
Validation loss: 1.8648188710212708

Epoch: 6| Step: 4
Training loss: 0.41183847188949585
Validation loss: 1.8942200144131978

Epoch: 6| Step: 5
Training loss: 0.27045655250549316
Validation loss: 1.8638868133227031

Epoch: 6| Step: 6
Training loss: 0.3934573233127594
Validation loss: 1.8765746156374614

Epoch: 6| Step: 7
Training loss: 0.24410086870193481
Validation loss: 1.8695804476737976

Epoch: 6| Step: 8
Training loss: 0.2501293420791626
Validation loss: 1.8637589414914448

Epoch: 6| Step: 9
Training loss: 0.21680758893489838
Validation loss: 1.8916984995206196

Epoch: 6| Step: 10
Training loss: 0.34923869371414185
Validation loss: 1.8837437232335408

Epoch: 6| Step: 11
Training loss: 0.2025386244058609
Validation loss: 1.8962934414545696

Epoch: 6| Step: 12
Training loss: 0.20863570272922516
Validation loss: 1.8498279253641765

Epoch: 6| Step: 13
Training loss: 0.3096083998680115
Validation loss: 1.8933254480361938

Epoch: 326| Step: 0
Training loss: 0.21232999861240387
Validation loss: 1.8968788981437683

Epoch: 6| Step: 1
Training loss: 0.28786295652389526
Validation loss: 1.8596428036689758

Epoch: 6| Step: 2
Training loss: 0.23572249710559845
Validation loss: 1.849954108397166

Epoch: 6| Step: 3
Training loss: 0.2842010259628296
Validation loss: 1.8913506865501404

Epoch: 6| Step: 4
Training loss: 0.2601011395454407
Validation loss: 1.869198242823283

Epoch: 6| Step: 5
Training loss: 0.36847251653671265
Validation loss: 1.9215600887934368

Epoch: 6| Step: 6
Training loss: 0.8539491891860962
Validation loss: 1.853653868039449

Epoch: 6| Step: 7
Training loss: 0.4019774794578552
Validation loss: 1.9163216551144917

Epoch: 6| Step: 8
Training loss: 0.3447878360748291
Validation loss: 1.8942781686782837

Epoch: 6| Step: 9
Training loss: 0.13732260465621948
Validation loss: 1.8564684589703877

Epoch: 6| Step: 10
Training loss: 0.2811275124549866
Validation loss: 1.863969624042511

Epoch: 6| Step: 11
Training loss: 0.3605279326438904
Validation loss: 1.8613457481066387

Epoch: 6| Step: 12
Training loss: 0.2534336745738983
Validation loss: 1.8990673025449116

Epoch: 6| Step: 13
Training loss: 0.27333545684814453
Validation loss: 1.8706836104393005

Epoch: 327| Step: 0
Training loss: 0.26584216952323914
Validation loss: 1.904399534066518

Epoch: 6| Step: 1
Training loss: 0.28918787837028503
Validation loss: 1.9117810726165771

Epoch: 6| Step: 2
Training loss: 0.20004428923130035
Validation loss: 1.8747239510218303

Epoch: 6| Step: 3
Training loss: 0.4792732894420624
Validation loss: 1.9423570036888123

Epoch: 6| Step: 4
Training loss: 0.3982614576816559
Validation loss: 1.9068829615910847

Epoch: 6| Step: 5
Training loss: 0.27175185084342957
Validation loss: 1.9096012115478516

Epoch: 6| Step: 6
Training loss: 0.28214719891548157
Validation loss: 1.9344101746877034

Epoch: 6| Step: 7
Training loss: 0.2723489999771118
Validation loss: 1.8731338779131572

Epoch: 6| Step: 8
Training loss: 0.2519000470638275
Validation loss: 1.864738921324412

Epoch: 6| Step: 9
Training loss: 0.38995158672332764
Validation loss: 1.8732235034306843

Epoch: 6| Step: 10
Training loss: 0.30024251341819763
Validation loss: 1.9228578805923462

Epoch: 6| Step: 11
Training loss: 0.30411213636398315
Validation loss: 1.8823623657226562

Epoch: 6| Step: 12
Training loss: 0.8441867828369141
Validation loss: 1.9082287748654683

Epoch: 6| Step: 13
Training loss: 0.484241783618927
Validation loss: 1.9284407297770183

Epoch: 328| Step: 0
Training loss: 0.3176824450492859
Validation loss: 1.8858379324277241

Epoch: 6| Step: 1
Training loss: 0.3884424567222595
Validation loss: 1.8502197066942851

Epoch: 6| Step: 2
Training loss: 0.18400099873542786
Validation loss: 1.9246817827224731

Epoch: 6| Step: 3
Training loss: 0.3098195791244507
Validation loss: 1.8686606685320537

Epoch: 6| Step: 4
Training loss: 0.2737051844596863
Validation loss: 1.9173904061317444

Epoch: 6| Step: 5
Training loss: 0.2630190849304199
Validation loss: 1.892723540465037

Epoch: 6| Step: 6
Training loss: 0.3510569930076599
Validation loss: 1.9192946751912434

Epoch: 6| Step: 7
Training loss: 0.2836156487464905
Validation loss: 1.8839982549349468

Epoch: 6| Step: 8
Training loss: 0.4739452302455902
Validation loss: 1.8938896656036377

Epoch: 6| Step: 9
Training loss: 0.6450396776199341
Validation loss: 1.869150996208191

Epoch: 6| Step: 10
Training loss: 0.2175799161195755
Validation loss: 1.9034918347994487

Epoch: 6| Step: 11
Training loss: 0.2283477932214737
Validation loss: 1.8829535444577534

Epoch: 6| Step: 12
Training loss: 0.20524531602859497
Validation loss: 1.8976343274116516

Epoch: 6| Step: 13
Training loss: 0.22765058279037476
Validation loss: 1.9024465481440227

Epoch: 329| Step: 0
Training loss: 0.18800924718379974
Validation loss: 1.85195392370224

Epoch: 6| Step: 1
Training loss: 0.5970188975334167
Validation loss: 1.863436261812846

Epoch: 6| Step: 2
Training loss: 0.2721307873725891
Validation loss: 1.9168418248494465

Epoch: 6| Step: 3
Training loss: 0.22212642431259155
Validation loss: 1.8679227232933044

Epoch: 6| Step: 4
Training loss: 0.32294103503227234
Validation loss: 1.8724455038706462

Epoch: 6| Step: 5
Training loss: 0.1531076729297638
Validation loss: 1.8908649881680806

Epoch: 6| Step: 6
Training loss: 0.5704014301300049
Validation loss: 1.8638221422831218

Epoch: 6| Step: 7
Training loss: 0.3812752962112427
Validation loss: 1.8538381457328796

Epoch: 6| Step: 8
Training loss: 0.15837743878364563
Validation loss: 1.9013630747795105

Epoch: 6| Step: 9
Training loss: 0.2539556622505188
Validation loss: 1.8734145959218342

Epoch: 6| Step: 10
Training loss: 0.28251636028289795
Validation loss: 1.8520374099413555

Epoch: 6| Step: 11
Training loss: 0.300909161567688
Validation loss: 1.8636032342910767

Epoch: 6| Step: 12
Training loss: 0.2321275770664215
Validation loss: 1.8965544700622559

Epoch: 6| Step: 13
Training loss: 0.2494627982378006
Validation loss: 1.8307083646456401

Epoch: 330| Step: 0
Training loss: 0.31699275970458984
Validation loss: 1.9118927319844563

Epoch: 6| Step: 1
Training loss: 0.36801284551620483
Validation loss: 1.849738339583079

Epoch: 6| Step: 2
Training loss: 0.27882951498031616
Validation loss: 1.856424907843272

Epoch: 6| Step: 3
Training loss: 0.20612457394599915
Validation loss: 1.873860518137614

Epoch: 6| Step: 4
Training loss: 0.24194322526454926
Validation loss: 1.881862958272298

Epoch: 6| Step: 5
Training loss: 0.47389110922813416
Validation loss: 1.8669827977816265

Epoch: 6| Step: 6
Training loss: 0.6457259654998779
Validation loss: 1.8910112182299297

Epoch: 6| Step: 7
Training loss: 0.21971598267555237
Validation loss: 1.8909237782160442

Epoch: 6| Step: 8
Training loss: 0.28904831409454346
Validation loss: 1.9273237983385723

Epoch: 6| Step: 9
Training loss: 0.2157776653766632
Validation loss: 1.8644125858942668

Epoch: 6| Step: 10
Training loss: 0.1515364795923233
Validation loss: 1.900829255580902

Epoch: 6| Step: 11
Training loss: 0.21581313014030457
Validation loss: 1.8871628642082214

Epoch: 6| Step: 12
Training loss: 0.3322566747665405
Validation loss: 1.878517786661784

Epoch: 6| Step: 13
Training loss: 0.23479819297790527
Validation loss: 1.899343232313792

Epoch: 331| Step: 0
Training loss: 0.36691001057624817
Validation loss: 1.9086538354555767

Epoch: 6| Step: 1
Training loss: 0.3383086025714874
Validation loss: 1.8618709047635396

Epoch: 6| Step: 2
Training loss: 0.2873229682445526
Validation loss: 1.8912399013837178

Epoch: 6| Step: 3
Training loss: 0.11950954049825668
Validation loss: 1.8859129548072815

Epoch: 6| Step: 4
Training loss: 0.31850332021713257
Validation loss: 1.8607009053230286

Epoch: 6| Step: 5
Training loss: 0.36854737997055054
Validation loss: 1.8770793676376343

Epoch: 6| Step: 6
Training loss: 0.2535587251186371
Validation loss: 1.8842541972796123

Epoch: 6| Step: 7
Training loss: 0.19501617550849915
Validation loss: 1.8900853594144185

Epoch: 6| Step: 8
Training loss: 0.2696719169616699
Validation loss: 1.874859611193339

Epoch: 6| Step: 9
Training loss: 0.3187832236289978
Validation loss: 1.8656990925470989

Epoch: 6| Step: 10
Training loss: 0.20900534093379974
Validation loss: 1.9183597962061565

Epoch: 6| Step: 11
Training loss: 0.4369814693927765
Validation loss: 1.9021218816439311

Epoch: 6| Step: 12
Training loss: 0.5932306051254272
Validation loss: 1.8727787534395854

Epoch: 6| Step: 13
Training loss: 0.2249857634305954
Validation loss: 1.8817339738210042

Epoch: 332| Step: 0
Training loss: 0.18943598866462708
Validation loss: 1.8985769550005596

Epoch: 6| Step: 1
Training loss: 0.4544212520122528
Validation loss: 1.856277346611023

Epoch: 6| Step: 2
Training loss: 0.2686002850532532
Validation loss: 1.8653740485509236

Epoch: 6| Step: 3
Training loss: 0.2624126970767975
Validation loss: 1.8899985154469807

Epoch: 6| Step: 4
Training loss: 0.588042676448822
Validation loss: 1.8836091955502827

Epoch: 6| Step: 5
Training loss: 0.430555522441864
Validation loss: 1.8925565878550212

Epoch: 6| Step: 6
Training loss: 0.2573612332344055
Validation loss: 1.8733424146970112

Epoch: 6| Step: 7
Training loss: 0.16058003902435303
Validation loss: 1.9133266806602478

Epoch: 6| Step: 8
Training loss: 0.41627371311187744
Validation loss: 1.870167891184489

Epoch: 6| Step: 9
Training loss: 0.24890945851802826
Validation loss: 1.9033430616060893

Epoch: 6| Step: 10
Training loss: 0.17235100269317627
Validation loss: 1.867619276046753

Epoch: 6| Step: 11
Training loss: 0.31510692834854126
Validation loss: 1.8787734707196553

Epoch: 6| Step: 12
Training loss: 0.16405612230300903
Validation loss: 1.8640168110529582

Epoch: 6| Step: 13
Training loss: 0.21697361767292023
Validation loss: 1.8638846278190613

Epoch: 333| Step: 0
Training loss: 0.3241042196750641
Validation loss: 1.873541275660197

Epoch: 6| Step: 1
Training loss: 0.34687697887420654
Validation loss: 1.8732412656148274

Epoch: 6| Step: 2
Training loss: 0.29245007038116455
Validation loss: 1.864327351252238

Epoch: 6| Step: 3
Training loss: 0.30703461170196533
Validation loss: 1.9095173478126526

Epoch: 6| Step: 4
Training loss: 0.302112340927124
Validation loss: 1.8779308795928955

Epoch: 6| Step: 5
Training loss: 0.3585294485092163
Validation loss: 1.8296154538790386

Epoch: 6| Step: 6
Training loss: 0.33028239011764526
Validation loss: 1.900458574295044

Epoch: 6| Step: 7
Training loss: 0.28540533781051636
Validation loss: 1.8806349833806355

Epoch: 6| Step: 8
Training loss: 0.2140609622001648
Validation loss: 1.8956664204597473

Epoch: 6| Step: 9
Training loss: 0.5482142567634583
Validation loss: 1.8678949475288391

Epoch: 6| Step: 10
Training loss: 0.32699862122535706
Validation loss: 1.887090007464091

Epoch: 6| Step: 11
Training loss: 0.29596713185310364
Validation loss: 1.891363501548767

Epoch: 6| Step: 12
Training loss: 0.18381235003471375
Validation loss: 1.8849952618281047

Epoch: 6| Step: 13
Training loss: 0.5923903584480286
Validation loss: 1.8570295174916585

Epoch: 334| Step: 0
Training loss: 0.28739702701568604
Validation loss: 1.8616709113121033

Epoch: 6| Step: 1
Training loss: 0.2550164759159088
Validation loss: 1.853677769502004

Epoch: 6| Step: 2
Training loss: 0.34135347604751587
Validation loss: 1.8940788904825847

Epoch: 6| Step: 3
Training loss: 0.18515950441360474
Validation loss: 1.910011351108551

Epoch: 6| Step: 4
Training loss: 0.19810856878757477
Validation loss: 1.8812984625498455

Epoch: 6| Step: 5
Training loss: 0.49231112003326416
Validation loss: 1.8481927315394084

Epoch: 6| Step: 6
Training loss: 0.3255220651626587
Validation loss: 1.899985134601593

Epoch: 6| Step: 7
Training loss: 0.2644806504249573
Validation loss: 1.8677761157353718

Epoch: 6| Step: 8
Training loss: 0.6833847165107727
Validation loss: 1.8986977537473042

Epoch: 6| Step: 9
Training loss: 0.3977383077144623
Validation loss: 1.9063454071680705

Epoch: 6| Step: 10
Training loss: 0.24901434779167175
Validation loss: 1.8651243448257446

Epoch: 6| Step: 11
Training loss: 0.22128325700759888
Validation loss: 1.86361159880956

Epoch: 6| Step: 12
Training loss: 0.22749312222003937
Validation loss: 1.919563392798106

Epoch: 6| Step: 13
Training loss: 0.23649296164512634
Validation loss: 1.875446617603302

Epoch: 335| Step: 0
Training loss: 0.35149121284484863
Validation loss: 1.9008331298828125

Epoch: 6| Step: 1
Training loss: 0.32684314250946045
Validation loss: 1.87813005844752

Epoch: 6| Step: 2
Training loss: 0.16639424860477448
Validation loss: 1.8751676281293232

Epoch: 6| Step: 3
Training loss: 0.21165576577186584
Validation loss: 1.9010000824928284

Epoch: 6| Step: 4
Training loss: 0.21199768781661987
Validation loss: 1.8245142896970112

Epoch: 6| Step: 5
Training loss: 0.26733070611953735
Validation loss: 1.9103150169054668

Epoch: 6| Step: 6
Training loss: 0.3282337188720703
Validation loss: 1.8855849901835124

Epoch: 6| Step: 7
Training loss: 0.2077374905347824
Validation loss: 1.884171485900879

Epoch: 6| Step: 8
Training loss: 0.33621299266815186
Validation loss: 1.9027257760365803

Epoch: 6| Step: 9
Training loss: 0.37510430812835693
Validation loss: 1.9048447211583455

Epoch: 6| Step: 10
Training loss: 0.2929149270057678
Validation loss: 1.926228106021881

Epoch: 6| Step: 11
Training loss: 0.5860283374786377
Validation loss: 1.8892021576563518

Epoch: 6| Step: 12
Training loss: 0.23626288771629333
Validation loss: 1.929724891980489

Epoch: 6| Step: 13
Training loss: 0.334155410528183
Validation loss: 1.8932146827379863

Epoch: 336| Step: 0
Training loss: 0.4829949736595154
Validation loss: 1.9010783831278484

Epoch: 6| Step: 1
Training loss: 0.24783286452293396
Validation loss: 1.8996475140253704

Epoch: 6| Step: 2
Training loss: 0.5711735486984253
Validation loss: 1.923634906609853

Epoch: 6| Step: 3
Training loss: 0.30655717849731445
Validation loss: 1.9115527272224426

Epoch: 6| Step: 4
Training loss: 0.32191401720046997
Validation loss: 1.8985605637232463

Epoch: 6| Step: 5
Training loss: 0.2361478954553604
Validation loss: 1.9084402124087017

Epoch: 6| Step: 6
Training loss: 0.33440637588500977
Validation loss: 1.8461592197418213

Epoch: 6| Step: 7
Training loss: 0.11361414194107056
Validation loss: 1.9334497054417927

Epoch: 6| Step: 8
Training loss: 0.17409227788448334
Validation loss: 1.875485082467397

Epoch: 6| Step: 9
Training loss: 0.17297086119651794
Validation loss: 1.9004955490430195

Epoch: 6| Step: 10
Training loss: 0.2979249060153961
Validation loss: 1.8689935008684795

Epoch: 6| Step: 11
Training loss: 0.2292153537273407
Validation loss: 1.9054784377415974

Epoch: 6| Step: 12
Training loss: 0.21799661219120026
Validation loss: 1.9117350578308105

Epoch: 6| Step: 13
Training loss: 0.6198277473449707
Validation loss: 1.91574631134669

Epoch: 337| Step: 0
Training loss: 0.16162998974323273
Validation loss: 1.8698817888895671

Epoch: 6| Step: 1
Training loss: 0.4556961953639984
Validation loss: 1.8693663676579793

Epoch: 6| Step: 2
Training loss: 0.19936488568782806
Validation loss: 1.8999854524930317

Epoch: 6| Step: 3
Training loss: 0.3050510883331299
Validation loss: 1.8984248836835225

Epoch: 6| Step: 4
Training loss: 0.7682948708534241
Validation loss: 1.8689365188280742

Epoch: 6| Step: 5
Training loss: 0.29406633973121643
Validation loss: 1.901101529598236

Epoch: 6| Step: 6
Training loss: 0.5969869494438171
Validation loss: 1.8543123205502827

Epoch: 6| Step: 7
Training loss: 0.26473909616470337
Validation loss: 1.9186211824417114

Epoch: 6| Step: 8
Training loss: 0.32415491342544556
Validation loss: 1.8708408276240032

Epoch: 6| Step: 9
Training loss: 0.2710690200328827
Validation loss: 1.8742686907450359

Epoch: 6| Step: 10
Training loss: 0.32378995418548584
Validation loss: 1.9081982572873433

Epoch: 6| Step: 11
Training loss: 0.30199897289276123
Validation loss: 1.9072764714558919

Epoch: 6| Step: 12
Training loss: 0.26939573884010315
Validation loss: 1.88404381275177

Epoch: 6| Step: 13
Training loss: 0.2303922325372696
Validation loss: 1.8610445261001587

Epoch: 338| Step: 0
Training loss: 0.3892786502838135
Validation loss: 1.8803887367248535

Epoch: 6| Step: 1
Training loss: 0.3887476325035095
Validation loss: 1.8326982657114665

Epoch: 6| Step: 2
Training loss: 0.2743287980556488
Validation loss: 1.87642502784729

Epoch: 6| Step: 3
Training loss: 0.22696001827716827
Validation loss: 1.877556045850118

Epoch: 6| Step: 4
Training loss: 0.2910231947898865
Validation loss: 1.8728390733400981

Epoch: 6| Step: 5
Training loss: 0.4581446945667267
Validation loss: 1.8940085768699646

Epoch: 6| Step: 6
Training loss: 0.5164021253585815
Validation loss: 1.8892585436503093

Epoch: 6| Step: 7
Training loss: 0.2668997347354889
Validation loss: 1.9104525049527485

Epoch: 6| Step: 8
Training loss: 0.28208816051483154
Validation loss: 1.9216705560684204

Epoch: 6| Step: 9
Training loss: 0.2693132162094116
Validation loss: 1.8544411460558574

Epoch: 6| Step: 10
Training loss: 0.17006489634513855
Validation loss: 1.889202078183492

Epoch: 6| Step: 11
Training loss: 0.19803404808044434
Validation loss: 1.894244412581126

Epoch: 6| Step: 12
Training loss: 0.7316595315933228
Validation loss: 1.8968016902605693

Epoch: 6| Step: 13
Training loss: 0.2730481028556824
Validation loss: 1.904858907063802

Epoch: 339| Step: 0
Training loss: 0.27446120977401733
Validation loss: 1.8412834008534749

Epoch: 6| Step: 1
Training loss: 0.2887871563434601
Validation loss: 1.8917823036511738

Epoch: 6| Step: 2
Training loss: 0.260714054107666
Validation loss: 1.8685827851295471

Epoch: 6| Step: 3
Training loss: 0.42326080799102783
Validation loss: 1.872773269812266

Epoch: 6| Step: 4
Training loss: 0.6764102578163147
Validation loss: 1.8787588079770405

Epoch: 6| Step: 5
Training loss: 0.5050267577171326
Validation loss: 1.879311482111613

Epoch: 6| Step: 6
Training loss: 0.4213074743747711
Validation loss: 1.8895541032155354

Epoch: 6| Step: 7
Training loss: 0.16898906230926514
Validation loss: 1.8970181743303935

Epoch: 6| Step: 8
Training loss: 0.3726867139339447
Validation loss: 1.8914928237597148

Epoch: 6| Step: 9
Training loss: 0.2417779564857483
Validation loss: 1.8610971172650654

Epoch: 6| Step: 10
Training loss: 0.11420176923274994
Validation loss: 1.879961609840393

Epoch: 6| Step: 11
Training loss: 0.2583966553211212
Validation loss: 1.8393850723902385

Epoch: 6| Step: 12
Training loss: 0.14931677281856537
Validation loss: 1.9102622469266255

Epoch: 6| Step: 13
Training loss: 0.24986548721790314
Validation loss: 1.8875180284182231

Epoch: 340| Step: 0
Training loss: 0.2094530463218689
Validation loss: 1.8948217233022053

Epoch: 6| Step: 1
Training loss: 0.3436241149902344
Validation loss: 1.8923575480779011

Epoch: 6| Step: 2
Training loss: 0.4054889678955078
Validation loss: 1.9083385666211445

Epoch: 6| Step: 3
Training loss: 0.1750536561012268
Validation loss: 1.8492964506149292

Epoch: 6| Step: 4
Training loss: 0.11845067143440247
Validation loss: 1.909310261408488

Epoch: 6| Step: 5
Training loss: 0.3293367028236389
Validation loss: 1.9076981743176777

Epoch: 6| Step: 6
Training loss: 0.25233185291290283
Validation loss: 1.905420998732249

Epoch: 6| Step: 7
Training loss: 0.6850788593292236
Validation loss: 1.9177979230880737

Epoch: 6| Step: 8
Training loss: 0.29704102873802185
Validation loss: 1.965213139851888

Epoch: 6| Step: 9
Training loss: 0.6269740462303162
Validation loss: 1.8581144213676453

Epoch: 6| Step: 10
Training loss: 0.33214133977890015
Validation loss: 1.9444430669148762

Epoch: 6| Step: 11
Training loss: 0.2184203863143921
Validation loss: 1.9106808702150981

Epoch: 6| Step: 12
Training loss: 0.1515556275844574
Validation loss: 1.8975715041160583

Epoch: 6| Step: 13
Training loss: 0.35469457507133484
Validation loss: 1.8829427361488342

Epoch: 341| Step: 0
Training loss: 0.4332861304283142
Validation loss: 1.9439704418182373

Epoch: 6| Step: 1
Training loss: 0.3669813573360443
Validation loss: 1.9133464694023132

Epoch: 6| Step: 2
Training loss: 0.3115484118461609
Validation loss: 1.874286373456319

Epoch: 6| Step: 3
Training loss: 0.28034597635269165
Validation loss: 1.9050462643305461

Epoch: 6| Step: 4
Training loss: 0.21170344948768616
Validation loss: 1.9452508091926575

Epoch: 6| Step: 5
Training loss: 0.30531638860702515
Validation loss: 1.8649369478225708

Epoch: 6| Step: 6
Training loss: 0.19382968544960022
Validation loss: 1.8473499218622844

Epoch: 6| Step: 7
Training loss: 0.5205384492874146
Validation loss: 1.8733897010485332

Epoch: 6| Step: 8
Training loss: 0.2660396099090576
Validation loss: 1.937180995941162

Epoch: 6| Step: 9
Training loss: 0.2879544198513031
Validation loss: 1.9268272519111633

Epoch: 6| Step: 10
Training loss: 0.3437381982803345
Validation loss: 1.8699411551157634

Epoch: 6| Step: 11
Training loss: 0.23107147216796875
Validation loss: 1.9057822426160176

Epoch: 6| Step: 12
Training loss: 0.6080101728439331
Validation loss: 1.8866934180259705

Epoch: 6| Step: 13
Training loss: 0.2921924591064453
Validation loss: 1.891847272713979

Epoch: 342| Step: 0
Training loss: 0.27327901124954224
Validation loss: 1.896584153175354

Epoch: 6| Step: 1
Training loss: 0.3209831416606903
Validation loss: 1.894393543402354

Epoch: 6| Step: 2
Training loss: 0.27130943536758423
Validation loss: 1.8510454893112183

Epoch: 6| Step: 3
Training loss: 0.32050201296806335
Validation loss: 1.8617923458417256

Epoch: 6| Step: 4
Training loss: 0.31245678663253784
Validation loss: 1.895556926727295

Epoch: 6| Step: 5
Training loss: 0.20984727144241333
Validation loss: 1.8892547686894734

Epoch: 6| Step: 6
Training loss: 0.1595577746629715
Validation loss: 1.8981316884358723

Epoch: 6| Step: 7
Training loss: 0.2560443878173828
Validation loss: 1.8716286619504292

Epoch: 6| Step: 8
Training loss: 0.2883220314979553
Validation loss: 1.9145946105321248

Epoch: 6| Step: 9
Training loss: 0.307250052690506
Validation loss: 1.9176682035128276

Epoch: 6| Step: 10
Training loss: 0.6505962610244751
Validation loss: 1.8696594834327698

Epoch: 6| Step: 11
Training loss: 0.27540236711502075
Validation loss: 1.871921141942342

Epoch: 6| Step: 12
Training loss: 0.22631439566612244
Validation loss: 1.871578335762024

Epoch: 6| Step: 13
Training loss: 0.30594193935394287
Validation loss: 1.8734547694524128

Epoch: 343| Step: 0
Training loss: 0.538529098033905
Validation loss: 1.8933468063672383

Epoch: 6| Step: 1
Training loss: 0.19423219561576843
Validation loss: 1.8460773626963298

Epoch: 6| Step: 2
Training loss: 0.15440621972084045
Validation loss: 1.893613040447235

Epoch: 6| Step: 3
Training loss: 0.17090383172035217
Validation loss: 1.8900226354599

Epoch: 6| Step: 4
Training loss: 0.24386756122112274
Validation loss: 1.8828351497650146

Epoch: 6| Step: 5
Training loss: 0.3834965229034424
Validation loss: 1.8660833636919658

Epoch: 6| Step: 6
Training loss: 0.2266356348991394
Validation loss: 1.8737698197364807

Epoch: 6| Step: 7
Training loss: 0.2740800380706787
Validation loss: 1.9021706183751423

Epoch: 6| Step: 8
Training loss: 0.1980305016040802
Validation loss: 1.885653018951416

Epoch: 6| Step: 9
Training loss: 0.31896400451660156
Validation loss: 1.854279379049937

Epoch: 6| Step: 10
Training loss: 0.36739349365234375
Validation loss: 1.8435542384783428

Epoch: 6| Step: 11
Training loss: 0.26441341638565063
Validation loss: 1.8568786183993022

Epoch: 6| Step: 12
Training loss: 0.21174785494804382
Validation loss: 1.8965812126795452

Epoch: 6| Step: 13
Training loss: 0.6219006776809692
Validation loss: 1.89360515276591

Epoch: 344| Step: 0
Training loss: 0.29396966099739075
Validation loss: 1.8858468731244404

Epoch: 6| Step: 1
Training loss: 0.3071635365486145
Validation loss: 1.8815341393152873

Epoch: 6| Step: 2
Training loss: 0.31874513626098633
Validation loss: 1.8654752771059673

Epoch: 6| Step: 3
Training loss: 0.4848478138446808
Validation loss: 1.8870614767074585

Epoch: 6| Step: 4
Training loss: 0.2583969831466675
Validation loss: 1.8760754267374675

Epoch: 6| Step: 5
Training loss: 0.29660743474960327
Validation loss: 1.8640661636988323

Epoch: 6| Step: 6
Training loss: 0.23013050854206085
Validation loss: 1.8879696528116863

Epoch: 6| Step: 7
Training loss: 0.258703351020813
Validation loss: 1.8476997812589009

Epoch: 6| Step: 8
Training loss: 0.22575072944164276
Validation loss: 1.921165406703949

Epoch: 6| Step: 9
Training loss: 0.1848176121711731
Validation loss: 1.8940210938453674

Epoch: 6| Step: 10
Training loss: 0.6688672304153442
Validation loss: 1.898225466410319

Epoch: 6| Step: 11
Training loss: 0.1819828748703003
Validation loss: 1.8741361498832703

Epoch: 6| Step: 12
Training loss: 0.465072900056839
Validation loss: 1.8804205854733784

Epoch: 6| Step: 13
Training loss: 0.26371443271636963
Validation loss: 1.9089618921279907

Epoch: 345| Step: 0
Training loss: 0.36644595861434937
Validation loss: 1.8580725193023682

Epoch: 6| Step: 1
Training loss: 0.3528223931789398
Validation loss: 1.8972824414571126

Epoch: 6| Step: 2
Training loss: 0.3198533058166504
Validation loss: 1.916899065176646

Epoch: 6| Step: 3
Training loss: 0.18078838288784027
Validation loss: 1.8724105556805928

Epoch: 6| Step: 4
Training loss: 0.2309996336698532
Validation loss: 1.847314139207204

Epoch: 6| Step: 5
Training loss: 0.24788424372673035
Validation loss: 1.8942230741182964

Epoch: 6| Step: 6
Training loss: 0.3661947548389435
Validation loss: 1.821536123752594

Epoch: 6| Step: 7
Training loss: 0.1934676170349121
Validation loss: 1.890198012193044

Epoch: 6| Step: 8
Training loss: 0.23493073880672455
Validation loss: 1.8814731637636821

Epoch: 6| Step: 9
Training loss: 0.5972676873207092
Validation loss: 1.8872366746266682

Epoch: 6| Step: 10
Training loss: 0.17739804089069366
Validation loss: 1.8468033075332642

Epoch: 6| Step: 11
Training loss: 0.3197001814842224
Validation loss: 1.870406488577525

Epoch: 6| Step: 12
Training loss: 0.19264253973960876
Validation loss: 1.8772602876027424

Epoch: 6| Step: 13
Training loss: 0.37448474764823914
Validation loss: 1.8856927553812664

Epoch: 346| Step: 0
Training loss: 0.21189428865909576
Validation loss: 1.8879394332567851

Epoch: 6| Step: 1
Training loss: 0.2440241575241089
Validation loss: 1.85776283343633

Epoch: 6| Step: 2
Training loss: 0.22581776976585388
Validation loss: 1.878754695256551

Epoch: 6| Step: 3
Training loss: 0.46566808223724365
Validation loss: 1.866185486316681

Epoch: 6| Step: 4
Training loss: 0.15585508942604065
Validation loss: 1.8636988600095112

Epoch: 6| Step: 5
Training loss: 0.3632127046585083
Validation loss: 1.858774761358897

Epoch: 6| Step: 6
Training loss: 0.2426861822605133
Validation loss: 1.903284211953481

Epoch: 6| Step: 7
Training loss: 0.2949046790599823
Validation loss: 1.8693840503692627

Epoch: 6| Step: 8
Training loss: 0.3948603868484497
Validation loss: 1.8654553294181824

Epoch: 6| Step: 9
Training loss: 0.20032508671283722
Validation loss: 1.846730351448059

Epoch: 6| Step: 10
Training loss: 0.21309682726860046
Validation loss: 1.8731390436490376

Epoch: 6| Step: 11
Training loss: 0.1478291153907776
Validation loss: 1.822704056898753

Epoch: 6| Step: 12
Training loss: 0.28194522857666016
Validation loss: 1.8817271987597148

Epoch: 6| Step: 13
Training loss: 0.7706219553947449
Validation loss: 1.8205114205678303

Epoch: 347| Step: 0
Training loss: 0.23087511956691742
Validation loss: 1.8460529049237568

Epoch: 6| Step: 1
Training loss: 0.2479742169380188
Validation loss: 1.8804381092389424

Epoch: 6| Step: 2
Training loss: 0.8079943656921387
Validation loss: 1.8590494592984517

Epoch: 6| Step: 3
Training loss: 0.3657280206680298
Validation loss: 1.8996935486793518

Epoch: 6| Step: 4
Training loss: 0.2785356044769287
Validation loss: 1.8503689765930176

Epoch: 6| Step: 5
Training loss: 0.4430001974105835
Validation loss: 1.8835823933283489

Epoch: 6| Step: 6
Training loss: 0.3108019232749939
Validation loss: 1.8647528688112895

Epoch: 6| Step: 7
Training loss: 0.1510952264070511
Validation loss: 1.9212215344111125

Epoch: 6| Step: 8
Training loss: 0.2544514238834381
Validation loss: 1.9041046897570293

Epoch: 6| Step: 9
Training loss: 0.30703631043434143
Validation loss: 1.8764491478602092

Epoch: 6| Step: 10
Training loss: 0.5013453960418701
Validation loss: 1.8829812208811443

Epoch: 6| Step: 11
Training loss: 0.1556948870420456
Validation loss: 1.8493322531382244

Epoch: 6| Step: 12
Training loss: 0.219210684299469
Validation loss: 1.83554474512736

Epoch: 6| Step: 13
Training loss: 0.1668536365032196
Validation loss: 1.8920094966888428

Epoch: 348| Step: 0
Training loss: 0.2787328362464905
Validation loss: 1.8619957566261292

Epoch: 6| Step: 1
Training loss: 0.20778459310531616
Validation loss: 1.8849817117055256

Epoch: 6| Step: 2
Training loss: 0.487033873796463
Validation loss: 1.8710381189982097

Epoch: 6| Step: 3
Training loss: 0.360196590423584
Validation loss: 1.889812449614207

Epoch: 6| Step: 4
Training loss: 0.2407130002975464
Validation loss: 1.8348088264465332

Epoch: 6| Step: 5
Training loss: 0.20967572927474976
Validation loss: 1.8736585974693298

Epoch: 6| Step: 6
Training loss: 0.27490735054016113
Validation loss: 1.8780691425005596

Epoch: 6| Step: 7
Training loss: 0.23647388815879822
Validation loss: 1.852607548236847

Epoch: 6| Step: 8
Training loss: 0.2317919135093689
Validation loss: 1.8492451310157776

Epoch: 6| Step: 9
Training loss: 0.6294634342193604
Validation loss: 1.9044412175814311

Epoch: 6| Step: 10
Training loss: 0.3885916769504547
Validation loss: 1.868962585926056

Epoch: 6| Step: 11
Training loss: 0.2702667713165283
Validation loss: 1.859139343102773

Epoch: 6| Step: 12
Training loss: 0.23088474571704865
Validation loss: 1.8397424221038818

Epoch: 6| Step: 13
Training loss: 0.16071972250938416
Validation loss: 1.845578670501709

Epoch: 349| Step: 0
Training loss: 0.25859424471855164
Validation loss: 1.887658178806305

Epoch: 6| Step: 1
Training loss: 0.28611722588539124
Validation loss: 1.8660987416903179

Epoch: 6| Step: 2
Training loss: 0.19560585916042328
Validation loss: 1.8781194885571797

Epoch: 6| Step: 3
Training loss: 0.2600153982639313
Validation loss: 1.8915863037109375

Epoch: 6| Step: 4
Training loss: 0.23462021350860596
Validation loss: 1.912169635295868

Epoch: 6| Step: 5
Training loss: 0.18158793449401855
Validation loss: 1.8848681052525837

Epoch: 6| Step: 6
Training loss: 0.6309934258460999
Validation loss: 1.8617016474405925

Epoch: 6| Step: 7
Training loss: 0.19466689229011536
Validation loss: 1.8893564343452454

Epoch: 6| Step: 8
Training loss: 0.32554587721824646
Validation loss: 1.8589599132537842

Epoch: 6| Step: 9
Training loss: 0.3161256015300751
Validation loss: 1.85489155848821

Epoch: 6| Step: 10
Training loss: 0.3592010736465454
Validation loss: 1.851955731709798

Epoch: 6| Step: 11
Training loss: 0.24456168711185455
Validation loss: 1.8654507398605347

Epoch: 6| Step: 12
Training loss: 0.3788027763366699
Validation loss: 1.8916874726613362

Epoch: 6| Step: 13
Training loss: 0.22354577481746674
Validation loss: 1.853294312953949

Epoch: 350| Step: 0
Training loss: 0.3262144923210144
Validation loss: 1.9025542934735615

Epoch: 6| Step: 1
Training loss: 0.41829532384872437
Validation loss: 1.9159513711929321

Epoch: 6| Step: 2
Training loss: 0.3593674302101135
Validation loss: 1.8686802585919697

Epoch: 6| Step: 3
Training loss: 0.1828392595052719
Validation loss: 1.8851328094800313

Epoch: 6| Step: 4
Training loss: 0.17346391081809998
Validation loss: 1.8945118983586628

Epoch: 6| Step: 5
Training loss: 0.20439013838768005
Validation loss: 1.8482338388760884

Epoch: 6| Step: 6
Training loss: 0.2366122156381607
Validation loss: 1.861544907093048

Epoch: 6| Step: 7
Training loss: 0.22276422381401062
Validation loss: 1.85500172773997

Epoch: 6| Step: 8
Training loss: 0.28754615783691406
Validation loss: 1.8644595344861348

Epoch: 6| Step: 9
Training loss: 0.7921755313873291
Validation loss: 1.8489570617675781

Epoch: 6| Step: 10
Training loss: 0.14618968963623047
Validation loss: 1.8873284061749775

Epoch: 6| Step: 11
Training loss: 0.370252400636673
Validation loss: 1.8502095341682434

Epoch: 6| Step: 12
Training loss: 0.2382136583328247
Validation loss: 1.8755480448404949

Epoch: 6| Step: 13
Training loss: 0.29373490810394287
Validation loss: 1.8532769481341045

Testing loss: 1.946224586569148
