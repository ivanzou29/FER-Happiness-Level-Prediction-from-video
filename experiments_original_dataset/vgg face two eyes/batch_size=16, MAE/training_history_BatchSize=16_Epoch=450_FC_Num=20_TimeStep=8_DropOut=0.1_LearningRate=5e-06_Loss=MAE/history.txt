Epoch: 1| Step: 0
Training loss: 6.349464416503906
Validation loss: 6.8801149527231855

Epoch: 6| Step: 1
Training loss: 7.096500396728516
Validation loss: 6.8520974318186445

Epoch: 6| Step: 2
Training loss: 6.243285179138184
Validation loss: 6.823506037394206

Epoch: 6| Step: 3
Training loss: 6.188014984130859
Validation loss: 6.796646038691203

Epoch: 6| Step: 4
Training loss: 6.4770097732543945
Validation loss: 6.76870059967041

Epoch: 6| Step: 5
Training loss: 6.359753608703613
Validation loss: 6.745226303736369

Epoch: 6| Step: 6
Training loss: 7.3620195388793945
Validation loss: 6.719866911570231

Epoch: 6| Step: 7
Training loss: 7.0683674812316895
Validation loss: 6.688896179199219

Epoch: 6| Step: 8
Training loss: 7.6464738845825195
Validation loss: 6.665456295013428

Epoch: 6| Step: 9
Training loss: 7.178564071655273
Validation loss: 6.637579282124837

Epoch: 6| Step: 10
Training loss: 7.955384254455566
Validation loss: 6.612566312154134

Epoch: 6| Step: 11
Training loss: 6.4956183433532715
Validation loss: 6.5850755373636884

Epoch: 6| Step: 12
Training loss: 6.595178604125977
Validation loss: 6.556858619054158

Epoch: 6| Step: 13
Training loss: 5.831315994262695
Validation loss: 6.52814785639445

Epoch: 2| Step: 0
Training loss: 6.028334140777588
Validation loss: 6.497872511545817

Epoch: 6| Step: 1
Training loss: 7.185953140258789
Validation loss: 6.4698976675669355

Epoch: 6| Step: 2
Training loss: 6.543937683105469
Validation loss: 6.435949484507243

Epoch: 6| Step: 3
Training loss: 6.982814788818359
Validation loss: 6.40789810816447

Epoch: 6| Step: 4
Training loss: 5.165457725524902
Validation loss: 6.371065457661946

Epoch: 6| Step: 5
Training loss: 6.0279436111450195
Validation loss: 6.337193409601848

Epoch: 6| Step: 6
Training loss: 6.621570110321045
Validation loss: 6.301763614018758

Epoch: 6| Step: 7
Training loss: 5.942137718200684
Validation loss: 6.266104618708293

Epoch: 6| Step: 8
Training loss: 6.841312885284424
Validation loss: 6.225796937942505

Epoch: 6| Step: 9
Training loss: 5.4007039070129395
Validation loss: 6.193375825881958

Epoch: 6| Step: 10
Training loss: 6.558950901031494
Validation loss: 6.1503086884816485

Epoch: 6| Step: 11
Training loss: 6.732966899871826
Validation loss: 6.1098094781239825

Epoch: 6| Step: 12
Training loss: 5.846140384674072
Validation loss: 6.067076524098714

Epoch: 6| Step: 13
Training loss: 6.883461952209473
Validation loss: 6.021855274836223

Epoch: 3| Step: 0
Training loss: 6.111967086791992
Validation loss: 5.9754641850789385

Epoch: 6| Step: 1
Training loss: 6.204169273376465
Validation loss: 5.928011814753215

Epoch: 6| Step: 2
Training loss: 6.512578964233398
Validation loss: 5.876670201619466

Epoch: 6| Step: 3
Training loss: 5.914308547973633
Validation loss: 5.824895143508911

Epoch: 6| Step: 4
Training loss: 5.800941467285156
Validation loss: 5.769797245661418

Epoch: 6| Step: 5
Training loss: 5.098503589630127
Validation loss: 5.714615186055501

Epoch: 6| Step: 6
Training loss: 6.342388153076172
Validation loss: 5.651524384816487

Epoch: 6| Step: 7
Training loss: 5.7537841796875
Validation loss: 5.595431963602702

Epoch: 6| Step: 8
Training loss: 5.509243965148926
Validation loss: 5.5296071370442705

Epoch: 6| Step: 9
Training loss: 5.975131034851074
Validation loss: 5.470194657643636

Epoch: 6| Step: 10
Training loss: 5.93426513671875
Validation loss: 5.399094978968303

Epoch: 6| Step: 11
Training loss: 5.252777099609375
Validation loss: 5.324425061543782

Epoch: 6| Step: 12
Training loss: 3.48797607421875
Validation loss: 5.249135653177897

Epoch: 6| Step: 13
Training loss: 5.483710289001465
Validation loss: 5.173577547073364

Epoch: 4| Step: 0
Training loss: 5.194324493408203
Validation loss: 5.093573133150737

Epoch: 6| Step: 1
Training loss: 3.8148303031921387
Validation loss: 5.002376000086467

Epoch: 6| Step: 2
Training loss: 4.567236423492432
Validation loss: 4.915601174036662

Epoch: 6| Step: 3
Training loss: 5.124337196350098
Validation loss: 4.828962127367656

Epoch: 6| Step: 4
Training loss: 4.491379261016846
Validation loss: 4.721971035003662

Epoch: 6| Step: 5
Training loss: 5.124143600463867
Validation loss: 4.627294460932414

Epoch: 6| Step: 6
Training loss: 5.027610778808594
Validation loss: 4.52610429128011

Epoch: 6| Step: 7
Training loss: 4.74476432800293
Validation loss: 4.4023863474528

Epoch: 6| Step: 8
Training loss: 4.599198341369629
Validation loss: 4.28165070215861

Epoch: 6| Step: 9
Training loss: 4.502159118652344
Validation loss: 4.160482009251912

Epoch: 6| Step: 10
Training loss: 2.9930858612060547
Validation loss: 4.037788510322571

Epoch: 6| Step: 11
Training loss: 3.5674092769622803
Validation loss: 3.915035843849182

Epoch: 6| Step: 12
Training loss: 4.065155029296875
Validation loss: 3.778462847073873

Epoch: 6| Step: 13
Training loss: 4.756447792053223
Validation loss: 3.6717233657836914

Epoch: 5| Step: 0
Training loss: 3.1356961727142334
Validation loss: 3.550609588623047

Epoch: 6| Step: 1
Training loss: 3.2009220123291016
Validation loss: 3.4015180667241416

Epoch: 6| Step: 2
Training loss: 3.1378884315490723
Validation loss: 3.285745859146118

Epoch: 6| Step: 3
Training loss: 2.8354814052581787
Validation loss: 3.1655978759129844

Epoch: 6| Step: 4
Training loss: 2.9185070991516113
Validation loss: 3.0475152730941772

Epoch: 6| Step: 5
Training loss: 3.0720696449279785
Validation loss: 2.927975058555603

Epoch: 6| Step: 6
Training loss: 3.5355429649353027
Validation loss: 2.784204045931498

Epoch: 6| Step: 7
Training loss: 2.8969321250915527
Validation loss: 2.6503925720850625

Epoch: 6| Step: 8
Training loss: 2.477729082107544
Validation loss: 2.5649195512135825

Epoch: 6| Step: 9
Training loss: 2.4018068313598633
Validation loss: 2.498798668384552

Epoch: 6| Step: 10
Training loss: 2.5309624671936035
Validation loss: 2.40667454401652

Epoch: 6| Step: 11
Training loss: 2.362875461578369
Validation loss: 2.3327152530352273

Epoch: 6| Step: 12
Training loss: 2.3157670497894287
Validation loss: 2.2946616808573403

Epoch: 6| Step: 13
Training loss: 2.8984758853912354
Validation loss: 2.293883184591929

Epoch: 6| Step: 0
Training loss: 3.488295793533325
Validation loss: 2.2774189114570618

Epoch: 6| Step: 1
Training loss: 2.092060089111328
Validation loss: 2.305286467075348

Epoch: 6| Step: 2
Training loss: 2.785151243209839
Validation loss: 2.3239685893058777

Epoch: 6| Step: 3
Training loss: 1.9260281324386597
Validation loss: 2.315047303835551

Epoch: 6| Step: 4
Training loss: 2.351557970046997
Validation loss: 2.342104117075602

Epoch: 6| Step: 5
Training loss: 2.3057861328125
Validation loss: 2.3283850948015847

Epoch: 6| Step: 6
Training loss: 2.7350120544433594
Validation loss: 2.3229130705197654

Epoch: 6| Step: 7
Training loss: 2.365649700164795
Validation loss: 2.323487162590027

Epoch: 6| Step: 8
Training loss: 2.3708302974700928
Validation loss: 2.254891117413839

Epoch: 6| Step: 9
Training loss: 2.9038443565368652
Validation loss: 2.288471500078837

Epoch: 6| Step: 10
Training loss: 2.116182327270508
Validation loss: 2.2714640696843467

Epoch: 6| Step: 11
Training loss: 2.666652202606201
Validation loss: 2.2411107619603476

Epoch: 6| Step: 12
Training loss: 1.9230000972747803
Validation loss: 2.252781172593435

Epoch: 6| Step: 13
Training loss: 2.640814781188965
Validation loss: 2.2501498063405356

Epoch: 7| Step: 0
Training loss: 1.7165076732635498
Validation loss: 2.2325862050056458

Epoch: 6| Step: 1
Training loss: 2.779622793197632
Validation loss: 2.258347431818644

Epoch: 6| Step: 2
Training loss: 2.6232950687408447
Validation loss: 2.243915875752767

Epoch: 6| Step: 3
Training loss: 2.3510794639587402
Validation loss: 2.256733238697052

Epoch: 6| Step: 4
Training loss: 2.5486817359924316
Validation loss: 2.292048613230387

Epoch: 6| Step: 5
Training loss: 2.198143720626831
Validation loss: 2.283994734287262

Epoch: 6| Step: 6
Training loss: 2.4823708534240723
Validation loss: 2.311838209629059

Epoch: 6| Step: 7
Training loss: 2.209744930267334
Validation loss: 2.3157116770744324

Epoch: 6| Step: 8
Training loss: 1.8120397329330444
Validation loss: 2.321950395901998

Epoch: 6| Step: 9
Training loss: 1.9177439212799072
Validation loss: 2.3253212571144104

Epoch: 6| Step: 10
Training loss: 2.218095302581787
Validation loss: 2.320480744043986

Epoch: 6| Step: 11
Training loss: 2.744868755340576
Validation loss: 2.318265914916992

Epoch: 6| Step: 12
Training loss: 2.808910369873047
Validation loss: 2.3152257204055786

Epoch: 6| Step: 13
Training loss: 1.998769760131836
Validation loss: 2.3011394341786704

Epoch: 8| Step: 0
Training loss: 2.648773670196533
Validation loss: 2.2831066052118936

Epoch: 6| Step: 1
Training loss: 2.0058798789978027
Validation loss: 2.278616726398468

Epoch: 6| Step: 2
Training loss: 1.7419309616088867
Validation loss: 2.239714562892914

Epoch: 6| Step: 3
Training loss: 2.801666498184204
Validation loss: 2.245568811893463

Epoch: 6| Step: 4
Training loss: 1.8740699291229248
Validation loss: 2.2376104593276978

Epoch: 6| Step: 5
Training loss: 2.474985361099243
Validation loss: 2.214810371398926

Epoch: 6| Step: 6
Training loss: 2.2856791019439697
Validation loss: 2.227136572202047

Epoch: 6| Step: 7
Training loss: 2.3283262252807617
Validation loss: 2.2212502559026084

Epoch: 6| Step: 8
Training loss: 2.620560646057129
Validation loss: 2.2393932938575745

Epoch: 6| Step: 9
Training loss: 2.464493751525879
Validation loss: 2.2093347907066345

Epoch: 6| Step: 10
Training loss: 2.389404773712158
Validation loss: 2.214995324611664

Epoch: 6| Step: 11
Training loss: 2.182156801223755
Validation loss: 2.177866836388906

Epoch: 6| Step: 12
Training loss: 2.455995559692383
Validation loss: 2.20884116490682

Epoch: 6| Step: 13
Training loss: 1.5109288692474365
Validation loss: 2.1995896697044373

Epoch: 9| Step: 0
Training loss: 1.6195614337921143
Validation loss: 2.1932783921559653

Epoch: 6| Step: 1
Training loss: 2.499551773071289
Validation loss: 2.191178103288015

Epoch: 6| Step: 2
Training loss: 2.2212114334106445
Validation loss: 2.177000959714254

Epoch: 6| Step: 3
Training loss: 2.6757187843322754
Validation loss: 2.1739296515782676

Epoch: 6| Step: 4
Training loss: 2.26204514503479
Validation loss: 2.1519269347190857

Epoch: 6| Step: 5
Training loss: 2.341846466064453
Validation loss: 2.1921987533569336

Epoch: 6| Step: 6
Training loss: 1.9977080821990967
Validation loss: 2.1885656118392944

Epoch: 6| Step: 7
Training loss: 3.307525634765625
Validation loss: 2.150435427824656

Epoch: 6| Step: 8
Training loss: 2.611362934112549
Validation loss: 2.171679695447286

Epoch: 6| Step: 9
Training loss: 1.933462381362915
Validation loss: 2.1727135181427

Epoch: 6| Step: 10
Training loss: 1.389142632484436
Validation loss: 2.1633086800575256

Epoch: 6| Step: 11
Training loss: 2.5915849208831787
Validation loss: 2.1462963819503784

Epoch: 6| Step: 12
Training loss: 1.9460678100585938
Validation loss: 2.1716960668563843

Epoch: 6| Step: 13
Training loss: 2.163543701171875
Validation loss: 2.147733449935913

Epoch: 10| Step: 0
Training loss: 2.2104363441467285
Validation loss: 2.162044942378998

Epoch: 6| Step: 1
Training loss: 2.480379343032837
Validation loss: 2.170874993006388

Epoch: 6| Step: 2
Training loss: 2.959888458251953
Validation loss: 2.170898973941803

Epoch: 6| Step: 3
Training loss: 2.005458354949951
Validation loss: 2.193717579046885

Epoch: 6| Step: 4
Training loss: 2.186988592147827
Validation loss: 2.1655927896499634

Epoch: 6| Step: 5
Training loss: 2.4120750427246094
Validation loss: 2.184706171353658

Epoch: 6| Step: 6
Training loss: 2.027829647064209
Validation loss: 2.178160786628723

Epoch: 6| Step: 7
Training loss: 1.6620852947235107
Validation loss: 2.183083434899648

Epoch: 6| Step: 8
Training loss: 2.5503408908843994
Validation loss: 2.1460776925086975

Epoch: 6| Step: 9
Training loss: 2.2944135665893555
Validation loss: 2.1500216325124106

Epoch: 6| Step: 10
Training loss: 1.573744297027588
Validation loss: 2.1592180927594504

Epoch: 6| Step: 11
Training loss: 1.820691466331482
Validation loss: 2.1397255857785544

Epoch: 6| Step: 12
Training loss: 2.58944034576416
Validation loss: 2.1405725479125977

Epoch: 6| Step: 13
Training loss: 2.589660167694092
Validation loss: 2.1434643467267356

Epoch: 11| Step: 0
Training loss: 2.2111456394195557
Validation loss: 2.125386973222097

Epoch: 6| Step: 1
Training loss: 2.129934072494507
Validation loss: 2.144002854824066

Epoch: 6| Step: 2
Training loss: 1.7955185174942017
Validation loss: 2.1176721652348838

Epoch: 6| Step: 3
Training loss: 2.1494975090026855
Validation loss: 2.1298123598098755

Epoch: 6| Step: 4
Training loss: 1.8844578266143799
Validation loss: 2.12301097313563

Epoch: 6| Step: 5
Training loss: 1.9008771181106567
Validation loss: 2.118629594643911

Epoch: 6| Step: 6
Training loss: 2.0726521015167236
Validation loss: 2.1503655513127646

Epoch: 6| Step: 7
Training loss: 2.9536147117614746
Validation loss: 2.133823355038961

Epoch: 6| Step: 8
Training loss: 2.391145944595337
Validation loss: 2.132039964199066

Epoch: 6| Step: 9
Training loss: 2.5864672660827637
Validation loss: 2.1147706508636475

Epoch: 6| Step: 10
Training loss: 1.839606523513794
Validation loss: 2.09143336613973

Epoch: 6| Step: 11
Training loss: 2.61806058883667
Validation loss: 2.1343151926994324

Epoch: 6| Step: 12
Training loss: 2.2524049282073975
Validation loss: 2.097342391808828

Epoch: 6| Step: 13
Training loss: 2.4032156467437744
Validation loss: 2.1174621184666953

Epoch: 12| Step: 0
Training loss: 2.5631284713745117
Validation loss: 2.1039625803629556

Epoch: 6| Step: 1
Training loss: 2.212421417236328
Validation loss: 2.098673701286316

Epoch: 6| Step: 2
Training loss: 1.3789199590682983
Validation loss: 2.1150222023328147

Epoch: 6| Step: 3
Training loss: 2.480025053024292
Validation loss: 2.0936633547147117

Epoch: 6| Step: 4
Training loss: 3.508671998977661
Validation loss: 2.0967299342155457

Epoch: 6| Step: 5
Training loss: 2.73842716217041
Validation loss: 2.118252754211426

Epoch: 6| Step: 6
Training loss: 2.546535015106201
Validation loss: 2.110132078329722

Epoch: 6| Step: 7
Training loss: 1.8443597555160522
Validation loss: 2.08873587846756

Epoch: 6| Step: 8
Training loss: 2.182715654373169
Validation loss: 2.06547604004542

Epoch: 6| Step: 9
Training loss: 1.9123790264129639
Validation loss: 2.1030344367027283

Epoch: 6| Step: 10
Training loss: 1.4954288005828857
Validation loss: 2.1273913383483887

Epoch: 6| Step: 11
Training loss: 1.414486289024353
Validation loss: 2.090498626232147

Epoch: 6| Step: 12
Training loss: 1.7113010883331299
Validation loss: 2.0905199448267617

Epoch: 6| Step: 13
Training loss: 2.4437413215637207
Validation loss: 2.0882058342297873

Epoch: 13| Step: 0
Training loss: 2.3343183994293213
Validation loss: 2.1057558059692383

Epoch: 6| Step: 1
Training loss: 1.8687384128570557
Validation loss: 2.121805568536123

Epoch: 6| Step: 2
Training loss: 2.043855667114258
Validation loss: 2.099608282248179

Epoch: 6| Step: 3
Training loss: 1.8932645320892334
Validation loss: 2.0880647897720337

Epoch: 6| Step: 4
Training loss: 2.2043323516845703
Validation loss: 2.121074080467224

Epoch: 6| Step: 5
Training loss: 1.8839783668518066
Validation loss: 2.0732925136884055

Epoch: 6| Step: 6
Training loss: 2.8845362663269043
Validation loss: 2.0980698267618814

Epoch: 6| Step: 7
Training loss: 2.384145498275757
Validation loss: 2.073368569215139

Epoch: 6| Step: 8
Training loss: 2.2584457397460938
Validation loss: 2.0767255624135337

Epoch: 6| Step: 9
Training loss: 2.3057503700256348
Validation loss: 2.090276082356771

Epoch: 6| Step: 10
Training loss: 2.2853012084960938
Validation loss: 2.045257488886515

Epoch: 6| Step: 11
Training loss: 2.5881097316741943
Validation loss: 2.0569249590237937

Epoch: 6| Step: 12
Training loss: 1.4827840328216553
Validation loss: 2.073690712451935

Epoch: 6| Step: 13
Training loss: 2.085973024368286
Validation loss: 2.06263800462087

Epoch: 14| Step: 0
Training loss: 2.367215871810913
Validation loss: 2.0781793196996055

Epoch: 6| Step: 1
Training loss: 1.6925147771835327
Validation loss: 2.060546616713206

Epoch: 6| Step: 2
Training loss: 1.547046184539795
Validation loss: 2.081116735935211

Epoch: 6| Step: 3
Training loss: 1.4656952619552612
Validation loss: 2.081988513469696

Epoch: 6| Step: 4
Training loss: 1.2901921272277832
Validation loss: 2.073182682196299

Epoch: 6| Step: 5
Training loss: 2.3866498470306396
Validation loss: 2.0629477898279824

Epoch: 6| Step: 6
Training loss: 2.012814521789551
Validation loss: 2.057382504145304

Epoch: 6| Step: 7
Training loss: 2.7841081619262695
Validation loss: 2.089565555254618

Epoch: 6| Step: 8
Training loss: 2.309173583984375
Validation loss: 2.079098423322042

Epoch: 6| Step: 9
Training loss: 1.918745517730713
Validation loss: 2.0419875979423523

Epoch: 6| Step: 10
Training loss: 3.373826265335083
Validation loss: 2.068490823109945

Epoch: 6| Step: 11
Training loss: 2.039015531539917
Validation loss: 2.0674081842104592

Epoch: 6| Step: 12
Training loss: 2.2135696411132812
Validation loss: 2.0452231764793396

Epoch: 6| Step: 13
Training loss: 2.6555051803588867
Validation loss: 2.0833197236061096

Epoch: 15| Step: 0
Training loss: 2.737983226776123
Validation loss: 2.067590276400248

Epoch: 6| Step: 1
Training loss: 1.8022363185882568
Validation loss: 2.0443443059921265

Epoch: 6| Step: 2
Training loss: 1.544129490852356
Validation loss: 2.0754363934199014

Epoch: 6| Step: 3
Training loss: 1.8595842123031616
Validation loss: 2.0734338760375977

Epoch: 6| Step: 4
Training loss: 2.11177921295166
Validation loss: 2.070137639840444

Epoch: 6| Step: 5
Training loss: 2.789597749710083
Validation loss: 2.0393019715944924

Epoch: 6| Step: 6
Training loss: 2.7762298583984375
Validation loss: 2.0359236796696982

Epoch: 6| Step: 7
Training loss: 2.5289082527160645
Validation loss: 2.053156773249308

Epoch: 6| Step: 8
Training loss: 2.0016794204711914
Validation loss: 2.0734103322029114

Epoch: 6| Step: 9
Training loss: 2.089111566543579
Validation loss: 2.0666035811106362

Epoch: 6| Step: 10
Training loss: 1.473457932472229
Validation loss: 2.055138190587362

Epoch: 6| Step: 11
Training loss: 1.548346757888794
Validation loss: 2.0673545002937317

Epoch: 6| Step: 12
Training loss: 1.8815817832946777
Validation loss: 2.0676814913749695

Epoch: 6| Step: 13
Training loss: 2.610597610473633
Validation loss: 2.0418858726819358

Epoch: 16| Step: 0
Training loss: 2.4927947521209717
Validation loss: 2.0532689491907754

Epoch: 6| Step: 1
Training loss: 2.757072687149048
Validation loss: 2.048047741254171

Epoch: 6| Step: 2
Training loss: 2.064619541168213
Validation loss: 2.074880838394165

Epoch: 6| Step: 3
Training loss: 2.8073043823242188
Validation loss: 2.048277576764425

Epoch: 6| Step: 4
Training loss: 2.573007583618164
Validation loss: 2.044596473375956

Epoch: 6| Step: 5
Training loss: 1.6472012996673584
Validation loss: 2.0649675130844116

Epoch: 6| Step: 6
Training loss: 1.9422556161880493
Validation loss: 2.0318058133125305

Epoch: 6| Step: 7
Training loss: 1.5665122270584106
Validation loss: 2.020774801572164

Epoch: 6| Step: 8
Training loss: 2.1343894004821777
Validation loss: 2.028756042321523

Epoch: 6| Step: 9
Training loss: 2.0755205154418945
Validation loss: 2.067331393559774

Epoch: 6| Step: 10
Training loss: 1.256086826324463
Validation loss: 2.0413687427838645

Epoch: 6| Step: 11
Training loss: 1.8249289989471436
Validation loss: 2.068036437034607

Epoch: 6| Step: 12
Training loss: 1.799438714981079
Validation loss: 2.0850577155749

Epoch: 6| Step: 13
Training loss: 2.468630313873291
Validation loss: 2.1127267281214395

Epoch: 17| Step: 0
Training loss: 1.595334768295288
Validation loss: 2.117715299129486

Epoch: 6| Step: 1
Training loss: 2.5484468936920166
Validation loss: 2.151094595591227

Epoch: 6| Step: 2
Training loss: 2.1197991371154785
Validation loss: 2.0971006949742637

Epoch: 6| Step: 3
Training loss: 2.0560784339904785
Validation loss: 2.0900648832321167

Epoch: 6| Step: 4
Training loss: 2.824138641357422
Validation loss: 2.1167044242223105

Epoch: 6| Step: 5
Training loss: 2.1959543228149414
Validation loss: 2.0855462352434793

Epoch: 6| Step: 6
Training loss: 1.6049448251724243
Validation loss: 2.0529337724049888

Epoch: 6| Step: 7
Training loss: 1.709425687789917
Validation loss: 2.04683252175649

Epoch: 6| Step: 8
Training loss: 2.417069435119629
Validation loss: 2.070078412691752

Epoch: 6| Step: 9
Training loss: 1.6447808742523193
Validation loss: 2.0111629168192544

Epoch: 6| Step: 10
Training loss: 1.753295660018921
Validation loss: 2.045922835667928

Epoch: 6| Step: 11
Training loss: 1.8727469444274902
Validation loss: 2.0298613905906677

Epoch: 6| Step: 12
Training loss: 2.962582588195801
Validation loss: 2.0478492975234985

Epoch: 6| Step: 13
Training loss: 2.4184069633483887
Validation loss: 1.9854695995648701

Epoch: 18| Step: 0
Training loss: 2.6237363815307617
Validation loss: 2.0199212233225503

Epoch: 6| Step: 1
Training loss: 2.49273681640625
Validation loss: 2.0318471988042197

Epoch: 6| Step: 2
Training loss: 2.080911874771118
Validation loss: 2.0333234866460166

Epoch: 6| Step: 3
Training loss: 2.5389225482940674
Validation loss: 2.0156772335370383

Epoch: 6| Step: 4
Training loss: 2.1447973251342773
Validation loss: 2.0375975569089255

Epoch: 6| Step: 5
Training loss: 1.9234645366668701
Validation loss: 2.043937881787618

Epoch: 6| Step: 6
Training loss: 2.632927894592285
Validation loss: 2.0405309796333313

Epoch: 6| Step: 7
Training loss: 1.2364304065704346
Validation loss: 2.0802648067474365

Epoch: 6| Step: 8
Training loss: 1.8262447118759155
Validation loss: 2.0034658114115396

Epoch: 6| Step: 9
Training loss: 2.292065143585205
Validation loss: 2.05598121881485

Epoch: 6| Step: 10
Training loss: 1.935627818107605
Validation loss: 2.080159842967987

Epoch: 6| Step: 11
Training loss: 1.948974370956421
Validation loss: 2.0507702430089316

Epoch: 6| Step: 12
Training loss: 1.5248832702636719
Validation loss: 2.068738341331482

Epoch: 6| Step: 13
Training loss: 2.0123062133789062
Validation loss: 2.0591190656026206

Epoch: 19| Step: 0
Training loss: 2.8656957149505615
Validation loss: 2.0825871427853904

Epoch: 6| Step: 1
Training loss: 1.9925434589385986
Validation loss: 2.016990542411804

Epoch: 6| Step: 2
Training loss: 1.3615837097167969
Validation loss: 2.058334549268087

Epoch: 6| Step: 3
Training loss: 1.7133204936981201
Validation loss: 2.0445856054623923

Epoch: 6| Step: 4
Training loss: 2.0755648612976074
Validation loss: 2.0445719361305237

Epoch: 6| Step: 5
Training loss: 1.9496221542358398
Validation loss: 2.033721605936686

Epoch: 6| Step: 6
Training loss: 2.1650283336639404
Validation loss: 2.055159032344818

Epoch: 6| Step: 7
Training loss: 2.1299781799316406
Validation loss: 2.054477314154307

Epoch: 6| Step: 8
Training loss: 1.9882413148880005
Validation loss: 2.03423802057902

Epoch: 6| Step: 9
Training loss: 2.172617197036743
Validation loss: 2.035537620385488

Epoch: 6| Step: 10
Training loss: 1.7249835729599
Validation loss: 2.05021063486735

Epoch: 6| Step: 11
Training loss: 3.2813100814819336
Validation loss: 2.062951703866323

Epoch: 6| Step: 12
Training loss: 2.2002382278442383
Validation loss: 2.037297566731771

Epoch: 6| Step: 13
Training loss: 1.8080933094024658
Validation loss: 2.0311215122540793

Epoch: 20| Step: 0
Training loss: 1.4473153352737427
Validation loss: 2.0571815967559814

Epoch: 6| Step: 1
Training loss: 2.6375017166137695
Validation loss: 2.032853364944458

Epoch: 6| Step: 2
Training loss: 1.7678297758102417
Validation loss: 2.017614205678304

Epoch: 6| Step: 3
Training loss: 2.4190587997436523
Validation loss: 2.0025014678637185

Epoch: 6| Step: 4
Training loss: 2.6063055992126465
Validation loss: 2.001710752646128

Epoch: 6| Step: 5
Training loss: 2.500171661376953
Validation loss: 2.036490738391876

Epoch: 6| Step: 6
Training loss: 1.946319580078125
Validation loss: 1.9897745847702026

Epoch: 6| Step: 7
Training loss: 1.5775744915008545
Validation loss: 2.0105958779652915

Epoch: 6| Step: 8
Training loss: 1.7336986064910889
Validation loss: 2.0371811787287393

Epoch: 6| Step: 9
Training loss: 2.730342149734497
Validation loss: 2.0593231916427612

Epoch: 6| Step: 10
Training loss: 1.5373812913894653
Validation loss: 2.0104695359865823

Epoch: 6| Step: 11
Training loss: 1.8041057586669922
Validation loss: 2.0303215384483337

Epoch: 6| Step: 12
Training loss: 1.9732977151870728
Validation loss: 2.012887438138326

Epoch: 6| Step: 13
Training loss: 2.5532655715942383
Validation loss: 2.093926032384237

Epoch: 21| Step: 0
Training loss: 2.0699219703674316
Validation loss: 2.1047989328702292

Epoch: 6| Step: 1
Training loss: 2.4869771003723145
Validation loss: 2.059152682622274

Epoch: 6| Step: 2
Training loss: 1.7625149488449097
Validation loss: 2.0457209944725037

Epoch: 6| Step: 3
Training loss: 1.897452473640442
Validation loss: 2.0608717799186707

Epoch: 6| Step: 4
Training loss: 1.8105764389038086
Validation loss: 2.066158672173818

Epoch: 6| Step: 5
Training loss: 2.067452907562256
Validation loss: 2.06618599096934

Epoch: 6| Step: 6
Training loss: 2.146038055419922
Validation loss: 2.0678900281588235

Epoch: 6| Step: 7
Training loss: 2.940624237060547
Validation loss: 2.0119125843048096

Epoch: 6| Step: 8
Training loss: 1.2620450258255005
Validation loss: 2.0602821707725525

Epoch: 6| Step: 9
Training loss: 2.5425615310668945
Validation loss: 2.0411458810170493

Epoch: 6| Step: 10
Training loss: 2.0664806365966797
Validation loss: 2.0069881280263266

Epoch: 6| Step: 11
Training loss: 1.9152381420135498
Validation loss: 2.0267414251963296

Epoch: 6| Step: 12
Training loss: 1.764266014099121
Validation loss: 2.0088824033737183

Epoch: 6| Step: 13
Training loss: 2.177112102508545
Validation loss: 2.0020713806152344

Epoch: 22| Step: 0
Training loss: 1.601273536682129
Validation loss: 2.0016414721806846

Epoch: 6| Step: 1
Training loss: 2.867457866668701
Validation loss: 2.066073755423228

Epoch: 6| Step: 2
Training loss: 1.905543565750122
Validation loss: 2.019978125890096

Epoch: 6| Step: 3
Training loss: 2.160506248474121
Validation loss: 1.9792811274528503

Epoch: 6| Step: 4
Training loss: 2.3554978370666504
Validation loss: 2.0124345223108926

Epoch: 6| Step: 5
Training loss: 1.823598861694336
Validation loss: 1.985344151655833

Epoch: 6| Step: 6
Training loss: 2.521805763244629
Validation loss: 1.9935441414515178

Epoch: 6| Step: 7
Training loss: 1.4321173429489136
Validation loss: 2.0321819384892783

Epoch: 6| Step: 8
Training loss: 2.380549192428589
Validation loss: 2.060833235581716

Epoch: 6| Step: 9
Training loss: 2.102295160293579
Validation loss: 2.0747719208399453

Epoch: 6| Step: 10
Training loss: 2.1936182975769043
Validation loss: 2.091912011305491

Epoch: 6| Step: 11
Training loss: 2.3629488945007324
Validation loss: 2.081166446208954

Epoch: 6| Step: 12
Training loss: 2.5246200561523438
Validation loss: 2.0582881967226663

Epoch: 6| Step: 13
Training loss: 1.4502798318862915
Validation loss: 2.08924130598704

Epoch: 23| Step: 0
Training loss: 2.2592356204986572
Validation loss: 2.094701608022054

Epoch: 6| Step: 1
Training loss: 2.3229987621307373
Validation loss: 2.06169984738032

Epoch: 6| Step: 2
Training loss: 1.5193345546722412
Validation loss: 2.034238040447235

Epoch: 6| Step: 3
Training loss: 2.147803783416748
Validation loss: 2.0246726671854653

Epoch: 6| Step: 4
Training loss: 1.3332056999206543
Validation loss: 2.0198134183883667

Epoch: 6| Step: 5
Training loss: 3.5050697326660156
Validation loss: 2.023725171883901

Epoch: 6| Step: 6
Training loss: 2.371466875076294
Validation loss: 1.9797500769297283

Epoch: 6| Step: 7
Training loss: 1.4933322668075562
Validation loss: 2.0324232975641885

Epoch: 6| Step: 8
Training loss: 2.4178295135498047
Validation loss: 2.0210357705752053

Epoch: 6| Step: 9
Training loss: 2.027792453765869
Validation loss: 2.0384032924969993

Epoch: 6| Step: 10
Training loss: 1.273967981338501
Validation loss: 2.0345819195111594

Epoch: 6| Step: 11
Training loss: 1.5771324634552002
Validation loss: 2.01006547609965

Epoch: 6| Step: 12
Training loss: 2.4640274047851562
Validation loss: 2.0300137599309287

Epoch: 6| Step: 13
Training loss: 2.1128745079040527
Validation loss: 2.035906354586283

Epoch: 24| Step: 0
Training loss: 1.9318541288375854
Validation loss: 2.0348047812779746

Epoch: 6| Step: 1
Training loss: 1.8554614782333374
Validation loss: 2.0383713841438293

Epoch: 6| Step: 2
Training loss: 2.450161933898926
Validation loss: 2.0552174051602683

Epoch: 6| Step: 3
Training loss: 1.435880422592163
Validation loss: 2.046048164367676

Epoch: 6| Step: 4
Training loss: 2.410642385482788
Validation loss: 2.019611914952596

Epoch: 6| Step: 5
Training loss: 2.013810634613037
Validation loss: 2.0718990763028464

Epoch: 6| Step: 6
Training loss: 2.1704747676849365
Validation loss: 2.0379273692766824

Epoch: 6| Step: 7
Training loss: 2.5890321731567383
Validation loss: 2.036107818285624

Epoch: 6| Step: 8
Training loss: 2.000248432159424
Validation loss: 2.0374514063199363

Epoch: 6| Step: 9
Training loss: 2.367898941040039
Validation loss: 2.0188181400299072

Epoch: 6| Step: 10
Training loss: 1.6061633825302124
Validation loss: 2.0431810220082602

Epoch: 6| Step: 11
Training loss: 1.844553828239441
Validation loss: 1.9986420075098674

Epoch: 6| Step: 12
Training loss: 2.2329063415527344
Validation loss: 2.0142634908358255

Epoch: 6| Step: 13
Training loss: 1.8369735479354858
Validation loss: 2.0197937885920205

Epoch: 25| Step: 0
Training loss: 1.8699182271957397
Validation loss: 1.9885418613751729

Epoch: 6| Step: 1
Training loss: 1.8994941711425781
Validation loss: 1.9756489793459575

Epoch: 6| Step: 2
Training loss: 1.7526116371154785
Validation loss: 2.030086358388265

Epoch: 6| Step: 3
Training loss: 1.9173693656921387
Validation loss: 1.9965320428212483

Epoch: 6| Step: 4
Training loss: 2.0193116664886475
Validation loss: 2.00114498535792

Epoch: 6| Step: 5
Training loss: 2.7573301792144775
Validation loss: 1.9570835034052532

Epoch: 6| Step: 6
Training loss: 2.2095067501068115
Validation loss: 2.0076183080673218

Epoch: 6| Step: 7
Training loss: 1.9553080797195435
Validation loss: 2.045512596766154

Epoch: 6| Step: 8
Training loss: 1.8153505325317383
Validation loss: 2.0202733278274536

Epoch: 6| Step: 9
Training loss: 2.079909324645996
Validation loss: 2.0548062721888223

Epoch: 6| Step: 10
Training loss: 1.8661799430847168
Validation loss: 2.0649263858795166

Epoch: 6| Step: 11
Training loss: 1.7000311613082886
Validation loss: 2.062308192253113

Epoch: 6| Step: 12
Training loss: 1.8991268873214722
Validation loss: 2.047281483809153

Epoch: 6| Step: 13
Training loss: 2.8386764526367188
Validation loss: 2.0358369946479797

Epoch: 26| Step: 0
Training loss: 3.056194543838501
Validation loss: 2.026877760887146

Epoch: 6| Step: 1
Training loss: 1.8885153532028198
Validation loss: 2.0476564168930054

Epoch: 6| Step: 2
Training loss: 1.4989707469940186
Validation loss: 2.0192671616872153

Epoch: 6| Step: 3
Training loss: 2.236602783203125
Validation loss: 2.016475200653076

Epoch: 6| Step: 4
Training loss: 1.9772993326187134
Validation loss: 2.0284156997998557

Epoch: 6| Step: 5
Training loss: 1.9566811323165894
Validation loss: 2.0341748793919883

Epoch: 6| Step: 6
Training loss: 1.6041796207427979
Validation loss: 2.0097629626592

Epoch: 6| Step: 7
Training loss: 1.7701740264892578
Validation loss: 2.037669817606608

Epoch: 6| Step: 8
Training loss: 1.613555908203125
Validation loss: 2.0319493810335794

Epoch: 6| Step: 9
Training loss: 2.3326547145843506
Validation loss: 2.0553124149640403

Epoch: 6| Step: 10
Training loss: 2.172618865966797
Validation loss: 2.059822221597036

Epoch: 6| Step: 11
Training loss: 2.0484049320220947
Validation loss: 2.007472892602285

Epoch: 6| Step: 12
Training loss: 1.8277654647827148
Validation loss: 2.063513398170471

Epoch: 6| Step: 13
Training loss: 2.579071044921875
Validation loss: 2.0388828913370767

Epoch: 27| Step: 0
Training loss: 1.7082464694976807
Validation loss: 2.0125339031219482

Epoch: 6| Step: 1
Training loss: 2.0187649726867676
Validation loss: 1.9936569333076477

Epoch: 6| Step: 2
Training loss: 1.5994174480438232
Validation loss: 2.004904548327128

Epoch: 6| Step: 3
Training loss: 2.2366018295288086
Validation loss: 2.0070034662882485

Epoch: 6| Step: 4
Training loss: 2.317805290222168
Validation loss: 2.037045876185099

Epoch: 6| Step: 5
Training loss: 2.219613552093506
Validation loss: 2.0030057032903037

Epoch: 6| Step: 6
Training loss: 2.0273303985595703
Validation loss: 2.0384138027826944

Epoch: 6| Step: 7
Training loss: 2.4903602600097656
Validation loss: 2.0207701921463013

Epoch: 6| Step: 8
Training loss: 1.8106515407562256
Validation loss: 2.051192065080007

Epoch: 6| Step: 9
Training loss: 1.9845294952392578
Validation loss: 1.9844653209050496

Epoch: 6| Step: 10
Training loss: 2.4355430603027344
Validation loss: 2.021863639354706

Epoch: 6| Step: 11
Training loss: 2.0331673622131348
Validation loss: 2.0190476377805076

Epoch: 6| Step: 12
Training loss: 1.867732286453247
Validation loss: 2.020701249440511

Epoch: 6| Step: 13
Training loss: 1.4575376510620117
Validation loss: 2.0131470561027527

Epoch: 28| Step: 0
Training loss: 2.2201051712036133
Validation loss: 1.9581053058306377

Epoch: 6| Step: 1
Training loss: 1.8595621585845947
Validation loss: 2.001108010609945

Epoch: 6| Step: 2
Training loss: 2.2964305877685547
Validation loss: 2.031711975733439

Epoch: 6| Step: 3
Training loss: 2.0526299476623535
Validation loss: 1.9454628427823384

Epoch: 6| Step: 4
Training loss: 1.8258874416351318
Validation loss: 2.043768286705017

Epoch: 6| Step: 5
Training loss: 1.8609520196914673
Validation loss: 2.006057540575663

Epoch: 6| Step: 6
Training loss: 2.12030291557312
Validation loss: 2.0213571786880493

Epoch: 6| Step: 7
Training loss: 1.97198486328125
Validation loss: 1.963666299978892

Epoch: 6| Step: 8
Training loss: 1.9963605403900146
Validation loss: 2.0172401070594788

Epoch: 6| Step: 9
Training loss: 1.1206247806549072
Validation loss: 1.9786724050839741

Epoch: 6| Step: 10
Training loss: 2.2763609886169434
Validation loss: 2.006805201371511

Epoch: 6| Step: 11
Training loss: 2.1343941688537598
Validation loss: 2.0606832106908164

Epoch: 6| Step: 12
Training loss: 2.649426221847534
Validation loss: 2.0217459003130593

Epoch: 6| Step: 13
Training loss: 1.8823800086975098
Validation loss: 2.0462012887001038

Epoch: 29| Step: 0
Training loss: 2.104931592941284
Validation loss: 2.0124650994936624

Epoch: 6| Step: 1
Training loss: 1.441402554512024
Validation loss: 2.0299681027730307

Epoch: 6| Step: 2
Training loss: 1.668578863143921
Validation loss: 2.0556593934694924

Epoch: 6| Step: 3
Training loss: 3.294064998626709
Validation loss: 2.0080228447914124

Epoch: 6| Step: 4
Training loss: 1.8860447406768799
Validation loss: 2.0374781489372253

Epoch: 6| Step: 5
Training loss: 2.5605194568634033
Validation loss: 1.9925293326377869

Epoch: 6| Step: 6
Training loss: 1.758263111114502
Validation loss: 1.999507208665212

Epoch: 6| Step: 7
Training loss: 2.2712926864624023
Validation loss: 2.055373211701711

Epoch: 6| Step: 8
Training loss: 2.289597988128662
Validation loss: 2.030334989229838

Epoch: 6| Step: 9
Training loss: 1.5166559219360352
Validation loss: 2.037816325823466

Epoch: 6| Step: 10
Training loss: 1.8369274139404297
Validation loss: 2.022622843583425

Epoch: 6| Step: 11
Training loss: 2.4621410369873047
Validation loss: 2.004768133163452

Epoch: 6| Step: 12
Training loss: 1.9219372272491455
Validation loss: 2.022446652253469

Epoch: 6| Step: 13
Training loss: 1.6149787902832031
Validation loss: 2.0601869026819863

Epoch: 30| Step: 0
Training loss: 2.0816760063171387
Validation loss: 2.058107157548269

Epoch: 6| Step: 1
Training loss: 1.5449228286743164
Validation loss: 2.0023738741874695

Epoch: 6| Step: 2
Training loss: 1.6203248500823975
Validation loss: 2.05917489528656

Epoch: 6| Step: 3
Training loss: 1.7174320220947266
Validation loss: 2.0343141158421836

Epoch: 6| Step: 4
Training loss: 1.816908597946167
Validation loss: 1.9908833702405293

Epoch: 6| Step: 5
Training loss: 2.387969970703125
Validation loss: 2.000886559486389

Epoch: 6| Step: 6
Training loss: 2.2081480026245117
Validation loss: 1.9667625228563945

Epoch: 6| Step: 7
Training loss: 2.001335859298706
Validation loss: 1.9961560567220051

Epoch: 6| Step: 8
Training loss: 1.688265085220337
Validation loss: 2.0173025528589883

Epoch: 6| Step: 9
Training loss: 1.9642212390899658
Validation loss: 2.0386154651641846

Epoch: 6| Step: 10
Training loss: 2.2056379318237305
Validation loss: 2.0069703261057534

Epoch: 6| Step: 11
Training loss: 1.8486263751983643
Validation loss: 1.9790540933609009

Epoch: 6| Step: 12
Training loss: 2.4970078468322754
Validation loss: 2.0049742062886557

Epoch: 6| Step: 13
Training loss: 2.3964285850524902
Validation loss: 2.0208072463671365

Epoch: 31| Step: 0
Training loss: 1.8263779878616333
Validation loss: 1.9908605416615803

Epoch: 6| Step: 1
Training loss: 1.8317275047302246
Validation loss: 1.9788635969161987

Epoch: 6| Step: 2
Training loss: 2.2955541610717773
Validation loss: 2.0459243655204773

Epoch: 6| Step: 3
Training loss: 2.565307140350342
Validation loss: 1.9753020405769348

Epoch: 6| Step: 4
Training loss: 1.7714943885803223
Validation loss: 2.06296439965566

Epoch: 6| Step: 5
Training loss: 1.8281056880950928
Validation loss: 1.9733884533246357

Epoch: 6| Step: 6
Training loss: 1.8175652027130127
Validation loss: 2.029580612977346

Epoch: 6| Step: 7
Training loss: 1.8625506162643433
Validation loss: 2.0246277848879495

Epoch: 6| Step: 8
Training loss: 2.2554163932800293
Validation loss: 2.0815870563189187

Epoch: 6| Step: 9
Training loss: 2.6238088607788086
Validation loss: 1.9913871089617412

Epoch: 6| Step: 10
Training loss: 1.4511033296585083
Validation loss: 2.0132822593053183

Epoch: 6| Step: 11
Training loss: 1.8202850818634033
Validation loss: 2.0274367332458496

Epoch: 6| Step: 12
Training loss: 2.383971691131592
Validation loss: 2.0767388542493186

Epoch: 6| Step: 13
Training loss: 1.6913894414901733
Validation loss: 2.0849622090657554

Epoch: 32| Step: 0
Training loss: 1.9670209884643555
Validation loss: 2.0743856032689414

Epoch: 6| Step: 1
Training loss: 1.6839299201965332
Validation loss: 2.042898495992025

Epoch: 6| Step: 2
Training loss: 1.483938455581665
Validation loss: 2.081908563772837

Epoch: 6| Step: 3
Training loss: 2.536994457244873
Validation loss: 2.014474630355835

Epoch: 6| Step: 4
Training loss: 2.1615962982177734
Validation loss: 2.0236952702204385

Epoch: 6| Step: 5
Training loss: 1.9728449583053589
Validation loss: 1.9954323172569275

Epoch: 6| Step: 6
Training loss: 1.254610300064087
Validation loss: 1.9970971544583638

Epoch: 6| Step: 7
Training loss: 2.0058746337890625
Validation loss: 1.9806442658106487

Epoch: 6| Step: 8
Training loss: 1.6658918857574463
Validation loss: 1.9762782057126362

Epoch: 6| Step: 9
Training loss: 2.8360977172851562
Validation loss: 1.985864023367564

Epoch: 6| Step: 10
Training loss: 2.178546905517578
Validation loss: 1.9481827815373738

Epoch: 6| Step: 11
Training loss: 2.201408863067627
Validation loss: 2.0194434920946756

Epoch: 6| Step: 12
Training loss: 2.2244393825531006
Validation loss: 2.0238596200942993

Epoch: 6| Step: 13
Training loss: 2.2320075035095215
Validation loss: 2.0540198485056558

Epoch: 33| Step: 0
Training loss: 2.0013046264648438
Validation loss: 2.0796013673146567

Epoch: 6| Step: 1
Training loss: 1.6994434595108032
Validation loss: 2.1063127915064492

Epoch: 6| Step: 2
Training loss: 2.372565746307373
Validation loss: 2.0868254701296487

Epoch: 6| Step: 3
Training loss: 1.9965949058532715
Validation loss: 2.0700461069742837

Epoch: 6| Step: 4
Training loss: 2.168771743774414
Validation loss: 2.040312886238098

Epoch: 6| Step: 5
Training loss: 1.8264293670654297
Validation loss: 2.0483202735582986

Epoch: 6| Step: 6
Training loss: 2.310478687286377
Validation loss: 2.0329389373461404

Epoch: 6| Step: 7
Training loss: 1.694718837738037
Validation loss: 2.0237497289975486

Epoch: 6| Step: 8
Training loss: 1.6574687957763672
Validation loss: 2.0344393253326416

Epoch: 6| Step: 9
Training loss: 2.1423490047454834
Validation loss: 2.006894568602244

Epoch: 6| Step: 10
Training loss: 2.102687358856201
Validation loss: 1.992607057094574

Epoch: 6| Step: 11
Training loss: 1.3843395709991455
Validation loss: 2.0120991468429565

Epoch: 6| Step: 12
Training loss: 2.5874507427215576
Validation loss: 2.0215617219607034

Epoch: 6| Step: 13
Training loss: 2.2281112670898438
Validation loss: 1.9873247941335042

Epoch: 34| Step: 0
Training loss: 1.751338005065918
Validation loss: 1.9841622312863667

Epoch: 6| Step: 1
Training loss: 2.4103586673736572
Validation loss: 2.0468397736549377

Epoch: 6| Step: 2
Training loss: 2.0744457244873047
Validation loss: 2.0529218912124634

Epoch: 6| Step: 3
Training loss: 1.745847225189209
Validation loss: 2.004969676335653

Epoch: 6| Step: 4
Training loss: 2.0796101093292236
Validation loss: 2.009213089942932

Epoch: 6| Step: 5
Training loss: 2.3515706062316895
Validation loss: 2.0668857296307883

Epoch: 6| Step: 6
Training loss: 2.1330666542053223
Validation loss: 2.026255468527476

Epoch: 6| Step: 7
Training loss: 1.2251956462860107
Validation loss: 2.04244601726532

Epoch: 6| Step: 8
Training loss: 1.9622045755386353
Validation loss: 2.009567399819692

Epoch: 6| Step: 9
Training loss: 2.440443515777588
Validation loss: 2.050412873427073

Epoch: 6| Step: 10
Training loss: 2.567713737487793
Validation loss: 1.9869582851727803

Epoch: 6| Step: 11
Training loss: 1.681056022644043
Validation loss: 2.034285068511963

Epoch: 6| Step: 12
Training loss: 1.5040279626846313
Validation loss: 2.0107144713401794

Epoch: 6| Step: 13
Training loss: 1.3814692497253418
Validation loss: 2.0036301811536155

Epoch: 35| Step: 0
Training loss: 1.8936889171600342
Validation loss: 2.0079662998517356

Epoch: 6| Step: 1
Training loss: 1.8237355947494507
Validation loss: 2.046456257502238

Epoch: 6| Step: 2
Training loss: 2.2346489429473877
Validation loss: 2.0429906845092773

Epoch: 6| Step: 3
Training loss: 1.7541775703430176
Validation loss: 2.0152439077695212

Epoch: 6| Step: 4
Training loss: 2.3103604316711426
Validation loss: 2.040377616882324

Epoch: 6| Step: 5
Training loss: 1.6041088104248047
Validation loss: 1.977030058701833

Epoch: 6| Step: 6
Training loss: 1.8002766370773315
Validation loss: 2.0191197196642556

Epoch: 6| Step: 7
Training loss: 2.2749369144439697
Validation loss: 2.018029431502024

Epoch: 6| Step: 8
Training loss: 1.893180012702942
Validation loss: 2.005589803059896

Epoch: 6| Step: 9
Training loss: 2.061805486679077
Validation loss: 1.9832684993743896

Epoch: 6| Step: 10
Training loss: 1.7284036874771118
Validation loss: 1.9832220872243245

Epoch: 6| Step: 11
Training loss: 2.0449514389038086
Validation loss: 1.9984898169835408

Epoch: 6| Step: 12
Training loss: 1.6399624347686768
Validation loss: 2.031530499458313

Epoch: 6| Step: 13
Training loss: 2.5594990253448486
Validation loss: 2.010610024134318

Epoch: 36| Step: 0
Training loss: 1.6959424018859863
Validation loss: 2.0217003424962363

Epoch: 6| Step: 1
Training loss: 2.1952991485595703
Validation loss: 2.020041743914286

Epoch: 6| Step: 2
Training loss: 2.012868642807007
Validation loss: 2.0485737125078836

Epoch: 6| Step: 3
Training loss: 1.8458868265151978
Validation loss: 2.042849679787954

Epoch: 6| Step: 4
Training loss: 1.690469741821289
Validation loss: 2.0627999901771545

Epoch: 6| Step: 5
Training loss: 2.5660455226898193
Validation loss: 1.9888408184051514

Epoch: 6| Step: 6
Training loss: 1.6758254766464233
Validation loss: 2.090483466784159

Epoch: 6| Step: 7
Training loss: 2.2131826877593994
Validation loss: 2.030581990877787

Epoch: 6| Step: 8
Training loss: 1.6819393634796143
Validation loss: 2.0762309432029724

Epoch: 6| Step: 9
Training loss: 2.100861072540283
Validation loss: 1.9700542489687602

Epoch: 6| Step: 10
Training loss: 2.5473551750183105
Validation loss: 2.0434617598851523

Epoch: 6| Step: 11
Training loss: 1.9186501502990723
Validation loss: 1.9836671551068623

Epoch: 6| Step: 12
Training loss: 1.7730603218078613
Validation loss: 2.0294742385546365

Epoch: 6| Step: 13
Training loss: 1.6684333086013794
Validation loss: 2.0543853044509888

Epoch: 37| Step: 0
Training loss: 1.7319971323013306
Validation loss: 2.0465545058250427

Epoch: 6| Step: 1
Training loss: 1.7169079780578613
Validation loss: 2.030300716559092

Epoch: 6| Step: 2
Training loss: 1.8418433666229248
Validation loss: 2.091379543145498

Epoch: 6| Step: 3
Training loss: 2.1691455841064453
Validation loss: 2.0497092405954995

Epoch: 6| Step: 4
Training loss: 2.1984572410583496
Validation loss: 2.0022363662719727

Epoch: 6| Step: 5
Training loss: 2.0752367973327637
Validation loss: 2.069678624471029

Epoch: 6| Step: 6
Training loss: 1.4810463190078735
Validation loss: 2.0086220502853394

Epoch: 6| Step: 7
Training loss: 1.960579752922058
Validation loss: 1.993859310944875

Epoch: 6| Step: 8
Training loss: 1.4831689596176147
Validation loss: 1.9933885335922241

Epoch: 6| Step: 9
Training loss: 2.560015916824341
Validation loss: 2.0247639815012612

Epoch: 6| Step: 10
Training loss: 1.9506285190582275
Validation loss: 1.9835806488990784

Epoch: 6| Step: 11
Training loss: 1.8835824728012085
Validation loss: 2.028245488802592

Epoch: 6| Step: 12
Training loss: 1.454992413520813
Validation loss: 1.9932079712549846

Epoch: 6| Step: 13
Training loss: 2.4858503341674805
Validation loss: 2.0603389541308084

Epoch: 38| Step: 0
Training loss: 1.5278546810150146
Validation loss: 2.085164705912272

Epoch: 6| Step: 1
Training loss: 1.607975959777832
Validation loss: 2.051060914993286

Epoch: 6| Step: 2
Training loss: 2.136525869369507
Validation loss: 2.107028086980184

Epoch: 6| Step: 3
Training loss: 1.8859158754348755
Validation loss: 2.0903396805127463

Epoch: 6| Step: 4
Training loss: 2.7720251083374023
Validation loss: 2.0747443040211997

Epoch: 6| Step: 5
Training loss: 1.7851262092590332
Validation loss: 2.016726811726888

Epoch: 6| Step: 6
Training loss: 1.4524879455566406
Validation loss: 2.0159672101338706

Epoch: 6| Step: 7
Training loss: 1.4423854351043701
Validation loss: 2.03152859210968

Epoch: 6| Step: 8
Training loss: 2.207514524459839
Validation loss: 1.989914079507192

Epoch: 6| Step: 9
Training loss: 1.350456953048706
Validation loss: 1.991155703862508

Epoch: 6| Step: 10
Training loss: 1.9300731420516968
Validation loss: 2.0060399373372397

Epoch: 6| Step: 11
Training loss: 2.0344221591949463
Validation loss: 2.011345307032267

Epoch: 6| Step: 12
Training loss: 2.924384593963623
Validation loss: 1.9346148173014324

Epoch: 6| Step: 13
Training loss: 2.2210261821746826
Validation loss: 1.9974165360132854

Epoch: 39| Step: 0
Training loss: 1.8040024042129517
Validation loss: 2.032291531562805

Epoch: 6| Step: 1
Training loss: 2.2583205699920654
Validation loss: 2.0113343596458435

Epoch: 6| Step: 2
Training loss: 1.8655200004577637
Validation loss: 2.019962747891744

Epoch: 6| Step: 3
Training loss: 2.82194185256958
Validation loss: 1.9927666385968525

Epoch: 6| Step: 4
Training loss: 1.5183064937591553
Validation loss: 2.029722015062968

Epoch: 6| Step: 5
Training loss: 1.8662521839141846
Validation loss: 2.0191526412963867

Epoch: 6| Step: 6
Training loss: 2.3130321502685547
Validation loss: 2.0223078529040017

Epoch: 6| Step: 7
Training loss: 1.5321824550628662
Validation loss: 1.968873679637909

Epoch: 6| Step: 8
Training loss: 1.9490166902542114
Validation loss: 1.9899876713752747

Epoch: 6| Step: 9
Training loss: 1.1221789121627808
Validation loss: 1.9933573802312214

Epoch: 6| Step: 10
Training loss: 1.9124314785003662
Validation loss: 2.049941082795461

Epoch: 6| Step: 11
Training loss: 2.61407208442688
Validation loss: 2.0728577375411987

Epoch: 6| Step: 12
Training loss: 1.3029848337173462
Validation loss: 1.994307319323222

Epoch: 6| Step: 13
Training loss: 2.3863022327423096
Validation loss: 1.9754598339398701

Epoch: 40| Step: 0
Training loss: 1.7520638704299927
Validation loss: 2.0131749709447226

Epoch: 6| Step: 1
Training loss: 2.1097474098205566
Validation loss: 2.010863701502482

Epoch: 6| Step: 2
Training loss: 1.6896204948425293
Validation loss: 2.0069256822268167

Epoch: 6| Step: 3
Training loss: 1.5572774410247803
Validation loss: 2.030580699443817

Epoch: 6| Step: 4
Training loss: 1.5767815113067627
Validation loss: 2.0711775620778403

Epoch: 6| Step: 5
Training loss: 2.0271711349487305
Validation loss: 1.9719322522481282

Epoch: 6| Step: 6
Training loss: 1.4249346256256104
Validation loss: 2.024210770924886

Epoch: 6| Step: 7
Training loss: 2.4783244132995605
Validation loss: 2.099117318789164

Epoch: 6| Step: 8
Training loss: 2.8203561305999756
Validation loss: 2.051441033681234

Epoch: 6| Step: 9
Training loss: 2.0311739444732666
Validation loss: 2.036211291948954

Epoch: 6| Step: 10
Training loss: 1.7256442308425903
Validation loss: 2.0649472077687583

Epoch: 6| Step: 11
Training loss: 1.668925166130066
Validation loss: 2.039129118124644

Epoch: 6| Step: 12
Training loss: 1.7330331802368164
Validation loss: 2.0019512375195823

Epoch: 6| Step: 13
Training loss: 2.28660249710083
Validation loss: 1.980970561504364

Epoch: 41| Step: 0
Training loss: 1.491984248161316
Validation loss: 2.037684222062429

Epoch: 6| Step: 1
Training loss: 1.855992078781128
Validation loss: 1.9849191705385845

Epoch: 6| Step: 2
Training loss: 2.4994137287139893
Validation loss: 2.000792304674784

Epoch: 6| Step: 3
Training loss: 1.7677817344665527
Validation loss: 1.9573769768079121

Epoch: 6| Step: 4
Training loss: 1.956478238105774
Validation loss: 2.03835391998291

Epoch: 6| Step: 5
Training loss: 1.605209231376648
Validation loss: 2.051782230536143

Epoch: 6| Step: 6
Training loss: 2.3667266368865967
Validation loss: 2.0101384123166404

Epoch: 6| Step: 7
Training loss: 1.6506731510162354
Validation loss: 1.988321324189504

Epoch: 6| Step: 8
Training loss: 1.9261412620544434
Validation loss: 2.0225961804389954

Epoch: 6| Step: 9
Training loss: 1.6729769706726074
Validation loss: 2.0550317962964377

Epoch: 6| Step: 10
Training loss: 2.399228096008301
Validation loss: 2.065305848916372

Epoch: 6| Step: 11
Training loss: 2.1410999298095703
Validation loss: 2.09059876203537

Epoch: 6| Step: 12
Training loss: 1.423919677734375
Validation loss: 2.117964824040731

Epoch: 6| Step: 13
Training loss: 2.311610698699951
Validation loss: 2.059300700823466

Epoch: 42| Step: 0
Training loss: 2.1821329593658447
Validation loss: 2.0087796449661255

Epoch: 6| Step: 1
Training loss: 1.5768316984176636
Validation loss: 2.0162949363390603

Epoch: 6| Step: 2
Training loss: 1.3692543506622314
Validation loss: 2.006224731604258

Epoch: 6| Step: 3
Training loss: 1.705507516860962
Validation loss: 2.004540224870046

Epoch: 6| Step: 4
Training loss: 2.5008633136749268
Validation loss: 2.0423319737116494

Epoch: 6| Step: 5
Training loss: 1.850181221961975
Validation loss: 1.9951894680658977

Epoch: 6| Step: 6
Training loss: 2.1185860633850098
Validation loss: 2.036075750986735

Epoch: 6| Step: 7
Training loss: 2.284067153930664
Validation loss: 2.0219101508458457

Epoch: 6| Step: 8
Training loss: 1.9668805599212646
Validation loss: 1.9828121662139893

Epoch: 6| Step: 9
Training loss: 2.212050437927246
Validation loss: 2.014594316482544

Epoch: 6| Step: 10
Training loss: 2.205953598022461
Validation loss: 1.9749648372332256

Epoch: 6| Step: 11
Training loss: 1.6092771291732788
Validation loss: 2.0548390547434487

Epoch: 6| Step: 12
Training loss: 1.9611634016036987
Validation loss: 2.0465274453163147

Epoch: 6| Step: 13
Training loss: 1.858442783355713
Validation loss: 2.0552696784337363

Epoch: 43| Step: 0
Training loss: 1.9183226823806763
Validation loss: 2.0929861068725586

Epoch: 6| Step: 1
Training loss: 1.4215500354766846
Validation loss: 2.0191993713378906

Epoch: 6| Step: 2
Training loss: 2.02575945854187
Validation loss: 2.020518183708191

Epoch: 6| Step: 3
Training loss: 1.8271853923797607
Validation loss: 1.9853233695030212

Epoch: 6| Step: 4
Training loss: 1.6419402360916138
Validation loss: 2.009168883164724

Epoch: 6| Step: 5
Training loss: 1.4088948965072632
Validation loss: 1.9985966483751934

Epoch: 6| Step: 6
Training loss: 1.8346750736236572
Validation loss: 1.9987579981486003

Epoch: 6| Step: 7
Training loss: 2.091081142425537
Validation loss: 2.009156048297882

Epoch: 6| Step: 8
Training loss: 1.7845158576965332
Validation loss: 2.015537679195404

Epoch: 6| Step: 9
Training loss: 2.207825183868408
Validation loss: 2.0598583022753396

Epoch: 6| Step: 10
Training loss: 2.2478418350219727
Validation loss: 2.0894864400227866

Epoch: 6| Step: 11
Training loss: 2.1547207832336426
Validation loss: 2.0938661694526672

Epoch: 6| Step: 12
Training loss: 2.701077938079834
Validation loss: 2.1019363005956015

Epoch: 6| Step: 13
Training loss: 1.5048985481262207
Validation loss: 2.169492761294047

Epoch: 44| Step: 0
Training loss: 2.3216750621795654
Validation loss: 2.108786880970001

Epoch: 6| Step: 1
Training loss: 1.780686616897583
Validation loss: 2.132560988267263

Epoch: 6| Step: 2
Training loss: 1.9179625511169434
Validation loss: 2.117160757382711

Epoch: 6| Step: 3
Training loss: 1.8130097389221191
Validation loss: 2.1025033791859946

Epoch: 6| Step: 4
Training loss: 2.245600700378418
Validation loss: 2.025352656841278

Epoch: 6| Step: 5
Training loss: 2.12641978263855
Validation loss: 2.0197253823280334

Epoch: 6| Step: 6
Training loss: 1.8751987218856812
Validation loss: 2.022721449534098

Epoch: 6| Step: 7
Training loss: 1.7089858055114746
Validation loss: 1.9756890734036763

Epoch: 6| Step: 8
Training loss: 1.3866486549377441
Validation loss: 2.010339697202047

Epoch: 6| Step: 9
Training loss: 1.9866585731506348
Validation loss: 2.013119916121165

Epoch: 6| Step: 10
Training loss: 1.7282609939575195
Validation loss: 2.0299789905548096

Epoch: 6| Step: 11
Training loss: 1.901360034942627
Validation loss: 2.0295621156692505

Epoch: 6| Step: 12
Training loss: 2.2580983638763428
Validation loss: 2.019034127394358

Epoch: 6| Step: 13
Training loss: 2.3820722103118896
Validation loss: 2.046331604321798

Epoch: 45| Step: 0
Training loss: 1.9596774578094482
Validation loss: 2.039762477080027

Epoch: 6| Step: 1
Training loss: 1.8730847835540771
Validation loss: 2.1177833875020347

Epoch: 6| Step: 2
Training loss: 1.805920124053955
Validation loss: 2.0782292087872825

Epoch: 6| Step: 3
Training loss: 1.8459488153457642
Validation loss: 2.1004517674446106

Epoch: 6| Step: 4
Training loss: 1.3744120597839355
Validation loss: 2.0723318656285605

Epoch: 6| Step: 5
Training loss: 1.9325486421585083
Validation loss: 2.0224433143933616

Epoch: 6| Step: 6
Training loss: 2.058103561401367
Validation loss: 2.0635668635368347

Epoch: 6| Step: 7
Training loss: 1.6331419944763184
Validation loss: 2.0297597646713257

Epoch: 6| Step: 8
Training loss: 2.0838756561279297
Validation loss: 1.9697908163070679

Epoch: 6| Step: 9
Training loss: 2.3437085151672363
Validation loss: 2.039323846499125

Epoch: 6| Step: 10
Training loss: 2.4429755210876465
Validation loss: 2.030848205089569

Epoch: 6| Step: 11
Training loss: 1.4396061897277832
Validation loss: 2.0337743361790976

Epoch: 6| Step: 12
Training loss: 1.9054534435272217
Validation loss: 2.053209900856018

Epoch: 6| Step: 13
Training loss: 1.8799787759780884
Validation loss: 2.0188210209210715

Epoch: 46| Step: 0
Training loss: 1.5231506824493408
Validation loss: 2.0248195131619773

Epoch: 6| Step: 1
Training loss: 2.013580322265625
Validation loss: 2.0220410426457724

Epoch: 6| Step: 2
Training loss: 2.073452949523926
Validation loss: 2.0877398252487183

Epoch: 6| Step: 3
Training loss: 1.736978530883789
Validation loss: 2.015614648660024

Epoch: 6| Step: 4
Training loss: 1.327736258506775
Validation loss: 2.020189722379049

Epoch: 6| Step: 5
Training loss: 2.1679182052612305
Validation loss: 2.0157060027122498

Epoch: 6| Step: 6
Training loss: 2.351264476776123
Validation loss: 2.026006023089091

Epoch: 6| Step: 7
Training loss: 2.288923978805542
Validation loss: 2.024645507335663

Epoch: 6| Step: 8
Training loss: 1.7694997787475586
Validation loss: 2.004033943017324

Epoch: 6| Step: 9
Training loss: 2.4946956634521484
Validation loss: 1.9853635629018147

Epoch: 6| Step: 10
Training loss: 1.9525177478790283
Validation loss: 1.992578665415446

Epoch: 6| Step: 11
Training loss: 1.8836758136749268
Validation loss: 1.973534921805064

Epoch: 6| Step: 12
Training loss: 1.2914867401123047
Validation loss: 2.0344290335973105

Epoch: 6| Step: 13
Training loss: 1.6562505960464478
Validation loss: 2.0277801950772605

Epoch: 47| Step: 0
Training loss: 2.0650851726531982
Validation loss: 2.0149362881978354

Epoch: 6| Step: 1
Training loss: 1.9368150234222412
Validation loss: 2.052358865737915

Epoch: 6| Step: 2
Training loss: 1.868145227432251
Validation loss: 2.084985295931498

Epoch: 6| Step: 3
Training loss: 1.9285551309585571
Validation loss: 2.0915688474973044

Epoch: 6| Step: 4
Training loss: 1.9344758987426758
Validation loss: 2.0540343523025513

Epoch: 6| Step: 5
Training loss: 1.4510807991027832
Validation loss: 2.055019756158193

Epoch: 6| Step: 6
Training loss: 1.6567972898483276
Validation loss: 2.03400049606959

Epoch: 6| Step: 7
Training loss: 1.539334774017334
Validation loss: 2.007831593354543

Epoch: 6| Step: 8
Training loss: 2.2328248023986816
Validation loss: 2.03127121925354

Epoch: 6| Step: 9
Training loss: 1.6399189233779907
Validation loss: 2.0399261514345803

Epoch: 6| Step: 10
Training loss: 1.5710910558700562
Validation loss: 1.9713878631591797

Epoch: 6| Step: 11
Training loss: 1.9135386943817139
Validation loss: 2.0119481086730957

Epoch: 6| Step: 12
Training loss: 2.548597812652588
Validation loss: 1.9601455529530842

Epoch: 6| Step: 13
Training loss: 1.594027042388916
Validation loss: 2.0184367895126343

Epoch: 48| Step: 0
Training loss: 2.0232396125793457
Validation loss: 1.9645453492800395

Epoch: 6| Step: 1
Training loss: 1.7702196836471558
Validation loss: 2.0000180999437966

Epoch: 6| Step: 2
Training loss: 2.3074560165405273
Validation loss: 2.019074559211731

Epoch: 6| Step: 3
Training loss: 1.35524320602417
Validation loss: 1.9715933402379353

Epoch: 6| Step: 4
Training loss: 2.152277946472168
Validation loss: 2.018961250782013

Epoch: 6| Step: 5
Training loss: 2.100559711456299
Validation loss: 2.024446725845337

Epoch: 6| Step: 6
Training loss: 1.84096360206604
Validation loss: 2.065356453259786

Epoch: 6| Step: 7
Training loss: 1.9637048244476318
Validation loss: 2.030917207400004

Epoch: 6| Step: 8
Training loss: 1.6950490474700928
Validation loss: 2.0474444031715393

Epoch: 6| Step: 9
Training loss: 1.470281720161438
Validation loss: 2.1369091868400574

Epoch: 6| Step: 10
Training loss: 2.2031431198120117
Validation loss: 2.063783367474874

Epoch: 6| Step: 11
Training loss: 2.2193403244018555
Validation loss: 2.0906643072764077

Epoch: 6| Step: 12
Training loss: 1.3301544189453125
Validation loss: 2.07743239402771

Epoch: 6| Step: 13
Training loss: 1.9883270263671875
Validation loss: 2.0541722575823465

Epoch: 49| Step: 0
Training loss: 1.4413516521453857
Validation loss: 2.0658719738324485

Epoch: 6| Step: 1
Training loss: 2.0947632789611816
Validation loss: 2.0423925717671714

Epoch: 6| Step: 2
Training loss: 2.3101539611816406
Validation loss: 2.049470285574595

Epoch: 6| Step: 3
Training loss: 2.571932554244995
Validation loss: 2.0407460729281106

Epoch: 6| Step: 4
Training loss: 2.485356330871582
Validation loss: 2.0599533319473267

Epoch: 6| Step: 5
Training loss: 2.0481512546539307
Validation loss: 1.9796793262163799

Epoch: 6| Step: 6
Training loss: 1.34914231300354
Validation loss: 2.028885543346405

Epoch: 6| Step: 7
Training loss: 1.7789332866668701
Validation loss: 1.9721855719884236

Epoch: 6| Step: 8
Training loss: 1.272172212600708
Validation loss: 2.107706129550934

Epoch: 6| Step: 9
Training loss: 1.504805326461792
Validation loss: 2.0444666544596353

Epoch: 6| Step: 10
Training loss: 1.8164088726043701
Validation loss: 2.083778738975525

Epoch: 6| Step: 11
Training loss: 1.4004710912704468
Validation loss: 2.0562374194463096

Epoch: 6| Step: 12
Training loss: 2.4543373584747314
Validation loss: 2.03057591120402

Epoch: 6| Step: 13
Training loss: 1.1502041816711426
Validation loss: 2.0994585951169333

Epoch: 50| Step: 0
Training loss: 2.766780138015747
Validation loss: 2.076714058717092

Epoch: 6| Step: 1
Training loss: 1.7517869472503662
Validation loss: 2.0718868176142373

Epoch: 6| Step: 2
Training loss: 1.7094119787216187
Validation loss: 2.10214900970459

Epoch: 6| Step: 3
Training loss: 2.001150131225586
Validation loss: 2.1513169010480246

Epoch: 6| Step: 4
Training loss: 2.34348201751709
Validation loss: 2.096806069215139

Epoch: 6| Step: 5
Training loss: 1.691418170928955
Validation loss: 2.0509647528330484

Epoch: 6| Step: 6
Training loss: 2.2621607780456543
Validation loss: 2.054295778274536

Epoch: 6| Step: 7
Training loss: 1.7276737689971924
Validation loss: 2.0164252519607544

Epoch: 6| Step: 8
Training loss: 1.65067720413208
Validation loss: 2.0397258003552756

Epoch: 6| Step: 9
Training loss: 1.4386701583862305
Validation loss: 1.991445779800415

Epoch: 6| Step: 10
Training loss: 1.815501093864441
Validation loss: 2.0386470556259155

Epoch: 6| Step: 11
Training loss: 1.931135654449463
Validation loss: 2.038931965827942

Epoch: 6| Step: 12
Training loss: 1.9538538455963135
Validation loss: 1.9853709141413372

Epoch: 6| Step: 13
Training loss: 1.537712574005127
Validation loss: 1.986534555753072

Epoch: 51| Step: 0
Training loss: 2.2994565963745117
Validation loss: 1.9797943035761516

Epoch: 6| Step: 1
Training loss: 2.079171657562256
Validation loss: 2.040629267692566

Epoch: 6| Step: 2
Training loss: 1.8461060523986816
Validation loss: 2.0132004221280417

Epoch: 6| Step: 3
Training loss: 1.3079742193222046
Validation loss: 2.059808075428009

Epoch: 6| Step: 4
Training loss: 1.880716323852539
Validation loss: 2.08201273282369

Epoch: 6| Step: 5
Training loss: 1.394280195236206
Validation loss: 2.07353542248408

Epoch: 6| Step: 6
Training loss: 1.558326244354248
Validation loss: 2.0935643315315247

Epoch: 6| Step: 7
Training loss: 2.0526065826416016
Validation loss: 2.045238753159841

Epoch: 6| Step: 8
Training loss: 1.8301379680633545
Validation loss: 2.084052781263987

Epoch: 6| Step: 9
Training loss: 1.9215914011001587
Validation loss: 2.051659941673279

Epoch: 6| Step: 10
Training loss: 1.6505846977233887
Validation loss: 2.0655754605929055

Epoch: 6| Step: 11
Training loss: 2.0321264266967773
Validation loss: 2.043264865875244

Epoch: 6| Step: 12
Training loss: 1.6944735050201416
Validation loss: 2.0982330441474915

Epoch: 6| Step: 13
Training loss: 2.020664691925049
Validation loss: 2.0185781915982566

Epoch: 52| Step: 0
Training loss: 1.5580552816390991
Validation loss: 2.128386437892914

Epoch: 6| Step: 1
Training loss: 2.0995779037475586
Validation loss: 2.080428679784139

Epoch: 6| Step: 2
Training loss: 1.936570405960083
Validation loss: 2.0958383878072104

Epoch: 6| Step: 3
Training loss: 2.165006399154663
Validation loss: 2.133253256479899

Epoch: 6| Step: 4
Training loss: 1.7150691747665405
Validation loss: 2.104592800140381

Epoch: 6| Step: 5
Training loss: 1.2090396881103516
Validation loss: 2.058661421140035

Epoch: 6| Step: 6
Training loss: 2.7406768798828125
Validation loss: 2.103223999341329

Epoch: 6| Step: 7
Training loss: 1.8629004955291748
Validation loss: 2.005851447582245

Epoch: 6| Step: 8
Training loss: 1.5676133632659912
Validation loss: 1.9947754343350728

Epoch: 6| Step: 9
Training loss: 1.2425751686096191
Validation loss: 1.9986535708109539

Epoch: 6| Step: 10
Training loss: 1.7044118642807007
Validation loss: 2.0355571111043296

Epoch: 6| Step: 11
Training loss: 2.4361133575439453
Validation loss: 2.038890779018402

Epoch: 6| Step: 12
Training loss: 1.922541856765747
Validation loss: 2.025931497414907

Epoch: 6| Step: 13
Training loss: 1.3649752140045166
Validation loss: 1.9834233522415161

Epoch: 53| Step: 0
Training loss: 1.6246997117996216
Validation loss: 2.0352806051572165

Epoch: 6| Step: 1
Training loss: 1.356186866760254
Validation loss: 2.0796778400739035

Epoch: 6| Step: 2
Training loss: 1.9789538383483887
Validation loss: 2.012663245201111

Epoch: 6| Step: 3
Training loss: 1.8630688190460205
Validation loss: 2.1326517860094705

Epoch: 6| Step: 4
Training loss: 1.7629475593566895
Validation loss: 2.0712418953577676

Epoch: 6| Step: 5
Training loss: 1.8733763694763184
Validation loss: 2.0249730547269187

Epoch: 6| Step: 6
Training loss: 2.2969110012054443
Validation loss: 2.023778796195984

Epoch: 6| Step: 7
Training loss: 1.7301993370056152
Validation loss: 2.0539567470550537

Epoch: 6| Step: 8
Training loss: 1.5782356262207031
Validation loss: 2.0618183414141336

Epoch: 6| Step: 9
Training loss: 2.1897497177124023
Validation loss: 2.0652912259101868

Epoch: 6| Step: 10
Training loss: 1.6819944381713867
Validation loss: 2.0649895866711936

Epoch: 6| Step: 11
Training loss: 2.1408915519714355
Validation loss: 2.070779045422872

Epoch: 6| Step: 12
Training loss: 1.7277063131332397
Validation loss: 2.0822792847951255

Epoch: 6| Step: 13
Training loss: 2.0913736820220947
Validation loss: 2.0875043272972107

Epoch: 54| Step: 0
Training loss: 1.634572982788086
Validation loss: 2.04428364833196

Epoch: 6| Step: 1
Training loss: 2.385526657104492
Validation loss: 2.0454880197842917

Epoch: 6| Step: 2
Training loss: 1.769949197769165
Validation loss: 2.0198163390159607

Epoch: 6| Step: 3
Training loss: 1.9799631834030151
Validation loss: 2.003892739613851

Epoch: 6| Step: 4
Training loss: 1.4384465217590332
Validation loss: 2.0161087910334268

Epoch: 6| Step: 5
Training loss: 1.524767279624939
Validation loss: 2.0211775302886963

Epoch: 6| Step: 6
Training loss: 2.426997184753418
Validation loss: 1.9902160962422688

Epoch: 6| Step: 7
Training loss: 1.4959856271743774
Validation loss: 2.0150517423947654

Epoch: 6| Step: 8
Training loss: 1.7057971954345703
Validation loss: 2.0312284231185913

Epoch: 6| Step: 9
Training loss: 1.4642397165298462
Validation loss: 1.9981775681177776

Epoch: 6| Step: 10
Training loss: 1.368796944618225
Validation loss: 2.0204451084136963

Epoch: 6| Step: 11
Training loss: 1.419982671737671
Validation loss: 2.0416823625564575

Epoch: 6| Step: 12
Training loss: 3.031614065170288
Validation loss: 2.0597981015841165

Epoch: 6| Step: 13
Training loss: 2.055025815963745
Validation loss: 2.16147251923879

Epoch: 55| Step: 0
Training loss: 1.849535346031189
Validation loss: 2.311554193496704

Epoch: 6| Step: 1
Training loss: 1.792088508605957
Validation loss: 2.359668413798014

Epoch: 6| Step: 2
Training loss: 2.247905731201172
Validation loss: 2.360420902570089

Epoch: 6| Step: 3
Training loss: 2.8991100788116455
Validation loss: 2.241975426673889

Epoch: 6| Step: 4
Training loss: 1.697567343711853
Validation loss: 2.0846929947535195

Epoch: 6| Step: 5
Training loss: 1.593054175376892
Validation loss: 2.0543776551882424

Epoch: 6| Step: 6
Training loss: 1.7750229835510254
Validation loss: 1.9913344184557598

Epoch: 6| Step: 7
Training loss: 1.775908350944519
Validation loss: 2.0802811980247498

Epoch: 6| Step: 8
Training loss: 1.891561508178711
Validation loss: 2.0187486012776694

Epoch: 6| Step: 9
Training loss: 1.7081669569015503
Validation loss: 2.0166579286257424

Epoch: 6| Step: 10
Training loss: 1.856372594833374
Validation loss: 2.036963164806366

Epoch: 6| Step: 11
Training loss: 1.9224579334259033
Validation loss: 2.010753095149994

Epoch: 6| Step: 12
Training loss: 1.8637946844100952
Validation loss: 2.0460422237714133

Epoch: 6| Step: 13
Training loss: 1.5695838928222656
Validation loss: 2.006997307141622

Epoch: 56| Step: 0
Training loss: 1.8537678718566895
Validation loss: 2.0145050684611

Epoch: 6| Step: 1
Training loss: 1.8123317956924438
Validation loss: 2.0543906688690186

Epoch: 6| Step: 2
Training loss: 1.8771679401397705
Validation loss: 2.0996304750442505

Epoch: 6| Step: 3
Training loss: 2.086510181427002
Validation loss: 2.185398896535238

Epoch: 6| Step: 4
Training loss: 1.5821142196655273
Validation loss: 2.1608349482218423

Epoch: 6| Step: 5
Training loss: 2.0273897647857666
Validation loss: 2.110165238380432

Epoch: 6| Step: 6
Training loss: 2.0377302169799805
Validation loss: 2.0894469221433005

Epoch: 6| Step: 7
Training loss: 1.8799126148223877
Validation loss: 2.105223834514618

Epoch: 6| Step: 8
Training loss: 1.6525940895080566
Validation loss: 2.1173293590545654

Epoch: 6| Step: 9
Training loss: 1.465680718421936
Validation loss: 2.02559228738149

Epoch: 6| Step: 10
Training loss: 1.8984262943267822
Validation loss: 2.068652033805847

Epoch: 6| Step: 11
Training loss: 2.1653738021850586
Validation loss: 2.0773852268854776

Epoch: 6| Step: 12
Training loss: 2.04903507232666
Validation loss: 2.0092952052752175

Epoch: 6| Step: 13
Training loss: 1.7294957637786865
Validation loss: 2.0462592045466104

Epoch: 57| Step: 0
Training loss: 1.6481009721755981
Validation loss: 2.0525699456532798

Epoch: 6| Step: 1
Training loss: 2.00362491607666
Validation loss: 1.9971718192100525

Epoch: 6| Step: 2
Training loss: 1.605012059211731
Validation loss: 2.0367077191670737

Epoch: 6| Step: 3
Training loss: 1.6463220119476318
Validation loss: 1.991848309834798

Epoch: 6| Step: 4
Training loss: 1.1785869598388672
Validation loss: 1.9998897512753804

Epoch: 6| Step: 5
Training loss: 2.04551362991333
Validation loss: 1.9797969659169514

Epoch: 6| Step: 6
Training loss: 1.7969982624053955
Validation loss: 1.9637454152107239

Epoch: 6| Step: 7
Training loss: 1.5736863613128662
Validation loss: 2.0477794408798218

Epoch: 6| Step: 8
Training loss: 1.183260440826416
Validation loss: 1.9949844479560852

Epoch: 6| Step: 9
Training loss: 2.176335334777832
Validation loss: 2.0535128116607666

Epoch: 6| Step: 10
Training loss: 1.788238525390625
Validation loss: 2.0457557837168374

Epoch: 6| Step: 11
Training loss: 2.329108476638794
Validation loss: 2.0498958230018616

Epoch: 6| Step: 12
Training loss: 1.7189232110977173
Validation loss: 2.0699490904808044

Epoch: 6| Step: 13
Training loss: 2.6081371307373047
Validation loss: 2.091143250465393

Epoch: 58| Step: 0
Training loss: 1.8435187339782715
Validation loss: 2.1208559473355613

Epoch: 6| Step: 1
Training loss: 1.625929594039917
Validation loss: 2.1207278966903687

Epoch: 6| Step: 2
Training loss: 1.6205782890319824
Validation loss: 2.1385759115219116

Epoch: 6| Step: 3
Training loss: 1.6390409469604492
Validation loss: 2.111052672068278

Epoch: 6| Step: 4
Training loss: 1.571950078010559
Validation loss: 2.1104915936787925

Epoch: 6| Step: 5
Training loss: 1.1262102127075195
Validation loss: 2.1122403144836426

Epoch: 6| Step: 6
Training loss: 1.7937501668930054
Validation loss: 2.0442880193392434

Epoch: 6| Step: 7
Training loss: 1.5136258602142334
Validation loss: 2.0356412331263223

Epoch: 6| Step: 8
Training loss: 2.0021162033081055
Validation loss: 2.0367791255315146

Epoch: 6| Step: 9
Training loss: 1.7770789861679077
Validation loss: 2.039448300997416

Epoch: 6| Step: 10
Training loss: 2.644727945327759
Validation loss: 2.004995663960775

Epoch: 6| Step: 11
Training loss: 2.39286470413208
Validation loss: 1.9832167228062947

Epoch: 6| Step: 12
Training loss: 2.2232706546783447
Validation loss: 2.0224764347076416

Epoch: 6| Step: 13
Training loss: 2.1203651428222656
Validation loss: 1.972535212834676

Epoch: 59| Step: 0
Training loss: 2.1542811393737793
Validation loss: 1.9874707460403442

Epoch: 6| Step: 1
Training loss: 1.7022385597229004
Validation loss: 1.9869765837987263

Epoch: 6| Step: 2
Training loss: 1.0653328895568848
Validation loss: 2.058398187160492

Epoch: 6| Step: 3
Training loss: 1.92122483253479
Validation loss: 2.025716225306193

Epoch: 6| Step: 4
Training loss: 2.5028674602508545
Validation loss: 2.0632781386375427

Epoch: 6| Step: 5
Training loss: 1.244795322418213
Validation loss: 2.0895254611968994

Epoch: 6| Step: 6
Training loss: 1.2740845680236816
Validation loss: 2.055929958820343

Epoch: 6| Step: 7
Training loss: 2.2883408069610596
Validation loss: 2.0699055989583335

Epoch: 6| Step: 8
Training loss: 1.5593266487121582
Validation loss: 2.0481939911842346

Epoch: 6| Step: 9
Training loss: 1.3665797710418701
Validation loss: 2.0711716214815774

Epoch: 6| Step: 10
Training loss: 2.077007293701172
Validation loss: 2.0865657329559326

Epoch: 6| Step: 11
Training loss: 1.5741114616394043
Validation loss: 2.061799387137095

Epoch: 6| Step: 12
Training loss: 2.4005513191223145
Validation loss: 2.0922301014264426

Epoch: 6| Step: 13
Training loss: 1.6882253885269165
Validation loss: 2.0420965552330017

Epoch: 60| Step: 0
Training loss: 1.9514800310134888
Validation loss: 2.0488789478937783

Epoch: 6| Step: 1
Training loss: 2.3000810146331787
Validation loss: 2.0950318972269693

Epoch: 6| Step: 2
Training loss: 1.6500186920166016
Validation loss: 1.975643793741862

Epoch: 6| Step: 3
Training loss: 1.7943850755691528
Validation loss: 2.0060596068700156

Epoch: 6| Step: 4
Training loss: 1.32021164894104
Validation loss: 2.0101645588874817

Epoch: 6| Step: 5
Training loss: 2.107640266418457
Validation loss: 2.0416433811187744

Epoch: 6| Step: 6
Training loss: 2.142235040664673
Validation loss: 2.0807012915611267

Epoch: 6| Step: 7
Training loss: 1.115797758102417
Validation loss: 2.0288424491882324

Epoch: 6| Step: 8
Training loss: 1.357759714126587
Validation loss: 2.0758368174235025

Epoch: 6| Step: 9
Training loss: 1.5632922649383545
Validation loss: 2.1056456168492637

Epoch: 6| Step: 10
Training loss: 1.8062912225723267
Validation loss: 2.149652600288391

Epoch: 6| Step: 11
Training loss: 2.188722610473633
Validation loss: 2.1334272623062134

Epoch: 6| Step: 12
Training loss: 1.7650954723358154
Validation loss: 2.107011914253235

Epoch: 6| Step: 13
Training loss: 1.960197925567627
Validation loss: 2.150371253490448

Epoch: 61| Step: 0
Training loss: 1.3206682205200195
Validation loss: 2.056715468565623

Epoch: 6| Step: 1
Training loss: 1.172221064567566
Validation loss: 2.085477352142334

Epoch: 6| Step: 2
Training loss: 2.5343642234802246
Validation loss: 2.0526570876439414

Epoch: 6| Step: 3
Training loss: 1.255716323852539
Validation loss: 1.9987282156944275

Epoch: 6| Step: 4
Training loss: 2.8235559463500977
Validation loss: 2.0692951679229736

Epoch: 6| Step: 5
Training loss: 2.1007790565490723
Validation loss: 2.0423022707303367

Epoch: 6| Step: 6
Training loss: 2.2907395362854004
Validation loss: 2.01632567246755

Epoch: 6| Step: 7
Training loss: 1.8000175952911377
Validation loss: 2.047509471575419

Epoch: 6| Step: 8
Training loss: 1.557572364807129
Validation loss: 2.009558320045471

Epoch: 6| Step: 9
Training loss: 1.0905311107635498
Validation loss: 2.05056885878245

Epoch: 6| Step: 10
Training loss: 1.7336599826812744
Validation loss: 2.015599528948466

Epoch: 6| Step: 11
Training loss: 2.3364224433898926
Validation loss: 2.0408332347869873

Epoch: 6| Step: 12
Training loss: 1.5813632011413574
Validation loss: 2.027002453804016

Epoch: 6| Step: 13
Training loss: 1.2648472785949707
Validation loss: 2.0558241804440818

Epoch: 62| Step: 0
Training loss: 1.6742552518844604
Validation loss: 2.132840871810913

Epoch: 6| Step: 1
Training loss: 1.857322335243225
Validation loss: 2.1267857352892556

Epoch: 6| Step: 2
Training loss: 2.152968645095825
Validation loss: 2.141080379486084

Epoch: 6| Step: 3
Training loss: 2.428685188293457
Validation loss: 2.1606673995653787

Epoch: 6| Step: 4
Training loss: 1.7961848974227905
Validation loss: 2.168491840362549

Epoch: 6| Step: 5
Training loss: 1.5770609378814697
Validation loss: 2.1308650573094687

Epoch: 6| Step: 6
Training loss: 1.817448377609253
Validation loss: 2.0939414898554483

Epoch: 6| Step: 7
Training loss: 0.9191386103630066
Validation loss: 1.9779824018478394

Epoch: 6| Step: 8
Training loss: 2.226807117462158
Validation loss: 1.9690897464752197

Epoch: 6| Step: 9
Training loss: 1.6664669513702393
Validation loss: 2.044334610303243

Epoch: 6| Step: 10
Training loss: 1.5025622844696045
Validation loss: 2.0250719785690308

Epoch: 6| Step: 11
Training loss: 1.939306378364563
Validation loss: 2.036702513694763

Epoch: 6| Step: 12
Training loss: 2.192352294921875
Validation loss: 2.009783685207367

Epoch: 6| Step: 13
Training loss: 1.8012768030166626
Validation loss: 2.0181854367256165

Epoch: 63| Step: 0
Training loss: 2.199005603790283
Validation loss: 2.027381161848704

Epoch: 6| Step: 1
Training loss: 2.134830951690674
Validation loss: 2.0412895480791726

Epoch: 6| Step: 2
Training loss: 1.986382246017456
Validation loss: 2.015414834022522

Epoch: 6| Step: 3
Training loss: 1.8606514930725098
Validation loss: 2.0758159359296164

Epoch: 6| Step: 4
Training loss: 1.937409520149231
Validation loss: 2.109914461771647

Epoch: 6| Step: 5
Training loss: 2.1724114418029785
Validation loss: 2.109044591585795

Epoch: 6| Step: 6
Training loss: 1.337801456451416
Validation loss: 2.131709416707357

Epoch: 6| Step: 7
Training loss: 1.9990551471710205
Validation loss: 2.153462012608846

Epoch: 6| Step: 8
Training loss: 1.2544198036193848
Validation loss: 2.1786964337031045

Epoch: 6| Step: 9
Training loss: 1.2993286848068237
Validation loss: 2.086973269780477

Epoch: 6| Step: 10
Training loss: 1.4874796867370605
Validation loss: 2.112321933110555

Epoch: 6| Step: 11
Training loss: 1.2708390951156616
Validation loss: 2.0959081848462424

Epoch: 6| Step: 12
Training loss: 1.8048489093780518
Validation loss: 2.095459779103597

Epoch: 6| Step: 13
Training loss: 1.5047787427902222
Validation loss: 2.0153661370277405

Epoch: 64| Step: 0
Training loss: 1.448882818222046
Validation loss: 1.966670552889506

Epoch: 6| Step: 1
Training loss: 1.8272919654846191
Validation loss: 1.9991479913393657

Epoch: 6| Step: 2
Training loss: 1.5114319324493408
Validation loss: 1.9870767990748088

Epoch: 6| Step: 3
Training loss: 1.1674588918685913
Validation loss: 2.020374119281769

Epoch: 6| Step: 4
Training loss: 1.8065786361694336
Validation loss: 2.0349783897399902

Epoch: 6| Step: 5
Training loss: 1.645709753036499
Validation loss: 2.067927300930023

Epoch: 6| Step: 6
Training loss: 1.514702320098877
Validation loss: 2.0907743771870932

Epoch: 6| Step: 7
Training loss: 2.2102718353271484
Validation loss: 2.1063678860664368

Epoch: 6| Step: 8
Training loss: 2.153937339782715
Validation loss: 2.049530883630117

Epoch: 6| Step: 9
Training loss: 2.1841888427734375
Validation loss: 2.1120861768722534

Epoch: 6| Step: 10
Training loss: 1.4515326023101807
Validation loss: 2.091148237387339

Epoch: 6| Step: 11
Training loss: 1.5690873861312866
Validation loss: 2.0343674222628274

Epoch: 6| Step: 12
Training loss: 2.3695852756500244
Validation loss: 2.0059908628463745

Epoch: 6| Step: 13
Training loss: 1.7354240417480469
Validation loss: 2.060152610143026

Epoch: 65| Step: 0
Training loss: 1.3734419345855713
Validation loss: 1.9867971539497375

Epoch: 6| Step: 1
Training loss: 1.5005838871002197
Validation loss: 2.008328139781952

Epoch: 6| Step: 2
Training loss: 2.1458868980407715
Validation loss: 1.988158146540324

Epoch: 6| Step: 3
Training loss: 1.5259279012680054
Validation loss: 1.955675979455312

Epoch: 6| Step: 4
Training loss: 1.4039034843444824
Validation loss: 2.0632541179656982

Epoch: 6| Step: 5
Training loss: 1.8161771297454834
Validation loss: 2.095650831858317

Epoch: 6| Step: 6
Training loss: 1.8147327899932861
Validation loss: 2.0358869632085166

Epoch: 6| Step: 7
Training loss: 2.2861270904541016
Validation loss: 2.067227760950724

Epoch: 6| Step: 8
Training loss: 1.4755622148513794
Validation loss: 2.1445690393447876

Epoch: 6| Step: 9
Training loss: 1.9201780557632446
Validation loss: 2.1485225756963096

Epoch: 6| Step: 10
Training loss: 1.920471429824829
Validation loss: 2.0752209226290383

Epoch: 6| Step: 11
Training loss: 2.149746894836426
Validation loss: 2.1377745270729065

Epoch: 6| Step: 12
Training loss: 1.552424669265747
Validation loss: 2.129582643508911

Epoch: 6| Step: 13
Training loss: 1.6510676145553589
Validation loss: 2.084564208984375

Epoch: 66| Step: 0
Training loss: 1.2839281558990479
Validation loss: 2.1040274500846863

Epoch: 6| Step: 1
Training loss: 1.4082520008087158
Validation loss: 2.1079288919766745

Epoch: 6| Step: 2
Training loss: 1.7587040662765503
Validation loss: 2.0805599292119346

Epoch: 6| Step: 3
Training loss: 1.532438039779663
Validation loss: 2.0244919459025064

Epoch: 6| Step: 4
Training loss: 2.47796630859375
Validation loss: 2.034928639729818

Epoch: 6| Step: 5
Training loss: 1.7085351943969727
Validation loss: 1.9742600321769714

Epoch: 6| Step: 6
Training loss: 1.7856128215789795
Validation loss: 1.9962459603945415

Epoch: 6| Step: 7
Training loss: 1.926712989807129
Validation loss: 2.014105757077535

Epoch: 6| Step: 8
Training loss: 2.127110719680786
Validation loss: 2.023582915465037

Epoch: 6| Step: 9
Training loss: 2.311145305633545
Validation loss: 1.9818092981974285

Epoch: 6| Step: 10
Training loss: 1.472904920578003
Validation loss: 2.03412655989329

Epoch: 6| Step: 11
Training loss: 1.611212968826294
Validation loss: 2.0978264808654785

Epoch: 6| Step: 12
Training loss: 1.3851096630096436
Validation loss: 2.0967394510904946

Epoch: 6| Step: 13
Training loss: 1.2296922206878662
Validation loss: 2.040550688902537

Epoch: 67| Step: 0
Training loss: 1.3931005001068115
Validation loss: 2.0153178373972573

Epoch: 6| Step: 1
Training loss: 1.882178783416748
Validation loss: 2.07576318581899

Epoch: 6| Step: 2
Training loss: 0.8876984715461731
Validation loss: 2.0505011876424155

Epoch: 6| Step: 3
Training loss: 1.8334654569625854
Validation loss: 2.0631155967712402

Epoch: 6| Step: 4
Training loss: 1.4651669263839722
Validation loss: 2.1296289960543313

Epoch: 6| Step: 5
Training loss: 1.8778126239776611
Validation loss: 2.095068554083506

Epoch: 6| Step: 6
Training loss: 1.7519681453704834
Validation loss: 2.0761935313542685

Epoch: 6| Step: 7
Training loss: 1.7520071268081665
Validation loss: 2.0424651304880777

Epoch: 6| Step: 8
Training loss: 1.5239994525909424
Validation loss: 2.028820971647898

Epoch: 6| Step: 9
Training loss: 1.656614065170288
Validation loss: 1.995711088180542

Epoch: 6| Step: 10
Training loss: 2.197592258453369
Validation loss: 2.0110586086908975

Epoch: 6| Step: 11
Training loss: 1.2140618562698364
Validation loss: 2.0402949452400208

Epoch: 6| Step: 12
Training loss: 2.1007323265075684
Validation loss: 2.0287720561027527

Epoch: 6| Step: 13
Training loss: 2.696702003479004
Validation loss: 2.0294122099876404

Epoch: 68| Step: 0
Training loss: 1.9874179363250732
Validation loss: 2.0493545134862265

Epoch: 6| Step: 1
Training loss: 1.7044320106506348
Validation loss: 1.9923534790674846

Epoch: 6| Step: 2
Training loss: 1.4632173776626587
Validation loss: 2.0183869997660318

Epoch: 6| Step: 3
Training loss: 1.6536921262741089
Validation loss: 2.037786324818929

Epoch: 6| Step: 4
Training loss: 1.5515530109405518
Validation loss: 2.0936150550842285

Epoch: 6| Step: 5
Training loss: 1.1486499309539795
Validation loss: 2.055722951889038

Epoch: 6| Step: 6
Training loss: 2.3318610191345215
Validation loss: 2.1018447875976562

Epoch: 6| Step: 7
Training loss: 1.5707769393920898
Validation loss: 2.0242999792099

Epoch: 6| Step: 8
Training loss: 1.4818825721740723
Validation loss: 2.078518569469452

Epoch: 6| Step: 9
Training loss: 1.7378759384155273
Validation loss: 2.071616808573405

Epoch: 6| Step: 10
Training loss: 2.1471314430236816
Validation loss: 2.1271268725395203

Epoch: 6| Step: 11
Training loss: 2.2099344730377197
Validation loss: 2.1131370663642883

Epoch: 6| Step: 12
Training loss: 2.0483086109161377
Validation loss: 2.0649916529655457

Epoch: 6| Step: 13
Training loss: 1.2973673343658447
Validation loss: 2.0311564405759177

Epoch: 69| Step: 0
Training loss: 1.5358895063400269
Validation loss: 2.0533931255340576

Epoch: 6| Step: 1
Training loss: 1.6451034545898438
Validation loss: 2.024229864279429

Epoch: 6| Step: 2
Training loss: 1.9410181045532227
Validation loss: 2.0821717381477356

Epoch: 6| Step: 3
Training loss: 1.1122374534606934
Validation loss: 2.069775919119517

Epoch: 6| Step: 4
Training loss: 1.575463056564331
Validation loss: 2.0464843114217124

Epoch: 6| Step: 5
Training loss: 1.820993423461914
Validation loss: 2.0738109350204468

Epoch: 6| Step: 6
Training loss: 1.562377691268921
Validation loss: 2.085409382979075

Epoch: 6| Step: 7
Training loss: 2.669804096221924
Validation loss: 2.0570892691612244

Epoch: 6| Step: 8
Training loss: 2.1797752380371094
Validation loss: 2.057749013106028

Epoch: 6| Step: 9
Training loss: 1.9365103244781494
Validation loss: 1.9839804768562317

Epoch: 6| Step: 10
Training loss: 1.552250623703003
Validation loss: 2.0174546241760254

Epoch: 6| Step: 11
Training loss: 1.5026155710220337
Validation loss: 2.033257027467092

Epoch: 6| Step: 12
Training loss: 1.6938660144805908
Validation loss: 2.0584017038345337

Epoch: 6| Step: 13
Training loss: 1.0645917654037476
Validation loss: 2.0833879510561624

Epoch: 70| Step: 0
Training loss: 1.0991251468658447
Validation loss: 2.0882080793380737

Epoch: 6| Step: 1
Training loss: 2.849729299545288
Validation loss: 2.1071605881055198

Epoch: 6| Step: 2
Training loss: 1.8154411315917969
Validation loss: 2.01609468460083

Epoch: 6| Step: 3
Training loss: 1.4486252069473267
Validation loss: 2.036731938521067

Epoch: 6| Step: 4
Training loss: 1.1928223371505737
Validation loss: 2.039411723613739

Epoch: 6| Step: 5
Training loss: 1.5531105995178223
Validation loss: 1.9741158882776897

Epoch: 6| Step: 6
Training loss: 1.7390670776367188
Validation loss: 1.967850665251414

Epoch: 6| Step: 7
Training loss: 1.917723536491394
Validation loss: 2.0170881152153015

Epoch: 6| Step: 8
Training loss: 1.5092512369155884
Validation loss: 2.0463943680127463

Epoch: 6| Step: 9
Training loss: 2.335392475128174
Validation loss: 2.0344345370928445

Epoch: 6| Step: 10
Training loss: 1.2705483436584473
Validation loss: 2.036535660425822

Epoch: 6| Step: 11
Training loss: 2.5780551433563232
Validation loss: 2.1180808941523233

Epoch: 6| Step: 12
Training loss: 2.06677508354187
Validation loss: 2.1447043816248574

Epoch: 6| Step: 13
Training loss: 1.5353214740753174
Validation loss: 2.2448028723398843

Epoch: 71| Step: 0
Training loss: 1.6886885166168213
Validation loss: 2.272580146789551

Epoch: 6| Step: 1
Training loss: 2.0953879356384277
Validation loss: 2.265284220377604

Epoch: 6| Step: 2
Training loss: 1.799778938293457
Validation loss: 2.072306752204895

Epoch: 6| Step: 3
Training loss: 1.7879836559295654
Validation loss: 2.0877244671185813

Epoch: 6| Step: 4
Training loss: 1.8040598630905151
Validation loss: 1.9970912138621013

Epoch: 6| Step: 5
Training loss: 1.9393171072006226
Validation loss: 1.978575865427653

Epoch: 6| Step: 6
Training loss: 1.34395170211792
Validation loss: 2.004710634549459

Epoch: 6| Step: 7
Training loss: 1.9439148902893066
Validation loss: 2.060059348742167

Epoch: 6| Step: 8
Training loss: 1.9001089334487915
Validation loss: 1.9845258394877117

Epoch: 6| Step: 9
Training loss: 2.212407112121582
Validation loss: 2.0630890528361

Epoch: 6| Step: 10
Training loss: 1.7228994369506836
Validation loss: 2.0025800665219626

Epoch: 6| Step: 11
Training loss: 1.250117540359497
Validation loss: 2.033844252427419

Epoch: 6| Step: 12
Training loss: 1.2551701068878174
Validation loss: 2.0707544485727944

Epoch: 6| Step: 13
Training loss: 2.252723217010498
Validation loss: 2.145638028780619

Epoch: 72| Step: 0
Training loss: 1.424001693725586
Validation loss: 2.1432347695032754

Epoch: 6| Step: 1
Training loss: 1.5100111961364746
Validation loss: 2.154876391092936

Epoch: 6| Step: 2
Training loss: 1.6196762323379517
Validation loss: 2.183123310407003

Epoch: 6| Step: 3
Training loss: 2.160503625869751
Validation loss: 2.188176174958547

Epoch: 6| Step: 4
Training loss: 1.950162649154663
Validation loss: 2.1450778245925903

Epoch: 6| Step: 5
Training loss: 1.8141186237335205
Validation loss: 2.110323448975881

Epoch: 6| Step: 6
Training loss: 1.393669843673706
Validation loss: 2.0390716592470803

Epoch: 6| Step: 7
Training loss: 1.8434079885482788
Validation loss: 2.0026591221491494

Epoch: 6| Step: 8
Training loss: 1.6708885431289673
Validation loss: 2.028158267339071

Epoch: 6| Step: 9
Training loss: 1.7956123352050781
Validation loss: 2.0044673085212708

Epoch: 6| Step: 10
Training loss: 2.101820945739746
Validation loss: 2.1090298692385354

Epoch: 6| Step: 11
Training loss: 1.764642596244812
Validation loss: 2.2165558536847434

Epoch: 6| Step: 12
Training loss: 2.3574211597442627
Validation loss: 2.1773478984832764

Epoch: 6| Step: 13
Training loss: 2.5162160396575928
Validation loss: 2.118796626726786

Epoch: 73| Step: 0
Training loss: 2.3278393745422363
Validation loss: 2.004982848962148

Epoch: 6| Step: 1
Training loss: 1.4443461894989014
Validation loss: 1.9712380766868591

Epoch: 6| Step: 2
Training loss: 1.6912496089935303
Validation loss: 2.0076489051183066

Epoch: 6| Step: 3
Training loss: 1.985665202140808
Validation loss: 2.0513046383857727

Epoch: 6| Step: 4
Training loss: 0.8849623203277588
Validation loss: 2.0332926313082376

Epoch: 6| Step: 5
Training loss: 2.095280647277832
Validation loss: 2.0719884236653647

Epoch: 6| Step: 6
Training loss: 1.8598917722702026
Validation loss: 2.1093857884407043

Epoch: 6| Step: 7
Training loss: 2.015169620513916
Validation loss: 2.1904653708140054

Epoch: 6| Step: 8
Training loss: 2.127929925918579
Validation loss: 2.168579856554667

Epoch: 6| Step: 9
Training loss: 1.2835766077041626
Validation loss: 2.140638748804728

Epoch: 6| Step: 10
Training loss: 1.3702764511108398
Validation loss: 2.124639312426249

Epoch: 6| Step: 11
Training loss: 1.664698839187622
Validation loss: 2.054039637247721

Epoch: 6| Step: 12
Training loss: 2.1668128967285156
Validation loss: 2.0426244735717773

Epoch: 6| Step: 13
Training loss: 1.1785014867782593
Validation loss: 2.0376652677853904

Epoch: 74| Step: 0
Training loss: 1.7455209493637085
Validation loss: 2.064007878303528

Epoch: 6| Step: 1
Training loss: 1.7487152814865112
Validation loss: 2.0016162991523743

Epoch: 6| Step: 2
Training loss: 1.5982248783111572
Validation loss: 2.042954961458842

Epoch: 6| Step: 3
Training loss: 1.4330358505249023
Validation loss: 1.9896418650945027

Epoch: 6| Step: 4
Training loss: 1.9750866889953613
Validation loss: 2.035958548386892

Epoch: 6| Step: 5
Training loss: 1.1349925994873047
Validation loss: 1.9867528875668843

Epoch: 6| Step: 6
Training loss: 2.2113256454467773
Validation loss: 2.093758742014567

Epoch: 6| Step: 7
Training loss: 1.5858030319213867
Validation loss: 2.101201077302297

Epoch: 6| Step: 8
Training loss: 0.541589617729187
Validation loss: 2.112466891606649

Epoch: 6| Step: 9
Training loss: 2.2590391635894775
Validation loss: 2.0893103082974753

Epoch: 6| Step: 10
Training loss: 1.1003738641738892
Validation loss: 2.128260354200999

Epoch: 6| Step: 11
Training loss: 1.732369303703308
Validation loss: 2.0978743632634482

Epoch: 6| Step: 12
Training loss: 2.278444528579712
Validation loss: 2.0856716632843018

Epoch: 6| Step: 13
Training loss: 2.1747703552246094
Validation loss: 2.0525216460227966

Epoch: 75| Step: 0
Training loss: 1.38919198513031
Validation loss: 2.0449538628260293

Epoch: 6| Step: 1
Training loss: 1.6731932163238525
Validation loss: 1.975460946559906

Epoch: 6| Step: 2
Training loss: 1.6725926399230957
Validation loss: 2.0518258213996887

Epoch: 6| Step: 3
Training loss: 1.3671746253967285
Validation loss: 2.045235832532247

Epoch: 6| Step: 4
Training loss: 1.8614673614501953
Validation loss: 2.0229075948397317

Epoch: 6| Step: 5
Training loss: 1.6375043392181396
Validation loss: 2.083288391431173

Epoch: 6| Step: 6
Training loss: 1.1655017137527466
Validation loss: 2.0306262373924255

Epoch: 6| Step: 7
Training loss: 1.3675589561462402
Validation loss: 2.070979336897532

Epoch: 6| Step: 8
Training loss: 2.2653188705444336
Validation loss: 2.058137575785319

Epoch: 6| Step: 9
Training loss: 1.6745367050170898
Validation loss: 2.1423962712287903

Epoch: 6| Step: 10
Training loss: 1.6615362167358398
Validation loss: 2.040753265221914

Epoch: 6| Step: 11
Training loss: 2.005554676055908
Validation loss: 2.0700913667678833

Epoch: 6| Step: 12
Training loss: 1.643850564956665
Validation loss: 2.039686679840088

Epoch: 6| Step: 13
Training loss: 1.5745973587036133
Validation loss: 2.049025237560272

Epoch: 76| Step: 0
Training loss: 2.1437695026397705
Validation loss: 2.0602163473765054

Epoch: 6| Step: 1
Training loss: 1.6460347175598145
Validation loss: 1.940904716650645

Epoch: 6| Step: 2
Training loss: 1.6563905477523804
Validation loss: 2.0320643186569214

Epoch: 6| Step: 3
Training loss: 1.1513292789459229
Validation loss: 2.0005820393562317

Epoch: 6| Step: 4
Training loss: 1.5684192180633545
Validation loss: 2.016606112321218

Epoch: 6| Step: 5
Training loss: 1.7185301780700684
Validation loss: 2.0852442185084024

Epoch: 6| Step: 6
Training loss: 1.7169369459152222
Validation loss: 2.009172042210897

Epoch: 6| Step: 7
Training loss: 1.777705430984497
Validation loss: 2.0240171949068704

Epoch: 6| Step: 8
Training loss: 1.5028152465820312
Validation loss: 2.1106886665026345

Epoch: 6| Step: 9
Training loss: 1.414093017578125
Validation loss: 2.0685105323791504

Epoch: 6| Step: 10
Training loss: 1.7105059623718262
Validation loss: 2.0786017775535583

Epoch: 6| Step: 11
Training loss: 1.8470019102096558
Validation loss: 2.2000133196512857

Epoch: 6| Step: 12
Training loss: 1.175701379776001
Validation loss: 2.129627784093221

Epoch: 6| Step: 13
Training loss: 1.8345965147018433
Validation loss: 2.1268913944562278

Epoch: 77| Step: 0
Training loss: 2.4216115474700928
Validation loss: 2.0882993936538696

Epoch: 6| Step: 1
Training loss: 1.857992172241211
Validation loss: 2.1083515882492065

Epoch: 6| Step: 2
Training loss: 1.51655912399292
Validation loss: 2.03891928990682

Epoch: 6| Step: 3
Training loss: 1.9349563121795654
Validation loss: 2.075650691986084

Epoch: 6| Step: 4
Training loss: 1.9606355428695679
Validation loss: 2.023198942343394

Epoch: 6| Step: 5
Training loss: 1.5800193548202515
Validation loss: 2.0075738430023193

Epoch: 6| Step: 6
Training loss: 2.1051740646362305
Validation loss: 2.0232608119646707

Epoch: 6| Step: 7
Training loss: 1.6416082382202148
Validation loss: 2.0377365946769714

Epoch: 6| Step: 8
Training loss: 1.7108032703399658
Validation loss: 1.9754269917805989

Epoch: 6| Step: 9
Training loss: 1.27530837059021
Validation loss: 2.0674028396606445

Epoch: 6| Step: 10
Training loss: 1.667609691619873
Validation loss: 2.127958039442698

Epoch: 6| Step: 11
Training loss: 1.5709829330444336
Validation loss: 2.19020676612854

Epoch: 6| Step: 12
Training loss: 1.3580695390701294
Validation loss: 2.1625014543533325

Epoch: 6| Step: 13
Training loss: 1.9488670825958252
Validation loss: 2.2618127266565957

Epoch: 78| Step: 0
Training loss: 1.61343252658844
Validation loss: 2.2883506615956626

Epoch: 6| Step: 1
Training loss: 1.8050317764282227
Validation loss: 2.1698999802271524

Epoch: 6| Step: 2
Training loss: 2.1071248054504395
Validation loss: 2.1376563707987466

Epoch: 6| Step: 3
Training loss: 1.440234661102295
Validation loss: 2.1109502712885537

Epoch: 6| Step: 4
Training loss: 1.1919492483139038
Validation loss: 2.039369821548462

Epoch: 6| Step: 5
Training loss: 1.2842261791229248
Validation loss: 2.028228680292765

Epoch: 6| Step: 6
Training loss: 2.2403104305267334
Validation loss: 2.0194095770517984

Epoch: 6| Step: 7
Training loss: 1.5808508396148682
Validation loss: 2.0144134163856506

Epoch: 6| Step: 8
Training loss: 1.9484320878982544
Validation loss: 2.0060484608014426

Epoch: 6| Step: 9
Training loss: 1.402259111404419
Validation loss: 1.9818284908930461

Epoch: 6| Step: 10
Training loss: 1.7829256057739258
Validation loss: 2.052284280459086

Epoch: 6| Step: 11
Training loss: 1.3733174800872803
Validation loss: 2.0698731342951455

Epoch: 6| Step: 12
Training loss: 1.967982530593872
Validation loss: 2.0767021973927817

Epoch: 6| Step: 13
Training loss: 1.9129879474639893
Validation loss: 2.0858769615491233

Epoch: 79| Step: 0
Training loss: 1.8420578241348267
Validation loss: 2.0452470183372498

Epoch: 6| Step: 1
Training loss: 1.917405605316162
Validation loss: 2.090941925843557

Epoch: 6| Step: 2
Training loss: 1.515866756439209
Validation loss: 2.0211989084879556

Epoch: 6| Step: 3
Training loss: 1.347887396812439
Validation loss: 2.058087189992269

Epoch: 6| Step: 4
Training loss: 1.6934916973114014
Validation loss: 2.1036455829938254

Epoch: 6| Step: 5
Training loss: 1.3071134090423584
Validation loss: 2.0249046881993613

Epoch: 6| Step: 6
Training loss: 1.2779685258865356
Validation loss: 2.0696826775868735

Epoch: 6| Step: 7
Training loss: 1.925516963005066
Validation loss: 1.9795289635658264

Epoch: 6| Step: 8
Training loss: 1.6446083784103394
Validation loss: 1.9662574132283528

Epoch: 6| Step: 9
Training loss: 1.5687801837921143
Validation loss: 1.9645829995473225

Epoch: 6| Step: 10
Training loss: 1.3481084108352661
Validation loss: 1.988885482152303

Epoch: 6| Step: 11
Training loss: 1.8813971281051636
Validation loss: 2.068794310092926

Epoch: 6| Step: 12
Training loss: 1.7492694854736328
Validation loss: 2.044994135697683

Epoch: 6| Step: 13
Training loss: 1.6795954704284668
Validation loss: 2.0776327649752298

Epoch: 80| Step: 0
Training loss: 1.2565137147903442
Validation loss: 2.050601065158844

Epoch: 6| Step: 1
Training loss: 1.4428457021713257
Validation loss: 2.033579409122467

Epoch: 6| Step: 2
Training loss: 0.9362170696258545
Validation loss: 2.0814878145853677

Epoch: 6| Step: 3
Training loss: 2.02957820892334
Validation loss: 2.0960291822751365

Epoch: 6| Step: 4
Training loss: 1.7808290719985962
Validation loss: 2.0899646083513894

Epoch: 6| Step: 5
Training loss: 1.61971914768219
Validation loss: 2.1287412444750466

Epoch: 6| Step: 6
Training loss: 2.7052130699157715
Validation loss: 2.1369111140569053

Epoch: 6| Step: 7
Training loss: 1.6210124492645264
Validation loss: 2.0818448066711426

Epoch: 6| Step: 8
Training loss: 1.184288501739502
Validation loss: 2.010123908519745

Epoch: 6| Step: 9
Training loss: 1.6601884365081787
Validation loss: 2.0264370838801065

Epoch: 6| Step: 10
Training loss: 1.0719249248504639
Validation loss: 1.9961388905843098

Epoch: 6| Step: 11
Training loss: 1.6388423442840576
Validation loss: 2.0227458079655967

Epoch: 6| Step: 12
Training loss: 1.4666377305984497
Validation loss: 1.9759255051612854

Epoch: 6| Step: 13
Training loss: 2.0861120223999023
Validation loss: 1.9853055874506633

Epoch: 81| Step: 0
Training loss: 1.5731631517410278
Validation loss: 1.9975863695144653

Epoch: 6| Step: 1
Training loss: 1.6046334505081177
Validation loss: 2.027396480242411

Epoch: 6| Step: 2
Training loss: 1.2511310577392578
Validation loss: 2.0416634678840637

Epoch: 6| Step: 3
Training loss: 1.6682357788085938
Validation loss: 2.1259998083114624

Epoch: 6| Step: 4
Training loss: 1.7685366868972778
Validation loss: 2.063407778739929

Epoch: 6| Step: 5
Training loss: 2.135120391845703
Validation loss: 2.128182828426361

Epoch: 6| Step: 6
Training loss: 1.3847788572311401
Validation loss: 2.096054991086324

Epoch: 6| Step: 7
Training loss: 0.952508270740509
Validation loss: 2.0659560561180115

Epoch: 6| Step: 8
Training loss: 1.63978910446167
Validation loss: 2.053392211596171

Epoch: 6| Step: 9
Training loss: 1.7638670206069946
Validation loss: 2.025190770626068

Epoch: 6| Step: 10
Training loss: 1.4144108295440674
Validation loss: 2.0484861532847085

Epoch: 6| Step: 11
Training loss: 2.4019389152526855
Validation loss: 2.08766508102417

Epoch: 6| Step: 12
Training loss: 1.7841957807540894
Validation loss: 2.028794229030609

Epoch: 6| Step: 13
Training loss: 1.6575562953948975
Validation loss: 2.0184383193651834

Epoch: 82| Step: 0
Training loss: 1.614084005355835
Validation loss: 1.9935864011446636

Epoch: 6| Step: 1
Training loss: 1.3597663640975952
Validation loss: 2.0195003549257913

Epoch: 6| Step: 2
Training loss: 1.407883882522583
Validation loss: 2.0593419472376504

Epoch: 6| Step: 3
Training loss: 2.3376784324645996
Validation loss: 2.0710001587867737

Epoch: 6| Step: 4
Training loss: 2.236632823944092
Validation loss: 2.070322573184967

Epoch: 6| Step: 5
Training loss: 1.7288163900375366
Validation loss: 2.1129779616991677

Epoch: 6| Step: 6
Training loss: 1.8350236415863037
Validation loss: 2.043780823548635

Epoch: 6| Step: 7
Training loss: 0.9641063809394836
Validation loss: 2.0432161887486777

Epoch: 6| Step: 8
Training loss: 1.4704163074493408
Validation loss: 1.9980520804723103

Epoch: 6| Step: 9
Training loss: 1.639765739440918
Validation loss: 2.0305003921190896

Epoch: 6| Step: 10
Training loss: 1.003301978111267
Validation loss: 2.100765287876129

Epoch: 6| Step: 11
Training loss: 1.9894824028015137
Validation loss: 2.0362948973973594

Epoch: 6| Step: 12
Training loss: 0.9840114116668701
Validation loss: 2.098385433355967

Epoch: 6| Step: 13
Training loss: 1.5108325481414795
Validation loss: 2.150335172812144

Epoch: 83| Step: 0
Training loss: 2.0253024101257324
Validation loss: 2.1335841615994773

Epoch: 6| Step: 1
Training loss: 1.4469492435455322
Validation loss: 2.106463293234507

Epoch: 6| Step: 2
Training loss: 1.5775330066680908
Validation loss: 2.1367612878481546

Epoch: 6| Step: 3
Training loss: 1.6948280334472656
Validation loss: 2.1212265690167746

Epoch: 6| Step: 4
Training loss: 1.4531357288360596
Validation loss: 2.1140138109525046

Epoch: 6| Step: 5
Training loss: 1.3191132545471191
Validation loss: 2.0271779894828796

Epoch: 6| Step: 6
Training loss: 1.3257765769958496
Validation loss: 2.0040153861045837

Epoch: 6| Step: 7
Training loss: 1.8132930994033813
Validation loss: 2.051404039065043

Epoch: 6| Step: 8
Training loss: 2.062981605529785
Validation loss: 2.0046454469362893

Epoch: 6| Step: 9
Training loss: 1.7362639904022217
Validation loss: 2.024114429950714

Epoch: 6| Step: 10
Training loss: 2.0588507652282715
Validation loss: 2.12339719136556

Epoch: 6| Step: 11
Training loss: 1.6171923875808716
Validation loss: 2.029874046643575

Epoch: 6| Step: 12
Training loss: 1.7278145551681519
Validation loss: 2.092063824335734

Epoch: 6| Step: 13
Training loss: 1.5558910369873047
Validation loss: 2.061653951803843

Epoch: 84| Step: 0
Training loss: 1.2059768438339233
Validation loss: 2.0842446088790894

Epoch: 6| Step: 1
Training loss: 1.5289535522460938
Validation loss: 2.087476909160614

Epoch: 6| Step: 2
Training loss: 1.3443691730499268
Validation loss: 2.215799649556478

Epoch: 6| Step: 3
Training loss: 1.6654369831085205
Validation loss: 2.200147529443105

Epoch: 6| Step: 4
Training loss: 1.6273061037063599
Validation loss: 2.2297666470209756

Epoch: 6| Step: 5
Training loss: 2.203883409500122
Validation loss: 2.1607556343078613

Epoch: 6| Step: 6
Training loss: 1.6441922187805176
Validation loss: 2.098066806793213

Epoch: 6| Step: 7
Training loss: 1.8862935304641724
Validation loss: 2.052208880583445

Epoch: 6| Step: 8
Training loss: 1.167675256729126
Validation loss: 1.9936587015787761

Epoch: 6| Step: 9
Training loss: 1.0602107048034668
Validation loss: 1.9973068833351135

Epoch: 6| Step: 10
Training loss: 2.1978864669799805
Validation loss: 2.0653428634007773

Epoch: 6| Step: 11
Training loss: 2.1348979473114014
Validation loss: 2.0006513794263205

Epoch: 6| Step: 12
Training loss: 1.3630636930465698
Validation loss: 2.0018842617670694

Epoch: 6| Step: 13
Training loss: 1.8819210529327393
Validation loss: 2.070688525835673

Epoch: 85| Step: 0
Training loss: 1.3206419944763184
Validation loss: 2.0376356641451516

Epoch: 6| Step: 1
Training loss: 1.6892857551574707
Validation loss: 2.0572542945543923

Epoch: 6| Step: 2
Training loss: 1.838985800743103
Validation loss: 2.079391062259674

Epoch: 6| Step: 3
Training loss: 1.014082908630371
Validation loss: 2.0739412903785706

Epoch: 6| Step: 4
Training loss: 2.0341837406158447
Validation loss: 2.1548758347829184

Epoch: 6| Step: 5
Training loss: 1.6359788179397583
Validation loss: 2.167204737663269

Epoch: 6| Step: 6
Training loss: 1.7487094402313232
Validation loss: 2.154559592405955

Epoch: 6| Step: 7
Training loss: 0.8897179365158081
Validation loss: 2.0865095059076944

Epoch: 6| Step: 8
Training loss: 1.521423578262329
Validation loss: 2.0830577611923218

Epoch: 6| Step: 9
Training loss: 1.4300460815429688
Validation loss: 2.108535965283712

Epoch: 6| Step: 10
Training loss: 1.591981291770935
Validation loss: 1.999867061773936

Epoch: 6| Step: 11
Training loss: 1.4246577024459839
Validation loss: 2.0073782404263816

Epoch: 6| Step: 12
Training loss: 2.200242042541504
Validation loss: 2.0411195953687034

Epoch: 6| Step: 13
Training loss: 1.254500389099121
Validation loss: 1.997728168964386

Epoch: 86| Step: 0
Training loss: 1.4237966537475586
Validation loss: 2.006435751914978

Epoch: 6| Step: 1
Training loss: 2.032090902328491
Validation loss: 1.997433106104533

Epoch: 6| Step: 2
Training loss: 1.4332988262176514
Validation loss: 2.035931885242462

Epoch: 6| Step: 3
Training loss: 1.560091495513916
Validation loss: 2.027481496334076

Epoch: 6| Step: 4
Training loss: 1.618193507194519
Validation loss: 2.102825919787089

Epoch: 6| Step: 5
Training loss: 1.2668156623840332
Validation loss: 2.066013594468435

Epoch: 6| Step: 6
Training loss: 1.9455620050430298
Validation loss: 2.1469815572102866

Epoch: 6| Step: 7
Training loss: 1.7516729831695557
Validation loss: 2.1413022677103677

Epoch: 6| Step: 8
Training loss: 1.307311773300171
Validation loss: 2.1498942375183105

Epoch: 6| Step: 9
Training loss: 1.496607780456543
Validation loss: 2.0894585053126016

Epoch: 6| Step: 10
Training loss: 1.428632140159607
Validation loss: 2.1151289343833923

Epoch: 6| Step: 11
Training loss: 1.6830012798309326
Validation loss: 2.058852791786194

Epoch: 6| Step: 12
Training loss: 1.7938408851623535
Validation loss: 2.0913579066594443

Epoch: 6| Step: 13
Training loss: 1.2431163787841797
Validation loss: 2.074816107749939

Epoch: 87| Step: 0
Training loss: 1.1888116598129272
Validation loss: 2.0066128969192505

Epoch: 6| Step: 1
Training loss: 1.962799072265625
Validation loss: 2.0796135663986206

Epoch: 6| Step: 2
Training loss: 1.6959245204925537
Validation loss: 2.0748292207717896

Epoch: 6| Step: 3
Training loss: 1.021168828010559
Validation loss: 2.0383562048276267

Epoch: 6| Step: 4
Training loss: 1.115701675415039
Validation loss: 2.010031839211782

Epoch: 6| Step: 5
Training loss: 1.2535521984100342
Validation loss: 2.040787696838379

Epoch: 6| Step: 6
Training loss: 1.4117510318756104
Validation loss: 2.0204431811968484

Epoch: 6| Step: 7
Training loss: 1.8666532039642334
Validation loss: 2.060162623723348

Epoch: 6| Step: 8
Training loss: 1.7601337432861328
Validation loss: 2.0691561301549277

Epoch: 6| Step: 9
Training loss: 1.0226759910583496
Validation loss: 2.057108521461487

Epoch: 6| Step: 10
Training loss: 2.0555107593536377
Validation loss: 2.0545573830604553

Epoch: 6| Step: 11
Training loss: 1.6795328855514526
Validation loss: 2.1097113887468972

Epoch: 6| Step: 12
Training loss: 1.1733351945877075
Validation loss: 2.076492706934611

Epoch: 6| Step: 13
Training loss: 1.7960855960845947
Validation loss: 2.1161956985791526

Epoch: 88| Step: 0
Training loss: 1.8610827922821045
Validation loss: 2.097698708375295

Epoch: 6| Step: 1
Training loss: 0.8458666205406189
Validation loss: 2.1740505695343018

Epoch: 6| Step: 2
Training loss: 1.1567203998565674
Validation loss: 2.107892910639445

Epoch: 6| Step: 3
Training loss: 1.3210855722427368
Validation loss: 2.105681896209717

Epoch: 6| Step: 4
Training loss: 1.9190400838851929
Validation loss: 2.0291298429171243

Epoch: 6| Step: 5
Training loss: 1.5861070156097412
Validation loss: 2.0216769576072693

Epoch: 6| Step: 6
Training loss: 2.0026752948760986
Validation loss: 2.0462536017100015

Epoch: 6| Step: 7
Training loss: 1.0077509880065918
Validation loss: 1.9878840446472168

Epoch: 6| Step: 8
Training loss: 2.1703977584838867
Validation loss: 2.003325661023458

Epoch: 6| Step: 9
Training loss: 1.7301826477050781
Validation loss: 2.0661748250325522

Epoch: 6| Step: 10
Training loss: 1.5543204545974731
Validation loss: 2.0181267460187278

Epoch: 6| Step: 11
Training loss: 1.721017837524414
Validation loss: 2.0378945668538413

Epoch: 6| Step: 12
Training loss: 1.2613400220870972
Validation loss: 2.026930034160614

Epoch: 6| Step: 13
Training loss: 1.3987241983413696
Validation loss: 2.0707356532414756

Epoch: 89| Step: 0
Training loss: 1.6297550201416016
Validation loss: 2.0599422454833984

Epoch: 6| Step: 1
Training loss: 1.4525747299194336
Validation loss: 2.1159690022468567

Epoch: 6| Step: 2
Training loss: 1.550626516342163
Validation loss: 2.1033786137898765

Epoch: 6| Step: 3
Training loss: 1.5286437273025513
Validation loss: 2.1382086873054504

Epoch: 6| Step: 4
Training loss: 0.9782317280769348
Validation loss: 2.099134643872579

Epoch: 6| Step: 5
Training loss: 1.5294482707977295
Validation loss: 2.056724707285563

Epoch: 6| Step: 6
Training loss: 1.4254812002182007
Validation loss: 2.0595474243164062

Epoch: 6| Step: 7
Training loss: 1.4799662828445435
Validation loss: 2.0516589879989624

Epoch: 6| Step: 8
Training loss: 1.8119009733200073
Validation loss: 2.0391710996627808

Epoch: 6| Step: 9
Training loss: 1.2037523984909058
Validation loss: 2.021342655022939

Epoch: 6| Step: 10
Training loss: 1.4426547288894653
Validation loss: 2.007046401500702

Epoch: 6| Step: 11
Training loss: 1.6171742677688599
Validation loss: 2.08179771900177

Epoch: 6| Step: 12
Training loss: 2.118353843688965
Validation loss: 1.9891878366470337

Epoch: 6| Step: 13
Training loss: 1.2535209655761719
Validation loss: 2.051205277442932

Epoch: 90| Step: 0
Training loss: 1.2678989171981812
Validation loss: 2.029651920000712

Epoch: 6| Step: 1
Training loss: 1.3234307765960693
Validation loss: 2.0511373480161033

Epoch: 6| Step: 2
Training loss: 1.2890324592590332
Validation loss: 2.1299362182617188

Epoch: 6| Step: 3
Training loss: 1.7785890102386475
Validation loss: 2.0864674846331277

Epoch: 6| Step: 4
Training loss: 1.077560544013977
Validation loss: 2.059773246447245

Epoch: 6| Step: 5
Training loss: 1.3536171913146973
Validation loss: 2.0628230770428977

Epoch: 6| Step: 6
Training loss: 1.1408717632293701
Validation loss: 2.0756964882214866

Epoch: 6| Step: 7
Training loss: 1.8224328756332397
Validation loss: 2.106251279513041

Epoch: 6| Step: 8
Training loss: 1.7897132635116577
Validation loss: 2.062449634075165

Epoch: 6| Step: 9
Training loss: 2.327363967895508
Validation loss: 2.0372394323349

Epoch: 6| Step: 10
Training loss: 1.1137065887451172
Validation loss: 2.008989691734314

Epoch: 6| Step: 11
Training loss: 1.0445740222930908
Validation loss: 2.0015130639076233

Epoch: 6| Step: 12
Training loss: 2.0222585201263428
Validation loss: 2.039746185143789

Epoch: 6| Step: 13
Training loss: 1.6744383573532104
Validation loss: 2.096614638964335

Epoch: 91| Step: 0
Training loss: 1.099522352218628
Validation loss: 2.1738640666007996

Epoch: 6| Step: 1
Training loss: 1.6575591564178467
Validation loss: 2.1961200634638467

Epoch: 6| Step: 2
Training loss: 2.3078677654266357
Validation loss: 2.2437251011530557

Epoch: 6| Step: 3
Training loss: 1.5384849309921265
Validation loss: 2.2089123924573264

Epoch: 6| Step: 4
Training loss: 1.6546919345855713
Validation loss: 2.1853867769241333

Epoch: 6| Step: 5
Training loss: 1.7169688940048218
Validation loss: 2.0965853134791055

Epoch: 6| Step: 6
Training loss: 1.051182508468628
Validation loss: 2.031811773777008

Epoch: 6| Step: 7
Training loss: 1.5810301303863525
Validation loss: 2.0592504739761353

Epoch: 6| Step: 8
Training loss: 1.5965404510498047
Validation loss: 2.059805750846863

Epoch: 6| Step: 9
Training loss: 1.6884853839874268
Validation loss: 1.963383714358012

Epoch: 6| Step: 10
Training loss: 1.4050816297531128
Validation loss: 2.058997869491577

Epoch: 6| Step: 11
Training loss: 1.4012386798858643
Validation loss: 2.0780072013537088

Epoch: 6| Step: 12
Training loss: 1.4904989004135132
Validation loss: 1.9582588871320088

Epoch: 6| Step: 13
Training loss: 1.5300453901290894
Validation loss: 2.0103276570638022

Epoch: 92| Step: 0
Training loss: 2.1040754318237305
Validation loss: 2.0646278460820517

Epoch: 6| Step: 1
Training loss: 0.7095934748649597
Validation loss: 2.1087893644968667

Epoch: 6| Step: 2
Training loss: 1.7691731452941895
Validation loss: 2.141285479068756

Epoch: 6| Step: 3
Training loss: 1.4052329063415527
Validation loss: 2.102817098299662

Epoch: 6| Step: 4
Training loss: 1.4482454061508179
Validation loss: 2.058627208073934

Epoch: 6| Step: 5
Training loss: 1.3132323026657104
Validation loss: 2.10649565855662

Epoch: 6| Step: 6
Training loss: 0.7820993661880493
Validation loss: 2.052030702431997

Epoch: 6| Step: 7
Training loss: 1.5590462684631348
Validation loss: 2.102741320927938

Epoch: 6| Step: 8
Training loss: 1.163449764251709
Validation loss: 2.0572441816329956

Epoch: 6| Step: 9
Training loss: 1.8459954261779785
Validation loss: 2.050523022810618

Epoch: 6| Step: 10
Training loss: 2.154017448425293
Validation loss: 2.0459647178649902

Epoch: 6| Step: 11
Training loss: 0.9197207689285278
Validation loss: 2.0308063626289368

Epoch: 6| Step: 12
Training loss: 1.2790553569793701
Validation loss: 2.123207072416941

Epoch: 6| Step: 13
Training loss: 2.214576005935669
Validation loss: 2.1576448480288186

Epoch: 93| Step: 0
Training loss: 1.3308234214782715
Validation loss: 2.1790106892585754

Epoch: 6| Step: 1
Training loss: 2.393019199371338
Validation loss: 2.225724975268046

Epoch: 6| Step: 2
Training loss: 1.3029406070709229
Validation loss: 2.223209341367086

Epoch: 6| Step: 3
Training loss: 1.3211841583251953
Validation loss: 2.187870184580485

Epoch: 6| Step: 4
Training loss: 1.510399341583252
Validation loss: 2.0523443818092346

Epoch: 6| Step: 5
Training loss: 1.3702688217163086
Validation loss: 2.0716488361358643

Epoch: 6| Step: 6
Training loss: 1.3624927997589111
Validation loss: 2.074876328309377

Epoch: 6| Step: 7
Training loss: 1.0601520538330078
Validation loss: 2.0851359168688455

Epoch: 6| Step: 8
Training loss: 1.2931464910507202
Validation loss: 2.084631641705831

Epoch: 6| Step: 9
Training loss: 1.0656073093414307
Validation loss: 1.9798477093378704

Epoch: 6| Step: 10
Training loss: 2.066610813140869
Validation loss: 2.0592637260754905

Epoch: 6| Step: 11
Training loss: 1.6148028373718262
Validation loss: 2.0618919134140015

Epoch: 6| Step: 12
Training loss: 1.6670777797698975
Validation loss: 2.0703502098719277

Epoch: 6| Step: 13
Training loss: 2.200019359588623
Validation loss: 2.118998885154724

Epoch: 94| Step: 0
Training loss: 0.8948720097541809
Validation loss: 2.0759580532709756

Epoch: 6| Step: 1
Training loss: 1.418520212173462
Validation loss: 2.1301913261413574

Epoch: 6| Step: 2
Training loss: 1.5946078300476074
Validation loss: 2.0943679809570312

Epoch: 6| Step: 3
Training loss: 2.0208628177642822
Validation loss: 2.0372011065483093

Epoch: 6| Step: 4
Training loss: 1.6942086219787598
Validation loss: 2.080031176408132

Epoch: 6| Step: 5
Training loss: 0.9787195324897766
Validation loss: 2.028017222881317

Epoch: 6| Step: 6
Training loss: 1.3646233081817627
Validation loss: 2.0642350713411965

Epoch: 6| Step: 7
Training loss: 1.4306838512420654
Validation loss: 1.9950955112775166

Epoch: 6| Step: 8
Training loss: 1.9805299043655396
Validation loss: 2.0457833409309387

Epoch: 6| Step: 9
Training loss: 1.8187001943588257
Validation loss: 2.022010107835134

Epoch: 6| Step: 10
Training loss: 1.0620590448379517
Validation loss: 1.9670881827672322

Epoch: 6| Step: 11
Training loss: 1.234012246131897
Validation loss: 2.008632322152456

Epoch: 6| Step: 12
Training loss: 1.5486998558044434
Validation loss: 2.033994495868683

Epoch: 6| Step: 13
Training loss: 1.1837248802185059
Validation loss: 2.0797021190325418

Epoch: 95| Step: 0
Training loss: 1.1162017583847046
Validation loss: 2.0284563302993774

Epoch: 6| Step: 1
Training loss: 1.213834524154663
Validation loss: 2.0316357215245566

Epoch: 6| Step: 2
Training loss: 2.0692858695983887
Validation loss: 2.056751847267151

Epoch: 6| Step: 3
Training loss: 1.8603001832962036
Validation loss: 2.0975676774978638

Epoch: 6| Step: 4
Training loss: 1.0658071041107178
Validation loss: 2.059409419695536

Epoch: 6| Step: 5
Training loss: 1.0238041877746582
Validation loss: 2.0480892856915793

Epoch: 6| Step: 6
Training loss: 1.3519952297210693
Validation loss: 2.039145767688751

Epoch: 6| Step: 7
Training loss: 0.9347206354141235
Validation loss: 2.0527410904566445

Epoch: 6| Step: 8
Training loss: 1.7456732988357544
Validation loss: 2.02564404408137

Epoch: 6| Step: 9
Training loss: 1.8387563228607178
Validation loss: 2.020204464594523

Epoch: 6| Step: 10
Training loss: 0.9428440928459167
Validation loss: 1.9963481426239014

Epoch: 6| Step: 11
Training loss: 1.6905795335769653
Validation loss: 2.018780847390493

Epoch: 6| Step: 12
Training loss: 1.2437666654586792
Validation loss: 2.075513482093811

Epoch: 6| Step: 13
Training loss: 1.6640329360961914
Validation loss: 2.044285992781321

Epoch: 96| Step: 0
Training loss: 1.5494493246078491
Validation loss: 2.0801029801368713

Epoch: 6| Step: 1
Training loss: 1.6087453365325928
Validation loss: 2.05913378794988

Epoch: 6| Step: 2
Training loss: 1.3147060871124268
Validation loss: 2.0380923549334207

Epoch: 6| Step: 3
Training loss: 1.439409852027893
Validation loss: 2.030129154523214

Epoch: 6| Step: 4
Training loss: 1.005176305770874
Validation loss: 2.10485049088796

Epoch: 6| Step: 5
Training loss: 1.8891582489013672
Validation loss: 2.0611879030863443

Epoch: 6| Step: 6
Training loss: 1.2350666522979736
Validation loss: 2.1102558771769204

Epoch: 6| Step: 7
Training loss: 1.2540339231491089
Validation loss: 2.0596465468406677

Epoch: 6| Step: 8
Training loss: 0.9211046695709229
Validation loss: 2.0546845197677612

Epoch: 6| Step: 9
Training loss: 1.2012150287628174
Validation loss: 2.0481487115224204

Epoch: 6| Step: 10
Training loss: 1.287245273590088
Validation loss: 2.085103710492452

Epoch: 6| Step: 11
Training loss: 1.8690690994262695
Validation loss: 2.1352071166038513

Epoch: 6| Step: 12
Training loss: 1.596228837966919
Validation loss: 2.082490384578705

Epoch: 6| Step: 13
Training loss: 1.8051323890686035
Validation loss: 2.0316035548845925

Epoch: 97| Step: 0
Training loss: 1.135664939880371
Validation loss: 2.03300811847051

Epoch: 6| Step: 1
Training loss: 1.10223388671875
Validation loss: 1.9898030161857605

Epoch: 6| Step: 2
Training loss: 1.1206188201904297
Validation loss: 2.0105106234550476

Epoch: 6| Step: 3
Training loss: 1.2818124294281006
Validation loss: 2.040979266166687

Epoch: 6| Step: 4
Training loss: 1.2461134195327759
Validation loss: 2.107563098271688

Epoch: 6| Step: 5
Training loss: 1.3252309560775757
Validation loss: 2.125957210858663

Epoch: 6| Step: 6
Training loss: 1.6701370477676392
Validation loss: 2.0994432171185813

Epoch: 6| Step: 7
Training loss: 1.5376977920532227
Validation loss: 2.1122485796610513

Epoch: 6| Step: 8
Training loss: 1.2031400203704834
Validation loss: 2.0873891711235046

Epoch: 6| Step: 9
Training loss: 1.562990427017212
Validation loss: 2.053839683532715

Epoch: 6| Step: 10
Training loss: 1.5260417461395264
Validation loss: 2.0120189984639487

Epoch: 6| Step: 11
Training loss: 1.710004210472107
Validation loss: 2.040197014808655

Epoch: 6| Step: 12
Training loss: 1.1673983335494995
Validation loss: 2.0550782680511475

Epoch: 6| Step: 13
Training loss: 1.7365553379058838
Validation loss: 2.068748116493225

Epoch: 98| Step: 0
Training loss: 1.2836776971817017
Validation loss: 2.0251484314600625

Epoch: 6| Step: 1
Training loss: 1.137145757675171
Validation loss: 2.035768191019694

Epoch: 6| Step: 2
Training loss: 1.45595383644104
Validation loss: 2.0605428218841553

Epoch: 6| Step: 3
Training loss: 1.3072375059127808
Validation loss: 2.0525378783543906

Epoch: 6| Step: 4
Training loss: 1.6014370918273926
Validation loss: 2.167841653029124

Epoch: 6| Step: 5
Training loss: 2.099247694015503
Validation loss: 2.1827897826830545

Epoch: 6| Step: 6
Training loss: 1.1390869617462158
Validation loss: 2.1962966918945312

Epoch: 6| Step: 7
Training loss: 1.5617516040802002
Validation loss: 2.213179071744283

Epoch: 6| Step: 8
Training loss: 1.79311203956604
Validation loss: 2.1593329111735025

Epoch: 6| Step: 9
Training loss: 1.7055988311767578
Validation loss: 2.069985310236613

Epoch: 6| Step: 10
Training loss: 1.084097146987915
Validation loss: 1.9597079753875732

Epoch: 6| Step: 11
Training loss: 1.124027967453003
Validation loss: 2.041450043519338

Epoch: 6| Step: 12
Training loss: 1.7203197479248047
Validation loss: 2.0288658142089844

Epoch: 6| Step: 13
Training loss: 1.2546453475952148
Validation loss: 2.0028151075045266

Epoch: 99| Step: 0
Training loss: 1.9397284984588623
Validation loss: 2.012888471285502

Epoch: 6| Step: 1
Training loss: 1.2550008296966553
Validation loss: 2.0553137063980103

Epoch: 6| Step: 2
Training loss: 1.059065580368042
Validation loss: 2.0641324321428933

Epoch: 6| Step: 3
Training loss: 1.5412306785583496
Validation loss: 2.0710222323735556

Epoch: 6| Step: 4
Training loss: 1.3775951862335205
Validation loss: 2.050984183947245

Epoch: 6| Step: 5
Training loss: 1.9206434488296509
Validation loss: 2.1166968941688538

Epoch: 6| Step: 6
Training loss: 1.3638355731964111
Validation loss: 2.1363681157430015

Epoch: 6| Step: 7
Training loss: 1.1237363815307617
Validation loss: 2.1986502210299173

Epoch: 6| Step: 8
Training loss: 0.8747004866600037
Validation loss: 2.116883873939514

Epoch: 6| Step: 9
Training loss: 1.594165325164795
Validation loss: 2.1595411896705627

Epoch: 6| Step: 10
Training loss: 1.1092402935028076
Validation loss: 2.1067784627278647

Epoch: 6| Step: 11
Training loss: 1.0332424640655518
Validation loss: 2.1117950876553855

Epoch: 6| Step: 12
Training loss: 1.623286485671997
Validation loss: 2.049397965272268

Epoch: 6| Step: 13
Training loss: 1.1691689491271973
Validation loss: 2.002147674560547

Epoch: 100| Step: 0
Training loss: 1.5772194862365723
Validation loss: 2.089447319507599

Epoch: 6| Step: 1
Training loss: 1.430688738822937
Validation loss: 2.0743149320284524

Epoch: 6| Step: 2
Training loss: 1.923547387123108
Validation loss: 1.9916887482007344

Epoch: 6| Step: 3
Training loss: 1.4090261459350586
Validation loss: 2.0797223647435508

Epoch: 6| Step: 4
Training loss: 2.312455177307129
Validation loss: 1.9854060014088948

Epoch: 6| Step: 5
Training loss: 1.2768901586532593
Validation loss: 2.018912692864736

Epoch: 6| Step: 6
Training loss: 1.4237995147705078
Validation loss: 2.043381849924723

Epoch: 6| Step: 7
Training loss: 1.0173377990722656
Validation loss: 2.0742299954096475

Epoch: 6| Step: 8
Training loss: 0.9776910543441772
Validation loss: 2.0583011309305825

Epoch: 6| Step: 9
Training loss: 1.252933382987976
Validation loss: 2.1005404591560364

Epoch: 6| Step: 10
Training loss: 1.2722477912902832
Validation loss: 2.1319074233373008

Epoch: 6| Step: 11
Training loss: 1.3850080966949463
Validation loss: 2.0537131627400718

Epoch: 6| Step: 12
Training loss: 1.4631102085113525
Validation loss: 2.035949091116587

Epoch: 6| Step: 13
Training loss: 1.4847455024719238
Validation loss: 2.018691897392273

Epoch: 101| Step: 0
Training loss: 1.1096619367599487
Validation loss: 2.0265411337216697

Epoch: 6| Step: 1
Training loss: 1.7474759817123413
Validation loss: 1.9610151251157124

Epoch: 6| Step: 2
Training loss: 1.4571547508239746
Validation loss: 2.029715617497762

Epoch: 6| Step: 3
Training loss: 1.5893734693527222
Validation loss: 2.0485070943832397

Epoch: 6| Step: 4
Training loss: 1.065657138824463
Validation loss: 2.007966240247091

Epoch: 6| Step: 5
Training loss: 1.3677347898483276
Validation loss: 2.0730045636494956

Epoch: 6| Step: 6
Training loss: 1.207639217376709
Validation loss: 2.0976871053377786

Epoch: 6| Step: 7
Training loss: 1.7647767066955566
Validation loss: 2.080655833085378

Epoch: 6| Step: 8
Training loss: 1.435124397277832
Validation loss: 2.1493491331736245

Epoch: 6| Step: 9
Training loss: 0.8061534762382507
Validation loss: 2.1215362350145974

Epoch: 6| Step: 10
Training loss: 1.6189208030700684
Validation loss: 2.124460220336914

Epoch: 6| Step: 11
Training loss: 1.746681809425354
Validation loss: 2.0475621620814004

Epoch: 6| Step: 12
Training loss: 1.686675786972046
Validation loss: 2.0333933234214783

Epoch: 6| Step: 13
Training loss: 1.4566004276275635
Validation loss: 1.9687318007151287

Epoch: 102| Step: 0
Training loss: 1.3497998714447021
Validation loss: 2.0212803284327188

Epoch: 6| Step: 1
Training loss: 1.6319704055786133
Validation loss: 1.9880647659301758

Epoch: 6| Step: 2
Training loss: 1.9564534425735474
Validation loss: 2.0422075986862183

Epoch: 6| Step: 3
Training loss: 1.359581470489502
Validation loss: 2.0247925519943237

Epoch: 6| Step: 4
Training loss: 1.2054240703582764
Validation loss: 2.0669538180033364

Epoch: 6| Step: 5
Training loss: 1.6470674276351929
Validation loss: 2.1618060866991677

Epoch: 6| Step: 6
Training loss: 1.1642003059387207
Validation loss: 2.115711490313212

Epoch: 6| Step: 7
Training loss: 1.4172828197479248
Validation loss: 2.123670001824697

Epoch: 6| Step: 8
Training loss: 1.5855685472488403
Validation loss: 2.0850653847058616

Epoch: 6| Step: 9
Training loss: 1.0182905197143555
Validation loss: 2.050131320953369

Epoch: 6| Step: 10
Training loss: 1.3931502103805542
Validation loss: 2.1134713888168335

Epoch: 6| Step: 11
Training loss: 1.1741888523101807
Validation loss: 2.0138085881868997

Epoch: 6| Step: 12
Training loss: 0.7486779093742371
Validation loss: 2.0368038217226663

Epoch: 6| Step: 13
Training loss: 1.8614161014556885
Validation loss: 2.0217248797416687

Epoch: 103| Step: 0
Training loss: 1.1860072612762451
Validation loss: 2.024409313996633

Epoch: 6| Step: 1
Training loss: 1.6904215812683105
Validation loss: 2.0991796056429544

Epoch: 6| Step: 2
Training loss: 1.6952149868011475
Validation loss: 2.079517364501953

Epoch: 6| Step: 3
Training loss: 1.0920497179031372
Validation loss: 2.0211051305135093

Epoch: 6| Step: 4
Training loss: 1.9036812782287598
Validation loss: 2.1009658376375833

Epoch: 6| Step: 5
Training loss: 1.3392984867095947
Validation loss: 2.03692489862442

Epoch: 6| Step: 6
Training loss: 1.362869381904602
Validation loss: 2.0220353603363037

Epoch: 6| Step: 7
Training loss: 0.7724952697753906
Validation loss: 2.0000434716542563

Epoch: 6| Step: 8
Training loss: 1.596201777458191
Validation loss: 2.0150934060414634

Epoch: 6| Step: 9
Training loss: 0.819725513458252
Validation loss: 2.0580297907193503

Epoch: 6| Step: 10
Training loss: 1.2274502515792847
Validation loss: 2.0777358412742615

Epoch: 6| Step: 11
Training loss: 1.3283658027648926
Validation loss: 2.115322490533193

Epoch: 6| Step: 12
Training loss: 1.5045230388641357
Validation loss: 2.1727643609046936

Epoch: 6| Step: 13
Training loss: 1.4314403533935547
Validation loss: 2.158913791179657

Epoch: 104| Step: 0
Training loss: 1.306357502937317
Validation loss: 2.1067469716072083

Epoch: 6| Step: 1
Training loss: 1.5947107076644897
Validation loss: 2.173114061355591

Epoch: 6| Step: 2
Training loss: 1.0186946392059326
Validation loss: 2.0944042603174844

Epoch: 6| Step: 3
Training loss: 1.678688645362854
Validation loss: 2.0377461512883506

Epoch: 6| Step: 4
Training loss: 1.3811962604522705
Validation loss: 2.105976323286692

Epoch: 6| Step: 5
Training loss: 1.4278472661972046
Validation loss: 2.089673936367035

Epoch: 6| Step: 6
Training loss: 1.264121413230896
Validation loss: 1.9813847541809082

Epoch: 6| Step: 7
Training loss: 1.3759777545928955
Validation loss: 2.0286003947257996

Epoch: 6| Step: 8
Training loss: 1.513730764389038
Validation loss: 1.991525928179423

Epoch: 6| Step: 9
Training loss: 1.9077141284942627
Validation loss: 2.0943267941474915

Epoch: 6| Step: 10
Training loss: 1.3251720666885376
Validation loss: 2.0197012623151145

Epoch: 6| Step: 11
Training loss: 1.3778797388076782
Validation loss: 2.063671112060547

Epoch: 6| Step: 12
Training loss: 0.47754979133605957
Validation loss: 2.1166969339052835

Epoch: 6| Step: 13
Training loss: 1.4113091230392456
Validation loss: 2.1163353522618613

Epoch: 105| Step: 0
Training loss: 1.4759577512741089
Validation loss: 2.0698299010594687

Epoch: 6| Step: 1
Training loss: 0.978478193283081
Validation loss: 2.0327523350715637

Epoch: 6| Step: 2
Training loss: 1.2723509073257446
Validation loss: 2.1317768494288125

Epoch: 6| Step: 3
Training loss: 1.139740228652954
Validation loss: 2.094808578491211

Epoch: 6| Step: 4
Training loss: 0.8803492188453674
Validation loss: 2.0966147780418396

Epoch: 6| Step: 5
Training loss: 1.92105233669281
Validation loss: 2.048518796761831

Epoch: 6| Step: 6
Training loss: 1.075122594833374
Validation loss: 2.0732619365056357

Epoch: 6| Step: 7
Training loss: 1.9717435836791992
Validation loss: 2.082318425178528

Epoch: 6| Step: 8
Training loss: 1.4560215473175049
Validation loss: 2.068106194337209

Epoch: 6| Step: 9
Training loss: 1.4684827327728271
Validation loss: 2.0547869404157004

Epoch: 6| Step: 10
Training loss: 0.8626787662506104
Validation loss: 2.0693158706029258

Epoch: 6| Step: 11
Training loss: 1.0931085348129272
Validation loss: 2.1248841484387717

Epoch: 6| Step: 12
Training loss: 1.5151195526123047
Validation loss: 2.0423390666643777

Epoch: 6| Step: 13
Training loss: 1.4033360481262207
Validation loss: 2.0173421700795493

Epoch: 106| Step: 0
Training loss: 1.4743618965148926
Validation loss: 2.048419773578644

Epoch: 6| Step: 1
Training loss: 1.0803745985031128
Validation loss: 2.1238582531611123

Epoch: 6| Step: 2
Training loss: 1.699578046798706
Validation loss: 2.0819782813390098

Epoch: 6| Step: 3
Training loss: 1.9411633014678955
Validation loss: 2.068612535794576

Epoch: 6| Step: 4
Training loss: 1.1606063842773438
Validation loss: 2.079046825567881

Epoch: 6| Step: 5
Training loss: 1.4756624698638916
Validation loss: 2.073570509751638

Epoch: 6| Step: 6
Training loss: 1.1173100471496582
Validation loss: 2.0411048531532288

Epoch: 6| Step: 7
Training loss: 1.3090288639068604
Validation loss: 2.014574329058329

Epoch: 6| Step: 8
Training loss: 0.9280102252960205
Validation loss: 2.0649165312449136

Epoch: 6| Step: 9
Training loss: 1.336881399154663
Validation loss: 2.1416474183400473

Epoch: 6| Step: 10
Training loss: 1.4022024869918823
Validation loss: 2.1304947336514792

Epoch: 6| Step: 11
Training loss: 1.129220724105835
Validation loss: 2.0448578198750815

Epoch: 6| Step: 12
Training loss: 1.5628037452697754
Validation loss: 2.13118048508962

Epoch: 6| Step: 13
Training loss: 1.0192209482192993
Validation loss: 2.0609171191851297

Epoch: 107| Step: 0
Training loss: 0.6997696161270142
Validation loss: 2.06101926167806

Epoch: 6| Step: 1
Training loss: 1.0401396751403809
Validation loss: 2.054869294166565

Epoch: 6| Step: 2
Training loss: 1.8906352519989014
Validation loss: 2.0448512037595115

Epoch: 6| Step: 3
Training loss: 1.7934595346450806
Validation loss: 2.0575854976971946

Epoch: 6| Step: 4
Training loss: 0.951292872428894
Validation loss: 2.1049506862958274

Epoch: 6| Step: 5
Training loss: 1.2023922204971313
Validation loss: 2.015410602092743

Epoch: 6| Step: 6
Training loss: 1.176143765449524
Validation loss: 2.050329049428304

Epoch: 6| Step: 7
Training loss: 1.1897289752960205
Validation loss: 2.074000875155131

Epoch: 6| Step: 8
Training loss: 1.6591355800628662
Validation loss: 2.1264076232910156

Epoch: 6| Step: 9
Training loss: 1.0389556884765625
Validation loss: 2.110174536705017

Epoch: 6| Step: 10
Training loss: 1.5262315273284912
Validation loss: 2.196748594443003

Epoch: 6| Step: 11
Training loss: 1.5015803575515747
Validation loss: 2.1091438929239907

Epoch: 6| Step: 12
Training loss: 1.025394082069397
Validation loss: 2.0581487814585366

Epoch: 6| Step: 13
Training loss: 1.891545295715332
Validation loss: 2.057227353254954

Epoch: 108| Step: 0
Training loss: 1.0713878870010376
Validation loss: 2.04767253001531

Epoch: 6| Step: 1
Training loss: 1.1814883947372437
Validation loss: 2.0991404056549072

Epoch: 6| Step: 2
Training loss: 0.8674173355102539
Validation loss: 2.0603877902030945

Epoch: 6| Step: 3
Training loss: 0.9769445061683655
Validation loss: 2.0931561390558877

Epoch: 6| Step: 4
Training loss: 1.071667194366455
Validation loss: 2.0963239669799805

Epoch: 6| Step: 5
Training loss: 1.2998912334442139
Validation loss: 2.0784682234128318

Epoch: 6| Step: 6
Training loss: 1.3117420673370361
Validation loss: 2.162832200527191

Epoch: 6| Step: 7
Training loss: 1.7454397678375244
Validation loss: 2.1708021561304727

Epoch: 6| Step: 8
Training loss: 1.841454267501831
Validation loss: 2.1353320876757302

Epoch: 6| Step: 9
Training loss: 1.4595985412597656
Validation loss: 2.134306848049164

Epoch: 6| Step: 10
Training loss: 1.2019941806793213
Validation loss: 2.0625600814819336

Epoch: 6| Step: 11
Training loss: 1.458794355392456
Validation loss: 2.052861432234446

Epoch: 6| Step: 12
Training loss: 1.4775869846343994
Validation loss: 2.063630223274231

Epoch: 6| Step: 13
Training loss: 0.9136978387832642
Validation loss: 2.0758837262789407

Epoch: 109| Step: 0
Training loss: 1.5214903354644775
Validation loss: 2.054651399453481

Epoch: 6| Step: 1
Training loss: 1.133460521697998
Validation loss: 2.036600331465403

Epoch: 6| Step: 2
Training loss: 1.3701269626617432
Validation loss: 2.0895683765411377

Epoch: 6| Step: 3
Training loss: 1.4083287715911865
Validation loss: 2.138106962045034

Epoch: 6| Step: 4
Training loss: 1.1445107460021973
Validation loss: 2.11799685160319

Epoch: 6| Step: 5
Training loss: 1.1952946186065674
Validation loss: 2.126617153485616

Epoch: 6| Step: 6
Training loss: 1.3904368877410889
Validation loss: 2.076255758603414

Epoch: 6| Step: 7
Training loss: 1.0206608772277832
Validation loss: 2.13046266635259

Epoch: 6| Step: 8
Training loss: 1.413586139678955
Validation loss: 2.089837431907654

Epoch: 6| Step: 9
Training loss: 1.1422796249389648
Validation loss: 2.102965990702311

Epoch: 6| Step: 10
Training loss: 1.0713837146759033
Validation loss: 2.0576199491818747

Epoch: 6| Step: 11
Training loss: 0.9128243327140808
Validation loss: 2.0887460907300315

Epoch: 6| Step: 12
Training loss: 1.4228930473327637
Validation loss: 2.075675288836161

Epoch: 6| Step: 13
Training loss: 1.571588397026062
Validation loss: 2.076835572719574

Epoch: 110| Step: 0
Training loss: 1.4888060092926025
Validation loss: 2.0592480103174844

Epoch: 6| Step: 1
Training loss: 1.3334364891052246
Validation loss: 2.0419219732284546

Epoch: 6| Step: 2
Training loss: 1.1979914903640747
Validation loss: 2.070804019769033

Epoch: 6| Step: 3
Training loss: 0.7940086722373962
Validation loss: 2.1655005613962808

Epoch: 6| Step: 4
Training loss: 1.775484323501587
Validation loss: 2.0997074047724404

Epoch: 6| Step: 5
Training loss: 1.273597002029419
Validation loss: 2.142279585202535

Epoch: 6| Step: 6
Training loss: 1.2641425132751465
Validation loss: 2.1621129711469016

Epoch: 6| Step: 7
Training loss: 1.2884364128112793
Validation loss: 2.1207337578137717

Epoch: 6| Step: 8
Training loss: 1.2815077304840088
Validation loss: 2.0092084407806396

Epoch: 6| Step: 9
Training loss: 1.260362148284912
Validation loss: 1.9972095290819805

Epoch: 6| Step: 10
Training loss: 1.5537281036376953
Validation loss: 2.055014669895172

Epoch: 6| Step: 11
Training loss: 1.6255778074264526
Validation loss: 2.09690268834432

Epoch: 6| Step: 12
Training loss: 1.2859885692596436
Validation loss: 2.076277256011963

Epoch: 6| Step: 13
Training loss: 0.8645687103271484
Validation loss: 2.102619191010793

Epoch: 111| Step: 0
Training loss: 1.339461088180542
Validation loss: 2.102039933204651

Epoch: 6| Step: 1
Training loss: 1.246585488319397
Validation loss: 2.0956061681111655

Epoch: 6| Step: 2
Training loss: 1.0372514724731445
Validation loss: 2.092779258886973

Epoch: 6| Step: 3
Training loss: 1.3211634159088135
Validation loss: 2.176101505756378

Epoch: 6| Step: 4
Training loss: 1.7336788177490234
Validation loss: 2.0798496206601462

Epoch: 6| Step: 5
Training loss: 0.864920437335968
Validation loss: 2.1342382629712424

Epoch: 6| Step: 6
Training loss: 0.7586660385131836
Validation loss: 2.093868136405945

Epoch: 6| Step: 7
Training loss: 1.8387678861618042
Validation loss: 2.125312646230062

Epoch: 6| Step: 8
Training loss: 1.1106138229370117
Validation loss: 2.074617246786753

Epoch: 6| Step: 9
Training loss: 1.1018009185791016
Validation loss: 2.072707931200663

Epoch: 6| Step: 10
Training loss: 1.1481839418411255
Validation loss: 2.0693635741869607

Epoch: 6| Step: 11
Training loss: 1.4440311193466187
Validation loss: 2.1042306224505105

Epoch: 6| Step: 12
Training loss: 1.1403840780258179
Validation loss: 2.0689463019371033

Epoch: 6| Step: 13
Training loss: 1.5497431755065918
Validation loss: 2.0075254241625466

Epoch: 112| Step: 0
Training loss: 1.3074419498443604
Validation loss: 2.113812267780304

Epoch: 6| Step: 1
Training loss: 0.869505763053894
Validation loss: 2.094175398349762

Epoch: 6| Step: 2
Training loss: 1.5047930479049683
Validation loss: 2.13885235786438

Epoch: 6| Step: 3
Training loss: 1.4841128587722778
Validation loss: 2.1951907674471536

Epoch: 6| Step: 4
Training loss: 0.6658220291137695
Validation loss: 2.1335309743881226

Epoch: 6| Step: 5
Training loss: 1.3328254222869873
Validation loss: 2.130194107691447

Epoch: 6| Step: 6
Training loss: 1.729323148727417
Validation loss: 2.043953796227773

Epoch: 6| Step: 7
Training loss: 1.4480595588684082
Validation loss: 2.0414432287216187

Epoch: 6| Step: 8
Training loss: 1.2163416147232056
Validation loss: 2.0451462666193643

Epoch: 6| Step: 9
Training loss: 0.9921882152557373
Validation loss: 2.018888235092163

Epoch: 6| Step: 10
Training loss: 0.8260906934738159
Validation loss: 2.0792487263679504

Epoch: 6| Step: 11
Training loss: 1.9727455377578735
Validation loss: 2.0309424996376038

Epoch: 6| Step: 12
Training loss: 1.1443935632705688
Validation loss: 2.0531665086746216

Epoch: 6| Step: 13
Training loss: 1.0157127380371094
Validation loss: 1.9957201679547627

Epoch: 113| Step: 0
Training loss: 1.2556623220443726
Validation loss: 2.0246412555376687

Epoch: 6| Step: 1
Training loss: 1.1866079568862915
Validation loss: 2.0613056222597756

Epoch: 6| Step: 2
Training loss: 1.463690161705017
Validation loss: 2.07578839858373

Epoch: 6| Step: 3
Training loss: 0.7344551086425781
Validation loss: 2.0837263266245523

Epoch: 6| Step: 4
Training loss: 0.9050664901733398
Validation loss: 2.0590383410453796

Epoch: 6| Step: 5
Training loss: 1.7267465591430664
Validation loss: 2.107440769672394

Epoch: 6| Step: 6
Training loss: 1.028904676437378
Validation loss: 2.093473275502523

Epoch: 6| Step: 7
Training loss: 0.5240719318389893
Validation loss: 2.07235195239385

Epoch: 6| Step: 8
Training loss: 1.5938332080841064
Validation loss: 2.0934425592422485

Epoch: 6| Step: 9
Training loss: 1.1601401567459106
Validation loss: 2.019333521525065

Epoch: 6| Step: 10
Training loss: 1.5434117317199707
Validation loss: 2.043950398763021

Epoch: 6| Step: 11
Training loss: 1.3724626302719116
Validation loss: 2.018694976965586

Epoch: 6| Step: 12
Training loss: 1.3137779235839844
Validation loss: 2.105428675810496

Epoch: 6| Step: 13
Training loss: 1.386211633682251
Validation loss: 2.0730945467948914

Epoch: 114| Step: 0
Training loss: 0.8519258499145508
Validation loss: 2.093286951382955

Epoch: 6| Step: 1
Training loss: 1.6241281032562256
Validation loss: 2.0739157597223916

Epoch: 6| Step: 2
Training loss: 1.0622202157974243
Validation loss: 2.0325063665707908

Epoch: 6| Step: 3
Training loss: 1.4305346012115479
Validation loss: 2.1244295040766397

Epoch: 6| Step: 4
Training loss: 1.1046860218048096
Validation loss: 2.0927701791127524

Epoch: 6| Step: 5
Training loss: 1.6392018795013428
Validation loss: 2.109137018521627

Epoch: 6| Step: 6
Training loss: 1.059369683265686
Validation loss: 2.0990848541259766

Epoch: 6| Step: 7
Training loss: 0.7162057161331177
Validation loss: 2.016470034917196

Epoch: 6| Step: 8
Training loss: 1.0054787397384644
Validation loss: 2.053179621696472

Epoch: 6| Step: 9
Training loss: 1.4176164865493774
Validation loss: 2.0476178328196206

Epoch: 6| Step: 10
Training loss: 0.900794267654419
Validation loss: 2.011755108833313

Epoch: 6| Step: 11
Training loss: 1.128624439239502
Validation loss: 2.0484073559443154

Epoch: 6| Step: 12
Training loss: 1.5011447668075562
Validation loss: 2.0697328050931296

Epoch: 6| Step: 13
Training loss: 1.638005018234253
Validation loss: 2.0506208141644797

Epoch: 115| Step: 0
Training loss: 1.2367181777954102
Validation loss: 2.103109379609426

Epoch: 6| Step: 1
Training loss: 1.2556726932525635
Validation loss: 2.1109575827916465

Epoch: 6| Step: 2
Training loss: 1.1242008209228516
Validation loss: 2.0676469604174295

Epoch: 6| Step: 3
Training loss: 0.6188604831695557
Validation loss: 2.0831605792045593

Epoch: 6| Step: 4
Training loss: 1.2615890502929688
Validation loss: 2.0678450663884482

Epoch: 6| Step: 5
Training loss: 1.5677716732025146
Validation loss: 2.0274741450945535

Epoch: 6| Step: 6
Training loss: 1.5899224281311035
Validation loss: 2.0484225948651633

Epoch: 6| Step: 7
Training loss: 1.8200619220733643
Validation loss: 1.9991185466448467

Epoch: 6| Step: 8
Training loss: 1.1097021102905273
Validation loss: 2.0130831003189087

Epoch: 6| Step: 9
Training loss: 1.1598844528198242
Validation loss: 2.0624106725056968

Epoch: 6| Step: 10
Training loss: 1.3193320035934448
Validation loss: 2.0529843966166177

Epoch: 6| Step: 11
Training loss: 0.8810262680053711
Validation loss: 2.140897810459137

Epoch: 6| Step: 12
Training loss: 1.1594730615615845
Validation loss: 2.206504503885905

Epoch: 6| Step: 13
Training loss: 1.3707218170166016
Validation loss: 2.146779477596283

Epoch: 116| Step: 0
Training loss: 1.0663468837738037
Validation loss: 2.128081758817037

Epoch: 6| Step: 1
Training loss: 1.2882752418518066
Validation loss: 2.117169976234436

Epoch: 6| Step: 2
Training loss: 1.8695753812789917
Validation loss: 2.0923675100008645

Epoch: 6| Step: 3
Training loss: 1.5708682537078857
Validation loss: 2.0235174894332886

Epoch: 6| Step: 4
Training loss: 1.201219916343689
Validation loss: 1.968716283639272

Epoch: 6| Step: 5
Training loss: 1.0023690462112427
Validation loss: 2.0383251110712686

Epoch: 6| Step: 6
Training loss: 0.9707903861999512
Validation loss: 1.9853036006291707

Epoch: 6| Step: 7
Training loss: 1.1785849332809448
Validation loss: 2.005982061227163

Epoch: 6| Step: 8
Training loss: 0.8245869278907776
Validation loss: 2.113524238268534

Epoch: 6| Step: 9
Training loss: 1.0049028396606445
Validation loss: 2.12378199895223

Epoch: 6| Step: 10
Training loss: 1.0945996046066284
Validation loss: 2.1567267576853433

Epoch: 6| Step: 11
Training loss: 1.2450870275497437
Validation loss: 2.1263561844825745

Epoch: 6| Step: 12
Training loss: 1.159844160079956
Validation loss: 2.0439146955808005

Epoch: 6| Step: 13
Training loss: 1.6005957126617432
Validation loss: 2.057435154914856

Epoch: 117| Step: 0
Training loss: 1.2692800760269165
Validation loss: 2.013460695743561

Epoch: 6| Step: 1
Training loss: 0.864513099193573
Validation loss: 2.0696386297543845

Epoch: 6| Step: 2
Training loss: 1.2459067106246948
Validation loss: 2.1323225498199463

Epoch: 6| Step: 3
Training loss: 1.5728870630264282
Validation loss: 2.1069148977597556

Epoch: 6| Step: 4
Training loss: 1.2548773288726807
Validation loss: 2.0416985948880515

Epoch: 6| Step: 5
Training loss: 1.1211512088775635
Validation loss: 2.0811910033226013

Epoch: 6| Step: 6
Training loss: 1.5389986038208008
Validation loss: 2.088226000467936

Epoch: 6| Step: 7
Training loss: 1.0678914785385132
Validation loss: 2.0424113074938455

Epoch: 6| Step: 8
Training loss: 0.9066661596298218
Validation loss: 2.0620111425717673

Epoch: 6| Step: 9
Training loss: 0.742097795009613
Validation loss: 1.9891040921211243

Epoch: 6| Step: 10
Training loss: 0.6366116404533386
Validation loss: 2.0975643595059714

Epoch: 6| Step: 11
Training loss: 1.5423588752746582
Validation loss: 2.0549866755803428

Epoch: 6| Step: 12
Training loss: 1.8707258701324463
Validation loss: 2.0491058627764382

Epoch: 6| Step: 13
Training loss: 1.2532200813293457
Validation loss: 2.0787814259529114

Epoch: 118| Step: 0
Training loss: 0.8207855224609375
Validation loss: 2.049566407998403

Epoch: 6| Step: 1
Training loss: 1.1580287218093872
Validation loss: 2.1369253595670066

Epoch: 6| Step: 2
Training loss: 1.2404184341430664
Validation loss: 2.1138710578282676

Epoch: 6| Step: 3
Training loss: 1.3011595010757446
Validation loss: 2.2104819615681968

Epoch: 6| Step: 4
Training loss: 1.7005499601364136
Validation loss: 2.1809170246124268

Epoch: 6| Step: 5
Training loss: 0.7038995623588562
Validation loss: 2.0456745823224387

Epoch: 6| Step: 6
Training loss: 1.2830562591552734
Validation loss: 2.015724837779999

Epoch: 6| Step: 7
Training loss: 1.3118699789047241
Validation loss: 2.096287707487742

Epoch: 6| Step: 8
Training loss: 1.20406973361969
Validation loss: 2.0449390014012656

Epoch: 6| Step: 9
Training loss: 1.3029040098190308
Validation loss: 2.0830815037091575

Epoch: 6| Step: 10
Training loss: 1.1772748231887817
Validation loss: 2.0216000080108643

Epoch: 6| Step: 11
Training loss: 1.0520564317703247
Validation loss: 2.099397818247477

Epoch: 6| Step: 12
Training loss: 1.4479985237121582
Validation loss: 2.0306465228398642

Epoch: 6| Step: 13
Training loss: 0.9217013120651245
Validation loss: 2.0637709895769754

Epoch: 119| Step: 0
Training loss: 1.1152844429016113
Validation loss: 2.084247350692749

Epoch: 6| Step: 1
Training loss: 0.550743818283081
Validation loss: 2.160641312599182

Epoch: 6| Step: 2
Training loss: 1.4861117601394653
Validation loss: 2.070021947224935

Epoch: 6| Step: 3
Training loss: 1.6207575798034668
Validation loss: 2.0639623006184897

Epoch: 6| Step: 4
Training loss: 1.380191445350647
Validation loss: 2.063529670238495

Epoch: 6| Step: 5
Training loss: 1.2191002368927002
Validation loss: 2.0132794181505838

Epoch: 6| Step: 6
Training loss: 1.0526314973831177
Validation loss: 2.0601319471995034

Epoch: 6| Step: 7
Training loss: 1.7797346115112305
Validation loss: 1.9992903470993042

Epoch: 6| Step: 8
Training loss: 0.8461832404136658
Validation loss: 2.0290213028589883

Epoch: 6| Step: 9
Training loss: 0.8924709558486938
Validation loss: 2.0180188616116843

Epoch: 6| Step: 10
Training loss: 0.8268947005271912
Validation loss: 2.102466960748037

Epoch: 6| Step: 11
Training loss: 1.39500093460083
Validation loss: 1.9878832300504048

Epoch: 6| Step: 12
Training loss: 1.0272772312164307
Validation loss: 2.0561960538228354

Epoch: 6| Step: 13
Training loss: 1.0877760648727417
Validation loss: 2.137985189755758

Epoch: 120| Step: 0
Training loss: 0.9590844511985779
Validation loss: 2.0278669794400535

Epoch: 6| Step: 1
Training loss: 1.209089756011963
Validation loss: 2.0662999550501504

Epoch: 6| Step: 2
Training loss: 1.18992280960083
Validation loss: 2.0623929500579834

Epoch: 6| Step: 3
Training loss: 1.0319898128509521
Validation loss: 2.026208142439524

Epoch: 6| Step: 4
Training loss: 1.1322948932647705
Validation loss: 1.9908246994018555

Epoch: 6| Step: 5
Training loss: 1.1419293880462646
Validation loss: 2.037380635738373

Epoch: 6| Step: 6
Training loss: 1.431695818901062
Validation loss: 2.009307563304901

Epoch: 6| Step: 7
Training loss: 1.2170591354370117
Validation loss: 2.0649116237958274

Epoch: 6| Step: 8
Training loss: 1.9611505270004272
Validation loss: 2.0273553133010864

Epoch: 6| Step: 9
Training loss: 1.1280593872070312
Validation loss: 2.1031203667322793

Epoch: 6| Step: 10
Training loss: 1.2586792707443237
Validation loss: 2.1008962988853455

Epoch: 6| Step: 11
Training loss: 1.0853569507598877
Validation loss: 2.088455597559611

Epoch: 6| Step: 12
Training loss: 0.4449242055416107
Validation loss: 2.053971449534098

Epoch: 6| Step: 13
Training loss: 1.2287462949752808
Validation loss: 2.0953145027160645

Epoch: 121| Step: 0
Training loss: 0.946647047996521
Validation loss: 2.025298774242401

Epoch: 6| Step: 1
Training loss: 0.7132599353790283
Validation loss: 2.0309091806411743

Epoch: 6| Step: 2
Training loss: 1.564115047454834
Validation loss: 2.0471729040145874

Epoch: 6| Step: 3
Training loss: 1.1452847719192505
Validation loss: 2.039362847805023

Epoch: 6| Step: 4
Training loss: 1.4046169519424438
Validation loss: 2.0421913067499795

Epoch: 6| Step: 5
Training loss: 1.190182089805603
Validation loss: 2.0663885871569314

Epoch: 6| Step: 6
Training loss: 0.6355669498443604
Validation loss: 2.102895140647888

Epoch: 6| Step: 7
Training loss: 1.3276140689849854
Validation loss: 2.0572217305501304

Epoch: 6| Step: 8
Training loss: 1.32682204246521
Validation loss: 2.0962040026982627

Epoch: 6| Step: 9
Training loss: 0.6963092088699341
Validation loss: 2.0411627491315207

Epoch: 6| Step: 10
Training loss: 1.3143200874328613
Validation loss: 2.02232418457667

Epoch: 6| Step: 11
Training loss: 1.2280914783477783
Validation loss: 2.0764453609784446

Epoch: 6| Step: 12
Training loss: 0.9608446359634399
Validation loss: 2.132863442103068

Epoch: 6| Step: 13
Training loss: 1.1856328248977661
Validation loss: 2.0503016312917075

Epoch: 122| Step: 0
Training loss: 0.9849481582641602
Validation loss: 2.000983794530233

Epoch: 6| Step: 1
Training loss: 1.2073230743408203
Validation loss: 2.0829718311627707

Epoch: 6| Step: 2
Training loss: 0.41143009066581726
Validation loss: 2.0972323020299277

Epoch: 6| Step: 3
Training loss: 1.0345423221588135
Validation loss: 2.07966943581899

Epoch: 6| Step: 4
Training loss: 1.4472485780715942
Validation loss: 2.0255480209986367

Epoch: 6| Step: 5
Training loss: 0.9830846190452576
Validation loss: 2.00168114900589

Epoch: 6| Step: 6
Training loss: 1.4644039869308472
Validation loss: 2.0822356740633645

Epoch: 6| Step: 7
Training loss: 0.8744452595710754
Validation loss: 2.0801305572191873

Epoch: 6| Step: 8
Training loss: 1.4281436204910278
Validation loss: 2.1156187057495117

Epoch: 6| Step: 9
Training loss: 1.3680436611175537
Validation loss: 2.1505380868911743

Epoch: 6| Step: 10
Training loss: 1.0306427478790283
Validation loss: 2.113653381665548

Epoch: 6| Step: 11
Training loss: 1.2868967056274414
Validation loss: 2.077761987845103

Epoch: 6| Step: 12
Training loss: 1.2035489082336426
Validation loss: 2.061927576859792

Epoch: 6| Step: 13
Training loss: 1.5654637813568115
Validation loss: 2.0373584429423013

Epoch: 123| Step: 0
Training loss: 1.2395343780517578
Validation loss: 1.9951207041740417

Epoch: 6| Step: 1
Training loss: 1.1003694534301758
Validation loss: 2.0519779324531555

Epoch: 6| Step: 2
Training loss: 0.6409766674041748
Validation loss: 2.089195410410563

Epoch: 6| Step: 3
Training loss: 1.3127788305282593
Validation loss: 2.1243035991986594

Epoch: 6| Step: 4
Training loss: 1.4477993249893188
Validation loss: 2.1353938579559326

Epoch: 6| Step: 5
Training loss: 1.5258855819702148
Validation loss: 2.2223607500394187

Epoch: 6| Step: 6
Training loss: 1.0615196228027344
Validation loss: 2.2359003027280173

Epoch: 6| Step: 7
Training loss: 1.6430866718292236
Validation loss: 2.2258943915367126

Epoch: 6| Step: 8
Training loss: 1.237007975578308
Validation loss: 2.1270897587140403

Epoch: 6| Step: 9
Training loss: 1.1383123397827148
Validation loss: 2.0739509661992392

Epoch: 6| Step: 10
Training loss: 1.369737148284912
Validation loss: 2.0372276107470193

Epoch: 6| Step: 11
Training loss: 1.1275326013565063
Validation loss: 1.98527197043101

Epoch: 6| Step: 12
Training loss: 1.2566992044448853
Validation loss: 2.04749329884847

Epoch: 6| Step: 13
Training loss: 1.0225765705108643
Validation loss: 2.0695630510648093

Epoch: 124| Step: 0
Training loss: 1.2050771713256836
Validation loss: 2.0610408385594687

Epoch: 6| Step: 1
Training loss: 1.306354284286499
Validation loss: 2.184949437777201

Epoch: 6| Step: 2
Training loss: 1.3188574314117432
Validation loss: 2.191623250643412

Epoch: 6| Step: 3
Training loss: 1.1535110473632812
Validation loss: 2.113094965616862

Epoch: 6| Step: 4
Training loss: 0.8805053234100342
Validation loss: 2.033180812994639

Epoch: 6| Step: 5
Training loss: 1.2833170890808105
Validation loss: 2.027515947818756

Epoch: 6| Step: 6
Training loss: 0.9176433086395264
Validation loss: 2.077651858329773

Epoch: 6| Step: 7
Training loss: 0.6679876446723938
Validation loss: 2.008023122946421

Epoch: 6| Step: 8
Training loss: 1.3121812343597412
Validation loss: 2.095218062400818

Epoch: 6| Step: 9
Training loss: 0.9147548079490662
Validation loss: 2.044284224510193

Epoch: 6| Step: 10
Training loss: 0.6495546102523804
Validation loss: 2.076942761739095

Epoch: 6| Step: 11
Training loss: 1.7338013648986816
Validation loss: 2.120957533518473

Epoch: 6| Step: 12
Training loss: 1.9424670934677124
Validation loss: 2.095804135004679

Epoch: 6| Step: 13
Training loss: 0.7781460285186768
Validation loss: 2.0431917111078897

Epoch: 125| Step: 0
Training loss: 0.9271470308303833
Validation loss: 2.0363031029701233

Epoch: 6| Step: 1
Training loss: 0.8770710229873657
Validation loss: 1.994472861289978

Epoch: 6| Step: 2
Training loss: 1.3406257629394531
Validation loss: 2.0599562923113504

Epoch: 6| Step: 3
Training loss: 1.1454472541809082
Validation loss: 2.039435605208079

Epoch: 6| Step: 4
Training loss: 1.3044652938842773
Validation loss: 2.029081185658773

Epoch: 6| Step: 5
Training loss: 1.6345019340515137
Validation loss: 2.0466806093851724

Epoch: 6| Step: 6
Training loss: 1.0058927536010742
Validation loss: 2.0746800700823465

Epoch: 6| Step: 7
Training loss: 0.770616352558136
Validation loss: 2.1701595385869346

Epoch: 6| Step: 8
Training loss: 1.234911322593689
Validation loss: 2.1157572269439697

Epoch: 6| Step: 9
Training loss: 1.00039803981781
Validation loss: 2.2177441318829856

Epoch: 6| Step: 10
Training loss: 0.7743568420410156
Validation loss: 2.198231856028239

Epoch: 6| Step: 11
Training loss: 1.8977656364440918
Validation loss: 2.1447452505429587

Epoch: 6| Step: 12
Training loss: 1.142744541168213
Validation loss: 2.069972574710846

Epoch: 6| Step: 13
Training loss: 0.9423375725746155
Validation loss: 2.036171774069468

Epoch: 126| Step: 0
Training loss: 1.3432711362838745
Validation loss: 2.064530611038208

Epoch: 6| Step: 1
Training loss: 1.1399590969085693
Validation loss: 2.0769503116607666

Epoch: 6| Step: 2
Training loss: 1.5457618236541748
Validation loss: 2.1311984062194824

Epoch: 6| Step: 3
Training loss: 1.051192045211792
Validation loss: 2.083050012588501

Epoch: 6| Step: 4
Training loss: 1.5566262006759644
Validation loss: 2.218591332435608

Epoch: 6| Step: 5
Training loss: 1.1964619159698486
Validation loss: 2.1242348551750183

Epoch: 6| Step: 6
Training loss: 0.8365870714187622
Validation loss: 2.1350506941477456

Epoch: 6| Step: 7
Training loss: 1.2853643894195557
Validation loss: 2.1448111136754355

Epoch: 6| Step: 8
Training loss: 0.7273766994476318
Validation loss: 2.0480090181032815

Epoch: 6| Step: 9
Training loss: 1.5049879550933838
Validation loss: 2.0219093958536782

Epoch: 6| Step: 10
Training loss: 0.8677151799201965
Validation loss: 2.073539892832438

Epoch: 6| Step: 11
Training loss: 0.8301529884338379
Validation loss: 2.140586495399475

Epoch: 6| Step: 12
Training loss: 1.081200122833252
Validation loss: 2.121222654978434

Epoch: 6| Step: 13
Training loss: 1.1340458393096924
Validation loss: 2.130364497502645

Epoch: 127| Step: 0
Training loss: 0.9006475806236267
Validation loss: 2.1018132964769998

Epoch: 6| Step: 1
Training loss: 1.2896132469177246
Validation loss: 2.111726144949595

Epoch: 6| Step: 2
Training loss: 0.8097916841506958
Validation loss: 2.128054360548655

Epoch: 6| Step: 3
Training loss: 0.5496445894241333
Validation loss: 2.1068046490351358

Epoch: 6| Step: 4
Training loss: 1.0980329513549805
Validation loss: 2.1158036589622498

Epoch: 6| Step: 5
Training loss: 0.9906384944915771
Validation loss: 2.1149202585220337

Epoch: 6| Step: 6
Training loss: 0.9694209098815918
Validation loss: 2.0823703010876975

Epoch: 6| Step: 7
Training loss: 1.4920142889022827
Validation loss: 2.0993574062983194

Epoch: 6| Step: 8
Training loss: 1.5944442749023438
Validation loss: 2.0463876326878867

Epoch: 6| Step: 9
Training loss: 1.2487540245056152
Validation loss: 2.0860634446144104

Epoch: 6| Step: 10
Training loss: 0.8159871697425842
Validation loss: 2.1303452849388123

Epoch: 6| Step: 11
Training loss: 1.3821396827697754
Validation loss: 2.0702631870905557

Epoch: 6| Step: 12
Training loss: 1.0898122787475586
Validation loss: 2.100219408671061

Epoch: 6| Step: 13
Training loss: 0.8229584693908691
Validation loss: 2.0656544963518777

Epoch: 128| Step: 0
Training loss: 1.3350982666015625
Validation loss: 2.0595959623654685

Epoch: 6| Step: 1
Training loss: 1.0372856855392456
Validation loss: 2.0750147898991904

Epoch: 6| Step: 2
Training loss: 0.8440529704093933
Validation loss: 2.1267324090003967

Epoch: 6| Step: 3
Training loss: 0.37729668617248535
Validation loss: 2.0241384704907737

Epoch: 6| Step: 4
Training loss: 1.3884848356246948
Validation loss: 1.9954793055852253

Epoch: 6| Step: 5
Training loss: 1.193263053894043
Validation loss: 2.038152734438578

Epoch: 6| Step: 6
Training loss: 0.9561408758163452
Validation loss: 2.041777511437734

Epoch: 6| Step: 7
Training loss: 1.2719790935516357
Validation loss: 2.0324907898902893

Epoch: 6| Step: 8
Training loss: 1.216484546661377
Validation loss: 2.0721248785654702

Epoch: 6| Step: 9
Training loss: 0.8267205953598022
Validation loss: 2.0683791438738504

Epoch: 6| Step: 10
Training loss: 1.2714284658432007
Validation loss: 2.137146472930908

Epoch: 6| Step: 11
Training loss: 1.481034755706787
Validation loss: 2.2017509937286377

Epoch: 6| Step: 12
Training loss: 1.2279152870178223
Validation loss: 2.219985286394755

Epoch: 6| Step: 13
Training loss: 0.809938907623291
Validation loss: 2.162726660569509

Epoch: 129| Step: 0
Training loss: 1.0819077491760254
Validation loss: 2.112814207871755

Epoch: 6| Step: 1
Training loss: 1.1487977504730225
Validation loss: 2.077303191026052

Epoch: 6| Step: 2
Training loss: 1.2110521793365479
Validation loss: 2.0241082310676575

Epoch: 6| Step: 3
Training loss: 1.0270427465438843
Validation loss: 2.0753292044003806

Epoch: 6| Step: 4
Training loss: 1.1258008480072021
Validation loss: 2.045689284801483

Epoch: 6| Step: 5
Training loss: 1.0729310512542725
Validation loss: 2.0703677336374917

Epoch: 6| Step: 6
Training loss: 0.8701337575912476
Validation loss: 2.0754356384277344

Epoch: 6| Step: 7
Training loss: 1.2311408519744873
Validation loss: 2.089559018611908

Epoch: 6| Step: 8
Training loss: 1.1608171463012695
Validation loss: 2.056582729021708

Epoch: 6| Step: 9
Training loss: 1.179612159729004
Validation loss: 2.1673278411229453

Epoch: 6| Step: 10
Training loss: 0.9959163665771484
Validation loss: 2.218614856402079

Epoch: 6| Step: 11
Training loss: 1.3083105087280273
Validation loss: 2.1398943265279136

Epoch: 6| Step: 12
Training loss: 1.3005468845367432
Validation loss: 2.1425861914952598

Epoch: 6| Step: 13
Training loss: 0.7191957235336304
Validation loss: 2.1288344860076904

Epoch: 130| Step: 0
Training loss: 0.9013002514839172
Validation loss: 2.054684122403463

Epoch: 6| Step: 1
Training loss: 0.8634743094444275
Validation loss: 2.1066282590230307

Epoch: 6| Step: 2
Training loss: 0.9276584386825562
Validation loss: 2.0577268997828164

Epoch: 6| Step: 3
Training loss: 1.0046981573104858
Validation loss: 2.036811331907908

Epoch: 6| Step: 4
Training loss: 1.7070364952087402
Validation loss: 2.06252650419871

Epoch: 6| Step: 5
Training loss: 1.3215739727020264
Validation loss: 2.106478293736776

Epoch: 6| Step: 6
Training loss: 1.4978671073913574
Validation loss: 2.167606989542643

Epoch: 6| Step: 7
Training loss: 1.1233675479888916
Validation loss: 2.3104039430618286

Epoch: 6| Step: 8
Training loss: 1.1474535465240479
Validation loss: 2.2692980766296387

Epoch: 6| Step: 9
Training loss: 1.5656797885894775
Validation loss: 2.1797016859054565

Epoch: 6| Step: 10
Training loss: 1.161357045173645
Validation loss: 2.063247819741567

Epoch: 6| Step: 11
Training loss: 1.0117015838623047
Validation loss: 2.096246143182119

Epoch: 6| Step: 12
Training loss: 1.281754493713379
Validation loss: 2.1758851408958435

Epoch: 6| Step: 13
Training loss: 1.0588659048080444
Validation loss: 2.0806682308514914

Epoch: 131| Step: 0
Training loss: 1.5097746849060059
Validation loss: 2.047334313392639

Epoch: 6| Step: 1
Training loss: 1.338091254234314
Validation loss: 2.0481106440226235

Epoch: 6| Step: 2
Training loss: 1.0491392612457275
Validation loss: 2.1645897229512534

Epoch: 6| Step: 3
Training loss: 1.2651402950286865
Validation loss: 2.119633754094442

Epoch: 6| Step: 4
Training loss: 0.9171887636184692
Validation loss: 2.1266650557518005

Epoch: 6| Step: 5
Training loss: 1.3358213901519775
Validation loss: 2.2469430764516196

Epoch: 6| Step: 6
Training loss: 1.1990889310836792
Validation loss: 2.1906417409578958

Epoch: 6| Step: 7
Training loss: 1.0959842205047607
Validation loss: 2.1175127824147544

Epoch: 6| Step: 8
Training loss: 0.8252748250961304
Validation loss: 2.103040039539337

Epoch: 6| Step: 9
Training loss: 1.661421298980713
Validation loss: 2.0819016496340432

Epoch: 6| Step: 10
Training loss: 0.8568971157073975
Validation loss: 2.103693882624308

Epoch: 6| Step: 11
Training loss: 1.0200517177581787
Validation loss: 2.1033770640691123

Epoch: 6| Step: 12
Training loss: 0.6890770196914673
Validation loss: 2.0656084219614663

Epoch: 6| Step: 13
Training loss: 1.0098445415496826
Validation loss: 2.0622191627820334

Epoch: 132| Step: 0
Training loss: 0.6903610229492188
Validation loss: 2.0798665086428323

Epoch: 6| Step: 1
Training loss: 1.0372929573059082
Validation loss: 2.1772242983182273

Epoch: 6| Step: 2
Training loss: 0.9798452854156494
Validation loss: 2.1257144610087075

Epoch: 6| Step: 3
Training loss: 1.2814173698425293
Validation loss: 2.1379820903142295

Epoch: 6| Step: 4
Training loss: 1.2453961372375488
Validation loss: 2.116042892138163

Epoch: 6| Step: 5
Training loss: 1.2983293533325195
Validation loss: 2.0945730408032737

Epoch: 6| Step: 6
Training loss: 1.3174798488616943
Validation loss: 2.0098124941190085

Epoch: 6| Step: 7
Training loss: 0.9756866693496704
Validation loss: 2.0200645526250205

Epoch: 6| Step: 8
Training loss: 1.2495150566101074
Validation loss: 2.043207108974457

Epoch: 6| Step: 9
Training loss: 0.7571640014648438
Validation loss: 2.047831197579702

Epoch: 6| Step: 10
Training loss: 1.2787615060806274
Validation loss: 2.065440515677134

Epoch: 6| Step: 11
Training loss: 0.5177404284477234
Validation loss: 2.055978079636892

Epoch: 6| Step: 12
Training loss: 1.3585810661315918
Validation loss: 2.119056145350138

Epoch: 6| Step: 13
Training loss: 1.0702944993972778
Validation loss: 2.0528759161631265

Epoch: 133| Step: 0
Training loss: 1.3516266345977783
Validation loss: 2.0442347725232444

Epoch: 6| Step: 1
Training loss: 0.8020140528678894
Validation loss: 2.0878875652949014

Epoch: 6| Step: 2
Training loss: 0.6869489550590515
Validation loss: 2.0248762170473733

Epoch: 6| Step: 3
Training loss: 0.700933039188385
Validation loss: 1.9756418863932292

Epoch: 6| Step: 4
Training loss: 0.8135168552398682
Validation loss: 2.055579503377279

Epoch: 6| Step: 5
Training loss: 1.1173008680343628
Validation loss: 2.067936579386393

Epoch: 6| Step: 6
Training loss: 1.2192010879516602
Validation loss: 2.0565825502077737

Epoch: 6| Step: 7
Training loss: 0.9221874475479126
Validation loss: 2.0608078837394714

Epoch: 6| Step: 8
Training loss: 1.4324711561203003
Validation loss: 2.119869351387024

Epoch: 6| Step: 9
Training loss: 0.8542054295539856
Validation loss: 2.0182170470555625

Epoch: 6| Step: 10
Training loss: 0.7962695956230164
Validation loss: 2.0483116706212363

Epoch: 6| Step: 11
Training loss: 1.3267714977264404
Validation loss: 2.146178126335144

Epoch: 6| Step: 12
Training loss: 1.0613874197006226
Validation loss: 2.129941244920095

Epoch: 6| Step: 13
Training loss: 0.9896961450576782
Validation loss: 2.1390294233957925

Epoch: 134| Step: 0
Training loss: 0.9160181283950806
Validation loss: 2.079609672228495

Epoch: 6| Step: 1
Training loss: 0.41534626483917236
Validation loss: 2.102099676926931

Epoch: 6| Step: 2
Training loss: 1.5347633361816406
Validation loss: 2.1668353279431662

Epoch: 6| Step: 3
Training loss: 1.343388319015503
Validation loss: 2.1696184078852334

Epoch: 6| Step: 4
Training loss: 1.4311741590499878
Validation loss: 2.181525230407715

Epoch: 6| Step: 5
Training loss: 1.1699934005737305
Validation loss: 2.184415817260742

Epoch: 6| Step: 6
Training loss: 1.3845696449279785
Validation loss: 2.1622606913248696

Epoch: 6| Step: 7
Training loss: 0.8642122149467468
Validation loss: 2.1333714524904885

Epoch: 6| Step: 8
Training loss: 0.5535752773284912
Validation loss: 2.121745487054189

Epoch: 6| Step: 9
Training loss: 1.096585988998413
Validation loss: 2.094614307085673

Epoch: 6| Step: 10
Training loss: 1.1096837520599365
Validation loss: 2.0935098528862

Epoch: 6| Step: 11
Training loss: 0.9415146708488464
Validation loss: 2.0732839107513428

Epoch: 6| Step: 12
Training loss: 1.2055041790008545
Validation loss: 2.0515171885490417

Epoch: 6| Step: 13
Training loss: 0.5542108416557312
Validation loss: 2.082343896230062

Epoch: 135| Step: 0
Training loss: 0.6500333547592163
Validation loss: 2.1330707669258118

Epoch: 6| Step: 1
Training loss: 0.6730978488922119
Validation loss: 2.166643261909485

Epoch: 6| Step: 2
Training loss: 1.6118073463439941
Validation loss: 2.0931734244028726

Epoch: 6| Step: 3
Training loss: 1.2756235599517822
Validation loss: 2.131324370702108

Epoch: 6| Step: 4
Training loss: 0.9148110747337341
Validation loss: 2.093116362889608

Epoch: 6| Step: 5
Training loss: 1.4315769672393799
Validation loss: 2.0984026193618774

Epoch: 6| Step: 6
Training loss: 1.0997822284698486
Validation loss: 2.0947584311167398

Epoch: 6| Step: 7
Training loss: 1.1625213623046875
Validation loss: 2.0620866219202676

Epoch: 6| Step: 8
Training loss: 1.1695963144302368
Validation loss: 2.0526923139890036

Epoch: 6| Step: 9
Training loss: 1.230717420578003
Validation loss: 2.098576386769613

Epoch: 6| Step: 10
Training loss: 0.9179027080535889
Validation loss: 2.083171566327413

Epoch: 6| Step: 11
Training loss: 1.413400411605835
Validation loss: 2.1500051021575928

Epoch: 6| Step: 12
Training loss: 1.0564619302749634
Validation loss: 2.1748255491256714

Epoch: 6| Step: 13
Training loss: 1.042299509048462
Validation loss: 2.213443080584208

Epoch: 136| Step: 0
Training loss: 1.0199015140533447
Validation loss: 2.2263795932133994

Epoch: 6| Step: 1
Training loss: 0.6529887914657593
Validation loss: 2.1064441005388894

Epoch: 6| Step: 2
Training loss: 0.5625420808792114
Validation loss: 2.125618318716685

Epoch: 6| Step: 3
Training loss: 0.9718434810638428
Validation loss: 2.0522074699401855

Epoch: 6| Step: 4
Training loss: 0.9612163305282593
Validation loss: 2.0173757672309875

Epoch: 6| Step: 5
Training loss: 1.328305959701538
Validation loss: 2.0352746645609536

Epoch: 6| Step: 6
Training loss: 0.9666802883148193
Validation loss: 2.098245541254679

Epoch: 6| Step: 7
Training loss: 1.358318567276001
Validation loss: 2.09686549504598

Epoch: 6| Step: 8
Training loss: 1.4414169788360596
Validation loss: 2.035074452559153

Epoch: 6| Step: 9
Training loss: 0.8673901557922363
Validation loss: 2.0807764728864035

Epoch: 6| Step: 10
Training loss: 0.7986764907836914
Validation loss: 2.1112923622131348

Epoch: 6| Step: 11
Training loss: 1.5751574039459229
Validation loss: 2.110466480255127

Epoch: 6| Step: 12
Training loss: 1.0956993103027344
Validation loss: 2.0751013358434043

Epoch: 6| Step: 13
Training loss: 1.118198037147522
Validation loss: 2.149670978387197

Epoch: 137| Step: 0
Training loss: 1.506292462348938
Validation loss: 2.0901962320009866

Epoch: 6| Step: 1
Training loss: 0.6772828102111816
Validation loss: 2.06142524878184

Epoch: 6| Step: 2
Training loss: 0.5568424463272095
Validation loss: 2.1109891335169473

Epoch: 6| Step: 3
Training loss: 0.9179210662841797
Validation loss: 2.1062283317248025

Epoch: 6| Step: 4
Training loss: 0.6998878717422485
Validation loss: 2.0827262798945108

Epoch: 6| Step: 5
Training loss: 1.3892252445220947
Validation loss: 2.043624301751455

Epoch: 6| Step: 6
Training loss: 1.233230471611023
Validation loss: 2.0464112957318625

Epoch: 6| Step: 7
Training loss: 0.9685297012329102
Validation loss: 2.0464523434638977

Epoch: 6| Step: 8
Training loss: 1.270430088043213
Validation loss: 2.1440884669621787

Epoch: 6| Step: 9
Training loss: 0.9383001327514648
Validation loss: 2.1196842789649963

Epoch: 6| Step: 10
Training loss: 1.0886272192001343
Validation loss: 2.188910404841105

Epoch: 6| Step: 11
Training loss: 1.1293327808380127
Validation loss: 2.1095505754152932

Epoch: 6| Step: 12
Training loss: 0.8018885850906372
Validation loss: 2.2049733797709146

Epoch: 6| Step: 13
Training loss: 0.8204441070556641
Validation loss: 2.054899354775747

Epoch: 138| Step: 0
Training loss: 1.2110483646392822
Validation loss: 2.052624821662903

Epoch: 6| Step: 1
Training loss: 1.1183967590332031
Validation loss: 2.041381816069285

Epoch: 6| Step: 2
Training loss: 1.2818996906280518
Validation loss: 2.119754155476888

Epoch: 6| Step: 3
Training loss: 0.9253605604171753
Validation loss: 2.143325388431549

Epoch: 6| Step: 4
Training loss: 1.258117914199829
Validation loss: 2.1025856137275696

Epoch: 6| Step: 5
Training loss: 1.1435317993164062
Validation loss: 2.1051531036694846

Epoch: 6| Step: 6
Training loss: 0.7909250259399414
Validation loss: 2.0160831212997437

Epoch: 6| Step: 7
Training loss: 0.9582038521766663
Validation loss: 2.026172637939453

Epoch: 6| Step: 8
Training loss: 1.0340981483459473
Validation loss: 2.0424588322639465

Epoch: 6| Step: 9
Training loss: 1.097594976425171
Validation loss: 2.0307158827781677

Epoch: 6| Step: 10
Training loss: 0.7624271512031555
Validation loss: 2.086949348449707

Epoch: 6| Step: 11
Training loss: 1.1452088356018066
Validation loss: 2.0968699057896933

Epoch: 6| Step: 12
Training loss: 0.8338559865951538
Validation loss: 2.105472723642985

Epoch: 6| Step: 13
Training loss: 0.7956429719924927
Validation loss: 2.1416687965393066

Epoch: 139| Step: 0
Training loss: 1.2605561017990112
Validation loss: 2.1124116579691568

Epoch: 6| Step: 1
Training loss: 0.9023693203926086
Validation loss: 2.100571552912394

Epoch: 6| Step: 2
Training loss: 0.5475063323974609
Validation loss: 2.1280577977498374

Epoch: 6| Step: 3
Training loss: 1.2090065479278564
Validation loss: 2.087578773498535

Epoch: 6| Step: 4
Training loss: 0.769000768661499
Validation loss: 2.0502386887868247

Epoch: 6| Step: 5
Training loss: 0.6830414533615112
Validation loss: 2.1755725344022117

Epoch: 6| Step: 6
Training loss: 0.8740923404693604
Validation loss: 2.0863800048828125

Epoch: 6| Step: 7
Training loss: 1.1739704608917236
Validation loss: 2.150631070137024

Epoch: 6| Step: 8
Training loss: 1.1849210262298584
Validation loss: 2.134939511617025

Epoch: 6| Step: 9
Training loss: 0.7270369529724121
Validation loss: 2.0869528452555337

Epoch: 6| Step: 10
Training loss: 0.9193219542503357
Validation loss: 2.1115100979804993

Epoch: 6| Step: 11
Training loss: 1.2898743152618408
Validation loss: 2.088652511437734

Epoch: 6| Step: 12
Training loss: 1.2410120964050293
Validation loss: 1.9910431305567424

Epoch: 6| Step: 13
Training loss: 1.0226596593856812
Validation loss: 2.031871795654297

Epoch: 140| Step: 0
Training loss: 0.9702367782592773
Validation loss: 2.047412912050883

Epoch: 6| Step: 1
Training loss: 1.06858229637146
Validation loss: 2.177260438601176

Epoch: 6| Step: 2
Training loss: 0.8447712659835815
Validation loss: 2.205380161603292

Epoch: 6| Step: 3
Training loss: 1.1677533388137817
Validation loss: 2.179682195186615

Epoch: 6| Step: 4
Training loss: 0.8004237413406372
Validation loss: 2.145929992198944

Epoch: 6| Step: 5
Training loss: 1.0915213823318481
Validation loss: 2.121060013771057

Epoch: 6| Step: 6
Training loss: 0.6700923442840576
Validation loss: 2.02744323015213

Epoch: 6| Step: 7
Training loss: 1.0504329204559326
Validation loss: 2.119153380393982

Epoch: 6| Step: 8
Training loss: 1.2454173564910889
Validation loss: 2.0269155303637185

Epoch: 6| Step: 9
Training loss: 0.8857004642486572
Validation loss: 2.085085153579712

Epoch: 6| Step: 10
Training loss: 1.129355549812317
Validation loss: 2.026141583919525

Epoch: 6| Step: 11
Training loss: 1.480489730834961
Validation loss: 2.0495877663294473

Epoch: 6| Step: 12
Training loss: 0.798851490020752
Validation loss: 2.148163656393687

Epoch: 6| Step: 13
Training loss: 0.9697731733322144
Validation loss: 2.248653789361318

Epoch: 141| Step: 0
Training loss: 0.8962386846542358
Validation loss: 2.2378046909968057

Epoch: 6| Step: 1
Training loss: 1.5270298719406128
Validation loss: 2.2255344788233438

Epoch: 6| Step: 2
Training loss: 0.9618091583251953
Validation loss: 2.2323907216389975

Epoch: 6| Step: 3
Training loss: 0.9443984031677246
Validation loss: 2.088738739490509

Epoch: 6| Step: 4
Training loss: 1.1079108715057373
Validation loss: 2.021225174268087

Epoch: 6| Step: 5
Training loss: 1.4290294647216797
Validation loss: 2.1053565541903176

Epoch: 6| Step: 6
Training loss: 0.9613733291625977
Validation loss: 2.112187385559082

Epoch: 6| Step: 7
Training loss: 1.6352829933166504
Validation loss: 2.029366930325826

Epoch: 6| Step: 8
Training loss: 0.9895373582839966
Validation loss: 2.1282675663630166

Epoch: 6| Step: 9
Training loss: 1.2810434103012085
Validation loss: 2.1244099140167236

Epoch: 6| Step: 10
Training loss: 0.9039832949638367
Validation loss: 2.156915624936422

Epoch: 6| Step: 11
Training loss: 0.9321417808532715
Validation loss: 2.26944907506307

Epoch: 6| Step: 12
Training loss: 1.2082746028900146
Validation loss: 2.2049341201782227

Epoch: 6| Step: 13
Training loss: 1.147572636604309
Validation loss: 2.2734700640042624

Epoch: 142| Step: 0
Training loss: 0.7632936835289001
Validation loss: 2.1261006593704224

Epoch: 6| Step: 1
Training loss: 0.9860068559646606
Validation loss: 2.1171457370122275

Epoch: 6| Step: 2
Training loss: 0.7798984050750732
Validation loss: 2.0393701990445456

Epoch: 6| Step: 3
Training loss: 0.8007408380508423
Validation loss: 2.058535913626353

Epoch: 6| Step: 4
Training loss: 1.2102737426757812
Validation loss: 2.056641936302185

Epoch: 6| Step: 5
Training loss: 0.6666961908340454
Validation loss: 2.067210574944814

Epoch: 6| Step: 6
Training loss: 0.8807789087295532
Validation loss: 2.0919800798098245

Epoch: 6| Step: 7
Training loss: 1.8412164449691772
Validation loss: 2.1149011055628457

Epoch: 6| Step: 8
Training loss: 0.8584458231925964
Validation loss: 2.159343163172404

Epoch: 6| Step: 9
Training loss: 0.8701469302177429
Validation loss: 2.118285516897837

Epoch: 6| Step: 10
Training loss: 0.9058139324188232
Validation loss: 2.1334675550460815

Epoch: 6| Step: 11
Training loss: 1.1424343585968018
Validation loss: 2.1129473447799683

Epoch: 6| Step: 12
Training loss: 0.88969486951828
Validation loss: 2.1340622107187905

Epoch: 6| Step: 13
Training loss: 1.0928516387939453
Validation loss: 2.0728640953699746

Epoch: 143| Step: 0
Training loss: 0.6111565828323364
Validation loss: 2.0865355928738913

Epoch: 6| Step: 1
Training loss: 0.9048199653625488
Validation loss: 2.1367193460464478

Epoch: 6| Step: 2
Training loss: 1.3929026126861572
Validation loss: 2.1095226407051086

Epoch: 6| Step: 3
Training loss: 0.665635347366333
Validation loss: 2.136343240737915

Epoch: 6| Step: 4
Training loss: 1.715293526649475
Validation loss: 2.0765204429626465

Epoch: 6| Step: 5
Training loss: 0.7904133796691895
Validation loss: 2.1060051123301187

Epoch: 6| Step: 6
Training loss: 0.7074227333068848
Validation loss: 2.13405579328537

Epoch: 6| Step: 7
Training loss: 0.858896017074585
Validation loss: 2.161978860696157

Epoch: 6| Step: 8
Training loss: 1.2266626358032227
Validation loss: 2.2138003508249917

Epoch: 6| Step: 9
Training loss: 0.7364338040351868
Validation loss: 2.125257154305776

Epoch: 6| Step: 10
Training loss: 1.1850156784057617
Validation loss: 2.1811586221059165

Epoch: 6| Step: 11
Training loss: 0.8136447072029114
Validation loss: 2.0598434011141458

Epoch: 6| Step: 12
Training loss: 0.8106576800346375
Validation loss: 1.9896257122357686

Epoch: 6| Step: 13
Training loss: 1.0417028665542603
Validation loss: 2.05527134736379

Epoch: 144| Step: 0
Training loss: 1.1144793033599854
Validation loss: 2.0662155151367188

Epoch: 6| Step: 1
Training loss: 0.6634902358055115
Validation loss: 2.197220245997111

Epoch: 6| Step: 2
Training loss: 0.7829763889312744
Validation loss: 2.0658922592798867

Epoch: 6| Step: 3
Training loss: 0.8396015763282776
Validation loss: 2.1614545583724976

Epoch: 6| Step: 4
Training loss: 0.5665284991264343
Validation loss: 2.130266785621643

Epoch: 6| Step: 5
Training loss: 0.9461082816123962
Validation loss: 2.145648777484894

Epoch: 6| Step: 6
Training loss: 0.4777698516845703
Validation loss: 2.083711584409078

Epoch: 6| Step: 7
Training loss: 0.8451992273330688
Validation loss: 2.0647300481796265

Epoch: 6| Step: 8
Training loss: 1.274874210357666
Validation loss: 2.078514118989309

Epoch: 6| Step: 9
Training loss: 1.2960940599441528
Validation loss: 2.0885176261266074

Epoch: 6| Step: 10
Training loss: 1.0314868688583374
Validation loss: 2.1528272231419883

Epoch: 6| Step: 11
Training loss: 1.0130915641784668
Validation loss: 2.0756962299346924

Epoch: 6| Step: 12
Training loss: 1.1558586359024048
Validation loss: 2.1715577443440757

Epoch: 6| Step: 13
Training loss: 1.3635585308074951
Validation loss: 2.174488882223765

Epoch: 145| Step: 0
Training loss: 0.672407329082489
Validation loss: 2.2727831999460855

Epoch: 6| Step: 1
Training loss: 0.6968566179275513
Validation loss: 2.171678841114044

Epoch: 6| Step: 2
Training loss: 1.0292766094207764
Validation loss: 2.1763949592908225

Epoch: 6| Step: 3
Training loss: 1.0474419593811035
Validation loss: 2.098231871922811

Epoch: 6| Step: 4
Training loss: 0.7083085775375366
Validation loss: 2.0902708768844604

Epoch: 6| Step: 5
Training loss: 1.0157983303070068
Validation loss: 2.1421876549720764

Epoch: 6| Step: 6
Training loss: 0.7721269130706787
Validation loss: 2.1184873580932617

Epoch: 6| Step: 7
Training loss: 0.7796017527580261
Validation loss: 2.0555068254470825

Epoch: 6| Step: 8
Training loss: 1.12558913230896
Validation loss: 2.1157750487327576

Epoch: 6| Step: 9
Training loss: 0.8233035802841187
Validation loss: 2.16049995024999

Epoch: 6| Step: 10
Training loss: 1.3367364406585693
Validation loss: 2.1184784372647605

Epoch: 6| Step: 11
Training loss: 0.8652958273887634
Validation loss: 2.133018910884857

Epoch: 6| Step: 12
Training loss: 1.1038565635681152
Validation loss: 2.1456108490626016

Epoch: 6| Step: 13
Training loss: 1.1493268013000488
Validation loss: 2.095033288002014

Epoch: 146| Step: 0
Training loss: 0.9817550182342529
Validation loss: 2.0776081681251526

Epoch: 6| Step: 1
Training loss: 1.1428496837615967
Validation loss: 2.1619863510131836

Epoch: 6| Step: 2
Training loss: 0.8995823860168457
Validation loss: 2.120330492655436

Epoch: 6| Step: 3
Training loss: 1.0550529956817627
Validation loss: 2.1791430910428367

Epoch: 6| Step: 4
Training loss: 0.9223663806915283
Validation loss: 2.1940524776776633

Epoch: 6| Step: 5
Training loss: 1.1695603132247925
Validation loss: 2.1580126881599426

Epoch: 6| Step: 6
Training loss: 0.7214623689651489
Validation loss: 2.1693618297576904

Epoch: 6| Step: 7
Training loss: 0.7501875162124634
Validation loss: 2.0887189308802285

Epoch: 6| Step: 8
Training loss: 0.7765437364578247
Validation loss: 2.074364483356476

Epoch: 6| Step: 9
Training loss: 0.8652805089950562
Validation loss: 2.1984212001164756

Epoch: 6| Step: 10
Training loss: 0.8329582214355469
Validation loss: 2.1696571111679077

Epoch: 6| Step: 11
Training loss: 1.1739296913146973
Validation loss: 2.1720572113990784

Epoch: 6| Step: 12
Training loss: 0.6232689619064331
Validation loss: 2.1846977869669595

Epoch: 6| Step: 13
Training loss: 1.1192426681518555
Validation loss: 2.1461460987726846

Epoch: 147| Step: 0
Training loss: 1.0624281167984009
Validation loss: 2.123502572377523

Epoch: 6| Step: 1
Training loss: 0.8887850046157837
Validation loss: 2.060355305671692

Epoch: 6| Step: 2
Training loss: 1.1629505157470703
Validation loss: 2.116713285446167

Epoch: 6| Step: 3
Training loss: 0.861177384853363
Validation loss: 2.064450224240621

Epoch: 6| Step: 4
Training loss: 1.774944543838501
Validation loss: 2.1792569557825723

Epoch: 6| Step: 5
Training loss: 1.3419424295425415
Validation loss: 2.193840483824412

Epoch: 6| Step: 6
Training loss: 1.1936171054840088
Validation loss: 2.1965250770250955

Epoch: 6| Step: 7
Training loss: 1.0594971179962158
Validation loss: 2.188741604487101

Epoch: 6| Step: 8
Training loss: 0.7396466732025146
Validation loss: 2.175511638323466

Epoch: 6| Step: 9
Training loss: 0.8089544773101807
Validation loss: 2.0803064703941345

Epoch: 6| Step: 10
Training loss: 0.6979555487632751
Validation loss: 2.090583344300588

Epoch: 6| Step: 11
Training loss: 0.9179748892784119
Validation loss: 2.119475841522217

Epoch: 6| Step: 12
Training loss: 0.7049154043197632
Validation loss: 2.068326393763224

Epoch: 6| Step: 13
Training loss: 0.6175919771194458
Validation loss: 2.102282683054606

Epoch: 148| Step: 0
Training loss: 1.1875061988830566
Validation loss: 2.1086259881655374

Epoch: 6| Step: 1
Training loss: 0.5866572856903076
Validation loss: 2.170882066090902

Epoch: 6| Step: 2
Training loss: 0.7788535356521606
Validation loss: 2.1934178670247397

Epoch: 6| Step: 3
Training loss: 0.7592486143112183
Validation loss: 2.1511945724487305

Epoch: 6| Step: 4
Training loss: 0.8821854591369629
Validation loss: 2.180612405141195

Epoch: 6| Step: 5
Training loss: 1.5007660388946533
Validation loss: 2.1303357680638633

Epoch: 6| Step: 6
Training loss: 1.0914018154144287
Validation loss: 2.0936619440714517

Epoch: 6| Step: 7
Training loss: 1.2956818342208862
Validation loss: 2.1518844962120056

Epoch: 6| Step: 8
Training loss: 0.74974524974823
Validation loss: 2.142022987206777

Epoch: 6| Step: 9
Training loss: 0.7283422946929932
Validation loss: 2.158332665761312

Epoch: 6| Step: 10
Training loss: 0.7601766586303711
Validation loss: 2.1351484258969626

Epoch: 6| Step: 11
Training loss: 0.8340896964073181
Validation loss: 2.214318831761678

Epoch: 6| Step: 12
Training loss: 1.048903226852417
Validation loss: 2.147314270337423

Epoch: 6| Step: 13
Training loss: 1.1275343894958496
Validation loss: 2.1669293443361917

Epoch: 149| Step: 0
Training loss: 1.1237666606903076
Validation loss: 2.1875954270362854

Epoch: 6| Step: 1
Training loss: 0.8871442079544067
Validation loss: 2.112009863058726

Epoch: 6| Step: 2
Training loss: 0.45285430550575256
Validation loss: 2.1061185399691262

Epoch: 6| Step: 3
Training loss: 0.6795421838760376
Validation loss: 2.1320334871610007

Epoch: 6| Step: 4
Training loss: 0.3771343529224396
Validation loss: 2.142127215862274

Epoch: 6| Step: 5
Training loss: 0.8049406409263611
Validation loss: 2.1427997946739197

Epoch: 6| Step: 6
Training loss: 0.6937022805213928
Validation loss: 2.1245291034380593

Epoch: 6| Step: 7
Training loss: 0.7113654017448425
Validation loss: 2.1262075901031494

Epoch: 6| Step: 8
Training loss: 1.5172295570373535
Validation loss: 2.197318414847056

Epoch: 6| Step: 9
Training loss: 1.080838918685913
Validation loss: 2.169488251209259

Epoch: 6| Step: 10
Training loss: 1.1681488752365112
Validation loss: 2.1061997413635254

Epoch: 6| Step: 11
Training loss: 0.6815768480300903
Validation loss: 2.128525952498118

Epoch: 6| Step: 12
Training loss: 0.8006258010864258
Validation loss: 2.083953102429708

Epoch: 6| Step: 13
Training loss: 1.336546778678894
Validation loss: 2.061933616797129

Epoch: 150| Step: 0
Training loss: 0.7268577814102173
Validation loss: 2.084570070107778

Epoch: 6| Step: 1
Training loss: 1.0349000692367554
Validation loss: 2.1483554442723594

Epoch: 6| Step: 2
Training loss: 0.973295271396637
Validation loss: 2.1676639119784036

Epoch: 6| Step: 3
Training loss: 0.42643293738365173
Validation loss: 2.138485550880432

Epoch: 6| Step: 4
Training loss: 1.0451624393463135
Validation loss: 2.1139184633890786

Epoch: 6| Step: 5
Training loss: 0.8135398030281067
Validation loss: 2.158181309700012

Epoch: 6| Step: 6
Training loss: 0.763280987739563
Validation loss: 2.121886750062307

Epoch: 6| Step: 7
Training loss: 1.173208475112915
Validation loss: 2.141452372074127

Epoch: 6| Step: 8
Training loss: 0.6247366070747375
Validation loss: 2.058220465977987

Epoch: 6| Step: 9
Training loss: 0.9445228576660156
Validation loss: 2.112646520137787

Epoch: 6| Step: 10
Training loss: 0.8855062127113342
Validation loss: 2.0897932648658752

Epoch: 6| Step: 11
Training loss: 0.6329206228256226
Validation loss: 2.09261691570282

Epoch: 6| Step: 12
Training loss: 1.0592477321624756
Validation loss: 2.0679532289505005

Epoch: 6| Step: 13
Training loss: 1.0479168891906738
Validation loss: 2.113724112510681

Epoch: 151| Step: 0
Training loss: 0.7482396960258484
Validation loss: 2.125835915406545

Epoch: 6| Step: 1
Training loss: 0.9647709131240845
Validation loss: 2.176761269569397

Epoch: 6| Step: 2
Training loss: 0.4268380403518677
Validation loss: 2.1352680722872415

Epoch: 6| Step: 3
Training loss: 1.1028051376342773
Validation loss: 2.143022815386454

Epoch: 6| Step: 4
Training loss: 0.9065753221511841
Validation loss: 2.127981940905253

Epoch: 6| Step: 5
Training loss: 0.6894822120666504
Validation loss: 2.160274783770243

Epoch: 6| Step: 6
Training loss: 0.9600251317024231
Validation loss: 2.1779476006825766

Epoch: 6| Step: 7
Training loss: 1.0198633670806885
Validation loss: 2.169413208961487

Epoch: 6| Step: 8
Training loss: 1.034602165222168
Validation loss: 2.201203207174937

Epoch: 6| Step: 9
Training loss: 0.5553932785987854
Validation loss: 2.1155343850453696

Epoch: 6| Step: 10
Training loss: 0.9371892809867859
Validation loss: 2.112090786298116

Epoch: 6| Step: 11
Training loss: 0.5957743525505066
Validation loss: 2.100998818874359

Epoch: 6| Step: 12
Training loss: 0.9319505095481873
Validation loss: 2.1091063221295676

Epoch: 6| Step: 13
Training loss: 0.9065062999725342
Validation loss: 2.2046548326810202

Epoch: 152| Step: 0
Training loss: 1.0859652757644653
Validation loss: 2.100442330042521

Epoch: 6| Step: 1
Training loss: 0.7266604900360107
Validation loss: 2.1438123186429343

Epoch: 6| Step: 2
Training loss: 0.569679319858551
Validation loss: 2.1707111994425454

Epoch: 6| Step: 3
Training loss: 1.1922574043273926
Validation loss: 2.1814523736635842

Epoch: 6| Step: 4
Training loss: 0.9968001842498779
Validation loss: 2.1585938135782876

Epoch: 6| Step: 5
Training loss: 0.8246307373046875
Validation loss: 2.137139678001404

Epoch: 6| Step: 6
Training loss: 0.9156904816627502
Validation loss: 2.1877564986546836

Epoch: 6| Step: 7
Training loss: 0.891656756401062
Validation loss: 2.1466538310050964

Epoch: 6| Step: 8
Training loss: 0.901352047920227
Validation loss: 2.1572842597961426

Epoch: 6| Step: 9
Training loss: 1.3690036535263062
Validation loss: 2.187345584233602

Epoch: 6| Step: 10
Training loss: 0.9011591672897339
Validation loss: 2.255822459856669

Epoch: 6| Step: 11
Training loss: 0.6034923791885376
Validation loss: 2.241602877775828

Epoch: 6| Step: 12
Training loss: 0.5585788488388062
Validation loss: 2.1156911849975586

Epoch: 6| Step: 13
Training loss: 0.889129638671875
Validation loss: 2.146016319592794

Epoch: 153| Step: 0
Training loss: 0.731992244720459
Validation loss: 2.093368093172709

Epoch: 6| Step: 1
Training loss: 0.7485560178756714
Validation loss: 2.08991531531016

Epoch: 6| Step: 2
Training loss: 0.9749709367752075
Validation loss: 2.117640217145284

Epoch: 6| Step: 3
Training loss: 0.7392523884773254
Validation loss: 2.0423481663068137

Epoch: 6| Step: 4
Training loss: 0.7552986145019531
Validation loss: 2.114575763543447

Epoch: 6| Step: 5
Training loss: 1.2767630815505981
Validation loss: 2.042729139328003

Epoch: 6| Step: 6
Training loss: 1.177844762802124
Validation loss: 2.1438777248064675

Epoch: 6| Step: 7
Training loss: 0.9719403982162476
Validation loss: 2.162798285484314

Epoch: 6| Step: 8
Training loss: 0.7125864624977112
Validation loss: 2.1618436773618064

Epoch: 6| Step: 9
Training loss: 1.1092106103897095
Validation loss: 2.1532197992006936

Epoch: 6| Step: 10
Training loss: 0.5040265917778015
Validation loss: 2.185518185297648

Epoch: 6| Step: 11
Training loss: 0.6673527359962463
Validation loss: 2.155089279015859

Epoch: 6| Step: 12
Training loss: 0.39137664437294006
Validation loss: 2.1750998298327127

Epoch: 6| Step: 13
Training loss: 0.9965873956680298
Validation loss: 2.2284215887387595

Epoch: 154| Step: 0
Training loss: 0.49907249212265015
Validation loss: 2.1497212648391724

Epoch: 6| Step: 1
Training loss: 1.2828890085220337
Validation loss: 2.1389824748039246

Epoch: 6| Step: 2
Training loss: 0.7776099443435669
Validation loss: 2.0607022841771445

Epoch: 6| Step: 3
Training loss: 0.7283480763435364
Validation loss: 2.1979248921076455

Epoch: 6| Step: 4
Training loss: 0.8313330411911011
Validation loss: 2.092838625113169

Epoch: 6| Step: 5
Training loss: 0.7484317421913147
Validation loss: 2.104084014892578

Epoch: 6| Step: 6
Training loss: 1.0145113468170166
Validation loss: 2.1465980211893716

Epoch: 6| Step: 7
Training loss: 0.7445592284202576
Validation loss: 2.087975859642029

Epoch: 6| Step: 8
Training loss: 0.37185072898864746
Validation loss: 2.1102136174837747

Epoch: 6| Step: 9
Training loss: 1.0374016761779785
Validation loss: 2.1551469961802163

Epoch: 6| Step: 10
Training loss: 1.4416453838348389
Validation loss: 2.1489993731180825

Epoch: 6| Step: 11
Training loss: 0.7870768308639526
Validation loss: 2.149515390396118

Epoch: 6| Step: 12
Training loss: 0.7158464193344116
Validation loss: 2.144632637500763

Epoch: 6| Step: 13
Training loss: 0.8284158706665039
Validation loss: 2.10272079706192

Epoch: 155| Step: 0
Training loss: 1.0896697044372559
Validation loss: 2.1489568948745728

Epoch: 6| Step: 1
Training loss: 0.35641688108444214
Validation loss: 2.213132162888845

Epoch: 6| Step: 2
Training loss: 1.1729129552841187
Validation loss: 2.1737886865933738

Epoch: 6| Step: 3
Training loss: 0.6878575086593628
Validation loss: 2.115573843320211

Epoch: 6| Step: 4
Training loss: 0.8484853506088257
Validation loss: 2.147456109523773

Epoch: 6| Step: 5
Training loss: 0.8918604850769043
Validation loss: 2.059467593828837

Epoch: 6| Step: 6
Training loss: 1.0162873268127441
Validation loss: 2.068368911743164

Epoch: 6| Step: 7
Training loss: 0.8465128540992737
Validation loss: 2.148591915766398

Epoch: 6| Step: 8
Training loss: 0.7541225552558899
Validation loss: 2.128903786341349

Epoch: 6| Step: 9
Training loss: 0.5968855619430542
Validation loss: 2.0971487164497375

Epoch: 6| Step: 10
Training loss: 0.8358855247497559
Validation loss: 2.1894211371739707

Epoch: 6| Step: 11
Training loss: 1.0909414291381836
Validation loss: 2.163910726706187

Epoch: 6| Step: 12
Training loss: 0.7908657193183899
Validation loss: 2.1055302222569785

Epoch: 6| Step: 13
Training loss: 0.8523332476615906
Validation loss: 2.1328604420026145

Epoch: 156| Step: 0
Training loss: 0.8879604339599609
Validation loss: 2.1212581594785056

Epoch: 6| Step: 1
Training loss: 0.649000883102417
Validation loss: 2.1154657999674478

Epoch: 6| Step: 2
Training loss: 1.161893367767334
Validation loss: 2.107268532117208

Epoch: 6| Step: 3
Training loss: 0.9881033897399902
Validation loss: 2.0792895754178367

Epoch: 6| Step: 4
Training loss: 0.37462547421455383
Validation loss: 2.1279490987459817

Epoch: 6| Step: 5
Training loss: 0.8861358761787415
Validation loss: 2.1202445824941

Epoch: 6| Step: 6
Training loss: 0.8783032894134521
Validation loss: 2.1628402868906655

Epoch: 6| Step: 7
Training loss: 0.5454573631286621
Validation loss: 2.1603922645250955

Epoch: 6| Step: 8
Training loss: 0.705596923828125
Validation loss: 2.1059447526931763

Epoch: 6| Step: 9
Training loss: 1.4120715856552124
Validation loss: 2.2110609014829

Epoch: 6| Step: 10
Training loss: 0.9798043966293335
Validation loss: 2.2485583424568176

Epoch: 6| Step: 11
Training loss: 0.5968768000602722
Validation loss: 2.1798245509465537

Epoch: 6| Step: 12
Training loss: 0.8825726509094238
Validation loss: 2.1811008850733438

Epoch: 6| Step: 13
Training loss: 1.1300190687179565
Validation loss: 2.1696722706158957

Epoch: 157| Step: 0
Training loss: 0.7871888279914856
Validation loss: 2.112001041571299

Epoch: 6| Step: 1
Training loss: 0.6780276298522949
Validation loss: 2.165063222249349

Epoch: 6| Step: 2
Training loss: 0.5600665807723999
Validation loss: 2.205973664919535

Epoch: 6| Step: 3
Training loss: 1.2484980821609497
Validation loss: 2.1789551377296448

Epoch: 6| Step: 4
Training loss: 0.9822474718093872
Validation loss: 2.1246273517608643

Epoch: 6| Step: 5
Training loss: 1.1375203132629395
Validation loss: 2.0818572839101157

Epoch: 6| Step: 6
Training loss: 0.6173670887947083
Validation loss: 2.093154708544413

Epoch: 6| Step: 7
Training loss: 0.5709316730499268
Validation loss: 2.15825347105662

Epoch: 6| Step: 8
Training loss: 1.0449650287628174
Validation loss: 2.1938281059265137

Epoch: 6| Step: 9
Training loss: 0.5991559028625488
Validation loss: 2.1604254245758057

Epoch: 6| Step: 10
Training loss: 0.7730865478515625
Validation loss: 2.1993767817815146

Epoch: 6| Step: 11
Training loss: 0.8629958033561707
Validation loss: 2.1440207958221436

Epoch: 6| Step: 12
Training loss: 0.8556241989135742
Validation loss: 2.1123822728792825

Epoch: 6| Step: 13
Training loss: 0.4593379497528076
Validation loss: 2.2044441302617392

Epoch: 158| Step: 0
Training loss: 0.6344175338745117
Validation loss: 2.2039796710014343

Epoch: 6| Step: 1
Training loss: 0.4162362217903137
Validation loss: 2.124699910481771

Epoch: 6| Step: 2
Training loss: 0.6226469278335571
Validation loss: 2.171324908733368

Epoch: 6| Step: 3
Training loss: 0.7738579511642456
Validation loss: 2.1384761134783425

Epoch: 6| Step: 4
Training loss: 0.6827176809310913
Validation loss: 2.2065075039863586

Epoch: 6| Step: 5
Training loss: 0.9681410789489746
Validation loss: 2.158389151096344

Epoch: 6| Step: 6
Training loss: 1.0704233646392822
Validation loss: 2.096578617890676

Epoch: 6| Step: 7
Training loss: 1.2544350624084473
Validation loss: 2.163334389527639

Epoch: 6| Step: 8
Training loss: 0.9864864349365234
Validation loss: 2.1235890785853067

Epoch: 6| Step: 9
Training loss: 0.7303217649459839
Validation loss: 2.2299623092015586

Epoch: 6| Step: 10
Training loss: 0.7396070957183838
Validation loss: 2.1803832252820334

Epoch: 6| Step: 11
Training loss: 0.758895754814148
Validation loss: 2.176993668079376

Epoch: 6| Step: 12
Training loss: 1.1648857593536377
Validation loss: 2.0886579950650535

Epoch: 6| Step: 13
Training loss: 0.6100919842720032
Validation loss: 2.1439815759658813

Epoch: 159| Step: 0
Training loss: 0.8295958042144775
Validation loss: 2.0855196118354797

Epoch: 6| Step: 1
Training loss: 0.6489683389663696
Validation loss: 2.193889637788137

Epoch: 6| Step: 2
Training loss: 0.9114784002304077
Validation loss: 2.2102288405100503

Epoch: 6| Step: 3
Training loss: 0.831304669380188
Validation loss: 2.23775980869929

Epoch: 6| Step: 4
Training loss: 0.5082643628120422
Validation loss: 2.2210589249928794

Epoch: 6| Step: 5
Training loss: 1.3503552675247192
Validation loss: 2.2694753209749856

Epoch: 6| Step: 6
Training loss: 0.8458248376846313
Validation loss: 2.121073842048645

Epoch: 6| Step: 7
Training loss: 0.963053822517395
Validation loss: 2.1336157520612082

Epoch: 6| Step: 8
Training loss: 0.7808036804199219
Validation loss: 2.0724791487058005

Epoch: 6| Step: 9
Training loss: 1.03239905834198
Validation loss: 2.1261625488599143

Epoch: 6| Step: 10
Training loss: 1.1778491735458374
Validation loss: 2.1612836718559265

Epoch: 6| Step: 11
Training loss: 0.8530875444412231
Validation loss: 2.0805729627609253

Epoch: 6| Step: 12
Training loss: 0.6364333629608154
Validation loss: 2.110108037789663

Epoch: 6| Step: 13
Training loss: 0.9875255823135376
Validation loss: 2.183229923248291

Epoch: 160| Step: 0
Training loss: 0.9737382531166077
Validation loss: 2.1526036461194358

Epoch: 6| Step: 1
Training loss: 1.0086791515350342
Validation loss: 2.2602845231691995

Epoch: 6| Step: 2
Training loss: 0.8236931562423706
Validation loss: 2.232528885205587

Epoch: 6| Step: 3
Training loss: 1.393365502357483
Validation loss: 2.179361899693807

Epoch: 6| Step: 4
Training loss: 0.7749342918395996
Validation loss: 2.089819848537445

Epoch: 6| Step: 5
Training loss: 0.9729257822036743
Validation loss: 2.0859041015307107

Epoch: 6| Step: 6
Training loss: 0.6461814641952515
Validation loss: 2.1313471595446267

Epoch: 6| Step: 7
Training loss: 0.9399633407592773
Validation loss: 2.131436824798584

Epoch: 6| Step: 8
Training loss: 0.8594192862510681
Validation loss: 2.181116203467051

Epoch: 6| Step: 9
Training loss: 1.0446127653121948
Validation loss: 2.1370071371396384

Epoch: 6| Step: 10
Training loss: 0.6552055478096008
Validation loss: 2.1580628951390586

Epoch: 6| Step: 11
Training loss: 0.7833106517791748
Validation loss: 2.1761834025382996

Epoch: 6| Step: 12
Training loss: 0.7653290629386902
Validation loss: 2.2323874632517495

Epoch: 6| Step: 13
Training loss: 1.1889641284942627
Validation loss: 2.2817432284355164

Epoch: 161| Step: 0
Training loss: 0.6549060940742493
Validation loss: 2.153795301914215

Epoch: 6| Step: 1
Training loss: 1.241208553314209
Validation loss: 2.1245053013165793

Epoch: 6| Step: 2
Training loss: 0.8079666495323181
Validation loss: 2.1653294960657754

Epoch: 6| Step: 3
Training loss: 0.953607976436615
Validation loss: 2.0731703837712607

Epoch: 6| Step: 4
Training loss: 0.8299257755279541
Validation loss: 2.12137770652771

Epoch: 6| Step: 5
Training loss: 0.6991734504699707
Validation loss: 2.088728944460551

Epoch: 6| Step: 6
Training loss: 0.8518863320350647
Validation loss: 2.1383519570032754

Epoch: 6| Step: 7
Training loss: 0.8506075143814087
Validation loss: 2.1067925095558167

Epoch: 6| Step: 8
Training loss: 0.6842899322509766
Validation loss: 2.2171643376350403

Epoch: 6| Step: 9
Training loss: 0.5716222524642944
Validation loss: 2.1673930486043296

Epoch: 6| Step: 10
Training loss: 0.8994083404541016
Validation loss: 2.2112280130386353

Epoch: 6| Step: 11
Training loss: 0.7823859453201294
Validation loss: 2.188839912414551

Epoch: 6| Step: 12
Training loss: 1.0072999000549316
Validation loss: 2.081425368785858

Epoch: 6| Step: 13
Training loss: 0.7628140449523926
Validation loss: 2.0730143785476685

Epoch: 162| Step: 0
Training loss: 0.6668674349784851
Validation loss: 2.1657601793607077

Epoch: 6| Step: 1
Training loss: 0.48207685351371765
Validation loss: 2.0640917817751565

Epoch: 6| Step: 2
Training loss: 0.8675887584686279
Validation loss: 2.153572996457418

Epoch: 6| Step: 3
Training loss: 0.7682081460952759
Validation loss: 2.1656853357950845

Epoch: 6| Step: 4
Training loss: 0.7729874849319458
Validation loss: 2.15936279296875

Epoch: 6| Step: 5
Training loss: 0.6545089483261108
Validation loss: 2.164058744907379

Epoch: 6| Step: 6
Training loss: 1.1580413579940796
Validation loss: 2.250374515851339

Epoch: 6| Step: 7
Training loss: 0.5273694396018982
Validation loss: 2.204045573870341

Epoch: 6| Step: 8
Training loss: 0.6668139696121216
Validation loss: 2.1137723128000894

Epoch: 6| Step: 9
Training loss: 0.6623421907424927
Validation loss: 2.0672751863797507

Epoch: 6| Step: 10
Training loss: 1.1103708744049072
Validation loss: 2.1344335476557412

Epoch: 6| Step: 11
Training loss: 1.0185065269470215
Validation loss: 2.0816231966018677

Epoch: 6| Step: 12
Training loss: 0.6790518760681152
Validation loss: 2.104498306910197

Epoch: 6| Step: 13
Training loss: 1.3455044031143188
Validation loss: 2.128468076388041

Epoch: 163| Step: 0
Training loss: 0.8487212657928467
Validation loss: 2.110163370768229

Epoch: 6| Step: 1
Training loss: 0.5176801085472107
Validation loss: 2.1187466581662497

Epoch: 6| Step: 2
Training loss: 1.049770474433899
Validation loss: 2.1956207950909934

Epoch: 6| Step: 3
Training loss: 1.0161070823669434
Validation loss: 2.245794713497162

Epoch: 6| Step: 4
Training loss: 0.7210421562194824
Validation loss: 2.208504398663839

Epoch: 6| Step: 5
Training loss: 1.0046815872192383
Validation loss: 2.1649226546287537

Epoch: 6| Step: 6
Training loss: 0.566865086555481
Validation loss: 2.1374939680099487

Epoch: 6| Step: 7
Training loss: 0.6837905645370483
Validation loss: 2.1308444142341614

Epoch: 6| Step: 8
Training loss: 0.9083718061447144
Validation loss: 2.083843390146891

Epoch: 6| Step: 9
Training loss: 0.4816049635410309
Validation loss: 2.1318095525105796

Epoch: 6| Step: 10
Training loss: 0.937677264213562
Validation loss: 2.1455761194229126

Epoch: 6| Step: 11
Training loss: 1.0504212379455566
Validation loss: 2.1637363831202188

Epoch: 6| Step: 12
Training loss: 0.773543119430542
Validation loss: 2.1464080810546875

Epoch: 6| Step: 13
Training loss: 0.8034682273864746
Validation loss: 2.127545416355133

Epoch: 164| Step: 0
Training loss: 0.6914739012718201
Validation loss: 2.1654541293780007

Epoch: 6| Step: 1
Training loss: 0.8927047252655029
Validation loss: 2.175101419289907

Epoch: 6| Step: 2
Training loss: 0.6091720461845398
Validation loss: 2.100399891535441

Epoch: 6| Step: 3
Training loss: 0.7065792083740234
Validation loss: 2.1353774269421897

Epoch: 6| Step: 4
Training loss: 0.9479125738143921
Validation loss: 2.181888004144033

Epoch: 6| Step: 5
Training loss: 0.5665542483329773
Validation loss: 2.169813950856527

Epoch: 6| Step: 6
Training loss: 1.3566858768463135
Validation loss: 2.1482563813527427

Epoch: 6| Step: 7
Training loss: 0.7328140735626221
Validation loss: 2.1357524593671164

Epoch: 6| Step: 8
Training loss: 0.8238722085952759
Validation loss: 2.1976660092671714

Epoch: 6| Step: 9
Training loss: 1.0830981731414795
Validation loss: 2.161033511161804

Epoch: 6| Step: 10
Training loss: 0.48809531331062317
Validation loss: 2.1479371587435403

Epoch: 6| Step: 11
Training loss: 0.874860405921936
Validation loss: 2.1225141684214273

Epoch: 6| Step: 12
Training loss: 0.30241549015045166
Validation loss: 2.1061137119928994

Epoch: 6| Step: 13
Training loss: 0.8026903867721558
Validation loss: 2.1563482681910195

Epoch: 165| Step: 0
Training loss: 0.9750702381134033
Validation loss: 2.1561525066693625

Epoch: 6| Step: 1
Training loss: 0.6346917152404785
Validation loss: 2.0675561229387918

Epoch: 6| Step: 2
Training loss: 0.7698765397071838
Validation loss: 2.1682578722635903

Epoch: 6| Step: 3
Training loss: 0.7868396043777466
Validation loss: 2.103494723637899

Epoch: 6| Step: 4
Training loss: 0.8076250553131104
Validation loss: 2.1254547834396362

Epoch: 6| Step: 5
Training loss: 1.0061447620391846
Validation loss: 2.1651271184285483

Epoch: 6| Step: 6
Training loss: 0.7613073587417603
Validation loss: 2.1996564269065857

Epoch: 6| Step: 7
Training loss: 1.032129168510437
Validation loss: 2.2175238529841104

Epoch: 6| Step: 8
Training loss: 0.960135817527771
Validation loss: 2.20202374458313

Epoch: 6| Step: 9
Training loss: 0.5624257922172546
Validation loss: 2.1615339120229087

Epoch: 6| Step: 10
Training loss: 0.6138385534286499
Validation loss: 2.148748815059662

Epoch: 6| Step: 11
Training loss: 0.8757433891296387
Validation loss: 2.1475905974706015

Epoch: 6| Step: 12
Training loss: 0.6199933290481567
Validation loss: 2.033174971739451

Epoch: 6| Step: 13
Training loss: 1.1315422058105469
Validation loss: 2.0816312233606973

Epoch: 166| Step: 0
Training loss: 0.5275323390960693
Validation loss: 2.089240392049154

Epoch: 6| Step: 1
Training loss: 0.8904978036880493
Validation loss: 2.163532078266144

Epoch: 6| Step: 2
Training loss: 1.1433218717575073
Validation loss: 2.1853994528452554

Epoch: 6| Step: 3
Training loss: 0.7186242341995239
Validation loss: 2.176237920920054

Epoch: 6| Step: 4
Training loss: 0.7346299886703491
Validation loss: 2.2138694127400718

Epoch: 6| Step: 5
Training loss: 0.49276575446128845
Validation loss: 2.1466601292292276

Epoch: 6| Step: 6
Training loss: 1.1696696281433105
Validation loss: 2.103510777155558

Epoch: 6| Step: 7
Training loss: 0.6576293706893921
Validation loss: 2.0933448672294617

Epoch: 6| Step: 8
Training loss: 0.7132819890975952
Validation loss: 2.1112662156422934

Epoch: 6| Step: 9
Training loss: 0.5233790874481201
Validation loss: 2.195113956928253

Epoch: 6| Step: 10
Training loss: 0.688231348991394
Validation loss: 2.153900980949402

Epoch: 6| Step: 11
Training loss: 1.229961633682251
Validation loss: 2.1780261596043906

Epoch: 6| Step: 12
Training loss: 0.7338906526565552
Validation loss: 2.1732204953829446

Epoch: 6| Step: 13
Training loss: 0.8280292749404907
Validation loss: 2.1044228076934814

Epoch: 167| Step: 0
Training loss: 0.949914813041687
Validation loss: 2.145740548769633

Epoch: 6| Step: 1
Training loss: 0.8067212104797363
Validation loss: 2.1755340695381165

Epoch: 6| Step: 2
Training loss: 0.85496985912323
Validation loss: 2.1043399572372437

Epoch: 6| Step: 3
Training loss: 0.7551277875900269
Validation loss: 2.1346741120020547

Epoch: 6| Step: 4
Training loss: 0.7645167112350464
Validation loss: 2.124582827091217

Epoch: 6| Step: 5
Training loss: 0.9381099343299866
Validation loss: 2.1604462464650473

Epoch: 6| Step: 6
Training loss: 0.758178174495697
Validation loss: 2.1640352408091226

Epoch: 6| Step: 7
Training loss: 0.8993220925331116
Validation loss: 2.1330767273902893

Epoch: 6| Step: 8
Training loss: 0.6802835464477539
Validation loss: 2.1175795793533325

Epoch: 6| Step: 9
Training loss: 0.49782878160476685
Validation loss: 2.129743297894796

Epoch: 6| Step: 10
Training loss: 0.829433798789978
Validation loss: 2.159006198247274

Epoch: 6| Step: 11
Training loss: 1.0716050863265991
Validation loss: 2.1244574983914695

Epoch: 6| Step: 12
Training loss: 0.6894099712371826
Validation loss: 2.1917824943860373

Epoch: 6| Step: 13
Training loss: 0.6427932977676392
Validation loss: 2.1660077571868896

Epoch: 168| Step: 0
Training loss: 0.5601650476455688
Validation loss: 2.237955073515574

Epoch: 6| Step: 1
Training loss: 1.2144007682800293
Validation loss: 2.1925503810246787

Epoch: 6| Step: 2
Training loss: 0.6227165460586548
Validation loss: 2.2187341252962747

Epoch: 6| Step: 3
Training loss: 1.364264965057373
Validation loss: 2.1201464931170144

Epoch: 6| Step: 4
Training loss: 0.5065636038780212
Validation loss: 2.1141364177068076

Epoch: 6| Step: 5
Training loss: 1.0063458681106567
Validation loss: 2.111837327480316

Epoch: 6| Step: 6
Training loss: 0.7487756013870239
Validation loss: 2.177902082602183

Epoch: 6| Step: 7
Training loss: 0.7038167715072632
Validation loss: 2.14468385775884

Epoch: 6| Step: 8
Training loss: 0.7635757327079773
Validation loss: 2.1187891165415444

Epoch: 6| Step: 9
Training loss: 0.2979714274406433
Validation loss: 2.127714991569519

Epoch: 6| Step: 10
Training loss: 0.922784686088562
Validation loss: 2.121730407079061

Epoch: 6| Step: 11
Training loss: 0.6362871527671814
Validation loss: 2.175649046897888

Epoch: 6| Step: 12
Training loss: 0.600473165512085
Validation loss: 2.13705708583196

Epoch: 6| Step: 13
Training loss: 0.7673799395561218
Validation loss: 2.1550148924191794

Epoch: 169| Step: 0
Training loss: 0.35655421018600464
Validation loss: 2.184820532798767

Epoch: 6| Step: 1
Training loss: 0.7925413250923157
Validation loss: 2.1678417722384133

Epoch: 6| Step: 2
Training loss: 0.8400672674179077
Validation loss: 2.1844249169031777

Epoch: 6| Step: 3
Training loss: 0.810646653175354
Validation loss: 2.1901854077974954

Epoch: 6| Step: 4
Training loss: 0.6527443528175354
Validation loss: 2.1839242974917092

Epoch: 6| Step: 5
Training loss: 0.784866452217102
Validation loss: 2.1209142208099365

Epoch: 6| Step: 6
Training loss: 0.5370714664459229
Validation loss: 2.154381434122721

Epoch: 6| Step: 7
Training loss: 0.7923568487167358
Validation loss: 2.111851374308268

Epoch: 6| Step: 8
Training loss: 1.538175106048584
Validation loss: 2.2096839348475137

Epoch: 6| Step: 9
Training loss: 0.6733480095863342
Validation loss: 2.1842865546544394

Epoch: 6| Step: 10
Training loss: 1.4170392751693726
Validation loss: 2.3197639187177024

Epoch: 6| Step: 11
Training loss: 0.6999805569648743
Validation loss: 2.1525014837582908

Epoch: 6| Step: 12
Training loss: 0.9761772751808167
Validation loss: 2.249362270037333

Epoch: 6| Step: 13
Training loss: 0.6176934242248535
Validation loss: 2.2285306652386985

Epoch: 170| Step: 0
Training loss: 0.972115695476532
Validation loss: 2.14896426598231

Epoch: 6| Step: 1
Training loss: 0.4254552125930786
Validation loss: 2.108252147833506

Epoch: 6| Step: 2
Training loss: 0.9551472067832947
Validation loss: 2.1371920903523765

Epoch: 6| Step: 3
Training loss: 0.9409921765327454
Validation loss: 2.2059120734532676

Epoch: 6| Step: 4
Training loss: 0.5651940107345581
Validation loss: 2.152559141318003

Epoch: 6| Step: 5
Training loss: 0.7381864190101624
Validation loss: 2.1704768737157187

Epoch: 6| Step: 6
Training loss: 0.7978636622428894
Validation loss: 2.1921998858451843

Epoch: 6| Step: 7
Training loss: 0.5783295631408691
Validation loss: 2.2374552289644876

Epoch: 6| Step: 8
Training loss: 0.6871761679649353
Validation loss: 2.163530429204305

Epoch: 6| Step: 9
Training loss: 0.5395216941833496
Validation loss: 2.1946770548820496

Epoch: 6| Step: 10
Training loss: 0.4501240849494934
Validation loss: 2.2268303831418357

Epoch: 6| Step: 11
Training loss: 0.7130764722824097
Validation loss: 2.142005185286204

Epoch: 6| Step: 12
Training loss: 0.7398484945297241
Validation loss: 2.1643545031547546

Epoch: 6| Step: 13
Training loss: 1.0376932621002197
Validation loss: 2.1341498692830405

Epoch: 171| Step: 0
Training loss: 0.8541369438171387
Validation loss: 2.157456696033478

Epoch: 6| Step: 1
Training loss: 0.6586809158325195
Validation loss: 2.1290640234947205

Epoch: 6| Step: 2
Training loss: 0.47203782200813293
Validation loss: 2.189552446206411

Epoch: 6| Step: 3
Training loss: 0.9661396145820618
Validation loss: 2.160086154937744

Epoch: 6| Step: 4
Training loss: 0.8311051726341248
Validation loss: 2.2017060120900473

Epoch: 6| Step: 5
Training loss: 1.2699172496795654
Validation loss: 2.18674107392629

Epoch: 6| Step: 6
Training loss: 0.7157176733016968
Validation loss: 2.1410882671674094

Epoch: 6| Step: 7
Training loss: 0.7108433842658997
Validation loss: 2.184728721777598

Epoch: 6| Step: 8
Training loss: 0.46794092655181885
Validation loss: 2.177562415599823

Epoch: 6| Step: 9
Training loss: 0.8467204570770264
Validation loss: 2.195271611213684

Epoch: 6| Step: 10
Training loss: 0.5885331630706787
Validation loss: 2.1853345036506653

Epoch: 6| Step: 11
Training loss: 1.1383132934570312
Validation loss: 2.156359295050303

Epoch: 6| Step: 12
Training loss: 0.5595846176147461
Validation loss: 2.192568302154541

Epoch: 6| Step: 13
Training loss: 1.0937232971191406
Validation loss: 2.1993746956189475

Epoch: 172| Step: 0
Training loss: 0.6612882614135742
Validation loss: 2.229005753993988

Epoch: 6| Step: 1
Training loss: 0.2986447811126709
Validation loss: 2.1615867217381797

Epoch: 6| Step: 2
Training loss: 0.625956118106842
Validation loss: 2.1597191095352173

Epoch: 6| Step: 3
Training loss: 0.7821378111839294
Validation loss: 2.1549187501271567

Epoch: 6| Step: 4
Training loss: 1.240429162979126
Validation loss: 2.2250575621922812

Epoch: 6| Step: 5
Training loss: 1.1024856567382812
Validation loss: 2.1911136309305825

Epoch: 6| Step: 6
Training loss: 1.4663081169128418
Validation loss: 2.232664624849955

Epoch: 6| Step: 7
Training loss: 0.7189086079597473
Validation loss: 2.19525941212972

Epoch: 6| Step: 8
Training loss: 1.106852412223816
Validation loss: 2.240716060002645

Epoch: 6| Step: 9
Training loss: 0.5979952812194824
Validation loss: 2.202872097492218

Epoch: 6| Step: 10
Training loss: 0.6444360017776489
Validation loss: 2.2268384099006653

Epoch: 6| Step: 11
Training loss: 0.7063024044036865
Validation loss: 2.1981974045435586

Epoch: 6| Step: 12
Training loss: 0.7876825332641602
Validation loss: 2.1574844121932983

Epoch: 6| Step: 13
Training loss: 1.1400684118270874
Validation loss: 2.1444305578867593

Epoch: 173| Step: 0
Training loss: 0.8519595265388489
Validation loss: 2.168414215246836

Epoch: 6| Step: 1
Training loss: 0.9206070303916931
Validation loss: 2.1839563449223838

Epoch: 6| Step: 2
Training loss: 0.8718096613883972
Validation loss: 2.18732351064682

Epoch: 6| Step: 3
Training loss: 1.2571778297424316
Validation loss: 2.123543461163839

Epoch: 6| Step: 4
Training loss: 0.8433982133865356
Validation loss: 2.137578070163727

Epoch: 6| Step: 5
Training loss: 0.7296197414398193
Validation loss: 2.1698495546976724

Epoch: 6| Step: 6
Training loss: 0.7539354562759399
Validation loss: 2.2360706130663552

Epoch: 6| Step: 7
Training loss: 0.6513614654541016
Validation loss: 2.2870461146036782

Epoch: 6| Step: 8
Training loss: 0.5057372450828552
Validation loss: 2.298117240269979

Epoch: 6| Step: 9
Training loss: 0.7767277359962463
Validation loss: 2.2681994636853537

Epoch: 6| Step: 10
Training loss: 0.7548477649688721
Validation loss: 2.293370246887207

Epoch: 6| Step: 11
Training loss: 0.7409229278564453
Validation loss: 2.225210110346476

Epoch: 6| Step: 12
Training loss: 1.097975492477417
Validation loss: 2.164157430330912

Epoch: 6| Step: 13
Training loss: 0.4885055422782898
Validation loss: 2.136660118897756

Epoch: 174| Step: 0
Training loss: 1.2643325328826904
Validation loss: 2.106804052988688

Epoch: 6| Step: 1
Training loss: 0.9266607761383057
Validation loss: 2.1590681870778403

Epoch: 6| Step: 2
Training loss: 0.8724715709686279
Validation loss: 2.1304599245389304

Epoch: 6| Step: 3
Training loss: 0.8867387771606445
Validation loss: 2.1668075919151306

Epoch: 6| Step: 4
Training loss: 0.8437487483024597
Validation loss: 2.218283951282501

Epoch: 6| Step: 5
Training loss: 1.3807705640792847
Validation loss: 2.2693597277005515

Epoch: 6| Step: 6
Training loss: 0.6767326593399048
Validation loss: 2.2942400376001992

Epoch: 6| Step: 7
Training loss: 0.6572465896606445
Validation loss: 2.234540045261383

Epoch: 6| Step: 8
Training loss: 0.6888391375541687
Validation loss: 2.197170615196228

Epoch: 6| Step: 9
Training loss: 0.5537933111190796
Validation loss: 2.143033981323242

Epoch: 6| Step: 10
Training loss: 1.0712605714797974
Validation loss: 2.200643539428711

Epoch: 6| Step: 11
Training loss: 0.8995365500450134
Validation loss: 2.193807284037272

Epoch: 6| Step: 12
Training loss: 0.7828106880187988
Validation loss: 2.1155611673990884

Epoch: 6| Step: 13
Training loss: 0.8119373321533203
Validation loss: 2.1613653103510537

Epoch: 175| Step: 0
Training loss: 1.103271245956421
Validation loss: 2.1867346366246543

Epoch: 6| Step: 1
Training loss: 0.39419305324554443
Validation loss: 2.177445888519287

Epoch: 6| Step: 2
Training loss: 0.7571964263916016
Validation loss: 2.2078147331873574

Epoch: 6| Step: 3
Training loss: 0.6122140884399414
Validation loss: 2.194025139013926

Epoch: 6| Step: 4
Training loss: 1.2254407405853271
Validation loss: 2.138615349928538

Epoch: 6| Step: 5
Training loss: 0.5206300616264343
Validation loss: 2.114985624949137

Epoch: 6| Step: 6
Training loss: 0.858849048614502
Validation loss: 2.125055988629659

Epoch: 6| Step: 7
Training loss: 0.5412373542785645
Validation loss: 2.1809938549995422

Epoch: 6| Step: 8
Training loss: 0.3077298402786255
Validation loss: 2.1561007698376975

Epoch: 6| Step: 9
Training loss: 0.5718671083450317
Validation loss: 2.0983688632647195

Epoch: 6| Step: 10
Training loss: 0.943615198135376
Validation loss: 2.1460782885551453

Epoch: 6| Step: 11
Training loss: 0.5238763093948364
Validation loss: 2.1353790362675986

Epoch: 6| Step: 12
Training loss: 0.8079779744148254
Validation loss: 2.1497581601142883

Epoch: 6| Step: 13
Training loss: 0.5744900703430176
Validation loss: 2.1549238363901773

Epoch: 176| Step: 0
Training loss: 0.5801551938056946
Validation loss: 2.1324968934059143

Epoch: 6| Step: 1
Training loss: 0.5641553401947021
Validation loss: 2.1298421025276184

Epoch: 6| Step: 2
Training loss: 0.4310377538204193
Validation loss: 2.153203328450521

Epoch: 6| Step: 3
Training loss: 0.6967558860778809
Validation loss: 2.162836730480194

Epoch: 6| Step: 4
Training loss: 0.5795722007751465
Validation loss: 2.1478211085001626

Epoch: 6| Step: 5
Training loss: 0.7534661293029785
Validation loss: 2.163584272066752

Epoch: 6| Step: 6
Training loss: 0.40987175703048706
Validation loss: 2.1712573568026223

Epoch: 6| Step: 7
Training loss: 0.922113299369812
Validation loss: 2.2097905476888022

Epoch: 6| Step: 8
Training loss: 1.0121017694473267
Validation loss: 2.193193515141805

Epoch: 6| Step: 9
Training loss: 1.0658128261566162
Validation loss: 2.2367358406384787

Epoch: 6| Step: 10
Training loss: 1.044525384902954
Validation loss: 2.2222894628842673

Epoch: 6| Step: 11
Training loss: 0.48268261551856995
Validation loss: 2.2253981232643127

Epoch: 6| Step: 12
Training loss: 0.6875320672988892
Validation loss: 2.1647539536158242

Epoch: 6| Step: 13
Training loss: 0.9793372750282288
Validation loss: 2.139529903729757

Epoch: 177| Step: 0
Training loss: 0.945091962814331
Validation loss: 2.190897305806478

Epoch: 6| Step: 1
Training loss: 0.6982253193855286
Validation loss: 2.149005631605784

Epoch: 6| Step: 2
Training loss: 0.5480865836143494
Validation loss: 2.122444291909536

Epoch: 6| Step: 3
Training loss: 0.5989757776260376
Validation loss: 2.1577420830726624

Epoch: 6| Step: 4
Training loss: 0.5156146883964539
Validation loss: 2.1118624210357666

Epoch: 6| Step: 5
Training loss: 0.6643611192703247
Validation loss: 2.1605741580327353

Epoch: 6| Step: 6
Training loss: 0.3022385239601135
Validation loss: 2.160060445467631

Epoch: 6| Step: 7
Training loss: 0.8548426628112793
Validation loss: 2.133115569750468

Epoch: 6| Step: 8
Training loss: 1.087263822555542
Validation loss: 2.189603249231974

Epoch: 6| Step: 9
Training loss: 0.6668961048126221
Validation loss: 2.1938188076019287

Epoch: 6| Step: 10
Training loss: 0.8212721943855286
Validation loss: 2.193400780359904

Epoch: 6| Step: 11
Training loss: 0.674325704574585
Validation loss: 2.1558452447255454

Epoch: 6| Step: 12
Training loss: 0.9183233976364136
Validation loss: 2.1590367952982583

Epoch: 6| Step: 13
Training loss: 0.7647183537483215
Validation loss: 2.169367710749308

Epoch: 178| Step: 0
Training loss: 0.5193746089935303
Validation loss: 2.1475313703219094

Epoch: 6| Step: 1
Training loss: 0.5091704726219177
Validation loss: 2.1331782937049866

Epoch: 6| Step: 2
Training loss: 0.9315160512924194
Validation loss: 2.1689678033192954

Epoch: 6| Step: 3
Training loss: 0.7632291913032532
Validation loss: 2.159227987130483

Epoch: 6| Step: 4
Training loss: 0.405714213848114
Validation loss: 2.1713279088338218

Epoch: 6| Step: 5
Training loss: 0.6149845123291016
Validation loss: 2.128742436567942

Epoch: 6| Step: 6
Training loss: 1.3224610090255737
Validation loss: 2.2378437916437783

Epoch: 6| Step: 7
Training loss: 0.6941455602645874
Validation loss: 2.2170897126197815

Epoch: 6| Step: 8
Training loss: 0.8995702862739563
Validation loss: 2.2532641291618347

Epoch: 6| Step: 9
Training loss: 0.6167891025543213
Validation loss: 2.1192302306493125

Epoch: 6| Step: 10
Training loss: 0.5821459293365479
Validation loss: 2.196222265561422

Epoch: 6| Step: 11
Training loss: 0.8030048608779907
Validation loss: 2.157509525616964

Epoch: 6| Step: 12
Training loss: 0.9575040340423584
Validation loss: 2.1733184258143106

Epoch: 6| Step: 13
Training loss: 1.0032365322113037
Validation loss: 2.1032143235206604

Epoch: 179| Step: 0
Training loss: 0.7009493112564087
Validation loss: 2.1642600695292153

Epoch: 6| Step: 1
Training loss: 0.8559728860855103
Validation loss: 2.188137630621592

Epoch: 6| Step: 2
Training loss: 0.5279566645622253
Validation loss: 2.1303919752438865

Epoch: 6| Step: 3
Training loss: 0.8962368965148926
Validation loss: 2.243031164010366

Epoch: 6| Step: 4
Training loss: 1.0952732563018799
Validation loss: 2.2049516836802163

Epoch: 6| Step: 5
Training loss: 0.599353015422821
Validation loss: 2.14521187543869

Epoch: 6| Step: 6
Training loss: 0.5639615058898926
Validation loss: 2.1014306346575418

Epoch: 6| Step: 7
Training loss: 0.6687413454055786
Validation loss: 2.123177687327067

Epoch: 6| Step: 8
Training loss: 0.5367312431335449
Validation loss: 2.160981913407644

Epoch: 6| Step: 9
Training loss: 0.8665474653244019
Validation loss: 2.121711790561676

Epoch: 6| Step: 10
Training loss: 0.41017189621925354
Validation loss: 2.127053717772166

Epoch: 6| Step: 11
Training loss: 0.6079022288322449
Validation loss: 2.1928011576334634

Epoch: 6| Step: 12
Training loss: 0.6431851983070374
Validation loss: 2.1313717563947043

Epoch: 6| Step: 13
Training loss: 0.9499562382698059
Validation loss: 2.0874699354171753

Epoch: 180| Step: 0
Training loss: 0.7087548971176147
Validation loss: 2.102557679017385

Epoch: 6| Step: 1
Training loss: 0.7909287810325623
Validation loss: 2.1724491914113364

Epoch: 6| Step: 2
Training loss: 0.6840736865997314
Validation loss: 2.1622355580329895

Epoch: 6| Step: 3
Training loss: 0.5767896771430969
Validation loss: 2.1951481699943542

Epoch: 6| Step: 4
Training loss: 0.6045653820037842
Validation loss: 2.22042985757192

Epoch: 6| Step: 5
Training loss: 0.7527061700820923
Validation loss: 2.141693909962972

Epoch: 6| Step: 6
Training loss: 0.42988121509552
Validation loss: 2.116930683453878

Epoch: 6| Step: 7
Training loss: 0.7645844221115112
Validation loss: 2.1736252307891846

Epoch: 6| Step: 8
Training loss: 0.6708782911300659
Validation loss: 2.119452436765035

Epoch: 6| Step: 9
Training loss: 0.5994828939437866
Validation loss: 2.1628464460372925

Epoch: 6| Step: 10
Training loss: 0.8458170890808105
Validation loss: 2.1886195143063865

Epoch: 6| Step: 11
Training loss: 1.0707707405090332
Validation loss: 2.207322974999746

Epoch: 6| Step: 12
Training loss: 0.52986079454422
Validation loss: 2.2423861622810364

Epoch: 6| Step: 13
Training loss: 0.8719688653945923
Validation loss: 2.204806864261627

Epoch: 181| Step: 0
Training loss: 0.7851338982582092
Validation loss: 2.1680206060409546

Epoch: 6| Step: 1
Training loss: 0.8155278563499451
Validation loss: 2.1601829528808594

Epoch: 6| Step: 2
Training loss: 0.8023414015769958
Validation loss: 2.161263585090637

Epoch: 6| Step: 3
Training loss: 0.5436717867851257
Validation loss: 2.169297516345978

Epoch: 6| Step: 4
Training loss: 0.5270063877105713
Validation loss: 2.1522627075513205

Epoch: 6| Step: 5
Training loss: 0.521984338760376
Validation loss: 2.1462355852127075

Epoch: 6| Step: 6
Training loss: 0.728305995464325
Validation loss: 2.1888816754023233

Epoch: 6| Step: 7
Training loss: 1.0424001216888428
Validation loss: 2.184888243675232

Epoch: 6| Step: 8
Training loss: 0.9536412358283997
Validation loss: 2.180699368317922

Epoch: 6| Step: 9
Training loss: 0.5826247930526733
Validation loss: 2.210210939248403

Epoch: 6| Step: 10
Training loss: 0.5005249977111816
Validation loss: 2.1645391384760537

Epoch: 6| Step: 11
Training loss: 0.7122554183006287
Validation loss: 2.1988956332206726

Epoch: 6| Step: 12
Training loss: 0.652614414691925
Validation loss: 2.1023006240526834

Epoch: 6| Step: 13
Training loss: 0.6389816999435425
Validation loss: 2.120328406492869

Epoch: 182| Step: 0
Training loss: 0.8898093700408936
Validation loss: 2.1029325127601624

Epoch: 6| Step: 1
Training loss: 0.6088608503341675
Validation loss: 2.091140389442444

Epoch: 6| Step: 2
Training loss: 0.968117356300354
Validation loss: 2.1672154664993286

Epoch: 6| Step: 3
Training loss: 0.9361348152160645
Validation loss: 2.145350754261017

Epoch: 6| Step: 4
Training loss: 1.2533724308013916
Validation loss: 2.215015629927317

Epoch: 6| Step: 5
Training loss: 0.6167334318161011
Validation loss: 2.285036861896515

Epoch: 6| Step: 6
Training loss: 0.7377249002456665
Validation loss: 2.1485902468363443

Epoch: 6| Step: 7
Training loss: 0.4707200229167938
Validation loss: 2.117120623588562

Epoch: 6| Step: 8
Training loss: 0.31013810634613037
Validation loss: 2.176341156164805

Epoch: 6| Step: 9
Training loss: 0.6123352646827698
Validation loss: 2.13200843334198

Epoch: 6| Step: 10
Training loss: 1.148284912109375
Validation loss: 2.1383410890897117

Epoch: 6| Step: 11
Training loss: 0.7739928960800171
Validation loss: 2.0837838649749756

Epoch: 6| Step: 12
Training loss: 0.7166990041732788
Validation loss: 2.189320464928945

Epoch: 6| Step: 13
Training loss: 1.0339359045028687
Validation loss: 2.145738740762075

Epoch: 183| Step: 0
Training loss: 0.5055477619171143
Validation loss: 2.134644389152527

Epoch: 6| Step: 1
Training loss: 0.6063145399093628
Validation loss: 2.1931792497634888

Epoch: 6| Step: 2
Training loss: 1.0568151473999023
Validation loss: 2.209866146246592

Epoch: 6| Step: 3
Training loss: 0.8835137486457825
Validation loss: 2.1859304904937744

Epoch: 6| Step: 4
Training loss: 0.5743752717971802
Validation loss: 2.1392216881116233

Epoch: 6| Step: 5
Training loss: 0.6005311012268066
Validation loss: 2.137480000654856

Epoch: 6| Step: 6
Training loss: 0.5435808897018433
Validation loss: 2.1386638879776

Epoch: 6| Step: 7
Training loss: 1.013864517211914
Validation loss: 2.138638973236084

Epoch: 6| Step: 8
Training loss: 0.43375784158706665
Validation loss: 2.1772230664889016

Epoch: 6| Step: 9
Training loss: 0.6547237634658813
Validation loss: 2.1883842746416726

Epoch: 6| Step: 10
Training loss: 0.7073601484298706
Validation loss: 2.1645158926645913

Epoch: 6| Step: 11
Training loss: 0.706716775894165
Validation loss: 2.1505935390790305

Epoch: 6| Step: 12
Training loss: 0.431660532951355
Validation loss: 2.1549302339553833

Epoch: 6| Step: 13
Training loss: 0.9764461517333984
Validation loss: 2.207674245039622

Epoch: 184| Step: 0
Training loss: 0.9000251293182373
Validation loss: 2.1682039697964988

Epoch: 6| Step: 1
Training loss: 0.8418488502502441
Validation loss: 2.2301332354545593

Epoch: 6| Step: 2
Training loss: 0.6861391067504883
Validation loss: 2.0950384537378945

Epoch: 6| Step: 3
Training loss: 0.897919774055481
Validation loss: 2.1322495142618814

Epoch: 6| Step: 4
Training loss: 0.8114804625511169
Validation loss: 2.0957947373390198

Epoch: 6| Step: 5
Training loss: 0.46002820134162903
Validation loss: 2.148590922355652

Epoch: 6| Step: 6
Training loss: 0.4732205271720886
Validation loss: 2.099956750869751

Epoch: 6| Step: 7
Training loss: 0.7355229258537292
Validation loss: 2.191473106543223

Epoch: 6| Step: 8
Training loss: 0.44135749340057373
Validation loss: 2.087930421034495

Epoch: 6| Step: 9
Training loss: 0.6137927174568176
Validation loss: 2.1572419007619223

Epoch: 6| Step: 10
Training loss: 0.7891629338264465
Validation loss: 2.1036563913027444

Epoch: 6| Step: 11
Training loss: 0.4214158058166504
Validation loss: 2.1893646319707236

Epoch: 6| Step: 12
Training loss: 0.4484744071960449
Validation loss: 2.1539915204048157

Epoch: 6| Step: 13
Training loss: 0.7140107750892639
Validation loss: 2.0503127773602805

Epoch: 185| Step: 0
Training loss: 0.480398952960968
Validation loss: 2.126876095930735

Epoch: 6| Step: 1
Training loss: 0.7761386036872864
Validation loss: 2.127655307451884

Epoch: 6| Step: 2
Training loss: 0.35735347867012024
Validation loss: 2.131690204143524

Epoch: 6| Step: 3
Training loss: 0.38427573442459106
Validation loss: 2.0892385641733804

Epoch: 6| Step: 4
Training loss: 1.106616497039795
Validation loss: 2.169415016969045

Epoch: 6| Step: 5
Training loss: 0.6342780590057373
Validation loss: 2.1664041678110757

Epoch: 6| Step: 6
Training loss: 0.6028977632522583
Validation loss: 2.0917287866274514

Epoch: 6| Step: 7
Training loss: 0.8959393501281738
Validation loss: 2.2106568415959678

Epoch: 6| Step: 8
Training loss: 1.161497950553894
Validation loss: 2.1812437375386557

Epoch: 6| Step: 9
Training loss: 0.6153712272644043
Validation loss: 2.101519743601481

Epoch: 6| Step: 10
Training loss: 0.3497202396392822
Validation loss: 2.1316038767496743

Epoch: 6| Step: 11
Training loss: 0.5099015235900879
Validation loss: 2.1614941159884133

Epoch: 6| Step: 12
Training loss: 0.493840754032135
Validation loss: 2.149298926194509

Epoch: 6| Step: 13
Training loss: 1.0210082530975342
Validation loss: 2.1635543505350747

Epoch: 186| Step: 0
Training loss: 0.5395214557647705
Validation loss: 2.2114571730295816

Epoch: 6| Step: 1
Training loss: 0.838880181312561
Validation loss: 2.1711870233217874

Epoch: 6| Step: 2
Training loss: 0.4302101731300354
Validation loss: 2.1323859691619873

Epoch: 6| Step: 3
Training loss: 0.4814809560775757
Validation loss: 2.10578590631485

Epoch: 6| Step: 4
Training loss: 0.9800052046775818
Validation loss: 2.127532720565796

Epoch: 6| Step: 5
Training loss: 0.9125832319259644
Validation loss: 2.1478957533836365

Epoch: 6| Step: 6
Training loss: 0.5943934917449951
Validation loss: 2.1117311318715415

Epoch: 6| Step: 7
Training loss: 0.4437328577041626
Validation loss: 2.158254404862722

Epoch: 6| Step: 8
Training loss: 0.7446664571762085
Validation loss: 2.1793708006540933

Epoch: 6| Step: 9
Training loss: 0.6991315484046936
Validation loss: 2.170907457669576

Epoch: 6| Step: 10
Training loss: 0.5625998973846436
Validation loss: 2.178072512149811

Epoch: 6| Step: 11
Training loss: 0.9829472303390503
Validation loss: 2.1489908695220947

Epoch: 6| Step: 12
Training loss: 0.8046166896820068
Validation loss: 2.2134987910588584

Epoch: 6| Step: 13
Training loss: 0.7409054636955261
Validation loss: 2.1318676273028054

Epoch: 187| Step: 0
Training loss: 0.9653515815734863
Validation loss: 2.124898115793864

Epoch: 6| Step: 1
Training loss: 0.45491909980773926
Validation loss: 2.1205708980560303

Epoch: 6| Step: 2
Training loss: 0.8487876653671265
Validation loss: 2.0870202779769897

Epoch: 6| Step: 3
Training loss: 0.8935223817825317
Validation loss: 2.1405802170435586

Epoch: 6| Step: 4
Training loss: 0.9198706150054932
Validation loss: 2.1458477775255838

Epoch: 6| Step: 5
Training loss: 0.7032603621482849
Validation loss: 2.274239242076874

Epoch: 6| Step: 6
Training loss: 0.8095877170562744
Validation loss: 2.1396022836367288

Epoch: 6| Step: 7
Training loss: 0.5862323641777039
Validation loss: 2.210346758365631

Epoch: 6| Step: 8
Training loss: 0.462911993265152
Validation loss: 2.1829919815063477

Epoch: 6| Step: 9
Training loss: 0.7574331760406494
Validation loss: 2.167574644088745

Epoch: 6| Step: 10
Training loss: 0.5514593124389648
Validation loss: 2.1718839009602866

Epoch: 6| Step: 11
Training loss: 0.5082405805587769
Validation loss: 2.1695321003595986

Epoch: 6| Step: 12
Training loss: 0.6050004959106445
Validation loss: 2.1417938272158303

Epoch: 6| Step: 13
Training loss: 0.7204782366752625
Validation loss: 2.1787789861361184

Epoch: 188| Step: 0
Training loss: 0.7369389533996582
Validation loss: 2.232657472292582

Epoch: 6| Step: 1
Training loss: 0.8636369705200195
Validation loss: 2.176542282104492

Epoch: 6| Step: 2
Training loss: 0.5734253525733948
Validation loss: 2.144386430581411

Epoch: 6| Step: 3
Training loss: 0.5160940885543823
Validation loss: 2.130037864049276

Epoch: 6| Step: 4
Training loss: 0.6262065172195435
Validation loss: 2.1424981554349265

Epoch: 6| Step: 5
Training loss: 0.9730268120765686
Validation loss: 2.1394537687301636

Epoch: 6| Step: 6
Training loss: 0.5843040943145752
Validation loss: 2.183571000893911

Epoch: 6| Step: 7
Training loss: 0.7888268232345581
Validation loss: 2.169918417930603

Epoch: 6| Step: 8
Training loss: 0.7518230676651001
Validation loss: 2.1529792745908103

Epoch: 6| Step: 9
Training loss: 0.6718360185623169
Validation loss: 2.2056323687235513

Epoch: 6| Step: 10
Training loss: 1.143627405166626
Validation loss: 2.139796574910482

Epoch: 6| Step: 11
Training loss: 0.5280139446258545
Validation loss: 2.1338611443837485

Epoch: 6| Step: 12
Training loss: 0.4640786647796631
Validation loss: 2.146735966205597

Epoch: 6| Step: 13
Training loss: 0.7710770964622498
Validation loss: 2.0895286003748574

Epoch: 189| Step: 0
Training loss: 0.9229575395584106
Validation loss: 2.156853516896566

Epoch: 6| Step: 1
Training loss: 0.787969708442688
Validation loss: 2.120621641476949

Epoch: 6| Step: 2
Training loss: 0.3457360863685608
Validation loss: 2.1370295683542886

Epoch: 6| Step: 3
Training loss: 0.8241528272628784
Validation loss: 2.1357837120691934

Epoch: 6| Step: 4
Training loss: 0.963311493396759
Validation loss: 2.2005458076794944

Epoch: 6| Step: 5
Training loss: 0.5281072854995728
Validation loss: 2.192697823047638

Epoch: 6| Step: 6
Training loss: 0.5105389356613159
Validation loss: 2.2087618112564087

Epoch: 6| Step: 7
Training loss: 0.5132931470870972
Validation loss: 2.1968525052070618

Epoch: 6| Step: 8
Training loss: 1.1124048233032227
Validation loss: 2.174651543299357

Epoch: 6| Step: 9
Training loss: 0.6648045182228088
Validation loss: 2.1767620046933494

Epoch: 6| Step: 10
Training loss: 0.7146596908569336
Validation loss: 2.1679354111353555

Epoch: 6| Step: 11
Training loss: 0.49445825815200806
Validation loss: 2.155981699625651

Epoch: 6| Step: 12
Training loss: 0.5668783187866211
Validation loss: 2.1814677516619363

Epoch: 6| Step: 13
Training loss: 0.6305350661277771
Validation loss: 2.142799139022827

Epoch: 190| Step: 0
Training loss: 1.104349970817566
Validation loss: 2.1769422690073648

Epoch: 6| Step: 1
Training loss: 1.153497338294983
Validation loss: 2.177705625693003

Epoch: 6| Step: 2
Training loss: 0.7299341559410095
Validation loss: 2.191510260105133

Epoch: 6| Step: 3
Training loss: 0.3692433834075928
Validation loss: 2.184427003065745

Epoch: 6| Step: 4
Training loss: 0.43409091234207153
Validation loss: 2.1573221484820047

Epoch: 6| Step: 5
Training loss: 0.47727805376052856
Validation loss: 2.125752329826355

Epoch: 6| Step: 6
Training loss: 0.5200839042663574
Validation loss: 2.1924438079198203

Epoch: 6| Step: 7
Training loss: 0.7086150646209717
Validation loss: 2.221633950869242

Epoch: 6| Step: 8
Training loss: 0.24540561437606812
Validation loss: 2.1473077138264975

Epoch: 6| Step: 9
Training loss: 0.5771204233169556
Validation loss: 2.1932507356007895

Epoch: 6| Step: 10
Training loss: 0.8486168384552002
Validation loss: 2.2183043360710144

Epoch: 6| Step: 11
Training loss: 0.5074654817581177
Validation loss: 2.2196434338887534

Epoch: 6| Step: 12
Training loss: 0.8667759895324707
Validation loss: 2.185225327809652

Epoch: 6| Step: 13
Training loss: 0.7117345929145813
Validation loss: 2.175250311692556

Epoch: 191| Step: 0
Training loss: 0.8970214128494263
Validation loss: 2.1828399896621704

Epoch: 6| Step: 1
Training loss: 0.8159761428833008
Validation loss: 2.208404282728831

Epoch: 6| Step: 2
Training loss: 0.515805721282959
Validation loss: 2.13590939839681

Epoch: 6| Step: 3
Training loss: 0.5183347463607788
Validation loss: 2.1557047764460244

Epoch: 6| Step: 4
Training loss: 1.1993179321289062
Validation loss: 2.221384664376577

Epoch: 6| Step: 5
Training loss: 0.3053056001663208
Validation loss: 2.190637985865275

Epoch: 6| Step: 6
Training loss: 0.5164705514907837
Validation loss: 2.1540958086649575

Epoch: 6| Step: 7
Training loss: 0.6165975332260132
Validation loss: 2.1117085218429565

Epoch: 6| Step: 8
Training loss: 0.47660765051841736
Validation loss: 2.1359827518463135

Epoch: 6| Step: 9
Training loss: 0.6333447694778442
Validation loss: 2.1570898294448853

Epoch: 6| Step: 10
Training loss: 0.6808069944381714
Validation loss: 2.2212045590082803

Epoch: 6| Step: 11
Training loss: 0.6449453830718994
Validation loss: 2.239064852396647

Epoch: 6| Step: 12
Training loss: 0.6992735266685486
Validation loss: 2.2119455337524414

Epoch: 6| Step: 13
Training loss: 0.5451573133468628
Validation loss: 2.188190221786499

Epoch: 192| Step: 0
Training loss: 0.5816007852554321
Validation loss: 2.1551016171773276

Epoch: 6| Step: 1
Training loss: 0.37242454290390015
Validation loss: 2.140628198782603

Epoch: 6| Step: 2
Training loss: 0.5765982866287231
Validation loss: 2.1014623045921326

Epoch: 6| Step: 3
Training loss: 0.9686295986175537
Validation loss: 2.1391045451164246

Epoch: 6| Step: 4
Training loss: 0.624076247215271
Validation loss: 2.1785398523012796

Epoch: 6| Step: 5
Training loss: 1.1606547832489014
Validation loss: 2.1670318643252053

Epoch: 6| Step: 6
Training loss: 0.45738351345062256
Validation loss: 2.2075719634691873

Epoch: 6| Step: 7
Training loss: 0.5056213140487671
Validation loss: 2.1937998135884604

Epoch: 6| Step: 8
Training loss: 0.9152765274047852
Validation loss: 2.19232044617335

Epoch: 6| Step: 9
Training loss: 0.773827850818634
Validation loss: 2.2395816842714944

Epoch: 6| Step: 10
Training loss: 0.8067747354507446
Validation loss: 2.2181095480918884

Epoch: 6| Step: 11
Training loss: 0.528462290763855
Validation loss: 2.189878821372986

Epoch: 6| Step: 12
Training loss: 0.8377013206481934
Validation loss: 2.1250652273495994

Epoch: 6| Step: 13
Training loss: 0.4307039976119995
Validation loss: 2.1036425828933716

Epoch: 193| Step: 0
Training loss: 0.5132752656936646
Validation loss: 2.2480565508206687

Epoch: 6| Step: 1
Training loss: 0.5097631216049194
Validation loss: 2.1666552821795144

Epoch: 6| Step: 2
Training loss: 1.1998140811920166
Validation loss: 2.146121164162954

Epoch: 6| Step: 3
Training loss: 0.6108092069625854
Validation loss: 2.185251474380493

Epoch: 6| Step: 4
Training loss: 0.6789454817771912
Validation loss: 2.211335559686025

Epoch: 6| Step: 5
Training loss: 0.787473738193512
Validation loss: 2.2579104900360107

Epoch: 6| Step: 6
Training loss: 0.6767277717590332
Validation loss: 2.2768338918685913

Epoch: 6| Step: 7
Training loss: 0.5467250347137451
Validation loss: 2.169845143953959

Epoch: 6| Step: 8
Training loss: 0.5640319585800171
Validation loss: 2.225017011165619

Epoch: 6| Step: 9
Training loss: 0.736956000328064
Validation loss: 2.152042031288147

Epoch: 6| Step: 10
Training loss: 0.22881223261356354
Validation loss: 2.1044399738311768

Epoch: 6| Step: 11
Training loss: 0.9295947551727295
Validation loss: 2.200759013493856

Epoch: 6| Step: 12
Training loss: 0.523848831653595
Validation loss: 2.129372497399648

Epoch: 6| Step: 13
Training loss: 0.8681198954582214
Validation loss: 2.2032034595807395

Epoch: 194| Step: 0
Training loss: 0.4673176407814026
Validation loss: 2.123478809992472

Epoch: 6| Step: 1
Training loss: 0.46603667736053467
Validation loss: 2.192366123199463

Epoch: 6| Step: 2
Training loss: 0.5126809477806091
Validation loss: 2.2235796252886453

Epoch: 6| Step: 3
Training loss: 0.4070304334163666
Validation loss: 2.2217341462771096

Epoch: 6| Step: 4
Training loss: 0.6350293159484863
Validation loss: 2.148849050203959

Epoch: 6| Step: 5
Training loss: 0.5514597296714783
Validation loss: 2.2073949575424194

Epoch: 6| Step: 6
Training loss: 0.3031563460826874
Validation loss: 2.2058741648991904

Epoch: 6| Step: 7
Training loss: 0.4631270468235016
Validation loss: 2.1949084798494973

Epoch: 6| Step: 8
Training loss: 0.664130449295044
Validation loss: 2.139781435330709

Epoch: 6| Step: 9
Training loss: 0.6593119502067566
Validation loss: 2.1253028909365335

Epoch: 6| Step: 10
Training loss: 0.5573880076408386
Validation loss: 2.1439000169436135

Epoch: 6| Step: 11
Training loss: 0.6929844617843628
Validation loss: 2.1541504859924316

Epoch: 6| Step: 12
Training loss: 1.0948002338409424
Validation loss: 2.202993313471476

Epoch: 6| Step: 13
Training loss: 1.0930137634277344
Validation loss: 2.1771897276242576

Epoch: 195| Step: 0
Training loss: 0.6155195236206055
Validation loss: 2.1729039947191873

Epoch: 6| Step: 1
Training loss: 0.5430849194526672
Validation loss: 2.1410478750864663

Epoch: 6| Step: 2
Training loss: 1.2482399940490723
Validation loss: 2.154290477434794

Epoch: 6| Step: 3
Training loss: 0.5259692668914795
Validation loss: 2.1416330337524414

Epoch: 6| Step: 4
Training loss: 0.7189099192619324
Validation loss: 2.0793997645378113

Epoch: 6| Step: 5
Training loss: 0.7436542510986328
Validation loss: 2.0975940028826394

Epoch: 6| Step: 6
Training loss: 0.4761175513267517
Validation loss: 2.159927407900492

Epoch: 6| Step: 7
Training loss: 0.980350136756897
Validation loss: 2.161038597424825

Epoch: 6| Step: 8
Training loss: 0.6049737334251404
Validation loss: 2.207454482714335

Epoch: 6| Step: 9
Training loss: 0.41288071870803833
Validation loss: 2.2586613098780313

Epoch: 6| Step: 10
Training loss: 0.43522417545318604
Validation loss: 2.168661336104075

Epoch: 6| Step: 11
Training loss: 0.5529007911682129
Validation loss: 2.077386260032654

Epoch: 6| Step: 12
Training loss: 0.40184202790260315
Validation loss: 2.1265340050061545

Epoch: 6| Step: 13
Training loss: 0.64762943983078
Validation loss: 2.148934304714203

Epoch: 196| Step: 0
Training loss: 0.7324182987213135
Validation loss: 2.1222753524780273

Epoch: 6| Step: 1
Training loss: 0.9352589249610901
Validation loss: 2.157981276512146

Epoch: 6| Step: 2
Training loss: 0.36013898253440857
Validation loss: 2.2095463275909424

Epoch: 6| Step: 3
Training loss: 0.7780818939208984
Validation loss: 2.1555320421854653

Epoch: 6| Step: 4
Training loss: 0.3789712190628052
Validation loss: 2.162204146385193

Epoch: 6| Step: 5
Training loss: 0.6046783328056335
Validation loss: 2.1645884911219277

Epoch: 6| Step: 6
Training loss: 1.1403502225875854
Validation loss: 2.19212398926417

Epoch: 6| Step: 7
Training loss: 0.6857326030731201
Validation loss: 2.1777931849161782

Epoch: 6| Step: 8
Training loss: 0.4333556890487671
Validation loss: 2.1315380136171975

Epoch: 6| Step: 9
Training loss: 0.6069440841674805
Validation loss: 2.1675819158554077

Epoch: 6| Step: 10
Training loss: 0.6127376556396484
Validation loss: 2.190828283627828

Epoch: 6| Step: 11
Training loss: 0.459177702665329
Validation loss: 2.202768941720327

Epoch: 6| Step: 12
Training loss: 0.6169213056564331
Validation loss: 2.15931769212087

Epoch: 6| Step: 13
Training loss: 0.3052597641944885
Validation loss: 2.096013903617859

Epoch: 197| Step: 0
Training loss: 0.4881085157394409
Validation loss: 2.154749790827433

Epoch: 6| Step: 1
Training loss: 0.61131751537323
Validation loss: 2.131223420302073

Epoch: 6| Step: 2
Training loss: 0.5983788371086121
Validation loss: 2.1678534348805747

Epoch: 6| Step: 3
Training loss: 0.45907869935035706
Validation loss: 2.1678786476453147

Epoch: 6| Step: 4
Training loss: 1.1749181747436523
Validation loss: 2.209906816482544

Epoch: 6| Step: 5
Training loss: 0.6300607919692993
Validation loss: 2.1962729692459106

Epoch: 6| Step: 6
Training loss: 0.7527625560760498
Validation loss: 2.129173517227173

Epoch: 6| Step: 7
Training loss: 0.4573907256126404
Validation loss: 2.220909814039866

Epoch: 6| Step: 8
Training loss: 0.5045515894889832
Validation loss: 2.2082147002220154

Epoch: 6| Step: 9
Training loss: 0.6863442659378052
Validation loss: 2.102788984775543

Epoch: 6| Step: 10
Training loss: 0.40062254667282104
Validation loss: 2.1334349711736045

Epoch: 6| Step: 11
Training loss: 0.9004093408584595
Validation loss: 2.1321489810943604

Epoch: 6| Step: 12
Training loss: 0.4676002264022827
Validation loss: 2.147938350836436

Epoch: 6| Step: 13
Training loss: 0.6129221320152283
Validation loss: 2.1394344369570413

Epoch: 198| Step: 0
Training loss: 0.40964847803115845
Validation loss: 2.148320655028025

Epoch: 6| Step: 1
Training loss: 0.9623239040374756
Validation loss: 2.253614068031311

Epoch: 6| Step: 2
Training loss: 1.2101457118988037
Validation loss: 2.324856479962667

Epoch: 6| Step: 3
Training loss: 0.6312013268470764
Validation loss: 2.2554287711779275

Epoch: 6| Step: 4
Training loss: 0.8040386438369751
Validation loss: 2.316899220148722

Epoch: 6| Step: 5
Training loss: 0.5500655174255371
Validation loss: 2.2096534967422485

Epoch: 6| Step: 6
Training loss: 0.5516571402549744
Validation loss: 2.162631173928579

Epoch: 6| Step: 7
Training loss: 0.5554195642471313
Validation loss: 2.142500917116801

Epoch: 6| Step: 8
Training loss: 0.8197067975997925
Validation loss: 2.1282172004381814

Epoch: 6| Step: 9
Training loss: 0.5604909062385559
Validation loss: 2.1136659383773804

Epoch: 6| Step: 10
Training loss: 0.5813744068145752
Validation loss: 2.1871724724769592

Epoch: 6| Step: 11
Training loss: 0.3675743043422699
Validation loss: 2.2153773506482444

Epoch: 6| Step: 12
Training loss: 1.0525916814804077
Validation loss: 2.216137091318766

Epoch: 6| Step: 13
Training loss: 0.5879011154174805
Validation loss: 2.233896096547445

Epoch: 199| Step: 0
Training loss: 0.3230302929878235
Validation loss: 2.2218048572540283

Epoch: 6| Step: 1
Training loss: 0.6236214637756348
Validation loss: 2.2183552185694375

Epoch: 6| Step: 2
Training loss: 0.9126259088516235
Validation loss: 2.181147575378418

Epoch: 6| Step: 3
Training loss: 0.7651669979095459
Validation loss: 2.1095739006996155

Epoch: 6| Step: 4
Training loss: 0.5177919268608093
Validation loss: 2.1612761418024697

Epoch: 6| Step: 5
Training loss: 0.6817271709442139
Validation loss: 2.1938462058703103

Epoch: 6| Step: 6
Training loss: 0.5279377102851868
Validation loss: 2.2137596209843955

Epoch: 6| Step: 7
Training loss: 0.7890812754631042
Validation loss: 2.233677923679352

Epoch: 6| Step: 8
Training loss: 0.4769607186317444
Validation loss: 2.207525889078776

Epoch: 6| Step: 9
Training loss: 0.49867865443229675
Validation loss: 2.2457145849863687

Epoch: 6| Step: 10
Training loss: 0.4881119728088379
Validation loss: 2.081650714079539

Epoch: 6| Step: 11
Training loss: 0.6167680025100708
Validation loss: 2.106420715649923

Epoch: 6| Step: 12
Training loss: 0.9252751469612122
Validation loss: 2.1398447155952454

Epoch: 6| Step: 13
Training loss: 0.5806843638420105
Validation loss: 2.1436952153841653

Epoch: 200| Step: 0
Training loss: 0.6030576229095459
Validation loss: 2.190046767393748

Epoch: 6| Step: 1
Training loss: 0.4462137222290039
Validation loss: 2.1955849726994834

Epoch: 6| Step: 2
Training loss: 0.47943225502967834
Validation loss: 2.1528200507164

Epoch: 6| Step: 3
Training loss: 0.799761176109314
Validation loss: 2.2201600074768066

Epoch: 6| Step: 4
Training loss: 0.8582019805908203
Validation loss: 2.1086369156837463

Epoch: 6| Step: 5
Training loss: 0.5494895577430725
Validation loss: 2.166127324104309

Epoch: 6| Step: 6
Training loss: 0.3271668553352356
Validation loss: 2.1337366501490274

Epoch: 6| Step: 7
Training loss: 0.4919566512107849
Validation loss: 2.170052627722422

Epoch: 6| Step: 8
Training loss: 0.629733681678772
Validation loss: 2.1974610686302185

Epoch: 6| Step: 9
Training loss: 0.48071497678756714
Validation loss: 2.1554131309191384

Epoch: 6| Step: 10
Training loss: 0.4283662736415863
Validation loss: 2.19166366259257

Epoch: 6| Step: 11
Training loss: 0.47178593277931213
Validation loss: 2.2367921272913613

Epoch: 6| Step: 12
Training loss: 0.8251533508300781
Validation loss: 2.159855624039968

Epoch: 6| Step: 13
Training loss: 1.2655442953109741
Validation loss: 2.205519954363505

Epoch: 201| Step: 0
Training loss: 0.5742563605308533
Validation loss: 2.178760846455892

Epoch: 6| Step: 1
Training loss: 0.5508904457092285
Validation loss: 2.1474077900250754

Epoch: 6| Step: 2
Training loss: 0.3858039379119873
Validation loss: 2.221285621325175

Epoch: 6| Step: 3
Training loss: 0.5731792449951172
Validation loss: 2.1858350237210593

Epoch: 6| Step: 4
Training loss: 0.5897549390792847
Validation loss: 2.2128300865491233

Epoch: 6| Step: 5
Training loss: 1.1250114440917969
Validation loss: 2.26618625720342

Epoch: 6| Step: 6
Training loss: 0.39346933364868164
Validation loss: 2.2000253597895303

Epoch: 6| Step: 7
Training loss: 1.0051894187927246
Validation loss: 2.1878809332847595

Epoch: 6| Step: 8
Training loss: 0.7773565649986267
Validation loss: 2.193247119585673

Epoch: 6| Step: 9
Training loss: 0.5630318522453308
Validation loss: 2.135537048180898

Epoch: 6| Step: 10
Training loss: 0.4491194188594818
Validation loss: 2.1762249867121377

Epoch: 6| Step: 11
Training loss: 0.3183250427246094
Validation loss: 2.163640638192495

Epoch: 6| Step: 12
Training loss: 0.4119587242603302
Validation loss: 2.174173593521118

Epoch: 6| Step: 13
Training loss: 0.8267563581466675
Validation loss: 2.1736024618148804

Epoch: 202| Step: 0
Training loss: 0.72843337059021
Validation loss: 2.2382328112920127

Epoch: 6| Step: 1
Training loss: 0.6873371601104736
Validation loss: 2.216537356376648

Epoch: 6| Step: 2
Training loss: 0.42497164011001587
Validation loss: 2.1843530734380088

Epoch: 6| Step: 3
Training loss: 0.6738594174385071
Validation loss: 2.1919190486272178

Epoch: 6| Step: 4
Training loss: 0.27609044313430786
Validation loss: 2.1729168693224588

Epoch: 6| Step: 5
Training loss: 0.3089073896408081
Validation loss: 2.1674935619036355

Epoch: 6| Step: 6
Training loss: 1.1528220176696777
Validation loss: 2.1342480977376304

Epoch: 6| Step: 7
Training loss: 0.2645312249660492
Validation loss: 2.2039512197176614

Epoch: 6| Step: 8
Training loss: 0.669821560382843
Validation loss: 2.206736445426941

Epoch: 6| Step: 9
Training loss: 0.7592767477035522
Validation loss: 2.304397483666738

Epoch: 6| Step: 10
Training loss: 0.9271711111068726
Validation loss: 2.2193032105763755

Epoch: 6| Step: 11
Training loss: 0.5919885635375977
Validation loss: 2.2435444792111716

Epoch: 6| Step: 12
Training loss: 0.6080663204193115
Validation loss: 2.236413300037384

Epoch: 6| Step: 13
Training loss: 0.5043816566467285
Validation loss: 2.126280645529429

Epoch: 203| Step: 0
Training loss: 0.6274760961532593
Validation loss: 2.1552749276161194

Epoch: 6| Step: 1
Training loss: 0.5907878279685974
Validation loss: 2.1085370779037476

Epoch: 6| Step: 2
Training loss: 1.2047441005706787
Validation loss: 2.173522194226583

Epoch: 6| Step: 3
Training loss: 0.8063071370124817
Validation loss: 2.206000546614329

Epoch: 6| Step: 4
Training loss: 1.037287712097168
Validation loss: 2.1614840825398765

Epoch: 6| Step: 5
Training loss: 0.8788717985153198
Validation loss: 2.1404244105021157

Epoch: 6| Step: 6
Training loss: 0.37683799862861633
Validation loss: 2.1700769662857056

Epoch: 6| Step: 7
Training loss: 0.42095330357551575
Validation loss: 2.160246272881826

Epoch: 6| Step: 8
Training loss: 0.4181252717971802
Validation loss: 2.16221821308136

Epoch: 6| Step: 9
Training loss: 0.444423645734787
Validation loss: 2.1786707043647766

Epoch: 6| Step: 10
Training loss: 0.3574281930923462
Validation loss: 2.1784690022468567

Epoch: 6| Step: 11
Training loss: 0.6161278486251831
Validation loss: 2.1315357287724814

Epoch: 6| Step: 12
Training loss: 0.6009551286697388
Validation loss: 2.1552634835243225

Epoch: 6| Step: 13
Training loss: 0.3530995845794678
Validation loss: 2.1942493518193564

Epoch: 204| Step: 0
Training loss: 1.238968849182129
Validation loss: 2.174787918726603

Epoch: 6| Step: 1
Training loss: 0.3215451240539551
Validation loss: 2.2176218032836914

Epoch: 6| Step: 2
Training loss: 0.4729423522949219
Validation loss: 2.273811459541321

Epoch: 6| Step: 3
Training loss: 0.4587036371231079
Validation loss: 2.19539866844813

Epoch: 6| Step: 4
Training loss: 0.438836932182312
Validation loss: 2.2328475515047708

Epoch: 6| Step: 5
Training loss: 0.5496398210525513
Validation loss: 2.115224222342173

Epoch: 6| Step: 6
Training loss: 0.9187090396881104
Validation loss: 2.162174562613169

Epoch: 6| Step: 7
Training loss: 0.7583599090576172
Validation loss: 2.201318681240082

Epoch: 6| Step: 8
Training loss: 0.8913267850875854
Validation loss: 2.1420737504959106

Epoch: 6| Step: 9
Training loss: 0.6790185570716858
Validation loss: 2.1670713424682617

Epoch: 6| Step: 10
Training loss: 0.4227403402328491
Validation loss: 2.2351425091425576

Epoch: 6| Step: 11
Training loss: 0.5913968682289124
Validation loss: 2.2918197313944497

Epoch: 6| Step: 12
Training loss: 0.8754821419715881
Validation loss: 2.2769761085510254

Epoch: 6| Step: 13
Training loss: 0.6532398462295532
Validation loss: 2.264176686604818

Epoch: 205| Step: 0
Training loss: 0.8832385540008545
Validation loss: 2.1493377089500427

Epoch: 6| Step: 1
Training loss: 0.8255645036697388
Validation loss: 2.118614137172699

Epoch: 6| Step: 2
Training loss: 0.8450588583946228
Validation loss: 2.2270641724268594

Epoch: 6| Step: 3
Training loss: 1.1413676738739014
Validation loss: 2.166966954867045

Epoch: 6| Step: 4
Training loss: 0.6569526195526123
Validation loss: 2.1374108592669168

Epoch: 6| Step: 5
Training loss: 0.741399884223938
Validation loss: 2.1293821732203164

Epoch: 6| Step: 6
Training loss: 0.27698057889938354
Validation loss: 2.209087630112966

Epoch: 6| Step: 7
Training loss: 0.7710820436477661
Validation loss: 2.296387473742167

Epoch: 6| Step: 8
Training loss: 0.7386511564254761
Validation loss: 2.321974496046702

Epoch: 6| Step: 9
Training loss: 0.5511316061019897
Validation loss: 2.329733908176422

Epoch: 6| Step: 10
Training loss: 0.7084033489227295
Validation loss: 2.2420773108800254

Epoch: 6| Step: 11
Training loss: 0.5522540807723999
Validation loss: 2.15014785528183

Epoch: 6| Step: 12
Training loss: 0.9908475279808044
Validation loss: 2.1649083495140076

Epoch: 6| Step: 13
Training loss: 0.9476422071456909
Validation loss: 2.153407017389933

Epoch: 206| Step: 0
Training loss: 0.5137487649917603
Validation loss: 2.1723533272743225

Epoch: 6| Step: 1
Training loss: 0.8061478734016418
Validation loss: 2.1266046365102134

Epoch: 6| Step: 2
Training loss: 0.668737530708313
Validation loss: 2.1535627841949463

Epoch: 6| Step: 3
Training loss: 0.6466659307479858
Validation loss: 2.229843556880951

Epoch: 6| Step: 4
Training loss: 0.6587281227111816
Validation loss: 2.2208619912465415

Epoch: 6| Step: 5
Training loss: 0.6416938304901123
Validation loss: 2.216144025325775

Epoch: 6| Step: 6
Training loss: 0.35402917861938477
Validation loss: 2.235445956389109

Epoch: 6| Step: 7
Training loss: 0.7729047536849976
Validation loss: 2.1488455136617026

Epoch: 6| Step: 8
Training loss: 0.5888856649398804
Validation loss: 2.1759530504544577

Epoch: 6| Step: 9
Training loss: 0.8676633834838867
Validation loss: 2.128945807615916

Epoch: 6| Step: 10
Training loss: 0.6485488414764404
Validation loss: 2.1708584427833557

Epoch: 6| Step: 11
Training loss: 0.27716606855392456
Validation loss: 2.171528081099192

Epoch: 6| Step: 12
Training loss: 0.8429569005966187
Validation loss: 2.1845983068148294

Epoch: 6| Step: 13
Training loss: 0.7422407865524292
Validation loss: 2.229102353254954

Epoch: 207| Step: 0
Training loss: 0.4300633370876312
Validation loss: 2.273792882760366

Epoch: 6| Step: 1
Training loss: 0.6905568838119507
Validation loss: 2.233455240726471

Epoch: 6| Step: 2
Training loss: 0.5437257289886475
Validation loss: 2.230315168698629

Epoch: 6| Step: 3
Training loss: 0.41021671891212463
Validation loss: 2.152455151081085

Epoch: 6| Step: 4
Training loss: 1.1827616691589355
Validation loss: 2.1442724466323853

Epoch: 6| Step: 5
Training loss: 0.9551346302032471
Validation loss: 2.1858819127082825

Epoch: 6| Step: 6
Training loss: 0.6692125201225281
Validation loss: 2.13979039589564

Epoch: 6| Step: 7
Training loss: 0.3906673789024353
Validation loss: 2.136104961236318

Epoch: 6| Step: 8
Training loss: 0.3757098317146301
Validation loss: 2.1407891114552817

Epoch: 6| Step: 9
Training loss: 0.6961022019386292
Validation loss: 2.175236761569977

Epoch: 6| Step: 10
Training loss: 0.4321335554122925
Validation loss: 2.174726724624634

Epoch: 6| Step: 11
Training loss: 0.48072385787963867
Validation loss: 2.1375813484191895

Epoch: 6| Step: 12
Training loss: 0.31968843936920166
Validation loss: 2.173794388771057

Epoch: 6| Step: 13
Training loss: 0.5886403322219849
Validation loss: 2.1068360010782876

Epoch: 208| Step: 0
Training loss: 0.8218322396278381
Validation loss: 2.1298630436261496

Epoch: 6| Step: 1
Training loss: 0.7559576034545898
Validation loss: 2.241316815217336

Epoch: 6| Step: 2
Training loss: 0.44613683223724365
Validation loss: 2.2353788216908774

Epoch: 6| Step: 3
Training loss: 0.3434421718120575
Validation loss: 2.195871035257975

Epoch: 6| Step: 4
Training loss: 0.6516640782356262
Validation loss: 2.2479744950930276

Epoch: 6| Step: 5
Training loss: 0.27489572763442993
Validation loss: 2.21932460864385

Epoch: 6| Step: 6
Training loss: 1.0787831544876099
Validation loss: 2.1885520815849304

Epoch: 6| Step: 7
Training loss: 0.727434515953064
Validation loss: 2.182506283124288

Epoch: 6| Step: 8
Training loss: 0.4951699674129486
Validation loss: 2.145077367623647

Epoch: 6| Step: 9
Training loss: 0.49298352003097534
Validation loss: 2.10380748907725

Epoch: 6| Step: 10
Training loss: 0.6430694460868835
Validation loss: 2.1381887992223105

Epoch: 6| Step: 11
Training loss: 0.44847139716148376
Validation loss: 2.1072060664494834

Epoch: 6| Step: 12
Training loss: 0.5281952023506165
Validation loss: 2.1415218512217202

Epoch: 6| Step: 13
Training loss: 0.6789507269859314
Validation loss: 2.20192414522171

Epoch: 209| Step: 0
Training loss: 0.6331433653831482
Validation loss: 2.1968291997909546

Epoch: 6| Step: 1
Training loss: 0.9941062331199646
Validation loss: 2.1925869584083557

Epoch: 6| Step: 2
Training loss: 0.7814494371414185
Validation loss: 2.2831808725992837

Epoch: 6| Step: 3
Training loss: 0.6821541786193848
Validation loss: 2.1993147929509482

Epoch: 6| Step: 4
Training loss: 0.6333414316177368
Validation loss: 2.199145793914795

Epoch: 6| Step: 5
Training loss: 0.5237340331077576
Validation loss: 2.159103035926819

Epoch: 6| Step: 6
Training loss: 0.5801836252212524
Validation loss: 2.188059409459432

Epoch: 6| Step: 7
Training loss: 0.7788156867027283
Validation loss: 2.180516997973124

Epoch: 6| Step: 8
Training loss: 0.6914682388305664
Validation loss: 2.1115063031514487

Epoch: 6| Step: 9
Training loss: 0.759367823600769
Validation loss: 2.149517317612966

Epoch: 6| Step: 10
Training loss: 0.772879421710968
Validation loss: 2.1946508288383484

Epoch: 6| Step: 11
Training loss: 0.6956635117530823
Validation loss: 2.2014368573824563

Epoch: 6| Step: 12
Training loss: 0.5067914724349976
Validation loss: 2.2755703131357827

Epoch: 6| Step: 13
Training loss: 0.725767195224762
Validation loss: 2.2050155202547708

Epoch: 210| Step: 0
Training loss: 0.3867971897125244
Validation loss: 2.175708512465159

Epoch: 6| Step: 1
Training loss: 0.8159722089767456
Validation loss: 2.169759194056193

Epoch: 6| Step: 2
Training loss: 0.5097135305404663
Validation loss: 2.2178584734598794

Epoch: 6| Step: 3
Training loss: 0.4705824851989746
Validation loss: 2.1543904344240823

Epoch: 6| Step: 4
Training loss: 0.9437212944030762
Validation loss: 2.131479799747467

Epoch: 6| Step: 5
Training loss: 0.6785542964935303
Validation loss: 2.177714924017588

Epoch: 6| Step: 6
Training loss: 0.6499040126800537
Validation loss: 2.188223918279012

Epoch: 6| Step: 7
Training loss: 0.7931334972381592
Validation loss: 2.145857294400533

Epoch: 6| Step: 8
Training loss: 0.4226716160774231
Validation loss: 2.2543360789616904

Epoch: 6| Step: 9
Training loss: 0.3435206413269043
Validation loss: 2.189732472101847

Epoch: 6| Step: 10
Training loss: 0.5531127452850342
Validation loss: 2.1651909351348877

Epoch: 6| Step: 11
Training loss: 0.6492811441421509
Validation loss: 2.258524755636851

Epoch: 6| Step: 12
Training loss: 1.0142388343811035
Validation loss: 2.1860236724217734

Epoch: 6| Step: 13
Training loss: 0.5139240622520447
Validation loss: 2.116007089614868

Epoch: 211| Step: 0
Training loss: 0.7419869899749756
Validation loss: 2.1572569807370505

Epoch: 6| Step: 1
Training loss: 0.5108532905578613
Validation loss: 2.1246586640675864

Epoch: 6| Step: 2
Training loss: 0.765601634979248
Validation loss: 2.1539386908213296

Epoch: 6| Step: 3
Training loss: 0.5316275358200073
Validation loss: 2.122581501801809

Epoch: 6| Step: 4
Training loss: 0.2002221792936325
Validation loss: 2.178443491458893

Epoch: 6| Step: 5
Training loss: 0.5801992416381836
Validation loss: 2.2525132298469543

Epoch: 6| Step: 6
Training loss: 1.2378686666488647
Validation loss: 2.3124765753746033

Epoch: 6| Step: 7
Training loss: 0.7180124521255493
Validation loss: 2.276439666748047

Epoch: 6| Step: 8
Training loss: 1.0465314388275146
Validation loss: 2.37145733833313

Epoch: 6| Step: 9
Training loss: 0.7740651965141296
Validation loss: 2.2569605112075806

Epoch: 6| Step: 10
Training loss: 0.7265269160270691
Validation loss: 2.2143553495407104

Epoch: 6| Step: 11
Training loss: 0.508764386177063
Validation loss: 2.1718075474103293

Epoch: 6| Step: 12
Training loss: 0.7867059111595154
Validation loss: 2.1323113640149436

Epoch: 6| Step: 13
Training loss: 1.050121784210205
Validation loss: 2.1866445541381836

Epoch: 212| Step: 0
Training loss: 0.7426233887672424
Validation loss: 2.1373361547787986

Epoch: 6| Step: 1
Training loss: 0.4511987864971161
Validation loss: 2.1202648480733237

Epoch: 6| Step: 2
Training loss: 0.6476941108703613
Validation loss: 2.2062675952911377

Epoch: 6| Step: 3
Training loss: 0.9180824756622314
Validation loss: 2.204176902770996

Epoch: 6| Step: 4
Training loss: 0.6174641847610474
Validation loss: 2.2512173652648926

Epoch: 6| Step: 5
Training loss: 0.7974103689193726
Validation loss: 2.35379829009374

Epoch: 6| Step: 6
Training loss: 0.8706586360931396
Validation loss: 2.2791461745897927

Epoch: 6| Step: 7
Training loss: 0.574252724647522
Validation loss: 2.263300140698751

Epoch: 6| Step: 8
Training loss: 0.46013545989990234
Validation loss: 2.1847644646962485

Epoch: 6| Step: 9
Training loss: 0.7885438799858093
Validation loss: 2.1509617964426675

Epoch: 6| Step: 10
Training loss: 0.5385544300079346
Validation loss: 2.144708732763926

Epoch: 6| Step: 11
Training loss: 0.8654370903968811
Validation loss: 2.2498921950658164

Epoch: 6| Step: 12
Training loss: 0.48576995730400085
Validation loss: 2.2214921514193215

Epoch: 6| Step: 13
Training loss: 0.2974483370780945
Validation loss: 2.1810312072436013

Epoch: 213| Step: 0
Training loss: 0.4331517815589905
Validation loss: 2.2166175047556558

Epoch: 6| Step: 1
Training loss: 0.7126288414001465
Validation loss: 2.2054200172424316

Epoch: 6| Step: 2
Training loss: 0.6416643857955933
Validation loss: 2.217733641465505

Epoch: 6| Step: 3
Training loss: 0.4514750838279724
Validation loss: 2.2395022908846536

Epoch: 6| Step: 4
Training loss: 0.5669488310813904
Validation loss: 2.1772557894388833

Epoch: 6| Step: 5
Training loss: 0.6188127994537354
Validation loss: 2.186887880166372

Epoch: 6| Step: 6
Training loss: 0.5384988188743591
Validation loss: 2.166116734345754

Epoch: 6| Step: 7
Training loss: 0.4868119955062866
Validation loss: 2.149289627869924

Epoch: 6| Step: 8
Training loss: 0.9247860908508301
Validation loss: 2.2052789330482483

Epoch: 6| Step: 9
Training loss: 0.5388280153274536
Validation loss: 2.1431920528411865

Epoch: 6| Step: 10
Training loss: 0.3196236491203308
Validation loss: 2.1924800674120584

Epoch: 6| Step: 11
Training loss: 0.8764828443527222
Validation loss: 2.1774811347325644

Epoch: 6| Step: 12
Training loss: 0.5068707466125488
Validation loss: 2.221031387646993

Epoch: 6| Step: 13
Training loss: 0.8673590421676636
Validation loss: 2.2724453608194985

Epoch: 214| Step: 0
Training loss: 0.9316650629043579
Validation loss: 2.299508968989054

Epoch: 6| Step: 1
Training loss: 1.009006142616272
Validation loss: 2.2381590604782104

Epoch: 6| Step: 2
Training loss: 0.6668956279754639
Validation loss: 2.1634804805119834

Epoch: 6| Step: 3
Training loss: 0.674505889415741
Validation loss: 2.137626846631368

Epoch: 6| Step: 4
Training loss: 0.7828155755996704
Validation loss: 2.150677800178528

Epoch: 6| Step: 5
Training loss: 0.8947558999061584
Validation loss: 2.171805441379547

Epoch: 6| Step: 6
Training loss: 0.6018752455711365
Validation loss: 2.116825302441915

Epoch: 6| Step: 7
Training loss: 0.7170177102088928
Validation loss: 2.1398621598879495

Epoch: 6| Step: 8
Training loss: 0.5146302580833435
Validation loss: 2.087116082509359

Epoch: 6| Step: 9
Training loss: 0.753020167350769
Validation loss: 2.1515250205993652

Epoch: 6| Step: 10
Training loss: 0.7457544803619385
Validation loss: 2.1781392097473145

Epoch: 6| Step: 11
Training loss: 0.6290732026100159
Validation loss: 2.2404284874598184

Epoch: 6| Step: 12
Training loss: 0.9038195610046387
Validation loss: 2.299540380636851

Epoch: 6| Step: 13
Training loss: 0.47364044189453125
Validation loss: 2.2307971318562827

Epoch: 215| Step: 0
Training loss: 0.5555424690246582
Validation loss: 2.1789745092391968

Epoch: 6| Step: 1
Training loss: 0.4934120774269104
Validation loss: 2.1296150286992392

Epoch: 6| Step: 2
Training loss: 0.45663660764694214
Validation loss: 2.1431166529655457

Epoch: 6| Step: 3
Training loss: 0.5369743704795837
Validation loss: 2.1251437067985535

Epoch: 6| Step: 4
Training loss: 0.8536079525947571
Validation loss: 2.1740673383076987

Epoch: 6| Step: 5
Training loss: 0.6631193161010742
Validation loss: 2.139170249303182

Epoch: 6| Step: 6
Training loss: 0.4621592164039612
Validation loss: 2.1985039114952087

Epoch: 6| Step: 7
Training loss: 0.5280054807662964
Validation loss: 2.226535677909851

Epoch: 6| Step: 8
Training loss: 0.7955058217048645
Validation loss: 2.23401931921641

Epoch: 6| Step: 9
Training loss: 0.8858431577682495
Validation loss: 2.237980326016744

Epoch: 6| Step: 10
Training loss: 0.4568397104740143
Validation loss: 2.2002389232317605

Epoch: 6| Step: 11
Training loss: 0.5614277124404907
Validation loss: 2.188754936059316

Epoch: 6| Step: 12
Training loss: 0.4930664002895355
Validation loss: 2.120354175567627

Epoch: 6| Step: 13
Training loss: 0.9746145009994507
Validation loss: 2.131697734196981

Epoch: 216| Step: 0
Training loss: 0.6689161062240601
Validation loss: 2.0899753173192344

Epoch: 6| Step: 1
Training loss: 0.5268170833587646
Validation loss: 2.14580762386322

Epoch: 6| Step: 2
Training loss: 0.37751317024230957
Validation loss: 2.215860962867737

Epoch: 6| Step: 3
Training loss: 0.4704432189464569
Validation loss: 2.1337610681851706

Epoch: 6| Step: 4
Training loss: 0.37784361839294434
Validation loss: 2.2346098224322

Epoch: 6| Step: 5
Training loss: 1.2636107206344604
Validation loss: 2.23667440811793

Epoch: 6| Step: 6
Training loss: 0.5429259538650513
Validation loss: 2.209350605805715

Epoch: 6| Step: 7
Training loss: 0.4750283658504486
Validation loss: 2.2493816614151

Epoch: 6| Step: 8
Training loss: 0.5613419413566589
Validation loss: 2.2000728050867715

Epoch: 6| Step: 9
Training loss: 0.9818049669265747
Validation loss: 2.1210269133249917

Epoch: 6| Step: 10
Training loss: 0.5656975507736206
Validation loss: 2.1477277676264444

Epoch: 6| Step: 11
Training loss: 1.113675594329834
Validation loss: 2.1055973768234253

Epoch: 6| Step: 12
Training loss: 0.4518411159515381
Validation loss: 2.1630935271581015

Epoch: 6| Step: 13
Training loss: 0.6947674751281738
Validation loss: 2.0745030641555786

Epoch: 217| Step: 0
Training loss: 0.7820532917976379
Validation loss: 2.1103107730547586

Epoch: 6| Step: 1
Training loss: 0.40445342659950256
Validation loss: 2.138039549191793

Epoch: 6| Step: 2
Training loss: 0.4643408954143524
Validation loss: 2.2008548974990845

Epoch: 6| Step: 3
Training loss: 0.5492224097251892
Validation loss: 2.2542649110158286

Epoch: 6| Step: 4
Training loss: 0.8233639001846313
Validation loss: 2.293833295504252

Epoch: 6| Step: 5
Training loss: 0.9386157989501953
Validation loss: 2.2838011582692466

Epoch: 6| Step: 6
Training loss: 0.767081618309021
Validation loss: 2.1822651823361716

Epoch: 6| Step: 7
Training loss: 0.9460470080375671
Validation loss: 2.166501740614573

Epoch: 6| Step: 8
Training loss: 0.34052491188049316
Validation loss: 2.1701985398928323

Epoch: 6| Step: 9
Training loss: 0.8165250420570374
Validation loss: 2.133661071459452

Epoch: 6| Step: 10
Training loss: 0.5882083177566528
Validation loss: 2.141889750957489

Epoch: 6| Step: 11
Training loss: 0.606360912322998
Validation loss: 2.1626232862472534

Epoch: 6| Step: 12
Training loss: 0.5880531072616577
Validation loss: 2.188340445359548

Epoch: 6| Step: 13
Training loss: 0.6715879440307617
Validation loss: 2.177913029988607

Epoch: 218| Step: 0
Training loss: 0.3397439420223236
Validation loss: 2.268026431401571

Epoch: 6| Step: 1
Training loss: 0.8066988587379456
Validation loss: 2.2453389962514243

Epoch: 6| Step: 2
Training loss: 0.661960780620575
Validation loss: 2.2229623198509216

Epoch: 6| Step: 3
Training loss: 0.8336575627326965
Validation loss: 2.202836354573568

Epoch: 6| Step: 4
Training loss: 0.33549046516418457
Validation loss: 2.2005591988563538

Epoch: 6| Step: 5
Training loss: 0.8500741124153137
Validation loss: 2.196064273516337

Epoch: 6| Step: 6
Training loss: 0.5982781052589417
Validation loss: 2.188016712665558

Epoch: 6| Step: 7
Training loss: 0.5345454216003418
Validation loss: 2.161208132902781

Epoch: 6| Step: 8
Training loss: 0.3321937322616577
Validation loss: 2.19538547595342

Epoch: 6| Step: 9
Training loss: 0.53714519739151
Validation loss: 2.2610906958580017

Epoch: 6| Step: 10
Training loss: 0.44342824816703796
Validation loss: 2.269714911778768

Epoch: 6| Step: 11
Training loss: 0.5290533304214478
Validation loss: 2.271911064783732

Epoch: 6| Step: 12
Training loss: 1.023256540298462
Validation loss: 2.269914189974467

Epoch: 6| Step: 13
Training loss: 0.7243121862411499
Validation loss: 2.1859710017840066

Epoch: 219| Step: 0
Training loss: 0.7877579927444458
Validation loss: 2.1753339767456055

Epoch: 6| Step: 1
Training loss: 0.44008612632751465
Validation loss: 2.2053040862083435

Epoch: 6| Step: 2
Training loss: 0.5136620998382568
Validation loss: 2.133718172709147

Epoch: 6| Step: 3
Training loss: 0.5721830129623413
Validation loss: 2.1757785876592

Epoch: 6| Step: 4
Training loss: 0.537281334400177
Validation loss: 2.181178947289785

Epoch: 6| Step: 5
Training loss: 0.6801877617835999
Validation loss: 2.1245426138242087

Epoch: 6| Step: 6
Training loss: 0.3223511874675751
Validation loss: 2.1598321199417114

Epoch: 6| Step: 7
Training loss: 0.43652716279029846
Validation loss: 2.1644166509310403

Epoch: 6| Step: 8
Training loss: 0.35141900181770325
Validation loss: 2.2138179341952005

Epoch: 6| Step: 9
Training loss: 0.5226154923439026
Validation loss: 2.192514936129252

Epoch: 6| Step: 10
Training loss: 0.5036863088607788
Validation loss: 2.216769297917684

Epoch: 6| Step: 11
Training loss: 0.9574222564697266
Validation loss: 2.164839963118235

Epoch: 6| Step: 12
Training loss: 0.6683242321014404
Validation loss: 2.1483386357625327

Epoch: 6| Step: 13
Training loss: 0.5819776058197021
Validation loss: 2.072593847910563

Epoch: 220| Step: 0
Training loss: 0.4957714080810547
Validation loss: 2.132049858570099

Epoch: 6| Step: 1
Training loss: 0.6270120143890381
Validation loss: 2.1742910941441855

Epoch: 6| Step: 2
Training loss: 0.8372458815574646
Validation loss: 2.1035231749216714

Epoch: 6| Step: 3
Training loss: 0.4809199273586273
Validation loss: 2.1740516225496926

Epoch: 6| Step: 4
Training loss: 0.3342047929763794
Validation loss: 2.1920347611109414

Epoch: 6| Step: 5
Training loss: 0.42376458644866943
Validation loss: 2.099156081676483

Epoch: 6| Step: 6
Training loss: 0.31148678064346313
Validation loss: 2.1658878525098166

Epoch: 6| Step: 7
Training loss: 0.3908313512802124
Validation loss: 2.0962815284729004

Epoch: 6| Step: 8
Training loss: 0.45725300908088684
Validation loss: 2.150230964024862

Epoch: 6| Step: 9
Training loss: 0.4775255620479584
Validation loss: 2.159234801928202

Epoch: 6| Step: 10
Training loss: 0.7304214239120483
Validation loss: 2.1693853537241616

Epoch: 6| Step: 11
Training loss: 0.2667005658149719
Validation loss: 2.1889787515004477

Epoch: 6| Step: 12
Training loss: 0.9435074329376221
Validation loss: 2.2184724609057107

Epoch: 6| Step: 13
Training loss: 0.7672574520111084
Validation loss: 2.237850467363993

Epoch: 221| Step: 0
Training loss: 0.4919474124908447
Validation loss: 2.139137387275696

Epoch: 6| Step: 1
Training loss: 0.6347990036010742
Validation loss: 2.1012528340021768

Epoch: 6| Step: 2
Training loss: 0.3950922191143036
Validation loss: 2.1735448837280273

Epoch: 6| Step: 3
Training loss: 0.4454370141029358
Validation loss: 2.1702457070350647

Epoch: 6| Step: 4
Training loss: 0.3888967037200928
Validation loss: 2.1390625635782876

Epoch: 6| Step: 5
Training loss: 0.7040953040122986
Validation loss: 2.107444187005361

Epoch: 6| Step: 6
Training loss: 0.48840171098709106
Validation loss: 2.193447212378184

Epoch: 6| Step: 7
Training loss: 1.0959640741348267
Validation loss: 2.1766157746315002

Epoch: 6| Step: 8
Training loss: 0.5287786722183228
Validation loss: 2.185092051823934

Epoch: 6| Step: 9
Training loss: 0.7263453602790833
Validation loss: 2.1711465318997702

Epoch: 6| Step: 10
Training loss: 0.6195966005325317
Validation loss: 2.183601995309194

Epoch: 6| Step: 11
Training loss: 0.29577744007110596
Validation loss: 2.1419196724891663

Epoch: 6| Step: 12
Training loss: 0.3676629066467285
Validation loss: 2.1552069981892905

Epoch: 6| Step: 13
Training loss: 0.4994965195655823
Validation loss: 2.169286290804545

Epoch: 222| Step: 0
Training loss: 0.750694215297699
Validation loss: 2.1468931237856546

Epoch: 6| Step: 1
Training loss: 0.35582250356674194
Validation loss: 2.1554303566614785

Epoch: 6| Step: 2
Training loss: 0.6098098158836365
Validation loss: 2.1936903595924377

Epoch: 6| Step: 3
Training loss: 0.4824483096599579
Validation loss: 2.196422894795736

Epoch: 6| Step: 4
Training loss: 0.6358456611633301
Validation loss: 2.2953123251597085

Epoch: 6| Step: 5
Training loss: 0.9127180576324463
Validation loss: 2.248017450173696

Epoch: 6| Step: 6
Training loss: 0.6490659117698669
Validation loss: 2.162304083506266

Epoch: 6| Step: 7
Training loss: 0.4008253216743469
Validation loss: 2.189778765042623

Epoch: 6| Step: 8
Training loss: 0.42146509885787964
Validation loss: 2.1141574382781982

Epoch: 6| Step: 9
Training loss: 0.35401594638824463
Validation loss: 2.1635284225145974

Epoch: 6| Step: 10
Training loss: 0.495304673910141
Validation loss: 2.127362291018168

Epoch: 6| Step: 11
Training loss: 0.549075722694397
Validation loss: 2.1376163562138877

Epoch: 6| Step: 12
Training loss: 0.40417176485061646
Validation loss: 2.2181718945503235

Epoch: 6| Step: 13
Training loss: 0.7445240020751953
Validation loss: 2.1758665243784585

Epoch: 223| Step: 0
Training loss: 0.5905352234840393
Validation loss: 2.156908611456553

Epoch: 6| Step: 1
Training loss: 0.6165958046913147
Validation loss: 2.215828458468119

Epoch: 6| Step: 2
Training loss: 0.6266471147537231
Validation loss: 2.1339056491851807

Epoch: 6| Step: 3
Training loss: 0.44271522760391235
Validation loss: 2.1635606487592063

Epoch: 6| Step: 4
Training loss: 0.4535132050514221
Validation loss: 2.1730204820632935

Epoch: 6| Step: 5
Training loss: 0.32844969630241394
Validation loss: 2.181251605351766

Epoch: 6| Step: 6
Training loss: 0.5953325033187866
Validation loss: 2.2016940116882324

Epoch: 6| Step: 7
Training loss: 0.459831178188324
Validation loss: 2.1752956310908

Epoch: 6| Step: 8
Training loss: 0.4004991054534912
Validation loss: 2.153017004330953

Epoch: 6| Step: 9
Training loss: 0.524456262588501
Validation loss: 2.1646499832471213

Epoch: 6| Step: 10
Training loss: 0.349087655544281
Validation loss: 2.1605864763259888

Epoch: 6| Step: 11
Training loss: 0.5188431143760681
Validation loss: 2.2027927239735923

Epoch: 6| Step: 12
Training loss: 1.00898015499115
Validation loss: 2.216904958089193

Epoch: 6| Step: 13
Training loss: 0.5796865224838257
Validation loss: 2.1464869578679404

Epoch: 224| Step: 0
Training loss: 0.480081170797348
Validation loss: 2.2336073915163674

Epoch: 6| Step: 1
Training loss: 0.4653257727622986
Validation loss: 2.1493119597434998

Epoch: 6| Step: 2
Training loss: 0.5849080085754395
Validation loss: 2.1860846678415933

Epoch: 6| Step: 3
Training loss: 0.961588978767395
Validation loss: 2.1614815990130105

Epoch: 6| Step: 4
Training loss: 0.8608506917953491
Validation loss: 2.234372615814209

Epoch: 6| Step: 5
Training loss: 0.5989777445793152
Validation loss: 2.159253180027008

Epoch: 6| Step: 6
Training loss: 0.6357312202453613
Validation loss: 2.204882005850474

Epoch: 6| Step: 7
Training loss: 0.26571840047836304
Validation loss: 2.2285625537236533

Epoch: 6| Step: 8
Training loss: 0.4903722405433655
Validation loss: 2.2957723339398703

Epoch: 6| Step: 9
Training loss: 0.25156480073928833
Validation loss: 2.2190665205319724

Epoch: 6| Step: 10
Training loss: 0.5716718435287476
Validation loss: 2.2067625522613525

Epoch: 6| Step: 11
Training loss: 0.4410207271575928
Validation loss: 2.187302271525065

Epoch: 6| Step: 12
Training loss: 0.440939337015152
Validation loss: 2.183839738368988

Epoch: 6| Step: 13
Training loss: 0.45793676376342773
Validation loss: 2.1559332609176636

Epoch: 225| Step: 0
Training loss: 0.8758734464645386
Validation loss: 2.201346496740977

Epoch: 6| Step: 1
Training loss: 0.6715528964996338
Validation loss: 2.1375073194503784

Epoch: 6| Step: 2
Training loss: 0.8246224522590637
Validation loss: 2.198187291622162

Epoch: 6| Step: 3
Training loss: 0.6375405788421631
Validation loss: 2.1930070916811624

Epoch: 6| Step: 4
Training loss: 0.7880326509475708
Validation loss: 2.2207342783610025

Epoch: 6| Step: 5
Training loss: 0.2885017395019531
Validation loss: 2.192502796649933

Epoch: 6| Step: 6
Training loss: 0.38760197162628174
Validation loss: 2.141684095064799

Epoch: 6| Step: 7
Training loss: 0.33291247487068176
Validation loss: 2.2197328011194863

Epoch: 6| Step: 8
Training loss: 0.40080320835113525
Validation loss: 2.185760259628296

Epoch: 6| Step: 9
Training loss: 0.2412198781967163
Validation loss: 2.1610477765401206

Epoch: 6| Step: 10
Training loss: 0.18889808654785156
Validation loss: 2.1790415048599243

Epoch: 6| Step: 11
Training loss: 0.5078564286231995
Validation loss: 2.231816033522288

Epoch: 6| Step: 12
Training loss: 0.5578214526176453
Validation loss: 2.2301788330078125

Epoch: 6| Step: 13
Training loss: 0.49142128229141235
Validation loss: 2.1858957608540854

Epoch: 226| Step: 0
Training loss: 0.5349793434143066
Validation loss: 2.17378568649292

Epoch: 6| Step: 1
Training loss: 0.6732069849967957
Validation loss: 2.166028002897898

Epoch: 6| Step: 2
Training loss: 0.4990440011024475
Validation loss: 2.2077642679214478

Epoch: 6| Step: 3
Training loss: 0.37464088201522827
Validation loss: 2.2156898975372314

Epoch: 6| Step: 4
Training loss: 0.5185790061950684
Validation loss: 2.1774431268374124

Epoch: 6| Step: 5
Training loss: 0.46720248460769653
Validation loss: 2.2196250557899475

Epoch: 6| Step: 6
Training loss: 0.4361150562763214
Validation loss: 2.220586101214091

Epoch: 6| Step: 7
Training loss: 0.30328691005706787
Validation loss: 2.1416895985603333

Epoch: 6| Step: 8
Training loss: 1.0581958293914795
Validation loss: 2.1245280106862388

Epoch: 6| Step: 9
Training loss: 0.4125637710094452
Validation loss: 2.181858400503794

Epoch: 6| Step: 10
Training loss: 0.6777399778366089
Validation loss: 2.1314802765846252

Epoch: 6| Step: 11
Training loss: 0.7273954749107361
Validation loss: 2.162698666254679

Epoch: 6| Step: 12
Training loss: 0.5818334221839905
Validation loss: 2.206226090590159

Epoch: 6| Step: 13
Training loss: 0.7713484764099121
Validation loss: 2.17000279823939

Epoch: 227| Step: 0
Training loss: 0.5338329672813416
Validation loss: 2.2624720533688865

Epoch: 6| Step: 1
Training loss: 0.5442125797271729
Validation loss: 2.197572429974874

Epoch: 6| Step: 2
Training loss: 0.3556687831878662
Validation loss: 2.1956783731778464

Epoch: 6| Step: 3
Training loss: 0.3982032537460327
Validation loss: 2.1520747741063437

Epoch: 6| Step: 4
Training loss: 0.4890076518058777
Validation loss: 2.1681682467460632

Epoch: 6| Step: 5
Training loss: 0.6484554409980774
Validation loss: 2.15510622660319

Epoch: 6| Step: 6
Training loss: 0.8192497491836548
Validation loss: 2.282683491706848

Epoch: 6| Step: 7
Training loss: 0.649290919303894
Validation loss: 2.214016556739807

Epoch: 6| Step: 8
Training loss: 0.9804180860519409
Validation loss: 2.172000507513682

Epoch: 6| Step: 9
Training loss: 0.6409711837768555
Validation loss: 2.214948276678721

Epoch: 6| Step: 10
Training loss: 0.4321528375148773
Validation loss: 2.185125768184662

Epoch: 6| Step: 11
Training loss: 0.30954426527023315
Validation loss: 2.1797236601511636

Epoch: 6| Step: 12
Training loss: 0.7310779094696045
Validation loss: 2.1904965241750083

Epoch: 6| Step: 13
Training loss: 0.5191616415977478
Validation loss: 2.1704095800717673

Epoch: 228| Step: 0
Training loss: 0.5010559558868408
Validation loss: 2.2112965186436973

Epoch: 6| Step: 1
Training loss: 0.3993791341781616
Validation loss: 2.184981962045034

Epoch: 6| Step: 2
Training loss: 0.3754625618457794
Validation loss: 2.177873194217682

Epoch: 6| Step: 3
Training loss: 0.5046068429946899
Validation loss: 2.2148645718892417

Epoch: 6| Step: 4
Training loss: 0.539236843585968
Validation loss: 2.21940807501475

Epoch: 6| Step: 5
Training loss: 0.7336276769638062
Validation loss: 2.180978318055471

Epoch: 6| Step: 6
Training loss: 0.4647325575351715
Validation loss: 2.2245594461758933

Epoch: 6| Step: 7
Training loss: 0.6524963974952698
Validation loss: 2.19464647769928

Epoch: 6| Step: 8
Training loss: 0.5843925476074219
Validation loss: 2.165442963441213

Epoch: 6| Step: 9
Training loss: 0.44531598687171936
Validation loss: 2.1548528472582498

Epoch: 6| Step: 10
Training loss: 0.2690376043319702
Validation loss: 2.2028635144233704

Epoch: 6| Step: 11
Training loss: 0.5112425684928894
Validation loss: 2.185159146785736

Epoch: 6| Step: 12
Training loss: 0.9937312006950378
Validation loss: 2.2160812616348267

Epoch: 6| Step: 13
Training loss: 0.6623971462249756
Validation loss: 2.253491461277008

Epoch: 229| Step: 0
Training loss: 0.45695850253105164
Validation loss: 2.217714269955953

Epoch: 6| Step: 1
Training loss: 0.5236417651176453
Validation loss: 2.225457747777303

Epoch: 6| Step: 2
Training loss: 0.43644455075263977
Validation loss: 2.198357125123342

Epoch: 6| Step: 3
Training loss: 0.5587288737297058
Validation loss: 2.174609621365865

Epoch: 6| Step: 4
Training loss: 0.5677832365036011
Validation loss: 2.2265491088231406

Epoch: 6| Step: 5
Training loss: 0.29427215456962585
Validation loss: 2.1652469635009766

Epoch: 6| Step: 6
Training loss: 0.38092154264450073
Validation loss: 2.214633822441101

Epoch: 6| Step: 7
Training loss: 0.3276645541191101
Validation loss: 2.1659871538480124

Epoch: 6| Step: 8
Training loss: 0.29115408658981323
Validation loss: 2.202760100364685

Epoch: 6| Step: 9
Training loss: 0.6107177734375
Validation loss: 2.1604621609052024

Epoch: 6| Step: 10
Training loss: 0.5967912673950195
Validation loss: 2.1684695283571878

Epoch: 6| Step: 11
Training loss: 0.3929481506347656
Validation loss: 2.189167638619741

Epoch: 6| Step: 12
Training loss: 0.7437498569488525
Validation loss: 2.230941891670227

Epoch: 6| Step: 13
Training loss: 1.1982433795928955
Validation loss: 2.227358102798462

Epoch: 230| Step: 0
Training loss: 0.36507076025009155
Validation loss: 2.181106428305308

Epoch: 6| Step: 1
Training loss: 0.45923200249671936
Validation loss: 2.173258662223816

Epoch: 6| Step: 2
Training loss: 0.926034152507782
Validation loss: 2.194799025853475

Epoch: 6| Step: 3
Training loss: 0.43255361914634705
Validation loss: 2.2062689463297525

Epoch: 6| Step: 4
Training loss: 0.362565279006958
Validation loss: 2.252937833468119

Epoch: 6| Step: 5
Training loss: 0.2831801772117615
Validation loss: 2.2126210729281106

Epoch: 6| Step: 6
Training loss: 0.5978071093559265
Validation loss: 2.22484815120697

Epoch: 6| Step: 7
Training loss: 0.7427385449409485
Validation loss: 2.13231768210729

Epoch: 6| Step: 8
Training loss: 0.8304901719093323
Validation loss: 2.1373608907063804

Epoch: 6| Step: 9
Training loss: 0.407035768032074
Validation loss: 2.249195953210195

Epoch: 6| Step: 10
Training loss: 0.5163204073905945
Validation loss: 2.212510645389557

Epoch: 6| Step: 11
Training loss: 0.7237900495529175
Validation loss: 2.2236740986506143

Epoch: 6| Step: 12
Training loss: 0.521856963634491
Validation loss: 2.246954301993052

Epoch: 6| Step: 13
Training loss: 0.4897843599319458
Validation loss: 2.2599783341089883

Epoch: 231| Step: 0
Training loss: 0.4468422532081604
Validation loss: 2.236802597840627

Epoch: 6| Step: 1
Training loss: 0.2732761800289154
Validation loss: 2.1594438751538596

Epoch: 6| Step: 2
Training loss: 0.6928702592849731
Validation loss: 2.152074933052063

Epoch: 6| Step: 3
Training loss: 0.46975433826446533
Validation loss: 2.1651353240013123

Epoch: 6| Step: 4
Training loss: 0.7503394484519958
Validation loss: 2.150948087374369

Epoch: 6| Step: 5
Training loss: 0.4316236972808838
Validation loss: 2.1992753744125366

Epoch: 6| Step: 6
Training loss: 0.40218687057495117
Validation loss: 2.157192349433899

Epoch: 6| Step: 7
Training loss: 0.32429957389831543
Validation loss: 2.1829156478246055

Epoch: 6| Step: 8
Training loss: 0.5788360834121704
Validation loss: 2.1782127022743225

Epoch: 6| Step: 9
Training loss: 0.867280125617981
Validation loss: 2.217622995376587

Epoch: 6| Step: 10
Training loss: 0.7293165922164917
Validation loss: 2.1713019609451294

Epoch: 6| Step: 11
Training loss: 0.5307927131652832
Validation loss: 2.163319706916809

Epoch: 6| Step: 12
Training loss: 0.5572378635406494
Validation loss: 2.1877837777137756

Epoch: 6| Step: 13
Training loss: 0.4893030524253845
Validation loss: 2.1579524874687195

Epoch: 232| Step: 0
Training loss: 0.5888017416000366
Validation loss: 2.125408093134562

Epoch: 6| Step: 1
Training loss: 0.3959181606769562
Validation loss: 2.136585791905721

Epoch: 6| Step: 2
Training loss: 0.31412142515182495
Validation loss: 2.1548191706339517

Epoch: 6| Step: 3
Training loss: 0.5141116380691528
Validation loss: 2.2308965921401978

Epoch: 6| Step: 4
Training loss: 0.3601002097129822
Validation loss: 2.2039098938306174

Epoch: 6| Step: 5
Training loss: 0.29009827971458435
Validation loss: 2.199795663356781

Epoch: 6| Step: 6
Training loss: 0.5929888486862183
Validation loss: 2.1499820947647095

Epoch: 6| Step: 7
Training loss: 0.3669705390930176
Validation loss: 2.2410956422487893

Epoch: 6| Step: 8
Training loss: 0.6551244854927063
Validation loss: 2.1569818258285522

Epoch: 6| Step: 9
Training loss: 0.7497797012329102
Validation loss: 2.1691009600957236

Epoch: 6| Step: 10
Training loss: 0.6576293706893921
Validation loss: 2.2193886836369834

Epoch: 6| Step: 11
Training loss: 0.5373964905738831
Validation loss: 2.2560408115386963

Epoch: 6| Step: 12
Training loss: 0.7433185577392578
Validation loss: 2.25161478916804

Epoch: 6| Step: 13
Training loss: 0.45245301723480225
Validation loss: 2.2607710361480713

Epoch: 233| Step: 0
Training loss: 0.46844664216041565
Validation loss: 2.2230514685312905

Epoch: 6| Step: 1
Training loss: 1.171706199645996
Validation loss: 2.2114702463150024

Epoch: 6| Step: 2
Training loss: 0.7313520908355713
Validation loss: 2.1570896108945212

Epoch: 6| Step: 3
Training loss: 0.37206554412841797
Validation loss: 2.2147252559661865

Epoch: 6| Step: 4
Training loss: 0.49150770902633667
Validation loss: 2.177202582359314

Epoch: 6| Step: 5
Training loss: 0.3208284378051758
Validation loss: 2.19808163245519

Epoch: 6| Step: 6
Training loss: 0.2960910499095917
Validation loss: 2.187188227971395

Epoch: 6| Step: 7
Training loss: 0.5168031454086304
Validation loss: 2.249874254067739

Epoch: 6| Step: 8
Training loss: 0.41511714458465576
Validation loss: 2.200192073980967

Epoch: 6| Step: 9
Training loss: 0.6854376196861267
Validation loss: 2.1750811338424683

Epoch: 6| Step: 10
Training loss: 0.37671637535095215
Validation loss: 2.160029888153076

Epoch: 6| Step: 11
Training loss: 0.4237805902957916
Validation loss: 2.149069050947825

Epoch: 6| Step: 12
Training loss: 0.38343799114227295
Validation loss: 2.1788575649261475

Epoch: 6| Step: 13
Training loss: 0.6600526571273804
Validation loss: 2.155446449915568

Epoch: 234| Step: 0
Training loss: 0.28709569573402405
Validation loss: 2.1872206926345825

Epoch: 6| Step: 1
Training loss: 0.31906986236572266
Validation loss: 2.2253846724828086

Epoch: 6| Step: 2
Training loss: 0.4496304392814636
Validation loss: 2.2315178712209067

Epoch: 6| Step: 3
Training loss: 0.7807793021202087
Validation loss: 2.229700187842051

Epoch: 6| Step: 4
Training loss: 0.5741659998893738
Validation loss: 2.267302095890045

Epoch: 6| Step: 5
Training loss: 0.6256360411643982
Validation loss: 2.2305895487467446

Epoch: 6| Step: 6
Training loss: 0.4893321096897125
Validation loss: 2.2059648036956787

Epoch: 6| Step: 7
Training loss: 0.29001498222351074
Validation loss: 2.1149378418922424

Epoch: 6| Step: 8
Training loss: 0.601794958114624
Validation loss: 2.1803593238194785

Epoch: 6| Step: 9
Training loss: 0.629956841468811
Validation loss: 2.093982378641764

Epoch: 6| Step: 10
Training loss: 0.7399890422821045
Validation loss: 2.1853652199109397

Epoch: 6| Step: 11
Training loss: 0.5210350751876831
Validation loss: 2.190580586592356

Epoch: 6| Step: 12
Training loss: 0.3157392144203186
Validation loss: 2.1984309554100037

Epoch: 6| Step: 13
Training loss: 0.6579741835594177
Validation loss: 2.2469309369723

Epoch: 235| Step: 0
Training loss: 0.6600782871246338
Validation loss: 2.212062974770864

Epoch: 6| Step: 1
Training loss: 0.27500495314598083
Validation loss: 2.180958608786265

Epoch: 6| Step: 2
Training loss: 0.26080551743507385
Validation loss: 2.1848977406819663

Epoch: 6| Step: 3
Training loss: 0.6181643009185791
Validation loss: 2.1697889963785806

Epoch: 6| Step: 4
Training loss: 0.3514955937862396
Validation loss: 2.22649351755778

Epoch: 6| Step: 5
Training loss: 0.42700356245040894
Validation loss: 2.143794278303782

Epoch: 6| Step: 6
Training loss: 0.41393595933914185
Validation loss: 2.176528255144755

Epoch: 6| Step: 7
Training loss: 0.5040794610977173
Validation loss: 2.151016672452291

Epoch: 6| Step: 8
Training loss: 0.8887940645217896
Validation loss: 2.1899022658665976

Epoch: 6| Step: 9
Training loss: 0.4234639108181
Validation loss: 2.225713392098745

Epoch: 6| Step: 10
Training loss: 0.15276502072811127
Validation loss: 2.1159435510635376

Epoch: 6| Step: 11
Training loss: 0.6761757731437683
Validation loss: 2.21978090206782

Epoch: 6| Step: 12
Training loss: 0.5803412199020386
Validation loss: 2.1969738205273948

Epoch: 6| Step: 13
Training loss: 0.5005317330360413
Validation loss: 2.1988274455070496

Epoch: 236| Step: 0
Training loss: 0.8474639058113098
Validation loss: 2.1612725257873535

Epoch: 6| Step: 1
Training loss: 0.4195498824119568
Validation loss: 2.1997883121172586

Epoch: 6| Step: 2
Training loss: 0.527923583984375
Validation loss: 2.170206844806671

Epoch: 6| Step: 3
Training loss: 0.5562898516654968
Validation loss: 2.2033177415529885

Epoch: 6| Step: 4
Training loss: 0.840030312538147
Validation loss: 2.192728042602539

Epoch: 6| Step: 5
Training loss: 0.2954297363758087
Validation loss: 2.2151116530100503

Epoch: 6| Step: 6
Training loss: 0.397842139005661
Validation loss: 2.2112968365351358

Epoch: 6| Step: 7
Training loss: 0.25782260298728943
Validation loss: 2.2715990940729776

Epoch: 6| Step: 8
Training loss: 0.6950953602790833
Validation loss: 2.2033642530441284

Epoch: 6| Step: 9
Training loss: 0.37775367498397827
Validation loss: 2.2233092983563743

Epoch: 6| Step: 10
Training loss: 0.5041980147361755
Validation loss: 2.2235156695048013

Epoch: 6| Step: 11
Training loss: 0.4364045262336731
Validation loss: 2.233300507068634

Epoch: 6| Step: 12
Training loss: 0.3902907371520996
Validation loss: 2.1618338028589883

Epoch: 6| Step: 13
Training loss: 0.326715350151062
Validation loss: 2.1797539989153543

Epoch: 237| Step: 0
Training loss: 0.3899678587913513
Validation loss: 2.1799679001172385

Epoch: 6| Step: 1
Training loss: 0.550742506980896
Validation loss: 2.1613452434539795

Epoch: 6| Step: 2
Training loss: 0.39920181035995483
Validation loss: 2.1998252471288047

Epoch: 6| Step: 3
Training loss: 0.7365465760231018
Validation loss: 2.235668977101644

Epoch: 6| Step: 4
Training loss: 0.45222008228302
Validation loss: 2.1790934602419534

Epoch: 6| Step: 5
Training loss: 0.432977557182312
Validation loss: 2.1845940947532654

Epoch: 6| Step: 6
Training loss: 0.5096438527107239
Validation loss: 2.1835087140401206

Epoch: 6| Step: 7
Training loss: 0.35635465383529663
Validation loss: 2.2151601711908975

Epoch: 6| Step: 8
Training loss: 0.7283535003662109
Validation loss: 2.1944047609965005

Epoch: 6| Step: 9
Training loss: 0.4663051962852478
Validation loss: 2.1429942647616067

Epoch: 6| Step: 10
Training loss: 0.7193542122840881
Validation loss: 2.2112430334091187

Epoch: 6| Step: 11
Training loss: 0.3231021761894226
Validation loss: 2.184210558732351

Epoch: 6| Step: 12
Training loss: 0.5471936464309692
Validation loss: 2.2085768779118857

Epoch: 6| Step: 13
Training loss: 0.30304616689682007
Validation loss: 2.1788494984308877

Epoch: 238| Step: 0
Training loss: 0.40315771102905273
Validation loss: 2.2333784898122153

Epoch: 6| Step: 1
Training loss: 0.735771119594574
Validation loss: 2.235504984855652

Epoch: 6| Step: 2
Training loss: 0.87937331199646
Validation loss: 2.182894011338552

Epoch: 6| Step: 3
Training loss: 0.40674468874931335
Validation loss: 2.1333813269933066

Epoch: 6| Step: 4
Training loss: 0.5536279678344727
Validation loss: 2.165130396684011

Epoch: 6| Step: 5
Training loss: 0.45469534397125244
Validation loss: 2.1383846402168274

Epoch: 6| Step: 6
Training loss: 0.4895450472831726
Validation loss: 2.13150155544281

Epoch: 6| Step: 7
Training loss: 0.8136425614356995
Validation loss: 2.137985368569692

Epoch: 6| Step: 8
Training loss: 0.5126746892929077
Validation loss: 2.1764582792917886

Epoch: 6| Step: 9
Training loss: 0.8339142799377441
Validation loss: 2.2878073851267495

Epoch: 6| Step: 10
Training loss: 0.5117020606994629
Validation loss: 2.2998100121816

Epoch: 6| Step: 11
Training loss: 0.24439477920532227
Validation loss: 2.190321147441864

Epoch: 6| Step: 12
Training loss: 0.43228238821029663
Validation loss: 2.172697365283966

Epoch: 6| Step: 13
Training loss: 0.588909387588501
Validation loss: 2.1305165886878967

Epoch: 239| Step: 0
Training loss: 0.3883461356163025
Validation loss: 2.1715579827626548

Epoch: 6| Step: 1
Training loss: 0.44326475262641907
Validation loss: 2.1945927937825522

Epoch: 6| Step: 2
Training loss: 0.6379250884056091
Validation loss: 2.1480767726898193

Epoch: 6| Step: 3
Training loss: 0.35040953755378723
Validation loss: 2.1839080254236856

Epoch: 6| Step: 4
Training loss: 0.4784501791000366
Validation loss: 2.213163197040558

Epoch: 6| Step: 5
Training loss: 0.9299452304840088
Validation loss: 2.309254288673401

Epoch: 6| Step: 6
Training loss: 0.4785429835319519
Validation loss: 2.254692852497101

Epoch: 6| Step: 7
Training loss: 0.46550559997558594
Validation loss: 2.238483985265096

Epoch: 6| Step: 8
Training loss: 0.36876749992370605
Validation loss: 2.1358575224876404

Epoch: 6| Step: 9
Training loss: 0.6373966932296753
Validation loss: 2.160768508911133

Epoch: 6| Step: 10
Training loss: 0.6406978964805603
Validation loss: 2.2034319043159485

Epoch: 6| Step: 11
Training loss: 0.6053484082221985
Validation loss: 2.109773854414622

Epoch: 6| Step: 12
Training loss: 0.31260597705841064
Validation loss: 2.188094993432363

Epoch: 6| Step: 13
Training loss: 0.6974866390228271
Validation loss: 2.214870353539785

Epoch: 240| Step: 0
Training loss: 0.6161256432533264
Validation loss: 2.2300510009129844

Epoch: 6| Step: 1
Training loss: 0.5038061141967773
Validation loss: 2.223633646965027

Epoch: 6| Step: 2
Training loss: 0.4334997236728668
Validation loss: 2.149398922920227

Epoch: 6| Step: 3
Training loss: 0.4923577606678009
Validation loss: 2.1849238673845925

Epoch: 6| Step: 4
Training loss: 0.34837475419044495
Validation loss: 2.1355408231417337

Epoch: 6| Step: 5
Training loss: 0.667447030544281
Validation loss: 2.147124091784159

Epoch: 6| Step: 6
Training loss: 0.3323727250099182
Validation loss: 2.148169298966726

Epoch: 6| Step: 7
Training loss: 0.40624040365219116
Validation loss: 2.1888293425242105

Epoch: 6| Step: 8
Training loss: 0.5030749440193176
Validation loss: 2.1902660926183066

Epoch: 6| Step: 9
Training loss: 0.573993444442749
Validation loss: 2.2031208078066506

Epoch: 6| Step: 10
Training loss: 0.8585882186889648
Validation loss: 2.2210686008135476

Epoch: 6| Step: 11
Training loss: 0.42651504278182983
Validation loss: 2.196391483147939

Epoch: 6| Step: 12
Training loss: 0.4863106608390808
Validation loss: 2.161617875099182

Epoch: 6| Step: 13
Training loss: 0.6307103037834167
Validation loss: 2.129258175690969

Epoch: 241| Step: 0
Training loss: 0.6057302951812744
Validation loss: 2.142307758331299

Epoch: 6| Step: 1
Training loss: 0.31891393661499023
Validation loss: 2.181763490041097

Epoch: 6| Step: 2
Training loss: 0.784072756767273
Validation loss: 2.110934019088745

Epoch: 6| Step: 3
Training loss: 0.2811683416366577
Validation loss: 2.1886073549588523

Epoch: 6| Step: 4
Training loss: 0.4797734022140503
Validation loss: 2.2490161657333374

Epoch: 6| Step: 5
Training loss: 0.5429246425628662
Validation loss: 2.200399955113729

Epoch: 6| Step: 6
Training loss: 0.4088890552520752
Validation loss: 2.1794240872065225

Epoch: 6| Step: 7
Training loss: 0.38337764143943787
Validation loss: 2.210064967473348

Epoch: 6| Step: 8
Training loss: 0.5746541023254395
Validation loss: 2.175082008043925

Epoch: 6| Step: 9
Training loss: 0.2590692639350891
Validation loss: 2.184017856915792

Epoch: 6| Step: 10
Training loss: 1.0012571811676025
Validation loss: 2.171112855275472

Epoch: 6| Step: 11
Training loss: 0.55108642578125
Validation loss: 2.1157317558924356

Epoch: 6| Step: 12
Training loss: 0.5844057202339172
Validation loss: 2.192787686983744

Epoch: 6| Step: 13
Training loss: 0.33349135518074036
Validation loss: 2.1818872690200806

Epoch: 242| Step: 0
Training loss: 0.29211515188217163
Validation loss: 2.212714513142904

Epoch: 6| Step: 1
Training loss: 0.32930853962898254
Validation loss: 2.2101370890935264

Epoch: 6| Step: 2
Training loss: 0.7173488140106201
Validation loss: 2.1542760332425437

Epoch: 6| Step: 3
Training loss: 0.6046403050422668
Validation loss: 2.188559373219808

Epoch: 6| Step: 4
Training loss: 0.5963315963745117
Validation loss: 2.2621236443519592

Epoch: 6| Step: 5
Training loss: 0.22461307048797607
Validation loss: 2.2147857546806335

Epoch: 6| Step: 6
Training loss: 0.6912410259246826
Validation loss: 2.1760387818018594

Epoch: 6| Step: 7
Training loss: 0.3908316195011139
Validation loss: 2.122204303741455

Epoch: 6| Step: 8
Training loss: 0.6325872540473938
Validation loss: 2.1448792020479837

Epoch: 6| Step: 9
Training loss: 0.7001161575317383
Validation loss: 2.1669952472050986

Epoch: 6| Step: 10
Training loss: 0.39027974009513855
Validation loss: 2.1541547775268555

Epoch: 6| Step: 11
Training loss: 0.5512399077415466
Validation loss: 2.1404027541478476

Epoch: 6| Step: 12
Training loss: 0.3195047378540039
Validation loss: 2.1834592819213867

Epoch: 6| Step: 13
Training loss: 0.5720734000205994
Validation loss: 2.166097640991211

Epoch: 243| Step: 0
Training loss: 0.43535923957824707
Validation loss: 2.204318185647329

Epoch: 6| Step: 1
Training loss: 0.24886736273765564
Validation loss: 2.1828808784484863

Epoch: 6| Step: 2
Training loss: 0.7778447866439819
Validation loss: 2.1564422249794006

Epoch: 6| Step: 3
Training loss: 0.2042841613292694
Validation loss: 2.1348173220952353

Epoch: 6| Step: 4
Training loss: 0.3858247697353363
Validation loss: 2.167252480983734

Epoch: 6| Step: 5
Training loss: 0.6163918972015381
Validation loss: 2.1906045277913413

Epoch: 6| Step: 6
Training loss: 0.5133090019226074
Validation loss: 2.1917872627576194

Epoch: 6| Step: 7
Training loss: 0.5596556663513184
Validation loss: 2.166184365749359

Epoch: 6| Step: 8
Training loss: 0.7010116577148438
Validation loss: 2.201276878515879

Epoch: 6| Step: 9
Training loss: 0.7663531303405762
Validation loss: 2.163269023100535

Epoch: 6| Step: 10
Training loss: 0.434140682220459
Validation loss: 2.148251791795095

Epoch: 6| Step: 11
Training loss: 0.23255714774131775
Validation loss: 2.185143073399862

Epoch: 6| Step: 12
Training loss: 0.47370874881744385
Validation loss: 2.1874775687853494

Epoch: 6| Step: 13
Training loss: 0.49910154938697815
Validation loss: 2.1285463770230613

Epoch: 244| Step: 0
Training loss: 0.7656606435775757
Validation loss: 2.1958643595377603

Epoch: 6| Step: 1
Training loss: 0.5695699453353882
Validation loss: 2.206363578637441

Epoch: 6| Step: 2
Training loss: 0.2542082965373993
Validation loss: 2.2138808965682983

Epoch: 6| Step: 3
Training loss: 0.4237786531448364
Validation loss: 2.220887045065562

Epoch: 6| Step: 4
Training loss: 0.7646766901016235
Validation loss: 2.187635143597921

Epoch: 6| Step: 5
Training loss: 0.5045492649078369
Validation loss: 2.152125517527262

Epoch: 6| Step: 6
Training loss: 0.4510812759399414
Validation loss: 2.197872579097748

Epoch: 6| Step: 7
Training loss: 0.9463123083114624
Validation loss: 2.156806727250417

Epoch: 6| Step: 8
Training loss: 0.5248323082923889
Validation loss: 2.1539549231529236

Epoch: 6| Step: 9
Training loss: 0.393616646528244
Validation loss: 2.1822029749552407

Epoch: 6| Step: 10
Training loss: 0.6103302240371704
Validation loss: 2.2441360354423523

Epoch: 6| Step: 11
Training loss: 0.4698605239391327
Validation loss: 2.2936124006907144

Epoch: 6| Step: 12
Training loss: 0.6124745011329651
Validation loss: 2.263072689374288

Epoch: 6| Step: 13
Training loss: 0.6495580673217773
Validation loss: 2.259248157342275

Epoch: 245| Step: 0
Training loss: 0.9841107130050659
Validation loss: 2.2099022467931113

Epoch: 6| Step: 1
Training loss: 0.3977959454059601
Validation loss: 2.1594704190889993

Epoch: 6| Step: 2
Training loss: 0.5369660258293152
Validation loss: 2.167974869410197

Epoch: 6| Step: 3
Training loss: 0.4808647036552429
Validation loss: 2.1259641647338867

Epoch: 6| Step: 4
Training loss: 0.5951033234596252
Validation loss: 2.1714618603388467

Epoch: 6| Step: 5
Training loss: 0.37888506054878235
Validation loss: 2.14064089457194

Epoch: 6| Step: 6
Training loss: 0.2089501917362213
Validation loss: 2.16852339108785

Epoch: 6| Step: 7
Training loss: 0.37373146414756775
Validation loss: 2.1679160992304483

Epoch: 6| Step: 8
Training loss: 0.6043561100959778
Validation loss: 2.1821303367614746

Epoch: 6| Step: 9
Training loss: 0.2679760456085205
Validation loss: 2.2016504605611167

Epoch: 6| Step: 10
Training loss: 0.3230881690979004
Validation loss: 2.226488490899404

Epoch: 6| Step: 11
Training loss: 0.5193966627120972
Validation loss: 2.264070471127828

Epoch: 6| Step: 12
Training loss: 0.7760393619537354
Validation loss: 2.215689778327942

Epoch: 6| Step: 13
Training loss: 0.5447009801864624
Validation loss: 2.1502288579940796

Epoch: 246| Step: 0
Training loss: 0.39531397819519043
Validation loss: 2.146975338459015

Epoch: 6| Step: 1
Training loss: 0.2974432110786438
Validation loss: 2.112803339958191

Epoch: 6| Step: 2
Training loss: 0.5911679267883301
Validation loss: 2.1860095461209617

Epoch: 6| Step: 3
Training loss: 0.36909186840057373
Validation loss: 2.111509601275126

Epoch: 6| Step: 4
Training loss: 0.6487748026847839
Validation loss: 2.187406341234843

Epoch: 6| Step: 5
Training loss: 0.6663120985031128
Validation loss: 2.173827290534973

Epoch: 6| Step: 6
Training loss: 0.8137284517288208
Validation loss: 2.1927642027537027

Epoch: 6| Step: 7
Training loss: 0.4381522536277771
Validation loss: 2.269523541132609

Epoch: 6| Step: 8
Training loss: 0.6449181437492371
Validation loss: 2.2087395985921225

Epoch: 6| Step: 9
Training loss: 0.3551035523414612
Validation loss: 2.197903275489807

Epoch: 6| Step: 10
Training loss: 0.25742971897125244
Validation loss: 2.1763999462127686

Epoch: 6| Step: 11
Training loss: 0.6153264045715332
Validation loss: 2.1421703497568765

Epoch: 6| Step: 12
Training loss: 0.46915745735168457
Validation loss: 2.1502399245897927

Epoch: 6| Step: 13
Training loss: 0.4824202060699463
Validation loss: 2.185215334097544

Epoch: 247| Step: 0
Training loss: 0.32747459411621094
Validation loss: 2.154242515563965

Epoch: 6| Step: 1
Training loss: 0.6892454028129578
Validation loss: 2.2019015351931253

Epoch: 6| Step: 2
Training loss: 0.6883962154388428
Validation loss: 2.2392456928888955

Epoch: 6| Step: 3
Training loss: 0.46093839406967163
Validation loss: 2.2872064113616943

Epoch: 6| Step: 4
Training loss: 0.3692770302295685
Validation loss: 2.180074771245321

Epoch: 6| Step: 5
Training loss: 0.17618894577026367
Validation loss: 2.2011652986208596

Epoch: 6| Step: 6
Training loss: 0.5876342058181763
Validation loss: 2.2571279207865396

Epoch: 6| Step: 7
Training loss: 0.33631816506385803
Validation loss: 2.209597726662954

Epoch: 6| Step: 8
Training loss: 0.6294809579849243
Validation loss: 2.1569430828094482

Epoch: 6| Step: 9
Training loss: 0.9911803007125854
Validation loss: 2.150506913661957

Epoch: 6| Step: 10
Training loss: 0.2636718451976776
Validation loss: 2.231491486231486

Epoch: 6| Step: 11
Training loss: 0.4026513993740082
Validation loss: 2.254240949948629

Epoch: 6| Step: 12
Training loss: 0.4689026176929474
Validation loss: 2.2716325918833413

Epoch: 6| Step: 13
Training loss: 0.33361437916755676
Validation loss: 2.2386314868927

Epoch: 248| Step: 0
Training loss: 0.5486000776290894
Validation loss: 2.138082285722097

Epoch: 6| Step: 1
Training loss: 0.18951931595802307
Validation loss: 2.152428130308787

Epoch: 6| Step: 2
Training loss: 0.2980440855026245
Validation loss: 2.1619611978530884

Epoch: 6| Step: 3
Training loss: 0.6091855764389038
Validation loss: 2.2215224504470825

Epoch: 6| Step: 4
Training loss: 0.6481991410255432
Validation loss: 2.2105401158332825

Epoch: 6| Step: 5
Training loss: 0.3057519793510437
Validation loss: 2.2133354544639587

Epoch: 6| Step: 6
Training loss: 0.3075818419456482
Validation loss: 2.1940666834513345

Epoch: 6| Step: 7
Training loss: 0.471259206533432
Validation loss: 2.195582906405131

Epoch: 6| Step: 8
Training loss: 0.2204425036907196
Validation loss: 2.2129077514012656

Epoch: 6| Step: 9
Training loss: 0.6619274616241455
Validation loss: 2.1710500717163086

Epoch: 6| Step: 10
Training loss: 0.5978939533233643
Validation loss: 2.2235647638638816

Epoch: 6| Step: 11
Training loss: 0.3383406102657318
Validation loss: 2.1808443665504456

Epoch: 6| Step: 12
Training loss: 0.3714001774787903
Validation loss: 2.2075434923171997

Epoch: 6| Step: 13
Training loss: 0.515945315361023
Validation loss: 2.2198990186055503

Epoch: 249| Step: 0
Training loss: 0.4526723325252533
Validation loss: 2.204875429471334

Epoch: 6| Step: 1
Training loss: 0.3153653144836426
Validation loss: 2.183382968107859

Epoch: 6| Step: 2
Training loss: 0.1668490767478943
Validation loss: 2.1846370697021484

Epoch: 6| Step: 3
Training loss: 0.583023190498352
Validation loss: 2.2083866198857627

Epoch: 6| Step: 4
Training loss: 0.4533001780509949
Validation loss: 2.171694278717041

Epoch: 6| Step: 5
Training loss: 0.3231302499771118
Validation loss: 2.2024291157722473

Epoch: 6| Step: 6
Training loss: 0.42356738448143005
Validation loss: 2.255893886089325

Epoch: 6| Step: 7
Training loss: 0.30480509996414185
Validation loss: 2.220703919728597

Epoch: 6| Step: 8
Training loss: 0.47236958146095276
Validation loss: 2.1915581027666726

Epoch: 6| Step: 9
Training loss: 0.34291696548461914
Validation loss: 2.1960182189941406

Epoch: 6| Step: 10
Training loss: 0.6907846331596375
Validation loss: 2.164175490538279

Epoch: 6| Step: 11
Training loss: 0.49285435676574707
Validation loss: 2.233772118886312

Epoch: 6| Step: 12
Training loss: 0.6209489107131958
Validation loss: 2.162199596563975

Epoch: 6| Step: 13
Training loss: 1.0079808235168457
Validation loss: 2.214482367038727

Epoch: 250| Step: 0
Training loss: 0.32024648785591125
Validation loss: 2.2149481177330017

Epoch: 6| Step: 1
Training loss: 0.36360403895378113
Validation loss: 2.2026902635892234

Epoch: 6| Step: 2
Training loss: 0.43190798163414
Validation loss: 2.2334750096003213

Epoch: 6| Step: 3
Training loss: 0.6270619630813599
Validation loss: 2.2133169174194336

Epoch: 6| Step: 4
Training loss: 0.3798246383666992
Validation loss: 2.1571362813313804

Epoch: 6| Step: 5
Training loss: 0.4670397639274597
Validation loss: 2.1692506869633994

Epoch: 6| Step: 6
Training loss: 0.5919560790061951
Validation loss: 2.2035065293312073

Epoch: 6| Step: 7
Training loss: 0.37020766735076904
Validation loss: 2.206153233846029

Epoch: 6| Step: 8
Training loss: 0.3665214776992798
Validation loss: 2.2200936675071716

Epoch: 6| Step: 9
Training loss: 0.30925849080085754
Validation loss: 2.200258215268453

Epoch: 6| Step: 10
Training loss: 0.38315045833587646
Validation loss: 2.1869375507036843

Epoch: 6| Step: 11
Training loss: 0.5558122396469116
Validation loss: 2.158180296421051

Epoch: 6| Step: 12
Training loss: 0.35937774181365967
Validation loss: 2.121978481610616

Epoch: 6| Step: 13
Training loss: 1.0400235652923584
Validation loss: 2.1701059142748513

Epoch: 251| Step: 0
Training loss: 0.7972387075424194
Validation loss: 2.204224109649658

Epoch: 6| Step: 1
Training loss: 0.2623746991157532
Validation loss: 2.215956767400106

Epoch: 6| Step: 2
Training loss: 0.32845157384872437
Validation loss: 2.2053380409876504

Epoch: 6| Step: 3
Training loss: 0.3666175305843353
Validation loss: 2.220287243525187

Epoch: 6| Step: 4
Training loss: 0.40863287448883057
Validation loss: 2.1951993902524314

Epoch: 6| Step: 5
Training loss: 0.4959508180618286
Validation loss: 2.2481406331062317

Epoch: 6| Step: 6
Training loss: 0.24575328826904297
Validation loss: 2.180416921774546

Epoch: 6| Step: 7
Training loss: 0.8207937479019165
Validation loss: 2.156488517920176

Epoch: 6| Step: 8
Training loss: 0.4143848717212677
Validation loss: 2.1843579014142356

Epoch: 6| Step: 9
Training loss: 0.36104804277420044
Validation loss: 2.1653714776039124

Epoch: 6| Step: 10
Training loss: 0.6808532476425171
Validation loss: 2.2075686852137246

Epoch: 6| Step: 11
Training loss: 0.30947867035865784
Validation loss: 2.22081991036733

Epoch: 6| Step: 12
Training loss: 0.39808812737464905
Validation loss: 2.257916569709778

Epoch: 6| Step: 13
Training loss: 0.8295750021934509
Validation loss: 2.2406795024871826

Epoch: 252| Step: 0
Training loss: 0.4553285539150238
Validation loss: 2.17940624554952

Epoch: 6| Step: 1
Training loss: 0.5564188957214355
Validation loss: 2.1984223326047263

Epoch: 6| Step: 2
Training loss: 0.6960484385490417
Validation loss: 2.1451122562090554

Epoch: 6| Step: 3
Training loss: 0.7960191965103149
Validation loss: 2.2252540389696756

Epoch: 6| Step: 4
Training loss: 0.6379081606864929
Validation loss: 2.1549643079439798

Epoch: 6| Step: 5
Training loss: 0.4266214072704315
Validation loss: 2.178307672341665

Epoch: 6| Step: 6
Training loss: 0.5037774443626404
Validation loss: 2.221675217151642

Epoch: 6| Step: 7
Training loss: 0.4235392212867737
Validation loss: 2.271698077519735

Epoch: 6| Step: 8
Training loss: 0.2794952392578125
Validation loss: 2.2224372227986655

Epoch: 6| Step: 9
Training loss: 0.540736734867096
Validation loss: 2.2618929545084634

Epoch: 6| Step: 10
Training loss: 0.228565976023674
Validation loss: 2.21857488155365

Epoch: 6| Step: 11
Training loss: 0.6970292329788208
Validation loss: 2.168093502521515

Epoch: 6| Step: 12
Training loss: 0.44262439012527466
Validation loss: 2.2522875666618347

Epoch: 6| Step: 13
Training loss: 0.25157344341278076
Validation loss: 2.1648840506871543

Epoch: 253| Step: 0
Training loss: 0.6892188787460327
Validation loss: 2.2279624938964844

Epoch: 6| Step: 1
Training loss: 0.526140034198761
Validation loss: 2.2346348762512207

Epoch: 6| Step: 2
Training loss: 0.27938857674598694
Validation loss: 2.241664191087087

Epoch: 6| Step: 3
Training loss: 0.6861228942871094
Validation loss: 2.2399810751279197

Epoch: 6| Step: 4
Training loss: 0.4520227909088135
Validation loss: 2.230721135934194

Epoch: 6| Step: 5
Training loss: 0.33475884795188904
Validation loss: 2.177849769592285

Epoch: 6| Step: 6
Training loss: 0.3130483329296112
Validation loss: 2.1440422534942627

Epoch: 6| Step: 7
Training loss: 0.31401166319847107
Validation loss: 2.1992359161376953

Epoch: 6| Step: 8
Training loss: 0.46275246143341064
Validation loss: 2.148033400376638

Epoch: 6| Step: 9
Training loss: 0.7328649759292603
Validation loss: 2.1540736754735312

Epoch: 6| Step: 10
Training loss: 0.22791674733161926
Validation loss: 2.2121894359588623

Epoch: 6| Step: 11
Training loss: 0.4965395927429199
Validation loss: 2.2388821045557656

Epoch: 6| Step: 12
Training loss: 0.5169483423233032
Validation loss: 2.207450052102407

Epoch: 6| Step: 13
Training loss: 0.7408064603805542
Validation loss: 2.195917805035909

Epoch: 254| Step: 0
Training loss: 0.2776392102241516
Validation loss: 2.2042717337608337

Epoch: 6| Step: 1
Training loss: 0.4218165874481201
Validation loss: 2.1847617626190186

Epoch: 6| Step: 2
Training loss: 0.7222198247909546
Validation loss: 2.2097374200820923

Epoch: 6| Step: 3
Training loss: 0.41276535391807556
Validation loss: 2.191140294075012

Epoch: 6| Step: 4
Training loss: 0.2745588421821594
Validation loss: 2.143640418847402

Epoch: 6| Step: 5
Training loss: 0.4646247923374176
Validation loss: 2.211317300796509

Epoch: 6| Step: 6
Training loss: 0.3892024755477905
Validation loss: 2.1481715639432273

Epoch: 6| Step: 7
Training loss: 0.4553395211696625
Validation loss: 2.2333946228027344

Epoch: 6| Step: 8
Training loss: 0.4285893440246582
Validation loss: 2.1450380285580954

Epoch: 6| Step: 9
Training loss: 0.48995858430862427
Validation loss: 2.1514323949813843

Epoch: 6| Step: 10
Training loss: 0.3768414258956909
Validation loss: 2.223532815774282

Epoch: 6| Step: 11
Training loss: 0.8802551031112671
Validation loss: 2.193031152089437

Epoch: 6| Step: 12
Training loss: 0.5284761786460876
Validation loss: 2.216304083665212

Epoch: 6| Step: 13
Training loss: 0.5092940330505371
Validation loss: 2.156739870707194

Epoch: 255| Step: 0
Training loss: 0.8784599900245667
Validation loss: 2.1813295682271323

Epoch: 6| Step: 1
Training loss: 0.3975929617881775
Validation loss: 2.19743017355601

Epoch: 6| Step: 2
Training loss: 0.3842148184776306
Validation loss: 2.1584176818529763

Epoch: 6| Step: 3
Training loss: 0.472981721162796
Validation loss: 2.181173006693522

Epoch: 6| Step: 4
Training loss: 0.5242952704429626
Validation loss: 2.2116132577260337

Epoch: 6| Step: 5
Training loss: 0.33438608050346375
Validation loss: 2.2415691614151

Epoch: 6| Step: 6
Training loss: 0.5330309271812439
Validation loss: 2.176211734612783

Epoch: 6| Step: 7
Training loss: 0.4928380846977234
Validation loss: 2.1965011954307556

Epoch: 6| Step: 8
Training loss: 0.5107121467590332
Validation loss: 2.1411378184954324

Epoch: 6| Step: 9
Training loss: 0.45681434869766235
Validation loss: 2.17567370335261

Epoch: 6| Step: 10
Training loss: 0.7413325309753418
Validation loss: 2.1818193197250366

Epoch: 6| Step: 11
Training loss: 0.22362163662910461
Validation loss: 2.1463948090871177

Epoch: 6| Step: 12
Training loss: 0.5230630040168762
Validation loss: 2.219898502031962

Epoch: 6| Step: 13
Training loss: 0.4308062493801117
Validation loss: 2.1896128058433533

Epoch: 256| Step: 0
Training loss: 0.4721991717815399
Validation loss: 2.1592461665471396

Epoch: 6| Step: 1
Training loss: 0.5400503873825073
Validation loss: 2.1708840330441794

Epoch: 6| Step: 2
Training loss: 0.44697797298431396
Validation loss: 2.1342270771662393

Epoch: 6| Step: 3
Training loss: 0.6096450686454773
Validation loss: 2.1738821466763816

Epoch: 6| Step: 4
Training loss: 0.482473760843277
Validation loss: 2.119211177031199

Epoch: 6| Step: 5
Training loss: 0.48767513036727905
Validation loss: 2.152808944384257

Epoch: 6| Step: 6
Training loss: 0.79315584897995
Validation loss: 2.165007491906484

Epoch: 6| Step: 7
Training loss: 0.3622916340827942
Validation loss: 2.157124400138855

Epoch: 6| Step: 8
Training loss: 0.378892183303833
Validation loss: 2.1810641090075173

Epoch: 6| Step: 9
Training loss: 0.550081729888916
Validation loss: 2.174857219060262

Epoch: 6| Step: 10
Training loss: 0.4520803689956665
Validation loss: 2.2551952997843423

Epoch: 6| Step: 11
Training loss: 0.7913062572479248
Validation loss: 2.2304577231407166

Epoch: 6| Step: 12
Training loss: 0.40002506971359253
Validation loss: 2.211576680342356

Epoch: 6| Step: 13
Training loss: 0.620025634765625
Validation loss: 2.162602424621582

Epoch: 257| Step: 0
Training loss: 0.3105316758155823
Validation loss: 2.1404877503712973

Epoch: 6| Step: 1
Training loss: 0.695543646812439
Validation loss: 2.145635704199473

Epoch: 6| Step: 2
Training loss: 0.5177333354949951
Validation loss: 2.1874928077061973

Epoch: 6| Step: 3
Training loss: 0.7382681369781494
Validation loss: 2.183647791544596

Epoch: 6| Step: 4
Training loss: 0.29986920952796936
Validation loss: 2.1801698009173074

Epoch: 6| Step: 5
Training loss: 0.3552972674369812
Validation loss: 2.1679923137029014

Epoch: 6| Step: 6
Training loss: 0.37685447931289673
Validation loss: 2.2400839726130166

Epoch: 6| Step: 7
Training loss: 0.48207157850265503
Validation loss: 2.206264932950338

Epoch: 6| Step: 8
Training loss: 0.660280704498291
Validation loss: 2.240120808283488

Epoch: 6| Step: 9
Training loss: 0.2963913083076477
Validation loss: 2.1932587027549744

Epoch: 6| Step: 10
Training loss: 0.6060128211975098
Validation loss: 2.1744384169578552

Epoch: 6| Step: 11
Training loss: 0.5699963569641113
Validation loss: 2.1470876137415567

Epoch: 6| Step: 12
Training loss: 0.3691323399543762
Validation loss: 2.1864260832468667

Epoch: 6| Step: 13
Training loss: 0.5813608169555664
Validation loss: 2.1763940254847207

Epoch: 258| Step: 0
Training loss: 0.44029074907302856
Validation loss: 2.2014588912328086

Epoch: 6| Step: 1
Training loss: 0.3701435327529907
Validation loss: 2.189074456691742

Epoch: 6| Step: 2
Training loss: 0.7594088912010193
Validation loss: 2.127316892147064

Epoch: 6| Step: 3
Training loss: 0.8197512626647949
Validation loss: 2.1721351941426597

Epoch: 6| Step: 4
Training loss: 0.5366247892379761
Validation loss: 2.151235500971476

Epoch: 6| Step: 5
Training loss: 0.5150728225708008
Validation loss: 2.1460044980049133

Epoch: 6| Step: 6
Training loss: 0.4415303170681
Validation loss: 2.1571110486984253

Epoch: 6| Step: 7
Training loss: 0.5647651553153992
Validation loss: 2.118974030017853

Epoch: 6| Step: 8
Training loss: 0.3409753143787384
Validation loss: 2.1886969804763794

Epoch: 6| Step: 9
Training loss: 0.27492454648017883
Validation loss: 2.164822061856588

Epoch: 6| Step: 10
Training loss: 0.301837295293808
Validation loss: 2.206166128317515

Epoch: 6| Step: 11
Training loss: 0.3279457092285156
Validation loss: 2.156488021214803

Epoch: 6| Step: 12
Training loss: 0.7040097713470459
Validation loss: 2.2119877338409424

Epoch: 6| Step: 13
Training loss: 0.2863609194755554
Validation loss: 2.1230523387591043

Epoch: 259| Step: 0
Training loss: 0.3092610239982605
Validation loss: 2.141370932261149

Epoch: 6| Step: 1
Training loss: 0.6322464942932129
Validation loss: 2.1437885761260986

Epoch: 6| Step: 2
Training loss: 0.9390628337860107
Validation loss: 2.203593651453654

Epoch: 6| Step: 3
Training loss: 0.4379219114780426
Validation loss: 2.2105934023857117

Epoch: 6| Step: 4
Training loss: 0.4387458562850952
Validation loss: 2.1610162059466043

Epoch: 6| Step: 5
Training loss: 0.5041022300720215
Validation loss: 2.1630430817604065

Epoch: 6| Step: 6
Training loss: 0.5844784379005432
Validation loss: 2.1841470201810202

Epoch: 6| Step: 7
Training loss: 0.4029785096645355
Validation loss: 2.243623375892639

Epoch: 6| Step: 8
Training loss: 0.22365431487560272
Validation loss: 2.186804016431173

Epoch: 6| Step: 9
Training loss: 0.3334306478500366
Validation loss: 2.1938427686691284

Epoch: 6| Step: 10
Training loss: 0.5091451406478882
Validation loss: 2.256724754969279

Epoch: 6| Step: 11
Training loss: 0.5815686583518982
Validation loss: 2.1742437283198037

Epoch: 6| Step: 12
Training loss: 0.4385526478290558
Validation loss: 2.1767735282580056

Epoch: 6| Step: 13
Training loss: 0.42032310366630554
Validation loss: 2.184686998526255

Epoch: 260| Step: 0
Training loss: 0.5603132843971252
Validation loss: 2.1848962704340615

Epoch: 6| Step: 1
Training loss: 0.2448887676000595
Validation loss: 2.2149296402931213

Epoch: 6| Step: 2
Training loss: 0.5950620174407959
Validation loss: 2.2203887701034546

Epoch: 6| Step: 3
Training loss: 0.4920405149459839
Validation loss: 2.1664523681004844

Epoch: 6| Step: 4
Training loss: 0.570605456829071
Validation loss: 2.1741597255071006

Epoch: 6| Step: 5
Training loss: 0.4255238175392151
Validation loss: 2.1615469654401145

Epoch: 6| Step: 6
Training loss: 0.2770763635635376
Validation loss: 2.1539546251296997

Epoch: 6| Step: 7
Training loss: 0.29691413044929504
Validation loss: 2.2342143456141152

Epoch: 6| Step: 8
Training loss: 0.5553098917007446
Validation loss: 2.1704074939092

Epoch: 6| Step: 9
Training loss: 1.0647706985473633
Validation loss: 2.171651005744934

Epoch: 6| Step: 10
Training loss: 0.30886024236679077
Validation loss: 2.207920014858246

Epoch: 6| Step: 11
Training loss: 0.26251840591430664
Validation loss: 2.2142446041107178

Epoch: 6| Step: 12
Training loss: 0.3293313980102539
Validation loss: 2.2053075432777405

Epoch: 6| Step: 13
Training loss: 0.40089166164398193
Validation loss: 2.153915524482727

Epoch: 261| Step: 0
Training loss: 0.4785346984863281
Validation loss: 2.1437406738599143

Epoch: 6| Step: 1
Training loss: 0.2758638858795166
Validation loss: 2.203649083773295

Epoch: 6| Step: 2
Training loss: 0.2077295184135437
Validation loss: 2.1788238485654197

Epoch: 6| Step: 3
Training loss: 0.6478561162948608
Validation loss: 2.2127235929171243

Epoch: 6| Step: 4
Training loss: 0.32124781608581543
Validation loss: 2.1833783984184265

Epoch: 6| Step: 5
Training loss: 0.39107394218444824
Validation loss: 2.2581489284833274

Epoch: 6| Step: 6
Training loss: 0.4234793484210968
Validation loss: 2.270151694615682

Epoch: 6| Step: 7
Training loss: 0.32809460163116455
Validation loss: 2.2025821606318154

Epoch: 6| Step: 8
Training loss: 0.6259683966636658
Validation loss: 2.183694382508596

Epoch: 6| Step: 9
Training loss: 0.5660677552223206
Validation loss: 2.162784218788147

Epoch: 6| Step: 10
Training loss: 0.33090442419052124
Validation loss: 2.192517856756846

Epoch: 6| Step: 11
Training loss: 0.6758341789245605
Validation loss: 2.185482660929362

Epoch: 6| Step: 12
Training loss: 0.4842088222503662
Validation loss: 2.1906850337982178

Epoch: 6| Step: 13
Training loss: 0.6120811700820923
Validation loss: 2.231107175350189

Epoch: 262| Step: 0
Training loss: 0.3348771929740906
Validation loss: 2.2537248531977334

Epoch: 6| Step: 1
Training loss: 0.6459856629371643
Validation loss: 2.2377366622289023

Epoch: 6| Step: 2
Training loss: 0.7816355228424072
Validation loss: 2.2029267152150473

Epoch: 6| Step: 3
Training loss: 0.3416804373264313
Validation loss: 2.188559969266256

Epoch: 6| Step: 4
Training loss: 0.4070044457912445
Validation loss: 2.144683579603831

Epoch: 6| Step: 5
Training loss: 0.4169226586818695
Validation loss: 2.152839461962382

Epoch: 6| Step: 6
Training loss: 0.3103317320346832
Validation loss: 2.1863728562990823

Epoch: 6| Step: 7
Training loss: 0.2931484580039978
Validation loss: 2.1155328949292502

Epoch: 6| Step: 8
Training loss: 0.5655690431594849
Validation loss: 2.204432706038157

Epoch: 6| Step: 9
Training loss: 0.3589337468147278
Validation loss: 2.1730918486913047

Epoch: 6| Step: 10
Training loss: 0.7998800873756409
Validation loss: 2.245850165685018

Epoch: 6| Step: 11
Training loss: 0.38779595494270325
Validation loss: 2.244614044825236

Epoch: 6| Step: 12
Training loss: 0.4544539451599121
Validation loss: 2.2023770014444985

Epoch: 6| Step: 13
Training loss: 0.34130048751831055
Validation loss: 2.1916911005973816

Epoch: 263| Step: 0
Training loss: 0.4184820353984833
Validation loss: 2.2216001749038696

Epoch: 6| Step: 1
Training loss: 0.29375070333480835
Validation loss: 2.179750382900238

Epoch: 6| Step: 2
Training loss: 0.7685062885284424
Validation loss: 2.1347710688908896

Epoch: 6| Step: 3
Training loss: 0.5412771701812744
Validation loss: 2.231991231441498

Epoch: 6| Step: 4
Training loss: 0.4893449544906616
Validation loss: 2.2149147590001426

Epoch: 6| Step: 5
Training loss: 0.3376861810684204
Validation loss: 2.1947975953420005

Epoch: 6| Step: 6
Training loss: 0.7795330286026001
Validation loss: 2.1766558488210044

Epoch: 6| Step: 7
Training loss: 0.6808606386184692
Validation loss: 2.2196881572405496

Epoch: 6| Step: 8
Training loss: 0.3178039789199829
Validation loss: 2.178642292817434

Epoch: 6| Step: 9
Training loss: 0.33789974451065063
Validation loss: 2.1945801973342896

Epoch: 6| Step: 10
Training loss: 0.33557918667793274
Validation loss: 2.178686797618866

Epoch: 6| Step: 11
Training loss: 0.38422101736068726
Validation loss: 2.2584121227264404

Epoch: 6| Step: 12
Training loss: 0.20488931238651276
Validation loss: 2.174789388974508

Epoch: 6| Step: 13
Training loss: 0.4019772410392761
Validation loss: 2.193763017654419

Epoch: 264| Step: 0
Training loss: 0.5842208862304688
Validation loss: 2.1985015869140625

Epoch: 6| Step: 1
Training loss: 0.3397740125656128
Validation loss: 2.2090985774993896

Epoch: 6| Step: 2
Training loss: 0.44768592715263367
Validation loss: 2.217325448989868

Epoch: 6| Step: 3
Training loss: 0.26748862862586975
Validation loss: 2.200641632080078

Epoch: 6| Step: 4
Training loss: 0.6892921328544617
Validation loss: 2.1684035857518515

Epoch: 6| Step: 5
Training loss: 0.27667635679244995
Validation loss: 2.184381127357483

Epoch: 6| Step: 6
Training loss: 0.1756126880645752
Validation loss: 2.1917277773221335

Epoch: 6| Step: 7
Training loss: 0.640682578086853
Validation loss: 2.1829448143641152

Epoch: 6| Step: 8
Training loss: 0.7171127796173096
Validation loss: 2.1840317646662393

Epoch: 6| Step: 9
Training loss: 0.30073460936546326
Validation loss: 2.1795663436253867

Epoch: 6| Step: 10
Training loss: 0.39384350180625916
Validation loss: 2.120556632677714

Epoch: 6| Step: 11
Training loss: 0.49657365679740906
Validation loss: 2.1548009514808655

Epoch: 6| Step: 12
Training loss: 0.4052783250808716
Validation loss: 2.175992170969645

Epoch: 6| Step: 13
Training loss: 0.2662263512611389
Validation loss: 2.191547671953837

Epoch: 265| Step: 0
Training loss: 0.7042046785354614
Validation loss: 2.2150061329205832

Epoch: 6| Step: 1
Training loss: 0.3057582974433899
Validation loss: 2.1763650377591452

Epoch: 6| Step: 2
Training loss: 0.44142258167266846
Validation loss: 2.18434210618337

Epoch: 6| Step: 3
Training loss: 0.5438843965530396
Validation loss: 2.1691746513048806

Epoch: 6| Step: 4
Training loss: 0.6667934060096741
Validation loss: 2.132266958554586

Epoch: 6| Step: 5
Training loss: 0.3286990523338318
Validation loss: 2.1566968162854514

Epoch: 6| Step: 6
Training loss: 0.5354739427566528
Validation loss: 2.201332906881968

Epoch: 6| Step: 7
Training loss: 0.5753593444824219
Validation loss: 2.1968669096628823

Epoch: 6| Step: 8
Training loss: 0.26098132133483887
Validation loss: 2.2275205850601196

Epoch: 6| Step: 9
Training loss: 0.5020923614501953
Validation loss: 2.204984128475189

Epoch: 6| Step: 10
Training loss: 0.44455090165138245
Validation loss: 2.194607893625895

Epoch: 6| Step: 11
Training loss: 0.3220040202140808
Validation loss: 2.1923884948094687

Epoch: 6| Step: 12
Training loss: 0.39732450246810913
Validation loss: 2.215345323085785

Epoch: 6| Step: 13
Training loss: 0.37778550386428833
Validation loss: 2.12525482972463

Epoch: 266| Step: 0
Training loss: 0.3409059941768646
Validation loss: 2.1271780530611673

Epoch: 6| Step: 1
Training loss: 0.5814884901046753
Validation loss: 2.169823785622915

Epoch: 6| Step: 2
Training loss: 0.724605917930603
Validation loss: 2.1667506098747253

Epoch: 6| Step: 3
Training loss: 0.477883905172348
Validation loss: 2.1838989853858948

Epoch: 6| Step: 4
Training loss: 0.4184819757938385
Validation loss: 2.174845278263092

Epoch: 6| Step: 5
Training loss: 0.5415248870849609
Validation loss: 2.148493528366089

Epoch: 6| Step: 6
Training loss: 0.4351955056190491
Validation loss: 2.2048105200131736

Epoch: 6| Step: 7
Training loss: 0.20211096107959747
Validation loss: 2.1999702056248984

Epoch: 6| Step: 8
Training loss: 0.4493336081504822
Validation loss: 2.241426666577657

Epoch: 6| Step: 9
Training loss: 0.23060354590415955
Validation loss: 2.142487426598867

Epoch: 6| Step: 10
Training loss: 0.5233854055404663
Validation loss: 2.1803714831670127

Epoch: 6| Step: 11
Training loss: 0.37697774171829224
Validation loss: 2.151354412237803

Epoch: 6| Step: 12
Training loss: 0.35958993434906006
Validation loss: 2.1989401976267495

Epoch: 6| Step: 13
Training loss: 0.6908993124961853
Validation loss: 2.1675232450167337

Epoch: 267| Step: 0
Training loss: 0.9607901573181152
Validation loss: 2.1982433795928955

Epoch: 6| Step: 1
Training loss: 0.4126083254814148
Validation loss: 2.2455069621404014

Epoch: 6| Step: 2
Training loss: 0.642625093460083
Validation loss: 2.259116550286611

Epoch: 6| Step: 3
Training loss: 0.394517183303833
Validation loss: 2.2444410721460977

Epoch: 6| Step: 4
Training loss: 0.4627308249473572
Validation loss: 2.1616540352503457

Epoch: 6| Step: 5
Training loss: 0.44593310356140137
Validation loss: 2.1990038553873696

Epoch: 6| Step: 6
Training loss: 0.4606892466545105
Validation loss: 2.160248120625814

Epoch: 6| Step: 7
Training loss: 0.3017047345638275
Validation loss: 2.182422478993734

Epoch: 6| Step: 8
Training loss: 0.38127556443214417
Validation loss: 2.2394242882728577

Epoch: 6| Step: 9
Training loss: 0.5795422792434692
Validation loss: 2.2084348996480307

Epoch: 6| Step: 10
Training loss: 0.535852313041687
Validation loss: 2.2217466036478677

Epoch: 6| Step: 11
Training loss: 0.29797130823135376
Validation loss: 2.226339836915334

Epoch: 6| Step: 12
Training loss: 0.5624688267707825
Validation loss: 2.1790554920832315

Epoch: 6| Step: 13
Training loss: 0.394008606672287
Validation loss: 2.151463270187378

Epoch: 268| Step: 0
Training loss: 0.4676123857498169
Validation loss: 2.16473654905955

Epoch: 6| Step: 1
Training loss: 0.42341312766075134
Validation loss: 2.182888150215149

Epoch: 6| Step: 2
Training loss: 0.7034062743186951
Validation loss: 2.187780201435089

Epoch: 6| Step: 3
Training loss: 0.3529433012008667
Validation loss: 2.205320715904236

Epoch: 6| Step: 4
Training loss: 0.36856335401535034
Validation loss: 2.194339116414388

Epoch: 6| Step: 5
Training loss: 0.3532579839229584
Validation loss: 2.2719073494275412

Epoch: 6| Step: 6
Training loss: 0.23550008237361908
Validation loss: 2.2925789952278137

Epoch: 6| Step: 7
Training loss: 0.628139853477478
Validation loss: 2.1728830536206565

Epoch: 6| Step: 8
Training loss: 0.25584542751312256
Validation loss: 2.194778343041738

Epoch: 6| Step: 9
Training loss: 0.27757638692855835
Validation loss: 2.179256816705068

Epoch: 6| Step: 10
Training loss: 0.6900690793991089
Validation loss: 2.207187016805013

Epoch: 6| Step: 11
Training loss: 0.3887662887573242
Validation loss: 2.2010491291681924

Epoch: 6| Step: 12
Training loss: 0.7412976026535034
Validation loss: 2.180013736089071

Epoch: 6| Step: 13
Training loss: 0.4044860005378723
Validation loss: 2.1176687677701316

Epoch: 269| Step: 0
Training loss: 0.20878803730010986
Validation loss: 2.2055119276046753

Epoch: 6| Step: 1
Training loss: 0.4544717073440552
Validation loss: 2.23278013865153

Epoch: 6| Step: 2
Training loss: 0.4229867458343506
Validation loss: 2.228879431883494

Epoch: 6| Step: 3
Training loss: 0.5837823748588562
Validation loss: 2.2602542638778687

Epoch: 6| Step: 4
Training loss: 0.2927606701850891
Validation loss: 2.2143671909968057

Epoch: 6| Step: 5
Training loss: 0.2615271210670471
Validation loss: 2.204717139403025

Epoch: 6| Step: 6
Training loss: 0.5040725469589233
Validation loss: 2.2230470776557922

Epoch: 6| Step: 7
Training loss: 0.3871415853500366
Validation loss: 2.1623218258221946

Epoch: 6| Step: 8
Training loss: 0.45200276374816895
Validation loss: 2.2210629185040793

Epoch: 6| Step: 9
Training loss: 0.7303374409675598
Validation loss: 2.256429394086202

Epoch: 6| Step: 10
Training loss: 0.27138543128967285
Validation loss: 2.204229493935903

Epoch: 6| Step: 11
Training loss: 0.35372161865234375
Validation loss: 2.279369135697683

Epoch: 6| Step: 12
Training loss: 0.46525105834007263
Validation loss: 2.2695010900497437

Epoch: 6| Step: 13
Training loss: 0.9898922443389893
Validation loss: 2.2132127483685813

Epoch: 270| Step: 0
Training loss: 0.23813147842884064
Validation loss: 2.2116894920667014

Epoch: 6| Step: 1
Training loss: 0.5278853178024292
Validation loss: 2.1694177389144897

Epoch: 6| Step: 2
Training loss: 0.5435492396354675
Validation loss: 2.1515896717707315

Epoch: 6| Step: 3
Training loss: 0.38338643312454224
Validation loss: 2.176887889703115

Epoch: 6| Step: 4
Training loss: 0.42829978466033936
Validation loss: 2.1881282925605774

Epoch: 6| Step: 5
Training loss: 0.3930603861808777
Validation loss: 2.169548432032267

Epoch: 6| Step: 6
Training loss: 0.42873725295066833
Validation loss: 2.1741972168286643

Epoch: 6| Step: 7
Training loss: 0.36783498525619507
Validation loss: 2.2846880356470742

Epoch: 6| Step: 8
Training loss: 0.7175912857055664
Validation loss: 2.2806748747825623

Epoch: 6| Step: 9
Training loss: 0.5453802347183228
Validation loss: 2.2441532015800476

Epoch: 6| Step: 10
Training loss: 0.5670984387397766
Validation loss: 2.303869287172953

Epoch: 6| Step: 11
Training loss: 0.5177248120307922
Validation loss: 2.2869014938672385

Epoch: 6| Step: 12
Training loss: 0.4275584816932678
Validation loss: 2.1844411492347717

Epoch: 6| Step: 13
Training loss: 0.3343700170516968
Validation loss: 2.1817821661631265

Epoch: 271| Step: 0
Training loss: 0.4275763928890228
Validation loss: 2.2554627458254495

Epoch: 6| Step: 1
Training loss: 0.38186168670654297
Validation loss: 2.2100504438082376

Epoch: 6| Step: 2
Training loss: 0.38688528537750244
Validation loss: 2.1484347184499106

Epoch: 6| Step: 3
Training loss: 0.33233070373535156
Validation loss: 2.250689367453257

Epoch: 6| Step: 4
Training loss: 0.42024099826812744
Validation loss: 2.2965384324391684

Epoch: 6| Step: 5
Training loss: 0.6334472894668579
Validation loss: 2.272887667020162

Epoch: 6| Step: 6
Training loss: 0.49599525332450867
Validation loss: 2.2490194439888

Epoch: 6| Step: 7
Training loss: 0.3364209532737732
Validation loss: 2.2026557127634683

Epoch: 6| Step: 8
Training loss: 0.433032363653183
Validation loss: 2.2364415526390076

Epoch: 6| Step: 9
Training loss: 0.5335797071456909
Validation loss: 2.1751258770624795

Epoch: 6| Step: 10
Training loss: 0.31731823086738586
Validation loss: 2.194284439086914

Epoch: 6| Step: 11
Training loss: 0.7963846921920776
Validation loss: 2.1935681899388633

Epoch: 6| Step: 12
Training loss: 0.5051478147506714
Validation loss: 2.1486192544301352

Epoch: 6| Step: 13
Training loss: 1.0524708032608032
Validation loss: 2.2038414080937705

Epoch: 272| Step: 0
Training loss: 0.3858126997947693
Validation loss: 2.21396533648173

Epoch: 6| Step: 1
Training loss: 0.2945210337638855
Validation loss: 2.2686698834101358

Epoch: 6| Step: 2
Training loss: 0.5753931999206543
Validation loss: 2.2333279848098755

Epoch: 6| Step: 3
Training loss: 0.4205760657787323
Validation loss: 2.246890068054199

Epoch: 6| Step: 4
Training loss: 0.36340218782424927
Validation loss: 2.232683797677358

Epoch: 6| Step: 5
Training loss: 0.4907926619052887
Validation loss: 2.2241076628367105

Epoch: 6| Step: 6
Training loss: 0.335386723279953
Validation loss: 2.197071055571238

Epoch: 6| Step: 7
Training loss: 0.3769044876098633
Validation loss: 2.178980608781179

Epoch: 6| Step: 8
Training loss: 0.47131335735321045
Validation loss: 2.198587954044342

Epoch: 6| Step: 9
Training loss: 0.37386399507522583
Validation loss: 2.1897132198015847

Epoch: 6| Step: 10
Training loss: 0.6671870946884155
Validation loss: 2.1518514355023703

Epoch: 6| Step: 11
Training loss: 0.4488416314125061
Validation loss: 2.169426659742991

Epoch: 6| Step: 12
Training loss: 0.48359739780426025
Validation loss: 2.1854695081710815

Epoch: 6| Step: 13
Training loss: 0.35473817586898804
Validation loss: 2.1612311800320945

Epoch: 273| Step: 0
Training loss: 0.2509247064590454
Validation loss: 2.1772384444872537

Epoch: 6| Step: 1
Training loss: 0.24664996564388275
Validation loss: 2.1878787080446878

Epoch: 6| Step: 2
Training loss: 0.3521011173725128
Validation loss: 2.2056815226872764

Epoch: 6| Step: 3
Training loss: 0.5380242466926575
Validation loss: 2.216023941834768

Epoch: 6| Step: 4
Training loss: 0.4582071900367737
Validation loss: 2.181402802467346

Epoch: 6| Step: 5
Training loss: 0.3728955090045929
Validation loss: 2.1251242955525718

Epoch: 6| Step: 6
Training loss: 0.48598727583885193
Validation loss: 2.1385706265767417

Epoch: 6| Step: 7
Training loss: 0.7617701292037964
Validation loss: 2.196432650089264

Epoch: 6| Step: 8
Training loss: 0.4495820999145508
Validation loss: 2.1699278354644775

Epoch: 6| Step: 9
Training loss: 0.4065265655517578
Validation loss: 2.208959718545278

Epoch: 6| Step: 10
Training loss: 0.44410353899002075
Validation loss: 2.1102879643440247

Epoch: 6| Step: 11
Training loss: 0.2630234360694885
Validation loss: 2.2069432139396667

Epoch: 6| Step: 12
Training loss: 0.8609267473220825
Validation loss: 2.227127949396769

Epoch: 6| Step: 13
Training loss: 0.8911094069480896
Validation loss: 2.2602083484331765

Epoch: 274| Step: 0
Training loss: 0.5120036602020264
Validation loss: 2.2818515499432883

Epoch: 6| Step: 1
Training loss: 0.3642722964286804
Validation loss: 2.18689618508021

Epoch: 6| Step: 2
Training loss: 0.2875805199146271
Validation loss: 2.1506896217664084

Epoch: 6| Step: 3
Training loss: 0.42962127923965454
Validation loss: 2.146308958530426

Epoch: 6| Step: 4
Training loss: 0.9537054896354675
Validation loss: 2.1508295933405557

Epoch: 6| Step: 5
Training loss: 0.2576010227203369
Validation loss: 2.117936988671621

Epoch: 6| Step: 6
Training loss: 0.31100738048553467
Validation loss: 2.164343615372976

Epoch: 6| Step: 7
Training loss: 0.38833120465278625
Validation loss: 2.167619744936625

Epoch: 6| Step: 8
Training loss: 0.41055822372436523
Validation loss: 2.169603943824768

Epoch: 6| Step: 9
Training loss: 0.397135466337204
Validation loss: 2.16284974416097

Epoch: 6| Step: 10
Training loss: 0.3379797041416168
Validation loss: 2.1538894375165305

Epoch: 6| Step: 11
Training loss: 0.32636937499046326
Validation loss: 2.160874366760254

Epoch: 6| Step: 12
Training loss: 0.6090129613876343
Validation loss: 2.159874598185221

Epoch: 6| Step: 13
Training loss: 0.3668232560157776
Validation loss: 2.130449056625366

Epoch: 275| Step: 0
Training loss: 0.31858205795288086
Validation loss: 2.146371086438497

Epoch: 6| Step: 1
Training loss: 0.2746836245059967
Validation loss: 2.184726297855377

Epoch: 6| Step: 2
Training loss: 0.14931081235408783
Validation loss: 2.2104417085647583

Epoch: 6| Step: 3
Training loss: 0.32748979330062866
Validation loss: 2.1711361010869346

Epoch: 6| Step: 4
Training loss: 0.8168121576309204
Validation loss: 2.1589554945627847

Epoch: 6| Step: 5
Training loss: 0.6782969236373901
Validation loss: 2.1604700684547424

Epoch: 6| Step: 6
Training loss: 0.2480531632900238
Validation loss: 2.1328893899917603

Epoch: 6| Step: 7
Training loss: 0.6581841111183167
Validation loss: 2.1429495414098105

Epoch: 6| Step: 8
Training loss: 0.4575503170490265
Validation loss: 2.1764013965924582

Epoch: 6| Step: 9
Training loss: 0.44800442457199097
Validation loss: 2.222576856613159

Epoch: 6| Step: 10
Training loss: 0.823351263999939
Validation loss: 2.2496891617774963

Epoch: 6| Step: 11
Training loss: 0.48595255613327026
Validation loss: 2.2306363582611084

Epoch: 6| Step: 12
Training loss: 0.44200578331947327
Validation loss: 2.2354633808135986

Epoch: 6| Step: 13
Training loss: 0.21968068182468414
Validation loss: 2.196593006451925

Epoch: 276| Step: 0
Training loss: 0.3846648931503296
Validation loss: 2.1854207714398703

Epoch: 6| Step: 1
Training loss: 0.3515394926071167
Validation loss: 2.199572523434957

Epoch: 6| Step: 2
Training loss: 0.3948025703430176
Validation loss: 2.211410641670227

Epoch: 6| Step: 3
Training loss: 0.7188110947608948
Validation loss: 2.1944103240966797

Epoch: 6| Step: 4
Training loss: 0.2887202501296997
Validation loss: 2.1630806724230447

Epoch: 6| Step: 5
Training loss: 0.5554037690162659
Validation loss: 2.190986613432566

Epoch: 6| Step: 6
Training loss: 0.3024354577064514
Validation loss: 2.234997272491455

Epoch: 6| Step: 7
Training loss: 0.499017596244812
Validation loss: 2.216958999633789

Epoch: 6| Step: 8
Training loss: 0.33517032861709595
Validation loss: 2.181843022505442

Epoch: 6| Step: 9
Training loss: 0.3513724207878113
Validation loss: 2.187069276968638

Epoch: 6| Step: 10
Training loss: 0.6140609979629517
Validation loss: 2.23011314868927

Epoch: 6| Step: 11
Training loss: 0.4101651906967163
Validation loss: 2.2069517374038696

Epoch: 6| Step: 12
Training loss: 0.3987785279750824
Validation loss: 2.2434635559717813

Epoch: 6| Step: 13
Training loss: 0.4029463827610016
Validation loss: 2.2702751557032266

Epoch: 277| Step: 0
Training loss: 0.40418487787246704
Validation loss: 2.230047106742859

Epoch: 6| Step: 1
Training loss: 0.6581147909164429
Validation loss: 2.2407728830973306

Epoch: 6| Step: 2
Training loss: 0.5577495694160461
Validation loss: 2.1999462842941284

Epoch: 6| Step: 3
Training loss: 0.37599727511405945
Validation loss: 2.1923879186312356

Epoch: 6| Step: 4
Training loss: 0.4517558515071869
Validation loss: 2.2434870998064675

Epoch: 6| Step: 5
Training loss: 0.5363324880599976
Validation loss: 2.264088988304138

Epoch: 6| Step: 6
Training loss: 0.4373282790184021
Validation loss: 2.2532440622647605

Epoch: 6| Step: 7
Training loss: 0.24118949472904205
Validation loss: 2.1660056908925376

Epoch: 6| Step: 8
Training loss: 0.4763758182525635
Validation loss: 2.1847718755404153

Epoch: 6| Step: 9
Training loss: 0.43940240144729614
Validation loss: 2.140875538190206

Epoch: 6| Step: 10
Training loss: 0.45939964056015015
Validation loss: 2.18599138657252

Epoch: 6| Step: 11
Training loss: 0.4417884349822998
Validation loss: 2.2144393722216287

Epoch: 6| Step: 12
Training loss: 0.2949656546115875
Validation loss: 2.2674861351648965

Epoch: 6| Step: 13
Training loss: 0.33812350034713745
Validation loss: 2.238726278146108

Epoch: 278| Step: 0
Training loss: 0.378365159034729
Validation loss: 2.3045395612716675

Epoch: 6| Step: 1
Training loss: 0.9436838030815125
Validation loss: 2.205074369907379

Epoch: 6| Step: 2
Training loss: 0.44458502531051636
Validation loss: 2.183395206928253

Epoch: 6| Step: 3
Training loss: 0.5047445297241211
Validation loss: 2.2057294646898904

Epoch: 6| Step: 4
Training loss: 0.2811598777770996
Validation loss: 2.147810220718384

Epoch: 6| Step: 5
Training loss: 0.48951390385627747
Validation loss: 2.16167680422465

Epoch: 6| Step: 6
Training loss: 0.4657987058162689
Validation loss: 2.2184981306393943

Epoch: 6| Step: 7
Training loss: 0.19749262928962708
Validation loss: 2.2014602025349936

Epoch: 6| Step: 8
Training loss: 0.2713819742202759
Validation loss: 2.2179136077562966

Epoch: 6| Step: 9
Training loss: 0.4403936266899109
Validation loss: 2.188763360182444

Epoch: 6| Step: 10
Training loss: 0.3245135545730591
Validation loss: 2.24528706073761

Epoch: 6| Step: 11
Training loss: 0.6819149255752563
Validation loss: 2.2301888267199197

Epoch: 6| Step: 12
Training loss: 0.266801118850708
Validation loss: 2.2010027170181274

Epoch: 6| Step: 13
Training loss: 0.35449355840682983
Validation loss: 2.122341752052307

Epoch: 279| Step: 0
Training loss: 0.7019219398498535
Validation loss: 2.1379026969273887

Epoch: 6| Step: 1
Training loss: 0.32447323203086853
Validation loss: 2.1701437632242837

Epoch: 6| Step: 2
Training loss: 0.7548848390579224
Validation loss: 2.214041074117025

Epoch: 6| Step: 3
Training loss: 0.3504374325275421
Validation loss: 2.258940895398458

Epoch: 6| Step: 4
Training loss: 0.6119768619537354
Validation loss: 2.311277747154236

Epoch: 6| Step: 5
Training loss: 0.3569369316101074
Validation loss: 2.2568333943684897

Epoch: 6| Step: 6
Training loss: 0.38829606771469116
Validation loss: 2.2386149962743125

Epoch: 6| Step: 7
Training loss: 0.3122512698173523
Validation loss: 2.2214984695116677

Epoch: 6| Step: 8
Training loss: 0.5942434668540955
Validation loss: 2.1726967493693032

Epoch: 6| Step: 9
Training loss: 0.3989143967628479
Validation loss: 2.1804142395655313

Epoch: 6| Step: 10
Training loss: 0.43813279271125793
Validation loss: 2.1507602532704673

Epoch: 6| Step: 11
Training loss: 0.37388455867767334
Validation loss: 2.1977924505869546

Epoch: 6| Step: 12
Training loss: 0.47852623462677
Validation loss: 2.2104657093683877

Epoch: 6| Step: 13
Training loss: 0.7875262498855591
Validation loss: 2.23263818025589

Epoch: 280| Step: 0
Training loss: 0.19408109784126282
Validation loss: 2.2171303828557334

Epoch: 6| Step: 1
Training loss: 0.3361217975616455
Validation loss: 2.268347163995107

Epoch: 6| Step: 2
Training loss: 0.4975872039794922
Validation loss: 2.224427322546641

Epoch: 6| Step: 3
Training loss: 0.42767077684402466
Validation loss: 2.2100884914398193

Epoch: 6| Step: 4
Training loss: 0.6627178192138672
Validation loss: 2.206076443195343

Epoch: 6| Step: 5
Training loss: 0.2065410614013672
Validation loss: 2.1634536186854043

Epoch: 6| Step: 6
Training loss: 0.27353745698928833
Validation loss: 2.1242022116978965

Epoch: 6| Step: 7
Training loss: 0.5128964185714722
Validation loss: 2.152285615603129

Epoch: 6| Step: 8
Training loss: 1.066164255142212
Validation loss: 2.166669329007467

Epoch: 6| Step: 9
Training loss: 0.5943006277084351
Validation loss: 2.199584643046061

Epoch: 6| Step: 10
Training loss: 0.27059149742126465
Validation loss: 2.178196668624878

Epoch: 6| Step: 11
Training loss: 0.2369907796382904
Validation loss: 2.195400834083557

Epoch: 6| Step: 12
Training loss: 0.3940288722515106
Validation loss: 2.150004426638285

Epoch: 6| Step: 13
Training loss: 0.4224812984466553
Validation loss: 2.1489953796068826

Epoch: 281| Step: 0
Training loss: 0.5082230567932129
Validation loss: 2.1371939977010093

Epoch: 6| Step: 1
Training loss: 0.5201250314712524
Validation loss: 2.157447258631388

Epoch: 6| Step: 2
Training loss: 0.3680168688297272
Validation loss: 2.129519283771515

Epoch: 6| Step: 3
Training loss: 0.2215050756931305
Validation loss: 2.1560264031092324

Epoch: 6| Step: 4
Training loss: 0.2006082534790039
Validation loss: 2.1334781845410666

Epoch: 6| Step: 5
Training loss: 0.30456364154815674
Validation loss: 2.190350890159607

Epoch: 6| Step: 6
Training loss: 0.7056009769439697
Validation loss: 2.1850918531417847

Epoch: 6| Step: 7
Training loss: 0.2603182792663574
Validation loss: 2.214117447535197

Epoch: 6| Step: 8
Training loss: 0.40177860856056213
Validation loss: 2.2075401544570923

Epoch: 6| Step: 9
Training loss: 0.45881569385528564
Validation loss: 2.1402108669281006

Epoch: 6| Step: 10
Training loss: 0.285927951335907
Validation loss: 2.129467229048411

Epoch: 6| Step: 11
Training loss: 0.2831950783729553
Validation loss: 2.12601246436437

Epoch: 6| Step: 12
Training loss: 0.7859123945236206
Validation loss: 2.1429237524668374

Epoch: 6| Step: 13
Training loss: 0.5306840538978577
Validation loss: 2.1940001050631204

Epoch: 282| Step: 0
Training loss: 0.3617161810398102
Validation loss: 2.1629475752512612

Epoch: 6| Step: 1
Training loss: 0.40867793560028076
Validation loss: 2.1393662889798484

Epoch: 6| Step: 2
Training loss: 0.6457477807998657
Validation loss: 2.2078896363576255

Epoch: 6| Step: 3
Training loss: 0.4334714412689209
Validation loss: 2.203006466229757

Epoch: 6| Step: 4
Training loss: 0.32724055647850037
Validation loss: 2.1515307426452637

Epoch: 6| Step: 5
Training loss: 0.7720740437507629
Validation loss: 2.1718631585439048

Epoch: 6| Step: 6
Training loss: 0.3368941843509674
Validation loss: 2.138347407182058

Epoch: 6| Step: 7
Training loss: 0.23425209522247314
Validation loss: 2.178002138932546

Epoch: 6| Step: 8
Training loss: 0.5396315455436707
Validation loss: 2.2014658053716025

Epoch: 6| Step: 9
Training loss: 0.49514225125312805
Validation loss: 2.215384761492411

Epoch: 6| Step: 10
Training loss: 0.36949628591537476
Validation loss: 2.115338087081909

Epoch: 6| Step: 11
Training loss: 0.49900346994400024
Validation loss: 2.2690048615137735

Epoch: 6| Step: 12
Training loss: 0.5272077918052673
Validation loss: 2.1853075424830117

Epoch: 6| Step: 13
Training loss: 0.34600135684013367
Validation loss: 2.24039359887441

Epoch: 283| Step: 0
Training loss: 0.38240116834640503
Validation loss: 2.2571364641189575

Epoch: 6| Step: 1
Training loss: 0.42003297805786133
Validation loss: 2.216180364290873

Epoch: 6| Step: 2
Training loss: 0.3937375843524933
Validation loss: 2.1301297346750894

Epoch: 6| Step: 3
Training loss: 0.8366820812225342
Validation loss: 2.1917008757591248

Epoch: 6| Step: 4
Training loss: 0.44615012407302856
Validation loss: 2.141752302646637

Epoch: 6| Step: 5
Training loss: 0.6568523645401001
Validation loss: 2.1874676942825317

Epoch: 6| Step: 6
Training loss: 0.36482852697372437
Validation loss: 2.186524510383606

Epoch: 6| Step: 7
Training loss: 0.41443294286727905
Validation loss: 2.1222209533055625

Epoch: 6| Step: 8
Training loss: 0.5076218843460083
Validation loss: 2.214161992073059

Epoch: 6| Step: 9
Training loss: 0.4401242136955261
Validation loss: 2.2336230675379434

Epoch: 6| Step: 10
Training loss: 0.4308636486530304
Validation loss: 2.199649135271708

Epoch: 6| Step: 11
Training loss: 0.4375215768814087
Validation loss: 2.180768847465515

Epoch: 6| Step: 12
Training loss: 0.6241315007209778
Validation loss: 2.22952663898468

Epoch: 6| Step: 13
Training loss: 0.3346075415611267
Validation loss: 2.1728020906448364

Epoch: 284| Step: 0
Training loss: 0.40416795015335083
Validation loss: 2.2329023679097495

Epoch: 6| Step: 1
Training loss: 0.7307113409042358
Validation loss: 2.180151085058848

Epoch: 6| Step: 2
Training loss: 0.2844172716140747
Validation loss: 2.1848931113878884

Epoch: 6| Step: 3
Training loss: 0.3959917426109314
Validation loss: 2.17899090051651

Epoch: 6| Step: 4
Training loss: 0.3062254786491394
Validation loss: 2.220664620399475

Epoch: 6| Step: 5
Training loss: 0.35077232122421265
Validation loss: 2.2645607391993203

Epoch: 6| Step: 6
Training loss: 0.5331864356994629
Validation loss: 2.2125263015429177

Epoch: 6| Step: 7
Training loss: 0.46746960282325745
Validation loss: 2.186813453833262

Epoch: 6| Step: 8
Training loss: 0.34454232454299927
Validation loss: 2.1660043597221375

Epoch: 6| Step: 9
Training loss: 0.6133700609207153
Validation loss: 2.1296311219533286

Epoch: 6| Step: 10
Training loss: 0.5007333755493164
Validation loss: 2.134376585483551

Epoch: 6| Step: 11
Training loss: 0.36845922470092773
Validation loss: 2.17289666334788

Epoch: 6| Step: 12
Training loss: 0.3567102253437042
Validation loss: 2.2434534430503845

Epoch: 6| Step: 13
Training loss: 0.4254022240638733
Validation loss: 2.173915068308512

Epoch: 285| Step: 0
Training loss: 0.6245803833007812
Validation loss: 2.216561198234558

Epoch: 6| Step: 1
Training loss: 0.26584118604660034
Validation loss: 2.2257198095321655

Epoch: 6| Step: 2
Training loss: 0.24147160351276398
Validation loss: 2.2005668481191

Epoch: 6| Step: 3
Training loss: 0.35109034180641174
Validation loss: 2.1996212204297385

Epoch: 6| Step: 4
Training loss: 0.8693110942840576
Validation loss: 2.153786838054657

Epoch: 6| Step: 5
Training loss: 0.5732324719429016
Validation loss: 2.102684199810028

Epoch: 6| Step: 6
Training loss: 0.2801817059516907
Validation loss: 2.167378087838491

Epoch: 6| Step: 7
Training loss: 0.33290377259254456
Validation loss: 2.1911030213038125

Epoch: 6| Step: 8
Training loss: 0.31459206342697144
Validation loss: 2.18117485443751

Epoch: 6| Step: 9
Training loss: 0.5219360589981079
Validation loss: 2.190154512723287

Epoch: 6| Step: 10
Training loss: 0.31759509444236755
Validation loss: 2.201513389746348

Epoch: 6| Step: 11
Training loss: 0.21437178552150726
Validation loss: 2.177976051966349

Epoch: 6| Step: 12
Training loss: 0.6577553749084473
Validation loss: 2.151666045188904

Epoch: 6| Step: 13
Training loss: 0.438099205493927
Validation loss: 2.1686128775278726

Epoch: 286| Step: 0
Training loss: 0.3946533799171448
Validation loss: 2.1298287312189736

Epoch: 6| Step: 1
Training loss: 0.29905861616134644
Validation loss: 2.1663990020751953

Epoch: 6| Step: 2
Training loss: 0.2888268530368805
Validation loss: 2.1596180399258933

Epoch: 6| Step: 3
Training loss: 0.3799898624420166
Validation loss: 2.1803093751271567

Epoch: 6| Step: 4
Training loss: 0.37988990545272827
Validation loss: 2.200103203455607

Epoch: 6| Step: 5
Training loss: 0.5348206758499146
Validation loss: 2.2397948702176413

Epoch: 6| Step: 6
Training loss: 0.27585044503211975
Validation loss: 2.169716238975525

Epoch: 6| Step: 7
Training loss: 0.5646243691444397
Validation loss: 2.1759804487228394

Epoch: 6| Step: 8
Training loss: 0.6663731932640076
Validation loss: 2.1682099103927612

Epoch: 6| Step: 9
Training loss: 0.35011422634124756
Validation loss: 2.1788498957951865

Epoch: 6| Step: 10
Training loss: 0.3520798683166504
Validation loss: 2.1667307217915854

Epoch: 6| Step: 11
Training loss: 0.23854860663414001
Validation loss: 2.1810216903686523

Epoch: 6| Step: 12
Training loss: 0.491794228553772
Validation loss: 2.1854631106058755

Epoch: 6| Step: 13
Training loss: 0.6909066438674927
Validation loss: 2.163571536540985

Epoch: 287| Step: 0
Training loss: 0.3550582528114319
Validation loss: 2.117692232131958

Epoch: 6| Step: 1
Training loss: 0.9377909898757935
Validation loss: 2.1959542632102966

Epoch: 6| Step: 2
Training loss: 0.2665320038795471
Validation loss: 2.2413513461748757

Epoch: 6| Step: 3
Training loss: 0.33305299282073975
Validation loss: 2.203223248322805

Epoch: 6| Step: 4
Training loss: 0.2850051522254944
Validation loss: 2.1822389960289

Epoch: 6| Step: 5
Training loss: 0.24757009744644165
Validation loss: 2.1796836853027344

Epoch: 6| Step: 6
Training loss: 0.3164621591567993
Validation loss: 2.215443472067515

Epoch: 6| Step: 7
Training loss: 0.5858689546585083
Validation loss: 2.190469284852346

Epoch: 6| Step: 8
Training loss: 0.337028443813324
Validation loss: 2.1718167066574097

Epoch: 6| Step: 9
Training loss: 0.6733120679855347
Validation loss: 2.1818240880966187

Epoch: 6| Step: 10
Training loss: 0.42469173669815063
Validation loss: 2.1770381927490234

Epoch: 6| Step: 11
Training loss: 0.520986795425415
Validation loss: 2.123966375986735

Epoch: 6| Step: 12
Training loss: 0.38047611713409424
Validation loss: 2.177540361881256

Epoch: 6| Step: 13
Training loss: 0.31914693117141724
Validation loss: 2.1623931527137756

Epoch: 288| Step: 0
Training loss: 0.3159943222999573
Validation loss: 2.169096052646637

Epoch: 6| Step: 1
Training loss: 0.6507121324539185
Validation loss: 2.1476113398869834

Epoch: 6| Step: 2
Training loss: 0.19763652980327606
Validation loss: 2.151014506816864

Epoch: 6| Step: 3
Training loss: 0.7533895969390869
Validation loss: 2.1428452332814536

Epoch: 6| Step: 4
Training loss: 0.5453728437423706
Validation loss: 2.2176385720570884

Epoch: 6| Step: 5
Training loss: 0.3927912712097168
Validation loss: 2.243189016977946

Epoch: 6| Step: 6
Training loss: 0.35300326347351074
Validation loss: 2.1694533228874207

Epoch: 6| Step: 7
Training loss: 0.3145599365234375
Validation loss: 2.2214258114496865

Epoch: 6| Step: 8
Training loss: 0.2537565529346466
Validation loss: 2.1233080625534058

Epoch: 6| Step: 9
Training loss: 0.4115421175956726
Validation loss: 2.1531357963879905

Epoch: 6| Step: 10
Training loss: 0.3206421136856079
Validation loss: 2.116018831729889

Epoch: 6| Step: 11
Training loss: 0.48139244318008423
Validation loss: 2.116731822490692

Epoch: 6| Step: 12
Training loss: 0.35493406653404236
Validation loss: 2.131906509399414

Epoch: 6| Step: 13
Training loss: 0.2938193082809448
Validation loss: 2.1496103008588157

Epoch: 289| Step: 0
Training loss: 0.5967570543289185
Validation loss: 2.1537738045056662

Epoch: 6| Step: 1
Training loss: 0.24319152534008026
Validation loss: 2.1680840055147805

Epoch: 6| Step: 2
Training loss: 0.29851233959198
Validation loss: 2.1584425965944924

Epoch: 6| Step: 3
Training loss: 0.25710439682006836
Validation loss: 2.1600129206975303

Epoch: 6| Step: 4
Training loss: 0.30065304040908813
Validation loss: 2.1156660119692483

Epoch: 6| Step: 5
Training loss: 0.3056265115737915
Validation loss: 2.1969521244366965

Epoch: 6| Step: 6
Training loss: 0.3910277783870697
Validation loss: 2.172586460908254

Epoch: 6| Step: 7
Training loss: 0.3424683213233948
Validation loss: 2.237169702847799

Epoch: 6| Step: 8
Training loss: 0.46010538935661316
Validation loss: 2.161107142766317

Epoch: 6| Step: 9
Training loss: 0.36413702368736267
Validation loss: 2.163368821144104

Epoch: 6| Step: 10
Training loss: 0.446335107088089
Validation loss: 2.139039953549703

Epoch: 6| Step: 11
Training loss: 0.6496111154556274
Validation loss: 2.146126170953115

Epoch: 6| Step: 12
Training loss: 0.1670355349779129
Validation loss: 2.176713705062866

Epoch: 6| Step: 13
Training loss: 0.49622267484664917
Validation loss: 2.14549454053243

Epoch: 290| Step: 0
Training loss: 0.7510979175567627
Validation loss: 2.172242740790049

Epoch: 6| Step: 1
Training loss: 0.4831341505050659
Validation loss: 2.2351996103922525

Epoch: 6| Step: 2
Training loss: 0.44216465950012207
Validation loss: 2.182378888130188

Epoch: 6| Step: 3
Training loss: 0.22363987565040588
Validation loss: 2.21705162525177

Epoch: 6| Step: 4
Training loss: 0.44903165102005005
Validation loss: 2.19826074441274

Epoch: 6| Step: 5
Training loss: 0.2716333270072937
Validation loss: 2.179909626642863

Epoch: 6| Step: 6
Training loss: 0.5034170150756836
Validation loss: 2.1916991074879966

Epoch: 6| Step: 7
Training loss: 0.55162513256073
Validation loss: 2.166656037171682

Epoch: 6| Step: 8
Training loss: 0.5748953819274902
Validation loss: 2.1638418634732566

Epoch: 6| Step: 9
Training loss: 0.3500954806804657
Validation loss: 2.200261394182841

Epoch: 6| Step: 10
Training loss: 0.3235090970993042
Validation loss: 2.1689825852711997

Epoch: 6| Step: 11
Training loss: 0.2589108347892761
Validation loss: 2.13205224275589

Epoch: 6| Step: 12
Training loss: 0.3671240210533142
Validation loss: 2.1744386355082193

Epoch: 6| Step: 13
Training loss: 0.4886460304260254
Validation loss: 2.1244564851125083

Epoch: 291| Step: 0
Training loss: 0.7077028751373291
Validation loss: 2.150831659634908

Epoch: 6| Step: 1
Training loss: 0.4271244406700134
Validation loss: 2.2088951468467712

Epoch: 6| Step: 2
Training loss: 0.23863309621810913
Validation loss: 2.1854539712270102

Epoch: 6| Step: 3
Training loss: 0.320079505443573
Validation loss: 2.1839242776234946

Epoch: 6| Step: 4
Training loss: 0.26082971692085266
Validation loss: 2.205382307370504

Epoch: 6| Step: 5
Training loss: 0.41137993335723877
Validation loss: 2.178244630495707

Epoch: 6| Step: 6
Training loss: 0.25375670194625854
Validation loss: 2.127018709977468

Epoch: 6| Step: 7
Training loss: 0.3752683997154236
Validation loss: 2.1883431673049927

Epoch: 6| Step: 8
Training loss: 0.4439910352230072
Validation loss: 2.1338196396827698

Epoch: 6| Step: 9
Training loss: 0.3608420193195343
Validation loss: 2.158160090446472

Epoch: 6| Step: 10
Training loss: 0.33972570300102234
Validation loss: 2.161196251710256

Epoch: 6| Step: 11
Training loss: 0.6062101125717163
Validation loss: 2.1985793908437095

Epoch: 6| Step: 12
Training loss: 0.26266783475875854
Validation loss: 2.163446764151255

Epoch: 6| Step: 13
Training loss: 0.5810039043426514
Validation loss: 2.2179913322130838

Epoch: 292| Step: 0
Training loss: 0.3702481985092163
Validation loss: 2.1955094734827676

Epoch: 6| Step: 1
Training loss: 0.41970503330230713
Validation loss: 2.1470349629720054

Epoch: 6| Step: 2
Training loss: 0.5244632959365845
Validation loss: 2.181972781817118

Epoch: 6| Step: 3
Training loss: 0.3121832311153412
Validation loss: 2.199725647767385

Epoch: 6| Step: 4
Training loss: 0.4333915710449219
Validation loss: 2.1457921663920083

Epoch: 6| Step: 5
Training loss: 0.5279911756515503
Validation loss: 2.1450326442718506

Epoch: 6| Step: 6
Training loss: 0.3971034288406372
Validation loss: 2.1200055678685508

Epoch: 6| Step: 7
Training loss: 0.28389567136764526
Validation loss: 2.161017199357351

Epoch: 6| Step: 8
Training loss: 0.5336143374443054
Validation loss: 2.18560121456782

Epoch: 6| Step: 9
Training loss: 0.6820557117462158
Validation loss: 2.1371960639953613

Epoch: 6| Step: 10
Training loss: 0.5843954086303711
Validation loss: 2.179780383904775

Epoch: 6| Step: 11
Training loss: 0.34520676732063293
Validation loss: 2.167325476805369

Epoch: 6| Step: 12
Training loss: 0.30770328640937805
Validation loss: 2.136625826358795

Epoch: 6| Step: 13
Training loss: 0.31399649381637573
Validation loss: 2.2017242709795632

Epoch: 293| Step: 0
Training loss: 0.33933308720588684
Validation loss: 2.1640138626098633

Epoch: 6| Step: 1
Training loss: 0.3138773441314697
Validation loss: 2.16473925113678

Epoch: 6| Step: 2
Training loss: 0.3681783080101013
Validation loss: 2.150029957294464

Epoch: 6| Step: 3
Training loss: 0.3515179753303528
Validation loss: 2.2117403944333396

Epoch: 6| Step: 4
Training loss: 0.338363379240036
Validation loss: 2.18665212392807

Epoch: 6| Step: 5
Training loss: 0.31442731618881226
Validation loss: 2.1377243796984353

Epoch: 6| Step: 6
Training loss: 0.2645365297794342
Validation loss: 2.187774141629537

Epoch: 6| Step: 7
Training loss: 0.8069494962692261
Validation loss: 2.1527281204859414

Epoch: 6| Step: 8
Training loss: 0.5021873712539673
Validation loss: 2.169947067896525

Epoch: 6| Step: 9
Training loss: 0.6406983137130737
Validation loss: 2.168526530265808

Epoch: 6| Step: 10
Training loss: 0.3981715142726898
Validation loss: 2.158199429512024

Epoch: 6| Step: 11
Training loss: 0.35387513041496277
Validation loss: 2.1667052110036216

Epoch: 6| Step: 12
Training loss: 0.5944636464118958
Validation loss: 2.1412017345428467

Epoch: 6| Step: 13
Training loss: 0.40650784969329834
Validation loss: 2.135296901067098

Epoch: 294| Step: 0
Training loss: 0.4847085475921631
Validation loss: 2.169984499613444

Epoch: 6| Step: 1
Training loss: 0.4288855195045471
Validation loss: 2.1243527928988137

Epoch: 6| Step: 2
Training loss: 0.3158700466156006
Validation loss: 2.1354909539222717

Epoch: 6| Step: 3
Training loss: 0.16510894894599915
Validation loss: 2.104774792989095

Epoch: 6| Step: 4
Training loss: 0.4108836054801941
Validation loss: 2.155127008756002

Epoch: 6| Step: 5
Training loss: 0.7880808115005493
Validation loss: 2.1155529419581094

Epoch: 6| Step: 6
Training loss: 0.3459407687187195
Validation loss: 2.156260867913564

Epoch: 6| Step: 7
Training loss: 0.45778244733810425
Validation loss: 2.1636519034703574

Epoch: 6| Step: 8
Training loss: 0.305637925863266
Validation loss: 2.1467113892237344

Epoch: 6| Step: 9
Training loss: 0.49253830313682556
Validation loss: 2.195460557937622

Epoch: 6| Step: 10
Training loss: 0.5125806331634521
Validation loss: 2.1494632760683694

Epoch: 6| Step: 11
Training loss: 0.5202538967132568
Validation loss: 2.1421867410341897

Epoch: 6| Step: 12
Training loss: 0.4127815365791321
Validation loss: 2.132600247859955

Epoch: 6| Step: 13
Training loss: 0.40983209013938904
Validation loss: 2.0940749247868857

Epoch: 295| Step: 0
Training loss: 0.4834754765033722
Validation loss: 2.146021048227946

Epoch: 6| Step: 1
Training loss: 0.33059000968933105
Validation loss: 2.1593746145566306

Epoch: 6| Step: 2
Training loss: 0.42831045389175415
Validation loss: 2.1649365226427713

Epoch: 6| Step: 3
Training loss: 0.5661789178848267
Validation loss: 2.129358927408854

Epoch: 6| Step: 4
Training loss: 0.5189546346664429
Validation loss: 2.197174926598867

Epoch: 6| Step: 5
Training loss: 0.7104028463363647
Validation loss: 2.1851287682851157

Epoch: 6| Step: 6
Training loss: 0.32588711380958557
Validation loss: 2.1640673875808716

Epoch: 6| Step: 7
Training loss: 0.4610285758972168
Validation loss: 2.1513230005900064

Epoch: 6| Step: 8
Training loss: 0.35067203640937805
Validation loss: 2.206536134084066

Epoch: 6| Step: 9
Training loss: 0.5098658800125122
Validation loss: 2.163551946481069

Epoch: 6| Step: 10
Training loss: 0.3438342213630676
Validation loss: 2.1516254345575967

Epoch: 6| Step: 11
Training loss: 0.5730665326118469
Validation loss: 2.1684387723604837

Epoch: 6| Step: 12
Training loss: 0.29118362069129944
Validation loss: 2.1534467339515686

Epoch: 6| Step: 13
Training loss: 0.18434017896652222
Validation loss: 2.184360941251119

Epoch: 296| Step: 0
Training loss: 0.6047682762145996
Validation loss: 2.1984694600105286

Epoch: 6| Step: 1
Training loss: 0.5025014877319336
Validation loss: 2.1522043546040854

Epoch: 6| Step: 2
Training loss: 0.27273041009902954
Validation loss: 2.1505740880966187

Epoch: 6| Step: 3
Training loss: 0.5426843762397766
Validation loss: 2.1441495617230735

Epoch: 6| Step: 4
Training loss: 0.6328368186950684
Validation loss: 2.1595760385195413

Epoch: 6| Step: 5
Training loss: 0.37220895290374756
Validation loss: 2.1382400592168174

Epoch: 6| Step: 6
Training loss: 0.4274202287197113
Validation loss: 2.147465229034424

Epoch: 6| Step: 7
Training loss: 0.22386875748634338
Validation loss: 2.1598464449246726

Epoch: 6| Step: 8
Training loss: 0.29816800355911255
Validation loss: 2.2123051484425864

Epoch: 6| Step: 9
Training loss: 0.26779621839523315
Validation loss: 2.184930920600891

Epoch: 6| Step: 10
Training loss: 0.42187419533729553
Validation loss: 2.221350530783335

Epoch: 6| Step: 11
Training loss: 0.26504606008529663
Validation loss: 2.197401762008667

Epoch: 6| Step: 12
Training loss: 0.290189266204834
Validation loss: 2.1918691794077554

Epoch: 6| Step: 13
Training loss: 0.2863493263721466
Validation loss: 2.17414398988088

Epoch: 297| Step: 0
Training loss: 0.2318047285079956
Validation loss: 2.1793789863586426

Epoch: 6| Step: 1
Training loss: 0.5665889382362366
Validation loss: 2.151380260785421

Epoch: 6| Step: 2
Training loss: 0.6386193633079529
Validation loss: 2.1583704352378845

Epoch: 6| Step: 3
Training loss: 0.394991934299469
Validation loss: 2.191178301970164

Epoch: 6| Step: 4
Training loss: 0.41392049193382263
Validation loss: 2.1655409932136536

Epoch: 6| Step: 5
Training loss: 0.6248637437820435
Validation loss: 2.2219186425209045

Epoch: 6| Step: 6
Training loss: 0.3792261481285095
Validation loss: 2.1953382094701133

Epoch: 6| Step: 7
Training loss: 0.2844963073730469
Validation loss: 2.2174199422200522

Epoch: 6| Step: 8
Training loss: 0.18542949855327606
Validation loss: 2.2015275756518045

Epoch: 6| Step: 9
Training loss: 0.5401201248168945
Validation loss: 2.2032336592674255

Epoch: 6| Step: 10
Training loss: 0.2160767763853073
Validation loss: 2.214871605237325

Epoch: 6| Step: 11
Training loss: 0.2551773488521576
Validation loss: 2.179786225159963

Epoch: 6| Step: 12
Training loss: 0.3830176889896393
Validation loss: 2.2594867746035256

Epoch: 6| Step: 13
Training loss: 0.5075042843818665
Validation loss: 2.223399023214976

Epoch: 298| Step: 0
Training loss: 0.6561800241470337
Validation loss: 2.1862534284591675

Epoch: 6| Step: 1
Training loss: 0.4588794410228729
Validation loss: 2.1502378384272256

Epoch: 6| Step: 2
Training loss: 0.29018422961235046
Validation loss: 2.152845859527588

Epoch: 6| Step: 3
Training loss: 0.25351524353027344
Validation loss: 2.199621578057607

Epoch: 6| Step: 4
Training loss: 0.4863905608654022
Validation loss: 2.232604165871938

Epoch: 6| Step: 5
Training loss: 0.4692191481590271
Validation loss: 2.2029646833737693

Epoch: 6| Step: 6
Training loss: 0.4048655033111572
Validation loss: 2.1924187938372293

Epoch: 6| Step: 7
Training loss: 0.2786980867385864
Validation loss: 2.222936828931173

Epoch: 6| Step: 8
Training loss: 0.516737699508667
Validation loss: 2.222418427467346

Epoch: 6| Step: 9
Training loss: 0.4449305832386017
Validation loss: 2.1894872585932412

Epoch: 6| Step: 10
Training loss: 0.3581874668598175
Validation loss: 2.1670461893081665

Epoch: 6| Step: 11
Training loss: 0.6753329634666443
Validation loss: 2.193639020125071

Epoch: 6| Step: 12
Training loss: 0.31780946254730225
Validation loss: 2.1662522753079734

Epoch: 6| Step: 13
Training loss: 0.3269018530845642
Validation loss: 2.1977757612864175

Epoch: 299| Step: 0
Training loss: 0.35686832666397095
Validation loss: 2.2093942364056907

Epoch: 6| Step: 1
Training loss: 0.17728681862354279
Validation loss: 2.241711914539337

Epoch: 6| Step: 2
Training loss: 0.4201808571815491
Validation loss: 2.182225783665975

Epoch: 6| Step: 3
Training loss: 0.673073410987854
Validation loss: 2.2037508686383567

Epoch: 6| Step: 4
Training loss: 0.33092886209487915
Validation loss: 2.188444177309672

Epoch: 6| Step: 5
Training loss: 0.6047266721725464
Validation loss: 2.195948362350464

Epoch: 6| Step: 6
Training loss: 0.4736010432243347
Validation loss: 2.166571338971456

Epoch: 6| Step: 7
Training loss: 0.24204036593437195
Validation loss: 2.193284571170807

Epoch: 6| Step: 8
Training loss: 0.6668450832366943
Validation loss: 2.1578309535980225

Epoch: 6| Step: 9
Training loss: 0.3038942217826843
Validation loss: 2.1757083336512246

Epoch: 6| Step: 10
Training loss: 0.32700586318969727
Validation loss: 2.2138015627861023

Epoch: 6| Step: 11
Training loss: 0.4411501884460449
Validation loss: 2.16227658589681

Epoch: 6| Step: 12
Training loss: 0.31274810433387756
Validation loss: 2.2241797844568887

Epoch: 6| Step: 13
Training loss: 0.2413095235824585
Validation loss: 2.145384589831034

Epoch: 300| Step: 0
Training loss: 0.31480756402015686
Validation loss: 2.191756010055542

Epoch: 6| Step: 1
Training loss: 0.2502523362636566
Validation loss: 2.1759190956751504

Epoch: 6| Step: 2
Training loss: 0.4013199210166931
Validation loss: 2.1990412871042886

Epoch: 6| Step: 3
Training loss: 0.23137575387954712
Validation loss: 2.2032313545544944

Epoch: 6| Step: 4
Training loss: 0.7408890724182129
Validation loss: 2.18010143438975

Epoch: 6| Step: 5
Training loss: 0.5670260190963745
Validation loss: 2.1987186272939048

Epoch: 6| Step: 6
Training loss: 0.35326817631721497
Validation loss: 2.2565881609916687

Epoch: 6| Step: 7
Training loss: 0.3417817950248718
Validation loss: 2.211790382862091

Epoch: 6| Step: 8
Training loss: 0.44409066438674927
Validation loss: 2.192656139532725

Epoch: 6| Step: 9
Training loss: 0.499664306640625
Validation loss: 2.179794490337372

Epoch: 6| Step: 10
Training loss: 0.8211660385131836
Validation loss: 2.166560093561808

Epoch: 6| Step: 11
Training loss: 0.3396819829940796
Validation loss: 2.2048423091570535

Epoch: 6| Step: 12
Training loss: 0.37734392285346985
Validation loss: 2.1990225116411843

Epoch: 6| Step: 13
Training loss: 0.6431963443756104
Validation loss: 2.2744239568710327

Epoch: 301| Step: 0
Training loss: 0.2616058886051178
Validation loss: 2.2210483153661094

Epoch: 6| Step: 1
Training loss: 0.32181692123413086
Validation loss: 2.1664083003997803

Epoch: 6| Step: 2
Training loss: 0.7050204277038574
Validation loss: 2.1782206694285073

Epoch: 6| Step: 3
Training loss: 0.38023555278778076
Validation loss: 2.1534096002578735

Epoch: 6| Step: 4
Training loss: 0.37589865922927856
Validation loss: 2.184558610121409

Epoch: 6| Step: 5
Training loss: 0.3331868052482605
Validation loss: 2.1916041175524392

Epoch: 6| Step: 6
Training loss: 0.4613075256347656
Validation loss: 2.206521908442179

Epoch: 6| Step: 7
Training loss: 0.6522207856178284
Validation loss: 2.248770515124003

Epoch: 6| Step: 8
Training loss: 0.29862067103385925
Validation loss: 2.168133020401001

Epoch: 6| Step: 9
Training loss: 0.3538956642150879
Validation loss: 2.16588294506073

Epoch: 6| Step: 10
Training loss: 0.3475302457809448
Validation loss: 2.2153576612472534

Epoch: 6| Step: 11
Training loss: 0.4017814099788666
Validation loss: 2.1379655599594116

Epoch: 6| Step: 12
Training loss: 0.37913697957992554
Validation loss: 2.137980898221334

Epoch: 6| Step: 13
Training loss: 0.488505482673645
Validation loss: 2.1836968660354614

Epoch: 302| Step: 0
Training loss: 0.6027314066886902
Validation loss: 2.1793376207351685

Epoch: 6| Step: 1
Training loss: 0.4195764362812042
Validation loss: 2.1948288083076477

Epoch: 6| Step: 2
Training loss: 0.2805436849594116
Validation loss: 2.200322151184082

Epoch: 6| Step: 3
Training loss: 0.3522741198539734
Validation loss: 2.2533832788467407

Epoch: 6| Step: 4
Training loss: 0.5081424713134766
Validation loss: 2.242913842201233

Epoch: 6| Step: 5
Training loss: 0.39237743616104126
Validation loss: 2.240753650665283

Epoch: 6| Step: 6
Training loss: 0.3469294309616089
Validation loss: 2.272829214731852

Epoch: 6| Step: 7
Training loss: 0.2355833649635315
Validation loss: 2.226142247517904

Epoch: 6| Step: 8
Training loss: 0.31821173429489136
Validation loss: 2.146383762359619

Epoch: 6| Step: 9
Training loss: 0.4594095051288605
Validation loss: 2.176702558994293

Epoch: 6| Step: 10
Training loss: 0.35522669553756714
Validation loss: 2.1973612308502197

Epoch: 6| Step: 11
Training loss: 0.3470735549926758
Validation loss: 2.1920802195866904

Epoch: 6| Step: 12
Training loss: 0.44549673795700073
Validation loss: 2.2507270773251853

Epoch: 6| Step: 13
Training loss: 0.7587902545928955
Validation loss: 2.172532081604004

Epoch: 303| Step: 0
Training loss: 0.24032311141490936
Validation loss: 2.2227379083633423

Epoch: 6| Step: 1
Training loss: 0.3129235506057739
Validation loss: 2.224284529685974

Epoch: 6| Step: 2
Training loss: 0.5308367609977722
Validation loss: 2.2365400393803916

Epoch: 6| Step: 3
Training loss: 0.2350321114063263
Validation loss: 2.213232676188151

Epoch: 6| Step: 4
Training loss: 0.5721484422683716
Validation loss: 2.1529659827550254

Epoch: 6| Step: 5
Training loss: 0.26662230491638184
Validation loss: 2.1716126998265586

Epoch: 6| Step: 6
Training loss: 0.3475799560546875
Validation loss: 2.1414307753245034

Epoch: 6| Step: 7
Training loss: 0.4385823905467987
Validation loss: 2.2546308437983194

Epoch: 6| Step: 8
Training loss: 0.2228638231754303
Validation loss: 2.2373609145482383

Epoch: 6| Step: 9
Training loss: 0.8173487186431885
Validation loss: 2.192437748114268

Epoch: 6| Step: 10
Training loss: 0.32890585064888
Validation loss: 2.1732856035232544

Epoch: 6| Step: 11
Training loss: 0.45004284381866455
Validation loss: 2.1854828794797263

Epoch: 6| Step: 12
Training loss: 0.3997999131679535
Validation loss: 2.165657083193461

Epoch: 6| Step: 13
Training loss: 0.40472251176834106
Validation loss: 2.139810840288798

Epoch: 304| Step: 0
Training loss: 0.5111231803894043
Validation loss: 2.1121866106987

Epoch: 6| Step: 1
Training loss: 0.590377688407898
Validation loss: 2.1556944052378335

Epoch: 6| Step: 2
Training loss: 0.4662783145904541
Validation loss: 2.18638281027476

Epoch: 6| Step: 3
Training loss: 0.2387632131576538
Validation loss: 2.233011225859324

Epoch: 6| Step: 4
Training loss: 0.31005480885505676
Validation loss: 2.165518303712209

Epoch: 6| Step: 5
Training loss: 0.46870139241218567
Validation loss: 2.25443967183431

Epoch: 6| Step: 6
Training loss: 0.49413222074508667
Validation loss: 2.2194221019744873

Epoch: 6| Step: 7
Training loss: 0.3512106239795685
Validation loss: 2.225954254468282

Epoch: 6| Step: 8
Training loss: 0.7750917077064514
Validation loss: 2.1874191761016846

Epoch: 6| Step: 9
Training loss: 0.3129991292953491
Validation loss: 2.17792671918869

Epoch: 6| Step: 10
Training loss: 0.3068057894706726
Validation loss: 2.178388237953186

Epoch: 6| Step: 11
Training loss: 0.669528067111969
Validation loss: 2.089990973472595

Epoch: 6| Step: 12
Training loss: 0.39597970247268677
Validation loss: 2.1716933250427246

Epoch: 6| Step: 13
Training loss: 0.20528236031532288
Validation loss: 2.190163334210714

Epoch: 305| Step: 0
Training loss: 0.5801289081573486
Validation loss: 2.2410759131113687

Epoch: 6| Step: 1
Training loss: 0.3797200620174408
Validation loss: 2.1602453788121543

Epoch: 6| Step: 2
Training loss: 0.5368463397026062
Validation loss: 2.190142830212911

Epoch: 6| Step: 3
Training loss: 0.2696678042411804
Validation loss: 2.115572472413381

Epoch: 6| Step: 4
Training loss: 0.968397855758667
Validation loss: 2.15285716454188

Epoch: 6| Step: 5
Training loss: 0.5358901023864746
Validation loss: 2.137848377227783

Epoch: 6| Step: 6
Training loss: 0.4122471213340759
Validation loss: 2.153924286365509

Epoch: 6| Step: 7
Training loss: 0.3273372948169708
Validation loss: 2.1523150404294333

Epoch: 6| Step: 8
Training loss: 0.34484440088272095
Validation loss: 2.1884729862213135

Epoch: 6| Step: 9
Training loss: 0.4740719795227051
Validation loss: 2.245174288749695

Epoch: 6| Step: 10
Training loss: 0.5515060424804688
Validation loss: 2.26889306306839

Epoch: 6| Step: 11
Training loss: 0.5622959136962891
Validation loss: 2.22703754901886

Epoch: 6| Step: 12
Training loss: 0.3595440983772278
Validation loss: 2.2402340372403464

Epoch: 6| Step: 13
Training loss: 0.29039257764816284
Validation loss: 2.1336111227671304

Epoch: 306| Step: 0
Training loss: 0.4437160789966583
Validation loss: 2.1848029692967734

Epoch: 6| Step: 1
Training loss: 0.5423643589019775
Validation loss: 2.1351959506670632

Epoch: 6| Step: 2
Training loss: 0.30265381932258606
Validation loss: 2.1775943835576377

Epoch: 6| Step: 3
Training loss: 0.2868901789188385
Validation loss: 2.2227781812349954

Epoch: 6| Step: 4
Training loss: 0.7273770570755005
Validation loss: 2.168468435605367

Epoch: 6| Step: 5
Training loss: 0.6272754073143005
Validation loss: 2.2333221435546875

Epoch: 6| Step: 6
Training loss: 0.46363216638565063
Validation loss: 2.2637460827827454

Epoch: 6| Step: 7
Training loss: 0.7167255282402039
Validation loss: 2.212335725625356

Epoch: 6| Step: 8
Training loss: 0.3028433918952942
Validation loss: 2.166109581788381

Epoch: 6| Step: 9
Training loss: 0.27948978543281555
Validation loss: 2.2068349917729697

Epoch: 6| Step: 10
Training loss: 0.3440456986427307
Validation loss: 2.158485233783722

Epoch: 6| Step: 11
Training loss: 0.320188969373703
Validation loss: 2.1656760970751443

Epoch: 6| Step: 12
Training loss: 0.3072476387023926
Validation loss: 2.1860527793566384

Epoch: 6| Step: 13
Training loss: 0.24528276920318604
Validation loss: 2.2036659518877664

Epoch: 307| Step: 0
Training loss: 0.4739554822444916
Validation loss: 2.234522600968679

Epoch: 6| Step: 1
Training loss: 0.3762015700340271
Validation loss: 2.227022031943003

Epoch: 6| Step: 2
Training loss: 0.35047346353530884
Validation loss: 2.1971150040626526

Epoch: 6| Step: 3
Training loss: 0.23972493410110474
Validation loss: 2.212114950021108

Epoch: 6| Step: 4
Training loss: 0.6504311561584473
Validation loss: 2.171709398428599

Epoch: 6| Step: 5
Training loss: 0.20829620957374573
Validation loss: 2.1746254762013755

Epoch: 6| Step: 6
Training loss: 0.21153073012828827
Validation loss: 2.2025705178578696

Epoch: 6| Step: 7
Training loss: 0.35399991273880005
Validation loss: 2.1791575948397317

Epoch: 6| Step: 8
Training loss: 0.33728811144828796
Validation loss: 2.143004059791565

Epoch: 6| Step: 9
Training loss: 0.33720916509628296
Validation loss: 2.192770083745321

Epoch: 6| Step: 10
Training loss: 0.7438951730728149
Validation loss: 2.2094178199768066

Epoch: 6| Step: 11
Training loss: 0.2651340365409851
Validation loss: 2.1926845709482827

Epoch: 6| Step: 12
Training loss: 0.33877912163734436
Validation loss: 2.243637522061666

Epoch: 6| Step: 13
Training loss: 0.21583786606788635
Validation loss: 2.1726839343706765

Epoch: 308| Step: 0
Training loss: 0.3914622962474823
Validation loss: 2.1653348803520203

Epoch: 6| Step: 1
Training loss: 0.3443479537963867
Validation loss: 2.165016233921051

Epoch: 6| Step: 2
Training loss: 0.29901832342147827
Validation loss: 2.1669889291127524

Epoch: 6| Step: 3
Training loss: 0.9611770510673523
Validation loss: 2.200053413709005

Epoch: 6| Step: 4
Training loss: 0.4406127631664276
Validation loss: 2.250463624795278

Epoch: 6| Step: 5
Training loss: 0.2806965410709381
Validation loss: 2.227181692918142

Epoch: 6| Step: 6
Training loss: 0.45673322677612305
Validation loss: 2.1813040574391684

Epoch: 6| Step: 7
Training loss: 0.31463423371315
Validation loss: 2.1961522698402405

Epoch: 6| Step: 8
Training loss: 0.30055952072143555
Validation loss: 2.187149246533712

Epoch: 6| Step: 9
Training loss: 0.30862802267074585
Validation loss: 2.171040137608846

Epoch: 6| Step: 10
Training loss: 0.4495338201522827
Validation loss: 2.1934000651041665

Epoch: 6| Step: 11
Training loss: 0.524479329586029
Validation loss: 2.1608398159344993

Epoch: 6| Step: 12
Training loss: 0.26692765951156616
Validation loss: 2.209277013937632

Epoch: 6| Step: 13
Training loss: 0.2907528579235077
Validation loss: 2.243807375431061

Epoch: 309| Step: 0
Training loss: 0.3093293607234955
Validation loss: 2.2530234654744468

Epoch: 6| Step: 1
Training loss: 0.5471023917198181
Validation loss: 2.213627060254415

Epoch: 6| Step: 2
Training loss: 0.7477986812591553
Validation loss: 2.1972036163012185

Epoch: 6| Step: 3
Training loss: 0.30452075600624084
Validation loss: 2.209887206554413

Epoch: 6| Step: 4
Training loss: 0.6354129314422607
Validation loss: 2.1667062242825827

Epoch: 6| Step: 5
Training loss: 0.2050369381904602
Validation loss: 2.188829263051351

Epoch: 6| Step: 6
Training loss: 0.29644775390625
Validation loss: 2.1709032456080117

Epoch: 6| Step: 7
Training loss: 0.4014153480529785
Validation loss: 2.175011853377024

Epoch: 6| Step: 8
Training loss: 0.28160566091537476
Validation loss: 2.2556729714075723

Epoch: 6| Step: 9
Training loss: 0.41630464792251587
Validation loss: 2.227411389350891

Epoch: 6| Step: 10
Training loss: 0.8163648247718811
Validation loss: 2.248303492863973

Epoch: 6| Step: 11
Training loss: 0.26253288984298706
Validation loss: 2.176768203576406

Epoch: 6| Step: 12
Training loss: 0.4431118965148926
Validation loss: 2.1612143317858377

Epoch: 6| Step: 13
Training loss: 0.25993525981903076
Validation loss: 2.1798320213953652

Epoch: 310| Step: 0
Training loss: 0.49085453152656555
Validation loss: 2.1560476223627725

Epoch: 6| Step: 1
Training loss: 0.2967284321784973
Validation loss: 2.1570702393849692

Epoch: 6| Step: 2
Training loss: 0.5608426928520203
Validation loss: 2.2118312319119773

Epoch: 6| Step: 3
Training loss: 0.2420017272233963
Validation loss: 2.226901332537333

Epoch: 6| Step: 4
Training loss: 0.2324989289045334
Validation loss: 2.168098032474518

Epoch: 6| Step: 5
Training loss: 0.4279462695121765
Validation loss: 2.225300947825114

Epoch: 6| Step: 6
Training loss: 0.31315815448760986
Validation loss: 2.1952322125434875

Epoch: 6| Step: 7
Training loss: 0.7509967684745789
Validation loss: 2.1917747060457864

Epoch: 6| Step: 8
Training loss: 0.6950090527534485
Validation loss: 2.2119664947191873

Epoch: 6| Step: 9
Training loss: 0.23462322354316711
Validation loss: 2.2039626240730286

Epoch: 6| Step: 10
Training loss: 0.30537936091423035
Validation loss: 2.1572236816088357

Epoch: 6| Step: 11
Training loss: 0.3113577365875244
Validation loss: 2.1851189136505127

Epoch: 6| Step: 12
Training loss: 0.2586081922054291
Validation loss: 2.179183026154836

Epoch: 6| Step: 13
Training loss: 0.3629579544067383
Validation loss: 2.1694922844568887

Epoch: 311| Step: 0
Training loss: 0.42219918966293335
Validation loss: 2.160407225290934

Epoch: 6| Step: 1
Training loss: 0.36694133281707764
Validation loss: 2.202734808127085

Epoch: 6| Step: 2
Training loss: 0.2545657455921173
Validation loss: 2.2078822453816733

Epoch: 6| Step: 3
Training loss: 0.8781959414482117
Validation loss: 2.192321221033732

Epoch: 6| Step: 4
Training loss: 0.41263872385025024
Validation loss: 2.1618091066678367

Epoch: 6| Step: 5
Training loss: 0.19637611508369446
Validation loss: 2.2488012115160623

Epoch: 6| Step: 6
Training loss: 0.31924140453338623
Validation loss: 2.221362849076589

Epoch: 6| Step: 7
Training loss: 0.4465005695819855
Validation loss: 2.289885620276133

Epoch: 6| Step: 8
Training loss: 0.30680596828460693
Validation loss: 2.246027092138926

Epoch: 6| Step: 9
Training loss: 0.4577743411064148
Validation loss: 2.180678963661194

Epoch: 6| Step: 10
Training loss: 0.31361857056617737
Validation loss: 2.1435336669286094

Epoch: 6| Step: 11
Training loss: 0.34348732233047485
Validation loss: 2.1860994895299277

Epoch: 6| Step: 12
Training loss: 0.40787893533706665
Validation loss: 2.171103815237681

Epoch: 6| Step: 13
Training loss: 0.3693273663520813
Validation loss: 2.178793748219808

Epoch: 312| Step: 0
Training loss: 0.8101153373718262
Validation loss: 2.194780627886454

Epoch: 6| Step: 1
Training loss: 0.349242627620697
Validation loss: 2.157402535279592

Epoch: 6| Step: 2
Training loss: 0.3846150040626526
Validation loss: 2.173534373442332

Epoch: 6| Step: 3
Training loss: 0.5010617971420288
Validation loss: 2.176379124323527

Epoch: 6| Step: 4
Training loss: 0.3227103352546692
Validation loss: 2.205442229906718

Epoch: 6| Step: 5
Training loss: 0.4462389349937439
Validation loss: 2.135915219783783

Epoch: 6| Step: 6
Training loss: 0.6382832527160645
Validation loss: 2.1274708906809487

Epoch: 6| Step: 7
Training loss: 0.33788108825683594
Validation loss: 2.1518727938334146

Epoch: 6| Step: 8
Training loss: 0.4843602776527405
Validation loss: 2.1908332109451294

Epoch: 6| Step: 9
Training loss: 0.3876347839832306
Validation loss: 2.1341710885365806

Epoch: 6| Step: 10
Training loss: 0.2645048499107361
Validation loss: 2.1753063599268594

Epoch: 6| Step: 11
Training loss: 0.3046146035194397
Validation loss: 2.154663602511088

Epoch: 6| Step: 12
Training loss: 0.22001776099205017
Validation loss: 2.163432796796163

Epoch: 6| Step: 13
Training loss: 0.20145490765571594
Validation loss: 2.1490001479784646

Epoch: 313| Step: 0
Training loss: 0.38228297233581543
Validation loss: 2.188509166240692

Epoch: 6| Step: 1
Training loss: 0.22837543487548828
Validation loss: 2.2255093653996787

Epoch: 6| Step: 2
Training loss: 0.3007921576499939
Validation loss: 2.2322492202123008

Epoch: 6| Step: 3
Training loss: 0.410363107919693
Validation loss: 2.224333167076111

Epoch: 6| Step: 4
Training loss: 0.48658719658851624
Validation loss: 2.187678416570028

Epoch: 6| Step: 5
Training loss: 0.4422294795513153
Validation loss: 2.154310703277588

Epoch: 6| Step: 6
Training loss: 0.4023173749446869
Validation loss: 2.136847217877706

Epoch: 6| Step: 7
Training loss: 0.4319819211959839
Validation loss: 2.1554425954818726

Epoch: 6| Step: 8
Training loss: 0.689558207988739
Validation loss: 2.1434642672538757

Epoch: 6| Step: 9
Training loss: 0.4734250605106354
Validation loss: 2.1743497053782144

Epoch: 6| Step: 10
Training loss: 0.2780601978302002
Validation loss: 2.129732131958008

Epoch: 6| Step: 11
Training loss: 0.31800925731658936
Validation loss: 2.1916977564493814

Epoch: 6| Step: 12
Training loss: 0.6725621223449707
Validation loss: 2.228676954905192

Epoch: 6| Step: 13
Training loss: 0.46787720918655396
Validation loss: 2.20957221587499

Epoch: 314| Step: 0
Training loss: 0.23568059504032135
Validation loss: 2.160152037938436

Epoch: 6| Step: 1
Training loss: 0.2640356421470642
Validation loss: 2.1680803298950195

Epoch: 6| Step: 2
Training loss: 0.33866268396377563
Validation loss: 2.103963255882263

Epoch: 6| Step: 3
Training loss: 0.4029642343521118
Validation loss: 2.123475809892019

Epoch: 6| Step: 4
Training loss: 0.28390294313430786
Validation loss: 2.1246936519940696

Epoch: 6| Step: 5
Training loss: 0.5115248560905457
Validation loss: 2.181592027346293

Epoch: 6| Step: 6
Training loss: 0.4642621576786041
Validation loss: 2.2161510388056436

Epoch: 6| Step: 7
Training loss: 0.5924127697944641
Validation loss: 2.207388997077942

Epoch: 6| Step: 8
Training loss: 0.2795955538749695
Validation loss: 2.186703105767568

Epoch: 6| Step: 9
Training loss: 0.38292673230171204
Validation loss: 2.1941856145858765

Epoch: 6| Step: 10
Training loss: 0.3230020999908447
Validation loss: 2.1605228384335837

Epoch: 6| Step: 11
Training loss: 0.3629230260848999
Validation loss: 2.174927592277527

Epoch: 6| Step: 12
Training loss: 0.7295181751251221
Validation loss: 2.1393381555875144

Epoch: 6| Step: 13
Training loss: 0.4570199251174927
Validation loss: 2.0963500142097473

Epoch: 315| Step: 0
Training loss: 0.3709104061126709
Validation loss: 2.1376200318336487

Epoch: 6| Step: 1
Training loss: 0.670417308807373
Validation loss: 2.128642717997233

Epoch: 6| Step: 2
Training loss: 0.297279953956604
Validation loss: 2.151734391848246

Epoch: 6| Step: 3
Training loss: 0.26629048585891724
Validation loss: 2.2011518478393555

Epoch: 6| Step: 4
Training loss: 0.38199588656425476
Validation loss: 2.154362161954244

Epoch: 6| Step: 5
Training loss: 0.5866057872772217
Validation loss: 2.1876832048098245

Epoch: 6| Step: 6
Training loss: 0.26156896352767944
Validation loss: 2.179450492064158

Epoch: 6| Step: 7
Training loss: 0.48856407403945923
Validation loss: 2.147930939992269

Epoch: 6| Step: 8
Training loss: 0.4940204620361328
Validation loss: 2.1520778934160867

Epoch: 6| Step: 9
Training loss: 0.3813598155975342
Validation loss: 2.1287330786387124

Epoch: 6| Step: 10
Training loss: 0.534153938293457
Validation loss: 2.1484244664510093

Epoch: 6| Step: 11
Training loss: 0.38761475682258606
Validation loss: 2.1121615370114646

Epoch: 6| Step: 12
Training loss: 0.2399514615535736
Validation loss: 2.1665266950925193

Epoch: 6| Step: 13
Training loss: 0.6492953300476074
Validation loss: 2.151850720246633

Epoch: 316| Step: 0
Training loss: 0.45081910490989685
Validation loss: 2.206876595815023

Epoch: 6| Step: 1
Training loss: 0.3813108801841736
Validation loss: 2.1857782999674478

Epoch: 6| Step: 2
Training loss: 0.2671583294868469
Validation loss: 2.2042916218439736

Epoch: 6| Step: 3
Training loss: 0.3634704649448395
Validation loss: 2.1430946787198386

Epoch: 6| Step: 4
Training loss: 0.484602153301239
Validation loss: 2.1517690618832908

Epoch: 6| Step: 5
Training loss: 0.5173293948173523
Validation loss: 2.1097150643666587

Epoch: 6| Step: 6
Training loss: 0.3503740429878235
Validation loss: 2.2134379148483276

Epoch: 6| Step: 7
Training loss: 0.40828266739845276
Validation loss: 2.2017817894617715

Epoch: 6| Step: 8
Training loss: 0.8454321622848511
Validation loss: 2.228552500406901

Epoch: 6| Step: 9
Training loss: 1.0996571779251099
Validation loss: 2.27696684996287

Epoch: 6| Step: 10
Training loss: 0.5071732401847839
Validation loss: 2.2841005523999534

Epoch: 6| Step: 11
Training loss: 0.21415290236473083
Validation loss: 2.2310626109441123

Epoch: 6| Step: 12
Training loss: 0.29005444049835205
Validation loss: 2.166828155517578

Epoch: 6| Step: 13
Training loss: 0.27610868215560913
Validation loss: 2.1987483302752175

Epoch: 317| Step: 0
Training loss: 0.2304205596446991
Validation loss: 2.1470908522605896

Epoch: 6| Step: 1
Training loss: 0.44107478857040405
Validation loss: 2.1926321585973105

Epoch: 6| Step: 2
Training loss: 0.20537248253822327
Validation loss: 2.1571770906448364

Epoch: 6| Step: 3
Training loss: 0.3244158625602722
Validation loss: 2.1918864647547402

Epoch: 6| Step: 4
Training loss: 0.26167476177215576
Validation loss: 2.2157827417055764

Epoch: 6| Step: 5
Training loss: 0.3125430643558502
Validation loss: 2.2133021553357444

Epoch: 6| Step: 6
Training loss: 0.5583044290542603
Validation loss: 2.2314062118530273

Epoch: 6| Step: 7
Training loss: 0.3247390389442444
Validation loss: 2.2163250843683877

Epoch: 6| Step: 8
Training loss: 0.3947140574455261
Validation loss: 2.2176526387532554

Epoch: 6| Step: 9
Training loss: 0.34588098526000977
Validation loss: 2.1797884901364646

Epoch: 6| Step: 10
Training loss: 0.2710171043872833
Validation loss: 2.176140308380127

Epoch: 6| Step: 11
Training loss: 0.8528128862380981
Validation loss: 2.1296786864598594

Epoch: 6| Step: 12
Training loss: 0.710803747177124
Validation loss: 2.159576098124186

Epoch: 6| Step: 13
Training loss: 0.4557816684246063
Validation loss: 2.154523770014445

Epoch: 318| Step: 0
Training loss: 0.4717891812324524
Validation loss: 2.193110446135203

Epoch: 6| Step: 1
Training loss: 0.32653847336769104
Validation loss: 2.1309131582578025

Epoch: 6| Step: 2
Training loss: 0.375593364238739
Validation loss: 2.1889807184537253

Epoch: 6| Step: 3
Training loss: 0.7571686506271362
Validation loss: 2.158605774243673

Epoch: 6| Step: 4
Training loss: 0.2953435778617859
Validation loss: 2.1582321325937905

Epoch: 6| Step: 5
Training loss: 0.3326195478439331
Validation loss: 2.169343968232473

Epoch: 6| Step: 6
Training loss: 0.31321632862091064
Validation loss: 2.159120559692383

Epoch: 6| Step: 7
Training loss: 0.4089972972869873
Validation loss: 2.177695353825887

Epoch: 6| Step: 8
Training loss: 0.3882480561733246
Validation loss: 2.152032732963562

Epoch: 6| Step: 9
Training loss: 0.3161466419696808
Validation loss: 2.1575196186701455

Epoch: 6| Step: 10
Training loss: 0.20868057012557983
Validation loss: 2.156779627005259

Epoch: 6| Step: 11
Training loss: 0.2836867570877075
Validation loss: 2.180556376775106

Epoch: 6| Step: 12
Training loss: 1.0099281072616577
Validation loss: 2.187618613243103

Epoch: 6| Step: 13
Training loss: 0.2816286087036133
Validation loss: 2.21906187136968

Epoch: 319| Step: 0
Training loss: 0.37402111291885376
Validation loss: 2.2220462560653687

Epoch: 6| Step: 1
Training loss: 0.22944781184196472
Validation loss: 2.1602288683255515

Epoch: 6| Step: 2
Training loss: 0.45781153440475464
Validation loss: 2.12241131067276

Epoch: 6| Step: 3
Training loss: 0.29126548767089844
Validation loss: 2.1447478532791138

Epoch: 6| Step: 4
Training loss: 0.34843695163726807
Validation loss: 2.1350939671198526

Epoch: 6| Step: 5
Training loss: 0.21740810573101044
Validation loss: 2.1482760906219482

Epoch: 6| Step: 6
Training loss: 0.26853543519973755
Validation loss: 2.2214667002360025

Epoch: 6| Step: 7
Training loss: 0.3801034688949585
Validation loss: 2.158638854821523

Epoch: 6| Step: 8
Training loss: 0.37715697288513184
Validation loss: 2.1857189337412515

Epoch: 6| Step: 9
Training loss: 0.929336428642273
Validation loss: 2.1863554318745932

Epoch: 6| Step: 10
Training loss: 0.3538669943809509
Validation loss: 2.1500446995099387

Epoch: 6| Step: 11
Training loss: 0.2718322277069092
Validation loss: 2.161759595076243

Epoch: 6| Step: 12
Training loss: 0.586185872554779
Validation loss: 2.1399888594945273

Epoch: 6| Step: 13
Training loss: 0.43073558807373047
Validation loss: 2.1816017826398215

Epoch: 320| Step: 0
Training loss: 0.3373757600784302
Validation loss: 2.203916827837626

Epoch: 6| Step: 1
Training loss: 0.17306452989578247
Validation loss: 2.1687580943107605

Epoch: 6| Step: 2
Training loss: 0.2163429856300354
Validation loss: 2.1981738805770874

Epoch: 6| Step: 3
Training loss: 0.37316393852233887
Validation loss: 2.1755014657974243

Epoch: 6| Step: 4
Training loss: 0.4710004925727844
Validation loss: 2.181860367457072

Epoch: 6| Step: 5
Training loss: 0.2260517179965973
Validation loss: 2.1900146206219993

Epoch: 6| Step: 6
Training loss: 0.41082310676574707
Validation loss: 2.118180433909098

Epoch: 6| Step: 7
Training loss: 0.4195919334888458
Validation loss: 2.162548085053762

Epoch: 6| Step: 8
Training loss: 0.5883117914199829
Validation loss: 2.1765149235725403

Epoch: 6| Step: 9
Training loss: 0.6815515756607056
Validation loss: 2.189758618672689

Epoch: 6| Step: 10
Training loss: 0.45672523975372314
Validation loss: 2.0690547029177346

Epoch: 6| Step: 11
Training loss: 0.24626284837722778
Validation loss: 2.2078204353650412

Epoch: 6| Step: 12
Training loss: 0.27319061756134033
Validation loss: 2.21748948097229

Epoch: 6| Step: 13
Training loss: 0.35566288232803345
Validation loss: 2.214912017186483

Epoch: 321| Step: 0
Training loss: 0.14725817739963531
Validation loss: 2.205050806204478

Epoch: 6| Step: 1
Training loss: 0.2153664380311966
Validation loss: 2.1652552684148154

Epoch: 6| Step: 2
Training loss: 0.2353706657886505
Validation loss: 2.164353529612223

Epoch: 6| Step: 3
Training loss: 0.3467550277709961
Validation loss: 2.164771238962809

Epoch: 6| Step: 4
Training loss: 0.43138501048088074
Validation loss: 2.187909563382467

Epoch: 6| Step: 5
Training loss: 0.4172016382217407
Validation loss: 2.15536234776179

Epoch: 6| Step: 6
Training loss: 0.1769268959760666
Validation loss: 2.197993814945221

Epoch: 6| Step: 7
Training loss: 0.43110406398773193
Validation loss: 2.156620681285858

Epoch: 6| Step: 8
Training loss: 0.4054679572582245
Validation loss: 2.1439042687416077

Epoch: 6| Step: 9
Training loss: 0.6543814539909363
Validation loss: 2.1302430828412375

Epoch: 6| Step: 10
Training loss: 0.32060346007347107
Validation loss: 2.164284884929657

Epoch: 6| Step: 11
Training loss: 0.4365341365337372
Validation loss: 2.141074240207672

Epoch: 6| Step: 12
Training loss: 0.25499993562698364
Validation loss: 2.1714294155438743

Epoch: 6| Step: 13
Training loss: 0.6700353622436523
Validation loss: 2.1719106634457908

Epoch: 322| Step: 0
Training loss: 0.2950637936592102
Validation loss: 2.1408124764760337

Epoch: 6| Step: 1
Training loss: 0.22375373542308807
Validation loss: 2.12967312335968

Epoch: 6| Step: 2
Training loss: 0.2662598490715027
Validation loss: 2.101982851823171

Epoch: 6| Step: 3
Training loss: 0.4891984164714813
Validation loss: 2.1331794460614524

Epoch: 6| Step: 4
Training loss: 0.46626606583595276
Validation loss: 2.1288466652234397

Epoch: 6| Step: 5
Training loss: 0.4669843912124634
Validation loss: 2.1513872941335044

Epoch: 6| Step: 6
Training loss: 0.4141576588153839
Validation loss: 2.1300039688746133

Epoch: 6| Step: 7
Training loss: 0.21964532136917114
Validation loss: 2.2107134262720742

Epoch: 6| Step: 8
Training loss: 0.3494611382484436
Validation loss: 2.1350165605545044

Epoch: 6| Step: 9
Training loss: 0.2505033016204834
Validation loss: 2.1681405107180276

Epoch: 6| Step: 10
Training loss: 0.7214924693107605
Validation loss: 2.134018043677012

Epoch: 6| Step: 11
Training loss: 0.2610229253768921
Validation loss: 2.1504260102907815

Epoch: 6| Step: 12
Training loss: 0.4863138794898987
Validation loss: 2.1336825092633567

Epoch: 6| Step: 13
Training loss: 0.3412478566169739
Validation loss: 2.1496650775273642

Epoch: 323| Step: 0
Training loss: 0.42424845695495605
Validation loss: 2.115643044312795

Epoch: 6| Step: 1
Training loss: 0.5759772658348083
Validation loss: 2.1661630670229592

Epoch: 6| Step: 2
Training loss: 0.3899824023246765
Validation loss: 2.1614955266316733

Epoch: 6| Step: 3
Training loss: 0.3428839147090912
Validation loss: 2.0812026460965476

Epoch: 6| Step: 4
Training loss: 0.5064614415168762
Validation loss: 2.137402911980947

Epoch: 6| Step: 5
Training loss: 0.3114507794380188
Validation loss: 2.1346543033917746

Epoch: 6| Step: 6
Training loss: 0.2611266076564789
Validation loss: 2.1512129505475364

Epoch: 6| Step: 7
Training loss: 0.3723432719707489
Validation loss: 2.1260981957117715

Epoch: 6| Step: 8
Training loss: 0.3352211117744446
Validation loss: 2.148040850957235

Epoch: 6| Step: 9
Training loss: 0.2641829550266266
Validation loss: 2.1036821603775024

Epoch: 6| Step: 10
Training loss: 0.6365325450897217
Validation loss: 2.1389490763346353

Epoch: 6| Step: 11
Training loss: 0.2668537497520447
Validation loss: 2.1638530691464744

Epoch: 6| Step: 12
Training loss: 0.25939375162124634
Validation loss: 2.2272860606511435

Epoch: 6| Step: 13
Training loss: 0.41333508491516113
Validation loss: 2.203921059767405

Epoch: 324| Step: 0
Training loss: 0.6189970970153809
Validation loss: 2.2116175293922424

Epoch: 6| Step: 1
Training loss: 0.2639646828174591
Validation loss: 2.194167892138163

Epoch: 6| Step: 2
Training loss: 0.3474956154823303
Validation loss: 2.1436185042063394

Epoch: 6| Step: 3
Training loss: 0.4926716983318329
Validation loss: 2.1156252225240073

Epoch: 6| Step: 4
Training loss: 0.8170806765556335
Validation loss: 2.1101510723431907

Epoch: 6| Step: 5
Training loss: 0.5605511665344238
Validation loss: 2.126986861228943

Epoch: 6| Step: 6
Training loss: 0.3878590166568756
Validation loss: 2.159388224283854

Epoch: 6| Step: 7
Training loss: 0.4359120726585388
Validation loss: 2.136241912841797

Epoch: 6| Step: 8
Training loss: 0.22200247645378113
Validation loss: 2.1619566480318704

Epoch: 6| Step: 9
Training loss: 0.3276023268699646
Validation loss: 2.1936211585998535

Epoch: 6| Step: 10
Training loss: 0.2622636556625366
Validation loss: 2.2122816244761148

Epoch: 6| Step: 11
Training loss: 0.4207812547683716
Validation loss: 2.1793601512908936

Epoch: 6| Step: 12
Training loss: 0.2795819640159607
Validation loss: 2.23016365369161

Epoch: 6| Step: 13
Training loss: 0.4498167634010315
Validation loss: 2.204982280731201

Epoch: 325| Step: 0
Training loss: 0.6487090587615967
Validation loss: 2.2142154773076377

Epoch: 6| Step: 1
Training loss: 0.4046460688114166
Validation loss: 2.176234722137451

Epoch: 6| Step: 2
Training loss: 0.28014880418777466
Validation loss: 2.169364273548126

Epoch: 6| Step: 3
Training loss: 0.5967605113983154
Validation loss: 2.229035218556722

Epoch: 6| Step: 4
Training loss: 0.46627897024154663
Validation loss: 2.183017611503601

Epoch: 6| Step: 5
Training loss: 0.49398690462112427
Validation loss: 2.2196046908696494

Epoch: 6| Step: 6
Training loss: 0.36212313175201416
Validation loss: 2.157397210597992

Epoch: 6| Step: 7
Training loss: 0.30112844705581665
Validation loss: 2.1862181425094604

Epoch: 6| Step: 8
Training loss: 0.5511231422424316
Validation loss: 2.1611447930336

Epoch: 6| Step: 9
Training loss: 0.4626871645450592
Validation loss: 2.1982422272364297

Epoch: 6| Step: 10
Training loss: 0.31758466362953186
Validation loss: 2.1328598459561667

Epoch: 6| Step: 11
Training loss: 0.28923696279525757
Validation loss: 2.19536825021108

Epoch: 6| Step: 12
Training loss: 0.3517010807991028
Validation loss: 2.200275977452596

Epoch: 6| Step: 13
Training loss: 0.41321104764938354
Validation loss: 2.2077320416768393

Epoch: 326| Step: 0
Training loss: 0.2246282398700714
Validation loss: 2.266366720199585

Epoch: 6| Step: 1
Training loss: 0.49966394901275635
Validation loss: 2.1961643298467

Epoch: 6| Step: 2
Training loss: 0.41331735253334045
Validation loss: 2.176571011543274

Epoch: 6| Step: 3
Training loss: 0.2470674216747284
Validation loss: 2.174383898576101

Epoch: 6| Step: 4
Training loss: 0.5752344131469727
Validation loss: 2.150704781214396

Epoch: 6| Step: 5
Training loss: 0.4123716950416565
Validation loss: 2.1185529232025146

Epoch: 6| Step: 6
Training loss: 0.47275394201278687
Validation loss: 2.171968181927999

Epoch: 6| Step: 7
Training loss: 0.31530484557151794
Validation loss: 2.159858783086141

Epoch: 6| Step: 8
Training loss: 0.6631202697753906
Validation loss: 2.2352998852729797

Epoch: 6| Step: 9
Training loss: 0.5270827412605286
Validation loss: 2.228359361489614

Epoch: 6| Step: 10
Training loss: 0.28026828169822693
Validation loss: 2.2732982436815896

Epoch: 6| Step: 11
Training loss: 0.3101571798324585
Validation loss: 2.197823961575826

Epoch: 6| Step: 12
Training loss: 0.42946526408195496
Validation loss: 2.2039408882459006

Epoch: 6| Step: 13
Training loss: 0.25566819310188293
Validation loss: 2.184822678565979

Epoch: 327| Step: 0
Training loss: 0.6710901260375977
Validation loss: 2.1154171427090964

Epoch: 6| Step: 1
Training loss: 0.44383174180984497
Validation loss: 2.193757712841034

Epoch: 6| Step: 2
Training loss: 0.7618556618690491
Validation loss: 2.1872271498044333

Epoch: 6| Step: 3
Training loss: 0.6949722170829773
Validation loss: 2.186116854349772

Epoch: 6| Step: 4
Training loss: 0.32227209210395813
Validation loss: 2.1832597653071084

Epoch: 6| Step: 5
Training loss: 0.333321750164032
Validation loss: 2.220035711924235

Epoch: 6| Step: 6
Training loss: 0.3887181878089905
Validation loss: 2.229318102200826

Epoch: 6| Step: 7
Training loss: 0.5282614827156067
Validation loss: 2.184990644454956

Epoch: 6| Step: 8
Training loss: 0.5540409088134766
Validation loss: 2.166795094807943

Epoch: 6| Step: 9
Training loss: 0.3206336498260498
Validation loss: 2.1545457442601523

Epoch: 6| Step: 10
Training loss: 0.3774760067462921
Validation loss: 2.1258985797564187

Epoch: 6| Step: 11
Training loss: 0.4404453635215759
Validation loss: 2.1160510778427124

Epoch: 6| Step: 12
Training loss: 0.42392611503601074
Validation loss: 2.1361594200134277

Epoch: 6| Step: 13
Training loss: 0.3411915600299835
Validation loss: 2.1462868650754294

Epoch: 328| Step: 0
Training loss: 0.3352299630641937
Validation loss: 2.186747908592224

Epoch: 6| Step: 1
Training loss: 0.38198211789131165
Validation loss: 2.1863547960917153

Epoch: 6| Step: 2
Training loss: 0.45832857489585876
Validation loss: 2.1663028995196023

Epoch: 6| Step: 3
Training loss: 0.491365909576416
Validation loss: 2.1452552676200867

Epoch: 6| Step: 4
Training loss: 0.3506811261177063
Validation loss: 2.175090471903483

Epoch: 6| Step: 5
Training loss: 0.5807095170021057
Validation loss: 2.1600016355514526

Epoch: 6| Step: 6
Training loss: 0.2995304763317108
Validation loss: 2.1807598074277244

Epoch: 6| Step: 7
Training loss: 0.4763537645339966
Validation loss: 2.1527079145113626

Epoch: 6| Step: 8
Training loss: 0.40450239181518555
Validation loss: 2.137353698412577

Epoch: 6| Step: 9
Training loss: 0.27905333042144775
Validation loss: 2.1066130002339682

Epoch: 6| Step: 10
Training loss: 0.27191823720932007
Validation loss: 2.181880613168081

Epoch: 6| Step: 11
Training loss: 0.2639877200126648
Validation loss: 2.141759475072225

Epoch: 6| Step: 12
Training loss: 0.16709357500076294
Validation loss: 2.2034020026524863

Epoch: 6| Step: 13
Training loss: 0.2372235208749771
Validation loss: 2.1775665879249573

Epoch: 329| Step: 0
Training loss: 0.4024025797843933
Validation loss: 2.136423945426941

Epoch: 6| Step: 1
Training loss: 0.2526405453681946
Validation loss: 2.1192549069722495

Epoch: 6| Step: 2
Training loss: 0.28537219762802124
Validation loss: 2.139291842778524

Epoch: 6| Step: 3
Training loss: 0.43638771772384644
Validation loss: 2.1315225958824158

Epoch: 6| Step: 4
Training loss: 0.36562806367874146
Validation loss: 2.0592063864072165

Epoch: 6| Step: 5
Training loss: 0.35622090101242065
Validation loss: 2.1502506931622825

Epoch: 6| Step: 6
Training loss: 0.3320639729499817
Validation loss: 2.1537864009539285

Epoch: 6| Step: 7
Training loss: 0.5808525681495667
Validation loss: 2.1469473441441855

Epoch: 6| Step: 8
Training loss: 0.2732725739479065
Validation loss: 2.1225180625915527

Epoch: 6| Step: 9
Training loss: 0.42759236693382263
Validation loss: 2.1504355867703757

Epoch: 6| Step: 10
Training loss: 0.33591291308403015
Validation loss: 2.1348137259483337

Epoch: 6| Step: 11
Training loss: 0.47511470317840576
Validation loss: 2.180664857228597

Epoch: 6| Step: 12
Training loss: 0.2617645859718323
Validation loss: 2.1785010496775308

Epoch: 6| Step: 13
Training loss: 0.5815494060516357
Validation loss: 2.103019674619039

Epoch: 330| Step: 0
Training loss: 0.2850956320762634
Validation loss: 2.0957089265187583

Epoch: 6| Step: 1
Training loss: 0.3267775774002075
Validation loss: 2.1636212865511575

Epoch: 6| Step: 2
Training loss: 0.759221613407135
Validation loss: 2.143662214279175

Epoch: 6| Step: 3
Training loss: 0.3602124750614166
Validation loss: 2.117351849873861

Epoch: 6| Step: 4
Training loss: 0.40852248668670654
Validation loss: 2.1519981622695923

Epoch: 6| Step: 5
Training loss: 0.2564479112625122
Validation loss: 2.1221142212549844

Epoch: 6| Step: 6
Training loss: 0.2811168432235718
Validation loss: 2.162652393182119

Epoch: 6| Step: 7
Training loss: 0.28850722312927246
Validation loss: 2.1809067924817405

Epoch: 6| Step: 8
Training loss: 0.36508649587631226
Validation loss: 2.166063368320465

Epoch: 6| Step: 9
Training loss: 0.26854413747787476
Validation loss: 2.2538320620854697

Epoch: 6| Step: 10
Training loss: 0.38355228304862976
Validation loss: 2.2039020458857217

Epoch: 6| Step: 11
Training loss: 0.6703295707702637
Validation loss: 2.2038877805074057

Epoch: 6| Step: 12
Training loss: 0.20233199000358582
Validation loss: 2.146198888619741

Epoch: 6| Step: 13
Training loss: 0.28990060091018677
Validation loss: 2.1660970648129783

Epoch: 331| Step: 0
Training loss: 0.5848790407180786
Validation loss: 2.15023410320282

Epoch: 6| Step: 1
Training loss: 0.2672692537307739
Validation loss: 2.165867726008097

Epoch: 6| Step: 2
Training loss: 0.2737855911254883
Validation loss: 2.1857263843218484

Epoch: 6| Step: 3
Training loss: 0.8196792602539062
Validation loss: 2.2037771940231323

Epoch: 6| Step: 4
Training loss: 0.2039036750793457
Validation loss: 2.184953490893046

Epoch: 6| Step: 5
Training loss: 0.3347626030445099
Validation loss: 2.160457730293274

Epoch: 6| Step: 6
Training loss: 0.4124515652656555
Validation loss: 2.1680047710736594

Epoch: 6| Step: 7
Training loss: 0.38528546690940857
Validation loss: 2.150769829750061

Epoch: 6| Step: 8
Training loss: 0.28759026527404785
Validation loss: 2.1244417627652488

Epoch: 6| Step: 9
Training loss: 0.24300046265125275
Validation loss: 2.2294466495513916

Epoch: 6| Step: 10
Training loss: 0.21926160156726837
Validation loss: 2.204081435998281

Epoch: 6| Step: 11
Training loss: 0.428771048784256
Validation loss: 2.1717931230862937

Epoch: 6| Step: 12
Training loss: 0.41908949613571167
Validation loss: 2.151367445786794

Epoch: 6| Step: 13
Training loss: 0.45629844069480896
Validation loss: 2.1875421603520713

Epoch: 332| Step: 0
Training loss: 0.3280318081378937
Validation loss: 2.17368092139562

Epoch: 6| Step: 1
Training loss: 0.4280329644680023
Validation loss: 2.219067931175232

Epoch: 6| Step: 2
Training loss: 0.6408602595329285
Validation loss: 2.1907641688982644

Epoch: 6| Step: 3
Training loss: 0.4352930784225464
Validation loss: 2.1621912320454917

Epoch: 6| Step: 4
Training loss: 0.44727736711502075
Validation loss: 2.171566446622213

Epoch: 6| Step: 5
Training loss: 0.32440558075904846
Validation loss: 2.1473152240117392

Epoch: 6| Step: 6
Training loss: 0.19655334949493408
Validation loss: 2.149250646432241

Epoch: 6| Step: 7
Training loss: 0.33282965421676636
Validation loss: 2.1614125768343606

Epoch: 6| Step: 8
Training loss: 0.22109031677246094
Validation loss: 2.171793778737386

Epoch: 6| Step: 9
Training loss: 0.2923034727573395
Validation loss: 2.14746230840683

Epoch: 6| Step: 10
Training loss: 0.3135668635368347
Validation loss: 2.201510230700175

Epoch: 6| Step: 11
Training loss: 0.4329448938369751
Validation loss: 2.203812042872111

Epoch: 6| Step: 12
Training loss: 0.5162021517753601
Validation loss: 2.158183455467224

Epoch: 6| Step: 13
Training loss: 0.16023418307304382
Validation loss: 2.1539708574612937

Epoch: 333| Step: 0
Training loss: 0.3101147413253784
Validation loss: 2.1197322408358255

Epoch: 6| Step: 1
Training loss: 0.7040811777114868
Validation loss: 2.1402759750684104

Epoch: 6| Step: 2
Training loss: 0.35154056549072266
Validation loss: 2.1351858377456665

Epoch: 6| Step: 3
Training loss: 0.248625248670578
Validation loss: 2.158628265062968

Epoch: 6| Step: 4
Training loss: 0.4000915586948395
Validation loss: 2.249087393283844

Epoch: 6| Step: 5
Training loss: 0.8025112152099609
Validation loss: 2.2041320403416953

Epoch: 6| Step: 6
Training loss: 0.30086472630500793
Validation loss: 2.1759244998296103

Epoch: 6| Step: 7
Training loss: 0.4239562153816223
Validation loss: 2.145381530125936

Epoch: 6| Step: 8
Training loss: 0.34021085500717163
Validation loss: 2.151442209879557

Epoch: 6| Step: 9
Training loss: 0.19220857322216034
Validation loss: 2.1527074178059897

Epoch: 6| Step: 10
Training loss: 0.372461199760437
Validation loss: 2.1363242665926614

Epoch: 6| Step: 11
Training loss: 0.37476128339767456
Validation loss: 2.127708653608958

Epoch: 6| Step: 12
Training loss: 0.24101150035858154
Validation loss: 2.1434311866760254

Epoch: 6| Step: 13
Training loss: 0.3204323649406433
Validation loss: 2.1740942001342773

Epoch: 334| Step: 0
Training loss: 0.45379263162612915
Validation loss: 2.187252402305603

Epoch: 6| Step: 1
Training loss: 0.3901311159133911
Validation loss: 2.206270178159078

Epoch: 6| Step: 2
Training loss: 0.6600887775421143
Validation loss: 2.1843764980634055

Epoch: 6| Step: 3
Training loss: 0.52922523021698
Validation loss: 2.1701557636260986

Epoch: 6| Step: 4
Training loss: 0.36808985471725464
Validation loss: 2.1494128505388894

Epoch: 6| Step: 5
Training loss: 0.32615211606025696
Validation loss: 2.1653302907943726

Epoch: 6| Step: 6
Training loss: 0.21716566383838654
Validation loss: 2.153234342734019

Epoch: 6| Step: 7
Training loss: 0.409882515668869
Validation loss: 2.2263428370157876

Epoch: 6| Step: 8
Training loss: 0.3665231466293335
Validation loss: 2.1639380852381387

Epoch: 6| Step: 9
Training loss: 0.3970230221748352
Validation loss: 2.131083329518636

Epoch: 6| Step: 10
Training loss: 0.2859494090080261
Validation loss: 2.204007546106974

Epoch: 6| Step: 11
Training loss: 0.4694287180900574
Validation loss: 2.1307597359021506

Epoch: 6| Step: 12
Training loss: 0.27166157960891724
Validation loss: 2.177973667780558

Epoch: 6| Step: 13
Training loss: 0.31294840574264526
Validation loss: 2.176659564177195

Epoch: 335| Step: 0
Training loss: 0.45608407258987427
Validation loss: 2.204614996910095

Epoch: 6| Step: 1
Training loss: 0.23097530007362366
Validation loss: 2.176004429658254

Epoch: 6| Step: 2
Training loss: 0.26021021604537964
Validation loss: 2.1786703864733377

Epoch: 6| Step: 3
Training loss: 0.30026277899742126
Validation loss: 2.181321303049723

Epoch: 6| Step: 4
Training loss: 0.5968740582466125
Validation loss: 2.1488041480382285

Epoch: 6| Step: 5
Training loss: 0.4399692714214325
Validation loss: 2.1571897864341736

Epoch: 6| Step: 6
Training loss: 0.21663600206375122
Validation loss: 2.1573349634806314

Epoch: 6| Step: 7
Training loss: 0.5762382745742798
Validation loss: 2.1653383572896323

Epoch: 6| Step: 8
Training loss: 0.2604247033596039
Validation loss: 2.1433581908543906

Epoch: 6| Step: 9
Training loss: 0.5549968481063843
Validation loss: 2.148104270299276

Epoch: 6| Step: 10
Training loss: 0.18231403827667236
Validation loss: 2.186637202898661

Epoch: 6| Step: 11
Training loss: 0.33833083510398865
Validation loss: 2.165883958339691

Epoch: 6| Step: 12
Training loss: 0.4341421127319336
Validation loss: 2.152941723664602

Epoch: 6| Step: 13
Training loss: 0.4000758230686188
Validation loss: 2.147855977217356

Epoch: 336| Step: 0
Training loss: 0.3065617084503174
Validation loss: 2.1279038190841675

Epoch: 6| Step: 1
Training loss: 0.23175138235092163
Validation loss: 2.1653926769892373

Epoch: 6| Step: 2
Training loss: 0.2868998646736145
Validation loss: 2.148440877596537

Epoch: 6| Step: 3
Training loss: 0.4070097506046295
Validation loss: 2.12840070327123

Epoch: 6| Step: 4
Training loss: 0.29663121700286865
Validation loss: 2.1854023933410645

Epoch: 6| Step: 5
Training loss: 0.37755024433135986
Validation loss: 2.179584781328837

Epoch: 6| Step: 6
Training loss: 0.4343163073062897
Validation loss: 2.2158771753311157

Epoch: 6| Step: 7
Training loss: 0.16627314686775208
Validation loss: 2.1315077940622964

Epoch: 6| Step: 8
Training loss: 0.3463234603404999
Validation loss: 2.147446652253469

Epoch: 6| Step: 9
Training loss: 0.38992181420326233
Validation loss: 2.1801361441612244

Epoch: 6| Step: 10
Training loss: 0.2866198718547821
Validation loss: 2.1553555528322854

Epoch: 6| Step: 11
Training loss: 0.3254949450492859
Validation loss: 2.1138118704160056

Epoch: 6| Step: 12
Training loss: 0.7476629614830017
Validation loss: 2.13184247414271

Epoch: 6| Step: 13
Training loss: 0.2537936568260193
Validation loss: 2.1772534251213074

Epoch: 337| Step: 0
Training loss: 0.3264296054840088
Validation loss: 2.16664848725001

Epoch: 6| Step: 1
Training loss: 0.3175346255302429
Validation loss: 2.2132012844085693

Epoch: 6| Step: 2
Training loss: 0.7431583404541016
Validation loss: 2.180782357851664

Epoch: 6| Step: 3
Training loss: 0.26670706272125244
Validation loss: 2.1357383926709494

Epoch: 6| Step: 4
Training loss: 0.3818482756614685
Validation loss: 2.1148009300231934

Epoch: 6| Step: 5
Training loss: 0.2810976207256317
Validation loss: 2.1025272210439048

Epoch: 6| Step: 6
Training loss: 0.2455025613307953
Validation loss: 2.1456431945165

Epoch: 6| Step: 7
Training loss: 0.5909214019775391
Validation loss: 2.1832028230031333

Epoch: 6| Step: 8
Training loss: 0.2653537690639496
Validation loss: 2.1549147566159568

Epoch: 6| Step: 9
Training loss: 0.23871707916259766
Validation loss: 2.161719262599945

Epoch: 6| Step: 10
Training loss: 0.3029569387435913
Validation loss: 2.137044111887614

Epoch: 6| Step: 11
Training loss: 0.3239666223526001
Validation loss: 2.089987595876058

Epoch: 6| Step: 12
Training loss: 0.5275045037269592
Validation loss: 2.14215616385142

Epoch: 6| Step: 13
Training loss: 0.4718466103076935
Validation loss: 2.13444314400355

Epoch: 338| Step: 0
Training loss: 0.46699607372283936
Validation loss: 2.123918294906616

Epoch: 6| Step: 1
Training loss: 0.24828213453292847
Validation loss: 2.1584338744481406

Epoch: 6| Step: 2
Training loss: 0.321225106716156
Validation loss: 2.145522356033325

Epoch: 6| Step: 3
Training loss: 0.2653962969779968
Validation loss: 2.1751758456230164

Epoch: 6| Step: 4
Training loss: 0.2376662939786911
Validation loss: 2.1230085293451944

Epoch: 6| Step: 5
Training loss: 0.849048376083374
Validation loss: 2.1257508595784507

Epoch: 6| Step: 6
Training loss: 0.23480883240699768
Validation loss: 2.1657407879829407

Epoch: 6| Step: 7
Training loss: 0.20079554617404938
Validation loss: 2.159774343172709

Epoch: 6| Step: 8
Training loss: 0.373198002576828
Validation loss: 2.1577236453692117

Epoch: 6| Step: 9
Training loss: 0.25159749388694763
Validation loss: 2.141475737094879

Epoch: 6| Step: 10
Training loss: 0.52007657289505
Validation loss: 2.16703192392985

Epoch: 6| Step: 11
Training loss: 0.38009315729141235
Validation loss: 2.12042506535848

Epoch: 6| Step: 12
Training loss: 0.21699994802474976
Validation loss: 2.16873292128245

Epoch: 6| Step: 13
Training loss: 0.37262552976608276
Validation loss: 2.1388367215792337

Epoch: 339| Step: 0
Training loss: 0.2491142749786377
Validation loss: 2.108620842297872

Epoch: 6| Step: 1
Training loss: 0.25919169187545776
Validation loss: 2.1758060455322266

Epoch: 6| Step: 2
Training loss: 0.3060729503631592
Validation loss: 2.191605567932129

Epoch: 6| Step: 3
Training loss: 0.20946051180362701
Validation loss: 2.201977252960205

Epoch: 6| Step: 4
Training loss: 0.5295052528381348
Validation loss: 2.205307185649872

Epoch: 6| Step: 5
Training loss: 0.49847349524497986
Validation loss: 2.1899868845939636

Epoch: 6| Step: 6
Training loss: 0.35392993688583374
Validation loss: 2.1817027926445007

Epoch: 6| Step: 7
Training loss: 0.326521635055542
Validation loss: 2.208809574445089

Epoch: 6| Step: 8
Training loss: 0.460593044757843
Validation loss: 2.21645724773407

Epoch: 6| Step: 9
Training loss: 0.5419654846191406
Validation loss: 2.1724159320195517

Epoch: 6| Step: 10
Training loss: 0.2645806670188904
Validation loss: 2.142160634199778

Epoch: 6| Step: 11
Training loss: 0.40760743618011475
Validation loss: 2.1424506505330405

Epoch: 6| Step: 12
Training loss: 0.8572438955307007
Validation loss: 2.1671629548072815

Epoch: 6| Step: 13
Training loss: 0.3268526494503021
Validation loss: 2.2199960748354592

Epoch: 340| Step: 0
Training loss: 0.31337425112724304
Validation loss: 2.1395612756411233

Epoch: 6| Step: 1
Training loss: 0.4324609637260437
Validation loss: 2.2186834812164307

Epoch: 6| Step: 2
Training loss: 0.5559865236282349
Validation loss: 2.2251357634862265

Epoch: 6| Step: 3
Training loss: 0.38061773777008057
Validation loss: 2.237507184346517

Epoch: 6| Step: 4
Training loss: 0.3733949065208435
Validation loss: 2.194202999273936

Epoch: 6| Step: 5
Training loss: 0.6692315340042114
Validation loss: 2.166823625564575

Epoch: 6| Step: 6
Training loss: 0.40482544898986816
Validation loss: 2.156414528687795

Epoch: 6| Step: 7
Training loss: 0.22932779788970947
Validation loss: 2.1406893730163574

Epoch: 6| Step: 8
Training loss: 0.25287550687789917
Validation loss: 2.119585116704305

Epoch: 6| Step: 9
Training loss: 0.32392364740371704
Validation loss: 2.161646246910095

Epoch: 6| Step: 10
Training loss: 0.36273062229156494
Validation loss: 2.1673683325449624

Epoch: 6| Step: 11
Training loss: 0.3236198127269745
Validation loss: 2.154794375101725

Epoch: 6| Step: 12
Training loss: 0.3036172389984131
Validation loss: 2.1619433164596558

Epoch: 6| Step: 13
Training loss: 0.233147531747818
Validation loss: 2.110171377658844

Epoch: 341| Step: 0
Training loss: 0.7012686133384705
Validation loss: 2.1583117246627808

Epoch: 6| Step: 1
Training loss: 0.4130292534828186
Validation loss: 2.1305771470069885

Epoch: 6| Step: 2
Training loss: 0.450660765171051
Validation loss: 2.1292179822921753

Epoch: 6| Step: 3
Training loss: 0.5112159848213196
Validation loss: 2.1854927937189736

Epoch: 6| Step: 4
Training loss: 0.2615121006965637
Validation loss: 2.139951248963674

Epoch: 6| Step: 5
Training loss: 0.45046260952949524
Validation loss: 2.2192596991856894

Epoch: 6| Step: 6
Training loss: 0.5151875615119934
Validation loss: 2.1753623286883035

Epoch: 6| Step: 7
Training loss: 0.2688101530075073
Validation loss: 2.2108256816864014

Epoch: 6| Step: 8
Training loss: 0.2574392557144165
Validation loss: 2.1930512388547263

Epoch: 6| Step: 9
Training loss: 0.2229907363653183
Validation loss: 2.130789319674174

Epoch: 6| Step: 10
Training loss: 0.38686564564704895
Validation loss: 2.212123453617096

Epoch: 6| Step: 11
Training loss: 0.35882940888404846
Validation loss: 2.1005111734072366

Epoch: 6| Step: 12
Training loss: 0.3910198509693146
Validation loss: 2.1419537464777627

Epoch: 6| Step: 13
Training loss: 0.24668368697166443
Validation loss: 2.1901561419169107

Epoch: 342| Step: 0
Training loss: 0.3342643082141876
Validation loss: 2.1801655093828836

Epoch: 6| Step: 1
Training loss: 0.356309175491333
Validation loss: 2.194165031115214

Epoch: 6| Step: 2
Training loss: 0.4602961540222168
Validation loss: 2.1863975524902344

Epoch: 6| Step: 3
Training loss: 0.8447688817977905
Validation loss: 2.216187576452891

Epoch: 6| Step: 4
Training loss: 0.2462533712387085
Validation loss: 2.110412299633026

Epoch: 6| Step: 5
Training loss: 0.3292766809463501
Validation loss: 2.158260921637217

Epoch: 6| Step: 6
Training loss: 0.5102871060371399
Validation loss: 2.1230086286862693

Epoch: 6| Step: 7
Training loss: 0.3695770502090454
Validation loss: 2.1499903202056885

Epoch: 6| Step: 8
Training loss: 0.3092173635959625
Validation loss: 2.1391934553782144

Epoch: 6| Step: 9
Training loss: 0.18175214529037476
Validation loss: 2.1295783519744873

Epoch: 6| Step: 10
Training loss: 0.16680742800235748
Validation loss: 2.2010438044865928

Epoch: 6| Step: 11
Training loss: 0.3686121106147766
Validation loss: 2.1308530370394387

Epoch: 6| Step: 12
Training loss: 0.32625389099121094
Validation loss: 2.1221317251523337

Epoch: 6| Step: 13
Training loss: 0.3654361069202423
Validation loss: 2.1171831488609314

Epoch: 343| Step: 0
Training loss: 0.2908169627189636
Validation loss: 2.101866145928701

Epoch: 6| Step: 1
Training loss: 0.45547473430633545
Validation loss: 2.1423781315485635

Epoch: 6| Step: 2
Training loss: 0.9041244387626648
Validation loss: 2.1749936739603677

Epoch: 6| Step: 3
Training loss: 0.34083086252212524
Validation loss: 2.1805251240730286

Epoch: 6| Step: 4
Training loss: 0.3113041818141937
Validation loss: 2.1874232292175293

Epoch: 6| Step: 5
Training loss: 0.19951152801513672
Validation loss: 2.1511552731196084

Epoch: 6| Step: 6
Training loss: 0.459028959274292
Validation loss: 2.1603528261184692

Epoch: 6| Step: 7
Training loss: 0.6071338653564453
Validation loss: 2.1430336038271585

Epoch: 6| Step: 8
Training loss: 0.45246174931526184
Validation loss: 2.1018842260042825

Epoch: 6| Step: 9
Training loss: 0.3424101769924164
Validation loss: 2.1324018637339273

Epoch: 6| Step: 10
Training loss: 0.2686058580875397
Validation loss: 2.1205204129219055

Epoch: 6| Step: 11
Training loss: 0.2842378616333008
Validation loss: 2.1722809871037803

Epoch: 6| Step: 12
Training loss: 0.3122747242450714
Validation loss: 2.139359633127848

Epoch: 6| Step: 13
Training loss: 0.264154851436615
Validation loss: 2.145914077758789

Epoch: 344| Step: 0
Training loss: 0.3180253207683563
Validation loss: 2.212769031524658

Epoch: 6| Step: 1
Training loss: 0.31064093112945557
Validation loss: 2.152070621649424

Epoch: 6| Step: 2
Training loss: 0.49697884917259216
Validation loss: 2.1861412127812705

Epoch: 6| Step: 3
Training loss: 0.42712756991386414
Validation loss: 2.186142643292745

Epoch: 6| Step: 4
Training loss: 0.38446512818336487
Validation loss: 2.183986564477285

Epoch: 6| Step: 5
Training loss: 0.2829630970954895
Validation loss: 2.131552815437317

Epoch: 6| Step: 6
Training loss: 0.22374533116817474
Validation loss: 2.175468067328135

Epoch: 6| Step: 7
Training loss: 0.2484370321035385
Validation loss: 2.220344920953115

Epoch: 6| Step: 8
Training loss: 0.2546074390411377
Validation loss: 2.2323800325393677

Epoch: 6| Step: 9
Training loss: 0.26368242502212524
Validation loss: 2.1960153778394065

Epoch: 6| Step: 10
Training loss: 0.3114972710609436
Validation loss: 2.19569198290507

Epoch: 6| Step: 11
Training loss: 0.6767637133598328
Validation loss: 2.165262301762899

Epoch: 6| Step: 12
Training loss: 0.3917089104652405
Validation loss: 2.143061856428782

Epoch: 6| Step: 13
Training loss: 0.47911763191223145
Validation loss: 2.1681278149286904

Epoch: 345| Step: 0
Training loss: 0.29000329971313477
Validation loss: 2.179767370223999

Epoch: 6| Step: 1
Training loss: 0.24883529543876648
Validation loss: 2.1543869972229004

Epoch: 6| Step: 2
Training loss: 0.2090943455696106
Validation loss: 2.152206301689148

Epoch: 6| Step: 3
Training loss: 0.3236960768699646
Validation loss: 2.1791661381721497

Epoch: 6| Step: 4
Training loss: 0.3707180619239807
Validation loss: 2.117585817972819

Epoch: 6| Step: 5
Training loss: 0.2665248513221741
Validation loss: 2.112883766492208

Epoch: 6| Step: 6
Training loss: 0.3794829845428467
Validation loss: 2.1807716290156045

Epoch: 6| Step: 7
Training loss: 0.3560642600059509
Validation loss: 2.1427109638849893

Epoch: 6| Step: 8
Training loss: 0.3524821996688843
Validation loss: 2.134875774383545

Epoch: 6| Step: 9
Training loss: 0.3063855767250061
Validation loss: 2.1362813313802085

Epoch: 6| Step: 10
Training loss: 0.2685644030570984
Validation loss: 2.127746105194092

Epoch: 6| Step: 11
Training loss: 0.8087266683578491
Validation loss: 2.1212688287099204

Epoch: 6| Step: 12
Training loss: 0.5422556400299072
Validation loss: 2.135755936304728

Epoch: 6| Step: 13
Training loss: 0.35862845182418823
Validation loss: 2.145240386327108

Epoch: 346| Step: 0
Training loss: 0.10858649760484695
Validation loss: 2.175769249598185

Epoch: 6| Step: 1
Training loss: 0.4427299499511719
Validation loss: 2.180051346619924

Epoch: 6| Step: 2
Training loss: 0.2903420627117157
Validation loss: 2.2013072768847146

Epoch: 6| Step: 3
Training loss: 0.5846251845359802
Validation loss: 2.139490822950999

Epoch: 6| Step: 4
Training loss: 0.3021968603134155
Validation loss: 2.19753634929657

Epoch: 6| Step: 5
Training loss: 0.3794487714767456
Validation loss: 2.1448142329851785

Epoch: 6| Step: 6
Training loss: 0.3293887972831726
Validation loss: 2.115096608797709

Epoch: 6| Step: 7
Training loss: 0.42725852131843567
Validation loss: 2.129646897315979

Epoch: 6| Step: 8
Training loss: 0.27632659673690796
Validation loss: 2.198429067929586

Epoch: 6| Step: 9
Training loss: 0.24691948294639587
Validation loss: 2.2149404684702554

Epoch: 6| Step: 10
Training loss: 0.59635329246521
Validation loss: 2.173848728338877

Epoch: 6| Step: 11
Training loss: 0.33169496059417725
Validation loss: 2.1778707106908164

Epoch: 6| Step: 12
Training loss: 0.3873598575592041
Validation loss: 2.1701785922050476

Epoch: 6| Step: 13
Training loss: 0.3099152743816376
Validation loss: 2.101783295472463

Epoch: 347| Step: 0
Training loss: 0.22956936061382294
Validation loss: 2.1673906445503235

Epoch: 6| Step: 1
Training loss: 0.4067498445510864
Validation loss: 2.1394733587900796

Epoch: 6| Step: 2
Training loss: 0.5365920066833496
Validation loss: 2.1771050095558167

Epoch: 6| Step: 3
Training loss: 0.6499555110931396
Validation loss: 2.1222685178120932

Epoch: 6| Step: 4
Training loss: 0.27126002311706543
Validation loss: 2.19340181350708

Epoch: 6| Step: 5
Training loss: 0.5939159989356995
Validation loss: 2.217210054397583

Epoch: 6| Step: 6
Training loss: 0.5994004011154175
Validation loss: 2.2635440826416016

Epoch: 6| Step: 7
Training loss: 0.574400782585144
Validation loss: 2.303904195626577

Epoch: 6| Step: 8
Training loss: 0.3773516118526459
Validation loss: 2.2329981525739035

Epoch: 6| Step: 9
Training loss: 0.30838969349861145
Validation loss: 2.117812136809031

Epoch: 6| Step: 10
Training loss: 0.531818151473999
Validation loss: 2.146637817223867

Epoch: 6| Step: 11
Training loss: 0.36556822061538696
Validation loss: 2.145424505074819

Epoch: 6| Step: 12
Training loss: 0.4158977270126343
Validation loss: 2.090647876262665

Epoch: 6| Step: 13
Training loss: 0.4341588616371155
Validation loss: 2.1628249486287436

Epoch: 348| Step: 0
Training loss: 0.39831098914146423
Validation loss: 2.1405543287595115

Epoch: 6| Step: 1
Training loss: 0.35456156730651855
Validation loss: 2.1880959471066794

Epoch: 6| Step: 2
Training loss: 0.7846124768257141
Validation loss: 2.230147401491801

Epoch: 6| Step: 3
Training loss: 0.3957359194755554
Validation loss: 2.1973586479822793

Epoch: 6| Step: 4
Training loss: 0.4239065647125244
Validation loss: 2.195349077383677

Epoch: 6| Step: 5
Training loss: 0.5557485818862915
Validation loss: 2.1151269475618997

Epoch: 6| Step: 6
Training loss: 0.4450739622116089
Validation loss: 2.1228849490483603

Epoch: 6| Step: 7
Training loss: 0.4036259949207306
Validation loss: 2.138864596684774

Epoch: 6| Step: 8
Training loss: 0.3688047528266907
Validation loss: 2.1545559962590537

Epoch: 6| Step: 9
Training loss: 0.322101891040802
Validation loss: 2.1661949356396994

Epoch: 6| Step: 10
Training loss: 0.4970017969608307
Validation loss: 2.151799440383911

Epoch: 6| Step: 11
Training loss: 0.4635196626186371
Validation loss: 2.1512762705485025

Epoch: 6| Step: 12
Training loss: 0.47854357957839966
Validation loss: 2.171451210975647

Epoch: 6| Step: 13
Training loss: 0.3024354577064514
Validation loss: 2.1638630827267966

Epoch: 349| Step: 0
Training loss: 0.49721771478652954
Validation loss: 2.1835978031158447

Epoch: 6| Step: 1
Training loss: 0.39783111214637756
Validation loss: 2.11438779036204

Epoch: 6| Step: 2
Training loss: 0.8395649194717407
Validation loss: 2.1671181519826255

Epoch: 6| Step: 3
Training loss: 0.37004491686820984
Validation loss: 2.1074318885803223

Epoch: 6| Step: 4
Training loss: 0.49681270122528076
Validation loss: 2.1098403930664062

Epoch: 6| Step: 5
Training loss: 0.4526161253452301
Validation loss: 2.1264150142669678

Epoch: 6| Step: 6
Training loss: 0.192252978682518
Validation loss: 2.196321209271749

Epoch: 6| Step: 7
Training loss: 0.31045961380004883
Validation loss: 2.2467066049575806

Epoch: 6| Step: 8
Training loss: 0.8938454985618591
Validation loss: 2.2276978294054666

Epoch: 6| Step: 9
Training loss: 0.5394424200057983
Validation loss: 2.2038334210713706

Epoch: 6| Step: 10
Training loss: 0.4590301215648651
Validation loss: 2.263335724671682

Epoch: 6| Step: 11
Training loss: 0.22964410483837128
Validation loss: 2.1630762616793313

Epoch: 6| Step: 12
Training loss: 0.35635095834732056
Validation loss: 2.0810179909070334

Epoch: 6| Step: 13
Training loss: 0.5471187233924866
Validation loss: 2.0823323726654053

Epoch: 350| Step: 0
Training loss: 0.45618894696235657
Validation loss: 2.131204525629679

Epoch: 6| Step: 1
Training loss: 0.39743679761886597
Validation loss: 2.0832422574361167

Epoch: 6| Step: 2
Training loss: 0.4106903672218323
Validation loss: 2.106191794077555

Epoch: 6| Step: 3
Training loss: 0.2458537518978119
Validation loss: 2.146257221698761

Epoch: 6| Step: 4
Training loss: 0.40456336736679077
Validation loss: 2.1754318674405417

Epoch: 6| Step: 5
Training loss: 0.8338096141815186
Validation loss: 2.178470810254415

Epoch: 6| Step: 6
Training loss: 0.36897680163383484
Validation loss: 2.211054801940918

Epoch: 6| Step: 7
Training loss: 0.40737494826316833
Validation loss: 2.1592794060707092

Epoch: 6| Step: 8
Training loss: 0.3857714831829071
Validation loss: 2.183711886405945

Epoch: 6| Step: 9
Training loss: 0.3632339835166931
Validation loss: 2.1779756347338357

Epoch: 6| Step: 10
Training loss: 0.4312698543071747
Validation loss: 2.1318352818489075

Epoch: 6| Step: 11
Training loss: 0.29142409563064575
Validation loss: 2.113757868607839

Epoch: 6| Step: 12
Training loss: 0.492816686630249
Validation loss: 2.085631251335144

Epoch: 6| Step: 13
Training loss: 0.25434157252311707
Validation loss: 2.125499884287516

Epoch: 351| Step: 0
Training loss: 0.5424244403839111
Validation loss: 2.147832155227661

Epoch: 6| Step: 1
Training loss: 0.2469748854637146
Validation loss: 2.193782091140747

Epoch: 6| Step: 2
Training loss: 0.37820005416870117
Validation loss: 2.174194316069285

Epoch: 6| Step: 3
Training loss: 0.769711971282959
Validation loss: 2.187547504901886

Epoch: 6| Step: 4
Training loss: 0.26227641105651855
Validation loss: 2.1259158651034036

Epoch: 6| Step: 5
Training loss: 0.22406375408172607
Validation loss: 2.1545204321543374

Epoch: 6| Step: 6
Training loss: 0.3838351368904114
Validation loss: 2.0957940022150674

Epoch: 6| Step: 7
Training loss: 0.5603904128074646
Validation loss: 2.106494724750519

Epoch: 6| Step: 8
Training loss: 0.37992608547210693
Validation loss: 2.142483671506246

Epoch: 6| Step: 9
Training loss: 0.17147183418273926
Validation loss: 2.1813925306002298

Epoch: 6| Step: 10
Training loss: 0.40832650661468506
Validation loss: 2.183497587839762

Epoch: 6| Step: 11
Training loss: 0.19953817129135132
Validation loss: 2.1976952155431113

Epoch: 6| Step: 12
Training loss: 0.36216357350349426
Validation loss: 2.157475749651591

Epoch: 6| Step: 13
Training loss: 0.2371787279844284
Validation loss: 2.1794323921203613

Epoch: 352| Step: 0
Training loss: 0.2222217619419098
Validation loss: 2.1547277768452964

Epoch: 6| Step: 1
Training loss: 0.3263315260410309
Validation loss: 2.18418151140213

Epoch: 6| Step: 2
Training loss: 0.3129225969314575
Validation loss: 2.185224413871765

Epoch: 6| Step: 3
Training loss: 0.38471588492393494
Validation loss: 2.1724663178126016

Epoch: 6| Step: 4
Training loss: 0.3555947244167328
Validation loss: 2.1760212977727256

Epoch: 6| Step: 5
Training loss: 0.29218149185180664
Validation loss: 2.160117963949839

Epoch: 6| Step: 6
Training loss: 0.6379928588867188
Validation loss: 2.211258351802826

Epoch: 6| Step: 7
Training loss: 0.3987301290035248
Validation loss: 2.141547441482544

Epoch: 6| Step: 8
Training loss: 0.24815873801708221
Validation loss: 2.167091210683187

Epoch: 6| Step: 9
Training loss: 0.2505987882614136
Validation loss: 2.204382280508677

Epoch: 6| Step: 10
Training loss: 0.32982566952705383
Validation loss: 2.1752214233080545

Epoch: 6| Step: 11
Training loss: 0.2523193955421448
Validation loss: 2.176295280456543

Epoch: 6| Step: 12
Training loss: 0.26984888315200806
Validation loss: 2.1611326336860657

Epoch: 6| Step: 13
Training loss: 0.43648791313171387
Validation loss: 2.128236552079519

Epoch: 353| Step: 0
Training loss: 0.2557566165924072
Validation loss: 2.1739466389020285

Epoch: 6| Step: 1
Training loss: 0.597567081451416
Validation loss: 2.1685763001441956

Epoch: 6| Step: 2
Training loss: 0.2278735190629959
Validation loss: 2.147667169570923

Epoch: 6| Step: 3
Training loss: 0.5229006409645081
Validation loss: 2.129165689150492

Epoch: 6| Step: 4
Training loss: 0.2871505916118622
Validation loss: 2.1749747594197593

Epoch: 6| Step: 5
Training loss: 0.3443572521209717
Validation loss: 2.177805026372274

Epoch: 6| Step: 6
Training loss: 0.36361026763916016
Validation loss: 2.191422979036967

Epoch: 6| Step: 7
Training loss: 0.1804308295249939
Validation loss: 2.1566147009531655

Epoch: 6| Step: 8
Training loss: 0.24827635288238525
Validation loss: 2.1596039533615112

Epoch: 6| Step: 9
Training loss: 0.2144002765417099
Validation loss: 2.146997650464376

Epoch: 6| Step: 10
Training loss: 0.37208321690559387
Validation loss: 2.1514770785967507

Epoch: 6| Step: 11
Training loss: 0.4169822037220001
Validation loss: 2.1053426464398703

Epoch: 6| Step: 12
Training loss: 0.48657330870628357
Validation loss: 2.177634358406067

Epoch: 6| Step: 13
Training loss: 0.19214007258415222
Validation loss: 2.154238780339559

Epoch: 354| Step: 0
Training loss: 0.5379308462142944
Validation loss: 2.196575939655304

Epoch: 6| Step: 1
Training loss: 0.32125693559646606
Validation loss: 2.1890401442845664

Epoch: 6| Step: 2
Training loss: 0.5311217308044434
Validation loss: 2.1472126046816506

Epoch: 6| Step: 3
Training loss: 0.45106858015060425
Validation loss: 2.130212664604187

Epoch: 6| Step: 4
Training loss: 0.3235184848308563
Validation loss: 2.1447463432947793

Epoch: 6| Step: 5
Training loss: 0.2956300377845764
Validation loss: 2.137573023637136

Epoch: 6| Step: 6
Training loss: 0.29274308681488037
Validation loss: 2.1207810044288635

Epoch: 6| Step: 7
Training loss: 0.17407551407814026
Validation loss: 2.160333832105001

Epoch: 6| Step: 8
Training loss: 0.49666935205459595
Validation loss: 2.1839546958605447

Epoch: 6| Step: 9
Training loss: 0.27506333589553833
Validation loss: 2.1520915428797402

Epoch: 6| Step: 10
Training loss: 0.17099392414093018
Validation loss: 2.1465488274892173

Epoch: 6| Step: 11
Training loss: 0.6549127697944641
Validation loss: 2.1760956048965454

Epoch: 6| Step: 12
Training loss: 0.2723374664783478
Validation loss: 2.1359408497810364

Epoch: 6| Step: 13
Training loss: 0.16198396682739258
Validation loss: 2.2001407543818154

Epoch: 355| Step: 0
Training loss: 0.4143347144126892
Validation loss: 2.2051214377085366

Epoch: 6| Step: 1
Training loss: 0.11683821678161621
Validation loss: 2.1528674562772117

Epoch: 6| Step: 2
Training loss: 0.26538917422294617
Validation loss: 2.105917056401571

Epoch: 6| Step: 3
Training loss: 0.3660644292831421
Validation loss: 2.142208218574524

Epoch: 6| Step: 4
Training loss: 0.1839008629322052
Validation loss: 2.188804864883423

Epoch: 6| Step: 5
Training loss: 0.34766948223114014
Validation loss: 2.185428957144419

Epoch: 6| Step: 6
Training loss: 0.3716934025287628
Validation loss: 2.226242462793986

Epoch: 6| Step: 7
Training loss: 0.5832723379135132
Validation loss: 2.13898499806722

Epoch: 6| Step: 8
Training loss: 0.6974257230758667
Validation loss: 2.1420447627703347

Epoch: 6| Step: 9
Training loss: 0.23536667227745056
Validation loss: 2.122955540815989

Epoch: 6| Step: 10
Training loss: 0.34809738397598267
Validation loss: 2.0906524459520974

Epoch: 6| Step: 11
Training loss: 0.3111792504787445
Validation loss: 2.083172857761383

Epoch: 6| Step: 12
Training loss: 0.27644771337509155
Validation loss: 2.1591069300969443

Epoch: 6| Step: 13
Training loss: 0.3732185363769531
Validation loss: 2.1614858309427896

Epoch: 356| Step: 0
Training loss: 0.32073891162872314
Validation loss: 2.208130439122518

Epoch: 6| Step: 1
Training loss: 0.4615962505340576
Validation loss: 2.1687865058581033

Epoch: 6| Step: 2
Training loss: 0.6444644331932068
Validation loss: 2.171059469381968

Epoch: 6| Step: 3
Training loss: 0.41262513399124146
Validation loss: 2.0943751335144043

Epoch: 6| Step: 4
Training loss: 0.4173225462436676
Validation loss: 2.128670851389567

Epoch: 6| Step: 5
Training loss: 0.3332991898059845
Validation loss: 2.1000988284746804

Epoch: 6| Step: 6
Training loss: 0.3142769932746887
Validation loss: 2.1263046662012735

Epoch: 6| Step: 7
Training loss: 0.18972429633140564
Validation loss: 2.1338216265042624

Epoch: 6| Step: 8
Training loss: 0.17403504252433777
Validation loss: 2.151388188203176

Epoch: 6| Step: 9
Training loss: 0.3622540831565857
Validation loss: 2.1055587331453958

Epoch: 6| Step: 10
Training loss: 0.3421049118041992
Validation loss: 2.137317935625712

Epoch: 6| Step: 11
Training loss: 0.5916811227798462
Validation loss: 2.132419466972351

Epoch: 6| Step: 12
Training loss: 0.30314555764198303
Validation loss: 2.139778991540273

Epoch: 6| Step: 13
Training loss: 0.4714982807636261
Validation loss: 2.1116750041643777

Epoch: 357| Step: 0
Training loss: 0.40194565057754517
Validation loss: 2.1065261165301004

Epoch: 6| Step: 1
Training loss: 0.2291611135005951
Validation loss: 2.170171837011973

Epoch: 6| Step: 2
Training loss: 0.2560197710990906
Validation loss: 2.2064140240351358

Epoch: 6| Step: 3
Training loss: 0.22497603297233582
Validation loss: 2.1677763859430947

Epoch: 6| Step: 4
Training loss: 0.1711139976978302
Validation loss: 2.1763269901275635

Epoch: 6| Step: 5
Training loss: 0.3050141930580139
Validation loss: 2.142217497030894

Epoch: 6| Step: 6
Training loss: 0.3217695355415344
Validation loss: 2.1967231829961142

Epoch: 6| Step: 7
Training loss: 0.2219601273536682
Validation loss: 2.1586065689722695

Epoch: 6| Step: 8
Training loss: 0.2818547785282135
Validation loss: 2.1492011547088623

Epoch: 6| Step: 9
Training loss: 0.5703719854354858
Validation loss: 2.1464268366495767

Epoch: 6| Step: 10
Training loss: 0.37062764167785645
Validation loss: 2.1928756833076477

Epoch: 6| Step: 11
Training loss: 0.3324597179889679
Validation loss: 2.211699287096659

Epoch: 6| Step: 12
Training loss: 0.5844902396202087
Validation loss: 2.202515403429667

Epoch: 6| Step: 13
Training loss: 0.4447849690914154
Validation loss: 2.21701047817866

Epoch: 358| Step: 0
Training loss: 0.3384888172149658
Validation loss: 2.1715059677759805

Epoch: 6| Step: 1
Training loss: 0.2745400667190552
Validation loss: 2.144075075785319

Epoch: 6| Step: 2
Training loss: 0.315743088722229
Validation loss: 2.1200148860613504

Epoch: 6| Step: 3
Training loss: 0.6625760197639465
Validation loss: 2.1345197558403015

Epoch: 6| Step: 4
Training loss: 0.4925316572189331
Validation loss: 2.1738816102345786

Epoch: 6| Step: 5
Training loss: 0.2571159303188324
Validation loss: 2.1935992439587912

Epoch: 6| Step: 6
Training loss: 0.24565891921520233
Validation loss: 2.1547300020853677

Epoch: 6| Step: 7
Training loss: 0.20142212510108948
Validation loss: 2.1644287109375

Epoch: 6| Step: 8
Training loss: 0.4584093689918518
Validation loss: 2.1963656147321067

Epoch: 6| Step: 9
Training loss: 0.2878836691379547
Validation loss: 2.1871818701426187

Epoch: 6| Step: 10
Training loss: 0.1988842487335205
Validation loss: 2.155824303627014

Epoch: 6| Step: 11
Training loss: 0.32804614305496216
Validation loss: 2.2043436765670776

Epoch: 6| Step: 12
Training loss: 0.3206329345703125
Validation loss: 2.1111514965693154

Epoch: 6| Step: 13
Training loss: 0.29437148571014404
Validation loss: 2.161235054334005

Epoch: 359| Step: 0
Training loss: 0.43549832701683044
Validation loss: 2.1624229749043784

Epoch: 6| Step: 1
Training loss: 0.26733118295669556
Validation loss: 2.2105809251467385

Epoch: 6| Step: 2
Training loss: 0.2560352087020874
Validation loss: 2.1513024171193442

Epoch: 6| Step: 3
Training loss: 0.21941205859184265
Validation loss: 2.1106463273366294

Epoch: 6| Step: 4
Training loss: 0.5593054294586182
Validation loss: 2.095333993434906

Epoch: 6| Step: 5
Training loss: 0.3455716371536255
Validation loss: 2.1517262856165567

Epoch: 6| Step: 6
Training loss: 0.47304049134254456
Validation loss: 2.1658517519632974

Epoch: 6| Step: 7
Training loss: 0.3856021463871002
Validation loss: 2.172367513179779

Epoch: 6| Step: 8
Training loss: 0.6748638153076172
Validation loss: 2.14543354511261

Epoch: 6| Step: 9
Training loss: 0.3293173313140869
Validation loss: 2.242012917995453

Epoch: 6| Step: 10
Training loss: 0.31706702709198
Validation loss: 2.147753973801931

Epoch: 6| Step: 11
Training loss: 0.24229413270950317
Validation loss: 2.188279449939728

Epoch: 6| Step: 12
Training loss: 0.2705792784690857
Validation loss: 2.1270053585370383

Epoch: 6| Step: 13
Training loss: 0.3058941066265106
Validation loss: 2.1099169651667276

Epoch: 360| Step: 0
Training loss: 0.830341100692749
Validation loss: 2.0937366485595703

Epoch: 6| Step: 1
Training loss: 0.21817347407341003
Validation loss: 2.173143764336904

Epoch: 6| Step: 2
Training loss: 0.2071092426776886
Validation loss: 2.1638251543045044

Epoch: 6| Step: 3
Training loss: 0.46166932582855225
Validation loss: 2.2590532501538596

Epoch: 6| Step: 4
Training loss: 0.3618210554122925
Validation loss: 2.196272055308024

Epoch: 6| Step: 5
Training loss: 0.3089921474456787
Validation loss: 2.2059881885846457

Epoch: 6| Step: 6
Training loss: 0.45519301295280457
Validation loss: 2.196799079577128

Epoch: 6| Step: 7
Training loss: 0.3465072810649872
Validation loss: 2.1346480449040732

Epoch: 6| Step: 8
Training loss: 0.36580416560173035
Validation loss: 2.0920843879381814

Epoch: 6| Step: 9
Training loss: 0.3170185685157776
Validation loss: 2.1683963537216187

Epoch: 6| Step: 10
Training loss: 0.6475680470466614
Validation loss: 2.13540909687678

Epoch: 6| Step: 11
Training loss: 0.3736879229545593
Validation loss: 2.162725845972697

Epoch: 6| Step: 12
Training loss: 0.26414427161216736
Validation loss: 2.184970478216807

Epoch: 6| Step: 13
Training loss: 0.22265198826789856
Validation loss: 2.2398261626561484

Epoch: 361| Step: 0
Training loss: 0.25632888078689575
Validation loss: 2.2102576891581216

Epoch: 6| Step: 1
Training loss: 0.5712963938713074
Validation loss: 2.1797797481218972

Epoch: 6| Step: 2
Training loss: 0.37858712673187256
Validation loss: 2.189040740331014

Epoch: 6| Step: 3
Training loss: 0.23332864046096802
Validation loss: 2.1381022532780967

Epoch: 6| Step: 4
Training loss: 0.24124404788017273
Validation loss: 2.1320202549298606

Epoch: 6| Step: 5
Training loss: 0.6497151851654053
Validation loss: 2.1450606981913247

Epoch: 6| Step: 6
Training loss: 0.4420369565486908
Validation loss: 2.147599458694458

Epoch: 6| Step: 7
Training loss: 0.24006187915802002
Validation loss: 2.165052672227224

Epoch: 6| Step: 8
Training loss: 0.4930611550807953
Validation loss: 2.2050036589304605

Epoch: 6| Step: 9
Training loss: 0.22705234587192535
Validation loss: 2.1653425892194114

Epoch: 6| Step: 10
Training loss: 0.34824469685554504
Validation loss: 2.1802157163619995

Epoch: 6| Step: 11
Training loss: 0.18050774931907654
Validation loss: 2.1662970185279846

Epoch: 6| Step: 12
Training loss: 0.24249455332756042
Validation loss: 2.1339154640833535

Epoch: 6| Step: 13
Training loss: 0.328532338142395
Validation loss: 2.1450809041659036

Epoch: 362| Step: 0
Training loss: 0.28006941080093384
Validation loss: 2.1836690107981362

Epoch: 6| Step: 1
Training loss: 0.3208470344543457
Validation loss: 2.170166254043579

Epoch: 6| Step: 2
Training loss: 0.20016351342201233
Validation loss: 2.143947978814443

Epoch: 6| Step: 3
Training loss: 0.18804138898849487
Validation loss: 2.117850184440613

Epoch: 6| Step: 4
Training loss: 0.3952668607234955
Validation loss: 2.1394015153249106

Epoch: 6| Step: 5
Training loss: 0.6418477296829224
Validation loss: 2.1541791955629983

Epoch: 6| Step: 6
Training loss: 0.3995557427406311
Validation loss: 2.1429235537846885

Epoch: 6| Step: 7
Training loss: 0.1594305783510208
Validation loss: 2.112450818220774

Epoch: 6| Step: 8
Training loss: 0.32202693819999695
Validation loss: 2.139990210533142

Epoch: 6| Step: 9
Training loss: 0.3674207329750061
Validation loss: 2.1766300996144614

Epoch: 6| Step: 10
Training loss: 0.22077608108520508
Validation loss: 2.1881494323412576

Epoch: 6| Step: 11
Training loss: 0.37803977727890015
Validation loss: 2.196669101715088

Epoch: 6| Step: 12
Training loss: 0.457234650850296
Validation loss: 2.2450095613797507

Epoch: 6| Step: 13
Training loss: 0.40428078174591064
Validation loss: 2.1235967675844827

Epoch: 363| Step: 0
Training loss: 0.2518113851547241
Validation loss: 2.121672034263611

Epoch: 6| Step: 1
Training loss: 0.4745716452598572
Validation loss: 2.1371567646662393

Epoch: 6| Step: 2
Training loss: 0.44723939895629883
Validation loss: 2.1411982774734497

Epoch: 6| Step: 3
Training loss: 0.5030131936073303
Validation loss: 2.1191389759381614

Epoch: 6| Step: 4
Training loss: 0.7450741529464722
Validation loss: 2.1427595814069114

Epoch: 6| Step: 5
Training loss: 0.3144792318344116
Validation loss: 2.1287887493769326

Epoch: 6| Step: 6
Training loss: 0.4098130464553833
Validation loss: 2.1776966651280723

Epoch: 6| Step: 7
Training loss: 0.28821688890457153
Validation loss: 2.181478222211202

Epoch: 6| Step: 8
Training loss: 0.44434404373168945
Validation loss: 2.2010632157325745

Epoch: 6| Step: 9
Training loss: 0.45344430208206177
Validation loss: 2.1646191279093423

Epoch: 6| Step: 10
Training loss: 0.4359269440174103
Validation loss: 2.151978294054667

Epoch: 6| Step: 11
Training loss: 0.23177394270896912
Validation loss: 2.1690971851348877

Epoch: 6| Step: 12
Training loss: 0.3431447446346283
Validation loss: 2.1131115555763245

Epoch: 6| Step: 13
Training loss: 0.2681117355823517
Validation loss: 2.115737954775492

Epoch: 364| Step: 0
Training loss: 0.33291083574295044
Validation loss: 2.1030227144559226

Epoch: 6| Step: 1
Training loss: 0.3697201609611511
Validation loss: 2.157509962717692

Epoch: 6| Step: 2
Training loss: 0.307509183883667
Validation loss: 2.146873672803243

Epoch: 6| Step: 3
Training loss: 0.7247062921524048
Validation loss: 2.1943782567977905

Epoch: 6| Step: 4
Training loss: 0.30059993267059326
Validation loss: 2.2161466677983603

Epoch: 6| Step: 5
Training loss: 0.5398591160774231
Validation loss: 2.2029652992884317

Epoch: 6| Step: 6
Training loss: 0.4143194854259491
Validation loss: 2.1630561351776123

Epoch: 6| Step: 7
Training loss: 0.22303202748298645
Validation loss: 2.1369706988334656

Epoch: 6| Step: 8
Training loss: 0.42367663979530334
Validation loss: 2.1254782676696777

Epoch: 6| Step: 9
Training loss: 0.2838567793369293
Validation loss: 2.1529753605524697

Epoch: 6| Step: 10
Training loss: 0.7983955144882202
Validation loss: 2.129165450731913

Epoch: 6| Step: 11
Training loss: 0.1952204406261444
Validation loss: 2.1505620082219443

Epoch: 6| Step: 12
Training loss: 0.3228302597999573
Validation loss: 2.1629356940587363

Epoch: 6| Step: 13
Training loss: 0.32952243089675903
Validation loss: 2.1843758622805276

Epoch: 365| Step: 0
Training loss: 0.5181825160980225
Validation loss: 2.1841880679130554

Epoch: 6| Step: 1
Training loss: 0.20932190120220184
Validation loss: 2.2030856013298035

Epoch: 6| Step: 2
Training loss: 0.3109772503376007
Validation loss: 2.156077802181244

Epoch: 6| Step: 3
Training loss: 0.17610616981983185
Validation loss: 2.1380510727564492

Epoch: 6| Step: 4
Training loss: 0.2863159775733948
Validation loss: 2.1040061712265015

Epoch: 6| Step: 5
Training loss: 0.6487804651260376
Validation loss: 2.1243401765823364

Epoch: 6| Step: 6
Training loss: 0.2107456922531128
Validation loss: 2.118927796681722

Epoch: 6| Step: 7
Training loss: 0.44238072633743286
Validation loss: 2.1736992597579956

Epoch: 6| Step: 8
Training loss: 0.21494333446025848
Validation loss: 2.180993378162384

Epoch: 6| Step: 9
Training loss: 0.3934246897697449
Validation loss: 2.1969721913337708

Epoch: 6| Step: 10
Training loss: 0.5094527006149292
Validation loss: 2.2108166813850403

Epoch: 6| Step: 11
Training loss: 0.31120771169662476
Validation loss: 2.121382455031077

Epoch: 6| Step: 12
Training loss: 0.7111985087394714
Validation loss: 2.1807119448979697

Epoch: 6| Step: 13
Training loss: 0.33275294303894043
Validation loss: 2.1374109188715615

Epoch: 366| Step: 0
Training loss: 0.26682376861572266
Validation loss: 2.12255867322286

Epoch: 6| Step: 1
Training loss: 0.6587266325950623
Validation loss: 2.1398614645004272

Epoch: 6| Step: 2
Training loss: 0.3510267436504364
Validation loss: 2.213641186555227

Epoch: 6| Step: 3
Training loss: 0.515993058681488
Validation loss: 2.1845614512761435

Epoch: 6| Step: 4
Training loss: 0.40798425674438477
Validation loss: 2.1493863662083945

Epoch: 6| Step: 5
Training loss: 0.3304486870765686
Validation loss: 2.1787025531133017

Epoch: 6| Step: 6
Training loss: 0.22065037488937378
Validation loss: 2.1657713055610657

Epoch: 6| Step: 7
Training loss: 0.2019331306219101
Validation loss: 2.134065310160319

Epoch: 6| Step: 8
Training loss: 0.637812077999115
Validation loss: 2.1361241539319358

Epoch: 6| Step: 9
Training loss: 0.2447572499513626
Validation loss: 2.1117979685465493

Epoch: 6| Step: 10
Training loss: 0.2373739778995514
Validation loss: 2.155742883682251

Epoch: 6| Step: 11
Training loss: 0.3924594521522522
Validation loss: 2.140012204647064

Epoch: 6| Step: 12
Training loss: 0.355375736951828
Validation loss: 2.111281156539917

Epoch: 6| Step: 13
Training loss: 0.2574646472930908
Validation loss: 2.1568809350331626

Epoch: 367| Step: 0
Training loss: 0.3489782214164734
Validation loss: 2.105001429716746

Epoch: 6| Step: 1
Training loss: 0.3394806981086731
Validation loss: 2.190702756245931

Epoch: 6| Step: 2
Training loss: 0.457960307598114
Validation loss: 2.14898020029068

Epoch: 6| Step: 3
Training loss: 0.3130759000778198
Validation loss: 2.0893439054489136

Epoch: 6| Step: 4
Training loss: 0.30888456106185913
Validation loss: 2.117038389046987

Epoch: 6| Step: 5
Training loss: 0.3579828441143036
Validation loss: 2.103178838888804

Epoch: 6| Step: 6
Training loss: 0.2725350856781006
Validation loss: 2.1191566387812295

Epoch: 6| Step: 7
Training loss: 0.2488914430141449
Validation loss: 2.132702112197876

Epoch: 6| Step: 8
Training loss: 0.4235205054283142
Validation loss: 2.1300896207491555

Epoch: 6| Step: 9
Training loss: 0.6633098125457764
Validation loss: 2.22969659169515

Epoch: 6| Step: 10
Training loss: 0.2924279570579529
Validation loss: 2.197100281715393

Epoch: 6| Step: 11
Training loss: 0.7363816499710083
Validation loss: 2.222835203011831

Epoch: 6| Step: 12
Training loss: 0.5337314605712891
Validation loss: 2.212094028790792

Epoch: 6| Step: 13
Training loss: 0.35323208570480347
Validation loss: 2.1715283393859863

Epoch: 368| Step: 0
Training loss: 0.459900438785553
Validation loss: 2.1770530541737876

Epoch: 6| Step: 1
Training loss: 0.44714879989624023
Validation loss: 2.1527188221613565

Epoch: 6| Step: 2
Training loss: 0.3237844705581665
Validation loss: 2.145577351252238

Epoch: 6| Step: 3
Training loss: 0.3628796637058258
Validation loss: 2.148021082083384

Epoch: 6| Step: 4
Training loss: 0.5169975161552429
Validation loss: 2.1401079297065735

Epoch: 6| Step: 5
Training loss: 0.21184036135673523
Validation loss: 2.1396780808766684

Epoch: 6| Step: 6
Training loss: 0.33521193265914917
Validation loss: 2.2239370147387185

Epoch: 6| Step: 7
Training loss: 0.6754229664802551
Validation loss: 2.203862249851227

Epoch: 6| Step: 8
Training loss: 0.341166615486145
Validation loss: 2.1750435034434

Epoch: 6| Step: 9
Training loss: 0.384249746799469
Validation loss: 2.145255366961161

Epoch: 6| Step: 10
Training loss: 0.4120441675186157
Validation loss: 2.150191843509674

Epoch: 6| Step: 11
Training loss: 0.29571372270584106
Validation loss: 2.1030139128367105

Epoch: 6| Step: 12
Training loss: 0.3250700831413269
Validation loss: 2.1088846723238626

Epoch: 6| Step: 13
Training loss: 0.259968101978302
Validation loss: 2.1458805004755654

Epoch: 369| Step: 0
Training loss: 0.2485845386981964
Validation loss: 2.1500346461931863

Epoch: 6| Step: 1
Training loss: 0.2729339599609375
Validation loss: 2.162614087263743

Epoch: 6| Step: 2
Training loss: 0.33177149295806885
Validation loss: 2.1330657998720803

Epoch: 6| Step: 3
Training loss: 0.21304914355278015
Validation loss: 2.115369498729706

Epoch: 6| Step: 4
Training loss: 0.20586204528808594
Validation loss: 2.1731295784314475

Epoch: 6| Step: 5
Training loss: 0.40027278661727905
Validation loss: 2.1376938422520957

Epoch: 6| Step: 6
Training loss: 0.40394505858421326
Validation loss: 2.145217935244242

Epoch: 6| Step: 7
Training loss: 0.3384047746658325
Validation loss: 2.1814854542414346

Epoch: 6| Step: 8
Training loss: 0.3267870247364044
Validation loss: 2.11737189690272

Epoch: 6| Step: 9
Training loss: 0.46080461144447327
Validation loss: 2.1616249879201255

Epoch: 6| Step: 10
Training loss: 0.6212316155433655
Validation loss: 2.124797224998474

Epoch: 6| Step: 11
Training loss: 0.43255001306533813
Validation loss: 2.1530993382136026

Epoch: 6| Step: 12
Training loss: 0.34493154287338257
Validation loss: 2.0992825826009116

Epoch: 6| Step: 13
Training loss: 0.28810355067253113
Validation loss: 2.1312058766682944

Epoch: 370| Step: 0
Training loss: 0.275508314371109
Validation loss: 2.180208742618561

Epoch: 6| Step: 1
Training loss: 0.3747609257698059
Validation loss: 2.157731850941976

Epoch: 6| Step: 2
Training loss: 0.43363672494888306
Validation loss: 2.157411595185598

Epoch: 6| Step: 3
Training loss: 0.3636135458946228
Validation loss: 2.1799766620000205

Epoch: 6| Step: 4
Training loss: 0.3063475489616394
Validation loss: 2.1594911217689514

Epoch: 6| Step: 5
Training loss: 0.2819034457206726
Validation loss: 2.131880263487498

Epoch: 6| Step: 6
Training loss: 0.31224876642227173
Validation loss: 2.0975449681282043

Epoch: 6| Step: 7
Training loss: 0.5285502076148987
Validation loss: 2.0867600440979004

Epoch: 6| Step: 8
Training loss: 0.2388632893562317
Validation loss: 2.1118739446004233

Epoch: 6| Step: 9
Training loss: 0.7197951078414917
Validation loss: 2.097506125768026

Epoch: 6| Step: 10
Training loss: 0.25687575340270996
Validation loss: 2.1213141481081643

Epoch: 6| Step: 11
Training loss: 0.4137686491012573
Validation loss: 2.145320097605387

Epoch: 6| Step: 12
Training loss: 0.35737165808677673
Validation loss: 2.104872206846873

Epoch: 6| Step: 13
Training loss: 0.41626131534576416
Validation loss: 2.1478401819864907

Epoch: 371| Step: 0
Training loss: 0.2841107249259949
Validation loss: 2.18454376856486

Epoch: 6| Step: 1
Training loss: 0.47156065702438354
Validation loss: 2.132523496945699

Epoch: 6| Step: 2
Training loss: 0.42248037457466125
Validation loss: 2.0949975848197937

Epoch: 6| Step: 3
Training loss: 0.2830110192298889
Validation loss: 2.1348665356636047

Epoch: 6| Step: 4
Training loss: 0.30336278676986694
Validation loss: 2.143632094065348

Epoch: 6| Step: 5
Training loss: 0.23251120746135712
Validation loss: 2.1472968260447183

Epoch: 6| Step: 6
Training loss: 0.33404359221458435
Validation loss: 2.1197473208109536

Epoch: 6| Step: 7
Training loss: 0.5887799263000488
Validation loss: 2.1335007349650064

Epoch: 6| Step: 8
Training loss: 0.19610416889190674
Validation loss: 2.140397310256958

Epoch: 6| Step: 9
Training loss: 0.23279696702957153
Validation loss: 2.1885978976885476

Epoch: 6| Step: 10
Training loss: 0.42312976717948914
Validation loss: 2.1159308552742004

Epoch: 6| Step: 11
Training loss: 0.23282906413078308
Validation loss: 2.129968067010244

Epoch: 6| Step: 12
Training loss: 0.3498407304286957
Validation loss: 2.1611293951670327

Epoch: 6| Step: 13
Training loss: 0.39649736881256104
Validation loss: 2.182885487874349

Epoch: 372| Step: 0
Training loss: 0.5845428109169006
Validation loss: 2.1457488338152566

Epoch: 6| Step: 1
Training loss: 0.2812872529029846
Validation loss: 2.144850730895996

Epoch: 6| Step: 2
Training loss: 0.23926544189453125
Validation loss: 2.2164390087127686

Epoch: 6| Step: 3
Training loss: 0.24161891639232635
Validation loss: 2.2290910681088767

Epoch: 6| Step: 4
Training loss: 0.2063712775707245
Validation loss: 2.2217121521631875

Epoch: 6| Step: 5
Training loss: 0.2744140028953552
Validation loss: 2.1783747474352517

Epoch: 6| Step: 6
Training loss: 0.30296868085861206
Validation loss: 2.156926472981771

Epoch: 6| Step: 7
Training loss: 0.3394755423069
Validation loss: 2.176468014717102

Epoch: 6| Step: 8
Training loss: 0.42798250913619995
Validation loss: 2.1545765002568564

Epoch: 6| Step: 9
Training loss: 0.35414350032806396
Validation loss: 2.1837856570879617

Epoch: 6| Step: 10
Training loss: 0.4426736533641815
Validation loss: 2.1618659098943076

Epoch: 6| Step: 11
Training loss: 0.30838871002197266
Validation loss: 2.1999776562054953

Epoch: 6| Step: 12
Training loss: 0.5283881425857544
Validation loss: 2.226854066054026

Epoch: 6| Step: 13
Training loss: 0.4276265501976013
Validation loss: 2.203502595424652

Epoch: 373| Step: 0
Training loss: 0.1910533457994461
Validation loss: 2.161477208137512

Epoch: 6| Step: 1
Training loss: 0.3014135956764221
Validation loss: 2.135009467601776

Epoch: 6| Step: 2
Training loss: 0.8429331183433533
Validation loss: 2.1578738490740457

Epoch: 6| Step: 3
Training loss: 0.39875733852386475
Validation loss: 2.115885555744171

Epoch: 6| Step: 4
Training loss: 0.20425336062908173
Validation loss: 2.1631274223327637

Epoch: 6| Step: 5
Training loss: 0.2849997282028198
Validation loss: 2.162427624066671

Epoch: 6| Step: 6
Training loss: 0.29673299193382263
Validation loss: 2.160524090131124

Epoch: 6| Step: 7
Training loss: 0.40118101239204407
Validation loss: 2.1439693172772727

Epoch: 6| Step: 8
Training loss: 0.3861086070537567
Validation loss: 2.176368832588196

Epoch: 6| Step: 9
Training loss: 0.2886110544204712
Validation loss: 2.1601475278536477

Epoch: 6| Step: 10
Training loss: 0.16327720880508423
Validation loss: 2.163099447886149

Epoch: 6| Step: 11
Training loss: 0.21440376341342926
Validation loss: 2.1269250909487405

Epoch: 6| Step: 12
Training loss: 0.41000184416770935
Validation loss: 2.1219417254130044

Epoch: 6| Step: 13
Training loss: 0.39302027225494385
Validation loss: 2.155893325805664

Epoch: 374| Step: 0
Training loss: 0.3988410234451294
Validation loss: 2.1082803209622702

Epoch: 6| Step: 1
Training loss: 0.15928512811660767
Validation loss: 2.133646289507548

Epoch: 6| Step: 2
Training loss: 0.3349008560180664
Validation loss: 2.173882027467092

Epoch: 6| Step: 3
Training loss: 0.2874813377857208
Validation loss: 2.132167120774587

Epoch: 6| Step: 4
Training loss: 0.21660348773002625
Validation loss: 2.098882873853048

Epoch: 6| Step: 5
Training loss: 0.18646490573883057
Validation loss: 2.1520800987879434

Epoch: 6| Step: 6
Training loss: 0.32114583253860474
Validation loss: 2.144535700480143

Epoch: 6| Step: 7
Training loss: 0.21535278856754303
Validation loss: 2.112500309944153

Epoch: 6| Step: 8
Training loss: 0.25336015224456787
Validation loss: 2.20334400733312

Epoch: 6| Step: 9
Training loss: 0.607494056224823
Validation loss: 2.1393479108810425

Epoch: 6| Step: 10
Training loss: 0.43670523166656494
Validation loss: 2.1705767711003623

Epoch: 6| Step: 11
Training loss: 0.25708824396133423
Validation loss: 2.107200046380361

Epoch: 6| Step: 12
Training loss: 0.38401368260383606
Validation loss: 2.0844812194506326

Epoch: 6| Step: 13
Training loss: 0.3544352948665619
Validation loss: 2.128171384334564

Epoch: 375| Step: 0
Training loss: 0.22044923901557922
Validation loss: 2.0917121171951294

Epoch: 6| Step: 1
Training loss: 0.5217337608337402
Validation loss: 2.150666276613871

Epoch: 6| Step: 2
Training loss: 0.11855591088533401
Validation loss: 2.118770102659861

Epoch: 6| Step: 3
Training loss: 0.3180663287639618
Validation loss: 2.1772844195365906

Epoch: 6| Step: 4
Training loss: 0.21109534800052643
Validation loss: 2.157401899496714

Epoch: 6| Step: 5
Training loss: 0.2917581796646118
Validation loss: 2.171718657016754

Epoch: 6| Step: 6
Training loss: 0.6940388679504395
Validation loss: 2.1293026407559714

Epoch: 6| Step: 7
Training loss: 0.32096925377845764
Validation loss: 2.132711410522461

Epoch: 6| Step: 8
Training loss: 0.26656708121299744
Validation loss: 2.1421926021575928

Epoch: 6| Step: 9
Training loss: 0.32477396726608276
Validation loss: 2.1243050495783486

Epoch: 6| Step: 10
Training loss: 0.31875720620155334
Validation loss: 2.1898553570111594

Epoch: 6| Step: 11
Training loss: 0.4817865788936615
Validation loss: 2.1830259362856546

Epoch: 6| Step: 12
Training loss: 0.2146729677915573
Validation loss: 2.159223179022471

Epoch: 6| Step: 13
Training loss: 0.21151573956012726
Validation loss: 2.1560110251108804

Epoch: 376| Step: 0
Training loss: 0.22193919122219086
Validation loss: 2.1632563869158425

Epoch: 6| Step: 1
Training loss: 0.2757539451122284
Validation loss: 2.1448719104131064

Epoch: 6| Step: 2
Training loss: 0.3729914426803589
Validation loss: 2.129707475503286

Epoch: 6| Step: 3
Training loss: 0.16848592460155487
Validation loss: 2.1629238526026406

Epoch: 6| Step: 4
Training loss: 0.2272660732269287
Validation loss: 2.15544060866038

Epoch: 6| Step: 5
Training loss: 0.6237254738807678
Validation loss: 2.1476336320241294

Epoch: 6| Step: 6
Training loss: 0.18734966218471527
Validation loss: 2.111721078554789

Epoch: 6| Step: 7
Training loss: 0.18994030356407166
Validation loss: 2.136155843734741

Epoch: 6| Step: 8
Training loss: 0.3326770067214966
Validation loss: 2.1181467374165854

Epoch: 6| Step: 9
Training loss: 0.34147271513938904
Validation loss: 2.130447506904602

Epoch: 6| Step: 10
Training loss: 0.2956065237522125
Validation loss: 2.1241573492685952

Epoch: 6| Step: 11
Training loss: 0.5621870160102844
Validation loss: 2.1303371588389077

Epoch: 6| Step: 12
Training loss: 0.3521484136581421
Validation loss: 2.1504181027412415

Epoch: 6| Step: 13
Training loss: 0.2681785821914673
Validation loss: 2.1984729766845703

Epoch: 377| Step: 0
Training loss: 0.37067484855651855
Validation loss: 2.1926735440889993

Epoch: 6| Step: 1
Training loss: 0.3123711049556732
Validation loss: 2.1755845149358115

Epoch: 6| Step: 2
Training loss: 1.0459132194519043
Validation loss: 2.1843498150507608

Epoch: 6| Step: 3
Training loss: 0.24341750144958496
Validation loss: 2.1342711448669434

Epoch: 6| Step: 4
Training loss: 0.3260417580604553
Validation loss: 2.1190765698750815

Epoch: 6| Step: 5
Training loss: 0.2628377676010132
Validation loss: 2.1462448040644326

Epoch: 6| Step: 6
Training loss: 0.2668701410293579
Validation loss: 2.0821802417437234

Epoch: 6| Step: 7
Training loss: 0.3679634928703308
Validation loss: 2.1076237161954245

Epoch: 6| Step: 8
Training loss: 0.35730332136154175
Validation loss: 2.107895255088806

Epoch: 6| Step: 9
Training loss: 0.2681976854801178
Validation loss: 2.0986966689427695

Epoch: 6| Step: 10
Training loss: 0.34652939438819885
Validation loss: 2.165292044480642

Epoch: 6| Step: 11
Training loss: 0.42398273944854736
Validation loss: 2.1923826336860657

Epoch: 6| Step: 12
Training loss: 0.33541440963745117
Validation loss: 2.168489933013916

Epoch: 6| Step: 13
Training loss: 0.3238396644592285
Validation loss: 2.1767634749412537

Epoch: 378| Step: 0
Training loss: 0.457826167345047
Validation loss: 2.1600175698598227

Epoch: 6| Step: 1
Training loss: 0.3241581618785858
Validation loss: 2.155974328517914

Epoch: 6| Step: 2
Training loss: 0.14383962750434875
Validation loss: 2.0567137201627097

Epoch: 6| Step: 3
Training loss: 0.27616384625434875
Validation loss: 2.129575729370117

Epoch: 6| Step: 4
Training loss: 0.19379612803459167
Validation loss: 2.083555440107981

Epoch: 6| Step: 5
Training loss: 0.6671392917633057
Validation loss: 2.138308028380076

Epoch: 6| Step: 6
Training loss: 0.24053922295570374
Validation loss: 2.102467437585195

Epoch: 6| Step: 7
Training loss: 0.3191986382007599
Validation loss: 2.1429690519968667

Epoch: 6| Step: 8
Training loss: 0.28656724095344543
Validation loss: 2.1552991469701133

Epoch: 6| Step: 9
Training loss: 0.3952506184577942
Validation loss: 2.1713960766792297

Epoch: 6| Step: 10
Training loss: 0.40212365984916687
Validation loss: 2.190399090449015

Epoch: 6| Step: 11
Training loss: 0.27836787700653076
Validation loss: 2.120425581932068

Epoch: 6| Step: 12
Training loss: 0.2442459911108017
Validation loss: 2.1638217767079673

Epoch: 6| Step: 13
Training loss: 0.553019642829895
Validation loss: 2.12604691584905

Epoch: 379| Step: 0
Training loss: 0.38950115442276
Validation loss: 2.1326642831166587

Epoch: 6| Step: 1
Training loss: 0.21160025894641876
Validation loss: 2.1403799653053284

Epoch: 6| Step: 2
Training loss: 0.389442503452301
Validation loss: 2.136568029721578

Epoch: 6| Step: 3
Training loss: 0.1970221996307373
Validation loss: 2.169011374314626

Epoch: 6| Step: 4
Training loss: 0.1990906000137329
Validation loss: 2.120113492012024

Epoch: 6| Step: 5
Training loss: 0.26416724920272827
Validation loss: 2.114755630493164

Epoch: 6| Step: 6
Training loss: 0.5210468769073486
Validation loss: 2.122248411178589

Epoch: 6| Step: 7
Training loss: 0.3154268264770508
Validation loss: 2.1348520119984946

Epoch: 6| Step: 8
Training loss: 0.5950561761856079
Validation loss: 2.0832675298055015

Epoch: 6| Step: 9
Training loss: 0.33069825172424316
Validation loss: 2.101188898086548

Epoch: 6| Step: 10
Training loss: 0.321414589881897
Validation loss: 2.1394125620524087

Epoch: 6| Step: 11
Training loss: 0.15527981519699097
Validation loss: 2.139291067918142

Epoch: 6| Step: 12
Training loss: 0.27748042345046997
Validation loss: 2.1703734000523887

Epoch: 6| Step: 13
Training loss: 0.3854712247848511
Validation loss: 2.078221638997396

Epoch: 380| Step: 0
Training loss: 0.4177749752998352
Validation loss: 2.1676579117774963

Epoch: 6| Step: 1
Training loss: 0.6610998511314392
Validation loss: 2.1049499114354453

Epoch: 6| Step: 2
Training loss: 0.22382420301437378
Validation loss: 2.165680408477783

Epoch: 6| Step: 3
Training loss: 0.25588321685791016
Validation loss: 2.163386344909668

Epoch: 6| Step: 4
Training loss: 0.24648304283618927
Validation loss: 2.151570975780487

Epoch: 6| Step: 5
Training loss: 0.1716812252998352
Validation loss: 2.107640504837036

Epoch: 6| Step: 6
Training loss: 0.49528592824935913
Validation loss: 2.14686785141627

Epoch: 6| Step: 7
Training loss: 0.3256685733795166
Validation loss: 2.1366066932678223

Epoch: 6| Step: 8
Training loss: 0.2760254740715027
Validation loss: 2.169590950012207

Epoch: 6| Step: 9
Training loss: 0.29671353101730347
Validation loss: 2.177276372909546

Epoch: 6| Step: 10
Training loss: 0.26320186257362366
Validation loss: 2.2021860678990683

Epoch: 6| Step: 11
Training loss: 0.2514026463031769
Validation loss: 2.1659812927246094

Epoch: 6| Step: 12
Training loss: 0.41915464401245117
Validation loss: 2.123769919077555

Epoch: 6| Step: 13
Training loss: 0.22784368693828583
Validation loss: 2.1527435978253684

Epoch: 381| Step: 0
Training loss: 0.2672783136367798
Validation loss: 2.152843455473582

Epoch: 6| Step: 1
Training loss: 0.46924903988838196
Validation loss: 2.0718244711558023

Epoch: 6| Step: 2
Training loss: 0.40964820981025696
Validation loss: 2.1034095684687295

Epoch: 6| Step: 3
Training loss: 0.3007543981075287
Validation loss: 2.137727697690328

Epoch: 6| Step: 4
Training loss: 0.31146422028541565
Validation loss: 2.1869834264119468

Epoch: 6| Step: 5
Training loss: 0.4714714586734772
Validation loss: 2.221540848414103

Epoch: 6| Step: 6
Training loss: 0.24675031006336212
Validation loss: 2.1812320947647095

Epoch: 6| Step: 7
Training loss: 0.28617703914642334
Validation loss: 2.178174674510956

Epoch: 6| Step: 8
Training loss: 0.252986341714859
Validation loss: 2.1465194821357727

Epoch: 6| Step: 9
Training loss: 0.17462459206581116
Validation loss: 2.1556390523910522

Epoch: 6| Step: 10
Training loss: 0.2558637261390686
Validation loss: 2.1382917960484824

Epoch: 6| Step: 11
Training loss: 0.3547496199607849
Validation loss: 2.116597831249237

Epoch: 6| Step: 12
Training loss: 0.6603938937187195
Validation loss: 2.060970902442932

Epoch: 6| Step: 13
Training loss: 0.3349319100379944
Validation loss: 2.1070337891578674

Epoch: 382| Step: 0
Training loss: 0.3011876046657562
Validation loss: 2.1654649575551352

Epoch: 6| Step: 1
Training loss: 0.2619822025299072
Validation loss: 2.1714211901028952

Epoch: 6| Step: 2
Training loss: 0.2539730966091156
Validation loss: 2.154659152030945

Epoch: 6| Step: 3
Training loss: 0.20728005468845367
Validation loss: 2.159432848294576

Epoch: 6| Step: 4
Training loss: 0.2060328722000122
Validation loss: 2.1477674643198648

Epoch: 6| Step: 5
Training loss: 0.25868672132492065
Validation loss: 2.119142174720764

Epoch: 6| Step: 6
Training loss: 0.32828065752983093
Validation loss: 2.1329994400342307

Epoch: 6| Step: 7
Training loss: 0.45307838916778564
Validation loss: 2.1255659461021423

Epoch: 6| Step: 8
Training loss: 0.37009158730506897
Validation loss: 2.1154578725496926

Epoch: 6| Step: 9
Training loss: 0.5692788362503052
Validation loss: 2.1350563565889993

Epoch: 6| Step: 10
Training loss: 0.2971801161766052
Validation loss: 2.1702810724576316

Epoch: 6| Step: 11
Training loss: 0.36458414793014526
Validation loss: 2.145563066005707

Epoch: 6| Step: 12
Training loss: 0.4874457120895386
Validation loss: 2.1249834299087524

Epoch: 6| Step: 13
Training loss: 0.2642548084259033
Validation loss: 2.1150810718536377

Epoch: 383| Step: 0
Training loss: 0.3484797477722168
Validation loss: 2.1473403175671897

Epoch: 6| Step: 1
Training loss: 0.6370033025741577
Validation loss: 2.0721798737843833

Epoch: 6| Step: 2
Training loss: 0.28335869312286377
Validation loss: 2.1844214598337808

Epoch: 6| Step: 3
Training loss: 0.3206905424594879
Validation loss: 2.1576498548189798

Epoch: 6| Step: 4
Training loss: 0.2379353940486908
Validation loss: 2.1614731748898826

Epoch: 6| Step: 5
Training loss: 0.6169525384902954
Validation loss: 2.1666529973347983

Epoch: 6| Step: 6
Training loss: 0.6047216653823853
Validation loss: 2.162902553876241

Epoch: 6| Step: 7
Training loss: 0.34617775678634644
Validation loss: 2.109090348084768

Epoch: 6| Step: 8
Training loss: 0.1967622935771942
Validation loss: 2.1007437109947205

Epoch: 6| Step: 9
Training loss: 0.24149250984191895
Validation loss: 2.1234558820724487

Epoch: 6| Step: 10
Training loss: 0.2472507208585739
Validation loss: 2.1325648029645285

Epoch: 6| Step: 11
Training loss: 0.29299262166023254
Validation loss: 2.1153875589370728

Epoch: 6| Step: 12
Training loss: 0.2740950882434845
Validation loss: 2.1965312361717224

Epoch: 6| Step: 13
Training loss: 0.414943665266037
Validation loss: 2.1576287150382996

Epoch: 384| Step: 0
Training loss: 0.3577941656112671
Validation loss: 2.179020901521047

Epoch: 6| Step: 1
Training loss: 0.20653413236141205
Validation loss: 2.134187658627828

Epoch: 6| Step: 2
Training loss: 0.23957979679107666
Validation loss: 2.1557640631993613

Epoch: 6| Step: 3
Training loss: 0.2795063257217407
Validation loss: 2.1522987286249795

Epoch: 6| Step: 4
Training loss: 0.6140393018722534
Validation loss: 2.092595160007477

Epoch: 6| Step: 5
Training loss: 0.28410661220550537
Validation loss: 2.109908183415731

Epoch: 6| Step: 6
Training loss: 0.20298653841018677
Validation loss: 2.143269340197245

Epoch: 6| Step: 7
Training loss: 0.3038330674171448
Validation loss: 2.094651520252228

Epoch: 6| Step: 8
Training loss: 0.2450944483280182
Validation loss: 2.1661826372146606

Epoch: 6| Step: 9
Training loss: 0.3522295653820038
Validation loss: 2.1877447168032327

Epoch: 6| Step: 10
Training loss: 0.36538660526275635
Validation loss: 2.1828269561131797

Epoch: 6| Step: 11
Training loss: 0.3141225576400757
Validation loss: 2.123722036679586

Epoch: 6| Step: 12
Training loss: 0.5305092334747314
Validation loss: 2.1177162726720176

Epoch: 6| Step: 13
Training loss: 0.4670291543006897
Validation loss: 2.110641141732534

Epoch: 385| Step: 0
Training loss: 0.270160973072052
Validation loss: 2.1207095781962075

Epoch: 6| Step: 1
Training loss: 0.3776683211326599
Validation loss: 2.1399309635162354

Epoch: 6| Step: 2
Training loss: 0.6396977305412292
Validation loss: 2.1361034711201987

Epoch: 6| Step: 3
Training loss: 0.2171216458082199
Validation loss: 2.1169340213139853

Epoch: 6| Step: 4
Training loss: 0.48177775740623474
Validation loss: 2.1653853257497153

Epoch: 6| Step: 5
Training loss: 0.22439385950565338
Validation loss: 2.1510714093844094

Epoch: 6| Step: 6
Training loss: 0.4155545234680176
Validation loss: 2.154390891393026

Epoch: 6| Step: 7
Training loss: 0.36023181676864624
Validation loss: 2.131153166294098

Epoch: 6| Step: 8
Training loss: 0.3368876278400421
Validation loss: 2.0748285055160522

Epoch: 6| Step: 9
Training loss: 0.2554605007171631
Validation loss: 2.085542917251587

Epoch: 6| Step: 10
Training loss: 0.29777076840400696
Validation loss: 2.091069241364797

Epoch: 6| Step: 11
Training loss: 0.3041132688522339
Validation loss: 2.0850799679756165

Epoch: 6| Step: 12
Training loss: 0.3969813287258148
Validation loss: 2.146156132221222

Epoch: 6| Step: 13
Training loss: 0.3227742314338684
Validation loss: 2.1454415321350098

Epoch: 386| Step: 0
Training loss: 0.26267701387405396
Validation loss: 2.1615023215611777

Epoch: 6| Step: 1
Training loss: 0.2729828655719757
Validation loss: 2.110491693019867

Epoch: 6| Step: 2
Training loss: 0.5590827465057373
Validation loss: 2.164249539375305

Epoch: 6| Step: 3
Training loss: 0.16352447867393494
Validation loss: 2.1511874397595725

Epoch: 6| Step: 4
Training loss: 0.29601627588272095
Validation loss: 2.136349340279897

Epoch: 6| Step: 5
Training loss: 0.3380752205848694
Validation loss: 2.1283087730407715

Epoch: 6| Step: 6
Training loss: 0.3306870758533478
Validation loss: 2.099322497844696

Epoch: 6| Step: 7
Training loss: 0.21824592351913452
Validation loss: 2.125139514605204

Epoch: 6| Step: 8
Training loss: 0.4187127351760864
Validation loss: 2.1761662562688193

Epoch: 6| Step: 9
Training loss: 0.2758296728134155
Validation loss: 2.1432047486305237

Epoch: 6| Step: 10
Training loss: 0.5544123649597168
Validation loss: 2.1147230664889016

Epoch: 6| Step: 11
Training loss: 0.27853551506996155
Validation loss: 2.140583097934723

Epoch: 6| Step: 12
Training loss: 0.32493746280670166
Validation loss: 2.158474306265513

Epoch: 6| Step: 13
Training loss: 0.30066370964050293
Validation loss: 2.1294323007265725

Epoch: 387| Step: 0
Training loss: 0.3856119215488434
Validation loss: 2.1454694867134094

Epoch: 6| Step: 1
Training loss: 0.3967975080013275
Validation loss: 2.1518816351890564

Epoch: 6| Step: 2
Training loss: 0.22068771719932556
Validation loss: 2.1206080118815103

Epoch: 6| Step: 3
Training loss: 0.4158779978752136
Validation loss: 2.185682992140452

Epoch: 6| Step: 4
Training loss: 0.3045905828475952
Validation loss: 2.137499729792277

Epoch: 6| Step: 5
Training loss: 0.27478301525115967
Validation loss: 2.133888224760691

Epoch: 6| Step: 6
Training loss: 0.363433301448822
Validation loss: 2.133822758992513

Epoch: 6| Step: 7
Training loss: 0.1900736689567566
Validation loss: 2.1866687337557473

Epoch: 6| Step: 8
Training loss: 0.22106488049030304
Validation loss: 2.1170563300450644

Epoch: 6| Step: 9
Training loss: 0.20499560236930847
Validation loss: 2.139056622982025

Epoch: 6| Step: 10
Training loss: 0.2405143678188324
Validation loss: 2.179190436999003

Epoch: 6| Step: 11
Training loss: 0.5129520893096924
Validation loss: 2.15362811088562

Epoch: 6| Step: 12
Training loss: 0.7649619579315186
Validation loss: 2.235018730163574

Epoch: 6| Step: 13
Training loss: 0.3428221344947815
Validation loss: 2.1611350377400718

Epoch: 388| Step: 0
Training loss: 0.38179805874824524
Validation loss: 2.106026212374369

Epoch: 6| Step: 1
Training loss: 0.27703991532325745
Validation loss: 2.1491855581601462

Epoch: 6| Step: 2
Training loss: 0.7798702716827393
Validation loss: 2.1394657691319785

Epoch: 6| Step: 3
Training loss: 0.2866734564304352
Validation loss: 2.195167819658915

Epoch: 6| Step: 4
Training loss: 0.2789582312107086
Validation loss: 2.1357195576032004

Epoch: 6| Step: 5
Training loss: 0.3793284296989441
Validation loss: 2.165440022945404

Epoch: 6| Step: 6
Training loss: 0.3419855237007141
Validation loss: 2.136785844961802

Epoch: 6| Step: 7
Training loss: 0.26321351528167725
Validation loss: 2.13224865992864

Epoch: 6| Step: 8
Training loss: 0.2778071165084839
Validation loss: 2.1803663969039917

Epoch: 6| Step: 9
Training loss: 0.3818452060222626
Validation loss: 2.1107752521832785

Epoch: 6| Step: 10
Training loss: 0.4301418662071228
Validation loss: 2.1327930887540183

Epoch: 6| Step: 11
Training loss: 0.2141379565000534
Validation loss: 2.1049882769584656

Epoch: 6| Step: 12
Training loss: 0.30022603273391724
Validation loss: 2.1214565436045327

Epoch: 6| Step: 13
Training loss: 0.25085705518722534
Validation loss: 2.1928728024164834

Epoch: 389| Step: 0
Training loss: 0.1801263988018036
Validation loss: 2.18067995707194

Epoch: 6| Step: 1
Training loss: 0.2290331870317459
Validation loss: 2.18008029460907

Epoch: 6| Step: 2
Training loss: 0.27538493275642395
Validation loss: 2.117348551750183

Epoch: 6| Step: 3
Training loss: 0.3854104280471802
Validation loss: 2.1335678895314536

Epoch: 6| Step: 4
Training loss: 0.6786397099494934
Validation loss: 2.153556783994039

Epoch: 6| Step: 5
Training loss: 0.3332687020301819
Validation loss: 2.0971262057622275

Epoch: 6| Step: 6
Training loss: 0.38203728199005127
Validation loss: 2.0863192081451416

Epoch: 6| Step: 7
Training loss: 0.41120409965515137
Validation loss: 2.1528621912002563

Epoch: 6| Step: 8
Training loss: 0.22698308527469635
Validation loss: 2.1233994166056314

Epoch: 6| Step: 9
Training loss: 0.28926515579223633
Validation loss: 2.135957896709442

Epoch: 6| Step: 10
Training loss: 0.2180744707584381
Validation loss: 2.1220902800559998

Epoch: 6| Step: 11
Training loss: 0.22402119636535645
Validation loss: 2.1015076438585916

Epoch: 6| Step: 12
Training loss: 0.22588658332824707
Validation loss: 2.1072811683019004

Epoch: 6| Step: 13
Training loss: 0.18319019675254822
Validation loss: 2.127931217352549

Epoch: 390| Step: 0
Training loss: 0.25376391410827637
Validation loss: 2.1299514373143515

Epoch: 6| Step: 1
Training loss: 0.3075774908065796
Validation loss: 2.154707988103231

Epoch: 6| Step: 2
Training loss: 0.4338836669921875
Validation loss: 2.1721661488215127

Epoch: 6| Step: 3
Training loss: 0.2762141227722168
Validation loss: 2.1208558678627014

Epoch: 6| Step: 4
Training loss: 0.17333394289016724
Validation loss: 2.18804798523585

Epoch: 6| Step: 5
Training loss: 0.4121270775794983
Validation loss: 2.119337280591329

Epoch: 6| Step: 6
Training loss: 0.18243689835071564
Validation loss: 2.11980410416921

Epoch: 6| Step: 7
Training loss: 0.5843387842178345
Validation loss: 2.1824618379275003

Epoch: 6| Step: 8
Training loss: 0.3138669729232788
Validation loss: 2.115610718727112

Epoch: 6| Step: 9
Training loss: 0.29452842473983765
Validation loss: 2.137253681818644

Epoch: 6| Step: 10
Training loss: 0.194026917219162
Validation loss: 2.1139293909072876

Epoch: 6| Step: 11
Training loss: 0.2450011968612671
Validation loss: 2.147198975086212

Epoch: 6| Step: 12
Training loss: 0.42944806814193726
Validation loss: 2.1637179454167685

Epoch: 6| Step: 13
Training loss: 0.24217593669891357
Validation loss: 2.1524316469828286

Epoch: 391| Step: 0
Training loss: 0.2433292120695114
Validation loss: 2.1396592259407043

Epoch: 6| Step: 1
Training loss: 0.31214138865470886
Validation loss: 2.151161472002665

Epoch: 6| Step: 2
Training loss: 0.49949175119400024
Validation loss: 2.1176246404647827

Epoch: 6| Step: 3
Training loss: 0.3751511573791504
Validation loss: 2.163495103518168

Epoch: 6| Step: 4
Training loss: 0.5271097421646118
Validation loss: 2.1076552073160806

Epoch: 6| Step: 5
Training loss: 0.5839624404907227
Validation loss: 2.1294518311818442

Epoch: 6| Step: 6
Training loss: 0.2608499526977539
Validation loss: 2.120848457018534

Epoch: 6| Step: 7
Training loss: 0.23498237133026123
Validation loss: 2.159078081448873

Epoch: 6| Step: 8
Training loss: 0.40072566270828247
Validation loss: 2.124870697657267

Epoch: 6| Step: 9
Training loss: 0.361586332321167
Validation loss: 2.1285934249560037

Epoch: 6| Step: 10
Training loss: 0.3334018588066101
Validation loss: 2.1791548331578574

Epoch: 6| Step: 11
Training loss: 0.2583490014076233
Validation loss: 2.12380450963974

Epoch: 6| Step: 12
Training loss: 0.3337457776069641
Validation loss: 2.073360860347748

Epoch: 6| Step: 13
Training loss: 0.4277735948562622
Validation loss: 2.090717315673828

Epoch: 392| Step: 0
Training loss: 0.41974905133247375
Validation loss: 2.114566922187805

Epoch: 6| Step: 1
Training loss: 0.2520780861377716
Validation loss: 2.0859670639038086

Epoch: 6| Step: 2
Training loss: 0.3850080072879791
Validation loss: 2.1129780610402427

Epoch: 6| Step: 3
Training loss: 0.43755418062210083
Validation loss: 2.098615308602651

Epoch: 6| Step: 4
Training loss: 0.22490769624710083
Validation loss: 2.149487634499868

Epoch: 6| Step: 5
Training loss: 0.6471168994903564
Validation loss: 2.1331273516019187

Epoch: 6| Step: 6
Training loss: 0.4408661723136902
Validation loss: 2.130873918533325

Epoch: 6| Step: 7
Training loss: 0.2769925594329834
Validation loss: 2.1621466676394143

Epoch: 6| Step: 8
Training loss: 0.3425009846687317
Validation loss: 2.131714105606079

Epoch: 6| Step: 9
Training loss: 0.2779028117656708
Validation loss: 2.140257716178894

Epoch: 6| Step: 10
Training loss: 0.30586326122283936
Validation loss: 2.1108542680740356

Epoch: 6| Step: 11
Training loss: 0.21663615107536316
Validation loss: 2.0636357267697654

Epoch: 6| Step: 12
Training loss: 0.27643054723739624
Validation loss: 2.114764849344889

Epoch: 6| Step: 13
Training loss: 0.4521675407886505
Validation loss: 2.1163568099339805

Epoch: 393| Step: 0
Training loss: 0.3260943293571472
Validation loss: 2.1191867788632712

Epoch: 6| Step: 1
Training loss: 0.30674290657043457
Validation loss: 2.1645957430203757

Epoch: 6| Step: 2
Training loss: 0.2450987994670868
Validation loss: 2.153817375500997

Epoch: 6| Step: 3
Training loss: 0.31583940982818604
Validation loss: 2.1114493211110434

Epoch: 6| Step: 4
Training loss: 0.33911600708961487
Validation loss: 2.120088040828705

Epoch: 6| Step: 5
Training loss: 0.37392908334732056
Validation loss: 2.070197661717733

Epoch: 6| Step: 6
Training loss: 0.31037449836730957
Validation loss: 2.0919418136278787

Epoch: 6| Step: 7
Training loss: 0.22926807403564453
Validation loss: 2.141253709793091

Epoch: 6| Step: 8
Training loss: 0.3688199520111084
Validation loss: 2.172924975554148

Epoch: 6| Step: 9
Training loss: 0.7526947259902954
Validation loss: 2.176534573237101

Epoch: 6| Step: 10
Training loss: 0.2697097063064575
Validation loss: 2.129145403703054

Epoch: 6| Step: 11
Training loss: 0.3932960033416748
Validation loss: 2.2113264997800193

Epoch: 6| Step: 12
Training loss: 0.21150361001491547
Validation loss: 2.114993989467621

Epoch: 6| Step: 13
Training loss: 0.38593924045562744
Validation loss: 2.115395426750183

Epoch: 394| Step: 0
Training loss: 0.2678760886192322
Validation loss: 2.105522572994232

Epoch: 6| Step: 1
Training loss: 0.23978257179260254
Validation loss: 2.097598115603129

Epoch: 6| Step: 2
Training loss: 0.16387483477592468
Validation loss: 2.1193849643071494

Epoch: 6| Step: 3
Training loss: 0.20343077182769775
Validation loss: 2.1196014483769736

Epoch: 6| Step: 4
Training loss: 0.3808334171772003
Validation loss: 2.1273837288220725

Epoch: 6| Step: 5
Training loss: 0.19781407713890076
Validation loss: 2.09506364663442

Epoch: 6| Step: 6
Training loss: 0.3599452078342438
Validation loss: 2.1133945186932883

Epoch: 6| Step: 7
Training loss: 0.796845555305481
Validation loss: 2.1221317450205484

Epoch: 6| Step: 8
Training loss: 0.3794810175895691
Validation loss: 2.1441185077031455

Epoch: 6| Step: 9
Training loss: 0.27736273407936096
Validation loss: 2.1629327734311423

Epoch: 6| Step: 10
Training loss: 0.4004363417625427
Validation loss: 2.1598196228345237

Epoch: 6| Step: 11
Training loss: 0.3285937011241913
Validation loss: 2.112030247847239

Epoch: 6| Step: 12
Training loss: 0.2026369571685791
Validation loss: 2.1324204405148826

Epoch: 6| Step: 13
Training loss: 0.19358834624290466
Validation loss: 2.0768699645996094

Epoch: 395| Step: 0
Training loss: 0.30116409063339233
Validation loss: 2.085617244243622

Epoch: 6| Step: 1
Training loss: 0.29515016078948975
Validation loss: 2.1125014821688333

Epoch: 6| Step: 2
Training loss: 0.2452351599931717
Validation loss: 2.1448103388150535

Epoch: 6| Step: 3
Training loss: 0.2413760870695114
Validation loss: 2.135051131248474

Epoch: 6| Step: 4
Training loss: 0.13447795808315277
Validation loss: 2.190681000550588

Epoch: 6| Step: 5
Training loss: 0.29132556915283203
Validation loss: 2.120226502418518

Epoch: 6| Step: 6
Training loss: 0.2976154088973999
Validation loss: 2.1487329800923667

Epoch: 6| Step: 7
Training loss: 0.2366580069065094
Validation loss: 2.1353216568628945

Epoch: 6| Step: 8
Training loss: 0.44642409682273865
Validation loss: 2.1349905331929526

Epoch: 6| Step: 9
Training loss: 0.3788928687572479
Validation loss: 2.0794796546300254

Epoch: 6| Step: 10
Training loss: 0.41352757811546326
Validation loss: 2.1096654335657754

Epoch: 6| Step: 11
Training loss: 0.2260397970676422
Validation loss: 2.142134666442871

Epoch: 6| Step: 12
Training loss: 0.12789742648601532
Validation loss: 2.1263128519058228

Epoch: 6| Step: 13
Training loss: 0.6499898433685303
Validation loss: 2.1893749634424844

Epoch: 396| Step: 0
Training loss: 0.5952058434486389
Validation loss: 2.1250951488812766

Epoch: 6| Step: 1
Training loss: 0.27552470564842224
Validation loss: 2.1621859471003213

Epoch: 6| Step: 2
Training loss: 0.24109333753585815
Validation loss: 2.1420712073644004

Epoch: 6| Step: 3
Training loss: 0.45889177918434143
Validation loss: 2.151675224304199

Epoch: 6| Step: 4
Training loss: 0.35174626111984253
Validation loss: 2.168042620023092

Epoch: 6| Step: 5
Training loss: 0.2663499414920807
Validation loss: 2.1090720891952515

Epoch: 6| Step: 6
Training loss: 0.7143646478652954
Validation loss: 2.172133723894755

Epoch: 6| Step: 7
Training loss: 0.241908997297287
Validation loss: 2.1257334550221763

Epoch: 6| Step: 8
Training loss: 0.2433892786502838
Validation loss: 2.094025711218516

Epoch: 6| Step: 9
Training loss: 0.29195892810821533
Validation loss: 2.2096324364344277

Epoch: 6| Step: 10
Training loss: 0.2593277096748352
Validation loss: 2.141256093978882

Epoch: 6| Step: 11
Training loss: 0.2722020447254181
Validation loss: 2.14670201142629

Epoch: 6| Step: 12
Training loss: 0.22962936758995056
Validation loss: 2.165874262650808

Epoch: 6| Step: 13
Training loss: 0.20239506661891937
Validation loss: 2.1393476724624634

Epoch: 397| Step: 0
Training loss: 0.15706251561641693
Validation loss: 2.1362035075823465

Epoch: 6| Step: 1
Training loss: 0.35182279348373413
Validation loss: 2.1203481753667197

Epoch: 6| Step: 2
Training loss: 0.257315456867218
Validation loss: 2.122033496697744

Epoch: 6| Step: 3
Training loss: 0.6106564998626709
Validation loss: 2.1273016134897866

Epoch: 6| Step: 4
Training loss: 0.22094836831092834
Validation loss: 2.1366652846336365

Epoch: 6| Step: 5
Training loss: 0.3190276026725769
Validation loss: 2.1504265666007996

Epoch: 6| Step: 6
Training loss: 0.3877139389514923
Validation loss: 2.146634817123413

Epoch: 6| Step: 7
Training loss: 0.24312154948711395
Validation loss: 2.1286523739496865

Epoch: 6| Step: 8
Training loss: 0.28018540143966675
Validation loss: 2.089262048403422

Epoch: 6| Step: 9
Training loss: 0.3629870116710663
Validation loss: 2.1407903830210366

Epoch: 6| Step: 10
Training loss: 0.2386680394411087
Validation loss: 2.1000630259513855

Epoch: 6| Step: 11
Training loss: 0.17280441522598267
Validation loss: 2.1474854747454324

Epoch: 6| Step: 12
Training loss: 0.16722527146339417
Validation loss: 2.120308001836141

Epoch: 6| Step: 13
Training loss: 0.25056278705596924
Validation loss: 2.108028829097748

Epoch: 398| Step: 0
Training loss: 0.1817830353975296
Validation loss: 2.101687788963318

Epoch: 6| Step: 1
Training loss: 0.44794172048568726
Validation loss: 2.1603659788767495

Epoch: 6| Step: 2
Training loss: 0.16166386008262634
Validation loss: 2.1234535574913025

Epoch: 6| Step: 3
Training loss: 0.6792129278182983
Validation loss: 2.1341780026753745

Epoch: 6| Step: 4
Training loss: 0.28395283222198486
Validation loss: 2.1347707907358804

Epoch: 6| Step: 5
Training loss: 0.1946471929550171
Validation loss: 2.141314685344696

Epoch: 6| Step: 6
Training loss: 0.2856784462928772
Validation loss: 2.0963419675827026

Epoch: 6| Step: 7
Training loss: 0.26481711864471436
Validation loss: 2.1690126061439514

Epoch: 6| Step: 8
Training loss: 0.25865912437438965
Validation loss: 2.0909063617388406

Epoch: 6| Step: 9
Training loss: 0.19641238451004028
Validation loss: 2.1162217458089194

Epoch: 6| Step: 10
Training loss: 0.1474858671426773
Validation loss: 2.1179985404014587

Epoch: 6| Step: 11
Training loss: 0.5574557781219482
Validation loss: 2.117287039756775

Epoch: 6| Step: 12
Training loss: 0.18940341472625732
Validation loss: 2.156161586443583

Epoch: 6| Step: 13
Training loss: 0.3419187366962433
Validation loss: 2.1391186316808066

Epoch: 399| Step: 0
Training loss: 0.2636447846889496
Validation loss: 2.1658096313476562

Epoch: 6| Step: 1
Training loss: 0.8243509531021118
Validation loss: 2.1373093525568643

Epoch: 6| Step: 2
Training loss: 0.3899734616279602
Validation loss: 2.152206838130951

Epoch: 6| Step: 3
Training loss: 0.41488367319107056
Validation loss: 2.1093361377716064

Epoch: 6| Step: 4
Training loss: 0.2991476356983185
Validation loss: 2.1272334655125937

Epoch: 6| Step: 5
Training loss: 0.2650749087333679
Validation loss: 2.13684872786204

Epoch: 6| Step: 6
Training loss: 0.30472755432128906
Validation loss: 2.0840771198272705

Epoch: 6| Step: 7
Training loss: 0.301743745803833
Validation loss: 2.1467719276746116

Epoch: 6| Step: 8
Training loss: 0.25010907649993896
Validation loss: 2.151679515838623

Epoch: 6| Step: 9
Training loss: 0.27973783016204834
Validation loss: 2.1729503075281777

Epoch: 6| Step: 10
Training loss: 0.23154790699481964
Validation loss: 2.1630837122599282

Epoch: 6| Step: 11
Training loss: 0.2514331638813019
Validation loss: 2.153257668018341

Epoch: 6| Step: 12
Training loss: 0.35940125584602356
Validation loss: 2.114054560661316

Epoch: 6| Step: 13
Training loss: 0.3418983817100525
Validation loss: 2.0954683423042297

Epoch: 400| Step: 0
Training loss: 0.3533601462841034
Validation loss: 2.1148469845453897

Epoch: 6| Step: 1
Training loss: 0.3710828721523285
Validation loss: 2.141294240951538

Epoch: 6| Step: 2
Training loss: 0.46135613322257996
Validation loss: 2.1444978515307107

Epoch: 6| Step: 3
Training loss: 0.21444061398506165
Validation loss: 2.1468642354011536

Epoch: 6| Step: 4
Training loss: 0.2640838623046875
Validation loss: 2.1869602600733438

Epoch: 6| Step: 5
Training loss: 0.3332284986972809
Validation loss: 2.187115947405497

Epoch: 6| Step: 6
Training loss: 0.3482816815376282
Validation loss: 2.141692300637563

Epoch: 6| Step: 7
Training loss: 0.34810662269592285
Validation loss: 2.103537996610006

Epoch: 6| Step: 8
Training loss: 0.24072907865047455
Validation loss: 2.0876707633336387

Epoch: 6| Step: 9
Training loss: 0.23170988261699677
Validation loss: 2.1234167416890464

Epoch: 6| Step: 10
Training loss: 0.3672928214073181
Validation loss: 2.1499722003936768

Epoch: 6| Step: 11
Training loss: 0.23406141996383667
Validation loss: 2.1484633088111877

Epoch: 6| Step: 12
Training loss: 0.6052951812744141
Validation loss: 2.207431515057882

Epoch: 6| Step: 13
Training loss: 0.3591483235359192
Validation loss: 2.1332213481267295

Epoch: 401| Step: 0
Training loss: 0.3249509930610657
Validation loss: 2.139948765436808

Epoch: 6| Step: 1
Training loss: 0.3141750693321228
Validation loss: 2.173409581184387

Epoch: 6| Step: 2
Training loss: 0.2041158527135849
Validation loss: 2.091794411341349

Epoch: 6| Step: 3
Training loss: 0.19390733540058136
Validation loss: 2.152857184410095

Epoch: 6| Step: 4
Training loss: 0.22849737107753754
Validation loss: 2.0795968969662986

Epoch: 6| Step: 5
Training loss: 0.3317844867706299
Validation loss: 2.1051703492800393

Epoch: 6| Step: 6
Training loss: 0.4182268977165222
Validation loss: 2.0909835497538247

Epoch: 6| Step: 7
Training loss: 0.1933298408985138
Validation loss: 2.1326165994008384

Epoch: 6| Step: 8
Training loss: 0.42036134004592896
Validation loss: 2.129350562890371

Epoch: 6| Step: 9
Training loss: 0.6586005091667175
Validation loss: 2.1534049113591514

Epoch: 6| Step: 10
Training loss: 0.2017298936843872
Validation loss: 2.1584788958231607

Epoch: 6| Step: 11
Training loss: 0.4216683804988861
Validation loss: 2.1535529692967734

Epoch: 6| Step: 12
Training loss: 0.38020098209381104
Validation loss: 2.0929306944211326

Epoch: 6| Step: 13
Training loss: 0.249818354845047
Validation loss: 2.1186614831288657

Epoch: 402| Step: 0
Training loss: 0.422545850276947
Validation loss: 2.120672821998596

Epoch: 6| Step: 1
Training loss: 0.9246419668197632
Validation loss: 2.1514251430829368

Epoch: 6| Step: 2
Training loss: 0.3261391520500183
Validation loss: 2.095199545224508

Epoch: 6| Step: 3
Training loss: 0.4376627504825592
Validation loss: 2.074972450733185

Epoch: 6| Step: 4
Training loss: 0.2251078337430954
Validation loss: 2.1265262166659036

Epoch: 6| Step: 5
Training loss: 0.2919010519981384
Validation loss: 2.100879708925883

Epoch: 6| Step: 6
Training loss: 0.20378440618515015
Validation loss: 2.143702248732249

Epoch: 6| Step: 7
Training loss: 0.4595027267932892
Validation loss: 2.206176221370697

Epoch: 6| Step: 8
Training loss: 0.23583851754665375
Validation loss: 2.17497311035792

Epoch: 6| Step: 9
Training loss: 0.252763569355011
Validation loss: 2.1183323661486306

Epoch: 6| Step: 10
Training loss: 0.3760972023010254
Validation loss: 2.05070036649704

Epoch: 6| Step: 11
Training loss: 0.2601708173751831
Validation loss: 2.0952895482381186

Epoch: 6| Step: 12
Training loss: 0.41821807622909546
Validation loss: 2.0934962828954062

Epoch: 6| Step: 13
Training loss: 0.24099129438400269
Validation loss: 2.065630614757538

Epoch: 403| Step: 0
Training loss: 0.24429363012313843
Validation loss: 2.1895243922869363

Epoch: 6| Step: 1
Training loss: 0.4146053194999695
Validation loss: 2.1463467280069985

Epoch: 6| Step: 2
Training loss: 0.3128817677497864
Validation loss: 2.189938028653463

Epoch: 6| Step: 3
Training loss: 0.41919034719467163
Validation loss: 2.171379725138346

Epoch: 6| Step: 4
Training loss: 0.322892427444458
Validation loss: 2.147386650244395

Epoch: 6| Step: 5
Training loss: 0.24519573152065277
Validation loss: 2.1614267031351724

Epoch: 6| Step: 6
Training loss: 0.2595386505126953
Validation loss: 2.1023317774136863

Epoch: 6| Step: 7
Training loss: 0.4158323407173157
Validation loss: 2.127116560935974

Epoch: 6| Step: 8
Training loss: 0.3388679623603821
Validation loss: 2.152059555053711

Epoch: 6| Step: 9
Training loss: 0.35177040100097656
Validation loss: 2.138253072897593

Epoch: 6| Step: 10
Training loss: 0.5191270112991333
Validation loss: 2.1882346073786416

Epoch: 6| Step: 11
Training loss: 0.19573161005973816
Validation loss: 2.1270450750986734

Epoch: 6| Step: 12
Training loss: 0.23708423972129822
Validation loss: 2.1396997968355813

Epoch: 6| Step: 13
Training loss: 0.2676768898963928
Validation loss: 2.1731900175412497

Epoch: 404| Step: 0
Training loss: 0.2539733052253723
Validation loss: 2.123638927936554

Epoch: 6| Step: 1
Training loss: 0.28307807445526123
Validation loss: 2.1327641208966575

Epoch: 6| Step: 2
Training loss: 0.4097661077976227
Validation loss: 2.1096181670824685

Epoch: 6| Step: 3
Training loss: 0.39882713556289673
Validation loss: 2.1332394083340964

Epoch: 6| Step: 4
Training loss: 0.23776482045650482
Validation loss: 2.1896215875943503

Epoch: 6| Step: 5
Training loss: 0.3127865195274353
Validation loss: 2.1625072161356607

Epoch: 6| Step: 6
Training loss: 0.3503117561340332
Validation loss: 2.183840741713842

Epoch: 6| Step: 7
Training loss: 0.17544451355934143
Validation loss: 2.145424962043762

Epoch: 6| Step: 8
Training loss: 0.3133411705493927
Validation loss: 2.0848885973294577

Epoch: 6| Step: 9
Training loss: 0.5366100072860718
Validation loss: 2.1229445139567056

Epoch: 6| Step: 10
Training loss: 0.3043352961540222
Validation loss: 2.111709713935852

Epoch: 6| Step: 11
Training loss: 0.25530165433883667
Validation loss: 2.079244395097097

Epoch: 6| Step: 12
Training loss: 0.3742283582687378
Validation loss: 2.120017349720001

Epoch: 6| Step: 13
Training loss: 0.6171138286590576
Validation loss: 2.1165160536766052

Epoch: 405| Step: 0
Training loss: 0.26854944229125977
Validation loss: 2.120317975680033

Epoch: 6| Step: 1
Training loss: 0.22542767226696014
Validation loss: 2.0905896425247192

Epoch: 6| Step: 2
Training loss: 0.2726513743400574
Validation loss: 2.117423097292582

Epoch: 6| Step: 3
Training loss: 0.2216840535402298
Validation loss: 2.1284013589223227

Epoch: 6| Step: 4
Training loss: 0.31307750940322876
Validation loss: 2.122075359026591

Epoch: 6| Step: 5
Training loss: 0.18181267380714417
Validation loss: 2.0769490599632263

Epoch: 6| Step: 6
Training loss: 0.7013448476791382
Validation loss: 2.138693849245707

Epoch: 6| Step: 7
Training loss: 0.19746775925159454
Validation loss: 2.1286672552426658

Epoch: 6| Step: 8
Training loss: 0.14423270523548126
Validation loss: 2.0965673128763833

Epoch: 6| Step: 9
Training loss: 0.38830673694610596
Validation loss: 2.173630932966868

Epoch: 6| Step: 10
Training loss: 0.25839871168136597
Validation loss: 2.127577026685079

Epoch: 6| Step: 11
Training loss: 0.30039575695991516
Validation loss: 2.1643213431040444

Epoch: 6| Step: 12
Training loss: 0.27695339918136597
Validation loss: 2.126762568950653

Epoch: 6| Step: 13
Training loss: 0.2910417318344116
Validation loss: 2.170249124368032

Epoch: 406| Step: 0
Training loss: 0.2916284501552582
Validation loss: 2.149261256059011

Epoch: 6| Step: 1
Training loss: 0.25589463114738464
Validation loss: 2.170063058535258

Epoch: 6| Step: 2
Training loss: 0.24503380060195923
Validation loss: 2.143183489640554

Epoch: 6| Step: 3
Training loss: 0.18112912774085999
Validation loss: 2.139162540435791

Epoch: 6| Step: 4
Training loss: 0.21268853545188904
Validation loss: 2.112032969792684

Epoch: 6| Step: 5
Training loss: 0.2531058192253113
Validation loss: 2.102019468943278

Epoch: 6| Step: 6
Training loss: 0.2752113938331604
Validation loss: 2.1054845253626504

Epoch: 6| Step: 7
Training loss: 0.5968936681747437
Validation loss: 2.109845519065857

Epoch: 6| Step: 8
Training loss: 0.31054598093032837
Validation loss: 2.1109072168668113

Epoch: 6| Step: 9
Training loss: 0.6546506881713867
Validation loss: 2.141465882460276

Epoch: 6| Step: 10
Training loss: 0.2556230425834656
Validation loss: 2.123077094554901

Epoch: 6| Step: 11
Training loss: 0.28956955671310425
Validation loss: 2.1119089126586914

Epoch: 6| Step: 12
Training loss: 0.3239848017692566
Validation loss: 2.1220206022262573

Epoch: 6| Step: 13
Training loss: 0.2685808539390564
Validation loss: 2.1265306870142617

Epoch: 407| Step: 0
Training loss: 0.34997838735580444
Validation loss: 2.142956813176473

Epoch: 6| Step: 1
Training loss: 0.2564966380596161
Validation loss: 2.1905418634414673

Epoch: 6| Step: 2
Training loss: 0.4294432997703552
Validation loss: 2.247610171635946

Epoch: 6| Step: 3
Training loss: 0.5174403190612793
Validation loss: 2.246093511581421

Epoch: 6| Step: 4
Training loss: 0.772672712802887
Validation loss: 2.1974393725395203

Epoch: 6| Step: 5
Training loss: 0.3803553581237793
Validation loss: 2.181168496608734

Epoch: 6| Step: 6
Training loss: 0.3118338882923126
Validation loss: 2.1013245979944863

Epoch: 6| Step: 7
Training loss: 0.3439478874206543
Validation loss: 2.1375661889712014

Epoch: 6| Step: 8
Training loss: 0.4991419315338135
Validation loss: 2.1408193707466125

Epoch: 6| Step: 9
Training loss: 0.24095171689987183
Validation loss: 2.1422938108444214

Epoch: 6| Step: 10
Training loss: 0.15454402565956116
Validation loss: 2.1521755854288735

Epoch: 6| Step: 11
Training loss: 0.46890926361083984
Validation loss: 2.178760826587677

Epoch: 6| Step: 12
Training loss: 0.26097291707992554
Validation loss: 2.1562678813934326

Epoch: 6| Step: 13
Training loss: 0.33246105909347534
Validation loss: 2.183421492576599

Epoch: 408| Step: 0
Training loss: 0.4906364977359772
Validation loss: 2.166232943534851

Epoch: 6| Step: 1
Training loss: 0.2722744941711426
Validation loss: 2.176987032095591

Epoch: 6| Step: 2
Training loss: 0.3247110843658447
Validation loss: 2.092646916707357

Epoch: 6| Step: 3
Training loss: 0.1823630928993225
Validation loss: 2.1519359946250916

Epoch: 6| Step: 4
Training loss: 0.2812698781490326
Validation loss: 2.1391676863034568

Epoch: 6| Step: 5
Training loss: 0.3130321204662323
Validation loss: 2.135167956352234

Epoch: 6| Step: 6
Training loss: 0.1868240088224411
Validation loss: 2.120647370815277

Epoch: 6| Step: 7
Training loss: 0.16438454389572144
Validation loss: 2.1718323826789856

Epoch: 6| Step: 8
Training loss: 0.3715783655643463
Validation loss: 2.125433385372162

Epoch: 6| Step: 9
Training loss: 0.7618449926376343
Validation loss: 2.124075770378113

Epoch: 6| Step: 10
Training loss: 0.23399877548217773
Validation loss: 2.1740453243255615

Epoch: 6| Step: 11
Training loss: 0.26727810502052307
Validation loss: 2.092632313569387

Epoch: 6| Step: 12
Training loss: 0.36686766147613525
Validation loss: 2.120742400487264

Epoch: 6| Step: 13
Training loss: 0.16616927087306976
Validation loss: 2.1450698177019754

Epoch: 409| Step: 0
Training loss: 0.1816011518239975
Validation loss: 2.1451072891553244

Epoch: 6| Step: 1
Training loss: 0.24938450753688812
Validation loss: 2.1551367044448853

Epoch: 6| Step: 2
Training loss: 0.3437114953994751
Validation loss: 2.176773170630137

Epoch: 6| Step: 3
Training loss: 0.36991339921951294
Validation loss: 2.1892549196879068

Epoch: 6| Step: 4
Training loss: 0.1934993863105774
Validation loss: 2.1605193614959717

Epoch: 6| Step: 5
Training loss: 0.3423340320587158
Validation loss: 2.1583550373713174

Epoch: 6| Step: 6
Training loss: 0.3264075517654419
Validation loss: 2.106293817361196

Epoch: 6| Step: 7
Training loss: 0.32980936765670776
Validation loss: 2.11508442958196

Epoch: 6| Step: 8
Training loss: 0.19463561475276947
Validation loss: 2.1092615922292075

Epoch: 6| Step: 9
Training loss: 0.3949149549007416
Validation loss: 2.1325200398763022

Epoch: 6| Step: 10
Training loss: 0.4865492284297943
Validation loss: 2.1378546953201294

Epoch: 6| Step: 11
Training loss: 0.5609103441238403
Validation loss: 2.1776603062947593

Epoch: 6| Step: 12
Training loss: 0.4515824317932129
Validation loss: 2.196153163909912

Epoch: 6| Step: 13
Training loss: 0.28189346194267273
Validation loss: 2.152848998705546

Epoch: 410| Step: 0
Training loss: 0.305477499961853
Validation loss: 2.169854005177816

Epoch: 6| Step: 1
Training loss: 0.3836621046066284
Validation loss: 2.0980687737464905

Epoch: 6| Step: 2
Training loss: 0.3034610152244568
Validation loss: 2.0972180366516113

Epoch: 6| Step: 3
Training loss: 0.2985158860683441
Validation loss: 2.087931434313456

Epoch: 6| Step: 4
Training loss: 0.3575708866119385
Validation loss: 2.1376981139183044

Epoch: 6| Step: 5
Training loss: 0.29247942566871643
Validation loss: 2.1104010343551636

Epoch: 6| Step: 6
Training loss: 0.28476765751838684
Validation loss: 2.1439768075942993

Epoch: 6| Step: 7
Training loss: 0.20258024334907532
Validation loss: 2.137960056463877

Epoch: 6| Step: 8
Training loss: 0.23749105632305145
Validation loss: 2.154473841190338

Epoch: 6| Step: 9
Training loss: 0.2183469980955124
Validation loss: 2.185145060221354

Epoch: 6| Step: 10
Training loss: 0.18628425896167755
Validation loss: 2.146144986152649

Epoch: 6| Step: 11
Training loss: 0.7971349358558655
Validation loss: 2.099008023738861

Epoch: 6| Step: 12
Training loss: 0.38051456212997437
Validation loss: 2.109694222609202

Epoch: 6| Step: 13
Training loss: 0.2439354956150055
Validation loss: 2.1301128466924033

Epoch: 411| Step: 0
Training loss: 0.22664889693260193
Validation loss: 2.1623670061429343

Epoch: 6| Step: 1
Training loss: 0.8363861441612244
Validation loss: 2.2213254968325296

Epoch: 6| Step: 2
Training loss: 0.5218856930732727
Validation loss: 2.1978850960731506

Epoch: 6| Step: 3
Training loss: 0.45217257738113403
Validation loss: 2.1801766753196716

Epoch: 6| Step: 4
Training loss: 0.28651514649391174
Validation loss: 2.134689231713613

Epoch: 6| Step: 5
Training loss: 0.30234020948410034
Validation loss: 2.1513469219207764

Epoch: 6| Step: 6
Training loss: 0.19293607771396637
Validation loss: 2.096371293067932

Epoch: 6| Step: 7
Training loss: 0.3504689931869507
Validation loss: 2.113860845565796

Epoch: 6| Step: 8
Training loss: 0.29350531101226807
Validation loss: 2.1196579337120056

Epoch: 6| Step: 9
Training loss: 0.23873190581798553
Validation loss: 2.1081430912017822

Epoch: 6| Step: 10
Training loss: 0.3670426607131958
Validation loss: 2.1248562335968018

Epoch: 6| Step: 11
Training loss: 0.4988497495651245
Validation loss: 2.1665895183881125

Epoch: 6| Step: 12
Training loss: 0.26513805985450745
Validation loss: 2.1350443363189697

Epoch: 6| Step: 13
Training loss: 0.3000335693359375
Validation loss: 2.1069490909576416

Epoch: 412| Step: 0
Training loss: 0.3358014225959778
Validation loss: 2.1016185879707336

Epoch: 6| Step: 1
Training loss: 0.27800875902175903
Validation loss: 2.1229011615117392

Epoch: 6| Step: 2
Training loss: 0.23062339425086975
Validation loss: 2.102381388346354

Epoch: 6| Step: 3
Training loss: 0.46971261501312256
Validation loss: 2.0961231191953025

Epoch: 6| Step: 4
Training loss: 0.35094764828681946
Validation loss: 2.1383948723475137

Epoch: 6| Step: 5
Training loss: 0.7371599078178406
Validation loss: 2.1568962732950845

Epoch: 6| Step: 6
Training loss: 0.19070854783058167
Validation loss: 2.1422749757766724

Epoch: 6| Step: 7
Training loss: 0.285247266292572
Validation loss: 2.181944171587626

Epoch: 6| Step: 8
Training loss: 0.365872323513031
Validation loss: 2.1215866804122925

Epoch: 6| Step: 9
Training loss: 0.22006094455718994
Validation loss: 2.1584813594818115

Epoch: 6| Step: 10
Training loss: 0.1695450246334076
Validation loss: 2.1561095317204795

Epoch: 6| Step: 11
Training loss: 0.3500739336013794
Validation loss: 2.100465734799703

Epoch: 6| Step: 12
Training loss: 0.23019763827323914
Validation loss: 2.0900136828422546

Epoch: 6| Step: 13
Training loss: 0.23506300151348114
Validation loss: 2.144566535949707

Epoch: 413| Step: 0
Training loss: 0.7259042263031006
Validation loss: 2.1612310210863748

Epoch: 6| Step: 1
Training loss: 0.2753354012966156
Validation loss: 2.1926564971605935

Epoch: 6| Step: 2
Training loss: 0.34295082092285156
Validation loss: 2.202316184838613

Epoch: 6| Step: 3
Training loss: 0.28230464458465576
Validation loss: 2.1468425393104553

Epoch: 6| Step: 4
Training loss: 0.3383994698524475
Validation loss: 2.1420030991236367

Epoch: 6| Step: 5
Training loss: 0.26008927822113037
Validation loss: 2.1393632292747498

Epoch: 6| Step: 6
Training loss: 0.20327675342559814
Validation loss: 2.1280102729797363

Epoch: 6| Step: 7
Training loss: 0.31121861934661865
Validation loss: 2.1134899059931436

Epoch: 6| Step: 8
Training loss: 0.35572361946105957
Validation loss: 2.1329975724220276

Epoch: 6| Step: 9
Training loss: 0.3792271018028259
Validation loss: 2.147221247355143

Epoch: 6| Step: 10
Training loss: 0.23743760585784912
Validation loss: 2.1786417762438455

Epoch: 6| Step: 11
Training loss: 0.3760443329811096
Validation loss: 2.1532760858535767

Epoch: 6| Step: 12
Training loss: 0.2098933756351471
Validation loss: 2.2147541443506875

Epoch: 6| Step: 13
Training loss: 0.3508942127227783
Validation loss: 2.212917447090149

Epoch: 414| Step: 0
Training loss: 0.1949903666973114
Validation loss: 2.1391431291898093

Epoch: 6| Step: 1
Training loss: 0.16904698312282562
Validation loss: 2.152208924293518

Epoch: 6| Step: 2
Training loss: 0.3890458345413208
Validation loss: 2.1236406366030374

Epoch: 6| Step: 3
Training loss: 0.3909425437450409
Validation loss: 2.111043612162272

Epoch: 6| Step: 4
Training loss: 0.2591463625431061
Validation loss: 2.1452398697535195

Epoch: 6| Step: 5
Training loss: 0.23425979912281036
Validation loss: 2.1364536682764688

Epoch: 6| Step: 6
Training loss: 0.33751773834228516
Validation loss: 2.149269779523214

Epoch: 6| Step: 7
Training loss: 0.327433705329895
Validation loss: 2.157536804676056

Epoch: 6| Step: 8
Training loss: 0.2533015012741089
Validation loss: 2.1603017250696817

Epoch: 6| Step: 9
Training loss: 0.23374566435813904
Validation loss: 2.178961714108785

Epoch: 6| Step: 10
Training loss: 0.39757299423217773
Validation loss: 2.114579717318217

Epoch: 6| Step: 11
Training loss: 0.2438291609287262
Validation loss: 2.1208815972010293

Epoch: 6| Step: 12
Training loss: 0.4556860327720642
Validation loss: 2.0851749976476035

Epoch: 6| Step: 13
Training loss: 0.5994220972061157
Validation loss: 2.1052972873051963

Epoch: 415| Step: 0
Training loss: 0.4689486026763916
Validation loss: 2.1282814542452493

Epoch: 6| Step: 1
Training loss: 0.17808794975280762
Validation loss: 2.15561709801356

Epoch: 6| Step: 2
Training loss: 0.8456811904907227
Validation loss: 2.120027701059977

Epoch: 6| Step: 3
Training loss: 0.2866343855857849
Validation loss: 2.124031921227773

Epoch: 6| Step: 4
Training loss: 0.27908915281295776
Validation loss: 2.135380824406942

Epoch: 6| Step: 5
Training loss: 0.22633257508277893
Validation loss: 2.138025403022766

Epoch: 6| Step: 6
Training loss: 0.1987399011850357
Validation loss: 2.1085934042930603

Epoch: 6| Step: 7
Training loss: 0.34619036316871643
Validation loss: 2.0674795905749

Epoch: 6| Step: 8
Training loss: 0.4821877181529999
Validation loss: 2.1032638549804688

Epoch: 6| Step: 9
Training loss: 0.22675350308418274
Validation loss: 2.0699754556020102

Epoch: 6| Step: 10
Training loss: 0.20191322267055511
Validation loss: 2.1064101656277976

Epoch: 6| Step: 11
Training loss: 0.20372305810451508
Validation loss: 2.1057013471921286

Epoch: 6| Step: 12
Training loss: 0.496920108795166
Validation loss: 2.0786129236221313

Epoch: 6| Step: 13
Training loss: 0.37288549542427063
Validation loss: 2.1151585976282754

Epoch: 416| Step: 0
Training loss: 0.19562198221683502
Validation loss: 2.106272280216217

Epoch: 6| Step: 1
Training loss: 0.7818101644515991
Validation loss: 2.08343505859375

Epoch: 6| Step: 2
Training loss: 0.34163105487823486
Validation loss: 2.15190456310908

Epoch: 6| Step: 3
Training loss: 0.22700026631355286
Validation loss: 2.184698243935903

Epoch: 6| Step: 4
Training loss: 0.38654547929763794
Validation loss: 2.166679640611013

Epoch: 6| Step: 5
Training loss: 0.2639535665512085
Validation loss: 2.1557888785998025

Epoch: 6| Step: 6
Training loss: 0.2366844117641449
Validation loss: 2.136835515499115

Epoch: 6| Step: 7
Training loss: 0.230880469083786
Validation loss: 2.0991306702295938

Epoch: 6| Step: 8
Training loss: 0.28098154067993164
Validation loss: 2.1209134658177695

Epoch: 6| Step: 9
Training loss: 0.3289549648761749
Validation loss: 2.108709235986074

Epoch: 6| Step: 10
Training loss: 0.3661545515060425
Validation loss: 2.146538237730662

Epoch: 6| Step: 11
Training loss: 0.2985064387321472
Validation loss: 2.122176925341288

Epoch: 6| Step: 12
Training loss: 0.24497973918914795
Validation loss: 2.157641271750132

Epoch: 6| Step: 13
Training loss: 0.25629639625549316
Validation loss: 2.1356194814046225

Epoch: 417| Step: 0
Training loss: 0.20436778664588928
Validation loss: 2.146733601888021

Epoch: 6| Step: 1
Training loss: 0.278955340385437
Validation loss: 2.1506393551826477

Epoch: 6| Step: 2
Training loss: 0.19224143028259277
Validation loss: 2.174350698788961

Epoch: 6| Step: 3
Training loss: 0.22913920879364014
Validation loss: 2.160757760206858

Epoch: 6| Step: 4
Training loss: 0.22508001327514648
Validation loss: 2.1259090900421143

Epoch: 6| Step: 5
Training loss: 0.8105271458625793
Validation loss: 2.124023119608561

Epoch: 6| Step: 6
Training loss: 0.26051414012908936
Validation loss: 2.137991507848104

Epoch: 6| Step: 7
Training loss: 0.3786607086658478
Validation loss: 2.1006521582603455

Epoch: 6| Step: 8
Training loss: 0.3663107752799988
Validation loss: 2.0996782382329306

Epoch: 6| Step: 9
Training loss: 0.15056830644607544
Validation loss: 2.0964913765589395

Epoch: 6| Step: 10
Training loss: 0.31852003931999207
Validation loss: 2.17041422923406

Epoch: 6| Step: 11
Training loss: 0.20488551259040833
Validation loss: 2.1544795632362366

Epoch: 6| Step: 12
Training loss: 0.40217214822769165
Validation loss: 2.164922853310903

Epoch: 6| Step: 13
Training loss: 0.38936543464660645
Validation loss: 2.176350235939026

Epoch: 418| Step: 0
Training loss: 0.47442537546157837
Validation loss: 2.1088713804880777

Epoch: 6| Step: 1
Training loss: 0.18245132267475128
Validation loss: 2.135915676752726

Epoch: 6| Step: 2
Training loss: 0.39957094192504883
Validation loss: 2.094829042752584

Epoch: 6| Step: 3
Training loss: 0.2737331688404083
Validation loss: 2.106685678164164

Epoch: 6| Step: 4
Training loss: 0.4023890495300293
Validation loss: 2.1130399306615195

Epoch: 6| Step: 5
Training loss: 0.2547076940536499
Validation loss: 2.0903148452440896

Epoch: 6| Step: 6
Training loss: 0.2046585977077484
Validation loss: 2.1256994803746543

Epoch: 6| Step: 7
Training loss: 0.2852884829044342
Validation loss: 2.1275567015012107

Epoch: 6| Step: 8
Training loss: 0.27287960052490234
Validation loss: 2.100821634133657

Epoch: 6| Step: 9
Training loss: 0.18067297339439392
Validation loss: 2.1177817781766257

Epoch: 6| Step: 10
Training loss: 0.22569720447063446
Validation loss: 2.1383291681607566

Epoch: 6| Step: 11
Training loss: 0.19734738767147064
Validation loss: 2.111949861049652

Epoch: 6| Step: 12
Training loss: 0.18054735660552979
Validation loss: 2.088888247807821

Epoch: 6| Step: 13
Training loss: 0.7236629724502563
Validation loss: 2.1149232586224875

Epoch: 419| Step: 0
Training loss: 0.3058423101902008
Validation loss: 2.087627867857615

Epoch: 6| Step: 1
Training loss: 0.20451295375823975
Validation loss: 2.0702788631121316

Epoch: 6| Step: 2
Training loss: 0.37286460399627686
Validation loss: 2.0693316062291465

Epoch: 6| Step: 3
Training loss: 0.25861793756484985
Validation loss: 2.112626314163208

Epoch: 6| Step: 4
Training loss: 0.20977690815925598
Validation loss: 2.118865152200063

Epoch: 6| Step: 5
Training loss: 0.8463777899742126
Validation loss: 2.074653764565786

Epoch: 6| Step: 6
Training loss: 0.3516918122768402
Validation loss: 2.103574355443319

Epoch: 6| Step: 7
Training loss: 0.2000228315591812
Validation loss: 2.126858393351237

Epoch: 6| Step: 8
Training loss: 0.2870716452598572
Validation loss: 2.11944043636322

Epoch: 6| Step: 9
Training loss: 0.2537256181240082
Validation loss: 2.133174240589142

Epoch: 6| Step: 10
Training loss: 0.27398961782455444
Validation loss: 2.1734105745951333

Epoch: 6| Step: 11
Training loss: 0.3073270916938782
Validation loss: 2.1116848587989807

Epoch: 6| Step: 12
Training loss: 0.22750596702098846
Validation loss: 2.157714287439982

Epoch: 6| Step: 13
Training loss: 0.3375711441040039
Validation loss: 2.1464970906575522

Epoch: 420| Step: 0
Training loss: 0.34220588207244873
Validation loss: 2.1089308857917786

Epoch: 6| Step: 1
Training loss: 0.26544860005378723
Validation loss: 2.0345731576283774

Epoch: 6| Step: 2
Training loss: 0.28953462839126587
Validation loss: 2.136488199234009

Epoch: 6| Step: 3
Training loss: 0.27510398626327515
Validation loss: 2.131912668546041

Epoch: 6| Step: 4
Training loss: 0.1580277681350708
Validation loss: 2.147715926170349

Epoch: 6| Step: 5
Training loss: 0.32514452934265137
Validation loss: 2.1616661747296653

Epoch: 6| Step: 6
Training loss: 0.1932060420513153
Validation loss: 2.1775507728258767

Epoch: 6| Step: 7
Training loss: 0.6601232290267944
Validation loss: 2.1131338477134705

Epoch: 6| Step: 8
Training loss: 0.2929370105266571
Validation loss: 2.1437012354532876

Epoch: 6| Step: 9
Training loss: 0.3070937991142273
Validation loss: 2.1167165835698447

Epoch: 6| Step: 10
Training loss: 0.4713285267353058
Validation loss: 2.115074952443441

Epoch: 6| Step: 11
Training loss: 0.508392870426178
Validation loss: 2.1027353604634604

Epoch: 6| Step: 12
Training loss: 0.3192024528980255
Validation loss: 2.1144617398579917

Epoch: 6| Step: 13
Training loss: 0.3622872829437256
Validation loss: 2.1337047815322876

Epoch: 421| Step: 0
Training loss: 0.22247959673404694
Validation loss: 2.09895259141922

Epoch: 6| Step: 1
Training loss: 0.25937098264694214
Validation loss: 2.1423556407292685

Epoch: 6| Step: 2
Training loss: 0.39679455757141113
Validation loss: 2.1818940242131553

Epoch: 6| Step: 3
Training loss: 0.4301741123199463
Validation loss: 2.2167309125264487

Epoch: 6| Step: 4
Training loss: 0.25814637541770935
Validation loss: 2.174736440181732

Epoch: 6| Step: 5
Training loss: 0.332352876663208
Validation loss: 2.0754247307777405

Epoch: 6| Step: 6
Training loss: 0.7010210156440735
Validation loss: 2.0941495498021445

Epoch: 6| Step: 7
Training loss: 0.23052376508712769
Validation loss: 2.0854854583740234

Epoch: 6| Step: 8
Training loss: 0.28199368715286255
Validation loss: 2.111535827318827

Epoch: 6| Step: 9
Training loss: 0.20474688708782196
Validation loss: 2.140163779258728

Epoch: 6| Step: 10
Training loss: 0.3567146360874176
Validation loss: 2.113966166973114

Epoch: 6| Step: 11
Training loss: 0.3842431604862213
Validation loss: 2.12665589650472

Epoch: 6| Step: 12
Training loss: 0.31214457750320435
Validation loss: 2.189806322256724

Epoch: 6| Step: 13
Training loss: 0.2850058376789093
Validation loss: 2.1897082130114236

Epoch: 422| Step: 0
Training loss: 0.23434637486934662
Validation loss: 2.1693193713823953

Epoch: 6| Step: 1
Training loss: 0.36238086223602295
Validation loss: 2.117813448111216

Epoch: 6| Step: 2
Training loss: 0.18607263267040253
Validation loss: 2.1384552319844565

Epoch: 6| Step: 3
Training loss: 0.2711445093154907
Validation loss: 2.139529267946879

Epoch: 6| Step: 4
Training loss: 0.3107145130634308
Validation loss: 2.1817996899286904

Epoch: 6| Step: 5
Training loss: 0.22562743723392487
Validation loss: 2.1221901774406433

Epoch: 6| Step: 6
Training loss: 0.6527926921844482
Validation loss: 2.1812246243158975

Epoch: 6| Step: 7
Training loss: 0.3491774797439575
Validation loss: 2.128010014692942

Epoch: 6| Step: 8
Training loss: 0.22209909558296204
Validation loss: 2.139937162399292

Epoch: 6| Step: 9
Training loss: 0.31143200397491455
Validation loss: 2.0930282274881997

Epoch: 6| Step: 10
Training loss: 0.6337975263595581
Validation loss: 2.0947447617848716

Epoch: 6| Step: 11
Training loss: 0.17616645991802216
Validation loss: 2.113038102785746

Epoch: 6| Step: 12
Training loss: 0.22069519758224487
Validation loss: 2.122557441393534

Epoch: 6| Step: 13
Training loss: 0.2845132052898407
Validation loss: 2.177600105603536

Epoch: 423| Step: 0
Training loss: 0.26791197061538696
Validation loss: 2.1745192805926004

Epoch: 6| Step: 1
Training loss: 0.20438645780086517
Validation loss: 2.1530852715174356

Epoch: 6| Step: 2
Training loss: 0.18053433299064636
Validation loss: 2.229377110799154

Epoch: 6| Step: 3
Training loss: 0.23986637592315674
Validation loss: 2.1346920132637024

Epoch: 6| Step: 4
Training loss: 0.7235174775123596
Validation loss: 2.1173075238863626

Epoch: 6| Step: 5
Training loss: 0.3051100969314575
Validation loss: 2.0990620652834573

Epoch: 6| Step: 6
Training loss: 0.37055766582489014
Validation loss: 2.152766843636831

Epoch: 6| Step: 7
Training loss: 0.20895916223526
Validation loss: 2.106476147969564

Epoch: 6| Step: 8
Training loss: 0.4036480784416199
Validation loss: 2.1764893730481467

Epoch: 6| Step: 9
Training loss: 0.23370830714702606
Validation loss: 2.11849308013916

Epoch: 6| Step: 10
Training loss: 0.4830063581466675
Validation loss: 2.153526326020559

Epoch: 6| Step: 11
Training loss: 0.20044219493865967
Validation loss: 2.1374327540397644

Epoch: 6| Step: 12
Training loss: 0.23166228830814362
Validation loss: 2.112220545609792

Epoch: 6| Step: 13
Training loss: 0.2890799641609192
Validation loss: 2.0970021883646646

Epoch: 424| Step: 0
Training loss: 0.24401769042015076
Validation loss: 2.138365685939789

Epoch: 6| Step: 1
Training loss: 0.18559640645980835
Validation loss: 2.109965145587921

Epoch: 6| Step: 2
Training loss: 0.2823413610458374
Validation loss: 2.1362894773483276

Epoch: 6| Step: 3
Training loss: 0.2648005485534668
Validation loss: 2.177393853664398

Epoch: 6| Step: 4
Training loss: 0.7089524269104004
Validation loss: 2.174291253089905

Epoch: 6| Step: 5
Training loss: 0.23208017647266388
Validation loss: 2.0904409885406494

Epoch: 6| Step: 6
Training loss: 0.4275607168674469
Validation loss: 2.1157131791114807

Epoch: 6| Step: 7
Training loss: 0.2523716688156128
Validation loss: 2.0969624121983848

Epoch: 6| Step: 8
Training loss: 0.28647586703300476
Validation loss: 2.109971344470978

Epoch: 6| Step: 9
Training loss: 0.21665000915527344
Validation loss: 2.140708645184835

Epoch: 6| Step: 10
Training loss: 0.22008614242076874
Validation loss: 2.1283857027689614

Epoch: 6| Step: 11
Training loss: 0.3996887803077698
Validation loss: 2.0931469599405923

Epoch: 6| Step: 12
Training loss: 0.2879757881164551
Validation loss: 2.155393958091736

Epoch: 6| Step: 13
Training loss: 0.3851499855518341
Validation loss: 2.1192166407903037

Epoch: 425| Step: 0
Training loss: 0.28410863876342773
Validation loss: 2.121544142564138

Epoch: 6| Step: 1
Training loss: 0.21011164784431458
Validation loss: 2.145830233891805

Epoch: 6| Step: 2
Training loss: 0.3737998604774475
Validation loss: 2.2099486589431763

Epoch: 6| Step: 3
Training loss: 0.31034696102142334
Validation loss: 2.1833040912946067

Epoch: 6| Step: 4
Training loss: 0.2636704444885254
Validation loss: 2.1709279219309487

Epoch: 6| Step: 5
Training loss: 0.23947519063949585
Validation loss: 2.1186704635620117

Epoch: 6| Step: 6
Training loss: 0.43508484959602356
Validation loss: 2.0821643670399985

Epoch: 6| Step: 7
Training loss: 0.30746081471443176
Validation loss: 2.1434587836265564

Epoch: 6| Step: 8
Training loss: 0.4027198553085327
Validation loss: 2.13688325881958

Epoch: 6| Step: 9
Training loss: 0.43226706981658936
Validation loss: 2.133312145868937

Epoch: 6| Step: 10
Training loss: 0.6000019907951355
Validation loss: 2.146707753340403

Epoch: 6| Step: 11
Training loss: 0.3864498436450958
Validation loss: 2.2030674616495767

Epoch: 6| Step: 12
Training loss: 0.5424926280975342
Validation loss: 2.204816540082296

Epoch: 6| Step: 13
Training loss: 0.33000463247299194
Validation loss: 2.167138417561849

Epoch: 426| Step: 0
Training loss: 0.37549906969070435
Validation loss: 2.212501287460327

Epoch: 6| Step: 1
Training loss: 0.26703736186027527
Validation loss: 2.1426319678624473

Epoch: 6| Step: 2
Training loss: 0.3375946283340454
Validation loss: 2.1303131381670632

Epoch: 6| Step: 3
Training loss: 0.2834681570529938
Validation loss: 2.1548593242963157

Epoch: 6| Step: 4
Training loss: 0.325566828250885
Validation loss: 2.15385635693868

Epoch: 6| Step: 5
Training loss: 0.3013399541378021
Validation loss: 2.173374275366465

Epoch: 6| Step: 6
Training loss: 0.613740861415863
Validation loss: 2.1718636949857077

Epoch: 6| Step: 7
Training loss: 0.35762086510658264
Validation loss: 2.188990910847982

Epoch: 6| Step: 8
Training loss: 0.5064764022827148
Validation loss: 2.1963412960370383

Epoch: 6| Step: 9
Training loss: 0.22971659898757935
Validation loss: 2.143612523873647

Epoch: 6| Step: 10
Training loss: 0.21570001542568207
Validation loss: 2.1380196809768677

Epoch: 6| Step: 11
Training loss: 0.2892865538597107
Validation loss: 2.109107732772827

Epoch: 6| Step: 12
Training loss: 0.4248056709766388
Validation loss: 2.140779356161753

Epoch: 6| Step: 13
Training loss: 0.13774247467517853
Validation loss: 2.1134020686149597

Epoch: 427| Step: 0
Training loss: 0.19946067035198212
Validation loss: 2.117752214272817

Epoch: 6| Step: 1
Training loss: 0.26579248905181885
Validation loss: 2.1430737574895224

Epoch: 6| Step: 2
Training loss: 0.3174397051334381
Validation loss: 2.1174461046854653

Epoch: 6| Step: 3
Training loss: 0.1833745837211609
Validation loss: 2.1563228766123452

Epoch: 6| Step: 4
Training loss: 0.4028470516204834
Validation loss: 2.167242725690206

Epoch: 6| Step: 5
Training loss: 0.33279383182525635
Validation loss: 2.143470029036204

Epoch: 6| Step: 6
Training loss: 0.2560156583786011
Validation loss: 2.13094562292099

Epoch: 6| Step: 7
Training loss: 0.15992870926856995
Validation loss: 2.0984402894973755

Epoch: 6| Step: 8
Training loss: 0.3687136471271515
Validation loss: 2.1452248295148215

Epoch: 6| Step: 9
Training loss: 0.24081280827522278
Validation loss: 2.1204134623209634

Epoch: 6| Step: 10
Training loss: 0.18697792291641235
Validation loss: 2.148852825164795

Epoch: 6| Step: 11
Training loss: 0.2603740096092224
Validation loss: 2.1104194124539695

Epoch: 6| Step: 12
Training loss: 0.6324580907821655
Validation loss: 2.095296541849772

Epoch: 6| Step: 13
Training loss: 0.3926474452018738
Validation loss: 2.0870362520217896

Epoch: 428| Step: 0
Training loss: 0.26264968514442444
Validation loss: 2.0795511404673257

Epoch: 6| Step: 1
Training loss: 0.24667172133922577
Validation loss: 2.157685935497284

Epoch: 6| Step: 2
Training loss: 0.24831457436084747
Validation loss: 2.073066473007202

Epoch: 6| Step: 3
Training loss: 0.34610462188720703
Validation loss: 2.1136343081792197

Epoch: 6| Step: 4
Training loss: 0.21380656957626343
Validation loss: 2.135688145955404

Epoch: 6| Step: 5
Training loss: 0.6912806034088135
Validation loss: 2.110461493333181

Epoch: 6| Step: 6
Training loss: 0.24173495173454285
Validation loss: 2.153481423854828

Epoch: 6| Step: 7
Training loss: 0.2398642599582672
Validation loss: 2.103785832722982

Epoch: 6| Step: 8
Training loss: 0.18496575951576233
Validation loss: 2.16259096066157

Epoch: 6| Step: 9
Training loss: 0.24645297229290009
Validation loss: 2.1483329931894937

Epoch: 6| Step: 10
Training loss: 0.1644091010093689
Validation loss: 2.100022315979004

Epoch: 6| Step: 11
Training loss: 0.3424261808395386
Validation loss: 2.16908589998881

Epoch: 6| Step: 12
Training loss: 0.2552798390388489
Validation loss: 2.1297779281934104

Epoch: 6| Step: 13
Training loss: 0.2958085536956787
Validation loss: 2.110101262728373

Epoch: 429| Step: 0
Training loss: 0.11908157169818878
Validation loss: 2.0888450344403586

Epoch: 6| Step: 1
Training loss: 0.2744395136833191
Validation loss: 2.116012374560038

Epoch: 6| Step: 2
Training loss: 0.35226452350616455
Validation loss: 2.1442745129267373

Epoch: 6| Step: 3
Training loss: 0.2571614980697632
Validation loss: 2.1246755719184875

Epoch: 6| Step: 4
Training loss: 0.22139304876327515
Validation loss: 2.1277007261912027

Epoch: 6| Step: 5
Training loss: 0.18531355261802673
Validation loss: 2.1286601026852927

Epoch: 6| Step: 6
Training loss: 0.17915597558021545
Validation loss: 2.127715984980265

Epoch: 6| Step: 7
Training loss: 0.9264715909957886
Validation loss: 2.1282172997792563

Epoch: 6| Step: 8
Training loss: 0.28737911581993103
Validation loss: 2.141732076803843

Epoch: 6| Step: 9
Training loss: 0.41607052087783813
Validation loss: 2.085813800493876

Epoch: 6| Step: 10
Training loss: 0.30910173058509827
Validation loss: 2.1092812021573386

Epoch: 6| Step: 11
Training loss: 0.13561135530471802
Validation loss: 2.088529904683431

Epoch: 6| Step: 12
Training loss: 0.37729373574256897
Validation loss: 2.118738035360972

Epoch: 6| Step: 13
Training loss: 0.26548629999160767
Validation loss: 2.137006402015686

Epoch: 430| Step: 0
Training loss: 0.22392500936985016
Validation loss: 2.180258254210154

Epoch: 6| Step: 1
Training loss: 0.15905019640922546
Validation loss: 2.1466272672017417

Epoch: 6| Step: 2
Training loss: 0.19802337884902954
Validation loss: 2.101421356201172

Epoch: 6| Step: 3
Training loss: 0.2342313826084137
Validation loss: 2.073199232419332

Epoch: 6| Step: 4
Training loss: 0.21224775910377502
Validation loss: 2.084651013215383

Epoch: 6| Step: 5
Training loss: 0.3377451002597809
Validation loss: 2.1034909884134927

Epoch: 6| Step: 6
Training loss: 0.4379282593727112
Validation loss: 2.148786703745524

Epoch: 6| Step: 7
Training loss: 0.7967846393585205
Validation loss: 2.0568010012308755

Epoch: 6| Step: 8
Training loss: 0.233542338013649
Validation loss: 2.0841601490974426

Epoch: 6| Step: 9
Training loss: 0.2930317521095276
Validation loss: 2.0905463695526123

Epoch: 6| Step: 10
Training loss: 0.1863403618335724
Validation loss: 2.0958992640177407

Epoch: 6| Step: 11
Training loss: 0.21026676893234253
Validation loss: 2.123680373032888

Epoch: 6| Step: 12
Training loss: 0.25514715909957886
Validation loss: 2.110856910546621

Epoch: 6| Step: 13
Training loss: 0.29723790287971497
Validation loss: 2.1027138034502664

Epoch: 431| Step: 0
Training loss: 0.16003403067588806
Validation loss: 2.1091925700505576

Epoch: 6| Step: 1
Training loss: 0.3068593740463257
Validation loss: 2.089804689089457

Epoch: 6| Step: 2
Training loss: 0.5243651270866394
Validation loss: 2.1130216916402182

Epoch: 6| Step: 3
Training loss: 0.552012026309967
Validation loss: 2.1254851818084717

Epoch: 6| Step: 4
Training loss: 0.27360233664512634
Validation loss: 2.136088271935781

Epoch: 6| Step: 5
Training loss: 0.23898185789585114
Validation loss: 2.116966704527537

Epoch: 6| Step: 6
Training loss: 0.2683994770050049
Validation loss: 2.118712623914083

Epoch: 6| Step: 7
Training loss: 0.2558218240737915
Validation loss: 2.1318980852762857

Epoch: 6| Step: 8
Training loss: 0.24844300746917725
Validation loss: 2.1236703991889954

Epoch: 6| Step: 9
Training loss: 0.2588501572608948
Validation loss: 2.101905862490336

Epoch: 6| Step: 10
Training loss: 0.42510518431663513
Validation loss: 2.073758145173391

Epoch: 6| Step: 11
Training loss: 0.411199688911438
Validation loss: 2.1321630477905273

Epoch: 6| Step: 12
Training loss: 0.46556636691093445
Validation loss: 2.1270155111948648

Epoch: 6| Step: 13
Training loss: 0.19900067150592804
Validation loss: 2.1463141441345215

Epoch: 432| Step: 0
Training loss: 0.22630193829536438
Validation loss: 2.10541033744812

Epoch: 6| Step: 1
Training loss: 0.4929252862930298
Validation loss: 2.1039479772249856

Epoch: 6| Step: 2
Training loss: 0.7710636854171753
Validation loss: 2.0377622842788696

Epoch: 6| Step: 3
Training loss: 0.2883166968822479
Validation loss: 2.0871662497520447

Epoch: 6| Step: 4
Training loss: 0.2983663082122803
Validation loss: 2.0692965388298035

Epoch: 6| Step: 5
Training loss: 0.19787195324897766
Validation loss: 2.120145340760549

Epoch: 6| Step: 6
Training loss: 0.28008580207824707
Validation loss: 2.1161245703697205

Epoch: 6| Step: 7
Training loss: 0.22144874930381775
Validation loss: 2.1435998678207397

Epoch: 6| Step: 8
Training loss: 0.4880962371826172
Validation loss: 2.1726816495259604

Epoch: 6| Step: 9
Training loss: 0.38073158264160156
Validation loss: 2.189244111378988

Epoch: 6| Step: 10
Training loss: 0.24254322052001953
Validation loss: 2.0987270871798196

Epoch: 6| Step: 11
Training loss: 0.1297217160463333
Validation loss: 2.103348513444265

Epoch: 6| Step: 12
Training loss: 0.252691388130188
Validation loss: 2.0734859903653464

Epoch: 6| Step: 13
Training loss: 0.39710789918899536
Validation loss: 2.0643279949824014

Epoch: 433| Step: 0
Training loss: 0.3546184301376343
Validation loss: 2.0999451875686646

Epoch: 6| Step: 1
Training loss: 0.26874101161956787
Validation loss: 2.1452438632647195

Epoch: 6| Step: 2
Training loss: 0.3052178621292114
Validation loss: 2.1473307609558105

Epoch: 6| Step: 3
Training loss: 0.4789172112941742
Validation loss: 2.185626268386841

Epoch: 6| Step: 4
Training loss: 0.4500495195388794
Validation loss: 2.196759025255839

Epoch: 6| Step: 5
Training loss: 0.24475309252738953
Validation loss: 2.160106639067332

Epoch: 6| Step: 6
Training loss: 0.27726906538009644
Validation loss: 2.1150437196095786

Epoch: 6| Step: 7
Training loss: 0.30729737877845764
Validation loss: 2.0901984572410583

Epoch: 6| Step: 8
Training loss: 0.2531489431858063
Validation loss: 2.130757510662079

Epoch: 6| Step: 9
Training loss: 0.8062829971313477
Validation loss: 2.0432965755462646

Epoch: 6| Step: 10
Training loss: 0.2701118588447571
Validation loss: 2.0659167965253196

Epoch: 6| Step: 11
Training loss: 0.3003121018409729
Validation loss: 2.077445129553477

Epoch: 6| Step: 12
Training loss: 0.42119258642196655
Validation loss: 2.1390068332354226

Epoch: 6| Step: 13
Training loss: 0.4362741708755493
Validation loss: 2.129745821158091

Epoch: 434| Step: 0
Training loss: 0.3489522933959961
Validation loss: 2.15621280670166

Epoch: 6| Step: 1
Training loss: 0.45889946818351746
Validation loss: 2.132281184196472

Epoch: 6| Step: 2
Training loss: 0.2305399775505066
Validation loss: 2.0897375543912253

Epoch: 6| Step: 3
Training loss: 0.317218542098999
Validation loss: 2.0801003177960715

Epoch: 6| Step: 4
Training loss: 0.289222776889801
Validation loss: 2.090295990308126

Epoch: 6| Step: 5
Training loss: 0.4652717113494873
Validation loss: 2.074562191963196

Epoch: 6| Step: 6
Training loss: 0.4154021441936493
Validation loss: 2.121073603630066

Epoch: 6| Step: 7
Training loss: 0.2546532154083252
Validation loss: 2.0905898610750833

Epoch: 6| Step: 8
Training loss: 0.15478581190109253
Validation loss: 2.1481205224990845

Epoch: 6| Step: 9
Training loss: 0.2893267571926117
Validation loss: 2.1566396355628967

Epoch: 6| Step: 10
Training loss: 0.8218981623649597
Validation loss: 2.1300170024236045

Epoch: 6| Step: 11
Training loss: 0.24926304817199707
Validation loss: 2.0942075649897256

Epoch: 6| Step: 12
Training loss: 0.23534832894802094
Validation loss: 2.0993347565333047

Epoch: 6| Step: 13
Training loss: 0.24225467443466187
Validation loss: 2.110084295272827

Epoch: 435| Step: 0
Training loss: 0.4173527657985687
Validation loss: 2.0999614000320435

Epoch: 6| Step: 1
Training loss: 0.2330843210220337
Validation loss: 2.087790310382843

Epoch: 6| Step: 2
Training loss: 0.27860885858535767
Validation loss: 2.1080183585484824

Epoch: 6| Step: 3
Training loss: 0.28773993253707886
Validation loss: 2.0933414300282798

Epoch: 6| Step: 4
Training loss: 0.3377358913421631
Validation loss: 2.122519850730896

Epoch: 6| Step: 5
Training loss: 0.2898654341697693
Validation loss: 2.16359273592631

Epoch: 6| Step: 6
Training loss: 0.7843197584152222
Validation loss: 2.177321513493856

Epoch: 6| Step: 7
Training loss: 0.5479691028594971
Validation loss: 2.1915778120358786

Epoch: 6| Step: 8
Training loss: 0.28842127323150635
Validation loss: 2.161391278107961

Epoch: 6| Step: 9
Training loss: 0.44542479515075684
Validation loss: 2.1484747529029846

Epoch: 6| Step: 10
Training loss: 0.22124701738357544
Validation loss: 2.131358802318573

Epoch: 6| Step: 11
Training loss: 0.5787225961685181
Validation loss: 2.087412198384603

Epoch: 6| Step: 12
Training loss: 0.3485151529312134
Validation loss: 2.05937127272288

Epoch: 6| Step: 13
Training loss: 0.23318061232566833
Validation loss: 2.111898938814799

Epoch: 436| Step: 0
Training loss: 0.37451815605163574
Validation loss: 2.0947568813959756

Epoch: 6| Step: 1
Training loss: 0.35040464997291565
Validation loss: 2.105142593383789

Epoch: 6| Step: 2
Training loss: 0.36773478984832764
Validation loss: 2.1939855813980103

Epoch: 6| Step: 3
Training loss: 0.4715505838394165
Validation loss: 2.1675980488459268

Epoch: 6| Step: 4
Training loss: 0.7871997952461243
Validation loss: 2.2215598622957864

Epoch: 6| Step: 5
Training loss: 0.2705061733722687
Validation loss: 2.2058717012405396

Epoch: 6| Step: 6
Training loss: 0.3662493824958801
Validation loss: 2.1587892174720764

Epoch: 6| Step: 7
Training loss: 0.26413631439208984
Validation loss: 2.112425963083903

Epoch: 6| Step: 8
Training loss: 0.30492061376571655
Validation loss: 2.1030264298121133

Epoch: 6| Step: 9
Training loss: 0.4847213625907898
Validation loss: 2.1129194299379983

Epoch: 6| Step: 10
Training loss: 0.44863396883010864
Validation loss: 2.1304060419400535

Epoch: 6| Step: 11
Training loss: 0.47125521302223206
Validation loss: 2.1253416538238525

Epoch: 6| Step: 12
Training loss: 0.3967176675796509
Validation loss: 2.1490493019421897

Epoch: 6| Step: 13
Training loss: 0.24193038046360016
Validation loss: 2.1363430420557656

Epoch: 437| Step: 0
Training loss: 0.293096661567688
Validation loss: 2.1960264245669046

Epoch: 6| Step: 1
Training loss: 0.5095288157463074
Validation loss: 2.2369046608606973

Epoch: 6| Step: 2
Training loss: 0.5342729091644287
Validation loss: 2.1696508328119912

Epoch: 6| Step: 3
Training loss: 0.37484899163246155
Validation loss: 2.2299752632776895

Epoch: 6| Step: 4
Training loss: 0.401214599609375
Validation loss: 2.1485944986343384

Epoch: 6| Step: 5
Training loss: 0.6408050656318665
Validation loss: 2.100061575571696

Epoch: 6| Step: 6
Training loss: 0.2914465069770813
Validation loss: 2.11615252494812

Epoch: 6| Step: 7
Training loss: 0.25111156702041626
Validation loss: 2.0964205066363015

Epoch: 6| Step: 8
Training loss: 0.3534165024757385
Validation loss: 2.0899570981661477

Epoch: 6| Step: 9
Training loss: 0.31919214129447937
Validation loss: 2.0362701614697776

Epoch: 6| Step: 10
Training loss: 0.20472781360149384
Validation loss: 2.095558524131775

Epoch: 6| Step: 11
Training loss: 0.27880218625068665
Validation loss: 2.12833180030187

Epoch: 6| Step: 12
Training loss: 0.2423042207956314
Validation loss: 2.133659581343333

Epoch: 6| Step: 13
Training loss: 0.4263902008533478
Validation loss: 2.144522766272227

Epoch: 438| Step: 0
Training loss: 0.9008768796920776
Validation loss: 2.170986215273539

Epoch: 6| Step: 1
Training loss: 0.3238071799278259
Validation loss: 2.135819653669993

Epoch: 6| Step: 2
Training loss: 0.3520086705684662
Validation loss: 2.108162522315979

Epoch: 6| Step: 3
Training loss: 0.20239663124084473
Validation loss: 2.1198688546816506

Epoch: 6| Step: 4
Training loss: 0.3549799621105194
Validation loss: 2.077359974384308

Epoch: 6| Step: 5
Training loss: 0.3487124443054199
Validation loss: 2.0608221093813577

Epoch: 6| Step: 6
Training loss: 0.37140199542045593
Validation loss: 2.152277926603953

Epoch: 6| Step: 7
Training loss: 0.15462547540664673
Validation loss: 2.1112826069196067

Epoch: 6| Step: 8
Training loss: 0.18425559997558594
Validation loss: 2.1168347795804343

Epoch: 6| Step: 9
Training loss: 0.298624724149704
Validation loss: 2.111816644668579

Epoch: 6| Step: 10
Training loss: 0.382490336894989
Validation loss: 2.1513083577156067

Epoch: 6| Step: 11
Training loss: 0.25192689895629883
Validation loss: 2.1654722690582275

Epoch: 6| Step: 12
Training loss: 0.22577619552612305
Validation loss: 2.12451042731603

Epoch: 6| Step: 13
Training loss: 0.3337622880935669
Validation loss: 2.0876316825548806

Epoch: 439| Step: 0
Training loss: 0.6589046716690063
Validation loss: 2.161215523878733

Epoch: 6| Step: 1
Training loss: 0.2972002923488617
Validation loss: 2.146230081717173

Epoch: 6| Step: 2
Training loss: 0.22764132916927338
Validation loss: 2.1278602878252664

Epoch: 6| Step: 3
Training loss: 0.2503291666507721
Validation loss: 2.1622447570165

Epoch: 6| Step: 4
Training loss: 0.1945129781961441
Validation loss: 2.1339306632677713

Epoch: 6| Step: 5
Training loss: 0.28433847427368164
Validation loss: 2.101805488268534

Epoch: 6| Step: 6
Training loss: 0.3127167820930481
Validation loss: 2.1486106514930725

Epoch: 6| Step: 7
Training loss: 0.24559205770492554
Validation loss: 2.1130431095759072

Epoch: 6| Step: 8
Training loss: 0.315965861082077
Validation loss: 2.1471028129259744

Epoch: 6| Step: 9
Training loss: 0.29824507236480713
Validation loss: 2.1250282724698386

Epoch: 6| Step: 10
Training loss: 0.3813917636871338
Validation loss: 2.1244549552599588

Epoch: 6| Step: 11
Training loss: 0.2515314817428589
Validation loss: 2.156087577342987

Epoch: 6| Step: 12
Training loss: 0.37483686208724976
Validation loss: 2.100631515185038

Epoch: 6| Step: 13
Training loss: 0.2418895810842514
Validation loss: 2.158520062764486

Epoch: 440| Step: 0
Training loss: 0.2115161120891571
Validation loss: 2.1293168862660727

Epoch: 6| Step: 1
Training loss: 0.5551919937133789
Validation loss: 2.104671061038971

Epoch: 6| Step: 2
Training loss: 0.25921812653541565
Validation loss: 2.14155779282252

Epoch: 6| Step: 3
Training loss: 0.21359285712242126
Validation loss: 2.1378071705500283

Epoch: 6| Step: 4
Training loss: 0.2746129631996155
Validation loss: 2.102677861849467

Epoch: 6| Step: 5
Training loss: 0.20246857404708862
Validation loss: 2.108676016330719

Epoch: 6| Step: 6
Training loss: 0.13209852576255798
Validation loss: 2.121165951093038

Epoch: 6| Step: 7
Training loss: 0.30632564425468445
Validation loss: 2.1359954277674356

Epoch: 6| Step: 8
Training loss: 0.16585847735404968
Validation loss: 2.1022669672966003

Epoch: 6| Step: 9
Training loss: 0.4936313033103943
Validation loss: 2.1688245733579

Epoch: 6| Step: 10
Training loss: 0.24320575594902039
Validation loss: 2.1201992432276406

Epoch: 6| Step: 11
Training loss: 0.14904913306236267
Validation loss: 2.13757316271464

Epoch: 6| Step: 12
Training loss: 0.36208051443099976
Validation loss: 2.0990813970565796

Epoch: 6| Step: 13
Training loss: 0.3174624443054199
Validation loss: 2.1188731590906777

Epoch: 441| Step: 0
Training loss: 0.3577360212802887
Validation loss: 2.117093245188395

Epoch: 6| Step: 1
Training loss: 0.26706886291503906
Validation loss: 2.1674444874127707

Epoch: 6| Step: 2
Training loss: 0.24955447018146515
Validation loss: 2.1257123152414956

Epoch: 6| Step: 3
Training loss: 0.2563416063785553
Validation loss: 2.182476262251536

Epoch: 6| Step: 4
Training loss: 0.1576608121395111
Validation loss: 2.169194281101227

Epoch: 6| Step: 5
Training loss: 0.339893639087677
Validation loss: 2.1580116550127664

Epoch: 6| Step: 6
Training loss: 0.46067535877227783
Validation loss: 2.1291956702868142

Epoch: 6| Step: 7
Training loss: 0.5792749524116516
Validation loss: 2.1307461063067117

Epoch: 6| Step: 8
Training loss: 0.20101463794708252
Validation loss: 2.144215921560923

Epoch: 6| Step: 9
Training loss: 0.238324835896492
Validation loss: 2.091991980870565

Epoch: 6| Step: 10
Training loss: 0.24304629862308502
Validation loss: 2.133892595767975

Epoch: 6| Step: 11
Training loss: 0.24841466546058655
Validation loss: 2.0948407451311746

Epoch: 6| Step: 12
Training loss: 0.3198986351490021
Validation loss: 2.161737342675527

Epoch: 6| Step: 13
Training loss: 0.219484344124794
Validation loss: 2.1303091049194336

Epoch: 442| Step: 0
Training loss: 0.35729822516441345
Validation loss: 2.1533449292182922

Epoch: 6| Step: 1
Training loss: 0.2585728168487549
Validation loss: 2.1302976608276367

Epoch: 6| Step: 2
Training loss: 0.34246423840522766
Validation loss: 2.171851615111033

Epoch: 6| Step: 3
Training loss: 0.17351943254470825
Validation loss: 2.132497946421305

Epoch: 6| Step: 4
Training loss: 0.2022881656885147
Validation loss: 2.1229364474614463

Epoch: 6| Step: 5
Training loss: 0.4188160300254822
Validation loss: 2.1426438093185425

Epoch: 6| Step: 6
Training loss: 0.16226333379745483
Validation loss: 2.0889829198519387

Epoch: 6| Step: 7
Training loss: 0.17679175734519958
Validation loss: 2.1309641400973

Epoch: 6| Step: 8
Training loss: 0.22877538204193115
Validation loss: 2.1336961587270102

Epoch: 6| Step: 9
Training loss: 0.24755942821502686
Validation loss: 2.146427353223165

Epoch: 6| Step: 10
Training loss: 0.23438990116119385
Validation loss: 2.1381850441296897

Epoch: 6| Step: 11
Training loss: 0.5904727578163147
Validation loss: 2.1528557538986206

Epoch: 6| Step: 12
Training loss: 0.2850745618343353
Validation loss: 2.0965028206507363

Epoch: 6| Step: 13
Training loss: 0.17503425478935242
Validation loss: 2.1233320434888205

Epoch: 443| Step: 0
Training loss: 0.2700735032558441
Validation loss: 2.137380838394165

Epoch: 6| Step: 1
Training loss: 0.3043186366558075
Validation loss: 2.1287394165992737

Epoch: 6| Step: 2
Training loss: 0.23888805508613586
Validation loss: 2.1400235096613565

Epoch: 6| Step: 3
Training loss: 0.6099412441253662
Validation loss: 2.135629336039225

Epoch: 6| Step: 4
Training loss: 0.2775290608406067
Validation loss: 2.0746654272079468

Epoch: 6| Step: 5
Training loss: 0.24670466780662537
Validation loss: 2.1462719241778054

Epoch: 6| Step: 6
Training loss: 0.24749669432640076
Validation loss: 2.140088518460592

Epoch: 6| Step: 7
Training loss: 0.23113135993480682
Validation loss: 2.1163105169932046

Epoch: 6| Step: 8
Training loss: 0.2983812093734741
Validation loss: 2.1198325554529824

Epoch: 6| Step: 9
Training loss: 0.17236986756324768
Validation loss: 2.1510568459828696

Epoch: 6| Step: 10
Training loss: 0.2897951304912567
Validation loss: 2.095722198486328

Epoch: 6| Step: 11
Training loss: 0.5025454759597778
Validation loss: 2.0653048356374106

Epoch: 6| Step: 12
Training loss: 0.1641986072063446
Validation loss: 2.135659615198771

Epoch: 6| Step: 13
Training loss: 0.24416467547416687
Validation loss: 2.1233304937680564

Epoch: 444| Step: 0
Training loss: 0.6225902438163757
Validation loss: 2.118288000424703

Epoch: 6| Step: 1
Training loss: 0.36850619316101074
Validation loss: 2.0809844732284546

Epoch: 6| Step: 2
Training loss: 0.1517496556043625
Validation loss: 2.115372896194458

Epoch: 6| Step: 3
Training loss: 0.2157258689403534
Validation loss: 2.1378520925839744

Epoch: 6| Step: 4
Training loss: 0.4481096565723419
Validation loss: 2.1613921920458474

Epoch: 6| Step: 5
Training loss: 0.1458934247493744
Validation loss: 2.125078797340393

Epoch: 6| Step: 6
Training loss: 0.20661191642284393
Validation loss: 2.142416993776957

Epoch: 6| Step: 7
Training loss: 0.2980782687664032
Validation loss: 2.0837390621503196

Epoch: 6| Step: 8
Training loss: 0.1930457502603531
Validation loss: 2.1157015760739646

Epoch: 6| Step: 9
Training loss: 0.25508007407188416
Validation loss: 2.1183157364527383

Epoch: 6| Step: 10
Training loss: 0.19003528356552124
Validation loss: 2.101002554098765

Epoch: 6| Step: 11
Training loss: 0.36412835121154785
Validation loss: 2.1145139733950296

Epoch: 6| Step: 12
Training loss: 0.2816804349422455
Validation loss: 2.1336328387260437

Epoch: 6| Step: 13
Training loss: 0.33414599299430847
Validation loss: 2.139377236366272

Epoch: 445| Step: 0
Training loss: 0.5593603849411011
Validation loss: 2.1589303612709045

Epoch: 6| Step: 1
Training loss: 0.1684035211801529
Validation loss: 2.1078756054242453

Epoch: 6| Step: 2
Training loss: 0.19905129075050354
Validation loss: 2.1374881068865457

Epoch: 6| Step: 3
Training loss: 0.17748256027698517
Validation loss: 2.1094852487246194

Epoch: 6| Step: 4
Training loss: 0.20481674373149872
Validation loss: 2.125150760014852

Epoch: 6| Step: 5
Training loss: 0.33115822076797485
Validation loss: 2.104564368724823

Epoch: 6| Step: 6
Training loss: 0.26396995782852173
Validation loss: 2.1124666333198547

Epoch: 6| Step: 7
Training loss: 0.39052245020866394
Validation loss: 2.15793244043986

Epoch: 6| Step: 8
Training loss: 0.2740919589996338
Validation loss: 2.168560961882273

Epoch: 6| Step: 9
Training loss: 0.13270190358161926
Validation loss: 2.1862624883651733

Epoch: 6| Step: 10
Training loss: 0.23709069192409515
Validation loss: 2.191411336263021

Epoch: 6| Step: 11
Training loss: 0.40355294942855835
Validation loss: 2.1678338845570884

Epoch: 6| Step: 12
Training loss: 0.26413825154304504
Validation loss: 2.1619728406270347

Epoch: 6| Step: 13
Training loss: 0.18909816443920135
Validation loss: 2.069986343383789

Epoch: 446| Step: 0
Training loss: 0.2387470006942749
Validation loss: 2.1464348236719766

Epoch: 6| Step: 1
Training loss: 0.2864823341369629
Validation loss: 2.076629320780436

Epoch: 6| Step: 2
Training loss: 0.2664121985435486
Validation loss: 2.1108978192011514

Epoch: 6| Step: 3
Training loss: 0.2934204936027527
Validation loss: 2.1254310607910156

Epoch: 6| Step: 4
Training loss: 0.2621234059333801
Validation loss: 2.1689897775650024

Epoch: 6| Step: 5
Training loss: 0.2965454161167145
Validation loss: 2.147796312967936

Epoch: 6| Step: 6
Training loss: 0.4729725420475006
Validation loss: 2.1328867077827454

Epoch: 6| Step: 7
Training loss: 0.6520707607269287
Validation loss: 2.104094405968984

Epoch: 6| Step: 8
Training loss: 0.2416800707578659
Validation loss: 2.1155696908632913

Epoch: 6| Step: 9
Training loss: 0.23903749883174896
Validation loss: 2.120889365673065

Epoch: 6| Step: 10
Training loss: 0.23574833571910858
Validation loss: 2.1093691190083823

Epoch: 6| Step: 11
Training loss: 0.3527695834636688
Validation loss: 2.125549773375193

Epoch: 6| Step: 12
Training loss: 0.2869361639022827
Validation loss: 2.091784199078878

Epoch: 6| Step: 13
Training loss: 0.24703818559646606
Validation loss: 2.1357385516166687

Epoch: 447| Step: 0
Training loss: 0.26479727029800415
Validation loss: 2.1426050662994385

Epoch: 6| Step: 1
Training loss: 0.16247586905956268
Validation loss: 2.1447720925013223

Epoch: 6| Step: 2
Training loss: 0.37413495779037476
Validation loss: 2.129589080810547

Epoch: 6| Step: 3
Training loss: 0.28694379329681396
Validation loss: 2.1539217432339988

Epoch: 6| Step: 4
Training loss: 0.268562912940979
Validation loss: 2.1521421472231546

Epoch: 6| Step: 5
Training loss: 0.22728386521339417
Validation loss: 2.151536464691162

Epoch: 6| Step: 6
Training loss: 0.27581873536109924
Validation loss: 2.1373014648755393

Epoch: 6| Step: 7
Training loss: 0.3384859561920166
Validation loss: 2.082278033097585

Epoch: 6| Step: 8
Training loss: 0.1824057251214981
Validation loss: 2.136680543422699

Epoch: 6| Step: 9
Training loss: 0.7318762540817261
Validation loss: 2.1243698398272195

Epoch: 6| Step: 10
Training loss: 0.19004306197166443
Validation loss: 2.125382979710897

Epoch: 6| Step: 11
Training loss: 0.2449478805065155
Validation loss: 2.113983949025472

Epoch: 6| Step: 12
Training loss: 0.20822876691818237
Validation loss: 2.142001450061798

Epoch: 6| Step: 13
Training loss: 0.3631395101547241
Validation loss: 2.166338264942169

Epoch: 448| Step: 0
Training loss: 0.1980559527873993
Validation loss: 2.1030112902323403

Epoch: 6| Step: 1
Training loss: 0.24263986945152283
Validation loss: 2.145739436149597

Epoch: 6| Step: 2
Training loss: 0.21543927490711212
Validation loss: 2.1543531815210977

Epoch: 6| Step: 3
Training loss: 0.6707273125648499
Validation loss: 2.095066030820211

Epoch: 6| Step: 4
Training loss: 0.19587892293930054
Validation loss: 2.098874032497406

Epoch: 6| Step: 5
Training loss: 0.34189939498901367
Validation loss: 2.107214570045471

Epoch: 6| Step: 6
Training loss: 0.5257302522659302
Validation loss: 2.136129359404246

Epoch: 6| Step: 7
Training loss: 0.17590904235839844
Validation loss: 2.0881800850232444

Epoch: 6| Step: 8
Training loss: 0.1590741127729416
Validation loss: 2.146000782648722

Epoch: 6| Step: 9
Training loss: 0.21036064624786377
Validation loss: 2.1347848375638327

Epoch: 6| Step: 10
Training loss: 0.25663474202156067
Validation loss: 2.1212921341260276

Epoch: 6| Step: 11
Training loss: 0.27597862482070923
Validation loss: 2.1610522071520486

Epoch: 6| Step: 12
Training loss: 0.17497754096984863
Validation loss: 2.119637370109558

Epoch: 6| Step: 13
Training loss: 0.2639615535736084
Validation loss: 2.1241612235705056

Epoch: 449| Step: 0
Training loss: 0.7255867719650269
Validation loss: 2.1863019863764444

Epoch: 6| Step: 1
Training loss: 0.23410820960998535
Validation loss: 2.1292218963305154

Epoch: 6| Step: 2
Training loss: 0.2701256275177002
Validation loss: 2.117018719514211

Epoch: 6| Step: 3
Training loss: 0.221586674451828
Validation loss: 2.132991671562195

Epoch: 6| Step: 4
Training loss: 0.39835700392723083
Validation loss: 2.1377247174580893

Epoch: 6| Step: 5
Training loss: 0.4404718279838562
Validation loss: 2.2079176704088845

Epoch: 6| Step: 6
Training loss: 0.15918774902820587
Validation loss: 2.1456639568010965

Epoch: 6| Step: 7
Training loss: 0.253836452960968
Validation loss: 2.1010458866755166

Epoch: 6| Step: 8
Training loss: 0.26019352674484253
Validation loss: 2.1314810514450073

Epoch: 6| Step: 9
Training loss: 0.2654455304145813
Validation loss: 2.0994132359822593

Epoch: 6| Step: 10
Training loss: 0.4798041880130768
Validation loss: 2.098315497239431

Epoch: 6| Step: 11
Training loss: 0.32370319962501526
Validation loss: 2.141704340775808

Epoch: 6| Step: 12
Training loss: 0.2090442180633545
Validation loss: 2.1441489458084106

Epoch: 6| Step: 13
Training loss: 0.2127319872379303
Validation loss: 2.163986643155416

Epoch: 450| Step: 0
Training loss: 0.28728821873664856
Validation loss: 2.1952120065689087

Epoch: 6| Step: 1
Training loss: 0.438673734664917
Validation loss: 2.108473777770996

Epoch: 6| Step: 2
Training loss: 0.35525229573249817
Validation loss: 2.119101583957672

Epoch: 6| Step: 3
Training loss: 0.2121492326259613
Validation loss: 2.102761367956797

Epoch: 6| Step: 4
Training loss: 0.2405834197998047
Validation loss: 2.1305724382400513

Epoch: 6| Step: 5
Training loss: 0.19308486580848694
Validation loss: 2.0882820884386697

Epoch: 6| Step: 6
Training loss: 0.5893765687942505
Validation loss: 2.115193724632263

Epoch: 6| Step: 7
Training loss: 0.22246231138706207
Validation loss: 2.145062883694967

Epoch: 6| Step: 8
Training loss: 0.23418855667114258
Validation loss: 2.1397135655085244

Epoch: 6| Step: 9
Training loss: 0.18135665357112885
Validation loss: 2.1488844950993857

Epoch: 6| Step: 10
Training loss: 0.21439799666404724
Validation loss: 2.086469908555349

Epoch: 6| Step: 11
Training loss: 0.25337111949920654
Validation loss: 2.0742056171099343

Epoch: 6| Step: 12
Training loss: 0.3260970711708069
Validation loss: 2.1008456150690713

Epoch: 6| Step: 13
Training loss: 0.2807154357433319
Validation loss: 2.1211941838264465

Testing loss: 1.9130404724491585
