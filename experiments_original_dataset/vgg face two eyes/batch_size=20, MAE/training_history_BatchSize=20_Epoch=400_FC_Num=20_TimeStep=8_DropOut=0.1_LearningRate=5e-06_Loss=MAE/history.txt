Epoch: 1| Step: 0
Training loss: 8.628338813781738
Validation loss: 7.877308150132497

Epoch: 5| Step: 1
Training loss: 7.808712959289551
Validation loss: 7.844533979892731

Epoch: 5| Step: 2
Training loss: 8.349742889404297
Validation loss: 7.811630308628082

Epoch: 5| Step: 3
Training loss: 7.333898067474365
Validation loss: 7.783351083596547

Epoch: 5| Step: 4
Training loss: 7.1987624168396
Validation loss: 7.75202214717865

Epoch: 5| Step: 5
Training loss: 6.996456146240234
Validation loss: 7.72125385204951

Epoch: 5| Step: 6
Training loss: 7.561887264251709
Validation loss: 7.693208793799083

Epoch: 5| Step: 7
Training loss: 8.640429496765137
Validation loss: 7.663840472698212

Epoch: 5| Step: 8
Training loss: 7.840257167816162
Validation loss: 7.634720663229625

Epoch: 5| Step: 9
Training loss: 7.3191328048706055
Validation loss: 7.604272842407227

Epoch: 5| Step: 10
Training loss: 7.839684963226318
Validation loss: 7.577280342578888

Epoch: 5| Step: 11
Training loss: 8.516361236572266
Validation loss: 7.541856249173482

Epoch: 2| Step: 0
Training loss: 7.795008659362793
Validation loss: 7.514578918615977

Epoch: 5| Step: 1
Training loss: 8.4768648147583
Validation loss: 7.483573138713837

Epoch: 5| Step: 2
Training loss: 7.51830530166626
Validation loss: 7.446532825628917

Epoch: 5| Step: 3
Training loss: 6.882382869720459
Validation loss: 7.417698721090953

Epoch: 5| Step: 4
Training loss: 6.334695816040039
Validation loss: 7.3842549324035645

Epoch: 5| Step: 5
Training loss: 6.973986625671387
Validation loss: 7.348330835501353

Epoch: 5| Step: 6
Training loss: 6.365533828735352
Validation loss: 7.310042440891266

Epoch: 5| Step: 7
Training loss: 8.224786758422852
Validation loss: 7.275456686814626

Epoch: 5| Step: 8
Training loss: 8.261689186096191
Validation loss: 7.236070195833842

Epoch: 5| Step: 9
Training loss: 6.78216552734375
Validation loss: 7.1944573521614075

Epoch: 5| Step: 10
Training loss: 7.7780914306640625
Validation loss: 7.151614387830098

Epoch: 5| Step: 11
Training loss: 7.797165870666504
Validation loss: 7.113939066727956

Epoch: 3| Step: 0
Training loss: 8.26984691619873
Validation loss: 7.0717581907908125

Epoch: 5| Step: 1
Training loss: 6.985141754150391
Validation loss: 7.02274356285731

Epoch: 5| Step: 2
Training loss: 7.133101463317871
Validation loss: 6.979145149389903

Epoch: 5| Step: 3
Training loss: 7.2444257736206055
Validation loss: 6.931605140368144

Epoch: 5| Step: 4
Training loss: 6.664950370788574
Validation loss: 6.879282732804616

Epoch: 5| Step: 5
Training loss: 6.351151943206787
Validation loss: 6.832109113534291

Epoch: 5| Step: 6
Training loss: 6.081335544586182
Validation loss: 6.778640508651733

Epoch: 5| Step: 7
Training loss: 7.167031764984131
Validation loss: 6.72085964679718

Epoch: 5| Step: 8
Training loss: 6.482261657714844
Validation loss: 6.661716143290202

Epoch: 5| Step: 9
Training loss: 5.991764068603516
Validation loss: 6.600013355414073

Epoch: 5| Step: 10
Training loss: 7.628279209136963
Validation loss: 6.536130845546722

Epoch: 5| Step: 11
Training loss: 5.594829082489014
Validation loss: 6.473239362239838

Epoch: 4| Step: 0
Training loss: 5.805746078491211
Validation loss: 6.406086464722951

Epoch: 5| Step: 1
Training loss: 6.289395809173584
Validation loss: 6.331015010674794

Epoch: 5| Step: 2
Training loss: 7.095980644226074
Validation loss: 6.251123865445455

Epoch: 5| Step: 3
Training loss: 5.5775837898254395
Validation loss: 6.18176273504893

Epoch: 5| Step: 4
Training loss: 6.421316623687744
Validation loss: 6.096765379110972

Epoch: 5| Step: 5
Training loss: 6.413235664367676
Validation loss: 6.018139064311981

Epoch: 5| Step: 6
Training loss: 5.816649913787842
Validation loss: 5.924527982870738

Epoch: 5| Step: 7
Training loss: 5.693964958190918
Validation loss: 5.839380760987599

Epoch: 5| Step: 8
Training loss: 5.814640045166016
Validation loss: 5.743655840555827

Epoch: 5| Step: 9
Training loss: 6.485066890716553
Validation loss: 5.643662353356679

Epoch: 5| Step: 10
Training loss: 5.830780982971191
Validation loss: 5.540226797262828

Epoch: 5| Step: 11
Training loss: 4.458281993865967
Validation loss: 5.4358775814374285

Epoch: 5| Step: 0
Training loss: 4.784969329833984
Validation loss: 5.340943654378255

Epoch: 5| Step: 1
Training loss: 6.488429069519043
Validation loss: 5.215544025103251

Epoch: 5| Step: 2
Training loss: 5.97435998916626
Validation loss: 5.104757328828176

Epoch: 5| Step: 3
Training loss: 5.257576942443848
Validation loss: 4.981438557306926

Epoch: 5| Step: 4
Training loss: 4.550605773925781
Validation loss: 4.864111701647441

Epoch: 5| Step: 5
Training loss: 5.717761993408203
Validation loss: 4.732875108718872

Epoch: 5| Step: 6
Training loss: 4.56752347946167
Validation loss: 4.60254708925883

Epoch: 5| Step: 7
Training loss: 3.313464403152466
Validation loss: 4.47131594022115

Epoch: 5| Step: 8
Training loss: 4.55862283706665
Validation loss: 4.305972596009572

Epoch: 5| Step: 9
Training loss: 3.8250560760498047
Validation loss: 4.148487061262131

Epoch: 5| Step: 10
Training loss: 4.152466773986816
Validation loss: 4.003618200620015

Epoch: 5| Step: 11
Training loss: 3.673088550567627
Validation loss: 3.859600226084391

Epoch: 6| Step: 0
Training loss: 2.869912624359131
Validation loss: 3.7232759396235147

Epoch: 5| Step: 1
Training loss: 3.249221086502075
Validation loss: 3.5541628301143646

Epoch: 5| Step: 2
Training loss: 3.5912201404571533
Validation loss: 3.425291568040848

Epoch: 5| Step: 3
Training loss: 4.03718376159668
Validation loss: 3.2594387928644815

Epoch: 5| Step: 4
Training loss: 4.044740676879883
Validation loss: 3.1153908570607505

Epoch: 5| Step: 5
Training loss: 2.6137259006500244
Validation loss: 2.9734819730122886

Epoch: 5| Step: 6
Training loss: 2.498447895050049
Validation loss: 2.8236604829629264

Epoch: 5| Step: 7
Training loss: 2.930865526199341
Validation loss: 2.702903022368749

Epoch: 5| Step: 8
Training loss: 3.226076126098633
Validation loss: 2.5597244203090668

Epoch: 5| Step: 9
Training loss: 2.8656907081604004
Validation loss: 2.42826900879542

Epoch: 5| Step: 10
Training loss: 2.4413716793060303
Validation loss: 2.301445816953977

Epoch: 5| Step: 11
Training loss: 0.9155735969543457
Validation loss: 2.2531890273094177

Epoch: 7| Step: 0
Training loss: 2.0067977905273438
Validation loss: 2.1565767526626587

Epoch: 5| Step: 1
Training loss: 2.5096123218536377
Validation loss: 2.1437532703081765

Epoch: 5| Step: 2
Training loss: 2.0112154483795166
Validation loss: 2.1201478987932205

Epoch: 5| Step: 3
Training loss: 1.7067077159881592
Validation loss: 2.129108270009359

Epoch: 5| Step: 4
Training loss: 2.7288742065429688
Validation loss: 2.103269840280215

Epoch: 5| Step: 5
Training loss: 2.7784786224365234
Validation loss: 2.122214878598849

Epoch: 5| Step: 6
Training loss: 2.2845358848571777
Validation loss: 2.1524447153011956

Epoch: 5| Step: 7
Training loss: 2.3656671047210693
Validation loss: 2.1990676323572793

Epoch: 5| Step: 8
Training loss: 2.3662893772125244
Validation loss: 2.163279245297114

Epoch: 5| Step: 9
Training loss: 2.3734946250915527
Validation loss: 2.252437800168991

Epoch: 5| Step: 10
Training loss: 1.686837911605835
Validation loss: 2.248161127169927

Epoch: 5| Step: 11
Training loss: 3.2244391441345215
Validation loss: 2.2097825407981873

Epoch: 8| Step: 0
Training loss: 2.15649676322937
Validation loss: 2.2260294755299888

Epoch: 5| Step: 1
Training loss: 1.6011111736297607
Validation loss: 2.205830231308937

Epoch: 5| Step: 2
Training loss: 2.174699306488037
Validation loss: 2.155656407276789

Epoch: 5| Step: 3
Training loss: 2.307091474533081
Validation loss: 2.1630174765984216

Epoch: 5| Step: 4
Training loss: 2.304861068725586
Validation loss: 2.1272432754437127

Epoch: 5| Step: 5
Training loss: 2.0673935413360596
Validation loss: 2.1552371283372245

Epoch: 5| Step: 6
Training loss: 2.6169779300689697
Validation loss: 2.119327495495478

Epoch: 5| Step: 7
Training loss: 2.682948112487793
Validation loss: 2.108847131331762

Epoch: 5| Step: 8
Training loss: 3.135272979736328
Validation loss: 2.116371681292852

Epoch: 5| Step: 9
Training loss: 2.3427159786224365
Validation loss: 2.0839525212844214

Epoch: 5| Step: 10
Training loss: 1.6431066989898682
Validation loss: 2.107768476009369

Epoch: 5| Step: 11
Training loss: 2.0249500274658203
Validation loss: 2.089201346039772

Epoch: 9| Step: 0
Training loss: 2.5460400581359863
Validation loss: 2.1125147541364035

Epoch: 5| Step: 1
Training loss: 2.8349947929382324
Validation loss: 2.101702556014061

Epoch: 5| Step: 2
Training loss: 1.7932960987091064
Validation loss: 2.1217006196578345

Epoch: 5| Step: 3
Training loss: 2.547625780105591
Validation loss: 2.1310088485479355

Epoch: 5| Step: 4
Training loss: 2.3841021060943604
Validation loss: 2.1373099933067956

Epoch: 5| Step: 5
Training loss: 2.0926074981689453
Validation loss: 2.130132332444191

Epoch: 5| Step: 6
Training loss: 1.7539260387420654
Validation loss: 2.0842776695887246

Epoch: 5| Step: 7
Training loss: 2.433903217315674
Validation loss: 2.0772793938716254

Epoch: 5| Step: 8
Training loss: 1.945594072341919
Validation loss: 2.0684429754813514

Epoch: 5| Step: 9
Training loss: 1.6268994808197021
Validation loss: 2.1162018477916718

Epoch: 5| Step: 10
Training loss: 2.8320305347442627
Validation loss: 2.0709053725004196

Epoch: 5| Step: 11
Training loss: 2.2927348613739014
Validation loss: 2.059182350834211

Epoch: 10| Step: 0
Training loss: 2.2645199298858643
Validation loss: 2.1215082009633384

Epoch: 5| Step: 1
Training loss: 2.1461362838745117
Validation loss: 2.090291346112887

Epoch: 5| Step: 2
Training loss: 1.8193418979644775
Validation loss: 2.124032740791639

Epoch: 5| Step: 3
Training loss: 2.5810465812683105
Validation loss: 2.1218382716178894

Epoch: 5| Step: 4
Training loss: 2.7265491485595703
Validation loss: 2.0992009341716766

Epoch: 5| Step: 5
Training loss: 2.6481680870056152
Validation loss: 2.1045313626527786

Epoch: 5| Step: 6
Training loss: 1.7723850011825562
Validation loss: 2.153141751885414

Epoch: 5| Step: 7
Training loss: 2.31121826171875
Validation loss: 2.0909493565559387

Epoch: 5| Step: 8
Training loss: 1.7974693775177002
Validation loss: 2.0993695656458535

Epoch: 5| Step: 9
Training loss: 2.3169713020324707
Validation loss: 2.112075294057528

Epoch: 5| Step: 10
Training loss: 1.948883295059204
Validation loss: 2.080064982175827

Epoch: 5| Step: 11
Training loss: 2.046581983566284
Validation loss: 2.1259034872055054

Epoch: 11| Step: 0
Training loss: 2.1966593265533447
Validation loss: 2.068305879831314

Epoch: 5| Step: 1
Training loss: 1.9550765752792358
Validation loss: 2.109983613093694

Epoch: 5| Step: 2
Training loss: 1.972659707069397
Validation loss: 2.056739091873169

Epoch: 5| Step: 3
Training loss: 2.731422185897827
Validation loss: 2.09959081808726

Epoch: 5| Step: 4
Training loss: 1.626725435256958
Validation loss: 2.0915434708197913

Epoch: 5| Step: 5
Training loss: 2.1331067085266113
Validation loss: 2.07633147140344

Epoch: 5| Step: 6
Training loss: 2.3264126777648926
Validation loss: 2.0384053041537604

Epoch: 5| Step: 7
Training loss: 2.322068452835083
Validation loss: 2.056251828869184

Epoch: 5| Step: 8
Training loss: 2.157679796218872
Validation loss: 2.0331866294145584

Epoch: 5| Step: 9
Training loss: 2.3307783603668213
Validation loss: 2.0359730571508408

Epoch: 5| Step: 10
Training loss: 2.709249258041382
Validation loss: 2.06914850572745

Epoch: 5| Step: 11
Training loss: 1.9202169179916382
Validation loss: 2.0632254779338837

Epoch: 12| Step: 0
Training loss: 1.6584354639053345
Validation loss: 2.060342699289322

Epoch: 5| Step: 1
Training loss: 1.9572185277938843
Validation loss: 2.106378272175789

Epoch: 5| Step: 2
Training loss: 2.543854236602783
Validation loss: 2.061227853099505

Epoch: 5| Step: 3
Training loss: 2.4079465866088867
Validation loss: 2.0946098417043686

Epoch: 5| Step: 4
Training loss: 1.7108278274536133
Validation loss: 2.084687188267708

Epoch: 5| Step: 5
Training loss: 2.357574939727783
Validation loss: 2.1383246928453445

Epoch: 5| Step: 6
Training loss: 2.4016177654266357
Validation loss: 2.110417236884435

Epoch: 5| Step: 7
Training loss: 2.1677544116973877
Validation loss: 2.09407647450765

Epoch: 5| Step: 8
Training loss: 1.94451105594635
Validation loss: 2.131399239102999

Epoch: 5| Step: 9
Training loss: 2.3652217388153076
Validation loss: 2.11407633125782

Epoch: 5| Step: 10
Training loss: 2.457913875579834
Validation loss: 2.110637550552686

Epoch: 5| Step: 11
Training loss: 3.4707090854644775
Validation loss: 2.070220490296682

Epoch: 13| Step: 0
Training loss: 2.7293083667755127
Validation loss: 2.0891620169083276

Epoch: 5| Step: 1
Training loss: 1.696183443069458
Validation loss: 2.0909276455640793

Epoch: 5| Step: 2
Training loss: 2.409961700439453
Validation loss: 2.0950091034173965

Epoch: 5| Step: 3
Training loss: 1.427381992340088
Validation loss: 2.05144864320755

Epoch: 5| Step: 4
Training loss: 2.1931185722351074
Validation loss: 2.0750585546096167

Epoch: 5| Step: 5
Training loss: 2.8556582927703857
Validation loss: 2.058656617999077

Epoch: 5| Step: 6
Training loss: 1.9364616870880127
Validation loss: 2.0694182068109512

Epoch: 5| Step: 7
Training loss: 2.0567727088928223
Validation loss: 2.055921792984009

Epoch: 5| Step: 8
Training loss: 2.25365948677063
Validation loss: 2.086027150352796

Epoch: 5| Step: 9
Training loss: 2.228118896484375
Validation loss: 2.0636915465195975

Epoch: 5| Step: 10
Training loss: 2.1898183822631836
Validation loss: 2.071542044480642

Epoch: 5| Step: 11
Training loss: 1.6185381412506104
Validation loss: 2.078945368528366

Epoch: 14| Step: 0
Training loss: 1.892367959022522
Validation loss: 2.1078801304101944

Epoch: 5| Step: 1
Training loss: 1.7668139934539795
Validation loss: 2.1054358730713525

Epoch: 5| Step: 2
Training loss: 2.9926841259002686
Validation loss: 2.0910774221022925

Epoch: 5| Step: 3
Training loss: 1.9419561624526978
Validation loss: 2.0424157977104187

Epoch: 5| Step: 4
Training loss: 2.3634138107299805
Validation loss: 2.059575309356054

Epoch: 5| Step: 5
Training loss: 2.3618323802948
Validation loss: 2.0249166786670685

Epoch: 5| Step: 6
Training loss: 1.645250678062439
Validation loss: 2.0517129550377526

Epoch: 5| Step: 7
Training loss: 2.5313193798065186
Validation loss: 2.11382723848025

Epoch: 5| Step: 8
Training loss: 2.121436595916748
Validation loss: 2.104813223083814

Epoch: 5| Step: 9
Training loss: 2.1230390071868896
Validation loss: 2.0827576319376626

Epoch: 5| Step: 10
Training loss: 2.131575345993042
Validation loss: 2.0957736571629844

Epoch: 5| Step: 11
Training loss: 1.9565075635910034
Validation loss: 2.112015023827553

Epoch: 15| Step: 0
Training loss: 1.7987016439437866
Validation loss: 2.1624238987763724

Epoch: 5| Step: 1
Training loss: 1.8012094497680664
Validation loss: 2.1632182647784552

Epoch: 5| Step: 2
Training loss: 2.625725507736206
Validation loss: 2.2079719553391137

Epoch: 5| Step: 3
Training loss: 2.309641122817993
Validation loss: 2.24622576435407

Epoch: 5| Step: 4
Training loss: 1.9617500305175781
Validation loss: 2.220820734898249

Epoch: 5| Step: 5
Training loss: 2.5750551223754883
Validation loss: 2.195768823226293

Epoch: 5| Step: 6
Training loss: 2.3613975048065186
Validation loss: 2.194593131542206

Epoch: 5| Step: 7
Training loss: 2.1468772888183594
Validation loss: 2.195294419924418

Epoch: 5| Step: 8
Training loss: 2.815626621246338
Validation loss: 2.1379869282245636

Epoch: 5| Step: 9
Training loss: 2.076704502105713
Validation loss: 2.1378822177648544

Epoch: 5| Step: 10
Training loss: 1.7086378335952759
Validation loss: 2.0929484417041144

Epoch: 5| Step: 11
Training loss: 2.1461377143859863
Validation loss: 2.06849471728007

Epoch: 16| Step: 0
Training loss: 2.3464951515197754
Validation loss: 2.0543289383252463

Epoch: 5| Step: 1
Training loss: 1.784949541091919
Validation loss: 2.02272201081117

Epoch: 5| Step: 2
Training loss: 1.892431616783142
Validation loss: 2.0697103341420493

Epoch: 5| Step: 3
Training loss: 2.6020007133483887
Validation loss: 2.0604826708634696

Epoch: 5| Step: 4
Training loss: 2.7321712970733643
Validation loss: 2.0911281605561576

Epoch: 5| Step: 5
Training loss: 2.3832919597625732
Validation loss: 2.060626914103826

Epoch: 5| Step: 6
Training loss: 2.3351151943206787
Validation loss: 2.0940574953953424

Epoch: 5| Step: 7
Training loss: 2.78583025932312
Validation loss: 2.099859560529391

Epoch: 5| Step: 8
Training loss: 1.5844898223876953
Validation loss: 2.066971927881241

Epoch: 5| Step: 9
Training loss: 1.8669008016586304
Validation loss: 2.0228179345528283

Epoch: 5| Step: 10
Training loss: 1.7214105129241943
Validation loss: 2.0803216795126596

Epoch: 5| Step: 11
Training loss: 1.4872461557388306
Validation loss: 2.0755320886770883

Epoch: 17| Step: 0
Training loss: 1.7366440296173096
Validation loss: 2.017723177870115

Epoch: 5| Step: 1
Training loss: 1.4226195812225342
Validation loss: 2.075444519519806

Epoch: 5| Step: 2
Training loss: 2.1886026859283447
Validation loss: 2.0977241595586142

Epoch: 5| Step: 3
Training loss: 2.2903637886047363
Validation loss: 2.0426856726408005

Epoch: 5| Step: 4
Training loss: 1.7310272455215454
Validation loss: 2.0319198022286096

Epoch: 5| Step: 5
Training loss: 2.414069890975952
Validation loss: 2.025747741262118

Epoch: 5| Step: 6
Training loss: 2.4616048336029053
Validation loss: 2.061610917250315

Epoch: 5| Step: 7
Training loss: 2.2006759643554688
Validation loss: 2.033819998304049

Epoch: 5| Step: 8
Training loss: 2.0484187602996826
Validation loss: 2.0684090654055276

Epoch: 5| Step: 9
Training loss: 2.1198065280914307
Validation loss: 2.0541397780179977

Epoch: 5| Step: 10
Training loss: 2.558244466781616
Validation loss: 2.0700623194376626

Epoch: 5| Step: 11
Training loss: 3.377908945083618
Validation loss: 2.0898260374863944

Epoch: 18| Step: 0
Training loss: 2.777372360229492
Validation loss: 2.1014240036408105

Epoch: 5| Step: 1
Training loss: 2.402039051055908
Validation loss: 2.0800219625234604

Epoch: 5| Step: 2
Training loss: 2.145993232727051
Validation loss: 2.1302205870548883

Epoch: 5| Step: 3
Training loss: 1.8997875452041626
Validation loss: 2.1070823123057685

Epoch: 5| Step: 4
Training loss: 1.7841205596923828
Validation loss: 2.067559709151586

Epoch: 5| Step: 5
Training loss: 1.6470601558685303
Validation loss: 2.149715334177017

Epoch: 5| Step: 6
Training loss: 1.9105825424194336
Validation loss: 2.1105040907859802

Epoch: 5| Step: 7
Training loss: 2.458296298980713
Validation loss: 2.1305900712807975

Epoch: 5| Step: 8
Training loss: 2.780963182449341
Validation loss: 2.134008824825287

Epoch: 5| Step: 9
Training loss: 1.7602485418319702
Validation loss: 2.1273820300896964

Epoch: 5| Step: 10
Training loss: 1.9364036321640015
Validation loss: 2.1310918231805167

Epoch: 5| Step: 11
Training loss: 1.7483320236206055
Validation loss: 2.1286663512388864

Epoch: 19| Step: 0
Training loss: 1.8177783489227295
Validation loss: 2.0446893771489463

Epoch: 5| Step: 1
Training loss: 2.159365177154541
Validation loss: 2.0728523482879004

Epoch: 5| Step: 2
Training loss: 1.734985113143921
Validation loss: 2.064279625813166

Epoch: 5| Step: 3
Training loss: 2.0079128742218018
Validation loss: 2.069903905193011

Epoch: 5| Step: 4
Training loss: 2.2999300956726074
Validation loss: 2.0616214275360107

Epoch: 5| Step: 5
Training loss: 1.9482837915420532
Validation loss: 2.116284877061844

Epoch: 5| Step: 6
Training loss: 1.8773552179336548
Validation loss: 2.040229062239329

Epoch: 5| Step: 7
Training loss: 2.440861225128174
Validation loss: 2.0129603197177253

Epoch: 5| Step: 8
Training loss: 2.1639485359191895
Validation loss: 2.0402993708848953

Epoch: 5| Step: 9
Training loss: 2.5183827877044678
Validation loss: 2.036856383085251

Epoch: 5| Step: 10
Training loss: 2.3172125816345215
Validation loss: 2.0079463521639505

Epoch: 5| Step: 11
Training loss: 1.025797724723816
Validation loss: 2.0625583827495575

Epoch: 20| Step: 0
Training loss: 1.9455686807632446
Validation loss: 2.0038846880197525

Epoch: 5| Step: 1
Training loss: 1.5915275812149048
Validation loss: 2.0150897751251855

Epoch: 5| Step: 2
Training loss: 2.1752452850341797
Validation loss: 2.0268001159032187

Epoch: 5| Step: 3
Training loss: 2.035970687866211
Validation loss: 2.060431887706121

Epoch: 5| Step: 4
Training loss: 1.6795825958251953
Validation loss: 2.060277650753657

Epoch: 5| Step: 5
Training loss: 2.553257465362549
Validation loss: 1.9706119745969772

Epoch: 5| Step: 6
Training loss: 2.570692539215088
Validation loss: 2.0444306631882987

Epoch: 5| Step: 7
Training loss: 1.7599948644638062
Validation loss: 2.0511403580506644

Epoch: 5| Step: 8
Training loss: 1.965736746788025
Validation loss: 2.0840616126855216

Epoch: 5| Step: 9
Training loss: 2.537017345428467
Validation loss: 2.049518326918284

Epoch: 5| Step: 10
Training loss: 2.5660603046417236
Validation loss: 2.0698619981606803

Epoch: 5| Step: 11
Training loss: 1.3995451927185059
Validation loss: 2.072007571657499

Epoch: 21| Step: 0
Training loss: 1.8722772598266602
Validation loss: 2.072870656847954

Epoch: 5| Step: 1
Training loss: 2.058882236480713
Validation loss: 2.0706267803907394

Epoch: 5| Step: 2
Training loss: 2.3856186866760254
Validation loss: 2.0414459009965262

Epoch: 5| Step: 3
Training loss: 2.41127347946167
Validation loss: 2.042278215289116

Epoch: 5| Step: 4
Training loss: 2.3923280239105225
Validation loss: 2.0985672374566398

Epoch: 5| Step: 5
Training loss: 2.162672519683838
Validation loss: 2.0436335653066635

Epoch: 5| Step: 6
Training loss: 2.7119994163513184
Validation loss: 2.041661615173022

Epoch: 5| Step: 7
Training loss: 1.6700403690338135
Validation loss: 2.084032952785492

Epoch: 5| Step: 8
Training loss: 1.5157371759414673
Validation loss: 2.065115918715795

Epoch: 5| Step: 9
Training loss: 1.6750571727752686
Validation loss: 2.077869971593221

Epoch: 5| Step: 10
Training loss: 2.2758307456970215
Validation loss: 2.0414579709370932

Epoch: 5| Step: 11
Training loss: 1.260353922843933
Validation loss: 2.0770604610443115

Epoch: 22| Step: 0
Training loss: 2.442627191543579
Validation loss: 2.033582409222921

Epoch: 5| Step: 1
Training loss: 2.0589184761047363
Validation loss: 2.0706251710653305

Epoch: 5| Step: 2
Training loss: 2.6233742237091064
Validation loss: 2.049568777283033

Epoch: 5| Step: 3
Training loss: 1.9338165521621704
Validation loss: 2.074250191450119

Epoch: 5| Step: 4
Training loss: 2.4021522998809814
Validation loss: 2.000750501950582

Epoch: 5| Step: 5
Training loss: 1.4770445823669434
Validation loss: 2.007668604453405

Epoch: 5| Step: 6
Training loss: 2.470841884613037
Validation loss: 2.071237176656723

Epoch: 5| Step: 7
Training loss: 2.0275580883026123
Validation loss: 2.0591440002123513

Epoch: 5| Step: 8
Training loss: 1.6697391271591187
Validation loss: 2.0296825418869653

Epoch: 5| Step: 9
Training loss: 1.7950124740600586
Validation loss: 2.057706410686175

Epoch: 5| Step: 10
Training loss: 2.1888630390167236
Validation loss: 2.0163336396217346

Epoch: 5| Step: 11
Training loss: 0.7120646238327026
Validation loss: 2.0628239462773004

Epoch: 23| Step: 0
Training loss: 2.1496801376342773
Validation loss: 2.0590669910113015

Epoch: 5| Step: 1
Training loss: 1.7104511260986328
Validation loss: 1.9998897810777028

Epoch: 5| Step: 2
Training loss: 1.9114288091659546
Validation loss: 2.1044979294141135

Epoch: 5| Step: 3
Training loss: 1.7909997701644897
Validation loss: 2.0318919916947684

Epoch: 5| Step: 4
Training loss: 2.1428933143615723
Validation loss: 2.067017897963524

Epoch: 5| Step: 5
Training loss: 1.9494717121124268
Validation loss: 2.059661423166593

Epoch: 5| Step: 6
Training loss: 1.5140880346298218
Validation loss: 2.023676003019015

Epoch: 5| Step: 7
Training loss: 2.683788776397705
Validation loss: 2.082409684856733

Epoch: 5| Step: 8
Training loss: 2.5632472038269043
Validation loss: 2.0277289003133774

Epoch: 5| Step: 9
Training loss: 2.3003125190734863
Validation loss: 2.02941786746184

Epoch: 5| Step: 10
Training loss: 2.164881706237793
Validation loss: 2.029785712560018

Epoch: 5| Step: 11
Training loss: 3.264770746231079
Validation loss: 1.9990009516477585

Epoch: 24| Step: 0
Training loss: 2.198483943939209
Validation loss: 2.0361113995313644

Epoch: 5| Step: 1
Training loss: 1.801430106163025
Validation loss: 2.0055520087480545

Epoch: 5| Step: 2
Training loss: 1.8850189447402954
Validation loss: 2.0184226036071777

Epoch: 5| Step: 3
Training loss: 2.39844012260437
Validation loss: 2.062366023659706

Epoch: 5| Step: 4
Training loss: 1.7904208898544312
Validation loss: 2.0404717375834784

Epoch: 5| Step: 5
Training loss: 2.8876452445983887
Validation loss: 1.98845570286115

Epoch: 5| Step: 6
Training loss: 2.3516149520874023
Validation loss: 2.063835466901461

Epoch: 5| Step: 7
Training loss: 2.09387469291687
Validation loss: 2.050416057308515

Epoch: 5| Step: 8
Training loss: 2.5027072429656982
Validation loss: 1.9998845756053925

Epoch: 5| Step: 9
Training loss: 1.477536916732788
Validation loss: 2.016670117775599

Epoch: 5| Step: 10
Training loss: 1.6159127950668335
Validation loss: 2.0405654261509576

Epoch: 5| Step: 11
Training loss: 2.3186233043670654
Validation loss: 2.0634456823269525

Epoch: 25| Step: 0
Training loss: 2.7643470764160156
Validation loss: 2.047606105605761

Epoch: 5| Step: 1
Training loss: 1.9419119358062744
Validation loss: 2.024401699503263

Epoch: 5| Step: 2
Training loss: 2.2993111610412598
Validation loss: 2.0141539623339972

Epoch: 5| Step: 3
Training loss: 1.802088975906372
Validation loss: 2.045980537931124

Epoch: 5| Step: 4
Training loss: 1.6701644659042358
Validation loss: 2.0221415062745414

Epoch: 5| Step: 5
Training loss: 1.9900951385498047
Validation loss: 2.035456041495005

Epoch: 5| Step: 6
Training loss: 2.3481833934783936
Validation loss: 2.0250361214081445

Epoch: 5| Step: 7
Training loss: 1.5638234615325928
Validation loss: 2.0446793834368386

Epoch: 5| Step: 8
Training loss: 2.3876824378967285
Validation loss: 2.0761909633874893

Epoch: 5| Step: 9
Training loss: 2.4378764629364014
Validation loss: 2.065608854095141

Epoch: 5| Step: 10
Training loss: 1.8557498455047607
Validation loss: 2.0583272526661553

Epoch: 5| Step: 11
Training loss: 2.216503143310547
Validation loss: 2.0946108202139535

Epoch: 26| Step: 0
Training loss: 2.6146998405456543
Validation loss: 2.1032359500726066

Epoch: 5| Step: 1
Training loss: 1.992288589477539
Validation loss: 2.0236896127462387

Epoch: 5| Step: 2
Training loss: 2.179211139678955
Validation loss: 2.03023199737072

Epoch: 5| Step: 3
Training loss: 1.4598616361618042
Validation loss: 2.0650437772274017

Epoch: 5| Step: 4
Training loss: 1.9430843591690063
Validation loss: 2.018839423855146

Epoch: 5| Step: 5
Training loss: 2.288971424102783
Validation loss: 2.013766810297966

Epoch: 5| Step: 6
Training loss: 2.3729007244110107
Validation loss: 2.0293190479278564

Epoch: 5| Step: 7
Training loss: 1.9328527450561523
Validation loss: 1.9901829560597737

Epoch: 5| Step: 8
Training loss: 1.574306607246399
Validation loss: 2.105126698811849

Epoch: 5| Step: 9
Training loss: 2.009242534637451
Validation loss: 2.0127867509921393

Epoch: 5| Step: 10
Training loss: 2.3320400714874268
Validation loss: 2.028474216659864

Epoch: 5| Step: 11
Training loss: 1.8346960544586182
Validation loss: 2.07194122672081

Epoch: 27| Step: 0
Training loss: 2.800022840499878
Validation loss: 2.0169770369927087

Epoch: 5| Step: 1
Training loss: 1.9702399969100952
Validation loss: 2.066329593459765

Epoch: 5| Step: 2
Training loss: 2.089332103729248
Validation loss: 2.0229444404443107

Epoch: 5| Step: 3
Training loss: 1.9550704956054688
Validation loss: 2.0430503338575363

Epoch: 5| Step: 4
Training loss: 1.750567078590393
Validation loss: 2.0695869475603104

Epoch: 5| Step: 5
Training loss: 2.514427423477173
Validation loss: 2.011193166176478

Epoch: 5| Step: 6
Training loss: 1.9072459936141968
Validation loss: 2.0592125356197357

Epoch: 5| Step: 7
Training loss: 1.6385749578475952
Validation loss: 2.0425869474808374

Epoch: 5| Step: 8
Training loss: 2.119502544403076
Validation loss: 2.0486321449279785

Epoch: 5| Step: 9
Training loss: 2.0799152851104736
Validation loss: 2.0704778681198754

Epoch: 5| Step: 10
Training loss: 1.7393258810043335
Validation loss: 2.0207336942354837

Epoch: 5| Step: 11
Training loss: 2.5159051418304443
Validation loss: 1.978681872288386

Epoch: 28| Step: 0
Training loss: 2.0012142658233643
Validation loss: 2.0239689151446023

Epoch: 5| Step: 1
Training loss: 2.000305652618408
Validation loss: 2.023997033635775

Epoch: 5| Step: 2
Training loss: 2.6715235710144043
Validation loss: 2.0382351030906043

Epoch: 5| Step: 3
Training loss: 2.0101356506347656
Validation loss: 2.0876437524954476

Epoch: 5| Step: 4
Training loss: 2.214458465576172
Validation loss: 2.056625852982203

Epoch: 5| Step: 5
Training loss: 1.869749665260315
Validation loss: 2.0441005676984787

Epoch: 5| Step: 6
Training loss: 2.0288374423980713
Validation loss: 2.067375977834066

Epoch: 5| Step: 7
Training loss: 2.2623822689056396
Validation loss: 2.083541681369146

Epoch: 5| Step: 8
Training loss: 1.8336169719696045
Validation loss: 2.0465046813090644

Epoch: 5| Step: 9
Training loss: 2.218925952911377
Validation loss: 2.0250201374292374

Epoch: 5| Step: 10
Training loss: 1.6843845844268799
Validation loss: 1.9956415990988414

Epoch: 5| Step: 11
Training loss: 1.5649232864379883
Validation loss: 2.033791104952494

Epoch: 29| Step: 0
Training loss: 2.5294718742370605
Validation loss: 2.0228110750516257

Epoch: 5| Step: 1
Training loss: 2.0358641147613525
Validation loss: 2.0849073082208633

Epoch: 5| Step: 2
Training loss: 2.4885902404785156
Validation loss: 2.0811243057250977

Epoch: 5| Step: 3
Training loss: 2.199106454849243
Validation loss: 1.9939510573943455

Epoch: 5| Step: 4
Training loss: 1.4369617700576782
Validation loss: 2.0459794203440347

Epoch: 5| Step: 5
Training loss: 2.215580701828003
Validation loss: 2.012956812977791

Epoch: 5| Step: 6
Training loss: 1.5175777673721313
Validation loss: 2.0257777770360312

Epoch: 5| Step: 7
Training loss: 2.3337597846984863
Validation loss: 2.0492350310087204

Epoch: 5| Step: 8
Training loss: 2.3602118492126465
Validation loss: 2.064460630218188

Epoch: 5| Step: 9
Training loss: 1.8812463283538818
Validation loss: 2.0776272217432656

Epoch: 5| Step: 10
Training loss: 1.74978768825531
Validation loss: 2.0889321068922677

Epoch: 5| Step: 11
Training loss: 1.376812219619751
Validation loss: 2.0959628522396088

Epoch: 30| Step: 0
Training loss: 2.5087480545043945
Validation loss: 2.0613670547803244

Epoch: 5| Step: 1
Training loss: 2.3794281482696533
Validation loss: 2.0526363054911294

Epoch: 5| Step: 2
Training loss: 2.334089994430542
Validation loss: 2.011302962899208

Epoch: 5| Step: 3
Training loss: 1.942845106124878
Validation loss: 2.020575006802877

Epoch: 5| Step: 4
Training loss: 1.9377238750457764
Validation loss: 2.039487138390541

Epoch: 5| Step: 5
Training loss: 2.3465073108673096
Validation loss: 2.0786958038806915

Epoch: 5| Step: 6
Training loss: 1.782386064529419
Validation loss: 2.002678394317627

Epoch: 5| Step: 7
Training loss: 1.5096327066421509
Validation loss: 2.0483893950780234

Epoch: 5| Step: 8
Training loss: 2.269108295440674
Validation loss: 2.007809892296791

Epoch: 5| Step: 9
Training loss: 1.7980897426605225
Validation loss: 2.054327502846718

Epoch: 5| Step: 10
Training loss: 1.6099491119384766
Validation loss: 2.0654086470603943

Epoch: 5| Step: 11
Training loss: 1.6888583898544312
Validation loss: 2.009717350204786

Epoch: 31| Step: 0
Training loss: 2.09883451461792
Validation loss: 2.053756127754847

Epoch: 5| Step: 1
Training loss: 1.9124233722686768
Validation loss: 2.061740274230639

Epoch: 5| Step: 2
Training loss: 2.21960186958313
Validation loss: 2.0400026937325797

Epoch: 5| Step: 3
Training loss: 1.582137107849121
Validation loss: 2.0796361168225608

Epoch: 5| Step: 4
Training loss: 1.8776588439941406
Validation loss: 2.0143760492404303

Epoch: 5| Step: 5
Training loss: 2.1969776153564453
Validation loss: 2.0318019737799964

Epoch: 5| Step: 6
Training loss: 1.6783409118652344
Validation loss: 2.0875220745801926

Epoch: 5| Step: 7
Training loss: 2.4237732887268066
Validation loss: 2.169334337115288

Epoch: 5| Step: 8
Training loss: 2.4482421875
Validation loss: 2.070983111858368

Epoch: 5| Step: 9
Training loss: 2.012627363204956
Validation loss: 2.0881008406480155

Epoch: 5| Step: 10
Training loss: 1.9356763362884521
Validation loss: 2.082905431588491

Epoch: 5| Step: 11
Training loss: 2.5342111587524414
Validation loss: 2.085138594110807

Epoch: 32| Step: 0
Training loss: 2.347240686416626
Validation loss: 2.0512567162513733

Epoch: 5| Step: 1
Training loss: 1.8785114288330078
Validation loss: 2.0625812709331512

Epoch: 5| Step: 2
Training loss: 1.8156654834747314
Validation loss: 2.037132680416107

Epoch: 5| Step: 3
Training loss: 1.9063705205917358
Validation loss: 2.0315481275320053

Epoch: 5| Step: 4
Training loss: 2.2138311862945557
Validation loss: 2.0746020078659058

Epoch: 5| Step: 5
Training loss: 2.2584781646728516
Validation loss: 2.0675483594338098

Epoch: 5| Step: 6
Training loss: 1.8612346649169922
Validation loss: 2.0135239511728287

Epoch: 5| Step: 7
Training loss: 1.8088372945785522
Validation loss: 2.046320309241613

Epoch: 5| Step: 8
Training loss: 2.0322422981262207
Validation loss: 2.053139160076777

Epoch: 5| Step: 9
Training loss: 2.315286636352539
Validation loss: 2.002880319952965

Epoch: 5| Step: 10
Training loss: 1.8068649768829346
Validation loss: 2.0187282959620156

Epoch: 5| Step: 11
Training loss: 2.110227584838867
Validation loss: 2.0597912122805915

Epoch: 33| Step: 0
Training loss: 2.2451934814453125
Validation loss: 2.0552935898303986

Epoch: 5| Step: 1
Training loss: 2.009587287902832
Validation loss: 2.0947813043991723

Epoch: 5| Step: 2
Training loss: 2.752316474914551
Validation loss: 2.067671224474907

Epoch: 5| Step: 3
Training loss: 1.5284545421600342
Validation loss: 2.112502927581469

Epoch: 5| Step: 4
Training loss: 1.8634204864501953
Validation loss: 2.1023792723814645

Epoch: 5| Step: 5
Training loss: 2.454845428466797
Validation loss: 2.1039625704288483

Epoch: 5| Step: 6
Training loss: 1.5225307941436768
Validation loss: 2.1122665107250214

Epoch: 5| Step: 7
Training loss: 1.8092081546783447
Validation loss: 2.1184858977794647

Epoch: 5| Step: 8
Training loss: 2.4148354530334473
Validation loss: 2.067915399869283

Epoch: 5| Step: 9
Training loss: 1.8046581745147705
Validation loss: 2.083864688873291

Epoch: 5| Step: 10
Training loss: 2.1347265243530273
Validation loss: 2.1231686025857925

Epoch: 5| Step: 11
Training loss: 2.6306939125061035
Validation loss: 2.0600278973579407

Epoch: 34| Step: 0
Training loss: 1.9033282995224
Validation loss: 2.040720656514168

Epoch: 5| Step: 1
Training loss: 2.7180395126342773
Validation loss: 2.0453858077526093

Epoch: 5| Step: 2
Training loss: 1.933172583580017
Validation loss: 2.0208810120821

Epoch: 5| Step: 3
Training loss: 1.9786258935928345
Validation loss: 2.0740944147109985

Epoch: 5| Step: 4
Training loss: 1.7738873958587646
Validation loss: 2.0167591174443564

Epoch: 5| Step: 5
Training loss: 2.489000082015991
Validation loss: 2.021534413099289

Epoch: 5| Step: 6
Training loss: 1.393867015838623
Validation loss: 2.0242332816123962

Epoch: 5| Step: 7
Training loss: 1.8999042510986328
Validation loss: 2.046131799618403

Epoch: 5| Step: 8
Training loss: 1.979612112045288
Validation loss: 2.0612039963404336

Epoch: 5| Step: 9
Training loss: 1.7293905019760132
Validation loss: 2.0513998915751777

Epoch: 5| Step: 10
Training loss: 2.409198760986328
Validation loss: 2.033062626918157

Epoch: 5| Step: 11
Training loss: 2.034834623336792
Validation loss: 2.0652731408675513

Epoch: 35| Step: 0
Training loss: 1.7224069833755493
Validation loss: 2.031991442044576

Epoch: 5| Step: 1
Training loss: 2.1062862873077393
Validation loss: 2.062304457028707

Epoch: 5| Step: 2
Training loss: 1.3814427852630615
Validation loss: 2.0655796974897385

Epoch: 5| Step: 3
Training loss: 2.8285317420959473
Validation loss: 2.182129164536794

Epoch: 5| Step: 4
Training loss: 1.9628722667694092
Validation loss: 2.157895306746165

Epoch: 5| Step: 5
Training loss: 1.419801950454712
Validation loss: 2.1624941329161325

Epoch: 5| Step: 6
Training loss: 1.714421272277832
Validation loss: 2.144766474763552

Epoch: 5| Step: 7
Training loss: 3.1187922954559326
Validation loss: 2.117402881383896

Epoch: 5| Step: 8
Training loss: 2.147571563720703
Validation loss: 2.1063080926736197

Epoch: 5| Step: 9
Training loss: 1.988115906715393
Validation loss: 2.0895531872908273

Epoch: 5| Step: 10
Training loss: 2.124415397644043
Validation loss: 2.0729609231154122

Epoch: 5| Step: 11
Training loss: 2.655202865600586
Validation loss: 2.0258850306272507

Epoch: 36| Step: 0
Training loss: 1.803734540939331
Validation loss: 2.081087584296862

Epoch: 5| Step: 1
Training loss: 2.3123116493225098
Validation loss: 2.124468515316645

Epoch: 5| Step: 2
Training loss: 2.4532530307769775
Validation loss: 2.037087470293045

Epoch: 5| Step: 3
Training loss: 1.7299697399139404
Validation loss: 2.008351961771647

Epoch: 5| Step: 4
Training loss: 2.134077787399292
Validation loss: 2.082408825556437

Epoch: 5| Step: 5
Training loss: 1.7944152355194092
Validation loss: 2.0474800169467926

Epoch: 5| Step: 6
Training loss: 2.0571064949035645
Validation loss: 2.091496785481771

Epoch: 5| Step: 7
Training loss: 1.7171729803085327
Validation loss: 2.0521820336580276

Epoch: 5| Step: 8
Training loss: 2.472865104675293
Validation loss: 2.0125114222367606

Epoch: 5| Step: 9
Training loss: 1.7775256633758545
Validation loss: 2.0085909962654114

Epoch: 5| Step: 10
Training loss: 1.4996731281280518
Validation loss: 2.032934164007505

Epoch: 5| Step: 11
Training loss: 2.3096790313720703
Validation loss: 2.0419626335302987

Epoch: 37| Step: 0
Training loss: 2.327829599380493
Validation loss: 2.0746128857135773

Epoch: 5| Step: 1
Training loss: 2.2527713775634766
Validation loss: 2.0587997436523438

Epoch: 5| Step: 2
Training loss: 1.791327714920044
Validation loss: 2.0540495117505393

Epoch: 5| Step: 3
Training loss: 1.3624324798583984
Validation loss: 2.1529214282830558

Epoch: 5| Step: 4
Training loss: 1.7986987829208374
Validation loss: 2.1716611087322235

Epoch: 5| Step: 5
Training loss: 2.059025287628174
Validation loss: 2.09344290693601

Epoch: 5| Step: 6
Training loss: 1.7508790493011475
Validation loss: 2.127051522334417

Epoch: 5| Step: 7
Training loss: 1.5774223804473877
Validation loss: 2.1818699141343436

Epoch: 5| Step: 8
Training loss: 2.5671441555023193
Validation loss: 2.138045315941175

Epoch: 5| Step: 9
Training loss: 2.293518304824829
Validation loss: 2.112165262301763

Epoch: 5| Step: 10
Training loss: 2.291053295135498
Validation loss: 2.1414315899213157

Epoch: 5| Step: 11
Training loss: 2.882901191711426
Validation loss: 2.105252375205358

Epoch: 38| Step: 0
Training loss: 2.0618484020233154
Validation loss: 2.0822319289048514

Epoch: 5| Step: 1
Training loss: 1.61434805393219
Validation loss: 2.0625783999760947

Epoch: 5| Step: 2
Training loss: 1.5180857181549072
Validation loss: 2.0901820162932077

Epoch: 5| Step: 3
Training loss: 2.1841671466827393
Validation loss: 2.0242401510477066

Epoch: 5| Step: 4
Training loss: 1.8998537063598633
Validation loss: 2.012137954433759

Epoch: 5| Step: 5
Training loss: 2.1077871322631836
Validation loss: 1.9845970571041107

Epoch: 5| Step: 6
Training loss: 2.289583683013916
Validation loss: 2.0076546321312585

Epoch: 5| Step: 7
Training loss: 2.4756059646606445
Validation loss: 2.1125776718060174

Epoch: 5| Step: 8
Training loss: 1.8726108074188232
Validation loss: 2.015453706185023

Epoch: 5| Step: 9
Training loss: 1.6131223440170288
Validation loss: 1.9923446029424667

Epoch: 5| Step: 10
Training loss: 2.1437554359436035
Validation loss: 2.070021783312162

Epoch: 5| Step: 11
Training loss: 0.7533625960350037
Validation loss: 2.063407684365908

Epoch: 39| Step: 0
Training loss: 2.1599059104919434
Validation loss: 2.049816648165385

Epoch: 5| Step: 1
Training loss: 2.108253002166748
Validation loss: 2.021771793564161

Epoch: 5| Step: 2
Training loss: 1.8388259410858154
Validation loss: 2.077329476674398

Epoch: 5| Step: 3
Training loss: 2.2867114543914795
Validation loss: 2.0341003984212875

Epoch: 5| Step: 4
Training loss: 2.1034576892852783
Validation loss: 2.1157702704270682

Epoch: 5| Step: 5
Training loss: 1.686179757118225
Validation loss: 2.1797095984220505

Epoch: 5| Step: 6
Training loss: 1.8625236749649048
Validation loss: 2.0668976505597434

Epoch: 5| Step: 7
Training loss: 1.9491188526153564
Validation loss: 2.0611947923898697

Epoch: 5| Step: 8
Training loss: 2.1959495544433594
Validation loss: 2.0595371077458062

Epoch: 5| Step: 9
Training loss: 1.7592710256576538
Validation loss: 2.0170143842697144

Epoch: 5| Step: 10
Training loss: 1.780931830406189
Validation loss: 2.0556185642878213

Epoch: 5| Step: 11
Training loss: 2.527757406234741
Validation loss: 2.035930414994558

Epoch: 40| Step: 0
Training loss: 2.2028069496154785
Validation loss: 2.0412322829167047

Epoch: 5| Step: 1
Training loss: 2.226717948913574
Validation loss: 1.993154262502988

Epoch: 5| Step: 2
Training loss: 1.7447140216827393
Validation loss: 2.0474509646495185

Epoch: 5| Step: 3
Training loss: 1.6851770877838135
Validation loss: 2.0564542512098947

Epoch: 5| Step: 4
Training loss: 1.6302160024642944
Validation loss: 2.005509600043297

Epoch: 5| Step: 5
Training loss: 2.0574123859405518
Validation loss: 2.0263654390970864

Epoch: 5| Step: 6
Training loss: 1.157752513885498
Validation loss: 2.0370063384373984

Epoch: 5| Step: 7
Training loss: 2.1298038959503174
Validation loss: 2.039287800590197

Epoch: 5| Step: 8
Training loss: 2.588169813156128
Validation loss: 2.0354782144228616

Epoch: 5| Step: 9
Training loss: 2.1441543102264404
Validation loss: 2.0317384699980416

Epoch: 5| Step: 10
Training loss: 2.3100738525390625
Validation loss: 2.046010305484136

Epoch: 5| Step: 11
Training loss: 2.1341140270233154
Validation loss: 2.060802325606346

Epoch: 41| Step: 0
Training loss: 1.537809133529663
Validation loss: 2.046003391345342

Epoch: 5| Step: 1
Training loss: 1.4092350006103516
Validation loss: 2.065564518173536

Epoch: 5| Step: 2
Training loss: 2.1649563312530518
Validation loss: 2.0800718615452447

Epoch: 5| Step: 3
Training loss: 2.768141508102417
Validation loss: 1.9986686557531357

Epoch: 5| Step: 4
Training loss: 1.7049366235733032
Validation loss: 2.009695276618004

Epoch: 5| Step: 5
Training loss: 1.984187126159668
Validation loss: 2.028943955898285

Epoch: 5| Step: 6
Training loss: 2.476746082305908
Validation loss: 2.060047830144564

Epoch: 5| Step: 7
Training loss: 1.6841074228286743
Validation loss: 2.0561645875374475

Epoch: 5| Step: 8
Training loss: 1.6573196649551392
Validation loss: 1.9586283415555954

Epoch: 5| Step: 9
Training loss: 2.0636770725250244
Validation loss: 2.0536872943242392

Epoch: 5| Step: 10
Training loss: 2.174410343170166
Validation loss: 2.044742703437805

Epoch: 5| Step: 11
Training loss: 2.6754939556121826
Validation loss: 2.0777467787265778

Epoch: 42| Step: 0
Training loss: 1.7204993963241577
Validation loss: 2.0648545970519385

Epoch: 5| Step: 1
Training loss: 1.6770614385604858
Validation loss: 2.0225092073281608

Epoch: 5| Step: 2
Training loss: 2.189876079559326
Validation loss: 2.030683492620786

Epoch: 5| Step: 3
Training loss: 1.615484595298767
Validation loss: 2.0519773165384927

Epoch: 5| Step: 4
Training loss: 1.976628303527832
Validation loss: 2.071129004160563

Epoch: 5| Step: 5
Training loss: 3.093355894088745
Validation loss: 2.0846977283557258

Epoch: 5| Step: 6
Training loss: 1.4564077854156494
Validation loss: 2.030039062102636

Epoch: 5| Step: 7
Training loss: 1.893510103225708
Validation loss: 2.01415608326594

Epoch: 5| Step: 8
Training loss: 1.948189377784729
Validation loss: 2.054623315731684

Epoch: 5| Step: 9
Training loss: 1.4737956523895264
Validation loss: 2.060896789034208

Epoch: 5| Step: 10
Training loss: 2.4007744789123535
Validation loss: 2.035251642266909

Epoch: 5| Step: 11
Training loss: 3.012423276901245
Validation loss: 2.0609274953603745

Epoch: 43| Step: 0
Training loss: 1.4466478824615479
Validation loss: 2.0877735018730164

Epoch: 5| Step: 1
Training loss: 2.5408096313476562
Validation loss: 2.058765480915705

Epoch: 5| Step: 2
Training loss: 1.3847172260284424
Validation loss: 2.0995128055413566

Epoch: 5| Step: 3
Training loss: 1.8912302255630493
Validation loss: 2.0523436069488525

Epoch: 5| Step: 4
Training loss: 1.823142647743225
Validation loss: 2.0706970592339835

Epoch: 5| Step: 5
Training loss: 2.3326261043548584
Validation loss: 2.088377758860588

Epoch: 5| Step: 6
Training loss: 1.6651859283447266
Validation loss: 2.068009460965792

Epoch: 5| Step: 7
Training loss: 1.4699852466583252
Validation loss: 2.063233107328415

Epoch: 5| Step: 8
Training loss: 2.4148917198181152
Validation loss: 2.0650457590818405

Epoch: 5| Step: 9
Training loss: 2.0489628314971924
Validation loss: 2.122996598482132

Epoch: 5| Step: 10
Training loss: 2.3833746910095215
Validation loss: 2.0051147441069284

Epoch: 5| Step: 11
Training loss: 2.20094633102417
Validation loss: 2.0922636141379676

Epoch: 44| Step: 0
Training loss: 1.8795734643936157
Validation loss: 2.0831294457117715

Epoch: 5| Step: 1
Training loss: 1.8234459161758423
Validation loss: 2.071564028660456

Epoch: 5| Step: 2
Training loss: 1.600987195968628
Validation loss: 2.0746071338653564

Epoch: 5| Step: 3
Training loss: 1.8595281839370728
Validation loss: 2.0621160368124642

Epoch: 5| Step: 4
Training loss: 1.9482263326644897
Validation loss: 2.074145292242368

Epoch: 5| Step: 5
Training loss: 2.3794567584991455
Validation loss: 2.134976843992869

Epoch: 5| Step: 6
Training loss: 1.6948401927947998
Validation loss: 2.102550978461901

Epoch: 5| Step: 7
Training loss: 2.0969300270080566
Validation loss: 2.0871379574139914

Epoch: 5| Step: 8
Training loss: 2.0475220680236816
Validation loss: 2.0470363895098367

Epoch: 5| Step: 9
Training loss: 1.8025896549224854
Validation loss: 2.078646868467331

Epoch: 5| Step: 10
Training loss: 1.8831027746200562
Validation loss: 2.094003215432167

Epoch: 5| Step: 11
Training loss: 3.4134609699249268
Validation loss: 2.0938282112280526

Epoch: 45| Step: 0
Training loss: 1.75655996799469
Validation loss: 2.054140751560529

Epoch: 5| Step: 1
Training loss: 2.0654892921447754
Validation loss: 2.0556139002243676

Epoch: 5| Step: 2
Training loss: 2.685480833053589
Validation loss: 2.043671319882075

Epoch: 5| Step: 3
Training loss: 1.5550981760025024
Validation loss: 2.077123632033666

Epoch: 5| Step: 4
Training loss: 2.1357951164245605
Validation loss: 2.0579097121953964

Epoch: 5| Step: 5
Training loss: 1.9993728399276733
Validation loss: 1.9983694454034169

Epoch: 5| Step: 6
Training loss: 1.9800151586532593
Validation loss: 2.055800994237264

Epoch: 5| Step: 7
Training loss: 1.670871376991272
Validation loss: 2.020179400841395

Epoch: 5| Step: 8
Training loss: 2.1400651931762695
Validation loss: 2.0337952276070914

Epoch: 5| Step: 9
Training loss: 1.6128110885620117
Validation loss: 2.0641253143548965

Epoch: 5| Step: 10
Training loss: 1.6826339960098267
Validation loss: 2.056422253449758

Epoch: 5| Step: 11
Training loss: 2.1244611740112305
Validation loss: 2.04182660082976

Epoch: 46| Step: 0
Training loss: 2.225552797317505
Validation loss: 2.094984084367752

Epoch: 5| Step: 1
Training loss: 1.7477763891220093
Validation loss: 2.158836434284846

Epoch: 5| Step: 2
Training loss: 2.3668410778045654
Validation loss: 2.1842722495396933

Epoch: 5| Step: 3
Training loss: 1.7945505380630493
Validation loss: 2.1298510680596032

Epoch: 5| Step: 4
Training loss: 1.9148311614990234
Validation loss: 2.1714778741200766

Epoch: 5| Step: 5
Training loss: 2.013913631439209
Validation loss: 2.1359239319960275

Epoch: 5| Step: 6
Training loss: 2.107161283493042
Validation loss: 2.172007441520691

Epoch: 5| Step: 7
Training loss: 1.9897792339324951
Validation loss: 2.083164542913437

Epoch: 5| Step: 8
Training loss: 1.8124927282333374
Validation loss: 2.0705221692721048

Epoch: 5| Step: 9
Training loss: 2.0615031719207764
Validation loss: 2.0567674189805984

Epoch: 5| Step: 10
Training loss: 1.5635380744934082
Validation loss: 2.0401095698277154

Epoch: 5| Step: 11
Training loss: 1.4602265357971191
Validation loss: 2.0734999626874924

Epoch: 47| Step: 0
Training loss: 1.4886682033538818
Validation loss: 2.0372117211421332

Epoch: 5| Step: 1
Training loss: 1.755715012550354
Validation loss: 2.0636162807544074

Epoch: 5| Step: 2
Training loss: 2.0049383640289307
Validation loss: 2.0083294808864594

Epoch: 5| Step: 3
Training loss: 1.82820725440979
Validation loss: 2.000209460655848

Epoch: 5| Step: 4
Training loss: 2.3947882652282715
Validation loss: 1.9975824405749638

Epoch: 5| Step: 5
Training loss: 1.538947343826294
Validation loss: 2.012685646613439

Epoch: 5| Step: 6
Training loss: 2.7670352458953857
Validation loss: 2.024017184972763

Epoch: 5| Step: 7
Training loss: 2.3892123699188232
Validation loss: 2.047351916631063

Epoch: 5| Step: 8
Training loss: 1.8245811462402344
Validation loss: 2.051084488630295

Epoch: 5| Step: 9
Training loss: 1.955626130104065
Validation loss: 2.05903651813666

Epoch: 5| Step: 10
Training loss: 1.2979769706726074
Validation loss: 2.050977940360705

Epoch: 5| Step: 11
Training loss: 1.7458209991455078
Validation loss: 1.9895513753096263

Epoch: 48| Step: 0
Training loss: 2.3593125343322754
Validation loss: 2.067031517624855

Epoch: 5| Step: 1
Training loss: 2.302521228790283
Validation loss: 2.074172392487526

Epoch: 5| Step: 2
Training loss: 2.3726449012756348
Validation loss: 2.060663734873136

Epoch: 5| Step: 3
Training loss: 1.9693777561187744
Validation loss: 2.0091300855080285

Epoch: 5| Step: 4
Training loss: 1.2516504526138306
Validation loss: 2.0553593834241233

Epoch: 5| Step: 5
Training loss: 1.5051448345184326
Validation loss: 2.0838314294815063

Epoch: 5| Step: 6
Training loss: 1.866498589515686
Validation loss: 2.0791133443514505

Epoch: 5| Step: 7
Training loss: 1.689823865890503
Validation loss: 2.0659789194663367

Epoch: 5| Step: 8
Training loss: 1.8190345764160156
Validation loss: 2.0302817821502686

Epoch: 5| Step: 9
Training loss: 1.6447105407714844
Validation loss: 2.0890122850735984

Epoch: 5| Step: 10
Training loss: 2.4008724689483643
Validation loss: 2.110149825612704

Epoch: 5| Step: 11
Training loss: 1.6289323568344116
Validation loss: 2.1175671915213266

Epoch: 49| Step: 0
Training loss: 1.6891486644744873
Validation loss: 1.9961314251025517

Epoch: 5| Step: 1
Training loss: 2.288813829421997
Validation loss: 2.0105783442656198

Epoch: 5| Step: 2
Training loss: 1.9560314416885376
Validation loss: 2.006082832813263

Epoch: 5| Step: 3
Training loss: 1.5446438789367676
Validation loss: 2.0656639486551285

Epoch: 5| Step: 4
Training loss: 1.8744693994522095
Validation loss: 2.0236947387456894

Epoch: 5| Step: 5
Training loss: 2.0098562240600586
Validation loss: 2.058537801106771

Epoch: 5| Step: 6
Training loss: 2.2993316650390625
Validation loss: 2.0693182796239853

Epoch: 5| Step: 7
Training loss: 1.5847139358520508
Validation loss: 2.0127387195825577

Epoch: 5| Step: 8
Training loss: 1.3968403339385986
Validation loss: 2.0802720238765082

Epoch: 5| Step: 9
Training loss: 2.610403060913086
Validation loss: 2.095856562256813

Epoch: 5| Step: 10
Training loss: 1.9837936162948608
Validation loss: 2.1077310939629874

Epoch: 5| Step: 11
Training loss: 2.779155731201172
Validation loss: 2.0858283787965775

Epoch: 50| Step: 0
Training loss: 1.630957007408142
Validation loss: 2.1097525457541146

Epoch: 5| Step: 1
Training loss: 2.2198305130004883
Validation loss: 2.0728325297435126

Epoch: 5| Step: 2
Training loss: 2.1069326400756836
Validation loss: 2.1191542893648148

Epoch: 5| Step: 3
Training loss: 1.645202398300171
Validation loss: 2.0787736823161445

Epoch: 5| Step: 4
Training loss: 2.2285959720611572
Validation loss: 2.0006832083066306

Epoch: 5| Step: 5
Training loss: 2.319762706756592
Validation loss: 2.0427310913801193

Epoch: 5| Step: 6
Training loss: 1.7883341312408447
Validation loss: 2.0914678623278937

Epoch: 5| Step: 7
Training loss: 1.5319846868515015
Validation loss: 2.0343268116315207

Epoch: 5| Step: 8
Training loss: 1.5720702409744263
Validation loss: 1.9649713784456253

Epoch: 5| Step: 9
Training loss: 2.3186984062194824
Validation loss: 1.9799276391665142

Epoch: 5| Step: 10
Training loss: 1.7811763286590576
Validation loss: 2.052391548951467

Epoch: 5| Step: 11
Training loss: 1.4529389142990112
Validation loss: 2.030255079269409

Epoch: 51| Step: 0
Training loss: 1.1006247997283936
Validation loss: 2.0836029648780823

Epoch: 5| Step: 1
Training loss: 2.0231852531433105
Validation loss: 2.1344565649827323

Epoch: 5| Step: 2
Training loss: 1.8605232238769531
Validation loss: 2.1974506080150604

Epoch: 5| Step: 3
Training loss: 2.2200474739074707
Validation loss: 2.1419972479343414

Epoch: 5| Step: 4
Training loss: 1.5354410409927368
Validation loss: 2.268277019262314

Epoch: 5| Step: 5
Training loss: 1.9938596487045288
Validation loss: 2.3528203616539636

Epoch: 5| Step: 6
Training loss: 1.8512824773788452
Validation loss: 2.3185449739297233

Epoch: 5| Step: 7
Training loss: 2.395049571990967
Validation loss: 2.2351157516241074

Epoch: 5| Step: 8
Training loss: 1.6759579181671143
Validation loss: 2.3205813467502594

Epoch: 5| Step: 9
Training loss: 2.2920775413513184
Validation loss: 2.1745636016130447

Epoch: 5| Step: 10
Training loss: 2.6894960403442383
Validation loss: 2.123801901936531

Epoch: 5| Step: 11
Training loss: 2.6820859909057617
Validation loss: 2.064288020133972

Epoch: 52| Step: 0
Training loss: 1.3627465963363647
Validation loss: 2.1310233771800995

Epoch: 5| Step: 1
Training loss: 1.626512885093689
Validation loss: 2.057267740368843

Epoch: 5| Step: 2
Training loss: 1.997850775718689
Validation loss: 2.0980421006679535

Epoch: 5| Step: 3
Training loss: 1.8107576370239258
Validation loss: 2.0324906210104623

Epoch: 5| Step: 4
Training loss: 1.4047528505325317
Validation loss: 2.0157024363676705

Epoch: 5| Step: 5
Training loss: 2.544520854949951
Validation loss: 2.0325865546862283

Epoch: 5| Step: 6
Training loss: 1.8469167947769165
Validation loss: 2.044304539759954

Epoch: 5| Step: 7
Training loss: 2.150322437286377
Validation loss: 1.9983934611082077

Epoch: 5| Step: 8
Training loss: 2.372659921646118
Validation loss: 2.0835859378178916

Epoch: 5| Step: 9
Training loss: 1.9047349691390991
Validation loss: 1.982280472914378

Epoch: 5| Step: 10
Training loss: 2.001866102218628
Validation loss: 2.0395920872688293

Epoch: 5| Step: 11
Training loss: 2.9981391429901123
Validation loss: 2.0183700372775397

Epoch: 53| Step: 0
Training loss: 1.86350417137146
Validation loss: 2.0594967355330787

Epoch: 5| Step: 1
Training loss: 2.3208484649658203
Validation loss: 2.0535004884004593

Epoch: 5| Step: 2
Training loss: 1.532844066619873
Validation loss: 1.9708723078171413

Epoch: 5| Step: 3
Training loss: 1.6919124126434326
Validation loss: 2.0014246702194214

Epoch: 5| Step: 4
Training loss: 2.202442169189453
Validation loss: 2.063803424437841

Epoch: 5| Step: 5
Training loss: 2.2875945568084717
Validation loss: 2.060563256343206

Epoch: 5| Step: 6
Training loss: 1.8705854415893555
Validation loss: 2.0525316099325814

Epoch: 5| Step: 7
Training loss: 1.3391826152801514
Validation loss: 2.0810655852158866

Epoch: 5| Step: 8
Training loss: 1.5691019296646118
Validation loss: 2.0955808758735657

Epoch: 5| Step: 9
Training loss: 2.1140124797821045
Validation loss: 2.124215433994929

Epoch: 5| Step: 10
Training loss: 1.61434805393219
Validation loss: 2.084646145502726

Epoch: 5| Step: 11
Training loss: 1.1995768547058105
Validation loss: 2.0806199808915458

Epoch: 54| Step: 0
Training loss: 1.971062421798706
Validation loss: 2.1111392080783844

Epoch: 5| Step: 1
Training loss: 1.5905450582504272
Validation loss: 2.0731347848971686

Epoch: 5| Step: 2
Training loss: 1.8413927555084229
Validation loss: 2.1081120371818542

Epoch: 5| Step: 3
Training loss: 1.910936951637268
Validation loss: 2.093989575902621

Epoch: 5| Step: 4
Training loss: 2.126277446746826
Validation loss: 2.1402512590090432

Epoch: 5| Step: 5
Training loss: 2.073451042175293
Validation loss: 2.120935390392939

Epoch: 5| Step: 6
Training loss: 1.8085811138153076
Validation loss: 2.1292317708333335

Epoch: 5| Step: 7
Training loss: 1.80342698097229
Validation loss: 2.012650817632675

Epoch: 5| Step: 8
Training loss: 1.4241414070129395
Validation loss: 2.0301098227500916

Epoch: 5| Step: 9
Training loss: 2.200165271759033
Validation loss: 2.0384077628453574

Epoch: 5| Step: 10
Training loss: 1.7329460382461548
Validation loss: 2.0055876870950065

Epoch: 5| Step: 11
Training loss: 1.819665789604187
Validation loss: 2.061795324087143

Epoch: 55| Step: 0
Training loss: 1.8884477615356445
Validation loss: 2.065863400697708

Epoch: 5| Step: 1
Training loss: 2.4087862968444824
Validation loss: 2.049170578519503

Epoch: 5| Step: 2
Training loss: 2.2997095584869385
Validation loss: 2.0527512431144714

Epoch: 5| Step: 3
Training loss: 1.9087941646575928
Validation loss: 1.9873993347088497

Epoch: 5| Step: 4
Training loss: 1.3596690893173218
Validation loss: 2.0202930023272834

Epoch: 5| Step: 5
Training loss: 1.7071468830108643
Validation loss: 2.1288380126158395

Epoch: 5| Step: 6
Training loss: 1.9127585887908936
Validation loss: 2.045605331659317

Epoch: 5| Step: 7
Training loss: 1.8754336833953857
Validation loss: 2.106542115410169

Epoch: 5| Step: 8
Training loss: 1.9398905038833618
Validation loss: 2.125311200817426

Epoch: 5| Step: 9
Training loss: 2.1795742511749268
Validation loss: 2.067042445143064

Epoch: 5| Step: 10
Training loss: 1.3226611614227295
Validation loss: 2.053800255060196

Epoch: 5| Step: 11
Training loss: 2.48563289642334
Validation loss: 2.110092078646024

Epoch: 56| Step: 0
Training loss: 2.3532304763793945
Validation loss: 2.176865021387736

Epoch: 5| Step: 1
Training loss: 2.174424886703491
Validation loss: 2.1163380394379296

Epoch: 5| Step: 2
Training loss: 1.7078869342803955
Validation loss: 2.206625292698542

Epoch: 5| Step: 3
Training loss: 2.3433830738067627
Validation loss: 2.1478098928928375

Epoch: 5| Step: 4
Training loss: 1.9767930507659912
Validation loss: 2.1830988427003226

Epoch: 5| Step: 5
Training loss: 1.6863782405853271
Validation loss: 2.126345237096151

Epoch: 5| Step: 6
Training loss: 1.8902820348739624
Validation loss: 2.1880376686652503

Epoch: 5| Step: 7
Training loss: 1.7936265468597412
Validation loss: 2.1293759644031525

Epoch: 5| Step: 8
Training loss: 2.364532947540283
Validation loss: 2.1089208871126175

Epoch: 5| Step: 9
Training loss: 1.3792731761932373
Validation loss: 2.0869322965542474

Epoch: 5| Step: 10
Training loss: 1.5454227924346924
Validation loss: 2.0747957130273185

Epoch: 5| Step: 11
Training loss: 2.3935320377349854
Validation loss: 2.0695506582657495

Epoch: 57| Step: 0
Training loss: 1.5201759338378906
Validation loss: 2.049991026520729

Epoch: 5| Step: 1
Training loss: 2.2568469047546387
Validation loss: 2.068536932269732

Epoch: 5| Step: 2
Training loss: 1.7064034938812256
Validation loss: 2.033708850542704

Epoch: 5| Step: 3
Training loss: 1.7053091526031494
Validation loss: 2.0700261145830154

Epoch: 5| Step: 4
Training loss: 1.6841843128204346
Validation loss: 1.9803064664204915

Epoch: 5| Step: 5
Training loss: 2.156830072402954
Validation loss: 2.051635200778643

Epoch: 5| Step: 6
Training loss: 2.094156265258789
Validation loss: 2.065651302536329

Epoch: 5| Step: 7
Training loss: 1.8999687433242798
Validation loss: 2.0317619244257608

Epoch: 5| Step: 8
Training loss: 1.194883108139038
Validation loss: 2.086372345685959

Epoch: 5| Step: 9
Training loss: 1.616703987121582
Validation loss: 2.025703564286232

Epoch: 5| Step: 10
Training loss: 2.2885894775390625
Validation loss: 2.1073206961154938

Epoch: 5| Step: 11
Training loss: 3.972951889038086
Validation loss: 2.1202795008818307

Epoch: 58| Step: 0
Training loss: 2.3795478343963623
Validation loss: 2.0911920766035714

Epoch: 5| Step: 1
Training loss: 2.2049717903137207
Validation loss: 2.082495371500651

Epoch: 5| Step: 2
Training loss: 2.624638080596924
Validation loss: 2.109402115146319

Epoch: 5| Step: 3
Training loss: 1.7285772562026978
Validation loss: 2.1060547530651093

Epoch: 5| Step: 4
Training loss: 1.9951339960098267
Validation loss: 2.087136149406433

Epoch: 5| Step: 5
Training loss: 1.9237016439437866
Validation loss: 2.0819253822167716

Epoch: 5| Step: 6
Training loss: 1.826409935951233
Validation loss: 2.1869446436564126

Epoch: 5| Step: 7
Training loss: 1.4711946249008179
Validation loss: 2.094256872932116

Epoch: 5| Step: 8
Training loss: 1.124489188194275
Validation loss: 2.1146690398454666

Epoch: 5| Step: 9
Training loss: 1.5317199230194092
Validation loss: 2.1055025905370712

Epoch: 5| Step: 10
Training loss: 1.7320407629013062
Validation loss: 1.9932233194510143

Epoch: 5| Step: 11
Training loss: 2.114805221557617
Validation loss: 2.0412740111351013

Epoch: 59| Step: 0
Training loss: 1.9095470905303955
Validation loss: 2.058544859290123

Epoch: 5| Step: 1
Training loss: 2.250915288925171
Validation loss: 2.00482369462649

Epoch: 5| Step: 2
Training loss: 2.0340418815612793
Validation loss: 2.068271671732267

Epoch: 5| Step: 3
Training loss: 2.0495376586914062
Validation loss: 2.04516439139843

Epoch: 5| Step: 4
Training loss: 1.7983825206756592
Validation loss: 2.107894549767176

Epoch: 5| Step: 5
Training loss: 2.422023057937622
Validation loss: 2.1758132030566535

Epoch: 5| Step: 6
Training loss: 1.9041115045547485
Validation loss: 2.090064058701197

Epoch: 5| Step: 7
Training loss: 1.529966115951538
Validation loss: 2.0464382022619247

Epoch: 5| Step: 8
Training loss: 1.5667095184326172
Validation loss: 2.068723887205124

Epoch: 5| Step: 9
Training loss: 2.108478546142578
Validation loss: 2.0275174528360367

Epoch: 5| Step: 10
Training loss: 1.902835488319397
Validation loss: 2.0849916338920593

Epoch: 5| Step: 11
Training loss: 2.9372339248657227
Validation loss: 2.100631758570671

Epoch: 60| Step: 0
Training loss: 1.8878939151763916
Validation loss: 2.1402007738749185

Epoch: 5| Step: 1
Training loss: 1.6528161764144897
Validation loss: 2.121864289045334

Epoch: 5| Step: 2
Training loss: 2.211182117462158
Validation loss: 2.1634585112333298

Epoch: 5| Step: 3
Training loss: 2.6485724449157715
Validation loss: 2.1646965642770133

Epoch: 5| Step: 4
Training loss: 2.1557719707489014
Validation loss: 2.197604631384214

Epoch: 5| Step: 5
Training loss: 1.6558291912078857
Validation loss: 2.12011511127154

Epoch: 5| Step: 6
Training loss: 2.022116184234619
Validation loss: 2.0983906189600625

Epoch: 5| Step: 7
Training loss: 1.7398847341537476
Validation loss: 2.0862572342157364

Epoch: 5| Step: 8
Training loss: 1.8658218383789062
Validation loss: 2.0932271828254065

Epoch: 5| Step: 9
Training loss: 1.519862413406372
Validation loss: 2.0804082254568734

Epoch: 5| Step: 10
Training loss: 1.6403602361679077
Validation loss: 2.0384974479675293

Epoch: 5| Step: 11
Training loss: 2.3623738288879395
Validation loss: 2.050861954689026

Epoch: 61| Step: 0
Training loss: 1.1416765451431274
Validation loss: 2.0348024864991507

Epoch: 5| Step: 1
Training loss: 2.0134401321411133
Validation loss: 2.0359728932380676

Epoch: 5| Step: 2
Training loss: 1.8223645687103271
Validation loss: 2.0421473681926727

Epoch: 5| Step: 3
Training loss: 1.278141975402832
Validation loss: 2.0405102421840033

Epoch: 5| Step: 4
Training loss: 1.997026801109314
Validation loss: 2.0205335716406503

Epoch: 5| Step: 5
Training loss: 2.140571117401123
Validation loss: 2.0393649339675903

Epoch: 5| Step: 6
Training loss: 1.9967149496078491
Validation loss: 2.032730221748352

Epoch: 5| Step: 7
Training loss: 1.8021529912948608
Validation loss: 2.026739557584127

Epoch: 5| Step: 8
Training loss: 2.2645022869110107
Validation loss: 2.067125474413236

Epoch: 5| Step: 9
Training loss: 1.8109667301177979
Validation loss: 2.1007393896579742

Epoch: 5| Step: 10
Training loss: 2.1777560710906982
Validation loss: 2.047955428560575

Epoch: 5| Step: 11
Training loss: 1.3191499710083008
Validation loss: 2.092734252413114

Epoch: 62| Step: 0
Training loss: 1.645329475402832
Validation loss: 2.1200557152430215

Epoch: 5| Step: 1
Training loss: 2.374196767807007
Validation loss: 2.090640346209208

Epoch: 5| Step: 2
Training loss: 2.0852973461151123
Validation loss: 2.0665402909119925

Epoch: 5| Step: 3
Training loss: 2.669631242752075
Validation loss: 2.149816612402598

Epoch: 5| Step: 4
Training loss: 1.6487432718276978
Validation loss: 2.0531880259513855

Epoch: 5| Step: 5
Training loss: 1.7686939239501953
Validation loss: 2.0879964381456375

Epoch: 5| Step: 6
Training loss: 1.720665693283081
Validation loss: 2.0556756258010864

Epoch: 5| Step: 7
Training loss: 1.706957221031189
Validation loss: 2.0275328954060874

Epoch: 5| Step: 8
Training loss: 1.293968915939331
Validation loss: 2.063385253151258

Epoch: 5| Step: 9
Training loss: 1.8835322856903076
Validation loss: 2.1238637218872705

Epoch: 5| Step: 10
Training loss: 1.4161584377288818
Validation loss: 2.077657386660576

Epoch: 5| Step: 11
Training loss: 1.2464368343353271
Validation loss: 2.061685939629873

Epoch: 63| Step: 0
Training loss: 2.03650164604187
Validation loss: 2.0767376124858856

Epoch: 5| Step: 1
Training loss: 1.5432398319244385
Validation loss: 2.0871494064728418

Epoch: 5| Step: 2
Training loss: 1.7717483043670654
Validation loss: 2.1623244136571884

Epoch: 5| Step: 3
Training loss: 1.8003473281860352
Validation loss: 2.1001564214626947

Epoch: 5| Step: 4
Training loss: 2.1364619731903076
Validation loss: 2.1553452710310617

Epoch: 5| Step: 5
Training loss: 1.778294324874878
Validation loss: 2.131991515556971

Epoch: 5| Step: 6
Training loss: 1.5442826747894287
Validation loss: 2.181003600358963

Epoch: 5| Step: 7
Training loss: 1.7451308965682983
Validation loss: 2.2142922580242157

Epoch: 5| Step: 8
Training loss: 1.8508720397949219
Validation loss: 2.197164684534073

Epoch: 5| Step: 9
Training loss: 1.8389101028442383
Validation loss: 2.1431903690099716

Epoch: 5| Step: 10
Training loss: 2.2718112468719482
Validation loss: 2.127676804860433

Epoch: 5| Step: 11
Training loss: 1.8768941164016724
Validation loss: 2.0528670152028403

Epoch: 64| Step: 0
Training loss: 1.7726455926895142
Validation loss: 2.091075360774994

Epoch: 5| Step: 1
Training loss: 1.3270008563995361
Validation loss: 2.0928799410661063

Epoch: 5| Step: 2
Training loss: 1.5053379535675049
Validation loss: 2.0937330226103463

Epoch: 5| Step: 3
Training loss: 2.210583209991455
Validation loss: 2.0315693815549216

Epoch: 5| Step: 4
Training loss: 2.1663095951080322
Validation loss: 2.053697223464648

Epoch: 5| Step: 5
Training loss: 1.7919248342514038
Validation loss: 2.0671728601058326

Epoch: 5| Step: 6
Training loss: 1.9229236841201782
Validation loss: 2.10082816084226

Epoch: 5| Step: 7
Training loss: 1.8899751901626587
Validation loss: 2.0067975719769797

Epoch: 5| Step: 8
Training loss: 2.151966094970703
Validation loss: 2.004555349548658

Epoch: 5| Step: 9
Training loss: 2.20451021194458
Validation loss: 2.055409237742424

Epoch: 5| Step: 10
Training loss: 1.5703084468841553
Validation loss: 2.0142082472642264

Epoch: 5| Step: 11
Training loss: 1.2403422594070435
Validation loss: 2.087160731355349

Epoch: 65| Step: 0
Training loss: 1.9999802112579346
Validation loss: 2.1549136340618134

Epoch: 5| Step: 1
Training loss: 1.7039436101913452
Validation loss: 2.095640689134598

Epoch: 5| Step: 2
Training loss: 2.0396742820739746
Validation loss: 2.1577629446983337

Epoch: 5| Step: 3
Training loss: 2.119549036026001
Validation loss: 2.118889644742012

Epoch: 5| Step: 4
Training loss: 1.9823672771453857
Validation loss: 2.1281625628471375

Epoch: 5| Step: 5
Training loss: 2.287309169769287
Validation loss: 2.1442038814226785

Epoch: 5| Step: 6
Training loss: 1.880527138710022
Validation loss: 2.123431220650673

Epoch: 5| Step: 7
Training loss: 1.1064242124557495
Validation loss: 2.23363666733106

Epoch: 5| Step: 8
Training loss: 1.389869213104248
Validation loss: 2.1472824811935425

Epoch: 5| Step: 9
Training loss: 1.7971982955932617
Validation loss: 2.132702191670736

Epoch: 5| Step: 10
Training loss: 1.6448466777801514
Validation loss: 2.0705462793509164

Epoch: 5| Step: 11
Training loss: 1.815405011177063
Validation loss: 2.056574140985807

Epoch: 66| Step: 0
Training loss: 1.708364486694336
Validation loss: 2.0648610641558967

Epoch: 5| Step: 1
Training loss: 2.0376391410827637
Validation loss: 2.099944924314817

Epoch: 5| Step: 2
Training loss: 1.6228101253509521
Validation loss: 2.0747634371121726

Epoch: 5| Step: 3
Training loss: 1.5506311655044556
Validation loss: 2.065825661023458

Epoch: 5| Step: 4
Training loss: 2.789431095123291
Validation loss: 2.027002528309822

Epoch: 5| Step: 5
Training loss: 1.4163026809692383
Validation loss: 2.013998801509539

Epoch: 5| Step: 6
Training loss: 1.840682029724121
Validation loss: 2.0555723955233893

Epoch: 5| Step: 7
Training loss: 2.024503707885742
Validation loss: 2.1091734071572623

Epoch: 5| Step: 8
Training loss: 1.3297460079193115
Validation loss: 2.0357392132282257

Epoch: 5| Step: 9
Training loss: 1.8539669513702393
Validation loss: 2.022578368584315

Epoch: 5| Step: 10
Training loss: 1.8440624475479126
Validation loss: 2.0895759214957557

Epoch: 5| Step: 11
Training loss: 0.9824795722961426
Validation loss: 2.0782209237416587

Epoch: 67| Step: 0
Training loss: 2.4161391258239746
Validation loss: 2.1227954427401223

Epoch: 5| Step: 1
Training loss: 1.2747163772583008
Validation loss: 2.159779737393061

Epoch: 5| Step: 2
Training loss: 2.658606767654419
Validation loss: 2.157382915417353

Epoch: 5| Step: 3
Training loss: 1.8851484060287476
Validation loss: 2.181726634502411

Epoch: 5| Step: 4
Training loss: 1.9337276220321655
Validation loss: 2.189874162276586

Epoch: 5| Step: 5
Training loss: 1.9262676239013672
Validation loss: 2.172965923945109

Epoch: 5| Step: 6
Training loss: 1.7778199911117554
Validation loss: 2.1906543523073196

Epoch: 5| Step: 7
Training loss: 1.6098201274871826
Validation loss: 2.0947454224030175

Epoch: 5| Step: 8
Training loss: 1.4042742252349854
Validation loss: 2.0671027253071466

Epoch: 5| Step: 9
Training loss: 1.6892573833465576
Validation loss: 2.0412300874789557

Epoch: 5| Step: 10
Training loss: 1.9110143184661865
Validation loss: 2.05930465956529

Epoch: 5| Step: 11
Training loss: 2.1362147331237793
Validation loss: 2.1101359774669013

Epoch: 68| Step: 0
Training loss: 1.954608678817749
Validation loss: 1.997323676943779

Epoch: 5| Step: 1
Training loss: 1.2971489429473877
Validation loss: 2.0235125919183097

Epoch: 5| Step: 2
Training loss: 1.9874255657196045
Validation loss: 2.0904903610547385

Epoch: 5| Step: 3
Training loss: 2.423344135284424
Validation loss: 2.0501818358898163

Epoch: 5| Step: 4
Training loss: 1.8077224493026733
Validation loss: 2.0853667855262756

Epoch: 5| Step: 5
Training loss: 1.3171629905700684
Validation loss: 2.0166229705015817

Epoch: 5| Step: 6
Training loss: 1.685398817062378
Validation loss: 2.052107577522596

Epoch: 5| Step: 7
Training loss: 2.495530605316162
Validation loss: 2.078332851330439

Epoch: 5| Step: 8
Training loss: 1.696092963218689
Validation loss: 2.0926544666290283

Epoch: 5| Step: 9
Training loss: 2.024479389190674
Validation loss: 2.069651941458384

Epoch: 5| Step: 10
Training loss: 1.9086503982543945
Validation loss: 2.14605621000131

Epoch: 5| Step: 11
Training loss: 0.2951836585998535
Validation loss: 2.1852755745251975

Epoch: 69| Step: 0
Training loss: 1.628340721130371
Validation loss: 2.177090739210447

Epoch: 5| Step: 1
Training loss: 1.4306024312973022
Validation loss: 2.2030945072571435

Epoch: 5| Step: 2
Training loss: 1.8274568319320679
Validation loss: 2.1241654604673386

Epoch: 5| Step: 3
Training loss: 2.4407341480255127
Validation loss: 2.147900159160296

Epoch: 5| Step: 4
Training loss: 1.8744052648544312
Validation loss: 2.046302452683449

Epoch: 5| Step: 5
Training loss: 2.0150883197784424
Validation loss: 2.0859230011701584

Epoch: 5| Step: 6
Training loss: 2.361642837524414
Validation loss: 2.017189751068751

Epoch: 5| Step: 7
Training loss: 1.573933720588684
Validation loss: 1.9892526020606358

Epoch: 5| Step: 8
Training loss: 1.3152393102645874
Validation loss: 2.028350606560707

Epoch: 5| Step: 9
Training loss: 1.478048324584961
Validation loss: 2.00311978161335

Epoch: 5| Step: 10
Training loss: 1.9637277126312256
Validation loss: 2.068267340461413

Epoch: 5| Step: 11
Training loss: 1.3980859518051147
Validation loss: 2.1037368128697076

Epoch: 70| Step: 0
Training loss: 2.860898494720459
Validation loss: 2.060133914152781

Epoch: 5| Step: 1
Training loss: 1.7803404331207275
Validation loss: 2.0654380470514297

Epoch: 5| Step: 2
Training loss: 1.9144614934921265
Validation loss: 2.090745876232783

Epoch: 5| Step: 3
Training loss: 1.5674679279327393
Validation loss: 2.040268063545227

Epoch: 5| Step: 4
Training loss: 1.6416244506835938
Validation loss: 2.0351254294315972

Epoch: 5| Step: 5
Training loss: 1.8280394077301025
Validation loss: 2.0810898691415787

Epoch: 5| Step: 6
Training loss: 1.5578116178512573
Validation loss: 2.120724911491076

Epoch: 5| Step: 7
Training loss: 1.4573496580123901
Validation loss: 2.13963990410169

Epoch: 5| Step: 8
Training loss: 1.687000036239624
Validation loss: 2.076320841908455

Epoch: 5| Step: 9
Training loss: 1.9424225091934204
Validation loss: 2.08865158756574

Epoch: 5| Step: 10
Training loss: 1.5474251508712769
Validation loss: 2.0671910842259726

Epoch: 5| Step: 11
Training loss: 2.265705108642578
Validation loss: 2.1606343587239585

Epoch: 71| Step: 0
Training loss: 1.5854500532150269
Validation loss: 2.1357183257738748

Epoch: 5| Step: 1
Training loss: 1.3587857484817505
Validation loss: 2.1260616928339005

Epoch: 5| Step: 2
Training loss: 1.5485455989837646
Validation loss: 2.1519850343465805

Epoch: 5| Step: 3
Training loss: 2.058600664138794
Validation loss: 2.064032018184662

Epoch: 5| Step: 4
Training loss: 1.3596631288528442
Validation loss: 2.069904545942942

Epoch: 5| Step: 5
Training loss: 1.4785263538360596
Validation loss: 2.0675975730021796

Epoch: 5| Step: 6
Training loss: 2.269440174102783
Validation loss: 2.1158809512853622

Epoch: 5| Step: 7
Training loss: 1.6937274932861328
Validation loss: 2.057940656940142

Epoch: 5| Step: 8
Training loss: 1.9204457998275757
Validation loss: 2.123555436730385

Epoch: 5| Step: 9
Training loss: 2.2379279136657715
Validation loss: 2.076377580563227

Epoch: 5| Step: 10
Training loss: 2.411445140838623
Validation loss: 2.03542930384477

Epoch: 5| Step: 11
Training loss: 1.2693166732788086
Validation loss: 2.066408688823382

Epoch: 72| Step: 0
Training loss: 1.8805198669433594
Validation loss: 2.1100789308547974

Epoch: 5| Step: 1
Training loss: 1.2055150270462036
Validation loss: 2.0784602661927543

Epoch: 5| Step: 2
Training loss: 2.246354341506958
Validation loss: 2.0686220079660416

Epoch: 5| Step: 3
Training loss: 2.2294692993164062
Validation loss: 2.0778209467728934

Epoch: 5| Step: 4
Training loss: 1.7944271564483643
Validation loss: 2.027962197860082

Epoch: 5| Step: 5
Training loss: 1.7084659337997437
Validation loss: 2.1124353408813477

Epoch: 5| Step: 6
Training loss: 1.8582528829574585
Validation loss: 2.0982214460770288

Epoch: 5| Step: 7
Training loss: 1.865915298461914
Validation loss: 2.08149986465772

Epoch: 5| Step: 8
Training loss: 1.9428459405899048
Validation loss: 2.134781539440155

Epoch: 5| Step: 9
Training loss: 0.9989988207817078
Validation loss: 2.112186203400294

Epoch: 5| Step: 10
Training loss: 1.7648957967758179
Validation loss: 2.045622860391935

Epoch: 5| Step: 11
Training loss: 1.1250038146972656
Validation loss: 2.082399199406306

Epoch: 73| Step: 0
Training loss: 1.6562827825546265
Validation loss: 2.0928582896788916

Epoch: 5| Step: 1
Training loss: 1.6873886585235596
Validation loss: 2.106732353568077

Epoch: 5| Step: 2
Training loss: 1.5746310949325562
Validation loss: 2.094434450070063

Epoch: 5| Step: 3
Training loss: 1.8327791690826416
Validation loss: 2.0726698686679206

Epoch: 5| Step: 4
Training loss: 2.137223482131958
Validation loss: 2.0800087054570517

Epoch: 5| Step: 5
Training loss: 1.5775692462921143
Validation loss: 2.079257915417353

Epoch: 5| Step: 6
Training loss: 2.2001936435699463
Validation loss: 2.066028873125712

Epoch: 5| Step: 7
Training loss: 1.8460884094238281
Validation loss: 2.1113207240899405

Epoch: 5| Step: 8
Training loss: 1.9345744848251343
Validation loss: 2.0679711401462555

Epoch: 5| Step: 9
Training loss: 1.6775963306427002
Validation loss: 2.0830955108006797

Epoch: 5| Step: 10
Training loss: 1.4211251735687256
Validation loss: 2.092044855157534

Epoch: 5| Step: 11
Training loss: 0.8946362733840942
Validation loss: 2.0059346506992974

Epoch: 74| Step: 0
Training loss: 1.6100276708602905
Validation loss: 2.106386661529541

Epoch: 5| Step: 1
Training loss: 2.045830726623535
Validation loss: 2.0930547217528024

Epoch: 5| Step: 2
Training loss: 1.9812103509902954
Validation loss: 2.047318716843923

Epoch: 5| Step: 3
Training loss: 1.4054813385009766
Validation loss: 2.1155991752942405

Epoch: 5| Step: 4
Training loss: 1.7579803466796875
Validation loss: 2.1050499776999154

Epoch: 5| Step: 5
Training loss: 1.4391189813613892
Validation loss: 2.1210463643074036

Epoch: 5| Step: 6
Training loss: 1.6504876613616943
Validation loss: 2.184098536769549

Epoch: 5| Step: 7
Training loss: 1.7901172637939453
Validation loss: 2.1322116951147714

Epoch: 5| Step: 8
Training loss: 1.5294649600982666
Validation loss: 2.0965857009092965

Epoch: 5| Step: 9
Training loss: 2.0189836025238037
Validation loss: 2.1558797657489777

Epoch: 5| Step: 10
Training loss: 2.064596652984619
Validation loss: 2.087772101163864

Epoch: 5| Step: 11
Training loss: 2.926806926727295
Validation loss: 2.0227070997158685

Epoch: 75| Step: 0
Training loss: 2.5439999103546143
Validation loss: 2.0909579495588937

Epoch: 5| Step: 1
Training loss: 2.1932225227355957
Validation loss: 1.9896316925684612

Epoch: 5| Step: 2
Training loss: 2.111194133758545
Validation loss: 2.046491508682569

Epoch: 5| Step: 3
Training loss: 1.811439871788025
Validation loss: 1.9934831609328587

Epoch: 5| Step: 4
Training loss: 1.5667475461959839
Validation loss: 2.040718903144201

Epoch: 5| Step: 5
Training loss: 1.344947099685669
Validation loss: 1.997167393565178

Epoch: 5| Step: 6
Training loss: 2.2545387744903564
Validation loss: 2.047561302781105

Epoch: 5| Step: 7
Training loss: 1.7360141277313232
Validation loss: 2.043069541454315

Epoch: 5| Step: 8
Training loss: 1.615308403968811
Validation loss: 2.043446039160093

Epoch: 5| Step: 9
Training loss: 1.8661645650863647
Validation loss: 2.0118132531642914

Epoch: 5| Step: 10
Training loss: 1.4205882549285889
Validation loss: 2.175979013244311

Epoch: 5| Step: 11
Training loss: 0.9557962417602539
Validation loss: 2.0878186374902725

Epoch: 76| Step: 0
Training loss: 1.7524579763412476
Validation loss: 2.0931646625200906

Epoch: 5| Step: 1
Training loss: 1.5151288509368896
Validation loss: 2.1169915348291397

Epoch: 5| Step: 2
Training loss: 1.803166389465332
Validation loss: 2.205017700791359

Epoch: 5| Step: 3
Training loss: 1.9097791910171509
Validation loss: 2.1782150516907373

Epoch: 5| Step: 4
Training loss: 1.5844002962112427
Validation loss: 2.10269695520401

Epoch: 5| Step: 5
Training loss: 2.430274486541748
Validation loss: 2.154645085334778

Epoch: 5| Step: 6
Training loss: 1.4320099353790283
Validation loss: 2.087634245554606

Epoch: 5| Step: 7
Training loss: 1.143667459487915
Validation loss: 2.0364274432261786

Epoch: 5| Step: 8
Training loss: 2.104773759841919
Validation loss: 2.123859961827596

Epoch: 5| Step: 9
Training loss: 2.181270122528076
Validation loss: 2.052282859881719

Epoch: 5| Step: 10
Training loss: 1.9860689640045166
Validation loss: 2.0538339813550315

Epoch: 5| Step: 11
Training loss: 1.2357704639434814
Validation loss: 2.0606030970811844

Epoch: 77| Step: 0
Training loss: 1.5107002258300781
Validation loss: 2.0844851483901343

Epoch: 5| Step: 1
Training loss: 1.8768819570541382
Validation loss: 2.0722040782372155

Epoch: 5| Step: 2
Training loss: 2.6620373725891113
Validation loss: 2.055840084950129

Epoch: 5| Step: 3
Training loss: 1.4046911001205444
Validation loss: 2.056222215294838

Epoch: 5| Step: 4
Training loss: 1.4597917795181274
Validation loss: 2.074300522605578

Epoch: 5| Step: 5
Training loss: 2.0796141624450684
Validation loss: 2.0502337217330933

Epoch: 5| Step: 6
Training loss: 1.9605642557144165
Validation loss: 2.051826149225235

Epoch: 5| Step: 7
Training loss: 1.7708228826522827
Validation loss: 2.0741723279158273

Epoch: 5| Step: 8
Training loss: 1.2652746438980103
Validation loss: 2.0939563711484275

Epoch: 5| Step: 9
Training loss: 1.434159755706787
Validation loss: 2.0914834340413413

Epoch: 5| Step: 10
Training loss: 1.4532666206359863
Validation loss: 2.200356220205625

Epoch: 5| Step: 11
Training loss: 2.248124122619629
Validation loss: 2.109795098503431

Epoch: 78| Step: 0
Training loss: 1.5467674732208252
Validation loss: 2.105648880203565

Epoch: 5| Step: 1
Training loss: 1.871986746788025
Validation loss: 2.0819170027971268

Epoch: 5| Step: 2
Training loss: 1.8050365447998047
Validation loss: 2.1011649866898856

Epoch: 5| Step: 3
Training loss: 1.593102216720581
Validation loss: 2.005070527394613

Epoch: 5| Step: 4
Training loss: 1.26747465133667
Validation loss: 2.0746036569277444

Epoch: 5| Step: 5
Training loss: 1.753434419631958
Validation loss: 2.015771120786667

Epoch: 5| Step: 6
Training loss: 2.0639193058013916
Validation loss: 2.076088567574819

Epoch: 5| Step: 7
Training loss: 2.4415855407714844
Validation loss: 2.0404881884654364

Epoch: 5| Step: 8
Training loss: 1.2491827011108398
Validation loss: 2.091200669606527

Epoch: 5| Step: 9
Training loss: 2.2308175563812256
Validation loss: 2.0460920333862305

Epoch: 5| Step: 10
Training loss: 1.5069633722305298
Validation loss: 2.06000953912735

Epoch: 5| Step: 11
Training loss: 0.931936502456665
Validation loss: 2.046864544351896

Epoch: 79| Step: 0
Training loss: 1.4756112098693848
Validation loss: 2.1077824582656226

Epoch: 5| Step: 1
Training loss: 1.7629268169403076
Validation loss: 2.0632557024558387

Epoch: 5| Step: 2
Training loss: 2.122905969619751
Validation loss: 2.168886368473371

Epoch: 5| Step: 3
Training loss: 1.5209081172943115
Validation loss: 2.106591612100601

Epoch: 5| Step: 4
Training loss: 1.8907725811004639
Validation loss: 2.0539281368255615

Epoch: 5| Step: 5
Training loss: 2.1213772296905518
Validation loss: 2.054015298684438

Epoch: 5| Step: 6
Training loss: 2.070007801055908
Validation loss: 2.1140235513448715

Epoch: 5| Step: 7
Training loss: 1.7088091373443604
Validation loss: 2.071234514315923

Epoch: 5| Step: 8
Training loss: 1.5747063159942627
Validation loss: 2.0873817801475525

Epoch: 5| Step: 9
Training loss: 1.2884409427642822
Validation loss: 2.0194001346826553

Epoch: 5| Step: 10
Training loss: 1.811478853225708
Validation loss: 2.0231254249811172

Epoch: 5| Step: 11
Training loss: 2.597067356109619
Validation loss: 2.0256146291891732

Epoch: 80| Step: 0
Training loss: 1.3976984024047852
Validation loss: 1.9787220805883408

Epoch: 5| Step: 1
Training loss: 1.3937304019927979
Validation loss: 2.0877629866202674

Epoch: 5| Step: 2
Training loss: 1.7717355489730835
Validation loss: 2.050766388575236

Epoch: 5| Step: 3
Training loss: 1.7236381769180298
Validation loss: 2.059808631738027

Epoch: 5| Step: 4
Training loss: 1.9829959869384766
Validation loss: 2.0587604294220605

Epoch: 5| Step: 5
Training loss: 1.838549256324768
Validation loss: 2.0640765974919

Epoch: 5| Step: 6
Training loss: 1.450381875038147
Validation loss: 2.0449653367201486

Epoch: 5| Step: 7
Training loss: 0.8326454162597656
Validation loss: 2.0389164785544076

Epoch: 5| Step: 8
Training loss: 2.434946298599243
Validation loss: 2.06049183011055

Epoch: 5| Step: 9
Training loss: 1.8299859762191772
Validation loss: 2.0098562836647034

Epoch: 5| Step: 10
Training loss: 2.0130932331085205
Validation loss: 2.015072286128998

Epoch: 5| Step: 11
Training loss: 2.3864738941192627
Validation loss: 2.1126402020454407

Epoch: 81| Step: 0
Training loss: 1.500383973121643
Validation loss: 2.101447264353434

Epoch: 5| Step: 1
Training loss: 2.009445905685425
Validation loss: 2.151255746682485

Epoch: 5| Step: 2
Training loss: 2.0927159786224365
Validation loss: 2.065859461824099

Epoch: 5| Step: 3
Training loss: 1.1318928003311157
Validation loss: 2.161963532368342

Epoch: 5| Step: 4
Training loss: 2.0892558097839355
Validation loss: 2.1653845459222794

Epoch: 5| Step: 5
Training loss: 1.3551925420761108
Validation loss: 2.1154872675736747

Epoch: 5| Step: 6
Training loss: 1.2759439945220947
Validation loss: 2.0455756336450577

Epoch: 5| Step: 7
Training loss: 2.269810914993286
Validation loss: 2.131043309966723

Epoch: 5| Step: 8
Training loss: 1.650552749633789
Validation loss: 2.1090264171361923

Epoch: 5| Step: 9
Training loss: 1.6849896907806396
Validation loss: 2.076327313979467

Epoch: 5| Step: 10
Training loss: 1.8014163970947266
Validation loss: 2.0511733988920846

Epoch: 5| Step: 11
Training loss: 1.0811069011688232
Validation loss: 2.06750096877416

Epoch: 82| Step: 0
Training loss: 1.5607479810714722
Validation loss: 2.0666281282901764

Epoch: 5| Step: 1
Training loss: 1.934130311012268
Validation loss: 2.0696892738342285

Epoch: 5| Step: 2
Training loss: 1.241452932357788
Validation loss: 2.1233627696832023

Epoch: 5| Step: 3
Training loss: 1.9247230291366577
Validation loss: 2.140662908554077

Epoch: 5| Step: 4
Training loss: 1.5258421897888184
Validation loss: 2.180220772822698

Epoch: 5| Step: 5
Training loss: 1.7399429082870483
Validation loss: 2.108662332097689

Epoch: 5| Step: 6
Training loss: 1.5940799713134766
Validation loss: 2.2105102986097336

Epoch: 5| Step: 7
Training loss: 1.9522746801376343
Validation loss: 2.2066370944182077

Epoch: 5| Step: 8
Training loss: 1.7771539688110352
Validation loss: 2.1491230179866156

Epoch: 5| Step: 9
Training loss: 1.359580159187317
Validation loss: 2.158478707075119

Epoch: 5| Step: 10
Training loss: 2.340254306793213
Validation loss: 2.116753856341044

Epoch: 5| Step: 11
Training loss: 1.0724296569824219
Validation loss: 2.0613215814034143

Epoch: 83| Step: 0
Training loss: 2.0940299034118652
Validation loss: 2.0292234222094216

Epoch: 5| Step: 1
Training loss: 1.694364309310913
Validation loss: 2.027108465631803

Epoch: 5| Step: 2
Training loss: 1.9015743732452393
Validation loss: 2.063360944390297

Epoch: 5| Step: 3
Training loss: 1.80769944190979
Validation loss: 2.1297334929307303

Epoch: 5| Step: 4
Training loss: 2.435554027557373
Validation loss: 2.067723090449969

Epoch: 5| Step: 5
Training loss: 2.5145747661590576
Validation loss: 2.0601235181093216

Epoch: 5| Step: 6
Training loss: 1.6339699029922485
Validation loss: 2.05413685242335

Epoch: 5| Step: 7
Training loss: 1.5393049716949463
Validation loss: 1.9957248816887538

Epoch: 5| Step: 8
Training loss: 1.7961620092391968
Validation loss: 2.0151642908652625

Epoch: 5| Step: 9
Training loss: 1.7348533868789673
Validation loss: 2.0244216124216714

Epoch: 5| Step: 10
Training loss: 1.1300907135009766
Validation loss: 2.082937722404798

Epoch: 5| Step: 11
Training loss: 2.1126012802124023
Validation loss: 2.1013303945461907

Epoch: 84| Step: 0
Training loss: 1.5207300186157227
Validation loss: 2.1777162551879883

Epoch: 5| Step: 1
Training loss: 1.5564643144607544
Validation loss: 2.1124932169914246

Epoch: 5| Step: 2
Training loss: 1.667504072189331
Validation loss: 2.169742986559868

Epoch: 5| Step: 3
Training loss: 1.6018333435058594
Validation loss: 2.1580740809440613

Epoch: 5| Step: 4
Training loss: 1.69683837890625
Validation loss: 2.1365468303362527

Epoch: 5| Step: 5
Training loss: 1.4693577289581299
Validation loss: 2.086988920966784

Epoch: 5| Step: 6
Training loss: 1.3547972440719604
Validation loss: 2.118654494484266

Epoch: 5| Step: 7
Training loss: 1.8394737243652344
Validation loss: 2.0641837318738303

Epoch: 5| Step: 8
Training loss: 1.9803091287612915
Validation loss: 2.071303794781367

Epoch: 5| Step: 9
Training loss: 1.4012315273284912
Validation loss: 2.095730905731519

Epoch: 5| Step: 10
Training loss: 2.1512985229492188
Validation loss: 2.042521759867668

Epoch: 5| Step: 11
Training loss: 3.1963980197906494
Validation loss: 2.041134168704351

Epoch: 85| Step: 0
Training loss: 1.492679476737976
Validation loss: 2.005741427342097

Epoch: 5| Step: 1
Training loss: 1.7258388996124268
Validation loss: 2.030486817161242

Epoch: 5| Step: 2
Training loss: 0.9263901710510254
Validation loss: 2.0780455668767295

Epoch: 5| Step: 3
Training loss: 1.7028173208236694
Validation loss: 2.068724905451139

Epoch: 5| Step: 4
Training loss: 2.076974391937256
Validation loss: 2.0368185689051947

Epoch: 5| Step: 5
Training loss: 1.6341367959976196
Validation loss: 2.055159534017245

Epoch: 5| Step: 6
Training loss: 2.142482280731201
Validation loss: 2.1001567393541336

Epoch: 5| Step: 7
Training loss: 2.111966609954834
Validation loss: 2.084181249141693

Epoch: 5| Step: 8
Training loss: 1.1250689029693604
Validation loss: 2.109770655632019

Epoch: 5| Step: 9
Training loss: 1.6048612594604492
Validation loss: 2.0461359272400537

Epoch: 5| Step: 10
Training loss: 1.5443994998931885
Validation loss: 2.0909565339485803

Epoch: 5| Step: 11
Training loss: 2.137659788131714
Validation loss: 2.0860861440499625

Epoch: 86| Step: 0
Training loss: 1.7098544836044312
Validation loss: 2.15884563823541

Epoch: 5| Step: 1
Training loss: 2.27642822265625
Validation loss: 2.1658464819192886

Epoch: 5| Step: 2
Training loss: 1.6944291591644287
Validation loss: 2.1532785346110663

Epoch: 5| Step: 3
Training loss: 0.9627904891967773
Validation loss: 2.124524195988973

Epoch: 5| Step: 4
Training loss: 1.5691068172454834
Validation loss: 2.165547028183937

Epoch: 5| Step: 5
Training loss: 1.6132335662841797
Validation loss: 2.126155133048693

Epoch: 5| Step: 6
Training loss: 2.3418688774108887
Validation loss: 2.0889814645051956

Epoch: 5| Step: 7
Training loss: 1.3573938608169556
Validation loss: 2.076332688331604

Epoch: 5| Step: 8
Training loss: 1.9058984518051147
Validation loss: 2.0487525512774787

Epoch: 5| Step: 9
Training loss: 1.6452404260635376
Validation loss: 2.01963605483373

Epoch: 5| Step: 10
Training loss: 1.4995813369750977
Validation loss: 2.0987696796655655

Epoch: 5| Step: 11
Training loss: 0.4040411710739136
Validation loss: 2.0886029104391732

Epoch: 87| Step: 0
Training loss: 1.6855922937393188
Validation loss: 2.0457107921441398

Epoch: 5| Step: 1
Training loss: 1.7668030261993408
Validation loss: 2.0081626375516257

Epoch: 5| Step: 2
Training loss: 1.7662798166275024
Validation loss: 2.051396240790685

Epoch: 5| Step: 3
Training loss: 1.0718969106674194
Validation loss: 2.080817257364591

Epoch: 5| Step: 4
Training loss: 1.68233323097229
Validation loss: 2.0283479193846383

Epoch: 5| Step: 5
Training loss: 1.8140805959701538
Validation loss: 2.0119929810365043

Epoch: 5| Step: 6
Training loss: 1.9479738473892212
Validation loss: 1.981025184194247

Epoch: 5| Step: 7
Training loss: 1.3617883920669556
Validation loss: 2.1003538221120834

Epoch: 5| Step: 8
Training loss: 1.6993671655654907
Validation loss: 2.0821968565384545

Epoch: 5| Step: 9
Training loss: 1.7083057165145874
Validation loss: 2.060003658135732

Epoch: 5| Step: 10
Training loss: 1.6585826873779297
Validation loss: 2.062462920943896

Epoch: 5| Step: 11
Training loss: 2.049145221710205
Validation loss: 2.0982777128616967

Epoch: 88| Step: 0
Training loss: 1.0122787952423096
Validation loss: 2.0679426938295364

Epoch: 5| Step: 1
Training loss: 1.3326274156570435
Validation loss: 2.1149380952119827

Epoch: 5| Step: 2
Training loss: 1.3666605949401855
Validation loss: 2.164207090934118

Epoch: 5| Step: 3
Training loss: 1.748032808303833
Validation loss: 2.1181823958953223

Epoch: 5| Step: 4
Training loss: 1.932222604751587
Validation loss: 2.106588383515676

Epoch: 5| Step: 5
Training loss: 1.61455500125885
Validation loss: 2.112847944100698

Epoch: 5| Step: 6
Training loss: 2.0771477222442627
Validation loss: 2.0601297666629157

Epoch: 5| Step: 7
Training loss: 1.4737517833709717
Validation loss: 2.0020836691061654

Epoch: 5| Step: 8
Training loss: 1.778402328491211
Validation loss: 2.0761622538169227

Epoch: 5| Step: 9
Training loss: 1.813647985458374
Validation loss: 2.0654015988111496

Epoch: 5| Step: 10
Training loss: 1.5049203634262085
Validation loss: 2.0860791405042014

Epoch: 5| Step: 11
Training loss: 2.8111135959625244
Validation loss: 2.045015056927999

Epoch: 89| Step: 0
Training loss: 1.1738466024398804
Validation loss: 2.073608269294103

Epoch: 5| Step: 1
Training loss: 1.8917531967163086
Validation loss: 2.0117433021465936

Epoch: 5| Step: 2
Training loss: 1.1329072713851929
Validation loss: 2.009030764301618

Epoch: 5| Step: 3
Training loss: 2.0272057056427
Validation loss: 2.096807430187861

Epoch: 5| Step: 4
Training loss: 1.7457767724990845
Validation loss: 2.144762014349302

Epoch: 5| Step: 5
Training loss: 1.8789091110229492
Validation loss: 2.126118669907252

Epoch: 5| Step: 6
Training loss: 0.9025714993476868
Validation loss: 2.1560313999652863

Epoch: 5| Step: 7
Training loss: 2.204326868057251
Validation loss: 2.1518987168868384

Epoch: 5| Step: 8
Training loss: 1.511790156364441
Validation loss: 2.1364731093247733

Epoch: 5| Step: 9
Training loss: 1.2832437753677368
Validation loss: 2.0698398053646088

Epoch: 5| Step: 10
Training loss: 2.2253012657165527
Validation loss: 2.131684104601542

Epoch: 5| Step: 11
Training loss: 2.489245891571045
Validation loss: 2.082476650675138

Epoch: 90| Step: 0
Training loss: 1.9775402545928955
Validation loss: 2.0075529416402182

Epoch: 5| Step: 1
Training loss: 1.5688673257827759
Validation loss: 2.042817081014315

Epoch: 5| Step: 2
Training loss: 1.0220108032226562
Validation loss: 1.993651936451594

Epoch: 5| Step: 3
Training loss: 1.2519108057022095
Validation loss: 2.0506855895121894

Epoch: 5| Step: 4
Training loss: 1.3734928369522095
Validation loss: 2.002742071946462

Epoch: 5| Step: 5
Training loss: 2.1186211109161377
Validation loss: 2.0102292646964393

Epoch: 5| Step: 6
Training loss: 1.4171382188796997
Validation loss: 2.0352661510308585

Epoch: 5| Step: 7
Training loss: 1.913297414779663
Validation loss: 2.0470784455537796

Epoch: 5| Step: 8
Training loss: 1.6755025386810303
Validation loss: 2.0544041196505227

Epoch: 5| Step: 9
Training loss: 1.8073030710220337
Validation loss: 2.1579197893540063

Epoch: 5| Step: 10
Training loss: 2.103299379348755
Validation loss: 2.1409038454294205

Epoch: 5| Step: 11
Training loss: 3.0249099731445312
Validation loss: 2.1103861729303994

Epoch: 91| Step: 0
Training loss: 1.2016681432724
Validation loss: 2.1260617524385452

Epoch: 5| Step: 1
Training loss: 2.2043840885162354
Validation loss: 2.2047047217686973

Epoch: 5| Step: 2
Training loss: 1.4321229457855225
Validation loss: 2.107501268386841

Epoch: 5| Step: 3
Training loss: 1.6338691711425781
Validation loss: 2.0959001580874124

Epoch: 5| Step: 4
Training loss: 2.3587255477905273
Validation loss: 2.155770575006803

Epoch: 5| Step: 5
Training loss: 1.2551440000534058
Validation loss: 2.0812460680802665

Epoch: 5| Step: 6
Training loss: 1.2007280588150024
Validation loss: 2.0649569580952325

Epoch: 5| Step: 7
Training loss: 1.5045758485794067
Validation loss: 2.0894116957982383

Epoch: 5| Step: 8
Training loss: 2.0976219177246094
Validation loss: 2.1533986578385034

Epoch: 5| Step: 9
Training loss: 1.3112117052078247
Validation loss: 2.0765720158815384

Epoch: 5| Step: 10
Training loss: 1.4631822109222412
Validation loss: 2.0340420554081597

Epoch: 5| Step: 11
Training loss: 1.895577311515808
Validation loss: 2.077587882677714

Epoch: 92| Step: 0
Training loss: 1.4385069608688354
Validation loss: 1.9718195895353954

Epoch: 5| Step: 1
Training loss: 1.3564177751541138
Validation loss: 2.1463117549816766

Epoch: 5| Step: 2
Training loss: 1.249342679977417
Validation loss: 2.0954679548740387

Epoch: 5| Step: 3
Training loss: 2.5291073322296143
Validation loss: 2.1511788864930472

Epoch: 5| Step: 4
Training loss: 2.2759764194488525
Validation loss: 2.1335473457972207

Epoch: 5| Step: 5
Training loss: 1.7380714416503906
Validation loss: 2.14580271144708

Epoch: 5| Step: 6
Training loss: 1.4521820545196533
Validation loss: 2.1798655688762665

Epoch: 5| Step: 7
Training loss: 1.961584448814392
Validation loss: 2.083395774165789

Epoch: 5| Step: 8
Training loss: 1.2062288522720337
Validation loss: 2.1464885572592416

Epoch: 5| Step: 9
Training loss: 1.3601086139678955
Validation loss: 2.1030236780643463

Epoch: 5| Step: 10
Training loss: 1.0991402864456177
Validation loss: 2.0958115458488464

Epoch: 5| Step: 11
Training loss: 0.9866052865982056
Validation loss: 2.025762364268303

Epoch: 93| Step: 0
Training loss: 1.3985145092010498
Validation loss: 2.0599762996037803

Epoch: 5| Step: 1
Training loss: 1.8187377452850342
Validation loss: 2.1172940333684287

Epoch: 5| Step: 2
Training loss: 1.9552196264266968
Validation loss: 2.121925632158915

Epoch: 5| Step: 3
Training loss: 2.07035493850708
Validation loss: 2.102971444527308

Epoch: 5| Step: 4
Training loss: 1.385750412940979
Validation loss: 2.0265750785668692

Epoch: 5| Step: 5
Training loss: 1.6895103454589844
Validation loss: 2.0567901730537415

Epoch: 5| Step: 6
Training loss: 1.2644002437591553
Validation loss: 2.0866486678520837

Epoch: 5| Step: 7
Training loss: 2.4717483520507812
Validation loss: 2.090518355369568

Epoch: 5| Step: 8
Training loss: 1.4486945867538452
Validation loss: 2.0696493486563363

Epoch: 5| Step: 9
Training loss: 1.385002851486206
Validation loss: 2.1163928657770157

Epoch: 5| Step: 10
Training loss: 0.6262952089309692
Validation loss: 2.1285509864489236

Epoch: 5| Step: 11
Training loss: 1.8911893367767334
Validation loss: 2.0543048729499183

Epoch: 94| Step: 0
Training loss: 1.274012565612793
Validation loss: 2.1073381155729294

Epoch: 5| Step: 1
Training loss: 1.2159714698791504
Validation loss: 2.204006185134252

Epoch: 5| Step: 2
Training loss: 1.5326299667358398
Validation loss: 2.087299168109894

Epoch: 5| Step: 3
Training loss: 1.7379086017608643
Validation loss: 2.067641297976176

Epoch: 5| Step: 4
Training loss: 1.356208086013794
Validation loss: 2.1597278316815696

Epoch: 5| Step: 5
Training loss: 1.7158048152923584
Validation loss: 2.1583919872840247

Epoch: 5| Step: 6
Training loss: 1.3211843967437744
Validation loss: 2.090164671341578

Epoch: 5| Step: 7
Training loss: 2.4595232009887695
Validation loss: 2.140624165534973

Epoch: 5| Step: 8
Training loss: 1.598240613937378
Validation loss: 2.06051038702329

Epoch: 5| Step: 9
Training loss: 1.6159398555755615
Validation loss: 2.1299677789211273

Epoch: 5| Step: 10
Training loss: 1.6975122690200806
Validation loss: 2.070948511362076

Epoch: 5| Step: 11
Training loss: 1.1706039905548096
Validation loss: 2.037373552719752

Epoch: 95| Step: 0
Training loss: 1.615936040878296
Validation loss: 2.047210216522217

Epoch: 5| Step: 1
Training loss: 1.5450974702835083
Validation loss: 2.0760123829046884

Epoch: 5| Step: 2
Training loss: 1.3364908695220947
Validation loss: 2.0689522176980972

Epoch: 5| Step: 3
Training loss: 1.8810348510742188
Validation loss: 2.0719315707683563

Epoch: 5| Step: 4
Training loss: 1.364537000656128
Validation loss: 2.0792539715766907

Epoch: 5| Step: 5
Training loss: 1.7159993648529053
Validation loss: 2.0528715550899506

Epoch: 5| Step: 6
Training loss: 1.616045594215393
Validation loss: 2.0847670833269754

Epoch: 5| Step: 7
Training loss: 1.9654849767684937
Validation loss: 2.0950140953063965

Epoch: 5| Step: 8
Training loss: 1.1046935319900513
Validation loss: 2.0624371071656546

Epoch: 5| Step: 9
Training loss: 2.0390279293060303
Validation loss: 2.127658506234487

Epoch: 5| Step: 10
Training loss: 1.2922065258026123
Validation loss: 2.1084502091010413

Epoch: 5| Step: 11
Training loss: 1.8905441761016846
Validation loss: 2.186530813574791

Epoch: 96| Step: 0
Training loss: 1.7723777294158936
Validation loss: 2.187765141328176

Epoch: 5| Step: 1
Training loss: 1.5002481937408447
Validation loss: 2.1844037423531213

Epoch: 5| Step: 2
Training loss: 1.3047736883163452
Validation loss: 2.063663358489672

Epoch: 5| Step: 3
Training loss: 1.3688347339630127
Validation loss: 2.0374285926421485

Epoch: 5| Step: 4
Training loss: 1.7359685897827148
Validation loss: 2.0492784529924393

Epoch: 5| Step: 5
Training loss: 2.3704421520233154
Validation loss: 2.072518934806188

Epoch: 5| Step: 6
Training loss: 1.5038554668426514
Validation loss: 2.0660321712493896

Epoch: 5| Step: 7
Training loss: 2.017547130584717
Validation loss: 1.9752049297094345

Epoch: 5| Step: 8
Training loss: 1.747751235961914
Validation loss: 2.037626023093859

Epoch: 5| Step: 9
Training loss: 1.4931565523147583
Validation loss: 2.158069228132566

Epoch: 5| Step: 10
Training loss: 1.3584461212158203
Validation loss: 2.0939605931440988

Epoch: 5| Step: 11
Training loss: 1.3556182384490967
Validation loss: 2.0748203049103418

Epoch: 97| Step: 0
Training loss: 1.5618441104888916
Validation loss: 2.1518690983454385

Epoch: 5| Step: 1
Training loss: 1.5407054424285889
Validation loss: 2.2053747375806174

Epoch: 5| Step: 2
Training loss: 1.9377517700195312
Validation loss: 2.236378232638041

Epoch: 5| Step: 3
Training loss: 1.3748139142990112
Validation loss: 2.2499959617853165

Epoch: 5| Step: 4
Training loss: 1.7284246683120728
Validation loss: 2.1528821090857186

Epoch: 5| Step: 5
Training loss: 1.9969873428344727
Validation loss: 2.155896693468094

Epoch: 5| Step: 6
Training loss: 1.4526208639144897
Validation loss: 2.162779231866201

Epoch: 5| Step: 7
Training loss: 1.9474769830703735
Validation loss: 2.0662240932385125

Epoch: 5| Step: 8
Training loss: 1.488896131515503
Validation loss: 2.0122764905293784

Epoch: 5| Step: 9
Training loss: 1.2252976894378662
Validation loss: 2.0841081738471985

Epoch: 5| Step: 10
Training loss: 1.0612637996673584
Validation loss: 2.028719514608383

Epoch: 5| Step: 11
Training loss: 1.4562220573425293
Validation loss: 2.0581938922405243

Epoch: 98| Step: 0
Training loss: 1.9494245052337646
Validation loss: 2.0804413110017776

Epoch: 5| Step: 1
Training loss: 1.435670256614685
Validation loss: 2.0447348157564798

Epoch: 5| Step: 2
Training loss: 1.3316634893417358
Validation loss: 2.0299150149027505

Epoch: 5| Step: 3
Training loss: 1.514788031578064
Validation loss: 2.031744956970215

Epoch: 5| Step: 4
Training loss: 1.4815776348114014
Validation loss: 2.026109059651693

Epoch: 5| Step: 5
Training loss: 1.3206754922866821
Validation loss: 2.132700507839521

Epoch: 5| Step: 6
Training loss: 1.744610071182251
Validation loss: 2.150561213493347

Epoch: 5| Step: 7
Training loss: 2.4323532581329346
Validation loss: 2.111723934610685

Epoch: 5| Step: 8
Training loss: 1.1345247030258179
Validation loss: 2.1253446837266288

Epoch: 5| Step: 9
Training loss: 1.4432399272918701
Validation loss: 2.1423328618208566

Epoch: 5| Step: 10
Training loss: 1.5698883533477783
Validation loss: 2.211053654551506

Epoch: 5| Step: 11
Training loss: 1.5616734027862549
Validation loss: 2.138312801718712

Epoch: 99| Step: 0
Training loss: 1.3776423931121826
Validation loss: 2.1503295501073203

Epoch: 5| Step: 1
Training loss: 1.6843225955963135
Validation loss: 2.136370594302813

Epoch: 5| Step: 2
Training loss: 1.3903180360794067
Validation loss: 2.1443698753913245

Epoch: 5| Step: 3
Training loss: 1.4702328443527222
Validation loss: 2.0748488257328668

Epoch: 5| Step: 4
Training loss: 2.5671730041503906
Validation loss: 2.0636030534903207

Epoch: 5| Step: 5
Training loss: 1.4733893871307373
Validation loss: 2.020274971922239

Epoch: 5| Step: 6
Training loss: 1.2692506313323975
Validation loss: 2.0389801263809204

Epoch: 5| Step: 7
Training loss: 1.0448086261749268
Validation loss: 2.1052005738019943

Epoch: 5| Step: 8
Training loss: 1.6250625848770142
Validation loss: 2.1059402773777642

Epoch: 5| Step: 9
Training loss: 1.9334360361099243
Validation loss: 2.0435426831245422

Epoch: 5| Step: 10
Training loss: 1.286582589149475
Validation loss: 2.063119113445282

Epoch: 5| Step: 11
Training loss: 1.7001354694366455
Validation loss: 2.019912208120028

Epoch: 100| Step: 0
Training loss: 1.2599637508392334
Validation loss: 2.0623334844907126

Epoch: 5| Step: 1
Training loss: 1.0081641674041748
Validation loss: 2.126021126906077

Epoch: 5| Step: 2
Training loss: 1.0442110300064087
Validation loss: 2.1407735347747803

Epoch: 5| Step: 3
Training loss: 1.9098269939422607
Validation loss: 2.1807302435239158

Epoch: 5| Step: 4
Training loss: 2.242767572402954
Validation loss: 2.1495085606972375

Epoch: 5| Step: 5
Training loss: 2.019390106201172
Validation loss: 2.2324963957071304

Epoch: 5| Step: 6
Training loss: 1.346765160560608
Validation loss: 2.224702090024948

Epoch: 5| Step: 7
Training loss: 1.3293975591659546
Validation loss: 2.1571574956178665

Epoch: 5| Step: 8
Training loss: 1.6605823040008545
Validation loss: 2.1159764379262924

Epoch: 5| Step: 9
Training loss: 1.7581201791763306
Validation loss: 2.144306222597758

Epoch: 5| Step: 10
Training loss: 1.068281888961792
Validation loss: 2.1089699069658914

Epoch: 5| Step: 11
Training loss: 1.7127469778060913
Validation loss: 2.0963521599769592

Epoch: 101| Step: 0
Training loss: 1.8899099826812744
Validation loss: 2.130178779363632

Epoch: 5| Step: 1
Training loss: 1.5480057001113892
Validation loss: 2.0652049481868744

Epoch: 5| Step: 2
Training loss: 1.7586851119995117
Validation loss: 2.1114852130413055

Epoch: 5| Step: 3
Training loss: 1.4941227436065674
Validation loss: 2.1242332806189856

Epoch: 5| Step: 4
Training loss: 1.7691882848739624
Validation loss: 2.0687767267227173

Epoch: 5| Step: 5
Training loss: 1.5228450298309326
Validation loss: 2.0737567295630774

Epoch: 5| Step: 6
Training loss: 1.8014647960662842
Validation loss: 2.080639402071635

Epoch: 5| Step: 7
Training loss: 1.3256750106811523
Validation loss: 2.068041612704595

Epoch: 5| Step: 8
Training loss: 1.1083040237426758
Validation loss: 2.064853399991989

Epoch: 5| Step: 9
Training loss: 1.3086812496185303
Validation loss: 2.128911405801773

Epoch: 5| Step: 10
Training loss: 1.716353178024292
Validation loss: 2.1773749391237893

Epoch: 5| Step: 11
Training loss: 0.904879093170166
Validation loss: 2.268939028183619

Epoch: 102| Step: 0
Training loss: 1.1909258365631104
Validation loss: 2.28141820927461

Epoch: 5| Step: 1
Training loss: 1.1846635341644287
Validation loss: 2.2543298602104187

Epoch: 5| Step: 2
Training loss: 0.9283887147903442
Validation loss: 2.1944608936707177

Epoch: 5| Step: 3
Training loss: 1.7813913822174072
Validation loss: 2.152960111697515

Epoch: 5| Step: 4
Training loss: 1.8040153980255127
Validation loss: 2.16592730085055

Epoch: 5| Step: 5
Training loss: 1.698793649673462
Validation loss: 2.080787102381388

Epoch: 5| Step: 6
Training loss: 2.7806496620178223
Validation loss: 2.0337700496117272

Epoch: 5| Step: 7
Training loss: 1.4886494874954224
Validation loss: 2.147626280784607

Epoch: 5| Step: 8
Training loss: 1.1910420656204224
Validation loss: 2.091422980030378

Epoch: 5| Step: 9
Training loss: 1.5577104091644287
Validation loss: 2.0854951540629068

Epoch: 5| Step: 10
Training loss: 1.694472074508667
Validation loss: 2.1124613334735236

Epoch: 5| Step: 11
Training loss: 0.5353635549545288
Validation loss: 2.136392076810201

Epoch: 103| Step: 0
Training loss: 1.518476128578186
Validation loss: 2.139471580584844

Epoch: 5| Step: 1
Training loss: 1.8422555923461914
Validation loss: 2.1769096553325653

Epoch: 5| Step: 2
Training loss: 1.065031886100769
Validation loss: 2.18695430457592

Epoch: 5| Step: 3
Training loss: 2.365403652191162
Validation loss: 2.188708816965421

Epoch: 5| Step: 4
Training loss: 1.4126005172729492
Validation loss: 2.258736858765284

Epoch: 5| Step: 5
Training loss: 1.1106668710708618
Validation loss: 2.202878028154373

Epoch: 5| Step: 6
Training loss: 1.1135423183441162
Validation loss: 2.2293661733468375

Epoch: 5| Step: 7
Training loss: 1.2291123867034912
Validation loss: 2.1104949563741684

Epoch: 5| Step: 8
Training loss: 1.6417763233184814
Validation loss: 2.197802265485128

Epoch: 5| Step: 9
Training loss: 1.6037626266479492
Validation loss: 2.158455550670624

Epoch: 5| Step: 10
Training loss: 1.8330609798431396
Validation loss: 2.1473581790924072

Epoch: 5| Step: 11
Training loss: 1.7561908960342407
Validation loss: 2.1597525825103125

Epoch: 104| Step: 0
Training loss: 1.517152190208435
Validation loss: 2.143771300713221

Epoch: 5| Step: 1
Training loss: 1.657576322555542
Validation loss: 2.078807552655538

Epoch: 5| Step: 2
Training loss: 1.632632851600647
Validation loss: 2.1111223896344504

Epoch: 5| Step: 3
Training loss: 1.658233880996704
Validation loss: 2.0026180843512216

Epoch: 5| Step: 4
Training loss: 1.610317587852478
Validation loss: 2.1370561718940735

Epoch: 5| Step: 5
Training loss: 1.6531822681427002
Validation loss: 2.0708153446515403

Epoch: 5| Step: 6
Training loss: 1.2184909582138062
Validation loss: 2.027460699280103

Epoch: 5| Step: 7
Training loss: 1.418540596961975
Validation loss: 2.0902691880861917

Epoch: 5| Step: 8
Training loss: 1.6617848873138428
Validation loss: 2.1685299774010978

Epoch: 5| Step: 9
Training loss: 1.6714222431182861
Validation loss: 2.1985726853211722

Epoch: 5| Step: 10
Training loss: 1.1816675662994385
Validation loss: 2.162855396668116

Epoch: 5| Step: 11
Training loss: 2.368353843688965
Validation loss: 2.174467225869497

Epoch: 105| Step: 0
Training loss: 1.3254646062850952
Validation loss: 2.240828404823939

Epoch: 5| Step: 1
Training loss: 1.369433045387268
Validation loss: 2.252802868684133

Epoch: 5| Step: 2
Training loss: 1.6412149667739868
Validation loss: 2.2015962352355323

Epoch: 5| Step: 3
Training loss: 2.1929757595062256
Validation loss: 2.2670689771572747

Epoch: 5| Step: 4
Training loss: 1.374274492263794
Validation loss: 2.2004945427179337

Epoch: 5| Step: 5
Training loss: 1.4889700412750244
Validation loss: 2.100542018810908

Epoch: 5| Step: 6
Training loss: 1.7492029666900635
Validation loss: 2.072188605864843

Epoch: 5| Step: 7
Training loss: 1.6333143711090088
Validation loss: 2.1418548176685968

Epoch: 5| Step: 8
Training loss: 1.3005911111831665
Validation loss: 2.0825484891732535

Epoch: 5| Step: 9
Training loss: 1.5848362445831299
Validation loss: 2.0460118850072226

Epoch: 5| Step: 10
Training loss: 1.3417648077011108
Validation loss: 2.100660264492035

Epoch: 5| Step: 11
Training loss: 1.0594956874847412
Validation loss: 2.036713312069575

Epoch: 106| Step: 0
Training loss: 1.470731496810913
Validation loss: 2.061567241946856

Epoch: 5| Step: 1
Training loss: 1.677137017250061
Validation loss: 2.0847366750240326

Epoch: 5| Step: 2
Training loss: 1.3652479648590088
Validation loss: 2.02836541334788

Epoch: 5| Step: 3
Training loss: 1.4549624919891357
Validation loss: 2.0080448240041733

Epoch: 5| Step: 4
Training loss: 0.6652051210403442
Validation loss: 2.127988656361898

Epoch: 5| Step: 5
Training loss: 1.8627055883407593
Validation loss: 2.1279950737953186

Epoch: 5| Step: 6
Training loss: 1.382596731185913
Validation loss: 2.1665164033571878

Epoch: 5| Step: 7
Training loss: 1.5605262517929077
Validation loss: 2.2341170608997345

Epoch: 5| Step: 8
Training loss: 1.5962308645248413
Validation loss: 2.2043116241693497

Epoch: 5| Step: 9
Training loss: 1.571624755859375
Validation loss: 2.133596564332644

Epoch: 5| Step: 10
Training loss: 1.729621171951294
Validation loss: 2.2028111666440964

Epoch: 5| Step: 11
Training loss: 2.0110349655151367
Validation loss: 2.1947480142116547

Epoch: 107| Step: 0
Training loss: 1.0008667707443237
Validation loss: 2.1441818475723267

Epoch: 5| Step: 1
Training loss: 1.2182927131652832
Validation loss: 2.1017339477936425

Epoch: 5| Step: 2
Training loss: 1.2379257678985596
Validation loss: 2.071244145433108

Epoch: 5| Step: 3
Training loss: 1.4785016775131226
Validation loss: 2.077480733394623

Epoch: 5| Step: 4
Training loss: 1.3114347457885742
Validation loss: 2.157340387503306

Epoch: 5| Step: 5
Training loss: 1.567237138748169
Validation loss: 2.148752053578695

Epoch: 5| Step: 6
Training loss: 1.7067737579345703
Validation loss: 2.0674521724383035

Epoch: 5| Step: 7
Training loss: 2.1960361003875732
Validation loss: 2.0830846230189004

Epoch: 5| Step: 8
Training loss: 1.1144776344299316
Validation loss: 2.0954786390066147

Epoch: 5| Step: 9
Training loss: 1.6873842477798462
Validation loss: 2.1532235940297446

Epoch: 5| Step: 10
Training loss: 1.6719930171966553
Validation loss: 2.1206888556480408

Epoch: 5| Step: 11
Training loss: 1.179803490638733
Validation loss: 2.1352949986855188

Epoch: 108| Step: 0
Training loss: 1.4116718769073486
Validation loss: 2.129895860950152

Epoch: 5| Step: 1
Training loss: 1.424512505531311
Validation loss: 2.148318032423655

Epoch: 5| Step: 2
Training loss: 0.8805796504020691
Validation loss: 2.14833731452624

Epoch: 5| Step: 3
Training loss: 0.8858867883682251
Validation loss: 2.1199016670385995

Epoch: 5| Step: 4
Training loss: 2.007111072540283
Validation loss: 2.14339679479599

Epoch: 5| Step: 5
Training loss: 1.8624299764633179
Validation loss: 2.14354399840037

Epoch: 5| Step: 6
Training loss: 1.9524132013320923
Validation loss: 2.1563170850276947

Epoch: 5| Step: 7
Training loss: 1.3489586114883423
Validation loss: 2.2224102367957435

Epoch: 5| Step: 8
Training loss: 1.6619155406951904
Validation loss: 2.178565035263697

Epoch: 5| Step: 9
Training loss: 1.1059520244598389
Validation loss: 2.179588571190834

Epoch: 5| Step: 10
Training loss: 1.7224899530410767
Validation loss: 2.220747947692871

Epoch: 5| Step: 11
Training loss: 0.9829011559486389
Validation loss: 2.115696574250857

Epoch: 109| Step: 0
Training loss: 1.5606746673583984
Validation loss: 2.1316453715165458

Epoch: 5| Step: 1
Training loss: 1.0683422088623047
Validation loss: 2.1056242833534875

Epoch: 5| Step: 2
Training loss: 2.073530435562134
Validation loss: 2.090034435192744

Epoch: 5| Step: 3
Training loss: 0.82262122631073
Validation loss: 2.089818080266317

Epoch: 5| Step: 4
Training loss: 1.6806379556655884
Validation loss: 2.111889580885569

Epoch: 5| Step: 5
Training loss: 1.2121264934539795
Validation loss: 2.1199255734682083

Epoch: 5| Step: 6
Training loss: 1.4563686847686768
Validation loss: 2.2031935652097068

Epoch: 5| Step: 7
Training loss: 1.7883132696151733
Validation loss: 2.2274697919686637

Epoch: 5| Step: 8
Training loss: 1.6513181924819946
Validation loss: 2.3125048180421195

Epoch: 5| Step: 9
Training loss: 1.64046311378479
Validation loss: 2.282224009434382

Epoch: 5| Step: 10
Training loss: 1.5650544166564941
Validation loss: 2.273466855287552

Epoch: 5| Step: 11
Training loss: 0.7295771241188049
Validation loss: 2.241287892063459

Epoch: 110| Step: 0
Training loss: 1.7019627094268799
Validation loss: 2.233456547061602

Epoch: 5| Step: 1
Training loss: 1.3729329109191895
Validation loss: 2.22214142481486

Epoch: 5| Step: 2
Training loss: 1.872897744178772
Validation loss: 2.1192445904016495

Epoch: 5| Step: 3
Training loss: 0.87422114610672
Validation loss: 2.1165954569975534

Epoch: 5| Step: 4
Training loss: 1.3094621896743774
Validation loss: 2.127469544609388

Epoch: 5| Step: 5
Training loss: 1.3084572553634644
Validation loss: 2.136962443590164

Epoch: 5| Step: 6
Training loss: 1.3798048496246338
Validation loss: 2.0884546289841333

Epoch: 5| Step: 7
Training loss: 0.9709529876708984
Validation loss: 2.1389531840880713

Epoch: 5| Step: 8
Training loss: 1.8707414865493774
Validation loss: 2.1528457750876746

Epoch: 5| Step: 9
Training loss: 1.5795313119888306
Validation loss: 2.1350814551115036

Epoch: 5| Step: 10
Training loss: 1.8684189319610596
Validation loss: 2.0338954776525497

Epoch: 5| Step: 11
Training loss: 1.69392728805542
Validation loss: 2.086095487078031

Epoch: 111| Step: 0
Training loss: 1.0869054794311523
Validation loss: 2.11922196050485

Epoch: 5| Step: 1
Training loss: 1.005797266960144
Validation loss: 2.221318691968918

Epoch: 5| Step: 2
Training loss: 1.9110736846923828
Validation loss: 2.1891419341166816

Epoch: 5| Step: 3
Training loss: 1.6769630908966064
Validation loss: 2.144489367802938

Epoch: 5| Step: 4
Training loss: 1.1088041067123413
Validation loss: 2.118533472220103

Epoch: 5| Step: 5
Training loss: 1.8921308517456055
Validation loss: 2.096345836917559

Epoch: 5| Step: 6
Training loss: 1.1316457986831665
Validation loss: 2.1333654820919037

Epoch: 5| Step: 7
Training loss: 1.4860546588897705
Validation loss: 2.165356626113256

Epoch: 5| Step: 8
Training loss: 1.512169599533081
Validation loss: 2.111331378420194

Epoch: 5| Step: 9
Training loss: 1.2033336162567139
Validation loss: 2.074168493350347

Epoch: 5| Step: 10
Training loss: 1.6298658847808838
Validation loss: 2.112922211488088

Epoch: 5| Step: 11
Training loss: 2.225902557373047
Validation loss: 2.1674379954735437

Epoch: 112| Step: 0
Training loss: 1.4450763463974
Validation loss: 2.1183912257353463

Epoch: 5| Step: 1
Training loss: 1.8454601764678955
Validation loss: 2.164633964498838

Epoch: 5| Step: 2
Training loss: 1.5287706851959229
Validation loss: 2.141384700934092

Epoch: 5| Step: 3
Training loss: 0.774382472038269
Validation loss: 2.0855325212081275

Epoch: 5| Step: 4
Training loss: 1.109951138496399
Validation loss: 2.1399706651767096

Epoch: 5| Step: 5
Training loss: 2.1859614849090576
Validation loss: 2.127638205885887

Epoch: 5| Step: 6
Training loss: 1.5558058023452759
Validation loss: 2.0898366620143256

Epoch: 5| Step: 7
Training loss: 1.5015833377838135
Validation loss: 2.115687112013499

Epoch: 5| Step: 8
Training loss: 0.8660827875137329
Validation loss: 2.2024495750665665

Epoch: 5| Step: 9
Training loss: 1.4662498235702515
Validation loss: 2.167327046394348

Epoch: 5| Step: 10
Training loss: 1.3426920175552368
Validation loss: 2.1956868022680283

Epoch: 5| Step: 11
Training loss: 1.5241026878356934
Validation loss: 2.138923078775406

Epoch: 113| Step: 0
Training loss: 1.205619215965271
Validation loss: 2.1615654826164246

Epoch: 5| Step: 1
Training loss: 1.4144068956375122
Validation loss: 2.1005446215470633

Epoch: 5| Step: 2
Training loss: 1.4326103925704956
Validation loss: 2.1573421160380044

Epoch: 5| Step: 3
Training loss: 1.228600263595581
Validation loss: 2.121963247656822

Epoch: 5| Step: 4
Training loss: 1.4668962955474854
Validation loss: 2.027025913198789

Epoch: 5| Step: 5
Training loss: 1.712677240371704
Validation loss: 2.0779540489117303

Epoch: 5| Step: 6
Training loss: 1.5337378978729248
Validation loss: 2.164917513728142

Epoch: 5| Step: 7
Training loss: 1.756138563156128
Validation loss: 2.063179299235344

Epoch: 5| Step: 8
Training loss: 1.0444790124893188
Validation loss: 2.099805027246475

Epoch: 5| Step: 9
Training loss: 1.6200001239776611
Validation loss: 2.0337886959314346

Epoch: 5| Step: 10
Training loss: 1.2883081436157227
Validation loss: 2.0714267243941626

Epoch: 5| Step: 11
Training loss: 1.9275062084197998
Validation loss: 2.1054736177126565

Epoch: 114| Step: 0
Training loss: 1.7896966934204102
Validation loss: 2.0562882920106254

Epoch: 5| Step: 1
Training loss: 1.6903350353240967
Validation loss: 2.062444513042768

Epoch: 5| Step: 2
Training loss: 0.697120189666748
Validation loss: 2.1439938644568124

Epoch: 5| Step: 3
Training loss: 1.6657413244247437
Validation loss: 2.1799517621596656

Epoch: 5| Step: 4
Training loss: 1.3015813827514648
Validation loss: 2.1138439377148948

Epoch: 5| Step: 5
Training loss: 1.1020448207855225
Validation loss: 2.2021490087111792

Epoch: 5| Step: 6
Training loss: 1.0132941007614136
Validation loss: 2.1613257179657617

Epoch: 5| Step: 7
Training loss: 2.2178518772125244
Validation loss: 2.1968952963749566

Epoch: 5| Step: 8
Training loss: 1.068505883216858
Validation loss: 2.1248233765363693

Epoch: 5| Step: 9
Training loss: 1.8738025426864624
Validation loss: 2.1282789756854377

Epoch: 5| Step: 10
Training loss: 1.176770567893982
Validation loss: 2.0886295586824417

Epoch: 5| Step: 11
Training loss: 1.8813139200210571
Validation loss: 2.1609762410322824

Epoch: 115| Step: 0
Training loss: 1.7094860076904297
Validation loss: 2.1222266256809235

Epoch: 5| Step: 1
Training loss: 1.4234484434127808
Validation loss: 2.0698702931404114

Epoch: 5| Step: 2
Training loss: 2.1086878776550293
Validation loss: 2.113177706797918

Epoch: 5| Step: 3
Training loss: 1.7682933807373047
Validation loss: 2.0911736289660134

Epoch: 5| Step: 4
Training loss: 1.5209482908248901
Validation loss: 2.1824442048867545

Epoch: 5| Step: 5
Training loss: 1.264054536819458
Validation loss: 2.2474582393964133

Epoch: 5| Step: 6
Training loss: 1.0512988567352295
Validation loss: 2.160817821820577

Epoch: 5| Step: 7
Training loss: 0.9819324612617493
Validation loss: 2.276100198427836

Epoch: 5| Step: 8
Training loss: 1.083274006843567
Validation loss: 2.1030986607074738

Epoch: 5| Step: 9
Training loss: 1.2724814414978027
Validation loss: 2.15765052040418

Epoch: 5| Step: 10
Training loss: 1.2943012714385986
Validation loss: 2.137983729441961

Epoch: 5| Step: 11
Training loss: 0.2863491475582123
Validation loss: 2.148658881584803

Epoch: 116| Step: 0
Training loss: 1.3190858364105225
Validation loss: 2.0754963755607605

Epoch: 5| Step: 1
Training loss: 1.3502264022827148
Validation loss: 2.049525171518326

Epoch: 5| Step: 2
Training loss: 1.2472193241119385
Validation loss: 2.108731602629026

Epoch: 5| Step: 3
Training loss: 1.0513415336608887
Validation loss: 2.1166497419277825

Epoch: 5| Step: 4
Training loss: 1.526599407196045
Validation loss: 2.1235316892464957

Epoch: 5| Step: 5
Training loss: 1.3929013013839722
Validation loss: 2.106379821896553

Epoch: 5| Step: 6
Training loss: 1.5527489185333252
Validation loss: 2.1753401706616082

Epoch: 5| Step: 7
Training loss: 1.7116283178329468
Validation loss: 2.1760377039512

Epoch: 5| Step: 8
Training loss: 1.264273762702942
Validation loss: 2.226388245820999

Epoch: 5| Step: 9
Training loss: 1.542747139930725
Validation loss: 2.2294000685214996

Epoch: 5| Step: 10
Training loss: 2.089298725128174
Validation loss: 2.2349241574605307

Epoch: 5| Step: 11
Training loss: 1.3699630498886108
Validation loss: 2.122952659924825

Epoch: 117| Step: 0
Training loss: 1.3817546367645264
Validation loss: 2.160768965880076

Epoch: 5| Step: 1
Training loss: 1.0454076528549194
Validation loss: 2.0945245027542114

Epoch: 5| Step: 2
Training loss: 1.7397228479385376
Validation loss: 2.0336997459332147

Epoch: 5| Step: 3
Training loss: 0.982617974281311
Validation loss: 2.05139488975207

Epoch: 5| Step: 4
Training loss: 1.239055871963501
Validation loss: 2.0650348514318466

Epoch: 5| Step: 5
Training loss: 1.1715075969696045
Validation loss: 2.206119403243065

Epoch: 5| Step: 6
Training loss: 1.6867964267730713
Validation loss: 2.0903710375229516

Epoch: 5| Step: 7
Training loss: 1.1379644870758057
Validation loss: 2.1135021646817527

Epoch: 5| Step: 8
Training loss: 1.5754907131195068
Validation loss: 2.0792493671178818

Epoch: 5| Step: 9
Training loss: 1.343124270439148
Validation loss: 2.1018096854289374

Epoch: 5| Step: 10
Training loss: 1.6604936122894287
Validation loss: 2.11259263753891

Epoch: 5| Step: 11
Training loss: 2.1939940452575684
Validation loss: 2.1194535394509635

Epoch: 118| Step: 0
Training loss: 1.4781017303466797
Validation loss: 2.074783444404602

Epoch: 5| Step: 1
Training loss: 1.6991071701049805
Validation loss: 2.13328825434049

Epoch: 5| Step: 2
Training loss: 2.3329505920410156
Validation loss: 2.0953496396541595

Epoch: 5| Step: 3
Training loss: 1.0758380889892578
Validation loss: 2.124217083056768

Epoch: 5| Step: 4
Training loss: 1.4412208795547485
Validation loss: 2.095395420988401

Epoch: 5| Step: 5
Training loss: 1.3630638122558594
Validation loss: 2.110012928644816

Epoch: 5| Step: 6
Training loss: 1.1102828979492188
Validation loss: 2.083118587732315

Epoch: 5| Step: 7
Training loss: 0.924953818321228
Validation loss: 2.061719904343287

Epoch: 5| Step: 8
Training loss: 1.3018782138824463
Validation loss: 2.152073487639427

Epoch: 5| Step: 9
Training loss: 1.0397926568984985
Validation loss: 2.098703687389692

Epoch: 5| Step: 10
Training loss: 0.9762809872627258
Validation loss: 2.1446217397848764

Epoch: 5| Step: 11
Training loss: 1.72127366065979
Validation loss: 2.1950812339782715

Epoch: 119| Step: 0
Training loss: 1.3953113555908203
Validation loss: 2.2105466773112616

Epoch: 5| Step: 1
Training loss: 1.5735437870025635
Validation loss: 2.254667043685913

Epoch: 5| Step: 2
Training loss: 1.0764381885528564
Validation loss: 2.217475081483523

Epoch: 5| Step: 3
Training loss: 1.5215716361999512
Validation loss: 2.132366046309471

Epoch: 5| Step: 4
Training loss: 0.7733261585235596
Validation loss: 2.186620687445005

Epoch: 5| Step: 5
Training loss: 1.576284646987915
Validation loss: 2.0779106418291726

Epoch: 5| Step: 6
Training loss: 1.4585649967193604
Validation loss: 2.0837978422641754

Epoch: 5| Step: 7
Training loss: 1.3594672679901123
Validation loss: 2.12281164030234

Epoch: 5| Step: 8
Training loss: 1.5474307537078857
Validation loss: 2.0874821494023004

Epoch: 5| Step: 9
Training loss: 1.508911371231079
Validation loss: 2.0429674883683524

Epoch: 5| Step: 10
Training loss: 1.2981836795806885
Validation loss: 2.123423000176748

Epoch: 5| Step: 11
Training loss: 4.587650299072266
Validation loss: 2.1254583348830542

Epoch: 120| Step: 0
Training loss: 1.2965724468231201
Validation loss: 2.072339634100596

Epoch: 5| Step: 1
Training loss: 1.233220100402832
Validation loss: 2.136249855160713

Epoch: 5| Step: 2
Training loss: 1.4715096950531006
Validation loss: 2.139169250925382

Epoch: 5| Step: 3
Training loss: 1.8016942739486694
Validation loss: 2.173436333735784

Epoch: 5| Step: 4
Training loss: 1.1889585256576538
Validation loss: 2.109421213467916

Epoch: 5| Step: 5
Training loss: 1.2112579345703125
Validation loss: 2.0675971607367196

Epoch: 5| Step: 6
Training loss: 0.8915979266166687
Validation loss: 2.1180295099814734

Epoch: 5| Step: 7
Training loss: 1.1884090900421143
Validation loss: 2.0893123348553977

Epoch: 5| Step: 8
Training loss: 1.3950579166412354
Validation loss: 2.143626938263575

Epoch: 5| Step: 9
Training loss: 1.2445123195648193
Validation loss: 2.140512704849243

Epoch: 5| Step: 10
Training loss: 1.243742823600769
Validation loss: 2.1564645965894065

Epoch: 5| Step: 11
Training loss: 1.8216044902801514
Validation loss: 2.260451704263687

Epoch: 121| Step: 0
Training loss: 1.4521596431732178
Validation loss: 2.195104112227758

Epoch: 5| Step: 1
Training loss: 1.5894831418991089
Validation loss: 2.1444954921801886

Epoch: 5| Step: 2
Training loss: 0.9188588261604309
Validation loss: 2.1301294366518655

Epoch: 5| Step: 3
Training loss: 1.1412513256072998
Validation loss: 2.13947656750679

Epoch: 5| Step: 4
Training loss: 1.6309449672698975
Validation loss: 2.121276537577311

Epoch: 5| Step: 5
Training loss: 1.391453504562378
Validation loss: 2.085966780781746

Epoch: 5| Step: 6
Training loss: 1.4377063512802124
Validation loss: 2.081099713842074

Epoch: 5| Step: 7
Training loss: 1.3947755098342896
Validation loss: 2.1054753015438714

Epoch: 5| Step: 8
Training loss: 0.8797740936279297
Validation loss: 2.1644176840782166

Epoch: 5| Step: 9
Training loss: 1.494652271270752
Validation loss: 2.112394799788793

Epoch: 5| Step: 10
Training loss: 1.357830286026001
Validation loss: 2.1196414828300476

Epoch: 5| Step: 11
Training loss: 1.4764814376831055
Validation loss: 2.0455143253008523

Epoch: 122| Step: 0
Training loss: 1.2282321453094482
Validation loss: 2.0768457651138306

Epoch: 5| Step: 1
Training loss: 1.1294187307357788
Validation loss: 2.0751207123200097

Epoch: 5| Step: 2
Training loss: 1.424944519996643
Validation loss: 2.0632159213225045

Epoch: 5| Step: 3
Training loss: 1.337755560874939
Validation loss: 2.0956722547610602

Epoch: 5| Step: 4
Training loss: 1.1558290719985962
Validation loss: 2.1191365470488868

Epoch: 5| Step: 5
Training loss: 0.7918680906295776
Validation loss: 2.094651088118553

Epoch: 5| Step: 6
Training loss: 1.1712403297424316
Validation loss: 2.137487232685089

Epoch: 5| Step: 7
Training loss: 1.7020021677017212
Validation loss: 2.0503681202729545

Epoch: 5| Step: 8
Training loss: 1.264268159866333
Validation loss: 2.098088577389717

Epoch: 5| Step: 9
Training loss: 1.3679577112197876
Validation loss: 2.0848289132118225

Epoch: 5| Step: 10
Training loss: 1.8075367212295532
Validation loss: 2.0939006954431534

Epoch: 5| Step: 11
Training loss: 0.537883996963501
Validation loss: 2.138267830014229

Epoch: 123| Step: 0
Training loss: 1.888704538345337
Validation loss: 2.1780268053213754

Epoch: 5| Step: 1
Training loss: 1.6580747365951538
Validation loss: 2.107793480157852

Epoch: 5| Step: 2
Training loss: 1.0713605880737305
Validation loss: 2.0730523765087128

Epoch: 5| Step: 3
Training loss: 1.099671721458435
Validation loss: 2.0544927219549813

Epoch: 5| Step: 4
Training loss: 0.7294299006462097
Validation loss: 2.0799690087636313

Epoch: 5| Step: 5
Training loss: 1.4843528270721436
Validation loss: 2.0274014870325723

Epoch: 5| Step: 6
Training loss: 0.6360541582107544
Validation loss: 2.101627637942632

Epoch: 5| Step: 7
Training loss: 1.2036925554275513
Validation loss: 2.1160017599662146

Epoch: 5| Step: 8
Training loss: 1.9176830053329468
Validation loss: 2.141413872440656

Epoch: 5| Step: 9
Training loss: 1.2351815700531006
Validation loss: 2.138156125942866

Epoch: 5| Step: 10
Training loss: 0.8838832974433899
Validation loss: 2.109670246640841

Epoch: 5| Step: 11
Training loss: 1.5586038827896118
Validation loss: 2.126015678048134

Epoch: 124| Step: 0
Training loss: 1.5673216581344604
Validation loss: 2.148491551478704

Epoch: 5| Step: 1
Training loss: 0.7317250967025757
Validation loss: 2.118315652012825

Epoch: 5| Step: 2
Training loss: 1.3053038120269775
Validation loss: 2.1486618171135583

Epoch: 5| Step: 3
Training loss: 0.9808391332626343
Validation loss: 2.099788799881935

Epoch: 5| Step: 4
Training loss: 0.9181362986564636
Validation loss: 2.0951304038365683

Epoch: 5| Step: 5
Training loss: 1.2438157796859741
Validation loss: 2.1203580051660538

Epoch: 5| Step: 6
Training loss: 1.3156558275222778
Validation loss: 2.1813871264457703

Epoch: 5| Step: 7
Training loss: 1.6493775844573975
Validation loss: 2.1439659893512726

Epoch: 5| Step: 8
Training loss: 1.5521968603134155
Validation loss: 2.0471726655960083

Epoch: 5| Step: 9
Training loss: 0.8510969877243042
Validation loss: 2.187920947869619

Epoch: 5| Step: 10
Training loss: 1.9173948764801025
Validation loss: 2.166211927930514

Epoch: 5| Step: 11
Training loss: 1.7341454029083252
Validation loss: 2.1553962032000222

Epoch: 125| Step: 0
Training loss: 0.8036834001541138
Validation loss: 2.1432586163282394

Epoch: 5| Step: 1
Training loss: 1.4170252084732056
Validation loss: 2.132203608751297

Epoch: 5| Step: 2
Training loss: 1.6728461980819702
Validation loss: 2.1780371268590293

Epoch: 5| Step: 3
Training loss: 1.1776484251022339
Validation loss: 2.088160678744316

Epoch: 5| Step: 4
Training loss: 1.3019641637802124
Validation loss: 2.162285486857096

Epoch: 5| Step: 5
Training loss: 1.9721901416778564
Validation loss: 2.0703143080075583

Epoch: 5| Step: 6
Training loss: 1.1886669397354126
Validation loss: 2.1154324213663735

Epoch: 5| Step: 7
Training loss: 0.6199619174003601
Validation loss: 2.1332068194945655

Epoch: 5| Step: 8
Training loss: 1.3430750370025635
Validation loss: 2.062761386235555

Epoch: 5| Step: 9
Training loss: 1.2478694915771484
Validation loss: 2.115382750829061

Epoch: 5| Step: 10
Training loss: 1.7001895904541016
Validation loss: 2.1334605515003204

Epoch: 5| Step: 11
Training loss: 1.4293898344039917
Validation loss: 2.1672315150499344

Epoch: 126| Step: 0
Training loss: 0.7893725037574768
Validation loss: 2.1400119264920554

Epoch: 5| Step: 1
Training loss: 1.363843560218811
Validation loss: 2.271354685227076

Epoch: 5| Step: 2
Training loss: 1.2172621488571167
Validation loss: 2.18006897966067

Epoch: 5| Step: 3
Training loss: 1.279895544052124
Validation loss: 2.2745661437511444

Epoch: 5| Step: 4
Training loss: 1.5223567485809326
Validation loss: 2.177537500858307

Epoch: 5| Step: 5
Training loss: 1.5242537260055542
Validation loss: 2.1587104499340057

Epoch: 5| Step: 6
Training loss: 1.7098957300186157
Validation loss: 2.180874447027842

Epoch: 5| Step: 7
Training loss: 1.2109228372573853
Validation loss: 2.108299419283867

Epoch: 5| Step: 8
Training loss: 1.2893002033233643
Validation loss: 2.068685139218966

Epoch: 5| Step: 9
Training loss: 1.5720998048782349
Validation loss: 2.089563265442848

Epoch: 5| Step: 10
Training loss: 1.0866641998291016
Validation loss: 2.1092977623144784

Epoch: 5| Step: 11
Training loss: 1.4464740753173828
Validation loss: 2.108620564142863

Epoch: 127| Step: 0
Training loss: 1.186300277709961
Validation loss: 2.125247965256373

Epoch: 5| Step: 1
Training loss: 1.6587886810302734
Validation loss: 2.116476679841677

Epoch: 5| Step: 2
Training loss: 1.1732875108718872
Validation loss: 2.221097687880198

Epoch: 5| Step: 3
Training loss: 0.7270094156265259
Validation loss: 2.1033333986997604

Epoch: 5| Step: 4
Training loss: 0.9574556350708008
Validation loss: 2.0844322194655738

Epoch: 5| Step: 5
Training loss: 1.6815788745880127
Validation loss: 2.076307455698649

Epoch: 5| Step: 6
Training loss: 1.3634061813354492
Validation loss: 2.101864824692408

Epoch: 5| Step: 7
Training loss: 1.638410210609436
Validation loss: 2.2001702139774957

Epoch: 5| Step: 8
Training loss: 1.2155357599258423
Validation loss: 2.1658233205477395

Epoch: 5| Step: 9
Training loss: 0.8946056365966797
Validation loss: 2.1091989229122796

Epoch: 5| Step: 10
Training loss: 1.0952167510986328
Validation loss: 2.131525903940201

Epoch: 5| Step: 11
Training loss: 3.066856861114502
Validation loss: 2.145582209030787

Epoch: 128| Step: 0
Training loss: 1.0466018915176392
Validation loss: 2.1558682918548584

Epoch: 5| Step: 1
Training loss: 1.7655446529388428
Validation loss: 2.2337952703237534

Epoch: 5| Step: 2
Training loss: 1.248457431793213
Validation loss: 2.1727799773216248

Epoch: 5| Step: 3
Training loss: 0.9972532391548157
Validation loss: 2.161772459745407

Epoch: 5| Step: 4
Training loss: 1.7594963312149048
Validation loss: 2.1454122910896936

Epoch: 5| Step: 5
Training loss: 0.9216219782829285
Validation loss: 2.230448603630066

Epoch: 5| Step: 6
Training loss: 2.147730588912964
Validation loss: 2.208438982566198

Epoch: 5| Step: 7
Training loss: 1.3499958515167236
Validation loss: 2.2330769350131354

Epoch: 5| Step: 8
Training loss: 0.7494195103645325
Validation loss: 2.1429217954476676

Epoch: 5| Step: 9
Training loss: 1.1481736898422241
Validation loss: 2.1899786641200385

Epoch: 5| Step: 10
Training loss: 1.1225817203521729
Validation loss: 2.1028728236754737

Epoch: 5| Step: 11
Training loss: 0.41614803671836853
Validation loss: 2.1321660578250885

Epoch: 129| Step: 0
Training loss: 0.7575719356536865
Validation loss: 2.163529023528099

Epoch: 5| Step: 1
Training loss: 0.8355294466018677
Validation loss: 2.1451797038316727

Epoch: 5| Step: 2
Training loss: 1.2622727155685425
Validation loss: 2.160428141554197

Epoch: 5| Step: 3
Training loss: 1.0443484783172607
Validation loss: 2.131154944499334

Epoch: 5| Step: 4
Training loss: 1.9574470520019531
Validation loss: 2.2327375461657843

Epoch: 5| Step: 5
Training loss: 1.8714580535888672
Validation loss: 2.155194560686747

Epoch: 5| Step: 6
Training loss: 0.7527478933334351
Validation loss: 2.161921590566635

Epoch: 5| Step: 7
Training loss: 1.3859708309173584
Validation loss: 2.0832108656565347

Epoch: 5| Step: 8
Training loss: 1.37913978099823
Validation loss: 2.1248699128627777

Epoch: 5| Step: 9
Training loss: 1.3949607610702515
Validation loss: 2.156079297264417

Epoch: 5| Step: 10
Training loss: 1.1378624439239502
Validation loss: 2.138219118118286

Epoch: 5| Step: 11
Training loss: 0.937798798084259
Validation loss: 2.1026907712221146

Epoch: 130| Step: 0
Training loss: 1.2921050786972046
Validation loss: 2.1167719761530557

Epoch: 5| Step: 1
Training loss: 1.2451051473617554
Validation loss: 2.069612075885137

Epoch: 5| Step: 2
Training loss: 1.0409138202667236
Validation loss: 2.136510650316874

Epoch: 5| Step: 3
Training loss: 0.9272569417953491
Validation loss: 2.123687078555425

Epoch: 5| Step: 4
Training loss: 1.3587223291397095
Validation loss: 2.1885301967461905

Epoch: 5| Step: 5
Training loss: 1.308356523513794
Validation loss: 2.26757342616717

Epoch: 5| Step: 6
Training loss: 1.8928232192993164
Validation loss: 2.319302648305893

Epoch: 5| Step: 7
Training loss: 0.8658833503723145
Validation loss: 2.2744232515494027

Epoch: 5| Step: 8
Training loss: 1.5140849351882935
Validation loss: 2.254898890852928

Epoch: 5| Step: 9
Training loss: 1.661171555519104
Validation loss: 2.1861727833747864

Epoch: 5| Step: 10
Training loss: 0.9844232797622681
Validation loss: 2.1220671186844506

Epoch: 5| Step: 11
Training loss: 2.0332095623016357
Validation loss: 2.1223882039388022

Epoch: 131| Step: 0
Training loss: 1.4453926086425781
Validation loss: 2.0782123108704886

Epoch: 5| Step: 1
Training loss: 1.3761128187179565
Validation loss: 2.070846368869146

Epoch: 5| Step: 2
Training loss: 1.1715424060821533
Validation loss: 2.155711367726326

Epoch: 5| Step: 3
Training loss: 0.948643684387207
Validation loss: 2.0584038148323693

Epoch: 5| Step: 4
Training loss: 1.4391486644744873
Validation loss: 2.1678400486707687

Epoch: 5| Step: 5
Training loss: 0.9537792205810547
Validation loss: 2.1263388643662133

Epoch: 5| Step: 6
Training loss: 2.0628998279571533
Validation loss: 2.2526031335194907

Epoch: 5| Step: 7
Training loss: 1.1700270175933838
Validation loss: 2.301301712791125

Epoch: 5| Step: 8
Training loss: 1.022862434387207
Validation loss: 2.375975246230761

Epoch: 5| Step: 9
Training loss: 1.0000778436660767
Validation loss: 2.304252286752065

Epoch: 5| Step: 10
Training loss: 1.706174612045288
Validation loss: 2.251630499958992

Epoch: 5| Step: 11
Training loss: 0.7793262600898743
Validation loss: 2.203976179162661

Epoch: 132| Step: 0
Training loss: 1.1079742908477783
Validation loss: 2.095358187953631

Epoch: 5| Step: 1
Training loss: 1.3538061380386353
Validation loss: 2.1386996110280356

Epoch: 5| Step: 2
Training loss: 1.2974523305892944
Validation loss: 2.091347888112068

Epoch: 5| Step: 3
Training loss: 2.117406129837036
Validation loss: 2.2013693700234094

Epoch: 5| Step: 4
Training loss: 1.3051693439483643
Validation loss: 2.132006347179413

Epoch: 5| Step: 5
Training loss: 1.144773244857788
Validation loss: 2.1229842056830726

Epoch: 5| Step: 6
Training loss: 1.5631611347198486
Validation loss: 2.1414150347312293

Epoch: 5| Step: 7
Training loss: 1.612015724182129
Validation loss: 2.165998250246048

Epoch: 5| Step: 8
Training loss: 1.0821857452392578
Validation loss: 2.2333608667055764

Epoch: 5| Step: 9
Training loss: 1.4204795360565186
Validation loss: 2.2921601980924606

Epoch: 5| Step: 10
Training loss: 0.8655607104301453
Validation loss: 2.1944037725528083

Epoch: 5| Step: 11
Training loss: 0.7198717594146729
Validation loss: 2.1753049492836

Epoch: 133| Step: 0
Training loss: 0.9054813385009766
Validation loss: 2.2646202693382897

Epoch: 5| Step: 1
Training loss: 1.7208220958709717
Validation loss: 2.169824242591858

Epoch: 5| Step: 2
Training loss: 1.0761162042617798
Validation loss: 2.125216787060102

Epoch: 5| Step: 3
Training loss: 1.3486369848251343
Validation loss: 2.124442140261332

Epoch: 5| Step: 4
Training loss: 1.541765809059143
Validation loss: 2.194319779674212

Epoch: 5| Step: 5
Training loss: 0.9979140162467957
Validation loss: 2.1786277890205383

Epoch: 5| Step: 6
Training loss: 0.8649582862854004
Validation loss: 2.0925502280394235

Epoch: 5| Step: 7
Training loss: 1.7058448791503906
Validation loss: 2.1170024275779724

Epoch: 5| Step: 8
Training loss: 0.6128484010696411
Validation loss: 2.1510060876607895

Epoch: 5| Step: 9
Training loss: 1.6619306802749634
Validation loss: 2.195701057712237

Epoch: 5| Step: 10
Training loss: 1.257608413696289
Validation loss: 2.17807799577713

Epoch: 5| Step: 11
Training loss: 1.2254217863082886
Validation loss: 2.2460658897956214

Epoch: 134| Step: 0
Training loss: 1.2370848655700684
Validation loss: 2.199882452686628

Epoch: 5| Step: 1
Training loss: 1.4435192346572876
Validation loss: 2.3377559979756675

Epoch: 5| Step: 2
Training loss: 1.9118354320526123
Validation loss: 2.3435438573360443

Epoch: 5| Step: 3
Training loss: 1.4295353889465332
Validation loss: 2.297363961736361

Epoch: 5| Step: 4
Training loss: 1.114424467086792
Validation loss: 2.1748527387777963

Epoch: 5| Step: 5
Training loss: 1.4716434478759766
Validation loss: 2.1486103236675262

Epoch: 5| Step: 6
Training loss: 1.4476039409637451
Validation loss: 2.1384170105059943

Epoch: 5| Step: 7
Training loss: 1.0369043350219727
Validation loss: 2.1000917007525763

Epoch: 5| Step: 8
Training loss: 1.5675033330917358
Validation loss: 2.124230593442917

Epoch: 5| Step: 9
Training loss: 0.8470611572265625
Validation loss: 2.1410700579484305

Epoch: 5| Step: 10
Training loss: 1.4662113189697266
Validation loss: 2.104797119895617

Epoch: 5| Step: 11
Training loss: 1.0036652088165283
Validation loss: 2.1346979240576425

Epoch: 135| Step: 0
Training loss: 1.2486705780029297
Validation loss: 2.120855818192164

Epoch: 5| Step: 1
Training loss: 1.2578543424606323
Validation loss: 2.13066428899765

Epoch: 5| Step: 2
Training loss: 1.760862112045288
Validation loss: 2.1445241620143256

Epoch: 5| Step: 3
Training loss: 0.8181012868881226
Validation loss: 2.1033429702123008

Epoch: 5| Step: 4
Training loss: 1.06960129737854
Validation loss: 2.1670615822076797

Epoch: 5| Step: 5
Training loss: 1.2173528671264648
Validation loss: 2.1074059307575226

Epoch: 5| Step: 6
Training loss: 1.2296146154403687
Validation loss: 2.0893472731113434

Epoch: 5| Step: 7
Training loss: 1.3692209720611572
Validation loss: 2.122181052962939

Epoch: 5| Step: 8
Training loss: 1.0206656455993652
Validation loss: 2.12546036640803

Epoch: 5| Step: 9
Training loss: 1.1797353029251099
Validation loss: 2.1010523438453674

Epoch: 5| Step: 10
Training loss: 1.6407378911972046
Validation loss: 2.1273137032985687

Epoch: 5| Step: 11
Training loss: 0.9317783713340759
Validation loss: 2.088190649946531

Epoch: 136| Step: 0
Training loss: 1.5341565608978271
Validation loss: 2.1130723605553308

Epoch: 5| Step: 1
Training loss: 0.7627108693122864
Validation loss: 2.1551115612188974

Epoch: 5| Step: 2
Training loss: 0.8879461288452148
Validation loss: 2.1496244420607886

Epoch: 5| Step: 3
Training loss: 1.5044102668762207
Validation loss: 2.143655632932981

Epoch: 5| Step: 4
Training loss: 1.5062100887298584
Validation loss: 2.164423331618309

Epoch: 5| Step: 5
Training loss: 1.5091582536697388
Validation loss: 2.216556429862976

Epoch: 5| Step: 6
Training loss: 1.3874670267105103
Validation loss: 2.1742562601963678

Epoch: 5| Step: 7
Training loss: 1.228704810142517
Validation loss: 2.1797181169191995

Epoch: 5| Step: 8
Training loss: 0.8666417002677917
Validation loss: 2.1938553551832833

Epoch: 5| Step: 9
Training loss: 1.674538254737854
Validation loss: 2.174508959054947

Epoch: 5| Step: 10
Training loss: 0.7815220952033997
Validation loss: 2.128939757744471

Epoch: 5| Step: 11
Training loss: 1.072247862815857
Validation loss: 2.2041803747415543

Epoch: 137| Step: 0
Training loss: 1.2625579833984375
Validation loss: 2.1906180679798126

Epoch: 5| Step: 1
Training loss: 1.3816509246826172
Validation loss: 2.157681996623675

Epoch: 5| Step: 2
Training loss: 1.5249055624008179
Validation loss: 2.141235262155533

Epoch: 5| Step: 3
Training loss: 1.1677690744400024
Validation loss: 2.145400126775106

Epoch: 5| Step: 4
Training loss: 0.8320345878601074
Validation loss: 2.168608988324801

Epoch: 5| Step: 5
Training loss: 1.4495117664337158
Validation loss: 2.12555784980456

Epoch: 5| Step: 6
Training loss: 1.451695203781128
Validation loss: 2.195217748483022

Epoch: 5| Step: 7
Training loss: 0.9615781903266907
Validation loss: 2.1862566669782004

Epoch: 5| Step: 8
Training loss: 0.5101912617683411
Validation loss: 2.204196333885193

Epoch: 5| Step: 9
Training loss: 1.3996604681015015
Validation loss: 2.119099423289299

Epoch: 5| Step: 10
Training loss: 1.1555511951446533
Validation loss: 2.1214747528235116

Epoch: 5| Step: 11
Training loss: 2.4781179428100586
Validation loss: 2.120848129192988

Epoch: 138| Step: 0
Training loss: 1.001918077468872
Validation loss: 2.124128356575966

Epoch: 5| Step: 1
Training loss: 1.2506803274154663
Validation loss: 2.109212045868238

Epoch: 5| Step: 2
Training loss: 0.6230449676513672
Validation loss: 2.063365618387858

Epoch: 5| Step: 3
Training loss: 1.2774916887283325
Validation loss: 2.165553813179334

Epoch: 5| Step: 4
Training loss: 1.3423221111297607
Validation loss: 2.080071270465851

Epoch: 5| Step: 5
Training loss: 1.443647861480713
Validation loss: 2.081880753238996

Epoch: 5| Step: 6
Training loss: 0.9733943939208984
Validation loss: 2.120864669481913

Epoch: 5| Step: 7
Training loss: 1.0205137729644775
Validation loss: 2.2155213256676993

Epoch: 5| Step: 8
Training loss: 1.425887107849121
Validation loss: 2.2446835239728293

Epoch: 5| Step: 9
Training loss: 1.4405168294906616
Validation loss: 2.210266391436259

Epoch: 5| Step: 10
Training loss: 1.1872622966766357
Validation loss: 2.152647316455841

Epoch: 5| Step: 11
Training loss: 3.12539005279541
Validation loss: 2.1215396722157798

Epoch: 139| Step: 0
Training loss: 1.1293723583221436
Validation loss: 2.1989826560020447

Epoch: 5| Step: 1
Training loss: 1.0630890130996704
Validation loss: 2.1666221419970193

Epoch: 5| Step: 2
Training loss: 1.1144976615905762
Validation loss: 2.187948445479075

Epoch: 5| Step: 3
Training loss: 1.109202265739441
Validation loss: 2.123754362265269

Epoch: 5| Step: 4
Training loss: 1.0945205688476562
Validation loss: 2.1169817447662354

Epoch: 5| Step: 5
Training loss: 1.179944634437561
Validation loss: 2.210942804813385

Epoch: 5| Step: 6
Training loss: 1.328599214553833
Validation loss: 2.1530237197875977

Epoch: 5| Step: 7
Training loss: 1.5165841579437256
Validation loss: 2.172899161775907

Epoch: 5| Step: 8
Training loss: 1.058323860168457
Validation loss: 2.1885437866051993

Epoch: 5| Step: 9
Training loss: 1.0008457899093628
Validation loss: 2.060922841231028

Epoch: 5| Step: 10
Training loss: 1.219173550605774
Validation loss: 2.170696641008059

Epoch: 5| Step: 11
Training loss: 1.71775484085083
Validation loss: 2.157557855049769

Epoch: 140| Step: 0
Training loss: 1.3276211023330688
Validation loss: 2.1977039327224097

Epoch: 5| Step: 1
Training loss: 1.2413924932479858
Validation loss: 2.2411798735459647

Epoch: 5| Step: 2
Training loss: 1.136074423789978
Validation loss: 2.1556287556886673

Epoch: 5| Step: 3
Training loss: 1.2125701904296875
Validation loss: 2.17261511584123

Epoch: 5| Step: 4
Training loss: 1.435173749923706
Validation loss: 2.137416804830233

Epoch: 5| Step: 5
Training loss: 0.9805909395217896
Validation loss: 2.1874891271193824

Epoch: 5| Step: 6
Training loss: 0.7945141792297363
Validation loss: 2.1116835176944733

Epoch: 5| Step: 7
Training loss: 1.0350404977798462
Validation loss: 2.1746733486652374

Epoch: 5| Step: 8
Training loss: 1.0676953792572021
Validation loss: 2.1927050153414407

Epoch: 5| Step: 9
Training loss: 1.507710576057434
Validation loss: 2.1492062509059906

Epoch: 5| Step: 10
Training loss: 0.9891947507858276
Validation loss: 2.194505035877228

Epoch: 5| Step: 11
Training loss: 2.2456226348876953
Validation loss: 2.1355577806631723

Epoch: 141| Step: 0
Training loss: 0.9327031373977661
Validation loss: 2.1926227460304895

Epoch: 5| Step: 1
Training loss: 1.3526140451431274
Validation loss: 2.2052944352229438

Epoch: 5| Step: 2
Training loss: 1.1872062683105469
Validation loss: 2.211350460847219

Epoch: 5| Step: 3
Training loss: 1.0122312307357788
Validation loss: 2.2407830357551575

Epoch: 5| Step: 4
Training loss: 0.9732857942581177
Validation loss: 2.223986193537712

Epoch: 5| Step: 5
Training loss: 1.4485946893692017
Validation loss: 2.247811108827591

Epoch: 5| Step: 6
Training loss: 1.4673246145248413
Validation loss: 2.182818671067556

Epoch: 5| Step: 7
Training loss: 0.951633095741272
Validation loss: 2.1864056636889777

Epoch: 5| Step: 8
Training loss: 0.9215513467788696
Validation loss: 2.160767843325933

Epoch: 5| Step: 9
Training loss: 1.2541104555130005
Validation loss: 2.2119658490022025

Epoch: 5| Step: 10
Training loss: 1.2360869646072388
Validation loss: 2.1314880549907684

Epoch: 5| Step: 11
Training loss: 1.6801657676696777
Validation loss: 2.1366753230492272

Epoch: 142| Step: 0
Training loss: 1.7061220407485962
Validation loss: 2.1301189213991165

Epoch: 5| Step: 1
Training loss: 1.3957847356796265
Validation loss: 2.1436063398917518

Epoch: 5| Step: 2
Training loss: 1.2867549657821655
Validation loss: 2.136303255955378

Epoch: 5| Step: 3
Training loss: 1.3629299402236938
Validation loss: 2.1684465607007346

Epoch: 5| Step: 4
Training loss: 0.7106454968452454
Validation loss: 2.0930096904436746

Epoch: 5| Step: 5
Training loss: 1.2278406620025635
Validation loss: 2.145174687107404

Epoch: 5| Step: 6
Training loss: 1.2859925031661987
Validation loss: 2.155671179294586

Epoch: 5| Step: 7
Training loss: 0.9706789255142212
Validation loss: 2.1534913033246994

Epoch: 5| Step: 8
Training loss: 0.8632877469062805
Validation loss: 2.1775521437327066

Epoch: 5| Step: 9
Training loss: 0.33844879269599915
Validation loss: 2.138125648101171

Epoch: 5| Step: 10
Training loss: 1.429640293121338
Validation loss: 2.167459860444069

Epoch: 5| Step: 11
Training loss: 1.0818610191345215
Validation loss: 2.09736035267512

Epoch: 143| Step: 0
Training loss: 0.9479166269302368
Validation loss: 2.1202691992123923

Epoch: 5| Step: 1
Training loss: 1.485120177268982
Validation loss: 2.102224657932917

Epoch: 5| Step: 2
Training loss: 1.1889994144439697
Validation loss: 2.173938368757566

Epoch: 5| Step: 3
Training loss: 1.500631332397461
Validation loss: 2.1814149916172028

Epoch: 5| Step: 4
Training loss: 1.7027111053466797
Validation loss: 2.133758991956711

Epoch: 5| Step: 5
Training loss: 1.3460131883621216
Validation loss: 2.132262130578359

Epoch: 5| Step: 6
Training loss: 0.9467005729675293
Validation loss: 2.1027823438247046

Epoch: 5| Step: 7
Training loss: 1.2250611782073975
Validation loss: 2.155173644423485

Epoch: 5| Step: 8
Training loss: 1.1417032480239868
Validation loss: 2.0665220469236374

Epoch: 5| Step: 9
Training loss: 0.7047430872917175
Validation loss: 2.092036912838618

Epoch: 5| Step: 10
Training loss: 1.0655301809310913
Validation loss: 2.1397423148155212

Epoch: 5| Step: 11
Training loss: 2.187868118286133
Validation loss: 2.0937057584524155

Epoch: 144| Step: 0
Training loss: 0.8023670315742493
Validation loss: 2.065226083000501

Epoch: 5| Step: 1
Training loss: 0.8411027789115906
Validation loss: 2.2006370474894843

Epoch: 5| Step: 2
Training loss: 1.0377122163772583
Validation loss: 2.101946175098419

Epoch: 5| Step: 3
Training loss: 0.8717271685600281
Validation loss: 2.0987170189619064

Epoch: 5| Step: 4
Training loss: 0.9149492383003235
Validation loss: 2.1377109736204147

Epoch: 5| Step: 5
Training loss: 1.2414436340332031
Validation loss: 2.0911033699909845

Epoch: 5| Step: 6
Training loss: 1.325293779373169
Validation loss: 2.1107892791430154

Epoch: 5| Step: 7
Training loss: 1.4697251319885254
Validation loss: 2.1475141594807305

Epoch: 5| Step: 8
Training loss: 1.4520976543426514
Validation loss: 2.1018861134847007

Epoch: 5| Step: 9
Training loss: 0.9431962966918945
Validation loss: 2.142748609185219

Epoch: 5| Step: 10
Training loss: 1.6595056056976318
Validation loss: 2.153014838695526

Epoch: 5| Step: 11
Training loss: 1.893574833869934
Validation loss: 2.1189024448394775

Epoch: 145| Step: 0
Training loss: 1.0481042861938477
Validation loss: 2.15731010834376

Epoch: 5| Step: 1
Training loss: 1.0717417001724243
Validation loss: 2.139995555082957

Epoch: 5| Step: 2
Training loss: 1.5158429145812988
Validation loss: 2.1205235024293265

Epoch: 5| Step: 3
Training loss: 1.3796441555023193
Validation loss: 2.1156272242466607

Epoch: 5| Step: 4
Training loss: 1.2438170909881592
Validation loss: 2.180010661482811

Epoch: 5| Step: 5
Training loss: 1.0630104541778564
Validation loss: 2.10417041182518

Epoch: 5| Step: 6
Training loss: 1.1425479650497437
Validation loss: 2.1754156003395715

Epoch: 5| Step: 7
Training loss: 0.746485710144043
Validation loss: 2.1065958539644876

Epoch: 5| Step: 8
Training loss: 1.0051331520080566
Validation loss: 2.100676770011584

Epoch: 5| Step: 9
Training loss: 1.0921962261199951
Validation loss: 2.160547837615013

Epoch: 5| Step: 10
Training loss: 1.1736319065093994
Validation loss: 2.126078655322393

Epoch: 5| Step: 11
Training loss: 0.9549229145050049
Validation loss: 2.197187294562658

Epoch: 146| Step: 0
Training loss: 1.4815795421600342
Validation loss: 2.1649742970863977

Epoch: 5| Step: 1
Training loss: 0.9714189767837524
Validation loss: 2.2026460270086923

Epoch: 5| Step: 2
Training loss: 1.0039746761322021
Validation loss: 2.1441067904233932

Epoch: 5| Step: 3
Training loss: 0.8586384057998657
Validation loss: 2.184758558869362

Epoch: 5| Step: 4
Training loss: 1.1265170574188232
Validation loss: 2.274432977040609

Epoch: 5| Step: 5
Training loss: 0.937919020652771
Validation loss: 2.188048099478086

Epoch: 5| Step: 6
Training loss: 1.2955982685089111
Validation loss: 2.1576709548632302

Epoch: 5| Step: 7
Training loss: 1.0222220420837402
Validation loss: 2.1333315720160804

Epoch: 5| Step: 8
Training loss: 0.9286982417106628
Validation loss: 2.104726036389669

Epoch: 5| Step: 9
Training loss: 1.4437978267669678
Validation loss: 2.1329325636227927

Epoch: 5| Step: 10
Training loss: 1.1124012470245361
Validation loss: 2.157499556740125

Epoch: 5| Step: 11
Training loss: 0.7834147214889526
Validation loss: 2.1698205967744193

Epoch: 147| Step: 0
Training loss: 0.9640814065933228
Validation loss: 2.1531231154998145

Epoch: 5| Step: 1
Training loss: 1.376787781715393
Validation loss: 2.1158162405093512

Epoch: 5| Step: 2
Training loss: 1.0958495140075684
Validation loss: 2.1541083504756293

Epoch: 5| Step: 3
Training loss: 1.168444275856018
Validation loss: 2.1360985040664673

Epoch: 5| Step: 4
Training loss: 0.8969326019287109
Validation loss: 2.1622839272022247

Epoch: 5| Step: 5
Training loss: 1.6150343418121338
Validation loss: 2.193992887934049

Epoch: 5| Step: 6
Training loss: 1.1255038976669312
Validation loss: 2.195447305838267

Epoch: 5| Step: 7
Training loss: 0.9880515933036804
Validation loss: 2.1582451363404593

Epoch: 5| Step: 8
Training loss: 1.1415793895721436
Validation loss: 2.1558988243341446

Epoch: 5| Step: 9
Training loss: 0.9329109191894531
Validation loss: 2.134437625606855

Epoch: 5| Step: 10
Training loss: 1.137969732284546
Validation loss: 2.157830069462458

Epoch: 5| Step: 11
Training loss: 0.8330761790275574
Validation loss: 2.1155409812927246

Epoch: 148| Step: 0
Training loss: 1.376892328262329
Validation loss: 2.1530442386865616

Epoch: 5| Step: 1
Training loss: 1.0383894443511963
Validation loss: 2.1406982243061066

Epoch: 5| Step: 2
Training loss: 0.7841790318489075
Validation loss: 2.113060399889946

Epoch: 5| Step: 3
Training loss: 1.1194124221801758
Validation loss: 2.118254840373993

Epoch: 5| Step: 4
Training loss: 1.2104465961456299
Validation loss: 2.169863278667132

Epoch: 5| Step: 5
Training loss: 1.33699631690979
Validation loss: 2.0544624676307044

Epoch: 5| Step: 6
Training loss: 0.784508466720581
Validation loss: 2.1725407391786575

Epoch: 5| Step: 7
Training loss: 1.239580750465393
Validation loss: 2.1107381532589593

Epoch: 5| Step: 8
Training loss: 1.2388029098510742
Validation loss: 2.11639874180158

Epoch: 5| Step: 9
Training loss: 1.2366125583648682
Validation loss: 2.2072202265262604

Epoch: 5| Step: 10
Training loss: 0.8739854693412781
Validation loss: 2.138032913208008

Epoch: 5| Step: 11
Training loss: 0.26801156997680664
Validation loss: 2.142202506462733

Epoch: 149| Step: 0
Training loss: 0.8996465802192688
Validation loss: 2.135154982407888

Epoch: 5| Step: 1
Training loss: 1.180320382118225
Validation loss: 2.1153366565704346

Epoch: 5| Step: 2
Training loss: 0.9981845617294312
Validation loss: 2.2104782164096832

Epoch: 5| Step: 3
Training loss: 1.4093074798583984
Validation loss: 2.1764822751283646

Epoch: 5| Step: 4
Training loss: 1.454741358757019
Validation loss: 2.140823652346929

Epoch: 5| Step: 5
Training loss: 0.7946106195449829
Validation loss: 2.089204649130503

Epoch: 5| Step: 6
Training loss: 1.4113216400146484
Validation loss: 2.152572969595591

Epoch: 5| Step: 7
Training loss: 1.034759521484375
Validation loss: 2.1491078039010367

Epoch: 5| Step: 8
Training loss: 0.7326850295066833
Validation loss: 2.159895325700442

Epoch: 5| Step: 9
Training loss: 0.799098789691925
Validation loss: 2.1860913087924323

Epoch: 5| Step: 10
Training loss: 1.1464859247207642
Validation loss: 2.2133813301722207

Epoch: 5| Step: 11
Training loss: 1.5304837226867676
Validation loss: 2.237895463903745

Epoch: 150| Step: 0
Training loss: 1.6228153705596924
Validation loss: 2.1871860027313232

Epoch: 5| Step: 1
Training loss: 1.267823338508606
Validation loss: 2.189338649312655

Epoch: 5| Step: 2
Training loss: 0.7981817126274109
Validation loss: 2.0865109662214913

Epoch: 5| Step: 3
Training loss: 0.9154081344604492
Validation loss: 2.1535504112641015

Epoch: 5| Step: 4
Training loss: 1.092380166053772
Validation loss: 2.1700780789057412

Epoch: 5| Step: 5
Training loss: 1.0510928630828857
Validation loss: 2.190710778037707

Epoch: 5| Step: 6
Training loss: 1.217909812927246
Validation loss: 2.162184481819471

Epoch: 5| Step: 7
Training loss: 0.8801788091659546
Validation loss: 2.17817888657252

Epoch: 5| Step: 8
Training loss: 1.2659542560577393
Validation loss: 2.172547231117884

Epoch: 5| Step: 9
Training loss: 1.2363260984420776
Validation loss: 2.2092067946990332

Epoch: 5| Step: 10
Training loss: 0.7389206886291504
Validation loss: 2.252545783917109

Epoch: 5| Step: 11
Training loss: 1.4895784854888916
Validation loss: 2.227119271953901

Epoch: 151| Step: 0
Training loss: 1.1959162950515747
Validation loss: 2.1900688856840134

Epoch: 5| Step: 1
Training loss: 1.1001826524734497
Validation loss: 2.1609269430239997

Epoch: 5| Step: 2
Training loss: 0.9810802340507507
Validation loss: 2.101277326544126

Epoch: 5| Step: 3
Training loss: 0.9087494611740112
Validation loss: 2.1409031550089517

Epoch: 5| Step: 4
Training loss: 1.6057548522949219
Validation loss: 2.150084137916565

Epoch: 5| Step: 5
Training loss: 1.6733325719833374
Validation loss: 2.1803860614697137

Epoch: 5| Step: 6
Training loss: 0.9373941421508789
Validation loss: 2.1863749027252197

Epoch: 5| Step: 7
Training loss: 1.1021631956100464
Validation loss: 2.1527017702658973

Epoch: 5| Step: 8
Training loss: 0.8566972613334656
Validation loss: 2.130736584464709

Epoch: 5| Step: 9
Training loss: 1.0046535730361938
Validation loss: 2.1342141032218933

Epoch: 5| Step: 10
Training loss: 1.076266884803772
Validation loss: 2.2415618300437927

Epoch: 5| Step: 11
Training loss: 0.6391948461532593
Validation loss: 2.114903603990873

Epoch: 152| Step: 0
Training loss: 1.4799424409866333
Validation loss: 2.1649377097686133

Epoch: 5| Step: 1
Training loss: 0.6614325046539307
Validation loss: 2.173042138417562

Epoch: 5| Step: 2
Training loss: 0.9921765327453613
Validation loss: 2.1559095780054727

Epoch: 5| Step: 3
Training loss: 1.3291809558868408
Validation loss: 2.1514890690644584

Epoch: 5| Step: 4
Training loss: 0.6831151247024536
Validation loss: 2.15693469842275

Epoch: 5| Step: 5
Training loss: 0.7451757192611694
Validation loss: 2.1633825500806174

Epoch: 5| Step: 6
Training loss: 1.4180556535720825
Validation loss: 2.0876205563545227

Epoch: 5| Step: 7
Training loss: 1.1497008800506592
Validation loss: 2.233079378803571

Epoch: 5| Step: 8
Training loss: 1.4898228645324707
Validation loss: 2.2254639019568763

Epoch: 5| Step: 9
Training loss: 1.6094862222671509
Validation loss: 2.2213492492834725

Epoch: 5| Step: 10
Training loss: 0.6506403684616089
Validation loss: 2.1701837877432504

Epoch: 5| Step: 11
Training loss: 0.854838490486145
Validation loss: 2.218772699435552

Epoch: 153| Step: 0
Training loss: 1.2205073833465576
Validation loss: 2.180331900715828

Epoch: 5| Step: 1
Training loss: 1.1718286275863647
Validation loss: 2.2077297270298004

Epoch: 5| Step: 2
Training loss: 1.0109479427337646
Validation loss: 2.2158470104138055

Epoch: 5| Step: 3
Training loss: 1.4179317951202393
Validation loss: 2.183534642060598

Epoch: 5| Step: 4
Training loss: 0.7131391763687134
Validation loss: 2.168160264690717

Epoch: 5| Step: 5
Training loss: 1.0151100158691406
Validation loss: 2.2323750058809915

Epoch: 5| Step: 6
Training loss: 0.5259001851081848
Validation loss: 2.2035436729590097

Epoch: 5| Step: 7
Training loss: 1.388654112815857
Validation loss: 2.1843366622924805

Epoch: 5| Step: 8
Training loss: 1.2253572940826416
Validation loss: 2.1174455831448236

Epoch: 5| Step: 9
Training loss: 1.1231451034545898
Validation loss: 2.1607562750577927

Epoch: 5| Step: 10
Training loss: 1.0394172668457031
Validation loss: 2.151786287625631

Epoch: 5| Step: 11
Training loss: 0.8414692878723145
Validation loss: 2.1739722987016044

Epoch: 154| Step: 0
Training loss: 1.1168497800827026
Validation loss: 2.0903889387845993

Epoch: 5| Step: 1
Training loss: 1.3289270401000977
Validation loss: 2.192520186305046

Epoch: 5| Step: 2
Training loss: 1.2287144660949707
Validation loss: 2.095500409603119

Epoch: 5| Step: 3
Training loss: 1.0298712253570557
Validation loss: 2.2224237422148385

Epoch: 5| Step: 4
Training loss: 0.7056939005851746
Validation loss: 2.2160035421450934

Epoch: 5| Step: 5
Training loss: 0.8663312792778015
Validation loss: 2.2571711341540017

Epoch: 5| Step: 6
Training loss: 1.4142183065414429
Validation loss: 2.2298839886983237

Epoch: 5| Step: 7
Training loss: 1.0957603454589844
Validation loss: 2.287151445945104

Epoch: 5| Step: 8
Training loss: 0.8964994549751282
Validation loss: 2.19077438612779

Epoch: 5| Step: 9
Training loss: 1.3107973337173462
Validation loss: 2.2953616430362067

Epoch: 5| Step: 10
Training loss: 0.86216801404953
Validation loss: 2.1521268983682

Epoch: 5| Step: 11
Training loss: 0.9095528721809387
Validation loss: 2.2310711493094764

Epoch: 155| Step: 0
Training loss: 0.9218804240226746
Validation loss: 2.1877014338970184

Epoch: 5| Step: 1
Training loss: 0.7161646485328674
Validation loss: 2.125340983271599

Epoch: 5| Step: 2
Training loss: 1.010498046875
Validation loss: 2.1947878946860633

Epoch: 5| Step: 3
Training loss: 0.9553132057189941
Validation loss: 2.2211820234855018

Epoch: 5| Step: 4
Training loss: 0.745112419128418
Validation loss: 2.115666146079699

Epoch: 5| Step: 5
Training loss: 1.581878900527954
Validation loss: 2.1300707310438156

Epoch: 5| Step: 6
Training loss: 0.7316794395446777
Validation loss: 2.198815902074178

Epoch: 5| Step: 7
Training loss: 1.1543734073638916
Validation loss: 2.2037952144940696

Epoch: 5| Step: 8
Training loss: 1.236471176147461
Validation loss: 2.2181087136268616

Epoch: 5| Step: 9
Training loss: 1.2379554510116577
Validation loss: 2.198976362744967

Epoch: 5| Step: 10
Training loss: 1.2904939651489258
Validation loss: 2.299898182352384

Epoch: 5| Step: 11
Training loss: 2.3746161460876465
Validation loss: 2.264793003598849

Epoch: 156| Step: 0
Training loss: 0.8018218874931335
Validation loss: 2.2312918454408646

Epoch: 5| Step: 1
Training loss: 1.3249495029449463
Validation loss: 2.179983456929525

Epoch: 5| Step: 2
Training loss: 1.0634815692901611
Validation loss: 2.166800618171692

Epoch: 5| Step: 3
Training loss: 0.9369038343429565
Validation loss: 2.132597585519155

Epoch: 5| Step: 4
Training loss: 1.0055949687957764
Validation loss: 2.162045101324717

Epoch: 5| Step: 5
Training loss: 0.9818779230117798
Validation loss: 2.0992501427729926

Epoch: 5| Step: 6
Training loss: 1.1379891633987427
Validation loss: 2.133541057507197

Epoch: 5| Step: 7
Training loss: 1.1511688232421875
Validation loss: 2.1310762067635856

Epoch: 5| Step: 8
Training loss: 0.9150802493095398
Validation loss: 2.1274650593598685

Epoch: 5| Step: 9
Training loss: 0.879403293132782
Validation loss: 2.109295686086019

Epoch: 5| Step: 10
Training loss: 1.6614145040512085
Validation loss: 2.197934036453565

Epoch: 5| Step: 11
Training loss: 0.631945013999939
Validation loss: 2.1733975410461426

Epoch: 157| Step: 0
Training loss: 1.1901521682739258
Validation loss: 2.2048665384451547

Epoch: 5| Step: 1
Training loss: 1.0246914625167847
Validation loss: 2.1691937992970147

Epoch: 5| Step: 2
Training loss: 0.7041314244270325
Validation loss: 2.143409257133802

Epoch: 5| Step: 3
Training loss: 0.5786265730857849
Validation loss: 2.1544084002574286

Epoch: 5| Step: 4
Training loss: 0.6984634399414062
Validation loss: 2.175904313723246

Epoch: 5| Step: 5
Training loss: 1.0740087032318115
Validation loss: 2.114552135268847

Epoch: 5| Step: 6
Training loss: 0.7112098932266235
Validation loss: 2.157415250937144

Epoch: 5| Step: 7
Training loss: 1.2618329524993896
Validation loss: 2.1310387353102365

Epoch: 5| Step: 8
Training loss: 1.18674635887146
Validation loss: 2.160447880625725

Epoch: 5| Step: 9
Training loss: 1.2407172918319702
Validation loss: 2.081667015949885

Epoch: 5| Step: 10
Training loss: 1.4535338878631592
Validation loss: 2.1707449009021125

Epoch: 5| Step: 11
Training loss: 2.422459602355957
Validation loss: 2.167086660861969

Epoch: 158| Step: 0
Training loss: 1.027888298034668
Validation loss: 2.1739992201328278

Epoch: 5| Step: 1
Training loss: 1.1948786973953247
Validation loss: 2.191679527362188

Epoch: 5| Step: 2
Training loss: 0.9154388308525085
Validation loss: 2.1503873765468597

Epoch: 5| Step: 3
Training loss: 1.116996169090271
Validation loss: 2.0770371009906134

Epoch: 5| Step: 4
Training loss: 0.5103527307510376
Validation loss: 2.1552750070889792

Epoch: 5| Step: 5
Training loss: 1.0078977346420288
Validation loss: 2.0876562297344208

Epoch: 5| Step: 6
Training loss: 1.0006550550460815
Validation loss: 2.183857172727585

Epoch: 5| Step: 7
Training loss: 1.4848310947418213
Validation loss: 2.23556479314963

Epoch: 5| Step: 8
Training loss: 1.1082547903060913
Validation loss: 2.2459146678447723

Epoch: 5| Step: 9
Training loss: 1.2813987731933594
Validation loss: 2.269733875989914

Epoch: 5| Step: 10
Training loss: 1.2809474468231201
Validation loss: 2.318805625041326

Epoch: 5| Step: 11
Training loss: 0.5392045974731445
Validation loss: 2.2414243519306183

Epoch: 159| Step: 0
Training loss: 0.7678815126419067
Validation loss: 2.191481128334999

Epoch: 5| Step: 1
Training loss: 1.1426080465316772
Validation loss: 2.245157226920128

Epoch: 5| Step: 2
Training loss: 1.0763801336288452
Validation loss: 2.165559709072113

Epoch: 5| Step: 3
Training loss: 1.262158751487732
Validation loss: 2.144897406299909

Epoch: 5| Step: 4
Training loss: 0.8750735521316528
Validation loss: 2.2215226888656616

Epoch: 5| Step: 5
Training loss: 1.2266654968261719
Validation loss: 2.100263441602389

Epoch: 5| Step: 6
Training loss: 1.17954421043396
Validation loss: 2.1447300414244332

Epoch: 5| Step: 7
Training loss: 1.2339670658111572
Validation loss: 2.2261501948038735

Epoch: 5| Step: 8
Training loss: 1.1404398679733276
Validation loss: 2.1768286923567453

Epoch: 5| Step: 9
Training loss: 0.8338033556938171
Validation loss: 2.193002079923948

Epoch: 5| Step: 10
Training loss: 1.562451720237732
Validation loss: 2.187943751613299

Epoch: 5| Step: 11
Training loss: 1.40859055519104
Validation loss: 2.2539831648270288

Epoch: 160| Step: 0
Training loss: 0.7695810198783875
Validation loss: 2.2443465689818063

Epoch: 5| Step: 1
Training loss: 0.9408407211303711
Validation loss: 2.176092892885208

Epoch: 5| Step: 2
Training loss: 1.1585743427276611
Validation loss: 2.161781514684359

Epoch: 5| Step: 3
Training loss: 1.1499757766723633
Validation loss: 2.1688977231582007

Epoch: 5| Step: 4
Training loss: 0.8219687342643738
Validation loss: 2.163080260157585

Epoch: 5| Step: 5
Training loss: 1.208904504776001
Validation loss: 2.103021815419197

Epoch: 5| Step: 6
Training loss: 1.1179225444793701
Validation loss: 2.0986110319693885

Epoch: 5| Step: 7
Training loss: 0.9326715469360352
Validation loss: 2.1293613463640213

Epoch: 5| Step: 8
Training loss: 0.8969861268997192
Validation loss: 2.131178985039393

Epoch: 5| Step: 9
Training loss: 1.447361946105957
Validation loss: 2.171727846066157

Epoch: 5| Step: 10
Training loss: 0.9374656677246094
Validation loss: 2.1793502817551293

Epoch: 5| Step: 11
Training loss: 0.26494258642196655
Validation loss: 2.2058951010306678

Epoch: 161| Step: 0
Training loss: 0.9049667119979858
Validation loss: 2.1746771931648254

Epoch: 5| Step: 1
Training loss: 0.9336250424385071
Validation loss: 2.2080354541540146

Epoch: 5| Step: 2
Training loss: 1.1233057975769043
Validation loss: 2.1773699720700583

Epoch: 5| Step: 3
Training loss: 0.5034618377685547
Validation loss: 2.1389181713263192

Epoch: 5| Step: 4
Training loss: 0.567213237285614
Validation loss: 2.148001948992411

Epoch: 5| Step: 5
Training loss: 1.2173564434051514
Validation loss: 2.199613188703855

Epoch: 5| Step: 6
Training loss: 1.1395496129989624
Validation loss: 2.159456650416056

Epoch: 5| Step: 7
Training loss: 2.1103363037109375
Validation loss: 2.186962683995565

Epoch: 5| Step: 8
Training loss: 1.313556432723999
Validation loss: 2.1689551721016564

Epoch: 5| Step: 9
Training loss: 0.8697983026504517
Validation loss: 2.1338473558425903

Epoch: 5| Step: 10
Training loss: 1.0764496326446533
Validation loss: 2.1473584274450936

Epoch: 5| Step: 11
Training loss: 0.4396045207977295
Validation loss: 2.2033958236376443

Epoch: 162| Step: 0
Training loss: 0.9193261861801147
Validation loss: 2.20192422469457

Epoch: 5| Step: 1
Training loss: 0.48682457208633423
Validation loss: 2.2263928651809692

Epoch: 5| Step: 2
Training loss: 1.0764938592910767
Validation loss: 2.187563478946686

Epoch: 5| Step: 3
Training loss: 0.6897436380386353
Validation loss: 2.1757035901149115

Epoch: 5| Step: 4
Training loss: 1.2829480171203613
Validation loss: 2.2848022480805716

Epoch: 5| Step: 5
Training loss: 1.2664769887924194
Validation loss: 2.2359750966231027

Epoch: 5| Step: 6
Training loss: 1.0922706127166748
Validation loss: 2.2447334825992584

Epoch: 5| Step: 7
Training loss: 0.9141255617141724
Validation loss: 2.2047393719355264

Epoch: 5| Step: 8
Training loss: 1.4222173690795898
Validation loss: 2.1912508805592856

Epoch: 5| Step: 9
Training loss: 0.5926839113235474
Validation loss: 2.1874097486337027

Epoch: 5| Step: 10
Training loss: 1.107092022895813
Validation loss: 2.2090571324030557

Epoch: 5| Step: 11
Training loss: 1.3338687419891357
Validation loss: 2.1737890293200812

Epoch: 163| Step: 0
Training loss: 1.1650986671447754
Validation loss: 2.207625761628151

Epoch: 5| Step: 1
Training loss: 1.2693679332733154
Validation loss: 2.1760260661443076

Epoch: 5| Step: 2
Training loss: 0.7728003859519958
Validation loss: 2.181962544719378

Epoch: 5| Step: 3
Training loss: 0.9442964792251587
Validation loss: 2.173527871568998

Epoch: 5| Step: 4
Training loss: 0.9738610982894897
Validation loss: 2.162362262606621

Epoch: 5| Step: 5
Training loss: 1.100383996963501
Validation loss: 2.1881217112143836

Epoch: 5| Step: 6
Training loss: 1.0700606107711792
Validation loss: 2.2039597680171332

Epoch: 5| Step: 7
Training loss: 0.8921079635620117
Validation loss: 2.1280958155790963

Epoch: 5| Step: 8
Training loss: 1.0431387424468994
Validation loss: 2.127986470858256

Epoch: 5| Step: 9
Training loss: 0.8779706954956055
Validation loss: 2.1461412459611893

Epoch: 5| Step: 10
Training loss: 0.8599802255630493
Validation loss: 2.1288734823465347

Epoch: 5| Step: 11
Training loss: 0.7544209957122803
Validation loss: 2.174024060368538

Epoch: 164| Step: 0
Training loss: 0.850621223449707
Validation loss: 2.1985674599806466

Epoch: 5| Step: 1
Training loss: 0.6780344247817993
Validation loss: 2.2094112435976663

Epoch: 5| Step: 2
Training loss: 0.8297266960144043
Validation loss: 2.1951895157496133

Epoch: 5| Step: 3
Training loss: 1.3040390014648438
Validation loss: 2.1938121616840363

Epoch: 5| Step: 4
Training loss: 0.9639607667922974
Validation loss: 2.195908010005951

Epoch: 5| Step: 5
Training loss: 0.7964932918548584
Validation loss: 2.1793237129847207

Epoch: 5| Step: 6
Training loss: 1.2131659984588623
Validation loss: 2.1635644733905792

Epoch: 5| Step: 7
Training loss: 1.554083228111267
Validation loss: 2.1410037080446878

Epoch: 5| Step: 8
Training loss: 0.8431436419487
Validation loss: 2.0698503901561103

Epoch: 5| Step: 9
Training loss: 1.3347556591033936
Validation loss: 2.1960764477650323

Epoch: 5| Step: 10
Training loss: 0.9465400576591492
Validation loss: 2.1695925494035087

Epoch: 5| Step: 11
Training loss: 0.28591978549957275
Validation loss: 2.163488730788231

Epoch: 165| Step: 0
Training loss: 0.975509524345398
Validation loss: 2.1542312453190484

Epoch: 5| Step: 1
Training loss: 1.0293048620224
Validation loss: 2.193282276391983

Epoch: 5| Step: 2
Training loss: 1.4826693534851074
Validation loss: 2.2303288330634436

Epoch: 5| Step: 3
Training loss: 0.9506314396858215
Validation loss: 2.216145565112432

Epoch: 5| Step: 4
Training loss: 1.0808982849121094
Validation loss: 2.244438444574674

Epoch: 5| Step: 5
Training loss: 0.950809121131897
Validation loss: 2.204593002796173

Epoch: 5| Step: 6
Training loss: 0.4478131830692291
Validation loss: 2.1938651651144028

Epoch: 5| Step: 7
Training loss: 0.7569937705993652
Validation loss: 2.146326740582784

Epoch: 5| Step: 8
Training loss: 1.267116665840149
Validation loss: 2.1602799048026404

Epoch: 5| Step: 9
Training loss: 1.3452138900756836
Validation loss: 2.2370788951714835

Epoch: 5| Step: 10
Training loss: 0.6744356155395508
Validation loss: 2.158155937989553

Epoch: 5| Step: 11
Training loss: 0.8871499300003052
Validation loss: 2.0969650646050773

Epoch: 166| Step: 0
Training loss: 1.3722233772277832
Validation loss: 2.241408626238505

Epoch: 5| Step: 1
Training loss: 0.6995809674263
Validation loss: 2.162591204047203

Epoch: 5| Step: 2
Training loss: 0.8380082845687866
Validation loss: 2.2216274589300156

Epoch: 5| Step: 3
Training loss: 1.0596721172332764
Validation loss: 2.1752836306889853

Epoch: 5| Step: 4
Training loss: 0.9432239532470703
Validation loss: 2.146896551052729

Epoch: 5| Step: 5
Training loss: 1.235062837600708
Validation loss: 2.1892807682355246

Epoch: 5| Step: 6
Training loss: 0.9490114450454712
Validation loss: 2.1039937237898507

Epoch: 5| Step: 7
Training loss: 0.5387611389160156
Validation loss: 2.1521975745757422

Epoch: 5| Step: 8
Training loss: 1.02167546749115
Validation loss: 2.112210581700007

Epoch: 5| Step: 9
Training loss: 1.0778238773345947
Validation loss: 2.174931690096855

Epoch: 5| Step: 10
Training loss: 1.0615483522415161
Validation loss: 2.1733544021844864

Epoch: 5| Step: 11
Training loss: 0.3187626004219055
Validation loss: 2.132651408513387

Epoch: 167| Step: 0
Training loss: 1.185960292816162
Validation loss: 2.088814854621887

Epoch: 5| Step: 1
Training loss: 1.1119320392608643
Validation loss: 2.19902695218722

Epoch: 5| Step: 2
Training loss: 0.7517404556274414
Validation loss: 2.179495796561241

Epoch: 5| Step: 3
Training loss: 0.9516448974609375
Validation loss: 2.1962705552577972

Epoch: 5| Step: 4
Training loss: 1.0901535749435425
Validation loss: 2.1901798446973166

Epoch: 5| Step: 5
Training loss: 1.0646135807037354
Validation loss: 2.2073062856992087

Epoch: 5| Step: 6
Training loss: 0.696527898311615
Validation loss: 2.17143244544665

Epoch: 5| Step: 7
Training loss: 1.2200922966003418
Validation loss: 2.1832337180773416

Epoch: 5| Step: 8
Training loss: 0.5695385932922363
Validation loss: 2.1864628891150155

Epoch: 5| Step: 9
Training loss: 0.619730532169342
Validation loss: 2.177388002475103

Epoch: 5| Step: 10
Training loss: 1.1796884536743164
Validation loss: 2.150765433907509

Epoch: 5| Step: 11
Training loss: 1.9483277797698975
Validation loss: 2.125872880220413

Epoch: 168| Step: 0
Training loss: 0.8085408210754395
Validation loss: 2.1739719758431115

Epoch: 5| Step: 1
Training loss: 1.0640283823013306
Validation loss: 2.075419823328654

Epoch: 5| Step: 2
Training loss: 0.6487455368041992
Validation loss: 2.186924561858177

Epoch: 5| Step: 3
Training loss: 0.7363471388816833
Validation loss: 2.129418815175692

Epoch: 5| Step: 4
Training loss: 1.072304129600525
Validation loss: 2.165017848213514

Epoch: 5| Step: 5
Training loss: 1.3457715511322021
Validation loss: 2.1748197078704834

Epoch: 5| Step: 6
Training loss: 0.9916706085205078
Validation loss: 2.1538036415974298

Epoch: 5| Step: 7
Training loss: 0.899920642375946
Validation loss: 2.184595068295797

Epoch: 5| Step: 8
Training loss: 0.6307801008224487
Validation loss: 2.1661339501539865

Epoch: 5| Step: 9
Training loss: 1.2803276777267456
Validation loss: 2.1592372059822083

Epoch: 5| Step: 10
Training loss: 0.9391424059867859
Validation loss: 2.162660693128904

Epoch: 5| Step: 11
Training loss: 1.055665135383606
Validation loss: 2.129043777783712

Epoch: 169| Step: 0
Training loss: 0.6732938885688782
Validation loss: 2.176538437604904

Epoch: 5| Step: 1
Training loss: 0.9748321771621704
Validation loss: 2.1867071042458215

Epoch: 5| Step: 2
Training loss: 1.2996892929077148
Validation loss: 2.173430616656939

Epoch: 5| Step: 3
Training loss: 1.3507105112075806
Validation loss: 2.2009997963905334

Epoch: 5| Step: 4
Training loss: 0.6425913572311401
Validation loss: 2.183094968398412

Epoch: 5| Step: 5
Training loss: 0.9130489230155945
Validation loss: 2.1153925706942878

Epoch: 5| Step: 6
Training loss: 0.6057383418083191
Validation loss: 2.183837632338206

Epoch: 5| Step: 7
Training loss: 1.1249244213104248
Validation loss: 2.2051544338464737

Epoch: 5| Step: 8
Training loss: 1.037011742591858
Validation loss: 2.2144025762875876

Epoch: 5| Step: 9
Training loss: 0.9421375393867493
Validation loss: 2.160475512345632

Epoch: 5| Step: 10
Training loss: 1.2246050834655762
Validation loss: 2.189004505674044

Epoch: 5| Step: 11
Training loss: 0.39545905590057373
Validation loss: 2.2204482654730477

Epoch: 170| Step: 0
Training loss: 1.0599844455718994
Validation loss: 2.301672493418058

Epoch: 5| Step: 1
Training loss: 1.0140526294708252
Validation loss: 2.258967379728953

Epoch: 5| Step: 2
Training loss: 0.8769054412841797
Validation loss: 2.3309651017189026

Epoch: 5| Step: 3
Training loss: 1.1702169179916382
Validation loss: 2.1926815708478293

Epoch: 5| Step: 4
Training loss: 0.5489464998245239
Validation loss: 2.160461351275444

Epoch: 5| Step: 5
Training loss: 1.0970014333724976
Validation loss: 2.095943177739779

Epoch: 5| Step: 6
Training loss: 1.0044721364974976
Validation loss: 2.1426435708999634

Epoch: 5| Step: 7
Training loss: 1.3341165781021118
Validation loss: 2.1470718383789062

Epoch: 5| Step: 8
Training loss: 1.07333242893219
Validation loss: 2.0770759085814157

Epoch: 5| Step: 9
Training loss: 1.11203932762146
Validation loss: 2.1404271523157754

Epoch: 5| Step: 10
Training loss: 1.3685280084609985
Validation loss: 2.19795161485672

Epoch: 5| Step: 11
Training loss: 0.7469238042831421
Validation loss: 2.1499971797068915

Epoch: 171| Step: 0
Training loss: 1.0029828548431396
Validation loss: 2.238105004032453

Epoch: 5| Step: 1
Training loss: 1.5535582304000854
Validation loss: 2.320324271917343

Epoch: 5| Step: 2
Training loss: 1.0719492435455322
Validation loss: 2.3881993293762207

Epoch: 5| Step: 3
Training loss: 1.558082938194275
Validation loss: 2.302726060152054

Epoch: 5| Step: 4
Training loss: 0.9491685628890991
Validation loss: 2.3195607662200928

Epoch: 5| Step: 5
Training loss: 1.0367848873138428
Validation loss: 2.3451306968927383

Epoch: 5| Step: 6
Training loss: 0.6871374845504761
Validation loss: 2.2254919509092965

Epoch: 5| Step: 7
Training loss: 0.9047924876213074
Validation loss: 2.155259743332863

Epoch: 5| Step: 8
Training loss: 0.8968518972396851
Validation loss: 2.165953437487284

Epoch: 5| Step: 9
Training loss: 1.2816078662872314
Validation loss: 2.1810696770747504

Epoch: 5| Step: 10
Training loss: 1.1026298999786377
Validation loss: 2.200917641321818

Epoch: 5| Step: 11
Training loss: 0.46929556131362915
Validation loss: 2.1647159854571023

Epoch: 172| Step: 0
Training loss: 1.534672737121582
Validation loss: 2.173379749059677

Epoch: 5| Step: 1
Training loss: 0.8421537280082703
Validation loss: 2.1476467549800873

Epoch: 5| Step: 2
Training loss: 0.8575336337089539
Validation loss: 2.173426568508148

Epoch: 5| Step: 3
Training loss: 1.0754042863845825
Validation loss: 2.205083211263021

Epoch: 5| Step: 4
Training loss: 0.8906005620956421
Validation loss: 2.191075543562571

Epoch: 5| Step: 5
Training loss: 1.1422827243804932
Validation loss: 2.2541174391905465

Epoch: 5| Step: 6
Training loss: 0.7532699704170227
Validation loss: 2.149830092986425

Epoch: 5| Step: 7
Training loss: 0.8603237271308899
Validation loss: 2.1793424834807715

Epoch: 5| Step: 8
Training loss: 0.7898985743522644
Validation loss: 2.181943789124489

Epoch: 5| Step: 9
Training loss: 0.6654677391052246
Validation loss: 2.175306702653567

Epoch: 5| Step: 10
Training loss: 1.2091416120529175
Validation loss: 2.1660596231619516

Epoch: 5| Step: 11
Training loss: 0.5993108153343201
Validation loss: 2.1076171646515527

Epoch: 173| Step: 0
Training loss: 1.123862862586975
Validation loss: 2.2177870074907937

Epoch: 5| Step: 1
Training loss: 1.3520090579986572
Validation loss: 2.148358235756556

Epoch: 5| Step: 2
Training loss: 0.925942599773407
Validation loss: 2.1636372208595276

Epoch: 5| Step: 3
Training loss: 1.1391732692718506
Validation loss: 2.2237644543250403

Epoch: 5| Step: 4
Training loss: 0.7641842365264893
Validation loss: 2.221780170996984

Epoch: 5| Step: 5
Training loss: 1.089858055114746
Validation loss: 2.201635772983233

Epoch: 5| Step: 6
Training loss: 1.2822120189666748
Validation loss: 2.159959395726522

Epoch: 5| Step: 7
Training loss: 1.317560076713562
Validation loss: 2.1463298400243125

Epoch: 5| Step: 8
Training loss: 0.8304018974304199
Validation loss: 2.2076893349488578

Epoch: 5| Step: 9
Training loss: 0.7150830030441284
Validation loss: 2.165249248345693

Epoch: 5| Step: 10
Training loss: 0.7209024429321289
Validation loss: 2.174417659640312

Epoch: 5| Step: 11
Training loss: 0.6091771125793457
Validation loss: 2.1788244942824044

Epoch: 174| Step: 0
Training loss: 0.7258695363998413
Validation loss: 2.1824100067218146

Epoch: 5| Step: 1
Training loss: 1.1735928058624268
Validation loss: 2.227688511212667

Epoch: 5| Step: 2
Training loss: 1.1920174360275269
Validation loss: 2.228023886680603

Epoch: 5| Step: 3
Training loss: 1.349778652191162
Validation loss: 2.172352949778239

Epoch: 5| Step: 4
Training loss: 1.0016412734985352
Validation loss: 2.159215420484543

Epoch: 5| Step: 5
Training loss: 1.1128454208374023
Validation loss: 2.1233487079540887

Epoch: 5| Step: 6
Training loss: 0.5675988793373108
Validation loss: 2.157561868429184

Epoch: 5| Step: 7
Training loss: 1.3348106145858765
Validation loss: 2.1483403692642846

Epoch: 5| Step: 8
Training loss: 0.6206455230712891
Validation loss: 2.147519956032435

Epoch: 5| Step: 9
Training loss: 1.0410575866699219
Validation loss: 2.1583492904901505

Epoch: 5| Step: 10
Training loss: 0.8815142512321472
Validation loss: 2.1491015553474426

Epoch: 5| Step: 11
Training loss: 1.3287711143493652
Validation loss: 2.118587856491407

Epoch: 175| Step: 0
Training loss: 0.6674325466156006
Validation loss: 2.068313995997111

Epoch: 5| Step: 1
Training loss: 0.8166384696960449
Validation loss: 2.1011285384496055

Epoch: 5| Step: 2
Training loss: 1.8747930526733398
Validation loss: 2.141455203294754

Epoch: 5| Step: 3
Training loss: 0.8620797991752625
Validation loss: 2.1947327057520547

Epoch: 5| Step: 4
Training loss: 0.6181899905204773
Validation loss: 2.1192569633324942

Epoch: 5| Step: 5
Training loss: 1.510869026184082
Validation loss: 2.164219617843628

Epoch: 5| Step: 6
Training loss: 0.8134128451347351
Validation loss: 2.1536924690008163

Epoch: 5| Step: 7
Training loss: 0.7952365279197693
Validation loss: 2.097644438346227

Epoch: 5| Step: 8
Training loss: 0.7060544490814209
Validation loss: 2.1475457549095154

Epoch: 5| Step: 9
Training loss: 0.8639057874679565
Validation loss: 2.157569080591202

Epoch: 5| Step: 10
Training loss: 0.8823955655097961
Validation loss: 2.1329500724871955

Epoch: 5| Step: 11
Training loss: 0.8941724896430969
Validation loss: 2.1571940183639526

Epoch: 176| Step: 0
Training loss: 0.870143711566925
Validation loss: 2.149255762497584

Epoch: 5| Step: 1
Training loss: 0.77923583984375
Validation loss: 2.1401535918315253

Epoch: 5| Step: 2
Training loss: 0.5672744512557983
Validation loss: 2.143225759267807

Epoch: 5| Step: 3
Training loss: 0.6397234797477722
Validation loss: 2.087150439620018

Epoch: 5| Step: 4
Training loss: 0.9064321517944336
Validation loss: 2.132821803291639

Epoch: 5| Step: 5
Training loss: 0.6736995577812195
Validation loss: 2.155354748169581

Epoch: 5| Step: 6
Training loss: 1.2549549341201782
Validation loss: 2.1648619969685874

Epoch: 5| Step: 7
Training loss: 0.6414240002632141
Validation loss: 2.12807826201121

Epoch: 5| Step: 8
Training loss: 1.0641757249832153
Validation loss: 2.195062572757403

Epoch: 5| Step: 9
Training loss: 1.6032860279083252
Validation loss: 2.194490904609362

Epoch: 5| Step: 10
Training loss: 0.7516017556190491
Validation loss: 2.239056259393692

Epoch: 5| Step: 11
Training loss: 1.9529393911361694
Validation loss: 2.1945558041334152

Epoch: 177| Step: 0
Training loss: 0.7916819453239441
Validation loss: 2.189906820654869

Epoch: 5| Step: 1
Training loss: 1.1414687633514404
Validation loss: 2.14793569346269

Epoch: 5| Step: 2
Training loss: 1.0045135021209717
Validation loss: 2.1583296060562134

Epoch: 5| Step: 3
Training loss: 0.9544761776924133
Validation loss: 2.180663858850797

Epoch: 5| Step: 4
Training loss: 0.7420129776000977
Validation loss: 2.184451629718145

Epoch: 5| Step: 5
Training loss: 0.6080044507980347
Validation loss: 2.2410361617803574

Epoch: 5| Step: 6
Training loss: 0.9234977960586548
Validation loss: 2.1856486797332764

Epoch: 5| Step: 7
Training loss: 1.3524019718170166
Validation loss: 2.181473126014074

Epoch: 5| Step: 8
Training loss: 1.1225812435150146
Validation loss: 2.2400958041350045

Epoch: 5| Step: 9
Training loss: 0.9262169003486633
Validation loss: 2.2601758390665054

Epoch: 5| Step: 10
Training loss: 1.148850679397583
Validation loss: 2.228774150212606

Epoch: 5| Step: 11
Training loss: 0.6946403384208679
Validation loss: 2.133648912111918

Epoch: 178| Step: 0
Training loss: 1.1750710010528564
Validation loss: 2.135963668425878

Epoch: 5| Step: 1
Training loss: 1.1421312093734741
Validation loss: 2.1061075031757355

Epoch: 5| Step: 2
Training loss: 1.2693690061569214
Validation loss: 2.168948625524839

Epoch: 5| Step: 3
Training loss: 1.0770013332366943
Validation loss: 2.1502996434768042

Epoch: 5| Step: 4
Training loss: 0.9956424832344055
Validation loss: 2.188357636332512

Epoch: 5| Step: 5
Training loss: 0.6560924053192139
Validation loss: 2.1699894020954766

Epoch: 5| Step: 6
Training loss: 0.7517973780632019
Validation loss: 2.2155034989118576

Epoch: 5| Step: 7
Training loss: 0.6216801404953003
Validation loss: 2.2232130964597068

Epoch: 5| Step: 8
Training loss: 1.0449014902114868
Validation loss: 2.2345566749572754

Epoch: 5| Step: 9
Training loss: 0.7983883023262024
Validation loss: 2.204852725068728

Epoch: 5| Step: 10
Training loss: 0.6734218001365662
Validation loss: 2.2111046512921653

Epoch: 5| Step: 11
Training loss: 0.9868948459625244
Validation loss: 2.2099172174930573

Epoch: 179| Step: 0
Training loss: 0.7296252846717834
Validation loss: 2.151868869860967

Epoch: 5| Step: 1
Training loss: 0.7225071787834167
Validation loss: 2.166095261772474

Epoch: 5| Step: 2
Training loss: 0.7447826266288757
Validation loss: 2.100821519891421

Epoch: 5| Step: 3
Training loss: 1.1011260747909546
Validation loss: 2.1552139222621918

Epoch: 5| Step: 4
Training loss: 1.012532353401184
Validation loss: 2.1953684439261756

Epoch: 5| Step: 5
Training loss: 0.7355631589889526
Validation loss: 2.189241329828898

Epoch: 5| Step: 6
Training loss: 0.9567489624023438
Validation loss: 2.1263316174348197

Epoch: 5| Step: 7
Training loss: 1.0913625955581665
Validation loss: 2.19214029610157

Epoch: 5| Step: 8
Training loss: 0.6465931534767151
Validation loss: 2.170870135227839

Epoch: 5| Step: 9
Training loss: 1.363296389579773
Validation loss: 2.1825489699840546

Epoch: 5| Step: 10
Training loss: 0.8699030876159668
Validation loss: 2.1649790157874427

Epoch: 5| Step: 11
Training loss: 1.197686791419983
Validation loss: 2.182133749127388

Epoch: 180| Step: 0
Training loss: 1.0642144680023193
Validation loss: 2.0702233066161475

Epoch: 5| Step: 1
Training loss: 0.5585952997207642
Validation loss: 2.0577198763688407

Epoch: 5| Step: 2
Training loss: 1.2537511587142944
Validation loss: 2.109470928708712

Epoch: 5| Step: 3
Training loss: 0.6961904764175415
Validation loss: 2.202336549758911

Epoch: 5| Step: 4
Training loss: 1.0618011951446533
Validation loss: 2.0715204228957496

Epoch: 5| Step: 5
Training loss: 0.640898585319519
Validation loss: 2.2248308211565018

Epoch: 5| Step: 6
Training loss: 0.9098820686340332
Validation loss: 2.193400094906489

Epoch: 5| Step: 7
Training loss: 0.8005551099777222
Validation loss: 2.1729968835910163

Epoch: 5| Step: 8
Training loss: 0.947789192199707
Validation loss: 2.200090984503428

Epoch: 5| Step: 9
Training loss: 1.0299198627471924
Validation loss: 2.1990219205617905

Epoch: 5| Step: 10
Training loss: 1.0579626560211182
Validation loss: 2.1933425764242807

Epoch: 5| Step: 11
Training loss: 1.1633617877960205
Validation loss: 2.1249956091245017

Epoch: 181| Step: 0
Training loss: 1.123736023902893
Validation loss: 2.163868730266889

Epoch: 5| Step: 1
Training loss: 0.9868766665458679
Validation loss: 2.1719711323579154

Epoch: 5| Step: 2
Training loss: 1.1226675510406494
Validation loss: 2.1658944487571716

Epoch: 5| Step: 3
Training loss: 0.6259562969207764
Validation loss: 2.169574518998464

Epoch: 5| Step: 4
Training loss: 0.9466248750686646
Validation loss: 2.1878337214390435

Epoch: 5| Step: 5
Training loss: 0.9638906717300415
Validation loss: 2.275532325108846

Epoch: 5| Step: 6
Training loss: 0.9702825546264648
Validation loss: 2.231415316462517

Epoch: 5| Step: 7
Training loss: 1.147043228149414
Validation loss: 2.3182100603977838

Epoch: 5| Step: 8
Training loss: 0.8525639772415161
Validation loss: 2.191411847869555

Epoch: 5| Step: 9
Training loss: 1.380099892616272
Validation loss: 2.189167618751526

Epoch: 5| Step: 10
Training loss: 0.6277180910110474
Validation loss: 2.2218543787797294

Epoch: 5| Step: 11
Training loss: 0.37117165327072144
Validation loss: 2.1777739226818085

Epoch: 182| Step: 0
Training loss: 0.9825043678283691
Validation loss: 2.202549010515213

Epoch: 5| Step: 1
Training loss: 0.8966689109802246
Validation loss: 2.096092159549395

Epoch: 5| Step: 2
Training loss: 0.7797836065292358
Validation loss: 2.1605554024378457

Epoch: 5| Step: 3
Training loss: 1.035947561264038
Validation loss: 2.1883809566497803

Epoch: 5| Step: 4
Training loss: 0.8880475163459778
Validation loss: 2.211590498685837

Epoch: 5| Step: 5
Training loss: 1.3874702453613281
Validation loss: 2.1801567475001016

Epoch: 5| Step: 6
Training loss: 0.5080540776252747
Validation loss: 2.2209643622239432

Epoch: 5| Step: 7
Training loss: 1.2803713083267212
Validation loss: 2.2679474502801895

Epoch: 5| Step: 8
Training loss: 1.0150386095046997
Validation loss: 2.164028897881508

Epoch: 5| Step: 9
Training loss: 0.8032310605049133
Validation loss: 2.158432056506475

Epoch: 5| Step: 10
Training loss: 0.581989586353302
Validation loss: 2.157131552696228

Epoch: 5| Step: 11
Training loss: 0.6904426217079163
Validation loss: 2.1212329864501953

Epoch: 183| Step: 0
Training loss: 1.0686687231063843
Validation loss: 2.203609804312388

Epoch: 5| Step: 1
Training loss: 0.9462437629699707
Validation loss: 2.1540018717447915

Epoch: 5| Step: 2
Training loss: 0.6334468126296997
Validation loss: 2.158546378215154

Epoch: 5| Step: 3
Training loss: 1.1142761707305908
Validation loss: 2.125294437011083

Epoch: 5| Step: 4
Training loss: 0.5597957372665405
Validation loss: 2.1861295104026794

Epoch: 5| Step: 5
Training loss: 1.0539590120315552
Validation loss: 2.20314884185791

Epoch: 5| Step: 6
Training loss: 0.8775938749313354
Validation loss: 2.205078979333242

Epoch: 5| Step: 7
Training loss: 0.6581242680549622
Validation loss: 2.202310249209404

Epoch: 5| Step: 8
Training loss: 0.8663598299026489
Validation loss: 2.175348177552223

Epoch: 5| Step: 9
Training loss: 0.7501412630081177
Validation loss: 2.174916540582975

Epoch: 5| Step: 10
Training loss: 1.1906344890594482
Validation loss: 2.1335293451944985

Epoch: 5| Step: 11
Training loss: 0.869464099407196
Validation loss: 2.1548613061507544

Epoch: 184| Step: 0
Training loss: 1.171820878982544
Validation loss: 2.1610442101955414

Epoch: 5| Step: 1
Training loss: 1.0654332637786865
Validation loss: 2.1164302031199136

Epoch: 5| Step: 2
Training loss: 0.7017086744308472
Validation loss: 2.114694302280744

Epoch: 5| Step: 3
Training loss: 0.5346269011497498
Validation loss: 2.2258750945329666

Epoch: 5| Step: 4
Training loss: 0.7057791948318481
Validation loss: 2.1580882171789804

Epoch: 5| Step: 5
Training loss: 1.154032588005066
Validation loss: 2.1896184434493384

Epoch: 5| Step: 6
Training loss: 0.599959135055542
Validation loss: 2.2025538633267083

Epoch: 5| Step: 7
Training loss: 0.758163332939148
Validation loss: 2.210509260495504

Epoch: 5| Step: 8
Training loss: 0.7296543121337891
Validation loss: 2.196569114923477

Epoch: 5| Step: 9
Training loss: 1.5594260692596436
Validation loss: 2.141229232152303

Epoch: 5| Step: 10
Training loss: 0.5490166544914246
Validation loss: 2.237377335627874

Epoch: 5| Step: 11
Training loss: 0.8137945532798767
Validation loss: 2.2381064544121423

Epoch: 185| Step: 0
Training loss: 0.9114769101142883
Validation loss: 2.1268306424220405

Epoch: 5| Step: 1
Training loss: 1.0386669635772705
Validation loss: 2.184974412123362

Epoch: 5| Step: 2
Training loss: 0.6638308763504028
Validation loss: 2.187559425830841

Epoch: 5| Step: 3
Training loss: 0.7472103834152222
Validation loss: 2.188332493106524

Epoch: 5| Step: 4
Training loss: 0.7640888094902039
Validation loss: 2.2062745094299316

Epoch: 5| Step: 5
Training loss: 1.0965949296951294
Validation loss: 2.1516354183355966

Epoch: 5| Step: 6
Training loss: 0.9726535677909851
Validation loss: 2.194313123822212

Epoch: 5| Step: 7
Training loss: 0.9381445050239563
Validation loss: 2.1787992169459662

Epoch: 5| Step: 8
Training loss: 0.9519201517105103
Validation loss: 2.232625092069308

Epoch: 5| Step: 9
Training loss: 0.7874540090560913
Validation loss: 2.2776799499988556

Epoch: 5| Step: 10
Training loss: 1.3232446908950806
Validation loss: 2.303566426038742

Epoch: 5| Step: 11
Training loss: 1.5386735200881958
Validation loss: 2.2086881548166275

Epoch: 186| Step: 0
Training loss: 0.617843508720398
Validation loss: 2.195446560780207

Epoch: 5| Step: 1
Training loss: 0.7875809669494629
Validation loss: 2.167136420806249

Epoch: 5| Step: 2
Training loss: 0.8812408447265625
Validation loss: 2.165726681550344

Epoch: 5| Step: 3
Training loss: 0.8016455769538879
Validation loss: 2.17428590854009

Epoch: 5| Step: 4
Training loss: 1.3674325942993164
Validation loss: 2.2219260533650718

Epoch: 5| Step: 5
Training loss: 1.0536781549453735
Validation loss: 2.2171872506539025

Epoch: 5| Step: 6
Training loss: 0.9716890454292297
Validation loss: 2.1395311852296195

Epoch: 5| Step: 7
Training loss: 0.7245957255363464
Validation loss: 2.1673679500818253

Epoch: 5| Step: 8
Training loss: 0.9185367822647095
Validation loss: 2.2011908988157907

Epoch: 5| Step: 9
Training loss: 0.7628083229064941
Validation loss: 2.2414979139963784

Epoch: 5| Step: 10
Training loss: 1.270550012588501
Validation loss: 2.1460646589597068

Epoch: 5| Step: 11
Training loss: 1.1544604301452637
Validation loss: 2.21891713142395

Epoch: 187| Step: 0
Training loss: 0.8376962542533875
Validation loss: 2.185429280002912

Epoch: 5| Step: 1
Training loss: 1.0995246171951294
Validation loss: 2.111693466703097

Epoch: 5| Step: 2
Training loss: 0.6887709498405457
Validation loss: 2.1166897465785346

Epoch: 5| Step: 3
Training loss: 0.8672548532485962
Validation loss: 2.1476577818393707

Epoch: 5| Step: 4
Training loss: 0.8558972477912903
Validation loss: 2.153444896141688

Epoch: 5| Step: 5
Training loss: 0.6500740051269531
Validation loss: 2.216596474250158

Epoch: 5| Step: 6
Training loss: 0.3644878566265106
Validation loss: 2.153538371125857

Epoch: 5| Step: 7
Training loss: 1.0980336666107178
Validation loss: 2.1684749921162925

Epoch: 5| Step: 8
Training loss: 1.0465017557144165
Validation loss: 2.1577457835276923

Epoch: 5| Step: 9
Training loss: 1.1073696613311768
Validation loss: 2.1895430386066437

Epoch: 5| Step: 10
Training loss: 0.9110377430915833
Validation loss: 2.176859805981318

Epoch: 5| Step: 11
Training loss: 0.89467853307724
Validation loss: 2.184387589494387

Epoch: 188| Step: 0
Training loss: 0.8930610418319702
Validation loss: 2.167894333600998

Epoch: 5| Step: 1
Training loss: 1.0022398233413696
Validation loss: 2.115073253711065

Epoch: 5| Step: 2
Training loss: 0.7053235173225403
Validation loss: 2.197156031926473

Epoch: 5| Step: 3
Training loss: 0.6780101656913757
Validation loss: 2.13630418976148

Epoch: 5| Step: 4
Training loss: 0.912710964679718
Validation loss: 2.1714359670877457

Epoch: 5| Step: 5
Training loss: 0.7463921904563904
Validation loss: 2.1794978429873786

Epoch: 5| Step: 6
Training loss: 0.8366317749023438
Validation loss: 2.207751601934433

Epoch: 5| Step: 7
Training loss: 0.6931045651435852
Validation loss: 2.2325330873330436

Epoch: 5| Step: 8
Training loss: 1.3506629467010498
Validation loss: 2.1907503654559455

Epoch: 5| Step: 9
Training loss: 0.9607107043266296
Validation loss: 2.1908630977074304

Epoch: 5| Step: 10
Training loss: 0.5332280993461609
Validation loss: 2.1947934528191886

Epoch: 5| Step: 11
Training loss: 0.285520076751709
Validation loss: 2.127448553840319

Epoch: 189| Step: 0
Training loss: 0.8717347979545593
Validation loss: 2.1666619877020517

Epoch: 5| Step: 1
Training loss: 0.9242706298828125
Validation loss: 2.2176663080851235

Epoch: 5| Step: 2
Training loss: 0.5907546281814575
Validation loss: 2.1718496481577554

Epoch: 5| Step: 3
Training loss: 1.4827425479888916
Validation loss: 2.119033674399058

Epoch: 5| Step: 4
Training loss: 1.0088351964950562
Validation loss: 2.187297264734904

Epoch: 5| Step: 5
Training loss: 0.7632046341896057
Validation loss: 2.125302861134211

Epoch: 5| Step: 6
Training loss: 0.5264979600906372
Validation loss: 2.1769136488437653

Epoch: 5| Step: 7
Training loss: 0.9511137008666992
Validation loss: 2.1087647825479507

Epoch: 5| Step: 8
Training loss: 0.8429261445999146
Validation loss: 2.128950277964274

Epoch: 5| Step: 9
Training loss: 0.554054856300354
Validation loss: 2.1369769275188446

Epoch: 5| Step: 10
Training loss: 0.85216224193573
Validation loss: 2.191598892211914

Epoch: 5| Step: 11
Training loss: 0.33158040046691895
Validation loss: 2.1621776719888053

Epoch: 190| Step: 0
Training loss: 0.672214686870575
Validation loss: 2.2116490999857583

Epoch: 5| Step: 1
Training loss: 0.9022483825683594
Validation loss: 2.163672392566999

Epoch: 5| Step: 2
Training loss: 0.9355499148368835
Validation loss: 2.170868143439293

Epoch: 5| Step: 3
Training loss: 0.6088566780090332
Validation loss: 2.109782467285792

Epoch: 5| Step: 4
Training loss: 0.7807925343513489
Validation loss: 2.160871704419454

Epoch: 5| Step: 5
Training loss: 1.0806736946105957
Validation loss: 2.109633053342501

Epoch: 5| Step: 6
Training loss: 0.8481369018554688
Validation loss: 2.128338282306989

Epoch: 5| Step: 7
Training loss: 0.7439495921134949
Validation loss: 2.1924711962540946

Epoch: 5| Step: 8
Training loss: 1.2217164039611816
Validation loss: 2.1756223340829215

Epoch: 5| Step: 9
Training loss: 0.7940637469291687
Validation loss: 2.176653911670049

Epoch: 5| Step: 10
Training loss: 1.206695795059204
Validation loss: 2.2537174373865128

Epoch: 5| Step: 11
Training loss: 2.2039966583251953
Validation loss: 2.2239225457111993

Epoch: 191| Step: 0
Training loss: 1.328979730606079
Validation loss: 2.3447782744963965

Epoch: 5| Step: 1
Training loss: 1.3003603219985962
Validation loss: 2.3839253932237625

Epoch: 5| Step: 2
Training loss: 1.226022720336914
Validation loss: 2.3689727783203125

Epoch: 5| Step: 3
Training loss: 1.1415255069732666
Validation loss: 2.320914015173912

Epoch: 5| Step: 4
Training loss: 0.9108650088310242
Validation loss: 2.274100740750631

Epoch: 5| Step: 5
Training loss: 0.6473627090454102
Validation loss: 2.150208036104838

Epoch: 5| Step: 6
Training loss: 1.0034687519073486
Validation loss: 2.0855581561724343

Epoch: 5| Step: 7
Training loss: 0.9592664837837219
Validation loss: 2.1640379329522452

Epoch: 5| Step: 8
Training loss: 1.1141769886016846
Validation loss: 2.1568655172983804

Epoch: 5| Step: 9
Training loss: 0.7289341688156128
Validation loss: 2.1238542646169662

Epoch: 5| Step: 10
Training loss: 0.8285928964614868
Validation loss: 2.1263209929068885

Epoch: 5| Step: 11
Training loss: 0.8780121803283691
Validation loss: 2.135699078440666

Epoch: 192| Step: 0
Training loss: 0.8130103349685669
Validation loss: 2.123471920688947

Epoch: 5| Step: 1
Training loss: 0.8731576800346375
Validation loss: 2.212451010942459

Epoch: 5| Step: 2
Training loss: 0.7905367612838745
Validation loss: 2.1240005095799765

Epoch: 5| Step: 3
Training loss: 0.8417150378227234
Validation loss: 2.2099912464618683

Epoch: 5| Step: 4
Training loss: 1.0199397802352905
Validation loss: 2.2380223274230957

Epoch: 5| Step: 5
Training loss: 0.8084949254989624
Validation loss: 2.191191087166468

Epoch: 5| Step: 6
Training loss: 0.7538156509399414
Validation loss: 2.1734657933314643

Epoch: 5| Step: 7
Training loss: 0.7276014089584351
Validation loss: 2.1381534337997437

Epoch: 5| Step: 8
Training loss: 0.9377242922782898
Validation loss: 2.1805131336053214

Epoch: 5| Step: 9
Training loss: 0.9333707094192505
Validation loss: 2.1966102371613183

Epoch: 5| Step: 10
Training loss: 1.5169792175292969
Validation loss: 2.1667162825663886

Epoch: 5| Step: 11
Training loss: 1.2402100563049316
Validation loss: 2.1751480052868524

Epoch: 193| Step: 0
Training loss: 0.7717175483703613
Validation loss: 2.185531129439672

Epoch: 5| Step: 1
Training loss: 1.1098073720932007
Validation loss: 2.184390977025032

Epoch: 5| Step: 2
Training loss: 0.7267733812332153
Validation loss: 2.2307791213194528

Epoch: 5| Step: 3
Training loss: 1.4566147327423096
Validation loss: 2.2176939050356546

Epoch: 5| Step: 4
Training loss: 0.9524628520011902
Validation loss: 2.192357415954272

Epoch: 5| Step: 5
Training loss: 0.486544132232666
Validation loss: 2.162383198738098

Epoch: 5| Step: 6
Training loss: 0.9040184020996094
Validation loss: 2.2035921017328897

Epoch: 5| Step: 7
Training loss: 0.678397536277771
Validation loss: 2.1504742205142975

Epoch: 5| Step: 8
Training loss: 0.7144461274147034
Validation loss: 2.1762787799040475

Epoch: 5| Step: 9
Training loss: 0.8988851308822632
Validation loss: 2.180690069993337

Epoch: 5| Step: 10
Training loss: 0.6990612149238586
Validation loss: 2.1381976356108985

Epoch: 5| Step: 11
Training loss: 1.0683571100234985
Validation loss: 2.1949602415164313

Epoch: 194| Step: 0
Training loss: 0.8380670547485352
Validation loss: 2.2354955772558847

Epoch: 5| Step: 1
Training loss: 0.8616048097610474
Validation loss: 2.206202839811643

Epoch: 5| Step: 2
Training loss: 0.6047170758247375
Validation loss: 2.194356014331182

Epoch: 5| Step: 3
Training loss: 0.8194161653518677
Validation loss: 2.216575731833776

Epoch: 5| Step: 4
Training loss: 0.8497633934020996
Validation loss: 2.181769460439682

Epoch: 5| Step: 5
Training loss: 0.6099122166633606
Validation loss: 2.2132588674624762

Epoch: 5| Step: 6
Training loss: 0.6352784633636475
Validation loss: 2.193339914083481

Epoch: 5| Step: 7
Training loss: 0.910454273223877
Validation loss: 2.128921697537104

Epoch: 5| Step: 8
Training loss: 1.1451928615570068
Validation loss: 2.1814366380373635

Epoch: 5| Step: 9
Training loss: 1.151301383972168
Validation loss: 2.205666775504748

Epoch: 5| Step: 10
Training loss: 0.6836391687393188
Validation loss: 2.138017122944196

Epoch: 5| Step: 11
Training loss: 0.7922077178955078
Validation loss: 2.174938201904297

Epoch: 195| Step: 0
Training loss: 0.8640779256820679
Validation loss: 2.1845285097757974

Epoch: 5| Step: 1
Training loss: 0.9510954022407532
Validation loss: 2.159203057487806

Epoch: 5| Step: 2
Training loss: 0.8636290431022644
Validation loss: 2.13590636352698

Epoch: 5| Step: 3
Training loss: 0.6134995222091675
Validation loss: 2.229852040608724

Epoch: 5| Step: 4
Training loss: 0.6951934695243835
Validation loss: 2.161659965912501

Epoch: 5| Step: 5
Training loss: 1.0433458089828491
Validation loss: 2.2517658174037933

Epoch: 5| Step: 6
Training loss: 0.6352391242980957
Validation loss: 2.1506493985652924

Epoch: 5| Step: 7
Training loss: 0.673857569694519
Validation loss: 2.2129815369844437

Epoch: 5| Step: 8
Training loss: 0.824077308177948
Validation loss: 2.2220180531342826

Epoch: 5| Step: 9
Training loss: 0.8236842155456543
Validation loss: 2.2283599227666855

Epoch: 5| Step: 10
Training loss: 0.8892990350723267
Validation loss: 2.100164905190468

Epoch: 5| Step: 11
Training loss: 0.9843456745147705
Validation loss: 2.2130593359470367

Epoch: 196| Step: 0
Training loss: 0.8275731205940247
Validation loss: 2.1717022409041724

Epoch: 5| Step: 1
Training loss: 0.5541771650314331
Validation loss: 2.1501428385575614

Epoch: 5| Step: 2
Training loss: 0.9522635340690613
Validation loss: 2.189680809775988

Epoch: 5| Step: 3
Training loss: 1.1665922403335571
Validation loss: 2.190102050701777

Epoch: 5| Step: 4
Training loss: 0.7344068288803101
Validation loss: 2.1530031164487204

Epoch: 5| Step: 5
Training loss: 0.9684355854988098
Validation loss: 2.1546848863363266

Epoch: 5| Step: 6
Training loss: 0.8755999803543091
Validation loss: 2.204872782031695

Epoch: 5| Step: 7
Training loss: 0.4976270794868469
Validation loss: 2.149722476800283

Epoch: 5| Step: 8
Training loss: 0.9973149299621582
Validation loss: 2.2065631647904715

Epoch: 5| Step: 9
Training loss: 0.8542326092720032
Validation loss: 2.1769428700208664

Epoch: 5| Step: 10
Training loss: 0.995641827583313
Validation loss: 2.219373792409897

Epoch: 5| Step: 11
Training loss: 1.733318567276001
Validation loss: 2.1998308102289834

Epoch: 197| Step: 0
Training loss: 0.5575312376022339
Validation loss: 2.1447986314694085

Epoch: 5| Step: 1
Training loss: 0.7446821331977844
Validation loss: 2.2478610972563424

Epoch: 5| Step: 2
Training loss: 0.7068119049072266
Validation loss: 2.1982411791880927

Epoch: 5| Step: 3
Training loss: 0.6509557366371155
Validation loss: 2.1896542757749557

Epoch: 5| Step: 4
Training loss: 1.3028342723846436
Validation loss: 2.255262240767479

Epoch: 5| Step: 5
Training loss: 0.6799942851066589
Validation loss: 2.16828823586305

Epoch: 5| Step: 6
Training loss: 1.2866226434707642
Validation loss: 2.196012794971466

Epoch: 5| Step: 7
Training loss: 0.4475270211696625
Validation loss: 2.198578586181005

Epoch: 5| Step: 8
Training loss: 0.6131787896156311
Validation loss: 2.175799866517385

Epoch: 5| Step: 9
Training loss: 0.7815145254135132
Validation loss: 2.2067594478527703

Epoch: 5| Step: 10
Training loss: 1.154213786125183
Validation loss: 2.175991415977478

Epoch: 5| Step: 11
Training loss: 0.6045178174972534
Validation loss: 2.208335896333059

Epoch: 198| Step: 0
Training loss: 0.5616591572761536
Validation loss: 2.1834634443124137

Epoch: 5| Step: 1
Training loss: 0.46594372391700745
Validation loss: 2.1651420245567956

Epoch: 5| Step: 2
Training loss: 0.5186079144477844
Validation loss: 2.1230435321728387

Epoch: 5| Step: 3
Training loss: 0.8069585561752319
Validation loss: 2.1418649504582086

Epoch: 5| Step: 4
Training loss: 0.8525568842887878
Validation loss: 2.1727302769819894

Epoch: 5| Step: 5
Training loss: 0.7089923620223999
Validation loss: 2.1507830917835236

Epoch: 5| Step: 6
Training loss: 0.5794868469238281
Validation loss: 2.146055539449056

Epoch: 5| Step: 7
Training loss: 0.5689083337783813
Validation loss: 2.182726263999939

Epoch: 5| Step: 8
Training loss: 1.585353136062622
Validation loss: 2.163268913825353

Epoch: 5| Step: 9
Training loss: 0.4479995369911194
Validation loss: 2.1661958744128547

Epoch: 5| Step: 10
Training loss: 1.3368935585021973
Validation loss: 2.182693565885226

Epoch: 5| Step: 11
Training loss: 1.3250293731689453
Validation loss: 2.1480032255252204

Epoch: 199| Step: 0
Training loss: 0.9191813468933105
Validation loss: 2.189341679215431

Epoch: 5| Step: 1
Training loss: 0.9914450645446777
Validation loss: 2.143789236744245

Epoch: 5| Step: 2
Training loss: 0.804979145526886
Validation loss: 2.1894631634155908

Epoch: 5| Step: 3
Training loss: 1.133927822113037
Validation loss: 2.1942608257134757

Epoch: 5| Step: 4
Training loss: 0.9319285154342651
Validation loss: 2.2454266200462976

Epoch: 5| Step: 5
Training loss: 0.6229780912399292
Validation loss: 2.1791108002265296

Epoch: 5| Step: 6
Training loss: 0.8027454614639282
Validation loss: 2.2094697803258896

Epoch: 5| Step: 7
Training loss: 0.5025869607925415
Validation loss: 2.1935210525989532

Epoch: 5| Step: 8
Training loss: 1.0852854251861572
Validation loss: 2.11404912173748

Epoch: 5| Step: 9
Training loss: 0.663044273853302
Validation loss: 2.2174021005630493

Epoch: 5| Step: 10
Training loss: 0.46520528197288513
Validation loss: 2.1658812314271927

Epoch: 5| Step: 11
Training loss: 0.859096884727478
Validation loss: 2.2810390492280326

Epoch: 200| Step: 0
Training loss: 0.970237135887146
Validation loss: 2.2221052845319114

Epoch: 5| Step: 1
Training loss: 0.8036767840385437
Validation loss: 2.196684261163076

Epoch: 5| Step: 2
Training loss: 0.6608191728591919
Validation loss: 2.181317523121834

Epoch: 5| Step: 3
Training loss: 1.0699783563613892
Validation loss: 2.161334832509359

Epoch: 5| Step: 4
Training loss: 0.695966899394989
Validation loss: 2.219476024309794

Epoch: 5| Step: 5
Training loss: 0.5945395231246948
Validation loss: 2.207745353380839

Epoch: 5| Step: 6
Training loss: 0.7775517702102661
Validation loss: 2.1491324802239737

Epoch: 5| Step: 7
Training loss: 0.5404379963874817
Validation loss: 2.211341549952825

Epoch: 5| Step: 8
Training loss: 0.7078782916069031
Validation loss: 2.1566465944051743

Epoch: 5| Step: 9
Training loss: 0.8584223985671997
Validation loss: 2.2830705642700195

Epoch: 5| Step: 10
Training loss: 0.9135486483573914
Validation loss: 2.247006128231684

Epoch: 5| Step: 11
Training loss: 0.40673044323921204
Validation loss: 2.243324562907219

Epoch: 201| Step: 0
Training loss: 0.8773934245109558
Validation loss: 2.263748750090599

Epoch: 5| Step: 1
Training loss: 0.704267144203186
Validation loss: 2.2008866469065347

Epoch: 5| Step: 2
Training loss: 0.5634549856185913
Validation loss: 2.188766931494077

Epoch: 5| Step: 3
Training loss: 0.7811899185180664
Validation loss: 2.182021905978521

Epoch: 5| Step: 4
Training loss: 1.2409664392471313
Validation loss: 2.1602882544199624

Epoch: 5| Step: 5
Training loss: 0.7167860269546509
Validation loss: 2.1768405536810556

Epoch: 5| Step: 6
Training loss: 0.48760494589805603
Validation loss: 2.208951453367869

Epoch: 5| Step: 7
Training loss: 0.8054126501083374
Validation loss: 2.202092265089353

Epoch: 5| Step: 8
Training loss: 0.6401141285896301
Validation loss: 2.1719869722922645

Epoch: 5| Step: 9
Training loss: 0.917407214641571
Validation loss: 2.1799968481063843

Epoch: 5| Step: 10
Training loss: 1.069376826286316
Validation loss: 2.19765933851401

Epoch: 5| Step: 11
Training loss: 2.0507171154022217
Validation loss: 2.2132716874281564

Epoch: 202| Step: 0
Training loss: 0.7745883464813232
Validation loss: 2.2231725454330444

Epoch: 5| Step: 1
Training loss: 0.623374342918396
Validation loss: 2.1916529734929404

Epoch: 5| Step: 2
Training loss: 0.9940136671066284
Validation loss: 2.162615959843

Epoch: 5| Step: 3
Training loss: 0.49187248945236206
Validation loss: 2.2220872789621353

Epoch: 5| Step: 4
Training loss: 0.6361988186836243
Validation loss: 2.1668755412101746

Epoch: 5| Step: 5
Training loss: 1.16001296043396
Validation loss: 2.2124511152505875

Epoch: 5| Step: 6
Training loss: 0.9499195218086243
Validation loss: 2.203608845671018

Epoch: 5| Step: 7
Training loss: 0.7229054570198059
Validation loss: 2.3102600971857705

Epoch: 5| Step: 8
Training loss: 0.5173308253288269
Validation loss: 2.189944341778755

Epoch: 5| Step: 9
Training loss: 1.0357983112335205
Validation loss: 2.187104806303978

Epoch: 5| Step: 10
Training loss: 0.7011283040046692
Validation loss: 2.1839675903320312

Epoch: 5| Step: 11
Training loss: 1.0788447856903076
Validation loss: 2.2130966931581497

Epoch: 203| Step: 0
Training loss: 0.89323490858078
Validation loss: 2.2205692529678345

Epoch: 5| Step: 1
Training loss: 0.9507678747177124
Validation loss: 2.153400426109632

Epoch: 5| Step: 2
Training loss: 0.9445000886917114
Validation loss: 2.2156536877155304

Epoch: 5| Step: 3
Training loss: 0.9557002782821655
Validation loss: 2.1825861434141793

Epoch: 5| Step: 4
Training loss: 0.8385397791862488
Validation loss: 2.2369300425052643

Epoch: 5| Step: 5
Training loss: 0.5904332995414734
Validation loss: 2.2044648230075836

Epoch: 5| Step: 6
Training loss: 1.0958335399627686
Validation loss: 2.2085353632767997

Epoch: 5| Step: 7
Training loss: 0.681675910949707
Validation loss: 2.2799575477838516

Epoch: 5| Step: 8
Training loss: 0.585830807685852
Validation loss: 2.219872315724691

Epoch: 5| Step: 9
Training loss: 0.6728461980819702
Validation loss: 2.220893303553263

Epoch: 5| Step: 10
Training loss: 0.48270878195762634
Validation loss: 2.208735167980194

Epoch: 5| Step: 11
Training loss: 1.0518276691436768
Validation loss: 2.243361542622248

Epoch: 204| Step: 0
Training loss: 0.5517371892929077
Validation loss: 2.242997179428736

Epoch: 5| Step: 1
Training loss: 0.4630930423736572
Validation loss: 2.1746112406253815

Epoch: 5| Step: 2
Training loss: 1.0293530225753784
Validation loss: 2.1588894426822662

Epoch: 5| Step: 3
Training loss: 0.9385043382644653
Validation loss: 2.176945527394613

Epoch: 5| Step: 4
Training loss: 0.6035922765731812
Validation loss: 2.2155792862176895

Epoch: 5| Step: 5
Training loss: 0.6359289884567261
Validation loss: 2.1558590829372406

Epoch: 5| Step: 6
Training loss: 0.6651707291603088
Validation loss: 2.1620064278443656

Epoch: 5| Step: 7
Training loss: 1.514674186706543
Validation loss: 2.170367951194445

Epoch: 5| Step: 8
Training loss: 0.5488452315330505
Validation loss: 2.088389977812767

Epoch: 5| Step: 9
Training loss: 0.8710435628890991
Validation loss: 2.1185756226380668

Epoch: 5| Step: 10
Training loss: 0.846148669719696
Validation loss: 2.1494129300117493

Epoch: 5| Step: 11
Training loss: 0.23058833181858063
Validation loss: 2.181436484058698

Epoch: 205| Step: 0
Training loss: 0.7380502820014954
Validation loss: 2.0883320470650992

Epoch: 5| Step: 1
Training loss: 0.6286640167236328
Validation loss: 2.1734758913517

Epoch: 5| Step: 2
Training loss: 0.4666784405708313
Validation loss: 2.0901812613010406

Epoch: 5| Step: 3
Training loss: 0.9046469926834106
Validation loss: 2.128607968489329

Epoch: 5| Step: 4
Training loss: 0.7471950054168701
Validation loss: 2.127611428499222

Epoch: 5| Step: 5
Training loss: 0.7464945912361145
Validation loss: 2.157703464229902

Epoch: 5| Step: 6
Training loss: 1.041261911392212
Validation loss: 2.190493901570638

Epoch: 5| Step: 7
Training loss: 0.9024174809455872
Validation loss: 2.147262583176295

Epoch: 5| Step: 8
Training loss: 1.0993239879608154
Validation loss: 2.1797756055990853

Epoch: 5| Step: 9
Training loss: 0.5339687466621399
Validation loss: 2.195837120215098

Epoch: 5| Step: 10
Training loss: 0.5782960653305054
Validation loss: 2.1452133556207023

Epoch: 5| Step: 11
Training loss: 0.5319104790687561
Validation loss: 2.1518956224123635

Epoch: 206| Step: 0
Training loss: 0.43117469549179077
Validation loss: 2.2068975418806076

Epoch: 5| Step: 1
Training loss: 0.4992189407348633
Validation loss: 2.166307419538498

Epoch: 5| Step: 2
Training loss: 0.9539912343025208
Validation loss: 2.242451677719752

Epoch: 5| Step: 3
Training loss: 0.8130108118057251
Validation loss: 2.258825053771337

Epoch: 5| Step: 4
Training loss: 0.6453679203987122
Validation loss: 2.1878379185994468

Epoch: 5| Step: 5
Training loss: 0.7423195838928223
Validation loss: 2.24145378669103

Epoch: 5| Step: 6
Training loss: 0.9236848950386047
Validation loss: 2.256159787376722

Epoch: 5| Step: 7
Training loss: 0.9169252514839172
Validation loss: 2.229952186346054

Epoch: 5| Step: 8
Training loss: 0.8342583775520325
Validation loss: 2.2175510774056115

Epoch: 5| Step: 9
Training loss: 0.6833370923995972
Validation loss: 2.176406820615133

Epoch: 5| Step: 10
Training loss: 0.7192095518112183
Validation loss: 2.210203086336454

Epoch: 5| Step: 11
Training loss: 0.9181132912635803
Validation loss: 2.199131429195404

Epoch: 207| Step: 0
Training loss: 0.6547228693962097
Validation loss: 2.202207068602244

Epoch: 5| Step: 1
Training loss: 0.4687959551811218
Validation loss: 2.2479202449321747

Epoch: 5| Step: 2
Training loss: 0.6879393458366394
Validation loss: 2.143946429093679

Epoch: 5| Step: 3
Training loss: 0.527431309223175
Validation loss: 2.2062177608410516

Epoch: 5| Step: 4
Training loss: 0.7130237817764282
Validation loss: 2.2192748486995697

Epoch: 5| Step: 5
Training loss: 0.4725135266780853
Validation loss: 2.173583169778188

Epoch: 5| Step: 6
Training loss: 0.5651966333389282
Validation loss: 2.156240845719973

Epoch: 5| Step: 7
Training loss: 0.8016483187675476
Validation loss: 2.181703135371208

Epoch: 5| Step: 8
Training loss: 1.1721925735473633
Validation loss: 2.152566115061442

Epoch: 5| Step: 9
Training loss: 0.751218855381012
Validation loss: 2.19376170138518

Epoch: 5| Step: 10
Training loss: 1.0757170915603638
Validation loss: 2.1731420109669366

Epoch: 5| Step: 11
Training loss: 0.772615373134613
Validation loss: 2.163877119620641

Epoch: 208| Step: 0
Training loss: 0.29428884387016296
Validation loss: 2.157474016149839

Epoch: 5| Step: 1
Training loss: 0.9278844594955444
Validation loss: 2.1412199983994165

Epoch: 5| Step: 2
Training loss: 0.5054359436035156
Validation loss: 2.140859285990397

Epoch: 5| Step: 3
Training loss: 0.631688117980957
Validation loss: 2.0994412104288735

Epoch: 5| Step: 4
Training loss: 0.8823220133781433
Validation loss: 2.175997147957484

Epoch: 5| Step: 5
Training loss: 1.4414992332458496
Validation loss: 2.1610741019248962

Epoch: 5| Step: 6
Training loss: 0.8027628064155579
Validation loss: 2.088661879301071

Epoch: 5| Step: 7
Training loss: 0.7386072278022766
Validation loss: 2.1391207724809647

Epoch: 5| Step: 8
Training loss: 0.5531377196311951
Validation loss: 2.089641516407331

Epoch: 5| Step: 9
Training loss: 0.6207303404808044
Validation loss: 2.1374605745077133

Epoch: 5| Step: 10
Training loss: 0.8248418569564819
Validation loss: 2.182241524259249

Epoch: 5| Step: 11
Training loss: 0.9230569005012512
Validation loss: 2.182547241449356

Epoch: 209| Step: 0
Training loss: 0.6389195322990417
Validation loss: 2.127567484974861

Epoch: 5| Step: 1
Training loss: 0.6189624071121216
Validation loss: 2.197024409969648

Epoch: 5| Step: 2
Training loss: 0.9586626887321472
Validation loss: 2.176474074522654

Epoch: 5| Step: 3
Training loss: 0.8549381494522095
Validation loss: 2.1554984698692956

Epoch: 5| Step: 4
Training loss: 0.5909575819969177
Validation loss: 2.2214168359835944

Epoch: 5| Step: 5
Training loss: 0.6341854929924011
Validation loss: 2.2473954955736795

Epoch: 5| Step: 6
Training loss: 0.7655001878738403
Validation loss: 2.249788244565328

Epoch: 5| Step: 7
Training loss: 0.5705894231796265
Validation loss: 2.2398462096850076

Epoch: 5| Step: 8
Training loss: 0.7050756216049194
Validation loss: 2.244802643855413

Epoch: 5| Step: 9
Training loss: 1.2198395729064941
Validation loss: 2.257964183886846

Epoch: 5| Step: 10
Training loss: 0.5674722790718079
Validation loss: 2.267065465450287

Epoch: 5| Step: 11
Training loss: 0.43415796756744385
Validation loss: 2.268007924159368

Epoch: 210| Step: 0
Training loss: 0.5020989775657654
Validation loss: 2.2962643802165985

Epoch: 5| Step: 1
Training loss: 0.9415775537490845
Validation loss: 2.2651200592517853

Epoch: 5| Step: 2
Training loss: 1.1773271560668945
Validation loss: 2.226719622810682

Epoch: 5| Step: 3
Training loss: 0.7013692259788513
Validation loss: 2.270162304242452

Epoch: 5| Step: 4
Training loss: 0.9031561613082886
Validation loss: 2.195822765429815

Epoch: 5| Step: 5
Training loss: 0.9679646492004395
Validation loss: 2.2157991429169974

Epoch: 5| Step: 6
Training loss: 0.9050811529159546
Validation loss: 2.176669200261434

Epoch: 5| Step: 7
Training loss: 0.6716852188110352
Validation loss: 2.202273413538933

Epoch: 5| Step: 8
Training loss: 0.3449341654777527
Validation loss: 2.2692944308122

Epoch: 5| Step: 9
Training loss: 0.7355836033821106
Validation loss: 2.300522575775782

Epoch: 5| Step: 10
Training loss: 0.8526278734207153
Validation loss: 2.3022501468658447

Epoch: 5| Step: 11
Training loss: 0.370114803314209
Validation loss: 2.245186150074005

Epoch: 211| Step: 0
Training loss: 0.7837716341018677
Validation loss: 2.2142626841863

Epoch: 5| Step: 1
Training loss: 0.9840259552001953
Validation loss: 2.2172620743513107

Epoch: 5| Step: 2
Training loss: 0.5706509351730347
Validation loss: 2.229277322689692

Epoch: 5| Step: 3
Training loss: 0.5027063488960266
Validation loss: 2.188752497235934

Epoch: 5| Step: 4
Training loss: 0.8985737562179565
Validation loss: 2.190607021252314

Epoch: 5| Step: 5
Training loss: 0.4630254805088043
Validation loss: 2.2051251928011575

Epoch: 5| Step: 6
Training loss: 0.6819641590118408
Validation loss: 2.2194915115833282

Epoch: 5| Step: 7
Training loss: 0.76079922914505
Validation loss: 2.184796611467997

Epoch: 5| Step: 8
Training loss: 0.7540539503097534
Validation loss: 2.1996511071920395

Epoch: 5| Step: 9
Training loss: 1.4073028564453125
Validation loss: 2.196177899837494

Epoch: 5| Step: 10
Training loss: 0.4432218670845032
Validation loss: 2.094947025179863

Epoch: 5| Step: 11
Training loss: 0.657302737236023
Validation loss: 2.1499249736467996

Epoch: 212| Step: 0
Training loss: 0.9650424122810364
Validation loss: 2.1696668416261673

Epoch: 5| Step: 1
Training loss: 0.5171505808830261
Validation loss: 2.1645962993303933

Epoch: 5| Step: 2
Training loss: 0.6238106489181519
Validation loss: 2.119078978896141

Epoch: 5| Step: 3
Training loss: 0.6111862063407898
Validation loss: 2.1931905150413513

Epoch: 5| Step: 4
Training loss: 0.8604057431221008
Validation loss: 2.1253506938616433

Epoch: 5| Step: 5
Training loss: 0.6746745705604553
Validation loss: 2.15167668958505

Epoch: 5| Step: 6
Training loss: 0.5761526823043823
Validation loss: 2.142815907796224

Epoch: 5| Step: 7
Training loss: 0.967719554901123
Validation loss: 2.2087961783011756

Epoch: 5| Step: 8
Training loss: 0.7882854342460632
Validation loss: 2.208640550573667

Epoch: 5| Step: 9
Training loss: 0.4848884642124176
Validation loss: 2.2022657841444016

Epoch: 5| Step: 10
Training loss: 0.8400823473930359
Validation loss: 2.215682730078697

Epoch: 5| Step: 11
Training loss: 0.6206573247909546
Validation loss: 2.2039927740891776

Epoch: 213| Step: 0
Training loss: 0.6947019100189209
Validation loss: 2.2196029126644135

Epoch: 5| Step: 1
Training loss: 0.882917046546936
Validation loss: 2.2266009747982025

Epoch: 5| Step: 2
Training loss: 0.8016154170036316
Validation loss: 2.1767346411943436

Epoch: 5| Step: 3
Training loss: 0.4212884306907654
Validation loss: 2.2129526833693185

Epoch: 5| Step: 4
Training loss: 0.8435618281364441
Validation loss: 2.1880596776803336

Epoch: 5| Step: 5
Training loss: 0.9167101979255676
Validation loss: 2.208121955394745

Epoch: 5| Step: 6
Training loss: 0.7248403429985046
Validation loss: 2.1921945214271545

Epoch: 5| Step: 7
Training loss: 0.6509817838668823
Validation loss: 2.259838193655014

Epoch: 5| Step: 8
Training loss: 0.9562125205993652
Validation loss: 2.1841207494338355

Epoch: 5| Step: 9
Training loss: 0.5075541734695435
Validation loss: 2.2079479098320007

Epoch: 5| Step: 10
Training loss: 0.5945720076560974
Validation loss: 2.2350620329380035

Epoch: 5| Step: 11
Training loss: 0.5495259761810303
Validation loss: 2.2118004262447357

Epoch: 214| Step: 0
Training loss: 0.6156631708145142
Validation loss: 2.2083612928787866

Epoch: 5| Step: 1
Training loss: 0.8733388781547546
Validation loss: 2.162045290072759

Epoch: 5| Step: 2
Training loss: 1.365298867225647
Validation loss: 2.1767130196094513

Epoch: 5| Step: 3
Training loss: 0.676313042640686
Validation loss: 2.188039720058441

Epoch: 5| Step: 4
Training loss: 0.43827828764915466
Validation loss: 2.238094672560692

Epoch: 5| Step: 5
Training loss: 0.7771652936935425
Validation loss: 2.1642471502224603

Epoch: 5| Step: 6
Training loss: 0.6349538564682007
Validation loss: 2.1677488684654236

Epoch: 5| Step: 7
Training loss: 0.8615105748176575
Validation loss: 2.2596044838428497

Epoch: 5| Step: 8
Training loss: 0.6747300624847412
Validation loss: 2.2104012221097946

Epoch: 5| Step: 9
Training loss: 0.4823091924190521
Validation loss: 2.2101591726144156

Epoch: 5| Step: 10
Training loss: 0.9860391616821289
Validation loss: 2.1934447338183722

Epoch: 5| Step: 11
Training loss: 0.4203002452850342
Validation loss: 2.207650144894918

Epoch: 215| Step: 0
Training loss: 0.893811047077179
Validation loss: 2.171776150663694

Epoch: 5| Step: 1
Training loss: 0.7541758418083191
Validation loss: 2.241179347038269

Epoch: 5| Step: 2
Training loss: 0.6847835183143616
Validation loss: 2.112017333507538

Epoch: 5| Step: 3
Training loss: 0.5101711750030518
Validation loss: 2.1782299826542535

Epoch: 5| Step: 4
Training loss: 0.6856316328048706
Validation loss: 2.170734445254008

Epoch: 5| Step: 5
Training loss: 0.8483303189277649
Validation loss: 2.137464607755343

Epoch: 5| Step: 6
Training loss: 0.8642657995223999
Validation loss: 2.161600281794866

Epoch: 5| Step: 7
Training loss: 0.4001035690307617
Validation loss: 2.203058183193207

Epoch: 5| Step: 8
Training loss: 0.8802542686462402
Validation loss: 2.189741457502047

Epoch: 5| Step: 9
Training loss: 0.5378877520561218
Validation loss: 2.2156265129645667

Epoch: 5| Step: 10
Training loss: 0.7767828106880188
Validation loss: 2.19107294579347

Epoch: 5| Step: 11
Training loss: 1.7914674282073975
Validation loss: 2.205817699432373

Epoch: 216| Step: 0
Training loss: 0.7434827089309692
Validation loss: 2.166781187057495

Epoch: 5| Step: 1
Training loss: 0.596965491771698
Validation loss: 2.182559465368589

Epoch: 5| Step: 2
Training loss: 0.5535327792167664
Validation loss: 2.193534562985102

Epoch: 5| Step: 3
Training loss: 0.9730555415153503
Validation loss: 2.193583384156227

Epoch: 5| Step: 4
Training loss: 0.7474103569984436
Validation loss: 2.185901348789533

Epoch: 5| Step: 5
Training loss: 0.7458489537239075
Validation loss: 2.1926933924357095

Epoch: 5| Step: 6
Training loss: 0.6678493022918701
Validation loss: 2.2059912929932275

Epoch: 5| Step: 7
Training loss: 0.8793516159057617
Validation loss: 2.1589969098567963

Epoch: 5| Step: 8
Training loss: 0.9188412427902222
Validation loss: 2.1551922063032785

Epoch: 5| Step: 9
Training loss: 0.5940760970115662
Validation loss: 2.2769089192152023

Epoch: 5| Step: 10
Training loss: 0.620141327381134
Validation loss: 2.240989238023758

Epoch: 5| Step: 11
Training loss: 0.6148679256439209
Validation loss: 2.230002840360006

Epoch: 217| Step: 0
Training loss: 0.8972997665405273
Validation loss: 2.1883435249328613

Epoch: 5| Step: 1
Training loss: 0.5009059906005859
Validation loss: 2.2182406733433404

Epoch: 5| Step: 2
Training loss: 0.7450782656669617
Validation loss: 2.219928095738093

Epoch: 5| Step: 3
Training loss: 0.9685274362564087
Validation loss: 2.192668785651525

Epoch: 5| Step: 4
Training loss: 0.6496221423149109
Validation loss: 2.2542320986588797

Epoch: 5| Step: 5
Training loss: 0.47833529114723206
Validation loss: 2.2698165625333786

Epoch: 5| Step: 6
Training loss: 0.6027144193649292
Validation loss: 2.198828861117363

Epoch: 5| Step: 7
Training loss: 0.8688423037528992
Validation loss: 2.243526726961136

Epoch: 5| Step: 8
Training loss: 0.8047623634338379
Validation loss: 2.2577599734067917

Epoch: 5| Step: 9
Training loss: 0.8272509574890137
Validation loss: 2.204698617259661

Epoch: 5| Step: 10
Training loss: 0.8788541555404663
Validation loss: 2.262963682413101

Epoch: 5| Step: 11
Training loss: 0.41838622093200684
Validation loss: 2.2045185565948486

Epoch: 218| Step: 0
Training loss: 0.5268212556838989
Validation loss: 2.2588802377382913

Epoch: 5| Step: 1
Training loss: 0.3676500916481018
Validation loss: 2.2171088457107544

Epoch: 5| Step: 2
Training loss: 0.7859979867935181
Validation loss: 2.1718622793753943

Epoch: 5| Step: 3
Training loss: 0.5498977899551392
Validation loss: 2.2122648557027182

Epoch: 5| Step: 4
Training loss: 0.5770688056945801
Validation loss: 2.2180592765410743

Epoch: 5| Step: 5
Training loss: 0.6871140599250793
Validation loss: 2.1943943202495575

Epoch: 5| Step: 6
Training loss: 1.1291019916534424
Validation loss: 2.172716741760572

Epoch: 5| Step: 7
Training loss: 0.49962884187698364
Validation loss: 2.2250391046206155

Epoch: 5| Step: 8
Training loss: 0.7722434997558594
Validation loss: 2.2180911352237067

Epoch: 5| Step: 9
Training loss: 1.0502817630767822
Validation loss: 2.129002958536148

Epoch: 5| Step: 10
Training loss: 0.7737939953804016
Validation loss: 2.243736599882444

Epoch: 5| Step: 11
Training loss: 0.3185768127441406
Validation loss: 2.1708185921112695

Epoch: 219| Step: 0
Training loss: 0.718014657497406
Validation loss: 2.2065491527318954

Epoch: 5| Step: 1
Training loss: 0.8210729360580444
Validation loss: 2.258945574363073

Epoch: 5| Step: 2
Training loss: 1.1005438566207886
Validation loss: 2.231348395347595

Epoch: 5| Step: 3
Training loss: 0.8569022417068481
Validation loss: 2.2224818716446557

Epoch: 5| Step: 4
Training loss: 0.7118210792541504
Validation loss: 2.1893939624230065

Epoch: 5| Step: 5
Training loss: 0.893841564655304
Validation loss: 2.176856537659963

Epoch: 5| Step: 6
Training loss: 0.46012812852859497
Validation loss: 2.1911287854115167

Epoch: 5| Step: 7
Training loss: 0.5254138112068176
Validation loss: 2.1449271142482758

Epoch: 5| Step: 8
Training loss: 0.6961961984634399
Validation loss: 2.193412259221077

Epoch: 5| Step: 9
Training loss: 0.4642826020717621
Validation loss: 2.2081121603647866

Epoch: 5| Step: 10
Training loss: 0.4736256003379822
Validation loss: 2.2031992971897125

Epoch: 5| Step: 11
Training loss: 0.24189114570617676
Validation loss: 2.190939635038376

Epoch: 220| Step: 0
Training loss: 0.7297385931015015
Validation loss: 2.2066716055075326

Epoch: 5| Step: 1
Training loss: 0.8044673204421997
Validation loss: 2.140704423189163

Epoch: 5| Step: 2
Training loss: 0.7151747941970825
Validation loss: 2.1991651554902396

Epoch: 5| Step: 3
Training loss: 0.7819668650627136
Validation loss: 2.1804044395685196

Epoch: 5| Step: 4
Training loss: 0.5548651218414307
Validation loss: 2.2233062088489532

Epoch: 5| Step: 5
Training loss: 0.7776786684989929
Validation loss: 2.183754121263822

Epoch: 5| Step: 6
Training loss: 0.4180351197719574
Validation loss: 2.231766626238823

Epoch: 5| Step: 7
Training loss: 0.5809472799301147
Validation loss: 2.189815173546473

Epoch: 5| Step: 8
Training loss: 1.1400387287139893
Validation loss: 2.1665536711613336

Epoch: 5| Step: 9
Training loss: 0.5660644173622131
Validation loss: 2.1988442043463388

Epoch: 5| Step: 10
Training loss: 0.7155441045761108
Validation loss: 2.135885010162989

Epoch: 5| Step: 11
Training loss: 1.0550323724746704
Validation loss: 2.236490542689959

Epoch: 221| Step: 0
Training loss: 0.7927433848381042
Validation loss: 2.1940252979596457

Epoch: 5| Step: 1
Training loss: 0.7878321409225464
Validation loss: 2.215459033846855

Epoch: 5| Step: 2
Training loss: 0.4993050694465637
Validation loss: 2.1828670650720596

Epoch: 5| Step: 3
Training loss: 0.676134467124939
Validation loss: 2.2111485600471497

Epoch: 5| Step: 4
Training loss: 0.8771467208862305
Validation loss: 2.2091645995775857

Epoch: 5| Step: 5
Training loss: 1.0427011251449585
Validation loss: 2.2200602988402047

Epoch: 5| Step: 6
Training loss: 0.5435799956321716
Validation loss: 2.179733067750931

Epoch: 5| Step: 7
Training loss: 0.7288678884506226
Validation loss: 2.2387410203615823

Epoch: 5| Step: 8
Training loss: 0.6897818446159363
Validation loss: 2.2092867692311606

Epoch: 5| Step: 9
Training loss: 0.6130884885787964
Validation loss: 2.2567166835069656

Epoch: 5| Step: 10
Training loss: 0.8021348118782043
Validation loss: 2.2164826542139053

Epoch: 5| Step: 11
Training loss: 0.3246411085128784
Validation loss: 2.2009150087833405

Epoch: 222| Step: 0
Training loss: 0.5268362164497375
Validation loss: 2.2880172232786813

Epoch: 5| Step: 1
Training loss: 0.6286736726760864
Validation loss: 2.209225654602051

Epoch: 5| Step: 2
Training loss: 1.0029973983764648
Validation loss: 2.23469485839208

Epoch: 5| Step: 3
Training loss: 0.5218325853347778
Validation loss: 2.1805414259433746

Epoch: 5| Step: 4
Training loss: 0.6484423875808716
Validation loss: 2.2399096141258874

Epoch: 5| Step: 5
Training loss: 0.8056299090385437
Validation loss: 2.210972547531128

Epoch: 5| Step: 6
Training loss: 0.5307247042655945
Validation loss: 2.219906191031138

Epoch: 5| Step: 7
Training loss: 0.4396549165248871
Validation loss: 2.217248539129893

Epoch: 5| Step: 8
Training loss: 1.1310334205627441
Validation loss: 2.285649905602137

Epoch: 5| Step: 9
Training loss: 0.6751686334609985
Validation loss: 2.2111461609601974

Epoch: 5| Step: 10
Training loss: 0.7659576535224915
Validation loss: 2.258893738190333

Epoch: 5| Step: 11
Training loss: 0.6277083158493042
Validation loss: 2.2156752248605094

Epoch: 223| Step: 0
Training loss: 1.0835704803466797
Validation loss: 2.121856282154719

Epoch: 5| Step: 1
Training loss: 0.6072751879692078
Validation loss: 2.2161751786867776

Epoch: 5| Step: 2
Training loss: 0.6399907469749451
Validation loss: 2.2297628621260324

Epoch: 5| Step: 3
Training loss: 0.5675995945930481
Validation loss: 2.2424565901358924

Epoch: 5| Step: 4
Training loss: 0.8807131052017212
Validation loss: 2.1895706752936044

Epoch: 5| Step: 5
Training loss: 0.7659043073654175
Validation loss: 2.173650801181793

Epoch: 5| Step: 6
Training loss: 0.28009968996047974
Validation loss: 2.164621889591217

Epoch: 5| Step: 7
Training loss: 0.55974280834198
Validation loss: 2.18595460553964

Epoch: 5| Step: 8
Training loss: 0.7513750195503235
Validation loss: 2.25680706401666

Epoch: 5| Step: 9
Training loss: 0.8308833241462708
Validation loss: 2.217554355661074

Epoch: 5| Step: 10
Training loss: 0.675881028175354
Validation loss: 2.218234971165657

Epoch: 5| Step: 11
Training loss: 0.29563820362091064
Validation loss: 2.214358389377594

Epoch: 224| Step: 0
Training loss: 0.8459672927856445
Validation loss: 2.233297422528267

Epoch: 5| Step: 1
Training loss: 0.7538493871688843
Validation loss: 2.1770951648553214

Epoch: 5| Step: 2
Training loss: 0.5174813866615295
Validation loss: 2.186832219362259

Epoch: 5| Step: 3
Training loss: 0.48077258467674255
Validation loss: 2.17833149433136

Epoch: 5| Step: 4
Training loss: 0.9507595896720886
Validation loss: 2.1763984660307565

Epoch: 5| Step: 5
Training loss: 0.6741317510604858
Validation loss: 2.195774808526039

Epoch: 5| Step: 6
Training loss: 0.612977147102356
Validation loss: 2.1562679459651313

Epoch: 5| Step: 7
Training loss: 0.4432019591331482
Validation loss: 2.161707063515981

Epoch: 5| Step: 8
Training loss: 0.5713459253311157
Validation loss: 2.254597023129463

Epoch: 5| Step: 9
Training loss: 0.6300861239433289
Validation loss: 2.223041440049807

Epoch: 5| Step: 10
Training loss: 0.8346484899520874
Validation loss: 2.2540103445450463

Epoch: 5| Step: 11
Training loss: 0.7062952518463135
Validation loss: 2.2220336198806763

Epoch: 225| Step: 0
Training loss: 0.41942572593688965
Validation loss: 2.1596207916736603

Epoch: 5| Step: 1
Training loss: 0.9642683863639832
Validation loss: 2.163165251413981

Epoch: 5| Step: 2
Training loss: 0.626202404499054
Validation loss: 2.2318878968556723

Epoch: 5| Step: 3
Training loss: 0.6024554371833801
Validation loss: 2.191363791624705

Epoch: 5| Step: 4
Training loss: 0.6175573468208313
Validation loss: 2.242974857489268

Epoch: 5| Step: 5
Training loss: 0.7287758588790894
Validation loss: 2.2400506188472114

Epoch: 5| Step: 6
Training loss: 1.0301949977874756
Validation loss: 2.284217302997907

Epoch: 5| Step: 7
Training loss: 0.4200010299682617
Validation loss: 2.2326156397660575

Epoch: 5| Step: 8
Training loss: 0.8524104952812195
Validation loss: 2.2187703202168145

Epoch: 5| Step: 9
Training loss: 0.5055749416351318
Validation loss: 2.2829129795233407

Epoch: 5| Step: 10
Training loss: 1.0384693145751953
Validation loss: 2.317315469185511

Epoch: 5| Step: 11
Training loss: 0.5000157356262207
Validation loss: 2.2921160658200583

Epoch: 226| Step: 0
Training loss: 0.6204851269721985
Validation loss: 2.31541083753109

Epoch: 5| Step: 1
Training loss: 0.6972736120223999
Validation loss: 2.2613518238067627

Epoch: 5| Step: 2
Training loss: 0.659574031829834
Validation loss: 2.2681024074554443

Epoch: 5| Step: 3
Training loss: 0.46972283720970154
Validation loss: 2.2852690517902374

Epoch: 5| Step: 4
Training loss: 0.8560001254081726
Validation loss: 2.261352921525637

Epoch: 5| Step: 5
Training loss: 1.121791958808899
Validation loss: 2.264868825674057

Epoch: 5| Step: 6
Training loss: 0.48344898223876953
Validation loss: 2.22828138868014

Epoch: 5| Step: 7
Training loss: 0.739690899848938
Validation loss: 2.220218002796173

Epoch: 5| Step: 8
Training loss: 0.7459479570388794
Validation loss: 2.163696140050888

Epoch: 5| Step: 9
Training loss: 0.7113629579544067
Validation loss: 2.3042221069335938

Epoch: 5| Step: 10
Training loss: 0.8785940408706665
Validation loss: 2.2263805170853934

Epoch: 5| Step: 11
Training loss: 1.0564970970153809
Validation loss: 2.2526781062285104

Epoch: 227| Step: 0
Training loss: 0.46542683243751526
Validation loss: 2.1855909625689187

Epoch: 5| Step: 1
Training loss: 0.471017450094223
Validation loss: 2.2124932557344437

Epoch: 5| Step: 2
Training loss: 0.4167424142360687
Validation loss: 2.196681653459867

Epoch: 5| Step: 3
Training loss: 0.5095664262771606
Validation loss: 2.199775184194247

Epoch: 5| Step: 4
Training loss: 0.9493036270141602
Validation loss: 2.1806064347426095

Epoch: 5| Step: 5
Training loss: 1.2612783908843994
Validation loss: 2.1888589709997177

Epoch: 5| Step: 6
Training loss: 1.052551031112671
Validation loss: 2.2503812114397683

Epoch: 5| Step: 7
Training loss: 0.4895142614841461
Validation loss: 2.166464606920878

Epoch: 5| Step: 8
Training loss: 0.69676274061203
Validation loss: 2.222076545159022

Epoch: 5| Step: 9
Training loss: 0.6145059466362
Validation loss: 2.216358572244644

Epoch: 5| Step: 10
Training loss: 0.5741646885871887
Validation loss: 2.2716774145762124

Epoch: 5| Step: 11
Training loss: 0.9886813163757324
Validation loss: 2.192399417360624

Epoch: 228| Step: 0
Training loss: 0.4936556816101074
Validation loss: 2.193934549887975

Epoch: 5| Step: 1
Training loss: 0.3947471082210541
Validation loss: 2.2182189226150513

Epoch: 5| Step: 2
Training loss: 0.6287351846694946
Validation loss: 2.2060656547546387

Epoch: 5| Step: 3
Training loss: 0.5385264158248901
Validation loss: 2.2443519035975137

Epoch: 5| Step: 4
Training loss: 0.6715563535690308
Validation loss: 2.192429875334104

Epoch: 5| Step: 5
Training loss: 1.0078871250152588
Validation loss: 2.26215723156929

Epoch: 5| Step: 6
Training loss: 0.6958781480789185
Validation loss: 2.2341445088386536

Epoch: 5| Step: 7
Training loss: 0.9016315340995789
Validation loss: 2.2984465608994165

Epoch: 5| Step: 8
Training loss: 0.9386696815490723
Validation loss: 2.2733407467603683

Epoch: 5| Step: 9
Training loss: 0.40807756781578064
Validation loss: 2.2100096692641578

Epoch: 5| Step: 10
Training loss: 0.7828068733215332
Validation loss: 2.2924528072277703

Epoch: 5| Step: 11
Training loss: 0.6523702144622803
Validation loss: 2.2706512163082757

Epoch: 229| Step: 0
Training loss: 0.7474619150161743
Validation loss: 2.2647792597611747

Epoch: 5| Step: 1
Training loss: 0.5320865511894226
Validation loss: 2.2660544365644455

Epoch: 5| Step: 2
Training loss: 0.6723834872245789
Validation loss: 2.235054930051168

Epoch: 5| Step: 3
Training loss: 1.0150917768478394
Validation loss: 2.256696412960688

Epoch: 5| Step: 4
Training loss: 0.661849856376648
Validation loss: 2.2254391511281333

Epoch: 5| Step: 5
Training loss: 1.2422457933425903
Validation loss: 2.238412544131279

Epoch: 5| Step: 6
Training loss: 0.5759223699569702
Validation loss: 2.212727576494217

Epoch: 5| Step: 7
Training loss: 0.32708439230918884
Validation loss: 2.203722208738327

Epoch: 5| Step: 8
Training loss: 0.6088753938674927
Validation loss: 2.209707965453466

Epoch: 5| Step: 9
Training loss: 0.8025625944137573
Validation loss: 2.2486320237318673

Epoch: 5| Step: 10
Training loss: 0.6446421146392822
Validation loss: 2.2217072248458862

Epoch: 5| Step: 11
Training loss: 0.576567530632019
Validation loss: 2.208177457253138

Epoch: 230| Step: 0
Training loss: 0.3607616126537323
Validation loss: 2.1546309987703958

Epoch: 5| Step: 1
Training loss: 0.7811291813850403
Validation loss: 2.2201432635386786

Epoch: 5| Step: 2
Training loss: 0.6638804078102112
Validation loss: 2.1903974264860153

Epoch: 5| Step: 3
Training loss: 0.6049975156784058
Validation loss: 2.1804358462492623

Epoch: 5| Step: 4
Training loss: 0.4791167676448822
Validation loss: 2.2285199066003165

Epoch: 5| Step: 5
Training loss: 0.6962348222732544
Validation loss: 2.1684137185414634

Epoch: 5| Step: 6
Training loss: 0.7456592321395874
Validation loss: 2.1787804712851844

Epoch: 5| Step: 7
Training loss: 0.7671009302139282
Validation loss: 2.231984014312426

Epoch: 5| Step: 8
Training loss: 0.8931391835212708
Validation loss: 2.2230224510033927

Epoch: 5| Step: 9
Training loss: 0.6543528437614441
Validation loss: 2.186884035666784

Epoch: 5| Step: 10
Training loss: 0.7848467230796814
Validation loss: 2.1650794992844262

Epoch: 5| Step: 11
Training loss: 2.049471616744995
Validation loss: 2.205840249856313

Epoch: 231| Step: 0
Training loss: 0.5936040878295898
Validation loss: 2.0799197256565094

Epoch: 5| Step: 1
Training loss: 0.985905647277832
Validation loss: 2.1268054445584617

Epoch: 5| Step: 2
Training loss: 0.7802287340164185
Validation loss: 2.167431394259135

Epoch: 5| Step: 3
Training loss: 0.7766520380973816
Validation loss: 2.197656278808912

Epoch: 5| Step: 4
Training loss: 0.7201825380325317
Validation loss: 2.1316555440425873

Epoch: 5| Step: 5
Training loss: 0.6440742611885071
Validation loss: 2.108646218975385

Epoch: 5| Step: 6
Training loss: 0.6128144264221191
Validation loss: 2.1291302194197974

Epoch: 5| Step: 7
Training loss: 0.49706587195396423
Validation loss: 2.0845714757839837

Epoch: 5| Step: 8
Training loss: 0.45156389474868774
Validation loss: 2.2139423539241156

Epoch: 5| Step: 9
Training loss: 0.5363532900810242
Validation loss: 2.2052722920974097

Epoch: 5| Step: 10
Training loss: 0.7041044235229492
Validation loss: 2.180679112672806

Epoch: 5| Step: 11
Training loss: 0.42767810821533203
Validation loss: 2.1849416891733804

Epoch: 232| Step: 0
Training loss: 0.7216187715530396
Validation loss: 2.1490027705828347

Epoch: 5| Step: 1
Training loss: 0.6634958982467651
Validation loss: 2.170117288827896

Epoch: 5| Step: 2
Training loss: 0.46602827310562134
Validation loss: 2.1631862819194794

Epoch: 5| Step: 3
Training loss: 0.504418134689331
Validation loss: 2.156011924147606

Epoch: 5| Step: 4
Training loss: 0.8122372627258301
Validation loss: 2.1692240287860236

Epoch: 5| Step: 5
Training loss: 1.0445634126663208
Validation loss: 2.2164232979218164

Epoch: 5| Step: 6
Training loss: 0.47300615906715393
Validation loss: 2.207326978445053

Epoch: 5| Step: 7
Training loss: 0.5611093640327454
Validation loss: 2.243130683898926

Epoch: 5| Step: 8
Training loss: 0.6323863863945007
Validation loss: 2.2669666012128196

Epoch: 5| Step: 9
Training loss: 0.6964280605316162
Validation loss: 2.2175403932730355

Epoch: 5| Step: 10
Training loss: 0.5565410256385803
Validation loss: 2.234504982829094

Epoch: 5| Step: 11
Training loss: 0.8847669363021851
Validation loss: 2.1906606455643973

Epoch: 233| Step: 0
Training loss: 0.4950990676879883
Validation loss: 2.162177080909411

Epoch: 5| Step: 1
Training loss: 0.6531821489334106
Validation loss: 2.254933868845304

Epoch: 5| Step: 2
Training loss: 0.5313211679458618
Validation loss: 2.2034966200590134

Epoch: 5| Step: 3
Training loss: 0.7383807301521301
Validation loss: 2.1631773114204407

Epoch: 5| Step: 4
Training loss: 0.6354562640190125
Validation loss: 2.1368812769651413

Epoch: 5| Step: 5
Training loss: 0.7229941487312317
Validation loss: 2.212743898232778

Epoch: 5| Step: 6
Training loss: 0.5491443872451782
Validation loss: 2.207373301188151

Epoch: 5| Step: 7
Training loss: 0.6611685752868652
Validation loss: 2.190925026933352

Epoch: 5| Step: 8
Training loss: 1.199906349182129
Validation loss: 2.213015620907148

Epoch: 5| Step: 9
Training loss: 0.8462471961975098
Validation loss: 2.2475754072268805

Epoch: 5| Step: 10
Training loss: 0.7115673422813416
Validation loss: 2.2401604801416397

Epoch: 5| Step: 11
Training loss: 0.7556276321411133
Validation loss: 2.1528370330731073

Epoch: 234| Step: 0
Training loss: 0.5983559489250183
Validation loss: 2.1616356621185937

Epoch: 5| Step: 1
Training loss: 0.5895475149154663
Validation loss: 2.1500582098960876

Epoch: 5| Step: 2
Training loss: 0.914569079875946
Validation loss: 2.1691729525725045

Epoch: 5| Step: 3
Training loss: 1.013897180557251
Validation loss: 2.141726240515709

Epoch: 5| Step: 4
Training loss: 0.5427249670028687
Validation loss: 2.1138729651769004

Epoch: 5| Step: 5
Training loss: 1.0365947484970093
Validation loss: 2.172020266453425

Epoch: 5| Step: 6
Training loss: 0.6280972957611084
Validation loss: 2.135421246290207

Epoch: 5| Step: 7
Training loss: 0.60307776927948
Validation loss: 2.1382199625174203

Epoch: 5| Step: 8
Training loss: 0.3671566843986511
Validation loss: 2.1975718637307486

Epoch: 5| Step: 9
Training loss: 0.3224233388900757
Validation loss: 2.1226718723773956

Epoch: 5| Step: 10
Training loss: 0.589835524559021
Validation loss: 2.1708369304736457

Epoch: 5| Step: 11
Training loss: 0.2434738278388977
Validation loss: 2.1195178776979446

Epoch: 235| Step: 0
Training loss: 0.6874189376831055
Validation loss: 2.1669935286045074

Epoch: 5| Step: 1
Training loss: 0.9658496975898743
Validation loss: 2.2139712125062943

Epoch: 5| Step: 2
Training loss: 0.8099883794784546
Validation loss: 2.2071772118409476

Epoch: 5| Step: 3
Training loss: 0.5032902956008911
Validation loss: 2.2185091574986777

Epoch: 5| Step: 4
Training loss: 0.45771265029907227
Validation loss: 2.2077143291632333

Epoch: 5| Step: 5
Training loss: 0.6215955018997192
Validation loss: 2.2076723674933114

Epoch: 5| Step: 6
Training loss: 1.1381365060806274
Validation loss: 2.24010868370533

Epoch: 5| Step: 7
Training loss: 0.3897765278816223
Validation loss: 2.1752924968798957

Epoch: 5| Step: 8
Training loss: 0.7184126973152161
Validation loss: 2.22358671327432

Epoch: 5| Step: 9
Training loss: 0.657974123954773
Validation loss: 2.1649931222200394

Epoch: 5| Step: 10
Training loss: 0.5615711808204651
Validation loss: 2.215260863304138

Epoch: 5| Step: 11
Training loss: 0.3459765911102295
Validation loss: 2.1763390749692917

Epoch: 236| Step: 0
Training loss: 0.8393099904060364
Validation loss: 2.214615305264791

Epoch: 5| Step: 1
Training loss: 0.5106233358383179
Validation loss: 2.2430912256240845

Epoch: 5| Step: 2
Training loss: 0.7778394818305969
Validation loss: 2.2576420605182648

Epoch: 5| Step: 3
Training loss: 0.5915071368217468
Validation loss: 2.228409210840861

Epoch: 5| Step: 4
Training loss: 0.891266942024231
Validation loss: 2.2650489012400308

Epoch: 5| Step: 5
Training loss: 0.9098153114318848
Validation loss: 2.2103781600793204

Epoch: 5| Step: 6
Training loss: 0.7899190187454224
Validation loss: 2.2500664393107095

Epoch: 5| Step: 7
Training loss: 0.5911425352096558
Validation loss: 2.298766111334165

Epoch: 5| Step: 8
Training loss: 0.8272102475166321
Validation loss: 2.3313439885775247

Epoch: 5| Step: 9
Training loss: 0.7203702926635742
Validation loss: 2.2525831510623298

Epoch: 5| Step: 10
Training loss: 0.5944056510925293
Validation loss: 2.230650871992111

Epoch: 5| Step: 11
Training loss: 0.2809007167816162
Validation loss: 2.150430594881376

Epoch: 237| Step: 0
Training loss: 0.6821349263191223
Validation loss: 2.2110429207483926

Epoch: 5| Step: 1
Training loss: 0.7400780320167542
Validation loss: 2.201092297832171

Epoch: 5| Step: 2
Training loss: 0.871791660785675
Validation loss: 2.2435003419717154

Epoch: 5| Step: 3
Training loss: 0.7631059885025024
Validation loss: 2.1934088369210563

Epoch: 5| Step: 4
Training loss: 0.6262970566749573
Validation loss: 2.2299722333749137

Epoch: 5| Step: 5
Training loss: 0.6653612852096558
Validation loss: 2.226672500371933

Epoch: 5| Step: 6
Training loss: 0.6406869888305664
Validation loss: 2.236605073014895

Epoch: 5| Step: 7
Training loss: 0.47802719473838806
Validation loss: 2.2594568779071174

Epoch: 5| Step: 8
Training loss: 1.1870344877243042
Validation loss: 2.197824160257975

Epoch: 5| Step: 9
Training loss: 0.47579675912857056
Validation loss: 2.182926038901011

Epoch: 5| Step: 10
Training loss: 1.1808418035507202
Validation loss: 2.1660225292046866

Epoch: 5| Step: 11
Training loss: 0.32369929552078247
Validation loss: 2.2043351531028748

Epoch: 238| Step: 0
Training loss: 0.46560367941856384
Validation loss: 2.141934797167778

Epoch: 5| Step: 1
Training loss: 1.0691776275634766
Validation loss: 2.1820207039515176

Epoch: 5| Step: 2
Training loss: 0.5282668471336365
Validation loss: 2.231877088546753

Epoch: 5| Step: 3
Training loss: 0.5358823537826538
Validation loss: 2.216679106156031

Epoch: 5| Step: 4
Training loss: 0.6968917846679688
Validation loss: 2.199176420768102

Epoch: 5| Step: 5
Training loss: 0.4271858334541321
Validation loss: 2.2377884089946747

Epoch: 5| Step: 6
Training loss: 0.6318355202674866
Validation loss: 2.222954958677292

Epoch: 5| Step: 7
Training loss: 0.5018559694290161
Validation loss: 2.189483717083931

Epoch: 5| Step: 8
Training loss: 0.717593789100647
Validation loss: 2.17109614610672

Epoch: 5| Step: 9
Training loss: 0.6968703269958496
Validation loss: 2.1812654634316764

Epoch: 5| Step: 10
Training loss: 0.9763778448104858
Validation loss: 2.239623467127482

Epoch: 5| Step: 11
Training loss: 1.0018469095230103
Validation loss: 2.1999490608771644

Epoch: 239| Step: 0
Training loss: 0.7836188673973083
Validation loss: 2.2569832652807236

Epoch: 5| Step: 1
Training loss: 0.5579565167427063
Validation loss: 2.201010748744011

Epoch: 5| Step: 2
Training loss: 0.8745107650756836
Validation loss: 2.2220448007186255

Epoch: 5| Step: 3
Training loss: 0.629015326499939
Validation loss: 2.1764313081900277

Epoch: 5| Step: 4
Training loss: 0.4410763382911682
Validation loss: 2.2156710624694824

Epoch: 5| Step: 5
Training loss: 0.5021699666976929
Validation loss: 2.171770383914312

Epoch: 5| Step: 6
Training loss: 0.624241292476654
Validation loss: 2.198566049337387

Epoch: 5| Step: 7
Training loss: 0.5536264181137085
Validation loss: 2.2335313012202582

Epoch: 5| Step: 8
Training loss: 0.48355865478515625
Validation loss: 2.1745493610699973

Epoch: 5| Step: 9
Training loss: 0.7331873178482056
Validation loss: 2.1749599625666938

Epoch: 5| Step: 10
Training loss: 0.8582919836044312
Validation loss: 2.2001023441553116

Epoch: 5| Step: 11
Training loss: 0.8058805465698242
Validation loss: 2.2060997684796653

Epoch: 240| Step: 0
Training loss: 0.5861481428146362
Validation loss: 2.1733503341674805

Epoch: 5| Step: 1
Training loss: 0.5510618686676025
Validation loss: 2.17722350358963

Epoch: 5| Step: 2
Training loss: 0.4894684851169586
Validation loss: 2.2059620916843414

Epoch: 5| Step: 3
Training loss: 0.6550441980361938
Validation loss: 2.2262243976195655

Epoch: 5| Step: 4
Training loss: 0.5438650250434875
Validation loss: 2.230094000697136

Epoch: 5| Step: 5
Training loss: 0.7784795165061951
Validation loss: 2.1720029364029565

Epoch: 5| Step: 6
Training loss: 0.7419356107711792
Validation loss: 2.138570467631022

Epoch: 5| Step: 7
Training loss: 0.44979581236839294
Validation loss: 2.138884276151657

Epoch: 5| Step: 8
Training loss: 0.9544819593429565
Validation loss: 2.197923610607783

Epoch: 5| Step: 9
Training loss: 0.576539158821106
Validation loss: 2.1735930293798447

Epoch: 5| Step: 10
Training loss: 0.7619434595108032
Validation loss: 2.159429575006167

Epoch: 5| Step: 11
Training loss: 0.604616105556488
Validation loss: 2.219120184580485

Epoch: 241| Step: 0
Training loss: 0.45686110854148865
Validation loss: 2.135373572508494

Epoch: 5| Step: 1
Training loss: 0.3741290271282196
Validation loss: 2.181606521209081

Epoch: 5| Step: 2
Training loss: 0.39727696776390076
Validation loss: 2.20732174317042

Epoch: 5| Step: 3
Training loss: 0.5672539472579956
Validation loss: 2.2106619576613107

Epoch: 5| Step: 4
Training loss: 0.4304347038269043
Validation loss: 2.1852747152249017

Epoch: 5| Step: 5
Training loss: 0.6482592225074768
Validation loss: 2.147542412082354

Epoch: 5| Step: 6
Training loss: 1.0326626300811768
Validation loss: 2.185285617907842

Epoch: 5| Step: 7
Training loss: 0.9755875468254089
Validation loss: 2.21490012605985

Epoch: 5| Step: 8
Training loss: 0.4778212606906891
Validation loss: 2.165207266807556

Epoch: 5| Step: 9
Training loss: 0.4956381916999817
Validation loss: 2.249713659286499

Epoch: 5| Step: 10
Training loss: 0.9926069974899292
Validation loss: 2.211395258704821

Epoch: 5| Step: 11
Training loss: 0.4666508436203003
Validation loss: 2.2262284259001413

Epoch: 242| Step: 0
Training loss: 0.5641918182373047
Validation loss: 2.2419949074586234

Epoch: 5| Step: 1
Training loss: 0.5227957963943481
Validation loss: 2.2224390705426535

Epoch: 5| Step: 2
Training loss: 0.5398463606834412
Validation loss: 2.27152148882548

Epoch: 5| Step: 3
Training loss: 0.7418163418769836
Validation loss: 2.2672477265199027

Epoch: 5| Step: 4
Training loss: 0.7304194569587708
Validation loss: 2.254325141509374

Epoch: 5| Step: 5
Training loss: 0.6794153451919556
Validation loss: 2.176984205842018

Epoch: 5| Step: 6
Training loss: 0.7464431524276733
Validation loss: 2.175668607155482

Epoch: 5| Step: 7
Training loss: 0.7779022455215454
Validation loss: 2.280782714486122

Epoch: 5| Step: 8
Training loss: 0.7758822441101074
Validation loss: 2.2884366512298584

Epoch: 5| Step: 9
Training loss: 0.4064445495605469
Validation loss: 2.248483886321386

Epoch: 5| Step: 10
Training loss: 0.4687590003013611
Validation loss: 2.22722460826238

Epoch: 5| Step: 11
Training loss: 0.32030045986175537
Validation loss: 2.2393846958875656

Epoch: 243| Step: 0
Training loss: 0.47711172699928284
Validation loss: 2.2859373490015664

Epoch: 5| Step: 1
Training loss: 1.1358911991119385
Validation loss: 2.2809261282285056

Epoch: 5| Step: 2
Training loss: 0.8415659070014954
Validation loss: 2.2170099367698035

Epoch: 5| Step: 3
Training loss: 0.5793367624282837
Validation loss: 2.2271980245908103

Epoch: 5| Step: 4
Training loss: 0.6342303156852722
Validation loss: 2.249449903766314

Epoch: 5| Step: 5
Training loss: 0.5798210501670837
Validation loss: 2.1894837270180383

Epoch: 5| Step: 6
Training loss: 0.5135246515274048
Validation loss: 2.2536913255850473

Epoch: 5| Step: 7
Training loss: 0.6180386543273926
Validation loss: 2.249746764699618

Epoch: 5| Step: 8
Training loss: 0.8380597829818726
Validation loss: 2.239555537700653

Epoch: 5| Step: 9
Training loss: 0.4349603056907654
Validation loss: 2.22096619506677

Epoch: 5| Step: 10
Training loss: 0.6086812019348145
Validation loss: 2.1890211204687753

Epoch: 5| Step: 11
Training loss: 0.7575467228889465
Validation loss: 2.2195966939131417

Epoch: 244| Step: 0
Training loss: 0.5601563453674316
Validation loss: 2.24684410293897

Epoch: 5| Step: 1
Training loss: 0.742538332939148
Validation loss: 2.1976800858974457

Epoch: 5| Step: 2
Training loss: 0.8563283085823059
Validation loss: 2.235237419605255

Epoch: 5| Step: 3
Training loss: 0.6789460182189941
Validation loss: 2.2409102519353232

Epoch: 5| Step: 4
Training loss: 0.43321651220321655
Validation loss: 2.259580830732981

Epoch: 5| Step: 5
Training loss: 0.5876916646957397
Validation loss: 2.2391582975784936

Epoch: 5| Step: 6
Training loss: 0.7428344488143921
Validation loss: 2.2341753095388412

Epoch: 5| Step: 7
Training loss: 0.40845614671707153
Validation loss: 2.182882080475489

Epoch: 5| Step: 8
Training loss: 0.45720261335372925
Validation loss: 2.216193755467733

Epoch: 5| Step: 9
Training loss: 0.7128409147262573
Validation loss: 2.201166570186615

Epoch: 5| Step: 10
Training loss: 0.6154327392578125
Validation loss: 2.2243250956137977

Epoch: 5| Step: 11
Training loss: 1.7083954811096191
Validation loss: 2.208344986041387

Epoch: 245| Step: 0
Training loss: 0.5587729215621948
Validation loss: 2.305272698402405

Epoch: 5| Step: 1
Training loss: 0.6258532404899597
Validation loss: 2.1693783700466156

Epoch: 5| Step: 2
Training loss: 0.6051861643791199
Validation loss: 2.2621047596136727

Epoch: 5| Step: 3
Training loss: 1.0385478734970093
Validation loss: 2.2382786025603614

Epoch: 5| Step: 4
Training loss: 0.6248767375946045
Validation loss: 2.2557097524404526

Epoch: 5| Step: 5
Training loss: 0.5038880109786987
Validation loss: 2.203443333506584

Epoch: 5| Step: 6
Training loss: 0.6430166959762573
Validation loss: 2.2138907810052237

Epoch: 5| Step: 7
Training loss: 0.31415462493896484
Validation loss: 2.309909696380297

Epoch: 5| Step: 8
Training loss: 0.5236243009567261
Validation loss: 2.231793334086736

Epoch: 5| Step: 9
Training loss: 0.8789492845535278
Validation loss: 2.3104314307371774

Epoch: 5| Step: 10
Training loss: 0.6026638150215149
Validation loss: 2.280509889125824

Epoch: 5| Step: 11
Training loss: 0.369769811630249
Validation loss: 2.2422080487012863

Epoch: 246| Step: 0
Training loss: 0.45868149399757385
Validation loss: 2.2237034738063812

Epoch: 5| Step: 1
Training loss: 0.6371501088142395
Validation loss: 2.2185477713743844

Epoch: 5| Step: 2
Training loss: 0.37326812744140625
Validation loss: 2.2533133725325265

Epoch: 5| Step: 3
Training loss: 0.4949325919151306
Validation loss: 2.198108692963918

Epoch: 5| Step: 4
Training loss: 0.7741833925247192
Validation loss: 2.264826054374377

Epoch: 5| Step: 5
Training loss: 0.3837427496910095
Validation loss: 2.226900185147921

Epoch: 5| Step: 6
Training loss: 0.8718032836914062
Validation loss: 2.2410794297854104

Epoch: 5| Step: 7
Training loss: 0.47216281294822693
Validation loss: 2.285078306992849

Epoch: 5| Step: 8
Training loss: 0.639186680316925
Validation loss: 2.2149647871653237

Epoch: 5| Step: 9
Training loss: 0.7968850135803223
Validation loss: 2.2215897838274636

Epoch: 5| Step: 10
Training loss: 0.6474130749702454
Validation loss: 2.2228692968686423

Epoch: 5| Step: 11
Training loss: 0.4983615279197693
Validation loss: 2.222076416015625

Epoch: 247| Step: 0
Training loss: 0.5416404008865356
Validation loss: 2.23230941593647

Epoch: 5| Step: 1
Training loss: 1.0148693323135376
Validation loss: 2.161028504371643

Epoch: 5| Step: 2
Training loss: 0.5706645846366882
Validation loss: 2.245341047644615

Epoch: 5| Step: 3
Training loss: 0.5010102987289429
Validation loss: 2.20059102276961

Epoch: 5| Step: 4
Training loss: 0.49164876341819763
Validation loss: 2.1684730798006058

Epoch: 5| Step: 5
Training loss: 0.37918657064437866
Validation loss: 2.1860107680161796

Epoch: 5| Step: 6
Training loss: 0.5295461416244507
Validation loss: 2.233498692512512

Epoch: 5| Step: 7
Training loss: 0.7280333042144775
Validation loss: 2.228254700700442

Epoch: 5| Step: 8
Training loss: 0.5452901721000671
Validation loss: 2.1944203972816467

Epoch: 5| Step: 9
Training loss: 0.5563856363296509
Validation loss: 2.225737581650416

Epoch: 5| Step: 10
Training loss: 0.6115256547927856
Validation loss: 2.176737447579702

Epoch: 5| Step: 11
Training loss: 0.17448091506958008
Validation loss: 2.1516440510749817

Epoch: 248| Step: 0
Training loss: 0.4318012595176697
Validation loss: 2.1685237884521484

Epoch: 5| Step: 1
Training loss: 0.7184597849845886
Validation loss: 2.217807893951734

Epoch: 5| Step: 2
Training loss: 0.4307915270328522
Validation loss: 2.2027337501446405

Epoch: 5| Step: 3
Training loss: 0.8928868174552917
Validation loss: 2.239906460046768

Epoch: 5| Step: 4
Training loss: 0.42897042632102966
Validation loss: 2.195999801158905

Epoch: 5| Step: 5
Training loss: 0.41431087255477905
Validation loss: 2.2233479420344033

Epoch: 5| Step: 6
Training loss: 0.5227110981941223
Validation loss: 2.1887900978326797

Epoch: 5| Step: 7
Training loss: 0.6615954041481018
Validation loss: 2.2052111327648163

Epoch: 5| Step: 8
Training loss: 0.6941692233085632
Validation loss: 2.221170167128245

Epoch: 5| Step: 9
Training loss: 0.47382718324661255
Validation loss: 2.223299890756607

Epoch: 5| Step: 10
Training loss: 0.7266278266906738
Validation loss: 2.2420251766840615

Epoch: 5| Step: 11
Training loss: 0.2930101156234741
Validation loss: 2.275670031706492

Epoch: 249| Step: 0
Training loss: 0.48114538192749023
Validation loss: 2.2037688295046487

Epoch: 5| Step: 1
Training loss: 0.7388864755630493
Validation loss: 2.246340254942576

Epoch: 5| Step: 2
Training loss: 0.6514603495597839
Validation loss: 2.247871528069178

Epoch: 5| Step: 3
Training loss: 0.4741673469543457
Validation loss: 2.2695660392443338

Epoch: 5| Step: 4
Training loss: 0.39635199308395386
Validation loss: 2.1919370839993157

Epoch: 5| Step: 5
Training loss: 0.4215250015258789
Validation loss: 2.266731629769007

Epoch: 5| Step: 6
Training loss: 0.4955064356327057
Validation loss: 2.189003308614095

Epoch: 5| Step: 7
Training loss: 0.5951167941093445
Validation loss: 2.2082370469967523

Epoch: 5| Step: 8
Training loss: 0.6010582447052002
Validation loss: 2.2482994198799133

Epoch: 5| Step: 9
Training loss: 0.8438553810119629
Validation loss: 2.175951808691025

Epoch: 5| Step: 10
Training loss: 0.3782753050327301
Validation loss: 2.1486042638619742

Epoch: 5| Step: 11
Training loss: 2.271660804748535
Validation loss: 2.2638531724611917

Epoch: 250| Step: 0
Training loss: 0.43417835235595703
Validation loss: 2.2560993234316506

Epoch: 5| Step: 1
Training loss: 0.5755087733268738
Validation loss: 2.2433718095223107

Epoch: 5| Step: 2
Training loss: 0.3691721260547638
Validation loss: 2.1911105811595917

Epoch: 5| Step: 3
Training loss: 0.5238138437271118
Validation loss: 2.238936185836792

Epoch: 5| Step: 4
Training loss: 0.8519200086593628
Validation loss: 2.1751352151234946

Epoch: 5| Step: 5
Training loss: 0.43701237440109253
Validation loss: 2.221352199713389

Epoch: 5| Step: 6
Training loss: 0.7380097508430481
Validation loss: 2.260017996033033

Epoch: 5| Step: 7
Training loss: 0.5369132161140442
Validation loss: 2.25687542061011

Epoch: 5| Step: 8
Training loss: 1.1746865510940552
Validation loss: 2.2135283648967743

Epoch: 5| Step: 9
Training loss: 0.7263844609260559
Validation loss: 2.1987220644950867

Epoch: 5| Step: 10
Training loss: 0.545829176902771
Validation loss: 2.246594915787379

Epoch: 5| Step: 11
Training loss: 0.731055736541748
Validation loss: 2.2192902863025665

Epoch: 251| Step: 0
Training loss: 0.5309171676635742
Validation loss: 2.275175154209137

Epoch: 5| Step: 1
Training loss: 0.4516587257385254
Validation loss: 2.2567033221324286

Epoch: 5| Step: 2
Training loss: 0.8232457041740417
Validation loss: 2.20806414882342

Epoch: 5| Step: 3
Training loss: 0.558969259262085
Validation loss: 2.255837390820185

Epoch: 5| Step: 4
Training loss: 0.6557292342185974
Validation loss: 2.197138021389643

Epoch: 5| Step: 5
Training loss: 0.5147446990013123
Validation loss: 2.173250123858452

Epoch: 5| Step: 6
Training loss: 0.5982760190963745
Validation loss: 2.1965279479821525

Epoch: 5| Step: 7
Training loss: 0.7087115049362183
Validation loss: 2.2471557358900704

Epoch: 5| Step: 8
Training loss: 0.8000262975692749
Validation loss: 2.212589999039968

Epoch: 5| Step: 9
Training loss: 0.5356950163841248
Validation loss: 2.2155627508958182

Epoch: 5| Step: 10
Training loss: 0.6052356958389282
Validation loss: 2.2173364013433456

Epoch: 5| Step: 11
Training loss: 0.3084491491317749
Validation loss: 2.165609081586202

Epoch: 252| Step: 0
Training loss: 0.3953210413455963
Validation loss: 2.1756795942783356

Epoch: 5| Step: 1
Training loss: 0.5845504403114319
Validation loss: 2.1992996583382287

Epoch: 5| Step: 2
Training loss: 0.5657219886779785
Validation loss: 2.2323189874490104

Epoch: 5| Step: 3
Training loss: 0.5385738611221313
Validation loss: 2.1845593800147376

Epoch: 5| Step: 4
Training loss: 0.46200260519981384
Validation loss: 2.169722711046537

Epoch: 5| Step: 5
Training loss: 0.7557860612869263
Validation loss: 2.2078448285659156

Epoch: 5| Step: 6
Training loss: 0.6240580677986145
Validation loss: 2.142927865187327

Epoch: 5| Step: 7
Training loss: 0.6636156439781189
Validation loss: 2.1959476371606192

Epoch: 5| Step: 8
Training loss: 0.8421229124069214
Validation loss: 2.2628809611002603

Epoch: 5| Step: 9
Training loss: 0.7921410202980042
Validation loss: 2.1582718789577484

Epoch: 5| Step: 10
Training loss: 0.5868196487426758
Validation loss: 2.1711039741834006

Epoch: 5| Step: 11
Training loss: 0.379966676235199
Validation loss: 2.175273468097051

Epoch: 253| Step: 0
Training loss: 0.671088695526123
Validation loss: 2.150691270828247

Epoch: 5| Step: 1
Training loss: 0.4576301574707031
Validation loss: 2.2097815523544946

Epoch: 5| Step: 2
Training loss: 0.5598565936088562
Validation loss: 2.207463706533114

Epoch: 5| Step: 3
Training loss: 0.4840138852596283
Validation loss: 2.152237892150879

Epoch: 5| Step: 4
Training loss: 0.37518855929374695
Validation loss: 2.2353521386782327

Epoch: 5| Step: 5
Training loss: 0.36012759804725647
Validation loss: 2.2369281351566315

Epoch: 5| Step: 6
Training loss: 0.5718693733215332
Validation loss: 2.206546535094579

Epoch: 5| Step: 7
Training loss: 0.6047672629356384
Validation loss: 2.201365446050962

Epoch: 5| Step: 8
Training loss: 1.090907335281372
Validation loss: 2.236867070198059

Epoch: 5| Step: 9
Training loss: 0.7509111762046814
Validation loss: 2.20152880748113

Epoch: 5| Step: 10
Training loss: 0.42888563871383667
Validation loss: 2.2231529355049133

Epoch: 5| Step: 11
Training loss: 0.7848744988441467
Validation loss: 2.2663311809301376

Epoch: 254| Step: 0
Training loss: 0.6311511397361755
Validation loss: 2.2161409159501395

Epoch: 5| Step: 1
Training loss: 0.6130959987640381
Validation loss: 2.234659880399704

Epoch: 5| Step: 2
Training loss: 0.6748355627059937
Validation loss: 2.28964601457119

Epoch: 5| Step: 3
Training loss: 0.6700922846794128
Validation loss: 2.2561531166235604

Epoch: 5| Step: 4
Training loss: 0.388457328081131
Validation loss: 2.217649757862091

Epoch: 5| Step: 5
Training loss: 0.4906485974788666
Validation loss: 2.251721208294233

Epoch: 5| Step: 6
Training loss: 0.6172360181808472
Validation loss: 2.221436003843943

Epoch: 5| Step: 7
Training loss: 0.6038606762886047
Validation loss: 2.2823356141646705

Epoch: 5| Step: 8
Training loss: 0.5872675180435181
Validation loss: 2.251280039548874

Epoch: 5| Step: 9
Training loss: 0.5465429425239563
Validation loss: 2.278738796710968

Epoch: 5| Step: 10
Training loss: 0.7771083116531372
Validation loss: 2.2179888635873795

Epoch: 5| Step: 11
Training loss: 0.6961972713470459
Validation loss: 2.2074478417634964

Epoch: 255| Step: 0
Training loss: 0.49897289276123047
Validation loss: 2.252867062886556

Epoch: 5| Step: 1
Training loss: 0.6465793251991272
Validation loss: 2.256081074476242

Epoch: 5| Step: 2
Training loss: 0.49861660599708557
Validation loss: 2.1935921758413315

Epoch: 5| Step: 3
Training loss: 0.579494297504425
Validation loss: 2.2270903289318085

Epoch: 5| Step: 4
Training loss: 0.3586180806159973
Validation loss: 2.255992462237676

Epoch: 5| Step: 5
Training loss: 0.4208197593688965
Validation loss: 2.2475978632767997

Epoch: 5| Step: 6
Training loss: 1.0893123149871826
Validation loss: 2.254903773466746

Epoch: 5| Step: 7
Training loss: 0.7086340188980103
Validation loss: 2.3277511447668076

Epoch: 5| Step: 8
Training loss: 0.5035344958305359
Validation loss: 2.276693423589071

Epoch: 5| Step: 9
Training loss: 0.4917137026786804
Validation loss: 2.2128193279107413

Epoch: 5| Step: 10
Training loss: 0.48730048537254333
Validation loss: 2.2451684375603995

Epoch: 5| Step: 11
Training loss: 0.8256632685661316
Validation loss: 2.1911382973194122

Epoch: 256| Step: 0
Training loss: 0.48518481850624084
Validation loss: 2.1781829247872033

Epoch: 5| Step: 1
Training loss: 0.8157321810722351
Validation loss: 2.2077930519978204

Epoch: 5| Step: 2
Training loss: 0.33115336298942566
Validation loss: 2.1743087768554688

Epoch: 5| Step: 3
Training loss: 0.5366140007972717
Validation loss: 2.253155122200648

Epoch: 5| Step: 4
Training loss: 0.4257686138153076
Validation loss: 2.2599094162384668

Epoch: 5| Step: 5
Training loss: 1.025963306427002
Validation loss: 2.1731302042802176

Epoch: 5| Step: 6
Training loss: 0.7261196970939636
Validation loss: 2.222411890824636

Epoch: 5| Step: 7
Training loss: 0.6717711687088013
Validation loss: 2.160045941670736

Epoch: 5| Step: 8
Training loss: 0.6279231309890747
Validation loss: 2.2277793486913047

Epoch: 5| Step: 9
Training loss: 0.6510529518127441
Validation loss: 2.1957905888557434

Epoch: 5| Step: 10
Training loss: 0.2633879780769348
Validation loss: 2.2120618422826133

Epoch: 5| Step: 11
Training loss: 0.2154591679573059
Validation loss: 2.1813241094350815

Epoch: 257| Step: 0
Training loss: 1.0072221755981445
Validation loss: 2.145059655110041

Epoch: 5| Step: 1
Training loss: 0.6663674116134644
Validation loss: 2.2040333251158395

Epoch: 5| Step: 2
Training loss: 0.4754207134246826
Validation loss: 2.155807221929232

Epoch: 5| Step: 3
Training loss: 0.5757230520248413
Validation loss: 2.1566702822844186

Epoch: 5| Step: 4
Training loss: 0.3259294629096985
Validation loss: 2.1320859293142953

Epoch: 5| Step: 5
Training loss: 0.8828541040420532
Validation loss: 2.221308787663778

Epoch: 5| Step: 6
Training loss: 0.6099694967269897
Validation loss: 2.2111413280169168

Epoch: 5| Step: 7
Training loss: 0.3329086899757385
Validation loss: 2.1712666054566703

Epoch: 5| Step: 8
Training loss: 0.6563138961791992
Validation loss: 2.2504020780324936

Epoch: 5| Step: 9
Training loss: 0.5385147929191589
Validation loss: 2.311912218729655

Epoch: 5| Step: 10
Training loss: 0.45308876037597656
Validation loss: 2.245884949962298

Epoch: 5| Step: 11
Training loss: 0.7725334763526917
Validation loss: 2.253252387046814

Epoch: 258| Step: 0
Training loss: 0.5475252270698547
Validation loss: 2.235746145248413

Epoch: 5| Step: 1
Training loss: 0.3969067633152008
Validation loss: 2.2496145218610764

Epoch: 5| Step: 2
Training loss: 0.46956920623779297
Validation loss: 2.2321990032990775

Epoch: 5| Step: 3
Training loss: 0.6445528268814087
Validation loss: 2.248876670996348

Epoch: 5| Step: 4
Training loss: 1.1497794389724731
Validation loss: 2.261852949857712

Epoch: 5| Step: 5
Training loss: 0.48211589455604553
Validation loss: 2.2144297460714975

Epoch: 5| Step: 6
Training loss: 0.5820587873458862
Validation loss: 2.251925533016523

Epoch: 5| Step: 7
Training loss: 0.588365912437439
Validation loss: 2.1982428828875222

Epoch: 5| Step: 8
Training loss: 0.3103828728199005
Validation loss: 2.184572080771128

Epoch: 5| Step: 9
Training loss: 0.5993622541427612
Validation loss: 2.2351422558228173

Epoch: 5| Step: 10
Training loss: 0.4794161319732666
Validation loss: 2.2579644868771234

Epoch: 5| Step: 11
Training loss: 0.43912559747695923
Validation loss: 2.260062704483668

Epoch: 259| Step: 0
Training loss: 0.6378709673881531
Validation loss: 2.267029802004496

Epoch: 5| Step: 1
Training loss: 0.6991397738456726
Validation loss: 2.195010463396708

Epoch: 5| Step: 2
Training loss: 0.7846993207931519
Validation loss: 2.199401617050171

Epoch: 5| Step: 3
Training loss: 0.6087490320205688
Validation loss: 2.1819456915060678

Epoch: 5| Step: 4
Training loss: 0.6493145823478699
Validation loss: 2.1965184956789017

Epoch: 5| Step: 5
Training loss: 0.601649820804596
Validation loss: 2.19684307773908

Epoch: 5| Step: 6
Training loss: 0.43122410774230957
Validation loss: 2.1852179567019143

Epoch: 5| Step: 7
Training loss: 0.6530750393867493
Validation loss: 2.15760305027167

Epoch: 5| Step: 8
Training loss: 0.5571380853652954
Validation loss: 2.2282486855983734

Epoch: 5| Step: 9
Training loss: 0.7365114688873291
Validation loss: 2.234151075283686

Epoch: 5| Step: 10
Training loss: 0.5264157056808472
Validation loss: 2.2146956821282706

Epoch: 5| Step: 11
Training loss: 0.30905383825302124
Validation loss: 2.202986086408297

Epoch: 260| Step: 0
Training loss: 0.4056776463985443
Validation loss: 2.218673676252365

Epoch: 5| Step: 1
Training loss: 0.5147889256477356
Validation loss: 2.209267814954122

Epoch: 5| Step: 2
Training loss: 0.37420105934143066
Validation loss: 2.1767376561959586

Epoch: 5| Step: 3
Training loss: 0.6614636778831482
Validation loss: 2.235478237271309

Epoch: 5| Step: 4
Training loss: 0.6509329080581665
Validation loss: 2.2299942076206207

Epoch: 5| Step: 5
Training loss: 0.6384113430976868
Validation loss: 2.2127219388882318

Epoch: 5| Step: 6
Training loss: 0.34984391927719116
Validation loss: 2.2357982645432153

Epoch: 5| Step: 7
Training loss: 0.6659935712814331
Validation loss: 2.211656947930654

Epoch: 5| Step: 8
Training loss: 0.7848367094993591
Validation loss: 2.2645967602729797

Epoch: 5| Step: 9
Training loss: 0.8428882360458374
Validation loss: 2.2614305118719735

Epoch: 5| Step: 10
Training loss: 0.40262871980667114
Validation loss: 2.2509669264157615

Epoch: 5| Step: 11
Training loss: 0.6433612108230591
Validation loss: 2.2747225910425186

Epoch: 261| Step: 0
Training loss: 0.5559740662574768
Validation loss: 2.22104379038016

Epoch: 5| Step: 1
Training loss: 0.619809627532959
Validation loss: 2.2202099909385047

Epoch: 5| Step: 2
Training loss: 0.6138487458229065
Validation loss: 2.233413894971212

Epoch: 5| Step: 3
Training loss: 0.5424168705940247
Validation loss: 2.2565720280011496

Epoch: 5| Step: 4
Training loss: 0.3587454855442047
Validation loss: 2.276099979877472

Epoch: 5| Step: 5
Training loss: 0.6412678360939026
Validation loss: 2.2579818417628608

Epoch: 5| Step: 6
Training loss: 0.8583542704582214
Validation loss: 2.1616037686665854

Epoch: 5| Step: 7
Training loss: 0.5311944484710693
Validation loss: 2.2261706988016763

Epoch: 5| Step: 8
Training loss: 0.4905017912387848
Validation loss: 2.243777091304461

Epoch: 5| Step: 9
Training loss: 0.7444080710411072
Validation loss: 2.235100785891215

Epoch: 5| Step: 10
Training loss: 0.6715863347053528
Validation loss: 2.258291020989418

Epoch: 5| Step: 11
Training loss: 0.26474183797836304
Validation loss: 2.262855420509974

Epoch: 262| Step: 0
Training loss: 0.5917379260063171
Validation loss: 2.194612314303716

Epoch: 5| Step: 1
Training loss: 0.3896363377571106
Validation loss: 2.241243158777555

Epoch: 5| Step: 2
Training loss: 0.4528701901435852
Validation loss: 2.1929812083641687

Epoch: 5| Step: 3
Training loss: 0.9285327792167664
Validation loss: 2.243378609418869

Epoch: 5| Step: 4
Training loss: 0.4646022319793701
Validation loss: 2.2293578038613

Epoch: 5| Step: 5
Training loss: 0.4975968897342682
Validation loss: 2.2473949690659842

Epoch: 5| Step: 6
Training loss: 0.7730592489242554
Validation loss: 2.2094488690296807

Epoch: 5| Step: 7
Training loss: 0.6265743970870972
Validation loss: 2.1647599736849465

Epoch: 5| Step: 8
Training loss: 0.5156269669532776
Validation loss: 2.223966956138611

Epoch: 5| Step: 9
Training loss: 0.47725504636764526
Validation loss: 2.163316696882248

Epoch: 5| Step: 10
Training loss: 0.5686990022659302
Validation loss: 2.247970402240753

Epoch: 5| Step: 11
Training loss: 0.41518187522888184
Validation loss: 2.216945464412371

Epoch: 263| Step: 0
Training loss: 0.6923571825027466
Validation loss: 2.2500570118427277

Epoch: 5| Step: 1
Training loss: 0.7424782514572144
Validation loss: 2.2398134569327035

Epoch: 5| Step: 2
Training loss: 0.7232447862625122
Validation loss: 2.2057567685842514

Epoch: 5| Step: 3
Training loss: 0.5652650594711304
Validation loss: 2.195059965054194

Epoch: 5| Step: 4
Training loss: 0.7205262184143066
Validation loss: 2.25103759765625

Epoch: 5| Step: 5
Training loss: 0.47223615646362305
Validation loss: 2.227223972479502

Epoch: 5| Step: 6
Training loss: 0.46708640456199646
Validation loss: 2.2282413442929587

Epoch: 5| Step: 7
Training loss: 0.5305456519126892
Validation loss: 2.2031837652126947

Epoch: 5| Step: 8
Training loss: 0.49518266320228577
Validation loss: 2.193311686317126

Epoch: 5| Step: 9
Training loss: 0.32172876596450806
Validation loss: 2.2403184175491333

Epoch: 5| Step: 10
Training loss: 0.3592774271965027
Validation loss: 2.3080612967411676

Epoch: 5| Step: 11
Training loss: 0.37182286381721497
Validation loss: 2.274154782295227

Epoch: 264| Step: 0
Training loss: 0.489091694355011
Validation loss: 2.1915957927703857

Epoch: 5| Step: 1
Training loss: 0.4296680986881256
Validation loss: 2.240301897128423

Epoch: 5| Step: 2
Training loss: 0.46685972809791565
Validation loss: 2.2540133893489838

Epoch: 5| Step: 3
Training loss: 0.5867140889167786
Validation loss: 2.1579620291789374

Epoch: 5| Step: 4
Training loss: 0.3505038321018219
Validation loss: 2.206241473555565

Epoch: 5| Step: 5
Training loss: 0.6379179358482361
Validation loss: 2.2309409826993942

Epoch: 5| Step: 6
Training loss: 0.9939540028572083
Validation loss: 2.201640119155248

Epoch: 5| Step: 7
Training loss: 0.5255094766616821
Validation loss: 2.1773882806301117

Epoch: 5| Step: 8
Training loss: 0.5916129946708679
Validation loss: 2.2051308850447335

Epoch: 5| Step: 9
Training loss: 0.6049462556838989
Validation loss: 2.2368977020184198

Epoch: 5| Step: 10
Training loss: 0.5802626609802246
Validation loss: 2.20642218987147

Epoch: 5| Step: 11
Training loss: 0.27195611596107483
Validation loss: 2.2679333239793777

Epoch: 265| Step: 0
Training loss: 0.4313508868217468
Validation loss: 2.258622884750366

Epoch: 5| Step: 1
Training loss: 0.5511662364006042
Validation loss: 2.2203302482763925

Epoch: 5| Step: 2
Training loss: 0.5603879690170288
Validation loss: 2.189412921667099

Epoch: 5| Step: 3
Training loss: 0.4118829667568207
Validation loss: 2.2110498746236167

Epoch: 5| Step: 4
Training loss: 0.4093549847602844
Validation loss: 2.2011601577202478

Epoch: 5| Step: 5
Training loss: 0.4936833381652832
Validation loss: 2.185719301303228

Epoch: 5| Step: 6
Training loss: 0.7453333139419556
Validation loss: 2.2063850114742913

Epoch: 5| Step: 7
Training loss: 0.7971251010894775
Validation loss: 2.2362408339977264

Epoch: 5| Step: 8
Training loss: 0.4611141085624695
Validation loss: 2.168992206454277

Epoch: 5| Step: 9
Training loss: 0.568793535232544
Validation loss: 2.2578664422035217

Epoch: 5| Step: 10
Training loss: 0.6213263869285583
Validation loss: 2.236879309018453

Epoch: 5| Step: 11
Training loss: 0.24275153875350952
Validation loss: 2.185277829567591

Epoch: 266| Step: 0
Training loss: 0.5919350385665894
Validation loss: 2.2316191842158637

Epoch: 5| Step: 1
Training loss: 0.37577131390571594
Validation loss: 2.1619525402784348

Epoch: 5| Step: 2
Training loss: 0.8331382870674133
Validation loss: 2.1983955005804696

Epoch: 5| Step: 3
Training loss: 0.37799879908561707
Validation loss: 2.1836980978647866

Epoch: 5| Step: 4
Training loss: 0.4070037007331848
Validation loss: 2.260616401831309

Epoch: 5| Step: 5
Training loss: 0.6235820651054382
Validation loss: 2.2371518363555274

Epoch: 5| Step: 6
Training loss: 0.4711143374443054
Validation loss: 2.26923730969429

Epoch: 5| Step: 7
Training loss: 0.8273832201957703
Validation loss: 2.2220653891563416

Epoch: 5| Step: 8
Training loss: 0.4479544758796692
Validation loss: 2.2659830898046494

Epoch: 5| Step: 9
Training loss: 0.5261503458023071
Validation loss: 2.266339883208275

Epoch: 5| Step: 10
Training loss: 1.0367991924285889
Validation loss: 2.2722783287366233

Epoch: 5| Step: 11
Training loss: 0.487257719039917
Validation loss: 2.196656803290049

Epoch: 267| Step: 0
Training loss: 0.5730953812599182
Validation loss: 2.2240334153175354

Epoch: 5| Step: 1
Training loss: 0.5940308570861816
Validation loss: 2.248010218143463

Epoch: 5| Step: 2
Training loss: 0.4582616686820984
Validation loss: 2.242434153954188

Epoch: 5| Step: 3
Training loss: 0.6479186415672302
Validation loss: 2.1703651348749795

Epoch: 5| Step: 4
Training loss: 0.5910082459449768
Validation loss: 2.231997177004814

Epoch: 5| Step: 5
Training loss: 0.5749711990356445
Validation loss: 2.2075259536504745

Epoch: 5| Step: 6
Training loss: 0.6129528284072876
Validation loss: 2.163331006964048

Epoch: 5| Step: 7
Training loss: 0.3111088275909424
Validation loss: 2.1415954331556954

Epoch: 5| Step: 8
Training loss: 0.8079164624214172
Validation loss: 2.26274773478508

Epoch: 5| Step: 9
Training loss: 0.5181505680084229
Validation loss: 2.1810392489035926

Epoch: 5| Step: 10
Training loss: 0.5453820824623108
Validation loss: 2.183774376908938

Epoch: 5| Step: 11
Training loss: 1.1930410861968994
Validation loss: 2.1626176089048386

Epoch: 268| Step: 0
Training loss: 0.5605506300926208
Validation loss: 2.2017036279042563

Epoch: 5| Step: 1
Training loss: 0.5129014849662781
Validation loss: 2.2206765711307526

Epoch: 5| Step: 2
Training loss: 1.0761845111846924
Validation loss: 2.224221244454384

Epoch: 5| Step: 3
Training loss: 0.5372821092605591
Validation loss: 2.248577987154325

Epoch: 5| Step: 4
Training loss: 0.5765258073806763
Validation loss: 2.158238857984543

Epoch: 5| Step: 5
Training loss: 0.49894118309020996
Validation loss: 2.254433294137319

Epoch: 5| Step: 6
Training loss: 0.5263188481330872
Validation loss: 2.1914920111497245

Epoch: 5| Step: 7
Training loss: 0.3876466751098633
Validation loss: 2.209105506539345

Epoch: 5| Step: 8
Training loss: 0.5083094835281372
Validation loss: 2.2222872376441956

Epoch: 5| Step: 9
Training loss: 0.609364926815033
Validation loss: 2.177310436964035

Epoch: 5| Step: 10
Training loss: 0.35425397753715515
Validation loss: 2.1900533884763718

Epoch: 5| Step: 11
Training loss: 0.5183051824569702
Validation loss: 2.1722510556379953

Epoch: 269| Step: 0
Training loss: 0.7045795917510986
Validation loss: 2.2745171735684075

Epoch: 5| Step: 1
Training loss: 0.5525029897689819
Validation loss: 2.2771734644969306

Epoch: 5| Step: 2
Training loss: 0.7005082368850708
Validation loss: 2.210223679741224

Epoch: 5| Step: 3
Training loss: 0.46580976247787476
Validation loss: 2.178069452444712

Epoch: 5| Step: 4
Training loss: 0.625157356262207
Validation loss: 2.207103967666626

Epoch: 5| Step: 5
Training loss: 0.43878254294395447
Validation loss: 2.2144701729218164

Epoch: 5| Step: 6
Training loss: 0.8229700326919556
Validation loss: 2.205572078625361

Epoch: 5| Step: 7
Training loss: 0.2454231083393097
Validation loss: 2.16632109383742

Epoch: 5| Step: 8
Training loss: 0.17417217791080475
Validation loss: 2.234941527247429

Epoch: 5| Step: 9
Training loss: 0.4364684522151947
Validation loss: 2.1998659322659173

Epoch: 5| Step: 10
Training loss: 0.4372946619987488
Validation loss: 2.222998375693957

Epoch: 5| Step: 11
Training loss: 0.8983805775642395
Validation loss: 2.193561648329099

Epoch: 270| Step: 0
Training loss: 0.3689177930355072
Validation loss: 2.232398291428884

Epoch: 5| Step: 1
Training loss: 0.5901437997817993
Validation loss: 2.2500793784856796

Epoch: 5| Step: 2
Training loss: 1.1620395183563232
Validation loss: 2.18220521012942

Epoch: 5| Step: 3
Training loss: 0.532625675201416
Validation loss: 2.2199646681547165

Epoch: 5| Step: 4
Training loss: 0.2821504473686218
Validation loss: 2.2243011196454368

Epoch: 5| Step: 5
Training loss: 0.5552646517753601
Validation loss: 2.1865579883257547

Epoch: 5| Step: 6
Training loss: 0.2646380066871643
Validation loss: 2.219675595561663

Epoch: 5| Step: 7
Training loss: 0.5249503254890442
Validation loss: 2.2317752043406167

Epoch: 5| Step: 8
Training loss: 0.3099741041660309
Validation loss: 2.1936603486537933

Epoch: 5| Step: 9
Training loss: 0.6348369717597961
Validation loss: 2.1765058835347495

Epoch: 5| Step: 10
Training loss: 0.3715309500694275
Validation loss: 2.2140561789274216

Epoch: 5| Step: 11
Training loss: 0.3983280658721924
Validation loss: 2.2513213455677032

Epoch: 271| Step: 0
Training loss: 0.42933574318885803
Validation loss: 2.2406319230794907

Epoch: 5| Step: 1
Training loss: 0.45565566420555115
Validation loss: 2.1742705404758453

Epoch: 5| Step: 2
Training loss: 0.2864488959312439
Validation loss: 2.1786040514707565

Epoch: 5| Step: 3
Training loss: 0.8357076644897461
Validation loss: 2.207188660899798

Epoch: 5| Step: 4
Training loss: 0.2857772707939148
Validation loss: 2.2289419968922934

Epoch: 5| Step: 5
Training loss: 0.6872290372848511
Validation loss: 2.2414508908987045

Epoch: 5| Step: 6
Training loss: 0.41588062047958374
Validation loss: 2.2263942062854767

Epoch: 5| Step: 7
Training loss: 0.6527872681617737
Validation loss: 2.2285599410533905

Epoch: 5| Step: 8
Training loss: 0.6892339587211609
Validation loss: 2.236121361454328

Epoch: 5| Step: 9
Training loss: 0.5351356267929077
Validation loss: 2.1660186847050986

Epoch: 5| Step: 10
Training loss: 0.4638203978538513
Validation loss: 2.231827904780706

Epoch: 5| Step: 11
Training loss: 0.395683616399765
Validation loss: 2.201722780863444

Epoch: 272| Step: 0
Training loss: 0.8105461001396179
Validation loss: 2.201786289612452

Epoch: 5| Step: 1
Training loss: 0.2577888071537018
Validation loss: 2.2585014601548514

Epoch: 5| Step: 2
Training loss: 0.46214184165000916
Validation loss: 2.3010838826497397

Epoch: 5| Step: 3
Training loss: 0.49118733406066895
Validation loss: 2.2294647494951882

Epoch: 5| Step: 4
Training loss: 0.4401273727416992
Validation loss: 2.1715042293071747

Epoch: 5| Step: 5
Training loss: 0.8380047082901001
Validation loss: 2.254105190436045

Epoch: 5| Step: 6
Training loss: 0.3905640244483948
Validation loss: 2.2266742885112762

Epoch: 5| Step: 7
Training loss: 0.8435987234115601
Validation loss: 2.1481797297795615

Epoch: 5| Step: 8
Training loss: 0.6691902875900269
Validation loss: 2.2463625917832055

Epoch: 5| Step: 9
Training loss: 0.33017274737358093
Validation loss: 2.2035831063985825

Epoch: 5| Step: 10
Training loss: 0.5385702848434448
Validation loss: 2.231595436731974

Epoch: 5| Step: 11
Training loss: 0.18993079662322998
Validation loss: 2.1869058459997177

Epoch: 273| Step: 0
Training loss: 0.4330718517303467
Validation loss: 2.257588321963946

Epoch: 5| Step: 1
Training loss: 0.5004161596298218
Validation loss: 2.1463382989168167

Epoch: 5| Step: 2
Training loss: 0.7842342853546143
Validation loss: 2.1714636335770288

Epoch: 5| Step: 3
Training loss: 0.39870700240135193
Validation loss: 2.2282747824986777

Epoch: 5| Step: 4
Training loss: 0.8873945474624634
Validation loss: 2.2229520877202353

Epoch: 5| Step: 5
Training loss: 0.6954429745674133
Validation loss: 2.288172205289205

Epoch: 5| Step: 6
Training loss: 0.5514512062072754
Validation loss: 2.2009603828191757

Epoch: 5| Step: 7
Training loss: 0.4494468569755554
Validation loss: 2.2232270489136376

Epoch: 5| Step: 8
Training loss: 0.37456685304641724
Validation loss: 2.2606692711512246

Epoch: 5| Step: 9
Training loss: 0.47019296884536743
Validation loss: 2.2007492234309516

Epoch: 5| Step: 10
Training loss: 0.5288254022598267
Validation loss: 2.244197756052017

Epoch: 5| Step: 11
Training loss: 0.3274235427379608
Validation loss: 2.2583806812763214

Epoch: 274| Step: 0
Training loss: 0.6597496867179871
Validation loss: 2.230513647198677

Epoch: 5| Step: 1
Training loss: 0.47620201110839844
Validation loss: 2.2340508053700128

Epoch: 5| Step: 2
Training loss: 0.6012850999832153
Validation loss: 2.209303468465805

Epoch: 5| Step: 3
Training loss: 0.4359751343727112
Validation loss: 2.227485259373983

Epoch: 5| Step: 4
Training loss: 0.9770223498344421
Validation loss: 2.161828726530075

Epoch: 5| Step: 5
Training loss: 0.49866876006126404
Validation loss: 2.2321583976348243

Epoch: 5| Step: 6
Training loss: 0.2790137827396393
Validation loss: 2.2343031664689383

Epoch: 5| Step: 7
Training loss: 0.5206162929534912
Validation loss: 2.249879151582718

Epoch: 5| Step: 8
Training loss: 0.6096054911613464
Validation loss: 2.256358027458191

Epoch: 5| Step: 9
Training loss: 0.47549325227737427
Validation loss: 2.289347251256307

Epoch: 5| Step: 10
Training loss: 0.5539145469665527
Validation loss: 2.2386471033096313

Epoch: 5| Step: 11
Training loss: 0.4299921691417694
Validation loss: 2.1895650873581567

Epoch: 275| Step: 0
Training loss: 0.5311392545700073
Validation loss: 2.270228619376818

Epoch: 5| Step: 1
Training loss: 0.6071263551712036
Validation loss: 2.188245748480161

Epoch: 5| Step: 2
Training loss: 0.33486324548721313
Validation loss: 2.2018856704235077

Epoch: 5| Step: 3
Training loss: 0.3591234087944031
Validation loss: 2.206311285495758

Epoch: 5| Step: 4
Training loss: 0.44754165410995483
Validation loss: 2.2179362575213113

Epoch: 5| Step: 5
Training loss: 0.6564921140670776
Validation loss: 2.184986725449562

Epoch: 5| Step: 6
Training loss: 0.29204243421554565
Validation loss: 2.2057812611262

Epoch: 5| Step: 7
Training loss: 0.580727219581604
Validation loss: 2.2030870566765466

Epoch: 5| Step: 8
Training loss: 0.7678643465042114
Validation loss: 2.20798522233963

Epoch: 5| Step: 9
Training loss: 0.442819207906723
Validation loss: 2.1750284979740777

Epoch: 5| Step: 10
Training loss: 0.46117106080055237
Validation loss: 2.2050133546193442

Epoch: 5| Step: 11
Training loss: 2.0856497287750244
Validation loss: 2.121701548496882

Epoch: 276| Step: 0
Training loss: 0.6157815456390381
Validation loss: 2.207168291012446

Epoch: 5| Step: 1
Training loss: 0.6212772130966187
Validation loss: 2.2212712466716766

Epoch: 5| Step: 2
Training loss: 0.4715779423713684
Validation loss: 2.154433528582255

Epoch: 5| Step: 3
Training loss: 0.47707614302635193
Validation loss: 2.2139930923779807

Epoch: 5| Step: 4
Training loss: 0.4775124490261078
Validation loss: 2.2317489683628082

Epoch: 5| Step: 5
Training loss: 0.6901572346687317
Validation loss: 2.1629471331834793

Epoch: 5| Step: 6
Training loss: 0.5756901502609253
Validation loss: 2.2374570618073144

Epoch: 5| Step: 7
Training loss: 0.38870781660079956
Validation loss: 2.298004890481631

Epoch: 5| Step: 8
Training loss: 0.570525050163269
Validation loss: 2.2432344953219094

Epoch: 5| Step: 9
Training loss: 0.31383559107780457
Validation loss: 2.198881521821022

Epoch: 5| Step: 10
Training loss: 0.6228270530700684
Validation loss: 2.2303435603777566

Epoch: 5| Step: 11
Training loss: 0.7022233009338379
Validation loss: 2.2134771247704825

Epoch: 277| Step: 0
Training loss: 0.4697764813899994
Validation loss: 2.2580031057198844

Epoch: 5| Step: 1
Training loss: 0.5008383989334106
Validation loss: 2.215400000413259

Epoch: 5| Step: 2
Training loss: 0.293928325176239
Validation loss: 2.2147949238618216

Epoch: 5| Step: 3
Training loss: 0.43888768553733826
Validation loss: 2.297973175843557

Epoch: 5| Step: 4
Training loss: 0.3603956997394562
Validation loss: 2.2390781889359155

Epoch: 5| Step: 5
Training loss: 1.014966607093811
Validation loss: 2.2084207981824875

Epoch: 5| Step: 6
Training loss: 0.810849666595459
Validation loss: 2.1795975863933563

Epoch: 5| Step: 7
Training loss: 0.5368856191635132
Validation loss: 2.280919517079989

Epoch: 5| Step: 8
Training loss: 0.39031773805618286
Validation loss: 2.2411258021990457

Epoch: 5| Step: 9
Training loss: 0.5016914010047913
Validation loss: 2.234555924932162

Epoch: 5| Step: 10
Training loss: 0.39733830094337463
Validation loss: 2.256198892990748

Epoch: 5| Step: 11
Training loss: 0.7125428915023804
Validation loss: 2.2444821993509927

Epoch: 278| Step: 0
Training loss: 0.7964560389518738
Validation loss: 2.2341944128274918

Epoch: 5| Step: 1
Training loss: 0.45884308218955994
Validation loss: 2.1951965590318046

Epoch: 5| Step: 2
Training loss: 0.4410344958305359
Validation loss: 2.2557815412680307

Epoch: 5| Step: 3
Training loss: 1.021376609802246
Validation loss: 2.2579561869303384

Epoch: 5| Step: 4
Training loss: 0.3342316746711731
Validation loss: 2.2531591604153314

Epoch: 5| Step: 5
Training loss: 0.43803325295448303
Validation loss: 2.242097099622091

Epoch: 5| Step: 6
Training loss: 0.4190247654914856
Validation loss: 2.270504350463549

Epoch: 5| Step: 7
Training loss: 0.32317981123924255
Validation loss: 2.225466544429461

Epoch: 5| Step: 8
Training loss: 0.6983809471130371
Validation loss: 2.192426711320877

Epoch: 5| Step: 9
Training loss: 0.6885325312614441
Validation loss: 2.2191748718420663

Epoch: 5| Step: 10
Training loss: 0.4871075749397278
Validation loss: 2.2852099537849426

Epoch: 5| Step: 11
Training loss: 0.10044169425964355
Validation loss: 2.287012110153834

Epoch: 279| Step: 0
Training loss: 0.3263925611972809
Validation loss: 2.2198669711748757

Epoch: 5| Step: 1
Training loss: 0.5308236479759216
Validation loss: 2.3013509064912796

Epoch: 5| Step: 2
Training loss: 0.47772741317749023
Validation loss: 2.2560408214728036

Epoch: 5| Step: 3
Training loss: 0.5628455281257629
Validation loss: 2.219568520784378

Epoch: 5| Step: 4
Training loss: 0.6036237478256226
Validation loss: 2.245258758465449

Epoch: 5| Step: 5
Training loss: 0.9883304834365845
Validation loss: 2.224823941787084

Epoch: 5| Step: 6
Training loss: 0.41645336151123047
Validation loss: 2.247740070025126

Epoch: 5| Step: 7
Training loss: 0.43870988488197327
Validation loss: 2.250746746857961

Epoch: 5| Step: 8
Training loss: 0.29699039459228516
Validation loss: 2.23841355741024

Epoch: 5| Step: 9
Training loss: 0.4636882245540619
Validation loss: 2.242448478937149

Epoch: 5| Step: 10
Training loss: 0.420154333114624
Validation loss: 2.264009435971578

Epoch: 5| Step: 11
Training loss: 0.4725401997566223
Validation loss: 2.2345800201098123

Epoch: 280| Step: 0
Training loss: 0.5412940979003906
Validation loss: 2.2861496210098267

Epoch: 5| Step: 1
Training loss: 0.5331475138664246
Validation loss: 2.239080160856247

Epoch: 5| Step: 2
Training loss: 0.5916303396224976
Validation loss: 2.2990471621354422

Epoch: 5| Step: 3
Training loss: 0.30460548400878906
Validation loss: 2.2716253300507865

Epoch: 5| Step: 4
Training loss: 0.484935998916626
Validation loss: 2.2653905749320984

Epoch: 5| Step: 5
Training loss: 0.43927496671676636
Validation loss: 2.263160487016042

Epoch: 5| Step: 6
Training loss: 0.9928945302963257
Validation loss: 2.2626663744449615

Epoch: 5| Step: 7
Training loss: 0.5830800533294678
Validation loss: 2.2695120672384896

Epoch: 5| Step: 8
Training loss: 0.35335367918014526
Validation loss: 2.2365116427342095

Epoch: 5| Step: 9
Training loss: 0.2956083118915558
Validation loss: 2.2579691112041473

Epoch: 5| Step: 10
Training loss: 0.5897323489189148
Validation loss: 2.188018023967743

Epoch: 5| Step: 11
Training loss: 0.6745926141738892
Validation loss: 2.2894300868113837

Epoch: 281| Step: 0
Training loss: 0.5603344440460205
Validation loss: 2.239056557416916

Epoch: 5| Step: 1
Training loss: 0.6105002164840698
Validation loss: 2.2775991559028625

Epoch: 5| Step: 2
Training loss: 0.35052841901779175
Validation loss: 2.2585108826557794

Epoch: 5| Step: 3
Training loss: 0.43166080117225647
Validation loss: 2.2479117115338645

Epoch: 5| Step: 4
Training loss: 0.4077419340610504
Validation loss: 2.232593754927317

Epoch: 5| Step: 5
Training loss: 0.41322407126426697
Validation loss: 2.2271792888641357

Epoch: 5| Step: 6
Training loss: 0.837793231010437
Validation loss: 2.261673221985499

Epoch: 5| Step: 7
Training loss: 0.45670145750045776
Validation loss: 2.270855739712715

Epoch: 5| Step: 8
Training loss: 0.5088450908660889
Validation loss: 2.296490708986918

Epoch: 5| Step: 9
Training loss: 0.48636525869369507
Validation loss: 2.248868480324745

Epoch: 5| Step: 10
Training loss: 0.7932621836662292
Validation loss: 2.238496591647466

Epoch: 5| Step: 11
Training loss: 0.3022753596305847
Validation loss: 2.213011845946312

Epoch: 282| Step: 0
Training loss: 0.6066439151763916
Validation loss: 2.2678860127925873

Epoch: 5| Step: 1
Training loss: 0.5464428663253784
Validation loss: 2.2614715546369553

Epoch: 5| Step: 2
Training loss: 0.4095836281776428
Validation loss: 2.244353080789248

Epoch: 5| Step: 3
Training loss: 0.48962101340293884
Validation loss: 2.265538528561592

Epoch: 5| Step: 4
Training loss: 0.6073591709136963
Validation loss: 2.2760479102532067

Epoch: 5| Step: 5
Training loss: 0.46855729818344116
Validation loss: 2.2708159188429513

Epoch: 5| Step: 6
Training loss: 0.6555588841438293
Validation loss: 2.2388866941134133

Epoch: 5| Step: 7
Training loss: 0.4419366717338562
Validation loss: 2.205263947447141

Epoch: 5| Step: 8
Training loss: 0.6744433045387268
Validation loss: 2.207517017920812

Epoch: 5| Step: 9
Training loss: 0.7905338406562805
Validation loss: 2.2504909485578537

Epoch: 5| Step: 10
Training loss: 0.31825804710388184
Validation loss: 2.2133040527502694

Epoch: 5| Step: 11
Training loss: 0.3686303496360779
Validation loss: 2.2377669413884482

Epoch: 283| Step: 0
Training loss: 0.60696941614151
Validation loss: 2.2117961943149567

Epoch: 5| Step: 1
Training loss: 0.726139485836029
Validation loss: 2.242299571633339

Epoch: 5| Step: 2
Training loss: 0.3857830762863159
Validation loss: 2.182974254091581

Epoch: 5| Step: 3
Training loss: 0.7347072958946228
Validation loss: 2.1649650981028876

Epoch: 5| Step: 4
Training loss: 0.6183470487594604
Validation loss: 2.2060759862264

Epoch: 5| Step: 5
Training loss: 0.6236802339553833
Validation loss: 2.253027563293775

Epoch: 5| Step: 6
Training loss: 0.42763686180114746
Validation loss: 2.2180254757404327

Epoch: 5| Step: 7
Training loss: 0.4398704469203949
Validation loss: 2.186555008093516

Epoch: 5| Step: 8
Training loss: 0.3509899973869324
Validation loss: 2.208051015933355

Epoch: 5| Step: 9
Training loss: 0.5072189569473267
Validation loss: 2.1826987663904824

Epoch: 5| Step: 10
Training loss: 0.5300785303115845
Validation loss: 2.1881695687770844

Epoch: 5| Step: 11
Training loss: 0.7803781032562256
Validation loss: 2.1923355062802634

Epoch: 284| Step: 0
Training loss: 0.5982218384742737
Validation loss: 2.2153429985046387

Epoch: 5| Step: 1
Training loss: 0.38774770498275757
Validation loss: 2.2668515145778656

Epoch: 5| Step: 2
Training loss: 0.6276689171791077
Validation loss: 2.255039339264234

Epoch: 5| Step: 3
Training loss: 0.9904779195785522
Validation loss: 2.2550492932399115

Epoch: 5| Step: 4
Training loss: 0.34133559465408325
Validation loss: 2.2033999214569726

Epoch: 5| Step: 5
Training loss: 0.454263836145401
Validation loss: 2.2372474869092307

Epoch: 5| Step: 6
Training loss: 0.653471827507019
Validation loss: 2.251093382636706

Epoch: 5| Step: 7
Training loss: 0.698646068572998
Validation loss: 2.2631212174892426

Epoch: 5| Step: 8
Training loss: 0.4969770014286041
Validation loss: 2.215807259082794

Epoch: 5| Step: 9
Training loss: 0.3612961769104004
Validation loss: 2.2127735068400702

Epoch: 5| Step: 10
Training loss: 0.46355876326560974
Validation loss: 2.23932945728302

Epoch: 5| Step: 11
Training loss: 0.6364518404006958
Validation loss: 2.2438863863547645

Epoch: 285| Step: 0
Training loss: 0.4023612141609192
Validation loss: 2.2594145039717355

Epoch: 5| Step: 1
Training loss: 0.24755504727363586
Validation loss: 2.2348285168409348

Epoch: 5| Step: 2
Training loss: 0.4795072078704834
Validation loss: 2.1984762946764627

Epoch: 5| Step: 3
Training loss: 0.5893908739089966
Validation loss: 2.2334107210238776

Epoch: 5| Step: 4
Training loss: 0.7340663075447083
Validation loss: 2.214529683192571

Epoch: 5| Step: 5
Training loss: 0.3319142758846283
Validation loss: 2.270392040411631

Epoch: 5| Step: 6
Training loss: 0.5439097881317139
Validation loss: 2.2211886445681253

Epoch: 5| Step: 7
Training loss: 0.4938550591468811
Validation loss: 2.2409773071606955

Epoch: 5| Step: 8
Training loss: 0.5515233874320984
Validation loss: 2.188768446445465

Epoch: 5| Step: 9
Training loss: 0.30930382013320923
Validation loss: 2.1813247948884964

Epoch: 5| Step: 10
Training loss: 0.7151945233345032
Validation loss: 2.2257144103447595

Epoch: 5| Step: 11
Training loss: 1.12692391872406
Validation loss: 2.252836455901464

Epoch: 286| Step: 0
Training loss: 0.8314260244369507
Validation loss: 2.2198537091414132

Epoch: 5| Step: 1
Training loss: 0.6382734775543213
Validation loss: 2.210446606079737

Epoch: 5| Step: 2
Training loss: 0.5702517032623291
Validation loss: 2.179366106788317

Epoch: 5| Step: 3
Training loss: 0.5142485499382019
Validation loss: 2.2190429468949637

Epoch: 5| Step: 4
Training loss: 0.40802597999572754
Validation loss: 2.1980431179205575

Epoch: 5| Step: 5
Training loss: 0.4026264250278473
Validation loss: 2.1604003806908927

Epoch: 5| Step: 6
Training loss: 0.5591089129447937
Validation loss: 2.2114999194939933

Epoch: 5| Step: 7
Training loss: 0.25377851724624634
Validation loss: 2.1839622606833777

Epoch: 5| Step: 8
Training loss: 0.3171982765197754
Validation loss: 2.199198290705681

Epoch: 5| Step: 9
Training loss: 0.7079077959060669
Validation loss: 2.1704071710507074

Epoch: 5| Step: 10
Training loss: 0.3320590853691101
Validation loss: 2.1961928755044937

Epoch: 5| Step: 11
Training loss: 0.16949132084846497
Validation loss: 2.2544782012701035

Epoch: 287| Step: 0
Training loss: 0.5813767313957214
Validation loss: 2.221151818831762

Epoch: 5| Step: 1
Training loss: 1.1108620166778564
Validation loss: 2.2252089828252792

Epoch: 5| Step: 2
Training loss: 0.6008372902870178
Validation loss: 2.2468893627325692

Epoch: 5| Step: 3
Training loss: 0.3792797923088074
Validation loss: 2.2156710426012673

Epoch: 5| Step: 4
Training loss: 0.4301854074001312
Validation loss: 2.2735687295595803

Epoch: 5| Step: 5
Training loss: 0.33015117049217224
Validation loss: 2.2133856415748596

Epoch: 5| Step: 6
Training loss: 0.4290858209133148
Validation loss: 2.237483670314153

Epoch: 5| Step: 7
Training loss: 0.42032819986343384
Validation loss: 2.2233811914920807

Epoch: 5| Step: 8
Training loss: 0.3770628571510315
Validation loss: 2.227731208006541

Epoch: 5| Step: 9
Training loss: 0.8326876759529114
Validation loss: 2.2235555996497474

Epoch: 5| Step: 10
Training loss: 0.41314268112182617
Validation loss: 2.219432438413302

Epoch: 5| Step: 11
Training loss: 0.35155653953552246
Validation loss: 2.2461359749237695

Epoch: 288| Step: 0
Training loss: 0.3824249804019928
Validation loss: 2.1998309393723807

Epoch: 5| Step: 1
Training loss: 0.43366917967796326
Validation loss: 2.269219477971395

Epoch: 5| Step: 2
Training loss: 0.6215274333953857
Validation loss: 2.188918799161911

Epoch: 5| Step: 3
Training loss: 0.6368370652198792
Validation loss: 2.26509099205335

Epoch: 5| Step: 4
Training loss: 0.39437970519065857
Validation loss: 2.2236503710349402

Epoch: 5| Step: 5
Training loss: 0.5196057558059692
Validation loss: 2.212193330128988

Epoch: 5| Step: 6
Training loss: 0.37347695231437683
Validation loss: 2.2230512152115502

Epoch: 5| Step: 7
Training loss: 0.41309434175491333
Validation loss: 2.202320729692777

Epoch: 5| Step: 8
Training loss: 0.8354450464248657
Validation loss: 2.2403263549009957

Epoch: 5| Step: 9
Training loss: 0.5481640100479126
Validation loss: 2.203664759794871

Epoch: 5| Step: 10
Training loss: 0.5583263635635376
Validation loss: 2.242533355951309

Epoch: 5| Step: 11
Training loss: 0.22230210900306702
Validation loss: 2.217400074005127

Epoch: 289| Step: 0
Training loss: 0.38470548391342163
Validation loss: 2.2385582625865936

Epoch: 5| Step: 1
Training loss: 0.541313111782074
Validation loss: 2.2005137552817664

Epoch: 5| Step: 2
Training loss: 0.2896011471748352
Validation loss: 2.249792476495107

Epoch: 5| Step: 3
Training loss: 0.42562150955200195
Validation loss: 2.231176575024923

Epoch: 5| Step: 4
Training loss: 0.3887588083744049
Validation loss: 2.20272596180439

Epoch: 5| Step: 5
Training loss: 0.4846112132072449
Validation loss: 2.2407426486412683

Epoch: 5| Step: 6
Training loss: 0.5321432948112488
Validation loss: 2.2233646363019943

Epoch: 5| Step: 7
Training loss: 0.6372091770172119
Validation loss: 2.3035971422990165

Epoch: 5| Step: 8
Training loss: 0.7113193273544312
Validation loss: 2.266568327943484

Epoch: 5| Step: 9
Training loss: 0.36410003900527954
Validation loss: 2.2728172838687897

Epoch: 5| Step: 10
Training loss: 0.7076470255851746
Validation loss: 2.356547713279724

Epoch: 5| Step: 11
Training loss: 0.384709894657135
Validation loss: 2.3346003194650016

Epoch: 290| Step: 0
Training loss: 0.30979830026626587
Validation loss: 2.321698928872744

Epoch: 5| Step: 1
Training loss: 0.361674964427948
Validation loss: 2.2927210181951523

Epoch: 5| Step: 2
Training loss: 1.091286301612854
Validation loss: 2.2868979076544442

Epoch: 5| Step: 3
Training loss: 0.43008631467819214
Validation loss: 2.2811816235383353

Epoch: 5| Step: 4
Training loss: 0.4956034719944
Validation loss: 2.2777816702922187

Epoch: 5| Step: 5
Training loss: 0.4483323097229004
Validation loss: 2.2415033827225366

Epoch: 5| Step: 6
Training loss: 0.2225443422794342
Validation loss: 2.198183079560598

Epoch: 5| Step: 7
Training loss: 0.3706006407737732
Validation loss: 2.255328064163526

Epoch: 5| Step: 8
Training loss: 0.45744433999061584
Validation loss: 2.310212959845861

Epoch: 5| Step: 9
Training loss: 0.6572428941726685
Validation loss: 2.202931120991707

Epoch: 5| Step: 10
Training loss: 0.3761550784111023
Validation loss: 2.21265055735906

Epoch: 5| Step: 11
Training loss: 1.1146410703659058
Validation loss: 2.2198279798030853

Epoch: 291| Step: 0
Training loss: 0.4968569874763489
Validation loss: 2.25314291814963

Epoch: 5| Step: 1
Training loss: 0.8072808980941772
Validation loss: 2.2381909688313804

Epoch: 5| Step: 2
Training loss: 0.3111897110939026
Validation loss: 2.2164373248815536

Epoch: 5| Step: 3
Training loss: 0.4844896197319031
Validation loss: 2.270478462179502

Epoch: 5| Step: 4
Training loss: 0.34644120931625366
Validation loss: 2.2943471570809684

Epoch: 5| Step: 5
Training loss: 0.5118016004562378
Validation loss: 2.2471146633227668

Epoch: 5| Step: 6
Training loss: 0.657821536064148
Validation loss: 2.267938216527303

Epoch: 5| Step: 7
Training loss: 0.4632844030857086
Validation loss: 2.2320114175478616

Epoch: 5| Step: 8
Training loss: 0.33776527643203735
Validation loss: 2.267985701560974

Epoch: 5| Step: 9
Training loss: 0.2376294583082199
Validation loss: 2.2841860949993134

Epoch: 5| Step: 10
Training loss: 0.9305751919746399
Validation loss: 2.2718280454476676

Epoch: 5| Step: 11
Training loss: 0.42127203941345215
Validation loss: 2.247532904148102

Epoch: 292| Step: 0
Training loss: 0.3887863755226135
Validation loss: 2.2843819508949914

Epoch: 5| Step: 1
Training loss: 0.33236151933670044
Validation loss: 2.2963369687398276

Epoch: 5| Step: 2
Training loss: 0.3918849527835846
Validation loss: 2.264890809853872

Epoch: 5| Step: 3
Training loss: 0.675076961517334
Validation loss: 2.274071365594864

Epoch: 5| Step: 4
Training loss: 0.2683502435684204
Validation loss: 2.2960018118222556

Epoch: 5| Step: 5
Training loss: 0.2453458309173584
Validation loss: 2.2857065945863724

Epoch: 5| Step: 6
Training loss: 1.1285125017166138
Validation loss: 2.2488977710405984

Epoch: 5| Step: 7
Training loss: 0.29235348105430603
Validation loss: 2.244410216808319

Epoch: 5| Step: 8
Training loss: 0.6222763061523438
Validation loss: 2.230473071336746

Epoch: 5| Step: 9
Training loss: 0.40549272298812866
Validation loss: 2.2317957480748496

Epoch: 5| Step: 10
Training loss: 0.22844643890857697
Validation loss: 2.2345981001853943

Epoch: 5| Step: 11
Training loss: 0.4997295141220093
Validation loss: 2.268777976433436

Epoch: 293| Step: 0
Training loss: 0.3591720163822174
Validation loss: 2.304624189933141

Epoch: 5| Step: 1
Training loss: 0.7958954572677612
Validation loss: 2.2738255659739175

Epoch: 5| Step: 2
Training loss: 0.4244653582572937
Validation loss: 2.2709173460801444

Epoch: 5| Step: 3
Training loss: 0.48283758759498596
Validation loss: 2.2138068477312722

Epoch: 5| Step: 4
Training loss: 0.6331960558891296
Validation loss: 2.244872366388639

Epoch: 5| Step: 5
Training loss: 0.5832732915878296
Validation loss: 2.3370652397473655

Epoch: 5| Step: 6
Training loss: 0.5442944765090942
Validation loss: 2.2506522287925086

Epoch: 5| Step: 7
Training loss: 0.4869214594364166
Validation loss: 2.2528503835201263

Epoch: 5| Step: 8
Training loss: 0.6338441967964172
Validation loss: 2.2498337974150977

Epoch: 5| Step: 9
Training loss: 0.3177899718284607
Validation loss: 2.21338785191377

Epoch: 5| Step: 10
Training loss: 0.33342689275741577
Validation loss: 2.2804696410894394

Epoch: 5| Step: 11
Training loss: 0.6510641574859619
Validation loss: 2.2973332703113556

Epoch: 294| Step: 0
Training loss: 0.294118195772171
Validation loss: 2.225970228513082

Epoch: 5| Step: 1
Training loss: 0.2658385634422302
Validation loss: 2.245750034848849

Epoch: 5| Step: 2
Training loss: 0.5265571475028992
Validation loss: 2.2436332404613495

Epoch: 5| Step: 3
Training loss: 0.42631444334983826
Validation loss: 2.1797492702802024

Epoch: 5| Step: 4
Training loss: 0.5837503671646118
Validation loss: 2.227150330940882

Epoch: 5| Step: 5
Training loss: 0.4884198307991028
Validation loss: 2.1883074740568795

Epoch: 5| Step: 6
Training loss: 0.4491187036037445
Validation loss: 2.1269725809494653

Epoch: 5| Step: 7
Training loss: 0.8447766304016113
Validation loss: 2.2209449112415314

Epoch: 5| Step: 8
Training loss: 0.4386330246925354
Validation loss: 2.2360216975212097

Epoch: 5| Step: 9
Training loss: 0.6095559000968933
Validation loss: 2.209367424249649

Epoch: 5| Step: 10
Training loss: 0.5123344659805298
Validation loss: 2.1773457527160645

Epoch: 5| Step: 11
Training loss: 0.3782576620578766
Validation loss: 2.203829601407051

Epoch: 295| Step: 0
Training loss: 0.3263492286205292
Validation loss: 2.2192562371492386

Epoch: 5| Step: 1
Training loss: 0.739604115486145
Validation loss: 2.187178666392962

Epoch: 5| Step: 2
Training loss: 0.5028654336929321
Validation loss: 2.2629467199246087

Epoch: 5| Step: 3
Training loss: 0.4561630189418793
Validation loss: 2.2202470898628235

Epoch: 5| Step: 4
Training loss: 0.38718658685684204
Validation loss: 2.201616500814756

Epoch: 5| Step: 5
Training loss: 0.4387633800506592
Validation loss: 2.2072228143612542

Epoch: 5| Step: 6
Training loss: 0.6908086538314819
Validation loss: 2.2338107575972876

Epoch: 5| Step: 7
Training loss: 0.3074381649494171
Validation loss: 2.2257389426231384

Epoch: 5| Step: 8
Training loss: 0.5301488041877747
Validation loss: 2.228675131996473

Epoch: 5| Step: 9
Training loss: 0.3332464098930359
Validation loss: 2.217588613430659

Epoch: 5| Step: 10
Training loss: 0.5292950868606567
Validation loss: 2.2378381490707397

Epoch: 5| Step: 11
Training loss: 0.517712414264679
Validation loss: 2.1721144566933313

Epoch: 296| Step: 0
Training loss: 0.5526917576789856
Validation loss: 2.1657487948735556

Epoch: 5| Step: 1
Training loss: 0.33439964056015015
Validation loss: 2.228442539771398

Epoch: 5| Step: 2
Training loss: 0.4330924153327942
Validation loss: 2.2760336101055145

Epoch: 5| Step: 3
Training loss: 0.5155937671661377
Validation loss: 2.2943446735541024

Epoch: 5| Step: 4
Training loss: 1.0684088468551636
Validation loss: 2.2820015102624893

Epoch: 5| Step: 5
Training loss: 0.6111432909965515
Validation loss: 2.2329466491937637

Epoch: 5| Step: 6
Training loss: 0.37293606996536255
Validation loss: 2.2704644948244095

Epoch: 5| Step: 7
Training loss: 0.46855250000953674
Validation loss: 2.3199687699476876

Epoch: 5| Step: 8
Training loss: 0.43641963601112366
Validation loss: 2.268690104285876

Epoch: 5| Step: 9
Training loss: 0.5099267363548279
Validation loss: 2.264176925023397

Epoch: 5| Step: 10
Training loss: 0.31303834915161133
Validation loss: 2.301317503054937

Epoch: 5| Step: 11
Training loss: 0.22953131794929504
Validation loss: 2.284135560194651

Epoch: 297| Step: 0
Training loss: 0.7831971645355225
Validation loss: 2.2048680782318115

Epoch: 5| Step: 1
Training loss: 0.4785490930080414
Validation loss: 2.2490987281004586

Epoch: 5| Step: 2
Training loss: 0.3903982937335968
Validation loss: 2.2490671823422113

Epoch: 5| Step: 3
Training loss: 0.6128662824630737
Validation loss: 2.251676475008329

Epoch: 5| Step: 4
Training loss: 0.3974129259586334
Validation loss: 2.2792712996403375

Epoch: 5| Step: 5
Training loss: 0.43565455079078674
Validation loss: 2.2139618595441184

Epoch: 5| Step: 6
Training loss: 0.47530603408813477
Validation loss: 2.255383069316546

Epoch: 5| Step: 7
Training loss: 0.5853439569473267
Validation loss: 2.250208149353663

Epoch: 5| Step: 8
Training loss: 0.2773306667804718
Validation loss: 2.2023344933986664

Epoch: 5| Step: 9
Training loss: 0.5313068628311157
Validation loss: 2.219711790482203

Epoch: 5| Step: 10
Training loss: 0.41392937302589417
Validation loss: 2.203322947025299

Epoch: 5| Step: 11
Training loss: 0.3245638608932495
Validation loss: 2.252631366252899

Epoch: 298| Step: 0
Training loss: 0.2919151186943054
Validation loss: 2.2456968973080316

Epoch: 5| Step: 1
Training loss: 0.5481902956962585
Validation loss: 2.2403877874215445

Epoch: 5| Step: 2
Training loss: 0.3456293046474457
Validation loss: 2.257974624633789

Epoch: 5| Step: 3
Training loss: 0.6911892890930176
Validation loss: 2.2347728510697684

Epoch: 5| Step: 4
Training loss: 1.0183897018432617
Validation loss: 2.219487821062406

Epoch: 5| Step: 5
Training loss: 0.26055413484573364
Validation loss: 2.235850691795349

Epoch: 5| Step: 6
Training loss: 0.29489320516586304
Validation loss: 2.2690980037053428

Epoch: 5| Step: 7
Training loss: 0.5606338381767273
Validation loss: 2.2540362030267715

Epoch: 5| Step: 8
Training loss: 0.4435649812221527
Validation loss: 2.2449141144752502

Epoch: 5| Step: 9
Training loss: 0.5605977773666382
Validation loss: 2.2428829868634543

Epoch: 5| Step: 10
Training loss: 0.671924889087677
Validation loss: 2.267415697375933

Epoch: 5| Step: 11
Training loss: 0.230597585439682
Validation loss: 2.224894419312477

Epoch: 299| Step: 0
Training loss: 0.6444917917251587
Validation loss: 2.25475682814916

Epoch: 5| Step: 1
Training loss: 0.7445186972618103
Validation loss: 2.213544249534607

Epoch: 5| Step: 2
Training loss: 0.3814343810081482
Validation loss: 2.1914569983879724

Epoch: 5| Step: 3
Training loss: 0.4855847954750061
Validation loss: 2.2223011453946433

Epoch: 5| Step: 4
Training loss: 0.40225568413734436
Validation loss: 2.251645932594935

Epoch: 5| Step: 5
Training loss: 0.8536659479141235
Validation loss: 2.2524595508972802

Epoch: 5| Step: 6
Training loss: 0.37738102674484253
Validation loss: 2.217906261483828

Epoch: 5| Step: 7
Training loss: 0.3433780074119568
Validation loss: 2.2376982222000756

Epoch: 5| Step: 8
Training loss: 0.61662757396698
Validation loss: 2.2572381794452667

Epoch: 5| Step: 9
Training loss: 0.3559640645980835
Validation loss: 2.2396151473124823

Epoch: 5| Step: 10
Training loss: 0.5372346639633179
Validation loss: 2.248414769768715

Epoch: 5| Step: 11
Training loss: 0.22333300113677979
Validation loss: 2.2683076163132987

Epoch: 300| Step: 0
Training loss: 0.7080494165420532
Validation loss: 2.2095134804646173

Epoch: 5| Step: 1
Training loss: 0.45395928621292114
Validation loss: 2.188473949829737

Epoch: 5| Step: 2
Training loss: 0.5393271446228027
Validation loss: 2.2344390749931335

Epoch: 5| Step: 3
Training loss: 0.4630623459815979
Validation loss: 2.2785556266705194

Epoch: 5| Step: 4
Training loss: 0.3208313584327698
Validation loss: 2.2598818192879357

Epoch: 5| Step: 5
Training loss: 0.285722017288208
Validation loss: 2.242752859989802

Epoch: 5| Step: 6
Training loss: 0.488593190908432
Validation loss: 2.251317689816157

Epoch: 5| Step: 7
Training loss: 0.3860930800437927
Validation loss: 2.2566890766223273

Epoch: 5| Step: 8
Training loss: 0.2790982723236084
Validation loss: 2.249161889155706

Epoch: 5| Step: 9
Training loss: 1.013633370399475
Validation loss: 2.25911479194959

Epoch: 5| Step: 10
Training loss: 0.2926254868507385
Validation loss: 2.206980894009272

Epoch: 5| Step: 11
Training loss: 0.22239479422569275
Validation loss: 2.293228546778361

Epoch: 301| Step: 0
Training loss: 0.5055795907974243
Validation loss: 2.2072426080703735

Epoch: 5| Step: 1
Training loss: 0.6712579727172852
Validation loss: 2.243690942724546

Epoch: 5| Step: 2
Training loss: 0.5186153650283813
Validation loss: 2.2931379874547324

Epoch: 5| Step: 3
Training loss: 0.7552979588508606
Validation loss: 2.2861745208501816

Epoch: 5| Step: 4
Training loss: 0.4284590780735016
Validation loss: 2.3063880453507104

Epoch: 5| Step: 5
Training loss: 0.2604414224624634
Validation loss: 2.2024084279934564

Epoch: 5| Step: 6
Training loss: 0.719687283039093
Validation loss: 2.208856721719106

Epoch: 5| Step: 7
Training loss: 0.6038511991500854
Validation loss: 2.2653782020012536

Epoch: 5| Step: 8
Training loss: 0.4959392547607422
Validation loss: 2.264681259791056

Epoch: 5| Step: 9
Training loss: 0.8802582025527954
Validation loss: 2.229311227798462

Epoch: 5| Step: 10
Training loss: 0.55016028881073
Validation loss: 2.24292454123497

Epoch: 5| Step: 11
Training loss: 0.7002285122871399
Validation loss: 2.2168056964874268

Epoch: 302| Step: 0
Training loss: 0.748919665813446
Validation loss: 2.258651783068975

Epoch: 5| Step: 1
Training loss: 0.5215374231338501
Validation loss: 2.1602178563674292

Epoch: 5| Step: 2
Training loss: 0.47456926107406616
Validation loss: 2.1796335130929947

Epoch: 5| Step: 3
Training loss: 0.3757038414478302
Validation loss: 2.164693276087443

Epoch: 5| Step: 4
Training loss: 0.5549908876419067
Validation loss: 2.2057677855094275

Epoch: 5| Step: 5
Training loss: 0.4172176420688629
Validation loss: 2.14037956794103

Epoch: 5| Step: 6
Training loss: 0.5944713950157166
Validation loss: 2.2220217188199363

Epoch: 5| Step: 7
Training loss: 0.7456903457641602
Validation loss: 2.2389732201894126

Epoch: 5| Step: 8
Training loss: 0.514593780040741
Validation loss: 2.244326283534368

Epoch: 5| Step: 9
Training loss: 0.6719287633895874
Validation loss: 2.236591120560964

Epoch: 5| Step: 10
Training loss: 0.39777636528015137
Validation loss: 2.157827744881312

Epoch: 5| Step: 11
Training loss: 0.3317203223705292
Validation loss: 2.3000789831082025

Epoch: 303| Step: 0
Training loss: 0.3030422627925873
Validation loss: 2.2274639010429382

Epoch: 5| Step: 1
Training loss: 0.33682388067245483
Validation loss: 2.206717371940613

Epoch: 5| Step: 2
Training loss: 0.24418577551841736
Validation loss: 2.2807618329922357

Epoch: 5| Step: 3
Training loss: 0.5761216282844543
Validation loss: 2.247729708751043

Epoch: 5| Step: 4
Training loss: 0.3016220033168793
Validation loss: 2.244976411263148

Epoch: 5| Step: 5
Training loss: 0.692497968673706
Validation loss: 2.299425035715103

Epoch: 5| Step: 6
Training loss: 0.462415874004364
Validation loss: 2.2699190179506936

Epoch: 5| Step: 7
Training loss: 0.5283780097961426
Validation loss: 2.2188781996568046

Epoch: 5| Step: 8
Training loss: 0.9237154126167297
Validation loss: 2.2062973082065582

Epoch: 5| Step: 9
Training loss: 0.37333977222442627
Validation loss: 2.1961329579353333

Epoch: 5| Step: 10
Training loss: 0.5623018145561218
Validation loss: 2.2377502471208572

Epoch: 5| Step: 11
Training loss: 0.36270976066589355
Validation loss: 2.2509526113669076

Epoch: 304| Step: 0
Training loss: 0.46317821741104126
Validation loss: 2.2345714271068573

Epoch: 5| Step: 1
Training loss: 0.27487653493881226
Validation loss: 2.241002937157949

Epoch: 5| Step: 2
Training loss: 0.5949705243110657
Validation loss: 2.214414656162262

Epoch: 5| Step: 3
Training loss: 0.27750515937805176
Validation loss: 2.2405812392632165

Epoch: 5| Step: 4
Training loss: 0.8056645393371582
Validation loss: 2.22771226366361

Epoch: 5| Step: 5
Training loss: 0.555823802947998
Validation loss: 2.276245911916097

Epoch: 5| Step: 6
Training loss: 0.3601314425468445
Validation loss: 2.224202831586202

Epoch: 5| Step: 7
Training loss: 0.5470856428146362
Validation loss: 2.2570139467716217

Epoch: 5| Step: 8
Training loss: 0.28614526987075806
Validation loss: 2.24860746661822

Epoch: 5| Step: 9
Training loss: 0.470902681350708
Validation loss: 2.2270020047823587

Epoch: 5| Step: 10
Training loss: 0.41778573393821716
Validation loss: 2.18294524649779

Epoch: 5| Step: 11
Training loss: 0.3620533049106598
Validation loss: 2.215970446666082

Epoch: 305| Step: 0
Training loss: 0.4486308991909027
Validation loss: 2.251011167963346

Epoch: 5| Step: 1
Training loss: 0.37329965829849243
Validation loss: 2.2663932542006173

Epoch: 5| Step: 2
Training loss: 0.33656415343284607
Validation loss: 2.206269398331642

Epoch: 5| Step: 3
Training loss: 0.5912365913391113
Validation loss: 2.283672591050466

Epoch: 5| Step: 4
Training loss: 0.26683908700942993
Validation loss: 2.2096912562847137

Epoch: 5| Step: 5
Training loss: 0.4286406636238098
Validation loss: 2.2680717309316

Epoch: 5| Step: 6
Training loss: 0.8414288759231567
Validation loss: 2.2362200866142907

Epoch: 5| Step: 7
Training loss: 0.46586862206459045
Validation loss: 2.2220819145441055

Epoch: 5| Step: 8
Training loss: 0.6563898921012878
Validation loss: 2.2123705546061196

Epoch: 5| Step: 9
Training loss: 0.4619200825691223
Validation loss: 2.2443493058284125

Epoch: 5| Step: 10
Training loss: 0.4155380129814148
Validation loss: 2.2446160515149436

Epoch: 5| Step: 11
Training loss: 0.657493531703949
Validation loss: 2.277504121263822

Epoch: 306| Step: 0
Training loss: 0.7261112928390503
Validation loss: 2.273945222298304

Epoch: 5| Step: 1
Training loss: 0.31062793731689453
Validation loss: 2.246117522319158

Epoch: 5| Step: 2
Training loss: 0.2961954176425934
Validation loss: 2.233625610669454

Epoch: 5| Step: 3
Training loss: 0.7803618907928467
Validation loss: 2.308529178301493

Epoch: 5| Step: 4
Training loss: 0.4543999135494232
Validation loss: 2.34251277645429

Epoch: 5| Step: 5
Training loss: 0.7278591394424438
Validation loss: 2.2805272936820984

Epoch: 5| Step: 6
Training loss: 0.4292810559272766
Validation loss: 2.2944981853167215

Epoch: 5| Step: 7
Training loss: 0.472450315952301
Validation loss: 2.2518698374430337

Epoch: 5| Step: 8
Training loss: 0.3944830894470215
Validation loss: 2.234245076775551

Epoch: 5| Step: 9
Training loss: 0.27840298414230347
Validation loss: 2.266716852784157

Epoch: 5| Step: 10
Training loss: 0.3563472032546997
Validation loss: 2.323820640643438

Epoch: 5| Step: 11
Training loss: 0.39428001642227173
Validation loss: 2.250582610567411

Epoch: 307| Step: 0
Training loss: 0.3007572889328003
Validation loss: 2.2335881888866425

Epoch: 5| Step: 1
Training loss: 0.33863019943237305
Validation loss: 2.2930080046256385

Epoch: 5| Step: 2
Training loss: 0.45470356941223145
Validation loss: 2.2733957717816033

Epoch: 5| Step: 3
Training loss: 0.6329336762428284
Validation loss: 2.2400402079025903

Epoch: 5| Step: 4
Training loss: 0.39594683051109314
Validation loss: 2.197523534297943

Epoch: 5| Step: 5
Training loss: 0.45658254623413086
Validation loss: 2.2428586333990097

Epoch: 5| Step: 6
Training loss: 0.6207183599472046
Validation loss: 2.2264854411284127

Epoch: 5| Step: 7
Training loss: 0.35042259097099304
Validation loss: 2.2476649781068168

Epoch: 5| Step: 8
Training loss: 0.549506664276123
Validation loss: 2.230430910984675

Epoch: 5| Step: 9
Training loss: 0.35235390067100525
Validation loss: 2.211237072944641

Epoch: 5| Step: 10
Training loss: 0.4266645014286041
Validation loss: 2.244785060485204

Epoch: 5| Step: 11
Training loss: 0.9751211404800415
Validation loss: 2.2387161552906036

Epoch: 308| Step: 0
Training loss: 0.4334692060947418
Validation loss: 2.186378171046575

Epoch: 5| Step: 1
Training loss: 0.46356692910194397
Validation loss: 2.2682573199272156

Epoch: 5| Step: 2
Training loss: 0.5203931927680969
Validation loss: 2.21769950290521

Epoch: 5| Step: 3
Training loss: 0.49244242906570435
Validation loss: 2.2670307060082755

Epoch: 5| Step: 4
Training loss: 0.3852502703666687
Validation loss: 2.276213973760605

Epoch: 5| Step: 5
Training loss: 0.7010836005210876
Validation loss: 2.2645591497421265

Epoch: 5| Step: 6
Training loss: 0.3700684905052185
Validation loss: 2.245156685511271

Epoch: 5| Step: 7
Training loss: 0.9369544982910156
Validation loss: 2.332142094771067

Epoch: 5| Step: 8
Training loss: 0.6547021269798279
Validation loss: 2.2499043544133506

Epoch: 5| Step: 9
Training loss: 0.5028479099273682
Validation loss: 2.235665872693062

Epoch: 5| Step: 10
Training loss: 0.2644917368888855
Validation loss: 2.3170423408349357

Epoch: 5| Step: 11
Training loss: 0.3647543787956238
Validation loss: 2.181605413556099

Epoch: 309| Step: 0
Training loss: 0.35413098335266113
Validation loss: 2.2296314537525177

Epoch: 5| Step: 1
Training loss: 0.6170570254325867
Validation loss: 2.2507032056649527

Epoch: 5| Step: 2
Training loss: 0.3735508918762207
Validation loss: 2.2680120120445886

Epoch: 5| Step: 3
Training loss: 0.6783846616744995
Validation loss: 2.2416669030984244

Epoch: 5| Step: 4
Training loss: 0.2893679440021515
Validation loss: 2.246671666701635

Epoch: 5| Step: 5
Training loss: 0.264273464679718
Validation loss: 2.205768436193466

Epoch: 5| Step: 6
Training loss: 0.32287827134132385
Validation loss: 2.1882969389359155

Epoch: 5| Step: 7
Training loss: 0.3232269883155823
Validation loss: 2.2770339051882424

Epoch: 5| Step: 8
Training loss: 0.9039298892021179
Validation loss: 2.2438602993885675

Epoch: 5| Step: 9
Training loss: 0.6949833631515503
Validation loss: 2.293093462785085

Epoch: 5| Step: 10
Training loss: 0.477914422750473
Validation loss: 2.3143616716066995

Epoch: 5| Step: 11
Training loss: 0.7672826051712036
Validation loss: 2.225156620144844

Epoch: 310| Step: 0
Training loss: 0.4431166648864746
Validation loss: 2.273700475692749

Epoch: 5| Step: 1
Training loss: 0.4350431561470032
Validation loss: 2.267611155907313

Epoch: 5| Step: 2
Training loss: 0.8055971264839172
Validation loss: 2.269212156534195

Epoch: 5| Step: 3
Training loss: 0.516057014465332
Validation loss: 2.299901525179545

Epoch: 5| Step: 4
Training loss: 0.20582008361816406
Validation loss: 2.249626432855924

Epoch: 5| Step: 5
Training loss: 0.5870125889778137
Validation loss: 2.232464144627253

Epoch: 5| Step: 6
Training loss: 0.47159966826438904
Validation loss: 2.286252791682879

Epoch: 5| Step: 7
Training loss: 0.4123814105987549
Validation loss: 2.2777917285760245

Epoch: 5| Step: 8
Training loss: 0.44432535767555237
Validation loss: 2.252341856559118

Epoch: 5| Step: 9
Training loss: 0.4289454519748688
Validation loss: 2.3008518318335214

Epoch: 5| Step: 10
Training loss: 0.49384790658950806
Validation loss: 2.265431265036265

Epoch: 5| Step: 11
Training loss: 0.36745595932006836
Validation loss: 2.280477379759153

Epoch: 311| Step: 0
Training loss: 0.31781718134880066
Validation loss: 2.241977552572886

Epoch: 5| Step: 1
Training loss: 0.30414122343063354
Validation loss: 2.219591254989306

Epoch: 5| Step: 2
Training loss: 0.4052676260471344
Validation loss: 2.327413265903791

Epoch: 5| Step: 3
Training loss: 0.45761698484420776
Validation loss: 2.230588808655739

Epoch: 5| Step: 4
Training loss: 0.46752113103866577
Validation loss: 2.285440042614937

Epoch: 5| Step: 5
Training loss: 1.1445649862289429
Validation loss: 2.290307879447937

Epoch: 5| Step: 6
Training loss: 0.42299309372901917
Validation loss: 2.2191926737626395

Epoch: 5| Step: 7
Training loss: 0.41783562302589417
Validation loss: 2.2089789112408957

Epoch: 5| Step: 8
Training loss: 0.39052191376686096
Validation loss: 2.3071566820144653

Epoch: 5| Step: 9
Training loss: 0.5279711484909058
Validation loss: 2.269807060559591

Epoch: 5| Step: 10
Training loss: 0.21830911934375763
Validation loss: 2.231043721238772

Epoch: 5| Step: 11
Training loss: 1.049458622932434
Validation loss: 2.2685582488775253

Epoch: 312| Step: 0
Training loss: 0.5435220003128052
Validation loss: 2.2795425852139792

Epoch: 5| Step: 1
Training loss: 0.916602611541748
Validation loss: 2.2304027577241263

Epoch: 5| Step: 2
Training loss: 0.48765191435813904
Validation loss: 2.2736906011899314

Epoch: 5| Step: 3
Training loss: 0.2775866389274597
Validation loss: 2.24842535952727

Epoch: 5| Step: 4
Training loss: 0.4748031497001648
Validation loss: 2.2597650388876596

Epoch: 5| Step: 5
Training loss: 0.33855879306793213
Validation loss: 2.3262264678875604

Epoch: 5| Step: 6
Training loss: 0.33933210372924805
Validation loss: 2.255547891060511

Epoch: 5| Step: 7
Training loss: 0.4044097065925598
Validation loss: 2.2048977315425873

Epoch: 5| Step: 8
Training loss: 0.4680711328983307
Validation loss: 2.2334172974030175

Epoch: 5| Step: 9
Training loss: 0.49372991919517517
Validation loss: 2.224749128023783

Epoch: 5| Step: 10
Training loss: 0.44140854477882385
Validation loss: 2.2659452706575394

Epoch: 5| Step: 11
Training loss: 0.4011853337287903
Validation loss: 2.233699838320414

Epoch: 313| Step: 0
Training loss: 0.21970686316490173
Validation loss: 2.2438318878412247

Epoch: 5| Step: 1
Training loss: 0.3300783038139343
Validation loss: 2.2385561764240265

Epoch: 5| Step: 2
Training loss: 0.5246383547782898
Validation loss: 2.2412145733833313

Epoch: 5| Step: 3
Training loss: 0.33421698212623596
Validation loss: 2.2244253009557724

Epoch: 5| Step: 4
Training loss: 0.8299655914306641
Validation loss: 2.2262545426686606

Epoch: 5| Step: 5
Training loss: 0.45417580008506775
Validation loss: 2.2342472970485687

Epoch: 5| Step: 6
Training loss: 0.5746223330497742
Validation loss: 2.256904751062393

Epoch: 5| Step: 7
Training loss: 0.3155476152896881
Validation loss: 2.2205085357030234

Epoch: 5| Step: 8
Training loss: 0.44663000106811523
Validation loss: 2.23758257428805

Epoch: 5| Step: 9
Training loss: 0.29936379194259644
Validation loss: 2.28927289446195

Epoch: 5| Step: 10
Training loss: 0.30672919750213623
Validation loss: 2.282407412926356

Epoch: 5| Step: 11
Training loss: 0.24871563911437988
Validation loss: 2.2798955192168555

Epoch: 314| Step: 0
Training loss: 1.0284688472747803
Validation loss: 2.2789335350195565

Epoch: 5| Step: 1
Training loss: 0.4776318073272705
Validation loss: 2.272414435942968

Epoch: 5| Step: 2
Training loss: 0.548081636428833
Validation loss: 2.2038705299297967

Epoch: 5| Step: 3
Training loss: 0.40709418058395386
Validation loss: 2.218893344203631

Epoch: 5| Step: 4
Training loss: 0.25399622321128845
Validation loss: 2.235538308819135

Epoch: 5| Step: 5
Training loss: 0.4903082847595215
Validation loss: 2.2683244347572327

Epoch: 5| Step: 6
Training loss: 0.3175336420536041
Validation loss: 2.239661688605944

Epoch: 5| Step: 7
Training loss: 0.2935391962528229
Validation loss: 2.2214624683062234

Epoch: 5| Step: 8
Training loss: 0.589285671710968
Validation loss: 2.3013901114463806

Epoch: 5| Step: 9
Training loss: 0.41197115182876587
Validation loss: 2.2435695926348367

Epoch: 5| Step: 10
Training loss: 0.3123766779899597
Validation loss: 2.269494737188021

Epoch: 5| Step: 11
Training loss: 0.5764780044555664
Validation loss: 2.228174472848574

Epoch: 315| Step: 0
Training loss: 0.3781443238258362
Validation loss: 2.248561273018519

Epoch: 5| Step: 1
Training loss: 0.37295734882354736
Validation loss: 2.236931413412094

Epoch: 5| Step: 2
Training loss: 0.2850917875766754
Validation loss: 2.2576133757829666

Epoch: 5| Step: 3
Training loss: 0.30044442415237427
Validation loss: 2.2279529919226966

Epoch: 5| Step: 4
Training loss: 0.38911616802215576
Validation loss: 2.247697025537491

Epoch: 5| Step: 5
Training loss: 0.38140401244163513
Validation loss: 2.1894642611344657

Epoch: 5| Step: 6
Training loss: 0.4766969680786133
Validation loss: 2.24400203426679

Epoch: 5| Step: 7
Training loss: 0.717049241065979
Validation loss: 2.2806725104649863

Epoch: 5| Step: 8
Training loss: 0.5118009448051453
Validation loss: 2.2245137045780816

Epoch: 5| Step: 9
Training loss: 0.8258500099182129
Validation loss: 2.224175820748011

Epoch: 5| Step: 10
Training loss: 0.27902740240097046
Validation loss: 2.2203140556812286

Epoch: 5| Step: 11
Training loss: 0.1980057656764984
Validation loss: 2.2246615439653397

Epoch: 316| Step: 0
Training loss: 0.6178787350654602
Validation loss: 2.197649205724398

Epoch: 5| Step: 1
Training loss: 0.34888115525245667
Validation loss: 2.245456258455912

Epoch: 5| Step: 2
Training loss: 0.564944863319397
Validation loss: 2.23217943807443

Epoch: 5| Step: 3
Training loss: 0.4031931459903717
Validation loss: 2.2491350173950195

Epoch: 5| Step: 4
Training loss: 0.2667272984981537
Validation loss: 2.2257928599913916

Epoch: 5| Step: 5
Training loss: 0.5118528604507446
Validation loss: 2.2010232557853064

Epoch: 5| Step: 6
Training loss: 0.476397842168808
Validation loss: 2.2432803163925805

Epoch: 5| Step: 7
Training loss: 0.349508136510849
Validation loss: 2.260281284650167

Epoch: 5| Step: 8
Training loss: 0.4764021039009094
Validation loss: 2.2824215392271676

Epoch: 5| Step: 9
Training loss: 0.8750181198120117
Validation loss: 2.236893355846405

Epoch: 5| Step: 10
Training loss: 0.3857477307319641
Validation loss: 2.2051746398210526

Epoch: 5| Step: 11
Training loss: 0.6055278778076172
Validation loss: 2.2471971909205117

Epoch: 317| Step: 0
Training loss: 0.36355167627334595
Validation loss: 2.245033949613571

Epoch: 5| Step: 1
Training loss: 0.33863693475723267
Validation loss: 2.2925153325001397

Epoch: 5| Step: 2
Training loss: 0.28379759192466736
Validation loss: 2.2166896164417267

Epoch: 5| Step: 3
Training loss: 0.5628503561019897
Validation loss: 2.2969308495521545

Epoch: 5| Step: 4
Training loss: 0.3699004650115967
Validation loss: 2.2127567480007806

Epoch: 5| Step: 5
Training loss: 0.749160885810852
Validation loss: 2.2558618982632956

Epoch: 5| Step: 6
Training loss: 0.38862282037734985
Validation loss: 2.2330914636452994

Epoch: 5| Step: 7
Training loss: 0.5072963833808899
Validation loss: 2.2534375886122384

Epoch: 5| Step: 8
Training loss: 0.3703124225139618
Validation loss: 2.211558441321055

Epoch: 5| Step: 9
Training loss: 0.4442368149757385
Validation loss: 2.2243259896834693

Epoch: 5| Step: 10
Training loss: 0.5505784749984741
Validation loss: 2.255722160140673

Epoch: 5| Step: 11
Training loss: 0.37146925926208496
Validation loss: 2.241975744565328

Epoch: 318| Step: 0
Training loss: 0.35520973801612854
Validation loss: 2.2413142025470734

Epoch: 5| Step: 1
Training loss: 0.25334399938583374
Validation loss: 2.294119546810786

Epoch: 5| Step: 2
Training loss: 0.2762468159198761
Validation loss: 2.238663082321485

Epoch: 5| Step: 3
Training loss: 0.8007216453552246
Validation loss: 2.2843058904012046

Epoch: 5| Step: 4
Training loss: 0.3906382620334625
Validation loss: 2.281765341758728

Epoch: 5| Step: 5
Training loss: 0.8816947937011719
Validation loss: 2.2489029665788016

Epoch: 5| Step: 6
Training loss: 0.44383543729782104
Validation loss: 2.2390178938706717

Epoch: 5| Step: 7
Training loss: 0.38110941648483276
Validation loss: 2.2108806570370994

Epoch: 5| Step: 8
Training loss: 0.3487418293952942
Validation loss: 2.1913157204786935

Epoch: 5| Step: 9
Training loss: 0.4538566470146179
Validation loss: 2.2370814283688865

Epoch: 5| Step: 10
Training loss: 0.3180975914001465
Validation loss: 2.2313420474529266

Epoch: 5| Step: 11
Training loss: 0.2975172996520996
Validation loss: 2.2803809493780136

Epoch: 319| Step: 0
Training loss: 0.34972643852233887
Validation loss: 2.2308908502260842

Epoch: 5| Step: 1
Training loss: 0.5709887146949768
Validation loss: 2.2573981235424676

Epoch: 5| Step: 2
Training loss: 0.8321788907051086
Validation loss: 2.196546792984009

Epoch: 5| Step: 3
Training loss: 0.3303084373474121
Validation loss: 2.2275733947753906

Epoch: 5| Step: 4
Training loss: 0.4725363850593567
Validation loss: 2.194694757461548

Epoch: 5| Step: 5
Training loss: 0.38511914014816284
Validation loss: 2.2429111103216806

Epoch: 5| Step: 6
Training loss: 0.5468848943710327
Validation loss: 2.2145939568678537

Epoch: 5| Step: 7
Training loss: 0.34479764103889465
Validation loss: 2.227299357453982

Epoch: 5| Step: 8
Training loss: 0.29154565930366516
Validation loss: 2.2415221482515335

Epoch: 5| Step: 9
Training loss: 0.32277387380599976
Validation loss: 2.2389942904313407

Epoch: 5| Step: 10
Training loss: 0.2917559742927551
Validation loss: 2.1929064840078354

Epoch: 5| Step: 11
Training loss: 0.19132575392723083
Validation loss: 2.2045028458038964

Epoch: 320| Step: 0
Training loss: 0.4229224622249603
Validation loss: 2.2559975385665894

Epoch: 5| Step: 1
Training loss: 0.6909841299057007
Validation loss: 2.2791154831647873

Epoch: 5| Step: 2
Training loss: 0.7052010297775269
Validation loss: 2.2429453631242118

Epoch: 5| Step: 3
Training loss: 0.5614360570907593
Validation loss: 2.2072619696458182

Epoch: 5| Step: 4
Training loss: 0.45230716466903687
Validation loss: 2.136899580558141

Epoch: 5| Step: 5
Training loss: 0.49879512190818787
Validation loss: 2.227579260865847

Epoch: 5| Step: 6
Training loss: 0.33271926641464233
Validation loss: 2.2232866138219833

Epoch: 5| Step: 7
Training loss: 0.5401182174682617
Validation loss: 2.2509996195634208

Epoch: 5| Step: 8
Training loss: 0.9012371897697449
Validation loss: 2.2426509112119675

Epoch: 5| Step: 9
Training loss: 0.7154123783111572
Validation loss: 2.2539885540803275

Epoch: 5| Step: 10
Training loss: 0.22143153846263885
Validation loss: 2.198397845029831

Epoch: 5| Step: 11
Training loss: 0.25807270407676697
Validation loss: 2.197585180401802

Epoch: 321| Step: 0
Training loss: 0.5436743497848511
Validation loss: 2.2608020106951394

Epoch: 5| Step: 1
Training loss: 0.3321146070957184
Validation loss: 2.2381878942251205

Epoch: 5| Step: 2
Training loss: 0.6115134954452515
Validation loss: 2.206995889544487

Epoch: 5| Step: 3
Training loss: 0.42621079087257385
Validation loss: 2.2049385209878287

Epoch: 5| Step: 4
Training loss: 0.383541077375412
Validation loss: 2.2274502168099084

Epoch: 5| Step: 5
Training loss: 0.39012736082077026
Validation loss: 2.195402279496193

Epoch: 5| Step: 6
Training loss: 0.4747784733772278
Validation loss: 2.198543126384417

Epoch: 5| Step: 7
Training loss: 0.42993730306625366
Validation loss: 2.215364103515943

Epoch: 5| Step: 8
Training loss: 0.387712299823761
Validation loss: 2.1888020783662796

Epoch: 5| Step: 9
Training loss: 0.4965640902519226
Validation loss: 2.2111920565366745

Epoch: 5| Step: 10
Training loss: 0.3596116602420807
Validation loss: 2.2358107964197793

Epoch: 5| Step: 11
Training loss: 0.6923343539237976
Validation loss: 2.1831433226664863

Epoch: 322| Step: 0
Training loss: 0.9441080093383789
Validation loss: 2.236150160431862

Epoch: 5| Step: 1
Training loss: 0.42027854919433594
Validation loss: 2.1983719815810523

Epoch: 5| Step: 2
Training loss: 0.5063072443008423
Validation loss: 2.240805755058924

Epoch: 5| Step: 3
Training loss: 0.5451098084449768
Validation loss: 2.2204994211594262

Epoch: 5| Step: 4
Training loss: 0.45660001039505005
Validation loss: 2.1723616818586984

Epoch: 5| Step: 5
Training loss: 0.4557070732116699
Validation loss: 2.2223407675822577

Epoch: 5| Step: 6
Training loss: 0.5899994969367981
Validation loss: 2.187843680381775

Epoch: 5| Step: 7
Training loss: 0.36867600679397583
Validation loss: 2.2330492536226907

Epoch: 5| Step: 8
Training loss: 0.28277236223220825
Validation loss: 2.218629240989685

Epoch: 5| Step: 9
Training loss: 0.41406112909317017
Validation loss: 2.167555332183838

Epoch: 5| Step: 10
Training loss: 0.43642082810401917
Validation loss: 2.209861824909846

Epoch: 5| Step: 11
Training loss: 0.11428956687450409
Validation loss: 2.2449709276358285

Epoch: 323| Step: 0
Training loss: 0.38278165459632874
Validation loss: 2.211725036303202

Epoch: 5| Step: 1
Training loss: 0.3425371050834656
Validation loss: 2.292168617248535

Epoch: 5| Step: 2
Training loss: 0.5781481266021729
Validation loss: 2.2640776385863624

Epoch: 5| Step: 3
Training loss: 0.6189097166061401
Validation loss: 2.2708850602308908

Epoch: 5| Step: 4
Training loss: 0.46613550186157227
Validation loss: 2.2908935149510703

Epoch: 5| Step: 5
Training loss: 0.7636592388153076
Validation loss: 2.325990915298462

Epoch: 5| Step: 6
Training loss: 0.5326480865478516
Validation loss: 2.279015521208445

Epoch: 5| Step: 7
Training loss: 0.39795345067977905
Validation loss: 2.2414451291163764

Epoch: 5| Step: 8
Training loss: 0.5218634605407715
Validation loss: 2.2146593828996024

Epoch: 5| Step: 9
Training loss: 0.412651389837265
Validation loss: 2.2422411938508353

Epoch: 5| Step: 10
Training loss: 0.36054927110671997
Validation loss: 2.22529503206412

Epoch: 5| Step: 11
Training loss: 0.3427013158798218
Validation loss: 2.3136991560459137

Epoch: 324| Step: 0
Training loss: 0.3667698800563812
Validation loss: 2.289697974920273

Epoch: 5| Step: 1
Training loss: 0.4989730417728424
Validation loss: 2.2709328681230545

Epoch: 5| Step: 2
Training loss: 0.458549827337265
Validation loss: 2.2473696768283844

Epoch: 5| Step: 3
Training loss: 0.4564703106880188
Validation loss: 2.285333280762037

Epoch: 5| Step: 4
Training loss: 0.34358254075050354
Validation loss: 2.2711576223373413

Epoch: 5| Step: 5
Training loss: 0.4777641296386719
Validation loss: 2.25334898630778

Epoch: 5| Step: 6
Training loss: 0.698664665222168
Validation loss: 2.250245208541552

Epoch: 5| Step: 7
Training loss: 0.6705718636512756
Validation loss: 2.2387985289096832

Epoch: 5| Step: 8
Training loss: 0.48949867486953735
Validation loss: 2.2144471307595572

Epoch: 5| Step: 9
Training loss: 0.36045271158218384
Validation loss: 2.198409507671992

Epoch: 5| Step: 10
Training loss: 0.693744957447052
Validation loss: 2.241767739256223

Epoch: 5| Step: 11
Training loss: 0.3185802698135376
Validation loss: 2.2150176763534546

Epoch: 325| Step: 0
Training loss: 0.26764464378356934
Validation loss: 2.231827919681867

Epoch: 5| Step: 1
Training loss: 0.37802571058273315
Validation loss: 2.194834957520167

Epoch: 5| Step: 2
Training loss: 0.6905757188796997
Validation loss: 2.2449469417333603

Epoch: 5| Step: 3
Training loss: 0.4994668960571289
Validation loss: 2.2139704575141272

Epoch: 5| Step: 4
Training loss: 0.4197259843349457
Validation loss: 2.2156205674012504

Epoch: 5| Step: 5
Training loss: 0.3046494424343109
Validation loss: 2.1994432161251702

Epoch: 5| Step: 6
Training loss: 0.39257222414016724
Validation loss: 2.156254385908445

Epoch: 5| Step: 7
Training loss: 0.3075951039791107
Validation loss: 2.20826056599617

Epoch: 5| Step: 8
Training loss: 0.5967908501625061
Validation loss: 2.2078864375750222

Epoch: 5| Step: 9
Training loss: 0.3033197820186615
Validation loss: 2.1717302004496255

Epoch: 5| Step: 10
Training loss: 0.6085704565048218
Validation loss: 2.2059138317902884

Epoch: 5| Step: 11
Training loss: 0.8545931577682495
Validation loss: 2.1811157961686454

Epoch: 326| Step: 0
Training loss: 0.3976210057735443
Validation loss: 2.213570088148117

Epoch: 5| Step: 1
Training loss: 0.5424576997756958
Validation loss: 2.2302689949671426

Epoch: 5| Step: 2
Training loss: 0.3966471254825592
Validation loss: 2.169221132993698

Epoch: 5| Step: 3
Training loss: 0.8550348281860352
Validation loss: 2.2084744970003762

Epoch: 5| Step: 4
Training loss: 0.2271648347377777
Validation loss: 2.1882230738798776

Epoch: 5| Step: 5
Training loss: 0.2416275441646576
Validation loss: 2.2147142191727958

Epoch: 5| Step: 6
Training loss: 0.4190220832824707
Validation loss: 2.2112705210844674

Epoch: 5| Step: 7
Training loss: 0.6036906838417053
Validation loss: 2.20904570321242

Epoch: 5| Step: 8
Training loss: 0.697738766670227
Validation loss: 2.3057292997837067

Epoch: 5| Step: 9
Training loss: 0.533413827419281
Validation loss: 2.2505343159039817

Epoch: 5| Step: 10
Training loss: 0.3436046242713928
Validation loss: 2.1945709784825644

Epoch: 5| Step: 11
Training loss: 0.2913329005241394
Validation loss: 2.248405839006106

Epoch: 327| Step: 0
Training loss: 0.39145803451538086
Validation loss: 2.2709145098924637

Epoch: 5| Step: 1
Training loss: 0.3976096510887146
Validation loss: 2.1953631242116294

Epoch: 5| Step: 2
Training loss: 0.7272080779075623
Validation loss: 2.1992186258236566

Epoch: 5| Step: 3
Training loss: 0.9536529779434204
Validation loss: 2.2305325269699097

Epoch: 5| Step: 4
Training loss: 0.6802468299865723
Validation loss: 2.280095865329107

Epoch: 5| Step: 5
Training loss: 0.24595589935779572
Validation loss: 2.153135930498441

Epoch: 5| Step: 6
Training loss: 0.4628276824951172
Validation loss: 2.251837139328321

Epoch: 5| Step: 7
Training loss: 0.5065127611160278
Validation loss: 2.2606748143831887

Epoch: 5| Step: 8
Training loss: 0.6473017930984497
Validation loss: 2.2314478059609733

Epoch: 5| Step: 9
Training loss: 0.44677600264549255
Validation loss: 2.2977395008007684

Epoch: 5| Step: 10
Training loss: 0.4338875710964203
Validation loss: 2.2413227260112762

Epoch: 5| Step: 11
Training loss: 0.17421352863311768
Validation loss: 2.239748328924179

Epoch: 328| Step: 0
Training loss: 0.32338500022888184
Validation loss: 2.2606233805418015

Epoch: 5| Step: 1
Training loss: 0.5063133835792542
Validation loss: 2.2352531204620996

Epoch: 5| Step: 2
Training loss: 0.5478935241699219
Validation loss: 2.282342846194903

Epoch: 5| Step: 3
Training loss: 0.6026466488838196
Validation loss: 2.257828881343206

Epoch: 5| Step: 4
Training loss: 0.2788155972957611
Validation loss: 2.2697747548421225

Epoch: 5| Step: 5
Training loss: 0.5285662412643433
Validation loss: 2.247001493970553

Epoch: 5| Step: 6
Training loss: 0.8729440569877625
Validation loss: 2.2231483111778894

Epoch: 5| Step: 7
Training loss: 0.45181742310523987
Validation loss: 2.2024331192175546

Epoch: 5| Step: 8
Training loss: 0.22874431312084198
Validation loss: 2.2395199636618295

Epoch: 5| Step: 9
Training loss: 0.4174557626247406
Validation loss: 2.2267640431722007

Epoch: 5| Step: 10
Training loss: 0.3830786347389221
Validation loss: 2.2068182677030563

Epoch: 5| Step: 11
Training loss: 0.43464118242263794
Validation loss: 2.2069348146518073

Epoch: 329| Step: 0
Training loss: 0.45561379194259644
Validation loss: 2.234216113885244

Epoch: 5| Step: 1
Training loss: 0.52092045545578
Validation loss: 2.205168123046557

Epoch: 5| Step: 2
Training loss: 0.5246554017066956
Validation loss: 2.1812403251727424

Epoch: 5| Step: 3
Training loss: 0.8726628422737122
Validation loss: 2.1943902373313904

Epoch: 5| Step: 4
Training loss: 0.5071157813072205
Validation loss: 2.200959453980128

Epoch: 5| Step: 5
Training loss: 0.5132461786270142
Validation loss: 2.20511985818545

Epoch: 5| Step: 6
Training loss: 0.34908753633499146
Validation loss: 2.238990768790245

Epoch: 5| Step: 7
Training loss: 0.32746419310569763
Validation loss: 2.258561462163925

Epoch: 5| Step: 8
Training loss: 0.510526180267334
Validation loss: 2.263714705904325

Epoch: 5| Step: 9
Training loss: 0.3664495348930359
Validation loss: 2.2328355063994727

Epoch: 5| Step: 10
Training loss: 0.40121594071388245
Validation loss: 2.2391438484191895

Epoch: 5| Step: 11
Training loss: 0.38687795400619507
Validation loss: 2.2441420406103134

Epoch: 330| Step: 0
Training loss: 0.30718308687210083
Validation loss: 2.2340083519617715

Epoch: 5| Step: 1
Training loss: 0.3913153409957886
Validation loss: 2.2082803895076117

Epoch: 5| Step: 2
Training loss: 0.45396390557289124
Validation loss: 2.210316593448321

Epoch: 5| Step: 3
Training loss: 0.19142988324165344
Validation loss: 2.2619816859563193

Epoch: 5| Step: 4
Training loss: 0.5790873765945435
Validation loss: 2.2898804048697152

Epoch: 5| Step: 5
Training loss: 0.21916918456554413
Validation loss: 2.2377100388209024

Epoch: 5| Step: 6
Training loss: 0.48744091391563416
Validation loss: 2.221359228094419

Epoch: 5| Step: 7
Training loss: 0.7722489833831787
Validation loss: 2.2113831440607705

Epoch: 5| Step: 8
Training loss: 0.3295041620731354
Validation loss: 2.245986357331276

Epoch: 5| Step: 9
Training loss: 0.3738199770450592
Validation loss: 2.2011453360319138

Epoch: 5| Step: 10
Training loss: 0.4812931418418884
Validation loss: 2.193063278992971

Epoch: 5| Step: 11
Training loss: 0.18380671739578247
Validation loss: 2.2462968627611795

Epoch: 331| Step: 0
Training loss: 0.42129701375961304
Validation loss: 2.2792268097400665

Epoch: 5| Step: 1
Training loss: 0.40249529480934143
Validation loss: 2.257531682650248

Epoch: 5| Step: 2
Training loss: 0.3024085760116577
Validation loss: 2.262609432140986

Epoch: 5| Step: 3
Training loss: 0.338828980922699
Validation loss: 2.2952133466800055

Epoch: 5| Step: 4
Training loss: 0.5359905958175659
Validation loss: 2.256111353635788

Epoch: 5| Step: 5
Training loss: 0.49333199858665466
Validation loss: 2.285314381122589

Epoch: 5| Step: 6
Training loss: 0.652233898639679
Validation loss: 2.2356642285982766

Epoch: 5| Step: 7
Training loss: 0.28827086091041565
Validation loss: 2.309876799583435

Epoch: 5| Step: 8
Training loss: 0.40397652983665466
Validation loss: 2.270883232355118

Epoch: 5| Step: 9
Training loss: 0.4361228048801422
Validation loss: 2.2447817772626877

Epoch: 5| Step: 10
Training loss: 0.26640453934669495
Validation loss: 2.2275925874710083

Epoch: 5| Step: 11
Training loss: 0.4751288890838623
Validation loss: 2.2337431609630585

Epoch: 332| Step: 0
Training loss: 0.35675185918807983
Validation loss: 2.1891674449046454

Epoch: 5| Step: 1
Training loss: 0.4384474754333496
Validation loss: 2.240088328719139

Epoch: 5| Step: 2
Training loss: 0.4681527018547058
Validation loss: 2.2338343063990274

Epoch: 5| Step: 3
Training loss: 0.3929418921470642
Validation loss: 2.268197019894918

Epoch: 5| Step: 4
Training loss: 0.24403145909309387
Validation loss: 2.29373570283254

Epoch: 5| Step: 5
Training loss: 0.449788898229599
Validation loss: 2.2393953253825507

Epoch: 5| Step: 6
Training loss: 0.357540488243103
Validation loss: 2.261069039503733

Epoch: 5| Step: 7
Training loss: 0.32072269916534424
Validation loss: 2.202466383576393

Epoch: 5| Step: 8
Training loss: 0.35323822498321533
Validation loss: 2.2397384494543076

Epoch: 5| Step: 9
Training loss: 0.4966112971305847
Validation loss: 2.2873767067988715

Epoch: 5| Step: 10
Training loss: 0.8633347749710083
Validation loss: 2.2464323292175927

Epoch: 5| Step: 11
Training loss: 0.2820582389831543
Validation loss: 2.2898071706295013

Epoch: 333| Step: 0
Training loss: 0.23893840610980988
Validation loss: 2.262512375911077

Epoch: 5| Step: 1
Training loss: 0.2779642939567566
Validation loss: 2.2165860384702682

Epoch: 5| Step: 2
Training loss: 0.5030360221862793
Validation loss: 2.2545552353064218

Epoch: 5| Step: 3
Training loss: 0.6312729716300964
Validation loss: 2.2812879582246146

Epoch: 5| Step: 4
Training loss: 0.4442744851112366
Validation loss: 2.240718960762024

Epoch: 5| Step: 5
Training loss: 0.5908712148666382
Validation loss: 2.3331006864706674

Epoch: 5| Step: 6
Training loss: 0.27044016122817993
Validation loss: 2.232064113020897

Epoch: 5| Step: 7
Training loss: 0.7395032644271851
Validation loss: 2.1972643981377282

Epoch: 5| Step: 8
Training loss: 0.3332606554031372
Validation loss: 2.325788418451945

Epoch: 5| Step: 9
Training loss: 0.27115046977996826
Validation loss: 2.2552013198534646

Epoch: 5| Step: 10
Training loss: 0.47713714838027954
Validation loss: 2.2605626583099365

Epoch: 5| Step: 11
Training loss: 0.404656320810318
Validation loss: 2.2622097730636597

Epoch: 334| Step: 0
Training loss: 0.6050743460655212
Validation loss: 2.2355999102195105

Epoch: 5| Step: 1
Training loss: 0.3771044611930847
Validation loss: 2.2548065235217414

Epoch: 5| Step: 2
Training loss: 0.3963507115840912
Validation loss: 2.2532283614079156

Epoch: 5| Step: 3
Training loss: 0.3924352824687958
Validation loss: 2.1827815969785056

Epoch: 5| Step: 4
Training loss: 0.3604249358177185
Validation loss: 2.244284282128016

Epoch: 5| Step: 5
Training loss: 0.1995653659105301
Validation loss: 2.21626507739226

Epoch: 5| Step: 6
Training loss: 0.551326334476471
Validation loss: 2.1862228314081826

Epoch: 5| Step: 7
Training loss: 0.6727566719055176
Validation loss: 2.219270279010137

Epoch: 5| Step: 8
Training loss: 0.2867123484611511
Validation loss: 2.161604026953379

Epoch: 5| Step: 9
Training loss: 0.7187706828117371
Validation loss: 2.1092568586270013

Epoch: 5| Step: 10
Training loss: 0.3061043620109558
Validation loss: 2.1804541995127997

Epoch: 5| Step: 11
Training loss: 0.16307230293750763
Validation loss: 2.1945071667432785

Epoch: 335| Step: 0
Training loss: 0.6311620473861694
Validation loss: 2.1829058676958084

Epoch: 5| Step: 1
Training loss: 0.3175647258758545
Validation loss: 2.204609433809916

Epoch: 5| Step: 2
Training loss: 0.2920704185962677
Validation loss: 2.227955306569735

Epoch: 5| Step: 3
Training loss: 0.3467749059200287
Validation loss: 2.2171597381432853

Epoch: 5| Step: 4
Training loss: 0.48434099555015564
Validation loss: 2.213447173436483

Epoch: 5| Step: 5
Training loss: 0.28537318110466003
Validation loss: 2.245459874471029

Epoch: 5| Step: 6
Training loss: 0.34388384222984314
Validation loss: 2.194707468152046

Epoch: 5| Step: 7
Training loss: 0.6773496866226196
Validation loss: 2.2328916688760123

Epoch: 5| Step: 8
Training loss: 0.7099515795707703
Validation loss: 2.1994948238134384

Epoch: 5| Step: 9
Training loss: 0.40317827463150024
Validation loss: 2.2217711210250854

Epoch: 5| Step: 10
Training loss: 0.5228421092033386
Validation loss: 2.2328336983919144

Epoch: 5| Step: 11
Training loss: 0.2507258653640747
Validation loss: 2.168004021048546

Epoch: 336| Step: 0
Training loss: 0.3777450919151306
Validation loss: 2.2343908150990806

Epoch: 5| Step: 1
Training loss: 0.3588579595088959
Validation loss: 2.2147530019283295

Epoch: 5| Step: 2
Training loss: 0.325448602437973
Validation loss: 2.2220285336176553

Epoch: 5| Step: 3
Training loss: 0.5200818777084351
Validation loss: 2.164573227365812

Epoch: 5| Step: 4
Training loss: 0.760786235332489
Validation loss: 2.227357789874077

Epoch: 5| Step: 5
Training loss: 0.3792693018913269
Validation loss: 2.218883365392685

Epoch: 5| Step: 6
Training loss: 0.4166173040866852
Validation loss: 2.1618901441494622

Epoch: 5| Step: 7
Training loss: 0.5113828182220459
Validation loss: 2.1878504206736884

Epoch: 5| Step: 8
Training loss: 0.46837058663368225
Validation loss: 2.2455509901046753

Epoch: 5| Step: 9
Training loss: 0.23930850625038147
Validation loss: 2.185300981005033

Epoch: 5| Step: 10
Training loss: 0.37265774607658386
Validation loss: 2.162601664662361

Epoch: 5| Step: 11
Training loss: 0.4635080099105835
Validation loss: 2.154342104991277

Epoch: 337| Step: 0
Training loss: 0.5016085505485535
Validation loss: 2.194981957475344

Epoch: 5| Step: 1
Training loss: 0.5018969774246216
Validation loss: 2.264598031838735

Epoch: 5| Step: 2
Training loss: 0.39547982811927795
Validation loss: 2.2910839517911277

Epoch: 5| Step: 3
Training loss: 0.4077945649623871
Validation loss: 2.1994496484597525

Epoch: 5| Step: 4
Training loss: 0.24512577056884766
Validation loss: 2.238861391941706

Epoch: 5| Step: 5
Training loss: 0.48883897066116333
Validation loss: 2.2085329492886863

Epoch: 5| Step: 6
Training loss: 0.4049406051635742
Validation loss: 2.218135620156924

Epoch: 5| Step: 7
Training loss: 0.33292707800865173
Validation loss: 2.2239978263775506

Epoch: 5| Step: 8
Training loss: 0.9012959599494934
Validation loss: 2.278543710708618

Epoch: 5| Step: 9
Training loss: 0.33842843770980835
Validation loss: 2.2178876797358194

Epoch: 5| Step: 10
Training loss: 0.467302143573761
Validation loss: 2.168585956096649

Epoch: 5| Step: 11
Training loss: 0.3741859197616577
Validation loss: 2.2182403107484183

Epoch: 338| Step: 0
Training loss: 0.45745038986206055
Validation loss: 2.2419973611831665

Epoch: 5| Step: 1
Training loss: 0.4628972113132477
Validation loss: 2.2580352226893106

Epoch: 5| Step: 2
Training loss: 0.6569532155990601
Validation loss: 2.2441179553667703

Epoch: 5| Step: 3
Training loss: 0.3473130166530609
Validation loss: 2.1803208390871682

Epoch: 5| Step: 4
Training loss: 0.44859009981155396
Validation loss: 2.247727001706759

Epoch: 5| Step: 5
Training loss: 0.3755945861339569
Validation loss: 2.2395520955324173

Epoch: 5| Step: 6
Training loss: 0.6234785914421082
Validation loss: 2.2899918407201767

Epoch: 5| Step: 7
Training loss: 0.7432610392570496
Validation loss: 2.269943098227183

Epoch: 5| Step: 8
Training loss: 0.4943011403083801
Validation loss: 2.207357337077459

Epoch: 5| Step: 9
Training loss: 0.2746807634830475
Validation loss: 2.2602847814559937

Epoch: 5| Step: 10
Training loss: 0.30808770656585693
Validation loss: 2.1888447254896164

Epoch: 5| Step: 11
Training loss: 0.3767228424549103
Validation loss: 2.2733790228764215

Epoch: 339| Step: 0
Training loss: 0.6668421030044556
Validation loss: 2.2526588290929794

Epoch: 5| Step: 1
Training loss: 0.5392816662788391
Validation loss: 2.3000365495681763

Epoch: 5| Step: 2
Training loss: 0.3678083121776581
Validation loss: 2.2395082463820777

Epoch: 5| Step: 3
Training loss: 0.4084842801094055
Validation loss: 2.19283926486969

Epoch: 5| Step: 4
Training loss: 0.24642448127269745
Validation loss: 2.1867342491944632

Epoch: 5| Step: 5
Training loss: 0.2841585874557495
Validation loss: 2.208701511224111

Epoch: 5| Step: 6
Training loss: 0.39835506677627563
Validation loss: 2.269133205215136

Epoch: 5| Step: 7
Training loss: 0.38848087191581726
Validation loss: 2.235740065574646

Epoch: 5| Step: 8
Training loss: 0.8110648989677429
Validation loss: 2.2262031733989716

Epoch: 5| Step: 9
Training loss: 0.5408641695976257
Validation loss: 2.219506800174713

Epoch: 5| Step: 10
Training loss: 0.4828242361545563
Validation loss: 2.2455685834089913

Epoch: 5| Step: 11
Training loss: 0.5147963762283325
Validation loss: 2.2132720152537027

Epoch: 340| Step: 0
Training loss: 0.4032835066318512
Validation loss: 2.19962747891744

Epoch: 5| Step: 1
Training loss: 0.520404040813446
Validation loss: 2.2247902005910873

Epoch: 5| Step: 2
Training loss: 0.3140479028224945
Validation loss: 2.2519304851690927

Epoch: 5| Step: 3
Training loss: 0.6338881850242615
Validation loss: 2.269304782152176

Epoch: 5| Step: 4
Training loss: 0.3585525453090668
Validation loss: 2.2477187663316727

Epoch: 5| Step: 5
Training loss: 0.42988020181655884
Validation loss: 2.3222160240014396

Epoch: 5| Step: 6
Training loss: 0.3977983295917511
Validation loss: 2.322196046511332

Epoch: 5| Step: 7
Training loss: 0.3571353852748871
Validation loss: 2.198475847641627

Epoch: 5| Step: 8
Training loss: 0.22704175114631653
Validation loss: 2.249364177385966

Epoch: 5| Step: 9
Training loss: 0.24671483039855957
Validation loss: 2.243206242720286

Epoch: 5| Step: 10
Training loss: 0.8335884809494019
Validation loss: 2.3207364877065024

Epoch: 5| Step: 11
Training loss: 0.39136362075805664
Validation loss: 2.2496188580989838

Epoch: 341| Step: 0
Training loss: 0.2575226128101349
Validation loss: 2.2122279753287635

Epoch: 5| Step: 1
Training loss: 0.23265734314918518
Validation loss: 2.216462587316831

Epoch: 5| Step: 2
Training loss: 0.4319264888763428
Validation loss: 2.2568888316551843

Epoch: 5| Step: 3
Training loss: 0.5559278130531311
Validation loss: 2.253827085097631

Epoch: 5| Step: 4
Training loss: 0.45436421036720276
Validation loss: 2.251160035530726

Epoch: 5| Step: 5
Training loss: 0.8288511037826538
Validation loss: 2.2268939912319183

Epoch: 5| Step: 6
Training loss: 0.2641753554344177
Validation loss: 2.219304626186689

Epoch: 5| Step: 7
Training loss: 0.4557724595069885
Validation loss: 2.212443172931671

Epoch: 5| Step: 8
Training loss: 0.6324104070663452
Validation loss: 2.256226748228073

Epoch: 5| Step: 9
Training loss: 0.33065661787986755
Validation loss: 2.2071357667446136

Epoch: 5| Step: 10
Training loss: 0.782848060131073
Validation loss: 2.2336149712403617

Epoch: 5| Step: 11
Training loss: 0.39102816581726074
Validation loss: 2.269228811065356

Epoch: 342| Step: 0
Training loss: 0.20972540974617004
Validation loss: 2.1974150091409683

Epoch: 5| Step: 1
Training loss: 0.34886062145233154
Validation loss: 2.2076131403446198

Epoch: 5| Step: 2
Training loss: 0.5501692891120911
Validation loss: 2.282546083132426

Epoch: 5| Step: 3
Training loss: 0.516038715839386
Validation loss: 2.2418486128250756

Epoch: 5| Step: 4
Training loss: 0.5161634087562561
Validation loss: 2.2402513126532235

Epoch: 5| Step: 5
Training loss: 0.29586562514305115
Validation loss: 2.2079303860664368

Epoch: 5| Step: 6
Training loss: 0.42089328169822693
Validation loss: 2.2110965053240457

Epoch: 5| Step: 7
Training loss: 0.45012974739074707
Validation loss: 2.2697491546471915

Epoch: 5| Step: 8
Training loss: 0.7635833621025085
Validation loss: 2.2818642457326255

Epoch: 5| Step: 9
Training loss: 0.6813497543334961
Validation loss: 2.305113971233368

Epoch: 5| Step: 10
Training loss: 0.383253276348114
Validation loss: 2.2748501698176065

Epoch: 5| Step: 11
Training loss: 0.3895118832588196
Validation loss: 2.291957765817642

Epoch: 343| Step: 0
Training loss: 0.34399673342704773
Validation loss: 2.256310522556305

Epoch: 5| Step: 1
Training loss: 0.4167100787162781
Validation loss: 2.206880966822306

Epoch: 5| Step: 2
Training loss: 0.3552442193031311
Validation loss: 2.2269003689289093

Epoch: 5| Step: 3
Training loss: 0.3665412962436676
Validation loss: 2.2149614691734314

Epoch: 5| Step: 4
Training loss: 0.34814298152923584
Validation loss: 2.2097142140070596

Epoch: 5| Step: 5
Training loss: 0.2908095419406891
Validation loss: 2.257492075363795

Epoch: 5| Step: 6
Training loss: 0.6687400937080383
Validation loss: 2.2031427770853043

Epoch: 5| Step: 7
Training loss: 0.280302494764328
Validation loss: 2.30696469048659

Epoch: 5| Step: 8
Training loss: 0.4114132821559906
Validation loss: 2.2434504131476083

Epoch: 5| Step: 9
Training loss: 0.7439574599266052
Validation loss: 2.2665331115325293

Epoch: 5| Step: 10
Training loss: 0.3449762761592865
Validation loss: 2.2814691762129464

Epoch: 5| Step: 11
Training loss: 1.0993269681930542
Validation loss: 2.2333979854981103

Epoch: 344| Step: 0
Training loss: 0.666547417640686
Validation loss: 2.2398233165343604

Epoch: 5| Step: 1
Training loss: 0.43245887756347656
Validation loss: 2.246975287795067

Epoch: 5| Step: 2
Training loss: 0.27432218194007874
Validation loss: 2.2994863092899323

Epoch: 5| Step: 3
Training loss: 0.36275023221969604
Validation loss: 2.193137069543203

Epoch: 5| Step: 4
Training loss: 0.7764401435852051
Validation loss: 2.2742603023846946

Epoch: 5| Step: 5
Training loss: 0.3096025288105011
Validation loss: 2.288829172650973

Epoch: 5| Step: 6
Training loss: 0.36048704385757446
Validation loss: 2.2424096167087555

Epoch: 5| Step: 7
Training loss: 0.3991279602050781
Validation loss: 2.279241532087326

Epoch: 5| Step: 8
Training loss: 0.4430251121520996
Validation loss: 2.283734460671743

Epoch: 5| Step: 9
Training loss: 0.4534492492675781
Validation loss: 2.231685067216555

Epoch: 5| Step: 10
Training loss: 0.5294734835624695
Validation loss: 2.318079466621081

Epoch: 5| Step: 11
Training loss: 0.3380669355392456
Validation loss: 2.2639232873916626

Epoch: 345| Step: 0
Training loss: 0.45835620164871216
Validation loss: 2.2320543428262076

Epoch: 5| Step: 1
Training loss: 0.33779507875442505
Validation loss: 2.2042500724395118

Epoch: 5| Step: 2
Training loss: 0.2012976109981537
Validation loss: 2.2346597810586295

Epoch: 5| Step: 3
Training loss: 0.6378852725028992
Validation loss: 2.2502679526805878

Epoch: 5| Step: 4
Training loss: 0.6119478344917297
Validation loss: 2.244694322347641

Epoch: 5| Step: 5
Training loss: 0.35104912519454956
Validation loss: 2.2589370707670846

Epoch: 5| Step: 6
Training loss: 0.36382731795310974
Validation loss: 2.19425205886364

Epoch: 5| Step: 7
Training loss: 0.457794725894928
Validation loss: 2.2374192625284195

Epoch: 5| Step: 8
Training loss: 0.48046475648880005
Validation loss: 2.2459676464398703

Epoch: 5| Step: 9
Training loss: 0.25614404678344727
Validation loss: 2.207145189245542

Epoch: 5| Step: 10
Training loss: 0.32330888509750366
Validation loss: 2.2607242663701377

Epoch: 5| Step: 11
Training loss: 0.06482475996017456
Validation loss: 2.158501843611399

Epoch: 346| Step: 0
Training loss: 0.21482053399085999
Validation loss: 2.2086554219325385

Epoch: 5| Step: 1
Training loss: 0.4730193614959717
Validation loss: 2.2770111759503684

Epoch: 5| Step: 2
Training loss: 0.8351196050643921
Validation loss: 2.2005640168984733

Epoch: 5| Step: 3
Training loss: 0.2668890357017517
Validation loss: 2.174901773532232

Epoch: 5| Step: 4
Training loss: 0.31160181760787964
Validation loss: 2.230423410733541

Epoch: 5| Step: 5
Training loss: 0.44383811950683594
Validation loss: 2.255608802040418

Epoch: 5| Step: 6
Training loss: 0.4753715395927429
Validation loss: 2.2118495106697083

Epoch: 5| Step: 7
Training loss: 0.3245878517627716
Validation loss: 2.178766588370005

Epoch: 5| Step: 8
Training loss: 0.3940872550010681
Validation loss: 2.2529624501864114

Epoch: 5| Step: 9
Training loss: 0.4531298577785492
Validation loss: 2.2226932843526206

Epoch: 5| Step: 10
Training loss: 0.4446781277656555
Validation loss: 2.2225276827812195

Epoch: 5| Step: 11
Training loss: 0.11649680137634277
Validation loss: 2.236681878566742

Epoch: 347| Step: 0
Training loss: 0.3234206438064575
Validation loss: 2.2158698439598083

Epoch: 5| Step: 1
Training loss: 0.4849732518196106
Validation loss: 2.2401766578356423

Epoch: 5| Step: 2
Training loss: 0.8020597696304321
Validation loss: 2.2402407377958298

Epoch: 5| Step: 3
Training loss: 0.30606594681739807
Validation loss: 2.2373055269320807

Epoch: 5| Step: 4
Training loss: 0.3287932276725769
Validation loss: 2.27569842338562

Epoch: 5| Step: 5
Training loss: 0.32749873399734497
Validation loss: 2.2746796309947968

Epoch: 5| Step: 6
Training loss: 0.2449180781841278
Validation loss: 2.2313411931196847

Epoch: 5| Step: 7
Training loss: 0.48032432794570923
Validation loss: 2.2754358500242233

Epoch: 5| Step: 8
Training loss: 0.4299813210964203
Validation loss: 2.2151783605416617

Epoch: 5| Step: 9
Training loss: 0.43447035551071167
Validation loss: 2.2617917557557425

Epoch: 5| Step: 10
Training loss: 0.32711464166641235
Validation loss: 2.2896008690198264

Epoch: 5| Step: 11
Training loss: 0.1285954713821411
Validation loss: 2.2363548427820206

Epoch: 348| Step: 0
Training loss: 0.7388383150100708
Validation loss: 2.268726795911789

Epoch: 5| Step: 1
Training loss: 0.4127167761325836
Validation loss: 2.273323347171148

Epoch: 5| Step: 2
Training loss: 0.2597867548465729
Validation loss: 2.2578246891498566

Epoch: 5| Step: 3
Training loss: 0.6362412571907043
Validation loss: 2.278481602668762

Epoch: 5| Step: 4
Training loss: 0.3444257378578186
Validation loss: 2.2263861944278083

Epoch: 5| Step: 5
Training loss: 0.3597838282585144
Validation loss: 2.2536629686752954

Epoch: 5| Step: 6
Training loss: 0.37954455614089966
Validation loss: 2.2683557917674384

Epoch: 5| Step: 7
Training loss: 0.33302420377731323
Validation loss: 2.2544126411279044

Epoch: 5| Step: 8
Training loss: 0.28715911507606506
Validation loss: 2.2598490019639335

Epoch: 5| Step: 9
Training loss: 0.4209676682949066
Validation loss: 2.258718882997831

Epoch: 5| Step: 10
Training loss: 0.3954017460346222
Validation loss: 2.1911347011725106

Epoch: 5| Step: 11
Training loss: 0.307351291179657
Validation loss: 2.2312873949607215

Epoch: 349| Step: 0
Training loss: 0.4336240291595459
Validation loss: 2.251983697215716

Epoch: 5| Step: 1
Training loss: 0.6487895846366882
Validation loss: 2.233208785454432

Epoch: 5| Step: 2
Training loss: 0.4975358545780182
Validation loss: 2.2384618371725082

Epoch: 5| Step: 3
Training loss: 0.687583327293396
Validation loss: 2.261425569653511

Epoch: 5| Step: 4
Training loss: 0.3825947642326355
Validation loss: 2.2749747385581336

Epoch: 5| Step: 5
Training loss: 0.4112861752510071
Validation loss: 2.1941071351369223

Epoch: 5| Step: 6
Training loss: 0.4357234835624695
Validation loss: 2.2080420156319938

Epoch: 5| Step: 7
Training loss: 0.41228145360946655
Validation loss: 2.1982402404149375

Epoch: 5| Step: 8
Training loss: 0.3581240773200989
Validation loss: 2.2502251068751016

Epoch: 5| Step: 9
Training loss: 0.5885854959487915
Validation loss: 2.306934575239817

Epoch: 5| Step: 10
Training loss: 0.20701630413532257
Validation loss: 2.222510894139608

Epoch: 5| Step: 11
Training loss: 0.7821409702301025
Validation loss: 2.217823247114817

Epoch: 350| Step: 0
Training loss: 0.35087350010871887
Validation loss: 2.2704998701810837

Epoch: 5| Step: 1
Training loss: 0.41302698850631714
Validation loss: 2.239682445923487

Epoch: 5| Step: 2
Training loss: 0.3281349539756775
Validation loss: 2.249969333410263

Epoch: 5| Step: 3
Training loss: 0.40975674986839294
Validation loss: 2.2673460046450296

Epoch: 5| Step: 4
Training loss: 0.7911487817764282
Validation loss: 2.198669577638308

Epoch: 5| Step: 5
Training loss: 0.5978432297706604
Validation loss: 2.2323240488767624

Epoch: 5| Step: 6
Training loss: 0.35238033533096313
Validation loss: 2.2120555440584817

Epoch: 5| Step: 7
Training loss: 0.33386412262916565
Validation loss: 2.236462578177452

Epoch: 5| Step: 8
Training loss: 0.5148157477378845
Validation loss: 2.247965157032013

Epoch: 5| Step: 9
Training loss: 0.3514048159122467
Validation loss: 2.2767629524072013

Epoch: 5| Step: 10
Training loss: 0.29797711968421936
Validation loss: 2.25254953900973

Epoch: 5| Step: 11
Training loss: 0.3940669596195221
Validation loss: 2.221802850564321

Epoch: 351| Step: 0
Training loss: 0.3209153115749359
Validation loss: 2.2855827709039054

Epoch: 5| Step: 1
Training loss: 0.6424041986465454
Validation loss: 2.220516249537468

Epoch: 5| Step: 2
Training loss: 0.4470856785774231
Validation loss: 2.2242230574289956

Epoch: 5| Step: 3
Training loss: 0.48700398206710815
Validation loss: 2.258197605609894

Epoch: 5| Step: 4
Training loss: 0.2624547481536865
Validation loss: 2.273912101984024

Epoch: 5| Step: 5
Training loss: 0.3032790422439575
Validation loss: 2.309058984120687

Epoch: 5| Step: 6
Training loss: 0.3542853593826294
Validation loss: 2.2873595853646598

Epoch: 5| Step: 7
Training loss: 0.4065181612968445
Validation loss: 2.1973709613084793

Epoch: 5| Step: 8
Training loss: 0.4030144214630127
Validation loss: 2.2716031024853387

Epoch: 5| Step: 9
Training loss: 0.33917301893234253
Validation loss: 2.242777501543363

Epoch: 5| Step: 10
Training loss: 0.5990380048751831
Validation loss: 2.2644090255101523

Epoch: 5| Step: 11
Training loss: 0.37926021218299866
Validation loss: 2.2797792156537375

Epoch: 352| Step: 0
Training loss: 0.42702531814575195
Validation loss: 2.2327306220928826

Epoch: 5| Step: 1
Training loss: 0.8444064259529114
Validation loss: 2.2286278506120047

Epoch: 5| Step: 2
Training loss: 0.4934379458427429
Validation loss: 2.182539463043213

Epoch: 5| Step: 3
Training loss: 0.43554458022117615
Validation loss: 2.272457540035248

Epoch: 5| Step: 4
Training loss: 0.34568721055984497
Validation loss: 2.2394579499959946

Epoch: 5| Step: 5
Training loss: 0.2689078450202942
Validation loss: 2.2045149008433023

Epoch: 5| Step: 6
Training loss: 0.47286662459373474
Validation loss: 2.215886577963829

Epoch: 5| Step: 7
Training loss: 0.4549258351325989
Validation loss: 2.2513330032428107

Epoch: 5| Step: 8
Training loss: 0.5755617618560791
Validation loss: 2.214145908753077

Epoch: 5| Step: 9
Training loss: 0.45993486046791077
Validation loss: 2.210992674032847

Epoch: 5| Step: 10
Training loss: 0.2813558578491211
Validation loss: 2.2385697066783905

Epoch: 5| Step: 11
Training loss: 0.4317173957824707
Validation loss: 2.2322998344898224

Epoch: 353| Step: 0
Training loss: 0.31175750494003296
Validation loss: 2.2522727201382318

Epoch: 5| Step: 1
Training loss: 0.5374273657798767
Validation loss: 2.259549339612325

Epoch: 5| Step: 2
Training loss: 0.42525386810302734
Validation loss: 2.195399284362793

Epoch: 5| Step: 3
Training loss: 0.35233497619628906
Validation loss: 2.180912291010221

Epoch: 5| Step: 4
Training loss: 0.5224521160125732
Validation loss: 2.2420217394828796

Epoch: 5| Step: 5
Training loss: 0.2657683193683624
Validation loss: 2.2650769352912903

Epoch: 5| Step: 6
Training loss: 0.3038276135921478
Validation loss: 2.253211776415507

Epoch: 5| Step: 7
Training loss: 0.8423277139663696
Validation loss: 2.256788343191147

Epoch: 5| Step: 8
Training loss: 0.19310759007930756
Validation loss: 2.2458897829055786

Epoch: 5| Step: 9
Training loss: 0.36542826890945435
Validation loss: 2.2597964257001877

Epoch: 5| Step: 10
Training loss: 0.4719029366970062
Validation loss: 2.1994486451148987

Epoch: 5| Step: 11
Training loss: 0.34881699085235596
Validation loss: 2.2752949595451355

Epoch: 354| Step: 0
Training loss: 0.46785491704940796
Validation loss: 2.249921277165413

Epoch: 5| Step: 1
Training loss: 0.2957497239112854
Validation loss: 2.296855628490448

Epoch: 5| Step: 2
Training loss: 0.43459552526474
Validation loss: 2.278131107489268

Epoch: 5| Step: 3
Training loss: 0.7995672225952148
Validation loss: 2.304779683550199

Epoch: 5| Step: 4
Training loss: 0.23583778738975525
Validation loss: 2.23085854947567

Epoch: 5| Step: 5
Training loss: 0.3937009871006012
Validation loss: 2.253000338872274

Epoch: 5| Step: 6
Training loss: 0.4694441854953766
Validation loss: 2.270993635058403

Epoch: 5| Step: 7
Training loss: 0.23249545693397522
Validation loss: 2.250276356935501

Epoch: 5| Step: 8
Training loss: 0.40321841835975647
Validation loss: 2.2382356921831765

Epoch: 5| Step: 9
Training loss: 0.32900214195251465
Validation loss: 2.221940149863561

Epoch: 5| Step: 10
Training loss: 0.4199081063270569
Validation loss: 2.277653490503629

Epoch: 5| Step: 11
Training loss: 0.2304668426513672
Validation loss: 2.219415287176768

Epoch: 355| Step: 0
Training loss: 0.3479791581630707
Validation loss: 2.2418578962484994

Epoch: 5| Step: 1
Training loss: 0.6922129392623901
Validation loss: 2.2413738717635474

Epoch: 5| Step: 2
Training loss: 0.29130101203918457
Validation loss: 2.2225882609685264

Epoch: 5| Step: 3
Training loss: 0.5414443016052246
Validation loss: 2.2773705820242562

Epoch: 5| Step: 4
Training loss: 0.3474353849887848
Validation loss: 2.2286521146694818

Epoch: 5| Step: 5
Training loss: 0.45389634370803833
Validation loss: 2.2484861512978873

Epoch: 5| Step: 6
Training loss: 0.41153621673583984
Validation loss: 2.2485200812419257

Epoch: 5| Step: 7
Training loss: 0.38584867119789124
Validation loss: 2.2780577143033347

Epoch: 5| Step: 8
Training loss: 0.40983980894088745
Validation loss: 2.2733821471532187

Epoch: 5| Step: 9
Training loss: 0.22731900215148926
Validation loss: 2.233853538831075

Epoch: 5| Step: 10
Training loss: 0.3610427975654602
Validation loss: 2.28368212779363

Epoch: 5| Step: 11
Training loss: 0.13852348923683167
Validation loss: 2.213697378834089

Epoch: 356| Step: 0
Training loss: 0.337272047996521
Validation loss: 2.270644540588061

Epoch: 5| Step: 1
Training loss: 0.33822527527809143
Validation loss: 2.26997180779775

Epoch: 5| Step: 2
Training loss: 0.516985297203064
Validation loss: 2.228297919034958

Epoch: 5| Step: 3
Training loss: 0.18397775292396545
Validation loss: 2.2015860279401145

Epoch: 5| Step: 4
Training loss: 0.6634520292282104
Validation loss: 2.2969461480776467

Epoch: 5| Step: 5
Training loss: 0.39596450328826904
Validation loss: 2.272968888282776

Epoch: 5| Step: 6
Training loss: 0.32601940631866455
Validation loss: 2.1978758722543716

Epoch: 5| Step: 7
Training loss: 0.25495555996894836
Validation loss: 2.2448596407969794

Epoch: 5| Step: 8
Training loss: 0.3206297755241394
Validation loss: 2.280436486005783

Epoch: 5| Step: 9
Training loss: 0.20852451026439667
Validation loss: 2.2185132106145224

Epoch: 5| Step: 10
Training loss: 0.7383224368095398
Validation loss: 2.268759697675705

Epoch: 5| Step: 11
Training loss: 0.2690914273262024
Validation loss: 2.276085446278254

Epoch: 357| Step: 0
Training loss: 0.6615001559257507
Validation loss: 2.2484581073125205

Epoch: 5| Step: 1
Training loss: 0.48809799551963806
Validation loss: 2.2884297569592795

Epoch: 5| Step: 2
Training loss: 0.5428177714347839
Validation loss: 2.2712969978650412

Epoch: 5| Step: 3
Training loss: 0.4788394868373871
Validation loss: 2.2639837861061096

Epoch: 5| Step: 4
Training loss: 0.33862724900245667
Validation loss: 2.2399081587791443

Epoch: 5| Step: 5
Training loss: 0.2546904683113098
Validation loss: 2.2524444609880447

Epoch: 5| Step: 6
Training loss: 0.3578670918941498
Validation loss: 2.2861463775237403

Epoch: 5| Step: 7
Training loss: 0.47893673181533813
Validation loss: 2.2658820102612176

Epoch: 5| Step: 8
Training loss: 0.4961709976196289
Validation loss: 2.251816362142563

Epoch: 5| Step: 9
Training loss: 0.3792744278907776
Validation loss: 2.266474907596906

Epoch: 5| Step: 10
Training loss: 0.3159105181694031
Validation loss: 2.2154374519983926

Epoch: 5| Step: 11
Training loss: 0.5883210897445679
Validation loss: 2.2411045531431832

Epoch: 358| Step: 0
Training loss: 0.8939858675003052
Validation loss: 2.2673393239577613

Epoch: 5| Step: 1
Training loss: 0.8908029794692993
Validation loss: 2.2990124821662903

Epoch: 5| Step: 2
Training loss: 0.5204132199287415
Validation loss: 2.2645510335763297

Epoch: 5| Step: 3
Training loss: 0.6240404844284058
Validation loss: 2.2516975700855255

Epoch: 5| Step: 4
Training loss: 0.2528846263885498
Validation loss: 2.163175344467163

Epoch: 5| Step: 5
Training loss: 0.4908321499824524
Validation loss: 2.2637714048226676

Epoch: 5| Step: 6
Training loss: 0.35453128814697266
Validation loss: 2.256678288181623

Epoch: 5| Step: 7
Training loss: 0.4104016423225403
Validation loss: 2.259260614713033

Epoch: 5| Step: 8
Training loss: 0.43907204270362854
Validation loss: 2.3140850762526193

Epoch: 5| Step: 9
Training loss: 0.34484797716140747
Validation loss: 2.241234684983889

Epoch: 5| Step: 10
Training loss: 0.33817142248153687
Validation loss: 2.2954732129971185

Epoch: 5| Step: 11
Training loss: 0.2174782156944275
Validation loss: 2.2847903867562613

Epoch: 359| Step: 0
Training loss: 0.37868496775627136
Validation loss: 2.2764094372590384

Epoch: 5| Step: 1
Training loss: 0.4138079583644867
Validation loss: 2.2843872010707855

Epoch: 5| Step: 2
Training loss: 0.3145877420902252
Validation loss: 2.262642741203308

Epoch: 5| Step: 3
Training loss: 0.28463783860206604
Validation loss: 2.302539269129435

Epoch: 5| Step: 4
Training loss: 0.6046464443206787
Validation loss: 2.2815866569677987

Epoch: 5| Step: 5
Training loss: 0.44406452775001526
Validation loss: 2.299917240937551

Epoch: 5| Step: 6
Training loss: 0.6378551125526428
Validation loss: 2.342698256174723

Epoch: 5| Step: 7
Training loss: 0.45909518003463745
Validation loss: 2.2788624266783395

Epoch: 5| Step: 8
Training loss: 0.3908695578575134
Validation loss: 2.2581620613733926

Epoch: 5| Step: 9
Training loss: 0.37908703088760376
Validation loss: 2.285071760416031

Epoch: 5| Step: 10
Training loss: 0.36094895005226135
Validation loss: 2.2805865108966827

Epoch: 5| Step: 11
Training loss: 0.7590060234069824
Validation loss: 2.2545593976974487

Epoch: 360| Step: 0
Training loss: 0.48805418610572815
Validation loss: 2.2948056707779565

Epoch: 5| Step: 1
Training loss: 0.5498654842376709
Validation loss: 2.213174963990847

Epoch: 5| Step: 2
Training loss: 0.46398577094078064
Validation loss: 2.2378522704044976

Epoch: 5| Step: 3
Training loss: 0.4162357449531555
Validation loss: 2.248726636171341

Epoch: 5| Step: 4
Training loss: 0.45733100175857544
Validation loss: 2.213267167409261

Epoch: 5| Step: 5
Training loss: 0.3002271056175232
Validation loss: 2.205889195203781

Epoch: 5| Step: 6
Training loss: 0.4365207254886627
Validation loss: 2.2298568934202194

Epoch: 5| Step: 7
Training loss: 0.8729389905929565
Validation loss: 2.221316928664843

Epoch: 5| Step: 8
Training loss: 0.5087639689445496
Validation loss: 2.2523277352253595

Epoch: 5| Step: 9
Training loss: 0.6457754373550415
Validation loss: 2.229547450939814

Epoch: 5| Step: 10
Training loss: 0.3507576286792755
Validation loss: 2.245862677693367

Epoch: 5| Step: 11
Training loss: 0.5481202006340027
Validation loss: 2.188433960080147

Epoch: 361| Step: 0
Training loss: 0.8079990148544312
Validation loss: 2.18053545554479

Epoch: 5| Step: 1
Training loss: 0.396810919046402
Validation loss: 2.1812465637922287

Epoch: 5| Step: 2
Training loss: 0.4896776080131531
Validation loss: 2.2085106323162713

Epoch: 5| Step: 3
Training loss: 0.37671130895614624
Validation loss: 2.2275979816913605

Epoch: 5| Step: 4
Training loss: 0.500606894493103
Validation loss: 2.200806895891825

Epoch: 5| Step: 5
Training loss: 0.3114018440246582
Validation loss: 2.179749771952629

Epoch: 5| Step: 6
Training loss: 0.28369322419166565
Validation loss: 2.1880377928415933

Epoch: 5| Step: 7
Training loss: 0.3496577739715576
Validation loss: 2.2386241108179092

Epoch: 5| Step: 8
Training loss: 0.7663742303848267
Validation loss: 2.222785775860151

Epoch: 5| Step: 9
Training loss: 0.7220697402954102
Validation loss: 2.212656646966934

Epoch: 5| Step: 10
Training loss: 0.3333900272846222
Validation loss: 2.2075746655464172

Epoch: 5| Step: 11
Training loss: 0.14103549718856812
Validation loss: 2.1854559977849326

Epoch: 362| Step: 0
Training loss: 0.37715625762939453
Validation loss: 2.258629967768987

Epoch: 5| Step: 1
Training loss: 0.37363165616989136
Validation loss: 2.1796456227699914

Epoch: 5| Step: 2
Training loss: 0.38305121660232544
Validation loss: 2.2427762001752853

Epoch: 5| Step: 3
Training loss: 0.6364074349403381
Validation loss: 2.1687067250410714

Epoch: 5| Step: 4
Training loss: 0.39959946274757385
Validation loss: 2.2044807523489

Epoch: 5| Step: 5
Training loss: 0.7795765399932861
Validation loss: 2.2439176440238953

Epoch: 5| Step: 6
Training loss: 0.39754003286361694
Validation loss: 2.2445746262868247

Epoch: 5| Step: 7
Training loss: 0.24293211102485657
Validation loss: 2.2412059903144836

Epoch: 5| Step: 8
Training loss: 0.3922114372253418
Validation loss: 2.275540883342425

Epoch: 5| Step: 9
Training loss: 0.352851927280426
Validation loss: 2.1882910430431366

Epoch: 5| Step: 10
Training loss: 0.2858925461769104
Validation loss: 2.209453910589218

Epoch: 5| Step: 11
Training loss: 0.27411627769470215
Validation loss: 2.188918779293696

Epoch: 363| Step: 0
Training loss: 0.3038322329521179
Validation loss: 2.2282320459683738

Epoch: 5| Step: 1
Training loss: 0.5085055828094482
Validation loss: 2.2418218553066254

Epoch: 5| Step: 2
Training loss: 0.3841467499732971
Validation loss: 2.2289371540149054

Epoch: 5| Step: 3
Training loss: 0.18759974837303162
Validation loss: 2.2108856985966363

Epoch: 5| Step: 4
Training loss: 0.720728874206543
Validation loss: 2.2226393769184747

Epoch: 5| Step: 5
Training loss: 0.5608347654342651
Validation loss: 2.23717466990153

Epoch: 5| Step: 6
Training loss: 0.32158589363098145
Validation loss: 2.261761392156283

Epoch: 5| Step: 7
Training loss: 0.30932101607322693
Validation loss: 2.2524120608965554

Epoch: 5| Step: 8
Training loss: 0.4276277422904968
Validation loss: 2.251230443517367

Epoch: 5| Step: 9
Training loss: 0.3844459056854248
Validation loss: 2.1862817804018655

Epoch: 5| Step: 10
Training loss: 0.3020913898944855
Validation loss: 2.229992767175039

Epoch: 5| Step: 11
Training loss: 0.4332915246486664
Validation loss: 2.254832531015078

Epoch: 364| Step: 0
Training loss: 0.45198744535446167
Validation loss: 2.2046671956777573

Epoch: 5| Step: 1
Training loss: 0.39878785610198975
Validation loss: 2.187659894426664

Epoch: 5| Step: 2
Training loss: 0.5497623682022095
Validation loss: 2.2178152203559875

Epoch: 5| Step: 3
Training loss: 0.37377026677131653
Validation loss: 2.2077218989531198

Epoch: 5| Step: 4
Training loss: 0.1778842806816101
Validation loss: 2.264038383960724

Epoch: 5| Step: 5
Training loss: 0.23989251255989075
Validation loss: 2.192593311270078

Epoch: 5| Step: 6
Training loss: 0.39980751276016235
Validation loss: 2.2342402239640555

Epoch: 5| Step: 7
Training loss: 0.4938199520111084
Validation loss: 2.2456118762493134

Epoch: 5| Step: 8
Training loss: 0.29034119844436646
Validation loss: 2.2535897890726724

Epoch: 5| Step: 9
Training loss: 0.3199664354324341
Validation loss: 2.2646570752064386

Epoch: 5| Step: 10
Training loss: 0.7557622194290161
Validation loss: 2.326883633931478

Epoch: 5| Step: 11
Training loss: 0.1863178014755249
Validation loss: 2.212712119023005

Epoch: 365| Step: 0
Training loss: 0.5677837133407593
Validation loss: 2.2434798727432885

Epoch: 5| Step: 1
Training loss: 0.4094375669956207
Validation loss: 2.208348830540975

Epoch: 5| Step: 2
Training loss: 0.6578191518783569
Validation loss: 2.267653912305832

Epoch: 5| Step: 3
Training loss: 0.3247798979282379
Validation loss: 2.2598101596037545

Epoch: 5| Step: 4
Training loss: 0.4287162721157074
Validation loss: 2.2470502456029258

Epoch: 5| Step: 5
Training loss: 0.47826045751571655
Validation loss: 2.287924587726593

Epoch: 5| Step: 6
Training loss: 0.3067287504673004
Validation loss: 2.3179907302061715

Epoch: 5| Step: 7
Training loss: 0.36819639801979065
Validation loss: 2.305636093020439

Epoch: 5| Step: 8
Training loss: 0.35594430565834045
Validation loss: 2.284287542104721

Epoch: 5| Step: 9
Training loss: 0.4240688383579254
Validation loss: 2.2441316346327462

Epoch: 5| Step: 10
Training loss: 0.47797998785972595
Validation loss: 2.323568731546402

Epoch: 5| Step: 11
Training loss: 0.17230847477912903
Validation loss: 2.19119593501091

Epoch: 366| Step: 0
Training loss: 0.427468478679657
Validation loss: 2.296469201644262

Epoch: 5| Step: 1
Training loss: 0.29339170455932617
Validation loss: 2.2074243326981864

Epoch: 5| Step: 2
Training loss: 0.29247260093688965
Validation loss: 2.247746080160141

Epoch: 5| Step: 3
Training loss: 0.44205886125564575
Validation loss: 2.255232354005178

Epoch: 5| Step: 4
Training loss: 0.4984683096408844
Validation loss: 2.2345628092686334

Epoch: 5| Step: 5
Training loss: 0.5299954414367676
Validation loss: 2.2294781456391015

Epoch: 5| Step: 6
Training loss: 0.6387414336204529
Validation loss: 2.2509090999762216

Epoch: 5| Step: 7
Training loss: 0.26892656087875366
Validation loss: 2.2479805648326874

Epoch: 5| Step: 8
Training loss: 0.32189297676086426
Validation loss: 2.2684872299432755

Epoch: 5| Step: 9
Training loss: 0.32120662927627563
Validation loss: 2.2904732823371887

Epoch: 5| Step: 10
Training loss: 0.43564170598983765
Validation loss: 2.2190613398949304

Epoch: 5| Step: 11
Training loss: 0.16452911496162415
Validation loss: 2.2286585370699563

Epoch: 367| Step: 0
Training loss: 0.36142370104789734
Validation loss: 2.241672843694687

Epoch: 5| Step: 1
Training loss: 0.35730400681495667
Validation loss: 2.22639229396979

Epoch: 5| Step: 2
Training loss: 0.18584831058979034
Validation loss: 2.239112357298533

Epoch: 5| Step: 3
Training loss: 0.41389673948287964
Validation loss: 2.1880069971084595

Epoch: 5| Step: 4
Training loss: 0.8826729655265808
Validation loss: 2.2897291531165442

Epoch: 5| Step: 5
Training loss: 0.25835785269737244
Validation loss: 2.270326475302378

Epoch: 5| Step: 6
Training loss: 0.28528332710266113
Validation loss: 2.3060946613550186

Epoch: 5| Step: 7
Training loss: 0.39832398295402527
Validation loss: 2.2298947870731354

Epoch: 5| Step: 8
Training loss: 0.3249877095222473
Validation loss: 2.2134303003549576

Epoch: 5| Step: 9
Training loss: 0.4517289102077484
Validation loss: 2.2831940899292626

Epoch: 5| Step: 10
Training loss: 0.45468026399612427
Validation loss: 2.256833349665006

Epoch: 5| Step: 11
Training loss: 0.5662829875946045
Validation loss: 2.2532971998055777

Epoch: 368| Step: 0
Training loss: 0.28175243735313416
Validation loss: 2.2204826970895133

Epoch: 5| Step: 1
Training loss: 0.6113640069961548
Validation loss: 2.2839886049429574

Epoch: 5| Step: 2
Training loss: 0.2732639014720917
Validation loss: 2.230300376812617

Epoch: 5| Step: 3
Training loss: 0.5137576460838318
Validation loss: 2.245791564385096

Epoch: 5| Step: 4
Training loss: 0.2823638916015625
Validation loss: 2.2623791694641113

Epoch: 5| Step: 5
Training loss: 0.47306028008461
Validation loss: 2.2652419904867807

Epoch: 5| Step: 6
Training loss: 0.2648053467273712
Validation loss: 2.32815690835317

Epoch: 5| Step: 7
Training loss: 0.22943536937236786
Validation loss: 2.2752349376678467

Epoch: 5| Step: 8
Training loss: 0.5227965116500854
Validation loss: 2.291376903653145

Epoch: 5| Step: 9
Training loss: 0.34769201278686523
Validation loss: 2.3187719335158667

Epoch: 5| Step: 10
Training loss: 0.43184080719947815
Validation loss: 2.285065531730652

Epoch: 5| Step: 11
Training loss: 0.39988914132118225
Validation loss: 2.276551127433777

Epoch: 369| Step: 0
Training loss: 0.1734451949596405
Validation loss: 2.333273450533549

Epoch: 5| Step: 1
Training loss: 0.3662478029727936
Validation loss: 2.323914666970571

Epoch: 5| Step: 2
Training loss: 0.2185770571231842
Validation loss: 2.294587547580401

Epoch: 5| Step: 3
Training loss: 0.22729258239269257
Validation loss: 2.2954151133696237

Epoch: 5| Step: 4
Training loss: 0.5929832458496094
Validation loss: 2.3321086366971335

Epoch: 5| Step: 5
Training loss: 0.40987831354141235
Validation loss: 2.2699091335137687

Epoch: 5| Step: 6
Training loss: 0.32284390926361084
Validation loss: 2.280053600668907

Epoch: 5| Step: 7
Training loss: 0.274433434009552
Validation loss: 2.271477291981379

Epoch: 5| Step: 8
Training loss: 0.7528918385505676
Validation loss: 2.2533855537573495

Epoch: 5| Step: 9
Training loss: 0.5562943816184998
Validation loss: 2.2659111618995667

Epoch: 5| Step: 10
Training loss: 0.5786871314048767
Validation loss: 2.243925387660662

Epoch: 5| Step: 11
Training loss: 0.2128753662109375
Validation loss: 2.194885343313217

Epoch: 370| Step: 0
Training loss: 0.3966046869754791
Validation loss: 2.230248341957728

Epoch: 5| Step: 1
Training loss: 0.46953099966049194
Validation loss: 2.212527801593145

Epoch: 5| Step: 2
Training loss: 0.7835420370101929
Validation loss: 2.235563407341639

Epoch: 5| Step: 3
Training loss: 0.3034919798374176
Validation loss: 2.248179485400518

Epoch: 5| Step: 4
Training loss: 0.39223164319992065
Validation loss: 2.2107447932163873

Epoch: 5| Step: 5
Training loss: 0.288687139749527
Validation loss: 2.1744254728158317

Epoch: 5| Step: 6
Training loss: 0.3477107882499695
Validation loss: 2.2043486336867013

Epoch: 5| Step: 7
Training loss: 0.23734183609485626
Validation loss: 2.249975696206093

Epoch: 5| Step: 8
Training loss: 0.4273868501186371
Validation loss: 2.2016023894151053

Epoch: 5| Step: 9
Training loss: 0.18862232565879822
Validation loss: 2.2400650878747306

Epoch: 5| Step: 10
Training loss: 0.6072667241096497
Validation loss: 2.190349484483401

Epoch: 5| Step: 11
Training loss: 0.3529598116874695
Validation loss: 2.2192500034968057

Epoch: 371| Step: 0
Training loss: 0.29867491126060486
Validation loss: 2.307472681005796

Epoch: 5| Step: 1
Training loss: 0.24158236384391785
Validation loss: 2.2326836387316384

Epoch: 5| Step: 2
Training loss: 0.2431848794221878
Validation loss: 2.274119863907496

Epoch: 5| Step: 3
Training loss: 0.3955700099468231
Validation loss: 2.2308188478151956

Epoch: 5| Step: 4
Training loss: 0.5133283734321594
Validation loss: 2.213546405235926

Epoch: 5| Step: 5
Training loss: 0.29936760663986206
Validation loss: 2.235685388247172

Epoch: 5| Step: 6
Training loss: 0.5745850205421448
Validation loss: 2.210007165869077

Epoch: 5| Step: 7
Training loss: 0.3693845868110657
Validation loss: 2.242203583319982

Epoch: 5| Step: 8
Training loss: 0.29655879735946655
Validation loss: 2.236804281671842

Epoch: 5| Step: 9
Training loss: 0.361060231924057
Validation loss: 2.23575692375501

Epoch: 5| Step: 10
Training loss: 0.8791143298149109
Validation loss: 2.277937392393748

Epoch: 5| Step: 11
Training loss: 0.09247249364852905
Validation loss: 2.2274173945188522

Epoch: 372| Step: 0
Training loss: 0.3030853867530823
Validation loss: 2.3058048288027444

Epoch: 5| Step: 1
Training loss: 0.3538624346256256
Validation loss: 2.2467620174090066

Epoch: 5| Step: 2
Training loss: 0.4609505236148834
Validation loss: 2.2595618019501367

Epoch: 5| Step: 3
Training loss: 0.4850352704524994
Validation loss: 2.2817857464154563

Epoch: 5| Step: 4
Training loss: 0.3508588671684265
Validation loss: 2.29945903023084

Epoch: 5| Step: 5
Training loss: 0.7500523328781128
Validation loss: 2.2367385029792786

Epoch: 5| Step: 6
Training loss: 0.44240742921829224
Validation loss: 2.235241095225016

Epoch: 5| Step: 7
Training loss: 0.45864254236221313
Validation loss: 2.274439975619316

Epoch: 5| Step: 8
Training loss: 0.2537272274494171
Validation loss: 2.2566096484661102

Epoch: 5| Step: 9
Training loss: 0.23425821959972382
Validation loss: 2.1891173322995505

Epoch: 5| Step: 10
Training loss: 0.3674842119216919
Validation loss: 2.220251684387525

Epoch: 5| Step: 11
Training loss: 0.3251934051513672
Validation loss: 2.2858733038107553

Epoch: 373| Step: 0
Training loss: 0.25818198919296265
Validation loss: 2.2862963676452637

Epoch: 5| Step: 1
Training loss: 0.3548033833503723
Validation loss: 2.217662592728933

Epoch: 5| Step: 2
Training loss: 0.3216380476951599
Validation loss: 2.289089779059092

Epoch: 5| Step: 3
Training loss: 0.3499148488044739
Validation loss: 2.169788504640261

Epoch: 5| Step: 4
Training loss: 0.3831077218055725
Validation loss: 2.2240370313326516

Epoch: 5| Step: 5
Training loss: 0.4795260429382324
Validation loss: 2.1771117647488913

Epoch: 5| Step: 6
Training loss: 0.5430228114128113
Validation loss: 2.1871391137441

Epoch: 5| Step: 7
Training loss: 0.8304816484451294
Validation loss: 2.226994643608729

Epoch: 5| Step: 8
Training loss: 0.2612273097038269
Validation loss: 2.20341956615448

Epoch: 5| Step: 9
Training loss: 0.32743287086486816
Validation loss: 2.1741394251585007

Epoch: 5| Step: 10
Training loss: 0.4693789482116699
Validation loss: 2.2470108022292457

Epoch: 5| Step: 11
Training loss: 0.6117157936096191
Validation loss: 2.1865106572707496

Epoch: 374| Step: 0
Training loss: 0.302035391330719
Validation loss: 2.188191736737887

Epoch: 5| Step: 1
Training loss: 0.3783283233642578
Validation loss: 2.228007127841314

Epoch: 5| Step: 2
Training loss: 0.31946831941604614
Validation loss: 2.1847023963928223

Epoch: 5| Step: 3
Training loss: 0.33693739771842957
Validation loss: 2.213880648215612

Epoch: 5| Step: 4
Training loss: 0.4401056170463562
Validation loss: 2.2246577938397727

Epoch: 5| Step: 5
Training loss: 0.376811683177948
Validation loss: 2.193707043925921

Epoch: 5| Step: 6
Training loss: 0.7610381841659546
Validation loss: 2.157876660426458

Epoch: 5| Step: 7
Training loss: 0.3867495059967041
Validation loss: 2.1968962450822196

Epoch: 5| Step: 8
Training loss: 0.3704424798488617
Validation loss: 2.2100186298290887

Epoch: 5| Step: 9
Training loss: 0.2997515797615051
Validation loss: 2.2147954404354095

Epoch: 5| Step: 10
Training loss: 0.1618189513683319
Validation loss: 2.2538097947835922

Epoch: 5| Step: 11
Training loss: 0.6966935396194458
Validation loss: 2.247359792391459

Epoch: 375| Step: 0
Training loss: 0.25226011872291565
Validation loss: 2.2671643495559692

Epoch: 5| Step: 1
Training loss: 0.44679245352745056
Validation loss: 2.2358782092730203

Epoch: 5| Step: 2
Training loss: 0.5097790956497192
Validation loss: 2.2540981272856393

Epoch: 5| Step: 3
Training loss: 0.6183183789253235
Validation loss: 2.2507684926191964

Epoch: 5| Step: 4
Training loss: 0.24222281575202942
Validation loss: 2.240372583270073

Epoch: 5| Step: 5
Training loss: 0.6965452432632446
Validation loss: 2.246795246998469

Epoch: 5| Step: 6
Training loss: 0.32791709899902344
Validation loss: 2.219566727677981

Epoch: 5| Step: 7
Training loss: 0.3026654124259949
Validation loss: 2.249270041783651

Epoch: 5| Step: 8
Training loss: 0.33173638582229614
Validation loss: 2.186277002096176

Epoch: 5| Step: 9
Training loss: 0.3381989002227783
Validation loss: 2.2495558510224023

Epoch: 5| Step: 10
Training loss: 0.19374598562717438
Validation loss: 2.269913842280706

Epoch: 5| Step: 11
Training loss: 0.42203855514526367
Validation loss: 2.213137060403824

Epoch: 376| Step: 0
Training loss: 0.34831124544143677
Validation loss: 2.22099876900514

Epoch: 5| Step: 1
Training loss: 0.8068255186080933
Validation loss: 2.1931649297475815

Epoch: 5| Step: 2
Training loss: 0.2088325023651123
Validation loss: 2.194281945625941

Epoch: 5| Step: 3
Training loss: 0.4767235815525055
Validation loss: 2.226625149448713

Epoch: 5| Step: 4
Training loss: 0.4523748755455017
Validation loss: 2.2086242039998374

Epoch: 5| Step: 5
Training loss: 0.30699336528778076
Validation loss: 2.1979831804831824

Epoch: 5| Step: 6
Training loss: 0.39460834860801697
Validation loss: 2.1821889877319336

Epoch: 5| Step: 7
Training loss: 0.43029284477233887
Validation loss: 2.194947903354963

Epoch: 5| Step: 8
Training loss: 0.421700656414032
Validation loss: 2.2024660954872766

Epoch: 5| Step: 9
Training loss: 0.37690025568008423
Validation loss: 2.2475277930498123

Epoch: 5| Step: 10
Training loss: 0.33801090717315674
Validation loss: 2.192497874299685

Epoch: 5| Step: 11
Training loss: 0.9395168423652649
Validation loss: 2.2658847918113074

Epoch: 377| Step: 0
Training loss: 0.3454773724079132
Validation loss: 2.2336899787187576

Epoch: 5| Step: 1
Training loss: 0.4399294853210449
Validation loss: 2.1966303884983063

Epoch: 5| Step: 2
Training loss: 0.3481294512748718
Validation loss: 2.2460734446843467

Epoch: 5| Step: 3
Training loss: 0.5619669556617737
Validation loss: 2.1905158360799155

Epoch: 5| Step: 4
Training loss: 0.2054777890443802
Validation loss: 2.2325522700945535

Epoch: 5| Step: 5
Training loss: 0.5204102993011475
Validation loss: 2.3261069854100547

Epoch: 5| Step: 6
Training loss: 0.23843398690223694
Validation loss: 2.2238669097423553

Epoch: 5| Step: 7
Training loss: 0.3844655156135559
Validation loss: 2.220609446366628

Epoch: 5| Step: 8
Training loss: 0.27566009759902954
Validation loss: 2.2278605699539185

Epoch: 5| Step: 9
Training loss: 0.3739446699619293
Validation loss: 2.2346497227748237

Epoch: 5| Step: 10
Training loss: 0.45694050192832947
Validation loss: 2.23069799443086

Epoch: 5| Step: 11
Training loss: 0.3342515230178833
Validation loss: 2.2503485679626465

Epoch: 378| Step: 0
Training loss: 0.45961350202560425
Validation loss: 2.27724955479304

Epoch: 5| Step: 1
Training loss: 0.30618759989738464
Validation loss: 2.2249165972073874

Epoch: 5| Step: 2
Training loss: 0.31979796290397644
Validation loss: 2.241806169350942

Epoch: 5| Step: 3
Training loss: 0.3184222877025604
Validation loss: 2.240842282772064

Epoch: 5| Step: 4
Training loss: 0.2292097806930542
Validation loss: 2.2317512333393097

Epoch: 5| Step: 5
Training loss: 0.34044286608695984
Validation loss: 2.2685063978036246

Epoch: 5| Step: 6
Training loss: 0.47890233993530273
Validation loss: 2.2499257822831473

Epoch: 5| Step: 7
Training loss: 0.286405086517334
Validation loss: 2.238187000155449

Epoch: 5| Step: 8
Training loss: 0.2935545742511749
Validation loss: 2.223070984085401

Epoch: 5| Step: 9
Training loss: 0.3816252052783966
Validation loss: 2.2344700545072556

Epoch: 5| Step: 10
Training loss: 0.7762080430984497
Validation loss: 2.251267820596695

Epoch: 5| Step: 11
Training loss: 0.42512649297714233
Validation loss: 2.249513934055964

Epoch: 379| Step: 0
Training loss: 0.36861100792884827
Validation loss: 2.2903816302617392

Epoch: 5| Step: 1
Training loss: 0.2884266972541809
Validation loss: 2.2395057678222656

Epoch: 5| Step: 2
Training loss: 0.3974485397338867
Validation loss: 2.265401855111122

Epoch: 5| Step: 3
Training loss: 0.4143168032169342
Validation loss: 2.2984318484862647

Epoch: 5| Step: 4
Training loss: 0.3754348158836365
Validation loss: 2.2254885087410607

Epoch: 5| Step: 5
Training loss: 0.7001708745956421
Validation loss: 2.195396547516187

Epoch: 5| Step: 6
Training loss: 0.42819294333457947
Validation loss: 2.2183449417352676

Epoch: 5| Step: 7
Training loss: 0.293544739484787
Validation loss: 2.2668659587701163

Epoch: 5| Step: 8
Training loss: 0.2841072678565979
Validation loss: 2.2791366378466287

Epoch: 5| Step: 9
Training loss: 0.3864062428474426
Validation loss: 2.2833345035711923

Epoch: 5| Step: 10
Training loss: 0.44897574186325073
Validation loss: 2.2474410384893417

Epoch: 5| Step: 11
Training loss: 0.31305021047592163
Validation loss: 2.233853206038475

Epoch: 380| Step: 0
Training loss: 0.3519560694694519
Validation loss: 2.274221877257029

Epoch: 5| Step: 1
Training loss: 0.5118420720100403
Validation loss: 2.249908854564031

Epoch: 5| Step: 2
Training loss: 0.3675171136856079
Validation loss: 2.253945996363958

Epoch: 5| Step: 3
Training loss: 0.3465121388435364
Validation loss: 2.2673284858465195

Epoch: 5| Step: 4
Training loss: 0.23982460796833038
Validation loss: 2.283861647049586

Epoch: 5| Step: 5
Training loss: 0.46962928771972656
Validation loss: 2.230661223332087

Epoch: 5| Step: 6
Training loss: 0.39685821533203125
Validation loss: 2.2528324524561563

Epoch: 5| Step: 7
Training loss: 0.3396512269973755
Validation loss: 2.2786396741867065

Epoch: 5| Step: 8
Training loss: 0.3225035071372986
Validation loss: 2.218614881237348

Epoch: 5| Step: 9
Training loss: 0.30625855922698975
Validation loss: 2.2068841407696405

Epoch: 5| Step: 10
Training loss: 0.7275469899177551
Validation loss: 2.2498775323232016

Epoch: 5| Step: 11
Training loss: 0.2844330668449402
Validation loss: 2.2864097505807877

Epoch: 381| Step: 0
Training loss: 0.29423069953918457
Validation loss: 2.2512892484664917

Epoch: 5| Step: 1
Training loss: 0.39972490072250366
Validation loss: 2.273968572417895

Epoch: 5| Step: 2
Training loss: 0.30860766768455505
Validation loss: 2.2652492076158524

Epoch: 5| Step: 3
Training loss: 0.32635965943336487
Validation loss: 2.228924890359243

Epoch: 5| Step: 4
Training loss: 0.5867682099342346
Validation loss: 2.269464502731959

Epoch: 5| Step: 5
Training loss: 0.3947528600692749
Validation loss: 2.307587683200836

Epoch: 5| Step: 6
Training loss: 0.24815097451210022
Validation loss: 2.2562137643496194

Epoch: 5| Step: 7
Training loss: 0.42733192443847656
Validation loss: 2.2271729558706284

Epoch: 5| Step: 8
Training loss: 0.3358888626098633
Validation loss: 2.258939206600189

Epoch: 5| Step: 9
Training loss: 0.5330079793930054
Validation loss: 2.2214313248793283

Epoch: 5| Step: 10
Training loss: 0.21169717609882355
Validation loss: 2.1868412693341575

Epoch: 5| Step: 11
Training loss: 0.6328468918800354
Validation loss: 2.2416590452194214

Epoch: 382| Step: 0
Training loss: 0.5579367876052856
Validation loss: 2.265915254751841

Epoch: 5| Step: 1
Training loss: 0.3825322985649109
Validation loss: 2.236492152015368

Epoch: 5| Step: 2
Training loss: 0.3737412393093109
Validation loss: 2.2324274679025016

Epoch: 5| Step: 3
Training loss: 0.40155696868896484
Validation loss: 2.259297107656797

Epoch: 5| Step: 4
Training loss: 0.28396040201187134
Validation loss: 2.2711293598016105

Epoch: 5| Step: 5
Training loss: 0.3207707703113556
Validation loss: 2.2186182737350464

Epoch: 5| Step: 6
Training loss: 0.6856932640075684
Validation loss: 2.2916501263777413

Epoch: 5| Step: 7
Training loss: 0.4108774662017822
Validation loss: 2.2357834776242576

Epoch: 5| Step: 8
Training loss: 0.5032407641410828
Validation loss: 2.2700533966223397

Epoch: 5| Step: 9
Training loss: 0.2899029552936554
Validation loss: 2.2852984964847565

Epoch: 5| Step: 10
Training loss: 0.542523980140686
Validation loss: 2.2492308964331946

Epoch: 5| Step: 11
Training loss: 0.2995119094848633
Validation loss: 2.2513692478338876

Epoch: 383| Step: 0
Training loss: 0.26424774527549744
Validation loss: 2.207387680808703

Epoch: 5| Step: 1
Training loss: 0.50330650806427
Validation loss: 2.229934295018514

Epoch: 5| Step: 2
Training loss: 0.5155917406082153
Validation loss: 2.2305204768975577

Epoch: 5| Step: 3
Training loss: 0.768248438835144
Validation loss: 2.2150548547506332

Epoch: 5| Step: 4
Training loss: 0.4180062711238861
Validation loss: 2.2588076243797937

Epoch: 5| Step: 5
Training loss: 0.328804075717926
Validation loss: 2.215435971816381

Epoch: 5| Step: 6
Training loss: 0.40588584542274475
Validation loss: 2.238881846268972

Epoch: 5| Step: 7
Training loss: 0.31497713923454285
Validation loss: 2.233202278614044

Epoch: 5| Step: 8
Training loss: 0.34494683146476746
Validation loss: 2.2855559438467026

Epoch: 5| Step: 9
Training loss: 0.5239256620407104
Validation loss: 2.2447682668765387

Epoch: 5| Step: 10
Training loss: 0.24146047234535217
Validation loss: 2.2033504794041314

Epoch: 5| Step: 11
Training loss: 0.4064440131187439
Validation loss: 2.190477639436722

Epoch: 384| Step: 0
Training loss: 0.5005542039871216
Validation loss: 2.2343635161717734

Epoch: 5| Step: 1
Training loss: 0.4526854455471039
Validation loss: 2.1685740699370704

Epoch: 5| Step: 2
Training loss: 0.5029156804084778
Validation loss: 2.2462523182233176

Epoch: 5| Step: 3
Training loss: 0.2775994539260864
Validation loss: 2.2052401999632516

Epoch: 5| Step: 4
Training loss: 0.4307176470756531
Validation loss: 2.2177134255568185

Epoch: 5| Step: 5
Training loss: 0.31083056330680847
Validation loss: 2.2276489436626434

Epoch: 5| Step: 6
Training loss: 0.24658679962158203
Validation loss: 2.2526831378539405

Epoch: 5| Step: 7
Training loss: 0.6513930559158325
Validation loss: 2.1944317469994226

Epoch: 5| Step: 8
Training loss: 0.38044485449790955
Validation loss: 2.2834321161111197

Epoch: 5| Step: 9
Training loss: 0.2606912851333618
Validation loss: 2.2047923455635705

Epoch: 5| Step: 10
Training loss: 0.4077828526496887
Validation loss: 2.2171789755423865

Epoch: 5| Step: 11
Training loss: 0.37566056847572327
Validation loss: 2.2686804036299386

Epoch: 385| Step: 0
Training loss: 0.25982800126075745
Validation loss: 2.224281261364619

Epoch: 5| Step: 1
Training loss: 0.3864593207836151
Validation loss: 2.286643440524737

Epoch: 5| Step: 2
Training loss: 0.39565980434417725
Validation loss: 2.163728872934977

Epoch: 5| Step: 3
Training loss: 0.22571761906147003
Validation loss: 2.199546068906784

Epoch: 5| Step: 4
Training loss: 0.3972982168197632
Validation loss: 2.2121633986632028

Epoch: 5| Step: 5
Training loss: 0.2677861452102661
Validation loss: 2.2332542538642883

Epoch: 5| Step: 6
Training loss: 0.32146692276000977
Validation loss: 2.1695615301529565

Epoch: 5| Step: 7
Training loss: 0.7495473027229309
Validation loss: 2.2930250763893127

Epoch: 5| Step: 8
Training loss: 0.241784006357193
Validation loss: 2.1905726293722787

Epoch: 5| Step: 9
Training loss: 0.32151541113853455
Validation loss: 2.20396522184213

Epoch: 5| Step: 10
Training loss: 0.6472973823547363
Validation loss: 2.170482859015465

Epoch: 5| Step: 11
Training loss: 0.6481852531433105
Validation loss: 2.1499377389748893

Epoch: 386| Step: 0
Training loss: 0.4837161600589752
Validation loss: 2.175194094578425

Epoch: 5| Step: 1
Training loss: 0.3496132493019104
Validation loss: 2.230154722929001

Epoch: 5| Step: 2
Training loss: 0.42811718583106995
Validation loss: 2.2026419192552567

Epoch: 5| Step: 3
Training loss: 0.5001422166824341
Validation loss: 2.1837962170441947

Epoch: 5| Step: 4
Training loss: 0.39319249987602234
Validation loss: 2.180503303805987

Epoch: 5| Step: 5
Training loss: 0.46325159072875977
Validation loss: 2.2200949986775718

Epoch: 5| Step: 6
Training loss: 0.41618409752845764
Validation loss: 2.2289208422104516

Epoch: 5| Step: 7
Training loss: 0.707897961139679
Validation loss: 2.212087353070577

Epoch: 5| Step: 8
Training loss: 0.4735621511936188
Validation loss: 2.220536639293035

Epoch: 5| Step: 9
Training loss: 0.34965333342552185
Validation loss: 2.231122374534607

Epoch: 5| Step: 10
Training loss: 0.32629474997520447
Validation loss: 2.271575023730596

Epoch: 5| Step: 11
Training loss: 0.3549240827560425
Validation loss: 2.2438808977603912

Epoch: 387| Step: 0
Training loss: 0.7310744524002075
Validation loss: 2.2607934375603995

Epoch: 5| Step: 1
Training loss: 0.2841946482658386
Validation loss: 2.225629210472107

Epoch: 5| Step: 2
Training loss: 0.5278593897819519
Validation loss: 2.2923254867394767

Epoch: 5| Step: 3
Training loss: 0.22313442826271057
Validation loss: 2.233502378066381

Epoch: 5| Step: 4
Training loss: 0.3652023375034332
Validation loss: 2.2429072757562003

Epoch: 5| Step: 5
Training loss: 0.39149388670921326
Validation loss: 2.244453797737757

Epoch: 5| Step: 6
Training loss: 0.5086764097213745
Validation loss: 2.23552372554938

Epoch: 5| Step: 7
Training loss: 0.23446059226989746
Validation loss: 2.20765982568264

Epoch: 5| Step: 8
Training loss: 0.34671610593795776
Validation loss: 2.241465156277021

Epoch: 5| Step: 9
Training loss: 0.30575504899024963
Validation loss: 2.2779662360747657

Epoch: 5| Step: 10
Training loss: 0.449598491191864
Validation loss: 2.268999998768171

Epoch: 5| Step: 11
Training loss: 0.18127310276031494
Validation loss: 2.2682627787192664

Epoch: 388| Step: 0
Training loss: 0.320012629032135
Validation loss: 2.2586961537599564

Epoch: 5| Step: 1
Training loss: 0.4844488203525543
Validation loss: 2.276843766371409

Epoch: 5| Step: 2
Training loss: 0.3352118134498596
Validation loss: 2.3190028071403503

Epoch: 5| Step: 3
Training loss: 0.6938600540161133
Validation loss: 2.2167742252349854

Epoch: 5| Step: 4
Training loss: 0.42085427045822144
Validation loss: 2.3005135903755822

Epoch: 5| Step: 5
Training loss: 0.42776036262512207
Validation loss: 2.2445054848988852

Epoch: 5| Step: 6
Training loss: 0.40527352690696716
Validation loss: 2.2460333108901978

Epoch: 5| Step: 7
Training loss: 0.2471572905778885
Validation loss: 2.269758924841881

Epoch: 5| Step: 8
Training loss: 0.368733286857605
Validation loss: 2.2862893690665564

Epoch: 5| Step: 9
Training loss: 0.4594368040561676
Validation loss: 2.2475570936997733

Epoch: 5| Step: 10
Training loss: 0.203710675239563
Validation loss: 2.275838777422905

Epoch: 5| Step: 11
Training loss: 0.3328981399536133
Validation loss: 2.20437557498614

Epoch: 389| Step: 0
Training loss: 0.190755233168602
Validation loss: 2.2732761104901633

Epoch: 5| Step: 1
Training loss: 0.2979186177253723
Validation loss: 2.2223075528939567

Epoch: 5| Step: 2
Training loss: 0.4392909109592438
Validation loss: 2.1888286968072257

Epoch: 5| Step: 3
Training loss: 0.24413521587848663
Validation loss: 2.2094111889600754

Epoch: 5| Step: 4
Training loss: 0.4707213342189789
Validation loss: 2.3048194547494254

Epoch: 5| Step: 5
Training loss: 0.24176688492298126
Validation loss: 2.2416301369667053

Epoch: 5| Step: 6
Training loss: 0.7815171480178833
Validation loss: 2.2607366840044656

Epoch: 5| Step: 7
Training loss: 0.40692877769470215
Validation loss: 2.2701328148444495

Epoch: 5| Step: 8
Training loss: 0.2837570905685425
Validation loss: 2.306360940138499

Epoch: 5| Step: 9
Training loss: 0.5289661884307861
Validation loss: 2.2819651861985526

Epoch: 5| Step: 10
Training loss: 0.4105990529060364
Validation loss: 2.2512047787507377

Epoch: 5| Step: 11
Training loss: 0.22764670848846436
Validation loss: 2.2842403948307037

Epoch: 390| Step: 0
Training loss: 0.7106372117996216
Validation loss: 2.286723921696345

Epoch: 5| Step: 1
Training loss: 0.2703436017036438
Validation loss: 2.2798459579547248

Epoch: 5| Step: 2
Training loss: 0.3695998787879944
Validation loss: 2.2687971790631614

Epoch: 5| Step: 3
Training loss: 0.38073673844337463
Validation loss: 2.2889561553796134

Epoch: 5| Step: 4
Training loss: 0.48526081442832947
Validation loss: 2.281246761480967

Epoch: 5| Step: 5
Training loss: 0.3012251853942871
Validation loss: 2.3024443686008453

Epoch: 5| Step: 6
Training loss: 0.3728489875793457
Validation loss: 2.237075462937355

Epoch: 5| Step: 7
Training loss: 0.2653281092643738
Validation loss: 2.256695876518885

Epoch: 5| Step: 8
Training loss: 0.5217790603637695
Validation loss: 2.258810579776764

Epoch: 5| Step: 9
Training loss: 0.279093861579895
Validation loss: 2.2996558099985123

Epoch: 5| Step: 10
Training loss: 0.3877348303794861
Validation loss: 2.2585297922293344

Epoch: 5| Step: 11
Training loss: 0.6994046568870544
Validation loss: 2.22727370262146

Epoch: 391| Step: 0
Training loss: 0.6296210885047913
Validation loss: 2.232785334189733

Epoch: 5| Step: 1
Training loss: 0.3970068395137787
Validation loss: 2.222277730703354

Epoch: 5| Step: 2
Training loss: 0.2859500050544739
Validation loss: 2.241533488035202

Epoch: 5| Step: 3
Training loss: 0.4079288840293884
Validation loss: 2.245902717113495

Epoch: 5| Step: 4
Training loss: 0.4081973135471344
Validation loss: 2.2709281146526337

Epoch: 5| Step: 5
Training loss: 0.4577775001525879
Validation loss: 2.235095332066218

Epoch: 5| Step: 6
Training loss: 0.353806734085083
Validation loss: 2.2394104401270547

Epoch: 5| Step: 7
Training loss: 0.4520607888698578
Validation loss: 2.2629141310850778

Epoch: 5| Step: 8
Training loss: 0.6017683744430542
Validation loss: 2.171764776110649

Epoch: 5| Step: 9
Training loss: 0.3116476535797119
Validation loss: 2.228888730208079

Epoch: 5| Step: 10
Training loss: 0.3144891858100891
Validation loss: 2.2543895095586777

Epoch: 5| Step: 11
Training loss: 0.2467402219772339
Validation loss: 2.1998837888240814

Epoch: 392| Step: 0
Training loss: 0.42458218336105347
Validation loss: 2.2652190029621124

Epoch: 5| Step: 1
Training loss: 0.35454511642456055
Validation loss: 2.224559153119723

Epoch: 5| Step: 2
Training loss: 0.4487292766571045
Validation loss: 2.190288722515106

Epoch: 5| Step: 3
Training loss: 0.46820497512817383
Validation loss: 2.241530100504557

Epoch: 5| Step: 4
Training loss: 0.3841095566749573
Validation loss: 2.252086490392685

Epoch: 5| Step: 5
Training loss: 0.5343167185783386
Validation loss: 2.235443423191706

Epoch: 5| Step: 6
Training loss: 0.4193374216556549
Validation loss: 2.233562340339025

Epoch: 5| Step: 7
Training loss: 0.31508389115333557
Validation loss: 2.245897670586904

Epoch: 5| Step: 8
Training loss: 0.7207748889923096
Validation loss: 2.2224500129620233

Epoch: 5| Step: 9
Training loss: 0.3188475966453552
Validation loss: 2.19009101887544

Epoch: 5| Step: 10
Training loss: 0.3611408770084381
Validation loss: 2.258227954308192

Epoch: 5| Step: 11
Training loss: 0.3269237279891968
Validation loss: 2.2920943746964135

Epoch: 393| Step: 0
Training loss: 0.33033567667007446
Validation loss: 2.268201837937037

Epoch: 5| Step: 1
Training loss: 0.4436877369880676
Validation loss: 2.2735124230384827

Epoch: 5| Step: 2
Training loss: 0.40174055099487305
Validation loss: 2.2458565831184387

Epoch: 5| Step: 3
Training loss: 0.28962889313697815
Validation loss: 2.3201437443494797

Epoch: 5| Step: 4
Training loss: 0.4454389214515686
Validation loss: 2.238429998358091

Epoch: 5| Step: 5
Training loss: 0.6162651181221008
Validation loss: 2.2508647541205087

Epoch: 5| Step: 6
Training loss: 0.2284708023071289
Validation loss: 2.2498239080111184

Epoch: 5| Step: 7
Training loss: 0.596790611743927
Validation loss: 2.2063982784748077

Epoch: 5| Step: 8
Training loss: 0.45707640051841736
Validation loss: 2.2461641828219094

Epoch: 5| Step: 9
Training loss: 0.26664501428604126
Validation loss: 2.2396994531154633

Epoch: 5| Step: 10
Training loss: 0.3046704828739166
Validation loss: 2.2506902317206063

Epoch: 5| Step: 11
Training loss: 0.4491631090641022
Validation loss: 2.2271710385878882

Epoch: 394| Step: 0
Training loss: 0.20712116360664368
Validation loss: 2.24865785241127

Epoch: 5| Step: 1
Training loss: 0.27196383476257324
Validation loss: 2.209780732790629

Epoch: 5| Step: 2
Training loss: 0.3263298273086548
Validation loss: 2.257096360127131

Epoch: 5| Step: 3
Training loss: 0.40823596715927124
Validation loss: 2.286023994286855

Epoch: 5| Step: 4
Training loss: 0.1954091638326645
Validation loss: 2.273315558830897

Epoch: 5| Step: 5
Training loss: 0.4998719096183777
Validation loss: 2.2427963415781655

Epoch: 5| Step: 6
Training loss: 0.258490651845932
Validation loss: 2.2351032545169196

Epoch: 5| Step: 7
Training loss: 0.4719604551792145
Validation loss: 2.282573699951172

Epoch: 5| Step: 8
Training loss: 0.38046303391456604
Validation loss: 2.165649880965551

Epoch: 5| Step: 9
Training loss: 0.2295502871274948
Validation loss: 2.2647350231806436

Epoch: 5| Step: 10
Training loss: 0.2236550748348236
Validation loss: 2.2904238551855087

Epoch: 5| Step: 11
Training loss: 2.039607524871826
Validation loss: 2.237902119755745

Epoch: 395| Step: 0
Training loss: 0.4229273796081543
Validation loss: 2.2756974399089813

Epoch: 5| Step: 1
Training loss: 0.68578040599823
Validation loss: 2.2256425420443215

Epoch: 5| Step: 2
Training loss: 0.47593170404434204
Validation loss: 2.254287670056025

Epoch: 5| Step: 3
Training loss: 0.34684786200523376
Validation loss: 2.226977696021398

Epoch: 5| Step: 4
Training loss: 0.23340480029582977
Validation loss: 2.301881730556488

Epoch: 5| Step: 5
Training loss: 0.4488467574119568
Validation loss: 2.263397733370463

Epoch: 5| Step: 6
Training loss: 0.3642636239528656
Validation loss: 2.29278797407945

Epoch: 5| Step: 7
Training loss: 0.37166187167167664
Validation loss: 2.2652647693951926

Epoch: 5| Step: 8
Training loss: 0.2671390771865845
Validation loss: 2.22446908056736

Epoch: 5| Step: 9
Training loss: 0.301792174577713
Validation loss: 2.274918794631958

Epoch: 5| Step: 10
Training loss: 0.3221086263656616
Validation loss: 2.3012521068255105

Epoch: 5| Step: 11
Training loss: 0.25140082836151123
Validation loss: 2.3077576756477356

Epoch: 396| Step: 0
Training loss: 0.4422244131565094
Validation loss: 2.2735803524653115

Epoch: 5| Step: 1
Training loss: 0.36959463357925415
Validation loss: 2.2939243565003076

Epoch: 5| Step: 2
Training loss: 0.41837137937545776
Validation loss: 2.293186773856481

Epoch: 5| Step: 3
Training loss: 0.2783828377723694
Validation loss: 2.285424768924713

Epoch: 5| Step: 4
Training loss: 0.29247623682022095
Validation loss: 2.2479146321614585

Epoch: 5| Step: 5
Training loss: 0.5192092657089233
Validation loss: 2.246345301469167

Epoch: 5| Step: 6
Training loss: 0.5097898244857788
Validation loss: 2.2517974078655243

Epoch: 5| Step: 7
Training loss: 0.7280747890472412
Validation loss: 2.218170255422592

Epoch: 5| Step: 8
Training loss: 0.32491081953048706
Validation loss: 2.279070963462194

Epoch: 5| Step: 9
Training loss: 0.34256696701049805
Validation loss: 2.2194707741340003

Epoch: 5| Step: 10
Training loss: 0.364960640668869
Validation loss: 2.213179071744283

Epoch: 5| Step: 11
Training loss: 0.33759188652038574
Validation loss: 2.250203569730123

Epoch: 397| Step: 0
Training loss: 0.506024956703186
Validation loss: 2.2690086315075555

Epoch: 5| Step: 1
Training loss: 0.3726458251476288
Validation loss: 2.246035491426786

Epoch: 5| Step: 2
Training loss: 0.17959940433502197
Validation loss: 2.2751584500074387

Epoch: 5| Step: 3
Training loss: 0.22556063532829285
Validation loss: 2.2252493699391684

Epoch: 5| Step: 4
Training loss: 0.3811454176902771
Validation loss: 2.2783320546150208

Epoch: 5| Step: 5
Training loss: 0.831379771232605
Validation loss: 2.278294324874878

Epoch: 5| Step: 6
Training loss: 0.6149650812149048
Validation loss: 2.3005414803822837

Epoch: 5| Step: 7
Training loss: 0.36747273802757263
Validation loss: 2.3018658459186554

Epoch: 5| Step: 8
Training loss: 0.22128815948963165
Validation loss: 2.217869743704796

Epoch: 5| Step: 9
Training loss: 0.3235967755317688
Validation loss: 2.280473361412684

Epoch: 5| Step: 10
Training loss: 0.4209938943386078
Validation loss: 2.3067775617043176

Epoch: 5| Step: 11
Training loss: 0.5224046111106873
Validation loss: 2.283003290494283

Epoch: 398| Step: 0
Training loss: 0.44189518690109253
Validation loss: 2.2942246993382773

Epoch: 5| Step: 1
Training loss: 0.45975321531295776
Validation loss: 2.2620866944392524

Epoch: 5| Step: 2
Training loss: 0.2813541889190674
Validation loss: 2.2996442218621573

Epoch: 5| Step: 3
Training loss: 0.3426956236362457
Validation loss: 2.2126793364683786

Epoch: 5| Step: 4
Training loss: 0.4749027192592621
Validation loss: 2.2828166534503302

Epoch: 5| Step: 5
Training loss: 0.7056723237037659
Validation loss: 2.2677941421667733

Epoch: 5| Step: 6
Training loss: 0.41871538758277893
Validation loss: 2.2378837366898856

Epoch: 5| Step: 7
Training loss: 0.21006229519844055
Validation loss: 2.1988753279050193

Epoch: 5| Step: 8
Training loss: 0.2698928415775299
Validation loss: 2.211309219400088

Epoch: 5| Step: 9
Training loss: 0.4308082163333893
Validation loss: 2.2590434849262238

Epoch: 5| Step: 10
Training loss: 0.2498382329940796
Validation loss: 2.233951762318611

Epoch: 5| Step: 11
Training loss: 0.245832622051239
Validation loss: 2.231602137287458

Epoch: 399| Step: 0
Training loss: 0.3169918954372406
Validation loss: 2.235128472248713

Epoch: 5| Step: 1
Training loss: 0.3606570363044739
Validation loss: 2.2204876244068146

Epoch: 5| Step: 2
Training loss: 0.29758062958717346
Validation loss: 2.226701016227404

Epoch: 5| Step: 3
Training loss: 0.4331965446472168
Validation loss: 2.2378757496674857

Epoch: 5| Step: 4
Training loss: 0.2679869532585144
Validation loss: 2.261045088370641

Epoch: 5| Step: 5
Training loss: 0.6356696486473083
Validation loss: 2.2114624132712684

Epoch: 5| Step: 6
Training loss: 0.5556010007858276
Validation loss: 2.236676280697187

Epoch: 5| Step: 7
Training loss: 0.25291627645492554
Validation loss: 2.2646349469820657

Epoch: 5| Step: 8
Training loss: 0.3455604016780853
Validation loss: 2.2284584641456604

Epoch: 5| Step: 9
Training loss: 0.4317476153373718
Validation loss: 2.2477146039406457

Epoch: 5| Step: 10
Training loss: 0.288626492023468
Validation loss: 2.221971645951271

Epoch: 5| Step: 11
Training loss: 0.5554020404815674
Validation loss: 2.240035434563955

Epoch: 400| Step: 0
Training loss: 0.3199247419834137
Validation loss: 2.279854873816172

Epoch: 5| Step: 1
Training loss: 0.24445001780986786
Validation loss: 2.220102737347285

Epoch: 5| Step: 2
Training loss: 0.3787178695201874
Validation loss: 2.290644645690918

Epoch: 5| Step: 3
Training loss: 0.22155611217021942
Validation loss: 2.2868644992510476

Epoch: 5| Step: 4
Training loss: 0.39209413528442383
Validation loss: 2.226079285144806

Epoch: 5| Step: 5
Training loss: 0.2493819296360016
Validation loss: 2.254096806049347

Epoch: 5| Step: 6
Training loss: 0.37080153822898865
Validation loss: 2.276805574695269

Epoch: 5| Step: 7
Training loss: 0.5306763648986816
Validation loss: 2.3102669715881348

Epoch: 5| Step: 8
Training loss: 0.4399392008781433
Validation loss: 2.2331418097019196

Epoch: 5| Step: 9
Training loss: 0.7066596150398254
Validation loss: 2.205096279581388

Epoch: 5| Step: 10
Training loss: 0.4625146985054016
Validation loss: 2.230490023891131

Epoch: 5| Step: 11
Training loss: 0.1754826307296753
Validation loss: 2.2551356852054596

Testing loss: 2.186275710304864
