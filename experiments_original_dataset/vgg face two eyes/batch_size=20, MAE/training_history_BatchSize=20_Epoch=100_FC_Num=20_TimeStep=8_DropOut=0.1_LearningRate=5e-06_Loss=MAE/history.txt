Epoch: 1| Step: 0
Training loss: 7.537326812744141
Validation loss: 7.510893881320953

Epoch: 5| Step: 1
Training loss: 7.418997287750244
Validation loss: 7.473210235436757

Epoch: 5| Step: 2
Training loss: 7.15496301651001
Validation loss: 7.437917669614156

Epoch: 5| Step: 3
Training loss: 7.765194892883301
Validation loss: 7.39467716217041

Epoch: 5| Step: 4
Training loss: 7.828768253326416
Validation loss: 7.357985059420268

Epoch: 5| Step: 5
Training loss: 7.208144187927246
Validation loss: 7.323484520117442

Epoch: 5| Step: 6
Training loss: 6.399206638336182
Validation loss: 7.285880943139394

Epoch: 5| Step: 7
Training loss: 7.653923988342285
Validation loss: 7.254100322723389

Epoch: 5| Step: 8
Training loss: 8.09699821472168
Validation loss: 7.21981265147527

Epoch: 5| Step: 9
Training loss: 6.856997489929199
Validation loss: 7.187209963798523

Epoch: 5| Step: 10
Training loss: 7.207099914550781
Validation loss: 7.1480986674626665

Epoch: 5| Step: 11
Training loss: 8.067346572875977
Validation loss: 7.11594174305598

Epoch: 2| Step: 0
Training loss: 7.537803649902344
Validation loss: 7.075902144114177

Epoch: 5| Step: 1
Training loss: 6.7702484130859375
Validation loss: 7.040077090263367

Epoch: 5| Step: 2
Training loss: 6.281857967376709
Validation loss: 7.002436141173045

Epoch: 5| Step: 3
Training loss: 6.934021949768066
Validation loss: 6.965861777464549

Epoch: 5| Step: 4
Training loss: 7.020817756652832
Validation loss: 6.930595378081004

Epoch: 5| Step: 5
Training loss: 6.4648332595825195
Validation loss: 6.88360458612442

Epoch: 5| Step: 6
Training loss: 6.500683784484863
Validation loss: 6.843368907769521

Epoch: 5| Step: 7
Training loss: 8.363058090209961
Validation loss: 6.798369566599528

Epoch: 5| Step: 8
Training loss: 7.7790937423706055
Validation loss: 6.75506728887558

Epoch: 5| Step: 9
Training loss: 6.815251350402832
Validation loss: 6.70477678378423

Epoch: 5| Step: 10
Training loss: 5.897848606109619
Validation loss: 6.658005317052205

Epoch: 5| Step: 11
Training loss: 6.450603485107422
Validation loss: 6.606389323870341

Epoch: 3| Step: 0
Training loss: 7.76715087890625
Validation loss: 6.549272338549296

Epoch: 5| Step: 1
Training loss: 6.194266319274902
Validation loss: 6.500486473242442

Epoch: 5| Step: 2
Training loss: 5.012856483459473
Validation loss: 6.442699770132701

Epoch: 5| Step: 3
Training loss: 6.358020782470703
Validation loss: 6.38153205315272

Epoch: 5| Step: 4
Training loss: 6.369915008544922
Validation loss: 6.3268682559331255

Epoch: 5| Step: 5
Training loss: 6.730149269104004
Validation loss: 6.258485496044159

Epoch: 5| Step: 6
Training loss: 6.381927490234375
Validation loss: 6.195631305376689

Epoch: 5| Step: 7
Training loss: 5.612236022949219
Validation loss: 6.123462359110515

Epoch: 5| Step: 8
Training loss: 6.743730068206787
Validation loss: 6.052812397480011

Epoch: 5| Step: 9
Training loss: 6.2971320152282715
Validation loss: 5.9786914984385175

Epoch: 5| Step: 10
Training loss: 5.975175857543945
Validation loss: 5.9058902859687805

Epoch: 5| Step: 11
Training loss: 5.584259986877441
Validation loss: 5.825666228930156

Epoch: 4| Step: 0
Training loss: 6.117452621459961
Validation loss: 5.73461111386617

Epoch: 5| Step: 1
Training loss: 5.965696811676025
Validation loss: 5.644904792308807

Epoch: 5| Step: 2
Training loss: 6.272223472595215
Validation loss: 5.547315677007039

Epoch: 5| Step: 3
Training loss: 5.6974358558654785
Validation loss: 5.456773618857066

Epoch: 5| Step: 4
Training loss: 5.699420928955078
Validation loss: 5.364468256632487

Epoch: 5| Step: 5
Training loss: 5.47779655456543
Validation loss: 5.262011508146922

Epoch: 5| Step: 6
Training loss: 4.766932964324951
Validation loss: 5.143060624599457

Epoch: 5| Step: 7
Training loss: 4.4989542961120605
Validation loss: 5.019656836986542

Epoch: 5| Step: 8
Training loss: 4.485888481140137
Validation loss: 4.912403047084808

Epoch: 5| Step: 9
Training loss: 4.429487705230713
Validation loss: 4.780813058217366

Epoch: 5| Step: 10
Training loss: 4.610215187072754
Validation loss: 4.646761814753215

Epoch: 5| Step: 11
Training loss: 6.209242343902588
Validation loss: 4.518098036448161

Epoch: 5| Step: 0
Training loss: 4.718289375305176
Validation loss: 4.3755475878715515

Epoch: 5| Step: 1
Training loss: 4.236330986022949
Validation loss: 4.232291320959727

Epoch: 5| Step: 2
Training loss: 3.949446201324463
Validation loss: 4.074341823657353

Epoch: 5| Step: 3
Training loss: 4.408620357513428
Validation loss: 3.9318910936514535

Epoch: 5| Step: 4
Training loss: 4.626365661621094
Validation loss: 3.7862553894519806

Epoch: 5| Step: 5
Training loss: 3.020259141921997
Validation loss: 3.6517792642116547

Epoch: 5| Step: 6
Training loss: 2.9386954307556152
Validation loss: 3.479758709669113

Epoch: 5| Step: 7
Training loss: 3.0608036518096924
Validation loss: 3.343331108490626

Epoch: 5| Step: 8
Training loss: 3.226590394973755
Validation loss: 3.1765958269437156

Epoch: 5| Step: 9
Training loss: 3.5082058906555176
Validation loss: 3.023585170507431

Epoch: 5| Step: 10
Training loss: 3.217944383621216
Validation loss: 2.8863845070203147

Epoch: 5| Step: 11
Training loss: 3.703795909881592
Validation loss: 2.7216674089431763

Epoch: 6| Step: 0
Training loss: 2.136899471282959
Validation loss: 2.6061130364735923

Epoch: 5| Step: 1
Training loss: 2.941016435623169
Validation loss: 2.4663306176662445

Epoch: 5| Step: 2
Training loss: 2.9255521297454834
Validation loss: 2.406251455346743

Epoch: 5| Step: 3
Training loss: 2.066312789916992
Validation loss: 2.355261047681173

Epoch: 5| Step: 4
Training loss: 2.313506841659546
Validation loss: 2.3543104082345963

Epoch: 5| Step: 5
Training loss: 3.187727451324463
Validation loss: 2.2975922177235284

Epoch: 5| Step: 6
Training loss: 1.8542850017547607
Validation loss: 2.277559300263723

Epoch: 5| Step: 7
Training loss: 2.360495090484619
Validation loss: 2.306275894244512

Epoch: 5| Step: 8
Training loss: 1.9300369024276733
Validation loss: 2.2858837445576987

Epoch: 5| Step: 9
Training loss: 3.2638535499572754
Validation loss: 2.372174839178721

Epoch: 5| Step: 10
Training loss: 2.418748378753662
Validation loss: 2.3694552878538766

Epoch: 5| Step: 11
Training loss: 4.259855270385742
Validation loss: 2.3743221859137216

Epoch: 7| Step: 0
Training loss: 2.146878719329834
Validation loss: 2.3813790380954742

Epoch: 5| Step: 1
Training loss: 2.054736375808716
Validation loss: 2.376927673816681

Epoch: 5| Step: 2
Training loss: 2.5632615089416504
Validation loss: 2.3003994524478912

Epoch: 5| Step: 3
Training loss: 2.890150547027588
Validation loss: 2.2932921250661216

Epoch: 5| Step: 4
Training loss: 2.085784435272217
Validation loss: 2.237593854467074

Epoch: 5| Step: 5
Training loss: 2.527864933013916
Validation loss: 2.234888404607773

Epoch: 5| Step: 6
Training loss: 2.314237117767334
Validation loss: 2.2383306672175727

Epoch: 5| Step: 7
Training loss: 2.054746150970459
Validation loss: 2.230331838130951

Epoch: 5| Step: 8
Training loss: 2.3407492637634277
Validation loss: 2.222296357154846

Epoch: 5| Step: 9
Training loss: 2.2144360542297363
Validation loss: 2.2390779852867126

Epoch: 5| Step: 10
Training loss: 2.7916550636291504
Validation loss: 2.26880274216334

Epoch: 5| Step: 11
Training loss: 1.6646583080291748
Validation loss: 2.207532932360967

Epoch: 8| Step: 0
Training loss: 2.40871000289917
Validation loss: 2.2036101122697196

Epoch: 5| Step: 1
Training loss: 3.1202175617218018
Validation loss: 2.2109316686789193

Epoch: 5| Step: 2
Training loss: 1.7805473804473877
Validation loss: 2.208037883043289

Epoch: 5| Step: 3
Training loss: 1.8580249547958374
Validation loss: 2.2076961398124695

Epoch: 5| Step: 4
Training loss: 2.33158016204834
Validation loss: 2.2220975955327353

Epoch: 5| Step: 5
Training loss: 1.9306752681732178
Validation loss: 2.185749645034472

Epoch: 5| Step: 6
Training loss: 2.2925004959106445
Validation loss: 2.2160289188226066

Epoch: 5| Step: 7
Training loss: 2.0170719623565674
Validation loss: 2.1989691058794656

Epoch: 5| Step: 8
Training loss: 3.1444976329803467
Validation loss: 2.2281437516212463

Epoch: 5| Step: 9
Training loss: 1.9924647808074951
Validation loss: 2.238537609577179

Epoch: 5| Step: 10
Training loss: 2.0470054149627686
Validation loss: 2.229681760072708

Epoch: 5| Step: 11
Training loss: 2.8090858459472656
Validation loss: 2.2094421883424125

Epoch: 9| Step: 0
Training loss: 2.137071132659912
Validation loss: 2.21592186888059

Epoch: 5| Step: 1
Training loss: 1.4737279415130615
Validation loss: 2.222259839375814

Epoch: 5| Step: 2
Training loss: 2.9483513832092285
Validation loss: 2.1796599477529526

Epoch: 5| Step: 3
Training loss: 2.011958599090576
Validation loss: 2.1809253692626953

Epoch: 5| Step: 4
Training loss: 1.9733874797821045
Validation loss: 2.2088349014520645

Epoch: 5| Step: 5
Training loss: 2.1586978435516357
Validation loss: 2.200399418671926

Epoch: 5| Step: 6
Training loss: 2.037503242492676
Validation loss: 2.2320118248462677

Epoch: 5| Step: 7
Training loss: 2.055417537689209
Validation loss: 2.1835188368956246

Epoch: 5| Step: 8
Training loss: 2.643956422805786
Validation loss: 2.1695790787537894

Epoch: 5| Step: 9
Training loss: 2.73832368850708
Validation loss: 2.1823234458764396

Epoch: 5| Step: 10
Training loss: 2.0705978870391846
Validation loss: 2.1203664541244507

Epoch: 5| Step: 11
Training loss: 2.7946314811706543
Validation loss: 2.157017777363459

Epoch: 10| Step: 0
Training loss: 1.9878603219985962
Validation loss: 2.1645524402459464

Epoch: 5| Step: 1
Training loss: 2.3407037258148193
Validation loss: 2.1706164479255676

Epoch: 5| Step: 2
Training loss: 1.6931164264678955
Validation loss: 2.139792318145434

Epoch: 5| Step: 3
Training loss: 1.8078405857086182
Validation loss: 2.173604905605316

Epoch: 5| Step: 4
Training loss: 2.615842580795288
Validation loss: 2.147975444793701

Epoch: 5| Step: 5
Training loss: 2.1911325454711914
Validation loss: 2.1664132525523505

Epoch: 5| Step: 6
Training loss: 2.9388179779052734
Validation loss: 2.1603511621554694

Epoch: 5| Step: 7
Training loss: 2.6218526363372803
Validation loss: 2.1680552860101066

Epoch: 5| Step: 8
Training loss: 2.2727723121643066
Validation loss: 2.1517131427923837

Epoch: 5| Step: 9
Training loss: 1.9063632488250732
Validation loss: 2.179507633050283

Epoch: 5| Step: 10
Training loss: 2.1815667152404785
Validation loss: 2.1465508143107095

Epoch: 5| Step: 11
Training loss: 2.1041922569274902
Validation loss: 2.1152404844760895

Epoch: 11| Step: 0
Training loss: 2.102388858795166
Validation loss: 2.144427408774694

Epoch: 5| Step: 1
Training loss: 2.245518445968628
Validation loss: 2.1621691832939782

Epoch: 5| Step: 2
Training loss: 1.5566039085388184
Validation loss: 2.155724306901296

Epoch: 5| Step: 3
Training loss: 1.9419209957122803
Validation loss: 2.1398749202489853

Epoch: 5| Step: 4
Training loss: 2.515751600265503
Validation loss: 2.168766920765241

Epoch: 5| Step: 5
Training loss: 1.5819299221038818
Validation loss: 2.1725853085517883

Epoch: 5| Step: 6
Training loss: 2.265366554260254
Validation loss: 2.159179463982582

Epoch: 5| Step: 7
Training loss: 2.5169174671173096
Validation loss: 2.150285621484121

Epoch: 5| Step: 8
Training loss: 2.341766357421875
Validation loss: 2.1277292172114053

Epoch: 5| Step: 9
Training loss: 2.333460569381714
Validation loss: 2.140292232235273

Epoch: 5| Step: 10
Training loss: 2.3241894245147705
Validation loss: 2.157501290241877

Epoch: 5| Step: 11
Training loss: 3.464010715484619
Validation loss: 2.1556436518828073

Epoch: 12| Step: 0
Training loss: 1.7467963695526123
Validation loss: 2.1442955682675042

Epoch: 5| Step: 1
Training loss: 2.4367172718048096
Validation loss: 2.1018201112747192

Epoch: 5| Step: 2
Training loss: 1.8742882013320923
Validation loss: 2.126522729794184

Epoch: 5| Step: 3
Training loss: 2.1721882820129395
Validation loss: 2.13228448232015

Epoch: 5| Step: 4
Training loss: 2.436393976211548
Validation loss: 2.138460526863734

Epoch: 5| Step: 5
Training loss: 2.1607725620269775
Validation loss: 2.146198978026708

Epoch: 5| Step: 6
Training loss: 3.0417046546936035
Validation loss: 2.1496745198965073

Epoch: 5| Step: 7
Training loss: 2.212515115737915
Validation loss: 2.142182191212972

Epoch: 5| Step: 8
Training loss: 2.3183186054229736
Validation loss: 2.101503218213717

Epoch: 5| Step: 9
Training loss: 1.8599369525909424
Validation loss: 2.1180604795614877

Epoch: 5| Step: 10
Training loss: 1.518035650253296
Validation loss: 2.1297645419836044

Epoch: 5| Step: 11
Training loss: 0.9843745231628418
Validation loss: 2.1455885718266168

Epoch: 13| Step: 0
Training loss: 3.0430245399475098
Validation loss: 2.0792769491672516

Epoch: 5| Step: 1
Training loss: 2.266136646270752
Validation loss: 2.1066276083389917

Epoch: 5| Step: 2
Training loss: 2.551762104034424
Validation loss: 2.147892345984777

Epoch: 5| Step: 3
Training loss: 2.1141908168792725
Validation loss: 2.106277639667193

Epoch: 5| Step: 4
Training loss: 2.203558921813965
Validation loss: 2.1165502121051154

Epoch: 5| Step: 5
Training loss: 1.705565094947815
Validation loss: 2.1664130290349326

Epoch: 5| Step: 6
Training loss: 1.5397851467132568
Validation loss: 2.109939232468605

Epoch: 5| Step: 7
Training loss: 2.0045552253723145
Validation loss: 2.1039321223894754

Epoch: 5| Step: 8
Training loss: 2.101644992828369
Validation loss: 2.134795660773913

Epoch: 5| Step: 9
Training loss: 1.8667945861816406
Validation loss: 2.1719690610965094

Epoch: 5| Step: 10
Training loss: 2.040341377258301
Validation loss: 2.143609647949537

Epoch: 5| Step: 11
Training loss: 2.3793654441833496
Validation loss: 2.10711661974589

Epoch: 14| Step: 0
Training loss: 2.1026761531829834
Validation loss: 2.1133464177449546

Epoch: 5| Step: 1
Training loss: 1.6119697093963623
Validation loss: 2.154294470945994

Epoch: 5| Step: 2
Training loss: 2.522042751312256
Validation loss: 2.105904201666514

Epoch: 5| Step: 3
Training loss: 2.218339204788208
Validation loss: 2.089480072259903

Epoch: 5| Step: 4
Training loss: 1.727503776550293
Validation loss: 2.1063461353381476

Epoch: 5| Step: 5
Training loss: 2.8095316886901855
Validation loss: 2.0673551112413406

Epoch: 5| Step: 6
Training loss: 1.6441274881362915
Validation loss: 2.0883141855398812

Epoch: 5| Step: 7
Training loss: 2.7386837005615234
Validation loss: 2.105268175403277

Epoch: 5| Step: 8
Training loss: 2.235182523727417
Validation loss: 2.0497081180413566

Epoch: 5| Step: 9
Training loss: 1.989749550819397
Validation loss: 2.140535061558088

Epoch: 5| Step: 10
Training loss: 2.112400531768799
Validation loss: 2.1060612152020135

Epoch: 5| Step: 11
Training loss: 1.5644761323928833
Validation loss: 2.072796588142713

Epoch: 15| Step: 0
Training loss: 2.2799041271209717
Validation loss: 2.1140473584334054

Epoch: 5| Step: 1
Training loss: 2.3738901615142822
Validation loss: 2.1460195084412894

Epoch: 5| Step: 2
Training loss: 2.3414692878723145
Validation loss: 2.2497733434041343

Epoch: 5| Step: 3
Training loss: 2.0214545726776123
Validation loss: 2.291959156592687

Epoch: 5| Step: 4
Training loss: 2.086313247680664
Validation loss: 2.245461126168569

Epoch: 5| Step: 5
Training loss: 2.7435061931610107
Validation loss: 2.218660458922386

Epoch: 5| Step: 6
Training loss: 1.9639298915863037
Validation loss: 2.2726473609606423

Epoch: 5| Step: 7
Training loss: 1.6978368759155273
Validation loss: 2.2372951954603195

Epoch: 5| Step: 8
Training loss: 1.7665579319000244
Validation loss: 2.239854484796524

Epoch: 5| Step: 9
Training loss: 2.5575287342071533
Validation loss: 2.1909226179122925

Epoch: 5| Step: 10
Training loss: 1.8464107513427734
Validation loss: 2.1852861444155374

Epoch: 5| Step: 11
Training loss: 1.0570149421691895
Validation loss: 2.129269778728485

Epoch: 16| Step: 0
Training loss: 2.573922872543335
Validation loss: 2.099832698702812

Epoch: 5| Step: 1
Training loss: 1.463078260421753
Validation loss: 2.094321424762408

Epoch: 5| Step: 2
Training loss: 2.509597063064575
Validation loss: 2.088316192229589

Epoch: 5| Step: 3
Training loss: 1.9309310913085938
Validation loss: 2.0903437385956445

Epoch: 5| Step: 4
Training loss: 2.2838425636291504
Validation loss: 2.1134208341439567

Epoch: 5| Step: 5
Training loss: 2.0077977180480957
Validation loss: 2.101257468263308

Epoch: 5| Step: 6
Training loss: 2.2977893352508545
Validation loss: 2.0968570510546365

Epoch: 5| Step: 7
Training loss: 1.742929220199585
Validation loss: 2.136537412802378

Epoch: 5| Step: 8
Training loss: 1.8998267650604248
Validation loss: 2.1068469484647117

Epoch: 5| Step: 9
Training loss: 2.065089464187622
Validation loss: 2.113490581512451

Epoch: 5| Step: 10
Training loss: 2.452042579650879
Validation loss: 2.106830596923828

Epoch: 5| Step: 11
Training loss: 2.4001269340515137
Validation loss: 2.1400002936522164

Epoch: 17| Step: 0
Training loss: 1.9789139032363892
Validation loss: 2.1311745643615723

Epoch: 5| Step: 1
Training loss: 2.1893038749694824
Validation loss: 2.0999935070673623

Epoch: 5| Step: 2
Training loss: 2.0221848487854004
Validation loss: 2.1124403278032937

Epoch: 5| Step: 3
Training loss: 1.9789901971817017
Validation loss: 2.150158792734146

Epoch: 5| Step: 4
Training loss: 1.9220768213272095
Validation loss: 2.170496349533399

Epoch: 5| Step: 5
Training loss: 1.9225099086761475
Validation loss: 2.1370293696721396

Epoch: 5| Step: 6
Training loss: 2.6351583003997803
Validation loss: 2.1412035673856735

Epoch: 5| Step: 7
Training loss: 1.9965088367462158
Validation loss: 2.129149854183197

Epoch: 5| Step: 8
Training loss: 1.949566125869751
Validation loss: 2.113987614711126

Epoch: 5| Step: 9
Training loss: 1.9901634454727173
Validation loss: 2.166927923758825

Epoch: 5| Step: 10
Training loss: 2.372702121734619
Validation loss: 2.184479907155037

Epoch: 5| Step: 11
Training loss: 1.9228689670562744
Validation loss: 2.161455363035202

Epoch: 18| Step: 0
Training loss: 2.636462926864624
Validation loss: 2.154708375533422

Epoch: 5| Step: 1
Training loss: 1.601274847984314
Validation loss: 2.138790542880694

Epoch: 5| Step: 2
Training loss: 1.9263445138931274
Validation loss: 2.1132706105709076

Epoch: 5| Step: 3
Training loss: 2.259603977203369
Validation loss: 2.1215998182694116

Epoch: 5| Step: 4
Training loss: 1.7969772815704346
Validation loss: 2.09879399339358

Epoch: 5| Step: 5
Training loss: 1.6910417079925537
Validation loss: 2.1297746896743774

Epoch: 5| Step: 6
Training loss: 2.2006821632385254
Validation loss: 2.0868100772301355

Epoch: 5| Step: 7
Training loss: 1.9795396327972412
Validation loss: 2.101641962925593

Epoch: 5| Step: 8
Training loss: 2.6443824768066406
Validation loss: 2.0586852629979453

Epoch: 5| Step: 9
Training loss: 2.3803772926330566
Validation loss: 2.110999882221222

Epoch: 5| Step: 10
Training loss: 2.05363130569458
Validation loss: 2.1183668673038483

Epoch: 5| Step: 11
Training loss: 1.4132133722305298
Validation loss: 2.1065967679023743

Epoch: 19| Step: 0
Training loss: 2.4447779655456543
Validation loss: 2.145617047945658

Epoch: 5| Step: 1
Training loss: 1.8184553384780884
Validation loss: 2.1091552327076593

Epoch: 5| Step: 2
Training loss: 2.5161662101745605
Validation loss: 2.091727544864019

Epoch: 5| Step: 3
Training loss: 2.0770015716552734
Validation loss: 2.144964391986529

Epoch: 5| Step: 4
Training loss: 1.9834072589874268
Validation loss: 2.1352192064126334

Epoch: 5| Step: 5
Training loss: 1.5664194822311401
Validation loss: 2.0848317792018256

Epoch: 5| Step: 6
Training loss: 1.8567367792129517
Validation loss: 2.09308622777462

Epoch: 5| Step: 7
Training loss: 2.2330291271209717
Validation loss: 2.120005890727043

Epoch: 5| Step: 8
Training loss: 1.8636817932128906
Validation loss: 2.098332087198893

Epoch: 5| Step: 9
Training loss: 2.1929423809051514
Validation loss: 2.116491417090098

Epoch: 5| Step: 10
Training loss: 1.95432448387146
Validation loss: 2.1317732433478036

Epoch: 5| Step: 11
Training loss: 2.620133399963379
Validation loss: 2.1355628967285156

Epoch: 20| Step: 0
Training loss: 2.4882254600524902
Validation loss: 2.1175197760264077

Epoch: 5| Step: 1
Training loss: 2.3664424419403076
Validation loss: 2.192671741048495

Epoch: 5| Step: 2
Training loss: 2.16009259223938
Validation loss: 2.180885230501493

Epoch: 5| Step: 3
Training loss: 1.971897840499878
Validation loss: 2.2029556334018707

Epoch: 5| Step: 4
Training loss: 2.0057592391967773
Validation loss: 2.184388056397438

Epoch: 5| Step: 5
Training loss: 2.0750250816345215
Validation loss: 2.229913115501404

Epoch: 5| Step: 6
Training loss: 2.2721967697143555
Validation loss: 2.228618025779724

Epoch: 5| Step: 7
Training loss: 2.169703245162964
Validation loss: 2.1678710877895355

Epoch: 5| Step: 8
Training loss: 1.8813289403915405
Validation loss: 2.131768584251404

Epoch: 5| Step: 9
Training loss: 1.7426164150238037
Validation loss: 2.115433712800344

Epoch: 5| Step: 10
Training loss: 1.233806848526001
Validation loss: 2.1684272239605584

Epoch: 5| Step: 11
Training loss: 2.820557117462158
Validation loss: 2.095134347677231

Epoch: 21| Step: 0
Training loss: 1.839797019958496
Validation loss: 2.1078936656316123

Epoch: 5| Step: 1
Training loss: 2.619356632232666
Validation loss: 2.0822024097045264

Epoch: 5| Step: 2
Training loss: 1.6359981298446655
Validation loss: 2.1193944960832596

Epoch: 5| Step: 3
Training loss: 2.7014477252960205
Validation loss: 2.124047189950943

Epoch: 5| Step: 4
Training loss: 1.8926427364349365
Validation loss: 2.1263059079647064

Epoch: 5| Step: 5
Training loss: 1.618472695350647
Validation loss: 2.111115202307701

Epoch: 5| Step: 6
Training loss: 2.3495852947235107
Validation loss: 2.134769191344579

Epoch: 5| Step: 7
Training loss: 2.1511242389678955
Validation loss: 2.086687038342158

Epoch: 5| Step: 8
Training loss: 1.5254052877426147
Validation loss: 2.142218510309855

Epoch: 5| Step: 9
Training loss: 2.0486607551574707
Validation loss: 2.0650003800789514

Epoch: 5| Step: 10
Training loss: 1.8234660625457764
Validation loss: 2.1211548993984857

Epoch: 5| Step: 11
Training loss: 2.4634547233581543
Validation loss: 2.100392291943232

Epoch: 22| Step: 0
Training loss: 2.0811657905578613
Validation loss: 2.1036432683467865

Epoch: 5| Step: 1
Training loss: 2.3021254539489746
Validation loss: 2.160088529189428

Epoch: 5| Step: 2
Training loss: 1.7357072830200195
Validation loss: 2.148062527179718

Epoch: 5| Step: 3
Training loss: 2.2432637214660645
Validation loss: 2.115969091653824

Epoch: 5| Step: 4
Training loss: 1.5842578411102295
Validation loss: 2.1680292089780173

Epoch: 5| Step: 5
Training loss: 1.8000173568725586
Validation loss: 2.180693427721659

Epoch: 5| Step: 6
Training loss: 2.9245738983154297
Validation loss: 2.1671997805436454

Epoch: 5| Step: 7
Training loss: 1.9478328227996826
Validation loss: 2.1155893007914224

Epoch: 5| Step: 8
Training loss: 2.1246159076690674
Validation loss: 2.1660762578248978

Epoch: 5| Step: 9
Training loss: 2.175504684448242
Validation loss: 2.127202386657397

Epoch: 5| Step: 10
Training loss: 1.466482400894165
Validation loss: 2.1094601154327393

Epoch: 5| Step: 11
Training loss: 1.5243803262710571
Validation loss: 2.13403328259786

Epoch: 23| Step: 0
Training loss: 2.295306921005249
Validation loss: 2.0859302282333374

Epoch: 5| Step: 1
Training loss: 2.6008553504943848
Validation loss: 2.0974153776963553

Epoch: 5| Step: 2
Training loss: 2.000588893890381
Validation loss: 2.1604262044032416

Epoch: 5| Step: 3
Training loss: 1.8133957386016846
Validation loss: 2.078264291087786

Epoch: 5| Step: 4
Training loss: 1.9024368524551392
Validation loss: 2.1144234041372933

Epoch: 5| Step: 5
Training loss: 1.6197398900985718
Validation loss: 2.160449837644895

Epoch: 5| Step: 6
Training loss: 1.9453096389770508
Validation loss: 2.074862619241079

Epoch: 5| Step: 7
Training loss: 2.8300318717956543
Validation loss: 2.095077325900396

Epoch: 5| Step: 8
Training loss: 1.7626075744628906
Validation loss: 2.1091768592596054

Epoch: 5| Step: 9
Training loss: 2.0447678565979004
Validation loss: 2.0894028147061667

Epoch: 5| Step: 10
Training loss: 1.6220433712005615
Validation loss: 2.1220695128043494

Epoch: 5| Step: 11
Training loss: 2.5460877418518066
Validation loss: 2.1387581626574197

Epoch: 24| Step: 0
Training loss: 1.6138455867767334
Validation loss: 2.1285468886295953

Epoch: 5| Step: 1
Training loss: 1.9516174793243408
Validation loss: 2.19555534919103

Epoch: 5| Step: 2
Training loss: 1.778677225112915
Validation loss: 2.1808824241161346

Epoch: 5| Step: 3
Training loss: 1.718610405921936
Validation loss: 2.17585352063179

Epoch: 5| Step: 4
Training loss: 2.0217244625091553
Validation loss: 2.172085384527842

Epoch: 5| Step: 5
Training loss: 2.4781150817871094
Validation loss: 2.128759170571963

Epoch: 5| Step: 6
Training loss: 2.438511371612549
Validation loss: 2.139456942677498

Epoch: 5| Step: 7
Training loss: 2.6142492294311523
Validation loss: 2.1100837091604867

Epoch: 5| Step: 8
Training loss: 1.6385612487792969
Validation loss: 2.1061418602863946

Epoch: 5| Step: 9
Training loss: 1.9004074335098267
Validation loss: 2.1531864255666733

Epoch: 5| Step: 10
Training loss: 2.1247057914733887
Validation loss: 2.1028906255960464

Epoch: 5| Step: 11
Training loss: 2.3575029373168945
Validation loss: 2.130723794301351

Epoch: 25| Step: 0
Training loss: 2.3846206665039062
Validation loss: 2.1199539502461753

Epoch: 5| Step: 1
Training loss: 1.7154308557510376
Validation loss: 2.1075717310110726

Epoch: 5| Step: 2
Training loss: 1.8859002590179443
Validation loss: 2.113632212082545

Epoch: 5| Step: 3
Training loss: 2.131423234939575
Validation loss: 2.1526663402716317

Epoch: 5| Step: 4
Training loss: 1.9551000595092773
Validation loss: 2.100438669323921

Epoch: 5| Step: 5
Training loss: 1.9323192834854126
Validation loss: 2.0863930781682334

Epoch: 5| Step: 6
Training loss: 2.2578823566436768
Validation loss: 2.1411004811525345

Epoch: 5| Step: 7
Training loss: 2.507969856262207
Validation loss: 2.1139654368162155

Epoch: 5| Step: 8
Training loss: 1.9897762537002563
Validation loss: 2.0942163666089377

Epoch: 5| Step: 9
Training loss: 2.378868818283081
Validation loss: 2.0775690774122872

Epoch: 5| Step: 10
Training loss: 1.5214895009994507
Validation loss: 2.0965193609396615

Epoch: 5| Step: 11
Training loss: 1.8083138465881348
Validation loss: 2.0993182559808097

Epoch: 26| Step: 0
Training loss: 2.5344626903533936
Validation loss: 2.1305510699748993

Epoch: 5| Step: 1
Training loss: 1.7621656656265259
Validation loss: 2.166962504386902

Epoch: 5| Step: 2
Training loss: 2.245081663131714
Validation loss: 2.178673361738523

Epoch: 5| Step: 3
Training loss: 1.8047730922698975
Validation loss: 2.173080235719681

Epoch: 5| Step: 4
Training loss: 2.6182546615600586
Validation loss: 2.23293170829614

Epoch: 5| Step: 5
Training loss: 2.4275290966033936
Validation loss: 2.1863852938016257

Epoch: 5| Step: 6
Training loss: 1.8331058025360107
Validation loss: 2.2188478112220764

Epoch: 5| Step: 7
Training loss: 2.007080078125
Validation loss: 2.1680306990941367

Epoch: 5| Step: 8
Training loss: 2.055992603302002
Validation loss: 2.113232284784317

Epoch: 5| Step: 9
Training loss: 1.929420828819275
Validation loss: 2.0927035361528397

Epoch: 5| Step: 10
Training loss: 1.630885362625122
Validation loss: 2.113353023926417

Epoch: 5| Step: 11
Training loss: 0.6439361572265625
Validation loss: 2.08770460387071

Epoch: 27| Step: 0
Training loss: 1.5862518548965454
Validation loss: 2.1003459443648658

Epoch: 5| Step: 1
Training loss: 1.7562620639801025
Validation loss: 2.133459910750389

Epoch: 5| Step: 2
Training loss: 2.168947696685791
Validation loss: 2.115460380911827

Epoch: 5| Step: 3
Training loss: 2.58247447013855
Validation loss: 2.1304012487332025

Epoch: 5| Step: 4
Training loss: 2.096022129058838
Validation loss: 2.1609567205111184

Epoch: 5| Step: 5
Training loss: 2.1072072982788086
Validation loss: 2.1140116651852927

Epoch: 5| Step: 6
Training loss: 2.202183246612549
Validation loss: 2.103206237157186

Epoch: 5| Step: 7
Training loss: 1.6673696041107178
Validation loss: 2.108340044816335

Epoch: 5| Step: 8
Training loss: 2.419377088546753
Validation loss: 2.1049275447924933

Epoch: 5| Step: 9
Training loss: 1.8596004247665405
Validation loss: 2.10030368467172

Epoch: 5| Step: 10
Training loss: 2.1011812686920166
Validation loss: 2.142937481403351

Epoch: 5| Step: 11
Training loss: 1.8843119144439697
Validation loss: 2.120402534802755

Epoch: 28| Step: 0
Training loss: 2.1802890300750732
Validation loss: 2.0899332414070764

Epoch: 5| Step: 1
Training loss: 1.8564592599868774
Validation loss: 2.1391899585723877

Epoch: 5| Step: 2
Training loss: 1.8630163669586182
Validation loss: 2.185220013062159

Epoch: 5| Step: 3
Training loss: 2.118588924407959
Validation loss: 2.2358265121777854

Epoch: 5| Step: 4
Training loss: 2.240940570831299
Validation loss: 2.2244541943073273

Epoch: 5| Step: 5
Training loss: 2.430558204650879
Validation loss: 2.2522579431533813

Epoch: 5| Step: 6
Training loss: 1.8067678213119507
Validation loss: 2.209203620751699

Epoch: 5| Step: 7
Training loss: 2.2918906211853027
Validation loss: 2.210129683216413

Epoch: 5| Step: 8
Training loss: 1.4605599641799927
Validation loss: 2.158680031696955

Epoch: 5| Step: 9
Training loss: 1.7618911266326904
Validation loss: 2.1560160468022027

Epoch: 5| Step: 10
Training loss: 2.246332883834839
Validation loss: 2.139212280511856

Epoch: 5| Step: 11
Training loss: 2.7908647060394287
Validation loss: 2.1420885771512985

Epoch: 29| Step: 0
Training loss: 2.0308163166046143
Validation loss: 2.0862998267014823

Epoch: 5| Step: 1
Training loss: 1.5279418230056763
Validation loss: 2.09621753791968

Epoch: 5| Step: 2
Training loss: 1.9650242328643799
Validation loss: 2.1295288304487863

Epoch: 5| Step: 3
Training loss: 2.269259214401245
Validation loss: 2.0688629696766534

Epoch: 5| Step: 4
Training loss: 2.3333683013916016
Validation loss: 2.0533508956432343

Epoch: 5| Step: 5
Training loss: 2.4920926094055176
Validation loss: 2.0887144058942795

Epoch: 5| Step: 6
Training loss: 1.6564613580703735
Validation loss: 2.0985211431980133

Epoch: 5| Step: 7
Training loss: 1.7279386520385742
Validation loss: 2.0694226920604706

Epoch: 5| Step: 8
Training loss: 1.7726434469223022
Validation loss: 2.120788882176081

Epoch: 5| Step: 9
Training loss: 1.9205543994903564
Validation loss: 2.1493471364180246

Epoch: 5| Step: 10
Training loss: 2.2377772331237793
Validation loss: 2.1242313583691916

Epoch: 5| Step: 11
Training loss: 1.7085535526275635
Validation loss: 2.1004109929005303

Epoch: 30| Step: 0
Training loss: 2.1845033168792725
Validation loss: 2.105052654941877

Epoch: 5| Step: 1
Training loss: 1.9856359958648682
Validation loss: 2.12877623240153

Epoch: 5| Step: 2
Training loss: 1.5527671575546265
Validation loss: 2.1410058240095773

Epoch: 5| Step: 3
Training loss: 1.5482641458511353
Validation loss: 2.124344363808632

Epoch: 5| Step: 4
Training loss: 1.6459718942642212
Validation loss: 2.152948945760727

Epoch: 5| Step: 5
Training loss: 2.1765003204345703
Validation loss: 2.1824381401141486

Epoch: 5| Step: 6
Training loss: 2.5281455516815186
Validation loss: 2.2563172777493796

Epoch: 5| Step: 7
Training loss: 1.8613767623901367
Validation loss: 2.238899072011312

Epoch: 5| Step: 8
Training loss: 2.520717144012451
Validation loss: 2.230229526758194

Epoch: 5| Step: 9
Training loss: 2.24003005027771
Validation loss: 2.201662321885427

Epoch: 5| Step: 10
Training loss: 1.8976571559906006
Validation loss: 2.1903614004453025

Epoch: 5| Step: 11
Training loss: 2.0150551795959473
Validation loss: 2.1330165962378183

Epoch: 31| Step: 0
Training loss: 2.044004440307617
Validation loss: 2.111125946044922

Epoch: 5| Step: 1
Training loss: 2.0097343921661377
Validation loss: 2.0967209935188293

Epoch: 5| Step: 2
Training loss: 2.0460712909698486
Validation loss: 2.113137905796369

Epoch: 5| Step: 3
Training loss: 2.008807420730591
Validation loss: 2.120471701025963

Epoch: 5| Step: 4
Training loss: 2.2669622898101807
Validation loss: 2.058443824450175

Epoch: 5| Step: 5
Training loss: 2.057424545288086
Validation loss: 2.110295275847117

Epoch: 5| Step: 6
Training loss: 1.7601791620254517
Validation loss: 2.11498532195886

Epoch: 5| Step: 7
Training loss: 2.2887749671936035
Validation loss: 2.100272923707962

Epoch: 5| Step: 8
Training loss: 1.6081444025039673
Validation loss: 2.1286704689264297

Epoch: 5| Step: 9
Training loss: 1.57724928855896
Validation loss: 2.1081998497247696

Epoch: 5| Step: 10
Training loss: 2.047611713409424
Validation loss: 2.0635454704364142

Epoch: 5| Step: 11
Training loss: 2.482455253601074
Validation loss: 2.1237552911043167

Epoch: 32| Step: 0
Training loss: 1.9988734722137451
Validation loss: 2.1043061961730323

Epoch: 5| Step: 1
Training loss: 1.950777292251587
Validation loss: 2.1785913705825806

Epoch: 5| Step: 2
Training loss: 2.6045360565185547
Validation loss: 2.077040617664655

Epoch: 5| Step: 3
Training loss: 1.9639112949371338
Validation loss: 2.152657891313235

Epoch: 5| Step: 4
Training loss: 1.8612232208251953
Validation loss: 2.2119364043076835

Epoch: 5| Step: 5
Training loss: 2.0237443447113037
Validation loss: 2.1343694726626077

Epoch: 5| Step: 6
Training loss: 2.10632586479187
Validation loss: 2.1234118193387985

Epoch: 5| Step: 7
Training loss: 1.990597128868103
Validation loss: 2.1271501779556274

Epoch: 5| Step: 8
Training loss: 1.2190093994140625
Validation loss: 2.0893584986527762

Epoch: 5| Step: 9
Training loss: 1.9695297479629517
Validation loss: 2.092162787914276

Epoch: 5| Step: 10
Training loss: 2.0134167671203613
Validation loss: 2.1172169198592505

Epoch: 5| Step: 11
Training loss: 1.0290744304656982
Validation loss: 2.1124518613020578

Epoch: 33| Step: 0
Training loss: 2.0271692276000977
Validation loss: 2.121123512585958

Epoch: 5| Step: 1
Training loss: 1.803727149963379
Validation loss: 2.12095641096433

Epoch: 5| Step: 2
Training loss: 1.5305994749069214
Validation loss: 2.1263918032248816

Epoch: 5| Step: 3
Training loss: 1.782200574874878
Validation loss: 2.1694544653097787

Epoch: 5| Step: 4
Training loss: 1.8522392511367798
Validation loss: 2.080400029818217

Epoch: 5| Step: 5
Training loss: 1.9546493291854858
Validation loss: 2.1210338175296783

Epoch: 5| Step: 6
Training loss: 2.349997043609619
Validation loss: 2.1409226258595786

Epoch: 5| Step: 7
Training loss: 1.5665748119354248
Validation loss: 2.15309306482474

Epoch: 5| Step: 8
Training loss: 2.289206027984619
Validation loss: 2.0936557998259864

Epoch: 5| Step: 9
Training loss: 2.5003933906555176
Validation loss: 2.174430633584658

Epoch: 5| Step: 10
Training loss: 2.109675645828247
Validation loss: 2.1334982216358185

Epoch: 5| Step: 11
Training loss: 2.360525369644165
Validation loss: 2.139188920458158

Epoch: 34| Step: 0
Training loss: 1.4970875978469849
Validation loss: 2.1001306821902594

Epoch: 5| Step: 1
Training loss: 1.6968177556991577
Validation loss: 2.1165953079859414

Epoch: 5| Step: 2
Training loss: 1.5073659420013428
Validation loss: 2.1487643867731094

Epoch: 5| Step: 3
Training loss: 2.1190743446350098
Validation loss: 2.139334484934807

Epoch: 5| Step: 4
Training loss: 2.2073347568511963
Validation loss: 2.1076966921488443

Epoch: 5| Step: 5
Training loss: 2.064157247543335
Validation loss: 2.142825817068418

Epoch: 5| Step: 6
Training loss: 1.9153411388397217
Validation loss: 2.131241023540497

Epoch: 5| Step: 7
Training loss: 2.6267569065093994
Validation loss: 2.148228034377098

Epoch: 5| Step: 8
Training loss: 2.3404438495635986
Validation loss: 2.118889888127645

Epoch: 5| Step: 9
Training loss: 2.0091795921325684
Validation loss: 2.116235335667928

Epoch: 5| Step: 10
Training loss: 1.7007081508636475
Validation loss: 2.144216919938723

Epoch: 5| Step: 11
Training loss: 1.5864028930664062
Validation loss: 2.114345078667005

Epoch: 35| Step: 0
Training loss: 2.794523239135742
Validation loss: 2.084421157836914

Epoch: 5| Step: 1
Training loss: 1.3547694683074951
Validation loss: 2.112767448027929

Epoch: 5| Step: 2
Training loss: 2.2510013580322266
Validation loss: 2.106617013613383

Epoch: 5| Step: 3
Training loss: 1.442886233329773
Validation loss: 2.0992063681284585

Epoch: 5| Step: 4
Training loss: 2.5564005374908447
Validation loss: 2.1246570299069085

Epoch: 5| Step: 5
Training loss: 1.6737849712371826
Validation loss: 2.1007483700911203

Epoch: 5| Step: 6
Training loss: 1.7849016189575195
Validation loss: 2.101093610127767

Epoch: 5| Step: 7
Training loss: 1.729575753211975
Validation loss: 2.1077712923288345

Epoch: 5| Step: 8
Training loss: 1.5276286602020264
Validation loss: 2.1481171449025473

Epoch: 5| Step: 9
Training loss: 2.372063398361206
Validation loss: 2.124225596586863

Epoch: 5| Step: 10
Training loss: 2.132812976837158
Validation loss: 2.1426594456036887

Epoch: 5| Step: 11
Training loss: 1.0631271600723267
Validation loss: 2.1337387363115945

Epoch: 36| Step: 0
Training loss: 1.7567188739776611
Validation loss: 2.1331691096226373

Epoch: 5| Step: 1
Training loss: 2.247044086456299
Validation loss: 2.131300538778305

Epoch: 5| Step: 2
Training loss: 2.4993462562561035
Validation loss: 2.174574459592501

Epoch: 5| Step: 3
Training loss: 1.674913763999939
Validation loss: 2.1216454108556113

Epoch: 5| Step: 4
Training loss: 1.9244937896728516
Validation loss: 2.116373583674431

Epoch: 5| Step: 5
Training loss: 2.3477704524993896
Validation loss: 2.168990135192871

Epoch: 5| Step: 6
Training loss: 1.4783399105072021
Validation loss: 2.1320342967907586

Epoch: 5| Step: 7
Training loss: 2.282688617706299
Validation loss: 2.138304670651754

Epoch: 5| Step: 8
Training loss: 1.7629940509796143
Validation loss: 2.161364118258158

Epoch: 5| Step: 9
Training loss: 1.7338268756866455
Validation loss: 2.1293333023786545

Epoch: 5| Step: 10
Training loss: 2.1181588172912598
Validation loss: 2.094330926736196

Epoch: 5| Step: 11
Training loss: 0.44302302598953247
Validation loss: 2.090322588880857

Epoch: 37| Step: 0
Training loss: 2.0101399421691895
Validation loss: 2.0802276929219565

Epoch: 5| Step: 1
Training loss: 2.243873119354248
Validation loss: 2.101458191871643

Epoch: 5| Step: 2
Training loss: 2.2203614711761475
Validation loss: 2.1059204836686454

Epoch: 5| Step: 3
Training loss: 2.2629847526550293
Validation loss: 2.10662334660689

Epoch: 5| Step: 4
Training loss: 1.8193676471710205
Validation loss: 2.0987410296996436

Epoch: 5| Step: 5
Training loss: 1.9069099426269531
Validation loss: 2.160839701692263

Epoch: 5| Step: 6
Training loss: 1.361101746559143
Validation loss: 2.122681344548861

Epoch: 5| Step: 7
Training loss: 1.643092393875122
Validation loss: 2.152132843931516

Epoch: 5| Step: 8
Training loss: 2.3327372074127197
Validation loss: 2.1630944361289344

Epoch: 5| Step: 9
Training loss: 2.029594898223877
Validation loss: 2.137434735894203

Epoch: 5| Step: 10
Training loss: 1.63497793674469
Validation loss: 2.073268567522367

Epoch: 5| Step: 11
Training loss: 1.667578935623169
Validation loss: 2.123804286122322

Epoch: 38| Step: 0
Training loss: 1.4478628635406494
Validation loss: 2.0714299231767654

Epoch: 5| Step: 1
Training loss: 2.3268439769744873
Validation loss: 2.0938577403624854

Epoch: 5| Step: 2
Training loss: 2.6274795532226562
Validation loss: 2.087794542312622

Epoch: 5| Step: 3
Training loss: 1.8233776092529297
Validation loss: 2.0661581406990686

Epoch: 5| Step: 4
Training loss: 2.0845048427581787
Validation loss: 2.0780161221822104

Epoch: 5| Step: 5
Training loss: 1.955163598060608
Validation loss: 2.1041030337413154

Epoch: 5| Step: 6
Training loss: 1.8712917566299438
Validation loss: 2.1152254541714988

Epoch: 5| Step: 7
Training loss: 2.370011568069458
Validation loss: 2.0891389548778534

Epoch: 5| Step: 8
Training loss: 1.7818546295166016
Validation loss: 2.1155698150396347

Epoch: 5| Step: 9
Training loss: 1.6775703430175781
Validation loss: 2.0839317987362542

Epoch: 5| Step: 10
Training loss: 1.587942123413086
Validation loss: 2.089303955435753

Epoch: 5| Step: 11
Training loss: 1.4023176431655884
Validation loss: 2.139962231119474

Epoch: 39| Step: 0
Training loss: 2.0088534355163574
Validation loss: 2.0702875604232154

Epoch: 5| Step: 1
Training loss: 1.7308368682861328
Validation loss: 2.1070541938145957

Epoch: 5| Step: 2
Training loss: 1.6932060718536377
Validation loss: 2.0689272582530975

Epoch: 5| Step: 3
Training loss: 2.1071219444274902
Validation loss: 2.178007443745931

Epoch: 5| Step: 4
Training loss: 1.9498450756072998
Validation loss: 2.1102790534496307

Epoch: 5| Step: 5
Training loss: 1.9783588647842407
Validation loss: 2.143150900801023

Epoch: 5| Step: 6
Training loss: 2.4243130683898926
Validation loss: 2.140807628631592

Epoch: 5| Step: 7
Training loss: 1.886389136314392
Validation loss: 2.1236042032639184

Epoch: 5| Step: 8
Training loss: 2.6071853637695312
Validation loss: 2.0899400959412255

Epoch: 5| Step: 9
Training loss: 1.8452094793319702
Validation loss: 2.0653605858484902

Epoch: 5| Step: 10
Training loss: 2.045335292816162
Validation loss: 2.1048831741015115

Epoch: 5| Step: 11
Training loss: 1.4578940868377686
Validation loss: 2.122244030237198

Epoch: 40| Step: 0
Training loss: 2.4923176765441895
Validation loss: 2.0933289527893066

Epoch: 5| Step: 1
Training loss: 1.7064917087554932
Validation loss: 2.073806251088778

Epoch: 5| Step: 2
Training loss: 1.8407357931137085
Validation loss: 2.1528014888366065

Epoch: 5| Step: 3
Training loss: 2.083517551422119
Validation loss: 2.115196923414866

Epoch: 5| Step: 4
Training loss: 1.9114195108413696
Validation loss: 2.139084686835607

Epoch: 5| Step: 5
Training loss: 1.6220617294311523
Validation loss: 2.125084231297175

Epoch: 5| Step: 6
Training loss: 2.338566780090332
Validation loss: 2.13850628832976

Epoch: 5| Step: 7
Training loss: 1.320293664932251
Validation loss: 2.1192046403884888

Epoch: 5| Step: 8
Training loss: 1.5265891551971436
Validation loss: 2.1104923635721207

Epoch: 5| Step: 9
Training loss: 2.008209228515625
Validation loss: 2.185029168923696

Epoch: 5| Step: 10
Training loss: 1.9543956518173218
Validation loss: 2.1249011854330697

Epoch: 5| Step: 11
Training loss: 2.4160993099212646
Validation loss: 2.1596616059541702

Epoch: 41| Step: 0
Training loss: 2.235182285308838
Validation loss: 2.136400351921717

Epoch: 5| Step: 1
Training loss: 1.8830268383026123
Validation loss: 2.1232060293356576

Epoch: 5| Step: 2
Training loss: 1.4917179346084595
Validation loss: 2.1463975658019385

Epoch: 5| Step: 3
Training loss: 2.039792537689209
Validation loss: 2.123800834019979

Epoch: 5| Step: 4
Training loss: 1.9878532886505127
Validation loss: 2.145724266767502

Epoch: 5| Step: 5
Training loss: 2.025170087814331
Validation loss: 2.0966976632674537

Epoch: 5| Step: 6
Training loss: 2.216146945953369
Validation loss: 2.072145327925682

Epoch: 5| Step: 7
Training loss: 2.158966064453125
Validation loss: 2.0609921365976334

Epoch: 5| Step: 8
Training loss: 1.8296045064926147
Validation loss: 2.132241686185201

Epoch: 5| Step: 9
Training loss: 1.386115312576294
Validation loss: 2.1243146707614264

Epoch: 5| Step: 10
Training loss: 1.4906976222991943
Validation loss: 2.0921033223470054

Epoch: 5| Step: 11
Training loss: 2.5063633918762207
Validation loss: 2.0942772924900055

Epoch: 42| Step: 0
Training loss: 2.2563562393188477
Validation loss: 2.152567997574806

Epoch: 5| Step: 1
Training loss: 1.9520454406738281
Validation loss: 2.068511148293813

Epoch: 5| Step: 2
Training loss: 1.7444400787353516
Validation loss: 2.1467118759950004

Epoch: 5| Step: 3
Training loss: 1.866438627243042
Validation loss: 2.1331898818413415

Epoch: 5| Step: 4
Training loss: 1.1375973224639893
Validation loss: 2.122533932328224

Epoch: 5| Step: 5
Training loss: 2.782352924346924
Validation loss: 2.106905907392502

Epoch: 5| Step: 6
Training loss: 1.4530500173568726
Validation loss: 2.1615920861562095

Epoch: 5| Step: 7
Training loss: 1.536812663078308
Validation loss: 2.138523285587629

Epoch: 5| Step: 8
Training loss: 2.5752816200256348
Validation loss: 2.160183697938919

Epoch: 5| Step: 9
Training loss: 2.462308406829834
Validation loss: 2.1870605846246085

Epoch: 5| Step: 10
Training loss: 1.0937618017196655
Validation loss: 2.1846652130285897

Epoch: 5| Step: 11
Training loss: 2.596078395843506
Validation loss: 2.0935829977194467

Epoch: 43| Step: 0
Training loss: 1.655236005783081
Validation loss: 2.1065007001161575

Epoch: 5| Step: 1
Training loss: 2.0639545917510986
Validation loss: 2.090585475166639

Epoch: 5| Step: 2
Training loss: 2.342407703399658
Validation loss: 2.073935920993487

Epoch: 5| Step: 3
Training loss: 2.3928654193878174
Validation loss: 2.111515169342359

Epoch: 5| Step: 4
Training loss: 2.1971967220306396
Validation loss: 2.110729143023491

Epoch: 5| Step: 5
Training loss: 1.608696699142456
Validation loss: 2.0535077502330146

Epoch: 5| Step: 6
Training loss: 1.6945464611053467
Validation loss: 2.0963786790768304

Epoch: 5| Step: 7
Training loss: 2.1289799213409424
Validation loss: 2.1384247392416

Epoch: 5| Step: 8
Training loss: 1.7274830341339111
Validation loss: 2.094598134358724

Epoch: 5| Step: 9
Training loss: 1.6532284021377563
Validation loss: 2.1213401506344476

Epoch: 5| Step: 10
Training loss: 1.6995245218276978
Validation loss: 2.135750080148379

Epoch: 5| Step: 11
Training loss: 2.3838653564453125
Validation loss: 2.04618668059508

Epoch: 44| Step: 0
Training loss: 1.5214755535125732
Validation loss: 2.1128397434949875

Epoch: 5| Step: 1
Training loss: 1.612839937210083
Validation loss: 2.170424590508143

Epoch: 5| Step: 2
Training loss: 2.447591781616211
Validation loss: 2.1486643652121225

Epoch: 5| Step: 3
Training loss: 1.9631643295288086
Validation loss: 2.15282208720843

Epoch: 5| Step: 4
Training loss: 1.985113501548767
Validation loss: 2.125724107027054

Epoch: 5| Step: 5
Training loss: 1.8095824718475342
Validation loss: 2.1291598776976266

Epoch: 5| Step: 6
Training loss: 1.637234091758728
Validation loss: 2.134792963663737

Epoch: 5| Step: 7
Training loss: 1.9511607885360718
Validation loss: 2.1053014248609543

Epoch: 5| Step: 8
Training loss: 1.9979358911514282
Validation loss: 2.0564323365688324

Epoch: 5| Step: 9
Training loss: 2.1187918186187744
Validation loss: 2.1044280578692756

Epoch: 5| Step: 10
Training loss: 2.1635375022888184
Validation loss: 2.0877635776996613

Epoch: 5| Step: 11
Training loss: 1.9016687870025635
Validation loss: 2.1310026546319327

Epoch: 45| Step: 0
Training loss: 1.6806236505508423
Validation loss: 2.085815201203028

Epoch: 5| Step: 1
Training loss: 2.2466564178466797
Validation loss: 2.1226880848407745

Epoch: 5| Step: 2
Training loss: 1.6869919300079346
Validation loss: 2.2031611800193787

Epoch: 5| Step: 3
Training loss: 1.7346222400665283
Validation loss: 2.195315033197403

Epoch: 5| Step: 4
Training loss: 1.827919602394104
Validation loss: 2.2244436840216317

Epoch: 5| Step: 5
Training loss: 1.8143246173858643
Validation loss: 2.2770317792892456

Epoch: 5| Step: 6
Training loss: 1.8557426929473877
Validation loss: 2.233851740757624

Epoch: 5| Step: 7
Training loss: 2.3691933155059814
Validation loss: 2.2162556499242783

Epoch: 5| Step: 8
Training loss: 1.7646710872650146
Validation loss: 2.2020267794529595

Epoch: 5| Step: 9
Training loss: 1.975012183189392
Validation loss: 2.1512547731399536

Epoch: 5| Step: 10
Training loss: 2.42702317237854
Validation loss: 2.2204887121915817

Epoch: 5| Step: 11
Training loss: 1.5383143424987793
Validation loss: 2.073220133781433

Epoch: 46| Step: 0
Training loss: 2.7160263061523438
Validation loss: 2.098263988892237

Epoch: 5| Step: 1
Training loss: 2.133673667907715
Validation loss: 2.101707845926285

Epoch: 5| Step: 2
Training loss: 1.7478444576263428
Validation loss: 2.1511116325855255

Epoch: 5| Step: 3
Training loss: 2.3690896034240723
Validation loss: 2.180321683486303

Epoch: 5| Step: 4
Training loss: 1.9936281442642212
Validation loss: 2.1068168679873147

Epoch: 5| Step: 5
Training loss: 1.6506820917129517
Validation loss: 2.0681471625963845

Epoch: 5| Step: 6
Training loss: 1.9882094860076904
Validation loss: 2.159403627117475

Epoch: 5| Step: 7
Training loss: 1.492159128189087
Validation loss: 2.1236007859309516

Epoch: 5| Step: 8
Training loss: 1.7003090381622314
Validation loss: 2.0869084000587463

Epoch: 5| Step: 9
Training loss: 1.5738134384155273
Validation loss: 2.0674317479133606

Epoch: 5| Step: 10
Training loss: 2.102781295776367
Validation loss: 2.0706610729297004

Epoch: 5| Step: 11
Training loss: 1.9252374172210693
Validation loss: 2.0683498879273734

Epoch: 47| Step: 0
Training loss: 1.9785022735595703
Validation loss: 2.1096153954664865

Epoch: 5| Step: 1
Training loss: 1.3285853862762451
Validation loss: 2.135601361592611

Epoch: 5| Step: 2
Training loss: 1.8658955097198486
Validation loss: 2.137819687525431

Epoch: 5| Step: 3
Training loss: 1.9614813327789307
Validation loss: 2.1425164341926575

Epoch: 5| Step: 4
Training loss: 1.4377838373184204
Validation loss: 2.100254644950231

Epoch: 5| Step: 5
Training loss: 2.0061957836151123
Validation loss: 2.083612804611524

Epoch: 5| Step: 6
Training loss: 1.400463342666626
Validation loss: 2.077015459537506

Epoch: 5| Step: 7
Training loss: 2.2347571849823
Validation loss: 2.1026697109142938

Epoch: 5| Step: 8
Training loss: 1.4966099262237549
Validation loss: 2.1000073750813804

Epoch: 5| Step: 9
Training loss: 3.06272292137146
Validation loss: 2.0874412010113397

Epoch: 5| Step: 10
Training loss: 1.744179129600525
Validation loss: 2.1336490909258523

Epoch: 5| Step: 11
Training loss: 1.1532145738601685
Validation loss: 2.117379436890284

Epoch: 48| Step: 0
Training loss: 1.4337422847747803
Validation loss: 2.046079456806183

Epoch: 5| Step: 1
Training loss: 2.158582925796509
Validation loss: 2.1544807453950248

Epoch: 5| Step: 2
Training loss: 2.1971046924591064
Validation loss: 2.1138258824745813

Epoch: 5| Step: 3
Training loss: 2.008092164993286
Validation loss: 2.1858357985814414

Epoch: 5| Step: 4
Training loss: 1.8478111028671265
Validation loss: 2.2011738419532776

Epoch: 5| Step: 5
Training loss: 1.9627685546875
Validation loss: 2.1571542024612427

Epoch: 5| Step: 6
Training loss: 1.92475163936615
Validation loss: 2.232728267709414

Epoch: 5| Step: 7
Training loss: 1.8517059087753296
Validation loss: 2.2503096958001456

Epoch: 5| Step: 8
Training loss: 1.5389792919158936
Validation loss: 2.173805962006251

Epoch: 5| Step: 9
Training loss: 1.6672815084457397
Validation loss: 2.1852460900942483

Epoch: 5| Step: 10
Training loss: 2.4060463905334473
Validation loss: 2.1515741695960364

Epoch: 5| Step: 11
Training loss: 1.0679672956466675
Validation loss: 2.1337903241316476

Epoch: 49| Step: 0
Training loss: 1.4264376163482666
Validation loss: 2.1561831583579383

Epoch: 5| Step: 1
Training loss: 1.7909495830535889
Validation loss: 2.1399023284514747

Epoch: 5| Step: 2
Training loss: 1.9300161600112915
Validation loss: 2.103438859184583

Epoch: 5| Step: 3
Training loss: 1.4077199697494507
Validation loss: 2.1082667907079062

Epoch: 5| Step: 4
Training loss: 2.139472723007202
Validation loss: 2.1853466232617698

Epoch: 5| Step: 5
Training loss: 1.4451802968978882
Validation loss: 2.143726055820783

Epoch: 5| Step: 6
Training loss: 1.4955549240112305
Validation loss: 2.1501264770825705

Epoch: 5| Step: 7
Training loss: 2.473926067352295
Validation loss: 2.085102175672849

Epoch: 5| Step: 8
Training loss: 1.7976186275482178
Validation loss: 2.069446807106336

Epoch: 5| Step: 9
Training loss: 2.1431989669799805
Validation loss: 2.0893619706233344

Epoch: 5| Step: 10
Training loss: 2.215132474899292
Validation loss: 2.138746624191602

Epoch: 5| Step: 11
Training loss: 0.8562600612640381
Validation loss: 2.060817336042722

Epoch: 50| Step: 0
Training loss: 2.1805641651153564
Validation loss: 2.106631542245547

Epoch: 5| Step: 1
Training loss: 1.2483160495758057
Validation loss: 2.096423094471296

Epoch: 5| Step: 2
Training loss: 2.0391485691070557
Validation loss: 2.0762667109568915

Epoch: 5| Step: 3
Training loss: 2.1654014587402344
Validation loss: 2.13509209950765

Epoch: 5| Step: 4
Training loss: 0.9687053561210632
Validation loss: 2.170048162341118

Epoch: 5| Step: 5
Training loss: 1.9696102142333984
Validation loss: 2.1079544574022293

Epoch: 5| Step: 6
Training loss: 1.9148905277252197
Validation loss: 2.1185930420955024

Epoch: 5| Step: 7
Training loss: 2.353452682495117
Validation loss: 2.1610659460226693

Epoch: 5| Step: 8
Training loss: 1.7230775356292725
Validation loss: 2.2137880523999534

Epoch: 5| Step: 9
Training loss: 1.8899335861206055
Validation loss: 2.1370217005411782

Epoch: 5| Step: 10
Training loss: 1.9994739294052124
Validation loss: 2.1010505060354867

Epoch: 5| Step: 11
Training loss: 2.485074043273926
Validation loss: 2.141070857644081

Epoch: 51| Step: 0
Training loss: 1.6891075372695923
Validation loss: 2.1001016100247702

Epoch: 5| Step: 1
Training loss: 2.310636281967163
Validation loss: 2.0773013879855475

Epoch: 5| Step: 2
Training loss: 2.228541851043701
Validation loss: 2.115503042936325

Epoch: 5| Step: 3
Training loss: 2.158250570297241
Validation loss: 2.159597044189771

Epoch: 5| Step: 4
Training loss: 2.4939050674438477
Validation loss: 2.095527316133181

Epoch: 5| Step: 5
Training loss: 1.3529630899429321
Validation loss: 2.1068732291460037

Epoch: 5| Step: 6
Training loss: 2.1410410404205322
Validation loss: 2.1629746903975806

Epoch: 5| Step: 7
Training loss: 2.1118264198303223
Validation loss: 2.0714455296595893

Epoch: 5| Step: 8
Training loss: 2.161741256713867
Validation loss: 2.116580138603846

Epoch: 5| Step: 9
Training loss: 1.6659061908721924
Validation loss: 2.0723992586135864

Epoch: 5| Step: 10
Training loss: 1.1819558143615723
Validation loss: 2.1330822060505548

Epoch: 5| Step: 11
Training loss: 1.8319870233535767
Validation loss: 2.1668194035689035

Epoch: 52| Step: 0
Training loss: 2.106832504272461
Validation loss: 2.1781175235907235

Epoch: 5| Step: 1
Training loss: 2.2336692810058594
Validation loss: 2.1970667441685996

Epoch: 5| Step: 2
Training loss: 2.133308172225952
Validation loss: 2.2223017613093057

Epoch: 5| Step: 3
Training loss: 1.7986953258514404
Validation loss: 2.2042978703975677

Epoch: 5| Step: 4
Training loss: 1.3765650987625122
Validation loss: 2.17383149266243

Epoch: 5| Step: 5
Training loss: 2.2203588485717773
Validation loss: 2.1635816345612207

Epoch: 5| Step: 6
Training loss: 1.8881800174713135
Validation loss: 2.121716449658076

Epoch: 5| Step: 7
Training loss: 2.3327393531799316
Validation loss: 2.0731099595626197

Epoch: 5| Step: 8
Training loss: 1.5375943183898926
Validation loss: 2.118855973084768

Epoch: 5| Step: 9
Training loss: 1.9334745407104492
Validation loss: 2.0984472831090293

Epoch: 5| Step: 10
Training loss: 1.3080201148986816
Validation loss: 2.1026247342427573

Epoch: 5| Step: 11
Training loss: 1.8226679563522339
Validation loss: 2.0678416093190513

Epoch: 53| Step: 0
Training loss: 1.7444692850112915
Validation loss: 2.093873808781306

Epoch: 5| Step: 1
Training loss: 1.32952082157135
Validation loss: 2.1008697350819907

Epoch: 5| Step: 2
Training loss: 1.9829199314117432
Validation loss: 2.1027848025163016

Epoch: 5| Step: 3
Training loss: 1.8061091899871826
Validation loss: 2.1676831543445587

Epoch: 5| Step: 4
Training loss: 3.0338382720947266
Validation loss: 2.1247942000627518

Epoch: 5| Step: 5
Training loss: 2.0510218143463135
Validation loss: 2.1109458605448403

Epoch: 5| Step: 6
Training loss: 1.7178453207015991
Validation loss: 2.1232108970483146

Epoch: 5| Step: 7
Training loss: 1.9190009832382202
Validation loss: 2.12991971274217

Epoch: 5| Step: 8
Training loss: 1.9719200134277344
Validation loss: 2.0898019671440125

Epoch: 5| Step: 9
Training loss: 2.0398213863372803
Validation loss: 2.1130265096823373

Epoch: 5| Step: 10
Training loss: 1.1568729877471924
Validation loss: 2.11325012644132

Epoch: 5| Step: 11
Training loss: 0.7054376602172852
Validation loss: 2.1116572668155036

Epoch: 54| Step: 0
Training loss: 2.1336145401000977
Validation loss: 2.05637060602506

Epoch: 5| Step: 1
Training loss: 1.7017902135849
Validation loss: 2.1485310097535453

Epoch: 5| Step: 2
Training loss: 1.2847102880477905
Validation loss: 2.0516003469626107

Epoch: 5| Step: 3
Training loss: 2.020582675933838
Validation loss: 2.0884630382061005

Epoch: 5| Step: 4
Training loss: 2.0277230739593506
Validation loss: 2.114872728784879

Epoch: 5| Step: 5
Training loss: 1.9181654453277588
Validation loss: 2.0644521514574685

Epoch: 5| Step: 6
Training loss: 2.253674030303955
Validation loss: 2.0980254461367926

Epoch: 5| Step: 7
Training loss: 1.6273034811019897
Validation loss: 2.160270298520724

Epoch: 5| Step: 8
Training loss: 1.968131422996521
Validation loss: 2.1295390923817954

Epoch: 5| Step: 9
Training loss: 1.5391511917114258
Validation loss: 2.118130867679914

Epoch: 5| Step: 10
Training loss: 1.5306860208511353
Validation loss: 2.1092817385991416

Epoch: 5| Step: 11
Training loss: 1.2517409324645996
Validation loss: 2.0939364234606423

Epoch: 55| Step: 0
Training loss: 1.1007764339447021
Validation loss: 2.106014465292295

Epoch: 5| Step: 1
Training loss: 2.040269374847412
Validation loss: 2.0986169477303824

Epoch: 5| Step: 2
Training loss: 1.8981552124023438
Validation loss: 2.1005075623591742

Epoch: 5| Step: 3
Training loss: 1.671836256980896
Validation loss: 2.1289628048737845

Epoch: 5| Step: 4
Training loss: 2.2009520530700684
Validation loss: 2.1590125213066735

Epoch: 5| Step: 5
Training loss: 1.6866157054901123
Validation loss: 2.137757937113444

Epoch: 5| Step: 6
Training loss: 1.9337942600250244
Validation loss: 2.1082517156998315

Epoch: 5| Step: 7
Training loss: 2.070542812347412
Validation loss: 2.163544684648514

Epoch: 5| Step: 8
Training loss: 1.817615270614624
Validation loss: 2.1146732717752457

Epoch: 5| Step: 9
Training loss: 1.7149131298065186
Validation loss: 2.063010483980179

Epoch: 5| Step: 10
Training loss: 2.287839412689209
Validation loss: 2.0832532942295074

Epoch: 5| Step: 11
Training loss: 2.700700283050537
Validation loss: 2.0749440292517343

Epoch: 56| Step: 0
Training loss: 2.286893844604492
Validation loss: 2.1198103775580726

Epoch: 5| Step: 1
Training loss: 1.7936270236968994
Validation loss: 2.0655922343333564

Epoch: 5| Step: 2
Training loss: 1.9187695980072021
Validation loss: 2.099598859747251

Epoch: 5| Step: 3
Training loss: 1.449724555015564
Validation loss: 2.090859899918238

Epoch: 5| Step: 4
Training loss: 2.730644702911377
Validation loss: 2.0252593954404197

Epoch: 5| Step: 5
Training loss: 1.8774998188018799
Validation loss: 2.1253665884335837

Epoch: 5| Step: 6
Training loss: 1.7360293865203857
Validation loss: 2.1373859445254006

Epoch: 5| Step: 7
Training loss: 1.2155603170394897
Validation loss: 2.0877053340276084

Epoch: 5| Step: 8
Training loss: 1.5498106479644775
Validation loss: 2.148163457711538

Epoch: 5| Step: 9
Training loss: 1.9343538284301758
Validation loss: 2.1169247031211853

Epoch: 5| Step: 10
Training loss: 1.661102056503296
Validation loss: 2.1021509865919747

Epoch: 5| Step: 11
Training loss: 1.7194232940673828
Validation loss: 2.115049416820208

Epoch: 57| Step: 0
Training loss: 1.5495256185531616
Validation loss: 2.11160642405351

Epoch: 5| Step: 1
Training loss: 1.556638240814209
Validation loss: 2.1019795735677085

Epoch: 5| Step: 2
Training loss: 2.040332078933716
Validation loss: 2.1237438718477883

Epoch: 5| Step: 3
Training loss: 1.3903508186340332
Validation loss: 2.1458865255117416

Epoch: 5| Step: 4
Training loss: 2.2104623317718506
Validation loss: 2.1197171211242676

Epoch: 5| Step: 5
Training loss: 2.2757327556610107
Validation loss: 2.1050983667373657

Epoch: 5| Step: 6
Training loss: 2.105593204498291
Validation loss: 2.104626859227816

Epoch: 5| Step: 7
Training loss: 1.3844373226165771
Validation loss: 2.0847910741964975

Epoch: 5| Step: 8
Training loss: 1.8221759796142578
Validation loss: 2.062878727912903

Epoch: 5| Step: 9
Training loss: 2.0748116970062256
Validation loss: 2.101891666650772

Epoch: 5| Step: 10
Training loss: 1.5548540353775024
Validation loss: 2.123871371150017

Epoch: 5| Step: 11
Training loss: 1.8226029872894287
Validation loss: 2.0802874863147736

Epoch: 58| Step: 0
Training loss: 2.0291342735290527
Validation loss: 2.0796387046575546

Epoch: 5| Step: 1
Training loss: 1.4550601243972778
Validation loss: 2.1277556816736856

Epoch: 5| Step: 2
Training loss: 1.035398006439209
Validation loss: 2.1217391391595206

Epoch: 5| Step: 3
Training loss: 1.8280456066131592
Validation loss: 2.0813728272914886

Epoch: 5| Step: 4
Training loss: 1.8999462127685547
Validation loss: 2.024336184064547

Epoch: 5| Step: 5
Training loss: 1.8702901601791382
Validation loss: 2.088605751593908

Epoch: 5| Step: 6
Training loss: 2.0674266815185547
Validation loss: 2.067005937298139

Epoch: 5| Step: 7
Training loss: 1.5212922096252441
Validation loss: 2.075335909922918

Epoch: 5| Step: 8
Training loss: 2.4930529594421387
Validation loss: 2.09691991408666

Epoch: 5| Step: 9
Training loss: 2.3205361366271973
Validation loss: 2.0666406949361167

Epoch: 5| Step: 10
Training loss: 1.3864790201187134
Validation loss: 2.0750732322533927

Epoch: 5| Step: 11
Training loss: 2.3655312061309814
Validation loss: 2.102252577741941

Epoch: 59| Step: 0
Training loss: 2.0921709537506104
Validation loss: 2.0793330669403076

Epoch: 5| Step: 1
Training loss: 1.2587435245513916
Validation loss: 2.0701900323232016

Epoch: 5| Step: 2
Training loss: 2.12019419670105
Validation loss: 2.0745630959669747

Epoch: 5| Step: 3
Training loss: 1.6366935968399048
Validation loss: 2.065260464946429

Epoch: 5| Step: 4
Training loss: 2.537722110748291
Validation loss: 2.064659928282102

Epoch: 5| Step: 5
Training loss: 1.931044578552246
Validation loss: 2.118206520875295

Epoch: 5| Step: 6
Training loss: 1.715216875076294
Validation loss: 2.080215185880661

Epoch: 5| Step: 7
Training loss: 2.3024816513061523
Validation loss: 2.0550895631313324

Epoch: 5| Step: 8
Training loss: 1.3172800540924072
Validation loss: 2.0972748746474585

Epoch: 5| Step: 9
Training loss: 2.1115527153015137
Validation loss: 2.116363763809204

Epoch: 5| Step: 10
Training loss: 1.448792576789856
Validation loss: 2.0550914059082666

Epoch: 5| Step: 11
Training loss: 1.3416688442230225
Validation loss: 2.1383999983469644

Epoch: 60| Step: 0
Training loss: 1.7966060638427734
Validation loss: 2.135018969575564

Epoch: 5| Step: 1
Training loss: 1.6176540851593018
Validation loss: 2.121173972884814

Epoch: 5| Step: 2
Training loss: 1.9487073421478271
Validation loss: 2.133093630274137

Epoch: 5| Step: 3
Training loss: 1.9776121377944946
Validation loss: 2.121156613032023

Epoch: 5| Step: 4
Training loss: 2.6451234817504883
Validation loss: 2.140021195014318

Epoch: 5| Step: 5
Training loss: 1.6186851263046265
Validation loss: 2.1069740702708564

Epoch: 5| Step: 6
Training loss: 1.4196022748947144
Validation loss: 2.1229768296082816

Epoch: 5| Step: 7
Training loss: 1.7034368515014648
Validation loss: 2.1087529361248016

Epoch: 5| Step: 8
Training loss: 2.132275342941284
Validation loss: 2.076176404953003

Epoch: 5| Step: 9
Training loss: 1.5823417901992798
Validation loss: 2.143921042482058

Epoch: 5| Step: 10
Training loss: 1.5819921493530273
Validation loss: 2.090314586957296

Epoch: 5| Step: 11
Training loss: 1.2126516103744507
Validation loss: 2.0776501993338266

Epoch: 61| Step: 0
Training loss: 1.7105367183685303
Validation loss: 2.1055895586808524

Epoch: 5| Step: 1
Training loss: 1.536501169204712
Validation loss: 2.1232684751351676

Epoch: 5| Step: 2
Training loss: 1.780218482017517
Validation loss: 2.1305148601531982

Epoch: 5| Step: 3
Training loss: 1.8472731113433838
Validation loss: 2.1103557348251343

Epoch: 5| Step: 4
Training loss: 2.1614670753479004
Validation loss: 2.0574274361133575

Epoch: 5| Step: 5
Training loss: 1.653846025466919
Validation loss: 2.1092185328404107

Epoch: 5| Step: 6
Training loss: 1.8053786754608154
Validation loss: 2.116364379723867

Epoch: 5| Step: 7
Training loss: 1.8557465076446533
Validation loss: 2.0879422376553216

Epoch: 5| Step: 8
Training loss: 1.9643869400024414
Validation loss: 2.1348619063695273

Epoch: 5| Step: 9
Training loss: 1.4732544422149658
Validation loss: 2.02675099670887

Epoch: 5| Step: 10
Training loss: 1.5827547311782837
Validation loss: 2.031573330362638

Epoch: 5| Step: 11
Training loss: 1.2723991870880127
Validation loss: 2.079083258907

Epoch: 62| Step: 0
Training loss: 1.842613935470581
Validation loss: 2.0574073990186057

Epoch: 5| Step: 1
Training loss: 1.3339273929595947
Validation loss: 2.117178430159887

Epoch: 5| Step: 2
Training loss: 2.0081946849823
Validation loss: 2.1370168874661126

Epoch: 5| Step: 3
Training loss: 1.7435312271118164
Validation loss: 2.117694060007731

Epoch: 5| Step: 4
Training loss: 1.9543912410736084
Validation loss: 2.125586618979772

Epoch: 5| Step: 5
Training loss: 2.1474051475524902
Validation loss: 2.0848223666350045

Epoch: 5| Step: 6
Training loss: 2.0669755935668945
Validation loss: 2.140873904029528

Epoch: 5| Step: 7
Training loss: 1.6788839101791382
Validation loss: 2.1547811776399612

Epoch: 5| Step: 8
Training loss: 2.048738956451416
Validation loss: 2.1067197173833847

Epoch: 5| Step: 9
Training loss: 1.8338110446929932
Validation loss: 2.0733344902594886

Epoch: 5| Step: 10
Training loss: 1.1802974939346313
Validation loss: 2.1350832283496857

Epoch: 5| Step: 11
Training loss: 1.230137586593628
Validation loss: 2.028730501731237

Epoch: 63| Step: 0
Training loss: 2.233895778656006
Validation loss: 2.0116217881441116

Epoch: 5| Step: 1
Training loss: 1.413104772567749
Validation loss: 2.100493460893631

Epoch: 5| Step: 2
Training loss: 1.5303471088409424
Validation loss: 2.023946856458982

Epoch: 5| Step: 3
Training loss: 1.7267873287200928
Validation loss: 2.121757452686628

Epoch: 5| Step: 4
Training loss: 2.4380943775177
Validation loss: 2.159248406688372

Epoch: 5| Step: 5
Training loss: 1.4046413898468018
Validation loss: 2.1116195569435754

Epoch: 5| Step: 6
Training loss: 2.045109510421753
Validation loss: 2.0993762016296387

Epoch: 5| Step: 7
Training loss: 1.8551867008209229
Validation loss: 2.096348429719607

Epoch: 5| Step: 8
Training loss: 1.7008056640625
Validation loss: 2.0955282946427665

Epoch: 5| Step: 9
Training loss: 1.2479959726333618
Validation loss: 2.0629078845183053

Epoch: 5| Step: 10
Training loss: 2.152218818664551
Validation loss: 2.092532674471537

Epoch: 5| Step: 11
Training loss: 0.864388108253479
Validation loss: 2.097727964321772

Epoch: 64| Step: 0
Training loss: 2.1382415294647217
Validation loss: 2.1165834267934165

Epoch: 5| Step: 1
Training loss: 1.4132964611053467
Validation loss: 2.0985099226236343

Epoch: 5| Step: 2
Training loss: 2.5911643505096436
Validation loss: 2.148507992426554

Epoch: 5| Step: 3
Training loss: 1.2665753364562988
Validation loss: 2.110627685983976

Epoch: 5| Step: 4
Training loss: 1.5415910482406616
Validation loss: 2.1357451726992926

Epoch: 5| Step: 5
Training loss: 2.272301435470581
Validation loss: 2.147344802816709

Epoch: 5| Step: 6
Training loss: 1.646999716758728
Validation loss: 2.142782300710678

Epoch: 5| Step: 7
Training loss: 1.8131107091903687
Validation loss: 2.1048421065012612

Epoch: 5| Step: 8
Training loss: 1.6030826568603516
Validation loss: 1.9975612610578537

Epoch: 5| Step: 9
Training loss: 1.650316596031189
Validation loss: 2.079560394088427

Epoch: 5| Step: 10
Training loss: 1.691286325454712
Validation loss: 2.0790539930264154

Epoch: 5| Step: 11
Training loss: 1.0638763904571533
Validation loss: 2.0991902947425842

Epoch: 65| Step: 0
Training loss: 2.004960775375366
Validation loss: 2.0840175449848175

Epoch: 5| Step: 1
Training loss: 2.1632156372070312
Validation loss: 2.1115156511465707

Epoch: 5| Step: 2
Training loss: 2.339493751525879
Validation loss: 2.098129133383433

Epoch: 5| Step: 3
Training loss: 1.8737154006958008
Validation loss: 2.1262721518675485

Epoch: 5| Step: 4
Training loss: 1.5927568674087524
Validation loss: 2.130687932173411

Epoch: 5| Step: 5
Training loss: 1.537768840789795
Validation loss: 2.13031675418218

Epoch: 5| Step: 6
Training loss: 1.6261873245239258
Validation loss: 2.1390378922224045

Epoch: 5| Step: 7
Training loss: 2.3746254444122314
Validation loss: 2.1508904496828714

Epoch: 5| Step: 8
Training loss: 1.676482915878296
Validation loss: 2.144996096690496

Epoch: 5| Step: 9
Training loss: 1.4005887508392334
Validation loss: 2.08365790049235

Epoch: 5| Step: 10
Training loss: 1.6208616495132446
Validation loss: 2.099072446425756

Epoch: 5| Step: 11
Training loss: 0.5389782190322876
Validation loss: 2.143761729200681

Epoch: 66| Step: 0
Training loss: 1.9355747699737549
Validation loss: 2.0463779866695404

Epoch: 5| Step: 1
Training loss: 1.8851715326309204
Validation loss: 2.1004433631896973

Epoch: 5| Step: 2
Training loss: 1.4277408123016357
Validation loss: 2.0981848736604056

Epoch: 5| Step: 3
Training loss: 1.6373798847198486
Validation loss: 2.072770982980728

Epoch: 5| Step: 4
Training loss: 1.6780054569244385
Validation loss: 2.046189417441686

Epoch: 5| Step: 5
Training loss: 1.8922016620635986
Validation loss: 2.061625892917315

Epoch: 5| Step: 6
Training loss: 2.1571075916290283
Validation loss: 2.0934420128663382

Epoch: 5| Step: 7
Training loss: 1.4990277290344238
Validation loss: 2.09538467725118

Epoch: 5| Step: 8
Training loss: 1.5975016355514526
Validation loss: 2.013732294241587

Epoch: 5| Step: 9
Training loss: 1.9952472448349
Validation loss: 2.0953975717226663

Epoch: 5| Step: 10
Training loss: 1.7062103748321533
Validation loss: 2.116376370191574

Epoch: 5| Step: 11
Training loss: 0.8574391007423401
Validation loss: 2.1245646476745605

Epoch: 67| Step: 0
Training loss: 1.6229770183563232
Validation loss: 2.0894044637680054

Epoch: 5| Step: 1
Training loss: 1.4586329460144043
Validation loss: 2.1401846458514533

Epoch: 5| Step: 2
Training loss: 1.1228604316711426
Validation loss: 2.069365675250689

Epoch: 5| Step: 3
Training loss: 1.7888323068618774
Validation loss: 2.0939302494128547

Epoch: 5| Step: 4
Training loss: 1.8511947393417358
Validation loss: 2.149816726644834

Epoch: 5| Step: 5
Training loss: 2.0936312675476074
Validation loss: 2.1381770074367523

Epoch: 5| Step: 6
Training loss: 1.8763084411621094
Validation loss: 2.1573056230942407

Epoch: 5| Step: 7
Training loss: 1.9273380041122437
Validation loss: 2.090846836566925

Epoch: 5| Step: 8
Training loss: 1.791608452796936
Validation loss: 2.0964108258485794

Epoch: 5| Step: 9
Training loss: 1.8396809101104736
Validation loss: 2.0827798545360565

Epoch: 5| Step: 10
Training loss: 2.1696667671203613
Validation loss: 2.0452612539132438

Epoch: 5| Step: 11
Training loss: 1.5372414588928223
Validation loss: 2.094946468869845

Epoch: 68| Step: 0
Training loss: 1.464914083480835
Validation loss: 2.0521103342374167

Epoch: 5| Step: 1
Training loss: 2.117626190185547
Validation loss: 2.0967596073945365

Epoch: 5| Step: 2
Training loss: 2.239347457885742
Validation loss: 2.006226768096288

Epoch: 5| Step: 3
Training loss: 1.575926423072815
Validation loss: 2.070029785235723

Epoch: 5| Step: 4
Training loss: 2.2200114727020264
Validation loss: 2.0449110517899194

Epoch: 5| Step: 5
Training loss: 1.6053135395050049
Validation loss: 2.0233541429042816

Epoch: 5| Step: 6
Training loss: 1.343788504600525
Validation loss: 2.05428775648276

Epoch: 5| Step: 7
Training loss: 2.239727020263672
Validation loss: 2.0474837770064673

Epoch: 5| Step: 8
Training loss: 1.3436400890350342
Validation loss: 2.0784344524145126

Epoch: 5| Step: 9
Training loss: 1.2422345876693726
Validation loss: 2.144311706225077

Epoch: 5| Step: 10
Training loss: 1.967738389968872
Validation loss: 2.1661714712778726

Epoch: 5| Step: 11
Training loss: 2.036252021789551
Validation loss: 2.2464495499928794

Epoch: 69| Step: 0
Training loss: 2.8917250633239746
Validation loss: 2.290130684773127

Epoch: 5| Step: 1
Training loss: 1.5438483953475952
Validation loss: 2.2857857843240104

Epoch: 5| Step: 2
Training loss: 1.6409971714019775
Validation loss: 2.2947208682696023

Epoch: 5| Step: 3
Training loss: 1.8293063640594482
Validation loss: 2.1538169284661612

Epoch: 5| Step: 4
Training loss: 1.6115039587020874
Validation loss: 2.135840599735578

Epoch: 5| Step: 5
Training loss: 1.7533397674560547
Validation loss: 2.1924367249011993

Epoch: 5| Step: 6
Training loss: 1.649237871170044
Validation loss: 2.110471079746882

Epoch: 5| Step: 7
Training loss: 1.527795433998108
Validation loss: 2.089023689428965

Epoch: 5| Step: 8
Training loss: 2.044534683227539
Validation loss: 2.047077476978302

Epoch: 5| Step: 9
Training loss: 1.8532253503799438
Validation loss: 1.9882820745309193

Epoch: 5| Step: 10
Training loss: 2.2695260047912598
Validation loss: 2.030680244167646

Epoch: 5| Step: 11
Training loss: 1.103610634803772
Validation loss: 2.023975516359011

Epoch: 70| Step: 0
Training loss: 1.4060907363891602
Validation loss: 2.0470093488693237

Epoch: 5| Step: 1
Training loss: 1.8370215892791748
Validation loss: 2.0730684995651245

Epoch: 5| Step: 2
Training loss: 1.992796540260315
Validation loss: 2.0634194711844125

Epoch: 5| Step: 3
Training loss: 1.6862993240356445
Validation loss: 2.1798517604668937

Epoch: 5| Step: 4
Training loss: 1.9765632152557373
Validation loss: 2.2246149679025016

Epoch: 5| Step: 5
Training loss: 2.1221911907196045
Validation loss: 2.16952183842659

Epoch: 5| Step: 6
Training loss: 1.5964463949203491
Validation loss: 2.1836500068505607

Epoch: 5| Step: 7
Training loss: 2.0504374504089355
Validation loss: 2.1527234812577567

Epoch: 5| Step: 8
Training loss: 1.6297365427017212
Validation loss: 2.062214568257332

Epoch: 5| Step: 9
Training loss: 1.2475106716156006
Validation loss: 2.076122393210729

Epoch: 5| Step: 10
Training loss: 2.1640145778656006
Validation loss: 2.0341915488243103

Epoch: 5| Step: 11
Training loss: 1.2951371669769287
Validation loss: 2.0960206588109336

Epoch: 71| Step: 0
Training loss: 1.5197430849075317
Validation loss: 2.099852576851845

Epoch: 5| Step: 1
Training loss: 2.046616792678833
Validation loss: 2.0918515423933663

Epoch: 5| Step: 2
Training loss: 1.423923134803772
Validation loss: 2.051531950632731

Epoch: 5| Step: 3
Training loss: 2.2431979179382324
Validation loss: 2.1102894792954126

Epoch: 5| Step: 4
Training loss: 1.5747655630111694
Validation loss: 2.0569185664256415

Epoch: 5| Step: 5
Training loss: 1.3516337871551514
Validation loss: 2.0899152954419455

Epoch: 5| Step: 6
Training loss: 2.1035423278808594
Validation loss: 2.046626756588618

Epoch: 5| Step: 7
Training loss: 1.7536941766738892
Validation loss: 2.101247807343801

Epoch: 5| Step: 8
Training loss: 1.599653959274292
Validation loss: 2.1305690308411918

Epoch: 5| Step: 9
Training loss: 1.9317958354949951
Validation loss: 2.118672400712967

Epoch: 5| Step: 10
Training loss: 1.7792097330093384
Validation loss: 2.1402160028616586

Epoch: 5| Step: 11
Training loss: 0.6492348313331604
Validation loss: 2.08871591091156

Epoch: 72| Step: 0
Training loss: 1.9958709478378296
Validation loss: 2.1175171931584678

Epoch: 5| Step: 1
Training loss: 1.519940733909607
Validation loss: 2.104184533158938

Epoch: 5| Step: 2
Training loss: 1.8044087886810303
Validation loss: 2.144786844650904

Epoch: 5| Step: 3
Training loss: 2.0604538917541504
Validation loss: 2.0111804753541946

Epoch: 5| Step: 4
Training loss: 1.8891534805297852
Validation loss: 2.088610718647639

Epoch: 5| Step: 5
Training loss: 1.6447067260742188
Validation loss: 2.0502708107233047

Epoch: 5| Step: 6
Training loss: 2.0834405422210693
Validation loss: 2.028709292411804

Epoch: 5| Step: 7
Training loss: 1.9075889587402344
Validation loss: 2.0354599157969155

Epoch: 5| Step: 8
Training loss: 1.4505748748779297
Validation loss: 2.1023457646369934

Epoch: 5| Step: 9
Training loss: 2.022047758102417
Validation loss: 2.0404035250345864

Epoch: 5| Step: 10
Training loss: 1.3646824359893799
Validation loss: 2.0927845438321433

Epoch: 5| Step: 11
Training loss: 2.3067779541015625
Validation loss: 2.0867504477500916

Epoch: 73| Step: 0
Training loss: 1.8772122859954834
Validation loss: 2.049815908074379

Epoch: 5| Step: 1
Training loss: 1.187748670578003
Validation loss: 2.0971281876166663

Epoch: 5| Step: 2
Training loss: 2.432968854904175
Validation loss: 2.177480106552442

Epoch: 5| Step: 3
Training loss: 1.7075932025909424
Validation loss: 2.182300200064977

Epoch: 5| Step: 4
Training loss: 1.3762277364730835
Validation loss: 2.173856422305107

Epoch: 5| Step: 5
Training loss: 2.1860592365264893
Validation loss: 2.1850713590780892

Epoch: 5| Step: 6
Training loss: 2.09187912940979
Validation loss: 2.1362477391958237

Epoch: 5| Step: 7
Training loss: 1.842034935951233
Validation loss: 2.0900058646996817

Epoch: 5| Step: 8
Training loss: 1.5579630136489868
Validation loss: 2.100727920730909

Epoch: 5| Step: 9
Training loss: 1.7841434478759766
Validation loss: 2.0105392932891846

Epoch: 5| Step: 10
Training loss: 1.816450834274292
Validation loss: 2.0497038662433624

Epoch: 5| Step: 11
Training loss: 1.9457882642745972
Validation loss: 2.057229166229566

Epoch: 74| Step: 0
Training loss: 1.8812437057495117
Validation loss: 2.0236132691303887

Epoch: 5| Step: 1
Training loss: 1.4063962697982788
Validation loss: 2.0548351307710013

Epoch: 5| Step: 2
Training loss: 1.6974529027938843
Validation loss: 2.0303292075792947

Epoch: 5| Step: 3
Training loss: 1.7606576681137085
Validation loss: 2.039125223954519

Epoch: 5| Step: 4
Training loss: 1.3264634609222412
Validation loss: 2.0088694343964257

Epoch: 5| Step: 5
Training loss: 2.4580092430114746
Validation loss: 2.0774784485499063

Epoch: 5| Step: 6
Training loss: 1.505124807357788
Validation loss: 2.0876405239105225

Epoch: 5| Step: 7
Training loss: 1.9543094635009766
Validation loss: 2.133172939221064

Epoch: 5| Step: 8
Training loss: 1.3739782571792603
Validation loss: 2.0746324757734933

Epoch: 5| Step: 9
Training loss: 2.062086820602417
Validation loss: 2.0870219667752585

Epoch: 5| Step: 10
Training loss: 1.7349669933319092
Validation loss: 2.1630917489528656

Epoch: 5| Step: 11
Training loss: 2.076784610748291
Validation loss: 2.13832979897658

Epoch: 75| Step: 0
Training loss: 1.779219388961792
Validation loss: 2.1292091061671576

Epoch: 5| Step: 1
Training loss: 1.4653011560440063
Validation loss: 2.117302507162094

Epoch: 5| Step: 2
Training loss: 1.9018363952636719
Validation loss: 2.0734407355388007

Epoch: 5| Step: 3
Training loss: 1.335986852645874
Validation loss: 2.0659332474072776

Epoch: 5| Step: 4
Training loss: 1.7493339776992798
Validation loss: 2.0966826379299164

Epoch: 5| Step: 5
Training loss: 1.2452218532562256
Validation loss: 2.105954095721245

Epoch: 5| Step: 6
Training loss: 1.4714399576187134
Validation loss: 2.054711192846298

Epoch: 5| Step: 7
Training loss: 1.6346778869628906
Validation loss: 2.0015682776769004

Epoch: 5| Step: 8
Training loss: 2.516543388366699
Validation loss: 2.097874174515406

Epoch: 5| Step: 9
Training loss: 1.856339693069458
Validation loss: 2.068068578839302

Epoch: 5| Step: 10
Training loss: 1.9139610528945923
Validation loss: 2.0799613694349923

Epoch: 5| Step: 11
Training loss: 1.8419859409332275
Validation loss: 2.1068846931060157

Epoch: 76| Step: 0
Training loss: 1.3880696296691895
Validation loss: 2.058824116985003

Epoch: 5| Step: 1
Training loss: 1.455307960510254
Validation loss: 2.0075538804133735

Epoch: 5| Step: 2
Training loss: 1.7511924505233765
Validation loss: 2.1428986390431723

Epoch: 5| Step: 3
Training loss: 1.6872570514678955
Validation loss: 2.1671378910541534

Epoch: 5| Step: 4
Training loss: 1.740631103515625
Validation loss: 2.1409295946359634

Epoch: 5| Step: 5
Training loss: 1.9152247905731201
Validation loss: 2.1098256409168243

Epoch: 5| Step: 6
Training loss: 2.1930973529815674
Validation loss: 2.085995470484098

Epoch: 5| Step: 7
Training loss: 1.9196287393569946
Validation loss: 2.1319076170523963

Epoch: 5| Step: 8
Training loss: 1.749291181564331
Validation loss: 2.094606935977936

Epoch: 5| Step: 9
Training loss: 1.8115314245224
Validation loss: 2.0768848756949105

Epoch: 5| Step: 10
Training loss: 1.5264171361923218
Validation loss: 2.075626124938329

Epoch: 5| Step: 11
Training loss: 0.9283432960510254
Validation loss: 2.0821238855520883

Epoch: 77| Step: 0
Training loss: 1.1039707660675049
Validation loss: 2.054834241668383

Epoch: 5| Step: 1
Training loss: 1.986084222793579
Validation loss: 2.0982762426137924

Epoch: 5| Step: 2
Training loss: 1.1902984380722046
Validation loss: 2.0314729561408362

Epoch: 5| Step: 3
Training loss: 2.126939058303833
Validation loss: 2.0784569829702377

Epoch: 5| Step: 4
Training loss: 1.617102026939392
Validation loss: 2.094401185711225

Epoch: 5| Step: 5
Training loss: 1.7885183095932007
Validation loss: 2.0933606028556824

Epoch: 5| Step: 6
Training loss: 2.184924602508545
Validation loss: 2.0778476297855377

Epoch: 5| Step: 7
Training loss: 1.38876473903656
Validation loss: 2.0959196239709854

Epoch: 5| Step: 8
Training loss: 1.962002158164978
Validation loss: 2.076968158284823

Epoch: 5| Step: 9
Training loss: 1.7179100513458252
Validation loss: 2.0875324805577598

Epoch: 5| Step: 10
Training loss: 1.4836704730987549
Validation loss: 2.0740221987167993

Epoch: 5| Step: 11
Training loss: 1.3517649173736572
Validation loss: 2.1526696582635245

Epoch: 78| Step: 0
Training loss: 1.5340311527252197
Validation loss: 2.134233603874842

Epoch: 5| Step: 1
Training loss: 1.5219104290008545
Validation loss: 2.045921206474304

Epoch: 5| Step: 2
Training loss: 1.131344199180603
Validation loss: 2.050845056772232

Epoch: 5| Step: 3
Training loss: 2.336393356323242
Validation loss: 2.035598506530126

Epoch: 5| Step: 4
Training loss: 2.109445571899414
Validation loss: 1.992204447587331

Epoch: 5| Step: 5
Training loss: 1.4581573009490967
Validation loss: 2.1251958310604095

Epoch: 5| Step: 6
Training loss: 1.791434645652771
Validation loss: 2.044033780694008

Epoch: 5| Step: 7
Training loss: 1.7548847198486328
Validation loss: 2.0796045313278833

Epoch: 5| Step: 8
Training loss: 1.4263148307800293
Validation loss: 2.0437949299812317

Epoch: 5| Step: 9
Training loss: 1.409585952758789
Validation loss: 2.1171646118164062

Epoch: 5| Step: 10
Training loss: 1.9746475219726562
Validation loss: 2.163540090123812

Epoch: 5| Step: 11
Training loss: 2.876817464828491
Validation loss: 2.0808468610048294

Epoch: 79| Step: 0
Training loss: 1.7631908655166626
Validation loss: 2.0297189901272454

Epoch: 5| Step: 1
Training loss: 1.222656488418579
Validation loss: 2.037532647450765

Epoch: 5| Step: 2
Training loss: 1.4742910861968994
Validation loss: 2.0758108099301658

Epoch: 5| Step: 3
Training loss: 0.9590786099433899
Validation loss: 2.02013889948527

Epoch: 5| Step: 4
Training loss: 2.2996127605438232
Validation loss: 2.0085743963718414

Epoch: 5| Step: 5
Training loss: 2.2395212650299072
Validation loss: 2.0092321236928306

Epoch: 5| Step: 6
Training loss: 1.3541224002838135
Validation loss: 2.0142056196928024

Epoch: 5| Step: 7
Training loss: 1.6963694095611572
Validation loss: 2.113341217239698

Epoch: 5| Step: 8
Training loss: 1.8553292751312256
Validation loss: 2.092939535776774

Epoch: 5| Step: 9
Training loss: 1.814110517501831
Validation loss: 2.0820926825205484

Epoch: 5| Step: 10
Training loss: 1.9313884973526
Validation loss: 2.0578377693891525

Epoch: 5| Step: 11
Training loss: 1.3027762174606323
Validation loss: 2.094106232126554

Epoch: 80| Step: 0
Training loss: 2.084648609161377
Validation loss: 2.078948383529981

Epoch: 5| Step: 1
Training loss: 1.9464725255966187
Validation loss: 2.0970228066047034

Epoch: 5| Step: 2
Training loss: 1.2725107669830322
Validation loss: 2.0164867689212165

Epoch: 5| Step: 3
Training loss: 1.7088950872421265
Validation loss: 2.018592690428098

Epoch: 5| Step: 4
Training loss: 1.1576974391937256
Validation loss: 2.0397813419500985

Epoch: 5| Step: 5
Training loss: 1.310789942741394
Validation loss: 1.9736480663220088

Epoch: 5| Step: 6
Training loss: 1.9984028339385986
Validation loss: 2.050931895772616

Epoch: 5| Step: 7
Training loss: 1.6316642761230469
Validation loss: 2.0578191628058753

Epoch: 5| Step: 8
Training loss: 1.4801056385040283
Validation loss: 2.1357429772615433

Epoch: 5| Step: 9
Training loss: 1.9518721103668213
Validation loss: 2.127416506409645

Epoch: 5| Step: 10
Training loss: 1.8778505325317383
Validation loss: 2.163577045003573

Epoch: 5| Step: 11
Training loss: 1.4758554697036743
Validation loss: 2.086327468355497

Epoch: 81| Step: 0
Training loss: 1.2071139812469482
Validation loss: 2.076756705840429

Epoch: 5| Step: 1
Training loss: 1.700953722000122
Validation loss: 2.0583861966927848

Epoch: 5| Step: 2
Training loss: 1.722254991531372
Validation loss: 2.058259362975756

Epoch: 5| Step: 3
Training loss: 1.2379653453826904
Validation loss: 2.0716284414132438

Epoch: 5| Step: 4
Training loss: 1.401085615158081
Validation loss: 2.039394681652387

Epoch: 5| Step: 5
Training loss: 1.9542045593261719
Validation loss: 2.085187723239263

Epoch: 5| Step: 6
Training loss: 1.9535884857177734
Validation loss: 1.9526052276293437

Epoch: 5| Step: 7
Training loss: 1.8974663019180298
Validation loss: 2.0782011449337006

Epoch: 5| Step: 8
Training loss: 1.801701307296753
Validation loss: 2.0118304987748465

Epoch: 5| Step: 9
Training loss: 1.3644115924835205
Validation loss: 2.121004045009613

Epoch: 5| Step: 10
Training loss: 2.1686604022979736
Validation loss: 2.121229430039724

Epoch: 5| Step: 11
Training loss: 1.7658833265304565
Validation loss: 2.0649063090483346

Epoch: 82| Step: 0
Training loss: 1.9088618755340576
Validation loss: 2.164041449626287

Epoch: 5| Step: 1
Training loss: 1.6096938848495483
Validation loss: 2.0167318681875863

Epoch: 5| Step: 2
Training loss: 1.98008131980896
Validation loss: 2.048785164952278

Epoch: 5| Step: 3
Training loss: 1.2736074924468994
Validation loss: 2.0879387160142264

Epoch: 5| Step: 4
Training loss: 1.8520128726959229
Validation loss: 2.0179356237252555

Epoch: 5| Step: 5
Training loss: 1.7749637365341187
Validation loss: 2.0579309860865274

Epoch: 5| Step: 6
Training loss: 1.9672571420669556
Validation loss: 2.031148076057434

Epoch: 5| Step: 7
Training loss: 1.5085573196411133
Validation loss: 2.107697606086731

Epoch: 5| Step: 8
Training loss: 1.2520105838775635
Validation loss: 2.069107860326767

Epoch: 5| Step: 9
Training loss: 1.2577370405197144
Validation loss: 2.1140430569648743

Epoch: 5| Step: 10
Training loss: 1.8176991939544678
Validation loss: 2.013504614432653

Epoch: 5| Step: 11
Training loss: 2.6701788902282715
Validation loss: 2.0783906330664954

Epoch: 83| Step: 0
Training loss: 1.6832364797592163
Validation loss: 2.0935242772102356

Epoch: 5| Step: 1
Training loss: 1.1913219690322876
Validation loss: 2.0591739366451898

Epoch: 5| Step: 2
Training loss: 1.3880250453948975
Validation loss: 2.0815978944301605

Epoch: 5| Step: 3
Training loss: 0.9788397550582886
Validation loss: 1.995660776893298

Epoch: 5| Step: 4
Training loss: 1.700990915298462
Validation loss: 2.031899025042852

Epoch: 5| Step: 5
Training loss: 1.7720133066177368
Validation loss: 1.9871712078650792

Epoch: 5| Step: 6
Training loss: 2.2539222240448
Validation loss: 2.000312094887098

Epoch: 5| Step: 7
Training loss: 2.181626796722412
Validation loss: 2.008397181828817

Epoch: 5| Step: 8
Training loss: 1.9119598865509033
Validation loss: 2.0238648056983948

Epoch: 5| Step: 9
Training loss: 1.5894744396209717
Validation loss: 2.003349478046099

Epoch: 5| Step: 10
Training loss: 1.6125576496124268
Validation loss: 1.999817634622256

Epoch: 5| Step: 11
Training loss: 1.7122015953063965
Validation loss: 1.9651173104842503

Epoch: 84| Step: 0
Training loss: 1.979151964187622
Validation loss: 2.051914855837822

Epoch: 5| Step: 1
Training loss: 1.8399055004119873
Validation loss: 2.065787598490715

Epoch: 5| Step: 2
Training loss: 1.194658875465393
Validation loss: 2.1059529185295105

Epoch: 5| Step: 3
Training loss: 2.136747360229492
Validation loss: 2.1387494802474976

Epoch: 5| Step: 4
Training loss: 1.7404619455337524
Validation loss: 2.170290152231852

Epoch: 5| Step: 5
Training loss: 1.7537208795547485
Validation loss: 2.1583441495895386

Epoch: 5| Step: 6
Training loss: 1.5064854621887207
Validation loss: 2.054643084605535

Epoch: 5| Step: 7
Training loss: 1.5700962543487549
Validation loss: 2.1377817541360855

Epoch: 5| Step: 8
Training loss: 1.6689027547836304
Validation loss: 2.0198521514733634

Epoch: 5| Step: 9
Training loss: 1.570848822593689
Validation loss: 2.069309468070666

Epoch: 5| Step: 10
Training loss: 1.1690864562988281
Validation loss: 2.019783159097036

Epoch: 5| Step: 11
Training loss: 1.764814019203186
Validation loss: 2.059712434808413

Epoch: 85| Step: 0
Training loss: 2.188436508178711
Validation loss: 2.0541534423828125

Epoch: 5| Step: 1
Training loss: 1.689481496810913
Validation loss: 2.1171412765979767

Epoch: 5| Step: 2
Training loss: 1.655289888381958
Validation loss: 2.134808520476023

Epoch: 5| Step: 3
Training loss: 1.8345043659210205
Validation loss: 2.1032321453094482

Epoch: 5| Step: 4
Training loss: 1.5587217807769775
Validation loss: 2.042735000451406

Epoch: 5| Step: 5
Training loss: 1.6781671047210693
Validation loss: 1.9988811512788136

Epoch: 5| Step: 6
Training loss: 1.6964915990829468
Validation loss: 2.072799955805143

Epoch: 5| Step: 7
Training loss: 1.4503774642944336
Validation loss: 2.1299028197924295

Epoch: 5| Step: 8
Training loss: 2.2526357173919678
Validation loss: 2.2306482791900635

Epoch: 5| Step: 9
Training loss: 2.13340163230896
Validation loss: 2.281969199577967

Epoch: 5| Step: 10
Training loss: 2.1879119873046875
Validation loss: 2.2196172922849655

Epoch: 5| Step: 11
Training loss: 1.234606146812439
Validation loss: 2.1359461694955826

Epoch: 86| Step: 0
Training loss: 1.61515212059021
Validation loss: 2.0845616906881332

Epoch: 5| Step: 1
Training loss: 1.3840594291687012
Validation loss: 2.063037430246671

Epoch: 5| Step: 2
Training loss: 2.090376377105713
Validation loss: 2.0473419775565467

Epoch: 5| Step: 3
Training loss: 1.7274014949798584
Validation loss: 2.0870539198319116

Epoch: 5| Step: 4
Training loss: 1.9695966243743896
Validation loss: 2.122777064641317

Epoch: 5| Step: 5
Training loss: 2.0841431617736816
Validation loss: 2.125722994407018

Epoch: 5| Step: 6
Training loss: 1.9460185766220093
Validation loss: 2.0200053999821344

Epoch: 5| Step: 7
Training loss: 1.935289978981018
Validation loss: 2.136032998561859

Epoch: 5| Step: 8
Training loss: 2.0470986366271973
Validation loss: 2.0527612765630088

Epoch: 5| Step: 9
Training loss: 1.0598409175872803
Validation loss: 2.029036372900009

Epoch: 5| Step: 10
Training loss: 1.6202455759048462
Validation loss: 2.0426099598407745

Epoch: 5| Step: 11
Training loss: 2.3837978839874268
Validation loss: 2.0725802232821784

Epoch: 87| Step: 0
Training loss: 1.7492974996566772
Validation loss: 2.1158968607584634

Epoch: 5| Step: 1
Training loss: 1.9582550525665283
Validation loss: 2.193690379460653

Epoch: 5| Step: 2
Training loss: 1.8926265239715576
Validation loss: 2.309937298297882

Epoch: 5| Step: 3
Training loss: 1.529181718826294
Validation loss: 2.21809388200442

Epoch: 5| Step: 4
Training loss: 1.5703812837600708
Validation loss: 2.1201391418774924

Epoch: 5| Step: 5
Training loss: 1.7769416570663452
Validation loss: 2.144036283095678

Epoch: 5| Step: 6
Training loss: 1.2005016803741455
Validation loss: 2.092288374900818

Epoch: 5| Step: 7
Training loss: 1.970248818397522
Validation loss: 2.0455879668394723

Epoch: 5| Step: 8
Training loss: 1.1713403463363647
Validation loss: 1.9613309303919475

Epoch: 5| Step: 9
Training loss: 1.6209440231323242
Validation loss: 2.0213464150826135

Epoch: 5| Step: 10
Training loss: 2.5235650539398193
Validation loss: 2.0651535987854004

Epoch: 5| Step: 11
Training loss: 1.8495972156524658
Validation loss: 2.0138121594985328

Epoch: 88| Step: 0
Training loss: 1.6431983709335327
Validation loss: 2.081417053937912

Epoch: 5| Step: 1
Training loss: 2.0779378414154053
Validation loss: 2.03700552880764

Epoch: 5| Step: 2
Training loss: 1.7680364847183228
Validation loss: 2.0454652359088263

Epoch: 5| Step: 3
Training loss: 1.745562195777893
Validation loss: 2.0800734957059226

Epoch: 5| Step: 4
Training loss: 1.6098159551620483
Validation loss: 2.0819110721349716

Epoch: 5| Step: 5
Training loss: 1.7879486083984375
Validation loss: 2.0462770611047745

Epoch: 5| Step: 6
Training loss: 1.9183437824249268
Validation loss: 2.056208019455274

Epoch: 5| Step: 7
Training loss: 1.5335642099380493
Validation loss: 2.0872757881879807

Epoch: 5| Step: 8
Training loss: 1.572918176651001
Validation loss: 2.0647718956073127

Epoch: 5| Step: 9
Training loss: 1.5343601703643799
Validation loss: 2.074002052346865

Epoch: 5| Step: 10
Training loss: 1.4191306829452515
Validation loss: 2.06862943371137

Epoch: 5| Step: 11
Training loss: 0.5766546726226807
Validation loss: 2.113003194332123

Epoch: 89| Step: 0
Training loss: 1.6580016613006592
Validation loss: 2.0460625340541205

Epoch: 5| Step: 1
Training loss: 1.4024995565414429
Validation loss: 2.0299993803103766

Epoch: 5| Step: 2
Training loss: 1.6976925134658813
Validation loss: 2.071317344903946

Epoch: 5| Step: 3
Training loss: 1.5156975984573364
Validation loss: 2.0634074012438455

Epoch: 5| Step: 4
Training loss: 1.7853752374649048
Validation loss: 2.0133114606142044

Epoch: 5| Step: 5
Training loss: 1.7935068607330322
Validation loss: 2.0269416322310767

Epoch: 5| Step: 6
Training loss: 1.583248257637024
Validation loss: 2.0580959618091583

Epoch: 5| Step: 7
Training loss: 1.4264048337936401
Validation loss: 2.033110419909159

Epoch: 5| Step: 8
Training loss: 1.9174808263778687
Validation loss: 2.043120563030243

Epoch: 5| Step: 9
Training loss: 1.7265167236328125
Validation loss: 2.02074071764946

Epoch: 5| Step: 10
Training loss: 1.2019331455230713
Validation loss: 2.103470742702484

Epoch: 5| Step: 11
Training loss: 1.7944921255111694
Validation loss: 2.0542971044778824

Epoch: 90| Step: 0
Training loss: 1.7181713581085205
Validation loss: 2.1132172346115112

Epoch: 5| Step: 1
Training loss: 1.5721886157989502
Validation loss: 2.0333566019932428

Epoch: 5| Step: 2
Training loss: 1.7925760746002197
Validation loss: 2.0236822962760925

Epoch: 5| Step: 3
Training loss: 1.9690606594085693
Validation loss: 2.097272738814354

Epoch: 5| Step: 4
Training loss: 1.6759392023086548
Validation loss: 2.054237499833107

Epoch: 5| Step: 5
Training loss: 1.365207314491272
Validation loss: 2.0916464825471244

Epoch: 5| Step: 6
Training loss: 1.9092295169830322
Validation loss: 2.035351817806562

Epoch: 5| Step: 7
Training loss: 1.8143234252929688
Validation loss: 2.0660629818836846

Epoch: 5| Step: 8
Training loss: 1.2843656539916992
Validation loss: 2.0781154731909433

Epoch: 5| Step: 9
Training loss: 1.4444416761398315
Validation loss: 2.0745679140090942

Epoch: 5| Step: 10
Training loss: 1.7075684070587158
Validation loss: 2.074213167031606

Epoch: 5| Step: 11
Training loss: 0.9039357304573059
Validation loss: 2.046341026822726

Epoch: 91| Step: 0
Training loss: 0.9971281886100769
Validation loss: 2.110147997736931

Epoch: 5| Step: 1
Training loss: 1.9973821640014648
Validation loss: 2.115623399615288

Epoch: 5| Step: 2
Training loss: 1.808074951171875
Validation loss: 2.066177800297737

Epoch: 5| Step: 3
Training loss: 1.9469327926635742
Validation loss: 2.0383913765350976

Epoch: 5| Step: 4
Training loss: 1.5910742282867432
Validation loss: 2.11549873650074

Epoch: 5| Step: 5
Training loss: 1.4337942600250244
Validation loss: 2.1285024334987006

Epoch: 5| Step: 6
Training loss: 1.4178390502929688
Validation loss: 2.0833400835593543

Epoch: 5| Step: 7
Training loss: 1.8608686923980713
Validation loss: 2.009177550673485

Epoch: 5| Step: 8
Training loss: 0.9569947123527527
Validation loss: 2.0134108811616898

Epoch: 5| Step: 9
Training loss: 1.5177618265151978
Validation loss: 2.0971574932336807

Epoch: 5| Step: 10
Training loss: 1.9122822284698486
Validation loss: 2.065520857771238

Epoch: 5| Step: 11
Training loss: 1.831898808479309
Validation loss: 2.018009692430496

Epoch: 92| Step: 0
Training loss: 2.1079039573669434
Validation loss: 1.9857997596263885

Epoch: 5| Step: 1
Training loss: 1.308502435684204
Validation loss: 2.0303176989157996

Epoch: 5| Step: 2
Training loss: 1.4675472974777222
Validation loss: 2.0452539225419364

Epoch: 5| Step: 3
Training loss: 1.6353975534439087
Validation loss: 2.050029436747233

Epoch: 5| Step: 4
Training loss: 1.8894264698028564
Validation loss: 2.0891362031300864

Epoch: 5| Step: 5
Training loss: 1.2393420934677124
Validation loss: 2.066128119826317

Epoch: 5| Step: 6
Training loss: 1.6170322895050049
Validation loss: 2.0226304034392038

Epoch: 5| Step: 7
Training loss: 1.4235893487930298
Validation loss: 2.045669913291931

Epoch: 5| Step: 8
Training loss: 1.590355396270752
Validation loss: 2.0347330619891486

Epoch: 5| Step: 9
Training loss: 1.5081884860992432
Validation loss: 2.079376404484113

Epoch: 5| Step: 10
Training loss: 1.60738205909729
Validation loss: 2.0542500714461007

Epoch: 5| Step: 11
Training loss: 0.9359323978424072
Validation loss: 2.1155888388554254

Epoch: 93| Step: 0
Training loss: 2.232642412185669
Validation loss: 2.1403217216332755

Epoch: 5| Step: 1
Training loss: 1.2601792812347412
Validation loss: 2.137605677048365

Epoch: 5| Step: 2
Training loss: 1.3744243383407593
Validation loss: 2.1581395119428635

Epoch: 5| Step: 3
Training loss: 2.385464906692505
Validation loss: 2.219077929854393

Epoch: 5| Step: 4
Training loss: 1.318461298942566
Validation loss: 2.164999549587568

Epoch: 5| Step: 5
Training loss: 1.990264892578125
Validation loss: 2.1211039622624717

Epoch: 5| Step: 6
Training loss: 1.2760941982269287
Validation loss: 2.007231742143631

Epoch: 5| Step: 7
Training loss: 1.9465434551239014
Validation loss: 2.0565975457429886

Epoch: 5| Step: 8
Training loss: 0.9325723648071289
Validation loss: 2.007362579305967

Epoch: 5| Step: 9
Training loss: 1.2898858785629272
Validation loss: 2.0499059607585273

Epoch: 5| Step: 10
Training loss: 1.8356876373291016
Validation loss: 2.042856236298879

Epoch: 5| Step: 11
Training loss: 2.043706178665161
Validation loss: 2.0835017760594687

Epoch: 94| Step: 0
Training loss: 1.5277817249298096
Validation loss: 2.069921945532163

Epoch: 5| Step: 1
Training loss: 1.6317373514175415
Validation loss: 2.0600931495428085

Epoch: 5| Step: 2
Training loss: 1.5459522008895874
Validation loss: 2.0627575616041818

Epoch: 5| Step: 3
Training loss: 1.9334383010864258
Validation loss: 2.0375199963649115

Epoch: 5| Step: 4
Training loss: 1.411033272743225
Validation loss: 2.147544647256533

Epoch: 5| Step: 5
Training loss: 1.2658085823059082
Validation loss: 2.088232403000196

Epoch: 5| Step: 6
Training loss: 1.8144311904907227
Validation loss: 1.9993622799714406

Epoch: 5| Step: 7
Training loss: 1.8473819494247437
Validation loss: 2.1269522110621133

Epoch: 5| Step: 8
Training loss: 1.882154107093811
Validation loss: 2.0454559127489724

Epoch: 5| Step: 9
Training loss: 1.6608960628509521
Validation loss: 2.067973410089811

Epoch: 5| Step: 10
Training loss: 1.3249037265777588
Validation loss: 2.046617031097412

Epoch: 5| Step: 11
Training loss: 1.1963776350021362
Validation loss: 2.0681096067031226

Epoch: 95| Step: 0
Training loss: 1.0834684371948242
Validation loss: 2.0839974532524743

Epoch: 5| Step: 1
Training loss: 1.7102336883544922
Validation loss: 2.089841971794764

Epoch: 5| Step: 2
Training loss: 1.0621377229690552
Validation loss: 2.0990667988856635

Epoch: 5| Step: 3
Training loss: 1.1870368719100952
Validation loss: 2.0229230721791587

Epoch: 5| Step: 4
Training loss: 1.517805814743042
Validation loss: 2.011168842514356

Epoch: 5| Step: 5
Training loss: 2.1515636444091797
Validation loss: 1.9777150998512905

Epoch: 5| Step: 6
Training loss: 2.0478177070617676
Validation loss: 2.05217936138312

Epoch: 5| Step: 7
Training loss: 1.91433846950531
Validation loss: 2.0429222931464515

Epoch: 5| Step: 8
Training loss: 1.522758960723877
Validation loss: 2.050673723220825

Epoch: 5| Step: 9
Training loss: 1.9601633548736572
Validation loss: 2.0956750214099884

Epoch: 5| Step: 10
Training loss: 1.3090240955352783
Validation loss: 2.090792795022329

Epoch: 5| Step: 11
Training loss: 1.1960207223892212
Validation loss: 2.0598413546880088

Epoch: 96| Step: 0
Training loss: 1.6229419708251953
Validation loss: 2.124943991502126

Epoch: 5| Step: 1
Training loss: 1.844595193862915
Validation loss: 2.0457085271676383

Epoch: 5| Step: 2
Training loss: 1.2753894329071045
Validation loss: 2.072898084918658

Epoch: 5| Step: 3
Training loss: 1.9706159830093384
Validation loss: 2.0630079259475074

Epoch: 5| Step: 4
Training loss: 1.7000116109848022
Validation loss: 2.056934341788292

Epoch: 5| Step: 5
Training loss: 1.925571084022522
Validation loss: 2.063807080189387

Epoch: 5| Step: 6
Training loss: 1.3511053323745728
Validation loss: 2.0649907837311425

Epoch: 5| Step: 7
Training loss: 1.2131311893463135
Validation loss: 2.077034408847491

Epoch: 5| Step: 8
Training loss: 1.222880482673645
Validation loss: 2.061744307478269

Epoch: 5| Step: 9
Training loss: 1.3145883083343506
Validation loss: 1.9968090852101643

Epoch: 5| Step: 10
Training loss: 2.066145181655884
Validation loss: 2.0703491270542145

Epoch: 5| Step: 11
Training loss: 1.834322214126587
Validation loss: 2.040227656563123

Epoch: 97| Step: 0
Training loss: 1.7645835876464844
Validation loss: 2.027291710178057

Epoch: 5| Step: 1
Training loss: 1.5980355739593506
Validation loss: 2.007029801607132

Epoch: 5| Step: 2
Training loss: 1.4041868448257446
Validation loss: 2.0131331235170364

Epoch: 5| Step: 3
Training loss: 1.168400526046753
Validation loss: 2.038476213812828

Epoch: 5| Step: 4
Training loss: 1.4425427913665771
Validation loss: 2.0564570973316827

Epoch: 5| Step: 5
Training loss: 1.4503426551818848
Validation loss: 2.0424811790386834

Epoch: 5| Step: 6
Training loss: 1.676584243774414
Validation loss: 2.008813669284185

Epoch: 5| Step: 7
Training loss: 2.149970531463623
Validation loss: 2.0563582529624305

Epoch: 5| Step: 8
Training loss: 1.1511635780334473
Validation loss: 2.03938619295756

Epoch: 5| Step: 9
Training loss: 1.6808478832244873
Validation loss: 2.089668100078901

Epoch: 5| Step: 10
Training loss: 1.585418462753296
Validation loss: 2.130026256044706

Epoch: 5| Step: 11
Training loss: 1.9391928911209106
Validation loss: 2.069557398557663

Epoch: 98| Step: 0
Training loss: 1.3331955671310425
Validation loss: 2.0762954552968345

Epoch: 5| Step: 1
Training loss: 1.3546361923217773
Validation loss: 2.021322106321653

Epoch: 5| Step: 2
Training loss: 1.500637412071228
Validation loss: 2.013052682081858

Epoch: 5| Step: 3
Training loss: 1.7050669193267822
Validation loss: 2.0259251445531845

Epoch: 5| Step: 4
Training loss: 1.98898446559906
Validation loss: 2.0132856518030167

Epoch: 5| Step: 5
Training loss: 1.781990647315979
Validation loss: 1.9914566278457642

Epoch: 5| Step: 6
Training loss: 1.4817653894424438
Validation loss: 2.02921669681867

Epoch: 5| Step: 7
Training loss: 2.0391669273376465
Validation loss: 2.0218766232331595

Epoch: 5| Step: 8
Training loss: 1.2838046550750732
Validation loss: 2.024180660645167

Epoch: 5| Step: 9
Training loss: 1.2986611127853394
Validation loss: 2.0380238046248755

Epoch: 5| Step: 10
Training loss: 1.5608195066452026
Validation loss: 2.0551286737124124

Epoch: 5| Step: 11
Training loss: 3.0241403579711914
Validation loss: 2.0940263668696084

Epoch: 99| Step: 0
Training loss: 1.6607685089111328
Validation loss: 2.1337322940429053

Epoch: 5| Step: 1
Training loss: 1.3656790256500244
Validation loss: 2.107523560523987

Epoch: 5| Step: 2
Training loss: 1.7246410846710205
Validation loss: 2.106209769845009

Epoch: 5| Step: 3
Training loss: 1.8996574878692627
Validation loss: 2.0441382378339767

Epoch: 5| Step: 4
Training loss: 1.3859647512435913
Validation loss: 2.0652786691983542

Epoch: 5| Step: 5
Training loss: 1.6243689060211182
Validation loss: 2.060367132226626

Epoch: 5| Step: 6
Training loss: 1.6331660747528076
Validation loss: 2.0919889708360038

Epoch: 5| Step: 7
Training loss: 1.5112979412078857
Validation loss: 2.1154644141594567

Epoch: 5| Step: 8
Training loss: 1.15115487575531
Validation loss: 2.0663416981697083

Epoch: 5| Step: 9
Training loss: 1.3921585083007812
Validation loss: 2.076210324962934

Epoch: 5| Step: 10
Training loss: 1.4087448120117188
Validation loss: 2.055077150464058

Epoch: 5| Step: 11
Training loss: 0.6144318580627441
Validation loss: 2.0395302126804986

Epoch: 100| Step: 0
Training loss: 1.5352710485458374
Validation loss: 2.0176947762568793

Epoch: 5| Step: 1
Training loss: 1.7338573932647705
Validation loss: 2.118924339612325

Epoch: 5| Step: 2
Training loss: 1.555535078048706
Validation loss: 2.050295278429985

Epoch: 5| Step: 3
Training loss: 1.4486852884292603
Validation loss: 2.09549817442894

Epoch: 5| Step: 4
Training loss: 1.2231409549713135
Validation loss: 2.048693925142288

Epoch: 5| Step: 5
Training loss: 1.1290634870529175
Validation loss: 2.122711812456449

Epoch: 5| Step: 6
Training loss: 1.7767994403839111
Validation loss: 2.0564329822858176

Epoch: 5| Step: 7
Training loss: 1.2708885669708252
Validation loss: 2.020841956138611

Epoch: 5| Step: 8
Training loss: 1.776355504989624
Validation loss: 2.084539850552877

Epoch: 5| Step: 9
Training loss: 1.3064987659454346
Validation loss: 2.024432515104612

Epoch: 5| Step: 10
Training loss: 1.8880951404571533
Validation loss: 2.059649164477984

Epoch: 5| Step: 11
Training loss: 3.0341014862060547
Validation loss: 2.081337774793307

Testing loss: 1.9022822954671845
