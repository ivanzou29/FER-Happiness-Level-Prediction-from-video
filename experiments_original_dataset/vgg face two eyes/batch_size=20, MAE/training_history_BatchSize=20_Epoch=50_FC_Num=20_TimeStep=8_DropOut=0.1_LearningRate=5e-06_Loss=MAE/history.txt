Epoch: 1| Step: 0
Training loss: 3.2419540882110596
Validation loss: 3.235525051752726

Epoch: 5| Step: 1
Training loss: 2.2750420570373535
Validation loss: 3.2132467230161033

Epoch: 5| Step: 2
Training loss: 3.522355318069458
Validation loss: 3.1921482582887015

Epoch: 5| Step: 3
Training loss: 3.402273178100586
Validation loss: 3.1718391875425973

Epoch: 5| Step: 4
Training loss: 3.934809446334839
Validation loss: 3.150588591893514

Epoch: 5| Step: 5
Training loss: 3.9245433807373047
Validation loss: 3.1303177177906036

Epoch: 5| Step: 6
Training loss: 4.363381385803223
Validation loss: 3.1084964871406555

Epoch: 5| Step: 7
Training loss: 3.7221360206604004
Validation loss: 3.0894864400227866

Epoch: 5| Step: 8
Training loss: 3.0338759422302246
Validation loss: 3.067709505558014

Epoch: 5| Step: 9
Training loss: 2.2266297340393066
Validation loss: 3.0472734570503235

Epoch: 5| Step: 10
Training loss: 3.097771644592285
Validation loss: 3.0302368104457855

Epoch: 5| Step: 11
Training loss: 1.6506284475326538
Validation loss: 3.011710206667582

Epoch: 2| Step: 0
Training loss: 3.4705371856689453
Validation loss: 2.9950192471345267

Epoch: 5| Step: 1
Training loss: 3.1737289428710938
Validation loss: 2.9742916027704873

Epoch: 5| Step: 2
Training loss: 2.527803659439087
Validation loss: 2.9546875059604645

Epoch: 5| Step: 3
Training loss: 3.31176495552063
Validation loss: 2.936333338419596

Epoch: 5| Step: 4
Training loss: 2.861783742904663
Validation loss: 2.9135130842526755

Epoch: 5| Step: 5
Training loss: 3.204678773880005
Validation loss: 2.897597054640452

Epoch: 5| Step: 6
Training loss: 3.434021472930908
Validation loss: 2.8784798681735992

Epoch: 5| Step: 7
Training loss: 3.02474308013916
Validation loss: 2.857612540324529

Epoch: 5| Step: 8
Training loss: 3.122546911239624
Validation loss: 2.8367351492245994

Epoch: 5| Step: 9
Training loss: 2.748608350753784
Validation loss: 2.8180083533128104

Epoch: 5| Step: 10
Training loss: 3.1503612995147705
Validation loss: 2.794167846441269

Epoch: 5| Step: 11
Training loss: 1.4656946659088135
Validation loss: 2.7712100545565286

Epoch: 3| Step: 0
Training loss: 3.089311361312866
Validation loss: 2.7532723546028137

Epoch: 5| Step: 1
Training loss: 3.148380756378174
Validation loss: 2.732773850361506

Epoch: 5| Step: 2
Training loss: 2.799333095550537
Validation loss: 2.712208221356074

Epoch: 5| Step: 3
Training loss: 2.0510058403015137
Validation loss: 2.688442180554072

Epoch: 5| Step: 4
Training loss: 2.4480068683624268
Validation loss: 2.6647348602612815

Epoch: 5| Step: 5
Training loss: 2.926590919494629
Validation loss: 2.645158976316452

Epoch: 5| Step: 6
Training loss: 2.8417203426361084
Validation loss: 2.618985891342163

Epoch: 5| Step: 7
Training loss: 2.9696717262268066
Validation loss: 2.5898344119389853

Epoch: 5| Step: 8
Training loss: 2.71873140335083
Validation loss: 2.563633054494858

Epoch: 5| Step: 9
Training loss: 2.953662872314453
Validation loss: 2.5315542817115784

Epoch: 5| Step: 10
Training loss: 2.427838087081909
Validation loss: 2.5000795423984528

Epoch: 5| Step: 11
Training loss: 2.479724884033203
Validation loss: 2.460910071929296

Epoch: 4| Step: 0
Training loss: 2.6508326530456543
Validation loss: 2.4323656260967255

Epoch: 5| Step: 1
Training loss: 2.548600673675537
Validation loss: 2.392189701398214

Epoch: 5| Step: 2
Training loss: 2.621351718902588
Validation loss: 2.358756944537163

Epoch: 5| Step: 3
Training loss: 2.3206875324249268
Validation loss: 2.3147158126036325

Epoch: 5| Step: 4
Training loss: 2.3876776695251465
Validation loss: 2.2759299824635186

Epoch: 5| Step: 5
Training loss: 2.163790702819824
Validation loss: 2.242305020491282

Epoch: 5| Step: 6
Training loss: 2.5070395469665527
Validation loss: 2.196670030554136

Epoch: 5| Step: 7
Training loss: 2.2355501651763916
Validation loss: 2.1600071688493094

Epoch: 5| Step: 8
Training loss: 2.244154453277588
Validation loss: 2.1296790838241577

Epoch: 5| Step: 9
Training loss: 1.9281753301620483
Validation loss: 2.1059183180332184

Epoch: 5| Step: 10
Training loss: 2.615586757659912
Validation loss: 2.0786529183387756

Epoch: 5| Step: 11
Training loss: 2.006467580795288
Validation loss: 2.0609300484259925

Epoch: 5| Step: 0
Training loss: 2.0026023387908936
Validation loss: 2.041214093565941

Epoch: 5| Step: 1
Training loss: 2.604698896408081
Validation loss: 2.025022139151891

Epoch: 5| Step: 2
Training loss: 1.9936622381210327
Validation loss: 2.013752649227778

Epoch: 5| Step: 3
Training loss: 2.586540699005127
Validation loss: 2.0135384649038315

Epoch: 5| Step: 4
Training loss: 2.383883237838745
Validation loss: 1.9985119253396988

Epoch: 5| Step: 5
Training loss: 1.7845051288604736
Validation loss: 2.0013347218434014

Epoch: 5| Step: 6
Training loss: 2.17686128616333
Validation loss: 2.005620544155439

Epoch: 5| Step: 7
Training loss: 2.1572365760803223
Validation loss: 2.013838599125544

Epoch: 5| Step: 8
Training loss: 2.256153106689453
Validation loss: 2.003468935688337

Epoch: 5| Step: 9
Training loss: 1.7180038690567017
Validation loss: 2.0249477426211038

Epoch: 5| Step: 10
Training loss: 1.8383967876434326
Validation loss: 2.011712928613027

Epoch: 5| Step: 11
Training loss: 1.8837127685546875
Validation loss: 2.0225782891114554

Epoch: 6| Step: 0
Training loss: 2.131978988647461
Validation loss: 2.0218918124834695

Epoch: 5| Step: 1
Training loss: 1.722262978553772
Validation loss: 2.0138058811426163

Epoch: 5| Step: 2
Training loss: 2.5897216796875
Validation loss: 2.012007544438044

Epoch: 5| Step: 3
Training loss: 2.447807788848877
Validation loss: 2.0202430337667465

Epoch: 5| Step: 4
Training loss: 1.8168199062347412
Validation loss: 1.9988638708988826

Epoch: 5| Step: 5
Training loss: 1.8819783926010132
Validation loss: 2.0061019361019135

Epoch: 5| Step: 6
Training loss: 1.8450359106063843
Validation loss: 2.011973520119985

Epoch: 5| Step: 7
Training loss: 2.1986076831817627
Validation loss: 2.016055022676786

Epoch: 5| Step: 8
Training loss: 2.096128463745117
Validation loss: 2.014682720104853

Epoch: 5| Step: 9
Training loss: 2.5122101306915283
Validation loss: 2.0116220712661743

Epoch: 5| Step: 10
Training loss: 1.8219101428985596
Validation loss: 2.0079422195752463

Epoch: 5| Step: 11
Training loss: 2.3883581161499023
Validation loss: 2.0117595195770264

Epoch: 7| Step: 0
Training loss: 2.2901389598846436
Validation loss: 1.9984297901391983

Epoch: 5| Step: 1
Training loss: 2.119135856628418
Validation loss: 1.9996627916892369

Epoch: 5| Step: 2
Training loss: 1.7068077325820923
Validation loss: 1.995872974395752

Epoch: 5| Step: 3
Training loss: 1.8141803741455078
Validation loss: 1.9748860200246174

Epoch: 5| Step: 4
Training loss: 2.372211217880249
Validation loss: 1.9926339586575825

Epoch: 5| Step: 5
Training loss: 1.9324004650115967
Validation loss: 1.9865726828575134

Epoch: 5| Step: 6
Training loss: 1.7355201244354248
Validation loss: 1.9877019027868907

Epoch: 5| Step: 7
Training loss: 2.550264835357666
Validation loss: 1.9850659271081288

Epoch: 5| Step: 8
Training loss: 2.1218817234039307
Validation loss: 1.9913667341073353

Epoch: 5| Step: 9
Training loss: 2.0753588676452637
Validation loss: 1.9869360327720642

Epoch: 5| Step: 10
Training loss: 2.198791742324829
Validation loss: 1.9874787231286366

Epoch: 5| Step: 11
Training loss: 3.259777069091797
Validation loss: 1.9841225842634838

Epoch: 8| Step: 0
Training loss: 2.178131103515625
Validation loss: 1.9870459934075673

Epoch: 5| Step: 1
Training loss: 1.8553667068481445
Validation loss: 1.985380008816719

Epoch: 5| Step: 2
Training loss: 2.2576451301574707
Validation loss: 1.9838278939326603

Epoch: 5| Step: 3
Training loss: 1.8970668315887451
Validation loss: 1.9824222524960835

Epoch: 5| Step: 4
Training loss: 2.5713863372802734
Validation loss: 1.9763222982486088

Epoch: 5| Step: 5
Training loss: 1.7519199848175049
Validation loss: 1.9772880921761196

Epoch: 5| Step: 6
Training loss: 2.045638084411621
Validation loss: 1.9823431372642517

Epoch: 5| Step: 7
Training loss: 2.0233585834503174
Validation loss: 1.9772970924774806

Epoch: 5| Step: 8
Training loss: 2.2532341480255127
Validation loss: 1.9756479114294052

Epoch: 5| Step: 9
Training loss: 1.9433648586273193
Validation loss: 1.9767423818508785

Epoch: 5| Step: 10
Training loss: 2.0463013648986816
Validation loss: 1.9734559108813603

Epoch: 5| Step: 11
Training loss: 2.2962470054626465
Validation loss: 1.982202063004176

Epoch: 9| Step: 0
Training loss: 2.2223896980285645
Validation loss: 1.9873203486204147

Epoch: 5| Step: 1
Training loss: 2.116339921951294
Validation loss: 1.9933622926473618

Epoch: 5| Step: 2
Training loss: 2.124523639678955
Validation loss: 2.0057123750448227

Epoch: 5| Step: 3
Training loss: 2.163315773010254
Validation loss: 2.0121762653191886

Epoch: 5| Step: 4
Training loss: 1.820242166519165
Validation loss: 2.0062273889780045

Epoch: 5| Step: 5
Training loss: 2.5710830688476562
Validation loss: 2.016917730371157

Epoch: 5| Step: 6
Training loss: 2.2503182888031006
Validation loss: 2.025031973918279

Epoch: 5| Step: 7
Training loss: 1.738138198852539
Validation loss: 2.015990490714709

Epoch: 5| Step: 8
Training loss: 1.9471124410629272
Validation loss: 2.0184351801872253

Epoch: 5| Step: 9
Training loss: 1.8705675601959229
Validation loss: 2.007887269059817

Epoch: 5| Step: 10
Training loss: 2.0934224128723145
Validation loss: 2.0142290045817695

Epoch: 5| Step: 11
Training loss: 1.7698458433151245
Validation loss: 2.009967545668284

Epoch: 10| Step: 0
Training loss: 2.206019163131714
Validation loss: 2.0239327996969223

Epoch: 5| Step: 1
Training loss: 2.1478357315063477
Validation loss: 2.008464222153028

Epoch: 5| Step: 2
Training loss: 2.3689143657684326
Validation loss: 1.9939256658156712

Epoch: 5| Step: 3
Training loss: 2.100468158721924
Validation loss: 1.9936719089746475

Epoch: 5| Step: 4
Training loss: 2.1669700145721436
Validation loss: 1.9786364783843358

Epoch: 5| Step: 5
Training loss: 1.5393216609954834
Validation loss: 1.9830378741025925

Epoch: 5| Step: 6
Training loss: 1.9076868295669556
Validation loss: 1.9806454628705978

Epoch: 5| Step: 7
Training loss: 2.3007359504699707
Validation loss: 1.973068540294965

Epoch: 5| Step: 8
Training loss: 2.0402660369873047
Validation loss: 1.981309602657954

Epoch: 5| Step: 9
Training loss: 1.6977580785751343
Validation loss: 1.9739174246788025

Epoch: 5| Step: 10
Training loss: 2.109729766845703
Validation loss: 1.9629918734232585

Epoch: 5| Step: 11
Training loss: 3.0511562824249268
Validation loss: 1.9613296687602997

Epoch: 11| Step: 0
Training loss: 2.0096042156219482
Validation loss: 1.9617034842570622

Epoch: 5| Step: 1
Training loss: 2.1401820182800293
Validation loss: 1.9799530357122421

Epoch: 5| Step: 2
Training loss: 2.165461301803589
Validation loss: 1.9799416065216064

Epoch: 5| Step: 3
Training loss: 2.1080164909362793
Validation loss: 1.9854228893915813

Epoch: 5| Step: 4
Training loss: 2.1616082191467285
Validation loss: 1.9841103653113048

Epoch: 5| Step: 5
Training loss: 2.312455654144287
Validation loss: 1.9862210651238759

Epoch: 5| Step: 6
Training loss: 1.5026863813400269
Validation loss: 1.993559405207634

Epoch: 5| Step: 7
Training loss: 2.5914745330810547
Validation loss: 1.989748900135358

Epoch: 5| Step: 8
Training loss: 1.9463145732879639
Validation loss: 2.000720535715421

Epoch: 5| Step: 9
Training loss: 1.6838510036468506
Validation loss: 1.994923358162244

Epoch: 5| Step: 10
Training loss: 2.1343486309051514
Validation loss: 1.9910632620255153

Epoch: 5| Step: 11
Training loss: 1.4699933528900146
Validation loss: 1.9940510988235474

Epoch: 12| Step: 0
Training loss: 2.4733669757843018
Validation loss: 1.9908666263024013

Epoch: 5| Step: 1
Training loss: 1.70220148563385
Validation loss: 1.997592732310295

Epoch: 5| Step: 2
Training loss: 1.8472263813018799
Validation loss: 1.984849085410436

Epoch: 5| Step: 3
Training loss: 1.7220481634140015
Validation loss: 1.9922443280617397

Epoch: 5| Step: 4
Training loss: 2.2156875133514404
Validation loss: 2.0030019034941993

Epoch: 5| Step: 5
Training loss: 2.2508747577667236
Validation loss: 1.9911237011353176

Epoch: 5| Step: 6
Training loss: 1.9875843524932861
Validation loss: 2.0022797733545303

Epoch: 5| Step: 7
Training loss: 2.2410147190093994
Validation loss: 1.9855518837769826

Epoch: 5| Step: 8
Training loss: 1.8876796960830688
Validation loss: 1.9902957479159038

Epoch: 5| Step: 9
Training loss: 2.338499069213867
Validation loss: 1.993388906121254

Epoch: 5| Step: 10
Training loss: 2.016392230987549
Validation loss: 1.9753292451302211

Epoch: 5| Step: 11
Training loss: 1.349411129951477
Validation loss: 1.9785865247249603

Epoch: 13| Step: 0
Training loss: 2.518742561340332
Validation loss: 1.9719326148430507

Epoch: 5| Step: 1
Training loss: 1.6682935953140259
Validation loss: 1.9699832101662953

Epoch: 5| Step: 2
Training loss: 1.9062602519989014
Validation loss: 1.9793526778618495

Epoch: 5| Step: 3
Training loss: 2.1819846630096436
Validation loss: 1.9808554848035176

Epoch: 5| Step: 4
Training loss: 1.7973976135253906
Validation loss: 1.977411150932312

Epoch: 5| Step: 5
Training loss: 2.1997439861297607
Validation loss: 1.960466206073761

Epoch: 5| Step: 6
Training loss: 1.992666482925415
Validation loss: 1.9819655964771907

Epoch: 5| Step: 7
Training loss: 2.1975181102752686
Validation loss: 1.9723877906799316

Epoch: 5| Step: 8
Training loss: 1.9377044439315796
Validation loss: 1.9671291659275691

Epoch: 5| Step: 9
Training loss: 1.8485796451568604
Validation loss: 1.9633961369593937

Epoch: 5| Step: 10
Training loss: 2.133946657180786
Validation loss: 1.954298198223114

Epoch: 5| Step: 11
Training loss: 2.142899990081787
Validation loss: 1.9695836106936138

Epoch: 14| Step: 0
Training loss: 3.283642530441284
Validation loss: 1.9655642459789913

Epoch: 5| Step: 1
Training loss: 1.230411410331726
Validation loss: 1.9653345048427582

Epoch: 5| Step: 2
Training loss: 1.959031343460083
Validation loss: 1.9558295806248982

Epoch: 5| Step: 3
Training loss: 2.3786392211914062
Validation loss: 1.9592479914426804

Epoch: 5| Step: 4
Training loss: 2.0092825889587402
Validation loss: 1.9581557015577953

Epoch: 5| Step: 5
Training loss: 2.1682651042938232
Validation loss: 1.9498232801755269

Epoch: 5| Step: 6
Training loss: 1.7394651174545288
Validation loss: 1.955012892683347

Epoch: 5| Step: 7
Training loss: 2.1089119911193848
Validation loss: 1.954899400472641

Epoch: 5| Step: 8
Training loss: 1.7303361892700195
Validation loss: 1.953023428718249

Epoch: 5| Step: 9
Training loss: 1.6341419219970703
Validation loss: 1.9613734583059947

Epoch: 5| Step: 10
Training loss: 1.8641090393066406
Validation loss: 1.9662621666987736

Epoch: 5| Step: 11
Training loss: 3.657653331756592
Validation loss: 1.9721792886654537

Epoch: 15| Step: 0
Training loss: 1.91512930393219
Validation loss: 1.967491830388705

Epoch: 5| Step: 1
Training loss: 1.4727647304534912
Validation loss: 1.9678557763497035

Epoch: 5| Step: 2
Training loss: 1.7470166683197021
Validation loss: 1.9717972973982494

Epoch: 5| Step: 3
Training loss: 1.5991934537887573
Validation loss: 1.9682528624931972

Epoch: 5| Step: 4
Training loss: 2.142275333404541
Validation loss: 1.969216098388036

Epoch: 5| Step: 5
Training loss: 1.8653614521026611
Validation loss: 1.9835815131664276

Epoch: 5| Step: 6
Training loss: 2.985001802444458
Validation loss: 1.993194043636322

Epoch: 5| Step: 7
Training loss: 1.850743293762207
Validation loss: 1.9783989290396373

Epoch: 5| Step: 8
Training loss: 2.407183885574341
Validation loss: 1.9782534688711166

Epoch: 5| Step: 9
Training loss: 2.083069086074829
Validation loss: 1.979634294907252

Epoch: 5| Step: 10
Training loss: 2.136068344116211
Validation loss: 1.9855713198582332

Epoch: 5| Step: 11
Training loss: 2.6305928230285645
Validation loss: 1.972835550705592

Epoch: 16| Step: 0
Training loss: 1.6806913614273071
Validation loss: 1.9739624311526616

Epoch: 5| Step: 1
Training loss: 2.427001714706421
Validation loss: 1.9735651810963948

Epoch: 5| Step: 2
Training loss: 1.7653363943099976
Validation loss: 1.9746041645606358

Epoch: 5| Step: 3
Training loss: 2.203968048095703
Validation loss: 1.9695794234673183

Epoch: 5| Step: 4
Training loss: 1.9291582107543945
Validation loss: 1.9742404421170552

Epoch: 5| Step: 5
Training loss: 2.0364203453063965
Validation loss: 1.9692944188912709

Epoch: 5| Step: 6
Training loss: 1.7781620025634766
Validation loss: 1.9755448997020721

Epoch: 5| Step: 7
Training loss: 2.3814144134521484
Validation loss: 1.978994607925415

Epoch: 5| Step: 8
Training loss: 2.2210304737091064
Validation loss: 1.979592854777972

Epoch: 5| Step: 9
Training loss: 1.775411605834961
Validation loss: 1.9801817784706752

Epoch: 5| Step: 10
Training loss: 2.1412224769592285
Validation loss: 1.976428692539533

Epoch: 5| Step: 11
Training loss: 1.7416828870773315
Validation loss: 1.9690299332141876

Epoch: 17| Step: 0
Training loss: 2.3617076873779297
Validation loss: 1.9598859896262486

Epoch: 5| Step: 1
Training loss: 2.1372768878936768
Validation loss: 1.966315175096194

Epoch: 5| Step: 2
Training loss: 1.9085512161254883
Validation loss: 1.9620104680458705

Epoch: 5| Step: 3
Training loss: 2.2147724628448486
Validation loss: 1.9716418584187825

Epoch: 5| Step: 4
Training loss: 2.1017799377441406
Validation loss: 1.9737508197625477

Epoch: 5| Step: 5
Training loss: 1.4160270690917969
Validation loss: 1.9584518869717915

Epoch: 5| Step: 6
Training loss: 1.882422685623169
Validation loss: 1.9674812108278275

Epoch: 5| Step: 7
Training loss: 1.7585933208465576
Validation loss: 1.9810327341159184

Epoch: 5| Step: 8
Training loss: 2.744276523590088
Validation loss: 1.9578124930461247

Epoch: 5| Step: 9
Training loss: 1.8969676494598389
Validation loss: 1.9679617534081142

Epoch: 5| Step: 10
Training loss: 1.8954452276229858
Validation loss: 1.9666686405738194

Epoch: 5| Step: 11
Training loss: 1.3092182874679565
Validation loss: 1.9698526362578075

Epoch: 18| Step: 0
Training loss: 1.728257179260254
Validation loss: 1.9799506564935048

Epoch: 5| Step: 1
Training loss: 1.5934776067733765
Validation loss: 1.9708563635746639

Epoch: 5| Step: 2
Training loss: 2.2565383911132812
Validation loss: 1.9708796044190724

Epoch: 5| Step: 3
Training loss: 1.6765950918197632
Validation loss: 1.9758855551481247

Epoch: 5| Step: 4
Training loss: 2.3459267616271973
Validation loss: 1.9781096478303273

Epoch: 5| Step: 5
Training loss: 2.1696667671203613
Validation loss: 1.974421555797259

Epoch: 5| Step: 6
Training loss: 1.531207799911499
Validation loss: 1.9734020829200745

Epoch: 5| Step: 7
Training loss: 1.8362817764282227
Validation loss: 1.980236714084943

Epoch: 5| Step: 8
Training loss: 2.146724224090576
Validation loss: 1.9668085724115372

Epoch: 5| Step: 9
Training loss: 2.2714836597442627
Validation loss: 1.9579980820417404

Epoch: 5| Step: 10
Training loss: 2.2542407512664795
Validation loss: 1.9539768298467

Epoch: 5| Step: 11
Training loss: 3.3070197105407715
Validation loss: 1.967165286342303

Epoch: 19| Step: 0
Training loss: 2.1939399242401123
Validation loss: 1.9590280552705128

Epoch: 5| Step: 1
Training loss: 1.4948238134384155
Validation loss: 1.9662547558546066

Epoch: 5| Step: 2
Training loss: 2.641984462738037
Validation loss: 1.9660529245932896

Epoch: 5| Step: 3
Training loss: 2.726868152618408
Validation loss: 1.9660830746094387

Epoch: 5| Step: 4
Training loss: 1.8321056365966797
Validation loss: 1.9750122626622517

Epoch: 5| Step: 5
Training loss: 1.620059609413147
Validation loss: 1.9585176855325699

Epoch: 5| Step: 6
Training loss: 2.1061129570007324
Validation loss: 1.9518315643072128

Epoch: 5| Step: 7
Training loss: 1.7507355213165283
Validation loss: 1.958075185616811

Epoch: 5| Step: 8
Training loss: 1.7177108526229858
Validation loss: 1.9623925040165584

Epoch: 5| Step: 9
Training loss: 1.7809511423110962
Validation loss: 1.9645493080218632

Epoch: 5| Step: 10
Training loss: 2.058422803878784
Validation loss: 1.9632296512524288

Epoch: 5| Step: 11
Training loss: 2.0024023056030273
Validation loss: 1.9611544211705525

Epoch: 20| Step: 0
Training loss: 1.2633154392242432
Validation loss: 1.961622695128123

Epoch: 5| Step: 1
Training loss: 1.5983338356018066
Validation loss: 1.9846732566754024

Epoch: 5| Step: 2
Training loss: 2.5734798908233643
Validation loss: 1.9767851779858272

Epoch: 5| Step: 3
Training loss: 2.6919758319854736
Validation loss: 1.9865506539742153

Epoch: 5| Step: 4
Training loss: 1.903294324874878
Validation loss: 1.9775417000055313

Epoch: 5| Step: 5
Training loss: 1.7252670526504517
Validation loss: 1.9806249638398488

Epoch: 5| Step: 6
Training loss: 1.5152860879898071
Validation loss: 1.9835388610760372

Epoch: 5| Step: 7
Training loss: 2.0722808837890625
Validation loss: 1.9805185894171398

Epoch: 5| Step: 8
Training loss: 1.5270131826400757
Validation loss: 1.97339162727197

Epoch: 5| Step: 9
Training loss: 2.701099395751953
Validation loss: 1.9771994650363922

Epoch: 5| Step: 10
Training loss: 2.410717487335205
Validation loss: 1.9720306595166524

Epoch: 5| Step: 11
Training loss: 2.091583490371704
Validation loss: 1.9684759626785915

Epoch: 21| Step: 0
Training loss: 1.471329689025879
Validation loss: 1.970173105597496

Epoch: 5| Step: 1
Training loss: 2.0323948860168457
Validation loss: 1.9617446114619572

Epoch: 5| Step: 2
Training loss: 2.001749038696289
Validation loss: 1.9712103307247162

Epoch: 5| Step: 3
Training loss: 2.3787903785705566
Validation loss: 1.973815768957138

Epoch: 5| Step: 4
Training loss: 2.564423084259033
Validation loss: 1.9708653688430786

Epoch: 5| Step: 5
Training loss: 1.080989122390747
Validation loss: 1.9526363958915074

Epoch: 5| Step: 6
Training loss: 2.1689629554748535
Validation loss: 1.954407552878062

Epoch: 5| Step: 7
Training loss: 2.2160327434539795
Validation loss: 1.956182728211085

Epoch: 5| Step: 8
Training loss: 2.355288028717041
Validation loss: 1.9580231606960297

Epoch: 5| Step: 9
Training loss: 1.965230941772461
Validation loss: 1.9626283645629883

Epoch: 5| Step: 10
Training loss: 1.6303927898406982
Validation loss: 1.9542982478936513

Epoch: 5| Step: 11
Training loss: 1.6237589120864868
Validation loss: 1.9718244969844818

Epoch: 22| Step: 0
Training loss: 1.9490350484848022
Validation loss: 1.9601705968379974

Epoch: 5| Step: 1
Training loss: 1.5611579418182373
Validation loss: 1.9555588612953823

Epoch: 5| Step: 2
Training loss: 2.2709386348724365
Validation loss: 1.9578356246153514

Epoch: 5| Step: 3
Training loss: 1.7580108642578125
Validation loss: 1.9555649757385254

Epoch: 5| Step: 4
Training loss: 2.129002809524536
Validation loss: 1.9572030752897263

Epoch: 5| Step: 5
Training loss: 2.2937467098236084
Validation loss: 1.9618079513311386

Epoch: 5| Step: 6
Training loss: 2.196786880493164
Validation loss: 1.961714247862498

Epoch: 5| Step: 7
Training loss: 1.8643745183944702
Validation loss: 1.9647670090198517

Epoch: 5| Step: 8
Training loss: 2.021897792816162
Validation loss: 1.960534542798996

Epoch: 5| Step: 9
Training loss: 1.930699348449707
Validation loss: 1.9546775668859482

Epoch: 5| Step: 10
Training loss: 1.6709277629852295
Validation loss: 1.9596498757600784

Epoch: 5| Step: 11
Training loss: 2.1324634552001953
Validation loss: 1.9618672132492065

Epoch: 23| Step: 0
Training loss: 2.0415737628936768
Validation loss: 1.9563513646523158

Epoch: 5| Step: 1
Training loss: 2.019970417022705
Validation loss: 1.9591802408297856

Epoch: 5| Step: 2
Training loss: 2.0074777603149414
Validation loss: 1.9660334984461467

Epoch: 5| Step: 3
Training loss: 2.0958361625671387
Validation loss: 1.9736570964256923

Epoch: 5| Step: 4
Training loss: 1.861594557762146
Validation loss: 1.9760370602210362

Epoch: 5| Step: 5
Training loss: 1.4721893072128296
Validation loss: 1.9770467629035313

Epoch: 5| Step: 6
Training loss: 2.6066997051239014
Validation loss: 1.97938505311807

Epoch: 5| Step: 7
Training loss: 1.59479558467865
Validation loss: 1.9675879677136738

Epoch: 5| Step: 8
Training loss: 1.7465248107910156
Validation loss: 1.96530981361866

Epoch: 5| Step: 9
Training loss: 2.1333794593811035
Validation loss: 1.9810947279135387

Epoch: 5| Step: 10
Training loss: 2.286104679107666
Validation loss: 1.966145118077596

Epoch: 5| Step: 11
Training loss: 1.119953989982605
Validation loss: 1.960785244901975

Epoch: 24| Step: 0
Training loss: 2.0703766345977783
Validation loss: 1.9495716442664464

Epoch: 5| Step: 1
Training loss: 2.0386157035827637
Validation loss: 1.9561003148555756

Epoch: 5| Step: 2
Training loss: 2.0070719718933105
Validation loss: 1.9703541994094849

Epoch: 5| Step: 3
Training loss: 1.9793285131454468
Validation loss: 1.9531392008066177

Epoch: 5| Step: 4
Training loss: 1.7018588781356812
Validation loss: 1.958747406800588

Epoch: 5| Step: 5
Training loss: 1.9336169958114624
Validation loss: 1.9483909755945206

Epoch: 5| Step: 6
Training loss: 1.9301464557647705
Validation loss: 1.954019586245219

Epoch: 5| Step: 7
Training loss: 1.810333013534546
Validation loss: 1.9608672708272934

Epoch: 5| Step: 8
Training loss: 2.413956880569458
Validation loss: 1.976300949851672

Epoch: 5| Step: 9
Training loss: 2.0924155712127686
Validation loss: 1.976510946949323

Epoch: 5| Step: 10
Training loss: 1.6461385488510132
Validation loss: 1.972672735651334

Epoch: 5| Step: 11
Training loss: 1.2082895040512085
Validation loss: 1.983553186058998

Epoch: 25| Step: 0
Training loss: 1.6240257024765015
Validation loss: 1.9793566117684047

Epoch: 5| Step: 1
Training loss: 1.7724205255508423
Validation loss: 1.9821924070517223

Epoch: 5| Step: 2
Training loss: 1.9401878118515015
Validation loss: 1.9818284461895626

Epoch: 5| Step: 3
Training loss: 2.1484711170196533
Validation loss: 1.9827882995208104

Epoch: 5| Step: 4
Training loss: 1.9959900379180908
Validation loss: 1.9943613211313884

Epoch: 5| Step: 5
Training loss: 1.639828085899353
Validation loss: 1.9898285617431004

Epoch: 5| Step: 6
Training loss: 1.5314298868179321
Validation loss: 1.9714425802230835

Epoch: 5| Step: 7
Training loss: 2.217689037322998
Validation loss: 1.9820627172787983

Epoch: 5| Step: 8
Training loss: 2.78230619430542
Validation loss: 1.9750433762868245

Epoch: 5| Step: 9
Training loss: 1.528157114982605
Validation loss: 1.9716298431158066

Epoch: 5| Step: 10
Training loss: 2.3388750553131104
Validation loss: 1.96559739112854

Epoch: 5| Step: 11
Training loss: 1.6867812871932983
Validation loss: 1.9529839505751927

Epoch: 26| Step: 0
Training loss: 1.4233793020248413
Validation loss: 1.9608444174130757

Epoch: 5| Step: 1
Training loss: 1.914007544517517
Validation loss: 1.9500703662633896

Epoch: 5| Step: 2
Training loss: 2.062443971633911
Validation loss: 1.967356229821841

Epoch: 5| Step: 3
Training loss: 1.6558347940444946
Validation loss: 1.9492359111706417

Epoch: 5| Step: 4
Training loss: 2.1211631298065186
Validation loss: 1.9629569848378499

Epoch: 5| Step: 5
Training loss: 1.8023996353149414
Validation loss: 1.975329319636027

Epoch: 5| Step: 6
Training loss: 2.0369648933410645
Validation loss: 1.9898333102464676

Epoch: 5| Step: 7
Training loss: 2.7120890617370605
Validation loss: 1.9808863898118336

Epoch: 5| Step: 8
Training loss: 1.9992077350616455
Validation loss: 1.978235125541687

Epoch: 5| Step: 9
Training loss: 2.0146961212158203
Validation loss: 1.9783734232187271

Epoch: 5| Step: 10
Training loss: 1.7040904760360718
Validation loss: 1.967312331000964

Epoch: 5| Step: 11
Training loss: 2.585012912750244
Validation loss: 1.9702002207438152

Epoch: 27| Step: 0
Training loss: 1.847837209701538
Validation loss: 1.953935573498408

Epoch: 5| Step: 1
Training loss: 2.3898675441741943
Validation loss: 1.9536429246266682

Epoch: 5| Step: 2
Training loss: 1.864999532699585
Validation loss: 1.9474068482716878

Epoch: 5| Step: 3
Training loss: 1.9143664836883545
Validation loss: 1.9607359220584233

Epoch: 5| Step: 4
Training loss: 1.5878851413726807
Validation loss: 1.9490574498971303

Epoch: 5| Step: 5
Training loss: 1.8994337320327759
Validation loss: 1.9657886326313019

Epoch: 5| Step: 6
Training loss: 2.3487534523010254
Validation loss: 1.9596928258736928

Epoch: 5| Step: 7
Training loss: 2.458367109298706
Validation loss: 1.9571060885985692

Epoch: 5| Step: 8
Training loss: 1.7164249420166016
Validation loss: 1.9646433194478352

Epoch: 5| Step: 9
Training loss: 1.6724342107772827
Validation loss: 1.959675704439481

Epoch: 5| Step: 10
Training loss: 1.6468193531036377
Validation loss: 1.955661654472351

Epoch: 5| Step: 11
Training loss: 2.1265857219696045
Validation loss: 1.966955949862798

Epoch: 28| Step: 0
Training loss: 2.0534462928771973
Validation loss: 1.95651209851106

Epoch: 5| Step: 1
Training loss: 1.644775390625
Validation loss: 1.9802997807661693

Epoch: 5| Step: 2
Training loss: 1.6572654247283936
Validation loss: 1.9758004546165466

Epoch: 5| Step: 3
Training loss: 1.3124372959136963
Validation loss: 1.9813144505023956

Epoch: 5| Step: 4
Training loss: 2.3984975814819336
Validation loss: 1.9741222659746807

Epoch: 5| Step: 5
Training loss: 2.101142168045044
Validation loss: 2.0173111061255136

Epoch: 5| Step: 6
Training loss: 1.87740159034729
Validation loss: 1.997413232922554

Epoch: 5| Step: 7
Training loss: 1.652695894241333
Validation loss: 2.006383404135704

Epoch: 5| Step: 8
Training loss: 2.884841203689575
Validation loss: 2.0205204834540686

Epoch: 5| Step: 9
Training loss: 1.7953475713729858
Validation loss: 2.013455882668495

Epoch: 5| Step: 10
Training loss: 2.0801243782043457
Validation loss: 1.97925166785717

Epoch: 5| Step: 11
Training loss: 2.083848476409912
Validation loss: 1.9650889088710148

Epoch: 29| Step: 0
Training loss: 1.9129356145858765
Validation loss: 1.9520985285441081

Epoch: 5| Step: 1
Training loss: 1.4771232604980469
Validation loss: 1.9594338635603588

Epoch: 5| Step: 2
Training loss: 2.146063804626465
Validation loss: 1.9495523323615391

Epoch: 5| Step: 3
Training loss: 1.9755761623382568
Validation loss: 1.9534551004568736

Epoch: 5| Step: 4
Training loss: 2.5462841987609863
Validation loss: 1.9431686600049336

Epoch: 5| Step: 5
Training loss: 1.4527645111083984
Validation loss: 1.9504950841267903

Epoch: 5| Step: 6
Training loss: 1.9502317905426025
Validation loss: 1.9573026895523071

Epoch: 5| Step: 7
Training loss: 1.8706881999969482
Validation loss: 1.9507604787747066

Epoch: 5| Step: 8
Training loss: 1.7840973138809204
Validation loss: 1.9407842457294464

Epoch: 5| Step: 9
Training loss: 2.1644318103790283
Validation loss: 1.9576434046030045

Epoch: 5| Step: 10
Training loss: 1.6216485500335693
Validation loss: 1.9638027896483738

Epoch: 5| Step: 11
Training loss: 4.06071662902832
Validation loss: 1.943278397123019

Epoch: 30| Step: 0
Training loss: 2.156839609146118
Validation loss: 1.9525088220834732

Epoch: 5| Step: 1
Training loss: 1.9033008813858032
Validation loss: 1.9568622161944706

Epoch: 5| Step: 2
Training loss: 2.1413536071777344
Validation loss: 1.9598315060138702

Epoch: 5| Step: 3
Training loss: 2.2789223194122314
Validation loss: 1.948037678996722

Epoch: 5| Step: 4
Training loss: 2.2275948524475098
Validation loss: 1.9548656692107518

Epoch: 5| Step: 5
Training loss: 1.7516822814941406
Validation loss: 1.9580679337183635

Epoch: 5| Step: 6
Training loss: 1.6948553323745728
Validation loss: 1.9545334080855052

Epoch: 5| Step: 7
Training loss: 1.5323129892349243
Validation loss: 1.9714432458082836

Epoch: 5| Step: 8
Training loss: 1.984214425086975
Validation loss: 1.9561508893966675

Epoch: 5| Step: 9
Training loss: 2.0389561653137207
Validation loss: 1.9625565260648727

Epoch: 5| Step: 10
Training loss: 1.5730106830596924
Validation loss: 1.966372216741244

Epoch: 5| Step: 11
Training loss: 1.6070668697357178
Validation loss: 1.9576240330934525

Epoch: 31| Step: 0
Training loss: 2.839439868927002
Validation loss: 1.9879510949055355

Epoch: 5| Step: 1
Training loss: 2.1712546348571777
Validation loss: 1.993482564886411

Epoch: 5| Step: 2
Training loss: 1.561850905418396
Validation loss: 1.9845880419015884

Epoch: 5| Step: 3
Training loss: 1.8522602319717407
Validation loss: 2.005386327703794

Epoch: 5| Step: 4
Training loss: 2.217658519744873
Validation loss: 1.9940533687671025

Epoch: 5| Step: 5
Training loss: 1.4474937915802002
Validation loss: 1.9872915148735046

Epoch: 5| Step: 6
Training loss: 1.6378787755966187
Validation loss: 1.9737172176440556

Epoch: 5| Step: 7
Training loss: 1.7865326404571533
Validation loss: 1.9991388022899628

Epoch: 5| Step: 8
Training loss: 2.050854444503784
Validation loss: 1.9722327639659245

Epoch: 5| Step: 9
Training loss: 1.4230096340179443
Validation loss: 1.9763630330562592

Epoch: 5| Step: 10
Training loss: 2.1350433826446533
Validation loss: 1.9882886310418446

Epoch: 5| Step: 11
Training loss: 2.005868434906006
Validation loss: 1.9751851856708527

Epoch: 32| Step: 0
Training loss: 1.8358417749404907
Validation loss: 1.9645975530147552

Epoch: 5| Step: 1
Training loss: 1.904982328414917
Validation loss: 1.9631947775681813

Epoch: 5| Step: 2
Training loss: 2.3174147605895996
Validation loss: 1.9709625939528148

Epoch: 5| Step: 3
Training loss: 1.6812719106674194
Validation loss: 1.9598697324593861

Epoch: 5| Step: 4
Training loss: 1.7447731494903564
Validation loss: 1.975269262989362

Epoch: 5| Step: 5
Training loss: 1.7712080478668213
Validation loss: 1.982920080423355

Epoch: 5| Step: 6
Training loss: 1.8209670782089233
Validation loss: 1.9686030050118764

Epoch: 5| Step: 7
Training loss: 1.6156165599822998
Validation loss: 1.9814886450767517

Epoch: 5| Step: 8
Training loss: 2.595738172531128
Validation loss: 1.9887703408797581

Epoch: 5| Step: 9
Training loss: 2.196768045425415
Validation loss: 1.9898595015207927

Epoch: 5| Step: 10
Training loss: 1.696006178855896
Validation loss: 1.9640909681717555

Epoch: 5| Step: 11
Training loss: 1.2811521291732788
Validation loss: 1.9736905843019485

Epoch: 33| Step: 0
Training loss: 1.6524572372436523
Validation loss: 1.9643413722515106

Epoch: 5| Step: 1
Training loss: 1.8793079853057861
Validation loss: 1.9602045168479283

Epoch: 5| Step: 2
Training loss: 2.539292812347412
Validation loss: 1.9643183747927349

Epoch: 5| Step: 3
Training loss: 1.6698356866836548
Validation loss: 1.9388105124235153

Epoch: 5| Step: 4
Training loss: 2.353074550628662
Validation loss: 1.9512506524721782

Epoch: 5| Step: 5
Training loss: 0.972870945930481
Validation loss: 1.9483885318040848

Epoch: 5| Step: 6
Training loss: 1.8886516094207764
Validation loss: 1.9477882782618205

Epoch: 5| Step: 7
Training loss: 1.6578515768051147
Validation loss: 1.9392737100521724

Epoch: 5| Step: 8
Training loss: 2.1894466876983643
Validation loss: 1.9455257256825764

Epoch: 5| Step: 9
Training loss: 1.952244520187378
Validation loss: 1.947898581624031

Epoch: 5| Step: 10
Training loss: 2.0463626384735107
Validation loss: 1.9662970900535583

Epoch: 5| Step: 11
Training loss: 3.5347940921783447
Validation loss: 1.9771145681540172

Epoch: 34| Step: 0
Training loss: 2.005657196044922
Validation loss: 1.977504124244054

Epoch: 5| Step: 1
Training loss: 2.0900075435638428
Validation loss: 1.9963473329941432

Epoch: 5| Step: 2
Training loss: 1.5692508220672607
Validation loss: 1.9982074946165085

Epoch: 5| Step: 3
Training loss: 2.508371353149414
Validation loss: 2.0048030465841293

Epoch: 5| Step: 4
Training loss: 1.41548752784729
Validation loss: 1.9908767342567444

Epoch: 5| Step: 5
Training loss: 1.6164029836654663
Validation loss: 1.9907610168059666

Epoch: 5| Step: 6
Training loss: 1.5015712976455688
Validation loss: 1.9651601314544678

Epoch: 5| Step: 7
Training loss: 2.4950907230377197
Validation loss: 1.958775907754898

Epoch: 5| Step: 8
Training loss: 2.16009521484375
Validation loss: 1.9556614359219868

Epoch: 5| Step: 9
Training loss: 2.2279086112976074
Validation loss: 1.9508341203133266

Epoch: 5| Step: 10
Training loss: 1.6756690740585327
Validation loss: 1.9513928443193436

Epoch: 5| Step: 11
Training loss: 1.493696689605713
Validation loss: 1.9700138370196025

Epoch: 35| Step: 0
Training loss: 1.9900569915771484
Validation loss: 1.9532146851221721

Epoch: 5| Step: 1
Training loss: 1.920243501663208
Validation loss: 1.9485384623209636

Epoch: 5| Step: 2
Training loss: 1.998509407043457
Validation loss: 1.9480257332324982

Epoch: 5| Step: 3
Training loss: 2.3076255321502686
Validation loss: 1.9434879074494045

Epoch: 5| Step: 4
Training loss: 2.2143771648406982
Validation loss: 1.9660830895105998

Epoch: 5| Step: 5
Training loss: 1.3876512050628662
Validation loss: 1.9575803925593693

Epoch: 5| Step: 6
Training loss: 1.2226274013519287
Validation loss: 1.9513241400321324

Epoch: 5| Step: 7
Training loss: 1.7383060455322266
Validation loss: 1.9604085336128871

Epoch: 5| Step: 8
Training loss: 2.1242761611938477
Validation loss: 1.9623140543699265

Epoch: 5| Step: 9
Training loss: 1.8644816875457764
Validation loss: 1.957757756114006

Epoch: 5| Step: 10
Training loss: 2.183882474899292
Validation loss: 1.9712862869103749

Epoch: 5| Step: 11
Training loss: 1.6276953220367432
Validation loss: 1.968104417125384

Epoch: 36| Step: 0
Training loss: 1.4229215383529663
Validation loss: 1.9604335526625316

Epoch: 5| Step: 1
Training loss: 2.155526638031006
Validation loss: 1.9582102100054424

Epoch: 5| Step: 2
Training loss: 2.577414035797119
Validation loss: 1.964130570491155

Epoch: 5| Step: 3
Training loss: 2.2604587078094482
Validation loss: 1.955946480234464

Epoch: 5| Step: 4
Training loss: 1.5228549242019653
Validation loss: 1.961657350262006

Epoch: 5| Step: 5
Training loss: 1.803884506225586
Validation loss: 1.9603347529967625

Epoch: 5| Step: 6
Training loss: 2.282407283782959
Validation loss: 1.9500860621531804

Epoch: 5| Step: 7
Training loss: 1.9635627269744873
Validation loss: 1.9522155225276947

Epoch: 5| Step: 8
Training loss: 1.6794874668121338
Validation loss: 1.9694961657126744

Epoch: 5| Step: 9
Training loss: 1.6126121282577515
Validation loss: 1.949706807732582

Epoch: 5| Step: 10
Training loss: 1.7686846256256104
Validation loss: 1.9610229581594467

Epoch: 5| Step: 11
Training loss: 0.582047700881958
Validation loss: 1.9586994896332424

Epoch: 37| Step: 0
Training loss: 1.9956458806991577
Validation loss: 1.97362353404363

Epoch: 5| Step: 1
Training loss: 1.9198997020721436
Validation loss: 1.9815325339635212

Epoch: 5| Step: 2
Training loss: 1.6533615589141846
Validation loss: 1.9683891187111537

Epoch: 5| Step: 3
Training loss: 2.1206045150756836
Validation loss: 1.9797518352667491

Epoch: 5| Step: 4
Training loss: 1.6215136051177979
Validation loss: 1.9770761728286743

Epoch: 5| Step: 5
Training loss: 1.794910192489624
Validation loss: 1.971821556488673

Epoch: 5| Step: 6
Training loss: 2.3616275787353516
Validation loss: 1.9598884532848995

Epoch: 5| Step: 7
Training loss: 1.6386821269989014
Validation loss: 1.944897085428238

Epoch: 5| Step: 8
Training loss: 1.996377944946289
Validation loss: 1.9467724015315373

Epoch: 5| Step: 9
Training loss: 2.195232629776001
Validation loss: 1.9584943701823552

Epoch: 5| Step: 10
Training loss: 1.6659762859344482
Validation loss: 1.947520598769188

Epoch: 5| Step: 11
Training loss: 0.5347036123275757
Validation loss: 1.9611326058705647

Epoch: 38| Step: 0
Training loss: 1.5646719932556152
Validation loss: 1.9542478621006012

Epoch: 5| Step: 1
Training loss: 1.695826768875122
Validation loss: 1.9404811014731724

Epoch: 5| Step: 2
Training loss: 2.1024057865142822
Validation loss: 1.9566091448068619

Epoch: 5| Step: 3
Training loss: 1.4871909618377686
Validation loss: 1.9541639933983486

Epoch: 5| Step: 4
Training loss: 2.3367908000946045
Validation loss: 1.9454013456900914

Epoch: 5| Step: 5
Training loss: 1.9898643493652344
Validation loss: 1.9414040644963582

Epoch: 5| Step: 6
Training loss: 1.4682241678237915
Validation loss: 1.930024469892184

Epoch: 5| Step: 7
Training loss: 1.8974883556365967
Validation loss: 1.944501832127571

Epoch: 5| Step: 8
Training loss: 2.281792402267456
Validation loss: 1.9455830305814743

Epoch: 5| Step: 9
Training loss: 2.1035497188568115
Validation loss: 1.9468419154485066

Epoch: 5| Step: 10
Training loss: 1.675021767616272
Validation loss: 1.9513533810774486

Epoch: 5| Step: 11
Training loss: 2.6048614978790283
Validation loss: 1.961046079794566

Epoch: 39| Step: 0
Training loss: 1.8260810375213623
Validation loss: 1.9602914651234944

Epoch: 5| Step: 1
Training loss: 1.8113596439361572
Validation loss: 1.9913727591435115

Epoch: 5| Step: 2
Training loss: 1.4047026634216309
Validation loss: 1.9948648810386658

Epoch: 5| Step: 3
Training loss: 2.856853723526001
Validation loss: 1.9893341213464737

Epoch: 5| Step: 4
Training loss: 1.5740063190460205
Validation loss: 2.0046425412098565

Epoch: 5| Step: 5
Training loss: 2.1241307258605957
Validation loss: 2.021381065249443

Epoch: 5| Step: 6
Training loss: 1.58641517162323
Validation loss: 2.0058514773845673

Epoch: 5| Step: 7
Training loss: 1.928544282913208
Validation loss: 2.0033613493045173

Epoch: 5| Step: 8
Training loss: 2.1416051387786865
Validation loss: 1.9844853828350704

Epoch: 5| Step: 9
Training loss: 2.1523361206054688
Validation loss: 1.990481197834015

Epoch: 5| Step: 10
Training loss: 1.6883862018585205
Validation loss: 1.952229897181193

Epoch: 5| Step: 11
Training loss: 1.153714895248413
Validation loss: 1.9474515865246456

Epoch: 40| Step: 0
Training loss: 2.005263566970825
Validation loss: 1.9277183959881465

Epoch: 5| Step: 1
Training loss: 2.066862106323242
Validation loss: 1.9363645762205124

Epoch: 5| Step: 2
Training loss: 1.7959293127059937
Validation loss: 1.9445517857869465

Epoch: 5| Step: 3
Training loss: 1.8622270822525024
Validation loss: 1.9526444921890895

Epoch: 5| Step: 4
Training loss: 1.2918179035186768
Validation loss: 1.9406264623006184

Epoch: 5| Step: 5
Training loss: 2.1055192947387695
Validation loss: 1.9469738105932872

Epoch: 5| Step: 6
Training loss: 2.0108790397644043
Validation loss: 1.9567945251862209

Epoch: 5| Step: 7
Training loss: 1.8282432556152344
Validation loss: 1.9547972331444423

Epoch: 5| Step: 8
Training loss: 2.1941628456115723
Validation loss: 1.9675524334112804

Epoch: 5| Step: 9
Training loss: 1.7526447772979736
Validation loss: 1.9449615428845088

Epoch: 5| Step: 10
Training loss: 1.7548720836639404
Validation loss: 1.9533509115378063

Epoch: 5| Step: 11
Training loss: 1.8871045112609863
Validation loss: 1.9601256400346756

Epoch: 41| Step: 0
Training loss: 2.2048611640930176
Validation loss: 1.9543304592370987

Epoch: 5| Step: 1
Training loss: 1.8733479976654053
Validation loss: 1.9558110535144806

Epoch: 5| Step: 2
Training loss: 2.24766206741333
Validation loss: 1.9596880823373795

Epoch: 5| Step: 3
Training loss: 2.2334723472595215
Validation loss: 1.9728354165951412

Epoch: 5| Step: 4
Training loss: 2.2037582397460938
Validation loss: 1.9560145735740662

Epoch: 5| Step: 5
Training loss: 1.3301169872283936
Validation loss: 1.969280630350113

Epoch: 5| Step: 6
Training loss: 1.165582299232483
Validation loss: 1.9545789957046509

Epoch: 5| Step: 7
Training loss: 1.7097501754760742
Validation loss: 1.9521197279294331

Epoch: 5| Step: 8
Training loss: 2.0676233768463135
Validation loss: 1.9484090954065323

Epoch: 5| Step: 9
Training loss: 2.0137243270874023
Validation loss: 1.9479078749815624

Epoch: 5| Step: 10
Training loss: 1.3158982992172241
Validation loss: 1.9511175205310185

Epoch: 5| Step: 11
Training loss: 1.7877167463302612
Validation loss: 1.948840801914533

Epoch: 42| Step: 0
Training loss: 2.067160129547119
Validation loss: 1.9362983852624893

Epoch: 5| Step: 1
Training loss: 1.9076144695281982
Validation loss: 1.9423187623421352

Epoch: 5| Step: 2
Training loss: 1.5174663066864014
Validation loss: 1.9372254759073257

Epoch: 5| Step: 3
Training loss: 1.8959077596664429
Validation loss: 1.9452338616053264

Epoch: 5| Step: 4
Training loss: 1.6446653604507446
Validation loss: 1.9492211292187374

Epoch: 5| Step: 5
Training loss: 2.09672474861145
Validation loss: 1.954457625746727

Epoch: 5| Step: 6
Training loss: 1.7162870168685913
Validation loss: 1.9776025613149006

Epoch: 5| Step: 7
Training loss: 1.5968244075775146
Validation loss: 1.975619335969289

Epoch: 5| Step: 8
Training loss: 1.9314830303192139
Validation loss: 1.9676705201466878

Epoch: 5| Step: 9
Training loss: 2.360424757003784
Validation loss: 1.9513903260231018

Epoch: 5| Step: 10
Training loss: 1.663793921470642
Validation loss: 1.9531636635462444

Epoch: 5| Step: 11
Training loss: 2.7330734729766846
Validation loss: 1.933517058690389

Epoch: 43| Step: 0
Training loss: 1.691625952720642
Validation loss: 1.938588524858157

Epoch: 5| Step: 1
Training loss: 1.8624179363250732
Validation loss: 1.9345945318539937

Epoch: 5| Step: 2
Training loss: 1.8734731674194336
Validation loss: 1.9250124394893646

Epoch: 5| Step: 3
Training loss: 2.196566343307495
Validation loss: 1.9295207560062408

Epoch: 5| Step: 4
Training loss: 2.6495091915130615
Validation loss: 1.9301318476597469

Epoch: 5| Step: 5
Training loss: 1.9635883569717407
Validation loss: 1.9353790034850438

Epoch: 5| Step: 6
Training loss: 2.1912341117858887
Validation loss: 1.9444638987382252

Epoch: 5| Step: 7
Training loss: 1.4011989831924438
Validation loss: 1.932605504989624

Epoch: 5| Step: 8
Training loss: 1.463172197341919
Validation loss: 1.9422098298867543

Epoch: 5| Step: 9
Training loss: 1.7757742404937744
Validation loss: 1.9351681421200435

Epoch: 5| Step: 10
Training loss: 2.1182026863098145
Validation loss: 1.9365654389063518

Epoch: 5| Step: 11
Training loss: 1.226513147354126
Validation loss: 1.9386271337668102

Epoch: 44| Step: 0
Training loss: 1.8449313640594482
Validation loss: 1.9433222661415737

Epoch: 5| Step: 1
Training loss: 2.0060677528381348
Validation loss: 1.9490222483873367

Epoch: 5| Step: 2
Training loss: 1.990369200706482
Validation loss: 1.9883151352405548

Epoch: 5| Step: 3
Training loss: 1.187705636024475
Validation loss: 1.9785921772321065

Epoch: 5| Step: 4
Training loss: 2.400491237640381
Validation loss: 1.9948245684305828

Epoch: 5| Step: 5
Training loss: 1.889786958694458
Validation loss: 1.9770839313666027

Epoch: 5| Step: 6
Training loss: 1.504596471786499
Validation loss: 1.9548596143722534

Epoch: 5| Step: 7
Training loss: 1.9101940393447876
Validation loss: 1.9648843258619308

Epoch: 5| Step: 8
Training loss: 2.461627960205078
Validation loss: 1.9658405135075252

Epoch: 5| Step: 9
Training loss: 1.6174108982086182
Validation loss: 1.9755889972050984

Epoch: 5| Step: 10
Training loss: 1.6276298761367798
Validation loss: 1.9654552688201268

Epoch: 5| Step: 11
Training loss: 1.653571605682373
Validation loss: 1.9713133970896404

Epoch: 45| Step: 0
Training loss: 1.7921091318130493
Validation loss: 1.9629314690828323

Epoch: 5| Step: 1
Training loss: 1.4741462469100952
Validation loss: 1.9608924686908722

Epoch: 5| Step: 2
Training loss: 2.2493700981140137
Validation loss: 1.966012418270111

Epoch: 5| Step: 3
Training loss: 1.4304563999176025
Validation loss: 1.9634371101856232

Epoch: 5| Step: 4
Training loss: 1.656031847000122
Validation loss: 1.9649781833092372

Epoch: 5| Step: 5
Training loss: 2.1997997760772705
Validation loss: 1.973710502187411

Epoch: 5| Step: 6
Training loss: 1.49439537525177
Validation loss: 1.964615449309349

Epoch: 5| Step: 7
Training loss: 2.157634735107422
Validation loss: 1.9598321914672852

Epoch: 5| Step: 8
Training loss: 2.276949882507324
Validation loss: 1.9242031872272491

Epoch: 5| Step: 9
Training loss: 2.1052143573760986
Validation loss: 1.9317750334739685

Epoch: 5| Step: 10
Training loss: 1.4385125637054443
Validation loss: 1.9284523477156956

Epoch: 5| Step: 11
Training loss: 2.2531020641326904
Validation loss: 1.9371439615885417

Epoch: 46| Step: 0
Training loss: 1.515831470489502
Validation loss: 1.9352689137061436

Epoch: 5| Step: 1
Training loss: 2.026550769805908
Validation loss: 1.9322986553112667

Epoch: 5| Step: 2
Training loss: 2.1041648387908936
Validation loss: 1.9245702028274536

Epoch: 5| Step: 3
Training loss: 1.7257699966430664
Validation loss: 1.9214517871538799

Epoch: 5| Step: 4
Training loss: 2.0305049419403076
Validation loss: 1.943631703654925

Epoch: 5| Step: 5
Training loss: 1.3973102569580078
Validation loss: 1.958916316429774

Epoch: 5| Step: 6
Training loss: 1.7951009273529053
Validation loss: 1.9700090785821278

Epoch: 5| Step: 7
Training loss: 2.7524638175964355
Validation loss: 1.9588051438331604

Epoch: 5| Step: 8
Training loss: 1.7412049770355225
Validation loss: 1.9859858850638072

Epoch: 5| Step: 9
Training loss: 1.7697728872299194
Validation loss: 1.9813552995522816

Epoch: 5| Step: 10
Training loss: 1.5836044549942017
Validation loss: 1.9932737201452255

Epoch: 5| Step: 11
Training loss: 2.2868475914001465
Validation loss: 1.9909074306488037

Epoch: 47| Step: 0
Training loss: 1.3932839632034302
Validation loss: 1.967455804347992

Epoch: 5| Step: 1
Training loss: 1.8373655080795288
Validation loss: 1.9800112942854564

Epoch: 5| Step: 2
Training loss: 2.1651101112365723
Validation loss: 1.952313353617986

Epoch: 5| Step: 3
Training loss: 1.6238704919815063
Validation loss: 1.961787263552348

Epoch: 5| Step: 4
Training loss: 2.8032736778259277
Validation loss: 1.9334211697181065

Epoch: 5| Step: 5
Training loss: 2.046509027481079
Validation loss: 1.943580836057663

Epoch: 5| Step: 6
Training loss: 1.715314507484436
Validation loss: 1.944260795911153

Epoch: 5| Step: 7
Training loss: 1.4453201293945312
Validation loss: 1.9496737370888393

Epoch: 5| Step: 8
Training loss: 2.043503522872925
Validation loss: 1.940853585799535

Epoch: 5| Step: 9
Training loss: 1.3065345287322998
Validation loss: 1.9478154629468918

Epoch: 5| Step: 10
Training loss: 1.6426537036895752
Validation loss: 1.940765971938769

Epoch: 5| Step: 11
Training loss: 2.192521095275879
Validation loss: 1.9264644185702007

Epoch: 48| Step: 0
Training loss: 2.199767589569092
Validation loss: 1.9389020204544067

Epoch: 5| Step: 1
Training loss: 2.2223687171936035
Validation loss: 1.9333494851986568

Epoch: 5| Step: 2
Training loss: 1.6500647068023682
Validation loss: 1.9404443701108296

Epoch: 5| Step: 3
Training loss: 1.4838300943374634
Validation loss: 1.9445261061191559

Epoch: 5| Step: 4
Training loss: 1.7052189111709595
Validation loss: 1.9478484839200974

Epoch: 5| Step: 5
Training loss: 2.5024991035461426
Validation loss: 1.9725880076487858

Epoch: 5| Step: 6
Training loss: 2.000718832015991
Validation loss: 1.9702122608820598

Epoch: 5| Step: 7
Training loss: 1.7462717294692993
Validation loss: 1.9639205237229664

Epoch: 5| Step: 8
Training loss: 1.9096088409423828
Validation loss: 1.9580870121717453

Epoch: 5| Step: 9
Training loss: 1.3768504858016968
Validation loss: 1.9341833541790645

Epoch: 5| Step: 10
Training loss: 1.5671979188919067
Validation loss: 1.9491353730360668

Epoch: 5| Step: 11
Training loss: 0.8461973071098328
Validation loss: 1.9498632649580638

Epoch: 49| Step: 0
Training loss: 1.8837814331054688
Validation loss: 1.9652808755636215

Epoch: 5| Step: 1
Training loss: 1.4912675619125366
Validation loss: 1.9756246954202652

Epoch: 5| Step: 2
Training loss: 1.6366159915924072
Validation loss: 2.0107035835584006

Epoch: 5| Step: 3
Training loss: 2.1294360160827637
Validation loss: 2.0039272606372833

Epoch: 5| Step: 4
Training loss: 1.5818790197372437
Validation loss: 1.9958059340715408

Epoch: 5| Step: 5
Training loss: 2.2909464836120605
Validation loss: 2.0092705438534417

Epoch: 5| Step: 6
Training loss: 1.840113639831543
Validation loss: 2.00524007777373

Epoch: 5| Step: 7
Training loss: 1.6848630905151367
Validation loss: 2.011196345090866

Epoch: 5| Step: 8
Training loss: 1.6994861364364624
Validation loss: 1.9749187777439754

Epoch: 5| Step: 9
Training loss: 1.9330583810806274
Validation loss: 1.9741289814313252

Epoch: 5| Step: 10
Training loss: 2.149066925048828
Validation loss: 1.950260857741038

Epoch: 5| Step: 11
Training loss: 1.0387790203094482
Validation loss: 1.9501390904188156

Epoch: 50| Step: 0
Training loss: 1.7753982543945312
Validation loss: 1.9359322637319565

Epoch: 5| Step: 1
Training loss: 1.674346923828125
Validation loss: 1.9389585455258687

Epoch: 5| Step: 2
Training loss: 2.003425121307373
Validation loss: 1.9396350036064784

Epoch: 5| Step: 3
Training loss: 2.302211284637451
Validation loss: 1.9479951411485672

Epoch: 5| Step: 4
Training loss: 1.9587570428848267
Validation loss: 1.940307209889094

Epoch: 5| Step: 5
Training loss: 1.611554741859436
Validation loss: 1.9398431777954102

Epoch: 5| Step: 6
Training loss: 1.872382402420044
Validation loss: 1.9414592931667964

Epoch: 5| Step: 7
Training loss: 1.197386622428894
Validation loss: 1.9428962618112564

Epoch: 5| Step: 8
Training loss: 1.480372428894043
Validation loss: 1.9438499758640926

Epoch: 5| Step: 9
Training loss: 2.0624566078186035
Validation loss: 1.9542861978212993

Epoch: 5| Step: 10
Training loss: 2.263812303543091
Validation loss: 1.95410351951917

Epoch: 5| Step: 11
Training loss: 0.808483362197876
Validation loss: 1.9708446462949116

Testing loss: 1.906552483709596
