Epoch: 1| Step: 0
Training loss: 4.689137083920332
Validation loss: 6.31662366277035

Epoch: 6| Step: 1
Training loss: 6.109594785049169
Validation loss: 6.27947395988634

Epoch: 6| Step: 2
Training loss: 6.716879224924086
Validation loss: 6.244425869224377

Epoch: 6| Step: 3
Training loss: 6.637677999577429
Validation loss: 6.212242286909149

Epoch: 6| Step: 4
Training loss: 7.364158031767495
Validation loss: 6.176085195797077

Epoch: 6| Step: 5
Training loss: 6.40662275020752
Validation loss: 6.1380526240133415

Epoch: 6| Step: 6
Training loss: 5.681613768628517
Validation loss: 6.104472581230513

Epoch: 6| Step: 7
Training loss: 4.928827322562109
Validation loss: 6.071000160468203

Epoch: 6| Step: 8
Training loss: 5.9030394532289
Validation loss: 6.039417777852319

Epoch: 6| Step: 9
Training loss: 6.462846061250862
Validation loss: 6.00476626654634

Epoch: 6| Step: 10
Training loss: 6.7403801079036665
Validation loss: 5.971477983613174

Epoch: 6| Step: 11
Training loss: 6.214278103678135
Validation loss: 5.934981069473032

Epoch: 6| Step: 12
Training loss: 6.633093730234937
Validation loss: 5.9029875933687865

Epoch: 6| Step: 13
Training loss: 5.807444352906825
Validation loss: 5.865084999901618

Epoch: 2| Step: 0
Training loss: 6.611361590572613
Validation loss: 5.829106661542487

Epoch: 6| Step: 1
Training loss: 6.516238250048604
Validation loss: 5.788230214971129

Epoch: 6| Step: 2
Training loss: 6.246853455987737
Validation loss: 5.753637131014803

Epoch: 6| Step: 3
Training loss: 5.105337618462302
Validation loss: 5.709494210515755

Epoch: 6| Step: 4
Training loss: 5.390945734627301
Validation loss: 5.665673795371768

Epoch: 6| Step: 5
Training loss: 5.948900060201846
Validation loss: 5.6240170220397365

Epoch: 6| Step: 6
Training loss: 5.245987039646743
Validation loss: 5.581120275432997

Epoch: 6| Step: 7
Training loss: 6.240354801263651
Validation loss: 5.538257133211468

Epoch: 6| Step: 8
Training loss: 6.281788968928078
Validation loss: 5.491431266050026

Epoch: 6| Step: 9
Training loss: 4.740600320328084
Validation loss: 5.4405586438749305

Epoch: 6| Step: 10
Training loss: 4.570156622942756
Validation loss: 5.391553981179286

Epoch: 6| Step: 11
Training loss: 5.209809828964921
Validation loss: 5.345506613606958

Epoch: 6| Step: 12
Training loss: 4.8830839768281535
Validation loss: 5.294284783635959

Epoch: 6| Step: 13
Training loss: 5.780301072882282
Validation loss: 5.24196009135564

Epoch: 3| Step: 0
Training loss: 3.967038243518344
Validation loss: 5.179507552099825

Epoch: 6| Step: 1
Training loss: 4.873869153444965
Validation loss: 5.118468379097505

Epoch: 6| Step: 2
Training loss: 5.114624126864695
Validation loss: 5.06047227854329

Epoch: 6| Step: 3
Training loss: 5.497145345436351
Validation loss: 4.999607102533942

Epoch: 6| Step: 4
Training loss: 4.853689516816994
Validation loss: 4.9383240346126875

Epoch: 6| Step: 5
Training loss: 4.178855285504917
Validation loss: 4.870779248087711

Epoch: 6| Step: 6
Training loss: 5.905439048679278
Validation loss: 4.799184767052008

Epoch: 6| Step: 7
Training loss: 5.26641024838522
Validation loss: 4.7301458053751615

Epoch: 6| Step: 8
Training loss: 4.489946366905238
Validation loss: 4.6555621259901425

Epoch: 6| Step: 9
Training loss: 5.078362186468019
Validation loss: 4.572567392738666

Epoch: 6| Step: 10
Training loss: 4.583740123845288
Validation loss: 4.495198743766676

Epoch: 6| Step: 11
Training loss: 4.263103256718209
Validation loss: 4.415429979802061

Epoch: 6| Step: 12
Training loss: 4.24615529006117
Validation loss: 4.317653580499806

Epoch: 6| Step: 13
Training loss: 4.719334446163579
Validation loss: 4.227862615871726

Epoch: 4| Step: 0
Training loss: 4.494841267771415
Validation loss: 4.1361638442322155

Epoch: 6| Step: 1
Training loss: 4.7963007977787875
Validation loss: 4.04900986220174

Epoch: 6| Step: 2
Training loss: 3.481268211878698
Validation loss: 3.9431012191776897

Epoch: 6| Step: 3
Training loss: 3.697182567245885
Validation loss: 3.844693344679389

Epoch: 6| Step: 4
Training loss: 3.418488660234784
Validation loss: 3.7303321906587894

Epoch: 6| Step: 5
Training loss: 3.5473055809248306
Validation loss: 3.63906094376479

Epoch: 6| Step: 6
Training loss: 3.1069007115210487
Validation loss: 3.5317250835225376

Epoch: 6| Step: 7
Training loss: 3.147120652369993
Validation loss: 3.423994386346024

Epoch: 6| Step: 8
Training loss: 3.666021087918812
Validation loss: 3.337126044421853

Epoch: 6| Step: 9
Training loss: 3.313417703435745
Validation loss: 3.2322520415991316

Epoch: 6| Step: 10
Training loss: 3.9429830491555165
Validation loss: 3.1364844184398053

Epoch: 6| Step: 11
Training loss: 3.480829599086398
Validation loss: 3.0316710818697037

Epoch: 6| Step: 12
Training loss: 2.356470910196909
Validation loss: 2.936877421423891

Epoch: 6| Step: 13
Training loss: 2.7095071058614826
Validation loss: 2.8543091527266617

Epoch: 5| Step: 0
Training loss: 2.5805113874072187
Validation loss: 2.78482109289622

Epoch: 6| Step: 1
Training loss: 2.230116727878745
Validation loss: 2.723585279507465

Epoch: 6| Step: 2
Training loss: 2.938749007237444
Validation loss: 2.6668690788418465

Epoch: 6| Step: 3
Training loss: 2.077492983515857
Validation loss: 2.630648454661423

Epoch: 6| Step: 4
Training loss: 2.5434356120264603
Validation loss: 2.624932076317123

Epoch: 6| Step: 5
Training loss: 2.665962324902183
Validation loss: 2.6289833514776

Epoch: 6| Step: 6
Training loss: 2.5628595797695306
Validation loss: 2.6238222507647495

Epoch: 6| Step: 7
Training loss: 2.3162260194495374
Validation loss: 2.6610278822250333

Epoch: 6| Step: 8
Training loss: 3.0372963605522147
Validation loss: 2.667969539375989

Epoch: 6| Step: 9
Training loss: 2.8810576600193976
Validation loss: 2.7031494536423826

Epoch: 6| Step: 10
Training loss: 3.8930028060718755
Validation loss: 2.738652152039095

Epoch: 6| Step: 11
Training loss: 3.0371101600179853
Validation loss: 2.777092301243818

Epoch: 6| Step: 12
Training loss: 2.6765148187544576
Validation loss: 2.7512054980045693

Epoch: 6| Step: 13
Training loss: 3.031181098705489
Validation loss: 2.7527367816450976

Epoch: 6| Step: 0
Training loss: 2.1550740891751228
Validation loss: 2.7440330330423897

Epoch: 6| Step: 1
Training loss: 3.1210349295830135
Validation loss: 2.7216612330808982

Epoch: 6| Step: 2
Training loss: 2.495074474469288
Validation loss: 2.6827365444586384

Epoch: 6| Step: 3
Training loss: 1.4809001203570038
Validation loss: 2.672911950273483

Epoch: 6| Step: 4
Training loss: 2.7640693729157766
Validation loss: 2.6495992537446744

Epoch: 6| Step: 5
Training loss: 2.850833998338729
Validation loss: 2.673547559591112

Epoch: 6| Step: 6
Training loss: 2.31051302939074
Validation loss: 2.624661454061936

Epoch: 6| Step: 7
Training loss: 3.244214116228088
Validation loss: 2.6317791896687153

Epoch: 6| Step: 8
Training loss: 2.3665724354999704
Validation loss: 2.6138102590436785

Epoch: 6| Step: 9
Training loss: 2.5067067783609365
Validation loss: 2.640213973881825

Epoch: 6| Step: 10
Training loss: 2.869330413545071
Validation loss: 2.6198720496240977

Epoch: 6| Step: 11
Training loss: 2.8614624408534595
Validation loss: 2.614573662323309

Epoch: 6| Step: 12
Training loss: 2.86134362330487
Validation loss: 2.602660931470811

Epoch: 6| Step: 13
Training loss: 2.744025416009045
Validation loss: 2.6007557821970106

Epoch: 7| Step: 0
Training loss: 2.669070729764545
Validation loss: 2.6003036508163957

Epoch: 6| Step: 1
Training loss: 3.266509597920708
Validation loss: 2.6060640492871854

Epoch: 6| Step: 2
Training loss: 2.6120664684022805
Validation loss: 2.5823295678705085

Epoch: 6| Step: 3
Training loss: 2.8402169886153827
Validation loss: 2.6065495130630603

Epoch: 6| Step: 4
Training loss: 2.50985340009448
Validation loss: 2.5960114742974736

Epoch: 6| Step: 5
Training loss: 3.0474131573515137
Validation loss: 2.628117473710964

Epoch: 6| Step: 6
Training loss: 2.9766547721918477
Validation loss: 2.611778249014364

Epoch: 6| Step: 7
Training loss: 2.6234936706454985
Validation loss: 2.6229812185895125

Epoch: 6| Step: 8
Training loss: 2.0850526454508906
Validation loss: 2.6356509309367047

Epoch: 6| Step: 9
Training loss: 2.2883887226970403
Validation loss: 2.6182666584399077

Epoch: 6| Step: 10
Training loss: 2.1827930490532346
Validation loss: 2.612768528718895

Epoch: 6| Step: 11
Training loss: 3.0033671238812194
Validation loss: 2.6141446012717497

Epoch: 6| Step: 12
Training loss: 2.4711458194057676
Validation loss: 2.6066178395396693

Epoch: 6| Step: 13
Training loss: 2.320528065336457
Validation loss: 2.611364021520563

Epoch: 8| Step: 0
Training loss: 2.6217171258874186
Validation loss: 2.600961197563289

Epoch: 6| Step: 1
Training loss: 2.4508510668425494
Validation loss: 2.5984676766875037

Epoch: 6| Step: 2
Training loss: 2.010218266265468
Validation loss: 2.5900999990573297

Epoch: 6| Step: 3
Training loss: 2.480060886281687
Validation loss: 2.590289937167794

Epoch: 6| Step: 4
Training loss: 2.6408905256953146
Validation loss: 2.5778878151036615

Epoch: 6| Step: 5
Training loss: 2.29054561128734
Validation loss: 2.583539313646546

Epoch: 6| Step: 6
Training loss: 2.921921020798171
Validation loss: 2.579935366858432

Epoch: 6| Step: 7
Training loss: 3.096998416662504
Validation loss: 2.5822651690290135

Epoch: 6| Step: 8
Training loss: 3.0938347698889843
Validation loss: 2.5858248083908615

Epoch: 6| Step: 9
Training loss: 2.7139025916130293
Validation loss: 2.598725583058254

Epoch: 6| Step: 10
Training loss: 2.1226971433854196
Validation loss: 2.5999968345329383

Epoch: 6| Step: 11
Training loss: 3.0828514409880583
Validation loss: 2.5966464190332323

Epoch: 6| Step: 12
Training loss: 2.97838018390827
Validation loss: 2.5761806515844703

Epoch: 6| Step: 13
Training loss: 2.2462851268673134
Validation loss: 2.576682610119065

Epoch: 9| Step: 0
Training loss: 2.9741550431719586
Validation loss: 2.564272957269278

Epoch: 6| Step: 1
Training loss: 2.468380671048741
Validation loss: 2.5691391296676236

Epoch: 6| Step: 2
Training loss: 2.485246421523588
Validation loss: 2.579946440946609

Epoch: 6| Step: 3
Training loss: 2.8132741922185662
Validation loss: 2.5647462288517398

Epoch: 6| Step: 4
Training loss: 2.313531490912138
Validation loss: 2.5877874850466918

Epoch: 6| Step: 5
Training loss: 2.1383052982069337
Validation loss: 2.582764891154703

Epoch: 6| Step: 6
Training loss: 1.860890003690428
Validation loss: 2.5723074115746996

Epoch: 6| Step: 7
Training loss: 2.5858532295441
Validation loss: 2.5946004155163687

Epoch: 6| Step: 8
Training loss: 3.088760205278631
Validation loss: 2.5743406939337294

Epoch: 6| Step: 9
Training loss: 1.9436876489384147
Validation loss: 2.592420244795706

Epoch: 6| Step: 10
Training loss: 3.310347667540779
Validation loss: 2.5740765776902834

Epoch: 6| Step: 11
Training loss: 2.7805485215819528
Validation loss: 2.585998073456202

Epoch: 6| Step: 12
Training loss: 2.618506620109192
Validation loss: 2.5729963982669686

Epoch: 6| Step: 13
Training loss: 2.690438194746078
Validation loss: 2.5629438155494566

Epoch: 10| Step: 0
Training loss: 2.135693515106114
Validation loss: 2.570129882756408

Epoch: 6| Step: 1
Training loss: 3.3006874928899608
Validation loss: 2.5679327742243543

Epoch: 6| Step: 2
Training loss: 2.61295689507197
Validation loss: 2.576097203412015

Epoch: 6| Step: 3
Training loss: 2.3105652422267644
Validation loss: 2.583838080246092

Epoch: 6| Step: 4
Training loss: 3.1135073092723866
Validation loss: 2.5785305128133427

Epoch: 6| Step: 5
Training loss: 2.3019425937444704
Validation loss: 2.5664976617567246

Epoch: 6| Step: 6
Training loss: 2.5558021283636463
Validation loss: 2.563246548460483

Epoch: 6| Step: 7
Training loss: 2.2743580845274285
Validation loss: 2.5744353508595452

Epoch: 6| Step: 8
Training loss: 2.4971191974340847
Validation loss: 2.578799319465176

Epoch: 6| Step: 9
Training loss: 2.892619171984674
Validation loss: 2.551778352121659

Epoch: 6| Step: 10
Training loss: 2.459455643413836
Validation loss: 2.5679105610681785

Epoch: 6| Step: 11
Training loss: 1.8854446690062356
Validation loss: 2.566720433311927

Epoch: 6| Step: 12
Training loss: 2.5395970178057583
Validation loss: 2.5563321511546135

Epoch: 6| Step: 13
Training loss: 3.0950826221586203
Validation loss: 2.5617152617425836

Epoch: 11| Step: 0
Training loss: 2.9682407946318965
Validation loss: 2.563548563596977

Epoch: 6| Step: 1
Training loss: 2.481000900256091
Validation loss: 2.5513205393874197

Epoch: 6| Step: 2
Training loss: 3.1346372393880912
Validation loss: 2.563832572315292

Epoch: 6| Step: 3
Training loss: 2.4873648832036737
Validation loss: 2.5698622180628212

Epoch: 6| Step: 4
Training loss: 2.701869871658375
Validation loss: 2.5625337582977457

Epoch: 6| Step: 5
Training loss: 2.3596212498575997
Validation loss: 2.5648663612288534

Epoch: 6| Step: 6
Training loss: 2.5679386388987986
Validation loss: 2.541149795590644

Epoch: 6| Step: 7
Training loss: 2.618332159898844
Validation loss: 2.555698688502335

Epoch: 6| Step: 8
Training loss: 2.6017786801076013
Validation loss: 2.553729267431428

Epoch: 6| Step: 9
Training loss: 3.0373748565137517
Validation loss: 2.5642973016491513

Epoch: 6| Step: 10
Training loss: 2.0743893195816296
Validation loss: 2.5611546093696287

Epoch: 6| Step: 11
Training loss: 2.8843672366879884
Validation loss: 2.570528510233809

Epoch: 6| Step: 12
Training loss: 1.8397201204979894
Validation loss: 2.5602631769403983

Epoch: 6| Step: 13
Training loss: 2.2869846951765287
Validation loss: 2.5595667263036446

Epoch: 12| Step: 0
Training loss: 2.8440766199363123
Validation loss: 2.5535090039016497

Epoch: 6| Step: 1
Training loss: 2.155500862349707
Validation loss: 2.565551793629549

Epoch: 6| Step: 2
Training loss: 2.8342910905591454
Validation loss: 2.561312997569797

Epoch: 6| Step: 3
Training loss: 2.2125057414352147
Validation loss: 2.5535598272542153

Epoch: 6| Step: 4
Training loss: 2.703407405147357
Validation loss: 2.5435904325508156

Epoch: 6| Step: 5
Training loss: 2.2996740607807094
Validation loss: 2.5668005483149474

Epoch: 6| Step: 6
Training loss: 2.590819024158651
Validation loss: 2.5704522524855316

Epoch: 6| Step: 7
Training loss: 2.4465202298461355
Validation loss: 2.5610396946084073

Epoch: 6| Step: 8
Training loss: 2.408609397755691
Validation loss: 2.5669396560782616

Epoch: 6| Step: 9
Training loss: 2.5913806802467394
Validation loss: 2.581987173807488

Epoch: 6| Step: 10
Training loss: 2.1190885335259457
Validation loss: 2.60249515040737

Epoch: 6| Step: 11
Training loss: 2.5773781359304864
Validation loss: 2.5628457030041867

Epoch: 6| Step: 12
Training loss: 2.2831592669814604
Validation loss: 2.5897175646421147

Epoch: 6| Step: 13
Training loss: 3.814816630944976
Validation loss: 2.5727426930862114

Epoch: 13| Step: 0
Training loss: 3.233482053292525
Validation loss: 2.566857649047356

Epoch: 6| Step: 1
Training loss: 2.4387412212141477
Validation loss: 2.573443807946638

Epoch: 6| Step: 2
Training loss: 1.988981771816158
Validation loss: 2.5556617302422966

Epoch: 6| Step: 3
Training loss: 2.2850359501921744
Validation loss: 2.562491533218911

Epoch: 6| Step: 4
Training loss: 2.4986969412913895
Validation loss: 2.5443276457884374

Epoch: 6| Step: 5
Training loss: 1.997605440032909
Validation loss: 2.540252078230903

Epoch: 6| Step: 6
Training loss: 2.752074499546825
Validation loss: 2.5379686082622572

Epoch: 6| Step: 7
Training loss: 3.1944137092622884
Validation loss: 2.555115923407304

Epoch: 6| Step: 8
Training loss: 2.5745857683343005
Validation loss: 2.5554856075398313

Epoch: 6| Step: 9
Training loss: 2.297679837964129
Validation loss: 2.5616524930829505

Epoch: 6| Step: 10
Training loss: 2.353216153794524
Validation loss: 2.5593008136981936

Epoch: 6| Step: 11
Training loss: 2.478098203651279
Validation loss: 2.547504105519389

Epoch: 6| Step: 12
Training loss: 3.241833329676642
Validation loss: 2.54484144597521

Epoch: 6| Step: 13
Training loss: 2.4512372376743397
Validation loss: 2.544031970792887

Epoch: 14| Step: 0
Training loss: 2.7180950208928567
Validation loss: 2.5422672020864776

Epoch: 6| Step: 1
Training loss: 3.1926125309288698
Validation loss: 2.5564606216822896

Epoch: 6| Step: 2
Training loss: 2.37083048985137
Validation loss: 2.5564431973224977

Epoch: 6| Step: 3
Training loss: 2.399488982791969
Validation loss: 2.5565907021999106

Epoch: 6| Step: 4
Training loss: 2.675913118329088
Validation loss: 2.5324216572078244

Epoch: 6| Step: 5
Training loss: 2.2704745251256147
Validation loss: 2.543104583190778

Epoch: 6| Step: 6
Training loss: 2.1421897348382535
Validation loss: 2.5387747890126793

Epoch: 6| Step: 7
Training loss: 2.8615147656705164
Validation loss: 2.544482458886589

Epoch: 6| Step: 8
Training loss: 2.4597120352194914
Validation loss: 2.554676300864214

Epoch: 6| Step: 9
Training loss: 2.4077430155615853
Validation loss: 2.5406031859064724

Epoch: 6| Step: 10
Training loss: 2.704968832404053
Validation loss: 2.553019267662847

Epoch: 6| Step: 11
Training loss: 2.8866553189918713
Validation loss: 2.5455302645466986

Epoch: 6| Step: 12
Training loss: 2.4082815338512775
Validation loss: 2.5476456082864716

Epoch: 6| Step: 13
Training loss: 2.1290259651331596
Validation loss: 2.5528340902702396

Epoch: 15| Step: 0
Training loss: 2.7010001061053575
Validation loss: 2.536147086115935

Epoch: 6| Step: 1
Training loss: 3.0957912300159633
Validation loss: 2.535122628716411

Epoch: 6| Step: 2
Training loss: 2.315753812720681
Validation loss: 2.524170697186857

Epoch: 6| Step: 3
Training loss: 2.4175060612189316
Validation loss: 2.5284742512552634

Epoch: 6| Step: 4
Training loss: 2.727862990689173
Validation loss: 2.5532907134135305

Epoch: 6| Step: 5
Training loss: 3.442829785919492
Validation loss: 2.536975397963294

Epoch: 6| Step: 6
Training loss: 2.633474385632546
Validation loss: 2.52905137921623

Epoch: 6| Step: 7
Training loss: 1.8760961507383318
Validation loss: 2.5432348937319653

Epoch: 6| Step: 8
Training loss: 2.791251896653853
Validation loss: 2.5321188640335275

Epoch: 6| Step: 9
Training loss: 2.346911320106876
Validation loss: 2.535533984648146

Epoch: 6| Step: 10
Training loss: 1.9702980978769888
Validation loss: 2.5375099404301613

Epoch: 6| Step: 11
Training loss: 2.3160358924126907
Validation loss: 2.525734846745085

Epoch: 6| Step: 12
Training loss: 2.3434915018580726
Validation loss: 2.5332093367430586

Epoch: 6| Step: 13
Training loss: 2.6077022101757645
Validation loss: 2.5392917470877587

Epoch: 16| Step: 0
Training loss: 2.3752249560981658
Validation loss: 2.529244142274759

Epoch: 6| Step: 1
Training loss: 2.4380557087016923
Validation loss: 2.527715247874805

Epoch: 6| Step: 2
Training loss: 2.0494504843372634
Validation loss: 2.5399890167769814

Epoch: 6| Step: 3
Training loss: 2.34505680527848
Validation loss: 2.55520041446778

Epoch: 6| Step: 4
Training loss: 2.5665448527308268
Validation loss: 2.549770823009951

Epoch: 6| Step: 5
Training loss: 2.710058416039619
Validation loss: 2.54314309893193

Epoch: 6| Step: 6
Training loss: 2.5956682212899724
Validation loss: 2.545498934530079

Epoch: 6| Step: 7
Training loss: 2.4849229124458447
Validation loss: 2.557562972294423

Epoch: 6| Step: 8
Training loss: 2.8983420795866617
Validation loss: 2.5518015543763752

Epoch: 6| Step: 9
Training loss: 2.97321634116607
Validation loss: 2.5389219430997243

Epoch: 6| Step: 10
Training loss: 2.192079600413347
Validation loss: 2.562396706460874

Epoch: 6| Step: 11
Training loss: 2.0251085605485044
Validation loss: 2.539481424837926

Epoch: 6| Step: 12
Training loss: 3.148049607531929
Validation loss: 2.542952639542902

Epoch: 6| Step: 13
Training loss: 2.792162286594419
Validation loss: 2.583142294023993

Epoch: 17| Step: 0
Training loss: 2.1873183038728667
Validation loss: 2.536864251484217

Epoch: 6| Step: 1
Training loss: 2.3113167287169403
Validation loss: 2.534324145012634

Epoch: 6| Step: 2
Training loss: 2.0880171449330054
Validation loss: 2.549695908110664

Epoch: 6| Step: 3
Training loss: 2.5150827332799452
Validation loss: 2.5360214880735903

Epoch: 6| Step: 4
Training loss: 2.0505406992476987
Validation loss: 2.5245433073327845

Epoch: 6| Step: 5
Training loss: 2.697765174255314
Validation loss: 2.5041399215395597

Epoch: 6| Step: 6
Training loss: 2.509800868399191
Validation loss: 2.5100039120373885

Epoch: 6| Step: 7
Training loss: 3.180357316533417
Validation loss: 2.517873639661758

Epoch: 6| Step: 8
Training loss: 1.9002097691634838
Validation loss: 2.5337381810102557

Epoch: 6| Step: 9
Training loss: 2.336932528558728
Validation loss: 2.541673321532829

Epoch: 6| Step: 10
Training loss: 2.8635390349082654
Validation loss: 2.519887010952782

Epoch: 6| Step: 11
Training loss: 2.6858000590880664
Validation loss: 2.5151920143427358

Epoch: 6| Step: 12
Training loss: 3.059496905788323
Validation loss: 2.5362833943181

Epoch: 6| Step: 13
Training loss: 2.9894975567960986
Validation loss: 2.520159825814755

Epoch: 18| Step: 0
Training loss: 3.1710110695175646
Validation loss: 2.5233213636130376

Epoch: 6| Step: 1
Training loss: 2.689523334459391
Validation loss: 2.515997762290412

Epoch: 6| Step: 2
Training loss: 2.4867624770960086
Validation loss: 2.5073235214316623

Epoch: 6| Step: 3
Training loss: 1.8986053392604236
Validation loss: 2.5199311562499633

Epoch: 6| Step: 4
Training loss: 2.867489500018238
Validation loss: 2.5402683778837676

Epoch: 6| Step: 5
Training loss: 2.6281768104263445
Validation loss: 2.5171971117874468

Epoch: 6| Step: 6
Training loss: 2.6056568815605456
Validation loss: 2.5289337565242387

Epoch: 6| Step: 7
Training loss: 2.6065380641631997
Validation loss: 2.5285478305126015

Epoch: 6| Step: 8
Training loss: 3.0479241545544573
Validation loss: 2.5187648425678533

Epoch: 6| Step: 9
Training loss: 2.919834668952774
Validation loss: 2.515248272411068

Epoch: 6| Step: 10
Training loss: 1.7152122848850107
Validation loss: 2.516702409410447

Epoch: 6| Step: 11
Training loss: 2.266593988973775
Validation loss: 2.5264326966173694

Epoch: 6| Step: 12
Training loss: 2.051588731468761
Validation loss: 2.5070486044151807

Epoch: 6| Step: 13
Training loss: 2.475838251441771
Validation loss: 2.5185535041892093

Epoch: 19| Step: 0
Training loss: 2.5536642562654994
Validation loss: 2.5241928308624764

Epoch: 6| Step: 1
Training loss: 2.9112518910671725
Validation loss: 2.5261334327205778

Epoch: 6| Step: 2
Training loss: 2.155750935615019
Validation loss: 2.5214429281163846

Epoch: 6| Step: 3
Training loss: 2.6269675555772323
Validation loss: 2.51408951458149

Epoch: 6| Step: 4
Training loss: 2.4021562704728883
Validation loss: 2.5253538840547654

Epoch: 6| Step: 5
Training loss: 2.5608967673673986
Validation loss: 2.5261809923479266

Epoch: 6| Step: 6
Training loss: 3.373384159544568
Validation loss: 2.537805177474249

Epoch: 6| Step: 7
Training loss: 2.1869554114242056
Validation loss: 2.523519398528482

Epoch: 6| Step: 8
Training loss: 2.8605272650030247
Validation loss: 2.5352459829444256

Epoch: 6| Step: 9
Training loss: 2.7010630422252184
Validation loss: 2.5483834026059244

Epoch: 6| Step: 10
Training loss: 1.725905901999339
Validation loss: 2.515285382141418

Epoch: 6| Step: 11
Training loss: 2.5879159602238624
Validation loss: 2.5329474656176343

Epoch: 6| Step: 12
Training loss: 2.033839174834878
Validation loss: 2.5165329473435496

Epoch: 6| Step: 13
Training loss: 2.4516069124963034
Validation loss: 2.531604522242038

Epoch: 20| Step: 0
Training loss: 2.306516484110484
Validation loss: 2.523171803567364

Epoch: 6| Step: 1
Training loss: 2.1811861744808905
Validation loss: 2.5257022800090354

Epoch: 6| Step: 2
Training loss: 1.9790369760953648
Validation loss: 2.5178128950076015

Epoch: 6| Step: 3
Training loss: 2.540857425957901
Validation loss: 2.51306656448314

Epoch: 6| Step: 4
Training loss: 2.520438475987179
Validation loss: 2.5233390481834586

Epoch: 6| Step: 5
Training loss: 1.9453123774394414
Validation loss: 2.5512773343929713

Epoch: 6| Step: 6
Training loss: 2.8712198035147387
Validation loss: 2.526674829682053

Epoch: 6| Step: 7
Training loss: 2.1482961157314184
Validation loss: 2.548383535144711

Epoch: 6| Step: 8
Training loss: 2.4160553937397413
Validation loss: 2.5393430662420133

Epoch: 6| Step: 9
Training loss: 3.27502694155262
Validation loss: 2.5412395983581773

Epoch: 6| Step: 10
Training loss: 2.9219249374283764
Validation loss: 2.521291412684176

Epoch: 6| Step: 11
Training loss: 1.989173913608748
Validation loss: 2.5071132711083646

Epoch: 6| Step: 12
Training loss: 3.1544539374112777
Validation loss: 2.5436639572825315

Epoch: 6| Step: 13
Training loss: 2.6466641861193714
Validation loss: 2.5146175444350334

Epoch: 21| Step: 0
Training loss: 2.997479651654863
Validation loss: 2.5102959177780275

Epoch: 6| Step: 1
Training loss: 2.8523434758349464
Validation loss: 2.50212542466443

Epoch: 6| Step: 2
Training loss: 2.790046838756883
Validation loss: 2.5050062440399703

Epoch: 6| Step: 3
Training loss: 1.831385126433881
Validation loss: 2.5107746317530513

Epoch: 6| Step: 4
Training loss: 1.998614308019854
Validation loss: 2.498179551757645

Epoch: 6| Step: 5
Training loss: 2.645085376738913
Validation loss: 2.5164582588310958

Epoch: 6| Step: 6
Training loss: 2.2817834726793484
Validation loss: 2.4896020981681324

Epoch: 6| Step: 7
Training loss: 2.9180092764086667
Validation loss: 2.500375417496138

Epoch: 6| Step: 8
Training loss: 2.7810528288826397
Validation loss: 2.500764380265737

Epoch: 6| Step: 9
Training loss: 1.7868377312332502
Validation loss: 2.5128816450770866

Epoch: 6| Step: 10
Training loss: 2.7148037036165102
Validation loss: 2.497202372822736

Epoch: 6| Step: 11
Training loss: 2.3294367838885552
Validation loss: 2.5040743766911477

Epoch: 6| Step: 12
Training loss: 2.5161138024117693
Validation loss: 2.5062437686858554

Epoch: 6| Step: 13
Training loss: 2.319185644801578
Validation loss: 2.4856715787597157

Epoch: 22| Step: 0
Training loss: 3.305784796308864
Validation loss: 2.5089250198336535

Epoch: 6| Step: 1
Training loss: 2.9159381138182896
Validation loss: 2.4990332641646873

Epoch: 6| Step: 2
Training loss: 2.5290362249565215
Validation loss: 2.4907398064995134

Epoch: 6| Step: 3
Training loss: 2.609655490807299
Validation loss: 2.5101108813269564

Epoch: 6| Step: 4
Training loss: 2.1674058338024467
Validation loss: 2.5173050224515854

Epoch: 6| Step: 5
Training loss: 1.9507781310203591
Validation loss: 2.5091263447941023

Epoch: 6| Step: 6
Training loss: 2.159164670204448
Validation loss: 2.502122407259248

Epoch: 6| Step: 7
Training loss: 2.4839864942886853
Validation loss: 2.4989722046514165

Epoch: 6| Step: 8
Training loss: 2.414639203465014
Validation loss: 2.503064407332793

Epoch: 6| Step: 9
Training loss: 2.637696216389608
Validation loss: 2.497443338259911

Epoch: 6| Step: 10
Training loss: 2.0311650185047645
Validation loss: 2.5162761943203518

Epoch: 6| Step: 11
Training loss: 2.5090605580337466
Validation loss: 2.490668763813644

Epoch: 6| Step: 12
Training loss: 3.028609236509508
Validation loss: 2.518881859494941

Epoch: 6| Step: 13
Training loss: 2.1852757726392635
Validation loss: 2.476551236388769

Epoch: 23| Step: 0
Training loss: 2.4564864338461976
Validation loss: 2.5167193194643476

Epoch: 6| Step: 1
Training loss: 3.158070407548832
Validation loss: 2.4969279646875733

Epoch: 6| Step: 2
Training loss: 3.0695542037311467
Validation loss: 2.5094716099011483

Epoch: 6| Step: 3
Training loss: 2.0864298378770827
Validation loss: 2.5064932105064197

Epoch: 6| Step: 4
Training loss: 2.666864437478396
Validation loss: 2.499861260379084

Epoch: 6| Step: 5
Training loss: 2.3508049134280187
Validation loss: 2.5043886923044787

Epoch: 6| Step: 6
Training loss: 2.4709182102834566
Validation loss: 2.500374368611678

Epoch: 6| Step: 7
Training loss: 2.0409789451698086
Validation loss: 2.4801399073053014

Epoch: 6| Step: 8
Training loss: 2.5021200727380046
Validation loss: 2.498305143596399

Epoch: 6| Step: 9
Training loss: 2.2871273049841587
Validation loss: 2.512442342688113

Epoch: 6| Step: 10
Training loss: 3.0604046251143635
Validation loss: 2.5118874611363142

Epoch: 6| Step: 11
Training loss: 2.2596729889315266
Validation loss: 2.485458281798287

Epoch: 6| Step: 12
Training loss: 2.1810233012008053
Validation loss: 2.502658352511698

Epoch: 6| Step: 13
Training loss: 1.9652816860787659
Validation loss: 2.512997694683118

Epoch: 24| Step: 0
Training loss: 2.4565821299334565
Validation loss: 2.5105208748574652

Epoch: 6| Step: 1
Training loss: 2.465630600684783
Validation loss: 2.489533177805626

Epoch: 6| Step: 2
Training loss: 1.8542855113942738
Validation loss: 2.463280860908107

Epoch: 6| Step: 3
Training loss: 2.158598574489044
Validation loss: 2.507255595356763

Epoch: 6| Step: 4
Training loss: 3.5314316154295793
Validation loss: 2.496017383248979

Epoch: 6| Step: 5
Training loss: 2.7127058873947885
Validation loss: 2.494210389868509

Epoch: 6| Step: 6
Training loss: 2.7719542069498995
Validation loss: 2.506150056109853

Epoch: 6| Step: 7
Training loss: 2.537896084996099
Validation loss: 2.505630367733528

Epoch: 6| Step: 8
Training loss: 2.7121588074878087
Validation loss: 2.5070976910257405

Epoch: 6| Step: 9
Training loss: 2.128181096036438
Validation loss: 2.488196019699682

Epoch: 6| Step: 10
Training loss: 2.6350731808020766
Validation loss: 2.5171987535291036

Epoch: 6| Step: 11
Training loss: 2.172540466669191
Validation loss: 2.4742272535362058

Epoch: 6| Step: 12
Training loss: 2.4632221576584876
Validation loss: 2.4918210070044946

Epoch: 6| Step: 13
Training loss: 2.5419946260913195
Validation loss: 2.4857094177945918

Epoch: 25| Step: 0
Training loss: 2.4015036998293775
Validation loss: 2.479504319179204

Epoch: 6| Step: 1
Training loss: 2.787448020416204
Validation loss: 2.467988729803607

Epoch: 6| Step: 2
Training loss: 2.6926508490933783
Validation loss: 2.512395946442002

Epoch: 6| Step: 3
Training loss: 2.631625488020284
Validation loss: 2.516626589079132

Epoch: 6| Step: 4
Training loss: 1.5523423185759473
Validation loss: 2.524421279670635

Epoch: 6| Step: 5
Training loss: 2.006950460540073
Validation loss: 2.5602660637419783

Epoch: 6| Step: 6
Training loss: 2.9502261834800745
Validation loss: 2.599527504365233

Epoch: 6| Step: 7
Training loss: 2.5419706152441353
Validation loss: 2.625052951097031

Epoch: 6| Step: 8
Training loss: 2.74744053423104
Validation loss: 2.5838520441941752

Epoch: 6| Step: 9
Training loss: 2.738843133719163
Validation loss: 2.57528113524866

Epoch: 6| Step: 10
Training loss: 2.51997681455694
Validation loss: 2.5846573041602503

Epoch: 6| Step: 11
Training loss: 2.7112540903935547
Validation loss: 2.571483913272664

Epoch: 6| Step: 12
Training loss: 2.1186248292211123
Validation loss: 2.5389131237986144

Epoch: 6| Step: 13
Training loss: 2.6094575058005556
Validation loss: 2.5114360707605705

Epoch: 26| Step: 0
Training loss: 2.7635693857983865
Validation loss: 2.4924481374203564

Epoch: 6| Step: 1
Training loss: 2.3908350235179707
Validation loss: 2.48986138635906

Epoch: 6| Step: 2
Training loss: 2.332445475277311
Validation loss: 2.4860418394112074

Epoch: 6| Step: 3
Training loss: 2.9684020792221975
Validation loss: 2.476369134231405

Epoch: 6| Step: 4
Training loss: 2.5360327852578783
Validation loss: 2.4807181325588727

Epoch: 6| Step: 5
Training loss: 3.1167860800430303
Validation loss: 2.4819409424535857

Epoch: 6| Step: 6
Training loss: 1.9842850071482943
Validation loss: 2.4950393893560627

Epoch: 6| Step: 7
Training loss: 1.7483797747344367
Validation loss: 2.4840618711947378

Epoch: 6| Step: 8
Training loss: 3.0009853016570607
Validation loss: 2.5061205487261615

Epoch: 6| Step: 9
Training loss: 1.789447859527562
Validation loss: 2.4786085627901846

Epoch: 6| Step: 10
Training loss: 2.1536008621803586
Validation loss: 2.4763156755837707

Epoch: 6| Step: 11
Training loss: 2.754392583664109
Validation loss: 2.4572040717432797

Epoch: 6| Step: 12
Training loss: 2.516048040419582
Validation loss: 2.4746817618613957

Epoch: 6| Step: 13
Training loss: 2.3507496388909845
Validation loss: 2.48423493188398

Epoch: 27| Step: 0
Training loss: 2.8890893104509954
Validation loss: 2.4930519908595006

Epoch: 6| Step: 1
Training loss: 2.2555342534922316
Validation loss: 2.487769281326346

Epoch: 6| Step: 2
Training loss: 1.8800880062526018
Validation loss: 2.496718255423818

Epoch: 6| Step: 3
Training loss: 2.365965272727588
Validation loss: 2.4807269825519627

Epoch: 6| Step: 4
Training loss: 2.5194698355826546
Validation loss: 2.5052605833022854

Epoch: 6| Step: 5
Training loss: 2.5254763465488126
Validation loss: 2.49822938524257

Epoch: 6| Step: 6
Training loss: 2.239775633133771
Validation loss: 2.489707964939173

Epoch: 6| Step: 7
Training loss: 2.3286706681798233
Validation loss: 2.472751095335318

Epoch: 6| Step: 8
Training loss: 2.7533177389514556
Validation loss: 2.4922008135369227

Epoch: 6| Step: 9
Training loss: 2.6867746660692795
Validation loss: 2.4886420371145457

Epoch: 6| Step: 10
Training loss: 2.466915849608882
Validation loss: 2.488023897333769

Epoch: 6| Step: 11
Training loss: 2.843868378910561
Validation loss: 2.502915732485848

Epoch: 6| Step: 12
Training loss: 2.5557051098872132
Validation loss: 2.488946319761398

Epoch: 6| Step: 13
Training loss: 2.299138932133974
Validation loss: 2.4816212217073867

Epoch: 28| Step: 0
Training loss: 2.4439270189567477
Validation loss: 2.5106045558997

Epoch: 6| Step: 1
Training loss: 2.692856440845787
Validation loss: 2.496410598504375

Epoch: 6| Step: 2
Training loss: 2.1134309556998776
Validation loss: 2.5217117376474456

Epoch: 6| Step: 3
Training loss: 2.225813354817654
Validation loss: 2.5269661119596827

Epoch: 6| Step: 4
Training loss: 2.1414680769859156
Validation loss: 2.4774189139145126

Epoch: 6| Step: 5
Training loss: 2.8199241138285025
Validation loss: 2.501043793215173

Epoch: 6| Step: 6
Training loss: 2.6045147981009076
Validation loss: 2.4858931695137234

Epoch: 6| Step: 7
Training loss: 2.430383220799771
Validation loss: 2.4879227743828234

Epoch: 6| Step: 8
Training loss: 2.2824221173439243
Validation loss: 2.5125329026555607

Epoch: 6| Step: 9
Training loss: 3.100770633032498
Validation loss: 2.4946732356897203

Epoch: 6| Step: 10
Training loss: 2.6431306767397085
Validation loss: 2.4887675354622583

Epoch: 6| Step: 11
Training loss: 2.456032748721598
Validation loss: 2.48328480502424

Epoch: 6| Step: 12
Training loss: 2.3261472763183004
Validation loss: 2.478605228184191

Epoch: 6| Step: 13
Training loss: 2.0479884722653443
Validation loss: 2.499644524415125

Epoch: 29| Step: 0
Training loss: 2.2120573085859476
Validation loss: 2.4964237064699044

Epoch: 6| Step: 1
Training loss: 2.504995980783006
Validation loss: 2.4997489962139134

Epoch: 6| Step: 2
Training loss: 2.0629973534378925
Validation loss: 2.495591090636164

Epoch: 6| Step: 3
Training loss: 2.7178684427732884
Validation loss: 2.502930902011203

Epoch: 6| Step: 4
Training loss: 2.62532513739277
Validation loss: 2.4943831606414184

Epoch: 6| Step: 5
Training loss: 3.3173608203660936
Validation loss: 2.5140368264110178

Epoch: 6| Step: 6
Training loss: 1.974833218256468
Validation loss: 2.5007888185258857

Epoch: 6| Step: 7
Training loss: 2.4024367399749154
Validation loss: 2.48889712263015

Epoch: 6| Step: 8
Training loss: 2.9337226443159166
Validation loss: 2.492096280428568

Epoch: 6| Step: 9
Training loss: 2.5511408927647112
Validation loss: 2.4854464030079053

Epoch: 6| Step: 10
Training loss: 2.2104933868909833
Validation loss: 2.5294390114376952

Epoch: 6| Step: 11
Training loss: 2.391911976779891
Validation loss: 2.5028533308706122

Epoch: 6| Step: 12
Training loss: 2.0610674882895466
Validation loss: 2.4745612657904084

Epoch: 6| Step: 13
Training loss: 2.3053773009345577
Validation loss: 2.491832241459796

Epoch: 30| Step: 0
Training loss: 1.9933982012580143
Validation loss: 2.488202679170617

Epoch: 6| Step: 1
Training loss: 2.544158891436277
Validation loss: 2.516930393480603

Epoch: 6| Step: 2
Training loss: 2.3730884689641814
Validation loss: 2.483822391237704

Epoch: 6| Step: 3
Training loss: 1.82635190351755
Validation loss: 2.4737086334033855

Epoch: 6| Step: 4
Training loss: 2.7715851091354557
Validation loss: 2.4902747137255687

Epoch: 6| Step: 5
Training loss: 2.2653785308421392
Validation loss: 2.4966975970659044

Epoch: 6| Step: 6
Training loss: 2.1626624250327273
Validation loss: 2.484497563119933

Epoch: 6| Step: 7
Training loss: 3.189487211812646
Validation loss: 2.5094590530475127

Epoch: 6| Step: 8
Training loss: 2.489836441857607
Validation loss: 2.496302890920853

Epoch: 6| Step: 9
Training loss: 2.53615932281822
Validation loss: 2.497550288659212

Epoch: 6| Step: 10
Training loss: 2.1845913759391893
Validation loss: 2.5020618678137505

Epoch: 6| Step: 11
Training loss: 2.514776809526722
Validation loss: 2.4897039269857077

Epoch: 6| Step: 12
Training loss: 2.464617783818112
Validation loss: 2.5073383235565623

Epoch: 6| Step: 13
Training loss: 2.8577994920404306
Validation loss: 2.475287067899281

Epoch: 31| Step: 0
Training loss: 2.251316744902073
Validation loss: 2.4472868467619953

Epoch: 6| Step: 1
Training loss: 2.7783343859485385
Validation loss: 2.462076002497295

Epoch: 6| Step: 2
Training loss: 2.1347530047016594
Validation loss: 2.456356139797719

Epoch: 6| Step: 3
Training loss: 2.3907574386313417
Validation loss: 2.463674059180856

Epoch: 6| Step: 4
Training loss: 2.527084691067483
Validation loss: 2.5123117240343196

Epoch: 6| Step: 5
Training loss: 2.7417593510352543
Validation loss: 2.4556609407550365

Epoch: 6| Step: 6
Training loss: 2.062968345410331
Validation loss: 2.481711929652325

Epoch: 6| Step: 7
Training loss: 2.840633151438215
Validation loss: 2.489199274890575

Epoch: 6| Step: 8
Training loss: 2.0370939259661074
Validation loss: 2.466888756247735

Epoch: 6| Step: 9
Training loss: 2.3841686954465215
Validation loss: 2.4656369987811475

Epoch: 6| Step: 10
Training loss: 2.3436289438137896
Validation loss: 2.4720527189583654

Epoch: 6| Step: 11
Training loss: 2.7432608826697003
Validation loss: 2.479410549531122

Epoch: 6| Step: 12
Training loss: 3.0437678217121347
Validation loss: 2.469941378887521

Epoch: 6| Step: 13
Training loss: 2.0918591059983327
Validation loss: 2.501222311664472

Epoch: 32| Step: 0
Training loss: 3.1095347914539717
Validation loss: 2.487203175840071

Epoch: 6| Step: 1
Training loss: 2.6330337205082923
Validation loss: 2.500891574188649

Epoch: 6| Step: 2
Training loss: 2.84281050704747
Validation loss: 2.4819299594157846

Epoch: 6| Step: 3
Training loss: 2.228666041360521
Validation loss: 2.5076969234972544

Epoch: 6| Step: 4
Training loss: 2.4188070246162185
Validation loss: 2.5017728718276016

Epoch: 6| Step: 5
Training loss: 2.5440939480930402
Validation loss: 2.494049747716284

Epoch: 6| Step: 6
Training loss: 2.404725223317251
Validation loss: 2.5141993998857095

Epoch: 6| Step: 7
Training loss: 1.8809635692031448
Validation loss: 2.4839694013932627

Epoch: 6| Step: 8
Training loss: 2.678311008327883
Validation loss: 2.523518477361967

Epoch: 6| Step: 9
Training loss: 2.5082383789474636
Validation loss: 2.5009028552860997

Epoch: 6| Step: 10
Training loss: 2.5604725702533937
Validation loss: 2.5663638254159293

Epoch: 6| Step: 11
Training loss: 2.0338142055699975
Validation loss: 2.5223146190141468

Epoch: 6| Step: 12
Training loss: 2.163720940582639
Validation loss: 2.541552577558894

Epoch: 6| Step: 13
Training loss: 1.9856246857947562
Validation loss: 2.4973764720453975

Epoch: 33| Step: 0
Training loss: 2.789820463905374
Validation loss: 2.478337082320223

Epoch: 6| Step: 1
Training loss: 2.412613023077073
Validation loss: 2.4883029523588753

Epoch: 6| Step: 2
Training loss: 2.1836248678811914
Validation loss: 2.4985522687777117

Epoch: 6| Step: 3
Training loss: 1.9107984465741477
Validation loss: 2.466667842435127

Epoch: 6| Step: 4
Training loss: 2.234790683306461
Validation loss: 2.4737933187497267

Epoch: 6| Step: 5
Training loss: 2.371710255647423
Validation loss: 2.4881863897857293

Epoch: 6| Step: 6
Training loss: 2.565066285345814
Validation loss: 2.4596805975611216

Epoch: 6| Step: 7
Training loss: 3.0714534745838495
Validation loss: 2.47363216994004

Epoch: 6| Step: 8
Training loss: 2.6437960212615828
Validation loss: 2.4728579727659015

Epoch: 6| Step: 9
Training loss: 1.8514823413349826
Validation loss: 2.4739414468824736

Epoch: 6| Step: 10
Training loss: 2.2892772586837236
Validation loss: 2.481174606856165

Epoch: 6| Step: 11
Training loss: 2.9701014604802434
Validation loss: 2.4956106117318444

Epoch: 6| Step: 12
Training loss: 2.6870996043885365
Validation loss: 2.475435804922231

Epoch: 6| Step: 13
Training loss: 2.072469947514224
Validation loss: 2.494181505952079

Epoch: 34| Step: 0
Training loss: 2.2724698553824263
Validation loss: 2.488506089397039

Epoch: 6| Step: 1
Training loss: 2.091198747534694
Validation loss: 2.4684072489964852

Epoch: 6| Step: 2
Training loss: 2.4623725703230503
Validation loss: 2.488818515362642

Epoch: 6| Step: 3
Training loss: 2.636493045895378
Validation loss: 2.482098141862403

Epoch: 6| Step: 4
Training loss: 2.5492892378035408
Validation loss: 2.4565853812056275

Epoch: 6| Step: 5
Training loss: 2.4001981256086533
Validation loss: 2.4822532822659635

Epoch: 6| Step: 6
Training loss: 2.5714263821395758
Validation loss: 2.478455887744201

Epoch: 6| Step: 7
Training loss: 2.182141088663829
Validation loss: 2.482135154879448

Epoch: 6| Step: 8
Training loss: 2.6501867768305316
Validation loss: 2.4565229026476842

Epoch: 6| Step: 9
Training loss: 2.24891636502884
Validation loss: 2.4648559376555856

Epoch: 6| Step: 10
Training loss: 2.5143283321744394
Validation loss: 2.478178489848586

Epoch: 6| Step: 11
Training loss: 2.130850871459889
Validation loss: 2.4482092797454515

Epoch: 6| Step: 12
Training loss: 2.6243713171020744
Validation loss: 2.4918807108960115

Epoch: 6| Step: 13
Training loss: 2.856138304815674
Validation loss: 2.4795915469293885

Epoch: 35| Step: 0
Training loss: 2.3630732168896813
Validation loss: 2.5058606594495685

Epoch: 6| Step: 1
Training loss: 3.0071025059959933
Validation loss: 2.497014687219073

Epoch: 6| Step: 2
Training loss: 1.8340612035874482
Validation loss: 2.478974604713656

Epoch: 6| Step: 3
Training loss: 2.3005832140007967
Validation loss: 2.4898826600070616

Epoch: 6| Step: 4
Training loss: 2.688409340957195
Validation loss: 2.484701379094258

Epoch: 6| Step: 5
Training loss: 1.8053023046595567
Validation loss: 2.481268702195515

Epoch: 6| Step: 6
Training loss: 1.8214330539594785
Validation loss: 2.454421767710521

Epoch: 6| Step: 7
Training loss: 2.5147611663142673
Validation loss: 2.4550116344624247

Epoch: 6| Step: 8
Training loss: 3.0273991930406927
Validation loss: 2.497699927205754

Epoch: 6| Step: 9
Training loss: 1.563964157747469
Validation loss: 2.500909520643002

Epoch: 6| Step: 10
Training loss: 2.584012793329179
Validation loss: 2.5432737434184087

Epoch: 6| Step: 11
Training loss: 3.3503993579189846
Validation loss: 2.48805110392058

Epoch: 6| Step: 12
Training loss: 2.446417708069486
Validation loss: 2.4894202004671726

Epoch: 6| Step: 13
Training loss: 1.8302646733229766
Validation loss: 2.4877644974935875

Epoch: 36| Step: 0
Training loss: 2.7444301031701506
Validation loss: 2.493684890840422

Epoch: 6| Step: 1
Training loss: 2.4659479391476262
Validation loss: 2.4935158245940237

Epoch: 6| Step: 2
Training loss: 2.259076777571513
Validation loss: 2.485073559194894

Epoch: 6| Step: 3
Training loss: 2.4999853133723877
Validation loss: 2.521046626837941

Epoch: 6| Step: 4
Training loss: 2.261585607216926
Validation loss: 2.502355244959784

Epoch: 6| Step: 5
Training loss: 1.6478114091683995
Validation loss: 2.465358029583117

Epoch: 6| Step: 6
Training loss: 2.580199915215491
Validation loss: 2.4987793644599305

Epoch: 6| Step: 7
Training loss: 1.9016692358072609
Validation loss: 2.4423504521827875

Epoch: 6| Step: 8
Training loss: 2.7665558880914722
Validation loss: 2.452399144433666

Epoch: 6| Step: 9
Training loss: 2.7733918522046688
Validation loss: 2.4652035345321326

Epoch: 6| Step: 10
Training loss: 2.743893866796982
Validation loss: 2.468672191826247

Epoch: 6| Step: 11
Training loss: 2.408658692272904
Validation loss: 2.4593302811948115

Epoch: 6| Step: 12
Training loss: 2.4283365007780002
Validation loss: 2.4739239392483094

Epoch: 6| Step: 13
Training loss: 2.3744927918771954
Validation loss: 2.491155771571572

Epoch: 37| Step: 0
Training loss: 2.4802117161979393
Validation loss: 2.447795156073856

Epoch: 6| Step: 1
Training loss: 1.9846487382128772
Validation loss: 2.447376375566835

Epoch: 6| Step: 2
Training loss: 1.828631273901801
Validation loss: 2.4564760325762642

Epoch: 6| Step: 3
Training loss: 2.3069478992321715
Validation loss: 2.475175920649941

Epoch: 6| Step: 4
Training loss: 1.8114818475684
Validation loss: 2.4720309583267013

Epoch: 6| Step: 5
Training loss: 1.9351340584065815
Validation loss: 2.520036009072064

Epoch: 6| Step: 6
Training loss: 1.4531440323434397
Validation loss: 2.505414709736144

Epoch: 6| Step: 7
Training loss: 1.8365693648584704
Validation loss: 2.535576564623027

Epoch: 6| Step: 8
Training loss: 3.3261996865579793
Validation loss: 2.5256442881534173

Epoch: 6| Step: 9
Training loss: 3.0557434910478096
Validation loss: 2.5243961178641707

Epoch: 6| Step: 10
Training loss: 2.832937287718784
Validation loss: 2.5091860090752007

Epoch: 6| Step: 11
Training loss: 3.1529451196058096
Validation loss: 2.539529704611755

Epoch: 6| Step: 12
Training loss: 2.503570486519051
Validation loss: 2.515035840658206

Epoch: 6| Step: 13
Training loss: 2.5831015903345285
Validation loss: 2.515878984412602

Epoch: 38| Step: 0
Training loss: 2.709710010905352
Validation loss: 2.4999413880788994

Epoch: 6| Step: 1
Training loss: 2.15711205982899
Validation loss: 2.525301061125282

Epoch: 6| Step: 2
Training loss: 2.5327218568409506
Validation loss: 2.456495168937779

Epoch: 6| Step: 3
Training loss: 2.5503782739747742
Validation loss: 2.470132191347195

Epoch: 6| Step: 4
Training loss: 2.449690923852641
Validation loss: 2.4569465044424006

Epoch: 6| Step: 5
Training loss: 2.1515295354441286
Validation loss: 2.469352021029569

Epoch: 6| Step: 6
Training loss: 2.1517623420716827
Validation loss: 2.453690757224145

Epoch: 6| Step: 7
Training loss: 2.3677429957495173
Validation loss: 2.451380034140449

Epoch: 6| Step: 8
Training loss: 2.485647967037979
Validation loss: 2.473553374759769

Epoch: 6| Step: 9
Training loss: 2.0707365933188875
Validation loss: 2.47361335892325

Epoch: 6| Step: 10
Training loss: 2.9557644790130873
Validation loss: 2.461026903577125

Epoch: 6| Step: 11
Training loss: 1.9150334600807266
Validation loss: 2.4445080881310726

Epoch: 6| Step: 12
Training loss: 1.9693523878072356
Validation loss: 2.484288643989558

Epoch: 6| Step: 13
Training loss: 3.0020414400233033
Validation loss: 2.4733587856945296

Epoch: 39| Step: 0
Training loss: 2.1069785739875657
Validation loss: 2.499140178323384

Epoch: 6| Step: 1
Training loss: 1.914059012273608
Validation loss: 2.447523715898263

Epoch: 6| Step: 2
Training loss: 2.5027908006847452
Validation loss: 2.4921503811646013

Epoch: 6| Step: 3
Training loss: 2.3130981084233966
Validation loss: 2.467044176605832

Epoch: 6| Step: 4
Training loss: 2.8921794938646954
Validation loss: 2.4684804133405103

Epoch: 6| Step: 5
Training loss: 1.4022307283978437
Validation loss: 2.531755224285861

Epoch: 6| Step: 6
Training loss: 1.9934989651576127
Validation loss: 2.5188410087027124

Epoch: 6| Step: 7
Training loss: 3.012736305687476
Validation loss: 2.52713877393557

Epoch: 6| Step: 8
Training loss: 2.6549666951132633
Validation loss: 2.4994072847283624

Epoch: 6| Step: 9
Training loss: 3.4194437386616787
Validation loss: 2.484099302849063

Epoch: 6| Step: 10
Training loss: 2.2864074933099454
Validation loss: 2.456070211170602

Epoch: 6| Step: 11
Training loss: 2.1274439277835353
Validation loss: 2.4806765491822182

Epoch: 6| Step: 12
Training loss: 1.980843111730097
Validation loss: 2.483170087193603

Epoch: 6| Step: 13
Training loss: 2.1822949199303268
Validation loss: 2.4711114880173133

Epoch: 40| Step: 0
Training loss: 2.965975458723981
Validation loss: 2.45195544764735

Epoch: 6| Step: 1
Training loss: 1.9484038398239651
Validation loss: 2.467323663782101

Epoch: 6| Step: 2
Training loss: 1.860476832540071
Validation loss: 2.4553557698960202

Epoch: 6| Step: 3
Training loss: 2.2804890238692845
Validation loss: 2.473050383884317

Epoch: 6| Step: 4
Training loss: 2.011129170659274
Validation loss: 2.477292816591294

Epoch: 6| Step: 5
Training loss: 2.6823956120667605
Validation loss: 2.4673431025296804

Epoch: 6| Step: 6
Training loss: 2.146297096086749
Validation loss: 2.4597786329399094

Epoch: 6| Step: 7
Training loss: 1.8253265219399482
Validation loss: 2.4848265567403724

Epoch: 6| Step: 8
Training loss: 2.2601703093507153
Validation loss: 2.481647177487976

Epoch: 6| Step: 9
Training loss: 2.2403277084211104
Validation loss: 2.4895138165545823

Epoch: 6| Step: 10
Training loss: 2.5545263210395843
Validation loss: 2.4968232077461647

Epoch: 6| Step: 11
Training loss: 2.7188691737922954
Validation loss: 2.4595229347133194

Epoch: 6| Step: 12
Training loss: 3.238232657110534
Validation loss: 2.4878234761582196

Epoch: 6| Step: 13
Training loss: 2.2454535857427778
Validation loss: 2.448701762382627

Epoch: 41| Step: 0
Training loss: 2.308104384139395
Validation loss: 2.5074713802764483

Epoch: 6| Step: 1
Training loss: 1.762335354304479
Validation loss: 2.4926391160480867

Epoch: 6| Step: 2
Training loss: 2.181968015525518
Validation loss: 2.4591279658296434

Epoch: 6| Step: 3
Training loss: 1.9331794680282737
Validation loss: 2.4637057926489794

Epoch: 6| Step: 4
Training loss: 2.069655749679201
Validation loss: 2.5158368370947417

Epoch: 6| Step: 5
Training loss: 2.810947328712536
Validation loss: 2.449516785257272

Epoch: 6| Step: 6
Training loss: 2.7885965764868255
Validation loss: 2.4840896970445634

Epoch: 6| Step: 7
Training loss: 3.0798904855257487
Validation loss: 2.445091440692095

Epoch: 6| Step: 8
Training loss: 2.4715842865762507
Validation loss: 2.4825409171121646

Epoch: 6| Step: 9
Training loss: 2.660135277484783
Validation loss: 2.4627443976558805

Epoch: 6| Step: 10
Training loss: 2.3299739587335444
Validation loss: 2.452111846922258

Epoch: 6| Step: 11
Training loss: 2.5385294662848192
Validation loss: 2.489708874674821

Epoch: 6| Step: 12
Training loss: 2.420066699850662
Validation loss: 2.4552950969304406

Epoch: 6| Step: 13
Training loss: 2.3170967809676415
Validation loss: 2.4133966179799544

Epoch: 42| Step: 0
Training loss: 1.993072193650798
Validation loss: 2.4927145341880266

Epoch: 6| Step: 1
Training loss: 2.196717813655644
Validation loss: 2.460077416021126

Epoch: 6| Step: 2
Training loss: 2.899725039370988
Validation loss: 2.473615728380293

Epoch: 6| Step: 3
Training loss: 2.0000051259928817
Validation loss: 2.4815251701483

Epoch: 6| Step: 4
Training loss: 2.5321825923257757
Validation loss: 2.467173060640066

Epoch: 6| Step: 5
Training loss: 2.051370822990804
Validation loss: 2.4969386032591063

Epoch: 6| Step: 6
Training loss: 2.5966610486415016
Validation loss: 2.479547636962859

Epoch: 6| Step: 7
Training loss: 2.2840717578845933
Validation loss: 2.470954747511099

Epoch: 6| Step: 8
Training loss: 1.8054585316664742
Validation loss: 2.4988539691570733

Epoch: 6| Step: 9
Training loss: 2.713300307382954
Validation loss: 2.46368108332046

Epoch: 6| Step: 10
Training loss: 1.8882860580591456
Validation loss: 2.495663617264661

Epoch: 6| Step: 11
Training loss: 2.6745256805584794
Validation loss: 2.493052206034227

Epoch: 6| Step: 12
Training loss: 2.7363797059735098
Validation loss: 2.534340984525432

Epoch: 6| Step: 13
Training loss: 2.5456058639904793
Validation loss: 2.4914267165024317

Epoch: 43| Step: 0
Training loss: 2.226790459993051
Validation loss: 2.5149737792673754

Epoch: 6| Step: 1
Training loss: 2.595178417621245
Validation loss: 2.4820114504775184

Epoch: 6| Step: 2
Training loss: 2.0917991545564143
Validation loss: 2.5232541674142968

Epoch: 6| Step: 3
Training loss: 1.5930166614281367
Validation loss: 2.4791140564110035

Epoch: 6| Step: 4
Training loss: 2.5734817769747074
Validation loss: 2.49428537815516

Epoch: 6| Step: 5
Training loss: 2.545693527187197
Validation loss: 2.5224355907301423

Epoch: 6| Step: 6
Training loss: 2.3428711324201
Validation loss: 2.512231532188388

Epoch: 6| Step: 7
Training loss: 2.8809244232592666
Validation loss: 2.460667735658777

Epoch: 6| Step: 8
Training loss: 2.5885215364488325
Validation loss: 2.463492311678194

Epoch: 6| Step: 9
Training loss: 2.516526907604363
Validation loss: 2.4471705713304814

Epoch: 6| Step: 10
Training loss: 2.40468417657594
Validation loss: 2.4663462223436783

Epoch: 6| Step: 11
Training loss: 2.1432259900674806
Validation loss: 2.4776402804747404

Epoch: 6| Step: 12
Training loss: 2.199319027499853
Validation loss: 2.4593725163254563

Epoch: 6| Step: 13
Training loss: 2.382265722358408
Validation loss: 2.476538753295392

Epoch: 44| Step: 0
Training loss: 1.97758318816511
Validation loss: 2.4703207370943243

Epoch: 6| Step: 1
Training loss: 2.900981434459906
Validation loss: 2.444449324193573

Epoch: 6| Step: 2
Training loss: 2.64686623383819
Validation loss: 2.499483007380518

Epoch: 6| Step: 3
Training loss: 1.7871179132309696
Validation loss: 2.4548830831414605

Epoch: 6| Step: 4
Training loss: 2.7797227588152102
Validation loss: 2.451005785660936

Epoch: 6| Step: 5
Training loss: 2.6735186066801355
Validation loss: 2.5060719503702473

Epoch: 6| Step: 6
Training loss: 2.1044920742096838
Validation loss: 2.4776542014319047

Epoch: 6| Step: 7
Training loss: 2.4121441672592
Validation loss: 2.500039020869587

Epoch: 6| Step: 8
Training loss: 1.9761891973746315
Validation loss: 2.485140676488591

Epoch: 6| Step: 9
Training loss: 2.5710434265682967
Validation loss: 2.506505005405414

Epoch: 6| Step: 10
Training loss: 2.541730025288653
Validation loss: 2.519515652078454

Epoch: 6| Step: 11
Training loss: 2.150712130399296
Validation loss: 2.483976544110242

Epoch: 6| Step: 12
Training loss: 2.5568307641230317
Validation loss: 2.473262124060434

Epoch: 6| Step: 13
Training loss: 1.7801523674891009
Validation loss: 2.4857245404585773

Epoch: 45| Step: 0
Training loss: 2.5805867781687604
Validation loss: 2.4464601498774416

Epoch: 6| Step: 1
Training loss: 2.032024059994248
Validation loss: 2.4746116230710324

Epoch: 6| Step: 2
Training loss: 3.032527693632242
Validation loss: 2.455887035313006

Epoch: 6| Step: 3
Training loss: 2.310659655723054
Validation loss: 2.46415716201898

Epoch: 6| Step: 4
Training loss: 2.113952530103273
Validation loss: 2.463826174501144

Epoch: 6| Step: 5
Training loss: 2.4844214477035838
Validation loss: 2.460164379608364

Epoch: 6| Step: 6
Training loss: 2.217128537276462
Validation loss: 2.431447151382155

Epoch: 6| Step: 7
Training loss: 2.366211038259645
Validation loss: 2.4721664498023306

Epoch: 6| Step: 8
Training loss: 2.246468527666185
Validation loss: 2.466685312969595

Epoch: 6| Step: 9
Training loss: 2.1807813736708583
Validation loss: 2.449864287737279

Epoch: 6| Step: 10
Training loss: 2.157093049144718
Validation loss: 2.4480022063764797

Epoch: 6| Step: 11
Training loss: 2.5421379361189045
Validation loss: 2.4933873300859313

Epoch: 6| Step: 12
Training loss: 2.128351373718006
Validation loss: 2.4733563276294794

Epoch: 6| Step: 13
Training loss: 2.634984600449212
Validation loss: 2.456822000800578

Epoch: 46| Step: 0
Training loss: 3.1373215947588844
Validation loss: 2.454557239646534

Epoch: 6| Step: 1
Training loss: 2.4538471106708353
Validation loss: 2.5011452833068106

Epoch: 6| Step: 2
Training loss: 2.172162482905534
Validation loss: 2.467820342583891

Epoch: 6| Step: 3
Training loss: 1.8935915789421371
Validation loss: 2.4742891003526695

Epoch: 6| Step: 4
Training loss: 1.7668921050899098
Validation loss: 2.4483132277879998

Epoch: 6| Step: 5
Training loss: 2.4314709952756375
Validation loss: 2.463984013550987

Epoch: 6| Step: 6
Training loss: 2.251294611309324
Validation loss: 2.4722688521108322

Epoch: 6| Step: 7
Training loss: 2.059693710371033
Validation loss: 2.447435621246799

Epoch: 6| Step: 8
Training loss: 2.981923959234579
Validation loss: 2.4675644389933393

Epoch: 6| Step: 9
Training loss: 2.31758826012632
Validation loss: 2.4674124494568517

Epoch: 6| Step: 10
Training loss: 1.6595969301369593
Validation loss: 2.4996500247130546

Epoch: 6| Step: 11
Training loss: 1.956092716024494
Validation loss: 2.531627053956889

Epoch: 6| Step: 12
Training loss: 3.137274477935003
Validation loss: 2.526969587172475

Epoch: 6| Step: 13
Training loss: 2.4360358902866452
Validation loss: 2.54576859888748

Epoch: 47| Step: 0
Training loss: 2.516043681494807
Validation loss: 2.516652894350814

Epoch: 6| Step: 1
Training loss: 1.9647718533961716
Validation loss: 2.488294664283897

Epoch: 6| Step: 2
Training loss: 2.1422220106287457
Validation loss: 2.464336748167328

Epoch: 6| Step: 3
Training loss: 2.379886419006295
Validation loss: 2.482538756253374

Epoch: 6| Step: 4
Training loss: 1.5732512044618616
Validation loss: 2.480843206861601

Epoch: 6| Step: 5
Training loss: 2.7130542593176172
Validation loss: 2.4823512025503036

Epoch: 6| Step: 6
Training loss: 2.4105630837308016
Validation loss: 2.4808614104654056

Epoch: 6| Step: 7
Training loss: 2.050757533345005
Validation loss: 2.447168850133318

Epoch: 6| Step: 8
Training loss: 2.647290817080083
Validation loss: 2.4658973243697933

Epoch: 6| Step: 9
Training loss: 3.2075810396775064
Validation loss: 2.4657000602381696

Epoch: 6| Step: 10
Training loss: 2.4149815066243563
Validation loss: 2.4618329876254763

Epoch: 6| Step: 11
Training loss: 2.3971104631812175
Validation loss: 2.463735025787137

Epoch: 6| Step: 12
Training loss: 2.2932762966530063
Validation loss: 2.467169887744804

Epoch: 6| Step: 13
Training loss: 2.091862411255992
Validation loss: 2.4920615440436147

Epoch: 48| Step: 0
Training loss: 2.4882644820434336
Validation loss: 2.4848515915128764

Epoch: 6| Step: 1
Training loss: 2.0238946228942054
Validation loss: 2.427460478812224

Epoch: 6| Step: 2
Training loss: 1.8472343753551947
Validation loss: 2.4753630869503835

Epoch: 6| Step: 3
Training loss: 2.139496777451155
Validation loss: 2.472541039039164

Epoch: 6| Step: 4
Training loss: 2.89880730668141
Validation loss: 2.4651943789659687

Epoch: 6| Step: 5
Training loss: 2.7934219952929813
Validation loss: 2.4872567279906295

Epoch: 6| Step: 6
Training loss: 2.259086064901648
Validation loss: 2.4589536390739437

Epoch: 6| Step: 7
Training loss: 1.8077988659502016
Validation loss: 2.4731149514159414

Epoch: 6| Step: 8
Training loss: 2.187320156878952
Validation loss: 2.4802088964323588

Epoch: 6| Step: 9
Training loss: 2.6645154819593513
Validation loss: 2.4897825541784506

Epoch: 6| Step: 10
Training loss: 2.8962474682384847
Validation loss: 2.463061753049593

Epoch: 6| Step: 11
Training loss: 2.0763993519916673
Validation loss: 2.5199595636827246

Epoch: 6| Step: 12
Training loss: 2.0870308171744703
Validation loss: 2.5230248254534136

Epoch: 6| Step: 13
Training loss: 2.4921650182971575
Validation loss: 2.494405447120053

Epoch: 49| Step: 0
Training loss: 2.78317656922638
Validation loss: 2.52133465870796

Epoch: 6| Step: 1
Training loss: 2.6970278381676143
Validation loss: 2.524903712938978

Epoch: 6| Step: 2
Training loss: 2.1855981461116363
Validation loss: 2.472167470470973

Epoch: 6| Step: 3
Training loss: 2.4621747494369965
Validation loss: 2.486660623705001

Epoch: 6| Step: 4
Training loss: 1.97111387480669
Validation loss: 2.4477141817365946

Epoch: 6| Step: 5
Training loss: 2.3708477866788704
Validation loss: 2.464496795691426

Epoch: 6| Step: 6
Training loss: 2.9227559602640927
Validation loss: 2.447088593911907

Epoch: 6| Step: 7
Training loss: 1.6041098828194587
Validation loss: 2.4845948711803136

Epoch: 6| Step: 8
Training loss: 2.130415131496048
Validation loss: 2.4879742667062295

Epoch: 6| Step: 9
Training loss: 2.863966460420508
Validation loss: 2.4661095659166588

Epoch: 6| Step: 10
Training loss: 2.0939908244998593
Validation loss: 2.491244146528703

Epoch: 6| Step: 11
Training loss: 2.2165036717579567
Validation loss: 2.4682901251894287

Epoch: 6| Step: 12
Training loss: 2.3883067340882556
Validation loss: 2.5134525277469777

Epoch: 6| Step: 13
Training loss: 2.2919480815685938
Validation loss: 2.4925607782400045

Epoch: 50| Step: 0
Training loss: 1.9659224292745645
Validation loss: 2.513489521706699

Epoch: 6| Step: 1
Training loss: 2.87172429433406
Validation loss: 2.4956329987058052

Epoch: 6| Step: 2
Training loss: 2.0938603386344323
Validation loss: 2.499907189871698

Epoch: 6| Step: 3
Training loss: 2.1188894940483047
Validation loss: 2.484527583205013

Epoch: 6| Step: 4
Training loss: 2.055693057619146
Validation loss: 2.4725513887995363

Epoch: 6| Step: 5
Training loss: 2.6519215940274594
Validation loss: 2.4236436190120747

Epoch: 6| Step: 6
Training loss: 2.2171200420072354
Validation loss: 2.421998199282669

Epoch: 6| Step: 7
Training loss: 2.60214987415989
Validation loss: 2.4753115891343076

Epoch: 6| Step: 8
Training loss: 1.4295907743492513
Validation loss: 2.4439085646339263

Epoch: 6| Step: 9
Training loss: 2.783747376884797
Validation loss: 2.486045915280384

Epoch: 6| Step: 10
Training loss: 2.371046389463426
Validation loss: 2.468712383901146

Epoch: 6| Step: 11
Training loss: 2.5552251874075242
Validation loss: 2.470405200792885

Epoch: 6| Step: 12
Training loss: 2.4466500326244276
Validation loss: 2.4518513866087766

Epoch: 6| Step: 13
Training loss: 2.6037967470013523
Validation loss: 2.4494464206689988

Testing loss: 2.080835985569352
